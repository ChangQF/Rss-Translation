<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 27 Mar 2024 21:12:20 GMT</lastBuildDate>
    <item>
      <title>实际数据集的距离矩阵不服从三角不等式，导致协方差矩阵非正定</title>
      <link>https://stats.stackexchange.com/questions/643696/distance-matrix-of-actual-dataset-doesnt-obey-triangle-inequality-leading-to-n</link>
      <description><![CDATA[昨天我问了一个问题，为什么我的随机生成的距离矩阵会导致马丁协方差矩阵不是正定的。那里的答案让我注意到这样一个事实：我生成随机生成距离矩阵的简单方法并不能确保此类矩阵遵守三角不等式。事实上，强制执行就解决了问题。
但是，我现在意识到我的真​​实数据也导致了同样的问题。也就是说，当计算数据集中行之间距离的距离矩阵时，我最终得到一个不遵守三角不等式的距离矩阵。因此，导致 Martén 协方差矩阵不是正定的。
这是我的实际数据（大约 40,000 行）的一小部分（1000 行），它确实重现了该问题，已上传到 Filebin：
actualdata.csv
这是我正在做的事情的说明：
library(Rfast) # 用于快速计算距离和检查对称性
Library(fossil) # 用于检查三角形不等式

# 加载实际数据的子集并计算距离矩阵：
X &lt;- read.csv(“实际数据.csv”)
d &lt;- Rfast:Dist(X)
d[d==0] &lt;- 0.000000000001 # 而不是零以避免数字问题

# 计算Marten协方差矩阵：
西格玛 &lt;- 1
v &lt;- 3
p &lt;- 5
项 1 &lt;- (2**(1-v))/(gamma(v))
项 2 &lt;- (sqrt(2*v)*(abs(d)/p))**v
term3 &lt;- besselK(sqrt(2*v)*(abs(d)/p), nu = v)
m &lt;- (sigma**2)*term1*term2*term3

# 检查协方差矩阵是否平方：
nrow(m) == ncol(m)

# 检查 Marten 协方差矩阵的特征值：
g &lt;- 特征值(m, only.values=TRUE, 对称 = TRUE)
print(min(g$values)) # 应该大于零，但事实并非如此
print(sum(g$values&lt;0)/length(g$values)) # 因此，这应该为零，但事实并非如此

以下是一组检查 d 是否遵守距离矩阵的所有 4 个属性的检查：
# 检查我们是否有正确的距离矩阵（警告：三角形不等式检查可能需要一段时间）：
sum(d &lt;0)==0 # 非负值？是的
sum(diag(d)!=0.000000000001)==0 # （有效）零对角线？是的
Rfast::is.symmetry(d) # 对称矩阵？是的
Fossil::tri.ineq(d) # 服从三角不等式？否（警告：这条线非常慢）

问题是：因为这里输入数据集X没有被模拟，所以我无法通过设计强制距离矩阵服从三角不等式。因此我的问题是：在这种情况下，可以采取什么措施来确保生成正定的 Martén 协方差矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/643696/distance-matrix-of-actual-dataset-doesnt-obey-triangle-inequality-leading-to-n</guid>
      <pubDate>Wed, 27 Mar 2024 21:08:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么chi2和mcnemar之间有如此大的差异？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/643692/why-is-there-such-a-difference-between-chi2-and-mcnemar</link>
      <description><![CDATA[使用 R，我运行这两个测试并得到非常不同的结果。有人有任何解释吗？
提前致谢！
这是代码：
response_distribution &lt;-matrix(c(1298, 818, # 条件“高”下的“否”和“是”的数量)
                                  4176, 2682), # “否”的数量和“是”处于“低”状态
                                nrow = 2, # 条件数
                                byrow = TRUE, # 按行填充矩阵
                                dimnames = list(c(&quot;高&quot;, &quot;低&quot;), c(&quot;0&quot;, &quot;1&quot;)))

chisq.test（响应分布）
mcnemar.test（响应分布）

这是结果：
&lt;前&gt;&lt;代码&gt;&gt; chisq.test（响应分布）

    皮尔逊卡方检验与耶茨连续性校正

数据：响应分布
X 平方 = 0.11924，df = 1，p 值 = 0.7299

&gt; mcnemar.test（响应分布）

    带连续性校正的 McNemar 卡方检验

数据：响应分布
McNemar 的卡方 = 2256.6，df = 1，p 值 &lt; 2.2e-16

我想做一个 mcnemar（因为受试者是匹配的），但结果与 chi2 如此不同，我对此表示怀疑。]]></description>
      <guid>https://stats.stackexchange.com/questions/643692/why-is-there-such-a-difference-between-chi2-and-mcnemar</guid>
      <pubDate>Wed, 27 Mar 2024 20:26:28 GMT</pubDate>
    </item>
    <item>
      <title>加权汇总统计分布的百分位数</title>
      <link>https://stats.stackexchange.com/questions/643690/percentiles-of-a-distribution-of-weighted-summary-statistics</link>
      <description><![CDATA[假设我有一个不同独立概率分布的集合，$\{ P_i(X)\}_{i=1}^N$，每个都有各自的概率分布自己的支持$I_i$。我知道给定分布的 $10^{th}$ 百分位给出为 $x_i^{10} | 0.1 = \int_{\inf(I_i)}^{x_i^{10}} P_i(x)dx$ 和 $10^{ 的平均值分布的第 th}$ 个百分位数为 $ y_i = \int_{\inf(I_i)}^{x_i^{10}} xP(x) dx$&lt; /跨度&gt;。然后，我可以获取所有平均 $10^{th}$ 值并创建这些值的分布 $Q(Y) $，此分布的 $10^{th}$ 百分位数将为 $y_k$最大的 $k$ 满足 $0.1 \geq \sum_{i=0}^k Q(y_i)$&lt; /跨度&gt;。是否有一种有意义的方法可以将此统计数据与所有分布组合的百分位相关联，即 $P(X) = P_1 * P_2 * \cdots * P_N$。我的直觉告诉我， $y_k$ 将是 $1^{st}$ 的上限&gt; $P$ 的百分位数，但我不知道如何证明这是对还是错。如果这个问题之前的陈述有任何错误，请纠正我的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/643690/percentiles-of-a-distribution-of-weighted-summary-statistics</guid>
      <pubDate>Wed, 27 Mar 2024 20:09:02 GMT</pubDate>
    </item>
    <item>
      <title>sjPlot 中的 tab_model() 如何报告 std.具有对数项的模型的 beta 值？</title>
      <link>https://stats.stackexchange.com/questions/643689/how-does-tab-model-in-sjplot-report-std-beta-for-models-with-log-terms</link>
      <description><![CDATA[我正在使用“std2” tab_model() 的选项，根据文档，它遵循“Gelman（2008）的建议，通过将估计值除以两个标准差而不是仅一个标准差来重新调整估计值。”该论文在这里：
http://www.stat.columbia.edu/ ~gelman/research/published/standardizing7.pdf
模型中没有对数项，我就得到了基于此的标准化 beta 的预期结果，与“Std.”相匹配。贝塔” tab_model() 结果中的列。
库(sjPlot)

模型 = lm(花瓣.长度 ~ 花瓣.宽度*萼片.宽度*萼片.长度, 数据 = 虹膜)
tab_model(模型, show.std = “std2”)

虹膜2 = 虹膜
iris2$Sepal.Length = (iris2$Sepal.Length - 平均值(iris2$Sepal.Length))/(2* sd(iris2$Sepal.Length))
iris2$Sepal.Width = (iris2$Sepal.Width - 平均值(iris2$Sepal.Width))/(2* sd(iris2$萼片宽度))
iris2$Petal.Width = (iris2$Petal.Width - 平均值(iris2$Petal.Width))/(2* sd(iris2$花瓣.宽度))

model2 = lm(花瓣.长度 ~ 花瓣.宽度*萼片.宽度*萼片.长度, 数据 = iris2)
摘要（模型2）

0.5/sd(iris2$Petal.Length)*model2$系数[2]
0.5/sd(iris2$Petal.Length)*model2$系数[3]
0.5/sd(iris2$Petal.Length)*model2$系数[4]

Gelman 论文中有一小部分是关于对数术语的：
“出现了更具挑战性的情况，其中一些输入已经过对数转换，而另一些则没有。我们这里没有通用的解决方案，但我们首先对尚未进行对数转换的变量进行居中和重新缩放。在对数转换后重新调整变量也可能有意义 - 例如，在图 1 中，如果收入被编码为“对数（美元收入）”，我们仍然可以考虑对其进行转换。”
但是，使用对数术语（我知道这对于这个虹膜示例来说效果不佳，但这只是为了简单的再现性），我无法再再现 std.根据我的理解，贝塔系数基于此逻辑。
model_log = lm(Petal.Length ~ log(Petal.Width)*Sepal.Width*Sepal.Length, data = iris)
tab_model(model_log, show.std = “std2”)

iris2$Petal.Width = log(iris$Petal.Width)
iris2$Petal.Width = (iris2$Petal.Width - 平均值(iris2$Petal.Width))/(2* sd(iris2$花瓣.宽度))

model_log2 = lm(花瓣.长度 ~ 花瓣.宽度*萼片.宽度*萼片.长度, 数据 = iris2)
摘要（model_log2）

0.5/sd(iris2$Petal.Length)*model_log2$系数[2]
0.5/sd(iris2$Petal.Length)*model_log2$系数[3]
0.5/sd(iris2$Petal.Length)*model_log2$系数[4]
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/643689/how-does-tab-model-in-sjplot-report-std-beta-for-models-with-log-terms</guid>
      <pubDate>Wed, 27 Mar 2024 19:56:42 GMT</pubDate>
    </item>
    <item>
      <title>白噪声 ACF 的渐近分布</title>
      <link>https://stats.stackexchange.com/questions/643688/asymptotic-distribution-of-white-noise-acf</link>
      <description><![CDATA[我（在我的讲座中遇到过这个）想知道为什么我们希望残差的自相关大部分在 2 s.d 以内。作为残差是一致白噪声的标志？
更具体

为什么我们希望残差的自相关大部分在 2 s.d. 以内？白噪声不应该尽可能不相关/随机吗？
这种一致性意味着什么？为什么我们希望它保持一致？
]]></description>
      <guid>https://stats.stackexchange.com/questions/643688/asymptotic-distribution-of-white-noise-acf</guid>
      <pubDate>Wed, 27 Mar 2024 19:50:12 GMT</pubDate>
    </item>
    <item>
      <title>处理 R 中线性混合模型中的嵌套一级随机效应</title>
      <link>https://stats.stackexchange.com/questions/643695/handling-nested-one-level-random-effects-in-linear-mixed-models-in-r</link>
      <description><![CDATA[我正在构建一个统计模型，以检查推力与从动物身上的标签收集的运动学数据之间的关系。数据的结构是“滑动”作为嵌套在“个体”中的随机效应。 “slip”描述了标签的滑动运动，它改变了推力和运动学数据之间的关系。为了考虑到标签条中标签位置变化导致的关系变化，我想制作一个线性混合模型。
但是，有些人没有单据，导致这些人的“单据”只有一个类别。由于“滑动”嵌套在线性混合模型 (LMM) 中的“个体”中，这会带来问题吗？如果是这样，有哪些方法可以解决这个问题？
我想使用 nlme 包而不是 lme4，因为我想在模型中包含自相关结构。
这是一个示例数据集：
# 加载所需的库
图书馆（dplyr）

# 设置种子以实现可重复性
设置.种子(123)

# 生成示例数据
每个个体的行数 &lt;- 54

# 个人 ID
个体 &lt;- 代表（1：3，每个 = num_rows_per_individual）

# 生成随机推力（0 - 100N）
推力 &lt;- runif(num_rows_per_individual * 3, min = 0, max = 100)

# 生成随机运动数据（0.3 - 1Hz）
kinematic_data &lt;- runif(num_rows_per_individual * 3, min = 0.3, max = 1)

# 生成单据
slips &lt;- c(rep(1:3,each = num_rows_per_individual/3), # 个体 1 有 3 个级别的 slips
           rep(1:2,each = num_rows_per_individual/2), # 个体2有2个级别的滑动
           rep(1, num_rows_per_individual)) # 个体 3 有 1 级滑动

# 将数据组合成数据框
数据 &lt;- data.frame(
  个人=个人，
  推力=推力，
  运动学数据=运动学数据，
  滑条=滑条
）

# 显示数据集的前几行
头（数据）


我尝试使用以下代码进行分析：
lme(推力 ~ kinematic_data, random = ~kinematic_data|individual/slips, data = data, cor=corAR1(), control = lmeControl(opt = “optim”))

我得到了带有结果的输出，但我不确定这对于这种情况是否是合适的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/643695/handling-nested-one-level-random-effects-in-linear-mixed-models-in-r</guid>
      <pubDate>Wed, 27 Mar 2024 19:15:01 GMT</pubDate>
    </item>
    <item>
      <title>如果不满足卡方假设，可以使用 Cramer 的 V 或列联系数吗？</title>
      <link>https://stats.stackexchange.com/questions/643685/can-cramers-v-or-contigency-coefficient-be-used-if-chi-squared-assumptions-are</link>
      <description><![CDATA[我目前正在测试一组特定变量相对于一个常见事件的独立性。尽管样本量相当不错 (n=236)，但我测试的事件相对较少（样本的 2%）。因此，在构建列联表时，各种变量的许多单元格的预期计数小于 5。
据我记得，每当此计数大于 20% 时，就会违反卡方假设，因此应使用另一个检验。我被告知费舍尔精确检验非常适合这种情况。
我想对那些与事件有显着关联的变量进行一些关联强度测量。但是，我不确定当不满足卡方假设时是否可以使用依赖于卡方值的列联系数或 Cramer&#39;s V 等检验。
虽然我已经计算了相对风险（因为我正在进行队列研究），但我担心仅根据相对风险来比较变量关联强度可能会变得令人费解。因此，我相信 Cramer 的 V 或类似的可能更适合这项任务。
如果您能确认是否可以使用此测量方法，如果不能，请建议替代方法，我将不胜感激。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/643685/can-cramers-v-or-contigency-coefficient-be-used-if-chi-squared-assumptions-are</guid>
      <pubDate>Wed, 27 Mar 2024 18:54:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中 vars 包中的 serial.test 函数根据我是否使用 type='BG'、'ES' 和 'PT.asymptotic' 给出矛盾的结果？</title>
      <link>https://stats.stackexchange.com/questions/643684/why-the-serial-test-function-from-the-vars-package-in-r-gives-contradictory-resu</link>
      <description><![CDATA[我安装了一个 VAR 模型，所有残差都没有自相关，但如果我使用serial.test，我会得到不同的结果：

输入“ES”Edgerton 和 Shukur (1999) 测试 p.value=0.99
类型“BG”Breusch-Godfrey LM 统计检验 p.value=0.45
输入“PT.asymptotic”Portmanteau 统计量 p.value=3.442e-15

我知道所有三个检验都有相同的零假设：
何。无自相关]]></description>
      <guid>https://stats.stackexchange.com/questions/643684/why-the-serial-test-function-from-the-vars-package-in-r-gives-contradictory-resu</guid>
      <pubDate>Wed, 27 Mar 2024 18:49:43 GMT</pubDate>
    </item>
    <item>
      <title>模糊决策</title>
      <link>https://stats.stackexchange.com/questions/643682/fuzzy-decission-making</link>
      <description><![CDATA[我正在使用双重层次模糊语言术语进行决策。我想问我们是否可以比较两个双重层次模糊语言术语。
我正在尝试实现 TODIM 算法进行排名。]]></description>
      <guid>https://stats.stackexchange.com/questions/643682/fuzzy-decission-making</guid>
      <pubDate>Wed, 27 Mar 2024 18:37:33 GMT</pubDate>
    </item>
    <item>
      <title>移动平均线的差分变换和平稳化</title>
      <link>https://stats.stackexchange.com/questions/643681/difference-transformation-and-stationarization-of-moving-average</link>
      <description><![CDATA[我有一个温度传感器数据，我想对其进行去噪。我首先想到的是移动平均线，它非常平滑，但仍然不稳定。如果我采用对数差值，根据 ADF 和 KPSS，它是平稳的，但这是正确的做法吗？移动平均线的差分变换对吗？我对此很困惑。你能从时间序列的角度来评估它吗？另外，我的第二个问题是移动平均过滤数据的 ACF/PACF 图是否有意义？让我对 ma 的对数差提出同样的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/643681/difference-transformation-and-stationarization-of-moving-average</guid>
      <pubDate>Wed, 27 Mar 2024 18:37:27 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的字符数据中提取条件数值</title>
      <link>https://stats.stackexchange.com/questions/643680/extracting-conditional-numeric-values-from-character-data-in-r</link>
      <description><![CDATA[遇到数据整理问题，并且不知道如何解决它。我有关于威士忌的杂乱特征数据，我希望将其组织起来，以便进行一些分析。具体来说，我希望从产品名称中提取 abv % 值，并将它们放入新列中。当前数据的示例如下所示：

&lt;标题&gt;

姓名
价格


&lt;正文&gt;

Aberfeldy，12 岁，40%
40


Ardbeg，1974 年年份，木桶 #3524，49.9%
20000



虽然我希望数据看起来像这样：

&lt;标题&gt;

姓名
价格
ABV


&lt;正文&gt;

Aberfeldy，12 岁，40%
40
40


Ardbeg，1974 年年份，木桶 #3524，49.9%
20000
49



我对此类混乱数据的经验很少，所以我不知道需要做什么。我尝试过使用 gsub 进行实验，但令人沮丧的是，我已经很接近了！ （我可以从Aberfeldy中提取40％的值，但只能从Ardbeg的49.9％中提取9）。
&lt;前&gt;&lt;代码&gt;#demo
  name &lt;- c(“Aberfeldy，12 年陈酿，40%”，“Ardbeg，1974 年年份，木桶 #3524，49.9%”)
  价格 &lt;- c(40, 20000)
example_data &lt;- data.frame(名称，价格)

尝试 &lt;- as.numeric(gsub(&quot;.*?([0-9]+).*%&quot;, &quot;\\1&quot;, example_data$name))

# 尝试结果
40 9

我可以做什么来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/643680/extracting-conditional-numeric-values-from-character-data-in-r</guid>
      <pubDate>Wed, 27 Mar 2024 18:34:34 GMT</pubDate>
    </item>
    <item>
      <title>结构方程模型 (SEM)</title>
      <link>https://stats.stackexchange.com/questions/643679/structural-equation-modeling-sem</link>
      <description><![CDATA[有人可以根据结构方程模型的后估计结果帮助我确定我的模型是识别不足、刚刚识别还是过度识别吗？我有 16 个观察变量和 2 个潜在变量，样本量为 921。]]></description>
      <guid>https://stats.stackexchange.com/questions/643679/structural-equation-modeling-sem</guid>
      <pubDate>Wed, 27 Mar 2024 17:21:09 GMT</pubDate>
    </item>
    <item>
      <title>这个时间序列模型的解读</title>
      <link>https://stats.stackexchange.com/questions/643674/interpretation-of-this-time-series-model</link>
      <description><![CDATA[我在模型描述（我无法分享）中看到某个 API 调用在时间序列回归模型中返回 alpha[t]
y[t-h..t] = alpha[t] * x[t-h..t] + epsilon_t[t-h]，对于两个时间序列 y 和 x。
这种表示法非常令人困惑，因此我并不真正理解该模型。谁能告诉我这是什么型号？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/643674/interpretation-of-this-time-series-model</guid>
      <pubDate>Wed, 27 Mar 2024 16:42:43 GMT</pubDate>
    </item>
    <item>
      <title>在回归中，如果观察之间的每个受试者的自变量都相同，那么该自变量是否仍然有用？</title>
      <link>https://stats.stackexchange.com/questions/643672/in-a-regression-is-an-independent-variable-still-useful-if-it-is-the-same-for-e</link>
      <description><![CDATA[我无法找到这个问题的答案，因为我觉得这个问题相当具体，而且问起来很尴尬。但是，就这样吧。这是我的数据的简化版本：

如您所见，我有不同的主题，每年我都会为每个主题测量三个变量。变量 1 和变量 2 对于每个科目和每年都是完全可变的。
然而，变量 3 对于各个年份的每个科目都是相同的。变量 3 对于主体 A 在 2000 年、2001 年和 2002 年的值为 500；主体B在2000年、2001年、2002年的值为1678；等等。
我想对此数据进行回归分析，并且我想知道变量 3 是否仍然是在回归中使用的有效或有用的自变量。如果可能的话我想使用它，因为我认为这对于我的特定数据来说是一个有用的控制变量，可以显示受试者之间变量 1 和 2 的变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/643672/in-a-regression-is-an-independent-variable-still-useful-if-it-is-the-same-for-e</guid>
      <pubDate>Wed, 27 Mar 2024 16:10:31 GMT</pubDate>
    </item>
    <item>
      <title>从配置文件比较推断</title>
      <link>https://stats.stackexchange.com/questions/643664/inference-from-profile-comparisons</link>
      <description><![CDATA[比较治疗之间差异模式的良好测试是什么？例如，Y 迷宫的结果是进入三个臂中每个臂的百分比。因此，每次试验都会生成三个数字。假设两组动物接受治疗，我们感兴趣的是三组动物的模式如何因治疗而变化。也就是说，我们对治疗与未治疗的 A 与 A 不感兴趣。相反，我们想要测试作为未处理的配置文件的复合 %A/%B/%C 是否与作为处理的配置文件的 %A/%B/%C 不同。结果受到限制，即每组中每只动物的 %A + %B + %C 必须等于 100%。
动物分为三类。 WT、Tg 和 Tg + 药物（这是在我腿上转储的数据，我没有设计实验）。每只动物都会穿过 Y 型迷宫一次。记录三个臂中每个臂的选择和花费的时间。这会生成计数和秒数作为数据，为每只动物生成三个计数和三个时间总和。该领域的惯例是将选择和时间转换为总选择的百分比等。我提供了数据截断的 CSV：
动物、治疗、手臂、条目、百分比
1,W,A,10,0.344827586
1,W,B,7,0.24137931
1,W,C,12,0.413793103
2,W,A,6,0.333333333
2,W,B,4,0.222222222
2,W,C,8,0.444444444
3,W,A,6,0.352941176
3,W,B,4,0.235294118
3,W,C,7,0.411764706
4、W、A、5、0.227272727
4,W,B,7,0.318181818
4,W,C,10,0.454545455
5,Y,A,10,0.357142857
5,Y,B,7,0.25
5,Y,C,11,0.392857143
6,Y,A,14,0.368421053
6,Y,B,10,0.263157895
6,Y,C,14,0.368421053
7,Y,A,9,0.3
7,Y,B,10,0.333333333
7,Y,C,11,0.366666667
8,Y,A,12,0.285714286
8,Y,B,15,0.357142857
8,Y,C,15,0.357142857
9,X,A,8,0.32
9,X,B,6,0.24
9,X,C,11,0.44
10,X,A,4,0.8
10,X,B,0,0
10,X,C,1,0.2
11,X,A,11,0.323529412
11,X,B,10,0.294117647
11,X,C,13,0.382352941
12,X,A,6,0.25
12,X,B,8,0.333333333
12,X,C,10,0.416666667

因此，得出的结果（由于现场惯例的限制）是“PercEnt”。治疗方法是W、X、Y。动物做出选择的臂是A、B、C。每只动物都会经历一次这个过程。感兴趣的结果是 A/B/C 之间的关系如何因治疗而不同。
这是完整数据集的图：
&lt;img alt=&quot;数据集图，每种颜色代表一种处理。在每种颜色中， A 臂是左侧，B 臂是中间，C 臂是右侧。黑条是每个治疗和臂内的平均值。” src =“https://i.stack.imgur.com/IoWke.png”/&gt;
因此，我想做的是正式推断 A/B/C 水平的整体模式是否因治疗而异。基本上是“高/低/高”。对于每个，但是“高/低/高”的程度可以是不同的。总体而言，治疗之间并不相同。这种差异显着吗？
我希望这足够清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/643664/inference-from-profile-comparisons</guid>
      <pubDate>Wed, 27 Mar 2024 14:44:08 GMT</pubDate>
    </item>
    </channel>
</rss>