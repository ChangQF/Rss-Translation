<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 12 Apr 2024 15:13:29 GMT</lastBuildDate>
    <item>
      <title>在（一些）心理学家所做的主题实验中</title>
      <link>https://stats.stackexchange.com/questions/644887/within-subject-experiments-done-by-some-psychologists</link>
      <description><![CDATA[预先感谢您可以将我链接到的任何回复或资源。
我接受了更多的经济/统计培训，最近我一直在与一些具有心理学背景的人一起工作。
他们进行所谓的“实验”老实说，我不认为它们是实验，每当我提出相关问题时，我都得不到满意的答案。对我来说，一个令人满意的答案更多的是一种统计解释，而不是像“我们已经做到了这一点并且它有效”这样的实际解释。或“我们需要更小的样本量”。
他们让调查参与者查看一个（或多个）控制条件并回答一个问题，然后查看多个治疗条件并回答一个问题。治疗条件都是不同的治疗，而不是相同治疗的版本。问题都是按顺序随机排列的。
另一个问题是，有时，他们有太多的控制/治疗，并不是每个人都回答所有的问题。
我认为这只是一项调查。这不是一个实验/调查实验。我熟悉联合实验和其他类型的主题内实验设计，但事实并非如此。
当参与者接受所有治疗时，这如何发挥作用？他们的答案会受到他们看到的顺序的影响。即使顺序是随机的，1/2 也会先看到一个，另外 1/2 会看到第二个。
结果不是 ATE（或相关），所以这不只是观察数据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644887/within-subject-experiments-done-by-some-psychologists</guid>
      <pubDate>Fri, 12 Apr 2024 14:47:15 GMT</pubDate>
    </item>
    <item>
      <title>对汇总数据使用哪些统计检验？</title>
      <link>https://stats.stackexchange.com/questions/644886/which-statistical-tests-to-use-for-aggregated-data</link>
      <description><![CDATA[我正在撰写金融学学士论文，主题是 Covid-19 对荷比卢地区（比利时、荷兰、卢森堡）不同财富群体家庭投资组合选择的影响。数据来自欧洲央行：(https:/ /www.ecb.europa.eu/stats/ecb_surveys/hfcs/html/index.en.html），包含每个国家和每个家庭财富组的分居家庭的不同财务数据（6组：底部20％） 、20-40%、40-60%、60-80%、80-90%、90-100%）。我有4波数据（2011年、2014年、2017年、2021年）。由于这些年份是自变量（2021 年是重点年份，因为现在正处于新冠疫情中期），除了使用描述性统计数据之外，我还想进行一些统计测试和回归，以测试 2021 年与其他年份之间的任何差异的显着性三波（2011、2014、2017）
我主要关注的数字包括：
A3 净财富，中位数
A4净财富，意味着
B3 实物资产，HMR 的所有权
B5 房地产资产，条件中位数
C4 金融资产，条件中位数
C5金融资产，拥有股份
D4 金融资产占总资产的比例
E5 持有债务的家庭百分比
E6 总债务，有条件中位数
F4 债务收入比中位数
F5 有偿债家庭的偿债与收入比率中位数
F6 债务资产比率中位数 - 细分
G3 经常支出低于收入
这些数字是来自大型调查的汇总数据，我不确定可以使用哪些统计测试和哪种回归。我从主管那里听说每次回归的目标是 30-50 个数据点，但是我的数据仅包含 6 个大组的数字（平均值、中位数、比率）。这将使每个国家/地区的每个财务数据有 6 个数据点，因此每个财务数据有 18 个数据点。由于这些数字是汇总数据，这 18 个数据点的数量是否足以进行回归分析？ （如果是，是哪种类型？）或者我仍然应该通过扩大我正在研究的国家/地区来争取 30-50 个数据点吗？
除了描述性统计之外，有人可以建议我对这些数据使用哪些统计测试和回归吗？提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644886/which-statistical-tests-to-use-for-aggregated-data</guid>
      <pubDate>Fri, 12 Apr 2024 14:37:05 GMT</pubDate>
    </item>
    <item>
      <title>如何计算怀孕率</title>
      <link>https://stats.stackexchange.com/questions/644885/how-to-calculate-pregnant-rate</link>
      <description><![CDATA[我有两个输入，

一个月的排卵概率，例如

&lt;预&gt;&lt;代码&gt;A=[0,0,0.03,0.04,0.09,0.11,0.18,0.23,0.25,0.24,0.19,0.1,0.07,0.05,0.02,0,0,0,0,0,0 ,0,0,0,0,0,0,0,0,0]


给定排卵日期的怀孕率，例如

&lt;前&gt;&lt;代码&gt;B=[0.03,0.06,0.09,0.18,0.27,0.33,0.42,0.2,0.08,0]

这里的0.2对应的是排卵日。所以女性在排卵日前1天怀孕的概率是42%，在排卵日怀孕的概率是20%……现在给定A和B，如何计算计算1个月的总怀孕概率？这看起来像是一个传统的条件概率问题，问题是 B 是一个窗口数组，而不是单个值。
换句话说，我们有事件 A 在一个月内发生的概率分布，我们还有事件 B 在 A 发生时发生几天的概率分布。现在如何计算事件B的总概率分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/644885/how-to-calculate-pregnant-rate</guid>
      <pubDate>Fri, 12 Apr 2024 14:36:03 GMT</pubDate>
    </item>
    <item>
      <title>使用结果变量确定数据集的重要预测变量</title>
      <link>https://stats.stackexchange.com/questions/644884/determining-significant-predictors-for-a-dataset-with-the-outcome-variable</link>
      <description><![CDATA[我正在处理数据集并尝试获取重要的预测变量？数据集包含数字和分类变量，并且有一个结果变量。
最好的方法是什么？我正在为一些分类变量制定假设，并运行费舍尔精确和卡方来确定统计数据
意义。对于数值变量，我正在检查相关矩阵并运行 T 检验以显示差异。
有人可以证明这些方法是正确的吗？另一种选择是因子分析。然而，数据集是数字变量和分类变量的组合。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644884/determining-significant-predictors-for-a-dataset-with-the-outcome-variable</guid>
      <pubDate>Fri, 12 Apr 2024 14:23:29 GMT</pubDate>
    </item>
    <item>
      <title>这种引导/排列测试设置是否存在与单变量回归相同的缺陷？</title>
      <link>https://stats.stackexchange.com/questions/644883/is-this-bootstrap-permutation-test-setup-flawed-in-the-same-way-univariate-regre</link>
      <description><![CDATA[我正在使用一个数据集，其中有一个计数因变量和许多（将分类变量转换为虚拟变量后大约 80 个）回归量。这是观察数据，其想法是确定哪些回归变量对响应有很大影响，以深入了解系统。因此，重点不是预测，而是指定一个合适的模型，该模型可以产生接近真实值的系数估计值，同时记录不同回归量的显着性。对于哪些回归变量可能很重要，存在一些先验领域知识，但在大多数情况下，系统相当复杂，并且预计所有回归变量对响应都有一定的影响，只有少数回归变量具有更强的影响。此外，回归量之间在一定程度上具有相关性。
不幸的是，样本量确实有限。在约 700,000 条总记录中，我只有几百条非零计数的记录。使用所有回归量拟合泊松回归是不可行的（特别是因为我们还想指定一些交互作用）。我不喜欢只使用一些回归量，因为我觉得根据我们的设置，这很容易产生有偏差的估计。
一个想法是对平均计数之间的差异进行引导/排列测试，该差异是将计数分为由每个回归量的低/高水平给出的 2 个类别。我的意思是一次对 1 个回归量进行分组，因为显然同时对所有回归量进行分组会产生许多 0 计数组，因为我们没有进行足够的采样来获得可靠的均值估计。我们将比较引导/排列的差异与实际差异，以确定特定回归量是否实际上影响观察到的计数。然而，在我看来，这遇到了与单变量回归相同的问题。也就是说，即使我们得到回归量 A 的显着结果，也可能只是因为我们在 bootstrat/排列测试期间没有考虑回归量 B。由于同样的原因，我认为即使平均估计的差异也没有意义。
当我说引导/排列测试想法（正如我所描述的）与单变量回归一样无用时，我的直觉是否正确？老实说，我个人认为除非我们增加样本量，否则这些数据没有太大关系，但团队中一直在争论是否有关于影响的有意义的事情需要学习。响应的协变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/644883/is-this-bootstrap-permutation-test-setup-flawed-in-the-same-way-univariate-regre</guid>
      <pubDate>Fri, 12 Apr 2024 14:14:04 GMT</pubDate>
    </item>
    <item>
      <title>计数数据因变量</title>
      <link>https://stats.stackexchange.com/questions/644878/count-data-dependent-variable</link>
      <description><![CDATA[简单说一下 - 我计划运行负二项分布，根据一系列对照来测试一周内在健身房花费的时间。
我只是想仔细检查一下 - 过去一周在健身房花费的小时数是否适合作为“计数”变量？我觉得我的假设是正确的，但只是想得到一些确认！]]></description>
      <guid>https://stats.stackexchange.com/questions/644878/count-data-dependent-variable</guid>
      <pubDate>Fri, 12 Apr 2024 13:28:07 GMT</pubDate>
    </item>
    <item>
      <title>组合多个数据集时的平衡（在荟萃研究中平衡？）</title>
      <link>https://stats.stackexchange.com/questions/644876/balancing-when-combining-multiple-datasets-balancing-in-a-metastudy</link>
      <description><![CDATA[该社区对平衡数据集进行了一些详细讨论：
不平衡的数据集是否有问题，以及（如何）过采样（声称）有帮助？
为什么准确度不是评估分类模型的最佳衡量标准？
主要结论似乎是，只要使用适当的措施，不平衡的数据集就不是问题（准确性很差，至少在单独使用时是这样。）
现在，假设我想组合多个数据集来训练二元分类器。这里的平衡可能不仅涉及相同数量的正面和负面结果（类平衡），还涉及平衡数据集的大小。作为一个传统的极端示例，假设所使用的数据集之一包含 95% 的样本。那么，仅在此数据集上表现良好的分类器将为所有组合的数据集提供近 95% 的准确率。
另一方面，将所有数据集减小到相同大小意味着丢弃大量样本（或者通过扩大较小数据集的大小来偏差结果，例如使用 SMOTE。）
处理这种情况的良好做法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644876/balancing-when-combining-multiple-datasets-balancing-in-a-metastudy</guid>
      <pubDate>Fri, 12 Apr 2024 12:29:11 GMT</pubDate>
    </item>
    <item>
      <title>受限三次样条与对数相对风险 = 0 的交点</title>
      <link>https://stats.stackexchange.com/questions/644874/intersection-of-restricted-cubic-spline-with-log-relative-hazard-0</link>
      <description><![CDATA[我想确定受限三次样条与对数相对危险 = 0 的交集（即从较低危险到较高危险的变化）。谢谢！
fit &lt;- cph(Surv(时间, 状态) ~ rcs(年龄, 4), data = df, x = TRUE, y = TRUE, surv = TRUE)
ggplot（预测（拟合））
]]></description>
      <guid>https://stats.stackexchange.com/questions/644874/intersection-of-restricted-cubic-spline-with-log-relative-hazard-0</guid>
      <pubDate>Fri, 12 Apr 2024 12:17:29 GMT</pubDate>
    </item>
    <item>
      <title>$X_nY_n=\mathcal{o}_{p}(\beta_n)$ 成立吗？</title>
      <link>https://stats.stackexchange.com/questions/644873/does-x-ny-n-mathcalo-p-beta-n-hold</link>
      <description><![CDATA[&lt;块引用&gt;
设 $X_n$ 和 $Y_n$ 均为非负随机变量序列。定义 $A_n:=\left\{\omega:X_{n}(\omega)&gt;0\right\}.$ 假设 $\lim_{n\rightarrow\infty}\mathbf{P}(A_n)=0,Y_n=\mathcal{O}_{p}(\beta_n),$ 其中 $\left\{\beta_n\right\}_{n\in\mathbf{N}}$ 是严格正实数的序列。
我们能否得出结论：$X_nY_n=\mathcal{o}_{p}(\beta_n)$？

来自$\mathcal{O}_{p}$ 和 $\mathcal{ 的定义o}_{p}$，我尝试证明对于每个 $\epsilon&gt;0,\mathbf{P}\left(\frac{ X_n Y_n}{\beta_n}&gt;\epsilon\right)\rightarrow 0,$ as $n\rightarrow\infty.$
由于 $\left\{\omega:\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right\}=\left\{\omega:\frac {X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt;\epsilon\right\}\biguplus\left\{\omega:\frac{X_n Y_n}{\ beta_n}\cdot\mathbb{I}_{\{X_n=0\}}&gt;\epsilon\right\}(\biguplus \text{表示不相交并}),$ $$\mathbf{P}\left\{\omega:\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right\}=\mathbf{P}\left\{\omega:\ frac{X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt;\epsilon\right\}.$$
不管怎样，$$\left\{\omega:\frac{X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt; \epsilon\right\}\subseteq A_n,$$ 然后 $$\lim_{n\rightarrow\infty}\mathbf{P}\left(\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right)=0.$$
我不确定我的证明似乎没有使用 $Y_n=\mathcal{O}_{p}(\beta_n).$ 如果需要，请纠正我.]]></description>
      <guid>https://stats.stackexchange.com/questions/644873/does-x-ny-n-mathcalo-p-beta-n-hold</guid>
      <pubDate>Fri, 12 Apr 2024 11:51:48 GMT</pubDate>
    </item>
    <item>
      <title>后验近似遵循优化方法</title>
      <link>https://stats.stackexchange.com/questions/644869/posterior-approximation-following-optimization-methods</link>
      <description><![CDATA[我正在尝试量化高维、多模态后验空间中的不确定性。我们没有正演模型的分析解，并且正演模型的运行成本可能很高。因为无梯度 MCMC 收敛时间太长并且无法并行化，所以我试图避免 MCMC。我们能做的是在多线程中运行无梯度优化。所以我想知道是否有一种方法可以在优化步骤中使用样本/步骤的集合来重建或近似后验。
这里我用一个 2D 案例来演示这个问题。背景颜色代表我们感兴趣的真实后验，黄色点是样本。我在这里使用梯度下降进行了简单的优化，仅用于演示目的。

显然直接使用直方图会导致一些过于密集的区域，这并不代表后验。蓝色阴影显示来自真实后验的样本。

如果我们使用所有优化步骤，当然也会存在相同的不平衡密度。但是有没有办法利用我们现在拥有的信息来以某种方式估计后验呢？任何想法都会受到赞赏。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644869/posterior-approximation-following-optimization-methods</guid>
      <pubDate>Fri, 12 Apr 2024 11:04:21 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释 ACF 和 PACF 图</title>
      <link>https://stats.stackexchange.com/questions/644868/help-interpreting-acf-and-pacf-plots</link>
      <description><![CDATA[我是时间序列分析的新手，一直在尝试了解如何正确识别 ACF 和 PACF 图。我已经运行了 gam，现在正在查看残差，然后运行 ​​GAMM。我有以下两组数据的图表，并且正在努力正确识别它们。我是否认为plot1只是噪声并且不需要考虑任何自相关：

然后对于图 2，我认为它会是 MA(2)，并且在 R 中编码为关联=corARMA(p=2)。这是正确的还是我完全错误？这是否可以被视为噪音以及峰值几乎超过 95% 的区间？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644868/help-interpreting-acf-and-pacf-plots</guid>
      <pubDate>Fri, 12 Apr 2024 10:34:11 GMT</pubDate>
    </item>
    <item>
      <title>计算不同结果变量的包含贝叶斯因子</title>
      <link>https://stats.stackexchange.com/questions/644867/calculating-inclusion-bayes-factors-across-different-outcome-variables</link>
      <description><![CDATA[我正在进行统计分析，以确定各种模型下观察到的数据的概率，特别是根据多种标准检查包含特定效应的模型是否比不包含特定效应的模型更有可能。
在我的研究中，我正在处理四个不同的结果变量（代表不同的人格特征：Y1、Y2、Y3 和 Y4）。对于每个结果，我使用以下模型运行了三个贝叶斯线性回归：

仅包含预测变量 X1 的模型
具有预测变量 X1 和 X2 的模型
包含预测变量 X1、X2 及其交互作用的模型

对于每个结果，我都使用单独的贝叶斯因子比较了模型。现在，我正在探索是否可以计算一个汇总贝叶斯因子来汇总所有结果的这些比较。
是否有一种方法或方法来计算涵盖不同结果变量的聚合或包含贝叶斯因子？我的目标是确定，与不包含效应 X 的模型相比，包含效应 X 的模型产生观测数据的可能性平均有多大。]]></description>
      <guid>https://stats.stackexchange.com/questions/644867/calculating-inclusion-bayes-factors-across-different-outcome-variables</guid>
      <pubDate>Fri, 12 Apr 2024 10:23:18 GMT</pubDate>
    </item>
    <item>
      <title>扩展隐马尔可夫模型 (HMM) 参数估计</title>
      <link>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</link>
      <description><![CDATA[对于更简单的 HMM，我们可以使用 Viterbi 训练（而不是解码）或 Baum Welch 等算法来估计最能描述观察到的数据的参数。
当使用更复杂的多元 HMM 或二阶 HMM 时，我们如何做同样的事情？是否有资源可以用来查看在这些情况下如何调整算法和设置？如果有它们的伪代码而不是描述，那就更好了，尽管我知道早期的算法（例如向前和向后）也会改变。
编辑：
对于关闭这个问题的人来说，这不是你所说的编程/代码调试，而是关于统计和算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</guid>
      <pubDate>Fri, 12 Apr 2024 00:37:56 GMT</pubDate>
    </item>
    <item>
      <title>我们如何摆脱 MLE 中的 $p(x|\theta)$</title>
      <link>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</link>
      <description><![CDATA[简单的问题...通常机器学习的介绍会告诉您以下内容：

您想要最大化 $p(\theta|D)$，因此优化为 $\theta = \ arg\max_\theta p(\theta|D)$
贝叶斯定理告诉我们 $p(\theta|D) \propto p(D|\theta)p(\theta)$，因此 $\theta = \arg\max_\theta p(D|\theta)p(\theta)$
如果你考虑 $p(\theta)$ 常数，你会得到 MLE，如果你考虑它高斯，你会得到 L2 正则化等等

但是，我想更详细一点，这是我的问题：
$$
p(\theta|D) \propto p(D|\theta)p(\theta) = p(x,y|\theta)p(\theta) = p(y|x, \theta)p(x| θ)p(θ)
$$
现在，通常我们优化的实际上是 $p(y|x,\theta)p(\theta)$，所以我的问题是...下我们要删除哪个假设 $p(x|\theta)$？
我们是否认为 $x$ 独立于 $\theta$ 并且保持不变？.. .]]></description>
      <guid>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</guid>
      <pubDate>Thu, 11 Apr 2024 22:11:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Hotellings T 方统计量按 n 倍缩放？</title>
      <link>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</link>
      <description><![CDATA[根据 NIST：https://www. itl.nist.gov/div898/handbook/pmc/section5/pmc543.htm T 方统计量的方程的缩放因子为 n （有趣的是，此内容的维基百科页面引用了此页面，但省略了 n 缩放因子）。 （我读错了，该因子包含在样本协方差计算中。）
我想知道为什么要包含这个比例因子？这背后有什么直觉吗？
这是否意味着随着样本数量的增加，正在测试的相同样本的可能性会导致我们拒绝零假设的可能性增加？
我想象 2-D 多元正态数据作为样本，可能 n=100 和 n=1000（从相同的真实分布中采样）。这些将具有（接近）相同的样本均值和方差，但是由于这个 n 因素，来自该分布的新样本不符合零假设的可能性随着 n 的增加而增加？
当然，随着 n 的增加，与 F 分布（我们用来检查的）的关系会发生变化，但变化幅度不大。对于 p=2，T^2 (n-p)/(pn-p) 的缩放比例为 98/198 ~ 1/2（n=100）和 998/1998 ~ 1/2（n=1000），并且 F 临界值对于 alpha=0.05 来说，两者都约为 3，因此它们的影响很小。]]></description>
      <guid>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</guid>
      <pubDate>Thu, 11 Apr 2024 19:13:50 GMT</pubDate>
    </item>
    </channel>
</rss>