<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 21:16:26 GMT</lastBuildDate>
    <item>
      <title>状态空间模型和卡尔曼滤波器</title>
      <link>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</link>
      <description><![CDATA[我有以下模型规范：
y_t = mu_t + v_t, mu_{t+1|t} = phi * mu_{t|t-1} + k*v_t
其中 v_t= y_t - mu_{t|t-1}, v_t|F_{t-1} ~ tv(0, sigma^2)。
我被要求提供 mu_t 或 mu_{t|t-1} 的滤波估计值，并估计静态参数：phi、v、sigma^2。
我使用卡尔曼滤波器。一般状态空间表示为：y_t = Z_t* alpha_t + G_t* epsilon_t。 alpha_{t+1} = T_t* alpha_t + H_t* eta_t
在这种情况下：Z_t=1，T_t = phi，G_t= sigma_v，H_t= k*sigma_v，alpha_t= mu_t。
对于卡尔曼滤波器：v_t = y_t - Z_t* alpha_{t|t-1} # 预测误差
F_t = Z_t * P_{t|t-1} Z_t&#39; + G_t G_t&#39; # 预测误差的方差
alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt # E[alpha_t| F_t]
P_{t|t} = P_{t|t-1} - P{t|t-1}*Z_T&#39; * F_t^-1 Z_tP_t # V[alpha_t|F_t]
alpha_{t+1|t} = T_t* alpha_{t|t-1} + k_t *vt# 更新状态估计
P_{t+1|t} = T_t* P_{t|t-1}* T_t&#39;+ H_tQ_tH_t&#39; - K_t * F_t *K_t&#39;# 更新状态方差
卡尔曼增益 K_t= T_t* P_{t|t-1Z_t&#39; F_t^-1
为了计算估计值mu_{t|t}，我是否只需替换 alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？
mu_{t|t} = mu_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？]]></description>
      <guid>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</guid>
      <pubDate>Tue, 09 Jul 2024 19:02:36 GMT</pubDate>
    </item>
    <item>
      <title>纵向或时间序列的 GLM - 如何使用 R 建模和解释随时间控制协变量的二元逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/650762/glm-for-longitudinal-or-time-series-how-to-model-and-interpret-a-binary-logis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650762/glm-for-longitudinal-or-time-series-how-to-model-and-interpret-a-binary-logis</guid>
      <pubDate>Tue, 09 Jul 2024 18:26:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sommer R 包中正确指定嵌套？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</link>
      <description><![CDATA[我习惯于 lme4，它很简单：(1|genotype/root_ID)，但我通过查看文档不清楚在 sommer 中执行此操作的适当方法。
mod1 &lt;- mmer(Y ~ 1,
random= ~vsr(genotype,Gu=a) + genotype + genotype:root_ID,
rcov= ~units, nIters=10,
data=fold, verbose = FALSE, dateWarning=FALSE)
结果看起来很逼真，但我不完全确定这是否正确，并担心我会得到虚高的 CV 准确度...]]></description>
      <guid>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</guid>
      <pubDate>Tue, 09 Jul 2024 18:10:33 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行网络元分析 - 输入二分数据</title>
      <link>https://stats.stackexchange.com/questions/650768/conducting-a-network-meta-analysis-in-r-inputting-dichotomous-data</link>
      <description><![CDATA[我希望使用 {netmeta} 在 R 中进行荟萃分析。但是，我感兴趣的结果有点复杂，希望得到有关如何最好地将其输入数据集的建议。
我正在研究牛营养补充后体外受精的卵母细胞卵裂率。大多数研究都没有在结果中说明平均值 +/- s.e.m. 或 s.d. - 它们主要将其报告为比例。
由于卵裂在技术上是一个二元结果（它已经卵裂了吗？是或否？），我打算将比例转换为风险比（这相当简单）。但是，问题之一是大多数研究不止一次从实验中的动物身上收集卵母细胞。例如，他们可能有五只动物在对照组，五只动物在实验组，它们经历三个卵母细胞收集周期。但是，大多数研究只是三次收集的结果的平均值，例如对照组三次采集五只动物，平均有 6/11 个卵母细胞分裂（54.5%），实验组有 9/15 个卵母细胞分裂（60%）。我觉得我需要考虑每项研究的样本量，但只需在下面的列中输入 6 和 11，以及 9 和 15：
没有考虑到这一点。
仅将动物数量乘以采集数量来估计总事件数和总数是否合适，或者这是否严重简化并可能引入抽样误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/650768/conducting-a-network-meta-analysis-in-r-inputting-dichotomous-data</guid>
      <pubDate>Tue, 09 Jul 2024 17:57:44 GMT</pubDate>
    </item>
    <item>
      <title>测试混合问题中多个比例的相等性</title>
      <link>https://stats.stackexchange.com/questions/650757/testing-equality-of-multiple-proportions-in-mixing-problems</link>
      <description><![CDATA[有两个湖泊 A（43000 立方英尺）和 B（30000 立方英尺）。一家工厂将废物倾倒到这两个湖泊中。测量结果显示三种污染物 a、b、c。
充满这些污染物的湖泊的百分比为：
湖泊 A：[%a(A)、%b(A)、%c(A)] = [8%、4%、2%]。这里的 8% 表示整个湖泊的 8% 由污染物 a 组成。
湖泊 B：[%a(B)、%b(B)、%c(B)] = [7%、5%、1.5%]。
我想检验三个比例相同的零假设，即 %a(A)=%a(B)、%b(A)=%b(B)、%c(A)=%c(B)。我需要一个统计数据来进行这个测试。
注意：测试必须是尺度不变的，这意味着如果我用立方英尺、立方英寸或立方米来测量湖泊，我都会得到相同的答案。常规卡方检验不具有尺度不变性。]]></description>
      <guid>https://stats.stackexchange.com/questions/650757/testing-equality-of-multiple-proportions-in-mixing-problems</guid>
      <pubDate>Tue, 09 Jul 2024 17:07:45 GMT</pubDate>
    </item>
    <item>
      <title>将模型 A 的输出作为训练数据输入到模型 B 中</title>
      <link>https://stats.stackexchange.com/questions/650755/output-from-model-a-as-training-data-into-model-b</link>
      <description><![CDATA[不确定这里是不是提出这个问题的合适地方，但我和同事在这个想法上意见不一。
假设我们有一个由“不干净”字符串组成的数据集。最终目标是拥有“干净”字符串。
现在假设有一个现有模型，称为模型 A。我们将所有“不干净”字符串传递到模型 A 中，并将结果称为“干净”数据。
接下来，如果我使用相同的“不干净”字符串作为输入来训练模型 B，并使用模型 A 的输出作为训练和验证数据，模型 B 是否会提供明显不同的结果？您能确定它的表现是否优于模型 A 吗？
关于目标的更多背景信息。当前项目目标是创建基于正则表达式的模型 A 的 ML 版本。我的理解是，如果我们使用模型 A 的输出来训练模型 B，它最多只能重现模型 A 的功能。
模型 A 的输出没有经过人工编辑，因此它实际上只是模型 A（正则表达式）进入模型 B（某种 ML 算法）。
以下是一些示例数据：
模型 A



输入字符串
输出字符串




发生了什么事？
发生了什么事？


你今天怎么样？
你好吗今天？


123 号主街
123 号主街


]]></description>
      <guid>https://stats.stackexchange.com/questions/650755/output-from-model-a-as-training-data-into-model-b</guid>
      <pubDate>Tue, 09 Jul 2024 16:48:33 GMT</pubDate>
    </item>
    <item>
      <title>Dickey-Fuller 检验统计显著性</title>
      <link>https://stats.stackexchange.com/questions/650752/dickey-fuller-test-statistical-significance</link>
      <description><![CDATA[我最近读到了关于 Dickey-Fuller 检验的文章。
首先，关于从
$$
y_t=\rho y_{t-1}+\epsilon_t
$$
到：
$$
y_t-y_{t-1}=(\rho-1) y_{t-1}+\epsilon_t
$$
我假设它是为了获得 $\delta=\rho -1$
的统计量，哪个更容易计算分布？
其次，据我所知，对 delta 进行的统计测试是片面的。为什么我们要忽略 rho 绝对值大于 1 的负值？]]></description>
      <guid>https://stats.stackexchange.com/questions/650752/dickey-fuller-test-statistical-significance</guid>
      <pubDate>Tue, 09 Jul 2024 16:21:22 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种相关性检验</title>
      <link>https://stats.stackexchange.com/questions/650748/which-correlation-test-to-use</link>
      <description><![CDATA[我正在处理县级经济不平等和犯罪率的数据集，以生成相关矩阵。我的经济不平等数据有几个变量，即收入处于特定区间（0 到 9,999、10,000 到 14,999、15,000 到 35,000 等）的县人口百分比。这是连续的区间数据。我的犯罪率数据有几个变量，即不同的犯罪类型（谋杀、抢劫、福利欺诈等）。这些值是各县每种犯罪的犯罪率，通过将绝对犯罪计数除以人口计算得出。这些数据也是连续的区间数据。
我的犯罪率都严重偏右（大多数县的犯罪率较低；少数县的犯罪率较高）。我的经济数据向右倾斜，最低收入和最高收入阶层的异常值较高，中等收入阶层的数据趋近于正态（尽管两边都有长尾）。
在我的经济和犯罪变量之间绘制一些散点图，没有显示出清晰的线性/曲线关系，没有清楚地表明单调性，并且表明相关值较低。我的 n = 1,441。我正在尝试确定是否使用 Pearson 的 r、Kendall 的 t 或 Spearman 的 rho。
在 Kendall 的 t 和 Spearman 的 rho 之间，最佳选择似乎是 Spearman，因为我的 n 很大（Kendall 的更适合小样本量）。所以问题是皮尔逊还是斯皮尔曼更好。
因为我的犯罪数据有偏差，而且我的经济数据有时有异常值，所以斯皮尔曼似乎比皮尔逊更可取。请注意，我假设单调性（随着特定收入阶层的人口百分比上升，犯罪率将均匀上升或下降），这支持使用斯皮尔曼。
我的分析合理吗？我遗漏了什么吗？我应该使用斯皮尔曼的 rho 还是其他测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/650748/which-correlation-test-to-use</guid>
      <pubDate>Tue, 09 Jul 2024 15:35:56 GMT</pubDate>
    </item>
    <item>
      <title>在 MVGAM 中，如何模拟 1 个连续变量（丰度）、1 个离散变量（天数）和 1 个因素（真核生物属）之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</link>
      <description><![CDATA[我正在从事微生物生态学研究，并试图在微生物初级演替的情况下模拟几个属的丰富程度对单个感兴趣的属随时间的影响。我已经创建了这个模型，但我真的不确定我是否理解得正确，尤其是关于相互作用。
我发现有几个主题讨论 1 个变量和因素，但没有 1 个连续变量（丰度）、一个离散变量（时间）和因素（属）

Alkanindiges 是包含我感兴趣的属的相对丰度的列
丰度是每天所有属的相对丰度
时间是天数（1-24）
生物反应器是我的实验三重奏（其中有 3 个）

我使用 CAR(1)，因为我预计前一天我感兴趣的属的丰度会对当天的丰度产生影响，但我缺少一些数据点。
这是完整的模型，我包含了数据的摘要我正在处理。如果您想要整个文件，我很乐意通过电子邮件发送给您！
非常感谢您抽出时间。

mod_alk &lt;- mvgam( Alkanindiges ~ te(Abundance, time, by = Genus) + s(bioreactor, bs = &#39;re&#39;),

trend_model = CAR(1),

noncentred = TRUE,

data = AHAPCN_train, 

chains = 4,

adapt_delta = 0.97,

max_treedepth = 14,

parallel = TRUE,

backend = &#39;cmdstanr&#39;,

family = Gamma(link = &#39;inverse&#39;)) 

这是我的 df 的摘要。 NA 是因为我将丰度列分成了每个属的丰度的多个列。
]]></description>
      <guid>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</guid>
      <pubDate>Tue, 09 Jul 2024 14:16:22 GMT</pubDate>
    </item>
    <item>
      <title>如何测量二进制数据列表中分布的规律性？</title>
      <link>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</link>
      <description><![CDATA[假设我有一个列表 list = [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]，它给出了某人在某一天是生病 (1) 还是没生病 (0) 的信息，由于该列表有 15 个元素，我考虑 1-15 天。现在我想确定如何“很好地”或者这些病假有规律地分布在这段时间内。
例如，规则的分布是
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1]

不美观的分布是例如：
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]

我考虑的是基尼系数或距离的标准差。但是我不知道如何处理第二个列表。
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]

这里，距离的标准差值为 0，但 1 的分布不太好。
还有什么其他可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</guid>
      <pubDate>Tue, 09 Jul 2024 13:46:10 GMT</pubDate>
    </item>
    <item>
      <title>处理 Cox 回归中的分类变量</title>
      <link>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</link>
      <description><![CDATA[我试图将 Cox 回归模型拟合到我的事件发生时间数据，并有一个具有 5 个不同级别的分类变量。如果我不忽略其中一个级别，那么我将具有多重共线性，因此我假设我需要忽略一个类别作为“参考”类别。如果我忽略一个级别，那么我将如何解释得到的 cox 系数？忽略的类别有什么影响？它是否会导致基线风险？
我正在使用 Python 中 lifelines 库中的 CoxTimeVaryingFitter。]]></description>
      <guid>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</guid>
      <pubDate>Tue, 09 Jul 2024 13:32:30 GMT</pubDate>
    </item>
    <item>
      <title>元问题：理解相关性与效应大小</title>
      <link>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</link>
      <description><![CDATA[背景：我一直在研究一些关于解释幸福（幸福感）的因素的荟萃分析，因为我想检查某种哲学对幸福的主张，并且希望自己总体上幸福（谁不想呢：）。当然，这些荟萃分析揭示了幸福的不同协变量，它们具有不同的相关系数。
所以我想知道：根据这些研究，为了了解什么能长期带来最大的幸福感，我只需要关注相关系数的大小吗？还是我需要查看效果大小？或者还有什么需要注意的？我想我想知道我应该做些什么才能从我花费的一小时内获得最大的长期幸福感？]]></description>
      <guid>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</guid>
      <pubDate>Tue, 09 Jul 2024 13:14:35 GMT</pubDate>
    </item>
    <item>
      <title>多个总体均值相互作用的效应对比矩阵</title>
      <link>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</link>
      <description><![CDATA[我想在我的 GAM（MGCV）中包含两个因素之间的相互作用：area 和 house_type，我希望进行总和为零的对比编码。
但是，我不希望将每个因素组合与所有级别的总平均值进行比较。我想要 每个级别的总平均值 area。因此，每个区域内的 house_types 都会与该 area 的总平均值进行比较。
这是我尝试过的
取 house_type 的对比矩阵。有 7 种类型：它是一个 7*6 矩阵。

对于 6 个级别的 area，我创建了一个矩阵，该矩阵由对角线上的 house_type 对比矩阵和非对角线上相同大小的零矩阵组成。这是 42*36。
前两个子矩阵如下所示：

查询

有没有更好的方法？
使用交互项运行简单线性回归，我得到 NA 系数 - 为什么会这样？
此模型中是否存在总体截距，还是每个 area 级别的截距代表总平均值？

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</guid>
      <pubDate>Tue, 09 Jul 2024 08:32:42 GMT</pubDate>
    </item>
    <item>
      <title>样本量对指标提升度的影响</title>
      <link>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</link>
      <description><![CDATA[假设我们连续运行了三个随机用户拆分 AB 实验 exp_1、exp_2、exp_3。这三个实验的处理和控制完全相同。
Exp_1 在 2014 年 6 月 1 日至 2014 年 6 月 1 日期间运行了 2 周。 Exp_2 在 06/15-06/28 期间运行了 2 周，Exp_3 在 06/29-07/12 期间运行了 2 周。
Exp_1 有 2% 的用户参与了实验，Exp_2 有 50% 的用户参与了实验，Exp_3 有 100% 的用户参与了实验。
Exp_1 的主要指标提升的 95% CI 为 2.3% - 13.0%
Exp_2 的主要指标提升的 95% CI 为 6.2% - 8.4%
Exp_3 的主要指标提升的 95% CI 为 5.9% - 7.4%
从这些结果中，我们可以得出结论，这三个实验都具有相同的指标提升吗？
如果是/否，为什么？
我原本希望这些实验的指标提升是相同的。因为三个实验的处理方式相同。它们之间唯一的区别是参与实验的用户数量。因此，我想了解的是指标提升是否会根据参与实验的用户数量而变化。如果是这样，那么我们将不得不始终在 100% 用户参与的情况下运行实验。这并不理想，因为我们不能同时运行其他实验。]]></description>
      <guid>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</guid>
      <pubDate>Tue, 09 Jul 2024 07:16:34 GMT</pubDate>
    </item>
    <item>
      <title>通过 TP、TN、FP 和 FN 值判断模型</title>
      <link>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</link>
      <description><![CDATA[我正在使用多个数据集评估一个模型，该模型可以预测某个“特征”是否存在（例如，“这幅图像中有一只狗”）。系统会针对每个数据集输出 TP、TN、FP 和 FN。
我想要一个指标来判断模型的工作效果如何，但我意识到我无法仅绘制 TP，因为例如第一个数据集有 20 个具有特征（有一只狗）的实例，而第二个数据集只有 10 个。即使模型是完美的，第二个数据集也只有 10 个 TP。
我正在考虑计算每个数据集和所有数据集的准确率、精确率和召回率。
我也对每个数据集运行了三次模型，变化很小
我也在研究精确率-召回率曲线，但似乎这些是针对不同的阈值的，显然每个数据集只有一组精确率、召回率
有什么好方法可以判断模型是否“好”？由于我的经验不足，我无法提出一个好的判断标准
起初我想绘制所有数据集的每个（TP 等）的分布
然后我想绘制一个结合所有数据集的混淆矩阵
任何建议都将不胜感激

作为一个简单的虚构示例，我想到
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confused_matrix, precision_score, recall_score, f1_score, accuracy_score

# 示例虚构数据
datasets = {
&#39;datasetA&#39;: {&#39;TP&#39;: 150, &#39;TN&#39;: 200, &#39;FP&#39;: 50, &#39;FN&#39;: 100, &#39;no_GT&#39;: 34},
&#39;数据集B&#39;：{&#39;TP&#39;：180，&#39;TN&#39;：220，&#39;FP&#39;：40，&#39;FN&#39;：81，&#39;no_GT&#39;：20}，
&#39;数据集C&#39;：{&#39;TP&#39;：160，&#39;TN&#39;：240，&#39;FP&#39;：70，&#39;FN&#39;：110，&#39;no_GT&#39;：30}，
&#39;数据集D&#39;：{&#39;TP&#39;：190，&#39;TN&#39;：250，&#39;FP&#39;：60，&#39;FN&#39;：90，&#39;no_GT&#39;：42}，
}

def calculate_metrics（TP，TN，FP，FN）：
准确度 = (TP + TN) / (TP + TN + FP + FN)
精度 = TP / (TP + FP) if (TP + FP) &gt; 0 else 0
召回率 = TP / (TP + FN) if (TP + FN) &gt; 0 else 0
f1 = 2 * (准确率 * 召回率) / (准确率 + 召回率) if (准确率 + 召回率) &gt; 0 else 0

return {
&#39;Accuracy&#39;: 准确度,
&#39;Precision&#39;: 精度,
&#39;Recall&#39;: 召回率,
&#39;F1 分数&#39;: f1
}

# 聚合计数
total_TP = sum(data[&#39;TP&#39;] for data in datasets.values())
total_TN = sum(data[&#39;TN&#39;] for data in datasets.values())
total_FP = sum(data[&#39;FP&#39;] for data in datasets.values())
total_FN = sum(data[&#39;FN&#39;] for data in datasets.values())

# 计算总体指标
overall_metrics = calculate_metrics(total_TP, total_TN, total_FP, total_FN)

# 计算每个数据集的指标
metrics_df = pd.DataFrame({dataset: calculate_metrics(data[&#39;TP&#39;], data[&#39;TN&#39;], data[&#39;FP&#39;], data[&#39;FN&#39;]) for dataset, data in datasets.items()})

# 添加总体指标
metrics_df[&#39;Overall&#39;] = Overall_metrics

print(metrics_df)

# 可视化
fig, axis = plt.subplots(2, 2, figsize=(14, 10))
axes = axis.flatten()

for i, (dataset, data) in enumerate(datasets.items()):
cm = confused_matrix([1] * data[&#39;TP&#39;] + [0] * data[&#39;TN&#39;] + [1] * data[&#39;FN&#39;] + [0] * data[&#39;FP&#39;],
[1] * (data[&#39;TP&#39;] + data[&#39;FP&#39;]) + [0] * (data[&#39;TN&#39;] + data[&#39;FN&#39;]))
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;Blues&#39;, ax=axes[i])
axes[i].set_title(f&#39;混淆矩阵 - {dataset}&#39;)
axes[i].set_xlabel(&#39;预测&#39;)
axes[i].set_ylabel(&#39;True&#39;)

plt.tight_layout()
plt.show()

我得到了
 数据集A 数据集B 数据集C 数据集D 总体
准确率 0.700000 0.767754 0.689655 0.745763 0.725696
精确率 0.750000 0.818182 0.695652 0.760000 0.755556
召回率 0.600000 0.689655 0.592593 0.678571 0.640905
F1 分数 0.666667 0.748441 0.640000 0.716981 0.693524

和
]]></description>
      <guid>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</guid>
      <pubDate>Tue, 09 Jul 2024 05:43:39 GMT</pubDate>
    </item>
    </channel>
</rss>