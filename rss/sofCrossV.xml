<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Sep 2024 15:18:02 GMT</lastBuildDate>
    <item>
      <title>使用 Lavaan 对二进制变量进行引导</title>
      <link>https://stats.stackexchange.com/questions/654787/bootstrapping-of-binary-variables-using-lavaan</link>
      <description><![CDATA[我是 R 的新用户，在使用我的模型进行引导时遇到了问题。
所有外生变量、内生变量和中介变量都是二元结果。我尝试按照解决方案添加“se = “bootstrap”、estimator = “DWLS”、verbose = TRUE”，但仍然不起作用。
请就此提出建议和意见。感谢您的时间。
这是我的代码
model19 &lt;-&#39;ls ~ a1participation1 + health_status
health_status ~ a2participation1
hsu~ d1ls + d2health_status +c1participation1 +e1rural + e2female +
e3middle+e4oldest+e5primary+e6secondary+e7higher+e8married+
e9all+e10employ+e11support+e12pension
indirect1:=a1d1
indirect2:=a2*d2
overallindirect:= indirect1+ indirect2
total:=overallindirect +c1+e1+e2+e3+e4+e5+e6+e7+e8+e9+e10+e11+e12&#39;
fit19 &lt;- sem(model19, data = old_main, ordered = c(&quot;hsu&quot;, &quot;ls&quot;, &quot;health_status&quot;),
se = &quot;bootstrap&quot;, estimator = &quot;DWLS&quot;, verbose = TRUE)
summary(fit19, unified=TRUE, ci=TRUE, fit.measures=TRUE)]]></description>
      <guid>https://stats.stackexchange.com/questions/654787/bootstrapping-of-binary-variables-using-lavaan</guid>
      <pubDate>Mon, 23 Sep 2024 15:16:57 GMT</pubDate>
    </item>
    <item>
      <title>加权后进行 g 计算时如何决定使用哪个样条曲线？</title>
      <link>https://stats.stackexchange.com/questions/654784/how-to-decide-which-spline-to-use-when-conducting-g-computation-after-weighting</link>
      <description><![CDATA[我已经进行了统计加权（R 包 WeightIt），现在我正在使用 g 计算（R 包边际效应）来估计树木覆盖率对作物产量的影响（遵循 https://ngreifer.github.io/WeightIt/articles/estimating-effects.html）。我不希望这种关系是线性的，所以我想使用自然样条曲线，但我不确定要指定多少 df，例如，df=4 和 df=2 会导致非常不同的结果和解释。进行模型选择（例如使用 AIC）感觉不太合适，因为它是一种预测技术，不适合因果推理。那么我该如何为我的样条曲线选择正确的 df 数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654784/how-to-decide-which-spline-to-use-when-conducting-g-computation-after-weighting</guid>
      <pubDate>Mon, 23 Sep 2024 14:43:42 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归——证明 B1=B2=B3=B4</title>
      <link>https://stats.stackexchange.com/questions/654782/multiple-linear-regression-proving-b1-b2-b3-b4</link>
      <description><![CDATA[给定 y = Bo +B1X1 +B2X2 +B3X3+ B4X4 + e
问题问：使用一般线性假设来展示如何测试：
a) Ho：B1=B2=B3=B4
b) Ho：B1=B2，B3=B4
给定照片中的解决方案，我正在寻找对上述问题部分 a) 和 b) 的解决方案的解释。
具体来说，在解决方案 a 和 b 中，此解决方案中的矩阵布局的原因是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654782/multiple-linear-regression-proving-b1-b2-b3-b4</guid>
      <pubDate>Mon, 23 Sep 2024 14:18:02 GMT</pubDate>
    </item>
    <item>
      <title>Box-Cox 变换和 t 检验</title>
      <link>https://stats.stackexchange.com/questions/654779/box-cox-transformation-and-t-test</link>
      <description><![CDATA[我有两个数据集，希望测试它们的均值差异（T 检验）。但是，根据 R 中的 Shapiro 检验，它们不服从正态分布。
我已经看到 Box-Cox 变换是可行的方法，但我是否使用相同的 $\lambda$ 来转换数据集，还是单独转换它们？
即：
$$y_{i,\,transformed} = \begin{cases} 
\frac{y_i^\lambda-1}{\lambda} &amp; \lambda\neq 0 \\
\ln(y_i) &amp; \lambda = 0 
\end{cases}$$
对数据集 A 和数据集 B 使用一个 $\lambda$，还是使用两个 $\lambda$（$\lambda_A$ 和 $\lambda_B$）？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654779/box-cox-transformation-and-t-test</guid>
      <pubDate>Mon, 23 Sep 2024 14:00:16 GMT</pubDate>
    </item>
    <item>
      <title>与其他架构相比，lstms 为 Apple 的语言识别提供了哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/654778/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</link>
      <description><![CDATA[既然 LSTM 的强大功能来自其长程依赖性记忆，那么为什么我们要使用 LSTM 而不是其他架构来从短文本字符串中进行基于字符的语言识别 (LID)？
例如，Apple 发布了一篇行业博客文章，指出他们使用 biLSTM 进行语言识别：https://machinelearning.apple.com/research/language-identification-from-very-short-strings
然后这篇论文试图复制它：https://aclanthology.org/2021.eacl-srw.6/
我在阅读 Karpathy 关于 RNN 的著名文章时，尝试训练一个小型语言识别模型进行练习。我首先尝试了一种简单、直观（对我来说）的方法：使用 tf-idf，使用在训练数据中的双或三元计数上训练的朴素贝叶斯分类器。我的数据集包含不同语系的 13 种语言。虽然我的简单分类器确实表现良好，但在查看类似语言时会出错。例如，西班牙语通常被归类为葡萄牙语。
我研究了神经网络架构，发现 LSTM 经常用于语言识别任务。在阅读了有关 RNN 和 LSTM 的内容后，我无法完全理解为什么 LSTM 更适合用于 LID，尤其是短文本字符串。这不是违反直觉的吗，因为 LSTM 擅长记住长距离依赖关系，而 RNN 则不然？对于短文本字符串，我建议使用 vanilla RNN....
Apple 博客确实说过：

在本文中，我们探讨了如何通过将其视为字符级别的序列标记问题，并使用在短字符序列上训练的双向长短期记忆 (bi-LSTM) 神经网络来提高 LID 准确性。

我觉得我没有理解这里的一些基本知识。
那么，他们的 LSTM 的学习目标是否是正确分类给定的字符 n-gram？这就是他们所说的“序列标记”问题吗？序列标记任务的根本难道不就是分类任务吗（“用 N 个预定义标签中的 1 个标记来自测试集的给定输入”）？
当您使用已知可以处理长序列的架构时，在短字符序列上训练 LSTM 有什么意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/654778/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</guid>
      <pubDate>Mon, 23 Sep 2024 13:52:29 GMT</pubDate>
    </item>
    <item>
      <title>矩阵的期望值=期望值矩阵？</title>
      <link>https://stats.stackexchange.com/questions/654777/expected-value-of-a-matrix-matrix-of-expected-value</link>
      <description><![CDATA[我对以下陈述感到疑惑：矩阵的期望等于期望矩阵。
例如，假设 A 是一个由 4 个随机变量组成的矩阵，W、X、Y、Z
那么，我们通常写为 E(A) = E(R.V.) 矩阵
这总是正确的吗？
R.V. 中的一些/全部是相关的吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654777/expected-value-of-a-matrix-matrix-of-expected-value</guid>
      <pubDate>Mon, 23 Sep 2024 13:26:45 GMT</pubDate>
    </item>
    <item>
      <title>两个比率指标之间的变异系数</title>
      <link>https://stats.stackexchange.com/questions/654776/coefficient-of-variation-between-two-ratio-metrics</link>
      <description><![CDATA[我想比较哪个指标更稳定（每次展示费用与每次视频观看费用）。
我使用了 CV（变异系数），并寻找了在使用不同货币的多个广告系列中，对于同一广告系列，哪个指标 CV 较低。这种方法合适吗？数据不呈正态分布有关系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654776/coefficient-of-variation-between-two-ratio-metrics</guid>
      <pubDate>Mon, 23 Sep 2024 13:24:12 GMT</pubDate>
    </item>
    <item>
      <title>各变量不平等问题的统计检验</title>
      <link>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</link>
      <description><![CDATA[我们的问卷有 5 个问题针对自变量，10 个问题针对因变量。是否可以测试这两个变量之间的相关性？如果可以，我们应该使用什么统计测试？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</guid>
      <pubDate>Mon, 23 Sep 2024 12:21:15 GMT</pubDate>
    </item>
    <item>
      <title>估计标准差并得到置信概率</title>
      <link>https://stats.stackexchange.com/questions/654773/estimate-standard-deviation-and-get-a-confidence-probability</link>
      <description><![CDATA[我没有统计学背景，所以请您多多包涵。凭借我有限的知识，我也没有找到任何类似的帖子，或者至少是我能理解的帖子。
这是我的问题，我有各种没有明确趋势的信号，从简单的收敛指数到看起来像跳跃的随机游走（最坏情况），见下文。这些信号很嘈杂，或多或少是恒定的噪声，我知道它遵循正态分布。

我想测量这种噪声的标准偏差，我对它的平均值不感兴趣，因为它不稳定。
我使用一种非常规的方法来估计标准偏差，但效果很好。我也快速检查了数学；理论上，输出是标准偏差。一开始，我使用 2 个点的移动标准差的标准差和贝塞尔校正，即 std(movstd(x,2,0),1)，可以在以下代码中简化。
time = linspace(0,80,300)&#39;;
true_sigma = 1;
noise = true_sigma*randn(size(time));
true_sigma = std(noise);
process = cumsum(0.3*randn(size(time)));
jump_point = 50;
process(time&gt;jump_point) = process(time&gt;jump_point)+15;
signal = process+noise;

s_list = nan(size(time));
for k=1:length(time)
d = gradient(signal(1:k));
s_list(k) = std(d)*2/sqrt(2);
end
subplot(2,1,1);
plot(time,signal); grid on; xlim([time(1) time(end)]); title(&#39;信号&#39;); xlabel(&#39;时间 (分钟)&#39;)
subplot(2,1,2);
plot(s_list); grid on; xlim([1 length(s_list)]); title(&#39;估计标准偏差&#39;); xlabel(&#39;样本&#39;); yline(true_sigma,&#39;--r&#39;);
legend(&#39;\sigma_{est}&#39;,&#39;\sigma_{true}&#39;)

这是此代码的输出。信号代表最坏情况，但仍有可能发生。您可以看到，当信号跳跃时，估计的标准偏差也会跳跃，并且需要很长时间才能再次收敛。
这就是我想要的：
解决方案 1：不受这种跳跃的影响或减轻它们的影响或更快地收敛
解决方案 2：有一个置信度指标，让我可以选择运行中最佳/最可能的猜测。
我确实研究过贝叶斯干扰，但说实话，我不明白该怎么做，也不知道从哪里开始。

谢谢你的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/654773/estimate-standard-deviation-and-get-a-confidence-probability</guid>
      <pubDate>Mon, 23 Sep 2024 12:12:22 GMT</pubDate>
    </item>
    <item>
      <title>如何控制模型中的观测次数？</title>
      <link>https://stats.stackexchange.com/questions/654771/how-control-for-the-number-of-observations-in-the-models</link>
      <description><![CDATA[假设我们有两个时间序列，即 $Y^{(1)}$ 和 $Y^{(2)}$，分别具有 $n^{(1)}&gt;&gt;n^{(2)}$ 个观测值（换句话说，$Y^{(1)}$ 比 $Y^{(2)}$ 具有更多的观测值）。对于每个时间序列，我们估计一个 AR(1) 模型，然后我们的目标是比较系数的大小：
$$Y^{(1)}_{t}=\alpha^{(1)}+\beta^{(1)}Y^{(1)}_{t-1}+\epsilon^{(1)}_{t},$$
$$Y^{(2)}_{t}=\alpha^{(2)}+\beta^{(2)}Y^{(2)}_{t-1}+\epsilon^{(2)}_{t},$$
我们想要确定 $sgn(\hat{\beta}^{(1)}-\hat{\beta}^{(2)})$。
这个简单问题的复杂性在于，观测值的数量差异很大，并且它产生了 AR(1) 系数估计值之间的一致差异。我估计了几千对时间序列的 AR(1) 模型，并通过统计证实，在其他条件相同的情况下，时间序列长度较短的时间序列的系数小于时间序列长度较长的时间序列（该结果是通过回归和随机森林实现的）。对于上面的这一对，我们有 $|\hat{\beta}^{(1)}&gt;\hat{\beta}^{(2)}|$。因此，我想在进行任何比较之前以某种方式调整 AR(1) 系数。
我想到的一个方法是根据标准误差调整相应的系数，因为后者考虑了观测次数。换句话说，该方法是计算 $\hat{\beta}^{(1)}/SE^{(1)}$ 和 $\hat{\beta}^{(2)}/SE^{(2)}$，然后确定 $sgn(\hat{\beta}^{(1)}/SE^{(1)} - \hat{\beta}^{(2)}/SE^{(2)})$。但是，这种方法并不有效，因为标准误差（可以预料）对于较长的时间序列来说较小，并且小于 1。因此，相对于 $\hat{\beta}^{(1)}$，$\hat{\beta}^{(1)}/SE^{(1)}$ 的增加幅度远远大于 $\hat{\beta}^{(2)}/SE^{(2)}$ 与 $\hat{\beta}^{(2)}$ 相比，这意味着我们进一步增加了系数之间的差距，但 $sgn(\cdot)$ 函数仍然产生相同的结果结果。
问题：

您将使用什么方法根据观察次数调整 AR(1) 系数？

您将如何改进/修改我在此处描述的方法，以使其可行且有效？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654771/how-control-for-the-number-of-observations-in-the-models</guid>
      <pubDate>Mon, 23 Sep 2024 11:42:34 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该在线性回归中对二元预测变量进行标准化？</title>
      <link>https://stats.stackexchange.com/questions/654770/should-you-normalize-binary-predictors-in-linear-regression</link>
      <description><![CDATA[我有一个线性回归 y=ax+c 和一个多元回归 y=ax+bz+c。在这两个回归中，x 都是二进制变量 (0,1)。y 已进行协变量校正和标准化。x 也应该标准化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654770/should-you-normalize-binary-predictors-in-linear-regression</guid>
      <pubDate>Mon, 23 Sep 2024 11:22:57 GMT</pubDate>
    </item>
    <item>
      <title>Tobit 模型正态性假设</title>
      <link>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</link>
      <description><![CDATA[对于 tobit 模型，我对正态性假设有点困惑。是不是我的因变量必须服从正态分布？还是我的模型的潜在残差必须服从正态分布？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</guid>
      <pubDate>Mon, 23 Sep 2024 09:07:10 GMT</pubDate>
    </item>
    <item>
      <title>这是贝叶斯分类器最优的证明吗？</title>
      <link>https://stats.stackexchange.com/questions/654760/is-this-the-proof-the-the-bayes-classifier-is-optimal</link>
      <description><![CDATA[在“统计学习简介”中，他们说贝叶斯分类器是最优的证明超出了本书的范围：

在“统计学习要素”中有这个：

我想知道他们所说的证明是否超出了《统计学习简介》一书的范围，第二张图片中提供的是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654760/is-this-the-proof-the-the-bayes-classifier-is-optimal</guid>
      <pubDate>Mon, 23 Sep 2024 07:46:10 GMT</pubDate>
    </item>
    <item>
      <title>影响 1/2 结果的多个相关变量的统计分析方法</title>
      <link>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</link>
      <description><![CDATA[我将抽象化这个问题以隐藏我实际的研究内容，但我绝对是统计分析方面的菜鸟，我想向这个网站的大神们学习更多。
我目前正在研究睡眠时间、是否生病以及白天的工作时间，以及这些因素在一年的时间内如何导致抑郁症的发展。另一个结果是他们因抑郁而产生暴力倾向。
我想调查的是这些因素对每个结果的独立影响，以解释潜在的混杂因素（因为抑郁是众所周知的暴力倾向的诱因，但我想看看这些因素是否会导致即使没有抑郁也会产生暴力倾向）。
我最初在 MANCOVA 和多元线性回归之间争论，但我不确定我应该如何处理这个问题。对所用方法还有其他建议吗？在此先向那些愿意帮助我的人表示感谢。这对我来说意义重大，是一次学习经历。]]></description>
      <guid>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</guid>
      <pubDate>Mon, 23 Sep 2024 02:39:35 GMT</pubDate>
    </item>
    <item>
      <title>R 包 aTSA 中的 ARCH-LM 检验统计量</title>
      <link>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</link>
      <description><![CDATA[我想执行 ARCH-LM 测试。首先，我自己计算了 LM 统计量，方法是将平方残差回归为常数和 p 滞后值。根据 Engle (1982)，LM 统计量是 TR^2，其中 T 个观测值和 R^2 作为辅助回归的判定系数。
然后，我尝试了 aTSA 中的 arch.test() 函数，它返回了完全不同的值，行为完全相反。顺序越大，统计量越小。此外，考虑到顺序=自由度、统计量和 p 值的组合，统计量似乎不是卡方分布。以下是我的步骤：
#访问数据

library(yfR)
CVX_data=yf_get(
tickers = &quot;CVX&quot;,
first_date = &quot;2020-01-02&quot;,
last_date = &quot;2021-12-31&quot;)

#计算数据

attach(CVX_data)
close_ln=c(log(price_adjusted))
close_ln_d=c(NA, diff(log(price_adjusted)*100))

#新格式

new_df=data.frame(ref_date, price_adjusted, close_ln, close_ln_d)
new_df_2=new_df[-c(1),]
comp_data=new_df_2[,4]

#内置 ARCH测试

ARM=arima(comp_data, order=c(2,0,0))
library(aTSA)
arch.test(ARM)

#ARCH 测试“手动”

AR=ar(comp_data, aic=FALSE, order.max=2)

uhat2=(AR$resid)^2
obs=length(uhat2)

ch1 &lt;- function(p){
uhat2[-c(obs:(obs-p+1))]
}
ch2 &lt;- function(p){
c(seq(1:p), ch1(p))
}
ch3 &lt;- function(p){
replace(ch2(p), ch2(p)[1:p], NA)
}
ch4 &lt;- function(p){
c(1:p)
}
U &lt;- function(p){
sapply(ch4(p), ch3)
}
reg2 &lt;- function(p){
lm(uhat2 ~ U(p))
}
T &lt;- function(p){
503-2-p
}
R2 &lt;- function(p){
summary(reg2(p))$r.squared
}
Statistic &lt;- function(p){
T(p)*R2(p) 
}
Statistic(2)

有人能解释一下这个差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</guid>
      <pubDate>Mon, 23 Sep 2024 00:30:45 GMT</pubDate>
    </item>
    </channel>
</rss>