<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 27 Feb 2025 01:17:52 GMT</lastBuildDate>
    <item>
      <title>log-transforming响应变量有助于创建均质的残差，但它会产生0 <x <1的不良值</title>
      <link>https://stats.stackexchange.com/questions/661899/log-transforming-response-variable-helps-create-homoscedastic-residuals-but-it</link>
      <description><![CDATA[我正在尝试建模我的模型预测误差（计算为测量的绝对值 - 预测）与省份的年平均温度，作为随机效应，并具有以下模型：
态
由于采用绝对值，错误响应变量始终为正。值通常范围从0.1（表明与测量值非常好的仿真一致）到100（表明模拟精度非常差）。 
当我建模这种关系时，我会得到非常异性的残差：
 如果我首先将响应变量登录，则会获得更多均匀的残差。但是，在模型一致性确实良好且错误在0到1之间的情况下，对数转换数据会导致较大的负值：
 这是一个很好的实例，我应该在其中进行日志（x+1）？这个论坛上的许多人都不同意这种做法（例如这是残留方差，其响应变量由log（x+1）转换：
 &lt;img alt =“在此处输入图像描述”]]></description>
      <guid>https://stats.stackexchange.com/questions/661899/log-transforming-response-variable-helps-create-homoscedastic-residuals-but-it</guid>
      <pubDate>Thu, 27 Feb 2025 00:12:59 GMT</pubDate>
    </item>
    <item>
      <title>Fisher信息的重新聚集</title>
      <link>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</link>
      <description><![CDATA[  大家好，
我不明白为什么我们为什么有 $ l _ {\ phi}（\ phi）= l _ {\ theta}（h^{ -  1}（\ phi）（\ phi））$ span $不应该是或如何 $ l _ {\ theta}（h^{ -  1}（\ phi）（\ phi）= l _ {\ phi}（\ phi}（\ phi}（\ theta））也许下标使我在这里感到困惑。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</guid>
      <pubDate>Wed, 26 Feb 2025 22:08:26 GMT</pubDate>
    </item>
    <item>
      <title>早期培训中的班级预测分布不平吗？</title>
      <link>https://stats.stackexchange.com/questions/661895/is-uneven-class-prediction-distribution-in-early-training-beneficial</link>
      <description><![CDATA[我正在用平衡的数据集编写一个模型，以解决图像分类问题。我注意到，随着培训的进展，我的模型似乎首先预测了几个课程，然后再扩展到培训结束时再次扩展到更均匀的预测分布。这种行为叫什么，这是有益的吗？它使我想起了课程学习的目标，或者据我所知，这是在这里独自发生的，而没有任何故意促进这种行为的情况。
这是三个图的图片，显示了我所指的行为：
 左图是在训练的最新开始，并且预测在所有类之间都非常均匀地分布。中间图是中间训练，显示出更不平衡的分布。右图显示了在训练结束时分布的样子，并且更甚至是。]]></description>
      <guid>https://stats.stackexchange.com/questions/661895/is-uneven-class-prediction-distribution-in-early-training-beneficial</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:40 GMT</pubDate>
    </item>
    <item>
      <title>随机效应建模与Stouffer的荟萃分析方法</title>
      <link>https://stats.stackexchange.com/questions/661894/random-effects-modeling-vs-stouffers-method-in-meta-analysis</link>
      <description><![CDATA[假设两个点估计值及其相应的 $ z $ 统计值可用于荟萃分析。随机效应模型通常被认为是适当的方法，因为它涉及研究内和研究之间的变异性。但是，如果Stouffer的方法专门用于 $ z $ 统计学，是否会导致低估或高估荟萃分析的统计强度？例如，一种方法可以产生重大结果，而另一种方法没有？如果是这样，是否存在模拟案例或现有文献来说明此类偏见？]]></description>
      <guid>https://stats.stackexchange.com/questions/661894/random-effects-modeling-vs-stouffers-method-in-meta-analysis</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:26 GMT</pubDate>
    </item>
    <item>
      <title>从山脊回归中的重要特征相互矛盾的特征 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</link>
      <description><![CDATA[我正在使用多种方法来得出具有相关功能的数据集的特征重要性：
我正在为以下模型使用模型系数：
山脊，套索和弹性净回归
此外，我还将置换重要性用于随机森林模型，XGBoost模型的平均增益用于分析特征重要性。
这些方法中的大多数都显示出合理的共识，但是脊回归给出了矛盾的结果。处理相关功能时，这是一种适当的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:03 GMT</pubDate>
    </item>
    <item>
      <title>SVD的行告诉我们有关PCA的什么？</title>
      <link>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</link>
      <description><![CDATA[If we have a matrix $X\in\mathbb{R}^{n\times p}$ with SVD $X = UDV^T$, we can say for example that the columns of $V$ are the principal directions and the columns of $UD$ are the principal components (see this answer).
我们可以就PCA的这些行做出任何有趣的陈述吗？一位同事告诉我， $ v $ 的行与功能对每个主要组件的贡献相对应，但是我无法在此上找到任何证据或文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</guid>
      <pubDate>Wed, 26 Feb 2025 21:59:12 GMT</pubDate>
    </item>
    <item>
      <title>有关跨尺度探索性结构方程建模（ESEM）的问题</title>
      <link>https://stats.stackexchange.com/questions/661890/question-about-cross-scale-exploratory-structural-equation-modeling-esem</link>
      <description><![CDATA[我正在研究一个正在使用探索性结构方程建模（ESEM）的项目。我通常会看到ESEM用于范围内的文章。您可以做ESEM，其中不仅在尺度上而且在尺度之间存在互载吗？
例如，假设您有2个量表，每个量表有3个因素，12个问题（每个因素4个问题）我可以在比例项内和比例项之间的每个项目交叉载荷吗？之间？
该项目的上下文，我的量表是我的理论化（和先前的研究）测量全球潜在特征。我试图将论点定位为“这些”正在测量同一件事。
如果您能提供任何有助于此询问的文章，我将非常感谢它！]]></description>
      <guid>https://stats.stackexchange.com/questions/661890/question-about-cross-scale-exploratory-structural-equation-modeling-esem</guid>
      <pubDate>Wed, 26 Feb 2025 21:51:52 GMT</pubDate>
    </item>
    <item>
      <title>选择一种重复测量的统计测试方法，以确定测量值是否存在趋势</title>
      <link>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</link>
      <description><![CDATA[这可能是一个简单的问题，但是...
我与之合作的城市有一个固定墙，显示了装饰性面部的一些裂缝。我们无法判断这是否只是需要修复的面孔，还是墙壁实际移动（那将是不好的）。  从现场观测来看，我们看不到任何其他证据表明墙壁运动（例如墙后的土壤或墙壁倾斜的土壤 - 所以，这很好）。  我们已经使用了调查设备来测量8个不同位置的墙壁顶部（通常在发生裂缝的位置上）。  我们从8月底开始了测量结果，并每月（一周内+/-）与相同的设备和操作员进行了相同的位置。  我们对每个位置都有6个观察结果。  测量误差的设备为+/- 0.03英尺。  数据是北向和朝东的坐标对（北方的坐标就像y柱，朝东是x柱子）。  我不知道的一件事是，季节性天气是否会引起墙壁的某些自然运动，我们只衡量了大约半年 - 我们从夏天开始，现在已经低于零，地面被冻结了 - 因此，如果有一些自然运动，我不会感到惊讶。我确定我还没有足够的数据来回答这个问题。
无论如何，我想分析我必须查看一个方向上是否存在趋势（墙正在移动），或者是移动和观察错误或多或少是随机的，或者有足够的数据要说，我们需要继续测量。  我的直觉告诉我，这并没有显着移动，但是我希望以某种方式以某种程度的概率进行中间分析。
我首先想到按位置对数据进行线性回归分析，以查看R2是否表示线性，但是我以为墙是否只是来回振荡，这可能显示出线性模式，尽管不是一个方向。  我想到了北向的T测试和t的t测试，以为如果动作是随机的，它将聚集在某个中心点周围（正常分布？也许？），但我并没有真正比较两个数据集的平均值。我正在比较随着时间的推移在同一位置进行的测量。  假设我的比较样本为零，我考虑了T测试，但这似乎也不正确。我有点挥舞着，可以使用一些指导，将我指向正确的方向进行适当的测试。  任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</guid>
      <pubDate>Wed, 26 Feb 2025 21:42:01 GMT</pubDate>
    </item>
    <item>
      <title>当分类变量具有零级时，Pairwse比较</title>
      <link>https://stats.stackexchange.com/questions/661886/pairwse-comparisons-when-categorical-variables-has-zeros-in-their-levels</link>
      <description><![CDATA[我有一个物种出现的数据集（社区矩阵），我在其中使用GLMM + Tukey HSD分析了树种的甲虫偏好和治疗。我的问题是，某些树种中缺少物种（例如，仅在松树中，橡木，山毛榉，云杉）或治疗导致Tukey的测试返回0的T值，从而无法从统计上确定偏好。。
这是我的模型：
  library（LME4）;库（MULTCOMP）
set.seed（8）

loop＆lt;  - 功能（x）{
  ＃x＆lt;  -  1
  x_org＆lt;  -  x
  打印（名称（Spec）[x]）
  
  ＃尝试安装模型并捕获错误
  结果＆lt;  -  trycatch（{{
    erg＆lt;  -  glmer（spec [，x]〜处理 + tree_species +曝光 +（1 | locality） +（1 |代码），
                 family =; poisson＆quot data = env）
    
    ＃检查奇异性
    if（Issingular（erg））{
      警告（粘贴（&#39;边界“界单数拟合”；名称（spec）[x]）））））
      返回（null）＃返回null以指示奇异性问题
    }
    
    ＃ 治疗
    res_treat＆lt;  -  cftest（glht（erg，linfct = mcp = mcp（处理=＆quot; tukey;）））））））
    res_treat＆lt;  -  cbind（res_treat  $ test $ 系数，res_treat  $ test $ test $  sigma，res_treat  $ test $  PVALUE）
    
    ＃树种
    res_tree＆lt;  -  cftest（glht（erg，linfct = mcp）
    res_tree＆lt;  -  cbind（res_tree  $ test $ 系数，res_tree  $ test $ test $  sigma，res_tree  $ test $  PVALUE）
    
    ＃ 接触
    res_exp＆lt;  -  cftest（glht（erg，linfct = mcp（曝光=＆quot; tukey; quot; quot）））））））
    res_exp &lt;- cbind(res_exp$test$coefficients, res_exp$test$sigma, res_exp$test$tstat, res_exp$test$pvalues)
    
    ＃结合结果
    res＆lt;  -  data.frame（rbind（res_treat，res_tree，res_exp））
    名称（res）＆lt;  -  c（“估算” std;
    res＆lt;  -  res [order（res $ tval，deping = true），]，]
    
    res  $ spec＆lt;  - 名称（spec）[x]
    res $ 组合＆lt;  -  row.names（res）
 
我可以使用哪种统计方法正确检测这些偏好？
这是一个数据示例：
  dput（sample_spec）
结构（列表（Ernobius.mollis = C（0L，0L，0L，0L，11L，0L，0L，0L，0L，0L，0L， 
0L，0L，0L），nemozoma.elongatum = C（0L，0L，0L，0L，0L，0L，0L，0L，0L，0L，，， 
0L，0L，0L），leiopus.nebulosus = C（3L，0L，0L，0L，0L，0L，0L，0L，0L，0L， 
0L，0L，0L），anaspis.flava = C（0L，0L，0L，0L，0L，0L，0L，0L，0L，0L，0L，0L， 
0L，0L），Antholinus.analis = C（0L，0L，0L，0L，0L，0L，0L，0L，0L，0L，0L， 
0l，0l）），row.names = c（; b_36_w_sim_c＆quort; b_23_w_got_e; 
＆quot＆quot; s_18_c_got_c＆quort; s_16_c_hlb_c＆quot; s_18_c_got_c;; 
＆quot&#39;p_54_r_sve_e_e;

dput（sample_env）
结构（列表（code = c）（s_03_s_got_c; quot_; o_30_w_pod_c; 
＆quot&#39;b_30_r_kam_c＆quot;＆quort; b_01_c_alp_c;; s_01_c_pal_c＆quot; s_01_c_pal_c＆quort 
＆quot＆quot; 
1L，3L，2L，2L，4L，2L，3L，1L，3L），级别= C（&#39;oak; quot&#39;beech&#39;; 
＆quot“ pine; quot”&#39;&#39; 
3L，2L，4L，2L，2L，4L，4L，3L，5L），级别= C（“灭菌” 
“ control”“ control”&#39;&#39;&#39;白与brown-rot; quot; quot; quot; quot; quot burned; quot class =“ factor” factor＆quot＆quot＆quort 
    位置=结构（C（4L，8L，2L，6L，1L，1L，7L，9L，4L，4L，2L，， 
    8l），laste = c（“ alp” bav; bes&#39;bes&#39;&#39; 
    “ pal” p; 
    1L，2L，1L，1L，1L，1L，1L，1L，1L），LEVEL = C（“ Shady” 
    ＆quot&#39;exped＆quot＆quot class =&#39;factor; factor; 
    390、1069、344、380、410、957、387），树=结构（c（2l， 
    1L，2L，1L，1L，2L，1L，2L，1L，2L），级别= C（&#39;Broadleaf＆quot＆quot＆quot； 
    ＆quot“针叶性”，class =; factor＆quot＆quot＆quot＆quot＆quot＆quot nspec = c（1、3、0、2、3， 
    0、4、1、3、2），abu = c（1、8、0、4、23、0、35、1、4、5）），class = c（＆quot; tbl_df; tbl_df; 
＆quot“ tbl”＆quot＆quot＆quot data.frame; quot＆quot; row.names = c（na，-10l））
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661886/pairwse-comparisons-when-categorical-variables-has-zeros-in-their-levels</guid>
      <pubDate>Wed, 26 Feb 2025 21:23:08 GMT</pubDate>
    </item>
    <item>
      <title>在具有自相关的时间序列数据中，我应该如何过滤观察值？</title>
      <link>https://stats.stackexchange.com/questions/661885/in-time-series-data-with-autocorrelation-how-should-i-filter-observations</link>
      <description><![CDATA[我正在研究预测森林碳的模型的模拟精度。我将这些模拟值与特定地点的森林碳的测量值进行比较。每个地点的森林碳在两个不同的时间点上都测量了一次（mus_num = 0）或两次（mus_num = 0或1）。我想拟合一个统计模型，该模型将模拟与测量（测量模拟）与位点降水水平之间的不匹配之间的不匹配。我的统计模型是
在
这是一个示例数据集：
 
data.frame（
  stringsasfactor = false，
  site = c（“ 1011666_0”，“ 1011666_0”，“ 1011681_0” 1011681_0
           “ 1012486_0”，“ 1018511_0”，“ 1018511_0”
           “ 1026191_0”），
  mes_num = c（0，1，0，1，0，0，0，1，0），
  MESE_DATE = C（“ 2003-Aug-24”，“ 2016-Aug-23” 2003-Aug-23＆quot;
                ＆quot“ 2015-Aug-24”，“ 1998-Aug-27”，“ 2004-Jul-14”
                ＆quot“ 2016-Aug-18”，“ 1992-Jul-15”，“），
  测量= C（0.910244639424594,1.54591958771036,51.7550140227804，
               26.0494596988173,6.17227241687225，
               23.8625721291267,25.3490409931351,33.8718849849445），
  模拟= C（28.1389578951376,28.1970020547013,28.697986472168，
                29.7952317313328,19.639836759173，
                25.830655108843,26.8851164535837,33.810315799549），
  不匹配= C（-27.228713255713，-26.651082466991,23.0570275506124，
               -3.74577203251553，-13.4675643423007，
               -1.96808297971629，-1.53​​607546044858,0.061569185389601），
  stread = c（361、414、289、300、1096、265、347、1014）
）
 
The question is, considering there is autocorrelation of simulated values (the autocorrelation of simulated values is higher than measured values due to all the extraneous variables in reality that are not present in the simulation), I&#39;m considering what to choose between three options of filtering the response variable (mismatch):

在分析中包括每一行，无论是sus_num，我的分析具有最高的n，但是第二次重复测量的不匹配受到该站点[自动相关]第一个测量的不匹配的不匹配而过度影响）））
仅包括suce_num = 0，以减少自相关的效果（减少我的n）
汇总每个站点，并对每个站点中的每个观察值使用平均不匹配。这也使我的n量减少了与选项2相同的数量，但没有丢弃。重新计量数据。
]]></description>
      <guid>https://stats.stackexchange.com/questions/661885/in-time-series-data-with-autocorrelation-how-should-i-filter-observations</guid>
      <pubDate>Wed, 26 Feb 2025 20:05:02 GMT</pubDate>
    </item>
    <item>
      <title>GLMMTMB订购Beta回归问题 - 模型收敛和NAN产生</title>
      <link>https://stats.stackexchange.com/questions/661881/glmmtmb-ordered-beta-regression-issue-model-convergence-and-nans-produced</link>
      <description><![CDATA[我有一个响应变量的蜗牛消耗，这是一个比例（蜗牛死亡的数量/每介子的蜗牛总数）。我有一些使所有蜗牛死亡或没有死亡的中焦（因此，介于两者之间的0s和1s）。）。
我一直在研究可以处理0s和1s的模型，从我的研究中，听起来好像是我的订单beta回归可能是我的最佳选择（ https://www.robertkubinec.com/post/limited_dvs/ ）。我（到目前为止）对贝叶斯统计数据并不熟悉或解释输出，因此我很高兴发现我可以在GLMMTMB软件包中进行有序的beta回归，而我更熟悉的输出。我的模型如下，没有随机效果：
  m3＆lt;  -  glmmtmb（snail_consumption〜处理，data = nail_surv， 
              family = odbeta）
 
当我运行时，我会得到此警告：
 警告消息： 
在finalizetmb（tmbstruc，obj，fit，h，data.tmb.old）中：  
模型收敛问题；奇异收敛（7）。看  
    Vignette（“故障排除”），帮助（“诊断”）
 
这就是我在诊断功能中得到的：
 诊断（M3）
异常大的系数（| x |＆gt; 10）：
（截距）处理13处理24处理5处理21处理1 
    治疗19
-48.16492 48.5203​​8 50.42512 47.99970 49.47301 49.30457 86.22261
较低的截止
-22.41878

ZI（零通气的log-odds）中的大型负系数，  
    分散或随机
效果（对数标准偏差）提出不必要的组件  
    （在
受限的量表）；大的负面和/或正组件  
    二项式或泊松
有条件参数建议（准）完全分离。大的  
    NBINOM2的值  
分散表明您应该使用泊松模型。
 
这就是我的模型摘要Nans所得到的，我认为这确实有一个融合问题：
 ＆gt;摘要（M3）
 家庭：Ordbeta（Logit）
配方：蜗牛_CHIMPOMPTION〜处理
数据：Snail_SURV2

     AIC BIC LOGLIK偏差DF。 
    45.3 62.7 -12.7 25.3 32 

Ordbeta家族的分散参数（）：3.29 

条件模型：
            估计标准。错误z值pr（＆gt; | z |）
（截距）-48.16 Nan Nan Nan
治疗13 48.52 Nan Nan Nan
处理24 50.43 Nan Nan Nan
处理5 48.00 Nan Nan Nan
处理21 49.47 Nan Nan Nan
治疗1 49.30 Nan Nan Nan
处理19 86.22 Nan Nan Nan
 
转换我的数据，因此没有0和1确实使模型起作用：
 ＃略微转换数据，因此不是1或0
n＆lt;  -  nrow（snail_surv2）
snail_surv2 $ snail_consumption＆lt;  - （snail_surv2 $ snail_cummumption *（n -1） + 
                                        0.5） /n
 
，但从我的阅读中，这已经不再是一种建议的实践了。有人对为什么该模型不运行以及我能做什么来修复它有任何洞察力？]]></description>
      <guid>https://stats.stackexchange.com/questions/661881/glmmtmb-ordered-beta-regression-issue-model-convergence-and-nans-produced</guid>
      <pubDate>Wed, 26 Feb 2025 17:51:27 GMT</pubDate>
    </item>
    <item>
      <title>卡方功率分析</title>
      <link>https://stats.stackexchange.com/questions/661880/chi-square-power-analysis</link>
      <description><![CDATA[我正在尝试确定我是否有足够的功率和/或大型样本量，可以通过我的数据进行卡方分析。当使用SPSS以1个样本人口比例运行功率分析时，它要求人口比例和无效价值。当我尝试估计功率或样本量时，我不知道该盒子放入这些框中。我正在寻找.8功率，样本量为44。]]></description>
      <guid>https://stats.stackexchange.com/questions/661880/chi-square-power-analysis</guid>
      <pubDate>Wed, 26 Feb 2025 17:21:43 GMT</pubDate>
    </item>
    <item>
      <title>自相关和信息丢失</title>
      <link>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</link>
      <description><![CDATA[当我们想在样本上训练ML模型时，最好拥有I.I.D培训样本。如果样本是自相关的，我们需要更多数据才能实际训练模型。
直觉上，这很有意义，因为当示例为i.i.d时，每个新数据点都会添加“信息”。 （我们更好地理解分布 $ \ Mathbb {p} _x $ ）。当数据自动相关时，很难理解 $ \ MATHBB {p} _x $ 由于每个数据点没有添加太多信息，我们总是会看到几乎相同的数据点。
我的第一个问题是：有没有一种方法可以实际量化“信息”的概念。数学上？因此，表明当数据自动相关时，我们会丢失有关分布的信息，因此需要更多的数据点。
我的第二个问题是：要使模型了解数据是自动关节的，因此它实际上并不能代表 $ x $ 的真实分布，我们经常考虑datapoints： $ x_t-$ x_t-\ sum \ \ \ alpha_i x_i x_i x_i $ x_i $ 。现在我的问题是：如果我们观察到数据的转换版本，我们仍然可以收敛到密度 $ \ Mathbb {p} _x $ ，此转换后的收敛速度有多慢？]]></description>
      <guid>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</guid>
      <pubDate>Wed, 26 Feb 2025 16:45:58 GMT</pubDate>
    </item>
    <item>
      <title>左截断和间隔审查的数据使用特恩布尔提出的自符敏感算法</title>
      <link>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</guid>
      <pubDate>Tue, 25 Feb 2025 18:29:13 GMT</pubDate>
    </item>
    <item>
      <title>使用Jackson等人时，按每个随机效果分配$ i^2 $异质性估计。 （2012）伪 -  $ i^2 $方法</title>
      <link>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the</link>
      <description><![CDATA[正如Jackson等人在堆栈[1]上其他地方建立的。 （2012）[2]和Nakagawa＆amp; Santos等。 (2012) methods are viable methods for calculating $I^2$-like heterogeneity estimates in multivariate meta-analytical models in the &#39;metafor&#39; R package - even where the variances are specified with a &#39;vi&#39; term rather than a full variance-covariance matrix as in the website example [4].结果有时是完全不同的，但两者都是有效的。
 nakagawa＆amp; santos方法，在堆栈[5]上的另一篇文章中，可以计算总计 $ i^2 $ 或 $ i^2 $ 每个随机效果，如下所示：：
  dat＆lt;  -  dat.konstantopoulos2011

＃通过〜1 |外部/内部指定的随机效应
res1＆lt;  -  rma.mv（yi，vi， 
               随机=列表（〜年|学校，〜1 |研究），
               数据= DAT）
Res1
w＆lt;  -  diag（1/res1 $ vi）
x＆lt;  -  model.matrix（res1）
p＆lt;  -  w- w％*％x％*％solve（t（x）％*％w％*％x）％*％t（x）％*％w

＃i2（总数）
100 * sum（res1  $ tau2，res1 $  sigma2）/（sum（res1  $ tau2，res1 $  sigma2）

＃i2在学校一年
100 * res1  $ tau2/（sum（res1 $  tau2，res1  $ sigma2） +（res1 $  k-res1 $ p）/sum/sum（diag（p））

＃i2学习
100 * res1  $ sigma2/（sum（res1 $  tau2，res1  $ sigma2） +（res1 $  k-res1 $ p）/sum（diag（p））
 
但是，我不清楚如何对杰克逊方法做同等的方法。有人可以澄清是否可以做到这一点，如果是这样，请如何做？
 参考 

See discussion in the comments of the question here: Computing I2使用内部|随机效应的内部规范 

  Jackson，D.，White，I。R.，＆amp; Riley，R。D.（2012）。量化研究间异质性在多元荟萃分析中的影响。医学的统计数据，31（29），3805–3820。

 中川，S。，＆amp; Santos，E。S. A.（2012）。生物荟萃分析的方法论问题和进步。进化生态学，26（5），1253–1274。

   https://metafor-project.org/doku.php/tips:i2_multilevel_multivariate?s [] =杂种＃jackson_et_al_al_2012_applace   

  
]]></description>
      <guid>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the</guid>
      <pubDate>Tue, 25 Feb 2025 11:35:44 GMT</pubDate>
    </item>
    </channel>
</rss>