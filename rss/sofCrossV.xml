<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 29 Jul 2024 01:08:28 GMT</lastBuildDate>
    <item>
      <title>在没有对照组的小型研究中评估导师的效果</title>
      <link>https://stats.stackexchange.com/questions/651914/assessing-effect-of-tutor-in-a-small-study-without-a-control-group</link>
      <description><![CDATA[假设我有以下“实验”设置。

我正在教一个有 N 名学生的班级。所有学生都可以获得助教的帮助。
每个学生全年都会得到 K 份家庭作业。在每份家庭作业中，每个学生可能会或可能不会得到助教的帮助。
对于每个学生，我记录每份家庭作业的分数（例如，8/10，其中正确答案的数量不一定在家庭作业中保持不变）+ 一个二元变量，表示他们是否在每份家庭作业中得到了助教的帮助。
我有兴趣使用泊松或二项回归来了解在有/没有助教的情况下答对问题的概率，同时控制学生。

是否有任何统计模型可以用来估计助教的影响？这种整体设置是否适合我可以阅读更多内容的任何现有框架？

在这里，我无法访问对照组（即没有导师的另一个班级）。
此外，访问 TA 的选择是自愿的。根据我所读的内容，也许我需要做一个带有 IV 的两阶段模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651914/assessing-effect-of-tutor-in-a-small-study-without-a-control-group</guid>
      <pubDate>Sun, 28 Jul 2024 23:24:11 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 z 分数的总和和 z 分数的平均总和？</title>
      <link>https://stats.stackexchange.com/questions/651913/how-to-interpret-sum-of-z-scores-and-average-sum-of-z-scores</link>
      <description><![CDATA[假设我有来自 5 个子测试和 2 组参与者的数据。z 分数的总和（即将所有 5 个测量值转换为 z 分数并将它们相加）与平均总和（即将总和除以 5）的解释有什么区别？

例如，如果我想分析诸如 lm(scores ~ age + group) 之类的模型。“1 个单位变化”是什么意思？在每个上下文中预测变量的平均值（总和 x 平均总和）？ ？

一些虚拟数据：


library(tidyverse)
set.seed(123)

# 生成虚拟数据
n &lt;- 100 # 参与者人数
data &lt;- data.frame(
contestant_id = 1:n,
age = sample(18:30, n, replace = TRUE), # 参与者年龄
group = sample(c(&quot;male&quot;, &quot;female&quot;), n, replace = TRUE), # 组 
subtest1 = rnorm(n), subtest2 = rnorm(n), subtest3 = rnorm(n), subtest4 = rnorm(n), subtest5 = rnorm(n)
)

# 标准化子测试分数
data_z &lt;- data %&gt;%
mutate(across(starts_with(&quot;subtest&quot;), scale)) %&gt;% # 缩放（标准化）子测试分数
mutate(sum_z_scores = rowSums(select(.,starts_with(&quot;subtest&quot;))), # z 分数总和
avg_z_scores = rowMeans(select(., starts_with(&quot;subtest&quot;)))) # z 分数平均值

# 拟合线性模型
model_sum &lt;- lm(sum_z_scores ~ age + group, data = data_z)
model_avg &lt;- lm(avg_z_scores ~ age + group, data = data_z)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651913/how-to-interpret-sum-of-z-scores-and-average-sum-of-z-scores</guid>
      <pubDate>Sun, 28 Jul 2024 23:08:04 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟评估功效 - 敏感度</title>
      <link>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</link>
      <description><![CDATA[我正在开展一个项目，该项目比较了两个给出二元结果的不同测试，我们想根据它们的灵敏度来评估这些测试。毫不奇怪，需要多少样本才能达到一定程度的功效的问题出现了。幸运的是，它是先验出现的，因此这不是事后功效计算。
我知道有很多方法可以比较两个具有二元结果的测试的灵敏度 - Fisher 精确检验、McNemar 检验和比例检验。此外，我们对第一个测试的灵敏度进行了估计，约为 75%。为了计算不同样本量的功效，我编写了如下所示的 R 函数。
我尝试将我的结果与一些文献资料进行比较，但到目前为止我发现的所有资料都没有指定测试的一些细节，例如使用哪种特定测试，是否假设测试独立（两个测试是针对同一个人还是针对两组不同的人？），重要性水平等。
对于我的代码，我假设两个测试在不同的组上运行，并且我在代码中指定了所有其他假设。这看起来正确吗？如果不正确，我将不胜感激任何建议。如果两个测试在同一受试者上运行，我将如何进行模拟？我假设我需要考虑两个测试之间的预期相关性，但我不确定如何做到这一点。此外，我是否正确地认为可以进行相同的模拟来估计特异性比较的功效？
set.seed(303)

se1 &lt;- .75 # 测试 1 的灵敏度（或特异性）
se2 &lt;- .80 # 测试 2 的灵敏度（或特异性）

Nd &lt;- 60 # 每组的 dz 数量
Z &lt;- 10000 # 试验次数
alpha = 0.05 # 目标显着性水平

powercalc(se1, se2, Nd, Z, alpha, &#39;fisher&#39;)

#####
powercalc &lt;- function(se1, se2, Nd, Z, alpha, test = c(&#39;fisher&#39;, &#39;mcnemar&#39;, &#39;proportion&#39;)){
p_vals &lt;- sapply(1:Z, function(z) {
s1_pos &lt;- rbinom(1, Nd, se1) # 用二项式抽样可能的测试结果
s1_neg &lt;- Nd - s1_pos
s2_pos &lt;- rbinom(1, Nd, se2)
s2_neg &lt;- Nd - s2_pos

# 创建一个矩阵，行对应于两个测试
# 列对应于这些测试的结果
# 这些是具有敏感性条件的受试者的结果
# 或不具有特异性条件的受试者的结果
m &lt;- matrix(c(s1_pos, s1_neg,
s2_pos, s2_neg),
nrow = 2, byrow = TRUE)

if(test == &#39;fisher&#39;)
fisher.test(m)$p.value
else if(test == &#39;mcnemar&#39;)
mcnemar.test(m)$p.value
else if(test == &#39;proportion&#39;)
prop.test(c(s1_pos, s2_pos), c(Nd, Nd))$p.value
})

# 计算我们看到极端排列的次数

# 对于双侧测试
lte_alpha = mean(p_vals &lt;= alpha / 2)
gte_alpha = mean(p_vals &gt;= 1 - (alpha /2))
power_2sided = lte_alpha + gte_alpha
beta_2sided = 1 - power_2sided

# 对于单侧，假设测试二具有更高的敏感度
beta_1sided = mean(p_vals &gt;= alpha)
power_1sided = 1 - beta_1sided

c(one_sided = power_1sided, two_sided = power_2sided)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</guid>
      <pubDate>Sun, 28 Jul 2024 23:03:29 GMT</pubDate>
    </item>
    <item>
      <title>rpart() 决策树无法生成分割（只有一个节点（根节点）的决策树）</title>
      <link>https://stats.stackexchange.com/questions/651910/rpart-decision-tree-fails-to-generate-splits-decision-tree-with-only-one-node</link>
      <description><![CDATA[我正在尝试创建决策树来预测特定贷款申请人是否会违约或偿还债务。
我正在使用以下数据集

library(readr)
library(dplyr)
library(rpart)
library(rpart.plot)

贷款 &lt;- read_csv(&#39;https://assets.datacamp.com/production/repositories/718/datasets/7805fceacfb205470c0e8800d4ffc37c6944b30c/loans.csv&#39;)

由于响应变量 default 被编码为 dbl，我首先将其转换为 chr，然后将其转换为 fct 类型变量以在我的分类中使用它模型。
loans &lt;- loans %&gt;% mutate(default = factor(as.character(default), levels = c(0, 1), labels = c(&#39;repaid&#39;, &#39;defaulted&#39;)))

现在，我开始构建递归分区 (rpart()) 对象 loans_model：响应变量为 default，解释变量为 loan_amount + credit_score + deal_to_income。
loans_model &lt;- rpart(default ~ loan_amount + credit_score + deal_to_income, data = loans, method = &#39;class&#39;)

当我使用此模型进行预测时，所有预测值都得到相同的值，即 repaid。
loans$pred_default &lt;- predict(loans_model, newdata = loans, type = &quot;class&quot;)

unique(loans$pred_default)


输出：
[1] 已偿还
级别：已偿还 已违约

此外，当我尝试可视化决策树时，我只得到一个节点（根节点）。
rpart.plot(loan_model)

输出：

您能帮我理解为什么我构建的模型没有做出适当的预测吗？
编辑：拼写错误并添加了 as.character()]]></description>
      <guid>https://stats.stackexchange.com/questions/651910/rpart-decision-tree-fails-to-generate-splits-decision-tree-with-only-one-node</guid>
      <pubDate>Sun, 28 Jul 2024 22:55:36 GMT</pubDate>
    </item>
    <item>
      <title>特定事后统计谬误的名称</title>
      <link>https://stats.stackexchange.com/questions/651907/name-of-a-particular-post-hoc-statistical-fallacy</link>
      <description><![CDATA[统计/逻辑上有一个令人惊讶的常见现象，即有人从大量随机样本中挑选出具有某些特殊属性的元素，并根据这些属性将其归因于独特的起源。
一个著名的例子是“火星上的脸”，在海盗 1 号航天器拍摄的火星上许多随机山丘和地质构造中，有一个看起来像人脸。清醒的科学家不得不向容易上当的普通公众解释，这种结构不是某种外星人的艺术品，而是在足够大的随机数据集中必然会出现“类似脸”的东西。
其他常见的例子包括，当基督的形象出现在烤得不均匀的面包中时，一些天真的人将其归因于宗教符号……“来自天堂”。
作为上下文：数学家约翰·纳什研究了如何计算随机点的特定配置（比如）将包含特定的空间模式（例如，正方形或茶壶的轮廓）。假设我们在某张深空天文照片中发现星星或星系与麦当劳餐厅双拱形标志的图案相似。我们会得出结论说宇宙中有什么东西故意放置了这个公司标志吗？当然不会……只要有足够多的随机星星，我们一定会找到一些落入双拱形图案的星星。
相信麦当劳标志是“故意设计并放置在天空中”是一种谬论。
这就是我需要指出的谬论。]]></description>
      <guid>https://stats.stackexchange.com/questions/651907/name-of-a-particular-post-hoc-statistical-fallacy</guid>
      <pubDate>Sun, 28 Jul 2024 21:47:06 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 中截距系数的解释</title>
      <link>https://stats.stackexchange.com/questions/651905/interpretation-of-the-intercept-coefficient-in-glmms</link>
      <description><![CDATA[假设我有一个包含三个变量的数据集；响应、性别和面积，其中响应是二进制的。如果我运行 glm 模型；
 glm(reponse ~ gender, family = ‘binomial’)

截距是参考类别的平均响应，假设男性是参考类别，如果我在数据集中过滤男性并找到经验平均值，那么它将与模型的截距匹配。但是，如果我运行混合效应模型；
 glmer(reponse ~ gender + 1|area, family = ‘binomial’)

截距与经验平均值不匹配。为什么会发生这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651905/interpretation-of-the-intercept-coefficient-in-glmms</guid>
      <pubDate>Sun, 28 Jul 2024 21:19:31 GMT</pubDate>
    </item>
    <item>
      <title>概率分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</link>
      <description><![CDATA[我试图理解概率分布之间的三种距离之间的差异，例如它们的优点和缺点是什么，它们强调什么和不强调什么，本质上从实际的角度来看：何时使用这一个而不是另一个，它很容易用数字计算/估计，等等。在这里我只对绝对连续的一维概率分布感兴趣。给定两个这样的概率分布 $P$ 和 $Q$，我感兴趣的三个距离是：

总变异距离 (TVD)：
$$
\mathsf{TVD}(P,Q)=\int_\mathbb{R}\big|p(x)-q(x)\big|\,\mathrm{d}x,
$$
其中 $p$ 是与 $P$ 相关的概率密度函数 (PDF)，而 $q$ 是与 $Q$ 相关的概率密度函数。
 Wasserstein-1 距离：
$$
\mathsf{W}_1(P,Q)=\int_0^1\big|F^{-1}(q)-G^{-1}(q)\big|\,\mathrm{d}q=\int_\mathbb{R}\big|F(x)-G(x)\big|\,\mathrm{d}x,
$$
其中 $F$ 是与 $P$ 相关的累积概率函数 (CDF)，而 $G$ 是与 $Q$ 相关的累积概率函数。
最大均值差 (MMD) 距离，其函数类被视为希尔伯特空间$\mathcal{H}$的单位球:
$$
\textsf{MMD}_\varphi(P,Q)=\big\|\mathbb{E}_{X\sim P}[\varphi(X)]-\mathbb{E}_{Y\sim Q}[\varphi(Y)]\big\|_\mathcal{H},
$$
其中$\varphi:\mathbb{R}\to\mathcal{H}$。在这篇文章中，我主要感兴趣的是 $\varphi$ 与高斯核的关系：
$$
\big\langle\varphi(x),\varphi(y)\big\rangle_\mathcal{H}=k(x,y)=\exp\left(-\frac{1}{2\sigma^2}|x-y|^2\right).
$$

我感兴趣的是这些距离之间的差异。例如，在我看来：

$\mathsf{W}_1$ 比较分位数或质量分配在分布中的差异（注意：我知道 $\mathsf{W}_1$ 的最佳传输解释），而 $\mathsf{TVD}$ 比较质量，但在“原子级”可以这么说，因为它涉及 PDF，所以它会“更紧密”，
上面的 $\textsf{MMD}_\varphi$ 的特定实例将比较两个分布之间的所有矩，如果我们从离散度、偏度和峰度的角度考虑，那么就会强调“几何形状”分布。
在数值方面，假设$P$和$Q$未知，如果我得到$P$和$Q$的样本，那么对于$\mathsf{TVD}$，我必须估计PDF并近似积分。对于$\mathsf{W}_1$也是如此：需要估计CDF并近似积分。但是，对于$\textsf{MMD}_\varphi$，使用核技巧很容易获得“插件”距离的估计量。

在统计/数据科学/机器学习中，哪些用例会使用一种距离而不是其他距离，为什么？有人有简单的例子可以解释这三种距离之间的差异吗？谢谢帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</guid>
      <pubDate>Sat, 27 Jul 2024 06:57:39 GMT</pubDate>
    </item>
    <item>
      <title>比较非嵌套混合效应模型之间的估计值</title>
      <link>https://stats.stackexchange.com/questions/651826/compare-estimates-between-non-nested-mixed-effects-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651826/compare-estimates-between-non-nested-mixed-effects-models</guid>
      <pubDate>Fri, 26 Jul 2024 18:27:10 GMT</pubDate>
    </item>
    <item>
      <title>这里应该使用哪种测试？“A/B 测试”</title>
      <link>https://stats.stackexchange.com/questions/651800/which-is-the-proper-test-to-use-here-a-b-testing</link>
      <description><![CDATA[新手问题：哪种测试更合适？
我们有两种算法，一种是旧算法，一种是新算法。使用测试数据，算法会生成输出，然后（目前）有 3 位评分员对哪种输出更好进行评分。评分范围从 1 到 5。
因此，我有成对的数据，算法 A 有 3 个评分，算法 B 有 3 个评分。
现在，确定一种算法优于另一种算法的合适方法是什么？取评分的平均值？将它们相加？然后，我应该使用哪种特定的显著性测试？
更新：
有 20 个测试样本，所以总共有 40 个评分]]></description>
      <guid>https://stats.stackexchange.com/questions/651800/which-is-the-proper-test-to-use-here-a-b-testing</guid>
      <pubDate>Fri, 26 Jul 2024 10:40:38 GMT</pubDate>
    </item>
    <item>
      <title>回归和独立随机向量</title>
      <link>https://stats.stackexchange.com/questions/651795/regression-and-independent-random-vectors</link>
      <description><![CDATA[假设数据样本由横截面数据的随机向量 $(X_1, Y_1)...(X_N, Y_N)$ 生成。对于回归，通常假设误差分布为 I.I.D。正态分布，数据的似然性纯粹由条件分布定义（忽略$X_i$的边际分布）：
$$
L(D) = p_{Y|X}(x_1,y_1)p_{Y|X}(x_2,y_2)...p_{Y|X}(x_N,y_N)
$$
其中$p_{Y|X}$是条件分布的概率函数。
这让我得出以下结论：

条件 p.d.f.每个随机向量的$p_{Y|X}(x_i,y_i)$彼此独立。这只有在随机向量 $(X_1, Y_1)...(X_N, Y_N)$ 也是独立的，因为任何独立随机向量的函数也是独立的。

$p_{Y|X}$ - 是一个固定函数，用于对数据样本的条件分布进行建模。

回归不对 DGP 每个随机向量内随机变量的联合分布做出任何假设，每个随机向量可以具有不同的联合分布，即 - $p_{X_1,Y_1} ,p_{X_2,Y_2}...p_{X_N,Y_N}$ 唯一的假设是它们彼此独立。


这些有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651795/regression-and-independent-random-vectors</guid>
      <pubDate>Fri, 26 Jul 2024 08:56:07 GMT</pubDate>
    </item>
    <item>
      <title>1 vs 2 源检测似然比检验的零分布</title>
      <link>https://stats.stackexchange.com/questions/651640/null-distribution-for-1-vs-2-source-detection-likelihood-ratio-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651640/null-distribution-for-1-vs-2-source-detection-likelihood-ratio-test</guid>
      <pubDate>Tue, 23 Jul 2024 23:59:41 GMT</pubDate>
    </item>
    <item>
      <title>具有多个时间段的 Diff-in-Diff</title>
      <link>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</link>
      <description><![CDATA[这是我在这里的第一篇帖子，我还是个新手，希望这篇文章能说清楚。
背景：
对于我的硕士论文，我想估计重复对论文引用的影响。为此，我想比较曾经重复过的论文和没有重复过的论文的引用。
我的导师告诉我，考虑到我的因变量的性质（引用是一个非负计数数字），更合适的模型是交错式差异分析，并采用泊松回归。但是，他告诉我尝试初始的“简单”差异分析来查看结果，即使结果可能有偏差。
在我的数据集中，我有大约 80 篇在不同时间点重复的论文（因此是我的治疗组），以及 160 篇从未重复的论文（对照组）。为了确保可比性，我只选取在同一期刊、卷、期上发表、涉及相同主题或 JEL 代码的实证论文。以下是一个片段：

因此，如果我们查看一个简单的 DiD 方程，并将其应用于我的数据，这就是我想要估计的：

其中，replicated 是治疗虚拟变量（如果已复制则为 1，如果从未复制则为 0），d_time 是时间虚拟变量（before=0 并且after=1)。
我在这里看到的问题是，我的对照组没有“之后”，因为这些论文从未被复制过，而且我无法获取单个处理过的论文的“之后”，因为所有论文的处理年份都不同（有些重复，但一般是 15 年）。因此，我的时间虚拟变量的构造使我的对照组的 d_time 始终为 0（replicated=0），
如果我运行这样的模型，由于交互项和 d_time 之间存在完全共线性，因此我的交互项会被省略。我在这里遗漏了什么？
现在，我知道这是“基本” DiD 模型，由于我的数据的性质，这可能会导致一些规范问题。但我想在尝试任何其他更高级的方法之前实现它。有人有什么建议吗？
（我试图理解 Callaway 和 Sant&#39;Ana 关于交错方法的论文，但我无法理解该模型的实施和解释。因为据我所知，如果在另一篇论文之后进行处理，每篇经过处理的论文都可以作为对照论文（例如：2015 年的重复论文可以作为 2010 年重复论文的对照论文，依此类推）。但是，我只想比较从未重复的论文和重复的论文，因此我不确定这是否是最好的方法）]]></description>
      <guid>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</guid>
      <pubDate>Sun, 21 Jul 2024 11:49:31 GMT</pubDate>
    </item>
    <item>
      <title>Ornstein–Uhlenbeck 过程最小值的 MLE</title>
      <link>https://stats.stackexchange.com/questions/651345/mle-for-a-minimum-of-ornstein-uhlenbeck-process</link>
      <description><![CDATA[使用 MLE 来估计一维 Ornstein–Uhlenbeck 过程的参数是众所周知的。但是，是否已经对以下形式的过程进行了类似的研究
\begin{equation}
X_t = \min \left( \int_0^t \theta (X_t - \mu) \, dt + \int_0^t \sigma \, dB_t , \alpha\right) \text{?}
\end{equation&gt;
这是在上限均值反转过程的背景下。即，给定该过程的数据，MLE 是什么样子来估计参数$\Theta = (\theta, \mu, \sigma)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/651345/mle-for-a-minimum-of-ornstein-uhlenbeck-process</guid>
      <pubDate>Thu, 18 Jul 2024 14:38:01 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系还成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    <item>
      <title>条件似然、条件独立和联合独立</title>
      <link>https://stats.stackexchange.com/questions/644953/conditional-likelihood-conditional-independence-and-joint-independence</link>
      <description><![CDATA[考虑由 $n$ 个独立随机向量生成的一系列数据样本 $(X_1, Y_1), (X_2,Y_2), (X_3,Y_3) ...$
$$D = (x_1,y_1), (x_2,y_2), (x_3,y_3) ...$$
其中 $(X_i, Y_i)$ - 是随机向量，$X_i$、$Y_i$ 是缩放器或向量值随机向量，并且 $X_i$、$Y_i$ 是缩放器或向量值随机向量，并且 $(x_i,y_i)$ 是这些数据样本。
似然函数可以定义如下：
$$
L(D;\theta) = \prod_{i=1}^n p_i(x_i, y_i;\theta) \tag{1}
$$
$p_i$ - 第 $i$ 个随机向量的概率分布函数。
我们可以取概​​率的乘积，因为这些随机向量是独立的。
$(1)$ 也可以表述为：
$$
L(D;\theta) = \prod_{i=1}^n p_i(y_i | x_i;\theta) p_i(x_i;\theta) \tag{2}
$$
假设数据是独立生成的，条件概率也可以表示为：
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \frac{P(x_1, x_2 ... x_n, y_1, y_2 ... y_n)}{P(x_1, x_2 ... x_n)} \tag{3}
$$
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \frac{\prod_{i=1}^n p_i(x_i, y_i)}{\prod_{i=1}^n p_i(x_i)} \tag{4}
$$
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \prod_{i=1}^n p_i(y_i | x_i) \tag{5}
$$
由于数据生成过程的独立性，等式 $(3)$ 变为 $(4)$。
基于上述内容：
是否可以说，如果随机向量是独立的，即
$$(X_i,Y_i) \mathrel{\unicode{x2AEB}} (X_j,Y_j), \forall j \neq i $$
那么数据样本的条件分布$$(Y_i | X_i) \mathrel{\unicode{x2AEB}} (Y_j | X_j), \forall j \neq i $$ ?
NB我只做独立性假设，随机向量序列可能有不同的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/644953/conditional-likelihood-conditional-independence-and-joint-independence</guid>
      <pubDate>Sat, 13 Apr 2024 20:08:21 GMT</pubDate>
    </item>
    </channel>
</rss>