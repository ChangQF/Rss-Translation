<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 10 Oct 2024 06:24:15 GMT</lastBuildDate>
    <item>
      <title>方差总是等于二阶导数的倒数吗？</title>
      <link>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</link>
      <description><![CDATA[这是基于 Fisher 评分法（本质上是 Newton-Raphson 优化算法的统计版本）估计模型参数的著名公式：
$$\theta^{(k+1)} = \theta^{(k)} + [I(\theta^{(k)})]^{-1}U(\theta^{(k)})$$
其中：

$\theta^{(k)}$ 是迭代时的估计值 $k$
$U(\theta)$ 是得分函数（对数似然的一阶导数）
$I(\theta)$ 是 Fisher 信息矩阵（基于 Hessian，即二阶导数）

我认为 Fisher 评分的真正酷之处在于它同时估计参数的方差：
$$E[-\nabla^2 \log L(\theta)] = I(\theta)$$
$$\text{Var}(\hat{\theta}) \approx I^{-1}(\hat{\theta})$$
在之前的问题中（例如如何防止似然优化中的负方差估计？），我了解到许多软件实现实际上并没有使用这种精确的 Fisher 评分方法，因为执行使用 Fisher 评分方法所需的矩阵微积分可能非常复杂。而是使用拟牛顿方法，例如 BFGS 算法。
BFGS 算法（具有与 Fisher 评分非常相似的结构）按如下方式更新 $\theta$ 的估计值：
$$\theta^{(k+1)} = \theta^{(k)} - \alpha^{(k)} H^{(k)} \nabla L(\theta^{(k)})$$
其中：

$\alpha^{(k)}$ 是由线搜索确定的步长
$H^{(k)}$ 是逆 Hessian 的近似值矩阵
$\nabla L(\theta^{(k)})$ 是对数似然的梯度
梯度$\nabla L(\theta)$与 Fisher 评分中的得分函数$U(\theta)$相同。

所有这些都让我感到疑惑。假设 BFGS 中产生的最终 Hessian（即收敛时）表示为 $H_{final}$。
这样说公平吗？
$$H_{final} \xrightarrow{p} [-\nabla^2 \log L(\theta)]^{-1}$$
$$\text{Var}(\hat{\theta}) \approx H_{final}$$
最终呢？
$$\text{Var}(\hat{\theta}) \approx \begin{cases}
I^{-1}(\hat{\theta}) &amp; \text{for Fisher Scoring} \\
H_{final} &amp; \text{for BFGS}
\end{cases}$$
因此，BFGS 算法似乎也估计了参数估计的方差（就像 Fisher Scoring 一样）。
如果这是真的（即 BFGS 通过避免 Fisher Scoring 所需的矩阵微积分节省了时间，并且 BFGS 仍然提供方差估计），那么为什么 Fisher Scoring 在应用中会使用呢？在我看来，Fisher Scoring 只有在一些非常具体的建模情况下才会真正具有优势（例如指数族、GLM），在这些情况下，我们已经事先知道填充得分函数和预期的 hessian 所需的精确矩阵微积分？或者也许从优化的角度来看，Fisher Scoring 更稳定，与 BFGS 相比，它不太可能陷入困境？]]></description>
      <guid>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</guid>
      <pubDate>Thu, 10 Oct 2024 04:26:36 GMT</pubDate>
    </item>
    <item>
      <title>如何建立 Piegorsch、Weinberg 和 Margolin（1988）中剂量反应关系的二项回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655582/how-to-formulate-a-binomial-regression-model-for-the-dose-response-relationship</link>
      <description><![CDATA[我正在尝试将逻辑回归模型应用于二项式比例数据。具体来说，我正在研究 $Biometrics$ 论文“探索多因素比例表中的简单独立作用”，作者是 Piegorsch、Weinberg 和 Margolin (1988)。
以下是论文中的数据，关于暴露于两种药剂 TNF 和 IFN 后分化的细胞数量。在两种药剂的 16 种组合中，每种组合都暴露了 200 个细胞。

我正在尝试根据暴露于 TNF 和 IFN 来模拟反应的分布。
在论文中，我看到作者将解释变量 TNF 和 IFN 建模为因子，每个因子包含 4 个级别。
但是，我正在尝试使用基于 TNF 和 IFN 剂量的连续解释变量。我尝试使用平方根、对数和正弦函数转换解释变量，并尝试了 logit 和 cloglog 链接。
残差图似乎没有表明模型拟合度足够。
除其他外，我尝试的模型如下：
$$
\log\left( \frac{\pi_i}{1 - \pi_i} \right) = \beta_0 + \beta_1 \text{TNF}_i + \beta_2 \text{IFN}_i + \beta_3 \log(\text{TNF}_i + 1) + \beta_4 \log(\text{IFN}_i + 1)
$$
我的偏差残差图如下所示：

使用 cloglog 链接，我有：
$$
\log\left( -\log(1 - \pi_i) \right) = \beta_0 + \beta_1 \text{TNF}_i + \beta_2 \text{IFN}_i + \beta_3 \log(\text{TNF}_i + 1) + \beta_4 \log(\text{IFN}_i + 1)
$$
以下是我对 cloglog 的偏差残差链接：

除了对数转换，我还尝试了 TNF 和 IFN 的平方根以及 TNF 和 IFN 的正弦。
我这里遗漏了什么吗？或者我可以做些不同的事情？如果您能分享有关在此处建模剂量反应关系的任何建议或意见，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655582/how-to-formulate-a-binomial-regression-model-for-the-dose-response-relationship</guid>
      <pubDate>Thu, 10 Oct 2024 03:39:28 GMT</pubDate>
    </item>
    <item>
      <title>估计量乘积的集中不等式</title>
      <link>https://stats.stackexchange.com/questions/655581/the-concentration-inequality-of-the-product-of-the-estimators</link>
      <description><![CDATA[当我尝试获取 $\|\hat{\Omega}\hat{\Sigma}-\Omega\Sigma\|_2$ 的收敛速度时，我发现我必须面对项 $\|\Omega-\hat{\Omega}\|_2\|\Sigma-\hat{\Sigma}\|_2$，它是浓度不等式的乘积。那是因为
$$
\|\hat{\Omega}\hat{\Sigma}-\Omega\Sigma\|_2 \le \|\Omega-\hat{\Omega}\|_2\|\Sigma-\hat{\Sigma}\|_2+\|\Omega-\hat{\Omega}\|_2\|\Sigma\|_2+\|\Sigma-\hat{\Sigma}\|_2\|\Omega\|_2。
$$
我可以分别得到$\|\Omega-\hat{\Omega}\|_2 \le C_1\sqrt{\frac{p}{n}}$和$\|\Sigma-\hat{\Sigma}\|_2\le C_2\sqrt{\frac{p}{n}}$的收敛速度，但是两个估计量的乘积让我感到困惑。$\sqrt{\frac{p}{n}}$和$\frac{p}{n}$会同时出现在最终结果中。但这在论文中似乎很少见。这是正确的吗？我猜测最终的收敛速度中可能只有$\sqrt{\frac{p}{n}}$会出现，因为$\frac{p}{n}$可以被$\sqrt{\frac{p}{n}}$所限制。]]></description>
      <guid>https://stats.stackexchange.com/questions/655581/the-concentration-inequality-of-the-product-of-the-estimators</guid>
      <pubDate>Thu, 10 Oct 2024 03:34:47 GMT</pubDate>
    </item>
    <item>
      <title>概率/标准正态分布作业帮助</title>
      <link>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</link>
      <description><![CDATA[我在家庭作业中被这个问题难住了，想知道是否有人可以提供一些关于如何解决这个问题的建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</guid>
      <pubDate>Thu, 10 Oct 2024 01:56:25 GMT</pubDate>
    </item>
    <item>
      <title>二进制数据特征的缩放</title>
      <link>https://stats.stackexchange.com/questions/655575/scaling-for-binary-data-features</link>
      <description><![CDATA[我的目标是对两名选手之间的体育比赛进行二元分类，特别是我关心每位选手获胜的概率。
我当前的数据框具有 [来自选手 A 的属性，来自选手 B 的属性] 的特征值。但是，当我在此特征行上应用缩放时，会出现问题 - 在这种情况下，当我交换特征值的顺序 [来自玩家 B 的属性，来自玩家 A 的属性] 时，缩放是不对称的。
例如：

feature_set_1：[人 A 的身高，人 A 的国家，人 A 的体重，人 B 的身高，人 B 的国家，人 B 的体重，比赛结果]
feature_set_2：[人 B 的身高，人 B 的国家，人 B 的体重，人 A 的身高，人 A 的国家，人 A 的体重，比赛结果]

由于缩放时顺序的重要性，feature_set_1 中人 A 身高的缩放结果将不等于 feature_set_2 中的缩放结果。
这导致在预测概率时出现问题，因为我得到的结果为概率（A 击败 B）+概率（B 击败 A）&gt;1，幅度相当大。此外，相对于这种情况，我们提供属性的顺序（玩家 A 先于玩家 B，或玩家 B 先于 A）应该没有实际影响。
在实践中，这种情况通常是如何解决的？
我想到的一个解决方案是实施特征工程，其中我将特征值改为 [来自玩家 A 的属性 - 来自玩家 B 的属性]。但是，当反转 A 和 B 的顺序时，这会导致负面结果。我不确定这会如何影响概率预测，更重要的是，它是否会保持玩家 A 和玩家 B 获胜（概率总和为 1）之间的互斥性。请注意，我使用的分类器需要缩放（MLP）]]></description>
      <guid>https://stats.stackexchange.com/questions/655575/scaling-for-binary-data-features</guid>
      <pubDate>Thu, 10 Oct 2024 00:22:26 GMT</pubDate>
    </item>
    <item>
      <title>(MacKay) 如何以易于处理的方式在线优化正则化常数？</title>
      <link>https://stats.stackexchange.com/questions/655574/mackay-how-can-regularization-constants-can-be-optimized-on-line-in-a-tractabl</link>
      <description><![CDATA[根据 MacKay 在其著作《信息理论、推理和学习算法》第 44 章“多层网络中的监督学习”（第 531 页）中的说法，他声称贝叶斯优化模型控制参数（尤其是神经网络，例如权重衰减常数）的优势如下：

“正则化常数可以在线优化，即
与普通模型参数的优化同时进行……可以评估证据相对于控制参数的梯度，从而可以同时
优化大量控制参数。”

但是，我看不出如何以易于处理的方式优化控制参数。例如，假设我们正在处理具有权重衰减惩罚的前馈神经网络。令 $\mathcal{D}$ 为数据，$\mathcal{H}_\lambda$ 为假设，即模型权重的先验是具有常数方差 $\lambda^2$ 的多元高斯分布（此处，$\lambda$ 是 MacKay 所说的“控制参数/正则化常数”）。然后通过贝叶斯论证，我们必须选择$\lambda$使得
$$
\begin{align*}
\lambda^* &amp;= \arg \max_{\lambda} \mathbb{P}[\mathcal{D} | \mathcal{H}_{\lambda}] \\
&amp;= \arg \max_\lambda \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \mathbb{P}[w|\mathcal{H}_\lambda] dw
\end{align*}
$$
其中 $w\in \mathbb{R}^{d_w}$ 是我们的神经网络中 $d_w$ 权重的向量。
如果我正确理解了 MacKay 的意思，他似乎在说，相对于 $\lambda$ 的积分梯度可以轻松计算，但我不明白为什么会这样。如果我理解正确的话，如果$E(\lambda) = \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \mathbb{P}[w|\mathcal{H}_\lambda] dw$，那么
$$
\begin{align*}
\frac{d}{d\lambda} E(\lambda) &amp;= \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \frac{d}{d\lambda} \mathbb{P}[w|\mathcal{H}_\lambda] dw \\ 
\end{align*}
$$
虽然积分中的梯度很容易计算，但积分本身感觉很难计算。
鉴于此 - 当 MacKay 写“可以评估证据相对于控制参数的梯度”时他的意思是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655574/mackay-how-can-regularization-constants-can-be-optimized-on-line-in-a-tractabl</guid>
      <pubDate>Wed, 09 Oct 2024 22:40:48 GMT</pubDate>
    </item>
    <item>
      <title>比较不同重叠组中两个变量的相关性</title>
      <link>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</link>
      <description><![CDATA[我有一个样本，其中我为同一种疾病应用了五种（差异很大）诊断定义。例如，50% 的诊断定义 1 下的患病病例不是诊断定义 2 下的患病病例，而 10% 的符合定义 2 的病例不是定义 1 下的病例。定义 1 是目前使用最广泛的“标准”，所有其他定义都将与定义 1 进行比较。
我想比较针对每个人测量的两个变量之间的相关性（称为 X 和 Y），看看定义 1 下的患病病例的 cor(X,Y) 是否与定义 2 下的患病病例的 cor(X,Y) 不同（请记住，有些人同时符合两个定义，并将同时属于两个组）。我想要用几对变量来做这个 - 根据具体变量，我可能会使用 Pearson、Spearman 或四分法相关系数。
将样本限制为“符合五个诊断定义中至少一个的人”后我的样本量约为 80,000，所有诊断定义至少产生 30,000 个病例。
我首先想到的方法是使用引导法：

使用“至少符合一个诊断定义的 80,000 人”的整个样本进行替换抽样。
对于五个诊断定义中的每一个，使用符合该定义的引导样本中的观测值计算 cor(X,Y)。
对得到的相关性使用 Fisher 变换，这样减法就合适了。
对于诊断定义 2-5 中的每一个，从定义 1 病例的相关性中减去该组的相关性。 （使用当前引导迭代中的 Fisher 变换相关性。）
重复步骤 1-4 数千次。
取 min(差异百分比 &gt; 0,差异百分比 &lt; 0)，并将该数字乘以 2，得到双尾检验，以确定相关性之间的差异是否不等于 0。

此过程合适吗？它会做我想做的事情吗（测试相关性的差异，同时考虑产生相关性的两个组之间的重叠）？我是否应该考虑使用其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</guid>
      <pubDate>Wed, 09 Oct 2024 22:02:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在等相关随机向量 MLE 中得到结果 3.56-3,58</title>
      <link>https://stats.stackexchange.com/questions/655572/how-can-we-get-the-result-3-56-3-58-in-the-equal-correlation-random-vector-mle</link>
      <description><![CDATA[
正如问题所发布的那样，我们如何在等相关随机向量 MLE 中得到结果 3.56-3,58]]></description>
      <guid>https://stats.stackexchange.com/questions/655572/how-can-we-get-the-result-3-56-3-58-in-the-equal-correlation-random-vector-mle</guid>
      <pubDate>Wed, 09 Oct 2024 21:59:29 GMT</pubDate>
    </item>
    <item>
      <title>多时间序列的超参数调整</title>
      <link>https://stats.stackexchange.com/questions/655571/hyperparameter-tuning-for-multiple-time-series</link>
      <description><![CDATA[我正在利用 NeuralProphet 开发一个时间序列模型，用于预测每日产品需求。我已根据平均需求、需求标准差和时间序列长度等特征将产品分组为多个集群。
我认为解决此问题的最佳方法是使用全局局部建模为每个集群创建一个模型，并使用该模型为每种产品生成单独的预测。但是，我正在努力弄清楚如何正确调整全局局部模型的超参数。我的目标是创建一个在各个集群中的所有产品上都具有可接受准确度的模型，但我不确定如何在不对每个项目进行试验的情况下做到这一点。
我已经测试使用贝叶斯优化在单个时间序列模型的上下文中调整超参数，并获得了很好的结果，但在多个时间序列模型的情况下，对每个单独的产品进行数十次试验将非常耗时。我曾考虑过从每个集群中抽取样本，但那么我该如何选择样本呢？即使我有集群中每种产品的最佳超参数列表，我如何将它们缩小到整个集群的单个集合？
我将非常感激有关如何解决这个问题的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/655571/hyperparameter-tuning-for-multiple-time-series</guid>
      <pubDate>Wed, 09 Oct 2024 21:26:02 GMT</pubDate>
    </item>
    <item>
      <title>Neal 算法 1 是如何推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</link>
      <description><![CDATA[我正在阅读 Neal 的狄利克雷过程混合模型的马尔可夫链抽样方法。我无法理解方程 3.2、3.3 和 3.4 是如何推导出来的。它们直观上是有意义的，但我很难想出一个正式的推导，特别是方程 3.4。
摘自论文：

这是我所得到的（不正确？）
$$\begin{align*}
p(\theta_i|\theta_{-i}, y_i)&amp;\propto p(\theta_i, \theta_{-i}, y_i)\\
&amp;=p(y_i|\theta_i, \theta_{-i})p(\theta_i|\theta_{-i})p(\theta_{-i})\\
&amp;=p(y_i|\theta_i)p(\theta_i|\theta_{-i})p(\theta_{-i}) \quad\text{since}\;{y_i\perp \theta_{-i}|\theta_i}\\
&amp;\propto p(y_i|\theta_i)p(\theta_i|\theta_{-i})
\end{align*}$$
我不确定积分从何而来。]]></description>
      <guid>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</guid>
      <pubDate>Wed, 09 Oct 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>在风险函数的定义中，$\leq$ 应该放在哪里？</title>
      <link>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</link>
      <description><![CDATA[我在几本教科书和在线资源中都看到过两种风险函数定义。
定义 1。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t &lt; T \leq t + \epsilon \mid T &gt; t)}{\epsilon},$$
定义 2。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t \leq T &lt; t + \epsilon \mid T \geq t)}{\epsilon}.$$
我推测如果 $T$ 是绝对连续的，那么它们是等价的。但是，是否存在它们不同的情况？如果有，哪一个是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</guid>
      <pubDate>Wed, 09 Oct 2024 18:40:31 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解具有多个随机变量的条件概率分布</title>
      <link>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</link>
      <description><![CDATA[我试图理解我正在阅读的一些机器学习讲义中介绍的以下步骤。在这种情况下，我们想要用参数化函数类 $\mathcal{F}(\Theta)$ 中的函数来近似函数 $f^*: \mathcal{X} \to \mathcal{Y}$，其中该类中的每个函数都依赖于一些参数 $\theta \in \Theta$。我们给出了输入 $x_{1:n}$ 和标签 $y_{1:n}$，其中我们使用符号 $x_{1:n} = (x_1, \ldots, x_n)^T$。我们假设标签是独立同分布的，并且 $y_i \sim p( \cdot | x_i, \theta)$ 成立。此外，我们假设参数 $\theta$ 具有先验分布 $p(\theta)$。我们现在希望通过对 $\theta$ 进行条件设定，预测新输入 $x^*$ 时的输出 $y^*$：
$$p(y^* | x^*, x_{1:n}, y_{1:n}) = \int_{\Theta}p(y^*, \theta | x^*, x_{1:n}, y_{1:n}) d\theta = \int_{\Theta}p(y^* | x^*, \theta) \cdot p(\theta | x_{1:n}, y_{1:n})d\theta,$$
根据讲义，第一个等式如下来自求和规则，其表述为
$$p(x_{1:i - 1}, x_{i + 1:n}) = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}) dx_i,$$
第二个等式来自 $y^* \perp x_{1:n}, y_{1:n} | \theta$ 和乘积规则，其表述为
$$p(x_{1:n}) = p(x_1) \prod_{i = 2}^np(x_i | x_{1: i-1}).$$
我认为我理解第一个等式，因为根据条件概率分布的定义，我们有
$$p(x_{1:i-1}, x_{i+1:n} | y_{1:n}) = \frac{p(x_{1:i-1}, x_{i+1:n}, y_{1:n})}{p(y_{1:n})} = \frac{\int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}, y_{1:n}) dx_i}{p(y_{1:n})} = $$
$$ = \frac{\int_{X_i(\Omega)} p(y_{1:n})p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i}{p(y_{1:n})} = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i.$$
但是，我不明白第二个等式如何从 $y^* \perp 得出x_{1:n}, y_{1:n} | \theta$ 和所述乘积规则。
如能得到任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</guid>
      <pubDate>Wed, 09 Oct 2024 18:33:29 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的最大似然估计方法中存在普遍的不一致性</title>
      <link>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</link>
      <description><![CDATA[我发现，通过最大似然估计方法得出逻辑回归的损失函数的方式存在一些普遍的不一致之处。
在逻辑回归模型中，我们假设$\Pr[Y = +1| X = x] = \sigma(w^T x)$，其中$\sigma$是逻辑函数，$\sigma(w^T x) = \dfrac{\exp(w^T x)}{1 + \exp(w^T x)}$。类似地，$\Pr[Y = -1| X = x] = 1 - \sigma(w^T x).$
$X, Y$ 具有示例和标签的通常含义。
请注意，$w$ 是一个恒定权重参数（没有假设分布），我们希望对其进行调整。 查找 $w$ 的最常见方法是通过最大条件似然估计。
这就是文献中出现不一致的地方：一些作者假设 $w$ 是我们以此为条件的随机变量，其他作者假设 $w$ 是一个常数参数。
假设 $w$ 为常数的参考文献参数：
https://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote06.html
请注意，作者使用冒号符号来分隔随机变量和常数参数，即 $p(y|x; w)$
https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf
https://cseweb.ucsd.edu/~elkan/250B/logreg.pdf
https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf
假设 $w$ 为随机变量的参考文献：
https://www.cs.cmu.edu/~awm/15781/slides/LogRegress-9-29-05.pdf
请注意作者对 $w$ 的条件，即 $p(y|x, w)$
https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf
https://zstevenwu.com/courses/s20/csci5525/resources/slides/lecture05.pdf
https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote06.html
https://svivek.com/teaching/lectures/slides/logistic-regression/logistic-regression.pdf（作者使用两种符号可以互换使用）
本书：https://mml-book.github.io/
我的问题是：

哪种推导是正确的？$w$ 应该被视为常数参数还是随机变量？

只是为了消除一些困惑：

在最大似然估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？

也许 2 的后续问题是，在最大后验估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</guid>
      <pubDate>Wed, 09 Oct 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归：共线性或接近共线性的参数的部分效应解释</title>
      <link>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</link>
      <description><![CDATA[我正在看一个最简单的多元线性回归模型示例：
\begin{equation}\label{linreg}
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\end{equation&gt;
我对当 $X_1=X_2$（共线性）或 $\text{cor}(X_1, X_2)$ 非常高（可能是 $\text{cor}(X_1, X_2)&gt;0.999$）时获得的参数估计值（同时估计）感兴趣。
回归系数的标准解释是偏效应：$\beta_1$ 是 $X_1$ 增加一个单位时 $Y$ 的变化，同时控制所有其他变量（此处仅 $X_2$）。但是，如果 $X_1=X_2$，则一旦我们控制了 $X_2$，$X_1$ 显然无法再解释 $Y$ 中的任何变化。基于此推理，我期望得到估计值$\hat\beta_1=0$，并且基于相同推理，我期望得到$\hat\beta_2=0$。
但是，如果我估计回归模型（在完全共线情况下使用贝叶斯模型，或在近共线情况下使用贝叶斯/频率论），我会得到 beta 系数，其总和等于真实参数的总和$\beta_1+\beta_2$。从优化的角度来看，这也是有道理的，因为如果 $X_1=X_2$，则上述模型的 RHS 可以重写为 $(\beta_1+\beta_2)X_1 + \varepsilon$，这也说明了为什么模型无法识别。
基于上述内容，似乎 $\beta_1, \beta_2$ 的部分效应解释与我在（近）共线情况下得到的结果不一致。显然，我犯了一个推理错误，我希望有人能指出这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</guid>
      <pubDate>Wed, 09 Oct 2024 08:49:59 GMT</pubDate>
    </item>
    </channel>
</rss>