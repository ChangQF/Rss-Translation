<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 05 Jan 2025 12:30:19 GMT</lastBuildDate>
    <item>
      <title>比较两个模型中的分类变量</title>
      <link>https://stats.stackexchange.com/questions/659562/comparing-a-categorical-variable-accross-two-models</link>
      <description><![CDATA[我在 R 中运行两个固定效应回归：一个针对男性，一个针对女性。除了年份固定效应外，我还有一个分类变量作为我感兴趣的解释变量，年龄组作为另一个分类变量。
如果两个模型之间的分类变量系数不同，我该如何比较？
我依稀记得你估计了一个合并模型，并包括性别和分类变量之间的交互项。然后你进行 Wald 检验以检查交互项是否具有联合显著性。但是，我不确定这是否是正确的方法。
此外，我不确定我是否还应该包括性别和年龄组之间的交互项，还是只包括性别和感兴趣的分类变量之间的交互项。
但是，最好直接比较系数，而不需要估计合并模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/659562/comparing-a-categorical-variable-accross-two-models</guid>
      <pubDate>Sun, 05 Jan 2025 12:03:16 GMT</pubDate>
    </item>
    <item>
      <title>空间滞后模型对数似然计算</title>
      <link>https://stats.stackexchange.com/questions/659560/spatial-lag-model-log-likelihood-calculation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659560/spatial-lag-model-log-likelihood-calculation</guid>
      <pubDate>Sun, 05 Jan 2025 11:31:04 GMT</pubDate>
    </item>
    <item>
      <title>股票价格变动分布的重尾现象表现在哪里？</title>
      <link>https://stats.stackexchange.com/questions/659559/wheres-heavy-tail-in-the-distribution-of-the-stock-price-changes</link>
      <description><![CDATA[有假设认为股票价格变化具有混合分布 - 头部服从正态分布，尾部服从幂律分布。
幂律$f(x) = C x^{-\alpha}$可以在对数对数图上识别为直线。
我绘制了实际股票价格变化的 CDF，但我找不到尾部 - 直线。它在哪里？ （相同数据上也有正常的 CDF 拟合，仅用于比较）。

在 CDF 图表上 - 仅显示部分 CDF - 对数对数刻度上的正向变化。此外，差异通过对数变换进行变换，并且以中位数为中心。正态 CDF 拟合中心差异，强制使用 0 作为平均值。
数据 - 股票价格差异 - 计算为每天的年度变化 $d_i=p_i/p_{i-360}$，针对几十年来单只股票的每日价格。
数据和代码
代码
import json
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

# 加载 &#39;diffs.json&#39;
with open(&#39;diffs.json&#39;, &#39;r&#39;) 作为文件：
diffs = json.load(file)

# 对数据进行对数转换
log_diffs = np.log(diffs)

# 将中心计算为中位数，它比平均值更合适
center = np.median(log_diffs)

# 将对数差异居中
log_diffs_centered = log_diffs - center

# 拟合真实 CDF 的函数
def fit_cdf_(data):
sorted_data = np.sort(data)
n = len(data)
cdf = [(x, (i + 1) / n) for i, x in enumerate(sorted_data)]
return cdf

# 拟合真实 CDF
real_cdf = fit_cdf_(log_diffs_centered)

# 拟合正常 CDF，强制平均值为 0
variance = np.mean(log_diffs_centered**2) # 方差
sigma = np.sqrt(variance) # 标准差

# 提取 CDF x 值
cdf_xs = np.array([x for x, _ in real_cdf])

# 计算这些 x 值的正态 CDF
normal_cdf = [(x, norm.cdf(x, loc=0, scale=sigma)) for x in cdf_xs]

# 绘制真实 CDF 和正态 CDF
real_cdf_ys = [p for _, p in real_cdf]
normal_cdf_ys = [p for _, p in normal_cdf]

plt.figure(figsize=(8, 6))
plt.plot(cdf_xs, real_cdf_ys, label=&#39;Real CDF&#39;, linestyle=&#39;-&#39;)
plt.plot(cdf_xs, normal_cdf_ys, label=&#39;Normal CDF&#39;, linestyle=&#39;--&#39;)
plt.xscale(&#39;log&#39;) # 对数 x 轴刻度
plt.yscale(&#39;log&#39;) # 对数 x 轴刻度
plt.ylim(0.5, 1) # y 轴域
plt.xlim(0.001, 2) # x 轴域
plt.xlabel(&#39;x (对数刻度)&#39;)
plt.ylabel(&#39;累积概率&#39;)
plt.title(&#39;真实与正常 CDF&#39;)
plt.legend()
x_ticks = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]
plt.xticks(x_ticks, [str(label) for label in x_ticks])
y_ticks = [0.5, 0.6, 0.7, 0.8, 0.9, 1]
plt.yticks(y_ticks, [str(label) for label in y_ticks])
plt.grid(True)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/659559/wheres-heavy-tail-in-the-distribution-of-the-stock-price-changes</guid>
      <pubDate>Sun, 05 Jan 2025 10:34:17 GMT</pubDate>
    </item>
    <item>
      <title>pmg 面板 ardl stata</title>
      <link>https://stats.stackexchange.com/questions/659556/pmg-panel-ardl-stata</link>
      <description><![CDATA[我一直有缺失字段错误。  代码不起作用：xtpmg d.dur l.dur l.v2xpa_popul l.social_filled, lr(l.v2xpa_popul l.social_filled) ec replace
是因为缺少字段吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659556/pmg-panel-ardl-stata</guid>
      <pubDate>Sun, 05 Jan 2025 10:01:35 GMT</pubDate>
    </item>
    <item>
      <title>使用负采样优化 t-SNE</title>
      <link>https://stats.stackexchange.com/questions/659555/using-negative-sampling-to-optimize-t-sne</link>
      <description><![CDATA[我对邻域嵌入方法和对比学习非常陌生，
我正在阅读论文“https://arxiv.org/abs/2206.01816”（从 t-SNE 到 UMAP 对比学习），我很难理解他们说负采样用于优化 t-SNE 和 NCE 用于优化 UMAP 的部分。
有人可以解释一下，这些方法是如何关联的，我如何使用负采样来优化 t-SNE？我从在线资源中了解了一些基础知识，但我找不到与此相关的内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/659555/using-negative-sampling-to-optimize-t-sne</guid>
      <pubDate>Sun, 05 Jan 2025 09:37:50 GMT</pubDate>
    </item>
    <item>
      <title>比较参数曲线：基于傅里叶级数的相似度度量</title>
      <link>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</link>
      <description><![CDATA[使用傅里叶级数开发二维参数曲线的相似性度量
我正在探索使用傅里叶级数表示来比较二维参数曲线的方法。我的目标是开发一个相似性度量，以捕获曲线的幅度和相位信息。这是我的方法和我正在考虑的一些想法：
背景：

我们可以将二维参数曲线表示为复杂的傅里叶级数
首先，我们将傅里叶级数标准化为能量为 1

当前考虑事项：

相位信息：我认为相位对于确定曲线形状至关重要。是否有证据表明情况并非如此？

相关工作：

一些现有方法比较功率谱密度（忽略相位）
这些方法通常将 PSD 视为概率密度
两个离散傅里叶变换的相似性
比较傅里叶空间中的两个分布



潜在方法：

分离幅度和相位比较：

分别比较功率谱密度和相位谱密度
将两者视为概率分布
使用上述相关工作中的方法


笛卡尔形式的余弦相似性：

以平坦笛卡尔形式写出傅里叶系数（包括幅度和相位）
应用余弦相似性
优点：自然界在 -1 和 1 之间
缺点：对于接近 0 或负值的分数的解释不明确


笛卡尔形式的 L1/L2 距离：

与方法 2 类似，但使用 L1 或 L2 距离而是



问题：
是否有一种原则性的方法，可以使用二维参数曲线的傅里叶级数表示来开发相似性度量，以同时考虑幅度和相位信息？
我特别有兴趣了解这些方法与我可能忽略的任何其他方法之间的权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</guid>
      <pubDate>Sun, 05 Jan 2025 08:49:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算独立拍卖实验中销售额、退货和退货率变化的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</link>
      <description><![CDATA[问题
假设我正在组织一场汽车拍卖会，并进行两个独立的实验：

拍卖会 A 进行了 1000 次。
拍卖会 B 进行了 1000 次。
（例如，我更换了拍卖会 B 中的拍卖师，并想测量其效果。）

以下是观察到的结果：




拍卖会 A
拍卖会 B
符号




数量运行
1000
1000
常数 $ n_A $ 和 $ n_B $


售出数量
500
600
随机变量 $ S_A $ 和 $ S_B $


（售出和）退回数量
200
300
随机变量$ R_A $ 和 $ R_B $



根据这些数据，增量（我感兴趣的）如下：

销售数量增加了 20%：从 500 增加到 600。
退货数量增加了 50%：从 200 增加到 300。
退货率增加了 25%：从 40%（$ \frac{200}{500} $）增加到 50%（$ \frac{300}{600} $)。

问题 1：增量的置信区间
如何计算 95% 置信水平下每个增量的置信区间？例如：

销售数量增量，例如 $[+16\%, +27\%]$。
退货数量增量，例如 $[+42\%, +53\%]$。
退货率增量，例如 $[-5\%, +41\%]$。


我目前的方法（针对 #1）：
计算销售数量增量的置信区间：

我假设 $ S_A \sim \text{Binomial}(n_A, p^s_A) $ 和 $ S_B \sim \text{Binomial}(n_B, p^s_B) $，其中 $ p^s_A $ 和 $ p^s_B $ 是拍卖 A 或拍卖 B 中拍卖成交的概率 ($ p^s_A = 50\%, p^s_B = 60\% $)。
然后，我计算置信区间如下：
$$
\Delta S \pm z_{\alpha/2} \sqrt{\text{Var}(\Delta S)}
$$
其中：
$$
\text{Var}(\Delta S) = \text{Var}(S_A) + \text{Var}(S_B),
$$
并且：
$$
\text{Var}(S_A) = n_A p^s_A (1 - p^s_A), \quad \text{Var}(S_B) = n_B p^s_B (1 - p^s_B)。
$$
这种方法有意义吗？


我的挑战（针对 #2 和 #3）：
计算回报数量和回报率的增量置信区间：

我假设 $ R_A \mid S_A \sim \text{Binomial}(S_A, p^r_A) $，对于 $ R_B $ 也是如此。
我应该如何计算 $ \text{Var}(R_A) $ 和 $ \text{Var}(R_B) $？

我是否应该将观察到的销售数量（$ s_A $ 和 $ s_B $）视为常数（如第一种情况下的 $ n_A $ 和 $ n_B $）？
或者我应该将销售数量（$ S_A $ 和 $ S_B $）视为随机变量，并使用总方差定理计算 $ \text{Var}(R_A) $：
$$
\text{Var}(R_A) = \mathbb{E}[\text{Var}(R_A \mid S_A)] + \text{Var}(\mathbb{E}[R_A \mid S_A])?
$$



如能提供关于这些计算的任何指导或替代方法的建议，我们将不胜感激！

备注

我特别关心我的假设（例如，将观察值视为常数而不是随机变量）是否正确。
我希望得到任何相关统计方法或框架的指引，以便更好地处理这些类型的分析。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:41 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。（下一部分超出了我的理解，但我听说随机效应是使用 RMLE 估计的）

所有这些是否正确（尤其是最终可能性）？在纵向研究中，基于每个受试者的可用测量次数的权重可用于隐式说明可靠性？在统计学中这样做可以接受吗？
最后，看起来只需使用基本的多级建模方法就可以处理所有事情，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>小样本随机森林</title>
      <link>https://stats.stackexchange.com/questions/659548/random-forest-on-small-sample</link>
      <description><![CDATA[我正在学习随机森林，想在我拥有的数据集上测试它。有 500 个样本均匀分布在 50 个类别中，样本有 ~500 个值。这适合随机森林吗？推荐的大小/比例是多少？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659548/random-forest-on-small-sample</guid>
      <pubDate>Sun, 05 Jan 2025 01:33:37 GMT</pubDate>
    </item>
    <item>
      <title>检验具有交互项的对数线性模型中变量效应的显著性</title>
      <link>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</link>
      <description><![CDATA[假设我们有以下模型：
$\log(\mathbb{E}(​​y|x_1, x_2))=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2$。
它可以是逻辑回归、泊松回归或负二项模型。
假设$y$为正整数，模型为负二项模型。
假设$x_1$和$x_2$为虚拟变量。
假设所有估计系数在统计上都是显著。
那么，当 $x_1=1$ 时，将 $x_2$ 从 $0$ 切换到 $1$ 会使 $\mathbb{E}(​​y|x_1, x_2)$ 乘以 $e^{\beta_2} e^{\beta_3}$。
$\beta_2$ 和 $\beta_3$ 都具有统计显著性，足以证明上述事实吗？
或者我需要测试两者对 $y$ 的影响也具有统计显著性？在这种情况下，对 $\beta_2+\beta_3&gt;0$ 进行单侧 t 检验是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</guid>
      <pubDate>Sat, 04 Jan 2025 22:36:32 GMT</pubDate>
    </item>
    <item>
      <title>寻找多项式似然和拉普拉斯先验的后验</title>
      <link>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</link>
      <description><![CDATA[使用狄利克雷先验和多项似然模型，可以推导出离散事件频率估计的后验分布。可以通过计算参数的后验均值估计来应用伪计数技术。假设对于 $\mathbf{n}$ 个可能的离散结果，存在均匀先验和多项模型，我正在寻找这些结果的概率向量 $\boldsymbol{\theta}$ 的后验分布。我来这里是为了验证我的发现。
推导：
后验来自贝叶斯规则：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{P(\mathbf{n} \mid \boldsymbol{\theta}) P(\boldsymbol{\theta})}{P(\mathbf{n})}$。
似然项
多项式似然为：
$P(\mathbf{n} \mid \boldsymbol{\theta}) = \frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i},$
其中 $N = \sum_{i=1}^K n_i$ 是观测总数。
先验项
先验是狄利克雷分布：
$P(\boldsymbol{\theta}) = \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1},$
带有归一化常数：
$Z(\boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}{\prod_{i=1}^K \Gamma(\alpha_i)}$。
合并项
后验变为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i} \cdot \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1}}{P(\mathbf{n})}$。
简化分子：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}}{P(\mathbf{n})}$。
规范化
确保$P(\boldsymbol{\theta} \mid \mathbf{n})$积分为1，归一化因子$P(\mathbf{n})$必须是：
$P(\mathbf{n}) = \frac{N!}{\prod_{i=1}^K n_i!} \cdot \frac{Z(\boldsymbol{\alpha})}{Z(\mathbf{n} + \boldsymbol{\alpha})}$。
此处：
$Z(\mathbf{n} + \boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K (n_i + \alpha_i)\right)}{\prod_{i=1}^K \Gamma(n_i + \alpha_i)}$.
最终后验
后验分布简化为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{1}{Z(\mathbf{n} + \boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}$.

均匀先验
我们使用拉普拉斯先验（不要与拉普拉斯分布混淆），它对应于均匀先验（$\boldsymbol{\alpha} = \mathbf{1}$)，其中 $\mathbf{1}$ 是一个向量，其长度与 $\mathbf{n}$ 的长度相对应。
$P(\boldsymbol{\theta} \mid \mathbf{n}) = D(\mathbf{n} + \mathbf{1}; \boldsymbol{\theta}) = \frac{1}{Z(\mathbf{n} + \mathbf{1})} \prod_{i=1}^K \theta_i^{n_i}$。
请随意评论此推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</guid>
      <pubDate>Sat, 04 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习的 Python 课，我们主要学习的是线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前在课上做过最小二乘），我们讨论了定义假设、损失函数、成本函数等。
我有两个问题：
为什么许多问题都可以看作是线性问题，而且基本上就是“试图找到方程 Ax = b 的解”？可以通过最小二乘法或训练神经网络来找到解。
我觉得“在现实世界中”，大多数问题根本不是线性的。既然线性代数只适用于线性函数，那么如何解决这些问题呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>识别与平方根过程相关的随机过程的分布</title>
      <link>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</link>
      <description><![CDATA[让 $x(t)$ 成为遵循以下的随机平方根过程
$$dx(t) = (a + bx(t)) dt + c\sqrt{x(t)} dW(t)$$
其中 $W(t)$ 是某些过滤的标准布朗运动。
它有很多名字，但出于本文的目的，我不会提及它们。如果我们定义
$$ \varphi(u;t,h) = \mathbb E\left( e^{u x(t+h)} \mid x(t) \right); \quad u\in \mathbb C$$
那么我可以证明对于 $\Re(u) \leqslant 0$，我们有
$$
\mathbb E(e^{u x(t+h)} \mid x(t) = x ) = 
\frac{1}{\left(1- 2z(h)u
\right)^{\frac k2}}\exp\left(
\dfrac{\lambda(t)x\cdot z(h)u }{1- 2z(h)u}
\right) $$
其中 $z(h) = q(h)e^{bh}\frac{c^2}{4}$，$q(h) = \dfrac{1-e^{-bh}}{b}$，$\lambda(h) = \frac{4q(h)^{-1}}{c^2}$ 和 $k = \frac{4a}{c^2}$。因此，在 $x(t)$ 条件下，我们有
$$
z(h)^{-1} x(t+h) \sim \chi_k^2(\lambda(h)^{-1}x(t))
$$
其中右边是非中心卡方分布，具有 $k$ 自由度和非中心参数 $\lambda = \lambda(h)^{-1}x(t)$。具体来说，我们可以让 $c=2$ 和 $b\to 0$ 恢复平方贝塞尔过程满足
$$
h^{-1} x(t+h) \sim \chi_k^2(h^{-1}x(t))
$$
这是众所周知的。

现在考虑联合过程 $y(t) = \left( \int_{0}^t x(s)ds, x(t) \right)$。然后，我可以证明联合条件特征函数
$$\varphi(u;t,h) = 
\mathbb E\left( e^{u\cdot y(t+h)}\mid y(t) \right); \quad u\in \mathbb C^2 
$$
对于$y(t) = (y_1, y_2)$等于
$$ \varphi(u;t,h) = \frac1 {\left(1- 2z\right)^{\frac k2}}
\exp\left(\dfrac{ \lambda z}
{1- 2 z}y_2 + v y_2\right)\exp(u_1 y_1 + ah v(u_1))
$$
其中$v(u_1)$是$\frac 12 c^2 v^2 + bv = u_1$的解，并且
\begin{align*}
z(h,u) &amp;= (u_2 - v(u_1))e^{(b + v(u_1)c^2)h}\lambda^{-1}(h,u) \\
\lambda(h,u) &amp;= \frac{4}{c^2}q_0(h,u)^{-1} \\
q_0(h, u) &amp;= \dfrac{1-e^{-(b + v(u_1)c^2)h}}{b + v(u_1)c^2} 
\end{align*&gt;
一个明显的检查是，如果 $u_1=0$ 那么我们可以连续选取 $v(u_1)=0$ 然后特征函数是 $x(t)$，正如它应该的那样。
然而，我无法识别这个联合分布。我最天真的猜测是它可能是广义卡方分布，如这里，但我没有取得太大进展。
有人知道该怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</guid>
      <pubDate>Sat, 04 Jan 2025 12:28:35 GMT</pubDate>
    </item>
    <item>
      <title>线性判别分析-有关公式的基本问题</title>
      <link>https://stats.stackexchange.com/questions/659524/linear-discriminant-analysis-basic-question-regarding-the-formulas</link>
      <description><![CDATA[我正在阅读 Hastie 和 Tishbirani 合著的《统计学习导论》。
他们在第 148 页上说，我们寻找类 $k$，以便最大化函数
$$\delta_k(x) =x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} +\log(\pi_k).$$
然后他们说，对于两个类 ($K=2$)，如果先验分布相等，我们将观察值 $x$ 分配给类 $1$，如果
$$2x(\mu_1 - \mu_2) &gt; \mu_1^2 - \mu_2^2, $$
这导致决策边界为
$$x = \frac{\mu_1^2 - \mu_2^2}{2(\mu_1 - \mu_2)}= \frac{\mu_1 + \mu_2}{2}.$$
现在我的代数不收敛到那个。我的不等式导致不同的符号 ($\mu_1^2 + \mu_2^2$)。我也不明白最后的结论。你能帮我算一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659524/linear-discriminant-analysis-basic-question-regarding-the-formulas</guid>
      <pubDate>Sat, 04 Jan 2025 12:14:32 GMT</pubDate>
    </item>
    <item>
      <title>在回归中指定仅与部分人群相关的交互项</title>
      <link>https://stats.stackexchange.com/questions/659460/specifying-interaction-terms-in-a-regression-that-are-only-relevant-to-some-part</link>
      <description><![CDATA[这是我教科书中的一道关于同化和移民对收入影响的问题。

瑞士的一位社会科学家正在研究移民对收入的影响。她有 1000 个人的数据（每个人一个数据点），包括他们当前的年龄、当前收入、是否出生在瑞士以及他们移民到瑞士时的年龄（如果适用）。她如何建立回归模型来研究在瑞士生活相同百分比的生活对收入的影响，与年轻时移民的人相比，与年老时移民的人相比，两者有何不同？


我是这样处理这个问题的
（我想我们假设一个出生在瑞士的人永远不会离开，一旦一个人移民到瑞士，他就永远不会离开——或者在外面度过的时间可以忽略不计，这个问题就可以成立）
：

$y$ 是因变量：收入（我可能会使用对数收入来防止负面预测）
$x_1$ 表示当前年龄（针对所有人）
$x_2$ 表示某人是否是移民：$x_2 = 0$ 为本土出生者，$x_2 = 1$ 为移民
$x_3$ 代表移民时的年龄：对于移民：他们抵达时的年龄，对于本土出生者：等于 0
$x_4$ 代表在该国度过的生命比例：对于本土出生者：$x_4 = 1$ 始终如此，对于移民：

$x_4 = \frac{\text{当前年龄} - \text{移民时的年龄}}{\text{当前年龄}} = \frac{x_1 - x_3}{x_1}$
我为本土出生者建立了一个模型（$x_2 = 0$):
$$ y = \beta_0 + \beta_1x_1 + \epsilon $$
然后我为移民建立了一个模型（$x_2 = 1$）：
$$ y = (\beta_0 + \beta_2) + \beta_3x_4 + \beta_4x_3 + \beta_5x_1 + \epsilon $$
然后我结合了两个模型：
$$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3(x_4 \cdot x_2) + \beta_4(x_3 \cdot x_2) + \beta_5(x_1 \cdot x_2) + \epsilon $$
从这里我们可以看到：

$\beta_0$：当所有变量都为零时（即出生在本国的人在 0 岁时的生活比例如何影响其收入（假设年龄和移民年龄保持不变）
$\beta_1$：年龄对收入的基本影响适用于所有人，无论移民身份如何
$\beta_2$：当所有其他变量为零时，移民与出生在本国的人相比的额外基线收入差异
$\beta_3$：在年龄和移民年龄保持不变的情况下，在本国度过的生活比例如何影响移民收入
$\beta_4$：在当前年龄和生活比例保持不变的情况下，移民的年龄如何影响其收入
$\beta_5$：与基线相比，移民的年龄影响有多大差异年龄效应

从这里开始，我认为该模型可用于以下解释：

$\beta_3$告诉我们，在该国度过更大人生比例的移民是否有更高的收入，即使在控制了他们目前的年龄和抵达时的年龄之后也是如此。

$\beta_4$揭示了抵达时年龄较大与较小是否会影响收入，即使在考虑了某人在该国居住的时间长短和他们目前的年龄之后也是如此。

在任何给定年龄$x_1$，移民和本土出生者之间的总收入差异为$\beta_2 + \beta_3x_4 + \beta_4x_3 + \beta_5x_1$。这表明移民与本地人的差距如何随着年龄、在该国居住的时间以及抵达时的年龄而变化。



当回归模型中的交互项仅适用于部分人口时，这是正确指定和解释交互项的方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659460/specifying-interaction-terms-in-a-regression-that-are-only-relevant-to-some-part</guid>
      <pubDate>Thu, 02 Jan 2025 17:49:11 GMT</pubDate>
    </item>
    </channel>
</rss>