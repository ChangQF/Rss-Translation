<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 15:16:35 GMT</lastBuildDate>
    <item>
      <title>对混合效应模型的结果感到困惑</title>
      <link>https://stats.stackexchange.com/questions/652492/confused-about-the-results-of-a-mixed-effect-model</link>
      <description><![CDATA[我有两个连续肌肉活动水平 A 和 B 的数据集。我假设 B 与 A 线性相关，这可以通过简单的相关性检验得到证实。我有两个分类因素：受试者和任务。我想知道线性关系（截距和斜率）是否因这两个因素而变化。因此，我构建了一个线性混合效应模型：B ~ 1 + A + (1+A|受试者) + (1+A|任务)，并执行了以下两个步骤：
1) 我比较了有和没有这两个随机因素。结果表明，将受试者作为随机因素可显著改善残差，但对任务则没有影响。
2) 我还检查了受试者和任务的 ICC。受试者的 ICC 为 0.0025，但任务的 ICC 为 0.67。
现在我很困惑。模型比较表明，受试者之间的差异很重要，但 ICC 结果表明任务是造成差异的主要原因。
我如何理解这些结果？我应该继续任务还是受试者？
如果有人能帮助我理清这个问题，我将不胜感激。我一定是理解错了某些部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/652492/confused-about-the-results-of-a-mixed-effect-model</guid>
      <pubDate>Thu, 08 Aug 2024 15:12:54 GMT</pubDate>
    </item>
    <item>
      <title>标准差的标准差估计</title>
      <link>https://stats.stackexchange.com/questions/652491/estimation-of-the-standard-deviation-of-the-standard-deviation</link>
      <description><![CDATA[假设我有$n$个数据点，我可以从中计算标准差$\sigma$。如果我想估计 $\sigma$ 的标准误差 (SE)，我可以使用引导法。
例如，使用此代码：
def SE_of_std(y, n_iterations=10**4):

if y.empty:

return np.NaN

bootstrapped_std = []

for _ in range(n_iterations):
sample = np.random.choice(y, size=len(y), replace=True)
bootstrapped_std.append(np.nanstd(sample))

return np.std(bootstrapped_std)

有没有办法使用与估计 SE 类似的方法来估计标准偏差的标准偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/652491/estimation-of-the-standard-deviation-of-the-standard-deviation</guid>
      <pubDate>Thu, 08 Aug 2024 14:38:43 GMT</pubDate>
    </item>
    <item>
      <title>即使随机化方案是受限随机化，排列检验是否可行？</title>
      <link>https://stats.stackexchange.com/questions/652490/is-the-permutation-test-possible-even-when-the-randomization-scheme-is-a-restric</link>
      <description><![CDATA[想象一个实验环境，参与者被随机分配到一些治疗组。但是，使用了一种限制性随机化形式（实验者知道）。
实验结束后，我可以做一个测试，重复使用这种限制性随机化，注册一个假设没有治疗效果的检验统计量，以获得该检验统计量的模拟分布。之后，我可以通过查看原始数据中的检验统计量与模拟数据相比有多极端来获得 p 值。我的第一个问题是：我可以称之为随机化测试吗？
现在假设我按照上面描述的方式进行操作，但我使用的是均匀/完全随机化，而不是限制性随机化。我的第二个也是主要的问题是：我“被允许”这样做吗？即使我知道分配方案不是来自这个分布，我也可以假装如果它来自这个分布：我们会得到一个特定的 p 值，我们可以用它来评估治疗是否有效果。我想说，但这听起来确实有点可疑。
另外，我可以将第二个过程称为排列测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652490/is-the-permutation-test-possible-even-when-the-randomization-scheme-is-a-restric</guid>
      <pubDate>Thu, 08 Aug 2024 14:04:55 GMT</pubDate>
    </item>
    <item>
      <title>合并引导迭代中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/652489/combining-p-values-from-bootstrap-iterations</link>
      <description><![CDATA[我正在尝试针对连续响应变量 $x$ 建模突变概率。我正在构建一个逻辑回归模型，将每个基因的突变状态作为 $y$，并将 $x$ 作为回归模型中的参数。结果系数表示突变的对数几率概率增加，而 $x$ 的单位增加。我正在为每个基因拟合一个单独的模型，类似于 DESeq2 中所做的。
从这些模型中，我可以轻松计算出 p 值。
我正在引导此过程 $n$ 次，因为我发现输入数据的微小变化经常会得到不稳定的结果。我想根据一些指标对这些基因进行排序，以考虑突变概率（系数）变化的幅度，以及我所掌握的支持这一结果的证据（标准误差）。
我可以根据突变概率的对数几率增加对基因进行排序，但这些并没有考虑与 $x$ 中的测量值相关的标准误差。因此，我想使用一个统计数据，如 p 值，它可以解释这一点，但我正在引导整个过程，并且相信我不能简单地平均 p 值（这里）。
我可以使用什么来对这些基因进行排序，以便在所有引导重复中获得单一排名？在每个单独的引导迭代中排名，然后对这些排名取平均值是否合适？
我对统计学还很陌生，所以您推荐的任何读物都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652489/combining-p-values-from-bootstrap-iterations</guid>
      <pubDate>Thu, 08 Aug 2024 11:49:03 GMT</pubDate>
    </item>
    <item>
      <title>事件研究实施</title>
      <link>https://stats.stackexchange.com/questions/652488/event-study-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652488/event-study-implementation</guid>
      <pubDate>Thu, 08 Aug 2024 11:48:39 GMT</pubDate>
    </item>
    <item>
      <title>如何估计线性回归中测量变量的标准差？</title>
      <link>https://stats.stackexchange.com/questions/652487/how-do-i-estimate-the-standard-deviation-of-the-measured-variables-in-linear-reg</link>
      <description><![CDATA[假设一个线性模型：
$$
y = \alpha x + \beta
$$
我对$(x_i,y_i)$进行了 n 次观察。
每个观测值都受到测量不确定性的影响，我假设该不确定性呈正态分布，平均值 = 0，但方差未知。
如何在 Python 中估算 $\alpha$、$\beta$ 以及 $\sigma_x$ 和 $\sigma_y$？
以下是一些为 $y = 2x + 1$ 生成测试数据的代码：
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import lstsq

n = 20
x = np.linspace(-5,5,n)
y = 2*x + 1

sigma_x = 0.1
sigma_y = 0.2

x_noisy = x + np.random.normal(0, sigma_x, x.shape)
y_noisy = y + np.random.normal(0, sigma_y, y.shape)

plt.plot(x,y, label = &#39;y = 2x + 1&#39;)
plt.scatter(x_noisy,y_noisy, color=&#39;red&#39;, label = &#39;测量的 (x,y) 值&#39;)
plt.xlabel(&#39;x&#39;)
plt.ylabel(&#39;y&#39;)
plt.legend()
plt.show()

给定上面的 x_noisy 和 y_noisy 值，我如何恢复 $\alpha=2$，$\beta=1$，$\sigma_x = 0.1$ 和 $\sigma_y = 0.2$？

也许可以先通过线性回归找到 $\alpha$ 和 $\beta$，然后将每个测量点投影到这条线上：

接下来，可以根据 dx 和 dy 的分布估算出 x 和 y 的标准差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652487/how-do-i-estimate-the-standard-deviation-of-the-measured-variables-in-linear-reg</guid>
      <pubDate>Thu, 08 Aug 2024 11:07:30 GMT</pubDate>
    </item>
    <item>
      <title>选择正确的效应大小 (Cohen's d) 进行功效分析</title>
      <link>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</link>
      <description><![CDATA[根据 Blevins 等人 (2015)，《精神障碍诊断和统计手册》第五版创伤后应激障碍检查表 (PCL-5) 在其两项研究中显示内部一致性 alpha 值 分别为 .94 和 .95。作者表明，该工具的重测信度为 .82（似乎被认为是强的），表明结果随时间推移稳定且一致。作者提到，聚合效度与 PTSD 测量结果呈现高度相关性（例如，与 PCL 的 .85、与 PDS 的 .85 以及与 DAPS 的 .84），这表明 PCL-5 似乎测量与其他已建立的 PTSD 测量相同的结构。作者表示，该工具与相关结构显示出中等相关性（例如，抑郁症 r = .60）并且与不相关结构显示出较低相关性（例如，躁狂症 r = .31），所有这些似乎都显示出良好的判别效度。
我的目标是在研究中使用 PCL-5（Blevins 等人，2015 年）。
但是，在执行此操作之前，我需要进行功效分析以计算获得可靠结果所需的先验最小样本量。为此，我需要以下内容：

显著性水平 (α = .05)
功效 (1-β = .80)
Cohen&#39;s d (尚不清楚)

我的问题：

根据上述描述，我可以自己决定 d 效果大小吗？
如果可以，值是多少，我该如何证明它（参考文献）？
如果不是，选项和/或替代方案是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</guid>
      <pubDate>Thu, 08 Aug 2024 10:43:46 GMT</pubDate>
    </item>
    <item>
      <title>在 GWAS 中调整协变量时，协变量是否需要取消惩罚？</title>
      <link>https://stats.stackexchange.com/questions/652484/when-adjusting-for-covariates-in-gwas-do-the-covariates-need-to-be-unpenalized</link>
      <description><![CDATA[我想知道是否有人遇到过这个问题并就如何最好地进行提出建议：
我正在使用基因型数据（这是 0、1 或 2 的数据）寻找 SNP 与 2 型糖尿病（二元性状为 0 或 1）之间的关联。需要调整协变量的效应大小，在本例中，协变量是前 10 个主成分（浮点数）、性别和年龄。
我正在使用 sci-kit 学习库、gridSearchCV 和 LogisticRegression。一些文献报告在使用惩罚回归时使用未惩罚的协变量进行此分析。这是为了确保在训练期间保留协变量，因为协变量可能会对遗传数据产生影响，最终的效应大小需要为此进行调整（即混杂）。但是据我所知，sci-kit learn 本身并不支持这一点。
我有两个问题：

有没有办法在 sci-kit learn 库中自定义每个特征的惩罚？或者是否有其他我可以考虑的解决方案？

我已经用协变量训练了几个模型，其中几个模型中只有 1 个协变量的 beta 系数为 0。这是否意味着模型保留了协变量并且这些结果有效？


或者，我可能需要重写 R 中的所有内容以使用 glm 库，该库本身支持这一点，但在走这条路之前我想先联系一下。
任何建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/652484/when-adjusting-for-covariates-in-gwas-do-the-covariates-need-to-be-unpenalized</guid>
      <pubDate>Thu, 08 Aug 2024 09:41:22 GMT</pubDate>
    </item>
    <item>
      <title>根据删失数据估计对数正态分布的参数以进行模拟</title>
      <link>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</link>
      <description><![CDATA[我有以下模型
$$Y=X_1/c_1+X_2*X_2/c_2+X_3/c_3+X_3*X_4/c_4.$$
我知道 $X_1$ 和 $X_3$ 遵循不同但已知的正态分布，$c_1\dots,c_4$ 是已知常数，而 $X_2,X_4$ 遵循不同的未知对数正态分布。我想进行蒙特卡罗模拟来估计 $Y$ 的分位数。
我有一些数据可以估计 $X_2,X_4$ 的分布，但这些数据是左删失和右删失的。它可能看起来像这样：
$$\begin{matrix} &lt;0.2 &amp; 0.1 &amp; &gt;4 &amp; 0.7 &amp; 0.9 &amp; &lt;0.3 &amp;&gt;0.7 &amp;0.3 &amp;&lt;0.1 \end{matrix}$$
在较好的情况下，我有 60 个数据点，其中 10 个是删失的。在最坏的情况下，我有 21 个数据点，其中 9 个是删失的。
使用删失数据，我可以估计对数正态分布 $X_2,X_4$ 的参数。我使用 R 包 fitdistrplus 执行此操作。对于 $X_3$，我得到例如：
$$\begin{matrix} &amp; \text{estimate} &amp; \text{Std. Error}\\ \text{meanlog} &amp; -1.5&amp; 0.2\\ \text{sdlog} &amp; 1.8 &amp; 0.19 \end{matrix}$$
我想将估计的不确定性纳入我的模型中。有没有自然的方法可以做到这一点？我的想法是根据错误改变对数正态分布的参数。因此，我可以从 $\mathcal{N}(-1.8,0.19^2)$ 中选择不同的 $\text{meanlog}$，用于模拟表格 $\mathcal{N}(-1.5,0.2^2)$ 和 $\text{sdlog}$。但此处选择正态分布似乎有些武断。如果数据没有被审查，则 t 分布和 $\chi^2$ 分布似乎很自然地被选择（如果我是对的？）但这如何处理被审查的数据？我是否应该忽略计算误差并以任何方式使用它们？但自由度是多少？或者这些数据是否足以使用正态近似？或者还有其他方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</guid>
      <pubDate>Thu, 08 Aug 2024 08:53:39 GMT</pubDate>
    </item>
    <item>
      <title>如果不考虑偏度，峰度的定义是不是不太清楚？</title>
      <link>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</link>
      <description><![CDATA[提前致歉，我不是统计学家，所以这个问题可能很幼稚。我的理解如下：
均值是第一个原始矩。
方差是第二个中心矩，即减去第一个原始矩（均值）后得到的。第二个原始矩可能在特定情况下有用，但并不能真正描述分布或数据集形状的某个方面（不考虑数据集的均值）。
类似地，偏度是第三个标准化矩，即减去均值并除以标准差（方差的根）后得到的。
但峰度是第四个标准化矩。它也是一个标准化矩，即它不考虑任何第三矩（偏度）。
这对于峰度的解释来说不是有问题吗？如果不是，为什么不是？如果有，有没有一种方法可以解释峰度并考虑到偏度？
（我说得对吗？没有一种简单的方法可以“去偏度”，即没有类似于集中化和标准化的简单转换会导致平均值为 0、标准差/方差为 1 和偏度为 0？）]]></description>
      <guid>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</guid>
      <pubDate>Thu, 08 Aug 2024 08:31:48 GMT</pubDate>
    </item>
    <item>
      <title>使用类似模型生成的标签训练模型：过度拟合？</title>
      <link>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</link>
      <description><![CDATA[我训练模型来预测航空影像中的一些线性特征。由于参考数据只是线条，我制作了一个简单的缓冲区，以便标签与目标特征的宽度非常接近。它们的宽度从 3 到 15 米不等，因此我将中位数宽度设置为 9 米。UNet 模型很好地预测了它们。事实上，预测比标签更接近现实/图像，因为预测更接近目标特征的边缘，而不是简单的 9 米宽度。但是，准确度指标很差（测试数据集中的 F1 为 0.6），因为标签和预测之间的 IoU 很低。所以，我想到我可以将此模型的预测用作改进的训练和测试标签。然后，我将使用改进的训练标签训练另一个模型，并针对改进的测试标签对其进行测试。结果在视觉上相似，但测试数据集中的 F1 上升到 0.9。这是过度拟合吗？测试数据集显然未用于训练任一模型。
我尝试使用 eCognition 分割整个图像并提取我的目标特征，但这不可行。我的目标特征分割通常非常不准确。
以下是损失和准确度曲线，以防万一：
]]></description>
      <guid>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</guid>
      <pubDate>Thu, 08 Aug 2024 07:58:07 GMT</pubDate>
    </item>
    <item>
      <title>对于小样本量、不明确（非正态）分布的适当显着性检验</title>
      <link>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</link>
      <description><![CDATA[给定数据：
30 个数据点，以可用性分数的形式呈现（系统可用性量表）
数据中有 2 个组（组 1：17，组 2：13，独立，大小不等）
目标：
看看这两组的可用性分数之间是否存在统计上的显著差异
问题：
这里研究比较两个独立组的统计显著性的适当方法是什么？
初步想法（基于作为非统计学家的一些研究）：
有些测试对底层数据分布做出假设，有些则不做。通过直方图和箱线图可视化数据，我的第一印象是它不是正态分布的。因此，例如 Mann-Whitney-U 检验可能是一种选择。此外，使用 Shapiro-Wilk 等方法进行正态性测试被认为是无用的，因为其拒绝正态性假设的能力很弱，尤其是在样本量较小的情况下。不过，如果这样的测试拒绝了假设（即：它是正态分布），我们确实可以将其视为非正态性的迹象。
有人可以确认或拒绝我得出的结论吗？根据提供的信息，是否有更好的替代方案？
我正在寻找处理此类数据的最佳实践，并希望听取您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</guid>
      <pubDate>Thu, 08 Aug 2024 07:17:57 GMT</pubDate>
    </item>
    <item>
      <title>我需要对 2 Ivs 和 2 DV 进行什么分析？</title>
      <link>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</link>
      <description><![CDATA[我认为我需要 MANOVA，但我可能需要 ANCOVA，然后仅在实验组内进行 ANOVA。
我认为它是干预组内的 2x2 因子独立测量 ANOVA。我没有任何等价的句子可以用于 MANOVA，因为我之前从未写过 MANOVA
我有 2 个 IV：
IV1 有 2 个级别：对照组和干预组
IV2 是干预组中的个性特征，因为这是一个次要假设
我有 2 个相关的 DV：
DV1 是儿童自我评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
DV2 儿童父母评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
我可以将幸福感得分分为各种不同的子分数（希望、幸福、乐观、价值）
我的假设是：
H0- 实验组和对照组之间的幸福感改善随时间没有显著差异
H1- 与对照组相比，干预组的幸福感得分将显着改善
H2- 干预组的具体幸福感得分显着改善希望、幸福、乐观和价值
H3- 干预组的改善程度在具有特定人格特质的人中会更高。
我很高兴被告知我完全错了，因为我的论文的分析部分总是花费最长的时间来写，我感到完全迷失了。提前谢谢 :)

Chat GPT 说：
根据您的假设，此分析策略涉及使用 MANOVA、ANCOVA、ANOVA 和回归分析的组合来彻底评估您的干预效果和关于自然相关性的次要假设。
重新审视假设：
H1：使用 MANOVA 评估总体差异并跟进特定 DV 变化的 ANOVA。
H2：使用因子 ANOVA 评估子量表差异。
H3：使用干预组内的方差分析或回归分析自然相关性的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</guid>
      <pubDate>Wed, 07 Aug 2024 19:41:25 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>解释变量高度不平衡的回归</title>
      <link>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</link>
      <description><![CDATA[我有一个回归问题，其中一个解释变量是分类变量，有 2 个类别。我的问题是，一个类别有 90% 的观测值，而第二个类别只有 10% 的观测值。
这种高度不平衡的分类变量的存在是否会对模型系数的统计推断造成任何问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</guid>
      <pubDate>Wed, 07 Aug 2024 13:20:48 GMT</pubDate>
    </item>
    </channel>
</rss>