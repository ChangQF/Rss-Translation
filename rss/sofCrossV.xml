<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 21 Jan 2024 15:13:28 GMT</lastBuildDate>
    <item>
      <title>使用 MTEFE 的边际治疗效果 - 事后估计差异</title>
      <link>https://stats.stackexchange.com/questions/637393/marginal-treatment-effects-using-mtefe-postestimation-discrepancy</link>
      <description><![CDATA[我目前正在计算结果 Y（收益）和处理 D（连接扇区 1 与扇区 0），使用 Stata 的 MTEFE 包。
我使用多项式 1 的单独方法，找到一条向下倾斜的曲线，根据结果，ATE 为 -0.63，ATT 为 -0.48，ATUT 为 -0.7（与向下倾斜的曲线一致）。
然后，我想要进行后估计并计算样本中每个具有特征 X、D 和 p 的个体的预期治疗效果。我遵循p中的公式。 137. 如果我对我的样本求和，我会发现与之前的 ATE 相似的值。但是，如果我对 D=1 的个体求和，我会发现值为 -1；如果我对 D=0 的个体求和，我会发现值为 -0.6，这与之前的 ATT 和 ATUT 不一致（我应该发现，对 D=1 的个体进行求和所得到的负值比对 D=0 的个体求和时得到的负值要小）。我在使用 LIV 方法时发现了类似的模式。
在我看来，我的后估计计算公式是正确的，所以我想知道我的发现是否有意义，或者它是否清楚地表明我在某个地方犯了错误。我的 Y 是收入，我的 D 是加入私营部门的指标（相对于学术界 - 我正在攻读博士学位）。是否会因为任一行业都存在产能限制，后测效应会朝另一个方向发展？我无法协调估算前和估算后的估算。
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637393/marginal-treatment-effects-using-mtefe-postestimation-discrepancy</guid>
      <pubDate>Sun, 21 Jan 2024 14:51:39 GMT</pubDate>
    </item>
    <item>
      <title>研究两个自变量之间关系的相关性度量</title>
      <link>https://stats.stackexchange.com/questions/637391/correlation-metric-for-investigating-relationship-between-two-independent-variab</link>
      <description><![CDATA[我正在从事一项计算机工程研究，其中我正在分析不确定性故障场景中指令的动态执行计数（频率）与相应的数据错误率 (SDC) 之间的关系。每条指令都会注入故障，故障注入过程是不确定的，并且在指令之间均匀分布。
我有一个表，其中包括当我们注入故障时每条指令的频率及其相应的SDC错误率。实际上，故障注入过程确保所有指令都注入相似数量的故障。
考虑到研究的性质，其中故障是非确定性且均匀地注入的，我想知道哪种相关性度量最适合调查频率和 SDC 错误率之间是否存在相关性；因此我们可以得出这样的结论：“保护频繁执行的指令将导致高故障覆盖率，即提高系统的可靠性。”
我考虑使用斯皮尔曼等级相关系数，因为它的稳健性和对非正态分布数据的适用性。不过，我想向社区寻求建议，看看是否有更适合此特定场景的相关性指标。
这里是我数据的一小部分
&lt;前&gt;&lt;代码&gt;指令。频率SDC
0x103f8 64 3
0x10410 64 2
0x10830 13 7
0x1083c 13 6
0x1086c 13 7
0x108ac 13 7
0x108b0 13 6
0x108bc 13 6
0x10a40 7 6
0x10a48 7 4
0x10a9c 7 5
0x103a0 1 0
0x1049c 1 4
0x104a0 1 4
0x106e0 1 0
0x106e8 1 6
0x10710 1 3
0x10724 1 6
0x10780 1 1
0x1078c 1 0
0x107b8 1 2
0x1090c 1 0

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637391/correlation-metric-for-investigating-relationship-between-two-independent-variab</guid>
      <pubDate>Sun, 21 Jan 2024 13:50:12 GMT</pubDate>
    </item>
    <item>
      <title>从相关值组中采样 1 项并合并统计数据</title>
      <link>https://stats.stackexchange.com/questions/637388/sampling-1-item-from-groups-of-correlated-values-and-combining-the-statistics</link>
      <description><![CDATA[我们有一个由多组观察结果组成的数据集：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

组
对象
值


&lt;正文&gt;

Gr_1
Ob_1
V_1


Gr_1
Ob_2
V_2


Gr_2
Ob_3
V_3


...
...
...




所有值都位于区间 [0,1] 内。
在每个组 Gr_i 中，值可能彼此相当接近，因为它们通常来自相似的对象。不同群体的价值观之间也存在一定的相关性。
在研究这些物体的学科中，通常将其分为“狭义”物体类别。 “宽”和“宽”，取决于值V_i是小(接近0)还是大(接近1)。然而，数据似乎并不支持这样的划分，因为这些值似乎相当均匀地填充了整个区间 [0,1]。如何才能做到这一点严格呢？
我能想到的最好方法如下：从每组中取出 1 个值并查看生成的样本。可以使用单样本 Kolmogorov-Smirnov 检验来检验均匀分布 - 如果我们取 1000 个这样的样本并将 KS 检验 p 值视为来自随机变量的样本，我们会得到平均值 0.49 和标准差 0.15。这看起来像是对“狭义”的区别这一想法的合理表达。和“广泛”不是很明显。然而，将这些 p 值（或初始 KS 统计量）合并为单个值会更好。如果我们获得的这些样本是独立的，则可以使用费舍尔方法，但事实并非如此，因此应该使用费舍尔方法的某些变体，但我很难确定哪种方法最有效（而且，那里显然存在很多陷阱，所以应该非常小心）。有什么想法或替代方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637388/sampling-1-item-from-groups-of-correlated-values-and-combining-the-statistics</guid>
      <pubDate>Sun, 21 Jan 2024 13:32:23 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 精确检验与差异基因表达</title>
      <link>https://stats.stackexchange.com/questions/637387/fishers-exact-test-vs-differential-gene-expression</link>
      <description><![CDATA[我通过 GWAS 鉴定了与表型相关的 SNP。我在那些显着相关的 SNP 中标记了遗传变异的类型，现在我正在尝试使用 Fisher 精确检验来评估这些变异与表型的关联。
看看 R 中费舍尔精确检验的输出，是否可以仅通过查看优势比和 p 值来判断感兴趣的遗传变异是富集还是耗尽？
例如，测试 ncRNA 和表型之间的关联时，p 值 = 0.0003，OR = 0.24，那么如何解释 OR？我们也可以在基因表达的背景下解释这一点吗？
我在某处读到，对于 2x2 列联表，计算优势比的公式和表达分析中的倍数变化是相同的。如果我错了，请纠正我。 
Fisher精确检验和差异基因表达分析之间有联系吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637387/fishers-exact-test-vs-differential-gene-expression</guid>
      <pubDate>Sun, 21 Jan 2024 13:30:08 GMT</pubDate>
    </item>
    <item>
      <title>将积分转换为某个事件的概率</title>
      <link>https://stats.stackexchange.com/questions/637386/converting-an-integral-into-a-probability-of-some-event</link>
      <description><![CDATA[假设 $X_1, X_2, .....X_n$ 是某个连续分布的独立同分布随机变量 $ F$。证明 $$\int_0^{\infty}(1-F(s+t))f(s)ds=\mathbb{P}(X_1&gt;X_2+t, X_2&gt; ;0)$$
$$$$考虑积分 $$\int_0^{\infty}(1-F(s+t)) f(s)ds=\int_0^{\infty}\mathbb{P}(X_1&gt;s+t)f(s)ds=\int_0^{\infty}\mathbb{P}(X_1&gt;X_2+t| X_2=s)f(s)ds=\int_0^{\infty}\mathbb{P}(X_1-X_2&gt;t|X_2=s)f(s)ds$$。现在我们知道 $X_1-X_2$ 和 $X_2$ 的联合密度由 $f_{X_1-X_2, X_2}(u, v)=f(u+v)f(v)$ 因此 $X_1-X_2|X_2=s$ 由 $$f_{X_1-X_2|X_2=s}(x)=(f(x +s)f(s))/f(s)=f(x+s)$$作为条件密度由关节和边缘的比率给出。所以 $$\mathbb{P}(X_1-X_2&gt;t|X_2=s)=\int_t^{\infty}f(x+s)dx$$因此 $$\int_0^{\infty}\mathbb{P}(X_1-X_2&gt;t|X_2=s)f(s)ds=\int_0^{\infty} \int_t^{\infty}f(x+s)f(s)dxds$$。但是$f(x+s)f(s)=f_{X_1-X_2, X_2}(x, s)$。所以 $$\int_0^{\infty}\mathbb{P}(X_1-X_2&gt;t|X_2=s)f(s)ds=\mathbb{P}(X_1- X_2&gt;t, X_2&gt;0)=\mathbb{P}(X_1&gt;X_2+t, X_2&gt;0)$$。
$$$$这个证明正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637386/converting-an-integral-into-a-probability-of-some-event</guid>
      <pubDate>Sun, 21 Jan 2024 13:18:27 GMT</pubDate>
    </item>
    <item>
      <title>随机变量函数的泰勒近似</title>
      <link>https://stats.stackexchange.com/questions/637385/taylor-approximation-for-function-of-a-random-variable</link>
      <description><![CDATA[假设我有一个随机变量 $\{1/2, a; 1/2, b\}$ 其中 $a, b \in \mathbb{R}_+$。
有一个函数$f$，其定义域是$\mathbb{R}_上的随机变量空间_ +$ 其范围为 $[0,1]$。此外， $f$ 是连续的，相对于一阶随机优势递增，并且具有 $I(\delta_d) = d$ 对于每个 $d \in \mathbb{R}_+$。
我的问题是，在对 $f(X)$ 进行线性泰勒近似时，其中 $X$&lt; /span&gt; 是一个随机变量，围绕一个确定性结果$d$，什么情况下允许写：
$f(X) \大约 f(d) + f&#39;(d) (E(X) - d)$？
我主要关心的是 $E(X)$ 部分，因为 $f$ 需要概率不是线性的，甚至可能是一个复合函数，例如 $f = \left(E[X^{1/2}] \right)^2$。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/637385/taylor-approximation-for-function-of-a-random-variable</guid>
      <pubDate>Sun, 21 Jan 2024 13:15:57 GMT</pubDate>
    </item>
    <item>
      <title>直接在样本上使用 ICA 的独立分量与在 PCA 降维后的特征上使用 ICA 混合矩阵的差异</title>
      <link>https://stats.stackexchange.com/questions/637383/differences-between-independent-components-from-ica-directly-on-samples-vs-mixi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637383/differences-between-independent-components-from-ica-directly-on-samples-vs-mixi</guid>
      <pubDate>Sun, 21 Jan 2024 13:06:06 GMT</pubDate>
    </item>
    <item>
      <title>分类报告中f1-score下的准确度值</title>
      <link>https://stats.stackexchange.com/questions/637380/accuracy-value-under-f1-score-in-classification-report</link>
      <description><![CDATA[考虑一下
y_true = [0, 1, 2, 2, 2]
y_pred = [0, 0, 2, 2, 1]
从 sklearn.metrics 导入分类报告
打印（分类报告（y_true，y_pred））

打印内容
 精确召回率 f1-score 支持

           0 0.50 1.00 0.67 1
           1 0.00 0.00 0.00 1
           2 1.00 0.67 0.80 3

    准确度 0.60 5
   宏观平均 0.50 0.56 0.49 5
加权平均 0.70 0.60 0.61 5

据我了解，准确度值不是特定于类的指标，而是一个全局指标，在所有类中计算，因此没有自己的精度、&lt;代码&gt;调用或&lt;代码&gt;支持。是否有任何特定原因导致它显示在f1-score列下，而不是在 precision第一列下？我还尝试向 classification_report 提供 output_dict = True 参数，它也只有一个 accuracy 键值。
classification_report（y_true，y_pred，output_dict = True）

打印内容
{&#39;0&#39;: {&#39;精度&#39;: 0.5,
  “回忆”：1.0，
  &#39;f1 分数&#39;: 0.66666666666666666,
  “支持”：1.0}，
 &#39;1&#39;: {&#39;精度&#39;: 0.0, &#39;召回率&#39;: 0.0, &#39;f1-score&#39;: 0.0, &#39;支持率&#39;: 1.0},
 &#39;2&#39;: {&#39;精度&#39;: 1.0,
  “回忆”：0.66666666666666666，
  “f1 分数”：0.8，
  “支持”：3.0}，
 “准确度”：0.6，
 &#39;宏平均值&#39;：{&#39;精度&#39;：0.5，
  “回忆”：0.5555555555555555，
  &#39;f1-分数&#39;：0.48888888888888893，
  “支持”：5.0}，
 &#39;加权平均值&#39;：{&#39;精度&#39;：0.7，
  “回忆”：0.6，
  &#39;f1-分数&#39;: 0.6133333333333334,
  “支持”：5.0}}

这只会让我认为 accuracy 行中的 support 值以及 accuracy 在报告字符串格式中的位置可能是巧合。是否有我遗漏的任何关系，或者这只是报告的打印方式？]]></description>
      <guid>https://stats.stackexchange.com/questions/637380/accuracy-value-under-f1-score-in-classification-report</guid>
      <pubDate>Sun, 21 Jan 2024 12:12:45 GMT</pubDate>
    </item>
    <item>
      <title>从 AdaBoost 返回不良异常值的目的是什么？</title>
      <link>https://stats.stackexchange.com/questions/637376/whats-the-purpose-by-returning-back-the-bad-outliers-from-adaboost</link>
      <description><![CDATA[假设您有一个包含数字和二进制数据的矩阵 $X$。您将数据 $X$ 插入 AdaBoost，AdaBoost 通过仅关注无法进行正确分类的行。
所以矩阵 $X$ 最终将包含属于异常值的行，对吗？
示例：
如果我在 $X$ 中有 10 行，并且其中只有两行分类不好，因为它们是“异常值”。我的 $X$ 最终会得到很多这两行，因为 AdaBoost 会大大增加它们的权重，因为它们的分类很糟糕。
如果它们的权重较大，则重新训练行的概率高于正确分类行的概率。]]></description>
      <guid>https://stats.stackexchange.com/questions/637376/whats-the-purpose-by-returning-back-the-bad-outliers-from-adaboost</guid>
      <pubDate>Sun, 21 Jan 2024 10:25:04 GMT</pubDate>
    </item>
    <item>
      <title>R中summary()和anova()结果的解释[重复]</title>
      <link>https://stats.stackexchange.com/questions/637375/interpretation-of-summary-and-anova-results-in-r</link>
      <description><![CDATA[我在理解 anova() 函数和 summary() 函数的使用差异时遇到一些困难。对于上下文，这是我正在研究的内容：
我正在使用 GLMM：
glmm_dogs2 &lt;- lmer(Den.Weeks ~ 人类 * 捕食者 + (1|packseasid)，数据 = 狗)
glmm_dogs3 &lt;- lmer(Den.Distance ~ 人类 * 捕食者 + (1|packseasid), data = dogs)
glmm_dogs4 &lt;- lmer(Pups.lost ~ 人类 + 捕食者 + Den.Distance + (1|packseasid), data = dogs)
我自己所依据的代码继续绘制残差并测试残差的正态性，然后使用 Anova(glmm_dogs2) 和 summary( glmm_dogs2)。然后我得到以下输出：
&lt;前&gt;&lt;代码&gt;方差分析(glmm_dogs2)
偏差表分析（II 型 Wald 卡方检验）
回复：Den.Weeks
              Chisq Df Pr(&gt;Chisq)
人类 2.1423 1 0.14329
捕食者 5.5678 1 0.01829 *
人类：掠食者 5.0390 1 0.02478 *
-------------
摘要（glmm_dogs2）
REML 拟合线性混合模型。 t 检验的使用
  萨特思韦特方法 [lmerModLmerTest]
公式：
Den.Weeks ~ 人类 * 掠夺者 + (1 | packseasid)
   数据：狗

REML 收敛准则：98.4

 缩放残差：
最小 1Q 中值 3Q 最大
-1.5586 -0.4267 -0.0769 0.6049 1.6837

随机效果：
 组名称方差标准差
 packseasid（拦截）1.015 1.008
 剩余 2.012 1.419
obs 数量：28，组：packseasid、11

固定效果：
               估计标准。误差df t值Pr(&gt;|t|)
（截距）9.9312 0.4444 14.2747 22.347 1.64e-12 ***
人类1 -2.3783 0.9541 20.1319 -2.493 0.02151 *
捕食者1 -3.6509 1.1213 18.7048 -3.256 0.00422 **
人类1：掠食者1 3.9813 1.7736 21.8223 2.245 0.03526 *
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
    (Intr) Humns1 Prdtr1
人类1 -0.255
捕食者1 -0.179 0.126
Hmns1:Prdt1 0.099 -0.579 -0.673

现在我有 Chisq 和 Pr(&gt;Chisq) 值，并且有 t 和 Pr(&gt;|t|) 值。根据Anova()，人类：捕食者之间的相互作用是显着的，掠夺者是显着的，而根据summary()，包括相互作用在内的所有术语都是显着的。
[旁注：我已经使用了 dredge(global_glmm) 函数来压缩 AIC，所以我的模型已经被简化，这个问题主要涉及我应该如何报告我的结果以及哪些变量我可以认为彼此之间有显着的相关性。]
我确实读到 Anova() 执行 II 型测试，summary() 执行 III 型测试，所以如果我理解正确，这意味着在这种情况下我应该使用 summary() 输出，因为人类：掠食者之间的重要相互作用。但是，如果summary()函数没有给我带来显着的结果，我应该使用Anova()结果吗？还是我误解了这一点？
仅供参考，下面是我构建的其他 GLMM 之一的结果，其中没有显着的交互作用；在这种情况下，我将在报告中使用 Anova() 结果，因为 summary() 没有显示任何显着的交互作用？
&lt;前&gt;&lt;代码&gt;方差分析(glmm_dogs3)
偏差表分析（II 型 Wald 卡方检验）
响应：密度距离
          Chisq Df Pr(&gt;Chisq)
人类 3.4109 1 0.06477 。
捕食者 0.0976 1 0.75467
人类：掠食者 1.3987 1 0.23694
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

&gt;摘要（glmm_dogs3）
REML 拟合线性混合模型。 t 检验的使用
萨特思韦特方法 [lmerModLmerTest]
公式：
Den.Distance ~ 人类 * 掠食者 + (1 | packseasid)
  数据：狗

REML 收敛准则：108.9

缩放残差：
 最小 1Q 中值 3Q 最大
-1.28514 -0.50117 -0.01259 0.56893 2.10258

随机效果：
 组名称方差标准差
 packseasid（拦截）2.554 1.598
 剩余 2.652 1.628
obs 数量：28，组：packseasid、11

固定效果：
                  估计标准。误差df t值Pr(&gt;|t|)
（截距）2.1269 0.6105 11.2745 3.484 0.00494 **
人类1 0.9035 1.1232 17.1159 0.804 0.43221
捕食者1 -0.7322 1.3067 15.6333 -0.560 0.58319
人类1：掠食者1 2.4991 2.1131 18.7481 1.183 0.25172
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
    (Intr) Humns1 Prdtr1
人类1 -0.211
捕食者1 -0.143 0.132
Hmns1:Prdt1 0.071 -0.586 -0.670
]]></description>
      <guid>https://stats.stackexchange.com/questions/637375/interpretation-of-summary-and-anova-results-in-r</guid>
      <pubDate>Sun, 21 Jan 2024 10:10:57 GMT</pubDate>
    </item>
    <item>
      <title>关于线性回归的疑问[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637373/doubt-regarding-linear-regression</link>
      <description><![CDATA[我读过并被告知，如果在线性回归问题中，回归方程 Y= mX +N + E 中的误差 E 归因于 Y 是随机变量。如果 Y 不是随机变量且具有确定性，则点 (X,Y) 将位于回归线上。
我不明白的是，即使 Y 不是随机的，通过多对 (X,Y) 拟合一条直线不会导致某些点位于回归线上方或下方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637373/doubt-regarding-linear-regression</guid>
      <pubDate>Sun, 21 Jan 2024 09:38:47 GMT</pubDate>
    </item>
    <item>
      <title>比较组时平均比例差异的统计显着性</title>
      <link>https://stats.stackexchange.com/questions/637372/statistical-significance-for-difference-in-mean-proportions-when-comparing-group</link>
      <description><![CDATA[我可能没有准确地描述我的问题，但我希望我能用下面的例子来说明它。
假设我有 $m$ 列联表：

&lt;表类=“s-表”&gt;
&lt;标题&gt;


第 1 列
第 2 栏
总计


&lt;正文&gt;

第 1 行
$a_i$
$b_i$
$a_i+b_i$


第 2 行
$c_i$
$d_i$
$c_i+d_i$


总计
$a_i+c_i$
$b_i+d_i$
$N$




其中$a_i+b_i+c_i+d_i=N,i=1,2,\dots,m$。对于每个表，令 $p_{1i}=\frac{a_i+b_i}{N}, p_{2i}=\frac{a_i+c_i}{N}$，$p_{1i}-p_{2i}$ 的标准误差由下式给出
$$se(p_{1i}-p_{2i})=\frac{1}{N}\sqrt{b_i+c_i-\frac{(b_i-c_i)^2 {N}}.$$
自从
$$
Var\left({{p_{1i}}-p_{2i}}\right)={Var(p_{1i})+Var(p_{2i})}- {2Cov(p_{1i},p_{2j) })}=\frac{1}{N^2}\left(b_i+c_i-\frac{(b_i-c_i)^2}{N}\right)。
$$
然后我可以对原假设 $p_{1i}=p_{2i}$ 进行显着性检验，假设原假设为真，标准错误简化为
$$
se(p_{1i}-p_{2i})=\frac{1}{N}\sqrt{b_i+c_i},
$$
检验统计量为
$$
z=\frac{p_{1i}-p_{2i}}{se(p_{1i}-p_{2i})}=\frac{b_i-c_i}{\sqrt{b_i+c_i}}。
$$
我的问题
如何进行以下测试？
$$H_0:\frac{\sum_{i=1}^m{p_{1i}}}{m}=\frac{\sum_{i=1}^m{ p_{2i}}}{m}$$
$$H_1:\frac{\sum_{i=1}^m{p_{1i}}}{m}\not=\frac{\sum_{i=1}^ m{p_{2i}}}{m}$$
事实上，每一对 $(p_{is},p_{jt}) $ 都是相关的， $i,j \in\{1,2\}, 1\le s,t \le m$，我还可以获得每对对应的所有列联表。同样，我可以计算 $\frac{\sum_{i=1}^m{p_{1i}}-p_{2i}}{m}$ 确定它们的协方差矩阵后，
$$
Var\left({\sum_{i=1}^m{p_{1i}}-p_{2i}}\right)=\sum_{i=1}^m \left({Var(p_{1i}) +Var(p_{2i})}\right)+{2\sum_{1\le i&lt; j \le m}\left({Cov(p_{1i},p_{1j})+Cov(p_{2i},p_{2j})}\right)} - {2\sum_{1\le i \ le j \le m}{Cov(p_{1i},p_{2j})}}
$$
假设原假设为真，我如何简化它。我可以直接使用它而忽略 ${\sum_{i=1}^m{b_{i}}}={\sum_{i=1}^m{c_ 的条件吗{i}}}$。
与我的问题相关的任何其他测试方法或文章/书籍都可以。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637372/statistical-significance-for-difference-in-mean-proportions-when-comparing-group</guid>
      <pubDate>Sun, 21 Jan 2024 07:09:09 GMT</pubDate>
    </item>
    <item>
      <title>Box-Cox变换公式</title>
      <link>https://stats.stackexchange.com/questions/637369/box-cox-transformation-formula</link>
      <description><![CDATA[我正在阅读一些有关 Box-Cox 转换的资源。我找到的几乎所有网站都给出了变换公式的公式为
$$y^{(\lambda )} =\begin{cases}\frac{y^\lambda-1}{\lambda}&amp;\lambda \neq 0 \cr \ln y&amp;\lambda =0\end{cases}.$$
但是，它们后面通常会跟一个表格，给出非常简单的转换，如 $$y^{(\lambda)}=y^{\lambda}$$
例如，$\lambda=2$表示转换后的数据为$y^2$； $\lambda=-1$ 表示转换后的数据为 $\frac{1}{y}$等。请参阅此处的链接： Box-Cox转型
我只是很困惑应该使用哪个公式进行转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/637369/box-cox-transformation-formula</guid>
      <pubDate>Sun, 21 Jan 2024 05:15:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算样本量？如何影响样本量？</title>
      <link>https://stats.stackexchange.com/questions/637367/how-to-calculate-sample-size-how-to-affect-sample-size</link>
      <description><![CDATA[我们正在尝试确定我们研究的样本量。我们正在与群体进行比较。第 1 组将接受治疗，第 2 组不接受治疗。从之前的研究中我们知道，第 1 组的治疗复发率为每例 1%，第 2 组的复发率为每例 6%。
我通过比较比例对样本大小进行了测试（比例推断：比较两个独立样本，https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html）。我使用了之前研究中的比例，第 1 组 0.01，第 2 组 0.06。据计算，我们每组需要 211 名患者。如果我们收集 211 名患者，将花费太多的时间和资源。
对于我们来说，每组收集大约 40-60 名患者是现实的。还有其他可能性吗？我可以使用效果大小吗？我该如何计算它？]]></description>
      <guid>https://stats.stackexchange.com/questions/637367/how-to-calculate-sample-size-how-to-affect-sample-size</guid>
      <pubDate>Sun, 21 Jan 2024 04:37:24 GMT</pubDate>
    </item>
    <item>
      <title>卡林-鲁宾定理：具有 MLR 属性的检验统计量与充分性检验统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</link>
      <description><![CDATA[假设我们正在尝试比较单个参数 $\theta$ 的两个假设。原假设 $H_0$ 是 $\theta = \theta_0$，替代假设是 &lt; span class=&quot;math-container&quot;&gt;$\theta ≥ \theta_0$。
据我所知，卡林-鲁宾定理告诉我们，如果存在这样一个统计量 $T(X)$，它具有单调性似然比（MLR）属性，意味着函数
$$
\frac{P\left(T(X)|\theta_1\right)}{P\left(T(X)|\theta_0\right)}
$$
在$T$中是单调非递减的，我们可以通过基于$T(X)$。
问题：$T(X)$ 是 MLR 和  之间有什么关系$T(X)$ 是一个足够的统计数据吗？

卡林-鲁宾定理是否要求 $T(X)$ 也足够，或者只是 MLR？
对于成为 MLR 和充分性有什么影响吗？

我们是否有足够的 MLR $\to$ 和/或足够的 $\to$ MLR？ 


关于 MLR 和最小足够怎么样？

我们是否有足够的最低 $\to$ MLR 和/或 MLR $\to$ 最低限度够了吗？


这些事情有任何关联吗？

简而言之，我在这里看到很多帖子讨论卡林-鲁宾定理设置中的足够统计量，但当我阅读它时，MLR 属性似乎是真正重要的标准。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</guid>
      <pubDate>Sat, 20 Jan 2024 19:47:12 GMT</pubDate>
    </item>
    </channel>
</rss>