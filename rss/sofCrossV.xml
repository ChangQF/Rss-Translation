<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Feb 2025 09:18:58 GMT</lastBuildDate>
    <item>
      <title>时间序列模型 - 基于机器学习与传统方法 - 具有变化趋势和附加特征的案例</title>
      <link>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</link>
      <description><![CDATA[我是时间序列领域的新手，一直在阅读相关资料。似乎没有压倒性的共识支持使用 ML 或经典方法解决预测问题。ML 方法似乎在较高频率的时间序列或具有较高时间步长的时间序列中效果很好。但经典方法通常具有良好的预测性能。
我也在阅读 FB 的先知模型预印本，其中声称在许多业务问题中存在复杂的季节性模式和变化趋势。此外，可能还有更多特征可以为时间序列提供信息。例如，预测股票的回报可能需要其滞后交易量、价格的每周移动平均值等。
由于时间序列对时间的条件均值的非线性依赖，基于 ML 的方法（例如 xgboost）可以有效地捕获它。此外，在 ML 模型中包含其他特征是非常自然的。因此，直觉上，我会认为 ML 模型在各种业务预测问题中的表现都会优于传统模型。
那么，为什么对于许多业务问题，传统模型仍然优于 ML 模型呢？从经验丰富的预测从业者/专家那里获得见解会很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</guid>
      <pubDate>Mon, 03 Feb 2025 08:50:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么添加截距会改变 python 中的 roc_auc_score？</title>
      <link>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</link>
      <description><![CDATA[为什么在 python sklearn 中添加常数会改变 ROC AUC 的值？
import pandas as pd
from sklearn.datasets import make_classification
import statsmodels.api as sm
from sklearn.metrics import roc_auc_score

X, y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, random_state=1)
X_const = sm.add_constant(X)

model1 = sm.Logit(y, X).fit()
model2 = sm.Logit(y, X_const).fit()

y_pred = model1.predict(X)
y_pred_c = model2.predict(X_const)

print(roc_auc_score(y, y_pred))
print(roc_auc_score(y, y_pred_c))

结果：
0.9425059793021525
0.9424627792866007
]]></description>
      <guid>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</guid>
      <pubDate>Mon, 03 Feb 2025 08:40:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么不直接使用样本的可能性作为检验统计量呢？</title>
      <link>https://stats.stackexchange.com/questions/660889/why-not-just-use-the-likelihood-of-a-sample-as-a-test-statistic</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但我有点困惑。
假设我们有一个随机变量$x_n = {x_1, x_2, ..., x_n}$的 iid 样本，并且该变量是离散的，因此概率$P(X=x_i)$是明确定义的。现在我们进行某种假设检验，并计算检验统计量 $t_n = T(x_n)$，然后询问，在给定一些关于 $t_n$ 分布方式的假设 $H_0$ 的情况下，观察到比 $t_n$ 更极端的统计量 $t_n&#39;$ 的概率是多少，例如
$$\rho = P(t_n&#39; &gt; t_n | H_0)$$
相当公平。但是假设我们让 $T = P(x|H_0)$，其中由于 $X_i$ 假设为 iid，我们有
$$P(x_n|H_0) = \prod_{i=1}^n P(X=x_i|H_0)$$
然后我们可以通过询问其他样本 $x_n&#39;$ 比 $x_n$ 更有可能的概率来形成一个测试。
$$\rho = \frac{\#\text{ of }x_n&#39;\text{ where } P(x_n&#39;|H_0) &gt; P(x_n|H_0)}{\text{total } \# \text{ of possible } x_n&#39;} $$
我的问题是，为什么这不是一个好的假设检验（如果计算复杂性不是问题）。优点是，如果我们已经知道如何计算$P(X|H_0)$，那么我们不需要做任何进一步的工作来得出某些统计数据的抽样分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660889/why-not-just-use-the-likelihood-of-a-sample-as-a-test-statistic</guid>
      <pubDate>Mon, 03 Feb 2025 03:00:19 GMT</pubDate>
    </item>
    <item>
      <title>关于 IID 随机变量的有限集合和事件的有限集合的“填充概率”的一般公式</title>
      <link>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</link>
      <description><![CDATA[背景
给定一个有限 IID 离散随机变量集合 $\{X_i\}_{i=1}^n$，其概率质量函数为 $\Pr$，以及一组有限事件 $S = \{ E_j \}_{j=1}^m$，填充概率是至少观察一次 $E_j$ 的概率。
我认为填充概率与分配问题相关，在分配问题中，人们感兴趣的是增加 $n$，以便所有目标 $m$ 事件可能（在一定风险承受能力下）达到通过。
假设我得到了正确的表达式，我打算编写一个轻量级的 Python 包，使用 Rust 扩展，根据 $n$、$m$ 和 $S$ 中每个事件的概率来计算这个数量。
目标
我想要这个填充概率的通用公式。让我展示一下我的工作，以防我犯了错误。
尝试
首先，我认为定义一个事件 $A_j$ 会很有用，它是 不 观察事件 $E_j$ 的事件。我认为$\Pr \left[ \bigcup_{j=1}^m A_j \right]$对这个问题很有用，因为它符合我的直觉，即至少一个事件缺失的概率。所以我的计划是实现这个结果：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - P\left(\bigcup_{j=1}^m A_j\right)$$
接下来我可以使用包含-排除原理将这个概率分解为一个有限和：
$$P\left(\bigcup_{j=1}^m A_j\right) = \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k})$$
这给我们留下了计算联合概率的任务。我希望它们可以像这样计算：
$$P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k}) = \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n$$
然后我们最终可以像这样计算填充概率：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n
$$
问题

我犯了什么错误吗？
有没有更好的方法？
有没有比“填充概率”更常规的名称？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</guid>
      <pubDate>Sun, 02 Feb 2025 22:55:55 GMT</pubDate>
    </item>
    <item>
      <title>数据聚合方面的困惑</title>
      <link>https://stats.stackexchange.com/questions/660884/confusion-on-aggregation-of-data</link>
      <description><![CDATA[我有一组约 7500 场比赛结果的数据集。每场比赛只有两名参赛者，我正在查看两个起跑站之间的获胜率差异，并尝试按不同组别（男性比赛与女性比赛、经验水平、生理因素等）进行划分。
我使用二项分布累积概率函数来表明，如果两个站的获胜率是 50:50，则总体获胜率差异的可能性很小，但除此之外，我感到很困惑。与我在网上找到的示例不同，计算获胜率差异需要进行一些汇总（而不是人口身高或在网站上花费的时间）。
我希望能够说，在获胜率方面，性别/经验水平/体重存在/不存在统计差异。为此，我认为我需要使用 t 检验/方差分析。但要计算获胜率的差异，我需要以某种方式进行汇总。到目前为止，我都是按年份进行操作的，所以我计算每年的胜率差异，然后将其用于我的测试。但我想知道这是否会隐藏一些信息。但如果我想计算总体（所有年份）的胜率差异，我只剩下一个数字，我认为这意味着方差分析不起作用？令人困惑的是，使用按年份计算的胜率差异时的 p 值为 0.0016，按日期聚合时为 3.2。所以改变聚合级别肯定是有作用的！
我可以把最细的粒度级别降低到日级别，这样我就可以得到每天的胜率差异。我应该这么做吗？
或者我完全走错了路，应该使用不同的测试]]></description>
      <guid>https://stats.stackexchange.com/questions/660884/confusion-on-aggregation-of-data</guid>
      <pubDate>Sun, 02 Feb 2025 19:51:25 GMT</pubDate>
    </item>
    <item>
      <title>约翰森测试条件</title>
      <link>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</link>
      <description><![CDATA[我当时正在 Goldkamp Cointegration for Time Series Analysis on medium.
作者提到，对于具有 $k$ 个不同序列的 VAR 过程，我们不能有 $k$ 个有效的协整关系。我的思路是，对于$k=2$：两个有效的协整关系意味着存在$\beta_1$和$\beta_2$，使得$y_t-\beta_1x_t$和$x_t-\beta_2y_t$都是$I(0)$。所以，这似乎有点多余。
只是想澄清我的推理是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</guid>
      <pubDate>Sun, 02 Feb 2025 19:17:46 GMT</pubDate>
    </item>
    <item>
      <title>有序回归（分类预测变量）的样本大小计算</title>
      <link>https://stats.stackexchange.com/questions/660878/sample-size-calculation-for-ordinal-regression-categorical-predictor</link>
      <description><![CDATA[如果您能为我提供一些公式/代码来计算 R 中有序回归的样本量，我将不胜感激。
我有一个 3 级有序结果变量（轻度、中度、重度）和一个分类预测因子（不利、有利），所以我的预测因子不是连续的。我预计结果和预测因子之间存在关联，因为“不利”与更严重的结果相关。
目标是找到一个具有 80% 功效和 0.25 F^2 效应大小的样本量。我更愿意通过模拟来计算样本量。
我了解 R 的基础知识，但我不是专业人士，所以我在搜索网站和完全理解代码方面遇到了麻烦。
提前感谢您的建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/660878/sample-size-calculation-for-ordinal-regression-categorical-predictor</guid>
      <pubDate>Sun, 02 Feb 2025 18:23:05 GMT</pubDate>
    </item>
    <item>
      <title>限制高斯 S 型函数期望的近似误差</title>
      <link>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</link>
      <description><![CDATA[我想限制$\mathbb{E}_x[\sigma(x)],$的近似误差 $\sigma(x):=1/(1+\exp(-x)),$ $x\sim\mathcal{N}(\mu,v)$:
$$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{\sigma^{(k)}(\mu)}{k!}\mathbb{E}[(x-\mu)^k].$$
由于$\mathbb{E}[(x-\mu)^k]=v^k(k-1)!!,$ 这简化为 $$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{v^k\sigma^{(k)}(\mu)}{k!!}.$$
事实上，看起来 $\frac{\sigma^{(k)}(\mu)}{k!!}$ 发散，但这意味着期望发散，而我真的不这么认为。我哪里做错了？
编辑：看来方差在这里至关重要，对于 .05 左右及以下的值，项（至少最多 140 个项，这是我可以计算而不会溢出的极限）不会爆炸。这种期望确实只存在于某些方差中吗？对我来说似乎违反直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</guid>
      <pubDate>Sat, 01 Feb 2025 23:55:33 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是参数检验还是非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</link>
      <description><![CDATA[也许这是一个微不足道的问题，但我一直收到一些相互矛盾的信息，这让我有些困惑。
首先，关于参数检验和非参数检验之间的区别似乎存在一些相互矛盾的信息。即，

一些来源表明参数检验对样本所来自的总体分布的参数做出假设
其他来源表明参数检验仅适用于正态分布的数据

我个人认为第一个说法是正确的，而不是后者，但我希望对此有清晰的认识。
如果第一点是正确的，这就引出了我的第二个问题。我看到多个来源都这么说：

卡方检验是一种非参数检验（a、b、c）

但是我想知道为什么卡方检验是非参数的，如果像 Z 检验、t 检验、ANOVA 等参数检验一样，它假设总体分布遵循特定分布，不是吗？我认为卡方检验假设检验统计量来自卡方分布，因此由于它做出了分布假设，所以它是参数化的。但我肯定是误解了什么。有人能帮忙澄清一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</guid>
      <pubDate>Sat, 01 Feb 2025 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>与子集相比，glmer() 模型中固定效应对较大数据集的放大作用</title>
      <link>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
#pooled data (no subsets) -- best model 
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W), family = Gammma(link = &quot;log&quot;), data = d)
#scale(X)estimate = -1.1341, pval ~0
#Random effects: Z variance = 1.76056, Z Std. dev = 1.3269; W variance = 0.09249, W Std. dev = 0.3041 

#数据子集 -- 最佳模型 
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q), family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329, Z Std. dev = 0.2476; Q 方差 = 0.020675, Q Std. dv = 0.1438 

#注意：Q 和 W 都以略有不同的单位来测量时间。

我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化，并以某种方式放大了固定效应，即使这种关系不是那么强？但是那些随机效应是有意义的并且包含结构，所以我不想忽视这一点。有什么建议或资源可以解决吗？
编辑：我还使用 allFit() 来调查收敛问题是否非常成问题，但事实并非如此，所以我尝试使用未转换的数据，结果相同。
编辑以回应评论：是的，我的工作流程中有模型选择，示例模型是最佳选择的模型。有 3 个子集 - 所有 3 个都按预期运行并预测平坦关系。一个子集有 379 个数据点，另一个有 213 个，另一个有 768 个。所有估计值都是正的但小于 1 - 最大的子集具有最强的关系。时间变量都是分类的，不是问题。至于缩放，唯一的数字预测器（X）已经缩放。收敛问题是由于（我认为）数据点非常小的问题；未转换的最低值为 0.0003，这对于 Gamma 分布来说可能略显不稳定]]></description>
      <guid>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:49:22 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>如何使用引导程序处理大规模文本匹配和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</link>
      <description><![CDATA[我有一个大型数据库，其中有一个字符列，其中包含数百万个产品描述。我有一个参考表，其中有一个字符列，其中包含我试图匹配的描述。我将使用 EXACT 匹配、IN 匹配和最终的 Levenshtein 距离进行匹配。然后我想计算匹配次数。有时会出现错误匹配，例如参考词包含在一个不匹配的大词中，这更像是参考数据的异常。所以我还想在组合中添加不确定性。我不会在完成后检查所有匹配，因为匹配实在太多了。
我对此有两个疑问：

我知道如何进行匹配。这不是问题。我想计算匹配次数，并说我们怀疑 3 月份有 200 次匹配。我们不知道误报率，但它很小（我们怀疑）。参考列表由另一个部门保存。假阳性可能由包含单词的产品引起，例如 shoe 可能包含在 Shoehorn 中。引导捆绑是一种我可以使用的方法吗？逐月从数据库中提取数据，然后应用匹配。这将为我提供该月的总匹配数，然后从每月样本中进行引导（10k 个案例 5000 次，并将这些案例相加并计算置信区间。

假设 A 是正确的。在理想情况下，我会这样做，其中一行包含一个产品实例。但是数据库很大。是否可以先在数据库中聚合 Shoehorn - 100 个匹配项。然后进行引导。这不会给我一个完全不同的答案吗，因为抽样不再在 100 个匹配项中随机抽样，它会将 Shoehorn - 100 个匹配项作为单个记录进行抽样。


所以我的问题是第一点是否是解决这个问题的有用方法，第二点是关于如何聚合数据对置信区间的有效性的影响。
下面是一些 R 代码，它生成数据的两种方法出现
# 加载必要的库
library(dplyr)

# 生成逐行数据 ----------------------------------------------------------
# 生成具有随机卷的虚假产品描述数据
set.seed(123)
descriptions &lt;- c(
&#39;红色鞋子&#39;, &#39;蓝色衬衫&#39;, &#39;绿色鞋带&#39;, &#39;黄色鞋拔&#39;, 
&#39;黑色帽子&#39;, &#39;白色鞋子&#39;, &#39;粉色衬衫&#39;, &#39;灰色帽子&#39;, 
&#39;紫色鞋拔&#39;, &#39;橙色鞋带&#39;
)
volumes &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)

product_descriptions &lt;- data.frame(
ProductID = unlist(lapply(1:10, function(i) rep(i, volumes[i]))),
Description = unlist(lapply(1:10, function(i) rep(descriptions[i], 
volumes[i]))),
Volume = unlist(lapply(1:10, function(i) rep(volumes[i], 
volumes[i])))
)

# 随机抽取 5000 行并替换以生成 
# 逐行乘积
set.seed(456) # 设置种子以实现可重复性
line_by_line_df &lt;- product_descriptions %&gt;%
sample_n(5000, replace = TRUE) |&gt; 
mutate(ProductID = row_number()) %&gt;% 
mutate(match = sample(0:1, n(), replace = TRUE))

# 生成聚合数据 -------------------------------------------------
# 在这里我们从“数据库”中提取数据并聚合计数 
# 在数据库中
aggregated_df &lt;- line_by_line_df |&gt; 
group_by(Description) |&gt; 
summarise(total_products = sum(Volume),
matches = sum(match))

]]></description>
      <guid>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</guid>
      <pubDate>Sun, 12 Jan 2025 12:03:38 GMT</pubDate>
    </item>
    <item>
      <title>msm 包：'vmmin' 中的多状态模型初始值不是有限的</title>
      <link>https://stats.stackexchange.com/questions/646057/msm-package-mutlti-state-model-initial-value-in-vmmin-is-not-finite</link>
      <description><![CDATA[我是 msm 包和马尔可夫模型的新手。我有一个随机试验数据集，其中包含三个时间点的读数：基线、1 年和 2 年。我试图计算以下两种情况下每种状态的年度转变概率和平均恢复时间。

NGT 到 iIFG 以及回归到 NGT 或进展到糖尿病（即 NGT &lt;-&gt; iIFG -&gt; 糖尿病）
NGT 到 iIFG 到糖尿病（即 NGT -&gt; iIFG -&gt; 糖尿病）

状态是血糖状态（NGT（状态=1）、iIFG（状态=2）和糖尿病（状态=3））。糖尿病是吸收状态。
这是我的数据的样子。请注意，并非所有参与者都有所有 3 个时间点的读数，但他们都至少有 2 个时间点的读数（基线和 1 年）。df 中没有 NA 值。时间以年为单位。我将基线读数的时间设置为 0。
例如显示一些行。
participant_num | 时间 |状态
2 0.0000000 2 
2 2.0123203 3 
3 0.0000000 1 
3 1.0157427 1 
3 2.0123203 1 
4 0.0000000 2 
4 1.0157427 2 
4 2.0123203 3 
5 1.0157427 2 
5 2.0123203 2 
7 0.0000000 1 
7 1.0157427 1 
7 2.0123203 2 
8 0.0000000 2 
8 1.0157427 2 
8 2.0123203 2 
9 0.0000000 2 
9 1.0157427 1 
9 2.0123203 1 
10 0.0000000 2 
10 1.0157427 1 
10 2.0123203 1

m1 &lt;- statetable.msm(state, party_num, data=df)
m1

to
from 1 2 3
1 269 195 6
2 162 626 58
3 0 1 42

summary(df$time)

最小值 第 1 区 中位数 平均值 第 3 区 最大值
0.000 0.000 1.185 1.039 2.012 2.585 

##场景 1：NGT &lt;-&gt; iIFG -&gt;糖尿病
trans_mat &lt;- matrix(c(1, 1,1,
1, 1, 1,
0, 0, 0),
nrow = 3, byrow = TRUE)
rownames(trans_mat) &lt;- colnames(trans_mat) &lt;- c(&quot;NGT&quot;, &quot;iIFG&quot;, &quot;Diabetes&quot;)

NGT iIFG 糖尿病
NGT 1 1 1
iIFG 1 1 1
糖尿病 0 0 0

mm &lt;- msm(state ~ time, subject=participant_num, data=df, deathexact=TRUE, gen.inits = TRUE, qmatrix=trans_mat)

optim 中的错误(method = &quot;BFGS&quot;, control = list(), par = c(qbase = -0.943801885337371, : 
&#39;vmmin&#39; 中的初始值不是有限的

我应该如何解决这个问题？我的 trans_mat 错了吗？还是我的数据格式错了？我将不胜感激任何帮助和建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646057/msm-package-mutlti-state-model-initial-value-in-vmmin-is-not-finite</guid>
      <pubDate>Sun, 28 Apr 2024 23:30:54 GMT</pubDate>
    </item>
    <item>
      <title>统计检验比较两组之间的 beta 分布</title>
      <link>https://stats.stackexchange.com/questions/642559/statistical-test-to-compare-beta-distributions-between-two-groups</link>
      <description><![CDATA[我不确定我使用的术语是否正确，但希望代码和图表能够很好地解释这一点。我有两组中的六个样本。样本 1、2 和 3 属于第 1 组，样本 4、5、6 属于第 2 组。所有样本都符合 beta 分布。我想使用统计检验来解释两组之间的差异，而不仅仅是使用平均值。这是它的代码。
set.seed(123)
params &lt;- list(c(1, 9), c(2, 18), c(3, 27), c(6, 4), c(9, 6), c(12, 8))
df &lt;- as.data.frame(matrix(ncol = 6, nrow = 500))
colnames(df) &lt;- paste(&quot;Sample&quot;, 1:6, sep = &quot;_&quot;)
for(i in 1:6) { df[,i] &lt;- rbeta(500, params[[i]][1], params[[i]][2]) }

]]></description>
      <guid>https://stats.stackexchange.com/questions/642559/statistical-test-to-compare-beta-distributions-between-two-groups</guid>
      <pubDate>Thu, 14 Mar 2024 04:00:39 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归与朴素贝叶斯和随机森林</title>
      <link>https://stats.stackexchange.com/questions/593990/logistic-regression-vs-naive-bayes-and-random-forest</link>
      <description><![CDATA[我有一个高维不平衡数据集。该数据集是一个分类数据集，我应用标签编码器将分类值转换为数值。该数据集是一个表格数据集。我还使用均值插补方法来插补缺失值。我在训练集上使用过采样技术，并获得了逻辑回归的预测召回率约为 0.800。我使用了其他分类器，如朴素贝叶斯、随机森林，但没有获得如此高的预测准确率。
我使用 weka 软件进行数据训练。
我的问题是，为什么我的逻辑回归准确率很高，而其他分类器却没有？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/593990/logistic-regression-vs-naive-bayes-and-random-forest</guid>
      <pubDate>Sat, 29 Oct 2022 23:47:05 GMT</pubDate>
    </item>
    </channel>
</rss>