<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 30 Aug 2024 03:18:03 GMT</lastBuildDate>
    <item>
      <title>贝塔分布的动机是什么？</title>
      <link>https://stats.stackexchange.com/questions/653596/what-is-the-motivation-of-the-beta-distribution</link>
      <description><![CDATA[Beta 分布的动机是什么？
Morris H. DeGroot 所著《概率与统计》中的定义
设 $\alpha, \beta&gt;0$，设 $X$ 为具有 p.d.f. 的随机变量。
$$
f(x| \alpha, \beta) = \begin{cases} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1} &amp;0&lt;x&lt;1\\
0 &amp;\text{otherwise} \end{cases}
$$
那么 $X$ 具有 beta 分布，其参数为 $\alpha$ 和 $\beta$。
在我读过的大多数教科书中，它都是用 p.d.f 定义的。然而，我们无法知道定义背后的动机和直觉。科学家为什么会提出这个建议？
我认为这对对此感兴趣的人来说非常重要。
请参阅https://math.stackexchange.com/q/4964602/1149986]]></description>
      <guid>https://stats.stackexchange.com/questions/653596/what-is-the-motivation-of-the-beta-distribution</guid>
      <pubDate>Fri, 30 Aug 2024 01:56:43 GMT</pubDate>
    </item>
    <item>
      <title>PC算法产生的DAG是否具有明确的因果关系？</title>
      <link>https://stats.stackexchange.com/questions/653595/is-the-dag-produced-by-pc-algorithm-definitively-causal</link>
      <description><![CDATA[我们知道，以 DAG 表示的贝叶斯网络 (BN) 的结构不一定具有因果性，而因果贝叶斯网络 (CBN) 的结构则具有因果性。问题是，我们如何获得这个 DAG？对同一数据集应用不同的方法可以产生不同的 DAG — — 有些具有因果性，有些则没有。PC 算法是一种常用的方法。因此，问题很简单：PC 算法生成的 DAG 是否具有明确的因果性？
抱歉，这看起来像是一个如此愚蠢的问题，但我确实想了很久，却想不出答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/653595/is-the-dag-produced-by-pc-algorithm-definitively-causal</guid>
      <pubDate>Fri, 30 Aug 2024 01:53:51 GMT</pubDate>
    </item>
    <item>
      <title>在零一膨胀贝塔中选择混合参数</title>
      <link>https://stats.stackexchange.com/questions/653594/choosing-mixing-parameter-in-zero-one-inflated-beta</link>
      <description><![CDATA[我正在处理一个问题，我需要根据大小为 $n$ 的样本比例 ($f$) 对 (独立) 人口比例 ($p$) 进行建模。我为此选择了 beta 分布：
$$ p \sim Beta[fn,(1-f)n]$$
有时，我观察到样本比例等于 1 或 0。对于这些情况，beta 分布始终返回 0 或 1，因此，这些情况不能很好地适应模型。为了解决这个问题，我决定加入 Jeffreys 的先验（将样本计数增加 0.5）。但是，人口比例等于 0（或 1）仍有可能成为样本比例为 0（或 1）的原因。我读过关于这个主题的文章，并找到了零一膨胀的 beta 模型（例如，对于 $f=1$）：
$$ p \sim \omega + (1-\omega)Beta(n+0.5,0.5) $$
我的问题是，如何选择混合参数 $\omega$？您能否给出一些见解，看看我的想法是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/653594/choosing-mixing-parameter-in-zero-one-inflated-beta</guid>
      <pubDate>Fri, 30 Aug 2024 01:34:04 GMT</pubDate>
    </item>
    <item>
      <title>描述辛普森多样性的概率分布</title>
      <link>https://stats.stackexchange.com/questions/653592/probability-distribution-describing-simpsons-diversity</link>
      <description><![CDATA[假设群落中有 $n$ 种丰度未知的物种。每种物种的比例为 $p_i$，即 $\sum_ip_i = 1$。辛普森多样性定义为 $S = \sum_ip_i^2$，最大值为 1，最小值为 $1/n$。
如果我们从这个种群中抽取样本，我相信我们观察到的每种物种的比例将被理解为来自 $n$ 维狄利克雷分布 $D(p_1, p_2, ... p_n)$。鉴于这种分布，有没有办法推导出多样性指数$S$的概率分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/653592/probability-distribution-describing-simpsons-diversity</guid>
      <pubDate>Fri, 30 Aug 2024 00:58:32 GMT</pubDate>
    </item>
    <item>
      <title>使用相同的独立变量模拟合成控制因变量是一种有效的方法吗？</title>
      <link>https://stats.stackexchange.com/questions/653591/is-simultaing-the-synthetic-control-dependent-variables-with-the-same-independen</link>
      <description><![CDATA[我正在做一个合成控制，但我有一些数据限制。
我正在为 A 国（处理单位）的一个城市做一个合成控制，为了模拟控制组，我有 B 国多个城市的数据。但是，我只有 B 国城市在国家层面的相关数据。也就是说，我使用 B 国的多个城市为合成器使用了很多“因变量”，但我只能在国家层面对每个国家使用相同的“自变量”。
这对合成控制来说是个问题还是一种有效的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653591/is-simultaing-the-synthetic-control-dependent-variables-with-the-same-independen</guid>
      <pubDate>Fri, 30 Aug 2024 00:56:09 GMT</pubDate>
    </item>
    <item>
      <title>如何可视化多元线性回归中一个预测变量的值</title>
      <link>https://stats.stackexchange.com/questions/653590/how-to-visualise-the-value-of-one-predictor-in-a-multiple-linear-regression</link>
      <description><![CDATA[我希望确认我的方法在统计上是否正确/直接，以及是否有任何参考资料支持这种关于如何可视化多元线性回归输出的思路...
我正在运行多元线性回归，其中我有一个连续响应变量（log10-volume），由连续变量（分数）预测。我在模型中加入了三个干扰协变量（年龄 [连续]、头部大小 [连续] 和组 [序数]），因为我感兴趣的是分数是否在考虑年龄、头部大小和组的影响后预测了 log10-volume。公式（抱歉，R 符号）如下所示：
log10-volume ~ 分数 + 年龄 + 头部大小 + 组
我采取的方法是首先保存多元线性回归的残差，其中 log10-volume 由这些干扰协变量（年龄、头部大小和组）预测：
log10-volume ~ 年龄 + 头部大小 + 组
然后，我在 y 轴上绘制这些残差，在 x 轴上绘制分数（公式如下）：

残差（log-10 体积）~ 分数
我几天后我会在一次演示中展示这些图表，我只是想确认这些图表是否正确地可视化了在考虑了这些干扰协变量的影响后，分数是否预测了 log10 体积。
谢谢阅读！]]></description>
      <guid>https://stats.stackexchange.com/questions/653590/how-to-visualise-the-value-of-one-predictor-in-a-multiple-linear-regression</guid>
      <pubDate>Fri, 30 Aug 2024 00:55:36 GMT</pubDate>
    </item>
    <item>
      <title>可以从梯度提升模型 CatBoost 和 XGBoost 中获得概率预测吗？</title>
      <link>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</link>
      <description><![CDATA[我正在寻找使用 CatBoost 或 XGBoost 对连续目标变量（位于 [0, 1] 中，即比例）进行概率预测（$\Pr(Y\mid X=x)$）。我可以使用官方库来生成概率预测，而不是 $E[Y\mid X=x]$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</guid>
      <pubDate>Thu, 29 Aug 2024 17:18:07 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的时间序列预测问题</title>
      <link>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</link>
      <description><![CDATA[我正在开展一个 Python 项目，需要预测各个家庭的能源消耗。我的数据集包含数千个家庭，每个家庭在两年内每月的能源消耗值，但仅限于某些月份（01-05），因此每个家庭的时间序列为 $10$ 点。每个家庭都有一个其他时间相关变量，即当地湿度/温度指数和几个时间无关特征，既有连续特征，如房屋大小（面积）、邮政编码，也有分类特征，如居民拥有房屋，居民有孩子。任务是使用此信息预测每个家庭未来几个月的能源消耗值。
数据集如下所示：



house_id
month
year
zipcode
en_cons
weather_idx
size
owns_house
has_children




1
1
2021
12
4.33
19.6
71
0.0
1.0


1
2
2021
12
4.35
17.6
71
0.0
1.0


1
3
2021
12
4.56
12.3
71
0.0
1.0


1
4&lt; /td&gt;
2021
12
4.77
15.9
71
0.0
1.0


1
5
2021
12
5.12
19.3
71
0.0 
1.0


1
1
2022
12
4.83
19.9
71
0.0
1.0


...
...
...
...
...
...
..
...
...


1
5
2022
12
5.49
18.7
71
0.0
1.0


2
1
2021
44
6.12
17.3
63
1.0
0.0


...
...
...
...
...
..
...
...


10000
5
2022
99
5.55
14.3
100
1.0
1.0



我我正在尝试弄清楚要实施哪种 ML 模型来预测未来几个月的 en_cons，以及如何将家庭的其他信息纳入模型中。
据我所知，时间序列预测中使用的典型模型（例如 ARIMA（及其变体））仅将时间戳和要预测的数量值作为输入（它们仅根据 $t-k$ 之前的值来预测 $t$ 时间的值）。因此，似乎可以包含所有给定信息的 ML 模型（可能是 XGB 或 LightGBM 之类的东西）才是可行的方法。但我不知道如何实际实施它。
此外，由于我想预测每个家庭的能源消耗，这意味着我每个家庭只有 $10$ 个时间点来创建测试和训练样本，这似乎太少了。这也意味着我必须为每个家庭创建一个单独的模型。这是正确的做法吗？有没有办法使用所有数据创建一种“全局”模型并为每个家庭分别预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</guid>
      <pubDate>Thu, 29 Aug 2024 16:52:14 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中自动删除了逻辑回归的类别</title>
      <link>https://stats.stackexchange.com/questions/653494/categories-automatically-dropped-in-spss-for-my-logistic-regression</link>
      <description><![CDATA[我的逻辑回归模型有问题。我使用 SPSS 分析一些分类 IV/2 数值变量与客户流失之间的关系（著名的 IBM Telco 数据集）。我选择了相关的因变量和所有自变量，并将其中一些标记为分类（最后一个类别作为参考）。我知道没有显示参考类别，但为什么在我的情况下会这样？我不知道该怎么做，因为我需要分析效果。
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/653494/categories-automatically-dropped-in-spss-for-my-logistic-regression</guid>
      <pubDate>Wed, 28 Aug 2024 16:34:10 GMT</pubDate>
    </item>
    <item>
      <title>努力证明 Hessian 是简单线性回归最小二乘法的 PSD</title>
      <link>https://stats.stackexchange.com/questions/653335/struggling-to-prove-that-the-hessian-is-psd-for-simple-linear-regression-least-s</link>
      <description><![CDATA[我正在研究最小化以下函数在 $b_0$ 和 $b_1$ 上的最简单情况：
$$(y_1 - [b_0 + b_1 x_1])^2 + \ldots + (y_n - [b_0 + b_1 x_n])^2$$
为了确定此函数在 $b_0$ 和 $b_1$ 上是凸函数，我已获得如下 Hessian 矩阵：
$$\Big(\begin{matrix}
2n &amp; 2(x_1 + \ldots + x_n)\\
2(x_1 + \ldots + x_n) &amp; 2(x_1^2 + \ldots + x_n^2)
\end{matrix}\Big)$$
如果我能证明这个 $2\times 2$ 矩阵的行列式是非负的，那么我就完成了。但在这里，我必须证明以下不等式：
$$n(x_1^2 + \ldots + x_n^2) \geq (x_1 + \ldots + x_n)^2$$
有没有简单的方法可以证明这个不等式？
我看过几本关于回归的书，包括 Wackerley、Mendenhall 和 Scheaffer。虽然他们推导出一阶条件，但并未考虑/提供全局最小值的二阶必要条件。任何帮助都值得感激。

已编辑并添加。啊，找到了一种相当优雅的方法来进一步探究这个问题。
在尝试通过归纳法证明这一点时，我需要证明以下不等式：
$$x_1^2 + \ldots + x_n^2 + nx_{n+1}^2 \geq 2(x_1 + \ldots + x_n)x_{n+1}$$
但这很容易通过重写 LHS 来证明：
$$(x_1^2 + x_{n+1}^2)+\ldots + (x_n^2 + x_{n+1}^2) \geq 2(x_1 + \ldots + x_n)x_{n+1}$$
然后，通过从 RHS 到 LHS，我们有：
$$(x_1^2 + x_{n+1}^2 - 2x_1 x_{n+1})+\ldots + (x_n^2 + x_{n+1}^2 - 2x_n x_{n+1}) \geq 0$$
这显然是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/653335/struggling-to-prove-that-the-hessian-is-psd-for-simple-linear-regression-least-s</guid>
      <pubDate>Mon, 26 Aug 2024 14:05:06 GMT</pubDate>
    </item>
    <item>
      <title>重新创建`lm`分类回归</title>
      <link>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</link>
      <description><![CDATA[考虑以下代码，它使用来自正确模型的数据，使用两个分类变量和一个连续变量的 lm 进行回归，没有交互作用：
set.seed(12345)

n &lt;- 100
X1 &lt;- as.factor(sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), n, replace = TRUE))
X2 &lt;- as.factor(sample(c(&quot;d&quot;, &quot;e&quot;), n, replace = TRUE))
X3 &lt;- rnorm(n, mean = 0, sd = 1)

effeta &lt;- 1
effetb &lt;- 2
effetc &lt;- 3
effetd &lt;- 4
effete &lt;- 5

Y &lt;- 10 + 3*X3 + effeta*(X1 == &quot;a&quot;) + effetb*(X1 == &quot;b&quot;) + 
effetc*(X1 == &quot;c&quot;) + effetd*(X2 == &quot;d&quot;) + effete*(X2 == &quot;e&quot;) + 
rnorm(n, mean = 0, sd = 1)

model &lt;- lm(Y ~ X1 + X2 + X3)
print(summary(model))

输出为：
调用：
lm(formula = Y ~ X1 + X2 + X3)

残差：
最小值 1Q 中位数 3Q 最大值
-2.74679 -0.60571 0.06521 0.67873 1.85143

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 15.06741 0.20151 74.773 &lt; 2e-16 ***
X1b 0.95913 0.23994 3.997 0.000127 ***
X1c 1.96010 0.23637 8.292 7.26e-13 ***
X2e 1.08521 0.18887 5.746 1.10e-07 ***
X3 3.03324 0.09537 31.804 &lt; 2e-16 ***
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：95 自由度上的 0.9327
多重 R 平方：0.9194，调整后的 R 平方：0.916
F 统计量：4 和 95 DF 上的 270.8，p 值：&lt; 2.2e-16

目标是从数学上理解到底发生了什么，然后在 R 中重现它。更具体地说：

可以说 X3 系数的估计是正确的。在线来源表明 lm 将以一个级别为参考，将其效果设置为零。在一般情况下，如何提前预测哪个变量将作为参考？也许是按字母顺序？一旦估计了效果，我们如何知道它们是正确的？
虽然没有参考，但我相信 R 使用虚拟变量将分类观察结果写入矩阵中，将所有内容组合在一起，就像 Searle 中提到的那样，然后进行多元线性回归。在这种情况下，我该如何写下这样的矩阵？

让我们用 $x_3 \in \mathbb{R}^n$ 代替 x3。然后：
\begin{equation*}
x_3 =
\begin{bmatrix}
x_{1,3} \\
x_{2,3} \\
\vdots \\
x_{n,3}
\end{bmatrix}
\end{equation*&gt;
要对分类变量进行盲目计算，可以这样写：
\begin{equation*}
x_1 =
\begin{bmatrix}
x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} \\
x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} \\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} \\
\end{bmatrix};
x_2 =
\begin{bmatrix}
x_{1,1d} &amp;&amp; x_{1,1e} \\
x_{2,1d} &amp;&amp; x_{2,1e}\\
\vdots &amp;&amp; \vdots \\
x_{n,1d} &amp;&amp; x_{n,1e} \\
\end{bmatrix}
\end{equation*&gt;
两个矩阵中的所有元素均为 $0$ 或 $1$。
然后输入：
\begin{equation*}
X =
\begin{bmatrix}
1 &amp;&amp;x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} &amp;&amp; x_{1,1d} &amp;&amp; x_{1,1e} &amp;&amp; x_{1,3} \\
1 &amp;&amp; x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} &amp;&amp; x_{2,1d} &amp;&amp; x_{2,1e} &amp;&amp;x_{2,3} \\\\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots \\
1 &amp;&amp; x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} &amp;&amp; x_{n,1d} &amp;&amp; x_{n,1e} &amp;&amp; x_{n,3}
\end{bmatrix}
\end{equation*
这样我们就可以进行回归分析 lm(Y~X)。但这显然不是实际发生的情况。我如何去掉一些列才能得到实际发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</guid>
      <pubDate>Thu, 18 Jul 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>如果前几个组件大于一，那么报告某些 PC 组件的零特征值可以吗？</title>
      <link>https://stats.stackexchange.com/questions/638833/is-it-okay-to-report-zero-eigen-values-for-some-pc-components-if-the-first-few-c</link>
      <description><![CDATA[我有一个数据集，收集了 3 年内的家庭反馈。由于并非所有家庭都参与了这三次调查，因此该数据集是不平衡的。我在 stata 中运行多级 PCA 来解释内部和之间的变化。为了进行比较，我还对整个数据集运行了整体 PCA，因为数据是独立的。
内部和内部 PCA 给出了 5 个和 4 个大于 1 的特征值，但是有许多特征值恰好为零。
但是，整体 PCA 有 11 个 PC 的特征值大于 1，其余的 PC 正在缓慢减少，并且有 0.14 个特征值。
可以报告这样的结果吗？我该如何解释我的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/638833/is-it-okay-to-report-zero-eigen-values-for-some-pc-components-if-the-first-few-c</guid>
      <pubDate>Thu, 08 Feb 2024 10:13:44 GMT</pubDate>
    </item>
    <item>
      <title>看到数据后权衡假设与持续学习</title>
      <link>https://stats.stackexchange.com/questions/631450/weighing-hypotheses-after-seeing-the-data-vs-consistent-learning</link>
      <description><![CDATA[在《理解机器学习，S. Ben David 等人》一书中关于非均匀学习的章节中（其免费在线版本此处），作者写道：

如果我们在看到数据之前坚持任何假设，那么我们就可以保证一个相当小的估计误差项
$$
L_\mathcal{D}(h)\le L_S(h) + \sqrt{\frac{\log(2/\epsilon)}{2m}}。
$$

该声明清楚地表明，如果我们仍然坚持相同的假设，但在看到数据之后，错误界限可能会有所不同。但是，我不知道作者所说的“看到数据之后”是什么意思。
我认为在看到数据之后坚持假设会将学习设置从非均匀学习更改为一致学习，但我不确定它是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/631450/weighing-hypotheses-after-seeing-the-data-vs-consistent-learning</guid>
      <pubDate>Thu, 16 Nov 2023 03:33:48 GMT</pubDate>
    </item>
    <item>
      <title>我的学习曲线或模型是否存在问题，因为它从完全相反的尾端开始？</title>
      <link>https://stats.stackexchange.com/questions/628446/is-there-something-wrong-with-my-learning-curve-or-my-model-because-it-starts-at</link>
      <description><![CDATA[
如果您能查看我的图表并告诉我是否有问题，那就太好了。上下文是它使用了 MLP。]]></description>
      <guid>https://stats.stackexchange.com/questions/628446/is-there-something-wrong-with-my-learning-curve-or-my-model-because-it-starts-at</guid>
      <pubDate>Wed, 11 Oct 2023 05:19:53 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯学习：寻找噪声的方差</title>
      <link>https://stats.stackexchange.com/questions/622310/bayesian-learning-finding-the-variance-of-noise</link>
      <description><![CDATA[假设 $x_i \sim N(10,4)$ - 即，分布已知。
有一个噪声信号 $s_i \sim N(x_i, \sigma_e^2)$，我想估计 $\sigma_e$。
我看到一些对 ($s_i, x_i$)，但它们不是“随机的”($s_i$ 上有一些选择 - 比如说，我看到这些值大多是 $s_i$ 的大值)。
您推荐哪种方法来估计$\sigma_e$?
我的第一个想法是简单地取 $\hat\sigma_e = \sqrt{\sum(s_i-x_i)^2/N}$，但我认为这是错误的，因为我的数据主要包含较大的 $s_i$?
接下来我尝试对 $x_i | s_i$ 的分布进行建模。贝叶斯后验分布为
$N((\frac{\sigma_{e}^2}{\sigma_{e}^2+4})10 + (\frac{4}{\sigma_{e}^2+4})s_{i}, \frac{\sigma_{e}^2*4}{\sigma_{e}^2+4})$
其中 $4$ 和 $10$ 来自上述 $x_i$ 的分布。
但我不知道如何继续。我认为 $x_i|s_i$ 的预期值与实际观测值之间的差异应该以某种方式反映 $\sigma_e$，但我感到困惑，因为 $\sigma_e$ 同时进入了上述预期值项和方差项。尝试通过区分上述对数似然来找到 MLE 变得非常复杂。我是否遗漏了一些显而易见的东西？或者您推荐任何方法来估计 $\sigma_e$？
编辑：明确地说，我知道 $s_i$ 上有选择，但我确信没有选择 $x_i$ 或 $x_i|s_i$。
所以我觉得 $x_i|s_i$ 应该对 $\sigma_e$ 有所裨益（例如，如果我只看到 $x_i$ 非常接近 $s_i$，则每个 $x_i$ 都应为 $\sigma_e$ 提供信息（例如，如果我仅看到 $x_i$ 非常接近 $s_i$，则每个 $x_i$ 都应为 $x_i ... class=&quot;math-container&quot;&gt;$s_i$，我知道$\sigma_e$很小；但如果我看到$x_i|s_i \sim N(10,4)$（即接近原始分布），我会相信$\sigma_e$很大。我怎样才能将这种直觉形式化以形成估计量？
编辑2：考虑$a_i = \frac{x_i-s_i}{10-s_i}$
$E[a_i|s_i] = E[\frac{x_i-s_i}{10-s_i} | s_i]$
$= \frac{E[x_i | s_i] - s_i}{10-s_i}$
从上面的等式中，我知道 $E[x_i | s_i] = (\frac{\sigma_{e}^2}{\sigma_{e}^2+4})10 + (\frac{4}{\sigma_{e}^2+4})s_{i}$
因此，$E[a_i|s_i] = \frac{\sigma_{e}^2}{\sigma_{e}^2+4}$。

这是正确的吗？如果是，我可以将 $[a_i|s_i]$ 的平均值作为 $\frac{\sigma_{e}^2}{\sigma_{e}^2+4}$ 的估计量吗？这应该可以解决选择问题，因为没有以 $s_i$ 为条件的选择。
我可以通过将其作为上面 1. 中公式的主题来获得 $\sigma_{e}^2$ 的估计值吗？

任何帮助，即使是指导性的，都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/622310/bayesian-learning-finding-the-variance-of-noise</guid>
      <pubDate>Wed, 26 Jul 2023 00:19:50 GMT</pubDate>
    </item>
    </channel>
</rss>