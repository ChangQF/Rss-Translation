<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 12 Oct 2024 06:21:26 GMT</lastBuildDate>
    <item>
      <title>关于因子分析的一些困惑</title>
      <link>https://stats.stackexchange.com/questions/655678/some-confusion-on-factor-analysis</link>
      <description><![CDATA[我是一名数学专业的学生，​​最近在自学因子分析。
虽然我对基础统计学有一些了解，但我觉得很难转换成统计学的思维方式。
以下是我对因子分析的一些困惑。
我读的书和维基百科都是这样定义因子分析的：

在因子分析中，让$\mathbf{x}=(x_1,\cdots,x_p)$成为一个显性变量。
我们想要找到一个矩阵 $L$，
$k$ 个随机变量 $f_1,\cdots,f_k$ 和 $p$ 个随机变量 $\epsilon_1,\cdots,\epsilon_p$，
且它们相互独立，$E(f_i)=0$，$\text{var}(x_i)=1$ 和 $E(\epsilon_i)=0$，并且
\begin{equation*}
\begin{pmatrix}x_1\\ \cdots\\x_p\end{pmatrix}=L\begin{pmatrix}f_1\\ \cdots\\f_k\end{pmatrix}+\begin{pmatrix}\epsilon_1\\ \cdots\\ \epsilon_p\end{pmatrix}.
\end{equation*&gt;

我有几个问题。
(1) 在上面的等式中，我们是否将$x_i$视为随机变量？
例如，我们通常对样本值进行标准化。
如果我们事先知道每个$x_i$都服从正态分布，并对其进行了标准化，那么在上面显示的方程中，我们是否将$x_i$视为随机变量，并且$x_i\sim N(0,1)$？
(2) 假设 (1) 成立。那么显示的方程就是一个随机变量方程。
但是没有像概率论那样的概率空间。
那么我们如何解释显示的方程，它是随机变量之间的等式？
一开始我认为这应该意味着它的似然性，或者，$p(\text{方程成立}| L)$应该接近于$1$。
但后来我觉得可能不是这样，因为我们不知道$\epsilon_i$和$f_i$的分布。
但是，如果我们不要求上述等式以一定的似然性成立，
那么似乎几乎任何随机变量都可以成为一个因子，条件很简单？
(3) 我问过一位教授，如果我们已经确定了$L$，那么我们如何回过头来为我们收集的每个样本数据求解$(f_i)_{1\le i\le k}$，$(\epsilon_i)_{1\le i\le k}$？
教授回答说我们不需要这样做，因为$f_i,\epsilon_i$是随机的。
对吗？如何进一步解释这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/655678/some-confusion-on-factor-analysis</guid>
      <pubDate>Sat, 12 Oct 2024 05:32:18 GMT</pubDate>
    </item>
    <item>
      <title>如果倾向评分匹配 (PSM) -DiD 中的治疗组大于对照组，应该怎么办</title>
      <link>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-control-groups-in-propen</link>
      <description><![CDATA[为了进行差异分析（DiD），以模仿随机对照试验，我们通常使用倾向得分匹配（PSM）在事件日期之前消除对照组和治疗组之间的差异。
通常我们会有一个小的治疗组和大的对照组，我们只需遵循原来的步骤即可。
但今天我遇到了一些不同的事情：
当我尝试检查法律A对澳大利亚所有上市公司的影响时，我应该比较该法律A对澳大利亚公司和新西兰公司的影响（因为新西兰在那段时间没有实施法律A）
事实上，澳大利亚的公司比新西兰多，这意味着治疗组比对照组大。
我尝试过1：2、1：3匹配，但匹配失败（匹配后治疗组和对照组之间存在差异）。只有 1:1 匹配效果良好。
在使用 1:1 匹配运行回归分析后，我仍然发现法律 A 对澳大利亚公司的影响比新西兰公司的影响更大（通过使用 DiD）
我想知道我的 1:1 设置是否可以接受，因为这意味着由于新西兰公司数量较少，并非所有澳大利亚公司都会在匹配样本中匹配。]]></description>
      <guid>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-control-groups-in-propen</guid>
      <pubDate>Sat, 12 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>我们何时在 glm 中使用非规范链接函数？</title>
      <link>https://stats.stackexchange.com/questions/655676/when-do-we-use-non-canonical-link-functions-in-glm</link>
      <description><![CDATA[例如，如果响应变量服从二项分布，则典型链接函数为 logit 链接。但是，其他链接函数也可用，例如 probit 链接和对数对数链接（但这些不是典型链接函数）。典型链接函数使统计推断的某些方面变得容易得多。但是，有时典型链接函数不太适合数据，我们不得不使用非典型链接函数来建立更好的回归模型。
我想知道在统计建模中是否存在一些经典情况，我们可以立即知道典型链接函数不适合？
我尝试进行一些研究，并认为混合模型或 gamma-hurdel 模型等一些模型可能由于其独特的设置而涉及非典型链接函数。但是是否存在一些众所周知的情况（例如双峰响应，响应中有许多零），我们可以立即知道具有典型链接的 GLM 不是一个好主意？]]></description>
      <guid>https://stats.stackexchange.com/questions/655676/when-do-we-use-non-canonical-link-functions-in-glm</guid>
      <pubDate>Sat, 12 Oct 2024 04:38:33 GMT</pubDate>
    </item>
    <item>
      <title>威尔克定理，投影子空间上的置信区域？</title>
      <link>https://stats.stackexchange.com/questions/655675/wilks-theorem-confidence-regions-on-a-projected-subspace</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655675/wilks-theorem-confidence-regions-on-a-projected-subspace</guid>
      <pubDate>Sat, 12 Oct 2024 04:03:54 GMT</pubDate>
    </item>
    <item>
      <title>报告缺失数据的分类器准确率</title>
      <link>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</link>
      <description><![CDATA[假设我们正在读取血压。有些读数已损坏且无法使用。然后我们训练二元分类器来检测高血压。当我们的模型无法使用某些数据时，实验设计理论对报告分类器准确性有何看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</guid>
      <pubDate>Sat, 12 Oct 2024 00:40:54 GMT</pubDate>
    </item>
    <item>
      <title>从系统中删除无关值以确定概率</title>
      <link>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</link>
      <description><![CDATA[我试图确定以下系统实例的发生概率，该系统有利于总和 &gt;= 106.6 和 =&lt; 117：
106.6 =&lt; 4.1x + 4.7y + 5.6z + 6.6t =&lt; 117 &amp;&amp; x + y + z + t == 26, {x,y,z,t} ∈ ℕ
但是，产生的组合数大大超过有利于确定概率的实际计数。例如，任何组合中 6.6 从初始位置连续出现 18 次，系统都不可能产生结果 =&lt; 117。然而，仍有 4^8 个子代组合。我可以通过什么方式确定系统内所有此类子代组合的数量？我怎样才能将这些后代从不利组合池中移除？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</guid>
      <pubDate>Fri, 11 Oct 2024 23:45:24 GMT</pubDate>
    </item>
    <item>
      <title>需要进行多少次测试（以及必须通过多少次）才能保证我的软件在 90% 的时间内以 95% 的置信度正常运行？</title>
      <link>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</link>
      <description><![CDATA[我有一些软件，其运行方式不确定。根据未知的外部因素，对代码运行测试可能会导致测试通过或失败。假设由于这些因素，测试通过或失败的几率相等，我必须运行测试多少次，软件必须通过测试多少次，这样我才能有 95% 的信心说软件在 90% 的时间内按预期运行？
编辑：假设外部因素导致测试失败的几率未知，而不是测试通过/失败相等。]]></description>
      <guid>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</guid>
      <pubDate>Fri, 11 Oct 2024 22:37:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么当使用 IV 独立变量并且包括区域固定效应时，系数会失去显著性？</title>
      <link>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</link>
      <description><![CDATA[我正在尝试研究 2018 年洪水冲击对男性和女性劳动力参与的影响。然而，洪水不仅可以归因于强降雨，还可以归因于其他因素，例如水库的蓄水能力差、水坝闸门打开。所以，洪水并非完全是外生的。因此，我首先使用地区固定效应和年份固定效应对 99 百分位季风降雨量（针对 1989-2018 年的每个季风月份计算）对洪水损害评分进行回归（使用 PCA 为每个地区构建损害指数，使用地区损害信息，例如受影响的农作物面积、受影响的养鱼场、人员伤亡等）。接下来，我使用此回归的预测值作为洪水冲击对劳动力参与回归的主要自变量。但是，当我采用地区固定效应时，系数在统计上变得不显著。在没有地区固定效应的情况下，它仍然具有统计显著性。有人能告诉我为什么会这样吗？我该如何解决这个问题？
注意：第一次回归基于 1989-2018 年期间每个地区的每日降雨量数据，这是一种面板数据，但在第二次回归中，个人和家庭层面的数据是重复的横截面，在 2017-2019 年期间每年四个季度都有。]]></description>
      <guid>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</guid>
      <pubDate>Fri, 11 Oct 2024 19:52:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 GLM 或 GLMM 来衡量多样性指标</title>
      <link>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</link>
      <description><![CDATA[我希望有人能帮我解答一个有关统计分析的问题。我正在查看物种计数数据，其中在重复地点进行了多年的采样。例如，每年在六个不同的地点进行采样。这些年份被分为一个温度组，有两个因素：温暖或寒冷。我只对探索不同温度组和不同年份之间的社区差异感兴趣。我使用 vegan 包来计算多样性指标（丰度、丰富度、多样性指数），并希望统计检查指标之间的差异。
我一直在使用带有负二项分布的 mvabund 包，但我想知道现在是否应该将重复的站点添加为随机效应，它实际上是一个混合模型。在这种情况下，glmmTMB 或 lme4 是否更合适？我不太熟悉在 R 中使用混合模型，因此非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</guid>
      <pubDate>Fri, 11 Oct 2024 19:40:20 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 到 pytorch 权重转移[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</link>
      <description><![CDATA[我正尝试在 pytorch 中模拟一个经过修改的 efficientnet TF 模型。我在 pytorch 中对模型进行了架构更改，转储了 TF 模型权重，然后将其重新加载到新的 pytorch 模型中。使用以下代码在 TF 中转储权重：
model = tf.saved_model.load(model_path)
ws = []
for i in range(len(model.variables)):
ws.append((i, model.variables[i].name, model.variables[i].numpy()))

with open(&quot;manually_dumped_contentnet_weights.pkl&quot;, &quot;wb&quot;) as ofile:
pickle.dump(ws, ofile)

pytorch 中的权重形状似乎与架构和导入的权重相匹配（在 conv2d 和深度 conv2d 之间进行转换之后）。我可以毫无错误地运行模型。但输出结果与 TF 模型的输出结果大不相同。
我注意到在 TF 代码中，模型不是直接加载的，而是在 tf Session 中加载的：
with Session(graph=Graph(), config=ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
saved_model.loader.load(sess, [saved_model.tag_constants.SERVING], model_path)
patch_feature, patch_label = sess.run(output_nodes,feed_dict={input_node: patch})

现在我想知道我最初转储模型权重的尝试是否做得不正确。或者如果我遗漏了其他内容。
我在加载数据时进行的转置是 conv2d 的 (3,2,0,1) 和深度 conv2d 的 (2,3,0,1)：
def reload_conv2d(layer, weights):
### weights 是一个元组，其中每个元素都由一个三元组组成：(1) 索引号，(2) TF 中权重转储的层的名称，以及 (3) 权重
count = 0
if (
&quot;/conv2d/kernel&quot; not in weights[0][1]
and &quot;/conv2d_1/kernel&quot; not in weights[0][1]
and &quot;depthwise_conv2d/depthwise_kernel&quot; not in weights[0][1]
and &quot;final_conv2d/final_conv2d&quot; 不在 weights[0][1] 中 :
raise ValueError(
f&quot;需要在第一个索引上有 conv2d/kernel，但得到了 {weights[0][1]}&quot;
)
transpose_shape = (2,3,0,1) if &quot;depthwise&quot;在 weights[0][1] 中否则（3、2、0、1）
transposed_weights = torch.from_numpy（weights[0][2].transpose（transpose_shape[0]、transpose_shape[1]、transpose_shape[2]、transpose_shape[3]））
layer.weight.data = transposed_weights
count += 1
如果 layer.bias 不是 None 或 layer.bias:
如果（
&quot;/conv2d/bias&quot; 不在 weights[1][1] 中
并且 &quot;/conv2d_1/bias&quot; 不在 weights[1][1] 中
）：
引发 ValueError（
f&quot;需要在第二个索引上有 conv2d/bias 但得到了 {weights[1][1]}&quot;
)
layer.bias.data = (
torch.from_numpy(weights[1][2])
如果type(weights[1][2]) == np.ndarray
else torch.from_numpy(weights[1][2])
)
count += 1
return layer, count

为什么 pytorch 和 TF 模型对相同输入给出完全不同的结果？是因为权重倾倒，还是权重加载……或者是模型架构变化？输入 TF 权重（在模型更改和转置之后）加载正常，我可以毫无问题地运行模型，但这对于调试它没有任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</guid>
      <pubDate>Fri, 11 Oct 2024 16:26:04 GMT</pubDate>
    </item>
    <item>
      <title>在使用 ARMA 过程拟合 GAMM 时如何优化资源使用？</title>
      <link>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</link>
      <description><![CDATA[我正在根据一系列时间预测因素（例如一年中的时间、昼夜循环、潮汐……类似于这篇文章）对每小时物种的出现情况（存在/不存在）进行建模。我使用收集自约 100 个人的数据，有 266,000 个数据点。我目前正在尝试按照以下结构拟合 GAMM 模型*：
ResGAM8 = gamm(data = Datanal, HL ~ s(Day) + s(Temperature) + s(ref, bs = &quot;re&quot;) + ti(Day, Temperature, SI), family = binomial, method = &quot;fREML&quot;, correlation = corARMA(form = ~1 | ref,p=1))

在之前的版本中，我使用 bam( ... rho = ) 来解释时间自相关，但是，ACF 和 pACF 仍然表明残差中存在一些自相关。因此，我决定在每个个体中嵌套一个 ARMA，以更好地解释时间自相关以及解释变量之间的相关性。 
我尝试在免费版 google colab 上运行此模型几次（大约 1 分钟后总是出现错误，表明会话已崩溃，因为它已达到分配的 RAM 限制）并在我自己的计算机上（没有 colab 快）运行了大约 2 个小时，没有任何显著的结果。

我的问题很简单（表述）：我如何优化这个过程以减少资源消耗（并避免上述问题）？

减少观察和/或个体的数量是可能的，但实际上是作为最后的手段，因为包括的动物数量是这项工作的原因之一。

*为了清楚起见，我删除了简单平滑中包含的一些解释变量]]></description>
      <guid>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</guid>
      <pubDate>Fri, 11 Oct 2024 12:48:58 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $H(Y|X) \le H(Y)$</title>
      <link>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</link>
      <description><![CDATA[假设我们有 100 张牌，其中 98 张两面都是白色，一张两面都是黑色，最后一张一面是白色，另一面是黑色。
如果我问“我看到的是哪一面”，我们有 $p(F) \sim Be(0.985)$，因为我们有 3 张黑面和 197 张白面。因此，$H(F) \approx 0.0808$
现在，假设我知道另一面是黑色。然后 $p(F|F&#39;=black) \sim Be(0.5)$, $H(F|F&#39;=black) = 1$
因此，在我看来，额外的信息似乎增加了熵，但信息论明确指出 $H(Y|X) \le H(Y)$，因此知道另一面的颜色不应该让我更加不确定
因此，我的结论是，我严重误解/遗漏了一些东西，有什么想法吗？我应该考虑平均条件熵而不是特定情况吗？...]]></description>
      <guid>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</guid>
      <pubDate>Thu, 10 Oct 2024 21:04:25 GMT</pubDate>
    </item>
    <item>
      <title>事件发生后定义治疗的差异-差异法</title>
      <link>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</link>
      <description><![CDATA[我正在写一篇使用差异-差异设计方法的科学论文，但这不是标准的 DID 设置。
考虑一下我们在多个时间段收集多个公司观察结果的情况。在 $t=0$ 时发生一个事件。到目前为止，一切都很基本。现在偏离标准设置：不知道哪些公司属于治疗组和对照组，治疗组被定义为那些可观察特征 $x$ 从事件前到事件后从 $0$ 变为 $1$ 的公司。控制公司是那些特征 $x$ 保持在 $0$ 的公司。
这是 DID 设计的常见/已知版本吗？如果是，如果您能给我提供一些文献，我会很高兴，因为我还没有找到任何接近这个的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</guid>
      <pubDate>Thu, 10 Oct 2024 20:42:08 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归：共线性或接近共线性的参数的部分效应解释</title>
      <link>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</link>
      <description><![CDATA[我正在看一个最简单的多元线性回归模型示例：
\begin{equation}\label{linreg}
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\end{equation&gt;
我对当 $X_1=X_2$（共线性）或 $\text{cor}(X_1, X_2)$ 非常高（可能是 $\text{cor}(X_1, X_2)&gt;0.999$）时获得的参数估计值（同时估计）感兴趣。
回归系数的标准解释是偏效应：$\beta_1$ 是 $X_1$ 增加一个单位时 $Y$ 的变化，同时控制所有其他变量（此处仅 $X_2$）。但是，如果 $X_1=X_2$，则一旦我们控制了 $X_2$，$X_1$ 显然无法再解释 $Y$ 中的任何变化。基于此推理，我期望得到估计值$\hat\beta_1=0$，并且基于相同推理，我期望得到$\hat\beta_2=0$。
但是，如果我估计回归模型（在完全共线情况下使用贝叶斯模型，或在近共线情况下使用贝叶斯/频率论），我会得到 beta 系数，其总和等于真实参数的总和$\beta_1+\beta_2$。从优化的角度来看，这也是有道理的，因为如果 $X_1=X_2$，则上述模型的 RHS 可以重写为 $(\beta_1+\beta_2)X_1 + \varepsilon$，这也说明了为什么模型无法识别。
基于上述内容，似乎 $\beta_1, \beta_2$ 的部分效应解释与我在（近）共线情况下得到的结果不一致。显然，我犯了一个推理错误，我希望有人能指出这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</guid>
      <pubDate>Wed, 09 Oct 2024 08:49:59 GMT</pubDate>
    </item>
    </channel>
</rss>