<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 01:23:20 GMT</lastBuildDate>
    <item>
      <title>与回归分析相比，生存分析在预测方面有哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</link>
      <description><![CDATA[我最近遇到了生存分析，它似乎对于模拟事件发生时间和/或处理审查非常有用。文献中激励性的例子很有意义，例如在临床试验中，我们可能会有参与者退出，或者那些可能经历了不良影响但研究提前结束的人。
在我的应用程序中，我使用机器学习对事件发生时间进行建模并将其视为回归问题。然而，审查在这里并不是一个真正的问题，我想知道生存分析是否会比标准回归方法提供任何优势。
为了简化设置，假设我们有来自小部件工厂的数据。小部件发生故障的平均时间为$\bar{Y} = 40$天（最多 100 天），而数据集可以追溯到几年前，并且有几百万个观察值。因此，确实存在一些右删失，但考虑到数据的大小，这相对微不足道。我们还观察到小部件级协变量 $X$，它们会影响故障时间。
目前，我只是将其建模为非参数回归问题，即学习函数 $f : X \to Y$，该函数可最小化 $L^2$ 经验风险/MSE。如果这里的目标只是预测故障时间 $Y$，而不考虑推理，那么生存分析是否会比回归方法有任何优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</guid>
      <pubDate>Fri, 13 Dec 2024 01:17:45 GMT</pubDate>
    </item>
    <item>
      <title>与基线纵向模型的变化</title>
      <link>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</link>
      <description><![CDATA[我正在研究一个纵向模型，以分析变量 Y 的相对于基线的变化，该变量在基线 Y1 和后续时间点 (Y2、Y3、Y4 ...) 处针对一组患者进行测量。对于每个测量值，我都有相应的标准差 (Y1_SD、Y2_SD、Y3_SD ...)。
(相对于基线的变化) 平均差异 (MD) 很容易计算为 ( Y1 ) 与每个后续 ( Y_i ) 之间的差异。但是，我很难正确定义 平均差异的标准差 (SD_diff)，因为这需要 ( Y1 ) 和 ( Y2、Y3、...) 之间的相关性 ( r )；编码协方差矩阵（例如自回归矩阵）也需要相关性
我引用的 SD_diff 公式是：
SD_diff = sqrt(S1² + S2² - 2 * r * S1 * S2)
我的问题是：

我需要两个元素来构建纵向模型吗？
纵向模型可以只用协方差矩阵编码吗？

方差和协方差矩阵应该如何定义？
假设任何协方差矩阵（例如 AR(1)）在其公式中包含变量方差；这应该由 SD_diff 定义吗？还是由 Yi_SD 定义？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</guid>
      <pubDate>Fri, 13 Dec 2024 00:07:57 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据以检查因果关系的算法或测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-or-tests-that-fit-my-data-to-examine-the-causal-relationship</link>
      <description><![CDATA[我有两份在 18 个采样点和 20 个采样日期收集的观测数据，我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-or-tests-that-fit-my-data-to-examine-the-causal-relationship</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经做过双向方差分析，现在我想做事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它能给出组别和字母，说明各组之间的差异。但我不确定这个函数是否可以用于两个因素，或者它是否只适用于单向方差分析。有人知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>fixest 和 plm 模型的回归表？</title>
      <link>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</link>
      <description><![CDATA[我正在使用 fixest 和 plm 模型。我通常对 fixest 对象使用 fixest 的 etable，对 plm 使用 stargazer。问题是它们不相互兼容。有没有支持这两种对象类的命令？
如果没有，我该怎么办？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</guid>
      <pubDate>Thu, 12 Dec 2024 22:58:40 GMT</pubDate>
    </item>
    <item>
      <title>和的联合分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</link>
      <description><![CDATA[假设 $X_1$ 和 $Y$ 是两个独立且正值的随机变量，其分布为 $F_{X_1}(x_1)$ 和 $F_{Y}(y)$。
现在，我们定义，
$X_2 = X_1 + Y$
$X_1$ 和 $X_2$ 的联合概率分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</guid>
      <pubDate>Thu, 12 Dec 2024 22:22:44 GMT</pubDate>
    </item>
    <item>
      <title>支持完全交叉研究设计的评分者间信度系数</title>
      <link>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</link>
      <description><![CDATA[我需要计算一项研究的评分者间信度，该研究有大约 100 名评分者针对 12 个研究对象进行。
评分是无顺序或排名的名义数据。
根据 Hallgren 2012，对于评分者不是针对每个受试者随机抽样的情况，Fleiss&#39; Kappa 不是一种选择。
相反，他建议使用 Light&#39;s kappa 或 Davies &amp;而是使用 Fleiss 的 kappa。
但是，Gwet 2014 不鼓励使用 Light 的 kappa，因为“对多个成对 kappa 系数求平均值将产生没有明确含义的测量值”。
对于 Davies &amp; Fleiss 的 kappa，我在 R 中找不到任何可以使用的实现。
目前尚不清楚 Gwet 手册中推荐的其他系数（如 Conger 的 Kappa、Gwet 的 AC1 或 Krippendorf 的 Alpha）是否也适用于完全交叉设计。
或者研究设计最终不是什么大问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</guid>
      <pubDate>Thu, 12 Dec 2024 22:10:00 GMT</pubDate>
    </item>
    <item>
      <title>“群体间协议”的适当指标</title>
      <link>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</link>
      <description><![CDATA[我需要比较发给两组不同评分员的问卷结果，并以某种方式量化两组之间的一致性。
问卷中有 12 个问题涉及对某些要求句子的解释，第一组约有 100 名独立评分员回答了这些问题，第二组约有 40 名独立评分员回答了这些问题。
收集的结果数据是无序或无排名的名义数据。
以下是数据摘录：
 V1 V2 V3 V4 V5 
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
1 2 2 3 2 1 
2 2 2 3 2 1 
3 1 4 4 4 1 
4 2 3 3 3 2 
5 1 1 4 2 4 
6 2 2 3 2 2 
7 1 1 3 1 1 
8 2 3 3 2 2 
9 2 2 3 3 3 
10 2 3 3 2 2 

列代表不同的评估者，而每行代表问卷的一个研究对象，可以从 1-3 或 1-4 进行评分（再次，名义数据）。
对于单个评估者组，我可以使用常见的评估者间信度指标（如 Lights&#39; Kappa）轻松计算“组内”一致性水平。
事实上，我已经这样做了，发现第一组 Kappa 为 0.218，第二组 Kappa 为 0.758（使用 R 包 irr 中的 kappam.light 计算）之间存在显著差异。
因此，看起来第二项研究中的组内一致性大幅提高。
但如果评级与第一组中最常见的评级相差很大，这对我没有帮助。
在这种情况下，我将如何计算“组间一致性”的水平。
我能做的就是将第一组的结果与第二组的结果相结合（即合并/连接表格）并计算联合 IRR。这将向我展示整体一致性，同时将两个组视为一个大组。
但这真的能量化第一组与第二组的响应有多接近吗？
如果是，我需要有相等的组大小吗？
或者是否有专门设计用于比较两组之间一致性水平的指标？
我在这里找到了一个类似的问题，但在这种情况下，作者处理的是序数数据。
这里建议计算和比较两组的平均值，然后进行统计显着性检验，这对于名义数据来说可能没有多大意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</guid>
      <pubDate>Thu, 12 Dec 2024 21:10:21 GMT</pubDate>
    </item>
    <item>
      <title>重复测量二元变量的 Cohen Kappa</title>
      <link>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</link>
      <description><![CDATA[我进行了一项实验，展示了两种类型的广告信息：第一种类型具有理性风格，第二种具有感性风格。样本多次接触这些信息（重复测量），每次我都会进行问卷调查，询问这些信息是理性的还是感性的。所以我有一个 2x2 矩阵，其中变量 1 是信息类型（理性/感性），变量 2 是信息的识别（理性/感性）。因此，两个变量都是二元名义分类变量。
我想进行操纵检查，看看受试者是否正确识别了信息风格，我应该使用哪种一致性测试？我考虑过 Cohen 的 kappa，但就我而言，我进行了重复测量，并且我读到这可能不是正确的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:46 GMT</pubDate>
    </item>
    <item>
      <title>具有排列标准误差的 Wald 检验？</title>
      <link>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</link>
      <description><![CDATA[许多统计检验都基于 Wald 类 z 统计量：$z = \frac{\hat{\theta} - \theta_0}{\text{SE}(\hat{\theta})}$，其中 $\theta$ 是感兴趣的参数，$\theta_0$ 是零假设下的值，SE 是标准误差。然后可以通过将 $z$ 与标准正态 (0,1) 分布进行比较来计算 p 值。
我想知道是否可以基于 $\theta$ 的置换零分布来估计 z 检验中的标准误差？或者 z 检验的标准误差是否应始终在备择假设下计算？
更多上下文：
我知道我可以直接从置换分布计算 p 值，但就我而言，我正尝试进行荟萃分析，这需要每个队列的点估计和标准误差。但是，我使用的统计数据没有封闭形式的标准误差估计，但我已经有了统计数据的置换零分布。我可以只使用置换分布的标准误差进行荟萃分析吗？
我使用的统计数据是来自 GSEA 的“标准化富集分数”(NES)。 NES 没有标准误差公式，而是使用置换检验来计算其 p 值。我想知道是否可以使用置换分布的标准差作为元分析的标准误差估计量。
编辑：这个答案似乎表明在置换零分布下估计标准误差是可以的，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:35 GMT</pubDate>
    </item>
    <item>
      <title>多项分布的广义方差</title>
      <link>https://stats.stackexchange.com/questions/658639/generalized-variance-of-a-multinomial-distribution</link>
      <description><![CDATA[标量方差是一个单变量概念，因此广义方差通过取多元分布的协方差矩阵的行列式，对多变量设置进行了概括。
但是，多项分布具有奇异协方差矩阵，因此行列式提供的有关多项分布中变异性的信息最少；每个多项分布都给出相同的广义方差零。
但是，我们可以从多项分布中删除一个类别，并暗示另一个类别会发生什么（在对分类变量进行回归时很常见）。当我们这样做然后计算广义方差时，该值并不总是零。
在进行此实验时，我们放弃哪些类别似乎并不重要。此外，如果我们只是从完整多项分布的协方差矩阵中删除行 $k$ 和列 $k$，行列式似乎并不依赖于 $k$。
set.seed(2024)

# 计算多项分布协方差矩阵的函数 
#
multinomial_cov &lt;- function(n, p){

k &lt;- length(p)

cov_np &lt;- matrix(NA, k, k)
for (i in 1:k){
for (j in 1:k){

if (i == j){
cov_np[i, j] &lt;- n * p[i] * (1 - p[j])
}
if (i != j) {
cov_np[i, j] &lt;- -n * p[i] * p[j]
}
}
}
return(cov_np)
}
#
# 函数结束

R1 &lt;- 25 # 不同多项式参数组合的数量
R2 &lt;- 100 # 确定要删除的索引的次数
dets &lt;- matrix(NA, R1, R2)
for (i in 1:R1){

# 确定分布参数
#
n &lt;- sample(seq(1, 10, 1), 1, replace = F) # 掷骰子次数
k &lt;- sample(seq(3, 25, 1), 1, replace = F) # 有多少个类别，3-25
p &lt;- runif(k, 0, 1); p &lt;- p/sum(p) # 概率参数

for (j in 1:R2){

# 从协方差矩阵中删除一行/列（相同索引）
​​
在计算 n-1 x n-1 矩阵的行列式之前
#
idx &lt;- sort(sample(seq(1, k, 1), k - 1, replace = F))
cov_mat &lt;- multinomial_cov(n, p)
dets[i, j] &lt;- det(cov_mat[idx, idx])
}
}
apply(dets, 1, unique) # 无论删除哪一行/列，行列式都是
# 对于给定的一组多项式参数来说都是相同的

我似乎已经在足够多的设置中这样做了，我可能不是运气好，所以我认为我偶然发现了关于多项式的一个一般事实分布。证明是什么，这种行列式是否是多项分布中变异性的有用描述？]]></description>
      <guid>https://stats.stackexchange.com/questions/658639/generalized-variance-of-a-multinomial-distribution</guid>
      <pubDate>Thu, 12 Dec 2024 18:21:31 GMT</pubDate>
    </item>
    <item>
      <title>4x4 空心矩阵的特征值 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/658638/eigenvalues-of-4x4-hollow-matrix</link>
      <description><![CDATA[
我正在解决这道练习题，我怀疑这是个插入和吐出问题。矩阵是对称的，而且看起来可能与上下三角有关？维基百科称它为空心矩阵，而 Wolfram alpha 给出了一个奇怪的答案，没有给出任何步骤。我被困在寻找特征值的行列式步骤上，其中 4x4 矩阵看起来太大而无法有效计算行列式。
关于如何继续进行，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658638/eigenvalues-of-4x4-hollow-matrix</guid>
      <pubDate>Thu, 12 Dec 2024 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>预处理和模型选择策略</title>
      <link>https://stats.stackexchange.com/questions/658637/preprocessing-and-model-selection-strategies</link>
      <description><![CDATA[我正在研究一个故障检测问题，其中每个样本都是标有特定类型故障的时间序列。我正在使用 CNN 模型和验证集进行超参数调整。目前，我想研究不同预处理技术的影响，例如使用原始信号与应用 DFT。
为了分析这一点，我有以下验证准确度矩阵：
$$
A=\begin{bmatrix}
&amp; \text{hprams}_1 &amp; \text{hprams}_2 &amp; \text{hprams}_3 \cdots &amp; \text{hprams}_n\\
\text{Raw} &amp; \text{acc}_{11} &amp; \text{acc}_{12} &amp; \text{acc}_{13} \ \ \ \ \ \cdots &amp;\text{acc}_{1n}\\
\text{DFT} &amp; \text{acc}_{21} &amp; \text{acc}_{22} &amp; \text{acc}_{23} \ \ \ \ \ \cdots &amp;\text{acc}_{2n} \\
\end{bmatrix}, 
$$
其中每个$\text{hprams}_i$代表特定的超参数配置，每个$\text{acc}_{ij}$表示特定预处理方法和超参数设置的验证准确率。例如，$\text{hprams}_1 = (\text{number of layer}: 4, \text{learning rate}: 0.001)$ 和 $\text{acc}_{11} = 0.87$。
我有两个问题：

我目前的模型选择方法是在所有预处理方法和超参数组合中选择验证准确率最高的配置，$\max(A)$，然后在测试集上评估该模型。这是一种正确的方法吗？

为了比较预处理技术（例如 Raw 与 DFT），我建议为每种预处理方法单独选择最佳超参数配置（即在 $A$ 的每一行中取最大准确度）。然后，我将报告与这些最佳配置相对应的两个模型的测试性能。这是一种合理的方法吗？


在我审阅过的许多论文中，方法各不相同。通常，数据被分成训练集和测试集，学习率和网络架构是固定的。然后使用不同的预处理方法在训练集上训练模型，并记录各个时期的测试准确度。通常会报告最大测试准确度和最终时期准确度。但是，我认为这种方法存在缺陷，因为它缺乏适当的模型选择，可能会导致有偏差的结果。研究人员可能会尝试各种配置，并在事后隐式地选择表现最佳的设置，这可能会使结果无效。
注意：我明白准确度不是一个合适的评分规则，而且交叉验证会更好。但是，为了回答这个问题，我想在当前设置下工作。]]></description>
      <guid>https://stats.stackexchange.com/questions/658637/preprocessing-and-model-selection-strategies</guid>
      <pubDate>Thu, 12 Dec 2024 18:02:39 GMT</pubDate>
    </item>
    <item>
      <title>在拟合模型之前通过统计抽样删除数据？</title>
      <link>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</link>
      <description><![CDATA[在正常情况下，其他条件相同，数据越多越好。
我对以下情况感到疑惑：我有一个非常大的数据集，我想拟合一个统计模型。但是，我的计算机不够强大，无法在整个数据集上拟合模型。
假设每个数据点都同样可靠且具有相同的数据质量，我是否可以考虑使用统计抽样来删除某些数据点，以便模型可以在我的计算机上运行？
我认为这可能相当复杂。正如我们在构建数据集时使用调查权重来确保没有一组观察结果被低估或被高估一样，是否可以使用类似的技术来确保减少数据量不会导致任何组被高估/低估？
我认为需要进行一些逻辑检查，以确保与原始数据相比，缩小后的数据集中不存在高估/低估？例如如果原始数据为（60%-40% 男女），我们希望缩减后的数据集中男女比例也大致有 20% 的差异。但是，这只是一种比较方法（例如，缩减后，男女比例保持不变，但就业与失业比例不保持不变）。也许存在一些通用技术来比较两个数据集（即原始数据集与缩减数据集）联合分布之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</guid>
      <pubDate>Thu, 12 Dec 2024 16:25:22 GMT</pubDate>
    </item>
    <item>
      <title>当我想比较矩阵问题（每行一个答案，5pt 李克特量表，相关样本）的均值时，进行重复测量方差分析是否有效？</title>
      <link>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</link>
      <description><![CDATA[我们要求参与者对不同的项目进行评分（矩阵问题，12 个项目（行）和 5 分李克特量表（每行一个答案））。调查中的行是随机的。
问题：如何比较项目的平均值？我想知道它们是否比其他项目高/低。
这听起来很简单。如果只有两个平均值，我只需进行 t 检验。但不知何故，我不知道我可以使用什么测试来检查 12 个组织（=我的因变量）之间的平均值是如何不同的。请记住，样本是因变量（我没有 UV/组）。
我想到的是重复测量方差分析……您觉得怎么样？我知道，通常 RM Anova 的示例是“在不同时间点测量相同的因变量”。我有“不同的因变量，在略有不同的时间点进行测量”。
或者还有其他您要检查的内容吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</guid>
      <pubDate>Thu, 12 Dec 2024 15:29:06 GMT</pubDate>
    </item>
    </channel>
</rss>