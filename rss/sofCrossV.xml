<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 03 Jul 2024 21:15:54 GMT</lastBuildDate>
    <item>
      <title>线性混合模型、负信息标准值和 Hessian 矩阵不是正定的？</title>
      <link>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</link>
      <description><![CDATA[我正尝试在 R 中执行此操作。
glmm_res &lt;- glmer(Chla ~ Temp + Sal + TP + Pluviometry + (1 | season) + (1 | river), data = Chla_model, family = poisson)
summary(glmm_res)

我收到以下消息：
通知消息：
1：在 vcov.merMod(object, use.hessian = use.hessian) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵
不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov
2：在 vcov.merMod(object, correlation = correlation, sigm = sig) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵有限差分 Hessian 不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov

在中心化和缩放数据 scale(Chla_model[,2:15],center = T, scale = T) 甚至标准化 normalize(Chla) 之后，消息始终相同。
以下是汇总数据：
Chla_model &lt;- read.csv(&quot;D:/Article Sediment/ACP en langage R/Chla_model.csv&quot;, sep=&quot;;&quot;, stringsAsFactors=TRUE)
str(Chla_model)

&#39;data.frame&#39;: 45 obs. 16 个变量中的 16 个变量：
$ 季节：因子，3 个级别“干旱”、“洪水”等：1 1 1 1 1 1 1 1 1 1 ...
$ 温度：数字 30 28.9 29.8 30 30.7 31.1 32.7 33.3 31 31.7 ...
$ EC：数字 61 126 64 67 74 ...
$ DO：数字 5.59 3.55 3.96 2.74 2.58 5.62 3.37 6.24 4.57 5.14 ...
$ pH：数字 7.6 6.5 7.3 6.8 6.8 7.7 7 8 7.5 7 ...
$ 盐：数字0.0268 0.0579 0.0282 0.0297 0.0314 0.0302 0.0574 0.0345 0.0423 0.0975 ...
$ TP：数量 0.15 0.43 0.09 0.16 0.15 0.09 0.17 0.05 0.65 1.59 ...
$ PO43.：数量 0.08 0.09 0.04 0.04 0.02 0.04 0.02 0.04 0.09 0.09 ...
$ NO3. ：数量 1.4 0.95 0.34 0.17 0.23 0.21 0.25 0.8 1.07 1.15 ...
$ TN ：数量 2.43 1.84 2.39 0.74 2.41 0.37 0.69 1.31 1.96 1.85 ...
$ NH4. ：数字0.06 0.05 0.08 0.03 0.08 0.05 0.1 0.07 0.05 0.04 ...
$ NO2。 : 数值 0.011 0.005 0.019 0.015 0.018 0.013 0.02 0.02 0.012 0.014 ...
$ Chla : 数值 29.84 55.49 18.63 18.72 2.71 ...
$ 排放量 : 数值 9.5 9.5 9.5 9.5 9.5 72.3 72.3 72.3 72.3 72.3 ...
$ 雨量测定法 : 数值 115 115 115 115 115 ...
$ 河流 : 因子 w/3 个级别 “Bandama”、“Bia”、..: 3 3 3 3 3 1 1 1 1 1 ...

我欢迎您提供任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</guid>
      <pubDate>Wed, 03 Jul 2024 19:13:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信区间有效？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</link>
      <description><![CDATA[最近，我开始了我的统计学之旅，以便更好地了解该领域。以前，我的统计学经验包括记住公式、条件和后者的应用。虽然人们常常可以摆脱这种肤浅的理解，但我忽略了大多数统计实践背后的直觉。
特别是，我开始质疑置信区间的数学价值。我的理论理解如下。任何置信区间的基础都是抽样分布的概念，这是一种理论分布，我们将样本统计量纳入每个可能的大小为 n 的样本；该分布的平均值是真实的总体参数。从那里，我们选择一个所需的置信水平（用 t 或 z 值表示），并使用我们的理论抽样分布的标准差，我们构建一个区间。根据定义，我们的置信水平将表示来自我们的样本分布的总样本的百分比，这些样本在真实总体统计量的误差范围内。换句话说，如果我们要重复收集大小为 n 的样本并构建相同置信水平的置信区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。
从理论上讲，数学是可行的。但在实践中，我们所做的事情与这一理论基础背道而驰。我将说明三种我有疑问的情况：
例如，假设我们试图为总体比例创建置信区间。比例的中心极限定理和数学推理使我们得出结论，对于足够大的大小为 n 的样本，抽样分布呈正态分布，其平均值为 $p$，标准差为 $\sqrt(\frac{p(1-p)}{n})$。理论上，如果我们采用 $\hat{p}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们没有这样做，因为我们不知道 $p$ 是什么，因此不知道抽样分布的标准差。相反，我们使用 $\hat{p}$ 作为标准差方程中的替代：$\sqrt(\frac{\hat{p}(1-\hat{p})}{n})$。即使我知道 $\hat{p}$ 是 $p$ 的无偏估计量，我们怎么能确定 $C%$% 的假设区间将捕捉到真实的总体参数呢？
当然，在估计总体平均值时，我也有同样的疑问。比例的中心极限定理和数学推理使我们得出结论，对于足够大的样本 n，抽样分布呈正态分布，其平均值为 $\mu$，标准差为 $\frac{\sigma}{\sqrt(n)}$。理论上，如果我们采用 $\bar{x}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们不会这样做，因为我们通常不知道 $\sigma$ 是什么，因此不知道抽样分布的标准差。在这些情况下，我们使用标准误差来近似标准差：$\frac{s_x}{\sqrt(n)}$。鉴于这一变化，我们如何确保 $C%$% 的假设区间能够捕捉到真实的总体参数？
对于更一般的情况，中心极限定理可能不适用，统计学家使用引导法来计算置信区间。总之，他们从原始大小为 n 的样本中创建许多大小为 n 的有放回样本。通过绘制每个样本的样本统计量，我们可以创建一个伪抽样分布。从那里，我们可以通过选择与第 50 个百分位数等距的两个百分位数来创建置信区间。例如，创建一个间隔，其中第 5 个和第 95 个百分位数的值代表 90% 的置信区间。然而，这似乎是一个很大的延伸。也就是说，我们假设伪分布的标准差是我们真实抽样分布的标准差。我们如何确保$C%$% 的假设区间能够捕捉到真实的总体参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</guid>
      <pubDate>Wed, 03 Jul 2024 18:57:10 GMT</pubDate>
    </item>
    <item>
      <title>在双变量线性回归中，为什么 $Y = \alpha X + \beta + U$，其中 $\alpha$ 和 $\beta$ 是实常数，而 $U$ 是一个假设？</title>
      <link>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</link>
      <description><![CDATA[假设我想对随机变量$Y$和$X$之间进行双变量回归。在我所阅读的教科书中，主要是 Jeffrey Wooldridge 所著的《计量经济学导论》和 Davidson 与 Mackinnon 所著的《计量经济学中的估计与推断》，其中我们假设 $Y$ 和 $X$ 是线性相关的：$Y = \alpha X + \beta + U $ 其中 $\alpha \text{ and } \beta$ 是实常数，而 $U$ 是被称为误差或扰动的随机变量。我不太明白为什么用 $X$ 来表示 $Y$ 必然是一种假设。似乎我们总是能够用 $X$ 来表示 $Y$，这仅仅是由于对随机变量的算术运算。
我的意思是：从线性代数的角度来看，让我们考虑在公共样本空间 $S$ 上定义的所有实值随机变量的集合，并假设 $Y$ 和 $X$ 属于 $S$。 $S$ 是一个向量空间，前提是标量乘法和向量加法以标准方式定义，因此，对于任何实数 $\alpha$ 和 $\beta$，我们有 $\alpha X + \beta$ 也属于 $S$，并且 $Y$ 与 $\alpha X + \beta$、$Y - \left( \alpha X + \beta \right)$ 之间的差值也位于 $S$ 中。将该差值称为 $Y - \left( \alpha X + \beta \right) = U .$，因此 $Y = \alpha X + \beta + U $。我不明白我们实际上“假设”了什么，除了 $Y$ 和 $X$ 是在公共样本空间中定义的随机变量，但这似乎很简单。我明白，如果我们指定一个标准，例如最小化 $Y$ 和 $\alpha X + \beta$ 之间的 MSE，那么我们就会得到 $\alpha \text{ and } \beta$ 必须是什么。但简单地用 X 线性表示 Y 似乎不是一个假设。我听说真正的关系可能不是，而且通常不是真正线性的，因为 Y = $\alpha X + \beta$ 其中 $U$ 等于零，我明白了。但是我不明白我如何仅通过用 $X.$ 来表达 $Y$ 就假设了任何有关真实关系的事情。我误解了什么吗？我在其他地方问过这个问题，人们断言方程式 $Y = \alpha X + \beta + U$ 是关于 $Y$ 和 $X$ 之间关系的断言，但我就是不明白为什么。任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</guid>
      <pubDate>Wed, 03 Jul 2024 18:51:54 GMT</pubDate>
    </item>
    <item>
      <title>将相关性与概率联系起来</title>
      <link>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</link>
      <description><![CDATA[给定两个中心化且经过缩放的随机变量 $X$ 和 $Y$，您能将它们具有相同符号的概率与它们的相关性联系起来吗？如果相关性接近 $1$，我设想平面中的联合分布主要集中在第一象限和第三象限，其中 $X$ 和 $Y$ 具有相同的符号。情况总是如此吗？是否存在反例，其中相关性接近 $1$，但具有相同符号的概率很低？那么是否存在界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</guid>
      <pubDate>Wed, 03 Jul 2024 18:27:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ggpredict 获取第 25 和第 75 百分位数的相应标准误差</title>
      <link>https://stats.stackexchange.com/questions/650423/how-to-get-corresponding-standard-error-of-the-25th-and-75th-percentile-using-gg</link>
      <description><![CDATA[我正在使用 ggpredict 函数获取高度的预测值，其中包含 x、predicted、std.error、conf.low 和 conf.high（如下面的屏幕截图所示）
pred_height&lt;-as.data.frame(ggpredict(modfit, term=&quot;height&quot;, representative=&quot;mean&quot;, back.transform=FALSE))

我使用 quantile(pred_height$predicted) 获得了 75 百分位数和 25 百分位数的预测值。但是，我认为我无法获得使用 quantile(std.error) 预测的 25 百分位数和 75 百分位数的相应标准误差。我想知道如何获得相应的 SE？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650423/how-to-get-corresponding-standard-error-of-the-25th-and-75th-percentile-using-gg</guid>
      <pubDate>Wed, 03 Jul 2024 17:31:46 GMT</pubDate>
    </item>
    <item>
      <title>对每行具有不同数量因子的数据集进行建模（非二项式）</title>
      <link>https://stats.stackexchange.com/questions/650422/modeling-for-a-data-set-that-has-different-number-of-factors-for-each-row-not-b</link>
      <description><![CDATA[我遇到的建模问题是每行的分类变量具有不同数量的因子。如果我可以按产品（a、b、c、.....~cost、hoursum、numPod、numDate）重塑数据，以便因变量为产品类型（a、c、b、...），其余数值是独立的，这可能是一种选择，但这会违反自由度，因为它是小数据集。（并且不应包括“周”）
那么我应该如何分析成本，或者我应该对这些数据使用什么模型，因为每行都有不同数量的产品因子（Prod1 到 Prod6）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650422/modeling-for-a-data-set-that-has-different-number-of-factors-for-each-row-not-b</guid>
      <pubDate>Wed, 03 Jul 2024 17:22:18 GMT</pubDate>
    </item>
    <item>
      <title>如果有三次多项式特征，那么这不是多项式回归，而不是线性回归吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650421/if-there-are-cubic-polynomial-features-then-isnt-this-a-polynomial-regression</link>
      <description><![CDATA[我有以下问题：

考虑一个具有两个特征的线性回归问题。根据您对训练集上这些 2D 特征 $x_1$ 和 $x_2$ 的可视化，您注意到使用三次多项式特征应该可以获得更好的模型性能。将所有多项式特征以 $x_1$ 和 $x_2$ 的形式写下来。

我发现这个问题的措辞令人困惑。如果有三次多项式特征，那么这难道不是多项式回归，而不是线性回归吗？我的理解是，如果我们有三次多项式特征 $x_1$ 和 $x_2$，那么多项式回归将是 $ \hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1^2 + \beta_4 x_1 x_2 + \beta_5 x_2^2 + \beta_6 x_1^3 + \beta_7 x_1^2 x_2 + \beta_8 x_1 x_2^2 + \beta_9 x_2^3$，对吗？但交互项不是使其变为非线性而不是线性（回归）吗？我在这里误解了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650421/if-there-are-cubic-polynomial-features-then-isnt-this-a-polynomial-regression</guid>
      <pubDate>Wed, 03 Jul 2024 16:59:00 GMT</pubDate>
    </item>
    <item>
      <title>回归的预处理数据：仅缩放/标准化联合观测，还是分别缩放/标准化回归量和回归对象观测？</title>
      <link>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</link>
      <description><![CDATA[假设您观察到两个变量$X, Y$（回归量和回归函数），它们在统计上是相关的，$Y \sim X$。
您的数据是独立同分布样本$\mathcal{D}:=\{(x_j, y_j) \mid j=1,\ldots, N\}\subset \mathbb{R}^ {d_X}\!\!\times\!\mathbb{R}^{d_Y}$ of $(X,Y)$。
然后，您想对这些数据应用某种回归方法，比如核岭回归或 SVR。
为此，通常建议对数据样本进行预处理$(x_j)$ 和 $(y_j)$ 可以通过对它们进行归一化或标准化来量化。
问题：这样的标准化/归一化是否会应用于联合观测值$\{(x_j, y_j)\}$（的子集），或者组件数据$(x_j)$ 和 $(y_j)$ 是否应该分别缩放？
由于关联$Y\sim X$ 非常非线性（例如$Y = e^X + \varepsilon$ 或类似），分别预处理 $(x_j)$ 和 $(y_j)$ 似乎是有问题的，因为分别对回归对象和回归量样本应用不同的（$(x_j)$- 和 $(y_j)$-依赖）尺度可能会对统计关联 $Y\sim X$ 造成非平凡的干扰。
很高兴看到相关文献或任何最佳实践的链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</guid>
      <pubDate>Wed, 03 Jul 2024 16:49:03 GMT</pubDate>
    </item>
    <item>
      <title>如何处理威布尔模型中的中间观测值（审查）</title>
      <link>https://stats.stackexchange.com/questions/650416/how-to-handle-intermediate-observations-in-weibull-models-censoring</link>
      <description><![CDATA[我目前正在更新之前创建的组件故障威布尔模型。
情况：

我有可用的数据，显示机器的某个组件是否因某种特定故障模式而被更换（主要是在检查期间，但有时机器会停止运行，组件会因严重损坏而被更换）。
数据包含组件的序列号、截至当日的使用寿命（以小时为单位）以及事件是否发生。

现在我不确定如何处理安装和拆卸之间具有唯一序列号的特定组件的观察结果。例如：零件在发生故障之前通常会被检查两到四次。（数据：|---0---0---0---1）。现在这些“0”点是否应作为右删失事件包含在模型数据中？我把右删失观测值理解为事件，我们不知道组件之后会发生什么。
我的观点是，如果我们知道确切的交换时间（由于严重损坏而没有检查/交换），则不会考虑这些观测值。如果在检查期间更换了组件，则它是区间删失数据。在这种情况下，更换将在没有事件的最后一次检查和事件之间进行。
之前创建的威布尔模型包含所有中间观测值作为右删失观测值，以及所有发生故障的观测值作为发生事件。
我做了很多研究，但在这个案例中找不到明确的答案。如果您有关于这个案例的文献，请分享它来帮助我。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650416/how-to-handle-intermediate-observations-in-weibull-models-censoring</guid>
      <pubDate>Wed, 03 Jul 2024 15:57:40 GMT</pubDate>
    </item>
    <item>
      <title>计算百分比标准化</title>
      <link>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</link>
      <description><![CDATA[请不要笑或关闭这篇文章，我对如何计算治疗后发生的正常化百分比感到困惑。
所以，这是问题的背景，我从用药物 A 和 B 治疗的对照和患病样本中读取了数据。读数是在药物的两个时间点，即时间 0 和时间 x。这些记录在下表中。
 基因控制 DrugA.to DrugA.tx DrugB.to DrugB.tx
GeneA1 0.255137598 0.996823656 0.841427508 0.838585838 0.637163007
GeneA2 0 1.002128241 1.088924271 0.708817547 0.858001516
GeneA3 0.649779583 0.970614468 0.883699106 0.863034514 0.863533489
GeneA4 0.261785973 1.228567772 0.860292411 0.950751742 1.026950264
基因A5 0 0.964363461 1.177734151 0.831123556 1.496702315
基因A6 0.539853517 1.185978246 0.999361733 0.88790566 0.926980252
基因A7 0.609842771 1.245618868 1.095380831 0.91075683 1.038654277
基因A8 0.546278983 1.143557146 1.31081493 0.961478462 0.955452931
基因A9 0.278067545 1.565468159 1.2463365 1.039837814 0.961697678
基因A10 0.841483131 1.637659304 1.195102944 1.171462249 1.274326013
基因A11 1.066410285 1.40104267 1.200123252 0.957711736 1.525794178
基因A12 2.613408631 1.052950881 0.908745691 0.863034514 0.892767429
基因A13 2.583216456 1.105396939 1.242388547 0.87318548 0.623271818
基因A14 2.800415579 1.097795107 0.999763993 0.893300428 0.863533489
基因A15 1.044277784 1.534601183 1.213267026 1.08889909 1.797417187
GeneA16 0 2.476333854 2.055473655 1.021699805 1.138185985
GeneA17 1.861254616 1.147626264 1.72825638 1.009700622 0.963547498
GeneA18 0.850735068 2.07213776 1.675176397 1.352168483 1.026950264
GeneA19 2.784079193 1.097795107 1.03334891 0.863034514 1.246543636
GeneA20 0.600378056 1.55167128 1.837088792 1.116134855 2.35125585
GeneA21 0.789140187 2.195590214 2.109625834 1.322807345 1.200786951
GeneA22 0.560671399 1.559604269 2.014979635 1.634260415 1.910905861
GeneA23 3.176300908 1.200678944 1.406041611 0.890985128 1.200293773
GeneA24 1.959958568 1.747658569 1.31081493 1.394319133 1.533792282
GeneA25 1.815692 1.933923319 1.221955458 1.08889909 1.971098865
GeneA26 2.918198494 1.2461771 1.847890057 0.998327027 1.200786951

现在我如何显示和/或计算药物 A或者药物 b 使基因表达更接近对照。我所说的“接近对照”是指，治疗后，时间 x 处的基因表达要么减少，要么增加，但其方向与对照方向一致，例如，GeneA1 在对照中的表达为 0.25，而在用药物 A 治疗的患病样本中，表达减少了 15.15% ((0.84-0.99)/0.99)，而用药物 B 治疗的表达减少了 24%。因此，对于基因 A，可以说药物 B 使基因表达更接近对照。现在，我想计算药物 A 和 B 的总体效果，而不是单个基因。
我可以计算每种药物每个基因的倍数变化或百分比倍数变化，但我如何显示哪种药物使基因表达更趋向于控制。
我脑海中有一个这样的图，其中绿色和紫色是药物 A 和 B。

感谢您的时间和帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</guid>
      <pubDate>Wed, 03 Jul 2024 15:57:27 GMT</pubDate>
    </item>
    <item>
      <title>互相关的重复测量分析</title>
      <link>https://stats.stackexchange.com/questions/650414/repeated-measurements-analysis-with-cross-correlation</link>
      <description><![CDATA[我正在尝试寻找水坝放水量和下游温度之间的因果关系。我有一个数据框，其中包含下游各个站点和尾水测量仪的所有温度测量值（见下文）。
dput(head(SaltData))
structure(list(Date = structure(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), class = c(&quot;POSIXct&quot;, &quot;POSIXt&quot;
), tzone = &quot;UTC&quot;), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(7.8908984375, 7.847998046875, 
7.8908984375, 7.80509765625, 7.847998046875, 7.847998046875), 
S5 = c(10.464921875, 10.507822265625, 10.507822265625, 
10.55072265625, 10.507822265625), S6 = c(11.280029296875, 
11.3229296875, 11.3229296875, 11.280029296875, 11.3229296875, 
11.280029296875), S7 = c(11.3229296875, 11.3229296875, 11.3229296875, 
11.365830078125, 11.3229296875, 11.365830078125), S8 = c(12.309638671875, 
12.309638671875, 12.26673828125, 12.3525390625, 12.3525390625, 
12.309638671875), S9 = c(10.808125, 10.808125, 10.851025390625, 
10.808125, 10.89392578125, 10.89392578125), S10 = c(11.06552734375, 
11.06552734375, 11.06552734375, 11.151328125, 11.194228515625, 
11.151328125), S11 = c(10.9797265625, 10.9797265625, 10.9797265625, 
10.9797265625, 11.06552734375, 11.022626953125), GaugeTemp = c(8.2, 
8.2, 8.2, 8.2, 8.2, 8.2), GaugeHeight = c(70.83, 70.84, 70.84, 
70.85, 70.83, 70.83)), row.names = c(NA, 6L), class = &quot;data.frame&quot;)

问了上一个问题后，我已获悉数据结构。我所做的是下游站点和尾水测量仪之间的相关性，但这并没有给我一个看似正确的模式（相关性随着每个下游站点而增加，这实际上应该与应该看到的相反）。我现在意识到我有重复的测量数据，并希望在两者之间进行某种互相关。我意识到我需要滞后数据以解释水流到每个站点的下游时间。我只是想知道这是否是分析数据以显示大坝释放（尾水测量仪）对下游温度的直接影响的好方法，或者另一种测试是否更好。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650414/repeated-measurements-analysis-with-cross-correlation</guid>
      <pubDate>Wed, 03 Jul 2024 15:44:07 GMT</pubDate>
    </item>
    <item>
      <title>关联替代方案/如何测试这种关系？</title>
      <link>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</link>
      <description><![CDATA[我有来自上游和下游测量仪的大量温度数据。我试图找出大坝泄水对下游温度的影响。为此，我正在比较尾水测量仪（位于大坝正下方）与各个下游站点之间的相关性。这是我的数据集。
&gt; dput(head(TravelTimeAdjustedSaltData))
结构(列表(日期 = 结构(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), 类 = c(&quot;POSIXct&quot;, &quot;POSIXt&quot;
), tzone = &quot;UTC&quot;), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(NA, NA, NA, NA, 7.8908984375, 
7.847998046875), S5 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S6 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S7 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S8 = c(12.309638671875, 12.309638671875, 
12.26673828125, 12.3525390625, 12.3525390625, 12.309638671875
), S9 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_
), S10 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), S11 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), GaugeTemp = c(8.2, 8.2, 8.2, 8.2, 8.2, 8.2), GaugeHeight = c(70.83, 
70.84, 70.84, 70.85, 70.83, 70.83)), row.names = c(NA, 6L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))

数据根据下游水流时间进行了调整，这就是为什么某些列的前几行有 NA。无论如何，我进行了 Spearman 相关性分析，但发现了一种意料之外的模式，因此，我认为相关性并没有真正检验我真正想要发现的东西。我发现，下游站点 (S10 / S11) 与尾水水位计的相关性实际上比下游第一个站点 (S4) 更高或大致相同。我同时包含了 S4（距离尾水下游最近的站点）和 S11（距离尾水最远的站点）来说明我的意思。事实并非如此，因为大坝泄水对下游温度的影响应该会随着距离的增加而减小。这让我相信相关性测试不是我的问题的答案。


cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S11, method = &quot;spearman&quot;, na.rm=TRUE)
cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S4, method = &quot;spearman&quot;, na.rm=TRUE)
我不知道如何测试大坝泄洪的原因（即尾水压力表温度读数）及其影响（下游温度读数）。我正在研究两者之间的某种非参数回归，但不确定这是否是正确的方法。任何帮助都将不胜感激。我只是想要一种统计方法来显示大坝泄洪是否确实对下游产生影响。相关性似乎没有达到这个目的（虽然不确定为什么）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</guid>
      <pubDate>Wed, 03 Jul 2024 13:20:19 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的混杂变量：辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</link>
      <description><![CDATA[我正在研究一个混合效应回归模型，其中 Yi = 学生 i 的考试成绩。
解释变量如下：

级别 3：学校类型（公立与私立）和学校的社会经济水平（数字变量）

级别 2：每个班级的教育模式（100% 西班牙语、50% 西班牙语、特殊教育）

级别 1：移民背景（学生是否是移民）、学生的社会经济水平（数字变量）、在家使用的语言（西班牙语或其他语言）以及学生的身份（学生是否必须留级）
我使用两个模型来解释 Y。第一个模型不包括变量 student_socioeconomic 和student_idoneity。
model1 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_inmigrant + student_language)
model2 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_socioeconomic + student_inmigrant + student_language +
student_idoneity)


在第一个模型中，变量“student_inmigrant”的估计系数为正，并且在 1% alpha 水平上显著。然而，当我添加变量“student_socioeconomic”时和“student_idoneity”，变量“student_inmigrant”的估计系数在 1% alpha 水平上变为负且显著。
我认为这里存在混杂变量的问题，但我不知道如何解决。您能给我一些关于如何处理这个问题的建议吗？
我检查了存在多重共线性时的 VIF 值，但 student_inmigrant、student_idoneity 和 student_socioeconomic 的调整后的 GVIF 都低于 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</guid>
      <pubDate>Wed, 03 Jul 2024 12:15:21 GMT</pubDate>
    </item>
    <item>
      <title>有限数据集的对象检测</title>
      <link>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</link>
      <description><![CDATA[考虑以下场景

如果我想训练一个模型来检测和计算这些方块：

这些方块永远不会不同。它们看起来总是一模一样，大小也完全相同，永远不会有某种重叠或障碍，也不会改变颜色等 - 它们总是完全相同。
但是反复训练同一张图片（因为您会使用其他什么图片来制作数据集？它永远不会改变），它无法正确识别这些框。如果您拍摄图像并制作扭曲的版本以便获得数据集，它仍然无济于事。
我该如何针对这种简单的场景训练算法？或者对象检测（或分类，如果我们包括标记的对象，那么我们将有 2 个类）是否仅适用于可以“在视觉上改变/扭曲”的事物，而不适用于始终相同的事物？
我一直在尝试查找有关它的文献、论文和文章，但我不知道这个问题叫什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</guid>
      <pubDate>Wed, 03 Jul 2024 03:04:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要使用零假设下假设的值来计算比例的标准差？</title>
      <link>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</link>
      <description><![CDATA[在计算第 2 类错误时，为什么即使我们将备择假设作为可能的真实值，我们仍使用零假设下的假设值来计算标准差？
如果零假设中 u = 20，备择假设中 u = 24，且采样 x = 21，则 H0σ（基于零假设计算）。我们通过“(x-24)/H0σ”计算第 2 类错误。我的问题是为什么不使用 H1σ...？
示例案例 - https://www.youtube.com/watch?v=BJZpx7Mdde4
我的教科书中的另一个示例案例（Martin Sternstein 先生的 EZ-101 统计学）
]]></description>
      <guid>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</guid>
      <pubDate>Wed, 03 Jul 2024 00:31:40 GMT</pubDate>
    </item>
    </channel>
</rss>