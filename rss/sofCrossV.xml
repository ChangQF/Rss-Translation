<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 16 May 2024 03:17:51 GMT</lastBuildDate>
    <item>
      <title>基于曲线预测连续变量</title>
      <link>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</link>
      <description><![CDATA[我有一组在不同频率下测量的曲线的数据集，因此它由如下图所示的曲线组成。当然，我的数据集还有更多曲线。曲线与连续因变量（例如高度）相关联。哪种机器学习方法可以让我根据整个曲线来预测因变量的值？
我想过线性混合效应，但是有没有一种机器学习方法，例如高斯过程，有谁知道我如何做到这一点的例子？
我没有高斯过程的经验，但我想学习如何做到这一点。
谢谢，非常感谢您的帮助。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</guid>
      <pubDate>Thu, 16 May 2024 00:53:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间序列数据的平稳性</title>
      <link>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</link>
      <description><![CDATA[我正在处理时间序列，想要测试不同的预测方法，但首先我需要测试我的时间序列（销售）数据是否稳定。所以我一直在学习KPSS和Dickey-fuller测试。我的数据是以百万美元为单位的货币价值
我是个新手，所以我仍在学习、阅读和观看有关如何操作的教程。我开发了一个 dickey-fuller：

无漂移：
t-stat=-1.6899
有漂移：
t-stat=9.9672
漂移+趋势：
t-stat=-9.9099
增强（2 个滞后）：
t-stat=-4.6365

我的最全面的关键价值观是：

&lt;标题&gt;

值
无趋势
趋势


&lt;正文&gt;

1%
-3.43
-3.96


5%
-2.86
-3.41



我所看到的（如果我错了，请纠正我）是，除了“无漂移”之外的所有内容都可以。 t-stat 显示我的时间序列数据是平稳的。
第一个问题：我是否可以假设因为 4 个 t 统计中有 3 个通过了平稳性测试，所以我的系列数据是平稳的？我不清楚如果无漂移 t-stat 显示不平稳，我应该得出什么结论。
第二个问题：我的累积残差没有加到零，所以这意味着我做错了什么？
因为我对Dickey-fuller感到困惑，所以我也参加了KPSS测试。以下是我的结果：

&lt;标题&gt;

值
常量
常量 + 趋势


&lt;正文&gt;

KPSS
0.02090016
0.020655886


临界值95%
0.463
0.146


临界值99%
0.739
0.216



因此，因为我的临界值高于我的 KPSS 统计数据，所以我接受零假设，并且我的数据系列是平稳的。
完成所有测试后，看起来我的数据确实是静止的，但我不确定我的残差没有加到零这一事实是否意味着我做错了什么，并且 t-stat 是否没有漂移，表明单位根的存在与我继续使用需要固定数据的预测方法相关。
如果您可以支持我，请告诉我。
提前谢谢您。
正如我之前提到的：
创建数据图表
迪基富勒测试
没有漂移，
随着漂移，
漂移+趋势，
增强（2 个滞后），以及
KPSS - 您可以看到上面的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</guid>
      <pubDate>Thu, 16 May 2024 00:13:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用泊松和高斯族对泊松数据进行 glm 拟合几乎没有差异？</title>
      <link>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</link>
      <description><![CDATA[我一直对模拟泊松分布数据的玩具回归问题感到困惑，并希望受过更多统计学教育的人可以帮助我对以下观察结果有一些了解。
使用的库
库(tidyverse)
图书馆（牛区）
图书馆（扫帚）
库（基于模型）
库（参数）
图书馆（ggbeeswarm）

数据生成
我使用 rpois 模拟了两种场景的计数值：

交通事故计数，其中 lambda 与交通量成线性比例。
当 lambda 按交通量指数缩放时的交通事故计数。

# 观察值
n_obs = 10

# 生成日志相关数据
流量 = log(c(1, 2, 4, 7, 10, 15))
日志数据=小标题（
  流量=流量_流量，
  lambda=exp(0.43*体积+0.2)
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

# 生成线性相关数据
线性数据=小标题（
  流量=流量_流量，
  拉姆达 = 0.43*体积 + 0.2
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

建模
我为每个数据集拟合了两个 glms。一种使用gaussian族，另一种使用poisson族。我对日志数据使用了“log”链接器，对线性数据使用了“identity”链接器。
# 适合
proc_list = 列表(
  日志=列表（数据=log_data，链接器=“日志”），
  线性=列表（数据=线性_数据，链接器=“身份”）
）
模型 = 地图（proc_list，函数（proc）{
  泊松模型 &lt;- glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    家庭=泊松（链接= proc $链接器），
  ）
  高斯模型 = glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    族=高斯(link=proc$linker),
    开始=c(1, 1)
  ）
  返回（列表（“泊松”= poisson_model，“高斯”= gaussian_model））
})

结果
&lt;代码&gt;&gt; Compare_models(unlist(模型，递归=FALSE))

参数|对数泊松 |对数高斯 |线性泊松|线性高斯
-------------------------------------------------- ----------------------------------------------------------
（拦截）| 0.01（-0.40，0.43）| -0.03 (-0.59, 0.53) | 0.39（0.06，0.73）| 0.43（-0.08，0.94）
卷 | 0.52（0.32，0.72）| 0.54（0.30，0.79）| 0.36（0.13，0.59）| 0.34（0.05、0.62）
-------------------------------------------------- ----------------------------------------------------------
观察| 60| 60| 60| 60

可视化
# 创建可视化网格并预测值
viz_grid = modelbased::visualization_matrix(tibble(volume=traffic_volume)) %&gt;% as_tibble
增强=map_df（unlist（模型，递归= FALSE），函数（.x）{
  增强（.x，newdata = viz_grid，type.predict =“响应”）
}, .id=&quot;型号&quot;)

# 单独的模型和数据标签
增强=增强%&gt;%
  split(“模型”, c(“数据”, “回归”), sep=&quot;\\.&quot;)

p = map_df(proc_list, ~.x$data, .id=&quot;数据&quot;) %&gt;%
  解除嵌套（事故计数）%&gt;%
  ggplot(aes(体积, 事故计数)) +
  # geom_violin(调整=1.5) +
  geom_quasirandom() +
  几何点（
    data=~.x %&gt;% unique(数据、体积、observed_avg_accidents),
    aes（数量，observed_avg_accidents），
    颜色＝“红色”
  ) +
  geom_line(数据=增强，aes(体积，.fitted，颜色=回归)) +
  facet_wrap(~data, labeller=label_both) +
  主题灰色(base_size=16)
p %&gt;% ggsave(file=“temp.pdf”, w=8, h=4)


问题
为什么无论家庭功能如何，拟合基本上没有差异？我故意选择了少量的观察值和相对较小的 lambda 值，希望使用高斯拟合家庭会崩溃。但这并没有发生。如果这里的数据生成过程真的是泊松分布，那么族函数的选择不会影响拟合吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</guid>
      <pubDate>Wed, 15 May 2024 23:10:11 GMT</pubDate>
    </item>
    <item>
      <title>PCA 因子模型 - 无关紧要的因子载荷</title>
      <link>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</link>
      <description><![CDATA[我有一个包含 N 个资产的时间序列，我正在尝试为其估计因子模型。令 $Z_{t}$ 为这些资产在 $t$ 时的价格之一。我们可以将其写为：
$$
Z_{t} = β F_{t} + θ_{t}
$$
其中 $F_{t}$ 是一些线性因子，$\theta_{t} = \alpha + \ epsilon_{t}$，$\epsilon_{t}$ 是一些具有协方差的白噪声 $\Sigma_ {\theta}$
有了这些假设，我们可以将 $Z_{t}$ 的期望值写为：
$$
\mu_{z} = \alpha + \beta \mu_{F}
$$
协方差矩阵：
$$
\Sigma_{z} = \beta\Sigma_{\theta}\beta^{T} + \Sigma_{\theta}
$$
我们的想法是，我们显着减少了需要估计的参数数量（尤其是协方差），因此（希望）估计出噪声较小的均值和协方差。
如果有一些股票投资组合，其投资组合权重为 $\mathbb{x}$，那么我们可以将投资组合均值写为 $\mu_{p} = \mathbb{b}\mu_{F}$，其中 $\mathbb{b} = \beta^{T }\mathbb{x}$ 和投资组合协方差为 $\mathbb{b}^{T}\Sigma_{F}\mathbb{b} + \mathbb{ x}^{T}\Sigma_{\theta}\mathbb{x}$。
我选择对贬低数据矩阵进行 SVD 分析作为因子模型（可以证明这相当于对协方差进行 PCA）。这非常方便，因为协方差矩阵 $\Sigma_{F}$ 与特征值平方成对角线。一旦我获得了 PC，我的 $F_{t}$，我就会估算 $\beta$ OLS 参数（但是，我也尝试了一些其他方法，例如迭代重新加权最小二乘法）。然而，在诊断分析中我可以看到这些参数并不重要。我对此有点困惑。一方面，我将其理解为只是一种线性代数方法，即最小二乘法只是一种用于查找因子的数值方法，那么显着性应该不重要（与推理意义上的回归不同）。即便如此，如果我的参数接近于零（微不足道），那么我的因子并没有真正..正确分解..。
有人可以向我解释一下这个结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</guid>
      <pubDate>Wed, 15 May 2024 23:05:28 GMT</pubDate>
    </item>
    <item>
      <title>条件期望算子是否像线性代数中的投影矩阵那样具有可解释的分解？</title>
      <link>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</link>
      <description><![CDATA[我试图将有限线性空间中的投影概念与无限线性空间中的投影概念进行比较。
这是设置，首先是有限维情况，然后是无限维情况：
给定一个单射矩阵 $A: \mathbb{R}^m \rightarrow \mathbb{R}^n$，我们可以构造一个正交投影算子让$P_A = A(A^TA)^{-1}A^T$。然后我们可以用它来获取 $y \in \mathbb{R}^n$ 并将其投影到 $A$ 得到 $P_A y = x \in \text{col(A)}$。
现在假设我们有两个随机变量 $X$ 和 $Y$，其二阶矩存在。条件期望 $\mathbb{E}[X|Y]$ 为我们提供了一些新的随机变量 $h(Y) $ 即 $X$ 到 $\sigma(Y)$ 的正交投影，$Y$ 的 sigma 代数。
我的问题是，在条件期望情况下是否存在与 $A$ 类似的可解释的类比。也就是说， $\mathbb{E}[X|Y]$ 是 $P_A$ 作为 [ ???] 是 $A$。
我看到用户 ExcitedSnail 在这里&lt; /a&gt;，但问题下面的评论似乎没有解决问题，除非我只是误解了。]]></description>
      <guid>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</guid>
      <pubDate>Wed, 15 May 2024 21:59:19 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中包含不相关变量时的方差比</title>
      <link>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</link>
      <description><![CDATA[我有兴趣知道是否有一个通用公式来计算正确指定模型和错误指定模型中预测变量的回归系数方差之比。
具体来说，假设我们有一组与回归 X 真正相关的变量和一组与回归 Y 不相关的变量，并且我们做了两个回归。
首先，我们进行 $y = X\beta_1$ 形式的加权最小二乘回归，这是正确的，并给出了 $\hat{\beta_1}$。
然后，我们进行形式为 $y = X\beta_1 + Y\beta_2$ 的加权最小二乘回归，这是正确的，给出的系数估计为$\tilde{\beta_1}$。
我有兴趣以封闭形式描述比率 $var(\hat{\beta_1}) / var(\tilde{\beta_1})$。&lt; /p&gt;
对于普通的未加权线性回归，Fomby 表现出回归分析效率损失，原因是
不相关变量：根据预测变量 $r_i$ 之间的典型相关性，两个模型中的方差比存在一个封闭形式 $var(\hat{\beta_1}) / var(\tilde{\beta_1}) = \prod_i \frac{1}{1 - r_i^2}$。
对于加权最小二乘法的情况，是否有一个清晰的概括？]]></description>
      <guid>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</guid>
      <pubDate>Wed, 15 May 2024 21:57:27 GMT</pubDate>
    </item>
    <item>
      <title>包含随机效应会降低模型拟合度</title>
      <link>https://stats.stackexchange.com/questions/647320/including-random-effect-reduces-model-fit</link>
      <description><![CDATA[我正在将零膨胀负二项式 GLMM 拟合到模型计数中。除 Effort_sq 为非零值外，固定效应均为分类效应。该实验在一次旅行中进行了多次，并进行了多次旅行（&gt; 6 个级别，因此我将其作为随机效应包括在内）。
shark_zi &lt;- glmmTMB(sharks ~ Treatment+ Net_type + Effort_sq + (1|Trip_code), ziformula = ~., family=“nbinom1”, data=P1)

我使用 DHARMa 包执行诊断，它表明分位数测试很重要：
simulateResiduals（fittedModel = shark_zi，plot = T）


但是，如果我尝试使用 GLM，则测试并不重要：
shark_zi_2 &lt;- glmmTMB(sharks ~ Treatment+ Net_type + Effort_sq, ziformula = ~., family=“nbinom1”, data=P1)

模拟残差（fittedModel = shark_zi_2，图= T）


我比较了两个模型，如  Bolker GLMM 常见问题解答
anova(shark_zi, shark_zi_2)


我如何解释这些结果以及为了改善贴合度我还应该考虑什么？我没有其他变量作为随机效应包含在内，并且我已经使用“疏浚”执行了模型选择，但由此产生的简化模型也不太适合。
另外，排除随机效应会不会是伪复制？根据 Hurlbert (1984)，“考虑不测试随机效应的显着性。如果随机效应是实验设计的一部分，这个过程可以被认为是“牺牲性伪复制”
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647320/including-random-effect-reduces-model-fit</guid>
      <pubDate>Wed, 15 May 2024 21:30:03 GMT</pubDate>
    </item>
    <item>
      <title>我对嵌套交叉验证、最终模型调整的理解/方法是否正确？</title>
      <link>https://stats.stackexchange.com/questions/647319/is-my-understanding-approach-to-nested-cross-validation-final-model-tuning-corr</link>
      <description><![CDATA[我正在使用不平衡类的有限训练数据来训练 SVM。
以下是我想做的事情：
1.) 我想声明该方法对不同独立训练和测试数据集的通用性。
2.) 我想训练最终的生产模型。
对于 1.)，我的理解是我会进行嵌套交叉验证。
这是我从各种来源艰难地总结出来的方法，只是希望得到有关这里是否有严重错误的反馈：
# 我想在优化中尝试的 SVM 参数
parameters_svm = {&#39;C&#39;: [1, 10, 100, 1000], &#39;kernel&#39;: [&#39;线性&#39;], &#39;概率&#39;: [True]}



# 定义内部和外部cv
# 在这里，我为内部简历选择了“n_splits=5”，为外部简历选择了“n_splits=10”，因为 https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/
# 我决定在这里使用 StratifiedKFold 作为内部简历，因为类别不平衡
# 我决定在外部 cv 中使用带有 n_repeats=10 的 RepeatedStratifiedKFold，因为它将在合理的时间内运行，并且因为您希望获得基于多次迭代的性能数字似乎是有意义的。


inner_cv = StratifiedKFold(n_splits=5,random_state=42, shuffle=True)
external_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)




# 运行嵌套交叉验证并计算外部分数（泛化误差）
嵌套得分 = cross_val_score(clf, X=nX, y=y, cv=outer_cv, 评分=&#39;balanced_accuracy&#39;)

print(f&#39;嵌套 CV 平衡精度：{nested_scores.mean()} +/- {nested_scores.std()}&#39;)

对于 2.)，我在这里不太确定，我已经看到了一些关于利用在嵌套 CV 中最常表现最佳的超参数集的讨论，但基于此 link 我会做一个外循环的循环，例如： 
grid = GridSearchCV(估计器=SVC(), param_grid=parameters_svm, cv=outer_cv, Scoring=&#39;balanced_accuracy&#39;)
网格.fit(X, y)

# 获取最佳参数
best_params = grid.best_estimator_.get_params()

这一切有意义还是我离谱了？]]></description>
      <guid>https://stats.stackexchange.com/questions/647319/is-my-understanding-approach-to-nested-cross-validation-final-model-tuning-corr</guid>
      <pubDate>Wed, 15 May 2024 21:04:03 GMT</pubDate>
    </item>
    <item>
      <title>相关数据集中的 Fisher 精确检验</title>
      <link>https://stats.stackexchange.com/questions/647318/fisher-exact-test-in-correlated-dataset</link>
      <description><![CDATA[假设我有 n 个科目。我对它们进行了两次测量，得出了一些二元结果。现在我想测试之前测量的结果是否与后来测量的结果一致。通常，我需要通过 McNemar 检验而不是卡方检验/Fisher 精确检验来完成此操作，后者不考虑重复测量。
$Q:$ 假设给出了数据 (n&lt;50) 并且标识符被删除。人们被迫使用卡方检验或费舍尔精确检验。假设在这种情况下相关性为正。在这种情况下可以使用 Fisher 精确检验吗？请注意，Fisher 的精确检验条件基于边际，而卡方条件基于独立性假设。
$Q&#39;:$ 在这种相关性&gt;0.2 的情况下，卡方检验和 Fisher 精确检验的覆盖范围有多差？]]></description>
      <guid>https://stats.stackexchange.com/questions/647318/fisher-exact-test-in-correlated-dataset</guid>
      <pubDate>Wed, 15 May 2024 21:02:21 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试拟合一个混合效应模型，并以比例作为响应。我很困惑哪个分布适合我的模型</title>
      <link>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</link>
      <description><![CDATA[目前，这是我最适合的模型。 dHARMA 看起来不太好。响应有许多 0 和许多 1
model_pollen_species.bi &lt;- glmmTMB(proportion_sunflower ~ 物种 +
                    (1|农场) + (1|日期) + (1|Bee.ID),
                    家庭=二项式（链接=“logit”），
                    数据=组合花粉）
                             
诊断（model_pollen_species.bi）

模拟.model_pollen_species.bi &lt;-
     模拟残差（fittedModel = model_pollen_species.bi）

情节（模拟.model_pollen_species.bi）

dHARMA 残差：
]]></description>
      <guid>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</guid>
      <pubDate>Wed, 15 May 2024 20:45:12 GMT</pubDate>
    </item>
    <item>
      <title>给定$X$和$Y$的边际和联合分布，如何从$X=x_0$估计$Y=y_0$？</title>
      <link>https://stats.stackexchange.com/questions/647312/given-the-marginals-and-joint-distribution-of-x-and-y-how-to-estimate-y-y</link>
      <description><![CDATA[假设我有两个随机变量 $X$ 和 $Y$ 及其边际分布（例如GEV 和 t 位置尺度），并假设它们的联合分布是 Frank copula 及其参数 ($\theta$)。我想知道，对于给定的 $X$ 值，如何估计 $Y$&lt; 的相应值/span&gt; 来自联合分布？
我已阅读这篇相关文章它的链接，但仍然无法弄清楚如何评估联合分布的条件期望。顺便说一句，正如链接文章中提到的，我还看到了 Python 中的一个 copula 包，您可以在其中插入数据，并且它会模拟具有相同依赖结构的新数据。但我不知道如何根据 $X$ 的给定值估计 $Y$将联结函数拟合到数据。
编辑：
我将用一个例子来阐明我的观点，
假设我们有 100 行数据，其中有两个随机变量 $X$ 和 $Y$。假设我已经计算了 $X$ 和 $Y$ 的边际分布及其联合分布（这是系词）。假设我的数据中的一行的值为 $X=10 $ 和 $Y= 15.4$ ，我想使用拟合的 copula 来开发一个模型，这样如果我将值 $X=10$ 赋予模型，它就会估计相应的 $Y$（假设它估计为$Y= 15.6$）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647312/given-the-marginals-and-joint-distribution-of-x-and-y-how-to-estimate-y-y</guid>
      <pubDate>Wed, 15 May 2024 20:01:16 GMT</pubDate>
    </item>
    <item>
      <title>最高密度与等尾置信区间</title>
      <link>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</link>
      <description><![CDATA[当采样分布是对称的（如果必要的话，我也可以假设单峰分布），很自然地将置信区间集中在点估计周围。但对于偏态分布（例如卡方），选择端点（在我见过的每一本书中）来创建 等尾间隔（ETI） 这似乎也是一个“自然”的选择。但在这种情况下，另一个自然的选择是最高密度区间 (HDI)。 （我只在贝叶斯可信区间设置中看到过 ETI 和 HDI，但它们似乎同样适用于频率论置信区间设置。）

在现实世界中是否存在使用 HDI 置信区间（更有意义？）的场景？我更喜欢一个统计量是样本方差的示例。
为什么教科书中没有讨论 HDI 与 ETI 的置信区间？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</guid>
      <pubDate>Wed, 15 May 2024 19:34:37 GMT</pubDate>
    </item>
    <item>
      <title>基于“排序均匀分布”和 beta 分布的常数近似</title>
      <link>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</link>
      <description><![CDATA[让 $X_1, X_2 \stackrel{\text{iid}}{\sim}\mathrm{Uniform}(0,1)$ 然后排序 &lt; span class=&quot;math-container&quot;&gt;$X_1,X_2$ 得到 $X_{(1)} $X_{(1)} &lt; X_{(2)}$。
根据$X_{(i)}$的pdf，我们知道$X_{(1)} \sim \mathrm{Beta}(1,2)$ 和 $X_{(2)} \sim \mathrm{Beta}(2,1)$ span&gt;，其中 $\mathbb{E}(​​X_{(1)}) = \frac{1}{3}$ 和 $\mathbb{E}(​​X_{(2)}) = \frac{2}{3}$。
考虑函数 $f(x) = x$ 的常数近似。

在 $(0, 1)$$x_1, x_2$ &gt; 然后对它们进行排序以获得 $x_{(1)}$ 和 $x_{(2)}$ span&gt;, $x_{(1)} &lt; x_{(2)}$。将期望表示为 $\mathbb{E}_1(\|f - c\|_2^2) = \mathbb{E}_1(\displaystyle\int_{x_{(1 )}}^{x_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {x_{(2)}-x_{(1)}}\displaystyle\int_{x_{(1)}}^{x_{(2)}} f(t)\; dt$ 是一个常数。

来自 $\mathrm{Beta}(1,2) 的示例 $y_{(1)}$ )$ 和 $y_{(2)}$ 来自 $\mathrm{Beta}(2,1 ）$。将期望表示为 $\mathbb{E}_2(\|f - c\|_2^2) = \mathbb{E}_2(\displaystyle\int_{y_{(1 )}}^{y_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {y_{(2)}-y_{(1)}}\displaystyle\int_{y_{(1)}}^{y_{(2)}} f(t)\; dt$ 是一个常数。


（注：$\mathbb{E}_1$ 和 $\mathbb{E}_2$ 的定义 相同；唯一的区别是获取点的方法$x_{(i)}, y_{(i)}$。）
比较 $\mathbb{E}_1(\|f - c\|_2^2)$ 和 $ \mathbb{E}_2(\|f - c\|_2^2)$。通过数值实验观察到 $\mathbb{E}_1(\|f - c\|_2^2) $\mathbb{E}_1(\|f - c\|_2^2) &lt; \mathbb{E}_2(\|f - c\|_2^2)$。这个结果让我很困惑。
我希望它们相等，因为 $x_{(i)}$ 和 $y_{(i) }$ 来自与上面讨论的相同的 Beta 发行版。
这是因为$x_{(1)} \;\mathrm{and}\; x_{(2)}$ 不独立？如果是，$x_{(1)}$ 和 $x_{(2)}$ 的 pdf 或 cdf 是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</guid>
      <pubDate>Wed, 15 May 2024 15:11:32 GMT</pubDate>
    </item>
    <item>
      <title>嵌套、交叉或两者随机效果</title>
      <link>https://stats.stackexchange.com/questions/647287/nested-crossed-or-both-random-effects</link>
      <description><![CDATA[我正在使用二项式响应变量构建 GLMM 模型，但在确定要使用哪种组合或嵌套或交叉效果时遇到困难。我的情况如下：
1.) 我有物种观察的公民科学数据，其中包括公民科学家观察员的 ID。
2.) 我附近有气象监测站，其中有我正在使用的重要预测变量。这些站具有唯一的 ID。
3.) 从天气监测站收集的数据与公民科学家提交观察结果的时间相匹配。
总而言之，我有独特的气象站，独特的公民科学家在多个独特的气象站进行观测，并且这些观测发生在不同的时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/647287/nested-crossed-or-both-random-effects</guid>
      <pubDate>Wed, 15 May 2024 13:28:35 GMT</pubDate>
    </item>
    <item>
      <title>干头骨与活头骨测量调整</title>
      <link>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</link>
      <description><![CDATA[我正在研究一个数据集，其中包含博物馆藏品（样本数量的两倍）或活体标本（不太常见）的干燥头骨测量值。正如您可以想象的那样，由于肌肉、皮肤和毛皮的存在，活体标本平均要大几厘米。我可以使用哪些统计方法来校正这些较大的尺寸，以更好地适应干燥的头骨测量？头骨长度将用作更大模型中的变量。
我想到了 3 种可能的方法：

将头骨类型作为随机效应，以解释这些方法之间的差异

按性别和年龄减去每种头骨类型的预测长度或平均值之间的差异，但这似乎是一种粗略的方法。

使用从线性回归模型获得的残差直接调整测量的头骨尺寸。从活体样本的测量头骨尺寸中减去残差，有效地减小它们的尺寸以适应更“平均”的头骨尺寸。尺寸。


# 线性回归：
lm1 &lt;- lm(Skull_length ~ ns(年龄, 3) + 性别 + Skull_code,
          数据=数据框）

# 从线性回归模型中获取残差
残差 &lt;- 残差(lm1)

# 创建新的数据框用于预测
new_data &lt;- Expand.grid(年龄 = 0:30,
                        性别 = c(“M”, “F”),
                        Skull_code = as.factor(1))

# 使用每个模型预测头骨长度
Predicted_skull_df2 &lt;- new_data %&gt;%
  变异（预测头骨 = 预测（lm1，新数据 = .））

# 将残差添加到 skull_code == 1 的平均头骨长度上
# （干头骨）头骨代码 == 2 （活头骨）
Growth_data &lt;- Growth_data %&gt;%
  left_join(预测_skull_df) %&gt;%
  突变（调整后的头骨2 = ifelse（头骨代码== 2，预测头骨+
                                  残差，Skull_l))

# 创建绘图以比较调整后的测量值与原始测量值
增长数据%&gt;%
  ggplot(aes(x = 年龄, y = Skull_l)) +
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 1），aes（x = 年龄 - 0.2），
   颜色 = “黑色”，alpha = 0.5，大小 = 1) +
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 1），颜色=“黑色”）+
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 2），aes（x = 年龄 + 0.2），
   颜色 =“紫色”，alpha = 0.5，大小 = 1) +
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 2），颜色=“紫色”）+
  geom_point(aes(y = adjustment_skull_l), 颜色 = “红色”,
                 阿尔法 = 0.5，大小 = 1) +
  geom_smooth(aes(y = adjustment_skull_l), color = “红色”) +
  主题(panel.background = element_rect(fill = &quot;white&quot;),
        axis.line = element_line(color = &quot;black&quot;),
        axis.text = element_text(face = &quot;bold&quot;, size = 9.5),
        axis.title = element_text(face = &quot;bold&quot;, size = 15)) +
  ylab(“头骨长度”) +
  ylim(180, 500)

]]></description>
      <guid>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</guid>
      <pubDate>Tue, 14 May 2024 22:02:21 GMT</pubDate>
    </item>
    </channel>
</rss>