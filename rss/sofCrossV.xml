<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 02 Jan 2024 21:12:22 GMT</lastBuildDate>
    <item>
      <title>为什么解码器网络中每个注意力层周围都有一个残差连接，然后是一个层归一化步骤？</title>
      <link>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</link>
      <description><![CDATA[我在测验中得到了以下问题，看来我的答案不正确。我不明白为什么：
为什么解码器网络中的每个注意层周围都有一个残差连接，然后是一个层归一化步骤？

答案：
帮助提高可解释性。
加快训练速度，并显着减少整体处理时间。
打破后支撑的对称性。
在培训期间帮助并行计算组件。

我回答“打破后向传播的对称性。”，但他们的回答似乎是错误的！
我不明白为什么我的答案是错误的。另外，我不明白其他答案怎么可能是正确的！]]></description>
      <guid>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</guid>
      <pubDate>Tue, 02 Jan 2024 21:03:04 GMT</pubDate>
    </item>
    <item>
      <title>用于小样本和功效计算的线性混合模型方差分析的非参数方法</title>
      <link>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</link>
      <description><![CDATA[我有一个小数据，其中有 3 个组（A、B、C），每组有 5 名参与者。所有这些参与者在 7 项不同的考试中每项都被测量 6 次，因此每个参与者总共得到 6*7=42 分。构建了一个简单的线性混合模型 mylmm&lt;-lmer(score ~1+group+exam+group*exam+(1|participant), data = mydata)。我可以使用 anova(mylmm) 和多重比较函数获得分组、考试和交互的方差分析结果和事后成对比较。
但是数据很小（只有5个参与者）并且mylmm的残差不正常，所以威力不足。我知道使用 robustlmm 的稳健混合模型和使用 lmeresampler 的残差引导混合模型。但是，我无法使用这些包执行方差分析和多重比较。有人可以帮我解决以下问题吗？实在是太感谢了。

是否有方法和可用的 R 软件包来执行线性混合模型的引导方差分析（和事后比较）？
是否还需要计算 bootstrap 或非参数方差分析的功效？如果可以的话，功率怎么计算？
我还了解对齐排名转换方差分析。这种方法在这里有效吗，特别是对于小数据？另外，如何计算功率？
还有另一个相关但不太重要的问题。对于直接从 lme 构建的模型（无需引导），我能够使用 simr 和 anova 方法来计算测试组、考试和交互的功效。 simr 是否也可用于查找事后成对比较的功效？谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</guid>
      <pubDate>Tue, 02 Jan 2024 20:23:38 GMT</pubDate>
    </item>
    <item>
      <title>拟合值与实际值较差</title>
      <link>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</link>
      <description><![CDATA[我正在使用 BART 模型（贝叶斯加性回归树）来预测控制 388 个特征的结果（21,384 个观察值）的相对风险，并且我得到的实际值与拟合值图非常差，与任何 I&#39; 都不同。之前在其他模型中已经得到过不同的结果。
DV = 记录的相对风险 + 1 人口普查区层面的租户驱逐率。我的第一个模型（未显示）使用原始相对风险（风险是与该州所有其他区域相比的区域驱逐率），但我的拟合效果不佳，因此最后一轮我将 DV 转换为 log(RR +1)，其中在记录之前将 +1 添加到所有 RR 值，以避免由于大量零而出现无穷大。
IV = 388 个变量中除一个之外的所有变量都是连续的。变量涉及住房市场、人口统计、建筑环境、地方政策以及与驱逐相关的其他变量。
目标 = 拟合该国其他地区的相对风险预测值，这些地区没有基于相应地区控制措施的数据。
流程 = 我从基线数量的控件（最多包含 388 个）开始，运行交叉验证的 BART 模型以获得最佳超参数，然后使用这些参数循环 20 个 BART 模型每个都用不同的种子来找到最重要的变量，在查看几个变量重要性因素后减少变量。然后我重复这个过程，直到找到满意的模型集。最后一次模型迭代的 R^2 约为 0.64，RMSE 约为 0.28。
问题我该如何改进这个模型？

编辑：澄清情节。这些是可信的区间点。蓝色表示在可信范围内，红色表示在可信范围外。这里我们的覆盖率是 45.06%。我之前遇到的最差情况是 95%（绘图看起来大部分是蓝色）。]]></description>
      <guid>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</guid>
      <pubDate>Tue, 02 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>竞争获胜的概率</title>
      <link>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</link>
      <description><![CDATA[我想象这样一个场景：两支球队互相比赛并取得历史胜率。 $1$ 团队相当出色，赢得了 $60\%$ 的比赛。然而，$2$ 团队确实非常出色，赢得了 $90\%$ 的比赛。当两队相遇时，每队获胜的概率是多少？
我尝试使用多变量方法解决此问题，但事实证明这不是一个多变量问题。只有两种结果： $1)$ $\text{团队 1 获胜，团队 2 失败}$ ，或 $2)$ $\text{团队 2 获胜，团队 1 失败}$。这是伯努利分布（a 的简单变体）： $P(\text{队伍 1 获胜，队伍 2 失败}) = p$ 和 $P(\text{团队 2 获胜，团队 1 失败}) = 1 - p$。
应该如何计算$p$？
在上述情况下，我认为两支球队中较差的一支球队的获胜概率一定小于其历史胜利概率$0.6$。然而，由于更好的球队面对的是一支相当不错的球队（赢多于输），因此它的胜利概率也必须低于其历史比率 $0.9$.
我的幼稚方法是将概率计算为“团队拥有的胜利概率的比例” （正如我所说的）。
$$
P(\text{队伍 1 获胜，队伍 2 失败}) = \dfrac{0.6}{0.6 + 0.9} = 0.4\\
P(\text{队伍 2 获胜，队伍 1 失败}) = \dfrac{0.9}{0.6 + 0.9} = 0.6
$$
这个计算有多合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</guid>
      <pubDate>Tue, 02 Jan 2024 19:20:49 GMT</pubDate>
    </item>
    <item>
      <title>R 中累积发生函数的详细输出</title>
      <link>https://stats.stackexchange.com/questions/636018/detailed-output-of-a-cumulative-incidence-function-in-r</link>
      <description><![CDATA[我会先说我不是受过训练的统计学家，所以请保持温和。我正在使用 R 构建累积发生函数曲线，用于多个感兴趣时间点的单臂评估。感兴趣的结果是“事件”，“死亡”作为竞争风险（第三个选项被“审查”）。我使用了“tidycmprsk”包和“cuminc”函数来创建曲线（代码如下）。我的合作者要求我输出分析中每个时间点的累积发生率（和 95% CI）以及发生过事件、经过审查或仍然符合资格的患者数量。输出 (tidyCumInc) 在设定的时间点为我提供了一些信息，但没有提供事件的数量。有谁知道我可以获得我想要的输出吗？
非常感谢您提前抽出时间。
比尔
── cuminc() ──────────────────────────────────────────── ────────────────────────
• 故障类型“死亡”
时间n.风险估计标准误差95% CI
500 2,507 0.250 0.005 0.240, 0.260
1,000 633 0.369 0.007 0.356, 0.382
1,500 163 0.432 0.008 0.416, 0.447
2,000 54 0.456 0.009 0.439, 0.473
2,500 18 0.465 0.009 0.447, 0.483
3,000 6 0.480 0.011 0.458, 0.501
• 失败类型“结果”
时间n.风险估计标准误差95% CI
500 2,507 0.260 0.005 0.250, 0.270
1,000 633 0.382 0.007 0.368, 0.395
1,500 163 0.439 0.008 0.424, 0.455
2,000 54 0.469 0.009 0.451, 0.486
2,500 18 0.495 0.010 0.475, 0.514
3,000 6 0.495 0.010 0.475, 0.514
## 使用“tidycmprsk”包的累积发生率函数
图书馆（tidycmprsk）
库（ggsurvfit）

tidyCumInc &lt;- cuminc(Surv(时间, 事件) ~ 1,
                     数据=数据测试，
                     罗 = 0)
整洁的公司

# 绘制 CIF 曲线
cuminc(Surv(时间，事件) ~ 1，数据 = DATA_TEST，rho = 0) %&gt;%
  ggcuminc() +
  add_confidence_interval() +
  添加风险表()

]]></description>
      <guid>https://stats.stackexchange.com/questions/636018/detailed-output-of-a-cumulative-incidence-function-in-r</guid>
      <pubDate>Tue, 02 Jan 2024 18:27:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么在分析语料库时使用每百万计数的日志？</title>
      <link>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</link>
      <description><![CDATA[这对你来说可能是一个微不足道的问题，但请告诉我，因为我没有统计学背景。所以我对语料库语言学很好奇，尤其是在这个例子中如何使用语料库来证明简洁法则，也称为Zip&#39;f缩写法则。简而言之，该定理假设单词越短，它们在语言中出现的频率越高。当然，可视化对于证明定理非常有意义，所以我从维基百科上看到了这个可视化：

x 轴代表单词字符长度，y 轴代表单词数，以每百万对数计数。
我的问题是，为什么要使用每百万对数计数？是为了标准化，以便在分析中很好地代表计数较少的单词吗？任何对此有见解的人以及一些小读物，我们将不胜感激。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</guid>
      <pubDate>Tue, 02 Jan 2024 17:53:22 GMT</pubDate>
    </item>
    <item>
      <title>R 的“样本”如何处理不等概率权重？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636014/how-does-rs-sample-work-with-unequal-probability-weights</link>
      <description><![CDATA[我希望了解 R 的 sample 函数如何采用不等概率权重且不进行替换的样本。例如，sample(x = 1:3，size = 2，replace = F，prob = c(0.2, 0.2, 0.6))。
有人可以通过参考解释这一点的教科书或文章来帮助我吗？提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636014/how-does-rs-sample-work-with-unequal-probability-weights</guid>
      <pubDate>Tue, 02 Jan 2024 16:42:20 GMT</pubDate>
    </item>
    <item>
      <title>计算成对比较的贝叶斯因子、线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/636013/computing-bayes-factors-for-pairwise-comparisons-linear-mixed-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636013/computing-bayes-factors-for-pairwise-comparisons-linear-mixed-models</guid>
      <pubDate>Tue, 02 Jan 2024 16:40:27 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型中的随机效应样本</title>
      <link>https://stats.stackexchange.com/questions/636012/sample-random-effects-from-mixed-effects-model</link>
      <description><![CDATA[我有一个混合效应模型，我想使用 MVN 近似（从预测分布中采样）来模拟随机效应。我的问题是，通过 1）使用联合方差-协方差矩阵模拟固定效应和随机效应（然后仅剔除随机效应）或 2）模拟以固定效应为条件的随机效应来模拟随机效应的优点是什么？我猜策略#1 包含了固定效应和随机效应的不确定性，而策略#2 只包含了随机效应的变异性。还有什么吗？
基本原理：在混合效应模型中，我正在做出随机效应的预测，并且我想从拟合模型中模拟这些预测的不同实现。]]></description>
      <guid>https://stats.stackexchange.com/questions/636012/sample-random-effects-from-mixed-effects-model</guid>
      <pubDate>Tue, 02 Jan 2024 16:40:18 GMT</pubDate>
    </item>
    <item>
      <title>计算多元 q-高斯分布的 Tsallis 熵</title>
      <link>https://stats.stackexchange.com/questions/636011/calculate-the-tsallis-entropy-of-the-multivariate-q-gaussian-distribution</link>
      <description><![CDATA[我之前在这里发布过类似的问题，但不幸的是，答案没有满足我的具体需求。
$\textbf{问题：}$
计算多元 q-高斯分布的 Tsallis 熵。密度函数由本文给出（https://www.mdpi.com /1099-4300/13/10/1746）作者：
$$
f_{\gamma}(x \mid \mu, \Sigma) = \frac{c_{\gamma}}{\left[ \det(2\pi\Sigma) \right]^{\​​frac{1}{2 }}} \left[ 1 - \frac{\gamma}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right]^{2 + \frac{d\伽玛}{2} + \frac{2\伽玛}{2}}
$$
Tsallis 熵 $S_q$ 定义为：
$$
S_q = 1 - \int [f_{\gamma}(x \mid \mu, \Sigma)]^q \, dx
$$
$\textbf{方法：}$
$S_q$ 定义中的积分可以使用极坐标进行变换和简化，得到积分：
$$
\int (A + B|\mathbf{x}|^2)^c \, d\mathbf{x} = V(S^{n-1}) \int_{0}^{\infty} (A + Br^2)^c r^{n-1} \, dr
$$
其中 A、B 和 c 是从 q-高斯分布参数导出的常数。
$\textbf{进度：}$
建议更改变量以简化积分：
$$
u = \frac{Br^2}{A + Br^2}, \quad r^2 = \frac{A}{B} \cdot \frac{u}{1-u}
$$
这导致了一个复杂的积分：
$$
\int_{0}^{1} u^{\frac{n}{2} - \frac{1}{2}} \left( \frac{A}{1 - u} \right)^c \left ( \frac{A}{-Bu + B} \right)^{\frac{n}{2} - \frac{1}{2}} \left| -\frac{A}{B(u - 1)} (u^2 - 2u + 1)^{-\frac{1}{2}} \right|杜
$$
我们尝试简化并求解该积分，但没有找到简单的解析解。
如果有不同的方法来解决这个问题，那对我来说将是完美的。任何简化此计算的见解或方法将不胜感激。预先感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/636011/calculate-the-tsallis-entropy-of-the-multivariate-q-gaussian-distribution</guid>
      <pubDate>Tue, 02 Jan 2024 16:07:59 GMT</pubDate>
    </item>
    <item>
      <title>荟萃分析 - PRISMA 2020 检查表</title>
      <link>https://stats.stackexchange.com/questions/636009/meta-analysis-prisma-2020-checklist</link>
      <description><![CDATA[合成方法（合成资格）
13a
• 描述用于决定哪些研究适合每次综合的过程。
我的研究旨在将互联网提供的基于正念的干预措施与常规治疗或其他面对面为接受癌症治疗的癌症患者提供的积极干预措施进行比较。我的研究问题是 -

在减轻与癌症及其治疗相关的心理和身体健康影响方面，基于正念的在线干预措施 (eMBI) 是否比常规治疗 (TAU) 更有效？

在解决癌症及其治疗对心理和身体健康的影响方面，eMBI 的功效与面对面的正念干预措施和其他积极疗法相比效果如何？

自助式 eMBI 和移动/电话提供的 eMBI 在解决癌症及其治疗对心理和身体健康的影响方面是否存在显着差异？

eMBI 的长期益处是否能够持续改善癌症患者的心理健康和减少身体症状？


在描述用于决定哪些研究适合每次综合的过程时，我可以简单地说 - 通过对所采用的干预措施之间的一致性进行细致的评估，系统地确定研究纳入综合的资格在每项研究和研究问题中。事先制定了明确的纳入和排除标准，包括研究设计、参与者特征、干预措施和结果等方面。结果的综合需要进行荟萃分析，以估计在线正念干预对接受癌症治疗的患者的总体效果大小。该分析还旨在观察 eMBI 与常规治疗 (TAU)/候补名单控制相比的有效性，评估 eMBI 与其他主动干预措施相比的效率，检查基于电话/计算机/应用程序的 MBI 与引导自助的有效性正念干预，并探索 eMBI 在不同时间点的有效性。 ？]]></description>
      <guid>https://stats.stackexchange.com/questions/636009/meta-analysis-prisma-2020-checklist</guid>
      <pubDate>Tue, 02 Jan 2024 15:54:07 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯定理和给定的准确度统计数据</title>
      <link>https://stats.stackexchange.com/questions/635739/using-bayes-theorem-with-given-accuracy-statistics</link>
      <description><![CDATA[证明贝叶斯基本定理的一个常见示例是药物测试或疾病测试。例如，贝叶斯定理的维基百科页面有一个大麻测试的示例其中讨论了敏感性和特异性，以证明测试可以正确识别实际用户 90 % 的情况下，这并不意味着阳性结果意味着该主题有 90% 的概率是用户。我知道这里的基本内容。
这一切都有道理。但在某些情况下，我发现类似的例子，其中准确度被用作灵敏度的直接替代品。也就是说，该示例将与上面的示例同构，但使用测试的准确性而不是灵敏度。
我知道准确性是“真实阳性”和/加上“真实阴性”除以所有预测。使用准确性来替代敏感性（或特异性）似乎是一个错误。例如，如果我们谈论死亡率，假设任何活着的人明年死亡的几率约为 1%。因此，我可以创建一个“死亡预测器”，其中包含：return False，其准确度将为 99%。
我认为应用贝叶斯定理使用准确性代替敏感性或特异性是一个错误，这是否正确？以这种方式使用准确性是否假设错误在两个类之间均匀分布？
假设示例
如果我在这里犯了错误，请告诉我。
假设我们正在玩一个赌博游戏，规则如下：将掷出一个骰子。每一轮您都可以选择是否下注。如果你下注并且骰子上的值为 5 或 6，我给你 2 美元。如果有其他值，你给我 \$1。您可以选择不下注，在这种情况下，回合结束并重新掷骰子。
你有一个特殊的魔法装置，可以预测出现的是 5 还是 6。您已测试此设备，结果如下：
&lt;前&gt;&lt;代码&gt; TP |田纳西 | FP |纤维网
----------------------
  4% | 55% | 11% | 30%

地点：

阳性：5 或 6
负数：1 - 4
TP：真阳性
TN：真阴性
FP：误报
FN：假阴性

基于此，我们得到一个

准确率：59%
灵敏度：12%
特异性：83%

那么，在给定的掷骰中，如果您的设备显示结果为正，则该值为 5 或 6 的可能性有多大？
$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$
使用我们获得的灵敏度和特异性值：
$$
\压裂{(.12)(.33)}{(.12)(.33)+(.17)(.66)} = 0.26
$$
也就是说，如果预测结果是 5 或 6，那么实际是 5 或 6 的可能性只有 26%。
但是，如果我们像我在一些示例中看到的那样插入“准确性”，我们会得到：
$$
\压裂{(.59)(.33)}{(.59)(.33)+(.41)(.66)} = 0.41
$$
在我完全人为的示例中，如果您使用准确性作为决定是否玩的指南，您会认为积极的预测意味着您有 41% 的机会赢得 \$2，并且在玩游戏的过程中，您应该有一个正的平均值每次投注的回报。
$$
(.41 * 2) - (.59 * 1) = \$0.23
$$
但是，如果您（正确）使用灵敏度和特异性值，您会意识到您不应该不相信设备的正面预测，因为遵循其正面预测会给每次投注带来负的平均回报：
$$
(.26 * 2) - (.74 * 1) = \$-0.22
$$
我的理解正确吗？我认为这些例子中的一些可能在术语上存在松散，例如，将测试称为“99% 准确”。当他们真正的意思是“99% 敏感”时但我也很确定很多人都没有意识到其中的区别。
]]></description>
      <guid>https://stats.stackexchange.com/questions/635739/using-bayes-theorem-with-given-accuracy-statistics</guid>
      <pubDate>Wed, 27 Dec 2023 22:59:43 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能得到最好的模型？探索性 LMM</title>
      <link>https://stats.stackexchange.com/questions/635717/how-can-i-get-a-best-model-an-exploratory-lmm</link>
      <description><![CDATA[我想询问线性混合模型及其在我的数据集中的应用。该数据集包含一个表示为 V 的因变量 (DV)，以及三个相关的人口统计变量（例如，标记为 d1-d3 的年龄和性别） ），单个主体内变量标识为wi，单个主体间变量标识为bw。变量id表示数据集中唯一的主题标识符。
现在，我将初始完整模型设置为：
V ~ d1 * d2 * d3 * wi * bw + (1 + wi | id)

然后我使用 step() 来识别最能解释“V”变化的模型，从而找到一个复杂的模型，例如：
V ~ d1 + d2 + d3 + wi + bw + (1 + wi | id) + d1:d2 + d1:d3 + ...

每个变量有 13 种组合。然后我评估了模型与这个复杂模型的拟合程度。它有很多固定效应，但只有一些显示出统计显着性（例如 d1、d1:wi 和 d2:wi:bw） .
我可以相信这个模型并得出显着的固定效应（d1、d1:wi 和 d2:wi:bw）的结论吗DV 的重要因素是什么？是否有更好的方法来查找哪些变量或其相互作用对 DV 很重要？请注意，数据集有 65 个主题，因此我想知道 step() 找到的模型是否有太多解释变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/635717/how-can-i-get-a-best-model-an-exploratory-lmm</guid>
      <pubDate>Wed, 27 Dec 2023 17:01:04 GMT</pubDate>
    </item>
    <item>
      <title>通过分类变量关联的卡方</title>
      <link>https://stats.stackexchange.com/questions/635707/chi-square-by-association-on-categorical-variables</link>
      <description><![CDATA[我正在对多年来在不同地点和森林使用的方法进行审查。
我有一个如下所示的数据集（这只是一部分，我有 395 行）：
年份 国家 地区reason.for.study.1 Reason.for.study.2 森林方法encoded_method encoded_forest
1 2020 哥伦比亚 南美利基 na 雨林 method_visual 5 3
2 2015年日本亚洲气候变化干旱雨林method_visual 5 3
3 2018 印度尼西亚亚洲生存 na 雨林 method_net 3 3
4 2018 印度尼西亚 亚洲生存 雨林方法_遥测 4 3
5 2019 马来西亚 亚洲 毁林农耕 雨林方法_视觉 5 3
6 2017年巴西南美雨林方法调查 method_visual 5 3
7 2018 墨西哥 中美洲 热带岛屿丰度 method_visual 5 6
8 2018 马来西亚 亚洲行为雨林喂养方法_视觉 5 3
9 2012 年澳大利亚 大洋洲 雨林丰度调查 method_visual 5 3
10 2017 印度尼西亚 亚洲 森林砍伐恢复 雨林方法_视觉 5 3
11 2002 巴西 南美洲 毁林丰度 雨林 method_net 3 3
12 2015年秘鲁南美洲方法调查雨林 method_visual 5 3
13 2015 秘鲁 南美洲方法调查 雨林 method_acoustic 1 3

我想测试森林（包含 6 个级别，雨林、热带岛屿、热带、农田、草原等）和方法（也包含 5 个级别，method_net、method_visual、method_acoustic）之间是否存在关联、method_telemetry 和 method_camera）。
使用 R，我一直在尝试使用卡方比较这两个独特的变量（森林和方法），但没有取得太大成功，我还想知道其他变量有什么影响，例如年份或国家。逐一进行比较似乎是一种非常无效的方法，我想知道是否有一种方法可以更直接地做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/635707/chi-square-by-association-on-categorical-variables</guid>
      <pubDate>Wed, 27 Dec 2023 11:41:53 GMT</pubDate>
    </item>
    </channel>
</rss>