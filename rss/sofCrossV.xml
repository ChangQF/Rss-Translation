<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 20 Jan 2025 18:21:52 GMT</lastBuildDate>
    <item>
      <title>当使用短于一年的区块长度时，如何从 GEV 获得 1/100 的回报期？</title>
      <link>https://stats.stackexchange.com/questions/660277/how-to-get-1-in-100-return-period-from-gev-when-using-a-block-length-shorter-tha</link>
      <description><![CDATA[我正在计算一个数据集的广义极值分布，该数据集包含每 5 秒采样一次的约 30 年数据。我想从 GEV 估算 100 年内 1 次的回报水平。我最初使用一年的块长度来计算 GEV（例如，取每 1 年间隔的最大值并将其用作 GEV 拟合的输入）。这使我能够轻松计算超出回报的概率：
$$P_{exceed} = 1-1/T_{return}$$
其中 $T_{return}$ 为 100 年。然后我可以找到具有超出概率的 GEV 水平，$P_{exceed}$。
但是，数据集在给定年份通常具有多个独立的&quot;极端值&quot;，并且在给定年份可能有多达 10 个，因此采用年度区块最大值将低估极端事件的数量和回报水平。
我如何修改它以获得 100 年 1 次的回报水平，同时使用例如GEV 中的 10 天区块长度？
我认为我可以使用 10 天区块计算 GEV，然后将 $T_{return}$ 乘以 36.5 以获得年度 $P_{exceed}$，而不是 10 天 $P_{exceed}$。这似乎有效，但我不确定它是否具有统计有效性。
这里有几个额外的注意事项：
首先，我的数据有一些差距。如果我执行年度区块最大值，那么就没有问题，因为每个区块仍然有一些数据来计算最大值，但如果我执行 10 天区块长度，那么有些区块根本没有数据，因此区块最大值为 NaN。是不是最好假装不存在间隙，时间序列更短但连续？（这就是我目前正在做的。）或者，是不是最好假设间隙具有非常小的最大值，并只给它们一些默认的小值？
其次，极端事件很少见（呃）。如果我做一个年度区块最大值，我基本上可以保证每个区块都会发生极端事件。但如果我做一个 10 天的区块长度，那么很多区块的最大值都非常小。GEV 可以很好地拟合那些最小的区块最大值，但最差的极端值拟合得最差（见下图）。数据几乎超出了 10 年回报率的置信区间，最极端的数据点（30 年回报率的 1 年回报率左右）完全超出了 95% 的置信区间。
如有任何澄清，我们将不胜感激！
谢谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/660277/how-to-get-1-in-100-return-period-from-gev-when-using-a-block-length-shorter-tha</guid>
      <pubDate>Mon, 20 Jan 2025 17:50:29 GMT</pubDate>
    </item>
    <item>
      <title>在 lme 中，我们应该使用 ML 还是 REML 方法进行假设检验？</title>
      <link>https://stats.stackexchange.com/questions/660274/in-lme-should-we-use-ml-or-reml-method-for-hypothesis-tesing</link>
      <description><![CDATA[我们有以下模型：
m &lt;- lme(y ~ x + time + event + time:event, data = df, 
random = ~ time | user_id, 
correlation = corAR1(form = ~ 1 | user_id), 
weights = varExp(form = ~ time))

我们对系数 time:event 的重要性感兴趣。我们使用 clubSandwich 包的函数进行估计：
robust_m &lt;- coef_test(m, vcov = &quot;CR2&quot;, cluster = df$user_id)
robust_se_ &lt;- robust_m$SE
robust_p &lt;- robust_m$p_Satt # Satterthwaite 调整后的 p 值

当我们使用 ML 方法时，交互系数在 p &lt; .01 处显著，但使用 REML 时，它不显著。
请注意，我们有大约 490,000 个观察值嵌套在 900 个用户下。
不确定应该使用哪种方法进行此类假设检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/660274/in-lme-should-we-use-ml-or-reml-method-for-hypothesis-tesing</guid>
      <pubDate>Mon, 20 Jan 2025 15:57:24 GMT</pubDate>
    </item>
    <item>
      <title>样品去除的独立性</title>
      <link>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</link>
      <description><![CDATA[我正在研究以下子问题。我得到了一个完全加权图，$G = (V,E)$。$1 \leq u &lt; v \leq n$ 的边集 $E = \{X_{uv}\}$ 是一组随机变量，其中每个 $X_{uv} \sim U(0,1)$。
让 $i \in [1,n]$ 成为该图的一个顶点。如果存在另外两个顶点 $j \neq k$，s.t。 $j,k \in [1,n]$ 且 $j,k \neq i$ 使得
$X_{ij} = \min\{ X_{uv} \text{ s.t. } u=j \text{ 或 }v=j \}$ 且 $X_{ik} = \max\{ X_{uv} \text{ s.t. } u=k \text{ 或 }v=k \}$
即，$i$ 与 $j$ 之间的边是 $j$ 的边中的最小值，而 $i$ 与 $k$ 之间的边是 $i$ 与 $k$ 的边中的最大值（或反之亦然），则我将表示 $R = \{ X_{uv} \text{ s.t. } u=i \text{ 或 } v=i \}$。
因此，我将通过获取 $G&#39;= (V&#39;, E&#39;)$ 来缩小我的图，其中 $V&#39; = V \setminus \{i\}$ 和 $E&#39;= E \setminus R$。
现在，我能够计算出找到具有这种属性的顶点 $i$ 的概率，因为我的所有边都是 r.v。$U(0,1)$。 $P[i \in V \text{ has property above}] = 1-e^{-1}$。但是，由于我需要递归执行此过程，并且由于集合 $R$ 的特定选择，我会说 $E&#39;$ 取决于选择 $i$，并且 $E&#39;$ 的值不再是 i.i.d。因此我很想说
$P[i&#39; \in V&#39; \text{ has property above}] \neq 1-e^{-1}$ 因为 $R$ 中的边的移除可能会增加/减少连续顶点 $i&#39; \in V&#39;$ 上的属性。
您认为有办法打破这种依赖关系吗？我可以假设（并以某种方式证明）$E&#39;$ 再次由所有 i.i.d. 随机变量组成，这样我就可以再次应用我在开始时找到的概率（$1-e^{-1}$）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</guid>
      <pubDate>Mon, 20 Jan 2025 13:36:19 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将标准化逻辑回归系数转换为相关性？</title>
      <link>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</link>
      <description><![CDATA[我正在对皮尔逊相关性 (Rs) 进行荟萃分析。我正在将其他相关性度量转换为 Rs（如果两个度量都是分类的，则可能在计算它们之后进行转换），并使用有关均值和标准差的信息来估计科恩的 d，然后将其转换为 R。
然而，有两篇论文，其中一个度量是连续的，另一个是二元的，并且只有比值比及其置信区间可用。我可以计算标准化（对数）比值比，因为我有连续预测变量的标准差，但是，有没有办法将其转换为相关性？当预测变量也是二元时，我已经找到了很多关于这种转换的资料，但没有关于预测变量是连续的情况的资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</guid>
      <pubDate>Mon, 20 Jan 2025 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>测试一系列点偏离给定线/水平的概率/重要性</title>
      <link>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</link>
      <description><![CDATA[我想评估后续$n$ 个点（总共 $N$ 个）偏离（即其误差线不涵盖）某个任意水平/线/模型/等的概率（或者，更好的是，如果发生这种情况，其重要性）。在下面的草图中，用红色圈出的三个连续点偏离了蓝色水平/线。在这里，连续性至关重要，我对其他两个偏离点（紫色框中）不感兴趣。
我可能会天真地根据二项分布得出某些东西，但我想知道

是否有一些（或多或少复杂的）机制、统计工具、实现或类似的东西可以解决这个问题，并且
考虑这种序列作为偏差的重要性是否可能/有意义？

请注意，我不想对黑点进行任何拟合 - 我只想判断一些离散点集与预定义的任意线（无论这条线是什么）偏离的概率/重要性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</guid>
      <pubDate>Mon, 20 Jan 2025 12:51:52 GMT</pubDate>
    </item>
    <item>
      <title>包含许多零的计数数据的 GLM 类型</title>
      <link>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</link>
      <description><![CDATA[我有一个非常大的数据集，其中统计了因某些原因（某种疾病）而入院的人数，并且该数据集的观测值是 5 年内每天的数据。除了变量入院之外，我还有 120 个其他变量，用于研究它们与因该原因入院的关系。
我的变量入院具有以下分布：60% 的天数为零人次入院，30% 的天数为一人次入院，其余 10% 的天数为2 至 4人次，范围类似（只有 5 天为4人次入院）。
我也有来自不同医院的数据，其中一些医院的零比例甚至更大。
至于我的响应变量，我控制的是季节性和长期趋势以及星期几。其余变量是连续的气象变量，其中大多数变量重复一定次数并有滞后，因为这些变量对独立变量的影响可能会随时间滞后。例如，heat 变量重复 5 次：heat1、heat2、heat3、heat4 和 heat5，每个变量都比前一个变量滞后 1 天。
admissions 的均值和方差几乎相同（~0.02（0.515, 0.535）的差异），因此我倾向于使用泊松回归而不是负二项回归进行建模。使用此方法建模后，我使用逐步向后消元法得到最终模型，因此我最终得到一个包含 27 个响应变量的模型。
R 中使用的代码如下：
modelP &lt;- glm(admissions ~ ., data = hospital, family = poisson(link = &quot;log&quot;))
我尝试使用拟泊松回归建模来比较方法，但此方法未定义 AIC，因此我无法执行向后消元法并比较两者。
modelQP &lt;- glm(admissions ~ ., data = hospital, family = quasipoisson(link = &quot;log&quot;))
使用此类数据执行泊松回归是否正确？大量变量会造成任何麻烦吗？我是否应该寻找其他类型的模型，例如 NB 或零膨胀模型？
我还想最终计算出起作用的重要变量的归因风险。]]></description>
      <guid>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</guid>
      <pubDate>Mon, 20 Jan 2025 11:37:12 GMT</pubDate>
    </item>
    <item>
      <title>我的 EM 算法中的对数似然没有增加（R）</title>
      <link>https://stats.stackexchange.com/questions/660265/my-log-likelihood-does-not-increase-in-my-em-algorithm-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660265/my-log-likelihood-does-not-increase-in-my-em-algorithm-r</guid>
      <pubDate>Mon, 20 Jan 2025 09:53:37 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生存回归问题：处理非删失数据和模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>是否可以汇总 AIC/BIC 值以进行参与者级模型比较？</title>
      <link>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</link>
      <description><![CDATA[我有一个数据集，其中包含来自数百名参与者的情绪时间序列数据，他们每个人都参加了生态瞬时评估 (EMA) 研究。由于每个参与者的事件时间完全不同，我决定使用 R 中的药代动力学建模包 (mrgsolve) 生成的复杂非线性模型分别拟合每个参与者的数据。
我使用 nloptr 根据从先验知识得出的初步猜测来推导参数。由于呈现的模型数量庞大，手动优化每个模型的参数并不切实际。相反，我使用合理但未优化的参数值运行这些模型，这实际上效果很好，因为每个参与者对事件的情绪反应模式大致相似。
对于每个模型，我的零假设是数据纯粹由噪声组成。我的备选假设是，药代动力学衍生的模型在模拟参与者的情绪反应方面优于噪声模型。到目前为止，药代动力学模型似乎在几乎（但不是所有）情况下都产生了更优的 RSS 和 AIC/BIC 值。
有没有办法批量测试药代动力学建模方法产生更优的建模结果的假设，表明其所基于的模型优于噪声的零假设？例如，如果 95%（或其他百分比）的药代动力学模型产生比基于噪声的模型更优的拟合结果，这可以用来证明统计意义吗？或者是否有另一种基于指标的方法来测试这个假设，例如比较每个参与者的每个模型之间的 AIC 和 BIC 值，并将这些值汇总到所有参与者中？]]></description>
      <guid>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</guid>
      <pubDate>Mon, 20 Jan 2025 08:21:49 GMT</pubDate>
    </item>
    <item>
      <title>《危险边缘》玩家的贝叶斯分析</title>
      <link>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</link>
      <description><![CDATA[这是我的一个想法。
有一个著名的电视智力竞赛节目叫做Jeopardy。玩家回答琐事问题并相互竞争。这个游戏有一个速度元素——虽然多个玩家可能知道同一个问题的答案，但更快响铃的玩家将优先回答问题。
我很好奇，想估计一下节目中玩家的“真实知识”。我天真地以为玩家可以大致分为 4 类：

第 1 组：回答很多问题且经常正确的玩家
第 2 组：回答很多问题且经常错误的玩家
第 3 组：回答不多但经常正确的玩家
第 4 组：回答不多且经常错误的玩家

我在 R 中模拟了一些数据，以直观地展示其可能的样子：

当我们拥有关于玩家的更多数据（即第 1 组和第 2 组）时，这样做是有道理的玩家知道多少的歧义应该更少。但是，对于数据较少的玩家（即第 3 组和第 4 组），这些玩家可能实际上知道的比数据显示的要多（例如，如果他们参加有相同问题的笔试，他们的表现会与他们在智力竞赛节目中的表现不同）。这似乎应该受到他们在智力竞赛节目中回答的问题数量的影响。
贝叶斯方法（例如标准贝叶斯、经验贝叶斯）可用于尝试估计“修正”这些玩家的得分比例是多少？
这是我的想法。

标准贝叶斯：对于每个玩家$i$：


$\theta_i$是他们正确回答问题的真实概率
$n_i$是他们尝试的问题数量
$y_i$是正确答案的数量

每个玩家的似然函数遵循二项分布：
$$y_i|\theta_i \sim \text{Binomial}(n_i, \theta_i)$$
$$\theta_i \sim \text{Beta}(\alpha, \beta)$$
$$\theta_i|y_i \sim \text{Beta}(\alpha + y_i, \beta + n_i - y_i)$$
$$E[\theta_i|y_i] = \frac{\alpha + y_i}{\alpha + \beta + n_i}$$
我不确定经验贝叶斯在这里会如何使用。这些方法对这个问题有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Jaynes 对他的 $A_p$ 分布使用均匀先验？</title>
      <link>https://stats.stackexchange.com/questions/660257/why-does-jaynes-use-a-uniform-prior-for-his-a-p-distribution</link>
      <description><![CDATA[上下文：在《概率论：科学的逻辑》第 18 章中，Jaynes 引入了 $A_p$ 分布的概念。基本思想是，我们感兴趣的是 $A$ 事件，该事件可能为真或为假。然后，$A_p$ 是语句
$$
A_p \equiv \begin{cases}
\small \text{不管您可能已经被告知了什么，$A$ 的概率为 $p$。 }
\end{cases}
$$
给定一些关于语句 $A$ 的先验信息 $X$，我们可以在给定 $X$ 的情况下引入 $A_p$ 的概率密度，Jaynes 将其写为 $(A_p | X)$。那么 $A$ 发生的概率就是 $A_p$ 分布的第一矩​​：
$$
\begin{aligned}
\text{P}(A|X) &amp;= \int_0^1 \text{P}(A | A_p X) (A_p | X) \, dp \\
&amp;= \int_0^1 p \cdot (A_p | X) \, dp
\end{aligned}
$$
假设信息 $X$ 并未提及 $A$，只是表示它可能为真或为假。 Jaynes 声称，根据此信息，$A_p$ 分布应该是均匀的。也就是说，
$$(A_p | X) = 1$$
问题：为什么 Jaynes 在这里假设均匀分布？
我至少可以明白为什么 $A_p$ 分布的一阶矩应该是 $1/2$。由于 $X$ 并未指定 $A$ 是否应为真或为假，最大熵原理表明，我们应将 $1/2$ 指定为 $A$ 为真。但指定整个分布比仅指定其第一矩更有力。
Jaynes 说他通过遵循第 12 章中的“完全无知的人群”来做到这一点。我认为这是指第 12.4.3 节，他从中得出成功概率 $\theta$ 的无知先验。但在这种情况下，导出的先验$f(\theta)$不是均匀的：
$$
f(\theta) = \frac{\text{const.}}{\theta(1-\theta)}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660257/why-does-jaynes-use-a-uniform-prior-for-his-a-p-distribution</guid>
      <pubDate>Mon, 20 Jan 2025 02:20:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不屏蔽 Transformer 中除了多头注意力之外的其他层？</title>
      <link>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</link>
      <description><![CDATA[通常在训练 NLP 任务时，我们需要将序列填充到 max_len，以便可以以批处理方式高效处理它们。但是，这些填充的标记不应影响训练（模型参数的更新），因为它们是“虚构的”。
每个人都在谈论掩盖注意力操作的必要性。这是有道理的，因为有效标记不应该关注虚拟标记。但是，我们仍然需要考虑到所有其他层（例如 FF 中的线性层、规范化层等）不受填充的影响。
为简单起见，考虑单个 Transformer-Encoder 层：

从图中可以清楚地看出，FF 和最后的规范化层将填充的标记作为其他每个标记进行处理（即相同且独立）。为了正确屏蔽所有层，我们应该屏蔽损失吗？
例如，假设我们想使用 Transformer 编码器对序列进行分类。我们传递一个形状为 (B, N, E) 的输入 x，其中 B 是批量大小，N 是最大序列长度，E 是嵌入维度。输出具有相同的形状，我们将使用它进行分类。我们可以通过为每个序列提取一个“全局”向量来实现，然后将其传递给特定于任务的头部，如下所示：
x =coder_layer(x)
x = x.mask_fill(mask, -torch.inf) # 在最大操作期间屏蔽填充。
x = torch.max(x, dim=1)[0] # 忽略索引，简化为形状 (B, E)。
loss = loss_fn(cls_head(x), y)

由于 max 操作对任何未选定元素返回 0 梯度，因此所有参数都不会受到填充的影响。我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</guid>
      <pubDate>Sun, 19 Jan 2025 18:58:05 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的区别是什么？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能得到严格澄清，我们将不胜感激。

编辑：这个问题被认为不清楚，因此这里进行澄清。
问题：术语“样本回归模型”是指什么？
动机：术语“样本回归模型”用于回归分析文献中。例如，Montgomery、Peck 和 Vining 所著的《线性回归分析导论》第六版就使用了该术语。使用 Google 的“图书”标签搜索“样本回归模型”（带引号）也会产生大量结果。但是，我很难理解该术语的正式含义，这就是我提出这个问题的原因。从我目前所见，似乎确实存在对该术语的混淆，因为许多人都在使用该术语，但一些知识渊博的人似乎并不熟悉它。因此，我认为在论坛中回答这个问题是有价值的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该在层次聚类中翻转（否定）反相关变量吗？</title>
      <link>https://stats.stackexchange.com/questions/657447/should-i-flip-negate-anticorrelated-variables-in-hierarchical-clustering</link>
      <description><![CDATA[在层次聚类中，我有一个变量似乎与其他变量编码方向相反。它与大多数其他变量呈负相关。（例如下面的变量 3）

我想找出哪些变量彼此之间最相关。方向是任意的，与科学问题无关。两个问题：

我是否需要翻转（即否定）一个明显被否定的变量，以防止它成为一个单独的集群？
如果我们不知道变量是否被翻转，是否有规则来决定何时翻转它们？例如，“如果 $r_{i,j}&lt;0$ 与其他变量的相关性超过 50%，则翻转变量 i”？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657447/should-i-flip-negate-anticorrelated-variables-in-hierarchical-clustering</guid>
      <pubDate>Mon, 18 Nov 2024 15:42:09 GMT</pubDate>
    </item>
    </channel>
</rss>