<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 11 Nov 2024 01:16:10 GMT</lastBuildDate>
    <item>
      <title>估计 Fisher 信息为 0 的回归系数？</title>
      <link>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</guid>
      <pubDate>Mon, 11 Nov 2024 00:51:27 GMT</pubDate>
    </item>
    <item>
      <title>证明当 $X_1,\cdots,X_n\sim U(0,\theta)$ 时检验最有效</title>
      <link>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</link>
      <description><![CDATA[设$X_1,\cdots,X_n\sim U(0,\theta),\theta &gt;0$为独立随机变量。我想证明 $\phi :\mathbb{R}^n\to [0,1]$ 由 $\phi (x):=\begin{cases}1,&amp;\theta _0&lt;x_{(n)}\vee x_{(n)}\leq \theta _0\alpha ^{1/n}\\0,&amp;\text{otherwise}\end{cases}$ 给出，是 $\alpha\in (0,1)$ 级别最强的测试，可测试 $H:\theta=\theta _0$ vs $K:\theta =\theta _1&gt;\theta _0$。

我能够证明 $\phi$ 具有级别 $\alpha$。为了证明 $\phi$ 最强大，我尝试使用 Neyman-Pearson 引理，但失败了。
首先，我尝试找到一个常数 $k\geq 0$，使得对于所有 $x\in\mathbb{R}^n$，$\phi (x)=\begin{cases}1,&amp;f_{\theta_1}(x)&gt;kf_{\theta_0}(x)\\0,&amp;\text{otherwise}\end{cases}$ 成立，以便使用 NP 引理的&quot;充分性&quot; 部分。我知道，通过 $k=(\theta _1/\theta _0)^n$ 我们可以得出结论，给定任意 $x\in\mathbb{R}^n$，不等式 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$ 意味着 $\phi (x)=1$。但是，我无法证明，给定 $x\in\mathbb{R}^n$，等式 $\phi (x)=1$ 意味着 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$。

我的问题是：如何证明测试 $\phi$ 对测试 $H:\theta=\theta _0$ 与 $K:\theta =\theta _1&gt;\theta _0$ 最有效。]]></description>
      <guid>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</guid>
      <pubDate>Sun, 10 Nov 2024 23:12:49 GMT</pubDate>
    </item>
    <item>
      <title>对于 t 分布，df = n-1。n 代表什么？</title>
      <link>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</link>
      <description><![CDATA[根据 2 人的建议从 Math Stack Exchange 交叉发布。
我知道 $t$ 分布有一个参数：自由度 (df) 的数量。
我还知道 $\mathrm{df} = n - 1$。
但是，$n$ 究竟代表什么？
我听说过几种含义：

&quot;数据集中的数据点数量。&quot; 这听起来不对。如果我有 $100$ 个数据点，但 $t$ 分布（其中 $\mathrm{df}=50$）比 $\mathrm{df}=99$ 更能模拟该分布，那么我为什么要强制 $\mathrm{df}$ 为 99？

&quot;您用来从样本平均值 $\bar{x}$ 定义 $t$ 统计量的正态随机变量的数量。&quot; 这听起来也不对。我知道
$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}.$$
然而，这看起来更像是一个数学关系，而不是$t$的定义。如果我不从正态随机变量开始会怎样？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</guid>
      <pubDate>Sun, 10 Nov 2024 22:38:03 GMT</pubDate>
    </item>
    <item>
      <title>非参数直方图密度估计量的渐近偏差是多少？</title>
      <link>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</link>
      <description><![CDATA[我试图推导非参数直方图密度估计量的渐近偏差表达式，以便将其与核密度估计量的偏差进行比较。在符号方面，直方图定义为$\hat{h}(x)=(nl_n)^{-1}\sum^n_{i=1}I(a_n\leq x\leq b_n)$，其中$l_n=b_n-a_n$，$I$表示指示函数（也许这很简单，但我对此事不太熟悉）。我收到了一个提示，提示我需要假设极限 $(a_n - x)/l_n$ 和 $(b_n-x)/l_n$ 的存在。
到目前为止，我已经将估计值的期望表达为：
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n)$。然后，我使用泰勒展开式围绕 $x$ 获得：
$f(u)\approx f(x)+f&#39;(x)(u-x)$。
因此我这样写，
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n) \approx (l_n)^{-1}\int^{b_n}_{a_n} f(x)+f&#39;(x)(u-x)du$。
然而，我在这里卡住了。我猜想，对边界上的第一项 ($f(x)$) 进行积分将得出 $\int^{b_n}_{a_n}f(x)du=f(x)l_n$，这是由于 $b_n$、$a_n$ 和 $l_n$ 之间的关系。然后，$l_n$ 被抵消，剩下 $f(x)$。这是密度的真实值，所以我认为积分第二项 ($\int^{b_n}_{a_n} f&#39;(x)(u-x)du$) 必定构成偏差。
我是否使用了极限存在的假设？ 我如何计算积分中的第二项？我希望能够将其与核估计进行比较，该估计等于 $\frac{h^2}{2}f&#39;&#39;(x)\mu_2(K)$。是否有第二项的表示（我可以进一步开发它）以便能够这样做？
顺便说一句，我知道我已经从泰勒展开式中省略了 O(.)（为了方便）。
如果有人能帮助我，我将不胜感激。提前感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</guid>
      <pubDate>Sun, 10 Nov 2024 22:08:19 GMT</pubDate>
    </item>
    <item>
      <title>时间序列平稳性和消除虚假相关性的严格证明</title>
      <link>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</link>
      <description><![CDATA[我理解时间序列分析中的平稳性至关重要，尤其是对于推断而言，因为它有助于降低伪回归的风险。在非平稳序列中，由于方差或均值的变化，相关性更有可能显得显著，从而导致对因果关系的误导性推断。
是否有严格的证明或理论解释支持这一点？具体来说，为什么随时间变化的非恒定方差会增加伪相关的可能性？平稳性如何增强暗示因果关系的相关性的可靠性？任何数学见解或参考资料都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</guid>
      <pubDate>Sun, 10 Nov 2024 21:34:25 GMT</pubDate>
    </item>
    <item>
      <title>Excel中PDF的离散化</title>
      <link>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</link>
      <description><![CDATA[我正在尝试使用 excel 计算对数正态分布的期望值，不知道我做得对不对。我有 0 到 1 之间的一千个 X 步长，我用 LOGNORM.DIST 计算 PDF，平均值为 -3.5，标准差为 1.17183，因此期望值为 0.06 -&gt; Exp(mu+st.dev^2/2)。
现在，如果我对 x 和 p(x) 进行求和，我会得到 0.0579，所以我想知道我在离散化 PDF 的积分中遗漏了什么]]></description>
      <guid>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</guid>
      <pubDate>Sun, 10 Nov 2024 21:29:03 GMT</pubDate>
    </item>
    <item>
      <title>具有一般解释因素的预测校准</title>
      <link>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</link>
      <description><![CDATA[我正在考虑对特朗普​​政府未来两年的执政情况做出一系列基于概率的预测。预测将是一系列命题，例如：

20% 的联邦将禁止堕胎。

这个想法是为了测试我的校准，即理想情况下，我的 20% 预测中的 20% 应该会实现，我的 50% 预测中的 50% 应该会实现，等等。
当我试图思考我的预测时，我很快遇到了一个潜在的问题，即所有预测都有一个共同的因素——我对 DJT 性格的评估。也许他最感兴趣的是赢得选举和获得掌声，在这种情况下，实施他的政策议程可能会几乎一事无成。或者他是一个有远见的人，之前被房间里的各种成年人所阻碍，而这些成年人这次不会在场。如果这种思路是正确的，那么我可能会在一个方向上完全出错，或者在另一个方向上完全出错。 （我觉得这会不公平地搞砸我的校准，因为我已经预见到了这个问题）。
我的问题是，是否有人对我如何将这个共同因素整合到我的预测集中有什么建议？
我的第一个想法是指定每个预测与这个因素的关系，如果一个预测成真，那么将增加所有其他预测的概率（每个命题指定的某个量）。当我试图找出如何做到这一点的细节时，不幸的是我被卡住了。有人对我如何做到这一点有什么建议吗？或者可以告诉我有人做过类似的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</guid>
      <pubDate>Sun, 10 Nov 2024 20:44:40 GMT</pubDate>
    </item>
    <item>
      <title>有一个与用作随机效应的变量重叠的预测因子可以吗？</title>
      <link>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</link>
      <description><![CDATA[我将使用基于国家紧密度指数（数字）的预测因子，因此每个国家都有一个值。我将在 50 个国家/地区收集数据，但我预计不同国家/地区的参与者数量会有很大差异（预计每个国家/地区的最低参与者数量为 100 名）。
因此，我正在考虑将国家/地区添加为随机效应（因子）。但大多数国家/地区都有独特的预测因子值，其中五个国家/地区的紧密度得分相同。
我担心这可能会使模型变得奇异或扰乱结果，假设国家/地区的随机效应最终可能会吞噬预测因子的大部分可变性。这是我应该担心的事情吗？ （我还没有数据，但我知道结果变量将是二分的）。
数据预期结构示例：
participant_id consequence_variable tightness country 
x01 1 -0.2 USA 
x01 0 -0.2 USA 
x01 0 -0.2 USA 
x01 1 -0.2 USA 
x02 1 -0.2 USA 
x02 1 -0.2 USA 
x02 0 -0.2 USA 
x02 1 -0.2 USA 
x03 1 0.3 UK 
x03 1 0.3 UK 
x03 1 0.3 UK 
x04 0 0.5 FR 
x04 1 0.5 FR 
x04 1 0.5 FR
x04 0 0.5 FR 

预期模型：
glmer(outcome_variable ~ tightness + (1 | contestant_id) + (1 | country), data, family=binomial)
我想看看在紧密度较高的国家，对某些规范（结果）的遵守是否更为普遍。]]></description>
      <guid>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</guid>
      <pubDate>Sun, 10 Nov 2024 18:48:49 GMT</pubDate>
    </item>
    <item>
      <title>经济学教科书数据科学建议</title>
      <link>https://stats.stackexchange.com/questions/657037/data-science-for-economics-textbook-suggestion</link>
      <description><![CDATA[我正在寻找一本经济学研究生学位课程的数据科学课程教科书。它必须基于 Python 并包含大量示例。我会很感激任何建议。
当然，经济学研究生学位课程已经包含统计、回归、时间序列、面板、机器学习、一些使用 R 和 Stata 的编程；以及大量的经济学课程。所以，我认为数据科学课程应该像学生已经知道的知识的应用加上良好的数据处理和可视化措施。]]></description>
      <guid>https://stats.stackexchange.com/questions/657037/data-science-for-economics-textbook-suggestion</guid>
      <pubDate>Sun, 10 Nov 2024 16:15:28 GMT</pubDate>
    </item>
    <item>
      <title>假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</link>
      <description><![CDATA[直观地讲，标准假设检验（其中检验统计量呈正态分布或近似正态分布）中的 p 值被认为是“在假设零假设成立的情况下，观察到至少与统计学家观察到的值一样极端的值的概率”。
我的问题来自“至少一样极端的部分”。这是由于使用了检验统计量的值的 CDF 的补集。这意味着我们正在考虑我们没有观察到的检验统计量的其他更极端（且不相关）的值。为什么使用检验统计量的 pdf 还不够？我担心在拒绝零假设时，我们正在考虑与特定检验无关的极端值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</guid>
      <pubDate>Sun, 10 Nov 2024 15:42:55 GMT</pubDate>
    </item>
    <item>
      <title>显示两个变量在数年内变化的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</link>
      <description><![CDATA[我试图在 y 轴上显示某个城市的中位租金及其人口，x 轴上显示年份。
我的第一反应是使用气泡图，其中 y 轴对应人口，x 轴对应年份，每个气泡的体积与中位租金相关。但这在视觉上模糊了人口与年份的关系。
有没有更好的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</guid>
      <pubDate>Sun, 10 Nov 2024 15:26:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的条件推理树与随机森林如此不同？</title>
      <link>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</link>
      <description><![CDATA[我正在使用条件推理树和随机森林分析数据集，使用的是 R 包 partykit（v. 1.2.20）。对于我的因变量（响应可能性），树和森林产生的解决方案非常不同，这使得它们都很难解释。我该如何理解这里发生了什么？
下面是我的代码以及树和森林的图像。如有必要，我可以共享数据集。
set.seed(2356)
library(partykit)

&gt; head(s1_images_response_item[,-2])
# A tibble：6 × 14
# 组：item [6]
item category response_mean_img causation colourful familiarity grow intent
&lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 飞机 移动臂… 1 3.25 2.57 4.4 1 1.29
2 藻类 植物 趣味… 0.887 2.44 3.57 2.1 4.14 1.06
3 羚羊 动物 0.981 4.25 2.79 3.85 4.77 3.53
4 自行车 移动臂… 1 2.12 2.64 4.65 1.05 1.12
5 船 移动臂… 0.981 3.19 2.64 3.65 1 1 
6 巨石 不动… 0.943 1.88 1.5 3 1.45 1.18
# ℹ 6 个其他变量：交互 &lt;dbl&gt;、运动 &lt;dbl&gt;、自然&lt;dbl&gt;,
# 感知 &lt;dbl&gt;, 重现 &lt;dbl&gt;, 提示 &lt;chr&gt;

条件推理树：
tree1.i.h &lt;- ctree(response_mean_img ~ 因果关系 + 意图 + 
交互 + 运动 + 感知 + 熟悉度 + 自然 + 
生长 + 重现 + 多彩, data=s1_images_response_item)

plot(tree1.i.h, terminal_panel = node_boxplot(tree1.i.h,id=T),
inner_panel = node_inner(tree1.i.h,id=F, pval = F), 
edge_panel = edge_simple(tree1.i.h, digits = 2))

--&gt;熟悉度是唯一重要的预测因素：

随机森林：
f1.i.h &lt;- cforest(response_mean_img ~ causation + intent + 
interaction + movement + perception + familiarity + natural + 
grow + reproduce + colourful, data=s1_images_response_item, 
ntree = 1000)

f1.i.h.varimp &lt;- varimp(f1.i.h)

dotchart(sort(f1.i.h.varimp,decreasing = F), 
main = &quot;研究 1B 试验的变量条件重要性响应性”）

--&gt; 预测因子交互、再现、感知和因果关系都具有比熟悉度更高的条件重要性值：

为什么交互、再现、感知和因果关系都没有出现在树中？]]></description>
      <guid>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</guid>
      <pubDate>Fri, 08 Nov 2024 02:26:03 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>时间相关效应：使用 coxph() 中的 nsk() 的 tt 函数</title>
      <link>https://stats.stackexchange.com/questions/656611/time-dependent-effects-tt-function-using-nsk-in-coxph</link>
      <description><![CDATA[我使用 coxph() 比较三种处理方法（大、小、对照）之间的树苗存活率数据。然而，coxzph() 显示小处理方法的系数随时间而变化。为了解决这个问题，我在 coxph () 中添加了一个 tt(Small)，并使用 nsk() 来实现回归样条，并且我正在使用指示变量进行治疗。
我的问题是，当使用 tt() 和 nsk() 时，系数是如何解释的，特别是对于时间相关变量？
以下是模型输出。
cox.tt4 &lt;- coxph (Surv (no.yrs.alive, censor) ~ Large + Small +
tt(Small) + frailty (Line), data = spruce.complete,
tt = function (x,t,...) x*nsk(t, knots = c(3)))
summary(cox.tt4)
## 调用：
## coxph(formula = Surv(no.yrs.alive, censor) ~ Large + Small + 
## tt(小) + frailty(Line), 数据 = spruce.complete, tt = function(x, 
## t, ...) x * nsk(t, knots = c(3)))
## 
## n= 96, 事件数= 35 
## 
## coef se(coef) se2 Chisq DF p 
## 大 -2.520 0.7409 0.7396 11.57 1.00 0.00067
## 小 -3.427 1.2067 1.2065 8.07 1.00 0.00450
## tt(小)1 3.056 1.7592 1.7585 3.02 1.00 0.08200
## tt(小)2 3.183 1.4072 1.4061 5.12 1.00 0.02400
## frailty(Line) 6.24 2.33 0.06000
## 
## exp(coef) exp(-coef) lower .95 upper .95
## Large 0.08044 12.43122 0.018830 0.3436
## Small 0.03249 30.77809 0.003052 0.3458
## tt(小)1 21.23826 0.04708 0.675532 667.7166
## tt(小)2 24.12159 0.04146 1.529754 380.3560
## gamma:L1 1.06620 0.93791 0.575824 1.9742
## gamma:L2 0.59206 1.68903 0.283618 1.2359
## gamma:L3 1.27464 0.78454 0.713532 2.2770
## gamma:L5 1.39426 0.71722 0.780017 2.4922
## gamma:L6 0.67284 1.48624 0.326825 1.3852
## 
## 迭代次数：6 外部，22 Newton-Raphson
## 随机效应方差 = 0.1925677 I-似然 = -134.1 
## 项的自由度 = 1.0 1.0 2.0 2.3 
## 一致性 = 0.813 (se = 0.041 )
## 似然比检验 = 44.22 on 6.32 df, p=9e-08

时间相关的 Therneau 等人。 2024 插图第 4.2 节指出“系数是节点 2、3 处的预测值，... - 节点 1 处的预测值”。
在这种情况下，这是否意味着第一个时间段（时间 0 到时间 3）的小治疗系数将是 -3.427 + 3.056 = -0.371？而对于第二个时间段（&gt;时间 3），-3.427 + 3.056 = -0.244？
此外，我可以对这些系数取指数来计算相对于参考治疗的风险比，两个时间段的风险比不同吗？
我对这种方法还不熟悉，非常感谢任何见解或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656611/time-dependent-effects-tt-function-using-nsk-in-coxph</guid>
      <pubDate>Fri, 01 Nov 2024 20:17:45 GMT</pubDate>
    </item>
    </channel>
</rss>