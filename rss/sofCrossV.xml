<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 20 Oct 2024 12:31:43 GMT</lastBuildDate>
    <item>
      <title>寻求有关固定效应 DID 回归的建议</title>
      <link>https://stats.stackexchange.com/questions/656035/seeking-advice-for-did-regression-with-fixed-effect</link>
      <description><![CDATA[由于我对此还比较陌生，因此我想寻求有关固定效应回归的 DID 的建议。我想研究从贸易优惠计划中撤出特定产品时对其征收的关税税率对该国出口的影响。我对变量有疑问，因为它是在产品层面，我目前只有 2016-2020 年每种产品的出口数据和从 2020 年开始变化的关税税率。你能解释一下我应该怎么做吗？你能否也给我展示一下我在 Stata 中应该使用什么来获取 DID 变量，即产品出口与产品关税税率变化之间的相互作用。提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/656035/seeking-advice-for-did-regression-with-fixed-effect</guid>
      <pubDate>Sun, 20 Oct 2024 12:07:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么神经网络训练中的所有这些自适应方法都需要 $g_t^2$ 项？</title>
      <link>https://stats.stackexchange.com/questions/656033/why-does-all-these-adaptive-methods-in-neural-network-training-require-a-g-t2</link>
      <description><![CDATA[所有自适应学习方法，AdaGrad、AdaDelta、RMSprop、ADAM 以及后续变体都需要 $g_t^2$，即以元素方式将梯度乘以自身。
为什么需要这样做？我从未找到令人信服的论据。]]></description>
      <guid>https://stats.stackexchange.com/questions/656033/why-does-all-these-adaptive-methods-in-neural-network-training-require-a-g-t2</guid>
      <pubDate>Sun, 20 Oct 2024 09:55:16 GMT</pubDate>
    </item>
    <item>
      <title>多臂老虎机问题的 epsilon-贪婪算法的遗憾界</title>
      <link>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</link>
      <description><![CDATA[考虑$1$-亚高斯 MAB，其中$n\geq 2$，考虑$\epsilon$-贪婪算法：首先选择每个臂一次，然后选择$A_t=\arg\max \hat \mu_i(t-1)$，其中 pr。 $1-\epsilon_t$，否则随机均匀选择一个臂。
我们想要证明，假设$\Delta_{\min}=\min\{\Delta_i:\Delta_i&gt;0\}$，其中$\Delta_i= \max \mu_j-\mu_i$，并让$\epsilon_t=\min\{1,\frac{Cn}{t\Delta_{\min}^2}\}$，其中$C$是足够大的通用常数，证明存在$C’&gt;0$通用标准差。
$$R_T\leq C&#39;\sum_{i=1}^n(\Delta_i+\frac{\Delta_i}{\Delta_{\min}}\log\max\{e,\frac{T\Delta_{\min}^2}{n}\}).$$
我的想法是分别分析每个 arm 的遗憾，即 arm $i$ 被选中的次数的期望，并将其分为探索部分和开发部分，在第一部分中，每个 arm 都有机会以 pr. $\epsilon_t/n$ 被选中，而在开发部分，我们可以选择一个时间阈值 $t$ s.t。当$T&gt;t$时，次优臂将以足够小的概率被选中。但是，我不知道如何选择正确的方法来达到与此问题相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</guid>
      <pubDate>Sun, 20 Oct 2024 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>寻找 $3\theta_2^2$ 的 MVUE 的技术背后的动机</title>
      <link>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</link>
      <description><![CDATA[这个问题来自 Hogg 和 McKean 的《数理统计学导论》。
练习 7.7.11。
让 $X_1,X_2,\cdots,X_n$ 成为来自 $N(\theta_1,\theta_2)$ 分布的随机样本。
(a) 证明 $E[(X_1 − \theta_1)^4] = 3\theta_2^2.$
(b) 找到 $3\theta_2^2$ 的 MVUE。
我的尝试：
$N(\theta_1,\theta_2)$ 的联合完全充分统计量是 $(\overline{X},S^2)$、样本均值和样本方差。与此处或此处所做的类似，很容易证明（对于部分 (b)）
$$T = \cfrac{3(n-1)^2\Gamma\left(\frac{n-1}{2}\right)}{16\Gamma\left(\frac{n+7}{2}\right)}S^4,$$其中$S^2=\frac{\sum_{i=1}^n(X_i-\overline{X})^2}{n-1},$给定随机样本的方差样本。对于部分 (a)，众所周知，我们可以使用 mgf 技术找到中心矩（例如，参见此处）。
我的问题：为什么作者要问部分 (a)？通常，他们这样做是为了引导读者找到解决部分 (b) 的方法。最初，我以为他们要我们猜测一个函数 $T$，使得 $\mathbb{E}(​​T) = 3\theta_2^2$ 并且 T 是 $\theta_1$ 和 $\theta_2$ 的联合完全统计量函数 $\pmb{Y}$。 这样自然会使 $T$ 成为 $3\theta_2^2$ 的 MVUE。具体来说，他们在上一节相关部分中提到（第 $448$ 页）
&quot;第 $7.3$ 和 $7.4$ 节中概述的 Rao–Blackwell、Lehmann–Scheffe 理论自然延伸到这种向量情况。简而言之，假设 $\delta = g(\pmb{\theta})$ 是感兴趣的参数，并且 $\pmb{Y}$ 是 $\pmb{\theta}$ 的充分和完整统计向量。令 $T$ 为 $\pmb{Y}$ 函数的统计数据，例如 $T = T(\pmb{Y})$。如果 $E(T) = \delta$，则 $T$ 是 $\delta$ 的唯一 MVUE。&quot;
那么部分 (a) 如何促使我们猜测此函数 $T$？
编辑 1：
SE 帖子 此处 显示了 $\sigma^4 = \theta_2^2$ 的无偏估计量，似乎与部分 (a) 中的形式相似，但不是 $\theta_2^2$。添加此评论以防万一相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</guid>
      <pubDate>Sun, 20 Oct 2024 07:03:17 GMT</pubDate>
    </item>
    <item>
      <title>Anova.glm 程序 - glm 的 II 型和 III 型设置之间的结果不同，但 lm 的相同吗？</title>
      <link>https://stats.stackexchange.com/questions/656029/anova-glm-procedure-results-different-between-type-ii-and-type-iii-settings-fo</link>
      <description><![CDATA[当使用 Anova 确定一般线性模型中因素的重要性时，众所周知，当设计平衡时，II 型和 III 型设置将产生相同的结果。
但是，当应用于广义线性模型并使用偏差作为离散度度量时，即使设计平衡，II 型和 III 型设置也会产生不同的结果（当使用 car 包中的 Anova.glm() 函数时）。我想知道为什么会这样...？
我使用 R 中的以下代码进行了实验：
library(car)
FacA=c(&quot;A1&quot;,&quot;A2&quot;) ### 因子 A 的两个级别
FacB=c(&quot;B1&quot;,&quot;B2&quot;,&quot;B3&quot;) ### 因子 B 的三个级别

dft=c()
for (nA in 1:length(FacA)){
for (nB in 1:length(FacB)){
FacA0=FacA[nA]
FacB0=FacB[nB]
y=rpois(n=10,lambda=10) ## n = 10 观测值服从泊松分布
df0=c()
df0=data.frame(A=FacA0,B=FacB0,y=y)
dft=rbind(dft,df0)
}
}

### 因此 dft 是平衡设计的模拟 df 

mt2=glm(y~A+B+A:B,contrasts=list(A=&quot;contr.sum&quot;,B=&quot;contr.sum&quot;),family=poisson(link=&quot;log&quot;),data=dft)
mt3=lm(y~A+B+A:B,contrasts=list(A=&quot;contr.sum&quot;,B=&quot;contr.sum&quot;),data=dft)

############# mt3 上的方差分析，它是lm
Anova(mt3,type=&quot;II&quot;)
Anova(mt3,type=&quot;III&quot;) 
##### 它们会给出相同的结果

############# mt2 上的 Anova，它是一个 glm
Anova(mt2,type=&quot;II&quot;)
Anova(mt2,type=&quot;III&quot;) 

#### 它们不同

那么这是否意味着即使在平衡设计中，Anova.glm() 的 II 型和 III 型设置通常也会给出不同的结果？我不太明白为什么会这样，因为 mt2 中的设计矩阵是正交的……那么 II 型和 III 型在分割分散方面有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/656029/anova-glm-procedure-results-different-between-type-ii-and-type-iii-settings-fo</guid>
      <pubDate>Sun, 20 Oct 2024 05:12:57 GMT</pubDate>
    </item>
    <item>
      <title>在训练时向特征添加随机空值是否会使模型对这些特征的“敏感度”降低？</title>
      <link>https://stats.stackexchange.com/questions/656028/does-adding-random-null-values-to-features-at-train-time-make-models-less-sensi</link>
      <description><![CDATA[我知道可以设置几个超参数，使模型对信号的“敏感度”降低，从而提高模型的稳健性，并使其在样本外泛化方面表现更好。
但我感兴趣的是通过修改数据，使模型对某些特征的敏感度降低的方法，具体来说，就是随机将特征值更改为空值和/或随机值。我感兴趣的是使模型（梯度提升树，如 LGBM）更能抵御对抗性攻击
随机用空值/缺失值（甚至随机值）替换某些特征值会有所帮助吗？
我的直觉是，某些特征中的随机/缺失值会使模型不那么信任这些特征——从而降低特征重要性，并使模型在生产中不易受到这些特征的对抗性攻击。
这有意义吗？我在文献中找不到太多关于这方面的内容。我知道dropout，它使模型变得更愚蠢，以实现正则化，但它改变的是权重/神经元，而不是数据本身。此外，我从未在深度神经网络的范围之外提到过这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/656028/does-adding-random-null-values-to-features-at-train-time-make-models-less-sensi</guid>
      <pubDate>Sun, 20 Oct 2024 05:08:04 GMT</pubDate>
    </item>
    <item>
      <title>假设 x 和 y 不相关，给定 sigma_x、sigma_y，如何计算径向方差？</title>
      <link>https://stats.stackexchange.com/questions/656027/how-do-i-compute-radial-variance-given-sigma-x-sigma-y-given-that-x-and-y-are-u</link>
      <description><![CDATA[给定 sigma_x、sigma_y，且 sigma_xy = 0。
如何将协方差矩阵的坐标系从笛卡尔坐标系转换为极坐标系，并以此计算 sigma_rho？]]></description>
      <guid>https://stats.stackexchange.com/questions/656027/how-do-i-compute-radial-variance-given-sigma-x-sigma-y-given-that-x-and-y-are-u</guid>
      <pubDate>Sun, 20 Oct 2024 05:07:42 GMT</pubDate>
    </item>
    <item>
      <title>既然 AlexNet 可以放在 1 GB 的内存中，为什么还要将其分成两个 GPU，每个 GPU 的内存大小为 3GB？</title>
      <link>https://stats.stackexchange.com/questions/656026/why-was-alexnet-split-on-two-gpus-each-of-memory-size-3gb-when-it-can-fit-on-1-g</link>
      <description><![CDATA[在8.1. 深度卷积神经网络（AlexNet）— 深入学习一书中，它声称：

在最后的卷积层之后，有两个巨大的全连接层，有 4096 个输出。这些层需要近 1GB 的模型参数。由于早期 GPU 的内存有限，最初的 AlexNet 采用了双数据流设计，这样它们的两个 GPU 中的每一个都可以只负责存储和计算其一半的模型。幸运的是，现在 GPU 内存相对充足，所以我们很少需要在 GPU 上拆分模型（我们版本的 AlexNet 模型在这方面与原始论文有所不同）。

在原始论文中，他们只是说

单个 GTX 580 GPU 只有 3GB 内存，这限制了可以在其上训练的网络的最大大小。事实证明，120 万个训练示例足以训练太大而无法在一个 GPU 上容纳的网络。因此，我们将网络分散到两个 GPU 上。

所以我想准确计算它应该占用多少内存。
该网络有 6000 万个参数和 650,000 个 float32 格式的神经元。它通过动量梯度下降训练，批量大小为 128。因此，在训练期间，每个参数对应 3 个参数（参数本身、梯度、动量）。这样就有了 1.8 亿个参数，也就是 720 MB。
它还需要存储 128 张图像的激活模式，因此就有 $0.65 \times 128 = 83$ 百万个参数，也就是 332 MB。
总共大约有 1 GB，比单个 GPU 上的 3GB 要低得多。
那么，为什么他们将 AlexNet 分成两半，并声称它不适合单个 GPU？]]></description>
      <guid>https://stats.stackexchange.com/questions/656026/why-was-alexnet-split-on-two-gpus-each-of-memory-size-3gb-when-it-can-fit-on-1-g</guid>
      <pubDate>Sun, 20 Oct 2024 04:48:22 GMT</pubDate>
    </item>
    <item>
      <title>后验预测 p 值和模型复杂性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655998/posterior-predictive-p-values-and-model-complexity</link>
      <description><![CDATA[我正在执行贝叶斯后验预测检验，我发现更复杂的模型（一般模型）的后验预测 p 值比更简单的模型（嵌套模型）的后验预测 p 值略差（远离 .5）。这可能吗？显然，一切都是正确的。我希望更通用的模型始终表现出与嵌套模型相同或更好的拟合度。]]></description>
      <guid>https://stats.stackexchange.com/questions/655998/posterior-predictive-p-values-and-model-complexity</guid>
      <pubDate>Sat, 19 Oct 2024 08:53:54 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着 X1 - X2 之差位于区间 [L1 - R2, R1 - L2] 内的概率将超过 95%？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？（不可能）</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度法的攻击对于神经网络来说似乎没有意义，因为训练误差是非凸的</title>
      <link>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</link>
      <description><![CDATA[有几种基于梯度的攻击方法。设$J$为训练误差，则例如投影梯度攻击为，
$$
\widetilde{x} = \Pi( x + \epsilon \nabla_x J(\theta, x, y) )
$$
快速有符号梯度法为
$$
\widetilde{x} = x + \epsilon \text{sign}( \nabla_x J(\theta, x, y) )
$$
这些方法都假设我们正在添加$\nabla_x J(\theta, x, y)$。这是在假设$\nabla_x J(\theta, x, y)$指向$J$相对于$x$的最大无穷增量方向的情况下实现的。
但这个假设是错误的，因为$J$是$x$的非凸函数。因此，添加 $\nabla_x J(\theta, x, y)$ 不一定会产生 $\widetilde x$，从而产生更大的 $J$ 值。
由于大多数这些方法都是单步的，因此不能保证 $\widetilde x$ 会增加 $J$ 的值，它甚至可能会降低 $J$ 的值。
我的推理有缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</guid>
      <pubDate>Fri, 11 Oct 2024 14:53:11 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归模型中模型非常不稳定，变量大多不显著</title>
      <link>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</link>
      <description><![CDATA[我的目标是通过几个公司和宏观经济控制变量来找出欧盟排放许可价格对公司自由现金流的影响。我为此使用的数据集涵盖了大约 500 家公司和 2005 年至 2022 年的数据。
我在 R 中建立了一个单向固定效应模型（内部），并尝试用它来估计模型。它导致了以下结果，这些结果还可以，但在我看来没有意义，因为我确信一些变量应该有显著的影响，比如 GDP 增长。
我可以做什么/调查什么，看看我估计模型的方式是否有错误？我是否需要以某种方式转换变量（尝试过对数、标准化、差分等方法）？
R 输出：
模型内的单向（个体）效应

调用：
plm(formula = FCFF ~ GDP_Growth + INTANGIBLE_ASSETS + REVENUE + 
DEPRECIATION + TOTAL_ASSETS + Patents_Filed + Exchange_Rate_EUR.CNY + 
Inflation + Oil_Price + Lead_Spot + EU_ETS_Future + EU_ETS_Spot, 
data = data, model = &quot;within&quot;)

平衡面板：n = 511，T = 18，N = 9198

残差：
最小值 第 1 区 中位数 第 3 区 最大值。
-5609351.5 -5784.3 -676.8 3676.6 7938700.2 


Signif.代码：0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：3.5016e+14 

残差平方和：2.8466e+14 

R 平方：0.18705 

调整 R 平方：0.13814 

F 统计量：12 和 8675 DF 上的 166.339

p 值：&lt; 2.22e-16

编辑/更新：
不确定我是否需要提出新问题或只是编辑帖子，所以只是先尝试​​编辑。
我对模型做了一些更改，包括使用新的、更好的数据集和标准化变量。我还稍微改变了边界内的变量，使它们之间不产生共线性。这导致了以下更新的结果。然而，R 平方仍然出奇地低。而且 p 值似乎有点好得令人难以置信。
不确定现在我是否可以使用这样的结果。
更新的数据输出：
]]></description>
      <guid>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</guid>
      <pubDate>Mon, 27 May 2024 12:34:17 GMT</pubDate>
    </item>
    <item>
      <title>解释 emmeans R 中 cld 输出的字母</title>
      <link>https://stats.stackexchange.com/questions/646903/interpreting-letters-from-cld-output-from-emmeans-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646903/interpreting-letters-from-cld-output-from-emmeans-r</guid>
      <pubDate>Thu, 09 May 2024 00:26:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么在多元回归中$\beta^{T}X_{c}^{T}X_{c}\beta$要除以$(k-1)\sigma^{2}$？</title>
      <link>https://stats.stackexchange.com/questions/624548/why-is-betatx-ctx-c-beta-divided-by-k-1-sigma2-in-multiple-r</link>
      <description><![CDATA[在单线性回归模型中，为了找到回归期望，我们使用以下公式：
$$E[MSR] = \sigma^{2}+\hat \beta^{2}(X-\bar X)^{2}.$$
$MSR = \frac{\sum_{i=0}^n (\hat y-\bar y)^{2}}{\operatorname{df}}$;
$\operatorname{df}= 1.$
对于多元回归模型，公式为
$$E[MSR] = \sigma^{2}+\frac{\beta^{T}X_{c}^{T}X_{c}\beta}{(k-1)\times\sigma^{2}}.$$
有人能解释一下为什么我们必须用$\beta^{T}X_{c}^{T}X_{c}\beta$除以$(k-1)\sigma^{2}$吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/624548/why-is-betatx-ctx-c-beta-divided-by-k-1-sigma2-in-multiple-r</guid>
      <pubDate>Mon, 21 Aug 2023 22:34:38 GMT</pubDate>
    </item>
    </channel>
</rss>