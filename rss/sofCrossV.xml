<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 15:16:54 GMT</lastBuildDate>
    <item>
      <title>一致性检验：p 值较低是否正常</title>
      <link>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</link>
      <description><![CDATA[我正在使用 kruskal-wallis 检验来检查不同类型的群体之间是否存在差异，在获得显著结果后，我进行了事后检验并获得了较低的 p 值。关于每个组的样本是这样的：


我的问题是，得到这些低 p 值是正常的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 14:56:33 GMT</pubDate>
    </item>
    <item>
      <title>是否可以预测边际效应曲线的形状？</title>
      <link>https://stats.stackexchange.com/questions/660166/is-it-possible-to-predict-the-shape-of-a-marginal-effects-curve</link>
      <description><![CDATA[这是逻辑回归的一般方程：
$$ P(Y=1|x_1,x_2) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2)}} $$
要找到边际效应，我们需要对每个预测变量求导。对于 $x_1$:
$$ \frac{\partial p}{\partial x_1} = \frac{\partial}{\partial x_1}\left(\frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2)}}\right) $$
$$ \frac{\partial p}{\partial x_1} = \beta_1 \cdot p \cdot (1-p) $$
对于 $x_2$:
$$ \frac{\partial p}{\partial x_2} = \beta_2 \cdot p \cdot (1-p) $$
正如预期的那样，两个变量的边际效应方程具有相同的形式。我尝试为不同的值绘制此方程：

所以这是我的问题：如果我们比较两种相同类型的模型（例如逻辑回归，没有交互作用，没有高阶项），边际效应曲线是否总是具有相同的形状？从理论上讲，我们甚至可以在分析它们之前就知道这种形状会是什么样子吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660166/is-it-possible-to-predict-the-shape-of-a-marginal-effects-curve</guid>
      <pubDate>Fri, 17 Jan 2025 14:51:46 GMT</pubDate>
    </item>
    <item>
      <title>当同时使用随机临床试验和随机对照试验时，如何计算效果大小？</title>
      <link>https://stats.stackexchange.com/questions/660165/how-to-calculate-effect-sizes-when-using-both-randomised-clinical-trials-and-ran</link>
      <description><![CDATA[我正在开展系统评价（10 篇论文）。6 项研究有对照组，4 项没有，并且正在比较多种干预措施。
要计算效果大小，我最好使用 RCT 中对照组和干预组的干预后平均值吗？
或者，由于我正在为临床试验进行事前/事后计算，我是否将其应用于 RCT 并仅查看事前/事后的平均值？
如果只查看一个组（事前/事后），我是否不必汇总标准差？]]></description>
      <guid>https://stats.stackexchange.com/questions/660165/how-to-calculate-effect-sizes-when-using-both-randomised-clinical-trials-and-ran</guid>
      <pubDate>Fri, 17 Jan 2025 14:32:34 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例在统计上是否存在差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，都使用 Mercer 定理作为依据？
我们能否用 Moore-Aronszajn 定理来证明这一点，该定理没有将紧致性假设置于 $X$ 和 $k$ 连续性上？]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>变换与顺序有关的分布</title>
      <link>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</link>
      <description><![CDATA[我有一组 $E = \{X_{ij}\}$，其中 $1 \leq i &lt; j \leq n$，s.t. $|E| = \binom{n}{2}$。$X_{ij}$ 在 $\sim [0,1]$ 内都是独立同分布的。这些是完整加权图的边。
假设我选择一个顶点并根据此处中描述的规则将其与相关边一起移除，从而获得较小的$E&#39;$。
分布可能会因此而改变。由于我有兴趣保留这些值的顺序（这对于属性在后续步骤中保持充分和必要是必要的），我可以使用此处描述的参数对剩余值进行非线性单调变换，并得出结论：$E&#39;$ 仍然是均匀分布的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</guid>
      <pubDate>Fri, 17 Jan 2025 11:37:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 calc 查找 emmeans 中的样本大小，调用准二项式会产生奇怪的结果</title>
      <link>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</link>
      <description><![CDATA[我在一项实验研究中运行了一个具有准二项式系列的 glm，该研究的因子有 4 个水平、2 个协变量和一个二项分布的响应（10 个正确/错误响应的总和）：
调用：
glm(formula = cbind(PT1SVAAll, 10 - PT1SVAAll) ~ CFGroup + PreSVAAll + 
FBPrePT1SVA, family = quasibinomial(link = &quot;logit&quot;), data = TestResultsAllreorderedPretestDoneFB)
系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -2.77546 0.58445 -4.749 5.10e-05 ***
CFGroupDA 0.81332 0.53051 1.533 0.136 
CFGroupM -0.37421 0.59334 -0.631 0.533 
CFGroupR 0.57151 0.57806 0.989 0.331 
PreSVAAll 0.70464 0.14138 4.984 2.65e-05 ***
FBPrePT1SVA 0.02369 0.05326 0.445 0.660 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（准二项式系列的分散参数取为 2.031543）

零偏差：34 个自由度上的 150.183

残差偏差：29 个自由度上的 68.354
（由于缺失，删除了 9 个观测值）
AIC：NA
Fisher 评分迭代次数：4
由此我假设 n=35（零偏差的 df+1）。我尝试使用 calc 语法查找因子 (CFGroup) 每个级别的样本大小，但得到了奇怪的结果：
emmeans(mod.PT1multfactors, &quot;CFGroup&quot;, infer = c(TRUE, TRUE), type=&quot;response&quot;,
+ calc = c(n = &quot;.wgt.&quot;))
CFGroup prob SE df n asymp.LCL asymp.UCL null z.ratio p.value
C 0.209 0.0645 Inf 90 0.1091 0.362 0.5 -3.415 0.0006
DA 0.373 0.0817 Inf 90 0.2305 0.541 0.5 -1.490 0.1363
M 0.153 0.0637 Inf 80 0.0648 0.321 0.5 -3.485 0.0005
R 0.318 0.0898 Inf 90 0.1717 0.512 0.5 -1.842 0.0655

使用的置信度：0.95

区间是从 logit 尺度反向转换而来的

测试是在 logit 尺度上执行的

出于某种原因，calc 似乎可能会将每个级别的 n 乘以权重 10（总共 10 个响应），使得 C、DA 和 R 的每个级别的 n 为 9，M 的每个级别的 n 为 8。但加起来是 36，而不是我上面从模型的零偏差假设的样本大小 35。
有人能解释一下这里发生了什么吗？我如何才能找到每个级别的准确样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</guid>
      <pubDate>Fri, 17 Jan 2025 10:57:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 I() 来更好地管理多个数据点</title>
      <link>https://stats.stackexchange.com/questions/660155/using-i-to-better-manage-many-data-points</link>
      <description><![CDATA[我有一个包含 3200 多行的大型数据框。我使用相关独立变量对疾病结果进行了逻辑回归分析，其中一个变量是液体平衡，范围从 -500 到 +1500。
我咨询的统计学家建议我使用
glm(disease~I(fluidbal/500)+var2+var3...var5, family = &quot;binomial&quot;, data = na.omit(data.frame))

因为这会将液体平衡分成 500 毫升的块。 P 值保持不变，但对于我的森林图 (ggplot2)，这样做可以澄清图表（之前，所有值都靠近中心，CI 条不可见）。
社区认为这合法吗？
通过使用 I(fluidbalance/500)，我的目的是实现数据的更好分辨率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660155/using-i-to-better-manage-many-data-points</guid>
      <pubDate>Fri, 17 Jan 2025 10:41:15 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，还是纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>确认蒙特卡洛简历</title>
      <link>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</link>
      <description><![CDATA[我想估算一个测量值。假设我们采用经验估计来估计累积分布函数 (CDF) $F(x,y)$。我想将交叉验证与蒙特卡洛相结合。
我的想法：
方法说明
目标是结合使用经验估计与蒙特卡洛模拟和k 倍交叉验证来估计基于累积分布函数 (CDF) (F(x, y)) 的测量值。

数据生成：
每次蒙特卡洛迭代都会从均匀分布生成数据。例如，两个变量 (X) 和 (Y) 由独立均匀随机变量产生，样本量为 (n = 300)。

为了进行比较，假设测量值有一个固定的真实值（例如 (0.23)）。


蒙特卡罗模拟：为了提供统计稳健性，模拟通过 5,000 次迭代完成。

根据获得的数据，使用平滑的经验 CDF 计算每次迭代中的估计量。


通过 k 倍验证：
每次迭代将数据集分为 (k = 5) 倍。

对训练集（数据）上的每个折叠计算估计量估计量与真实值之间的平均平方差称为“偏差”。估计量与真实值在所有迭代过程中的平均平方差称为均方误差 (MSE)。

实施和输出：- 模拟在 5,000 次迭代中生成测量估计值，以及偏差和 MSE。这些测量值显示出 MSE 随着样本量增加而降低的模式，用于评估估计量的准确性和可靠性。

我们可以这样做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</guid>
      <pubDate>Fri, 17 Jan 2025 07:54:49 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 和 R 中提取负二项式参数 $r$ 和 $\pi$？</title>
      <link>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</link>
      <description><![CDATA[我尝试使用 Python 和 R 提取移位负二项分布的参数 $r$ 和 $\pi$。但是，我很难在两种语言之间获得一致的结果。
假设我的示例数据是：1,2,3,4,5,6,7,8,9,9,8,7,6,5,4,3,2,1
我对负二项 PMF 使用以下参数化：
$$
p(k) = \binom{k - 2 + r}{k - 1} \cdot \pi^r \cdot (1 - \pi)^{k-1}
$$
这是我的 Python 代码（使用statsmodels):
X = np.ones_like(s)
s = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1])
res = sm.NegativeBinomial(s, X).fit(start_params=[1, 1], disp=False)
mu = np.exp(res.params[0]) # 平均值 (mu)
p = 1 / (1 + np.exp(res.params[0]) * res.params[1]) # 成功概率

这是我的 R 代码（使用 fitdistr）：
data = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1)
fit &lt;- fitdistr(data, &quot;Negative Binomial&quot;)
size &lt;- fit$estimate[&quot;size&quot;] # r：size 参数
mu &lt;- fit$estimate[&quot;mu&quot;] # 平均值，用于计算 p
r = size
pi = r / (r + mu)

我不确定我将 Python 中的拟合参数转换为 $r$ 和 $\pi$ 是否正确，我也不清楚这两种方法是否使用相同的参数化。
有人能帮忙澄清一下吗：

我对 $r$ 和 $\pi$ 的转换在 Python 和 R 中是否正确？
Python 和 R 对负二项分布的拟合是否存在差异，或者我应该注意哪些参数化差异？

提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</guid>
      <pubDate>Fri, 17 Jan 2025 03:38:59 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>如何测试具有少量箱体的直方图是否符合正态分布？</title>
      <link>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</link>
      <description><![CDATA[假设我有一个直方图，显示已成功完成 $0, 1, 2, ..., n$ 门课程的学生人数。学生人数较多，但课程数量较少（例如 6 门）。我的零假设 $H_{0}$ 是学生的“能力”是一个具有正态分布的实数（均值和方差未知），学生完成的课程数量为 $\lfloor \text{aptitude} \rfloor$。如何检验备择假设 $H_{1}$“能力分布不正常”？我知道 Jarque-Bera、Lilliefors 或 Anderson-Darling 等正态性检验，但据我所知，它们假设离散化细化程度要高得多，即有更多的箱体，并且它们不包含任何限制假设（即，观测量的最大值和最小值是有限的，尽管底层随机变量不是）。我也在 Cross Validated 上看到了这个问题，其中一个答案建议使用卡方拟合优度检验，但据我所知，您需要指定正态分布的均值和方差才能使用卡方拟合优度检验，而我两者都没有。
附言。由于我发现在教育背景下提出这个问题会引发太多与统计本身无关的问题，因此假设我们讨论的是游戏中给予玩家的随机点数。玩家最多可以购买 $n$ 件物品，每件物品花费 $X$ 点，并且总是会购买尽可能多的物品。通过查看玩家购买的物品数量的分布，我们试图确定给予玩家的点数是否符合正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:45 GMT</pubDate>
    </item>
    <item>
      <title>给定 5 个随机变量，关于条件独立性的问题</title>
      <link>https://stats.stackexchange.com/questions/660063/a-question-regarding-conditional-independence-given-5-random-variables</link>
      <description><![CDATA[设 $U,V,W,X,Y$ 为满足以下条件的 5 个随机变量：
$$P(U,V,W,X,Y) = P(U)P(V)P(W|U,V)P(X|W)P(Y|W)$$
如何得出语句 $ \text{给定 W，Y 条件独立于 V} $ 为 True，而语句 $ \text{给定 𝑊，𝑈 和 𝑉 条件独立于 𝑊} $ 为 False？
我的尝试
我不知何故觉得会使用以下恒等式：
$$P(U,V,W,X,Y) = P(U)P(V|U)P(W|U,V)P(X|U,V,W)P(Y|U,V,W,X)$$。但我将其等同于问题的右侧，但无法取得太大进展。
我还需要知道“给定...，...独立于...”在数学上到底是什么意思？我理解随机变量独立性的定义，但如果有人能澄清“条件独立性”是什么意思，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660063/a-question-regarding-conditional-independence-given-5-random-variables</guid>
      <pubDate>Wed, 15 Jan 2025 14:04:10 GMT</pubDate>
    </item>
    </channel>
</rss>