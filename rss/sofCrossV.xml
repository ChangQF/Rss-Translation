<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 12 Apr 2024 03:15:25 GMT</lastBuildDate>
    <item>
      <title>CNN（一维和二维）必须采用相同大小的输入吗？</title>
      <link>https://stats.stackexchange.com/questions/644846/must-a-cnn-both-1d-and-2d-take-input-of-the-same-size</link>
      <description><![CDATA[我认为 CNN 输入数据必须始终具有相同的维度。如果我们输入一维表格数据，列的编号必须相同；如果我们输入 2D 图像数据，所有图像必须具有相同的尺寸。这种大小调整可能发生在 CNN 的输入层中，也可能发生在 CNN 外部 - 在数据处理阶段。
因此，我给我的主管写了以下电子邮件：
&lt;块引用&gt;
你好。
CNN 可以处理一维表格数据和二维数据。但是，它无法处理具有不同列长度的一维表格数据。
我们不能使用以下文件：
ABC.dat
 ------------------数据-------------------- --matrix- -
  6 赖氨酸 C 4.768 7.342 10.221 1 0 1 0 1 0 1 2 3
  7 酪氨酸C 8.992 6.431 4.110 0 1 0 1 0 0 1 2 3
  8 SER C 2.345 8.901 12.345 0 0 1 0 1 1 1 2 3

PQR.dat
--------------------数据-------------------- ---矩阵--
  0 丙氨酸 C 0.000 0.000 0.000 1 1 1 1 1 0 1 2 3 4 5 6
  1 GLU C 6.691 9.772 0.000 1 1 1 1 1 0 1 2 3 4 5 6
  2 PHE C 6.601 8.709 12.389 0 0 0 0 1 0 1 2 3 4 5 6
  3 参数 C 6.489 9.682 11.525 0 0 0 0 0 0 1 2 3 4 5 6
  4 HIS C 6.249 0.000 0.000 0 0 0 0 0 0 1 2 3 4 5 6
  5 ASP C 0.000 0.000 0.000 0 0 0 0 0 0 1 2 3 4 5 6

XYZ.dat
&lt;前&gt;&lt;代码&gt;--------------------数据-------------------- ---- - -矩阵 -  -  - -
  0 GLU C 0.773 6.403 9.702 1 0 1 0 1 0 0 1 2 3 4 5 6 7 8 9 10
  1 酪氨酸C 1.710 3.978 3.997 1 0 1 1 1 0 1 1 2 3 4 5 6 7 8 9 10
  2 ASP C 2.564 9.689 4.051 1 0 1 0 0 0 1 1 2 3 4 5 6 7 8 9 10
  3 酪氨酸C 4.485 4.886 8.724 1 0 0 1 1 1 0 1 2 3 4 5 6 7 8 9 10
  4 HIS C 6.145 7.992 9.437 1 0 0 1 0 0 1 1 2 3 4 5 6 7 8 9 10
  5 丙氨酸 C 5.373 3.810 6.506 1 0 0 0 0 0 1 1 2 3 4 5 6 7 8 9 10
  6 HIS C 6.314 3.519 1.994 0 1 0 1 1 0 0 1 2 3 4 5 6 7 8 9 10
  7 ASP C 8.348 3.026 9.201 0 1 1 0 1 0 1 1 2 3 4 5 6 7 8 9 10
  8 酪氨酸 5.810 2.019 9.094 0 1 0 1 1 1 0 1 2 3 4 5 6 7 8 9 10
  9 赖氨酸 C 7.361 1.221 2.055 0 0 0 1 0 0 0 1 2 3 4 5 6 7 8 9 10

我们可以将这三个文件输入 CNN 吗？当然，我们可以。然而，问题将是标签。在我们的数据中，每一行的第三列都有一个标签。如果我们将这些表作为 2D 数据输入 CNN，我们就会丢失这些标签。因为 CNN 需要为每条 2D 数据分配一个标签，在我们的例子中就是蛋白质名称。
另一个问题是 CNN 必须（并且必须）采用相同维度的 2D 输入。在我们的例子中，每个文件都有不同的尺寸。因此，我们必须将文件大小调整为通用尺寸（平均值、中位数或众数），或者需要将较小的图像用零填充到文件中找到的最大尺寸。在我们的例子中，这将一事无成。因为由于上一段中描述的标签问题，我们的 2D 数据首先将毫无用处。
亲切的问候。
学生

我的教授不同意这一点。
他写道：
&lt;块引用&gt;
&lt;块引用&gt;
另一个问题是 CNN 必须（并且必须）采用相同维度的 2D 输入。

不，没必要。以我们之前的论文为例：对于 N 个残基的蛋白质，输入的大小为 NxK，每个残基有 K 个特征。输出层为Nx2。对于每种蛋白质，输入的大小不同，我们使用相同的网络。它使用一维卷积。
&lt;块引用&gt;
在我们的例子中，每个文件都有不同的尺寸。因此，我们必须将文件大小调整为通用尺寸（平均值、中位数或众数），或者需要将较小的图像用零填充到文件中找到的最大尺寸。在我们的例子中，这将一事无成。因为由于上一段中描述的标签问题，我们的 2D 数据首先将毫无用处。

不，这不是必需的。
但是，您可以使用填充，否则您的图层将会收缩。更具体地说，当您的卷积窗口为 WxW 时，大小为 NxN 的输入将产生 (N-W) x (N-W) 的输出。
亲切的问候
主管

你能解决我的困惑吗？
CNN（一维和二维）是否必须接受相同大小的输入？]]></description>
      <guid>https://stats.stackexchange.com/questions/644846/must-a-cnn-both-1d-and-2d-take-input-of-the-same-size</guid>
      <pubDate>Fri, 12 Apr 2024 02:50:18 GMT</pubDate>
    </item>
    <item>
      <title>FDR 置信区间调整</title>
      <link>https://stats.stackexchange.com/questions/644844/fdr-adjustment-for-confidence-intervals</link>
      <description><![CDATA[我在 R 中有一个多元回归模型，我应该报告 beta 估计值、95 CI 和 p 值。模型中有很多变量，因此我使用 Benjamini-Hochberg 方法来调整 p 值。然而，现在 CI 和调整后的 p 值不匹配；有些变量的 95% CI 不包含零，但调整后的 p 值不显着。
我想知道如何调整 FDR 的 CI。我可以使用调整后的 p 值通过下面本文中描述的过程对 CI 进行逆向工程吗？
https://www.bmj.com/content/343/bmj.d2090 
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644844/fdr-adjustment-for-confidence-intervals</guid>
      <pubDate>Fri, 12 Apr 2024 01:07:52 GMT</pubDate>
    </item>
    <item>
      <title>扩展隐马尔可夫模型 (HMM) 参数估计</title>
      <link>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</link>
      <description><![CDATA[对于更简单的 HMM，我们可以使用 Viterbi 训练（而不是解码）或 Baum Welch 等算法来估计最能描述观察到的数据的参数。
当使用更复杂的多元 HMM 或二阶 HMM 时，我们如何做同样的事情？是否有资源可以用来查看在这些情况下如何调整算法和设置？如果有它们的伪代码而不是描述，那就更好了，尽管我知道早期的算法（例如向前和向后）也会改变。]]></description>
      <guid>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</guid>
      <pubDate>Fri, 12 Apr 2024 00:37:56 GMT</pubDate>
    </item>
    <item>
      <title>组内系统回顾和荟萃</title>
      <link>https://stats.stackexchange.com/questions/644842/within-group-systematic-review-and-metalysis</link>
      <description><![CDATA[我正在研究 SRMA，以评估干预前后研究的效果。效应大小是速率比。怎么做？对于使用没有真实对照组的前后设计给出的结果，我需要进行什么修正？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644842/within-group-systematic-review-and-metalysis</guid>
      <pubDate>Thu, 11 Apr 2024 23:43:21 GMT</pubDate>
    </item>
    <item>
      <title>我们如何摆脱 MLE 中的 $p(x|\theta)$</title>
      <link>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</link>
      <description><![CDATA[简单的问题...通常机器学习的介绍会告诉您以下内容：

您想要最大化$p(\theta|D)$
应用贝叶斯定理$p(\theta|D) \propto p(D|\theta)p(\theta)$
如果你考虑 $p(\theta)$ 常数，你会得到 MLE，如果你考虑它高斯，你会得到 L2 正则化等等

但是，我想更详细一点，这是我的问题：
$$
p(\theta|D) \propto p(D|\theta)p(\theta) = p(x,y|\theta)p(\theta) = p(y|x, \theta)p(x| θ)p(θ)
$$
现在，通常我们优化的实际上是 $p(y|x,\theta)p(\theta)$，所以我的问题是...下我们要删除哪个假设 $p(x|\theta)$？
我们是否认为 $x$ 独立于 $\theta$ 并且保持不变？.. .]]></description>
      <guid>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</guid>
      <pubDate>Thu, 11 Apr 2024 22:11:00 GMT</pubDate>
    </item>
    <item>
      <title>估计梯度提升树中的最佳树数</title>
      <link>https://stats.stackexchange.com/questions/644840/estimating-optimal-number-of-trees-in-gradient-boosted-trees</link>
      <description><![CDATA[我试图提出一个公式来估计梯度提升树中树的最佳数量（我知道在实践中使用提前停止或交叉验证是更好的方法，但我只想得到一个近似值）。 
我的直觉如下：设 $y = \mu + \epsilon$ 其中 $y$ 和 $\epsilon$ 是向量。令学习率为 $l$。然后，根据我对 gbdt 在每一步的理解，我们将预测大约移动为 $l \times \epsilon_t$，其中 $\epsilon_t$ 在 $t$ 时是无法解释的错误（可能更糟，因为我们无法适应  $\epsilon_t$ 与树完全一样）
因此，在 $t$ 树之后，剩余误差应约为 $(1-l)^t \epsilon$&lt; /span&gt;，这意味着我们正在解释 $(1-(1-l)^t)^2$ 方差百分比
因此，如果理想模型可以解释 $r$ 的变化百分比，那么可以从  中找到最佳树数$(1-(1-l)^t)^2 = r$ 这意味着 $t=\frac{\log(1-\sqrt{r} )}{\log(1-l)}$。我知道这只是一个近似值，实际上它会受到树深度等的影响。
我尝试在合成数据上对此进行测试，结果非常不同。例如，在具有 10 个特征的模型中，根据此公式， $l=0.01$ 和理想的 r2 为 10% 应该有大约 40 棵树，但实际上我发现基于早期停止，近 1000 棵树是最佳的。我还发现，即使数据生成过程没有改变，最佳树数也会随着数据大小的增加而增加。我使用 lightgbm 进行实验。
您能否指出我的推理中的错误，并解释为什么最佳树数随着数据大小的增加而增长？]]></description>
      <guid>https://stats.stackexchange.com/questions/644840/estimating-optimal-number-of-trees-in-gradient-boosted-trees</guid>
      <pubDate>Thu, 11 Apr 2024 22:04:49 GMT</pubDate>
    </item>
    <item>
      <title>如何证明K-Means将所有空间分割成凸多边形？</title>
      <link>https://stats.stackexchange.com/questions/644838/how-to-prove-that-k-means-splits-all-space-into-convex-polygons</link>
      <description><![CDATA[我想证明 K-Means 算法将整个对象空间分割成凸（可能没有边界）多边形。我试图利用K-Means算法收敛的事实并与之矛盾，但我没有成功。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/644838/how-to-prove-that-k-means-splits-all-space-into-convex-polygons</guid>
      <pubDate>Thu, 11 Apr 2024 21:41:29 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫决策过程和消息传递</title>
      <link>https://stats.stackexchange.com/questions/644835/markov-decision-process-and-message-passing</link>
      <description><![CDATA[我正在读《贝叶斯推理与机器学习》这本书。我正在阅读第 7.5 章有关马尔可夫决策过程的内容。我来自最佳停止/最佳控制背景，熟悉贝尔曼原理等。本质上，这个想法是从最后开始并向后工作。
令我困惑的是，Bellamn 原理（向后步进）的应用是用消息传递来解释的，其中消息是状态的价值函数。
这样表达有什么特殊原因吗？我觉得我一定没有抓住要点。]]></description>
      <guid>https://stats.stackexchange.com/questions/644835/markov-decision-process-and-message-passing</guid>
      <pubDate>Thu, 11 Apr 2024 20:58:20 GMT</pubDate>
    </item>
    <item>
      <title>使用变量公式的变化计算后验</title>
      <link>https://stats.stackexchange.com/questions/644834/compute-posterior-using-change-of-variable-formula</link>
      <description><![CDATA[给定一个从单位圆盘到 $\mathbb R^2$ 的双射 f，$w \sim N( 0、\gamma^2 I)$ 和 $y = f^{-1}(f(x) + w)$，如何显示那
$$ \pi(y | x) = |\det Df(y)| \pi_w(f(x) - f(y))。 $$
我知道 $y = f(x)$ 的变量变化是 $\pi(y) = \pi( f^{-1}(y)) |\det Df^{-1}(y)|$，但这仅适用于 $\pi(y) $ 而不是 $\pi(y|x)$，那么我该如何使用它呢？
编辑更多详细信息：$f(x) = \frac{x}{1- ||x||^2}$。给定单位圆盘中的$x$，计算$f(x)$并随机抽取$w$ 来自正态分布，则 $y = f^{-1}(f(x) + w)$。我需要证明后验分布 $\pi(y | x)$ 如上]]></description>
      <guid>https://stats.stackexchange.com/questions/644834/compute-posterior-using-change-of-variable-formula</guid>
      <pubDate>Thu, 11 Apr 2024 20:23:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 PROC PHREG 的边际结构模型</title>
      <link>https://stats.stackexchange.com/questions/644833/marginal-structural-model-using-proc-phreg</link>
      <description><![CDATA[我想拟合一个边际结构模型来解释随访期间的治疗转换。
我发现了一篇关于如何在 R 中执行此操作的精彩论文：https: //www.sciencedirect.com/science/article/abs/pii/S0010482519302082
但是，当然，我正在从事临床试验并使用 SAS。
2000 年，Hernan、Brumback 和 Robins 提供了在 SAS 中构建 MSM 的代码：
https://journals.lww.com/epidem/fulltext/ 2000/09000/marginal_structural_models_to_estimate_the_causal.12.aspx
由于PROC PHREG不支持时间更新权重，因此使用合并逻辑回归来获得边际风险比。
现在是 2024 年，而不是 2000 年，我想知道时间更新的权重现在是否可以合并到 PROC PHREG 中，或者合并逻辑回归仍然是事实上的 MSM 拟合方法？或者，是否有众所周知的宏可以用来适应这个模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/644833/marginal-structural-model-using-proc-phreg</guid>
      <pubDate>Thu, 11 Apr 2024 20:00:26 GMT</pubDate>
    </item>
    <item>
      <title>通过具有时空相关性的二元测量的重复横截面调查进行区域层面的预测</title>
      <link>https://stats.stackexchange.com/questions/644832/forecasting-at-areal-level-from-repeated-cross-sectional-survey-with-binary-meas</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644832/forecasting-at-areal-level-from-repeated-cross-sectional-survey-with-binary-meas</guid>
      <pubDate>Thu, 11 Apr 2024 19:28:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Hotellings T 方统计量按 n 倍缩放？</title>
      <link>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</link>
      <description><![CDATA[根据 NIST：https://www. itl.nist.gov/div898/handbook/pmc/section5/pmc543.htm T 方统计量的方程的比例因子为 n（有趣的是，维基百科页面引用了此页面，但省略了n 比例因子）。
我想知道为什么要包含这个比例因子？这背后有什么直觉吗？
这是否意味着随着样本数量的增加，正在测试的相同样本的可能性会导致我们拒绝零假设的可能性增加？
我想象 2-D 多元正态数据作为样本，可能 n=100 和 n=1000（从相同的真实分布中采样）。这些将具有（接近）相同的样本均值和方差，但由于此 n 因素，此分布中的新样本不符合零假设的可能性会随着 n 的增加而增加？
当然，随着 n 的增加，与 F 分布（我们用来检查的）的关系会发生变化，但变化幅度不大。对于 p=2，T^2 (n-p)/(pn-p) 的缩放比例为 98/198 ~ 1/2（n=100）和 998/1998 ~ 1/2（n=1000），并且 F 临界值对于 alpha=0.05 来说，两者都约为 3，因此它们的影响很小。]]></description>
      <guid>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</guid>
      <pubDate>Thu, 11 Apr 2024 19:13:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么选择术语“显着性”($a$) 来表示 I 类错误的概率？</title>
      <link>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</link>
      <description><![CDATA[我目前正在学习“统计 1”作为我计算机科学学位的一部分，我很难理解“重要性”的概念。
我们获得了以下定义：
$H_0$ - 零假设
$H_1$ - 替代假设。
$R$ - $H_0$ 拒绝区
$\bar{R}$ - $H_0$ 无拒绝区
$\begin{对齐} \alpha &amp;= P(\text{I 型错误})\\&amp;=P_{H_0}(\text{拒绝 } H_0 ) \\&amp;= P_{H_0}(X\in R) \\&amp;; \end{对齐} $
虽然我相信我已经很好地掌握了这些定义以及它们与 p 值的关系，但术语“显着性”并不适用。我仍然感到困惑。
我理解某事物“具有统计显着性”的概念，但显着性水平越高，出错的风险就越大，这似乎违反直觉。直觉上，当某件事非常重要时，我预计风险会较低。
有人可以解释一下为什么“重要性”一词如此重要吗？被选中了？
对于那些正在寻找的人来说，这些是关于这些术语的统计含义的一些非常好的讨论。我正在寻找更直观的解释来解释为什么选择这个术语。
比较和对比，p -值、显着性水平和 I 类错误
显着性水平 alpha 与 1 类误差 alpha 之间的关系是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</guid>
      <pubDate>Thu, 11 Apr 2024 15:02:37 GMT</pubDate>
    </item>
    <item>
      <title>滞后增强局部投影和标准误差</title>
      <link>https://stats.stackexchange.com/questions/644757/lag-augmented-local-projection-and-standard-errors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644757/lag-augmented-local-projection-and-standard-errors</guid>
      <pubDate>Wed, 10 Apr 2024 22:29:14 GMT</pubDate>
    </item>
    <item>
      <title>对连续解释变量每单位变化结果的纵向变化进行建模</title>
      <link>https://stats.stackexchange.com/questions/644717/modeling-longitudinal-change-in-outcome-per-unit-of-change-in-a-continuous-expla</link>
      <description><![CDATA[我的问题与相关您如何处理“嵌套”问题？回归模型中的变量？但是，我的问题略有不同。
我正在分析来自减肥干预的 RNA-seq 基因表达数据（&gt; 10 000 个基因）。对参与者进行测量，并根据干预前和两个随访点（可变访视）采集的样本进行 RNA 测序。从后续 1 到后续 2，参与者的体重减轻了不同程度，有些甚至反弹了。我们还有其他队列的数据，这些数据无法直接与该数据集进行比较，因为 RNA-seq 实验是分开的。然而，为了产生稍微具有可比性的结果，我想对基因表达的干预效果进行建模，以便结果能够显示从基线到每次随访的体重减轻百分比的变化 (wlp) .
在本例中，visit 是解释变量，wlp 嵌套在其中。如果我只有两个时间点，我将仅使用 wlp 作为解释变量来获得我想要的结果（给出与 visit:wlp 交互相同的结果）。 
我的问题是：在这种情况下，当有三个时间点时，没有主效应的 visit:wlp 交互是否会给我每个 wlp 结果（基因表达）的变化code&gt; 处两次不同的访问？如果我分别分析两个后续点，估计结果非常相似；然而，p 值较小。]]></description>
      <guid>https://stats.stackexchange.com/questions/644717/modeling-longitudinal-change-in-outcome-per-unit-of-change-in-a-continuous-expla</guid>
      <pubDate>Wed, 10 Apr 2024 11:01:24 GMT</pubDate>
    </item>
    </channel>
</rss>