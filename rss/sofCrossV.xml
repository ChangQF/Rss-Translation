<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 31 Dec 2024 21:15:25 GMT</lastBuildDate>
    <item>
      <title>对称单峰分布系列，其中峰度与峰值成反比？</title>
      <link>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</link>
      <description><![CDATA[DeCarlo 于 1997 年在著名期刊《心理学方法》上发表了论文《论峰度的意义和用途》。该论文被广泛引用（引用次数超过 1500 次，其中 129 次“极具影响力”），人们仍然在文献和网络内容中频繁引用它。然而，摘要的第一句话指出：

对于对称单峰分布，正峰度表示
相对于正态分布，尾部较重且呈尖峰状，而负峰度表示尾部较轻且呈平坦状。

这种说法在尖峰状和平坦状方面是不正确的，并且无疑导致了“尖峰状/平坦状”现象的持续存在尽管最近的研究彻底推翻了峰度可以衡量分布的峰值或平坦度（无论是对称分布还是单峰分布）的观点，但这种误解仍然难以消除。
如果给出一组对称单峰分布，其中峰度降低时分布变得更加尖锐，峰度增加时分布变得更加平顶，这将有助于消除这种误解。
（编辑：由于“峰值”定义不明确，因此出于本练习的目的，可以将其操作为标准化变量分布的高度。）
这种对称单峰族的一个简单示例是$\{F_1, F_2\}$，其中$F_1$ 和 $F_2$ 在 维基百科页面 中给出：$F_1$ 是参数为 $0.5$ 和 $1$ 的 beta 分布与其关于 $0.0$ 的反射的均等混合，而 $F_2$ 是 $−1$ 和 $1$ 具有 $T(4.0000001)$ 学生 t 分布，混合概率为 $0.999$ 和 $0.001$。在这个家族中，峰度较高的分布较低，并且看起来完全是平顶的，而峰度较低的（和“platykurtic”）分布则无限尖峰。
然而，描述一个更传统的无限家族 $F_{\theta}$ 会很有趣，其中 $\theta$ 连续变化，峰度范围从“platykurtic” ($&lt;3$) 到无穷大，并且分布（所有对称和单峰）的范围从无限峰值到几乎平顶，因为峰度范围从最小值到无穷大。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</guid>
      <pubDate>Tue, 31 Dec 2024 17:07:42 GMT</pubDate>
    </item>
    <item>
      <title>复制 Pocock 和 Simon 最小化论文 1975 中的模拟结果 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659399/replicating-simulation-results-in-pocock-and-simon-minimization-paper-1975</link>
      <description><![CDATA[我试图复制图 1a 的纯随机分配和随机置换块的模拟结果，该结果来自 Pocock and Simon 1975。
按照本文中介绍的方向，下面是我针对 M=1 因子（2 级）进行随机置换块模拟的尝试：
nsim=1000;
val&lt;- rep(0,nsim)
sq&lt;- seq(0, 1, 0.0002)
prob&lt;- numeric(length(sq))

for (i in seq_along(sq)){
#i=50
for (j in 1:nsim){
#j = 1; 
X11 = rbinom(1, 25, 0.5) 
X21 = rbinom(1, 25, 0.5) 

q1 = X11/25 
q2 = X21/25 
val[j] &lt;- abs(q1 - q2)
}
prob[i] &lt;- 1 - mean( val &lt; sq[i])

}

result &lt;- data.frame(sq=sq,prob=prob)
plot(result$sq , result$prob , type = &quot;l&quot; , xlim = c(0, 0.3))

以下是我的输出：

我用于复制纯随机置换分配的代码如下：

nsim=1000
for (i in seq_along(sq)){

for (j in 1:nsim){
X11 = rbinom(1, 50, 0.5) 
q1 = X11/50 
q2 = 1 - q1
val[j] &lt;- abs(q1 - q2)
}
prob[i] &lt;- 1 - mean( val &lt; sq[i])
}

result &lt;- data.frame(sq=sq,prob=prob)

plot(result$sq , result$prob , type = &quot;l&quot; , xlim = c(0, 0.3))

输出看起来类似：

这些输出与出版物不同。我的代码有什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659399/replicating-simulation-results-in-pocock-and-simon-minimization-paper-1975</guid>
      <pubDate>Tue, 31 Dec 2024 16:16:38 GMT</pubDate>
    </item>
    <item>
      <title>降秩回归的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/659397/asymptotic-normality-of-reduced-rank-regression</link>
      <description><![CDATA[我正在尝试遵循 Reinsel、Velu 和 Chen 编写的《多元降秩回归》教科书。我从降秩回归开始
$$
Y_t = C X_t + \epsilon_t \quad \Leftrightarrow \quad Y_t = A B X_{t} + \epsilon_t
$$
我对 $A \in \mathbb{R}^{N \times r}$ 和 $B \in \mathbb{R}^{r \times N}$ 的渐近协方差感兴趣。
我知道基于矩阵的扰动展开，$M = \Sigma_{\epsilon \epsilon}^{-1/2} \widehat{\Sigma}_{yx} \widehat{\Sigma}_{xx}^{-1} \widehat{\Sigma}_{xy} \Sigma_{\epsilon \epsilon}^{-1/2}$ 的特征向量可以围绕 $N = \Sigma_{\epsilon \epsilon}^{-1/2} \Sigma_{yx} \Sigma_{xx}^{-1} \Sigma_{xy} \Sigma_{\epsilon 的特征向量 $V_j$ 展开\epsilon}^{-1/2}$ 获得
$$
\widehat{V}_j \sim V_j + \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[V_j&#39;(M - N)V_i\right] \quad (j = 1, \ldots, r)。
$$
其中 $\lambda^2$ 是与特征向量相关的特征值。然后我就可以得到
$$
\widehat{\Sigma}_{yx} \widehat{\Sigma}_{xx}^{-1} \widehat{\Sigma}_{xy} - \Sigma_{yx} \Sigma_{xx}^{-1} \Sigma_{xy} = C U_T + U_T&#39; C&#39; + U_T&#39; \widehat{\Sigma}_{xx}^{-1} U_T + C (\widehat{\Sigma}_{xx} - \Sigma_{xx}) C&#39;,
$$
其中 $U_T = T^{-1} \sum_{k=1}^T X_k \epsilon_k$ 我删除了最后两个项，因为我假设预测变量是非随机的。然后我可以使用 $\Sigma_{\epsilon \epsilon}^{-1/2}C = \Sigma_{\epsilon \epsilon} A B = V B$ 来获得
$$
\widehat{V}_j \sim V_j + \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[\underbrace{V_j&#39; V B U_T \Sigma_{\epsilon \epsilon}^{-1/2} V_i}_{(a)} + \underbrace{V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2} U_T&#39; B&#39; V&#39; V_i}_{(b)} \right] \quad (j = 1, \ldots, r)。
$$
然后使用克罗内克乘积规则，我可以将 $(a)$ 矢量化为
$$
(V_i&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_j&#39; V B) \text{vec}(U_T)，
$$
并且 $(b)$ 矢量化为
$$
(V_i&#39; V B \otimes V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2}) \text{vec}(U_T&#39;)。
$$
但是，我不知道如何从 $(b)$ 项中删除转置，以分解出 $\text{vec}(U_T)$。我的一个想法是使用交换矩阵 $K_{mn} \text{vec} (U_T&#39;) = \text{vec}(U_T)$，但这无法解释最后一个大 $O_p$ 部分。最终结果应为
$$
T^{1/2} (\widehat{V}_j - V_j) = 
$$
$$
T^{1/2} \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[(V_i&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_j&#39; V B) + (V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_i&#39; V B)\right] \operatorname{vec}(U_T) + O_p(T^{-1/2})。
$$
此外，我不确定缩放$T^{1/2}$是如何实现的。这是从$M-N$来的吗？提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659397/asymptotic-normality-of-reduced-rank-regression</guid>
      <pubDate>Tue, 31 Dec 2024 12:04:03 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以我们知道是真实的任何事物为条件（例如，婴儿出生在银河系），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>线性 PDF 近似</title>
      <link>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</link>
      <description><![CDATA[鉴于我的数据不完整，我试图估算帕累托分布 PDF 的形状参数 alpha。具体来说，真实数据集的值介于 10 到 50 之间，但我观察到的数据仅涵盖 25 到 50 的范围（即，我缺少 10 到 25 之间的所有数据）。我的挑战是在给定缺失数据的情况下恢复正确的 alpha 值。
背景
帕累托分布由两个参数定义：

alpha（形状参数，决定尾部的斜率）和
xmin（分布的最小值）。

如果我尝试将帕累托分布直接拟合到观察到的数据，则存在两个问题：

如果我设置 xmin = 10（真正的最小值），则拟合无效，因为我的数据不包含低于 25 的值，并且 alpha 不正确。
如果我设置 xmin = 25（我观察到的数据的最小值），则估计的 alpha 不正确，因为它没有考虑到数据的缺失部分。

关键见解
帕累托分布的一个关键属性是其概率密度函数 (PDF) 在对数对数空间 log​​10(x) vs. log10(y) 中绘制时，形成一条直线。该线的斜率与形状参数 alpha 的关系为：
斜率 = -(alpha + 1)
此属性表明，即使缺少大部分数据，我仍然可以通过将观察到的数据转换为对数对数空间、将直线拟合到结果点并使用斜率计算 alpha 来恢复 alpha。
问题
困难在于为观察到的数据构建 PDF。由于我只有一个数据值向量，因此我没有直接的 PDF（或密度值）。这基本上意味着，如果我尝试构建一条直线来恢复 alpha，我有 x 但没有 y。为了近似密度，我尝试了以下方法：

使用核密度估计（通过 R 的 density() 函数）生成 PDF 的平滑近似值。

将 x 值（数据）和 y 值（密度估计）都转换为 log10 空间，将结果拟合成一条线，然后使用斜率估计 alpha。


这是核密度方法的一个例子，但我并不执着于它。
# 模拟观察数据
set.seed(123)
data &lt;- rpareto(1000, alpha = 2, xmin = 10) # 真实数据
observed_data &lt;- data[data &gt;= 25] # 截断到观察范围

# 估计密度使用核平滑
density_est &lt;- density(observed_data, from = 25, to = 50)
log_x &lt;- log10(density_est$x)
log_y &lt;- log10(density_est$y)

# 在对数对数空间中拟合线性模型
lm_fit &lt;- lm(log_y ~ log_x)

# 提取斜率并计算 alpha
slope &lt;- coef(lm_fit)[2]
alpha_est &lt;- -slope - 1

alpha_est

问题

是否有一种更有原则或更稳健的方法来近似此上下文中观察到的数据的 PDF，特别是考虑到缺失数据的方法？
是否有办法近似线性 PDF？我知道它并不存在，但有解决方法吗？
为此目的使用核密度估计是否存在任何理论或实际缺陷？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</guid>
      <pubDate>Tue, 31 Dec 2024 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>统计学中帽子符号的混淆</title>
      <link>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</link>
      <description><![CDATA[学习统计学中的不同符号让我感到困惑。
在基本的线性回归中，我们写：
$$Y = \beta_0 + \beta_1 X + \epsilon$$
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X$$
$$\hat{\epsilon} = y - \hat{y}$$
这是因为误差仅存在于理论模型中，上限位于估计值之上，而残差（$\hat{\epsilon}$）取决于估计量，因此它有一个上限。
除此之外，我越来越困惑。
例如，关于 $Y$ 的边际分布，这两个陈述是否正确？

$$Y \sim N(X^T \beta, \sigma^2) \implies E(Y) = X^T \beta$$
$$Y \sim N(X^T \hat{\beta}, \hat{\sigma}^2) \implies E(Y) = X^T \beta$$

关于 $Y$ 的条件分布，这两个陈述是否正确？

$$E(Y \mid X) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \beta, \sigma^2) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \hat{\beta}, \hat{\sigma}^2) = \beta_0 + \beta_1 X$$

一般来说，我知道一旦你对左边的某个东西取期望，右边就会失去帽子。但我想知道，也许这些陈述中的一些实际上是等价的，只是陈述 1)（在条件和边际陈述中）是简写符号，而其他陈述实际上等同于 1)？
如能帮助澄清有关帽子符号和期望的困惑，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</guid>
      <pubDate>Tue, 31 Dec 2024 02:39:46 GMT</pubDate>
    </item>
    <item>
      <title>分层简单随机抽样的推断</title>
      <link>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</link>
      <description><![CDATA[我想使用分层随机抽样来估计总体概率 $p$，因为我的数据由许多层 $h$ 组成。
在这种情况下，如果我们选择总共 $n$ 个样本，则每层的最佳样本数 $n_h$ 优化如下
$n_h = n\cdot \sqrt{T_h} /(\sum_h \sqrt{T_h})$
其中 $T_h$ 如下
$T_h = (N_h/N)^2({{N_h}\over{N_h -1}}p_h(1-p_h))$
其中 $N$ 为总人口，$N_h$ 为各阶层的数量，$p_h$ 为各阶层的真实概率。因此，当使用分层随机抽样确定来自每个层 $h$ 的最佳样本数 $n_h$ 时，假设每个层 $p_h$ 的真实概率已经已知。 $n_h$ 取决于层大小 $N_h$ 和概率 $p_h$，因此如果 $N_h$ 很大，我们会抽样更多。此外，如果$p_h$在0.5左右，换句话说，如果方差很大，我们就会抽样更多。
那么我想知道使用分层简单随机抽样进行抽样和推断有什么意义？既然我们假设我们知道总体中各层的概率，以便确定最佳样本数，那么是否可以使用$p_h$找出总体的概率？
所以我自己想..我们不假设我们确切地知道$p_h$，但我们几乎知道（可能误差在5％左右？），并使用抽样来计算总体。]]></description>
      <guid>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</guid>
      <pubDate>Tue, 31 Dec 2024 01:10:11 GMT</pubDate>
    </item>
    <item>
      <title>在处理现实世界数据时，统计推断中关于总体分布存在的错误假设的后果</title>
      <link>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</link>
      <description><![CDATA[统计推断方法，例如统计假设检验，假设观察到的数据是从总体分布中抽样的。对于现实世界的数据，这是一个很大的简化。例如，imdb.com 上特定电影的评分不是从任何分布中抽样的。相反，它们是多种因素的组合，如演员阵容、演技、声音、观众的情绪等。
据我所知，只要我们能够评估这些假设引入了什么错误，对数据做出错误的假设是完全可以的。例如，我们在机器学习中有一个朴素贝叶斯模型，它假设在给定目标类的情况下，特征是条件独立的。对于许多数据集来说，这是错误的。但我们有一个测试集，即整个数据集的一部分，它使我们能够评估建立在错误假设基础上的这种模型的错误。
在统计假设检验的情况下，我们没有提供评估此类错误的方法。据我所知，当测试集缺失时，统计推断方法的任何结果（例如拒绝零假设）都会受到未知大小的误差的影响，从而使结果完全无用。
我大胆地说统计假设检验对现实世界数据无用，对吗？还是我在这里遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</guid>
      <pubDate>Mon, 30 Dec 2024 21:21:18 GMT</pubDate>
    </item>
    <item>
      <title>“AUROC 曲线”这个术语实际上是否正确且有意义？</title>
      <link>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</link>
      <description><![CDATA[15 年前，当我进入机器学习领域时，我了解到 AUC 代表“曲线下面积”，即“ROC 曲线下面积”，而 ROC 是“接收者操作特性”。
现在我自己在指导学生，（当然）他们有时会根据他们首先阅读的文献和资料使用不同的术语。我听说过 AUROC，根据这里的一些观点，它比 AUC 更好，因为后者没有指定指的是哪条曲线，而且除了 ROC 之外还有其他可能。
但后来我读到 AUROC 曲线，它在很多层面上听起来都是错误的。 （我不是以英语为母语的人。）
您指的是曲线下的面积，即 AUC 或 AUROC，或曲线本身，即ROC 曲线，因此 AUROC 曲线对我来说真的没有意义。但是，通过 CV 搜索我发现它被使用了几次，但从未被更正或解决，例如

为什么 ROC 曲线和 AUC 值并不总是相关的？
如何解释抵押贷款拒绝/批准的 AUROC 曲线？
如何解释 AUROC分数？

所以，我的问题是：我在这里是对的还是过于迂腐？还是忽略了一些显而易见的东西？
澄清：
似乎我的问题含糊不清，我应该澄清：
我的问题是使用术语“AUROC 曲线”来表示曲线，而不是值，例如

对于随机分类器，AUROC 曲线将是一条从 [0,0] 到 [1,1] 的对角线
]]></description>
      <guid>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</guid>
      <pubDate>Mon, 30 Dec 2024 15:26:49 GMT</pubDate>
    </item>
    <item>
      <title>使用信息标准（如 AIC）来比较适合具有不同 Box-Cox lambda 的转换数据的 ARIMA 模型是否合理？</title>
      <link>https://stats.stackexchange.com/questions/659367/is-it-reasonable-to-use-information-criteria-like-aic-to-compare-arima-models</link>
      <description><![CDATA[我正在使用 R 中 forecast 包中的 auto.arima 函数。
我有以下 2 个模型拟合
&gt; (ar_fit_0 &lt;- auto.arima(series_data, lambda = 0, max.d = 0))
系列：series_data 
ARIMA(2,0,1) 具有非零均值 
Box Cox 变换：lambda= 0 

系数：
ar1 ar2 ma1 均值
1.2472 -0.2572 -0.8259 14.9760
s.e. 0.0579 0.0551 0.0394 0.2315

sigma^2 = 0.1508：对数似然 = -341.64
AIC=693.27 AICc=693.36 BIC=716.2

&gt; (ar_fit_auto &lt;- auto.arima(series_data, lambda = &quot;auto&quot;, max.d = 0))
系列：series_data 
ARIMA(2,0,1) 具有非零均值 
Box Cox 变换：lambda= 0.1369332 

系数：
ar1 ar2 ma1 均值
1.2522 -0.2620 -0.8260 49.6173
s.e. 0.0582 0.0554 0.0396 1.8434

sigma^2 = 9.216：对数似然 = -1832.6
AIC=3675.21 AICc=3675.29 BIC=3698.14

两者之间的唯一区别是第二个使用自动 Box-Cox lambda 选择
自动 lambda 选择会导致更高的 AIC。但我对在这些情况下使用可能性相关指标有点怀疑。数据已经以不同的方式进行了转换，我怀疑拟合过程只看到转换后的数据，因此“不知道”已经发生了转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/659367/is-it-reasonable-to-use-information-criteria-like-aic-to-compare-arima-models</guid>
      <pubDate>Mon, 30 Dec 2024 12:19:47 GMT</pubDate>
    </item>
    <item>
      <title>区间变量与名义变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</link>
      <description><![CDATA[我有一个表示村庄大小（以公顷为单位）的数值变量和一个表示四种土壤类型的分类变量。我想使用 R 研究土壤类型是否与村庄大小有关。我绘制了箱线图，但现在我想得到一些关联度量。我读过这里的一些答案，建议使用 ANOVA 的 Eta（相关比）。我的规模数据不是正态分布的，所以我怀疑我是否可以使用它。在包 rstatix 中，函数 kruskal_effsize 也给出了 eta-squared 的值，但基于 H。根据 rstatix 文档“...eta-squared...表示由独立变量解释的因变量方差的百分比。”使用这个度量来得出关于两个变量之间关系的结论是否正确？
如果有人能对此有所启发，我将不胜感激。
我得到了所有的 Eta 值，但我需要知道我是否可以使用它们。

感谢大家的所有建议和帮助。我真的很感激。
同时，我阅读了一些参考书目，并决定进行 Kruskal-Wallis 检验，因为我的数据不是正态分布的，并使用了 epsilon-squared。]]></description>
      <guid>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</guid>
      <pubDate>Sat, 28 Dec 2024 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SPSS 对重复测量方差分析中的两个受试者内因素进行事后分析</title>
      <link>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</link>
      <description><![CDATA[我目前正在对两个受试者内因素进行重复测量方差分析。分析结果显示存在显著的相互作用，我添加了以下命令进行事后分析：
/EMMEANS=TABLES(IV1*IV2) COMPARE(IV1) ADJ(BONFERRONI)
虽然结果显示存在显著影响，但我对分析结果存有疑虑，因此寻求建议。
当我将此命令的结果与配对 t 检验（未校正）的结果进行比较时，配对 t 检验的值与 SPSS 命令生成的结果相同。这让我怀疑 Bonferroni 校正可能未正确应用。
我使用的命令可能存在问题？如果存在，那么在 SPSS 中正确应用 Bonferroni 校正的正确命令是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</guid>
      <pubDate>Fri, 27 Dec 2024 05:17:56 GMT</pubDate>
    </item>
    <item>
      <title>在具有许多零值的数据中选择正确的相关方法</title>
      <link>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</link>
      <description><![CDATA[我想计算我的数据中两个基因之间的相关性。到目前为止，我所做的是计算 Pearson 或 Spearman 相关性（我更依赖 Spearman，因为基因之间没有线性关系）。
但是 - 许多细胞对基因 1、基因 2 或两者的表达为零，这导致相关性不准确和偏差。
所以我有一些选择 -

我可以只保留表达两个基因的细胞（这将删除大量细胞），然后重新计算相关性。
我应该保留零，因为它是生物学的一部分
使用对零不太敏感的其他方法，例如余弦相似度？

例如，这里有一个图 - 每个点是一个细胞，X 轴是基因 1 的表达，Y 轴是基因 2 的表达：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</guid>
      <pubDate>Tue, 24 Dec 2024 11:42:54 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习要素（第 44 页），并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i \mid \theta)。
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n \mid \theta)。
$$



观察：

边际：
在情况 1中，由于独立性假设，输入的边际分布分解为$\prod_{i=1}^n P(x_i \mid \theta)$。
在情况 2中，输入的边际分布写为单个项$P(x_1, x_2, \dots, x_n \mid \theta)$，因为没有假设$x_i$。

条件：
在这两种情况下，除去边际，给定$x_i$的$y_i$的条件分布是相同的：
$$
\prod_{i=1}^n P(y_i \mid x_i, \theta)。
$$


这表明，尽管对边际的假设不同，但条件结构并没有不同。

问题：

两种情况下的联合似然方程是否准确，它们是否正确反映了各自的独立性或条件独立性假设？

如果是这样，那么假设$(x_i, y_i)$完全独立（情况 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性，如观察结果所示？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>相干系统的累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/658321/cumulative-distribution-function-of-coherent-system</link>
      <description><![CDATA[该定理来自这里
定理 3.1. 设 $X_1, \ldots, X_n$ 为具有签名 $s$ 的 $n$ 组件相干系统的 i.i.d. 组件生命周期，并设 $T$ 为系统的生命周期。然后
$$
\overline{F}_T(t) \equiv P(T &gt; t) = \sum_{i=1}^n s_i \sum_{j=0}^{i-1} \binom{n}{j} (F(t))^j \big(\overline{F}(t)\big)^{n-j}.$$
证明：我们首先注意到系统与其某个组件的故障同时发生，因此 $T$ 必然会取样本 $X_1, \ldots, X_n$ 的顺序统计量 $X_{i:n}$ 之一的值，即 $T \in \{X_{1:n}, X_{2:n}, \ldots, X_{n:n}\}$ 的概率为 $1$。然后，利用全概率定律和 i.i.d。关于组件寿命的假设，我们可以写成
\begin{align}
P(T &gt; t) &amp;= \sum_{i=1}^n P(T &gt; t, T = X_{i:n})\\
&amp;= \sum_{i=1}^n P(T &gt; t \mid T = X_{i:n}) P(T = X_{i:n})\\
&amp;= \sum_{i=1}^n s_i P(X_{i:n} &gt; t)\\
&amp;= \sum_{i=1}^n s_i \sum_{j=0}^{i-1} \binom{n}{j} (F(t))^j \big(\overline{F}(t)\big)^{n-j}
\end{align&gt;
我想要知道最后的平等是怎么产生的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658321/cumulative-distribution-function-of-coherent-system</guid>
      <pubDate>Thu, 05 Dec 2024 12:54:43 GMT</pubDate>
    </item>
    </channel>
</rss>