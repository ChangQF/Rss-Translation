<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 21 Jan 2025 09:17:42 GMT</lastBuildDate>
    <item>
      <title>Patricia trie 的高度是 iid 与有界字符串</title>
      <link>https://stats.stackexchange.com/questions/660302/height-of-a-patricia-trie-is-iid-vs-bounded-strings</link>
      <description><![CDATA[我想知道产生一个独立同分布的字符串的过程与长度有限的字符串之间的关系是什么？我试图想出一个长度有限但最终不是独立同分布的字符串，但我做不到——最终，人们必须分散差异，因为深度是有限的。我可以想到一个对抗性的过程，比如 $\{1, 11, 111, 1111, 11111, \ldots\}$，其中高度将退化为 $\mathcal{O}(n)$，但我想不出任何有界的东西。
我很好奇，因为在 Tong, Goebel, Lin, 2015, Smoothed 中，他们研究了尝试，

给定一个集合 $\mathscr{L}\{s_1, s_2, \ldots, s_n\}$ 个 $n$ 个二进制字符串，我们通过向每个字符串的每个位添加 i.i.d. 伯努利随机噪声来扰乱该集合。我们表明，最终的 trie [我假设使用路径压缩] 和 patricia trie [二进制路径压缩] 的平滑高度都在 $\mathcal{\Theta}(\log n)$ 中。

我用无意义的随机词测试了这一点，发现与实验数据非常吻合。]]></description>
      <guid>https://stats.stackexchange.com/questions/660302/height-of-a-patricia-trie-is-iid-vs-bounded-strings</guid>
      <pubDate>Tue, 21 Jan 2025 07:12:35 GMT</pubDate>
    </item>
    <item>
      <title>CLIP 实际上使用哪种损失函数？</title>
      <link>https://stats.stackexchange.com/questions/660300/which-loss-function-is-clip-actually-using</link>
      <description><![CDATA[我研究 CLIP 有一段时间了，我通过 InfoNCE 等损失得出了结论，但实际上我确实没有找到任何可以深入研究的细节。
据我所知，CLIP 使用稀疏 CCE。
他们像这样获取 logits
# 对于 batch_size=3
image_text_logits = [
[5.0, 1.0, 2.0], # Image0 与 [Text0, Text1, Text2] 的相似性
[1.0, 4.0, 2.0], # Image1 与 [Text0, Text1, Text2] 的相似性
[2.0, 1.0, 6.0] # Image2 与 [Text0, Text1, Text2] 的相似性
]

# 经过 softmax
probabilities = [
[0.87, 0.03, 0.10], # 应该在索引 0 处最高
[0.12, 0.75, 0.13]，# 应该在索引 1 处最高
[0.06, 0.02, 0.92] # 应该在索引 2 处最高
]

# 目标是标签=[0,1,2]

目标是这些 logit 的索引吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660300/which-loss-function-is-clip-actually-using</guid>
      <pubDate>Tue, 21 Jan 2025 06:10:47 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型中的偏移</title>
      <link>https://stats.stackexchange.com/questions/660299/offset-in-linear-regression-model</link>
      <description><![CDATA[我有一个线性回归模型，它接收特征列表 $X$ 并生成预测向量 $\hat{Y}$。总体而言，该模型表现良好：预测值 $\hat{Y}$ 和实际观测值 $Y$ 之间的相关性很高。此外，我知道数据的 y 截距应等于零。
我遇到了以下问题：似乎有一些漂移应用于数据，导致截距随时间移动。我的相关性仍然很高，因为偏移不会影响模型的 $r^2$，但我预测的真实值不再与观测值匹配。
这是一个例子。如果我今天拟合我的线性回归系数，我可能会得到一个如下所示的散点图：

如果我在几个小时后使用相同的线性回归系数，我可能会得到一个如下所示的散点图：

请注意上面的常量偏移量$(0, 0)$。尽管“实际值”的均值仍为零，但“预测值”的均值大于零。这引出了以下问题：
如何解释我的预测值和实际值之间的时变偏移？我考虑过通过对我的预测值取一些移动平均值并将其从真实预测值中减去来降低预测值的意义，但我不确定这是否会对我的结果造成偏差。实际上，我会将特征的观测值的某些函数重新插入到线性回归模型中，我不确定这是否会因为内生性而导致问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/660299/offset-in-linear-regression-model</guid>
      <pubDate>Tue, 21 Jan 2025 05:30:29 GMT</pubDate>
    </item>
    <item>
      <title>来自观察回归的因果陈述</title>
      <link>https://stats.stackexchange.com/questions/660298/causal-statements-from-observational-regressions</link>
      <description><![CDATA[假设一个拼车服务的背景。现有的乘客-司机匹配算法已经存在，但提出了一种新的替代方案。在实施该方法的成本（更不用说实验测试）之前，公司希望了解对所提出方法的投资是否值得。核心目标是增加乘客量（增加预订量和/或减少取消量）。使用逻辑回归，公司以诸如接送预计到达时间和价格等协变量为条件来预测预订量。提取了接送预计到达时间和价格的系数，公司认为，与现有模型匹配模型相比，如果所提出的模型能够实现接送预计到达时间和价格的减少 5%，公司应该会观察到预订量增加 2%。
这是一个假设性问题和用例。因为只有观察数据可用，而不是 RCT，所以我们首先不知道接送预计到达时间减少 5% 是否可能，其次，我们不知道这是否会对预订产生 +2% 的因果影响，对吗？
在我看来，该分析表明这是一个潜在的值得投资的机会，但不能保证预期的结果，因为尚未观察到该结果。
但是，我希望得到反馈，根据观察到的数据，是否可以真正做出因果陈述（例如，如果接送预计到达时间减少 5%，乘客人数将增加 2%）。
我确实相信可以实施反向测试，其中随机用户体验到接送预计到达时间的任意 x% 增加将导致预订量减少 y%。该系数在对数赔率空间中是线性的，而不是原始预订空间本身，因此我不确定提货预计到达时间增加 5% 是否会导致预订量减少 2%（即不对称）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660298/causal-statements-from-observational-regressions</guid>
      <pubDate>Tue, 21 Jan 2025 03:56:09 GMT</pubDate>
    </item>
    <item>
      <title>这些常见的计量经济学测试中哪些对条件异方差不变？</title>
      <link>https://stats.stackexchange.com/questions/660297/which-of-these-common-econometrics-tests-are-invariant-to-conditional-heterosked</link>
      <description><![CDATA[这些常见的计量经济学检验中哪些对条件异方差不变？如果在测试回归中存在条件异方差的证据，哪些检验需要异方差稳健标准误差？
在测试回归中，是否存在需要 HAC（而不是 HC）一致性标准误差的情况？

Breusch-Pagan 检验（使用 F 统计量还是 LM 统计量）
Breusch-Godfrey 检验（使用 F 统计量还是 LM 统计量）
增强 Dickey-Fuller 检验
在第一阶段回归中测试弱工具（想想股票和 Yogo）
Ramsey RESET 检验
]]></description>
      <guid>https://stats.stackexchange.com/questions/660297/which-of-these-common-econometrics-tests-are-invariant-to-conditional-heterosked</guid>
      <pubDate>Tue, 21 Jan 2025 03:22:46 GMT</pubDate>
    </item>
    <item>
      <title>使用半层次生态数据的 GAM 的正确公式化？</title>
      <link>https://stats.stackexchange.com/questions/660295/proper-formulation-of-gam-with-semi-hierarchical-ecological-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660295/proper-formulation-of-gam-with-semi-hierarchical-ecological-data</guid>
      <pubDate>Tue, 21 Jan 2025 00:25:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 计算第三类修正贝塞尔函数 (关于其参数) 的导数？[重复]</title>
      <link>https://stats.stackexchange.com/questions/660292/how-do-we-calculate-the-derivative-of-the-modified-bessel-function-of-the-third</link>
      <description><![CDATA[正如标题所述，我想知道如何使用 R 计算第三类修正贝塞尔函数的导数（关于其参数）。据我所知，没有包可以做到这一点。有人能提供一些指导吗？任何帮助都值得感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660292/how-do-we-calculate-the-derivative-of-the-modified-bessel-function-of-the-third</guid>
      <pubDate>Mon, 20 Jan 2025 23:07:58 GMT</pubDate>
    </item>
    <item>
      <title>使用具有时间依赖性系数的 Cox 模型预测风险</title>
      <link>https://stats.stackexchange.com/questions/660291/predicting-risk-from-a-cox-model-with-time-dependent-coefficients</link>
      <description><![CDATA[假设我们想使用年龄、性别和 Epicel 的存在来预测恶性黑色素瘤的死亡率，该模型中的年龄系数是时间的阶跃函数，在 1500 天处有一个中断（年龄具有时间依赖性系数）。
library(tidyverse)

library(riskRegression)

data &lt;- as_tibble(Melanoma) %&gt;% mutate(status=as.numeric(status==1))

data2 &lt;- survSplit(Surv(time,status)~age+sex+epicel,data=data,cut=1500,episode=&#39;tgroup&#39;,id=&#39;id&#39;)

fit &lt;- coxph(Surv(tstart,time,status)~age:strata(tgroup)+sex+epicel,data=data2)

现在，为了计算一名 20 岁且有 epicel 的女性在 2000 天内的绝对风险，我们可以估算她的相关累积风险 ($H(t)$)，然后 2000 天内的绝对风险估计值为 $1-exp(-H(2000))$。根据 https://cran.r-project.org/web/packages/survival/vignettes/timedep.pdf 第 4.1 部分，我们将得到：
nd &lt;- tibble(id=1,tgroup=1:2,tstart=c(0,1500),time=c(1500,5000),status=0,

age=20,sex=&#39;Female&#39;,epicel=&#39;present&#39;)

H &lt;- with(survfit(fit,newdata=nd,id=id),splinefun(time,cumhaz))

1 - exp(-H(2000))

问题：

当我们具有时间相关系数时，survfit 如何始终为我们的示例患者生成一组累积风险估计值？换句话说，不同时间间隔的不同年龄系数如何有助于创建一组随时间推移的累积风险估计值？
我们是否需要估计 newdata 中每个个体的累积风险来估计他们的风险？因为显然 $H(t)=H_0(t)exp(LP)$（$LP$ 是线性预测因子）在这里不成立，因为 $LP$ 包括时间的阶跃函数，因此它会随时间生成风险的阶跃函数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660291/predicting-risk-from-a-cox-model-with-time-dependent-coefficients</guid>
      <pubDate>Mon, 20 Jan 2025 22:29:38 GMT</pubDate>
    </item>
    <item>
      <title>如何训练具有较小ECE（预期校准误差）的模型？</title>
      <link>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</link>
      <description><![CDATA[如果我们训练一个具有交叉熵损失的深度学习模型，我们期望该模型具有较低的交叉熵损失。有没有办法训练模型，使模型获得较小的预期校准误差，同时保持负对数似然较小？或者有没有好的后处理方法来降低 ECE，同时保持交叉熵损失较小？]]></description>
      <guid>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</guid>
      <pubDate>Mon, 20 Jan 2025 19:19:42 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将标准化逻辑回归系数转换为相关性？</title>
      <link>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</link>
      <description><![CDATA[我正在对皮尔逊相关性 (Rs) 进行荟萃分析。我正在将其他相关性度量转换为 Rs（可能在计算它们之后进行，以防两个度量都是分类的），并使用有关均值和标准差的信息来估计 Cohen&#39;s d，然后将其转换为 R。
然而，有两篇论文，其中一个度量是连续的，另一个是二元的，并且只有优势比及其置信区间可用。我可以计算标准化（对数）优势比，因为我有连续预测变量的标准差，但是，有没有办法将其转换为相关性？当预测变量也是二进制时，我发现了很多关于这种转换的资料，但没有关于预测变量是连续的情况的资料。
编辑
本文：pmc.ncbi.nlm.nih.gov/articles/PMC8096648 指出：“比值比主要取决于受影响个体在人群中的比例或患病率”，“虽然比值比在这种情况下具有很大的实用性，但它们在衡量变量关联或相关程度方面做得很差”，“由于缺乏关于基准率的信息，比值比可能代表变量之间不同程度的相关度”和“比值比可以代表广泛的点双列相关性，具体取决于序数特征的普遍性”。因此，任何公式都应考虑结果的频率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</guid>
      <pubDate>Mon, 20 Jan 2025 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>《危险边缘》玩家的贝叶斯分析</title>
      <link>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</link>
      <description><![CDATA[这是我的一个想法。
有一个著名的电视智力竞赛节目叫做Jeopardy。玩家回答琐事问题并相互竞争。这个游戏有一个速度元素——虽然多个玩家可能知道同一个问题的答案，但更快响铃的玩家将优先回答问题。
我很好奇，想估计一下节目中玩家的“真实知识”。我天真地以为玩家可以大致分为 4 类：

第 1 组：回答很多问题且经常正确的玩家
第 2 组：回答很多问题且经常错误的玩家
第 3 组：回答不多但经常正确的玩家
第 4 组：回答不多但经常错误的玩家

我在 R 中模拟了一些数据，以直观地展示其可能的样子：

当我们拥有关于玩家的更多数据（即第 1 组和第 2 组）时，应该有玩家知道多少的模糊性较小。但是，对于数据较少的玩家（即第 3 组和第 4 组），这些玩家可能实际上知道的比数据显示的要多（例如，如果他们参加有相同问题的书面测试，他们的表现会与他们在智力竞赛节目中的表现不同）。这似乎应该受到他们在智力竞赛节目中回答的问题数量的影响。
贝叶斯方法（例如标准贝叶斯、经验贝叶斯）可用于尝试估计“修正”这些玩家的得分比例是多少？
这是我的想法。

标准贝叶斯：对于每个玩家$i$：


$\theta_i$是他们正确回答问题的真实概率
$n_i$是他们尝试的问题数量
$y_i$是正确答案的数量

每个玩家的似然函数遵循二项分布：
$$y_i|\theta_i \sim \text{Binomial}(n_i, \theta_i)$$
$$\theta_i \sim \text{Beta}(\alpha, \beta)$$
$$\theta_i|y_i \sim \text{Beta}(\alpha + y_i, \beta + n_i - y_i)$$
$$E[\theta_i|y_i] = \frac{\alpha + y_i}{\alpha + \beta + n_i}$$
我不确定经验贝叶斯在这里会如何使用。这些方法对这个问题有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:31 GMT</pubDate>
    </item>
    <item>
      <title>第二部分：为什么生存函数总是随着时间的推移而减少？</title>
      <link>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</link>
      <description><![CDATA[我发布了这个问题为什么生存函数总是随着时间的推移而减少？，我得到了一个非常好的答案（https://stats.stackexchange.com/a/660245/455511）解释了为什么生存函数总是随着时间的推移而减少：

是的，随着时间的推移，幸存疾病的概率会增加，
但这不是生存函数。生存函数
会每次告诉你在指定的较早时间患有该疾病的人中有多少人仍然存活下来。

我可以看到风险函数可以随时间增加和减少。例如，对于对数正态分布，风险函数可以随时间增加和减少（对数正态风险的公式是什么？）。我可以在这里看到这一点（https://devinincerti.com/2019/06/18/parametric_survival.html）。
我想知道：即使生存函数本身总是随着时间的推移而减少，生存模型（例如 AFT、Cox-PH）是否可以表明，患病后存活的概率实际上可能（暂时）随着时间的推移而增加？
例如，想象一种疾病通常会在第一年杀死人（即死亡概率很高），但如果它没有杀死你，那么身体就会适应变得更有弹性，因此死亡的概率就会降低……而死亡的概率只有在多年后才会再次增加。我理解风险函数可能能够更自然地捕捉这种行为，但我想知道生存模型是否可以通过概率而不是风险来描述这种现象？
我想也许可以使用条件生存概率来实现？典型的生存函数是生存超过一定时间$t$的概率，即$S(t) = P(T &gt; t)$。但是由于条件生存概率定义为：
$$P(T &gt; t | T &gt; s) = \frac{S(t)}{S(s)}$$
但是似乎条件生存概率必须始终随时间减少？

设 $s &lt; t_1 &lt; t_2$。考虑：
$$P(T &gt; t_2|T &gt; s) &gt; P(T &gt; t_1|T &gt; s)$$
使用定义：$$\frac{S(t_2)}{S(s)} &gt; \frac{S(t_1)}{S(s)}$$
将两边乘以 $S(s)$：$$S(t_2) &gt; S(t_1)$$
由于 $t_2 &gt; t_1$，且生存函数 $S(t)$ 单调递减：$$S(t_2) &lt; S(t_1)$$
这与我们的假设相矛盾。
因此：$$P(T &gt; t_2|T &gt; s) &lt; P(T &gt; t_1|T &gt; s)\ \text{for}\ t_2 &gt; t_1$$

我很困惑：似乎条件生存概率也必须随时间减少？


条件生存概率的推导：

$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)}$$
$$P(T &gt; t \cap T &gt; s) = P(T &gt; t) \quad \text{when } t &gt; s$$
$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)} = \frac{P(T &gt; t)}{P(T &gt; s)}$$
由于 $S(t) = P(T &gt; t)$，因此：
$$P(T &gt; t|T &gt; s) = \frac{S(t)}{S(s)}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</guid>
      <pubDate>Mon, 20 Jan 2025 03:47:17 GMT</pubDate>
    </item>
    <item>
      <title>层次模型规范和伪复制</title>
      <link>https://stats.stackexchange.com/questions/660236/hierarchical-model-specification-and-pseudoreplication</link>
      <description><![CDATA[我有一个实验，我们测量嵌套在地块内的单棵树的直径。地块在整个景观中成对出现，配对中的其中一个地块随机分配到治疗组，另一个地块分配到对照组。地块内的所有树木要么接受治疗，要么接受对照条件。
至少有两种方法可以对这些数据进行建模。第一种方法是指定一个随机效应模型，考虑配对结构（下面以 R 为例）。
library(nlme)
fit &lt;- lme(diameter ~ treatment, random = ~1|pair)

或者，我也可以将地块指定为嵌套在配对中的随机效应。
fit &lt;- lme(diameter ~ treatment, random = ~1|pair/plot)

这会导致非常不同的功率水平。地块和处理完全混淆了——给定地块内的所有树木要么接受处理条件，要么接受控制条件。因此，我认为将地块指定为随机效应是没有意义的，因为它会在估计过程中“吸收”所有潜在的处理效果。
这里有明显的选择吗？或者可以选择任一结构？指向特定学术文献的回复可获得加分！]]></description>
      <guid>https://stats.stackexchange.com/questions/660236/hierarchical-model-specification-and-pseudoreplication</guid>
      <pubDate>Sun, 19 Jan 2025 14:39:09 GMT</pubDate>
    </item>
    <item>
      <title>当其中一个分布比较简单时，使用蒙特卡洛估计 Kullback-Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</link>
      <description><![CDATA[我感兴趣的是估算$D_\mathrm{KL}(q \parallel p) = \int q(x) \log \frac{q(x)}{p(x)}\,\mathrm dx$，其中$p$是多元高斯分布，$q$是通过神经网络参数化的隐式分布，例如GAN中的生成器网络。背景：分布是隐式的，这意味着虽然我们可以从分布中抽样，但其密度是难以处理的。
一种直接的估计方法是拟合一个 Logistic 分类器 $f(x)$，将 $q$ 的样本与 $p$ 的样本区分开来，然后通过蒙特卡洛近似 KL 为：$\frac{1}{S}\sum_{j=1}^S \log\frac{\sigma(f(x_j))}{1-\sigma(f(x_j))}$，又名密度比技巧。我们用$\sigma(\cdot)$表示 S 型函数。
这种方法的一个明显缺点，也是我想问这个问题的原因，是我们没有利用$p(x)$的密度是已知且简单的事实，参见这篇文章。我们能做些什么来利用$p(x)$的高斯分布来改进估计吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</guid>
      <pubDate>Thu, 16 Jan 2025 16:12:32 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    </channel>
</rss>