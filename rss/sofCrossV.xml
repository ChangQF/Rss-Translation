<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 08 Jan 2024 06:19:30 GMT</lastBuildDate>
    <item>
      <title>带粒子滤波的维特比算法的实现</title>
      <link>https://stats.stackexchange.com/questions/636398/implementation-of-viterbi-algorithm-with-particle-filtering</link>
      <description><![CDATA[我正在尝试实现本文中的算法：https:/ /www2.stat.duke.edu/~mw/MWextrapubs/Godsill2001.pdf
这是主要方程
状态空间模型方程：

状态演化密度：$x_t \sim f(x_t | x_{t-1})$（公式 1）
观测密度：$y_t \sim g(y_t | x_t)$（公式 2）

状态和观测值的联合分布：

$p(x_{1:t} | y_{1:t}) \propto \prod_{i=1}^{t} f(x_i | x_{i) -1}) g(y_i | x_i)$（公式 3）

联合分布的递归：

$p(x_{1:t+1} | y_{1:t+1}) = p(x_{1:t} | y_{1:t} ) g(y_{t+1} | x_{t+1}) \frac{p(y_{t+1})}{p(x_{t+1} | y_t)}$ （方程4）

粒子过滤近似：

$p(x_{1:t} | y_{1:t}) \approx \sum_{i=1}^{N} w_t^{(i)} \delta_{x_{1:t}^{(i)}} (dx_{1:t})$（公式 5）

MAP序列估计：

$x_{\text{MAP}}^{1:t} (t) = \arg \max_{x_{1:t}} p(x_{1: t} | y_{1:t})$（公式 6）
边际固定滞后 MAP 序列：$x_{\text{MMAP}}^{t-L+1:t} (t) = \arg \max_{x_{ t-L+1:t}} p(x_{t-L+1:t} | y_{1:t})$（公式 7）

通过动态规划优化：

$x_{\text{MAP}}^{1:t} (t) = \arg \max_{x_{1:t}} \sum_{k=1 }^{t} [\log g(y_k | x_k) + \log f(x_k | x_{k-1})]$ （公式 9）

这是我的尝试：
将 numpy 导入为 np

def state_transition(x, process_noise_std):
    返回 x + np.random.normal(0, process_noise_std, size=x.shape)

def观察似然（x，y，观察噪声标准）：
    返回 np.exp(-0.5 * ((y - x) ** 2) / Observation_noise_std ** 2)

def 重新采样（粒子，权重）：
    指数 = np.random.choice(len(粒子), size=len(粒子), p=权重)
    返回粒子[索引]

def 粒子过滤器（初始粒子，观测值，process_noise_std，observation_noise_std）：
    num_articles = len(初始粒子)
    粒子= np.copy（初始粒子）
    所有粒子 = []
    所有权重 = []

    对于观测值中的 y：
        粒子 = state_transition(粒子, process_noise_std)
        权重=观察似然（粒子，y，观察噪声标准）
        重量 += 1.e-300
        权重 /= 总和(权重)
        
        all_articles.append(粒子)
        all_weights.append(权重)

        粒子=重新采样（粒子，权重）

    返回所有粒子、所有权重

def viterbi_for_article_filter(x_articles, 权重, y_observations, Observation_noise_std):
    num_observations = len(y_observations)
    num_粒子 = len(x_粒子[0])

    delta = np.zeros((观察数, 粒子数))
    psi = np.zeros((num_observations, num_articles), dtype=int)

    # 初始化
    delta[0, :] = np.log(权重[0] + 1.e-300) + np.log(观察似然(x_粒子[0], y_观察[0], 观察_噪声_std))

    # 维特比算法
    对于 t in range(1, num_observations)：
        对于范围内的 i（num_articles）：
            log_trans_probs = np.log(权重[t-1] + 1.e-300)
            log_obs_prob = np.log(observation_likelihood(x_articles[t][i], y_observations[t], Observation_noise_std))
            Total_log_probs = delta[t-1, :] + log_trans_probs + log_obs_prob
            
            psi[t, i] = np.argmax(total_log_probs)
            delta[t, i] = np.max(total_log_probs)

    # 回溯寻找最可能的路径
    x_MAP = np.zeros(num_observations, dtype=int)
    x_MAP[num_observations-1] = np.argmax(delta[num_observations-1, :])

    对于范围内的 t(num_observations-2, -1, -1)：
        x_MAP[t] = psi[t+1, x_MAP[t+1]]

    返回x_粒子[0][x_MAP]

# 用法示例
粒子数 = 1000
初始粒子 = np.random.normal(0, 1, 大小=num​​_articles)
y_观察值 = [1.2, 1.5, 1.7, 1.4, 1.1]
过程噪声标准 = 0.1
观察噪声标准 = 0.2

x_粒子，权重 = 粒子过滤器（初始粒子，y_观察，过程噪声标准，观察噪声标准）
x_MAP = viterbi_for_article_filter（x_粒子，权重，y_观察值，observation_noise_std）
打印（x_MAP）

根据我对本文的解释，我不确定我的实现是否正确 - 有人可以帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636398/implementation-of-viterbi-algorithm-with-particle-filtering</guid>
      <pubDate>Mon, 08 Jan 2024 06:00:34 GMT</pubDate>
    </item>
    <item>
      <title>寻找具有约束的标准正态的联合概率分布</title>
      <link>https://stats.stackexchange.com/questions/636397/finding-joint-probability-distribution-of-standard-normal-with-constraints</link>
      <description><![CDATA[&lt;块引用&gt;
设 $X, Y \mathop{\sim}\limits^{iid} N(0,1)$。
a) 假设 $X &lt; Y$，找到$X$和$Y$的联合pdf。
b) 如果 $X$ 和 $Y$ 的联合 pdf 是多少=&quot;math-container&quot;&gt;$X = Y$？

我们知道 $f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2} }$ 和 $f_Y(y)= \frac{1}{\sqrt{2\pi}}e^{-\frac{y^2}{2 }}.$
无约束时，联合pdf为$f_{X,Y}(x,y) = f_X(x)\times f_Y(y),$ 因为 $X$ 和 $Y$ 是独立的。现在，
对于a)部分，我的想法是$f(x,y|x 其中 $P(x 但是，这种集成似乎没有紧密的形式。也许，我在这里使用了错误的想法？。
对于 b) 部分，我尝试在 ChatGPT 上获取一些想法，但在不同时间得到不同的结果（尽管第一个结果出现了几次）。在某些情况下，ChatGPT 建议设置 $X = Y = Z,$ 然后 $f(x,y|x = y ) = f_{X,Y}(z,z)=\frac{1}{2\pi}e^{-z^2}$ 作为联合 pdf。在不同的实例中，它发现 $f(x,y|x = y)=f_Z(z)=\delta{(x-y)},$ 其中 $\delta{()}$ 是 Dirac delta 函数，作为联合 pdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/636397/finding-joint-probability-distribution-of-standard-normal-with-constraints</guid>
      <pubDate>Mon, 08 Jan 2024 05:00:52 GMT</pubDate>
    </item>
    <item>
      <title>如果解存在，任何左逆都会给我们解之一？ [迁移]</title>
      <link>https://stats.stackexchange.com/questions/636396/if-solution-exits-any-left-inverse-give-us-one-of-solutions</link>
      <description><![CDATA[据我所知，对于问题 Ax=b，x=Bb 不可能是 B 是 A 的左逆的解。
但如果 Ax=b 存在解，我们能保证 x=Bb 是解之一吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636396/if-solution-exits-any-left-inverse-give-us-one-of-solutions</guid>
      <pubDate>Mon, 08 Jan 2024 04:10:12 GMT</pubDate>
    </item>
    <item>
      <title>随机样本的方差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636395/variance-of-a-random-sample</link>
      <description><![CDATA[
令 S^2 为大小为 𝑛 &gt; 的随机样本的方差1 来自具有未知均值 𝜇 和未知有限方差 𝜎2 &lt; 的正态总体无穷大。考虑以下陈述： (I) S^2 是 𝜎^2 的无偏估计量，并且 𝑆 是 𝜎 的无偏估计量。 (II) (n-1/n) S2 是 𝜎2 的最大似然估计量，√(n-1/n)𝑆 是 𝜎 的最大似然估计量。
上述哪些说法是正确的？为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636395/variance-of-a-random-sample</guid>
      <pubDate>Mon, 08 Jan 2024 04:09:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 SE 上找到你想成为导师的人？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636393/how-to-approach-someone-you-want-to-be-your-mentor-here-on-se</link>
      <description><![CDATA[我提前道歉，这不是一个统计问题，但在 SE 上点击这里一个多小时后，我找不到直接吸引用户的方法。
有没有合适的地方可以提出问题：
“你愿意做我的导师吗？”给特定的人？这不完全是我想要的公开讨论，它显然可能涉及交换联系信息。
再次，如果这是一个失礼行为，我深表歉意，我只是真诚地欣赏这个人的见解，想了解他们所学到的东西，并请求他们指导我如何进行自己的学习，因为我希望能够思考与他们类似。
提前感谢您提供任何提示或重定向。无意冒犯。
（P.S. - 我确实找到了这个 SE 群组的聊天室，但由于对话是公开且永久的，我不想将其用作起点）]]></description>
      <guid>https://stats.stackexchange.com/questions/636393/how-to-approach-someone-you-want-to-be-your-mentor-here-on-se</guid>
      <pubDate>Mon, 08 Jan 2024 03:45:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在Rstudio中将多列变量转换为虚拟变量？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636392/how-to-transform-multiple-columns-variables-into-dummy-variables-in-rstudio</link>
      <description><![CDATA[
我有以下变量 f_100_0_0 和 f_100_0_1。它们代表从总共 4 种颜色（1-红、2-绿、3-蓝和 4-白）中选择您最喜欢的两种颜色。在R中，如何将它们更改为右侧的虚拟变量，即代表4种颜色的4个虚拟变量。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636392/how-to-transform-multiple-columns-variables-into-dummy-variables-in-rstudio</guid>
      <pubDate>Mon, 08 Jan 2024 03:45:25 GMT</pubDate>
    </item>
    <item>
      <title>比较具有主效应和交互作用的模型</title>
      <link>https://stats.stackexchange.com/questions/636391/comparing-models-with-main-effects-and-interactions</link>
      <description><![CDATA[我有两个模型：

模型1：仅包含自变量$x$，而$x$不显着.
模型 2：包含 $x$、$m$ 和 $x * m$，并且 $x * m$ 很重要。

我该如何说明这个结果？我还能说 $m$ 有调节作用吗？如果是这样，我如何确定 $m$ 效果的方向？]]></description>
      <guid>https://stats.stackexchange.com/questions/636391/comparing-models-with-main-effects-and-interactions</guid>
      <pubDate>Mon, 08 Jan 2024 03:39:22 GMT</pubDate>
    </item>
    <item>
      <title>不正确的统计假设如何影响估计？</title>
      <link>https://stats.stackexchange.com/questions/636389/how-do-incorrect-statistical-assumptions-affect-estimation</link>
      <description><![CDATA[作为一个学习示例，我试图了解当错误指定错误分布时，统计分析会受到怎样的不利影响。具体来说，我试图了解当随机过程被错误地建模为非随机过程（即我错误地将其视为独立同分布）时会发生什么 - 这会变得多么糟糕？
以下是我考虑过的一些具体情况：

连续随机变量：假设我从非独立同分布过程（例如随机游走、布朗运动或 AR（自回归过程））观察到 $n$ 点）。想象一下，我天真且错误地假设这些 $n$ 点确实来自 i.i.d 随机变量（我想估计此数据的均值和方差）

离散随机变量（基本上是马尔可夫链）：假设我翻转硬币 $n$ 次，其中当前翻转获得正面的概率取决于之前的翻转。如果上一次翻转是正面，则下一次翻转出现正面的概率为 $p_1$（并且 1-$p_1 $ 下一次翻转出现反面的概率）。如果上一次翻转是反面，则下一次翻转出现反面的概率为 $p_2$（并且 1 - $ p_2$ 下一次翻转正面朝上的概率）。想象一下，我相信这枚硬币是独立同分布的（我想估计获得正面的一般概率及其方差）

离散随机变量（基本上是隐马尔可夫模型，EM/潜在变量情况）：假设现在有两个硬币。对于 Coin1，如果前一次翻转是正面且 $p_2$，则正面的概率为 $p_1$如果前一次翻转是反面，则出现反面的概率。对于 Coin2，如果前一次翻转是正面且 $p_4$，则正面的概率为 $p_3$如果前一次翻转是反面，则出现反面的概率。如果选择了 Coin1，则下一次翻转时我再次选择 Coin1 的概率为 $p_5$（1- $p_5$  我选择 Coin2 的概率） - 如果选择了 Coin2，则我再次选择 Coin2 的概率为 $p_6$ （以及 1 - $p_6$ 我选择 Coin1 的概率）。我玩这个游戏 $n$ 次，并且有一个由头和尾组成的长度 $n$ 的序列，但我不知道每次翻转是哪些硬币产生的。想象一下，我相信只有一枚硬币，并且这枚硬币也是独立同分布的。 （因为我只相信有 1 个硬币，所以我想估计获得正面的一般概率及其方差）


在这些类型的情况下（假设我顽固地坚持对这些问题的错误信念），我有兴趣知道：

我对情况的错误了解会影响对参数估计进行的统计推断，代价有多大？ （例如：$p_1$ 与 $\hat{p_1}$，Var($p_1$) 与 Var($\hat{p_1}$) .... 将不正确的估计值与实际参数值进行比较正确的数据生成过程）
统计推断的哪些部分会不正确？例如，也许均值估计可能几乎是正确的，但方差估计将明显不正确，也许参数估计将不再具有渐近正态分布，参数估计将需要更多样本才能收敛到真实值，或者根本不会收敛到其真实值概率的真实值（一致性）等。
哪些统计定理将不再适用于这些情况？例如，也许中心极限定理或大数定律在这些情况下不太相关，等等。

目前，我正在尝试设计一些统计模拟（使用 R Studio）来模拟此类情况，然后我可以根据具体情况了解我对情况的错误了解将带来多大的代价。 ..我的推论将受到多么严重的影响。
但我想知道是否有一些数学/统计方法可以抽象地分析这些情况？
PS：（我花了一整天的时间记录在存在相关错误/非恒定方差的情况下错误地坚持标准 OLS 如何影响参数估计......如果有人有兴趣查看它们，我可以发布这些注释） ]]></description>
      <guid>https://stats.stackexchange.com/questions/636389/how-do-incorrect-statistical-assumptions-affect-estimation</guid>
      <pubDate>Mon, 08 Jan 2024 02:21:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在非正态右偏分布的数据中获得最佳机器学习模型？</title>
      <link>https://stats.stackexchange.com/questions/636388/how-to-get-best-ml-model-in-data-with-not-normal-right-skewed-distribution</link>
      <description><![CDATA[我正在处理少量数据：https://github。 com/jeffheaton/data/blob/master/bupa.csv 我想预测 y 数据，即饮料，其具有非正态右偏分布。有一个分布和 kdeplot

在几乎每个回归模型中，这些数据都存在拟合问题。如何处理这种分布的数据？如何为他们制作最好的模型？
我只是想拥有最好的身材。有两种看起来很糟糕的性能模型：

]]></description>
      <guid>https://stats.stackexchange.com/questions/636388/how-to-get-best-ml-model-in-data-with-not-normal-right-skewed-distribution</guid>
      <pubDate>Mon, 08 Jan 2024 02:05:26 GMT</pubDate>
    </item>
    <item>
      <title>如果您只知道事后结果，请计算方差分析 F</title>
      <link>https://stats.stackexchange.com/questions/636387/compute-anova-f-if-you-only-know-post-hoc-results</link>
      <description><![CDATA[阅读一篇科学文章，其中作者执行方差分析，然后进行事后 t 检验，但根本不报告方差分析的结果，而是直接跳到帖子的结果，这种情况并不罕见- 临时 t 检验。假设报告了所有事后事件，读者是否可以通过任何方式反算方差分析的结果？为简单起见，我们假设它是 2 路方差分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/636387/compute-anova-f-if-you-only-know-post-hoc-results</guid>
      <pubDate>Mon, 08 Jan 2024 01:38:19 GMT</pubDate>
    </item>
    <item>
      <title>离散分布的概率密度函数，其行为类似于高斯分布，但有界</title>
      <link>https://stats.stackexchange.com/questions/636386/probability-density-function-for-discrete-distribution-that-behaves-like-a-gauss</link>
      <description><![CDATA[这篇文章准确地描述了我关心的情况，但由于某种原因被认为不够明确定义。作为一名非统计学家，这对我来说似乎定义得很好，但让我提供一个具体的例子，也许这将有助于确定一个好的解决方案。
我想要一个 0 到 255 之间采样像素值的概率密度函数。我可以只维护每个值的频率列表，但如果我要使用 16 或 24 位的像素密度，则比这个变得有问题。如果我们假设这些像素值服从正态分布，那么我们可以使用函数并大大减少近似曲线所需的信息量。然而，这个函数的范围是 0 到 255，或者说是 0 到 2^num_bits。它也是离散的，因此我不清楚如何应用高斯分布。
那么，是否存在类似于离散值高斯分布且具有有界域的函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/636386/probability-density-function-for-discrete-distribution-that-behaves-like-a-gauss</guid>
      <pubDate>Mon, 08 Jan 2024 00:37:57 GMT</pubDate>
    </item>
    <item>
      <title>似然比渐近分布的局部线性与正则性条件</title>
      <link>https://stats.stackexchange.com/questions/636384/local-linearity-vs-regularity-conditions-for-the-asymptotic-distribution-of-the</link>
      <description><![CDATA[Aad van der Vaart 在他的《渐近统计》一书中，在讨论对数似然比的渐近分布时说道：
“本章最重要的结论是，在原假设下，序列Λ（对数似然比）是渐近卡方分布的。主要条件是模型在 θ 上可微，并且零假设和完整参数集（局部）等于线性空间。”
然后后者说“假设的局部线性对于卡方近似至关重要”。
我之前看到的推导要求该属性满足通常的正则条件。正则条件没有提到局部线性，所以我现在很困惑。它们是等价的还是局部线性会自动满足这些规律性条件？
[]]></description>
      <guid>https://stats.stackexchange.com/questions/636384/local-linearity-vs-regularity-conditions-for-the-asymptotic-distribution-of-the</guid>
      <pubDate>Sun, 07 Jan 2024 23:18:57 GMT</pubDate>
    </item>
    <item>
      <title>如何高效求泊松分布的四阶矩？</title>
      <link>https://stats.stackexchange.com/questions/636379/how-to-efficiently-find-the-fourth-moment-of-a-poisson-distribution</link>
      <description><![CDATA[假设我们有 $X\sim \textrm{Poisson}(\lambda)$ 并且我们知道矩生成函数 $M(t)=\mathbb{E}(​​e^{tX})$。我们如何使用矩生成函数属性 $M^k(0)=\mathbb{E}(​​X^k)$ 来导出，比方说，$\mathbb{E}(​​X^4)$?对我来说，对矩生成函数进行微分似乎极其乏味。有没有更快的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/636379/how-to-efficiently-find-the-fourth-moment-of-a-poisson-distribution</guid>
      <pubDate>Sun, 07 Jan 2024 20:59:10 GMT</pubDate>
    </item>
    <item>
      <title>选择贝叶斯先验[重复]</title>
      <link>https://stats.stackexchange.com/questions/636374/choosing-bayesian-priors</link>
      <description><![CDATA[我对贝叶斯建模相当陌生，但是我正在尝试使用这样的框架以产生一些估计。
我最困难的部分是模型参数先验分布的选择。在我读到的有关贝叶斯建模的所有内容中，选择此类分布对我来说似乎有些武断。
是否有正式定义的程序来选择不受建模者直接影响的先验分布？我不明白应该根据一种分布而不是另一种分布来分布特定参数。做出选择时是否需要考虑任何特定因素？
谢谢你，
马可]]></description>
      <guid>https://stats.stackexchange.com/questions/636374/choosing-bayesian-priors</guid>
      <pubDate>Sun, 07 Jan 2024 19:16:33 GMT</pubDate>
    </item>
    <item>
      <title>特征工程-词嵌入[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636372/feature-engineering-word-embedding</link>
      <description><![CDATA[如何从 Word2vec 嵌入向量中选择特征？我可以选择一些有助于我完成特定任务的功能吗？我可以添加一些功能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636372/feature-engineering-word-embedding</guid>
      <pubDate>Sun, 07 Jan 2024 19:01:48 GMT</pubDate>
    </item>
    </channel>
</rss>