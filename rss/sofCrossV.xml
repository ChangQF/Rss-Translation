<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 05 May 2024 18:16:45 GMT</lastBuildDate>
    <item>
      <title>如何估计时间序列干预模型的参数</title>
      <link>https://stats.stackexchange.com/questions/646562/how-to-estimate-the-parameters-of-an-intervention-model-for-time-series</link>
      <description><![CDATA[如果我们考虑一次简单的干预：
$$Y_t=m_t+N_t$$
其中 $m_t$ 是均值函数的变化，$N_t$ 被建模为某些 ARIMA 过程，可能是季节性的。
我一直在试图找到如何估计干预部分的参数，但我发现的只是以下内容
&lt;块引用&gt;
干预模型参数的估计可以由
最大似然估计方法。事实上，Y t − m t 是季节性 ARIMA 亲
使似然函数等于 Y t − m t , t = 1, 2,…, n 的联合 pdf，其中
可以通过第 7 章中研究的方法计算

我还是不太清楚。谁能给我推荐一本详细解释如何估计干预模型参数的书？]]></description>
      <guid>https://stats.stackexchange.com/questions/646562/how-to-estimate-the-parameters-of-an-intervention-model-for-time-series</guid>
      <pubDate>Sun, 05 May 2024 18:01:15 GMT</pubDate>
    </item>
    <item>
      <title>构造“更正常”的随机变量的变换</title>
      <link>https://stats.stackexchange.com/questions/646561/construct-transformations-of-random-variables-that-are-more-normal</link>
      <description><![CDATA[我正在阅读数学百科全书中关于随机变量变换的此页面。&lt; /p&gt;
我对示例 2 感到困惑：
&lt;块引用&gt;
设 $X_1,...,X_n,...$ 为独立随机变量，每个变量在 [−1,1] 上均匀分布，并且放
$$Z_n=\frac{X_1+\cdots+X_n}{\sqrt{n/3}}.$$
由中心极限定理，
$$𝖯\{Z_n
如果一套
$$ V_n=Z_n−\frac{1}{20n}(3Z_n−Z_n^3), $$
然后
$$𝖯\{V_n

他们如何获得费率 $O(1/n)$ 和 $O(1/n^2 )$?
我在此页面中找到关于中心极限定理的以下结果：
&lt;块引用&gt;
...这个结果以某种更强的形式断言
$$ F_n(x)−\Phi(x)= \frac{e^{-x^2/2}}{\sqrt{2\pi}}\left(\分形{Q_1(x)}{\sqrt{n}}+\cdots+\frac{Q_{s-2}(x)}{n^{(s−2)/2}}
+o\left(\frac{1}{n^{(s−2)/2}}\right)\right), $$
均匀地在 x 中。这种渐近展开式是构建广泛的随机变量变换的基础。

这对于获取费率有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646561/construct-transformations-of-random-variables-that-are-more-normal</guid>
      <pubDate>Sun, 05 May 2024 17:57:10 GMT</pubDate>
    </item>
    <item>
      <title>用于表达因果关系的嵌套积分的蒙特卡罗估计</title>
      <link>https://stats.stackexchange.com/questions/646560/monte-carlo-estimation-of-nested-integral-used-to-express-cause-effect-relations</link>
      <description><![CDATA[我有这个积分：
$$ \mathbb{E} [ Y \mid \text{do}(Z=z)] = \int_{B, S, W, X} P(B | S) P(W | B, S) P(X | B, S, Z) \left[ \int_{Z} P(S) P(Y | B, S, W, X, Z=z) P (Z=z| S) \右]
$$
我正在尝试从样本中估计。
在我提问之前需要提供一些详细信息：

我们感兴趣的是干预 $Z$ 对 $Y$ 的因果影响。&lt; /里&gt;
积分中的变量可以在因果图上找到
积分中的密度估计变量之间的统计关系，它们是根据联合样本估计的
由于我们正在干预，$P(Z|S)$ 自然会简化为 $Z$关于 $Z$

我很困惑。我应该如何近似这个期望。
唉，这是我的直觉。首先，我准备了大小为 $N$ 的数据集 $\mathcal{D}$ 用于拟合积分中的密度。

从内部积分开始，我将采样一个新的 $s&#39; \sim P(S)$，然后使用该新 $P(Y=y|B=b,S=s&#39;,W=w,X=x,Z=z)$ 中的示例 - 这里的相等只是意味着我将该变量设置为已收集的数据集中的样本 $\mathcal{D}$，除了 $Z$&lt; /span&gt; 采用固定干预值 $z$。
然后我继续进行外积分，并在密度中使用我的新值 $S&#39;$：$P( B=b | S=s&#39;) P(W=w | B=b, S=s&#39;) P(X=x | B=b, S=s&#39;, Z=z)$ , $z$ 是 $Z$ 的干预水平。

或者我只是在 $\mathcal{D}$ 中使用我已经观察到的样本，将它们与 $ 一起插入Z=z$，然后只取最后的平均值来得到期望？这就是我困惑的根源。我将在这里完成一些其他工作，但我发现也很奇怪，我应该在 $\mathcal{D}$ 中重新使用我的样本，用于适应首先计算密度，以估计期望。
如果所有这些都是错误的，假设密度已经适合数据集$\mathcal{D}，您将如何估计这个积分 $？]]></description>
      <guid>https://stats.stackexchange.com/questions/646560/monte-carlo-estimation-of-nested-integral-used-to-express-cause-effect-relations</guid>
      <pubDate>Sun, 05 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>关于为 WLS 选择权重的非常基本的问题</title>
      <link>https://stats.stackexchange.com/questions/646559/very-basic-questions-about-choosing-weights-for-wls</link>
      <description><![CDATA[大家好，我是统计学和机器学习的新手（虽然有丰富的数学经验，但我并不是一个寻求家庭作业帮助的学生，我 58 岁，懂很多数学，并且希望扩展我的技能）。我对 Ames 住房数据集的一些连续值列进行了简单线性回归 (OLS)。（我知道我需要学习如何在某个时候合并分类数据）。我检查了结果模型的异方差，残差中肯定存在模式，特别是随着拟合值的增加，它们会变得更高。
  
所以我正在尝试使用 WLS 模型，但我无法分配权重。我有一个很好的资源展示了一些例子，但只针对一个预测因子，而我使用了大约 10 个预测因子。该示例取拟合数据的倒数并将其用作权重，但仅适用于单个预测因子。我当然不能将该值用作所有预测因子的权重，对吧？我认为权重完全相同的 WLS 模型就像 OLS 模型，尽管我可能完全错了。
 
有人能给我指出任何好的指导方针或以前的答案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646559/very-basic-questions-about-choosing-weights-for-wls</guid>
      <pubDate>Sun, 05 May 2024 16:50:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 Fischer 精确测试评估盲法</title>
      <link>https://stats.stackexchange.com/questions/646553/evaluate-blinding-using-fischers-exact-test</link>
      <description><![CDATA[在临床试验中，有A、B、B 3组。 C，但参与者只有 2 项干预措施是不知情的。 A组均得到积极治疗，B、B组均得到积极治疗。 C 服用安慰剂。试验结束时，参与者被问及他们得到了什么干预措施。这将创建一个 2x3 列联表，如下所示：
猜A: B: C:
主动：a、b、c
安慰剂：d、e、f

我可以运行 2x3 Fisher 精确检验或此表。
或者我可以创建一个 2x2 表，其中对 B 列和 C 列进行求和，然后对此表运行 Fisher 精确检验。这两个表产生不同的结果。
如果我想知道各组参与者猜测自己手臂的能力是否存在显着差异，正确的方法是什么？两种不同的测试回答了哪些不同的假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/646553/evaluate-blinding-using-fischers-exact-test</guid>
      <pubDate>Sun, 05 May 2024 15:35:37 GMT</pubDate>
    </item>
    <item>
      <title>即使没有高斯误差，OLS 渐近也是最好的估计吗？</title>
      <link>https://stats.stackexchange.com/questions/646549/is-ols-asymptotically-the-best-estimator-even-without-gaussian-error</link>
      <description><![CDATA[据了解

MLE 是一致的且渐近有效的。
OLS 在某些假设下是渐近正态的。
如果误差为高斯分布，则 OLS 等效于 MLE。
如果误差为均值 0 且方差恒定的高斯误差，则 OLS 为 UMVU。
如果误差不是高斯分布且在某些假设下，OLS 为蓝色。

鉴于上述事实，我想知道以下陈述是否正确。

根据 (2) 和 (4)，即使误差不是高斯分布，OLS 也是渐近 UMVU，并且如下
这样，最好的估计器。

通过 (2) 和 (3) OLS 渐近与 MLE 相同，因此通过 (1) 渐近
高效且渐近一致。


我试图查书，但找不到这些说法，我想知道它们是否正确。请问有什么帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646549/is-ols-asymptotically-the-best-estimator-even-without-gaussian-error</guid>
      <pubDate>Sun, 05 May 2024 14:39:04 GMT</pubDate>
    </item>
    <item>
      <title>使用小鼠和 WeightIt 后如何获取加权组平均值和标准误差？</title>
      <link>https://stats.stackexchange.com/questions/646546/how-to-access-weighted-group-means-and-standard-errors-after-using-mice-and-weig</link>
      <description><![CDATA[一些背景：我对两组人的数据进行了估算和加权，一组在某个组织中，另一组在该组织之外。最终，我想比较他们在接下来的一年中如何发展心理特征 X，具体取决于他们是否是组织的一部分（到目前为止，我只有 X 的基线值）。但现在，我想知道另一件事。
我根据协变量“年龄”、“健康状况”对各组进行了平衡。和“教育”。我想看看 A 组和 B 组在 Trait_X 方面是否在开始时存在显着差异，因为其余变量是平衡的。所以我想查看每组的加权平均值和标准误差。我尝试了这段代码，最后两行不起作用，我不知道为什么：
# 权重估算数据集
加权数据集 &lt;- 权重（组〜年龄+教育+健身，
                                导入数据，
                                方法=“内部”，
                                估计量＝“ATT”，
                                方法 = &#39;glm&#39;)
bal.tab(加权.数据集, un = TRUE)
摘要（加权.数据集）
# 平衡性看起来非常好
# 现在我尝试找出方法和方法
model1 &lt;- with(weighted.datasets, lm_weightit(trait_X ~ group * (age+education+fitness),family = Linear))
avg_comparisons(model1, 变量 = “组”, newdata = 子集(组 == 1))
&gt;错误：找不到对象“组”
avg_predictions(model1, 变量 = “组”, newdata = 子集(组 == 1))
&gt;错误：找不到对象“组”

我认为问题可能是 avg_comparisons() 无法处理多个数据集？ “组” 确实存在于wimids对象深处的某个地方，位于weighted.datasets[[“object”]][[“data”]][[“group”]]，但我不能找出引用它的正确语法。我可能找到了一种解决方法，可以显示平均差异，但不能显示每个组的平均值和标准误差。老实说，我认为这不是一个合适的解决方案：
model2 &lt;- with(weighted.datasets, lm_weightit(trait_X ~ group, family = Linear))
结果 &lt;- 池（模型）

&gt;结果
等级：mipo m = 5
           项 m 估计 ubar b t dfcom df riv lambda fmi
1（截距）5 3.1886385 0.0003606696 1.534207e-05 0.0003790801 1349 729.9524 0.05104527 0.04856620 0.05116237
2 B组 5 0.1090137 0.0018477567 6.542353e-05 0.0019262649 1349 840.8954 0.04248841 0.04075672 0.04303009

任何人都可以帮我修复其中一个代码片段，以便我可以看到每组的加权平均值和标准误差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646546/how-to-access-weighted-group-means-and-standard-errors-after-using-mice-and-weig</guid>
      <pubDate>Sun, 05 May 2024 13:50:42 GMT</pubDate>
    </item>
    <item>
      <title>如何衡量焦虑水平（20-80分）与养育方式（专制、权威、宽容）之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/646545/how-to-measure-correlation-between-anxiety-level-score-20-80-and-parenting-sty</link>
      <description><![CDATA[正如标题所说，我想知道如何衡量焦虑水平和养育方式之间的相关性，因为一个是序数，另一个是分类。
斯皮尔曼相关法是正确的方法吗？如果没有，我应该使用什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646545/how-to-measure-correlation-between-anxiety-level-score-20-80-and-parenting-sty</guid>
      <pubDate>Sun, 05 May 2024 13:34:16 GMT</pubDate>
    </item>
    <item>
      <title>具有（稳健）Huber-White 标准误的最大似然估计适合异常值管理？</title>
      <link>https://stats.stackexchange.com/questions/646544/maximum-likelihood-estimation-with-robust-huber-white-standard-errors-appropri</link>
      <description><![CDATA[具有鲁棒 Huber-White 标准误差和缩放检验统计量（渐近等于 Yuan-Bentler 检验统计量）的最大似然估计是否适合具有大量异常值的数据？关于异常值，它的引导效果如何？
（我正在使用 lavaan 中 MLR 的实现 包）]]></description>
      <guid>https://stats.stackexchange.com/questions/646544/maximum-likelihood-estimation-with-robust-huber-white-standard-errors-appropri</guid>
      <pubDate>Sun, 05 May 2024 13:19:52 GMT</pubDate>
    </item>
    <item>
      <title>比较二元问题的答案比例</title>
      <link>https://stats.stackexchange.com/questions/646535/compare-proportions-of-answers-to-binary-questions</link>
      <description><![CDATA[我正在做一个实验，我以随机顺序向参与者询问三个二元问题（A、B 和 C）。这是一个主题内设计，因此每个人都会看到同一组问题。
问题 A 对应于基本情况。在问题 A 和 B 之间，我改变变量 1。在问题 A 和 C 之间，我改变变量 2。这两个变量都是二元的，问题 A、B 和 C 在参与者之间是相同的。
我想知道两件事：

是否考虑变量 1 和 2。
更考虑哪一个。

我想找到一个统计测试来根据参与者的答案来比较他们的比例。我想回答以下问题：

按问题计算正确/错误答案的比例并进行比较。
在对问题 A 做出正确回答的参与者中，从统计数据来看，其他所有问题都正确的参与者是否比答对 B 和 C 错误的参与者多......

我真的不知道应该使用什么统计测试来进行这样的比较。有人建议我在某个时候使用 logit 回归，但我不确定这是否是一个值得遵循的好提示，如果是的话，如何对我的数据进行编码以使用此测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/646535/compare-proportions-of-answers-to-binary-questions</guid>
      <pubDate>Sun, 05 May 2024 10:55:19 GMT</pubDate>
    </item>
    <item>
      <title>点双列与 Spearman 相关性</title>
      <link>https://stats.stackexchange.com/questions/646521/point-biserial-vs-spearman-correlation</link>
      <description><![CDATA[我正在使用来自 UCI 的 Spambase 数据集，该数据集也在 bayesreg R 包中（4601 个实例）。
目标是一个二进制文件，其类分布大约为 $60-40\%$
$(0/1)$。有 $57$ 左右的预测变量是最小-最大缩放的。预测变量严重右偏，因为它们是电子邮件中给定单词的频率，因此大多数实例自然会落向 $0$。
斯皮尔曼或点双列相关性是否是更合适的指标来快速查看哪些特征是不错的预测因子？据我了解，斯皮尔曼可以与连续和序数一起使用，而点双序列明确用于解释连续与序数。我知道我正在研究参数方法与非参数方法，但为什么参数方法似乎可以更好地解释非线性数据？
我真的不明白在这种情况下使用其中一种比另一种有什么好处。]]></description>
      <guid>https://stats.stackexchange.com/questions/646521/point-biserial-vs-spearman-correlation</guid>
      <pubDate>Sun, 05 May 2024 03:25:58 GMT</pubDate>
    </item>
    <item>
      <title>KNN K = 1 自身训练 vs K > 1</title>
      <link>https://stats.stackexchange.com/questions/646512/knn-k-1-training-on-itself-vs-k-1</link>
      <description><![CDATA[在训练 $KNN$ 算法时，为什么 $K = 1$ 时，模型使用“每个训练点最近的 1 个观测值”进行训练，并将其视为自身，导致训练误差为 $0$。而对于 $K = 2$，它会使用除自身之外的两个邻居。
似乎缺少对 1 个最近（实际）邻居进行训练的情况？为什么会这样，我们该如何描述它。
为了验证这一担忧，我附上了经典 ISL 教科书的屏幕截图。例如，一张图片显示 $K = 3$ 在 3 个实际邻居上进行训练，另一张图片提到 $K = 1$ 的训练误差为 $0$。谢谢！

]]></description>
      <guid>https://stats.stackexchange.com/questions/646512/knn-k-1-training-on-itself-vs-k-1</guid>
      <pubDate>Sat, 04 May 2024 21:14:48 GMT</pubDate>
    </item>
    <item>
      <title>如何检测短时间序列末尾的平稳状态？</title>
      <link>https://stats.stackexchange.com/questions/646494/how-to-detect-a-plateau-at-the-end-of-a-short-time-series</link>
      <description><![CDATA[在运动测试（螺旋测功法）中，参与者在进行逐渐加强的体育锻炼时，会连续测量他们的摄氧量。测量是定期进行的，例如每 10 秒一次。了解摄氧量在测量结束时是否达到稳定水平非常有用。我们正在谈论测试的最后一分钟左右。基本上，这取决于最终摄氧量是否仍在增加或是否趋于平缓。下图显示了三名参与者的测量结果。在左侧面板中，看不到平台。中间的面板显示出清晰的平台，而右侧的面板则有些模糊。

存在多种关于如何检测平稳状态的启发式方法。所有这些都有些武断，因为不存在基本事实或黄金标准。尽管如此，我想知道是否有一种原则性的方法来检测时间序列中的平稳状态。
我自己的想法如下：

使用 LOESS 平滑测量结果（上图中的黑色曲线）。如图所示，测量结果有些噪音。使用此处说明的过程选择平滑量。
如果预测平滑数据的最后一个 $x$（例如 6 个）测量值的标准差低于特定阈值，则检测到稳定状态。

我的想法是，小的标准偏差意味着测量值变化很小/大致恒定。这仍然引出了一个问题，即如何选择最后平滑测量的标准差阈值，低于该阈值则声明稳定。
我的问题：上面的算法有意义吗？如何改进？可以使用哪些其他算法/启发式方法来检测测量结束时的平稳状态？
我尝试过但效果不佳的事情：

计算平滑函数一阶导数的置信区间（例如使用 mgcv 和 gratia 包计算）。置信限度太大，几乎总是包含 $0$。
某种变化点检测。同样，不确定性太大，并且通常无法通过线性函数很好地近似轨迹。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646494/how-to-detect-a-plateau-at-the-end-of-a-short-time-series</guid>
      <pubDate>Sat, 04 May 2024 15:34:14 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算 Levene 检验</title>
      <link>https://stats.stackexchange.com/questions/646537/calculate-levene-test-in-r</link>
      <description><![CDATA[我正在尝试计算具有多种交互作用的 Levene 测试。
草食动物处理水平均匀度
NC 0.796
超低 0.780
古尔0.833
累积值 0.757
苏赫 0.819
古赫 0.820
CUH 0.882


install.packages(“汽车”)
图书馆（车）
levene_test &lt;- leveneTest(Eveness ~ 草食动物 * 治疗 * 级别，数据 = 数据)

但我得到了这个回应：
Levene 方差齐性检验（中心 = 中位数）
      Df F值Pr(＞F)
第 6 组 NaN NaN
       0

我查了资料。均匀度被视为一个数值。我使用提供的数据创建了一个框架，但遇到了同样的错误。
我使用 chatGPT 但它提供相同的代码。无法知道问题出在哪里......]]></description>
      <guid>https://stats.stackexchange.com/questions/646537/calculate-levene-test-in-r</guid>
      <pubDate>Sat, 04 May 2024 13:46:08 GMT</pubDate>
    </item>
    <item>
      <title>随机化实验运行以解决不可控因素</title>
      <link>https://stats.stackexchange.com/questions/646432/randomization-of-experiment-runs-to-account-for-uncontrollable-factors</link>
      <description><![CDATA[我正在进行一项实验，我怀疑有一个因素可能会影响结果，我无法控制也无法绝对测量（即，我可以检测样本之间的差异，但无法测量它，并且在操作环境中，您只得到 1 个样本）该因素（我们称之为因素 A），所以我希望随机化可以解决这个问题。但是，我在决定如何正确随机化实验（有 3 次重复和 8 次运行（总共 24 次））时遇到问题，我有 2 个选择：
1-每次重复使用不同的样本，但该重复中的所有运行都使用相同的样本（在这种情况下，我想我会将每个重复视为一个块）
2- 每次重复和每次运行使用不同的样本
我更喜欢选项 1，但是，我真的想不出反对选项 2 的有力论据，特别是因为我并不真正关心因素 A 的影响，所以我将感谢任何输入和任何不同的意见考虑哪个选项更好。]]></description>
      <guid>https://stats.stackexchange.com/questions/646432/randomization-of-experiment-runs-to-account-for-uncontrollable-factors</guid>
      <pubDate>Fri, 03 May 2024 13:58:17 GMT</pubDate>
    </item>
    </channel>
</rss>