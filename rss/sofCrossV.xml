<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 19 Mar 2024 21:11:45 GMT</lastBuildDate>
    <item>
      <title>如何指定一个具有多个治疗组的模型，在一段时间内重复测量两次（lme4）？</title>
      <link>https://stats.stackexchange.com/questions/643005/how-to-specify-a-model-with-multiple-treatment-groups-measured-twice-repeatedl</link>
      <description><![CDATA[我有 30 只动物（因子：animal_id，30 个级别），它们已接受过药物或媒介物治疗（因子：treatment，2 个级别）。然后使用两个传感器（技术重复）同时测量它们的活动（因子：sensor_id，2 个级别），每个传感器每天产生 1 个读数，持续 30 天（变量日期）。首先，date应该是一个因子还是一个数值变量？
还有一个更大的问题：如何使用 lme4 指定此设计？我的主要兴趣是估计两个治疗组之间的活动差异，但不同日期的值差异很大，因此我无法查看所有日期的总体效果，因此我的第一次尝试是：
 lmer(活动 ~ 治疗*日期 + (1|animal_id), data=data)

每个animal_id 对于每个日期 始终有两个activity 值，每个sensor_id 级别都有一个值。理想情况下，所有传感器应该相同，但预计它们之间的灵敏度会有一些随机差异，这些差异应该是恒定的，例如在所有测量中，动物 28 的传感器 1 将比动物 7 的传感器 2 稍微敏感一些。所以我不确定是否应该以某种方式添加 sensor_id 。我的第一个想法是将其嵌套在 animal_id 下，将随机效应项更改为 (1|animal_id/sensor_id)，即使每个传感器之间的差异是这样的，这是否有意义总是恒定的？我问，因为在我看来，每个传感器之间的差异是“固定的”，这是一个“随机”的差异。效应项。不过，我并不关心估计每个传感器之间的差异，我只是认为将其包含在模型中是有意义的，因为随着时间的推移，在每只动物的两个读数中，传感器 1 的读数始终与其他传感器更相似1 的读数比传感器 2 的读数高。
最后，无论治疗或animal_id如何，活动在几天内都会上升或下降。是否应该在模型中以某种方式指定这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/643005/how-to-specify-a-model-with-multiple-treatment-groups-measured-twice-repeatedl</guid>
      <pubDate>Tue, 19 Mar 2024 20:44:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit 学习回归</title>
      <link>https://stats.stackexchange.com/questions/643003/using-scikit-learn-regression</link>
      <description><![CDATA[我正在尝试使用如下所示的简单函数来学习scikit-learn回归：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np
从 sklearn.ensemble 导入 GradientBoostingRegressor、RandomForestRegressor
从 sklearn.gaussian_process 导入 GaussianProcessRegressor
从 sklearn.gaussian_process.kernels 导入 RBF
从 sklearn.metrics 导入mean_squared_error
从 sklearn.model_selection 导入 train_test_split
从 sklearn.multioutput 导入 MultiOutputRegressor
从 sklearn.neural_network 导入 MLPRegressor
从 sklearn.svm 导入 SVR


def func(x: np.ndarray):
    # x (N, 24), y (N, 2)
    x_mean = np.mean(x, 轴=1)
    a = np.sin(x_mean)
    b = np.cos(x_mean)
    y = np.array([a, b]).T
    返回y


np.随机.种子(0)
x = np.random.rand(1000, 24) * np.pi * 10
y = 函数(x)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

型号=[
    梯度提升回归器（），
    随机森林回归器(),
    高斯过程回归器(RBF()),
    MLPRegressor(max_iter=1000),
    支持向量机（），
]

plt.figure(figsize=(5, len(模型) * 3))

对于 i，枚举（模型）中的 base_model：
    名称 = 基础模型.__class__.__name__
    模型 = MultiOutputRegressor(base_model)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    mse = 均方误差(y_test, y_pred)

    x_mean = np.mean(x_test, 轴=1)
    plt.subplot(len(模型), 1, i + 1)
    标题 = f&quot;{名称}. MSE: {mse:.2e}”
    打印（标题）
    plt.标题（标题）
    plt.plot(x_mean, y_test[:, 0], “.”, label=“y_test[:, 0]”)
    plt.plot(x_mean, y_test[:, 1], “.”, label=“y_test[:, 1]”)
    plt.plot(x_mean, y_pred[:, 0], “.”, label=“y_pred[:, 0]”)
    plt.plot(x_mean, y_pred[:, 1], “.”, label=“y_pred[:, 1]”)
    plt.图例()

plt.tight_layout()
plt.savefig(“regression_test.png”)


但是结果并不好：

我认为我没有正确使用这些回归器。
我应该如何修改我的代码？
更新
通过减少 x 的暗度，我得到了一些好的结果：
我应该如何更改 GP 的代码以支持高亮度输入？
]]></description>
      <guid>https://stats.stackexchange.com/questions/643003/using-scikit-learn-regression</guid>
      <pubDate>Tue, 19 Mar 2024 20:12:39 GMT</pubDate>
    </item>
    <item>
      <title>集换式卡牌游戏pos</title>
      <link>https://stats.stackexchange.com/questions/643002/trading-card-game-poss</link>
      <description><![CDATA[一款名为“血肉之躯”的集换式卡牌游戏，由两名玩家构建一副 60 张牌，手牌限制为 4 张。玩家 2 的牌组颜色组合：牌组中有 60 张牌；玩家 2 的牌组颜色组合：牌组中有 60 张牌； 34 个是蓝色，17 个是红色，9 个是黄色。统计场景：玩家1生命值26点，手牌1张。玩家 2 手中有 4 张牌（3 张蓝色和 1 张黄色），桌上有 1 张牌（红色）面朝下。仅当玩家 2 的牌组顶牌为 (Y) 且玩家 1 手中的牌为 (X) 时，玩家 2 才能获胜：
X(P1)/Y(P2)：
红色/红色=胜利
红/黄=获胜
红/蓝=获胜
黄色/红色=失败
黄色/黄色=获胜
黄色/蓝色=胜利
蓝色/红色=失败
蓝色/黄色=失败
蓝色/蓝色=失败
获胜场景/总场景 = 5/9 或 55.6% 获胜。
我的问题是：当进行上述场景时，我是否需要添加玩家 2 牌组中剩余颜色的百分比？在这种情况下，玩家 2 的牌组有 45 张牌。其中 4 个（3 个蓝色和 1 个黄色）在手中，1 个（红色）在桌上，10 个在墓地（4 个红色、3 个黄色和 3 个蓝色）。玩家 2 为每个红色和黄色添加 -1，为每个蓝色添加 +1。结合手牌和坟墓场颜色计数，玩家 2 的二十一点计数将为 -3，显示出有轻微机会看到红色和黄色之上的蓝色。
34 蓝调/60 牌组大小 = 0.5667 或 56.67%，在游戏开始时将蓝色置于牌组顶部。 -1/+1 表示套牌中蓝调的总数，表明其差异为 +/-1.66%。当我的计数为 -3 时，我这样做：1.66x3= 4.98%。所以增加5%就可以看到上面有蓝色了
3 种蓝色组合中的 2 种，玩家 2 获胜，因此如果上面是蓝色，则有 67% 的机会获胜。我是否需要将 5% 添加到获胜概率中？
请告诉我这是否太令人困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/643002/trading-card-game-poss</guid>
      <pubDate>Tue, 19 Mar 2024 20:08:07 GMT</pubDate>
    </item>
    <item>
      <title>我想在 Jamovi 进行 Kruskal-Wallis 测试</title>
      <link>https://stats.stackexchange.com/questions/643000/i-would-like-to-perform-a-kruskal-wallis-test-in-jamovi</link>
      <description><![CDATA[我的问题是，我有性自信（7 点李克特量表，SAQ）和关系满意度（5 点李克特量表，RAS）的数据，但我想将性自信变量分为 3 组：低，中，高性自信，因为我的假设是具有较高性自信的人也具有较高的关系满意度。我认为这 3 个组可以用四分位数来完成，但我不知道如何实现这一点，以便在 Jamovi 进行 Kruskal-Wallis 测试。
感谢您提前的答复！]]></description>
      <guid>https://stats.stackexchange.com/questions/643000/i-would-like-to-perform-a-kruskal-wallis-test-in-jamovi</guid>
      <pubDate>Tue, 19 Mar 2024 19:40:31 GMT</pubDate>
    </item>
    <item>
      <title>断点回归设计，交错治疗分配</title>
      <link>https://stats.stackexchange.com/questions/642997/regression-discontinuity-design-staggered-treatment-allocation</link>
      <description><![CDATA[我不确定这个复杂的分配规则是否适合 RDD。我将获得交错推出治疗的数据，其中两年内将进行大约 10 轮服务（治疗）选择。我们拥有将在每一轮中更新的管理数据，用于对“分数 1”上的个人进行排名，将给定轮次中第 99 个百分位以上的人标记为有资格接受治疗，然后将符合条件的人按不同的“分数 2”排名;并为每轮选拔中的前 5 名人员提供服务。分数会发生变化，人们会在轮次之间加入和退出数据，但一旦进入治疗组，就不再考虑接受治疗。
为了构建反事实，我将根据每轮数据使用第 98 到 99 个百分位数，并执行与选择第 99 个以上百分位数相同的步骤，从而在十轮中生成治疗组。一旦分配到反事实，他们就不会被考虑再次分配到反事实，但如果他们的分数在未来几轮中发生变化，则必须转移到治疗。第一排名得分和第二排名得分是独立的（在$round_{t}$中选择$person_{i}$  沿着分数 1) 的分布看起来就像随机的一样好。在静态数据模拟中，经过 10 轮模拟选择后，我得到了一个很好的连续运行变量，用于滞后结果，生成 50 个选定的处理和 50 个对照，除以截止值。我将各轮选择的截止值标准化并合并，因为各轮的分数 1 上的截止值应略有变化。我将能够通过所有轮次的所有措施/状态的完整信息来回顾性地识别反事实案例。
典型的 RDD 是具有同期分配的横截面。我的想法似乎不寻常但合理（想法？），但我担心交错分配。特别是，第一轮中的某个人可能（或已经）被分配为该轮的 10 个反事实案例之一。然后，通过任何 $round_{t&gt;1}$，他们在分数 1 上的排名会随着时间的推移而增加，并且他们会“重新分配”到分数 1。进入治疗。这应该是少数人，所以我的计划是从潜在的反事实中排除所有曾经治疗过的人（回顾一下，我知道他们后来成为治疗病例），并在排除最终/的那些病例后，每轮定义第 98-99 个反事实资格组。曾经治疗过。
我是否通过将那些我知道稍后会加入治疗的反事实合格群体中的人排除在外而产生偏见（具体来说，因为已知他们的分数 1 稍后会增加）。他们实际上被下一个反事实人所取代。这有什么问题吗？有解决办法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642997/regression-discontinuity-design-staggered-treatment-allocation</guid>
      <pubDate>Tue, 19 Mar 2024 18:23:15 GMT</pubDate>
    </item>
    <item>
      <title>测试数据是否应该与训练数据唯一不同并且来自不同的源/数据集？</title>
      <link>https://stats.stackexchange.com/questions/642995/should-the-testing-data-be-uniquely-distinct-and-come-from-different-source-data</link>
      <description><![CDATA[我正在使用 CNN 构建音频分类系统。我的数据集由我录制的不同音频组成，并拼接为相同的时间长度。与任何其他常见的 ML 或 DL 任务一样，我要将数据集拆分为训练数据和测试数据，并评估我的模型。然而，我的教授说测试数据一定不能来自与训练数据相同的环境/来源。由于我录制了所有音频样本并将它们拼接并分割为训练和测试数据，因此它们本质上来自相同的环境。他基本上认为测试数据本质上必须是“在野外”。
但是，我对此的看法是，只要我的模型没有训练并且在模型拟合期间没有将测试数据作为输入，那么测试数据就被认为是“看不见的”和“野外的”。有人可以指出我正确的方向吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642995/should-the-testing-data-be-uniquely-distinct-and-come-from-different-source-data</guid>
      <pubDate>Tue, 19 Mar 2024 18:00:40 GMT</pubDate>
    </item>
    <item>
      <title>用优势比解释元回归表</title>
      <link>https://stats.stackexchange.com/questions/642994/interpreting-a-meta-regression-table-with-odds-ratios</link>
      <description><![CDATA[我的元回归解释需要一些帮助。效应大小基于优势比。
我在metafor包中使用了rma：
reg &lt;- rma(yi = es,
sei=se，
数据 = df,
方法=“ML”，
mods =〜组）
产生了这个表：
 b 参见 zval p ci.lb ci.ub
截距 -0.44 0.225 -1.955 0.051 -0.882 0.001
 （参考） -- -- -- -- -- --
  A -0.525 0.173 -3.037 0.002 -0.863 -0.186 **
  乙 -0.353 0.195 -1.808 0.071 -0.736 0.03


我想知道如何解释这个...
问题 1 = 这是否意味着与参考组相比，A 组的 OR 比参考组低 0.55，B 组的 OR 比参考组低 0.35？
问题 2 = 那么，A 组和 B 组是降低疾病发生率的干预措施...因此，我是否可以说，与参考组相比，A 组是与参考组相比最有效的干预措施。 A 组比 B 组有效 17.2%（两个值之间的差异）
我希望这是有道理的；提前谢谢了
〜R]]></description>
      <guid>https://stats.stackexchange.com/questions/642994/interpreting-a-meta-regression-table-with-odds-ratios</guid>
      <pubDate>Tue, 19 Mar 2024 17:59:43 GMT</pubDate>
    </item>
    <item>
      <title>相信图表还是使用 Breusch-Pagan 和 White 对大型数据集的同方差性检验？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/642992/trust-the-graphs-or-go-with-breusch-pagan-and-whites-tests-for-homoscedasticity</link>
      <description><![CDATA[我有一个大型数据集（n &gt; 500,000），我正在使用 lm(PV1READ ~ PV1MATH + PV1SCIE + ST004D01T) 构建线性模型。正态性、无多重共线性、独立性的检验看起来不错，但它总是在同方差性上出错。 Breusch-Pagan 测试 ols_test_breusch_pagan(mdl) 给出：
&lt;块引用&gt;
Chi2 = 930.8976，概率 &gt; Chi2 = 1.88444e-204

我在其他地方读到，B-P 测试在较大的数据集上效果不太好（我添加的观察值越多，p 值就会下降），但 White 的测试给出了类似的结果 white_test_boot(mdl)：
&lt;块引用&gt;
测试统计量：1053.69，P 值：0

我会把模型踢出去，但情节看起来很有希望，线条对我来说非常直接：

但是当我绘制学生化残差时，大量点是|残差| &gt; 2

&lt;块引用&gt;
总和(abs(stud_resids)&gt;2)/长度(stud_resids)

这相当于总体的约 5%，这看起来还不错。
我错过了什么吗？如果数据集足够大，我可以只使用图表而不是测试吗？我该如何报告？]]></description>
      <guid>https://stats.stackexchange.com/questions/642992/trust-the-graphs-or-go-with-breusch-pagan-and-whites-tests-for-homoscedasticity</guid>
      <pubDate>Tue, 19 Mar 2024 17:46:03 GMT</pubDate>
    </item>
    <item>
      <title>是否可以根据基尼系数和平均值计算标准差？</title>
      <link>https://stats.stackexchange.com/questions/642991/is-it-possible-to-calculate-a-standard-deviation-from-the-gini-coefficient-and-m</link>
      <description><![CDATA[我希望创建一项分析，显示特定国家/地区有多少人的收入超过 X 美元。
我知道平均收入、人口数量和收入差距的基尼系数。
是否可以用这三个数据点返回 X？
提前非常感谢您，抱歉这是一个愚蠢的问题。
-安德鲁]]></description>
      <guid>https://stats.stackexchange.com/questions/642991/is-it-possible-to-calculate-a-standard-deviation-from-the-gini-coefficient-and-m</guid>
      <pubDate>Tue, 19 Mar 2024 17:45:36 GMT</pubDate>
    </item>
    <item>
      <title>社区可以对我选择建模特征的方法提出批评吗？</title>
      <link>https://stats.stackexchange.com/questions/642990/could-the-community-provide-critiques-on-my-method-for-picking-features-for-mode</link>
      <description><![CDATA[我刚刚开始了一份新工作，它的统计数据比我以前的 DS 工作要重一些。在我以前的工作中，我主要从事抓取、描述性统计、可视化、仪表板等领域。所以我不得不抛弃旧的统计知识。
我获得了一些新数据，我的老板想知道它与我们现有模型的关系。一般来说（根据数据，我的方法存在一些变化）到目前为止，我正在做的是 1) 运行我设计的特征和感兴趣的结果变量之间的相关性 2) 运行一个饱和线性模型，其中包括所有预测变量相关系数达到 0.1 或更高 3) 为每个预测变量运行双变量线性模型 4) 计算每个双变量模型的 AIC。我创建了一个易于阅读的分数图表，其中某个特征在四个指标中的两个或多个指标上得分很高，我用覆盖有黄土曲线的散点图以及可能的基础数据的一些直方图或密度图来直观地检查数据。然后我提供了一个理论解释，解释为什么我们可能会看到我们现在的样子。
我没有尝试将新数据插入现有模型，因为这些模型是别人的宝贝，我不想踩到脚趾。我认为这为他成功地从他已经创建的内容中获得更高的准确性做好了准备。
希望你们能够就我还可以做什么或者我当前的方法存在哪些限制提供一些意见。
提前非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/642990/could-the-community-provide-critiques-on-my-method-for-picking-features-for-mode</guid>
      <pubDate>Tue, 19 Mar 2024 17:34:37 GMT</pubDate>
    </item>
    <item>
      <title>我在哪里可以使用遗传算法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/642989/where-can-i-use-genetic-algorithms</link>
      <description><![CDATA[我想为我的硕士学位算法课程制作一个项目。它们在哪些领域比传统算法有更好的应用？]]></description>
      <guid>https://stats.stackexchange.com/questions/642989/where-can-i-use-genetic-algorithms</guid>
      <pubDate>Tue, 19 Mar 2024 17:26:42 GMT</pubDate>
    </item>
    <item>
      <title>同一量表的重复测量的可靠性测试是什么？</title>
      <link>https://stats.stackexchange.com/questions/642987/what-test-of-reliability-for-repeated-measurements-of-the-same-scale</link>
      <description><![CDATA[我需要向您寻求帮助，了解使用什么方法来计算我在实验期间对同一受试者反复测量的量表的信度和效度。
让我解释一下：通常，当您想要测量构建的可靠性时，您会执行 EFA、CFA、Cronbach&#39;s alpha、复合可靠性、AVE 和 AVE 的平方根。显然，刚才所说的是一种简化，但我想澄清一下。但是，当仅对样品进行一次秤（且不超过一次）时，可以使用此程序。
我的情况如下：我管理了一个熟悉度量表，其中包含 6 个品牌的 4 个项目（熟悉度是指受试者对每个品牌的了解程度）。因此，相同的量表进行了 6 次。在这 6 个品牌中，选择 3 个是因为不熟悉（即熟悉度低），而选择另外 3 个是因为众所周知/熟悉（即熟悉度高）。学生的 t 检验证实，这两组品牌（高熟悉度和低熟悉度）在统计上存在差异。
我问你：我应该使用什么样的可靠性测试（即结构的内部一致性）来衡量熟悉度量表的可靠性？事实上，这个量表测量了 6 次，即 4（项目）x 6（品牌），总共 24 个项目。
感谢您的关注。]]></description>
      <guid>https://stats.stackexchange.com/questions/642987/what-test-of-reliability-for-repeated-measurements-of-the-same-scale</guid>
      <pubDate>Tue, 19 Mar 2024 17:13:25 GMT</pubDate>
    </item>
    <item>
      <title>模拟 ARMA 数据的 SARIMAX 参数估计令人困惑</title>
      <link>https://stats.stackexchange.com/questions/642986/confusing-sarimax-parameter-estimates-from-simulated-arma-data</link>
      <description><![CDATA[我一直致力于在 Python 中模拟 ARMA（自回归移动平均）时间序列数据，并使用 statsmodels 包中的 SARIMAX 类拟合 ARIMA 模型。然而，我在参数估计中遇到了一些令人费解的结果，更具体地说，当在我的数据生成过程中包含 MA 组件时，我得到 $\hat{c} = 0.002, \hat{ \theta_{1}} = 0.261，\hat{\theta_2} = -0.069$ 而实际上 $c = 0.002，\theta_{1} = 0.3，\ theta_2 = -0.1$（即使我有 80,000 个观察值）。
我认为可以公平地假设 SARIMAX 已正确实现，但同时我在模拟中没有看到错误。我希望也许有人能发现我的错误。
下面是我生成 ARMA 数据和拟合模型的实现：
将 numpy 导入为 np
从 statsmodels.tsa.statespace.sarimax 导入 SARIMAX

defgenerate_arma_data（截距，ar_coefficients，ma_coefficients，std_eps，n_periods）：

    # 供以后使用：ARMA(p, q)
    p = len(ar_系数)
    q = len(ma_系数)

    # 生成以 0 为中心的正态误差，并指定标准误差
    eps = np.random.normal(loc=0, 尺度=std_eps, 大小=n_periods+max(p, q))

    # 初始化
    模拟数据 = [0] * 最大值(p, q)

    # 迭代生成序列
    对于范围内的 t(max(p, q), len(eps))：
        # 对于每个 AR 系数，我们将其与滞后数据相乘并求和以获得 AR 贡献
        ar_component = sum(ar_coefficients[j] * Simulated_data[t-j-1] for j in range(p))
        # 对于每个 MA 系数，我们将其与滞后误差和总和相乘以获得 MA 贡献
        ma_component = sum(ma_coefficients[j] * eps[t-j-1] for j in range(q))
        # 最后添加截距或常量并添加当前时间步长的误差
        数据点 = 截距 + ar_component + ma_component + eps[t]
        Simulated_data.append(数据点)

    返回模拟数据[-n_periods::]

# 初始化
Intercept = 0.002 # ARMA 规范中的常量
std_eps = 0.001 # 误差的标准偏差
n_periods = 80000 # 样本中的观察数
ma_coefs = [0.3, -0.1] # MA 项的系数

# 生成数据
data_ma_2 =generate_arma_data（截距，[]，ma_coefs，std_eps，n_periods）

# 拟合模型
模型 = SARIMAX(data_ma_2, 顺序=(0, 0, 2), 季节性_顺序=(0, 0, 0, 0), 趋势=&#39;c&#39;)
results_ma = model.fit()

# 显示结果
print(results_ma.summary()) # 产生糟糕的参数估计 (c, ma.L1, ma.L2) = (0.002, 0.261, -0.069)
]]></description>
      <guid>https://stats.stackexchange.com/questions/642986/confusing-sarimax-parameter-estimates-from-simulated-arma-data</guid>
      <pubDate>Tue, 19 Mar 2024 17:10:27 GMT</pubDate>
    </item>
    <item>
      <title>寻找伯努利 GLMM（随机截距）的协方差结构</title>
      <link>https://stats.stackexchange.com/questions/642985/finding-covariance-structure-for-bernoulli-glmm-random-intercept</link>
      <description><![CDATA[如何从理论上找到伯努利 GLM 的协方差结构？
对于普通 LMM ($y_{ik} = x_i^T\beta + \epsilon_i + u_k$) 来说，这是非常简单的。对于同一组内的观察，我们可以计算
$$ cov(y_{ik},y_{jk}) = cov(x_i^T\beta + \epsilon_i + u_k, x_j^T\beta + \epsilon_j + u_k) = cov(\epsilon_i + u_k, \epsilon_j + u_k) \\ = cov(\epsilon_i, \epsilon_j) + cov(\epsilon_i , u_k) + cov(u_k, \epsilon_j) + cov(u_k,u_k) = \sigma_u^ 2$$
同样，对于不同组的观察，我们可以发现协方差为 0。
但如何计算伯努利 GLM 的值呢？比如说，用logit链接功能？
$$ logit(\mu_{ik})=x_i^T\beta + u_k \Rightarrow \mu_{ik} = \sigma(x_i^T\beta + u_k) $$
有没有办法计算$cov(y_{ik},y_{jk})$？向链接函数添加随机截距是否会影响协方差结构，或者我们是否还必须添加关于协方差结构的额外假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/642985/finding-covariance-structure-for-bernoulli-glmm-random-intercept</guid>
      <pubDate>Tue, 19 Mar 2024 17:05:36 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布的长期平均成本</title>
      <link>https://stats.stackexchange.com/questions/642984/long-run-average-cost-for-uniform-distribution</link>
      <description><![CDATA[设备的寿命是一个连续随机变量，具有连续均匀分布$\mathrm{Unif}(0,15)$。假设根据年龄更换策略，计划在 $T=12$ 年龄进行更换的费用为 300 美元，而在 $X  花费 350 美元。确定单位时间的长期平均成本
到目前为止我的尝试：对于 $\mathrm{Unif}(0,15)$ 我们有 $f( x) = \frac{1}{15}$ 对于 $0 \leq x \leq 15$ 等等 $P(X&lt;12) = \int_{0}^{12} \frac{1}{15} \,dx = \frac{12}{15}$
长期平均成本 = $P(X&lt;12)\cdot$（T 之前的成本）+  $(1-P(X&lt;12))\cdot$（T 时的成本）= $\frac{4}{5}\cdot300 + \frac{1 {5}\cdot350 = 340$
如果我这样做正确，请告诉我，如果我错了，请随时纠正我]]></description>
      <guid>https://stats.stackexchange.com/questions/642984/long-run-average-cost-for-uniform-distribution</guid>
      <pubDate>Tue, 19 Mar 2024 17:05:10 GMT</pubDate>
    </item>
    </channel>
</rss>