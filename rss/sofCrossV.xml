<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 23 Mar 2025 18:22:08 GMT</lastBuildDate>
    <item>
      <title>测试固定效应在GLMM中的重要性：III型WALD卡方测试与LRT</title>
      <link>https://stats.stackexchange.com/questions/663032/testing-the-significance-of-fixed-effects-in-glmm-type-iii-wald-chi-square-test</link>
      <description><![CDATA[我想知道测试R中固定效应的重要性的最佳方法（具有逻辑链接功能；二进制结果，2个固定效应，1个随机效应）。
我的高级目的是计算概念上类似于f值，p值和效应大小的统计数据。 
首先，我从GLMM FAQ中阅读了这些建议，但我不理解排名背后的理由 - 尤其是在前两个选项中，我重点关注的是：

 效果测试（即测试几个参数同时为零），从最差到最佳： 
 Wald Chi-square测试（例如CAR :: ANOVA）
似然比测试（通过ANOVA或Drop1）
对于可以计算DF的平衡，嵌套的LMM：条件
F检验
对于LMMS：带有DF校正的条件F检验（例如Kenward-Roger
在pbkrtest软件包中：请参见下面的K-R等上的注释。
 mcmc或parametric或非参数，引导性比较
（必须仔细实施非参数启动以说明
对于分组因素）
来源：
 https://bbolker.github.io/mixedmodels-misc/glmmfaq.html#hat-what-are-are-the-pare-p--values-listed-by-summaryglmerfit-eetc.--are-are-are-are-are-are-are-are-able可靠   

我的模型定义为：
 模型＆lt;  -  glmer（结果〜条件〜条件b +（1 |主题），data = mydata，family = binomial）
 
 选项1：  car :: anova（型号，type = 3） 
为条件，条件B和两者之间的相互作用提供卡方和p值。
这为我提供了以下每种情况的卡方，DF和p值：条件，条件B和条件：条件B（互动）。
 选项2：将模型重新定义为嵌套
  model_0＆lt;  -  glmer（结果〜1 +（1 |主题），data = mydata，family = binomial）
model_1a＆lt;  -  glmer（结果〜条件 +（1 |主题），data = mydata，family =二项式）
model_1b＆lt;  -  glmer（结果〜条件b +（1 |主题），data = mydata，family = binorial）
model_2＆lt;  -  glmer（结果〜条件*条件b +（1 |主题），data = mydata，family = binomial）
 
然后运行似然比测试（LRT）：
条件a
 ANOVA（model_0，model1a）
条件b
 ANOVA（Model_0，model1b）
对于条件：条件B（相互作用）：
 ANOVA（Model_0，model2）
 ANOVA（model_1a，model2）
 ANOVA（model_1b，model2） 
最后，我可以根据几率比率计算效应大小：
来源： glmm中的效果大小  
为了简单性和解释性，我更喜欢选项1。对于选项2，有人可以建议如何报告交互作用吗？这些方差分析设置是否有意义？
我感谢有关这两种选择的其他任何反馈，非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/663032/testing-the-significance-of-fixed-effects-in-glmm-type-iii-wald-chi-square-test</guid>
      <pubDate>Sun, 23 Mar 2025 18:19:50 GMT</pubDate>
    </item>
    <item>
      <title>从HTML页面检索信息的ML算法</title>
      <link>https://stats.stackexchange.com/questions/663030/ml-algorithms-for-information-retrieval-from-html-pages</link>
      <description><![CDATA[我想知道是否有一种ML算法适合于从HTML中提取信息或其他标记的数据文档的信息。
在Python中，通常会使用像美丽的汤这样的库来创建一个脚本，但这需要了解文档的结构，通常需要通过反向工程来获得。
我想知道是否有一种ML算法可以通过从例子中学习来减轻我们的负担。例如。如果您多次从具有相同结构的页面中提取数据，则可以将先前刮擦的HTML与所需输出作为标记的培训数据。。
对此有什么方法？
我想到了RNN，但我怀疑这是最有效的方法，因为它们通常很大，序列可能很长，因此学习提取正确的部分可能需要大量资源，并且如果令牌设置更改并且可能需要完整的再训练，则体系结构会发生巨大变化。那还有其他东西吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663030/ml-algorithms-for-information-retrieval-from-html-pages</guid>
      <pubDate>Sun, 23 Mar 2025 17:19:12 GMT</pubDate>
    </item>
    <item>
      <title>数据泄漏随STL分解</title>
      <link>https://stats.stackexchange.com/questions/663029/data-leakage-with-stl-decomposition</link>
      <description><![CDATA[我有一个时间序列，我需要使用Sarima模型进行预测。我进行火车测试拆分，然后将Sarima型号安装在培训数据上。我想避免数据泄漏并保留现实主义，因此我不想对测试数据进行培训的模型，但是我不知道如何从Python中未经培训的数据中删除季节和趋势？我的代码在下面（或多或少）
 种子（20030715）
功能_GAIN= {键：值[0]对于键，value.items（）} #features供其中一个模型使用
features_gauss = {键：值[1]对于键，value.items（）}＃要用于其他模型的功能

残差= {}

tscv = timeseriessplit（n_splits = 5）

main_split = []

对于train_index，tscv.split中的test_index（housing_prices_gain2.index）：
    main_split.append（（train_index，test_index））

用于housing_prices_gain2.columns中的列：
    start_time = time.time（）
    full_split_gain = [[]，[]，[]]
    full_split_gauss = [[]，[]，[]]
    endog_gauss = housing_prices_gauss2 [列]
    endog_gain = housing_prices_gain2 [列]
    exog_gauss = housing_prices_gauss2.copy（）。loc [：，features_gauss [column]]。join（fed_funds_gauss）
    exog_gain = housing_prices_gain2.copy（）。loc [：,, features_gain [column]]。join（fed_funds_gain）
    ＃训练和测试
    （endog，exog，full_split）在[（endog_gauss，exog_gauss，full_split_gauss），（endog_gain，exog_gain，full_split_gain）]：
        #best_params = get_best_sarimax_params（endog，12）
        #print（&#39;\ rfound参数
        对于train_index，test_index在main_split中：
            x_train，x_test = exog.iloc [train_index，：]，exog.iloc [test_index，：]
            y_train，y_test = endog.iloc [train_index]，endog.iloc [test_index]
            
            #STL分解 
            stl_model = stl（y_train，
                        周期= 12，
                        季节性= 13，
                        趋势= 17，
                        稳健= true）
            decomp = stl_model.fit（）
            y_train = demomp.isid
            ＃在这里是我要使用stl_model从测试数据集获取残差的地方


            尝试：
                模型= sarimax（
                    exog = x_train，
                    endog = y_train，
                    趋势= [1,1,1]
                    ＃order = best_params [：3]，＃（p，d，q）
                    ＃sishenal_order = best_params [3：]，＃（p，d，q，s）
                ）。合身（
                    Maxiter = 5000，
                    方法=&#39;nm&#39;，
                    disp = false
                ）
            除了：
                打印（x_train）
                提高价值
            
            如果x_train.shape [1]！= 0：
                forecast = model.get_forecast（steps = len（y_test），exog = x_test）
                y_pred = forecast.predicted_mean
            别的：
                预测= model.get_forecast（steps = len（y_test））
            full_split [0] .extend（y_pred）
            full_split [1] .extend（y_test）
            full_split [2] .extend（test_index）
        ＃节省
        残差[列] =（full_split_gain，full_split_gauss，time.time（） -  start_time）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663029/data-leakage-with-stl-decomposition</guid>
      <pubDate>Sun, 23 Mar 2025 17:06:51 GMT</pubDate>
    </item>
    <item>
      <title>这项MCMC提案有​​效吗？</title>
      <link>https://stats.stackexchange.com/questions/663028/is-this-mcmc-proposal-valid</link>
      <description><![CDATA[我正在尝试使用MCMC进行概率向量变量的采样，但是我没有在通常的连续空间中提出新样本，而是在尝试使用珠子计数类比：
dirichlet矢量的每个组成部分都对应于“ bin”。包含一定数量的珠子（即整数计数）。珠子的总数是固定的，归一化的计数给出了单纯形上的概率向量。
我创建了一个使用 .count 给出珠子计数和 .prob 给定概率向量的类。。
问题：
我以为这是一个对称的建议，并且对Dirchlet进行了MCMC，但没有给出正确的分布。
我做错了吗？
在
    “”
    生成一个新概率数组的建议。
    “”

    Movables = np.random.binomial（self.counts，rate）＃确定可移动珠
    new_counts = self.counts-移动
    
    ＃左右重新分配珠
    mvleft = np.random.binamial（MovableS，0.5）
    mvright = Movables -mvleft

    new_counts [： -  1] += mvleft [1：]
    new_counts [0] += mvleft [0]＃珠子从第一个垃圾箱留下来向左移动

    new_counts [1：] += mvright [： -  1]
    new_counts [-1] += mvright [-1]＃珠子从最后一个bin停留

    
    返回prog_array（new_counts，new_counts.size，new_counts.sum（））
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663028/is-this-mcmc-proposal-valid</guid>
      <pubDate>Sun, 23 Mar 2025 16:29:16 GMT</pubDate>
    </item>
    <item>
      <title>帮助操纵截短的正常人</title>
      <link>https://stats.stackexchange.com/questions/663024/help-manipulating-truncated-normals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663024/help-manipulating-truncated-normals</guid>
      <pubDate>Sun, 23 Mar 2025 16:07:47 GMT</pubDate>
    </item>
    <item>
      <title>在线性固定效果面板数据模型中测试多重共线性（在Stata中）</title>
      <link>https://stats.stackexchange.com/questions/663023/testing-multicollinearity-in-linear-fixed-effect-panel-data-model-in-stata</link>
      <description><![CDATA[我正在分析具有自变量的面板数据，我高度怀疑是多共线的。我正在尝试在Stata（Statanow 18/se）中构建数据的固定效应模型。我是该主题的新手，只有从横截面线性回归模型中知道，方差通胀因子（VIF）可以是检测一组自变量中多重共线性的好方法，并指向变量以考虑删除。
但是，似乎使用VIF不适用于纵向/面板数据分析。例如，使用 xtreg 。
现在我不确定该怎么办。我有三个链接的问题：

多重共线性甚至是我在FE面板数据分析中应该关注的事情吗？
如果是的话，会做一个汇总的OLS以获取VIF并删除多共线变量是统计上合理的方法吗？
如果通过合并OLS的VIF不是解决方案，那是什么？

我也很想了解为什么VIF不适用于FE面板数据模型，因为他们的公式中没有任何指示我不应该适用的。
非常感谢您的输入！]]></description>
      <guid>https://stats.stackexchange.com/questions/663023/testing-multicollinearity-in-linear-fixed-effect-panel-data-model-in-stata</guid>
      <pubDate>Sun, 23 Mar 2025 15:11:45 GMT</pubDate>
    </item>
    <item>
      <title>我们可以根据基线和修剪模型的验证精度提高验证准确性，在早期停止标准中设置不同的耐心</title>
      <link>https://stats.stackexchange.com/questions/663019/can-we-set-different-patience-in-early-stopping-criteria-based-on-improvement-in</link>
      <description><![CDATA[我在CNN中进行非结构化特征重量修剪。首先，我训练了一个基线模型，而无需修剪和停止标准基于验证精度的提高，并为基线模型设定了耐心15。然后我采用了相同的型号，并结合了火车时间修剪。对于修剪模型，我使用了相同的停止标准，但是我将耐心值设置为5。由于修剪模型的参数较少，并且需要更少的时期来收敛。对于这个论点，我可以给出众所周知的“彩票假说”声称获胜票是唯一的票。我的问题是，为基线和修剪模型设定不同的patirnce价值是否有意义？这是一个公平的比较吗？我的目标是用于资源受限的嵌入式系统的AI驱动解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/663019/can-we-set-different-patience-in-early-stopping-criteria-based-on-improvement-in</guid>
      <pubDate>Sun, 23 Mar 2025 14:03:18 GMT</pubDate>
    </item>
    <item>
      <title>使用相关介质计算SEM中的间接效应</title>
      <link>https://stats.stackexchange.com/questions/663017/calculating-indirect-effects-in-sem-with-correlated-mediators</link>
      <description><![CDATA[我正在尝试通过SEM模型来计算直接，间接和总效果。如果我有这样的模型：
  $ x_1 $  on  $ x_4 $  is  $ ab+cd $ cd $ 。例如， $ x_2 $  on  $ x_4 $  is  $ b + acd $ 。
但是，如果两个调解人 $ x_2 $  and  $ x_3 $ 允许关联？ IE。
 我的问题是：

在计算 $ x_1 $ 上的效果时
在计算 $ x_2 $ 上的效果时
在计算 $ x_2 $ 上的效果时 $ rcab $ 它会让我输入 $ x_2 $ 两次。这是正确的吗？

我不知道R]]></description>
      <guid>https://stats.stackexchange.com/questions/663017/calculating-indirect-effects-in-sem-with-correlated-mediators</guid>
      <pubDate>Sun, 23 Mar 2025 13:58:29 GMT</pubDate>
    </item>
    <item>
      <title>漏斗分为两个阶段，仅在整体上成功</title>
      <link>https://stats.stackexchange.com/questions/663015/funnel-split-into-two-stages-with-success-only-for-the-whole</link>
      <description><![CDATA[我的雇主有一个渠道，它会让访客通过。  要简化，假设所有访问者都到达步骤 $ a $ ，我们在其中将它们随机化为同伙，然后有些人选择转到步骤 $ b $ 。  在 $ b $ ，我们根据认为可以将访问货币化的方式分为不同的组。  然后，我们看看它们是否从 $ b $ 转到 $ c_1 $ （第一组成功），还是从我的雇主作为业务决策，认为渠道的成功是到达 $ C_1 $ ，并询问我是否赢得了用户界面拆分测试。  假设 $ b_1 \％$ 访问者到达 $ b $  $ b $ ，并向 $ c_1 $ c_1 $ span&gt;， $ b $ ，并向 $ C_2 $ 和 $ b_0 \％= 1-b_1 \％ -  b_2 \％ -  b_2 \％$ $ 不要到 $ C_1 $ 的访问者中， $ C_1 \％$ 成功地到达 $ c_1 $ 。  我建议比较转换率 $ b_1 \％\ cdot c_1 \％$ 在两个队列之间，使用 $ a $ a $ 的同类尺寸。  这是评估此漏斗的方法吗？  什么可能是更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/663015/funnel-split-into-two-stages-with-success-only-for-the-whole</guid>
      <pubDate>Sun, 23 Mar 2025 12:08:29 GMT</pubDate>
    </item>
    <item>
      <title>使用阻塞的Gibbs采样器，在Dirichlet工艺混合模型中精确参数的后验采样</title>
      <link>https://stats.stackexchange.com/questions/663014/posterior-sampling-of-precision-parameter-in-a-dirichlet-process-mixture-model-u</link>
      <description><![CDATA[ Gelman的贝叶斯数据分析的第553页（第三版），根据 高位分布，显示了DPM模型的PRICISION参数的后分布公式，用于阻止的Gibbs采样器算法。。 。
  $ \ alpha |  -  \ sim gamma（a_ \ alpha +n-1，b_ \ alpha- \ sum_ {
此结果的证明/推导是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/663014/posterior-sampling-of-precision-parameter-in-a-dirichlet-process-mixture-model-u</guid>
      <pubDate>Sun, 23 Mar 2025 12:06:01 GMT</pubDate>
    </item>
    <item>
      <title>如何以额外的贡献项计算几何布朗运动的百分位数？</title>
      <link>https://stats.stackexchange.com/questions/663013/how-to-calculate-percentiles-on-geometric-brownian-motion-with-an-extra-contribu</link>
      <description><![CDATA[我试图在几何布朗运动上计算百分位数，并在每个间隔的中间有其他贡献条款：
 $ s_ {t+1} = s_t * \ exp { \ sigma^2/2）+\ sqrt {1/2}*r*\ sigma]} $ 其中 $ r $ 是标准的标准， $ c_t $ c_t $ c_t $ 我使用R来模拟这些布朗动作。我现在想计算这项运动的第十和第90个百分点。我尝试了多件事：
将变量放置 $ r = 1.282 $ 对于第90个百分位数不起作用，因为这假设这是每个步骤中的第90个百分位数，这将在第一步之后给出非常不现实的结果。 。
计算偏差＆lt;  -  qnorm（0.90，0，波动率），然后 mu＆lt;  -  mu + deviation/sqrt/sqrt {j} 在每个jth步骤中为每个jth步骤（我计算j + 1）的结果很接近，但在95上却不完全是900s（对于900 simate in 5 inter in 5 00al simime in 90 simimile of 90％百分位数）。
我确实尝试使用仿真，但我想找到一个与预期场景和百分位数之间差异的两个百分位数中的三角洲，因此一种更理论的方法可能很好。。
我还找到了计算布朗尼运动百分位数的方法（例如，在 note ） class =“ Math-Container”&gt; $ C_T $ 。
有人知道是否可以分析或通过不使用模拟的R-Code解决此问题？？]]></description>
      <guid>https://stats.stackexchange.com/questions/663013/how-to-calculate-percentiles-on-geometric-brownian-motion-with-an-extra-contribu</guid>
      <pubDate>Sun, 23 Mar 2025 11:38:05 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-Learn PCA与自定义PCA实现之间的符号差异[重复]</title>
      <link>https://stats.stackexchange.com/questions/663020/discrepancy-in-signs-between-scikit-learn-pca-and-custom-pca-implementation</link>
      <description><![CDATA[我正在实现自己的PCA版本，并将其与Scikit-Learn的PCA进行比较。但是，我注意到主要组件的迹象的差异。
 使用scikit-learn  
  sualer =标准尺度（）
scaled_data = scaler.fit_transform（数据）

pca_scaled = pca（n_components = 2）
PCA_SCALED.FIT（scaled_data）

principal_components = pca_scaled.components_
 
输出：
  [[0.70710678 0.70710678]
 [-0.70710678 0.70710678]]
 
 自定义PCA  
  def custom_pca（数据，num_components）：
    平均值= np.mean（数据，轴= 0）
    std = np.std（数据，轴= 0）  
    X_Standardized =（数据 - 平均） / STD

    cov_matrix = np.cov（x_standardized，rowvar = false）

    特征值，eigenVectors = np.linalg.eig（cov_matrix）

    返回特征向量
 
输出：
  [[0.70710678 -0.70710678]
 [0.70710678 0.70710678]]
 
为什么符号被翻转？
  scikit-learn：
[[0.70710678 0.70710678]
 [-0.70710678 0.70710678]]

自定义PCA：
[[0.70710678 -0.70710678]
 [0.70710678 0.70710678]]
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663020/discrepancy-in-signs-between-scikit-learn-pca-and-custom-pca-implementation</guid>
      <pubDate>Sun, 23 Mar 2025 07:25:07 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将GMM视为差异差异的更丰富版本吗？</title>
      <link>https://stats.stackexchange.com/questions/662976/can-we-consider-gmm-as-a-richer-version-of-difference-in-differences</link>
      <description><![CDATA[注意：我在这里和统计数据中是新手。
我正在阅读A 期刊文章（公开访问），并谈论他们如何使用一般的Moments（GMM）分析。基本上，有一些位置，每个地方都有多个业务。
分析查看10年的数据（数据包括10年中每个位置的10个不同属性）。该分析还关注每个位置中企业的盈利能力以及在这10年中的变化。
作为一个非常新手的人，在我看来，这与差异的差异非常相似，但是具有更高水平的复杂水平（更多的变量，更多的时间点等）。
我在这里还是我只是在误解了这里如何使用GMM？]]></description>
      <guid>https://stats.stackexchange.com/questions/662976/can-we-consider-gmm-as-a-richer-version-of-difference-in-differences</guid>
      <pubDate>Sat, 22 Mar 2025 12:27:26 GMT</pubDate>
    </item>
    <item>
      <title>手动反向倾向得分重新加权与加权OLS回归之间的等效性</title>
      <link>https://stats.stackexchange.com/questions/662957/equivalence-between-manual-inverse-propensity-score-reweighting-and-a-weighted-o</link>
      <description><![CDATA[假设 $ y_i $ 是结果， $ d_i $ 是一种二进制处理， $ x_i $ 是covariate。将倾向分数表示为 $ p（x_i）= e [d_i | x_i] $ 。。
我们可以使用以下方式使用逆倾向评分来恢复平均治疗效果（ATE）：
 $$
ate = e \ left [\ frac {y_ {y} \ cdot d_i} {p（x__ {i}）} \ right]  -  e \ left [\ frac {y_ {y} {i} \ cdot（1- d_i）}
$$  
实际上，这通常是通过估计加权OLS回归来实现的：
 $$
y_i = \ alpha + \ beta d_i + \ varepsilon_i
$$ 
由 $ \ omega $ 其中 $ \ omega = 1/p（x_i）$ 用于处理的观察值和 $ \ omega = 1/（for omega）
我有两个问题：

有人可以为为什么这两个程序产生相同的治疗效果提供正式论证吗？使用加权回归的定义的东西将非常有用。
两个程序都会产生相同的标准错误吗？要么正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/662957/equivalence-between-manual-inverse-propensity-score-reweighting-and-a-weighted-o</guid>
      <pubDate>Fri, 21 Mar 2025 18:38:50 GMT</pubDate>
    </item>
    <item>
      <title>最好拥有具有较大差异的估计器吗？</title>
      <link>https://stats.stackexchange.com/questions/662927/is-it-ever-preferable-to-have-an-estimator-with-a-larger-variance</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662927/is-it-ever-preferable-to-have-an-estimator-with-a-larger-variance</guid>
      <pubDate>Fri, 21 Mar 2025 09:22:19 GMT</pubDate>
    </item>
    </channel>
</rss>