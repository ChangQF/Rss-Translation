<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Dec 2024 12:33:05 GMT</lastBuildDate>
    <item>
      <title>N 维单调函数的可逆性</title>
      <link>https://stats.stackexchange.com/questions/659121/invertibility-of-n-dimensional-monotonic-function</link>
      <description><![CDATA[给定一个函数 $F: \mathbb{R}^n\rightarrow \mathbb{R}^n$，其中我们知道 $\frac{dF_i(x)}{dx_j}\ge 0 \,\,\forall i,j$（因此 $F$ 的每个分量对所有输入都是单调的），我们可以说它是可逆的吗？
实际上，这指的是规范化流，具体来说，我正在阅读这篇论文，特别是在定理 1（在补充材料）他们声称他们的复合函数是可逆的。
但是，我不太同意，具体来说，如果我们取$F = [x+y, x+y]$，我们有一个二维函数，其中每个分量相对于输入都是单调的，但它绝对不是可逆的。现在，假设他们使用残差连接，这样的示例可以轻松实现：
$$
x&#39; = x + \begin{bmatrix}0,1\\1,0\end{bmatrix}x
$$
我知道缺少非线性，但这证明了单调性是不够的，不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659121/invertibility-of-n-dimensional-monotonic-function</guid>
      <pubDate>Mon, 23 Dec 2024 10:58:18 GMT</pubDate>
    </item>
    <item>
      <title>跨栏模型等同于零膨胀模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</link>
      <description><![CDATA[换句话说，障碍模型可以转换为零膨胀模型吗？
我正在查看障碍模型的维基百科页面（https://en.wikipedia.org/wiki/Hurdle_model）。据我理解，障碍模型只是零概率，对于非零情况，则是严格非零分布。
零膨胀模型是零概率，对于其他情况，则是包含零的分布。
所以你可以采用零膨胀模型，将零概率分解为单一情况，然后将其称为障碍模型，对吗？我遗漏了什么吗？
它们似乎都能够形成相同的总概率分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</guid>
      <pubDate>Mon, 23 Dec 2024 10:49:34 GMT</pubDate>
    </item>
    <item>
      <title>单因素方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</link>
      <description><![CDATA[我正在观看一场关于方差分析的讲座，讲师给出了 3 个可能的数据假设示例：

对于假设 3 (mu2 = mu1 - 3*mu3)，对比系数的总和不为零 (-1 + 1 + 3 != 0)。在这种情况下，我们可以说它是对比吗？如果不是，那它是什么？在这种情况下，我们可以检查第三个假设与假设 1 的正交性，就像幻灯片上所做的那样 (a * c)？]]></description>
      <guid>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</guid>
      <pubDate>Mon, 23 Dec 2024 05:03:38 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</link>
      <description><![CDATA[我试图理解 F 检验对简单线性回归模型有效性的检验，但我对此有几个问题：

为什么我们要用 SSR 除以独立变量的数量，用 SSE 除以自由度的数量？为什么不用它们都除以独立变量的数量，这样我们就可以计算出每个独立变量对应的平均解释/未解释变异性？

在 $\beta_1 = 0$ 的零假设下，检验统计量的 F 是如何分布的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</guid>
      <pubDate>Mon, 23 Dec 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以计算/指定 SEM 全项目分割方法中的误差方差？</title>
      <link>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</link>
      <description><![CDATA[我是 SEM 和 lavaan 的新手。我创建了一个模型，需要为其运行 SEM。由于样本量极小且模型参数很多，我需要采用全项目包裹方法进行 SEM 和 ML 估计，尽管我知道包裹是有争议的。
先前的文献表明，如果我要为某个因子包裹所有项目，则需要计算误差方差。

有趣的是，此处引用的作为全项目包裹方法示例的四项研究使用了略有不同的方程来计算误差方差 (θε)。 Holbert (2005) 和 Theiss
and Solomon (2006) 使用了 Bollen (1989) 的程序（即 θε = [1 − α] × s2），而其他两项研究的作者修改了该方程：Dillard 和 Shen (2005) 将每个构造的误差方差固定为“1 − α2 乘以其方差”（第 156 页）（即 θε = [1 − α2] × s2）；另一方面，在 Pfau 等人（2004 年，第 341 页）的研究中，“误差项设置为每个变量的方差乘以 1 减去该变量可靠性估计的平方根”（即 θε = [1 − α1/2] × s2）。鉴于 α ≤ 1.0 且 s2 &gt; 0，
与 Bollen 的原始公式相比，
对 alpha 求平方会使误差方差增大，而对 alpha 求平方根会使误差方差减小。
所有这些作者都引用了 Bollen 作为计算过程的来源。
（Matsunaga，2014；DOI：10.1080/19312450802458935）

我的问题是，在 R 中使用 lavaan 时，如何以及在哪里指定/计算此误差方差？我想出了以下语法，它正确吗（尤其是使用 ~~）？误差方差已通过以下公式计算：θε = [1 − α] × s2
model &lt;- &#39;
Institutional_Support =~ 1*INSPT_COMP
Lesson_Preparation_Time =~ 1*LPT_COMP
Access_Use_Technology =~ 1*TECH_COMP
Self_Efficacy =~ 1*SEFF_COMP
Orchestration_Load =~ 1*TLX_COMP

# 结构模型：以 SHT 为观察变量的经验
Orchestration_Load ~ Institutional_Support + Lesson_Preparation_Time + EXP1

# 为每个地块指定固定方差
INSPT_COMP ~~ error_variances_INSPT
LPT_COMP ~~ error_variances_LPT
TECH_COMP ~~ error_variances_TECH
SEFF_COMP ~~ error_variances_SEFF
TLX_COMP ~~ error_variances_TLX
&#39;

# 使用 ML 估计量和 bootstrap 标准误差拟合 SEM 模型
fit_ml &lt;- sem(
model,
data = my_data,
estimator = &quot;ML&quot;,
se = &quot;bootstrap&quot;, # 使用 bootstrap 标准误差
bootstrap = 1000 # bootstrap 样本数
)

&#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</guid>
      <pubDate>Mon, 23 Dec 2024 00:21:23 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型对不平衡聚类是否具有鲁棒性？</title>
      <link>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</link>
      <description><![CDATA[我们已拟合以下模型：
m = lmer(y ~ time + event + time_since_event + (time|id), data = df)

有些集群有 1000 多个数据点，而其他集群则少于 10 个。
lmer 模型是否考虑了这种集群大小不平衡？即使存在这种不平衡，time、event 和 time_since_event 的 $p$ 值是否可靠？
是否有必要使用 clubSandwich 之类的包来实现聚类稳健标准误差：
coef_test(m, vcov = &quot;CR2&quot;, cluster = df$id)

我们询问的原因是从 coef_test 获得的 $p$ 值无法支持我们的假设，而从 lmer 模型获得的 $p$ 值则支持我们的假设。不确定哪个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</guid>
      <pubDate>Sun, 22 Dec 2024 22:26:49 GMT</pubDate>
    </item>
    <item>
      <title>利用二进制数据的 MSE 进行快速搜索</title>
      <link>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</link>
      <description><![CDATA[我有一个巨大的二进制向量数据库。给定一个传入向量，我想在数据库中找到 MSE 最接近的向量并返回 MSE 分数。到目前为止，我一直在手动进行此搜索，但花费的时间太长了。
我可以利用 MSE 与二进制向量一起使用时的特性来加快搜索速度吗？
更多详细信息：我正在寻找。我可以利用的 MSE 或二进制向量或数据稀疏性的属性来显着加快搜索速度！我的数据集有大约 400 万个高维（~4000）二进制向量，其中大部分是稀疏的（包含大量零）。我有一个循环，逐个遍历 400 万个向量并返回 MSE 分数最低的向量。我不能使用任何其他指标，并且在考虑是否可以利用 MSE 的任何属性来加快搜索速度。即使可以使用使用 MSE 的 ML 模型，它也会很完美]]></description>
      <guid>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</guid>
      <pubDate>Sat, 21 Dec 2024 01:58:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>如何应用对系数有约束的 OLS 并使输出规模与目标变量对齐？</title>
      <link>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</link>
      <description><![CDATA[我正在研究一个 OLS 回归问题，其中：
因变量（目标）的范围从 1 到 6（步长为 1）。
独立变量的范围从 1 到 10（步长为 0.5）。
我想要设置模型，使得：
没有截距。
所有系数的总和（β）等于 1。
输出与因变量的尺度一致（1 到 6）。
但是，当所有独立变量都达到其最大值 10 时，模型输出将扩大到 10，这超出了目标范围。我无法缩放独立变量。我可以缩放因变量。因此，它是 1 到 10。下面是我用来缩放因变量的映射。



原始比例
新scale




1
1


2
2.8


3
4.6


4
6.4


5
8.2


6
10



但是还有其他方法吗？我如何调整我的 OLS 设置？
如果您能提供任何关于如何实施的指导或建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</guid>
      <pubDate>Wed, 18 Dec 2024 07:41:36 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost - `colsample_bytree`<1 的树所见列的顺序</title>
      <link>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsample-bytree1</link>
      <description><![CDATA[我的理解是，如果两个或多个列在拆分时提供相同的增益，XGBoost 会选择第一列。
为了确保 XGBoost 有机会查看并包含所有相关列，我认为我可以简单地传递 colsample_bytree=0.99。但是，为了使其工作，采样返回的列必须按随机顺序排列。这种方法正确吗？还是我应该在某种交叉验证方案中对列进行打乱？]]></description>
      <guid>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsample-bytree1</guid>
      <pubDate>Tue, 17 Dec 2024 11:02:34 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验为 z 检验或卡方检验</title>
      <link>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</link>
      <description><![CDATA[我是统计学入门课的助教。我们正​​在向学生介绍 McNemar 检验，以比较相关样本上的两个比例。我注意到教科书中，我们将 McNemar 检验定义为遵循 z 分布的 z 统计量：
$$
z = \frac{b-c}{\sqrt{b+c}}
$$
而其他来源，例如维基百科，将检验统计量定义为遵循卡方分布
$$
\chi_1^2 = \frac{(b-c)^2}{b+c}
$$
我从数理统计中得知，z 统计量的平方服从自由度为 1 的卡方分布。
有人知道为什么人们可能更喜欢将一种框架作为 z 检验或将另一种框架作为 z 检验吗？我认为这两个统计数据会产生相同的推论。我怀疑如果学生决定自己阅读这个主题，他们可能会感到困惑。
将测试框架为 z 检验确实允许计算与卡方框架无关的标准误差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</guid>
      <pubDate>Wed, 20 Nov 2024 21:28:46 GMT</pubDate>
    </item>
    <item>
      <title>交付预测模型中实现 ETA 平稳过渡的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/652343/best-approach-to-smooth-eta-transitions-in-delivery-prediction-models</link>
      <description><![CDATA[我正在使用随时间演变的预测模型来显示物品交付的 ETA（预计到达时间）。我面临的问题涉及平滑初始和后续 ETA 预测之间的过渡。
问题描述
初始预测准确度：该模型最初提供的 ETA 非常不准确（附图中的星号代表此初始预测）。随着时间的推移和更多信息的出现，ETA 预测变得更加准确。这可能导致第一次和第二次预测之间出现较大的差距（20-30 分钟）。
稳定预测：第二次预测后，ETA 通常会在一段时间内保持不变，然后最终更新。例如，在提供的图中，ETA 从 17:31 到 17:37 保持在 10 分钟，然后开始略微下降。
当前方法
我正在使用简单的指数加权移动平均线平滑 ETA 值以处理从初始不准确预测到更准确的后续预测的过渡。
问题：
处理大差距：有哪些有效的技术可以平滑或减轻初始和第二个 ETA 预测之间的 20 分钟差距？（这是我主要关心的问题）
解决稳定的 ETA 值：应该如何处理 ETA 几分钟内不变的问题？是否有基于用户体验的理由来调整此行为，或者是否可以接受？
附加上下文：
我不确定简单地将平滑函数应用于 ETA 值是否是最佳解决方案，或者是否有更复杂的方法来有效地处理这两个问题。任何有关改进 ETA 预测显示的见解或建议都将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/652343/best-approach-to-smooth-eta-transitions-in-delivery-prediction-models</guid>
      <pubDate>Mon, 05 Aug 2024 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 代码计算信用评分的基尼系数、准确度和 AUROC</title>
      <link>https://stats.stackexchange.com/questions/616618/calculation-of-the-gini-coefficient-accuracy-and-auroc-for-credit-scoring-using</link>
      <description><![CDATA[我有以下数据，我想计算 GINI 和 Accuracy 以进行模型验证。但我尝试使用 Python 代码计算 GINI 和 Accuracy，但似乎不正确。我想通过计算借款人累计数量、商品累计数量和坏账累计数量来计算 AUC、GINI 和 Accuracy。
因为我想在 Microsoft Excel 和 Python 中实现这一点，因此尝试计算但没有成功
以下是代码：
# code 1
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

data = {
&quot;Decile&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
&quot;No.借款人”：[100, 300, 200, 300, 600, 200, 700, 800, 900, 1000],
“好借款人”：[80, 160, 140, 220, 500, 1000, 560, 640, 1500, 800],
“坏借款人”：[20, 140, 60, 80, 1000 ,1000 ,1400 ,1600 ,7500 ,200]
}
good_borrowers = data[&#39;好借款人&#39;]
bad_borrowers = data[&#39;坏借款人&#39;]

total_borrowers = [good_borrowers[i] + bad_borrowers[i] for i in range(len(good_borrowers))]
cumulative_good_borrowers = [sum(good_borrowers[:i+1]) for i in range(len(good_borrowers))]
cumulative_bad_borrowers = [sum(bad_borrowers[:i+1]) for i in range(len(bad_borrowers))]

cumulative_good_borrower_ratio = [cumulative_good_borrowers[i]/total_borrowers[i] for i in range(len(total_borrowers))]
cumulative_bad_borrower_ratio = [cumulative_bad_borrowers[i]/total_borrowers[i] for i in range(len(total_borrowers))]

fpr,tpr,_ = roc_curve(data[&#39;Decile&#39;],累积良好借款人比率)
roc_auc = auc(fpr,tpr)
gini = (2 * roc_auc) -1

print(&quot;AUC: &quot;, roc_auc)
print(&quot;GINI: &quot;, gini)

#code 2: 
import numpy as np
import matplotlib.pyplot as plt

# 创建一个数据框来存储每个十分位数中的借款人、好借款人和坏借款人的数量。
data = {
&quot;十分位数&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
&quot;No.借款人”：[100, 300, 200, 300, 600, 200, 700, 800, 900, 1000],
“好借款人”：[80, 160, 140, 220, 500, 100, 560, 640, 150, 800],
“坏借款人”：[20, 140, 60, 80, 100, 100, 140, 160, 750, 200]
}

# 计算 ROC 曲线。
fpr = []
tpr = []
for decile in range(0, len(data[&quot;Decile&quot;])):
good_borrowers_in_decile = data[&quot;Good Borrowers&quot;][decile]
bad_borrowers_in_decile = data[&quot;Bad Borrowers&quot;][decile]
total_borrowers_in_decile = good_borrowers_in_decile + bad_borrowers_in_decile
fpr.append(bad_borrowers_in_decile / total_borrowers_in_decile)
tpr.append(good_borrowers_in_decile / total_borrowers_in_decile)

# 绘制 ROC 曲线。
plt.plot(fpr, tpr)
plt.xlabel(&quot;假阳性率&quot;)
plt.ylabel(&quot;真阳性率&quot;)
plt.title(&quot;ROC 曲线&quot;)
plt.show()

# 计算 AUC。
auc = np.trapz(tpr,fpr)
print(&quot;AUC:&quot;, auc)

# 计算准确率。
accuracy = (sum(data[&quot;好借款人&quot;]) + sum(data[&quot;坏借款人&quot;])) / sum(data[&quot;借款人数量&quot;])
print(&quot;准确率:&quot;, accuracy)

# 计算基尼系数。
#gini = 1 - np.sum((np.array(data[&quot;No. Borrowers&quot;]) * (np.array(data[&quot;No. Borrowers&quot;]) -1))) / (np.prod(np.array(data[&quot;No. Borrowers&quot;])) **2)
def gini(data):
borrowers = np.array(data[&quot;No. Borrowers&quot;])
if 0 in borrowers:
return None
gini = 1 - np.sum((borrowers * (borrowers -1))) / (np.prod(borrowers) **2)
return gini
gini(data)
print(&quot;Gini 系数:&quot;, gini)


数据:





十分位
借款人数量
优质借款人
不良借款人




1
100
80
20


2
300
160
140


3 
200
140
60


4
300
220
80


5
600
500
100


6
200
100
100


7
700
560
140


8
800
640
160


9
900
150
750


10
1000
800
200




希望这有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/616618/calculation-of-the-gini-coefficient-accuracy-and-auroc-for-credit-scoring-using</guid>
      <pubDate>Mon, 22 May 2023 21:09:43 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型的优势比解释</title>
      <link>https://stats.stackexchange.com/questions/612874/odds-ratio-interpretation-for-generalized-additive-models</link>
      <description><![CDATA[这可能是一个很粗略的问题，我已经思考了一段时间。广义加性模型 (GAM) 的几率比是否与广义线性模型 (GLM) 的几率比相同？如果不是，那么我该如何在逻辑 GAM 中解释它们？我发现很多关于 GAMM 几率比的链接，但没有关于 GAM 的链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/612874/odds-ratio-interpretation-for-generalized-additive-models</guid>
      <pubDate>Fri, 14 Apr 2023 01:21:31 GMT</pubDate>
    </item>
    </channel>
</rss>