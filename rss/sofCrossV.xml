<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 17 Apr 2024 09:14:21 GMT</lastBuildDate>
    <item>
      <title>方差分析和逻辑回归之间统计显着性的差异</title>
      <link>https://stats.stackexchange.com/questions/645206/difference-in-the-statistical-significance-between-anova-and-logistic-regression</link>
      <description><![CDATA[我对 120 名患者进行了手术。其中，我对经历过手术部位感染的患者和未经历过方差分析的患者进行了比较。我发现两个统计显着性。然后，我使用手术部位感染作为自变量进行了逻辑回归分析，并且方差分析中 p&lt;0.1 的变量作为自变量。我没有发现任何显着性，甚至那些方差分析中 p&lt;0.05 的显着性也没有。这是什么意思？感谢您的宝贵时间]]></description>
      <guid>https://stats.stackexchange.com/questions/645206/difference-in-the-statistical-significance-between-anova-and-logistic-regression</guid>
      <pubDate>Wed, 17 Apr 2024 09:07:34 GMT</pubDate>
    </item>
    <item>
      <title>小鼠：默认脊参数</title>
      <link>https://stats.stackexchange.com/questions/645205/mice-default-ridge-parameter</link>
      <description><![CDATA[当基础数据接近多重共线时，mice 中的一些方法（如 pmm 和norm）应用默认的岭参数 1e-5。在 van Buuren 的伟大著作第 6.3 章 (https://stefvanbuuren.name/fimd/sec-modelform. html）我读到，岭参数可以增加到 0.001 或 0.01，以使算法更加稳健，但会牺牲偏差。我想知道这些值的确定是否有任何可靠的规则？]]></description>
      <guid>https://stats.stackexchange.com/questions/645205/mice-default-ridge-parameter</guid>
      <pubDate>Wed, 17 Apr 2024 09:03:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们可以在渐进机制中得到更好的全局估计量，即使对于 IID 随机变量也是如此？</title>
      <link>https://stats.stackexchange.com/questions/645203/why-can-we-get-better-global-estimators-in-the-asymptotic-regime-even-for-iid-r</link>
      <description><![CDATA[设 $X_1,...,X_N$ 为从参数化分布中采样的 IID 随机变量 $p_\theta $，并假设我的目标是从这些样本中检索 $\theta$。
我们知道 MLE 在渐近状态下提供了一种有效的无偏估计，这意味着它将是渐近无偏的，并且方差（渐近）饱和 Cramer-Rao 界。
另一方面，我们也知道，即使在单次状态下，即在一次观察之后，我们也可以找到一个有效的局部无偏估计量，该估计量的主要警告通常只是local（这意味着它取决于有关 $\theta$ 的一些先验知识）。
相比之下，MLE 是无偏且有效的（尽管只是渐近），不需要参数的先验知识来进行估计。
为了用一个明确的玩具示例来具体化讨论，假设我们要从伯努利过程中估计 $p^2$，$X_i\sim\operatorname{伯尔尼}(p)$。
标准计算将显示此问题的 MLE 为
$$\hat p_N^2 = \left(\frac{\sum_{i=1}^N X_i}{N}\right)^2,
\\ \mathbb{E}[\hat p_N] = p^2 + \frac{p(1-p)}{N},
\\ \operatorname{Var}[\hat p_N] = \frac{4p^3(1-p)}{N} + O(1/N^2).$$
另一方面，局部围绕参数值 $p^2$ 饱和 Cramer-Rao 边界的单次估计量为
$$\hat f_{p^2}(X) = -p^2 + 2p X.$$
此处显示了 MLE 的计算例如，而局部有效估计器的计算此处。
因此，这两个估计量具有渐近相同的方差（取较大 $N$ 的局部估计量的平均值），但 MLE 的一大优势是非局部，即不是要估计的参数的函数。
我的问题是：是否有任何直觉可以理解为什么会发生这种情况？由于我们正在讨论 IID 变量，因此一系列观察中的信息不应比每个单独观察中的信息多。如果 $X_i,X_j$ 相关，我完全理解需要使用同时对完整统计数据进行操作的估计器，但为什么会出现这种情况当单个样本是 IID 时有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645203/why-can-we-get-better-global-estimators-in-the-asymptotic-regime-even-for-iid-r</guid>
      <pubDate>Wed, 17 Apr 2024 08:42:08 GMT</pubDate>
    </item>
    <item>
      <title>显示有偏见的 CRB 的标准做法</title>
      <link>https://stats.stackexchange.com/questions/645202/standard-practice-to-show-biased-crbs</link>
      <description><![CDATA[我在四参数估计方面遇到问题。我使用蒙特卡罗模拟（数值模拟）导出了估计参数的方差，并使用费舍尔信息矩阵的逆矩阵导出了理论参数的方差。
理论值和数值值存在差异。对于某些参数，数值方差可能比理论方差更小。我怀疑原因是估计量的偏差。我想计算有偏差的 CRB，以便它们可以进行公平的比较。最重要的是，我需要显示一些具有这些差异的参数扫描。
有偏差的CRB可以通过以下公式找到。
$$ \text{CRB}(\theta) = \text{diag}\{ \left[\mathbf{1} + \nabla_\theta \mathbb{B} (\theta) \right] \mathbf{I}^{-1}(\theta) \left[\mathbf{1} + \nabla_\theta \mathbb{B}(\theta) \right]^\text{ T}\}，$$
其中 $\mathbf{1}$ 是单位矩阵，$\mathbf{I}$ 是 Fisher 信息矩阵。 $\mathbb{B}(\theta)$ 是偏差向量，但 $\nabla_\theta \mathbb{B }(\theta)$ 是偏差梯度矩阵。
偏差可能来自以下因素：对数似然涉及的积分样本量不足 ($N$)、参数空间受限、优化器错误、对于我的问题，我认为我拥有所有这些，特别是 $N$ 不足和空间有限。 $\nabla_\theta \mathbb{B}(\theta)$ 的函数形式几乎是不可能的。然而，我可以看到有一些贝叶斯推理技术可以计算有偏差的 CRB，例如[1]。这超出了我的理解范围，而且有点复杂。
我想我可以使用数值偏差通过蒙特卡罗模拟获得偏差梯度。然而，它的计算成本非常昂贵。由于梯度是相对于参数的，并且我想要进行一些参数扫描，因此我需要对 $M^4 \times M_c$ 计算执行蒙特卡罗模拟优化器的参数，其中 $M$ 是一次参数扫描中的值数量，$M_c$ 是蒙特卡洛运行的次数。为每种情况准备模拟测量也需要一些时间。我使用 MATLAB 进行编码，并且只能并行化这些扫描之一。
是否有更聪明的方法来从概念上或通过编程策略获取有偏差的 CRB？我将不胜感激任何形式的帮助。
[1] C. L. Matson 和 A. Haji，“不平等约束估计量的有偏 Cramér-Rao 下界计算”，J. Opt。苏克。是。 A，卷。 23、没有。 11，第 2702–2713 页，2006 年，doi：10.1364/josaa.23.002702。]]></description>
      <guid>https://stats.stackexchange.com/questions/645202/standard-practice-to-show-biased-crbs</guid>
      <pubDate>Wed, 17 Apr 2024 08:24:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 copula 测量两组数据点的“相关性”</title>
      <link>https://stats.stackexchange.com/questions/645201/how-to-measuring-the-correlation-of-two-sets-of-datapoints-using-copula-s</link>
      <description><![CDATA[假设我有 2 组数据点 $(x_1,x_2,…,x_n)$, $(y_1 ,y_2,…,y_n)$ 这是两只不同股票的对数回报，$S^X$ 和 $S^Y$，我没有理由相信它们的日志返回是正态分布的，所以我想使用 copula 来衡量它们的相关性。根据定量
风险
McNeil 等人的管理，我们使用联结函数而不是相关性，因为存在以下 3 个谬误：

随机向量的边缘分布和成对相关性决定其联合分布。

对于给定的单变量分布 F1 和 F2 以及任何相关值 $\rho \in [−1, 1]$ 总是可以构造一个联合分布 $F$，边距 $F_1$ 和 $ F_2$ 和相关性 $\rho$。

对于房车 $X_1 \sim F_1$ 和 $X_2 \sim F_2$ 和对于给定的 $\alpha$，总和的分位数
当联合分布 $F 时，$F^{\leftarrow}_{X_1+X_2}(\alpha)$ 最大化$ 具有最大相关性。


实际上，我如何使用联结函数来衡量它们的相关性？
如果我采取$\Sigma=A^T A$
然后生成$$Z\sim N(0,P)$$
($\Sigma$ 是观测数据的协方差矩阵，$P$ 是对应的相关矩阵）
然后我有 $$X = A^T Z$$
然后对于选择的 ，他们的 cdfs
$ U = (\Phi(X_1), \Phi(X_2))$
其中 $\Phi$ 是标准正态 CDF。系词的分布由下式给出：
$$ \text{Prob}(U_1 \leq u_1, \ldots, U_d \leq u_d) = \Phi_P(\Phi^{-1}(u_1), \ Phi^{-1}(u_2)) $$
$\Phi_P$ 是我们数据的联合 CDF。
但是这里如何衡量转换后的相关性呢？我们如何从 $U$ 采样的 $u_1, u_2$ 中获取相关性。基本上生成的相关性与原始数据的皮尔逊相关性不同。
最后，如果我们从某个分布生成相关矩阵，则 CDF $\Phi_P$ 必须始终是该分布，但我们仍然可以选择任何分布$\Phi_1, Phi_2$？
即假设 $S^X$ 和 $S^Y$ 的对数返回的联合分布为t-分布。我们会发现 $S^X$ 呈指数分布且 $S^Y$ 呈正态分布的联结分散式。生成样本 $X_1$ 和 $X_2$ 后，我们进行采样
$$U \sim (\Phi_{exp. dist.}(X_1), \Phi_{norm. dist.}(X_2))$$&lt; /p&gt;
然后我们的联结函数具有分布：
$$ \text{Prob}(U_1 \leq u_1, U_2 \leq u_2) = \Phi_P(\Phi_{exp. dist.} ^{-1}(u_1 ), \Phi _{范数} ^{-1}(u_2))$$]]></description>
      <guid>https://stats.stackexchange.com/questions/645201/how-to-measuring-the-correlation-of-two-sets-of-datapoints-using-copula-s</guid>
      <pubDate>Wed, 17 Apr 2024 08:20:25 GMT</pubDate>
    </item>
    <item>
      <title>Resnet50中的[[1x1,64],[3x3,64],[1x1,256]]是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/645200/what-does-the-meaning-of-1x1-64-3x3-64-1x1-256-in-resnet50</link>
      <description><![CDATA[在ResNet50中，第一个Bottleneck（第二个​​卷积层）包含内核[[1x1,64]，[3x3,64]，[1x1,256]]。
而且我不太明白这个组合的含义。]]></description>
      <guid>https://stats.stackexchange.com/questions/645200/what-does-the-meaning-of-1x1-64-3x3-64-1x1-256-in-resnet50</guid>
      <pubDate>Wed, 17 Apr 2024 07:55:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用皂膜平滑器的交互项创建 GAM</title>
      <link>https://stats.stackexchange.com/questions/645197/how-to-create-a-gam-with-interation-term-for-a-soap-film-smoother</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645197/how-to-create-a-gam-with-interation-term-for-a-soap-film-smoother</guid>
      <pubDate>Wed, 17 Apr 2024 06:29:58 GMT</pubDate>
    </item>
    <item>
      <title>统计方法确定阈值</title>
      <link>https://stats.stackexchange.com/questions/645196/statistical-method-to-determine-threshold</link>
      <description><![CDATA[我有多个样品（包括一个对照样品）的每个细胞的增殖评分。我想确定在我的治疗样本中增殖的细胞相对于对照细胞的百分比是多少。对于如何进行有什么建议吗？我的想法是使用 Otsu 方法根据样本中细胞的增殖评分找到每个样本的客观阈值。这将找到一个增殖评分阈值，将细胞分为两组，增殖组和非增殖组。然后我可以计算该样本中正在增殖的细胞的百分比。我可以对包括对照在内的每个样本执行此操作，并将处理样本中的细胞增殖百分比与对照进行比较。这听起来合理吗？或者有更好的方法来解决这个问题吗？感谢任何想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/645196/statistical-method-to-determine-threshold</guid>
      <pubDate>Wed, 17 Apr 2024 04:36:36 GMT</pubDate>
    </item>
    <item>
      <title>从无向、未加权图中随机采样一个子图，“子图中每两个节点的距离至少为 3”的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/645193/sample-a-random-subgraph-from-an-undirected-unweighted-graph-whats-the-probab</link>
      <description><![CDATA[这可能是抽样理论或图论中的问题。我做了很多研究，但仍然没有找到有效的解决方案。
我知道一个简单的随机样本可以代表总体。现在我想知道当它受到社交网络的“限制”时它是否仍然有效，这意味着如果有两个节点的距离小于3，则不能选择它作为样本。我想知道在什么条件下，简单随机样本中每两个节点的距离至少为3的概率很高。
具体来说，考虑一个无向无权图 $G=(V,E)$，其中 $V=\ {1,\dots,n\}$ 是顶点集，E 是边集。考虑一个简单的随机样本 $S\subseteq V$，并让 $|S|$ 表示数字集合$S$。现在我们问：在什么条件下（比如对$|S|$的限制，$G$&lt;的模式/span&gt; 趋于无穷大，对 $G$ 的限制等），
$$P(d(i,j)\geq3,\forall i,j\in S) \to 1.$$
如果有非渐近性质就更好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/645193/sample-a-random-subgraph-from-an-undirected-unweighted-graph-whats-the-probab</guid>
      <pubDate>Wed, 17 Apr 2024 02:40:17 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用整个数据，IPW有效吗？</title>
      <link>https://stats.stackexchange.com/questions/645191/if-i-use-entire-data-the-ipw-is-effective</link>
      <description><![CDATA[当涉及到因果推理时，如果我使用整个总体数据，逆概率加权（IPW）仍然有效吗？
我可以访问整个人口数据，并且需要进行一些回归来调整一些混杂因素。
根据我的理解，IPW是通过模拟一个伪种群来模仿整个种群的数据，以实现可交换性。
因此，我认为针对混杂因素进行调整是可以的，但我仍然不确定 IPW 是否必要。]]></description>
      <guid>https://stats.stackexchange.com/questions/645191/if-i-use-entire-data-the-ipw-is-effective</guid>
      <pubDate>Wed, 17 Apr 2024 01:47:25 GMT</pubDate>
    </item>
    <item>
      <title>英文文本中每个单词有多少知识点？</title>
      <link>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</link>
      <description><![CDATA[人们常说，典型的英语文本可以最佳地压缩到每个单词 12 位左右。
然而，由于陈述相同事实的方式有很多种，因此典型文本中传达的事实知识每个字少于 12 位。我正在阅读的一篇 ML 论文提到了一个数值估计：
&lt;块引用&gt;
[4]
截至 2024 年 2 月 1 日，英语维基百科总共包含 45 亿个单词，请参阅 https://en.wikipedia。 org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database，访问于 2024 年 3 月。
据估计，英语教科书的非重叠内容总共不到160亿字，参见
备注 G.1。这总计 205 亿个单词，但我们认为它们包含的知识不到 140 亿位。

但没有提供参考资料，因此我的问题是：
英文文本中每个单词有多少知识点？这是如何得出的？]]></description>
      <guid>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</guid>
      <pubDate>Tue, 16 Apr 2024 21:31:36 GMT</pubDate>
    </item>
    <item>
      <title>我可以利用岭回归来更新新数据集的线性回归模型的系数吗？</title>
      <link>https://stats.stackexchange.com/questions/645181/can-i-utilize-ridge-regression-to-update-coefficients-of-a-linear-regression-mod</link>
      <description><![CDATA[我已经使用一个数据集拟合了线性回归模型。现在，我有另一个较小的数据集，我想用它来优化模型。我可以使用岭回归来更新这个新数据集的估计系数吗？或者您推荐一种更合适的方法？
编辑：在 John Madden 提供有用的答案之后，我使用 Python 实现了他的方法，如下所示，您是否发现此代码在反映该逻辑方面存在任何问题：
# 第 1 步：计算数据集 (X1, y1) 上的系数
beta1 = np.linalg.pinv(X1) @ y1
print(&quot;原始系数：&quot;, beta1)

# 步骤 2：计算数据集 (X2, y2) 上的残差
y_hat2 = X2 @ beta1
残差2 = y2 - y_hat2

# 步骤 3：对残差进行岭回归
ridge_reg = 山脊(alpha=alpha)
ridge_reg.fit(X2,残差2)
delta = ridge_reg.coef_

# 第四步：调整系数
β2 = β1 + δ
print(&quot;调整后的系数：&quot;, beta2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/645181/can-i-utilize-ridge-regression-to-update-coefficients-of-a-linear-regression-mod</guid>
      <pubDate>Tue, 16 Apr 2024 21:08:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么“systemfit”对 OLS 和 WLS 产生相同的结果？</title>
      <link>https://stats.stackexchange.com/questions/645173/why-does-systemfit-yield-identical-results-for-ols-and-wls</link>
      <description><![CDATA[我正在使用 R 中的 systemfit 包估计一个看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我使用两种替代估计方法：普通最小二乘 OLS (method=“OLS”) 和加权最小二乘 WLS (method=“WLS”)，如下所示在 &lt; 的第 2.1 节（第 3-4 页）中讨论代码&gt;systemfit小插图。我从两者中得到相同的点估计和标准误差。系数的协方差矩阵也相同。这让我很困惑。标准误差和更一般地说，系数的协方差矩阵不应该有所不同吗？
问题：为什么 systemfit 对 method=&quot;OLS&quot; 和 method=&quot;WLS&quot;&lt; 产生相同的结果/代码&gt;？
库(systemfit)

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N), ncol=N); colnames(x) &lt;-paste0(“x”, 1:N) # 生成回归量
dummy &lt;- c(rep(0, n-m), rep(1, m)) # 生成一个公共回归器
x &lt;- cbind(x, dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N), ncol=N); colnames(y) &lt;- Paste0(“y”, 1:N) # 因变量的占位符
for (i in 1:N) {
  y[, i] &lt;- i + sqrt(i)*x[, i] - i*虚拟 + y[, i]*15*sqrt(i)
  # y[, i] 是 x[, i] 和虚拟变量的线性函数，
  # 加上一个带有方程特定方差的误差项 - 这正是 WLS 的用途
}
data1 &lt;- as.data.frame(cbind(y, x)) # 创建所有数据（y和x）的数据框

# 创建模型方程
eqSystem &lt;- 列表()
for (i in 1:N) {
  eqSystem[[i]] &lt;-
    as.formula(分配(paste0(“eq”, i),
                      value=paste0(&quot;y&quot;, i, &quot;~ x&quot;, i, &quot;+ dummy&quot;))) # 定义 SUR 的线性方程
}

# 使用 `method=&quot;OLS&quot;` 和 `method=&quot;WLS&quot;` 估计模型
m1 &lt;- systemfit(公式=eqSystem, 方法=“OLS”, 数据=data1)
m2 &lt;- systemfit(公式=eqSystem, 方法=“WLS”, 数据=data1)
摘要（m1，residCov=FALSE，方程=FALSE）
摘要（m2，residCov=FALSE，方程=FALSE）
m1$coefCov # 系数的协方差矩阵
m2$coefCov # 系数的协方差矩阵
]]></description>
      <guid>https://stats.stackexchange.com/questions/645173/why-does-systemfit-yield-identical-results-for-ols-and-wls</guid>
      <pubDate>Tue, 16 Apr 2024 19:57:43 GMT</pubDate>
    </item>
    <item>
      <title>用于跨多个地点的两组之间的纵向害虫调查的正确回归</title>
      <link>https://stats.stackexchange.com/questions/645160/correct-regression-to-use-for-longitudinal-pest-survey-between-two-groups-across</link>
      <description><![CDATA[数据：我们有 3 个地点，总共生长 36 种植物：每个地点包含 12 种植物（6 种属于 spp1，6 种属于 spp2）。每个植物的大小和地理位置是已知的。每 10-14 天检查一次每株植物的害虫丰度（原始计数），持续 6 个月。因此，每株植物大约有 18 个害虫计数数据点。

注意：2 个地点相距约 500m，而第 3 个地点距离其他 2 个地点 8 公里。在每个地块内，植物分布总体上有些均匀，但在任何给定地块内肯定存在一些明显的样本植物聚集（例如，2 个样本植物相距 &lt;5m，而第 3 个样本植物相距可能为 50m）。

假设：我们会在 spp2 上捕获比 spp1 更多的害虫
模型选择：因此，我们显然需要某种回归（PestAbundance ~ PlantType），但它也可能包含大小和地理位置。

问题：

将“重复措施”纳入其中的最佳方式是什么？这项研究的结构？这是否仅仅需要一个混合效应模型？如果是这样，我们是否有足够的数据来构建这个模型并期望可靠的系数估计？（特别是如果试图纳入规模和地理位置的影响）。

设计该模型的合适方法是什么？ （即，我们如何整合对 36 株植物进行重复测量的数据的“结构”？


将地理定位（纬度和经度）合并到此模型中的最佳方法是什么？我们应该将纬度/经度合并为两个单独的变量，还是有一些优雅的方法来组合它们？（特别是在不削弱我们使用当前数据大小运行可靠测试的能力的情况下）




奖励：R 中的任何指导总是有帮助的:) [在这种情况下nlme 或 lme4 ？]]]></description>
      <guid>https://stats.stackexchange.com/questions/645160/correct-regression-to-use-for-longitudinal-pest-survey-between-two-groups-across</guid>
      <pubDate>Tue, 16 Apr 2024 18:33:58 GMT</pubDate>
    </item>
    <item>
      <title>对于从业者来说，什么时候理解 CI 很重要？</title>
      <link>https://stats.stackexchange.com/questions/644998/when-is-it-important-for-a-practitioner-to-understand-cis</link>
      <description><![CDATA[我有一位医生朋友，他问我有关统计的问题。他对一些事情感到困惑，例如置信区间 (CI) 的定义及其复杂性。例如，他发现以下内容令人困惑：表示感兴趣的参数$\theta$。在绘制数据之前，
$$
\mathbb{P}(\theta \in CI) = 1-\alpha。
$$
但是，一旦提取数据，就不再有任何概率，真实参数要么在 CI 内，要么不在 CI 内。
我告诉我的朋友，他认为“参数在 CI 内部的概率为 $1-\alpha$”可能是可以的。但我可能错了。所以我正在寻找一个例子：
对于从业者（在本例中为医生）来说，什么时候完全理解 CI 的定义很重要？
一个误解 CI 可能导致错误临床决策的例子是理想的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644998/when-is-it-important-for-a-practitioner-to-understand-cis</guid>
      <pubDate>Sun, 14 Apr 2024 17:41:14 GMT</pubDate>
    </item>
    </channel>
</rss>