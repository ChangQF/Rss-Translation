<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 18:24:45 GMT</lastBuildDate>
    <item>
      <title>使用因变量变化为零的测试数据集来解决面板数据的二元分类问题</title>
      <link>https://stats.stackexchange.com/questions/657891/using-a-test-dataset-with-zero-variation-in-the-dependent-variable-for-binary-cl</link>
      <description><![CDATA[对于一个大学项目，我试图提出一个概率模型，该模型使用各种经济和金融指标的面板数据集来估计给定时间内经济衰退的概率。
根据我拥有的数据并使用标准的 80/20 训练/测试分割，因变量（表示是否发生经济衰退的虚拟变量）的值在整个测试期间将为 0。
从理论上讲，即使因变量在此期间没有变化，我是否仍然可以使用此测试期？
我理解在用于估计模型的训练期间，因变量和自变量都需要有变化。但这肯定不是测试期的要求，因为我只是使用已经估计的模型进行预测，即使任何对经济衰退的预测都是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657891/using-a-test-dataset-with-zero-variation-in-the-dependent-variable-for-binary-cl</guid>
      <pubDate>Tue, 26 Nov 2024 17:46:17 GMT</pubDate>
    </item>
    <item>
      <title>以三进制为单位的熵有没有一个常用的名称？</title>
      <link>https://stats.stackexchange.com/questions/657889/is-there-a-commonly-used-name-for-the-units-of-entropy-measured-with-base-three</link>
      <description><![CDATA[以三进制为基数测量的熵单位是否有一个常用名称（例如，对于状态 $-1, 0, 1$）：
$$
H=-\sum_ip_i\log_3p_i,$$
类似于以 $2$ 和 $e$ 为基数的比特和 NAT？]]></description>
      <guid>https://stats.stackexchange.com/questions/657889/is-there-a-commonly-used-name-for-the-units-of-entropy-measured-with-base-three</guid>
      <pubDate>Tue, 26 Nov 2024 17:22:38 GMT</pubDate>
    </item>
    <item>
      <title>我的研究标题是否决定了我将用于分析的模型？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/657887/is-my-tittle-of-research-is-determine-my-model-that-i-will-used-in-analysis</link>
      <description><![CDATA[我的研究题目是确定我将用于分析的模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657887/is-my-tittle-of-research-is-determine-my-model-that-i-will-used-in-analysis</guid>
      <pubDate>Tue, 26 Nov 2024 16:46:45 GMT</pubDate>
    </item>
    <item>
      <title>在梯度递减区域中“膨胀”学习率以进行 NN 训练</title>
      <link>https://stats.stackexchange.com/questions/657886/inflating-learning-rates-in-diminishing-gradient-areas-for-nn-training</link>
      <description><![CDATA[在神经网络训练中，如今隐藏层中的 tanh 和 sigmoid 激活函数被避免使用，因为它们往往容易“饱和”。这意味着，如果插入 tanh/sigmoid 的 x 值非常大或非常小，则该值处的导数将趋向于零，因此我们从该梯度推导出的神经网络的变化也将很小。

但是——我们通过将该梯度乘以学习率来对我们的 NN 进行更改。如果“理想”梯度导数函数就是权重本身（即线性函数的导数），人们为什么不人为地提高学习率以获得更饱和的导数值，以便这些神经元能够轻松改变同时保留梯度的方向？]]></description>
      <guid>https://stats.stackexchange.com/questions/657886/inflating-learning-rates-in-diminishing-gradient-areas-for-nn-training</guid>
      <pubDate>Tue, 26 Nov 2024 16:45:50 GMT</pubDate>
    </item>
    <item>
      <title>比较两个方差</title>
      <link>https://stats.stackexchange.com/questions/657884/compare-two-variances</link>
      <description><![CDATA[我正在阅读这篇论文
我很难理解第 6 节：线性时间统计和测试。
一开始，他们声称 $\text{MMD}^2_l$ 的方差高于 $\text{MMD}^2_u$（我们稍后会明确看到这一点）。&#39;但是，即使在阅读了剩余部分之后，我也不明白原因
我猜它来自那些行

假设 $0 &lt; \mathbb{E}(​​h^2) &lt; \ infty $。然后$\text{MMD}_l^2$在分布上收敛到高斯分布，根据
$$m^{\frac{1}{2}} \left( \text{MMD}_l^2 - \text{MMD}^2[\mathcal{F}, p, q] \right) \overset{D}{\to} \mathcal{N}(0, \sigma_l^2)$$
其中
$$
\sigma_l^2 = 2 \left[ \mathbb{E}_{z, z&#39;} h^2(z, z&#39;) - \left( \mathbb{E}_{z, z&#39;} h(z, z&#39;) \right)^2 \right]$$
其中我们使用简写 $\mathbb{E}_{z, z&#39;} := \mathbb{E}_{z, z&#39; \sim p \times q}$
2 的因子出现是因为我们仅对 $\lfloor m/2 \rfloor$ 个观测值取平均值。将此渐近分布与 $\mathcal{H}_A$ 下的二次时间统计 $\text{MMD}_u^2$ 进行比较是有益的，此时 $m = n$。在这种情况下，$\text{MMD}_u^2$ 根据以下公式在分布上收敛到高斯分布
$$m^{\frac{1}{2}} \left( \text{MMD}_u^2 - \text{MMD}^2[\mathcal{F}, p, q] \right) \overset{D}{\to} \mathcal{N}(0, \sigma_u^2)$$
其中
$$
\sigma_u^2 = 4 \left( \mathbb{E}_z \left[ \left( \mathbb{E}_{z&#39;} h(z, z&#39;) \right)^2 \right] - \left( \mathbb{E}_{z, z&#39;} h(z, z&#39;) \right)^2 \right) \quad \text{(Serfling, 1980, 第 5.5 节)}.$$
因此，对于 $\text{MMD}_u^2$，渐近方差（按比例）为 $\mathbb{E}_z[h(z, z&#39;)]$ 的方差，而对于 $\text{MMD}_l^2$，渐近方差为 $\text{Var}_{z, z&#39;}[h(z, z&#39;)]$

我对他们如何证明他们的陈述感到很困惑。我希望你能明确地向我解释一下，因为我对这个领域还比较陌生。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657884/compare-two-variances</guid>
      <pubDate>Tue, 26 Nov 2024 16:30:44 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 Beta 分布和二项分布来模拟 Beta 二项分布的随机数？</title>
      <link>https://stats.stackexchange.com/questions/657883/is-it-possible-to-simulate-random-numbers-from-beta-binomial-distribution-using</link>
      <description><![CDATA[在我看来，Beta-二项分布可以被认为是这样的：

我们从 beta$(a,b)$ 中模拟一个随机数... 将此数字称为 $p_1$
然后我们采用成功概率为 $p_1$ 的二项分布，并查看在 $n$ 次试验中有多少次成功

我尝试在 R 中执行此操作：
library(tidyverse)

generate_beta_samples &lt;- function(n_samples, alpha, beta) {
p_values &lt;- rbeta(n_samples, alpha, beta)

data.frame(
simulation = 1:n_samples,
p = p_values
)
}

generate_binomial_samples &lt;- function(p_df, n_trials) {
p_df %&gt;%
mutate(
successes = map_dbl(p, ~rbinom(1, size = n_trials, prob = .x))
)
}

n_simulations &lt;- 10000
n_trials &lt;- 20
alpha &lt;- 2
beta &lt;- 5

set.seed(123)

beta_samples &lt;- generate_beta_samples(n_simulations, alpha, beta)

#二项式样本
results &lt;- generate_binomial_samples(beta_samples, n_trials)

p1 &lt;- ggplot(results, aes(x = p)) +
geom_histogram(bins = 50, fill = &quot;blue&quot;, alpha = 0.6) +
geom_vline(xintercept = alpha/(alpha + beta), 
color = &quot;red&quot;, linetype = &quot;dashed&quot;) +
labs(
title = &quot;步骤 1：Beta 随机变量的分布&quot;,
subtitle = paste0(&quot;Beta(&quot;, alpha, &quot;,&quot;, beta, &quot;)&quot;),
x = &quot;p&quot;,
y = &quot;Count&quot;
) +
theme_minimal()

p2 &lt;- ggplot(results, aes(x = successes)) +
geom_histogram(bins = n_trials + 1, fill = &quot;green&quot;, alpha = 0.6) +
labs(
title = &quot;步骤 2：二项式成功分布&quot;,
subtitle = paste0(n_trials, &quot; 每个 p 值的试验&quot;),
x = &quot;成功次数&quot;,
y = &quot;计数&quot;
) +
theme_minimal()


我还尝试查看联合分布：
ggplot(results, aes(x = p, y = successes)) +
geom_bin2d(bins = 30) +
scale_fill_viridis_c(option = &quot;magma&quot;, name = &quot;Count&quot;) +
labs(
title = &quot;Joint Distribution of Beta Values and Binomial Successes&quot;,
subtitle = paste0(&quot;Beta(&quot;, alpha, &quot;,&quot;, beta, &quot;) and Binomial(n=&quot;, 
n_trials, &quot;) from &quot;, n_simulations, &quot;模拟”），
x = “p（Beta 随机变量）”，
y = “成功次数（二项式结果）”
) +
theme_minimal() +
scale_x_continuous(limits = c(0, 1)) +
scale_y_continuous(limits = c(0, n_trials)) +
theme(panel.grid.minor = element_line(color = &quot;gray90&quot;),
panel.grid.major = element_line(color = &quot;gray85&quot;))


这是不使用预建 R 函数来模拟 Beta-Binomial 的正确方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657883/is-it-possible-to-simulate-random-numbers-from-beta-binomial-distribution-using</guid>
      <pubDate>Tue, 26 Nov 2024 16:24:45 GMT</pubDate>
    </item>
    <item>
      <title>对于 PLS 模型拟合，如何计算 R2VX、R2VY 以及累积 R2VX、R2VY？</title>
      <link>https://stats.stackexchange.com/questions/657880/for-a-pls-model-fit-how-can-i-calculate-r2vx-r2vy-and-the-cumulative-r2vx-r2</link>
      <description><![CDATA[根据Eriksson等人2013年出版的《多变量和巨变量数据分析基本原理与应用》一书，衡量模型性能的重要指标包括$R2VX$和$R2VY$，其文本定义为“X/Y变量变异的解释分数”数学上为：
$$ 
R2VX = 1 - \frac{ \Sigma_i e_{i,k}^2 } { \Sigma_i e_{i,0}^2 }
$$
其中 $e_{i,k}$ 表示 $k$ 分量模型的 $i$ 个 X 残差。
类似地，
$$ 
R2VY = 1 - \frac{ \Sigma_i f_{i,k}^2 } { \Sigma_i f_{i,0}^2 }
$$
其中$f_{i,k}$ 表示 $k$ 个组件模型的 $i$ 个 Y 残差。
我想出了以下代码来计算 $R2VY$：
library(pls)

fit = plsr(hp ~ ., 
segments = 10,
scale=T, 
center=T,
validation = &quot;CV&quot;,
method = &quot;simpls&quot;,
data=mtcars)

## 对于组件 1
R2VX = 1 - sum(residuals(fit)[,,1]^2)/sum((mtcars$hp - mean(mtcars$hp))^2)
R2VX 

# 与 R2() 函数的结果匹配
R2(fit)

但是，我不清楚应该如何计算 $R2VX$。我甚至不确定如何提取 X 变量的残差。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657880/for-a-pls-model-fit-how-can-i-calculate-r2vx-r2vy-and-the-cumulative-r2vx-r2</guid>
      <pubDate>Tue, 26 Nov 2024 15:42:27 GMT</pubDate>
    </item>
    <item>
      <title>正态分布之间的柯西-施瓦茨散度</title>
      <link>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-normal-distributions</link>
      <description><![CDATA[我试图使用本文中正态分布混合之间的柯西-施瓦茨散度的推导来推导两个多元正态分布之间的柯西-施瓦茨散度：https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b6201d3fd08e96ccbdba564ab33e9e88853d103e
考虑$p(x) = \mathcal{N}(x|\mu,\Lambda^{-1})=\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\mu)^{\top}\Lambda(x-\mu)\Big)$ 和 $q(x) = \mathcal{N}(x|\nu,\Omega^{-1})=\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\nu)^{\top}\Omega(x-\nu)\Big)$。
使用论文中的公式柯西-施瓦茨散度可以简化为：
\begin{align}
D_{CS}(p,q) &amp;=-\log\Big(\mathcal{N}\big(\mu|\nu,(\Lambda^{-1}+\Omega^{-1}\big)\Big) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= -\log\Bigg(\frac{\big|\Lambda^{-1}+\Omega^{-1}\big|^{-1/2}}{(2\pi)^{D/2}}\Bigg) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= \frac{1}{2}\log\Big(\big|\Lambda^{-1}+\Omega^{-1}\big|\Big) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{4}\log\big(|\Lambda|\big) + \frac{1}{4}\log\big(|\Omega|\big)
\end{align&gt;
但是，如果我将 $p$ 插入 $q$，我会得到：
\begin{align}
D_{CS}(p,p)= \frac{1}{2}\log\Big(\big|2\Lambda^{-1}\big|\Big) + \frac{1}{2}\log\big(|\Lambda|\big) = \frac{D}{2}\log(2) \neq0
\end{align&gt;
我哪里犯了错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-normal-distributions</guid>
      <pubDate>Tue, 26 Nov 2024 15:19:24 GMT</pubDate>
    </item>
    <item>
      <title>聚类方法之前先进行 SVD（无降维）</title>
      <link>https://stats.stackexchange.com/questions/657878/svd-before-clustering-method-no-dimensionality-reduction</link>
      <description><![CDATA[在应用聚类方法之前将 SVD 应用于数据集是否在性能方面有意义？我的意思是：这样做是否有统计上的原因？它是否取决于方法，取决于维数？或者也许没有办法概括这一点？
我指的是仅应用 SVD，而不是完整的 PCA（即：没有降维）]]></description>
      <guid>https://stats.stackexchange.com/questions/657878/svd-before-clustering-method-no-dimensionality-reduction</guid>
      <pubDate>Tue, 26 Nov 2024 15:18:27 GMT</pubDate>
    </item>
    <item>
      <title>如何解读多项模型的摘要？</title>
      <link>https://stats.stackexchange.com/questions/657885/how-to-interpret-the-summary-of-a-multinomial-model</link>
      <description><![CDATA[我有一个模型，其中有 5 个多项式级别，编码为 0 到 4：
library(mgcv)

gam = gam(
list(
level ~generation * gender + s(long, lat) + s(id, bs = &quot;re&quot;),
~generation * gender + s(long, lat) + s(id, bs = &quot;re&quot;),
~generation * gender + s(long, lat) + s(id, bs = &quot;re&quot;),
~generation * gender + s(long, lat) + s(id, bs = &quot;re&quot;)
),
data = data,
family = multinom(K = 4)
)

summary(gam)

如何解释摘要？：
Family: multinom 
Link 函数：

公式：
级别 ~ 代数 * 性别 + s(long, lat) + s(id, bs = &quot;re&quot;)
~代数 * 性别 + s(long, lat) + s(id, bs = &quot;re&quot;)
~代数 * 性别 + s(long, lat) + s(id, bs = &quot;re&quot;)
~代数 * 性别 + s(long, lat) + s(id, bs = &quot;re&quot;)

参数系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -2.2018 0.2435 -9.042 &lt; 2e-16 ***
generationYounger -0.2989 0.2890 -1.034 0.30096 
genderFemale -0.0975 0.2870 -0.340 0.73403 
generationYounger:genderFemale 0.3714 0.4097 0.907 0.36460 
（截距）。1 -3.5076 0.3136 -11.185 &lt; 2e-16 ***
generationYounger.1 -0.2449 0.4032 -0.607 0.54353 
genderFemale.1 0.3558 0.3952 0.900 0.36793 
generationYounger:genderFemale.1 -1.0224 0.6592 -1.551 0.12088 
[...]

多项式模型将从 1 到 x 的每个级别与参考级别 0 进行比较，因此有 x 个公式。摘要中没有扩展的系数是否对应于级别 1 与级别 0 的比较，以及 .1 对应于级别 2 与级别 0 的比较等？那么以下关系正确吗？：



级别编号
模型编码
摘要中的扩展




1
0
[不在摘要]


2
1
[无]


3
2
.1


4
3
.2


5
4
.3



并且 generationYounger:genderFemale.1 是否对应于 Young 和 Female 的效果表现为与 Older、Male 和 0 级（全局；与参考级别的截距）相比的 2 级，或与 Older 相比的 2 级，男性，并且级别 2（其自身拦截）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657885/how-to-interpret-the-summary-of-a-multinomial-model</guid>
      <pubDate>Tue, 26 Nov 2024 14:48:49 GMT</pubDate>
    </item>
    <item>
      <title>计算贝叶斯后验与重复对比的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/657877/best-practice-to-compute-contrasts-from-bayesian-posterior-with-repeats</link>
      <description><![CDATA[我有来自参数 ($\theta$) 后验分布的样本 ($i$)，针对两个不同条件 $a$ 和 $b$。
两个条件 $\theta_{\delta i}$ 之间的后验差异的样本只需从条件 a 中减去条件 b 的后验：($\theta_{\delta i} = \theta_{bi} - \theta_{ai}$)。
但是，我有来自每个条件 $r$ 次重复的后验样本，即$\theta_{ai}^1, \theta_{ai}^2, ... \theta_{ai}^r$，以及 $\theta_{bi}^1, \theta_{bi}^2, ... \theta_{bi}^r$。
我知道，理想情况下，要计算 $\theta_{\delta}$，我应该有一个分层公式，其中每个条件重复的效果共享一些超先验，然后我只需使用 $\theta_a$ 和 $\theta_b$ 的超先验样本来计算对比度。
但是，如果我要处理的只是来自重复（例如 $\theta_{ai}^1, \theta_{ai}^2, ... \theta_{ai}^r$），计算 $\theta_{\delta}$ 样本的最佳方法是什么？
我考虑过的选项：

配对重复。即计算$\theta_{\delta i}^1 = \theta_{bi}^1 - \theta_{ai}^1$, $\theta_{\delta i}^2 = \theta_{bi}^2 - \theta_{ai}^2$等...然后将所有$\theta_{\delta i}^1, \theta_{\delta i}^2$, ...堆叠在一起以创建$\theta_{\delta i}$。这很好，但如果每个条件的重复次数不同，则不会使用所有重复。
与 1 类似，但不是对每个条件制作 $\theta_i$ 的重复对，而是计算所有成对的重复组合。这样，所有条件的所有重复都会被使用，并且所有重复都会相互比较。但重复次数较少的条件的后验样本被更多地使用，这感觉不对。

还有其他方法可以做到这一点吗？什么是最好的？（或者最不坏的？）
感谢您的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/657877/best-practice-to-compute-contrasts-from-bayesian-posterior-with-repeats</guid>
      <pubDate>Tue, 26 Nov 2024 14:36:27 GMT</pubDate>
    </item>
    <item>
      <title>如何验证和报告具有 family = quasibinomal 的 glm 的结果？</title>
      <link>https://stats.stackexchange.com/questions/657876/how-to-verify-and-report-results-from-a-glm-with-family-quasibinominal</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657876/how-to-verify-and-report-results-from-a-glm-with-family-quasibinominal</guid>
      <pubDate>Tue, 26 Nov 2024 14:29:47 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中执行比例分层抽样的正确方法？</title>
      <link>https://stats.stackexchange.com/questions/657875/correct-way-to-perform-proportional-stratified-sampling-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657875/correct-way-to-perform-proportional-stratified-sampling-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 14:20:30 GMT</pubDate>
    </item>
    <item>
      <title>我如何改进我的扩散模型？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657873/how-can-i-improve-my-diffusion-model</link>
      <description><![CDATA[我一直在研究一个受 2020 年 DDPM 论文启发的扩散模型。它运行良好，但我不明白为什么它没有表现得更好。
情况如下：

在 MNIST 上，该模型的 FID 达到 15 左右，您可以识别这些数字。
在 CIFAR-10 上，大多数时候很难分辨出生成了什么。
在 CelebA 上，有些脸还可以，但大多数最终看起来像扭曲的怪物。

我尝试调整学习率、批量大小和其他超参数，但没有产生显着的变化。我从头开始构建了 UNet 架构和 loss+sample 函数，因此我怀疑那里可能存在问题，但经过几个小时的调试，我仍然找不到任何明显的东西。
我的模型应该表现得比这更好吗？我应该专注于进一步调整或调试哪些特定领域？有人可以看看我的代码并提供反馈或建议吗？
这是 github 上项目的链接：https://github.com/juliuseg/Diffusion_plz_help]]></description>
      <guid>https://stats.stackexchange.com/questions/657873/how-can-i-improve-my-diffusion-model</guid>
      <pubDate>Tue, 26 Nov 2024 13:39:01 GMT</pubDate>
    </item>
    <item>
      <title>UMP 无偏测试的定义到底是什么？</title>
      <link>https://stats.stackexchange.com/questions/657870/what-exactly-is-the-definition-of-a-ump-unbiased-test</link>
      <description><![CDATA[我正在解答 Hogg 和 McKean 的《数理统计学导论》第 8.3 节的练习。&amp;我无法继续，因为作者没有正式定义 UMPU 检验，尽管他们已经给出了 UMP 检验的定义。
上下文：在练习 $8.3.8,$ 中，作者要求我们证明用于测试 $H_0:\theta = \theta_0$ 对 $H_1:\theta \neq \theta_0$ 的 LRT 原理导致不等式 $\lvert \overline{x}-\theta_0\rvert \geq c,$ 其中 $\overline{x}$ 是来自 $N(\theta,1),$ 的随机样本的实际平均值，其中 $\theta = \theta_0$ class=&quot;math-container&quot;&gt;$\theta_0$ 已指定。然后他们问

(a) 这是 $H_0$ 对 $H_1$ 的一致最强检验吗？
(b) 这是 $H_0$ 对 $H_1$ 的一致最强无偏检验吗？

事实上，在文中，作者已经表明，对于这种双面假设，没有 UMP 检验。也有 SE 帖子（如 这个）显示了这一点。对我来说，问题是部分 (b)。
UMP 无偏 测试的定义到底是什么？我在这里卡住了，因为文本中没有对此的正式定义。只有一行说

那里表明，对于这种情况不存在 UMP 测试。如果我们将注意力限制在无偏测试类别上（定义 $8.1.2$），那么就可以构建最佳测试理论；参见 Lehmann ($1986$)。

定义 $8.1.2$ 是在 我之前的一篇文章中给出的，其中基本上说，如果 $\theta \in \omega_1$，即备选参数集，则 $P_\theta(X \in C) \geq \alpha,$ 其中 $C$ 临界区域，级别为 $\alpha$。如果 UMP 测试是大小为 $\alpha$ 的 最佳临界区域，用于针对 $H_1$ 中的每个简单假设测试 $H_0$，则 UMP 测试是由此临界区域定义的测试。
我的问题：UMPU 测试的精确数学定义到底是什么？我们究竟应该为这道练习题的 (b) 部分展示什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657870/what-exactly-is-the-definition-of-a-ump-unbiased-test</guid>
      <pubDate>Tue, 26 Nov 2024 12:44:23 GMT</pubDate>
    </item>
    </channel>
</rss>