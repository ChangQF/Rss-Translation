<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 05 Apr 2025 18:21:33 GMT</lastBuildDate>
    <item>
      <title>转换凸壳顶点重量以均匀分布</title>
      <link>https://stats.stackexchange.com/questions/663559/transform-convex-hull-vertex-weights-for-uniform-distribution</link>
      <description><![CDATA[给定一个 $ n $   - 维二等凸面由 $ m $  vertices  $ v $ v $  \ le n \ le 10 $ ，我想生成 $ p $ 船体中包含的随机点，并通过船体体积尽可能均匀地分布。  $ p $ 可能是成千上万。
生成这些点的快速方法是产生一个随机的权重矩阵 $ w $  shape  $（p，m）$ ，其中每一行都是正常且均匀分布的；然后由于 $ v $  is  $（m，n）$ ，我可以得到product  $ r = wv $ 具有一些正确的特征：

所有要点肯定会包含在船体中
它是随机的

但是，它绝对不是均匀分布的；分布趋向于中心：

更好的一个步骤是而是 $ w $ ，使用例如。
  $$
w&#39;_ {ij}：=
\ frac {w_ {ij}^{ -  1.5}}
{
\ sum_j {w_ {ij}^{ -  1.5}}}
}
$$  
  这显然也不是均匀分布的（它显示了那些类似射线的区域接近顶点），但实际上对于我的应用来说足够均匀。我的问题是：
在 $ n $  dimensions的一般性时，有什么重量变换（如果有的话）能够提高统一性？
相关
 
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663559/transform-convex-hull-vertex-weights-for-uniform-distribution</guid>
      <pubDate>Sat, 05 Apr 2025 17:53:11 GMT</pubDate>
    </item>
    <item>
      <title>在使用R的GAMM4时，如何获得包含随机效应和更光滑效果的残留物？</title>
      <link>https://stats.stackexchange.com/questions/663557/how-to-get-residuals-that-include-both-random-effects-and-smoother-effects-when</link>
      <description><![CDATA[使用R的GAMM4包装的GAMM4函数拟合了广义的加性混合效应模型后，可以基于更平滑的拟合度（GAM）或基于广义线性混合效应（MER）获得两种类型的残差，（i）。  这是一个示例：
 fit3＆lt; -gamm4（protos〜mass〜mass+frass，random =〜（1 | year）+（1 | nest），data = blue.tits，family，family =＆quort; poisson; quisson;
残差（fit3 $ gam）
残差（fit3 $ mer）
我的理解（？）是
 fit3 $ gam 
包括固定效果和平滑效果，但不包括随机效果，而
fit3 $ mer
包括固定和随机效果，但不包括平滑效果。  如果是这样，那么我如何获得包括固定效果，随机效应和平滑效果的（响应）残差？]]></description>
      <guid>https://stats.stackexchange.com/questions/663557/how-to-get-residuals-that-include-both-random-effects-and-smoother-effects-when</guid>
      <pubDate>Sat, 05 Apr 2025 17:10:51 GMT</pubDate>
    </item>
    <item>
      <title>在Cox pH模型中使用依赖时间的分类协变量作为阶层是有意义的</title>
      <link>https://stats.stackexchange.com/questions/663555/does-it-make-sense-to-use-time-dependent-categorical-covariates-as-strata-in-cox</link>
      <description><![CDATA[在COX比例危害模型中，我想控制的婚姻状况有变化的协变量，这是绝对的，但是我使用的数据已经在足够长的时间内，婚姻状况会随着时间而变化。我使用时间常数的协变量（例如性别阶层）没有问题，但是我不确定是否也将婚姻状况作为阶层使用是有意义的，因为它会有所不同。当然，从数学上讲，这没问题，但是如果统计学上有意义地在非参数基线危险之间跳动，随着婚姻状况的变化，我有点不安。它与我对Cox模型的理解有关，该模型随着时间的推移会加速或减速基线危害功能。 
您的想法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/663555/does-it-make-sense-to-use-time-dependent-categorical-covariates-as-strata-in-cox</guid>
      <pubDate>Sat, 05 Apr 2025 14:12:41 GMT</pubDate>
    </item>
    <item>
      <title>在面板VECM估计中不遵守模型诊断测试</title>
      <link>https://stats.stackexchange.com/questions/663554/failure-to-comply-with-model-diagnostics-test-in-panel-vecm-estimation</link>
      <description><![CDATA[我有一个不平衡的面板（n = 39，t = 14）。我的目的是调查特定于公司特定变量和公司风险之间的长期和短期因果关系。根据非平稳性的发现和协调关系的存在，我进行了VECM估计，并具有两个依赖和所有内源回归因子的滞后。我正在使用Eviews 12学生精简版。
长期和短期因果关系与现有文献广泛一致。但是，模型诊断测试揭示了串行自相关的存在，尽管使用了更深层次的滞后（最多6个滞后，即使这几乎没有实践意义）。相反，使用更深的滞后使因果关系微不足道。下面附上的是使用所有变量的最多第二，第三和第6个滞后的自相关LM测试结果。
    
  我还尝试了VECM框架中的其他回归器，以解决省略的变量偏差。但是，连续自相关残留的问题仍然存在。我非常感谢关于我出错的地方或解决问题的任何解决方案的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/663554/failure-to-comply-with-model-diagnostics-test-in-panel-vecm-estimation</guid>
      <pubDate>Sat, 05 Apr 2025 13:13:51 GMT</pubDate>
    </item>
    <item>
      <title>如何比较来自同一组评估者的两个Kappa统计数据，并在两个不同的条件下对同一受试者进行评分？</title>
      <link>https://stats.stackexchange.com/questions/663540/how-to-compare-two-kappa-statistics-from-the-same-group-of-raters-rating-the-sa</link>
      <description><![CDATA[是否有一种统计方法可以比较来自同一评估者的两个KAPPA统计数据，并将同一受试者评级，但在两个不同的条件下（低场均与高场强MRI）？我们无法检查这些因样本的置信区间重叠。]]></description>
      <guid>https://stats.stackexchange.com/questions/663540/how-to-compare-two-kappa-statistics-from-the-same-group-of-raters-rating-the-sa</guid>
      <pubDate>Sat, 05 Apr 2025 11:28:54 GMT</pubDate>
    </item>
    <item>
      <title>分析整个数据范围内不统一的单调关系-Pearson＆Kendall's Tau不合适</title>
      <link>https://stats.stackexchange.com/questions/663539/analysing-a-monotonic-relationship-that-isnt-uniform-across-the-whole-range-of</link>
      <description><![CDATA[我的假设（在绘制散点图之前）是一个较高的数字（x轴）会导致更高的％增益（y轴），但没有假设线性（单调关系）。
从散点图中，我观察到的是从0-50起完全没有关系，但是一旦x轴增加了50以上，它似乎会表现出某种正相关关系。尤其是从上方的75起，相应的y轴值都是正。
我尝试使用Pearson的相关性和Kendall的Tau，但它似乎并没有显示出任何具有统计意义的东西/似乎没有显示出单调效应（尽管50岁以上，但看着
散点图似乎确实具有某种单调效应）。在整个数据范围内，这种关系似乎并不逐渐或统一。
我还可以使用哪些其他严格的统计工具来确认我的假设/确认在75（或50）以上的X轴值（y轴）上（y轴）上的X轴值在统计学上显着发生？
我的数据（文本文件在下面）：
https://jumpshare.com/s/ZTSMqA4Lrl9IASKQatHJ
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/663539/analysing-a-monotonic-relationship-that-isnt-uniform-across-the-whole-range-of</guid>
      <pubDate>Sat, 05 Apr 2025 11:20:37 GMT</pubDate>
    </item>
    <item>
      <title>解释ACF和PACF图以确定ARMA过程</title>
      <link>https://stats.stackexchange.com/questions/663538/interpreting-acf-and-pacf-plot-to-determine-the-arma-process</link>
      <description><![CDATA[我正在努力解释这些图，以确定Arima过程应该是什么。
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/663538/interpreting-acf-and-pacf-plot-to-determine-the-arma-process</guid>
      <pubDate>Sat, 05 Apr 2025 10:21:53 GMT</pubDate>
    </item>
    <item>
      <title>相关配对测试SPSS</title>
      <link>https://stats.stackexchange.com/questions/663534/correlation-paired-test-spss</link>
      <description><![CDATA[使用配对样本t检验时，是否有必要对线性进行初步检查（例如，通过散点图或其他过程）（因为此测试还决定了两个相关变量之间的相关性）？还是简单地满足进行测试本身的要求是足够的 - 通常分布式变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/663534/correlation-paired-test-spss</guid>
      <pubDate>Sat, 05 Apr 2025 06:05:33 GMT</pubDate>
    </item>
    <item>
      <title>分散矩阵的可逆性和中心矩阵等级</title>
      <link>https://stats.stackexchange.com/questions/663525/invertibility-of-dispersion-matrix-and-the-rank-of-centering-matrix</link>
      <description><![CDATA[我明白， $ r（\ mathbf {x}^\ text {t} \ mathbf {x}）= r（\ Mathbf {x}）$  $ ，据称是分散型当 $ \ Mathbf {$ \ Mathbf {x} $ 是完整等级时class =“数学 - 范围”&gt; $ r（\ mathbf {x}）= $ 在此上下文中， $ \ mathbf {p} $ 是中心矩阵）。  如果数据已经居中，则在 $ \ mathbf {x} $ 是完整的等级（即\ tfrac {1} {n} \ mathbf {x}^\ text {t} \ mathbf {x} $ ），但是当我必须居中时，它似乎不可逆转。

 问题1：如果我必须居中数据， $ \ mathbf {p} $ 破坏 $ \ mathbf {s} s} $ （因为等级 $ \ Mathbf {p} $ 小于列数）？
 问题2：您如何计算中心矩阵的等级？
据我所知，居中矩阵正在投影在一个矢量生成的空间上，但这并不意味着矩阵的等级（图像的维度）是一个？]]></description>
      <guid>https://stats.stackexchange.com/questions/663525/invertibility-of-dispersion-matrix-and-the-rank-of-centering-matrix</guid>
      <pubDate>Fri, 04 Apr 2025 22:57:15 GMT</pubDate>
    </item>
    <item>
      <title>测试集插补</title>
      <link>https://stats.stackexchange.com/questions/663514/test-set-imputation</link>
      <description><![CDATA[假设我的一个功能之一中缺少值，并且火车和测试集中都缺少值。我想使用观察到的特征的中位数重合。我应该：
 a）计算火车集中的中位数， $ m _ {\ text {train}} $ ，并将其用于火车和测试的所有缺失值？
 b）计算火车集上的中位数， $ m _ {\ text {train}} $ ，并将其代替仅用于火车集的所有缺失值。计算测试集上的中位数， $ M _ {\ text {test}} $ ，并将其代替仅用于测试集的所有缺失值。
对我来说，a）似乎是一个可怕的想法，因为我正在使用培训数据中的信息来影响我的测试数据，因此我得到的任何测试错误估计都是完全没有用的，因为我将测试数据偏向火车数据。在极端情况下，假设测试集中缺少大部分或所有该功能，并且我使用 $ m _ {\ text {train}} $ ，那么我对测试错误的估计（对于那个功能而言），即使我绝对没有任何东西。
 b）更有意义，因为我在火车和测试数据上应用一致的过程，因此测试错误估计应该更好地反映真实错误。
是否有严格研究这个问题的参考，还是有人告诉我A实际上比B更好？或者如果有更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/663514/test-set-imputation</guid>
      <pubDate>Fri, 04 Apr 2025 16:55:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在Gamlss中为Lasso执行交叉验证以找到最佳的$ \ lambda $？</title>
      <link>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</link>
      <description><![CDATA[我正在使用用于位置，比例和形状（GAMLSS）的通用加法模型，并试图确定最佳的 $ \ lambda $ 使用交叉验证的套索式回归的值。但是，我正在努力了解如何在这种情况下正确设置交叉验证程序。
对于标准的广义线性模型（GLM），可以使用cv.glmnet（）进行此操作，该步骤遵循以下步骤：

数据集分为 $ k $  folds。
对于每个折叠，使用一个模型对剩余数据进行训练
100  $ \ lambda $ 值的网格。
这些 $ k $  per  $ \ lambda $ 然后在
对应 $ k $ 测试集。
  $ k $  folds均计算每个 $ \ lambda $ 。
  $ \ lambda $ 最小化平均测试错误的选择。

我无法弄清楚如何使用gamlss2软件包实现套索回归，但是我找到了gamlss.lasso，似乎有相同的目的。但是，我的主要问题不是套索实施本身，而是如何正确设置交叉验证过程以选择最佳 $ \ lambda $  。
对于GLM，我们只调整一个 $ \ lambda $ ，但是对于gamlss，我们需要调整第二个：一个：一个用于位置参数 $ \ mu $ $ $ $ $  scale/scale/disperersion parametion参数这表明我们应该使用二维网格的 $ \ lambda $ 值，这意味着，如果我们为 $ \ lambda_ \ lambda_ \ lambda_ \ mu $ 和100 class =“ Math-Container”&gt; $ 100 \ times 100 = 10,000 $ 不同的组合。给定的 $ k = 10 $ 折叠，这将导致培训100,000款模型，这似乎在计算上昂贵。
我试图在没有交叉验证的情况下实施套索，如下所示：
  set.seed（123）
N＆lt; -500
d＆lt; -50
x＆lt;  - 矩阵（rnorm（n*d），n，d）
beta＆lt;  -  cbind（&#39;mu&#39;= rbinom（d，1，.1），sigma&#39;= rbinom（d，1，.1） * .3）
ysd＆lt;  -  Exp（1 + tcrossprod（beta [，2]，x））
data＆lt;  -  cbind（y = as.numeric（rnorm（n，sd = ysd））） + 
    t（tcrossprod（beta [，1]，x）），as.data.frame（x））

＃使用GNET默认设置估算模型
mod＆lt;  -  gamlss（y〜gnet（x.vars = names = names（data）[ -  1]），
              sigma.fo = 〜gnet（x.vars = names（data）[ -  1]）， 
              数据=数据， 
              家庭=不，
              i.control = glim.control（cyc = 1，bf.cyc = 1））

mu_betas＆lt;  -  as.matrix（mu [[1]]  $ beta）
mu_lambdas＆lt;  -  mu [[1]] $  lambda

sigma_betas＆lt;  -  as.matrix（sigma [[1]]  $ beta）
sigma_lambdas＆lt;  -  sigma [[1]] $  lambda
 
从每个 $ \ lambda $ 值的估计系数中，可以评估测试数据的性能并构建交叉验证过程。但是，我尚不清楚以下几点：

由于我们在gamlss中建模两个参数，我们需要一个
 $ \ lambda $ 值的二维网格？也就是说，我们应该测试
所有 $ 100 \ times 100 $ 组合 $（\ lambda_ \ mu，\ lambda_ \ lambda_ \ theta）$ 
独立？例如，这将允许
 $ \ lambda_ \ mu $ 很大，而 $ \ lambda_ \ lambda_ \ theta $ 很小，如果
取决于许多变量，而 $ \ mu $ 取决于很少。
在上述实施中，似乎只有100个组合
经过测试，按照序列 $（\ lambda _ {\ Mu} [1]，
\ lambda _ {\ theta} [1]），...（\ lambda _ {\ mu} [100]，
\ lambda _ {\ theta} [100]）$ ，而不是评估所有可能的
来自两个独立网格的成对组合。这是
正确的方法，或者应全部 $ 10,000 $ 组合
明确？
我读到可以将套索和交叉验证结合在一起
使用gamlss2，但我找不到有关如何如何
到
这样做。如果有人知道如何使用gamlss2进行交叉验证
有了拉索，我将感谢任何指导！
]]></description>
      <guid>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</guid>
      <pubDate>Wed, 02 Apr 2025 17:51:04 GMT</pubDate>
    </item>
    <item>
      <title>后续数据中的差距和目的是治疗精神治疗耐用性的分析</title>
      <link>https://stats.stackexchange.com/questions/663476/gaps-in-follow-up-data-and-intention-to-treat-analysis-for-durability-of-psychia</link>
      <description><![CDATA[使用PHQ-9，我正在分析诊所治疗对患者抑郁症的影响。患者在治疗前的基线PHQ分数（是一次性TX，而不是像药物一样反复出现的TX），然后进行后续行动，我们监视PHQ分数的变化。
我试图确定对那些对治疗反应的人的治疗持久性。但是，由于我们是一家小型诊所，并且由于我们没有特定的激励措施使患者完成随访，因此我们的数据频繁存在差距。例如，一名患者在治疗后一个月进行随访，然后直到6个月后才进行随访。。
我正在检查TX之后以下时间点的治疗耐用性：[1个月，2个月，3个月，6个月，9个月，12个月]。根据我读过的意向性治疗文献，如果他们在失去的最新FU之前，我可以安全地将患者安全地标记为“不再反应”。
但是，如果我有一个患者在1个月和6个月时显示出反应，但没有其他随访，那么在2＆amp期间将患者作为呼吸者是适当的。 3个月的随访时间点？同样，如果患者通过所有先前的随访都表现出持续的反应，那么在科学上是否可以将他们标记为通过未完成的后续行动进行持续的反应？ （例如，患者显示了1-6个月的反应，并丢失了fu。
我可以将它们标记为在第9个月仍在响应中，我是否应该将它们标记为没有响应，还是应该在该时间点从n中删除它们？）
我知道，其他意向性治疗分析使用其他协变量使用插补来填充缺失的数据点，但是我不确定这适用于我的人群。请让我知道您是否有任何想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/663476/gaps-in-follow-up-data-and-intention-to-treat-analysis-for-durability-of-psychia</guid>
      <pubDate>Tue, 01 Apr 2025 18:59:54 GMT</pubDate>
    </item>
    <item>
      <title>递归的贝叶斯更新高斯分布，观察到有限的观察</title>
      <link>https://stats.stackexchange.com/questions/663311/recursive-bayesian-updating-for-gaussian-distribution-with-limited-observations</link>
      <description><![CDATA[考虑以下自适应贝叶斯推理方案：
我们依次和独立地绘制随机变量： $$ x_i \ sim n（\ mu，\ sigma^2），$$ 
具有已知方差 $ \ sigma^2 $ 和未知的平均值 $$ \ mu \ mu \ sim n（\ mu_0，\ sigma^2_0）。$$ 
我们定义了一系列后验表示 $ \ mu_i $ 如下：
最初，at  $ i = 1 $ ，我们将阈值设置为 $ \ mu_0 $ 。然后，我们只观察到指标：
 $$ y_1 = 1 \ {x_1 \ geq \ mu_0 \}。$$ 
仅使用此二进制观察 $ y_1 $ ，我们为 $ \ MU $ $ 形成后分布，并获得后平均值 $ \ MU_1 $ \ MU_1 $ 。
在时间 $ i = 2 $ ，新的抽奖 $ x_2 $ 是制作的，我们表示 $ y_2 = 1 = 1 \ \ \ \ \ {x_2 \ geq \ geq \ geq \ mu_1 \ 。但是我们不观察单个二进制结果 $ y_1 $ ， $ y_2 $ 直接。相反，我们只看到他们的总和：
 $$ n_2 = y_1+y_2。$$  
仅基于单个整数 $ n_2 $ （可以是0、1或2），我们形成了 $ \ mu $ $ $ $ $ 
在时间 $ i = 3 $ ，同样，我们有一个新的抽奖 $ x_3 $ ，结果 $ y_3 $ ，我们只观察：仅观察：：
 $$ n_3 = y_1+y_2+y_3，$$ 
我们更新后验 $ \ mu $ 仅基于 $ n_3 $ 。。
以这种方式继续，在一般时间 $ t $ ，我们仅观察： $ n_t = \ sum^t_ t_ t_ = 1} y_i $ 。因此，基本上，我们忘记了所有历史性 $ n_ {j} $ ， $ j＆lt; t $ 。
所使用的阈值始终是上一步的后词（ $ \ mu_ {i-1} $ ），但重要的是，每个后平均值 $ \ mu_i $  $ n_i $ ，无法访问单个位 $ y_ {i-1} $  $ y_ {i-1} $ 也不明确。。
问题：
 $ \ mu $ 的后验分布，仅基于观察 $ n_t $ ，以 $ \ mu $ $ $ $ $  $ n_t $  class =“ Math-Container”&gt; $ t \ rightarrow \ infty $ ？
直观地，由于 $ \ mu_ {i-1} $ 是步骤 $ i-i-i-span&gt; $ i-i-span&gt;的后验，因此它可以定期和适应性地进行 $ \ $ \ mu $ $ $ 。但是，观察者只看到累积计数，而不是单个二元结果，从而造成了有关可识别性和一致性的不确定性。
我会感谢您对这种适应性，综合信息方案和相关理论的参考的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/663311/recursive-bayesian-updating-for-gaussian-distribution-with-limited-observations</guid>
      <pubDate>Mon, 31 Mar 2025 02:37:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么最大似然估计过高或在稀疏事件的情况下？</title>
      <link>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</link>
      <description><![CDATA[在统计类别中，我们被教导说，当事件稀疏（相对于预测变量相对于预测变量的结果少），最大的可能性估计（MLE）通常高估了逻辑回归中的几率比（ORS）。）。
我了解为什么MLE在近距离分离或完全分离的情况下产生无限估计，而预测因子可以完美地预测结果。但是，我没有完全掌握为什么，为什么在稀疏数据的情况下（不分开），MLE倾向于高估OR，而不是简单地产生围绕真实价值的宽阔，不精确的置信区间。
一些解释提到，可能性表面在0（当𝛽0）接近0（当𝛽0）附近，使MLE向更陡峭的斜坡漂移，从而发现更大或估计。我不完全了解这种机制是如何工作的 - 为什么一个扁平的可能性表面会导致系统性高估，而不仅仅是不确定性？
有人可以帮助澄清：
为什么在逻辑回归中，可能性功能的形状会导致MLE在稀疏数据设置中高估的趋势？
为什么“更喜欢” mle&#39; β（效果更强​​）的绝对值较大，而不仅仅是在较小的估计值周围产生宽的顺式？]]></description>
      <guid>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</guid>
      <pubDate>Thu, 13 Mar 2025 12:09:35 GMT</pubDate>
    </item>
    <item>
      <title>如果一个随机变量受较高概率的常数界定，那么它的期望是否也以相同概率的相同常数界定？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/592467/if-a-random-variable-is-bounded-by-a-constant-with-high-probability-is-its-expe</link>
      <description><![CDATA[假设 $ x $ 是一个随机变量，以高概率为界，即 $ | x | ＆lt; M $ 对于某些 $ m \ in \ Mathbb {r}^+$ 带有概率 $ 1-P $ 。说 $ \ mathbb {e}（| x |）＆lt; m $ 带有概率 $ 1- p $ 以及吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/592467/if-a-random-variable-is-bounded-by-a-constant-with-high-probability-is-its-expe</guid>
      <pubDate>Sun, 16 Oct 2022 10:40:52 GMT</pubDate>
    </item>
    </channel>
</rss>