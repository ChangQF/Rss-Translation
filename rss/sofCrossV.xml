<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 Jan 2025 18:21:38 GMT</lastBuildDate>
    <item>
      <title>如何比较两个组件的可靠性？</title>
      <link>https://stats.stackexchange.com/questions/660773/how-to-compare-two-component-reliability</link>
      <description><![CDATA[我有两个不同的组件在使用中，一个是旧的，另一个是新的。我想知道新组件是否比旧组件更可靠（即更高的 MTBF）
组 1 旧组件：包含 80% 的可用数据。对于组中的每个组件，我们知道它们是否发生故障，以及在发生故障时或测量期结束时（如果没有发生故障，则为多少小时（审查）。测量是在 6 年内完成的。
组 2 新组件：包含剩余数据的 20%，信息相同，但测量是在 1 年内完成的。
预计这两个组件都会遵循相同的“浴盆曲线”磨损模式。
在知道实验具有不同的测量周期和不同大小的组的情况下，是否可以以及如何比较两个组件的可靠性？]]></description>
      <guid>https://stats.stackexchange.com/questions/660773/how-to-compare-two-component-reliability</guid>
      <pubDate>Thu, 30 Jan 2025 17:34:41 GMT</pubDate>
    </item>
    <item>
      <title>3 在 R 中绘制指数趋势的不同结果。为什么它们不同以及哪一个是正确的？</title>
      <link>https://stats.stackexchange.com/questions/660772/3-different-results-plotting-exponential-trend-in-r-why-are-they-different-and</link>
      <description><![CDATA[我有以下数据：
dput(data)
structure(list(sizenum = c(32.5, 37.5, 42.5, 52.5, 57.5, 47.5, 
62.5, 67.5, 72.5, 42.5, 47.5, 52.5, 57.5, 67.5, 72.5, 62.5, 27.5, 
37.5), TEQ_ALL_HIGH_FW = c(2.3, 0.45, 0.33, 0.41, 0.46, 0.9, 
0.36, 0.31, 0.42, 1.4, 0.34, 0.29, 0.35, 0.23, 0.22, 0.46, 6.9, 
3.3)), class = &quot;data.frame&quot;, row.names = c(NA, -18L))

数据最好通过具有对数转换响应变量的线性模型来解释：
lm1 &lt;- lm(log(TEQ_ALL_HIGH_FW) ~ sizenum, data = data)
summary(lm1)

调用：
lm(formula = log(TEQ_ALL_HIGH_FW) ~ sizenum, data = data)

残差：
最小值 1Q 中位数 3Q 最大值 
-1.10237 -0.31674 0.08979 0.30782 1.12699 

系数：
估计标准差误差 t 值 Pr(&gt;|t|) 
(截距) 2.29105 0.61673 3.715 0.001882 ** 
sizenum -0.05406 0.01144 -4.725 0.000229 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：16 个自由度上的 0.6495

多重 R 平方：0.5825，调整后的 R 平方：0.5564

F 统计量：1 和 16 DF 上的 22.33，p 值：0.0002288

我尝试用三种方式在数据上绘制模型。第一种，使用 Duan 的涂抹校正。第二种，将预测结果转换回线性空间。第三个，使用带有对数链接的 glm 平滑器。
func1 &lt;- function(x){
exp(lm1$coefficients[1] + lm1$coefficients[2] * (x))*mean(exp(lm1$residuals))
}

func2 &lt;- function(x, m) {
d &lt;- data.frame(sizenum = x)
log_pred &lt;- predict(m, newdata = d)
exp(log_pred)
}

scattertrend &lt;- ggplot() +
geom_smooth(data = data, mining = aes(x = sizenum, y = TEQ_ALL_HIGH_FW),color = &quot;orange&quot;,linewidth = 1, se=FALSE, method = &quot;glm&quot;, formula = y~x, method.args = list(family = gaussian(link = &#39;log&#39;)))+
geom_function(fun = func1, color = &quot;black&quot;, linetype = &quot;solid&quot;, linewidth = 1, alpha = .5) + 
geom_function(fun = func2, color = &quot;purple&quot;, args= list(m = lm1), linetype = &quot;solid&quot;, linewidth = 1, alpha = .5)+
geom_point(data = data, mining = aes(x = sizenum, y = TEQ_ALL_HIGH_FW), size = 3) +
theme_classic()
scattertrend


您可以看到，在结果图上，所有曲线都不同：

我想知道为什么这些曲线都不一样，以及在数据上描绘曲线的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660772/3-different-results-plotting-exponential-trend-in-r-why-are-they-different-and</guid>
      <pubDate>Thu, 30 Jan 2025 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>在偏最小二乘潜在空间中提取模式（即聚类）是否有优势？</title>
      <link>https://stats.stackexchange.com/questions/660771/are-there-advantages-in-extracting-patterns-i-e-clustering-on-partial-least-s</link>
      <description><![CDATA[我使用偏最小二乘法，以便在相关协变量的情况下获得线性模型参数。
我想尝试在偏最小二乘潜在空间中进行聚类，即由第一个偏最小二乘分量和第二个偏最小二乘分量构成的空间，或者可能是由第一个偏最小二乘分量的 X 分数和 Y 分数构成的空间。
在这个空间上进行聚类可以揭示一些与 PCA 相关的其他特征吗？
如果我有独立的 X 数据和相关的 Y 数据，PLS 会找到主成分，以便数据在最适合 X 数据的直线上的投影与最适合 Y 数据的直线上的投影之间的协方差最大化。因此，我们最大化 X 空间中的投影和 Y 空间中的投影所形成的空间中的方差。
相反，使用 PCA，您会提取 X 中的所有 Y 数据，并对 X 应用 PCA。PCA 会找到最大化数据之间方差的主成分。
我的问题是：是否可以合理地认为 PLS 潜在空间会根据某些特征分离数据，而使用简单的 PCA 则无法实现这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660771/are-there-advantages-in-extracting-patterns-i-e-clustering-on-partial-least-s</guid>
      <pubDate>Thu, 30 Jan 2025 17:27:34 GMT</pubDate>
    </item>
    <item>
      <title>如何更好地拟合二元回归模型？</title>
      <link>https://stats.stackexchange.com/questions/660770/how-do-i-better-fit-binary-regression-model</link>
      <description><![CDATA[我在家庭层面运行了一个二元逻辑回归模型，其中响应变量为实践。目的是看看这 22 个预测因子是否影响实践。
这是我的数据集的摘要：
&gt;摘要（BeanPureePractice）
城市区域 近郊区域 农村区域 偏远农村区域 实践 女性年龄_10_30 女性年龄_31_51
否 :98 否 :105 否 :74 否 :83 否 : 16 否 :59 否 :50 
是:22 是: 15 是:46 是:37 是:104 是:61 是:70 
女性年龄_52_72 女性年龄_73_90 男性年龄_10_30 男性年龄_31_51 男性年龄_52_72 男性年龄_73_90
否 :81 否 :92 否 :63 否 :88 否 :102 否 :106 
是:39 是:28 是:57 是:32 是: 18 是: 14 
无教育 小学 小学 初中 高中 高等教育 就业 
否 :90 否 :92 否 :52 否 :36 否 :82 否 :94 否 :101 
是:30 是:28 是:68 是:84 是:38 是:26 是:19 
失业 退休人员 学习者
否 :17 否 :65 否 :52 
是:103 是:55 是:68 

模型结果:
&gt; summary(logit_model)

调用：
glm(formula = Practice ~ Urban_zone + Peri_urban_zone + Rural_zone + 
Remote_rural_zone + Female_Age_10_30 + Female_Age_31_51 + 
Female_Age_52_72 + Female_Age_73_90 + Male_Age_10_30 + Male_Age_31_51 + 
Male_Age_52_72 + Male_Age_73_90 + No_education + Lower_Primary + 
Upper_Primary + Junior_Secondary + Senior_Secondary + Tertiary + 
Employed + Unemployed + Pensioners + Learners, family = binomial, 
data = BeanPureePractice)

系数：（由于奇异性，1 未定义）
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -134.73 23024.40 -0.006 0.995
Urban_zoneYes -210.79 29195.67 -0.007 0.994
Peri_urban_zoneYes 115.58 28452.80 0.004 0.997
Rural_zoneYes 192.08 29544.61 0.007 0.995
Remote_rural_zoneYes NA NA NA NA
Female_Age_10_30Yes 152.80 21874.22 0.007 0.994
Female_Age_31_51Yes 152.80 21874.22 0.007 0.994
女性年龄_52_72是 133.20 19093.66 0.007 0.994
女性年龄_73_90是 228.94 51691.56 0.004 0.996
男性年龄_10_30是 97.49 17912.18 0.005 0.996
男性年龄_31_51是 -38.14 9693.96 -0.004 0.997
男性年龄_52_72是 169.05 40634.69 0.004 0.997
男性年龄_73_90是 212.06 61042.26 0.003 0.997
未受教育是 384.87 54658.22 0.007 0.994
小学是 442.93 64269.61 0.007 0.995
小学是 -18.40 10120.44 -0.002 0.999
初中是 345.60 46617.56 0.007 0.994
高中是 364.13 48898.46 0.007 0.994
高等教育是 382.13 51298.76 0.007 0.994
就业是 -190.10 27020.57 -0.007 0.994
失业者是 -152.88 21890.22 -0.007 0.994
退休人员是 -227.64 45060.46 -0.005 0.996
学习者是 -384.46 53144.00 -0.007 0.994

（二项式系列的分散参数取为 1）

零偏差：119 个自由度上的 94.242
残差偏差：98 个自由度上的 12.137
AIC：56.137

Fisher 评分迭代次数：25

我收到以下警告消息：
警告消息：
1：glm.fit：算法未收敛
2：glm.fit：拟合概率在数值上为 0 或 1

尽管模型拟合结果很奇怪，但标准误差很大。我的结果变量“实践”主要是“是”（104 个观察值）和“否”（14 个观察值），也许这就是原因。进一步的阅读指出了预测因子之间的多重共线性问题，我不确定如何解决这个问题。如何更好地拟合模型或改善结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/660770/how-do-i-better-fit-binary-regression-model</guid>
      <pubDate>Thu, 30 Jan 2025 17:24:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么在之前的抛硬币过程中，下一次抛硬币的不确定性会随着测量次数的增加而增加？</title>
      <link>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</link>
      <description><![CDATA[我对与给定先前抛硬币的抛硬币预测后验相关的一些事情有点困惑。假设我在 N 次抛硬币中看到 k 次正面，我想找出下一次抛硬币是正面的概率。我不仅想量化下一次抛硬币是正面的概率，还想量化我对它是否会是正面的不确定性。如果我假设一个均匀的先验并做一些数学运算，我可以得出下一次抛硬币的预期值为
$$
E_p[E_H[H|p]] = \frac{k+1}{N+2}
$$
方差的期望值为
$$
E_p[Var_H[H|p]] = \frac{(k+1)(N-k+1)}{(N+2)(N+3)}。
$$
但是当我尝试几个 k 和 N 的值，使 k=N/3 保持不变时，我注意到不确定性会随着翻转次数的增加而增加。
 k N E[E[H|p]] E[Var[H|p]]
1 3 0.400000 0.200000
2 6 0.375000 0.208333
4 12 0.357143 0.214286
8 24 0.346154 0.217949
16 48 0.340000 0.220000

为什么我获得更多数据时不确定性会增加？这似乎不正确。我猜想使用方差的期望值作为不确定性的代理肯定是有缺陷的，但我不知道更好的指标是什么。如果是这样的话，你能在下一次抛硬币时提出一个更好的不确定性指标吗，以符合不确定性应该随着数据增加而减少的直觉？否则这里还有其他问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</guid>
      <pubDate>Thu, 30 Jan 2025 17:24:09 GMT</pubDate>
    </item>
    <item>
      <title>如果这些变量也包含在随机效应结构中，如何检验固定效应的显著性？</title>
      <link>https://stats.stackexchange.com/questions/660766/how-to-test-for-significance-of-fixed-effects-if-those-variables-are-also-includ</link>
      <description><![CDATA[我对混合效应模型有一个更一般/更实际的问题。我绝对不是这方面的专家，只是注意到一些似乎不对劲的地方。我想知道当固定效应也包含在模型的随机效应结构中时，是否可以测试该效应的显著性？
我将使用 R 中的 glmmTMB() 举例说明我的问题。假设您有一个模型，其中 Y 是二项分布（0 或 1）响应，X1 和 X2 是固定效应，g 是随机阻塞变量。探索了最佳随机效应结构（使用 AIC 和 LRT），发现对于 g 的每个级别，Y~X1 的随机截距和斜率都很重要。最终模型如下所示：final_model&lt;-glmmTMB(Y ~ X1 + X2 + (1+X1|g), family=binomial(link=&quot;logit&quot;), data=dat)
下一步是获取固定效应的检验统计量和 p 值（换句话说，得出结论，它们是否显著影响响应 Y）。我知道有多种方法可以做到这一点，从不好的（例如，Wald 检验）到更好的（例如，似然比检验），再到最好的（例如，模拟？）。假设您正在使用似然比检验（例如，使用 drop1() 命令）。由于这种方法涉及拟合简化（或嵌套）模型进行比较，这是否会产生一个问题，即其中一个简化模型不包括 X1，但 X1 仍然是随机效应结构的一部分？换句话说，这是否会导致某些简化模型被错误指定？我尝试在 R 中运行此类测试并得到了结果，但我不确定是否应该相信它。如果简化模型确实指定错误，那么您如何测试固定效应的显著性？由于它是随机效应结构的一部分，因此它永远无法从模型中移除。]]></description>
      <guid>https://stats.stackexchange.com/questions/660766/how-to-test-for-significance-of-fixed-effects-if-those-variables-are-also-includ</guid>
      <pubDate>Thu, 30 Jan 2025 16:20:30 GMT</pubDate>
    </item>
    <item>
      <title>如何降低 80% 右删失生存模型的偏差？</title>
      <link>https://stats.stackexchange.com/questions/660765/how-to-lower-the-bias-with-80-right-censored-survival-models</link>
      <description><![CDATA[我对糖尿病患者慢性肾病 (CKD) 与死亡率之间的关联感兴趣，CKD 是暴露因素，死亡是结果。然而，当对每位患者进行 4 年的随访（最长的随访时间）时，80% 的患者在研究结束前还活着，而 5% 的患者被审查，因为他们被作为对照治疗但患上了 CKD。
我对这个数据集进行了 Cox 回归，风险比 (HR) 约为 11。这个值比预期的要高得多。
我想确定糖尿病患者慢性肾病 (CKD) 与死亡率之间的关联的风险比。我该如何计算这个，也许不使用 Cox 回归？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660765/how-to-lower-the-bias-with-80-right-censored-survival-models</guid>
      <pubDate>Thu, 30 Jan 2025 16:15:53 GMT</pubDate>
    </item>
    <item>
      <title>未调整生存率与 IPW 调整生存率的 Kaplan-Meier 估计时限差异</title>
      <link>https://stats.stackexchange.com/questions/660764/difference-in-time-limits-for-kaplan-meier-estimates-with-unadjusted-vs-ipw-adj</link>
      <description><![CDATA[我正在使用 adjustedsurv 函数计算两组 (Treatment_type_tumor_near_gallbladder) 在特定时间点 (0 到 120 个月，以 12 个月为间隔) 的 Kaplan-Meier (K-M) 总生存期 (OS) 估计值。
但是我遇到了一个问题：
1. 未调整的 K-M 估计值：使用标准 Kaplan-Meier 方法 (method=&quot;km&quot;) 时，我获得了两组长达 84 个月的生存期估计值。
2. IPW 调整后的 K-M 估计值：使用逆概率加权 (IPW) 时，方法为&quot;iptw_km&quot;并且 weight_method=&quot;OptWeight&quot;，生存估计值仅可用于 48 个月以内。
鉴于 IPW 重新加权所有观察值，而不是排除不匹配的患者（如倾向得分匹配），我预计所有患者和事件仍将包括在内。但是，在 IPW 调整的分析中，时间范围似乎被截断了。
有人能解释一下为什么会发生这种情况吗？这是一个“限制”吗？ IPW 方法，还是表明我的代码存在潜在问题？
提前谢谢您！
这是我的代码：
# 未调整的总体生存率 K-M
surv_values &lt;- adaptedsurv(data=df,
variable=&quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time=&quot;OS_from_target_local_treatment&quot;,
event=&quot;death_mine&quot;,
times=seq(0, 120, by=12),
method=&quot;km&quot;,
conf_int=TRUE,
bootstrap=TRUE,
n_boot=500,
n_cores=10)

# 将列“surv”、“se”、“ci_lower”四舍五入到小数点后第二位， &#39;ci_upper&#39;
surv_values$boot_adj %&gt;%
mutate(across(c(surv, se, ci_lower, ci_upper), ~ round(.x, 2)))

未调整的 OS 选项卡：

# 调整后的总生存率 K-M
adj_values &lt;- adaptedsurv(data=df,
variable=&quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time=&quot;OS_from_target_local_treatment&quot;,
event=&quot;death_mine&quot;,
times= seq(0, 120, by=12), 
method=&quot;iptw_km&quot;,
conf_int=TRUE,
bootstrap=TRUE,
# stabilize=TRUE,
n_boot=1000,
n_cores=10,
treatment_model=formula_OS,
weight_method=&quot;OptWeight&quot;) # OptWeight, ebal, cbps, energy

# 将列 &#39;surv&#39;、&#39;se&#39;、&#39;ci_lower&#39;、&#39;ci_upper&#39; 四舍五入到小数点后第二位
adj_values$boot_adj %&gt;%
mutate(across(c(surv, se, ci_lower, ci_upper), ~ round(.x, 2)))


调整后的 OS标签：
]]></description>
      <guid>https://stats.stackexchange.com/questions/660764/difference-in-time-limits-for-kaplan-meier-estimates-with-unadjusted-vs-ipw-adj</guid>
      <pubDate>Thu, 30 Jan 2025 16:15:33 GMT</pubDate>
    </item>
    <item>
      <title>通过对 K 个独立均匀分布进行抽样并排序，从具有 K 个类别的多项分布中抽样</title>
      <link>https://stats.stackexchange.com/questions/660761/sampling-from-a-multinomial-distribution-with-k-categories-by-sampling-k-indepen</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660761/sampling-from-a-multinomial-distribution-with-k-categories-by-sampling-k-indepen</guid>
      <pubDate>Thu, 30 Jan 2025 15:52:16 GMT</pubDate>
    </item>
    <item>
      <title>组合在概率中的理论应用</title>
      <link>https://stats.stackexchange.com/questions/660759/theoretical-applications-of-combinants-in-probability</link>
      <description><![CDATA[我最近在阅读概率论时遇到了组合的概念。维基百科上关于组合的文章提供了基本概述，但并未详细介绍如何在理论（或实践）中应用它。引用的资源是一本名为软多强子动力学的书，据我所知，我无法访问它，但标题暗示与强子有关。
当我在谷歌上搜索“组合生成函数的应用”时我搜索到了很多关于重组 DNA的结果，但没有任何关于这个函数（al）的信息。
必须有无数个函数$f$与矩生成函数以$(M_X \circ f) (t)$的形式组合，所以问题不可避免地是：我们为什么要关心这个特定的函数？理论上，给定任何一组有限的所需组合，我会对随机变量学到什么？或者组合生成函数是否经常作为其他形式分析的中间步骤出现？]]></description>
      <guid>https://stats.stackexchange.com/questions/660759/theoretical-applications-of-combinants-in-probability</guid>
      <pubDate>Thu, 30 Jan 2025 14:38:30 GMT</pubDate>
    </item>
    <item>
      <title>生存数据引导</title>
      <link>https://stats.stackexchange.com/questions/660757/bootstrap-for-survival-data</link>
      <description><![CDATA[我将 Cox PH 生存模型拟合到一些数据：
$$ h(t|\mathbf{X}_i) = h_0(t)\exp(\mathbf{X}_i\boldsymbol{\beta}) $$
我对从该模型模拟生存时间感兴趣。我知道有一种标准方法可以做到这一点：
$$ T = H_0^{-1}(-\log(U)\exp(-\mathbf{X}\boldsymbol{\beta})) $$
我只是想知道以下内容。虽然我以前从未对生存模型进行过这样的操作，但我想您可以在拟合生存模型后使用不同类型的引导方法来解释额外的不确定性来源。例如：

经典重采样：Bootstrap 重采样通过以下方式创建采样分布（对于 $b = 1,...,B$ 个 bootstrap 样本）：
$$ \hat{\boldsymbol{\beta}}^{(b)} = \text{CoxPH}(\text{Bootstrap Sample }b) $$

渐近分布：随着样本量增大，依赖于估计参数的采样分布（其中 $\mathbf{I}(\boldsymbol{\beta})$ 是 Fisher 信息矩阵
）：$$ \hat{\boldsymbol{\beta}} \sim \text{MVN}(\boldsymbol{\beta}, \mathbf{I}^{-1}(\boldsymbol{\beta})) $$


因此，在模拟生存时间之前，是否需要考虑这些方法中的任何一种？例如：

首先使用任一方法（自举或渐近）生成多组系数$\beta^{*}$。
然后，对于每个个体，模拟每组系数的生存时间。

因此，对于$k^{th}$模拟：
$$ T^{(k)} = \hat{H}_0^{-1}(-\log(U)\exp(-\mathbf{X}\boldsymbol{\beta}^{*(k)})) $$
模拟生存时间时，在模拟生存时间之前是否需要这个额外的步骤？]]></description>
      <guid>https://stats.stackexchange.com/questions/660757/bootstrap-for-survival-data</guid>
      <pubDate>Thu, 30 Jan 2025 14:04:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来选择岭回归参数 $k$：如果 $\mathbf x_i$ 和 $y_i$ 的平均值在测试/训练集上可能为非零怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</link>
      <description><![CDATA[考虑一个回归模型$$ Y= X\beta+ u.\tag{$\star$} $$
$Y$是一个长度为$n$的列向量，包含$n$个观测值。
$X$是一个$n\times p$矩阵，每行对应一个观测值，每列对应一个特征。
$\beta$是回归系数。
$u$是一个长度为$n$的列向量，包含误差。
对于参数为 $k&gt;0$ 的岭回归，$\beta$ 的估计值为 $$\hat\beta= (X^TX +kI)X^TY .$$
我知道正则化参数 $k$ 的选择可以通过交叉验证来选择，例如论文 变量选择与数据增强之间的关系以及预测方法。
我的问题是，假设我们使用十倍交叉验证，数据集的子集为 $S_1,\cdots, S_{10}$。
$(\star)$ 的右侧没有均值项 $\mu$ 的原因是数据 $X,Y$ 被标准化为具有零均值。
但是当应用交叉验证时（例如，使用 $S_{10}$ 进行测试，使用其他数据进行训练），
则 $\cup_{i=1}^9 S_i$ 中的 $\mathbf x_i$ 和 $y_i$ 的均值可能不为零。
$S_{10}$ 中的 $\mathbf x_i$ 和 $y_i$ 的平均值也可能为非零。
那么我们如何仍然使用公式 $$\hat\beta= (X^TX +kI)X^TY$$ 来计算 $\cup_{i=1}^9 S_i$ 上的 $\hat\beta$，以及使用 $$ \sum\nolimits_{(\mathbf x_i, y_i)\in S_{10}} \|y_i- \langle \hat\beta, \mathbf x_i \rangle\|^2 $$
作为测试集 $S_{10}$ 上的误差？
我认为均值项 $\mu$ 也应该考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</guid>
      <pubDate>Thu, 30 Jan 2025 04:05:46 GMT</pubDate>
    </item>
    <item>
      <title>这是生态谬误吗？</title>
      <link>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</link>
      <description><![CDATA[
使用历史数据，我有一个模型，它根据一些个人特征/协变量告诉我单个单位在某个 $t$ 后存活的概率：

$$\hat{S}_j(t) = [\hat{S}_0(t)]^{\exp(x_j^{new^T}\hat{\beta})}$$

现在，$n$ 个新单位进来，我只有它们的预测因子（与之前相同的预测因子），即它们都还活着。
一般来说，每天要花费 $j$ 美元来维持这些 $n$ 个单位活着。
一旦单位不再活着，就不会产生任何相关成本。此外，单位死亡也不会产生任何相关成本。

我想估算一下这些 $n$ 单位明年会花多少钱。我正在尝试推导成本函数
使用预期值，我为每个新单元和所有新单元定义了一个预期成本函数（如果需要，我可以展示我的工作）：
$$E[\text{Cost}_i] = j\int_0^T tf_i(t)dt + jTS_i(T)$$
$$E[\text{Total Cost}] = \sum_{i=1}^n \left(j\int_0^T tf_i(t)dt + jTS_i(T)\right)$$
我不禁想到，我正在陷入类似生态谬误，使用旧模型来估计新数据的成本。这是因为我实际上是在为每个单独的单元恢复单独的生存函数，这可能会导致非常不稳定的预测。
例如，我认为如果我的历史模型非常简单（例如，仅包含 A 类与 B 类的预测变量），那么我可以使用这个旧模型来预测新数据中所有 A 类和所有 B 类的预期成本（即所有 A 类单元的单一生存曲线和所有 B 类单元的单一生存曲线……然后通过将它们相加来估算成本）。旧模型将有足够的 A 类与 B 类的成本和时间数据，因此可以更好地推断新数据。然而，这样做虽然不太细致，但可能更可靠（更安全的方法是拟合一个没有任何协变量的模型）。
但如果我开始在历史模型中包含更多变量，我感觉我会开始将自己局限在某个领域，历史模型将变得更适合仅提供对历史数据的推断，而不太适合新数据。
这个想法正确吗？我是否陷入了生态谬误，或者我的做法是否正确？
我个人的观点是，我需要进行一些探索性数据分析，看看旧数据与新数据的相似程度，然后决定历史模型是否适合新数据……但这不是一种明确的做法，我也不确定如何客观地做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</guid>
      <pubDate>Thu, 30 Jan 2025 03:44:49 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，拟合残差是否与回归量正交？</title>
      <link>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</link>
      <description><![CDATA[我正在研究 Wooldridge 的《计量经济学分析》中的回归问题。回归量被视为随机的。他说，最小二乘估计一致性的一个基本假设是“总体正交性条件”（“假设 OLS.1”），即
$$
E(x&#39;u)=0。
$$
此处的线性模型为$y = \beta&#39;x + u$，其中$u$是误差项的符号，prime 表示矩阵转置。
我的问题是，在此模型下，通过最小二乘估计获得的拟合残差$\hat u$是否与回归量$x$不相关，即$E(x&#39;\hat u)=0$。]]></description>
      <guid>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</guid>
      <pubDate>Wed, 29 Jan 2025 20:13:21 GMT</pubDate>
    </item>
    </channel>
</rss>