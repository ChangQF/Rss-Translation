<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 09 Feb 2025 01:18:40 GMT</lastBuildDate>
    <item>
      <title>我在不同表面之间做一个Wilcox和Permanova的知识，可以忽略重复序列吗？</title>
      <link>https://stats.stackexchange.com/questions/661145/i-am-intersted-in-doing-a-wilcox-and-permanova-between-different-surfaces-is-it</link>
      <description><![CDATA[我正在从SRA重新分析数据集。基本上，我的表面是“车站床铁路”，“地板”。一些表面进行了两次采样。我想知道忽略重复是否可以吗？我的核心问题是，与手相关的表面和地板相关表面之间是否存在差异，因此我永远不会在一个时间点测量一个时间点与另一个时间点测量表面。]]></description>
      <guid>https://stats.stackexchange.com/questions/661145/i-am-intersted-in-doing-a-wilcox-and-permanova-between-different-surfaces-is-it</guid>
      <pubDate>Sat, 08 Feb 2025 23:27:14 GMT</pubDate>
    </item>
    <item>
      <title>有限样本量$ n $的最大似然估计的偏差限制</title>
      <link>https://stats.stackexchange.com/questions/661137/a-bound-for-the-bias-of-maximum-likelihood-estimates-for-finite-sample-size-n</link>
      <description><![CDATA[随机示例 $ x_1，\ dots，x_n $ 。每个 $ x_i $ 是来自函数 $ f（x; \ theta）$ 的IID。令 $ \ hat \ theta_ {mle} $ 是真实参数 $ \ theta $的最大似然估计器（mle） 。
I know that the MLE is consistent and asymptotically efficient.我知道偏见可以写在 form ：
  $$ e（\ hat \ theta_ {mle}  -  \ theta）= \ frac {b（\ theta）} {n} + o \ biggl（\ frac {1 } {n^2} \ biggr）$$  
是否有有关MLE的 $ b（\ theta）$ 的信息？特别是某些上限？

另外，我也会对存在的浆果 - 埃森边界感兴趣，以防万一 $ b（\ theta）$ 是已知的。]]></description>
      <guid>https://stats.stackexchange.com/questions/661137/a-bound-for-the-bias-of-maximum-likelihood-estimates-for-finite-sample-size-n</guid>
      <pubDate>Sat, 08 Feb 2025 18:01:05 GMT</pubDate>
    </item>
    <item>
      <title>比较几个没有地面真相的测量来源（大多数情况下）</title>
      <link>https://stats.stackexchange.com/questions/661136/compare-several-sources-of-measurement-with-no-ground-truth-most-of-the-time</link>
      <description><![CDATA[我有处置的3个数据集 $（x_t），\，（y_t），\，（z_t）$ 降水数据（通过雷达估算）在同一时间和一组位置。我的目标是在每个时间和位置确定3个测量中的一个更准确。
此外，我可以访问量规测量，以一种比雷达更精确的时空网格的更粗口（和不同的）时空网格。
我已经确定了 paper   将测量值作为线性回归的纸张 true值 $ \ theta $ ，即：
 $$ x = \ alpha_x + \ beta_x \ theta + \ epsilon_x $$ 
并估计误差方差 $ \ sigma _ {\ epsilon} $ 从经验方差和协方差 $ x，\，\，\，y，y ，\，z $ &lt; /span&gt;。
但是，在我的情况下做出的假设不存在。
我可以使用另一个框架还是可以追求的想法？每个帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661136/compare-several-sources-of-measurement-with-no-ground-truth-most-of-the-time</guid>
      <pubDate>Sat, 08 Feb 2025 17:39:21 GMT</pubDate>
    </item>
    <item>
      <title>预期的掷骰数以滚动数字m次以n侧为单位</title>
      <link>https://stats.stackexchange.com/questions/661134/expected-number-of-rolls-necessary-to-roll-a-specific-number-m-times-with-a-n-si</link>
      <description><![CDATA[我想计算以给定的置信
我知道这与优惠券收集者的问题关于滚动的概率 m数字，而不是特定数字m次。
为了了解WW分布的外观，我对1000侧的模拟卷进行了模拟，以计算至少一次滚动数字1到10所需的掷骰数。 Fortran代码看起来像这样：
 运行= 100000000
侧= 100
滚动= 0

i = 1，运行
    run_rolls = 0

    做s = 1，10
        run_rolls = run_rolls + 1
        while（int（侧 * rand（） + 1） /= s）
            run_rolls = run_rolls + 1
        结束
    结束

    rolls（run_rolls）= rolls（run_rolls） + 1
结束
 
这会产生几乎与最佳拟合参数拟合对数正态分布的分布：
  shape = 2.20115409E-01
LOC = -4.32304744E+02
比例= 1.39866682E+03
 
看起来像这样：
    
以给定的置信度计算所需的预期模具数量的分析公式是什么？此问题会产生什么样的分布？
编辑：按照评论中的建议，我重新制定了这个问题。旧的标题过去是“预期的卷卷数，以滚动M数至少至少一次。但是我已经改写了它以更好地说明我的意图用户酶。]]></description>
      <guid>https://stats.stackexchange.com/questions/661134/expected-number-of-rolls-necessary-to-roll-a-specific-number-m-times-with-a-n-si</guid>
      <pubDate>Sat, 08 Feb 2025 16:57:40 GMT</pubDate>
    </item>
    <item>
      <title>看似无关的回归集？</title>
      <link>https://stats.stackexchange.com/questions/661133/a-seemingly-unrelated-set-of-regressions</link>
      <description><![CDATA[研究可卡因使用和租金价格之间的关系，我有一个数据集，我只能一次观察两个功能，换句话说，我可以运行一组 $ k \ times（k-1）$ 由 $ i，j $  
  $$
y^{ij} _ {ct} = \ beta_0 + \ beta_1 p_ {ct} + \ beta_2 x^{（i）} _ {ct} + \ beta_3 x^x^x^X^{（J）} ct} \ gamma + \ epsilon_ {ct}。
$$  
  $ y^{ij} _ {ct} $ 是进入可卡因康复中心的数量，用于可卡因中的可卡因中心“&gt; $ c $ 和年 $ t $ 在爱尔兰。该观察结果取决于分类变量的选择 $ x^{（i）} _ {ct} $  and  $ x^ {（J）} _ {CT} $ （例如使用频率，无论是否单独生活，教育水平）。向量 $ w_ {ct} $ 包含少数个人特征：年龄，性别，先前接受康复中心的入学。
的原因是 hrb国家药物图书馆一次变量和这些分区数据，以便任何两个观察值 $ y^{ij} _ {ct} $ 和 $ y^{k \ ell} _ {ct} $ 不需要重合，而是 $ \ sum_ {c，t} y^{ij} _} _ {ct} = n $   $ i $ 和 $ j $ 。 在我的另一个问题中重建原始数据并更详细地说明数据。
我显然对省略的可变偏差感到怀疑，因为该功能很可能彼此相关，是否有任何方法可以减轻问题并利用我确实观察到更多回归器的事实，即使我只成对观察它们？ 
这看起来像是看似无关的回归的应用，但是我不确定对错误术语在观察值中不相关的要求（但在回归中不相关）是否得到满足。]]></description>
      <guid>https://stats.stackexchange.com/questions/661133/a-seemingly-unrelated-set-of-regressions</guid>
      <pubDate>Sat, 08 Feb 2025 16:51:59 GMT</pubDate>
    </item>
    <item>
      <title>重用对照组进行多个实验</title>
      <link>https://stats.stackexchange.com/questions/661131/reusing-control-group-for-multiple-experiments</link>
      <description><![CDATA[这基本上是用于多个实验的一个控件/B测试问题。
除了共享对照组的实验结果之间的相关性之外，使用共享对照有任何不良后果吗？我觉得我重复使用相同的数据进行多次比较！]]></description>
      <guid>https://stats.stackexchange.com/questions/661131/reusing-control-group-for-multiple-experiments</guid>
      <pubDate>Sat, 08 Feb 2025 16:06:22 GMT</pubDate>
    </item>
    <item>
      <title>我是否有正确的想法来解释贝叶斯推断中的超参数？</title>
      <link>https://stats.stackexchange.com/questions/661130/have-i-got-the-right-idea-for-interpreting-hyperparameters-in-bayesian-inference</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661130/have-i-got-the-right-idea-for-interpreting-hyperparameters-in-bayesian-inference</guid>
      <pubDate>Sat, 08 Feb 2025 15:57:44 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟与分类预测变量的三向相互作用的数据？</title>
      <link>https://stats.stackexchange.com/questions/661128/how-to-simulate-data-for-a-three-way-interaction-with-categorical-predictors</link>
      <description><![CDATA[我正在设计一项研究2（参与者_sex，介于：女性，男性）×2（target_sex，内部：女性，男性）×2（norm_type，内部：隐性，显式）设计。参与者将看到一个人（目标）的照片以及一个句子，该句子描述了目标，即不遵循隐式规范或明确的规范（取决于试验条件），并将对他们对李克特的目标进行负面评价。比例（0 =“完全不是负面”至6 =“极为负”。照片句子对将随机分组，每个参与者都没有重复。每个参与者将看到所有照片（30）和所有句子（30），从而进行30次试验。
我计划适合以下模型：
  lmer（评分〜参与者_sex * target_sex * norm_type +（1 | garterant_id） +（1 | stone_id） +（1 | photo_id））
 
 如何模拟对RSTUDIO的功率分析的数据，以确定样本量以在α= 0.05处获得90％的功率以检测我的模型中的相互作用效应很小？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/661128/how-to-simulate-data-for-a-three-way-interaction-with-categorical-predictors</guid>
      <pubDate>Sat, 08 Feb 2025 14:17:47 GMT</pubDate>
    </item>
    <item>
      <title>R（NLME）中混合效应模型中残留的奇数模式</title>
      <link>https://stats.stackexchange.com/questions/661138/odd-pattern-in-residual-in-mixed-effect-model-in-r-nlme</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661138/odd-pattern-in-residual-in-mixed-effect-model-in-r-nlme</guid>
      <pubDate>Sat, 08 Feb 2025 12:26:41 GMT</pubDate>
    </item>
    <item>
      <title>投资组合返回的线性回归</title>
      <link>https://stats.stackexchange.com/questions/661144/linear-regression-on-portfolio-returns</link>
      <description><![CDATA[我知道投资组合返回和每个资产类别中的共享，但没有这些资产类别的回报。我的想法是通过表单的线性回归估算不同资产类别的回报
  $$ r _ {\ text {ptf}} = \ beta_1 s_1 + \ dots + \ beta_n s_n s_n + \ epsilon $$   
其中 $ s_i $ 是资产类别的已知股份 $ \ {1，\ dots，n \} $ 和 $ \ beta_i $ 是要估算的系数，该系数最终代表资产类返回。
我觉得我会遇到多重共线性问题，因为我的资产类别的股票将总结到 $ 1 $ 。有什么方法可以解决这个问题？请注意，某些投资组合可能仅投资于某些资产类别，而在其他资产类别中则为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/661144/linear-regression-on-portfolio-returns</guid>
      <pubDate>Sat, 08 Feb 2025 09:49:44 GMT</pubDate>
    </item>
    <item>
      <title>如何将2个序数变量和1个二分法变量组合到一个（最好是连续）变量中？</title>
      <link>https://stats.stackexchange.com/questions/661118/how-to-combine-2-ordinal-variables-and-1-dichotomous-variable-into-a-single-pre</link>
      <description><![CDATA[我有3个变量，这些变量是SES（收入，教育和就业）的指标。前两个是序数（分别为12个级别和3个级别）。就业是二分的。有没有办法将它们组合到单个变量中以捕获参与者SES？我在R中这样做，以引用任何编码问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/661118/how-to-combine-2-ordinal-variables-and-1-dichotomous-variable-into-a-single-pre</guid>
      <pubDate>Sat, 08 Feb 2025 04:55:13 GMT</pubDate>
    </item>
    <item>
      <title>匹配Kaplan-Meier在电子表格中与Lifelines Python包装</title>
      <link>https://stats.stackexchange.com/questions/661089/match-kaplan-meier-in-spreadsheet-with-lifelines-python-package</link>
      <description><![CDATA[使用众所周知的
 
对于每个任期，我都会计算出流失，累积流失以及累积生存。然后，在每个时间点，我都计算了那些搅动的人 /那些可能会搅动的人。然后以累积概率认为这是Kaplan-Meier：
    
这是同一张表，显示了使用的公式：
   
公式的描述：

可乐任期：数据中的独特任期
 COLB帐户：每个任期的帐户计数
 Colc Churn：此时流失的帐户计数
冷累积流失：所有杂种帐户的数量 
 Cole累积生存：总帐户（SUM COLB） - 日期总搅拌
 COLF生存％在每个时间点：在此期间的筹集帐户 /累计生存期间&lt; / li&gt; &lt; / li&gt;
 Colg Kaplan -Meir：Colf *以前的Colg-累积概率

公式在链接的纸张中。
使用Python我在相同的数据上安装了一个km：
 导入pandas作为pd
    从救生线进口kaplanmeierfi​​tter
    导入matplotlib.pyplot作为PLT
    
    ＃加载数据
    TELCO_CHURN = PD.READ_CSV（&#39;https：//docs.google.com/spreadsheets/d/1l5/1l5axjlzdcqskozefrcfpv8in5 ededyxne7t8sbrvfffrsqursbrvfffrsq/export？
    电视_CHURN [&#39;Churn&#39;] =电视_Churn [&#39;Churn&#39;]。MAP（{&#39;YES&#39;：1，&#39;no&#39;：0}）
    
    ＃适合Kaplan-Meier
    kmf = kaplanmeierfi​​tter（）
    kmf.fit（telco_churn [&#39;tenure&#39;]，event_observed = telco_churn [&#39;Churn&#39;]）
    
    ＃在特定时间计算生存概率
    time_points = [5，10，20，30]
    survival_probs = kmf.predict（time_points）
    印刷（reservival_probs）
 
输出：
  5 0.891111
10 0.854915
20 0.804520
30 0.768680
名称：km_estimate，dtype：float64
 
将其与我的电子表格进行比较：
  5：89.44
10：86.26
20：82.24
30：79.77
 
我的电子表格正确吗？我该如何计算此纸上的公里？为什么它与Python的Lifelines软件包计算有所不同？
 [编辑]
这是我屏幕截图的数据，因为似乎没人想查看我共享的Gsheet。这是每个任期水平汇总的分组/减少数据。我已经分享了前3列，任期，帐户，流失。这3列使用电信数据上的公式从Kaggle下载到该级别。所有其余的列均使用公式源自这3个。也许有人可以在电子表格中重新创建KM？：
 任期，帐户，流失
0,11,0
1,613,380
2,238,123
3,200,94
4,176,83
5,133,64
6,110,40
7,131,51
8,123,42
9,119,46
10,116,45
11,99,31
12,117,38
13,109,38
14,76,24
15,99,37
16,80,28
17,87,26
18,97,24
19,73,19
20,71,18
21,63,17
22,90,27
23,85,13
24,94,23
25,79,23
26,79,15
27,72,13
28,57,12
29,72,15
30,72,16
31,65,16
32,69,19
33,64,14
34,65,12
35,88,15
36,50,10
37,65,15
38,59,13
39,56,14
40,64,13
41,70,14
42,65,14
43,65,15
44,51,6
45,61,6
46,74,12
47,68,14
48,64,9
49,66,15
50,68,10
51,68,8
52,80,8
53,70,14
54,68,13
55,64,9
56,80,10
57,65,8
58,67,11
59,60,8
60,76,6
61,76,8
62,70,5
63,72,4
64,80,4
65,76,9
66,89,13
67,98,10
68,100,9
69,95,8
70,119,11
71,170,6
72,362,6
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661089/match-kaplan-meier-in-spreadsheet-with-lifelines-python-package</guid>
      <pubDate>Fri, 07 Feb 2025 12:58:39 GMT</pubDate>
    </item>
    <item>
      <title>Lambda的大小与Ridge Recression的罚款大小</title>
      <link>https://stats.stackexchange.com/questions/661082/size-of-lambda-vs-size-of-penalty-term-in-ridge-regression-and-lasso</link>
      <description><![CDATA[训练山脊回归时，我们最小化
 $$ rss（\ lambda） + \ lambda \ sum_ {j = 1}^p [\ beta_j（\ lambda）]^2 $$ 
其中 $ rss（\ lambda）=（y_i  - （\ beta_0 + \ sum_ {i = 1}^{n_ {train}} \ beta_j（\ beta_j（\ lambda） }））^2 $ 是训练集中的平方残差之和。
确实将罚款权重从 $ \ lambda_1 $ 到 $ \ lambda_2 $ （带有 $ \ lambda_1＆lt; \ lambda_2 $ ）必​​须增加罚款项吗？ IE。我们可以确定
 $$ \ lambda_1 \ sum_ {j = 1}^p [\ beta_j（\ lambda_1）]^2  -  \ lambda_2 \ sum_ {j = 1} lambda_2）]^2 \？$$  
拉索的答案与山脊一样吗？
（我认识到 $ rss（\ lambda_1） = 1}^p [\ beta_j（\ lambda_1）]^2＆gt; \ sum_ {j = 1}^p [\ beta_j（\ lambda_2）]^2 $ 问题。）]]></description>
      <guid>https://stats.stackexchange.com/questions/661082/size-of-lambda-vs-size-of-penalty-term-in-ridge-regression-and-lasso</guid>
      <pubDate>Fri, 07 Feb 2025 09:08:11 GMT</pubDate>
    </item>
    <item>
      <title>此数据的正态测试</title>
      <link>https://stats.stackexchange.com/questions/661064/normality-test-for-this-data</link>
      <description><![CDATA[我进行了一个实验，其中一组使用A和B方法执行任务。每个参与者两次完成了一次调查，并以5个步骤从0到100分开处理的六个问题。我需要比较哪种方法在统计学上是优越的。当使用shapiro – wilk测试评估正常性时，所有分数似乎都通过了测试（即 $ p＆gt; 0.05 $ ），除了方法中的一个问题答：我目前面临的问题是，我可以执行 $ t $   - 对于所有问题，除了未通过方法A中的正态性测试的问题但是它确实在方法B中传递了。数据是 75,15,20,20,35,50,20,35,25 。有趣的是，Matlab不支持Shapiro-Wilk测试。它确实支持 anderson-darling  “ https://uk.mathworks.com/help/stats/kstest.html” rel =“ nofollow noreferrer”&gt; kolmogorov-smirnov 测试。使用Anderson-Darling方法，数据通过正常性测试，但未能通过Kolmogorov-Smirnov测试。您建议处理这个问题吗？

编辑：
为了详细说明，我正在采用NASA任务负载指数，这是一个公认的主观措施。我已经阅读了几篇论文，提到他们使用Shapiro-Wilk测试对正常性进行了测试。如果测试失败，他们会使用Wilcoxon签名的级测试来进一步研究是否有足够的差异。我已经阅读了最近发布的 paper ，作者说

虽然没有明确声明测量水平
NASA-TLX的假设，可以从其设计和
使用。首先，在科学文献中，使用了NASA-TLX分数
使用参数统计，尤其是 t检验和的分析
方差。因此，显然科学界认为NASA-TLX
测量的工作量及其组成维度好像在
至少间隔。

他们继续

共同表明，治疗工作是安全的
负载及其尺寸好像它们是间隔。这是积极的
开发是因为它表明标准参数
大多数研究人员用来评估NASA-TLX的统计数据是有效的。
但是，在考虑个人的测量时，分析师
应该更加小心。在这种情况下，可能是谨慎的
除非具体
有证据表明个人正在以更高的态度对待他们
级别。

根据本文，在我看来，我需要将维度视为序数。因此，我必须使用Wilcoxon签名的秩检验作为非参数测试，以确定方法A是否比方法更好或更糟。
我知道这篇文章分析NASA TLX时要使用的统计检验？；但是，OP有兴趣将所有评分合并为单个分数，根据我提到的论文，这是无效的。]]></description>
      <guid>https://stats.stackexchange.com/questions/661064/normality-test-for-this-data</guid>
      <pubDate>Thu, 06 Feb 2025 22:27:00 GMT</pubDate>
    </item>
    <item>
      <title>横截面数据集的预测比较的重要性</title>
      <link>https://stats.stackexchange.com/questions/661061/significance-in-forecast-comparison-in-cross-sectional-dataset</link>
      <description><![CDATA[我的最终目标是评估与横截面数据集中的模型2相比，模型1是否产生的预测误差明显较小。根据不同的预测精度，例如RMSE或MAE。
让我们假设一个简单的方案我想预测客户支出。我在10年内观察10,000个不同客户的数据，包括收入，区域等信息。根据这些数据，我创建了两个模型，模型1（例如，某些机器学习模型）和模型2（例如，线性回归） ，预测客户支出。培训数据是1  -  7年的数据，测试数据是8  -  10年的数据。。
对于测试集中的每个观察结果，我将预测误差视为预测和实际数量之间的差异。现在，我想评估与模型2相比，模型1是否产生明显较小的预测错误。
我知道是文献评估此类预测差异的一种常见方法。但是，通常在时间序列数据的背景下使用，而我的数据集则是横截面。
为了完整性，我附上了DM测试实现的小R代码。虽然我在这里模拟了简单性的正态分布预测错误，但在我的实际应用中，它们可能不是正态分布的。
这是解决此问题的正确方法，还是有其他方法可以获得两个模型之间的性能是否显着不同？
示例性R代码：
 库（预测）

set.seed（123）

＃样本尺寸
N＆lt; -3000

＃预测误差模型1和模型2，正态分布为简单
m1＆lt;  -  rnorm（n，平均值= 0.02，sd = 0.5）
m2＆lt;  -  rnorm（n，平均= 0.10，sd = 0.5）

dm. -test（M1，M2，替代=; lims＆quort＆quort＆quort h = 1，power = 2）
 
 DM检验的输出：
  diebold-mariano测试

数据：M1M2
dm = -2.2584，预测范围= 1，损耗函数功率= 2，p值= 0.012
替代假设：少
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661061/significance-in-forecast-comparison-in-cross-sectional-dataset</guid>
      <pubDate>Thu, 06 Feb 2025 21:51:03 GMT</pubDate>
    </item>
    </channel>
</rss>