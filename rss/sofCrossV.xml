<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 24 Apr 2024 15:15:15 GMT</lastBuildDate>
    <item>
      <title>一级项失去显着性，但二级项在倾向匹配样本上仍然显着</title>
      <link>https://stats.stackexchange.com/questions/645738/first-degree-term-loses-significance-but-second-degree-term-stays-significant-on</link>
      <description><![CDATA[我的回归如下：
$$ y = \alpha + \mu L + \beta_1 x + \beta_2 x^2 + \varepsilon $$
其中 L 是虚拟变量，x 是控制变量。
当我运行回归时，$x$ 和 $x^2$ 都很重要。我使用 $L$、$x$ 和 $x^2$。匹配样本的回归结果仅对 $x^2$ 有意义，对 $x$ 有意义span&gt; 消失。
你能帮我解释一下这个结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645738/first-degree-term-loses-significance-but-second-degree-term-stays-significant-on</guid>
      <pubDate>Wed, 24 Apr 2024 15:02:31 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归是否与衡量组间差异的传统统计检验一样可靠？</title>
      <link>https://stats.stackexchange.com/questions/645737/is-logistic-regression-as-reliable-as-traditional-statistical-tests-to-measure-d</link>
      <description><![CDATA[我正在开展病例对照分析，我必须报告这些组是否实际上具有可比性。我对感兴趣的自变量（例如年龄、性别、身高、体重、每个患者患有的病症等）进行了不同的统计测试。但是，我正在重新考虑使用逻辑回归，以便查看是否有任何变量可以有意义地用于预测属于一组或另一组。
我的问题是：逻辑回归对于此目的是否与传统方法一样可靠（例如对一个变量使用 t 检验，对另一个变量使用 Mann-Whitney U 等）？或者潜在问题（例如多重共线性）是否限制了该方法测量统计显着差异的能力？]]></description>
      <guid>https://stats.stackexchange.com/questions/645737/is-logistic-regression-as-reliable-as-traditional-statistical-tests-to-measure-d</guid>
      <pubDate>Wed, 24 Apr 2024 14:50:50 GMT</pubDate>
    </item>
    <item>
      <title>我是否使用包装车中使用 III 型 Anova 函数的二项式 glm 的正确检验统计量？</title>
      <link>https://stats.stackexchange.com/questions/645735/am-i-using-the-correct-test-statistic-for-a-binomial-glm-using-the-type-iii-anov</link>
      <description><![CDATA[我试图了解事件 Y 的可能性如何受到两个因素 A（5 个级别）和 B（2 个级别）的影响，我的模型如下：
type3.Y &lt;- list(A = contr.sum, B = contr.sum)
modelY&lt;-glm(Y ~ A*B，族=二项式（链接=“logit”），数据=可能性，对比= type3.Y）
摘要（型号Y）

我目前正在使用 Anova() 函数来确定模型中每一项的重要性，如下所示：
Anova(model.Y, type = 3, test.statistic = &quot;LR&quot;)

偏差分析表（III型测试）

回应：是
                    LR Chisq Df Pr(&gt;Chisq)
8.4573 4 0.07619 。
B 0.4137 1 0.52010
答：B 7.2847 4 0.12159

我的理解是，LR Chisq 值表明，在考虑所有其他项后，包含特定项的模型是否比不包含特定项的模型更好地解释数据，即如果该值为正，则模型具有该术语更好地解释了数据（如果值为负，则没有该术语的模型可以更好地解释数据）。
但是，我知道可以在此函数中编码其他测试统计数据，即 test.statistic =“F”、test.statistic =“Wald”）。这两个给出的结果略有不同，所以我想知道：
a) 这些测试之间有什么区别？
b) 我是否使用了正确的数据分析方法（是否存在特定情况下您会使用其中一种方法而不是其他方法）？我还注意到，如果我不指定测试统计量，则函数默认为 LR。]]></description>
      <guid>https://stats.stackexchange.com/questions/645735/am-i-using-the-correct-test-statistic-for-a-binomial-glm-using-the-type-iii-anov</guid>
      <pubDate>Wed, 24 Apr 2024 13:56:07 GMT</pubDate>
    </item>
    <item>
      <title>平滑空间数据以解决隐私问题</title>
      <link>https://stats.stackexchange.com/questions/645734/smoothing-spatial-data-for-privacy-issues</link>
      <description><![CDATA[我有一个数据集，其中包含大约 6000 个与市政当局相关的观察结果。
数据集的结构包括四列：城市代码、城市中的企业数量、拥有至少 n 名员工的企业数量以及后者占总数的百分比。
由于一些城市非常小，因此观察到百分比为 0 或 100。
因为我需要公开这个数据集，所以我需要在不丢失观察结果的情况下去掉这些 0 和 100。因此，我应该应用一些空间平滑算法。
我尝试使用空间移动平均线，但它对结果的扭曲太大（如果拥有 3000 家企业的城市是拥有 0 家企业的城市的邻居，则 SMA 的扭曲程度太大）。
如何去掉 0 和 1，而不扭曲（过多）其他城市的数据？我可以使用什么算法？
数据集通过市政代码链接到 shapefile。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645734/smoothing-spatial-data-for-privacy-issues</guid>
      <pubDate>Wed, 24 Apr 2024 12:42:16 GMT</pubDate>
    </item>
    <item>
      <title>如何将药物暴露期纳入事件分析时间？</title>
      <link>https://stats.stackexchange.com/questions/645733/how-to-include-drug-exposure-periods-in-a-time-to-event-analysis</link>
      <description><![CDATA[我发现很难在文献中找到一种方法来处理如何处理服用药物（或不服用药物）的暴露时间对未来结果的影响。假设我的结果是死亡，并且我有纵向药物数据：
person_id |首次处方日期 |持续用药月数 |药物类型 |研究开始日期 |研究结束日期 |地位
----------+------------------------+------------- --------+------------+------------------+--------- -------+--------
1 | 2012-01-06 | 6 |药物C | 2010-01-01 | 2020-12-31 | 0
2 | 2011-08-27 | 10 | 10药物C | 2010-01-01 | 2019-09-01 | 1
2 | 2012-03-01 | 8 |药物B | 2010-01-01 | 2019-09-01 | 1
3 |不适用 | 0 |没有药物| 2010-01-01 | 2020-12-31 | 0
4 | 2010-08-10 | 2 |药物A | 2010-01-01 | 2016-10-23 | 1
4 | 2014-11-30 | 12 | 12药物C | 2010-01-01 | 2016-10-23 | 1
5 | 2011-05-29 | 24 |药物B | 2010-01-01 | 2020-12-31 | 0
5 | 2014-03-27 | 4 |药物A | 2010-01-01 | 2020-12-31 | 0
6 |不适用 | 0 |没有药物| 2010-01-01 | 2013-12-12 | 1

只有 1 行数据表明参与者从未服用过药物，并且对于一个人服用的每种药物都有一行数据，其中包括哪种药物、首次开处方的时间和持续时间。状态栏表示生存。
我知道我可以只记录是否服用药物的二元结果，甚至可以记录研究期间接触药物的时间比例，但即使是第二种方法也没有考虑他们何时接触药物。 
本文讨论了许多方法和陷阱https://onlinelibrary.wiley .com/doi/full/10.1002/pds.4372 使用此类数据 - 但我仍然没有留下结论性的路径。有没有人有什么建议？我正在使用 R，所以任何可以提供帮助的软件包都会很棒。我经常使用生存包，但从来没有使用过顺序数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/645733/how-to-include-drug-exposure-periods-in-a-time-to-event-analysis</guid>
      <pubDate>Wed, 24 Apr 2024 12:33:51 GMT</pubDate>
    </item>
    <item>
      <title>两个时间段内组间增量的统计检验（分类数据）</title>
      <link>https://stats.stackexchange.com/questions/645732/statistical-test-of-increase-between-groups-in-two-time-periods-categorial-data</link>
      <description><![CDATA[我想检查组之间的百分比变化和二项式变量的时间是否显着不同。使用什么测试？
在 t0 的 A 组（n = 1000）中，我们有 10% 的份额回答“是”，在 t1 中有 15% 的份额回答“是”-&gt;所以股份增加+50%
在 t0 的 B 组（n = 100）中，我们有 50% 的份额回答“是”，在 t1 中有 55% 的份额回答“是”。 -&gt;所以股份增加+10%
我想检查 A 组的 +50% 和 B 组的 +10% 是否有统计差异
我已经检查过：

差异中的差异（两个百分比变化之间的统计显着性）并通过模型进行测试，但它比较的是份额，而不是份额的变化。
二项式测试（测试是否两个二项式分布在统计上彼此不同），因为在我的一些真实示例中，我们有下降并且平方根值为负
]]></description>
      <guid>https://stats.stackexchange.com/questions/645732/statistical-test-of-increase-between-groups-in-two-time-periods-categorial-data</guid>
      <pubDate>Wed, 24 Apr 2024 12:32:21 GMT</pubDate>
    </item>
    <item>
      <title>二项式分布的概率</title>
      <link>https://stats.stackexchange.com/questions/645731/probability-in-binomial-distribution</link>
      <description><![CDATA[假设我们想证明没有放回的球的绘制不是二项式。
我们想要找到 3 次抽奖中 5 个红球和 5 个蓝球无替换的红球数量。这是一个经典的超几何分布。我读到超几何分布的成功概率各不相同。
然而，对于所有 i=1,2,3，P[第 i 回合的红球]= 0.5。我的理解是条件概率变化而边际概率保持不变。
我的问题是我们如何定义二项式分布的成功概率？是条件概率还是边际概率？说超几何分布的成功概率是变化的，因此不是二项式的，这是否有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/645731/probability-in-binomial-distribution</guid>
      <pubDate>Wed, 24 Apr 2024 12:16:00 GMT</pubDate>
    </item>
    <item>
      <title>线性分类公式中的各项代表什么？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645729/what-do-the-terms-in-a-linear-classification-formula-represent</link>
      <description><![CDATA[我目前正在通过麻省理工学院的课程学习机器学习。我来自非技术背景，无法理解本次线性分类器讲座中显示的一些方程：

https://youtu.be/yOKDzd73KgM?t=57
https://youtu.be/yOKDzd73KgM?t=349

如果有人能用简单的语言向我解释这些方程，我将非常感激。下面等式中的每一项代表什么？
$$θ_1x_1+θ_2x_2+θ_0=0$$]]></description>
      <guid>https://stats.stackexchange.com/questions/645729/what-do-the-terms-in-a-linear-classification-formula-represent</guid>
      <pubDate>Wed, 24 Apr 2024 12:07:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么二项式 GLM 的 III 型方差分析输出中会出现负卡方值？</title>
      <link>https://stats.stackexchange.com/questions/645726/why-do-i-get-a-negative-chi-squared-value-in-my-type-iii-anova-output-for-my-bin</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645726/why-do-i-get-a-negative-chi-squared-value-in-my-type-iii-anova-output-for-my-bin</guid>
      <pubDate>Wed, 24 Apr 2024 10:20:21 GMT</pubDate>
    </item>
    <item>
      <title>多层次模型和随机效应：仍然困惑[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645725/multi-level-models-and-random-effects-still-confused</link>
      <description><![CDATA[我知道有很多关于多级模型、随机效应、固定效应等解释的帖子。但在阅读完这些内容并观看由 Prof. Mikko Rönkkö（芬兰于韦斯屈莱大学），我对某些具体方面仍然感到困惑。
最重要的是：我们什么时候真正需要随机效应模型。 YouTube 系列，以及这些两篇文章似乎暗示，如果我只对模型固定部分的平均效果感兴趣，我不需要随机即使数据是分层的，也可以使用效应模型，因为在这种情况下，聚类标准误差就足够了。仅当我对聚类之间的方差感兴趣时，我才需要采用随机效应模型。这是正确的吗？
我认为通过一个模仿我正在使用的数据的示例来理解所有这些对我来说是最容易的：

鉴于有汇总的横截面调查数据，其中个人
受访者分布在多个国家，并且调查是多次进行的
多年来每个国家的次数。

研究问题旨在查明国家层面的变量（例如 GDP）是否会影响受访者回答有关生活满意度问题的方式。但我只对 GDP 对生活满意度的总体影响感兴趣。

在此示例中，我是否需要随机效应模型（如果假设成立）？或者对标准错误进行聚类就足够了吗？我在这里测量什么效果？之间的效果？

]]></description>
      <guid>https://stats.stackexchange.com/questions/645725/multi-level-models-and-random-effects-still-confused</guid>
      <pubDate>Wed, 24 Apr 2024 10:07:43 GMT</pubDate>
    </item>
    <item>
      <title>机器学习建模建议，其中某个功能部分缺失，但存在时信息丰富</title>
      <link>https://stats.stackexchange.com/questions/645722/ml-modelling-advice-where-a-feature-is-partially-missing-but-highly-informative</link>
      <description><![CDATA[我正在构建一个模型来预测网站上的客户购买事件。特别针对那些在模型运行后过夜但尚未购买的客户。预测很重要，但特征洞察也同样关键。
我正在收集有关客户的基本数据（例如设备、大致位置）、他们的点击详细信息（例如引荐来源网址和营销来源、访问的页面），并自己从中得出一些特征，例如时间戳，最显着的是“自上次访问以来的时间”。
我的困境是这样的：
在训练期间，“自上次访问以来的时间”会被显示。对于那些我们不止一次见到的客户来说，这成为了一个非常重要的购买指标。然而，这些客户只是少数（30%）
但是，那些只访问一次并立即购买的人没有“自上次查看以来的时间”价值，因为他们已经完成了他们的旅程，TimeSince = NA（或者零，如果你愿意）。
如果我仅针对访问两次或多次的客户构建模型（因此我有“此后的时间”），那么我将从那些 1 次客户那里留下很多见解。
但是，如果我构建一个包含 1 次访问者的模型，那么我的模型会将 TimeSince=NA 作为指示购买的泄漏数据，从而使模型和准确性指标产生偏差。
我需要建议吗？
对我来说，理想的模型就是“忽略” NA 的字段，但在我有值的地方使用它。但我目前使用的是 XGB，这不是树模型的工作原理！ NA 被视为离散值并推入分支。
我的第一个问题：是否有其他分类器模型可以选择性地仅在填充的地方使用字段？
我的另一个想法是某种合奏。一个模型，每个人都在，但没有这个自始至终的字段，因此它不会泄漏，第二个模型有该字段，但仅适用于访问次数超过 2 次的访问者......然后是这些的某种组合。
我对这个想法有点挣扎，因为随后洞察部分变得更加复杂，并且这是否总体上是最佳路线。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645722/ml-modelling-advice-where-a-feature-is-partially-missing-but-highly-informative</guid>
      <pubDate>Wed, 24 Apr 2024 09:34:36 GMT</pubDate>
    </item>
    <item>
      <title>在电价预测神经网络的训练、验证和测试集中分割 3 年每小时数据的好方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/645719/what-is-a-good-approach-to-split-3-years-of-hourly-data-in-a-train-validation-a</link>
      <description><![CDATA[我想训练一个简单的神经网络来预测某个地区的电价。然而，我只有“有限”的可用数据（该地区连续 3 年的历史价格、发电量和负荷，间隔 1 小时 - 不允许导入其他数据）。首先，我知道不允许随机分割数据，因为它是一个时间序列。接下来，文献建议以 60-20-20、70-15-15 或 80-10-10 的方式拆分以获得训练集、验证集和测试集。分裂“2年、0.5年、0.5年”训练集、验证集和测试集分别将导致 1 月至 6 月期间的超参数优化，并在 7 月至 12 月期间测试模型。直觉上，这对我来说不是一个好方法，因为这会导致验证和测试集中的季节性不匹配。这种直觉是否正确？如果正确，可以采取什么替代方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/645719/what-is-a-good-approach-to-split-3-years-of-hourly-data-in-a-train-validation-a</guid>
      <pubDate>Wed, 24 Apr 2024 09:26:44 GMT</pubDate>
    </item>
    <item>
      <title>手动计算的发生率与泊松回归的估计边际均值获得的发生率不同</title>
      <link>https://stats.stackexchange.com/questions/645612/incidence-rates-from-manual-calculation-differs-from-that-obtained-from-the-esti</link>
      <description><![CDATA[
泊松回归

我做了一个泊松回归，其中数据是个人级别的数据，因变量事件如果个人有事件则为1，如果个人没有事件则为0。自变量 positive_culture_group  是我试图进行比较的 3 个组（Aerobic、Blood 和 Aerobic &amp; Blood&lt; /代码&gt;）。我有一个偏移量，它是 time_to_event 的日志。然后，我使用 emmeans::emmeans 函数估计边际均值来计算发生率。这是代码：
模型 &lt;- glm(event ~ Positive_culture_group + offset(log(time_to_event/365.25)),
数据= df，族=“泊松”）
emmeans::emmeans(模型, ~ Positive_culture_group, type = “response”, offset = log(100000))

结果：
 Positive_culture_group 率 SE df asymp.LCL asymp.UCL
 有氧 8500 1578 英孚 5907 12232
 血液 46353 4440 信息 38419 55925
 有氧运动血液 10449 1975 信息 7215 15134

使用的置信水平：0.95
间隔是从对数刻度反向转换的


手动计算

这是我使用过的代码
&lt;前&gt;&lt;代码&gt;
df &lt;- df %&gt;% filter(positive_culture_group == &quot;Aerobic&quot;) # 对血液和有氧 &amp; 进行相应更改血

# 事件数量
new_cases &lt;- sum(df$event == 1)

# 涉及的总人年
person_years &lt;- sum(df$time_to_event)/365.25

# 计算发生率
发病率 &lt;- (new_cases / person_years) * 100000 # 转换为每 100,000 人年

# 精确泊松法计算 CI
lower_bound &lt;- qpois(0.025, lambda = new_cases) / person_years * 100000
upper_bound &lt;- qpois(0.975, lambda = new_cases) / person_years * 100000

结果是
有氧运动
CRC发病率：879.3436/10万人年
95% CI（下限）：0
95% CI（上限）：2051.802

血
CRC发病率：2126.266/10万人年
95% CI（下限）：425.2532
95% CI（上限）：4252.532

有氧运动血
CRC发病率：746.3678/10万人年
95% CI（下限）：0
95% CI（上限）：1865.919

如何继续使用泊松回归并尝试获得与手动收集相同的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/645612/incidence-rates-from-manual-calculation-differs-from-that-obtained-from-the-esti</guid>
      <pubDate>Tue, 23 Apr 2024 08:58:37 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点的 NHST</title>
      <link>https://stats.stackexchange.com/questions/645547/nhst-from-the-bayesian-point-of-view</link>
      <description><![CDATA[在如何通过八个简单步骤成为贝叶斯主义者中，说明了
&lt;块引用&gt;
频率统计仅允许对 P（数据 | 理论）进行陈述。假设理论是正确的，则评估观察到的（或更极端的）数据的概率。 Dienes 认为，假设理论正确的数据概率通常并不是研究人员感兴趣的概率。什么
研究人员通常想知道的是 P（理论 | 数据）：假设数据是获得的数据，那么该理论正确的概率是多少？

我的问题是：从贝叶斯的角度来看，NHST 给出的答案的价值是什么（关于p(data|theory)的陈述）？]]></description>
      <guid>https://stats.stackexchange.com/questions/645547/nhst-from-the-bayesian-point-of-view</guid>
      <pubDate>Mon, 22 Apr 2024 12:53:32 GMT</pubDate>
    </item>
    <item>
      <title>我的列联表标准化残差图不是标准正态分布，为什么？</title>
      <link>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</link>
      <description><![CDATA[我正在学习列联表中的标准化残差。
在“分类数据分析简介”中作者：Alan Agresti (2007) 我发现了以下内容：

我想验证上述陈述，即在零假设下，较大列联表的标准化残差分布为标准正态分布。
作为验证我的代码的教科书示例参考，我使用 Eric Naioti 和 Erika Mudrak 使用调整后的标准化残差解释列联表：

这里还显示标准化残差的数字：

我可以用自己的代码重现：
数组([[ 6.13651969, -4.25381552, -0.57502606, -2.28789602],
       [ 2.16428238, -3.39788279, 2.05021621, -0.50826301],
       [-0.10082422、-2.31105226、0.9895118、2.5765686]、
       [-8.32824833、9.96755012、-2.73797698、0.73202319]])

所以现在我知道那部分没有错误，我生成了一个相当大的列联表，有 4000 行和 3000 列。我画出了“观察到的”单元格条目均匀分布在 10 到 100 之间，我认为这应该会产生独立的单元格内容。
然后我应用了与上面相同的代码，完全期望单元标准化残差的直方图显示标准正态分布。
但是，我得到了这个：

问题：为什么我的直方图不是标准正态分布或者我遗漏了什么？
2024 年 4 月 24 日更新：评论中指出，数据不是根据原假设生成的。原假设为： $H_{0}: \pi_{ij}=\pi_{i+}\pi_{+j}$，它表明数据为独立。均匀分布就可以做到这一点，对吗？那么有人可以进一步解释一下吗，不幸的是我在这里错过了这一点。
我用来生成绘图的代码是这样的：
将 numpy 导入为 np
从 scipy 导入统计数据
导入 matplotlib
从 matplotlib 导入 pyplot 作为 plt

matplotlib.use(&#39;TkAgg&#39;)


plt.ion()


N_ROWS = 4000
N_COLS = 3000

# 生成独立的 (??) 观察结果
rng = np.random.default_rng(1)
df_obs = rng.integers(低=10，高=100，大小=(N_ROWS，N_COLS))

# 获取期望值，观察低 p 值 (??)
chi2, pvalue, dof, df_exp = stats.chi2_contingency(df_obs, Correction=False)

# 获取边际值，用于计算标准化残差（如下）
margin_col = df_obs.sum(轴=1)
margin_row = df_obs.sum(轴=0)
sum_tot = margin_col.sum()

# 循环每个单元格，记录其残差和标准化残差
resids_lst = 列表()
resids_std_lst = 列表()
对于范围内的 irow(N_ROWS)：
    对于范围内的 icol(N_COLS)：

        obs = df_obs[irow, icol]
        exp = df_exp[irow, icol]

        marg_col = margin_col[irow]
        marg_row = margin_row[icol]
        std_fac = exp * (1. - marg_col/sum_tot) * (1. - marg_row/sum_tot)

        残差 = obs - exp
        resid_std = resid / np.sqrt(std_fac)

        resids_std_lst.append(resid_std)

# 绘制记录的残差
plt.figure()
plt.suptitle(&#39;期望标准化残差的标准正态分布？&#39;)
plt.hist(resids_std_lst, alpha=0.5, label=&#39;标准化残差&#39;)
plt.图例()
]]></description>
      <guid>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</guid>
      <pubDate>Sun, 21 Apr 2024 15:36:52 GMT</pubDate>
    </item>
    </channel>
</rss>