<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 15:17:51 GMT</lastBuildDate>
    <item>
      <title>如何测试事件频率（梯度）是否随时间变化？</title>
      <link>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</link>
      <description><![CDATA[我有 Python 中的时间序列数据，用于跟踪特定操作随时间的变化。我已经量化了这些操作，并想测试这些事件在单位时间内的频率（基本上是梯度）是否随着时间的推移而发生统计变化。基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
数据由时间戳和一列组成，该列指示操作是否在该时间戳发生。一些时间戳有重复发生的事件（用相同的 ID 分组），而其他时间戳为空或包含单个事件。哪些统计方法（以及 Python 中的库）最适合进行此分析？
data = {
&#39;timestamp&#39;: [
&#39;00:01&#39;, &#39;00:02&#39;, &#39;00:03&#39;, &#39;00:04&#39;, &#39;00:05&#39;, 
&#39;00:06&#39;, &#39;00:07&#39;, &#39;00:08&#39;, &#39;00:09&#39;, &#39;00:10&#39;, 
&#39;00:11&#39;, &#39;00:12&#39;, &#39;00:13&#39;, &#39;00:14&#39;, &#39;00:15&#39;
],
&#39;event_group&#39;: [
1, 1, &#39;&#39;, &#39;&#39;, 2, 
2, 2, &#39;&#39;, &#39;&#39;, 
&#39;&#39;, 3, &#39;&#39;, &#39;&#39;, 4, 4
]
}

df = pd.DataFrame(data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</guid>
      <pubDate>Wed, 06 Nov 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>R 中多个组之间的计数/比例的统计比较？</title>
      <link>https://stats.stackexchange.com/questions/656837/statistical-comparison-of-counts-proportions-between-multiple-groups-in-r</link>
      <description><![CDATA[我正在努力为一个数据集选择适当的统计分析，该数据集中有多个组（groupA-groupE），每个组在两个类别（健康或患病）中都有一定数量的计数，也可以表示为比例（患病/[患病+健康]）：
df &lt;- data.frame(group = c(&quot;groupA&quot;,&quot;groupB&quot;,&quot;groupC&quot;,&quot;groupD&quot;,&quot;groupE&quot;),
n_sick = c(12, 32, 99, 37, 48),
n_healthy = c(36, 250, 120, 68, 93))
df %&lt;&gt;% mutate(tot = n_sick + n_healthy, prop = n_sick / tot)

我想找出哪些组在统计上彼此具有不同的比率，类似于我在 ANOVA/Kruskal-Wallis+事后检验中所做的操作（当存在重复时）。但是，这显然在这里不起作用，因为数据是端点，因此不包含变化。我发现 stats 包包含一个名为 pairwise_prop_test 的函数，它看起来就像是我想要它做的事情：
t &lt;- as.table(rbind(
c(12, 32, 99, 37, 48),
c(36, 250, 120, 68, 93)))
dimnames(t) &lt;- list(
condition = c(&quot;n_sick&quot;, &quot;n_healthy&quot;),
group = c(&quot;groupA&quot;,&quot;groupB&quot;,&quot;groupC&quot;,&quot;groupD&quot;,&quot;groupE&quot;))

pairwise_prop_test(t, p.adjust.method = &quot;bonferroni&quot;)

... 它会针对组间每次比较得出一个 p.adj 值（例如，组 B 与组 C 不同）。这是正确的方法吗，还是我忽略了什么？感谢您抽出时间来提供帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656837/statistical-comparison-of-counts-proportions-between-multiple-groups-in-r</guid>
      <pubDate>Wed, 06 Nov 2024 14:33:01 GMT</pubDate>
    </item>
    <item>
      <title>相关性质的乘积</title>
      <link>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</link>
      <description><![CDATA[corr(A,B)*corr(B,C) 是否与 corr(A,C) 有一定关联，还是完全独立？
此乘积 (corr(A,B)*corr(B,C)) 有任何属性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</guid>
      <pubDate>Wed, 06 Nov 2024 14:31:48 GMT</pubDate>
    </item>
    <item>
      <title>Pymc-BART 索引错误</title>
      <link>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</link>
      <description><![CDATA[我尝试按照此处的示例笔记本进行操作，但在执行代码时遇到了一些 IndexError。
这是一个最小的工作示例：
import numpy as np
import pandas as pd
import pymc as pm
import pymc_bart as pmb
import pytensor.tensor as pt
from scipy.special import logit

# 读取样本数据
data_df = pd.read_csv(
&quot;https://raw.githubusercontent.com/juanitorduz/website_projects/master/data/retention_data.csv&quot;,
parse_dates=[&quot;cohort&quot;, &quot;period&quot;],
)

# 处理数据
eps = np.finfo(float).eps
train_data_red_df = data_df.query(&quot;cohort_age &gt; 0&quot;).reset_index(drop=True)
train_obs_idx = train_data_red_df.index.to_numpy()
train_n_users = train_data_red_df[&quot;n_users&quot;].to_numpy()
train_n_active_users = train_data_red_df[&quot;n_active_users&quot;].to_numpy()
train_retention = train_data_red_df[&quot;retention&quot;].to_numpy()
train_retention_logit = logit(train_retention + eps)
train_data_red_df[&quot;month&quot;] = train_data_red_df[&quot;period&quot;].dt.strftime(&quot;%m&quot;).astype(int)
features: list[str] = [&quot;age&quot;, &quot;cohort_age&quot;, &quot;month&quot;]
x_train = train_data_red_df[features]

# 模型
with pm.Model(coords={&quot;feature&quot;: features}) as model:
# --- 数据 ---
model.add_coord(name=&quot;obs&quot;, values=train_obs_idx, mutable=True)
x = pm.MutableData(name=&quot;x&quot;, value=x_train, dims=(&quot;obs&quot;, &quot;feature&quot;))
n_users = pm.MutableData(name=&quot;n_users&quot;, value=train_n_users, dims=&quot;obs&quot;)
n_active_users = pm.MutableData(name=&quot;n_active_users&quot;, value=train_n_active_users, dims=&quot;obs&quot;)

# --- 参数化 ---
# BART 组件在
# logit 变换下对保留率的图像进行建模，因此范围不限制在 [0, 1]。
mu = pmb.BART(
name=&quot;mu&quot;,
X=x,
Y=train_retention_logit,
dims=&quot;obs&quot;,
)
# 我们使用逆 logit 变换将保留率恢复到 [0, 1]。
p = pm.Deterministic(name=&quot;p&quot;, var=pm.math.invlogit(mu), dims=&quot;obs&quot;)
# 我们添加一个小的 epsilon 以避免数值问题。
p = pt.switch(pt.eq(p, 0), eps, p)
p = pt.switch(pt.eq(p, 1), 1 - eps, p)

# --- 可能性 ---
n_active_users_estimated = pm.Binomial(
name=&quot;n_active_users_estimated&quot;,
n=n_users,
p=p,
perceived=n_active_users,
dims=&quot;obs&quot;,
)

pm.model_to_graphviz(model=model)

# 拟合模型
使用模型：
idata = pm.sample(draws=100, chains=1)
posterior_predictive = pm.sample_posterior_predictive(trace=idata)

我已检查 x_train 和 train_retention_logit 的形状传递给 BART 方法，它们似乎具有正确的形状，分别为 (1128,3) 和 (1128,)。
然而，后验采样返回了一个我无法追溯到其来源的错误：
IndexError：元组索引超出范围
导致错误的应用节点：BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}(RNG(&lt;Generator(PCG64) at 0x1721017E0&gt;), [], x, [-1.609437 ... .51268651], 100, 0.95, 2.0, [])
Toposort 索引：0
输入类型：[RandomGeneratorType, TensorType(int64, shape=(0,)), TensorType(float64, shape=(None, None)), TensorType(float64, shape=(1128,)), TensorType(int8, shape=()), TensorType(float64, shape=()), TensorType(float32, shape=()), TensorType(float64, shape=(0,))]
输入形状：[&#39;无形状&#39;, (0,), (1128, 3), (1128,), (), (), (), (0,)]
输入步幅：[&#39;无步幅&#39;, (0,), (8, 9024), (8,), (), (), (), (0,)]
输入值：[Generator(PCG64) at 0x1721017E0, array([], dtype=int64), &#39;未显示&#39;, &#39;未显示&#39;, array(100, dtype=int8), array(0.95), array(2., dtype=float32), array([], dtype=float64)]
输出客户端：[[output[1](BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}.0)], [Second(mu, [-3.09309984])]]

相关库的版本为：
python 3.10.15
pymc 5.16.2
pymc-bart 0.7.0

以防它与软件包版本之间的行为差​​异有关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</guid>
      <pubDate>Wed, 06 Nov 2024 14:10:28 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归后需要进行后续分析吗？</title>
      <link>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</link>
      <description><![CDATA[我正在研究一组 3200 名患者，他们存在许多术后并发症风险因素。我在 R 中进行了逻辑回归，并使用 step() 函数改进了回归。因此，我确定了几个非常重要的风险因素。其中之一就是液体平衡。众所周知，液体过多和过少都可能促进并发症，但我从 R 中得到的是，每增加 100 毫升液体，并发症的可能性就会增加 0.03（估计值）。P=0.001。
我需要对此进行某种事后分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</guid>
      <pubDate>Wed, 06 Nov 2024 12:00:05 GMT</pubDate>
    </item>
    <item>
      <title>样本量越大，错误拒绝 0 假设的风险是否会越大？</title>
      <link>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</link>
      <description><![CDATA[我经常看到类似这样的话：“如果样本量足够大，较小的效应量可以产生显著的结果”。我不太明白这一点。
对我来说，这听起来是这样的：增加样本量，你最终肯定会拒绝 0 假设（也就是说，如果你将样本量增加到一定大小，你 100% 肯定会拒绝 0 假设）。
重新阅读此主题。据我所知，鉴于我在统计学方面的经验，0 假设被正确拒绝。
决定在 ttest_1samp 测试的代码中检查这一点，使 popmean=15.03 与样本 (mean=15) 的差异非常小。滑块选择 N - 样本，分布实时重新绘制，垂直条是上限值（蓝色）和 p_value（橙色）。
在大约 N - 4000 之后，在大多数情况下，零假设被拒绝。更不清楚的是，在 popmean=15 时，有时也会拒绝零假设（即均值相等）。
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import t, norm, ttest_1samp
from matplotlib.widgets import Slider

fig, ax = plt.subplots()
fig.subplots_adjust(bottom=0.25)

ax_n = fig.add_axes([0.25, 0.15, 0.65, 0.03])
s_n = Slider(ax_n, &quot;N&quot;, valmin=15, valmax=16000,valinit=30, valstep=1)

rng = np.random.default_rng(1)

def更新（val）：
N = s_n.val
rvs = np.sort（norm.rvs（loc=15，scale=1，size=N，random_state=rng））
mu，std = np.mean（rvs），np.std（rvs）
z_statistic =（rvs - mu）/ std
df = N - 1
pdf = t.pdf（rvs，loc=mu，scale=std，df=df）
p_value = ttest_1samp（rvs，popmean=15.03）[1]
ax.clear()
ax.plot（z_statistic，pdf，lw=2，color=“red”）
ax.axvline（x=t.ppf（0.975，df=df），linestyle=“--”， color=&quot;蓝色&quot;)
ax.axvline(x=t.ppf(1 - 0.975, df=df), linestyle=&quot;--&quot;, color=&quot;蓝色&quot;)
ax.axvline(x=t.ppf(p_value/2, df=df), linestyle=&quot;--&quot;, color=&quot;橙色&quot;)
ax.axvline(x=-t.ppf(p_value/2, df=df), linestyle=&quot;--&quot;, color=&quot;橙色&quot;)
ax.text(0, (np.max(pdf) + np.min(pdf))/2, &quot;p_value =&quot; + str(round(p_value, 4)), fontsize=12)

s_n.on_changed(update)
update(0)

plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</guid>
      <pubDate>Wed, 06 Nov 2024 11:43:12 GMT</pubDate>
    </item>
    <item>
      <title>使用无模型参考模型的 Heidke 技能得分名称</title>
      <link>https://stats.stackexchange.com/questions/656822/name-for-heidke-skill-score-with-model-free-reference-model</link>
      <description><![CDATA[Heidke 技能得分是一种常用的量化预测技能的方法。它遵循技能得分 (SS) 的一般定义：
$$SS = \frac{l_m-l_r}{l_p-l_r},$$
其中 $l_p$ 表示完美模型的损失（通常为零），$l_m$ 表示模型损失，$l_r$ 表示某些参考模型的损失。给出以下列联表惯例：

摘自 Appelman 1960，$l_m = \frac{b+c}{T}$ 和 $l_r = \frac{(a+c)(a+b) + (b+d)(c+d)}{T^2}$。因此，参考模型是一个随机猜测模型，其成功概率与模型预测相同。这导致 Heidke 技能得分为 $HSS = \frac{2(ad-bc)}{(a+b)(b+d) +(a+c)(c+d)}$。这种选择让参考模型依赖于预测模型。
作为替代方案，Appelman 1960 提出了一个确定性参考模型，预测“是”如果 $X&gt;Y$，则为“否”，否则为“否”。这导致技能得分为 $\frac{d-b}{c+d}$。
我的问题是关于这两者之间的折衷，即成功概率为 $X/T$ 的随机猜测模型，因此仅基于 观察，而不会像 Appleman 技能得分的选择那样偏斜。该参考模型的损失为 $l_r = 2\frac{(b+d)(a+c)}{T^2}$，技能得分为 $\frac{(a+c)(d-c)+(b+d)(a-b)}{2(b+d)(a+c)}$。我在文献中找不到这个技能得分，它曾经被使用过或命名过吗？为什么没有？]]></description>
      <guid>https://stats.stackexchange.com/questions/656822/name-for-heidke-skill-score-with-model-free-reference-model</guid>
      <pubDate>Wed, 06 Nov 2024 10:08:54 GMT</pubDate>
    </item>
    <item>
      <title>理解广义加性模型中相似平滑函数的含义</title>
      <link>https://stats.stackexchange.com/questions/656821/understanding-the-implications-of-similar-smooth-functions-in-generalised-additi</link>
      <description><![CDATA[我对 GAM 模型有疑问。
如果我拟合两个 GAM 模型，一个包含所有变量，另一个每次添加一个变量，并且得到的平滑函数相似，这意味着什么？
为了非常清楚，我提供了一个例子：
假设我们正在使用广义加性模型 (GAM) 分析温度、湿度和风速对能源消耗的影响。我决定拟合两个模型：
模型 A：我同时包括所有预测因子（温度、湿度和风速）。
模型 B：我每次拟合多个具有一个预测因子的模型，因此您可以分别观察每个变量的平滑函数的影响。
如果模型 A 和模型 B 中各个模型的预测因子（例如湿度）的平滑函数看起来非常相似，这表明什么？
我认为存在：
变量之间的独立性：独立变量彼此之间没有很强的相关性，因此每个变量都解释了因变量中不同部分的变化。因此，每个变量的贡献在两种类型的模型中都以类似的方式表示，不受其他变量存在或不存在的影响。
共线性程度低：共线性程度低意味着变量在它们带给模型的信息方面没有太多重叠。这使得每个变量在模型中保持稳定的贡献，并且当包含或排除其他变量时，与每个变量相关的平滑函数不会发生显着变化。
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656821/understanding-the-implications-of-similar-smooth-functions-in-generalised-additi</guid>
      <pubDate>Wed, 06 Nov 2024 09:48:05 GMT</pubDate>
    </item>
    <item>
      <title>电子商务中的 AB 测试设计 - 按用户分组并按商品统计汇总</title>
      <link>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</link>
      <description><![CDATA[运行 A/B 测试（其中 A/B 组按用户划分，然后按项目汇总统计数据）在统计上是否正确/可行？
让我们将问题缩小到一个具体示例：

设置：一家在线商店，多家公司发布用户可以购买的商品。公司可以购买可提升网站上商品排名的插件。
目标：增加达到特定插件点击目标的商品比例（例如 5%）
测试：我们正在处理二项分布，因此选择了 Fisher 精确检验。尤其是没有那么多项目，因此测试不应该在计算上耗费精力

示例数据：
插件点击率目标：5%




计数达到目标的项目
计数未达到目标的项目




组 A
5216
1295


组 B
5558
953



Fisher 精确p 值小于 0.0001 -&gt; 结果在 alpha=0.05 时具有统计学意义。
我担心的是，这种方法（按用户分组，按项目聚合）违反了 AB 测试设计和理论的一些假设。我们运行了 500 次 AA Fisher 精确测试，alpha=0.05，在这 500 次模拟中，只有 0.012 次具有统计学意义。
我尝试在线查找采用这种方法的文章，但由于“AB 测试教程”泛滥，我无法找到相关来源（也许我的搜索技巧很差）。我问过 GenAI，模型似乎对这种方法没有问题，但是……它是 GenAI。
有人可以详细说明一下吗？有任何相关来源或链接吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</guid>
      <pubDate>Wed, 06 Nov 2024 08:32:55 GMT</pubDate>
    </item>
    <item>
      <title>估计一个向量 $\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}}$</title>
      <link>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</link>
      <description><![CDATA[在高维设置中，我们使用依赖于稀疏性假设的套索方法解​​决线性回归，
$$
\hat{\beta}=\underset{\beta\in \mathbb{R}^{p}}{\arg \min}\|Y-X\beta\|_2^2+\lambda\|\beta\|_1 。
$$
现在我对一个新模型感兴趣，其中$\beta$分解为一个稀疏向量和一个密集向量
$$
\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}},\\
Y=X\beta_1+X\beta_2+\epsilon,
$$
并获得估计量
$$
\left(\hat{\beta}_1,\hat{\beta}_2\right)=\underset{\beta_1,\beta_2}{\arg \min}\|Y-X\left(\beta_1+\beta_2\right)\|_2^2+\lambda_1\|\beta_1\|_a+\lambda_2\|\beta_2\|_b
$$
其中$\|\cdot\|_a$和$\|\cdot\|_b$鼓励估计量稀疏和密集。
我猜这个模型已经得到很好的研究了。现在这个模型的最佳结果是什么？你能给我提供一些相关的论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</guid>
      <pubDate>Wed, 06 Nov 2024 02:42:52 GMT</pubDate>
    </item>
    <item>
      <title>联合检验复合零假设</title>
      <link>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</link>
      <description><![CDATA[假设我们有一个 GLM，其 $g^{-1}(\mathbb{E}[y|x]) = \beta_0+x_A\beta_A+x_b\beta_B$。我想检验以下假设：$H_0:\beta_A \leq 0 \cup\beta_B\leq0$ $H_1:\beta_A&gt;0\cap \beta_B&gt;0$。有人能指点我如何构建一个检验方法，在这些情况下得出有效的 p 值吗？如果我没错的话，我正在检验两个复合零假设，但我不知道还能用这些信息做什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</guid>
      <pubDate>Tue, 05 Nov 2024 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分解论证</title>
      <link>https://stats.stackexchange.com/questions/656666/time-series-decomposition-justification</link>
      <description><![CDATA[问题的背景。
有一条沃尔德定理，称任何协方差平稳随机过程都可以写成无限阶移动平均模型和确定性分量的总和，它是随机的，但完全确定为其过去值的线性组合。
这是一个定理，因为它可以被证明，证明可以在 Brockwell 和 Davis 的书《时间序列：理论与方法》中找到。
然而，我注意到使用以下事实非常普遍：
时间序列$\{Y_t\}_{t \in T}$可以写成因为
$$Y(t) = Y_{\text{stationary}} + f_{\text{trend}}(t) + f_{\text{periodic}}(t) + \epsilon(t)\, ,$$

$Y_{\text{stationary}}$ 是一个弱平稳过程，其中
$\mathbb{E}[Y_{\text{stationary}}] = 0$;

$f_{\text{trend}}$ 是一个趋势分量，建模为确定性
低次多项式，即 $f_{\text {trend}}(t)\sim \sum _ k c_ kt^
k$;

$f_{\text {periodic}}(t)$ 是周期分量，建模为
确定性的有限谐波和，即 $f_{\text {periodic}}(t)
\sim \sum _ k a_ k \sin (\theta _ k t)+ b_ k \cos (\theta _ k t)$。

$\epsilon (t)$ 是白噪声，即 $\epsilon (t)$独立同分布于
所有$t$，期望值为$\mathbb E[\epsilon (t)]=0$，方差为
$\mathbb E[(\epsilon (t)^2]=\sigma (t)$，且独立于其他
成分。


有多种表达方式，虽然维基百科使用不同的形式，但我更喜欢坚持使用这种形式，因为它与我在笔记中遇到的形式相匹配。我将这种分解称为“时间序列”分解”。
问题。
时间序列分解能否被证明或至少被陈述为定理，并明确规定其限制？我很惊讶我找不到任何关于它证明的参考资料。
我也不明白它与沃尔德定理有什么关系，因为这里右边可能有非平稳部分$f_{\text{trend}}(t) + f_{\text{periodic}}(t)$，而我的调查显示，没有任何关于$Y(t)$平稳性的假设。起初，我认为这应该是沃尔德定理的推论，但现在在我看来，这个定理实际上是一个更普遍事实的具体情况。
我想即使这是一个经验法则，也应该有正式的数学推理。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656666/time-series-decomposition-justification</guid>
      <pubDate>Sun, 03 Nov 2024 11:50:07 GMT</pubDate>
    </item>
    <item>
      <title>结合加权均匀分布和正态分布变量的复杂概率分布建模</title>
      <link>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</link>
      <description><![CDATA[最近，我一直在尝试为视频游戏中的随机分布提出一个准确的概率模型。我试图建模的过程如下：

从加权战利品表中随机选择三个物品（有替换）
每个物品都被分配一个正态分布的大小
然后比较这三个物品的大小，并将其中最大的一个交给玩家

在这个过程中，我已经知道从战利品表中选中每个物品的概率，以及每个物品大小分布的平均值和标准差。我如何将这个基本概率与大小分布结合起来，找出考虑到大小分布后选中某个物品的真实概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</guid>
      <pubDate>Sat, 02 Nov 2024 14:33:55 GMT</pubDate>
    </item>
    <item>
      <title>多项式回归中数据中心化和标准化的正确方法</title>
      <link>https://stats.stackexchange.com/questions/656248/correct-way-of-centering-and-standardizing-data-in-polynomial-regression</link>
      <description><![CDATA[我想使用套索回归建立一个回归模型。我的理解是，我应该首先缩放和集中我的数据（例如，如此处所问：回归中需要集中和标准化数据）。
但是，我想在模型中包含测量数据的交互和二次项（因此，如果我的数据包含 A 和 B，我还想在我的模型中包含 A^2、A*B 和 B^2 作为预测因子。
我的问题是，是否先计算交互和二次项（因此先构建 X），然后独立标准化每一列，还是先标准化 A 和 B，然后从这些标准化值构建 X。
对于正态最小二乘回归，这没有什么区别，因为多项式回归模型在线性变换下不变，当且仅当多项式是“分层良好公式化”的。因此，使用任一方法的模型所做的预测都是相同的（就像它们对非标准化数据所做的预测一样）。但每个系数的值和符号可能不同（事实上，该值几乎肯定会不同），并且由于 Lasso 会规范系数的大小，因此它应该得出不同的结论。
我找不到关于哪种操作顺序更好的确切答案。一方面，在构建 X 之后进行第二次标准化将确保所有预测因子具有相同的比例并正确居中，这在直觉上是合理的。但另一方面，您会失去这些术语之间的数学联系，其中 (A^2)_scaled 不会是 A_scaled 的平方。首先缩放也是我在一些统计软件中看到的方法（尽管对于普通最小二乘回归来说，这并不重要），并且由于套索回归不一定是“层次良好地制定的”，所以我不确定它是否有效。
我很感激任何关于为什么这种方式更好/正确的建议或解释。最好有一些参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/656248/correct-way-of-centering-and-standardizing-data-in-polynomial-regression</guid>
      <pubDate>Thu, 24 Oct 2024 11:52:06 GMT</pubDate>
    </item>
    </channel>
</rss>