<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Mon, 17 Feb 2025 18:23:01 GMT</lastBuildDate>
    <item>
      <title>一个一个变量固定的3个变量的关节概率如何扩大？</title>
      <link>https://stats.stackexchange.com/questions/661501/how-does-one-expand-joint-probability-of-3-variables-with-one-variable-fixed</link>
      <description><![CDATA[我正在以条件性概率进行审议，然后遇到本讲义&lt; /a&gt;。但是，我被困在本节下面的突出显示部分，有条件独立。
    

您能否澄清为什么分子中只有一个 p（z = 1）？
或换句话说，如何获得 p（x，y，z = 1）？的扩展
此扩展中使用的属性名称？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661501/how-does-one-expand-joint-probability-of-3-variables-with-one-variable-fixed</guid>
      <pubDate>Mon, 17 Feb 2025 17:32:00 GMT</pubDate>
    </item>
    <item>
      <title>成为有效拉普拉斯变换的必要条件</title>
      <link>https://stats.stackexchange.com/questions/661500/necessary-conditions-for-being-a-valid-laplace-transform</link>
      <description><![CDATA[我需要证明expression  $ l {（f}）（s）$  =  $（（{{{{{ 1 -e^{ -  s}}）^{1/2}）/s $ 不满足成为概率密度函数的有效拉普拉斯变换的必要条件。具体来说，我怀疑该表达式与有效的PDF不符，但我不确定如何严格显示此表达式。任何指导或提示都将不胜感激！

我的gues  $ {l（f）（s）} $ 在半计划中不分析 $ rep＆rep＆gt ; S0 $ ，但是IDK如何证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/661500/necessary-conditions-for-being-a-valid-laplace-transform</guid>
      <pubDate>Mon, 17 Feb 2025 17:10:37 GMT</pubDate>
    </item>
    <item>
      <title>识别策略的建议</title>
      <link>https://stats.stackexchange.com/questions/661499/advice-on-identification-strategy</link>
      <description><![CDATA[我有一个请求，请求为我的研究选择计量经济学模型的识别策略/形式。它是什么：

我有一个看起来像下图的城市的数据。
城市中部有一家工厂产生空气污染
我知道，当风污染污染目前污染该城市的哪一部分
红点是我拥有GPS坐标的位置，并标记自杀事件的位置和日期
我想研究污染对城市自杀人数的影响。

我应该从计量经济学的角度处理这一问题？我正在考虑以下内容：

我正在考虑将城市分为某些地区，观察单位将是该地区每天的自杀人数。
但我没有有关城市人口的数据。  因此，我无法重新计算因变量为“每10万居民自杀”。
是否有任何统计方法可以帮助我？

理想情况下，我想估计“自杀”〜空气污染假人。非常感谢您的帮助
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661499/advice-on-identification-strategy</guid>
      <pubDate>Mon, 17 Feb 2025 16:24:01 GMT</pubDate>
    </item>
    <item>
      <title>将CNN模型与变压器进行分类</title>
      <link>https://stats.stackexchange.com/questions/661498/using-a-cnn-model-with-transformer-for-classification</link>
      <description><![CDATA[如果我想使用CNN+变压器进行操作识别，则用于提取空间信息的CNN和用于建模帧之间的时间依赖性的变压器，我需要同时使用Encoder和解码器，或者仅使用编码器（我需要）（我需要） ISIT最好明确添加位置编码?? ]]></description>
      <guid>https://stats.stackexchange.com/questions/661498/using-a-cnn-model-with-transformer-for-classification</guid>
      <pubDate>Mon, 17 Feb 2025 16:22:54 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个唯一项目正确拆分时间序列LSTM预测的列车/Val集？</title>
      <link>https://stats.stackexchange.com/questions/661496/how-to-properly-split-train-val-sets-for-time-series-lstm-prediction-with-multip</link>
      <description><![CDATA[我正在使用LSTM模型处理时间序列预测问题。我的数据集由27个不同的项目组成，每个项目都有独特的ID，每个项目的样本数量大致相同。大约有50个功能，我正在使用过去30天的数据来预测目标。
最初，我将数据集分为火车和测试集，以确保测试项目完全看不见（即火车和测试具有不重叠的唯一ID）。但是，我现在面临着决定如何将培训数据进一步将培训数据分为火车和验证集的困难。
这是我尝试过的两种方法：
 1.通过唯一ID（确保火车和瓦尔之间的非重叠ID）拆卸火车/阀：

火车RMSE明显高于验证RMSE。
与验证相比，火车数据具有更大的极值范围，导致目标分布非常不同。

 2.在每个唯一项目的时间序列中分解火车/瓦尔（即，将每个ID的数据顺序分配而不是跨ID分配）：

火车和验证RMSS较低，每个时期之后保持近距离。
模型性能看起来更稳定，但是我不确定这是否是一种有效的方法。

我的问题：

这样的时间序列问题将训练设置为Train/Val的正确方法是什么？
我应该始终将验证ID分开，还是在每个唯一ID中分配时间序列可以接受？
为什么在第一种情况下，训练RMSE要比验证RMSE高得多？这可能是由于火车和瓦尔之间的不同目标分布引起的吗？
我该如何减轻此问题？
对于第二种情况，我是否应该专注于调整我的模型（例如，添加更多层，增加的神经元等），还是有更好的方法来处理这种验证策略？
另外，也许我应该为展示类似目标分布的独特ID组训练单独的LSTM模型。
然后，我训练一个元模型，该元模型加权这些LSTM的预测以做出最终预测。

 未来目标 
最终，我想使用转移学习将此模型调整为另一个域的数据。这意味着我的验证策略不仅应帮助我当前的数据集，而且还应确保我的模型在将来适应新领域的概括。
任何见解或建议将不胜感激。预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661496/how-to-properly-split-train-val-sets-for-time-series-lstm-prediction-with-multip</guid>
      <pubDate>Mon, 17 Feb 2025 15:47:05 GMT</pubDate>
    </item>
    <item>
      <title>测试是否在重复测量中进行观察显示一致的顺序？</title>
      <link>https://stats.stackexchange.com/questions/661495/testing-if-observations-in-repeated-measurements-show-a-consistent-order</link>
      <description><![CDATA[我必须分析一个生物数据集。让我首先描述实验和数据：
我们有一块具有数百个井的塑料，将发生化学/生物反应。这件塑料称为板。我们将3个这样的板拿走，并在他们的井中分发总共720种不同的药物，每个板上有240种。每个井都包含一种药物。每种药物仅在1孔中存在。  我们称这3个包含全部药物的板的组合为药物库。这些库是由自动化机器人非常稳定地创建的。即使机器人非常精确，我们仍在微级尺度上工作，任何可变性都可以在此处引入错误。
对于实际实验，在库中的每个井中添加了细胞悬浮液。相同的悬架量相同训练有素的专业人员将其添加到每个井中。尽管如此，在这一点上的随机性可能是巨大的噪声来源，要么是由于添加的悬浮量的微小差异，要么是在给定井处添加的悬浮液中的单元格数（我们谈论的是，每个孔都约有25个单元，微小的变化将导致重大变化）。将细胞留在药物存在几个小时的情况下。实验的目的是查看这些细胞上这些药物的致命/非致命性。最后，在每个孔上添加了一个试剂，在该孔中会发生发光的化学反应。将每个板放在仪器上。该仪器测量每个井的光（发光）的强度，并报告值。每个良好和板的值是我正在使用的数据。发光越高，细胞还越多（药物无能为力）；较低，细胞存活越少（药物更致命）。这些值是整数范围从〜100到〜1m。
每次进行分析时，我们都有两个重复。整个过程已重复3次（不同的日子），为我们提供了每个孔的发光值的6个测量值。 （由于质量控制的原因，我们有4个额外的测量值，但我不确定我应该丢弃其中3个）。
这些是所有板上所有原始发光值的分布x重复：
    
我必须运行数据的QC。我最幼稚的问题是：尽管这可能引起的所有技术和生物学变异/噪声/噪声，我是否看到一些药物始终杀死很多/几乎没有细胞？
我对此的天真方法是将3个不同的板中的每个板中的每个板拿走，并且在每个复制中，按照其原始发光值对每个井/药物进行排名。然后，我计算了平均等级（所有6个重复的井的井，整数从1到240），以及井的最大和最小排名之间的距离（所有6个重复中的最高和最低）。
这就是外观，使用所有6个重复，然后在删除（从平均值和范围内）删除2个最极端的等级值：：
    
您可以看到，这似乎是一个非常嘈杂的数据。许多点具有截然不同的排名值，有时在一个重复中的排名有时很高，而对其他排名则非常低。。
我想知道是否有任何类型的统计测试可以用于评估/检测我在寻找的内容：是否将数据点/井的顺序/等级放置在跨重复的位置一致的位置，或者是否数据是如此嘈杂，错误来源太多，以至于一切都是混乱的，这里没有统计信息可应用。
另外，我是否可以使用任何测试来突出某些重复作为错误的源，但是一旦删除数据/订购就变得更加一致？还是我应该只计算所有6个重复的每个井的平均 + SD，然后从那里删除始终落在±1〜2 SD之外的重复，和/或井的井中，我们可以认为AS不可靠，测量“？”
您对如何以某种鲁棒性分析这些数据有什么建议？至少要比翻转硬币和rorschach检验散点图更健壮。
预先感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/661495/testing-if-observations-in-repeated-measurements-show-a-consistent-order</guid>
      <pubDate>Mon, 17 Feb 2025 15:28:02 GMT</pubDate>
    </item>
    <item>
      <title>促销对需求的效果</title>
      <link>https://stats.stackexchange.com/questions/661494/promotional-effect-on-demand</link>
      <description><![CDATA[我有几个产品类别的每周销售数据3年。我有兴趣分析价格促销的直接和滞后影响。价格促销一次限制为几周。
我计划在此时间序列上使用分布式滞后模型。我的问题是我的数据具有季节性模式，在圣诞节和夏季时期尤其有节日影响。
所以，我的问题是：

三年的总数据是否足以控制季节性模式以检查促销效果？我可以使用带有虚拟变量的分布式滞后模型来度假吗？
对其他方法有什么建议，可以使该分析在统计上尽可能稳定？

预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661494/promotional-effect-on-demand</guid>
      <pubDate>Mon, 17 Feb 2025 14:46:20 GMT</pubDate>
    </item>
    <item>
      <title>相互作用对因变量的影响？</title>
      <link>https://stats.stackexchange.com/questions/661493/interaction-effect-on-the-dependent-variable</link>
      <description><![CDATA[我想在R中使用两个二进制依赖变量运行一个模型。我知道如何在自变量上建模交互作用，但是也可以在因变量上执行此操作吗？
如果我的选择是（1）香蕉或梨，以及（2）绿色与黄色。有效地，人们可以在四种选择中选择：黄色香蕉，绿色香蕉，黄梨，绿梨。我想分析年龄（后来又有一些其他控制变量）如何影响四个选项中的哪种。我必须使用哪个正确的模型？
我建议使用具有四个选项的多项式logit模型。我的老师建议我应该使用选择模型。我想尝试使用选择模型，但是我需要使用哪一个？我想找出年龄是否影响两者，并且还知道一种选择是否有条件，例如老年人宁愿去香蕉，但水果的选择是有条件的。
非常感谢您的帮助！ ：D 
 P.S。我的数据看起来像这样：

香蕉：1、0、1、0 
黄色：1、1、0、0 
年龄：20、40、60、80 
]]></description>
      <guid>https://stats.stackexchange.com/questions/661493/interaction-effect-on-the-dependent-variable</guid>
      <pubDate>Mon, 17 Feb 2025 13:43:14 GMT</pubDate>
    </item>
    <item>
      <title>在配对数据上测试离散变量（R实现的测试）</title>
      <link>https://stats.stackexchange.com/questions/661491/testing-discrete-variable-on-paired-data-r-implemented-test</link>
      <description><![CDATA[我有配对的数据，代表了每个受试者治疗前后进行的血压测量。
后处理值取决于处理的类型（三种类型：TRT1，TRT2和TRT3）。
我想测试治疗类型是否对血压变化有重大影响（即delta =之后 - 之前）。。
我最初的本能是使用Kruskal-Wallis检验比较三个治疗组的三角洲。但是，我已经看到建议，建议Friedman测试可能更适合配对数据。

 Kruskal-Wallis测试适合此分析？
弗里德曼测试会是更好的选择吗？

如果这个问题已经在其他地方回答，请分享链接。
下面是一个可再现的示例，其中有模拟数据：
 库（dplyr）
set.seed（123）
＆lt;  -  rnorm（100、2、1）
type＆lt;  - 示例（c（“ trt1” trt2＆quot” trt3＆quort“ trt3＆quort”），100，替换= true）

d＆lt;  -  data.frame（id = paste0（obs_ obs_＆quot; 1：100），以前，type）％＆gt;％
  rowwise（）％＆gt;％
  突变（after = case_when（
    type ==＆quot&#39;trt1＆quot 〜 * 2之前，
    type ==&#39;trt2＆quot＆quot 〜rnorm（1，2，1），
    type ==＆quot&#39;trt3＆quot 〜之前-3，
    .default = na
  ）％＆gt;％
  突变（delta =之后 - 之前）

kruskal.test（delta〜type，data = d）
 
 在2025-02-17创建的使用 preprex v2.0.2     ]]></description>
      <guid>https://stats.stackexchange.com/questions/661491/testing-discrete-variable-on-paired-data-r-implemented-test</guid>
      <pubDate>Mon, 17 Feb 2025 13:09:26 GMT</pubDate>
    </item>
    <item>
      <title>足够的降低（反回归）与判别分析</title>
      <link>https://stats.stackexchange.com/questions/661481/sufficient-dimension-reduction-inverse-regression-vs-discriminant-analysis</link>
      <description><![CDATA[我最近指出了一类以“足够降低尺寸”的名称的较知名的降维技术。 （例如，在这里）。我正在努力理解这些技术的一些关键概念。
广泛地，这些方法在标记的数据上运行，其中有一些变量 $ x \ in \ Mathbb {r}^n $ 和一个响应变量 $ y \ in \ Mathbb {r} $ 。他们的目标是找到一组 $ x $ 的线性组合，由 $ u \ in \ mathbb {r}给出^{n \ times m} $ ，以便在投影 $ y $ 的所有信息&gt; $ z = u^t x $ 。也就是说，目标是找到 $ z $ ，以便 $ y $ 独立于 $ x $ 给定 $ z $ 。
该技术有许多变体。通常，他们似乎估计 $ x $ 在 $ y $ 上的时刻（也许与＆quot“反向回归”？），并以某种方式找到 $ x $ 的子空间，可捕获这些 $ $ y $ 依赖性更改。
我对称为，它似乎最大化 $ x $ 给定带有 $ y $ &lt;$ y $ &lt;的子空间/span&gt;  - 依赖的矩，另一个没有（另请参见在这里）。
我感到困惑的是，“缩小尺寸降低”的目标是如何的。与线性组合 $ z = u^t x $ 分开 $ y $ &lt; /span&gt;。
说我们将功能的数量 $ M $ 设置为某些理想的值（例如，也许太多的 $ x $ 取决于 $ y $ ），我们使用“降低尺寸降低”。要找到 $ m $ 功能。这些功能在某种程度上是最歧视的吗？还有其他技术，例如LDA，试图找到标有标记数据集的最判别功能（and  lda的版本也解释了特定于类的协方差）。是“足够降低尺寸”尺寸与这些其他方法的尺寸一样，在 $ z $ ？的空间中最大化可区分性
对此问题的一个相关观点是，“缩小维度降低”找到 $ x $ 最依赖于 $ y $ 的方向。这是否等于找到 $ x $ 最能区分 $ y $ ？？]]></description>
      <guid>https://stats.stackexchange.com/questions/661481/sufficient-dimension-reduction-inverse-regression-vs-discriminant-analysis</guid>
      <pubDate>Mon, 17 Feb 2025 04:09:51 GMT</pubDate>
    </item>
    <item>
      <title>如何确定MGCV的问题：gam（y〜s（x） + s（x，fac，bs =“ sz”））？</title>
      <link>https://stats.stackexchange.com/questions/661480/how-to-identify-problems-with-mgcvgamy-sx-sx-fac-bs-sz</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661480/how-to-identify-problems-with-mgcvgamy-sx-sx-fac-bs-sz</guid>
      <pubDate>Mon, 17 Feb 2025 03:26:41 GMT</pubDate>
    </item>
    <item>
      <title>精确地测量整个人口或多次测量人口的子集？</title>
      <link>https://stats.stackexchange.com/questions/661479/measure-the-whole-population-exactly-once-or-measure-a-subset-of-the-population</link>
      <description><![CDATA[
我的人口 $ n $ 个人。
每个人都有一个属性 $ x $ 。
对于同一个人， $ x $ 的值可能会从测量到测量。
作为一个具体的例子，我问个人：您可以屏住呼吸多长时间？ （我测量时间）。
我有兴趣找出人口的平均值 $ x $ 。

我有两个选择。

选项1：测量所有 $ n $ 精确一次，以找出 $ x $ 人口
选项2：测量一组随机的 $ m $ 个人（例如 $ m $ ＆lt ; &gt;

我想知道：总的来说，我们说，如果我们可以访问人群，那么就没有可变性的概念，因为我们有完整的信息。但是，在这种情况下，即使我们可以访问整个人群（即选项1），仍然可能存在可变性。
我如何从选项1的测量中提出一些不确定性？可以通过假设同一个体的测量值的差异根据正态分布而变化，以某些先前的参数为中心？来实现这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/661479/measure-the-whole-population-exactly-once-or-measure-a-subset-of-the-population</guid>
      <pubDate>Mon, 17 Feb 2025 02:34:00 GMT</pubDate>
    </item>
    <item>
      <title>具有固定和随机效应的TOBIT回归</title>
      <link>https://stats.stackexchange.com/questions/661460/tobit-regression-with-fixed-and-random-effect</link>
      <description><![CDATA[我是R编程语言的初学者。
我有一个面板数据集，其中包括LEK（男性）的男性数量，每个男性的战斗数量（战斗）和几个不同的Lek网站（Lek = Lek站点的索引数字1-20），大约150个观察结果。
目的是测试男性数量如何影响男性战斗数量。
来自不同LEK站点的1-10个观测值，大多数观察结果都有0次战斗，这意味着数据被驱动为零，并以零为零。一些Lek网站根本没有战斗的观察。  由于LEK站点之间的战斗数量可能存在差异，因此显示位点应作为随机效果包括在模型中。
我了解，Tobit回归是合适的，但是我无法使它起作用。我尝试过，例如AER和CENSREG套餐，但我可能还没有完全了解如何进行。对于AER，我尝试了此错误（尽管不应该有多重共线性）：
 模型＆lt;  -  tobit（战斗〜MALES +（1 | lek），data = fightsdata，左= 0）
摘要（模型）
 

 car :: linearhypothesis.default中的错误
模型中有混叠系数

什么是可行的解决方案和正确的脚本？
我找不到提出后续问题的方法，所以我在问题结束时将其添加到这里：
响应对我澄清了几件事，但是Glmer似乎没有运行，并且正在产生以下错误消息。问题可能是男性计算的战斗是十进制数字吗？添加Ziformula会导致不同的错误消息。

型号＆lt;  -  glmer（战斗〜log（男性） +（1 | lek） +偏移（log（log（males））），data = frightsdata，fightsdata，family =＆quot&#39;poisson;）&gt;

有50个或更多警告（使用警告（）查看前50个）

警告（）
警告消息：
1：在（函数（fr，x，retrms，family，nagq = 1l，详细= 0l，...：：：：
非全能X = 0.500000
2：在（函数（fr，x，retrms，family，nagq = 1l，冗长= 0l，...：：：：：
非全能X = 0.200000
3：在（函数（fr，x，retrms，family，nagq = 1l，详细= 0l，... ）

摘要（模型）
警告消息：
 1：在vcov.mermod（object，use.hessian = use.hessian）：
根据有限差异Hessian计算出的方差 - 互动矩阵是
不是正定的或包含Na值：降回从Rx 估计的VAR-COV
 2：在vcov.mermod中（对象，相关=相关，sigm = sig）：
根据有限差异Hessian计算出的方差 - 互动矩阵是
不是正定的或包含Na值：降回从Rx 估计的VAR-COV

型号＆lt;  -  glmer（战斗〜log（男性） +（1 | lek） +偏移（log（log（males））），data = fightsdata，fightsdata，family =＆quot; poisson＆quort; zi〜1）

 glmer中的错误（战斗〜log（男性） +（1 | lek） + offset（log（log（males））），：
“控制”不是列表；使用glmercontrol（）]]></description>
      <guid>https://stats.stackexchange.com/questions/661460/tobit-regression-with-fixed-and-random-effect</guid>
      <pubDate>Sun, 16 Feb 2025 15:32:59 GMT</pubDate>
    </item>
    <item>
      <title>使用普通方程或OL解决线性问题的条件编号</title>
      <link>https://stats.stackexchange.com/questions/661458/condition-number-for-solving-a-linear-problem-using-the-normal-equations-or-ols</link>
      <description><![CDATA[我检查了这篇文章 OLS的数字也。
但是，我的问题更加直接和概念，而且数值较少。阅读 $ K $ ）使我感到困惑。下面我扩展并解释上下文。
 上下文 
查找系数的向量 $ x $  in  $ a x = b $  &#39;t一个精确的解决方案（几乎总是在现实世界中。）一个人使用的最佳解决方案是通过最小化的平方误差而找到的，涉及查找 $ x $  =“ Math-Container”&gt; $ a^t a x = a^t b $ 是正常方程。

 我已经学会了条件号，从概念上讲，这是概念上的比率误差的最大拉伸与解决方案上的最大伸展

 这个数字实际上独立于要转换的实际向量，但仅取决于所涉及的矩阵。


当此比率（条件编号）很大时，解决 $ x $ 可能会失败的方法。
他们提到 $ k（a^ta $ ）对于这个目的至关重要，但是在我看来，人们应该专注于 $ k（（a^ta）^{ -  1}）$ 。但是，似乎在数值上似乎是相同的有same-condition-number-as-the-matrix“&gt;”和这篇文章。 
 次要评论 
 有趣的是，chatgpt继续疯狂地咆哮，证明那些 $ k $ 是不同的（除非是正确的，但是似乎很不对劲。）&lt;）&lt; /em&gt; 
 问题 

那些 $ k $ 相同？

无论如何，我认为我们对那个 $ k $ 都不感兴趣，但是在我在下面问的一个。

我们真的不是对 $ k（（（a^ta）^{ -  1}）a^t）$ 测量来自&lt;&lt;的错误SPAN类=“ Math-Container”&gt; $ b $ ？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661458/condition-number-for-solving-a-linear-problem-using-the-normal-equations-or-ols</guid>
      <pubDate>Sun, 16 Feb 2025 12:28:14 GMT</pubDate>
    </item>
    <item>
      <title>有条件模型</title>
      <link>https://stats.stackexchange.com/questions/661421/maximum-likelihood-cross-entropy-and-conditional-empirical-distributions-for-c</link>
      <description><![CDATA[我遇到了这篇文章：“ MSE是心脏的跨熵：解释了最大似然估计” 哪个指出：

“训练神经网络时，我们正在尝试找到概率分布的参数，该参数与培训集的分布尽可能接近。

假设真实的数据生成过程是IID，那么当模型正在学习数据的非条件分布时，这是有道理的。在这种情况下，我们可以将平均对数可能性写为模型概率相对于数据的经验概率的期望：
  $$
\ frac {1} {n} \ sum_ {i = 1}^{n} \ log p _ {\ theta}（x_i）（x_i）\ quad \ text {或等效地} \ quad} \ quad \ quad \ quad \ quad \ m athbb {e} } _ {\ text {data}}} [\ log p _ {\ theta}（x）]
$$  
对于条件模型，我们通常使用条件概率编写类似的表达式：
  $$
\ frac {1} {n} \ sum_ {i = 1}^{n} \ log p _ {\ theta}（y_i \ mid x_i）\ quad \ quad \ text {或等效} hat {p} _ {\ text {data}}}} [\ log p _ {\ theta}（y \ mid x）]
$$  
但是，我有几个问题：

  有条件独立性和跨渗透率等效性：&lt; /strong&gt; 
对于有条件的模型，我们通常只假设有条件的独立性（请参见此讨论）。这是否意味着条件情况下的对数可能性并不总是等同于跨肠道与经验数据分布，除非数据生成过程是IID？我的理解正确吗？

  日志可能性和有条件的经验分布：&lt; /strong&gt; 
通常，为什么根据条件模型的条件经验数据分布未计算对数的可能性？换句话说，为什么我们直接使用期望：
  $$
   \ Mathbb {
   $$  
而不是用有条件的经验分布 $ \ hat {p} _ {\ text {data}}（y \ mid x）$ ？ 


任何可以帮助澄清这些观点的见解或参考文献都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661421/maximum-likelihood-cross-entropy-and-conditional-empirical-distributions-for-c</guid>
      <pubDate>Sat, 15 Feb 2025 12:18:30 GMT</pubDate>
    </item>
    </channel>
</rss>