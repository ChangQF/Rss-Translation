<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 23 Jan 2025 03:18:40 GMT</lastBuildDate>
    <item>
      <title>Metropolis-Hastings 算法和接受概率</title>
      <link>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</link>
      <description><![CDATA[根据我从维基百科中了解到的内容，在 Metropolis-Hastings 算法中，我们希望构建转移概率密度，以满足详细的平衡：
$P(x^{\prime},x) \pi(x)=P(x|x^{\prime})\pi(x^{\prime}) $
在上面的等式中，$\pi$ 是我们想要从中抽样的概率密度分布，$P$ 是转移概率密度。
原因是在马尔可夫链随机游走中构造上述转移概率密度，我们最终达到稳定状态，然后访问每个状态的次数与我们感兴趣的分布成正比。
通过将转移概率密度分为两部分来证明算法的合理性：

选择候选状态$x^\prime$的提议概率密度$g(x^\prime|x)$。
接受$A(x^\prime, x)$的概率（我不确定是概率密度还是概率质量）。
因此$P(x^\prime |x)=g(x^\prime|x)A(x^\prime, x)$。
接受概率分配如下：
$A(x^\prime, x) = min(1, \frac{\pi(x^\prime)g(x|x^\prime)}{\pi(x)g(x^\prime|x)})$。

这是我的问题：
算法将 $A$ 与 0 到 1 之间的随机数进行比较，以决定是否转换到状态 $x^\prime$。
但是，转换概率密度为 $P$。
我不明白这样一个不使用 $P$ 进行跳跃的马尔可夫链如何能够具有与 $\pi$ 成比例的静止状态。
算法使用 $A$ 进行跳跃的方式就好像 $A$ 是转移概率密度一样。
换句话说，我期望我们计算 $P$，然后将其与 0 到 1 之间的随机数进行比较。
我认为我错了，因为 $P$ 有一个数字，可以通过将其与均匀随机数进行比较来进行马尔可夫链模拟。实际上，构建 $P$ 仍然无法明确我们可能跳转到哪个状态，因此将这个概率密度分解为选择候选状态然后计算接受度的步骤。选择候选状态并根据接受度概率决定是否跳转的过程与构建所有 $P$ 然后以某种方式进行跳转的过程相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</guid>
      <pubDate>Wed, 22 Jan 2025 23:45:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么混合效应模型（lme）与固定效应模型（fixest）相比很慢？</title>
      <link>https://stats.stackexchange.com/questions/660393/why-is-mixed-effects-model-lme-slow-compared-to-fixed-effects-model-fixest</link>
      <description><![CDATA[我对固定效应建模的计量经济学方法还不熟悉。我刚刚尝试了我的第一个模型，但对所实现的速度感到难以置信。
这是我们的中断时间序列模型的混合效应模型规范：
##混合效应模型
m &lt;- nlme::lme(
specific_language_of_interest ~ 
work_experience + #随时间变化的控制变量 
latest_twitter_follower_count + latest_twitter_total_tweets + ##随时间不变的控制变量
time + event + time:event, ## 中断时间序列变量，时间整数范围从 0 到 1800 天
random = ~ time|user_id, corAR1(form = ~time | user_id), weights = varExp(form = ~time), method = &#39;REML&#39;, ## 用于解决异方差和自相关的模型参数
data = df)

以下是固定效应规范中的可比模型：
pdat &lt;- panel(df, ~user_id + time)
fixest_m &lt;- feols(specific_language_of_interest ~
               work_experience + #control variable that are time-variant
                       time + event + time:event | user_id，## 中断时间序列变量和固定效应
data = pdat)

lme() 混合效应模型需要大约 8-10 小时才能收敛，而使用 fixest 的固定效应模型则需要不到一秒钟。
由于我是计量经济学领域的新手，我不确定我是否做错了什么。这两个模型确实不等价吗？如果它们是等价的，为什么 fixest 比 lme 快这么多？]]></description>
      <guid>https://stats.stackexchange.com/questions/660393/why-is-mixed-effects-model-lme-slow-compared-to-fixed-effects-model-fixest</guid>
      <pubDate>Wed, 22 Jan 2025 22:36:00 GMT</pubDate>
    </item>
    <item>
      <title>比较覆盖概率和间隔长度：BCa 与百分位数引导方法</title>
      <link>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</link>
      <description><![CDATA[我进行了一项参数引导研究，以评估四个参数的覆盖概率，样本量分别为 35、50 和 100。在研究中，我计算了百分位数 CI 和 BCa CI。结果表明，百分位数方法的覆盖概率往往更为保守，而 BCa 方法通常可实现更接近标称水平的覆盖概率（$1-\alpha$）。但是，百分位数方法的平均间隔长度通常较短。
我怀疑这种差异是由于研究中使用的样本量较小造成的。我查阅的一篇参考文献提到，BCa CI 可调整偏差和偏斜度，除小样本外通常准确。我也知道最短的 CI 并不总是最好的。从覆盖概率的角度来看，在这种情况下，BCa 似乎优于百分位数方法。但与直觉相反，较短的 CI 也提供了更高的覆盖概率。我该如何证明我认为 BCa 更好？
我查阅了经典书籍，例如 Efron, B., &amp; Tibshirani, R. J. (1994) An Introduction to the Bootstrap、Davison, A. C., &amp; Hinkley, D. V. (1997) Bootstrap Methods and Their Application，并搜索了一些论文以找到类似的现象或讨论。但是，我还没有找到解决这一特定观察的明确理由，尤其是较短的 CI 提供更高的覆盖概率。
是否有人有见解或参考资料可以提供对这种行为的更深入了解？在此先感谢您的想法和指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</guid>
      <pubDate>Wed, 22 Jan 2025 18:45:21 GMT</pubDate>
    </item>
    <item>
      <title>我可以针对不同的独立变量（特征）使用不同的核函数吗？我应该这样做吗？</title>
      <link>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</link>
      <description><![CDATA[我正在使用核回归来模拟多个独立变量和一个因变量之间的非线性关系。我了解核函数和带宽选择，但我想知道是否有可能或有益地对不同类型的独立变量使用不同的核函数。
例如：

特征 1：连续变量（例如，以平方米为单位的大小）。
特征 2：离散变量（例如，房间数量）。

使用以下方法是否有意义：

特征 1（连续）使用 高斯核？
特征 2（离散）使用 三角核？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</guid>
      <pubDate>Wed, 22 Jan 2025 18:35:03 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络开始时权重的更新是否较少？</title>
      <link>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</link>
      <description><![CDATA[也就是说，因为错误来自神经网络的末端（即在输出层）并且通过反向传播回流到神经网络的开始处，这是否意味着靠近末端的权重比开始处的权重变化更大。这是真的吗？如果是，我该如何证明？
更一般地说，相对于网络层，权重增量的分布是怎样的？
直觉上，我认为这对于梯度下降（左）是正确的，但对于符号梯度下降（右）不正确：

最后发现 nanogpt 使用符号梯度下降比 AdamW 训练得更快：https://github.com/nullonesix/sign_nanoGPT
我想知道我的直觉是否可以被证明是正确的（如果是的话）。在此先感谢大家对这个话题的任何其他直觉或资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</guid>
      <pubDate>Wed, 22 Jan 2025 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>子集选择成功与逻辑分布之间的联系</title>
      <link>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</link>
      <description><![CDATA[我是统计学新手，所以如果我遗漏了一些显而易见的东西，请不要起诉我。我最近在做一项作业，任务是分析以下带有子集选择的模型：
$$
y_i = \beta_1 x_{1, i} + \beta_2 x_{2,i} + \beta_3 x_{3,i} + \beta_4 x_{4,i} + u_i
$$
其中
$$(x_{k,i})_{k=1}^4 \sim \mathcal{N}(0, \Sigma)$$
$$
\Sigma = 
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; \gamma &amp; \gamma\\
0 &amp; \gamma &amp; 1 &amp; \gamma\\
0 &amp; \gamma &amp; \gamma &amp; 1
\end{pmatrix}
$$
其中 $\gamma \in [-1, 1]$。此外，我们有 $\beta_2 = \beta_3 = \beta_4 = 2$，并且 $\beta_1 &gt; 2$。最后，$u_i$ 是 i.i.d。正态分布，均值为零，方差为 2，$i = 1, \ldots, N$。
我们的任务是确定 $\gamma$ 和 $\beta_1$ 的阈值，对于这些阈值，子集选择（子集大小等于 $1$）正确识别出最重要的协变量，即 $\beta_1$。
在此过程中，我设法得出以下曲线，对于 $N = 500$，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线。 class=&quot;math-container&quot;&gt;$\gamma = 0$ 第二个。
$\gamma$&quot; /&gt;
$\beta$&quot; /&gt;
在我看来，这些看起来非常符合逻辑！因此，我运行了一个简单的逻辑曲线拟合，模型如下：
$$
f(x) = \frac{A}{1 + \exp(-k(x - x_0))}
$$
我管理了以下参数
最适合 gamma 的逻辑函数是： 
A = 1.0011916177515001, x0 = 0.46613345213429164, k = -25.287773424878644
99% 置信区间： 
[[ 0.99834479 1.00403845]
[ 0.46495465 0.46731225]
[-25.94535303 -24.63019382]]
最适合 beta 的逻辑函数是： 
A = 1.0008861957715565, x0 = 4.131595820642967, k = 6.469500267867452
99% 置信区间： 
[[0.99799143 1.00378096]
[4.12631938 4.13687226]
[6.27646573 6.66253481]]

使用以下图表（不提供信息，只是漂亮）：


我不完全理解如何测量非线性最小二乘的拟合优度，但这些是非常严格的置信区间，所以这最终引出了我的问题。
这种行为有一个很好的理论解释吗？看来，正确识别具有子集选择的协变量的概率是具有这些神奇参数的逻辑分布。事实确实如此吗？它是渐近逻辑的吗？这实际上只是一个正态分布（我在写这篇文章时意识到了这一点）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</guid>
      <pubDate>Wed, 22 Jan 2025 18:06:40 GMT</pubDate>
    </item>
    <item>
      <title>计算或估计稀疏编码模型（即 LASSO、基追踪等）中数据的边际似然</title>
      <link>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-data-in-sparse-coding-model-i-e</link>
      <description><![CDATA[我有一个模型，它将波形表示为字典中元素的稀疏线性组合。这是使用平方欧几里得误差和$\ell_1$正则化建模的，相当于具有拉普拉斯先验的高斯似然。这本质上是一个贝叶斯 LASSO，在这种情况下也称为“基础追踪”。
我想根据模型计算某些数据的可信度。具体来说，给定一个数据点$y$，我们的字典能多好地稀疏地表示$y$？ $y$ 的边际似然将提供一个清晰的理论答案，但对于大型字典来说，评估所需的积分似乎很难。
是否有任何简单的闭式表达式？
或者，是否有任何好的近似值或相关的标量可以可靠地估计边际似然？
或者，是否有其他方法可以量化“可信度”（例如，MLE 的似然）？
最后，如果其他稀疏线性模型简化了这个计算，我愿意接受建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-data-in-sparse-coding-model-i-e</guid>
      <pubDate>Wed, 22 Jan 2025 16:51:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Andorson-Darling 假设检验 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</link>
      <description><![CDATA[我有一个自定义 PDF 分布函数。我想测试自定义 PDF 分布函数是否适合数据，并将其与其他内置分布（如正态分布、威布尔分布、莱斯分布、中上分布和瑞利分布）进行比较。自定义 pdf 函数如下所示
function pdf_values = bivariate_pdf_r(r, phi, mr, mi, sr, si, cf)

% 定义正值的自定义 PDF 函数
f = @(r, phi) r&#39;.* (1 / (2 * pi * sr * si * sqrt(1 - cf^2))) .* ...
exp((-1 / (2 * (1 - cf^2))) * (((r .* cos(phi) - mr).^2 / sr^2) + ...
((r .* sin(phi) - mi).^2 / si^2) - 2 * cf * (r .* cos(phi) - mr) .* (r .* sin(phi) - mi) / (sr * si)));

% 在样本点处评估函数
pdf_values = f(r, phi);
end
]]></description>
      <guid>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</guid>
      <pubDate>Wed, 22 Jan 2025 16:35:51 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么估算器来估计不同名称的数量？</title>
      <link>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</link>
      <description><![CDATA[我有 $N$ 个信封，每个信封都包含一张写有姓名的便条。有些姓名出现在多张便条上。总共有 $X$ 个不同的姓名。
为了弄清 $X$ 是什么，我打开 $n$ 个信封，找到 $x$ 个不同的姓名。
我应该使用什么 $X$ 估计量？理想情况下，我希望得到 $X$ 的估计量，并带有置信区间。
编辑：我不知道姓名计数遵循什么分布。但我知道我打开的信封中重复了多少次。如果有帮助的话，可以假设单个名字的最大出现次数比$N$小得多（&lt;1%）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</guid>
      <pubDate>Wed, 22 Jan 2025 11:25:23 GMT</pubDate>
    </item>
    <item>
      <title>R 中使用二元变量的结构方程模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660356/structural-equation-modelling-with-binary-variables-in-r</link>
      <description><![CDATA[我的项目重点是使用电子病历数据探索疾病 A 的癌前合并症模式。在之前的项目中，我们根据诊断/实验室测试/药物信息确定了大约 30 种合并症。在这个项目中，我们旨在使用探索性因子分析（通过 psych 包）分析这些合并症如何聚类，并检查疾病 B 在疾病 A 发展中的中介作用（使用 lavaan 包）。我目前有以下主要问题：

数据显示 KMO 值较低（约为 0.2）。我们删除了共现率为零的变量对，这改善了 KMO，但导致一些变量丢失。我们是否应该继续使用低 KMO，因为我们更愿意保留这些变量？

对于包含所有二元变量的探索性因子分析，我可以使用四分相关（wls 估计量）吗？

A 和 B 是二元变量。对于中介分析，我可以使用对 A 和 B 进行排序的 lavaan 包（wls 估计器）吗？


非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660356/structural-equation-modelling-with-binary-variables-in-r</guid>
      <pubDate>Wed, 22 Jan 2025 05:10:03 GMT</pubDate>
    </item>
    <item>
      <title>是否可以拥有在集群内变化的 2 级变量？</title>
      <link>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-within-a-cluster</link>
      <description><![CDATA[我正在尝试创建一个包含 1 级和 2 级预测因子的 2 级回归模型。但是，我的一个预测因子是非自均值变量。
这个非自均值的解释：假设它与回答“是”的问题数量有关（总共 5 个问题，因此范围是 0-5），我们将其命名为“N_Yes”。对于集群 A，假设我们有 n 个参与者。我会将这 n 个人的 N_Yes 加起来，得到 S_Yes = sum(N_Yes)（对于整个集群来说，这是相同的）。然后，对于这个集群中的每个参与者，他们的非自均值 = (S_Yes - N_Yes)/(n-1)。因此，基本上，这会导致集群中所有人的平均值，不包括该参与者本人。
所以我的问题是，您能否将这个非自身平均值作为 2 级回归模型中的 2 级预测变量（如 R 中的 lme4 或类似模型）？到目前为止，我看到的所有内容都表明 2 级变量不应该在集群内变化。如果模型可以在 2 级使用此变量运行，它会正常运行，还是会成为您不想做的事情？您将如何处理这种情况？
使用这种奇怪方法的理由：我想调查一些问题的“同伴效应”，这涉及估计一个人周围环境的平均水平，不包括自己。这对于大型集群来说可能微不足道，但对于少于 15 个且有异常值的集群，它可能很有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-within-a-cluster</guid>
      <pubDate>Wed, 22 Jan 2025 04:42:19 GMT</pubDate>
    </item>
    <item>
      <title>给定时间序列数据集中，输出与输入相比时间偏移不规则</title>
      <link>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</link>
      <description><![CDATA[我有一些具有多个特征的时间序列数据。输出发生了偏移（我的意思是，输出值的时间与相应的输入发生了偏移，而且偏移不规律）。我对偏移量有一些了解，但并不准确。有没有办法使用长短期记忆 (LSTM) 神经网络来考虑这些不规则的偏移？或者在训练 LSTM 模型之前有什么预处理可以提供帮助？]]></description>
      <guid>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</guid>
      <pubDate>Tue, 21 Jan 2025 21:56:41 GMT</pubDate>
    </item>
    <item>
      <title>确保回归参数估计值始终为正</title>
      <link>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</link>
      <description><![CDATA[我有兴趣了解如何完成以下任务：

假设我有两个变量 $X_t$ 和 $Y_t$ 的月度数据。我有兴趣为 $Y_t$ 创建一个 ARIMAX 模型，该模型依赖于 $Y_t$ 和 $X_t$ 的旧版本。我可以像这样编写基本的 ARIMAX 模型：
$$ y_t = c + \phi_1y_{t-1} + \beta x_{t-1} + \epsilon_t $$
但是，我希望此模型具有以下属性：假设其他所有条件都相同，$X_{t-1}$ 的较大值必须产生 $Y_t$ 的较大值，而 $X_{t-1}$ 的较小值则不能产生。从数学上讲，我认为这可以理解为 $\beta$ 必须始终为正。我希望模型尊重这一事实。
$$ \frac{\partial y_t}{\partial x_{t-1}} = \beta &gt; 0 $$
$$ y_t = c + \phi_1y_{t-1} + \beta x_{t-1} + \epsilon_t $$
$$ \text{subject to: } \beta &gt; 0 $$
我想知道我们如何在模型中强制执行这一点。我天真地想到了两种方法：


基本约束：我不确定如何为这个 ARIMAX 模型写出基本可能性，但它应该是这样的：

$$ L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
如果我希望 $\beta$ 为正，我应该能够写出一个受约束的可能性并使用拉格朗日函数来解决这个问题：
$$ \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
$$ \beta \geq \epsilon $$
$$ \mathcal{L} = \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) + \lambda(\beta - \epsilon) $$

贝叶斯方法：我认为，如果我策略性地选择先验，我就可以确保 $\beta$ 始终为正。使用贝叶斯原理，我写了联合先验和后验：

$$ P(\theta) = P(\beta)P(c)P(\phi_1)P(\sigma^2) $$
$$ P(\theta|\textbf{y},\textbf{x}) = \frac{L(\theta|\textbf{y},\textbf{x})P(\theta)}{\int L(\theta|\textbf{y},\textbf{x})P(\theta)d\theta} $$
然后在$\beta$上，我可以放置一个先验，例如半正态（https://en.wikipedia.org/wiki/Half-normal_distribution) 以确保正性，但我不确定要使用哪些其他分布作为其他参数的先验。我认为 $\sigma^2$ 上的先验也需要是具有正支持的分布，因为方差不能为负。

我不确定这些方法是否可行且合乎逻辑。社区能否就此提供一些建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</guid>
      <pubDate>Tue, 21 Jan 2025 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>如何训练具有较小ECE（预期校准误差）的模型？</title>
      <link>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</link>
      <description><![CDATA[如果我们训练一个具有交叉熵损失的深度学习模型，我们期望该模型具有较低的交叉熵损失。有没有办法训练模型，使模型获得较小的预期校准误差，同时保持负对数似然较小？或者有没有好的后处理方法来降低 ECE，同时保持交叉熵损失较小？]]></description>
      <guid>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</guid>
      <pubDate>Mon, 20 Jan 2025 19:19:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生存回归问题：处理非删失数据和模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    </channel>
</rss>