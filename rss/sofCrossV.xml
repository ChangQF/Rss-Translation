<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 18:21:02 GMT</lastBuildDate>
    <item>
      <title>具有替代特定属性的 R 中的多项 Logit</title>
      <link>https://stats.stackexchange.com/questions/657367/multinomial-logit-in-r-with-alternative-specific-attributes</link>
      <description><![CDATA[我想问一个关于在 R 中使用 mlogit 的问题。
当使用多项选择或混合逻辑对离散选择进行建模时，有些情况下，使替代方案有吸引力的属性并不适用于竞争替代方案。
例如，比较传统汽车与电动汽车 (EV)，传统汽车中不存在 EV 组件的成本。或者在出行方式选择的背景下，当比较仅使用汽车与两种公共交通选项时，等待时间或舒适度适用于公共交通选项，但不适用于仅使用汽车。当属性因替代方案而异时，如何使用 mlogit？我在网上搜索过，最常见的建议是为不适用于替代方案的属性值分配 NA，但看起来 mlogit 不接受此选项。
我将不胜感激任何反馈。
问候，
鲍勃]]></description>
      <guid>https://stats.stackexchange.com/questions/657367/multinomial-logit-in-r-with-alternative-specific-attributes</guid>
      <pubDate>Sat, 16 Nov 2024 16:47:12 GMT</pubDate>
    </item>
    <item>
      <title>匹配和边际效应</title>
      <link>https://stats.stackexchange.com/questions/657366/matchthem-and-marginaleffect</link>
      <description><![CDATA[这是我的代码：
# 在每个估算数据集中执行匹配
m.out_model1 &lt;- matchthem(Treatment_type_tumor_near_gallbladder ~ age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage_binary, 
data = new_amcore_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

# 对匹配的数据执行逻辑回归
results &lt;- with(m.out_model1, svyglm(complications ~ Treatment_type_tumor_near_gallbladder + age + sex + bmi + ASA + 合并症 + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage_binary,
family = quasibinomial()), cluster = FALSE)

完成此步骤后，如何正确使用 marginaleffects::avg_comparisons() 函数？
我尝试了以下操作：
# 计算平均边际效应
comparisons &lt;- marginaleffects::avg_comparisons(results)
summary(comparisons, exponentiate = TRUE)

但是，我不确定这是否正确，因为输出不是我所期望的。我按照这里提供的教程操作：https://ngreifer.github.io/blog/treatment-effects-mi/，但我无法将其应用于我的情况。
我也尝试了这种方法，它给了我一个更易于理解的输出：
output &lt;- pool(results, dfcom = NULL)

summary(output, exponentiate = TRUE, conf.int = TRUE) %&gt;% 
mutate(across(where(is.numeric), round, digits = 3))

这两种方法可以比较吗？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657366/matchthem-and-marginaleffect</guid>
      <pubDate>Sat, 16 Nov 2024 15:48:18 GMT</pubDate>
    </item>
    <item>
      <title>建立对数正态模型的时间参数</title>
      <link>https://stats.stackexchange.com/questions/657364/building-time-parameters-for-lognormal-model</link>
      <description><![CDATA[我正在尝试弄清楚如何为我的对数正态模型构建时间参数。
该模型有 N 条对数正态曲线，每条曲线都有一个 t 和 t0 参数。虽然我理解如何构建此问题中未显示的其他参数，但我对这些参数的创建方式感到困惑。

下表显示了使用高斯随机分布生成参数 t 和 t0 值的平均值和标准差。在此上下文中，参数 t 表示运动的总持续时间，该运动被划分为 N 个段以适应 N 条对数正态曲线。每个对数正态都会将额外的时间持续时间添加到总时间中，表示为 ti ，并且起始时间称为 t0i 。每条曲线的持续时间 ti 使用高斯分布计算，起始时间 t 0i 标志着每条对数正态曲线效应的开始。

时间参数表



参数
平均值
标准差
下限




t（持续时间）
0.75
0.3
0.4


ti (附加)
0.3
0.05
0.1


t0i
t0i-1 + t/N
t/3N
0.1



我想弄清楚的是，如果我想使用 4 条对数正态曲线 (N = 4)，我的输出会是什么。初始 t 值会始终保持不变吗？
这是我目前的解释：



Stroke(N)
t
ti
t0i




1
0.75
0.3
0.1875


2
0.75
0.3
0.375


3
0.75
0.3
0.5625


4
0.75
0.3
0.75



但这没有意义，因为我不确定 ti 提供了什么。
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/657364/building-time-parameters-for-lognormal-model</guid>
      <pubDate>Sat, 16 Nov 2024 15:14:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 mlogit 正确构建嵌套 logit 的嵌套</title>
      <link>https://stats.stackexchange.com/questions/657363/how-to-properly-construct-nests-for-nested-logit-using-mlogit</link>
      <description><![CDATA[我很难根据 mlogit 所需的逻辑正确构建嵌套。我的结果变量有 4 个选项 A、B、C、D。但是，您首先在 A 或非 A 之间进行选择。然后，您在 B 和非 B 之间进行选择。最后，您在 C 或 D（或 C 和非 C）之间进行选择。
我首先尝试了一个更简单的嵌套，其中只有 A、B、C，您首先在 A 和非 A 之间进行选择，然后在 B 和 C 之间进行选择。这是我为此准备的嵌套：
nests &lt;- list(
OP1 = c(&quot;A&quot;),
OP2 = c(&quot;B&quot;,&quot;C&quot;)
)

但我收到一个错误，似乎表明嵌套中不能只有一个选项。我也尝试过：
nests &lt;- list(
OP1 = c(&quot;A&quot;,&quot;OP2&quot;),
OP2 = c(&quot;B&quot;,&quot;C&quot;)
)

但是这也不起作用，因为“OP2”不在我的实际选择之列。
我想请教一下这个比较简单的问题以及关于添加嵌套的更复杂的问题的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657363/how-to-properly-construct-nests-for-nested-logit-using-mlogit</guid>
      <pubDate>Sat, 16 Nov 2024 15:06:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们对线性函数使用回归？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657359/why-do-we-use-regression-for-linear-functions</link>
      <description><![CDATA[为什么我们要对线性函数使用回归，而线性函数的因变量的平均值永远不会随着独立变量的值的变化而变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/657359/why-do-we-use-regression-for-linear-functions</guid>
      <pubDate>Sat, 16 Nov 2024 13:39:57 GMT</pubDate>
    </item>
    <item>
      <title>X-帕累托分布</title>
      <link>https://stats.stackexchange.com/questions/657358/x-pareto-distribution</link>
      <description><![CDATA[我有一份作业，要求我证明威布尔帕累托分布属于指数族，然后是项$a(x)$的均值和方差。为此，我使用了Dobson，因为 $g(y;\tau)=exp\{a(x)b(\tau)+c(\tau)d(x)\}$并得到 $a(x)=log(x)-log (\lambda)$、$c(\tau) =-(\alpha log (\frac{x}{\lambda}))$、$b(\tau) = (c-1)log (\alpha)$ 和 $d(x)= -log (x)$。请检查这些是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/657358/x-pareto-distribution</guid>
      <pubDate>Sat, 16 Nov 2024 13:19:44 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>REML 与 ML 的比较</title>
      <link>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</link>
      <description><![CDATA[我有两个问题，非常感谢您的回答。
如果最大似然 (ML) 和限制最大似然 (REML) 方法在模型中具有相同的固定效应，那么这两种方法的结果是否具有可比性？
当 ML 和 REML 以相同的固定效应应用时，它们是否会产生相同的固定效应估计方差？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</guid>
      <pubDate>Fri, 15 Nov 2024 17:44:11 GMT</pubDate>
    </item>
    <item>
      <title>泛化误差与模型复杂度呈 U 形曲线（偏差方差权衡）</title>
      <link>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</link>
      <description><![CDATA[是否有任何数学著作严格证明某些学习问题的泛化误差随模型复杂度（偏差方差权衡）呈现 U 形曲线？有任何参考资料吗]]></description>
      <guid>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</guid>
      <pubDate>Fri, 15 Nov 2024 15:41:58 GMT</pubDate>
    </item>
    <item>
      <title>在几乎为零的数据中寻找异常值</title>
      <link>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</link>
      <description><![CDATA[背景
我正在研究一种算法，用于在长 DNA 序列中查找短的 DNA 序列片段。我不会详细介绍它的实际工作原理，但让我更正式地说明它以提供足够的背景信息。每个 DNA 序列只是字母表 ATGC 中的一个字符串。给定参考 r，我们沿着参考 r 移动窗口 w。例如，如果参考 r 是 ATGCA 且 w=3，我们将生成窗口 ATG、TGC、GCA。然后将每个窗口与每个查询进行比较以生成计数 c，该计数类似于它们的匹配程度。从而基本上生成一个矩阵，其中列是 r 中的窗口起始位置，行是每个查询的每个窗口的计数。根据实验数据，我们预计在参考的左侧和右侧会看到计数峰值。但是，这并不能保证，左侧、右侧或两个峰值可能都不存在，并且每侧（甚至中间）可能有多个峰值。
图
颜色代表不同的查询，但省略了图例，因为它占用了太多空间
示例 1。大多数窗口实际上与查询不匹配，因此零占主导地位（参见底部面板，不确定为什么绘图库将条形图放在 0 旁边，但第一个条形图是零）。但是，左右两侧的两个蓝绿色峰值明显突出，计数超过 20。

示例 2
与示例 1 类似，但是左侧峰值不太明显。从视觉上看，我认为蓝色仍然高于“平均”水平它不像橙色那么明显。

示例 3
这是一个单侧有多个峰值的示例：

问题
我的第一直觉是使用 z 分数、百分位数或 IQR 之类的东西来选择这些高值。但是由于零占主导地位，计数 3 或 5 实际上也被视为“异常值”，但这不是我感兴趣的。我真的很想知道如何“自动”检测出如此高的异常值。主要目的只是尽量减少用户输入，因为设置最小计数并不直观。此外，当我设置最小 z 分数时，例如，一个峰值会通过，但另一个不会，等等。虽然从视觉上看它们似乎很明显，但我找不到一种方法来巧妙地检测它们。
好奇地想看看回复！]]></description>
      <guid>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</guid>
      <pubDate>Fri, 15 Nov 2024 12:03:04 GMT</pubDate>
    </item>
    <item>
      <title>R 中的嵌套方差分析产生警告消息“Error（）模型是奇异的”</title>
      <link>https://stats.stackexchange.com/questions/656958/nested-anova-in-r-produces-warning-message-error-model-is-singular</link>
      <description><![CDATA[我正在尝试理解嵌套方差分析，特别是使用 R 中的 aov() 函数，但我遇到了一些概念问题，我相信这也是因为互联网上的术语不一致。
作为数据集，我修改了来自此处的“dragons”数据集。除其他外，现在它包含一个数字响应变量（“testScore”）、一个（嵌套）“较低级别”因子变量（“Observer”，8 个级别）和固定的“较高级别”因子变量“Species”（4 个级别）。设计相当平衡，每个“Species”级别包含两个“Observer”级别：
&gt;表（龙$Species,dragons$观察者）

Erika Hannah Judith Julia Marie Paul Tarek Till
Deathmist 0 0 0 0 0 0 55 63
Fire 0 69 0 56 0 0 0 0
Green 0 0 0 0 54 53 0 0
Thorntail 64 0 66 0 0 0 0 0

目的是测试预测变量“物种”的不同级别是否在响应变量“testScore”中有所不同，同时校正了嵌套因子“观察者”。
我的理解是，嵌套因子始终是一种随机效应（具体而言：较低“随机”因子中给定级别的样本始终只出现在固定“较高”因子的一个级别中，但固定因子级别有来自多个随机因子级别的样本）。但是，包括“嵌套因子”的方差分析有时在互联网上表示为 Y ~ A/B（具有固定因子 A 的主要影响及其与随机因子 B 的相互作用），术语为“因子 B 嵌套在固定因子 A 中”...
&gt; summary(aov(testScore~Species/Observer, data=dragons))
Df Sum Sq Mean Sq F value Pr(&gt;F) 
Species 3 12913 4304 13.30 2.38e-08 ***
Species:Observer 4 87969 21992 67.98 &lt; 2e-16 ***
Residuals 472 152704 324 

(这个结果似乎不对，因为物种在 testScore 中可能不会有差异)
...虽然有时它表示为 Y ~ A + Error(B/A)，术语切换为“固定因子 A 嵌套在随机因子 B 中” （再次参阅此处和此处的回复）...
&gt; summary(aov(testScore~Species+Error(Observer/Species), data=dragons))

错误：观察者
Df Sum Sq Mean Sq F 值 Pr(&gt;F)
物种 3 12913 4304 0.196 0.894
残差 4 87969 21992 

错误：在内
Df Sum Sq Mean Sq F 值 Pr(&gt;F)
残差 472 152704 323.5 
警告消息：
在 aov(testScore ~ Species + Error(Observer/Species), data = dragons) 中：
Error() 模型是奇异的

后一个示例提供了我预期的测试结果，其中物种没有差异。但是，警告消息引起了我对给定数据集的模型有效性的担忧。此外，假设后一种方法是正确的，那么何时使用“Y ~ A/B”？
如果有人能帮助我解决我的困惑，并可能建议我警告消息可能暗示什么，我如何针对此数据集更正我的模型，或者数据必须是什么样子才能适用于此模型，我将不胜感激。谢谢！
*** 编辑：这是我的谷歌驱动器上的数据 ***]]></description>
      <guid>https://stats.stackexchange.com/questions/656958/nested-anova-in-r-produces-warning-message-error-model-is-singular</guid>
      <pubDate>Fri, 08 Nov 2024 10:44:32 GMT</pubDate>
    </item>
    <item>
      <title>何时回归模型优于简单方法？</title>
      <link>https://stats.stackexchange.com/questions/656897/when-regression-models-outperforms-the-naive-methods</link>
      <description><![CDATA[我遵循了此问题

案例 1：
我有以下任务要做：通过连续 3 天的训练来预测每个第 4 天。每天的数据代表一个尺寸为 24x25 的 CSV 文件。每个 CSV 文件的每个数据点都是像素。
现在，我需要这样做，使用训练数据第 1 天、第 2 天、第 3 天（即连续三天）预测第 4 天（即第 4 天），然后计算预测的第 4 天数据和原始第 4 天数据之间的 mse。我们称之为 mse1。
同样，我需要使用训练数据 day2、day3、day4 预测 day5（即第 5 天），然后计算 mse2（预测的第 5 天数据与原始的第 5 天数据之间的 mse）
我需要使用训练数据 day3、day4、day5 预测 day6（即第 6 天），然后计算 mse3（预测的第 6 天数据与原始的第 6 天数据之间的 mse）
..........
最后，我想使用训练数据 day90、day91、day92 预测 day93，计算 mse90（预测的第 93 天数据与原始的第 93 天数据之间的 mse）
我想使用 Ridge 回归，线性回归和 LSTM 模型。每个模型都有 90 mse。
案例 2：
这里我使用的是被称为“朴素预测”或“随机游走”预测的方法。它通常很难被打败。
朴素方法是：
任何一天的猜测都只是前一天的地图。我的意思是简单地猜测第 2 天与第 1 天相同，猜测第 3 天与第 2 天相同，猜测第 4 天与第 3 天相同，......，猜测第 91 天与第 90 天相同。我的意思是使用当天的数据 (predicted_data = current_day_data) 预测第二天的数据。然后计算 next_day_data 和 current_day_data 之间的 mse。
结果：

在案例 1 中，我观察到，在数据较少的情况下，非常简单的方法 (回归模型) 的表现优于复杂方法 (lstm) 的情况极为常见。 这令人满意，正如预期的那样。简单的方法在数据较少的情况下尤其具有竞争力。&quot;有竞争力&quot;很简单，就意味着“更低的预测误差”。

在案例 2 中，我们知道朴素方法通常很难被击败，这意味着更低的 MSE，但在案例 1 中，简单回归方法的表现优于朴素方法。



我的问题：

在哪种情况下，一个简单的回归模型（在案例 1 中）会胜过一个简单的方法（在案例 2 中）？我的意思是，如何具体知道为什么一种简单方法在我的特定数据集上优于另一种简单方法？

如何挖掘我的数据集以了解一种简单方法优于另一种简单方法？


我的数据样本例如第 1 天、第 2 天、第 3 天，第 4 天。]]></description>
      <guid>https://stats.stackexchange.com/questions/656897/when-regression-models-outperforms-the-naive-methods</guid>
      <pubDate>Thu, 07 Nov 2024 14:09:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型是否有类似间隔重复学习的东西？</title>
      <link>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</link>
      <description><![CDATA[我想知道是否存在类似间隔重复的方法，但这种方法可以帮助机器学习模型学习。
间隔重复是一种人类学习抽认卡的方法，算法会尝试在学习者可能忘记之前展示抽认卡。
例如，如果抽认卡正确，你会在一天内再次看到它。如果再次正确，你会在两天后看到它，然后是四天，依此类推。如果你做错了，你的记忆时间就会降到零天，你必须重新做一遍。它基于赫尔曼·艾宾浩斯对遗忘曲线的发现。从 1880 年到 1885 年，他通过记忆一种假语言的单词对自己进行了实验（因为没有其他人愿意这样做）。这使他无法将已知单词与他试图记忆的单词联系起来，因此他可以获得更好的原始记忆数据。如今，确定等待时间的算法稍微复杂一些，但基本思想仍然适用。（如果您有兴趣尝试，请谷歌搜索“anki”）

将这个想法应用于机器学习会产生任何好处吗？或者已经存在类似的东西？基本上是相同的想法，但使用时期而不是天来管理何时应该进行审查。我知道灾难性遗忘是一种现象，但如果以类似于间隔重复的方式进行训练，也许有一些架构会保留在记忆中。这个想法让我想到了批处理，有时如果你不同时关注所有示例的梯度，你就可以摆脱局部最小值。
还有一些细节：你如何判断模型是否“正确”？例如，假设你正在训练一个分类模型，当它对正确类别有 90% 的确定性时，它是否正确？也许你可以随着每张卡片的训练而将正确所需的百分比降低到更高的水平，以将其引入 99.99% 的领域？也许有一种更好的通用方法可以根据该卡片的确定性历史来确定何时进行审查？使用这种方法是否存在偏见的危险？ （即：它会对有困难的练习进行更艰苦的训练，因此，它会在这方面做得更好，但在它认为容易的练习上却变得更糟，并且来回反复？）在开启间隔重复之前，你是否必须进行一段时间的定期训练才能使其发挥作用？
谢谢阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</guid>
      <pubDate>Tue, 22 Aug 2023 13:24:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不使用敏感度和特异性的调和平均值？</title>
      <link>https://stats.stackexchange.com/questions/610364/why-dont-we-use-the-harmonic-mean-of-sensitivity-and-specificity</link>
      <description><![CDATA[F-1 分数上有这个问题，询问为什么我们计算精确度和召回率的调和平均值而不是算术平均值。答案中有很多支持调和平均值的论据，特别是它适合取比率的平均值，并且当其中一个比率为零时，它就会降至零。
这引出了一个问题，为什么敏感性和特异性的调和平均值不是一个东西（据我所知）？存在两个比率，并且可以应用相同的论据。]]></description>
      <guid>https://stats.stackexchange.com/questions/610364/why-dont-we-use-the-harmonic-mean-of-sensitivity-and-specificity</guid>
      <pubDate>Wed, 22 Mar 2023 21:28:27 GMT</pubDate>
    </item>
    <item>
      <title>如果我只能计算 $g(X)$ 的平均值，那么 LOTUS 的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</link>
      <description><![CDATA[无意识统计学家定律 (LOTUS) 是一条定理，用于计算随机变量 $X$ 的函数 $g(X)=Y$ 的期望值，当人们知道 $X$ 的概率分布，但不知道 $g(X)$ 的分布时。
如果 LOTUS 的目的是找到期望值 $E[g(X)]$，那么该定理建议使用 $X$ 的概率密度和 $g(X)$ 的值：
$$E[g(X)]=\sum_x\,g(x)f_X(x),\;\text{(discrete)}$$
或
$$E[g(X)]=\int_{-\infty}^{\infty}\,g(x)f_X(x)\,dx,\;\text{(continuous).}$$
但是，这是我的问题：如果我们知道并且可以访问所有实现$y=g(x)$，那么为什么我们不计算$g$的平均值呢？为什么我要涉及$X$的 PDF/PMF？]]></description>
      <guid>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</guid>
      <pubDate>Thu, 19 Jan 2023 13:00:49 GMT</pubDate>
    </item>
    </channel>
</rss>