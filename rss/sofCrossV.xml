<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 11 Jan 2025 21:14:24 GMT</lastBuildDate>
    <item>
      <title>对已进行 FDR 校正的数据批次进行 FDR 校正</title>
      <link>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</link>
      <description><![CDATA[背景：
这个问题来自组学背景，其中大量数据有时需要将整个数据集分成几批，并用一些分析软件分别处理它们。
示例：
对于此示例，请考虑两个大小相等的测量数据批次。在每个批次中，可以用各种置信度分数识别 50000 个分子。在 1% 阈值下应用错误发现校正后，每个数据集中仍保留 1000 个具有显著 q 值的分子。任务是重新组合两个批次并获得一个仍具有 1% FDR 的数据集。
问题：
我的问题是，BH 校正（或任何其他类型的调整）是否可用于重新校正批次 q 值并允许组合批次而不会夸大错误发现？任何有关现有实现和/或统计背景的评论都将不胜感激。
示例方法：
我能想到一种方法，其中从每个批次中取出 50000 个 q 值并对整个 100000 个值集运行 BH 校正，同时取 q 值 &lt; 0.01。这基本上相当于解释批次 q 值，就像解释单个数据集中的原始 p 值一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</guid>
      <pubDate>Sat, 11 Jan 2025 20:52:03 GMT</pubDate>
    </item>
    <item>
      <title>Grover 算法是否比同时进行的贝叶斯更新更具优势？</title>
      <link>https://stats.stackexchange.com/questions/659892/does-grover-s-algorithm-offer-advantages-over-simultaneous-bayesian-updates</link>
      <description><![CDATA[最近我一直在学习 Grover 算法，该算法用于量子计算中的非结构化搜索。该算法的思路是这样的：您有一个大型未排序列表，并且想要找到某个东西（称为目标）的位置。您假设目标在列表中，但您不知道它在列表中的位置，并且想要找到这个位置。在开始搜索之前，您为列表中的每个项目分配相同的概率（从技术上讲，您为每个项目分配一个幅度，但平方幅度对应于概率）。例如，如果列表中有 100 个项目，则每个项目的（先验）概率为 1%。您可以通过使用这些概率初始化一个 100 个元素的向量来实现这一点。然后，您执行一系列计算来更新此概率向量，并多次执行这些计算（大约是列表大小的平方根，在本例中为 10，即 100 的平方根），直到（希望）表示目标的向量元素的概率很大（理想情况下为 1）。然后，您使用概率作为权重对向量索引进行采样（量子计算和物理学家称之为“测量”），希望您获得的采样向量索引对应于包含目标的向量元素。
Grover 算法（在某些条件下）比传统计算替代方案的速度快了二次。其中一个原因是 sqrt{100}=10 向量更新中的每一个实际上都会同时更新所有 100 个向量元素，这有时被称为量子并行性。
然而，我认为这种方法的精神与贝叶斯更新非常相似甚至相同。我到底错过了什么？例如，我曾经研究过一种贝叶斯聚类算法，我们逐一更新每个观测与其他 $N - 1$ 个观测聚类的概率，并将结果存储在一个向量中。显然，我应该考虑将该更新计算重新表述为单个操作，然后我可以同时更新所有概率。除了这种并行性（这似乎并不是 Grover 算法或量子计算所独有的）之外，Grover 算法是否还有一些额外的东西可以使其比某些可以同时更新所有向量元素的贝叶斯计算更具优势？
顺便说一句，这个论点可以扩展到任何阶的张量，而不仅仅是向量，尽管合理的更新计算可能很难得出。]]></description>
      <guid>https://stats.stackexchange.com/questions/659892/does-grover-s-algorithm-offer-advantages-over-simultaneous-bayesian-updates</guid>
      <pubDate>Sat, 11 Jan 2025 20:42:17 GMT</pubDate>
    </item>
    <item>
      <title>跨维度网格上的后验</title>
      <link>https://stats.stackexchange.com/questions/659890/posterior-on-a-grid-across-dimensions</link>
      <description><![CDATA[我已经注意到，虽然每维 100 个点可以很好地近似一维后验，但当你进入高维（3 维或 4 维）时，我通常必须增加每维的点数才能获得良好的近似值。这一定是由于“高维欧几里得空间的广阔性”，正如维基百科的距离函数部分所指出的那样。
有没有估计一下，每维应该使用多少个点才能正确覆盖 N 维的整个空间？]]></description>
      <guid>https://stats.stackexchange.com/questions/659890/posterior-on-a-grid-across-dimensions</guid>
      <pubDate>Sat, 11 Jan 2025 18:39:46 GMT</pubDate>
    </item>
    <item>
      <title>并行化蒙特卡罗模拟最简单的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</link>
      <description><![CDATA[据我所知，并行化蒙特卡罗模拟归结为将问题分解为子问题，并行运行它们以产生多个马尔可夫链，最后将马尔可夫链连接在一起。
现在的问题是，没有直接的方法来连接马尔可夫链。
并行化蒙特卡罗模拟最简单的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</guid>
      <pubDate>Sat, 11 Jan 2025 18:02:09 GMT</pubDate>
    </item>
    <item>
      <title>固定效应面板回归中的特征选择和异常值检测</title>
      <link>https://stats.stackexchange.com/questions/659888/feature-selection-and-outlier-detection-in-panel-regression-with-fixed-effects</link>
      <description><![CDATA[我试图拟合以下具有固定实体效应的面板回归
$$Y_{it} = \alpha_i + \sum_j \beta_jX^{(j)}_{it} + \epsilon_{it},$$
其中索引$j$标记了不同的特征。我知道其中一些特征对所有实体都很重要（领域知识），而有些可能只对某些实体很重要。此外，某些特征 $X^{(j)}_{it}$ 可能包含某些实体的错误数据（或极端异常值）。
我正在寻找此模型的诊断方法，以便能够检测：

某些特征仅与面板中的一小部分实体相关，并识别该子集；
某些特征包含异常值或高杠杆点，并识别它们。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659888/feature-selection-and-outlier-detection-in-panel-regression-with-fixed-effects</guid>
      <pubDate>Sat, 11 Jan 2025 17:54:42 GMT</pubDate>
    </item>
    <item>
      <title>非参数检验显著但回归不显著</title>
      <link>https://stats.stackexchange.com/questions/659886/non-parametric-test-significant-but-regression-not-significant</link>
      <description><![CDATA[我正在研究测试分数与某些指标的线性回归，并注意到在某些情况下测试分数存在上限效应，因此回归似乎不合适。我附上了一个示例图，尽管回归是显著的，但从图中可以明显看出它没有意义。
有人告诉我，我可以另外计算 Spearman 等级相关系数，并且只接受 Spearman 检验显著的显著回归结果，因为它比回归更保守，并且丢弃 Spearman 检验不显著的显著回归结果。但是，如果相反的情况是回归不显著但 Spearman 检验显著，该怎么办？我该如何报告这个结果？
提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/659886/non-parametric-test-significant-but-regression-not-significant</guid>
      <pubDate>Sat, 11 Jan 2025 16:36:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯与频率派 A/B 测试</title>
      <link>https://stats.stackexchange.com/questions/659882/bayesian-vs-frequentist-a-b-testing</link>
      <description><![CDATA[我是一名统计学消费者，正在阅读一篇软文，我发现它很直接，信息量很大，所以我希望它也是正确的。它讲述了一些关于贝叶斯统计学和频率统计学在实际使用中所谓差异的常见误解，比如在线 A/B 测试实验的偷看和提前结束。我同意其中的大部分内容，但有一点我很好奇。文章说

在两个变体（对照和治疗）的情况下，当用户数量足够大时，单尾 p 值几乎与对照优于治疗的贝叶斯概率相同，记为 P(A&gt;B| 数据) =1-P(B&gt;A| 数据)。在 A/B 测试中，较低的单尾 p 值和较低的 P(A&gt;B| 数据)（相当于较高的 P(B&gt;A| 数据)）表明处理组优于对照组。这两个指标几乎相同，这意味着从技术上讲，基于 P(B&gt;A | 数据) 的提前停止相当于基于 p 值未能维持 I 类错误率（假阳性率）的提前停止。

在“偷看”和提前结束实验的情况下，提前停止是否恰恰不是“当用户数量足够大时”的“单尾 p 值几乎与贝叶斯概率相同”的情况？这对他的论点重要吗？
我正在努力思考这个问题。似乎可以，“提前停止”有点意味着“对于我们所针对的置信度而言，样本不足”，但这对他的论点并不重要。贝叶斯估计器和频率估计器的小样本行为在这里有显著的不同吗？这甚至是一个相关的问题吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659882/bayesian-vs-frequentist-a-b-testing</guid>
      <pubDate>Sat, 11 Jan 2025 15:19:42 GMT</pubDate>
    </item>
    <item>
      <title>在建模孕产妇死亡率时，ARCH 和 GARCH 与 Logistic 回归模型之间是否存在关系？</title>
      <link>https://stats.stackexchange.com/questions/659880/is-there-relationship-between-arch-and-garch-to-logistic-regression-model-in-mod</link>
      <description><![CDATA[让您的 ARCH 模型和 GARCH 模型与 Logistic 回归模型相关联
将产妇死亡作为响应变量，并具有各种协变量，例如死亡发生的环境、门诊服务、不可预测的天气模式加剧了不确定的洪水和高温等变量]]></description>
      <guid>https://stats.stackexchange.com/questions/659880/is-there-relationship-between-arch-and-garch-to-logistic-regression-model-in-mod</guid>
      <pubDate>Sat, 11 Jan 2025 13:18:05 GMT</pubDate>
    </item>
    <item>
      <title>联合高斯的充分条件</title>
      <link>https://stats.stackexchange.com/questions/659878/sufficient-condition-for-jointly-gaussian</link>
      <description><![CDATA[设 $Z = f(X) + V$，其中 $X$ 和 $V$ 为独立的高斯随机变量，且 $f:\mathbb{R}\to \mathbb{R}$。
联合 $(Z,X)$ 为高斯的必要充分条件是什么？我怀疑 $f$ 应该是仿射线性的，比如 $ax + b$，但我该如何正式证明这一点呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/659878/sufficient-condition-for-jointly-gaussian</guid>
      <pubDate>Sat, 11 Jan 2025 12:55:03 GMT</pubDate>
    </item>
    <item>
      <title>M 估计量的一致性条件</title>
      <link>https://stats.stackexchange.com/questions/659869/conditions-of-m-estimator-to-be-consistent</link>
      <description><![CDATA[我从渐近统计学（Van der Vaart，1998）定理 5.7 中读到，要让 M 估计量 $\hat{\theta}_n$ 有概率收敛到 $\theta_0$，需要满足两个条件，其中一个条件是对于每个 $\epsilon&gt;0$，
$$\sup_{\theta:d(\theta,\theta_0)\geq\epsilon}M(\theta)&lt;M(\theta_0).$$
这个不等式看起来很复杂，涉及到度量 $d$，这让我很困惑。为什么我们不能删除度量，将其表示为
$$\forall\theta\neq\theta_0,M(\theta)&lt;M(\theta_0)$$
这两者不是等价的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659869/conditions-of-m-estimator-to-be-consistent</guid>
      <pubDate>Sat, 11 Jan 2025 10:00:26 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>理解相互矛盾的 Cox 回归结果</title>
      <link>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</link>
      <description><![CDATA[我有一个数据集，其中我使用 Cox 模型检查生存时间与血清胆固醇水平之间的关联，同时调整 BMI 和性别。我以两种不同的方式进行了分析，但难以协调两种不同方法之间的结果：
方法 1：对整个数据集进行 Cox 回归，以生存为结果，以胆固醇、BMI 和性别为预测变量。
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI + sex, data = df)
这导致输出结果为胆固醇与生存时间相关 (P &lt; 0.05)。 BMI 和性别的风险比并不显著，这表明胆固醇与生存时间相关，与本分析中的性别和 BMI 无关（解释正确吗？）

方法 2：Cox 回归，同时将数据集分层为男性和女性队列，而不使用性别作为预测变量：
#女性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;F&quot;))

#男性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;M&quot;))

这导致输出结果为女性患者的胆固醇与生存时间之间没有关联队列，但在男性队列中胆固醇与生存率之间确实存在关联。这难道不表明性别确实是决定胆固醇是否与生存时间相关的一个因素吗？为什么方法 1（其中性别被作为整个数据集中的预测变量）表明胆固醇与生存率相关，而与性别无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</guid>
      <pubDate>Fri, 10 Jan 2025 23:37:46 GMT</pubDate>
    </item>
    <item>
      <title>偏最小二乘回归 - 解释 X 的方差高于 100%</title>
      <link>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</link>
      <description><![CDATA[我正在使用 58 个参数（股票价格、历史回报、利率、国债收益率、商品……等）对标准普尔 500 指数的每日回报进行建模。
我使用偏最小二乘法创建了一个回归模型。
我的模型总共有 58 个组件，从 50 个组件开始，独立变量的解释方差超过 100%。
可能是什么原因造成的？
如果您需要更多信息，请告诉我。
编辑：
我使用 pls 包中的 plsr 函数实现了 PLSR：
dfAnalysisNumeric = read.csv(&quot;dfAnalysisNumeric.csv&quot;)[,-1]

plsrModel = plsr(indexReturn_t~.,data=dfAnalysisNumeric,
validation =&quot;CV&quot;,
scale=TRUE,
center=TRUE)
summary(plsrModel)

dfAnalysisNumeric 是我的数据集。我将其导出为 csv 文件。
这是链接：https://mega.nz/file/3ZsWDJpa#oueRGUqrVnyWqEIMdvU0mZYBjkAW57xklxkjbpTD_nQ
]]></description>
      <guid>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</guid>
      <pubDate>Fri, 10 Jan 2025 16:48:36 GMT</pubDate>
    </item>
    <item>
      <title>比例与连续变量的“总和”和“平均值”的正确用法</title>
      <link>https://stats.stackexchange.com/questions/658715/correct-usage-of-sum-and-mean-for-proportions-vs-continuous-variables</link>
      <description><![CDATA[通过“总和”与“平均值”来聚合“比例”与“连续”度量的正确方法是什么？
例如，假设我有“time_on_site”和“converted”。从逻辑上讲，将所有转化相加是有意义的，因为我们关心该变量的总体影响。但我也可以提出想要提高转化率的理由，因为我有兴趣在我的假设小部件中捕获更大比例的用户。
这是否取决于用例（这特别适用于 AB 测试），或者是否存在何时使用哪种聚合技术的一般经验法则？
如果这个问题与主题无关，请告诉我；我对按用例进行的统计上正确的聚合感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/658715/correct-usage-of-sum-and-mean-for-proportions-vs-continuous-variables</guid>
      <pubDate>Sat, 14 Dec 2024 12:18:41 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    </channel>
</rss>