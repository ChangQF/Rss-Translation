<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 13 May 2024 15:15:50 GMT</lastBuildDate>
    <item>
      <title>使用 emtrends 为不同组提供相同的 SE 值</title>
      <link>https://stats.stackexchange.com/questions/647147/identical-se-values-for-different-groups-using-emtrends</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647147/identical-se-values-for-different-groups-using-emtrends</guid>
      <pubDate>Mon, 13 May 2024 14:49:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么 1/SE 或 1/方差通常用作回归中的权重？</title>
      <link>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</link>
      <description><![CDATA[我第一次尝试进行荟萃分析，将简单实验处理的测量结果与多个物种的对照进行比较。我首先将混合效应模型拟合到从一组已发表的研究中收集的平均值。这工作得很好，但它当然忽略了一个事实，即平均值是用不同的精度水平估计的。听起来这是一个应该通过适当加权手段来解决的问题。其中几项研究发布了标准误差或其原始数据，因此我可以使用 SE 进行加权。
我的问题是：1/SE（或 1/ σ2）有什么特别之处？为什么不使用 2/SE、10/SE 或任何其他此类加权因子？
我很想问这个问题，因为由于一些研究使用了极其精确的仪器，SE 相差几乎两个数量级。精度越高显然越好，但对我来说，这些精确估计值与 100 次精确估计值相比并不明显。 （加权在拟合模型时还引入了一些算法问题，但这可能是可以解决的，我对概念论证更感兴趣）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</guid>
      <pubDate>Mon, 13 May 2024 14:37:12 GMT</pubDate>
    </item>
    <item>
      <title>集群 SE 与固定中的 0 单元进行跨级交互的行为</title>
      <link>https://stats.stackexchange.com/questions/647143/behavior-of-clustered-ses-for-cross-level-interaction-with-a-0-cell-in-fixest</link>
      <description><![CDATA[我在 R 中使用fixst 来进行具有聚类 SE 的固定效应逻辑回归。我无法分享我的数据，但希望我能很好地解释这个问题。我有 11 个聚类，每个聚类有 29 到 493 个观测值，这些观测值分为基线时间点和后续时间点（称为时间）。
我估计了时间与具有4个级别的簇级因子变量（称为组）之间的跨级别交互作用，因此有3个交互项。对于第二级组，随访时所有结果值均相同。我注意到，对于与时间对应的交互项，使用聚类时 SE 很小，p 值非常小。
m2 = feglm(y ~ time * L2var | group, data = set1, family = “二项式”)
概要(m2)

&gt;概要(m2)
GLM 估计，族 = 二项式，Dep。各不相同
观察次数：1,497
固定效果：站点：11
标准错误：集群（组）
                                         估计标准。误差z值Pr(&gt;|z|)
时间跟进 1.373515 0.342168 4.014151 0.00005966 ***
时间跟进：组1 0.743281 0.778241 0.955078 0.33953814
时间跟进：group2 14.310706 0.342168 41.823604 &lt; 2.2e-16***
时间跟进：组3 0.165190 0.561198 0.294353 0.76848817
...由于共线性，删除了 3 个变量（组 1、组 2 和组 3）
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
对数似然：-770.6 调整后伪 R2：0.115961
           BIC: 1,650.8 平方 Cor.: 0.138072

如果我通过指定 vcov = “iid” 来删除聚类，则 SE 和 p 值会很大，这就是我在单元格为 0 时所看到的情况。
&lt;前&gt;&lt;代码&gt;&gt;摘要（m2，vcov =“iid”）
GLM 估计，族 = 二项式，Dep。各不相同
观察次数：1,497
固定效果：站点：11
标准错误：IID
                                         估计标准。误差z值Pr(&gt;|z|)
时间随访 1.373515 0.168833 8.135366 4.1070e-16 ***
时间跟进：group1 0.743281 0.784142 0.947891 3.4318e-01
时间跟进：group2 14.310706 359.444491 0.039813 9.6824e-01
时间跟进：组3 0.165190 0.320735 0.515036 6.0653e-01
...由于共线性，删除了 3 个变量（组 1、组 2 和组 3）
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
对数似然：-770.6 调整后伪 R2：0.115961
           BIC: 1,650.8 平方 Cor.: 0.138072

我的问题是：集群 SE 出现的小 SE 和 p 值是预期的，还是我做错了什么？如果是预期的，有人可以提供直观的解释吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647143/behavior-of-clustered-ses-for-cross-level-interaction-with-a-0-cell-in-fixest</guid>
      <pubDate>Mon, 13 May 2024 13:27:21 GMT</pubDate>
    </item>
    <item>
      <title>方差分析还是稳健分析？</title>
      <link>https://stats.stackexchange.com/questions/647137/ancova-or-moderation</link>
      <description><![CDATA[我正在努力处理一个问题的统计数据，我正在收集数据来回答。
我的论文是关于在控制生活意义时不同的冥想类型是否可以增加幸福感。冥想分为三个组，一组为对照组。在冥想干预之前和之后测量幸福感。生命的意义是我的协变量，在干预前测量一次。每个参与者被随机分配到一个组（3 个冥想条件，一个对照组）。
我想知道：

控制 MIL 时，冥想是否会增加幸福感
控制 MIL 时，每次冥想增加幸福感的顺序是什么 - 影响最大的顺序（第 1、2、3 组，然后是对照组）
对于不同级别的 MIL，哪种冥想对于增加幸福感最有效

我知道我可以通过混合设计（在主题因素之内和之间）ANCOVA 来回答 1 和 2，并通过后续事后测试来测试问题 2。
但是，问题 3 也可以通过该 ANCOVA 分析得到答案吗？或者问题 3 是否需要调节回归？我认为这需要适度的回归；然而，我在制定如何将幸福感的变化纳入调节回归模型时遇到了困难。这是因为我已经了解了使用变化分数的缺点以及如何在 ANCOVA 中使用 time_1 作为 CV 更可取。
关于#3，我希望发现群体与幸福感增加之间的关系会随着不同 MIL 水平的变化而变化。
这一切绝对让我头晕目眩，我希望得到一些帮助！希望这里的一切都清楚！]]></description>
      <guid>https://stats.stackexchange.com/questions/647137/ancova-or-moderation</guid>
      <pubDate>Mon, 13 May 2024 12:36:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在lme4中建模对照实验（三个时间点，两组）？</title>
      <link>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</link>
      <description><![CDATA[我们使用以下变量进行了行为改变现场实验：

三个时间点（T0、T1、T2）
两组（干预组与对照组）
个人 ID
工作室 ID

干预措施是在不同的小组、研讨会中进行的，使用 R 中的 lme4 包。我们计划将 T1 和 T2 的组间差异（由于样本量小/退出而分开）与 T0 进行比较分数作为协变量和两个随机截距。我们对所有 DV 进行了子选择 T1 行并添加了 T0 列。
例如：
model_1_post_self_efficacy &lt;- lmer(self_efficacy ~ T0_self_efficacy + group + (1 | individual_ID) +(1 | Workshop_ID), data = data_T1_baseline)

这不起作用，因为每个 individual_ID 只有一行。当我们使用由 T0 和 T1 行以及 T0 协变量列组成的数据集时，它确实有效。然而，从概念上讲，以 T0_DV 作为协变量来预测 T0 和 T1 之间的 DV 似乎很奇怪。
或者，没有协变量的模型，而是时间 * 组交互 + individual_ID + Workshop_ID 作为随机截距）也可以工作。
model_4_post_self_efficacy &lt;- lmer(self_efficacy ~ 时间 * 组 + (1 | 工作室_ID) + (1 | 个人_ID), data = data_T1_T0)

我的问题是：

有没有办法合理地将协变量和个体随机效应结合起来
我们如何最好地决定该做什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</guid>
      <pubDate>Mon, 13 May 2024 11:12:58 GMT</pubDate>
    </item>
    <item>
      <title>处理情况： (x ~ y) == (y ~ x)</title>
      <link>https://stats.stackexchange.com/questions/647134/handling-the-situation-x-y-y-x</link>
      <description><![CDATA[如果使用线性回归拟合以下两个模型，产生的系数本质上是相同的，那么使用什么合适的建模技术？

x ~ y
y ~ x

变量错误模型是正确的选择吗？
还是情况已经毫无希望了，两种模型本质上都毫无意义？
理论告诉我们：
$y=\frac{cov(x, y)}{var(x)}x+ϵx$
$x=\frac{cov(x, y)}{var(y)}y+ϵy$
我有生成模型的数据：

x=1.2+0.59y
y=1.2+0.64x

对于该数据，上述理论产生的斜率值为：0.3689927 和 0.818845，即不满足理论假设
数据可用，并且用于拟合模型的 R 代码是：
bal_mod=glm(log(估计) ~ log(Elapsed_Duration), data=bal, 子集=(Elapsed_Duration &gt; 0) &amp; (估计 &gt; 7))

和：
bal_mod=glm(log(Elapsed_Duration) ~ log(估计), data=bal, 子集=(Elapsed_Duration &gt; 0) &amp; (估计 &gt; 7))

值的分布似乎大致呈泊松分布，添加 family=poisson 会产生更好的拟合，但系数不会发生太大变化。
x 和 y 都是数据的 log 形式。]]></description>
      <guid>https://stats.stackexchange.com/questions/647134/handling-the-situation-x-y-y-x</guid>
      <pubDate>Mon, 13 May 2024 10:44:09 GMT</pubDate>
    </item>
    <item>
      <title>“重复测量测试”数据输入</title>
      <link>https://stats.stackexchange.com/questions/647133/repeated-measurement-test-data-input</link>
      <description><![CDATA[大家好！
几周前我刚刚开始使用 SPSS。假设我想做一个统计测试来检查 4 种不同农药在 5 周内的效率（第一周是对照）。每周我们都会进行测量。我决定采用双向重复测量方差分析测试（分析--&gt;一般线性模型--&gt;重复测量的选择）。
当我必须添加第二个因素（我将第一个因素添加为五级）时，我的问题就出现了。无论我如何插入数据，添加第二个因素都是不可能的。
周控制 Pes1 Pes2 Pes3 Pest4
1 2000 100 20 20 300
2 800 10 90 8 60
3 3 80 80 70 400
4 100 80 30 4 200
5 2 3 40 20 300

或
ID 周 CFU pESID 测量 ID
1 周1 2000 控制 1,00
1 周1 100 PES1 1,00
……
5 周5 40 PES2 2,00
5 周5 20 PES3 3,00
5 周5 300 pes4 4,00

或
产品 week1 week2 week3 week4 week5
1 2000 100 20 20 300
2 800 10 90 8 60
3 3 80 80 70 400
4 100 80 30 4 200
5 2 3 40 20 300

我是否使用了错误的测试或搞乱了设置？
感谢您提供的任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647133/repeated-measurement-test-data-input</guid>
      <pubDate>Mon, 13 May 2024 10:43:27 GMT</pubDate>
    </item>
    <item>
      <title>在模型中治疗效果后重新计算准确率、精确度和召回率</title>
      <link>https://stats.stackexchange.com/questions/647132/re-calculate-accuracy-precision-and-recall-after-treatment-effect-in-a-model</link>
      <description><![CDATA[采用流失预测模型，其目标是检测很有可能从网站流失的玩家，并向这些玩家发送报价以让他们留在网站。
在初始训练阶段，不会向玩家发送任何报价，因此您可以训练模型（在本例中为分类器）以确定是否失效为 1，如果未失效则为 0。使用准确度、精确度、召回率、f1 等标准指标，您可以选择最佳模型然后进行部署。
现在，一旦模型到位，您检测到的玩家将收到报价，假设几个月后您想要重新计算模型指标以评估模型是否需要重新训练，现在的问题是有一种治疗方法会改变玩家的行为，所以如果模型预测会失效（在本例中为 1），那么您发送报价，然后检查实际值，您可能会看到 0（没有失效），这可能意味着该优惠成功地防止了玩家失效。数据现在看起来像这样：

&lt;标题&gt;

user_id
churn_prediction
实际流失


&lt;正文&gt;

200
0
0


201
1
0


202
1
1



从表中您可以看到，例如 user_id 201 被预测会流失，因此他当时会接受治疗，然后当我们在 x 时间后检查实际/真实状态时，我们可以看到该用户仍然在地点。问题在于，对于分类器指标来说，churn_prediction 为 1 且actual_churn 为 0 将被视为错误的预测，但实际上，玩家的真实行为可能会因处理为 0 而改变（这对于系统，但我们不知道模型是否真的出错了，或者治疗是否影响了这一结果）。没有治疗的情况（预测=0）应该不会影响，因为我可以正确测量模型是否正确预测并检查实际情况，但是有治疗的情况很难估计模型是否正确。这肯定会影响所有分类指标，从而使正确评估模型的纯粹性能以进行重新训练/监控变得更加困难。
我知道我可以衡量与整个系统相关的其他指标，例如，也许报价不是最好的并且需要更改，但如果我只想评估模型的性能，我的问题是如何考虑治疗效果来重新计算指标，以便我可以评估模型的当前性能以进行重新训练/监控。]]></description>
      <guid>https://stats.stackexchange.com/questions/647132/re-calculate-accuracy-precision-and-recall-after-treatment-effect-in-a-model</guid>
      <pubDate>Mon, 13 May 2024 10:41:41 GMT</pubDate>
    </item>
    <item>
      <title>将 softmax 理解为激活函数以及数据和梯度的稀疏性</title>
      <link>https://stats.stackexchange.com/questions/647131/understanding-softmax-as-an-activation-function-and-sparsity-in-data-and-gradie</link>
      <description><![CDATA[我正在开发一个项目，其中包括一个使用单热点的概率模型，并且偶尔会部分冻结权重或将梯度归零到权重的特定区域。在模型的某些部分，我们还尝试使用 softmax 激活来增强模型这些部分的概率解释。我们正在尝试获得更多的可解释性，并看看以后是否可以使用它们来改进我们的分类。
然而，我在这些实验中遇到了一些困难，而且我经常发现模型很容易发散。从我所看到的来看，我相信这些是问题的（部分）——softmax函数往往会给小输入赋予过多的权重，当你再次使用softmax时，这种效果会变得更糟，而且权重的部分冻结（在一层内，而不是在层内）常见的层部分冻结）或者在某些情况下梯度本身已经稀疏，我认为这会影响优化器。单热输入也是一件事，并且可能有所贡献，但我不确定目前我是否有不同的选择。所以我的激活有问题，输入稀疏，梯度稀疏
是否有研究这些问题或类似问题的文献？您是否尝试过任何方法并在这些场景中取得了成功？
我已经尝试了一些关于 softmax 函数的要点，或者用其他东西替换它并添加归一化（总和为 1），但它们要么没有帮助，要么太不稳定，无法使用，现在我要继续数据本身和梯度。我们正在尝试其他不同的事情，但我想首先看看是否可能，如果不可能，至少了解这些主题的更多/原因。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647131/understanding-softmax-as-an-activation-function-and-sparsity-in-data-and-gradie</guid>
      <pubDate>Mon, 13 May 2024 10:07:24 GMT</pubDate>
    </item>
    <item>
      <title>泊松分布随机变量的高斯场</title>
      <link>https://stats.stackexchange.com/questions/647130/gaussian-field-of-poisson-distributed-random-variables</link>
      <description><![CDATA[即使观测值服从泊松分布，空间过程是否也可能是高斯场？它们的任何有限组合如何遵循多元正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/647130/gaussian-field-of-poisson-distributed-random-variables</guid>
      <pubDate>Mon, 13 May 2024 09:39:20 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的概率区间</title>
      <link>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</link>
      <description><![CDATA[目标：找到概率真正处于 [x]% 置信度的区间。
让我们从一个非预测性实验开始。抛硬币。正面或反面。我们已经知道，在公平的游戏中，正面或反面出现的概率各为 50%，但要实现这一目标，我们需要分析实验数据。
我抛了十次硬币，其中有六次是正面。
话虽这么说，我可以计算出置信度为 95% 的概率区间（z 得分为 1.96）。
置信区间 = 0.6 ± 1.96 × sqrt(0.6 * (1 - 0.6) / 10) = [0.2962, 0.9038]
这意味着，对于我第 11 次抛硬币，我可以有 95% 的置信度说正面朝上的概率等于或大于 29.62% 且等于或小于 90.38%。
酷！任务完成。现在是最困难的部分，机器学习预测。
我们不知道概率应该是多少，但我仍然想达到同样的目标。我希望能够创建一个概率区间，其中真实概率的确定性为 [x]%，而不是获得预测概率。
我创建了一个 C# 机器学习 ml.net 二进制分类模型，对它进行了训练并对其进行了评估，给了我一个 CalibrateBinaryClassificationMetrics 具有大量指标。

准确性；
精确召回曲线下的面积；
Roc曲线下面积；
混淆矩阵；
熵；
F1分数；
对数损失；
对数损失减少；
负精度；
负召回率；
正精度；
积极回忆；

从我去年的研究来看，我发现这些都对我想要实现的目标没有帮助，如果你证明我错了，我会很高兴。
我想预测概率区间，而不仅仅是概率。
我总是将输入样本分为两部分：训练和测试。测试部分用于获取 校准的二进制分类指标。
此测试部分是预测的，然后我将预测概率与实际输出进行比较（1 - 发生，0 - 未发生）。
我可以用这些数据实现预测区间吗？也许是一般误差范围？
我应该怎么做才能获得概率区间而不仅仅是预测概率？如果我们不知道概率有多准确，那么概率本身就没有任何意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</guid>
      <pubDate>Mon, 13 May 2024 01:42:57 GMT</pubDate>
    </item>
    <item>
      <title>在论文/论文的哪一部分报告变量的三分分割和虚拟编码？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647139/in-which-section-of-a-paper-thesis-to-report-tercile-split-and-dummy-coding-of-v</link>
      <description><![CDATA[我正在写心理学研究论文。我对一个变量进行了三分位数分割，因为在其他实证工作中经常这样做，并且文献表明很可能会对分布的极端部分产生影响。然后在分析中，我将使用虚拟编码变量。
我应该在哪一部分报告三分位数分割？当我描述措施本身时直接在方法部分？
或者稍后在分析计划中我提到所使用的统计方法（例如回归）？
编辑：我必须提到，该量表是 10 分制，但在样本中仅观察到 3 到 7 之间的值，因此这也是对变量进行分类的一个论点。]]></description>
      <guid>https://stats.stackexchange.com/questions/647139/in-which-section-of-a-paper-thesis-to-report-tercile-split-and-dummy-coding-of-v</guid>
      <pubDate>Sun, 12 May 2024 19:38:26 GMT</pubDate>
    </item>
    <item>
      <title>提升和逻辑回归之间有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/647099/what-is-the-connection-between-lift-and-logistic-regression</link>
      <description><![CDATA[我注意到两个（显然不同的）措施之间存在有趣的联系。我处于购物篮分析框架（又名频繁项集挖掘，两者都是通用名称）下，其中所有变量都是热编码的。因此，我们的预测变量 Y 和预测变量 X 都是虚拟变量，代表交易中产品是否存在。
第一个度量“提升”来自 apriori 算法。
它被定义为
$$ \frac{置信度(A \rightarrow B)}{support(B)} = \frac{P(B|A)}{P(B)}$$
基本上是 $$ \frac{P(A \cap B)}{P(A)P(B)}$$
第二个度量来自单变量逻辑回归。
$$logit(Y) = a + bX + e_i$$
我的疑问在于逻辑回归部分。
a 是截距，b 表示对数赔率之差。
这两种度量都是对称的，当在 X 上回归 Y 或在 Y 上回归 X 时（或使用先验时），我仍然得到相同的 lift 和 b。但它们有不同的尺度。这有什么关系？
是否有一种形式可以将逻辑回归中的 b 值转换为等效提升力？
非常感谢我可以找到更多信息的任何提示或参考书目。
编辑：

这里我附上一个小样本。这些代表了apriori算法提取的一些规则。列 Antecedent 代表产品 A，列 Consequent 代表产品 B。在本例中，Lift 和 Logistics_coefficients 是我们感兴趣的变量，我试图弄清楚它们是如何相关的，以及我们是否可以从一个映射到另一个。
（如果有人感兴趣，这里是其他结果的链接)]]></description>
      <guid>https://stats.stackexchange.com/questions/647099/what-is-the-connection-between-lift-and-logistic-regression</guid>
      <pubDate>Sun, 12 May 2024 19:10:24 GMT</pubDate>
    </item>
    <item>
      <title>使用深度集成量化预测不确定性：如何组合拉普拉斯分布？</title>
      <link>https://stats.stackexchange.com/questions/647054/quantifying-prediction-uncertainty-using-deep-ensembles-how-to-combine-laplace</link>
      <description><![CDATA[对于回归问题，我想训练深度神经网络的集合来预测标记的输出以及不确定性，类似于论文中提出的方法使用深度集成进行简单且可扩展的预测不确定性估计。作者使用高斯分布的负对数似然（NLL）作为损失函数，使模型隐式学习方差
$$
{\ell_\text{NLL}}_G =
-\log p_G\left(y \mid \hat \mu, \hat\sigma^2\right)=
\frac{\log \hat\sigma^2}{2}+
\frac{\left(y-\hat \mu\right)^2}
{2 \帽子\sigma^2}+
\text{常量}
$$
其中 $y$ 是目标，$\hat \mu$ 是预测平均值， $\hat \sigma^2$ 是预测方差。
但是，我注意到当使用平均误差而不是均方误差作为损失函数时，我的模型收敛得更好。因此我想利用拉普拉斯 NLL，它对异常值应该更加鲁棒：
$$
{\ell_\text{NLL}}_L =
-\log p_L\left(y \mid \hat \mu, \hat b\right)=
\log \hat b +
\frac{\left|y-\hat \mu\right|}{\hat b} +
\text{常量}
$$
其中 $\hat b$ 是预测的比例参数。
在高斯情况下，作者将各个模型的预测均值和方差结合起来$m$：
$$
\mu_*=\frac{1}{M} \sum_{m=1}^M \hat \mu_m \\
\text{Var}(\mu_*) = \sigma_*^2=\frac{1}{M} \left(\sum_{m=1}^M\hat\sigma_m^2+\hat \mu_m^2 \右）-\mu_*^2
$$
计算混合拉普拉斯分布的均值和方差的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647054/quantifying-prediction-uncertainty-using-deep-ensembles-how-to-combine-laplace</guid>
      <pubDate>Sat, 11 May 2024 21:35:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解决与 LMM 中的随机效应项相关的奇点问题</title>
      <link>https://stats.stackexchange.com/questions/647138/how-do-i-resolve-singularity-issues-related-to-my-random-effect-term-in-lmm</link>
      <description><![CDATA[我正在尝试运行线性混合模型 (LMM) 来观察 CH4 和 CO2 通量如何随时间变化。我有一个随机区组设计，随着时间的推移重复测量。我的样本量也不平等，因为我无法在某个时间点对一个块进行采样。我尝试将 LMM 拟合到我的数据中，但发现控制重复测量的随机效应导致了奇点问题。我担心如果我删除这个变量并运行一个简单的线性回归，我会得到伪复制。我的变量的一些解释：

plot_type = 治疗
plot_id = 唯一 ID（块 ID 和治疗 ID 一起）

模型中的代码和错误：
buck.flux.co2 &lt;- lmer(co2_flux ~plot_type+ (1|plot_ID), data = bucket_data)

边界（单数）拟合：参见 help(&#39;isSingular&#39;)


我听说这意味着我的随机效应变量无法解释我们看到的任何变化。然而，由于我的生态系统变化很大，我希望我的随机效应变量能够控制至少一点点的变化。
有没有办法让我检查这是否是真实的响应，因为我的块设计没有影响任何变化？如果我无法检查，奇点错误是否会影响我的结果，或者我可以简单地忽略该错误吗？是否有另一个更简单的模型，我可以在其中删除这个随机效应变量，但仍然考虑重复和不平等的测量？
我尝试使用 glm() 但我找不到适合具有大量负连续值的左偏数据集的分布。我已经将数据可视化，治疗之间似乎没有显着差异，但我再次预计会有一些变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/647138/how-do-i-resolve-singularity-issues-related-to-my-random-effect-term-in-lmm</guid>
      <pubDate>Sat, 11 May 2024 20:24:05 GMT</pubDate>
    </item>
    </channel>
</rss>