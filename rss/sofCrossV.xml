<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 14 Jul 2024 06:22:16 GMT</lastBuildDate>
    <item>
      <title>为什么在参数 θ 阶的梯度推导中省略了平方项</title>
      <link>https://stats.stackexchange.com/questions/651007/why-does-the-square-term-get-omitted-in-gradient-derivation-of-parameter-%ce%b8-th</link>
      <description><![CDATA[我知道我的问题可能听起来有点复杂或难以理解，但当你阅读下面的图片时，它就很简单了。

正如你所见，平方^2完全消散，尽管我们使用的成本函数 MSE 确实包含一个误差项，后跟一个平方。]]></description>
      <guid>https://stats.stackexchange.com/questions/651007/why-does-the-square-term-get-omitted-in-gradient-derivation-of-parameter-%ce%b8-th</guid>
      <pubDate>Sun, 14 Jul 2024 03:52:56 GMT</pubDate>
    </item>
    <item>
      <title>使用连续风险函数证明参数可分离性</title>
      <link>https://stats.stackexchange.com/questions/651006/proving-parameter-separability-with-a-continuous-risk-function</link>
      <description><![CDATA[我有一个连续函数 $R : \Theta \mapsto \mathbb{R}$，其最小化函数为 $\tilde{\theta}$，我想要证明
$$\inf_{\theta:d(\theta, \tilde{\theta}) &gt; \delta} ( R(\theta) - R(\tilde{\theta}) ) &gt; 0 \text{ 对于任意 } \delta &gt; 0$$
示例函数为 $R(\theta) = E_Y[-\text{log}(p_{\theta}(Y))]$，其中 $p_{\theta}(y)$ 是有限混合分布的 pdf
$$p_{\theta}(y) = \sum_{c = 1}^C w_c p_{\psi_c}(y) \quad \theta = (w_1,...w_c)$$
并且没有两个 $p_{\psi_c}$ 是相同的]]></description>
      <guid>https://stats.stackexchange.com/questions/651006/proving-parameter-separability-with-a-continuous-risk-function</guid>
      <pubDate>Sun, 14 Jul 2024 02:51:38 GMT</pubDate>
    </item>
    <item>
      <title>为了成功地进行特征选择，至少应该使用多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/651005/how-many-samples-should-i-use-at-minimum-for-successful-feature-selection</link>
      <description><![CDATA[假设我的表格数据集中有 100 万个样本和 1000 列。
我想在数据集上运行特征子集选择算法。
加载完整数据集将使我的系统不堪重负。因此，我想加载其中的一部分。
我应该至少使用多少个样本来执行成功的特征选择，以便当我使用这些特征训练神经网络时，它将为我提供最高的准确度。]]></description>
      <guid>https://stats.stackexchange.com/questions/651005/how-many-samples-should-i-use-at-minimum-for-successful-feature-selection</guid>
      <pubDate>Sun, 14 Jul 2024 02:28:26 GMT</pubDate>
    </item>
    <item>
      <title>如何为已知偏差、准确率和召回率的 LLM 分类器构建类别比例置信区间？</title>
      <link>https://stats.stackexchange.com/questions/651004/how-to-construct-class-proportion-confidence-interval-for-an-llm-classifier-with</link>
      <description><![CDATA[假设我有一个数据集 $D$，其中有已知的基本事实标签。尽管如此，我还是在这个数据集上使用了一个少样本 LLM 分类器来预测每个标签的 $k$ 个类别。
从 LLM 结果中，我获得了每个 $k$ 个类别的精确召回率。我还获得了每个标签比例的偏差量，即预测比例与基本事实之间的差异。我知道该模型在预测标签方面的准确性。
我现在计划在新的数据集上预测标签，但我不知道基本事实。我想根据 LLM 的过去表现量化每个类别中标签总数的不确定性。
通常，我可能会使用引导程序简单地重新采样并在循环中重新拟合确定性模型，并采用预测的经验分布来获得预测的置信区间。但是，我们不能这样做，因为 LLM 调用成本太高。
我的想法是，我们应该：

通过从已知比例 $p_k$ 中减去经验估计的类比例 $\frac{TP_k}{N}$，确定每个 $k$ 类的分类器偏差。
使用标准 Wald 正态近似二项式方法确定经验类估计 $\frac{TP_k}{N}$ 的置信区间，并简单地将这些区间移动偏差量。

但是，我不确定这是否有效。它看起来无效，因为标准错误对于 $p_k$ 的值不是不变的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651004/how-to-construct-class-proportion-confidence-interval-for-an-llm-classifier-with</guid>
      <pubDate>Sun, 14 Jul 2024 01:59:37 GMT</pubDate>
    </item>
    <item>
      <title>AMOS 上的稳健最大似然估计量？</title>
      <link>https://stats.stackexchange.com/questions/651003/robust-maximum-likelihood-estimator-on-amos</link>
      <description><![CDATA[有谁有建议或能够使用 AMOS 上的稳健最大似然估计器吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651003/robust-maximum-likelihood-estimator-on-amos</guid>
      <pubDate>Sun, 14 Jul 2024 01:19:00 GMT</pubDate>
    </item>
    <item>
      <title>检验的一致性 - 分位数收敛</title>
      <link>https://stats.stackexchange.com/questions/650998/consistency-of-a-test-convergence-of-quantile</link>
      <description><![CDATA[我给出了统计模型$((0,1)^n, \mathcal{B}(0,1)^n,\mathcal{P}_n)$，其中$\mathcal{P}_n=\{ P_{\theta}^{\otimes n} \ |\ \theta \in (0, \infty) \}$且每个$P_{\theta}$都有密度函数$f_{\theta}(x)=\theta x^{\theta-1}$，且$P_{\theta}^{\otimes n}$表示乘积测量，同时假设独立性。我们想要测试：
$$H:\theta\leq 1\ ; \ K: \theta&gt;1$$
使用测试，$$\varphi_n(x)=\chi_{\{T_n(x)&gt;-\gamma_{n,1,\alpha}\}}$$
其中 $T_n(x)=\sum_\limits{i=1}^nlog(x_i)$ 且 $\gamma_{n,1,\alpha}$ 是 $Erlang(n,1)$ 分布的 $\alpha$-分位数。
我试图表明 $\varphi_n$ 是一个一致性测试，因此：
$$\lim_\limits{n \longrightarrow\infty}\mathbb{E}_{\theta}(\varphi_n)=1, \ \theta &gt;1$$
我的尝试如下：
首先我证明了 $Y_i:=-log(X_i) \sim Exp(\theta), \ X_i \sim P_{\theta}$，然后我们知道 $\sum_\limits{i=1}^n Y_i \sim Erlang(n,\theta)$，或者 $\sum_\limits{i=1}^n \theta Y_i \sim Erlang(n,1)$，因为 $\theta Y_i \sim Exp(1) $，使用假设的独立性。
因此我们最终得到 $-\theta \ T_n(X) \sim Erlang(n,1) $，因此如果我们将 $\gamma_{n,1}(x)$ 表示为 $Erlang(n,1)$ 分布的分布函数，我们得到以下结果：
$$\mathbb{E}_{\theta}(\varphi_n)=P_{\theta}(T_n(X)&gt;-\gamma_{n,1,\alpha})=P(-\theta T_n(X)&lt;\theta \ \gamma_{n,1,\alpha})=\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})$$
建议证明 $\lim_\limits{n \longrightarrow\infty}\frac{\gamma_{n,1,\alpha}}{n}=1$，我没能证明这一点，但假设我会证明这一点，我们现在可以使用 $\lim_\limits{n \longrightarrow\infty}\gamma_{n,1,\alpha}= \infty$，我假设这意味着
$$\lim_\limits{n \longrightarrow\infty}\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})=1$$
使用该$\gamma_{n,1}$是一个分布函数。但我不太确定如何严格论证这一点。
所以我的问题在于，如何真正证明$\lim_\limits{n \longrightarrow\infty}\frac{\gamma_{n,1,\alpha}}{n}=1$以及如何使用它来证明$\lim_\limits{n \longrightarrow\infty}\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})=1$。
任何帮助都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/650998/consistency-of-a-test-convergence-of-quantile</guid>
      <pubDate>Sun, 14 Jul 2024 00:23:24 GMT</pubDate>
    </item>
    <item>
      <title>证明线性回归的残差直方图和 QQ 图</title>
      <link>https://stats.stackexchange.com/questions/650996/justifying-residual-histograms-and-qq-plots-for-linear-regression</link>
      <description><![CDATA[从概念上讲，我很难理解为什么我们要考虑线性回归对角线的分位数-分位数图，经过广泛搜索后，我似乎无法得到明确的答案。
我发现的常见而肤浅的答案是，使用 QQ 图将我们的残差与正态分布进行比较（或通过构建残差直方图）可确保我们满足我们的误差对每个 x 值呈正态分布的假设。但这里面有一个缺陷。也就是说，QQ 图和残差直方图将来自所有 x 值的误差合并为一个分布。这样，我们不再考虑每个 x 值的分布，而是查看单个“拼贴”分布。因此，即使我们的 QQ 图看起来是线性的，或者我们的直方图看起来近似正态，我们也不能确定每个 x 值处的单个分布是否是正态的。这有某种概念上的理由吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650996/justifying-residual-histograms-and-qq-plots-for-linear-regression</guid>
      <pubDate>Sun, 14 Jul 2024 00:08:24 GMT</pubDate>
    </item>
    <item>
      <title>SAE 中的 l2 惩罚和 l2 损失之间的区别</title>
      <link>https://stats.stackexchange.com/questions/650995/difference-between-l2-penalty-and-l2-loss-in-sae</link>
      <description><![CDATA[我读过 Anthropic 的这篇论文 https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html，论文中损失的定义如下：$$
L = \mathbb{E}_x \left[ \| x - \hat{x} \|_2^2 + \lambda \sum_i f_i(x) \cdot \| W_{:,i}^{\text{dec}} \|_2 \right]
$$，其表述如下：损失函数
L 是重建损失的 L2 惩罚和特征激活的 L1 惩罚的组合。但这里不是 L2 惩罚吗？因为这里没有 L2 正则化，所以不是 L2 损失而是 L2 惩罚。我会将重建损失定义为 L2 损失而不是惩罚。你能解释一下吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650995/difference-between-l2-penalty-and-l2-loss-in-sae</guid>
      <pubDate>Sun, 14 Jul 2024 00:06:12 GMT</pubDate>
    </item>
    <item>
      <title>Dickey-Fuller 单位根检验，确定性项</title>
      <link>https://stats.stackexchange.com/questions/650993/dickey-fuller-unit-root-test-deterministic-terms</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650993/dickey-fuller-unit-root-test-deterministic-terms</guid>
      <pubDate>Sat, 13 Jul 2024 22:03:05 GMT</pubDate>
    </item>
    <item>
      <title>我可以将数据增强应用于测试集吗？</title>
      <link>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</link>
      <description><![CDATA[我正在处理一个包含 102 行（表格数据）的数据集，其中 91 行用于训练，11 行用于测试。我通过为训练集添加高斯噪声来使用数据增强。假设我做了所有正确的预处理（没有数据泄露），那么科学出版物将数据增强应用于我的测试集是否正确/可以接受，因此它可以大于 11 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</guid>
      <pubDate>Sat, 13 Jul 2024 21:47:42 GMT</pubDate>
    </item>
    <item>
      <title>评估贝叶斯回归模型后验的黄金标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</link>
      <description><![CDATA[让我解释一下我的意思和上下文：

我的意思是评估后验的正确性（例如对于近似贝叶斯推理方法）。
我最关心的是贝叶斯深度学习，我想要一种可以扩展到非常高维度的方法&amp;参数计数。。
有许多方法可用于分类（例如 Brier 评分），但我要求一些可与回归相媲美的方法。

一个有前途的想法是后验预测检查，但老实说，鉴于大多数贝叶斯模型输出样本而不是显式 pdf，我不确定如何以实用的方式实现它……
有什么想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</guid>
      <pubDate>Sat, 13 Jul 2024 19:51:03 GMT</pubDate>
    </item>
    <item>
      <title>非齐次几何分布方法</title>
      <link>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</link>
      <description><![CDATA[我正尝试通过考虑概率不等的几何分布来解决这个问题。
首先，我使用 Irwin-Hall 分布来推导，对于 n 个独立的均匀随机变量，$P(U_{1}+U_{2} + ... + U_{n} \geq 1) = 1 - \frac{1}{n!}$
因此，如果我们让 $X$ = 成功前的试验次数，那么
\begin{equation}
\begin{aligned}
P(X=2) &amp;= P(U_{1} + U_{2} \geq 1) \\
&amp; = 1-\frac{1}{2} \\
&amp; = \frac{1}{2}
\end{aligned}
\end{equation&gt;
\begin{equation}
\begin{aligned}
P(X=3) &amp;= (1-P(X=2))P(U_{1} + U_{2} + U_{3} \geq 1) \\
&amp; = (1-\frac{1}{2}) (1-\frac{1}{6}) \\
&amp; = \frac{5}{12}
\end{aligned}
\end{equation
一般来说，如果 n &gt; 2，则似乎 $P(X = n) = (1-\frac{1}{n!})\displaystyle \prod_{k=2}^{n-1} (1-P(X=k))$
我读到这个问题的答案应该是 $e$。但使用这种方法，我得到的预期值为 $\approx$ 2.6。这种方法有什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</guid>
      <pubDate>Sat, 13 Jul 2024 18:57:55 GMT</pubDate>
    </item>
    <item>
      <title>多类分类的假阴性与假阳性</title>
      <link>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</link>
      <description><![CDATA[假设我有三个类别 1、2、3。
并且有如下评估，其中第二个元素是错误预测，其中模型预测类别 3，而基本事实是 2。
y_true = [1,2,3]
y_pred = [1,3,3]

我正在制作可视化工具，其中

如果模型预测为类别 1 而基本事实不是类别 1，则为红色
如果模型预测为类别 2 而基本事实不是类别 2，则为绿色
如果模型预测为类别 3 而基本事实不是类别 3，则为蓝色
真实预测无颜色

第二个元素的错误类型是什么？假阳性还是假阴性？
从我上面的案例来看，第二个元素将是蓝色。]]></description>
      <guid>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</guid>
      <pubDate>Sat, 13 Jul 2024 16:44:51 GMT</pubDate>
    </item>
    <item>
      <title>前测试和后测试应使用什么方法？</title>
      <link>https://stats.stackexchange.com/questions/650976/what-methods-to-use-in-pre-and-post-testing</link>
      <description><![CDATA[嗨，我目前正在进行干预前后的研究。我的假设是干预是否有效果，以及人格特质是否会缓和干预的效果。
我有 253 个预样本，后续只有 102 个。我的分析计划是 t 检验，比较效果，然后进行分层分析，最后进行调节分析。
我的问题是
我是否只讨论我分析中的 102 名参与者？
我是否使用后测分数作为因变量？
我是否需要使用前测分数作为分层回归中的协变量？
我是否需要使用前测分数作为独立变量或计算前后之间的差异分数？
非常感谢您的帮助。如果有人能向我指出一篇使用类似分析的论文那就太好了，因为我已经研究这个问题好几个星期了。]]></description>
      <guid>https://stats.stackexchange.com/questions/650976/what-methods-to-use-in-pre-and-post-testing</guid>
      <pubDate>Sat, 13 Jul 2024 15:35:29 GMT</pubDate>
    </item>
    <item>
      <title>如何估计 RERI 的 CI [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650966/how-to-estimate-the-ci-of-reri</link>
      <description><![CDATA[此主题涉及用于测量交互作用的统计技术。RERI 是“由于交互作用而产生的相对超额风险”的缩写。我知道这有点难以理解，但简单来说，我想知道的是如何使用多元回归模型来估计这个 RERI。我考虑的场景是在事件发生时间分析中，通常使用 COX 回归模型。

这是关于 COX 模型的。
我读的论文在理解临床试验中的相互作用（亚组）分析。这篇论文的主题是如何估计临床研究中的相互作用。我不知道如何估计交互作用导致的相对超额风险（RERI）的置信区间。本文给出的公式（表2）由几个部分组成，公式中有多个回归系数。
因此，如何通过这种方式估计RERI的置信区间？非常感谢您的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/650966/how-to-estimate-the-ci-of-reri</guid>
      <pubDate>Sat, 13 Jul 2024 07:14:47 GMT</pubDate>
    </item>
    </channel>
</rss>