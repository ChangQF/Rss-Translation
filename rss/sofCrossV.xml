<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 18:21:40 GMT</lastBuildDate>
    <item>
      <title>通过过去的结果来预测未来表现的可能性的标准数学模型是什么？</title>
      <link>https://stats.stackexchange.com/questions/654116/what-is-a-standard-mathematical-model-for-the-likelihood-that-past-results-predi</link>
      <description><![CDATA[我是统计学新手。我想了解一些逻辑、数学和哲学基础以及建立“可能性”的简单应用理论的理由，而对实践中更常用的复杂和启发式技术不太感兴趣。
我首先考虑在逻辑（或类型理论）中定义一些场景。
该场景是一个具有输入和输出的函数，并且存在与正确预期输出之间的误差测量。
问题是基于过去的表现来证明某事的可能性。
我认为大部分分析都与输入空间的数学特征有关。
如果可能的输入集是无限的，我们可能会问，是否没有任何数量的函数采样可以证明测试数据是准确的预测因子。
我认为一个关键方面是输入集类似于“连续”、拓扑连接或其他东西。这可能使我们能够证明给定的采样告诉我们有关空间的更多信息，而不仅仅是我们采样的点，例如，如果我们知道中间点的值不能超过一定程度。
是否有一个基本公式，我们可以将概率定义为函数重复 N 次输出的预期准确度，该准确度与已经获得的值相同，因为我们假设函数的行为是“恒定的”，只要我们选择有效的“采样空间”？（我想函数是否具有确定性也很重要。）
感谢您提供详细的教程式答案。我也愿意进行修改，以使我的问题在统计方面更加规范。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654116/what-is-a-standard-mathematical-model-for-the-likelihood-that-past-results-predi</guid>
      <pubDate>Mon, 09 Sep 2024 18:17:56 GMT</pubDate>
    </item>
    <item>
      <title>对于具有一些重复测量的研究设计，如何计算评估者内类内相关性？</title>
      <link>https://stats.stackexchange.com/questions/654114/how-do-i-compute-the-intra-rater-intraclass-correlation-for-a-study-design-with</link>
      <description><![CDATA[对于具有重复测量的研究设计，如何计算评分者组内相关性？
该研究有大约 1000 名受试者，由 500 名评分者评分（连续 0-100%）。每个评分者平均评估 100 名受试者（从 30 到 200 名受试者不等，评分者可以自由选择多少）。受试者被随机分配给评分者，每个受试者平均获得大约 35 个评分。在评分者进行评估时，他们收到的待评分受试者中大约 5% 实际上是他们已经评估过的某些受试者的重复（随机选择，最多一个受试者被评分者评估两次）。
目前感兴趣的分析是这些重复受试者的评分者内变异性。我想计算 ICC，但我找不到适合此研究设计的方法。我已阅读 Koo &amp; Li，2016 年和其他人，但他们的描述似乎不符合本研究设计。
我的数据目前是这样的：



主题
评分者
值
重复




1
1
35
否


45
1
75
否


890
1
10
否


45
1
80
是


1
2
50
否


700
2
90
否



使用R，我认为计算这个 ICC 的正确方法是创建一些 lmer 模型并对其方差应用一些公式，但我不确定如何正确描述该模型（例如，我是否在评估者中嵌套重复？）以及什么是合适的公式。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654114/how-do-i-compute-the-intra-rater-intraclass-correlation-for-a-study-design-with</guid>
      <pubDate>Mon, 09 Sep 2024 17:45:22 GMT</pubDate>
    </item>
    <item>
      <title>如何表征数据集</title>
      <link>https://stats.stackexchange.com/questions/654112/how-to-characterize-a-dataset</link>
      <description><![CDATA[我知道我们可以计算数据集中连续变量的相关矩阵。但是，为了总结变量之间的相关程度，是否可以根据相关矩阵进行均值或其他操作？
此外，除了变量数量、样本大小之外，还有什么可以从统计或 ML 的角度描述数据集（最好是一个数字）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654112/how-to-characterize-a-dataset</guid>
      <pubDate>Mon, 09 Sep 2024 17:15:38 GMT</pubDate>
    </item>
    <item>
      <title>随机森林模型的 MSE 太大</title>
      <link>https://stats.stackexchange.com/questions/654111/way-too-large-mse-for-random-forest-model</link>
      <description><![CDATA[我目前正在用 Python 构建随机森林模型。我的主题是研究特定变量对于机器学习解释市值的准确性的重要性。我现在的问题是，我的 R 平方非常合理，但我的 MSE 每次都大得离谱。我认为这是因为我处理的值非常大（数十亿）。我必须规范化或缩放数据吗？我不知道该怎么做，因为我读到过规范化对于随机森林来说并不是很必要。我已经尝试了其他所有方法，例如特征重要性、特征工程、交叉验证、删除异常值等……但 MSE 保持在 2.72883556377383e+20 等范围内。有人能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654111/way-too-large-mse-for-random-forest-model</guid>
      <pubDate>Mon, 09 Sep 2024 16:42:37 GMT</pubDate>
    </item>
    <item>
      <title>比较两个散点图矩阵之间的线性斜率</title>
      <link>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</link>
      <description><![CDATA[下面是可重现的代码示例，它生成的数据集和图表与我正在处理的大致相似。数据集由多列基因转录本丰度值和一列二元处理变量组成。
library(GGally)
library(ggplot2)
set.seed(123)
n &lt;- 30 

treatment &lt;- factor(rep(c(&quot;Group1&quot;, &quot;Group2&quot;), each = n)) #二元分组变量 

col1_group1 &lt;- rnorm(n, mean = 50, sd = 15) 
col1_group2 &lt;- rnorm(n, mean = 50, sd = 8)

col2_group1 &lt;- 0.6 * col1_group1 + rnorm(n, sd = 7)
col2_group2 &lt;- 0.4 * col1_group2 + rnorm(n, sd = 4)
col3_group1 &lt;- 0.5 * col1_group1 + rnorm(n, sd = 7)
col3_group2 &lt;- 0.3 * col1_group2 + rnorm(n, sd = 4)
col4_group1 &lt;- 0.7 * col2_group1 + rnorm(n, sd = 7)
col4_group2 &lt;- 0.5 * col2_group2 + rnorm(n, sd = 4)
col5_group1 &lt;- 0.8 * col3_group1 + rnorm(n, sd = 7)
col5_group2 &lt;- 0.6 * col3_group2 + rnorm(n, sd = 4)
col6_group1 &lt;- 0.6 * col4_group1 + rnorm(n, sd = 7)
col6_group2 &lt;- 0.4 * col4_group2 + rnorm(n, sd = 4)

dat &lt;- data.frame(
treatment = treatment,
col1 = c(col1_group1, col1_group2),
col2 = c(col2_group1, col2_group2),
col3 = c(col3_group1, col3_group2),
col4 = c(col4_group1, col4_group2),
col5 = c(col5_group1, col5_group2),
col6 = c(col6_group1, col6_group2))

ggpairs(dat, columns = 2:7, 
lower = list(continuous = wrap(&quot;smooth&quot;, method = &quot;lm&quot;, se=FALSE)),
diag = NULL, switch = &quot;both&quot;, ggplot2::aes(colour = treatment))


在我进一步详细描述我想要实现的目标之前，先介绍一下数据的几个关键特征：

这些基因都在某种程度上相互关联，因此并不相互独立（即具有多个基因预测因子的模型存在显著的多重共线性问题）
在可视化按治疗分组的基因之间的双变量关系时，很明显 A 组和 B 组具有相等的相关性和不相等的协方差（我在我的真实数据集中也有统计证据，通过 cortest.mat() 对来自心理学包和 Box 的 M 检验的非配对样本进行分析）。不平等的协方差给许多模型方法带来了另一个问题。
所有基因都是正态分布的

现在，我感兴趣的是测试第 1 组的斜率矩阵是否等于第 2 组的斜率矩阵。好吧，更具体地说，在我的真实数据集中，我实际上想测试第 1 组中某个基因相对于其余基因的斜率向量 (?) 是否等于第 2 组的斜率向量，因为当我可视化真实数据时，这种趋势对我来说非常明显，并且这种趋势可能具有生物学相关性。但我认为我对这个更具体问题的解决方案可能来自比较矩阵的方法。
其他一些想法：

我了解交互项和对比的工作原理。我对为每个基因运行单独的 lm(col_2~col_1*treatment, data=dat) 不感兴趣。无论如何，这可能会造成共线性问题，因为治疗会影响所有基因。由于我的样本量很小，所以我也希望最大化统计能力，这就是为什么我希望测试尽可能多地使用数据。
虽然多元多元回归方法确实在一次测试中使用了所有数据，乍一看似乎很有希望（即 lm(c(col_2,col_3,col_4,col_5)~col_1*treatment, data=dat)），但不平等的协方差在这里是一个重大问题。共线性仍然是一个潜在的问题。
这并不是最好的逻辑（原谅我，我是生物学家，不是统计学家），但如果可以比较两个矩阵的协方差，那么考虑到斜率与协方差直接相关，比较斜率难道不应该是这个的简单扩展吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</guid>
      <pubDate>Mon, 09 Sep 2024 15:57:03 GMT</pubDate>
    </item>
    <item>
      <title>如何将“X-Y%”或“约 Z%”表示为狄利克雷先验</title>
      <link>https://stats.stackexchange.com/questions/654109/how-to-express-x-y-or-about-z-as-a-dirichlet-prior</link>
      <description><![CDATA[我正在研究一个问题，我们需要从一个源获取一个物体的质量分数估计值。该源提供质量分数范围或有时是点估计值。例如，$m_1$ 在 80-90% 之间，$m_2$ 在 10-20% 之间，$m_3$ 为 2.4%，$m_4$ &lt; 1%。
将质量分数的分布建模为分类分布似乎是合适的，因为$\sum_i m_i = 1$。狄利克雷分布是表达这些质量分数 $m_i$ 的先验信息的自然选择，因为狄利克雷分布是分类分布的共轭先验。在狄利克雷分布中，表达“X-Y%”的不确定性范围或“Z%”等点估计值的最合适方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654109/how-to-express-x-y-or-about-z-as-a-dirichlet-prior</guid>
      <pubDate>Mon, 09 Sep 2024 15:49:11 GMT</pubDate>
    </item>
    <item>
      <title>m模型的目标函数</title>
      <link>https://stats.stackexchange.com/questions/654107/objective-function-of-m-model</link>
      <description><![CDATA[我试图将多变量指数模型*拟合到观察面板数据（m 个点和 n 个时间观察的空间和纵向数据）中的每个点。我想为每个观察（每个点的 n_j 不同）拟合一个跨时间（n 维或垂直）的独立模型，以最小化某个目标函数 (1)。我对目标函数 (1) 使用梯度下降和平方误差和*
$\ SSE=\sum_{i=1}^n (y_i - \hat{y_i})^2 \\$ ...(1)
但是，我的总体目标是最小化所有 m 个模型（水平）中的误差。
我正在考虑使用与目标函数 (1) 相关的目标函数 (2) 来同时评估所有模型作为梯度下降的目标函数。在这种情况下，这可以是目标函数 (1) 的 SSE 的均方误差
$\ MSE&#39; = \frac{1}{m}\sum_{j=1}^m (SSE_j)^2 \\$ ...(2)
我想对此类问题有一些既定的研究，但我找不到来源来找到我的情况的直接答案！我仍然想知道这是否有意义，或者在使用这种总体目标时我应该注意哪些缺点？我将不胜感激您的见解和建议
*我的每个点 $\ j \in [1 \to m ]\\$ 的模型可以表示为三个变量的函数。对于每个点，都会为 n 维上的所有观测值拟合一个模型。 （即 $(x_1,x_2,x_3) \\$ 点与点之间变化，但对于所有 n 个观测，该点内的数值保持不变）。
$f_i(x_1,x_2,x_3) = x_1 + x_2 * a^{x_3} + b = 0 \ where \ i \in [1 \to n ]\\$
**我选择“平方误差总和”是因为在我的案例中，每个模型的 n 都不同。因此，在评估目标函数 (2) 时，总和作为与 n 维中包含的观测数量相对应的加权值。]]></description>
      <guid>https://stats.stackexchange.com/questions/654107/objective-function-of-m-model</guid>
      <pubDate>Mon, 09 Sep 2024 14:58:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决贝叶斯分析中有关 beta 分布的这个问题？</title>
      <link>https://stats.stackexchange.com/questions/654106/how-to-solve-this-question-about-the-beta-distribution-in-a-bayesian-analysis</link>
      <description><![CDATA[该问题出现在 Babak Shahbaba 教授的书（使用 R 进行生物统计学：通过生物数据进行统计学入门）第 13 章的问题中。

Q4。假设我们对皮马印第安妇女中受糖尿病影响的人口比例感兴趣。让我们用随机变量 X 表示每个人的糖尿病状况，其中如果该人患有糖尿病，则 X = 1，如果该人没有糖尿病，则 X = 0。然后我们可以假设 X 具有参数 μ 的伯努利分布。我们知道整个美国糖尿病女性的人口比例约为 10%。我们想用这些信息来指定 μ 的先验。使用 R-Commander 找到一个具有相对较高概率密度值（约为 0.1）的 beta 分布。为此，通过更改参数绘制不同的 beta 分布，直到找到一个分布，该分布的概率密度曲线下面积在 0.05 到 0.15 的区间内较大。然后，使用 Pima.tr 数据（可从 MASS 包获得）找到 μ 的后验概率分布。使用后验概率分布获得 μ 的点估计和 95% 可信区间。

我的试验
library(tidyverse)
library(MASS)

x &lt;- seq(0, 1, by = 0.01)
dfb1 &lt;- tibble(x, prob = dbeta(x, shape1 = 1, shape2 = 9), curve = &quot;Beta(1, 9)&quot;, line = 1, sh1 = 1, sh2 = 9)
dfb2 &lt;- tibble(x, prob = dbeta(x, shape1 = 0.5, shape2 = 5), curve = &quot;Beta(0.5, 5)&quot;, line = 1, sh1 = 0.5, sh2 = 5)
dfb3 &lt;- tibble(x, prob = dbeta(x, shape1 = 10, shape2 = 90), 曲线 = &quot;Beta(10, 90)&quot;, 线 = 1, sh1 = 10, sh2 = 90)
dfb4 &lt;- tibble(x, prob = dbeta(x, shape1 = 0.1, shape2 = 0.9), 曲线 = &quot;Beta(0.1, 0.9)&quot;, 线 = 1, sh1 = 0.1, sh2 = 0.9)
dfb5 &lt;- tibble(x, prob = dbeta(x, shape1 = 100, shape2 = 900), 曲线 = &quot;Beta(100, 900)&quot;, 线 = 1, sh1 = 100, sh2 = 900)

df &lt;- dfb1 %&gt;%
dplyr::bind_rows(dfb2) %&gt;%
dplyr::bind_rows(dfb3) %&gt;%
dplyr::bind_rows(dfb4) %&gt;%
dplyr::bind_rows(dfb5) %&gt;%
dplyr::mutate(curve = factor(curve)) %&gt;%
dplyr::mutate(line = factor(line)) %&gt;%
group_by(curve) %&gt;%
dplyr::mutate(xhigh = sh1 / (sh1 + sh2), highest = dbeta(x = xhigh, shape1 = sh1, shape2 = sh2)) %&gt;%
ungroup()

ggplot(df) +
geom_line(aes(x, prob, color = curve, linetype = line), size = 0.5) +
geom_point(aes(xhigh, highest, color = curve), size = 3) + 
scale_color_brewer(palette = &quot;Dark2&quot;, name = &quot;Curve&quot;) +
scale_linetype(guide = &quot;none&quot;) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + 
theme_minimal()

绘图

我的试验答案
pbeta(q = 0.15, shape1 = 0.1, shape2 = 0.9, lower.tail = TRUE) - pbeta(q = 0.05, shape1 = 0.1, shape2 = 0.9, lower.tail = TRUE) #0.08547915
pbeta(q = 0.15, shape1 = 0.5, shape2 = 5, lower.tail = TRUE) - pbeta(q = 0.05, shape1 = 0.5, shape2 = 5, lower.tail = TRUE) #0.2712344
pbeta(q = 0.15, shape1 = 1, shape2 = 9, lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 1，shape2 = 9，lower.tail = TRUE) #0.3986325
pbeta(q = 0.15，shape1 = 10，shape2 = 90，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 10，shape2 = 90，lower.tail = TRUE) #0.9139534
pbeta(q = 0.15，shape1 = 100，shape2 = 900，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 100，shape2 = 900，lower.tail = TRUE) #0.9999987
pbeta(q = 0.15，shape1 = 1000，shape2 = 9000，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 1000，shape2 = 9000，lower.tail = TRUE) #1

因此，我猜测参数shape1和shape2应该分别为100和900，因为它们在0.1附近具有较大的概率密度面积（p = 0.9999987）。我的结论对吗？
需要什么？
我有兴趣解决这一部分：

为此，通过更改参数绘制不同的beta分布，直到找到一个概率密度曲线下面积在0.05到0.15区间内较大的分布。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654106/how-to-solve-this-question-about-the-beta-distribution-in-a-bayesian-analysis</guid>
      <pubDate>Mon, 09 Sep 2024 14:55:39 GMT</pubDate>
    </item>
    <item>
      <title>对大数据集进行子采样和多重测试</title>
      <link>https://stats.stackexchange.com/questions/654103/subsampling-large-data-set-and-multiple-testing</link>
      <description><![CDATA[考虑一组点$X=\{x_{1},...,x_{N}\}\subset [0,1]^{d}$，这些点独立于分布$P$进行采样。设$T$为检验统计量，$C\in\mathbb{R}$为相关检验。如果 $N$ 很大，并且 $T$ 难以计算，则一个（可能很简单？）策略是考虑 $K$ 个大小为 $n$ 的子样本，这些子样本来自 $X$，表示为 $X^{(1)}$, ..., $X^{(K)}$，并对每个子样本使用检验 $\phi$。
它可能需要以某种方式假设子样本 $X^{(1)}$, ..., $X^{(K)}$（无替换？独立性？）。但是，是否有任何工作为此类方法提供理论保证（例如，对第一类和第二类错误的约束）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654103/subsampling-large-data-set-and-multiple-testing</guid>
      <pubDate>Mon, 09 Sep 2024 14:19:37 GMT</pubDate>
    </item>
    <item>
      <title>具有时间变化协变量的 Cox 回归与离散时间 Cox 模型之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654101/difference-between-a-cox-regression-with-a-time-varying-covariate-and-discrete-t</link>
      <description><![CDATA[我很好奇离散时间 Cox 模型和具有时间依赖性协变量的 Cox 回归之间的区别。我的数据集包含一个单一事件变量和一个二元协变量，如下所示。我可以将治疗视为时间依赖性协变量吗？我知道风险比的值 = 0.4（来自类似研究）。我想知道哪种方法是正确的选择。
ID 时间 事件 治疗（协变量）
1 0 0 0
1 1 0 1
1 2 1 1
2 0 0 0
2 1 0 0
2 2 0 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/654101/difference-between-a-cox-regression-with-a-time-varying-covariate-and-discrete-t</guid>
      <pubDate>Mon, 09 Sep 2024 13:58:34 GMT</pubDate>
    </item>
    <item>
      <title>如何确定因素和相互作用内的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</link>
      <description><![CDATA[我的研究结构如下（虚假信息，相同想法）：
因素 A：3 个水平（3 种细菌菌株）
因素 B：3 个水平（3 种抗菌剂）
因素 C：2 个水平（细菌生长阶段：早期、老年）
因素 D：6 个水平（抗菌剂剂量：5、10、15、20 毫克）
感兴趣的测量：存活人口，$X$
我想知道：

在考虑因素 A 或因素 B 时，因素 C 是否会显著影响存活人口的测量，$X$？
在比较因素 A（或因素 B）的 3 个水平时，是否存在存活人群中存在显著差异，$X$？

我的直觉是将数据分成子集并进行多次方差分析，以比较因子 A 和因子 B 在每个剂量（因子 D）下的效果。并通过进行多次 t 检验来比较两个治疗水平。但我觉得这是错的。我从未使用过“复杂”（对我来说）的模型，感觉很迷茫。]]></description>
      <guid>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</guid>
      <pubDate>Mon, 09 Sep 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能求解 $\|X-A\|_2+\lambda_n\|X\|_1$？</title>
      <link>https://stats.stackexchange.com/questions/654099/is-it-possible-to-solve-x-a-2-lambda-n-x-1</link>
      <description><![CDATA[在深入了解了套索之后，我想到了一个想法：我们能否得到一个估计量$\hat{X}$，其谱范数与目标矩阵$A$相似？添加惩罚项以获得稀疏/低秩估计量，我认为这可以表示为解决以下优化问题
$$
\hat{X}=\underset{X\in\mathbb{R}^{n\times n}}{\operatorname{arg\,min}}\|X-A\|_2+\lambda_n\|X\|_1
$$
或
$$
\hat{X}=\underset{X\in\mathbb{R}^{n\times n}}{\operatorname{arg\,min}}\|X-A\|_2+\lambda_n\|X\|_{\text{nuclear}}.
$$
其中 $\|\cdot\|_2$ 表示谱范数，$\|X\|_1=\underset{i,j}{\sum}|X_{ij}|$ 和 $\|\cdot\|_{\text{nuclear}}$ 表示核范数。
这个问题有得到很好的研究吗？如果是，我应该用什么关键词来查找相应的论文？]]></description>
      <guid>https://stats.stackexchange.com/questions/654099/is-it-possible-to-solve-x-a-2-lambda-n-x-1</guid>
      <pubDate>Mon, 09 Sep 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>使用伪回归来检验多元方差分析假设</title>
      <link>https://stats.stackexchange.com/questions/654097/pseudo-regression-as-a-way-of-checking-manova-assumptions</link>
      <description><![CDATA[我偶然发现了一个在线教程（YT 系列，据说是统计学研究生课程），用于在 R 中实施 MANOVA 测试。在进行测试之前，需要测试一些重要的假设。作者部署了一个假回归，作为测试响应变量（因变量/DV）的线性组合是否满足正态性、线性和同质性/同方差性的假设的一种手段。
与帖子相关的假设：
$\mathbf{假设\ 1}$：因变量（即误差向量）是从多元正态分布中抽样的。
$\mathbf{假设\ 2}$：假设/预期这两个或多个连续因变量（DV）之间存在某种相关性。理想情况下，它们之间的关系是线性的，否则 MANOVA 将无法捕获和利用它（这里没有疑问，因为有些文献没有将其作为这些假设的一部分）。
$\mathbf{假设 3}$：所有因变量 (DV) 都显示协方差和方差的同质性。
以下是 R 代码中的具体设置以及作者的进行方式：
假设我们有一个设计矩阵 $\mathbf{X}$，包含三列，分别对应于 $DV_1$、$DV_2$、$DV_3$。
作者在 R 中基于卡方分布模拟了具有相同数量随机观测值的样本。
random &lt;- rchisq( nrow($\mathbf{X}$), df)
然后，此“随机”用作以下假回归的响应变量，其中$DV_1$、$DV_2$、$DV_3$：
fake &lt;- lm(random ~. , data=$\mathbf{X}$)
通过使用 rstudent()，标准化残差（作者称之为）被检索用于残差分析/诊断分析。
标准化 &lt;- rstudent(fake)
合理的原因是，模拟响应变量“随机”是卡方分布的，并且与$DVs$的相关性最小，回归线只是一条直线，残差也是具有卡方分布的随机变量。另一方面，标准化残差 (rstudent(fake)) 呈正态分布，这使我们能够通过检查直方图和 QQ 图来检查正态性和线性假设是否合理满足。
R 代码
正态性：
hist(标准化)
线性：
qqnorm(标准化)
然后，作者根据以下代码对假回归的拟合值进行标准化，以便于进行视觉比较，并检查共享常数方差和协方差的假设。
R 代码
同质性/同方差性：
fitted &lt;- scale(fake$fitted.values)
plot(fitted, 标准化)
所以这是我们通常看到的拟合与残差图OLS 回归。
问题：
1，为什么是卡方分布？为什么不是正态分布，这样残差就是正态分布？如果 QQ 图和直方图确实显示出合理的正态分布，那么它们对于 DV 到​​底意味着什么？
2，为什么使用 rstudent()？rstudent() 函数相当于用于检测异常值的折刀检验。我不明白它如何以这种方式用于残差诊断。
3，它是否是一种适合测试这些假设的技术，还是我误解了作者的意思？我对这种检查上述假设的方式的底层逻辑有些困惑。
我们通常只查看椭圆和协方差-方差矩阵的$DVs$的成对联合分布图，并发现它们相当相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/654097/pseudo-regression-as-a-way-of-checking-manova-assumptions</guid>
      <pubDate>Mon, 09 Sep 2024 13:21:07 GMT</pubDate>
    </item>
    <item>
      <title>如果我的 ARDL 结果与文献不符该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/654096/what-if-my-ardl-results-doesnt-follow-the-litterature</link>
      <description><![CDATA[我实际上正在写一篇关于货币政策的论文，我正在通过 Eviews 使用 ARDL 进行估算。我的结果表明，政策利率对通货膨胀率产生正向影响，这与文献所说的相反。我已经检查了所有测试，该模型是有效的。什么可以解释这种情况，或者我应该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/654096/what-if-my-ardl-results-doesnt-follow-the-litterature</guid>
      <pubDate>Mon, 09 Sep 2024 13:11:29 GMT</pubDate>
    </item>
    <item>
      <title>条件剩余事件时间悖论</title>
      <link>https://stats.stackexchange.com/questions/654095/conditional-remaining-time-to-event-paradox</link>
      <description><![CDATA[事件发生的条件预期剩余时间似乎随着等待时间的增加而增加。这似乎是错误的，或者像某种悖论。
让我们以 Lomax 分布为例。假设我们正在等待一个事件，事件的等待时间分布为
$$f(x)=\frac{a}{b}\left[1+\frac{x}{b}\right]^{-(a+1)}$$
其中 $a&gt;2$ 和 $b&gt;0$。还假设我们在时间 $T$ 观察到事件尚未发生。等待时间的条件密度变为
$$f(x|x\geq T)=\frac{f(x)}{f(x\geq T)}=\frac{f(x)}{1-f(x&lt; T)}=\frac{\frac{a}{b}\left[1+\frac{x}{b}\right]^{-(a+1)}}{\left[1+\frac{T}{b}\right]^{-a}}$$
假设我们观察到事件在时间 $T$ 未发生，则等待时间的预期值为
$$E[X|x\geq T]=\int_{T}^{\infty}xg(x|x\geq T)=\left[1+\frac{T}{b}\right]^{a}\int_{T}^{\infty}\frac{a}{b}x\left[1+\frac{x}{b}\right]^{-(a+1)}dx$$
积分可以用分部积分法求得。
$$\int_{T}^{\infty}\frac{a}{b}x\left[1+\frac{x}{b}\right]^{-(a+1)}dx=-x(1+\frac{x}{b})^{-a}\vert_{T}^{\infty}+\frac{b}{-a+1}(1+\frac{x}{b})^{-a+1}\vert_{T}^{\infty}$$
$$=T(1+\frac{T}{b})^{-a}-\frac{b}{-a+1}(1+\frac{T}{b})^{-a+1}$$
我使用了以下操作来评估 $\infty$。
$$x(1+\frac{x}{b})^{-a}=x^{-a}x^{a+1}(1+\frac{x}{b})^{-a}=x^{a+1}\left[x(1+\frac{x}{b})\right]^{-a}=x^{a+1}\left[\frac{x^{2}}{b}+x\right]^{-a}$$
应该清楚的是，当 $x\rightarrow\infty$ 为 $a&gt;2$ 时，这会趋于零，尽管它可能更严格。
那么最终的预期值为
$$\left[1+\frac{T}{b}\right]^{a}\left[T(1+\frac{T}{b})^{-a}-\frac{b}{-a+1}(1+\frac{T}{b})^{-a+1}\right]=T+\frac{b}{a-1}\left[1+\frac{T}{b}\right]^{a}$$
如果我们关心的是观察后的等待时间，而不是总等待时间
$$\frac{b}{a-1}\left[1+\frac{T}{b}\right]^{a}$$
因此，在我们注意到事件尚未发生之后，预期的额外等待时间至少会呈二次增长 ($a&gt;2$) 与我们观察的时间有关。这对我来说似乎非常违反直觉。通常，如果您等待某个事件发生一段时间并且它还没有发生，您会假设它会很快发生。我想知道我是否错过了什么或搞砸了什么？也许这是 Lomax 分布尾部较重的结果？这个结果有直观的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654095/conditional-remaining-time-to-event-paradox</guid>
      <pubDate>Mon, 09 Sep 2024 13:04:30 GMT</pubDate>
    </item>
    </channel>
</rss>