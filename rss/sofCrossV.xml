<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 07 May 2024 21:13:05 GMT</lastBuildDate>
    <item>
      <title>P 值与置信区间解释</title>
      <link>https://stats.stackexchange.com/questions/646760/p-value-vs-confidence-interval-interpretation</link>
      <description><![CDATA[令人耳目一新的假设检验。 p值被定义为“在原假设为真的情况下观察结果与观察结果相同或更极端的概率”。原假设通常为零；例如，均值之间的零差异、回归中的零系数等。
这个值没有说明替代假设；例如，均值之间的差异不为零。 $P(X \ge 观察|N_0=True)$
这让我想知道，置信区间怎么样？换句话说，他们是否假设 $N_0=True$ ？或者他们是否对 $P(X)$ 发表声明？因为置信区间可能不包括零（统计显着性！）
我对 CI 的理解是，平均值周围 95%（或 x%）的区间是给定样本和相应随机误差的最佳猜测。但这可能与 $P(X)$ 不同；这只是一种直觉，我无法解释为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/646760/p-value-vs-confidence-interval-interpretation</guid>
      <pubDate>Tue, 07 May 2024 21:12:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 bootstrapping 来估计方差有什么好处？</title>
      <link>https://stats.stackexchange.com/questions/646759/what-is-the-advantage-of-using-bootstrapping-to-estimate-variance</link>
      <description><![CDATA[我正在学习假设检验在线课程 其中使用自助法完成比例的单样本测试。我有一些统计学基础，其中单样本比例检验的检验统计量 $ z $ 是使用 te 公式进行数学计算的：
$$ z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0 * (1-p_0)}{n}}} $$，其中 $ p_0 $ 是假设的人口比例。分母是标准误差。
然而，本课程使用引导程序对此进行估计：它需要对样本进行多次重新采样，并采用 $ \hat{p} $ 的标准差作为估计值标准误差，可以简单地通过数学计算。
&lt;小时/&gt;
在相关课程中，自举法用于估计连续变量均值的抽样分布的标准误差。然后，使用正态分布的 CDF，使用该标准误差来计算样本均值的置信区间。
我的问题再次类似于比例情况：我们不是已经知道样本均值的标准误了吗？不就是 $ \frac{s}{\sqrt{n}} $ 其中 $ s $ 是样本标准差，$ n $ 是样本大小吗？除此之外，我们还知道样本均值的抽样分布遵循正态分布 (CLT)——因此我们不需要自举来生成置信区间。
为什么我们需要引导分布来估计统计样本分布的标准误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/646759/what-is-the-advantage-of-using-bootstrapping-to-estimate-variance</guid>
      <pubDate>Tue, 07 May 2024 21:05:57 GMT</pubDate>
    </item>
    <item>
      <title>关于非线性最小二乘法的问题</title>
      <link>https://stats.stackexchange.com/questions/646753/question-on-nonlinear-least-squares</link>
      <description><![CDATA[考虑以下 $Y&gt;0$ 等式：
$$
\log(Y)=\log(\gamma)+\log(\alpha+\beta X)+\epsilon。
$$
假设$E(\epsilon| X)=c\neq 0$。这个假设对 $(\gamma, \alpha, \beta)$ 的估计有什么影响？更准确地说， $c\neq 0$ 是否只会导致估计截距 $\gamma$ 出现偏差（如线性最小二乘），或者这是非线性最小二乘模型这一事实意味着 $c\neq 0$ 也可能导致估计的偏差 $(\alpha, \beta)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/646753/question-on-nonlinear-least-squares</guid>
      <pubDate>Tue, 07 May 2024 19:18:48 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性是因果推理的“警告标志”吗？</title>
      <link>https://stats.stackexchange.com/questions/646752/is-multicollinearity-a-warning-sign-for-causal-inference</link>
      <description><![CDATA[假设我们推断$A$是否导致$B$，同时保持$N = [N_0, N_1, \ldots, N_n]$不变，我们发现$N_i$与$A$相关性较好，但并不完全相关。有四个理由排除$N_i$：

我们可能发现了因果混淆$N_i \rightarrow A$（读作：$N_i$导致$A$）或$A \rightarrow N_i$。如果存在合理的因果关系（无论哪个方向），则不应控制$N_i$，因为它是一个混杂因素（$N_i \rightarrow A$和$N_i \rightarrow B$），一个中介因素（$A \rightarrow N_i \rightarrow B$）。

得到的系数将不稳定且可能无法重现；再次进行实验可能会为 $A$ 和 $N_i$ 选择不同的系数对（我并不认为相关性是完美的；只是足够好，加上一些统计噪声，选择不同的系数）。

奥卡姆剃刀原则建议首先追求一种更简约的理论（即去除 $N_i$）。如果 $A$ 和 $N_i$ 共线，那么仅包含 $A$ 的理论将更加简约，几乎与包含 $A$ 和 $N_i$ 的理论一样好。

由于自由度更多，因此具有该附加系数（自由参数）也会增加过度拟合的可能性，这会使 AIC、BIC 和样本外泛化恶化。


那么，为什么维基百科声称预测因子之间的多重共线性不是问题（多次那篇文章）而不是排除变量的理由，指出

高共线性表明包含所有共线变量非常重要，因为排除任何变量都会导致更差的系数估计、强烈的混杂和标准误差的向下偏差估计。

我同意盲目地事后删除它们是不合理的，但它应该警告研究人员重新检查他们首先选择这些变量的先验推理，评估中介和混杂效应的可能性以及附加参数在其预测值中是否“值得”。]]></description>
      <guid>https://stats.stackexchange.com/questions/646752/is-multicollinearity-a-warning-sign-for-causal-inference</guid>
      <pubDate>Tue, 07 May 2024 18:47:28 GMT</pubDate>
    </item>
    <item>
      <title>在估计 GARCH 过程之前标准化数据</title>
      <link>https://stats.stackexchange.com/questions/646751/standardising-data-before-estimating-a-garch-process</link>
      <description><![CDATA[我正在使用自制算法估计 GARCH 过程。当我在极端数据集上测试数据时，我获得了每个值的无意义估计值。如果我在估计 GARCH 参数之前对数据进行标准化，会出现什么问题？这显然会使常数项的估计变得毫无用处。]]></description>
      <guid>https://stats.stackexchange.com/questions/646751/standardising-data-before-estimating-a-garch-process</guid>
      <pubDate>Tue, 07 May 2024 18:44:53 GMT</pubDate>
    </item>
    <item>
      <title>无需正规方程即可导出残差的正交性？</title>
      <link>https://stats.stackexchange.com/questions/646750/deriving-orthogonality-of-residuals-without-normal-equation</link>
      <description><![CDATA[在我的阅读中，我偶然发现了此页面，这似乎证明了表达式OLS 估计器使用 $X^T\hat{\varepsilon} = 0$ 这一事实。然而，我似乎无法找到这个先前事实的证据，该事实不开始使用我们打算导出的表达式！
特别是，我正在寻找：

这句话的理由：“因为如果不是，就会有另一个解决方案 $\widetilde{\beta}$ 给出另一个向量 $\widetilde{\varepsilon}$ 具有较小的残差平方和。”这是为什么？

理解残差向量与设计矩阵正交的含义（即为什么它有用，或者可能是几何直觉）


提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/646750/deriving-orthogonality-of-residuals-without-normal-equation</guid>
      <pubDate>Tue, 07 May 2024 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>具有多个类别的不平衡数据集</title>
      <link>https://stats.stackexchange.com/questions/646746/imbalanced-dataset-with-multiple-classes</link>
      <description><![CDATA[我有一个包含多个类的不平衡数据集，其中一些类少于 100，一些类超过 10k，我想应用随机森林（数据集是机密的，所以我无法共享），我使用了所有采样方法来克服这个问题，使用了所有 SMOTE 技术，完成了超级调整，除了我的 f1score 仍然是 40% 之外，我该怎么办，是否有任何新的先进技术或任何关于这个问题的研究文章或期刊，??????]]></description>
      <guid>https://stats.stackexchange.com/questions/646746/imbalanced-dataset-with-multiple-classes</guid>
      <pubDate>Tue, 07 May 2024 17:32:12 GMT</pubDate>
    </item>
    <item>
      <title>联合模型/建模中二项式纵向结果系数的解释</title>
      <link>https://stats.stackexchange.com/questions/646745/interpretation-of-coefficient-for-binomial-longitudinal-outcome-in-joint-models</link>
      <description><![CDATA[在执行生存和纵向结果的联合模型时，当纵向结果为二项式时，我们如何解释系数？
在此处的幻灯片中，第 131 至 142 页https://www.drizopoulos。 com/courses/EMC/ESP72.pdf
我们可以考虑条件期望值或条件线性预测器（第 133 页）。有了条件期望值，我们可以使用 JMbayes2 中的 vexpit 函数
https://drizopoulos.github.io/JMbayes2/articles/Transformation_Functions.html
在第 139 页，我们估计了 expit(value(spiders)) = 0.458。这里 expit(value(spiders)) 可以取 0 到 1 之间的值，因为我们使用 logit 链接函数建模了 GLMM。

对于连续的情况是可以的。我们可以说，logSB 每增加 1，我们的死亡风险就会增加 exp(1.326)。但这是可以的，因为 logSB 取正值。
那么我们怎么能说“对于 expit(value(spiders)) 增加一个单位，我们将得到......”。对我来说，蜘蛛出现的概率增加一个单位并没有多大意义，因为它的范围只是从 0 到 1。
我的意思是，这里的 Spiders 不是虚拟变量，对吧？我们不能说在时间 t 有蜘蛛=是会增加死亡风险 exp(0.458) 吗？
我不确定这个解释。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646745/interpretation-of-coefficient-for-binomial-longitudinal-outcome-in-joint-models</guid>
      <pubDate>Tue, 07 May 2024 17:19:19 GMT</pubDate>
    </item>
    <item>
      <title>帮助对本科统计课程中的主题进行排序</title>
      <link>https://stats.stackexchange.com/questions/646741/help-with-sequencing-topics-in-undergrad-stats-course</link>
      <description><![CDATA[多年来，我对统计课程进行了排序，以便估计理论先于抽样理论。似乎有道理——你需要几个估算器来讨论他们的分布。但我意识到，自从我有了构建 CI 背后的概率陈述的工具以来，我一直在采样部分中包含置信区间。但区间估计就是估计，逻辑将决定主题应该与估计相关。我快速浏览了几条短信，看看他们是如何处理的，但没有一条令我满意。所以我的问题是：解决这个先有鸡还是先有蛋的问题的最佳方法是什么？如果我将 CI 与估计一起放入，那么我必须在估计量的分布上挥舞手臂，从教学的角度来看，这并不是一件好事。如果我把它们留在采样部分，它们现在对我来说似乎不合适，而且我对此感到不舒服。有什么想法、想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646741/help-with-sequencing-topics-in-undergrad-stats-course</guid>
      <pubDate>Tue, 07 May 2024 16:12:53 GMT</pubDate>
    </item>
    <item>
      <title>受试者内部和受试者之间的方差和观察的独立性</title>
      <link>https://stats.stackexchange.com/questions/646740/within-and-between-subjects-variance-and-independence-of-observations</link>
      <description><![CDATA[我发现一些说法说，如果受试者内和受试者间的标准差相似，即使存在重复测量（例如，来自纵向调查），观察结果也可以被认为是独立的。因此，可以使用线性回归来代替对数据中的依赖性进行建模的多级模型。
我认为这种说法毫无根据，但我没有找到任何反对它的参考资料。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646740/within-and-between-subjects-variance-and-independence-of-observations</guid>
      <pubDate>Tue, 07 May 2024 15:54:26 GMT</pubDate>
    </item>
    <item>
      <title>导出数据与 R 中特定模型的拟合程度的指标</title>
      <link>https://stats.stackexchange.com/questions/646748/deriving-a-metric-for-how-well-data-fits-a-specific-model-in-r</link>
      <description><![CDATA[假设我有 3 个虚拟模型（下图）和一组跨时间点 A、B、C 的数据，我想做一个测试，看看每组测量值与 3 个模型中的每一个模型的拟合程度如何模型 1、2、3 的指标。
我该如何在 R 中执行此操作？
虚拟模型数据
dummy.df &lt;- data.frame(S = c(0.8, 0.4, 0.1),
                       P = c(0.4, 0.5, 0.3),
                       R = c(0.1, 0.35, 0.9),
                       row.names = 字母[1:3])

虚拟输入数据
random.df &lt;- as.data.frame(matrix(runif(5*3),
                                  n行 = 5,
                                  ncol = 3,
                                  暗名称=列表（1：5，字母[1：3]）））

]]></description>
      <guid>https://stats.stackexchange.com/questions/646748/deriving-a-metric-for-how-well-data-fits-a-specific-model-in-r</guid>
      <pubDate>Tue, 07 May 2024 14:55:55 GMT</pubDate>
    </item>
    <item>
      <title>聚类标准误</title>
      <link>https://stats.stackexchange.com/questions/646744/cluster-standard-errors</link>
      <description><![CDATA[您应该仅在国家/地区级别或同时在国家/地区和年份级别上对标准误差进行聚类吗？我是否正确地在国家层面和年份层面添加了固定效应？我是否应该加入其他固定效应来提高精度？我正在研究干旱引起的失业的双向固定效应回归。
我将劳动力参与率、人均国内生产总值、全国人口份额、对数教育、城市化和对数平均家庭规模作为协变量，但不确定我是否正确添加了协变量。此外，我没有得到因变量洪水发生和干旱发生的任何统计显着结果。为什么我只能得到具有统计意义的劳动力结果？我该如何解决这个问题？
平衡面板：n = 49，T = 16，N = 784

残差：
       分钟。第一曲。第三曲中位数。
-4.8622e-02 -5.3658e-03 -9.9058e-05 5.0385e-03
       最大限度。
 4.6806e-02

系数：
                      估计标准。误差 t 值
洪水发生 0.00111652 0.00112015 0.9968
干旱发生 0.00094809 0.00140501 0.6748
劳动力党 0.12565008 0.03728062 3.3704
log_gdp_percapita -0.00037989 0.00049768 -0.7633
全国人口 -0.01481916 0.04815143 -0.3078
日志教育-0.00424230 0.00142365 -2.9799
城市化率 -0.00140794 0.00717339 -0.1963
log_householdsize 0.00459906 0.00149072 3.0851
                    Pr(&gt;|t|)
洪水发生 0.3192224
干旱发生 0.5000275
劳工党 0.0007911 ***
log_gdp_percapita 0.4455178
全国人口 0.7583538
日志教育 0.0029818 **
城市化0.8444525
log_householdsize 0.0021134 **
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：0.10884
残差平方和：0.1049
R 平方：0.036186
调整。 R 平方：-0.059925
F 统计量：8 和 712 DF 上为 3.34144，p 值：0.00091405

我尝试执行以下编码：
reg1 &lt;- plm（失业率 ~ 洪水发生率 + 干旱发生率 + labourforceparti + log_gdp_percapita + 国民人口 +
              log_教育+城市化+log_家庭规模，
                            数据 = 全国失业人数，
                            索引 = c(“参考区域”, “开始年份”),
                            模型=“内”，
                            效果=“双向”，
                            vcov＝“HC1”，
                            cluster = “reference_area”) # HC1 表示稳健的标准误差

摘要（reg1）
]]></description>
      <guid>https://stats.stackexchange.com/questions/646744/cluster-standard-errors</guid>
      <pubDate>Tue, 07 May 2024 12:13:11 GMT</pubDate>
    </item>
    <item>
      <title>无随机效应的简单线性混合模型的近似功效分析</title>
      <link>https://stats.stackexchange.com/questions/646718/approximate-power-analysis-for-simple-linear-mixed-model-without-random-effects</link>
      <description><![CDATA[出于教育目的，对两种条件下所有参与者的重复测量被建模为线性混合模型。我们对控制混杂因素 c1 和 c2 时结果的差异感兴趣；只有固定效应才有意义，随机效应完全可以忽略不计（事实上为零）：
模型 &lt;- &#39;结果 ~ 条件 + c1 + c2 + (1 | id)&#39;

通过模拟进行复杂的功率分析（如 LMM 的建议）在我们的环境中是不可行的。
那么，我怎样才能完成一个非常粗略（也许保守）的功效估计，只需要一些参数（例如 G*Power 中通常使用的参数），例如效应大小 f2、误差和 1-β 概率，而不是过多的其他参数参数？
编辑：只是澄清一下，这不是时滞测量，重复测量是指所有参与者在两种不同条件下进行测试（实验室测试，条件之间间隔 5 分钟，因此可以忽略不计）]]></description>
      <guid>https://stats.stackexchange.com/questions/646718/approximate-power-analysis-for-simple-linear-mixed-model-without-random-effects</guid>
      <pubDate>Tue, 07 May 2024 11:56:26 GMT</pubDate>
    </item>
    <item>
      <title>二项式数据、误差范围、样本标准误差</title>
      <link>https://stats.stackexchange.com/questions/646692/binomial-data-margin-of-error-standard-error-of-a-sample</link>
      <description><![CDATA[选举季即将到来，民意调查经常出现“误差范围”与其结果相关（例如，有 2 名候选人，有一项调查，候选人 A 是 52% 的受访者最喜欢的，候选人 B 是 48% 的受访者最喜欢的。但误差幅度为 3%）。&lt; /p&gt;
试图理解这个“误差幅度”是如何产生的。计算我在互联网上搜索并发现 这篇文章。文章说：
&lt;块引用&gt;
样本的标准误差乘以临界值=误差幅度

本文包含以下示例，但没有一步步解决。这似乎是二项式数据的示例（如果我错了，请纠正我）。 他们是如何得出等于 2% 的误差幅度的？（特别是，这里的样本标准误差是如何计算的，以及临界值是如何确定的？）。
&lt;块引用&gt;
一家出版公司想要调查其客户，看看他们是否
更喜欢阅读电子书或实体书。公司大约有
其数据库中有 100 万客户。由于公司无法
现实地调查了所有一百万人，他们随机收集了
从代表整个客户群的 3,000 名客户中抽取样本。

&lt;块引用&gt;
完成调查后，数据显示，3,000 人中有 2,000 人
客户更喜欢实体书（2000 / 3000 = 0.67 或 67%）。用一个
置信度为 95% 时，他们可以确定
误差为2%。精确度介于 65% 和 69% (67% +/- 2) 之间
描述整个客户数据库。然后公司可以假设
如果他们继续调查他们的剩余人口
客户群中，他们会发现 65% 到 69% 的人会
与其读电子书，不如读实体书。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646692/binomial-data-margin-of-error-standard-error-of-a-sample</guid>
      <pubDate>Tue, 07 May 2024 04:26:32 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，误差方差估计量的渐近分布是什么？</title>
      <link>https://stats.stackexchange.com/questions/646690/in-linear-regression-whats-the-asymptotic-distribution-of-the-error-variance-e</link>
      <description><![CDATA[假设 $Y_i=X_i&#39;\beta+\epsilon_i$ 与 $E(\epsilon_i|X_i)=0$  和 $E\epsilon^2_i=\sigma^2$ ，我估计 $\sigma^2$  使用 $s^2=\frac{1}{n}\sum_{i=1}^n (Y_i-X_i&#39;\widehat{\beta})^ 2$，其中 $\widehat{\beta}$ 是 $\beta$&lt; 的 OLS 估计量/跨度&gt;。我想知道 $s^2$ （适当缩放和标准化版本）的渐近分布是什么？如果能提供详细的推导步骤就太好了。预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646690/in-linear-regression-whats-the-asymptotic-distribution-of-the-error-variance-e</guid>
      <pubDate>Tue, 07 May 2024 04:18:06 GMT</pubDate>
    </item>
    </channel>
</rss>