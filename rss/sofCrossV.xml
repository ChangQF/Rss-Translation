<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 22 Oct 2024 09:18:19 GMT</lastBuildDate>
    <item>
      <title>如何解释 lmer 的输出</title>
      <link>https://stats.stackexchange.com/questions/656128/how-to-interpret-output-from-a-lmer</link>
      <description><![CDATA[我在 R 中创建了一个 lmer，但在解释结果时遇到了困难。
我的问题是“时间”、“Kön”、“Ålder”、“Rökning”、“BMI”等因素如何影响接受过不同类型手术“Dikoop”的患者的结果“PCS”（具有三个级别的因素，0、1 和 2）。因此，例如 0 表示仅切除一小部分肺，1 表示切除一个肺叶，2 表示切除整个肺。
模型如下所示：
lmer(PCS ~ Dikoop + Time + VATS + Kön + Ålder +
BMI + FEV1 + DLCO + Rökning + Stadie + Komplikation +
Radikalitet + Histologi + (1 | Kod)，数据 = HRQoL_NA)
因此，我想知道的是 PCS（身体成分评分）在不同类型的手术（Dikoop 0 - 2）中会受到不同因素（Time + VATS + Kön + Ålder + BMI + FEV1 + DLCO + Rökning + Stadie + Komplikation + Radikalitet + Histologi）的影响。
有四个时间点，术前（“TimePre”）、3 个月（“TimeTre”）、1 年（“TimeTolv”）和 5 年（“TimeFemÅ”）。每个人的随机效应（“Kod”）。
要求 R 进行汇总时的输出如下所示：
&gt; summary(Model1)
REML 拟合的线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;] 公式：PCS ~ Dikoop + Time + VATS + Kön + Ålder + BMI + FEV1 + DLCO + Rökning + Stadie + Komplikation + Radikalitet + Histologi + (1 | Kod) 数据：收敛时的 HRQoL_NA REML 标准：3654.3 缩放残差：最小 1Q 中位数 3Q最大 -3.3493 -0.5389 0.0833 0.5735 2.4092 随机效应：组名称方差标准差。
 Kod（截距）49.40 7.028 
残差 43.25 6.576 
观察数：519，组：Kod，176

固定效应：

估计标准差。误差 df t 值 Pr(&gt;|t|) 

（截距） 38.34981 9.69407 160.64379 3.956 0.000114 ***

Dikoop -0.45375 1.45507 169.91653 -0.312 0.755543 

TimeFemÅ -8.02217 0.98242 370.12756 -8.166 5.09e-15 ***

TimeTolv -5.23974 0.80719 368.19768 -6.491 2.75e-10 ***

TimeTre -7.61993 0.74825 362.20865 -10.184＜ 2e-16 *** VATS 0.38724 1.52337 165.42421 0.254 0.799659 Kön 3.50594 1.76898 162.44963 1.982 0.049178 * 奥德尔 -0.03157 0.08939 163.71 292 -0.353 0.724361 体重指数 -0.24615 0.14369 162.98625 -1.713 0.088605 。  
    
    FEV1 3.45599 1.41612 165.90302 2.440 0.015721 * DLCO 0.07706 0.03554 158.01131 2.168 0.031629 * 洛克宁 0.65038 0.92677 162.75792 0. 702 0.483822 斯塔迪 0.01772 0.02988 159.66675 0.593 0.554023 复杂 -2.04195 1.63403 164.92713 -1.250 0.213200 Radikalitet 2.00072 2.74861 162.97434 0.728 0.467718 

Histologi -0.83041 0.72293 158.52445 -1.149 0.252422 

---
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

默认情况下不显示相关矩阵，因为 p = 16 &gt; 12。

如果需要，请使用 print(x, correlation=TRUE) 或

vcov(x)

对于 Dikoop 增加的每个步骤（从 0 到 1 或从 1 到 2），PCS 都会降低 -0.45 点，但并不显着，这样说对吗？我如何解释其他因素的估计数字，以及它与什么进行比较？例如，TimeFemÅ 的估计值为 -8.022（显著），这是什么意思，这是否意味着术后 5 年的患者的 PCS 显著低于其他所有患者？
希望有人能理解我的问题，否则请不要犹豫询问。
谢谢！
//Embla]]></description>
      <guid>https://stats.stackexchange.com/questions/656128/how-to-interpret-output-from-a-lmer</guid>
      <pubDate>Tue, 22 Oct 2024 09:11:08 GMT</pubDate>
    </item>
    <item>
      <title>深度集合操作只是逐元素加法吗？</title>
      <link>https://stats.stackexchange.com/questions/656127/is-the-deep-set-operation-just-elementwise-addition</link>
      <description><![CDATA[我一直在阅读 Deep Sets, 2017, Zaheer 等人
其中的数学看起来相当复杂。
但我查看了代码库。
看起来它只是元素相加？
这很好也很合理——最简单的方法。
但我想确保我没有误解，因为这篇论文看起来太复杂了]]></description>
      <guid>https://stats.stackexchange.com/questions/656127/is-the-deep-set-operation-just-elementwise-addition</guid>
      <pubDate>Tue, 22 Oct 2024 09:10:08 GMT</pubDate>
    </item>
    <item>
      <title>关于 Nyström 方法和矩阵求逆的探究</title>
      <link>https://stats.stackexchange.com/questions/656123/inquiry-about-the-nystr%c3%b6m-method-and-matrix-inversion</link>
      <description><![CDATA[我一直在研究用于获得矩阵低秩近似的 Nyström 方法，并想询问其在计算矩阵逆方面的适用性。
在我的研究中，我偶然发现了以下文章：Nyström 近似。但是，我不清楚作者如何应用 Woodbury 恒等式来计算此上下文中的逆。
我理解方程 (1) 为止
\begin{align} K = K_{22} &amp;= K_{21} U_1 \underbrace{\Lambda^{-1} \Lambda}_{I} \Lambda^{-1} U_1^\top K_{12} \\ &amp;= K_{21} U_1 \Lambda^{-1} U_1^\top K_{12}。 \tag{1} \label{eq:K22} \end{align
之后，我无法理解：如何使用 Woodbury 恒等式计算 $K^{-1}$。
有人能帮我理解这方面吗？
此外，如果您能提供任何关于使用 Nyström 近似计算矩阵逆的替代方法的见解，我将不胜感激。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656123/inquiry-about-the-nystr%c3%b6m-method-and-matrix-inversion</guid>
      <pubDate>Tue, 22 Oct 2024 08:20:26 GMT</pubDate>
    </item>
    <item>
      <title>CoxTimeVaryingFitter 样本外预测</title>
      <link>https://stats.stackexchange.com/questions/656122/coxtimevaryingfitter-out-of-sample-predictions</link>
      <description><![CDATA[我试图预测未来 24 个月内客户的生存几率。我使用的是来自生命线的 CoxTimeVaryingFitter。
我有一列，指示客户已经是客户的时间（关系持续时间）。这用于收集我的基线。我的 CoxTimeVaryingFitter (CTV) 已拟合并具有系数。这些系数用于获取客户的部分风险。
我可以使用以下代码来获取样本预测吗？我知道时间变化的样本外假设，但目前我主要只对样本外预测感兴趣。
# 从模型中获取基线累积风险
baseline_cumulative_hazard = ctv_model.baseline_cumulative_hazard_

# 获取基线风险时间点的范围
min_time = baseline_cumulative_hazard.index.min()
max_time = baseline_cumulative_hazard.index.max()

# 重新索引基线累积风险以包含所有时间点（以允许插值）
full_index = pd.RangeIndex(start=int(min_time), stop=int(max_time) + 1) # 创建时间点范围
baseline_cumulative_hazard = baseline_cumulative_hazard.reindex(full_index)

# 插值以填充时间点之间的缺失值
baseline_cumulative_hazard = baseline_cumulative_hazard.interpolate(method=&#39;linear&#39;)

# 获取最大和最小可用基线时间
max_baseline_time = baseline_cumulative_hazard.index.max()
min_baseline_time = baseline_cumulative_hazard.index.min()

survival_results = {}

for customer_id in extrapolated_data[&#39;customer_id&#39;].unique():

# 按 klant 过滤数据
customer_data = extrapolated_data[extrapolated_data[&#39;klt_rle_nummer&#39;] == customer_id]

# 获取客户当前的 `relation_duration`（任期起点）
relationship_duration = customer_data[&#39;end_date&#39;].iloc[0] # 假设客户的所有行都具有相同的 `relation_duration`

# 如果客户的 relationship_duration 超出可用基线，则使用最后一个可用基线值
if relationship_duration &gt; max_baseline_time:
baseline_hazard_from_relation_duration = baseline_cumulative_hazard.loc[max_baseline_time].iloc[0]

# 如果客户的 relationship_duration 超出最大可用基线，则使用最后一个可用基线值的基线 
elif relationship_duration &lt; min_baseline_time:
baseline_hazard_from_relation_duration = baseline_cumulative_hazard.loc[min_baseline_time].iloc[0] 

# 如果客户的 relationship_duration 在可用基线内，则使用来自客户的 `relation_duration` 的基线
else:
baseline_hazard_from_relation_duration = baseline_cumulative_hazard.loc[relationship_duration].iloc[0]

# 预测此客户的部分风险
partial_hazards = ctv_model.predict_partial_hazard(customer_data).values.flatten()

# 将累积风险计算为基线累积风险乘以部分风险
cumulative_hazard = baseline_hazard_from_relation_duration * partial_hazards

# 将生存概率计算为 S(t) = exp(-cumulative_hazard)
survival_prob = np.exp(-cumulative_hazard)

# 将结果存储在字典中，以 customer_id 为键
survival_results[customer_id] = survivor_prob

# 将结果转换为具有生存和流失概率的 DataFrame
survival_df = pd.DataFrame(survival_results, index=time_horizo​​n)

我有一个 for 循环，我可以从中获得一个月前的推断数据，然后使用上面的代码来获得一个月前的预测。这意味着我推断了 24 次，并使用上面的函数获得了 24 个月的 24 个预测。这里的推理是否正确，cumulative_hazard = baseline_hazard_from_relation_duration * partial_hazards 确实是获得累积风险的正确方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656122/coxtimevaryingfitter-out-of-sample-predictions</guid>
      <pubDate>Tue, 22 Oct 2024 07:51:40 GMT</pubDate>
    </item>
    <item>
      <title>GARCH-MIDAS 模型中系数的重要性</title>
      <link>https://stats.stackexchange.com/questions/656120/significance-of-coefficients-in-garch-midas-model</link>
      <description><![CDATA[我用GARCH-MIDAS模型检验股票波动率和epu的关系，但有些国家的$\alpha$（长期波动率参数）为0，p值为1，这个模型的条件$\alpha$应该大于0，不知道为什么，而其他国家的同类型数据可以得到正常的显著结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/656120/significance-of-coefficients-in-garch-midas-model</guid>
      <pubDate>Tue, 22 Oct 2024 05:41:13 GMT</pubDate>
    </item>
    <item>
      <title>推导 DDIM 下的扩散模型得分</title>
      <link>https://stats.stackexchange.com/questions/656118/deriving-the-score-of-a-diffusion-model-under-ddim</link>
      <description><![CDATA[我试图理解扩散噪声预测模型$\epsilon_\theta(x_t)$（预测添加到样本中的噪声）与得分函数之间的线性关系是如何得出的$$\nabla_{x_t}logp_\theta (x_t) = -\frac{1}{\sqrt{1-\bar{\alpha_t}}}\epsilon_\theta(x_t)$$，如(Dhariwal and Nichol 2021)中公式 11 所示
Lilian Weng 的博客写道，给定一个定义的前向噪声过程$q(x_t|x_0)\sim N(\sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})I)$我们有
$\nabla_{x_t}logq(x_t) = \mathbb{E}_{q(x_0)}[\nabla_{x_t}q(x_t|x_0)]= \mathbb{E}_{q(x_0)}[-\frac{\epsilon_\theta(x_t,t)}{\sqrt{1-\bar{\alpha_t}}}]=-\frac{\epsilon_\theta(x_t,t)}{\sqrt{1-\bar{\alpha_t}}}$.
虽然这一系列等式似乎恢复了所需的方程 11，但我很难理解第一个等式，$\nabla_{x_t}logq(x_t) = \mathbb{E}_{q(x_0)}[\nabla_{x_t}q(x_t|x_0)]$]]></description>
      <guid>https://stats.stackexchange.com/questions/656118/deriving-the-score-of-a-diffusion-model-under-ddim</guid>
      <pubDate>Tue, 22 Oct 2024 05:21:41 GMT</pubDate>
    </item>
    <item>
      <title>寻求有关测量睡眠剥夺的研究建议</title>
      <link>https://stats.stackexchange.com/questions/656116/seeking-advice-on-measuring-sleep-deprivation-for-research</link>
      <description><![CDATA[我正在研究会计专业学生的睡眠不足和学业成绩之间的关系。我们使用李克特量表来衡量学业成绩，并希望通过以同样的方式测量睡眠不足来保持一致性。
您能推荐一些现有的工具吗，或者建议我们如何将睡眠不足​​测量方法改编为李克特量表格式？
非常感谢您的见解！提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/656116/seeking-advice-on-measuring-sleep-deprivation-for-research</guid>
      <pubDate>Tue, 22 Oct 2024 03:50:00 GMT</pubDate>
    </item>
    <item>
      <title>当第二阶段的因变量是分类变量（而不仅仅是二进制）时，我们应该如何进行两阶段回归？</title>
      <link>https://stats.stackexchange.com/questions/656113/how-should-we-do-two-stage-regression-when-the-dependent-variable-in-second-stag</link>
      <description><![CDATA[我了解到，当内生回归量为连续且主要因变量（第二阶段）为二元时，Newey（1987）的两步估计量可以像 2SLS 一样使用。但是，在我感兴趣的研究问题中，我的第二阶段回归具有分类的因变量（如果某人完成毕业及以上，则为 1；如果个人完成高中教育，则为 2；如果个人完成中学教育，则为 3；如果没有接受过正规教育，则为 4）。但我的工具和内生自变量是连续的。
当因变量超出二元时，有没有办法进行两步估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/656113/how-should-we-do-two-stage-regression-when-the-dependent-variable-in-second-stag</guid>
      <pubDate>Tue, 22 Oct 2024 01:35:01 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 coxph 获取子组中的风险比？</title>
      <link>https://stats.stackexchange.com/questions/656119/how-to-get-hazard-ratios-in-subgroups-by-coxph</link>
      <description><![CDATA[如何获取子组变量每个级别的风险比？例如，在下面的例子中，我想获取男性患者的 HR/(95% CI)（男性患者第 1 组对第 2 组的治疗效果）和女性患者的 HR/(95% CI)（女性患者第 1 组对第 2 组的治疗效果）。
我读了讨论，有人建议包含一个交互项，这比对数据进行子集化更好。但我不知道如何获取每个患者子集的 HR。

我想要的是像森林图中那样，一个类别中两个治疗组的 HR，另一个类别中两个治疗组的 HR：

以下代码有意义吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656119/how-to-get-hazard-ratios-in-subgroups-by-coxph</guid>
      <pubDate>Mon, 21 Oct 2024 18:44:56 GMT</pubDate>
    </item>
    <item>
      <title>理解深度学习符号和期望的性质 - 邻居2邻居</title>
      <link>https://stats.stackexchange.com/questions/656102/understanding-deep-learning-notation-and-properties-of-expectation-neighbor2ne</link>
      <description><![CDATA[我试图遵循此处的定理 1 的证明，但无法完全理解作者使用的符号，因此我无法完全理解这些步骤。当我尝试深入研究深度学习社区的一些证明细节时，这种误解不断出现。
我的问题是：

(1) 作者从$\mathbb{E}_{x,y} ||f_\theta(y)-x||_2^2 $开始。这个表达式的正式定义是什么？是不是 $\sum ||f_\theta(y_i)-x_i||_2^2 p(x_i,y_i)$ 其中 $p$ 是 $x$ 和 $y$ 的联合分布？
(2) 在第一步中，作者使用 $\mathbb{E}_{y|x} ||f_\theta(y)-x ||_2^2= \mathbb{E}_{y,z|x} ||f_\theta(y)-z+z-x ||_2^2$。有没有办法用条件期望的定义来解释这一步？我不明白他们怎么能在对 $z$ 进行加减后，再将其添加到分布中？
(3) 考虑到以上两个问题，您可能对我误解符号的原因有了更好的了解。您有什么推荐的书/论文/youtube 可以从头开始介绍这些内容吗？我确实有概率论背景，但仍然无法理解他们采取的步骤。

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656102/understanding-deep-learning-notation-and-properties-of-expectation-neighbor2ne</guid>
      <pubDate>Mon, 21 Oct 2024 18:34:59 GMT</pubDate>
    </item>
    <item>
      <title>寻找 $3\theta_2^2$ 的 MVUE 的技术背后的动机</title>
      <link>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</link>
      <description><![CDATA[这个问题来自 Hogg 和 McKean 的《数理统计学导论》。
练习 7.7.11。
让 $X_1,X_2,\cdots,X_n$ 成为来自 $N(\theta_1,\theta_2)$ 分布的随机样本。
(a) 证明 $E[(X_1 − \theta_1)^4] = 3\theta_2^2.$
(b) 找到 $3\theta_2^2$ 的 MVUE。
我的尝试：
$N(\theta_1,\theta_2)$ 的联合完全充分统计量是 $(\overline{X},S^2)$、样本均值和样本方差。与此处或此处所做的类似，很容易证明（对于部分 (b)）
$$T = \cfrac{3(n-1)^2\Gamma\left(\frac{n-1}{2}\right)}{4\Gamma\left(\frac{n+3}{2}\right)}S^4,$$其中$S^2=\frac{\sum_{i=1}^n(X_i-\overline{X})^2}{n-1},$给定随机样本的样本方差。对于部分 (a)，众所周知，我们可以使用 mgf 技术找到中心矩（例如，请参见此处）。
我的问题：作者为什么要问部分 (a)？通常，他们这样做是为了引导读者找到解决部分 (b) 的方法。最初，我以为他们要我们猜测一个函数 $T$，使得 $\mathbb{E}(​​T) = 3\theta_2^2$ 并且 T 是 $\theta_1$ 和 $\theta_2$ 的联合完全统计量函数 $\pmb{Y}$。 这样自然会使 $T$ 成为 $3\theta_2^2$ 的 MVUE。具体来说，他们在上一节相关部分中提到（第 $448$ 页）
&quot;第 $7.3$ 和 $7.4$ 节中概述的 Rao–Blackwell、Lehmann–Scheffe 理论自然延伸到这种向量情况。简而言之，假设 $\delta = g(\pmb{\theta})$ 是感兴趣的参数，并且 $\pmb{Y}$ 是 $\pmb{\theta}$ 的充分和完整统计向量。令 $T$ 为 $\pmb{Y}$ 函数的统计数据，例如 $T = T(\pmb{Y})$。如果 $E(T) = \delta$，则 $T$ 是 $\delta$ 的唯一 MVUE。&quot;
那么部分 (a) 如何促使我们猜测此函数 $T$？
编辑 1：
SE 帖子 此处 显示了 $\sigma^4 = \theta_2^2$ 的无偏估计量，似乎与部分 (a) 中的形式相似，即
$$T&#39; = \frac{n}{3\left(n-1\right)^2} \sum_{i=1}^n \left(X_i - \overline X\right)^4$$
但不是 $\theta_2^2$ 的 MVUE。添加此评论以防万一相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</guid>
      <pubDate>Sun, 20 Oct 2024 07:03:17 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个 R 函数/统计数据可以查看 A 列中多次出现的特定值对 B 列的影响？</title>
      <link>https://stats.stackexchange.com/questions/656114/is-there-an-r-function-statistic-to-see-the-influence-of-a-specific-value-that-a</link>
      <description><![CDATA[我是 R 的初学者，正在研究松果的不同特征如何影响松果中种子的数量。
我使用 lm() 进行了许多线性回归，没有发现任何问题，发现几个特征都有显著的 p 值，例如种子所在的螺旋度（“Deg”）和松果中的种子总数（“TotalSeed”）。
在“Deg”列中，数字 360 出现的频率最高（15 个数据点中有 6 个）。有没有办法查看 360 度是否比其他数据点（720、540、270 等）与更高的 TotalSeed 更相关？如果可能的话，使用 p 值，因为它是我所在领域中唯一能理解/接受的统计数据。




度
总种子




1
480
358


2
200
400


3
3 60
366


4
360
394


5
360
362


6
270
476


7
360
516


8
475
284


9
540
441


10
270
363


11
720
380


12 
360
345


13
720
451


14
360
359


15
300
286



我尝试将 lm() 与 dplyr 的 filter() 和 select() 函数结合使用，但这并不能告诉我 360 是否比其他结果具有更强的相关性（这是有道理的）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656114/is-there-an-r-function-statistic-to-see-the-influence-of-a-specific-value-that-a</guid>
      <pubDate>Sat, 19 Oct 2024 16:08:30 GMT</pubDate>
    </item>
    <item>
      <title>在 10 个样本中，从 21 个列表中选择少于 4 个唯一数字的概率（有放回）</title>
      <link>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</link>
      <description><![CDATA[我有 21 个数字的列表，编号为 0 到 20（或 1 到 21，无所谓）。我随机挑选 10 次，每次都使该选择可用于下一次选择。这 10 次选择中唯一数字少于 4 个的概率是多少？
我用一个我认为正确的公式来解决组合问题，但是当我在电子表格上模拟该过程时，我得到了一个非常不同的结果：请问​​正确的公式是什么？以下是我对如何获得公式和模拟结果的解释。
选择少于 4 个唯一数字的概率是始终选择相同数字的概率 + 选择 2 个不同数字的概率 + 选择 3 个不同数字的概率。
$$P(&lt;4) = P(1) + P(2) +P(3)$$
我第一次从 10 个数字中挑选出 1 个唯一数字。第二次挑选时，我可以选择相同的数字，概率为 $\frac1{21}$，也可以选择不同的数字，概率为 $\frac{20}{21}$。在第一次选择之后的 9 次选择中始终选择相同数字的概率为
$$P(1) = \left(\frac1{21}\right)^9$$
在第二次选择之后，我选择了一个与第一次不同的数字，然后我还有第三次选择，我可以选择前 2 个数字中的一个，概率为 $\frac2{21}$，或者选择第三个不同的数字，概率为 $\frac{19}{21}$。在前 2 个数字之后，我在剩余的 8 次选择中继续选择相同的 2 个数字的概率为
$(\frac{2}{21})^8$，因此
$$P(2) = \frac{20}{21}\left(\frac{2}{21}\right)^8$$
继续同样的思路，在第 4 次选择时，我可以选择之前选择的 3 个数字之一，概率为 $\frac3{21}$，或者选择第 4 个不同的数字，概率为 $\frac{18}{21}$。在前 3 个数字之后，我在剩余的 7 次选择中继续选择相同的 3 个数字的概率为
$(\frac{3}{21})^7$，因此
$$P(3) = \frac{20}{21}\frac{19}{21}\left(\frac3{21}\right)^7$$
将三项相加
$$P(&lt;4) = \left(\frac1{21}\right)^9 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^8 + \frac{19}{21}\left(\frac3{21}\right)^7\right] = $$
这给了我大约 $P(&lt;4) = 0.00011\%$
当我尝试通过在 Google 表格中模拟该过程来验证结果时，我无法模拟足够的试验进行计算；上面的概率意味着大约 909,000 次试验的平均值是 1，但我发现 Google 表格允许我模拟大约 47,500 次试验。因此，我将问题从 10 次选择缩减为 8 次选择，通过归纳法获得
$$P(&lt;4) = \left(\frac1{21}\right)^7 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^6 + \frac{19}{21}\left(\frac3{21}\right)^5\right] = 0.0052\%$$
但是当我模拟它时，我得到 $P(&lt;4) = 0.016\%$
我用来模拟上述结果的 Google Sheets 公式是
=countif( byrow( map(RANDarray(55000, 8), lambda(x, int(x*21))), lambda(trial,COUNTUNIQUE(trial)) ), &quot;&lt;4&quot;) / 55000
]]></description>
      <guid>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</guid>
      <pubDate>Tue, 08 Oct 2024 18:49:31 GMT</pubDate>
    </item>
    <item>
      <title>一维激活波的预期时间</title>
      <link>https://stats.stackexchange.com/questions/655603/expected-time-of-activation-waves-in-1-dimension</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655603/expected-time-of-activation-waves-in-1-dimension</guid>
      <pubDate>Fri, 27 Sep 2024 17:03:01 GMT</pubDate>
    </item>
    <item>
      <title>关于真实分数方差估计的效率（低下）我们了解多少？</title>
      <link>https://stats.stackexchange.com/questions/645385/what-is-known-about-the-inefficiency-of-true-score-variance-estimation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645385/what-is-known-about-the-inefficiency-of-true-score-variance-estimation</guid>
      <pubDate>Fri, 19 Apr 2024 13:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>