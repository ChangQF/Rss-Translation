<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 12 Jul 2024 03:18:04 GMT</lastBuildDate>
    <item>
      <title>检查综合得分与其各变量之间协变量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/650915/checking-if-the-relationship-between-a-composite-score-and-its-components-across</link>
      <description><![CDATA[我创建了一个连续综合得分 C，它由得分 A + B 组成。我有一个预测变量 D。这将产生 3 个不同的回归公式，其中预测变量 D 对每个因变量都有一个系数：A、B 和 C。
我的目标是比较 A、B 和 C 的预测系数，看看它们是否具有统计差异。
在这种情况下，什么是合适的统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/650915/checking-if-the-relationship-between-a-composite-score-and-its-components-across</guid>
      <pubDate>Fri, 12 Jul 2024 02:58:08 GMT</pubDate>
    </item>
    <item>
      <title>单侧 t 检验的功效</title>
      <link>https://stats.stackexchange.com/questions/650914/power-of-one-sided-t-test</link>
      <description><![CDATA[设 $X_1, \ldots, X_n$ 为 $N(\mu, \sigma^2)$ 中的一个样本，其中未知数 $\mu \in \mathbb{R}$ 和未知数 $\sigma &gt; 0$。固定 $\mu_0 \in \mathbb{R}$。单侧假设为 $H_0: \mu \leqslant \mu_0$ 对 $H_1 : \mu &gt; \mu_0$。 t 检验由以下公式给出：
\begin{equation*}
t(X) = \frac{\sqrt{n} (\overline{X} - \mu_0)}{S}
\end{equation*&gt;
如果 $t(X) &gt; t_{1-\alpha, n-1}$，则对于 $\alpha \in (0,1)$，我们应该拒绝 $H_0$。
有没有办法计算这个检验的功效？我们知道，如果 $H_1$ 为真，则 $t(X)$ 服从非中心 t 分布：
\begin{equation*}
t_{n-1} (\frac{\sqrt{n}(\mu-\mu_0)}{\sigma})
\end{equation*&gt;
设 $Y_{\mu,\sigma}$ 为服从该分布的随机变量。其幂由下式给出：
\begin{equation*}
\inf_{\mu &gt; \mu_0, \sigma &gt; 0} P \{Y_{\mu,\sigma} &gt; t_{1-\alpha, n-1}\}
\end{equation*&gt;
我猜这确实有一个封闭形式，因为非中心 t 分布的累积分布函数很复杂。有哪些方法可以计算这个数量？特别是，我想知道 g-power 如何计算它，以便我可以重现结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/650914/power-of-one-sided-t-test</guid>
      <pubDate>Fri, 12 Jul 2024 02:31:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络从数据集中选择特征子集？</title>
      <link>https://stats.stackexchange.com/questions/650912/how-can-i-use-a-neural-network-to-choose-a-subset-of-features-from-a-dataset</link>
      <description><![CDATA[假设我的数据集有 256 个特征。
现在，我能想到的是：

创建一个这样的 NN 模型：
a. 创建一个顺序模型
b. 添加一个 Conv1D 层
c. 添加一个 flatten 层
d. 添加带有 relu 的 1024 密集层
e. 添加带有 relu 的 512 密集层
f. 添加带有 relu 的 256 密集层 =&gt; 因为我们有 256 个特征，所以我们将使用此层进行排名
g. 添加带有 relu 的 128 密集层
h. 添加带有 relu 的 64 密集层
i.添加 3 个带有 softmax 的输出密集层
将数据集分成 50 个块
使用每个块训练模型 2 个时期
收集层 (f) 的权重
堆叠所有块的所有权重
计算平均值
根据计算的平均值对特征进行排序

添加层 d、e、g 和 h 只是为了有一些变化。
坦率地说，我只是用常识编造了这种方法。我没有使用计算科学或数学。
你能提出一个更好的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650912/how-can-i-use-a-neural-network-to-choose-a-subset-of-features-from-a-dataset</guid>
      <pubDate>Fri, 12 Jul 2024 02:18:03 GMT</pubDate>
    </item>
    <item>
      <title>相关 p 值较低，未达到统计显著性阈值</title>
      <link>https://stats.stackexchange.com/questions/650911/related-low-p-values-that-do-not-meet-statistically-significant-thresholds</link>
      <description><![CDATA[如果我有多个相关测量，每个测量的 p 值都很“低”，且未完全达到显著性阈值，那么多个测量产生具有“低”p 值的总体趋势这一事实是否可以（谨慎地）证明零假设可以被拒绝？
例如，我正在比较 100 名学生在多场考试中的表现。在这些学生中，理论上有 20 名学生由于外部因素而面临较高的失败风险。我分析了他们在 10 场考试中的表现，并注意到他们的平均分数似乎比他们的同行更差。但是，比较测试（使用 Mann-Whitney U 检验）返回的 p 值在 0.03 和 0.20 之间，具体取决于考试。总的来说，（谨慎地）证明零假设可以被拒绝是否公平？总体趋势似乎表明这些学生的表现比他们的同龄人更差，尽管大多数比较测试没有返回显著性。
我听说一些研究人员认为这是可以接受的。但是，我还没有找到关于这个主题的任何文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/650911/related-low-p-values-that-do-not-meet-statistically-significant-thresholds</guid>
      <pubDate>Fri, 12 Jul 2024 02:08:05 GMT</pubDate>
    </item>
    <item>
      <title>使用尺度正权重和非 0.5 截止分数来建立相似模型</title>
      <link>https://stats.stackexchange.com/questions/650910/using-scale-pos-weight-and-non-0-5-cut-off-score-for-a-look-alike-model</link>
      <description><![CDATA[我正在研究一个分类问题，试图识别出第 0 类中第 1 类的相似者。第 1 类和第 0 类是根据客户使用的产品类型建立的。基本上，第 1 类客户拥有产品 A 并表现出某些行为。第 0 类客户拥有产品 B，但其中一些客户表现出的行为类似于拥有产品 A 的第 1 类客户的行为。
我的模型旨在识别表现出第 1 类行为的 0 类客户，以便可以有针对性地将第 0 类客户迁移到产品 A。我们称此类客户为相似者。
基本上，我只有确认的第 1 类客户。第 0 类在某种程度上是一组混合客户。我正在构建一个分类器来识别第 0 类中的相似者。基本上，模型识别的误报。
第 1 类和第 0 类的实际比例约为 1:10。我的样本的比例为 1:4。我正在使用 xgboost 分类器，其尺度正权重约为 4。
我试图保守一点，使用更高的截止分数 0.7 来识别相似者。即，任何获得 0.7 或更高分数的 0 类客户都被视为相似者。我使用召回率作为模型性能指标，在 0.7 截止分数下，我得到的召回率为 0.7，相似者或假阳性率为 0.05（5%）。考虑到业务用例，这看起来是合理的。
我的问题是，在这种情况下同时使用尺度正权重和更高的截止分数是否有意义？我的建模方法听起来有问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650910/using-scale-pos-weight-and-non-0-5-cut-off-score-for-a-look-alike-model</guid>
      <pubDate>Fri, 12 Jul 2024 01:16:22 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析电视剧集的受欢迎程度并兼顾时间因素？</title>
      <link>https://stats.stackexchange.com/questions/650909/how-should-i-analyse-tv-episode-popularity-while-accounting-for-time</link>
      <description><![CDATA[我有一个玩具数据集，其中包含电视剧集、发布日期以及收到的流媒体数量：



剧集
日期
流媒体




暗影领域
2024-03-08
5987


禁书
2024-03-01
6315


魔鬼的茶
2024-02-23
9584


魔法师的鞋子
2024-02-16
8996


魔法森林​​
2024-02-09
7564


回响深渊
2024-02-02
7982


失落文明
2024-01-26
8456


次元裂隙
2024-01-19
8834


水晶迷宫
2024-01-12
9215


扎尔萨的权杖
2024-01-05
9763



我有兴趣分析每集的流媒体数量接收。
具体来说，从数据中我们可以看到，一集播出的时间越长，它收到的流媒体就越多（一般来说）。同时，一些较新的剧集的流媒体播放量高于“预期”流媒体数量与发布日期的关系（此处的剧集是《魔鬼的茶》和《魔法师的鞋子》）。
我应该使用什么分析方法来确定每集的受欢迎程度（更高的流媒体 = 更受欢迎），同时考虑/控制时间的影响（较早的发布日期 = 更高的流媒体）？
如果有帮助，数据也以 R dput 格式提供。
structure(list(episode = c(&quot;The Shadow Realm&quot;, &quot;The Forbidden Tome&quot;, 
&quot;The Devil&#39;s Tea&quot;, &quot;The Sorcerer&#39;s Shoes&quot;, &quot;The Enchanted Forest&quot;, 
&quot;The Echoing Abyss&quot;, &quot;The Lost Civilization&quot;, &quot;The Dimensional Rift&quot;, 
&quot;The Crystal迷宫”、“扎尔萨的权杖”），date = structure(c(19790, 
19783, 19776, 19769, 19762, 19755, 19748, 19741, 19734, 19727
), class = “日期”），streams = c(5987, 6315, 9584, 8996, 7564, 
7982, 8456, 8834, 9215, 9763)), class = “data.frame”，row.names = c(NA, 
-10L))
]]></description>
      <guid>https://stats.stackexchange.com/questions/650909/how-should-i-analyse-tv-episode-popularity-while-accounting-for-time</guid>
      <pubDate>Fri, 12 Jul 2024 00:13:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 npmlt 函数构建的多项混合回归系数的重要性</title>
      <link>https://stats.stackexchange.com/questions/650907/significance-of-the-coefficients-of-a-multinomial-mixed-regression-built-with-np</link>
      <description><![CDATA[我（使用 npmlt 函数）拟合了一个混合多项回归模型，该模型运行时没有错误。
我期望模型的输出包含我未找到的 p 值。
我现在需要的是有人在这里帮助我找出如何了解这种模型系数的重要性。
请在下方找到模型的输出：
调用：npmlt（公式 = 三级分类变量 ~ 变量 1 + 变量 2 ，
公式.npo = ~1 + 变量 1 ，随机 = ~1，id = Patient_id，k = 2）
系数：
| |估计 |标准误差|
---------------------------------------------------
|（截距）1 | -1.029e+01|2.995e+00 |
|(截距) 2 |1.024e+01 |1.544e+00| 
|(截距) 3 |2.351e+01 |1.352e+00|
|变量1 水平1 1 |-7.995e+00 | 2.444e+00|
|变量1 水平1 2 |-2.711e+00 | 7.896e-01|
|变量1 水平1 3 |-1.375e+01| 7.093e-01|
|变量1 水平2 1 |-1.970e+01 |7.507e-07|
|变量1 水平2 2 |-2.172e+01 |1.171e+00|
|变量1 水平2 3 |-1.688e+01 | 9.573e-01|
|变量1 级别3 1 |-1.976e+01 |5.782e-15|
|变量1 级别3 2 |-2.835e+01 |3.827e-15|
|变量1 级别3 3 |-4.295e+01 |8.260e-16|
|变量2 1 | 1.527e+00 |7.733e-01|
|变量2 2 |2.288e-01 |1.865e-01|
|变量2 3 |2.760e-01 |2.915e-01|

有人能帮我解决以下问题吗？
我如何知道一个系数（上面的输出）是否重要？
提前感谢您的回答。
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/650907/significance-of-the-coefficients-of-a-multinomial-mixed-regression-built-with-np</guid>
      <pubDate>Thu, 11 Jul 2024 23:47:51 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型预测的引导置信度和预测区间问题</title>
      <link>https://stats.stackexchange.com/questions/650906/issue-with-bootstrap-confidence-and-prediction-intervals-of-mixed-effects-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650906/issue-with-bootstrap-confidence-and-prediction-intervals-of-mixed-effects-model</guid>
      <pubDate>Thu, 11 Jul 2024 23:36:05 GMT</pubDate>
    </item>
    <item>
      <title>在语义分割中不注意的情况下使用 U-Net 作为特征金字塔网络 (FPN) 的骨干是一种好方法吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650903/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpnwithout-attention</link>
      <description><![CDATA[我目前正在进行一项用于研究目的的图像分割任务，我正在考虑构建一个没有注意力的特征金字塔网络 (FPN)，使用 U-Net 作为主干模型。我已经基于这种方法实现了一个模型，但我不确定这是否是最好的方法。请告诉我使用 U-Net 作为 FPN 的主干是否是语义分割的好方法？我将不胜感激您的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650903/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpnwithout-attention</guid>
      <pubDate>Thu, 11 Jul 2024 21:10:12 GMT</pubDate>
    </item>
    <item>
      <title>我可以利用数据的时间序列属性，而不产生滞后吗？</title>
      <link>https://stats.stackexchange.com/questions/650901/can-i-utilise-time-series-properties-of-the-data-without-creating-lags</link>
      <description><![CDATA[我正在做一个项目，项目人员给我提供了训练集和测试集。数据（股票收益）本质上是时间序列，但关键是我无法创建滞后，因为这意味着丢弃前 k 个观测值，因为它们无法产生滞后。

为什么这对我来说是个问题？因为我将通过测试集上的 MSE 进行判断，该 MSE 由具有真实值（我无法访问）的预定义脚本计算得出。因此，这意味着我无法从测试数据集中删除任何值。我很乐意在数据上实现 LSTM 或 AR(I)MA，但由于这意味着为了进行预测，我也必须在测试集中创建滞后，所以我只能使用随机森林和 XGBoost。
有没有什么方法可以利用数据的时间序列属性，而不会产生滞后，或者是否存在任何深度学习方法可以让我做到这一点（我不知道）？
谢谢，感谢您的善意意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/650901/can-i-utilise-time-series-properties-of-the-data-without-creating-lags</guid>
      <pubDate>Thu, 11 Jul 2024 20:30:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 U-Net 作为特征金字塔网络 (FPN) 的骨干，而不关注语义分割，这是一种好方法吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650900/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpn-without-the-atten</link>
      <description><![CDATA[我目前正在进行一项用于研究的图像分割任务，我正在考虑构建一个没有注意力的特征金字塔网络 (FPN)，使用 U-Net 作为主干模型。
我已经基于这种方法实现了一个模型，但我不确定这是否是最好的方法。
请告诉我使用 U-Net 作为 FPN 的主干是否是语义分割的好方法？
我将不胜感激任何形式的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650900/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpn-without-the-atten</guid>
      <pubDate>Thu, 11 Jul 2024 20:00:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么 scikit-learn 梯度提升分类器的默认参数不同？（GradientBoostingClassifier 和 HistGradientBoostingClassifier）</title>
      <link>https://stats.stackexchange.com/questions/650899/why-the-different-default-parameters-for-scikit-learn-gradient-boosting-classifi</link>
      <description><![CDATA[为什么梯度提升分类器 (GradientBoostingClassifier) 和基于直方图的梯度提升分类器 (HistGradientBoostingClassifier) 在 scikit-learn 中有显著不同的默认超参数值，以及如何最好地协调这些差异？
鉴于这两个前提：

scikit-learn 设计原则包括 合理的默认值 适用于其对象
据我所知，基于直方图的梯度提升分类器在概念上与普通梯度提升分类器几乎相同，只是输入是分箱的

如果上述前提正确，我很难理解为什么默认超参数会不同。以下是两个分类器（以下称为 Gradient 和 HistGradient）之间的最大区别：



参数
渐变
HistGradient




max_depth
3
无


min_samples_le af
1
20


max_leaf_nodes
None
31


n_iter_no_change
None
10



不同的 max_depth 默认值是一个巨大的变化；Gradient 分类器的 max_depth=3 是一棵非常浅的树，而 max_depth=None 根本不限制树的深度。另一方面，HistGradient 分类器上的 min_samples_leaf 和 max_leaf_nodes 约束似乎是任意的，并且可能比根据数据限制树的深度更不合理。不同的 n_iter_no_change 默认值意味着 HistGradient 分类器默认使用提前停止，而 Gradient 分类器则不这样做。
我应该如何理解这些不同的默认值？在梯度提升方法中，是否有理论或算法上的理由来限制 max_depth 与 min_samples_leaf 与 max_leaf_nodes？
当然，我应该探索适合我的数据的最佳超参数值，但这些差异似乎违反了“合理的默认值”设计原则，同时也使得超参数搜索从截然不同的地方开始。]]></description>
      <guid>https://stats.stackexchange.com/questions/650899/why-the-different-default-parameters-for-scikit-learn-gradient-boosting-classifi</guid>
      <pubDate>Thu, 11 Jul 2024 19:40:01 GMT</pubDate>
    </item>
    <item>
      <title>如何得出 KL-UCB 老虎机的即时相关遗憾？</title>
      <link>https://stats.stackexchange.com/questions/650896/how-to-derive-instant-dependent-regret-for-kl-ucb-bandit</link>
      <description><![CDATA[我正在阅读 Lattimore 所著的 Bandit Algorithms 一书中的带有伯努利奖励的 Bandit 的 KL-UCB 算法（第 10.2 节），该算法提供的遗憾值是即时相关的，并且取决于所有臂的最优性差距。我想知道我们如何确定此算法的即时独立界限，它仅取决于臂的数量和时间范围。此外，给定 UCB 的定义，置信度是多少？
此外，无论是从理论上还是从经验上讲，该算法都是所有带有伯努利奖励的 Bandit 算法中最好的算法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650896/how-to-derive-instant-dependent-regret-for-kl-ucb-bandit</guid>
      <pubDate>Thu, 11 Jul 2024 18:36:20 GMT</pubDate>
    </item>
    <item>
      <title>比较两组间多种疾病的比例</title>
      <link>https://stats.stackexchange.com/questions/650886/compare-the-proportion-of-multiple-diseases-between-2-groups</link>
      <description><![CDATA[我正在对来自处于不同环境条件下的两组人的数据进行分析。以下是简要概述：

A 组：750 人暴露于烟雾中。
B 组：1500 人暴露于清洁空气中。
两组人均在两个不同的时间点招募，每个时间点各招募一半人。
研究中的每个人都会患上三种相互排斥的疾病之一。我的目标是确定两组之间的总体疾病比例是否存在显着差异。

我最初考虑对每种疾病进行简单的比例测试，比较 A 组和 B 组的患病率。但是，这种方法似乎是多余的，因为由于相互排斥性，组中一种疾病的患病率增加本质上会降低其他疾病的患病率。
这是我使用的代码片段：
# 加载必要的库
library(dplyr)

# 设置可重复性的种子
set.seed(123)

# 定义每个组中的个体数量
n_group_a &lt;- 750
n_group_b &lt;- 1500

# 定义招募时间点
timepoints_a &lt;- c(rep(1, n_group_a / 2), rep(2, n_group_a / 2))
timepoints_b &lt;- c(rep(1, n_group_b / 2), rep(2, n_group_b / 2))

# 定义疾病
diseases &lt;- c(&quot;DiseaseX&quot;, &quot;DiseaseY&quot;, &quot;DiseaseZ&quot;)

prob_group_a &lt;- c(0.7, 0.15, 0.15) # Disease1 在 A 组中更常见
prob_group_b &lt;- c(0.33, 0.33, 0.34) # B 组中的概率相等

# 为 A 组创建数据框
group_a &lt;- data.frame(
id = 1:n_group_a,
group = rep(&quot;A&quot;, n_group_a),
exponence = rep(&quot;smoke&quot;, n_group_a),
timepoint = timepoints_a,
disease = sample(diseases, n_group_a, replace = TRUE, prob = prob_group_a)
)

# 为 Group B 创建数据框
group_b &lt;- data.frame(
id = (n_group_a + 1):(n_group_a + n_group_b),
group = rep(&quot;B&quot;, n_group_b),
Exposure = rep(&quot;clean_air&quot;, n_group_b),
timepoint = timepoints_b,
disease = sample(diseases, n_group_b, replace = TRUE, prob = prob_group_b)
)

# 将两组合并为一个数据框
combined_data &lt;- bind_rows(group_a, group_b)

# 显示合并的数据
head(combined_data, 20) # 显示前 20 行

# 创建比例 DF
proportion_df &lt;- combined_data %&gt;%
group_by(disease, Exposure) %&gt;%
tally() %&gt;%
left_join(., combined_data %&gt;%
group_by(, Exposure) %&gt;%
tally(n = &quot;n_total&quot;)) %&gt;%
mutate(fraction = n / n_total)

# 可视化结果比例
ggplot(proportion_df, aes(x=disease,y=fraction, fill=disease))+
geom_col()+
facet_wrap(~exposure, ncol=1) + 
theme(legend.position = &quot;none&quot;)+
ylab(&quot;Fraction of disease&quot;)+
geom_text(aes(label = round(fraction,2)), vjust = -0.5, position = position_dodge(0.9), size = 3.5) +
theme_minimal() %+%
theme(legend.position = &quot;none&quot;) + 
ylim(0, max(proportion_df$fraction) * 1.15) # 调整标签空间的 y 轴限制

# 计算每种疾病的差异
pro_test_res &lt;- lapply(unique(proportion_df$disease), function(disease) {
n_success &lt;- percentage_df %&gt;%
filter(disease == !!disease) %&gt;%
pull(n)
n_total &lt;- percentage_df %&gt;%
filter(disease == !!disease) %&gt;%
pull(n_total)
res &lt;- prop.test(x = n_success, n = n_total) %&gt;%
broom::tidy() %&gt;%
mutate(disease = disease)
}) %&gt;%
bind_rows() %&gt;%
select(-c(contains(&quot;conf&quot;), &quot;method&quot;, &quot;parameter&quot;, &quot;alternative&quot;))

虽然上述方法很简单，但我觉得我缺少一种更简化的方法，可以通过一次测试抓住分析的本质。
有人对这种情况下可能更有效的统计方法有什么建议或见解吗？
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/650886/compare-the-proportion-of-multiple-diseases-between-2-groups</guid>
      <pubDate>Thu, 11 Jul 2024 15:35:40 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据中非常特殊的平台期</title>
      <link>https://stats.stackexchange.com/questions/650885/very-specific-plateaus-in-time-series-data</link>
      <description><![CDATA[我正在查看不同管道中水深的时间序列数据。有一种罕见的情况，即大量的水试图进入管道，但由于管道已满，水会流到其他地方，这是一个问题。这种情况只发生在水位比正常水平高很多的时候。考虑到这一点，我决定使用 z 分数来尝试创建一个模型来检测这种情况何时发生。我还需要能够在实时数据上检测这些。我遇到的问题是，通过今年早些时候的一场风暴中的几个例子，z 分数似乎变化很大，所以我想知道是否有办法可以缩放它，以便我可以找到一个准确的阈值来预测未来的这种情况？以下是我计算的一些可能有用的值：
名称：管道 1
所有值的平均值：1.6845702429333351
高于阈值的 z 分数的平均值：38.66435012815608
高于 z 分数阈值的值的平均值：99.30582815151514
高于阈值的计数：33
高于 95 的值的数量：23
名称：管道 2
所有值的平均值：8.057098070279554
高于阈值的 z 分数的平均值：22.411958576390177
高于 z 分数阈值的值的平均值：101.77036324675325
高于阈值的计数：77
高于 95 的值的数量： 48
名称：管道 3
所有值的平均值：2.8228191822640967
高于阈值的 z 分数的平均值：15.52506391321617
高于 z 分数阈值的值的平均值：98.46318181818182
高于阈值的计数：22
高于 95 的值的数量：23

在此示例中，我的 z 分数阈值设置为 15。如您所见，z 分数从 15 到接近 40 不等，第一个管道甚至达到超过 50 z 分数。如果该值在一段时间内很高，我想这是有道理的，但我不确定如何在模型中解释这一点。我也在寻求有关实际预测这些事件的建议，以及最好的方法是什么，或者是否只需找到一个合适的阈值即可。我是否能够根据先前的值为每个管道计算出一个好的阈值？还有许多其他管道，但这种情况的例子很少。]]></description>
      <guid>https://stats.stackexchange.com/questions/650885/very-specific-plateaus-in-time-series-data</guid>
      <pubDate>Thu, 11 Jul 2024 15:21:54 GMT</pubDate>
    </item>
    </channel>
</rss>