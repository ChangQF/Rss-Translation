<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 19 Dec 2024 12:34:44 GMT</lastBuildDate>
    <item>
      <title>我得到的部分 Mc Fadden 伪 R^2 为负数。这可能吗？</title>
      <link>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mc-faddens-pseudo-r2-is-this-possible</link>
      <description><![CDATA[对于 R 中的逻辑回归，我尝试分别计算一个预测变量的 Mc Fadden R 平方。我使用了以下代码，该代码来自这个问题：如何计算 R 中仅一个变量的 McFadden r 平方？
model1 &lt;- glm(Q22_factor ~ Q24_1 + age, family = &quot;binomial&quot;, data = subset_data&quot;)
model_age &lt;- glm(Q22_factor ~ age, family = &quot;binomial&quot;, data = subset_data)

loss_full &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model1, type = &quot;response&quot;)
)

loss_reduced &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model_age, type = &quot;response&quot;)
)
(loss_reduced - loss_full)/(loss_reduced)

在我的数据上使用此代码，我得到了负结果 (-0.269)。有人知道这是否可能，或者我的代码是否出了什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mc-faddens-pseudo-r2-is-this-possible</guid>
      <pubDate>Thu, 19 Dec 2024 12:32:24 GMT</pubDate>
    </item>
    <item>
      <title>藤蔓系动词的三维密度图</title>
      <link>https://stats.stackexchange.com/questions/658961/3d-density-plot-for-vine-copula</link>
      <description><![CDATA[有人可以分享 R 代码或命令来绘制 Vine Copula 的 3D 密度图吗？就我而言，VineCopula 包中的代码或命令仅涵盖双变量 3D 图。如何继续绘制 2 级、3 级和 4 级的 3D 密度图？]]></description>
      <guid>https://stats.stackexchange.com/questions/658961/3d-density-plot-for-vine-copula</guid>
      <pubDate>Thu, 19 Dec 2024 11:31:48 GMT</pubDate>
    </item>
    <item>
      <title>具有（非平方）L2 惩罚的正则化属性</title>
      <link>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</link>
      <description><![CDATA[我一直在寻找有关线性回归设置中 L2 范数惩罚的正则化属性的资料。我的意思是，例如，当使用 L2 范数而不是平方 L2 范数作为惩罚时的收缩属性（所以我不是在谈论岭回归）。我正在思考的问题如下：
$$
min_{\beta} \frac{1}{n}\|y - X\beta\|_2^2 + \lambda\|\beta\|_2,
$$
其中 $\beta$ 是实数向量，$X$ 是实数矩阵，$y$ 是实数向量，$\lambda$ 是正实数标量。
有谁知道关于这个问题的正则化性质的讨论好的资料吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</guid>
      <pubDate>Thu, 19 Dec 2024 11:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的线性规划优化问题</title>
      <link>https://stats.stackexchange.com/questions/658959/linear-programming-optimization-problem-in-python</link>
      <description><![CDATA[我有以下 pandas 数据框，它代表 10 个人 (ids) 7 天的消费情况（day_0 是今天，day_-1 是昨天等）：
import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randint(8, 15, size=(10, 7)))
df.columns = [&#39;day_0&#39;, &#39;day_-1&#39;, &#39;day_-2&#39;, &#39;day_-3&#39;, &#39;day_-4&#39;, &#39;day_-5&#39;, &#39;day_-6&#39;]
df.index.name = &#39;id&#39;

print(df.reset_index())

id day_0 day_-1 day_-2 day_-3 day_-4 day_-5 day_-6
0 0 10 10 14 8 14 14 14
1 1 10 13 11 11 8 10 10
2 2 10 12 9 12 9 10 10
3 3 12 12 9 11 9 12 13
4 4 12 13 8 12 8 11 9
5 5 13 9 8 13 9 12 10
6 6 8 9 8 14 8 13 14
7 7 13 10 14 12 8 9 11
8 8 8 8 10 12 11 14 14
9 9 14 13 13 9 11 14 13

我想查找每日体重（因此总共有 7 个权重：w_0、w_-1、w_-2、w_-3、w_-4、w_-5、w_-6），它们需要具有以下属性：

w_0 &gt; w_-1 &gt; w_-2 &gt; ... &gt; w_-6 &gt; 0
w_0 + w_-1 + w_-2 + ... + w_-6 = 7
10 个 ids 中 恰好 k 个的加权平均值严格高于阈值（例如 11）

我可以实现先决条件 1 和2 通过使用指数衰减函数并随后进行规范化：
import numpy as np

n = 7

_lambda = 0.5

# 使用指数衰减计算权重
weights = np.exp(-_lambda * np.arange(n))

# 对权重进行规范化，使它们的总和等于时间序列的长度
weights *= n / np.sum(weights)

但我不知道如何应用先决条件 3。
这可能吗？我如何在 python 中做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658959/linear-programming-optimization-problem-in-python</guid>
      <pubDate>Thu, 19 Dec 2024 09:21:55 GMT</pubDate>
    </item>
    <item>
      <title>X-meta 学习器和 CATE 估计器</title>
      <link>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</link>
      <description><![CDATA[在 X-learner 中，使用适当的模型估算治疗样本和对照样本（使用对照样本估算治疗样本响应，反之亦然）。
然后使用两个模型来估计 CATE，每组估算值一个模型（通常使用倾向得分组合）。我添加了从 Kunzel 等人 2019 年获得的 X-learner 伪代码。

为什么我们使用单独的 CATE 模型？为什么不将所有估算结果组合起来并拟合单个模型（例如，使用逆倾向对观察结果进行加权）。有没有探讨这个想法的作品？]]></description>
      <guid>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</guid>
      <pubDate>Thu, 19 Dec 2024 08:55:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 MERF 进行超参数调整不起作用 - fit 函数仅接受两个参数，但函数需要更多</title>
      <link>https://stats.stackexchange.com/questions/658956/hyperparameter-tuning-with-merf-doesnt-work-fit-function-only-takes-two-argume</link>
      <description><![CDATA[我正在尝试使用混合效应随机森林 (MERF) 执行嵌套交叉验证。但是，我遇到了一个问题：RandomizedSearchCV 的拟合函数仅接受两个参数（X 和 y），而 MERF 模型需要四个参数（X、Z、cluster 和 y）。
这种差异使我无法成功实施嵌套交叉验证。有人对如何修改工作流程以适应向 fit 函数传递两个以上参数有什么建议吗？
model = MERF()
search = RandomizedSearchCV(model, random_grid, n_iter=10, cv=inner_cv, refit=True,scoring = &#39;r2&#39;, n_jobs=-1,random_state=42)
result = search.fit(X= X_train, Z=Z_values_train, clusters=ID_train,y=y_train)]]></description>
      <guid>https://stats.stackexchange.com/questions/658956/hyperparameter-tuning-with-merf-doesnt-work-fit-function-only-takes-two-argume</guid>
      <pubDate>Thu, 19 Dec 2024 08:51:19 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中使用 Loess 平滑变量与其他预测因子</title>
      <link>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</link>
      <description><![CDATA[我正在运行一个普通最小二乘回归分析，其中有 9 个预测变量，2 个数值变量，5 个二进制 (1/0) 变量和 2 个分类变量。我的一个预测变量 (pred3) 与响应具有明显的非线性关系，如所附散点图所示。我拟合了一个线性模型，没有转换任何预测变量，并得到了 $R^2$ 值为 0.57。我希望我的模型具有较高的 $R^2$ 值。如果可能的话，我想避免交互项。为了解释 pred 3 和响应之间的非线性关系，我遵循了 ChatGPT 的建议，其中我拟合了一个形式为 pred3 ~ response 的 loess 平滑模型，然后在 lm() 模型语句中使用了 pred3 的 loess 预测值（参见下面的代码片段）。这导致 $R^2$ 值为 0.95。但是，我并不完全确定这是否是预测我的反应的有效方法。有人同意这个想法或有什么建议吗？我尝试过使用广义加性模型和多项式模型，但它们似乎并没有改善我的模型拟合度。请让我知道！
loess_fit=loess(pred3 ~ response,data=data)
loess_pred3=predict(loess_fit)
model=lm(response ~ pred1+pred2+loess_pred3+pred4+pred5+pred6+pred7+pred8+pred9,data=data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</guid>
      <pubDate>Thu, 19 Dec 2024 06:24:15 GMT</pubDate>
    </item>
    <item>
      <title>在处理与因子分析的 MLE 相关的函数时，如何保证结果是全局最小值？</title>
      <link>https://stats.stackexchange.com/questions/658953/how-do-we-guarantee-the-result-is-the-global-minimizer-when-dealing-a-function-r</link>
      <description><![CDATA[我正在阅读论文对最大似然因子分析的一些贡献。
考虑因子分析模型$$y=\Lambda x+z, $$
其中$y$是一个包含$p$个特征的向量，$x$是长度为$k&lt;p$的潜在因子向量。
设$z$的协方差矩阵为$\Psi$，$$\Sigma= \Lambda\Lambda&#39;+\Psi.$$
设样本协方差矩阵为$S$.
作者说，要最大化对数似然函数，只需最小化
$$ F_k(\Lambda ,\Psi) =\log|\Sigma|+\text{tr}(S\Sigma^{-1})-\log|S|-p。 $$
然后作者求解了方程$\frac{\partial F_k}{\partial \Lambda}=0$，
并得出结论，这样的$\Lambda$满足$\Psi^{-\frac 12}\Lambda$的列是$\Psi^{-\frac 12}S\Psi^{-\frac 12}$的特征向量，
并且如果我们选择这些特征向量对应于$k$个最大特征值，
则相应的$F_k$小于任何其他选择的特征向量。
作者还求解了$\frac{\partial F_k}{\partial \Psi}=0$，得到$$ \Psi= \text{diag} (S-\Lambda\Lambda&#39;) 。 $$
作者接着说，$\Lambda$和$\Psi$的最大似然估计是通过上述过程确定的对。
我的问题是，既然我们只取了梯度，我们如何保证对于给定的$\Psi$，这样的$\Lambda$不是局部最大值，
并且存在一些$\Lambda$使得$F_k$更小（例如，$F_k\to -\infty$沿某个方向）？
对于$\Psi$，我们如何确保由上述过程确定的$\Psi$不是函数$\Psi\mapsto \min F_k(\Lambda,\Psi)$的局部最大值？
作者说这是 MLE，那么我们能证明这对 $\Lambda$ 和 $\Psi$ 是 $F_k$ 的全局最小化器吗？

这篇文章 提出了一个类似的问题，但针对的是一般的 MLE。我认为答案并没有解决我的困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/658953/how-do-we-guarantee-the-result-is-the-global-minimizer-when-dealing-a-function-r</guid>
      <pubDate>Thu, 19 Dec 2024 04:36:37 GMT</pubDate>
    </item>
    <item>
      <title>当统计数据从不同角度得出完全不同的结论时，该如何决策？</title>
      <link>https://stats.stackexchange.com/questions/658948/how-to-make-decisions-when-statistics-provide-completely-different-conclusions-w</link>
      <description><![CDATA[人们可以从两个不同的角度看待统计数据，并得出两个完全相反的结论。
考虑一下家中的氡气如何导致肺癌。
危险与空气中的浓度成线性比例：

一生中接触 300 Bq/m³ 的氡气将导致千分之 15 人死亡。
一生中接触 150 Bq/m³ 的氡气将导致千分之 8 人死亡。
一生中接触 75 Bq/m³ 的氡气将导致千分之 4 人死亡。


暖通空调公司可以安装“热回收通风机”，不断更新房屋内的空气，通常将氡的环境浓度降低约 50%。
5-10 千美元，加上持续增加的供暖和制冷成本，这很昂贵，但将患肺癌的几率降低一半听起来是件好事。

将浓度从 300 减半到 150 可使存活率从 98.5% 提高到 99.2%，而将浓度从 150 减半到 75 可使存活率从 99.2% 提高到 99.6%。
花费那么多钱来将本来就很好的成功率提高不到 ½%，这似乎不值得。


这两个论点都基于完全相同的统计值，并且同样有效。
证据确凿且客观，但决定从哪个角度看待它却非常模糊且主观。
这种看似矛盾的现象有名字吗？有没有数学上合理的方法来解决它？

请注意，上述情况仅作为示例。请不要质疑它使用的数值，也不要认为它是关于氡气而不是其他因素。]]></description>
      <guid>https://stats.stackexchange.com/questions/658948/how-to-make-decisions-when-statistics-provide-completely-different-conclusions-w</guid>
      <pubDate>Thu, 19 Dec 2024 00:49:20 GMT</pubDate>
    </item>
    <item>
      <title>轻松理解混合模型中聚类变量和随机变量之间的区别</title>
      <link>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</link>
      <description><![CDATA[假设我们有一个数据集，其中我们根据社会经济地位对一系列不同学校的数学成绩分数进行建模。使用 lme4 的适当模型将是：
lmer(math~ses + (ses | school), data=d)
我的学生经常混淆 ses 和 school 的位置。为了解决这个问题，我制作了一个 YouTube 视频，帮助学生识别他们的“聚类变量”。该视频为他们提供了三条规则来帮助识别他们的聚类变量：

这个变量在您的数据集中是否经常重复出现？（聚类变量将重复）
这个变量是否识别一个人？ （如果是，那就是您的聚类变量，跳过 #3）
此变量是否表示特定组？（如果是，那就是您的聚类变量）

对于此示例，学校将被重复（该学校的每个学生一行），它不会识别特定的人，但会识别特定的组。
我对我的解释一直不太满意，因为它留下了一些歧义。让我们修改示例以使我的规则失败。假设我们正在预测数学成绩，但这次，我们想添加种族作为预测因素。合适的模型可以是：
lmer(math~ses + ethnicity + (ses + ethnicity | school), data=d)
（假设 ses 和 ethnicity 的斜率实际上因学校而异）。
这个例子的问题是学生会感到困惑，特别是如果数据集尚未按学校排序。ethnicity 和 school 都符合标准：两者都重复，都不能识别一个人，并且都表示一个“群体”。当他们问为什么 ethnicity 不是时，我有点不知道如何解释为什么 ethnicity 不是一个群体。
关于如何使差异更具体，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</guid>
      <pubDate>Wed, 18 Dec 2024 15:33:06 GMT</pubDate>
    </item>
    <item>
      <title>调整超参数以尽量减少过度拟合时的目标应该是什么？</title>
      <link>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</link>
      <description><![CDATA[我正在研究一个包含约 90k 行数据和 12 个特征的分类问题。我正在尝试调整 XGBoost 模型的超参数以尽量减少过度拟合。我使用 ROC_AUC 作为评估模型性能的指标。使用默认的 XGBoost 参数，5 倍 CV 结果分别显示训练 auc 为 0.782 和测试 auc 为 0.739。这表明过度拟合，因为训练集的表现优于测试集。
我开始调整超参数，因为 a) 应该调整，b) 已知超参数可用于减少过度拟合。但是，像许多其他人一样，我将验证 auc 设置为目标并在目标函数中实现交叉验证。使用的库是 Optuna 和 Hyperopt。有趣的是，对于这两种情况，我发现当算法试图将验证 auc 推向 0.745 时，训练测试 auc 差距（过度拟合指标）会扩大。如果我按验证 auc 降序绘制训练和验证 auc，验证 auc 会从 0.745 降至 0.729，而训练 auc 会从 0.868 降至 0.742。
我对结果感到很困惑。我将验证 auc 设置为 Optuna 优化的目标是否正确？我是否应该选择（训练 auc - 验证 auc），但我在网上没有找到类似的例子。而且我是否应该查看结果并选择最低的验证 auc 和相关的超参数值作为“最佳参数”，因为训练验证指标差距最小？
请在这里分享您的想法，因为在我输入时，我不确定我对过度拟合的理解是否正确。
我的代码：
X, y = df[features], df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 42, stratify = y)
dtrain = xgb.DMatrix(X_train, label = y_train, enable_categorical = True)
dtest = xgb.DMatrix(X_test, label = y_test, enable_categorical = True)

def objective(trial):

params = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 3, 10),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 100),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0, 2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.5, 1),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.5, 1),
&#39;reg_alpha&#39;: trial.suggest_float(&#39;reg_alpha&#39;, 1e-8, 10, log = True),
&#39;reg_lambda&#39;: trial.suggest_float(&#39;reg_lambda&#39;, 1e-8, 10, log = True),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.001, 0.3),
&#39;objective&#39;: &#39;binary:logistic&#39;}

cv_results = xgb.cv(
params, dtrain, num_boost_round = 10000, early_stopping_rounds = 50, 
metrics = &#39;auc&#39;, nfold = 5, stratified = True, shuffle = False
)

trial.set_user_attr(&#39;n_estimators&#39;, len(cv_results))
trial.set_user_attr(&#39;train-auc&#39;, cv_results[&#39;train-auc-mean&#39;].iloc[-1])

return cv_results[&#39;test-auc-mean&#39;].iloc[-1]

study = optuna.create_study(
direction =&#39;maximize&#39;, sampler = optuna.samplers.TPESampler(seed = 42))

study.optimize(objective, n_trials = 500, n_jobs = -1)


]]></description>
      <guid>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</guid>
      <pubDate>Wed, 18 Dec 2024 09:28:26 GMT</pubDate>
    </item>
    <item>
      <title>这个方程对于安全地估计下限值有何意义？</title>
      <link>https://stats.stackexchange.com/questions/658908/what-is-the-significance-of-this-equation-for-safely-estimating-a-lower-bound-va</link>
      <description><![CDATA[我遇到了一个可以安全估计某些属性下限值的公式。
$$k = N \cdot \sqrt{1+\frac{1}{n}}$$
$$X = X_m \cdot \left(1 - k \cdot \mathrm{CoV} \right)$$
其中 $N$ 是与所需分位数的标准差数，例如 $0.05$（即 z 分数），$n$ 是用于估计的样本点数，$X_m$ 是平均值值，而$\mathrm{CoV}$是变异系数。
现在，请注意，在第一个等式中，如果平方根下只有$1/n$，那么整个表达式将给出由平均值和标准误差定义的分布的$0.05$分位数——这将是平均值的安全估计。但是，加上${}+ 1,$，它应该可以给出一个安全的下限值估计值，但我无法弄清楚结果实际上代表什么。
我知道对于$n \to \infty.$，结果是整个样本或总体分布的$0.05$分位数，并且对于较少数量的观察值，z 分数会增加 - 但为什么它会增加这么多，这是怎么回事？这可能是真正的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/658908/what-is-the-significance-of-this-equation-for-safely-estimating-a-lower-bound-va</guid>
      <pubDate>Wed, 18 Dec 2024 08:43:02 GMT</pubDate>
    </item>
    <item>
      <title>逆指数分布的双变量数据生成</title>
      <link>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</link>
      <description><![CDATA[对于以下双变量逆指数分布，我必须从随机向量创建数据：$$ F_{X,Y}(x,y) =\exp({-x^{-1}-y^{-1}-\theta {(xy)}^{-1}}),0\leq\theta\leq 1, x,y&gt;0.$$ 我知道如何使用均匀随机变量（我使用 $\texttt{R}$）从单变量创建和转换数据，但我不知道如何对随机向量执行相同操作。您有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</guid>
      <pubDate>Tue, 17 Dec 2024 14:10:42 GMT</pubDate>
    </item>
    <item>
      <title>将整数矩阵的行和分布得接近泊松分布，并对列总数和非零计数进行约束</title>
      <link>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</link>
      <description><![CDATA[我遇到一种情况，我需要构建一个 $M\times N$ 矩阵，称为 $H$，表示 $M$ 个对象，这些对象可能具有 $N$ 个不同的修饰符，所有这些修饰符都可以应用于正整数数量。我知道每个修饰符都有一个指定的列总数，即 $\sum^{i\in 1:M} H_{i,j} = T_j, j\in 1:N$。还有一个二进制矩阵 $D_{i,j} \in \{1,0\}$ 表示受 $j$ 第个修饰符影响的对象，即我们知道 $H$ 中 $S_j$ 个条目的数量将非零。必然地，我们建立$S_j \leq T_j \forall j\in 1:N$，因为每个对象必须至少有一个修饰量，由$D$表示，并且该列的其余值必须为零。
我希望这个矩阵的行和大致服从泊松分布，但由于这些限制，我觉得不可能保证这是可以实现的。因此，或者，我希望有一种有效的算法能够尽可能接近地分配修饰符，使得​​从行总和的角度来看，应用的总修饰符数量大致呈指数衰减。
我相信，如果没有 $D$ 矩阵部分来限制每个修饰符的具体对象数量，那么使用每列上的多项分布（使用可选的狄利克雷先验来集中/使分布均匀）应该很容易实现这一点。有人有什么想法可以轻松实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</guid>
      <pubDate>Tue, 17 Dec 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>使用泊松分布在 R 中构建 GLM。使用“偏移量”</title>
      <link>https://stats.stackexchange.com/questions/658838/using-poisson-distribution-to-build-glm-in-r-using-offset</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658838/using-poisson-distribution-to-build-glm-in-r-using-offset</guid>
      <pubDate>Mon, 16 Dec 2024 20:55:46 GMT</pubDate>
    </item>
    </channel>
</rss>