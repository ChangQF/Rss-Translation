<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 09:17:21 GMT</lastBuildDate>
    <item>
      <title>具有约束损失变分自动编码器的词嵌入</title>
      <link>https://stats.stackexchange.com/questions/652993/word-embeddings-with-a-constrained-loss-variational-autoencoder</link>
      <description><![CDATA[我在复习有关 CBOW 和 Skip-Gram 的一些知识时有了一个想法。我想在这里发帖接受一些批评，也许还能学到一些新东西。
这个想法是使用一个基本的变分自动编码器，它一次接受一个标记作为输入 - 但有一个额外的损失函数，它表示每个标记向量表示应该是窗口内之前出现的标记的向量和（添加每个组件），即：三个之前的标记。
作为一个玩具示例，假设它将具有二维嵌入。这意味着潜在空间将有两个 z 均值的节点（最终的平均值将是我们的嵌入）。
继续这个例子，训练数据点将是电影评论数据集中的这句话：
sample_text = &quot;对于一部不受尊重的电影，肯定有很多令人难忘的名言为这部珍品列出。&quot; 

如果窗口设置为 3，则

&quot;for&quot; 没有先前的标记
&quot;a&quot; 应等于 &quot;for&quot;
&quot;movie&quot; 应为 &quot;for&quot; + &quot;a&quot;
&quot;that&quot; 应为 &quot;for&quot; + &quot;a&quot; + &quot;movie&quot;
&quot;gets&quot; 应为 &quot;a&quot; + &quot;movie&quot; + “that”，等等。

因此，对于训练句子/段落数据中的每个标记，我们在损失中有三个项：kl、重构和向量加法项​​ i, j，因为我们只有两个维度。
经过几个时期后，上述句子的图如下所示：

正如我所料，像“a”、“for”、“there”这样很常见的词将具有非常小的值，因为它们不能解释太多内容 - 但其他词如“gem”或“quotes”具有更高的值。因此，虽然约束可能非常简单，但看起来它在某种程度上是有效的。此外，可能可以通过不同的维度添加不同的约束，等等。
我很乐意听到任何意见或批评 - 或者如果有人知道任何实际的类似工作。我不是研究人员 - 只是一个爱好者。]]></description>
      <guid>https://stats.stackexchange.com/questions/652993/word-embeddings-with-a-constrained-loss-variational-autoencoder</guid>
      <pubDate>Mon, 19 Aug 2024 02:24:25 GMT</pubDate>
    </item>
    <item>
      <title>Cox 模型中时间依赖的协变量</title>
      <link>https://stats.stackexchange.com/questions/652991/time-dependent-covariates-in-cox-model</link>
      <description><![CDATA[我正在研究如何处理长期随访时的生存数据。当我进行长期随访时，Cox 模型中 HR 比例假设往往会失败，因为协变量会随时间而变化。为了处理 Cox 模型中的时间依赖性协变量，可以尝试将随访时间分成几个间隔。然后，计算每个间隔的 Cox 模型。
现在假设我有一个没有事件的间隔，可能是因为间隔太短，结果很少见。在这种情况下，我想这种策略无法应用。我说得对吗？
此外，使用这种策略我得到了许多风险比（每个间隔一个 HR），所以我必须计算总 HR。我相信这个总 HR 应该计算为时间间隔 HR 的加权平均值。每个间隔的权重是如何分配的？我找不到任何迹象。]]></description>
      <guid>https://stats.stackexchange.com/questions/652991/time-dependent-covariates-in-cox-model</guid>
      <pubDate>Mon, 19 Aug 2024 00:32:49 GMT</pubDate>
    </item>
    <item>
      <title>如果我们对 PDF 或 CDF 都不了解，是否有可能找到它们？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652988/is-it-possible-to-find-pdf-or-cdf-if-we-dont-know-about-either-of-them</link>
      <description><![CDATA[我知道 PDF 是 CDF 的导数，而 CDF 是 PDF 的反导数。但是如果我们不知道它们中的任何一个，该怎么办？那么，我们如何找到 CDF 或 PDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/652988/is-it-possible-to-find-pdf-or-cdf-if-we-dont-know-about-either-of-them</guid>
      <pubDate>Sun, 18 Aug 2024 22:32:46 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>IRLS 可以处理不平等约束吗？否则我应该使用什么？</title>
      <link>https://stats.stackexchange.com/questions/652968/can-irls-deal-with-inequallity-constrains-what-should-i-use-otherwise</link>
      <description><![CDATA[我有一组观察到的数据点$p_i = (a_i,b_i)$和一个公共常数$c$。理论上，这些点应该遵循以下方程：
$$a_i = b_i + x_1 + x_2(b_i + c)$$
我的目标是找到最小化误差的最佳$(x_1, x_2)$。 $(x_1, x_2)$ 的值受到以下约束：
$$ -w \leq x_1 \leq w$$
$$-1 \leq x_2 \leq w - 1$$
我尝试制定以下问题：
$$\min_x f(x) = \Sigma_i^{N-1} (a_i - b_i - x_1 - x_2(b_i + c))^2$$
或者
$$\min_x f(x) = \left\|\overrightarrow{\alpha} - x_1 - x_2\overrightarrow{\beta}\right\|_2^2$$
$$S.T. -w \leq x_1 \leq w$$
$$-1 \leq x_2 \leq w - 1$$
我得到的原始解决方案利用了迭代加权最小二乘 (IRLS)，忽略了约束。然而，这给了我们不可行的解决方案。
IRLS 算法是否可以适应不等式约束？否则，这个问题的最佳优化器或回归是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652968/can-irls-deal-with-inequallity-constrains-what-should-i-use-otherwise</guid>
      <pubDate>Sun, 18 Aug 2024 10:43:07 GMT</pubDate>
    </item>
    <item>
      <title>R 中的多个时间点的元分析</title>
      <link>https://stats.stackexchange.com/questions/652985/meta-analysis-of-multiple-time-points-in-r</link>
      <description><![CDATA[我有许多研究报告了患者在特定时间点测量的生理参数（平均值、标准差）。
鉴于这些数据不是独立的；在 R 中，我如何使用这些数据进行荟萃分析，以查明时间 t1 时参数的汇总值是否与 t0 时的值不同？
我尝试使用 dosresmeta 包来构建汇总线性和非线性模型；但我无法证实该包实际上适用于配对（多个时间点）数据。
我正在考虑方差分析，但我不知道如何汇总配对数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/652985/meta-analysis-of-multiple-time-points-in-r</guid>
      <pubDate>Sun, 18 Aug 2024 00:31:33 GMT</pubDate>
    </item>
    <item>
      <title>了解何时使用负二项式 GLMM</title>
      <link>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</link>
      <description><![CDATA[我有 16 只鸟（191978、191984、191977、191980、191986、201446、191983、201447、211598、211590、211595、191981、211591、201441、201445、211592）。其中有 6 只雄性和 10 只雌性。数据集名为 Gbirds_sex。我有它们重访释放地点的次数（visitIdx）。我还有（timeInside）列来显示在释放地点内的停留时间。我想在 R 中进行统计分析，看看性别是否会影响重访次数 (visitIdx) 和停留时间 (timeInside)。我不知道哪种测试效果最好，以及它的 R 代码是什么。LLM，GLM。我应该使用随机截距吗？
我试过这些：
#1
#visitIdx 是一个计数变量，因此
# 用泊松分布拟合 GLMM
library(lme4)
model_glmm &lt;- glmer(visitIdx ~ sex + (1 | id), family =
poisson(), data = Gbirds_sex)
summary(model_glmm)
#2
#residenceTime 是连续的 - 使用高斯族。
# 使用高斯响应分布和随机 
# 截距拟合每个个体的 GLMM
model_timeInside_Gaussian &lt;- lm(timeInside ~ sex, data = 
Gbirds_sex)
summary(model_timeInside_Gaussian)

但是，分散度很高 (2.8)
我现在应该使用：
library(glmmTMB)
model_glmm_nb &lt;- glmmTMB(visitIdx ~ sex + (1 | id), 
family = nbinom2(), data = Gbirds_sex)
summary(model_glmm_nb)

关于 timeInside：
首先，我运行了一个 GLM：
拟合使用高斯族对“timeInside”进行 GLM，以“性别”作为预测因子
glm_timeInside &lt;- glm(timeInside ~ sex, data = Gbirds_sex)
summary(glm_timeInside)

其次，我检查了过度分散：
residual_deviance &lt;- deviance(glm_timeInside)
df_residual &lt;- df.residual(glm_timeInside)

计算过度分散统计量
overdispersion_statistic &lt;- residual_deviance / df_residual
print(overdispersion_statistic)

第三，由于分散度较高（7），我运行了 GLMM， timeInside 作为响应变量，sex 作为固定效应，id 作为随机效应
glmm_timeInside &lt;- lmer(timeInside ~ sex + (1|id), data = Gbirds_sex)
summary(glmm_timeInside)

这不适合

边界（奇异）拟合：请参阅 help(&#39;isSingular&#39;)

下一步是准高斯 GLM 吗？它不提供 AIC 值（“NA”）可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</guid>
      <pubDate>Fri, 16 Aug 2024 03:05:07 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>计算或近似亚指数分布（即指数 rv 和的分布）的对数概率密度</title>
      <link>https://stats.stackexchange.com/questions/652713/calculating-or-approximating-the-log-probability-density-for-hypoexponential-dis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652713/calculating-or-approximating-the-log-probability-density-for-hypoexponential-dis</guid>
      <pubDate>Tue, 13 Aug 2024 12:54:25 GMT</pubDate>
    </item>
    <item>
      <title>纵向多组增长模型的不变性检验。是否需要对所有时间点进行组不变性检验？</title>
      <link>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</link>
      <description><![CDATA[我有 7 波数据，用于包含来自两个不同国家样本的构造。作为增长曲线分析的初步步骤，已经进行了纵向不变性测试，并支持部分强不变性。我的问题是，是否需要对我拥有的所有时间点进行组不变性测试？我计划在我的增长曲线模型中将国家变量指定为时间不变协变量。
此外，如果有关于需要保持“未释放”多少项目才能保持不变性的文献，那将非常有帮助。
感谢大家的支持]]></description>
      <guid>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</guid>
      <pubDate>Tue, 13 Aug 2024 09:17:42 GMT</pubDate>
    </item>
    <item>
      <title>两个样本是否来自同一个二项分布？[重复]</title>
      <link>https://stats.stackexchange.com/questions/652524/are-2-samples-from-the-same-binomial-distribution</link>
      <description><![CDATA[我有 2 个从二项分布中抽取的样本。我的零假设是 2 个样本来自同一分布。如何拒绝 p &lt; 0.05 的零假设？
具体案例：

样本 #1：n=5,665,657，k=7
样本 #2：n=7,954,069，k=6

（n 为样本大小，k 为成功次数）
我的问题因重复而被关闭，其中包含指向 3 个已回答问题的链接。这些问题很有帮助，我将总结它们如何部分回答了我最初的问题，以及它们如何没有提供完整的答案。

第一个问题（测试两个二项分布是否在统计上彼此不同）看起来确实与我的非常相似，但观察到的比例接近 0.5，而我的具体情况高度不平衡（即比例接近 0）。我不知道这是否重要。

接受的答案使用 z 检验。


第二个问题（有没有针对没有正态近似的两个二项分布的假设检验？）与我的问题类似，但它假定正态/泊松分布不是好的近似值。我不知道我的情况是否符合这一点。

可接受的答案是使用 Fisher 精确检验，但第二个答案解释说这是一个糟糕的选择（即使有效）。


第三个问题（R 中的精确两个样本比例二项式检验（和一些奇怪的 p 值））与我的类似，但样本量要小得多，观察到的比例接近 0.5。同样，我不确定这是否适合我的情况。

接受的答案支持使用 R 的 prop.test，它利用卡方检验统计量。


在我的问题评论中：

Henry 还建议使用 Barnard 检验。
kjetil 建议使用泊松近似。



我已经尝试了上面提到的所有测试。结果如下：



测试名称
Python
p 值




双尾双比例合并 z 检验
statsmodels.stats.proportion.proportions_ztest
0.370


Fisher 精确检验
scipy.stats.fisher_exact
0.408


卡方测试
scipy.stats.chi2_contingency
0.539


Barnard 测试
scipy.stats.barnard_exact
0.631


E 测试
scipy.stats.poisson_means_test
0.397



我剩下的问题是：这些测试中的哪些是无效的、有效但不是很好，或者在我的案例中可以使用（即样本非常大、非常不平衡）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652524/are-2-samples-from-the-same-binomial-distribution</guid>
      <pubDate>Fri, 09 Aug 2024 08:05:45 GMT</pubDate>
    </item>
    <item>
      <title>对 Fisher 评分算法的困惑</title>
      <link>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</link>
      <description><![CDATA[给定一个概率模型$f(X;\theta)$和一组 i.i.d.观测值$x_1,\ldots,x_n$我们假设这些观测值来自某个真实参数$f(X; \theta_0)$，我们可以使用牛顿法进行最大似然估计：
$$
\theta_{t+1} = \theta_t + \eta (\nabla^2 \ell(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
其中$\eta$表示步长，$\ell(\theta) = \sum_{i=1}^n \log f(x_i;\theta)$
另一方面另一方面，Fisher 评分算法用 Fisher 信息矩阵代替了对数似然的 Hessian，$\nabla^2 \ell(\theta)$
$$
\mathcal{I}(\theta) = - \mathbb{E}_{X \sim f(X;\theta)} \nabla^2 \ell(\theta)
$$
因此，Fisher 评分算法是
$$
\theta_{t+1} = \theta_t + \eta (\mathcal{I}(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
我的问题是：鉴于一般而言，Fisher 评分算法的迭代次数$\theta_t$ 并不接近 MLE 和真实参数 $\theta_0$，为什么 Fisher 信息矩阵 $\mathcal{I}(\theta_t) = - \mathbb{E}_{X \sim f(X;\theta_t)} \nabla^2 \ell(\theta_t)$ 是 Hessian 的合理近似值？具体而言，在我看来，对分布 $X \sim f(X;\theta_t)$ 取期望根本不会对在观测值 $x_1,\ldots,x_n \sim f(X; \theta_0)$ 处评估的对数似然的 Hessian 矩阵产生良好的估计，除非 $\theta_t$ 已经接近 MLE，从而接近真实参数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</guid>
      <pubDate>Tue, 02 Jul 2024 21:33:58 GMT</pubDate>
    </item>
    <item>
      <title>ADALINE 简单实现，有 2 个特征 bug</title>
      <link>https://stats.stackexchange.com/questions/650294/adaline-simple-implementation-with-2-features-bug</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650294/adaline-simple-implementation-with-2-features-bug</guid>
      <pubDate>Tue, 02 Jul 2024 04:23:50 GMT</pubDate>
    </item>
    <item>
      <title>梯度提升的历史</title>
      <link>https://stats.stackexchange.com/questions/648222/on-the-history-of-gradient-boosting</link>
      <description><![CDATA[我最近做了一些工作，改变了流行的梯度提升决策树 (GBDT) 以用于回归，我正致力于为现代算法建立理论基础。这里有一篇论文，我倾向于阅读 Jerome Friedman (1999) 的论文：贪婪函数近似：梯度提升机。简介中介绍了一个很好的背景知识，我找到了我认为是 GBDT 回归的通用算法，复制在此处，即算法 2。

我的问题现在变得明显了。在 for 循环中，我们有三行。第一行只是根据分阶段学习器计算直到该步骤的梯度。$h(\textbf{x},\textbf{a})$ 是参数化函数（回归树），它适合每个阶段的残差。这种拟合发生在第二行。在这一行中，参数 $\rho_m$ 也正在优化，然后在最后一步中使用它来缩放对函数 $F$ 的更新。
我解释 $\rho_m$ 的方式是我们现在在流行的 GBDT 库（如 XGBoost 或 LightGBM）中所说的学习率。$\rho_m$ 在训练开始时设置为固定值，它不会像本算法一样在每个步骤中进行优化。这是为什么？有没有重要的论文讨论为什么要进行这种简化？这个算法让我们觉得我们应该在每个阶段调整学习率，而不是保持固定。我只是想知道为什么我们似乎在现代 GBDT 实现中丢失了这个细节？]]></description>
      <guid>https://stats.stackexchange.com/questions/648222/on-the-history-of-gradient-boosting</guid>
      <pubDate>Wed, 29 May 2024 16:03:53 GMT</pubDate>
    </item>
    <item>
      <title>多头注意力和单头注意力之间的区别</title>
      <link>https://stats.stackexchange.com/questions/627229/difference-between-multi-head-and-single-head-attention</link>
      <description><![CDATA[只要梯度计算在意，注意力就是两个嵌套的张量乘法和一个 softmax。我认为，当多头注意力结束时，$h=8$ 和 $d_k=64$ 会产生与单头注意力相同的张量，$d_k = 512$ 也应用了相同的投影。以下是我在 Python 中的理由：
import torch
import torch.nn as nn
import math

deftention(query, key, value, mask=None, dropout=None):
&quot;计算‘缩放点积注意力’&quot;
d_k = query.size(-1)
scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)
if mask 不是 None:
scores = scores.masked_fill(mask == 0, -1e9)
p_attn = scores.softmax(dim=-1)
if dropout 不是 None:
p_attn = dropout(p_attn)
return torch.matmul(p_attn, value), p_attn

wq = torch.rand(512, 512)
wk = torch.rand(512, 512)
wv = torch.rand(512, 512)
class MultiHeadedAttention(nn.Module):
def __init__(self, h, d_model, dropout=0.1):
&quot;输入模型大小和heads.&quot;
super(MultiHeadedAttention, self).__init__()
assert d_model % h == 0
# 我们假设 d_v 始终等于 d_k
self.d_k = d_model // h
self.h = h
self.linears = [wq, wk, wv]
# self.linears = clones(nn.Linear(d_model, d_model), 4)
self.attn = None
self.dropout = nn.Dropout(p=dropout)

def forward(self, query, key, value, mask=None):
&quot;实现图 2&quot;
if mask is not None:
# 对所有 h heads 应用相同的 mask。
mask = mask.unsqueeze(1)
nbatches = query.size(0)

# 1) 从 d_model 批量执行所有线性投影 =&gt; h x d_k
query, key, value = [
(x @ lin).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
for lin, x in zip(self.linears, (query, key, value))
]

# 2) 对批次中的所有投影向量应用注意力。
x, self.attn =tention(
query, key, value, mask=mask, dropout=None
)

# 3) 使用视图进行“连接”并应用最终的线性。
x = (
x.transpose(1, 2)
.contiguous()
.view(nbatches, -1, self.h * self.d_k)
)
del query
del key
del value
return x

multi = MultiHeadedAttention(8, 512)
sin = MultiHeadedAttention(1, 512)

x = torch.rand(2, 10, 512)

torch.all(sin(x,x,x).eq(multi(x,x,x)))
# returns tensor(True)

如果我没有记错的话，到目前为止，多头注意力和单头注意力是等价的，那么它们的区别在哪里？我认为它们的区别在于对头部的单独优化，但我无法计算出梯度。]]></description>
      <guid>https://stats.stackexchange.com/questions/627229/difference-between-multi-head-and-single-head-attention</guid>
      <pubDate>Mon, 25 Sep 2023 10:55:18 GMT</pubDate>
    </item>
    </channel>
</rss>