<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 22 Mar 2024 21:12:24 GMT</lastBuildDate>
    <item>
      <title>灵敏度、特异性、PPV 和 NPV</title>
      <link>https://stats.stackexchange.com/questions/643293/sensitivity-specificity-ppv-and-npv</link>
      <description><![CDATA[我有一个关于计算灵敏度、特异性、PPV 和 NPV 的练习，我尝试解决该问题，但我不确定并且需要帮助。
乳腺癌自动深度学习图像分类器经过训练，可以检测乳房 X 光照片中是否存在肿瘤，并一步将其分类为良性或恶性（即乳腺癌）。经过训练和测试，在包含 1000 张乳房 X 光照片的独立数据集上进行验证，结果如下：

此外，我们知道，考虑到所有年龄段的女性，乳房 X 光检查中良性肿瘤和恶性肿瘤的患病率分别为 20% 和 2%。
-计算该分类器对于恶性肿瘤预测的敏感性、特异性、阳性预测值和阴性预测值（即将“无肿瘤”和“良性肿瘤”视为阴性）。 
考虑到这一点，我计算了以下内容，但我对 PPV 和 NPV 非常不确定。
灵敏度：TP/(TP+FN) = 22/(22+3) = 0.88
特异性：TN/(TN+FP) = 963/(963+12) = 0.988
阳性预测值：(Sen * Prev)/(Sen * Prev + (1-Sen)*(1-Prev)) = ??
阴性预测值：TN/(TN+FN) = ??]]></description>
      <guid>https://stats.stackexchange.com/questions/643293/sensitivity-specificity-ppv-and-npv</guid>
      <pubDate>Fri, 22 Mar 2024 21:07:14 GMT</pubDate>
    </item>
    <item>
      <title>分层（多级）关联的统计显着性</title>
      <link>https://stats.stackexchange.com/questions/643292/statistical-significance-of-hierarchical-multi-level-associations</link>
      <description><![CDATA[关联规则挖掘是数据挖掘中的一种常见技术，用于查找一起出现的项集在大型交易数据库中非常频繁（例如，在表 3 中我们看到在交易数据库中牛奶和面包的购买非常频繁）。
为了检查此类模式的统计显着性，我们可以生成随机数据，这意味着原假设中模式的项目之间没有关联。然后我们可以使用一些兴趣度量来计算 p 值并检查显着性。
现在，如果我们在数据中引入层次结构，其中形成模式的项目可能处于多个级别，例如，如果我们想要检查 附于此论文，我们如何检查统计数据这种模式的意义是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/643292/statistical-significance-of-hierarchical-multi-level-associations</guid>
      <pubDate>Fri, 22 Mar 2024 20:50:20 GMT</pubDate>
    </item>
    <item>
      <title>伽玛分布的充分统计量的使用</title>
      <link>https://stats.stackexchange.com/questions/643291/usage-of-sufficient-statistic-for-a-gamma-distribution</link>
      <description><![CDATA[我需要一些帮助来了解如何利用数据中的足够统计数据。
假设我观察到一些产生 $x∈X$ 的随机过程，其中所有元素都具有伽玛分布。据我了解， $X$ 的足够统计量是 $(log(x), x)$ 或 $(E[log(X)], E[X])$ 如果我要更新我对观测值的了解。
但是，如果我知道足够的统计数据，我不明白如何获取底层伽玛分布的参数化 $(a, b)$ 。对于正态分布和一些离散分布，它或多或少是清楚的，但我被困住了。]]></description>
      <guid>https://stats.stackexchange.com/questions/643291/usage-of-sufficient-statistic-for-a-gamma-distribution</guid>
      <pubDate>Fri, 22 Mar 2024 20:45:30 GMT</pubDate>
    </item>
    <item>
      <title>用于统计测试的 R 编码 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/643290/r-coding-for-statistical-test</link>
      <description><![CDATA[在 R 中对两组中位年龄数据应用 Mann Whitney 检验时，显示无法计算 p 值。请进一步指导]]></description>
      <guid>https://stats.stackexchange.com/questions/643290/r-coding-for-statistical-test</guid>
      <pubDate>Fri, 22 Mar 2024 20:35:53 GMT</pubDate>
    </item>
    <item>
      <title>估计选择加入的用户的营销贡献</title>
      <link>https://stats.stackexchange.com/questions/643289/estimating-marketing-contribution-from-opted-in-users</link>
      <description><![CDATA[我正在尝试估计营销对我们产品的使用有多大贡献，但由于同意要求，我只能收集一部分用户的数据 - 那些同意我们收集和分析他们的数据的用户营销目的。
我的问题涉及我需要多少用户同意才能对营销贡献做出任何可靠的推断，其中营销贡献定义为点击后首次使用我们产品的用户所占的百分比在营销 URL 上。我一直将其视为一个抽样问题 - 给定 99% 的置信区间和 1% 的置信区间，我需要多大的样本才能获得 3000 万用户的用户群（人口）的营销贡献的统计显着性衡量标准误差范围？ （暂时先不考虑让用户选择加入可能会引入抽样偏差的事实。）
在我们付出所有努力获得上述同意之前，我只需要一个粗略的近似值来直观地检查它是否看起来是一个可以达到的数字，所以我尝试将一些数字插入一些在线工具，但我得到的数字由于样本量太小，我不相信结果。 3000 万用户中约有 17000 名？我一定在构建这个框架的某个地方犯了错误。
样本大小是思考这个问题的错误方式吗？我应该如何考虑我需要多少选择率才能使我收集的数据足以满足分析目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/643289/estimating-marketing-contribution-from-opted-in-users</guid>
      <pubDate>Fri, 22 Mar 2024 20:15:22 GMT</pubDate>
    </item>
    <item>
      <title>SCAD惩罚具有预言性的证明说明</title>
      <link>https://stats.stackexchange.com/questions/643287/explanation-of-the-proof-that-scad-penalty-has-the-oracle-property</link>
      <description><![CDATA[我正在尝试理解SCAD具有oracle属性的证明。您能帮我解释一下并完整分解这些步骤，以便我能够理解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/643287/explanation-of-the-proof-that-scad-penalty-has-the-oracle-property</guid>
      <pubDate>Fri, 22 Mar 2024 20:03:38 GMT</pubDate>
    </item>
    <item>
      <title>网格搜索估计似然函数中的自由度参数</title>
      <link>https://stats.stackexchange.com/questions/643285/grid-search-for-estimation-of-degrees-of-freedom-parameters-in-likelihood-functi</link>
      <description><![CDATA[在下面的脚本中，出于本次练习的目的，我尝试使用具有 t-Student 边际的高斯 Copula 来估计 Apple 和 Amazon 的参数。
执行脚本时，我注意到每次迭代时 nu1 和 nu2 的估计似乎有问题，并且在输出中我似乎得到了 mu1 和 mu2 的良好估计，但是其他五个参数（sd1、sd2、nu1、nu2、和 theta）都处于其上限。因此，我怀疑我需要实现网格搜索才能正确估计 nu1 和 nu2，但是我完全不知道如何在当前脚本中实现这种估计方法。
任何帮助，将不胜感激。
**我知道我可以使用带有特殊包的简单命令来轻松适合模型，但是我宁愿尝试使用似然函数来估计模型。
#install.packages(“tseries”)
库（&#39;tseries&#39;）
#install.packages(“copula”)
库（&#39;系词&#39;）
x1 &lt;- get.hist.quote(instrument = &quot;aapl&quot;, start = &quot;2002-01-01&quot;, end = &quot;2010-01-01&quot;, quote = &quot;Close&quot;)

ret1 &lt;- 100*diff(log(as.numeric(x1$Close)))


x2 &lt;- get.hist.quote(instrument = &quot;amzn&quot;, start = &quot;2002-01-01&quot;, end = &quot;2010-01-01&quot;, quote = &quot;Close&quot;)

ret2 &lt;- 100*diff(log(as.numeric(x2$Close)))

X &lt;- cbind(ret1, ret2)

Ut &lt;- cbind(pt(X[,1], df=3),pt(X[,2], df=3.5))
Ut &lt;- pmax(pmin(Ut, 1 - 1e-7), 1e-7)

Xmeta1 &lt;- cbind(qt(Ut[,1], df=3),qt(Ut[,2], df=3.5))

就像&lt;-函数（pars）{
  
  mu1 &lt;- pars[1]
  sd1 &lt;- 参数[2]
  nu1 &lt;- pars[3]
  mu2 &lt;- pars[4]
  sd2 &lt;- 参数[5]
  nu2 &lt;- pars[6]
  θ &lt;- pars[7]
  
  llike &lt;- 矩阵(0,长度(ret1),1)
  clike &lt;- 矩阵(0,长度(ret1),1)
  llike1 &lt;- 矩阵(0,长度(ret1),1)
  llike2 &lt;- 矩阵(0,长度(ret1),1)
  
  temp &lt;- 正常 Copula(param = theta)
  
  for (t in 1:length(ret1)){
    llike1[t] &lt;- dt((ret1[t]-mu1)/sd1, df=nu1, log=TRUE)
    llike2[t] &lt;- dt((ret2[t]-mu2)/sd2, df=nu2, log=TRUE)
    u1 &lt;- pt((ret1[t]-mu1)/sd1, df=nu1)
    u2 &lt;- pt((ret2[t]-mu2)/sd2, df=nu2)
    u1 &lt;- pmax(pmin(u1, 1 - 1e-7), 1e-7)
    u2 &lt;- pmax(pmin(u2, 1 - 1e-7), 1e-7)
    clike[t] &lt;- log( dCopula(c(u1,u2),temp) )
    llike[t] &lt;- clike[t] + llike1[t] + llike2[t]
  }
  ans &lt;- sum(类似)
  打印（c（pars，ans））
  返回（答）
}

Y1 &lt;- Xmeta1[,1]
Y2 &lt;- Xmeta1[,2]

pars0 &lt;- c(平均值(Y1),sd(Y1),3,平均值(Y2),sd(Y2),3.5,cor(Y1,Y2))

temp &lt;- optim(pars0,like,method=“L-BFGS-B”,control=list(fnscale=-1),lower=c(-1,0.1,2,-1,0.1,2,- 0.98),upper=c(1,10,15,1,10,15,0.98),hessian=TRUE) # 你需要在边界中包含 &#39;df&#39;

pars1 &lt;- temp$par

Ihat &lt;- -1 * temp$hessian
SE &lt;- sqrt(diag(solve(Ihat)))

打印（第 1 部分）
]]></description>
      <guid>https://stats.stackexchange.com/questions/643285/grid-search-for-estimation-of-degrees-of-freedom-parameters-in-likelihood-functi</guid>
      <pubDate>Fri, 22 Mar 2024 19:24:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 R TAM 包，如何绘制调整标记与观察标记？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/643284/using-r-tam-package-how-can-i-plot-adjusted-marks-vs-observed-marks</link>
      <description><![CDATA[我正在 R 中使用带有 TAM 包的 Rasch 建模。我有一个多方面模型，包含近 3,000 名考生、325 名考官。分数范围为 0 - 2。
我想根据观察者分数绘制调整后的（预期？）分数，如下所示：

我已经尝试了一百万种方法，但我确信我错过了一些东西。如何计算调整后的分数（是预期分数还是预测分数）？]]></description>
      <guid>https://stats.stackexchange.com/questions/643284/using-r-tam-package-how-can-i-plot-adjusted-marks-vs-observed-marks</guid>
      <pubDate>Fri, 22 Mar 2024 19:24:02 GMT</pubDate>
    </item>
    <item>
      <title>关于精确召回率、F1 分数和准确率的问题</title>
      <link>https://stats.stackexchange.com/questions/643283/question-regarding-precsision-recall-f1-score-and-accuracy</link>
      <description><![CDATA[我一直想回答这个问题，但我真的不知道我是否正确回答了。
练习如下：
您使用查询 Q 检索了数字图书馆。数字图书馆中有 8 个与查询 Q 相关的文档，您从关联的信息检索服务中获得了以下结果集：

(*)


(*)

(*)
(*)


(*)




(*)

假设标有（*）的文档已被判断为相关。
a) 该查询的信息检索服务的 precision@10 和灵敏度（召回率）的值是多少？
我的答案是：
Precision@10：检索到的前 10 个文档中相关结果的数量
精度@10 = 5/10 = 0.5
召回率：检索到的相关文档数与检索到的相关文档数的比率数字图书馆相关文献数量
召回率 = 6/8 =0.75
b) 30% 召回率的精确度值是多少？
对此不太确定，但我的答案是：
召回率 = 0.3 # 检索到的相关文档8 # 检索到的相关文档= 2.4 ≈ 3
鉴于我们需要检索大约 3 个相关文档才能获得 30% 的召回率，这意味着根据给定的结果集，我们总共需要检索 6 个文档。因此，我们追求 Precision@6，可以计算为：
精度@6 = 3/6 = 0.5
c) 您已使用 4 个查询测试了该服务，Q1…Q4，并获得了以下结果（精确度、召回率）：Q1：(52%, 40%)； Q2：（33%，90%）；第三季度：（100%，20%），第四季度：（20%，80%）。计算该系统的 F1 和 Accuracy 值（如果找不到其中任何一个，请解释原因）。
这里我尝试根据公式计算每个查询的F1分数，然后我考虑计算这些分数的平均值以获得系统的F1分数。那是对的吗？另外，关于准确性，我认为我没有足够的信息来计算它。我的假设正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/643283/question-regarding-precsision-recall-f1-score-and-accuracy</guid>
      <pubDate>Fri, 22 Mar 2024 19:01:06 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的 gls() 对象计算拟合值</title>
      <link>https://stats.stackexchange.com/questions/643282/calculating-the-fitted-values-from-a-gls-object-in-r</link>
      <description><![CDATA[我创建了一个 gls() 对象来创建具有 AR(1) 误差的线性模型。从所有迹象来看，该模型非常适合数据，并且生成的模型似乎符合假设。但是，当我从模型中调用 $fitted 时，拟合值根本不是很准确，事实上，当我的响应具有 [55,68] 中的值时，它们都包含在 [61,62] 中。我做了一些研究，并且对计算拟合值的公式有相互矛盾的陈述，因此想知道是否有人遇到同样的问题或可以帮助澄清计算拟合值背后的理论？
这是我的具体代码，
gls1 &lt;- gls(体重 ~ ., 数据 = 患者数据, 相关性 = corAR1())
]]></description>
      <guid>https://stats.stackexchange.com/questions/643282/calculating-the-fitted-values-from-a-gls-object-in-r</guid>
      <pubDate>Fri, 22 Mar 2024 18:53:37 GMT</pubDate>
    </item>
    <item>
      <title>推导 AR(1)-GARCH(1,1) 无条件矩</title>
      <link>https://stats.stackexchange.com/questions/643280/deriving-ar1-garch1-1-unconditional-moments</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/643280/deriving-ar1-garch1-1-unconditional-moments</guid>
      <pubDate>Fri, 22 Mar 2024 18:33:01 GMT</pubDate>
    </item>
    <item>
      <title>卡方用于演示逻辑回归中的混杂（或不是......）</title>
      <link>https://stats.stackexchange.com/questions/643278/chi-squared-for-demonstrating-confounding-in-logistic-regression-or-not</link>
      <description><![CDATA[我使用逻辑回归进行推理和分类，使用来自 190 个 X 射线/受试者的数据。我们想看看某些 X 射线测量是否可以预测以后疾病的发展（病例与对照）。
我想了解混杂因素对我的逻辑回归预测的影响。
我有一个重要的已知混杂因素：X 射线捕获期间患者的位置（坐/站，0,1）。由于这是临床回顾性数据*，因此谁坐着/站着存在一定的随机性。但对于坐着进行更多 X 光检查的病例存在明显的偏见：
&lt;前&gt;&lt;代码&gt; 控制案例
坐着：13.16% 48.42%
站立 25.26% 13.16%

我知道我的一些（不是全部）测量结果非常受坐/站条件的影响。
为了更好地演示坐/站的混杂效应，我获得了数据的预测类别。然后，我为每个样本获取了一个关于预测是正确 (1) 还是错误 (0) 的二进制变量。
我想，我可以通过卡方测试来查看与混杂因素（坐/站）之间的关系，因为正确/不正确 + 坐/站都是二元的：
单变量 LogReg--&gt;预测---&gt;卡方（预测正确/不正确〜坐/站）---&gt; P值
使用 X 射线进行测试测量值我知道与坐/站密切相关（测量值 1）会生成非常小的卡方 P 值。我将其解释为坐/站对模型预测的影响。
同样，使用我们知道不受坐/站 (measurement_22) 影响的 X 射线特征，会生成较大的 P 值：
&lt;前&gt;&lt;代码&gt;XR-测量_1 XR-测量_22
卡方 p 值：0.0002 卡方 p 值：0.21
卡方统计量：13.44 13.47 卡方统计量：0.65

&lt;小时/&gt;
这是我想到的一个主意。所以它不可能很好......但是，我正在努力寻找方法来推断我的预测是如何被混淆的。我觉得尝试查看正确和错误分类样本的属性可以帮助我了解“坐/站”位置混淆了我的 X 射线测量结果。
我认为该模型很难处理站立的案例（因为 2/3 的案例是坐着的）

这是一种不必要的复杂演示方式吗？
混淆？
它是否表现出了混淆？
有更好的工具来探索这个问题吗？
这是一条死胡同吗？我应该完成“David Hosmer JR 的应用逻辑回归”。**

*我们正在研究一种罕见疾病...我们不太可能前瞻性地收集数据。因此，坐/站问题不太可能消失。
**我正在慢慢地学习：David Hosmer JR 的《应用逻辑回归》。但到目前为止，我刚刚读到了使用系数/比值比/模型摘要进行混杂观察的内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/643278/chi-squared-for-demonstrating-confounding-in-logistic-regression-or-not</guid>
      <pubDate>Fri, 22 Mar 2024 18:21:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么条件 VAE 需要调节编码器</title>
      <link>https://stats.stackexchange.com/questions/643276/why-conditional-vae-require-conditioning-of-the-encoder</link>
      <description><![CDATA[查看这篇博文以及许多其他文章， cVAE 看起来像这样：

现在，我的问题是......为什么我们需要编码器级别的标签？显然，信息已经在图像内部，因此我们不需要告诉网络第二部分，我的意思是，对我来说，这似乎是
$$
l_{enc} \perp\!\!\!\!\perp y | X
$$
&lt;小时/&gt;
更新：
我发现这篇论文他们说您实际上训练了 3 个组件（$p(x|z,y)$、$p(z|x)$&lt; /span&gt; 和 $q(z|x,y)$)，最终，他们实际上设置了 $p(z|x) = q(z|x,y)$...所以看起来编码器实际上并不以标签为条件]]></description>
      <guid>https://stats.stackexchange.com/questions/643276/why-conditional-vae-require-conditioning-of-the-encoder</guid>
      <pubDate>Fri, 22 Mar 2024 17:15:13 GMT</pubDate>
    </item>
    <item>
      <title>找到 $\theta$ 的二维充分统计量</title>
      <link>https://stats.stackexchange.com/questions/643275/find-a-two-dimensional-sufficient-statistic-for-theta</link>
      <description><![CDATA[设 $\{X_i\}_{i=1}^n$ 是条件独立的，给定 $\theta $ 与分配
$$p_{X_i | \theta} (x |\theta) = \frac{1}{2i\theta}, \ -i\theta
找到 $\theta.$ 的二维充分统计量
尝试使用因式分解定理解决：
$$p_{X | \theta} = \prod_{i=1}^{n}\frac{1}{2i\theta}1_{x_i &gt; -i\theta} 1_{x_i &lt; i\theta} = \frac{1}{(2i\theta)^n} 1_{\min(x_i) &gt; -i\theta} 1_{\max(x_i) &lt; i\theta}$$
所以我们可以选择 $T(x) = \big(T_1(x), T_2(x)\big) = \big(\min(x_i), \max (x_i)\big) $ 和 $g\big(\theta, T_1(x), T_2(x)\big) = \frac{1}{( 2i\theta)^n} 1_{T_1 &gt; -i\theta} 1_{T_2 &lt; i\theta}$.
根据因式分解定理，$T(x)$ 应该是一个足够的二维统计量，对吗？
通过关于充分统计量维度的旁注，我们总是可以简单地增加维度，例如通过说 $T_n(x) = 1$ 和乘以它？另一方面，我们不能将维度减少到某个点吗？在这个例子中，二维统计是我们可以达到的最低值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/643275/find-a-two-dimensional-sufficient-statistic-for-theta</guid>
      <pubDate>Fri, 22 Mar 2024 16:56:42 GMT</pubDate>
    </item>
    <item>
      <title>对一组进行费舍尔精确检验的模拟？</title>
      <link>https://stats.stackexchange.com/questions/643272/analogue-of-fishers-exact-test-for-one-group</link>
      <description><![CDATA[我了解费舍尔精确检验适用于测试一组结果的比例 $p_1$ 是否与另一组的结果比例不同，$p_2$。这可能类似于第 1 组的药物功效与第 2 组的药物功效。
是否有一个类似物可以测试同一组的 $p_1$ 与 $p_2$ ？我想到的设置是你有两个分类器对同一组进行预测，分类器 1 的精度为 $p_1$，分类器 2 的精度为 $p_2$。假设分类器 1 从 $n$ 个样本中获得了 $k_1$，分类器 2 获得了 $k_2$ 来自相同的 $n$ 样本，我们如何测试是否 $p_1&gt; p_2$ 类似于 Fisher 精确检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/643272/analogue-of-fishers-exact-test-for-one-group</guid>
      <pubDate>Fri, 22 Mar 2024 16:17:52 GMT</pubDate>
    </item>
    </channel>
</rss>