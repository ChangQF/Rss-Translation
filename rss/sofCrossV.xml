<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Jun 2024 09:16:07 GMT</lastBuildDate>
    <item>
      <title>样本量。配对 T 检验和重复性</title>
      <link>https://stats.stackexchange.com/questions/648524/sample-size-paired-t-test-and-repeatability</link>
      <description><![CDATA[这项研究涉及 10 名受试者，我们用 4 只不同的鞋子测量速度，测量重复 4 次，在室内和室外两个不同的跑道上进行。
一方面，我们只关心报告室内和室外所有测量结果是否存在差异。这就是我理解它是配对 T 检验的原因。这样对吗？
在这种情况下，您如何计算样本量？我理解在这种情况下样本量等于 160，10 x 4 x 4。
此外，我应该如何计算可重复性的样本量？也就是说，如果我有 10 名受试者，因为他们用 4 只鞋子重复测量，那么实际上样本量将是 40，重复测量将是 4，对吗？对于这 40 个样本，到底需要重复多少次？
我见过一些关于受试者内标准差的乏味 Altman 论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/648524/sample-size-paired-t-test-and-repeatability</guid>
      <pubDate>Mon, 03 Jun 2024 08:24:42 GMT</pubDate>
    </item>
    <item>
      <title>PCA 应用于非线性数据</title>
      <link>https://stats.stackexchange.com/questions/648520/pca-applied-to-non-linear-data</link>
      <description><![CDATA[假设我将标准主成分分析应用于数据，其中观察到的变量是因子的非线性函数。也就是说，我有一个面板变量$Y_{i} \in \mathbb{R}^{N_{Y}} $，对于因子$X_i \in \mathbb{R}^{N_{X}}$和$N_{X} &lt; N_Y$，它可以表示为$Y_{i}=g(X_i)$。有没有关于此类问题的文献？例如，一些高斯-马尔可夫类型的结果，以便$N$第一个主成分给出最佳线性$N$因子近似？]]></description>
      <guid>https://stats.stackexchange.com/questions/648520/pca-applied-to-non-linear-data</guid>
      <pubDate>Mon, 03 Jun 2024 06:29:39 GMT</pubDate>
    </item>
    <item>
      <title>基于伯努利（p）样本的无偏估计量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648518/unbiased-estimator-based-on-a-sample-from-bernoullip</link>
      <description><![CDATA[设 X1、X2、X3、...... Xn 为服从 Ber(p) 的总体中的随机样本。给出 (1+p)^n 的无偏估计量。
提示：
(1+p)^n = C0 + C1.p + C2.p^2 + C3.p^3 ........ Cn.p^n，
且 p 的估计量为均值（Xi 的估计量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648518/unbiased-estimator-based-on-a-sample-from-bernoullip</guid>
      <pubDate>Mon, 03 Jun 2024 05:52:17 GMT</pubDate>
    </item>
    <item>
      <title>根据训练数据，惩罚 Ridge/Lasso 回归中的斜率是否会产生不利影响？</title>
      <link>https://stats.stackexchange.com/questions/648515/does-penalizing-the-slope-in-ridge-lasso-regression-has-adverse-effect-based-on</link>
      <description><![CDATA[我刚刚开始学习岭回归和套索回归（通过这个 YouTube 视频）。据我所知，这些回归类似于线性回归，但我们通过系数$\lambda$惩罚较高的斜率以减少过度拟合。对于双变量情况，我们希望通过岭回归最小化$\sum_{i=1}^n(y_i-\hat y)^2+\lambda(\text{slope of the line})^2$。
但让我们假设在下图中，红色圆圈是我的训练数据，蓝色圆圈是我的测试数据。假设在惩罚斜率之后，最佳拟合线是绿线，这样线性模型的性能就会变差。（另一方面，如果蓝色圆圈是训练数据，则拟合线会减少过度拟合问题）。我想知道在这种情况下 Ridge（或 Lasso 回归）如何减少过度拟合，因为降低斜率会导致直线拟合不良。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648515/does-penalizing-the-slope-in-ridge-lasso-regression-has-adverse-effect-based-on</guid>
      <pubDate>Mon, 03 Jun 2024 04:38:56 GMT</pubDate>
    </item>
    <item>
      <title>负二项模型中的有偏 MLE</title>
      <link>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</link>
      <description><![CDATA[我发现负二项模型的最大似然参数是有偏差的。下面提供了一个示例代码。这是正常的吗？有没有办法获得无偏估计？
&gt; set.seed(3)
&gt; z &lt;- 2
&gt; a &lt;- 100
&gt; b &lt;- 100
&gt; theta &lt;- 15
&gt; 
&gt; negloglik &lt;- function(p,x,y){
+ if(any(p&lt;=0)) return(NA)
+ a &lt;- p[1]
+ b &lt;- p[2]
+ z &lt;- p[3]
+ theta &lt;- p[4]
+ -sum(dnbinom(y,mu=(a*x^z)/(b+x^z),size=theta,log=T))
+ }
&gt; 
&gt; nsim &lt;- 1000
&gt; ppp &lt;- matrix(NA,nsim,4)
&gt; for(i in 1:nsim){
+ x &lt;- round(rep(seq(3,30,by=5),each=5))
+ y &lt;- rnbinom(length(x),mu=((a*x^z)/(b+x^z)),size=theta)
+ ppp[i,] &lt;- optim(c(a,b,z,theta),negloglik,x=x,y=y)$par
+ }
&gt; 
&gt; # MLE（预期）
&gt; apply(ppp,2,mean)
[1] 105.135854 123.325672 2.054681 19.150245
&gt; 
&gt; # 偏差
&gt; apply(ppp,2,mean)-c(a,b,z,theta)
[1] 5.13585361 23.32567187 0.05468069 4.15024470
]]></description>
      <guid>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</guid>
      <pubDate>Mon, 03 Jun 2024 04:32:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PySpark `BinaryClasssificationEvaluator` 指标 `areaUnderROC` 在同一数据集上的多次评估中返回的结果略有不同？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648513/why-pyspark-binaryclasssificationevaluator-metric-areaunderroc-returns-sligh</link>
      <description><![CDATA[我在 Pyspark 中使用 BinaryClasssificationEvaluator 来计算 AUC，但是我发现对同一数据集进行多次评估后返回的 auc 不同（在相同的开发环境下，只需在 jupyter 中多次单击此单元格即可）。这意味着，我无法保证结果的重复性。
由于隐私问题，我无法发布数据集 data_sample_full_w_target_subexample_pd 的内容，但它的形状是 234225，其中“bad”为 0/1，“probability”为是 [0, 1] 内的双精度数。
以下是代码
从 pyspark.ml.evaluation 导入 BinaryClassificationEvaluator
从 pyspark.ml.classification 导入 RandomForestClassifier
从 pyspark.ml.feature 导入 VectorAssembler

导入 pyspark.sql.functions 作为 F
导入 pyspark.sql.types 作为 T

# 假设我有一个 pandas 数据框 `data_sample_full_w_target_subexample_pd`，其中列“bad”是 y_true 和“prob”是 y_pred 概率

# 对其进行排序以避免排名不确定性
data_sample_full_w_target_subexample_pd_sorted = data_sample_full_w_target_subexample_pd[[&quot;bad&quot;, &quot;prob&quot;]].sort_values(by=[&quot;prob&quot;, &quot;bad&quot;], accending=[False, True])

# pyspark 计算 auc
prediction = spark.createDataFrame(data_sample_full_w_target_subexample_pd_sorted)
prediction = prediction.withColumnRenamed(&quot;bad&quot;,&quot;label&quot;)

evaluator = BinaryClassificationEvaluator(
labelCol=&quot;label&quot;, 
metricName=&quot;areaUnderROC&quot;)
evaluator.setRawPredictionCol(&quot;prob&quot;)
areaUnderROC = evaluator.evaluate(prediction)

# pandas 计算 auc
# RF_pred = prediction.select(&#39;label&#39;, &#39;prob&#39;).toPandas()
RF_pred = prediction.toPandas() 
probRF=[]
for i in range(prediction.count()):
probRF.append(RF_pred[&#39;prob&#39;][i]) # 它只取标签 1 的概率 

auc = roc_auc_score(RF_pred[&#39;label&#39;], probRF) # 这将始终返回 0.9683804033270174

# auc 和 areaUnderROC 应该相同！
print(areaUnderROC)
print(auc)


但是，无论我运行多少次，pandas 版本都可以产生相同的 auc 结果。
我相信 BinaryClassificationEvaluator 一定发生了什么，但从其文档来看，其参数中没有提到随机性。
有什么见解吗？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648513/why-pyspark-binaryclasssificationevaluator-metric-areaunderroc-returns-sligh</guid>
      <pubDate>Mon, 03 Jun 2024 04:31:18 GMT</pubDate>
    </item>
    <item>
      <title>拟合超几何分布需要非整数参数吗？</title>
      <link>https://stats.stackexchange.com/questions/648512/fitting-hypergeometric-distribution-requires-non-integer-arguments</link>
      <description><![CDATA[我有一个观测向量（长度为 s），x 为类“0”，s-x 为类“1”，它们来自大小为 N 的总体。因此，它们遵循超几何分布：
$$H(x| p,s,N) = \frac{ {pN \choose x} {N-pN \choose s-x} }{ {N \choose s} }$$
我对这个向量进行子采样（使用 $j$ 刀切间隔）以获得比例直方图（$O$），其中箱体 $x \in [0, js]$ 与频率相关。人口规模$N$和比例$p$未知，我需要根据观察结果推断它们。
为了解决这个问题，我想使用最小二乘法拟合超几何分布直方图（$O$）。我计划使用 Newton-Raphson (NR) 方法来查找 $p$ 和 $N$ 的值，以使 $L = \sum_x (O-H)^2$ 最小化。
我的理由是，我需要使用具有非整数参数的二项式系数，使用有限差分以数值方式计算 $L$ 的导数，但我发现这会导致 $H$ 出现负值。
请给我一些反馈。这种方法是否正确，或者我应该如何推断 $N$ 和 $p$ 的值？我正在研究别人的工作，所以我无法选择彻底改变方法（即我不能使用贝叶斯推理）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648512/fitting-hypergeometric-distribution-requires-non-integer-arguments</guid>
      <pubDate>Mon, 03 Jun 2024 03:01:20 GMT</pubDate>
    </item>
    <item>
      <title>Scipy 的高斯 KDE 积分令人困惑[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648510/scipys-gaussian-kde-integration-is-confusing</link>
      <description><![CDATA[这是一个简单的问题，但我需要澄清。
在Scipy Docs中，用于积分多元高斯 KDE 的函数有一个可选参数，表示最大点数，默认值为 None。
那么...默认情况下，它实际上使用多少个点进行积分？这是否取决于拟合数据的大小和形状，即这是否以某种方式作为准确度和运行时间之间的权衡而进行了优化？
当您声明最大点数时，这是每个维度的点数还是总数的点数，即如果它是二维分布，10,000 个点是否意味着它在 100x100 或 10,000x10,000 网格上积分？]]></description>
      <guid>https://stats.stackexchange.com/questions/648510/scipys-gaussian-kde-integration-is-confusing</guid>
      <pubDate>Mon, 03 Jun 2024 01:42:19 GMT</pubDate>
    </item>
    <item>
      <title>如何用 R 语言对评级数据进行（线性）混合效应模型的拟合和诊断</title>
      <link>https://stats.stackexchange.com/questions/648507/how-to-fit-and-perform-diagnostics-for-linear-mixed-effects-models-on-rating-d</link>
      <description><![CDATA[我进行了一项实验，其中 143 名测试对象（访谈）对 20 个刺激集（刺激）进行评分，评分范围从 0 到 100。从 80 个刺激集（分为两个类别，轴心国和同盟国，每个类别抽取 10 个）中随机抽取每个参与者的刺激集。首先在短时间曝光（Gist）条件下呈现并评分该组刺激，然后在长时间曝光（LE）条件下获得第二组评分。综上所述，我们让不同的受试者对不同的刺激集进行评分，每个受试者对每个刺激进行两次评分。
两种观看条件的评分分别记录在两个单独的列中，RatingGist 和 RatingLE，第三列为 RatingDELTA，其中添加了从 -100 到 +100 的刻度，表示受试者对同一刺激的 LE 和 Gist 评分之间的差异。
除了评分之外，我的数据集还包含在参与者级别（Sex、PolNum）和刺激级别（Semiotics）记录的其他变量，其中 PolNum 是参与者的政治倾向，以连续的左右刻度（-3 到 +3）记录，而符号学（虚拟编码）表示政治符号在给定的刺激中是否可见。
我的目标是调查政治倾向、刺激类别和图像内容是否可用于预测长时间曝光下的收视率和/或观看条件之间的收视率变化 (RatingDELTA)。
我的想法是拟合三个独立的模型：

RatingLE 作为因变量，RatingGist 作为基线

RatingDELTA 作为因变量，RatingGist 作为基线

RatingGist 作为因变量，假设在短时间曝光下，不会从刺激中提取政治信息，并且可能根据语义内容改变图像感知的认知过程不会启动。


现在，在拟合 LMM 方面，我首先定义我的随机效应结构并拟合一个没有固定效应预测因子的零模型：
delta_0 &lt;- lmer(RatingDELTA ~ 1 + (1 |访谈) + (1 | 刺激)

LE_0 &lt;- lmer(RatingLE ~ 1 + (1 | 访谈) + (1 | 刺激)

Gist_0 &lt;- lmer(RatingGist ~ 1 + (1 | 访谈) + (1 | 刺激)

然后我继续逐步添加固定效应，一次添加一个预测因子，在迭代之间比较拟合指数 (AIC、对数似然和伪$R^2$)，直到我得到现在的完整模型：
delta_6 &lt;- lmer(RatingDELTA ~ RatingGist + PolNum*Publisher + Sex + Semiotics*PolNum + (1 + RatingGist + Publisher | 访谈) + (1 | 刺激), data = dfx, REML = FALSE)

LE_6 &lt;- lmer(RatingLE ~ RatingGist + PolNum*Publisher + Sex + Semiotics*PolNum + (1 + RatingGist + Publisher | Interview) + (1 | Stimulus), data = dfx, REML = FALSE)

（我在这里省略了 Gist 模型，因为之前使用的任何预测因子都没有改善该模型 - 但是，对于具有转换后的 DV（重新缩放为 0.0001–0.9999）和 beta-link 函数的 GLMM，它们确实改善了模型）。
每个预测因子和交互项的包含都显著改善了 LE 和 Delta 模型的拟合度，但我很难确定模型是否首先正确指定。我一直在使用 DHARMa 进行诊断，但我根本没有统计知识，也没有充分评估它们的经验（delta_6 模型的残差诊断图如下所示）。

首先，我不确定 LMM 是否可以直接拟合评级本身，因为它们的尺度是双重边界的，而且残差图中确实似乎存在轻微的模式（如下所示）。

我曾使用 glmmTMB 尝试过 Gist 和 LE 模型的 beta 混合回归和零膨胀 beta 混合回归模型，但我不知道如何正确设置 DHARMa 来运行诊断以及要查找什么。
如果有人能为我的 LMM 推荐一种全面的诊断策略，以及如何在 LMM 或具有特定链接函数的 GLMM 之间做出选择，我将不胜感激。如果需要，我也可以提供原始数据，尽管超过 2000 个观测值，数据量还是有点大。]]></description>
      <guid>https://stats.stackexchange.com/questions/648507/how-to-fit-and-perform-diagnostics-for-linear-mixed-effects-models-on-rating-d</guid>
      <pubDate>Mon, 03 Jun 2024 01:13:39 GMT</pubDate>
    </item>
    <item>
      <title>比例变量与分类变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/648502/correlation-between-proportion-variable-and-categorical-variable</link>
      <description><![CDATA[我有兴趣测试流感活动与不同时期（不同年代）之间的相关性。变量流感活动是两个变量的组合：ILI 比例（ILI 病例/总人口）$\times$实验室阳性率（阳性样本/总样本）。因此，它是两个比例的乘积。变量时期是分类的（时期 A、时期 B 和时期 C）。此外，流感活动不是正态分布的，即使其因子在本质上是成比例的，但它们加起来也不等于一。考虑到这些数据的性质，我想知道哪种相关性测试最合适：Spearman rho？Kendall tau？拟泊松回归？OLS 回归？
我是统计学的初学者，因此很感谢您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/648502/correlation-between-proportion-variable-and-categorical-variable</guid>
      <pubDate>Sun, 02 Jun 2024 21:38:14 GMT</pubDate>
    </item>
    <item>
      <title>安德森·达林假设检验是如何建立的？</title>
      <link>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</link>
      <description><![CDATA[我想知道 Anderson Darling 检验背后的假设检验是什么。我知道 H0 表示数据服从分布，H1 表示数据不服从分布。但它在数学上如何写？我猜它使用 A2 值，例如 H0：$A^2 = 0$ 和 H1：$A^2 \gtrless 0$。这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</guid>
      <pubDate>Sun, 02 Jun 2024 20:41:07 GMT</pubDate>
    </item>
    <item>
      <title>根据胜率和游戏数量计算启发式</title>
      <link>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</link>
      <description><![CDATA[我需要根据玩家的表现（以游戏数量和这些游戏的胜率表示）对大量玩家（MOBA 游戏）进行排序。
我使用简单的阈值根据胜率减少了初始玩家组，但玩家仍然太多，所以我需要通过消除“幸运”玩家来找到精英中的精英。玩家（那些胜率高但比赛场次不足以证明他们是促成胜利的主要因素的玩家）。
在这个阶段我不想再使用阈值了，因为我觉得既然我的列表中的玩家现在变少了，他们的排序现在应该是相关的，以便找到精英中的精英。
这是一个真实的样本，用来说明我正在处理的数据类型：

我试过$winrate\times \text{log}(games)$，但即使它对极端值有效（成功将（38, 92）放在顶部，但放置得太多了较低（50, 83）。
直观地说，我会说我正在寻找的启发式方法表明，上一个例子中的最佳球员是（38, 92），（50, 83），（18, 95）......我想你看到了模式。
说到模式，我也试图自己对它们进行排名，以便能够为每个“级别”的表现绘制“回归”线，但最终我变得更加困惑，因为我最终得到了一个非常针对问题的解决方案，因为它适合这组特定的数据点，而我不知道如何概括它。
我不是在这个领域工作，所以我不习惯那种东西，因此自己找不到解决方案，但我想我至少可以理解它，所以如果你有任何关于此类场景的已知技术的参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</guid>
      <pubDate>Sun, 02 Jun 2024 19:05:28 GMT</pubDate>
    </item>
    <item>
      <title>如果 $T\gg N$，则 $O_p(N^{-1/2}) + O_p(T^{-1/2}) = O_p(N^{-1/2})$ 的数学推导 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/648485/mathematical-derivation-of-why-o-pn-1-2-o-pt-1-2-o-pn-1-2-i</link>
      <description><![CDATA[我会尽量简单。假设我们有一系列随机变量，$X_{NT}$，其边界表达式为：$X_{NT} = O_p(N^{-1/2}) + O_p(T^{-1/2})$。现在，这意味着如果 $T\gg N$，则 $X_{NT} = O_p(N^{-1/2})$，因为在这种情况下，$N^{-1/2}$ 占主导地位。使用$O_p(\cdot)$的定义，我们可以看到，对于每个$\varepsilon&gt;0$，存在一个常数$M$和$N_0$，使得
$$ P\left( \left|\frac{X_{NT}}{N^{-1/2} + T^{-1/2}} \right| &gt; M \right) &lt; \varepsilon $$
对于 $NT\geq N_0.$ 如果我犯了错误，请纠正我。
一般来说，这意味着 $O_p(N^{-1/2}) + O_p(T^{-1/2}) = O_p(C^{-1}_{NT})$，其中 $C_{NT} = \min(\sqrt{T},\sqrt{N}).$
你能更严格地向我展示这一点吗？如果你能从概念上解释一下，我将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648485/mathematical-derivation-of-why-o-pn-1-2-o-pt-1-2-o-pn-1-2-i</guid>
      <pubDate>Sun, 02 Jun 2024 16:54:29 GMT</pubDate>
    </item>
    <item>
      <title>如何规范化以“最大值”为未知数的自定义范围？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</link>
      <description><![CDATA[要对范围进行规范化，我们应用以下变换：
$$
\frac{x_i - \min(x)}{\max(x) - \min(x)}
$$
要将规范化调整为首选范围，其中 b=max_target 和 a=min_target：
$$
\text{norm}_i \cdot (b - a) + a
$$
如果我们希望调整后的规范化数组的总和等于 1，b 将是一个未知数，可通过以下方式求解：
$$
\left( \frac{1 - n \cdot a}{\sum \text{norm}_i} \right) + a
$$
但是，当 n &gt; 9 时，查找 b 会失败。例如，假设我想规范化一个分布，其中 b=x 和 a=0.1：



标签
频率
adj_norm




1
7
0.35


2
10
0.55


3
3
0.10






标签
频率
adj_norm




1
7
0.09...


2
&lt; td&gt;10
0.08...


3
3
0.09...


4
5
0.09...


5
9
0.08... 


6
4
0.09...


7
6
0.09...


8
8
0.08...


9 
1
0.10


10
2
0.09...


11
20
0.07...



请注意，在第一个表中，频率最低的标签被正确识别为最小值，而频率最高的标签具有正确的最大值，使得数组等于 1。但是，在第二个表中，最大值被错误分类...
关于如何更正 n &gt; 9 的公式，您有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</guid>
      <pubDate>Sun, 02 Jun 2024 06:14:01 GMT</pubDate>
    </item>
    <item>
      <title>中位数的平均值始终不同于中位数</title>
      <link>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</link>
      <description><![CDATA[免责声明：这是我的第一个问题。
问题背景：
我想比较两个分布（n1 ~ 500 和 n2 ~ 700），它们不是正态分布，方差也不同，但大致是单峰分布。我决定使用中位数进行比较统计。
使用（scipy 的）置换检验，我得到了两个中位数观察到的差异的 p 值。使用同样生成的零假设分布，我也能够得到实验的最小可检测效果。
我想估计观察到的差异（中位数）的误差（-&gt; 用于绘图的误差线）。所以我使用 np.random.choice 绘制两个具有相同大小的新分布并重复/替换；但不混合组（即假设效果/观察到的差异是真实的）。我计算了两个新分布的中位数差，并重复了 100000 次。
问题
在所有这些实现中，我计算了平均值和标准差，发现平均值（中位数差）与原始数据中位数差相比始终相差约 13%。
这是错误、测试设计错误还是实际可能的结果？如果是最后一个，为什么？这意味着什么？
代码
# 原始实验数据：A、B
# 绘制新的分布 a、b，不进行混合
a = np.random.choice(A, (100000, len(A), True) 
b = np.random.choice(B, (100000, len(B), True)
med_m = np.mean(np.median(a, axis = 1) - np.median(b, axis = 1))
med_s = np.std(np.median(a, axis = 1) - np.median(b, axis = 1))
med = np.median(A) - np.median(B)

med_m / med
&gt;&gt;&gt; 1.13...
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</guid>
      <pubDate>Sun, 02 Jun 2024 00:57:18 GMT</pubDate>
    </item>
    </channel>
</rss>