<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 15 Dec 2023 12:25:23 GMT</lastBuildDate>
    <item>
      <title>使用判别性损失进行实例分割？</title>
      <link>https://stats.stackexchange.com/questions/634984/instance-segmentation-using-a-discriminative-loss</link>
      <description><![CDATA[我一直在阅读这篇论文，我想知道他们的判别性损失定义是否正确分段？
据我了解，他们将图像像素映射到更高的维度，并尝试根据它们所属的实例对它们进行聚类。有一个损失项“拉动”损失。属于同一类别的像素嵌入朝向其平均值（L_var），而另一个术语“推动”不同实例的away 平均值(L_dist)。


但问题是，这是一个分类设置，其中我们的类数量有限。但在实例分割中，每个实例应该有自己独立的簇，这很容易遇到维数灾难问题。此外，该函数如何在推理过程中将看不见的实例映射到其自己的单独集群？
我认为损失函数实际上是根据实例的外观以及图像中像素的位置对实例进行分类。因此，看起来相似且重叠的实例始终是该模型的错误来源。
如果有人能阐明这一点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/634984/instance-segmentation-using-a-discriminative-loss</guid>
      <pubDate>Fri, 15 Dec 2023 11:46:43 GMT</pubDate>
    </item>
    <item>
      <title>马歇尔·奥尔金算法 R</title>
      <link>https://stats.stackexchange.com/questions/634983/marshall-olkin-algorithm-r</link>
      <description><![CDATA[您知道如何使用第 29 页（Cholesky 分解）中提供的广义 Marshall-Olkin 算法在 R-Studio 中模拟 Clayton Copula 样本https://people.math.ethz.ch/~embrecht/ftp/copchapter.pdf?]]></description>
      <guid>https://stats.stackexchange.com/questions/634983/marshall-olkin-algorithm-r</guid>
      <pubDate>Fri, 15 Dec 2023 11:30:23 GMT</pubDate>
    </item>
    <item>
      <title>使用重复测量设计的 gamlss 进行前高斯模型拟合的随机效应</title>
      <link>https://stats.stackexchange.com/questions/634982/random-effects-in-ex-gaussian-model-fitting-using-gamlss-with-a-repeated-measure</link>
      <description><![CDATA[我有一个重复测量设计，其中包含目标类型（箭头与注视）和一致性（一致与不一致）等因素，因此每个主题 (id) 都会在每个条件下进行测量。
我正在尝试使用“gamlss”拟合前高斯模型包，允许每个主题在 mu 参数中的 TargetType 和 Congruency 条件上有所不同，但我遇到了一些错误。我正在尝试两种不同的随机效果语法，它们对吗？
模型1：
m1 &lt;- gamlss(RT ~ TargetType * 一致性 + re(random = list(id = pdDiag(~1 + TargetType + Congruency))), data = adhd_exG, family = exGAUS(), control = gamlss.control(n.cyc = 1000))

M1错误：
&lt;块引用&gt;
lme.formula 中的错误（fixed = fix.formula，data = Data，random = random，：
nlminb 问题，收敛错误代码 = 1
message = 达到迭代限制但未收敛 (10)

模型2：
m2 &lt;- gamlss(RT ~ TargetType * 一致性 + re(random = list(id = ~TargetType, id = ~ Congruency)), data = adhd_exG, family = exGAUS(), control = gamlss.控制（n.cyc = 1000））

错误M2：
&lt;块引用&gt;
lme.formula 中的错误（fixed = fix.formula，data = Data，random = random，：
nlminb 问题，收敛错误代码 = 1
message = 达到迭代限制但未收敛 (10)

尽管我已将 n.cyc 更改为 1000，但仍然收到错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/634982/random-effects-in-ex-gaussian-model-fitting-using-gamlss-with-a-repeated-measure</guid>
      <pubDate>Fri, 15 Dec 2023 11:12:51 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么 ES 对干预组和对照组的前后研究进行多级荟萃分析（metafor 包）？</title>
      <link>https://stats.stackexchange.com/questions/634981/what-es-should-i-use-for-a-multilevel-meta-analysis-metafor-package-of-pre-pos</link>
      <description><![CDATA[我们对研究体育锻炼对工人疼痛和残疾的影响进行了系统回顾，并要求我们对数据进行荟萃分析来补充它。
因此，我们选择了以干预组和对照组为特色的研究，并报告了干预前和干预后的措施。
我们拥有的变量是：
&lt;前&gt;&lt;代码&gt;me_pre_int
sd_pre_int
me_post_int
sd_post_int
数字整数

我_pre_c
sd_pre_c
me_post_c
sd_post_c
数字c

干预/实验组和对照组的平均值、标准差和样本量。
我应该使用什么 ES 指标来进行荟萃分析？我们对不同的疼痛程度有不同的测量，因此我们可能需要标准化的平均差，但我不确定该使用什么。
我应该只比较实验组和对照组之间的干预后数据吗？
或者我是否需要计算干预组和对照组的变化分数，然后比较两者？
我正在使用metafor包，所以它基本上可以归结为我应该在escalc()函数中输入哪些数据。
如有必要，我很乐意提供更多详细信息。
我知道 escalc 的选项之一是计算平均变化分数，但它需要数据的相关性，而我没有用于任何研究。
此外，未报告前后差异的标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/634981/what-es-should-i-use-for-a-multilevel-meta-analysis-metafor-package-of-pre-pos</guid>
      <pubDate>Fri, 15 Dec 2023 11:10:30 GMT</pubDate>
    </item>
    <item>
      <title>消除自变量对因变量的影响</title>
      <link>https://stats.stackexchange.com/questions/634980/remove-effect-of-an-independent-variable-on-a-dependent-one</link>
      <description><![CDATA[目前，我们正在使用 1 公斤重的砖块进行重量测量，作为校准方法。然而，传感器返回的最终重量不是1kg，而是随着环境温度的变化而变化，这可能是由于传感器估计重量的方式所致（我附上了图表上缩放的数据）。

我们希望返回的测量值不受温度的影响，即我们期望一条水平线，因为砖块的重量不会改变。为此，应消除温度对最终重量的影响。这个想法是从植物等其他来源进行测量，这样温度对秤所标记的重量的影响可能会导致将来在处理数据时出现错误的估计。
为此，我尝试运行回归模型，估计温度随时间对体重的影响。估计后，我用中值或最高温度等值保持温度恒定，以便重量保持恒定。另一个想法是减去温度对实际重量测量的估计影响（从线性回归），以便重量也保持恒定。但是，我不确定这些方法是否足够，对于如何实现这一目标有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634980/remove-effect-of-an-independent-variable-on-a-dependent-one</guid>
      <pubDate>Fri, 15 Dec 2023 10:45:50 GMT</pubDate>
    </item>
    <item>
      <title>寻找 JS 散度的计算问题</title>
      <link>https://stats.stackexchange.com/questions/634979/computational-issue-for-finding-the-js-divergence</link>
      <description><![CDATA[我有两个 2 维 144 个点的数据集，然后我使用 sklearn 库来拟合 GMM，结果拟合得很好，我在拟合模型时检查了 BIC 值，并选择了 BIC 值较低的模型。之后我想计算我们获得的两个 gmm 之间的 JS 散度，我使用了以下代码
from scipy.stats 导入熵

def js_divergence(gmm_p, gmm_q, n_samples=10000, eps=1e-5):
    X_p, _ = gmm_p.sample(n_samples)
    X_q, _ = gmm_q.sample(n_samples)
    X = np.vstack([X_p, X_q])

    p_pdf = np.exp(gmm_p.score_samples(X))
    q_pdf = np.exp(gmm_q.score_samples(X))

    # 添加一个小常数以保持数值稳定性
    p_pdf = np.clip(p_pdf, eps, 1 - eps)
    q_pdf = np.clip(q_pdf, eps, 1 - eps)
    
    m_pdf = 0.5 * (p_pdf + q_pdf)
    js_div = 0.5 * (熵(p_pdf, m_pdf) + 熵(q_pdf, m_pdf))
    返回js_div

js_div = js_divergence(gmm_first, gmm_second)
print(&quot;詹森-香农散度：&quot;, js_div)

但我面临的问题是，即使我获取几乎相同的数据，有时 JS 值也会非常高，因为我们有 $0\leq JSD(p|| q)\leq \ln(2)=0.693147$ 所以有时我会得到 $0.6823$ 这意味着两个 pdf 是不同的，但如果我的数据集是几乎一样那为什么JS值高呢？有时运行几次后会显示值 $0.0345$ 像这样，这是可以接受的！我犯了什么错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/634979/computational-issue-for-finding-the-js-divergence</guid>
      <pubDate>Fri, 15 Dec 2023 10:26:56 GMT</pubDate>
    </item>
    <item>
      <title>当我有两个对照时比较两个组</title>
      <link>https://stats.stackexchange.com/questions/634976/comparing-two-groups-when-i-have-two-controls-for-them</link>
      <description><![CDATA[我对统计方法有一些疑问。我收到了来自蛋白质印迹的数据，其中计算了与总蛋白相关的蛋白质水平，并根据每个对照组的平均值标准化为 1。
我的数据：

鼠标 A：控制鼠标 A&#39;
鼠标 B：控制鼠标 B&#39;

对于每只小鼠，我有 3 个经过治疗和未经治疗的观察结果（我们称之为 T 和未治疗 NT）。总共有来自 24 只小鼠的 24 个数据点。
我可以将我的变量描述为鼠标控制（A 或 B）、鼠标模型（A、A&#39;、B、B&#39;）以及 T 或 NT 治疗。
我想比较小鼠 A&#39; 和 B&#39; 的治疗效果。我计划使用 DiD，并参考每只鼠标的具体控制，将数据归一化为 1。这是一个有效的选择，还是您知道更可靠的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/634976/comparing-two-groups-when-i-have-two-controls-for-them</guid>
      <pubDate>Fri, 15 Dec 2023 09:41:36 GMT</pubDate>
    </item>
    <item>
      <title>用于生存分析的混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/634975/mixed-effect-models-for-survival-analysis</link>
      <description><![CDATA[在使用混合模型进行生存分析时，我通常使用随机截距或随机截距和随机斜率模型以及 R 中的这些代码：
随机截取：
coxme(surv~variable1+ (1|分组))

随机截距和斜率：
coxme(surv~变量1 + (1+变量1|分组))

变量 1 是分类虚拟变量 (1,0)，分组变量是名义分类变量（从 1 到 x，无顺序）。
但是，我的一位同事告诉我，这些模型不正确地执行这些分析，因为它们没有假设每个组都有可变效应，并告诉我使用这个对我来说听起来很奇怪的模型，因为它消除了拦截：
coxme(surv~0+变量1+(变量1-1|分组))

我应该如何解释这段代码，因为它看起来像一个没有截距的纯随机斜率？]]></description>
      <guid>https://stats.stackexchange.com/questions/634975/mixed-effect-models-for-survival-analysis</guid>
      <pubDate>Fri, 15 Dec 2023 08:48:57 GMT</pubDate>
    </item>
    <item>
      <title>我的非线性问题的最大似然估计量是多少？</title>
      <link>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</link>
      <description><![CDATA[在区域$0\leq x\leq 1$和$0\leq y\leq 1$ 我在 $(x_b,y_b)$ 中放置了 1 个无线电广播电台和 N 个接收器。广播公司的立场尚不清楚。
然而，每个接收器的位置是已知的： $(x_i,y_i)$ 以及从接收器到广播器的距离：$d_i$。
距离测量中存在一些噪声，我假设这些噪声呈正态分布，均值为 0，并且所有接收器的方差相同：
$$
\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} = d_i + \epsilon_i
$$
在哪里
$$
\epsilon_i \sim \mathcal{N}(0,\,\sigma^{2})
$$
我的目标是估计无线电广播公司最可能的位置：$(x_b,y_b)$。
我想通过将其表述为一个最小化问题来做到这一点。
到目前为止，我正在最小化：
$$
SE = \sum_i \left[\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} - d_i\right]^2
$$
我读到，对于线性回归，最小二乘估计器也是正态分布误差假设下的最大似然估计器。
但是这对于我的非线性问题也适用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</guid>
      <pubDate>Fri, 15 Dec 2023 08:33:05 GMT</pubDate>
    </item>
    <item>
      <title>数学可以用来形式化数据集“几何”结构的分析吗</title>
      <link>https://stats.stackexchange.com/questions/634973/can-mathematics-be-used-to-formalize-the-analysis-of-a-datasets-geometric-str</link>
      <description><![CDATA[我想知道是否可以应用数学形式主义来理解“几何”概念。实验数据集的结构，尤其是。其分类预测变量之间的关系。
&lt;小时/&gt;
首先，定义术语......
交叉与嵌套与嵌套分类预测器

交叉预测变量的每个级别在另一个预测变量的每个级别都有一个测量值。
嵌套预测器的每个级别在另一个预测器的至少两个唯一级别中都有一个测量值。
嵌套预测器的每个级别仅在另一个预测器的一个级别中具有测量值。

在此处显示的图片中，预测变量 A 和 B 相互交叉，预测变量 C 相对于 D 嵌套，预测变量 D 嵌套在 C 内。

请注意，嵌套预测器的级别必须使用唯一的标识号进行编码，否则计算机无法知道它们是嵌套的。
&lt;小时/&gt;
第二，一些例子......
最基本的“复杂”是我可以在这里展示的设计具有三个分类预测变量。由于这篇文章不能太长，因此我将使用速记图形符号，并用箭头连接预测变量来描述交叉/嵌套/嵌套成对关系。双向箭头表示交叉预测变量，单向虚线箭头表示嵌套预测变量。
我看到三个分类预测变量的四种可能组合......

&lt;小时/&gt;
以下是一些可以提出的问题（结合我的想法）：

这种“几何”可以吗？预测信息，例如数据集结构，用于在程序上指定给定实验的设计矩阵？ （是）
是否有任何数学规则，例如嵌套预测器的传递性，可以证明吗？ （我不知道）
仅成对关系就足以指定设计矩阵，还是需要更高维度的分析？这个问题的答案能以某种方式得到证明吗？ （在某些情况下仅成对分析是不够的，但我不知道为什么）
]]></description>
      <guid>https://stats.stackexchange.com/questions/634973/can-mathematics-be-used-to-formalize-the-analysis-of-a-datasets-geometric-str</guid>
      <pubDate>Fri, 15 Dec 2023 08:05:54 GMT</pubDate>
    </item>
    <item>
      <title>预处理具有大量唯一值的 ISCX 数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/634971/preprocessing-iscx-data-with-lots-of-unique-values</link>
      <description><![CDATA[我对 ISCX 2012 数据集感兴趣，其中包括 pcap 和 XML 格式的流。
我想创建一个机器学习系统，用于基于流的攻击检测。
首先，我使用各种技术预处理数据。
各列如下：
column_categorical = [&#39;appName&#39;, &#39;direction&#39;, &#39;sourceTCPFlagsDescription&#39;, &#39;destinationTCPFlagsDescription&#39;, &#39;protocolName&#39;, &#39;source&#39;, &#39;destination&#39;, &#39;sourcePort&#39;, &#39;destinationPort&#39;]
column_numerical = [&#39;totalSourceBytes&#39;、&#39;totalDestinationBytes&#39;、&#39;totalSourcePackets&#39;、&#39;totalDestinationPackets&#39;、&#39;持续时间&#39;]

对于端口，我删除了频率较低的端口（小于5个）以减少数量，从而创建了一个binaryEncoder。这是一个例子：
port_counts = df[&#39;sourcePort&#39;].value_counts()

稀有端口 = 端口计数 [端口计数 &lt; 5]

num_rare_ports = len(rare_ports)

print(f“有 {num_rare_ports} 个端口出现次数少于 5。”)

稀有端口 = 端口计数 [端口计数 &lt; 5].索引

df[&#39;sourcePort&#39;] = df.apply(lambda row: None if row[&#39;sourcePort&#39;] inrare_ports else row[&#39;sourcePort&#39;], axis=1)

temp_value = -9999 # 编码期间处理 NaN 的临时值。
df[&#39;sourcePort&#39;].fillna(temp_value, inplace=True)

编码器 = this.BinaryEncoder(cols=[&#39;sourcePort&#39;])
df_encoded = 编码器.fit_transform(df[&#39;sourcePort&#39;])

mask = df[&#39;sourcePort&#39;] == temp_value
对于 df_encoded.columns 中的 col：
    df_encoded.loc[掩码, col] = np.nan

df.drop(&#39;sourcePort&#39;, axis=1, inplace=True)
df = pd.concat([df, df_encoded], 轴=1)

print(&quot;数据个数：&quot;, len(df))

然后，对于值非常多的类别，我使用“qcut”创建分位数，例如目标 IP，我将其转换为数字，然后创建组：
df[&#39;destination_int&#39;] = df[&#39;destination&#39;].apply(ip_to_int)

quantile_bins = pd.qcut(df[&#39;destination_int&#39;], q=5, 重复项=&#39;drop&#39;)

df[&#39;destination_int_quantile&#39;] = quantile_bins

我对 Source Ip、totalDestinationPackets、totalSourceBytes、totalDestinationBytes 等执行此操作。
然后，我对这些列（分位数）执行 oneHotEncoder，并通过删除不必要的列等来执行清理。
它似乎运行良好，我能够通过交叉验证来测试随机森林的性能，并且得到了非常好的结果。
因此，我创建了模型的 pickle，在其上调整了参数，并且我想使用包含训练期间使用的流程的 XML 文件来测试模型。然而，这个测试文件较小，分位数不同，这会产生错误。
我来这里是为了了解在这种情况下该怎么做。我希望我的预处理能够扩展到任何数据大小，但事实并非如此。
我尝试记录训练期间使用的分位数，但我不知道这是否是正确的方法。因为模型的精度仅为 0.20，即使这是它应该知道的数据......]]></description>
      <guid>https://stats.stackexchange.com/questions/634971/preprocessing-iscx-data-with-lots-of-unique-values</guid>
      <pubDate>Fri, 15 Dec 2023 07:40:53 GMT</pubDate>
    </item>
    <item>
      <title>你好，有人知道我如何在我的 mac gpu（'mps' 设备）中运行 rayune 吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/634969/hello-do-you-anyone-know-how-i-run-the-ray-tune-in-my-mac-gpumps-device</link>
      <description><![CDATA[有人知道我如何在我的 mac gpu（&#39;mps&#39; 设备）中运行光线调谐吗？你能帮我举个例子吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/634969/hello-do-you-anyone-know-how-i-run-the-ray-tune-in-my-mac-gpumps-device</guid>
      <pubDate>Fri, 15 Dec 2023 07:12:40 GMT</pubDate>
    </item>
    <item>
      <title>如果您对交互感兴趣，但变量多于样本，那么哪种测试最合适</title>
      <link>https://stats.stackexchange.com/questions/634966/what-test-is-most-appropriate-if-youre-interested-in-an-interaction-but-have-m</link>
      <description><![CDATA[我很乐意就以下问题获得一些建议！
我有一个数据集 (n = 99)，其中包括：

7 个不同认知领域的综合得分
测量 934 种脂质，可归纳为 27 个亚类
以最大摄氧量 (VO2max) 衡量的心肺健康状况（我也将其分类为低/高）
在一个名为“fitnessCategory”的新变量中）

我对个人的健康和血脂如何影响认知功能感兴趣，但我不确定最好的统计方法是什么。我考虑了以下几点：

执行多重线性回归分析（认知 ~ 脂质 * 健身类别 + 协变量），并循环遍历所有 7 个认知域和 27 个脂质子类，但随后我面临着调整多重比较的问题。在这种情况下，我是否需要调整 7 x 27 比较？我也只对脂质 *fitnessCategory 之间的相互作用显着感兴趣，那么我是否会调整相互作用或整体模型的 p 值？我也不确定我是否需要首先进行调整，因为我的脂质并不是真正彼此独立的（它们高度相关，因为许多脂质属于相似的总体类别，并且仅存在 1 个碳或 1 个羟基）。&lt; /p&gt;

执行 PLS，但随后我不确定如何整合脂质和健身之间的相互作用。我能看到这种情况发生的唯一方法是执行 PLS-DA（Y = 健身类别，X = 所有脂质），但随后我的样本量显着减少（每组约 40-50 个）并导致组大小不均匀。我也不知道如何控制多个混杂因素，例如性别/年龄（F 和 70+ 往往属于较低健康组），这是 O-PLS-DA 可以解释的吗？


任何和所有建议/提示/建议将不胜感激！我是一名统计新手，所以如果我问的是一个非常基本的问题，我深表歉意。请随意在您的答案中陈述显而易见的内容，就好像我没有先验知识一样！]]></description>
      <guid>https://stats.stackexchange.com/questions/634966/what-test-is-most-appropriate-if-youre-interested-in-an-interaction-but-have-m</guid>
      <pubDate>Fri, 15 Dec 2023 03:25:42 GMT</pubDate>
    </item>
    <item>
      <title>分析 Attrak Diff 问卷结果时，Tukey 检验中 R 为正估计，但 p 值不显着</title>
      <link>https://stats.stackexchange.com/questions/634965/tukey-test-in-r-positive-estimate-but-non-significant-p-value-when-analyzing-att</link>
      <description><![CDATA[我是一名硕士生，正在分析我的用户研究中的 Attrak Diff 调查问卷结果。我没有统计学背景，我很难解释我的结果。
我以一种方式重复测量方差分析并获得显着的 p 值，因此我运行 Tukey 来查看四个问卷类别中的哪一个具有显着差异。
我现在很困惑，因为其中两个估计值是正值（根据我的阅读，这意味着存在显着差异？），但只有其中一个 p 值是显着的。在讨论估计值时，我遇到过诸如“可检测差异”之类的措辞，但这只会让我更加困惑。我在这里找不到任何与我的情况完全匹配的问题。
如何准确描述我的结果？


这是我的 R 代码：
g &lt;- glht(M,linfct=mcp(&#39;quality&#39;=&#39;Tukey&#39;))
概要(g)
]]></description>
      <guid>https://stats.stackexchange.com/questions/634965/tukey-test-in-r-positive-estimate-but-non-significant-p-value-when-analyzing-att</guid>
      <pubDate>Fri, 15 Dec 2023 03:00:50 GMT</pubDate>
    </item>
    <item>
      <title>Python 中无趋势或季节性的短时间序列的预测方法</title>
      <link>https://stats.stackexchange.com/questions/634938/forecasting-methods-for-a-short-time-series-with-no-trend-or-seasonality-in-pyth</link>
      <description><![CDATA[我对数据科学还很陌生，我的项目遇到了一些问题。
我正在尝试为时间序列数据建立预测模型。这大约是农业每年的二氧化碳排放量。
问题是数据集非常有限（30 个值对应 30 年，即每年一个值），从这个系列中我没有发现任何趋势，并且季节性为 0。
df 来自 csv 文件，格式如下：
“年份”包含 1990 - 2020 年值的列
“CO 2 ”包含每年值的列 (115-47)
所有值都是整数，没有缺失值或极端值
我正在尝试使用Python工作，到目前为止，我已经尝试过ETS、Holt Winters、Prophet和ARIMA，但它们都输出一条对应于总值平均值的直线，作为预测，具有非常广泛的ci .
我的问题是，我可以使用什么模型来尝试为即将到来的
10-20 个时间步长（年）？
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/634938/forecasting-methods-for-a-short-time-series-with-no-trend-or-seasonality-in-pyth</guid>
      <pubDate>Thu, 14 Dec 2023 19:07:58 GMT</pubDate>
    </item>
    </channel>
</rss>