<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 29 Jul 2024 15:16:45 GMT</lastBuildDate>
    <item>
      <title>不平衡面板数据——最佳选择？</title>
      <link>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</link>
      <description><![CDATA[我有 1920-1935 年的一组购房交易。我希望研究一系列变量对这些交易规模的影响。这些交易通常涉及相同的买家，但它们在这段时间内的分布并不一致（例如，公司 A 可能在 1921 年、1927 年和 1933 年有重复交易，而公司 C 在 1922 年、1927 年、1930 年和 1935 年有重复交易）。
理想情况下，我会使用固定效应估计量来解释实体特定特征，但我认为我不能这样做，因为我没有足够的一致重复（如果我选择最佳间隔 - 在我的情况下是 1923 年、1927 年、1932 年和 1934 年 - 在这些年份我可以获得重复数据的公司数量最多为 8 家）。考虑到这个问题，我应该使用合并 OLS 回归吗？或者，我的数据是否最适合时间序列（虽然丢失实体级变化似乎很可惜）？
非常感谢您的建议，]]></description>
      <guid>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</guid>
      <pubDate>Mon, 29 Jul 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>确保至少遇到 1 只动物的概率的圆的半径</title>
      <link>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</link>
      <description><![CDATA[我正在尝试计算一个圆的半径，在这个圆中，至少有一只已知密度的动物以一定的概率出现。为简单起见，我们假设动物呈连续的圆形均匀分布。
首先，我知道动物密度 (D) 是丰度 (N) 与面积 (A) 之比，
$$
D = \frac{N}{A}
$$
我知道圆面积与半径 (R) 的关系方程，
$$
D = \frac{N}{\pi R^2}
$$
重新排列为 $R$，
$$
R^2 = \frac{N}{\pi D}
$$
这就是我有点迷茫的地方。举个例子，我们假设 $D = 5$（意味着每 100 公里有 5 只动物$^2$ 或每公里有 0.05 只动物$^2$），我将概率设置为 10%。那么半径应该是，
$$
R = \sqrt{\frac{0.10}{0.05\pi}}
$$
那么半径为 ~0.80 公里的圆有 10% 的概率遇到至少 1 只动物（再次假设连续圆形均匀分布）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</guid>
      <pubDate>Mon, 29 Jul 2024 15:13:55 GMT</pubDate>
    </item>
    <item>
      <title>麦克内马尔的测试要经过多少次试验才会得出错误结果？</title>
      <link>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcneymars-test-gives-an-incorrect-result</link>
      <description><![CDATA[（虽然这个问题的表述方式像是一道考试题，但这是我完全自己编造的一道题。）
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
 L 不太擅长统计，所以他们使用 ChatGPT 并了解 McNemar 检验来计算结果是否具有统计意义。
具体来说：
def mcnemars_test(w1, w2):
n10 = w1 # 玩家 1 获胜
n01 = w2 # 玩家 2 获胜

# 计算检验统计量（使用 Yates 连续性校正）
chi2_stat = (abs(n01 - n10) - 1)**2 / (n01 + n10)

# 从自由度为 1 的卡方分布计算 p 值
p_value = stats.chi2.sf(chi2_stat, df=1)

return chi2_stat, p_value

但是，由于 L 先生是毕业生学生担心发表，他们希望确保他们的结果具有统计意义。因此，他们决定继续让人工智能玩游戏，直到结果具有统计意义（p&lt;0.05）。
假设 L 先生失败了，两个人工智能实际上是等价的。平均而言，L 先生需要让人工智能玩多少场游戏，McNemar 的测试才会返回结果，即数据由性能相同的模型生成的概率小于 5%（p&lt;0.05）？
额外加分 #1：我们已经回答了“平均而言”L 先生需要玩多少场游戏的问题，但分布是什么样的？如果 L 先生进行了 $n$ 次试验，那么观察到显著结果的概率是多少（尽管模型相同）？
额外加分 #2：如果 L 先生真的想确保他们的结果显著，因此他们使用 p&lt;0.01 作为截止值，会怎样？那么平均需要多少场游戏？一般情况下，p
我问这个问题是因为我被告知，对于统计测试，您应该事先确定试验次数，然后使用测试，并且增加测试次数直到获得显著结果就是 p-hacking 并破坏测试。但是，我实际上还没有看到过关于这种 p 值操纵有多严重的计算，而且我不知道如何凭空计算这样的事情。
我的直觉是，额外积分 #1 (EC#1) 实际上相当容易回答，我只是没有清楚地考虑它，主要问题只是 EC#1 的预期值，所以它也可能很容易回答。但是，我真的不确定 EC#2。]]></description>
      <guid>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcneymars-test-gives-an-incorrect-result</guid>
      <pubDate>Mon, 29 Jul 2024 15:10:13 GMT</pubDate>
    </item>
    <item>
      <title>使用向量自回归 (VAR) 模型预测金融资产回报</title>
      <link>https://stats.stackexchange.com/questions/651943/predicting-financial-asset-returns-using-a-vector-autoregressive-var-model</link>
      <description><![CDATA[我有 10 种资产（假设是股票）的交易数据。数据自 2007 年以来以 5 分钟为间隔。数据行和列的示例如下所示，其中“ivv”、“iwm”和“xlf”是 10 种资产中的 3 种，而“_o”、“_h”、“_l”、“_c”和“_v”后缀指的是时间戳中每项资产的开盘价、最高价、最低价、收盘价和成交量值。整个数据集的形状为 (342200, 55)。这些值不是按百分比变化（回报）直接计算的价格。

从理论上讲，可以想象每个变量都会影响每个变量。因此，我运行了一个 VAR 模型，其中所有变量都是内生变量（并且基于 AIC 的阶数为 5）。但实际上，我最感兴趣的是预测收盘价，因为您可以更轻松地根据收盘价进行交易（但开盘价也可以，而且预测最高价和最低价仍然是非常有用的信息）。
接下来，我计算每个方程的 R 平方，即方程中实际值和拟合值之间的平方相关性。R 平方的范围从 0.3% 到 73%。所有收盘变量的 R 平方均小于 6%，而 R 平方最高的变量几乎都是开盘价。
可视化预测表现的一种方法是绘制累积实际值和拟合值。请记住，这些值是回报，因此这将是累积回报，这接近于交易系统绩效的评估方式。对于资产“ijr”收盘价（R 平方=6%），图表如下所示：

而对于资产“xlu”开盘价（R 平方=73%），图表如下所示：

因此，我有几个问题：

xlu_o 的预测看起来非常好。我是否忽略了方法论中的某些内容？
鉴于这些资产不会隔夜交易，并且今天的收盘价与明天的开盘价非常接近，那么如何解释所有收盘价预测都如此糟糕，而开盘价预测却如此好？
我将所有变量都用作内生变量而没有一个变量是外生变量的理由是否正确？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651943/predicting-financial-asset-returns-using-a-vector-autoregressive-var-model</guid>
      <pubDate>Mon, 29 Jul 2024 14:57:55 GMT</pubDate>
    </item>
    <item>
      <title>具有不常见处理的工具变量（IV）</title>
      <link>https://stats.stackexchange.com/questions/651942/instrumental-variables-iv-with-uncommon-treatment</link>
      <description><![CDATA[我正在研究一种工具变量策略，其中我有一个不常见的二元处理（不到 1% 的样本经过处理）。我有一个二元工具，大约 85% 的治疗组和 45% 的未治疗组都启用了该工具。我的结果变量是连续的。
在我的第二阶段回归中，我得到的系数似乎大得难以置信。我尝试了 R 中的不同方法来处理我的治疗中的非线性（例如使用概率单位来预测治疗并将其用作工具或使用 sampleSelection 包中的 treatReg 函数）。但是，问题仍然存在。
我认为问题可能是因为第二阶段将结果回归到治疗的预测值上，由于治疗非常不常见，所以这些预测值非常小（在所有情况下）。即，当工具从关闭切换到打开时，治疗的预测概率从 1% 变为 3%。但是，第二阶段的治疗系数代表治疗概率发生一个单位的完全变化（从 0 到 100%）所导致的结果变化。但是，这是从治疗概率的有限变化（1 到 3% 的变化）推断出来的。
有人对如何解释这些结果有什么建议或想法吗？是否有任何方法可以缩放系数等？此外，我很可能完全忽略了我对 IV 的理解！
以下是系数的示例：
结果 = 测试分数（满分 100 分）
截距 = 65.00
treatment_pred. = -80.00
在这种情况下，如果某人“接受治疗”，他们的分数将为负数。但是因为该处理变量是治疗状态的预测概率，所以没有人实际上有负分，因为他们的系数被 treatment_pred 的值缩小了（介于 0 到 3% 之间）。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651942/instrumental-variables-iv-with-uncommon-treatment</guid>
      <pubDate>Mon, 29 Jul 2024 14:08:31 GMT</pubDate>
    </item>
    <item>
      <title>lme 成对比较中的估计解释</title>
      <link>https://stats.stackexchange.com/questions/651941/interpretation-of-estimate-in-lme-pairwise-comparison</link>
      <description><![CDATA[我正在运行此模型：mod &lt;- lme(log_weight ~ log_weight0 + Group*Day, random = ~ 1 | ID, data = mydata, na.action = na.exclude)。
Day 变量是我模型中的一个因素，因此我可以比较不同日期的多个组。对于成对比较，我使用 emmeans_results &lt;- emmeans(mod, specs = trt.vs.ctrlk ~ Group | Day) 和 pairs(emmeans_results)。
例如，Day=1 的输出如下所示：
 对比估计 SE df t.ratio p.value
Group1 - Group2 -0.026452 0.0423 202 -1.627 0.5817

我的问题是：由于我的因变量是对数变换后的权重，估计值是否等于 log(group1 的权重) - log(group2 的权重) = log(group1 的权重/group2 的权重)？据我所知，如果我将其变换回来，它将不再是权重的平均值，而是权重的几何平均值？因此，在我的示例中，估计值 -0.026 意味着 Group1 的权重几何平均值比 Group2 低 exp(-0.026) 倍？]]></description>
      <guid>https://stats.stackexchange.com/questions/651941/interpretation-of-estimate-in-lme-pairwise-comparison</guid>
      <pubDate>Mon, 29 Jul 2024 13:49:42 GMT</pubDate>
    </item>
    <item>
      <title>处理小数据集和异常值</title>
      <link>https://stats.stackexchange.com/questions/651939/dealing-with-small-dataset-and-outliers</link>
      <description><![CDATA[我是一名医学生，目前正在研究从医学物理图像中提取的与医学物理领域相关的数据集。我的数据集有 66 行和 22 列。目标是借助前 17 列预测接下来的 5 列。星星是关于肺的，而人类的肺非常不同，因此尽管样本数量很少，但数据集很可能包含大量数据。有些列有软件，有些列有非正常列。您对我如何处理这些提议有什么建议吗？我再次询问，没有收到答复。（非常抱歉，但我是初学者，因此我希望您能尽可能轻松地进行指导）
]]></description>
      <guid>https://stats.stackexchange.com/questions/651939/dealing-with-small-dataset-and-outliers</guid>
      <pubDate>Mon, 29 Jul 2024 13:14:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要对 t 分布进行测试，而不是对任何其他渐近正态分布进行测试？</title>
      <link>https://stats.stackexchange.com/questions/651937/why-do-we-test-on-the-t-distribution-rather-than-any-other-asymptotically-normal</link>
      <description><![CDATA[根据这个问题，答案指出，对于非正态分布的数据，t 分布并没有什么特别之处，我想知道为什么使用 t 分布。
对我的链接问题的回答是，t 分布比 z 分布更保守。但是，t 分布对于任何基础分布都不保守（我认为？），那么为什么不选择更保守的渐近正态分布呢？（我们有无限的可能性）。显然，如果我们走得太远，我们的测试就会太弱，所以也许提出这个问题的最佳方式是：
我们如何决定对非正态分布数据的小样本量进行测试的分布有多保守？为什么人们普遍认为 t 分布最能平衡这种权衡？]]></description>
      <guid>https://stats.stackexchange.com/questions/651937/why-do-we-test-on-the-t-distribution-rather-than-any-other-asymptotically-normal</guid>
      <pubDate>Mon, 29 Jul 2024 12:23:41 GMT</pubDate>
    </item>
    <item>
      <title>基于精度的平均变化计算</title>
      <link>https://stats.stackexchange.com/questions/651935/precision-based-calculation-of-mean-change</link>
      <description><![CDATA[我有两个关于平均变化（基于精度）的 SS 计算的基本问题（我是一名医生，不是生物统计学家，所以如果问题非常基础，请见谅）：

我的一位同事建议使用 0 相关性来计算保守的变化。我的观点是（保守估计可能是 0.5 相关性或 0.4），如果 Corr=0，即独立性，那么计算变化就没有什么意义了，最好使用事后平均值。对此有什么看法？
与问题无关，他计算了精度公式中输入的变化 SD，即 SDchange=SQRT(VARpre/npre+VARpost/Npost)，认为 CI 计算中用于平均变化的参数是 SEM。我会使用 SDchange=SQRT(VARpre+VARpost)，然后在公式中输入 SD 以进行基于精度的样本大小计算。

我的计算：我们使用测试前 SD 1.2 和测试后 SD 0.8 计算受试者内标准差。测试不同的相关性 0.5、0.6、0.7 和 0.8，我们分别获得了 1.058、0.963、0.858 和 0.738 的 SD 变化。平均值计算的精度为 1，平均值为 1，产生的 95% 置信区间范围为 [0.913, 1.087]（SD 为 1.05）到 [0.940, 1.060]（SD 为 0.73），共有 564 名受试者
对此有什么看法？
BR
亚历克斯]]></description>
      <guid>https://stats.stackexchange.com/questions/651935/precision-based-calculation-of-mean-change</guid>
      <pubDate>Mon, 29 Jul 2024 11:47:40 GMT</pubDate>
    </item>
    <item>
      <title>在双向固定效应中，添加时间和感兴趣的变量之间的交互项是否合适？</title>
      <link>https://stats.stackexchange.com/questions/651934/is-it-appropiate-to-add-a-interaction-term-between-time-and-the-variable-of-inte</link>
      <description><![CDATA[我感兴趣的是评估各国经济发展对其民主程度的影响。为此，我使用了双向固定效应。固定效应包括单位和时间固定效应。
我读到，使用固定效应模型时，一个隐含的假设是效应大小随时间保持不变；因此，我应该在我感兴趣的系数和时间变量之间添加一个交互项。在这种情况下，变量可能是年份。然后，这个交互项可以指示系数的影响是否随时间保持不变。
考虑到模型已经包括时间固定效应，这是否真的合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/651934/is-it-appropiate-to-add-a-interaction-term-between-time-and-the-variable-of-inte</guid>
      <pubDate>Mon, 29 Jul 2024 11:44:00 GMT</pubDate>
    </item>
    <item>
      <title>有哪些情况不应同时使用 Kolmogorov-Smirnov 检验和卡方检验来比较两个数据集？</title>
      <link>https://stats.stackexchange.com/questions/651933/are-there-cases-where-the-kolmogorov-smirnov-test-and-chi-squared-test-should-no</link>
      <description><![CDATA[通过关注Kolmogorov-Smirnov 检验与卡方检验问题，看起来这两个检验都可用于比较两组数据。显然，对于 Kolmogorov-Smirnov 检验，将数据保持“未分箱”，而对于卡方检验，将数据“分箱”。
是否存在两种检验可能互斥的情况，即您使用其中一种而不使用另一种，或者，它们不应一起使用来比较两组数据（因此当您“分箱”数据时，应比较直方图/分布）的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651933/are-there-cases-where-the-kolmogorov-smirnov-test-and-chi-squared-test-should-no</guid>
      <pubDate>Mon, 29 Jul 2024 11:20:50 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归的置信上限较高 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651931/high-upper-confidence-limit-on-cox-regression</link>
      <description><![CDATA[我正在对癌症的生存分析进行 Cox 回归分析。我在 Cox 回归中得到的置信区间上限很大，风险比 (expB) 也很高。我已纳入 10 个变量，并在 SPSS 中输入了方法。样本量为 32。置信上限高的原因是什么？如何处理？我已附上 spss 输出。
除癌症分期外，所有变量均有二分结果 (0,1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651931/high-upper-confidence-limit-on-cox-regression</guid>
      <pubDate>Mon, 29 Jul 2024 11:07:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在影响评估中解释不平衡数据和治疗前暴露？</title>
      <link>https://stats.stackexchange.com/questions/651929/how-to-account-for-imbalanced-data-and-pre-treatment-exposure-in-an-impact-evalu</link>
      <description><![CDATA[我正在尝试评估辅导干预的影响，并且有接受治疗的儿童和对照组的测试成绩数据。但是，治疗组的研究报名时间早于对照组。因此，在对照组报名时，治疗组可能在基线测量之前最多接受了三个月的干预。
有两种不同的测试：
测试 1（不平衡数据）：自实施开始以来，治疗组的数据可用，但对照组的数据仅在报名后可用（即，治疗组的数据较早）
测试 2（治疗前暴露）：对于这两个组，数据仅在对照组报名后可用（即数据集是平衡的，但治疗组在第一个数据点之前已经接受了长达 3 个月的干预）。
在这两种情况下，是否有任何缓解策略？对于测试 1，是否有任何方法可以仅解释治疗组的早期测试分数数据？对于测试 2，我是否只需要接受效应大小的任何系数实际上都是下限估计值？]]></description>
      <guid>https://stats.stackexchange.com/questions/651929/how-to-account-for-imbalanced-data-and-pre-treatment-exposure-in-an-impact-evalu</guid>
      <pubDate>Mon, 29 Jul 2024 11:04:02 GMT</pubDate>
    </item>
    <item>
      <title>数据集比较的异常值检测</title>
      <link>https://stats.stackexchange.com/questions/651927/outlier-detection-for-data-set-comparison</link>
      <description><![CDATA[我有两个数据集，它们具有相似的列，一个是数值列，其余的是分类列。
col_1= categorical: city_name,
col_2= categorical: company_name,
col_3 = categorical: product_name,
col_4 = numeric : volume。
行数约为 5000。
city_name 有大约 300-400 个唯一值，公司名称有大约 10 个唯一值，有 5 种不同类型的产品，其中产品“a”是最常见的产品类型。volume 对于每个 col_1、col_2、col_3 组合都是唯一的（过去 12 个月的总和）。
我们将第一个数据集称为 df1，将第二个数据集称为 df2。假设从 df2 中删除异常值后，df1 与 df2 相似。在移除异常值之前，这两个数据集在描述性统计方面显示出截然不同的数字。
根据散点图手动从 df2 中移除异常值后，df1 和 df2 具有更相似的描述性统计。
我们认为 df2 中的异常值来自我们目前无法访问的数据。因此，移除这些异常值目前基于“数据领域专家知识”，即具有领域知识的人查看散点图并做出决定。
我的问题是，是否有可能以更复杂的方式进行这种异常值检测？我一直在研究 k-nn 算法，并尝试将分类值转换为 id/数字，并得出了一些受数量和邻域影响很大的随机异常值选择。
所以我的问题是，对于任何特定情况，对于复杂的异常值检测模型来说，什么方法最好？任何建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/651927/outlier-detection-for-data-set-comparison</guid>
      <pubDate>Mon, 29 Jul 2024 10:39:04 GMT</pubDate>
    </item>
    <item>
      <title>如何解释逻辑回归中的相反系数估计？</title>
      <link>https://stats.stackexchange.com/questions/651926/how-interpret-contrary-coefficient-estimates-in-a-logistic-regression</link>
      <description><![CDATA[我需要帮助来解释中介分析的结果输出。
我有一个预测因子 X，它以负面的方式预测三个中介变量 M1、M2、M3。当 X 增加时，M1、M2、M3 会减少。M1、M2、M3 预测二元响应结果 Y，但 M1 和 M3 以正向方式，而 M3 以负向方式。
我在解释结果时遇到了一些困难，其中 X 和 M 之间的关系是平行的，但 M 对 Y 的影响在 M 个变量之间是相反的。你能帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651926/how-interpret-contrary-coefficient-estimates-in-a-logistic-regression</guid>
      <pubDate>Mon, 29 Jul 2024 10:15:53 GMT</pubDate>
    </item>
    </channel>
</rss>