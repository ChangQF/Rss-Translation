<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 Jan 2025 18:22:13 GMT</lastBuildDate>
    <item>
      <title>为什么当发现因素很重要时，比较字母没有差异？</title>
      <link>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</link>
      <description><![CDATA[我使用&quot;lmer&quot;在 r 中运行了一系列包含两个因素的模型函数，还测试了因子相互作用。
例如：
model &lt;- lmer(parameter ~ factor1*factor2 + (1|ID_repeated), data=db)
summary(model)
joint_tests(model)
AIC(model)
shapiro.test(resid(model))

然后，我对重要因子（或当重要时对它们的相互作用）进行了成对比较测试，以查看该因子的哪些情况不同。
mcp&lt;-emmeans(model,~factor, method=&quot;tukey&quot;,adjustment=&quot;bonferroni&quot;)
cld(mcp, Letters=&quot;ABCDE&quot;, reversed=TRUE, sort=FALSE)

在两种情况下，mcp&lt;-emmeans 没有显示不同的字母，即使那些根据模型结果，因子是显著的。
例如，在以下情况下，交互作用是显著的，但这并没有从我运行比较时得到的字母中显现出来。
模型术语 df1 df2 F.ratio p.value
因子1 1 18 0.574 0.4584
因子2 4 72 57.563 &lt;.0001
因子1：因子2 4 72 2.825 0.0309
因子1 因子2 emmean SE df lower.CL upper.CL .group
A 2000 0.582 0.154 72.7 0.275 0.890 b
B 2000 0.670 0.154 72.7 0.362 0.977 b
A 2005 0.622 0.154 72.7 0.314 0.929 b
B 2005 0.437 0.154 72.7 0.129 0.744 b
A 2010 0.616 0.154 72.7 0.309 0.924 b
B 2010 0.534 0.154 72.7 0.227 0.842 b
A 2015 0.966 0.154 72.7 0.659 1.273 b
B 2015 1.026 0.154 72.7 0.719 1.334 b
A 2020 1.917 0.154 72.7 1.610 2.224 a
B 2020 2.556 0.154 72.7 2.249 2.863 a
你能帮我理解为什么会发生这种情况以及我做错了什么吗？
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</guid>
      <pubDate>Wed, 29 Jan 2025 18:16:14 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 交叉验证</title>
      <link>https://stats.stackexchange.com/questions/660732/lightgbm-crossvalidation</link>
      <description><![CDATA[我正在调整 LightGBM 模型以进行一些时间序列预测，我正在使用交叉验证。我有很多不同的特征（日期特征、滞后、超前等）想要尝试。同时，我还需要弄清楚要使用哪些超参数。我尝试了一些，得到了一些不错的结果，但我的执行过程似乎不是最佳的。
如果我从尝试一些特征开始，如果我没有一些合适的超参数，我将无法真正知道它们是否有效。反过来说，如果我使用了错误的特征，似乎也很难确定我拥有正确的超参数集。那么该怎么办？
我是否找到一组有限的特征并尝试基于这些特征找到一些好的超参数？我应该调整哪些超参数，以及调整到什么深度？]]></description>
      <guid>https://stats.stackexchange.com/questions/660732/lightgbm-crossvalidation</guid>
      <pubDate>Wed, 29 Jan 2025 18:06:35 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是派生值时处理模型假设</title>
      <link>https://stats.stackexchange.com/questions/660731/dealing-with-model-assumptions-when-your-response-variable-is-a-derived-value</link>
      <description><![CDATA[首先我要说的是，在使用线性模型方面，我是个新手。
我正在处理的运动数据如下所示：



id
location
treatment
size
totaldist
dailydist
firstdaydist
Days跟踪




1
site1
soft
1.2
75
4.2
5
18


2
site1
sof t
1.3
50
2.7
2
18


3
site1
困难
1.1
200
11.1
25
18


4
site2
软
0.6
0
0
0
15


5
site2
硬
0.2
500
27.8
100
18


6
site2
soft
0.7
20
1.3
1
15



其中我为每个动物 id 计算了平均距离值（totaldist、dailydist、firstdaydist）。这些距离值基于未在此处包括的单个观测值（GPS 点）的计算。
我已设置了一系列线性模型（例如 fit &lt;- lm(totaldist ~ treatment+location+size+Days tracked, data=df) 来检查这些预测因子对距离值的影响。在此过程中，我注意到我的一些模型不能很好地满足线性模型的假设，但对这些数据进行转换感觉很奇怪，因为它是派生数据，而不是“原始”（原始观测）数据。
我的问题：如果这种格式合适，是否有办法对这些数据进行线性模型处理，或者我需要重新考虑我的数据格式？我更感兴趣的是了解因素（treatment、location、size、Days tracked）如何影响这些派生/汇总值（totaldist 等）比我更了解单个观测值之间距离的原始数据。
如果有讨论这种情况的资源，请告诉我。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660731/dealing-with-model-assumptions-when-your-response-variable-is-a-derived-value</guid>
      <pubDate>Wed, 29 Jan 2025 18:03:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用表示定理（不直接调用 KKT）证明核 SVM 解是稀疏的？</title>
      <link>https://stats.stackexchange.com/questions/660730/how-to-show-kernel-svm-solutions-are-sparse-using-the-representer-theorem-witho</link>
      <description><![CDATA[在软边缘 SVM 的核化形式中，目标是
$$
\min_{\alpha \in \mathbb{R}^n} \biggl[
\tfrac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i\,\alpha_j\,k(x_i, x_j)
\;+\;
C \sum_{i=1}^n \max\bigl(0,\,1 - y_i\,f_\alpha(x_i)\bigr)
\biggr],
$$
其中
$$
f_\alpha(x) \;=\; \sum_{j=1}^n \alpha_j\,k(x_j, x)。
$$
根据表示定理，最优解 $f^*$ 也具有这种形式。通常，从原始对偶分析中，我们知道 $y_i f^*(x_i) &gt; 1$ 时 $\alpha_i = 0$（即，对于严格位于边界之外的点）。
我的问题：我们能否在此展示这种稀疏性，即 $\alpha_i = 0$，而不是明确依赖 KKT 条件？]]></description>
      <guid>https://stats.stackexchange.com/questions/660730/how-to-show-kernel-svm-solutions-are-sparse-using-the-representer-theorem-witho</guid>
      <pubDate>Wed, 29 Jan 2025 17:12:42 GMT</pubDate>
    </item>
    <item>
      <title>去趋势时间序列：感兴趣的空间变量是否应包括在去趋势步骤中？</title>
      <link>https://stats.stackexchange.com/questions/660728/detrending-a-time-series-should-spatial-variables-of-interest-be-included-in-th</link>
      <description><![CDATA[我对时间序列数据还不熟悉，对时间序列去趋势化感兴趣，然后用去趋势化的数据进行多元线性回归，但我对时间序列的位置部分（纬度）有点迷茫。简而言之，包含在“去趋势化”数据中的变量是否可以包含在后续分析中？我很难理解这在统计上是否合理。
举例来说：我有季节性事件（一年中鸟类目击日）在时间（年份）和空间（纬度）上的观察数据，以及每个特定时间点（年份、月份、纬度）的平均温度数据。我感兴趣的是，随着这些不同地点的季节性温度变化，鸟类观测次数可能会增加或减少（那么，在春季或夏季气温升高的情况下，我们在北纬地区看到的鸟类是否比南纬地区多？）。
在查看了数据的年度趋势并阅读了时间序列数据后，似乎最直接的方法是：

首先使用回归对我的观测和温度数据进行去趋势处理（观察：观测日期 ~ 年份和温度数据：温度 ~ 年份）
然后使用残差作为回归中的数据来评估我的问题（去趋势的观测日期 ~ 去趋势的春季温度 + 去趋势的夏季温度 + 纬度 + 所有 2 向和 3 向交互作用）

但是，由于这些模式可能会在空间上发生变化，我现在想知道初始去趋势步骤是否也需要纬度（观察：观测日期 ~ 年份+ 纬度 + 年份 x 纬度和温度数据：温度 ~ 年份 + 纬度 + 年份 x 纬度）。
如果是这种情况，1）从统计角度来看，我是否仍可以在主模型中包含纬度，因为它是一个感兴趣的变量？如果是……2）如果我们在去趋势步骤中控制纬度的变化，纬度是否仍可以解释为主模型中的空间/纬度差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/660728/detrending-a-time-series-should-spatial-variables-of-interest-be-included-in-th</guid>
      <pubDate>Wed, 29 Jan 2025 16:34:48 GMT</pubDate>
    </item>
    <item>
      <title>干预后测试群体的相似性 - 收敛还是方差？</title>
      <link>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</link>
      <description><![CDATA[我感兴趣的是测试一个群体在干预后是否变得更加相似。例如，假设我有一个连续变量干预前后的分数列表，该连续变量被合理地假设为正常。我感兴趣的是看看在经历这次干预后，这个群体是否变得更加相似。我不需要知道他们的平均值是否发生了变化，但我认为我需要了解的是他们的变异是如何变化的。（因此，如果我预期的结果已经实现，那么干预后该群体的方差就会减小，这表明该群体在结果变量上已经在某种程度上趋向于相似的分数）。
我最初的想法是 (1) 通过将参与者视为“评估者”并查看干预后的 ICC 是否比干预前更高来建立某种类间相关性。或者，(2) 方差分析来检验两组之间的差异。
与本论坛的许多人相比，我的统计知识相对有限 - 因此，如果您能提供任何链接或参考资料，以便我可以进一步阅读建议的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</guid>
      <pubDate>Wed, 29 Jan 2025 16:08:10 GMT</pubDate>
    </item>
    <item>
      <title>排序相关性的概括</title>
      <link>https://stats.stackexchange.com/questions/660724/generalization-of-ranking-correlation</link>
      <description><![CDATA[我有一个系统，它产生了 $n$ 个输出，并且两个注释者对它们进行了评判。每个注释者都生成了一个 $n$ 项的排序列表。我通过计算排序相关性（具体来说是 Spearmans $\rho$）来测量它们的相关性，它产生了一个值，比如 $x$（以及 p 值）。
我们能对 $x$ 的普遍性说些什么？如果系统生成 $p$ 个新输出，我可以说，如果注释者对这 $n+p$ 个项目进行了排名，那么排名相关性仍然会是 $\approx x$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660724/generalization-of-ranking-correlation</guid>
      <pubDate>Wed, 29 Jan 2025 16:06:22 GMT</pubDate>
    </item>
    <item>
      <title>模型复杂性导致收益递减的引文</title>
      <link>https://stats.stackexchange.com/questions/660719/citations-for-diminishing-returns-from-model-complexity</link>
      <description><![CDATA[显而易见，随着统计或机器学习模型的复杂度不断提高，您可以获得更好的性能（例如，在预测准确性方面），但每增加一个单位复杂度，性能的提升就会逐渐减弱。例如，在普通最小二乘法的背景下，采用没有交互项的模型并添加所有一阶交互项所获得的性能提升通常会大于添加所有二阶交互项所获得的性能提升，尽管前一种情况下添加的项数要少得多。
这一点与增加训练集大小带来的收益递减有关，但略有不同。同样，过度拟合的危险也是如此：即使您使用单独的测试集等正确评估模型，并添加防止过度拟合的措施（例如正则化），您仍然应该预期复杂性带来的收益递减。
您能推荐一些好的论文或教科书章节来引用这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660719/citations-for-diminishing-returns-from-model-complexity</guid>
      <pubDate>Wed, 29 Jan 2025 15:22:17 GMT</pubDate>
    </item>
    <item>
      <title>如何为 Cox-PH 模型选择概率分布？</title>
      <link>https://stats.stackexchange.com/questions/660718/how-to-select-a-probability-distribution-for-the-cox-ph-model</link>
      <description><![CDATA[我正在尝试学习如何从 Cox-PH 生存模型模拟生存时间。我写了 Cox-PH 模型、生存函数（来自 Cox-PH）和累积风险的公式（如何从 Cox-PH 回归中恢复生存函数？）：
$$ h(t|\mathbf{x}) = h_0(t)\exp(\mathbf{x}^T\boldsymbol{\beta}) $$
$$ S(t|\mathbf{x}) = [S_0(t)]^{\exp(\mathbf{x}^T\boldsymbol{\beta})} $$
$$ H(t|\mathbf{x}) = H_0(t)\exp(\mathbf{x}^T\boldsymbol{\beta}) $$
似乎我们需要利用以下关系（累积风险是否始终呈指数分布？）：
$$ H(T|\mathbf{x}) \sim \text{Exp}(1) $$
基于这些先决条件，以下是我对如何从拟合的Cox-PH：

生成一个随机指数：
$$ E \sim \text{Exp}(1) $$

求解方程中的 $T$：
$$ H_0(T)\exp(\mathbf{x}^T\boldsymbol{\beta}) = E $$
$$ T = H_0^{-1}(E\exp(-\mathbf{x}^T\boldsymbol{\beta})) $$


这就是我感到困惑的地方。似乎您仍然需要为基线风险选择分布？ （即用于反演）
下面我尝试通过写出指数分布和威布尔分布的风险来继续这一过程，并写出模拟生存时间的公式：
$$ h_0(t) = \lambda $$
$$ H_0(t) = \lambda t $$
$$ T = \frac{E}{\lambda\exp(\mathbf{x}^T\boldsymbol{\beta})} $$
$$ h_0(t) = \lambda\gamma t^{\gamma-1} $$
$$ H_0(t) = \lambda t^{\gamma} $$
$$ T = \left(\frac{E}{\lambda\exp(\mathbf{x}^T\boldsymbol{\beta})}\right)^{1/\gamma} $$
那么，我们应该根据什么来选择基线风险的概率分布？我认为这是半参数 Cox-PH 模型的全部优势，即不需要选择概率分布（例如在估计参数时）。但似乎如果我们想从 Cox-PH 模拟生存时间，仍然需要选择分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/660718/how-to-select-a-probability-distribution-for-the-cox-ph-model</guid>
      <pubDate>Wed, 29 Jan 2025 15:18:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 lavaan 中的 SEM 修改指数？</title>
      <link>https://stats.stackexchange.com/questions/660722/how-to-interpret-modification-indices-for-a-sem-in-lavaan</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660722/how-to-interpret-modification-indices-for-a-sem-in-lavaan</guid>
      <pubDate>Wed, 29 Jan 2025 15:17:23 GMT</pubDate>
    </item>
    <item>
      <title>r 面板数据 - 哪个标准误差 - Driscoll-Kraay，Beck-Katz，还是减少偏差的线性化估计量？</title>
      <link>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</link>
      <description><![CDATA[使用面板数据（不平衡），我想知道应该对以下 plm 使用哪种标准误差来理解事件的影响（跨用户相同）：
m = plm(y ~ x + time + event + time:event, 
data=df, 
index=c(&quot;user_id&quot;, &quot;date&quot;),
model=&quot;within&quot;, 
effect = &quot;individual&quot;)

数据包括嵌套在 800 多个用户中的 ~400,000 个观察值，其中几个用户的观察值很少，而其他用户的观察值则很多。
为了解释异方差和自相关，不确定我们是否应该使用 Driscoll-Kraay 标准误差、Beck-Katz 或 CR2 偏差减少线性化估计器：
lmtest::coeftest(m, vcov = vcovSCC(m, type = &#39;HC1&#39;)) ##Driscoll-Kraay
lmtest::coeftest(m, vcov = vcovBK(m, type = &#39;HC1&#39;)) ##Beck-Katz
clubSandwich::coef_test(m, vcov = &quot;CR2&quot;, cluster = df$user_id) ##Bell &amp; McCaffrey (2002); Pustejovsky &amp; Tipton (2017) 

虽然幸运的是，感兴趣的变量的重要性对于假设检验来说并没有太大变化，但不确定哪一个最适合使用。
它们是否都解决了异方差性和自相关性问题，但只是在解决方式上有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</guid>
      <pubDate>Wed, 29 Jan 2025 15:08:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 构建和预测每日功能曲线（电力供应）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</link>
      <description><![CDATA[我正在处理一个大型电力市场数据集（约 9700 万行），时间跨度从 2022 年 12 月 1 日到 2024 年 12 月 20 日。主要列如下：
[&#39;PURPOSE_CD&#39;, &#39;STATUS_CD&#39;, &#39;UNIT_REFERENCE_NO&#39;, &#39;INTERVAL_NO&#39;, &#39;BID_OFFER_DATE_DT&#39;, &#39;QUANTITY_NO&#39;, &#39;AWARDED_QUANTITY_NO&#39;, &#39;ENERGY_PRICE_NO&#39;, &#39;MERIT_ORDER_NO&#39;, &#39;PARTIAL_QTY_ACCEPTED_IN&#39;, &#39;ADJ_QUANTITY_NO&#39;, &#39;ZONE_CD&#39;, &#39;AWARDED_PRICE_NO&#39;, &#39;OPERATORE&#39;]

我已过滤掉 OPERATORE == 的行&quot;Bilateralista&quot;（这些对应于不通过市场的双边合同，因此它们具有“虚假”或未知的价格）。我还只保留 PURPOSE_CD == &quot;OFF&quot;（官方报价）的行。我已将日期字段 BID_OFFER_DATE_DT 转换为适当的日期时间（格式 &#39;%Y%m%d&#39;）。
接下来，对于每个日期和每个小时（由 INTERVAL_NO 给出），我按 ENERGY_PRICE_NO 对数据进行分组并求和 QUANTITY_NO。然后我按价格排序并计算累计数量以构建供应曲线的“阶梯”版本。由于我需要更平滑的表示，我应用样条/核平滑将这些阶跃函数转换为连续、非递减曲线$S(p)$。因此，本质上，对于每一天和每小时，我最终得到一个一维函数$S_t(p)$，其中$t$表示时间（天 + 小时），$p$表示价格轴。
我的目标：

以时间序列的方式预测这些剩余供应曲线（平滑函数）。
理想情况下，我希望实现函数自回归模型（如 FAR(1) 或类似模型）或广义加性模型 (GAM) 方法，将每条每日/每小时曲线视为函数时间序列中的观测值。我很好奇是否有现有的 Python 库或工作流程可以更直接地处理：

函数自回归模型，或
函数 GAM（其中每个函数都是响应），或
推荐使用 Python 进行函数时间序列预测的“最佳实践”方法。



问题：

鉴于我已经为每个时间点建立了平滑的、非递减的供应曲线，哪种建模方法（函数自回归、函数数据的 GAM 或其他方法）最适合将这些曲线预测为时间序列？
是否有任何 Python 库或生态系统（类似于 R 中的 FDA 包）提供现成的函数时间序列建模方法（例如 FAR(1)、FPCA 等）？
如果不，您是否建议在曲线上实施 PCA 以降低维数，然后在主成分上使用标准时间序列模型（ARIMA、VAR 甚至神经网络）？
在现实世界中，像这样的高频数据集中构建功能预测时，我应该记住哪些实际考虑因素（例如，训练/测试拆分、性能指标、处理缺失的小时/日期）？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</guid>
      <pubDate>Wed, 29 Jan 2025 14:51:20 GMT</pubDate>
    </item>
    <item>
      <title>SEM 中因果关系的作用（示例）</title>
      <link>https://stats.stackexchange.com/questions/660714/role-of-causality-in-sem-via-an-example</link>
      <description><![CDATA[我问过一个关于SEM和解释结构系数的先前问题，但我找到了一个更实质性的例子，并决定提出一个新问题来帮助我理解。
在《结构方程模型：第二门课程》一书中由 Hershberger 等人撰写，讨论了这对模型：

这些是统计上等效的模型，即给出相同的隐含协方差矩阵和拟合指标。在他们的例子中，他们说
$$ b_{\text{V2V1}} = 0.470, b_{\text{V3V2}} = 0.361 \rightarrow b_{\text{V2V1}}b_{\text{V3V2}} = 0.170 $$
$$ b_{\text{V1V2}} = 0.522, b_{\text{V2V3}} = 0.433 \rightarrow b_{\text{V1V2}}b_{\text{V2V3}} = 0.226 $$
换句话说，$V1$ 对 为class=&quot;math-container&quot;&gt;$V3$ 或反之亦然，具体取决于所选的模型。
我通常认为，“如何绘制箭头”（即断言什么因果关系）的选择应该有实质性理论作为依据。但鉴于此示例，感觉您选择的理论（结合您的数据）现在对一个变量对另一个变量的影响做出了定量预测。如果两个方向都有合理的理论论据，那么人们几乎可以任意选择根据您的研究问题做出的定量论据。
这是正确的理解吗？我以前真的想将 SEM 中的箭头视为真正的双向箭头，即我无法从中推断出任何因果关系。也许我确实无法从 SEM 中推断出因果关系，但我可以从构建 SEM 模型所用的理论中推断出因果关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/660714/role-of-causality-in-sem-via-an-example</guid>
      <pubDate>Wed, 29 Jan 2025 14:00:31 GMT</pubDate>
    </item>
    <item>
      <title>测试回归斜率是否接近零</title>
      <link>https://stats.stackexchange.com/questions/660713/testing-if-a-regression-slope-is-close-to-zero</link>
      <description><![CDATA[我正在编写一个程序，希望在其中找到某个信号的本底噪声。为此，我对缓冲区执行线性回归，直到遇到斜率为零，这应该告诉我我的缓冲区已充满本底噪声。
这意味着我必须能够判断观察到的斜率是否确实为零。但是，标准线性回归程序通常会为您提供测试的 p 值或统计量
$H_0$：斜率为零
$H_1$：斜率非零（或单侧替代中的正或负）
我想要的是实际上相反的测试，我希望能够拒绝零假设“$H_0$：斜率非零”。但这个问题感觉像是不适定的，我不确定如何计算这个测试的 t 统计量。有没有好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/660713/testing-if-a-regression-slope-is-close-to-zero</guid>
      <pubDate>Wed, 29 Jan 2025 13:44:02 GMT</pubDate>
    </item>
    <item>
      <title>如何用 IPW（WeightIt/weightthem）正确调整混杂因素，并用 adaptedCurves 绘制调整后的生存曲线？</title>
      <link>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</link>
      <description><![CDATA[我正在估计两组之间的总体生存率 (OS) 差异，同时调整混杂因素。我的工作流程包括：

缺失数据的多重插补。
使用 weightthem 包进行逆概率加权 (IPW)，方法为 &quot;cbps&quot; （estimand = &quot;ATE&quot;）。
使用 bal.tab() 和 love.plot()（来自 cobalt 包）检查平衡。
对加权数据进行 Cox 回归（在每个插补数据集中使用 coxph_weightit()）。
绘制调整后的生存曲线（使用 adjustedCurves 包，方法为 &quot;iptw_cox&quot;）。

以下是我的代码：
# 1. 生成 IPW 权重
w.out_model1 &lt;- weightthem(
formula_OS, 
data = df, 
method = &quot;cbps&quot;, # 例如 &quot;ebal&quot;、&quot;cbps&quot;、&quot;glm&quot; 等。
estimand = &quot;ATE&quot;,
criterion = &quot;smd.mean&quot;,
link = &quot;logit&quot;
)

# 2. 检查 IPW 前后的平衡
bal.tab(
w.out_model1, 
data = df, 
s.d.denom = &quot;pooled&quot;, 
m.threshold = 0.1, 
v.threshold = 2, 
imp.fun = &quot;max&quot;, 
un = TRUE, 
abs = TRUE,
binary = &quot;std&quot;
)

love.plot(
w.out_model1, 
stats = c(&quot;mean.diffs&quot;), 
Thresholds = c(m = 0.1), 
abs = TRUE, 
var.order = &quot;alphabetical&quot;,
grid = TRUE,
drop.distance = TRUE,
wrap = 20,
binary = &quot;std&quot;
)

# 3. 通过 coxph_weightit 在每个估算数据集上拟合 Cox 模型
fit.imp.cox &lt;- with(
df,
WeightIt::coxph_weightit(
Surv(OS_from_target_local_treatment, death) ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary + Treatment_type_tumor_near_gallbladder
)
)

# 4. 来自 Cox 的汇总结果模型
summary(mice::pool(fit.imp.cox), conf.int = TRUE, exponentiate = TRUE)

# 5. 使用 adaptedCurves 绘制调整后的生存曲线
adj &lt;- adaptedsurv(
data = df,
variable = &quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time = &quot;OS_from_target_local_treatment&quot;,
event = &quot;death&quot;,
method = &quot;iptw_cox&quot;,
times = c(12, 36, 60, 96, 120),
bootstrap = TRUE,
n_boot = 500,
n_cores = 10,
treatment_model = Treatment_type_tumor_near_gallbladder ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary,
weight_method = &quot;cbps&quot;
)

plot(adj, use_boot = TRUE, risk_table = TRUE, risk_table_stratify = TRUE, 
censoring_ind = &#39;lines&#39;)

经过此分析，我发现两组之间的 OS 没有统计学上的显著差异。但是，我想确认我的步骤是正确的，并且是 IPW + Cox 建模的最佳实践。此外，我想在调整后的生存曲线上绘制置信区间，但无法让它们出现在 adaptedCurves 生成的图中。

我的整体工作流程（多重插补中的 IPW + 通过 coxph_weightit 的 Cox 模型 + 通过 adaptedCurves 绘图）是否适合估计两组之间的调整生存曲线？

在使用 adaptedCurves 和 IPW 时，如何包含置信区间？我看到 use_boot =TRUE 选项，但置信区间仍未显示在最终图中。是否有不同的参数或已知的解决方法？


任何有关最佳实践、替代方法或调试技巧的指导都将不胜感激。提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</guid>
      <pubDate>Wed, 29 Jan 2025 12:02:36 GMT</pubDate>
    </item>
    </channel>
</rss>