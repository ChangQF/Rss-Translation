<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 15 Mar 2025 09:16:41 GMT</lastBuildDate>
    <item>
      <title>人口规模的置信区间</title>
      <link>https://stats.stackexchange.com/questions/662655/confidence-interval-for-the-size-of-a-population</link>
      <description><![CDATA[说我想估计数字 $ n $ 在urn中的球中的球 $ n $ 球（无替换）。球从 $ 1 $  to  $ n $ 和让 $ z $ 表示样品的最大值。
一个人可以证明 $ z $  is  $ e（z）= \ frac {n} {n+1}（n+1}（n+1）$  $ \ hat { z（1+ \ frac {1} {n}） -  1 $ 是 $ n $ 的无偏估计器。  $ \ hat {n} $  is  $ v（\ hat {n}）= \ frac {（n-n+1）}
我想使用Chebyshev的不平等来计算 $ n $ 以95％的置信度为95％的置信区间，前提
我将如何执行此操作而不近似差异 $ v（\ hat {n}）$ （例如，用 $ n $   $ z $ z $ 最好只使用马尔可夫的不等式 $ p（| \ hat {n} -n |＆gt; a）＆lt; \ frac {]]></description>
      <guid>https://stats.stackexchange.com/questions/662655/confidence-interval-for-the-size-of-a-population</guid>
      <pubDate>Sat, 15 Mar 2025 08:36:51 GMT</pubDate>
    </item>
    <item>
      <title>平均统计值还是平均其相应的p值？</title>
      <link>https://stats.stackexchange.com/questions/662654/average-the-statistic-values-or-average-their-corresponding-p-values</link>
      <description><![CDATA[说我正在计算 hopkins统计范围聚类趋势的。统计量将数据云与在同一空间区域中随机和均匀模拟的点云进行比较。在零假设中，数据是统一的随机，统计量已知遵循β分布。因此，我可以计算统计量的P值。如果p值不显着，我们得出结论数据的群集不超过随机均匀点。。
由于可以多次模拟随机点的云，因此可以多次计算统计值及其相应的p值。然后，一个人希望对多个测试的总和结果产生总体印象。什么是：的利弊

 平均p值的多个实例; 

 平均统计量的多个实例，然后计算一个
该平均统计量的P值。

]]></description>
      <guid>https://stats.stackexchange.com/questions/662654/average-the-statistic-values-or-average-their-corresponding-p-values</guid>
      <pubDate>Sat, 15 Mar 2025 08:27:10 GMT</pubDate>
    </item>
    <item>
      <title>LSTM优于线性回归</title>
      <link>https://stats.stackexchange.com/questions/662653/lstm-outperform-linear-regression</link>
      <description><![CDATA[我们知道，简单方法表现良好，尤其是样本外（这是重要的地方）很普遍。这种效果在短系列中变得更强大。
 i有 tec 时间序列的数据。但是，当我尝试根据较短的培训期（例如，每三天的窗口连续）预测（例如每第四天）时，我观察到LSTM的表现要优于线性回归。
我想知道这是不寻常的吗？这是否意味着我正在使用的时代系列很奇怪？]]></description>
      <guid>https://stats.stackexchange.com/questions/662653/lstm-outperform-linear-regression</guid>
      <pubDate>Sat, 15 Mar 2025 06:20:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的Copula模型关闭了？</title>
      <link>https://stats.stackexchange.com/questions/662652/why-is-my-copula-model-off</link>
      <description><![CDATA[我是第一次是自学的，主要是使用由索斯滕·施密特（Thorsten Schmidt）作者。我主要学习这件事是为了模拟基于Copula的发行版的数据，我需要该项目，该项目正在从事工作。在将学习应用于任何真实数据之前，我想确保我了解自己在做什么，所以我决定查看玩具模型。
 i生成 $ x $  as  $ \ Mathcal {n}（0，1）$ ，并让 $ y = x+y = x+x+epsilon $ sim 是高斯噪声。
 导入matplotlib.pyplot as plt
导入numpy作为NP

n = 10000
噪声= 1

x = np.random.normal（0，1，n）
y = x + np.random.normal（0，噪声，n）
 
  $ x $ 根据定义是正常的， $ y $ 应该基于两个高斯随机变量添加的方式。双变量正态分布似乎只是3个因素的产物：两个高斯和相关因素，我希望这是我的模拟数据的结果分布，所以我认为尝试一个高斯copula是有意义的。&gt; 
我对如何从这种副本中采样的理解是：首先，用x和y之间的协方差矩阵从标准的双变量正态分布中生成样品，作为参数：
 导入scipy.stats作为统计
导入数学

samples = stats.multivariate_normal.rvs（平均= [0，0]，
                                        cov = np.cov（x，y），
                                        尺寸= n）
 
以生成点的CDF使其均匀：
  uniform_samples = stats.norm.cdf（示例）
 
最后，通过应用逆CDF（python中的PPF）将统一样品转换回原始空间：
  ointer_samples = np.empty_like（uniform_samples）
onigral_samples [：，0] = stats.norm.ppf（uniform_samples [：，0]，
                                        比例= 1）
onigral_samples [：，1] = stats.norm.ppf（uniform_samples [：，1]，
                                        比例= Math.sqrt（2））
 
请注意，X值的PPF来自 $ \ Mathcal {n}（0,1）$ ，如果来自 $ \ mathcal {n} n}（0,2）$  $ x $ 和 $ Y $ 已定义。但是，当我这样做时，来自copula仿真的数据和直接模拟的数据似乎并不排队
  direct_fit_slope，direct_fit_intercept = np.polyfit（x，x，y，1）
x_fit = np.linspace（-5，5，10000）
direct_fit = direct_fit_slope*x_fit + direct_fit_intercept
copula_fit_slope，copula_fit_intercept = np.polyfit（oilter_samples [：，0]，
                                                    onigral_samples [：，1]，
                                                    1）
copula_fit = copula_fit_slope*x_fit + copula_fit_intercept

图，ax = plt.subplots（）
AX.Scatter（X，Y，Alpha = 0.03）
ax.Scatter（Original_samples [：，0]，Original_samples [：，1]，alpha = 0.03）
ax.Scatter（[]，[]，C =;＃1f77b4＆quot; label =;直接模拟＆quot; alpha = 0.3）
ax.scatter（[]，[]，c =;＃ff7f0e; label =; copula Simulation＆quot; alpha = 0.3）
ax.plot（x_fit，direct_fit，c =“＃1f77b4
ax.plot（x_fit，copula_fit，c =“＃ff7f0e”
ax.set_xlim（-5，5）
ax.set_ylim（-10，10）
ax.legend（）
 
    [246]：direct_fit_slope
OUT [246]：NP.Float64（0.9881371016103613）

在[247]中：copula_fit_slope
OUT [247]：NP.Float64（1.390232088699879）
 
我必须缺少一些东西。有人可以帮我了解发生了什么事吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/662652/why-is-my-copula-model-off</guid>
      <pubDate>Sat, 15 Mar 2025 06:04:40 GMT</pubDate>
    </item>
    <item>
      <title>计算错误项的NLME :: GLS（）的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</link>
      <description><![CDATA[我在这里试图与 nlme :: gls（）一起工作，因为这是我发现的最佳解决方案。我想找到类似的数据：
  stdconc_dil＆lt;  -  1：200
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））
 
我正在尝试对 2标准偏差项进行不确定性估计，而不是斜率。 （实际上，我试图完全删除坡度，直接制​​作y〜x + varconstprop（），但我未能找到解决方案。）
如果我可以提取诸如完整协方差矩阵或黑森州之类的东西，则 solve（），它可能会为我做。
 tia！]]></description>
      <guid>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</guid>
      <pubDate>Fri, 14 Mar 2025 21:46:41 GMT</pubDate>
    </item>
    <item>
      <title>两年之间分析盐度数据的最佳统计方法</title>
      <link>https://stats.stackexchange.com/questions/662644/best-statistical-approach-to-analyze-salinity-data-between-two-years</link>
      <description><![CDATA[我有兴趣确定盐度在特定河口的湿年中与干燥年份之间的几个月之间的变化。例如，2000年1月的盐度与2010年1月有很大不同，等等。
数据具有：站点，盐度，年和月列。有4个站点，每个站点都有自己的每日盐度价值，每天在这个时间范围内。我想知道确定这一重要性的适当统计假设检验是什么，以及我是否应平均值进行比较或仅作为每日平均值。任何建议都将不胜感激：）]]></description>
      <guid>https://stats.stackexchange.com/questions/662644/best-statistical-approach-to-analyze-salinity-data-between-two-years</guid>
      <pubDate>Fri, 14 Mar 2025 21:45:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在两个不同n样品中比较相同的回归模型</title>
      <link>https://stats.stackexchange.com/questions/662643/how-to-compare-the-same-regression-model-in-two-samples-with-different-n</link>
      <description><![CDATA[我阅读了一些类似问题的答案，例如在这里href =“ https://stats.stackexchange.com/questions/39227/comparing-regression-coeffitic--with-with-same-model-model-model-but-two-distinct-samples”&gt;在这里，但他们不满意我。
我的问题是我想将两个回归模型与一个互动术语进行比较。
具体来说，我想验证模型之间的模型是否有所不同（编码虚拟编码）。
要创建三向互动术语列（IV X IV X国家 /地区），我是否应该结合数据集并重新计算双向交互项（国家之间的双向互动项的相同方式），还是应该保留旧的交互项（国家之间的双向互动术语的不同手段）？
对我来说，似乎并没有回答“结合后要做什么”的问题。
预先感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/662643/how-to-compare-the-same-regression-model-in-two-samples-with-different-n</guid>
      <pubDate>Fri, 14 Mar 2025 21:38:27 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的不同可读性指标与文本复杂性的主观测量相关。我要求18个人阅读12条短文，我衡量他们认为每个文本都有5项李克特调查的困难（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
提供一些示例，一个度量标准可能将第一文本的复杂性评为4，第二个文本的复杂性，而另一个指标自身尺度上的标准将与10和12的相同文本评分，同时，一个参与者对前两个文本的复杂性的主观得分是3和4的第4条。我们只想找出他们与参与者的主观分数有多相关。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息。多级模型在这里是否合适？
评论：这个问题类似于]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>检查核密度估计的L2标准的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</link>
      <description><![CDATA[让  $ \ hat {f} _n $ ， $ n \ in \ Mathbb {n} $ 是kernel密度估计器和 $ f $ f $  true dement&gt; true dementy。我想检查 $$ \ sqrt {nh}（\ lvert \ hat {f} _n \ rvert_2- \ lvert f \ rvert f \ rvert_2）
收敛到 $ \ mathbb {r} $   $ nh \ rightarrow \ rightarrow \ infty $ 时，收敛到任何普通的随机变量， $ \ mathbb {r} $ ，并且找不到任何结果。。
我们无法使用功能增量方法来证明这一点，因为通过 $ \ sqrt {nh}（\ hat {f} _n-f）$ 收敛到功能空间上的任何内容，它可能是0。因此，我尝试使用中心限制定理。第一个问题是 $ \ lvert \ hat {f} _n \ rvert $ ， $ n \ in \ in \ mathbb {n} $ 是独立的。但是我找不到随机函数独立性的定义。另外，我们没有像中心限制定理中的随机变量总和。因此，我不确定我是否处于正确的方式。非常感谢您的提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</guid>
      <pubDate>Fri, 14 Mar 2025 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>椭圆形的数据或随机变量的示例？</title>
      <link>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</link>
      <description><![CDATA[我正在研究一些神经科学模型，这些模型可以被认为是在椭球上分布数据。在这些模型中（例如， 1 ，， 2 ）有一些随机变量 $ \ sqrt {y^t b y} $ ，其中 $ b $ 是一种对称的正定矩阵。结果变量 $ z = y / \ sqrt {y^t b y} $ &lt; / span&gt;在椭圆形的表面上。一个相关的替代变量 $ z = y/\ sqrt {y^t b y + c} $ 其中 $ c $ 是一个积极的标量，是一个积极的标量。
我想知道在其他领域的椭圆机上是否有类似的数据示例或随机变量。例如，一些深度学习应用程序项目高维特征在球体上（例如 href =“ https://academic.up.com/biostatistics/article/9/1/66/253727” rel =“ nofollow noreferrer”&gt;一些生物信息学应用程序。但是，我还没有找到将向量投射到椭圆上的一个示例。有这样的例子吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</guid>
      <pubDate>Fri, 14 Mar 2025 20:24:01 GMT</pubDate>
    </item>
    <item>
      <title>GridSearch结果与学习曲线</title>
      <link>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</link>
      <description><![CDATA[我正在使用GridSearchCV来优化XGBoost模型上的一些超级参数。但是，尽管根据域知识，logloss（我正在优化的度量）似乎还不错，但学习曲线显示出过度拟合的经典迹象。为了减少过度拟合，手动调整超出拟合的参数（可能是XGBOOSTING，由于其对过度拟合的敏感性）是正常的吗？还是我不正确地解释学习曲线？
  &lt;img alt =“用于neg log损失的优化”]]></description>
      <guid>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</guid>
      <pubDate>Fri, 14 Mar 2025 18:27:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么一些自变量有巨大的性病错误？</title>
      <link>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</link>
      <description><![CDATA[我想知道我的结果是否正确。我不明白为什么四个独立变量有大的性病错误。
以下是GLM调用：
致电：
  glm（公式=练习〜Urban_zone + peri_urban_zone + rural_zone + 
    remote_rural_zone + num_female_age_10_30 + num_female_age_31_51 + 
    num_female_age_52_72 + num_female_age_73_90plus + num_male_age_10_30 + 
    num_male_age_31_51 + num_male_age_52_72 + num_male_age_age_73_90plus + 
    num_no_education + num_lower_primary + num_upper_primary + 
    num_junior_secondary + num_senior_secondary + num_tertiary + 
    num_employed + num_unemployed + num_pensioners + num_learners， 
    family =二项式，data = beanpurepractice）
 
和结果：
 系数：（3由于奇异性而未定义）
                           估计标准。错误z值pr（＆gt; | z |）  
（截距）2.69299 2.60852 1.032 0.3019  
Urban_Zoneyes -6.17754 2.53048 -2.441 0.0146 *
peri_urban_zoneyes 16.33651 6566.01336 0.002 0.9980  
rural_zoneyes -1.48510 2.13068 -0.697 0.4858  
远程_rural_zoneyes na na na na na na na na na na na  
num_female_age_10_30 -2.27482 2.41113 -0.943 0.3454  
num_female_age_31_51 2.31677 2.66000 0.871 0.3838  
num_female_age_52_72 2.62843 2.80616 0.937 0.3489  
num_female_age_73_90plus 28.03286 5429.89633 0.005 0.9959  
num_male_age_10_30 2.17702 2.20519 0.987 0.3235  
num_male_age_31_51 -0.04994 3.15402 -0.016 0.9874  
num_male_age_52_72 2.23831 3.76589 0.594 0.5523  
num_male_age_73_90plus 21.97843 8491.96006 0.003 0.9979  
num_no_education 0.61582 2.44018 0.252 0.8008  
num_lower_primary 16.32515 5412.19502 0.003 0.9976  
num_upper_primary -0.71340 2.14795 -0.332 0.7398  
num_junior_secondary 0.42343 1.77102 0.239 0.8110  
num_senior_secondary 1.00463 1.47758 0.680 0.4966  
num_tertiary na na na na  
num_employed 0.05111 2.88391 0.018 0.9859  
num_unemployed 0.63221 2.06144 0.307 0.7591  
num_pensioners -4.4.00465 3.29184 -1.217 0.2238  
num_learners na na na na na na na na  
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

（二项式家族的分散参数为1）

    空偏差：94.242在119自由度上
剩余偏差：31.062 on 100自由度
AIC：71.062

Fisher评分迭代的数量：21
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</guid>
      <pubDate>Fri, 14 Mar 2025 08:30:56 GMT</pubDate>
    </item>
    <item>
      <title>与自相关和部分自动相关的时间序列</title>
      <link>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 50，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 50，ax = axes [1]）
plt.show（）
 
我的输出：
对于 lags = 50  
  对于 lags = 100  
  对于 lags = 150  
  对于 lags = 250  
  对于 lags = 500  
  对于 lags = 900  
  从上面的图像中，我会说短/长滞后时的强大ACF相关性表明时间依赖性很大？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>如果一个变量在个人之间持续不变，我可以使用面板数据吗？</title>
      <link>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</link>
      <description><![CDATA[我正在研究一个小组模型，以分析地缘政治风险对商品市场的影响，但我遇到了挑战。由于商品价格是全球的，因此随着时间的流逝而不同。 
随着时间的推移，使用相同的价格值对不同国家/地区使用相同的价格值是有效的，或者这会使面板模型不适合分析？
这是我的模型：
 pcpi =α +β1.gpr +β2.EPU +β3.VIX + DCOV + DGFC +ε

 pcpi：的国家i的主要商品价格指数
 gpr：国家的地缘政治风险指数
 epu：t。
 vix：cboe波动率指数i在时间t。
 dcov：covid-19虚拟变量。
 DGFC：全球金融危机虚拟变量。
ε：错误项。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</guid>
      <pubDate>Thu, 13 Mar 2025 17:57:07 GMT</pubDate>
    </item>
    <item>
      <title>使用变压器（或其他ML）模型与结构化数据</title>
      <link>https://stats.stackexchange.com/questions/662532/using-transformer-or-other-ml-model-with-structured-data</link>
      <description><![CDATA[ 概述 
任务是我有许多不同的SQL表，对于每个表，都有多个相关的行和列。最大〜1K列在所有表中，通常更少。培训示例的每个表都有很大的相关行。
使用这些列中的数据（当前是人）来创建一系列离散值（一系列有限范围内的UINT和10个总值）。
 当前方法 
我当前的方法是以这种格式喂食GPT样式模型（Nanogpt）示例：
输入：
 ＆lt; table_column_token＆gt; ＆lt; line_token＆gt; ＆lt; value_tokens＆gt; ...重复非零列...＆lt; prev_output_tokens＆gt;
 

 table_column_token：特定表中的列的唯一令牌
 line_token：一个令牌指示这是哪一行
 value_tokens：数字值中的每个数字的令牌
 prev_output_tokens：已经预测的示例的令牌

目标：
 ＆lt; next_output_token＆gt;
 

 next_output_token：我们要预测的输出令牌或停止令牌

因此，真实数据被分解为每个输出令牌的另一个培训示例，再加上一个又一个用于“停止”的培训示例。输出令牌。
 问题 
这实际上可以正常工作，但有点盲目。
是“标记”这样的数据有意义吗？还是有更好的方法从这种可变长度结构化数据中提取功能？]]></description>
      <guid>https://stats.stackexchange.com/questions/662532/using-transformer-or-other-ml-model-with-structured-data</guid>
      <pubDate>Wed, 12 Mar 2025 17:46:20 GMT</pubDate>
    </item>
    </channel>
</rss>