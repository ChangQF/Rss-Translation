<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 13 Apr 2024 09:11:17 GMT</lastBuildDate>
    <item>
      <title>具有省略变量的非参数回归</title>
      <link>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</link>
      <description><![CDATA[假设我们使用核回归估计器$$\hat{m}(c)=\frac{\sum_{i=1}^n K\left(\frac{ x_i-c}{h}\right)y_i}{\sum_{i=1}^n K\left(\frac{x_i-c}{h}\right)}$$
其中 $h\to 0$ 和 $nh\to \infty$ 为 $n\to \infty$。
真正的 DGP 的形式为 $$y_i=\alpha +\beta x_i +\gamma z_i+\varepsilon_i$$
我假设 $\{(y_i,x_i,z_i)\}$ 是独立同分布的。并且所有变量都是绝对连续的，具有有限的二阶矩，并且在整个实线上具有正密度。我假设两个变量都具有严格的外生性，即 $\mathbb{E}[\varepsilon_i|x_i;z_i]=0$，并且 $x_i$ 和 $z_i$ 彼此独立。
我想知道 $\hat{m}(c)$ 收敛到什么对象。
为此，定义 $\hat{g}(c)=\frac{1}{nh}\sum_{i=1}^n K\left(\ frac{x_i-c}{h}\right)y_i$ 和 $\hat{f}(c)=\frac{1}{nh}\sum_{ i=1}^n K\left(\frac{x_i-c}{h}\right)$ 使得 $\hat{m}(c)= \hat{g}(c)/\hat{f}(c)$。很容易显示 $\hat{f}(c)\xrightarrow{p} f(c)$ 其中  $f(c)$ 是 $x$ 的 pdf。现在，让 $p(z)$ 为 $z$ 的 pdf，\begin{align*}
\mathbb{E}[\hat{g}(c)]
&amp;= \mathbb{E}\left[\frac{1}{nh}\sum_{i=1}^nK\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;= \frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i+\varepsilon_i) \正确的] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i)\right ] \\
&amp;= \frac{1}{h}\int_{\Omega}K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z)d\mathbb{P} \\
&amp;=\frac{1}{h}\int \int K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z)f(x)p(z) dxdz \\
&amp;=\int \int K(u)(\alpha +\beta (uh+c) +\gamma z)f(uh+c)p(z)dudz \\
&amp;= (\alpha + \beta c+\gamma \mathbb{E}[z])f(c) +o(1) \\
&amp;\xrightarrow{n\to \infty} (\alpha + \beta c+\gamma \mathbb{E}[z])f(c)
\end{对齐*}
我还可以显示 $\mathbb{V}[\hat{g}(c)]\to 0$ 显示 $\hat{g}(c)\xrightarrow{p} (\alpha + \beta c+\gamma \mathbb{E}[z])f(c)$.因此，我认为 $$\hat{m}(c)\xrightarrow{p}\alpha + \beta c+\gamma \mathbb{E}[z]$$
但是，我正在学习的课程的助教提到 $\hat{m}(c)$ 应该收敛到 $c$ 我显然没有得到。我认为原因可能是我假设 $x_i$ 和 $z_i$ 是独立的。但是，如果没有这个假设，我不确定如何找到 $\hat{m}(c)$ 的概率极限。
有人可以指出我工作中出错的地方，或者解释如何在不假设独立的情况下找到限制吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</guid>
      <pubDate>Sat, 13 Apr 2024 08:13:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 blme 避免 R 中混合模型中的奇异拟合 - 检查外行人的先验</title>
      <link>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</link>
      <description><![CDATA[在拟合线性混合模型时，我想避免零随机效应 (ranef(model)) 和集群级 SD 估计 (as.data.frame(VarCorr(model) ))[1,5])。这些可以在某些两级场景中由 lme4 R 包生成，即使模拟的采样总体是集群且异构的。零输出的典型符号是奇异拟合。 lme4 模型的另一个令人沮丧的特征是，在某些情况下，奇异拟合率似乎随着聚类数量的增加而增加。与直觉相反的是，随着输入的信息增多，模型会放弃并且不估计任何聚类级别的变化，即使模拟的抽样群体是异质的（如 ICC 0.05）。作为特定的背景细节，我希望至少有很小的 ranef(model) 和 as.data.frame(VarCorr(model))[1,5] 甚至如果群体确实是同质的（ICC 0.00），则在模型拟合后启用引导程序。我的目标模型是dependent ~ dicthomous_predictor + (1|cluster)。
作为 lme4 文档中建议的替代方案来管理这些问题，可以使用被称为“部分贝叶斯方法”的 blme R 包。经过测试，我可以验证，在默认先验优于随机效应/建模系数的协方差（cov.prior = Wishart 参数）的情况下，模型拟合的总体成功率随着 &lt;代码&gt;blme包。我所说的成功是指非零ranef(model)。然而，簇级 SD 估计值会超出图表，因为簇数量很少，例如两个，两者都具有 cov.prior = Wishart 和 cov.prior = gamma（让我们此时排除基本建议“获取更多测量/聚类”）。另一方面，当我模拟异质群体（例如国际商会 0.10-0.98）。另一方面，在没有奇异拟合的情况下，在不同数量的簇、簇大小和 ICC 中幸存下来的 lme4 模型的簇级 SD 估计更加平衡，与真实的簇级匹配更好我模拟的总体标准差。
因此，如果非奇异 lme4 模型的非零簇级估计值更高，我会很高兴。这就是为什么我想为 blme 模型找到一个合适的 cov.prior ，从而实现与非奇异  类似的非零簇级估计&gt;lme4 模型的成功率有所提高。
以下是 blme 文档中如何定义自定义先验的示例：
# 自定义优先级
惩罚Fn &lt;-函数(西格玛)
dcauchy(西格玛, 0, 10, log = TRUE)
(fm5 &lt;- blmer(反应 ~ 天数 + (0 + 天数|主题), sleepstudy,
cov.prior = 自定义（penaltyFn，chol = TRUE，scale =“log”）））

如有错误，请指正。我刚刚熟悉这个概念，还没有找到好的介绍材料。这是否是一种合理的方法，并且可以使用此 penaltyFn 来定义找到与总均值相关的聚类均值（更低或更高）的概率，类似于抛硬币吗？因此，如果我们假设总体呈正态分布，我们是否可以将 dcauchy() 替换为 dbinom()，如下所示：
penaltyFn &lt;- 函数(sigma) {
dbinom(sigma, 簇数, 0.5)
}
模型 &lt;- blmer（依赖 ~ dicthomous_predictor + (1|cluster)，数据，
cov.prior = 自定义(penaltyFn)))

这个原则是否有意义，实施情况如何？或者有人可以建议一种更好的方法来拟合dependent ~ dicthomous_predictor + (1|cluster)模型和其他提供的上下文？当前的结果并不完美，但根据测试 dbinom() 之前提高了获得非零 ranef(model) 的成功率，并在整个模拟中实现了更平衡的集群级 SD 估计。一个缺点是，如果模拟的抽样群体确实是同质的（ICC 和簇级 SD 均为零），即使有 30 个簇且簇大小为 30，簇级 SD blme 估计值也稳定在 0.75 左右，而 lme4 估计值更接近真实的零。通过对最小变化簇进行如此多的测量，我想知道为什么 dbinom() 先验会导致估计更高的簇级别 SD？我的逻辑和/或实现也可能没有意义。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</guid>
      <pubDate>Sat, 13 Apr 2024 07:39:10 GMT</pubDate>
    </item>
    <item>
      <title>当 Metropolis-Hastings 算法仅使用比例分布时，它如何从目标分布中进行采样？</title>
      <link>https://stats.stackexchange.com/questions/644921/how-does-the-metropolis-hastings-algorithm-sample-from-the-target-distribution-w</link>
      <description><![CDATA[我最近开始研究 M-H 算法，据我了解，它用于通过使用比例分布 f(x) 从复杂目标分布 P(x) 生成样本。这个想法是样本使用基于 P(x_new)/P(x_old) 的接受概率，这相当于 f(x_new)/f(x_old)。我的问题是样本如何直接收敛到 P(x)，而不是收敛到与 P(x) 成比例的其他分布。例如，如果目标分布是 P(x)/2，那么 M-H 算法的行为不是完全相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644921/how-does-the-metropolis-hastings-algorithm-sample-from-the-target-distribution-w</guid>
      <pubDate>Sat, 13 Apr 2024 07:07:16 GMT</pubDate>
    </item>
    <item>
      <title>确定结果变量的显着特征的最佳方法是什么</title>
      <link>https://stats.stackexchange.com/questions/644920/what-is-the-best-method-to-determine-the-significant-features-for-an-outcome-var</link>
      <description><![CDATA[我正在使用的数据集位于https://archive。 ics.uci.edu/dataset/45/heart+disease。
有 14 个属性，数据集包含数值变量和分类变量。有一个二分结果变量。
最好的方法是什么？我正在为一些分类变量制定假设，并运行费舍尔精确和卡方以确定统计显着性。对于数值变量，我正在考虑逻辑回归模型（类别不平衡）并根据变量的 p 值进行过滤。
有人可以证明这些方法是正确的吗？另一种选择是因素分析。然而，数据集是数字变量和分类变量的组合。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644920/what-is-the-best-method-to-determine-the-significant-features-for-an-outcome-var</guid>
      <pubDate>Sat, 13 Apr 2024 06:15:50 GMT</pubDate>
    </item>
    <item>
      <title>倾向调整的最坏情况</title>
      <link>https://stats.stackexchange.com/questions/644918/worst-case-for-propensity-adjustment</link>
      <description><![CDATA[我正在研究因果 ML 下的各种 CATE 估计方法（x/t/s/r 学习器和因果森林）。我想知道是否存在已知的倾向调整困难的场景？ （即 CATE 估计偏差最大的设置），具有标准假设（倾向重叠、SUTVA 等）
是否有任何研究对此进行探索？比较不同倾向设置下的不同算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644918/worst-case-for-propensity-adjustment</guid>
      <pubDate>Sat, 13 Apr 2024 05:23:16 GMT</pubDate>
    </item>
    <item>
      <title>称重数据问题</title>
      <link>https://stats.stackexchange.com/questions/644914/weighing-data-issue</link>
      <description><![CDATA[我正在研究一个城市内电子烟的流行程度。我通过调查向居民收集了数据，我对称重数据有疑问。
由于调查结果中特定群体的代表性过高或过低，我做出了这样的假设：应根据城市人口中的年龄分布来权衡数据，并据此权衡我的数据。例如。我从人口普查中收集了每个年龄段（例如 18-24 岁、25-34 岁等）内的人口数量数据，然后将城市中每个年龄段的人口分布与我的数据进行比较，以获得所需的响应和根据权重因素。然后我用这些来获得加权数据，这可以更好地代表城市的人口统计数据。
我的问题是，如果我错了，请纠正我，但我应该只在跨代年龄类别或整个人口进行比较时使用这些加权数据。在查看一代人本身的具体反应时，请使用未加权的数据。
例如如果我试图了解当前用户、以前的用户、从未使用过的 18-24 岁人群对电子烟危害的看法 - 我应该只查看未加权的数据来进行这些比较？但如果我要了解当前电子烟用户对每个年龄段之间的危害的看法，我会使用加权数据吗？
我只是想在对不同因素进行数百次统计测试之前确认这一点。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644914/weighing-data-issue</guid>
      <pubDate>Sat, 13 Apr 2024 02:27:54 GMT</pubDate>
    </item>
    <item>
      <title>复杂随机变量的最小二乘回归</title>
      <link>https://stats.stackexchange.com/questions/644912/least-square-regression-of-complex-random-variable</link>
      <description><![CDATA[我查看了一些有关如何使用复杂随机变量计算最小二乘回归的答案。但我想知道以下内容：

作为多元最小二乘
回归，我们是否必须考虑实部和虚部之间的多重共线性？如果是这样，我们如何解决这个问题？

作为多元最小二乘回归，具有复数随机变量的最小二乘总是比单个实数变量更好，因为复数具有实部和虚部（即，像包含两个变量）？

]]></description>
      <guid>https://stats.stackexchange.com/questions/644912/least-square-regression-of-complex-random-variable</guid>
      <pubDate>Sat, 13 Apr 2024 00:56:28 GMT</pubDate>
    </item>
    <item>
      <title>风险价值/尾部风险价值</title>
      <link>https://stats.stackexchange.com/questions/644911/value-at-risk-tail-value-at-risk</link>
      <description><![CDATA[问题：设 X 为具有以下损失分布的随机变量
&lt;前&gt;&lt;代码&gt; k Pk
    0 0.50
 1000 0.30
 2000年0.10
 5000 0.06
10000 0.04

 – 计算 95% 的风险价值。
– 计算 95% 尾部风险价值。
大家好，以上是我需要帮助的问题。我尝试了公式
风险值 (%) = [预期回报 – (投资组合的标准偏差 x 置信区间的 Z 分数)]。然而，答案是否定的，这看起来并不正确。任何帮助，将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644911/value-at-risk-tail-value-at-risk</guid>
      <pubDate>Sat, 13 Apr 2024 00:01:35 GMT</pubDate>
    </item>
    <item>
      <title>两个原子光谱的兼容性</title>
      <link>https://stats.stackexchange.com/questions/644910/compatibility-of-two-atom-spectra</link>
      <description><![CDATA[我在实验室测量了未知元素发射线的波长。
我现在将这些值及其相对误差放在一个集合中（称为 x）。
现在我需要将我的测量结果与来自完全准确的源（存储在 xtrue 中）的已知值进行比较，也就是说，我必须检查两个光谱是否相同。
我应该如何计算这种兼容性？
我熟悉检验假设的概念，所以我的第一次尝试是定义类似于 chi2 的东西，所以在 python 中：
def chi2(x, xtrue, errs):
    如果 len(x) != len(xtrue) 或 len(xtrue) != len(errs): 返回 -1
    总和 = 0
    对于范围内的 i(len(x))：
        sum += abs(x[i] - xtrue[i]) / errs[i]

返回总和

我认为，在某种程度上，这是衡量我的测量质量的一个很好的指标，但我认为我无法以任何有意义的方式将其标准化，更不用说通过其分布找到 p 值了。&lt; /p&gt;
我错了吗？
处理此类问题有什么通用的方法吗？
我应该如何继续给出可靠的统计理由来解释为什么两个光谱相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/644910/compatibility-of-two-atom-spectra</guid>
      <pubDate>Sat, 13 Apr 2024 00:00:23 GMT</pubDate>
    </item>
    <item>
      <title>联结函数揭示不明显的统计依赖性（或缺乏统计依赖性）的令人信服的例子有哪些？</title>
      <link>https://stats.stackexchange.com/questions/644909/what-are-the-convincing-examples-of-copulas-uncovering-not-obvious-statistical-d</link>
      <description><![CDATA[什么是一个好的、有力且令人信服的例子，可以通过揭示一些不明显的统计依赖性来展示联结函数的威力？
我对对比联结函数与原始分布相关系数的简单计算的示例特别感兴趣。
类似这样的事情 - 双变量分布分量的（适当归一化的）相关系数并不表明它们之间存在很强的统计依赖性，但是这两个分量的 copula 分布显示了它们之间明显的依赖性（可能表现为值为 copula 分布计算的相关系数？）。或者相反-原始二元分布的相关系数表明有很强的依赖性，但其连接函数表明统计依赖性是“弱”的，或者只是不存在。
最感兴趣的是用公式描述的示例（以便可以生成样本，例如在 MATLAB 中），但如果有人可以指出特定的预先生成的二元分布数据集（或其图），那也可以。&lt; /p&gt;
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644909/what-are-the-convincing-examples-of-copulas-uncovering-not-obvious-statistical-d</guid>
      <pubDate>Fri, 12 Apr 2024 23:38:40 GMT</pubDate>
    </item>
    <item>
      <title>Lipschitz 函数类的伪维数是多少？</title>
      <link>https://stats.stackexchange.com/questions/644907/what-is-the-pseudo-dimension-for-lipschitz-function-class</link>
      <description><![CDATA[我正在尝试使用 Lipschitz 类的伪维度或令人震惊的数字，以 $L_2(P_n)$ 范数覆盖数字。]]></description>
      <guid>https://stats.stackexchange.com/questions/644907/what-is-the-pseudo-dimension-for-lipschitz-function-class</guid>
      <pubDate>Fri, 12 Apr 2024 23:17:11 GMT</pubDate>
    </item>
    <item>
      <title>如何建立轮廓似然模型进行估计？</title>
      <link>https://stats.stackexchange.com/questions/644906/how-to-make-the-profile-likelihood-model-for-estimation</link>
      <description><![CDATA[我尝试使用土壤中的化合物结果来制作年龄估计模型。最初，我使用多变量回归模型。然而，由于过度拟合问题，审稿人强烈建议使用轮廓似然而不是回归模型。我学习了轮廓似然法。我想仅使用轮廓可能性来制作估计模型。然而，我发现仅仅使用轮廓似然来建立估计模型是不可能的。它需要创建基本函数（如线性模型），然后应用似然度。
但我也听说没有人将似然法应用到线性回归模型中，因为结果是相同的，而且更复杂。我确信我的方式是错误的。但我不明白如何使用轮廓似然方法来开发估计模型。
你能帮我借一下你的大脑吗？如果您有任何建议，请告诉我。
这是我用来制作估计模型的原始代码。
Com1&lt;- c(-0.91475561, -1.39706018, -3.88102766, -2.15068888, 3.36007488, 8.09092947, 5.10511848, 4.98272449)
Com2＜-c(-0.642793922、-0.481519952、0.545645985、-0.151149253、-0.812447751、-0.363022089、4.288690815、0.523588945)
年龄 &lt;-c(20, 21, 22, 23, 93, 94, 95, 96)
ChemicalResult&lt;-data.frame(年龄、Com1、Com2)
RegModel &lt;-lm(Age~., data = ChemicalResult)
ExC1＜-c(0.00169)
ExC2＜-c(0.94)
Chem&lt;-data.frame（ExC1、ExC2）
名称(Chem)&lt;-c(“Com1”，“Com2”)
Expred&lt;-预测（PCR、化学）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644906/how-to-make-the-profile-likelihood-model-for-estimation</guid>
      <pubDate>Fri, 12 Apr 2024 23:05:15 GMT</pubDate>
    </item>
    <item>
      <title>回归悖论</title>
      <link>https://stats.stackexchange.com/questions/644915/regression-paradox</link>
      <description><![CDATA[我必须使用两个二分自变量进行二元逻辑回归。
我发现自己面临着一个悖论，我不知道如何处理。
在完整的数据库中，我有 377 名 volo_1=1 患者的 21 名 (5.6%) 死亡患者，以及 2766 名 volo_1=0 患者的 86 (3.1%) 名死亡患者，volo_1 1vs 0 的 OR 1.84 预测死亡 1 vs 0 。
因此，volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &gt;0，并且 volo_1=0 的死亡患者少于 volo_1=1 的死亡患者。
如果我将数据库替换为二分变量（RTS_cat2），我有两个新数据库，其中 volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &lt;0，并且 volo_1=0 的死亡患者比死亡人数更多volo_1=1 的患者。
怎么可能呢？
我该如何处理这个问题？
这是我有问题的数据：
&lt;前&gt;&lt;代码&gt;&gt; x &lt;- xtabs(~dead + 交互(volo_1, RTS_cat2), data = db)
&gt; X
     交互（volo_1，RTS_cat2）
死亡 0.0 1.0 0.1 1.1
    0 2485 283 195 73
    1 12 1 74 20

&gt;表（db$dead，db$volo_1）
   
       0 1
  0 2680 356
  1 86 21

&gt; full.model &lt;- glm(dead ~ volo_1 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡 1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 1.84 (1.13,3) 0.015 0.021
                                                       
对数似然 = -464.1848
观察次数 = 3143
AIC 值 = 932.3696

&gt; full.model &lt;- glm(morto ~ volo_1 + RTS_cat2 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
                 粗 OR(95% CI) 调整值OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1：1 vs 0 1.84 (1.13,3) 0.72 (0.42,1.24) 0.24 0.232
                                                                                     
RTS_cat2：1 vs 0 74.68 (41.26,135.18) 78.49 (43.12,142.9) &lt; 0.001＜ 0.001
                                                                                     
对数似然 = -289.3289
观察次数 = 3143
AIC 值 = 584.6577


db_rts &lt;- db[ 其中(db$RTS_cat2==1), ]

&gt;表（db_rts$morto，db_rts$volo_1）
   
      0 1
  0 195 73
  1 74 20
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测 morto ：1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.72 (0.41,1.27) 0.256 0.249
                                                          
对数似然 = -206.6552
观察次数 = 362
AIC 值 = 417.3104

db_rts1 &lt;- db[ 其中(db$RTS_cat2==0), ]

&gt;表（db_rts1$morto，db_rts1$volo_1）
   
       0 1
  0 2485 283
  1 12 1
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts1,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.73 (0.09,5.65) 0.765 0.754
                                                          
对数似然 = -82.6736
观察次数 = 2781
AIC 值 = 169.3472

]]></description>
      <guid>https://stats.stackexchange.com/questions/644915/regression-paradox</guid>
      <pubDate>Fri, 12 Apr 2024 22:47:07 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}[X^2]\leq k \mathbb{E}[X]^2$，第一时刻的上界第二时刻</title>
      <link>https://stats.stackexchange.com/questions/644905/mathbbex2-leq-k-mathbbex2-upper-bound-second-moment-from-first-mo</link>
      <description><![CDATA[设 $X$ 为以 $[0,1]$。 $\mathbb{E}[X^2]\leq k \mathbb{E}[X]^2$ 对于某些常量 $k$？如果不是，是否有任何关于 $X$ 的最小假设？
很容易证明这适用于伯努利随机变量，但我不确定它们是最糟糕的例子。
相关问题是对称 r.v. 的第一时刻的期望就方差而言，这表明该陈述对于一般 $X$（非非负）来说是错误的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644905/mathbbex2-leq-k-mathbbex2-upper-bound-second-moment-from-first-mo</guid>
      <pubDate>Fri, 12 Apr 2024 22:45:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 确定两种算法之间特异性的 p 值</title>
      <link>https://stats.stackexchange.com/questions/644916/determine-p-value-for-specificity-between-two-algorithms-using-r</link>
      <description><![CDATA[在 R 中，我有一个看起来像这样的数据框（2000 多行）：
示例 AlgoA AlgoB
FP TP
TN TN
TP TP
DFNTP
电子浮点法
FT TN TN
TP TP

TN/TP 等是通过将算法与真值集进行比较而得出的。
我通过执行常规计算生成了规格/感知值，并且还生成了 95% CI。
我现在只需要看看两组之间是否存在统计差异。这种情况我该怎么办？ AlgoA 和 AlgoB 完全无关，只是两种不同的实验室方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/644916/determine-p-value-for-specificity-between-two-algorithms-using-r</guid>
      <pubDate>Fri, 12 Apr 2024 20:01:50 GMT</pubDate>
    </item>
    </channel>
</rss>