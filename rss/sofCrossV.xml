<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 21 May 2024 12:26:48 GMT</lastBuildDate>
    <item>
      <title>查看 X 变化和 Y 变化之间关联的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</link>
      <description><![CDATA[分析两个变量变化之间的关联并考虑均值回归的正确方法是什么？
我已经计算了变量的增量变化分数𝑋
X 和 Y（例如，ΔX = X_time2 - X_time1），然后查看这些变化分数之间的相关性。然而，我的结果显示与我的假设相反的关联。我怀疑均值回归可能会影响我的结果，但我还没有找到太多关于这种影响如何影响两个变量变化之间关联的信息。
更好的方法是计算“变化”吗？使用线性模型的残差，例如 X_time2 ~ X_time1。此方法还允许我通过将协变量添加到线性模型来调整协变量。
具体问题：

均值回归如何影响变化分数之间的相关性？
使用线性模型（例如 X_time2 ~ X_time1）的残差来分析变量的变化是否是更合适的方法？
还有哪些其他推荐方法可以在控制基线值和潜在协变量的同时准确评估两个变量变化之间的关联？

任何对相关文献的想法或参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</guid>
      <pubDate>Tue, 21 May 2024 12:02:45 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助解释交互效果</title>
      <link>https://stats.stackexchange.com/questions/647686/need-help-interpreting-interaction-effects</link>
      <description><![CDATA[我有两个分类自变量（类别：治疗前/治疗后 [A、B、C]）和二元响应。
我在 R 中的回归输出如下：
 估计标准。误差z值Pr(&gt;|z|)
(截距)-1.16220 0.14103 -8.241＜ 2e-16 ***
类别之后 0.89254 0.24876 3.588 0.000333 ***
治疗B -0.03485 0.20577 -0.169 0.865513
治疗C 0.29998 0.30781 0.975 0.329771
类别之后：治疗B -0.73438 0.37841 -1.941 0.052295 。
类别之后：治疗C -0.47215 0.56504 -0.836 0.403382

交互作用项不具有统计显着性。但是“之后”治疗A的“治疗A”与“之前”的治疗显着不同。对于治疗A。
我的理解是，如果交互项不显着，那么结果就不能解释为交互效应。然而，我很难看出这怎么不是一种相互作用：之前/之后的效果仅在治疗 A 中才明显。我应该如何解释这一点？
这是交互图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/647686/need-help-interpreting-interaction-effects</guid>
      <pubDate>Tue, 21 May 2024 11:55:37 GMT</pubDate>
    </item>
    <item>
      <title>当存在发生率极低的竞争风险时，如何处理事件时间数据</title>
      <link>https://stats.stackexchange.com/questions/647685/how-to-handle-time-to-event-data-when-there-is-a-competing-risk-with-very-low-in</link>
      <description><![CDATA[我正在分析事件发生时间数据。主要结果是出院时间，并且存在死亡风险。竞争风险模型似乎是合适的，但我想知道如果第二个事件的发生率非常低：经历该事件的样本少于 5%，这是否仍然适用。
我正在考虑两种可能的选择：

使用特定原因模型并审查死亡。
假设估计策略：使用特定原因模型并将死亡时间计为缺失并估算出院时间。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647685/how-to-handle-time-to-event-data-when-there-is-a-competing-risk-with-very-low-in</guid>
      <pubDate>Tue, 21 May 2024 11:49:06 GMT</pubDate>
    </item>
    <item>
      <title>解释 LMM 中固定效应的相关性</title>
      <link>https://stats.stackexchange.com/questions/647681/interpreting-the-correlation-of-fixed-effects-in-a-lmm</link>
      <description><![CDATA[我计算了一个线性混合模型，其中因变量“兴趣”为这是按照 1-7 的等级和三个固定效应威胁级别、极端和超人性进行测量的，这些因素都是具有 2 个级别（0 和 1）及其相互作用的因素。这是我在 R 中的输出：
通过最大似然拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：兴趣~威胁等级 * 极限 * 超人性 + (1 | ID) + (1 | items_recode)
   数据：subset_data.long

     AIC BIC logLik 偏差 df.resid
  3691.9 3746.3 -1835.0 3669.9 1029

缩放残差：
    最小 1Q 中值 3Q 最大
-2.9717 -0.6725 0.0326 0.6630 2.8920

随机效果：
 组名称方差标准差
 ID（截距） 1.0635 1.0313
 items_recode（拦截）0.1141 0.3377
 残差 1.5537 1.2465
obs数量：1040，组：ID，130；项目重新编码，8

固定效果：
                                        估计标准。误差df t值Pr(&gt;|t|)
（截距）3.01350 0.23121 22.21688 13.034 6.94e-12 ***
威胁级别1 -0.22480 0.23895 263.69178 -0.941 0.3477
肢体1 2.11180 0.28221 12.57909 7.483 5.61e-06 ***
超人性1 0.01503 0.15155 924.30143 0.099 0.9210
威胁级别1：肢体1 0.16775 0.22866 927.72532 0.734 0.4634
威胁级别1：超人性1 0.15327 0.22966 929.31973 0.667 0.5047
肢体1：超人1 -0.43173 0.21860 938.21094 -1.975 0.0486 *
威胁级别1：肢体1：超人1 -0.10793 0.33440 948.21803 -0.323 0.7470
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
            （内部）thrtl1 extrm1 sprhm1 thrtlvl1:x1 thrtlvl1:s1 ext1:1
威胁等级1 -0.452
肢体1 -0.600 0.158
超级1 -0.308 0.298 0.266
thrtlvl1:x1 0.202 -0.453 -0.350 -0.329
thrtlvl1:s1 0.203 -0.453 -0.176 -0.661 0.509
外部1:s1 0.224 -0.217 -0.387 -0.727 0.477 0.481
thrtlv1:1:1 -0.146 0.332 0.253 0.476 -0.731 -0.732 -0.653

我很难理解固定效应的相关性，有时固定效应的相关性非常高。到目前为止，我的谷歌搜索也没有帮助我。有人可以解释一下这些相关性意味着什么吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647681/interpreting-the-correlation-of-fixed-effects-in-a-lmm</guid>
      <pubDate>Tue, 21 May 2024 10:48:57 GMT</pubDate>
    </item>
    <item>
      <title>将 tf.keras.metrics.Precision 添加到 TensorFlow 中的模型指标时出现 ValueError [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647680/valueerror-when-adding-tf-keras-metrics-precision-to-model-metrics-in-tensorflow</link>
      <description><![CDATA[我正在尝试使用 MobileNet 在自定义数据集上应用迁移学习。我的代码工作正常，直到我将 tf.keras.metrics.Precision(name=“ precision”) 添加到模型的指标中。添加此指标后，我在 model.fit 期间遇到以下错误：
update_confusion_matrix_variables y_pred.shape.assert_is_兼容_with(y_true.shape) ValueError：形状（无，4）和（无，1）不兼容
相关代码块：
导入tensorflow为tf
从tensorflow.keras.utils导入image_dataset_from_directory作为get_dataset

图像大小 = (224, 224)
preprocessing_layer = tf.keras.applications.mobilenet.preprocess_input
img_shape = img_size + (3,)

base_model = tf.keras.applications.MobileNet(
    输入形状=img_形状，
    include_top=假，
    权重=&#39;imagenet&#39;,
）

批量大小 = 32
训练集 = 获取数据集（
    &#39;某条路&#39;,
    随机播放=真，
    批量大小=批量大小，
    图像大小=img_大小，
）

班级名称 = train_set.班级名称
num_classes = len(类名)

base_model.trainable = False
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

输入 = tf.keras.Input(shape=img_shape)
k = 预处理层（输入）
k = base_model(k, 训练=False)
k = 全局平均层(k)
k = tf.keras.layers.Dropout(0.2)(k)

Prediction_layer = tf.keras.layers.Dense(
    类数，
    激活=“softmax”
）
输出=预测层（k）

模型= tf.keras.Model（输入，输出）

模型.编译(
    优化器=tf.keras.optimizers.Adam(learning_rate=0.0001),
    损失=tf.keras.losses.SparseCategoricalCrossentropy(),
    指标=[
        tf.keras.metrics.SparseCategoricalAccuracy(name=&#39;accuracy&#39;),
        tf.keras.metrics.Precision(name=“精度”),
    ]
）

自动调谐 = tf.data.AUTOTUNE

train_set = train_set.prefetch(buffer_size=AUTOTUNE)

历元 = 1
历史=模型.fit(
    动车组，
    纪元=纪元，
）

数据集被组织成子目录，其中每个子目录名称都是类标签。有四个类标签。
数据集加载和预处理似乎工作正常，因为模型在没有 tf.keras.metrics.Precision 指标的情况下进行训练。
在添加精度指标时会特别出现此问题。
epochs 出于实验目的特意设置为 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/647680/valueerror-when-adding-tf-keras-metrics-precision-to-model-metrics-in-tensorflow</guid>
      <pubDate>Tue, 21 May 2024 10:18:04 GMT</pubDate>
    </item>
    <item>
      <title>非正态分布相关小样本量的 t 检验</title>
      <link>https://stats.stackexchange.com/questions/647679/t-test-for-non-normally-distributed-dependent-small-sample-size</link>
      <description><![CDATA[我想测试治疗前后样本点的显著变化，但样本点很少，治疗前后组均不呈正态分布。我该怎么办，我有点迷茫。
TIA]]></description>
      <guid>https://stats.stackexchange.com/questions/647679/t-test-for-non-normally-distributed-dependent-small-sample-size</guid>
      <pubDate>Tue, 21 May 2024 10:14:01 GMT</pubDate>
    </item>
    <item>
      <title>调查样本量</title>
      <link>https://stats.stackexchange.com/questions/647678/sample-size-for-survey</link>
      <description><![CDATA[我的兴趣是对 1700 人进行一项具有统计意义的调查，这些调查可以分为不同的类别，因此每个人只属于一个类别。
我有两类兴趣：Cat1 由 700 人组成，Cat2 由 200 人组成。
我的调查应该由足够多的人完成，以便这两类人中的每一组都有显着的代表性，置信度为 95%，误差幅度为 5%，尽管这些值可以更改。
我知道误差幅度越大，样本就越小。到什么值才合理？
此外，考虑总体有限或无限对样本大小有何影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/647678/sample-size-for-survey</guid>
      <pubDate>Tue, 21 May 2024 10:12:50 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 的 RMSE 小于 SARIMA，该选择哪一个？</title>
      <link>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</link>
      <description><![CDATA[虽然用原始数据（第二个）绘制去季节值，但没有太大差异。阶数为 ARIMA(1,1,0) 和 SARIMA((1,1,0),(7,1,0,12))。虽然评估 ARIMA 的 RMSE 小于 SARIMA。
可以假设数据没有很强的季节性吗？或者可能是因为过度拟合导致 SARIMA 表现不佳？
另外，我应该选择哪种型号？ （原油价格时间序列分析（印度篮子）。
这里还有 RMSE：
rollingARIMA=6.1377,
rollSARIMA= 6.6290
]]></description>
      <guid>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</guid>
      <pubDate>Tue, 21 May 2024 10:04:57 GMT</pubDate>
    </item>
    <item>
      <title>证明输出的交叉熵随着输入的 KL 散度的减小而减小</title>
      <link>https://stats.stackexchange.com/questions/647674/prove-decreasing-cross-entropy-of-outputs-with-decreasing-kl-divergence-of-input</link>
      <description><![CDATA[我试图证明不等式$H(gt, y) &gt; H(gt,y_1)&gt; H(gt, y_2)$，假设 $D_{KL}(x, x_1) &gt; D_{KL}(x_1, x_2)$,
其中 $y = f(x)$，$gt$ - 基本事实，$D_{KL}$ - KL 散度，$H$ 是交叉熵，$f()$ 是一个单调函数。
假设将 $x$ 平滑到 $x_1$ 的水平后，交叉分类器 $f()$ 的熵损失减小，直到平滑之间的 KL 散度停止减小。
我尝试通过用 KL 散度表示交叉熵来证明这一点，但我总是陷入最初的 $D_{KL}(x, x_1) &gt; D_{KL}(x_1, x_2)$]]></description>
      <guid>https://stats.stackexchange.com/questions/647674/prove-decreasing-cross-entropy-of-outputs-with-decreasing-kl-divergence-of-input</guid>
      <pubDate>Tue, 21 May 2024 06:35:31 GMT</pubDate>
    </item>
    <item>
      <title>基础模型 ANOVA 和 Kruskal-Wallis</title>
      <link>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</link>
      <description><![CDATA[单向方差分析 ($Y_{ij}= u + t_i + E_{ij}$) 的基础模型是否与 Kruskal-Wallis 检验完全相同因为 KW 是非参数方差分析，还是有不同的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</guid>
      <pubDate>Tue, 21 May 2024 04:28:39 GMT</pubDate>
    </item>
    <item>
      <title>Quantile 函数的 Numpy 实现[重复]</title>
      <link>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</link>
      <description><![CDATA[我正在尝试围绕有限样本的分位数函数的实现，特别是在 numpy 中（这样做的主要原因：我正在研究保角预测）。我可能遗漏了一些明确的内容，欢迎任何人指出我的明显错误！
假设我们观察值 $\mathcal{X} = \{x_1, x_2 \ldots x_n\}$ 并且我们想要计算 $p \in [0, 1]$ 观察样本的分位数。因此，我们将这个有限样本的分位数函数表示为 $Q(q, \mathcal{X})$。
如果我检查分位数的维基百科页面 (https://en.wikipedia.org/wiki/分位数），我们将分位数定义如下：
$Q(p, \mathcal{X}) := x: P(X
我不是 100% 确定如何解释“$P(X”这里。我认为这是对 e.c.d.f 的引用。 (https://en.wikipedia.org/wiki/Empirical_distribution_function) $\mathcal{X}$。即，“$P(X”可操作为样本中小于 $x$ 的点的比例。因此，我们得到以下等效定义：
$Q(p, \mathcal{X}) = \text{sup}\{x \in \mathbb{R} : \text{ecdf}_\mathcal{ X}(x)＜ p\}$。
到目前为止一切都很好，我相信。假设 $\mathcal{X} = \{2,3,4,10 \}$。现在让我们检查 numpy 的实现：
将 numpy 导入为 np
v = np.array([2,3,4,10])
q_third = np.quantile(v, 1/3) # 3
断言 q_third == 3 # 这是真的！分位数正好是 3

我在这里不知所措。 numpy 告诉我 $Q(\frac{1}{3}, \{2,3,4,10 \}) = 3$。根据上面的定义，我预计 $Q(\frac{1}{4}, \{2,3,4,10 \}) = 3$ 。事实上，上面的定义是不明确的。据我了解，$ Q(\frac{1}{3}, \{2,3,4,10 \})$。
在线性插值（numpy 中的默认方法）下，我们可以假设 $Q(\frac{1}{3}, \{2 ,3,4,10 \}) \neq Q(\frac{1}{3}, \{2,3,4,10 \})$。所以，要么是我，要么是 numpy 错了。我倾向于认为 numpy 在这里一定是正确的，但我无法发现我的错误。如果有人能给我解释一下，我将不胜感激。
我承认有一个类似的问题（分位数的定义&lt; /a&gt;），但该问题的答案只是报告了上面相同的维基百科定义并引用了 R （与此上下文无关）。对我的示例中应用的逻辑 numpy 的解释（希望与我使用的符号相同）将被接受作为答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</guid>
      <pubDate>Mon, 20 May 2024 23:52:30 GMT</pubDate>
    </item>
    <item>
      <title>统计测试以查看一组是否大于另一组</title>
      <link>https://stats.stackexchange.com/questions/647653/statistical-test-to-see-whether-one-group-is-larger-than-the-other</link>
      <description><![CDATA[我有一个数据集，其中包含 2020 年至 2023 年 2 组中提供的福利的百分比。我可以使用任何统计测试来测试 A 组的百分比是否大于 B 组的百分比吗？每组的样本量为 4，因此非常小。
集团年份 Number_of_plans Plans_with_benefits 百分比
2020 51 51 100
2021年 160 160 100
个 2022 220 220 100
2023 320 320 100
乙 2020 4472 1617 40
乙 2021 4905 1876 42
乙 2022 4905 2205 46
乙 2023 5082 2496 49.1
]]></description>
      <guid>https://stats.stackexchange.com/questions/647653/statistical-test-to-see-whether-one-group-is-larger-than-the-other</guid>
      <pubDate>Mon, 20 May 2024 21:43:01 GMT</pubDate>
    </item>
    <item>
      <title>比较两个延迟测量组的方法</title>
      <link>https://stats.stackexchange.com/questions/647647/method-to-compare-two-latency-measurement-groups</link>
      <description><![CDATA[我有两个服务器软件 (DNS) 测量（或者更确切地说是两组或更多组测量）。
测量结果不服从正态分布，非常偏向0-1毫秒范围。
举个例子：

总计为 41178744
延迟如下所示：

&lt;前&gt;&lt;代码&gt; 37 ▽ 延迟: (2001) [24673509, 12560724, 360898, 248331, 173744, 137900, 116894, 102247, 84900, 76741, 76066, 62945, 56794, 53765、51767、51180、49078、48807、 48590, 48472, 47094, 45483, 43727, 40700, 38913, 37…, …]
    38[0]：24673509
    39[1]：12560724
    40[2]：360898
    41[3]：248331
    42[4]：173744
    43[5]：137900
    44[6]：116894
    45[7]：102247
    46[8]：84900
    47[9]：76741
    48[10]：76066
    49[11]：62945
    50[12]：56794
    51[13]：53765
    52[14]：51767
    53[15]：51180
    54[16]：49078
    55[17]：48807
    56[18]：48590
    57[19]：48472
    58[20]：47094
    [...]

大约有 2001 个桶。
生成的数据如下所示：

请注意，图表已“向下”倾斜。对于对数刻度，请参阅 https:/ /blog.apnic.net/2017/11/24/dns-performance-metrics-logarithmic-percentile-histogram/ 进行解释。
我几乎可以通过肉眼看出 main 分支的所有测量值都是相似的，而 each-qpcache-heavy 分支的所有测量值则不然，但我是几乎不知道如何使用统计方法来测试差异。
我使用以下代码将延迟数据转换回 python 中的完整数据集：
def gen_data_from_json(json):
    sum = json[&#39;stats_sum&#39;]
    数据 = []
    毫秒 = 1
    对于 sum[&#39;latency&#39;] 中的响应：
        对于 x 在范围内（resp）：
            数据.追加（毫秒）
        毫秒 += 1
    返回数据

我已经尝试过 Kolmogorov-Smirnov 检验，但失败了（即使在 main1 和 main2 组之间，p 值始终为 0.0）。
我尝试使用 Boxcox 对数据进行标准化，然后使用单向方差分析（和双向 t 检验），但 p 值再次仅为 0.0。
上述文章建议：
基于对数百分位直方图的监控/报警
&lt;块引用&gt;
如上所述，这些图表的形状非常稳健 - 例如，临时异常值几乎不会出现。只有网络或服务器条件的真正变化才会使图表移动。这使得这些百分位数特别适合监控。对最慢性能“1%”和“0.1%”设置限制既敏感又具体：它会检测到所有真正的问题，并且它检测到的所有问题都是真正的问题。

所以，也许我可以采取这条路线，从每组中选择最慢的 1%，然后使用它们。
举个例子，如果我只取结果字段中的最后一个值（即在 &lt;2000 毫秒内未回答的查询）：
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;打印（main_per）
[284243, 292413, 271626, 294025, 285524]
&gt;&gt;&gt;&gt;&gt;打印（每个_每个）
[910587, 898288, 894027, 892618, 879973]
&gt;&gt;&gt;&gt;&gt; stats.shapiro(main_per)
ShapiroResult（统计=0.9037228358106117，p值=0.4308025315693231）
&gt;&gt;&gt;&gt;&gt; stats.shapiro(each_per)
ShapiroResult（统计=0.9700229533553387，p值=0.8754009192891016）
&gt;&gt;&gt;&gt;&gt; stats.f_oneway(main_per,each_per)
F_onewayResult(统计=9280.58639361942，p值=1.505113310148663e-13)

或者，我可能可以在所有毫秒桶上执行此操作，但我不确定是否需要这样做。
但我不是统计学家，可能有一些更聪明的方法来处理这种倾斜的数据。
编辑：我可能应该补充一点，如果我们可以通过比较每个分支的两次运行来摆脱困境，那么这将为我们节省一些在 AWS 上的时间。因此，如果这可以做成多步骤，也会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647647/method-to-compare-two-latency-measurement-groups</guid>
      <pubDate>Mon, 20 May 2024 20:53:04 GMT</pubDate>
    </item>
    <item>
      <title>荟萃分析中死亡率结果的汇总风险比或粗事件（M-H 到 RR 或 OR）？</title>
      <link>https://stats.stackexchange.com/questions/647643/pooled-hazard-ratio-or-crude-events-m-h-to-rr-or-or-for-mortality-outcomes-in</link>
      <description><![CDATA[我正在执行 MA 来评估治疗 A 相对于安慰剂（或倾向匹配对照组）相对于全因死亡的效果。
我的 MA 中包含的所有研究都报告了原始事件和 HR（95% CI）（通常是 Cox 回归模型）。因此，我可以使用带有粗事件的 M-H 模型来执行汇总效果，或者使用逆方差 (LogHR) 来执行对比度水平。
我的问题是：哪种方法是最好的方法以及我应该如何以不同的方式解释汇总结果（LogHR 或 RR/OR 与 H-M）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647643/pooled-hazard-ratio-or-crude-events-m-h-to-rr-or-or-for-mortality-outcomes-in</guid>
      <pubDate>Mon, 20 May 2024 20:01:15 GMT</pubDate>
    </item>
    <item>
      <title>R 中 VAR 脉冲响应的 MSE</title>
      <link>https://stats.stackexchange.com/questions/647633/mse-of-var-impulse-responses-in-r</link>
      <description><![CDATA[我在 R 中使用 vars 库。如何计算使用 irf 函数生成的脉冲响应的 MSE？ irf 函数返回脉冲响应系数矩阵以及下置信区间和上置信区间。是否有其他方法可以计算我生成的脉冲响应的 MSE？]]></description>
      <guid>https://stats.stackexchange.com/questions/647633/mse-of-var-impulse-responses-in-r</guid>
      <pubDate>Mon, 20 May 2024 18:53:54 GMT</pubDate>
    </item>
    </channel>
</rss>