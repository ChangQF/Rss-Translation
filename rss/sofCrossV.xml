<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 18 Nov 2024 12:35:30 GMT</lastBuildDate>
    <item>
      <title>平均差异（连续数据）（元分析中）（组内非标准化或标准化平均差异）</title>
      <link>https://stats.stackexchange.com/questions/657438/mean-difference-continious-data-in-meta-analysis-within-group-unstandardize</link>
      <description><![CDATA[我正在做一个元分析项目，对这个主题完全陌生，所以任何建议都非常感谢。具体来说，如果你能提供参考或 R 代码，那将非常有帮助。在这个项目中，我们为一组患者提供了手术前后的两份不同的问卷（调查新疗法的有效性），以从 1 到 10 的等级对他们的疼痛程度进行评分。但是，有时有些人拒绝在手术后完成问卷，导致手术前后的样本量不同。
数据是这样的（随机示例）

研究 之前平均值 之前标准差 之前n 之后平均值 之后标准差 之后n
研究 1 5.1 8 22 4.1 3.1 21
研究 2 6.1 4.1 32 6.4 3.4 30



假设我们对所有研究都有相同的测量方法，并且我们将应用随机效应模型。我需要访问这项研究的相关值吗？是否有任何公式（或 R 中的代码）可用于比较前后分数？ （组内非标准化均值差异）

假设我们使用不同的测量方法，需要计算标准化均值差异。在这种情况下，我需要访问相关值吗？是否有任何公式（或代码）可用于比较前后分数？（组内标准化均值差异）

]]></description>
      <guid>https://stats.stackexchange.com/questions/657438/mean-difference-continious-data-in-meta-analysis-within-group-unstandardize</guid>
      <pubDate>Mon, 18 Nov 2024 10:07:57 GMT</pubDate>
    </item>
    <item>
      <title>在什么条件下 PCA 能够一致地估计动态因子模型中的潜在因子？</title>
      <link>https://stats.stackexchange.com/questions/657437/under-which-conditions-does-pca-consistently-estimate-latent-factors-in-a-dynami</link>
      <description><![CDATA[考虑一个包含 N 个时间序列和 T 个观察期的数据集。
假设每个系列 $x_t$ 都是根据以下模型从 单个（未观察到的）共同因子 $f_t$ 生成的：
$$
X_t = \Lambda f_t + \epsilon_t, \quad \text{with} \quad \epsilon_t \sim N(0, \sigma^2_\epsilon) \\
f_t = \rho f_{t-1} + v_t, \quad \text{with} \quad v_t \sim N(0, \sigma^2_v) \quad 和 \quad |\rho|&lt;1
$$
其中$X_t$ 是 $N \times 1$ 个观测值列向量，$\Lambda$ 是 $N \times 1$ 个&amp;;因子载荷&amp;;向量，表示公共因子如何影响每个观测序列，$\epsilon_t$ 是 $N \times 1$ 个高斯创新项向量，没有序列或横截面相关性。
公共因子 $f_t$ 遵循 AR(1) 动态，在两个方程中特质项 $\epsilon_t$ 和 $v_t$ 具有有限方差。
这应该是一个非常简单的动态因子模型设置。
在什么条件下，观测矩阵的第一个主成分应该一致地估计共同因子？
我有兴趣在小样本中测试不同因子提取方法的性能，为此我构建了一个蒙特卡罗模拟。然而，我观察到，随着我的（人工）数据集的横截面（N）增加，共同因子的估计值会恶化，估计因子系列与真实因子系列之间的均方误差（MSE）更高。我想知道为什么。
相反，我确实观察到，随着 T 的增加，估计值变得更加精确，MSE 更低。
为了获得人工数据集，我首先生成一个具有高斯误差项的 AR(1) 序列，以充当共同因子 $f_t$。然后，我随机抽取 N 个因子载荷来计算受其他高斯误差项污染的原始潜在序列的 N 个线性变换。例如，第一个观察到的序列如下：
$$
x_{1,t} = \lambda_1 f_t + \epsilon_{1,t}
$$
非常感谢您的回复！]]></description>
      <guid>https://stats.stackexchange.com/questions/657437/under-which-conditions-does-pca-consistently-estimate-latent-factors-in-a-dynami</guid>
      <pubDate>Mon, 18 Nov 2024 09:58:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么图像分类模型在仅增强少数类时表现更差</title>
      <link>https://stats.stackexchange.com/questions/657434/why-does-the-image-classification-model-perform-worse-when-augmenting-only-minor</link>
      <description><![CDATA[我在图像分类任务中遇到了数据不平衡（1:10 比例）的问题。
为了解决这个问题，我尝试了不同的不平衡训练策略，包括加权损失函数、不同的损失函数、加权随机采样器、数据增强等。
我尝试了仅在少数类和加权随机采样器上进行染色增强（因为它是组织病理学补丁）组合，以便少数类的增强数据与多数类的采样量相同。我根据此url中的建议实现了这一点。但是，正如您在损失和度量曲线中所看到的；蓝色 - 仅在少数类上进行增强，粉色 - 在两个类上都进行增强，这种策略最初似乎效果更好，然后在训练的后期性能急剧下降。
我想知道为什么会发生这种情况，如果您对如何在高度不平衡的数据上训练和评估模型有任何想法，那将很有帮助。
少数类增强和加权随机采样器的组合，似乎表现更差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657434/why-does-the-image-classification-model-perform-worse-when-augmenting-only-minor</guid>
      <pubDate>Mon, 18 Nov 2024 09:39:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ggmagnify() 放大插图是禁止的？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657433/why-do-ggmagnify-zoomed-in-insets-are-off-limit</link>
      <description><![CDATA[首先，我对 R 语言不是很熟悉，所以学了它。
其次，我的需求大部分是绘图，所以 ggplot 很有用。这个周末，我玩了一下 ggmagnify 包，结果显示结果很奇怪。
使用此代码，我得到了一个常规图，正如预期的那样
install.packages(&quot;ggmagnify&quot;, repos = c(&quot;https://hughjonesd.r-universe.dev&quot;, 
&quot;https://cloud.r-project.org&quot;))

library(tidyverse)
library(ggmagnify)

starwars %&gt;% 

ggplot(mapping = aes(x = mass,
y = height,
color = sex)) +

geom_point(show.legend = FALSE) +

geom_smooth(se = FALSE,
method = &quot;lm&quot;) +

labs(x = &quot;masse en kg&quot;,
y = &quot;taille en cm&quot;) +

theme_bw() +

geom_magnify(from = c(xmin = 0, xmax = 200, ymin = 50, ymax = 275),
to = c(xmin = 500, xmax = 750, ymin = 50, ymax = 140))


到目前为止，一切都很好，但是，当我尝试使用条件执行此代码时，情节并不像预期的那样：
starwars %&gt;% 

ggplot(mapping = aes(x =质量，
y = 高度，
颜色 = 性别)) +

geom_point(show.legend = FALSE) +

geom_smooth(se = FALSE，
method = &quot;lm&quot;) +

labs(x = &quot;质量和千克&quot;，
y = &quot;尺寸和厘米&quot;) +

theme_bw() +

geom_magnify(mapping = aes(from = sex == &quot;female&quot; &amp; 质量 &lt; 100),
to = c(xmin = 500, xmax = 750, ymin = 50, ymax = 140), 
zoom.size = 2)


然后，我尝试进行双重缩放（zoom2 应该从 zoom1 创建），看看会发生什么。代码：
starwars %&gt;% 

ggplot(mapping = aes(x = mass,
y = height,
color = sex)) +

geom_point(show.legend = FALSE) +

geom_smooth(se = FALSE,
method = &quot;lm&quot;) +

labs(x = &quot;mass in kg&quot;,
y = &quot;height in cm&quot;) +

theme_bw() +

geom_magnify(mapping = aes(from = sex == &quot;female&quot; &amp; mass &lt; 100),
to = c(xmin = 500, xmax = 750, ymin = 50, ymax = 140), 
zoom.size = 2) +

geom_magnify(from = c(xmin = 550, xmax = 700, ymin = 100, ymax = 125),
to = c(xmin = 1000, xmax = 1250, ymin = 200, ymax = 250))


我不明白 2 点：

为什么小缩放窗口偏移，而 to= 参数中的限制在轴限制范围内？
为什么这个代码块

 geom_magnify(mapping = aes（来自 = 性别 == “女性” &amp; 质量 &lt; 100),
to = c(xmin = 500, xmax = 750, ymin = 50, ymax = 140))

给出的结果与此相同吗？
geom_magnify(mapping = aes(from = mass &lt; 100),
to = c(xmin = 500, xmax = 750, ymin = 50, ymax = 140))

我尝试过的修复包括：

更改值或注释掉 zoom.size = 参数
使用 drop_na(mass, height) 删除 NA
更改 from = 和 to 的值=

如能得到任何帮助，我将非常感激，以便更好地了解我错在哪里以及如何错的。
祝您有美好的一天。]]></description>
      <guid>https://stats.stackexchange.com/questions/657433/why-do-ggmagnify-zoomed-in-insets-are-off-limit</guid>
      <pubDate>Mon, 18 Nov 2024 09:15:57 GMT</pubDate>
    </item>
    <item>
      <title>处理 SEM 中代表性不足的性别类别</title>
      <link>https://stats.stackexchange.com/questions/657429/handling-underrepresented-gender-categories-in-sem</link>
      <description><![CDATA[我将性别作为 SEM 中的协变量。我的数据包含 1,078 个案例，其中 29 个为“不想说”，8 个为“性别多样化”。
我将“不想说”视为 NA。但是，性别多样化群体非常小，这可能会导致不稳定。我应该：

将这些案例也视为 NA？
完全排除它们并定性报告结果？
使用其他方法？

不幸的是，我在网上找不到任何文献或建议。您通常如何处理此类案件？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657429/handling-underrepresented-gender-categories-in-sem</guid>
      <pubDate>Mon, 18 Nov 2024 08:19:31 GMT</pubDate>
    </item>
    <item>
      <title>随机增加参数族中的 MLE</title>
      <link>https://stats.stackexchange.com/questions/657427/mle-in-stochastically-increasing-parametric-family</link>
      <description><![CDATA[设 $X$ 具有累积密度函数 $F_{\theta}$，假设该族在 $\theta$ 上随机递增，即对于 $\theta_1&lt;\theta_2$，$F(x;\theta_2) \le F(x;\theta_1)$。
我们有一个数据点，$X$。我相信 $\theta$ 的 MLE 必须是 $X$ 的非递减函数。直观地看，这应该是正确的，因为对于较大的 $\theta$，$X$ 会趋于更大，因此较大的 $X$ 值也可能来自较大的 $\theta$ 值。但是，我无法证明这一点。我发现将随机增加的定义转化为关于可能性的陈述非常困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/657427/mle-in-stochastically-increasing-parametric-family</guid>
      <pubDate>Mon, 18 Nov 2024 07:42:21 GMT</pubDate>
    </item>
    <item>
      <title>非线性回归（泊松、负二项式）和机器学习算法需要进行多重共线性（共线预测因子）检查吗？</title>
      <link>https://stats.stackexchange.com/questions/657424/multicollinearity-collinear-predictors-checking-is-needed-for-non-linear-regre</link>
      <description><![CDATA[我正在读这本书：Max Kuhn 的《应用预测模型》。
在第 3.5 部分“移除预测变量”中，作者指出检查多重共线性（共线预测变量）对于线性回归很重要。
但是，我感到困惑，为什么需要检查非线性回归（泊松、负二项式）和机器学习算法（随机森林、支持向量机、k-最近邻和人工神经网络）的多重共线性？
这是因为多重共线性（根据我的理解）是针对线性关系的。此外，机器学习算法（随机森林）本身在处理过程中确实会消除变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/657424/multicollinearity-collinear-predictors-checking-is-needed-for-non-linear-regre</guid>
      <pubDate>Mon, 18 Nov 2024 04:16:47 GMT</pubDate>
    </item>
    <item>
      <title>广义线性模型真的需要假设误差的分布吗？</title>
      <link>https://stats.stackexchange.com/questions/657423/do-generalized-linear-models-really-need-to-assume-the-distribution-of-errors</link>
      <description><![CDATA[GLM 具有以下形式：
$$
g(\mathbb E[Y\mathop | X])=X^T\beta
$$
其中 $g$ 是链接函数。我们可以将矩条件写为
$$
Y=g^{-1}(X^T\beta)+\varepsilon,\\
\mathbb E[g^{-1}(X)^T\varepsilon]=0,
$$
其样本模拟给出了 GMM 估计量：
$$
\frac 1n\sum_{i=1}^ng^{-1}(X_i)^T[Y_i-g^{-1}(X_i^T\hat\beta_{\text{GMM}})]=0.
$$
有一点我不明白：许多在线资料都说 GLM 需要指定误差项的分布（例如高斯、泊松、二项式等），但这真的是 GLM 有效所需的假设吗？当指定函数 $g$ 时，我们只需要 GMM 估计量的矩条件即可有效（当模型正确指定时，即 $\mathbb E[\varepsilon \mathop |X]=0$，即为真，即使模型指定错误，我们仍然可以得到一个近似于“真实”$\mathbb E[Y\mathop | X]$ 的“最佳参数预测器”。那么为什么在 GLM 中经常假设误差分布呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/657423/do-generalized-linear-models-really-need-to-assume-the-distribution-of-errors</guid>
      <pubDate>Mon, 18 Nov 2024 03:54:18 GMT</pubDate>
    </item>
    <item>
      <title>估计具有未知偏差 $p \in [0,1]$ 的硬币的偏差，近似正态分布</title>
      <link>https://stats.stackexchange.com/questions/657417/estimating-bias-of-a-coin-with-an-unknown-bias-p-in-0-1-approximately-norm</link>
      <description><![CDATA[我已将此发布在 MSE 上，但有人建议将其发布在此处。假设您得到一枚硬币，其正面朝上的概率为 $p$。您不知道 $p$，但您知道 $p$ 是从 $[0,1]$ 中的某个截断正态分布中得出的，中心为 $1/2$。给定 $N$ 次翻转，您能对 $p$ 做出什么判断，您对此的置信度有多大？
由于我的问题很模糊，因此我不是在寻找具体答案，而是在寻找解决问题的方法。我对$p$从$[0,1]$均匀抽取的情况比较熟悉，但我不确定如何将推理应用到这种情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/657417/estimating-bias-of-a-coin-with-an-unknown-bias-p-in-0-1-approximately-norm</guid>
      <pubDate>Mon, 18 Nov 2024 00:10:22 GMT</pubDate>
    </item>
    <item>
      <title>预测模型和机器学习中的信噪比</title>
      <link>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</link>
      <description><![CDATA[对此问题的有趣评论涉及信噪比如何影响预测能力。更明确地说，信噪比如何影响预测的准确性？例如，信噪比究竟是什么意思？它对预测建模意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</guid>
      <pubDate>Sun, 17 Nov 2024 13:42:20 GMT</pubDate>
    </item>
    <item>
      <title>X-帕累托分布</title>
      <link>https://stats.stackexchange.com/questions/657358/x-pareto-distribution</link>
      <description><![CDATA[我有一个作业，其中我必须证明威布尔帕累托属于指数族，然后是项$a(x)$的均值和方差。
$g(x)=\frac{\beta c}{x}\{\beta log (\frac{x}{\theta})\}^{c-1}exp \{-(\beta log (\frac{x}{\theta})^c\}$
为此，我使用了Dobson，因为$g(y;\tau)=exp\{a(x)b(\tau)+c(\tau)d(x)\}$并得到$a(x)=log(x)-log (\lambda)$，$c(\tau) =-(\alpha log (\frac{x}{\lambda}))$, $b(\tau) = (c-1)log (\alpha)$ 和 $d(x)= -log (x)$。请检查这是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/657358/x-pareto-distribution</guid>
      <pubDate>Sat, 16 Nov 2024 13:19:44 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么数据引导可以修改来自同一分布的总体的斜率？</title>
      <link>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</link>
      <description><![CDATA[我正在引导一些样本来计算斜率（有替换）。一旦完成，应该具有相同分布的斜率就不会具有相同的分布。要清楚，我不是要求调试代码，而是要求理解为什么我会引入偏差。
这是 R 中可重现的代码：
library(plotly)

N&lt;- 3000
x &lt;- runif(N,0,1)*5
y &lt;- x + rnorm(N, 1, .2)
y2 &lt;- x + rnorm(N, 1, .2)
t.test(y,y2)
dummy &lt;- rep(c(TRUE,FALSE),each = N)
df &lt;- data.frame(x = c(x,x), y = c(y,y2), dummy = dummy)

fig &lt;- plot_ly() %&gt;%
add_trace(x = df[df$dummy == TRUE,]$x, y = df[df$dummy == TRUE,]$y) %&gt;%
add_trace(x = df[df$dummy == FALSE,]$x, y= df[df$dummy == FALSE,]$y)
图

boot_strap &lt;- function(data, n_bootstraps){
输出 &lt;- sapply(1:n_bootstraps, function(i){
tmp &lt;- data[sample(seq_len(nrow(data)), nrow(data), replace = TRUE),]
模型 &lt;- lm(y ~ x, data = tmp)
return(coef(model)[2])
})
返回（输出）
}

for (size in c(1e2, 2e2, 5e2, 1e3, 1e4)){
sample_1 &lt;- boot_strap(df[df$dummy == TRUE,], size)
sample_2 &lt;- boot_strap(df[df$dummy == FALSE,], size) 
print(paste0(&#39;Size: &#39;, size,&#39; - Pvalue: &#39;, t.test(sample_1, sample_2)$p.value))
}

fig &lt;- plot_ly() %&gt;%
add_histogram(sample_1) %&gt;%
add_histogram(sample_2)
fig

数据：


这里我们没有差异，因为来自同一人群（如第一个 T 检验所示）是预期的
但另一方面，斜率的分布明显不同。


我的偏见在哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</guid>
      <pubDate>Thu, 14 Nov 2024 13:56:47 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>指数族的不同参数化</title>
      <link>https://stats.stackexchange.com/questions/657191/different-parametrizations-of-the-exponential-family</link>
      <description><![CDATA[我在这篇文章 https://arxiv.org/pdf/1607.06450 中找到了公式 10，这是指数族的参数化，我认为可以这样写：
$$P(t|\eta,s)=e^{\eta t/s}e^{-g(\eta)/s}e^{c(t,s)}$$
我只是进行了简单的重命名，以便（稍微）与我在 Bishop（模式识别书）上找到的形式更兼容，我的版本中的公式 4.118：
$$P(t|\eta,s)=e^{\eta t/s}\frac{1}{s}h\left(\frac{t}{s}\right)g(\eta)$$
现在我明白了，对同一事物可以有不同的参数化，例如，我可以尝试看看，如果在第一个参数化中给定 e $g(*), c(*,*)$, $\eta$ ,$s$，我可以在第二个表达式中恢复第二种形式，选择新的 $g(*), h(*)$, $\eta$, $s$，反之亦然。得到的表达式对于任何 $t$ 都必须有效，这样我们才能确认我们能够在这两种方法下参数化相同的分布。
我开始做这个练习，如果需要，我可以展示我得到的结果，但在继续之前，我想问一下：
问题 1：文章中提供的第一个参数化是否众所周知？有参考资料吗？我总是找到 Bishop 的第二种形式。
问题 2：我是否应该简单地看看两种不同参数化的后果是什么，以及在什么情况下我们应该使用其中一种？]]></description>
      <guid>https://stats.stackexchange.com/questions/657191/different-parametrizations-of-the-exponential-family</guid>
      <pubDate>Wed, 13 Nov 2024 09:45:56 GMT</pubDate>
    </item>
    </channel>
</rss>