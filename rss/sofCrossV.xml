<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 15 Jan 2024 18:17:26 GMT</lastBuildDate>
    <item>
      <title>sklearn.metrics.r2_score 与 sklearn.LinearRegression.score</title>
      <link>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</link>
      <description><![CDATA[我正在使用 sklearn 来计算 X（真实年龄）和 Y（预测年龄）之间的决定系数。但是我为两种不同的方法获得了两个不同的值，据我所知，这应该是相同的。
这是带有直线拟合的数据。 （我知道这不太适合，但在研究模型架构之前我正在研究管道）

然后，尝试计算 R2 值，检查两种不同的方法。我做错了什么吗？
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; Xs
数组([[6.80000000e+001],
       [7.50000000e+001],
       [5.90000000e+001],
       ...,
       [1.15882924e-310]，
       [1.15882924e-310]，
       [1.15882924e-310]]）
&gt;&gt;&gt;&gt;&gt;伊苏
数组([[58.503006],
       [67.75964],
       [63.875973],
       ...,
       [67.37394],
       [67.37394],
       [67.37394]]）
&gt;&gt;&gt;&gt;&gt;回归器=线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.fit(Xs, Ys)
线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.score(Xs, Ys)
0.006946203557267383
&gt;&gt;&gt;&gt;&gt; r2_score(Xs, Ys)
-0.16379061117029314
]]></description>
      <guid>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</guid>
      <pubDate>Mon, 15 Jan 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>Keras 中一个二元向量与另一个二元向量的回归</title>
      <link>https://stats.stackexchange.com/questions/636928/regression-of-a-binary-vector-from-another-binary-vector-in-keras</link>
      <description><![CDATA[我正在尝试在 Keras 中建立 X 和 Y 之间的关系，其中 X= (1,30) 和 Y= (1, 10) .
我制作了模型，从X预测Y。我在生物学领域工作，我想通过预测Y的二元向量X 准确度 (90%)。
我将解释模式：X 是长度为 n 的二进制向量（例如，X(1,:) = [0/1, 0/1, ..., 0 /1]）。
Y 是长度为 m 的二元向量，其中 m  n（例如，Y(1,:) = [0/1, 0/1, ..., 0/1]）。
对于每个 X =&gt;是
数据是这样的：例如样本：
X = [1,0,1,1,1,0,1,0,1,0,1,1,0,1] 及其 Y=[0,1,1,1, 1,0,1]

我的目标是开发一种机器学习模型 M，它可以根据向量 X 预测向量 Y，准确度高于 90%。我只接受 1 位错误！不多了。
我的问题，我应该使用的最佳成本函数和损失函数是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636928/regression-of-a-binary-vector-from-another-binary-vector-in-keras</guid>
      <pubDate>Mon, 15 Jan 2024 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>基于直方图的数据驱动的分箱条件方法</title>
      <link>https://stats.stackexchange.com/questions/636923/data-driven-approach-to-binning-conditions-based-on-a-histogram</link>
      <description><![CDATA[（请注意，目前这都是假设，数据细节应该不那么重要）。
假设我有一个数据集，其中参与者花费了一定的时间来完成任务（下面的 x 轴）。这些参与者自然地大致分为两组：用时约 4 秒的组和用时约 11 秒的组。如果我想将参与者标记为“慢”或“慢”或“快”，我怎样才能合理地做到这一点？这种分箱方式叫什么？我应该从阅读哪些论文开始？等等
就这个问题而言，假设分组是有意义的，并且我很清楚导致它的原因。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636923/data-driven-approach-to-binning-conditions-based-on-a-histogram</guid>
      <pubDate>Mon, 15 Jan 2024 16:07:43 GMT</pubDate>
    </item>
    <item>
      <title>什么时候应该控制协变量？</title>
      <link>https://stats.stackexchange.com/questions/636922/when-should-one-control-for-covariates</link>
      <description><![CDATA[假设要估计下面因果图中 X 对 Y 的影响

是否应该将 Z 作为协变量（以及为什么/为什么不？）
例如，假设有人想要估计性别对力量的影响。为了举例说明，我们假设男性平均身高高于女性。
在估计性别对力量的影响时是否应该使用身高作为协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636922/when-should-one-control-for-covariates</guid>
      <pubDate>Mon, 15 Jan 2024 16:04:10 GMT</pubDate>
    </item>
    <item>
      <title>SEM，无潜变量的路径分析</title>
      <link>https://stats.stackexchange.com/questions/636919/sem-path-analysis-without-latent-variables</link>
      <description><![CDATA[如果中介分析仅包括观察到的变量，是否有必要在路径分析之前测试测量模型并进行 CFA？
除了假设之外，是否建议在路径分析本身之前进行其他分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/636919/sem-path-analysis-without-latent-variables</guid>
      <pubDate>Mon, 15 Jan 2024 15:24:35 GMT</pubDate>
    </item>
    <item>
      <title>通过 lmer 或 glmer 通过 Predict() 仅使用混合模型回归中的某些项进行预测</title>
      <link>https://stats.stackexchange.com/questions/636917/predicting-using-only-certain-terms-in-a-mixed-model-regression-via-lmer-or-glme</link>
      <description><![CDATA[使用 lm() 或 glm() 时，predict.lm() 或 Predict.glm() 函数允许仅使用预测变量的子集从模型中获取预测，同时设置其他变量的系数为零。例如，fit&lt;-lm(y~x1+x2)则predict(fit,type=“terms”,terms=“x1”)将给出给定x1的y的预测值，同时保持x2恒定为零。通过 pred.merMod 从 lmer 或 glmer 进行混合模型回归似乎没有相同的选项。有人知道解决方法吗？最好是另一个已经存在的函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/636917/predicting-using-only-certain-terms-in-a-mixed-model-regression-via-lmer-or-glme</guid>
      <pubDate>Mon, 15 Jan 2024 15:07:06 GMT</pubDate>
    </item>
    <item>
      <title>根据不完整的信息，你能在多大程度上估计随机变量的属性？</title>
      <link>https://stats.stackexchange.com/questions/636916/how-well-can-you-estimate-properties-of-a-random-variable-based-on-incomplete-in</link>
      <description><![CDATA[这是我一直在思考的一个问题：

假设有一些随机变量 $X$ 与 pdf $X \sim f(X; \theta_1,\ theta_2... \theta_n)$
A 每天能够从该随机变量中进行 100 次测量。 A 这样做了 100 次。
B 只能获取 A 每天 $X$ 的平均值。

现在，A 和 B 被告知 $X$ 的真实 pdf，并负责估计 $E (X)$ 和 $Var(X)$。
从逻辑上讲，在这种情况下，A 显然具有优势。不仅人 A 比人 B 拥有更多信息，而且人 A 拥有个人级别信息，而人 B 仅拥有聚合级别信息。
在这种情况下，如果我们指定 $f(X; \theta_1,\theta_2...\theta_n)$ 的一些选择和一些估计过程（例如经典 MLE）：是否有可能知道 A 的估计 $E(X)$ 和 $Var 有多接近与 B 的估计相比，(X)$ 会是他们的真实值吗？

PS：这个问题看起来很武断，但我认为它在社会科学中出现得不少。很多时候，社会学报告（例如人口普查）只会提供来自全国不同地区的一些随机变量的有限汇总信息（例如不同邮政编码的收入中位数）......以及未来其他研究人员群体（不涉及通过这些报告）必须使用有限的汇总级别信息来估计该随机变量的属性（例如均值、方差）。因此，我认为 B 的情况经常出现，我想知道当我们被迫使用有限的摘要级别信息来估计参数估计时，是否有可能知道参数估计有多不正确。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636916/how-well-can-you-estimate-properties-of-a-random-variable-based-on-incomplete-in</guid>
      <pubDate>Mon, 15 Jan 2024 15:05:11 GMT</pubDate>
    </item>
    <item>
      <title>分类变量的假设检验</title>
      <link>https://stats.stackexchange.com/questions/636915/hypothesis-testing-of-categorical-variable</link>
      <description><![CDATA[我从一份关于影响年轻毕业生就业能力的因素的调查问卷中提取了数据。问卷是由我班的学生回答的，所以我提取了他们的年龄、专业以及他们对我所做的一堆陈述的同意程度。将excel数据表中的数据导入R后，我进行了编码（将一致性程度转换为李克特量表），现在我想测试一些假设。
因此，在答案的数据框中，我们有这些成员代表与引号之间的每个命题的一致程度：
X1 =“缺乏专业经验是年轻毕业生就业的主要障碍。”
X2 =“年轻毕业生更有可能面临失业、不稳定和就业市场歧视。”
X3 =“就业市场在不断发展，新工作的出现和其他工作的消失。”
X4 =“年轻毕业生必须能够适应这些变化并培养满足就业市场需求所需的技能。”
X5 =“人口统计数据的变化将对就业市场产生重大影响。”
Y1 =“软技能对于年轻毕业生的专业融入至关重要。”
Y2 =“软技能包括沟通、协作、解决问题、批判性思维、适应能力和复原力。”
Y3 =“拥有软技能的年轻毕业生更有可能在工作和职业生涯中取得成功。”
Y4 =“雇主正在寻找能够团队合作、解决问题并适应变化的员工。”
Y5 =“软技能可以随着时间的推移而发展和提高。”
Z1 =“年轻毕业生的专业融入是摩洛哥的一项重大挑战。”
Z2 =“有利于年轻毕业生融入的因素包括经济增长、教育水平提高以及公共政策的实施。”
Z3 =“不利于年轻毕业生融入的因素包括失业率高、竞争加剧以及缺乏合适的培训。”
Z4 = “对于那些准备充分并具备必要技能的年轻毕业生来说，融入是可能的。”
Z5 =“激烈的竞争以及教育与就业之间的不匹配是摩洛哥年轻毕业生融入社会的具体挑战。”
我试图检验的假设如下：
H1：认识到软技能在专业整合背景下的重要性是一个重要的认识。
H2：激烈的竞争以及教育与就业的不匹配是年轻毕业生融入社会的挑战。
H3：专业经验是就业的重大障碍。
我的问题是，同时我没有二分变量“可以使用”的数据集，我该使用什么类型的统计模型来完成我的工作？我可以使用什么类型的测试来检查我的假设的有效性？
谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/636915/hypothesis-testing-of-categorical-variable</guid>
      <pubDate>Mon, 15 Jan 2024 14:27:46 GMT</pubDate>
    </item>
    <item>
      <title>将中值绝对偏差转换为标准偏差</title>
      <link>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</link>
      <description><![CDATA[我正在从事一些医学研究，我想知道将中位数和中位数绝对偏差 (MAD) 转换为平均值和标准差的最直接方法是什么。
如果有人有任何链接以及我可以引用的来源链接，这将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</guid>
      <pubDate>Mon, 15 Jan 2024 14:04:44 GMT</pubDate>
    </item>
    <item>
      <title>使用预定义系数拟合 glmmTMB 模式</title>
      <link>https://stats.stackexchange.com/questions/636792/fitting-a-glmmtmb-mode-with-pre-defined-coefficients</link>
      <description><![CDATA[我正在开展一项分析，其中使用 glmmTMB 进行多模型推理和模型平均，我将其用于有序 beta 分布，并且我想坚持使用。我挖掘了全局模型，采用 95% 的置信度集，并计算了每个预测变量的平均系数。然而现在，我想弄清楚这个平均模型对数据的解释效果如何。有没有办法用预定义的系数制作或拟合模型对象？然后我会在 k 折交叉验证和/或 Performance::r2 中使用它，但无论哪种方式我都需要一个模型对象。
这是一个例子：
数据 = data.frame(响应 = c(0.5, 0.2, 0, 1, 0.75),
         varA = c(0, 0.2, 0.4, 1, 0.8),
         varB = c(-0.4, -1.3, 0.3, 1.6, 0.8),
         varC = c(-1.2, -0.1, 0.5, 1.2, -0.3))

模型 &lt;- glmmTMB(响应 ~ varA + varB + varC,
                 family = glmmTMB::ordbeta(link = &quot;logit&quot;),
                 数据=数据）

model_dredge &lt;- MuMIn::dredge(模型)

#找到 95% 置信度的截止值
值 &lt;- 0

for (i in 1:nrow(model_dredge)){
  如果（值&lt;0.95）{
    值 &lt;- 值 + as.numeric(model_dredge$weight[i])
    model_cutoff &lt;- i
  } 别的 {}
}

conf_set &lt;- model_dredge[1:model_cutoff, ]

varA_coeff &lt;- stats::weighted.mean(conf_set$`cond(varA)`,
                               conf_set$权重，
                                   na.rm = T)
varB_coeff &lt;- stats::weighted.mean(conf_set$`cond(varB)`,
                               conf_set$权重，
                                   na.rm = T)
varC_coeff &lt;- stats::weighted.mean(conf_set$`cond(varC)`,
                               conf_set$权重，
                                   na.rm = T)

最终，我得到了一组与我的全局模型相似但不同的系数。我考虑进入全局模型对象并手动覆盖对象中的可变系数（例如， model$fit$par[1] 是截距，model$fit$par[2 ] 是 varA，等等。）但是，还有其他参数我不知道如何在不使用新平均系数重新拟合模型的情况下获得，其中一个标记为“betad”和两个标记为“psi”的。
有人可以建议 a) 如何使用 varA_coeff、varB_coeff 和 varC_coeff 拟合模型，b) 如何计算出“betad”和“psi”无需重新拟合模型，或者 c) 评估平均模型拟合度的替代方法？
真诚的，
科琳娜]]></description>
      <guid>https://stats.stackexchange.com/questions/636792/fitting-a-glmmtmb-mode-with-pre-defined-coefficients</guid>
      <pubDate>Sat, 13 Jan 2024 21:19:04 GMT</pubDate>
    </item>
    <item>
      <title>方差分析是此类应用的有效测试吗？</title>
      <link>https://stats.stackexchange.com/questions/636668/is-anova-a-valid-test-for-such-application</link>
      <description><![CDATA[上下文：
我们公司销售产品“A”到世界不同地区。我们的部门通过测量不合格产品和客户退货的百分比来衡量产品的可靠性。
每个区域有多个客户，但同一个客户不能在2个区域。我们按年份测量每个区域内的客户满意度（= 可靠产品百分比），然后测量同年和同区域的平均客户满意度，因此我们得到了/年/区域的总满意度。
目标：
我们想要评估产品“A”的平均可靠性是否符合要求。不同地区之间是相同的，或者某些地区存在显着差异。
方法：
建议的方法是对下面的数据使用方差分析

问题：

方差分析是比较该区域平均值的有效检验吗？
如果检验结果为正（并且我们拒绝原假设：性能 Region1 = Region2），则假设该区域与性能之间存在某种因果关系是否合理？

编辑
为了澄清这个问题，我们的目标不是估计每个区域的可靠性，而是评估每个区域的平均可靠性之间的差异是否具有统计显着性。]]></description>
      <guid>https://stats.stackexchange.com/questions/636668/is-anova-a-valid-test-for-such-application</guid>
      <pubDate>Thu, 11 Jan 2024 18:58:47 GMT</pubDate>
    </item>
    <item>
      <title>如何对重复测量的数据进行混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</guid>
      <pubDate>Thu, 11 Jan 2024 14:09:01 GMT</pubDate>
    </item>
    <item>
      <title>将一个脆弱值应用于混合效应 cox 回归中的所有观测值，然后重新计算生存概率</title>
      <link>https://stats.stackexchange.com/questions/636585/applying-one-frailty-value-to-all-observations-in-mixed-effects-cox-regression-a</link>
      <description><![CDATA[我想测试数据集中的每个观察值是否属于具有最差或最佳虚弱值的虚弱组的一部分，从而测试生存概率的差异。我想计算数据中最大“时间”的生存概率。 （这只是一个演示性思想实验，旨在展示随机效应如何影响结果）。
例如，在这个例子中，我想比较如果所有老鼠都在第 5 窝中，以及第 25 窝中的所有老鼠的死亡概率差异。
我尝试重新利用 riskRegression:::predictRisk.coxph.penal() 函数中的一些代码来创建我自己的函数。使用以下代码访问 cox 回归的 PredictRisk 函数背后的代码：
#访问风险回归代码
风险回归:::predictRisk.coxph.penal

我的推理是，如果我可以检索时间 t 时的基线风险、预测变量的线性方程以及该组的脆弱性，我应该能够计算时间 t 时每个观察值的生存概率。这是使用等式：
exp(-bhValue)^ (exp(frailval) * exp(线性Pred[i])
但是，我的队列中最高和最低的生存概率之间的差异似乎比我预期的要大（当前的示例是 11.5% 与 27.5%），这让我认为我当前的方程是错误的？我真的很感激有人来校对这段代码。
图书馆（生存）
库（风险回归）
图书馆（tidyverse）

大鼠 &lt;- data.frame(大鼠)
rats$litter &lt;- as.factor(rats$litter)
rats$sex &lt;- as.factor(rats$sex)
rats$rx &lt;- as.factor(rats$rx)

coxph.me &lt;- coxph(Surv(时间，状态) ~ rx + 性别 + 脆弱(垃圾)，
                  数据=大鼠）

frailty_risk &lt;- 函数（对象、簇、frail_group、df）{

  ### 获取特定的脆弱值###
  effects_list &lt;- as.data.frame(object$frail)
  # 获取组级别
  group_levels &lt;- 级别(df[[簇]])
  # 将组水平与脆弱性估计相结合
  effects_list &lt;- data.frame(Group = group_levels, frailty = Effects_list) %&gt;% 过滤器(Group == Paste(frail_group))
  
  打印（效果列表[,2]）
  # 检索脆弱值
  frailval &lt;- as.numeric(effects_list[, 2])

  ### 定义预测变量的线性组合 ###
  LinearPred &lt;- 预测（对象，newdata = df，se.fit = FALSE，
                        conf.int = FALSE)

  ### 在最大时间检索基线危险###
  basehaz &lt;- basehaz(object) %&gt;% 过滤器(时间 == max(时间))
  bhValue &lt;- basehaz[, 1] #检索基线危险值

  ### 应用生存概率方程###
  # 将每个观察的生存概率附加到数据帧
  survPred &lt;- do.call(“rbind”, lapply(1:NROW(df),
                                      # 应用生存概率方程
                                      函数（一）{
                                        (exp(-bhValue)^ (exp(frailval) * exp(线性Pred[i])))
                                    }））
  # 计算队列的平均 survPred
  p &lt;- 均值(survPred)
  # 计算死亡概率
  返回(1-p)

}


frailty_risk(coxph.me, &#39;垃圾&#39;, &#39;5&#39;, 老鼠)
frailty_risk(coxph.me, &#39;垃圾&#39;, &#39;25&#39;, 老鼠)
]]></description>
      <guid>https://stats.stackexchange.com/questions/636585/applying-one-frailty-value-to-all-observations-in-mixed-effects-cox-regression-a</guid>
      <pubDate>Wed, 10 Jan 2024 15:17:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性和样条项估计如此不同？</title>
      <link>https://stats.stackexchange.com/questions/636570/why-are-linear-and-spline-term-estimates-so-different</link>
      <description><![CDATA[我正在流行病学环境中进行建模。我想估计一次暴露（空气污染）和两个事件结果之间的关联。为了实现这一目标，我使用了具有时变暴露的 Cox PH 模型（我使用 R 中的survival 包）。
我定义了两个主要模型：

线性：coxph(Surv(time1, time2, event) ~ 协变量 + 曝光)
样条线：coxph(Surv(time1, time2, event) ~ 协变量 + pspline(exposure, df=4))

线性模型的估计关联通过暴露量增加 5 个单位来显示：

结果 1：HR= 1.21（95% 置信区间 = 1.03-1.43）
结果 2：HR= 1.22（95% 置信区间 = 1.00-1.50）

样条模型的估计关联如下所示，使用暴露的最低值（图中的 x）作为参考。

我不明白为什么尽管线性模型中的 HR 非常相似，但它们的曲线在样条模型中却如此不同。特别是，对于结果 1，我不明白当曲线大部分低于 1.00 时，线性 HR 为何会是 1.22，直到曝光量约为 12 (x $\approx$ 12)
HR 样条图的代码（由 Terry Therneau 简化和启发 教程）：
#数据提取
mod &lt;- coxph(Surv(time1, time2, event) ~ 协变量 + pspline(曝光, df=4), data=df)
pmterm &lt;- termplot(mod,terms = which(mod$pterms == 1),
                 se=真，图=假）
dtplot&lt;- list(pmterm = pmterm[[&quot;曝光&quot;]], 曝光 = df$曝光)

 
#数据格式化
 中心 &lt;- with(dtplot$spline, y[x==min(x)])
 ytemp &lt;- dtplot$样条$y + 外部(dtplot$样条$se, c(0, -1.96, 1.96), &#39;*&#39;)
 ytemp &lt;- exp(ytemp - center) #此行针对对数危险图进行了注释
 datspline &lt;- data.frame(cbind(dtplot$样条$x,ytemp))
 datexp&lt;- data.frame(dtplot$exp)
 名称(dat)&lt;-c(“exp”、“HR”、“低”、“上”)
 
#绘图
 ggplot(datspline, aes(x = exp)) +
 geom_line(aes(y=HR)) + geom_ribbon(aes(ymin=低, ymax=上),alpha = .1) +
 geom_histogram(aes(x=exp, y=10*(after_stat(密度))), binwidth=1,
        线宽=0，颜色=“firebrick3”，填充=“firebrick3”，alpha = 0.25，
        data=datexp) + #GEOM_HISTOGRAM 被排除在日志危险图之外
labs(title=paste0(“结果”,i), x = “暴露”, y = “HR (95% CI)”) + #y=“对数危险”对于对数危险图
主题_经典() +
geom_hline(yintercept = 1, lty = 2) + coord_cartesian(ylim = c(0,2.5)) #ylim=c(-0.5,0.5) 用于对数危险图
]]></description>
      <guid>https://stats.stackexchange.com/questions/636570/why-are-linear-and-spline-term-estimates-so-different</guid>
      <pubDate>Wed, 10 Jan 2024 11:29:09 GMT</pubDate>
    </item>
    <item>
      <title>从 GLMER 模型计算标准化回归系数</title>
      <link>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</link>
      <description><![CDATA[我有三个独立的 glmer 模型，调查三个不同空间位置的个人和家庭层面的疟疾感染风险因素：1) 森林外，2) 森林边缘，3) 森林内。
解释变量是连续变量、二元变量和分类变量的混合。结果变量是“疟疾感染”
我想要对不同空间位置的系数的相对重要性进行粗略比较，即每个位置的系数的排名。
我一直在阅读《计算标准化Logistic回归系数的六种方法》梅纳德（2004）。 美国统计学家，卷。 58号第3号，其中明确指出，对于系数的简单排序（和比较），文中提到的任何方法都是可以接受的。 （在他们的例子中，解释变量和我的一样，是连续变量、二元变量和分类变量的混合）。因此，最简单的方法是将非标准化系数乘以该系数所指的预测变量的标准差。
但是，我不知道如何从 glmer 输出中提取系数的标准差。我对具有标准差的二元或分类变量的想法尤其感到困惑。谁能给点建议吗？
其次，我在另一个论坛上读到了一篇未引用的帖子，其中提到一种可接受的、快速且肮脏的比较方法是对汇总输出中的 Wald 卡方求和，然后取每个变量的 Wald 卡方并将其除以总和。由此，可以制定一个粗略的排名。这是可以接受的措施吗？如果有的话，有什么参考资料吗？
我更喜欢前一种方法，但我需要帮助提取标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</guid>
      <pubDate>Wed, 03 Jan 2024 23:05:57 GMT</pubDate>
    </item>
    </channel>
</rss>