<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 23 Nov 2024 15:16:20 GMT</lastBuildDate>
    <item>
      <title>Copulas：通过伪观测还是通过 CDF 获得均匀边际分布？</title>
      <link>https://stats.stackexchange.com/questions/657725/copulas-obtaining-uniform-marginal-distribution-via-pseudo-observation-or-via-c</link>
      <description><![CDATA[我正在为时间序列分析考试学习 copula，为了练习，我们的教授给我们布置了一道关于财务数据的练习题。
练习的要点之一是拟合椭圆 copula 以估计两种资产的超额收益之间的相关性，现在我有一些问题。
我是否应该使用 vinecopula 包来拟合最佳椭圆 copula（高斯或 t）？否则，我应该如何知道 copula 的参数？
要拟合 copula，我需要将数据转换为它们的均匀分布，对吗？
我读到，要做到这一点，有两种方法：

使用 pobs() 函数计算伪观测值
如果我知道边际分布（在我的例子中，我尝试使用 fitdistrplus 包找到最佳分布），则使用 CDF 获得均匀分布（对这一点并不完全确定）

我尝试了这两种方法，它们返回不同的 copula，这是有道理的。但主要的问题是，当我制作两个边际均匀分布的散点图时，我得到了一个使用 CDF 获得的奇怪的图。
这是使用 cdf 的图：

这是使用伪观测的图：

提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/657725/copulas-obtaining-uniform-marginal-distribution-via-pseudo-observation-or-via-c</guid>
      <pubDate>Sat, 23 Nov 2024 14:36:15 GMT</pubDate>
    </item>
    <item>
      <title>单位根检验的功效</title>
      <link>https://stats.stackexchange.com/questions/657723/power-of-unit-root-tests</link>
      <description><![CDATA[我正在测试基本单位根检验的功效：ADF、PP 和 DFGLS。
具体来说，我正在生成这个序列：
$$y_t = \text{drift} + (\text{trend_coeff} \cdot t) + (\phi \cdot y_{t-1}) + e_t$$
对于 $\phi$ 的范围，介于 0 和 1 之间，包括 0 和 1。
从数学上讲，这从 [0,1) 得出一个趋势平稳过程：

在 $\phi$ = 1 时，它会产生一个具有随机趋势的过程：

对 $\phi = [0,1)$ 执行任何单位根检验都应拒绝零假设并接受平稳性，在 $\phi = 1$ 时，它应接受单位根的零假设。
期望：通过从结果中绘制 p 值，应该期望看到 $\phi = [0,1)$ 低 p 值（至少低于显着性水平），因为这将拒绝单位根检验的零值，并且看到 $\phi = 1$ 大 p 值（至少大于显着性水平），因为这意味着接受零值。
结果：
ADF 和 ADFGLS 都使用“AIC”，PP 使用 Newey-West 估计量进行滞后选择。
样本数量：300
drift=30
trend_coeff=10
sigma=20
模拟次数 = 20

问题：ADF-GLS 返回该钟形曲线的原因可能是什么？它不应该是 ADF 的改进版本吗？
注意：我在 python 中使用 Arch lib 中的 DFGLS。]]></description>
      <guid>https://stats.stackexchange.com/questions/657723/power-of-unit-root-tests</guid>
      <pubDate>Sat, 23 Nov 2024 14:04:38 GMT</pubDate>
    </item>
    <item>
      <title>使用权重来模拟比例结果的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/657719/what-is-the-best-way-to-model-a-proportion-outcome-with-weights</link>
      <description><![CDATA[我有一份有关监测覆盖时间比例（特定测试覆盖他们的时间/他们接受监测的总时间）的数据。例如，如果人员 A 参与研究的时间是 36.5 个月，他们在第一年参加了一次测试，在第二年参加了一次测试。假设每次测试覆盖他们 6 个月，他们的覆盖时间比例 (PTC) 将是 12/36.5= 0.33。两个人可以拥有相同的 PTC，但参与研究的时间不同。总研究时间和覆盖时间都可以是非整数。评估是否有任何特征与 PTC 相关以说明他们在研究中的时间的最佳方法（模型）是什么（因此，时间较长的那些具有更大的权重）。
一篇论文建议用（参与者在研究中的时间/所有参与者在研究中的时间总和）来加权每个参与者的 PTC。
我可以使用二项式逻辑回归吗？如果是这样，我不确定因变量和权重是什么。我一直使用二项回归的成功次数而不是比例。]]></description>
      <guid>https://stats.stackexchange.com/questions/657719/what-is-the-best-way-to-model-a-proportion-outcome-with-weights</guid>
      <pubDate>Sat, 23 Nov 2024 12:22:48 GMT</pubDate>
    </item>
    <item>
      <title>用两个数字变量解释分类变量 - 哪种方法合适？</title>
      <link>https://stats.stackexchange.com/questions/657718/categorical-variable-explained-by-two-numeric-variables-which-methods-are-appr</link>
      <description><![CDATA[我有以下情况：
我有一份患者名单，这些患者被给予了两种药物，药物 A 和 药物 B，两者都是数字，作为处方数量，以及他们的治愈成功记录，作为分类变量，“治愈”/“未治愈”。有些患者只服用了药物 A，有些只服用了药物 B，而其他患者则服用了两种药物。
我现在的目标是分析哪种药物对治愈有积极作用，考虑两种药物之间可能存在的相互作用。我正在考虑进行逻辑回归。但我想知道是否还有其他有用的方法可以考虑？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/657718/categorical-variable-explained-by-two-numeric-variables-which-methods-are-appr</guid>
      <pubDate>Sat, 23 Nov 2024 12:01:17 GMT</pubDate>
    </item>
    <item>
      <title>逻辑模型中的优势比</title>
      <link>https://stats.stackexchange.com/questions/657716/odds-ratio-in-a-logistic-model</link>
      <description><![CDATA[我在 R 中拟合了一个逻辑回归模型，获得了 95% 的准确率、0.98 的 AUC 得分、0.4 的 Brier 得分，灵敏度和特异性值约为 90%，因此我认为这是一个好的模型，而且我确信我没有过度拟合它，因为样本量足够大，我使用嵌套交叉验证进行训练，之前使用该数据集的工作具有相似的指标得分。但是当我使用来评估优势比时
# 优势比的整洁模型
OR_forward &lt;- tidy(model_forward, conf.int = TRUE, exp = TRUE)
# 查看
print(OR_forward)

我获得的模型
| term | 估计 | std.error | 统计 | p.value | conf.low | conf.high |
| -------------------- | --------------- | ---------------- | ---------------- | -------------- | --------------- | ---------------- |
| (截距) | 0.9803722 | 0.5585423 | -0.0354905 | 0.9716886222 | 0.34167844 | 3.099333e+00 |
| perimeter_worst | 138.4584082 | 1.6246777 | 3.0347988 | 0.0024069620 | 8.85712651 | 6.073470e+03 |
| smoothness_worst | 2.8558969 | 0.6659321 | 1.5758153 | 0.1150683769 | 0.86645297 | 1.232178e+01 |
| 纹理最差 | 21.1155988 | 0.8005182 | 3.8100470 | 0.0001389404 | 5.43421791 | 1.362067e+02 |
| 半径 | 249.6495402 | 1.7514729 | 3.1516663 | 0.0016234171 | 18.82154660 | 1.576302e+04 |
| 凹面点最差 | 12.5199362 | 1.3407680 | 1.8849810 | 0.0594324041 | 1.06768453 | 2.285697e+02 |
| 分形维数 | 0.1506027 | 0.6689871 | -2.8298153 | 0.0046574880 | 0.03406688 | 4.961252e-01 |
| 凹度平均值 | 13.0852042 | 1.1904412 | 2.1601084 | 0.0307642776 | 1.28731054 | 1.542539e+02 |
| 纹理维数 | 0.1935264 | 0.8072612 | -2.0344610 | 0.0419051325 | 0.03440948 | 8.765000e-01 |

这对我来说很奇怪。我对数据执行的唯一操作是使用 来缩放它们
data[-1] &lt;- scale(data[-1]) # 第一列是分类的

我还绘制了残差
plot(residuals(model_forward)) #stats library


因为据我所知，异常值可能会影响模型的 OR，但我认为我不能简单地将它们从数据中删除。有人能帮我理解为什么我的 OR 这么高并降低它们吗，或者我应该如何解释这些值？]]></description>
      <guid>https://stats.stackexchange.com/questions/657716/odds-ratio-in-a-logistic-model</guid>
      <pubDate>Sat, 23 Nov 2024 10:55:35 GMT</pubDate>
    </item>
    <item>
      <title>机器学习方法在行业中用于定价吗？</title>
      <link>https://stats.stackexchange.com/questions/657714/ml-approaches-to-pricing-in-industry</link>
      <description><![CDATA[这是一个非常模糊的问题。我很好奇行业内是如何定价的，特别是大型科技公司。我知道亚马逊不会根据用户进行价格歧视，因此价格实验是随着时间的推移而进行的。
但从更广泛的意义上讲，我想知道支付意愿分布是如何拟合的。如果你只收取一个价格，你就没有足够的数据来估计曲线。
更广泛地说，如果你假设一个线性模型，你会得到负价格的正需求和任意高价格的负需求。使用对数变换可能会有所帮助，但现在存在美元异方差问题（美元金额与误差之间的相关性），并且逻辑模型假设市场规模固定（40% 的市场将以此价格需求产品），但假设市场规模可以从外部很好地估计。
此外，随着需求预测，随着市场规模的波动（冬季市场上购买泳池用品的人较少），这变得更加复杂。
考虑到这里所有棘手的问题，参数模型是首选吗？还是更灵活的 ML 方法？
您看到什么在行业中获得了关注？]]></description>
      <guid>https://stats.stackexchange.com/questions/657714/ml-approaches-to-pricing-in-industry</guid>
      <pubDate>Sat, 23 Nov 2024 09:31:42 GMT</pubDate>
    </item>
    <item>
      <title>跨境不连续方法中的固定效应：包括县固定效应和州边界固定效应？</title>
      <link>https://stats.stackexchange.com/questions/657712/fixed-effect-in-cross-border-discontinuity-approach-include-both-county-fixed-e</link>
      <description><![CDATA[所关注的跨境不连续性方法使用以交错方式引入各州的州级事件，并涉及县级 GDP 作为因变量。我想知道我是否应该只考虑县级固定效应？还是应该同时考虑县级固定效应和州边界固定效应？我特别想知道我是否应该另外包括州边界固定效应，因为一些县同时位于不同的州边界（例如，德克萨斯州的鲍伊县除了德克萨斯州外还与两个州接壤）。但是，我认为观点仍然成立，即这种影响可能也已被吸收到县级固定效应中。]]></description>
      <guid>https://stats.stackexchange.com/questions/657712/fixed-effect-in-cross-border-discontinuity-approach-include-both-county-fixed-e</guid>
      <pubDate>Sat, 23 Nov 2024 07:49:10 GMT</pubDate>
    </item>
    <item>
      <title>我可以假装 Spearman = Pearson 相关系数进行元分析吗？</title>
      <link>https://stats.stackexchange.com/questions/657710/can-i-pretend-that-spearmans-pearsons-correlation-coefficients-for-meta-anal</link>
      <description><![CDATA[将 Spearman 相关性假设为 Pearson 相关性有多合理？
我目前正在进行系统评价和荟萃分析，研究测试 A 与测试 B（黄金标准）的相关性。我的荟萃分析涉及汇总来自各种研究的相关系数，但我遇到了一个方法论挑战：一些研究报告 Spearman 相关系数，而其他研究报告 Pearson 相关系数。
鉴于 Spearman 和 Pearson 系数背后的不同假设和计算，我正在寻求有关将它们结合到荟萃分析中的最佳方法的建议（这涉及对 Pearson 系数进行 Fischer Z 变换，然后重新转换为系数进行解释；我应该对 Spearman 这样做吗？怎么做？）
如果有人有使用统计软件或提供此类问题解决方案的软件包的经验，您的建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657710/can-i-pretend-that-spearmans-pearsons-correlation-coefficients-for-meta-anal</guid>
      <pubDate>Sat, 23 Nov 2024 06:46:36 GMT</pubDate>
    </item>
    <item>
      <title>布冯针问题</title>
      <link>https://stats.stackexchange.com/questions/657708/the-buffon-needle-problem</link>
      <description><![CDATA[目前，我正在做概率教科书中的以下练习：
（布冯针问题）：

一根长度为 L 的针掉落在由宽度为 D 的平行板制成的地板上。对掉落的针的位置和方向做出明显的均匀性和独立性假设。证明如果 L &lt; D，则针穿过两块地板之间的裂缝的概率为 2L/$\pi$D。布丰根据数百次试验中该事件发生的次数比例，对 $\pi$ 进行了经验估计。

以下是我的一些观察（和困惑）；

问题没有具体说明有多少块木板，所以我猜想针头可能落到的裂缝数量是无限的。
假设一根针头落在一对平行木板上，那么针头可能落到的位置数量是无限的。
在任何给定的裂缝上，针头可能处于的方向数量是无限的。

我理解，由于这些“无限”，这个问题应该被视为涉及连续随机变量而不是离散随机变量的问题。但是，我不确定如何继续回答这个问题，特别是有三种情况我必须考虑（如上文列出的要点）。它会像三重积分一样吗？
此外，问题还指出 $\pi$ 来自经验发现。如果是这样，那么如何从等式中得到 $\pi$？
附注：我知道这是一个经典的概率问题，因此网上有很多解决方案。但是，我还没有看过它们，我想自己解决这个问题，所以我非常感谢任何指导（而不是解决方案）！]]></description>
      <guid>https://stats.stackexchange.com/questions/657708/the-buffon-needle-problem</guid>
      <pubDate>Sat, 23 Nov 2024 04:55:27 GMT</pubDate>
    </item>
    <item>
      <title>GAMM 中的 AIC 值问题</title>
      <link>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</link>
      <description><![CDATA[为了检验一个假设，我在 R 中使用广义加性混合模型，并使用 mgcv 包构建了以下模型：
 gam(Resp ~ s(Pred1, bs=&quot;cr&quot;) + s(Pred2, bs=&quot;cr&quot;) + s(Pred3, bs=&quot;cr&quot;) + s(Pred4, bs=&quot;cr&quot;) + ti(Pred3, Pred4) + s(Factor, bs=&quot;re&quot;), data=Data, family=binomial)

然后，我使用 dredge 函数（MuMIn 包）获取按 AIC 值递增排序的所有潜在模型的列表。在此列表中，前四个模型具有相同的 AIC 值，因此具有相同的 DeltaAIC 和 AIC 权重（见下图）。并且这种情况一直发生在以下模型中。
为什么会发生这种情况？这是估算 Pred1 以及 Pred3 和 Pred4 之间相互作用的问题吗？任何帮助都将不胜感激！
]]></description>
      <guid>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</guid>
      <pubDate>Fri, 22 Nov 2024 11:07:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的二项式家族（link="log"）的 glm 有时需要起始值？</title>
      <link>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</guid>
      <pubDate>Fri, 22 Nov 2024 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>测试马尔可夫无记忆假设时 I 类错误的趋势</title>
      <link>https://stats.stackexchange.com/questions/657664/trends-in-type-i-error-when-testing-markov-memoryless-assumption</link>
      <description><![CDATA[问题
在测试马尔可夫无记忆假设时，I 类错误（假阳性/错误拒绝 $H_0$）是否会出现以下趋势？具体而言，I 类错误似乎随着以下情况而增加：

时间点数量 (nt) 减少 (从右到左)
个体链数量 (ni) 增加 (从上到下)。

我怀疑我可能错误地定义了自由度：（$S*(S-1)*(T-1)$ 对应 $S$ 个状态和 $T$ 个周期。编辑：我刚刚注意到这个 d.f. 没有考虑 ni！... 我应该如何/应该在 d.f. 中考虑 ni？

背景和代码
之前也问过类似的问题（例如 1、2、3），但这些答案中很少有提供代码。根据这篇论文），我实现了 R 代码来生成随机马尔可夫样本并运行皮尔逊和似然比$\chi^2$检验。注意：我们不允许零概率转换；这会使测试统计数据的定义更加复杂。
library(&#39;ggplot2&#39;)
rbind.lappy = function(...){ # 便利
do.call(rbind,parallel::mclapply(...,mc.cores=7))
}
px.random = function(d=2){ # 生成随机转换矩阵
px = matrix(runif(d^2,.1,.9),d,d) # 随机数
px = sweep(px,1,rowSums(px),&#39;/&#39;) # 标准化
}
markov.limit = function(px){ # 获取极限分布
e1 = eigen(t(px))$vectors[,1]
p0 = e1 / sum(e1)
}
markov.sim = function(p0,px,nt,ni){ # 模拟样本
ns = length(p0)
state = list(sample(1:ns,ni,p=p0,rep=TRUE)) # 初始时间
for (i in 2:nt){ # 后续每个时间
state[[i]] = sapply(state[[i-1]],function(si){ sample(1:ns,1,p=px[si,]) })
}
names(state) = paste0(&#39;s&#39;,1:nt)
ms = data.frame(i=1:ni,state)
}
markov.test = function(ms){
ns = length(unique(ms[,2])) # 状态数
nt = ncol(ms)-1 # 时间点数
n_hij = array(1,c(ns,ns,ns)) # 二阶计数*
n_ij = array(1,c(ns,ns)) # 一阶计数*
# *初始化为 1 以避免除以零
for (m in seq(nt-2)){ n_hij = n_hij + 表(ms[paste0(&#39;s&#39;,m+0:2)]) }
  for (m in seq(nt-1)){ n_ij = n_ij + table(ms[paste0(&#39;s&#39;,m+0:1)]) }
  n_hi = rowSums(n_hij,dim=2)
  n_i = rowSums(n_ij, 暗淡=1)
  p_hij = 扫描(n_hij,1:2,n_hi,&#39;/&#39;)
  p_ij = 扫描(n_ij, 1, n_i, &#39;/&#39;)
  Q.p = sum(扫描(扫描(扫描(p_hij,2:3,p_ij,&#39;-&#39;)^2,2:3,p_ij,&#39;/&#39;),1:2,n_hi,&#39;*&#39;))
Q.lr = 2*sum(n_hij*log(sweep(p_hij,2:3,p_ij,&#39;/&#39;)))
Q = c(pearson=Q.p, likel.ratio=Q.lr)
p = pchisq(Q,df=ns*(ns-1)*(nt-1),lower=FALSE)
}
markov.test.pvs = function(nt,ni,ns=2,nk=100,lim=1){
pvs = rbind.lappy(1:nk,function(k){
set.seed(k)
px = px.random(ns)
if (lim){ p0 = markov.limit(px) }
else { p0 = rep(1,ns) / ns }
ms = markov.sim(p0,px,nt=nt,ni=ni)
pv = c(nt=nt,ni=ni,ns=ns,nk=nk,lim=lim,markov.test(ms))
})
}
# main
G = expand.grid( # 要扫描的参数
ni=c(30,100,300,1000), # 个体数（链）
nt=3:7, # 时间点数
ns=2, # 状态数
nk=1000, # 重复次数
lim=0:1) # 在稳定状态下初始化
pvs = rbind.lappy(split(G,1:nrow(G)),do.call,what=markov.test.pvs)
# 重塑 &amp;图
pvs.m = reshape2::melt(as.data.frame(pvs),id=colnames(pvs)[1:5])
pvs.m$init = factor(pvs.m$lim,0:1,c(&#39;uniform&#39;,&#39;limit&#39;))
pos = position_dodge(width=1)
g = ggplot(pvs.m,aes(y=value,x=&#39;&#39;,color=variable,lty=init)) +
facet_grid(&#39;ni~nt&#39;,labeller=label_both) +
geom_violin(scale=&#39;width&#39;,position=pos,fill=NA) +
geom_hline(yintercept=.05,lty=&#39;11&#39;) +
stat_summary(geom=&#39;text&#39;,position=pos,show.legend=FALSE,
fun.data=function(x){ data.frame(y=-.1,label=mean(x &lt; .05),size=2) }) +
labs(y=&#39;p 值&#39;,x=&#39;&#39;,color=&#39;统计量&#39;) + ylim(-.1,1)
ggsave(&#39;Rplots.pdf&#39;,w=8,h=6)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657664/trends-in-type-i-error-when-testing-markov-memoryless-assumption</guid>
      <pubDate>Fri, 22 Nov 2024 09:04:40 GMT</pubDate>
    </item>
    <item>
      <title>发生率受测试频率影响</title>
      <link>https://stats.stackexchange.com/questions/657657/incidence-influenced-by-test-frequency</link>
      <description><![CDATA[我对研究设计感到困惑。假设我想研究一种疾病的发病率，但这种疾病大多无症状，其检测仅依赖于定期检测。有些人的检测频率比其他人高。我想根据每个人的检测频率为他们分配权重。如果我打算使用逆倾向得分来计算权重（仅举一个例子）：
PS= glm(test_frequency~age+sex, data=df)
PS$Wt= 1/predict(PS, df)

这听起来合理吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657657/incidence-influenced-by-test-frequency</guid>
      <pubDate>Fri, 22 Nov 2024 05:07:30 GMT</pubDate>
    </item>
    <item>
      <title>为我的数据寻找分布时遇到问题（glmm）</title>
      <link>https://stats.stackexchange.com/questions/657616/problem-finding-a-distribution-for-my-data-glmm</link>
      <description><![CDATA[我想对两个变量进行相关性分析，范围从 0 到 1（包括这些值），并包括其他可能的环境解释变量。
我选择了混合模型，因为我的数据是分层的（按采集数据的区域）。问题是，当我运行模型并分析残差时，我发现它们远非正常（漏斗形状）。我一直在思考如何解决这个问题，但我陷入困境：我的数据是从 0 到 1 的小数，所以泊松分布不太好，我知道二项式也不适用于这种情况。我被伽马分布说服了，但问题是我必须牺牲我的 0 值数据，而这些数据非常有用，有什么解决方案呢？
顺便说一句，我的数据（如果有帮助的话）是一个指数，它是将一个地块中的物种数量除以该地区所有地块中发现的物种总数而得出的，可以说是一个非常简单的生物多样性指数。
非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657616/problem-finding-a-distribution-for-my-data-glmm</guid>
      <pubDate>Thu, 21 Nov 2024 14:31:19 GMT</pubDate>
    </item>
    <item>
      <title>基于协方差或精度矩阵的特征选择</title>
      <link>https://stats.stackexchange.com/questions/656674/feature-selection-based-on-covariance-or-precision-matrix</link>
      <description><![CDATA[我刚刚读到关于精度矩阵的属性，其中最让我吃惊的是，如果 $|\Sigma^{-1}_{ij}|\gg0$，则意味着即使我们以所有其他特征为条件，特征 $i$ 和 $j$ 也高度相关
另一方面，相关矩阵仅考虑这两个特征，并检查它们是否相关
所以我的问题是，使用精度矩阵进行特征选择是否比使用协方差更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/656674/feature-selection-based-on-covariance-or-precision-matrix</guid>
      <pubDate>Sun, 03 Nov 2024 15:59:09 GMT</pubDate>
    </item>
    </channel>
</rss>