<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 11 Jul 2024 03:19:43 GMT</lastBuildDate>
    <item>
      <title>对给定点的连续随机变量的概率的困惑</title>
      <link>https://stats.stackexchange.com/questions/650845/confusion-about-the-probability-of-a-continuous-random-variable-at-a-given-point</link>
      <description><![CDATA[
一个人从一家有 80 个 A 型电池和 260 个 B 型电池的商店中随机选择一块电池。A 型和 B 型电池的寿命呈指数分布，平均寿命分别为 8.0 年和 13.0 年。如果所选电池的使用寿命为 5 年，那么该电池为 A 型的概率是多少？

定义随机变量 $X$ 和 $Y$，使得
$$
X = \begin{cases} 
1, &amp; \text{如果电池为 A 型} \\
0, &amp; \text{如果电池是 B 型} 
\end{cases}
$$
$$Y = \text{电池寿命}$$
在答题纸上，他们使用了 $f_{Y|X}(y) = \lambda e^{-\lambda x}$，其中他们输入 $y = 5$ 来得到答案。但我研究发现，给定点处连续随机变量的概率为 $0$。所以我这样做 $P(X = 1 | Y \ge 5)$ 来找到答案。他们为什么这样做，解决这个问题的正确方法是什么？我真的对这些概念感到困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/650845/confusion-about-the-probability-of-a-continuous-random-variable-at-a-given-point</guid>
      <pubDate>Thu, 11 Jul 2024 03:12:55 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型（DDPM）中，如果我们预测总噪声，为什么不直接在一次采样中去除噪声呢？</title>
      <link>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</link>
      <description><![CDATA[正如 DDPM 论文所指出的，我们可以选择将均值的预测重新参数化为总噪声的预测“εθ 是一个函数近似器，旨在根据 x 预测 ε”（公式 11）。那么，在采样过程中，我们为什么不直接从最后一步（纯噪声）中去除预测的总噪声，而是逐步采样图像？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</guid>
      <pubDate>Thu, 11 Jul 2024 03:07:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们在得出标准误差时假设样本具有相同的方差？</title>
      <link>https://stats.stackexchange.com/questions/650843/why-do-we-assume-samples-have-the-same-variance-when-deriving-standard-error</link>
      <description><![CDATA[在我见过的所有标准误差公式 $\sigma/\sqrt{n}$ 的推导中，都假设抽样分布中的所有样本具有相同的方差 ($\sigma^2$)。为什么？它们不能有不同的方差吗？
例如，在这个答案中：
https://stats.stackexchange.com/a/89159/419909，假设每个 $X_i$ 具有相同的 $\sigma^2$]]></description>
      <guid>https://stats.stackexchange.com/questions/650843/why-do-we-assume-samples-have-the-same-variance-when-deriving-standard-error</guid>
      <pubDate>Thu, 11 Jul 2024 02:52:03 GMT</pubDate>
    </item>
    <item>
      <title>建模条件特定关联</title>
      <link>https://stats.stackexchange.com/questions/650842/modeling-condition-specific-associations</link>
      <description><![CDATA[我正在尝试建立交叉重复测量设计模型，其中个人完成主动和控制条件。这些个人还在两种条件之前和之后完成认知测试（总共四次）。我想检查主动和控制条件下变量的变化（例如，主动期间的 HR 和控制期间的 HR）与认知变化前后之间的关联。为了对此进行建模，我使用了线性混合模型，其中条件作为固定效应，HR 和条件对认知变化（事后-事前）的相互作用。从逻辑上讲，考虑重复测量似乎是有意义的，但我还没有看到任何使用这种方法的出版物。有人可以提供一些见解和/或分享使用这种方法的出版物吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650842/modeling-condition-specific-associations</guid>
      <pubDate>Thu, 11 Jul 2024 01:47:52 GMT</pubDate>
    </item>
    <item>
      <title>在 r 中对数变换左数据</title>
      <link>https://stats.stackexchange.com/questions/650841/log-transform-left-data-in-r</link>
      <description><![CDATA[我很难找到左/负偏斜数据的转换操作。问题是什么？我的所有值都在 0 和 1 之间。因此，尝试标准 log10 转换命令会计算出一堆 NA。
log10(max(df$Var+1) - df$Var)

您有什么建议？
我计算的偏度为  -0.6818167
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650841/log-transform-left-data-in-r</guid>
      <pubDate>Thu, 11 Jul 2024 01:17:08 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛积分减法 - 灾难性取消</title>
      <link>https://stats.stackexchange.com/questions/650840/subtraction-of-monte-carlo-integrals-catastrophic-cancellation</link>
      <description><![CDATA[我试图估计一个量 $Q$，它由蒙特卡洛积分的两个函数在一组点 $\{x_i\}_{i=1}^N$ 上的差给出，调用估计器 $\hat{Q}$:
$$ \hat{Q} = \frac{1}{N} \sum_i f(x_i) - \left(\frac{1}{N}\sum_j g(x_j)\right)^2~.$$
不幸的是，在两个项几乎相等的情况下，灾难性的抵消结果和最终的近似值是不可信的。在这种情况下，有没有什么方法可以避免灾难性的取消？
编辑：请注意，尽管相似，但这并不是计算方差的尝试！]]></description>
      <guid>https://stats.stackexchange.com/questions/650840/subtraction-of-monte-carlo-integrals-catastrophic-cancellation</guid>
      <pubDate>Thu, 11 Jul 2024 01:13:52 GMT</pubDate>
    </item>
    <item>
      <title>从数学上来说，Fisher 方法下的组合测试为何通常比单独测试更强？</title>
      <link>https://stats.stackexchange.com/questions/650839/how-the-combined-test-under-fishers-method-is-generally-stronger-than-individua</link>
      <description><![CDATA[我已在多种材料中研究了 Fisher 方法的定义，但不清楚 Fisher 方法为何比单个测试更强大。我猜情况并非总是如此，即在某些情况下组合测试可能表现更差，但不确定在哪些情况下。为了验证这一点，我尝试设置以下简单设置，并想比较单个测试和组合测试中的 II 类错误。
假设有 2 个单个测试具有相同的假设 $H_0: \mu=\mu_0$、$H_a:\mu &gt; \mu_0$，其 p 值分别为 $p_1$ 和 $p_2$。 Fisher 的方法通过计算以下检验统计量来合并 p 值：
$$\chi^2=-2(ln(p_1)+ln(p_2))$$
设 $\mu_a$ 为满足 $H_a$ 的值。设 $\beta_f$ 和 $\beta_1$ 分别为组合检验和第一次检验的 2 型错误。我想知道在哪些条件下 $\beta_f&lt;\beta_1$ 和反之亦然，但不确定如何继续。上述公式是否完整，还是需要进一步假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/650839/how-the-combined-test-under-fishers-method-is-generally-stronger-than-individua</guid>
      <pubDate>Thu, 11 Jul 2024 00:57:26 GMT</pubDate>
    </item>
    <item>
      <title>当 $\sigma^2 > 0$ 时，概率 PCA 中的后验均值会向 0 移动</title>
      <link>https://stats.stackexchange.com/questions/650838/posterior-mean-in-probabilistic-pca-shifts-towards-0-when-sigma2-0</link>
      <description><![CDATA[我们知道，在概率​​ PCA 中，$$x = Wz + \mu + \epsilon, \epsilon \sim N(0, I)$$
后验可以推导出为$$z|x \sim N\left(M^{-1}W^T(x-\mu), \sigma^{-1}M\right)$$
其中$M = W^TW + \sigma^2I$。
在 Bishop 的模式识别中，它说当$\sigma^2&gt;0$时，后验均值相对于正交投影向原点移动。有人能帮我理解这句话吗？当 $\sigma^2 &gt; 0$ 时，不是不再有正交投影了吗？那么这实际上是在比较什么？在这种情况下，向原点移动在数学上意味着什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650838/posterior-mean-in-probabilistic-pca-shifts-towards-0-when-sigma2-0</guid>
      <pubDate>Wed, 10 Jul 2024 23:00:48 GMT</pubDate>
    </item>
    <item>
      <title>入门数据分析研究论文 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650837/research-paper-for-introductory-data-analytics</link>
      <description><![CDATA[我正在学习一门入门数据分析课程，这门课程要求我们使用统计方法撰写一篇小型研究论文。我们打算找到使用相当简单的技术（如 OLS）的过去研究，并使用更新的数据或额外的预测变量自己尝试该方法。
我感兴趣的领域是经济学，但我很难找到一篇可以借鉴的论文。大多数论文从数学角度来看都太高级了，使用的方法超出了本课程的预期。
有人能给我指出一篇符合这个标准的论文吗？理想情况下应该是经济学方面的，但金融/商业也可以接受。
感谢您的任何帮助或见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/650837/research-paper-for-introductory-data-analytics</guid>
      <pubDate>Wed, 10 Jul 2024 22:47:39 GMT</pubDate>
    </item>
    <item>
      <title>X 中有噪声的回归。我应该使用无偏估计量还是 OLS 估计量进行预测？</title>
      <link>https://stats.stackexchange.com/questions/650835/regression-with-noises-in-x-should-i-use-the-unbiased-estimator-or-the-ols-esti</link>
      <description><![CDATA[我正在处理一个包含变量 $Y$ 和 $X$ 的数据集。我假设
$$ Y = \beta X + \epsilon $$
满足 OLS 的所有假设。根据行业知识，我知道理论上 $\beta = 1$。但是，我知道 $X$ 包含噪声，这意味着我观察到 $\hat{X} = X + u$，其中 $u$ 表示噪声。当我运行 OLS 估计时，我发现估计的 $\beta$ 小于 1，这是由于 $X$ 中的噪声，这增加了 $X$ 的方差。
我有来自不同组的不同对 $(Y, X)$。我可以通过观察在较大的组中（其中数据变异性被中心极限定理降低）来验证我的假设，拟合的$\beta$更接近 1。
鉴于此，我的问题是：如果我想进行样本外预测，我应该使用 1 作为我的$\beta$还是应该使用有偏差的 OLS $\beta$ 估计值？
一方面，似乎使用无偏的$\beta$ 1 是更好的选择，因为它在理论上是无偏的。但是，如果我假设相同的噪声 $u$ 存在于我的样本外 $X$ 中，我的残差项将具有更大的方差，因为它包括项 $\beta^2 \text{Var}(u)$。使用较小的、有偏差的 $\beta$ 可能有助于减少残差方差，尽管存在偏差。
这是一个偏差-方差权衡场景吗？如果我的目标是最小化样本外残差 MSE，那么这里最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650835/regression-with-noises-in-x-should-i-use-the-unbiased-estimator-or-the-ols-esti</guid>
      <pubDate>Wed, 10 Jul 2024 21:49:14 GMT</pubDate>
    </item>
    <item>
      <title>随机变量加权平均的二阶矩</title>
      <link>https://stats.stackexchange.com/questions/650833/second-moment-of-weighted-average-of-random-variables</link>
      <description><![CDATA[我偶然发现了 SOA 考试 P 列表中的第 254 个问题
https://www.soa.org/globalassets/assets/Files/Edu/edu-exam-p-sample-quest.pdf
我对其中描述的解决方案感到困惑
https://www.soa.org/globalassets/assets/files/edu/edu-exam-p-sample-sol.pdf
基本上，他们解决问题的方式是通过声明泊松变量加权平均值的二阶矩是二阶矩的加权平均值来表示的。对于一阶矩（期望值），这显然通常是正确的，但对于二阶矩，人们期望
$E[(aX+bY)^2] = a^2 E[X^2] + 2abE[XY] + b^2 E[Y^2]$。
根本没有提到独立性或相关性，只是说这些是泊松变量，它们的均值为正。这样说是否足以说明
$E[(aX+bY)^2] = a E[X^2] + bE[Y^2]$
如解决方案所述？]]></description>
      <guid>https://stats.stackexchange.com/questions/650833/second-moment-of-weighted-average-of-random-variables</guid>
      <pubDate>Wed, 10 Jul 2024 20:06:19 GMT</pubDate>
    </item>
    <item>
      <title>拉普拉斯继承定律悖论</title>
      <link>https://stats.stackexchange.com/questions/650830/laplace-law-of-succession-paradox</link>
      <description><![CDATA[（我是贝叶斯概率的新手……所以如果这很幼稚，请多多包涵！）
拉普拉斯继承定律：对于二进制下一个事件，(r+1)/(n+2)
Jaynes（“概率论”，第 571 页）似乎将其扩展为：当事件有 k 种可能性时，(r+1)/(n+k)。
现在假设：你抽出 4 个黄球。假设你有 1&#39;000 种颜色可能性（可能是因为你的比色计只有 3 位数字）。
那么下一个球是黄色的概率将是：(4+1)/(4+1000) 约 0.5%
但你也可以这样看待它：球可以是黄色或非黄色（1&#39;000 种颜色中的任何其他颜色）。因此，由于您有一个二元事件：黄色与非黄色，黄色的概率将是 (4+1)/(4+2) = 5/6
这与之前的数字完全不同（您可以说特定非黄色的概率是 (5/6) / 999。
那么下一个球是黄色的概率到底是多少：0.5% 还是 5/6？]]></description>
      <guid>https://stats.stackexchange.com/questions/650830/laplace-law-of-succession-paradox</guid>
      <pubDate>Wed, 10 Jul 2024 19:20:34 GMT</pubDate>
    </item>
    <item>
      <title>R：如何计算检测平均 beta reg 变化的功率？</title>
      <link>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</link>
      <description><![CDATA[我有兴趣计算通过特定效应大小检测我的平均响应变量变化的功效，但我不知道如何开始。我的 Y 变量是平均植物覆盖率 0-100% 覆盖率（每个站点 10 次随机重复调查的平均值，以小数表示，包括 0 和 1），我想计算检测未来假设覆盖变化的效应大小的功效（单/配对样本检验）。每年在同一位置重复采样植物覆盖率（随机截距）。
我将这个问题输入 chatgpt，但我想验证这是正确的方法。它回复说建议我制作两个单独的模型（一个模型中我的协变量没有影响，另一个模型中它有指定的效应），然后计算每个模型的两个平均响应之间的差异。然后它说使用 t 检验计算功效。
这个答案看起来正确吗？我如何才能准确地模拟出与原始数据相似的数据（如何在 rbeta 中选择 alpha 和 beta）？我如何才能使年份协变量对 cover 产生特定的影响（chatgpt 假设了一个连续协变量并将其设置为 0.5）？此外，我知道我的回答不是概率，但我不应该使用功率计算来计算比例，因为这是 0-&gt;1 数据（即使用 pwr::pwr.p.test）？
我尝试模拟数据以便更容易发布这个问题，但它在摘要输出中没有达到预期的效果。
set.seed(123)

n &lt;- 100
x1 &lt;- rep(seq(1, 10), each = 10)
x2 &lt;- seq(1, 10)

y &lt;- rbeta(n, 2, 5) # 模拟响应变量（beta 分布）

# 创建数据框
data &lt;- data.frame(cover = y, year = x1, site = x2)
data$site &lt;- as.factor(data$site)

我认为这比 betareg 更好，因为它允许随机截距
library(glmmTMB)
# 拟合 beta 回归模型
model &lt;- glmmTMB(y ~ year + (1|site), ziformula = ~1, data = data, family=beta_family(link=&quot;logit&quot;))

Chatgpt:
# 模拟数据以进行功效计算：
# 要计算功效，通常需要在零假设和备择假设下模拟数据。

# 零假设 (H0)：假设预测变量 x1 没有影响。
# 备择假设 (H1)：假设预测变量 x1 具有一定大小的影响。
# 假设您想要计算检测 x1 的两个值之间的平均响应变量 y 的差异的功效：x1 = 0 和 x1 = 0.5。

# 在 H0 下模拟数据（x1 无影响）
data_null &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n))

# 在 H1 下模拟数据（x1 = 0.5 的影响）
data_alt &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n, mean = 0.5))

model_null &lt;- betareg(y ~ x1, data = data_null)
model_alt &lt;- betareg(y ~ x1, data = data_alt)

# 在 H0 下计算 x1 = 0.5 和 x1 = 0 之间的平均响应变量 (y) 差异
mean_y_alt &lt;- predict(model_alt, newdata = data_null)
mean_y_null &lt;- predict(model_null, newdata = data_null)
effect_size &lt;- mean(mean_y_alt - mean_y_null)

# y 的标准差
sd_y &lt;- sd(predict(model, type = &quot;response&quot;))

# 样本大小
n &lt;- nrow(data)

# 显着性水平
alpha &lt;- 0.05

# 计算功效
power &lt;- pwr.t.test(n = n, delta = effect_size, sd = sd_y, sig.level = alpha, type = &quot;two.sample&quot;)$power
power

这是对比例数据的更好测试，不是吗？
power &lt;- pwr.p.test(h = effect_size, n = n, sig.level = alpha, alternative = &quot;two.sided&quot;)$power
power
]]></description>
      <guid>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</guid>
      <pubDate>Wed, 10 Jul 2024 19:08:56 GMT</pubDate>
    </item>
    <item>
      <title>当误差不服从正态分布（拉普拉斯分布）时，OLS 与 MLE</title>
      <link>https://stats.stackexchange.com/questions/650828/ols-vs-mle-when-errors-are-not-normally-distributed-laplace-distributed</link>
      <description><![CDATA[我们说，在高斯-马尔可夫定理的假设下，OLS 是 BLUE。高斯-马尔可夫定理没有提到误差的正态性。

如果误差按照拉普拉斯分布分布，那么根据高斯马尔可夫定理，OLS 仍然是 BLUE 吗？

使用拉普拉斯误差的 MLE 估计，我们会得到最佳线性估计量将最小化 MAE，而不是 SSE。因此，当误差不正态时，MLE 估计不再是 OLS 估计。这是什么意思？哪个更适合使用？

]]></description>
      <guid>https://stats.stackexchange.com/questions/650828/ols-vs-mle-when-errors-are-not-normally-distributed-laplace-distributed</guid>
      <pubDate>Wed, 10 Jul 2024 19:07:05 GMT</pubDate>
    </item>
    <item>
      <title>如何基于 R 中 nnet 包的 multinom() 函数进行模型比较？</title>
      <link>https://stats.stackexchange.com/questions/650831/how-to-perform-model-comparison-based-on-multinom-function-of-nnet-package-in</link>
      <description><![CDATA[我的自变量是性别和顺序，因变量是干预（包括3种干预方式）。我建立了多项逻辑回归模型来检验性别和顺序对干预的影响。主要步骤为：
我先用multinom()函数建立空模型，再建立全模型，最后用anova()函数比较模型。
代码如下：
model_null&lt;- multinom(intervention~ 1,data = test_data)
model_full&lt;- multinom(intervention~ 1+ gender+sequence,data = test_data)
anova(model_full,model_null,test = &quot;Chisq&quot;)

结果输出如下：
enter image description here
我有两个问题：1.我不确定这种分析方法是否正确，因为这是我第一次使用多项逻辑回归。因为线性回归一般都是用这种方法做模型比较，所以我就采用了这种方法；2.如果正确的话，我不知道如何得到模型比较的卡方值，目前输出的结果没有卡方值，只有P值。
如果能给点帮助，我将不胜感激~~]]></description>
      <guid>https://stats.stackexchange.com/questions/650831/how-to-perform-model-comparison-based-on-multinom-function-of-nnet-package-in</guid>
      <pubDate>Wed, 10 Jul 2024 13:30:12 GMT</pubDate>
    </item>
    </channel>
</rss>