<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 12:28:36 GMT</lastBuildDate>
    <item>
      <title>我可以使用均方预测误差来选择 CausalImpact 模型中的先验 SD 吗？</title>
      <link>https://stats.stackexchange.com/questions/648959/can-i-use-the-mean-squared-prediction-error-to-select-the-prior-sd-in-a-causalim</link>
      <description><![CDATA[我正在使用 CausalImpact 包（在 R 中），并且（正如我所期望的那样）结果对所使用的先验非常敏感。
我认为我对先验在此模型中的作用有很好的理解，但我仍然难以从理论上确定先验 SD 应该是多少，特别是因为结果对微小变化非常敏感。在我工作的环境中，我的同事对于放弃默认设置有些犹豫（即使我们正在处理的数据与默认设置的设计不同）。还有一种担心是客户会对任何可能被解释为“偏见”的东西产生怀疑结果。
我正在考虑的想法是，在干预前后半段对每个数据点分别运行具有各种先验水平 SD 的模型，然后（对于每个先验水平 SD）提取并汇总所有分析中的所有预测误差，将其变成一些衡量绩效的分数（可能是均方预测误差）。然后，我可以选择在干预前运行分析时导致最低 MSPE（或某些相关度量）的先验 SD。
这是一种合法的方法吗？在这种情况下，还有其他更有原则的方法来选择先验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648959/can-i-use-the-mean-squared-prediction-error-to-select-the-prior-sd-in-a-causalim</guid>
      <pubDate>Mon, 10 Jun 2024 11:49:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 进行两个连续预测变量的多元回归</title>
      <link>https://stats.stackexchange.com/questions/648958/multiple-regression-with-two-continuous-predictor-variables-with-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648958/multiple-regression-with-two-continuous-predictor-variables-with-r</guid>
      <pubDate>Mon, 10 Jun 2024 11:13:50 GMT</pubDate>
    </item>
    <item>
      <title>计算 GLM-拟泊松模型的权重</title>
      <link>https://stats.stackexchange.com/questions/648957/calculate-weight-for-glm-quasi-poisson-model</link>
      <description><![CDATA[我正在运行几个拟泊松系列模型。我正在查看秃鹫餐厅的数据。每个地点的秃鹫数量都被建模为日期或月份的线性或二次效应函数，以及地点、季节和它们之间相互作用的固定效应。使用 R 中的对数链接函数对模型进行拟泊松误差拟合。最佳模型由最低的拟 AICc 分数选出。为了计算 QAICc 分数，我重新运行了所有具有标准泊松误差的模型，并使用 R 包“bblme”（Bolker 2016）使用每组（日期 2 × 地点 × 季节）中最复杂模型的离散度来校正 AICc 分数。
我想通过报告 QAICc 权重来展示对顶级模型的支持水平。但我在网上找不到如何做到这一点。包中是否有函数可用于计算每个模型的权重？
以下是我从名为 Table_DeltaQAICc 的包“bblme”中获得的结果：

我尝试按照我在网上看到的这个公式来计算权重，这是一个使用 IC 的示例。模型权重的计算公式如下：e(−δIC/2)
Table_DeltaQAICc$Weight &lt;- exp((-Table_DeltaQAICc$dqAICc)/2)

这是我得到的结果，我这样计算每个模型的权重合适吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648957/calculate-weight-for-glm-quasi-poisson-model</guid>
      <pubDate>Mon, 10 Jun 2024 11:08:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么情节看起来不同？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648955/why-do-the-plots-look-different</link>
      <description><![CDATA[如果我使用 SYSTAT 应用程序绘制此数据，它看起来如下所示：

在 ChatGPT 中，它看起来如下所示：

但是，当我使用我的 C# 应用程序绘制它时，它看起来如下所示：

你能告诉我为什么这些图看起来不一样吗？
残基、密度、Tau0
10,0.001,21.937
10,0.001,22.04
10,0.001,22.032
10,0.001,21.962
10,0.001,21.845
10,0.001,21.929
10,0.001,21.794
10,0.001,21.918
10,0.00 1,21.877
10,0.001,21.81
10,0.001,21.832
10,0.001,21.872
10,0.001,21.813
10,0.001,21.608
10,0.001,21.679
10,0.005,22.067
10,0.005,22.037
10,0.005,21.906
10,0.005,21.941
10,0.005,21.964
10,0.005,21.871
10,0.005,21.938
10,0.005,21.918
10,0.005,21.941
10,0.005,21.752
10,0.0 05,21.766
10,0.005,21.821
10,0.005,21.757
10,0.005,21.699
10,0.005,21.776
10,0.01,22.231
10,0.01,22.228
10,0.01,22.116
10,0.01,22.131
10 ,0.01,22.166
10,0.01,22.155
10,0.01,21.951
10,0.01,22.003
10,0.01,21.996
10,0.01,22.126
10,0.01,21.981
10,0.01,21.913
10,0.01,21.984
10 ,0.01,21.947
10,0.01,21.889
15,0.001,55.011
15,0.001,54.892
15,0.001,54.325
15,0.001,54.349
15,0.001,54.554
15,0.001,54.288
15,0.001,54. 213
15,0.001,53.985
15,0.001,54.296
15,0.001,54.29
15,0.001,54.187
15,0.001,53.237
15,0.001,53.908
15,0.001,53.524
15,0.001,52.545
15,0 .005,55.073
15,0.005,55.296
15,0.005,55.072
15,0.005,54.901
15,0.005,54.969
15,0.005,54.625
15,0.005,54.299
15,0.005,53.906
15,0.005,54. 336
15,0.005,53.949
15,0.005,54.12
15,0.005,54.243
15,0.005,53.788
15,0.005,53.831
15,0.005,53.746
15,0.01,55.233
15,0.01,55.165
15,0.0 1,55.057
15,0.01,54.919
15,0.01,54.849
15,0.01,55.066
15,0.01,55.113
15,0.01,54.624
15,0.01,54.419
15,0.01,54.389
15,0.01,54.075
15,0.0 1,54.335
15,0.01,53.77
15,0.01,54.248
15,0.01,53.563
25,0.001,164.724
25,0.001,164.99
25,0.001,163.518
25,0.001,164.708
25,0.001,162.76 9
25,0.001,162.927
25,0.001,162.678
25,0.001,163.869
25,0.001,162.71
25,0.001,161.045
25,0.001,161.379
25,0.001,161.428
25,0.001,161.531
25,0.001,159.493
25,0.001,160.823
25,0.005,167.892
25,0.005,166.525
25,0.005,165.384
25,0.005,164.054
25,0.005,163.825
25,0.005,163.31 9
25,0.005,161.626
25,0.005,161.139
25,0.005,158.917
25,0.005,160.506
25,0.005,161.778
25,0.005,160.07
25,0.005,159.091
25,0.005,160.715
25,0.005,157.838
25,0.01,167.243
25,0.01,166.138
25,0.01,164.303
25,0.01,167.051
25,0.01,164.707
25,0.01,163.833
25,0.01,164.682
25,0. 01,163.755
25,0.01,163.913
25,0.01,162.615
25,0.01,163.848
25,0.01,162.233
25,0.01,160.745
25,0.01,163.592
25,0.01,159.967
]]></description>
      <guid>https://stats.stackexchange.com/questions/648955/why-do-the-plots-look-different</guid>
      <pubDate>Mon, 10 Jun 2024 10:56:32 GMT</pubDate>
    </item>
    <item>
      <title>样本量中固定 alpha 和 beta 的平均差计算的 z 分数总和</title>
      <link>https://stats.stackexchange.com/questions/648954/z-score-total-for-fixed-alpha-and-beta-in-sample-size-calculation-of-mean-differ</link>
      <description><![CDATA[有人能详细解释一下在均值差$\mu_1 - \mu_2$的单尾假设检验中，$z_\text{total}=z_{\alpha} + z_{1-\beta}$如何用共同方差来确定样本量吗？
我找到的所有参考资料都得出了这个公式，但没有分解得出该公式的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/648954/z-score-total-for-fixed-alpha-and-beta-in-sample-size-calculation-of-mean-differ</guid>
      <pubDate>Mon, 10 Jun 2024 10:02:27 GMT</pubDate>
    </item>
    <item>
      <title>标准差的最大似然法</title>
      <link>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</link>
      <description><![CDATA[我试图更好地理解样本标准差的分布和不确定性。由于我不是数学家，我尝试将数学文献与一些模拟结果进行比较。
我做了一个相当简单的模拟研究，首先假设 X∼N(μ,σ²)。我从这个分布中抽样三次并估计样本方差。
我使用估计的样本方差并模拟卡方分布以获得方差的上限和下限 95% CI。（我知道，我可以通过取分布的分位数而不模拟结果来做到这一点，但出于比较的原因，我希望得到分布）。我取这些结果的平方根并将它们与总体标准差进行比较。通过重复这种方法 2,500 次，我可以显示样本标准差的 95% 置信区间的覆盖率约为 95%。这就是我所期望的。
不过，我还对 2,500 个卡方分布的众数取了平均值，取了平方根，并将该值与平均样本方差的平方根进行了比较。
众所周知，方差是真实总体方差的无偏估计量，我得到了 1 作为结果。但是，平均模式的平方根导致结果约为 0.77。
为了更好地理解这一点，我绘制了模拟 2500 的卡方分布，并将该分布的模式与样本方差（红线）进行了比较。

模式和估计的样本方差之间存在明显偏差。我的下一个想法是，这可能与最大似然 (ML) 与受限最大似然估计 (REML) 有关。所以，我做了一个小改动。我没有将样本方差乘以 n-1，而是将其乘以 n，然后重复该过程。
var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)
对比
var_sim &lt;- (n)*sample_var[i]/rchisq(n = n_sim, df = n-1)
样本方差的预期值再次为 1，平均模式的平方根约为 0.95，现在更接近预期值 1。然而，这带来了覆盖率损失（89%）的代价。

我预计卡方分布的众数/最大似然估计量应该与样本方差一起下降。然而，这两种方法都不是这种情况。我想，我对 ML 估计量和卡方样本分布的模式有一个根本性的误解，我希望有人能解释一下我的问题。
这里是重现我的结果的代码：
set.seed(09062024)

result_var &lt;- NULL
sd_qt_upper &lt;- NULL
sd_qt_lower &lt;- NULL
sd_mean &lt;- NULL
sd_mode &lt;- NULL
sample_var &lt;- NULL

n_sim &lt;- 2500
n &lt;- 3

for(i in 1:n_sim){
x &lt;- rnorm(n = n, 0,1)
sample_var[i] &lt;- var(x)

var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)

sd_qt_lower[i] &lt;- sqrt(quantile(var_sim, probs = 0.025)) 
sd_qt_upper[i] &lt;- sqrt(quantile(var_sim, probs = 0.975))
sd_mean[i] &lt;- sqrt(mean(var_sim))
var_density_temp &lt;- density(var_sim, n = n_sim, from = 0, to = 10 )
sd_mode[i] &lt;- sqrt(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))])
}

coverage_sd &lt;- sd_qt_upper&gt;1&amp;sd_qt_lower&lt;1
mean(coverage_sd) #覆盖率
mean(sd_mean) #基于每个卡方分布和模拟轮次的预期值的预期值
sqrt(mean(sample_var)) #基于初始 var 计算的预期值
mean(sd_mode) #基于模拟模式的预期值

#plot
plot(var_density_temp, main = paste(&quot;chi square distribution simulation:&quot;, i, &quot;\n Mode = &quot;, 
round(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))],2),
&quot;\n 样本方差 = &quot;, round(sample_var[n_sim], 2)))
abline(v = sample_var[n_sim], col = &quot;red&quot;, lwd = 2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</guid>
      <pubDate>Mon, 10 Jun 2024 08:07:12 GMT</pubDate>
    </item>
    <item>
      <title>计算结果的标准差</title>
      <link>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</link>
      <description><![CDATA[我正在根据实验数据计算一个值。计算结果为
$$ k = \frac{a - b}{c} \cdot \frac{1}{T}, $$
并且 $a$、$b$ 和 $c$ 都是通过多次实验测量的，样本之间会有一些差异，并且 $T$ 是一个常数。它们也是独立测量的，因此即使我碰巧有 $a$、$b$ 和 $c$ 各 $N$ 个值，我也不能说它们在三元组中彼此“属于”对方，或诸如此类。
计算结果 $k$ 中的标准差的正确方法是什么？我相信我不能完全不合理地假设 $a$、$b$ 和 $c$ 服从正态分布，尽管严格来说，这些数字（无论是在现实中还是在测量中）都被限制为正值，因此它们不是真正正态的。
（我尝试从 $a$、$b$ 和 $c$ 的不同值的所有排列中计算 $k$。假设 $N = 4$，那么我有 $4 \times 4我可以使用 \times 4 = 64$ 种不同的组合来计算 $k$，然后我可以取其标准差。不过，这有点像黑客攻击，所以如果能有一些理论见解就好了。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</guid>
      <pubDate>Mon, 10 Jun 2024 07:59:51 GMT</pubDate>
    </item>
    <item>
      <title>使用哪些数据来确定医学诊断测试的最终阈值？</title>
      <link>https://stats.stackexchange.com/questions/648946/what-data-are-used-to-find-the-final-threshold-for-a-medical-diagnostic-test</link>
      <description><![CDATA[假设我有一些血液测量值 X，其值与某种疾病 Y 相关（因此患有该疾病的人通常具有较大的 X 值）。此外，假设该疾病很罕见，占人口的 1%。
现在我想开发一种新的医学诊断测试。
我应该从 1000 名健康和 1000 名不健康的人中计算阈值，还是应该将计数与人口计数相对应（例如 100 名患病者和 10 000 名健康人），因为在这两种情况下，找到的最佳阈值都会不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/648946/what-data-are-used-to-find-the-final-threshold-for-a-medical-diagnostic-test</guid>
      <pubDate>Mon, 10 Jun 2024 06:51:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么真正无信息的先验不存在？</title>
      <link>https://stats.stackexchange.com/questions/648945/why-a-truly-uninformative-prior-does-not-exist</link>
      <description><![CDATA[据说，没有真正无信息的先验。
例如，这里。
问：

是否已经证明不存在真正无信息的先验，或者仅仅是没有发现这样的先验？

如果已经证明，那么为什么真正无信息的先验不可能存在的概念解释是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/648945/why-a-truly-uninformative-prior-does-not-exist</guid>
      <pubDate>Mon, 10 Jun 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>如何对电力系统的144个数据集和4个输入参数进行多元分析和可视化？</title>
      <link>https://stats.stackexchange.com/questions/648942/how-to-do-multivariate-analysis-and-visualization-for-144-datasets-and-4-input-p</link>
      <description><![CDATA[我正在为研究建模和模拟微电网。我修改了模拟的 4 个输入参数，以便观察它产生的不同结果。为了明确起见，我将在下面描述设置。
输入特性：

太阳能容量（0 kW、200 kW、400 kW）
电池大小（0 kWh、800 kWh、1600 kWh、2400 kWh）
电动汽车充电器数量（0、5、10）
控制算法（控制算法 #1、控制算法 #2、控制算法 #3、控制算法 #4）

每个模拟都是这些特性的变体，例如：（太阳能 200 kW、电池 1600 kWh、电动汽车充电器数量 10、控制算法 # 3）。这就是为什么有 144 次模拟。
每次模拟都是一个为期一年的时间序列，分辨率为 5 分钟。输出数据为：

时间戳（每 5 分钟一个 [我使用重采样来实现此目的]）
功率输出 (kW)
温室气体排放量 (mTons)
电力成本 ($)

我进行此实验的目的是查看控制算法对输出参数的影响。但是，我改变了其他输入参数，以便更有力地证明我得出的关于控制算法的结论是始终可见的，而不仅仅是异常。
我遇到的困境是如何最好地分析和可视化这些数据：
在我进行这个大型实验之前，我会做一些较小的实验，其中我会改变 1-2 个参数，总共进行 6-8 次模拟。在这种情况下，使用相关系数或线性回归可以达到我的目的。我读过关于多元分析的不同方法，但我不确定哪种方法最适合我上面提到的实验（多元协方差分析、典型相关分析、聚类等）。哪种方法是最佳实践，最好是可以用 Python 实现的方法？
至于数据可视化，我将对每个模拟使用箱线图，这些箱线图针对时间序列数据单独标记，或者当我将数据平均为每个模拟一个数据点时使用散点图（例如：年度温室气体排放量（mTons）6-8 个数据点）。我可以轻松改变图表中的 1 或 2 个特征，以轻松查看模式。我不确定可视化这些数据的好方法是什么。我正在考虑显示 4 个子图，其中我改变一个特征，并在 3d 图中绘制其他 3 个子图，其中颜色变化以显示每个模拟图（总共 144 个数据点）单个数据点的输出数据（温室气体等）。我不知道如何在用户可以进行 144 次模拟的地方显示四分位数数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648942/how-to-do-multivariate-analysis-and-visualization-for-144-datasets-and-4-input-p</guid>
      <pubDate>Mon, 10 Jun 2024 06:12:08 GMT</pubDate>
    </item>
    <item>
      <title>考虑分类问题中的非对称损失函数</title>
      <link>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</link>
      <description><![CDATA[
考虑一种二元分类方法，该方法估计类别概率，并且可以指定观察权重（例如 Logistic 回归）。为了适应 TP 和 FP 的差异损失，哪种方法效果更好：

1a) 不要指定权重。相反，调整概率阈值，直到结果从客户端的角度来看看起来不错。
1b) 将概率阈值固定在 0.5 并调整权重。

考虑一个问题，其中响应有超过 2 个类别，并且损失函数取决于观察被错误分类的确切程度。例如，将 1 误分类为 5 比将 1 误分类为 2 损失更大。

2a) 我理解的对吗？仅通过指定观察权重就不可能容纳这种损失函数？
2b) 如果 2a) 的答案是肯定的，您可以推荐什么免费软件来解决该问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</guid>
      <pubDate>Sun, 09 Jun 2024 21:06:27 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型中的估计</title>
      <link>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</link>
      <description><![CDATA[我目前正在尝试通过 Simon N. Wood 所著的《广义可加模型：R 语言简介》一书来了解广义可加模型 (GAM)。但是，我对以下部分有一些疑问。
第 6.1 章指出，GAM 成为过度参数化的 GLM，形式为
$$g(\mu_i) = X_i\beta, \quad y_i \sim EF(\mu_i, \phi),$$
其中 $EF$ 代表指数族，并且 $\beta$ 通过最大化来估计
$$l_p(\beta) = l(\beta) - \frac{1}{2\phi}\sum_j\lambda_j\beta^TS_j\beta.$$
我的问题是：

简单地从对数似然中减去惩罚项的总和，然后最大化相对于$\beta$的结果函数的理由是什么？
因子$\frac{1}{2\phi}$从何而来？

任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</guid>
      <pubDate>Sun, 09 Jun 2024 20:48:15 GMT</pubDate>
    </item>
    <item>
      <title>$E[X\mid \max(X,Y,Z)]$ 带有因变量 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648896/ex-mid-maxx-y-z-with-dependent-variables</link>
      <description><![CDATA[设$(X,Y,Z)$为三维随机变量，其密度函数为$f(x,y,z)=\frac{2}{3}(x+y+z)$在$0&lt;x,y,z&lt;1$上。计算$E[X\mid \max(X,Y,Z)]$。
我认为答案是$\frac{25}{36}\max(X, Y, Z)$，但我不确定：
\begin{gather*}
E[X\mid \max(X,Y,Z)=u]=\\
=\frac{\int_0^u\int_0^u uf(u,y,z)dydz+\int_0^u\int_0^u xf(x,u,z)dxdz+\int_0^u\int_0^u xf(x,y,u)dxdy}{\int_0^u\int_0^u f(u,y,z)dydz+\int_0^u\int_0^u f(x,u,z)dxdz+\int_0^u\int_0^u f(x,y,u)dxdy}
\end{gather*&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/648896/ex-mid-maxx-y-z-with-dependent-variables</guid>
      <pubDate>Sun, 09 Jun 2024 09:13:22 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归模型的饱和模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648883/saturated-model-for-logistic-regression-model</link>
      <description><![CDATA[一个逻辑回归模型已拟合到包含 n = 27 个不同协变量模式的样本，
其中 ni = 10 个单位。
相应饱和模型中的参数数量是 27 还是 26（不包括截距）？]]></description>
      <guid>https://stats.stackexchange.com/questions/648883/saturated-model-for-logistic-regression-model</guid>
      <pubDate>Sat, 08 Jun 2024 21:41:29 GMT</pubDate>
    </item>
    <item>
      <title>emmeans 中交互作用中缺少类别，我可以获得某个因子水平的全局边际均值吗？</title>
      <link>https://stats.stackexchange.com/questions/648947/missing-category-in-an-interaction-in-emmeans-can-i-obtain-the-global-marginal</link>
      <description><![CDATA[我有一个数据集，其中的测量值来自五个不同城市的两种环境。在其中一个城市，我们无法获得其中一个环境的测量值。运行 emmeans 时，我得到了该城市该环境的预期非估计边际均值。见下文：
 environment city_key emmean SE df lower.CL upper.CL
R C 3.20 0.472 210 2.266 4.13
U C 2.98 0.472 210 2.047 3.91
R K 4.61 0.609 210 3.408 5.81
U K 3.13 0.677 210 1.794 4.46
R M 3.85 0.666 210 2.534 5.16
U M nonEst NA NA NA NA
R T 1.93 0.518 210 0.904 2.95
U T 1.95 0.509 210 0.952 2.96
R V 2.78 0.354 210 2.080 3.47
U V 3.32 0.879 210 1.586 5.05

但是，我也想获得仅来自环境的边际均值，但由于我缺少其中一个，因此其中一个环境结果不是估计值。这就是 emmeans 的工作方式，据我所知。
 environment emmean SE df lower.CL upper.CL
R 3.27 0.231 210 2.81 3.73
U nonEst NA NA NA NA

我知道 emmeans 的警告（“由于涉及相互作用，结果可能会产生误导”），解决方案是删除我的两个因素之间的相互作用（已经尝试过，并且有效，但是......），但在我看来，相互作用的生物学意义及其解释很重要。
主要是，我想要结果的原因是由于标准误差和置信区间，我不确定如何手动计算边际均值。
有没有办法让 emmeans 输出结果，尽管我的模型中存在明显的漏洞数据？或者我手动计算边际均值的方法？或者有其他解决方案吗？
除了消除模型中的交互作用。我尝试了 ggeffects 中的 predict_response，使用 margin=marginalmeans 和 margin=empirical，但这些结果不同，我认为边际均值是我想要的结果。我也尝试过手动获得边际均值，只需从预测值中计算它们即可，但我不知道如何从它们中计算标准误差或置信区间——说到这个话题，如果我使用混合模型，这一切会有所不同吗？
我没有包含任何内容来重现我的结果，因为我认为我的问题很简单。如果您对我的观察次数感兴趣，这里有一个表格，列出了每个类别的观察次数（以及为什么我没有对 city_keyM:environmentU 进行估计）：
 city_key environment obs
&lt;fct&gt; &lt;fct&gt; &lt;int&gt;
1 C R 25
2 C U 35
3 K R 13
4 K U 10
5 M R 15
6 M U 0
7 T R 23
8 T U 22
9 V R 72
10 V U 16
]]></description>
      <guid>https://stats.stackexchange.com/questions/648947/missing-category-in-an-interaction-in-emmeans-can-i-obtain-the-global-marginal</guid>
      <pubDate>Sat, 08 Jun 2024 20:43:17 GMT</pubDate>
    </item>
    </channel>
</rss>