<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 17 May 2024 01:01:58 GMT</lastBuildDate>
    <item>
      <title>BerHu XGBoost 的自定义损失函数</title>
      <link>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</link>
      <description><![CDATA[我想要一个损失函数，它可以惩罚像 平方损失 这样的异常值，同时处理较小的损失误差不那么严重，例如绝对损失。看来我正在寻找一个 Huber loss 函数，但反过来，所谓的BerHu （提供我第一次看到它使用的论文，你可以在部分找到它&gt;3.2. 损失函数):
$$\mathrm{BerHu}_{\delta}(x)=\begin{cases} |x|, \text{ if } x\le \delta \\ \frac{ x^2 + \delta^2}{2\delta}, \text{ if } x&gt; \delta \end{案例}$$
我想将其实现为 XGBoost 的自定义损失。对于这个实现，如果我没有记错的话，您需要提供损失的梯度和粗麻布。然而，BerHu 不可二次微分，因为它包含绝对值项。 
我认为正是由于这个原因，XGBoost 不会 甚至有一个 Huber 损失的实现，而不是使用 Pseudo-Huber 损失。 
基本上我有两个问题：

尝试实现 XGBoost 的 BerHu 损失函数的最佳方法是什么？也许我错了，有一种方法可以完全按原样实现它。
如果不可能，“Pseudo-BerHu”的类似物将如何实现？看起来像？我不太明白 Pseudo-Huber 损失如何近似 Huber 损失，所以我正在努力想出类似的方法。

非常感谢有关此事的任何建议。如果已经存在另一个具有相同目的的函数，该函数是二次可微的，那么我也很想知道它]]></description>
      <guid>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</guid>
      <pubDate>Thu, 16 May 2024 23:57:49 GMT</pubDate>
    </item>
    <item>
      <title>如何处理导致数据漂移的特征？</title>
      <link>https://stats.stackexchange.com/questions/647392/what-to-do-with-features-causing-data-drift</link>
      <description><![CDATA[我处理了标记的训练数据和未标记的测试数据。我想调整和验证训练数据上的分类器，使其在测试中具有良好的性能。
通过进行一些调查，我注意到训练和测试的分布有很大不同。我针对识别数据点是否属于训练或测试的任务训练了分类算法。这会产生 AUC_score = 0.95。
y = np.zeros(len(total_df_all))
y[train_idx] = 1
XGBdata = xgb.DMatrix(数据=total_df_all, 标签=y)
params = {“目标”：“二进制：逻辑”，
          &quot;eval_metric&quot;:&quot;对数损失&quot;,
          “学习率”：0.05，
          &#39;最大深度&#39;: 8, }
# 使用 XGBoost 进行交叉验证
cross_val_results = cv(dtrain=XGBdata, params=params,
                       nfold=5，指标=“auc”，
                       num_boost_round=200,early_stopping_rounds=20,
                       as_pandas=真）
print((cross_val_results[“test-auc-mean”]).tail(1))

然后我提取了该分类器中具有较高重要性的特征的名称。
def prune_divergent_features(数据):
    Total_df_all = 数据
    发散特征 = []
    分数 = 1
    当分数 &gt;= 0.7 时：
        XGBdata = xgb.DMatrix(数据=total_df_all, 标签=y)
        params = {“目标”：“二进制：逻辑”，
                &quot;eval_metric&quot;:&quot;对数损失&quot;,
                “学习率”：0.05，
                &#39;最大深度&#39;: 8, }
        # 使用 XGBoost 进行交叉验证
        cross_val_results = cv(dtrain=XGBdata, params=params,
                            nfold=5，指标=“auc”，
                            num_boost_round=200,early_stopping_rounds=20,
                            as_pandas=真）
        valid_auc = (cross_val_results[&quot;test-auc-mean&quot;]).tail(1).values[0]
        分类器 = XGBClassifier(eval_metric=&#39;logloss&#39;,use_label_encoder=False)
        分类器.fit(total_df_all, y)
        发散 = 排序(classifier.get_booster().get_fscore().items()，reverse=True，key=lambda item:item[1])[0][0]
        divergent_features.append（发散）
        分数 = valid_auc
        Total_df_all = Total_df_all.drop([发散], axis=1)
       
    返回（分数，divergent_features）

当 AUC 分数达到 0.7 时，此代码将停止提取。这让我从 280 个特征中得到了大约 149 个特征。

很明显，在训练模型时，删除这么多特征将导致大量信息丢失。那么我该怎么做才能减轻训练和测试之间的这种差异呢？

我听说过一种技术，即根据训练集与测试集的 KL 散度对训练集进行加权，但这不会被视为数据泄漏吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/647392/what-to-do-with-features-causing-data-drift</guid>
      <pubDate>Thu, 16 May 2024 23:43:05 GMT</pubDate>
    </item>
    <item>
      <title>何时以及如何分层？</title>
      <link>https://stats.stackexchange.com/questions/647391/when-and-how-of-stratification</link>
      <description><![CDATA[我对分层的理解还处于初级阶段。例如，如果我们想在实验后推断中以性别为条件，我们可能会对性别进行分层或阻止。据我所知，我们取阻止变量可以采用的每个值，检索过滤器为真的所有单元，并随机分配给治疗和控制。结果，变量将被均匀分割或在$+/-1$一个单元内（如果样本大小为奇数）。
一些问题

什么时候需要这样做？ （又名纯随机化难道不应该“足够接近”吗？）
在没有分层的情况下对变量进行条件化是否错误？
对于连续变量，是否有一致同意的方法？

对于最后一个问题，我设想可以将数据分组为分位数，然后将纯随机化应用于每个分位数块。
最后，据我所知，ANCOVA 可以纠正因变量及其协变量的不平衡；分层是否仅仅可以防止其中的任何强相关性？（而这仅被认为是极不可能的，但通过纯随机化并非不可能？）]]></description>
      <guid>https://stats.stackexchange.com/questions/647391/when-and-how-of-stratification</guid>
      <pubDate>Thu, 16 May 2024 23:13:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 nls() 对非常嘈杂的数据进行非线性回归</title>
      <link>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</link>
      <description><![CDATA[我正在尝试将噪声数据拟合到具有两个我想估计的参数的特定模型。不幸的是，模型拟合很糟糕，噪声也增加了。我可以做些什么来改善这种契合度吗？
公式/模型如下所示：
model_form &lt;- as.formula(y ~ 1/((1/i)-(r*x)))
下面我创建了一些添加了噪声的示例数据。如果没有此噪音，nls() 拟合效果良好，最终估计 r 和 i 足够好。但随着噪声的增加，尽管热图中存在可见的模式，但模型拟合和参数估计很差。
使用示例参数 i 和 r 创建样本数据（这些参数实际上未知，但仅限于特定的已知区间）：
my_i &lt;- 0.5 # i 参数示例
my_r &lt;- 100 # r 参数示例
d &lt;- data.frame(x=c(-rexp(500,rate=10),
                    seq(-1,0,length.out = 500))) %&gt;%
    突变（y=抖动（1/（（1/my_i）-（my_r * x）），1000））
噪声 &lt;- data.frame(x=runif(1000,-1,0),
                    y=runif(1000,0,0.5))
d &lt;-bind_rows(d,噪声)

以下函数使用上面的 model_form 将该数据拟合为 nls。
fitPlot &lt;- 函数（数据）{
    适合 &lt;- nls(model_form,数据,
               开始=列表(r=10,i=0.3))

    fit_r &lt;- 摘要(fit)$系数[“r”,1]
    fit_i &lt;- 摘要(fit)$coefficients[“i”,1]

    预测 &lt;- data.frame(x=seq(-1,0,length.out=1000)) %&gt;%
        变异(y=1 / (1/fit_i - fit_r * x))

    p &lt;- ggplot(数据)+
        geom_bin2d(aes(x,y),bins=14)+
        geom_line(数据=预测,aes(x,y))+
        注释（“标签”，x=-0.7，y=0.5，
                 标签=paste0(“r:”,fit_r,”, i:”,fit_i))
    p
}

拟合图(d)

此时我能做些什么吗？我已经尝试过了

具有可能的 i 和 r 值的网格搜索 = 与 nls 相同的结果
optim具有不同的优化方法，具有最小化SS的功能
nlrob 来自使用不同方法的Robustbase

我在这一点上迷失了，不知何故必须有一种方法来创建一个强大的模型？不知何故，我需要减少对异常值的惩罚，但是怎么做呢？欢迎任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</guid>
      <pubDate>Thu, 16 May 2024 23:02:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么 n 个 iid 随机变量 (X1, X2,…, Xn) 的最大值 (Y) 的 cdf G(y) 的 cdf F(X<=y) 提高到 n 次方，而不是 F(X<=y) )^(n-1)*f(X=y)？</title>
      <link>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-gy-for-the-maximum-y-of-n-iid-random-variables-x1-x2-xn</link>
      <description><![CDATA[当我从精算概率问题样本库中解决问题#64时，我想到了这个问题：https://www.soa.org/globalassets/assets/Files/Edu/edu-exam-p-sample-quest.pdf 
这里也给出了解决方案：https://www.soa.org/499179/globalassets/assets/files/edu/edu-exam-p-sample-sol.pdf
如果您有任何疑问，请告诉我，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-gy-for-the-maximum-y-of-n-iid-random-variables-x1-x2-xn</guid>
      <pubDate>Thu, 16 May 2024 22:56:54 GMT</pubDate>
    </item>
    <item>
      <title>观测数据的隆起建模/条件平均治疗效果 (CATE) 估计技术</title>
      <link>https://stats.stackexchange.com/questions/647389/techniques-for-uplift-modelling-conditional-average-treatment-effectcate-estim</link>
      <description><![CDATA[我最近开始学习 CI，正在阅读这篇非常著名的论文：https:/ /proceedings.mlr.press/v67/gutierrez17a.html 其中提到随机对照试验是提升建模的重要组成部分。
我的问题如下：一家公司开展了 WhatsApp 营销活动，他们仅向那些最有可能（高概率）使用其某项服务的客户发送消息。
此概率是使用 ML 模型计算的。我们试图建议我们不要将消息发送给那些在没有任何此类推动的情况下就会这样做的用户，这将降低获取成本。
这需要估算每个客户的 CATE，并仅向 CATE 估算较高的客户发送消息。我找不到任何用于估计观测数据中的 CATE 的既定技术。
关于观测数据的 CATE 估计，我发现的所有内容如下：https://youtu.be/0GK6IZut6K8 ?si=Ha1klt_kQaCILyGO 但他们没有引用任何论文（我认为）。 uber 的因果机器学习库也提到他们支持根据观测数据进行 CATE 估计，但我没有看到任何示例。
如果有人能给我指出一些已在行业中实施的论文，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/647389/techniques-for-uplift-modelling-conditional-average-treatment-effectcate-estim</guid>
      <pubDate>Thu, 16 May 2024 22:17:20 GMT</pubDate>
    </item>
    <item>
      <title>Delta 方法与实际期望</title>
      <link>https://stats.stackexchange.com/questions/647386/delta-method-vs-actual-expectation</link>
      <description><![CDATA[如果
&lt;块引用&gt;
$x \sim N(\mu,\sigma^2)$

然后根据第一原则，
&lt;块引用&gt;
$E(e^x) = e^{\mu + \sigma^2 / 2}$

我正在尝试找出“Delta 方法”在哪里。这里错了：
如果
&lt;块引用&gt;
$(x-\mu) \sim N(0,\sigma^2)$

然后
&lt;块引用&gt;
$(f(x)-f(\mu)) \sim N(0,\sigma^2 * f&#39;(\mu)^2)$

使用 $f(x) = e^x$ 的 Delta 方法将意味着
&lt;块引用&gt;
$(e^x-e^\mu) \sim N(0,\sigma^2 * (e^\mu)^2 )$

这意味着
$E(e^x) = e^\mu$]]></description>
      <guid>https://stats.stackexchange.com/questions/647386/delta-method-vs-actual-expectation</guid>
      <pubDate>Thu, 16 May 2024 21:00:56 GMT</pubDate>
    </item>
    <item>
      <title>合并时间序列回归</title>
      <link>https://stats.stackexchange.com/questions/647384/pooled-time-series-regression</link>
      <description><![CDATA[假设我正在对某些全球预测变量 $r_{i,t}$ -container&quot;&gt;$p_{t-1}$ ，其中 $i$ 和 $t$&lt; /span&gt; 分别表示国家和月份：
\begin{方程}
r_{i,t}=\alpha_i + \beta_i p_{t-1}+\epsilon_{i,t}
\end{方程}
假设我在 50 个国家/地区运行此程序，从而获得 50 个 $\beta_i$。如果我想解释为什么一些国家是根据一些非时变国家特征来预测的 $C_{i}$ 我可以运行这个跨国回归:
\begin{方程}
\beta_{i}=\gamma + \lambda C_{i}+\omega
\end{方程}
例如，$C$ 可以作为一个虚拟国家，用于判断一个国家是发达国家还是新兴国家，在这种情况下，我们想要了解 $p$ 对发达国家的预测多于对新兴国家的预测。
$\lambda $ 是兴趣系数。
现在，我的问题：如何最好一步完成此操作，以避免错误估计 $\beta$ 并允许使用随时间变化的 $C$。一种选择是合并回归（仅堆叠 50 个国家/地区并与 $C$ 交互）：
\begin{方程}
r_{i,t}=\alpha + \beta_{1} p_{t-1} + \beta_{2} p_{t-1}\times C_{i,t} + \beta_{3} C_{i ,t}+\epsilon_{i,t}
\end{方程}
这是否相当于上面概述的两步过程或者有问题？如果有问题，为什么会这样以及什么是更好的替代方案？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647384/pooled-time-series-regression</guid>
      <pubDate>Thu, 16 May 2024 20:29:10 GMT</pubDate>
    </item>
    <item>
      <title>预测拼写错误：如何对噪声通道建模？</title>
      <link>https://stats.stackexchange.com/questions/647383/predicting-spelling-errors-how-should-the-noisy-channel-be-modeled</link>
      <description><![CDATA[我有兴趣使用噪声通道方法来执行此操作拼写纠正。当拼写错误导致另一个现有单词时，我对使用此技术特别感兴趣。例如。想象一下，如果有人输入“NUCLEAR”当他们想写“不清楚”时。
噪声通道方法将结合每个单词的先验概率，以及分隔序列的噪声概率（在 UNCLEAR 的情况下有 1 次换位，在 NUCLEAR 的情况下没有错误）。
但是，根据我们的噪声概率函数的粒度，我们最终得到的“UNCLEAR”概率可能要低得多。
$$P(\text{UNCLEAR}) = P(\text{UNCLEAR})\cdot P(\text{1 换位})$$
$$P(\text{UNCLEAR}) = P(\text{UNCLEAR})\cdot P(\text{1 在字符 1 和 2 处转置})$$
例如，如果我们的噪声模型忽略了错误的位置，那么我们最终会得到 UNCLEAR 的较高概率，而如果我们的噪声模型考虑位置，则判断为 UNCLEAR 的可能性要小得多。&lt; /p&gt;
我们的噪声概率函数应该有多精细？]]></description>
      <guid>https://stats.stackexchange.com/questions/647383/predicting-spelling-errors-how-should-the-noisy-channel-be-modeled</guid>
      <pubDate>Thu, 16 May 2024 19:50:24 GMT</pubDate>
    </item>
    <item>
      <title>重复测量比例，但没有个别受试者的信息</title>
      <link>https://stats.stackexchange.com/questions/647380/repeated-measurements-of-proportions-with-no-information-on-individual-subjects</link>
      <description><![CDATA[我正在研究一个数据集（不是我的），其中包括在 50 个等间隔时间点测量的重复测量比例。有两组。 A组有65人，B组有23人。对于每个时间点，数据包括每组进行梳理的个体数量。例如，在第一个时间点，A 组的 65 个人中有 10 人正在梳理毛发，而 55 人则没有。例如在下一个时间点，65 个人中有 11 个人在整理，但我不知道这是否包括之前相同的 10 个人，或者不同的人。
如何比较两组的平均整理比例？
我担心的是，因为它们是重复测量，所以数据点不是独立的，但由于没有关于个体的信息，我不能对受试者 ID 使用随机效应。
此外，假设同一群体中的所有个体都花费相同的时间进行整理，那么群体的平均比例是否可以作为该群体中个体进行整理的时间比例的估计？
这是数据集的前 3 行和最后 3 行。

非常感谢您的宝贵时间！]]></description>
      <guid>https://stats.stackexchange.com/questions/647380/repeated-measurements-of-proportions-with-no-information-on-individual-subjects</guid>
      <pubDate>Thu, 16 May 2024 19:34:40 GMT</pubDate>
    </item>
    <item>
      <title>逆高斯函数的 CDF 的简化形式，作为漂移参数的函数</title>
      <link>https://stats.stackexchange.com/questions/647377/simplified-form-for-cdf-of-inverse-gaussian-function-as-function-of-the-drift-p</link>
      <description><![CDATA[我正在考虑将事件的概率建模为带有漂移的布朗运动通过某个障碍的等待时间。然后考虑该概率的表达式如何作为漂移。该表达式是否与某些更知名的函数相关（例如，某些类型的二项式回归中使用的函数）？
对于具有正漂移的布朗运动 $\nu$ 方差 $\sigma^2$ 和从零开始，正距离处的第一次通过时间 $a$ 分布为 $IG\left(\mu =\frac{a}{\nu}, \lambda = \left(\frac{ a}{\sigma}\right)^2 \right)$。然后通过 CDF 计算 $t$ 时刻的通过概率。
我们可以将表达式简化为用于二项式回归的形式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647377/simplified-form-for-cdf-of-inverse-gaussian-function-as-function-of-the-drift-p</guid>
      <pubDate>Thu, 16 May 2024 19:04:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么两个线性回归中的 beta 系数相同？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/647369/why-are-beta-coefficients-in-the-two-linear-regressions-same</link>
      <description><![CDATA[我尝试了两个具有相同因变量的线性回归$y$。让我们假设因变量和自变量都以 0 为中心，以避免需要截距。
第一个有 2 个自变量 $[X_1, X_2]$ 并获得系数 $\beta_1$ 和 $\beta_2$。
在第二个回归中，$y$ 相对于 $E_1$ 进行回归，其中 $E1$ 是 $X_2$ 相对于 $X1$&lt; 回归时的残差/span&gt; 并得到系数 $\beta_1^{&#39;}$
我发现 $\beta_1$ = $\beta_1^{&#39;}$。
我也尝试过对多个自变量进行此操作。在第一个回归中，我使用 $[X_1, X_2, ..., X_{n+1}]$ 作为自变量，下一个回归我使用 $[E_1, E_2, ..., E_n]$ 其中每个 $E_i$ 是 &lt; 回归的残差span class=&quot;math-container&quot;&gt;$X_i$ 与 $X_{n+1}$ 对比，发现系数与两个中的所有 n 个向量都匹配回归。
有人可以帮我理解为什么会出现这种情况吗？下面是我用来测试这个的代码。
代码
导入 statsmodels.api 作为 sm
将 numpy 导入为 np

np.随机.种子(0)

n = 100
X = np.random.normal(大小=(n, 5))
y = X.sum(axis=1) + np.random.normal(scale=2, size=n)
y = y - y.mean()

打印（sm.OLS（y，X）.fit（）.params）

E = np.zeros((n, 4))
对于范围 (4) 内的 i：
    E[:, i] = X[:, i] - sm.OLS(X[:, i], X[:, 4]).fit().params * X[:, 4]

打印（sm.OLS（y，E）.fit（）.params）

输出
&lt;预&gt;&lt;代码&gt;[1.04494552 1.13192292 1.41357081 0.9452581 0.920087]
[1.04494552 1.13192292 1.41357081 0.9452581 ]
]]></description>
      <guid>https://stats.stackexchange.com/questions/647369/why-are-beta-coefficients-in-the-two-linear-regressions-same</guid>
      <pubDate>Thu, 16 May 2024 15:55:20 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用 ANCOVA 评估适度吗？</title>
      <link>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</link>
      <description><![CDATA[我正在使用 SPSS 进行 1 组 IV（4 个水平）的分析，在时间 1 和时间 2 为每组中的每位参与者测量一个 DV，并在时间 2 或为每组中的每位参与者测量一次协变量。每个组在时间 1 和时间 2 之间接受不同类型的干预。
我计划使用组内变量作为时间进行 2 x 4 混合 ANCOVA。我可以使用相同的模型来评估 CV 的调节效果吗？我想根据 CV 水平了解哪组/（干预类型）的 DV 增加幅度更大。
我正在考虑进行后续审核；但是，我不确定是否可以通过将时间 1 DV 分数作为受试者内因素来计算模型中的时间 1 DV 分数。
CV与DV、IV与CV之间已建立关系；然而，人们对 IV（组）各水平与 DV 之间的关系程度知之甚少。
我想知道：

我想看看当我调整 CV 时，IV 对 DV 的影响是否显着（各组从时间 1 到时间 2 增加 DV 的能力是否存在差异）
我想查看各组从时间 1 到时间 2 增加 DV 能力的顺序（哪一组最好，第二，第三，最后）。
我想看看 IV 和 IV 之间的关系在不同 CV 点是否发生变化。 （对于不同级别的 CV/调节器，哪个组/（干预类型）的 DV 增加更大）。

我不确定这两项调查是否从根本上相互对立（例如，由于违反了彼此的模型假设，两者不可能同时具有显着性）。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</guid>
      <pubDate>Thu, 16 May 2024 15:13:02 GMT</pubDate>
    </item>
    <item>
      <title>有向边可见吗？</title>
      <link>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</link>
      <description><![CDATA[
以上两个PAG（部分祖先图）都是在相同条件下使用FCI（快速因果推理）算法生成的，唯一的区别是右边的PAG是在从数据集中排除变量5后生成的。
有人可以帮我确定右侧 PAG 中 9 和 11 之间的有向边是否可见并解释一下此分析中涉及的步骤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</guid>
      <pubDate>Thu, 16 May 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 R 中的 AggregateExpression()？</title>
      <link>https://stats.stackexchange.com/questions/647378/how-to-interpret-aggregateexpression-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647378/how-to-interpret-aggregateexpression-in-r</guid>
      <pubDate>Thu, 16 May 2024 14:39:46 GMT</pubDate>
    </item>
    </channel>
</rss>