<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 18:20:21 GMT</lastBuildDate>
    <item>
      <title>glmmTMB 的预测函数</title>
      <link>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</link>
      <description><![CDATA[我有以下模型：
mod &lt;- glmmTMB(cound_data ~ year-1 +(1|Site), ziformula = ~year-1, data = df, family = &quot;nbinom2&quot;)。我正在对 4 个不同年份和 38 个不同站点的计数数据进行建模。由于数据中存在许多零，我使用零膨胀模型。我的主要兴趣在于年份的影响，但我也对探索不同站点的结果感兴趣。
我使用代码获得固定效应：fixef(mod)，使用代码获得随机效应：ranef(mod)。
假设对于 2018 年，我的固定效应为 0.85，对于站点&quot;X&quot;，我的随机效应（截距）为 -0.18。根据我的理解，要获得站点&quot;X&quot;的预测值在 2018 年，我应该手动计算如下：exp(0.85-0.18)=1.95。
但是，当我使用 predict() 函数时：df$predicted_mean &lt;- predict(mod, newdata = df, re.form = NULL, type = &quot;response&quot;) 我获得了 2018 年站点 &quot;X&quot; 的不同值，例如 1.1。我不认为这种差异是由于舍入误差造成的。
predict() 函数计算的值与我的手动计算不同吗？它也考虑了 ziformula 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</guid>
      <pubDate>Mon, 19 Aug 2024 17:37:05 GMT</pubDate>
    </item>
    <item>
      <title>在成对 Wilcox 检验中选择 p 调整方法</title>
      <link>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</link>
      <description><![CDATA[我需要一些帮助来选择 p 调整方法，以在四个不同独立组的权重上进行成对 Wilcox 检验（使用 R）。
我一直在阅读有关不同方法的文章，并在 Google 上搜索了大量答案。我是统计学新手，不幸的是，其中许多方法变得过于复杂，但我的结论是方法取决于数据。所以我想知道是否有人可以根据我的数据给我一些提示或指导（见下面的测试结果）。
我已经测试了所有可用的方法（“bonferroni”、“holm”、“hochberg”、“hommel”、“BH”、“BY”），除了 Benjamini 和Yekutieli 方法。
如果有人知道根据数据选择方法的一般准则，请告诉我（我找不到任何准则）。
我的测试结果如下：
BH 方法（作为示例 - 除了 BY 之外，N-A 的 p.adj 值对所有值都相同）：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.signif
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 0.673 ns 
2 权重 S A 127 164 11542 0.113 0.226 ns 
3 权重 S T 127 195 11720 0.417 0.625 ns 
4 权重 N A 7696 164 711349 0.005 0.031 * 
5 权重 N T 7696 195 734472 0.613 0.673 ns 
6 权重 A T 164 195 14233 0.073 0.219 ns 

按方法：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.si
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 1 ns 
2 权重 S A 127 164 11542 0.113 0.554 ns 
3 权重 S T 127 195 11720 0.417 1 ns 
4 权重 N A 7696 164 711349 0.005 0.077 ns 
5 权重 N T 7696 195 734472 0.613 1 ns 
6 权重 A T 164 195 14233 0.073 0.536 ns 

请注意，组 N 的样本比其他组多得多。
两个问题：

哪一个我应该使用什么方法？
为什么 BY 不同？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</guid>
      <pubDate>Mon, 19 Aug 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>具有相同因变量的半相关回归 (SUR)。这对于时间序列有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/653018/semingly-unrelated-regressions-sur-with-the-same-dependant-variable-does-it-m</link>
      <description><![CDATA[SUR 对我来说是一个新概念，我的导师提到过它，我应该在研究中探索它。
我有一个变量（我们称之为 y），它是我的因变量。我还有 6 个控制变量和一个表示不同国家情绪的变量（比如说，sentiment_country_A 和 sentiment_country_B）。
我将所有这些变量都放在一个表中，它们的值在 6 年内每三个月出现一次（30 行）。
我想知道每个国家的情绪如何影响我的因变量。所以，我想创建这两个回归：
y ~ sentiment_country_A + 控制变量
y ~ sentiment_country_B + 控制变量
我尝试对它们运行 SUR，结果得到的 R 平方非常低（0.36），而且并非所有变量的 p&lt;0.05。残差也高度相关（~0.99）。
对于我的场景，这是正确的方法吗？我应该使用其他方法吗？我没有统计学背景，因此获得一些见解将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653018/semingly-unrelated-regressions-sur-with-the-same-dependant-variable-does-it-m</guid>
      <pubDate>Mon, 19 Aug 2024 16:42:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 或 Eviews 中的 arima() 无法为 ARMA(1,1) 提供准确的 ML 估计量？为什么我的代码可以给出更好的估计？</title>
      <link>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</link>
      <description><![CDATA[我模拟了一个遵循 ARMA(1,1) 模型的时间序列，具体来说就是 y(t)=2+0.8y(t-1)+e(t)-0.4e(t-1)。我根据精确似然函数编写了一些代码来执行最大似然估计 (MLE)。代码如下
library(numDeriv)
#生成一个时间序列
n &lt;- 50
set.seed(123)
epsilon=rnorm(n,0,1)
y=c(1:n)

for(i in 2:n)
{
y[i]=2+0.8*y[i-1]+epsilon[i]-0.4*epsilon[i-1]
}
#--------------------------------------------------------

llk &lt;- function(miu,alpha,beta,sigma2){
mean = miu /(1-alpha)
sigma_total = (1 + (alpha+beta)^2/(1-alpha)) * sigma2 #方差
log_likelihood &lt;- sum(dnorm(y, mean, sigma_total, log = TRUE)) 
return(-log_likelihood)
}

library(bbmle)
lower_bounds &lt;- c(miu = -Inf, alpha = -1, beta = -1, sigma2 = 0)
fit_norm &lt;- mle2(llk, start = list(miu=0.1,alpha=0.1,beta=-0.1,sigma2=0.25)
summary(fit_norm)

运行结果为：
系数：
估计标准误差z值Pr(z) 
miu 2.4832e+00 1.2019e+00 2.0661 0.03882 * 
alpha 7.2875e-01 1.2790e-01 5.6977 1.214e-08 ***
beta -9.0982e-05 2.3149e-01 -0.0004 0.99969 
sigma2 1.4708e+00 1.4708e-01 9.9998 &lt; 2.2e-16 ***

然而，当我使用 R 或 Eviews 中的 arima() 函数估算模型时，我注意到：（1）从两个软件包获得的结果之间有细微的差异。但我自己的结果和软件的结果之间存在显着差异。（2）与从软件获得的估计值相比，我的 MLE 估计更接近真实参数。“
为什么？
R 的结果是
arma_model&lt;-arima(y,order=c(1,0,1))
arma_model$coef
ar1 ma1 截距 
0.9493775 -0.1092253 7.7225015 

Eviews 的结果是
 变量系数 
C 7.513484
AR(1) 0.968957
MA(1) -0.199021
SIGMASQ 1.326798
]]></description>
      <guid>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</guid>
      <pubDate>Mon, 19 Aug 2024 14:33:18 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（甚至可能到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合）？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，将重复数据作为增强技术是否存在各种统计问题？

注意：这可能是一个很难回答的问题，因为它需要了解两种不同文化中的原理，即统计学和机器学习中的原理，即使它们本质上在做同样的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>回归中的独立指标变量在改变类别数量时变得显著</title>
      <link>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</link>
      <description><![CDATA[我正在使用二元响应变量运行逻辑回归。无论我是否使用家庭作为指示变量，家庭规模都会产生微小的正向但不显著的影响。
当将家庭规模视为具有 3 个级别的分类变量（单户、中型或大型家庭）来检查其是否有影响时，与排除的类别（单户）相比，两个包含的虚拟变量都具有很强的显著性和正向性。为什么会这样？
假设不仅家庭规模会对结果产生积极影响，而且家庭规模也会产生积极影响。我也将家庭规模视为分类变量，因为它在数据集中只能采用 7 个不同的值。
（我有大量观察值和其他预测因子。）
非常感谢您的帮助，br]]></description>
      <guid>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</guid>
      <pubDate>Mon, 19 Aug 2024 13:47:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/653008/time-series-forecast</link>
      <description><![CDATA[我一直想向预测领域的专家询问一个关于我正在进行的预测项目的迫切问题。我正在建立一个模型来预测地下水厚度，任务是使用地表温度、降水等外生变量。鉴于使用季节和日历特征作为外生变量在预测范围内始终可用，但地表温度、降水等外生变量则不可用。我是否必须递归预测地表温度和降水等外生变量，然后才能继续预测地下水厚度？我非常感谢您的意见。期待很快收到您的来信。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653008/time-series-forecast</guid>
      <pubDate>Mon, 19 Aug 2024 11:53:55 GMT</pubDate>
    </item>
    <item>
      <title>计算缺失值数据的趋势</title>
      <link>https://stats.stackexchange.com/questions/653006/computing-trends-on-data-with-missing-value</link>
      <description><![CDATA[我正在收集一些用户的反馈。无法保证所有用户都会提供反馈。因此，在每个时间段内，都会有很多没有反馈值的反馈表。
我想确定通过表单收集的反馈值的趋势和异常值。考虑到大部分数据缺失，计算它们的最佳方法是什么。
缺失值影响问题的方式之一是“坏”或“好”反馈数量的减少并不一定意味着反馈发生变化。回复表单的人数可能较少。在这种情况下，我该如何处理缺失数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/653006/computing-trends-on-data-with-missing-value</guid>
      <pubDate>Mon, 19 Aug 2024 11:22:57 GMT</pubDate>
    </item>
    <item>
      <title>包含一些随机和固定效应因素的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</link>
      <description><![CDATA[我目前正在分析一项实地试验的数据，该试验最初设计用于双向方差分析。该试验涉及两个因素——土壤（2 个级别）和植物（2 个级别），在区块设计中重复 6 次。该试验包括三个采样时间和两个土壤深度的数据。
考虑到随时间和不同深度重复测量，我担心双向方差分析所需的独立性假设。虽然对每个采样和深度进行单独的双向方差分析是一种选择，但它会导致统计能力的损失，并阻碍不同采样和深度之间的交叉比较，这对我的研究至关重要。
为了应对这些挑战，我正在考虑使用具有以下结构的线性混合模型：
soil_carbon ~ (SOILPLANTDEPTH*TIME) + (1|BLOCK) + (1|PLOT) + (1|PLOT:SAMPLING) + (1|PLOT:DEPTH)
模型说明：
(SOILPLANTDEPTH*TIME)：该术语表示研究的固定效应之间的相互作用。
(1|BLOCK)：阻塞的随机效应
1|PLOT)：不同地块的随机效应
(1|PLOT:SAMPLING)：嵌套在 PLOT 中的 SAMPLING。考虑到采样总是在同一图中完成的事实。
（1|PLOT:DEPTH）：PLOT 内嵌套的 DEPTH。考虑到每个图中采样的深度不同。
具体问题：
a) 鉴于随机效应中的 SAMPLING 和 DEPTH 嵌套在 PLOT 内，这些因素是否也可以作为固定效应包含在模型中？我的目标是比较不同级别的深度和采样。它们应该同时包含在随机效应和固定效应中，还是只包含在随机效应中？
b) 为了检验固定效应的显著性，我正在考虑使用似然比检验来简化模型。这种方法适用于线性混合模型吗？
如果您对分析这些数据有任何其他建议或推荐，我将非常感谢您的见解。
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</guid>
      <pubDate>Mon, 19 Aug 2024 11:21:13 GMT</pubDate>
    </item>
    <item>
      <title>与连续和分类变量的 emtrends 或 emmeans 进行双向交互</title>
      <link>https://stats.stackexchange.com/questions/653021/2-way-interaction-with-emtrends-or-emmeans-for-a-continues-and-categorical-varia</link>
      <description><![CDATA[我有一个数据集，其中包含一个连续结果变量（好奇心）和三个独立变量：年龄和准确度（均为两个级别的分类），以及具有线性和二次项的置信度。这是一个与我的类似的示例数据集（id 是主题编号）：
 set.seed(300)
df&lt;-data.frame(
id=rep(c(1:10), each=100),
confidence=sample(1000, 100, replace=TRUE),
curry=sample(1000, 100, replace=TRUE),
age=as.factor(rep(c(1:2), each=500)),
accuracy=as.factor(sample(c(1,2), replace=TRUE, size=1000))
)

df &lt;- df %&gt;%
polypoly::poly_add_columns(confidence, degree = 2, prefix = &quot;c&quot;, scale_width = 101)

假设，我对此数据集进行分层贝叶斯回归拟合，如下所示（这里我将 chain 和 iter 设置为较低，以简化和提高速度）
reg_model = brm(curiosity~(c1+c2)*age*accuracy+
((c1 + c2) * accuracy | id),
data=df,
chains = 1, iter = 500)

这给了我以下结果。
describe_posterior(
reg_model,
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;,
effects = &quot;fixed&quot;, diagnostic = NULL, distribution = TRUE
) %&gt;%
as_tibble() %&gt;% 
mutate(pd = percent(pd, .01)) %&gt;%
kbl(digits = 2,
caption = &quot;原始模型的参数&quot;) %&gt;% 
kable_classic(html_font = &quot;Arial&quot;, full_width = FALSE)


如您所见，此示例中没有显著的交互作用。但是，假设准确度和 c1 之间的交互作用是显著的。因此，我想跟踪这种交互作用，看看正确（准确度=1）和不正确（准确度=2）的 c1 斜率有何不同。也就是说，我想查看不正确的 c1 斜率，正确的 c1 分钟斜率。我使用了 emtreand 和 emmeans 但总是得到三向交互结果。这是我尝试过的。
emm &lt;- emtrends(
reg_model,
var = &quot;c1&quot;, by = c(&quot;accuracy&quot;),
at = list(confidence1 = 0, c2 = -32.9)
)
describe_posterior(
emm,
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;, distribution = TRUE
) %&gt;%
bind_rows(
describe_posterior(
pair(emm),
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;, distribution = TRUE
) 
) %&gt;% 
mutate(pd = percent(pd, .01)) %&gt;%
kbl(digits = 2,
caption = &quot;线性趋势对比&quot;) %&gt;% 
kable_classic(html_font = &quot;Arial&quot;, full_width = FALSE)

这给了我这个

如您所见，此表还包括年龄。有办法解决这个问题吗？非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653021/2-way-interaction-with-emtrends-or-emmeans-for-a-continues-and-categorical-varia</guid>
      <pubDate>Sun, 18 Aug 2024 23:41:37 GMT</pubDate>
    </item>
    <item>
      <title>平均预测和边际效应相互作用之间的差异</title>
      <link>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</link>
      <description><![CDATA[我有一个固定效应模型，其中我对分类变量随时间变化的边际效应感兴趣。以下是一个示例，说明我正在做什么：
library(fixest)
library(marginaleffects)
library(ggplot2)

# 设置可重复性的种子
set.seed(123)

# 观察次数
n &lt;- 500 # 10 个时间点，每个时间点 50 次观察

# 模拟数据
data &lt;- data.frame(
ID = 1:n,
Time = factor(rep(1:10, each = 50)), # 10 个时间点，每个时间点 50 次观察
Category = factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), length.out = n)), # 3 级分类独立变量
Control1 = rnorm(n, mean = 50, sd = 10), # 具有一定变化的连续控制变量
Control2 = sample(0:1, n, replace = TRUE) # 具有随机分配的二元控制变量
)

# 二元结果变量，设计为随类别和时间变化
data$Outcome &lt;- rbinom(n, 1, prob = plogis(0.5 + 0.3 * as.numeric(data$Category) - 0.2 * as.numeric(data$Time) + 0.05 * data$Control1 - 0.1 * data$Control2))

# 使用固定效应拟合模型
model &lt;- feglm(
Outcome ~ Category + Control1 + Control2 |时间，
数据 = 数据，
家庭 = 二项式 (&quot;logit&quot;)
)

# 模型摘要
summary(model)

# 按类别和时间获取平均预测
预测 &lt;- avg_predictions(model, by = c(&quot;类别&quot;, &quot;时间&quot;))

# 显示预测
print(predictions)

# 绘制带有置信区间的预测
ggplot(predictions, aes(x = 时间, y = 估计, 颜色 = 类别, 组 = 类别)) +
geom_line(size = 1) +
geom_point(size = 2) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = 类别), alpha = 0.2, 颜色 = NA) +
labs(title = &quot;按类别随时间变化的预测概率&quot;,
x = &quot;时间&quot;,
y = &quot;预测概率&quot;) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

我有两个问题：

绘制类别变量在时间变量值上的边际效应与将每个时间变量与每个类别交互并绘制这些交互的边际效应之间有什么区别？我理解包括交互会假设效果可能会受到时间的影响，但如果数据表明如此，边际效应方法不会显示相同的结果吗？例如，如果时间 =3 类别 A 的结果可能性明显高于基线，即使没有交互项，这也可能会反映在数据中，对吗？
无论是否添加交互项（类别*时间），逐步分析每个类别的时间条件效应的正确方法是什么？例如，如果我想确定时间 =3、类别 A、时间=4、类别= A、时间= 5、类别的值，以与上一次相比估计的变化为准
]]></description>
      <guid>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</guid>
      <pubDate>Sun, 18 Aug 2024 16:47:17 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>非参数和半参数 cif</title>
      <link>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</link>
      <description><![CDATA[我最近尝试使用 {survival 来深入了解竞争风险分析。
使用的数据来自 {survival。
library(survival)
library(ggsurvfit)

mgus2$etime &lt;- with(mgus2, ifelse(pstat==0, futime, ptime))
event &lt;- with(mgus2, ifelse(pstat==0, 2*death, 1))
mgus2$event &lt;- factor(event, 0:2, labels=c(&quot;censor&quot;, &quot;pcm&quot;, &quot;death&quot;))

我使用非参数方法计算了累积发生率函数，并得出了事件或死亡在时间的概率t。
可以通过 summary_mfit2$lower 和 summary_mfit2$upper 显示概率的置信区间。
此外，我绘制了累积发生率函数：
mfit2 &lt;- survfit(Surv(etime, event) ~ sex, data=mgus2)

summary_mfit2 &lt;- summary(mfit2, times=c(20))

&gt; summary_mfit2
调用：survfit(formula = Surv(etime, event) ~ sex, data = mgus2)

sex=F 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 540 93 0.852 0.0175 0.130

sex=M 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 621 137 0.818 0.0106 0.171

ggcuminc(mfit2, consequence = c(&quot;pcm&quot;)) +
add_confidence_interval()

接下来，我尝试了半参数方法，如下所示：
cfit1 &lt;- coxph(Surv(etime, event) ~ sex, mgus2, id=id)

dummy &lt;- expand.grid(sex = c(&quot;F&quot;, &quot;M&quot;))

csurv &lt;- survfit(cfit1, newdata = dummy)

temp &lt;- summary(csurv, times = c(20))

&gt; temp 
调用：survfit(formula = cfit1, newdata = dummy)

数据 1 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8668 0.0111 0.1221 

数据 2 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8388 0.0102 0.1510 

问题：

由于只使用了一个二元协变量（性别），使用半参数模型是否有意义方法还是应该使用非参数方法？
当有人描述使用原因特异性 cox ph 回归时，我的理解是这自动指的是半参数方法来估计风险 (CIF)，还是我错了？
非参数方法为时间 t 的风险提供 CI。如何为半参数方法推导出这些 CI？
如果推导出 CI，如何绘制半参数对象 csurv 的置信区间？函数 ggcuminc() 不起作用，使用基本函数 plot()（确实有效）很麻烦。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</guid>
      <pubDate>Fri, 16 Aug 2024 09:18:11 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用已知范围但未知平均值生成正态分布的变量</title>
      <link>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</link>
      <description><![CDATA[我想生成一个具有已知范围（例如 $10.4\text{–}16.6$）但不知道平均值的 100 个数据点的正态分布变量。要使用 rnorm，我需要平均值和标准差。如果我假设它是精确的中点（平均值${} = (10.4 + 16.6) \cdot 0.5 = 13.5).$，我可以估计平均值，并对 sd 进行一些类似的估计（sd${} = (13.5 - 10.4) /2 = 1.55).$，然后我可以使用 rnorm 函数
rnorm (n=100, 平均值 = 13.5, sd = 1.55)

但结果变量的范围超出了我的初始范围 $10.4\text{–}16.6.$，我想看看是否有更好的方法来生成这个变量并强制以保持我预期的范围。]]></description>
      <guid>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</guid>
      <pubDate>Wed, 14 Aug 2024 18:22:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ARIMA 对相同数据进行预测时，会指出数据在一个预测持续时间内是白噪声，而没有指出它在另一个持续时间内不是白噪声</title>
      <link>https://stats.stackexchange.com/questions/652789/why-arima-on-same-data-says-data-is-white-noise-for-one-forecast-duration-while</link>
      <description><![CDATA[我正在对我的数据运行 ARIMA 模型。我有 2021 年 1 月的每周数据。当我运行 12 周预测时，ARIMA 给出了最佳参数值 (0,0,0)，表明数据是白噪声。但是当我使用相同的数据并运行 8 周的预测时，最佳参数值是 (4,0,4)，这意味着数据不是白噪声。
有人可以告诉我预测持续时间是如何使数据变成白噪声的吗？
所以这就是我进行预测的方式：
数据从 2021 年 1 月到 2024 年 7 月。
训练数据：2021 年 1 月 1 日至 2024 年 2 月 11 日。
测试数据：2024 年 2 月 18 日至 2024 年 5 月 6 日。
我使用以下方法循环遍历大量 p、d、q 值：
params = {
&#39;p&#39; : [0,1,2,3,4,5],
&#39;d&#39; : [0,1,2,3,4,5],
&#39;q&#39; : [0,1,2,3,4,5]
}

for vals in product(*params.values()):
comb = dict(zip(params.vals)

然后我将 comb 传递到执行 ARIMA 的函数中。
完成上述步骤后，我根据测试值与预测值的最低 RMSE 分数选择最佳 p、d、q 值。并将它们传递到未来 12 周的预测中：
现在训练数据：2021 年 1 月 1 日至 2024 年 5 月 13 日
测试数据：2024 年 5 月 13 日至 2024 年 7 月 29 日]]></description>
      <guid>https://stats.stackexchange.com/questions/652789/why-arima-on-same-data-says-data-is-white-noise-for-one-forecast-duration-while</guid>
      <pubDate>Wed, 14 Aug 2024 14:08:01 GMT</pubDate>
    </item>
    </channel>
</rss>