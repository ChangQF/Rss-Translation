<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 15 Feb 2024 00:57:24 GMT</lastBuildDate>
    <item>
      <title>估计最大效应大小和 Skillings-Mack 检验</title>
      <link>https://stats.stackexchange.com/questions/639309/estimating-maximum-effect-size-and-skillings-mack-test</link>
      <description><![CDATA[我正在处理符合 Skillings-Mack 测试的数据：不平衡不完整的块设计。或者类似弗里德曼测试的缺失数据。
如果测试结果为阴性，我想估计可以“隐藏”测试结果的最大效应大小。数据中。
通过弗里德曼检验，我可以相当容易地估计效果的大小，方法是选取任意两组并根据成对差异（无论是均值、中位数还是截尾均值）引导 95% 置信区间。
但是，当样本中的组大小遵循二项式分布时，即使是最高计数组的大小也非常小，因此自举置信区间非常大，即使 Skillings-Mack 检验非常显着（p 值 &lt; 1e -9)。
具体示例
我想要测量的是其中一个变量的汉明权重（RSA）对测量变量（使用该素数进行 RSA 签名的时间）有影响。问题在于变量（素数）是均匀随机的并且具有特定的位长度（如 1024）。这意味着预期的汉明权重将遵循 p=0.5 且 N=1024 的二项式分布。
在缺乏独立性产生影响之前，我可以执行大约 10 到 30 次测量，因此我的 Skillings-Mack 块不大于 30 次测量。块中的具体权重是独立且随机的。这意味着对于特定的汉明权重（例如 511 和 513），很少有组实际上会同时包含这两个权重，在我看来，单个对的自举严重低估了样本中的效应大小（Skillings-Mack 测试可以报告1e-18 的 p 值和成对差异 95% 置信区间仍包含零，符号检验和 Wilcoxon 符号秩检验均为负，p 值 &gt; 0.01）。
问题
如何估计此类数据的效应大小？
据我了解，排名上的重复测量方差分析也可以用于测试此类数据，但如果组的大小不同（我的组非常多），我也看到很少有反对它的建议。那是对的吗？如果没有，有没有办法用 rANOVA 来估计排名的效应大小？
背景
由于我正在测量计算机上操作的计算时间，因此我需要能够区分亚 1 纳秒的效应，但我还需要知道样本何时足够大且足够干净以检测特定大小的效应。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/639309/estimating-maximum-effect-size-and-skillings-mack-test</guid>
      <pubDate>Thu, 15 Feb 2024 00:48:43 GMT</pubDate>
    </item>
    <item>
      <title>格兰杰因果关系和 FEVD 的输出彼此相反</title>
      <link>https://stats.stackexchange.com/questions/639307/outputs-of-granger-causality-and-fevd-are-opposite-of-each-other</link>
      <description><![CDATA[这是关于双变量系统的协整或 VAR 分析。格兰杰因果关系要么表示工具 1（例如股票）和工具 2（例如期货）不是彼此的格兰杰原因，要​​么是工具 2 是工具 1 的格兰杰原因。
但是，当我看到 FEVD 输出时，仪器 2 90% 以上的 FEV 归因于仪器 1。无论两个仪器之间是否存在协整，都会发生这种情况。换句话说，set1 是协整的，并且估计 ECM，而 set2 不是协整的，并且估计差异中的 VAR。
这意味着 FEVD 和格兰杰因果关系输出显示相反的结果。我该如何解决这个问题？
这些输出已通过 E-Views 和 R 检查。因此，这可能不是由于我在 R 中编写的一些错误代码所致。我正在使用“使用 R 进行集成和协整时间序列分析”作者：Bernhard Pfaff 的 R 代码。
我请求社区就此提供帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/639307/outputs-of-granger-causality-and-fevd-are-opposite-of-each-other</guid>
      <pubDate>Thu, 15 Feb 2024 00:38:21 GMT</pubDate>
    </item>
    <item>
      <title>运行回归并且不清楚如何思考问题</title>
      <link>https://stats.stackexchange.com/questions/639303/running-a-regression-and-unclear-how-to-think-about-the-problem</link>
      <description><![CDATA[我想运行线性回归，以更好地理解力如何与分层/扭曲面部框架的位置相关。这是针对与机械工程相关的制造产品。因此，我在 8 个不同位置对 20 个独立单元进行了力测量。因此，我使用单元位置编号作为 x 值（自变量），并将测量的力作为 y 值（因变量）。
我不确定如何在 Excel 中设置回归，因为面部框架上的每个位置都有 20 个单独的条目。但我希望能够查看数据，或许还可以根据 8 个位置中的 6 个位置来预测力的大小（在我的测试中显示出更高的力值）。我该如何设置呢？我将附上几张图片来提供一些背景。
在第一幅图像中，从左到右的测量值分别是最小值、平均值、最大值、标准偏差和范围（后面是 20 帧中每一帧的单独测量值）。第二张图显示了一个范围图，其中我根据位置（x 轴）确定了力测量的范围。

]]></description>
      <guid>https://stats.stackexchange.com/questions/639303/running-a-regression-and-unclear-how-to-think-about-the-problem</guid>
      <pubDate>Wed, 14 Feb 2024 21:57:45 GMT</pubDate>
    </item>
    <item>
      <title>计数数据和比例协变量：最佳实践</title>
      <link>https://stats.stackexchange.com/questions/639301/count-data-and-proportion-covariates-best-practices</link>
      <description><![CDATA[我正在处理空间数据，并且我有以下用于计数数据的对数线性模型。让 $y \sim Poisson(\lambda_{i})$ 使得
$$
\log \lambda_{i} = \text{x}_i^\top\beta_{} + \epsilon_{i}
$$
这样 $\epsilon_{ij}$ 就是站点 $i$ 处的空间效果。
我有每个站点的计数，我想将其作为响应变量进行分析，以及文献中所说的相关的其他辅助计数，并且可能会导致计数上升或下降。我的问题是将数据计数为协变量的最佳实践是什么，我应该使用

原始计数；
比例（我知道每个地点的总人口）；
$z$-分数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639301/count-data-and-proportion-covariates-best-practices</guid>
      <pubDate>Wed, 14 Feb 2024 21:44:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用具有成分（加起来为 1 的比例）预测变量的广义线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/639299/how-to-use-generalised-linear-mixed-model-with-compositional-proportions-that-a</link>
      <description><![CDATA[该研究分析了用户的视线，看看视线是否可以用来预测场景的记忆力。我的目标是观察时间和视觉目标（屏幕、机器人等）之间的交互，并查看用户在早期阶段（具体来说，120 秒中的前 25 秒）的注视分布是否更能体现记忆性比后期用户的注视分布。
以下变量与本研究相关：

已记忆：二进制响应变量，0 表示未记忆，1 表示已记忆
级别：它是一个从 0 -&gt; 0 的分类变量。 23. 这基本上是指时间间隔。 0 表示前 5 秒，23 表示第 23 个 5 秒间隔（即 115 秒-120 秒间隔）
机器人：这是用户看机器人的时间比例
屏幕：这是用户观看屏幕的时间比例
其他：这是用户注视非机器人或屏幕的目标的时间比例。
视觉：这是另一个分类变量，用于标识用户正在查看的场景。由于使用了具有多个参与者的单一场景，因此我将其用作随机效应。

请注意，机器人 + 屏幕 + 其他总和为 1。每个数据点都是 5 秒间隔（用 0 到 23 之间的数字表示），并具有相关的注视分布和可记忆性（响应）。
我有以下广义线性混合模型（广义是因为响应变量是二进制的）：
已记住 ~ 1 + 关卡 + 机器人 + 屏幕 + 关卡：屏幕 + 关卡：机器人 + (1 | 视觉)

我省略其中一个目标（其他）的原因是因为它们依赖于机器人和屏幕。
我的问题是，我可以使用比例作为预测变量吗？如果您对上下文有任何疑问，请随时提问。
我的另一个问题是，如果我有 24 个时间步长（5 秒的时间间隔），那么最好的建模方法是什么来检查初始时间步长是否比后面的时间步长在指示记忆性方面具有更好的效果？我不确定当前的建模是否可用于获取该信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/639299/how-to-use-generalised-linear-mixed-model-with-compositional-proportions-that-a</guid>
      <pubDate>Wed, 14 Feb 2024 21:26:10 GMT</pubDate>
    </item>
    <item>
      <title>每个参与者具有随机条件子集的多级模型</title>
      <link>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</link>
      <description><![CDATA[我对 5 个因素进行了重复测量实验，每个因素有 3 个不同的水平。我正在尝试找到一种方法来减少对参与者的需求，让他们不必经历每一种情况。
我一直在研究部分因子设计，但我突然想到，我可以运行一个为每个参与者部分完成的多级模型。
所以，我的问题是：是否可以向每个参与者展示条件的随机子集（例如 50%），收集足够的参与者，以便每个单独的条件都有良好的代表性，然后使用多级线性模型来建立各因素的影响？我怀疑可能是这样，但我不确定是否有什么我忽略的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</guid>
      <pubDate>Wed, 14 Feb 2024 21:02:54 GMT</pubDate>
    </item>
    <item>
      <title>使用部分审查的类别信息进行分类</title>
      <link>https://stats.stackexchange.com/questions/639294/classification-with-partially-censored-class-information</link>
      <description><![CDATA[我想为我的小部件构建一个分类器！这是我的数据：

&lt;标题&gt;

类
功能 1
功能 2
...


&lt;正文&gt;

[1,5]
0.1
“E”
...


4
1.7
“B”
...


[2,3,5]
0.8
“D”
...


...
...
...
...



也就是说，对于某些观察结果，我只知道它们属于 5 个可能的类标签的子集中的一个类，但我不知道它们到底属于哪个类。
有谁知道解决这个问题的原则方法吗？理想情况下，解决方案是概率 多类分类器有效地合并了部分审查的类信息。
我考虑过的一种方法是将未知类拆分为加权观测值，即将上述数据集转换为：

&lt;标题&gt;

类
重量
功能 1
功能 2
...


&lt;正文&gt;

1
0.5
0.1
“E”
...


5
0.5
0.1
“E”
...


4
1
1.7
“B”
...


2
0.33
0.8
“D”
...


3
0.33
0.8
“D”
...


5
0.33
0.8
“D”
...


...
...
...
...
...



这似乎可以产生合理的输出，但我很想知道是否存在更干净的解决方案！感谢您可能拥有的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/639294/classification-with-partially-censored-class-information</guid>
      <pubDate>Wed, 14 Feb 2024 20:20:46 GMT</pubDate>
    </item>
    <item>
      <title>使用多个其他 PCA 的结果执行 PCA？这是合法的吗，我该如何解释？</title>
      <link>https://stats.stackexchange.com/questions/639293/performing-pca-with-results-of-multiple-other-pcas-is-this-legit-how-do-i-inte</link>
      <description><![CDATA[我是一名生物学研究员，正在撰写一份涉及我学科之外的人员的手稿。他们使用 PCA 创建人口变量指数，对地理区域进行分类。对于其中一种情况，他们实际上使用了变量的子集，运行了 3 个单独的 PCA，然后使用这些分析的结果作为数据来运行另一个 PCA。
从数学角度来看，这似乎是一种合理的技术，但我不知道如何解释结果，至少在底层原始数据属性的贡献方面是这样。
此外，我对这种方法完全不熟悉。这与我之前使用 PCA 的方式非常不同。我想知道做这样的事情有多成熟，是否有任何我可以阅读的文献，或者只是我可以看的例子。]]></description>
      <guid>https://stats.stackexchange.com/questions/639293/performing-pca-with-results-of-multiple-other-pcas-is-this-legit-how-do-i-inte</guid>
      <pubDate>Wed, 14 Feb 2024 20:06:15 GMT</pubDate>
    </item>
    <item>
      <title>百分比平均值，还是总计/总计？</title>
      <link>https://stats.stackexchange.com/questions/639292/average-of-percents-or-sum-total-sum-total</link>
      <description><![CDATA[我有一些数据，需要知道所有商品的平均佣金。对于每一行，我计算发出的项目的百分比。如果我想知道“平均佣金是多少”，正确的是 $14.96$% 或 $12.89$&lt; /span&gt;%?
 项目 成本 收入 佣金
           1,000 289 28.90%
           2,991 190 6.35%
          10,400 1,050 10.10%
          20,000 2,900 14.50%
总计 34,391 4,429 **14.96%**

$14.96$% 在 Excel 中计算如下：
&lt;预&gt;&lt;代码&gt;=平均值(28.90%, 6.35%, 10.10%, 14.50%)

（这称为百分比平均值吗？不知道该怎么称呼它）。
现在，如果我执行4429 / 34391，我会得到$12.88$%。我“想要”哪个平均值？用于回答“平均佣金是多少？”我认为 SUM(Revenue) / SUM(Item Cost) 是我想要的，而不是计算的百分比的平均值，但甚至不知道使用什么术语来查找差异是什么，或者何时使用其中一种而不是另一种。对于前者，AVERAGE()，因为将百分比相加，然后除以 $4$，我不认为这对我的目的来说是准确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/639292/average-of-percents-or-sum-total-sum-total</guid>
      <pubDate>Wed, 14 Feb 2024 19:47:38 GMT</pubDate>
    </item>
    <item>
      <title>岭正则化与CNN数据增强的关系</title>
      <link>https://stats.stackexchange.com/questions/639291/the-relationship-between-ridge-regularization-and-cnn-data-augmentation</link>
      <description><![CDATA[在 James 等人的 Python 应用程序统计学习简介 的第 10.3.4 章中。有一句话是关于 CNN 的数据增强（将图像的自然变换添加到训练集中以提高泛化能力），内容如下：
&lt;块引用&gt;
这种数据肥化在本质上与岭正则化类似

我已阅读此帖子：为什么数据增强是否被归类为正则化的一种类型？并从最上面的答案中了解数据增强如何被视为正则化的一种形式。
我不明白的是引用的句子专门提到了岭正则化。我觉得我缺少一些更深入的概念点，即为什么 ridge 与 lasso 或任何其他正则化方法相比，与数据增强类似。
我能想象到的最好的结果是，使用岭可以有效地平滑模型系数。但增加数据量呢？我没看到。我只是想太多了吗？它们只是意味着一般的正则化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639291/the-relationship-between-ridge-regularization-and-cnn-data-augmentation</guid>
      <pubDate>Wed, 14 Feb 2024 19:39:52 GMT</pubDate>
    </item>
    <item>
      <title>如何自动生成表示多种治疗之间的异同的字母？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/639290/how-to-automatically-generate-letters-denoting-similarities-and-differences-betw</link>
      <description><![CDATA[我进行了比较治疗的试验，并将治疗作为固定效应进行回归分析。这会生成 p 值，表示各种结果的治疗之间的相似性/差异，我将其输入显着性矩阵（参见图片）以可视化每个治疗比较。上标字母用于表示每种处理之间的相似性/差异；共享字母的治疗相似，而不共享字母的治疗显着不同。目前，我手动分配字母，即在脑海中计算出来，但这对于进行大量治疗的研究来说很棘手。我一直在寻找一种自动生成重要字母的方法，但我发现这很困难，特别是因为我没有编码背景。任何想法将非常感激。
[1]: https://i.stack.imgur.com/u7E2C.png]]></description>
      <guid>https://stats.stackexchange.com/questions/639290/how-to-automatically-generate-letters-denoting-similarities-and-differences-betw</guid>
      <pubDate>Wed, 14 Feb 2024 19:21:28 GMT</pubDate>
    </item>
    <item>
      <title>引导测试集是否提供真实的错误置信区间？</title>
      <link>https://stats.stackexchange.com/questions/639289/does-bootstrapping-the-test-set-provide-a-real-error-confidence-interval</link>
      <description><![CDATA[我的问题是引导测试集？的答案中部分讨论的内容的具体示例。 .
假设我训练一个模型，在该模型中我无法从数学上导出误差的置信区间（考虑随机森林或神经网络），并进一步假设测试集和训练集的目标变量数据分布大致相同。 
引导测试集并对其进行多次评估是否会给出模型误差的真实置信区间？具体来说，我是否可以 X% 确定从未抽样总体中随机抽取与测试集相同大小的随机抽取将在区间内出现错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/639289/does-bootstrapping-the-test-set-provide-a-real-error-confidence-interval</guid>
      <pubDate>Wed, 14 Feb 2024 19:08:54 GMT</pubDate>
    </item>
    <item>
      <title>$P(\text{观察到的极端数据} | \text{替代假设})$</title>
      <link>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</link>
      <description><![CDATA[在频率假设检验中，计算值 $P(\text{与观察到的极端数据} | H_0)$，如果它小于特定阈值，$H_0$ 被拒绝。我理解“极端”的概念是“极端”。需要定义，这取决于$H_1$。它可以使用似然比明确定义，但据我在文献（在我的例子中是生物学）中看到的，对 $H_1$ 的依赖通常是隐含的。这就提出了一个问题：人们使用的“正确”是什么？极端的定义？
现在，这听起来可能像是我很迂腐。但我问这个问题的原因是，在我正在分析的数据集上，我定义了一个统计量和极端的直观定义，并使用采样计算了 pvalue $P(\text {观察到的极端数据} | H_0)$。看到这个值很小，我心里就高兴了。由于我的替代假设 $H_1$ 也得到了很好的定义，我可以计算 $P(\text{与观察到的极端数据} | H_1)$ 也是如此，发现这个值也很小。这让我想知道：

我该如何解释这一点？直观上，这让我认为 $H_0$ 和 $H_1$ 都不是好的假设，并且“ “现实” （当然，定义很宽松），是另一回事。我能想到的另一种解释是，我的数据（或至少是我的汇总统计数据）并不能提供有关这些假设的信息。另一种看待它的方式是，我拒绝了复合假设 $H_C:H_0 \lor H_1$（如果这些概率的总和也很小）。
如果我不报告 $P(\text{观察到的极端数据} | H_1)$，而只报告 pvalue，这实际上可能令人信服至少有一些我能够拒绝的人 $H_0$，因为直观地导致测试的替代方案是 $ H_1$，对于那些人来说，这似乎是 $H_1$ 的证据。这告诉我，至少可能有一些论文存在类似的问题。有人研究过这个吗？我的担心有道理吗？如果这确实是一个值得关注的问题，那么补救措施是什么（除了完全放弃 pvalue 的概念并进行贝叶斯测试之外）？是否应该要求人们始终计算和报告 $P(\text{观察到的极端数据} | H_1)$ 以及 pvalue？这样就能解决问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</guid>
      <pubDate>Wed, 14 Feb 2024 18:15:45 GMT</pubDate>
    </item>
    <item>
      <title>适用于具有重复的非正态、离散数据的假设检验</title>
      <link>https://stats.stackexchange.com/questions/639275/suitable-hypothesis-test-for-non-normal-discrete-data-with-repetitions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/639275/suitable-hypothesis-test-for-non-normal-discrete-data-with-repetitions</guid>
      <pubDate>Wed, 14 Feb 2024 15:04:52 GMT</pubDate>
    </item>
    <item>
      <title>四个不同城市土壤有毒元素与表观遗传老化的关系</title>
      <link>https://stats.stackexchange.com/questions/639266/association-of-soil-toxic-element-with-epigenetic-aging-in-four-different-cities</link>
      <description><![CDATA[我想做土壤有毒元素和表观遗传年龄加速的线性回归分析；我们使用 ICP-MS 测量了四个不同城市的土壤元素（毫克/千克）。
您能否建议以下方法是否正确，或者我们是否应该仅使用 log2 变换土壤元素；
要将原始元素值划分为分位数以进行回归分析，您可以使用 R 中的 cut 函数。以下示例说明了如何修改脚本以包含原始元素值的分位数：
# 读取数据
df &lt;- read.table(&quot;clean.file2.txt&quot;, header = TRUE, sep = &quot;,&quot;)
 
# 检查列名
列名(df)
 
# 为原始元素值创建分位数
quantile_cols &lt;- c(“Zn”、“Cu”、“Hg”、“Pb”)
分位数_列

             锌 铜 汞 铅
          4.55000 0.73000 2.07500 192.00000
          5.33333 0.23667 1.90667 115.33333
 
for (分位数列中的列) {
  df[[paste0(col, &quot;_quantile&quot;)]] &lt;- cut(df[[col]],
               中断 = 分位数(df[[col]], 概率 = 0:4/4),
               标签=假）
}
 
# 拟合回归模型
model1 &lt;- lm(epigenic_age_acceleration ~ 0 + 城市 + 城市：
  (Zn_分位数 + Cu_分位数 + Hg_分位数 + Mo_分位数 +
  Pb_quantile + Smoking_Status + 性别 + 年龄), 数据 = df)
# 总结模型
摘要_模型1 &lt;- 摘要(模型1)

此脚本向数据框“(Zn_quantile, Cu_quantile, Hg_quantile, Mo_quantile, Pb_quantile)”添加新列，表示每个原始元素值的分位数。然后将这些新列用于回归模型。根据您的具体需求和数据结构调整代码。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639266/association-of-soil-toxic-element-with-epigenetic-aging-in-four-different-cities</guid>
      <pubDate>Wed, 14 Feb 2024 14:14:30 GMT</pubDate>
    </item>
    </channel>
</rss>