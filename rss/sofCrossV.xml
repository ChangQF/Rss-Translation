<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Wed, 26 Feb 2025 03:25:58 GMT</lastBuildDate>
    <item>
      <title>基因型 - 环境关联的变量选择在部分冗余分析（RDA）中</title>
      <link>https://stats.stackexchange.com/questions/661861/variable-selection-for-genotype-environment-association-in-partial-redundancy-an</link>
      <description><![CDATA[我正在使用部分冗余分析（RDA）进行基因型 - 环境协会研究。我的数据集由大约250个个体组成，每个个体都针对5000个SNP（响应变量，编码为0/1/2）。此外，我有57个气候变量（解释变量），其中许多是高度相关的。我也有一个人口Q值（祖先系数）的矩阵，我用来部分谱系在RDA中的影响。
 问题：挑战在于在执行RDA之前选择气候变量。解释变量解释的方差比例非常低（在这类研究中与往常一样），这似乎可以防止有效利用套索回归用于可变选择。对于大多数SNP，未通过方法选择气候变量。
 问题： 

任何人都可以建议在这种情况下可以改善可变选择的套索方法调整参数吗？
是否有替代性形式变量选择方法可以更有效？

 替代方法：我正在考虑一种涉及气候变量层次聚类的替代方法，然后使用PCA为每个群集创建复合变量。步骤如下：

 在所有气候变量上执行分层聚类。

 对于每个集群，执行PCA并提取第一个主组件（PC1）的加载。

 计算原始气候变量的点产物和权重向量（PC1的PCA载荷）为每个集群创建一个复合变量。


此方法适合我的分析，还是我应该使用正式的变量选择方法？
非常感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/661861/variable-selection-for-genotype-environment-association-in-partial-redundancy-an</guid>
      <pubDate>Wed, 26 Feb 2025 02:04:15 GMT</pubDate>
    </item>
    <item>
      <title>解决SVM微调的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/661858/best-way-to-tackling-svm-fine-tuning</link>
      <description><![CDATA[我正在遇到一个多类分类问题，我正在尝试使用SVM预测4个类别。我正在尝试使用贝叶斯优化来微调其超参数，以加快持续时间。但是，这需要很长的时间才能融合。 （我说的是日子）。我可以问我是否错误地编码它，还是我应该采用其他方法？我只有大约6000个观测值和大约30个变量。
 来自bayes_opt进口
来自Sklearn.svm导入SVC
来自sklearn.model_selection导入cross_val_score

＃定义优化功能
def svm_evaluate（c，gamma_value，学位，收缩，kernel_index，class_weight_index）：
    ＃定义分类参数的选择
    kernel_choices = [&#39;linear&#39;，&#39;poly&#39;，&#39;rbf&#39;，&#39;sigmoid&#39;]
    class_weight_choices = [none，&#39;Balanced&#39;]
    
    ＃将索引转换为分类值
    kernel = kernel_choices [int（kernel_index）]
    class_weight = class_weight_choices [int（class_weight_index）]
    gamma =&#39;scale&#39;如果[&#39;linear&#39;] else gamma_value中的内核
    
    ＃使用给定参数创建SVM模型
    svm = svc（
        C = C，
        内核=内核，
        伽玛=伽玛，
        度= int（dem），
        class_weight = class_weight，
        收缩=收缩＆gt; 0.5＃转换回布尔值
    ）
    
    ＃使用交叉验证评估模型
    得分= cross_val_score（svm，x_train_short，y_train，cv = 5，评分=&#39;准确性&#39;）。eyan（）
    
    返回分数

＃定义参数范围
pbounds = {
    &#39;c&#39;：（1E-3，1E3），
    &#39;gamma_value&#39;：（1E-6，1E1），
    &#39;学位&#39;：（2，5），
    “收缩”：（0，1），＃使用0和1模拟布尔值
    &#39;kernel_index&#39;：（ 0，3），＃内核选择索引
    &#39;class_weight_index&#39;：（ 0，1）＃类重量选择索引
}

＃运行贝叶斯优化
优化器= Bayesianoptimization（
    f = svm_evaluate，
    pbounds = pbounds，
    Random_State = 42
）

优化器。maximize（init_points = 10，n_iter = 30）

＃打印最佳参数
BEST_PARAMS = Optimizer.max [&#39;params&#39;]
best_params [&#39;kernel&#39;] = [&#39;linear&#39;，&#39;poly&#39;，&#39;rbf&#39;，&#39;sigmoid&#39;] [int（best_params [&#39;kernel_index&#39;]]]]]
best_params [&#39;class_weight&#39;] = [none，&#39;balanced&#39;] [int（best_params [&#39;class_weight_index&#39;]）]]]
best_params [&#39;缩小&#39;] = best_params [&#39;shinking&#39;]＆gt; 0.5＃转换回布尔值
BEST_PARAMS [&#39;grem&#39;] = int（best_params [&#39;deg&#39;]）

打印（best_params）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661858/best-way-to-tackling-svm-fine-tuning</guid>
      <pubDate>Wed, 26 Feb 2025 00:59:16 GMT</pubDate>
    </item>
    <item>
      <title>$ \ chi^2 $测试后的不确定性正常</title>
      <link>https://stats.stackexchange.com/questions/661855/normalizing-uncertainties-after-chi2-test</link>
      <description><![CDATA[我的一位教授在某个时候告诉我，我可以“重新归一化”  $ \ chi^2 $ 测试之后的不确定性如果我降低了 $ \ chi^2 $ 与 $ 1 $ 有很大不同。想象一个简单的线性模型，这个想法是我可以以以下方式重新归一化错误
  $$ \ SIGMA&#39;= \ SQRT {\ CHI^2 _ {\ MATHRM {RED}}}}} \SIGMA。$$  
如果 $ \ chi^2 _ {\ mathrm {red}} $ 很小，因为我高估了错误，这会纠正它；如果 $ \ chi^2 _ {\ mathrm {red}} $ 很大，则反之亦然，因为错误被低估了。
我的问题是，这实际上是一个著名的“技巧”，这是所做的事情？如果是这样，有人知道这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661855/normalizing-uncertainties-after-chi2-test</guid>
      <pubDate>Tue, 25 Feb 2025 23:28:10 GMT</pubDate>
    </item>
    <item>
      <title>用IPW在R中进行中介分析。应该使用什么权重？</title>
      <link>https://stats.stackexchange.com/questions/661851/performing-mediation-analysis-in-r-with-ipw-what-weights-should-be-used</link>
      <description><![CDATA[我有兴趣使用Mediation  https://cran.r-project.org/web/packages/mediation/vignettes/mediation.pdf 。
我已经设置了结果和调解器模型，并按照文档所示将其介绍。从概念上讲，我很难理解：如何在结果和调解器模型上进行加权以调整混淆？
我的猜测是调解人通常是IPW（ $ 1/p（a = 1 | x）$ ），而结果模型加权应为反向加权BY  $ 1/（p（a = a | x = x）*p（m = 1 | a = a，x））$ 。如果我想稳定，我可以将相应的分子乘以 $ p（a = 1）$  and  $ p（a = a）*p（m = m）$ 。
这里的正确选择是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/661851/performing-mediation-analysis-in-r-with-ipw-what-weights-should-be-used</guid>
      <pubDate>Tue, 25 Feb 2025 21:44:34 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Kendall测试和Philips-Perron测试在R中给出不同的结果</title>
      <link>https://stats.stackexchange.com/questions/661853/mann-kendall-test-and-philips-perron-test-giving-different-results-in-r</link>
      <description><![CDATA[考虑这个时间序列。我想检查一般趋势是什么以及它是否重要。
tss = c(255911, 305257, 314258, 294006, 380817, 412120, 419021, 336756, 242161, 232846, 295826, 398630, 372016, 374842, 417062, 379535, 321790、359170、380963、468196、492634、455149、431348、440693、274894、200003）  
使用Mann-Kendall测试进行固定时间序列，我发现没有明显的趋势，因此时间序列是固定的。

 Mann-Kendall趋势测试
数据：TSS
z = 1.8956，n = 26，p值= 0.02901
替代假设：True S大于0
样本估算：
S vars tau
87.0000000 2058.333333 0.2676923 

但是使用PP测试，我发现该系列不是固定的（p＆gt; 0.01）

菲利普斯 - 佩隆单元根测试
数据：TSS
dickey-fuller z（alpha）= -9.7259，截断滞后参数= 2，p-value = 0.4936
替代假设：固定

我期望这两个测试都会给出类似的结果（固定或不固定）]]></description>
      <guid>https://stats.stackexchange.com/questions/661853/mann-kendall-test-and-philips-perron-test-giving-different-results-in-r</guid>
      <pubDate>Tue, 25 Feb 2025 21:39:53 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中参数的差异</title>
      <link>https://stats.stackexchange.com/questions/661850/variance-of-parameter-in-linear-regression</link>
      <description><![CDATA[我的目标是尝试调和两个关于 $ \ hat {\ beta_1} $ 的显而易见的结果。我在两本计量经济学书中找到了这些。
接下来是在两个来源中众所周知和共享的：
   
不幸的是，在大多数书籍中都没有完全共享，因此我在两种情况下都显示了这些。我怀疑不同的结论来自不同的假设，但我的意思对我来说并不清楚。
现在，我显示了有关 $ v [\ hat {\ beta_1}] $ 在库存和沃森中给出的假设和结论：
   
在这里，我显示了有关 $ v [\ hat {\ beta_1}] $ 在Greene中给出的假设和结论：
    
我认为差异的理由来自这些来源：

无条件差异与条件（ $ x $ ）方差。在绿色方差肯定是有条件的，而库存和沃森对我来说还不清楚。
精确与渐近结果。渐近股票和沃森，而不是格林

关于Greene中的渐近结果，我可以补充：
   
但是，我找不到解决两个结果的方法。有人可以帮我吗？如果需要，我可以添加详细信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/661850/variance-of-parameter-in-linear-regression</guid>
      <pubDate>Tue, 25 Feb 2025 20:45:27 GMT</pubDate>
    </item>
    <item>
      <title>COX回归中连续变量的线性检查</title>
      <link>https://stats.stackexchange.com/questions/661849/linearity-check-of-continuous-variables-in-cox-regression</link>
      <description><![CDATA[嗨，我试图理解我在模型危险中看到的有关变量的线性的看似差异。
代码遵循的是，查看是否满足连续变量的线性假设：
 ＆gt;摘要（FM_2）
称呼：
coxph（formula = surch（onset_edss_conworse_m，status_onset_edss_conworse）〜 
    RS10504033_C + PSPLINE（YOB） + PSPLINE（AAO） + EDSS_1 + PC1 + 
        PC2 + PC3 + PC4 + PC5 + PC6 + PC7，数据=结果_2）

  n = 6656，事件数= 3611 

                     COEF SE（COEF）SE2 CHISQ DF P P       
RS10504033_C -0.05069 0.026141 0.026133 3.76 1.00 5.3E -02
PSPLINE（YOB），线性0.09715 0.002711 0.002711 1284.12 1.00 3.2E-281
PSPLINE（YOB），NONLIN 3.70 3.05 3.0E-01
PSPLINE（AAO），线性0.10701 0.002943 0.002942 1321.83 1.00 2.0E 2.0E-289
PSPLINE（AAO），NONLIN 12.08 3.01 7.2E-03
EDSS_1 -0.02626 0.010005 0.009999 6.89 1.00 8.7E -03
PC1 -2.20275 2.750456 2.749590 0.64 1.00 4.2E -01
PC2 3.09137 2.147148 2.146728 2.07 1.00 1.5E-01
PC3 8.82073 2.132244 2.129735 17.11 1.00 3.5E-05
PC4 3.03276 1.725568 1.724969 3.09 1.00 7.9E-02
PC5 -4.85096 2.122560 2.121993 5.22 1.00 2.2E -02
PC6 -5.38660 1.825511 1.825053 8.71 1.00 3.2E -03
PC7 5.12791 2.048041 2.047844 6.27 1.00 1.2E-02

             EXP（COEF）EXP（-COEF）下部.95上.95
RS10504033_C 9.506E-01 1.052E+00 9.031E-01 1.001E+00
PS（YOB）3 2.070E+00 4.831E-01 1.403E+00 3.053E+00
PS（YOB）4 4.301E+00 2.325E-01 2.265E+00 8.167E+00
PS（YOB）5 9.097E+00 1.099E-01 4.245E+00 1.950E+01
PS（YOB）6 1.887E+01 5.299E-02 8.569E+00 4.156E+01
PS（YOB）7 3.779E+01 2.646E-02 1.721E+01 8.298E+01
PS（YOB）8 8.021E+01 1.247E-02 3.643E+01 1.766E​​+02
PS（YOB）9 1.794E+02 5.574E-03 8.071E+01 3.988E+02
PS（YOB）10 3.756E+02 2.662E-03 1.672E+02 8.440E+02
PS（YOB）11 7.375E+02 1.356E-03 3.242E+02 1.678E+03
PS（YOB）12 1.427E+03 7.009E-04 6.111E+02 3.331E+03
PS（YOB）13 2.656E+03 3.765E-04 1.048E+03 6.735E+03
PS（YOB）14 4.941E+03 2.024E-04 1.620E+03 1.507E+04
PS（AAO）3 2.170E+00 4.609E-01 1.249E+00 3.769E+00
PS（AAO）4 4.707E+00 2.125E-01 1.849E+00 1.198E+01
PS（AAO）5 1.011E+01 9.889E-02 3.246E+00 3.150E+01
PS（AAO）6 1.964E+01 5.091E-02 6.066E+00 6.360E+01
PS（AAO）7 3.786E+01 2.641E-02 1.181E+01 1.214E+02
PS（AAO）8 8.190E+01 1.221E-02 2.546E+01 2.634E+02
PS（AAO）9 1.781E+02 5.613E-03 5.500E+01 5.770E+02
PS（AAO）10 4.289E+02 2.332E-03 1.313E+02 1.401E+03
PS（AAO）11 1.018E+03 9.819E-04 3.068E+02 3.381E+03
PS（AAO）12 2.438E+03 4.102E-04 6.955E+02 8.547E+03
PS（AAO）13 5.752E+03 1.738E-04 1.412E+03 2.344E+04
PS（AAO）14 1.350E+04 7.409E-05 2.482E+03 7.340E+04
EDSS_1 9.741E-01 1.027E+00 9.552E-01 9.934E-01
PC1 1.105E-01 9.050E+00 5.037E-04 2.424E+01
PC2 2.201E+01 4.544E-02 3.273E-01 1.480E+03
PC3 6.773E+03 1.476E-04 1.037E+02 4.423E+05
PC4 2.075E+01 4.818E-02 7.052E-01 6.108E+02
PC5 7.821E-03 1.279E+02 1.220E-04 5.012E-01
PC6 4.578E-03 2.185E+02 1.279E-04 1.639E-01
PC7 1.687E+02 5.929E-03 3.046E+00 9.339E+03

迭代：8外，20个牛顿 - 拉夫森
     theta = 0.983754 
     theta = 0.9706721 
条款的自由度= 1 4 4 1 1 1 1 1 1 1 1 1 
一致性= 0.737（SE = 0.004）
17.05 df，p =＆lt; 2e-16的似然比测试= 2270
 
我检查了YOB和AAO的TEMPLOT，以查看变量是否是线性的。
但是它们看起来都是线性的，而AAO的非线性效应很重要。谁能帮助理解这一点？
   ]]></description>
      <guid>https://stats.stackexchange.com/questions/661849/linearity-check-of-continuous-variables-in-cox-regression</guid>
      <pubDate>Tue, 25 Feb 2025 19:45:43 GMT</pubDate>
    </item>
    <item>
      <title>左截断和间隔审查数据使用Turnbull提出的自洽算法</title>
      <link>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</guid>
      <pubDate>Tue, 25 Feb 2025 18:29:13 GMT</pubDate>
    </item>
    <item>
      <title>我可以包括个人和个人匹配固定效果吗？</title>
      <link>https://stats.stackexchange.com/questions/661847/can-i-include-both-individual-and-individual-job-match-fixed-effects</link>
      <description><![CDATA[如果我试图研究工作任期对工资的影响，并且我观察到每个人的工作变化，则仅包括个人job匹配固定效果已经说明了个人固定效果，或者我必须包括两者？]]></description>
      <guid>https://stats.stackexchange.com/questions/661847/can-i-include-both-individual-and-individual-job-match-fixed-effects</guid>
      <pubDate>Tue, 25 Feb 2025 18:01:34 GMT</pubDate>
    </item>
    <item>
      <title>如何正确模拟对数正态分布中的可变性？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661846/how-to-properly-simulate-the-variability-in-a-log-normal-distribution</link>
      <description><![CDATA[我试图通过通过先前生成的高斯白噪声的指示，差异等于2， $ y $  =“ Math-Container”&gt; $ x $ ，
  $$
y = \ exp（x），\\
x \ sim n（0，2）。
$$  
但是，所得的对数正态样品的样本方差广泛低估了理论方差，根据维基百科为
  $$
\ exp（2）（\ exp（2/2）-1）= 47.21
$$  
我犯了任何错误吗？有没有办法在样本中重现适量的可变性？
以下是一些可再现的python代码。
 导入numpy作为NP

n_samp = int（1E8）

＃白噪声
vwn = np.random.normal（size = n_samp，scale = np.sqrt（2））

emp_mean = np.mean（vwn）
theo_mean = 0
emp_var = np.var（vwn）
theo_var = 2

图，axs = plt.subplot（2，1，无花果=（10，8））
axs [0] .scatter（x = 0，y = emp_mean，color =; blue＆quot; label =; emp; quot;）  
axs [0] .scatter（x = 0，y = theo_mean，color =; red＆quot; label =; quot; theo; quot;）
axs [0] .set_title（“平均”）
axs [0] .legend（）
axs [1] .scatter（x = 0，y = emp_var，color =; blue＆quot; label =; emp; quot;）
axs [1] .scatter（x = 0，y = theo_var，color =; red＆quot; label =; theo; quot;）
axs [1] .set_ylim（[1，3]）
axs [1] .set_title（; var; var;）
axs [1] .legend（）  
plt.show（）

＃log-normal
vksi = np.exp（vwn）
emp_mean = np.mean（vksi）
theo_mean = np.exp（1）
emp_var = np.mean（vksi）
theo_var = np.exp（2） *（np.exp（2）-1）

图，axs = plt.subplot（2，1，无花果=（10，8））
axs [0] .scatter（x = 0，y = emp_mean，color =; blue＆quot; label =; emp; quot;）  
axs [0] .scatter（x = 0，y = theo_mean，color =; red＆quot; label =; quot; theo; quot;）
axs [0] .set_title（“平均”）
axs [0] .legend（）
axs [1] .scatter（x = 0，y = emp_var，color =; blue＆quot; label =; emp; quot;）
axs [1] .scatter（x = 0，y = theo_var，color =; red＆quot; label =; theo; quot;）
axs [1] .set_ylim（[[0，100]）
axs [1] .set_title（; var; var;）
axs [1] .legend（）  
plt.show（）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661846/how-to-properly-simulate-the-variability-in-a-log-normal-distribution</guid>
      <pubDate>Tue, 25 Feb 2025 17:43:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么跳过嵌入式工作？</title>
      <link>https://stats.stackexchange.com/questions/661839/why-do-skip-gram-embeddings-work</link>
      <description><![CDATA[我有一个有关跳过算法的问题。为了使问题有道理，我将描述它。不过，我可能不会完美。我将尝试给出我的书使用的解释。
创建单词嵌入是一种算法。假设您有一个带有25 000个单词的文字。您可以创建25000个矢量，这是一个热编码，这意味着它们的尺寸为25 000。然后，您查看句子或单词近距离，然后跳过这样的单词：
可以说，您有一个句子“背包可以包含书籍和铅笔”。您跳过了背包，看周围的单词，然后创建（背包，包含），（背包，书籍），（书籍，背包），（铅笔，书籍）。。
您创建这样的神经网络：
您的输入向量为25000个维层（神经网络），该层产生了尺寸500的矢量，这些矢量又被送达到输出层（也是一个神经网络），该层产生了维度的维度。下一个单词的25000个概率，该向量与25 000个维输入向量有关。我们使用跨凝结训练数据。这意味着，在我们喂食它（背包，书籍）之后，该模型会自我调整，从而使“书籍”的概率;当我们给它一个“背包”一词时，变得更高一点。
 我的问题 
 为什么我们要说的是，语义上相似的单词像嵌入一样近距离togeher？我的书说，例如“电影”
和“电影”即使没有出现
通常在一起，因为他们周围的单词通常是相同的。
但是我们怎么知道算法不仅会创建两个
嵌入层中的不同嵌入式，但输出层
给出这两个不同的向量（嵌入）的值相同的值？我只能看到我们控制了复合函数，而不是第一个函数。 
 从我看到的函数g（f（x））来看，如果x和y在语义上接近，我确实看到g（f（x））将接近g（f（y） ），并且使F（x）接近f（y）的算法是很明智的，但是严格来说，我不认为它必须为了优化问题吗？  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661839/why-do-skip-gram-embeddings-work</guid>
      <pubDate>Tue, 25 Feb 2025 12:35:19 GMT</pubDate>
    </item>
    <item>
      <title>最大可能性估计量何时有偏见？</title>
      <link>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</link>
      <description><![CDATA[众所周知，最大似然估计器（MLE）可能会偏差。我们可以预测给定的分布和感兴趣的参数是否会产生偏见的MLE？它取决于什么属性？偏斜？
例如，正态分布和平均值 $ \ mu $ 将给出公正的mle，而 $ \ theta $  in  $ \ text {stormiforn}（0，\ theta）$ 将是偏见的（根据chatgpt）]]></description>
      <guid>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</guid>
      <pubDate>Tue, 25 Feb 2025 11:40:56 GMT</pubDate>
    </item>
    <item>
      <title>“最小化”高斯NLL的含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</link>
      <description><![CDATA[我试图充分理解在模型训练期间的最小化高斯负模样（NLL）的最小值。使用MSE，它是直观的：接近0意味着更好的预测。但是高斯nll似乎不那么简单，尤其是因为它可能是负面和无限的。
在我的情况下，我的模型预测平均值 $ \ mu $  and  $ \ log（\ sigma^2） $ ，我指出要获得差异。我使用以下高斯NLL损失：
 $$ nll = \ frac {1} {2} {2} \ big [\ log（\ sigma^2）+\ frac {（y- \ mu）^2} {\ sigma^ 2}+\ log（2 \ pi）\ big]。$$  
我的主要问题是：最小化高斯NLL的含义是什么，我们如何跟踪改进？ 

仅查看上述方程式，我们可能会认为较低的损失总是更好的：对于完美的预测，NLL中的第二个任期将为零。在这种情况下，损失主要取决于 $ \ log（\ sigma^2）$ 。预测方差越小，负 $ \ log（\ sigma^2）$ 变成了，这似乎是一件好事，表明该模型有信心。遵循该逻辑，我们可以认为“最小化”。 NLL意味着我们只是希望它尽可能负面：-5的验证损失比-4之一好。但是，实际上，更负值的值也可能只是表明该模型过于自信并低估了不确定性，因此较低的值不一定更好，这将我带到了下一个点：
如果我正确理解，优化高斯NLL确实意味着使残留物的分布（预测错误）类似于： $ \ mu = 0 $ ，则表示预测平均是准确的， $ \ sigma^2 $ 匹配模型的预测不确定性。如果是这样，我们应该在培训期间如何解释或跟踪改进？如果较低的验证损失不一定更好，并且我们的目标不是尽可能接近零，那么哪些指标或方法可以帮助跟踪真正的改进？我们如何判断残差在培训时是否会融合到预测的高斯分布？
这是如何与早期停止和超参数调整相结合的，在哪里“更好”假定验证损失仅意味着较低的值？

我真的很感谢您对如何在培训期间解释高斯NLL的任何见解，尤其是如何平衡预测与不确定性估计以及如何在标准培训工作流程中起作用，例如早期停止和超参数调整。。]]></description>
      <guid>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</guid>
      <pubDate>Tue, 25 Feb 2025 10:42:25 GMT</pubDate>
    </item>
    <item>
      <title>带有修改的似然函数的似然比测试</title>
      <link>https://stats.stackexchange.com/questions/661327/likelihood-ratio-test-with-a-modified-likelihood-function</link>
      <description><![CDATA[我已决定使用似然比测试来评估我的模型是否严格考虑的所有协变量，如第388页所述，后来在 统计方法的示例14.4中进行了说明  ，由Lee和Wenyu Wang（第三版）。
不幸的是，对我来说，我的模型是基于修改的对数可能函数在R中训练的，该函数还包含形式的正则化参数
  $$
c_1 \ sum_ j \ | \ vec {b} _j \ |^2。
$$  
索引 $ J $ 在测量时间运行（请参见下面的详细信息）。
在这里，一个额外的协变量可以转化为 $ \ vec {b} _j $ 的任何一个非零组件，我想找出我有多少我可以根据此可能性比测试添加。
由于问题的设置，我想知道：
 1.-在修改了可能性功能时，进行可能比率测试仍然有意义。
 2.-如果这样做，是否很明显
  $$ -2（\ ell（\ vec {b} _j） -  \ ell（\ vec {b} _j&#39;）） &gt;
遵循具有一个自由度的卡方分布（作为示例），或者我应该进行自己的分析以了解自由度的数量（我希望它仍然会遵循卡方分布）。 
 更多细节 
正式地，我正在处理一个非基础有限的马尔可夫链，其中每个 $ x_j $ 对应于“测量”，状态空间为 $ s = \ {0,1 \} $ （活着或死）。
该模型计算观察特定序列 $ x =（x_1，\ dots，x_n）$ 的可能性x_j = 0 $ 或 $ 1 $ 当然 $ p（x_ {j+1} = 0 | x_j = 1）= 0 $ 。
显然是为了避免过度拟合，并确保参数 $ \ vec {b} _J $ 从时间 $ j $  to  $ J+1 $ 。
最终的概率是一种逻辑回归，但实际上从马尔可夫随机字段的角度来看更容易理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/661327/likelihood-ratio-test-with-a-modified-likelihood-function</guid>
      <pubDate>Thu, 13 Feb 2025 14:45:10 GMT</pubDate>
    </item>
    <item>
      <title>预测建模和机器学习中的信噪比</title>
      <link>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</link>
      <description><![CDATA[ 这个问题问题 。对此有更明确的态度，信号噪声比率如何与预测的良好方式有关？例如，确切地说是通过信噪比的含义是什么？它暗示了预测建模？
 编辑 
在看到链接答案的进一步评论后，我想知道（人口级）共同信息或KL分歧是正确考虑这一点的正确方法。结果是噪声的信号和（种群级）熵吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</guid>
      <pubDate>Sun, 17 Nov 2024 13:42:20 GMT</pubDate>
    </item>
    </channel>
</rss>