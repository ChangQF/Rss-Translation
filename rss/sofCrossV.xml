<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 26 Aug 2024 03:19:31 GMT</lastBuildDate>
    <item>
      <title>对标签实例进行平均以进行 SVM 分类</title>
      <link>https://stats.stackexchange.com/questions/653314/averaging-over-labels-instances-for-svm-classification</link>
      <description><![CDATA[这是一个假设性问题，关于将训练/测试数据输入 SVM 模型的不同方法。我有两个类，每个类有 128 个实例，可以按层次分组为 4 个集合（即每个类有 4 个集合，每个集合有 32 个实例）。通常，我会通过在 3 个集合（每个类有 128 个实例）上训练分类器并解码遗漏的集合（每个类有 32 个实例）来交叉验证 SVM，并迭代所有训练和测试组合。
有人告诉我，更好的方法是取每个集合的平均值，这样在训练/测试之前，每个集合只有一个平均特征向量。这意味着我将在每个类标签的 3 个平均实例上训练 SVM，并在每个标签的 1 个遗漏实例上进行测试。理由是这些平均模式更稳定。
我已经运行了模拟，并且确实从中获得了更好的解码效果，但我从未见过有人使用这种方法。像这样取类标签的平均值有什么缺点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653314/averaging-over-labels-instances-for-svm-classification</guid>
      <pubDate>Mon, 26 Aug 2024 02:18:46 GMT</pubDate>
    </item>
    <item>
      <title>结合不确定性</title>
      <link>https://stats.stackexchange.com/questions/653312/combining-uncertainties</link>
      <description><![CDATA[我有这个数据集：



$y_{observed}$
$\sigma_{stat}^+$
$\sigma_{stat}^-$
$\sigma_{sys}^+$
$\sigma_{sys}^-$




0.193
0.002
-0.002
0.0316
-0.0218


0.1504
0.0014
0.0158
-0.0121


0.13507
0.00079
-0.00079
0.01092
-0.00787


0.11647
0.00072
-0.00072
0.00846
-0.00603


$\vdots$
$\vdots$
$\vdots$
$\vdots$
$\vdots$



$stat$ 代表统计，$sys$ 代表系统。
我的理解是，我可以对 $\sigma_{stat}$ 和 $\sigma_{sys}$ 求和，因为它们不相关
$$
\sigma_{total} = \sqrt{ (\sigma_{stat})^2+(\sigma_{sys})^2}
$$
因此我会得到：
$$
\sigma_{total}^+ = \sqrt{ (\sigma_{stat}^+)^2+(\sigma_{sys}^+)^2}
$$
$$
\sigma_{total}^- = \sqrt{ (\sigma_{stat}^-)^2+(\sigma_{sys}^-)^2}
$$
我能否以某种方式结合 $\sigma_{total}^+$ 和 $\sigma_{total}^-$？我认为它们是相关的，对吗？我应该如何处理 $\sigma_{total}^+$ 和 $\sigma_{total}^-$ 的组合？]]></description>
      <guid>https://stats.stackexchange.com/questions/653312/combining-uncertainties</guid>
      <pubDate>Sun, 25 Aug 2024 23:23:07 GMT</pubDate>
    </item>
    <item>
      <title>解释 GAM 输出中的随机效应：高斯分位数</title>
      <link>https://stats.stackexchange.com/questions/653308/interpreting-random-effect-in-gam-output-gaussian-quantiles</link>
      <description><![CDATA[模型运行良好。对于因子，解释效果更容易。对于因子水平被分配了随机效应的变量，输出/图并不直观。我试图解释的图包括因子水平作为点、y 轴上的效应和 x 轴上的高斯分位数。有一条直线穿过这些点，看起来是线性正的。
如何解释这些因子变量的图？穿过这些点的线是什么意思？图顶部的 8.8 是什么意思？非常感谢任何解释方面的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653308/interpreting-random-effect-in-gam-output-gaussian-quantiles</guid>
      <pubDate>Sun, 25 Aug 2024 22:22:54 GMT</pubDate>
    </item>
    <item>
      <title>我计算调整后的标准化发生率（SIR）的方法正确吗？</title>
      <link>https://stats.stackexchange.com/questions/653307/is-my-approach-of-calculating-adjusted-standardized-incidence-ratiossir-correc</link>
      <description><![CDATA[我正在尝试使用以下模拟数据框计算标准化发病率 (SIR) 来确定吸烟对癌症的影响。吸烟对癌症的 SIR 及其 95% 置信区间 (CI) 需要根据性别和年龄组进行调整。
问：我的方法正确吗？
library(dplyr)

set.seed(123)
n &lt;- 1000
# 生成数据
df &lt;- data.frame(
cancer_case = sample(0:1, n, replace = TRUE), # cancer
smoke = sample(0:1, n, replace = TRUE),
age_group = factor(sample(c(&quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;), n, 
replace = TRUE)),
sex = factor(sample(c(&quot;male&quot;, &quot;female&quot;), n, replace = TRUE)),
start_follow = sample(1990:2005, n, replace = TRUE),
stop_follow = sample(1996:2015, n, replace = TRUE)
)

# 确保 stop_follow 在 start_follow 之后
df &lt;- df %&gt;%
mutate(stop_follow = pmax(start_follow + sample(1:10, n, 
replace = TRUE), stop_follow))

# 计算人年 (pyrs)。
# SIR = 观察值 / 预期值

df &lt;- df %&gt;%
mutate(pyrs = stop_follow - start_follow)

## 步骤 1：统计吸烟者和非吸烟者的观察病例

observed_cases &lt;- df %&gt;%
group_by(smoking, age_group, sex) %&gt;%
summarise(observed = sum(cancer_case), .groups = &#39;drop&#39;)

## 步骤 2：计算人年

person_years &lt;- df %&gt;%
group_by(smoking, age_group, sex) %&gt;%
summarise(total_pyrs = sum(pyrs, na.rm = TRUE), 
.groups = &#39;drop&#39;)

## 步骤 3：计算参考人群的发病率（非吸烟者）

reference_rates &lt;- df %&gt;%
filter(smoking == 0) %&gt;%
group_by(age_group, sex) %&gt;%
summarise(rate = sum(cancer_case) / sum(pyrs), 
.groups = &#39;drop&#39;)

## 步骤 4：计算预期病例（如果没有吸烟者）
将总人年数乘以每组的发病率。

expected_cases &lt;- person_years %&gt;%
left_join(reference_rates, by = c(&quot;age_group&quot;, &quot;sex&quot;)) %&gt;%
mutate(expected = total_pyrs * rate)

## 步骤 5：合并观察到的和预期的病例

combined &lt;- perceived_cases %&gt;%
left_join(expected_cases, by = c(&quot;smoking&quot;, &quot;age_group&quot;, &quot;sex&quot;)) %&gt;%
group_by(smoking) %&gt;%
summarise(
obs_cases = sum(observed, na.rm = TRUE),
exp_cases = sum(expected, na.rm = TRUE),
total_pyrs = sum(total_pyrs, na.rm = TRUE)
)

## 步骤6：通过将观察到的病例除以预期病例来计算 SIR

combined &lt;- combined %&gt;%

mutate(
SIR = obs_cases / exp_cases,
SE_log_SIR = sqrt(1 / obs_cases),
lower = exp(log(SIR) - 1.96 * SE_log_SIR),
upper = exp(log(SIR) + 1.96 * SE_log_SIR)
)

## 步骤 7：调整参考人群值
## 由于非吸烟者是我的参考人群，我将 SE、
## lower 和 upper 值更改为“ref”。

combined &lt;- combined %&gt;%
mutate(
SIR = ifelse(smoking == 0, 1.0, SIR),
SE_log_SIR = ifelse(smoking == 0, &quot;ref&quot;, SE_log_SIR),
lower = ifelse(smoking == 0, &quot;ref&quot;, lower),
upper = ifelse(smoking == 0, &quot;ref&quot;, upper)
)

我正在尝试实现从讲座材料和一些 sas 代码中读到的内容。但是，我不擅长 SAS，很难将它们翻译成 R 并获得类似的结果。
所以我不能确定我的方法是否正确。有些人使用参考人群的总体发生率而不是每个分组变量组合的参考人群发生率。使用总体发生率对我来说没有任何意义。您能否告诉我这种计算 SIR 的方法是否正确，尤其是针对性别和年龄组的调整？任何建议都将不胜感激。请保持礼貌，我来这里是为了学习，而不是被侮辱，我希望我的问题也能帮助其他人学习。]]></description>
      <guid>https://stats.stackexchange.com/questions/653307/is-my-approach-of-calculating-adjusted-standardized-incidence-ratiossir-correc</guid>
      <pubDate>Sun, 25 Aug 2024 20:30:31 GMT</pubDate>
    </item>
    <item>
      <title>在 VAE 中将单个输入编码为潜在空间上的分布背后的原理是什么？</title>
      <link>https://stats.stackexchange.com/questions/653304/whats-the-rational-behind-encoding-a-single-input-as-a-distribution-over-the-la</link>
      <description><![CDATA[我一直在阅读一些关于 VAE 的教程，但发现自己很难理解将单个输入表示为潜在空间中的分布的想法。
通常，就像在 vanilla 自动编码器中一样，单个输入被映射到潜在空间中的单个点，这显然是有道理的。然而，在 VAE 中，单个输入被映射到参数高斯分布中。这是否意味着来自此分布的任何样本都应该给我相同的输出？这种做法背后的理由是什么？它究竟如何帮助形成正则化的潜在空间？]]></description>
      <guid>https://stats.stackexchange.com/questions/653304/whats-the-rational-behind-encoding-a-single-input-as-a-distribution-over-the-la</guid>
      <pubDate>Sun, 25 Aug 2024 19:57:01 GMT</pubDate>
    </item>
    <item>
      <title>对二进制时间序列进行采样并估计 1 的比例 - 为什么当时间序列具有较长的连续区域时，误差会较小</title>
      <link>https://stats.stackexchange.com/questions/653302/sampling-a-binary-time-series-and-estimating-proportion-of-1s-why-is-the-error</link>
      <description><![CDATA[我一直在研究一个可以抽象为二进制时间序列的数据集。也就是说，一系列可以是 1 或 0 的值，每个值代表一毫秒的时间。
我试图从这个时间序列的样本中估计 1 的比例。最简单的情况是每千分之一元素进行采样，但我也对随机采样进行了一些调整。
估计 1 的比例没有问题。最好的估计量就是样本中 1 的比例。我非常确信这个估计的标准误差也非常简单，等于比例 sqrt(p(1-p)/n) 的标准误差，可能对非常高的采样率进行有限的总体校正。
然而，我观察到一些似乎很直观的东西，但我找不到任何好的量化方法。当时间序列实际上是一个随机序列时，后续元素之间没有相关性，我在多次运行中观察到的误差与公式完全匹配。当我从 1 和 0 的连续区域构建序列时，误差会变小。这感觉很直观，因为我引入了被采样值和附近值之间的相关性，这使我的采样更有效，但我无法弄清楚如何利用一些有关该序列的信息（例如连续区域的平均长度或类似信息）先验地估计这个误差。有人能帮帮我吗？或者甚至只是给我一个更强大的定性方法来思考这种影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/653302/sampling-a-binary-time-series-and-estimating-proportion-of-1s-why-is-the-error</guid>
      <pubDate>Sun, 25 Aug 2024 18:56:41 GMT</pubDate>
    </item>
    <item>
      <title>生成具有给定自相关函数的伪随机样本序列，直至最大滞后</title>
      <link>https://stats.stackexchange.com/questions/653301/generating-pseudo-random-sample-sequence-with-a-given-autocorrelation-function-u</link>
      <description><![CDATA[假设变量 $X_t$ 是连续的，在均匀离散时间（时间序列）上采样。

我有完整的自相关函数，最大时间滞后为 $l_{max}$。系数可能为正数和负数。一些系数可能为零。
我有完整的时间序列“历史”，$X_0$ 到 $X_t$，以满足序列生成开始时的任何初始滞后条件。我想生成任意数量的随机可能序列扩展 $X_{t+1}$ 到 $X_{t+N}$，其中扩展序列完全符合（或至少以合理的容差收敛）历史时期的所有自相关系数（到最大时间滞后 $l_{max}$）。
数据分布复杂且多峰，因此如果可能的话，我更喜欢非参数方法，但我意识到这可能会使事情进一步复杂化。因此，如果非参数技术太难，我愿意妥协，从松散拟合的高斯分布中抽样。或者，如果可以简化事情，我们也可以假设我有一个 KDE 分布估计值，可以从中抽样：${\widehat {f}}_{h}(X)$

欢迎任何想法或算法，包括迭代技术。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653301/generating-pseudo-random-sample-sequence-with-a-given-autocorrelation-function-u</guid>
      <pubDate>Sun, 25 Aug 2024 18:36:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的混合逻辑回归分析满意度对交通方式偏好的影响</title>
      <link>https://stats.stackexchange.com/questions/653300/analyzing-the-effect-of-satisfaction-on-transport-mode-preference-using-mixed-lo</link>
      <description><![CDATA[我想分析对特定路线上不同交通方式（公交车与火车）的满意度对偏好的影响。参与者以公交车或火车为主要交通方式反复驾驶特定路线，并填写满意度调查问卷。每位参与者的总乘车次数从 5 到 10 不等，导致设计不平衡。
DV：偏好（巴士 =0，火车 =1）

每次乘车的 IV：主模式（巴士 = 1，火车 = 2）
满意度得分（正态分布）（TEc）

为了回答我的问题，我在 R 中尝试了混合逻辑回归。如果对巴士或火车乘车的满意度差异对偏好有影响，我预计它们之间的相互作用会产生显著的固定效应（这是否正确？）：
model &lt;- glmer(bus_vs_train ~ TEc * Mainmode + (1 | Participant), 
data =filtered_df, 
family = binomial)

输出：
Nobs：354
nGroups：40

AIC BIC logLik 偏差 df.resid
49.5 68.8 -19.7 39.5 349 




固定效应
估计
标准误差
z值
Pr(&gt;z)




(截距)
14.1501
4.4655
3.169
0.00153


TEc
-0.5621
4.7430
-0.119
0.90566&lt; /td&gt;


主模式
0.2581
2.6815
0.096
0.92331


TEc:主模式
0.1237
2.8474
0.043
0.96534






随机效应
方差
标准差
标准差




参与者（截距）
5322
72.95







模型摘要






AIC
49.5



BIC
68.8



LogLik
-19.7



偏差
39.5



数量obs
354



组
40




没有固定效应显著，模型拟合度较差。这是否意味着对公交车或火车的满意度对偏好没有影响？我的分析和解释正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653300/analyzing-the-effect-of-satisfaction-on-transport-mode-preference-using-mixed-lo</guid>
      <pubDate>Sun, 25 Aug 2024 18:32:24 GMT</pubDate>
    </item>
    <item>
      <title>Clopper-Pearson 区间的渐近一致性</title>
      <link>https://stats.stackexchange.com/questions/653299/asymptotic-consistency-of-the-clopper-pearson-interval</link>
      <description><![CDATA[我有一系列随机变量 $X_n \sim Bin(n,p)$，我想声明对于每个置信水平 $c \in (0,1)$，$ClopperPearsonLower(X_n, n, c)$ 都以概率收敛到 $p$，也就是说对于每个 $\epsilon&gt;0$：$Pr[|ClopperPearsonLower(X_n, n,c) - p| &gt; \epsilon]\stackrel{n\to\infty}{\longrightarrow}0$。
这是真的吗？如果是这样，我很乐意提供一本可以参考的书。]]></description>
      <guid>https://stats.stackexchange.com/questions/653299/asymptotic-consistency-of-the-clopper-pearson-interval</guid>
      <pubDate>Sun, 25 Aug 2024 17:01:22 GMT</pubDate>
    </item>
    <item>
      <title>我们能否从两个（非独立）随机变量序列分布的边际收敛得出分布的联合收敛结论？</title>
      <link>https://stats.stackexchange.com/questions/653297/can-we-conclude-joint-convergence-in-distribution-from-marginal-convergence-in-d</link>
      <description><![CDATA[假设我们有两个随机变量序列 Xn 和 Yn，它们定义在相同的概率空间中，使得 Xn 在分布上收敛到 X，而 Yn 几乎肯定会收敛到 Y。Xn 和 Yn 不独立。X 和 Y 也不独立。我们能得出关于 (Xn,Yn) 分布联合收敛的任何结论吗？
我知道当两个序列都独立时，这是一个既定的结果。但序列并不独立。我尝试的另一件事是使用 Xn 序列的 Skorohod 表示。但在这种情况下，我们正在转向另一个概率空间。所以我想这在这里不会奏效。有什么线索吗？提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653297/can-we-conclude-joint-convergence-in-distribution-from-marginal-convergence-in-d</guid>
      <pubDate>Sun, 25 Aug 2024 16:36:40 GMT</pubDate>
    </item>
    <item>
      <title>R 平方因果推断</title>
      <link>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</link>
      <description><![CDATA[我想知道在评估系数时，较低的 R 平方值是否会造成问题。我的人群被分为两组（A 和 B），我想评估它们之间在因变量方面是否存在显著差异。我在回归中加入了几个控制变量，但 R 平方值非常低（&lt;0.05）。我应该担心这个问题吗？添加更多控制变量是否明智？
假设我想在学术期刊上发表结果，这会造成问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</guid>
      <pubDate>Sun, 25 Aug 2024 15:42:45 GMT</pubDate>
    </item>
    <item>
      <title>固定样本大小顺序方差分析或 t 检验</title>
      <link>https://stats.stackexchange.com/questions/653286/fixed-sample-size-sequential-anova-or-t-test</link>
      <description><![CDATA[我有一个固定样本大小的实验，其中允许单位（2 个或 3 个分支中每个分支 20 个）随时间增长。一旦有足够的证据表明分支不以相同的速率增长，我希望停止实验。
我考虑每小时测量一次单位的大小。我可以假设给定臂中单位的大小呈正态分布，且各臂之间的方差相同。
这听起来像是 Wald 的序贯概率比检验的案例，只不过我没有积累新的单位。
我研究过执行序贯方差分析检验的方法，例如序贯方差分析：提高假设检验的效率，但我看过的所有论文都假设我在实验中添加了新的单位。
我尝试评估两个嵌套线性模型的似然比，一个模型带有臂项，另一个模型没有（例如仅使用截距）但不清楚阈值应该是什么。此外，由于两个嵌套模型的似然比永远不会小于 1，因此不能保证此检验会终止。
以下是部分数据的样子：

编辑
我认为需要应用一种名为重复测量方差分析的方法，但我不清楚如何应用它这里也没有说明如何按顺序应用它（即，一旦得出结论就停止测试）。]]></description>
      <guid>https://stats.stackexchange.com/questions/653286/fixed-sample-size-sequential-anova-or-t-test</guid>
      <pubDate>Sun, 25 Aug 2024 07:34:49 GMT</pubDate>
    </item>
    <item>
      <title>如果我的 LMM 与我的预测变量不匹配，我是否应该在 LMM 中使用较低的分辨率？</title>
      <link>https://stats.stackexchange.com/questions/653278/should-i-be-using-a-lower-resolution-in-my-lmm-if-it-dosent-match-my-predictor</link>
      <description><![CDATA[我有一组以三小时为采样点的动物运动值（例如 500m/3h）
我运行了一个线性混合模型，以运动距离作为响应变量，使用性别、白天（夜晚和白天）和月份作为可解释变量，但现在我正在重新考虑。
由于我的预测协变量的最低分辨率是白天（~12h），我正在重新考虑是否最好使用 a) 三小时值、b) 每天/夜晚的平均值或 c) 每天/夜晚的总和来运行我的模型。
从研究的角度来看，其中任何一个都对我的研究问题有相同的意义，但我对它的统计部分不太确定。我很难为自己的任何一种选择找到合理性。]]></description>
      <guid>https://stats.stackexchange.com/questions/653278/should-i-be-using-a-lower-resolution-in-my-lmm-if-it-dosent-match-my-predictor</guid>
      <pubDate>Sat, 24 Aug 2024 17:46:14 GMT</pubDate>
    </item>
    <item>
      <title>HGAMM（分层广义加性混合模型）中因子变量的族分布和处理的选择</title>
      <link>https://stats.stackexchange.com/questions/653223/chooice-of-the-family-distribution-and-handle-of-factor-variables-in-hgamm-hier</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653223/chooice-of-the-family-distribution-and-handle-of-factor-variables-in-hgamm-hier</guid>
      <pubDate>Fri, 23 Aug 2024 10:14:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么通过残差估计的数据与原始数据相比对重要性有 50/50 的影响？</title>
      <link>https://stats.stackexchange.com/questions/652971/why-estimates-of-data-via-residuals-has-50-50-effect-on-significance-compared-to</link>
      <description><![CDATA[我根据以下模型生成数据

在真实数据集中，变量 I 是未知的，目标是研究 I 和 D、B11 之间的关系，看它是否显着非零。为此，在已知 I 的模拟数据中，将使用 I 值的方法与使用 G ~ B 残差估计值的方法进行比较。换句话说，将 I ~ D 与 ([G ~ B] 的残差) ~ D 进行比较。根据下面的 R 代码，在中位数上，两个显着性检验是相同的，而在平均数上，直接使用 I 会略胜一筹。
对此的解释是什么？为什么不是“显而易见”的想法，因为残差只是变量 I 的估计值，而不是真实变量，所以它总是给出更不可靠的结果？相反，只有一半的时间给出更糟糕的结果？而另一半更好？
# Part A:
set.seed(0); n &lt;- 40; numSims &lt;- 10000; ronDsigs &lt;- c(); 
IonDsigs &lt;- c()
B8s &lt;- B9s &lt;- B10s &lt;- B11s &lt;- B12s &lt;- c()
for (index1 in 1:numSims) {
B &lt;- rnorm(n); I &lt;- rnorm(n); J &lt;- rnorm(n)
B8 &lt;- rnorm(1); B9 &lt;- rnorm(1); B10 &lt;- rnorm(1); B11 &lt;- rnorm(1); 
B12 &lt;- rnorm(1)
B8s &lt;- c(B8s, B8); B9s &lt;- c(B9s, B9); B10s &lt;- c(B10s, B10); 
B11s &lt;- c(B11s, B11);
B12s &lt;- c(B12s, B12)
G &lt;- B*B8 + I*B10; D &lt;- B*B9 + I*B11 + J*B12
GonB &lt;- lm(G ~ B)
GonBresiduals &lt;- GonB$residuals
GonBresidualsonD &lt;- lm(GonBresiduals ~ D)
IonD &lt;- lm(I ~ D)
ronDsigs &lt;- c(ronDsigs, 
summary(GonBresidualsonD)$coefficients[[8]])
IonDsigs &lt;- c(IonDsigs, summary(IonD)$coefficients[[8]])
}
rminI &lt;- ronDsigs - IonDsigs
summary(rminI)

# B 部分：与 A 部分完全相同的重复，但有一点不同B8,B9,B10,B11,B12
# 这次所有值都是常量。
set.seed(0); n &lt;- 40; numSims &lt;- 10000; ronDsigs &lt;- c(); 
IonDsigs &lt;- c()
B8s &lt;- B9s &lt;- B10s &lt;- B11s &lt;- B12s &lt;- c()
for (index1 in 1:numSims) {
B &lt;- rnorm(n); I &lt;- rnorm(n); J &lt;- rnorm(n)
B8 &lt;- 3; B9 &lt;- 1; B10 &lt;- 2; B11 &lt;- 11; B12 &lt;- 19
B8s &lt;- c(B8s, B8); B9s &lt;- c(B9s, B9); B10s &lt;- c(B10s, B10); 
B11s &lt;- c(B11s, B11);
B12s &lt;- c(B12s, B12)
G &lt;- B*B8 + I*B10; D &lt;- B*B9 + I*B11 + J*B12
GonB &lt;- lm(G ~ B)
GonBresiduals &lt;- GonB$residuals
GonBresidualsonD &lt;- lm(GonBresiduals ~ D)
IonD &lt;- lm(I ~ D)
ronDsigs &lt;- c(ronDsigs, 
summary(GonBresidualsonD)$coefficients[[8]])
IonDsigs &lt;- c(IonDsigs, summary(IonD)$coefficients[[8]])
}
rminI &lt;- ronDsigs - IonDsigs
summary(rminI)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652971/why-estimates-of-data-via-residuals-has-50-50-effect-on-significance-compared-to</guid>
      <pubDate>Sun, 18 Aug 2024 13:52:56 GMT</pubDate>
    </item>
    </channel>
</rss>