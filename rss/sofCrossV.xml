<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 24 Nov 2024 18:21:36 GMT</lastBuildDate>
    <item>
      <title>信息标准相对于交叉验证的优势</title>
      <link>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</link>
      <description><![CDATA[我理解 AIC 渐近等同于留一交叉验证。而 BIC 具有与留一交叉验证类似的渐近等同性。我的问题是，除了计算效率之外，还有什么理由比交叉验证更倾向于使用 AIC/wAIC/BIC 等信息标准？
在生态学文献中，使用 AIC 进行模型选择非常普遍。但如果可以进行交叉验证，还有什么理由使用 AIC？]]></description>
      <guid>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</guid>
      <pubDate>Sun, 24 Nov 2024 17:27:03 GMT</pubDate>
    </item>
    <item>
      <title>经验分布和狄拉克德尔塔问题</title>
      <link>https://stats.stackexchange.com/questions/657765/empirical-distribution-and-dirac-delta-question</link>
      <description><![CDATA[根据我目前正在阅读的一本书（Bishop 的《深度学习》），经验分布可以定义为
$\displaystyle p(x|D) = \frac{1}{N} \sum_{n=1}^N \delta(x-x_n)$
其中 $D$ 是从密度 $p(x)$ 中抽取的一组有限样本。
由于 $\delta(x-x_n)$ 在 $x = x_n$ 时定义为无限，我假设 $p(x=x_n|D)$ 具有相同的“峰顶高度”与$n$无关。（也许我的直觉在这里被打破了）
当我们从$x$中抽取越来越多的样本时，$\displaystyle \lim_{N \to \infty} p(x|D) = p(x)$怎么可能呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/657765/empirical-distribution-and-dirac-delta-question</guid>
      <pubDate>Sun, 24 Nov 2024 13:26:18 GMT</pubDate>
    </item>
    <item>
      <title>普通续约流程是不是都是延迟续约流程？</title>
      <link>https://stats.stackexchange.com/questions/657763/is-ordinary-renewal-process-always-delayed-renewal-process</link>
      <description><![CDATA[从定义上看，我觉得普通更新过程对第一个事件间隔时间有附加条件，为 iid，而延迟更新过程只有第一个事件间隔时间与其他事件间隔时间无关。那么，我是否可以得出普通更新过程也总是延迟更新过程的结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/657763/is-ordinary-renewal-process-always-delayed-renewal-process</guid>
      <pubDate>Sun, 24 Nov 2024 13:03:25 GMT</pubDate>
    </item>
    <item>
      <title>如何汇总差异估计中的差异数据？</title>
      <link>https://stats.stackexchange.com/questions/657761/how-to-aggregate-data-for-difference-in-differences-estimation</link>
      <description><![CDATA[我拥有某国三个州的连锁店五年来的每日销售数据。我想研究一项限制定价的法律对价格和需求的影响。该法律仅在三个州中的两个州执行。
关于数据：每个州各有三家商店、三个产品类别和大约三千种不同的产品。我想研究某一周期间、之前和之后的定价行为，我预计这一周的价格和销售额会发生剧烈变化。我应该按周和类别汇总价格和销售额，还是按产品汇总更好？我想知道由于汇总而导致的样本量减少是否会成为问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/657761/how-to-aggregate-data-for-difference-in-differences-estimation</guid>
      <pubDate>Sun, 24 Nov 2024 12:52:50 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中的嵌入</title>
      <link>https://stats.stackexchange.com/questions/657760/embeddings-in-time-series-prediction</link>
      <description><![CDATA[我越来越多地注意到，嵌入越来越多地用于纯预测 ML 任务。例如，不是预测用户 i 是否会购买商品 i，从而向 ML 模型添加数千或数百万个输入，而是通过一些外部黑盒函数嵌入用户和商品，然后构建一个简单的分类模型，该模型接受用户嵌入和商品嵌入，其大小将随着时间的推移而固定。
太棒了！至于时间序列预测，我注意到在单变量空间中有很多工作，例如 Facebook 的 Prophet。然而，我们可能需要预测每个地区每个产品的需求，这是很常见的。预测 r 个区域和 p 个产品的未来 t 个时间步长的预测模型在计算上会过于臃肿，可能不可行，并且随着新产品和区域添加到企业中而无法扩展。
所以我想知道，在预测模型接受 r 个区域嵌入、p 个产品嵌入和 t 个时间步长（特定区域特定产品的历史需求）的情况下，已经做了哪些工作，从而产生 q 个时间步长的预测？
我也知道，传统的预测方法 ARIMA 需要去趋势数据，这可能会很繁重，因此 RNN、GRU、LSTM 和 transformers 等 DL 方法越来越受欢迎。
对于这个问题，我想看看接受嵌入和过去观察的时间序列模型的引用和整体概述，以便可以对各种嵌入单元（产品、区域等）进行预测。
这里做了哪些工作，学术界和工业界的趋势如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/657760/embeddings-in-time-series-prediction</guid>
      <pubDate>Sun, 24 Nov 2024 11:02:31 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 1 个因变量和多个自变量来分析数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657752/how-to-analyase-data-with-1-dependent-variable-and-multiple-independent-variable</link>
      <description><![CDATA[我有以下农业指标：

农业，增加值（占 GDP 的百分比）
农业就业（占总就业的百分比）
可耕地（公顷）
作物生产指数（2004 2006 = 100）
畜牧业生产指数（2004 2006 = 100
粮食生产指数（2004 2006 = 100）
农村人口（占总人口的百分比）

我想看看这些指标对越南出口到欧盟的价值的影响。我应该如何在 eviews 中执行此操作，因为我有数据，还有（公顷）和百分比中的数据，我应该保持原样并运行吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657752/how-to-analyase-data-with-1-dependent-variable-and-multiple-independent-variable</guid>
      <pubDate>Sun, 24 Nov 2024 04:34:36 GMT</pubDate>
    </item>
    <item>
      <title>计算随机过程的平均值和方差？</title>
      <link>https://stats.stackexchange.com/questions/657751/calculate-the-mean-and-variance-of-a-stochastic-process</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657751/calculate-the-mean-and-variance-of-a-stochastic-process</guid>
      <pubDate>Sun, 24 Nov 2024 03:33:58 GMT</pubDate>
    </item>
    <item>
      <title>使用零截断负二项 (polya) 分布估计缺失零类概率</title>
      <link>https://stats.stackexchange.com/questions/657750/estimating-missing-zero-class-probability-using-a-zero-truncated-negative-binomi</link>
      <description><![CDATA[我有缺少零类的离散数据。即，我有以 $[1,2,..N]$ 为中心的频率箱，但没有零位置箱的数据。
我已成功使用递归关系将零截断泊松分布拟合到数据中：
$$ \lambda_0 = \bar{X}, \\ \lambda_{i+1} = \bar{X} \, ( 1-e^{- \lambda_i} ) $$
其中 $\bar{X}$ 为样本均值，$\lambda_i$ 为迭代 $i$ 时泊松分布的均值。那么缺失零类的概率为：
$$ \hat{P}_0 = \frac{P_0}{1-P_0} = \frac{e^{- \bar{\lambda}}}{ 1-e^{{- \bar{\lambda}}} } $$
此方法有效，但在某些情况下，数据并不完全遵循泊松分布，导致对零类的估计毫无意义。
我的数据只有少量的类别。我相信具有有限支持的分布会是更好的选择。我决定尝试使用二项式求解：
$$ p_0 = \bar{X} /N, \\ p_{i+1} = \bar{X} \, \bigg[ 1 - (1-p_i)^N \bigg] \,/N $$
使用二项式可以得到更好的估计，但是我想尝试将负二项式 (Polya) 分布拟合到数据中。我找到了这篇论文，其中他们提出了 Polya 分布情况下零类概率的估计量。我实现了上述结果（论文中的方程 14 和 15）来推断我的问题中缺失的零类：
$$ \omega_0 = 2 \sigma^2 , \\ \omega_{i+1} = 2 \sigma^2 \, \bigg[ 1 - (1+\omega_i)^{-\bar{X}/{2 \sigma^2}} \bigg] \,/N $$
但结果大相径庭。也许我遗漏了什么？有人能建议一个更好的估计器，或者指出我的错误吗？谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/657750/estimating-missing-zero-class-probability-using-a-zero-truncated-negative-binomi</guid>
      <pubDate>Sun, 24 Nov 2024 02:22:17 GMT</pubDate>
    </item>
    <item>
      <title>单独的小样本交叉验证测试集（n=140）</title>
      <link>https://stats.stackexchange.com/questions/657749/separate-test-set-for-cross-validation-for-small-sample-n-140</link>
      <description><![CDATA[我正在研究一个生存分析模型，该模型有一个小型内部数据集（n=140）。一位外部研究人员建议将数据集拆分为训练/验证，并留出一个单独的测试集（例如，~10%，或 14 个样本）进行评估。但是，我担心进一步拆分已经很小的数据集可能会损害结果的可靠性。
在不留出单独的测试集的情况下对整个数据集进行交叉验证是否更合适，或者拆分是否仍然有必要？]]></description>
      <guid>https://stats.stackexchange.com/questions/657749/separate-test-set-for-cross-validation-for-small-sample-n-140</guid>
      <pubDate>Sun, 24 Nov 2024 01:56:42 GMT</pubDate>
    </item>
    <item>
      <title>在 Mann Whitney U 检验中支持零假设后，进行事后功效分析是否合适？样本量不相等</title>
      <link>https://stats.stackexchange.com/questions/657740/is-it-appropriate-to-do-a-post-hoc-power-analysis-after-the-null-hypothesis-is-f</link>
      <description><![CDATA[嗨，在 Mann Whitney U 检验中支持零假设后进行事后功效分析是否合适？样本量不相等，我想知道它是否功效不足。对于像链接的帖子，我不确定这是否合适。谢谢
样本量和功效检测]]></description>
      <guid>https://stats.stackexchange.com/questions/657740/is-it-appropriate-to-do-a-post-hoc-power-analysis-after-the-null-hypothesis-is-f</guid>
      <pubDate>Sat, 23 Nov 2024 21:24:17 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析、斜向旋转、方差解释</title>
      <link>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</link>
      <description><![CDATA[如何计算通过探索性因子分析获得的因子模型解释的方差的问题时常出现。这里有一个包含多种可能性的摘要：在 R 中使用斜旋转进行探索性因子分析后计算因子解释的方差
我使用的是 R，带有 psych 包，如代码片段所示：
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
mean(fa_results$communalities)
print(fa_results)


平均共同性金额：0.7418824
摘要表还将 0.74 报告为斜交旋转的解释方差：
斜交旋转：

[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00


如果我使用正交旋转进行相同的分析，例如varimax，那么我得到的解释总方差值相同。
Varimax 旋转：
[...]

MR1 MR3 MR2 MR5 MR4
SS 载荷 2.44 1.45 1.06 0.91 0.81
比例方差 0.27 0.16 0.12 0.10 0.09
累积方差 0.27 0.43 0.55 0.65 0.74
解释比例 0.37 0.22 0.16 0.14 0.12
累积比例 0.37 0.58 0.74 0.88 1.00


据我了解，正交旋转会在因子之间重新分配载荷，但解释总方差仍然是整个系统都一样。但是，我不确定斜向旋转，因为这些因素在它们解释的方差上重叠。在上面的例子中，我在一些因素之间存在显著的相关性，但我得到的总解释方差与方差最大值相同。在这种情况下，总解释方差是否也相同，还是我做错了什么？我需要反馈。谢谢！
更新：
我还查看了两种情况下 fa_results$loadings 的输出。它显示的方差最大值的摘要值不与 print(fa_results) 相同，但在斜向旋转的情况下，输出偏差更大。哪些值是正确的？
Oblimin：与 print(fa_results) 相比的偏差
Oblimin 旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.310 1.350 0.975 1.038 0.563
比例变异 0.257 0.150 0.108 0.115 0.063
累积变异 0.257 0.407 0.515 0.630 0.693

Varimax：与 print(fa_results) 相比的偏差。
Varimax旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR2 MR5 MR4
SS 载荷 2.444 1.450 1.064 0.913 0.806
比例方差 0.272 0.161 0.118 0.101 0.090
累积方差 0.272 0.433 0.551 0.652 0.742
]]></description>
      <guid>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</guid>
      <pubDate>Fri, 22 Nov 2024 17:10:04 GMT</pubDate>
    </item>
    <item>
      <title>检查两组比例是否_无差异_的检验</title>
      <link>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</link>
      <description><![CDATA[是否有检验方法可以检查两组小比例是否显著无差异？
例如，考虑两组比例
(0.2,0.3,0.25,0.35,0.19)
(0.31, 0.25, 0.21,0.17, 0.22) 
我想证明两组显著无差异。这意味着零假设必须是它们不同。
如果对数据来源​​感兴趣，那就是各种样本的细胞类型比例。我想表明，经过治疗后，各种细胞类型比例的分布不会改变。
之所以选择零假设和备择假设，是因为我感兴趣的实质性主张是两种条件之间没有发生变化。无法拒绝无变化的零假设并不等同于接受无变化的假设，而后者才是我感兴趣的。

编辑：在示例数据中，每个值都是单个样本。一种细胞类型有 5 个样本，而不是五种不同的细胞类型（我在上一段中以误导性的方式描述了它）。]]></description>
      <guid>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</guid>
      <pubDate>Fri, 22 Nov 2024 08:15:29 GMT</pubDate>
    </item>
    <item>
      <title>对偶自然对数模型中的过度拟合</title>
      <link>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</link>
      <description><![CDATA[我有以下函数来模拟质谱仪中气体强度的变化：
$$y = a \ln(p(t + 32)) - b \ln(q(t+30))$$
正如 JJacquelin 在下面指出的那样，简化为：
$$y = a \ln(t+32) - b \ln(t+30) + c\quad \text{where}\quad c = \ln p - \ln q$$
其中第一项表示从记忆中长出，第二项表示通过电离消耗。

$t,y$ 是独立变量和因变量， 
$a$、$b$ 和 $c$ 是拟合参数
$32$ 表示 $t=0$ 之前气体从内存中开始增长的时间（以秒为单位）
$30$ 表示 $t=0$ 之前电离开始消耗的时间（以秒为单位）

目标是确定 $y$ 在 $t=0$ 处的截距，代表理论上的平衡气体强度。
虽然单个自然对数可以捕捉许多分析的趋势，但它对其他分析来说却不够准确，或者需要补偿（减少 30 秒的时间偏移）才能捕捉某些消耗趋势，这会损害其适应其他生长趋势的能力。
“双对数”然而，模型在绝大多数情况下都能产生理想的结果：

然而，在少数情况下，该模型在低$t$值下会产生不切实际的行为：



这种“俯冲”行为表明在向内生长占主导地位之前，早期的气体消耗量很大，这在物理上是不现实的。通常，低信号分析以内生为主，高信号分析以消耗为主，而匹配分析会产生噪声趋势。
因此，问题在于截距过于依赖于低$t$ 处的几个不均匀异常点，从而扭曲拟合并产生不合理的高截距。截距不是由整体趋势决定的，而是由一些低$t$ 数据的趋势决定的。
目标是修改模型以消除这些波动而不引入任意约束（例如，手动限制$b$ 有效，但没有物理依据，因此截距在基于边界的一定范围内变成我想要的任何东西）。
我已经为此浪费了好几天的时间，但看不到解决方案。如能得到任何指导、指示或建议的解决方案，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</guid>
      <pubDate>Fri, 22 Nov 2024 00:53:34 GMT</pubDate>
    </item>
    <item>
      <title>不进行回归分析时多重共线性的澄清</title>
      <link>https://stats.stackexchange.com/questions/657135/clarification-of-multicollinearity-when-not-performing-a-regression-analysis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657135/clarification-of-multicollinearity-when-not-performing-a-regression-analysis</guid>
      <pubDate>Tue, 12 Nov 2024 10:30:33 GMT</pubDate>
    </item>
    <item>
      <title>时间序列平稳性和消除虚假相关性的严格证明</title>
      <link>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</link>
      <description><![CDATA[我理解时间序列分析中的平稳性至关重要，尤其是对于推断而言，因为它有助于降低伪回归的风险。在非平稳序列中，由于方差或均值的变化，相关性更有可能显得显著，从而导致对因果关系的误导性推断。
是否有严格的证明或理论解释支持这一点？具体来说，为什么随时间变化的非恒定方差会增加伪相关的可能性？平稳性如何增强暗示因果关系的相关性的可靠性？任何数学见解或参考资料都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</guid>
      <pubDate>Sun, 10 Nov 2024 21:34:25 GMT</pubDate>
    </item>
    </channel>
</rss>