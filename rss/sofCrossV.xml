<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 15:18:40 GMT</lastBuildDate>
    <item>
      <title>关于VC理论的两个问题（关于泛化误差界限）</title>
      <link>https://stats.stackexchange.com/questions/658674/two-questions-about-the-vc-theory-on-the-generalization-error-bound</link>
      <description><![CDATA[在 Andrews Ng 的机器学习笔记 (https://cs229.stanford.edu/main_notes.pdf) 中，他引入了以下泛化误差与训练误差之间的差异界限（见下图），该界限取决于假设类的 VC 维度：

关于这个结果，我有两个问题：

在他的讲义中，这个结果是在二元分类的背景下提出的。这个定理也适用于回归吗？ （如果不是，那么回归问题的界限是什么？）

该学习理论在给定假设集$H$上限制泛化误差与训练误差的偏差。我的问题是，数据驱动的模型选择/正则化如何适应这个框架？假设$\widehat{H}$是数据驱动模型选择的结果（例如，它可能是具有非零系数的回归量的子集），人们是否仅在$H=\widehat{H}$的条件下应用此界限？或者这个界限在模型选择或正则化下不再有用？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658674/two-questions-about-the-vc-theory-on-the-generalization-error-bound</guid>
      <pubDate>Fri, 13 Dec 2024 14:41:39 GMT</pubDate>
    </item>
    <item>
      <title>一个第二阶段协变量是第一阶段回归的内生变量</title>
      <link>https://stats.stackexchange.com/questions/658673/one-second-stage-covariate-is-endogenous-to-first-stage-regression</link>
      <description><![CDATA[我正在研究一个数据库（区域级，称为 DB），以分析通勤模式选择的决定因素。我运行了一个多项逻辑回归：我对一些个人变量（年龄、工作类型、居住地、在家工作……）和一些公司层面的变量（有利于主动模式的基础设施、PT 的可访问性……）对模式选择（汽车、自行车、步行、PT、拼车）进行回归。
这样做，我可能会面临一个反向因果关系的问题：通勤使用的模式可能会对在家工作的事实产生影响（我骑自行车上班，但有点太多，所以我决定每周在家工作一天）。在家工作是我感兴趣的变量之一。
因此，我构建了一个工具来控制这个内生性问题。我使用一个国家就业数据库（称为 NT），并按就业部门（工业、行政、健康等）计算在家工作的人数比例。然后，我的数据库 DB 中的每个受访者都与其公司对应部门的在家工作的人数全国份额相关联。这个工具可能会奏效：它与个人模式选择无关，因为它来自另一个数据库（国家级），并且与受访者声明在家工作的事实相关（我的数据库 DB 的公司属于部门）。
当我运行第一阶段回归时，我的问题出现了：我将我的内生变量（至少部分在家工作的事实）回归到我的主要回归的所有外生变量上。在这些变量中，我们发现通勤距离和居住地。尽管如此，这里可能还会出现另一个内生性问题：通勤距离和居住地会影响在家工作的事实（我更倾向于在家工作，因为我通勤距离很远）。
我现在有点不知道该如何处理这种情况。我非常确定我绝对需要在第一阶段回归中添加第二阶段的所有外生变量。但我也确定我第一阶段的估计必须是一致的，但事实并非如此。
任何帮助都会非常受欢迎！！]]></description>
      <guid>https://stats.stackexchange.com/questions/658673/one-second-stage-covariate-is-endogenous-to-first-stage-regression</guid>
      <pubDate>Fri, 13 Dec 2024 14:28:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么虽然我们有闭式估计量$(X'X)^{-1}X'Y$，但机器学习课程中的回归分析大多侧重于梯度下降？</title>
      <link>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</link>
      <description><![CDATA[在许多在线机器学习课程和视频（例如 Andrew Ng 的 Coursera 课程）中，当谈到回归（例如对特征 $X$ 进行 $Y$ 回归）时，虽然我们有回归系数 $\widehat{\beta}=(X&#39;X)^{-1}X&#39;Y$ 的闭式估计量，并且基于此我们可以得出 $X_i=x$ 的预测为 $x&#39;\widehat{\beta}$。这很简单，不需要数值优化。我的问题是：

鉴于闭式回归估计器（和预测器）的简单性，为什么机器学习课程通常会忽略它，而只关注梯度下降？

以这种方式教授回归有什么优点？

此外，梯度下降在实际性能方面的相对优点是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</guid>
      <pubDate>Fri, 13 Dec 2024 14:08:57 GMT</pubDate>
    </item>
    <item>
      <title>条件概率中的或语句：P(A|B 或 C)</title>
      <link>https://stats.stackexchange.com/questions/658669/or-statement-in-conditional-probability-pab-or-c</link>
      <description><![CDATA[我正在阅读有关竞争风险的 Fine-Gray 模型，其中给出的子分布风险函数的定义[1,2]是：
$$\lambda(t) := \lim_{\Delta t \rightarrow 0} \frac{P \left( T \leq t + \Delta t, \epsilon = 1|T \geq t \bigcup [T \leq t \cap \epsilon \neq 1] \right)}{\Delta t}$$
其中 $T$ 是失败时间，$\epsilon$ 是失败原因。我将 $\cup$ 符号解释为 &quot;OR&quot;，将 $\cap$ 解释为 &quot;AND&quot; - 但这可能不正确？
我从未见过形式为 $P(A|B \cup C)$ 的概率陈述，一个简单的人为示例是伯努利 ($p$) 正面朝上的概率，假设 $p=0.25$ 或 $p=0.8$：$P(H|p = 0.25 \cup p = 0.8)$。我不明白如果不对 $p$ 进行先验分析，或者对于任何陈述 $P(A|B \cup C)$ 进行一般分析，该陈述如何得到答案，除了 $P(A|B) = P(A|C)$ 的特殊情况。我的问题是，形式为 $P(A|B \cup C)$ 的陈述是否有效（在贝叶斯世界之外）？此外，Fine 和 Gray 是否滥用了符号？如果是这样，子分布风险函数是否有正式定义？

Fine, J. P., &amp; Gray, R. J. (1999). A Proportional Hazards Model for the Subdistribution of a Competing Risk.美国统计协会杂志，94(446)，496–509。https://doi.org/10.1080/01621459.1999.10474144

Austin PC，Fine JP。报告竞争风险数据的 Fine-Gray 模型分析的实用建议。医学统计学。2017；36：4391–4400。 https://doi.org/10.1002/sim.7501（开放获取）

]]></description>
      <guid>https://stats.stackexchange.com/questions/658669/or-statement-in-conditional-probability-pab-or-c</guid>
      <pubDate>Fri, 13 Dec 2024 12:38:05 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[我一直在研究 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时 $Y=-\log(X)$ 的分布，因此 $\mathbb R_{\ge 0}$ 支持 $Y$。这可以称为 负 exp-Beta 分布吗？
对于 $\beta=1$，众所周知 $Y \sim \operatorname{Exp}(\alpha)$ 即 $\operatorname{Gamma}(1,\alpha)$。我对 $\beta$ 取其他值的情况很感兴趣。
从经验上讲，对于整数 $\beta$，似乎 $m=\mathbb E[Y] = \sum\limits_{k=\alpha}^{\alpha+\beta-1} \frac1k$ 和 $v=\operatorname{Var}(Y)=\sum\limits_{k=\alpha}^{\alpha+\beta-1} \frac1{k^2}$，或者至少这些是非常接近的近似值。这些是精确的吗？对于非整数 $\beta$，其等价项是什么？
再次从经验上看，$Y$ 分布的近似值似乎是 $\operatorname{Gamma}\left(\frac{m^2}{v},\frac{m}{v}\right)$，并且当 $\alpha \not \ll \beta$ 时，这似乎是一个更好的近似值。这种近似值有依据吗？当 $\beta \not = 1$ 时，是否有确切分布的描述？
例如，使用 R，
alpha &lt;- 5.6789
beta &lt;- 8
cases &lt;- 10^6
X &lt;- qbeta(ppoints(cases), alpha, beta)
Y &lt;- -log(X)
mean(Y)
# 0.9327204
print(m &lt;- sum(1/(alpha:(alpha+beta-1))))
# 0.9327205
var(Y)
# 0.1166561
print(v &lt;- sum(1/(alpha:(alpha+beta-1))^2))
# 0.1166563

查看黑色的 $Y$ 密度和红色的相应 Gamma 分布，可以看出它们有多接近：
plot(density(Y))
curve(dgamma(x, shape=m^2/v, rate=m/v), 
from=0, to=max(Y), col=&quot;red&quot;, add=TRUE)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>多参数最大似然估计的渐近正态性证明</title>
      <link>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</link>
      <description><![CDATA[我有一个问题，关于如何证明多个 MLE 估计量的渐近性质。您在网上找到的大多数资源都提供了仅估计一个参数的情况的证明（例如此处：https://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/）。在这个证明中，将参数方面的均值定理应用于似然的一阶导数，得到类似$(\hat{\theta} - \theta_0) = - \frac{L_n&#39;(\theta_0)}{L_n&#39;&#39;(\tilde{\theta})}$的表达式，然后将渐近结果应用于似然。我将这种证明扩展到多参数情况的问题是均值定理仅适用于标量函数。对于矢量值函数，只有不等式成立，参见例如。 https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions。
有人能告诉我如何证明多个参数的渐近正态性吗？当然，如果能提供参考，我也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</guid>
      <pubDate>Fri, 13 Dec 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>OR、se、CI 之间有什么关系</title>
      <link>https://stats.stackexchange.com/questions/658663/what-is-the-relationship-between-or-se-and-ci</link>
      <description><![CDATA[如果这是一个重复的问题，请原谅，但我一直无法找到明确的答案。
比值比、标准误差和置信区间之间的关系是什么？
我尝试对汇总统计数据进行荟萃分析。一些研究报告 OR + se，一些研究报告 OR + CI。
我理解 se = (log(CI 较高) - log(CI 较低)) / 3.92，但我不明白如何使用 OR 的 se 来获取 OR 的 CI。和/或如何在不使用 CI 的情况下获取对数转换 OR 的 se？
执行 CI = OR +/- 1.96 * se 似乎不正确。或者这只适用于对数变换后的 OR？
如果我使用 se of log OR = se / OR 来反向计算 Log OR +/- 1.96*se of log OR 和 exp(CI bounds)，我似乎仍然无法获得正确的置信区间]]></description>
      <guid>https://stats.stackexchange.com/questions/658663/what-is-the-relationship-between-or-se-and-ci</guid>
      <pubDate>Fri, 13 Dec 2024 10:12:21 GMT</pubDate>
    </item>
    <item>
      <title>模拟多级数据以获得特定的边际 R 平方值</title>
      <link>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</link>
      <description><![CDATA[我正在致力于模拟多级数据，目标是通过模拟实现特定的边际 R 平方值。鉴于多级建模中的方差分解在调整不同级别的参数时会变得相当复杂，我一直在尝试通过模拟来近似边际 R 平方值。
以下是 R 代码片段，用于具有两个 1 级预测因子（X1ij、X2ij）和两个 2 级预测因子（Z1j、Z2j）的两级模型的基本数据生成过程：
# 加载必要的库
library(lme4) # 用于拟合混合模型

# # 设置种子以实现可重复性
# set.seed(12654)

# 模拟参数
n_groups &lt;- 30 # 2 级组数
n_per_group &lt;- 30 # 每组的 1 级单元数
n &lt;- n_groups * n_per_group # 总数观察

# 固定效应
gamma_00 &lt;- 0 # 截距
gamma_10 &lt;- 1 # 1 级预测器的初始斜率（X1ij - 待调整）
gamma_01 &lt;- 1 # 2 级预测器的初始斜率（Z1j - 待调整）
gamma_20 &lt;- 0 # 附加 1 级预测器的斜率（X2ij）
gamma_02 &lt;- 0 # 附加 2 级预测器的效应（Z2j）

# 方差分量
sigma2_e &lt;- 1 # 残差方差（epsilon）
sigma2_U0j &lt;- 0.5 # 随机截距方差

# 数据生成过程函数
dgp_function &lt;- function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) {

# 模拟 2 级预测因子 (Z1j 和 Z2j)
Z1j &lt;- rnorm(n_groups, mean = 0, sd = 1)
Z2j &lt;- rnorm(n_groups, mean = 0, sd = 1)

# 初始化数据存储
data &lt;- data.frame()

# 为每个组生成数据
for (j in 1:n_groups) {
# 组 j 的随机截距
b_j &lt;- rnorm(1, mean = 0, sd = sqrt(sigma2_U0j))

# 1 级预测因子 (X1ij 和 X2ij)
X1ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)
X2ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)

# 1 级残差
epsilon &lt;- rnorm(n_per_group, mean = 0, sd = sqrt(sigma2_e))

# 生成结果变量 Y
Y &lt;- (gamma_00 + b_j) + gamma_10 * X1ij + gamma_01 * Z1j[j] + gamma_20 * X2ij + gamma_02 * Z2j[j] + epsilon

# 为该组创建数据框
group_data &lt;- data.frame(
group = j,
X1ij = X1ij,
X2ij = X2ij,
Z1j = Z1j[j],
Z2j = Z2j[j],
Y = Y
)

# 与主数据框合并
data &lt;- rbind(data, group_data)
}

return(data)
}

我的目标是通过使用缩放因子更新模型参数 gamma_10 和 gamma_01，以迭代调整它们，以近似所需的边际 R 平方值。但是，我使用的方法产生了一些奇怪的结果，我不确定是否有更可靠的方法。
这是我的代码的一部分，我调整了 gamma_10 和 gamma_01 以尝试达到所需的 R 平方：
不幸的是，我没有这种模拟的经验，因此任何想法或文献参考都值得赞赏。
# 期望的边际 R 平方
desired_marginal_R2 &lt;- 0.25

# 实现的 R2 和迭代容差和计数器的占位符
achieved_R2 &lt;- 0
容差 &lt;- 0.01
迭代 &lt;- 1
max_iterations &lt;- 100

# 迭代调整 gamma_10 和 gamma_01 以实现所需的边际R2
while (abs(achieved_R2 - desire_marginal_R2) &gt; tolerance &amp;&amp; iteration &lt;= max_iterations) {
# 生成数据
data &lt;- dgp_function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) 

# 拟合混合模型
model &lt;- lmer(Y ~ X1ij + Z1j + (1 | group), data = data)

# 使用 performance 包计算边际 R2
reached_R2 &lt;- performance::r2(model, details = TRUE)$R2_marginal

# 根据实现的 R2 调整 gamma_10 和 gamma_01（启发式）
scaling_factor &lt;- sqrt(desired_marginal_R2 / reached_R2)
gamma_10 &lt;- gamma_10 * scaling_factor
gamma_01 &lt;- gamma_01 * scaling_factor

# 增加迭代计数器
iteration &lt;- iteration + 1
}

# 输出结果
cat(&quot;Achieved Marginal R2:&quot;, reached_R2, &quot;\n&quot;)
cat(&quot;Desired Marginal R2:&quot;, desire_marginal_R2, &quot;\n&quot;)
cat(&quot;迭代次数：&quot;, 迭代次数 - 1, &quot;\n&quot;)
cat(&quot;调整后的 gamma_10：&quot;, gamma_10, &quot;\n&quot;)
cat(&quot;调整后的 gamma_01：&quot;, gamma_01, &quot;\n&quot;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</guid>
      <pubDate>Fri, 13 Dec 2024 08:24:27 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况会越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为组 1（2022），包含 207 个样本，组 2（2023），包含 250 个样本。 y 轴变量以整数形式测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，组 2 中有 9 个点高于 10（约为组 1 的平均值），组 2 中有 10 个点约为 10（总共 12 个高异常值），其中组 2 中的顶级异常值高于组 1。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些都表明平均值有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，而不管平均值的行为如何。有人要求我在不同性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些统计数据最适合用于评估基于常模的能力评估的有效性和可靠性？</title>
      <link>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</link>
      <description><![CDATA[我计划评估常模参照能力评估的有效性和可靠性。该工具有 5 个与能力相关的子量表。有现成的常模，但我想对我拥有的样本进行一些额外的研究，以增加对该工具的研究内容。
对于标准参照评估，我会考虑的两个统计数据是每个项目的 Cronbach&#39;s alpha 和因子分析。一般来说，这些是否也构成能力评估的最佳实践？]]></description>
      <guid>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</guid>
      <pubDate>Fri, 13 Dec 2024 05:44:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) \hat{\bf V}^{-1} (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X - \bf M)^\top \hat{\bf U}^{-1} (\bf X - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\, \mathrm{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X - \bf M)^\top (\bf X - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>基于密度比估计的分类</title>
      <link>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</link>
      <description><![CDATA[考虑分类问题 $p(y \mid x)$，其中 $y$ 是标签，$x$ 是特征向量，例如图像。通常，我们会拟合卷积网络，并根据 $x$ 预测 $y$。昨天我突然想到，根据贝叶斯规则，$\log p(y \mid x) = \log p(y) + \color{blue}{\log \frac{p(x \mid y)}{p(x)}}$。由于$\log p(y)$可以从数据集中轻松估算出来，因此找到对数密度比（蓝色）将等同于找到分类器$p(y \mid x)$。根据密度比技巧（Sugiyama 等人， 2012；Dhuliawala 等人， 2023），可以通过拟合一组分类器 $T_y(x)$（也可以选择拟合一个摊销分类器）来找到对数密度比，该分类器区分 $p(x \mid y)$ 样本和 $p(x)$ 样本。 $T_y(x)$ 的优化条件是 $\mathbb E_{p(x \mid y)}[\log \sigma(T_y(x))] + \mathbb E_{p(x)}[\log (1-\sigma(T_y(x)))]$ 最大化，其中 $\sigma(\cdot)$ 为 S 型函数。因此，$\log p(y \mid x) = \log p(y) + T_y(x)$。一个优点可能是校准标签偏移很简单。
这种方法在实践中使用过吗？如果有人能给我指出相关文献，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</guid>
      <pubDate>Fri, 13 Dec 2024 03:36:18 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据进行因果关系检验的算法/测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</link>
      <description><![CDATA[我有两份在 18 个采样点和 20 个采样日期收集的观测数据，我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经完成了双向方差分析与交互作用（编辑），现在我想做一个事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它能给出组别和字母，说明各组之间的差异。但我不确定这个函数是否可以用于两个因素，或者它是否只适用于单向方差分析。有人知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以准确地找到我所寻找的内容。
由于缺乏估计量的封闭公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$n\hat{p}$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。
（这是我对此的第一个问题论坛）]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    </channel>
</rss>