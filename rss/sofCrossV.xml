<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 22 Aug 2024 12:29:59 GMT</lastBuildDate>
    <item>
      <title>仅根据比值比和样本总量计算比值比的置信区间</title>
      <link>https://stats.stackexchange.com/questions/653167/calculating-confidence-intervals-for-odds-ratios-based-only-on-odds-ratio-and-to</link>
      <description><![CDATA[我正在运行荟萃分析，许多研究仅报告总样本量和优势比，这使计算抽样方差变得复杂。我可以使用优势比、总样本量和 p 值来确定抽样方差（conv.wald 函数）。但是，这些研究要么没有报告 p 值，要么只提供近似值。
有没有办法仅使用 OR 和总样本来计算置信区间？
我已经编写了下面的函数，但我不完全确定假设 se_or &lt;- sqrt(1/n) 是否正确。
my_func &lt;- function(or, n) {
log_or &lt;- log(or)
se_or &lt;- sqrt(1/n)
z &lt;- qnorm((1 + .95)/2)
log_or_ci_lower = log_or - z*se_or
log_or_ci_upper = log_or + z*se_or
ci_lower = exp(log_or_ci_lower)
ci_upper = exp(log_or_ci_upper)
返回（列表（或，ci_lower，ci_upper））
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/653167/calculating-confidence-intervals-for-odds-ratios-based-only-on-odds-ratio-and-to</guid>
      <pubDate>Thu, 22 Aug 2024 11:59:48 GMT</pubDate>
    </item>
    <item>
      <title>在扑克中，为什么同花比顺子好？</title>
      <link>https://stats.stackexchange.com/questions/653166/in-poker-why-do-flushes-overtake-straights</link>
      <description><![CDATA[5 张牌的扑克牌更有可能是顺子而不是同花。
但 13 张牌的桥牌牌更有可能包含 5 张牌的同花而不是 5 张牌的顺子（来源：我在网上某处读到的）。
对于为什么添加牌会导致同花超过顺子，最直观、最令人信服的解释是什么？
很明显，同花必须在第 17 张牌之前超过顺子，因为不可能有 17 张牌而没有同花，但我更感兴趣的是为什么前几张额外的牌会导致同花赶上来。我猜答案将涉及争论为什么顺子比同花更具相关性（这意味着你更有可能拿到一手牌，其中许多不同的 5 张牌子集是顺子，这必须与你更有可能拿到一手牌，其中没有 5 张牌子集是顺子）相平衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/653166/in-poker-why-do-flushes-overtake-straights</guid>
      <pubDate>Thu, 22 Aug 2024 11:23:08 GMT</pubDate>
    </item>
    <item>
      <title>手动计算拟合模型的对数似然</title>
      <link>https://stats.stackexchange.com/questions/653165/manually-calculate-loglikelihood-of-fitted-model</link>
      <description><![CDATA[我的目标是计算拟合模型对一些未见数据的对数似然。
为此，我定义了一个函数，用于手动计算一些新数据的对数似然。但是，作为健全性检查，我将新定义函数的结果与现有 logLik() 函数的结果进行了比较，结果不匹配。有人能解释一下我哪里出错了吗？
library(&quot;lme4&quot;)
# 创建数据集
set.seed(123)
n &lt;- 20000

TRT &lt;- rnorm(n, mean = 336.59, sd = 244.09)
zipf &lt;- rnorm(n, mean = 5.83, sd = 1.22)
word_length &lt;- rnorm(n, mean = 4.69, sd = 2.31)
surprisal &lt;- rnorm(n, mean = 5.04, sd = 2.92)
word_sent_index &lt;- as.factor(sample(2:26, n, replace = TRUE))
participant_ID &lt;- as.factor(sample(1:40, n, replace = TRUE))
word_token &lt;- as.factor(sample(1:828, n, replace = TRUE))

df &lt;- data.frame(TRT, zipf, word_length, word_sent_index, surprisal, party_ID, word_token)

# 将数据集拆分为训练集和测试集
Nfolds &lt;- 5
df$folds &lt;- sample(1:Nfolds, size = nrow(df), replace = TRUE)
fold = 5

train_data &lt;- df[df$folds != fold, ]
test_data &lt;- df[df$folds == fold, ]

# 使用拟合 lme4 模型计算新数据集的对数似然函数。
logLik_test &lt;- function(lm, test_X, test_y) {
predictions &lt;- predict(lm, test_X, re.form = ~(1 | contestant_ID) + (1 | word_token), allow.new.levels = TRUE)
stdev &lt;- sigma(lm)
loglik &lt;- sum(dnorm(test_y, predictions, stdev, log=TRUE))
return(loglik)
}

接下来，我在 train_data 上拟合一个混合效应模型，并将 logLik 函数的输出与之前定义的 logLik_test() 进行比较，并使用 train_data 评估拟合度。
TRT_surprisal &lt;- lmer(TRT ~
1 + zipf + word_length + word_sent_index + surprisal +
(1 | contestant_ID) + (1 | word_token), train_data, REML = FALSE)
logLik(TRT_surprisal)
[1] &#39;log Lik.&#39; -111093 (df=31)

logLik_test(TRT_surprisal, train_data, train_data$TRT)
[1] -111063.7

这两个值不匹配，我不知道为什么。
我也尝试了这个问题的答案，但仍然得到两个不同的结果。欢迎任何帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653165/manually-calculate-loglikelihood-of-fitted-model</guid>
      <pubDate>Thu, 22 Aug 2024 10:00:58 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵预测概率</title>
      <link>https://stats.stackexchange.com/questions/653162/cross-entropy-predicted-probability</link>
      <description><![CDATA[在交叉熵中，预测概率分布的总和不需要为 1 吗？
我最近查看了这个视频 https://www.youtube.com/watch?v=ErfnhcEV1O8，其中提到预测概率分布的总和不为 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/653162/cross-entropy-predicted-probability</guid>
      <pubDate>Thu, 22 Aug 2024 09:21:11 GMT</pubDate>
    </item>
    <item>
      <title>MCMC 中离散参数的收敛诊断</title>
      <link>https://stats.stackexchange.com/questions/653161/convergence-diagnostics-for-discrete-parameters-in-mcmc</link>
      <description><![CDATA[我为有限混合模型生成了 MCMC 样本。这包括潜在类别，它们不仅是离散的，而且缺乏排序。
现在我正在尝试评估算法的收敛性。虽然轨迹图有意义，但我不确定自相关或 Rhat 是否有意义。对于 Rhat 统计量，我使用的是 Vehtari 等人于 2019 年新提出的统计量。它可以方便地在 R 中的“后验”包中实现。
我的第一个问题是，哪些指标（如 Rhat）适用于潜在类别等因子变量。（或者也许 Rhat 已经是了，但我忽略了一些东西。）其次，这是否可以在任何地方方便地实现。我在这个项目上的时间表有点紧张。]]></description>
      <guid>https://stats.stackexchange.com/questions/653161/convergence-diagnostics-for-discrete-parameters-in-mcmc</guid>
      <pubDate>Thu, 22 Aug 2024 09:16:18 GMT</pubDate>
    </item>
    <item>
      <title>在定义一致的情况下，如何调和统计和机器学习中偏差和效率/方差术语的混淆示例</title>
      <link>https://stats.stackexchange.com/questions/653158/how-to-reconcile-confusing-examples-of-bias-and-efficiency-variance-terminology</link>
      <description><![CDATA[如果统计学和机器学习领域确实就估计偏差和方差/效率的定义达成一致，那么如何调和 stackexchange 上讨论的术语使用中令人困惑和看似不同的问题？
据我所知，这两个领域一致认为，略有偏差且非常有效的估计量可能比无偏差且效率低下的估计量更受欢迎。因此，复杂性和准确性之间需要权衡。然而我感到困惑：

在机器学习中，低偏差通常被描述为最小化残差，或过度拟合训练数据，导致测试数据/额外样本的方差更大或拟合度更差。
在统计学中，低偏差是指估计量以较小的系统偏差近似一个感兴趣的未知参数，最终可能在额外样本/测试数据中显示出来。

例如，一个完美拟合的估计量是否可以表示 1) 内生性偏差（如统计学中），或 2) 低偏差但可能高方差（如机器学习中）？
SE 上的来源：

统计学和机器学习中的偏差是否意味着一样吗？
“偏见”一词的不同用法在统计/机器学习中
名称的含义：偏差（截距）
效率 - 偏差权衡
机器学习中的偏差和方差是什么？
两种文化，偏差
有偏估计量的方差是否总是小于无偏估计量的方差？
偏差-方差：它真的是一种“权衡”吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653158/how-to-reconcile-confusing-examples-of-bias-and-efficiency-variance-terminology</guid>
      <pubDate>Thu, 22 Aug 2024 08:11:18 GMT</pubDate>
    </item>
    <item>
      <title>样本大小对 BIC 的影响</title>
      <link>https://stats.stackexchange.com/questions/653152/effect-of-sample-size-on-bic</link>
      <description><![CDATA[BIC 由以下公式给出
$$BIC = k\ln(n)-2\ln(\hat{L}).$$
假设我有一个高斯模型，我正在拟合一个数据集——非常典型的东西。高斯模型的对数似然由以下公式给出：
$$\log(\hat{L}) = -\frac{n}{2}\log(2\pi\sigma^2)-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{2\sigma^2}.$$
可以清楚地看到，两个项都随$n$线性缩放，而 BIC 中惩罚参数数量的第一个项随$\ln(n)$缩放。这意味着，在对从大型数据集上学习的模型进行模型选择时，模型中的参数数量很快就会变得无关紧要。在这种情况下，正确的模型选择方法是什么？
此外，在实验应用中，数据点的数量通常有些随意（至少在我的用例中是这样的）。想象一下两个模型，一个简单，一个有一些冗余。虽然 BIC 可能会为较少的数据点挑选出更简单的模型，但我可以通过获取更多数据来任意增加对更复杂模型的偏好。然而，我正在研究的系统的基本原理并没有改变，而且无论你重复实验多少次，简单的模型可能都是更好的模型。如何将其与 BIC 等模型选择的统计方法相协调？]]></description>
      <guid>https://stats.stackexchange.com/questions/653152/effect-of-sample-size-on-bic</guid>
      <pubDate>Thu, 22 Aug 2024 04:50:36 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助评估给定过程是否为 m.d.s</title>
      <link>https://stats.stackexchange.com/questions/653150/help-needed-for-assessing-if-given-process-is-m-d-s</link>
      <description><![CDATA[摘自 Hayashi 的《计量经济学》：

示例 2.4（第 101 页）（非严格平稳的白噪声过程）：设 $w$ 为区间 $(0, 2\pi)$ 内均匀分布的随机变量，并定义 $z_{i} = \cos{(iw)}\ (i = 1, 2,
&gt; \ldots)$。可以证明 $\mathbb{E}(​​z_{i}) = 0$，
$\operatorname{Var}(z_{i}) = \frac{1}{2}$，且
$\operatorname{Cov}(z_{i}, z_{j}) = 0$，其中 $i \neq j$。因此 $\{z_{i}\}$
是白噪声。但显然，它不是一个独立的白噪声
过程。它甚至不是严格平稳的。
马丁格尔差分序列 (p. 104) 向量过程 $\{\boldsymbol{g}_{i}\}$ 且 $\mathbb{E}(​​\boldsymbol{g}_{i}) =
&gt; \boldsymbol{0}$ 被称为鞅差序列 (m.d.s.) 或
鞅差，如果其过去值的条件期望
也为零：$\mathbb{E}(​​\boldsymbol{g}_{i} \mid
&gt; \boldsymbol{g}_{i-1}, \boldsymbol{g}_{i-2}, \ldots) = \boldsymbol{0}$
对于 $i \geq 2.$
复习题 (第 108 页)（预测白噪声）对于示例 2.4 中的白噪声过程，$\mathbb{E}(​​z_{i}) = 0$。对于 $i \geq 2$，
$\mathbb{E}(​​z_{i} \mid z_{1})$ 是多少？提示：如果您知道 $z_{1}$ 的值，您应该能够准确预测未来。
该过程是否为 m.d.s？ [答案：否]

解决方案尝试：
$F_{z_{1}}(z) = P(z_{1} &lt; z) = P(\cos{(w)} &lt; z) = 2P(\arccos{(z)} &lt; w &lt; \pi) = 1 - \frac{\arccos{(z)}}{\pi}$;
$f_{z_{1}}(z) = \frac{d}{dz}F_{z_{1}}(z) = \frac{1}{\pi\sqrt{1 - z^{2}}}1_{(-1, 1)}{(z)}$;
$\mathbb{E}[z_{i}^{k} \mid z_{1} = z] = \mathbb{E}[\cos^{k}{(iw)} | \cos{(w)} = z] = \mathbb{E}[\cos^{k}{(iw)}| w = \arccos{(z)}] = \cos^{k}{(i\arccos{(z)})}$;
$\operatorname{Var}[z_{i} \mid z_{1} = z] = \mathbb{E}[z_{i}^{2} \mid z_{1} = z] - \mathbb{E}[z_{i} \mid z_{1} = z]^{2} = 0 \Rightarrow \operatorname{Var}[z_{i} \mid z_{1}] = 0$;
$\mathbb{E}[z_{i} \mid z_{1}] = \int_{-\infty}^{\infty}\mathbb{E}[\cos{(iw)} | \cos{(w)} = z] f_{z_{1}}(z) dz = \frac{\sin{(i\pi)}}{i\pi} = 0$ for $i = 1, 2, \ldots$;
$\mathbb{E}[z_{i} \mid z_{i-1}, \ldots, z_{1}] = \mathbb{E}[z_{i} \mid z_{1}] = 0$.
那么，这个过程不是 m.d.s. 吗？任何能发现错误或缺乏理解的帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/653150/help-needed-for-assessing-if-given-process-is-m-d-s</guid>
      <pubDate>Thu, 22 Aug 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>用于动物建模的负二项分布连续数据</title>
      <link>https://stats.stackexchange.com/questions/653148/negative-binomial-distributed-continuous-data-for-animal-modelling</link>
      <description><![CDATA[我对统计建模还很陌生。我们正在研究疾病对产奶量遗传性和可重复性的影响。根据我的理解，产奶量是连续数据（家族 = 高斯）。但是，当我们查看数据的分布时，它不是正态分布的。它遵循负二项分布。我正在使用 MCMCglmm，该包不支持负二项。我曾在某处读到，我们可以对过度分散的连续数据使用“family = “poisson””，但我不禁认为泊松只能用于计数数据。如果有人能给我一些建议，我将不胜感激。
我非常感谢您提供的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653148/negative-binomial-distributed-continuous-data-for-animal-modelling</guid>
      <pubDate>Thu, 22 Aug 2024 01:13:45 GMT</pubDate>
    </item>
    <item>
      <title>关于使用软件功效和样本量计算的问题</title>
      <link>https://stats.stackexchange.com/questions/653147/questions-about-use-software-power-and-sample-size-calculation</link>
      <description><![CDATA[我正在使用功效和样本量计算来计算两组之间跌倒风险比的样本量。 这是该软件的页面。
在独立的前瞻性设置中，我需要输入实验对象相对于对照组的相对失败风险（R）。
这里的相对失败风险是什么意思？
例如，对照组的跌倒改善率为0.3，干预组为0.5。
这里的比率是指0.5/0.3，还是（1-0.5）/（1-0.3）？

这是其文档的屏幕截图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/653147/questions-about-use-software-power-and-sample-size-calculation</guid>
      <pubDate>Thu, 22 Aug 2024 00:49:44 GMT</pubDate>
    </item>
    <item>
      <title>贝塔回归模型参数估计值的解释</title>
      <link>https://stats.stackexchange.com/questions/653143/interpretation-of-parameter-estimates-from-a-beta-regression-model</link>
      <description><![CDATA[我在 R 中使用 beta 回归模型。我将用模拟数据进行说明，以便理解解释。假设结果变量称为 outcome，其范围在 0 和 1 之间。我还有两个协变量：treatment，其有 3 个类别（A、B 和 C）和使用标准正态分布模拟的 iq。我的目标是调查结果和协变量之间是否存在关联。
用于模拟数据的 R 代码：
set.seed(1)
mydata = data.frame(outcome=runif(100),treatment = factor(sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),100,replace=TRUE)),iq=rnorm(100))

然后我们可以使用 betareg 函数拟合 beta 回归模型。
library(betareg)
library(tidyverse)
library(dplyr)
library(marginaleffects)
library(ggeffects)
library(ordbetareg)
library(knitr)
library(parameters)

model_beta = betareg(outcome~factor(treatment)+iq | factor(treatment)+iq,
data=mydata,link=&quot;logit&quot;)
summary(model_beta)

模型摘要如下。我理解有两个不同的部分：一个用于均值模型，另一个用于精度模型。由于我们使用了 logit 链接，因此估计值是对数几率估计。
第一个问题：我可以从以下输出中做出推断吗？我可以解释为“如果 iq 增加 1 个单位，则 .......
调用：
betareg(formula = consequence ~ factor(treatment) + iq | factor(treatment) + iq, data = mydata, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-2.5729 -0.5849 0.0389 0.6002 2.0709 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.02176 0.17159 -0.127 0.899 
因子(治疗)B -0.13444 0.26595 -0.506 0.613 
因子(治疗)C 0.24357 0.26630 0.915 0.360 
iq -0.19714 0.11071 -1.781 0.075 .

Phi 系数（带对数链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.99059 0.20671 4.792 1.65e-06 ***
因子(治疗)B -0.68443 0.28269 -2.421 0.0155 * 
因子(治疗)C -0.12546 0.31100 -0.403 0.6867 
iq 0.07665 0.11955 0.641 0.5214 
---
有效代码: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：8 Df 上的 6.014
伪 R 平方：0.04711
迭代次数：30（BFGS）+ 1（Fisher 评分）

但是，我也遇到了类似以下的输出（概率差异）。
 #get difference
avg_comparisons(model_beta)%&gt;%
kable()

输出如下。
|term |contrast |estimate|std.error|statistic|p.value|s.value|conf.low|conf.high|predicted_lo|predicted_hi|predicted|
|:---------|:-----------------|-----------:|---------:|-----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|
|iq |平均值(+1) | -0.0483355| 0.0264920| -1.8245311| 0.0680718| 3.8767987| -0.1002589| 0.0035879| 0.4774381| 0.4286290| 0.4774381|
|治疗 |平均值(B) - 平均值(A) | -0.0332144| 0.0656963| -0.5055740| 0.6131557| 0.7056745| -0.1619768| 0.0955481| 0.5110320| 0.4774381| 0.4774381|
|treatment |mean(C) - mean(A) | 0.0600606| 0.0653734| 0.9187318| 0.3582359| 1.4810184| -0.0680689| 0.1881902| 0.5110320| 0.5714338| 0.4774381|

第二个问题：我可以使用上述输出进行推断吗？我理解上表中的估计值是概率的差异。我可以说以下吗？

如果 iq 增加 1 个单位，则在保持其他变量不变的情况下，结果的概率会降低 4.83%。
在保持其他变量不变的情况下，治疗 = C 与治疗 = A 的结果概率增加 6%。

第三个问题：还有其他简单的解释吗？
第四个问题：如果我的数据中 结果 变量中有 0 和 1，该怎么办？我发现我们可以使用零一膨胀贝塔回归模型？任何有关 R 的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653143/interpretation-of-parameter-estimates-from-a-beta-regression-model</guid>
      <pubDate>Wed, 21 Aug 2024 21:23:33 GMT</pubDate>
    </item>
    <item>
      <title>依赖于辅助随机变量的一系列相互独立的变量</title>
      <link>https://stats.stackexchange.com/questions/653136/series-of-mutually-independent-variables-that-are-dependent-on-an-auxiliary-rand</link>
      <description><![CDATA[假设 $X_1, X_2, ... , X_n$ 是相互独立的随机变量。有一个随机变量 $C \sim U(-1,1)$，所有 $X$ 都依赖于它。我如何构造这样的 $X$，使它们无条件独立且均值为零？]]></description>
      <guid>https://stats.stackexchange.com/questions/653136/series-of-mutually-independent-variables-that-are-dependent-on-an-auxiliary-rand</guid>
      <pubDate>Wed, 21 Aug 2024 19:00:09 GMT</pubDate>
    </item>
    <item>
      <title>根据样本预测唯一观测值总数 - R</title>
      <link>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</link>
      <description><![CDATA[我有一组包含 N 个唯一元素的数据，这些元素可以重复任意次以得到 X 个总元素。
N 和 X 的值未知。
我有此数据的样本，并计算了样本总大小和样本中唯一元素总数。
为了了解样本的结构，我以一系列样本大小重复进行了子样本抽样，没有进行替换，并计算了唯一元素。
绘制在此处：

（红色 = 总样本，黑色 = 下采样。每个可见黑点实际上是 20 个重复）。
由此，我想在 R 中拟合一条超出 x 的观测值的曲线，以预测 y 的最大值（例如：数据集中唯一元素的总数，N）。
样本中的元素总数：185718411
样本中的唯一元素总数：51588754
下采样数据：
x=c(1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08,
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08 , 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 
1.75e+08, 1.75e+08) y=c(8879407L, 8882853L, 8879146L, 8879963L, 8879973L, 8877565L, 8879535L, 8879441L, 8881377L, , 8880186L, 8879063L, 8881647L, 8879511L, 8881403L, 8878382L, 8879544L, 8881002L, 8880604L, 8880240L, 18927193L, 18924435L、18923731L、18920494L、18923974L、18923199L、18923360L、18923648L、18923131L、18922984L、18926592L、18924276L、1 8923680L、18923344L、18926252L、18921600L、18924428L、18928711L、18925935L、18922126L、30157610L、30155501L、30158640L、 30159612L, 30158025L, 30157679L, 
30154834L, 30159222L, 30160493L, 30157565L, 30158045L, 30157807L, 
30155821L, 30155840L, 30158622L, 30159742L, 30161088L, 30158046L, 
30159089L, 30155885L, 37409984L, 37400952L, 37402514L, 37408682L, 
37404248L, 37403547L、37401649L、37407739L、37405915L、37407328L、37402003L、37408206L、37398749L、37406762L、37401890L、37406383L、3 7404693L、37409054L、37403259L、37405316L、42387997L、42386810L、42386963L、42390976L、42390837L、42387186L、42387391L、 42385265L、42383010L、42392749L、42390451L、42390822L、42389636L、42389803L、42385593L、42390989L、42386302L、42389008L、4 2390049L、42386454L、45991832L、45992758L、45991351L、45993242L、45993277L、45990663L、45992366L、45992018L、45994867L、 45996211L、45992212L、45991838L、45991638L、45992517L、45993411L、45993444L、45992878L、45993934L、45993354L、45993045L、4 8707677L、48710261L、48705408L、48705354L、48706640L、48708658L、48708765L、48708926L、48707986L、48709516L、48705780L、 48708451L, 48707766L, 48711356L, 48708200L, 48707612L, 
48708961L, 48707509L, 48708770L, 48706288L, 50821205L, 50820451L, 
50819444L, 50821245L, 50821327L, 50820153L, 50819789L, 50821493L, 
50821043L, 50819115L, 50821689L, 50821538L, 50821014L, 50819974L, 
50821665L, 50819515L, 50820771L, 50819985L, 50820110L, 50819491L, 
51588754L)

我认为曲线的形状符合渐近回归，我研究过各种拟合方法，但我认为这并不是我想要的。
我知道对样本进行下采样并不等同于重复采样 - 但这是我所能获得的全部。因此，我必须基于（有效）假设，即考虑到样本的大小和重复的一致性，样本可以代表整个数据集。
我想对许多不同的数据集重复此操作，因此正在寻找一种可以一致应用的方法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</guid>
      <pubDate>Wed, 21 Aug 2024 14:21:44 GMT</pubDate>
    </item>
    <item>
      <title>当风险差异如此容易解释时，为什么 Cohen's h 对于比较比例有用？</title>
      <link>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</link>
      <description><![CDATA[当风险差异如此易于解释时，为什么 Cohen&#39;s h 可用于比较比例？
我认为这与标准化不同比例量级的比较有关（例如，当 $p_{1}$ 和 $p_{2}$ 分别接近 0、接近 0.5 和接近 1 时，$p_{1}-p_{2}$）。
但我很难在脑海中将其形式化。]]></description>
      <guid>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</guid>
      <pubDate>Wed, 21 Aug 2024 05:46:44 GMT</pubDate>
    </item>
    <item>
      <title>采用 RSM 的中心复合设计-重复次数？</title>
      <link>https://stats.stackexchange.com/questions/653066/central-composite-design-with-rsm-number-of-replicates</link>
      <description><![CDATA[我对实验设计还不是很熟悉，现在我想结合中心复合设计进行响应曲面建模。
我读过几次，中心点应该重复，原因有很多，其中之一是估计纯实验误差。我对此有两个问题：
(1) 为什么只应重复中心点？
(2) 我可以想象，对 (1) 的（或一个）答案可能是“因为重复所有设计点会很耗时”。假设我的 CCD 有 27 个点，我可以重复所有点 X 次。我该如何进行响应曲面模型拟合？我应该尝试将模型拟合到 27*X 个数据点，还是应该先对每个数据点取 X 次重复的平均值，然后将我的模型拟合到 27 个（平均）数据点？]]></description>
      <guid>https://stats.stackexchange.com/questions/653066/central-composite-design-with-rsm-number-of-replicates</guid>
      <pubDate>Tue, 20 Aug 2024 16:48:03 GMT</pubDate>
    </item>
    </channel>
</rss>