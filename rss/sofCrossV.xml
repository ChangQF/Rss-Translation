<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 12 Dec 2023 18:17:08 GMT</lastBuildDate>
    <item>
      <title>迭代训练 ARIMA 模型</title>
      <link>https://stats.stackexchange.com/questions/633734/iteratively-training-an-arima-model</link>
      <description><![CDATA[上下文
为了便于论证，假设我有一个时间序列数据集 $X_t$，它是平稳的，表现出很强的自相关性，并且是 ARIMA 的良好候选者 -类型模型。
我对该时间序列变量进行了一系列观察，$(X_{1,0},X_{1,1},...X_{1,N} )$ 在时间上分布均匀且没有间隙。
我还对该时间序列变量进行了第二组观察，来自不同且不重叠的时间段，$(X_{2,0},X_{2, 1},...X_{2,N})$，例如 $t$ 在  的时间$X_{2,0}$ 远大于 $X_{1 处的时间 $t$ ,N}$。
$X_{1,N}$ 和 $X_{2,0}$ 之间的时间序列span&gt; 是不可观察的。
我预计相同的 ARIMA 模型非常适合这两个系列（因为它只是相同的时间序列，从不同的起点测量）。
问题
在 Python 中，如何同时将 ARIMA 模型拟合到两个观测值系列？如果第三个系列 $(X_{3,0},X_{3,1},...X_{3,N})$ 可用如何在给定新数据的情况下提高 ARIMA 模型的拟合度？
我在网上看到了许多不同的方法，但我并不相信其中任何一种。
他们似乎建议将系列连接在一起并将它们视为单个时间序列，我认为这不是一个好的选择，因为该系列不是连续的。
我见过的替代方法是使用像 pmdarima 这样具有 .update() 方法的库。我不清楚 pmdarima 是否只是将新系列连接到旧系列上，即使没有，它似乎只是使用旧参数作为起点将模型重新拟合到新系列，而不是拟合整套观察结果。
我可能在这里遗漏了一些东西，这似乎应该是一个常见问题，应该很容易解决。]]></description>
      <guid>https://stats.stackexchange.com/questions/633734/iteratively-training-an-arima-model</guid>
      <pubDate>Tue, 12 Dec 2023 17:45:48 GMT</pubDate>
    </item>
    <item>
      <title>中介分析未产生预期结果，可能是多重共线性问题的结果</title>
      <link>https://stats.stackexchange.com/questions/633733/mediation-analysis-not-producing-expected-results-probably-as-consequence-of-mu</link>
      <description><![CDATA[我正在使用 PROCESS 宏进行基本的中介分析，变量 X、M 和 Y。所有都是连续的。我从理论上知道X和M，以及M和Y分别应该有关系。我从理论中确信 X 导致了 M，而不是相反。事实上，在我的数据中，当我进行常规线性回归时，路径 a、b 和 c 都很重要。 3 条路径的标准化 Beta 值分别为 0.76、-0.17 和 0.16。
这让我预计，当我进行中介分析时，路径 c&#39; 或 b 中至少有一个应该具有显着关系。然而，这种情况并非如此。在PROCESS结果中，直接和间接结果都不显着。我怀疑 X 和 M 的相关性非常强（非标准化 B=0.76），路径 b 和路径 c&#39; 都因此被抑制。路径 ab 比路径 c&#39; 大很多，这确实表明中介程度很高。不过，由于路径 ab 并不重要，所以我觉得这个结果没有任何价值。
我的解释正确吗？有什么办法可以解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633733/mediation-analysis-not-producing-expected-results-probably-as-consequence-of-mu</guid>
      <pubDate>Tue, 12 Dec 2023 16:57:26 GMT</pubDate>
    </item>
    <item>
      <title>判断两个预测值是否相同的正确测试是什么？</title>
      <link>https://stats.stackexchange.com/questions/633732/what-is-the-correct-test-to-see-if-two-predicted-values-are-identical</link>
      <description><![CDATA[我的关键变量 (v) 被定义为回归中 x=0 的（估计）点（但是，在数据集中无法观察到 x = 0）。
我有 2 个回归，形式均为 y = b_0 + b_1x_1 + e。
在 R 中，我像这样运行它们： lm_robust(estimate ~ x, data = data1,weights = 1/std.error^2, se_type = &quot;classical&quot;)
和
lm_robust(估计 ~ x, data = data2, Weights = 1/std.error^2, se_type = “classical”) .
（是的，它们都是加权回归。）
它们来自不同的数据生成过程，我存储在2个数据帧中。对于它们两个，我通过设置 x=0 来计算 v。
正确的双边测试是什么，以查看两个数据生成过程中的 v 是否彼此不同。
如果我不是测试一个 v 与另一个 v，而是从相同的数据生成过程生成 v 的多个估计值，并报告平均值，那么答案（正确的测试）会如何变化。然后，我会对两个不同的 DGP 都有两个mean(v)，并且想要测试这两个组之间生成的 v 均值是否彼此不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/633732/what-is-the-correct-test-to-see-if-two-predicted-values-are-identical</guid>
      <pubDate>Tue, 12 Dec 2023 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>获取 LASSO/L1 惩罚回归模型中确定的顶级预测变量的 R^2</title>
      <link>https://stats.stackexchange.com/questions/633730/obtain-the-r2-of-just-the-top-predictors-identified-in-a-lasso-l1-penalized-re</link>
      <description><![CDATA[我使用 tidymodels 和 10 倍交叉验证使用 L1 惩罚回归开发了一个模型，并确定了解释测试数据中大约 87% 方差的预测变量。我需要惩罚将不重要的预测因子缩放为零。然而，在现场，顶级预测变量被认为比我所看到的更加黯然失色，因此我想报告仅包含顶级预测变量的模型的 R²。
通过将简单线性模型的预测与测试集中真实测量中包含的关注预测变量进行比较，我可以分别获得主要预测变量的 R²。
但是我可以假设那个简单得多的模型的 R² 实际上与惩罚回归相当吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633730/obtain-the-r2-of-just-the-top-predictors-identified-in-a-lasso-l1-penalized-re</guid>
      <pubDate>Tue, 12 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>在一个 GAM 模型中混合线性和非线性回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/633728/mixing-linear-and-nonlinear-regression-in-one-gam-model</link>
      <description><![CDATA[我使用随机森林和GAM模型进行预测。使用 GAM 时，我在 X 次迭代的 for 循环中运行它，每次都使用不同的测试集。每次迭代使用线性回归 (glm.fit) 运行一次，然后使用非线性回归 (GCV.Cp)。
在评估模型时，将它们视为 2 个模型（随机森林和 GAM）或者可能将它们视为 3 个模型（随机森林、线性 GAM 和非线性 GAM）在统计上是否正确？
我希望我的问题很清楚并且不是太基本......]]></description>
      <guid>https://stats.stackexchange.com/questions/633728/mixing-linear-and-nonlinear-regression-in-one-gam-model</guid>
      <pubDate>Tue, 12 Dec 2023 15:28:56 GMT</pubDate>
    </item>
    <item>
      <title>多重插补数据中的变量选择</title>
      <link>https://stats.stackexchange.com/questions/633727/variable-selection-in-multiply-imputed-data</link>
      <description><![CDATA[我有一个包含大约 1800 个观察值的数据集，我正在尝试拟合一个多变量逻辑回归模型（250 个案例，1550 个对照）。有 19 个协变量（连续变量、有序变量和分类变量的混合），其中 P &lt; 1。 0.2 单变量回归，我计划将它们包含在初始完整模型中。大多数协变量都存在低中度缺失数据 (1-10%)，而一个协变量 (70%) 存在高缺失数据，因此我使用 R 中的 mouse 包创建了 70 个多重插补数据集。
这是我第一次对多重插补数据进行建模。我之前曾使用过 Hosmer 和 Lemeshow 所描述的有目的地选择协变量，但我不确定如何在多重插补数据中执行此操作，因为我认为不可能使用部分似然比检验来比较拟合。在有目的的选择过程的每个阶段使用 fit.mult.impute 是否合理（我理解它适合每个估算数据集中的模型，然后使用鲁宾规则组合系数）？是否有最佳方法来评估和比较每个模型与上一个模型的拟合度？
是否有其他选择程序可能更简单或为我的数据产生更好的结果？我见过一个名为“miselect：多重插补数据的变量选择”的包，它提供了多重插补数据中的 LASSO 和弹性网络回归的程序。这值得探索吗？
非常感谢您的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/633727/variable-selection-in-multiply-imputed-data</guid>
      <pubDate>Tue, 12 Dec 2023 14:51:08 GMT</pubDate>
    </item>
    <item>
      <title>有几个基于 R 因果影响进行因果影响分析的 python 库，但我应该使用哪一个？</title>
      <link>https://stats.stackexchange.com/questions/633725/several-python-libraries-for-causal-impact-analysis-based-on-r-causal-impact-but</link>
      <description><![CDATA[我的问题：我喜欢 R 中的 Google causalimpact 包，并且想在 Python 中做同样的工作。我应该使用哪个包？
我看到的第一个库是 Google 的 R 因果影响包的移植，也许是第一个：

pycausalimpact 0.1.1。但是存储库已经消失了（但是
网上还有medium.com教程，可以安装Python包）。

有更积极的开发：

causalimpact 0.2.6。：此案例中有一个活的社区。有趣的是它指的是上面的那个。

但是还有第三个：

tfp-causalimpact 更接近 Google，但仍不是官方的。我注意到它是基于 TensorFlow 问题。型号，但我看不出有什么区别。

我尝试搜索白皮书进行比较，但没有这样的论文。我是这个主题的新手，所以在我的脑海中形成一幅图画是很有挑战性的。]]></description>
      <guid>https://stats.stackexchange.com/questions/633725/several-python-libraries-for-causal-impact-analysis-based-on-r-causal-impact-but</guid>
      <pubDate>Tue, 12 Dec 2023 14:09:43 GMT</pubDate>
    </item>
    <item>
      <title>是否有一种类似于多元回归且不需要线性的技术？</title>
      <link>https://stats.stackexchange.com/questions/633723/is-there-a-technique-similar-to-multiple-regression-which-does-not-require-linea</link>
      <description><![CDATA[背景：
我们有细胞的生物基因表达数据（来自单细胞实验）。因此，数据的形式是基因*细胞矩阵，其中每个值是特定细胞中特定基因的表达。
我正在寻求建立能够“协同”的基因。与细胞的另一个（连续）属性（每个细胞的甲基化得分）。
第一个选择的测试（一个明显且简单的测试）是斯皮尔曼相关性测试。可以对每个基因单独运行，然后只能推导出相关的基因。
然而，我们发现有一个技术变量（细胞质量的测量）也与两者相关。它与甲基化评分和基因表达相关（至少对于一些有趣的基因而言）。
明显的第二个测试选择似乎是执行多元回归，其中有两个变量
甲基化得分 ~ 基因表达 + 细胞质量
如果我理解正确的话，它应该准确地给出基因表达对感兴趣分数的影响，并控制细胞质量。
问题
我没有理由假设基因表达和感兴趣的得分（甲基化）之间的关系必然是线性的......
问题
是否存在一种广泛使用的统计方法，可以在两个变量之间的关系非线性时建立该关系，并控制第三个变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/633723/is-there-a-technique-similar-to-multiple-regression-which-does-not-require-linea</guid>
      <pubDate>Tue, 12 Dec 2023 13:52:16 GMT</pubDate>
    </item>
    <item>
      <title>利用观察面板数据进行因果推断的贝叶斯方法</title>
      <link>https://stats.stackexchange.com/questions/633722/bayesian-methods-for-causal-inference-with-observational-panel-data</link>
      <description><![CDATA[在尝试利用观察面板数据进行因果推断时，贝叶斯推断工具包的综合程度如何？
我可以看到一个简单的应用程序，结合了固定效应或 ADL 模型，但这些模型有详细记录的问题。
我还了解贝叶斯应用可用于双重差分和合成控制，但每种方法通常都适合非常特定的设计（DID 的并行趋势、用于合成控制的一个/几个处理单元、一个（最好）两者的治疗时间等）
我越来越喜欢的两种方法是面板匹配和边际结构模型。然而，据我所知，{PanelMatch} 包的开发人员尚未为其方法实现贝叶斯框架。此外，贝叶斯边际结构模型的开发似乎正在作品&lt; /a&gt;，但尚未完成。
假设我有 N &gt; 50个单位且T&gt;治疗状态可能随时间变化的 20 个时间段，我想在贝叶斯框架下进行操作，尝试估计治疗的因果效应。在这种情况下人们会做什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/633722/bayesian-methods-for-causal-inference-with-observational-panel-data</guid>
      <pubDate>Tue, 12 Dec 2023 13:41:40 GMT</pubDate>
    </item>
    <item>
      <title>如何比较二元或分类变量对组间二元目标变量的影响？</title>
      <link>https://stats.stackexchange.com/questions/633718/how-do-i-compare-the-effect-a-binary-or-categorical-variable-has-on-a-binary-tar</link>
      <description><![CDATA[我有一个包含三个级别的数据集：

最底层有新闻文章
在中层，新闻文章属于新闻媒体
在最高级别，新闻媒体按类别变量进行分组

每篇新闻文章只能属于一个新闻媒体，每个新闻媒体只能属于一个高层组。无论社交媒体上是否提及新闻文章，目标变量都是二元的。在新闻文章级别，我们有一个独立的二元特征（例如，文章是否关于某个主题）。新闻媒体的文章数量不同（有的只有 1 篇，有的有几千篇）。高层团体拥有不同数量的新闻媒体（有的约 50 个，有的约 200 个）。
我有兴趣 (1) 评估新闻文章级别的二元主题变量是否对文章被提及的可能性有影响。此外，我有兴趣 (2) 评估主题变量对文章被提及的可能性的影响是否取决于高级组/高级组之间的差异。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

组
新闻媒体
新闻文章
主题
提及


&lt;正文&gt;

1
一个
1A1
1
1


1
一个
1A2
0
0


1
B
1B1
1
0


2
C
2C1
1
1


2
C
2C2
1
0


2
C
2C3
0
0




到目前为止，我们的想法是使用广义线性混合模型来解释数据和二元目标变量的层次性质。 GLMM 在方法论上是否适合这些研究问题？如果是，回归模型会是什么样子（例如，带有 lmer 的 r 型模型）？]]></description>
      <guid>https://stats.stackexchange.com/questions/633718/how-do-i-compare-the-effect-a-binary-or-categorical-variable-has-on-a-binary-tar</guid>
      <pubDate>Tue, 12 Dec 2023 13:34:12 GMT</pubDate>
    </item>
    <item>
      <title>C 统计量和测量多级逻辑回归中的上下文效应</title>
      <link>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</link>
      <description><![CDATA[我有一个两级逻辑回归模型，其结果是“InfectedqPCR” （通过 qPCR 确定是否感染疟原虫）在个体水平上。
我有一系列个人和家庭层面的变量。
家庭是分组结构。
我一直在阅读 Austin 和 Merlo (2017) 的“多级逻辑回归分析中的中级和高级主题”生物统计学教程 - 医学统计 - 关于使用c-统计量作为一般情境效应大小的度量。
按照他们的方法，我尝试解释以下三个模型的 c 统计输出：
model1 &lt;- glm(Infected_qPCR ~ Sex + Age_Band_Years, family=“二项式”, data=Data_Model_In_Adults)
Cstat(x = 预测(模型1),
      resp = model.response(model.frame(model1))) # 0.653
              # 仅包含固定效应 - 无随机效应结构
Cstat(x = 预测(Mod_MAd_Indi),
      resp = model.response(model.frame(Mod_MAd_Indi))) # 0.823
              # 包含相同的固定效应（Sex 和 Age_Band_Years）和家庭聚类随机效应
Cstat(x = 预测(Mod_MAd_Comb_Vil),
      resp = model.response(model.frame(Mod_MAd_Comb_Vil))) # 0.771
              # 包含相同的个体固定效应（Sex和Age_Band_Years）和各种家庭因素以及家庭聚类随机效应

因此，据此，我认为 c 统计量从仅具有固定效应且无随机效应结构的 model1 到包含随机效应结构的 Mod_MAd_Indi 的变化为 0.17。
在 Austin 和 Merlo 的论文中，他们的示例的 c 统计量发生了 0.004 的变化，这表明“一般上下文效应较弱”。
问题 1：
那么，如果 0.004 很弱，那么如果我的上下文效果是 0.17，我能说什么？这是中等的情境效应还是强烈的效应？有这方面的任何指南或参考吗？
问题2：
Austin 和 Merlo 的论文还强调，“向包含特定簇随机效应的模型添加簇特征不能增加仅包含特定簇随机效应的模型的 c 统计量。”那么，c 统计量的 0.17 变化是否是最大可能变化（Austin 和 Merlo 所说的“上限”）？这就是我添加家庭变量 (Mod_MAd_Comb_Vil) 导致 c 统计量较低的原因吗？它可能相同或更低，但绝对不会更高 - 这就是奥斯汀和梅洛的意思吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</guid>
      <pubDate>Tue, 12 Dec 2023 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>线性回归的性能比（线性）神经网络好得多[关闭]</title>
      <link>https://stats.stackexchange.com/questions/633715/linear-regression-performs-considerably-better-than-linear-neural-network</link>
      <description><![CDATA[我查看了 stats.exchange 上的其他问题，但找不到类似的问题，&lt;a href=&quot;https://stats.stackexchange.com/questions/582202/neural-network-vs-linear-regression ”这篇文章&lt;/a&gt;可能是最接近的。
由于只有一层且没有激活函数的（全连接）神经网络是线性回归，即使它是用某种形式的梯度下降进行训练的，我预计其性能与普通执行的线性回归相对相似最小二乘法。但就我而言，它们的差异高达 2 或 3 倍！这是可以预料的吗？
一些背景知识：
我正在使用神经网络来预测从沿海某些点到其他点的海浪高度。离岸越远（如果您在计算中不包括某些物理相互作用），问题就越线性。这就是为什么我开始将我的结果与 (OLS) 线性回归进行比较，并发现它优于我最好的神经网络（大约 2 倍）。一开始这令人震惊，但考虑到大多数领域的强线性关系，这在某种程度上是可以解释的。然而，在分析误差时，我可以看到线性回归在非线性最强的海岸附近表现较差，但如果我仅针对该区域训练（非线性）神经网络，它的表现仍然比简单的神经网络差线性回归！
但我还想指出，它们的神经网络表现一点也不差。相比之下，结果非常有希望，令人惊讶的是，即使在设置非线性多于线性的地方，它们也能如此轻松地表现出色。
数据集：
输入的形状为 (2918, 69)，其中 80% 用于训练，20% 用于验证。每行由域中某个位置的波高组成。
输出的形状为 (2918, 3773)，因此神经网络和线性回归正在执行超分辨率。同样，每行都包含域中（不同）位置的波高。
神经网络架构
如上所述，我尝试使用 OLS 进行正常线性回归。一个简单的神经网络，具有一层且没有激活函数（因此又是线性回归），具有 SGD 或 ADAM，我在其中训练了不同的学习率和很多很多时期（最多 5000 个）。我尝试的批量大小是 16、32 和 512（只是为了差异很大）。每批次后权重都会更新。
另外两个网络对于这个问题来说并不是太重要，因为我想更多地了解线性方法之间的差异，但我使用其中之一：1.具有多个隐藏层（范围从 2 到 2）的全连接神经网络5）具有不同的单元大小（128 到 2056）和 ReLU 激活。
2. 一个图神经网络，对输入执行多个切比雪夫卷积，然后将其上采样到输出大小，并执行 2-3 个额外的卷积。
两个非线性网络都表现良好并且大致相等，但线性回归仍然是最好的。
问题

即使理论上是相同的，线性神经网络的性能是否会比线性回归差很多？

即使在设置大部分是非线性的情况下（即使存在一些线性区域），线性回归是否也能优于神经网络


我尝试过的
由于它看起来像是收敛问题或错误，我尝试了不同的学习率、不同的优化器（带动量和不带动量的 SGD、ADAM）、不同的损失函数（l1 和 l2 损失），并在 2 个不同的库（pytorch 和 tensorflow）中实现了所有内容，具有不同的神经网络架构（全连接和图神经网络）。我尝试标准化和不标准化我的数据，仍然存在很大差异。我让所有内容也运行多个纪元
是否有一些明显的事情我错过了或者我可以尝试？结果令人惊讶吗？特别是OLS线性回归和梯度下降线性回归之间的差异？
我知道没有与此问题相关的代码或图像，但我希望整体问题设置仍然清晰。非常感谢您的回答！]]></description>
      <guid>https://stats.stackexchange.com/questions/633715/linear-regression-performs-considerably-better-than-linear-neural-network</guid>
      <pubDate>Tue, 12 Dec 2023 12:08:42 GMT</pubDate>
    </item>
    <item>
      <title>建立投资回报率 (RoI) 的预测模型</title>
      <link>https://stats.stackexchange.com/questions/633712/building-a-predictive-model-for-the-return-on-investment-roi</link>
      <description><![CDATA[我在一家公司工作，该公司投资于不同商店的应用广告。我有一个数据集，其中包含列日期、应用程序、投资、收入、可视化 以及其他一些。因此，对于给定的日期和给定的应用程序，我知道那天花了多少钱（投资），以及那天该应用程序产生了多少钱（收入） ）。我还知道有多少人查看了该添加（可视化）。每个应用程序可用的观察次数（即天数）取决于。对于一个应用程序，我有去年的信息，但也许对于另一个最近开始投资的应用程序，我只有最近 15 天的信息。
根据这些信息，我计算了投资回报率（基本上是（收入 - 投资）/投资）。我认为这个指标只有在我查看聚合数据时才有意义，这意味着，在某一天，我使用有关当天和之前所有天的总和的信息。
综上所述，我想要的是构建一个预测模型，对于特定应用程序可以给出下周投资回报率的估计。我不确定如何做到这一点。让我烦恼的是：

我考虑过使用一些时间序列方法，但数据没有平稳性，也没有明显的趋势。收入很大程度上取决于投资，因此如果投资增加，收入就会增加。但对于所有应用程序来说，它不会以相同的方式增加。
我考虑过在一天的投资​​回报率与前一周的投资、收入和可视化之间使用线性回归模型之类的模型。但令我担心的是，通过考虑每天的汇总数据，我的观察结果根本不是独立的。
我的老板说我不应该使用数据的总聚合，但我应该考虑 1 个月的聚合，这意味着我每天都会计算上个月的总和。但我认为这没有任何意义。如果有大量投资，并且收入需要（比如说）两个月才能通过该投资反映，则 1 个月的汇总将无法反映这一点。
此外，roi 是一个介于 -1 和无穷大之间的值。所以我不确定在这里尝试使用回归技术是否有意义。

我不知道如何面对这个项目，任何想法都非常受欢迎。]]></description>
      <guid>https://stats.stackexchange.com/questions/633712/building-a-predictive-model-for-the-return-on-investment-roi</guid>
      <pubDate>Tue, 12 Dec 2023 11:21:52 GMT</pubDate>
    </item>
    <item>
      <title>这个混合随机变量的方差是多少？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/633681/what-is-this-hybridmixed-random-variable-s-variance</link>
      <description><![CDATA[X ∼ 均匀(a,b)，a]]></description>
      <guid>https://stats.stackexchange.com/questions/633681/what-is-this-hybridmixed-random-variable-s-variance</guid>
      <pubDate>Tue, 12 Dec 2023 04:52:23 GMT</pubDate>
    </item>
    <item>
      <title>混合数据类型的评估者间可靠性？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/633652/inter-rater-reliability-for-mixed-data-types</link>
      <description><![CDATA[我对统计学非常陌生，我需要帮助确定问卷的最佳相互可靠性测试。我的调查问卷将由三位评估者进行评估。我只是提供我的调查问卷样本及其外观：
dat = data.frame(rater1 =
                   c(3,3.2,4,4,2.4,3,&#39;Y&#39;),
                 评分者2 =
                   c(4,1,3,4,3,2,&#39;N&#39;),
                 评分者3 =
                   c(1,1,4,1,2,1,&#39;Y&#39;)
）

评估混合数据类型调查问卷相互可靠性的最佳方法是什么？我怎样才能知道最大的分歧来自哪里？例如，它是#1，其中rater1=3、rater2=4、rater3=1。我怎么知道这是导致最大差异的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/633652/inter-rater-reliability-for-mixed-data-types</guid>
      <pubDate>Mon, 11 Dec 2023 20:10:17 GMT</pubDate>
    </item>
    </channel>
</rss>