<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 04 Dec 2023 03:15:32 GMT</lastBuildDate>
    <item>
      <title>当一种密度难以处理时，是否存在一种引导过程来量化两种密度的相似性？</title>
      <link>https://stats.stackexchange.com/questions/632978/is-there-a-bootstrapping-process-to-quantify-similarity-of-two-densities-when-on</link>
      <description><![CDATA[我有两个密度，$p, q$ 和样本空间 $\mathbb{R}^n$&lt; /span&gt;，我们可以假设都是 $p,q&gt;0$ （完全支持）。我可以从 $p$ 进行计算和采样。我可以计算 $q$ 直到一个常数，但无法从 $q$ 中采样。 （一个一般的例子是 $q(t) = \exp(f(t))/Z$，我们无法计算归一化常数 $Z = \int_t \exp(f(t))dt$ 但我们可以计算 $f(t)$ 因此可以计算 $q(t)Z = \exp(f(t))$。
我的目标是看看是否$p=q$，或者更具体地（严格地）证明$\|p-q\|_1$ 或等效于 $P-Q$ 的总变体。我对密度上的其他相似函数持开放态度，例如 KL 散度或 $\ell(2)$ 距离或 ..
是否有适用于这种情况的引导过程？
我的直觉是，我们可以计算任何 $a 的 $q(a)/q(b)$， b$ （$Z$ 取消！）。此外，所有此类比率的集合 ($\{q(s)/q(t)\}$) 应唯一定义 $q$。如果是这样，我们应该有足够的信息来获得 $q, p$ 之间的量化相似性。因此，这引导我进入一个过程：示例 $t_i\sim p, i = 1, ..., N$。然后我们确实可以计算并比较 $q(t_i)/q(t_j)$ 与 $p(t_i)/p (t_j)$ 为 $1\leq i \leq j \leq N$。但我一直不知道如何将其转化为严格的量化相似度。]]></description>
      <guid>https://stats.stackexchange.com/questions/632978/is-there-a-bootstrapping-process-to-quantify-similarity-of-two-densities-when-on</guid>
      <pubDate>Mon, 04 Dec 2023 01:12:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在 2x2 因子实验 (Minitab) 中调整区组？</title>
      <link>https://stats.stackexchange.com/questions/632977/how-to-adjust-blocks-in-a-2x2-factorial-experiment-minitab</link>
      <description><![CDATA[我目前正处于一项实验的规划阶段，该实验涉及 2 个因素，每个因素有 2 个水平，每个组合有 3 次重复，最终进行 12 次实验。在 Minitab 中，因子设计中建议的区组编号为 1、2、3 和 6。
然而，实际限制限制我每天只能在一个区块中进行 3 个实验。这需要扩展区块以涵盖三天的实验，总共有 4 个区块。
我正在向社区寻求指导，以了解手动将块数从 3 调整到 4 在统计上是否可以接受。我想确保我没有忽略实验设计中的任何基本概念。
任何见解或建议将不胜感激！
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/632977/how-to-adjust-blocks-in-a-2x2-factorial-experiment-minitab</guid>
      <pubDate>Mon, 04 Dec 2023 01:05:59 GMT</pubDate>
    </item>
    <item>
      <title>审查的 gee 模型</title>
      <link>https://stats.stackexchange.com/questions/632976/censored-gee-model</link>
      <description><![CDATA[有谁知道是否可以拟合具有自回归相关结构的左截尾 GEE 模型？
我知道censReg可以处理左删失重复数据，但我不确定是否可以指定自回归相关结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/632976/censored-gee-model</guid>
      <pubDate>Mon, 04 Dec 2023 00:07:18 GMT</pubDate>
    </item>
    <item>
      <title>如何确定足够的功效所需的样本量来比较混合模型中固定效应的水平？</title>
      <link>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</link>
      <description><![CDATA[我对受试者内部实验进行了一项试点研究，其中感兴趣的固定效应是分类的，有 4 个级别。研究问题涉及比较该 IV 的哪些水平在统计上可以被视为相似与不同。
这是一个简化的示例。假设对于 A、B、C、D 级，这些条件下的平均反应时间为 1000 毫秒、1100 毫秒、1150 毫秒和 1175 毫秒。通过轮换参照组，我们确定：(1) A B 和 C 水平在统计上均不同，(2) D 水平与 A 和 B 不同，但 (3) C 和 D 相当。
如上所述，我有试点数据，并且也很乐意进行基于模拟的分析。但我发现的所有工具似乎都在告诉我检测固定效应效果所需的样本量，这显然不足以实现我的实际目标。例如，simR 确信我只需要大约 12 名参与者即可获得 80% 的功效，尽管效果大小不同且每个条件的试验规模较小 (30)。
我也尝试过仅基于数据子集运行 simR（例如，仅比较级别 2 和 3 或 3 和 4），但当然这是非常有缺陷的（例如，级别 3 和 4 突然变得显着不同） ）此外，我知道我需要更大的样本来解释实际分析中的额外水平。所以这种方法没有真正的实用性。
请注意，在我的领域，我使用混合效应模型是一个强烈的惯例，这也是项目预注册分析计划中记录的内容。如果可能的话，请不要只是告诉我切换到[在此处插入您最喜欢的分析方法]会更容易。]]></description>
      <guid>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</guid>
      <pubDate>Sun, 03 Dec 2023 23:31:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有统一潜变量的吉布斯采样？</title>
      <link>https://stats.stackexchange.com/questions/632973/how-to-sample-using-gibbs-with-a-uniform-latent-variable</link>
      <description><![CDATA[我尝试使用吉布斯从比例分布中进行采样$f_{Z}(z)$：
\begin{align*}
 f_{Z}(z) \propto e^{-z}\left(1-e^{-z}\right)^4, \quad z &gt;0
\end{对齐*}
使用联合 $f_{Z,\textbf{U}}(z,\textbf{u})$
$$
f_{Z,\textbf{U}}(z,\textbf{u}) \propto e^{- z} \prod_{i=1}^4 I_{\left(e^{-z}, 1\右)}\左(u_i\右)
$$
与 $U \sim U(0,1)$。我发现 $p(U_i|Z,U_{-i}) \sim U(e^{-z},1)$，但我找不到 &lt; span class=&quot;math-container&quot;&gt;$p(Z|\textbf{U})$。我应该如何从 $p(Z|\textbf{U })$？它取决于所有 $u_i$ 值？我被困在这个问题上了。]]></description>
      <guid>https://stats.stackexchange.com/questions/632973/how-to-sample-using-gibbs-with-a-uniform-latent-variable</guid>
      <pubDate>Sun, 03 Dec 2023 23:16:57 GMT</pubDate>
    </item>
    <item>
      <title>使用MCMC导出的后验来设计变分逼近函数</title>
      <link>https://stats.stackexchange.com/questions/632970/using-mcmc-derived-posterior-to-design-variational-approximation-function</link>
      <description><![CDATA[我正在尝试使用概率编程语言 Pyro 来拟合一个估计某些参数的协方差的分层模型。
在模拟实验中，我看到 MCMC 生成了很好的后验样本，可以很好地估计地面真实协方​​差。然而，为了将模型扩展到高维数据，我试图设计一个变分近似（指南）来实现随机变分推理（SVI）。标准平均场近似不能产生正确的估计，因此我认为它们不够复杂，无法描述后验。
为了了解哪些潜在变量交互作用包含在近似值中，在 MCMC 生成的后验样本中寻找这些交互作用并将其推广到高维设置是否有意义？
换句话说，假设我研究了 MCMC 后验样本，并观察到变量 $A$ 和 $B$，我可以在变分近似中强加同样的关系。
我从未听说过这种方法，因为通常我知道人们倾向于使用 SVI 来获得快速近似拟合，然后使用 MCMC 进行细化，而这将是相反的过程。]]></description>
      <guid>https://stats.stackexchange.com/questions/632970/using-mcmc-derived-posterior-to-design-variational-approximation-function</guid>
      <pubDate>Sun, 03 Dec 2023 22:12:58 GMT</pubDate>
    </item>
    <item>
      <title>更换不同颜色球的瓮问题</title>
      <link>https://stats.stackexchange.com/questions/632967/urn-problem-with-replacement-of-a-ball-of-diferent-color</link>
      <description><![CDATA[一个瓮包含​B 个黑球和​W 个白球。随机抽取一个球，并将相反颜色的球放入瓮中。让瓮装满相同颜色的球所需的抽奖次数的平均值和方差是多少？
在第一次抽奖中，P(black) = B/(B+W) 和 P(white) = W/(B+W)。
如果第一次抽牌是黑球，我们现在有 W+1 白球和 B-1 黑球。
如果第一次抽牌是白球，我们现在有 W-1 白球和 B+1 黑球。
即使是 W=2 和 B=2 的简单情况我也感到困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/632967/urn-problem-with-replacement-of-a-ball-of-diferent-color</guid>
      <pubDate>Sun, 03 Dec 2023 21:00:48 GMT</pubDate>
    </item>
    <item>
      <title>测试是否可以从模型中剔除变量（多因素资产定价）</title>
      <link>https://stats.stackexchange.com/questions/632966/testing-whether-a-variable-can-be-kicked-out-from-a-model-multifactor-asset-pri</link>
      <description><![CDATA[假设有两个数据生成过程。
DGP1：
$$
Y_{i,t}=\beta_0+\lambda_1\beta_{1,i}+\varepsilon_{i,t} \tag{1}
$$
与 $\beta_0=0$、$\varepsilon_{\cdot,t} \stackrel{\text{i.i.d.}} {\sim} N(\mathbf{0},\Sigma)$ ，其中 $\beta_{1,i}$ 是斜率系数
$$
Y_{i,t}=\gamma_0+\beta_{1,i} X_{1,i,t}+u_{i,t}。 \标签{i}
$$
DGP2：
$$
Y_{i,t}=\tilde\beta_0+\lambda_1\tilde\beta_{1,i}+\lambda_2\tilde\beta_{2,i}+\tilde\varepsilon_{i,t} \tag{2}
$$
与 $\tilde\beta_0=0$、$\tilde\varepsilon_{\cdot,t} \stackrel{\text {i.i.d.}}{\sim} N(\mathbf{0},\tilde\Sigma)$ 且其中 $\tilde\beta_{1,i}, \ tilde\beta_{2,i}$ 是斜率系数
$$
Y_{i,t}=\tilde\gamma_0+\tilde\beta_{1,i} X_{1,i,t}+\tilde\beta_{2,i} X_{2,i,t}+\tilde u_ {它}。 \标签{ii}
$$
我们有一个 $(Y_{i,t},X_{1,i,t},X_{2,i,t})$ 的样本对于 $i=1,\dots,N$ 和 $t=1,\dots,T$ 。我们想弄清楚它是来自DGP1还是DGP2。 问题：我们能否比较 DGP1 和 DGP2 的拟合度以获得 $\chi^2$ 统计量，以便我们测试 $H_0$：DGP1 是事实 反对 $H_1$：DGP2 是事实？理想情况下，答案还包括 $X_{1,i,t}$ 和 $X_{2, i,t}$ 是向量值随机变量而不是标量。我也不太愿意假设误差是多元高斯的，但希望我们能够渐近地摆脱这个假设。
（背景是多因素资产定价模型，我的更具体的、面向财务的问题是此处。设置不相同但相似。在那里，我们也许可以容纳 $(1)$ 和 $(2)$ （没有限制 $\beta_0=0$）并比较统计数据 $\boldsymbol{\hat\beta} _0&#39; \text{Cov}(\boldsymbol{\hat\beta}_0,\boldsymbol{\hat\beta}_0&#39;)^{-1}\boldsymbol{\hat\beta}_0\sim\chi^2_{ ?}$ 与 $\boldsymbol{\hat{\tilde{\beta}}}_0&#39; \text{Cov}(\boldsymbol{\hat{\tilde{ \beta}}_0,\boldsymbol{\hat{\tilde{\beta}}}_0&#39;)^{-1}\boldsymbol{\hat{\tilde{\beta}}}_0\sim\chi^2_ {??}$，也许$\sim\chi^2_{???}$？)]]></description>
      <guid>https://stats.stackexchange.com/questions/632966/testing-whether-a-variable-can-be-kicked-out-from-a-model-multifactor-asset-pri</guid>
      <pubDate>Sun, 03 Dec 2023 20:23:28 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 和 PSPP 使用相同的数据集产生截然不同的逻辑回归结果</title>
      <link>https://stats.stackexchange.com/questions/632962/spss-and-pspp-yield-very-different-logistic-reggression-results-with-same-datase</link>
      <description><![CDATA[我正在尝试运行一个多元逻辑回归模型，其中因变量是二分变量，自变量是二元变量或连续变量。起初我只能访问 PSPP，但最终获得了 SPSS 许可证。我在具有相同数据集的两个软件上运行模型，得到了截然不同的结果，但我一生都无法弄清楚为什么。
样本大小为 4296 条记录。我有 24 个自变量。我已经检查了共线性。数据集有些不平衡，有 190 个入口点被分类为 1。

在 PSPP 上，伪 R2 为负且接近 0（我认为这根本不可能） - 但性能（正确分类的百分比）相当不错，为 86%
在 SPSS 上，伪 R2 更好，但性能较差，接近正确分类的 20%
在每个解决方案中，不同的自变量均显示为显着，并显示不同（有时相反）的指数。

对可能发生的事情有什么想法吗？我应该说我对这一切都很陌生。
SPSS 模型：https://drive.google.com/文件/d/1RahEtsR3CertVIrTb3C3iLWAEis6NnFU/view?usp=drive_link
&lt;前&gt;&lt;代码&gt;获取
FILE=&#39;/Volumes/GoogleDrive-104327187730824169032/O meu disco/_MESTRADO PP
2022 23/_ PESQUISA_LA/DADOS/SPSS 结果/Modelo_com_cortes.sav&#39;。
数据集名称 DataSet1 WINDOW=FRONT。
逻辑回归变量 OODC_pop50_provavel
/METHOD=ENTER Pop_log Servidores_logRede Fibra 内联网 CPD Cadastro Cad
astro_inf 地舆地理
Cadastro_anualPGV PGV_inf PGV_10anos Proporção_de_quadro_com_ensino_su
perior_ou_mais软件
Secretaria_ou_instituto_de_planejamentoZoneamento Obras Contribuição D
ependencia_financeiraIPTU
比例委员会Consorcio Conselhos Proporção_de_CCs_com_ensino_superior_ou_mais
/对比度（重新）=指标
/对比度（Fibra）=指标
/CONTRAST（内联网）=指标
/对比度 (CPD)=指标
/CONTRAST (Cadastro)=指标
/CONTRAST (Cadastro_inf)=指标
/CONTRAST (Cadastro_geo)=指标
/CONTRAST (Cadastro_anual)=指标
/对比度 (PGV)=指标
/CONTRAST (PGV_inf)=指标
/CONTRAST (PGV_10anos)=指标
/对比度（软件）=指示器
/CONTRAST (Secretaria_ou_instituto_de_planejamento)=指标
/CONTRAST（区域）=指标
/CONTRAST (Obras)=指标
/CONTRAST (Contribuição)=指标
/对比度(IPTU)=指标
/CONTRAST (Consorcio)=指标
/CONTRAST (Conselhos)=指标
/打印=CI(95)
/CRITERIA=PIN(0.05) POUT(0.10) 迭代(20) 剪切(0.5)。
在此处输入代码

PSPP 模型：https://drive.google。 com/file/d/13zHSKhdlxbwwiPYbn-mBmSqSPm6oMRMb/view?usp=sharing
逻辑回归 OODC_pop50_provavel 与 Pop_log Servidores_log Rede Fibra Intranet
CPD Cadastro Cadastro_inf Cadastro_geo Cadastro_anual PGV PGV_inf PGV_10anos
Proporção_de_quadro_com_ensino_superior_ou_mais 软件
Secretaria_ou_instituto_de_planejamento Zoneamento Obras 贡献
Dependencia_financeira IPTU Consorcio Conselhos Diff_CC_quadro_normalizado
/CATEGORICAL = Rede Fibra 内联网 CPD Cadastro Cadastro_inf Cadastro_geo
Cadastro_anual PGV PGV_inf PGV_10anos Software Secretaria_ou_instituto_de_planejamento
地区事务贡献 IPTU 联盟联盟
/标准 = 剪切(0.5) 迭代(20)
/NOORIGIN。
]]></description>
      <guid>https://stats.stackexchange.com/questions/632962/spss-and-pspp-yield-very-different-logistic-reggression-results-with-same-datase</guid>
      <pubDate>Sun, 03 Dec 2023 19:57:17 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 DCC Garch Alpha 和 Beta（R 中的 dcca1 和 dccb1）</title>
      <link>https://stats.stackexchange.com/questions/632961/how-to-interpret-dcc-garch-alpha-and-beta-dcca1-and-dccb1-in-r</link>
      <description><![CDATA[我刚刚在 R 中运行 DCC GARCH 模型，并尝试解释输出。我已经运行了 3 个时间序列的模型。我知道阿尔法和贝塔反映了短期和长期的溢出效应。然而，我只得到一个 dcca1 和 dccb1，即使 dcca1 和 dccb1 的值对于不同的时间序列应该是不同的。那么 dcca1 和 dccb1 告诉我什么？预先感谢您的帮助！
]]></description>
      <guid>https://stats.stackexchange.com/questions/632961/how-to-interpret-dcc-garch-alpha-and-beta-dcca1-and-dccb1-in-r</guid>
      <pubDate>Sun, 03 Dec 2023 19:56:36 GMT</pubDate>
    </item>
    <item>
      <title>因变量存在间隙的时间序列</title>
      <link>https://stats.stackexchange.com/questions/632960/time-series-with-gaps-in-the-dependent-variable</link>
      <description><![CDATA[我有一个时间序列数据，其中的因变量代表某些股票的股票市场价值。该数据在工作日可用，但在周末不可用，因为没有交易。此外，我还有一些自变量的值。该数据除了工作日之外还包括周末。
这种情况我该怎么办？
删除缺少周末数据的行将导致自变量的数据丢失。
用最后的观察填补空白（最后的观察结转？） ?
用某种平均值来填补空白？]]></description>
      <guid>https://stats.stackexchange.com/questions/632960/time-series-with-gaps-in-the-dependent-variable</guid>
      <pubDate>Sun, 03 Dec 2023 19:52:03 GMT</pubDate>
    </item>
    <item>
      <title>比较具有重叠临床特征的患者中生物标志物的分布</title>
      <link>https://stats.stackexchange.com/questions/632957/comparing-distribution-of-a-biomarker-among-patients-with-overlapping-clinical-f</link>
      <description><![CDATA[我有一个问题，如何比较一种测试的生物标志物在具有不同重叠临床综合征的患者中的分布。
就我而言，我正在调查多发性硬化症患者，他们的临床症状可以归因于几种不同的综合症，例如锥体综合症、感觉综合症等。此外，一名患者可能有两种甚至三种综合症。在我的数据表中，我创建了具有不同综合征的列（总共 5 个），并将所有患者编码为阳性 (1) 或阴性 (0)。目前，我想比较这些综合症中测试的生物标志物的分布是否有所不同。到目前为止，我只能评估一组内是否存在差异，例如在患有锥体综合症和不患有锥体综合症的患者之间（使用曼-惠特尼 U 检验，因为数据是非参数的）。然而，这种比较不允许我评估这些综合征的重叠，因为锥体综合征患者也可能有感觉和脑干症状。
我应该如何组织数据以及应该执行什么统计测试来评估不同综合征之间生物标志物的分布，同时记住它们的重叠？]]></description>
      <guid>https://stats.stackexchange.com/questions/632957/comparing-distribution-of-a-biomarker-among-patients-with-overlapping-clinical-f</guid>
      <pubDate>Sun, 03 Dec 2023 19:16:13 GMT</pubDate>
    </item>
    <item>
      <title>Bonferroni 修正不适用于随机性测试，我说得对吗？</title>
      <link>https://stats.stackexchange.com/questions/632945/am-i-right-that-the-bonferroni-correction-does-not-apply-to-randomness-testing</link>
      <description><![CDATA[有一些统计测试套件（如下）通常用于确定序列是否看起来是（伪）随机的。其中一些测试套件有一些测试 (ent/ent3000)，而其他测试套件则有超过 100 个测试 (NIST STS)。它们都假设相同的零假设，即样本来自独立且均匀的分布。
而且这些测试非常严峻。它们用于国家安全密码学、银行安全以及数十亿美元交易的赌场。
它们都没有对关键的 $\alpha$ 值应用 Bonferroni 校正。为什么不呢？
&lt;小时/&gt;
死忠
顽固分子
pracrand
ent
ent3000
NIST STS
测试 U01
其他一些...]]></description>
      <guid>https://stats.stackexchange.com/questions/632945/am-i-right-that-the-bonferroni-correction-does-not-apply-to-randomness-testing</guid>
      <pubDate>Sun, 03 Dec 2023 14:22:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用假设检验而不是仅仅让人们进行贝叶斯更新？</title>
      <link>https://stats.stackexchange.com/questions/632935/why-do-we-use-hypothesis-tests-instead-of-just-letting-people-do-bayesian-update</link>
      <description><![CDATA[如果这是一个愚蠢的问题，我很抱歉，我不太明白这一点，但我想知道为什么我们需要“离散化”我们使用假设检验进行判断。为什么我们不能在每次研究完成时，让人们报告数据、p 值和效应大小，然后报告数据如何改变他们的主观概率？
对于人们来说，拥有自己的某些陈述为真的概率，然后在研究中遇到新数据时更新该概率，似乎更有价值。
只有当数据“具有统计显着性”时才让人们这样做对我来说似乎有点武断。统计上不显着但仍然指向某个方向的数据仍然是应该更新你的信念的证据，只是不够强大，以至于你可以“合理地”相信这些数据。认为研究结论是正确的（不要期望很多时候都是错误的）。
我听到有些人说它是有害的，因为它会导致人们不发表没有统计意义的研究。
总的来说，对我来说，它在概念上似乎更清晰，每个人都有自己分配给陈述的概率，然后，当他们遇到一组新数据时，他们会更新自己的概率。然后，也许这些数据在统计上并不显着，而且更新也没有那么多，但这总比没有好。特别是如果这会导致科学界更健康的规范，所有研究都会发表。
如果这是一个非常愚蠢的问题，再次抱歉。]]></description>
      <guid>https://stats.stackexchange.com/questions/632935/why-do-we-use-hypothesis-tests-instead-of-just-letting-people-do-bayesian-update</guid>
      <pubDate>Sun, 03 Dec 2023 11:42:19 GMT</pubDate>
    </item>
    <item>
      <title>对数变换对于使用 2 边 z 检验进行实验前样本量计算是否有效？</title>
      <link>https://stats.stackexchange.com/questions/632921/is-a-log-transformation-valid-for-a-pre-experiment-sample-size-calculation-using</link>
      <description><![CDATA[目标
我正在进行实验前分析，以确定在给定特定功效、显着性水平和提升度的情况下所需的样本量。
数据
这是一个研究问题，我从一个大样本中获得了货币存款的分布（大到足以被认为是它所抽取的人口）。
方法
我尝试重现我在多个参考文献中找到的标准样本量计算，包括这个链接。这是幻灯片 12 中的图像以及公式。功效 = $\beta$，显着性水平 = $\alpha$，提升度由 $\mu_1-\mu_2$。

根据我的理解，这种方法假设数据呈正态分布，并且最终的实验将使用 2 边 Z 检验。另外，由于是预实验数据，因此 $\sigma_1^2$ 设置为等于 $\sigma_2^2$ （尚未进行任何治疗）。
但是，存款数据的分布是对数正态的。因此，我应用了以 10 为底的对数转换，使其更加正常。这意味着输入提升现在是相对比率而不是平均值的绝对差异，但我认为这不会改变此计算的整体有效性： log($\mu_1$&lt; /span&gt;) - log($\mu_2$) = log($\frac{\mu_1}{\mu_2} $)。
我想知道在实验前样本量计算中使用美元值的对数变换是否有效。我得到的其他建议方法包括使用 Mann Whitney U 检验，但我不确定如何为此进行实验前样本量计算。我发现了这个相关问题但是没有任何参考链接仍然有效。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/632921/is-a-log-transformation-valid-for-a-pre-experiment-sample-size-calculation-using</guid>
      <pubDate>Sun, 03 Dec 2023 02:17:25 GMT</pubDate>
    </item>
    </channel>
</rss>