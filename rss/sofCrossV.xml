<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 22 Jun 2024 15:14:47 GMT</lastBuildDate>
    <item>
      <title>计算涉及不同估计量和分位数的相关测量的平均值和误差</title>
      <link>https://stats.stackexchange.com/questions/649719/calculating-the-mean-and-error-for-correlated-measurements-involving-different-e</link>
      <description><![CDATA[我的目标是找到一种方法来报告同一分布（相同测量值）的不同估计量和分位数的平均$\pm$误差。
我正在用不同的估计量（检查稳定性）和不同的分位数（越来越多地限制内核）测量分布的宽度（高斯核心和长尾）。
我发现了两个稳定的估计量：

各种分位数的高斯拟合的西格玛：从 100%（考虑拟合的完整分布）到 80% 内核——基本上是切割越来越多的尾部。
中位数绝对偏差（中位数），同样适用于相同的
分位数。

为了完整起见，下面是分布的图片。在那里，我用高斯拟合蓝色部分（98％分位数，通过从分布的两侧去除 1％）。对于这个 98% 的核心，除了用红色报告的高斯西格玛外，我还得到了 AAD、RMS 和 MAD 等估计量。
对于不同的估计量和分位数，我得到了一个值及其不确定性的列表，我将其报告如下：
估计量、分位数、值、误差
MAD，100，0.371，0.018
MAD，99，0.364，0.017
MAD，98，0.367，0.017
MAD，97，0.347，0.017
MAD，95，0.363，0.017
MAD，93，0.345，0.017
MAD，90，0.378，0.018
MAD，85， 0.363，0.017
MAD，80，0.383，0.018
Gauss_sigma，100，0.335，0.017
Gauss_sigma，99，0.335，0.017
Gauss_sigma，98，0.334，0.017
Gauss_sigma，97，0.339，0.017
Gauss_sigma，95，0.357，0.017
Gauss_sigma，93，0.351，0.017
Gauss_sigma，90，0.337，0.017
Gauss_sigma，85，0.332， 0.017
Gauss_sigma，80，0.314，0.016

现在，这些测量值都属于同一分布。因此，误差是完全相关的。
我正在尝试找出一种方法来报告这些测量值的平均值和误差。
我认为对于误差，我可以进行误差传播，考虑到相关系数为 1。我会得到：$\sigma = \sqrt{\sigma_A^2 + \sigma_B^2 + 2\sigma_A\sigma_B}$
对于平均值，我不确定从这些值计算平均值是否有意义，因为我上面报告的值不是不同的测量值，而是同一测量值的不同估计量和分位数。
任何提示都值得赞赏 :) 谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/649719/calculating-the-mean-and-error-for-correlated-measurements-involving-different-e</guid>
      <pubDate>Sat, 22 Jun 2024 13:49:42 GMT</pubDate>
    </item>
    <item>
      <title>解释有无聚类调整的置信区间之间的差异。调整后的置信区间应该更宽吗？</title>
      <link>https://stats.stackexchange.com/questions/649717/interpreting-differences-between-confidence-intervals-with-and-without-adjustmen</link>
      <description><![CDATA[我正在尝试解释一篇涉及集群随机试验数据的文章，其中效应大小的置信区间据说已经“使用回归系数的标准误差进行了调整，并转化为效应大小以产生效应大小的上限和下限”与计算 ES 的 CI 的更常用方法相比，这会导致更窄的置信区间和更具统计意义的结果。我感到困惑是因为如果这个测量应该纠正 CSBias，那么考虑到 CSBias 的通常方向，它肯定会导致更宽的置信区间。除此之外，如何解决以不同方式计算的置信区间之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/649717/interpreting-differences-between-confidence-intervals-with-and-without-adjustmen</guid>
      <pubDate>Sat, 22 Jun 2024 13:29:57 GMT</pubDate>
    </item>
    <item>
      <title>计算 GLM 的 QAIC</title>
      <link>https://stats.stackexchange.com/questions/649716/calculating-qaic-for-glm</link>
      <description><![CDATA[我正在尝试使用此处提供的代码来计算 DLNM 模型的 QAIC。
但我对这个公式与其他 R 包中的 QAIC 公式之间的区别感到困惑，就像对这个问题的回答一样。
前者将弥散参数添加到 AIC 公式的似然项中，而另一个则添加到 df 项中，尽管增加弥散会导致两者均采用 QAIC。]]></description>
      <guid>https://stats.stackexchange.com/questions/649716/calculating-qaic-for-glm</guid>
      <pubDate>Sat, 22 Jun 2024 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表答案中问题组的相关性</title>
      <link>https://stats.stackexchange.com/questions/649714/correlation-of-group-of-questions-in-likert-scale-answers</link>
      <description><![CDATA[假设我们有一个包含 6 列的响应调查数据框。每列是一个问题：Q1、Q2、Q3、...、Q6。响应从 1 到 5。1 表示非常差，4 表示差，3 表示一般，2 表示好，1 表示非常好。另外，考虑 A 是 q1、q2、q3 的一组问题，B 单独包含问题 q4，C 包含 q5 和 q6。我的最终任务是找出所有组之间的相关性。A 与 B、B 与 C、A 与 C 等等，如相关矩阵所示。我的问题是：响应是因素的级别。等级。每个响应都是一个等级。它可能是数字，但它是一个等级。如果我取问题的平均值，那么可以使用 Spearman 相关系数吗？还是我必须取中位数？如果我不使用 Spearman（处理等级）我可以使用 Pearson 系数吗？

likert_levels &lt;- c(1,2,3,4,5)
set.seed(42)
library(dplyr)
df &lt;-
tibble(
&quot;q1&quot; = sample(likert_levels, 150, replace = TRUE),
&quot;q2&quot; = sample(likert_levels, 150, replace = TRUE, prob = 5:1),
&quot;q3&quot; = sample(likert_levels, 150, replace = TRUE, prob = 1:5),
&quot;q4&quot; = sample(likert_levels, 150, replace = TRUE, prob = 1:5),
&quot;q5&quot; =样本（c（likert_levels，NA），150，替换 = TRUE），
“q6”= 样本（likert_levels，150，替换 = TRUE，prob = c（1，0，1，1，0））
）%&gt;%
突变（across（everything（），~factor（.x，levels = likert_levels）））

df2 = tibble（类别 = c（“A”，“A”，“A”，“B”，“C”，“C”），
问题 = c(&quot;q1&quot;,&quot;q2&quot;,&quot;q3&quot;,&quot;q4&quot;,&quot;q5&quot;,&quot;q6&quot;))

df2
df%&gt;%
mutate(id = row_number())%&gt;%
tidyr::pivot_longer(!id,names_to = &quot;questions&quot;,values_to = &quot;responses&quot;)%&gt;%
left_join(.,df2,by=&quot;questions&quot;)

df_cor=df%&gt;%
mutate_if(is.factor,as.double)%&gt;%
rowwise() %&gt;%
mutate(QA = mean(c(q1, q2, q3)),
QB = mean(c(q4)),
QC =平均值（c（q5，q6）））％＆gt;％
选择（QA，QB，QC）

cor（df_cor，方法=＆quot;spearman＆quot;，使用=＆quot;pairwise.complete.obs＆quot;）
cor（df_cor，方法=＆quot;pearson＆quot;，使用=＆quot;pairwise.complete.obs＆quot;）
]]></description>
      <guid>https://stats.stackexchange.com/questions/649714/correlation-of-group-of-questions-in-likert-scale-answers</guid>
      <pubDate>Sat, 22 Jun 2024 11:55:19 GMT</pubDate>
    </item>
    <item>
      <title>单位根平稳性和建模 AR(p) 过程</title>
      <link>https://stats.stackexchange.com/questions/649711/unit-root-stationarity-and-modelling-arp-process</link>
      <description><![CDATA[我正在阅读 Gary Koop 的《计量经济学导论》。我对 AR(p) 过程的建模过程有点困惑。希望有人能帮我澄清一下。让我阐述一下我的理解和我有点困惑的地方。
假设我们有一个 AR(p) 过程：
$$ Y_t = \alpha +\rho_1 Y_{t-1} + \ldots +\rho_p Y_{t-p}+\varepsilon_t \tag{1}.$$
然后我们可以将其一阶差分视为：
$$\Delta Y_t = \alpha + \theta Y_{t-1} + \gamma_1\Delta Y_{t-1} + \ldots + \gamma_{p-1}\Delta Y_{t-p+1} + \varepsilon_t \tag{2}$$
其中 $\theta = \rho_1+\dots +\rho_{p} - 1$。
如果我们有一组数据，那么我们可以使用 OLS 将 $(2)$ 拟合到数据中，使用顺序 t 检验或似然函数（例如 BIC）选择滞后和参数。
完成此操作后，我们需要对参数 $\theta$ 使用 Dickey-Fuller 检验，其中零假设为 $H_0\colon\ \theta = 0$。如果我们找不到任何证据来拒绝原假设，那么这意味着我们的原始模型 $(1)$ 有一个单位根。在模型 $(2)$ 中，我们将得到 $\theta = 0$，并且 $\Delta Y_t$ 将是平稳的，因为我们知道具有单位根的 AR(p) 模型的一阶差分是平稳的。
但是，如果我们拒绝 $\theta = 0$ 的原假设，我有点搞不清楚我们该怎么做。在这种情况下，我们可以得出结论，原始序列没有单位根。那么我们可以继续使用 OLS 直接对其进行建模吗？我们是否必须进一步假设它不是一个爆炸性过程？除非我遗漏了某些内容，否则教科书似乎没有涵盖这些内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/649711/unit-root-stationarity-and-modelling-arp-process</guid>
      <pubDate>Sat, 22 Jun 2024 11:08:17 GMT</pubDate>
    </item>
    <item>
      <title>使用方差分析对不同比例的模型进行比较，有何不同？</title>
      <link>https://stats.stackexchange.com/questions/649708/using-anova-for-model-comparison-with-a-different-ratio-how-does-it-differ</link>
      <description><![CDATA[当我们使用方差分析比较两个模型时，我们通常会计算 F 分数，例如
$$F = \frac{\left(\frac{RSS_1-RSS_2}{p_2-p_1}\right)}{\left(\frac{RSS_2}{n-p_2}\right)}$$
其中下标指的是模型，$p_1&lt;p_2$ 是模型参数的数量，$RSS$ 是计算出的残差平方和。
我们也可以使用不同的比较方法，例如
$$F&#39; = \frac{\left(\frac{RSS_1}{n-p_1}\right)}{\left(\frac{RSS_2}{n-p_2}\right)}$$
这些方法有何不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/649708/using-anova-for-model-comparison-with-a-different-ratio-how-does-it-differ</guid>
      <pubDate>Sat, 22 Jun 2024 10:57:33 GMT</pubDate>
    </item>
    <item>
      <title>如何表达右尾 Fisher 精确检验的 OR 中的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/649707/how-to-express-the-uncertainty-in-the-or-of-a-right-tailed-fishers-exact-test</link>
      <description><![CDATA[许多 OR（比值比）可视化显示 95% 的置信区间，表达不确定性，如下图左侧面板所示。

然而，在基因组过度表达分析中使用右尾 Fisher 检验，fisher.test(., alternative=&#39;greater&#39;) 用于列联表，例如，
 DE nDE Sum
IN 20 79 99
nIN 1869 13032 14901
Sum 1889 13111 15000

产生无限的置信上限。
 OR lower upper
Term_1 1.995 1.9000 Inf
Term_2 1.728 1.6320 Inf
Term_3 1.455 1.3677 Inf
Term_4 1.188 0.8910 Inf
Term_5 1.050 0.8000 Inf

按照这个逻辑，可视化应该看起来像右侧面板中的那样，但我从未见过。
执行双侧检验将产生有限的上限，但这并不正确。
我听说我们可以在这个中使用双侧检验的置信区间，其中&lt;​​span class=&quot;math-container&quot;&gt;$\alpha=0.1$情况，但我不确定。
我考虑过引导 CI，并尝试通过不替换地延续差异基因表达矩阵的 p 值并使用引导 OR 的百分位数，但这给了我低于估计 OR 的上限。（我想我只能引导 p 值，而不能引导 CI。）
那么如何分别计算适当的置信区间或误差幅度，或者在可视化中正确表达不确定性？]]></description>
      <guid>https://stats.stackexchange.com/questions/649707/how-to-express-the-uncertainty-in-the-or-of-a-right-tailed-fishers-exact-test</guid>
      <pubDate>Sat, 22 Jun 2024 10:47:52 GMT</pubDate>
    </item>
    <item>
      <title>如果两个 IV 在第一阶段回归中产生不同的 F 统计量，是否表明它们是不同的 IV，而不管相关性如何？</title>
      <link>https://stats.stackexchange.com/questions/649706/if-two-iv-yield-distinct-f-statistics-in-the-first-stage-regression-does-it-ind</link>
      <description><![CDATA[假设我们处于面板环境中，在控制固定效应的同时进行估计。假设我们有两个用于 X 内生变量的工具 Z1 和 Z2，并且两个工具都是相关的。我们分别使用 Z1 和 Z2 通过 2SLS 对 X 上的 Y 进行回归（两个不同的回归）。
场景 1）：Corr(Z1,Z2) &gt; 0.8，但 Z1 的 F 统计量为 50，Z2 的 F 统计量为 90。我们可以说它们是两个不同的工具吗？
场景 2）：Corr(Z1,Z2) &lt; 0.5，但 Z1 的 F 统计量为 85，Z2 的 F 统计量为 90。我们可以说它们是两个不同的工具吗？
现在假设我们尝试通过“移除”固定效应来评估工具之间的相关性。也就是说，只需对固定效应进行 Z 回归，保存残差，然后计算 Z1 残差与 Z2 残差之间的相关性。我们称之为“demeaned corr”。
场景 1.1）：demeaned corr(Z1,Z2) &gt; 0.8，但 Z1 的 F 统计量为 50，Z2 的 F 统计量为 90。我们可以说它们是两种不同的工具吗？
场景 2.1）：demeaned corr(Z1,Z2) &lt; 0.5，但 Z1 的 F 统计量为 85，Z2 的 F 统计量为 90。我们可以说它们是两种不同的工具吗？
如果能对仅使用 F 统计量的差异是否可用于确定工具的独特性提供任何见解，我们将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649706/if-two-iv-yield-distinct-f-statistics-in-the-first-stage-regression-does-it-ind</guid>
      <pubDate>Sat, 22 Jun 2024 10:33:57 GMT</pubDate>
    </item>
    <item>
      <title>情景还原技术</title>
      <link>https://stats.stackexchange.com/questions/649703/scenario-reduction-techniques</link>
      <description><![CDATA[我有一个包含 7 个特征和 500 个样本的数据集，即一个包含 7 个特征场景的 7 x 500 矩阵。场景是指“随机变量的潜在结果”，在我的例子中，它是产品的需求。
由于在我的模型中处理 500 个样本计算量很大，我想知道哪些方法最适合将场景数量减少到 7 x 50。
我知道 PCA 通常用于降维，但是否可以使用 PCA 来减少场景数量？例如，是否可以计算主成分并沿着下图中的主要成分 $u_1$ 和 $u_2$ 选择场景？这有意义吗？

截断点反映了所选的 PCA 转换数据点 - 在运行我的模型之前将其转换回原始坐标。
我的模型基本上由以下推论给出：

正是由于半正定 (PSD) 约束，我的问题才变得计算复杂很重。决策变量 $\Lambda$ 是一个 7 x 7 矩阵，因此，对于每个 $i \in N$ 和 $N=500$（即样本/场景的数量），PSD 约束变为 8 x 8 矩阵。
一般来说，这对于线性程序来说不是问题，但是，这是一个线性和凸 PSD 程序，其求解难度要大得多。因此，500 个 PSD 约束相当重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/649703/scenario-reduction-techniques</guid>
      <pubDate>Sat, 22 Jun 2024 09:48:06 GMT</pubDate>
    </item>
    <item>
      <title>对 PCA、FA 和 PCR 感到困惑？</title>
      <link>https://stats.stackexchange.com/questions/649701/confusion-regarding-pca-fa-and-pcr</link>
      <description><![CDATA[我在这里学到了：PCA 后跟旋转（例如方差最大）是否仍是 PCA？
关于 PCA 和 FA 之间的关系，以及它们各自如何提供观察同一事物的视角。然而，在工作中，我遇到了一些遗留代码，它们做了一些奇怪的事情，至少在上述帖子中描述的框架内是这样的（将进行总结）。
在帖子中，作者说 SVD 给了我们
$X=USV^⊤$
然后我们可以将其分解为正交基和成分分数（PCA 视图）或潜在单位方差变量及其载荷（FA 视图），通过将 $S$ 矩阵与 $U$ 分组（$US$ = PCA 中的成分分数，$V$ 有基础）或与 $V$ 分组（$VS$ 是载荷矩阵，$U$ 有因子）。
这很有道理，但我看到的代码中有人计算 PCA，提取如上所述的载荷（特征向量按 sqrt(特征值) 缩放），然后在这些载荷上对原始矩阵进行回归以找到因子，结果当然是不同的。这种差异意味着什么？每个有什么优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/649701/confusion-regarding-pca-fa-and-pcr</guid>
      <pubDate>Sat, 22 Jun 2024 08:45:25 GMT</pubDate>
    </item>
    <item>
      <title>如何对机器学习模型执行置换检验以获得其性能的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</link>
      <description><![CDATA[这个问题与上一篇文章中的问题类似。但由于没有回复，而且我很难找到答案，所以我想再问一次。
我正在 caret 中训练回归模型（SVM 线性核）。我曾多次使用名为 PRONTO 的软件，它可以运行置换测试以获得预测模型指标（R²、MSE 等）的 p 值。
如何在 R 中重现此问题？是否可以在 caret 包中执行此操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</guid>
      <pubDate>Fri, 21 Jun 2024 23:31:13 GMT</pubDate>
    </item>
    <item>
      <title>（理论）树模型是否输出概率？</title>
      <link>https://stats.stackexchange.com/questions/649666/theory-do-tree-models-output-probabilities</link>
      <description><![CDATA[我有一个关于决策树分类输出的纯理论问题。我听过很多人说“树模型的输出不是概率”，研究过这些之后，我不明白他们为什么会这么说。
我说它们实际上是概率的原因如下：
1. 简单分类树：决策树中的每个叶子代表训练数据的一个子集，具有一定的类别分布。叶子中每个类别的比例可以解释为属于该类别的概率估计。例如，如果叶子包含 80 个 A 类样本和 20 个 B 类样本，则 A 类的概率估计为 80%，B 类的概率估计为 20%。
2. 集成模型（随机森林）：在随机森林中，多个决策树在数据和/或特征的不同子集上进行训练。然后汇总这些树的预测。对于分类，这通常涉及进行多数投票或平均每棵树的预测概率。通过对多棵树的预测概率进行平均，随机森林可以提供比单个决策树更可靠的概率估计。这进一步支持了基于树的模型可以输出概率的观点。
3. 增强模型（梯度增强，XGBoost）：像梯度增强或 XGBoost 这样的增强模型按顺序构建树，每棵树都会纠正前一棵树的错误。对于二元分类，最终输出通常采用对数几率的形式，然后使用逻辑函数（S 型函数）将其转换为概率。此转换明确产生概率估计。
说它们不是概率的原因是：
1.校准：众所周知，许多分类问题都涉及不平衡的数据集，为此，许多人使用 is_unbalance 或 class_weights 等参数来补偿这一点。使用这些参数会使输出校准不充分。这意味着预测的概率不一定与事件的真实可能性相对应。例如，一片叶子可能以 80% 的概率预测一个类别，但实际上，该类别的真实可能性可能不同。校准技术（例如 Platt 缩放或保序回归）通常用于改善这种情况。虽然我相信这个理由是有效的，但使用这些参数只是树模型的一个特例，所以我不会那么快地说基于树的模型不会产生概率。
2.过度拟合：我们都同意决策树很容易过度拟合（尽管我会在随机森林的情况下对此进行更多辩论），尤其是那些未经修剪的决策树，这会导致过度自信的概率估计。这种过度拟合可能导致叶子样本很少，从而使概率估计不太可靠。我有点同意这种说法，但是，这只是告诉我这是一个训练不良的模型，这并不意味着基于树的模型本质上不输出概率，这只是一个像其他模型一样训练不良的模型的情况。训练不良的神经网络甚至逻辑回归也可能会发生同样的情况。
我很想听听你对这个问题的想法和意见，并学习一些新东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/649666/theory-do-tree-models-output-probabilities</guid>
      <pubDate>Fri, 21 Jun 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    <item>
      <title>聚类实际上会减少数据集中的行数吗？</title>
      <link>https://stats.stackexchange.com/questions/649709/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</link>
      <description><![CDATA[我正在阅读 Luis G. Serrano 的《grokking Machine Learning》一书，看到了这样一句话：
“看起来聚类和降维没什么相似之处，但实际上，它们并没有太大区别。如果我们有一张满是数据的表，每一行对应一个数据点，每一列对应一个特征。因此，我们可以使用聚类来减少数据集中的行数，使用降维来减少列数。”
我对聚类减少行数的说法有疑问。似乎聚类只是对数据进行分组，而不减少其列数。我错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649709/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</guid>
      <pubDate>Thu, 20 Jun 2024 18:55:16 GMT</pubDate>
    </item>
    <item>
      <title>评估预期值加变异的估计量</title>
      <link>https://stats.stackexchange.com/questions/649483/evaluating-estimator-of-expected-value-plus-variation</link>
      <description><![CDATA[我知道，对于典型情况，可以根据预测的均方误差 (MSE) 来评估估计量。我该如何评估一个估计量，它给出的是一个预测值加上一些变化？
例如，软件开发人员可能会估计一个项目需要 8 天的工作时间。如果他们被问到“你需要多长时间才能有 80% 的机会在这段时间内完成项目？”，他们可能会说 12 天。一旦知道实际值（项目实际花费的时间），如何评估第二个预测？
一种简单的综合评估方法，如“预测中有多少比例大于实际时间？”不起作用，因为如果开发人员 80% 的时间猜测为 100 天，20% 的时间猜测为 0 天，那么这将是完美的选择。
背景：众所周知，估算项目长度是软件开发中的一个难题，我想知道开发人员在猜测更大的百分位数而不是预期值时是否更准确。]]></description>
      <guid>https://stats.stackexchange.com/questions/649483/evaluating-estimator-of-expected-value-plus-variation</guid>
      <pubDate>Tue, 18 Jun 2024 20:28:55 GMT</pubDate>
    </item>
    </channel>
</rss>