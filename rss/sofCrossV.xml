<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 22 Feb 2025 15:16:07 GMT</lastBuildDate>
    <item>
      <title>使用复杂的随机拦截来解决LMM中的奇异性/收敛问题</title>
      <link>https://stats.stackexchange.com/questions/661726/using-complex-random-intercepts-to-resolve-singularity-convergence-issues-in-lmm</link>
      <description><![CDATA[我将混合模型拟合到由2 x 2重复测量设计产生的数据。自变量是上下文（高，低）和一致性（一致，不一致）。有20段。因变量是在目标信息上读取时间（请注意，我在适当的情况下进行log-thransform）。。
我正在阅读Scandola＆amp; tidoni（2024;  https：//doii.org/1177/1177/251515259231231212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212AIN感谢您，本！），并与复杂的随机拦截模型（CRI）一起玩。斯堪的兰州＆amp; Tidoni提供了一个逐步的过程，用于拟合跨设计的模型，当最大模型导致收敛/奇异性问题时，这很有帮助。但是，经过文章后，我有两个有关使用CRI模型的问题。
 问题1 ：Scandola＆amp; Tidoni（2024）建议，如果最大模型（随机截距＆amp;随机斜率）会导致收敛/奇异性问题，以尝试完整的CRI模型。如果完整的CRI模型解决了问题，请出色并继续下一步。如果完整的CRI模型无法解决问题，那么Scandola＆amp; Tidoni建议以最低的方差去除CRI，然后重试。这是我的问题 -  我要降低哪种型号 - 最初的最大模型或完整的CRI模型？
例如，如果“段落”导致最小的可变性，请从中减少原始最大模型：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 +上下文*一致性|主题） +（1 +上下文*一致性| vassage），mydata）;摘要（m）;方差分析（M） 
对此：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 +上下文*一致性|主题） +（1 | vassage），mydata）;摘要（m）;方差分析（M） 
或，我应该从中减少CRI模型
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 |主题/上下文：一致性） +（1 | vassage/context/context：一致性），mydata）;摘要（m）;方差分析（M） 
对此：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 |主题/上下文：一致性） +（1 | vassage），mydata）;摘要（m）;方差分析（M） 
 Scandola＆amp;蒂多尼（Tidoni）的语言在减少模型时的语言“……可以删除最低方差的CRIS”表明我应该减少CRI模型，而不是原始的最大模型。对此有任何想法吗？
 问题2 ：如果一个实验只有1个固定效果，而最大模型会导致奇异性，那么尝试将完整的CRI模型（并在必要时减少）是否合适？ /p&gt;
因此，例如，如果以下最大模型导致奇异性：
  m＆lt;  -  lmer（rt_target〜一致性 +（1 +一致性|主题） +（1 +一致性| vassage），mydata）; ANOVA（M）;摘要（M） 
然后尝试以下类似于以下的完整CRI模型是合适的：
  m＆lt;  -  lmer（rt_target〜一致性 +（1 |主题/一致性） +（1 | vassage/Ontermentions），mydata）;摘要（m）;方差分析（M） 
我问的是Scandola＆amp; Tidoni在交叉设计的背景下讨论CRIS。我想知道CRIS是否也适用于具有1个固定效果的简单实验设计。
一如既往，我感谢您的任何反馈或建议。我在这里得到的支持刚刚出色。]]></description>
      <guid>https://stats.stackexchange.com/questions/661726/using-complex-random-intercepts-to-resolve-singularity-convergence-issues-in-lmm</guid>
      <pubDate>Sat, 22 Feb 2025 14:59:12 GMT</pubDate>
    </item>
    <item>
      <title>用于证明Q学习收敛的定理中数学术语的含义</title>
      <link>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</link>
      <description><![CDATA[我试图在这里理解定理的陈述 htttps：// apps.dtic.mil/sti/tr/pdf/ada276517.pdf ，用于证明Q学习算法的收敛性（即使定理更抽象）：
    
，但是我在理解术语的含义方面有问题。您能评论以下几点：
 1-什么是 $ x $ 在这里？是在x $ 中假设 $ x \的语句，因此，每个 $ x $ ，例如在高斯流程中？并且 $ x $ 即使没有明确提及条件1的状态空间？
 2-标准 $ || \ cdot || _W $ 在哪个设置上定义了？是在上一个集合 $ x $ 上定义的规范（在这种情况下是矢量空间）？是在基本概率空间的随机变量 $ \ omega $ 上定义的规范，让我们称其为 $ v（\ omega） ）$ ？它是否在随机过程的空间中定义了标准（我猜 $ v（\ omega）\ times x $ ）？
例如。在左侧的条件3中，规范适用于 $ e \ {f_n（x）| p_n \} $ （案例1），我将其解释为一个函数 $ x $ ，但在右边，它应用于流程 $ \ delta_n $  （情况3），所以我不确定正确的解释是什么。
感谢您帮助我澄清。该定理中似乎给予了一些设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</guid>
      <pubDate>Sat, 22 Feb 2025 11:11:23 GMT</pubDate>
    </item>
    <item>
      <title>变压器：如果值和嵌入向量不具有相同的维度，则如何完成残差连接器？</title>
      <link>https://stats.stackexchange.com/questions/661722/transformers-how-are-the-residual-connectinos-done-if-the-value-and-embedding-v</link>
      <description><![CDATA[在这篇文章中&gt;据说查询，密钥和值向量不必与嵌入相同的维度。 （&#39;他们不必较小，这是一个架构的选择，可以选择多头注意的计算（主要）恒定。＆quort;）
后来他解释了残差连接。我想知道：当嵌入和值向量没有相同的维度时，是否可以进行残差连接？那你不能添加它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/661722/transformers-how-are-the-residual-connectinos-done-if-the-value-and-embedding-v</guid>
      <pubDate>Sat, 22 Feb 2025 10:52:52 GMT</pubDate>
    </item>
    <item>
      <title>结合非独立概率指标</title>
      <link>https://stats.stackexchange.com/questions/661721/combining-non-independent-probability-indicators</link>
      <description><![CDATA[ i有n指标，每个事件都发生了，每个事件都具有关联的概率
  indies_a-＆gt; 0.1
indionator_b-＆gt; 0.7
indionator_c-＆gt; 0.5
 
 i还具有一个相关矩阵，该矩阵描述了每对指标的相关性。
我想计算事件发生的总体概率。
我有一个想法（但我不确定它是正确的）：
  p（e）≈w_a.p（a） + w_b.p（b） + w_c.p（c）

w_a = 1 + p（a，b） + p（a，c） / z
w_b = 1 + p（a，b） + p（b，c） / z
w_c = 1 + p（a，c） + p（b，c） / z

z = w_a + w_b + w_c
 
其中p（a，b）可能是从相关矩阵中得出的一定程度。

如果有一种正式的方法可以做到这一点，那就太好了。但是粗糙的近似也可以。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661721/combining-non-independent-probability-indicators</guid>
      <pubDate>Sat, 22 Feb 2025 10:09:07 GMT</pubDate>
    </item>
    <item>
      <title>适度分析假设：居中后单变量异常值</title>
      <link>https://stats.stackexchange.com/questions/661716/moderation-analysis-assumption-univariate-outliers-after-centering</link>
      <description><![CDATA[我正在为我的论文进行适度分析，并正在进行假设测试。
我发现了一些单变量异常值，并改变了所有Z分数的分数＆gt; （ - ）3.29。然后，我继续查看多重共线性，该性是根据TOL和VIF统计侵犯的。我手动以中心的变量为中心（这样做），但是现在我获得了casewise Diagnostics表显示单变量异常值 - 并确认了Z分数的4个单变量异常值。
我是否忽略了这些案例，因为我已经在初始检查中纠正了单变量异常值？还是我需要改造这些分数，然后再进行节制？
欢迎任何建议或文献！]]></description>
      <guid>https://stats.stackexchange.com/questions/661716/moderation-analysis-assumption-univariate-outliers-after-centering</guid>
      <pubDate>Sat, 22 Feb 2025 03:02:41 GMT</pubDate>
    </item>
    <item>
      <title>使用coxph（）中的样条时间转换计算危险比的95％C.I.S</title>
      <link>https://stats.stackexchange.com/questions/661714/calculating-95-c-i-s-for-hazard-ratios-using-a-spline-time-transform-in-coxph</link>
      <description><![CDATA[我想通过 tt（）在 coxph（ ）模型，是正确的。假设您有非比例危害，因此您可以通过旋转的时间相互作用放松在有问题的变量上的假设。然后，您有兴趣能够在特定的观察时间计算该变量的HR。使用 nsk（）变换为您在设置打结位置的特定时间时为您提供系数/HR，相对  （如果我已经正确理解） 。
我在时间依赖时间依赖Vignette的Vignetten （第23页）。对我来说没有意义的一件事是行：

如果ns使系数是结的预测值，则NSK函数是一个变体
2，3，...-结1 的预测值

如果我在下面的代码中减去系数，那似乎是不对的，但是如果我添加它们确实可以（也许我已经误解了）。
无论如何，要在每个结位置获得s.e.s，我将此页面。有人可以建议我的基本计算是否正确吗？它们似乎通过凝视很有意义。
我唯一的其他问题是类似的参数术语（而不是设置通用 df = 3 （例如），如果您有兴趣在某些时间获得HR，而不是自然设置在那个时间的结节，这可能不是最佳的结位/分配（例如，您可以设置比最佳拟合所需的打结）。行动？
 库（生存）
图书馆（整洁）
＃加载退伍军人数据，然后将TRT转换为数字，并使用参考CAT = 0
Vdata1＆lt;  - 老兵
vdata1  $ trt＆lt;  -  as.numeric（vdata1 $  trt） -  1
vdata1 $ id＆lt;  -  seq（1：dim（vdata1）[1]）
vdata1＆lt;  -  vdata1 |＆gt; 
  选择（id，afterts（））

＃++++++++++++++++++++++++++++++++++++ +++

＃计算固定结的HR
vfit1＆lt;  -  coxph（surv（时间，状态）〜trt + tt（trt），tt =函数（x，t，...）x * nsk（t，knots = c（5，100，100，200，300，300， 400，500），boundard.knots = false），vdata1）
摘要（VFIT1）

＃时间= 100的HR（在日志刻度上添加系数）
＃1。结2的预测值 - 结1的预测值
EXP（0.1536-0.1461）＃= 1.007528
＃2。这似乎不正确，而是添加系数
EXP（0.1536+0.1461）＃= 1.349454
＃3。时间= 100（在指数尺度上乘以HR））
1.1573 * 1.1660＃= 1.349412
＃2。和3。现在同意

＃时间= 200（在日志刻度上添加系数）
＃1。结2的预测值 - 结1的预测值
EXP（-1.3714-0.1461）＃= 0.2192594
＃2。这似乎不正确，而是添加系数
EXP（-1.3714+0.1461）＃= 0.2936696
＃3。时间= 200（在指定刻度上乘以HRS）
1.1573 * 0.2537＃= 0.293607
＃2。和3。现在同意

＃计算时间= 100
VCOV（VFIT1）
SQRT（0.12950242 + 0.32909021 + 2*-0.17118702）＃= 0.3409085
＃时间上的95％限制= 100
EXP（0.1461 + 0.1536 + 1.96 * SQRT（0.12950242 + 0.32909021 + 2 * -0.17118702））＃= 2.63236
＃时间降低95％的限制= 100
EXP（0.1461 + 0.1536-1.96 * SQRT（0.12950242 + 0.32909021 + 2 * -0.17118702）＃= 0.6917846
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661714/calculating-95-c-i-s-for-hazard-ratios-using-a-spline-time-transform-in-coxph</guid>
      <pubDate>Sat, 22 Feb 2025 01:34:21 GMT</pubDate>
    </item>
    <item>
      <title>我的数据适合混合模型吗？</title>
      <link>https://stats.stackexchange.com/questions/661711/is-my-data-suitable-for-mixed-model</link>
      <description><![CDATA[我有5年在美国3个州的10家商店中观察到的300种产品的每日价格（纵向）数据。 2个州有3个商店，一个州有4个商店。我试图了解什么是随机和固定效应。预测变量是一个虚拟变量，它指示是否已在一个州实施了特定的策略，并且在每年发生的某些事件/国家假期中是否已在某个州实施了一个虚拟策略。我想考虑到州之间的变化，但有问题：
只有3个州 - 必须将州视为固定效应。
商店嵌套在状态下（即每个商店仅出现在一个状态下），并且产品交叉。
国家和政策假人之间的完美共线性。我不确定如何在模型中处理状态。我应该：
将产品与其他预测变量一起以固定效果为固定效果，将产品嵌套在状态中，并将其作为固定效果？
价格〜政策虚拟 +事件虚拟 +时间 +时间 +策略虚拟*事件虚拟 +状态 +（1 | product） +（1 |商店\ state）。商店嵌套在状态下，但产品在商店中交叉/非嵌套吗？是可以的吗？
或2）在上述模型中删除状态为固定效果
或3）仅将产品和存储作为模型中的随机效应以1）为1），同时排除了fe状态，因为它将与政策虚拟的完美。
这也是多级模型吗？我对术语感到困惑，无法决定我的数据中的级别。混合和多级相同的IE第一个空模型的建模步骤，然后检查固定的或随机的斜率以及完整的模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661711/is-my-data-suitable-for-mixed-model</guid>
      <pubDate>Sat, 22 Feb 2025 00:43:29 GMT</pubDate>
    </item>
    <item>
      <title>自我注意力的输出</title>
      <link>https://stats.stackexchange.com/questions/661710/output-of-self-attention</link>
      <description><![CDATA[我的问题是关于注意的，如果我们从 $ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 是我们应该将数量添加到令牌的原始嵌入中，还是新嵌入？
 首先说明： 
在3blue1brown的这段视频中，他解释了注意力。
  https://www.youtube.com/watch?v=emlx5ffnoyc&amp;ab_channel=3blue1brown1brown  
在加利福尼亚州。 13:14他解释说，他对注意力的关注：注意力的重量告诉我们我们将要更新嵌入方式。例如，如果我们拥有ITH和jth令牌，我们将添加 $（q_i \ cdot k_i）v_j $ 添加到ITH代币的嵌入中。其中 $ v_j = w^vx_j $ ， $ x_j $ 是 $ j $ &#39;Th Token。
  $ \ delta $   - 以15:32的方式看到。
 第二个解释： 
在我看来，在我看来，输出是 $ v_k $ 的线性组合，那就是新嵌入者本身 $ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 。因此， $ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 不仅是我们添加到oridingal嵌入中的东西，它是新嵌入。
 我的问题： 
 is  $ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）要获得新的嵌入？我误解了什么吗？似乎我会说两个不同的消息。
陈述了另一种方式：如果我们有一个嵌入 $ \ textbf {x} _i $ 是新的嵌入式 $（ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）_i $ 或 $ \ textbf {x} _i+（softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）v）_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661710/output-of-self-attention</guid>
      <pubDate>Sat, 22 Feb 2025 00:27:14 GMT</pubDate>
    </item>
    <item>
      <title>关于比较三个不同小组评分的问题</title>
      <link>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</link>
      <description><![CDATA[我目前正在比较三个群体之间的职业障碍：学生，教职员工和行业专业人员。尽管我使用李克特量表的同一调查问卷（例如，“在决定职业时工作满意度很重要”），但我注意到与其他两个群体相比，行业参与者的反应通常更为负面。例如，学生的平均评分为6.2/7，教职员工的平均评分为6.1/7，在所有调查项目中的行业专业人员的平均评分为4.89/7。。
鉴于这些基线差异，我担心简单的均值比较可能不会产生有意义的见解。取而代之的是，我正在考虑专注于排名（例如，确定哪些障碍对学生与行业专业人员最重要）。在这种情况下，使用最合适的分析方法是什么？
我记得看到一篇有类似方法的论文，但是尽管进行了数小时的搜索，但我还是找不到它。任何人都知道有类似方法的好论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</guid>
      <pubDate>Fri, 21 Feb 2025 16:30:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同聚集/粒度水平下的时间序列数据的经验估计标准偏差和变异系数？</title>
      <link>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</link>
      <description><![CDATA[我正在与2024年9月19日至11月19日的图书馆建筑物收集的时间序列建筑物占用数据。每5分钟，使用Motion（PIR）传感器（总共450张椅子）记录每5分钟的数据。然后将数据重新采样至30分钟的间隔（2689个数据点），并在不同级别进行汇总：
椅子级别：450椅→1,210,050个数据点（450*2689）
表级：50个表→134,450数据点（50*2689）
子区域级别：6个子区域→16,134个数据点（6*2689）
区域级别：2区→5,378个数据点（2*2689）
 客观：我旨在使用两个关键指标（即标准偏差（SD）（SD）和变异系数（CV），在不同水平的粒度（椅子，桌子，子区域和区域）处量化可变性。 。
在较小的级别（例如椅子级）下，我有更多的观察结果（更高的数据点，而在更粗的水平（例如区域级别）下，样本量明显较小。
我的主要问题是
 1-当每个粒度水平的数据点总数显着差异时，我如何从经验上估计SD，CV进行公平比较？我已经计算了原始SD，而没有考虑到不平等的观察数（请参阅附件图）每小时标准偏差的箱形图表所有粒度级别” src =“ https://i.sstatic.net/vok57dth.jpg”/&gt; 。
数据集附加在此处
考虑不平等的数据点，可以用来估算SD的任何见解，参考或方法将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</guid>
      <pubDate>Fri, 21 Feb 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>我是否了解主教的主教？</title>
      <link>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</link>
      <description><![CDATA[主教将A 定义参数满足以下内容，
 $$
p（x | \ mu）= f（x- \ mu）。
$$ 
他想定义“不信息先验”对于 $ {\ MU} $ 对于贝叶斯推理。如果我没记错的话，那是他想利用以下不变性，
 $$
\ wideHat {x}：= x + c \ leadsto p（\ wideHat {x} | \ wideHat {\ mu}）= p（x | \ mu），
$$ 
我们定义了 $ {\ wideHat {\ mu} = \ mu+c} $ 。这是我想验证我理解的阶段：他本质上想定义先前的 $ {p（\ mu）} $ ，以便我们具有以下后代：
 $$
p（\ wideHat {\ mu} | \ wideHat {x} _1，...，\ wideHat {x} _n）= p（\ mu | x_1，...，...，x_n）。
$$ 
他并没有这样说，所以这就是为什么我想检查我本质上理解这个想法的原因。如果您继续这个想法，则最终会以 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ ，并且由于选择了 $ {c} $ 是任意的，您最终会 $ {p（\ mu）= \ text {const。}} $  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</guid>
      <pubDate>Fri, 21 Feb 2025 12:12:55 GMT</pubDate>
    </item>
    <item>
      <title>$ \ boldsymbol \ mu $ $ \ lvert \ lvert \ boldsymbol \ mu \ mu \ mu \ rvert = 1 $时，mle的渐近方差</title>
      <link>https://stats.stackexchange.com/questions/661647/asymptotic-variance-of-mle-of-boldsymbol-mu-when-lvert-boldsymbol-mu-rv</link>
      <description><![CDATA[假设 $（x_1，y_1），\ ldots，（x_n，y_n）$ 是来自双变量正常 $ n_2（\ boldsymbol \ mu，i_2）$ 分布 $ \ lvert \ boldsymbol \ mu \ rvert = 1 $ 。令 $ \ wideHat {\ boldsymbol \ mu} $ 是 $ \ boldsymbol \ mu $ $ $ 的mle。我如何获得 $ \ widehat {\ boldsymbol \ mu} $ 数字上的渐近方差的估计值？？
我认为 $ \ wideHat {\ boldsymbol \ mu} = \ frac {\ edrace {\ overline {\ boldsymbol z}}}} {\ lvert \ lvert \ edrover \ edrows {\ boldsymbol z} ，其中 $ \叠加{\ boldsymbol z} $ 是 $ \ boldsymbol z_i =（x_i，y_i）$ 的平均值， $ i = 1,2，\ ldots，n $ 。
 is  $ \ wideHat {\ boldsymbol \ mu} $ 仍然渐变地正常，这样我就可以将MLE的观察到信息矩阵的倒数用作一个大的信息矩阵差异的样本估计值？我们可以通过写作 $ \ boldsymbol \ mu =（\ cos \ cos \ cos \ theta ，\ sin \ theta）$ ，但不确定是否有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661647/asymptotic-variance-of-mle-of-boldsymbol-mu-when-lvert-boldsymbol-mu-rv</guid>
      <pubDate>Thu, 20 Feb 2025 19:03:39 GMT</pubDate>
    </item>
    <item>
      <title>参数方法绕过计算关节分布？</title>
      <link>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</link>
      <description><![CDATA[如果我想使用平方损耗函数解决ML问题，那么最佳预测因子是 $ \ Mathbb {e} [y \ mid x] $  &lt;&lt;&lt;。 /p&gt;
有两种计算方法 $ \ Mathbb {e} [y \ mid x] $ 。我们要么平镇 $ \ Mathbb {p} _ {x，y} $ 是关节分布，要么假设 Mathbb {e} [y \ mid x] $ 是一个函数 $ f $   $ n $ 参数： $ p_i $ 。
如果我没记错的话，第一个解决方案是局部平均方法尝试在ML中使用的方法，例如K-NN，树。在第二种情况下，这是线性回归和神经网络尝试做的。
因此，参数方法不使用联合分布来计算 $ \ mathbb {e} [y \ mid x] $ ，假设贝叶斯预测器具有一个他们解决的某些机构形式。
但这意味着这些模型无法计算 $ \ text {var}（y \ id x）$ ，因为我们只是训练该模型以解决&lt;&lt; SPAN class =“ Math-Container”&gt; $ \ Mathbb {e} [y \ mid x] $ 。
我的理解正确吗？因此，我们可以得出结论，如果样本的数量很高，则本地平均方法是优越的，因为它们为我们提供了有关该问题的更多信息（有关 $ \ Mathbb {p} _ { x，y} $ 可以帮助我们计算更多的指标，而不是 $ \ Mathbb {e} [y \ mid x] $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</guid>
      <pubDate>Thu, 20 Feb 2025 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>基于过渡概率的聚类</title>
      <link>https://stats.stackexchange.com/questions/661254/clustering-based-on-transition-probabilities</link>
      <description><![CDATA[我有工人职业历史的面板数据，其中每个工人的职业在每个时间段都被指示。我希望将职业聚集在一起。这个想法是在同一集群中的职业之间建立群集。
例如，如果许多工人从数据科学家转换为计算机科学家，反之亦然，这两个职业可能处于同一集群中。
我知道序列聚类，但这会根据工人的职业历史而不是职业聚类。
问题：什么是（）将职业分为组的方式？]]></description>
      <guid>https://stats.stackexchange.com/questions/661254/clustering-based-on-transition-probabilities</guid>
      <pubDate>Tue, 11 Feb 2025 22:08:45 GMT</pubDate>
    </item>
    <item>
      <title>r中的重量参数glm</title>
      <link>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</link>
      <description><![CDATA[我有一个心理物理学实验，我正在测量参与者是否可以基于对比度看到刺激。
我有两个用于物流回归的选项。 1）使用原始数据（0和1）指示它们是否看到了刺激。
但是，我将分析基于分析的论文运行了二项式（概率）GLM，这是考虑到假阳性速率的转换数据。因此，选项2）是遵循该论文并具有结果变量为0到1的值。。
 i然后有较少的数据点，因为它们会根据刺激参数折叠以提供转换后的结果变量。
所以问题是：我可以使用R的GLM中的权重参数来指定每个转换的数据点表示多少个试验？
很抱歉长期解释，但我认为某些背景是相关的。
我已经尝试了这两个选项，并且使用了不重量的转换结果变量，并且它们都产生不同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</guid>
      <pubDate>Tue, 11 Feb 2025 12:10:09 GMT</pubDate>
    </item>
    </channel>
</rss>