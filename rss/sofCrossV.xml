<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 10 Mar 2024 18:14:48 GMT</lastBuildDate>
    <item>
      <title>长期和短期面板因果关系</title>
      <link>https://stats.stackexchange.com/questions/642269/panel-causality-relationship-in-long-run-and-short-run</link>
      <description><![CDATA[当我想估计面板数据的长期和短期变量之间的因果关系时，应该使用什么计量经济学？面板VAR、面板VECM或面板ADRL等模型是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/642269/panel-causality-relationship-in-long-run-and-short-run</guid>
      <pubDate>Sun, 10 Mar 2024 17:22:02 GMT</pubDate>
    </item>
    <item>
      <title>统一来自同一模型但具有不同假设的预测</title>
      <link>https://stats.stackexchange.com/questions/642268/unifying-predictions-from-the-same-model-but-with-differing-assumptions</link>
      <description><![CDATA[我正在使用相同的数据集，并且正在探索几种对其进行建模的方法。每个模型都应用相同的模型，但在不同的假设下运行，例如：

平稳性与非平稳性
对数转换数据与非对数转换数据
集群极端与非集群极端

鉴于这些变化，每个模型自然会产生不同的点预测，因为它们对数据集进行不同的转换。我正在寻求有关如何系统地量化这些不同的预测并可能将这些不同的预测整合到统一的预测框架中的建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642268/unifying-predictions-from-the-same-model-but-with-differing-assumptions</guid>
      <pubDate>Sun, 10 Mar 2024 16:30:06 GMT</pubDate>
    </item>
    <item>
      <title>我可以对具有 1 个自变量和 2 个因变量的实验数据运行什么统计检验？</title>
      <link>https://stats.stackexchange.com/questions/642265/what-statistical-test-can-i-run-on-data-from-an-experiment-with-1-independent-va</link>
      <description><![CDATA[为了说明我的学术水平，我是一名高中生。对于实验室报告，我需要进行统计测试来验证我的结果。我所做的是改变抑制剂的浓度（2%、4%、6%、8%、10%），看看这如何影响酶的活性。本质上，这是一种放热反应，意味着抑制剂浓度越高，释放的热量就越少。此外，当酶通常分解其底物时，它会释放出一种酸，从而改变溶液的 pH 值。但更多的抑制剂意味着更少的酸。
我已经计算了初始温度/pH 和最终温度/pH。然后减去这些值即可得到温度/pH 值的变化。对于每个浓度，我进行了 6 次试验。我想我可以获得温度/pH 值的平均变化，这样会更好。
那么什么样的统计测试是合适的呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/642265/what-statistical-test-can-i-run-on-data-from-an-experiment-with-1-independent-va</guid>
      <pubDate>Sun, 10 Mar 2024 16:09:50 GMT</pubDate>
    </item>
    <item>
      <title>计算给定分布中的经验 Beta [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642261/computing-empirical-beta-in-a-given-distribution</link>
      <description><![CDATA[我必须计算经验β并将其与理论β进行比较测量差异。这是开发新代码的模型：
if (!require(&quot;pwr&quot;)) install.packages(&quot;pwr&quot;)

＃ 参数
N=1000
人数 = 25
k = 500
a_teo = 0.05

# 在这里我们创造了宇宙
波布拉西翁 &lt;- rnorm(N, 10, 10)
m.pob &lt;- 平均值(poblacion)
sd.pob &lt;- sd(poblacion)

# 数据模拟和 p.values 存储
p &lt;- 向量（长度=k）
对于 (i in 1:k){
 muestra &lt;- poblacion[样本(1:N, n)]
 p[i] &lt;- t.test(muestra, mu=15)$p.value
}

# 经验测试版
beta_emp &lt;- 长度(p[p&gt;a_teo])/k

# 理论测试版
d=(10 - 15) / sd.pob
beta_teo &lt;- 1 - pwr.t.test(n,
                           d=d,
                           sig.level=a_teo,
                            类型=“one.sample”）$power
# 打印理论与经验赌注
sprintf(“beta_teo = %.3f -- beta_emp = %.3f -- Diff = %.3f”, beta_teo,
         beta_emp、beta_teo-beta_emp)

使用前面的内容作为参考，我必须运行一个非“正态”分布的模拟，而是仅具有 (2, 3, 4, 5) 范围内的值并进行测量经验贝塔值和理论贝塔值之间的差异。这是我的代码：
if (!require(&quot;pwr&quot;)) install.packages(&quot;pwr&quot;)

N=1000
人数 = 25
k = 500
a_teo = .05

poblacion &lt;- 样本(2:5, N, 替换 = TRUE)
m.pob &lt;- 平均值(poblacion)
sd.pob &lt;- sd(poblacion)

p &lt;- 向量（长度=k）
for (i in seq_along(p)){
  muestra &lt;- 样本(2:5, N, 替换 = TRUE)
  p[i] &lt;- t.test(muestra, mu=m.pob)$p.value
}

# 经验测试版
beta_emp &lt;- 长度(p[p&gt;a_teo])/k

# 理论测试版
d=(10 - m.pob) / sd.pob
beta_teo &lt;- 1 - pwr.t.test(n,
                           d=d,
                           sig.level=a_teo,
                           类型=“one.sample”）$power
sprintf(“beta_teo = %.3f -- beta_emp = %.3f -- Diff = %.3f”, beta_teo,
         beta_emp、beta_teo-beta_emp)

问题是我得到“零”作为理论贝塔值。有人能告诉我问题出在哪里吗？ “10”值是示例中的平均值，因此可能应该对此进行更改。]]></description>
      <guid>https://stats.stackexchange.com/questions/642261/computing-empirical-beta-in-a-given-distribution</guid>
      <pubDate>Sun, 10 Mar 2024 14:49:35 GMT</pubDate>
    </item>
    <item>
      <title>调查分析中的卡方检验不一致（这是什么意思！）</title>
      <link>https://stats.stackexchange.com/questions/642259/chi-squared-test-inconsistencies-in-survey-analysis-what-does-it-mean</link>
      <description><![CDATA[我是一名高等教育学生，我已经完成了一项针对高等教育学生的政治抱负调查，以性别和学习科目为自变量，看看学习政治是否会减少性别差距。
我完成了卡方测试，因为我的数据集是分类的
性别=男、女
政治=是、否
政治野心=是、否、也许
我的第一个问题着眼于过去的抱负，性别在这里并不具有统计意义，但政治是（合乎逻辑的）。
尽管如此，当我对非政治男性与非政治女性进行卡方检验时，X2 低于临界值（X2 = 3.0222，临界值 = 5.99），因此观察到的分布与预期分布之间的差异并不明显统计上显着。然而，Pr 值为 0。p 值为 0 表明有强有力的证据反对原假设，表明变量之间存在显着关联。
这里发生了什么？我很困惑为什么这在静态上既不显着又显着。
如有任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/642259/chi-squared-test-inconsistencies-in-survey-analysis-what-does-it-mean</guid>
      <pubDate>Sun, 10 Mar 2024 14:09:50 GMT</pubDate>
    </item>
    <item>
      <title>被高斯噪声破坏的均匀分布的估计</title>
      <link>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</link>
      <description><![CDATA[问题定义
我有一个由 $m$ 观测值 $y^{(1)},\dots,y 组成的数据集^{(m)} \in \mathbb{R}^2$ 生成如下
\begin{方程*}\begin{对齐}
y &amp;= z + v \换行符
z&amp; \sim\mathcal{U}([a,b]) \换行符
v&amp; \sim\mathcal{N}(0_{2\times1}, \sigma_v^2 I_2)
\结束{对齐}
\end{方程*}
这里 $z$ 均匀分布在连接顶点 $[\begin{array}{cc}a &amp; 的线上。 0 \end{array}]$, $[\begin{array}{cc}b &amp; 0\end{array}]$ 与 $b&gt;a$，而 $v$ 是具有各向同性协方差的零均值高斯变量 $\sigma_v^2 I_2$ ($I_2$是 $2\times 2$ 单位矩阵）。两个组件 $z$ 和 $v$ 是独立的。
给定数据集$y^{(1)},\dots, y^{(m)}$，我想估计参数$a$ 和 $b$ 定义生成 $z 的段$.
我的尝试
对于 $\sigma_v\triangleq 0$，即没有高斯噪声，如果我没记错的话，$a$ 和 $b$ 应该是
\begin{方程}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} \newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{数组}] y^{(j)}
\结束{对齐}
\标签{$\星星$}
\end{方程}
现在，如果 $\sigma_v$ 是“小”与段长度 $b-a$ 相比，那么上面的估计应该效果很好。随着 $\sigma_v$ 与 $b-a$ 变得相当，我预计估计精度会下降。
我正在考虑一种启发式修正如下
\begin{方程*}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} +\sigma_v\newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} -\sigma_v
\结束{对齐}
\end{方程*}
因为由于高斯噪声 $v$，最小值和最大值可能会超过 $a$ 和 $b$。
问题
我的解决方案远非严格，我什至不确定它是否有意义。我的问题如下：

基于一些可靠的原则，是否可以修正估计 $(\star)$ 以考虑 $v$?
如果我的方法不起作用，我们如何估算$a$、$b$？&lt; /里&gt;
]]></description>
      <guid>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</guid>
      <pubDate>Sun, 10 Mar 2024 11:22:56 GMT</pubDate>
    </item>
    <item>
      <title>求加权数据的累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/642251/finding-cumulative-distribution-function-of-weighted-data</link>
      <description><![CDATA[我有人口普查区数据，其中每行保存人口规模和变量值（例如收入）。我想绘制真实人口的累积分布函数（CDF），即考虑每个地区的人口规模。
因此，如果我的数据有约 3000 个人口普查区，则总人口约为 800 万。
我尝试将数据转换为长形式，但结果是一个非常大的DF，很难绘制和分析（我的真实数据有十年的数据，因此它创建了一个具有8000万行的DF）。&lt; /p&gt;
这是示例数据和我尝试过的长格式版本：
df = data.frame(PopSize = rnorm(20,1000,300),
                收入 = rnorm(20,100,30))
df_long = df[rep(seq_len(nrow(df)), times=df$PopSize),]

这会将 20 行（每行样本大小约为 1000）转换为具有约 20,000 行的 DF，这使得在我的约 800 万实际数据中使用变得不切实际。
有没有办法创建一个 CDF 图来说明每行中的样本大小？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/642251/finding-cumulative-distribution-function-of-weighted-data</guid>
      <pubDate>Sun, 10 Mar 2024 09:14:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我能够将观测值的总和除以观测值的数量以获得平均值和正面概率？</title>
      <link>https://stats.stackexchange.com/questions/642244/why-am-i-able-to-divide-the-sum-of-observation-values-by-the-number-of-observati</link>
      <description><![CDATA[我们每天都使用算术平均值来计算样本平均值来估计总体的平均值，例如正态分布。此外，我们还计算平均值来找出抛硬币时正面落地的概率。在这里，我想知道我们如何知道我们可以将正面总和（HEADS = 1，TAILS = 0）除以抛硬币的次数，以获得一次试验或一系列试验后正面朝上的概率。我已经学会了计算平均值的方法，但我想知道我们如何找到计算平均值以及在一次试验或一系列试验后出现正面概率的方法。我只是想知道这有什么数学背景。]]></description>
      <guid>https://stats.stackexchange.com/questions/642244/why-am-i-able-to-divide-the-sum-of-observation-values-by-the-number-of-observati</guid>
      <pubDate>Sun, 10 Mar 2024 02:37:06 GMT</pubDate>
    </item>
    <item>
      <title>平稳性对于弹性网络回归的预言属性的重要性？</title>
      <link>https://stats.stackexchange.com/questions/642237/the-importance-of-stationarity-for-the-oracle-property-of-elastic-net-regression</link>
      <description><![CDATA[我已经寻找了一段时间，但不幸的是，在寻找深入探讨非平稳性对弹性影响的理论推导或模拟的论文或书籍时，我仍然空手而归。净回归。有没有人偶然发现讨论这个特定主题的资源？任何相关论文或书籍的指示将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/642237/the-importance-of-stationarity-for-the-oracle-property-of-elastic-net-regression</guid>
      <pubDate>Sat, 09 Mar 2024 20:23:24 GMT</pubDate>
    </item>
    <item>
      <title>这个谬误的名称以及如何得出结论</title>
      <link>https://stats.stackexchange.com/questions/642144/name-of-this-fallacy-and-how-to-reach-conclusion</link>
      <description><![CDATA[在处理一些人口统计数据时，我陷入了一个无法得出结论的境地（我没有透露实际的数据集以及它涉及的对象，因此我用假设的数据代替它）。

假设我们有两类人； A和B。
我们有两种意识形态/政治观点：Alpha 和 Beta。

确定或加入的个人会员数量如下：
$$\begin{array}{c|c|c|}
 &amp; \text{意识形态-阿尔法} &amp; \text{ 意识形态测试版} \\ \hline
\text{A 组} &amp; 90&amp; 10 \\ \h行
\text{B 组} &amp; 70&amp; 30 \\ \h行
\end{数组}$$
在这种情况下； 新闻来源 1 将数据解释为
&lt;块引用&gt;
“B 组中只有30% 的成员代表意识形态-Beta。 B组成员不想要意识形态Beta”

另一个新闻来源 2 将数据解释为
&lt;块引用&gt;
“大约75%隶属于Ideology Beta成员，得到B组的支持，因此Ideology Beta包含了所属人员的权利和要求到社会类别B组”。

现在，我的问题是；哪一个来源值得信任？使用完全相同的民意调查，两个消息来源产生了截然不同的叙述，这令人难以置信的混乱。这两种计算在技术上都是正确的，并且可能部分地显示了事实的不同方面。但我该如何重建真实的故事或从这些数据中得出结论呢？哪一个来源有偏见？或者两种表述都有偏见？这种偏见的名称或文档是什么？
额外问题：
表示此类数据的适当模式应该是什么？
礼貌：我已从此处复制代码以格式化表格https://math.meta.stackexchange.com/questions/4240/how-do-i-insert-a-table-when-asking-a-question]]></description>
      <guid>https://stats.stackexchange.com/questions/642144/name-of-this-fallacy-and-how-to-reach-conclusion</guid>
      <pubDate>Fri, 08 Mar 2024 12:52:31 GMT</pubDate>
    </item>
    <item>
      <title>查看泊松回归是否遵循必要的假设</title>
      <link>https://stats.stackexchange.com/questions/641830/seeing-if-a-poisson-regression-follows-the-necessary-assumptions</link>
      <description><![CDATA[我试图了解当残差没有精确分布时，模拟如何在检查模型假设方面发挥作用。
我采用了这个泊松回归模型：
$$\lambda_i = e^{(\beta_0 + \beta_1X_i)}$$
$$P(Y_i | X_i) \sim Poisson(\lambda_i = e^{(\beta_0 + \beta_1X_i)})$$
如何查看模型假设是否得到满足？
我想到了一些想法：

方法 1：我可以引导数据，在每个引导样本上拟合模型。如果满足模型假设 - 在每个 $x_i$ 处：所有 bootstrap 样本的残差分布的平均值为 0，方差为 $\lambda_i$。 （这种方法似乎是计算量最大的方法，因为正在拟合多个模型）

方法 2：我将模型拟合到原始数据上，然后从模型中模拟新数据集...并比较所有真实的 $Y$ 与模拟的 $Y$。如果满足模型假设，则模型将能够非常接近地“再现”模型。观察到的数据。 （我不知道如何衡量所有 $x_i$ 的“接近度”）。这种方法似乎工作量较少，因为只适合一个模型。

方法 3（DHARMA 方法 https:/ /cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html)：我将模型拟合到原始数据上。拟合模型后，我在每个 $x_i$ 处生成多个 $y_i$ 值。对于给定的 $x_i$ ，我制作了模拟的 $y_i$ 的经验 CDF。对于在 $x_i$ 处实际观察到的 $y_i$，我找出了这个 $y_i$ 位于 CDF 上。如果模型很好地拟合数据，则此 $y_i$ 应该处于 50% 的水平（我不确定为什么 - 这是因为残差具有均匀分布吗？ ）。然后，我对每个 $x_i$ 重复此经验 CDF，并平均查看真实的 $y_i$ 是否为平均每个 CDF 接近 50% 的水平。 （这种方法也只涉及拟合一个模型）


这 3 种方法都正确吗？当残差不具有精确分布时，这是正确使用模拟来验证模型假设的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641830/seeing-if-a-poisson-regression-follows-the-necessary-assumptions</guid>
      <pubDate>Mon, 04 Mar 2024 22:10:10 GMT</pubDate>
    </item>
    <item>
      <title>使用经典误差计算而不是 PI 指标来评估上限预测结果</title>
      <link>https://stats.stackexchange.com/questions/639190/evaluate-upper-bound-prediction-results-using-classic-error-calculation-instead</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/639190/evaluate-upper-bound-prediction-results-using-classic-error-calculation-instead</guid>
      <pubDate>Tue, 13 Feb 2024 14:28:39 GMT</pubDate>
    </item>
    <item>
      <title>标准差在此数据集中到底意味着什么？我如何在另一个数据集中生成它？</title>
      <link>https://stats.stackexchange.com/questions/546992/what-exactly-does-standard-deviation-mean-in-this-dataset-and-how-do-i-go-about</link>
      <description><![CDATA[我正在尝试向 R 中的箱线图添加误差线。我需要 sd/se 以及我能找到的所有说明，我可以理解这些数据集已经计算出 sd/se 的数据集，如下所示：

我的数据集的设置方式与此数据集相同，但我对“sd”的含义感到困惑和“se”列指的是以及如何根据我自己的数据计算它们以生成该列？]]></description>
      <guid>https://stats.stackexchange.com/questions/546992/what-exactly-does-standard-deviation-mean-in-this-dataset-and-how-do-i-go-about</guid>
      <pubDate>Mon, 04 Oct 2021 18:14:04 GMT</pubDate>
    </item>
    <item>
      <title>如何用交叉熵损失处理策略梯度中的负奖励</title>
      <link>https://stats.stackexchange.com/questions/536047/how-to-deal-with-negative-rewards-in-policy-gradient-with-crossentropy-loss</link>
      <description><![CDATA[在策略梯度强化学习中，我们可以使用 -log(P)*reward 形式的损失函数，其中 P 是给定条件下所选动作的概率政策。对于离散操作，这会变成categorical_crossentropy：
损失= categorical_crossentropy（chosen_action，policy_output）*奖励

有些人似乎认为这对于负面奖励来说没什么问题，但其他人则不然。在应用中，我看到的问题是可能会造成巨大的负损失。如果奖励是-1.0，那么损失就是无限负的。如果可以将所选操作的策略推至接近于零，则损失可能接近于负无穷大。对于 +1.0 的奖励，损失只能降至零。我认为这种不对称是有问题的。
应该如何管理？]]></description>
      <guid>https://stats.stackexchange.com/questions/536047/how-to-deal-with-negative-rewards-in-policy-gradient-with-crossentropy-loss</guid>
      <pubDate>Mon, 26 Jul 2021 17:01:49 GMT</pubDate>
    </item>
    <item>
      <title>滞后/超前变量</title>
      <link>https://stats.stackexchange.com/questions/524821/lag-lead-variables</link>
      <description><![CDATA[我有一个与时间序列分析中的变量相关的简单问题。
我正在使用面板固定效应回归来查看工具发行对公司业绩的影响。我感兴趣的自变量是一个固定问题虚拟变量（1 = 问题；0 = 不问题）。在第一个回归中，我对所有变量使用年份 $t$ 来查看效果。但我想看看发行一年后对公司业绩的影响。
在这种情况下，滞后自变量是否正确？或者，我应该将因变量领先一年吗？而且，如果我主导因变量，我是否也应该主导我的自变量，除了感兴趣的变量（虚拟变量）之外？]]></description>
      <guid>https://stats.stackexchange.com/questions/524821/lag-lead-variables</guid>
      <pubDate>Tue, 18 May 2021 16:01:39 GMT</pubDate>
    </item>
    </channel>
</rss>