<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 08 Mar 2025 12:24:41 GMT</lastBuildDate>
    <item>
      <title>估计概率与原始二元结果的分段回归</title>
      <link>https://stats.stackexchange.com/questions/662340/segmented-regression-on-estimated-probabilities-vs-raw-binary-outcome</link>
      <description><![CDATA[我正在对R进行分段回归分析，并希望确认我的方法是否在统计上有效。我首先使用天然花键拟合逻辑回归模型来预测二进制结果。然后，我使用这些估计的概率作为结果估算了独立变量不同值的预测概率，并拟合了准级GLM。最后，我将分段（）函数应用于第二个模型，而不是原始的逻辑回归模型。这种方法是否有效，还是应使用原始二进制结果在初始模型上进行分段回归？分割估计的概率会导致不正确的断点估计吗？
 库（dplyr）
图书馆（花键）
图书馆（Marginaleffects）
图书馆（ggplot2）
图书馆（分段）

d＆lt;  -  my_dataset

d  $ binary_outcome＆lt;  - 因子（d $  binary_outcome）

fit＆lt;  -  glm（binary_outcome〜splines :: ns（x_axis_variable，df = 5，intercept = t），
           数据= D，
           family =“二项式”

values＆lt;  -  with（d，seq（d  $ x_axis_variable，na.rm = true）， 
                  max（d $  x_axis_variable，na.rm = true），
                      length.out = nrow（d）））

p＆lt;  -  avg_predictions（fit，
                     变量= list（x_axis_variable = values），
                     byfun =函数（...）qnorm（平均（...）），
                     变换= pnorm）

fit.lm＆lt;  -  glm（估计〜x_axis_variable，data = p，family = quasibinomial）

seg.fit＆lt;  - 分割（fit.lm，seg.z = 〜x_axis_variable，npsi = 1）

断点＆lt;  - 摘要（seg.fit）$ psi [，&#39;es; est。]
打印（断点）

ggplot（p，aes（x = x_axis_variable，y = estime）） +
  geom_point（alpha = 0.5）+
  ＃GEOM_RIBBON（AES（ymin = conf.low，ymax = conf.high），
  ＃alpha = .3，
  ＃fill =&#39;slategray＆quot”）+
  geom_line（aes（y = predict（seg.fit，type，type =＆quote; worlds; quots; quot; quot; quot; quot＆quot =; blue; blue; quot;） +
  geom_vline（Xintercept =断点，color =; red＆quord&#39;，lineType =; dashed＆quot;）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662340/segmented-regression-on-estimated-probabilities-vs-raw-binary-outcome</guid>
      <pubDate>Sat, 08 Mar 2025 11:28:29 GMT</pubDate>
    </item>
    <item>
      <title>测试多重回归的系数A1和A2的比率与另一个多元回归的比率</title>
      <link>https://stats.stackexchange.com/questions/662338/test-the-difference-between-the-ratio-of-the-coefficients-a1-and-a2-of-a-multipl</link>
      <description><![CDATA[这个问题与以下 questiopn&gt;给定以下多元回归模型。
在
在
其中 $ y $ 是响应变量， $ n（μ，σ）$  $ und $ $ $ $ $ $ $ $  $ x_1 $ 和 $ x_2 $ 是解释性变量， $ a_n $  $ a_n $ 和我想测试 $ \ frac {a_1} {a_2} $ 和 $ \ frac {b_1} {b_2} $ 。换句话说，在运行上述回归时，如何测试以下假设测试？
  $ H_0：\ frac {a_1} {a_2} = \ frac {b_1} {b_2} $   
  $ H_1：\ frac {a_1} {a_2} \ ne \ frac {b_1} {b_2} $    
如果其中一个是固定值，我认为我可以使用等效的线性假设（如上一个问题所示），但是您如何处理它不是固定值的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/662338/test-the-difference-between-the-ratio-of-the-coefficients-a1-and-a2-of-a-multipl</guid>
      <pubDate>Sat, 08 Mar 2025 09:58:22 GMT</pubDate>
    </item>
    <item>
      <title>2个不等大小的样品的分布测试</title>
      <link>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</link>
      <description><![CDATA[说我有两个示例 $ n $ 和另一个大小 $ m $ ，我不知道每个样本的先验分布，但想知道是否从相同的分布中绘制样品（即是否试图检测概念draind drave drail）。每个示例中的每个数据点均为 $ d $ 尺寸。为了测试分布平等，我可以使用具有一定校正（Bonferroni）的Kolmogorov-Smirnov或使用2样本内核测试（具有最大平均差异）。
我想知道，如果 $ n $ 比 $ m $ （但是 $ m $ 仍然非常大） class =“ Math-Container”&gt; $ n = 20000 $ 。测试技术（我上面提到的确切条件）是否仍然存在？
如果没有，那我该怎么办？如果有已知技术，请随时向我指出资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</guid>
      <pubDate>Sat, 08 Mar 2025 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯过滤 - 为什么我们不能迭代地直接更新联合分布？为什么需要预测和更新步骤？</title>
      <link>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</link>
      <description><![CDATA[进行贝叶斯过滤时，我们有一个贝叶斯网络，因此：
  $$
p（x_ {0：t}）= p（x_0）\ prod_ {k = 1}^t p（x_k | x__ {k-1}）
$$ 
 $$
p（y_ {1：t} | x_ {0：t}）= \ prod_ {k = 1}^t p（y_ _ {k} | x_ {k {k}）
$$  
和
  $$
p（x_ {0：t}，y_ {1：t}）= p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）
$$  
给定
  $$
p（x_ {0：t+1}，y_ {1：t+1}）= p（x_0）p（x_ {t+1} | x_t）
$$  
如果我们有 $ p（x_ {0：t}，y_ {1：t}）$ ，为什么我们不能简单地计算 $ p（x__ {0：x_ {0：t+1}
  $$
p（x_ {0：t}，y_ {1：t}）p（x_ {t+1} | x_t）p（y_ {t+1} | x__ {t+1}）
$$  
因此，迭代地计算了一段时间的关节分布，而不是在每个时间步骤进行预测和更新步骤？
我知道，在过滤我们实际关心的分布时，是 $ p（x_ {t} | y_ {1：t}）$ ，但是如果我们忽略归一化常规化，这不应该等于关节分布吗？即。
  $$
p（x_ {0：t} | y_ {1：t}）\ propto p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）= p（x__ {0：t}，y__ ___ {1：t}）
$$  
我觉得我一定会缺少一些东西，所以如果有人可以指出它是什么，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</guid>
      <pubDate>Sat, 08 Mar 2025 00:03:15 GMT</pubDate>
    </item>
    <item>
      <title>每组进行预测时是否需要归一化？</title>
      <link>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</link>
      <description><![CDATA[作为ML的初学者，我正在观看
功能之一是历史参与数，例如视图/喜欢。
我不明白的是，面试官问，如果某些用户比其他用户比其他用户单击更多，因为他们通常更活跃，因为他们是点击器，他们点击了很多。并解释说，这就是为什么我们需要将点击标准化（例如，除以某些用户活动的总数）。
如果一个模型正在预测每个组，则预测是针对每个用户的歌曲。  那么您真的必须标准化吗？如果用户A有900个单击歌曲A和歌曲B的100次点击，而用户B有20个点击歌曲A，歌曲B的5次点击，则为歌曲C进行5次点击。归根结底，我们在每个用户之间决定不关心不同用户的歌曲。
，即使您要归一化，您也可以模拟歌曲A的用户为0.9，而歌曲B则为0.1，但用户B观看了3首歌曲，因此他的发行版本是0.6、0.2和0.2。。
标准化对您有何帮助？您仍然无法比较0.9和0.6。它们是每组最佳分数，但整个组仍然是无与伦比的。原始点击数与比率有何不同？
，但根据用户，就像原始数字一样，它可以获得最大的百分比。
所以我的意思是，当预测为每个组时，您需要正常化。您是否必须关心各组的比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</guid>
      <pubDate>Fri, 07 Mar 2025 23:14:59 GMT</pubDate>
    </item>
    <item>
      <title>绘制测试统计量与其相应的PVALUE</title>
      <link>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</link>
      <description><![CDATA[我想可视化特定测试的p值与其测试统计量的关系。该测试是“两次采样的未配对t检验，具有不平等的差异（welch的t检验）＆quot。
这样的数据，如果汇总40次左右，则可能出现：
  q = tstat_lst = [0.9660006171910432，
 0.7721621329351528，
 1.8100610634639722，
 -1.658160637924077，
 0.40426388807743174，
 -0.39322170596362177，
 -0.10057948819452832，
 -0.184443124516603937，
 0.12476123296525302，
 0.15156528516797133，
 -0.09564454667893868，
 -0.3565764937019235，
 0.6296035952012742，
 0.41864142400724524，
 -0.2947978905804754，
 -2.0477391038941315，
 0.6516953409964041，
 -0.10427275892823629，
 -0.383987967078378，
 0.49301579010836505，
 0.34309883856311163，
 -0.555996825678678，
 -0.9614457089082035，
 -0.4307174435897561，
 -0.2402370244487562，
 2.7217356150809198，
 -0.017687813740055347，
 0.37063599036565176，
 -1.433975290423805，
 -2.3163482190361595，
 0.527195768444428，
 1.0793544390271224，
 1.3726447186789736，
 2.1823987824609015，
 -1.886371488297514，
 -0.3327480340089581，
 -0.845831028027378，
 0.14159397099600338，
 1.770628236732337，
 -0.7129657016096798]

a = pvals_lst = [0.3351428270482858，
 0.44086256073619356，
 0.07167660898253647，
 0.09875110470687849，
 0.6864215472089106，
 0.6945485673825906，
 0.9199788061143731，
 0.8538488639722835，
 0.9008289373935419，
 0.8796716928044668，
 0.9238915619509784，
 0.7217575250663029，
 0.5296193782796346，
 0.6758955006039，
 0.7684339395166478，
 0.04185437874159891，
 0.51530430232936，
 0.9170562755796249，
 0.7013651604121057，
 0.6225036851619269，
 0.7318582035931929，
 0.5787900268922169，
 0.3374373699051052，
 0.6671072554315649，
 0.8103783128508254，
 0.007040388064127454，
 0.9859042929350978，
 0.7112719001389117，
 0.15302591592384204，
 0.021480204407496793，
 0.5986165798143437，
 0.2816495551645849，
 0.17128927509245642，
 0.030158422398817143，
 0.06060294356030884，
 0.7396484229164317，
 0.39859184655628466，
 0.8875327037601481，
 0.0780364091452371，
 0.4766433668999457]
 
是否有一个通用图？]]></description>
      <guid>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</guid>
      <pubDate>Fri, 07 Mar 2025 21:35:51 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 -  FDR或Holm -Bonferroni？</title>
      <link>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</link>
      <description><![CDATA[我正在用猴子进行听觉侧翼任务。它是一个受试者内部设计，有4个（6个）受试者，有4个条件。我想在运行单向RM ANOVA后进行成对比较。 Bonferroni被证明是非常保守的。我看着替代方案，罗姆和霍尔姆出现了。两者都给出不同的结果。哪一个对我的数据集更好？是否有一个在认知心理学中比其他人更好地接受的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</guid>
      <pubDate>Fri, 07 Mar 2025 21:18:20 GMT</pubDate>
    </item>
    <item>
      <title>对称与不对称分布的引导程序</title>
      <link>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</guid>
      <pubDate>Fri, 07 Mar 2025 21:04:15 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助进行哪些测试进行[关闭]</title>
      <link>https://stats.stackexchange.com/questions/662282/need-help-with-what-tests-to-run</link>
      <description><![CDATA[在我的论文中，我对调查数据进行了横断面研究，分析了环境自我效能对行为期望对零废物购物的影响，这是由感知的障碍所介导的。
我以复合分数总结了我的构造，它们都显示出很高的内部一致性，并进行了一些基本测试，并且我的数据并未完全正态分布（仅复合屏障得分是）。
我想进行回归（多个线性回归），但在数据不正常时听到了有关引导的信息。任何人都可以给出建议是“适当的”。对于学士学位论文？感谢您的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/662282/need-help-with-what-tests-to-run</guid>
      <pubDate>Thu, 06 Mar 2025 17:00:49 GMT</pubDate>
    </item>
    <item>
      <title>在部分相关分析中处理分类变量</title>
      <link>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</link>
      <description><![CDATA[我正在分析具有两个条件的实验的数据：野生型（WT）和突变基因型。每个基因型大约有25个样本。
对于每个样品，测量了〜15个基因和〜5代谢产物的表达。
目的是研究基因与代谢产物之间的关系，以及基因本身之间的关系。
但是，我注意到基因型之间的基因和代谢产物水平的主要差异。这意味着简单的相关分析将主要捕获基因型驱动的差异而不是真实的关联。
我遇到了部分相关（ ppcor :: pcor.test  in R），该在R）中计算两个变量之间的相关性，同时控制第三个变量（在这种情况下，基因型）。该方法可以应用于所有变量对，并在具有多测试校正的相关图中可视化。 Spearman的等级相关性（似乎是适当的选择）可以计算。
但是， ppcor 要求控制变量是数字的，而基因型为分类（WT/MUT）。
一种方法是将基因型编码为（0,1），但我不确定这种转换的含义。

 将基因型（WT，MUT）转换为（0,1）的统计后果是什么？？

 是否有任何有效性检查以确保此方法合适？

]]></description>
      <guid>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</guid>
      <pubDate>Mon, 03 Mar 2025 07:55:24 GMT</pubDate>
    </item>
    <item>
      <title>协方差传播法的几何解释</title>
      <link>https://stats.stackexchange.com/questions/662012/geometric-interpretation-of-covariance-propagation-law</link>
      <description><![CDATA[众所周知，如果 $ \ Mathbf {y} \ in \ Mathbb {r}^m $ 是R.V.与另一个R.V.有关 $ \ MathBf {x} \ in \ Mathbb {r} class =“ Math-Container”&gt; $ \ MathBf {Y} $ 由 $ a p a^{t} $ 其中 $ p $  $ p $ 是尽管很长一段时间使用此公式，但我觉得我仍然对此没有几何解释。在卡尔曼过滤器框架中众所周知，协方差更新降低了可观察到的子空间的不确定性，并且应在上述公式中反映出来。特别是，在此上下文中的协方差更新由以下方式给出：
  $$
p_ {k | k} =（i -kh）p_ {k | k -1}（i -kh）^{t} + k rk^{t} =（i -kh）p_ {k | k -1}
\ tag {1}
$$ 
其中 $ k $ ， $ h $  and  $ r $ 是合适尺寸的矩阵。
几何， $ p_ {k | k-1} $ 与平面中的椭圆的平行投影 $ p $ 在另一个平面 $ \ tildedel 
  我们可以观察到曲率更新的公式 $ \ tilde {\ kappa} = cos（\ alpha）\ kappa $ 类似于一个小方程（1）。。
任何人是否知道方程（1）是否可以表示为 $ p_ {k | k-1} $ 在某些超平面中定义的超平面 $ kh $ ？换句话说，这个类比可以严格吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662012/geometric-interpretation-of-covariance-propagation-law</guid>
      <pubDate>Sat, 01 Mar 2025 22:24:58 GMT</pubDate>
    </item>
    <item>
      <title>如何处理HLM Logistic回归中没有差异的群集</title>
      <link>https://stats.stackexchange.com/questions/661928/how-to-handle-clusters-that-have-no-variance-in-hlm-logistic-regression</link>
      <description><![CDATA[使用逻辑回归进行建模时，采用以下形式：
  $$
\ text {ln} \ frac {p（x）} {1- p（x）} = \ beta_0 + \ beta_1x_1 + \ dots + \ beta_px_p 
$$  
  $ p（x）$ 接近1或0获得正无穷大或负的无穷大。
使用HLM时，让我们定义一个随机截距：
  $$
\ text {ln} \ frac {p（x）} {1- p（x）} = \ beta_0+ u_j
$$  
  $ u_j $ 当某些簇只有所有1或0观察值（即没有差异）时，会发生什么？这些集群是否应该包括在模型中？它们是否导致 $ \ beta_0 $ ？
我在R中进行了一些模拟来调查
 库（dplyr）＃for数据框架操纵
图书馆（TIDYR）＃对于不努力的列表列
图书馆（LME4）＃for Glmer
J＆lt; -20 #number of clusters
n＆lt;  -  100 #number ob obs per cluster
set.seed（123）
sim.dat＆lt;  -  data.frame（id = as.factor（1：j），
           pi_cluster = rbeta（n，shape1 = 1，shape2 = 1））|＆gt;
  rowwise（）|＆gt; 
  突变（obs = list（rbinom（n，size = 1，prob = pi_cluster）））|＆gt; 
  Unnest（obs）


glmer（obs〜1 +（1 | id），data = sim.dat，
      family =“二项式”
＃＆gt;广义线性混合模型拟合最大似然（拉普拉斯
＃＆gt;   近似）[glmermod]
＃＆gt;  家庭：二项式（logit）
＃＆gt;公式：obs〜1 +（1 | id）
＃＆gt;    数据：sim.dat
＃＆gt;       AIC BIC LOGLIK偏差DF。 
＃＆gt; 13412.788 13427.208 -6704.394 13408.788 9998 
＃＆gt;随机效果：
＃＆gt;  组名称std.dev。
＃＆gt;  ID（截距）0.4617  
＃＆gt;观察数：10000，组：ID，20
＃＆gt;固定效果：
＃＆gt; （截距）  
＃＆gt;      -0.101

perfect_scores＆lt;  -  data.frame（id = as.factor（c（21,22）），obs = rep（1，n））

sim.dat_100 = persect_scores |＆gt;  ＃100％准确性
  bind_rows（sim.dat）

test＆lt; -glmer（obs〜1 +（1 | id），data = sim.dat_100，
      family =“二项式”
测试
＃＆gt;广义线性混合模型拟合最大似然（拉普拉斯
＃＆gt;   近似）[glmermod]
＃＆gt;  家庭：二项式（logit）
＃＆gt;公式：obs〜1 +（1 | id）
＃＆gt;    数据：SIM.DAT_100
＃＆gt;       AIC BIC LOGLIK偏差DF。 
＃＆gt; 13457.053 13471.494 -6726.527 13453.053 10098 
＃＆gt;随机效果：
＃＆gt;  组名称std.dev。
＃＆gt;  ID（截距）1.004   
＃＆gt;观察数：10100，组：ID，22
＃＆gt;固定效果：
＃＆gt; （截距）  
＃＆gt;      0.1791
头（ranef（test）$ id）
＃＆gt;    （截距）
＃＆gt; 21 2.69422960
＃＆gt; 22 2.69422960
＃＆gt; 1 0.27435351
＃＆gt; 2 0.07770447
＃＆gt; 3 0.35866584
＃＆gt; 4 -0.30482495
 
我们可以看到HLM中所有1s的簇具有非常大的随机效果。和 $ \ beta_0 $ 估计已向上拉。
在这个简单的示例中，我们只是随机拦截。如果我们有其他协变量，将包含所有1导致 $ \ beta_1，\ ldots，\ beta_p $ 更接近零的class =“ nath-container”&gt; $ \ beta_1，]]></description>
      <guid>https://stats.stackexchange.com/questions/661928/how-to-handle-clusters-that-have-no-variance-in-hlm-logistic-regression</guid>
      <pubDate>Thu, 27 Feb 2025 17:58:59 GMT</pubDate>
    </item>
    <item>
      <title>序数回归：z得分预测变量后的p值[封闭]</title>
      <link>https://stats.stackexchange.com/questions/661607/ordinal-regression-p-values-change-after-z-scoring-predictors</link>
      <description><![CDATA[使用标准线性回归，p值在z得分后不变，只有系数。但是，在我正在运行的序数回归模型中，预测变量的p值在某种程度上发生了变化（请注意，我仅z得分只有z得分，或者预测因素和序数结果都无关紧要）。。
结果有19个级别。
 没有z得分：
   z得分后：
  变量 Choroid_volume 具有范围 200-4000 ， tiv   1153852-1153852-1927779 范围。我测试了它是将这些变量缩放还是以零为中心的变量，以更改P值。
缩放它们，因此平均值为1不会影响脉络膜_volume，但确实会影响tiv（鉴于tiv太大，我并不感到惊讶，尽管缩放不会随线性回归而改变任何内容）。。
零中心更改两个变量的p值。关于序数回归是否有一些使变量分布的符号或中心相关的内容？因此，有理由是您不应该在序数回归中z得分吗？
缩放但不居中
这是缩放结果的结果，但不为病变evol_cubic，choroid_volume和tiv。
   choroid_volume和vol_cubic的p与原始数据相同（我现在相信tiv只会翻转，因为它的原始比例很大）。 Z得分后所有三个P值都会发生变化，这使我相信分布的中心很重要。为了娱乐，我尝试翻译分布不同的数量，并且每次都会改变。这与线性回归没有区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/661607/ordinal-regression-p-values-change-after-z-scoring-predictors</guid>
      <pubDate>Wed, 19 Feb 2025 21:23:52 GMT</pubDate>
    </item>
    <item>
      <title>在多级潜在类别的远端结果中的3级聚类</title>
      <link>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</link>
      <description><![CDATA[我正在研究基于PISA数据（横截面，连续的“远端结果”和班级的分类典型指标）的潜在学生体验（也在学校一级汇总）与学生成绩之间的关系。我打算使用多级潜在类别分析，以便可以在学生级别和学校层面上对关系进行建模。但是，我很担心，因为学生数据不仅嵌套在学校，而且还嵌套在国家（有60多个国家）。由于我对国家水平的效果不感兴趣，但只想考虑国家内的聚类，我是否有办法进行这种调整？我可以使用Mplus或R。您是否有建议，或者您会推荐任何资源，有人使用MLCA使用这样的3级聚类来预测远端结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</guid>
      <pubDate>Tue, 20 Aug 2024 09:03:44 GMT</pubDate>
    </item>
    <item>
      <title>CFA：卡方值为0，但自由度</title>
      <link>https://stats.stackexchange.com/questions/631991/cfa-chi-square-value-is-0-but-with-degrees-of-freedom</link>
      <description><![CDATA[我想在 mplus 中使用Actor-Partner相互依赖模型进行SEM分析。我设法计算了它，如果我查看手段，SD，效果等，一切似乎都正确。但是我对模型拟合有问题。
合适的索引很奇怪，太好了……所以它一定有问题。我读到，如果一个人的卡方值为0以及0度的自由度，则该模型已饱和，因此未完成模型拟合测试。但是，即使我的卡方值为0，我的DF也是12。所有其他模型拟合指数也是完美的。这是不对的。.有人知道问题可能是什么，还是告诉我什么？因为要安静坦率，我没有计划。而且我似乎找不到任何信息。
 这是输出： 
模型拟合信息
免费参数的数量15 
 loglikelihood 
  H0值-927.087
      H1值-927.087
 
信息标准
  akaike（AIC）1884.173
      贝叶斯（BIC）1928.082
      样品大小调整后的BIC 1880.627
        （n* =（n + 2） / 24）
 
模型拟合的卡方检验
 值0.000
      自由度12
      P值1.0000
 
 rmsea（近似的均方根误差）
 估计0.000
      90％C.I.                    0.000 0.000
      概率RMSEA＆lt; = .05 1.000
 
 cfi/tli 
  CFI 1.000
      TLI 1.000
 
用于基线模型的模型拟合的卡方检验
 值90.763
      自由度14
      p值0.0000
 
 srmr（标准化的均方根残差）
 值0.000
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/631991/cfa-chi-square-value-is-0-but-with-degrees-of-freedom</guid>
      <pubDate>Tue, 21 Nov 2023 19:22:29 GMT</pubDate>
    </item>
    </channel>
</rss>