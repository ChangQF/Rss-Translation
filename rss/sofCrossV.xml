<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 08 Jan 2024 12:26:28 GMT</lastBuildDate>
    <item>
      <title>求R包计算零值和负值的基尼系数</title>
      <link>https://stats.stackexchange.com/questions/636416/seeking-r-package-for-gini-coefficient-calculation-with-zero-and-negative-values</link>
      <description><![CDATA[我正在研究 R 中的基尼系数计算，以分析财富不平等的各个方面。但是，我的数据包含零值和负值，并且我还没有发现能够处理这些值的 R 包。相比之下，Stata 有一个名为 INEQDEC0  的包来解释这些值。有谁知道 R 中的等效包吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636416/seeking-r-package-for-gini-coefficient-calculation-with-zero-and-negative-values</guid>
      <pubDate>Mon, 08 Jan 2024 11:36:16 GMT</pubDate>
    </item>
    <item>
      <title>存在异常值时时间序列数据的正态性假设违反</title>
      <link>https://stats.stackexchange.com/questions/636414/normality-assuption-violation-of-time-series-data-in-the-presence-of-outliers</link>
      <description><![CDATA[我有一个数据集，其中包含 2010 年至 2021 年各地区每月登革热发病率的信息。我发现由于 2019 年出现新变种，登革热发病率突然增加。我正在尝试拟合一个模型来识别影响登革热发病率的因素，我应用了时间序列回归。数据不是平稳的，因此我对数据进行了差分变换。但该模型违反了正态性假设和自相关假设。我在模型中加入了第一滞后，它解决了自相关问题。但即使进行对数变换，模型也不满足正态性假设。
由于数据都是时间序列和横截面数据，我尝试使用面板数据回归，但模型仍然违反了正态性假设。我认为这可能是因为数据中存在异常值，但因为这是时间序列数据，我无法删除异常值。
以下是时间序列回归模型的残差图。

我的主管建议我应该考虑最简单的方法，并尝试处理违反正态性假设的情况，而不是寻找新的方法。但我仍然找不到这个问题的任何解决方案。有人知道我应该采取什么方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636414/normality-assuption-violation-of-time-series-data-in-the-presence-of-outliers</guid>
      <pubDate>Mon, 08 Jan 2024 11:23:28 GMT</pubDate>
    </item>
    <item>
      <title>计算 95% 置信区间时，两种方法产生了两个不同的结果</title>
      <link>https://stats.stackexchange.com/questions/636411/calculating-the-95-confidence-interval-two-approaches-generated-two-different</link>
      <description><![CDATA[我对同一正态分布数据集生成的两个结果感到非常困惑，请参见下面的图和统计数据。原始数据可在此处下载。
sd 表示 n
12325.37 7993.051 10000


方法 1
95% 置信区间 = 平均值 ± SD/sqrt(n)，
结果是
 上限值 下限值
8234.653 7993.051 7751.449

方法 2
2.5% 和 97.5% 分位数。很多人说如果样本量足够大，分位数范围相当于95%CI范围，但下面的结果与方法1的结果有很大差异。
&lt;预&gt;&lt;代码&gt;2.5% 50% 97.5%
-16195.35 7932.73 32429.37

所以我有两个问题：

为什么这两个结果相差如此之大？哪一个才是真正的 CI？
为什么当样本量足够大时，2.5%-97.5%分位数范围相当于95%CI范围？我很困惑，因为一方面，分位数不考虑样本量。另一方面，当样本量足够大时，等式不是会变成“95%置信区间=平均值±非常小的误差范围”吗？非常小的误差幅度不会延伸到 2.5% 和 97.5% 的两个尾部。

任何帮助将不胜感激！
这是这个问题和这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/636411/calculating-the-95-confidence-interval-two-approaches-generated-two-different</guid>
      <pubDate>Mon, 08 Jan 2024 10:47:47 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘估计和潜在空间</title>
      <link>https://stats.stackexchange.com/questions/636410/least-square-estimate-and-latent-space</link>
      <description><![CDATA[我目前正在论文中研究回归系数与潜在空间高维无脊最小二乘插值中的惊喜&lt; /a&gt; 作者：Trevor Hastie 等。该主题出现在第 5.4 章（第 16 页~）。让我写一些与我的问题相关的章节的部分内容。
&lt;小时/&gt;
$\dots$ 为了激发此示例，假设响应 $y_i$ 是线性的潜在特征向量$z_i \in \mathbb R^d$。我们不观察这个潜在向量，而是观察 $p \ge d$ 协变量 $x_i := (x_{i ,1},\dots,x_{i,p})$ 在潜在向量 $z_i$ 中也是线性的：
$$y_i = \theta^T z_i + \zeta_i, \quad x_{i,j} = w_j^Tz_i+u_{i,j}.$$
此处，$\{\zeta_i\}_{1\le i \le n}$ 和 $\{u_ {i,j}\}_{1\le i \le n, 1 \le j \le p}$ 是相互独立的噪声变量，并且独立于 $z_i$，与 $\zeta_i \sim N(0, \sigma_{\zeta}^2),\ u_{i,j} \sim N( 0,1)$。特征矩阵采用 $X = ZW^T + U$ 的形式，因此，对于 $p &gt; n$，最小范数回归（$l_2$范数）等于
$$\hat \beta = \arg\min_b \Bigl\{b : ZW^Tb + Ub = 0 \Bigr\} \tag1.$$
&lt;小时/&gt;
特征矩阵可以通过让
$$Z = \begin{bmatrix}
z_1^T\\
\vdots \\
z_n^T
\end{bmatrix}, \quad W^T = \begin{bmatrix} w_1 \dots w_p\end{bmatrix}, \ \ [X]_{i,j} = x_{i,j}.$$
现在，这就是我陷入困境的地方。我们可以通过以下方式获得 OLS 估计器
$$X^T(Y - Xb) = 0.$$
但上面的最小范数估计器意味着 $Xb = 0$，我不确定这个方程来自哪里。 （它似乎不是来自OLS方程）。任何有助于理解（1）的提示将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636410/least-square-estimate-and-latent-space</guid>
      <pubDate>Mon, 08 Jan 2024 10:46:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 CNN 检测高分辨率图像中的小细节？</title>
      <link>https://stats.stackexchange.com/questions/636409/how-to-detect-small-details-in-high-resolution-images-using-cnns</link>
      <description><![CDATA[我的目标是训练一个 CNN 模型，该模型可以检测衣物是否有任何缺陷（破洞、污渍等）。我正在使用 Keras 来完成此任务。
讲述我面临的问题；我收到的推理输入将来自用户，它们将是从这些用户的智能手机上传的照片。因此，平均而言，输入分辨率将为 3024 x 4032 ，纵横比始终为 3:4。我收集了高分辨率图像的数据集，并将模型的输入设置为 900 x 1200 像素。但在检测小细节方面我似乎仍然无法取得任何成功，而且我的模型的准确性相当低。例如；

这是输入图像，3024 x 4032 像素
这些是我试图检测的漏洞

我认为我已经收集了足够的数据来训练模型，但我相信当调整图像大小以匹配输入分辨率时，细节会丢失。我还能做些什么来让我的模型发挥作用？除了将输入分辨率设置得更高还有什么办法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636409/how-to-detect-small-details-in-high-resolution-images-using-cnns</guid>
      <pubDate>Mon, 08 Jan 2024 10:36:34 GMT</pubDate>
    </item>
    <item>
      <title>带有审查数据的 C 统计量</title>
      <link>https://stats.stackexchange.com/questions/636408/c-statistic-with-censoring-data</link>
      <description><![CDATA[我分析了包含风险因素和结果的癌症数据集。然而，我正在处理许多因后续观察而丢失的观察结果和缺失值。
我想要获取 c 统计量，但有人告诉我，在存在审查数据的情况下，c 统计量可能会出现偏差，并建议我使用 Uno c 统计量（R 中提供）。
目前，我正在使用 Stata，并提到 Gonen 和 Heller 估计在审查数据的情况下更好。
哪种方法更好？ Gonen/Heller 还是 Uno c 统计数据？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/636408/c-statistic-with-censoring-data</guid>
      <pubDate>Mon, 08 Jan 2024 10:35:15 GMT</pubDate>
    </item>
    <item>
      <title>解读g公式干预密度</title>
      <link>https://stats.stackexchange.com/questions/636407/interpreting-g-formula-intervention-density</link>
      <description><![CDATA[我正在阅读本文中关于参数化的附录A.2节g-公式，我正在努力理解“干预密度”当干预取决于治疗的自然价值时。
有关符号的简要背景，假设一个观察数据集，处理$A_k$，协变量向量$L_k$&lt; /span&gt;，并有时审查 $C_k$ $k = 0,1,2,...K$&lt; /跨度&gt;。上横线表示历史记录；例如，$\bar{a}_2 = (a_0,a_1,a_2)$。
我正在努力理解这段话中的最终密度（$f^d$）：

我不明白根据 $a_k$ 的密度进行随机抽取意味着什么，条件是 自然 值$k$ 的治疗（和历史）。
到底什么是“自然价值”？的治疗？我们应该如何理解以这个值为条件的干预密度？]]></description>
      <guid>https://stats.stackexchange.com/questions/636407/interpreting-g-formula-intervention-density</guid>
      <pubDate>Mon, 08 Jan 2024 10:32:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 Lavaan SEM 指定两个潜在变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/636406/getting-lavaan-sem-to-specify-the-correlation-between-two-latent-variables</link>
      <description><![CDATA[我正在 R 中使用 Lavaan 运行 SEM，其中 6 个潜在预测变量（proc、perf...、pol2）中的每一个都预测两个潜在结果 (ti 和 ci)。
我想找出 ti 和 ci 之间的相关性，但当我使用 SEM 命令时无法让 R 给我这个。我只能得到它们残差的协方差；在输出的协方差部分下，变量名称前面有一个点。
我可以修改我的代码来生成这个吗？或者说在 SEM 中谈论潜在结果变量之间的相关性没有意义吗？
我的代码如下 -
#测量模型

型号&lt;-&#39;
proc=~proc01+proc02+proc03+proc04+proc05+proc06+proc07+proc08
perf_pers=~perf09+perf10+perf11+perf12+perf13+perf14
perf_ds=~perf07+perf08
perf_eqmt=~perf05+perf06
perf_regs=~perf15+perf16+perf17
pol2=~pol01+pol02+pol03+pol05
ti=~ti01+ti02+ti03+ti04
ci=~ci02+ci03+ci04+ci05+ci06

#回归
ti~proc+pol2+perf_pers+perf_ds+perf_eqmt+perf_regs
ci~proc+pol2+perf_pers+perf_ds+perf_eqmt+perf_regs
&#39;

fitmodel&lt;-sem(模型,数据=数据)
摘要（fitmodel，标准化= TRUE，fit.measures = TRUE）
modindices（fitmodel，排序= TRUE）
]]></description>
      <guid>https://stats.stackexchange.com/questions/636406/getting-lavaan-sem-to-specify-the-correlation-between-two-latent-variables</guid>
      <pubDate>Mon, 08 Jan 2024 10:02:32 GMT</pubDate>
    </item>
    <item>
      <title>工具变量估计中的偏差与一致性</title>
      <link>https://stats.stackexchange.com/questions/636404/bias-vs-consistency-in-instrumental-variable-estimation</link>
      <description><![CDATA[因此，在《Mostly Harmless Econometrics》第 206 页中，他们分析了工具变量的偏差：
他们考虑一个内生变量$x$、多个工具$Z$的情况，以及$\eta$ 是结构错误，$\xi$ 是第一阶段的错误。 
他们得出这个等式：
$$
\开始{对齐}
\beta_{2SLS}-\beta &amp;= (x&#39;P_{z}x)^{-1}(\pi&#39;Z&#39;+\xi&#39;)P_{z}x \\
&amp;=((x&#39;P_{z}x)^{-1})\pi&#39;Z&#39;x + (x&#39;P_{z}x)^{-1}\xi&#39;P_{z}\eta。
\结束{对齐}
$$
对于一致性论证，我想，人们需要能够证明右侧的两项都为零。
然后他们认为可以通过观察来研究偏见
$$
\mathbb{E}[\hat{\beta}_{2SLS}-\beta]\approx(\mathbb{E}(​​x&#39;P_{z}x))^{-1}\mathbb{E}[\ pi&#39;Z&#39;\xi] + (\mathbb{E}(​​x&#39;P_{z}x))^{-1} \mathbb{E}[\xi&#39;P_{Z}\eta]。
$$
然后他们说 $\mathbb{E}[\xi&#39;P_{Z}\eta]$ 不为零，但 $\xi&#39;P_{z}\eta \rightarrow 0$。我很难看到这个。
最后，他们后来说]]></description>
      <guid>https://stats.stackexchange.com/questions/636404/bias-vs-consistency-in-instrumental-variable-estimation</guid>
      <pubDate>Mon, 08 Jan 2024 08:34:52 GMT</pubDate>
    </item>
    <item>
      <title>寻找可信度评分模型的统计建模技术</title>
      <link>https://stats.stackexchange.com/questions/636403/looking-for-a-statistical-modelling-technique-for-a-credibility-scoring-model</link>
      <description><![CDATA[我正在开发一个模型，为组织内的疲劳报告分配可信度分数。员工在一年中可以无限次地报告感到“疲倦”，我的模型的目标是评估这些报告的可信度。
模型应考虑几个因素，包括：

历史报告模式（例如，员工是否始终在周五或周一等特定日期报告疲劳情况）。
指定时间范围内（例如上个月）疲劳报告的频率。
每次疲劳报告之前和之后员工的职责性质。

我目前正在考虑哪种统计建模技术最适合这项任务。我正在考虑的两种方法是：

进行描述性分析，为过去的行为分配权重，并根据这些权重计算分数。

开发贝叶斯模型来计算疲劳报告真实的概率（假设疲劳报告是由特定员工报告的）。


解决这个问题的最佳方法是什么？有没有可以使用的最先进的建模技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/636403/looking-for-a-statistical-modelling-technique-for-a-credibility-scoring-model</guid>
      <pubDate>Mon, 08 Jan 2024 08:34:33 GMT</pubDate>
    </item>
    <item>
      <title>asreml-R 中群体争论的行为不明确[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636400/unclear-behavior-of-group-argument-in-asreml-r</link>
      <description><![CDATA[我正在学习 asreml-R，并且无法弄清楚为什么如果我提供方差矩阵的起始值，我的分组项仅适用于双变量模型。除了对我来说很奇怪之外，它还使我无法成功指定方差矩阵项的界限（例如“F”“U”“P”）。
以下是有效的双变量模型的代码：
结果 &lt;- asreml(
固定 = cbind(HP_SUR4,ND_SUR4) ~ 特征，
随机 = ~ grp(LINE):us(特质, init = c(0.03,0.1,0.03)),
残差 = ~ 单位:diag(特征, init = c(0.19,0.13)),
组 = 列表(LINE = c(2,3,4,5,6,7,8)),
na.action = na.method(x=&quot;include&quot;),
数据 = 数据
）
请注意，行“group = list(LINE = c(2,3,4,5,6,7,8))”指定第 2 列到第 8 列都是我想要建模的 LINE 项的不同级别，并注意“grp(LINE)”是导致所有指定列被视为单个因素的函数。
现在，如果我取出初始值并运行相同的模型：
结果 &lt;- asreml(
固定 = cbind(HP_SUR4,ND_SUR4) ~ 特征，
随机 = ~ grp(LINE):us(特质),
残差 = ~ 单位:diag(特征, init = c(0.19,0.13)),
组 = 列表(LINE = c(2,3,4,5,6,7,8)),
na.action = na.method(x=&quot;include&quot;),
数据=数据，R.param=init2
）
我收到以下错误：
[.data.table(data, , x[1], with = FALSE) 中出现错误：
未找到列：LINE
我无法使用非分组因子重现此错误，这阻碍了我通过使用“start.values = T”来更改方差矩阵的边界。方法。
如果有人对我收到此错误的原因有所了解，或者对如何指定方差矩阵的界限有一些想法（我希望能够制作“U”“F”“） F”矩阵），我将不胜感激。
最好，
弗雷德]]></description>
      <guid>https://stats.stackexchange.com/questions/636400/unclear-behavior-of-group-argument-in-asreml-r</guid>
      <pubDate>Mon, 08 Jan 2024 07:36:31 GMT</pubDate>
    </item>
    <item>
      <title>shap 方法中变量的期望应该为零吗？</title>
      <link>https://stats.stackexchange.com/questions/636399/should-the-expectation-of-an-variable-in-shap-method-being-zero</link>
      <description><![CDATA[不知道我是否误解了shap值的概念：
所以对于所有样本的目标var(y)，都有一个对它们的期望，或者E(f(x))，它被设置为shap的水平线，被设置为零。
在特定的var（X之一）中，对于每个特定的var值（例如5），还应该有一个目标值的期望，在数学中表示为E(f(x)|x1 = 5) 
因此，对于该 var 的某些值，f(x) 的期望应该超过平均值 E(f(x))[对该样本的特定 var 具有正的平均形状值]，而该 var 的某些值应该是低于平均值[该样本的特定 var 的平均 shap 值为负]，但每个样本的 var shap 值的总和也应该为零（意味着 E(f(x))）。否则 E(E(f(x)|x1)) 的总平均值不可能是 E(f(x))
但是，当我在分类任务中使用 github 中的项目时，对于某些 var，所有 shap 值都小于 0，而对于某些 var，所有 shap 值都大于 0。
意思是可以理解的，如果所有形状值都为负值，则对于任何值，它都会将 f(x) 从其水平值向下拖动，而对于所有形状值为正值的情况，则意味着对于任何值值它将把 f(x) 从平均值拉高。但如果是这样的话，var 的 shap 的定义可能与我的理解不同。
我在github的一个项目中使用了一个方法，链接在这里：github形状计算
我参考的 shap 解释在这里：shap应用说明
此处提供的变量没有缺失值。
我这里有一个情节：

你可以在图片中更好地理解我的意思。
欢迎任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/636399/should-the-expectation-of-an-variable-in-shap-method-being-zero</guid>
      <pubDate>Mon, 08 Jan 2024 07:19:39 GMT</pubDate>
    </item>
    <item>
      <title>带粒子滤波的维特比算法的实现</title>
      <link>https://stats.stackexchange.com/questions/636398/implementation-of-viterbi-algorithm-with-particle-filtering</link>
      <description><![CDATA[我正在尝试实现本文中的算法：https:/ /www2.stat.duke.edu/~mw/MWextrapubs/Godsill2001.pdf
这是主要方程
状态空间模型方程：

状态演化密度：$x_t \sim f(x_t | x_{t-1})$（公式 1）
观测密度：$y_t \sim g(y_t | x_t)$（公式 2）

状态和观测值的联合分布：

$p(x_{1:t} | y_{1:t}) \propto \prod_{i=1}^{t} f(x_i | x_{i) -1}) g(y_i | x_i)$（公式 3）

联合分布的递归：

$p(x_{1:t+1} | y_{1:t+1}) = p(x_{1:t} | y_{1:t} ) g(y_{t+1} | x_{t+1}) \frac{p(y_{t+1})}{p(x_{t+1} | y_t)}$ （方程4）

粒子过滤近似：

$p(x_{1:t} | y_{1:t}) \approx \sum_{i=1}^{N} w_t^{(i)} \delta_{x_{1:t}^{(i)}} (dx_{1:t})$（公式 5）

MAP序列估计：

$x_{\text{MAP}}^{1:t} (t) = \arg \max_{x_{1:t}} p(x_{1: t} | y_{1:t})$（公式 6）
边际固定滞后 MAP 序列：$x_{\text{MMAP}}^{t-L+1:t} (t) = \arg \max_{x_{ t-L+1:t}} p(x_{t-L+1:t} | y_{1:t})$（公式 7）

通过动态规划优化：

$x_{\text{MAP}}^{1:t} (t) = \arg \max_{x_{1:t}} \sum_{k=1 }^{t} [\log g(y_k | x_k) + \log f(x_k | x_{k-1})]$ （公式 9）

这是我的尝试：
将 numpy 导入为 np

def state_transition(x, process_noise_std):
    返回 x + np.random.normal(0, process_noise_std, size=x.shape)

def观察似然（x，y，观察噪声标准）：
    返回 np.exp(-0.5 * ((y - x) ** 2) / Observation_noise_std ** 2)

def 重新采样（粒子，权重）：
    指数 = np.random.choice(len(粒子), size=len(粒子), p=权重)
    返回粒子[索引]

def 粒子过滤器（初始粒子，观测值，process_noise_std，observation_noise_std）：
    num_articles = len(初始粒子)
    粒子= np.copy（初始粒子）
    所有粒子 = []
    所有权重 = []

    对于观测值中的 y：
        粒子 = state_transition(粒子, process_noise_std)
        权重=观察似然（粒子，y，观察噪声标准）
        重量 += 1.e-300
        权重 /= 总和(权重)
        
        all_articles.append(粒子)
        all_weights.append(权重)

        粒子=重新采样（粒子，权重）

    返回所有粒子、所有权重

def viterbi_for_article_filter(x_articles, 权重, y_observations, Observation_noise_std):
    num_observations = len(y_observations)
    num_粒子 = len(x_粒子[0])

    delta = np.zeros((观察数, 粒子数))
    psi = np.zeros((num_observations, num_articles), dtype=int)

    # 初始化
    delta[0, :] = np.log(权重[0] + 1.e-300) + np.log(观察似然(x_粒子[0], y_观察[0], 观察_噪声_std))

    # 维特比算法
    对于 t in range(1, num_observations)：
        对于范围内的 i（num_articles）：
            log_trans_probs = np.log(权重[t-1] + 1.e-300)
            log_obs_prob = np.log(observation_likelihood(x_articles[t][i], y_observations[t], Observation_noise_std))
            Total_log_probs = delta[t-1, :] + log_trans_probs + log_obs_prob
            
            psi[t, i] = np.argmax(total_log_probs)
            delta[t, i] = np.max(total_log_probs)

    # 回溯寻找最可能的路径
    x_MAP = np.zeros(num_observations, dtype=int)
    x_MAP[num_observations-1] = np.argmax(delta[num_observations-1, :])

    对于范围内的 t(num_observations-2, -1, -1)：
        x_MAP[t] = psi[t+1, x_MAP[t+1]]

    返回x_粒子[0][x_MAP]

# 用法示例
粒子数 = 1000
初始粒子 = np.random.normal(0, 1, 大小=num​​_articles)
y_观察值 = [1.2, 1.5, 1.7, 1.4, 1.1]
过程噪声标准 = 0.1
观察噪声标准 = 0.2

x_粒子，权重 = 粒子过滤器（初始粒子，y_观察，过程噪声标准，观察噪声标准）
x_MAP = viterbi_for_article_filter（x_粒子，权重，y_观察值，observation_noise_std）
打印（x_MAP）

根据我对本文的解释，我不确定我的实现是否正确 - 有人可以帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636398/implementation-of-viterbi-algorithm-with-particle-filtering</guid>
      <pubDate>Mon, 08 Jan 2024 06:00:34 GMT</pubDate>
    </item>
    <item>
      <title>寻找具有约束的标准正态的联合概率分布</title>
      <link>https://stats.stackexchange.com/questions/636397/finding-joint-probability-distribution-of-standard-normal-with-constraints</link>
      <description><![CDATA[&lt;块引用&gt;
设 $X, Y \mathop{\sim}\limits^{iid} N(0,1)$。
a) 假设 $X &lt; Y$，找到$X$和$Y$的联合pdf。
b) 如果 $X$ 和 $Y$ 的联合 pdf 是多少=&quot;math-container&quot;&gt;$X = Y$？

我们知道 $f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2} }$ 和 $f_Y(y)= \frac{1}{\sqrt{2\pi}}e^{-\frac{y^2}{2 }}.$
无约束时，联合pdf为$f_{X,Y}(x,y) = f_X(x)\times f_Y(y),$ 因为 $X$ 和 $Y$ 是独立的。现在，
对于a)部分，我的想法是$f(x,y|x 其中 $P(x 但是，这种集成似乎没有紧密的形式。也许，我在这里使用了错误的想法？。
对于 b) 部分，我尝试在 ChatGPT 上获取一些想法，但在不同时间得到不同的结果（尽管第一个结果出现了几次）。在某些情况下，ChatGPT 建议设置 $X = Y = Z,$ 然后 $f(x,y|x = y ) = f_{X,Y}(z,z)=\frac{1}{2\pi}e^{-z^2}$ 作为联合 pdf。在不同的实例中，它发现 $f(x,y|x = y)=f_Z(z)=\delta{(x-y)},$ 其中 $\delta{()}$ 是 Dirac delta 函数，作为联合 pdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/636397/finding-joint-probability-distribution-of-standard-normal-with-constraints</guid>
      <pubDate>Mon, 08 Jan 2024 05:00:52 GMT</pubDate>
    </item>
    <item>
      <title>比较具有主效应和交互作用的模型</title>
      <link>https://stats.stackexchange.com/questions/636391/comparing-models-with-main-effects-and-interactions</link>
      <description><![CDATA[我有两个模型：

模型1：仅包含自变量$x$，而$x$不显着.
模型 2：包含 $x$、$m$ 和 $x * m$，并且 $x * m$ 很重要。

我该如何说明这个结果？我还能说 $m$ 有调节作用吗？如果是这样，我如何确定 $m$ 效果的方向？]]></description>
      <guid>https://stats.stackexchange.com/questions/636391/comparing-models-with-main-effects-and-interactions</guid>
      <pubDate>Mon, 08 Jan 2024 03:39:22 GMT</pubDate>
    </item>
    </channel>
</rss>