<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 04 Jul 2024 01:05:13 GMT</lastBuildDate>
    <item>
      <title>最可能结果的可能性有一个名称吗？</title>
      <link>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</link>
      <description><![CDATA[在流行统计学中，通常会将最可能的结果描述为非常有意义的属性。
但是，如果不知道最可能的结果有多大可能性，那么它实际上就没有那么大的意义。
例如，在四次抛硬币中，最可能的结果是一半正面，一半反面，
但实际得到该结果的可能性只有 37.5%；近三分之二的时间会是其他结果。
随着硬币数量的增加，最可能的结果不会改变，但实现该结果的可能性接近于零。
也就是说，最有可能发生的事件可能非常不可能。
这似乎是几乎从未提及的事情，但是这个最可能结果的（不）可能性的概念有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</guid>
      <pubDate>Thu, 04 Jul 2024 00:35:03 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中以年龄为时间尺度的基线协变量</title>
      <link>https://stats.stackexchange.com/questions/650437/baseline-covariates-with-age-as-time-scale-in-survival-analysis</link>
      <description><![CDATA[我正在寻找以年龄为时间尺度的生存分析中纳入基线信息的正确方法（或确认我下面所说的是正确的）。
显然，如果您将原点设置为出生，那么协变量信息在那时将不可用。因此，另一种选择可能是确定感兴趣的最低年龄 - 例如 20 岁，将其设置为原点，然后对任何年龄超过 20 岁进入研究的人进行延迟进入和左截断。
我有两个与此相关的问题：

这依赖于拥有 20 岁时每个人的协变量信息，对吗？即，如果有人在 26 岁时进入研究，那么使用该年龄的协变量值作为基线是不正确的？如果您只有这些，您可以做些什么？
将每个人的年龄居中是否合适/必要？即从每个年龄中减去 20，这样“新”基线就是零？

另外，我还想知道当使用年龄作为时间尺度时，倾向得分匹配的含义是什么。
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/650437/baseline-covariates-with-age-as-time-scale-in-survival-analysis</guid>
      <pubDate>Wed, 03 Jul 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型、负信息标准值和 Hessian 矩阵不是正定的？</title>
      <link>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</link>
      <description><![CDATA[我正尝试在 R 中执行此操作。
glmm_res &lt;- glmer(Chla ~ Temp + Sal + TP + Pluviometry + (1 | season) + (1 | river), data = Chla_model, family = poisson)
summary(glmm_res)

我收到以下消息：
通知消息：
1：在 vcov.merMod(object, use.hessian = use.hessian) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵
不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov
2：在 vcov.merMod(object, correlation = correlation, sigm = sig) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵有限差分 Hessian 不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov

在中心化和缩放数据 scale(Chla_model[,2:15],center = T, scale = T) 甚至标准化 normalize(Chla) 之后，消息始终相同。
以下是汇总数据：
Chla_model &lt;- read.csv(&quot;D:/Article Sediment/ACP en langage R/Chla_model.csv&quot;, sep=&quot;;&quot;, stringsAsFactors=TRUE)
str(Chla_model)

&#39;data.frame&#39;: 45 obs. 16 个变量中的 16 个变量：
$ 季节：因子，3 个级别“干旱”、“洪水”等：1 1 1 1 1 1 1 1 1 1 ...
$ 温度：数字 30 28.9 29.8 30 30.7 31.1 32.7 33.3 31 31.7 ...
$ EC：数字 61 126 64 67 74 ...
$ DO：数字 5.59 3.55 3.96 2.74 2.58 5.62 3.37 6.24 4.57 5.14 ...
$ pH：数字 7.6 6.5 7.3 6.8 6.8 7.7 7 8 7.5 7 ...
$ 盐：数字0.0268 0.0579 0.0282 0.0297 0.0314 0.0302 0.0574 0.0345 0.0423 0.0975 ...
$ TP：数量 0.15 0.43 0.09 0.16 0.15 0.09 0.17 0.05 0.65 1.59 ...
$ PO43.：数量 0.08 0.09 0.04 0.04 0.02 0.04 0.02 0.04 0.09 0.09 ...
$ NO3. ：数量 1.4 0.95 0.34 0.17 0.23 0.21 0.25 0.8 1.07 1.15 ...
$ TN ：数量 2.43 1.84 2.39 0.74 2.41 0.37 0.69 1.31 1.96 1.85 ...
$ NH4. ：数字0.06 0.05 0.08 0.03 0.08 0.05 0.1 0.07 0.05 0.04 ...
$ NO2。 : 数值 0.011 0.005 0.019 0.015 0.018 0.013 0.02 0.02 0.012 0.014 ...
$ Chla : 数值 29.84 55.49 18.63 18.72 2.71 ...
$ 排放量 : 数值 9.5 9.5 9.5 9.5 9.5 72.3 72.3 72.3 72.3 72.3 ...
$ 雨量测定法 : 数值 115 115 115 115 115 ...
$ 河流 : 因子 w/3 个级别 “Bandama”、“Bia”、..: 3 3 3 3 3 1 1 1 1 1 ...

我欢迎您提供任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</guid>
      <pubDate>Wed, 03 Jul 2024 19:13:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信区间有效？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</link>
      <description><![CDATA[最近，我开始了我的统计学之旅，以便更好地了解该领域。以前，我的统计学经验包括记住公式、条件和后者的应用。虽然人们常常可以摆脱这种肤浅的理解，但我忽略了大多数统计实践背后的直觉。
特别是，我开始质疑置信区间的数学价值。我的理论理解如下。任何置信区间的基础都是抽样分布的概念，这是一种理论分布，我们将样本统计量纳入每个可能的大小为 n 的样本；该分布的平均值是真实的总体参数。从那里，我们选择一个所需的置信水平（用 t 或 z 值表示），并使用我们的理论抽样分布的标准差，我们构建一个区间。根据定义，我们的置信水平将表示来自我们的样本分布的总样本的百分比，这些样本在真实总体统计量的误差范围内。换句话说，如果我们要重复收集大小为 n 的样本并构建相同置信水平的置信区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。
从理论上讲，数学是可行的。但在实践中，我们所做的事情与这一理论基础背道而驰。我将说明三种我有疑问的情况：
例如，假设我们试图为总体比例创建置信区间。比例的中心极限定理和数学推理使我们得出结论，对于足够大的大小为 n 的样本，抽样分布呈正态分布，其平均值为 $p$，标准差为 $\sqrt(\frac{p(1-p)}{n})$。理论上，如果我们采用 $\hat{p}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们没有这样做，因为我们不知道 $p$ 是什么，因此不知道抽样分布的标准差。相反，我们使用 $\hat{p}$ 作为标准差方程中的替代：$\sqrt(\frac{\hat{p}(1-\hat{p})}{n})$。即使我知道 $\hat{p}$ 是 $p$ 的无偏估计量，我们怎么能确定 $C%$% 的假设区间将捕捉到真实的总体参数呢？
当然，在估计总体平均值时，我也有同样的疑问。比例的中心极限定理和数学推理使我们得出结论，对于足够大的样本 n，抽样分布呈正态分布，其平均值为 $\mu$，标准差为 $\frac{\sigma}{\sqrt(n)}$。理论上，如果我们采用 $\bar{x}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们不会这样做，因为我们通常不知道 $\sigma$ 是什么，因此不知道抽样分布的标准差。在这些情况下，我们使用标准误差来近似标准差：$\frac{s_x}{\sqrt(n)}$。鉴于这一变化，我们如何确保 $C%$% 的假设区间能够捕捉到真实的总体参数？
对于更一般的情况，中心极限定理可能不适用，统计学家使用引导法来计算置信区间。总之，他们从原始大小为 n 的样本中创建许多大小为 n 的有放回样本。通过绘制每个样本的样本统计量，我们可以创建一个伪抽样分布。从那里，我们可以通过选择与第 50 个百分位数等距的两个百分位数来创建置信区间。例如，创建一个间隔，其中第 5 个和第 95 个百分位数的值代表 90% 的置信区间。然而，这似乎是一个很大的延伸。也就是说，我们假设伪分布的标准差是我们真实抽样分布的标准差。我们如何确保$C%$% 的假设区间能够捕捉到真实的总体参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</guid>
      <pubDate>Wed, 03 Jul 2024 18:57:10 GMT</pubDate>
    </item>
    <item>
      <title>在双变量线性回归中，为什么 $Y = \alpha X + \beta + U$，其中 $\alpha$ 和 $\beta$ 是实常数，而 $U$ 是一个假设？</title>
      <link>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</link>
      <description><![CDATA[假设我想对随机变量$Y$和$X$之间进行双变量回归。在我所阅读的教科书中，主要是 Jeffrey Wooldridge 所著的《计量经济学导论》和 Davidson 与 Mackinnon 所著的《计量经济学中的估计与推断》，其中我们假设 $Y$ 和 $X$ 是线性相关的：$Y = \alpha X + \beta + U $ 其中 $\alpha \text{ and } \beta$ 是实常数，而 $U$ 是被称为误差或扰动的随机变量。我不太明白为什么用 $X$ 来表示 $Y$ 必然是一种假设。似乎我们总是能够用 $X$ 来表示 $Y$，这仅仅是由于对随机变量的算术运算。
我的意思是：从线性代数的角度来看，让我们考虑在公共样本空间 $S$ 上定义的所有实值随机变量的集合，并假设 $Y$ 和 $X$ 属于 $S$。 $S$ 是一个向量空间，前提是标量乘法和向量加法以标准方式定义，因此，对于任何实数 $\alpha$ 和 $\beta$，我们有 $\alpha X + \beta$ 也属于 $S$，并且 $Y$ 与 $\alpha X + \beta$、$Y - \left( \alpha X + \beta \right)$ 之间的差值也位于 $S$ 中。将该差值称为 $Y - \left( \alpha X + \beta \right) = U .$，因此 $Y = \alpha X + \beta + U $。我不明白我们实际上“假设”了什么，除了 $Y$ 和 $X$ 是在公共样本空间中定义的随机变量，但这似乎很简单。我明白，如果我们指定一个标准，例如最小化 $Y$ 和 $\alpha X + \beta$ 之间的 MSE，那么我们就会得到 $\alpha \text{ and } \beta$ 必须是什么。但简单地用 X 线性表示 Y 似乎不是一个假设。我听说真正的关系可能不是，而且通常不是真正线性的，因为 Y = $\alpha X + \beta$ 其中 $U$ 等于零，我明白了。但是我不明白我如何仅通过用 $X.$ 来表达 $Y$ 就假设了任何有关真实关系的事情。我误解了什么吗？我在其他地方问过这个问题，人们断言方程式 $Y = \alpha X + \beta + U$ 是关于 $Y$ 和 $X$ 之间关系的断言，但我就是不明白为什么。任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</guid>
      <pubDate>Wed, 03 Jul 2024 18:51:54 GMT</pubDate>
    </item>
    <item>
      <title>将相关性与概率联系起来</title>
      <link>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</link>
      <description><![CDATA[给定两个中心化且经过缩放的随机变量 $X$ 和 $Y$，您能将它们具有相同符号的概率与它们的相关性联系起来吗？如果相关性接近 $1$，我设想平面中的联合分布主要集中在第一象限和第三象限，其中 $X$ 和 $Y$ 具有相同的符号。情况总是如此吗？是否存在反例，其中相关性接近 $1$，但具有相同符号的概率很低？那么是否存在界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</guid>
      <pubDate>Wed, 03 Jul 2024 18:27:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ggpredict 获取第 25 和第 75 百分位数的相应标准误差</title>
      <link>https://stats.stackexchange.com/questions/650423/how-to-get-corresponding-standard-error-of-the-25th-and-75th-percentile-using-gg</link>
      <description><![CDATA[我正在使用 ggpredict 函数获取高度的预测值，其中包含 x、predicted、std.error、conf.low 和 conf.high（如下面的屏幕截图所示）
pred_height&lt;-as.data.frame(ggpredict(modfit, term=&quot;height&quot;, representative=&quot;mean&quot;, back.transform=FALSE))

我使用 quantile(pred_height$predicted) 获得了 75 百分位数和 25 百分位数的预测值。但是，我认为我无法获得使用 quantile(std.error) 预测的 25 百分位数和 75 百分位数的相应标准误差。我想知道如何获得相应的 SE？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650423/how-to-get-corresponding-standard-error-of-the-25th-and-75th-percentile-using-gg</guid>
      <pubDate>Wed, 03 Jul 2024 17:31:46 GMT</pubDate>
    </item>
    <item>
      <title>对每行具有不同数量因子的数据集进行建模（非二项式）</title>
      <link>https://stats.stackexchange.com/questions/650422/modeling-for-a-data-set-that-has-different-number-of-factors-for-each-row-not-b</link>
      <description><![CDATA[我遇到的建模问题是每行的分类变量具有不同数量的因子。如果我可以按产品（a、b、c、.....~cost、hoursum、numPod、numDate）重塑数据，以便因变量为产品类型（a、c、b、...），其余数值是独立的，这可能是一种选择，但这会违反自由度，因为它是小数据集。（并且不应包括“周”）
那么我应该如何分析成本，或者我应该对这些数据使用什么模型，因为每行都有不同数量的产品因子（Prod1 到 Prod6）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650422/modeling-for-a-data-set-that-has-different-number-of-factors-for-each-row-not-b</guid>
      <pubDate>Wed, 03 Jul 2024 17:22:18 GMT</pubDate>
    </item>
    <item>
      <title>如果有三次多项式特征，那么这不是多项式回归，而不是线性回归吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650421/if-there-are-cubic-polynomial-features-then-isnt-this-a-polynomial-regression</link>
      <description><![CDATA[我有以下问题：

考虑一个具有两个特征的线性回归问题。根据您对训练集上这些 2D 特征 $x_1$ 和 $x_2$ 的可视化，您注意到使用三次多项式特征应该可以获得更好的模型性能。将所有多项式特征以 $x_1$ 和 $x_2$ 的形式写下来。

我发现这个问题的措辞令人困惑。如果有三次多项式特征，那么这难道不是多项式回归，而不是线性回归吗？我的理解是，如果我们有三次多项式特征 $x_1$ 和 $x_2$，那么多项式回归将是 $ \hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1^2 + \beta_4 x_1 x_2 + \beta_5 x_2^2 + \beta_6 x_1^3 + \beta_7 x_1^2 x_2 + \beta_8 x_1 x_2^2 + \beta_9 x_2^3$，对吗？但交互项不是使其变为非线性而不是线性（回归）吗？我在这里误解了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650421/if-there-are-cubic-polynomial-features-then-isnt-this-a-polynomial-regression</guid>
      <pubDate>Wed, 03 Jul 2024 16:59:00 GMT</pubDate>
    </item>
    <item>
      <title>回归的预处理数据：仅缩放/标准化联合观测，还是分别缩放/标准化回归量和回归对象观测？</title>
      <link>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</link>
      <description><![CDATA[假设您观察到两个变量$X, Y$（回归量和回归函数），它们在统计上是相关的，$Y \sim X$。
您的数据是独立同分布样本$\mathcal{D}:=\{(x_j, y_j) \mid j=1,\ldots, N\}\subset \mathbb{R}^ {d_X}\!\!\times\!\mathbb{R}^{d_Y}$ of $(X,Y)$。
然后，您想对这些数据应用某种回归方法，比如核岭回归或 SVR。
为此，通常建议对数据样本进行预处理$(x_j)$ 和 $(y_j)$ 可以通过对它们进行归一化或标准化来量化。
问题：这样的标准化/归一化是否会应用于联合观测值$\{(x_j, y_j)\}$（的子集），或者组件数据$(x_j)$ 和 $(y_j)$ 是否应该分别缩放？
由于关联$Y\sim X$ 非常非线性（例如$Y = e^X + \varepsilon$ 或类似），分别预处理 $(x_j)$ 和 $(y_j)$ 似乎是有问题的，因为分别对回归对象和回归量样本应用不同的（$(x_j)$- 和 $(y_j)$-依赖）尺度可能会对统计关联 $Y\sim X$ 造成非平凡的干扰。
很高兴看到相关文献或任何最佳实践的链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</guid>
      <pubDate>Wed, 03 Jul 2024 16:49:03 GMT</pubDate>
    </item>
    <item>
      <title>计算百分比标准化</title>
      <link>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</link>
      <description><![CDATA[请不要笑或关闭这篇文章，我对如何计算治疗后发生的正常化百分比感到困惑。
所以，这是问题的背景，我从用药物 A 和 B 治疗的对照和患病样本中读取了数据。读数是在药物的两个时间点，即时间 0 和时间 x。这些记录在下表中。
 基因控制 DrugA.to DrugA.tx DrugB.to DrugB.tx
GeneA1 0.255137598 0.996823656 0.841427508 0.838585838 0.637163007
GeneA2 0 1.002128241 1.088924271 0.708817547 0.858001516
GeneA3 0.649779583 0.970614468 0.883699106 0.863034514 0.863533489
GeneA4 0.261785973 1.228567772 0.860292411 0.950751742 1.026950264
基因A5 0 0.964363461 1.177734151 0.831123556 1.496702315
基因A6 0.539853517 1.185978246 0.999361733 0.88790566 0.926980252
基因A7 0.609842771 1.245618868 1.095380831 0.91075683 1.038654277
基因A8 0.546278983 1.143557146 1.31081493 0.961478462 0.955452931
基因A9 0.278067545 1.565468159 1.2463365 1.039837814 0.961697678
基因A10 0.841483131 1.637659304 1.195102944 1.171462249 1.274326013
基因A11 1.066410285 1.40104267 1.200123252 0.957711736 1.525794178
基因A12 2.613408631 1.052950881 0.908745691 0.863034514 0.892767429
基因A13 2.583216456 1.105396939 1.242388547 0.87318548 0.623271818
基因A14 2.800415579 1.097795107 0.999763993 0.893300428 0.863533489
基因A15 1.044277784 1.534601183 1.213267026 1.08889909 1.797417187
GeneA16 0 2.476333854 2.055473655 1.021699805 1.138185985
GeneA17 1.861254616 1.147626264 1.72825638 1.009700622 0.963547498
GeneA18 0.850735068 2.07213776 1.675176397 1.352168483 1.026950264
GeneA19 2.784079193 1.097795107 1.03334891 0.863034514 1.246543636
GeneA20 0.600378056 1.55167128 1.837088792 1.116134855 2.35125585
GeneA21 0.789140187 2.195590214 2.109625834 1.322807345 1.200786951
GeneA22 0.560671399 1.559604269 2.014979635 1.634260415 1.910905861
GeneA23 3.176300908 1.200678944 1.406041611 0.890985128 1.200293773
GeneA24 1.959958568 1.747658569 1.31081493 1.394319133 1.533792282
GeneA25 1.815692 1.933923319 1.221955458 1.08889909 1.971098865
GeneA26 2.918198494 1.2461771 1.847890057 0.998327027 1.200786951

现在我如何显示和/或计算药物 A或者药物 b 使基因表达更接近对照。我所说的“接近对照”是指，治疗后，时间 x 处的基因表达要么减少，要么增加，但其方向与对照方向一致，例如，GeneA1 在对照中的表达为 0.25，而在用药物 A 治疗的患病样本中，表达减少了 15.15% ((0.84-0.99)/0.99)，而用药物 B 治疗的表达减少了 24%。因此，对于基因 A，可以说药物 B 使基因表达更接近对照。现在，我想计算药物 A 和 B 的总体效果，而不是单个基因。
我可以计算每种药物每个基因的倍数变化或百分比倍数变化，但我如何显示哪种药物使基因表达更趋向于控制。
我脑海中有一个这样的图，其中绿色和紫色是药物 A 和 B。

感谢您的时间和帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</guid>
      <pubDate>Wed, 03 Jul 2024 15:57:27 GMT</pubDate>
    </item>
    <item>
      <title>对于动物袭击记录的时间序列，最佳的混合模型方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</link>
      <description><![CDATA[我有 2007 年至 2022 年巴西各州动物袭击记录的数据集。我有三个解释变量，它们已标准化以用于分析。为了将数据的时间自相关性纳入混合模型，我考虑使用具有泊松分布（计数数据）的 glmmPQL（MASS 包）。由于此分析不允许获取 AIC 值，因此我考虑通过目视检查残差来评估模型的最佳自相关结构。模型的结构如下。我使用 r.squaredGLMM 函数获得了 R^2 值，但它给出了两个不同的 R^2 值（见下文）。因为这是我第一次使用具有时间自相关的混合模型，所以我想知道我是否朝着正确的方向前进。
模型 &lt;- glmmPQL(attacks~x1 + x2 + x3,random=~1|ID,data=envir,family=poisson, correlation=corGaus(form = ~ year|ID))
###“ID”代表巴西各州，“年份”代表表示每年（2007-2022 年）和每个州的袭击次数。
plot(model)#检查残差
r.squaredGLMM(model)#package MuMIn
 R2m R2c

delta 0.6348790 0.9995354
lognormal 0.6348793 0.9995358
trigamma 0.6348788 0.9995350]]></description>
      <guid>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</guid>
      <pubDate>Wed, 03 Jul 2024 14:46:02 GMT</pubDate>
    </item>
    <item>
      <title>关联替代方案/如何测试这种关系？</title>
      <link>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</link>
      <description><![CDATA[我有来自上游和下游测量仪的大量温度数据。我试图找出大坝泄水对下游温度的影响。为此，我正在比较尾水测量仪（位于大坝正下方）与各个下游站点之间的相关性。这是我的数据集。
&gt; dput(head(TravelTimeAdjustedSaltData))
结构(列表(日期 = 结构(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), 类 = c(&quot;POSIXct&quot;, &quot;POSIXt&quot;
), tzone = &quot;UTC&quot;), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(NA, NA, NA, NA, 7.8908984375, 
7.847998046875), S5 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S6 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S7 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S8 = c(12.309638671875, 12.309638671875, 
12.26673828125, 12.3525390625, 12.3525390625, 12.309638671875
), S9 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_
), S10 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), S11 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), GaugeTemp = c(8.2, 8.2, 8.2, 8.2, 8.2, 8.2), GaugeHeight = c(70.83, 
70.84, 70.84, 70.85, 70.83, 70.83)), row.names = c(NA, 6L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))

数据根据下游水流的流动时间进行了调整，这就是为什么某些列的前几行有 NA。无论如何，我进行了 Spearman 相关性分析，但发现了一种意料之外的模式，因此，我认为相关性并没有真正检验出我真正想要发现的东西。我发现，下游站点 (S10 / S11) 与尾水水位计的相关性实际上比下游第一个站点 (S4) 更高或大致相同。我同时包含了 S4（距离尾水下游最近的站点）和 S11（距离尾水最远的站点）来说明我的意思。事实并非如此，因为大坝泄水对下游温度的影响应该会随着距离的增加而减小。这让我相信相关性测试不是我的问题的答案。


cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S11, method = &quot;spearman&quot;, na.rm=TRUE)
cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S4, method = &quot;spearman&quot;, na.rm=TRUE)
我不知道如何测试大坝泄洪的原因（即尾水压力表温度读数）及其影响（下游温度读数）。我正在研究两者之间的某种非参数回归，但不确定这是否是正确的方法。任何帮助都将不胜感激。我只是想要一种统计方法来显示大坝泄洪是否确实对下游产生影响。相关性似乎没有达到这个目的（虽然不确定为什么）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</guid>
      <pubDate>Wed, 03 Jul 2024 13:20:19 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的混杂变量：辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</link>
      <description><![CDATA[我正在研究一个混合效应回归模型，其中 Yi = 学生 i 的考试成绩。
解释变量如下：

级别 3：学校类型（公立与私立）和学校的社会经济水平（数字变量）

级别 2：每个班级的教育模式（100% 西班牙语、50% 西班牙语、特殊教育）

级别 1：移民背景（学生是否是移民）、学生的社会经济水平（数字变量）、在家使用的语言（西班牙语或其他语言）以及学生的身份（学生是否必须留级）
我使用两个模型来解释 Y。第一个模型不包括变量 student_socioeconomic 和student_idoneity。
model1 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_inmigrant + student_language)
model2 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_socioeconomic + student_inmigrant + student_language +
student_idoneity)


在第一个模型中，变量“student_inmigrant”的估计系数在 1% alpha 水平上为正且显著。然而，当我添加变量“student_socioeconomic”时和“student_idoneity”，变量“student_inmigrant”的估计系数在 1% alpha 水平上变为负且显著。
我认为这里存在混杂变量的问题，但我不知道如何解决。您能给我一些关于如何处理这个问题的建议吗？
我检查了存在多重共线性时的 VIF 值，但 student_inmigrant、student_idoneity 和 student_socioeconomic 的调整后的 GVIF 都低于 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</guid>
      <pubDate>Wed, 03 Jul 2024 12:15:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要使用零假设下假设的值来计算比例的标准差？</title>
      <link>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</link>
      <description><![CDATA[在计算第 2 类错误时，为什么即使我们将备择假设作为可能的真实值，我们仍使用零假设下的假设值来计算标准差？
如果零假设中 u = 20，备择假设中 u = 24，且采样 x = 21，则 H0σ（基于零假设计算）。我们通过“(x-24)/H0σ”计算第 2 类错误。我的问题是为什么不使用 H1σ...？
示例案例 - https://www.youtube.com/watch?v=BJZpx7Mdde4
我的教科书中的另一个示例案例（Martin Sternstein 先生的 EZ-101 统计学）
]]></description>
      <guid>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</guid>
      <pubDate>Wed, 03 Jul 2024 00:31:40 GMT</pubDate>
    </item>
    </channel>
</rss>