<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 12 Jan 2025 12:30:29 GMT</lastBuildDate>
    <item>
      <title>时间序列回归的滚动 PCA：信息泄露</title>
      <link>https://stats.stackexchange.com/questions/659913/rolling-pca-for-time-series-regression-information-leakage</link>
      <description><![CDATA[假设一个随机变量$y_{i,t}$由一些线性因子$x_{t,j}$和一个随机噪声项$\epsilon_{i,t+1}$控制：
$$
y_{i,t} = \sum_{j}^{M+1}\beta_{j,i}x_{t,j} + \epsilon_{i,t+1}
$$
写得更紧凑：
$$
\mathbf{Y} = \mathbf{X}\mathbf{\beta} + \mathbf{E}
$$
其中，

$\mathbf{Y}$ 是一个 $(T,N)$ 矩阵
$\mathbf{X}$ 是一个 $(T,M)$ 矩阵
$\beta$ 是一个 $(M,N)$ 时不变参数矩阵，用于解释 $M$ 个因素对 $N$ 个随机变量的影响。
$\mathbf{E}$ 是一个 $(T,N)$ 矩阵，包含 $T$ 个误差项，维度为 $N$，即 $E \sim N(0,\Sigma_{\epsilon})$

使用这种因子模型，我们可以更稳健地分解和估计均值和方差，因为 $
\mathbb{X}$ 的维度要小得多，即 $M&lt;&lt;N$。
$$
\mathbb{E}_{t|t-1}[\mathbf{Y}] = \mathbf{\mu}_{t} = \mathbf{x}_{t}\mathbf{\beta} \\
\mathbb{V}_{t|t-1}[\mathbf{Y}] = \mathbf{\Sigma}_{t} = \mathbf{x}_{t}\Sigma_{x}\mathbf{x}_{t}^{T} + \Sigma_{\epsilon}
$$
我选择 PCA 作为统计潜在因子，而我的估计选择是时间序列回归方式。我是否对贬低的$\mathbf{Y}$进行 SVD 或对经验协方差进行 PCA 并不重要，假设我进行前者。回归现在将是：
$$
y_{i,t} = \sum_{j}^{M+1}\beta_{j,i}PC_{t,j} + \epsilon_{i,t+1}
$$
这里出现的问题是 $PC_{t,j}$ 已使用 整个 $
\mathbf{Y}$ 矩阵进行估计，即它依赖于 $y_{i,t+1}, y_{i,t+2}, ... y_{i,T}$，因此存在信息泄露。
我可以选择进行滚动 PCA。使用移动窗口 $t$ 来 $t+w$ 估计 PCA，并得出 $PC_{t+w}$。但是，我需要 $PC_{t+w}$ 为标量，而不是向量，否则在上述问题中 $\mathbf{X}$ 变为三维（PC 数量、次数、窗口数量）。在这种情况下如何执行滚动 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/659913/rolling-pca-for-time-series-regression-information-leakage</guid>
      <pubDate>Sun, 12 Jan 2025 12:28:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用引导程序处理大规模文本匹配和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</link>
      <description><![CDATA[我有一个大型数据库，其中有一个字符列，其中包含数百万个产品描述。我有一个参考表，其中有一个字符列，其中包含我试图匹配的描述。我将使用 EXACT 匹配、IN 匹配和最终的 Levenshtein 距离进行匹配。然后我想计算匹配次数。有时会出现错误匹配，例如参考词包含在一个不匹配的大词中，这更像是参考数据的异常。所以我还想在组合中添加不确定性。我不会在完成后检查所有匹配，因为匹配实在太多了。
我对此有两个疑问：

我知道如何进行匹配。这不是问题。我想计算匹配次数，并说我们怀疑 3 月份有 200 次匹配。我们不知道误报率，但它很小（我们怀疑）。参考列表由另一个部门保存。假阳性可能由包含单词的产品引起，例如 shoe 可能包含在 Shoehorn 中。引导捆绑是一种我可以使用的方法吗？逐月从数据库中提取数据，然后应用匹配。这将为我提供该月的总匹配数，然后从每月样本中进行引导（10k 个案例 5000 次，并将这些案例相加并计算置信区间。

假设 A 是正确的。在理想情况下，我会这样做，其中一行包含一个产品实例。但是数据库很大。是否可以先在数据库中聚合 Shoehorn - 100 个匹配项。然后进行引导。这不会给我一个完全不同的答案吗，因为抽样不再在 100 个匹配项中随机抽样，它会将 Shoehorn - 100 个匹配项作为单个记录进行抽样。


所以我的问题是第一点是否是解决这个问题的有用方法，第二点是关于如何聚合数据对置信区间的有效性的影响。
下面是一些 R 代码，它生成数据的两种方法出现
# 加载必要的库
library(dplyr)

# 生成逐行数据 ----------------------------------------------------------
# 生成具有随机卷的虚假产品描述数据
set.seed(123)
descriptions &lt;- c(
&#39;红色鞋子&#39;, &#39;蓝色衬衫&#39;, &#39;绿色鞋带&#39;, &#39;黄色鞋拔&#39;, 
&#39;黑色帽子&#39;, &#39;白色鞋子&#39;, &#39;粉色衬衫&#39;, &#39;灰色帽子&#39;, 
&#39;紫色鞋拔&#39;, &#39;橙色鞋带&#39;
)
volumes &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)

product_descriptions &lt;- data.frame(
ProductID = unlist(lapply(1:10, function(i) rep(i, volumes[i]))),
Description = unlist(lapply(1:10, function(i) rep(descriptions[i], volumes[i]))),
Volume = unlist(lapply(1:10, function(i) rep(volumes[i], volumes[i])))
)

# 随机抽取 5000 行并替换以生成逐行产品
set.seed(456) # 设置种子以实现可重复性
line_by_line_df &lt;- product_descriptions %&gt;%
sample_n(5000, replace = TRUE) |&gt; 
mutate(ProductID = row_number()) %&gt;% 
mutate(match = sample(0:1, n(), replace = TRUE))

# 生成聚合数据 -------------------------------------------------
# 在这里我们从&quot;database&quot; 中提取并汇总数据库中的计数
aggregated_df &lt;- line_by_line_df |&gt; 
group_by(Description) |&gt; 
summarise(total_products = sum(Volume),
matches = sum(match))

]]></description>
      <guid>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</guid>
      <pubDate>Sun, 12 Jan 2025 12:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如果水平为 $\alpha$ 的假设检验对我的实际样本拒绝，那么所有水平 > $\alpha$ 的检验是否也会拒绝同一个样本？</title>
      <link>https://stats.stackexchange.com/questions/659910/if-a-hypothesis-test-with-level-alpha-rejects-for-my-realized-sample-will-al</link>
      <description><![CDATA[问题：如果水平为 $\alpha$ 的假设检验拒绝了一个已实现样本，那么水平 &gt; $\alpha$ 的所有检验是否也会拒绝同一个样本？
正式地：让 $\hat{\psi}_{\alpha} \in \{0, 1\}$ 成为我的水平为 $\alpha$ 的检验。我获得一个已实现样本 $x_{obs} = \left( x_1, ..., x_n \right)^{T}$，并获得了拒绝的决定，即 $\hat{\psi}_{\alpha}(x_{obs}) = 1$。这是否意味着同一家族（即相同的零模型和备选模型，以及相同的检验统计量）但水平为 $&gt; \alpha$ 的任何检验也将拒绝 $H_0$？我们将这样的检验称为 $\hat{\psi}_{&gt; \alpha}$。
更直观地，如果我们考虑单调递增的级别序列$\{\alpha\}_{0 \le \alpha \le 1}$，我们有相应的测试$\{\hat{\psi}_{\alpha}\}_{0 \le \alpha \le 1}$和决策$\{\hat{\psi}_{\alpha}(x_{obs})\}_{0 \le \alpha \le 1}$，是否可以保证我的决策序列看起来像 00000000111111...，或者可能是像 00001010001111... 这样的序列？
我看到一些幻灯片中有人断言了这一说法（幻灯片 3 和 4 上的橙色框，“请注意...”位于 https://pages.stat.wisc.edu/~shao/stat610/stat610-13.pdf）：

请注意，inf({t ∈ (0, 1) : $T_t(x_{obs})$ 拒绝 $H_0$}) ≤ α 意味着 $T_α(x_{obs})$ 拒绝 $H_0$。

但我觉得它唯一正确的方法是，如果拒绝域序列 $\{RR_{\alpha}\}_{0 \le \alpha \le 1}$ 随着级别的增加而成为彼此的超集。我认为这一般不能保证吗？对于某些特定类别的测试，例如 UMP 测试，它有保证吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659910/if-a-hypothesis-test-with-level-alpha-rejects-for-my-realized-sample-will-al</guid>
      <pubDate>Sun, 12 Jan 2025 11:35:17 GMT</pubDate>
    </item>
    <item>
      <title>不存在负负数据时的评分者间信度</title>
      <link>https://stats.stackexchange.com/questions/659908/inter-rater-reliability-when-negative-negative-data-does-not-exist</link>
      <description><![CDATA[我想分析口语表达以确定隐喻的使用。两位评分员将独立分析全文，并识别、计数和列出他们发现的隐喻。然后将他们的列表进行比较以确定一致性。可能的结果是两位评分员都同意某个语言实例是隐喻，或者一位评分员发现/识别出某个语言实例是隐喻，但另一位评分员不同意（他们实际上不同意）。Cohen Kappa 通常用于两人评分者间信度。问题是，在我描述的研究中，不会有任何负负一致性的机会，即两位评分员都将一段语言识别为非隐喻（大多数文本都不是隐喻，这是一个寻找语言的问题）。这可能会导致数据偏差，因为观察到的一致性可能看起来很低，因为没有负负一致性。是否有替代的 Cohen Kappa 来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659908/inter-rater-reliability-when-negative-negative-data-does-not-exist</guid>
      <pubDate>Sun, 12 Jan 2025 10:38:46 GMT</pubDate>
    </item>
    <item>
      <title>估计混合效应模型后，如何使用附加数据更新新组的 BLUP？</title>
      <link>https://stats.stackexchange.com/questions/659906/how-to-update-blup-for-a-new-group-with-additional-data-after-estimating-a-mixed</link>
      <description><![CDATA[问题。在估计混合效应模型后，如何更新随机效应的 BLUP 以适应具有额外数​​据的新组，从而实现准确预测？
目标。我有水污染物浓度的纵向数据，每个单位（即样品采集点）的观测次数随时间变化，范围在 1 到 10 之间。除了在同一地点重复测量外，这些地点还按水系统聚类（由于共用管道），而水系统又按地理区域聚类（由于共用水源）。研究目的是创建一个预测模型，以准确预测预测站点未来时间点的水污染物浓度，理想情况下具有可解释的预测、置信度或可信区间。预测地点及其水系统可能包括在模型开发样本中，也可能不包括在内，但将提供其历史数据（包括响应和预测因子），而这些数据在模型估计时不可用。
现有方法。我的理解是，最合适的模型类型是具有时间趋势平滑函数的混合效应 Cox 比例风险模型，因为 Cox 模型对于严格正响应和非检测删失具有分布自由的灵活性。但我不认为模型类型在特定地点预测的方法中很重要。因此，为了概念简单起见，我们可以在线性混合模型下进行讨论。随机效应方差可能很大，尤其是聚集在地理区域聚集的水系统中的收集点的随机截距。因此，控制新组的随机效应对于减少预测误差非常重要。我注意到，在混合效应模型的后估计例程中，有几个统计软件包允许新组，例如 R 软件包 lme4 在 predict() 中提供了参数 allow.new.levels = 。但是，启用此参数将 (1) 将所有随机系数设置为 0，并为新组提供非常大的标准误差（完全包括随机效应的不确定性）或 (2) 将随机系数设置为其组特定的 BLUP，并为现有组提供非常小的标准误差（我推测不包括任何随机效应的不确定性）。我认为它们都不符合我的目标。
暂定方法。我认为我应该利用在模型估计后在模型部署期间提交的预测站点的历史数据，以减少预测误差。我的计划如下。

使用频率论框架和软件包下的模型开发样本估计模型。提交新站点数据后，通过结合模型开发样本和新站点数据重新估计模型。使用模型开发样本是因为新站点数据的样本量可能太小，无法估计所有参数。为了加速重新估计的收敛，请在先前的点估计中设置固定系数和随机效应方差（或其他一些估计量，如对数标准差）的起始值。然后将 predict() 应用于重新估计的模型，其中新站点成为现有组。但是，当参数 re.form = NULL 包含所有随机效应时，我不知道预测标准误差中不包括哪种不确定性。
使用贝叶斯框架和包下的模型开发样本估计模型。提交新站点数据后，仅使用新站点数据拟合新模型，并将先验设置为先前估计的后验分布。我认为在重新拟合过程中不需要大量的模型开发样本，因为其信息已包含在所选先验中。如果先验很强，贝叶斯模型似乎在样本量小于参数数量时有效。但我对线性混合效应模型的解读表明，BLUP 是由整个响应系列生成的，因此仅新站点数据可能不足以对随机效应给出良好的估计。但是，如果我结合模型开发样本和新站点数据来重新估计模型，模型拟合过程可能会对最终用户花费太长时间。

我想到了上述两个选项，但我没有理论和实践经验来支持任何一个。你有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/659906/how-to-update-blup-for-a-new-group-with-additional-data-after-estimating-a-mixed</guid>
      <pubDate>Sun, 12 Jan 2025 08:14:53 GMT</pubDate>
    </item>
    <item>
      <title>DDPM 中的 $p_{\theta}(x_{t-1} | x_t)$ 仍然是条件 pdf 吗？</title>
      <link>https://stats.stackexchange.com/questions/659905/is-p-thetax-t-1-x-t-in-ddpm-still-a-conditional-pdf</link>
      <description><![CDATA[我正在阅读这篇论文（第 5 页中间），内容是关于去噪扩散模式。在逆向过程中，它指出我们无法直接计算$q(x_{t-1} | x_t)$，因此我们改为使用$p_{\theta}(x_{t-1} | x_t)$来近似它。如果我错了请纠正我，但我相信$q(x_{t-1} | x_t)$是给定$\mathbf{X}_{t}$的随机变量$\mathbf{X}_{t-1}$的条件pdf。这是否意味着近似值$p_{\theta}$也是条件pdf？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659905/is-p-thetax-t-1-x-t-in-ddpm-still-a-conditional-pdf</guid>
      <pubDate>Sun, 12 Jan 2025 08:12:11 GMT</pubDate>
    </item>
    <item>
      <title>在因子分析中，为什么因子载荷矩阵中有效参数的个数不是$\frac 12 k(k+1)$？</title>
      <link>https://stats.stackexchange.com/questions/659902/in-factor-analysis-why-is-the-number-of-effective-parameters-in-the-factor-load</link>
      <description><![CDATA[如果这是一个基本问题，我很抱歉，但我不知道我错在哪里。
考虑因子分析模型
\begin{equation*}
\begin{array}{cccccc}
X &amp; = &amp; L&amp; f &amp; + &amp; u \\ 
p\times 1 &amp; &amp; p\times k &amp; k\times k &amp; &amp; 
\end{array} 
\end{equation*
其中 $f \sim N(\mathbf 0, I)$ 和 $X\sim N(\mathbf 0,\Sigma) $。
在进行似然比检验时，我们需要确定因子载荷矩阵 $L$ 中有效参数的数量。
虽然 $L$ 有 $pk$ 个条目，但如果 $L$ 适合模型，那么对于任何 $O$ 正交，$LO$ 也适合。
因此我们实际上需要少于 $pk$ 个数字。我们知道这个数字是 $pk- \frac 12 k(k-1)$。
我理解我们可以添加限制，即 $L&#39;\Psi^{-1} L$ 是对角线的，
这又增加了 $\frac 12 k(k+1)$ 个限制。因此我们得到结果 $pk- \frac 12 k(k-1)$。
但我还推导出有效参数的数量是 $\frac 12 k(k+1)$，我不知道我错在哪里。
我的理由：假设我们知道 $\triangle$ 位置的参数：
\begin{equation*}
\begin{pmatrix}
\triangle &amp; \cdots &amp; &amp; &amp; \triangle \\ 
&amp; \triangle &amp; \cdots &amp; &amp; \triangle \\ 
&amp; &amp; &amp; &amp; \cdots \\ 
\cdots &amp; &amp; &amp; \cdots &amp; \triangle \\ 
\cdots &amp; &amp; &amp; &amp; 
\end{pmatrix} 
\end{equation*
即前 $k\times k$ 行和列的 $k$ 子矩阵的上对角线元素，
然后因为我们知道 $LL^T$，即每行的内积，
然后我们可以确定 $(2,1)$ 元素，并完成第二行。
第三行有两个未知元素，可以通过第三行和第一（第二）行的内积等确定，我们可以完成 $k\times k$ 子矩阵。
一般情况下$\text{rank}( L )=k$，而对于$(k+1),\cdots, p$行，由于我们知道它们与前$k$行的内积，而前$k$行构成一个非奇异矩阵，因此我们可以唯一地确定整个$L$。
因此$L$中有效参数的数量为$\frac 12 k(k+1)$。]]></description>
      <guid>https://stats.stackexchange.com/questions/659902/in-factor-analysis-why-is-the-number-of-effective-parameters-in-the-factor-load</guid>
      <pubDate>Sun, 12 Jan 2025 03:36:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 进行多层次结构方程建模？</title>
      <link>https://stats.stackexchange.com/questions/659901/using-r-for-multilevel-structural-equation-modeling</link>
      <description><![CDATA[我通常使用 Mplus，但手头没有。有人告诉我 MSEM 可以在 R 中完成，但我需要指导（网站或代码），因为我是 R 新手。
我对使用随机斜率作为 2 级结果的预测因子很感兴趣。任何关于在哪里查看的建议都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659901/using-r-for-multilevel-structural-equation-modeling</guid>
      <pubDate>Sun, 12 Jan 2025 03:29:10 GMT</pubDate>
    </item>
    <item>
      <title>零协方差何时意味着独立？</title>
      <link>https://stats.stackexchange.com/questions/659900/when-does-null-covariance-imply-independence</link>
      <description><![CDATA[众所周知，如果 $X,Y$ 是独立随机变量，则 $\text{Cov}(X,Y) = 0$。认为这一事实的反面成立也是一种很常见的谬论。但是，我的问题是，反面成立的情况不是经常发生吗？
例如，如果随机向量 $(X,Y)$ 呈正态分布，是一个二维随机向量，则 $X,Y$ 独立就等同于它们具有零协方差。
继续下去，由于 CLT，假设 $(X,Y)$ 呈正态分布是很常见的（即使在大多数情况下不是这样）。因此，尽管零协方差在学术意义上并不意味着独立性，但从更实际的意义上来说却意味着独立性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659900/when-does-null-covariance-imply-independence</guid>
      <pubDate>Sun, 12 Jan 2025 03:11:46 GMT</pubDate>
    </item>
    <item>
      <title>并行化蒙特卡罗模拟最简单的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</link>
      <description><![CDATA[据我所知，并行化蒙特卡罗模拟归结为将问题分解为子问题，并行运行它们以产生多个马尔可夫链，最后将马尔可夫链连接在一起。
现在的问题是，没有直接的方法来连接马尔可夫链。
并行化蒙特卡罗模拟最简单的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</guid>
      <pubDate>Sat, 11 Jan 2025 18:02:09 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\frac{\partial\log f(X;\theta)}{\partial \theta} \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，这一探究具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中，部分合并聚类估计值消失或超出总体估计值</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/（编辑：不幸的是，动画不再可见，至少在我的浏览器中）。
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应该限制在初始无池位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？我还没有拿尺子，但我的直觉也告诉我，尽管聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因是否可以从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么所有聚类估计值不应该沿着截距轴和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>DF 和 ADF 检验结果相矛盾</title>
      <link>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</link>
      <description><![CDATA[我正在对 globtemp 数据集进行单位根检验，该数据集显然是具有趋势和季节性（非平稳）的序列。但是，当应用简单的 Dickey-Fuller 检验时，我获得的 p 值很小，导致拒绝零假设并表明该序列是平稳的。
同时，使用增强版本 (ADF) 执行测试，使用 R 的默认滞后数 (k)，p 值不会拒绝零假设，表明时间序列是非平稳的。话虽如此，我很困惑，不明白这种差异。为什么在简单的 DF 测试（k=0）的情况下，测试无法产生真实的结果？此外，如果测试对“k”的选择如此敏感，那么最好的方法是什么？我们应该始终依赖默认值吗？
此外，我读到残差中存在自相关违反了测试中残差不相关的假设，可能会导致错误的结果。因此，我还评估了第一次测试（DF）残差中是否存在自相关，它们的行为与白噪声的行为一致（我也使用 Box-Ljung 对此进行了测试）。这让我对上面提到的不一致的结果更加困惑。
可以检查下面我所做的代码：
library(tseries)

globtemp &lt;- stats::ts(
c(-0.32, -0.32, -0.4, -0.39, -0.65, -0.43, -0.4, -0.52, -0.3, -0.12,
-0.4, -0.42, -0.39, -0.45, -0.35, -0.36, -0.19, -0.14, -0.37, -0.22,
0, -0.08, -0.24, -0.36, -0.49, -0.27, -0.19, -0.43, -0.29, -0.3,
    -0.29、-0.29、-0.28、-0.23、-0.04、-0.02、-0.24、-0.42、-0.35、-0.16、
    -0.17、-0.09、-0.13、-0.16、-0.14、-0.14、0.1、-0.03、0.03、-0.18、
    -0.06、0.04、0.02、-0.13、0.03、-0.06、0.02、0.13、0.13、-0.03、
    0.15、0.12、0.1、0.04、0.11、-0.04、0.01、  0.13、-0.01、-0.06、
    -0.14、-0.02、0.04、0.14、-0.07、-0.06、-0.17、0.1、0.1、0.05、
    -0.01、0.08、0.02、0.02、-0.26、-0.16、-0.09、-0.02、-0.12、0.03、
    0.04、-0.11、-0.07、0.19、-0.07、-0.05、-0.22、0.16、0.09、0.14、
    0.28、0.39、0.07、0.29、0.11、0.11、0.16、 0.32, 0.35, 0.25,
0.47, 0.41, 0.13),
start=1880, end = 1992)

plot(globtemp)

adf.test(globtemp, k=0) #DF 检验
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414

dx &lt;- diff(globtemp) 
x_lag &lt;- globtemp[-length(globtemp)] 
df_model &lt;- lm(dx ~ x_lag) 
summary(df_model)

residuals_df &lt;- resid(df_model)
acf(residuals_df, 50, main = &quot;&quot;) #否自相关
Box.test(residuals_df, lag = 15, type = &quot;Ljung-Box&quot;)

adf.test(globtemp) #ADF 默认为 &quot;k&quot;
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414
]]></description>
      <guid>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</guid>
      <pubDate>Fri, 22 Nov 2024 04:44:14 GMT</pubDate>
    </item>
    <item>
      <title>MA(1)-GARCH(1,1) 过程的无条件方差</title>
      <link>https://stats.stackexchange.com/questions/616494/unconditional-variance-of-ma1-garch1-1-process</link>
      <description><![CDATA[令 $y_t = \Delta{p_t}$ 表示资产对数收益的时间序列，其中 $p_t$ 是对数价格； $y_t$ 由条件异方差 MA(1) 过程生成
$y_t = \epsilon_t + \theta \epsilon_{t-1}$，其中 $\epsilon_t = \sqrt{h_t}z_t$ 且
$z_t\sim i.i.d N (0,1) $ 其中 $|\theta|&lt;1$，
$h_t = \omega+\alpha \epsilon_t^2+\beta h_{t-1},\quad \omega&gt;0, \alpha&gt;0 ,\alpha+\beta&lt;1$.

推导无条件均值$E(y_t)$、无条件方差$Var(y_t)$和自相关函数$y_t, \rho(k),k=1,2,.....$的表达式

我计算出无条件均值等于 0，因为$E(\sqrt{h_t} z_t)+\theta E(\sqrt{h_{t-1}}z_{t-1})=0 $
对于无条件方差$Var(y_t)= E(y_t^2)= (h_t z_t^2+\theta^2 h_{t-1} z_t^2)$ = $E(h_t+\theta^2 h_{t-1})$ 因为 $z_t\sim i.i.d N (0,1)$。
从现在开始我不确定。我是否应该用 $h_t$ 来代替？
任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/616494/unconditional-variance-of-ma1-garch1-1-process</guid>
      <pubDate>Sun, 21 May 2023 16:21:53 GMT</pubDate>
    </item>
    </channel>
</rss>