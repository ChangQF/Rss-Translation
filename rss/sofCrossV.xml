<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 13 Mar 2025 12:35:15 GMT</lastBuildDate>
    <item>
      <title>为什么最大似然估计过高或在稀疏事件的情况下？</title>
      <link>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</link>
      <description><![CDATA[在统计类别中，我们被教导说，当事件稀疏（相对于预测变量相对于预测变量的结果少），最大的可能性估计（MLE）通常高估了逻辑回归中的几率比（ORS）。）。
我了解为什么MLE在近距离分离或完全分离的情况下产生无限估计，而预测因子可以完美地预测结果。但是，我没有完全掌握为什么，为什么在稀疏数据的情况下（不分开），MLE倾向于高估OR，而不是简单地产生围绕真实价值的宽阔，不精确的置信区间。
一些解释提到，可能性表面在0（当𝛽0）接近0（当𝛽0）附近，使MLE向更陡峭的斜坡漂移，从而发现更大或估计。我不完全了解这种机制是如何工作的 - 为什么一个扁平的可能性表面会导致系统性高估，而不仅仅是不确定性？
有人可以帮助澄清：
为什么在逻辑回归中，可能性功能的形状会导致MLE在稀疏数据设置中高估的趋势？
为什么“更喜欢” mle&#39; β（效果更强​​）的绝对值较大，而不仅仅是在较小的估计值周围产生宽的顺式？
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</guid>
      <pubDate>Thu, 13 Mar 2025 12:09:35 GMT</pubDate>
    </item>
    <item>
      <title>线性回归后MRI多次测试比较</title>
      <link>https://stats.stackexchange.com/questions/662561/mri-multiple-test-comparisons-after-linear-regression</link>
      <description><![CDATA[我想问如何处理MRI脑图像中的多个测试比较。
我在70个大脑区域和40个功能区域（这是特定大脑区域的总和）进行了110个多个线性回归模型。我的模型控制了5个混杂因素和1个曝光。
这是我重要的p值（＆lt; 0.05）：0.038、0.014、0.014和0.04。
但是，当我应用FDR时，Q值是以下内容：0.00045、0.00091、0.00136、0.00182。
是否有任何方法可以处理这种苛刻的p值？]]></description>
      <guid>https://stats.stackexchange.com/questions/662561/mri-multiple-test-comparisons-after-linear-regression</guid>
      <pubDate>Thu, 13 Mar 2025 10:30:41 GMT</pubDate>
    </item>
    <item>
      <title>r中使用LME4的预测差异（考虑随机效应）</title>
      <link>https://stats.stackexchange.com/questions/662558/predictive-variances-with-lme4-in-r-accounting-for-random-effects</link>
      <description><![CDATA[考虑具有两个交叉随机效应的线性混合效应模型：
  y〜x * beta + z * b + epsilon。 
是否可以在R中使用 lme4 获得这种模型的预测差异？具体而言，（后）预测分布p（yp | y，xp，ZP），其中XP是协变量，ZP是进行预测的分组变量，是一个具有已知均值和协方差的高斯分布（假设ZB包含数据z中现有组已经存在的现有组）。是否可以使用 LEM4 获得此预测分布的差异？我知道 lme4 可以分别计算随机效果的条件（=后验）差异，但是当进行预测时，不能仅仅添加它们，因为它忽略了相关性（请参见下面的示例）。我还知道使用预测Interval 从 mertools 软件包进行计算预测间隔的软件包，可以进行调整以获得近似方差。但是我正在寻找一种获得确切差异的方法，鉴于对此有一个分析公式。
下面是一个示例，如何在 gpboost 中完成此操作
 ＃仿真数据
N＆lt;  -  400＃样品数量
m＆lt;  -  200＃大约1个类别 /级别的数量。分组变量
group1＆lt;  -  rep（1，n）＃分组变量
for（i in 1：m）group1 [（（i-1）*n/m+1）:( i*n/m）]＆lt;  -  i
group1＆lt;  -  group1 [sample.int（n，n，替换= true）]
group1＆lt;  - 匹配（group1，unique（sort（group1）））
set.seed（1）
b1＆lt;  -  sqrt（0.5） * rnorm（m）＃模拟随机效果
group2＆lt;  -  rep（1，n）＃2。分组变量
for（i in 1：（m/2））group2 [（（（i-1）*n*2/m+1）:( i*n*2/m）]＆lt;  -  i
group2＆lt;  -  group2 [sample.int（n，n，替换= true）]
group2＆lt;  - 匹配（group2，unique（stort（group2）））
b2＆lt;  -  sqrt（0.25） * rnorm（m）＃模拟第二个交叉随机效应
y＆lt; -b1 [group1] + b2 [group2] + sqrt（0.1） * rnorm（n）＃响应变量

＃带GPBoost的后差异
图书馆（GPBoost）
gpb_model＆lt;  -  fitgpmodel（group_data = cbind（group1，group2），y = y，x = rep（1，n），可能性=＆quot; gaussian;）
＃摘要（gpb_model）
pred＆lt;  - 预测（gpb_model，group_data_pred = cbind（group1，group2），x_pred = rep（1，n），precenta _var = true）
pred $ var
 
以下代码计算 lme4 中两个随机效应的条件差异，但忽略进行预测时随机效果之间的后验相关：
 库（LME4）
lme4_model＆lt;  -  lmer（y〜1 +（1 | group1） +（1 | group2），data = data.frame（y = y，group1 = group1，group2 = group2））
＃摘要（lme4_model）
ranef_vals＆lt;  -  ranef（lme4_model，condvar = true）
post_means_group1＆lt;  -  ranef_vals  $ group1 [，1]
post_means_group2＆lt;  -  ranef_vals $  group2 [，1]
post_var_group1＆lt;  -  attr（ranef_vals  $ group1，“ post var”）[1,1，]
post_var_group2＆lt;  -  attr（ranef_vals $  group2，&#39;post var＆quot; quot;
ristual_variance＆lt;  -  sigma（lme4_model）^2 
tot_var_lme4＆lt;  -  post_var_group1 [as.numeric（group1）] + post_var_group2 [as.numeric（group2）] + resctual_variance
TOT_VAR_LME4


＃与GPBoost的同一件事
pred_train＆lt;  -  gpb_model  $ predict_training_data_random_effects（prection_var = true）
appla（pred_train [，3：4]，1，sum） + gpb_model $  get_cov_pars（）[1] 
＃与&#39;tot_var_lme4&#39;相同，但与&#39;pred $ var&#39;不同
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662558/predictive-variances-with-lme4-in-r-accounting-for-random-effects</guid>
      <pubDate>Thu, 13 Mar 2025 09:05:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在MonoBit测试中确定阈值，为什么要比5％的显着性水平高1％？</title>
      <link>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</link>
      <description><![CDATA[在随机性的单托测试中，通过或失败的阈值基于置信区间。我了解到1％的显着性水平（99％的置信度）导致阈值较大，而显着性水平为5％（95％的置信度）。
然而，这似乎是违反直觉的 - 由于较高的信心应该意味着与预期的50:50比率更少的偏差，为什么它允许在零数量和零之间有更大的差异？更严格的测试（较低的alpha）不需要较小的偏差吗？
有人可以澄清阈值是如何设定的，为什么会发生这种行为？
我尝试的是：我审查了单片测试公式，该公式根据对应于所选置信度的z得分设置阈值。我还研究了95％和99％置信度的临界值是从正态分布中得出的。
我期望的是：我期望较高的置信度（99％）会导致更严格的测试，这意味着允许的数量和零之间的差异较小。
实际发生的事情：相反，我发现较高的置信度（99％）允许在零和零之间差异更大，而95％则允许置信度更大。这似乎是违反直觉的，因为我认为更严格的测试应该忍受较小的偏差。我想澄清为什么这是数学上会发生的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</guid>
      <pubDate>Thu, 13 Mar 2025 05:18:08 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助将名称放在发行</title>
      <link>https://stats.stackexchange.com/questions/662551/need-help-putting-a-name-to-a-distribution</link>
      <description><![CDATA[最近，我一直在研究精算师协会在我的ASA认证之路上进行的概率考试。现在有几个问题涉及一个可以表征如下的分布：
  $$
\ begin {Aligned}
p_x（x）=（1 -r）r^x = r^x -r^{x+1}
\ end {Aligned}
$$  
如果我错了一般的公式，请纠正我，这已经晚了，我有点累。本质上，这是概率质量函数的一般形式，该概率质量函数在支持 $ r \ in（0,1）$  in Support  $ x \ in（0，\ infty）
  $$
p_x（n+1）= r*p_x（n）
$$  
即。发生事件发生的概率再次产生的概率小于先前的概率，而 $ r $ 。作为参考，可以找到引发这个问题的问题 noreflow noreferrer“&gt; noreferrer”&gt;在这里问题13和15和15。 The first question (13) only gives the sequence definition of the probability function, so to solve it you have to solve the infinite geometric series (as per $\frac{a}{1-r}$) and then solve for $a$ such that the sum of probabilities is one, as we expect.当然，这会产生 $ a = 1-r $ ，从而将其乘以我们不断减小的因子 $ r^x $ 产生PMF。对不起，漫不经心的人只是想澄清发行的来源，以便有人可以在一般公式上查看我的工作。
我认为这个几何系列发行很有趣，并且想知道是否有正式名称。如果是这样，我想对此进行更多的研究。如果没有，我认为这是一个整洁的分布，很有趣。让我知道。]]></description>
      <guid>https://stats.stackexchange.com/questions/662551/need-help-putting-a-name-to-a-distribution</guid>
      <pubDate>Thu, 13 Mar 2025 04:01:44 GMT</pubDate>
    </item>
    <item>
      <title>减轻多个残差连接的效果</title>
      <link>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</link>
      <description><![CDATA[我最近遇到了一个问题，我无法根据我的先前知识回答（注意：不是作业，我已经毕业了）：
假设，我们在具有前层归一化的变压器中使用多个残差连接（即在层开始时层标准），我们假设每个残差都独立地分布在某种程度上，那么其总和的方差就会增长到添加的数量。例如，如果我们有2个残差，那么方差就可以达到极端水平，例如3-4个数量级。因此，在培训期间，我们将遇到具有精度和二元效应的问题（层变为-1或1），并且梯度将变得很小（接近0）。
我们该怎么做才能避免这些问题？
我认为，为避免这些问题，我们必须弄清楚如何在这些残差连接之间进行检查。我的第一个思想是围绕在这些残差连接之间应用层归一化的，以使方差恢复到正常水平。但是，由于我们已经具有层归一化，因此这种想法显然是错误的。另外，这显然也会导致梯度爆炸。
您还可以提供与此问题相关的一些理论（或参考文献）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</guid>
      <pubDate>Thu, 13 Mar 2025 02:25:05 GMT</pubDate>
    </item>
    <item>
      <title>用时间系数变化的监管提交系数来解释和重新组合生存曲线</title>
      <link>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</link>
      <description><![CDATA[我一直在用一个分析数据集挣扎，其中分类预测器具有时间变化的系数。在观察期间固定协变量。为了在上面放一个创可贴，我使用了步骤功能方法。有了3个切点，我可以解决时间依赖问题，但现在我陷入困境。我现在有四个单独的曲线，我一直在尝试将它们拼凑回一个可以促进与广泛受众的沟通的情节。
根据我对互联网的搜索，这是一个开放的问题……任何人都有任何简单的示例绘制这些内容。小插图示例，不适用于我的特定情况，因为它是二进制的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</guid>
      <pubDate>Wed, 12 Mar 2025 21:08:10 GMT</pubDate>
    </item>
    <item>
      <title>使用Poisson模型比较具有相同行百分比的表</title>
      <link>https://stats.stackexchange.com/questions/662531/comparing-tables-with-the-same-row-percentages-using-the-poisson-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662531/comparing-tables-with-the-same-row-percentages-using-the-poisson-model</guid>
      <pubDate>Wed, 12 Mar 2025 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>具有系统发育惩罚的广义加性模型</title>
      <link>https://stats.stackexchange.com/questions/662495/generalized-additive-model-with-phylogenetic-penalty</link>
      <description><![CDATA[我想适应一个控制观测中系统发育相关性的GAM。我发现并采用了此代码通过基于马可分子的平稳性，通过添加逆向精度仿真，从而引入系统生成关系拟合模型后，我预测了相互作用，并简单地排除了物种项以可视化拟合度 - 这是Phylogam的方法吗？
 库（MGCV）
图书馆（猿）
图书馆（弥撒）
库（数据。表）

＃假树
set.seed（123）
树＆lt;  -  rtree（30）
物种＆lt;  - 树$ tip.label

＃系统发育差异协方差矩阵
phylo_penalty＆lt;  -  solve（vcv（tree））

＃假特征
set.seed（42）
fake_data＆lt;  -  data.table（
  物种=物种，
  trait_x = rnorm（30），
  trait_y = rnorm（30），
  response_var = rbeta（30，2，5）＃beta分布响应
）

＃订购物种
tops_ordered＆lt;  - 仓库（phylo_penalty）
facky_data＆lt;  -  face_data [match（thers_ordered，face_data  $ strip），]，]，]
facky_data $ 物种＆lt;  - 因子（face_data $ stelt，laste = term_ordered）

＃ 合身
mod_example＆lt;  -  gam（response_var〜 
                     ti（trait_x，k = 5） +
                     ti（trait_y，k = 5） +
                     ti（trait_x，trait_y，k = c（7，7）） + 
                     s（物种，bs =; mrf; xt = list（惩罚= phylo_penalty） 
                   方法=; reml＆quot;
                   data = fake_data）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662495/generalized-additive-model-with-phylogenetic-penalty</guid>
      <pubDate>Tue, 11 Mar 2025 21:05:45 GMT</pubDate>
    </item>
    <item>
      <title>我对蒙特卡洛模拟的理解是正确的吗？ （外行术语）</title>
      <link>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</link>
      <description><![CDATA[我有时会在心理学期刊上遇到蒙特卡洛模拟一词。我不是一个统计书呆子，更像是统计用户，因此，即使阅读了相当数量的材料，我仍然对它的运作方式有些困惑。
假设我收集了400名研究参与者，并将他们的数据输入到统计软件中。统计软件将尝试推断这400名参与者的数据，并想象我设法收集了1000或5000名参与者的数据。我对蒙特卡洛模拟的理解是否正确？
另外，统计软件如何进行仿真过程？我收集了来自400名研究参与者的5个变量的数据。统计软件是否试图检测模式？从这种模式来看，如果我设法收集1000或5000名参与者，它将尝试推断人们如何填写问卷？如果我收集5或6个变量，结果会有所不同吗？
如果我的理解是正确的，是否需要这种统计分析？还是夸张的统计复杂形式？我仍然不确定我们是否需要模拟从10.000参与者那里收集数据的感觉。
对不起，如果这个问题非常业余。我试图理解其背后的逻辑。]]></description>
      <guid>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</guid>
      <pubDate>Tue, 11 Mar 2025 13:39:24 GMT</pubDate>
    </item>
    <item>
      <title>关于AUC是一种不连贯的模型比较方法的疑虑</title>
      <link>https://stats.stackexchange.com/questions/662426/misgivings-about-the-notion-that-auc-is-an-incoherent-model-comparison-method</link>
      <description><![CDATA[  2009年有影响力的论文， 测量分类器绩效：在Roc courve ucure  em em em em em em em em em em em em em em em em em em em&gt; “从根本上说，在错误分类成本方面是不一致的，“使用“不同分类器的不同分类成本分布”。
详细介绍了论证和数学推导，我发现很难说服自己中心点。这是我的分析。

 本文表明，通过评估每个可能的模型得分错误分类的概率，可以将AUC表示为损失函数，通过模型得分分布的PDF加权并集成以获得预期的损失。 。

 另一方面，它表明，使用其他功能而不是分数PDF来加权该积分等同于将各种错误分类成本概率的信念纳入损失函数中。

 我摆脱了这一点，即AUC可以被视为关于错误分类成本的特殊案例。但是，我不相信这很重要。 AUC不承担错误分类成本，而成本敏感的损失计算没有参考AUC。


如果上述推论是合理的，我认为使用AUC作为模型比较的手段没有问题。本文认为，在应用于每个模型的情况下，AUC量度任意改变了与错误分类成本有关的假设。但是，尽管第1点中提到的模型得分分布的PDF可以看作是错误分类成本比率，但我看不出这样做的理由，因为成本在AUC量度中没有任何作用。如果我们 do 决定将其视为错误分类成本比率，那么一致的方法是将其固定在模型之间，而简单地将其视为AUC措施。
对此的协议或替代思维方式将受到欢迎。在这种情况下
 P.S。鉴于该主题可以采取回合，我指出的是，本文使用AUC进行了与任何类型的模型比较类型。]]></description>
      <guid>https://stats.stackexchange.com/questions/662426/misgivings-about-the-notion-that-auc-is-an-incoherent-model-comparison-method</guid>
      <pubDate>Mon, 10 Mar 2025 20:51:57 GMT</pubDate>
    </item>
    <item>
      <title>COX模型预测中置信区间的差异</title>
      <link>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</link>
      <description><![CDATA[我试图通过此
特别是，我在使用时获得不同的顺式：

  type =; lp;  in  predict&gt; predict（），然后从标准错误（SE）中计算95％CI并指出结果（如在Vignette中完成）。
  type =;风险;  in  predict&gt; predict（），然后直接从se。直接计算95％CI

在第二种情况下，置信区间更窄。
根据 precade.coxph 的帮助文件，“风险&#39;仅是 exp（lp），所以我希望两种方法可以产生相同的结果。
有人知道为什么他们有所不同吗？
事先感谢您的见解！
 
 库（生存）
图书馆（dplyr）
图书馆（TinyPlot）

fit＆lt;  -  coxph（surv（未来，死亡）〜性 * splines :: ns（年龄，df = 3），data = flchain）
pdata＆lt;  -  Expand.Grid（年龄= 50:99，性= C（“ m＆quot”; f＆quot;））

lp_pred＆lt;  -  broom :: augment（fit，newdata = pdata，type.predict =＆quot; lp; lp; se = true）|＆gt; 
  突变（
    type =; lp＆quort
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fittit + 1.96 * .se.fit，
    跨越（c（.fited，conf.low，conf.high），exp）
  ）

firk_pred＆lt;  -  broom :: augment（
  fit，newdata = pdata，type.predict =“风险”，se = true
  ）|＆gt; 
  突变（
    类型=“风险”，
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fitted + 1.96 * .se.fit
  ）

pred＆lt;  -  rbind（lp_pred，firk_pred）

和（
  pread，
  TinyPlot（
    x =年龄，y =.。 
    facet = type，type =＆quord; ribbon＆quord＆quot log =&#39;y y＆quot;
  ）
）

 
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</guid>
      <pubDate>Tue, 25 Feb 2025 14:35:47 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Kendall趋势分析丢失数据</title>
      <link>https://stats.stackexchange.com/questions/660960/mann-kendall-trend-analyses-with-missing-data</link>
      <description><![CDATA[我需要分析38年内年度火灾严重程度的趋势。我的数据集从1982年至2020年延伸；但是，在时间序列中，有22年的价值缺少，因为在那些年中没有发生火灾。我希望使用完整的数据集测试Mann-Kendall趋势分析的趋势统计意义。但是我不知道如何处理丢失的数据，因为它们可能会影响测试的性能。我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/660960/mann-kendall-trend-analyses-with-missing-data</guid>
      <pubDate>Tue, 04 Feb 2025 15:57:38 GMT</pubDate>
    </item>
    <item>
      <title>双变量正常覆盖圆圈和椭圆</title>
      <link>https://stats.stackexchange.com/questions/629035/bivariate-normal-covering-circles-and-ellipses</link>
      <description><![CDATA[我正在寻找由独立双变量随机变量给出的笛卡尔坐标的覆盖圈， $ x，y \ sim n（0，\ sigma）$ 。。
这些样品的比例 p 的圆形半径由瑞利分布分数函数给出： $ r（p，\ sigma）= \ sigma \ sigma \ sqrt {-2 \ ln（1-p）} $  $ 。。。。。
有趣的是，如果每个轴的方差不等 -   $ x \ sim n（0，0，\ sigma_x），y \ sim n（0，\ sigma_y）$   - 那么rayleigh量化功能可通过覆盖的eLlipse  $ a = \ sigma_x \ sqrt {-2 \ ln（1-p）} $  and  $ b = $ b = \ sigma_y \ sqrt
 什么是覆盖范围 circle 的公式？ 
我发现一个基于平均方差 $ \ sigma_ {Xy}^2 = \ frac {\ sigma_x^2+\ sigma_y^2} {2} $始终*始终*比覆盖比 p  p 。  即，一个带半径 $ r（p，\ sqrt {\ sigma_ {xy}^2}）$ 总是比样品的 p 始终覆盖。
* eTa来自关联的图：这对于 p ＆lt; 〜79％；对于较大的 p ，覆盖下的圆圈总是。
这是一个示例，显示了60％覆盖椭圆形的情况，其中 $ \ sigma_x = 2.5 \ sigma_y $ 。  红色圆圈具有半径=  $ \ sqrt {\ sigma_ {xy}^2} $ ，覆盖了65％的样品点。
 （鉴于覆盖椭圆的公式是如此简单，我希望有一种优雅的表达方式可以使不平等的差异案例循环。我有一个预感，正常的分位数功能提供了所需的信息，而魔术拐点处于79％的覆盖率，正好 $ \ sqrt“&gt; $ \ sqrt is I.半正常]]></description>
      <guid>https://stats.stackexchange.com/questions/629035/bivariate-normal-covering-circles-and-ellipses</guid>
      <pubDate>Tue, 17 Oct 2023 23:21:30 GMT</pubDate>
    </item>
    <item>
      <title>如何计算返回系列的风险（VAR）和条件VAR的时变值？</title>
      <link>https://stats.stackexchange.com/questions/615000/how-can-i-calculate-time-varying-value-at-risk-var-and-conditional-var-for-ret</link>
      <description><![CDATA[我正在研究ABT索引，并计算了返回系列。另外，我打算将&lt;​​code&gt; garch（1,1）模型拟合到返回系列，然后将VAR和CVAR计算为以下图像：
 我使用了许多方法，据我所知，VAR和CVAR是每个系列的一个值。我不了解随时间变化的var/cvar。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/615000/how-can-i-calculate-time-varying-value-at-risk-var-and-conditional-var-for-ret</guid>
      <pubDate>Fri, 05 May 2023 13:22:35 GMT</pubDate>
    </item>
    </channel>
</rss>