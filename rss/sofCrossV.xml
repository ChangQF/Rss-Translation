<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 23 Feb 2025 09:17:55 GMT</lastBuildDate>
    <item>
      <title>将高维向量可视化到2D极空间</title>
      <link>https://stats.stackexchange.com/questions/661753/visualizing-high-dimensional-vectors-into-2d-polar-space</link>
      <description><![CDATA[实际上这是降低维度的问题，但是使用T-SNE或UMAP应该找到正确的参数并取决于数据集的可用性。问题是，随着时间的推移，样本的数量正在增加，因此这意味着我需要重述参数。
这是因为我正在制作一个迅速的猜测游戏，其中提示器提示生成图像，然后猜测者猜测生成的图像。两个原始提示和猜测的提示都存储在高维矢量中。因此，我不得不使用缩小维度缩减技术，这些技术取决于第一次生成的图像引起的数据可用性正在等待猜测器的可用性。

 正如我的直觉所说的那样，圆/球/球是中立形状的，这就是为什么我打算使用极地坐标。

 所以，我想创建一个带有极地坐标格式（2D空间）的仪表板，以可视化原始提示的当前相似性，而不是猜测的提示。其中中心（原点点）是原始提示的点。

 这意味着，我需要通过猜测在原始提示向量中执行向量相似性操作。

 归一化的L2标准在极坐标中解释为半径，而余弦相似性用于theta。


让 $ r_1 $ 是第一个猜测提示的半径， $ \ theta_1 $ 是第一个角度猜测提示， $ l_2 $ 是原始和猜测之间的欧几里得距离， $ \ cos（\ phi）$ 是余弦相似性， $ \ vec {o} $ 是原始提示，并且 $ \ vec {g} _1 $ 首先是猜测提示。

  $ r_1 = l_2（\ vec {o}  -  \ vec {g} _1）$  
  $ \ theta_1 = \ pi \ cos（\ phi）$    

问题是，我如何归一化半径以使范围是[0,1]？使用标准归一化或最低最大标准化，需要数据可用性依赖性。我打算使用：
 $$
r_1 = 1- \ frac {\ min（\ | \ | \ vec {o} \ |，\ | \ | \ vec {g} _1 \ |）} {\ max（\ | \ | \ | \ vec {o} {g} _1 \ |）}
$$  
这个想法是，因为半径更接近零，表明欧几里得距离更近。
   
这是仿真： https://wwwww.desmos.com/calculator/calculator/calculator/calculator/s7gjqpycficpedcpedcpedcpedcfi  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661753/visualizing-high-dimensional-vectors-into-2d-polar-space</guid>
      <pubDate>Sun, 23 Feb 2025 05:23:06 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个已知的理论或实际证据表明，较高的对象检测性能会导致更高的聚类准确性？</title>
      <link>https://stats.stackexchange.com/questions/661752/is-there-a-known-theoretical-or-practical-proof-that-higher-object-detection-per</link>
      <description><![CDATA[我正在处理一个基于图像的对象检测问题，我注意到相关性：对象检测性能的改进（按照标准指标（例如MAP或IOU）衡量）似乎在下游聚类任务中产生了更高的准确性。 
我想知道这种关系是在理论上还是通过文献中的经验研究正式表达或证明。是否存在已知的参考文献，论文或经过良好接受的分析，这些分析（或挑战）更好地检测指标可以直接转化为提高的聚类准确性？任何指示或见解都将不胜感激。
我在文献审查过程中，到目前为止，我还没有遇到任何类似的理论。我一直在研究Google Scholar的相关论文。
预先感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/661752/is-there-a-known-theoretical-or-practical-proof-that-higher-object-detection-per</guid>
      <pubDate>Sun, 23 Feb 2025 04:34:20 GMT</pubDate>
    </item>
    <item>
      <title>Euler-Maruyama近似与估计参数的强烈收敛</title>
      <link>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</link>
      <description><![CDATA[ 背景。考虑一个扩散过程 $（x_t）$ 是以下随机微分方程（SDE）的解决方案：&lt; /p&gt;
  $$ DX_T = B（X_T）dt + \ sigma（x_t）dw_t $$   
其中 $ W_T $ 是标准Wiener过程。表示 $ x_t $  as  $ \ {\ bar {x} _ {k \ delta} \ } _ {k = 1}^n $ ，因此定义了连续的时间过程 $ \ bar {x} _t：= \ bar {x} _ {k \ delta} $  for  $ t \ in [k in [k in [k in] \ delta，（k+1）\ delta）$ 。众所周知，牢固的连接保持：
  $$ \ | x- \ bar {x} \ | _ {l_2（\ omega \ times [0，t]）}：= \ sqrt {\ int_0^t \ Mathrm {e} | x_t- \ bar {x} _t |^2 dt} = o（\ delta^{ -  \ frac {1} {2}}）$$ 
参见，例如，此注释。。 
 问题。假设函数 $ b $  and  $ \ sigma $ 由 $ \ theta $ 参数化。例如，最简单的线性过程：
在
 with  $ \ theta =（b，\ sigma）$ 。但是，我们不知道 $ \ theta $ 的值，因此，为了计算欧拉近似，我们首先估计 $ \ theta $  with  $ \ hat {\ theta} $ 从某些观测数据中class =“ Math-Container”&gt; $ \ hat {\ theta} $  in  $ \ {\ bar {x} _ {k \ delta} \} _ {k {k {k {k = 1}^n $ 获得 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 。
我们调用 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 作为Euler近似估计参数。 Define  $ \ hat {\ bar {x}} _ t：= \ hat {\ bar {x}} _ {k \ delta} $  for 。中
我们如何获得 $ \ | x- \ hat {\ bar {x}}} \ | _ {l_2（\ omega \ times [0，t]） } $ ，给定 $ \ delta \ to 0 $ 和 $ \ hat {\ theta} \ to \ theta $ （以任何形式）？
 注。这仅供示范。此外，我们有 $ \ hat {\ theta} $ 是从某些数据估算的，独立于 $ w_t $  （ $ \ hat {\ theta} \ perp w_t $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</guid>
      <pubDate>Sun, 23 Feb 2025 02:14:46 GMT</pubDate>
    </item>
    <item>
      <title>在计算Nesterov优化梯度时，深度学习框架是否会“向前看”？</title>
      <link>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</link>
      <description><![CDATA[ Nesterov优化背后的全部要点是计算当前参数值 $ \ theta_t $ ，而是在 $ \ theta_t + \ beta m $ ，其中 $ \ beta $ 是动量系数和 $ M $ 动量。更新步骤如下：
  $$
m \ get \ beta m- \ eta \ nabla l（\ theta + \ beta m）\\
\ theta \ get \ theta + m
$$  
通过查看
  velocity =动量 *速度-Learning_rate * g
w = w +动量 *速度-Learning_rate * g
 
通过查看 pytorch的文档更新步骤是：
    
如果我错了，请纠正我，但是在这两种情况下，梯度都不以“向前看”计算。参数位置（由于需要Nesterov优化）。这些实现原始方法的近似吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</guid>
      <pubDate>Sat, 22 Feb 2025 22:20:04 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型中的非结构化协方差矩阵：用于随机效应或残留误差</title>
      <link>https://stats.stackexchange.com/questions/661743/unstructured-covariance-matrix-in-linear-mixed-effects-model-for-random-effects</link>
      <description><![CDATA[我一直在研究一些纵向研究，包括临床试验，在那里他们使用线性混合效应模型进行纵向数据。可以在此开放式文章中找到一个示例：。在方法部分中，作者提到：“我们使用了 非结构化协方差矩阵的线性混合效应模型来估计平均变化率……
在Stata 中混合 命令，有两个您可以在其中指定方差 - 交互矩阵的参数：协方差（vartype） 方差 - 稳定效应的结构或残差（RSPEC），用于残留误差的结构。
我想知道在这样的文章中，作者通常意味着他们使用非结构化方差 - 协方差矩阵来进行随机效果和残差错误，还是其中一个？
如果任何人在研究中都采用了线性混合效应模型，请随时分享您的实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/661743/unstructured-covariance-matrix-in-linear-mixed-effects-model-for-random-effects</guid>
      <pubDate>Sat, 22 Feb 2025 21:05:18 GMT</pubDate>
    </item>
    <item>
      <title>用于证明Q学习收敛的定理中数学术语的含义</title>
      <link>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</link>
      <description><![CDATA[我试图在这里理解定理的陈述 htttps：// apps.dtic.mil/sti/tr/pdf/ada276517.pdf ，用于证明Q学习算法的收敛性（即使定理更抽象）：
    
，但是我在理解术语的含义方面有问题。您能评论以下几点：
 1-什么是 $ x $ 在这里？是在x $ 中假设 $ x \的语句，因此，每个 $ x $ ，例如在高斯流程中？并且 $ x $ 即使没有明确提及条件1的状态空间？
 2-标准 $ || \ cdot || _W $ 在哪个设置上定义了？是在上一个集合 $ x $ 上定义的规范（在这种情况下是矢量空间）？是在基本概率空间的随机变量 $ \ omega $ 上定义的规范，让我们称其为 $ v（\ omega（\ omega） ）$ ？它是否在随机过程的空间中定义了标准（我猜 $ v（\ Omega \ times x）$ ）？
无论正确的解释如何，我都会发现条件3和4之间的差异令人困惑。正确的成员是相同类型的，而在左侧，我们在第一种情况下有一个额外的规范，我们在条件4中找不到这是对有效性领域的任何其他评论
感谢您帮助我澄清。该定理中似乎给予了一些设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</guid>
      <pubDate>Sat, 22 Feb 2025 11:11:23 GMT</pubDate>
    </item>
    <item>
      <title>自我注意力的输出</title>
      <link>https://stats.stackexchange.com/questions/661710/output-of-self-attention</link>
      <description><![CDATA[  $ \ newCommand {\ softmax} {\ propatatorName {softmax}} $ 我的问题是关于注意的问题，如果我们从
  $ \ delta $   - 以15:32的方式看到。
 第二个解释： 
在我看来，在我看来，输出是 $ v_k $ 的线性组合，那就是新嵌入者本身 $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 。因此， $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 不仅仅是我们添加到oridingal嵌入中的东西，它是新的嵌入。
 我的问题： 
 is  $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）嵌入以获取新的嵌入？我误解了什么吗？似乎我会说两个不同的消息来源。
陈述了另一种方式：如果我们有一个嵌入 $ \ textbf {x} _i $ 是新的嵌入式 $（ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）_i $ 或 $ \ textbf {x} _i+（\ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）v）_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661710/output-of-self-attention</guid>
      <pubDate>Sat, 22 Feb 2025 00:27:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同聚集/粒度水平下的时间序列数据的经验估计标准偏差和变异系数？</title>
      <link>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</link>
      <description><![CDATA[我正在与2024年9月19日至11月19日的图书馆建筑物收集的时间序列建筑物占用数据。每5分钟，使用Motion（PIR）传感器（总共450张椅子）记录每5分钟的数据。然后将数据重新采样至30分钟的间隔（2689个数据点），并在不同级别进行汇总：
椅子级别：450椅→1,210,050个数据点（450*2689）
表级：50个表→134,450数据点（50*2689）
子区域级别：6个子区域→16,134个数据点（6*2689）
区域级别：2区→5,378个数据点（2*2689）
 客观：我旨在使用两个关键指标（即标准偏差（SD）（SD）和变异系数（CV），在不同水平的粒度（椅子，桌子，子区域和区域）处量化可变性。 。
在较小的级别（例如椅子级）下，我有更多的观察结果（更高的数据点，而在更粗的水平（例如区域级别）下，样本量明显较小。
我的主要问题是
 1-当每个粒度水平的数据点总数显着差异时，我如何从经验上估计SD，CV进行公平比较？我已经计算了原始SD，而没有考虑到不平等的观察数（请参阅附件图）每小时标准偏差的箱形图表所有粒度级别” src =“ https://i.sstatic.net/vok57dth.jpg”/&gt; 。
数据集附加在此处
考虑不平等的数据点，可以用来估算SD的任何见解，参考或方法将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</guid>
      <pubDate>Fri, 21 Feb 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>我是否了解主教的主教？</title>
      <link>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</link>
      <description><![CDATA[主教将A 定义参数满足以下内容，
 $$
p（x | \ mu）= f（x- \ mu）。
$$ 
他想定义“不信息先验”对于 $ {\ MU} $ 对于贝叶斯推理。如果我没记错的话，那是他想利用以下不变性，
 $$
\ wideHat {x}：= x + c \ leadsto p（\ wideHat {x} | \ wideHat {\ mu}）= p（x | \ mu），
$$ 
我们定义了 $ {\ wideHat {\ mu} = \ mu+c} $ 。这是我想验证我理解的阶段：他本质上想定义先前的 $ {p（\ mu）} $ ，以便我们具有以下后代：
 $$
p（\ wideHat {\ mu} | \ wideHat {x} _1，...，\ wideHat {x} _n）= p（\ mu | x_1，...，...，x_n）。
$$ 
他并没有这样说，所以这就是为什么我想检查我本质上理解这个想法的原因。如果您继续这个想法，则最终会以 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ ，并且由于选择了 $ {c} $ 是任意的，您最终会 $ {p（\ mu）= \ text {const。}} $  

  edit ：要澄清，我应该提到 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 最终是一个足够的（但我认为不是严格必要的条件） class =“ Math-Container”&gt; $ {p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）} $ ：
 $$
p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）\ rightarrow \ frac {p（\ wideHat {\ mu}）}} {\ int_d p（\ wideHat {x} | \ wideHat {\ mu}）p（\ wideHat {\ mu}）d \ wideHat {\ mu}} =
\ frac {p（\ mu）} {\ int_d p（x | \ mu）p（\ mu）d \ mu}。
$$ 
由于我们已经确定 $ { span class =“ nath-container”&gt; $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 对于任何 $ C $ 满足了平等。嗯，也许我们可以说更多：
 $$
\ rightarrow \ int_d f（x- \ mu）p（
$$  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</guid>
      <pubDate>Fri, 21 Feb 2025 12:12:55 GMT</pubDate>
    </item>
    <item>
      <title>纯粹的可预测性衡量</title>
      <link>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</guid>
      <pubDate>Fri, 21 Feb 2025 11:57:38 GMT</pubDate>
    </item>
    <item>
      <title>GLMM用于计数数据，受试者的随机效果为小样本量，I型错误风险，如何推断因子效应和事后。</title>
      <link>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</guid>
      <pubDate>Thu, 20 Feb 2025 18:03:25 GMT</pubDate>
    </item>
    <item>
      <title>了解人们为什么对自己的身高撒谎（第2部分）</title>
      <link>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</link>
      <description><![CDATA[我有兴趣了解不同类型的人（例如不同年龄，不同的性别，不同的身高）在他们的自我报告如何自我报告以及可能存在哪种偏见方面存在差异。
我想我站在街上进行类似的实验（ https://www.youtube 。获得一些有关它们的基本信息（例如性别，年龄）。我可以写一个非常基本的模型：
  $$ D = H_R -H_T $$ 
 $$ d = \ beta_0 + \ beta_1h_t + \ beta_2a + \ beta_3g + \ beta_3g + \ epsilon $$

  $ H_R $ ：报告高度
  $ H_T $ ：true Height 
  $ a $ ：age 
  $ g $ ：性别（ $ g = 1 $  vs vs  $ g = 0 $ ）

我想添加以下注释：

这些是我拥有的一些幼稚理论（为人们如何撒谎制定统计模型）：



在许多文化中，人们认为男人很高。因此，也许男人更有可能比他们高的自我报告高度
实际上是。
一般来说，高个子（即超出一定身高）可能会通过自我报告的高度比实际的高度来获得任何收益。
年长的人可能会更认为他们通过误会高度而获得的收益较少，因此可能是更真实的



在这种情况下，我的数据很可能包含更多类型的人群（例如，男性大学生）。

 如何考虑我的统计模型，考虑到我对高度报告的天真理论以及某些人口统计学的反映在数据中？。第一点，我会认为贝叶斯的方法可能很有用。对于第二点，我已经阅读了可能在这里可能相关的heckman选择模型的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</guid>
      <pubDate>Thu, 13 Feb 2025 19:41:26 GMT</pubDate>
    </item>
    <item>
      <title>IRT标称响应模型Theta</title>
      <link>https://stats.stackexchange.com/questions/638939/irt-nominal-response-model-theta</link>
      <description><![CDATA[我对多种IRT模型非常熟悉；但是，我似乎无法理解名义响应模型。 Theta如何估计？例如，如果我们有多项选择项目的科学测试（“以下哪一项是动物？ ;知道＆quot＆quot哪个答案反映了最大的知识？我是否必须将答案放入“逻辑”中。我自己（为0-椅子，1-向日葵，2-猫头鹰，3 -cat），所以类别越大，“ right”答案？还是我必须将密钥添加到模型中？
这很令人困惑，因为我到处都读到答案可以是无序的（这就是为什么它肯定被称为名义的原因）。但是，如果我不添加密钥或以合乎逻辑的方式重新排序答案，那么我真的无法理解如何估算能力/theta。]]></description>
      <guid>https://stats.stackexchange.com/questions/638939/irt-nominal-response-model-theta</guid>
      <pubDate>Fri, 09 Feb 2024 13:30:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么变压器模型不需要负面采样，而是Word2Vec？</title>
      <link>https://stats.stackexchange.com/questions/614980/why-the-transformer-model-does-not-require-negative-sampling-but-word2vec-does</link>
      <description><![CDATA[两者 word2vec 和变形金刚在输出侧的单词/令牌。
对于Word2Vec型号，负面采样用于计算原因 ：

  仅出于计算原因而使用？ 

   https://stackoverflow.com/a/56401065/1516331   


 so 为什么我们也不对变压器模型使用负抽样？
是因为：

变压器模型的发布时间晚于Word2Vec，因此现在软词的计算成本在整个词汇上都不是一个大问题；  
变压器是一种自回归模型。我们需要尽可能确保对概率分布的准确估计。

这些是真的吗？还有其他原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/614980/why-the-transformer-model-does-not-require-negative-sampling-but-word2vec-does</guid>
      <pubDate>Fri, 05 May 2023 09:11:11 GMT</pubDate>
    </item>
    <item>
      <title>计算调整为患病率的PPV的置信区间或标准误差</title>
      <link>https://stats.stackexchange.com/questions/595786/calculating-the-confidence-interval-or-standard-error-of-a-ppv-adjusted-for-prev</link>
      <description><![CDATA[我正在尝试评估疾病测试在病例对照研究中的表现。在此示例中，患病率为0.5％，结果如下：




 
疾病 +
疾病 -  




 测试 + 
 40（TP）
 10（fp）


 测试 -   
 600（FN）
 5000（TN）




随着样本的疾病患者的样本，标准PPV计算 $ ppv = \ frac {tp} {tp+fp} $ 不准确。我可以使用 $ ppv = \ frac {p \ cdot sens} {p \ cdot sens +（1-p）\ cdot（1-spec）} $计算出患病率调整的PPV。 ，如此页面，此处的PPV为13.6％。
但考虑到较低的患病率，我担心假阳性数量的少量变化可能会对PPV产生很大的影响，因此我想计算此PPV的95％置信区间。
 这个问题标准错误为 $ SE = \ sqrt { \ frac {ppv（1-ppv）} {tp+fp}} $ 。
这将给出4.8％的标准错误，如果然后使用 $ ci_ {ppv} = ppv \ pm 1.96*se $ ，我得到的CI为4.1％ -23.1％。
但是：

 在调整PPV的患病率时，该方程仍然适用吗？

 我读到，由于比例的不确定性不是对称的，因此使用上述方程计算CI不是很有用（例如，在”这个问题）。


因此，在这种情况下，有更好的方法可以计算PPV的置信区间吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/595786/calculating-the-confidence-interval-or-standard-error-of-a-ppv-adjusted-for-prev</guid>
      <pubDate>Tue, 15 Nov 2022 16:51:56 GMT</pubDate>
    </item>
    </channel>
</rss>