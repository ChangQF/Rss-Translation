<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 21 Dec 2023 06:18:30 GMT</lastBuildDate>
    <item>
      <title>我想预测未来的利率。我应该使用日期作为预测变量吗？</title>
      <link>https://stats.stackexchange.com/questions/635399/i-want-to-predict-future-interest-rates-should-i-use-dates-as-a-variable-for-my</link>
      <description><![CDATA[为了预测利率，我使用 CPI、联邦融资利率、年平均房价和利率。我将所有数据设置为具体年份，例如，1971-01-01 有 CPI x、IR x、FED 利率 x 和价格 x。我想我想看看我是否可以使用日期不仅作为索引，而且可以预测未来的 IR。我正在使用线性回归。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/635399/i-want-to-predict-future-interest-rates-should-i-use-dates-as-a-variable-for-my</guid>
      <pubDate>Thu, 21 Dec 2023 05:32:54 GMT</pubDate>
    </item>
    <item>
      <title>不同复杂度任务的统计采样</title>
      <link>https://stats.stackexchange.com/questions/635397/statistical-sampling-for-tasks-with-different-complexities</link>
      <description><![CDATA[我们有承包商提交了不同复杂性（高/中/低）的任务，我们希望对其进行审核。考虑到审计资源的可用性，我们必须对提交的任务进行抽样并进行审计。
我计划采用“ISO 2859-1：按属性检验的抽样程序”并使用相应的表格来确定样本量和样本量。 AQL 选择。我的理解是，选择级别（级别 1、级别 2 或级别 3）将决定样本大小和样本大小。 AQL（1、1.5、2.5 等）将确定接受/拒绝限制。
根据快速计算，为所有复杂性级别选择级别 1 将在我们的资源容量限制范围内。然而，我担心它是否会通过审核非常低（~5%）的“高”复杂性任务来增加风险。另一方面，选择级别 2 将导致审核相当数量的“高”复杂性任务（&gt;10%），但所需的全部审核将超出我们的资源能力。
我想知道对“高”复杂性任务进行 2 级检查和对“中/低”复杂性任务进行 1 级检查是否有意义。同样，对于“高”和“低”选择更严格的 AQL（例如 1%）。 “中/低”的 AQL 宽松（2.55 或 5%）。
请告诉我您的想法和建议。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/635397/statistical-sampling-for-tasks-with-different-complexities</guid>
      <pubDate>Thu, 21 Dec 2023 04:28:03 GMT</pubDate>
    </item>
    <item>
      <title>从具有二元协变量的分段指数模型生成事件时间数据？</title>
      <link>https://stats.stackexchange.com/questions/635396/generate-time-to-event-data-from-a-piecewise-exponential-model-with-a-binary-cov</link>
      <description><![CDATA[如何从 R 中具有二元协变量的分段指数模型生成事件时间数据？有人可以向我指出一些 R 包和/或演示如何从头开始编码吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635396/generate-time-to-event-data-from-a-piecewise-exponential-model-with-a-binary-cov</guid>
      <pubDate>Thu, 21 Dec 2023 03:42:15 GMT</pubDate>
    </item>
    <item>
      <title>如何证明危险函数和生存函数之间的数学联系？</title>
      <link>https://stats.stackexchange.com/questions/635395/how-to-prove-the-mathematical-connection-between-hazard-and-survival-functions</link>
      <description><![CDATA[这是讲座笔记的屏幕截图。我只是想知道如何用数学方式表示这个方程。

参考：biostat/Sing2022/lectures 3.2 生存、危险、Cox 回归。网址：https://www.meb.ki.se /biostat/Sing2022/lectures/3.2%20Survival_hazard_Cox_regression.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/635395/how-to-prove-the-mathematical-connection-between-hazard-and-survival-functions</guid>
      <pubDate>Thu, 21 Dec 2023 03:16:42 GMT</pubDate>
    </item>
    <item>
      <title>我应该评估测试集上主题模型的主题连贯性吗？</title>
      <link>https://stats.stackexchange.com/questions/635394/should-i-evaluate-topic-coherence-of-topic-model-on-test-set</link>
      <description><![CDATA[我是主题模型的新手。根据我的理解，像潜在狄利克雷分配（LDA）这样的主题模型（在超参数上没有经验贝叶斯）执行变分推理来近似后验，实际上它与参数估计无关。 然后，我应该在训练集上拟合 LDA，修复主题词分布（$\beta$），并使用 $\beta$ 在单独的测试集上？如果是，为什么它有意义？
我读了几篇论文，例如（Srivastava 和 Sutton，2017），特别是实验部分；但我没有发现作者提到评估测试集的一致性。也许在本领域中提及这一点太常见了......这就是我在这里寻求澄清的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/635394/should-i-evaluate-topic-coherence-of-topic-model-on-test-set</guid>
      <pubDate>Thu, 21 Dec 2023 02:39:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么折刀可以减少偏差？</title>
      <link>https://stats.stackexchange.com/questions/635393/why-does-the-jackknife-reduce-bias</link>
      <description><![CDATA[给定一个示例 $x = (x_1, \ldots, x_n)$，定义 $x_{(-i )}$ 作为示例值，不包括示例 $x_i$。那是，
$$
x_{(-i)} = (x_1, \ldots, x_{i-1}, x_{i+1}, \ldots x_n)。
$$
现在给出参数 $\tau(\theta)$ 的估计器 $T(x)$ 基于示例 $x$，Lehmann 和 Casella（在《点估计理论》第二版中）定义了 $T(x)$ 作为
$$
T_J(x) = nT(x) - \frac{n -1}{n}\sum_{i=1}^n T\left(x_{(-i)}\right)。
$$
他们声称如果 $E[T(x)] = \tau(\theta) + O\left(\frac{1}{n}\right)$ ，然后 $E[T_J(x)] = \tau(\theta) + O\left(\frac{1}{n^2}\right)$ 。有人可以解释为什么 $T(x)$ 的折叠版本比原始估计器具有更低的渐近偏差吗？
一些注意事项：

我自己尝试过解决这个问题，但我认为我不清楚如何处理 $T\left(x_{(-i )}\right)$ 条款。特别是，将它们视为彼此独立的感觉并不正确，因此我真的不知道如何解决这个问题。
我在数学堆栈交换平台上发布了同样的问题几天前，但没有得到任何答复。经过一番搜索，我在这个论坛上看到了更多类似的问题，所以我在这里转发，希望相关的专家在这里:)
]]></description>
      <guid>https://stats.stackexchange.com/questions/635393/why-does-the-jackknife-reduce-bias</guid>
      <pubDate>Thu, 21 Dec 2023 02:24:12 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在基于速率的指标（例如转化率）上使用 Google 的 causalImpact 方法吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635385/can-we-use-causalimpact-method-by-google-on-a-rate-based-metric-like-conversion</link>
      <description><![CDATA[我有一个影响测量问题，其中主要指标是转化率，并且不可能运行 A/B 测试，所以我正在考虑 causalImpact 包。有人在基于速率的指标上使用过 causalImpact 包吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635385/can-we-use-causalimpact-method-by-google-on-a-rate-based-metric-like-conversion</guid>
      <pubDate>Wed, 20 Dec 2023 23:49:19 GMT</pubDate>
    </item>
    <item>
      <title>我们可以解释趋势季节性分解中的残差吗？</title>
      <link>https://stats.stackexchange.com/questions/635383/can-we-interpret-residuals-in-trend-seasonality-decomposition</link>
      <description><![CDATA[一般情况：建立市场模型以进一步评估我们的算法的质量。 （预测最优价格、需求预测等）
目前的方法：采用产品的两个特征——价格和需求，将其表示为时间序列。
下一步我试图“摆脱”该系列的时间依赖性——通过“减法”或“划分”趋势和季节性成分。
分解模型有两个主要假设：线性和乘法。我们假设我们的平均需求曲线类似于某些 $\exp(x)$ 函数，因此我们必须使用乘法方法。
我尝试过使用 statsmodels.tsa.seasonal 的一些经典方法：  seasonal_decompose 和 STL。使用经典方法，我只能分解一个特征（需求或价格）。
结果是这样的（对于需求系列，某些类别的平均值，一年的数据）：

还使用了 prophet，但这次有两个特征（这次假设乘法模型，但在 Prophet 乘法中）模型是
$$y(t) = \text{趋势}(t)*(1 + \text{季节}(t) + \text{beta} * \text{残差}( t))$$，与经典不同
$$y(t) = \text{趋势}(t)*\text{季节}(t)*\text{残差}(t)$$
我已经拟合了该系列，然后根据我之前拟合的整个数据进行预测，获得趋势和季节性成分，得到 $\text{residual}(t)$ ：

那么，有两个问题：

这是消除趋势和季节性成分的有效方法吗？尤其是在数据量较少的情况下。
我们可以将残留成分解释为“干净”吗？要求？或者更高的噪声值不允许我们解释这个组件？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635383/can-we-interpret-residuals-in-trend-seasonality-decomposition</guid>
      <pubDate>Wed, 20 Dec 2023 23:03:07 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Fisher 精确检验或单独 t 检验来分析这些数据吗？</title>
      <link>https://stats.stackexchange.com/questions/635381/should-i-use-fishers-exact-test-or-individual-t-tests-to-analyze-this-data</link>
      <description><![CDATA[突变体OH1-Y151F和OH1-Y152F对STAT1转录因子转位至细胞核的影响。
进行了两个独立的实验来评估 STAT1 在转染以下质粒的 HeLa 细胞中的定位：pHSV-IRES-EGFP、pHSV-OH1WT-IRES-EGFP、pHSV-OH1C112S-IRES-EGFP、pHSV-OH1Y151F-IRES -EGFP 和 pHSV-OH1Y152F-IRES-EGFP。由于这些质粒载体编码 EGFP 与感兴趣的蛋白质串联的表达，因此使用绿色荧光发射来选择用于分析的细胞。通过这种方式，在表达 OH1 变体或不表达 OH1 变体的细胞（仅表达 EGFP 的对照）中评估不同的条件。在这些测定中，总共对 214 个指示 GFP 表达以及 OH1 磷酸酶表达的荧光细胞进行了计数。
下表显示荧光细胞数换算为%，每行相加为100%。我应该使用百分比来进行统计测试还是应该仅使用细胞计数来进行？我是否应该对两个实验取平均值？如果一个实验显示的数据与第二个实验相矛盾怎么办？
如有任何澄清，我们将不胜感激。谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/635381/should-i-use-fishers-exact-test-or-individual-t-tests-to-analyze-this-data</guid>
      <pubDate>Wed, 20 Dec 2023 22:46:17 GMT</pubDate>
    </item>
    <item>
      <title>GEE 参数的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/635379/asymptotic-normality-for-gee-parameters</link>
      <description><![CDATA[在著名的Liang和Zeger 1986年关于GEE的论文中https://www.jstor .org/stable/2336267?seq=9，他们使用标准 m 估计参数绘制了一个证明：（未说明的）正则条件 + 一阶泰勒展开 + 概率中的余数消失（由正则条件覆盖） ) + 用于证明速率 $\sqrt{n_c}$ 的渐近正态性的常规收敛参数，其中 $n_c$ &gt; 是簇的数量。通常引用独立数据的中心极限定理 (CLT) 的哪个版本来实现渐近正态性？我觉得我从来没有在任何地方看到过特别指出这一点。
为了进一步详细说明，让 $\varphi_{n_i}(Z_i;\theta)$ 其中 $ Z_1,...,Z_{n_c}$ 是相互独立的组级数据，使得 $E(\varphi_{n_i}(Z_i;\theta))=0 $ 对于所有 $i=1,...n_c$ 和 $n_i$ 是簇的大小。假设求解无偏估计方程
$$\sum_{i=1}^{n_c} \varphi_{n_i}(Z_i;\theta) = 0$$
为您提供 GEE 估算器。为简单起见，假设随机效应的方差已知。 $\varphi_{n_i}(Z_i;\theta)$ 是独立的并且具有相同的维度，但它们只是相互独立的；事实上，鉴于 $n_i$ 不是常数，它们通常不会相同分布。系数渐近正态性的证明要求（除其他外）$\sqrt{n_c}\left (\frac{1}{n_c} \sum_{i=1}^ {n_c} \varphi_{n_i}(Z_i;\theta)\right )$ 分布收敛于均值零多元正态分布。通常需要哪个版本的 CLT 来发表此声明？]]></description>
      <guid>https://stats.stackexchange.com/questions/635379/asymptotic-normality-for-gee-parameters</guid>
      <pubDate>Wed, 20 Dec 2023 21:40:57 GMT</pubDate>
    </item>
    <item>
      <title>如何建立具有多个协变量和交互作用的线性混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/635377/how-to-set-up-a-linear-mixed-effects-model-with-multiple-covariates-and-interact</link>
      <description><![CDATA[我对当前关注的项目有点不确定。
我有一个感兴趣的结果，例如 $y$，还有一个主要预测变量，例如 $x$，两者都是连续的。我在不同时间点对 $x$ 和 $y$ 的每个主题进行了多次测量。除此之外，我还有一些其他协变量，应该包含在模型中。
我现在的印象是，当我只指定截距+斜率（主要预测变量）的随机效应时，我忽略了时间信息。但是，如果我指定随机截距 + 斜率（时间），我觉得我没有解决研究问题，即主要预测变量如何影响结果变量。
基本上有两个问题：

主要预测因素如何影响结果？
时间如何影响结果？

我不知道如何处理这个/设置随机效果。我从来没有遇到过包含两个随机效应的情况，我认为这不是正确的方法。我可能会将所有协变量作为固定效应，加上交互项 Time * Main Predictor，但是随机效应又如何呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/635377/how-to-set-up-a-linear-mixed-effects-model-with-multiple-covariates-and-interact</guid>
      <pubDate>Wed, 20 Dec 2023 21:24:05 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型中 p 值计算的当前观点</title>
      <link>https://stats.stackexchange.com/questions/635275/current-perspectives-on-p-value-computation-in-mixed-effects-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635275/current-perspectives-on-p-value-computation-in-mixed-effects-models</guid>
      <pubDate>Tue, 19 Dec 2023 17:06:52 GMT</pubDate>
    </item>
    <item>
      <title>估计数据的分布</title>
      <link>https://stats.stackexchange.com/questions/635152/estimating-the-distribution-of-the-data</link>
      <description><![CDATA[我想知道一些离散点的分布，但根据图形和其他方法，它们不遵循任何特定的分布。于是，我想到了应用非参数方法KDE并获得了KDE图。现在我有两个疑问：

如何解释 KDE 图以便我可以继续估计参数
有没有其他方法可以估计参数？

这些是数据点：
&lt;预&gt;&lt;代码&gt;数据 = [6,10,3,2,16,1,17,11,4,5]

请告诉我，即使您对此有一点点了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/635152/estimating-the-distribution-of-the-data</guid>
      <pubDate>Thu, 14 Dec 2023 10:52:30 GMT</pubDate>
    </item>
    <item>
      <title>C 统计量和测量多级逻辑回归中的上下文效应</title>
      <link>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</link>
      <description><![CDATA[我有一个两级逻辑回归模型，其结果是“InfectedqPCR” （通过 qPCR 确定是否感染疟原虫）在个体水平上。
我有一系列个人和家庭层面的变量。
家庭是分组结构。
我一直在阅读 Austin 和 Merlo (2017) 的“多级逻辑回归分析中的中级和高级主题”生物统计学教程 - 医学统计 - 关于使用c-统计量作为一般情境效应大小的度量。
按照他们的方法，我尝试解释以下三个模型的 c 统计输出：
model1 &lt;- glm(Infected_qPCR ~ 性别 + Age_Band_Years, family=“二项式”,
              数据=Data_Model_In_Adults）
Cstat(x = 预测(模型1),
      resp = model.response(model.frame(model1))) # 0.653
      # 仅包含固定效应 - 无随机效应结构
Cstat(x = 预测(Mod_MAd_Indi),
      resp = model.response(model.frame(Mod_MAd_Indi))) # 0.823
      # 包含相同的固定效果（Sex 和 Age_Band_Years）和
      # 家庭聚类随机效应
Cstat(x = 预测(Mod_MAd_Comb_Vil),
      resp = model.response(model.frame(Mod_MAd_Comb_Vil))) # 0.771
      # 包含相同的个体固定效应（性别和
      # Age_Band_Years) 和各种家庭因素以及
      # 家庭聚类随机效应

因此，据此，我认为 c 统计量从仅具有固定效应且无随机效应结构的 model1 到包含随机效应结构的 Mod_MAd_Indi 的变化为 0.17。
在 Austin 和 Merlo 的论文中，他们的示例的 c 统计量发生了 0.004 的变化，这表明“一般上下文效应较弱”。
问题 1：
那么，如果 0.004 很弱，那么如果我的上下文效果是 0.17，我能说什么？这是中等的情境效应还是强烈的效应？有这方面的任何指南或参考吗？
问题2：
Austin 和 Merlo 的论文还强调，“向包含特定簇随机效应的模型添加簇特征不能增加仅包含特定簇随机效应的模型的 c 统计量。”那么，c 统计量的 0.17 变化是否是最大可能变化（Austin 和 Merlo 所说的“上限”）？这就是我添加家庭变量 (Mod_MAd_Comb_Vil) 导致 c 统计量较低的原因吗？它可能相同或更低，但绝对不会更高 - 这就是奥斯汀和梅洛的意思吗？
这是根据 Eric Ruzek 在下面的评论中提供的有用意见进行的补充：
在进一步的系列模型中，我的 C 统计量有所增加，仅在小数点后第二位，但尽管如此，在模型中包含家庭层面的变量后，它还是有所增加。

在个体（和随机效应）模型中，该值为 0.880
在家庭和个人（和随机效应）模型中，该值为 0.892。

这似乎违背了所有统计直觉，但以下内容可以解释这一点吗？
个体模型如下：
Mod_Indi_Child_0.05_Apriori &lt;- glmer(Infected_qPCR ~ 1 +
      年龄范围_年份 + 工作地点_附近_森林 + 床网_最后一夜 +
      (1 | Household_ID.x)，数据 = Data_Model_In_Child，
      族=二项式，glmerControl（优化器=“bobyqa”））

组合模型如下：
Mod_Comb_Child_Apriori &lt;- glmer(Infected_qPCR ~ 1 + Age_Band_Years +
    工作地点_附近_森林 + 床网_昨晚 +
    规模（Persons_living_in_house_count，中心= TRUE，规模= FALSE）
    + (1 | Household_ID.x), 数据 = Data_Model_In_Child,
    族=二项式，glmerControl（优化器=“bobyqa”））

两种模式的区别在于增加了“家庭级”功能。组合模型中的因素（房屋计数中的人数）。该模型比仅个人模型具有更高的 C 统计量的原因可能是因为该“家庭水平”水平因子实际上也包含个体水平的信息？我的意思是，因为变量是“住在房子里的人数”，所以该个人是该房屋计数的一部分，因此该模型正在处理该“房屋计数”的至少一部分。作为个人层面的变量，因此 C 统计量有所上升。
这是对我所得到的不寻常结果的可能解释，还是我抓住了救命稻草？]]></description>
      <guid>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</guid>
      <pubDate>Tue, 12 Dec 2023 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 lme （或 lm）之后进行方差分析 [重复]</title>
      <link>https://stats.stackexchange.com/questions/633707/why-an-anova-after-lme-or-lm</link>
      <description><![CDATA[我想了解为什么在 lme（或 lmer）上进行方差分析以及如何解释方差分析输出。
lm1 &lt;- lme(EWL..mg.h. ~ 条件*会话 + 条件*性别 +
    条件*质量，随机 = ~1|个体，
    数据 = data_respiro_acoustic)

摘要(m1)
方差分析(m1, 类型 = c(“III”))


输出摘要：
REML 拟合的线性混合效果模型
  数据：data_respiro_acoustic
       AIC BIC 日志
  1232.332 1261.459 -606.1662

随机效果：
 公式：~1 |个人
        （截取）残差
标准差：18.01137 13.9361

固定效应：EWL..mg.h。 ~ 状况 * 疗程 + 状况 * 性别 + 状况 * 弥撒
                               值 标准误差 DF t 值 p 值
(截距) 32.45663 25.611020 103 1.267292 0.2079
条件 17.14916 17.503442 103 0.979759 0.3295
SessionSession_2 2.68361 3.284770 103 0.816986 0.4158
性别M 8.13412 7.651439 33 1.063083 0.2955
质量 0.03087 0.107194 33 0.288001 0.7751
条件S：SessionSession_2 -5.78778 4.645366 103 -1.245925 0.2156
条件：性别M 21.74791 5.193698 103 4.187364 0.0001
条件：质量 0.00369 0.072762 103 0.050762 0.9596
 相关性：
                            (Intr) CndtnS SssS_2 SexM 质量 CS:SS_ CnS:SM
条件S -0.342
会话Session_2 -0.064 0.094
性别M -0.558 0.188 0.000
质量 -0.980 0.330 0.000 0.447
条件S：SessionSession_2 0.045 -0.133 -0.707 0.000 0.000
条件：性别M 0.189 -0.554 0.000 -0.339 -0.152 0.000
条件：质量 0.333 -0.973 0.000 -0.152 -0.339 0.000 0.447

标准化组内残差：
       最小 Q1 中值 Q3 最大
-2.1236561 -0.6115711 0.1679837 0.6287077 2.3180579

观察次数：144
组数：36

方差分析输出
偏差表分析（III 类测试）

响应：EWL..mg.h。
                    Chisq Df Pr(&gt;Chisq)
（截距）1.6060 1 0.2051
条件 0.9599 1 0.3272
会话 0.6675 1 0.4139
性别 1.1301 1 0.2877
质量 0.0829 1 0.7733
条件：会话 1.5523 1 0.2128
状况：性别 17.5340 1 2.822e-05 ***
条件：质量 0.0026 1 0.9595


我还想知道我应该做什么类型的方差分析以及为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/633707/why-an-anova-after-lme-or-lm</guid>
      <pubDate>Tue, 12 Dec 2023 10:42:25 GMT</pubDate>
    </item>
    </channel>
</rss>