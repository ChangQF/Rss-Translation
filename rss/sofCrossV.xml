<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 25 Jan 2025 01:10:43 GMT</lastBuildDate>
    <item>
      <title>较弱的“完整”统计定义</title>
      <link>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</link>
      <description><![CDATA[为什么我们不定义充分统计量 $T(x)$ 的完备性，因为 $g(T(x))$ 依赖于所有函数 g 的 $\theta$？
定义
$$\mathbb{E}_\theta \left[ g(T(X)) \right] = 0 \quad \text{for all } \theta \quad \Rightarrow \quad g(T(X)) = 0 \quad \text{almost sure}$$
似乎更强。
此外，前一个定义似乎足以证明 Basu 定理，而且更直观？]]></description>
      <guid>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</guid>
      <pubDate>Sat, 25 Jan 2025 00:29:55 GMT</pubDate>
    </item>
    <item>
      <title>使用皮尔逊卡方拟合优度检验来比较混合对数正态和逆伽马拟合数据</title>
      <link>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</link>
      <description><![CDATA[我有一些数据（非分类数据），我认为它们来自某些基础分布。数据严格为正值。从视觉上看，我认为逆伽马分布和 2 分量混合对数正态分布看起来都是数据的合理分布。我正在使用 Pearson 卡方拟合优度检验（通过 MATLAB 的 chi2gof 函数）来测试我是否应该接受或拒绝我的数据可能来自这些分布的零假设。
虽然 Pearson 卡方检验应该用于分类数据，但我读过许多在构建一些箱体后将其用于非分类数据的例子，这有点主观。关于这一点，我理解每个箱体的预期计数应该有 &gt;5 个计数才能使测试可靠，并且它们不需要均匀分布。但是，由于分箱会影响统计量的计算，我是否应该对每个分布的拟合优度检验使用相同的分箱边界，以便对它们进行最佳比较？
我还想能够说明哪种分布更适合。从视觉上看，混合对数正态分布看起来稍好一些，但我想避免过度拟合，因为有 6 个参数，而逆伽马只有两个参数。我还读到，较低的卡方统计量代表更好的分布，但是，卡方统计量不包含自由度的数量（这仅在从卡方统计量计算 p 值时使用），所以我假设这在比较具有不同数量参数的分布时不一定成立，就像我的情况一样。相反，合理的比较似乎是 p 值较高的分布可能更适合。这听起来对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</guid>
      <pubDate>Sat, 25 Jan 2025 00:24:47 GMT</pubDate>
    </item>
    <item>
      <title>生存结果和连续中介的中介分析给出了较大的治疗效果估计</title>
      <link>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</link>
      <description><![CDATA[在执行中介分析时，我收到了非常奇怪的输出。
具体来说，我正在使用 AFT 模型和连续变量（即身体质量指数）作为中介，对事件发生时间事件（即心肌梗死）的结果进行中介分析。
但是，在执行分析时，我收到了非常奇怪的治疗效果估计和置信区间，例如效果约为 31,100，95% CI（2,590.00；80,574.58）。
这是正常的吗？收敛过程中是否存在错误或类似情况？
我给你一个示例代码：
event=rep(c(0,1),700)
event=as.numeric(event)
time=as.numeric(c(1:1400))
predictor=as.numeric(rep(c(1,0,0,1),350))
mediator=c(1:1400)

reg=lm(mediator~predictor)

surv=survreg(Surv(event = event, time = time)~ predictor + mediator)

med=mediate(
model.y = surv, model.m = reg, treat = &quot;predictor&quot;, mediator = &quot;mediator&quot;, 
boot = FALSE, sims = 1000
)

摘要（med）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</guid>
      <pubDate>Sat, 25 Jan 2025 00:19:15 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Benjamini Hochberg 检验中获得总体 P 值？</title>
      <link>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</link>
      <description><![CDATA[我写信是为了询问如何将 Benjamini Hochberg 程序应用于独立样本 t 检验。我知道如何获得 SPSS 上每个参与者的校正 p 值。但是，我需要澄清的是，如何根据 Benjamini Hochberg 程序计算总体 p 值，类似于原始独立样本 t 检验提供 p 值的方式。
感谢您对这个问题的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</guid>
      <pubDate>Sat, 25 Jan 2025 00:02:49 GMT</pubDate>
    </item>
    <item>
      <title>内生控制变量</title>
      <link>https://stats.stackexchange.com/questions/660502/endogenous-control-variables</link>
      <description><![CDATA[假设一个由 OLS 估计的线性模型。假设 X1 是研究变量，并且是严格外生的。现在，假设添加了控制变量 X2 和 X3。假设 X2 和 X3 与误差项相关。
Pearson 的积差相关检验（在 X1 和 X2 之间以及 X1 和 X3 之间）是否足以证明 X2 和 X3 的内生性不会影响 X1 的系数估计（假设检验的相关性在统计上为零）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660502/endogenous-control-variables</guid>
      <pubDate>Fri, 24 Jan 2025 21:37:09 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归 CS229 斯坦福</title>
      <link>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</link>
      <description><![CDATA[我正在尝试从 Andrew Ng 在 YouTube 上的课程学习基本的机器学习。我们刚刚介绍了逻辑回归，我尝试自己使用课程中的 ds1_train.csv 数据集来实现该理论，该数据集可在此处找到。
这是数据的图，以及预期的决策边界（我在 Mathematica 中使用 LogitModelFit 找到）：https://i.imgur.com/aSavXMo.png（如果有更多代表可以在此处添加图片，我将不胜感激）。
预期的分类器是 $h_\theta(x)=\sigma(\theta^T x)$，其中$\sigma(z)=1/(1+e^{-z})$是通常的 S 形函数，并且$\theta=(6.26,-2.47,0.03)$。我尝试自己使用下降法重现参数的这个值，即我们通过迭代更新初始猜测
$$
\theta_j\leftarrow \theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x^{(i)}_j,\qquad j=0,1,2
$$
其中 $i$ 遍历所有数据点。这在课程讲义的第 5 节中有解释，可在此处找到 。。 （此处的公式没有解释如何处理索引 $i$，但 Ng 教授解释了两种方法，要么对所有 $i$ 求和，要么对其进行迭代，他称之为“批量下降”，应该对大型数据集运行得更快）。
上面的公式似乎没有收敛，我不确定我是否误解了算法，或者在实现它时犯了错误。
这是我在 Mathematica 中的代码（如果有帮助，我可以尝试翻译成 python，但希望代码本身足够容易理解）
data = Import[&quot;ds1_train.csv&quot;] // Rest; (* import dataset *)
X = {1, #[[1]], #[[2]]} &amp; /@ data; (* 前两列是 x，我们用 1 来增加截距 *)
Y = #[[3]] &amp; /@ data; (* 第三列是 y *)
σ[z_] := 1/(1 + E^-z); (* sigmoid *)

h[θ_, x_] := σ[θ . x]; (* 逻辑模型 *)

(* 现在我们迭代 10 次，初始猜测 θ = {0, 0, 0} *)
Nest[# + .1 Sum[(Y[[i]] - h[#, X[[i]]]) X[[i]], {i, 1, Length[X]}] &amp;, {0, 0, 0}, 10] // Quiet

迭代失败。知道我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</guid>
      <pubDate>Fri, 24 Jan 2025 21:23:03 GMT</pubDate>
    </item>
    <item>
      <title>建立依赖于估计数据的回归模型</title>
      <link>https://stats.stackexchange.com/questions/660498/making-a-regression-model-that-relies-on-estimated-data</link>
      <description><![CDATA[这是我一直在研究的问题。

给定：我有跨多个单位的测量值（由 $i$ 索引）：


响应变量 $Y$（0 到 1 之间的数字）在 $t_1 = 2015$ 和 $t_4 = 2019$ 两个时间点测量。
预测变量 $X$（正数，完全连续）在 $t_2 = 2016$ 和 $t_5 = 两个时间点测量2021$


目标：我想了解随着时间的推移，$X$ 的变化如何影响 $Y$ 的变化，但测量是在不同的时间点进行的。例如，$X$ 的急剧变化是否与 $Y$ 的急剧增加有关？

模型：我认为我们可以为 $X$ 建立一个混合效应模型（假设随时间呈线性变化）：


$$ X_i(t) = \alpha_0 + \alpha_1t + u_i + \epsilon_{it} $$
使用此模型，我们可以为所需的时间点插入值并计算变化：
$$ \Delta X_i = X_i(2019) - X_i(2015) $$
$$ \Delta Y_i = Y_{i,2019} - Y_{i,2015} $$
然后，经过以下转换，我们可以制作 Beta GLM：
$$ p_i = \frac{\Delta Y_i + 1}{2} $$
$$ p_i \sim \text{Beta}(\mu_i\phi, (1-\mu_i)\phi) $$
$$ \text{logit}(\mu_i) = \beta_0 + \beta_1\Delta X_i $$
$$ \text{logit}(\mu_i) = \log\left(\frac{\mu_i}{1-\mu_i}\right) $$
$$ E(p_i) = \mu_i $$

不确定性：我想到的一件事是，由于我正在插入 $X$，因此会有一些错误需要考虑。我想到使用随机效应模型中的误差分布并执行引导模拟（反复估计 GLM 参数）。

这种方法有意义吗？我可以像这样使用 bootstrap 方法吗？

Bootstrap 过程：

步骤 1：使用观察到的 $X$ 值 () 拟合混合效应模型：
$$ X_i(t) = \alpha_0 + \alpha_1t + u_i + \epsilon_{it} $$

步骤 2：对于每次 bootstrap 迭代 $b = 1, ..., B$：

生成新的随机效应和残差：
$$ u_i^{(b)} \sim N(0, \hat{\sigma}^2_u) $$
$$ \epsilon_{it}^{(b)} \sim N(0, \hat{\sigma}^2_\epsilon) $$

计算所需时间点的 bootstrapped $X$ 值：
$$ X_i^{(b)}(t) = \hat{\alpha}_0 + \hat{\alpha}_1t + u_i^{(b)} + \epsilon_{it}^{(b)} $$

计算 bootstrapped 变化：
$$ \Delta X_i^{(b)} = X_i^{(b)}(2019) - X_i^{(b)}(2015) $$
$$ \Delta Y_i = Y_{i,2019} - Y_{i,2015} \text{（由于这些是观察到的，因此保持不变）} $$

转换 Beta GLM 的变化：
$$ p_i = \frac{\Delta Y_i + 1}{2} $$

为此引导样本拟合 Beta GLM：
$$ p_i \sim \text{Beta}(\mu_i^{(b)}\phi^{(b)}, (1-\mu_i^{(b)})\phi^{(b)}) $$
$$ \text{logit}(\mu_i^{(b)}) = \beta_0^{(b)} + \beta_1^{(b)}\Delta X_i^{(b)} $$


完成所有引导迭代后，我们可以计算感兴趣参数的置信区间。对于任何参数 $\theta$（例如 $\beta_1$），$1-\alpha$ 置信区间将是：
$$ [\theta_{(\alpha/2)}, \theta_{(1-\alpha/2)}] $$
其中 $\theta_{(q)}$ 表示引导分布的第 $q$ 分位数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660498/making-a-regression-model-that-relies-on-estimated-data</guid>
      <pubDate>Fri, 24 Jan 2025 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>如何用贝叶斯公式更新概率来计算证据权重？</title>
      <link>https://stats.stackexchange.com/questions/660497/how-to-update-probabilities-with-bayesian-formula-to-calculate-weight-of-evidenc</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660497/how-to-update-probabilities-with-bayesian-formula-to-calculate-weight-of-evidenc</guid>
      <pubDate>Fri, 24 Jan 2025 19:37:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 二项分布中制作一个 tukey？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660496/how-can-i-make-a-tukey-in-glm-binomial-distribution</link>
      <description><![CDATA[我想查看我处理方法之间字母的差异，以了解杀虫剂对昆虫死亡率的影响。当我尝试进行 Tukey 检验时，Rstudio 给出了错误。我的数据是二项式的，表示存活（1）和死亡（0）。
数据为：
Trat|Product1|Product2|Alive/dead|
1 | 0,5 | 1 |0 |
1 | 0,5 | 1 |0 |
1 | 0,5 | 1 |0 |
1 | 0,5 | 1 |0 |
2 | 0,5 | 2 |1 |
2 | 0,5 | 2 |1 |
2 | 0,5 | 2 |0 |
2 | 0,5 | 2 |0 |
3 | 1 | 1 |
3 | 1 | 1 |0 |
3 | 1 | 1 |1 |
3 | 1 | 1 |1 |
4 | 0,5 | 2 |0 |
4 | 0,5 | 2 |0 |
4 | 0,5 | 2 |1 |
4 | 0,5 | 2 |1 |
目前我唯一能做的就是 glm:
alive &lt;- glm(alive/dead)~Product1*product2, family = binomial(logit
))
你能帮帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660496/how-can-i-make-a-tukey-in-glm-binomial-distribution</guid>
      <pubDate>Fri, 24 Jan 2025 19:28:43 GMT</pubDate>
    </item>
    <item>
      <title>T 检验重要性查询[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660494/t-test-significance-query</link>
      <description><![CDATA[在前测后测实验研究中，当实验组和对照组的得分具有统计学意义时，是否意味着治疗无效？治疗效果是通过 Cohen&#39;s d 计算的，实验组的得分略高于对照组。这种差异是否表明治疗效果较小，还是因为对照组的得分不应该具有统计学意义，所以这只是偶然现象？]]></description>
      <guid>https://stats.stackexchange.com/questions/660494/t-test-significance-query</guid>
      <pubDate>Fri, 24 Jan 2025 19:00:53 GMT</pubDate>
    </item>
    <item>
      <title>层规范化如何处理特征具有很大尺度差异的情况？</title>
      <link>https://stats.stackexchange.com/questions/660492/how-does-layer-normalization-handle-cases-where-features-have-very-different-sca</link>
      <description><![CDATA[我目前正在学习批量标准化和层标准化，但我对它们的实现和潜在影响有一些疑问。
在批量标准化中，我们在批次级别对特征进行标准化。具体来说，对于批次中的给定特征，我们计算其平均值和方差，并汇总批次中的所有观测值。
另一方面，在层标准化中，标准化是在观测级别完成的。对于给定的观测，将计算所有特征的平均值和方差
这让我想到了我的问题：
由于层标准化会汇总特征，它是否可以处理特征具有非常不同尺度的情况？这种尺度上的差异是否会对性能产生负面影响，因为量级较大的特征可能会主导每次观察的标准化过程？
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/660492/how-does-layer-normalization-handle-cases-where-features-have-very-different-sca</guid>
      <pubDate>Fri, 24 Jan 2025 17:42:24 GMT</pubDate>
    </item>
    <item>
      <title>混合模型：我应该使用哪一种？</title>
      <link>https://stats.stackexchange.com/questions/660490/mixed-model-which-should-i-use</link>
      <description><![CDATA[抱歉，我问了个愚蠢的问题，但我对统计学很陌生。我需要帮助。
我必须使用混合模型分析一些数据。
具体来说，我计算了两种声音（我们称之为“A”和“B”）在不同类型的对话中出现的频率。
在某些情况下，A 在同一对话中出现很多次，而在其他情况下只出现一次甚至零次。B 也是如此。A 和 B 的出现应该与一些预测因子有关：

上下文（3 个级别：中性、修改、修改后）
态度（4 个级别：可靠、不可靠、中性、自信）

我认为我应该使用具有泊松分布的混合回归模型。
但是，这样可以检测声音 A 的发生是否受上下文和态度的调节（B 也是如此）吗？
此外，为了检测 A 和 B 之间在预测变量方面是否存在差异，我是否应该将预测变量声音类型（2 个级别：A、B）也添加到固定效应结构中？
如果频率（2 个声音的因变量在不同对话中不同）也将其作为随机截距对话类型是否正确？
您能为我提供您要运行的模型的代码吗？（我知道您可能需要更多信息，但我无法为您提供更多信息）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660490/mixed-model-which-should-i-use</guid>
      <pubDate>Fri, 24 Jan 2025 17:27:26 GMT</pubDate>
    </item>
    <item>
      <title>MLE 的正式定义是否是最大化样本数据的联合似然？</title>
      <link>https://stats.stackexchange.com/questions/660489/is-the-mle-formally-defined-as-maximizing-the-joint-likelihood-of-the-sample-dat</link>
      <description><![CDATA[我正在尝试了解随机向量序列实现的最大似然估计量 (MLE) 的计算。我目前的理解是，MLE 应该通过最大化从样本数据的联合分布得出的对数似然函数来计算。
这种理解基于 John Stachurski 的书中的一句话（链接在此处：QuantEcon Notes），其中指出：

“最大似然原理告诉我们要最大化由样本联合密度形成的对数似然函数。”

这是否意味着 MLE 始终基于观测值的联合密度（或离散数据的联合概率质量函数）计算？这个原则有什么例外或细微差别吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660489/is-the-mle-formally-defined-as-maximizing-the-joint-likelihood-of-the-sample-dat</guid>
      <pubDate>Fri, 24 Jan 2025 16:38:45 GMT</pubDate>
    </item>
    <item>
      <title>定义“辅助信息”，但不引用辅助统计数据</title>
      <link>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</link>
      <description><![CDATA[我正在寻找辅助信息的定义，但该定义本质上不是“辅助统计数据中的信息”。有趣的是，辅助信息的定义似乎很难找到。至少有一篇被广泛引用的辅助统计数据评论甚至没有包含该短语。我不喜欢上述定义，因为它不仅是循环的，而且还让我陷入矛盾。
即：完整统计数据没有辅助信息。因此，不完整统计数据必须具有一些辅助信息。然后，不完整的充分统计数据具有一些辅助信息，但该信息无法根据辅助统计数据来定义。如果可以的话，您可以根据辅助统计量来获得方差小于充分统计量的估计量。但充分统计量是最具信息量的度量……您看到了问题所在。]]></description>
      <guid>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</guid>
      <pubDate>Fri, 24 Jan 2025 16:03:59 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险模型外部验证的校准曲线：为什么需要互补对数-对数变换？</title>
      <link>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</link>
      <description><![CDATA[我想制作一条平滑的校准曲线，以从外部验证竞争风险模型。我遵循本文中提出的建议：
https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-021-00114-6
标题为：“竞争风险模型的图形校准曲线和校准指标”的部分。
这建议在我们想要从外部验证的模型的预测风险（概率）的互补对数对数的样条上拟合观察到的生存率（时间、事件）的竞争风险模型（例如原因特定 Cox 模型、Fine-Gray 模型等）。假设有足够多的事件，我理解使用样条函数实现非线性的好处。但为什么在拟合模型之前需要对独立变量进行互补对数-对数变换？]]></description>
      <guid>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</guid>
      <pubDate>Fri, 24 Jan 2025 13:11:41 GMT</pubDate>
    </item>
    </channel>
</rss>