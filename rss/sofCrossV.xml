<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 28 Jan 2025 12:31:49 GMT</lastBuildDate>
    <item>
      <title>这个在线 A/B 测试计算器在做什么？感觉不太准确</title>
      <link>https://stats.stackexchange.com/questions/660660/what-is-this-online-a-b-testing-calculator-doing-it-doesnt-feel-accurate</link>
      <description><![CDATA[我遇到过这种情况：
https://neilpatel.com/ab-testing-calculator/
它输出的结果在我看来并不严格，我对测试的内容很感兴趣（Fisher 精确检验、学生 t 检验等）。
我不是统计学家或数据科学家，所以我很想听听统计学家或数据科学家的看法。一旦我有了方向，我可以通过计算来验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660660/what-is-this-online-a-b-testing-calculator-doing-it-doesnt-feel-accurate</guid>
      <pubDate>Tue, 28 Jan 2025 10:09:13 GMT</pubDate>
    </item>
    <item>
      <title>尽管 PCA 对多类数据的分离效果较差，但分类准确率仍然很高</title>
      <link>https://stats.stackexchange.com/questions/660658/high-classification-accuracy-despite-poor-separation-in-pca-for-multi-class-data</link>
      <description><![CDATA[我最近对一个具有四类目标变量的数据集进行了主成分分析 (PCA)。虽然 PCA 得分图显示一个组的分离效果很好，但其余三个类别的区分度较差。
对于分类，我使用主成分作为支持向量机 (SVM) 和线性判别分析 (LDA) 中的特征，并且两个模型都实现了非常好的准确性。我希望从社区获得有关这一观察的一些见解。有人可以解释这个明显的矛盾吗？为什么 PCA 图没有显示三个类别之间的明显分离，但使用主成分作为特征时分类算法表现良好？
感谢您的时间和考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660658/high-classification-accuracy-despite-poor-separation-in-pca-for-multi-class-data</guid>
      <pubDate>Tue, 28 Jan 2025 09:43:50 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程填补缺失的时间序列数据</title>
      <link>https://stats.stackexchange.com/questions/660657/using-gaussian-process-to-impute-missing-time-series-data</link>
      <description><![CDATA[使用 R，我模拟了一些月度时间序列数据并随机删除了一些数据点：
library(ggplot2)
library(tidyverse)
library(MASS)
library(gridExtra)

set.seed(123)

dates &lt;- seq(as.Date(&quot;2014-01-01&quot;), as.Date(&quot;2023-12-31&quot;), by = &quot;month&quot;)
n &lt;- length(dates)

trend &lt;- seq(10, 30, length.out = n)
seasonal &lt;- 5 * sin(2 * pi * (1:n) / 12)
noise &lt;- rnorm(n, 0, 0.5)
values &lt;- trend + seasonal + noise

df &lt;- data.frame(date = dates, value = values)
n_remove &lt;- floor(0.3 * (n-2))
interior_indices &lt;- 2:(n-1)
remove_indices &lt;- sample(interior_indices, n_remove)

df$type &lt;- &quot;original&quot;
df$type[remove_indices] &lt;- &quot;removed&quot;


我的目标是填补时间序列中缺失的数据点。我有以下想法 - 可以使用高斯过程（通过 RBF 核）来实现吗？
我希望以这样的方式实现，即当非缺失点之间的空间增加时，插值/估算的不确定性会变得更大。我还想在插值/估算中添加一个概率元素，这以后可能会有用。我在下面写了基本的高斯过程公式：

$$ \begin{bmatrix} y_{observed} \\ y_{interpolated} \end{bmatrix} \sim \mathcal{N}\left(\begin{bmatrix} \mu_{observed} \\ \mu_{interpolated}
\end{bmatrix}, \begin{bmatrix} K_{11} &amp; K_{12} \\ K_{21} &amp; K_{22}
\end{bmatrix}\right) $$
$$ k(x_1, x_2) = \sigma^2 \exp\left(-\frac{(x_1 - x_2)^2}{2l^2}\right)$$
$$ p(y_{interpolated}|y_{observed}) = \mathcal{N}(\mu_{post}, \Sigma_{post}) $$
$$ \mu_{post} = K_{12}K_{11}^{-1}y_{observed} $$
$$\Sigma_{post} = K_{22} - K_{12}K_{11}^{-1}K_{21} $$ $$ y_{sample} \sim
\mathcal{N}(\mu_{post}, \Sigma_{post}) $$

我首先设置了执行此操作所需的不同函数：
 kernel &lt;- function(x1, x2, l = 30, sigma = 2) {
sqdist &lt;- outer(x1, x2, function(x, y) (as.numeric(x - y))^2)
sigma^2 * exp(-0.5 * sqdist / l^2)
}

x_obs &lt;- as.numeric(df$date[df$type == &quot;original&quot;])
y_obs &lt;- df$value[df$type == &quot;original&quot;]
x_pred &lt;- as.numeric(df$date)

K &lt;- kernel(x_obs, x_obs)
K_star &lt;- kernel(x_pred, x_obs)
K_star_star &lt;- kernel(x_pred, x_pred)

K &lt;- K + diag(1e-6, length(x_obs))

K_inv &lt;- solved(K)
mu_post &lt;- as.vector(K_star %*% K_inv %*% y_obs)
Sigma_post &lt;- K_star_star - K_star %*% K_inv %*% t(K_star)

然后，我写了采样程序：
n_samples &lt;- 50
samples &lt;- t(mvrnorm(n_samples, mu_post, Sigma_post))

ci_data &lt;- data.frame(
date = df$date,
mean = mu_post,
lower = apply(samples, 1, quantile, probs = 0.025),
upper = apply(samples, 1, quantile, probs = 0.975)
)

samples_df &lt;- as.data.frame(samples)
colnames(samples_df) &lt;- paste0(&quot;sample_&quot;, 1:n_samples)
samples_df$date &lt;- df$date
samples_long &lt;- tidyr::pivot_longer(samples_df, 
-date,
names_to = &quot;sample&quot;, 
values_to = &quot;value&quot;)

最后我尝试将其可视化：

Cross Validated 的人员：您之前尝试过/听说过有人尝试这样做吗？

注意：如果有人感兴趣，我可以分享 ggplot 可视化 R 代码
]]></description>
      <guid>https://stats.stackexchange.com/questions/660657/using-gaussian-process-to-impute-missing-time-series-data</guid>
      <pubDate>Tue, 28 Jan 2025 08:48:22 GMT</pubDate>
    </item>
    <item>
      <title>绘制箱线图时应该使用模型训练精度还是测试精度？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660656/for-plotting-box-plot-should-one-use-model-training-accuracy-or-test-accuracy</link>
      <description><![CDATA[我正在处理一个包含 500 个样本的数据集。我将数据集按 80、20 的比例分成训练和测试。使用训练集，我使用网格搜索方法对 SVM、KNN 和决策树分类器进行了超参数调整，并为每个分类器获得了最佳超参数。然后再次使用获得的超参数拟合训练数据集，并通过交叉验证评估分类器的训练准确率。最后使用测试数据集计算模型准确率，并将测试准确率报告为模型准确率。
现在我想绘制箱线图来表示模型准确率，那么我应该使用训练准确率还是测试数据（交叉验证）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660656/for-plotting-box-plot-should-one-use-model-training-accuracy-or-test-accuracy</guid>
      <pubDate>Tue, 28 Jan 2025 08:16:40 GMT</pubDate>
    </item>
    <item>
      <title>SAS 和 Python 之间的 Somers D 对二元结果不匹配吗？</title>
      <link>https://stats.stackexchange.com/questions/660655/mismatch-of-somers-d-between-sas-and-python-for-binary-outcomes</link>
      <description><![CDATA[执行摘要：

scipy.stats.somersd(x,y) 将 y 视为独立变量。
与 SAS 的 PROC LOGISTIC 相比，对于二元变量，如果我切换变量，我只能让它与 Python 匹配。
在查看二元目标时，是否有令人信服的理由来切换变量，或者我在使用中遗漏了什么？

背景：
因此，我尝试将 Somers 的 D 用于观察值 x 和 y，y 是 因变量。换句话说：我想知道 x 对 y 的排名如何。我希望我的用法对于两个变量都分组的情况和 y 是二进制变量的基数是一致的。但是，SAS 和 Python 之间的惯例似乎不同。为此，我为自己生成了一些数据。x 和 y 是连续的。还有分组列和二进制目标（由 y 中的非常粗略的分箱制成）
scipy.stats.somersd 文档指出 somersd(x,y) 将 x 视为独立变量，将 y 视为独立变量。按照该标准计算 Somers 的 D（对于分组变量），我得到的值为 0.36057，我可以通过手动计算进行交叉检查。代码位于此处。
改为计算二进制情况，我得到 0.23609。如果我切换变量的顺序，我得到 0.51680。
转到 SAS（并导入相同的数据集），我尝试从 PROC LOGISTIC 获取 Somers 的 D：
ods output Association=assoc;
proc logistic data=somersd;
model y_binarized(event=&#39;1&#39;) = x_group;
run;

如果我切换因变量和自变量，则会产生与 scipy.stats.somersd 匹配的 0.51680 值。
实际问题：
我试图弄清楚特定变量 x 对二元结果 y 的预测效果如何。在我看来，这意味着 y 是 因变量，我应该计算 scipy.stats.somersd(x,y)。但是，SAS 计算与 scipy.stats.somersd(y,x) 匹配。
在计算二元结果时，是否有令人信服的理由来改变变量的顺序，或者我是否滥用了 SAS 或 Python？
备份信息：
我喜欢用代码交流。我的想法（代码）可以在这个 Github 存储库中找到。Readme.md 文件是丹麦语（合作者是丹麦人），但代码是用英语注释的。为一致性而欢呼。
Python 代码调用 scipy.stats.somersd 并通过手动计算进行交叉检查。
SAS 代码 从 Github 读取 csv 文件（您可能需要调整代理设置）并运行 PROC LOGISTIC 以获取 Somers 的 D。还有一些 PROC FREQ 的东西我还没有想完。]]></description>
      <guid>https://stats.stackexchange.com/questions/660655/mismatch-of-somers-d-between-sas-and-python-for-binary-outcomes</guid>
      <pubDate>Tue, 28 Jan 2025 08:01:37 GMT</pubDate>
    </item>
    <item>
      <title>异常值检测，取 Z 分数的平均值是否合适？</title>
      <link>https://stats.stackexchange.com/questions/660654/outlier-detection-is-it-appropriate-to-take-the-mean-of-z-scores</link>
      <description><![CDATA[简单的背景故事，我有几个加密代币想要查看。我想做一些异常检测，并寻找哪些代币可能容易受到欺诈或骗局的影响。
假设我们有 10 个代币。我将它们放在一个数据框中，每个代币都有股票代码以及价格、流动性和交易量等数字属性。
假设我计算了每个代币的价格、流动性和交易量的 $Z$ 分数。如果我想评估哪个代币可能是骗局，那么取所有 $Z$ 分数列的平均值在统计上是否合适？（即 $\frac{Z_{price}+Z_{liquidity}+Z_{volume}}{3}$）]]></description>
      <guid>https://stats.stackexchange.com/questions/660654/outlier-detection-is-it-appropriate-to-take-the-mean-of-z-scores</guid>
      <pubDate>Tue, 28 Jan 2025 06:38:38 GMT</pubDate>
    </item>
    <item>
      <title>向使用现有距离矩阵构建的 UMAP 添加新点</title>
      <link>https://stats.stackexchange.com/questions/660652/adding-new-points-to-umap-built-with-existing-matrix-of-distances</link>
      <description><![CDATA[我有一个距离矩阵，比如说 1000x1000。我想在 2D 投影上绘制这个数据集，但有一个技巧 - 我想只使用前 800 个点来绘制图表，然后在其上添加剩余的 200 个点。当使用“原始”数据点作为输入时，UMAP 允许添加新点，但我确实需要一个距离矩阵。我正在寻找 R 或 Python 中的代码或只是一个想法（ChatGPT 提供了一些，但最终都没有奏效）。
实际上，它不一定是 UMAP，它只需要是一种将距离矩阵投影到 2D 图上的好方法。
这项练习背后的实际意义：800 个固定点是疾病，这个集合是恒定的，但 200 个（或 300 个或更多）是患者，它们会随着每次新的分析而变化。疾病或患者用一组症状来描述，必须使用基于复杂本体的距离。]]></description>
      <guid>https://stats.stackexchange.com/questions/660652/adding-new-points-to-umap-built-with-existing-matrix-of-distances</guid>
      <pubDate>Tue, 28 Jan 2025 04:48:46 GMT</pubDate>
    </item>
    <item>
      <title>累积风险总是呈指数分布吗？</title>
      <link>https://stats.stackexchange.com/questions/660650/is-the-cumulative-hazard-always-exponentially-distributed</link>
      <description><![CDATA[我知道累积风险函数与生存函数具有以下关系（如何从 Cox-PH 回归中恢复生存函数？）：
$$S(t) = \exp(-H(t))$$
这是否意味着累积风险始终具有指数 (1) 分布？
我可以看到这一点，因为对于某个随机变量 $y$，我们可以写成：
$$S(y) = P(Y &gt; y) = e^{-y} = e^{-H(t)}$$
现在，如果我为指数分布编写生存函数，其中 $\lambda=1$:
$$f(y, \lambda) = \lambda e^{-\lambda y}$$
$$f(y, \lambda=1) = e^{-y}$$
$$S(y) = P(Y &gt; y)$$
$$S(y) = \int_y^\infty e^{-t} \, dt$$
$$S(y) = \left[ -e^{-t} \right]_y^\infty = 0 - (-e^{-y}) = e^{-y}$$
$$S(y) = e^{-y}$$
因此，一般来说，对于任何随机变量，累积风险都遵循指数分布，其中$\lambda=1$:
$$H(t) \sim \exp(1) $$
这是正确的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660650/is-the-cumulative-hazard-always-exponentially-distributed</guid>
      <pubDate>Tue, 28 Jan 2025 03:46:44 GMT</pubDate>
    </item>
    <item>
      <title>在 GLMM 中，什么样的随机效应方差才算是“接近零”？</title>
      <link>https://stats.stackexchange.com/questions/660635/what-qualifies-as-near-zero-random-effect-variance-in-glmm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660635/what-qualifies-as-near-zero-random-effect-variance-in-glmm</guid>
      <pubDate>Mon, 27 Jan 2025 19:51:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么高度相关的特征会导致相应系数很大且符号相反？</title>
      <link>https://stats.stackexchange.com/questions/660628/why-do-highly-correlated-features-cause-the-corresponding-coefficients-to-be-lar</link>
      <description><![CDATA[我进行了以下实验。假设我们要构建一个具有 3 个特征的线性回归：$$y = w_1 * x_1 + w_2 * x_2 + w_3 * x_3$$，并且我们有一个包含一定数量样本的数据集。该数据集是一个均匀随机设计矩阵 $X$，除了特征 $x_3$，它是 $x_2$ 加上一些随机噪声，以使 $x_2$ 和 $x_3$ 高度相关。此外，真实权重向量 $w_{true}$ 也是随机生成的，导致目标计算为：$$y 
= Xw_{true} + \epsilon$$，其中 $\epsilon$ 是随机生成的噪声。给定 $X$ 和 $y$，我想要找到 $w^*$，如下所示：$$w^* = (X^T X)^{-1}X^T Y$$
这是最小化 MSE 损失函数的解析解。因此，估计系数 $w_2^*$ 和 $w_3^*$ 的绝对值较大，但符号相反。如果我将目标噪声 $\epsilon$ 调大，系数的绝对值会变大，但当我将特征 $x_2$ 和 $x_3$ 之间的噪声调小时，系数也会增大。一种可能的解释是，由于 $x_2$ 和 $x_3$ 高度相关，因此在选择相应的回归系数时具有很大的灵活性，并且我们的解决方案尝试学习目标噪声 $\epsilon$，但由于相关特征之间的差异与目标噪声相比很小，因此我们需要较大的系数来解释特征值的细微变化。但是，我并不完全了解其背后的机制，以及为什么添加相关特征会使我的模型过度拟合]]></description>
      <guid>https://stats.stackexchange.com/questions/660628/why-do-highly-correlated-features-cause-the-corresponding-coefficients-to-be-lar</guid>
      <pubDate>Mon, 27 Jan 2025 18:59:16 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 - AIC 还是 ANOVA？</title>
      <link>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</link>
      <description><![CDATA[我正在比较三种不同的嵌套线性回归模型。基于 ANOVA F 统计量，最简单的模型是最好的 (i1)。但是，这些模型的 AIC 非常相似，在 +_3 以内。根据 AIC，第三个模型是最好的 (i3)。最好使用 ANOVA 或 AIC。
此外，在查看诊断图时，第二个模型看起来更好。我知道这不是用来确定最佳拟合模型的，但我认为最好尽量减少方差。
所以我有点不知道如何决定哪个模型最好。提前谢谢！
&gt; i1 &lt;- lm(Cumulative_N2O ~ 0 + Grass + Legume + Herb + Nfert_0N + 
Site_2, data=n2o)
&gt; summary(i1)

调用：
lm(公式 = Cumulative_N2O ~ 0 + Grass + Legume + Herb + Nfert_0N + 
Site_2, data = n2o)

残差：
最小值 1Q 中值 3Q 最大值 
-1.32809 -0.19026 -0.00881 0.21082 1.58006 

系数：
估计标准差误差 t 值 Pr(&gt;|t|) 
草 2.07796 0.10890 19.08 &lt;2e-16 ***
豆科植物 2.62105 0.09654 27.15 &lt;2e-16 ***
草本植物 1.99249 0.10891 18.30 &lt;2e-16 ***
Nfert_0N -1.74548 0.08029 -21.74 &lt;2e-16 ***
Site_2 -0.04660 0.08029 -0.58 0.563 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：95 自由度上 0.4014

多重 R 平方：0.9458，调整后的 R 平方：0.943

F 统计量：5 和 95 DF 上的 331.9，p 值：&lt; 2.2e-16

&gt; 
&gt; i2 &lt;- lm(Cumulative_N2O ~ 0 + Nfert:Grass + Nfert:Legume + 
Nfert:Herb + Site_2, data=n2o)
&gt; summary(i2)

调用：
lm(公式 = Cumulative_N2O ~ 0 + Nfert:Grass + Nfert:Legume + 
Nfert:Herb + Site_2, 数据 = n2o)

残差：
最小值 1Q 中值 3Q 最大值 
-1.26452 -0.19709 0.00877 0.17978 1.51149 

系数：
估计标准差错误 t 值 Pr(&gt;|t|) 
Site_2 -0.04660 0.07881 -0.591 0.55574 
Nfert0N:Grass 0.32782 0.13486 2.431 0.01698 * 
Nfert150N:Grass 2.08262 0.13486 15.442 &lt; 2e-16 ***
Nfert0N:Legume 0.74308 0.11533 6.443 5.12e-09 ***
Nfert150N:Legume 2.75353 0.11533 23.875 &lt; 2e-16 ***
Nfert0N:Herb 0.41873 0.13490 3.104 0.00253 ** 
Nfert150N:Herb 1.82076 0.13490 13.497 &lt; 2e-16 ***
---
符号代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：93 自由度上的 0.394
多重 R 平方：0.9489，调整后的 R 平方：0.9451
F 统计量：7 和 93 DF 上的 246.8，p 值：&lt; 2.2e-16

&gt; 
&gt; i3&lt;-lm(Cumulative_N2O ~ 0 + Nfert:Grass + Nfert:Legume + 
Nfert:Herb + Site:Nfert, data=n2o)
&gt; summary(i3)

调用：
lm(formula = Cumulative_N2O ~ 0 + Nfert:Grass + Nfert:Legume + 
Nfert:Herb + Site:Nfert, data = n2o)

残差：
最小值 1Q 中值 3Q 最大值 
-1.33224 -0.13940 -0.03067 0.16073 1.44379 

系数：
估计标准差误差 t 值 Pr(&gt;|t|) 
Nfert0N:Grass 0.21360 0.13895 1.537 0.1277 
Nfert150N:Grass 2.10364 0.13895 15.140 &lt; 2e-16 ***
Nfert0N:Legume 0.62870 0.12060 5.213 1.13e-06 ***
Nfert150N:Legume 2.77471 0.12060 23.008 &lt; 2e-16 ***
Nfert0N:Herb 0.30433 0.13907 2.188 0.0312 * 
Nfert150N:Herb 1.84196 0.13907 13.245 &lt; 2e-16 ***
Nfert0N:Site2 0.18207 0.11026 1.651 0.1021 
Nfert150N:Site2 -0.08887 0.11026 -0.806 0.4223 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：92 个自由度上的 0.3898

多重 R 平方：0.9505，调整后的 R 平方：0.9462

F 统计量：8 和 92 DF 上的 221，p 值：&lt; 2.2e-16 

]]></description>
      <guid>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</guid>
      <pubDate>Mon, 27 Jan 2025 12:49:29 GMT</pubDate>
    </item>
    <item>
      <title>卡方蒙特卡罗模拟反馈和替代方案</title>
      <link>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</link>
      <description><![CDATA[我有一个列联表，我想在其上应用卡方检验，但某些单元格不大于 5，这意味着我无法使用该检验。我读到过蒙特卡罗模拟是可行的，但我不知道在这种情况下它是否合适，或者是否有替代测试。
这是我的数据：
data &lt;- matrix(c(326, 32, 22, 2, 96, 115, 271, 4, 132, 29), 
nrow = 5, byrow = TRUE,
dimnames = list(c(&quot;GR1&quot;, &quot;GR2&quot;, &quot;GR3&quot;, &quot;GR4&quot;, &quot;GR5&quot;),
c(&quot;No&quot;, &quot;Yes&quot;)))

这是 R 中的结果：
chisq.test(data, mock.p.value = TRUE, B = 10000)

带模拟 p 值的 Pearson 卡方检验（基于 10000 次重复）

数据：数据
X 平方 = 266.48，df = NA，p 值 = 9.999e-05

我的方法好吗，或者是否有更可靠或更有趣的替代方法？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</guid>
      <pubDate>Mon, 27 Jan 2025 12:20:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何将对数刻度分布函数插入到规则网格上？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660533/how-should-i-interpolate-a-log-scaled-distribution-function-onto-a-regular-grid</link>
      <description><![CDATA[我有一些实验数据，它们遵循某个分布函数。为简单起见，假设为高斯分布。支持是不规则采样的。以下 Python 代码应该大致生成一些有代表性的假数据。
import matplotlib.pyplot as plt
import numpy as np

rng = np.random.default_rng()

x = 10 ** rng.uniform(-1, high=2, size=50)
y = 1 / np.sqrt(2 * np.pi) * np.exp(-0.5 * x**2)

fig, ax = plt.subplots(1, 1)
kw = {&quot;ec&quot;: &quot;none&quot;, &quot;s&quot;: 40}

ax.scatter(x, y, fc=&quot;k&quot;, **kw)
ax.set_yscale(&quot;log&quot;)
ax.set_xscale(&quot;log&quot;)

plt.show()


由于支撑范围很广（本例中超过 3 个标准差），因此函数值可以跨越多个数量级。范围不如这个假数据那么大（&gt;100 个数量级），但典型的实验数据可以在 10-40 个数量级之间变化。
现在，我想将这些数据插入（重新网格化）到规则网格上（以便支撑中的间距保持恒定）。有两种方法可以做到这一点，要么我计算每个箱中的 (1) y 的算术平均值，要么 (2) y 的几何平均值，即
$
y_1^i=\frac1{N_i}\sum_{x_j\in(\overline{x}_i,\overline{x}_{i+1})}y_j,\qquad\text{and}\qquad
\log_{10}y_2^i=\frac1{N_i}\sum_{x_j\in(\overline{x}_i,\overline{x}_{i+1})}\log_{10}y_j,
$
其中 $N_i=\sum_{x_j\in(\overline{x}_i,\overline{x}_{i+1})}1$ 是由 $(\overline{x}_i,\overline{x}_{i+1})$ 和 $\{\overline{x}_i\}$ 常规网格定义的 $i$ 个箱子内的数据点数量（对于所有 $i$，$\Delta\overline{x}_i=d$）。请参阅以下代码：
log_x_grid, dx = np.linspace(
np.log10(x).min(), np.log10(x).max(), 100, retstep=True
)
log_x_bins = np.append(log_x_grid, log_x_grid[-1] + dx)
x_grid = 10**log_x_grid

H = np.histogram(np.log10(x), bins=log_x_bins)[0]
Hy1 = np.histogram(np.log10(x), bins=log_x_bins, weights=y)[0]
Hy2 = np.histogram(np.log10(x), bins=log_x_bins, weights=np.log10(y))[0]
y1 = Hy1 / H
y2 = 10.0 ** (Hy2 / H)

fig,axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)
kw = {&quot;ec&quot;: &quot;none&quot;, &quot;s&quot;: 40}

axes[0].scatter(x_grid, y1, fc=&quot;r&quot;, label=&quot;Interpolated&quot;, **kw)
axes[1].scatter(x_grid, y2, fc=&quot;r&quot;, **kw)

for i, ax in enumerate(axes):
ax.plot(
x[np.argsort(x)],
y[np.argsort(x)],
&quot;-k&quot;,
label=&quot;Original&quot; if i == 0 else &quot;&quot;,
)
ax.set_xscale(&quot;log&quot;)
ax.set_yscale(&quot;log&quot;)

axes[0].set_title(&quot;算术平均值&quot;)
axes[1].set_title(&quot;几何平均值&quot;)
axes[0].legend(frameon=False, loc=&quot;lower left&quot;)
plt.show()


所以算术平均值($y_1$) 可以在一定数量级内正确地近似原始数据（显然是由于机器代码精度），但几何平均值 ($y_2$) 可以通过所有数量级近似数据。如果计算精度无限，算术平均值计算应该是正确的操作。但我们没有。所以我不得不使用几何平均值。但是，我也没有充分的理由说明为什么它会给出与原始数据相同的结果，以及什么时候不会。请帮助我解决困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660533/how-should-i-interpolate-a-log-scaled-distribution-function-onto-a-regular-grid</guid>
      <pubDate>Sat, 25 Jan 2025 16:30:47 GMT</pubDate>
    </item>
    <item>
      <title>不存在对称性时的条件期望[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660531/conditional-expectation-when-there-are-no-symmetries</link>
      <description><![CDATA[当没有对称性时，如何计算条件期望？例如：
如何证明$E[Y\mid S]=S/3$，其中$(X,Y,Z)$是一个三维变量，其密度函数为$f(x,y,z)=(x+2y+3z)/3$，位于$0&lt;x,y,z&lt;1$和$S=X+Y+Z$上？
待完成。
$$E[X|S]=
\begin{cases}
\displaystyle\frac{7S}{24} \qquad &amp;0&lt;s&lt;1\\ 
\displaystyle\frac{14S^4-36S^3-6S^2+36S-15}{24S(2S^2-6S+3)} \qquad &amp;1&lt;s&lt;2\\
\displaystyle\frac{7S^2+6S-9}{24S} \qquad &amp;2&lt;s&lt;3
\end{cases}$$
$$E[Z|S]=
\begin{cases}
\displaystyle\frac{9S}{24} \qquad &amp;0&lt;s&lt;1\\ 
\displaystyle\frac{18S^4-60S^3+54S^2-36S+15}{24S(2S^2-6S+3)} \qquad &amp;1&lt;s&lt;2\\
\displaystyle\frac{9S^2-6S+9}{24S} \qquad &amp;2&lt;s&lt;3
\end{cases}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660531/conditional-expectation-when-there-are-no-symmetries</guid>
      <pubDate>Sat, 25 Jan 2025 14:34:11 GMT</pubDate>
    </item>
    <item>
      <title>是否可以汇总 AIC/BIC 值以进行参与者级模型比较？</title>
      <link>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</link>
      <description><![CDATA[我有一个数据集，其中包含来自数百名参与者的情绪时间序列数据，他们每个人都参加了生态瞬时评估 (EMA) 研究。由于每个参与者的事件时间完全不同，我决定使用 R 中的药代动力学建模包 (mrgsolve) 生成的复杂非线性模型分别拟合每个参与者的数据。
我正在使用 nloptr 根据我已经对这些数据执行的一些混合效应建模得出的初步猜测来推导参数，但这是一个不需要药代动力学方法的更简单的模型。由于呈现的模型数量庞大，手动优化每个模型的参数并不切实际。相反，我使用合理但未优化的参数值运行这些模型，这实际上效果很好，因为每个参与者对事件的情绪反应模式大致相似。
对于每个模型，我的零假设是数据纯粹由噪声组成。我的替代假设是，药代动力学模型在模拟参与者的情绪反应方面优于噪声模型。到目前为止，药代动力学模型似乎在几乎（但不是所有）情况下都能产生更优的 RSS 和 AIC/BIC 值。
有没有办法批量测试药代动力学建模方法产生更优的建模结果的假设，表明它所基于的模型优于噪声的零假设？例如，如果 95%（或其他百分比）的药代动力学模型比基于噪声的模型产生更好的拟合效果，这可以用来证明统计意义吗？或者是否有另一种基于指标的方法来测试这个假设，例如比较每个参与者的每个模型之间的 AIC 和 BIC 值，并在所有参与者中汇总这些值？]]></description>
      <guid>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</guid>
      <pubDate>Mon, 20 Jan 2025 08:21:49 GMT</pubDate>
    </item>
    </channel>
</rss>