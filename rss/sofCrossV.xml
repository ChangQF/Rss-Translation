<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 14 Aug 2024 21:14:59 GMT</lastBuildDate>
    <item>
      <title>KS 和 AD 测试的假阴性率高得离谱</title>
      <link>https://stats.stackexchange.com/questions/652819/false-negative-rates-of-ks-and-ad-tests-are-absurdly-high</link>
      <description><![CDATA[我正在 R 中运行模拟，我想测量 Kolmogorov–Smirnov (KS) 检验和 Anderson Darling (AD) 检验的相对假阴性率。我不确定我在这里使用的术语是否正确，但我所说的假阴性是指即使样本数据来自测试的假定分布，测试也会得出显著结果 ($p &lt; \alpha$)。我以为假阴性率大约等于 $\alpha$，但我得到的结果却接近 1。例如，这里我从对数正态分布中抽取 50 个样本，然后执行每个拟合优度检验，计算检验给出显著结果的次数：
 library(DescTools)

alpha = 0.05
sims = 100
sampleSize = 50
fnAD = 0
fnKS = 0

for(i in 1:sims){

data = rlnorm(sampleSize, 2, 3)
test = AndersonDarlingTest(data, &quot;plnorm&quot;)
if(test$p.value &lt; alpha){
fnAD = fnAD + 1
}

test = ks.test(data, &quot;plnorm&quot;)
if(test$p.value &lt; alpha){
fnKS = fnKS + 1
}

}

print(c(fnAD/sims, fnKS/sims)) 


我发现无论我使用什么参数来定义对数正态分布，这种情况都会发生，并且发生在不同的样本大小下。为什么假阴性率这么高？我的代码有错误吗，还是我从根本上误解了拟合优度检验的某些内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/652819/false-negative-rates-of-ks-and-ad-tests-are-absurdly-high</guid>
      <pubDate>Wed, 14 Aug 2024 19:59:43 GMT</pubDate>
    </item>
    <item>
      <title>多层模型，其中随机效应的偏差取决于独立变量</title>
      <link>https://stats.stackexchange.com/questions/652818/multilevel-model-where-skew-of-random-effect-depends-on-an-independent-variable</link>
      <description><![CDATA[我正在尝试构建一个模型，其中随机效应分布的偏斜随独立变量而变化。我最终想使用 R 中的 brms 来拟合它。这是一个类似于我的数据的具体示例：
假设我经营一家杂货店，我想了解食品销售量如何根据天气变化。因此，我收集了商店中每件商品的销售数据和每日最高温度。我还怀疑食品的辣度会影响对温度的反应，因此我收集了每种食品的辣度分数作为连续变量。
标准方法是制作一个多层模型，其中包含温度和辣度之间的交互项以及食品的不同斜率。因此，对于 P（购买的食物量）、T 温度和 S 辣度
$$
log(P_i) \sim Normal(\mu_i, \sigma_i)
\\\mu_i = \alpha_{FOOD[i]} + \beta_{FOOD[i]}T + (\beta_S + \beta_{ST}T)S
\\ \begin{vmatrix}
\alpha_{FOOD[i]}\\ 
\beta_{FOOD[i]}\\
\end{vmatrix} \sim MVNormal(\begin{vmatrix}
\alpha\\ 
\beta\\
\end{vmatrix}, \Sigma)
$$
对不同的参数和方差-协方差矩阵指定各种先验。这应该可以检测出辣度是否会改变温度对食品销售的影响，但允许斜率在不同食品之间变化。
然而，我遇到麻烦的地方是，我怀疑存在这样一种情况，即大多数食品的销售不受温度的影响，但受温度影响最大的食品平均而言往往更辣，随着温度升高而变得不那么受欢迎。与此同时，许多同样辣的食品对温度的反应没有变化（可能是因为它们一开始就不受欢迎）。我担心，因为如果是这样的话，上面指定的模型可能很难捕捉到辣度的影响，因为平均值可能不会有太大变化。如果是这种情况，随机斜率可能会遵循类似这样的分布，其中 $\beta_{FOOD[i]}$ 的平均值相同，但偏斜会根据辣度而改变：
 因此，我正在考虑一个类似这样的模型，我将辣度作为随机斜率 $\beta_{FOOD[i]}$ 的偏斜预测因子
$$
log(P_i) \sim Normal(\mu_i, \sigma_i)
\\\mu_i = \alpha_{FOOD[i]} + \beta_{FOOD[i]}T + \beta_SS
\\ \begin{vmatrix}
\alpha_{FOOD[i]}\\ 
\beta_{FOOD[i]}\\
\end{vmatrix} \sim MVSkewNormal(\begin{vmatrix}
\alpha\\ 
\beta\\
\end{vmatrix}, \Sigma, D)
\\D = \alpha_D + \beta_{S, Shape}S
$$
我认为我需要为 $\beta_{S, Shape}$ 和 $\alpha_D$ 以及其他参数指定先验。在这里，我认为我们可以说，例如，辛辣食物会增加斜率更高的可能性（实际上并没有改变平均值$\beta_{FOOD[i]}$
所以我想我的问题是：

以这种方式建立模型是否有效/是否比仅包含标准交互项更有效？或者是否有其他方法更有可能捕捉到我感兴趣的效果？

我可以在brms中实现类似的东西吗？语法是什么样的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652818/multilevel-model-where-skew-of-random-effect-depends-on-an-independent-variable</guid>
      <pubDate>Wed, 14 Aug 2024 19:47:46 GMT</pubDate>
    </item>
    <item>
      <title>优化精度比优化协方差矩阵更有效吗？</title>
      <link>https://stats.stackexchange.com/questions/652812/is-it-more-efficient-to-optimize-precision-than-covariance-matrix</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但我想确保我没有遗漏任何东西。
假设我们想通过最大化数据的可能性来将多元高斯分布$\mathcal{N}(\mu, \Sigma)$拟合到某些数据。出于某种原因，我们希望使用梯度下降法对参数 $\mu$ 和 $\Sigma$ 最大化数据的可能性（例如，我们可能希望对 $\mu$ 施加约束或惩罚），将 $\Sigma$ 约束为正定。
在优化的每个步骤中，我们都在评估数据点上高斯分布的 PDF，因此我们需要反转 $\Sigma$。我的问题是，直接在精度矩阵 $\Sigma^{-1}$ 上进行优化是否在计算上更有效率？是否有某些原因导致我们可能更喜欢对 $\Sigma$ 进行优化并在每一步中对其进行反转？]]></description>
      <guid>https://stats.stackexchange.com/questions/652812/is-it-more-efficient-to-optimize-precision-than-covariance-matrix</guid>
      <pubDate>Wed, 14 Aug 2024 19:05:44 GMT</pubDate>
    </item>
    <item>
      <title>预测新手——对于使用合适的模型有什么建议吗？</title>
      <link>https://stats.stackexchange.com/questions/652811/new-to-forecasting-any-tips-for-proper-model-to-use</link>
      <description><![CDATA[所以我做了大量的互联网研究，但失败了。我试图预测海上钻井船的日费率。我有两个外生变量与我的历史日费率数据密切相关。（需求和供应指数的日费率数据相关性约为 0.75）。大量数据输入其中。
问题是，这些数据非常繁荣 - 萧条。我的数据集是 2010-2024 年的日费率。我已经预测了 2029 年的数据，因为其中很多值在某种程度上是“已知的”（新建船舶队列、未经证实/未经批准的 E&amp;P 活动等）。对于我的问题，绝对最佳的模型是什么？我相信我的需求供应指数是这些费率的非常强的预测指标。
我尝试过 SARIMAX 和后来的马尔可夫切换 ARIMAX，但它们似乎都没有考虑到我的萧条阶段。最终，我确实相信我的供需指数在历史上是强有力的预测指标——我应该如何解释这一点？
我真的只是想征求一个建议，哪些模型可能适合这些数据。供需指数的范围是 1-150 左右（最小-最大），代表总深水投资需求（以十亿美元计）。供应紧张程度的范围是 0-1，来自其他几个数据集。
以下是我的一小部分数据：
日期 平均 铅 日费率 供应紧张指数 需求指数
2010 年 6 月 1 日 500869.5381 0.578840012 94.82266832]]></description>
      <guid>https://stats.stackexchange.com/questions/652811/new-to-forecasting-any-tips-for-proper-model-to-use</guid>
      <pubDate>Wed, 14 Aug 2024 18:58:38 GMT</pubDate>
    </item>
    <item>
      <title>随机过程的底层 sigma 代数</title>
      <link>https://stats.stackexchange.com/questions/652810/underlying-sigma-algebra-of-a-random-process</link>
      <description><![CDATA[随机过程通常定义为一个集合$(X_i)_{i\in \mathcal{I}}$，其中$\mathcal{I}$是某个索引集，每个$X_i$都是一个随机变量$X_i:(\Omega,\mathcal{A})\rightarrow(\mathcal{X},\mathcal{B})$。若某个随机过程中的每一个随机变量$X_i$都作用于共同可测空间$(\Omega_b,\mathcal{A}_b)$，则该随机过程的底层$\Omega$就不是$\Omega_b$，而是$\Omega\times\Omega\cdots$。比如，如果 $X_i$ 是 $i$ 次硬币抛掷中正面朝上的次数，则随机过程 $(X_i)$ 的底层 $\Omega$ 不是 $\{H,T\}$，而是 $\{H,T\}^\infty$（具有相应的 $\sigma$-代数）。我说得对吗？
有些文本省略了这个基本概念，并认为例如这个过程存在于 $\{H,T\}$ 上。我认为这种理解在应用方面是很好的，除非我们开始思考它的数学原理。如果我理解错了，一些概念，如过滤、马丁格尔等，对我来说就是没有意义的。例如，如果我们将子$\sigma$-代数$\mathcal{A}$的某些过滤视为截至时间$n$的信息，则$\mathcal{A}_n$的形式为$\mathcal{A}_n$=\mathcal{P}(\{H,T\})\otimes \mathcal{P}(\{H,T\}) \otimes \cdots \otimes \mathcal{P}(\{H,T\}) \otimes \{\emptyset,\{H,T\}\}\otimes \{\emptyset,\{H,T\}\} \cdots$.
有人能告诉我，我的这种理解是否正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652810/underlying-sigma-algebra-of-a-random-process</guid>
      <pubDate>Wed, 14 Aug 2024 18:57:22 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用已知范围但未知平均值生成正态分布的变量</title>
      <link>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</link>
      <description><![CDATA[我想生成一个具有已知范围（例如 10.4-16.6）但不知道平均值的 100 个数据点的正态分布变量。要使用 rnorm，我需要平均值和标准差。如果我假设它是精确的中点（平均值 = (10.4 + 16.6) * 0.5 = 13.5），我可以估算平均值。并对标准差进行一些类似的估计（标准差 = (13.5 - 10.4) /2 = 1.55）。然后我可以使用 rnorm 函数

rnorm (n=100, 平均值 = 13.5, 标准差 = 1.55)

但结果变量的范围超出了我最初的 10.4-16.6 范围。我想看看是否有更好的方法来生成这个变量并强制它保持在我想要的范围内。]]></description>
      <guid>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</guid>
      <pubDate>Wed, 14 Aug 2024 18:22:10 GMT</pubDate>
    </item>
    <item>
      <title>加权平均值（平均客户与产品互动）</title>
      <link>https://stats.stackexchange.com/questions/652806/weighted-averages-average-customer-product-interactions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652806/weighted-averages-average-customer-product-interactions</guid>
      <pubDate>Wed, 14 Aug 2024 18:10:16 GMT</pubDate>
    </item>
    <item>
      <title>两个独立的受试者内模型中回归系数之间的 G*Power 样本量计算</title>
      <link>https://stats.stackexchange.com/questions/652803/gpower-sample-size-calculation-between-regression-coefficients-in-two-separate</link>
      <description><![CDATA[我有两个相同的回归模型在两个不同的子样本上运行。在 R 中，我的模型如下：
library(fixest)
library(tidyverse)

mod1 &lt;- feols(outcome ~ treatment | id, data=df %&gt;% filter(group == 1)) 
mod2 &lt;- feols(outcome ~ treatment | id, data=df) %&gt;% filter(group == 2)) 

其中 treatment 是一个因子变量，其级别分别为控制、1 和 2（控制是参考，已被删除）。 id 是受访者 ID，因此上述内容代表了受访者固定效应，从而支持受试者内设计。
对于我的分析，我想比较 mod1 中的 treatment1 与 mod2 中的 treatment1 的效应显著性之间的差异。
我需要对需要以 0.8 功率和 95% 置信度进行测试的受访者数量进行先验功率计算。我正在尝试使用 G*Power 来计算，但我不确定要使用哪种设置。我的直觉是，鉴于我正在比较回归系数，t 检验适合此设置，但当它们来自两个不同的模型时，哪种设置合适？如果它要求标准差，我会使用特定于特定子集的标准差吗？我的做法是否错误，是否可以使用其他测试？如果是，您能否提供一个适当的功效计算示例，该示例基于感兴趣的估计值作为两个受访者模型中两个回归系数之间的差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/652803/gpower-sample-size-calculation-between-regression-coefficients-in-two-separate</guid>
      <pubDate>Wed, 14 Aug 2024 16:56:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自然三次样条解释逻辑回归的系数？</title>
      <link>https://stats.stackexchange.com/questions/652801/how-to-interpret-coefficients-of-logistic-regression-using-natural-cubic-splines</link>
      <description><![CDATA[我正在尝试使用自然三次样条函数在 R 中进行逻辑回归，但在解释和使用结果时遇到了麻烦。
出于各种原因，我需要能够在 Python 中绘制（并可能进一步分析）结果。问题是，虽然我可以使用标准逻辑回归来做到这一点，但我不知道如何使用（自然三次）样条函数进行逻辑回归。
示例：对螺旋星系中恒星棒的频率进行逻辑回归，作为单个星系的总恒星质量的函数。 （如果您想自己尝试拟合，这里有一个指向数据文件的链接。）
如果我使用二次逻辑函数进行标准逻辑回归——就像我对Erwin 2018中数据集的早期版本所做的那样[Github 链接到 Python 和 R 笔记本：https://github.com/perwin/s4g_barfractions]，我会在 R 中得到类似这样的结果（删除一些输出）：
ff &lt;- &quot;barpresence_vs_logmstar_for_R_sp_w30_updateddist.txt&quot;
logmstarBarSpTable &lt;- read.table(ff, header=TRUE)

logMstarFitSp_quad &lt;- glm(bar ~ logmstar + I(logmstar^2), 
family = binomial, logmstarBarSpTable)
summary(logMstarFitSp_quad)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -19.2096 26.0781 -0.737 0.461
logmstar 4.2945 5.3723 0.799 0.424
I(logmstar^2) -0.2332 0.2760 -0.845 0.398
AIC：828.4

我可以轻松地在 Python 中绘制结果，因为我知道“系数”值对应于二次方程中的系数：
logit = beta_0 + beta_1*x + beta_2*x^2
其中 beta_0 = &quot;(Intercept)&quot;，beta_1 = &quot;logmstar&quot;，beta_2 = &quot;I(logmstar^2)&quot;，因此实际表达式变为
logit = -19.2096 + 4.2945*x - 0.2332*(x**2)
然后我可以使用 Python 代码生成概率值，如下所示：
probability = 1.0 / (1.0 + np.exp(-logit))
这是通过以下方式要求 R 绘制拟合结果：
plot_model(logMstarFitSp_quad, type = &quot;pred&quot;, term = c(&quot;logmstar&quot;))

这是在 Python 中执行相同操作的结果，结果非常吻合：
def logit_quad( x, params=[-19.2096, 4.2945, -0.2332] ):
return params[0] + params[1]*x + params[2]*(x**2)
xx = np.arange(8.5,11,0.01)
plt.plot(xx, 1.0 / (1.0 + np.exp(-logit_quad(xx)))


另一方面，如果我尝试在 R 中进行简单的自然三次样条逻辑回归（为简单起见，仅从一个内部结开始，因此 df=2），我会得到：
require(&quot;splines&quot;)
logMstarFitSp_spline2df &lt;- glm(bar ~ ns(logmstar, 2),
family = 二项式，logmstarBarSpTable)
summary(logMstarFitSp_spline2df)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) 0.5049 0.2285 2.210 0.0271 *
ns(logmstar, 2)1 -0.2487 0.5061 -0.492 0.6231 
ns(logmstar, 2)2 -0.7645 0.4276 -1.788 0.0738 .
AIC：828.16

不管怎样，我可以通过以下方式找出单个内部结点位于 logmstar = 9.5575 处
str(attributes(summ$terms)$predvars)
language list(bar, ns(logmstar, knots = c(`50%` = 9.5575), Boundary.knots = c(8.759, 11.024), intercept = FALSE))

... 我不知道如何解释这一点，也不知道 Python 中的 logit 表达式是什么样子。什么是“系数”在这个模型中？
原则上，我认为它们应该是与样条函数相乘的系数，因此
 logit = beta_0*h_1(x) + beta_1*h_2(x) + beta_1*h_3(x)

其中 h_1、h_2 和 h_3 是三个基函数（并且 beta_0 = &quot;(Intercept)&quot;，等等）。
但是基函数是什么？（我尝试阅读 R 函数 ns 的文档，结果让我感到困惑；而且我在这个网站上的各种样条函数请求问题中没有找到太多帮助。）]]></description>
      <guid>https://stats.stackexchange.com/questions/652801/how-to-interpret-coefficients-of-logistic-regression-using-natural-cubic-splines</guid>
      <pubDate>Wed, 14 Aug 2024 16:10:12 GMT</pubDate>
    </item>
    <item>
      <title>当涉及到潜在变量时，为什么我们在寻找 p(data) 时需要边缘化？（elbo 推导的一部分）</title>
      <link>https://stats.stackexchange.com/questions/652800/why-do-we-need-to-marginalize-when-finding-pdata-when-latent-variables-are-inv</link>
      <description><![CDATA[与 elbo 的推导非常混淆。在推导过程中，p(data) 是难以处理的，因为它涉及高维潜在变量的积分。我不明白为什么在计算 p(data) 时会涉及潜在变量。以图像为例，为什么 p(特定图像) 不是 = 1 / 数据集中的图像总数？我不确定为什么在计算 p(data) 时会涉及潜在变量，因为它不在等式的左侧，并且我们提供数据集，因此我们应该了解有关数据的所有信息。
任何帮助都非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652800/why-do-we-need-to-marginalize-when-finding-pdata-when-latent-variables-are-inv</guid>
      <pubDate>Wed, 14 Aug 2024 16:03:53 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>Aalen Johansen - 绝对风险和置信区间</title>
      <link>https://stats.stackexchange.com/questions/652776/aalen-johansen-absolute-risks-and-confidence-intervals</link>
      <description><![CDATA[如果存在竞争风险情况，可以使用 AJ 估计量来计算累积发生率函数 (CIF)。
在 R 中，使用 survfit{survival 和事件 0,1,2 来实现 AJ 非常简单。
在检查时间 20 的绝对风险时，R 还会计算置信区间 $lower 和 $upper，例如：



时间
cif
cif_lower
cif_upper




20
0.0175
0.0097
0.0314



因此，在时间 20 时，1.75% 的人遭遇了该事件 (CI 0.97% - 3.14%)
问题：

那是什么样的置信区间？
AJ 估计量是否需要特定的置信区间？
这个特定的置信区间是否需要使用匹配/加权后需要进一步调整吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652776/aalen-johansen-absolute-risks-and-confidence-intervals</guid>
      <pubDate>Wed, 14 Aug 2024 10:55:55 GMT</pubDate>
    </item>
    <item>
      <title>如何解释泊松模型估计的离散度？</title>
      <link>https://stats.stackexchange.com/questions/652770/how-to-interpret-dispersion-estimated-for-a-poisson-model</link>
      <description><![CDATA[假设我有以下数据：$(N_i, x_i, \nu_i)$，其中 $i=1,\dots,n$。我很快从汽车保险定价中得到启发。$N_i$ 代表索赔数量，$x_i$ 是我知道的一些特征，$\nu_i$ 是一些曝光（=时间）。例如：在半年的时间里（即 $\nu_i = 0.5$），我观察到两起（即 $N_i = 2$）索赔，索赔人年龄为 35 岁，车龄为 1 年（即 $x_i = (35, 1)$，在这种情况下，我的特征包括驾驶员年龄和车龄）。
根据数据，我可以选择以下建模方法：
$$
N_i \overset{ind.}{\sim} \mathrm{Poisson}(\lambda(x_i)\nu_i),
$$
因此，索赔数量由独立的泊松随机变量建模，其中频率函数 $x_i \to \lambda (x_i)$ 需要建模。请注意，曝光不是由 $\lambda(.)$ 建模的，而只是包含在模型中。
此示例源自我正在阅读的一本书，即这。现在，人们可以为$\lambda(.)$选择不同的建模方法，如 GLM、神经网络等。
为了评估拟合优度，本书讨论了两种方法：首先，计算（样本内）Pearson 残差，公式为
$$
\hat \delta_i^P = \frac{N_i - \lambda(x_i)\nu_i}{\sqrt{\lambda(x_i)\nu_i}}。
$$
根据我的（泊松）建模假设，这些应该是独立的，大致以单位方差为中心。
其次，他们定义了泊松偏差残差，由以下公式给出
$$
\hat \delta_i^D = \mathrm{sgn}(N_i - \lambda(x_i)\nu_i) \sqrt{2N_i \left[\frac{\lambda(x_i)\nu_i}{N_i} - 1 - \log\left(\frac{\lambda(x_i)\nu_i}{N_i}\right)\right]}
$$
最后，作者为模型的离散度定义了两个估计量（这里$q+1$是特征的数量$x_i$):
$$
\hat \p​​hi^P = \frac1{n-(q+1)} \sum_{i=1}^n (\hat \delta_i^P)^2
$$
并且
$$
\hat \p​​hi^D = \frac1{n-(q+1)} \sum_{i=1}^n (\hat \delta_i^D)^2 = \frac{D^*(\mathbf{N}, \lambda(.))}{n-(q+1)},
$$
其中 $D^*(\mathbf{N}, \lambda(.))$ 是泊松偏差损失。
问题：我不太明白我们为什么要查看这些离散度估计量。据我了解，离散度告诉我，模型方差是否接近其均值（我知道在泊松模型中方差等于其均值）。$\hat \p​​hi^P$ 和 $\hat \p​​hi^D$ 的哪些值会支持我的泊松模型假设？特别是，为什么 $\hat \p​​hi^D$ 是查看此问题的一个好方法，我该如何解释其值以及哪些值会支持我的假设？
如您所见，我并不清楚为什么（尤其是 $\hat\delta^D$）值得关注。他们只是来告诉我我选择的泊松模型是好是坏吗？如果有更有经验的人能阐明我的想法，我会很高兴。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652770/how-to-interpret-dispersion-estimated-for-a-poisson-model</guid>
      <pubDate>Wed, 14 Aug 2024 09:39:06 GMT</pubDate>
    </item>
    <item>
      <title>Delta 方法和方差收敛</title>
      <link>https://stats.stackexchange.com/questions/652753/delta-method-and-the-variance-convergence</link>
      <description><![CDATA[在我看过的参考文献中，$\Delta$ 方法通常以分布收敛的形式来表述：对于 $X_i$ i.i.d.，$\mathbb{E}[X_i]=\mu$ 和 $\mathrm{Var}_\mu(X_i)=\sigma^2&lt;\infty$（因此 CLT 对样本均值成立，$\bar{X}_n$），并且 $g$ 是一个足够平滑的函数，
$$
\sqrt{n}g(\bar{X}_n) -g(\mu))\Rightarrow N(0,g&#39;(\mu)^2\sigma^2)
$$
我正在看一篇论文（参见 https://arxiv.org/abs/1910.06222 中的 (11)），其中有以下估计：
$$
\lim_{n\to \infty} n \mathbb{E}[(\bar{X}_n) -g(\mu))^2] = g&#39;(\mu)^2\sigma^2
$$
我意识到，我不确定如何将 CLT 型弱收敛映射到二阶中心矩的这种收敛。我将如何论证这一点？
编辑：不出所料，我发现如果我们对导数有先验界限，那么结果就会成立（参见 Bickel 和 Doksum 的教科书）。但这一假设似乎并不存在于 Song &amp; Ermon 的论文中。]]></description>
      <guid>https://stats.stackexchange.com/questions/652753/delta-method-and-the-variance-convergence</guid>
      <pubDate>Wed, 14 Aug 2024 00:00:08 GMT</pubDate>
    </item>
    <item>
      <title>MLE 和非闭形式的解 - 如何查看或证明它？</title>
      <link>https://stats.stackexchange.com/questions/652748/mle-and-non-closed-form-solutions-how-to-see-or-proof-it</link>
      <description><![CDATA[我真的无法理解 MLE 的非闭式解。在讲座中，我们没有深入探讨它，只是假设某些对数似然函数（或者说分数函数）无法针对其各自的参数进行求解。
例如，如果我们使用逻辑回归对二元响应进行建模：

$y_i \sim Ber(\pi_i)$
$\pi_i = P(y_i=1) = h(\eta_i) = E(y_i) = \frac{exp(\eta_i)}{1+exp(\eta_i)}$
$\eta_i = g(\pi_i)= log(\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1x_i$

由此我们可以得到：

$ \ell(\beta) = \sum\limits_{i=1}^{n}[y_ilog(\pi_i) + (1-y_i)log(1-\pi_i)]$
$s(\beta) = \sum\limits_{i=1}^{n} \frac{\partial\eta_i}{\partial\beta} \frac{\partial\pi_i}{\partial\eta_i} \frac{\partial}{\partial\pi_i} \ell_i(\beta)$ $\leftarrow$（如果我没记错的话）

$s(\beta)$ 的哪一部分导数是不可计算的，我如何才能看到甚至证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/652748/mle-and-non-closed-form-solutions-how-to-see-or-proof-it</guid>
      <pubDate>Tue, 13 Aug 2024 21:38:32 GMT</pubDate>
    </item>
    </channel>
</rss>