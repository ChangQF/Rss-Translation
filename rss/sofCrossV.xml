<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 14 Nov 2024 15:17:59 GMT</lastBuildDate>
    <item>
      <title>比较幸存和未幸存的一组个体的不同时间点的测量值（1、2、3、4）</title>
      <link>https://stats.stackexchange.com/questions/657254/comparing-different-timepoints-of-measurments-1-2-3-4-for-a-group-of-individua</link>
      <description><![CDATA[希望您能帮上忙！？在大多数情况下，我们会对一组从疾病中幸存或未幸存（生存）的个体（重复测量）进行基于时间序列的测量（CD8T）。基于时间点的测量部分不完整，因为缺少数据，这就是为什么有时系列不完整（Time_Point）。我们想知道成分（CD8T）随时间的变化是否对生存有影响。此外，我们希望根据年龄和性别进行校正。您会建议什么模型？非常感谢任何帮助和设计、对比和在 R 中应用的代码。期待您的建议。希望您能为我指明正确的方向。
提前致谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657254/comparing-different-timepoints-of-measurments-1-2-3-4-for-a-group-of-individua</guid>
      <pubDate>Thu, 14 Nov 2024 15:07:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么这两个模型的系数不同？</title>
      <link>https://stats.stackexchange.com/questions/657253/why-are-the-coefficients-different-in-these-2-models</link>
      <description><![CDATA[假设您有 1 个输出变量 $y$ 和 2 个预测变量 $x_1$ 和 $x_2$。在模型 1 中，您使用普通最小二乘法对 $\ln(y)$ 进行建模，即您找到最佳的 $\beta_0$、$\beta_1$ 和 $\beta_2$，以使残差平方和 $\sum_{i = 1}^n e_i$ 最小化，其中
$$ e_i = \ln(y_i) - (\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}).$$
现在让我们将具有线性的广义线性模型视为模型 2预测器
$$ \eta = \beta_0 + \beta_1 x_1 + \beta_2 x_2, $$
输出变量 $y$（而不是 $\ln(y)$），其中族为高斯，链接函数为 $g(\mu) = \ln(\mu)$。
我知道这两个模型是不同的。一个区别是，GLM 更丰富，因为我们根据给定（指数）族的分布对给定 $x_1, x_2$ 的变量 $y$ 进行建模，该分布的参数可能随着 $x_1, x_2$ 的变化而变化。
但如果我们使用 GLM 的方式只是在给定 $x_1, x_2$ 的情况下输出 $y$ 的平均值，那么在我看来，我们做的事情与模型 1 中做的事情非常相似，至少是天真的。
我的问题是，系数 $\beta_0$、$\beta_1$ 和 $\beta_2$ 在这两个模型中总体上有什么不同？我理解模型 1 中这些系数是如何获得的，但我想更深入地了解模型 2 中这些系数是如何获得的，特别是权重的作用，因为我在某处读到我们可以进行迭代加权最小二乘估计来获得 GLM 中的系数。
另一个问题是，如果我们假设模型 2 中的同方差性，那么我们是否会在两个模型中获得相同的系数 $\beta_0$、$\beta_1$ 和 $\beta_2$，从而得到相同的预测？
我希望得到一个能向我澄清这些事情的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657253/why-are-the-coefficients-different-in-these-2-models</guid>
      <pubDate>Thu, 14 Nov 2024 14:48:25 GMT</pubDate>
    </item>
    <item>
      <title>对于受试者内实验设计来说，适当的偏倚风险评估工具是什么？</title>
      <link>https://stats.stackexchange.com/questions/657252/what-is-the-appropriate-risk-of-bias-assessment-tool-for-within-subject-experime</link>
      <description><![CDATA[我正在研究一项系统评价，其中绝大多数纳入的研究都使用了受试者内设计，即所有受试者在一种条件下执行一项或多项任务，然后在另一种条件下再次执行该任务。
我认为 RoB2 或 ROBINS 不合适，因为只涉及一个组，并且没有后续行动。
那么，我可以用什么来评估纳入研究的偏倚风险？有没有经过验证的工具？]]></description>
      <guid>https://stats.stackexchange.com/questions/657252/what-is-the-appropriate-risk-of-bias-assessment-tool-for-within-subject-experime</guid>
      <pubDate>Thu, 14 Nov 2024 14:21:50 GMT</pubDate>
    </item>
    <item>
      <title>如何平均发动机性能：直接还是加权？</title>
      <link>https://stats.stackexchange.com/questions/657251/how-to-average-engine-performance-direct-or-weighted</link>
      <description><![CDATA[我不确定在我的分析中应该使用哪种方法来计算平均值。以下是我的设置：
场景：我有三个新引擎（A、B 和 C）和两个主要目标：

确定每个引擎的总体性能
（标记为 W 代表引擎 A、X 代表引擎 B、Y 代表引擎 C）
计算所有三个引擎的综合总体性能
（标记为 Z）。

数据详细信息：每个引擎都有不同数量的数据点（例如，引擎 A 有 3 个数据点，引擎 B 有 12 个，等等）。
以下是有关引擎 A 数据的表格（插图）：

其中 %Efficiency 计算如​​下：

这是回答我的第二个目标 (Z) 的预期表格

我得到的部分困惑：

对于 W、X 和 Y（单个引擎性能）：

方法 1：通过直接平均计算 %Efficiency。
方法 2：将数据点产生的总燃料和电力相加，然后计算新的组合 L/kWh 并使用它来计算 %Efficiency。


对于 Z（所有引擎的整体性能）：

方法 1：与上文相同
方法 2：与上文相同
方法 3：计算 %Efficiency 的加权平均值，其中每个引擎的权重基于其数据点数量。



我的问题：

对于 W、X 和 Y，哪种方法是正确的，为什么？
对于 Z，哪种方法是正确的，为什么？

注意：你能不能解释得简单点，因为我不是统计学或数学专业的学生 :&#39;)]]></description>
      <guid>https://stats.stackexchange.com/questions/657251/how-to-average-engine-performance-direct-or-weighted</guid>
      <pubDate>Thu, 14 Nov 2024 13:58:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么数据引导可以修改来自同一分布的总体的斜率？</title>
      <link>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</link>
      <description><![CDATA[我正在引导一些样本来计算斜率（带替换）。一旦完成，应该具有相同分布的斜率就不会具有相同的分布。
这是 R 中可重现的代码：
N &lt;- 3000
x &lt;- runif(N,0,1)*5
y &lt;- x + rnorm(N, 1, .2)
y2 &lt;- x + rnorm(N, 1, .2)
t.test(y,y2)
dummy &lt;- rep(c(TRUE,FALSE),each = N)
df &lt;- data.frame(x = c(x,x), y = c(y,y2), dummy = dummy)

boot_strap &lt;- function(data, n_bootstraps){
output &lt;- sapply(1:n_bootstraps, function(i){
tmp &lt;-数据[sample(seq_len(nrow(data)), nrow(data), replace = TRUE),]
model &lt;- lm(y ~ x, data = tmp)
return(coef(model)[2])})
return(output)

for (size in c(1e2, 2e2, 5e2, 1e3, 1e4)){
sample_1 &lt;- boot_strap(df[df$dummy == TRUE,], size)
sample_2 &lt;- boot_strap(df[df$dummy == FALSE,], size) 
print(paste0(&#39;Size: &#39;, size,&#39; - Pvalue: &#39;, t.test(sample_1, sample_2)$p.value))
#print(paste0(&#39;Size: &#39;, size,&#39; - Pvalue: &#39;, ks.test(sample_1, sample_2)$p.value))

数据：

这里我们没有差异，因为来自同一人群（如第一个 T 检验所示）是预期的
但另一方面，斜率的分布明显不同。

我的偏见在哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</guid>
      <pubDate>Thu, 14 Nov 2024 13:56:47 GMT</pubDate>
    </item>
    <item>
      <title>我使用 DESeq2 进行的时间过程分析有效吗？</title>
      <link>https://stats.stackexchange.com/questions/657249/is-my-time-course-analysis-with-deseq2-valid</link>
      <description><![CDATA[作为一名纯行为生态学家，我偶然进入了基因表达分析领域，并且是基因表达分析的新手，我请求帮助验证我的模型是否适合我想要进行的分析类型。我一直在阅读 DESeq2 手册，并试图找出分析数据的正确方法。
我的实验是关于在面临病原体感染的蚂蚁中发现差异基因表达，因此我有三个时间点（时间：0、1、2）和一个条件（治疗：对照、感染）的样本。我正在使用来自共享原始巢穴的菌落片段来处理所有时间点的两种情况，这意味着我应该控制模型的批次效应（原始巢穴，在模型中作为复制）。
我按照以下方式进行分析：
dds &lt;- DESeqDataSetFromMatrix(countData = tempdf,
colData = sfile,
design=~ Replicate + Treatment + Time + Treatment:Time)
dds &lt;- DESeq(dds)

使用对比，我想特别关注时间点 1 和时间点 2 的差异表达，这是我从交互项 Treatment:Time 中获得的
resT1 &lt;- results(dds, name=&quot;TreatmentInfected.Time1&quot;, test = &quot;Wald&quot;)
resT2 &lt;- results(dds, name=&quot;TreatmentInfected.Time2&quot;, test=&quot;Wald&quot;)

我不太清楚我是否应该使用这些类型的比较，或者是否应该包含一个带有 LRT 测试的简化模型，或者交互模型是否是正确的选择。
这些模型的结果似乎合乎逻辑，与快速粗略地查看表达计数非常一致，并且以相当高的准确度找到与 EdgeR 尝试相同的差异表达基因（但是由于某种原因，我无法让批量效应在那里发挥作用）。
如果有人对我的方法是否正确或者我是否应该修改我的模型并采取另一种方法发表评论，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/657249/is-my-time-course-analysis-with-deseq2-valid</guid>
      <pubDate>Thu, 14 Nov 2024 13:12:15 GMT</pubDate>
    </item>
    <item>
      <title>比较两个具有相同数量观测值且均值相同但方差不同的样本</title>
      <link>https://stats.stackexchange.com/questions/657248/comparing-two-samples-with-same-number-of-observations-and-having-same-mean-but</link>
      <description><![CDATA[假设两个不同的数据集样本具有相同的平均值和相同的观测值数量；如果它们的方差相同，可以得出什么结论？如果两个方差不同，可以得出什么结论？
测试问题中只写了这些，没有更详细的信息。问题不是英文的，所以我尽力翻译了。我不知道这是什么意思，但它似乎是在询问方差差异在比较两个不同样本时的影响的一般信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/657248/comparing-two-samples-with-same-number-of-observations-and-having-same-mean-but</guid>
      <pubDate>Thu, 14 Nov 2024 12:44:50 GMT</pubDate>
    </item>
    <item>
      <title>是否存在类似 Z 分数但适用于高度偏斜分布的东西？</title>
      <link>https://stats.stackexchange.com/questions/657246/is-there-something-like-z-score-but-for-highly-skewed-distributions</link>
      <description><![CDATA[我正在分析我的 anki 评论回答时间。由于我有大量数据（超过 14 年），评论之间存在差距，不同的学习模式也不同，所以我想以群组形式进行分析。
我想创建的一个指标是我对答案的“信心”：我想知道“与典型情况相差多远”特定答案是，但我想要一个可以在群组之间一致使用的指标（并在它们之间进行比较）。
我在一个类似的问题上找到了这个答案，它建议使用百分位数，但我认为百分位数并不能完全满足我的需求 - 有些群组的典型回答时间接近中位数，但也有一些群组远离中位数。
我可以使用例如 (值 - 模式) / 分位数间范围 作为我的指标吗？或者我可以使用类似的东西吗？
我知道我的回答时间严重右偏。]]></description>
      <guid>https://stats.stackexchange.com/questions/657246/is-there-something-like-z-score-but-for-highly-skewed-distributions</guid>
      <pubDate>Thu, 14 Nov 2024 12:25:53 GMT</pubDate>
    </item>
    <item>
      <title>混合分布的过程能力</title>
      <link>https://stats.stackexchange.com/questions/657243/process-capability-with-mixture-distributions</link>
      <description><![CDATA[我需要进行过程能力分析，但我的过程通常不呈正态分布。我使用了非参数方法，但我的客户使用基于混合分布的过程能力计算。使用混合分布作为分析过程能力的基础是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/657243/process-capability-with-mixture-distributions</guid>
      <pubDate>Thu, 14 Nov 2024 11:33:12 GMT</pubDate>
    </item>
    <item>
      <title>Ljung-Box 检验的自由度</title>
      <link>https://stats.stackexchange.com/questions/657242/degrees-of-freedom-for-ljung-box-test</link>
      <description><![CDATA[对于不同 AR(p) 模型中残差的 Ljung-Box 检验的自由度，我有两个问题：
对于具有非连续滞后的模型：据我了解，必须从要测试的滞后数 (l) 中减去估计参数数 (k) 才能获得正确的自由度。通常，k 等于 p。现在，例如，如果我有一个 AR(4) 模型，其中只有 2 个 AR 系数而不是 4 个，那么我只估计 2 个参数。我应该取哪个值？4 还是 2？
对于具有结构突变的模型：如果存在结构突变，则可以通过二元交互项等改进模型。然后必须估计这些模型参数。它们是否也包含在 k 值中？]]></description>
      <guid>https://stats.stackexchange.com/questions/657242/degrees-of-freedom-for-ljung-box-test</guid>
      <pubDate>Thu, 14 Nov 2024 09:56:42 GMT</pubDate>
    </item>
    <item>
      <title>堆叠解决非常严重的类别不平衡问题</title>
      <link>https://stats.stackexchange.com/questions/657241/stacking-for-very-high-imbalanced-class-problem</link>
      <description><![CDATA[背景：我面临一个 1：40 000 类不平衡问题。
这是一个二元分类问题，正类大约有 500-700 个实例，负类有数千万个实例。
我读过其他几个问题、参考资料等：
具有强烈不平衡类的二元分类
https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/
https://datascience.stackexchange.com/questions/61733/class-imbalance-and-cost-sensitive-learning-xgboost
类别不平衡问题的根本原因是什么？
以及其他等等...
根据这些参考资料，我尝试了几种方法（还有更多）：

欠采样/过采样：
我将数据欠采样到 10:1，性能从 0.1% 的精度提高到 ~1-5%（对于高度不平衡的问题，这相当不错从绝对数字来看，效果不错，尤其是因为我的数据有几千万）。召回率也从 0.1% 上升到了 ~5-10%。

使用几个通常针对类不平衡进行调整的超参数进行调整：
在大多数学习算法（XGB、CatBoost、LGBM）中，调整 scale_pos_weight、min_child_weight、max_delta_step 特别“棒” （但结果仍与上文相同）。

使用目标函数进行调整：
使用对成本敏感的函数，例如 logloss 和 AUC

特征工程和选择：
33 个基础/原始特征，工程化为 142 个。从前 10 个特征中，只有 2 个基础特征具有较高的 SHAP 值（参见：https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/bar.html）。

进一步的特征选择：
我还使用了基于 scikit-learn 指南的 VarianceThreshold 和基于树的特征选择（https://scikit-learn.org/1.5/modules/feature_selection.html)

堆叠：
我在 XGBoost 中构建了数百个基础学习器，每个都使用不同的超参数进行训练（基本上，使用 numpy.random 围绕一些合理的值进行调整），使用不同的负类集（即在每轮训练中使用不同的种子对多数类进行欠采样），使用不同的训练特征集（即从我的 142 个特征中随机选择一定数量的特征，尽管我总是根据 SHAP 保留前 8 个特征）。然后我平均每个学习者的predict_proba，并将最终概率阈值设置为99.9％。


现在，最佳模型（在我结合上述所有方法之后）的召回率为20-30％，准确率为5-10％。目标是50％的召回率和50-90％的准确率。
接下来我想尝试的是：
使用我从第6点训练的数百名学习者（在训练每个基础学习者时牢记第1-5点），我将在我的训练集上应用model.predict_proba。
然后，我将使用predict_proba的值（来自数百名基础学习者）作为特征来训练最终模型，在同一训练集上。这个想法是，我不会对所有基础学习器的 predict_proba 进行平均（权重相同），而是让最终模型决定每个基础学习器的权重。
我想问问大家，上述想法是否有意义？

会不会有数据泄露问题？（因为我在 train_set 上训练了每个基础学习器。然后要求它预测相同的 train_set。然后使用此输出在 train_set 上训练最终模型）。

你认为，如果我训练 100 个 CatBoost、100 个 XGBoost 和 100 个 LGBM，然后基于总共 300 个 predict_proba 输出训练神经网络，这也有意义吗？我读到过一些模型堆叠架构这样做，但我不确定这是否是一种广泛使用的做法？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657241/stacking-for-very-high-imbalanced-class-problem</guid>
      <pubDate>Thu, 14 Nov 2024 09:35:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么高斯过程回归（GPR）是非参数的？</title>
      <link>https://stats.stackexchange.com/questions/657239/why-gaussian-process-regression-gpr-is-non-parametric</link>
      <description><![CDATA[鉴于高斯过程 (GP) 回归依赖于具有特定超参数的核来控制点之间的关系和平滑度，GP 回归真的可以被视为非参数技术吗？我有以下几点。

GP 的行为在很大程度上取决于核的参数结构，这限制了函数形式与某些假设（例如平滑度、周期性）的一致性。这使其成为由超参数控制的确定性过程，而不是固有灵活的无参数模型。

与任何参数技术（例如 DFT 或 AR 模型）一样，随着数据量的增长，GP 可以更精确地估计更适合数据的超参数。这种数据改进可以被认为类似于减少参数估计中的次优性，而不是反映开放的无参数结构。此外，从后验分布中绘制多个函数的能力（如使用抽样或引导方法的参数模型）并不意味着非参数模型。

虽然每个 GP 实现都代表一个潜在函数，但它们都遵循由内核建立的底层规则，该规则有效地控制了样本拟合观察到的数据的方式。因此，仅仅因为函数形式不是完全可预测而将 GP 标记为非参数可能是不准确的，因为内核参数化并限制了 GP 灵活性。


总之，由于内核作为指导模型行为的明确参数化结构的作用，GP 回归不应该被视为参数方法吗？在我看来，它确实是一个参数核估计器，当与贝叶斯框架一起使用时，会产生后验预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/657239/why-gaussian-process-regression-gpr-is-non-parametric</guid>
      <pubDate>Thu, 14 Nov 2024 06:48:07 GMT</pubDate>
    </item>
    <item>
      <title>多层次建模中的 CWC(M)</title>
      <link>https://stats.stackexchange.com/questions/657237/cwcm-in-multilevel-modeling</link>
      <description><![CDATA[我是多层次建模的新手，最近了解了 Zhang 等人的 CWC(M)（2009 年，https://journals.sagepub.com/doi/abs/10.1177/1094428108327450）。我正在运行一个多级调节中介模型（第 1 级调节、第 2 级调节、跨级交互）。
即使阅读了本文和相关文章（https://journals.sagepub.com/doi/full/10.1177/10944281211060712），我仍然对如何使用 CWC(M) 感到困惑。例如，它应该在人内（第 1 级）和/或人间（第 2 级）分析级别使用吗？如何在 R 或 Mplus 中创建这种类型的中心化？任何建议都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657237/cwcm-in-multilevel-modeling</guid>
      <pubDate>Thu, 14 Nov 2024 05:40:31 GMT</pubDate>
    </item>
    <item>
      <title>当数据集中存在 NA 时，predict() 函数对 R 中的 lmer 不起作用</title>
      <link>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</guid>
      <pubDate>Wed, 13 Nov 2024 23:28:54 GMT</pubDate>
    </item>
    <item>
      <title>木材分解</title>
      <link>https://stats.stackexchange.com/questions/657223/wold-decomposition</link>
      <description><![CDATA[考虑一个 AR(p) 过程
$$
Y_t=\phi_1Y_{t-1}+\ldots+\phi_pY_{t-p}+u_t
$$
在某些情况下，该过程允许 $MA(\infty)$ 表示
$$
Y_t=\sum_{k=0}^\infty\psi_ku_{t-k}
$$
为什么这个等式成立？
$$
\sum_{k=0}^{\infty} \psi_k = \frac{1}{1-\sum_{i=1}^{p}\phi_{i}}
$$
另请参阅 AR(p) 模型的自协方差总和]]></description>
      <guid>https://stats.stackexchange.com/questions/657223/wold-decomposition</guid>
      <pubDate>Wed, 13 Nov 2024 20:15:45 GMT</pubDate>
    </item>
    </channel>
</rss>