<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 03:17:14 GMT</lastBuildDate>
    <item>
      <title>成对回归与个体回归之间的关系</title>
      <link>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</link>
      <description><![CDATA[我想在成对回归和线性回归之间建立联系。我将在下面用一个例子解释成对回归和线性回归的含义，但这个例子只是为了解释我想做什么。
考虑这样一个场景：一所高中有 5 个教室，每个教室有 10 名学生。为简单起见，假设同一个教室里的每个人都互相认识，但不认识其他教室里的任何人。当学生毕业时，他们会决定去哪个州上大学。
我感兴趣的是，在同一个教室里的学生是否更有可能去同一个州上大学。为此，我为所有 50 名学生创建了一个学生对，结果有 50C2 = 1225 对。对于每一对，我可以构建一个指示变量 classmate，如果该对中的两个学生在同一个班级，则该变量等于 1；如果两个学生都去同一个州上大学，则该变量等于 1。
然后，我可以运行回归分析，将 same_college 与 classmate 进行回归，并将 comove 前面的系数解释为同学们去同一个州上大学的额外倾向。这就是我所说的成对回归。
但请注意，50 名学生创建了 1225 对。当样本变大时，这种情况很快就会失控。此外，我没有通过将数据集从个人级别转换为成对级别来插入任何新数据；这只是数据集的转换。**此外，这只研究一个学生如何影响该对中的另一个学生。它忽略了 3 组或更多组学生可能对决策产生不同于仅构建学生对的任何可能性。
问题：我想知道我是否可以从成对回归中检索相同的系数，而无需将数据集转换为成对级别。我很难弄清楚我可以在个体级别上运行的回归是什么，它将与成对级别的系数相匹配。
** 我相信这是一个双射变换，但如果不是，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</guid>
      <pubDate>Sat, 20 Jul 2024 02:47:30 GMT</pubDate>
    </item>
    <item>
      <title>分类独立变量</title>
      <link>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</link>
      <description><![CDATA[我正在开展一项回顾性研究，有一些分类独立变量，我的结果变量也是分类变量。我想知道具有多个分类独立变量的卡方检验是否是最佳模型。你能帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</guid>
      <pubDate>Sat, 20 Jul 2024 02:22:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算所需样本量以实现所需的假阴性率</title>
      <link>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</link>
      <description><![CDATA[我正在尝试设计一个进行二元分类的系统。假阴性的成本很高，所以我想确保我已经进行了足够彻底的测试，以尽量减少这种可能性。我希望系统的假阴性率小于 1%，确定性为 95%。如果我预计真阳性率很小（大约 2%），我应该如何计算达到这一置信度所需的人口规模？ 单侧检验程序是此处适用的正确方程吗？
$$
N \geq \left ( \frac{z_{1-\alpha} \sqrt{p_0(1-p_0)} + z_{1-\beta} \sqrt{p_1(1-p_1)}}{p_1-p_0} \right ) ^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</guid>
      <pubDate>Sat, 20 Jul 2024 01:48:58 GMT</pubDate>
    </item>
    <item>
      <title>在 FDR 之前过滤单侧检验</title>
      <link>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</link>
      <description><![CDATA[在这篇博文中，作者展示了一个“奇怪”的例子p 值直方图（“场景 C”）：

一种解释是，进行了单侧检验，而效果相反的检验给出的 p 值接近 1。他的建议是在计算 FDR 之前根据效果方向过滤掉检验。
但是，我知道，如果过滤方式不正确，在计算 FDR 之前进行预过滤可能会出现问题，例如讨论过的那样这里，当我们查看结果时，感觉按效果方向过滤是“作弊”。
现在，如果我在 R 中运行快速模拟（如下所示），过滤会导致 p 值分布在 0 到 0.5 之间，因此 p 值在 0 和 1 之间均匀的假设不再有效。那么，在计算 FDR 之前根据效果方向进行过滤是否正确？
此外，从经验上看我模拟中的 FDR 和功效，如果我在 p.adjust() 中指定测试总数，似乎我可以保持正确的 FDR 控制，同时仍获得一点功效。这是正确的做法吗？
模拟
set.seed(1)

## 生成数据 ----
real_means &lt;- c(
rep(0, 1000), # 无影响
runif(200, -1, 0), # 减少
runif(200, 0, 1) # 增加
)
labels &lt;- c(
rep(&quot;none&quot;, 1000),
rep(&quot;decreased&quot;, 200),
rep(&quot;increased&quot;, 200)
)

samples &lt;- lapply(real_means, \(mu) rnorm(30, mu, sd = 1))

## 计算 p 值和 fdr ----
p_values &lt;- sapply(samples, \(x) t.test(x, alternative = &quot;greater&quot;)$p.value )
p_values &lt;- setNames(p_values, labels)

hist(p_values, breaks = 70)




fdr &lt;- p.adjust(p_values, method = &quot;BH&quot;)

## 检查结果 ----
false_positives &lt;- sum( fdr[names(fdr) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( fdr &lt; 0.05 )
true_positives &lt;- sum( fdr[names(fdr) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(fdr) == &quot;increased&quot; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.01234568

# 真正率
true_positives / positives
#&gt; [1] 0.4

## 带过滤 ----

direction_increasing &lt;- sapply(samples, \(x) mean(x) &gt;= 0 )

filtered_p_values &lt;- p_values[ direction_increasing ]

hist(filtered_p_values)



filt_fdr &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot; )

false_positives &lt;- sum(filt_fdr[names(filt_fdr) != &quot;increased&lt;] &lt; 0.05 )
predicted_positives &lt;- sum(filt_fdr &lt; 0.05 )
true_positives &lt;- sum(filt_fdr[names(filt_fdr) == &quot;increased&lt;] &lt; 0.05 )
positives &lt;- sum(names(filt_fdr) == &quot;increased&lt; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.04301075

# 真正率
true_positives / positives
#&gt; [1] 0.4863388

## 带过滤，但指定测试总数 ----

filt_fdr_with_n &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot;, n = length(p_values) )

false_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( filt_fdr_with_n &lt; 0.05 )
true_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(filt_fdr_with_n) == &quot;increased&quot; )

# 错误发现率
false_positives / predictive_positives
#&gt; [1] 0.01234568

# 真阳性率
true_positives / positives
#&gt; [1] 0.4371585

于 2024-07-19 使用 reprex v2.1.0 创建]]></description>
      <guid>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</guid>
      <pubDate>Fri, 19 Jul 2024 22:21:49 GMT</pubDate>
    </item>
    <item>
      <title>证明 $T$ 是一个完全统计量，并找到 $p$ 的 UMVUE [重复]</title>
      <link>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</link>
      <description><![CDATA[在准备预赛时，我遇到了这个问题：
设$X_1, X_2,\cdots, X_n$为伯努利试验序列，$n \geq 4.$已知，$X_1,X_2,X_3 \stackrel{\text{i.i.d.}}{\sim} Ber(\frac12),$且对于$4\leq i \leq n,$ $P(X_i=X_{i-1}|X_1,\cdots,X_{i-1})=1-p,$ $p \in (0,1).$ 考虑 $T:=\sum_{i=4}^n |X_i-X_{i-1}|$。$T$ 是否完整？因此（否则），找到 $p$ 的 UMVUE。
到目前为止，我所能证明的只是 $S:=\frac{T}{n-3}$ 对于 $p$ 是无偏的。如果我能进一步证明 $T$ 对于 $p$ 是完全充分的，那么 $S$ 将是 UMVUE，由 Lehmann-Scheffe 提出。我如何证明 $T$ 是完全的？我没能找到 $E[f(T)],$ 的简洁表达式，其中 $f$ 是 Borel 可测的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</guid>
      <pubDate>Fri, 19 Jul 2024 20:46:19 GMT</pubDate>
    </item>
    <item>
      <title>有人可以给我举一个概率分布的例子及其符号吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/651429/can-someone-give-me-an-example-of-what-a-probability-distribution-looks-like-and</link>
      <description><![CDATA[什么是随机变量 X 的概率分布？概率分布的典型符号是什么？
有人能给我举个概率分布的例子吗？它的符号是什么样的？]]></description>
      <guid>https://stats.stackexchange.com/questions/651429/can-someone-give-me-an-example-of-what-a-probability-distribution-looks-like-and</guid>
      <pubDate>Fri, 19 Jul 2024 20:45:09 GMT</pubDate>
    </item>
    <item>
      <title>xtreg 和 reghdfe 之间的区别</title>
      <link>https://stats.stackexchange.com/questions/651427/difference-between-xtreg-and-reghdfe</link>
      <description><![CDATA[当我尝试在 Stata 中使用以下命令设置面板数据时
xtset familyid MatricYear

我收到以下错误
面板内重复的时间值
r(451);

但是当我直接运行 reghdfe 时，没有错误。所以我的问题是，我将在 xtset 之后使用 xtreg 进行固定效应回归。但它不会运行，因为我无法设置 xtset。但 reghdfe 完全忽略了这一点。为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651427/difference-between-xtreg-and-reghdfe</guid>
      <pubDate>Fri, 19 Jul 2024 20:15:18 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊卡方和相关性</title>
      <link>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</link>
      <description><![CDATA[我的数据是有序的
Pearson 卡方检验值为 4.664
并且不对称 sig 为 0.97，因此数据是独立的
但是 pearson 的 R =-0.309
并且近似 sig=0.037
它们可以同时独立和负相关吗]]></description>
      <guid>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 20:13:56 GMT</pubDate>
    </item>
    <item>
      <title>如何预测变换后的时间序列数据？</title>
      <link>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</link>
      <description><![CDATA[我有包含趋势和季节性成分的时间序列数据。我使用以下方法从数据中删除了这些成分：
x &lt;- data[,2]

n &lt;- length(x)

t &lt;- 1:n

Z_fixed &lt;- cbind(t, sin(2*pi*t/52), cos(2*pi*t/52))

data$trend_fixed &lt;- lm(x ~ Z_fixed)$fitted.values

data$x_fixed &lt;- x - data$trend_fixed

然后我能够使用平稳数据拟合 ARMA(1,1) 模型。
我现在想预测 n 步。我知道 predict() 函数采用转换后的模型，并且我相信新的平稳 x 值 (data$x_fixed)，但我不知道在哪里应用原始趋势/季节性转换以使预测变得非平稳？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</guid>
      <pubDate>Fri, 19 Jul 2024 20:05:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在多项回归中找到 $p_k$ 的边际分布</title>
      <link>https://stats.stackexchange.com/questions/651424/how-to-find-the-marginal-distribution-of-p-k-in-multinominal-regression</link>
      <description><![CDATA[给定多项式回归，某个类$k$的概率是预测因子的函数。假设我们知道 ${\bf X}_i$ 的分布，那么我们如何通过分析找到 $p_k$ 的边际概率
多项式回归作为对数线性模型：
$$
\text{ln Pr}(Y_i = k) = \beta_k \cdot{\bf X}_i - \text{ln} Z 
$$
$$
Z = \sum_{k=1}^K e^{\beta_k\cdot{\bf X}_i}
$$
$$
\text{Pr}(Y_i = k) = \frac{e^{\beta_k \cdot{\bf X}_i}}{\sum_{k=1}^K e^{\beta_k\cdot{\bf X}_i}} 
$$
我们还可以将多项式回归指定为具有参考类别的对数概率。不确定哪种方法更容易进行分析。
一个预测变量和 3 个类的示例：
$$
X_i \sim Norm(0,1)
$$
$$
\beta_1 = a, \beta_2 = b, \beta_3 = c
$$
$$
Pr(Y_i = k) = \frac{e^{\beta_k \cdot X_i}}{e^{\beta_1 \cdot X_i} + e^{\beta_2 \cdot X_i} + e^{\beta_3 \cdot X_i}}
$$
有什么解决这个问题的技巧吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651424/how-to-find-the-marginal-distribution-of-p-k-in-multinominal-regression</guid>
      <pubDate>Fri, 19 Jul 2024 19:46:46 GMT</pubDate>
    </item>
    <item>
      <title>模型具有更高的（且更接近 1）$\beta$，但 $R^2$ 和相关性相似</title>
      <link>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</link>
      <description><![CDATA[我有一个模型，它产生预测$\hat{y_1}$，后来我又想出了一个新模型，它产生预测$\hat{y_2}$。我有基本事实$y$。 这些模型不是基于回归的，但它们是线性的，我想在回归指标中对它们进行评估。
如果我运行$y \sim \beta_1 \hat{y_1}$、$y \sim \beta_2 \hat{y_2}$，我会看到$\beta_2 \sim 1$和$\beta_1 \sim 0.8$。我认为这意味着我的模型 2 “缩放得更好”。
但如果我直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$ 和 $R2(y, \hat{y_2}) = 1- \frac{\sum (y_t - \hat{y_2}_t )^2 }{\sum y_t^2}$（因为我不会尝试重新运行回归 $y \sim \beta_1 \hat{y_1}$ 并得到回归 R2。我只是直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$)。我发现它们大致相等。
当我计算 $y$ 和 $\hat{y_1}$ 之间的相关性以及 $y$ 和 $\hat{y_2}$ 之间的相关性时，我发现它们也几乎相等。请注意，这里的相关性可能不是 R2 的平方根，因为我的模型不是基于回归的。
它告诉了我关于预测的什么？我觉得有点惊讶。我认为“更好的规模”预测因子应该出现在回归指标的某个地方吗？为什么“更好的尺度”回归没有给我更好的 R2？]]></description>
      <guid>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 19:10:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的卡方检验的 p 值这么高？</title>
      <link>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</link>
      <description><![CDATA[我从值 = [0, 1] 中抽样，概率 = [.25, .75]。
我得到 25019 个零和 74981 个一。然而，通过卡方检验结果如下：
statistic=0.0196，pvalue=0.889
这似乎与我的直觉不符。
也许这是使用 Fisher 精确检验的原因？我应该使用 KS 测试来获取频率吗？
这是我的代码
N = 100000
values = [np.random.choice([0, 1], p=[.25, .75]) for _ in range(N)]
one_count = sum(values)
zero_count = len(values) - one_count
test_stat = (N*.75 - one_count)**2/(N*.75) + (N*.25 - zero_count)**2/(N*.25)
print(test_stat, 1 - stats.chi2.cdf(test_stat, 1))
]]></description>
      <guid>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</guid>
      <pubDate>Thu, 18 Jul 2024 22:58:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么第一个主成分的特征值比其余主成分高得多？</title>
      <link>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-much-higher-tha</link>
      <description><![CDATA[我有 16 个水质参数的时间序列，在使用 zscore 方法对其进行标准化后，我进行了主成分分析。这些是我的特征值 [7.62675203795075
2.25806327090482
1.72428547604366
1.44517173004117
1.30223669986535
1.18683140226834
1.01121663757535
0.840810909788259
0.68 3733271693109
0.641289626275986
0.427483271093487
0.367733123021385
0.243180116969796
0.216284282138318
0.132868635217870
0.0705244464795644]。

可以看到，第一个主成分的特征值和其余主成分相差很大，这是我在以前的研究中没有见过的，而且是随着间隔变小而减小的。是什么因素导致了结果这样？是不是我的数据不适合做主成分分析？我还做了KMO检验，结果是0.91。]]></description>
      <guid>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-much-higher-tha</guid>
      <pubDate>Thu, 18 Jul 2024 21:47:30 GMT</pubDate>
    </item>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个模型开始，该模型以温度作为三次多项式，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$）和国家增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
我使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
样本外预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了一个具有更高次数多项式时间趋势的不同模型，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
样本外预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系更大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致样本外预测区间更接近 95% 的目标，同时增加模型的样本外 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的样本外预测区间换取随后的样本外 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>在验证性因子分析中将权重固定为 1 - 如何获得重要性 (p) 值？</title>
      <link>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</link>
      <description><![CDATA[我有一个与此主题有些相关的问题。
我现在明白了为什么在验证分析中应该将 1 的值固定到其中一条路径上，我也明白可以使用各种技巧来释放这个参数。但我感兴趣的问题是，如何用标准化解决方案计算固定路径到 1 的统计显著性。
让我们考虑一个来自这里的例子，我将使用 R 中的 Lavaan 包的示例。
library(lavaanPlot)
library(foreign) 
library(lavaan)

dat &lt;- read.spss(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2018/05/SAQ.sav&quot;, to.data.frame=TRUE, use.value.labels = FALSE)

m1a &lt;- &#39; f =~ q03 + q04 + q05&#39;
onefac3items_a &lt;- cfa(m1a, data=dat) 
summary(onefac3items_a) 

这里，正如您在摘要中看到的，没有统计意义，因为路径 f~q03 是固定的。
潜在变量：
估计 Std.Err z 值 P(&gt;|z|)
f =~ 
q03 1.000 
q04 -1.139 0.073 -15.652 0.000
q05 -0.945 0.056 -16.840 0.000

摘要相同标准化：
summary(onefac3items_a,standardized=TRUE)
(...)

潜在变量：
估计 Std.Err z 值 P(&gt;|z|) Std.lv Std.all
f =~ 
q03 1.000 0.583 0.543
q04 -1.139 0.073 -15.652 0.000 -0.665 -0.701
q05 -0.945 0.056 -16.840 0.000 -0.551 -0.572

但是，当使用标准化解决方案函数时，我得到了 p 值。怎么回事，为什么？这怎么可能呢？
standardizedsolution(onefac3items_a)
lhs op rhs est.std se z pvalue ci.lower ci.upper
1 f =~ q03 0.543 0.022 25.120 0 0.500 0.585
2 f =~ q04 -0.701 0.024 -29.710 0 -0.747 -0.655
3 f =~ q05 -0.572 0.022 -26.105 0 -0.615 -0.529

同样，当我使用 plot 时，我得到了显著性星号。
lavaanPlot(model = onefac3items_a, coefs=T, covs=T, stars = c(&quot;covs&quot;,&quot;latent&quot;,&quot;regress&quot;), stand=T)

我不完全理解这种机制。为什么一条固定的、没有计算系数的路径突然与标准化解具有统计意义？这里用了什么方法？是不是程序只是改变了固定路径的位置，例如，我们暂时将路径 f~q04 固定为 1 来计算 f~q03 的系数，还是方法完全不同？
附加问题：AMOS 中可以实现相同的效果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</guid>
      <pubDate>Thu, 18 Jul 2024 19:36:32 GMT</pubDate>
    </item>
    </channel>
</rss>