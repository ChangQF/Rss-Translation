<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Feb 2025 09:18:23 GMT</lastBuildDate>
    <item>
      <title>适合小样本量的对称高斯混合？</title>
      <link>https://stats.stackexchange.com/questions/660979/fit-symmetrical-gaussian-mixture-with-small-sample-size</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660979/fit-symmetrical-gaussian-mixture-with-small-sample-size</guid>
      <pubDate>Wed, 05 Feb 2025 07:11:11 GMT</pubDate>
    </item>
    <item>
      <title>对对称高斯分布的每个点分别重新采样？</title>
      <link>https://stats.stackexchange.com/questions/660978/re-sample-each-point-of-symmetrical-gaussian-distribution-individually</link>
      <description><![CDATA[我尝试从高斯分布中扩展 N 个点的样本 $X$，将每个点视为正态分布 $N(0, \sigma=abs(x_i))$，并从中抽取 100 个点。
因此“平滑”并将原始样本 N 扩展为 100*N。
问题是 - 得到的样本看起来不像原始样本，甚至看起来不像正常样本（黑色原始样本，红色重新采样直方图）：）。

但是，我想知道是否有办法对高斯样本的每个点单独$N(0, \sigma=f(x_i))$进行重新采样，以使得到的分布与原始分布相同？是否存在这样的$f$？
注意 - 我们知道分布是对称的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660978/re-sample-each-point-of-symmetrical-gaussian-distribution-individually</guid>
      <pubDate>Wed, 05 Feb 2025 06:48:19 GMT</pubDate>
    </item>
    <item>
      <title>回归可以应用于网络吗？</title>
      <link>https://stats.stackexchange.com/questions/660977/can-regression-be-applied-to-networks</link>
      <description><![CDATA[我有一个如下所示的图形网络。没有新节点可以出现，也没有现有节点可以消失。此外，不会出现新的边，也不会消失现有的边：

此网络中的每个节点都有在不同时间记录的多个测量值，例如
 node subgraph total_nodes_in_subgraph first_degree_neighbors number_of_first_neighbors time y x1
1 A 3 2,3 1 1 26.788488 -0.06136412
1 A 3 2,3 1 4 10.834021 -6.20129015
1 A 3 2,3 1 9 1.555070 5.76456306
2 A 3 1,3 1 1 4.171894 1.71324788
2 A 3 1,3 1 10 14.494354 11.93502071
3 A 3 1,2 2 1 7.002672 6.68514794

在这种情况下，是否有可能在此图网络结构上拟合随机效应回归模型？
我尝试编写模型，其中节点 $i$ 在时间 $t$ 的响应受到其一度邻居、同一子图中的邻居和其他网络的影响属性：
$$ y_{it} = \beta_0 + \beta_1x_{it} + \beta_2N_i + \beta_3S_​​i + \beta_4t + \beta_5\left(\frac{1}{N_i}\sum_{j \in \mathcal{N}i} x{jt}\right) + u_i + c_{ij} + v_g + w_t + \epsilon_{it} $$
其中：

$y_{it}$ 是节点 $i$ 在时间 $t$ 的结果

$\beta_0$ 是截距项

$x_{it}$ 表示随时间变化的预测变量，其系数为 $\beta_1$

$N_i$ 是一级邻居的数量，其系数为 $\beta_2$

$S_i$ 是子图中的总节点数，其系数为 $\beta_3$

$t$ 是时间变量，其系数为 $\beta_4$

$\mathcal{N}_i$ 表示与节点 i 相邻的节点集

$\frac{1}{N_i}\sum_{j \in \mathcal{N}i} x{jt}$ 是来自相邻节点的协变量值的平均值

$\beta_5$ 测量邻居的协变量对节点 i 响应的影响程度

$u_i$ 是节点特定的随机效应，其中 $u_i \sim N(0, \sigma^2_u)$

$c_{ij}$ 是节点 $i$ 和 $j$ 之间连接的随机效应，其中 $c_{ij} \sim N(0, \sigma^2_c)$

$v_g$ 是子图特定的随机效应，其中 $v_g \sim N(0, \sigma^2_v)$

$w_t$ 是时间特定的随机效应，其中 $w_t \sim N(0, \sigma^2_w)$

$\epsilon_{it}$ 是误差项，其中 $\epsilon_{it} \sim N(0, \sigma^2_\epsilon)$


这是将回归应用于图网络的合适方法吗？
结束语：

我认为我需要添加一些与随机效应相关的可识别性约束
在获取节点 $i$ 的邻居的平均协变量信息时，由于可以在不同时间测量节点，因此我考虑使用在节点 $i$ 被测量之前最近时间测量的 $i$ 邻居的协变量信息
]]></description>
      <guid>https://stats.stackexchange.com/questions/660977/can-regression-be-applied-to-networks</guid>
      <pubDate>Wed, 05 Feb 2025 03:29:59 GMT</pubDate>
    </item>
    <item>
      <title>GLMMadaptive 中零膨胀 Beta 负二项式的自定义密度函数</title>
      <link>https://stats.stackexchange.com/questions/660976/custom-density-function-for-zero-inflated-beta-negative-binomial-in-glmmadaptive</link>
      <description><![CDATA[我注意到，在 GLMMadaptive R 包的 hybrid_model 函数中，可以编写自定义密度函数。我正尝试为 零膨胀 beta 负二项式 (ZIBNB) 模型定义密度函数，并且有几个问题。
具体来说，我想知道该模型是否可以估计两组独立的固定效应。对于 beta 负二项式模型的计数分量，假设 r 是固定的，则需要估计 $\alpha$ 和 $\beta$。
如果模型有四个协变量，那么我希望估计 alpha 的四个参数和 beta 的四个参数。我意识到要包含一组额外的参数，我需要指定 n_phi，但是当我设置 n_phi &gt; 1，我遇到了与矩阵计算相关的错误。
有人遇到过类似的问题或对如何在此情况下正确指定多个固定效应有什么建议吗？任何建议都将不胜感激！
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660976/custom-density-function-for-zero-inflated-beta-negative-binomial-in-glmmadaptive</guid>
      <pubDate>Wed, 05 Feb 2025 02:22:49 GMT</pubDate>
    </item>
    <item>
      <title>如何匹配均值、方差和偏度</title>
      <link>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</link>
      <description><![CDATA[我正在分析一项政策对结果 y 的影响。但是，混杂因素 x 也可能影响 y，并在治疗组和对照组中显示不同的模式。
在对 y 运行组虚拟变量回归之前，我试图执行匹配方法来平衡治疗组和对照组。
我应该如何设置匹配以在混杂因素 x 的均值、方差和偏度上创建相似的治疗组和对照组？
数据看起来像
library(ggplot2)
library(sn)
set.seed(1)
x1 &lt;- rsn(n = 1000, xi = 3, omega = 3, alpha = 5) 
x2 &lt;- rsn(n = 1000, xi = 2, omega = 2, alpha = 0) 
df &lt;- data.frame(
x = c(x1, x2),
y = rnorm(2000),
group = rep(c(&quot;treated&quot;, &quot;control&quot;), each = 1000)
)
ggplot(df, aes(x = x, fill = group)) +
geom_density(alpha = 0.5) +
theme_minimal() 


提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</guid>
      <pubDate>Wed, 05 Feb 2025 00:00:03 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归的大 O 复杂度是多少？</title>
      <link>https://stats.stackexchange.com/questions/660970/what-is-the-big-o-complexity-of-poisson-regression</link>
      <description><![CDATA[我发现几个类似的问题提到了 O(n p2)，但没有一个问题引用了来源。有谁知道有哪篇文章提供了大 O 复杂度并证明了它的合理性？]]></description>
      <guid>https://stats.stackexchange.com/questions/660970/what-is-the-big-o-complexity-of-poisson-regression</guid>
      <pubDate>Tue, 04 Feb 2025 22:03:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准误差总是零</title>
      <link>https://stats.stackexchange.com/questions/660967/why-is-standard-error-always-zero</link>
      <description><![CDATA[假设，我想确定每次抛硬币时是否都是正面。所以我设计了一个实验，其中$N=5$。所以我抛了 5 次，得到了 5 次正面。
我想测量我的置信区间，所以我需要标准误差。
$\hat p=1$
$SE=0$
置信区间是$(1,1)$。
但直观上看这是胡说八道，对吧？我的信心难道不应该随着$N$的增加而增加吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660967/why-is-standard-error-always-zero</guid>
      <pubDate>Tue, 04 Feb 2025 21:12:38 GMT</pubDate>
    </item>
    <item>
      <title>AR 流程偏差和其他问题</title>
      <link>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</link>
      <description><![CDATA[我读过这篇文章：分析 ACF 和 PACF 图，评论中指出数据有左偏，这是 AR 过程的问题。
我想知道为什么这是一个问题，以及在时间序列上执行 ACF 图并得出该时间序列具有统计意义的自回归结论的一般条件是什么。
我的猜测是，偏斜意味着您有更多机会在分布的左侧拥有数据，因此您可能会发现虚假相关性？因为数据更有可能位于分布的同一侧，而如果偏斜为 0，情况就不是这样。
所以我的猜测是我们不希望时间序列的分布有任何不对称。因此，我会直观地说，要执行 AR 分析，以便我们可以以一定的统计意义说该过程是 AR，我们需要始终：$E[X^n]$ 当 $n$ 为奇数时等于 $0$。我的直觉正确吗？如果是，有办法证明吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</guid>
      <pubDate>Tue, 04 Feb 2025 19:37:09 GMT</pubDate>
    </item>
    <item>
      <title>实现扩散生成模型进行数据增强，但训练损失值太高</title>
      <link>https://stats.stackexchange.com/questions/660969/implementing-a-diffusion-generative-model-for-data-augmentation-but-training-los</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660969/implementing-a-diffusion-generative-model-for-data-augmentation-but-training-los</guid>
      <pubDate>Tue, 04 Feb 2025 16:56:25 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据的 Mann-Kendall 趋势分析</title>
      <link>https://stats.stackexchange.com/questions/660960/mann-kendall-trend-analyses-with-missing-data</link>
      <description><![CDATA[我需要分析 38 年来每年火灾严重程度的趋势。我的数据集从 1982 年延续到 2020 年；但是时间序列中有 22 年缺少值，因为这些年没有发生过火灾。我想使用完整的数据集，通过 Mann-Kendall 趋势分析来测试趋势的统计显著性。但我不知道如何处理缺失的数据，因为它们可能会影响测试的性能。我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/660960/mann-kendall-trend-analyses-with-missing-data</guid>
      <pubDate>Tue, 04 Feb 2025 15:57:38 GMT</pubDate>
    </item>
    <item>
      <title>对称狄利克雷序统计量的一阶矩</title>
      <link>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</link>
      <description><![CDATA[设 $\mathbf q\in[0,1]^n$ 为服从对称狄利克雷分布的随机向量，其参数为 $\alpha$:
$$
\mathbf{q}\sim \operatorname{Dir}(\alpha,\cdots,\alpha).
$$
将 $q_{(i)}$ 定义为 $\mathbf{q}$ 的 $i$ 阶统计量，按升序排列：
$$
q_{(1)}\le\cdots\le q_{(n)}.
$$
问题。 $E[q_{(i)}]$ 是什么？
我们可以将 $q_i$ 表示为
$$
q_i=\frac{z_i}{\sum_{k=1}^nz_k}
$$
对于 i.i.d. $z_i\sim\operatorname{Gamma}(\alpha,\lambda)$。
当 $\alpha=1$ 时，$E[q_{(i)}]$ 的表达式很简单。 Rényi 的表述表明
$$
z_{(i)}=\sum_{k=1}^i\frac{d_i}{n-k+1}
$$
其中 i.i.d. $d_i\sim\operatorname{Exp}(\lambda)$ 和 $\sum_{k=1}^nd_k=\sum_{k=1}^nz_k$。现在我们有
$$
q_{(i)}=\frac{z_{(i)}}{\sum_{k=1}^nz_k}=\sum_{k=1}^i\frac1{n-k+1}\underbrace{\frac{d_i}{\sum_{t=1}^nd_t}}_{=:D_i}。
$$
由于
$$
(D_1,\cdots,D_n)\sim\operatorname{Dir}(1,\cdots,1),
$$
$D_i$ 的一阶矩为
$$
E[D_i]=\frac1n,
$$
且
$$
E[q_{(i)}]=\frac1n\sum_{k=1}^i\frac1{n-k+1}。
$$
我试图将其推广到任何 $\alpha&gt;0$。我发现一些论文从伽马分布中得出了顺序统计的一阶矩。但在 $q_{(i)}$ 的表达式中，分子 $z_{(i)}$ 和分母 $\sum_{k=1}^nz_k$ 显然不是独立的；我需要推导出 $q_{(i)}$ 整体的矩。
如能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</guid>
      <pubDate>Tue, 04 Feb 2025 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>使用小样本校正对后双套索估计残差进行校正</title>
      <link>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</link>
      <description><![CDATA[后双重选择是一种在高维稀疏模型中对低维参数进行推理的方法。原始论文之一由Belloni、Chernozhukov 和 Hansen (2014) 在 ReStud 中撰写。他们考虑了一个部分线性模型：
\begin{align*} 
y_i &amp;= d_i \alpha_0 + g(z_i) + \zeta_i, &amp;E[\zeta_i | z_i, d_i] = 0 \\
d_i &amp;= m(z_i) + \nu_i, &amp;E[\nu_i | z_i] = 0。
\end{align*&gt;
用他们的话来说，该方法可以总结如下：

在第一步中，我们选择一组可用于预测治疗$d_i$的控制变量。此步骤有助于通过查找与治疗密切相关的控制变量（因此可能是重要的混杂因素）来确保模型选择后推断的有效性。
在第二步中，我们通过选择预测$y_i$的控制变量来选择其他变量。此步骤有助于确保我们已捕获感兴趣的方程中的重要元素，理想情况下有助于保持残差方差较小，并提供额外的机会来找到重要的混淆因素。
在最后一步中，我们通过$y_i$对治疗$d_i$的线性回归以及在两个变量选择步骤中选择的变量集的并集来估计感兴趣的治疗效果$\alpha_0$。

他们的主要理论结果如下图所示。这里 $\widehat{s}$ 表示上述算法中回归步骤 3 中包含的回归量的数量（即步骤 1 和 2 的并集）。

可以看出，为了估计估计量的方差，人们使用 $\widehat{\zeta}_i$ 和 $\widehat{\nu}_i$ 来估计残差。为了估计 $\widehat{\zeta}_i$，我们使用了小样本偏差校正，类似于用于估计经典样本方差的偏差校正。这在高维设置中很有意义，因为可以想象 $\widehat{s}$ 可能接近 $n$。当使用$\widehat{s} \geq n$时，甚至可以得到全为零的残差，这将为模型中的真实误差提供非常差的估计。
有谁知道或直觉为什么不应用这种偏差校正$\widehat{\nu}_i$？我们还针对此回归采用了变量选择，并且非零回归量的数量可能相对接近$n$？
我的问题与此帖子有关，但略有不同，因为该问题侧重于特定的 stata 实现，而我的问题是关于不使用偏差校正$\widehat{\nu}_i$背后的直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:16 GMT</pubDate>
    </item>
    <item>
      <title>计算平均变化（平均差异）和 SD 变化</title>
      <link>https://stats.stackexchange.com/questions/660939/calculate-the-mean-change-mean-difference-and-sd-change</link>
      <description><![CDATA[我想估计手术前后细胞密度的平均变化（平均差异）和 SD 变化。

有些研究没有直接提供这些值。相反，他们报告了平均年度细胞损失（细胞/平方毫米/年）及其 SD，如下所示：

o 0–1 年：228.1 ± 319.7
o 1–2 年：93.1 ± 129.3
o 2–3 年：80.7 ± 125.3
o 3–4 年：47.8 ± 83.3
o 4–5 年：18.7 ± 93.5
假设初始细胞计数为 mean_baseline = 2148 ± 604，是否有可能估计整个 0–5 年期间而不是每个年份的 mean_final 和 SD_final 或 mean_change 和 SD_change？

其他一些研究报告mean_baseline，例如 1968.2 ± 719.0，并指出 24 个月后，细胞损失为 14.6 ± 5.0%（百分比和百分比的 SD）。在这种情况下，是否可以计算 mean_final 和 SD_final 或 mean_change（平均差异）和 SD_change？

这些方法在统计上是否不正确？
提前感谢您的时间和宝贵的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660939/calculate-the-mean-change-mean-difference-and-sd-change</guid>
      <pubDate>Tue, 04 Feb 2025 08:00:12 GMT</pubDate>
    </item>
    <item>
      <title>什么不是马尔可夫链？</title>
      <link>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</link>
      <description><![CDATA[不久前我学习了马尔可夫链，它对我来说很有意义。如果系统状态之间的转换和这些转换的概率不依赖于系统的先前状态，那么系统所遵循的任何过程都被归类为马尔可夫链。但后来我学习了高阶马尔可夫链，据我所知，它总是可以表示为一阶马尔可夫链，尽管这在实践中可能并不理想，因为这种表示将具有更多节点。所以现在我想知道哪些过程不能表示为马尔可夫链。]]></description>
      <guid>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</guid>
      <pubDate>Mon, 03 Feb 2025 20:09:37 GMT</pubDate>
    </item>
    <item>
      <title>样本与总体平均治疗效果抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</link>
      <description><![CDATA[我读到Gerber 和 Green 2012 年的田野实验时，了解到了随机化推断的概念，即在进行随机化实验时，可以有两个推断目标。其样本平均治疗效果与研究参与者的有限群体有关。以及与研究参与者所取样的人群相关的人口平均治疗效果。
我的问题是关于如何估计这两个量的抽样变异性。
将平均治疗效果估计量定义为以下形式，其中 $Y_i(t=0)$ 和 $Y_i(t= 1)$ 分别是如果给予治疗 $t = 0$、治疗 $t=1$，则观察 $i$ 的潜在结果：
$$
ATE = \mathbb{E} [Y_i(1)] - \mathbb{E} [Y_i(0)]
$$
该数量是通过假设稳定单位值假设 (SUTVA) 的样本平均值估算的。其中 $t_i$ 是观察到的处理分配，处理时为 1，未处理时为 0。 $N$ 是观测总数，$m$ 是处理过的观测数。
$$
\widehat{ATE} = \frac{1}{m}\sum_{i=1}^m{Y_i(1)|}t_i=1 + \frac{1}{N-m}\sum_{i=m+1}^N{Y_i(0)|t_i = 0}
$$
$\widehat{ATE}$ 的方差如下：
$$
\text{Var}[\widehat{ATE}] = \frac{1}{N-1}\left [\frac{(N-m) \text{Var}[Y_i(1)]}{m} + \frac{m \text{Var}[Y_i(0)]}{N-m} + 2\text{Cov}(Y_i(0), Y_i(1))\right] 
$$
我从现场实验 Gerber and Green 2012 eq 3.4 中得到了方差公式
在教科书中，这种变异性的特点是基于随机化推理。变异性来自随机分配，导致潜在结果的样本平均值不同。
我们没有观察到$\text{Cov}(Y_i(0), Y_i(1))$，因此我们可以估计方差如下：
$$
\widehat{\text{Var}}[\widehat{ATE}] = \frac{\widehat{\text{Var}}[Y_i(1)]}{m} + \frac{\widehat{\text{Var}}[Y_i(0)]}{N-m}
$$
在教科书中，这种变异性是真实抽样方差的保守估计。教科书提到，在以下情况下，该变异性估计量是无偏的：

治疗效果对每个人都是恒定的，或者，
实验中的样本是较大总体的随机样本，推论以此为基础。

总体平均治疗效果的方差为 Gerber and Green 2012 实地实验 等式 11.1：
$$
\text{Var}[\widehat{PATE}] = \frac{\text{Var}[Y_i(1)]}{m} + \frac{\text{Var}[Y_i(0)]}{N-m}
$$
我的问题是，如果治疗效果对每个人都是恒定的，那么为什么$\widehat{\text{Var}}[\widehat{ATE}] = \text{Var}[\widehat{PATE}]$]]></description>
      <guid>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</guid>
      <pubDate>Fri, 31 Jan 2025 21:39:56 GMT</pubDate>
    </item>
    </channel>
</rss>