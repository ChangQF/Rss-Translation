<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 16 May 2024 12:27:08 GMT</lastBuildDate>
    <item>
      <title>2 个独立的数值数据集。 A 是法律类别的优先级（1 到 10）。 B - 对同一事物优先级的看法。使用什么统计测试？</title>
      <link>https://stats.stackexchange.com/questions/647352/2-independent-numerical-datasets-a-is-prioritisation-1-to-10-of-legal-categor</link>
      <description><![CDATA[我有 2 个数据集。其中一个（A 组）是立法中的类别排名。另一组数据（B）是社区成员对相同类别的排名。我想对此进行统计分析，以确定是否存在一致性 - 即法律和社区是否相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/647352/2-independent-numerical-datasets-a-is-prioritisation-1-to-10-of-legal-categor</guid>
      <pubDate>Thu, 16 May 2024 12:21:59 GMT</pubDate>
    </item>
    <item>
      <title>如何快速学习人工智能——当你深入/充分了解Python基础知识和JavaScript时[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647350/how-to-learn-ai-quick-when-you-know-python-basics-and-javascript-in-depth-ade</link>
      <description><![CDATA[我想参加今年 6 月 4 日举行的当地人工智能竞赛。 （还有两周半的时间。）我有一个好主意想提交。
我需要关于使用什么路线图来学习人工智能的建议。这是我迄今为止所掌握的知识。
JavaScript：

我拥有 Udemy 颁发的全栈 Web 开发证书。
这意味着我可以使用 html、css 和 JavaScript 制作一个网站。
而且我也熟悉 Node JS、Express Mongo DB 等。
我对前端开发比后端开发更满意
时刻。

Python：

我在学校上过一个学期的 Python 课程，我真的很高兴
了解。
作为初学者，我可以轻松地使用 Python 进行编程。
但是我从未使用 Python 制作过任何网站。
我不知道如何在网站上显示Python代码
但我听说学习时推荐Python
人工智能。
出于某种原因，我觉得使用 Python 编程比使用 Python 编程更舒服
使用 JavaScript。

从这里学习人工智能最有效的途径是什么。既是为了比赛，也只是为了学习人工智能。]]></description>
      <guid>https://stats.stackexchange.com/questions/647350/how-to-learn-ai-quick-when-you-know-python-basics-and-javascript-in-depth-ade</guid>
      <pubDate>Thu, 16 May 2024 10:04:22 GMT</pubDate>
    </item>
    <item>
      <title>将质量体积解释为无监督异常检测的评估标准</title>
      <link>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</link>
      <description><![CDATA[我发现这篇论文讨论了通过使用什么来评估无监督异常评分函数作者称之为质量体积和过剩质量。我还从这里的论文中找到了代码，这相当不错便利。我专注于 M-V，并试图解释其含义以及为什么它有意义。
质量-体积描述如下：
$$
MV_{s}(\alpha) = \inf_{u \geq 0} Leb(s(\mathbf{U}) \geq u) ~~~ s.t. ~~~ \mathbb{P}(s((\mathbf{X})) \geq u) \geq \alpha
$$
哪里
$\alpha$ 是累积质量
$s$ 是一些异常评分函数
$\mathbf{X}$ 是我们的特征集，维度为 (N,M)
$\mathbf{U}$ 是一个随机生成的多元均匀变量，以下边界 $\inf(\mathbf{ X})$ 和上限 $\sup(\mathbf{X})$。这本质上创建了一个从最小特征值到最大特征值的矩形。
$u$ 是我们评估勒贝格度量的分位数，表示为 $Leb$。
在 Python 中的实现中，如下所示：
clf = SomeAnomalyScoringModel()


阿尔法最小值 = 0.9
阿尔法最大值 = 0.999
axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)


lim_inf = X.min(轴=0)
lim_sup = X.max(轴=0)
n_生成 = 100000
unif = np.random.uniform(lim_inf, lim_sup,
                            大小=（n_生成，n_特征））
Volume_support = (lim_sup - lim_inf).prod()


s_unif = clf.decision_function(unif)
s_x = clf.decision_function(X)


def 质量体积（axis_alpha、volume_support、s_unif、s_X、n_generate）：
    n_samples = s_X.shape[0]
    s_X_argsort = s_X.argsort()
    质量 = 0
    点 = 0
    u = s_X[s_X_argsort[-1]]
    mv = np.zeros(axis_alpha.shape[0])
    对于范围内的 i(axis_alpha.shape[0])：
        而质量&lt; axis_alpha[i]：
            #在这里找你
            cpt += 1
            u = s_X[s_X_argsort[-cpt]]
            质量 = 1./ n​​_samples * cpt # sum(s_X &gt; u)
        mv[i] = float((s_unif &gt;= u).sum()) / n_ generated * volume_support
    返回 auc(axis_alpha, mv), mv

我对这里发生的事情有一个大概的了解。通过对 $s(x)$ 进行排序，我们正在寻找给定 $u$ =&quot;math-container&quot;&gt;$\alpha$ 通过添加 $mass$ 直到达到所需的  $\alpha$-质量。完成后，我们停止，因为我们已经达到约束 $\mathbf{P}(s(\mathbb{X})\geq q) \geq \alpha$&lt; /跨度&gt;。此时，我们计算 $Leb(s(\mathbf{U})\geq u)$。我们对所有所需的 $\alpha$ 级别重复此操作。
这里有两个问题：
我们如何解释这一点？我最好的解释是，我们将评分函数 $s$ 视为均匀分布（由设计没有离群值），并在到达真实得分分布的尾部后测量其累积密度，以勒贝格测量为代表（因此，在本例中只是面积）。但这如何表明 $s$ 是一个好模型呢？
为什么 Lebesgue 定义为 float((s_unif &gt;= u).sum()) / n_generate *volume_support？
当统一变量大于$u$时，这相当于矩形盒子的体积，那么它是二元累积密度吗？这是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</guid>
      <pubDate>Thu, 16 May 2024 09:45:24 GMT</pubDate>
    </item>
    <item>
      <title>匹配后：如何解释 r 包 cobalt bal.tab 的平衡度量表中“距离”类型的值（=倾向得分）？</title>
      <link>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</link>
      <description><![CDATA[我使用了R 包“MatchIt” 来执行 (1) 基于弗雷明汉心脏研究的最近邻倾向得分匹配 (NNM) 和 (2) 进行比较，最佳 PS相同 PS 模型的匹配（OM）。
PS 模型：BPMeds ~ 年龄 + 男性 + 教育程度 + BMI + 糖尿病 + prevalentHyp
对于天平诊断，我使用了R-Package ‘Cobalt’的bal.tab功能，并得到了以下结果：
&lt;前&gt;&lt;代码&gt;
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1172 0.1172 -0.0003 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.0000 56.0182 0.0024 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3091 0.3000 -0.0091 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9000 1.8909 -0.0090 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 28.2804 28.1248 -0.0296 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0636 0.0636 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
 可变 Diff.Adj M.Threshold
      BMI -0.0296 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 110 110
无与伦比 3437 1

bal.tab(m.framingham_**OM**, Continuous = &quot;std&quot;, binary = &quot;raw&quot;, disp = c(&quot;means&quot;), un = TRUE, stats = c(&quot;m&quot;) ,+ 阈值 = c(m = .10))
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1184 0.1188 0.0085 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.5135 56.0721 -0.0579 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3423 0.2973 -0.0450 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9820 1.9009 -0.0804 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 27.8785 28.2104 0.0632 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0721 0.0721 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
  可变 Diff.Adj M.Threshold
 教育程度 -0.0804 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 111 111
无与伦比 3436 0


如何解释 r 包 cobalt bal.tab 平衡度量表第一行中“距离”类型的值（=倾向得分）？
我可以使用距离来说明哪种匹配方法更适合（比较 NNM 与 OM 的两种模型/匹配方法）吗？

我刚刚找到以下关于距离的描述，但没有解释（ https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html）：
距离包含距离值距离（例如倾向得分）的可选公式或数据框或包含其名称的字符向量。如果指定了公式或变量名称，bal.tab() 将在 data 的参数中查找（如果指定）。由 matchit() 生成的距离测量（例如倾向得分）会自动包含在内并命名为“距离”。]]></description>
      <guid>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</guid>
      <pubDate>Thu, 16 May 2024 09:41:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 CEC2013 基准函数时面临为 PCA 生成数据的困难 [已关闭]</title>
      <link>https://stats.stackexchange.com/questions/647346/facing-difficulty-to-generate-data-for-pca-while-using-cec2013-benchmark-functio</link>
      <description><![CDATA[通过使用MATLAB，我想生成cec2013基准函数的数据，以便我可以应用PCA并降低其维度，有谁可以正确指导我，先谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647346/facing-difficulty-to-generate-data-for-pca-while-using-cec2013-benchmark-functio</guid>
      <pubDate>Thu, 16 May 2024 08:01:29 GMT</pubDate>
    </item>
    <item>
      <title>动态广义帕累托分布的推导</title>
      <link>https://stats.stackexchange.com/questions/647345/derivation-of-a-dynamical-generalized-pareto-distribution</link>
      <description><![CDATA[我目前正在阅读一篇关于使用峰值阈值法进行资产回报尾部指数估计的硕士论文论文。在本文中，作者介绍了广义帕累托分布的累积分布函数 (1)
$$ G_{\xi,\beta}(x) = 1 - \left(1 + \frac{x - \mu}{\beta}\right)^{-1 /\xi} if \xi \neq 0 $$ 我理解这一点，但后来作者引入了 GDP 条件 cdf 的重写版本，称为动态 CDF (2)。
$$ G_{t}^{\gamma}(r_{t}|F_{t-1}) = 1 - \left(1 + \frac{r_{t} - \gamma}{\alpha_{t}}\right)^{-\zeta_{t}} $$
我迷失在从（1）到（2）的步骤之间。我不明白他们如何推导出新函数，我不确定他们如何推断 $ 的比率$ \beta*\zeta_{t} = \alpha_{t} $$ 我似乎缺少一些步骤。引用的论文无助于提供更多信息
重写函数的论文摘录
非常感谢任何帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/647345/derivation-of-a-dynamical-generalized-pareto-distribution</guid>
      <pubDate>Thu, 16 May 2024 07:58:41 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用 Lasso，或者向我指出适合这项工作的正确工具。]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中模拟 1 阶时间序列的双变量整数值自回归过程的数据？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647341/how-to-simulate-data-for-a-bivariate-integer-valued-auto-regressive-process-of-o</link>
      <description><![CDATA[我想模拟数据（蒙特卡罗模拟）来评估 BINAR(1) 模型的最大似然估计器 (MLE) 的小样本属性：
\begin{对齐}
&amp; Y_{1, t}=\rho_1 \cdot Y_{1, t-1}+R_{1, t} \\
&amp; Y_{2, t}=\rho_2 \cdot Y_{2, t-1}+R_{2, t}
\end{对齐}
$R_{1, t}$ 和 $R_{2, t}$ 的分布&gt;，创新，也称为误差项，具有通过 Frank copula 连接的泊松边际。
我的目标是使用两种样本大小进行模拟：$n=200$ 和 $n=500$ span&gt;，每个有 200 个重复。 BINAR 模型的初始参数为：
$$
\rho_1=0.3，\quad \rho_2=0.7，\quad \lambda_1=1，\quad \lambda_2=1 \quad \delta=-1
$$
$\rho_1$ 和 $\rho_2$ 是时间序列的参数。 $\lambda_1$ 和 $\lambda_2$ 是泊松分布的参数。 $\delta$ 是 Frank copula 的依赖参数。
我打算使用“optim”函数进行对数似然优化，并使用 R 中的“stats”包来执行此操作。从这个模拟中，我应该得到上述 $n=200$ 的 5 个值和 $n=500 的 5 个值$.
有人可以帮我在 R 中实现这个过程吗？
我为 Frank copula 定义了一个函数，如下所示：
# 这是坦率的联结公式
pcoula.fam1&lt;-函数(u,v,a){
  - (1/a) * log(1 + ((exp(-a*u)-1) * (exp(-a*v)-1))/(exp(-a)-1))
}

# 这是一个用于表达通过 Frank copula 连接的二元泊松分布的函数
dmass&lt;-函数(x,y,l1,l2,a){
  a1&lt;-pcopula.fam1(ppois(x,lambda=l1), ppois(y,lambda=l2),a)
  b&lt;-pcopula.fam1(ppois(x-1,lambda=l1),ppois(y,lambda=l2),a)
  
  c1&lt;-pcopula.fam1(ppois(x,lambda=l1),ppois(y-1,lambda=l2),a)
  d&lt;-pcopula.fam1(ppois(x-1,lambda=l1),ppois(y-1,lambda=l2),a)
  a1-b-c1+d
}

##### 对数似然（ML 估计器）#####
loglik&lt;-函数(theta){
  x＜-x
  y&lt;-y
  alp11&lt;- exp(theta[1])/(1+exp(theta[1]))
  alp22&lt;- exp(theta[2])/(1+exp(theta[2]))
  th1&lt;-theta[3]
  th2&lt;-theta[4]
  th3&lt;-theta[5]
  p&lt;-NULL
  对于 (i in 2:n){
    k&lt;-rep(0:x[i],each=y[i]+1)
    s&lt;-rep(0:y[i],x[i]+1)
    f1&lt;-dbinom(x[i]-k,x[i-1],alp11) # alpha1 是二项式分布的成功概率“p”
    f2&lt;-dbinom(y[i]-s,y[i-1],alp22) # alpha2 是二项式分布的成功概率“p”
    f3&lt;-dmass(k,s,th1,th2,th3)
    p&lt;-c(p,总和(f1*f2*f3))
  }
  -sum(log(p),na.rm=T)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/647341/how-to-simulate-data-for-a-bivariate-integer-valued-auto-regressive-process-of-o</guid>
      <pubDate>Thu, 16 May 2024 07:08:24 GMT</pubDate>
    </item>
    <item>
      <title>基于曲线预测连续变量</title>
      <link>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</link>
      <description><![CDATA[我有一组在不同频率下测量的曲线的数据集，因此它由如下图所示的曲线组成。当然，我的数据集还有更多曲线。曲线与连续因变量（例如高度）相关联。哪种机器学习方法可以让我根据整个曲线来预测因变量的值？
我想过线性混合效应，但是有没有像高斯过程这样的机器学习方法，有谁知道我如何做到这一点的例子？
我没有高斯过程的经验，但我想学习如何做到这一点。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</guid>
      <pubDate>Thu, 16 May 2024 00:53:41 GMT</pubDate>
    </item>
    <item>
      <title>FPP教材中简单指数平滑（状态空间形式）的误差和残差</title>
      <link>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</link>
      <description><![CDATA[我正在阅读 Hyndman &amp; Athanasopoulos《预测：原理与实践》第二版（FPP2）。 （我知道存在第三版。）在关于指数平滑的章节中，第 7.5 节讨论了具有附加误差的简单指数平滑，ETS(A,N,N)。它引入了残差 $e_t:=y_t-\ell_{t-1}$ 其中 $\ell_{t-1 }$ 是平滑方程的滞后水平。然后就在下面几行，有下面一段话：
&lt;块引用&gt;
对于具有加性误差的模型，我们假设残差（一步训练误差）$e_t$ 是正态分布的白噪声，平均值为 $0$ 和方差 $\sigma^2$。其简写形式为 $e_t = \varepsilon_t \sim NID(0,\sigma^2)$; NID 代表“正态独立分布”。

然后使用 $e_t$ 的一些方程用 $\varepsilon_t$ 重写。我对引用段落中 $e_t = \varepsilon_t$ 的含义有点困惑。它只是为 $e_t$ 引入了一个新符号吗？如果是这样，为什么不从一开始就使用 $\varepsilon_t$ 呢？或者 $e_t = \varepsilon_t$ 是否具有其自身的某种含义，告诉我们一个对象等于另一个对象？如果是这样，会有什么影响？简而言之，编写 $e_t = \varepsilon_t$ 的意义是什么？
（本书的某些部分似乎对模型误差（随机变量）、拟合误差/残差（其拟合值）和输入与输出之间的区别不太仔细，这并没有帮助。样本预测误差（随机变量或其实现）。）]]></description>
      <guid>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</guid>
      <pubDate>Wed, 15 May 2024 11:39:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习模型要学习概率分布以及为什么它很重要？</title>
      <link>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</link>
      <description><![CDATA[我知道这个问题很愚蠢，但我已经阅读和编写神经网络有一段时间了，研究了反向传播等。
但是，我认为我从未理解过神经网络建模的概率分布是什么？
我确实知道它们是频率与特征图，但我为什么了解数据集中 L 形边界的数量会有帮助呢？
当然，我也没有看到线性回归学习任何这些（我寻找一个非常简单的案例来分析。）
如果可能的话，您的概念解释是什么？您能给我推荐一些针对这方面的初学者的文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</guid>
      <pubDate>Wed, 15 May 2024 08:46:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中编写普通联结函数？</title>
      <link>https://stats.stackexchange.com/questions/647258/how-to-write-a-function-for-the-normal-copula-in-r</link>
      <description><![CDATA[如何在 R 中为普通联结函数编写以下函数？
$$
C_\theta(u, v)=\Phi_\theta\left(\Phi^{-1}(u), \Phi^{-1}(v)\right),
$$
其中 $\Phi$ 是 $N(0,1)$ cdf，$\Phi^{-1}$ 是 $\Phi$ 和 $\Phi_\theta$ 是具有相关性的二元标准正态 CDF $\theta$。
我尝试过这样写，但效果不好，因为最终当我尝试查找对数似然值时，它不会返回任何值。
pcopula.fam1 &lt;- 函数(u, v, a) {
  返回(exp(-(qnorm(u)^2-2*a*qnorm(u)*qnorm(y)+qnorm(y)^2)/(2*(1-a^2)))/(2 *pi))
}

弗兰克系动词
这就是我为 Frank 联结函数编写函数的方式，但我仍坚持使用上面描述的普通联结函数。
pcopula.fam1&lt;-function(u,v,a){
  - (1/a) * log(1 + ((exp(-a*u)-1) * (exp(-a*v)-1))/(exp(-a)-1))
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/647258/how-to-write-a-function-for-the-normal-copula-in-r</guid>
      <pubDate>Wed, 15 May 2024 07:19:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv 的 GAM 中的随机效应与使用 lme4 的 LMM 中的随机效应</title>
      <link>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</guid>
      <pubDate>Tue, 14 May 2024 21:41:43 GMT</pubDate>
    </item>
    <item>
      <title>在训练逻辑回归以预测未来结果时如何分割和采样“面板数据”</title>
      <link>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</link>
      <description><![CDATA[简介
我有面板数据，可以观察一段时间内的客户行为。对于给定参考日期的每个客户，我有 12 个月的回顾窗口用于生成功能，以及 12 个月的展望窗口用于识别结果，例如取消订阅、默认或类似操作。

每个客户按月存在于我的数据集中，方式如下：

现在我想训练逻辑回归来预测二元结果，这就是我有很多问题的地方。我大多只能找到有关时间序列验证的博客和书籍，但找不到有关面板数据的博客和书籍。但以下是我的想法，我想提出意见。
拆分的最佳实践是什么？
我需要将数据集分成训练/有效/测试，其中训练/有效将用于训练逻辑回归和对抗模型（验证数据用于超参数调整和早期停止），以及测试数据将用于最终评估。
由于模型必须随着时间的推移以及新客户的表现而变化，我想做两种类型的“样本外”测试：验证：1）时间验证（过时）以确保它适用于未来未见的数据，2）“外部验证”，以便训练数据、验证数据和数据中不存在相同的客户测试数据。

什么是“最佳实践”？用于拆分面板数据？
大多数博客文章都提到做“不合时宜”的事情。验证，但没有人真正提到对训练数据中不存在的样本进行验证。最后一部分没有必要吗？
如何处理“串行相关性”？
在逻辑回归中，观察之间的独立性假设通常很重要。让同一客户在训练数据中多次出现（可能具有相关变量和结果）违反了这一假设，因为他们的每月观察并不真正独立。这可能会导致低估标准误差和过度自信的预测，因为该模型不会考虑受试者内的相关性。
什么是“最佳实践”？用于处理这些“序列相关性”？
我处理这个问题的一些想法：

数据中仅保留单个客户一次

一个潜在的问题是，我可能会丢失重要分段和二进制结果上的太多数据


使用聚集标准错误

对非独立观察结果（客户）进行聚类，并计算修正的标准误差以考虑客户内的相关性。


使用广义估计方程 (GEE)

我对这些不太熟悉，但他们应该能够根据数据中的相关结构调整模型指标



您将如何验证模型的时间方面？
我希望模型能够随着时间的推移尽可能保持高性能，但它需要在为测试留出多少时间方面进行权衡。已经充分证明，“最近的过去”已经过去了。比“遥远的过去”更好地预测未来。但我正在考虑这样的事情，我在 2 年的评估期内每月单独评估模型，有或没有校准（将预测率调整为过去一年的观察率）。
整个“校准”的原因是步骤是我们期望模型的排名性能随着时间的推移保持一致，而总体结果率预计随着时间的推移而变化。
什么是“最佳实践”？获得最“值得信赖”的随着时间的推移有效的评估指标？

您还有其他很酷的提示和技巧吗？
这里可能缺少很多东西，所以请随时提供其他建议和最佳实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</guid>
      <pubDate>Mon, 06 May 2024 15:13:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用与损失函数不同的评分规则？</title>
      <link>https://stats.stackexchange.com/questions/625845/why-use-a-scoring-rule-different-from-the-loss-function</link>
      <description><![CDATA[我想我的问题与这些相关：选择适当的评分规则，预测中使用的性能指标与训练模型的目标函数不同，但我仍然很困惑......
我被告知执行回归的正确方法是通过最大似然找到参数。这适用于线性回归和概率回归，例如逻辑回归。那么，为什么我想通过可能性（或它的一些单调变换）以外的其他方式来量化模型的性能呢？使用 Brier 分数、球面分数或其他分数的理由是什么？
此答案说明：
&lt;块引用&gt;
评分规则的选择取决于您想要在概率尺度的不同部分上放置多少权重，或者同等地，不同的相对假阳性和假阴性成本。

我不明白。据我所知，Brier 分数在误报和漏报方面是对称的。但是，即使上面的解释是正确的，并且我真的想对“概率尺度的不同部分”进行不同的加权，我不应该首先最小化这个分数，而不是最大化对数-可能性？
所以，在我看来，我可以

使用最大似然进行回归，然后坚持使用似然进行评估；或
根据我的实际应用确定评分规则，然后通过优化该分数来找到回归参数，我稍后也会将其用于评估模型。

（请注意，在后一种情况下，如果我选择 Brier 分数，这将归结为最小二乘优化。但最小二乘实际上是存在高斯噪声的情况下的最大似然，这对于二进制数据来说是不可能的。 ..)
我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/625845/why-use-a-scoring-rule-different-from-the-loss-function</guid>
      <pubDate>Wed, 06 Sep 2023 16:59:01 GMT</pubDate>
    </item>
    </channel>
</rss>