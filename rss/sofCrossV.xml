<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Jan 2024 15:15:29 GMT</lastBuildDate>
    <item>
      <title>线性回归中的二次项</title>
      <link>https://stats.stackexchange.com/questions/636142/quadratic-terms-in-linear-regression</link>
      <description><![CDATA[我制作回归模型已经有一段时间了，我对 $$y = \beta_0 +\beta_1x^2 \text{ 是线性的并且} y =\beta_0 +\beta_1^2x \text{ 不是}$$
但我一直不明白为什么会这样。在我看来，我们假设 $\beta_1$ 是一个固定数字，那么为什么我们不能直接说 $ \beta_{new} = \beta_1^2$ 并从那里开始。另外，什么时候我会出现二次回归系数？总的来说，我真的很好奇为什么这很重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/636142/quadratic-terms-in-linear-regression</guid>
      <pubDate>Thu, 04 Jan 2024 15:05:59 GMT</pubDate>
    </item>
    <item>
      <title>异方差趋势回归中的 OLS 与 WLS</title>
      <link>https://stats.stackexchange.com/questions/636135/ols-vs-wls-in-a-heteroskedastic-trending-regression</link>
      <description><![CDATA[假设我们有以下异方差趋势回归模型：$$y_i=bi+a_i u_i$$ 对于一些非零常数序列$a_i$ 和 $u_i$ 是一个 i.i.d.均值 0 和方差 1 随机变量的序列。我想找到 OLS 和不可行的 WLS 估计器的渐近分布并比较它们的效率。
为此，我计算了两个渐近分布的归一化常数。我使用 Lindeberg-Feller CLT 并假设相关的 Grenander 条件成立。我计算 $\hat{b}_{OLS}$ 和 $\hat{b}_{WLS} $, $$\left(\sum_{i=1}^n i^2\right)\left(\sum_{i=1}^n a_i^2 i^2\right)^{-1/2}(\hat{b}_{OLS}-b)\xrightarrow{d} N(0,1)$$
$$\left(\sum_{i=1}^n i^2\right)\left(\sum_{i=1}^n \frac{i^2}{a_i ^2} \right)^{-1/2}(\hat{b}_{WLS}-b)\xrightarrow{d} N(0,1)$$
但是，我认为这一定是不正确的，因为我不明白为什么 WLS 一定比 OLS 估计器更有效。我认为在某些情况下，任一标准化都较大，这意味着任一估计器在不同情况下都可能有效。例如，我认为这些意味着如果 $a_i&gt;1$ 对于所有 $i$ 则 WLS效率更高，但如果 $a_i&lt;1$ 对于所有 $i$ 则 OLS 效率更高.
我的计算有问题吗？我希望 WLS 更加高效，但看不出我的工作中出现了错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/636135/ols-vs-wls-in-a-heteroskedastic-trending-regression</guid>
      <pubDate>Thu, 04 Jan 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么作者放弃有用的专栏？</title>
      <link>https://stats.stackexchange.com/questions/636133/why-author-discards-useful-column</link>
      <description><![CDATA[我对这种逻辑思维感到困惑：

这句话来自 Matloff 的《机器学习的艺术》一书
他正在使用数据集https://www.kaggle.com/datasets/joniarroba /noshowappointments
我同意 ID 列，但是……为什么不包括邻居？这似乎是一个很好的功能，（公共交通较差的社区可能会取消交通......）
预约日和预约日似乎也很重要……如果预约是提前几个月安排的，患者可能会忘记……而且，如果那天是星期五，也许人们在星期五更健忘……为什么作者要丢弃有用的数据？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/636133/why-author-discards-useful-column</guid>
      <pubDate>Thu, 04 Jan 2024 14:04:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 GMM 或 LDV 来处理 1945-2018 年数据帧中自相关的大问题？</title>
      <link>https://stats.stackexchange.com/questions/636132/how-do-i-use-gmm-or-ldv-to-handle-a-big-problem-with-autocorrelation-in-a-data-f</link>
      <description><![CDATA[对于一项考试（该考试的结果不需要完全准确并解释我们变量中的所有变化），我正在分析（世界上所有国家）议会中女性比例是否较高，倾向于较少作为侵略者参与战争。我创建的数据模型跨越 1945 年至 2018 年（对于分析来说有点不切实际 - 我必须认识到）。
毫不奇怪，在进行双向固定效应模型之后，我现在遇到了自相关问题。在阅读了一些有关如何处理自相关的材料后，据我所知，建议使用两种方法作为解决方案；
滞后因变量 (LDV) 和 GMM（广义矩量法）。
我注意到 GMM 在复杂性方面可能有点超出我的能力范围。
但是，您建议我使用哪种方法？如果是这样/您可以给我哪些关于编写这两种方法的代码的提示。
编辑：我现在尝试使用以下代码来滞后我的因变量。然而，这仍然在 Breusch-Godfrey/Wooldridge 序列相关性检验中返回显着的 p 值：
# 创建滞后因变量
Finaldatamerged$Dependent_Variable_Lag1 &lt;- lag(finaldatamerged$`战争开始了`, 1)

# 估计具有滞后因变量的固定效应模型
laggedfemodel &lt;- plm(finaldatamerged$Dependent_Variable_Lag1 ~ Percent_women_in_parliament + Finaldatamerged$`自由民主比率`,
                     数据=最终数据合并，模型=“内部”，效果=“双向”）

pbgtest（滞后femodel）

]]></description>
      <guid>https://stats.stackexchange.com/questions/636132/how-do-i-use-gmm-or-ldv-to-handle-a-big-problem-with-autocorrelation-in-a-data-f</guid>
      <pubDate>Thu, 04 Jan 2024 13:59:51 GMT</pubDate>
    </item>
    <item>
      <title>多级边际结构模型和中心预测器</title>
      <link>https://stats.stackexchange.com/questions/636131/multilevel-marginal-structural-models-and-centering-predictors</link>
      <description><![CDATA[我读过以预测变量的值为中心（减去个体，$i$，组平均值的值，$j$，多级模型中的值或总平均值）有助于多级建模输出的可解释性。
通常，采用多级模型的动机是面板数据的存在，以及随着时间的推移对单位进行重复观察。虽然多级模型可以解决面板数据的某些特征（个体观察嵌套在单元内的嵌套结构），但 MLM 本身并不能解释时间的偏差特性。
我研究边际结构模型 (MSM) 一段时间了，我对它们的应用很着迷，因为它们可以解决反馈循环问题 ($X_{it-1} \rightarrow Y_{it-1} \rightarrow X_{it} \rightarrow Y_{it} \rightarrow X_{it+1}$ 等）理论上存在于面板数据中。自然，这让我产生疑问如何将多级建模与边际结构模型结合起来（多级边际结构模型？）
首先，这样的组合可能吗？如果是这样，我的第二个问题涉及多级 MSM 输出的可解释性。同样，许多人认为居中对于可解释性是必要的。在 MSM 中，协变量包含在所应用的权重中（给定协变量的治疗的逆概率），并且不直接包含在回归方程中。这种中心化是否仅适用于多水平 MSM（治疗）中存在的单个预测因子？或者，是否应该使用中心协变量值来开发逆倾向得分，然后用于对观察结果进行加权？此外，如果我有兴趣估计中间随机效应模型，指定为：
$y_{ij} = \beta_0 + \beta_{W}(x_{ij} - \bar{xj}) + \beta_{B}\bar{x_j} + (u_j + e_{ij})$
我是否还需要将组级平均值作为协变量包含在 MSM 中和/或以某种方式将其包含在加权方案中？这可能是无意义的，但我正在努力理解这两种方法背后的数学如果结合起来是如何工作的。]]></description>
      <guid>https://stats.stackexchange.com/questions/636131/multilevel-marginal-structural-models-and-centering-predictors</guid>
      <pubDate>Thu, 04 Jan 2024 13:53:32 GMT</pubDate>
    </item>
    <item>
      <title>多变量单目标时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/636130/timeseries-forecasting-single-target-with-multi-variables</link>
      <description><![CDATA[我正在尝试为单个目标创建一个时间序列预测模型...许多相关变量的实际过去值和未来预测是可用的，应该用作输入（例如，GDP、失业率等） - 不需要对变量进行预测。我在网上看到的所有论文都使用历史值并预测目标和变量的未来......有什么建议吗？还有其他模型更适合这种情况吗？
研究了几个 VAR 模型，但这些模型都没有在预测目标时考虑现成的未来变量预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/636130/timeseries-forecasting-single-target-with-multi-variables</guid>
      <pubDate>Thu, 04 Jan 2024 13:33:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 VAR 过程的定义中创新均值限制为零？</title>
      <link>https://stats.stackexchange.com/questions/636128/why-is-mean-of-innovations-restricted-to-zero-in-definition-of-var-process</link>
      <description><![CDATA[VAR过程定义为：
$$\begin{align}
\mathbf{y}_t = A_1\mathbf{y}_{t-1} + \dots + A_d\mathbf{y}_{t-d} + \boldsymbol{\epsilon}_t, \quad t \in \mathbb{ Z}
\end{对齐}$$
其中 $\boldsymbol{\epsilon}_t$ 是白噪声过程，特别是 $\mathbb{E} [\boldsymbol{\epsilon}_t] = 0$ 和 $\mathbb{E}[\boldsymbol{\epsilon}_t\boldsymbol{\epsilon}_s^T ] = \mathbf{O}$，对于 $s \neq t$。
为什么创新被限制为均值为零？
查看 Lutkepohl书和引用的命题C.9，我认为这甚至不是过程稳定所必需的。]]></description>
      <guid>https://stats.stackexchange.com/questions/636128/why-is-mean-of-innovations-restricted-to-zero-in-definition-of-var-process</guid>
      <pubDate>Thu, 04 Jan 2024 12:28:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么大量的审查在生存分析中是不好的？</title>
      <link>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</link>
      <description><![CDATA[我试图理解为什么大量的审查（即许多患者被审查）在生存分析中是不可取的。
作为概念证明，假设有 5 名患者：

患者 1 在 t1 发生事件
患者 2 在 t2 发生事件
患者 3 在 t3 时退出研究
患者 4 在 t4 发生事件
当研究在 t5 结束时，患者 5 没有发生该事件

（半参数方法）这是我在这种情况下尝试编写 Cox-PH 回归的模型和可能性：
$$ h(t|X) = h_0(t) \exp(\beta^T X) $$
$$ L(\beta) = \prod_{i: \delta_i = 1} \frac{h(t_i|X_i)}{\sum_{j: t_j \geq t_i} \ exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\sum_{j: t_j \geq t_1} \exp(\beta^T X_j)} \次\frac{h(t_2|X_2)}{\sum_{j: t_j \geq t_2} \exp(\beta^T X_j)} \次\frac{h(t_4|X_4)}{\sum_{j: t_j \geq t_4} \exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\exp(\beta^T X_1) + \exp(\beta^T X_2 ) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_2|X_2)}{\exp(\beta ^T X_2) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_4|X_4)}{\exp (\beta^T X_3) + \exp(\beta^T X_5)} $$
（参数方法）这是我在这种情况下尝试编写 AFT 模型的模型和可能性：
$$ \log(T) = \mu + \sigma \beta^TX + \epsilon $$
$$ L(\mu, \sigma, \beta) = \prod_{i=1}^{n} \left[ \frac{1}{\sigma} f\left( \frac{\log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{\​​delta_i} \left[ 1 - F\left( \frac{\ log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{1-\delta_i} $$
$$ L(\mu, \sigma, \beta) = \left[ \frac{1}{\sigma} f\left( \frac{\log(t_1) ) - \mu - \beta^T X_1}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_2) - \mu - \beta^T X_2}{\sigma} \right) \right] \times \left[ 1 - F\left( \frac{\log(t_3) - \mu - \beta^T X_3}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_4) - \mu - \beta^T X_4}{\sigma} \right) \右] \times \left[ 1 - F\left( \frac{\log(t_5) - \mu - \beta^T X_5}{\sigma} \right) \right] $$
那么在 Cox-Ph 和 AFT 模型中，推理（例如，可能会导致高方差、高偏差、不一致性、较大的样本量来实现比较结果与较小的样本量和较少的审查）和参数估计如何当大量患者受到审查时会产生负面影响吗？数学优化是否变得困难（例如，矩阵秩不完整、矩阵逆未定义、模型不可识别）？
PS：我听说一些策略涉及使用混合分布对无事件（审查）和事件（非审查）群体进行建模，这在数据集中很大一部分数据集未开发出事件的情况下显然很有用。事件。例如，基于威布尔分布的生存函数可用于使用混合分布方法（参数）分别对无事件和事件群体进行建模。这称为治愈模型。
威布尔函数（pdf、cdf、生存和危险）：
$$ f(t|\lambda, \gamma) = \frac{\gamma}{\lambda} \left(\frac{t}{\lambda}\right )^{\gamma - 1} \exp\left[-\left(\frac{t}{\lambda}\right)^\gamma\right] $$
$$ F(t|\lambda, \gamma) = \int_0^t f(u|\lambda, \gamma) du = 1 - \exp\left[-\左(\frac{t}{\lambda}\right)^\gamma\right] $$
$$ S(t|\lambda, \gamma) = 1 - F(t|\lambda, \gamma) = \exp\left[-\left(\frac) {t}{\lambda}\right)^\gamma\right] $$
$$ h(t|\lambda, \gamma) = \frac{f(t|\lambda, \gamma)}{S(t|\lambda, \gamma) )} = \frac{\gamma}{\lambda} \left(\frac{t}{\lambda}\right)^{\gamma - 1} $$
模型和似然（$f_1(t)$、$f_2(t)$ 是两个人群的 pdf，$p(x)$ 是治愈率）：
$$ f(t) = p \cdot f_1(t) + (1 - p) \cdot f_2(t) $$
$$ S(t) = p \cdot S_1(t) + (1 - p) \cdot S_2(t) $$
$$ p(X) = \frac{\exp(X&#39;\alpha)}{1 + \exp(X&#39;\alpha)} $$
$$ L(p, \theta_1, \theta_2) = \prod_{i=1}^{n} \left[p \cdot f_1(t_i|\theta_1) + (1 - p) \cdot f_2(t_i|\theta_2)\right]^{d_i} \cdot \left[p \cdot S_1(t_i|\theta_1) + (1 - p) \cdot S_2(t_i|\ theta_2)\right]^{1-d_i} $$
（我不太确定如何继续这个......只是偏离了主题）]]></description>
      <guid>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</guid>
      <pubDate>Thu, 04 Jan 2024 06:08:48 GMT</pubDate>
    </item>
    <item>
      <title>如果效应规模如此之小，那么研究调节效应还有什么意义呢？</title>
      <link>https://stats.stackexchange.com/questions/636082/whats-the-point-in-studying-moderation-effects-if-effect-sizes-are-so-small</link>
      <description><![CDATA[.002 是中位数，0.009 是心理学中的平均调节效应大小，基于 Aguinis 等人。 2005，评估分类变量调节效应的效应大小和功效：30 年回顾，J。应用心理学，90 94-107。
我的意思是，影响是如此之小，我无法弄清楚它怎么可能有任何兴趣......而且社交世界也充满了噪音......
我正在寻找想法和建议。
提前感谢大家
编辑：感谢您的编辑。我正在添加一些上下文：

期刊：1969 年至 1998 年在《Journal of Applied Psychology》（JAP）、《Personnel Psychology》（PP）和《Academy of Management Journal》（AMJ）上发表的所有文章。选择这些期刊是因为其方法论严谨且强调理论；
纳入标准：(a) 至少一项 MMR 分析被纳入研究的一部分，(b) MMR 分析包括连续标准，(c) MMR 分析包括连续预测因子，以及 (d) MMR 分析分析包括分类调节器。 （NB MMR= 调节多元回归）
最终样本：“计算了 261 个 MMR 分析的效应量，其中样本量和基于调节器的亚组之间的预测因子-标准相关性可用。当可用时，我们使用 X 和 Y 方差信息，并假设该信息不可用的 MMR 分析的误差方差同质性。
在计算结构水平效应大小时（即基于无差错测量），我们在可用时使用可靠性信息，在该信息不可用时使用 0.80 值。
在计算能力方面，我们使用范围从 0.001 到 0.35 的目标 f 2 值，以涵盖应用心理学和管理研究中可被视为关键效应大小的广泛范围以及每项已发表研究中报告的样本大小。”

2°编辑：感谢@所有回答和评论的人。我要结束这个问题了。]]></description>
      <guid>https://stats.stackexchange.com/questions/636082/whats-the-point-in-studying-moderation-effects-if-effect-sizes-are-so-small</guid>
      <pubDate>Wed, 03 Jan 2024 17:59:13 GMT</pubDate>
    </item>
    <item>
      <title>“外生”工具 Z 上的反向因果关系</title>
      <link>https://stats.stackexchange.com/questions/635700/reverse-causality-on-a-exogenous-instrument-z</link>
      <description><![CDATA[假设我们想要进行工具变量回归。我们有内生变量 X、外生工具 Z、因变量 Y 和误差项 U。
为了使该方法有效，我们需要令人信服地排除外生工具与误差项无关。但我读到，此外我们还必须排除 Y 对 Z 存在反向因果关系。
如果我怀疑存在反向因果关系，那么 IV 的什么假设会被违反？这也是外生性假设吗？ Y 对 Z 的反向因果关系是否会导致 Z 和误差项之间存在相关性，因此可以被视为 Z 和 U 之间不相关的一般假设的特例？]]></description>
      <guid>https://stats.stackexchange.com/questions/635700/reverse-causality-on-a-exogenous-instrument-z</guid>
      <pubDate>Wed, 27 Dec 2023 12:44:02 GMT</pubDate>
    </item>
    <item>
      <title>治疗和结果在不同水平上汇总时的因果推断</title>
      <link>https://stats.stackexchange.com/questions/635663/causal-inference-when-treatment-and-outcome-are-aggregated-at-different-levels</link>
      <description><![CDATA[考虑这样一种情况：治疗是美国州级政策（一些州采用了该政策，而另一些州则没有），结果是个人对美国各州调查的反应。为了使这种情况不那么抽象，我们假设该政策是枪支改革立法，而结果是个人对安全的看法。因此，治疗和结果会在不同级别上汇总。
我立刻就发现了这种方法的一个问题，因为它涉及到识别要调整的混杂因素。例如，在这种情况下，意识形态似乎是一个明显的混杂因素，但意识形态以什么方式聚合？国家的意识形态构成将影响通过枪支改革立法的可能性，个人的意识形态将影响他们对安全的看法，但一个人的意识形态将影响他们对安全的看法。国家和个人的意识形态是两个独立（但相关）的概念。而且，如果是这样的话，这就是“意识形态”吗？甚至是一个混杂因素？
天真地说，我可以说：
枪支改革$\leftarrow$意识形态$\rightarrow$安全认知
但这并不是真的，不是吗？因为，我实际上假设的是两种完全独立的意识形态衡量标准：
枪支改革$\leftarrow$国家意识形态构成
安全认知$\leftarrow$个人意识形态
人们如何处理诸如此类的情况，其中问题似乎完全是由治疗和结果之间的不同聚合程度驱动的？一个明显的做法可能是对结果的响应进行平均并崩溃到州一级，但这有一个严重的缺点，即严重减少 N。有没有办法在不重新聚合的情况下继续前进？]]></description>
      <guid>https://stats.stackexchange.com/questions/635663/causal-inference-when-treatment-and-outcome-are-aggregated-at-different-levels</guid>
      <pubDate>Tue, 26 Dec 2023 16:55:05 GMT</pubDate>
    </item>
    <item>
      <title>我们可以解释趋势季节性分解中的残差吗？</title>
      <link>https://stats.stackexchange.com/questions/635383/can-we-interpret-residuals-in-trend-seasonality-decomposition</link>
      <description><![CDATA[一般情况：建立市场模型以进一步评估我们的算法的质量。 （预测最优价格、需求预测等）
目前的方法：采用产品的两个特征——价格和需求，将其表示为时间序列。
下一步我试图“摆脱”该系列的时间依赖性——通过“减法”或“划分”趋势和季节性成分。
分解模型有两个主要假设：线性和乘法。我们假设我们的平均需求曲线类似于某些 $\exp(x)$ 函数，因此我们必须使用乘法方法。
我使用 statsmodels.tsa.seasonal 尝试了一些经典方法：  season_decompose 和 STL。使用经典方法，我只能分解一个特征（需求或价格）。
结果是这样的（对于需求系列，某些类别的平均值，一年的数据）：

还使用了 prophet，但这次有两个特征（这次假设乘法模型，但在 Prophet 乘法中）模型是
$$y(t) = \text{趋势}(t)*(1 + \text{季节}(t) + \text{beta} * \text{残差}( t))$$，与经典不同
$$y(t) = \text{趋势}(t)*\text{季节}(t)*\text{残差}(t)$$
我已经拟合了该系列，然后根据我之前拟合的整个数据进行预测，获得趋势和季节性成分，得到 $\text{residual}(t)$ :

那么，有两个问题：

这是消除趋势和季节性成分的有效方法吗？尤其是在数据量较少的情况下。
我们可以将残留成分解释为一些“干净”的成分吗？要求？或者更高的噪声值不允许我们解释这个组件？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635383/can-we-interpret-residuals-in-trend-seasonality-decomposition</guid>
      <pubDate>Wed, 20 Dec 2023 23:03:07 GMT</pubDate>
    </item>
    <item>
      <title>在 Kruskal-Wallis 后调整多重比较</title>
      <link>https://stats.stackexchange.com/questions/635278/adjusting-for-multiple-comparisons-after-kruskal-wallis</link>
      <description><![CDATA[我正在比较从免疫测定获得的生物标志物水平（总共 50 个），该队列分为 3 组（对照组、非活动组和活动组）。
我想使用 Kruskal-Wallis 检验和 Dunn 检验来评估各组之间是否存在差异（对照组与不活动组、对照组与活动组、不活动组与活动组）。
然后，我想计算一个 q 值来估计多次比较的错误发现率（使用 R 中的 p.adjust 函数）。在使用 Mann-Whitney 检验比较 2 组（对照组与疾病组）之前，我已经完成了此操作，并输入所有 p 值以产生调整后的 p 值（或 q 值）。
在 Kruskal-Wallis 测试后做同样的事情时，我对何时调整 p 感到困惑。是在对所有 50 个生物标记物执行 KW w/Dunns 并获得最终 p 值，然后将它们输入到 p.adjust 代码中之后吗？我是否只调整那些对最初的 Kruskal-Wallis 产生重要影响的内容？使用 Mann-Whitney 检验（控制与非活动、控制与活动、非活动与活动）单独比较各组，然后调整所有 50 个 p 值是否会更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/635278/adjusting-for-multiple-comparisons-after-kruskal-wallis</guid>
      <pubDate>Tue, 19 Dec 2023 17:41:17 GMT</pubDate>
    </item>
    <item>
      <title>对测试集文本（无标签）进行预训练可以吗？</title>
      <link>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</link>
      <description><![CDATA[编辑：浏览本文后6，我将这个问题的范围缩小到NLP问题。摘要的相关摘录（强调我自己的）：
&lt;块引用&gt;
我们证明，无监督预处理实际上会给交叉验证估计带来很大的偏差，并可能损害模型选择。 这种偏差可能是正的，也可能是负的，其确切大小以复杂的方式取决于问题的所有参数。

动机
使用测试集标签来训练测试集特征显然是错误的。但在许多机器学习竞赛中，发布测试集功能并允许参与者对其进行训练是标准做法。一个例子是 NLP 中的真实世界注释少样本任务 (RAFT) 基准。1以下摘录自 RAFT论文（强调我自己的）：
&lt;块引用&gt;
对于每项任务，我们都会发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。 我们鼓励对未标记示例进行无监督预训练和开放域信息检索。

在 RAFT 竞赛中，您可以通过在您可能训练的同一组未标记文本上运行模型来提交预测。在 NLP 中，训练未标记文本的常见方法是训练一个语言模型，该模型根据其他标记来预测标记。将此过程应用于特定域的数据集通常称为“域适应”。
我知道发布测试集功能对于主办竞赛的人很有帮助，因为它允许参与者提交预测而不是模型/代码。我还了解到，在现实世界的模型开发中，您可能观察到大量未标记的文本。但我认为关键的区别在于，在现实世界中，您无法访问样本外文本。
问题
在（样本内）测试集文本上训练模型，然后在相同测试集上评估该模型是否是样本外性能的乐观估计？
一个听起来合理的假设是，对（样本内）测试集文本进行训练会导致测试集预测和测试集标签之间存在相关性，这是一个乐观的估计量（至少对于线性回归，请参见 ESL 中的方程 7.21&lt; sup&gt;2）。但对于这种依赖究竟是如何在没有测试集标签的测试集文本上进行训练而产生的，我没有任何争论。
我的PCA实验结果对机器学习竞赛有重要意义：如果测试很少如果集合观测值和特征表现出高等级，那么可以通过在测试集特征上拟合 PCA 来人为地减少测试集上的误差。
我很好奇是否可以在 NLP 中观察到类似类型的结果，这是标准实践&lt; /a&gt; 在分类任务之前训练未标记文本的语言模型。3 我有一种感觉，部分答案就在论文的某个地方 关于因果和反因果学习4或其子数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响5。这些论文表明，领域适应应该只对文本导致目标的数据有帮助。
参考文献

亚历克斯、尼尔等人。 “RAFT：现实世界的少量文本分类基准。” arXiv 预印本 arXiv:2109.14076 (2021)。

Hastie、Trevor 等人。统计学习的要素：数据挖掘、推理和预测。卷。 2. 纽约：施普林格，2009 年。

Gururangan、Suchin 等人。 “不要停止预训练：使语言模型适应领域和任务。” arXiv 预印本 arXiv:2004.10964 (2020)。

Schölkopf、Bernhard 等人。 “关于因果学习和反因果学习。” arXiv 预印本 arXiv:1206.6471 (2012)。

金志敬，等。 “数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响。” arXiv 预印本 arXiv:2110.03618 (2021)。

莫斯科维奇、阿米特和萨哈龙·罗塞特。 “关于由于无监督预处理造成的交叉验证偏差。”英国皇家统计学会杂志 B 系列：统计方法 84.4 (2022)：1474-1502。

]]></description>
      <guid>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</guid>
      <pubDate>Tue, 04 Apr 2023 19:17:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么通过python库'stats.chi2_contigency'计算的卡方p值与通过手动方法计算的p值不同</title>
      <link>https://stats.stackexchange.com/questions/602954/why-p-values-of-chi-squared-calculated-through-python-library-stats-chi2-contig</link>
      <description><![CDATA[首先我计算了卡方 p 值
data = pd.crosstab(df[&#39;变量1&#39;],df[&#39;变量2&#39;])
chi2、p、dof、预期 = chi2_contingency(数据)

print(&quot;卡方统计量：&quot;, chi2)
print(&quot;p 值：&quot;, p)

卡方统计量：70.23601804402738；
p 值：2.893285699471121e-10；
自由度：12
然后我尝试使用以下代码手动计算
数据.值
观察值 = 数据.值
val = stats.chi2_contingency(数据)
chisq_stat、pvalue、df、预期 = chi2_contingency(观察值)
预期值 = val[3]
no_of_rows=len(data.iloc[0:4,0])
no_of_columns=len(data.iloc[0,0:5])
ddof=(行数-1)*(列数-1)
print(&quot;自由度:-&quot;,ddof)
阿尔法 = 0.05
chi_square=sum([(o-e)**2/e for o,e in zip(observed_values,expected_values)])
chi_square_statistic=chi_square[0]+chi_square[1]
打印（卡方）
print(&quot;卡方统计量:-&quot;,chi_square_statistic)
临界值=chi2.ppf(q=1-alpha,df=ddof)
打印（&#39;临界值：&#39;，临界值）
p_value=1-chi2.cdf(x=chi_square_statistic,df=ddof)
print(&#39;p 值：&#39;,p_value)
print(&#39;显着性水平：&#39;,alpha)
print(&#39;自由度: &#39;,ddof)

这些是上面代码的结果
卡方统计量：- 11.94630668094643；
临界值：21.02606981748307；
p 值：0.45000142553796574；
显着性水平：0.05；
自由度：12
我哪里做错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/602954/why-p-values-of-chi-squared-calculated-through-python-library-stats-chi2-contig</guid>
      <pubDate>Tue, 24 Jan 2023 09:27:26 GMT</pubDate>
    </item>
    </channel>
</rss>