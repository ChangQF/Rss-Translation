<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 09:17:37 GMT</lastBuildDate>
    <item>
      <title>为什么卡方检验的 p 值和 KS 检验的 p 值之间差异很大？</title>
      <link>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</link>
      <description><![CDATA[简介。我有数据，表示某个地理区域中哺乳动物的数量。我在这里展示了一个数据示例（有关更多信息，请参阅下面的代码）：
&gt;&gt; r1

500、1700、0、600、400、100、200、400、9700、4300、100 等。

我想使用双样本卡方检验和 KS 检验来比较两组哺乳动物的分布。
我能够重现与我的情况类似的情况，其中卡方检验的 p 值低于显着性水平 $\alpha = 0.05$，而 KS 检验的 p 值相当高（因此，两个 p 值非常不同）：
rng(0,&#39;twister&#39;);
a = 0;
b = 100;
bw = 100;
r1 = (b-a).*round(lognrnd(1,1,1000,1)) + a;
r2 = (b-a).*round(lognrnd(0.88,1.1,1000,1)) + a;
保持
h1 = histogram(r1,&#39;BinWidth&#39;,bw);
h2 = histogram(r2,&#39;BinWidth&#39;,bw);
la​​st_bin = 20;
[~,p_CS,~] = chi2gof(1:length(h1.Values(1:last_bin)), &#39;Expected&#39;, h2.Values(1:last_bin), &#39;Frequency&#39;, h1.Values(1:last_bin), &#39;EMin&#39;, 0)
[~,p_KS,~] = kstest2(r1,r2)
xlim([0 2000])

使用这个结果图和 p 值：

p_CS =
0.00029734

p_KS =
0.71613

问题。为什么卡方检验的 p 值和 KS 检验的 p 值之间会存在很大差异？
其他评论。我理解卡方检验“测量” 落入 bin“i” 的观测值数量（第一个数据集/分布）与预计落入 bin“i” 的观测值数量（第二个数据集/分布）之间的平方差，而 Kolmogorov-Smirnov 检验“测量”两个 ECDF 之间的最大距离。
也就是说，KS 检验“往往对分布中心比尾部更敏感”，但只是我的解释，卡方检验似乎对分布的每个“部分”都很敏感，因为观测值和预期值之间的平方差是针对分布的所有箱体计算的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</guid>
      <pubDate>Tue, 13 Aug 2024 09:08:18 GMT</pubDate>
    </item>
    <item>
      <title>在 KNN_classifier 中查找给定数据点 x 的 k 个最近邻居</title>
      <link>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</link>
      <description><![CDATA[在 python 中，knn 算法可以应用于训练数据，代码如下：
 from sklearn.neighbors import KNeighborsClassifier

KNN_classifier = KNeighborsClassifier(n_neighbors=k)
KNN_classifier.fit(X_train, y_train)
y_pred = KNN_classifier.predict(X_test)

现在对于给定的数据点 $x$，我想准确找到 knn 算法在学习过程中使用的 $x$ 的 $k$ 个邻居。是否可以访问给定数据点 $x$ 的邻居？如果有人能帮助我解决这个问题，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</guid>
      <pubDate>Tue, 13 Aug 2024 09:05:57 GMT</pubDate>
    </item>
    <item>
      <title>3PL IRT 方程和程序</title>
      <link>https://stats.stackexchange.com/questions/652700/3pl-irt-equation-and-program</link>
      <description><![CDATA[大家好，下面是我编写的一个程序，用于根据现有参数检查新分数 -
但我注意到不同的地方对 3PL 方程式的报告不同，例如
Wickepdia 说了一件事，而我的教科书说了另一件事 - 有人可以通过来源（自定义模型）确认 3PL 的适当公式吗？非常感谢？
library(ltm)
item_params &lt;- data.frame(
discrimination = c(1.01, 1.30, 1.43, 1.36, 1.13, 1.19, 1.04, 1.08, 1.69, 1.55, 1.18, 1.37, 1.24, 1.24, 1.43, 1.50, 1.34, 2.25, 1.92, 1.72, 1.43, 1.25, 2.35、1.32、1.66、1.98、1.67、1.14、1.36、1.35、1.34、1.05、1.54、2.02、1.28、1.62、2.24、1.23、2.11、1.93、1.91、2.81、1。 38、2.35、1.29、1.98、1.17、2.88、0.72、1.44、1.89、1.38、1.47、1.60、2.94、1.52、1.95、0.88、1.23、2.98、1.68、1.28、1.71、 2.32, 1.25, 1.54, 1.34, 1.85, 0.72, 1.34, 2.98, 1.06),
难度 = c(-5.67, -3.65, -3.04, -3.55, -3.49, -3.34, -5.18, -4.24, -3.38, -3.47, -3.39, -3.39, -2.64, -3.04, -3.49, -3.44, -2.69, -2.23, -2.76, -1.01, -1.17, -0.91, 0.17, -0.86, -0.36, -1.64, -1.05, -0.40, -0.86, -1.11, -0.48、-0.35、-1.06、1.36、-0.81、0.34、-1.94、0.64、-1.13、-0.68、0.17、-0.17、-0.35、-1.39、0.59、-0.76、-0.18、-0.67、0.34、1.58、-0。 60、-0.11、-0.14、0.15、0.53、1.54、-1.25、0.66、0.05、0.63、-0.21、-0.67、0.20、-0.34、0.11、-0.29、1.25、1.19、0.63、0.21、1.14、 -1.94)，
猜测 = c(0.00, 0.00, 0.15, 0.00, 0.00, 0.19, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.01, 0.08, 0.49, 0.12, 0.35, 0.40, 0.25, 0.28, 0.30, 0.47, 0.41, 0.36, 0.38, 0.24, 0.15, 0.14, 0.34, 0.29, 0.37, 0.47, 0.20, 0.30, 0.00, 0.23, 0.40, 0.40, 0.19, 0.26, 0.27, 0.50, 0.32, 0.31, 0.33, 0.35, 0.35, 0.27, 0.23, 0.40, 0.33, 0.30, 0.18, 0.34, 0.30, 0.24, 0.35, 0.27, 0.57, 0.38, 0.27, 0.44, 0.21, 0.50, 0.22, 0.19, 0.45, 0.25, 0.35)
)
response_data &lt;- matrix(
c(
# 第一受访者的答复
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,0,1,0,1,0,1,1,1,0,
# 第二位受访者的答复
1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,
# 第三位受访者的响应
1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,0,1,1,0,1,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,0
), nrow = 3, byrow = TRUE
)
custom_model &lt;- function(theta, params) {
a &lt;- params$discrimination
b &lt;- params$difficulty
c &lt;- params$guessing
P &lt;- c + ((1 - c) /(1 + exp(-a * (theta - b))))
return(P)

estimate_theta &lt;- function(response, item_params) {
theta_values &lt;- seq(-4, 4, by = 0.1)
likelihoods &lt;- sapply(theta_values, function(theta) {
probs &lt;- custom_model(theta, item_params)
likelihood &lt;- prod(probs^response * (1 - probs)^(1 - response))
return(likelihood)
})
best_theta &lt;- theta_values[which.max(likelihoods)]
return(best_theta)

theta_scores &lt;- apply(response_data, 1,estimate_theta, item_params) = item_params)
打印(theta_scores)]]></description>
      <guid>https://stats.stackexchange.com/questions/652700/3pl-irt-equation-and-program</guid>
      <pubDate>Tue, 13 Aug 2024 08:56:21 GMT</pubDate>
    </item>
    <item>
      <title>损失函数收敛于零？</title>
      <link>https://stats.stackexchange.com/questions/652699/a-loss-function-converges-to-zero</link>
      <description><![CDATA[背景：我正在阅读一篇很长的论文（链接），该论文介绍了分位数回归，该论文在该领域使用了迁移学习方法。该方法的一个关键部分是避免负迁移——当您有一个新的源数据集时，您必须测量源数据和目标数据之间的“距离”。如果两个数据相对“相似”，则可以使用源数据来提高目标统计问题的估计性能。因此，作者提供了一种数据导出方法来识别可转移集并建立一致性理论，证明了我们可以正确地选择“相似”的源数据集。
证明过程：在第 104 页的证明中，作者显示
$$
\begin{aligned}
&amp; P\left(\varepsilon_0 L_0\left(\widehat{\boldsymbol{\beta}}_{\text {lasso }}, \mathcal{V}_{\text {te }}\right) \geq \min \left\{\frac{\kappa_0}{4}\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2^2, \frac{3 \kappa_0^3}{16 m_0}\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2\right\}\right。\\
&amp; -c_3\left(\sqrt{\frac{s^{\prime} \log p}{n_k+n_0}}+\sqrt{h^{\prime}}\left(\frac{\log p}{n_k+n_0}\right)^{1 / 4}\right)\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2 \\
&amp; -c_3\left(\sqrt{\frac{s^{\prime} \log p}{n_k+n_0}}+\sqrt{h^{\prime}}\left(\frac{\log p}{n_k+n_0}\right)^{1 / 4}+\sqrt{\frac{s_0 \log p}{n_0}}\right)^2 \\
&amp; \left.-c_3 \sqrt{\frac{\log p}{n_0}}\left(s^{\prime} \sqrt{\frac{\log p}{n_k+n_0}}+h^{\prime}+s_0 \sqrt{\frac{\log p}{n_0}}+\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_1\right)\right) \\
&amp; +\frac{1}{p^2}+\frac{14+2 C_2}{p} 
\end{aligned}
$$
收敛到零。并且条件为
$$
\max \left\{\frac{s_0 \log p}{n_0}, s^{\prime} \sqrt{\frac{\log p}{n_0}} \sqrt{\frac{\log p}{n_k+n_0}}, h^{\prime} \sqrt{\frac{\log p}{n_0}}, \varepsilon_0\right\} \lesssim \min \left\{\frac{n_k^2 h^2}{\left(n_0^2+n_k^2\right)\left(s_0+s^{\prime}\right)}, \frac{n_k h}{\left(n_0+n_k\right) \sqrt{s_0+s^{\prime}}}\right\},
$$
( RHS 是关于 $|\beta_{k}^{\star}-\beta_0|_2 \ge \frac{2n_k\lambda h}{(n_0m_0 B^2 +2n_k \lambda)\sqrt{s_0+s\prime}}$，已在 第 99 页引理 c.3 中证明)
我们有
$$
\begin{aligned}
&amp; c_3\left(\sqrt{\frac{s^{\prime} \log p}{n_k+n_0}}+\sqrt{h^{\prime}}\left(\frac{\log p}{n_k+n_0}\right)^{1 / 4}\right)\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2 \\
&amp; +c_3\left(\sqrt{\frac{s^{\prime} \log p}{n_k+n_0}}+\sqrt{h^{\prime}}\left(\frac{\log p}{n_k+n_0}\right)^{1 / 4}+\sqrt{\frac{s_0 \log p}{n_0}}\right)^2 \\
&amp; +c_3 \sqrt{\frac{\log p}{n_0}}\left(s^{\prime} \sqrt{\frac{\log p}{n_k+n_0}}+h^{\prime}+s_0 \sqrt{\frac{\log p}{n_0}}+\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_1\right)+\varepsilon_0 L_0\left(\widehat{\boldsymbol{\beta}}_{\text {lasso }}, \mathcal{V}_{\text {te }}\right) \\ 
&amp; \leq \min \left\{\frac{\kappa_0}{8}\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2^2, \frac{3 \kappa_0^3}{32 m_0}\left|\boldsymbol{\beta}_k^*-\boldsymbol{\beta}_0\right|_2\right\} \\
\end{aligned}
$$
当$n_k, n_0, p$足够大时。 $L_0(\beta; \mathcal{A})= \frac{1}{|\mathcal{A}|}\sum \rho_{\tau}(Y_{0i}-Z_{0i}^{T}\beta)$ 是分位数损失函数。(第 22 页)
我的问题：这是我对证明最后一部分的理解：当 $n_k$ 趋于无穷大时，LHS 中的每个项都非常小。同时，RHS 也趋于零，但在规定条件下，它们略大于不等式的 LHS。
我对术语 $\varepsilon_0 L_0\left(\widehat{\boldsymbol{\beta}}_{\text {lasso }}, \mathcal{V}_{\text {te }}\right)$ 感到困惑，其中 $\varepsilon_0$ 是有界的。根据我之前的理解，$L_0$ 必须足够小，并且 $\varepsilon_0 L_0\left(\widehat{\boldsymbol{\beta}}_{\text {lasso }}, \mathcal{V}_{\text {te }}\right)$ 项是可以控制的。当 $n_k,n$ 趋于无穷大时，$L_0$ 会趋于零吗？
这是一个很长的问题，提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/652699/a-loss-function-converges-to-zero</guid>
      <pubDate>Tue, 13 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>时间序列季节性分析-评分方法</title>
      <link>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</link>
      <description><![CDATA[我正在研究时间序列中的季节性搜索，并希望使用序列中的符号来自动化该过程，而无需手动检查曲线。我建议评估季节性的三个分数是：
季节性强度：使用 Python 的 STL 分解 (LOESS) 后，我恢复了三个组成部分：趋势、季节性和残差。我测量了季节性成分相对于噪声的方差比例。我使用 STL 参数“周期”的不同值进行迭代。
季节性相似性：使用季节性成分，我比较季节性子周期以检查从一个时期到另一个时期的模式一致性。
季节性模式：分析季节性成分子周期之间模式（上升/下降）的重复性，以评估季节性的稳定性。
我将这 3 个分数与 python 的分解 STL（来自 statsmodels.tsa.seasonal 导入 STL）结合使用，并使用参数“period”定义季节性周期，然后我检索分数。
您认为这些符号与自动搜索季节性一致吗？您知道其他有效的方法吗？也许是分类方法？我希望能够从不同的数据细分（每周、每月、每季度）中了解每个细分的最强季节性周期。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</guid>
      <pubDate>Tue, 13 Aug 2024 08:33:48 GMT</pubDate>
    </item>
    <item>
      <title>野生引导标准误差与分析 HAC 标准误差的收敛</title>
      <link>https://stats.stackexchange.com/questions/652695/convergence-of-wild-bootstrap-standard-error-to-analytical-hac-standard-error</link>
      <description><![CDATA[我目前正在估计局部投影回归，一个众所周知的问题是需要校正自相关残差。因此，我使用 Newey-West HAC 估计量来计算标准误差。
对于同一项目的另一部分，我需要使用引导标准误差，我目前正在测试野生依赖引导Davidson 和 Monticini (2014)。
具体来说，他们的论文提出了野生标准引导技术作为 Newey-West 估计量的引导版本（就像野生引导是 Eicker-White 方法的引导等效物一样）。 我的问题是，在有限样本中，我们是否应该预期随着引导重复次数趋近于无穷大，野生引导 SE 会收敛到（或至少近似一致）Newey-West SE？假设相同的大小相当大（&gt; 500）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652695/convergence-of-wild-bootstrap-standard-error-to-analytical-hac-standard-error</guid>
      <pubDate>Tue, 13 Aug 2024 06:01:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用统计测试比较多个列表中各个项目的排名？</title>
      <link>https://stats.stackexchange.com/questions/652692/how-to-compare-ranks-for-individual-items-across-multiple-lists-using-statistica</link>
      <description><![CDATA[我有多个针对相同项目的排名列表，我想比较特定项目在两个列表子集中的排名并评估统计意义，我应该使用哪些统计测试？我可以简单地对排名进行 t 检验吗，尽管它们的分布不正常？
例如，在虚拟数据集 df 中：
&gt; set.seed(123)
&gt; df &lt;- data.frame(replicate(n = 6, expr = sample(1:10, 10, replace = FALSE)))
&gt; rownames(df) &lt;- paste0(&quot;Item&quot;, LETTERS[1:10])

&gt; df
X1 X2 X3 X4 X5 X6
ItemA 3 10 8 7 7 2
ItemB 10 5 7 5 5 1
ItemC 2 3 2 4 10 9
ItemD 8 8 1 10 9 3
ItemE 6 1 6 2 3 8
ItemF 9 4 3 9 1 5
ItemG 1 6 4 3 2 7
ItemH 7 9 10 1 8 6
ItemI 5 7 9 8 6 4
ItemJ 4 2 5 6 4 10

我想查看两个子集（列 1、2、3 与列 4、5、6）之间 ItemF 的排名是否不同。我可以这样做吗：
&gt; t.test(df[&quot;ItemF&quot;, 1:3], df[&quot;ItemF&quot;, 4:6])

Welch 双样本 t 检验

数据：df[&quot;ItemF&quot;, 1:3] 和 df[&quot;ItemF&quot;, 4:6]
t = 0.11251，df = 3.823，p 值 = 0.9161
备择假设：均值的真实差异不等于 0
95% 置信区间：
-8.044952 8.711619
样本估计值：
x 的均值 y 的均值
5.333333 5.000000
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652692/how-to-compare-ranks-for-individual-items-across-multiple-lists-using-statistica</guid>
      <pubDate>Tue, 13 Aug 2024 03:18:05 GMT</pubDate>
    </item>
    <item>
      <title>哪种拟合优度检验适合检验大小为一的样本？</title>
      <link>https://stats.stackexchange.com/questions/652682/which-goodness-of-fit-test-to-test-a-sample-of-size-one</link>
      <description><![CDATA[我有一个 1 到 16 范围内的整数样本。它们是从某个未指定的分布中独立同分布抽取的。如果我再得到一个从可能不同的分布中独立抽取的整数，那么什么样的拟合优度检验可以拒绝原假设，即它与第一组整数来自相同的分布？
我考虑过使用卡方检验，但我不知道当第二个样本大小为 1 时这是否合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/652682/which-goodness-of-fit-test-to-test-a-sample-of-size-one</guid>
      <pubDate>Mon, 12 Aug 2024 21:22:04 GMT</pubDate>
    </item>
    <item>
      <title>我需要知道此代码中的第 3 步是否正确[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652671/i-need-to-know-if-step-3-in-this-code-is-correct</link>
      <description><![CDATA[我是 R 新手，我正在尝试使用 ltm 包从 72 项集（来自这篇已发表的论文）中获取一些 IRT 参数（a、b、g）
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4461534/#:~:text=The%20CFMT%20uses%20a%20three,be%20selected%20among%20two%20distractors（见表4)
下面是我的代码……它看起来似乎在做一些合理的事，但我需要一个绝地武士来检查我是否在这里没有脱离正轨。
library(ltm)

# 步骤 1：定义先前估计的项目参数
item_params &lt;- data.frame(
discriminator = c(1.01, 1.30, 1.43, 1.36, 1.13, 1.19, 1.04, 1.08, 1.69, 1.55, 1.18, 1.37, 1.24, 1.24, 1.43, 1.50, 1.34, 2.25, 1.92, 1.72, 1.43, 1.25, 2.35, 1.32, 1.66、1.98、1.67、1.14、1.36、1.35、1.34、1.05、1.54、2.02、1.28、1.62、2.24、1.23、2.11、1.93、1.91、2.81、1.38、2.35、1。 29、1.98、1.17、2.88、0.72、1.44、1.89、1.38、1.47、1.60、2.94、1.52、1.95、0.88、1.23、2.98、1.68、1.28、1.71、2.32、 1.54, 1.34, 1.85, 0.72, 1.34, 2.98, 1.06),
难度 = c(-5.67, -3.65, -3.04, -3.55, -3.49, -3.34, -5.18, -4.24, -3.38, -3.47, -3.39, -3.39, -2.64, -3.04, -3.49, -3.44, -2.69, -2.23, -2.76, -1.01, -1.17, -0.91, 0.17, -0.86, -0.36, -1.64, -1.05, -0.40, -0.86, -1.11, -0.48, -0.35, -1.06, 1.36, -0.81, 0.34, -1.94, 0.64, -1.13, -0.68, 0.17, -0.17, -0.35, -1.39, 0.59, -0.76, -0.18, -0.67, 0.34, 1.58, -0.60, -0.11, -0.14, 0.15, 0.53, 1.54, -1.25, 0.66, 0.05, 0.63, -0.21, -0.67, 0.20, -0.34, 0.11, -0.29, 1.25, 1.19, 0.63, 0.21, 1.14, -1.94),
猜测 = c(0.00, 0.00、0.15、0.00、0.00、0.19、0.00、0.00、0.00、0.00、0.00、0.01、0.00、0.00、0.00、0.01、0.08、0.49、0.12、0.35、0.40、0。 25、0.28、0.30、0.47、0.41、0.36、0.38、0.24、0.15、0.14、0.34、0.29、0.37、0.47、0.20、0.30、0.00、0.23、0.40、0.40、0.19、 0.26, 0.27, 0.50, 0.32, 0.31, 0.33, 0.35, 0.35, 0.27, 0.23, 0.40, 0.33, 0.30, 0.18, 0.34, 0.30, 0.24, 0.35, 0.27, 0.57, 0.38, 0.27, 0.44, 0.21, 0.50, 0.22, 0.19, 0.45, 0.25, 0.35)
)

# 步骤 2：创建三个不同样本答案的矩阵（1 表示正确，0 表示不正确）
response_data &lt;- matrix(
c(
# 第一位受访者的答案
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,1,1,0,1,0,1,1,1,0,
# 第二位受访者的回答
1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,
# 第三位受访者的回答
1,1,1,1,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1
), nrow = 3, byrow = TRUE
)

# 步骤 3：使用给定的项目参数设置 IRT 模型
custom_model &lt;- function(theta, params) {
a &lt;- params$discrimination
b &lt;- params$difficulty
c &lt;- params$guessing
P &lt;- c + (1 - c) / (1 + exp(-a * (theta - b)))
return(P)
}

# 使用 MLE（最大似然估计）估计每个受访者的 theta
estimate_theta &lt;- function(response, item_params) {
theta_values &lt;- seq(-4, 4, by = 0.1)
likelys &lt;- sapply(theta_values, function(theta) {
probs &lt;- custom_model(theta, item_params)
likely &lt;- prod(probs^response * (1 - probs)^(1 - response))
return(likelihood)
})
best_theta &lt;- theta_values[which.max(likelihoods)]
return(best_theta)
}

# 步骤 4：计算所有受访者（三名参与者）的 IRT 量表分数
theta_scores &lt;- apply(response_data, 1,estimate_theta,item_params = item_params)

# 输出估计的 theta 分数
print(theta_scores)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652671/i-need-to-know-if-step-3-in-this-code-is-correct</guid>
      <pubDate>Mon, 12 Aug 2024 17:41:34 GMT</pubDate>
    </item>
    <item>
      <title>两种荟萃分析方法：哪一种更可取？</title>
      <link>https://stats.stackexchange.com/questions/652670/two-ways-of-meta-analysis-which-one-is-preferred</link>
      <description><![CDATA[假设我有 $k=1, 2, 3...K$ 项研究，其中连续自变量 $Y$ 和因变量 $X$ 为同一组。研究之间的效果可能不同，我想进行荟萃分析。
我知道的一种方法是进行回归分析。我可以创建一个 $(K-1)$ 维虚拟变量 $Z$，并运行具有随机效果的线性回归。如果 $j$ 是研究指标，$i$ 是样本指标：
$$Y_{ij}=\beta X_{ij}+\gamma_j Z_{ij}+\epsilon$$
$$\gamma_j\sim N(0,\tau^2)$$
$$\epsilon\sim N(0,\sigma^2)$$
或者如果研究不多，我可以做一个固定效应模型：
$$Y_{ij}=\beta X_{ij}+\beta_j Z_{ij}+\epsilon$$
$$\epsilon\sim N(0,\sigma^2)$$
但是，我也看到了对每项研究单独进行分析并计算对数 p 值的加权平均值（可能按样本量或样本量的平方根加权）的做法，如以下线程所示：
组合 p 值时，为什么不直接取平均值？
我是元分析的新手。有人可以给我简单介绍一下哪种方法更可取吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652670/two-ways-of-meta-analysis-which-one-is-preferred</guid>
      <pubDate>Mon, 12 Aug 2024 17:26:34 GMT</pubDate>
    </item>
    <item>
      <title>“正弦”激活对于重建/隐式映射以外的任务有用吗？</title>
      <link>https://stats.stackexchange.com/questions/652669/are-sine-activations-useful-for-tasks-other-than-reconstruction-implicit-map</link>
      <description><![CDATA[这篇文章询问了在神经网络中使用sine激活的问题。
2020 年的一篇有趣的论文 (SIREN)使用激活来完成一些任务。本网站中也有作者编写的节选版。
据我所知，这些是重建任务，即不是标准计算机视觉、NLP 等任务。
我的理解也基于Reddit 上的这条评论。
显然，该领域被称为隐式神经表征，它们对单个信号样本进行了过度拟合；例如将图像中的 x,y 坐标映射到像素，这是 隐式 部分。
由此，它们是否有助于重建图像或音频的部分或任何输入信号？作者似乎表明他们可以对输入进行编码（以某种方式过度拟合）。

对此的解释是否正确？
如前所述，正弦激活实际上并未用于/用于标准机器学习任务，对吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652669/are-sine-activations-useful-for-tasks-other-than-reconstruction-implicit-map</guid>
      <pubDate>Mon, 12 Aug 2024 16:46:24 GMT</pubDate>
    </item>
    <item>
      <title>由指数和确定的概率数值稳定对数概率</title>
      <link>https://stats.stackexchange.com/questions/652651/probability-determined-from-sum-of-exponentials-numerically-stable-log-probabili</link>
      <description><![CDATA[在这个问题中，我问：
如果我们有：$\tau_i \overset{\text{independent}}{\sim}
\exp(\lambda_i)$，对于$i=1,2,3,...,n$，其中$\lambda_i\neq \lambda_j, \forall i\neq j$，那么我想找到概率的一般形式：
$$
\text{Pr}(\sum_{i=1}^{n-1} \tau_i \leq t, \sum_{i=1}^{n} \tau_i &gt; t)
$$
我收到了 Ben 的回答：
$$
\sum_{i=1}^{n-1} m_{n,i} \cdot [ \exp (- \lambda_i t) - \exp (- \lambda_n t) ],
$$
其中术语 $m_{n,j}$ 定义为如：
$$
m_{n,i} = \frac{\lambda_i}{\lambda_n} \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i}。
$$
我发现，当 $n$ 相当大（甚至高于 10）时，上述规则计算出的概率在计算上可能会变为负数。即由于 $m_{n,i}$ 既可以为正数也可以为负数，因此计算的精度对于确保概率为正数非常重要。
我想知道是否有一种计算稳定的方法来计算 对数概率？
注意：我意识到 $m_{n,i}$ 的一部分就是所谓的 拉格朗日多项式：
$$
l_j(0) := \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i},
$$
其确实有一个稳定的形式定义在这里。不过，我试过了，对于中等大小的 n，我仍然会得到负概率。这也是我希望找到对数概率更稳定表达式的部分原因；使用对数概率也更方便，因为我正在做使用这个的 MCMC。
注意：使用这里设计的一些用于稳定和对数的巧妙解决方案并不简单，因为$m_{n,i}$ 可能是负数。]]></description>
      <guid>https://stats.stackexchange.com/questions/652651/probability-determined-from-sum-of-exponentials-numerically-stable-log-probabili</guid>
      <pubDate>Mon, 12 Aug 2024 13:33:50 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险 - 加权人群中的累积发生率</title>
      <link>https://stats.stackexchange.com/questions/652642/competing-risk-cumulative-incidence-in-a-weighted-population</link>
      <description><![CDATA[我有以下已根据倾向得分加权的数据。

模型中唯一感兴趣的独立变量是 treat，因为协变量已使用权重进行平衡。
感兴趣的事件是疾病。

竞争风险是死亡。

因此，event == 0（审查），event == 1（疾病），event == 2（死亡）。
library(cobalt)
library(cmprsk)
library(survminer)

set.seed(123)
lalonde &lt;- cbind(lalonde,
event = sample(c(0, 1), size = 614, replace = TRUE, prob = c(0.84, 0.16)),
time = runif(614, min = 10, max = 365))
n &lt;- ceiling(0.05 * nrow(lalonde)) 
selected_indices &lt;- sample(1:nrow(lalonde), size = n)
lalonde[selected_indices, &quot;event&quot;] &lt;- 2

formula &lt;- treat ~ age + educ + race + marriage + nodegree + re74 + re75 + re78

# PS
lalonde$pscore &lt;- glm(formula, data = lalonde,
family = binomial(link = &quot;logit&quot;))$fitted.values

# Weights
lalonde$weight &lt;- ifelse(lalonde$treat == 1,
pmin(lalonde$pscore, 1 - lalonde$pscore) / lalonde$pscore,
pmin(lalonde$pscore, 1 - lalonde$pscore) / (1 - lalonde$pscore))


如果没有权重，我会计算并绘制如下：
cr &lt;- cuminc(ftime = lalonde$time,
fstatus = lalonde$event, 
cencode = 0,
group = lalonde$treat)

p &lt;- ggcompetingrisks(fit = cr, 
multiple_panels = F, 
xlab = &quot;Days&quot;, 
ylab = &quot;Cumulative事件发生率&lt;,
title = &quot;竞争风险分析&quot;) 

由于我对调整竞争风险后的事件感兴趣，因此我排除了竞争风险的曲线：
p$data &lt;- p$data[p$data$event == 1, ]

p + labs(colour = &quot;Group&quot;) 

结果为：

问题：

这怎么可能来解释权重？
也许有解决方法？
我无法想象它会强迫某人使用匹配而不是加权，因为没有参数使用 cuminc 来实现权重。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652642/competing-risk-cumulative-incidence-in-a-weighted-population</guid>
      <pubDate>Mon, 12 Aug 2024 09:07:17 GMT</pubDate>
    </item>
    <item>
      <title>样本方差的渐近分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652639/asymptotic-distribution-in-sample-variance</link>
      <description><![CDATA[如何证明正确的样本方差是渐近正态的？]]></description>
      <guid>https://stats.stackexchange.com/questions/652639/asymptotic-distribution-in-sample-variance</guid>
      <pubDate>Mon, 12 Aug 2024 08:24:31 GMT</pubDate>
    </item>
    <item>
      <title>估计偏好率</title>
      <link>https://stats.stackexchange.com/questions/652550/estimating-preference-rate</link>
      <description><![CDATA[我提供在线服务，想确定人们选择我的服务的频率与选择我的竞争对手的频率相比如何。为了估算这一点，我有一些数据可以跟踪用户何时看到服务列表以及他们选择哪种服务。这些数据来自各种来源（供应商）。因此，我可以计算特定来源的偏好率。
我收集的数据是用户级别的，按日期组织。这是一个架构：
date, source, cust_id, os, democratics, #_my_service_chosen, #total_services_availaed
1/6, s1, 101, iOS, US, 7, 10
2/6, s1, 107, iOS, US, 3, 10
:::
8/6, s4, 707, iOS, UK, 13, 20

但是，我知道我的数据来源并不详尽，只覆盖了我整个用户群的 20% 左右。此外，数据存在偏差：来源 1 (s1) 约占样本的 80%，而其他来源仅占 5%。
现在考虑到这种表示偏差，样本覆盖率较低（20%）；我如何才能可靠地估计人口偏好率？
我已经尝试过的方法：

使用引导抽样进行基线估计。
将抽样组合简单投影到人口

我还可以探索哪些其他方法？我对贝叶斯方法还不熟悉，正在考虑贝叶斯分层模型，但考虑到我有大约 500 万条记录，在客户级别应用该方法是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/652550/estimating-preference-rate</guid>
      <pubDate>Fri, 09 Aug 2024 16:59:00 GMT</pubDate>
    </item>
    </channel>
</rss>