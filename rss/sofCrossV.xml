<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Jun 2024 09:16:35 GMT</lastBuildDate>
    <item>
      <title>合成控制方法中无与伦比的预处理趋势</title>
      <link>https://stats.stackexchange.com/questions/649162/unparallel-pre-treatment-trends-in-synthetic-control-method</link>
      <description><![CDATA[我正在使用 R 包 Synth 运行合成控制模型，其中包含 44 个季度（36 个处理前和 8 个处理后）200 个地区的犯罪数据。我的模型包括几个社会人口变量（例如，总人口、平均年龄、男性比例、平均收入）和总犯罪作为结果变量。
但是，处理单元和合成单元的趋势并不平行，这与文章中经常看到的近乎完美的模仿不同。这是我的数据中的样子：

我的主要问题是：这足以进行有效的比较吗？如果没有，我该如何改进？
例如，我是否应该考虑在捐赠者池中使用更少的控制单元，如果是，基于哪些标准？
我应该注意，我尝试使用犯罪率（每 1,000 名居民）以及犯罪率的移动平均值（试图“平滑”趋势），但没有帮助。
任何建议都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649162/unparallel-pre-treatment-trends-in-synthetic-control-method</guid>
      <pubDate>Thu, 13 Jun 2024 08:48:13 GMT</pubDate>
    </item>
    <item>
      <title>使用引导独立时间序列构建预测区间是否有效？</title>
      <link>https://stats.stackexchange.com/questions/649161/is-bootstrapping-independent-time-series-to-construct-prediction-intervals-valid</link>
      <description><![CDATA[问题：
我有一个由多个单变量时间序列组成的数据集，每个时间序列代表随时间变化的独立保险索赔金额序列。我的目标是使用 LSTM 模型预测未来的索赔金额。
鉴于经典的引导方法由于时间依赖性而不直接适用于时间序列数据，我正在考虑以下方法：

每个索赔被视为彼此独立，因此每个单变量时间序列都是独立的。

通过随机选择整个单变量时间序列并替换来创建引导样本（我的数据包含超过一百万个索赔序列）。

在每个引导数据集上训练 LSTM 模型。

对所有 LSTM 模型的预测取平均值以获得最终预测并创建置信区间。


我的问题是：这种方法在统计上有效吗？如果有效，为什么？
其他详细信息：
每个单变量时间序列都假定独立于其他时间序列（例如，来自不同客户或保单的索赔）。
通过对整个时间序列进行重新采样，我旨在保留每个序列内的时间依赖性。
目标是利用引导方法来减少方差并提高 LSTM 预测的稳健性并了解不确定性。
如果您能提供关于此方法有效性的任何见解或参考，以及它是否能适当地解决时间序列数据背景下引导的挑战，我将不胜感激。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649161/is-bootstrapping-independent-time-series-to-construct-prediction-intervals-valid</guid>
      <pubDate>Thu, 13 Jun 2024 06:04:16 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    <item>
      <title>您能在一般加法模型中使用百分比作为因变量吗？</title>
      <link>https://stats.stackexchange.com/questions/649157/can-you-use-a-percentage-as-the-dependent-variable-in-general-additive-models</link>
      <description><![CDATA[这更像是一个关于统计建模的一般问题，而不是一个项目特定的问题。
在广义加性模型 (GAM) 中，因变量可以是百分比吗？如果因变量是百分比，我需要为自变量使用特定的基础吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649157/can-you-use-a-percentage-as-the-dependent-variable-in-general-additive-models</guid>
      <pubDate>Thu, 13 Jun 2024 05:19:48 GMT</pubDate>
    </item>
    <item>
      <title>最不坏的逐步程序</title>
      <link>https://stats.stackexchange.com/questions/649156/least-bad-stepwise-procedure</link>
      <description><![CDATA[我非常清楚逐步回归导致的问题。我想通过特定情况下的模拟来演示其中的一些问题。
我正在考虑一个回归，其中我有一些感兴趣的分类变量，然后是一些协变量。我假设这些协变量的某些组合很重要，并且逐步选择将选择出它们的良好组合（可能不是，但我希望在模拟中显示失败）。
但是，如果我只是运行正常的逐步回归，如 MASS:stepAIC，则存在不包括原始感兴趣的分类变量的风险。
我理想情况下想要做的是只对协变量运行逐步选择，然后找到最终测试的 t 统计量（在逐步消除或包含之后）对原始感兴趣的分类变量，就好像我从一开始就使用该模型一样，但如果完全排除该变量，则不会有 t 统计量。
补救措施是什么？当然，我可以编写自己的不考虑特定变量的逐步选择算法，但我甚至不完全确定如果“正确”的逐步消除步骤是删除感兴趣的主要变量，我会怎么做。我的向后消元法就到此结束了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649156/least-bad-stepwise-procedure</guid>
      <pubDate>Thu, 13 Jun 2024 05:19:27 GMT</pubDate>
    </item>
    <item>
      <title>按实际收入匹配与按意外收入类型匹配</title>
      <link>https://stats.stackexchange.com/questions/649154/matching-on-actual-earnings-versus-matching-on-the-kind-of-unexpectedness-in-ear</link>
      <description><![CDATA[为简单起见，我们假设这是一个关于线性建模的问题，尽管我实际上正在研究一些非线性模型，并且愿意考虑其他模型，如果它们更有利的话。
我有大量短期、重叠的两年面板。我想将它们粘合在一起，以便创建一个持续时间更长的合成面板，用于研究收入动态和一生或十年的收入不平等。为此，我需要将一个面板第二年的家庭或个人与下一个面板第一年的家庭或个人联系起来。在面板中，我有关于哪些家庭或个人匹配（大多数年份）的数据信息，尽管搬入或搬出该地区的人可能不会被分配匹配。我希望匹配在经济行为和结果上与匹配的经济相似。
作为初步事项，我为每个样本面板年构建了 Mincer 方程，根据教育和培训历史以及人口统计特征预测收入。然而，在其他特征上匹配的个人的收入（对数收入）存在相当大的差异。此外，我已经确定这些错误具有高度持久性。所以我想我会把预测收入与实际收入的比率扔进我的匹配算法中，让最小二乘法来解决它。
但后来我想，既然我可以在匹配中使用的相似性算法中使用实际收入，为什么要使用这个比率作为预测因子。虽然这两种方法似乎选择了相似的人作为匹配，但几乎所有匹配产生的实际配对都会发生变化。
从那时起，我就一直在兜圈子，反复改变主意。最后，我想我应该问那些真正了解这种模型的人。因此我向你们求助。
救命！]]></description>
      <guid>https://stats.stackexchange.com/questions/649154/matching-on-actual-earnings-versus-matching-on-the-kind-of-unexpectedness-in-ear</guid>
      <pubDate>Thu, 13 Jun 2024 01:53:47 GMT</pubDate>
    </item>
    <item>
      <title>我如何将家庭分配到与成对距离测量一致的社会空间坐标？</title>
      <link>https://stats.stackexchange.com/questions/649151/how-can-i-assign-households-to-coordinates-in-a-social-space-consistent-with-pai</link>
      <description><![CDATA[如何将家庭分配到与成对距离测量一致的社会空间坐标？
我有一个定义不太明确的问题，关于创建一个有趣且有用的社会距离测量。
过去已经这样做过，例如，将社会经济地位压缩为一个维度。然而，在这种情况下，虽然他们想要一个内部一致的指标，但我认为他们同样有兴趣创建一个符合他们直觉的指标，而我希望由数据引导，而不是引导数据。这是许多人面临的一种问题，我认为对问题更清晰的定义和技术解决方案是相辅相成的。
我有很多测量人物特征的向量。我还有一个基于相似性的有意义但嘈杂的成对距离测量。我可以将每个特征分配给一个维度，然后定位这些点，但对于我的目的而言，这些位置没有用。只有点之间的距离才重要。为了回答这个问题，假设距离测量有意义，或者让我担心如何构建距离。
我对大约 180 个特征进行了测量。有些是连续的，具有有意义的差异和比率。其他是分类的，这就是我犹豫是否使用 PCA 的原因。我目前倾向于使用 Jaccard 度量将分类差异转换为差异度量，从而转换为距离度量。我正在寻找一种方法来减少与距离测量一致的维度。一旦我将数据尽可能地扁平化，我就会寻找有趣的特征、关系和形状，并使用一种方法让数据说话，而无需在其上施加线性模型。例如，我想尝试几种拓扑数据分析方法，如持久同源性。
多年来，我所做的大多数统计分析都是计量经济学或计量经济学衍生的，并且几乎完全由线性回归的变体组成。过去，当我谈到非线性模型时，我通常指的是对数线性的模型，或包括二次项和交互项等。走出那个领域让人感到兴奋又有点害怕。我不会想到有实用的技术可以在数据中查找形状，而无需明确说明允许什么样的形状。
如果我可以分配与我的距离测量一致的点位置，那将非常方便。为了获得洞察力和数据可视化，我希望使用尽可能少的维度。我如何——根据什么标准——确定我需要多少个维度？
一方面，我容忍的错误越少，需要的维度就越多。当某些点与其他两个点之间的距离比其他点之间的距离更远时，将更大的距离扩展到另一个维度可以避免违反三角不等式。如果三角不等式有很多大的违反，那么空间位置可能不是社会地位或社会距离的有用类比。知道它是否是本身就很有趣。但是因为我的距离测量值很嘈杂，所以如果这意味着我可以将数据压缩为更少的维度，那么允许对距离进行一些细微的调整是有意义的。
一旦我有了多个维度，我想为每个点对找到一组与该维度数和我的距离测量值一致的坐标。我不关心点云的旋转或平移，并且乐于使用任何方便的方法。有人能建议一种可以做到这一点的技术吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649151/how-can-i-assign-households-to-coordinates-in-a-social-space-consistent-with-pai</guid>
      <pubDate>Thu, 13 Jun 2024 00:43:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么维数会影响完全条件独立 (FullCI) 检验中的显著性和效应大小？</title>
      <link>https://stats.stackexchange.com/questions/649147/why-does-dimensionality-affect-significance-and-effect-size-in-a-full-conditiona</link>
      <description><![CDATA[2018 年 Runge 等人的论文“检测大型非线性时间序列数据集中的因果关联” 描述了 PCMCI 方法。它将新的 PCMCI 方法与他们称之为完全条件独立性测试 (FullCI) 的另一种方法进行了比较。FullCI 的工作原理是测试以所有其他变量为条件的两个变量之间的独立性（如果我理解正确的话，它就像是 PC 的强力版本）。
他们通过使用 FullCI 来测试天气模式（$Nino$）和不列颠哥伦比亚省地表温度（$BCT$）之间的因果关系，强调了 PCMCI 的必要性。首先，他们使用 FullCI 测试（并正确找到）链接 $Nino \rightarrow BCT$。然后，他们添加一个变量 $Z$，该变量由 $Nino + \mu $ 驱动，存在一些滞后，其中 $\mu$ 是噪声。重要的是，$Z$ 不会影响 $BCT$。
添加 $Z$ 会导致 $Nino \rightarrow BCT$ 关系的影响和重要性降低。他们通过指出$Z$将“解释”$BCT$的部分影响来解释这种减少的部分原因，因为它将成为条件集的一部分，这对我来说很有意义。但他们也指出，重要性降低的部分原因是维数增加。
为什么/如何维数会降低这种“FullCI”方法确定的因果关系的影响大小/重要性？]]></description>
      <guid>https://stats.stackexchange.com/questions/649147/why-does-dimensionality-affect-significance-and-effect-size-in-a-full-conditiona</guid>
      <pubDate>Thu, 13 Jun 2024 00:12:15 GMT</pubDate>
    </item>
    <item>
      <title>独立高斯分布的界积</title>
      <link>https://stats.stackexchange.com/questions/649146/bound-product-of-independent-gaussians</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649146/bound-product-of-independent-gaussians</guid>
      <pubDate>Wed, 12 Jun 2024 23:16:03 GMT</pubDate>
    </item>
    <item>
      <title>对零假设的困惑</title>
      <link>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</link>
      <description><![CDATA[我最近在做统计题时看到了这个问题：

一罐 Fun Juice 应该至少装有 64 盎司果汁。

灌装机经过校准，平均每瓶应该装有 64.05 盎司果汁。一位经理想知道机器是否灌装不足。她计划随机抽取一些瓶子样本，然后进行显著性检验。
零假设和备择假设是什么？

答案指出 $H_0$ 是 $\mu=64.05$ 并且 $H_a$ 是 $\mu&lt;64.05$。但是，我得到的结果是 $H_0$ 是 $\mu=64$，而 $H_a$ 是 $\mu&lt;64%$。这里的“未充满”难道不是意味着平均值低于其应包含的量（64 盎司）而不是低于机器校准的填充量（64.05 盎司）吗？这是教科书中的错误，还是我只是遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</guid>
      <pubDate>Wed, 12 Jun 2024 23:15:30 GMT</pubDate>
    </item>
    <item>
      <title>与马哈拉诺比斯距离相关的术语“白化”数据的含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/649111/what-is-the-meaning-of-term-whiten-data-in-relation-to-mahalanobis-distance</link>
      <description><![CDATA[我正在写论文，但在理解这篇论文时遇到了困难：https://people.bu.edu/bkulis/pubs/ftml_metric_learning.pdf
我的专业不是数学，但我能理解基础知识，所以我希望你能用基本的词汇帮助我理解
我在第 2.2.1 节马哈拉诺比斯距离。
据我所知，马哈拉诺比斯距离是在数据点“白化”后计算它们之间的欧几里得距离（据我理解，就是将数据的分布转换为高斯分布（正态分布），其均值为 0，协方差为单位矩阵。哇，但它不会丢失数据点之间的相关距离，对吧？
顺便问一下，这样做有什么直觉吗？比如数据的形状一开始可能是椭圆形并向左倾斜，变换后它会变成圆形和垂直的，对吧？它对噪音有什么作用吗？
最后抱歉，因为我不是本地人，我不明白“白化”这个词，你在这里如何表达白化的含义
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649111/what-is-the-meaning-of-term-whiten-data-in-relation-to-mahalanobis-distance</guid>
      <pubDate>Wed, 12 Jun 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>如何确定二阶张量主轴的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/649109/how-to-determine-the-confidence-intervals-for-the-principal-axes-of-a-second-ran</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649109/how-to-determine-the-confidence-intervals-for-the-principal-axes-of-a-second-ran</guid>
      <pubDate>Wed, 12 Jun 2024 14:40:58 GMT</pubDate>
    </item>
    <item>
      <title>以干扰为主要动机检验因果关系</title>
      <link>https://stats.stackexchange.com/questions/649106/testing-causal-relationships-with-interference-as-the-primary-motivation</link>
      <description><![CDATA[因果推断的核心要素之一是治疗的一致性。其中一个要素是没有干扰，即空间/时间单元中的暴露不会影响非暴露单元的结果。干扰可以在空间上（例如，在国家级研究中，治疗效果“泄漏”到边界之外）或时间上（预期效应）影响单元。
然而，预期效应通常是因果探究的核心点。例如，我一直在阅读有关人道主义干预的文献，反对使用人道主义干预的论点之一是，对未来人道主义干预的预期会激励持不同政见者与国家发生不对称冲突。
考虑到隐含的预期效应，人们可以将这一论点视为测试该论点的复杂因素：
$人道主义干预_{it} \rightarrow 暴力_{it}$
或者，人们可能对测试这种预期效应感兴趣……尽管我承认，当我为此绘制 DAG 时，它变得有些荒谬，因为感觉我在测试以下内容：
$人道主义干预_{it+1} \rightarrow 暴力_{it}$
所以，我的问题是有两个方面：1）在预期效应存在的情况下，是否仍然可以进行因果识别？2）如何检验预期效应是否真的存在？]]></description>
      <guid>https://stats.stackexchange.com/questions/649106/testing-causal-relationships-with-interference-as-the-primary-motivation</guid>
      <pubDate>Wed, 12 Jun 2024 14:06:46 GMT</pubDate>
    </item>
    <item>
      <title>泊松减去一个常数仍然是泊松吗？</title>
      <link>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</link>
      <description><![CDATA[我正在处理一个过程，其中我期望我的变量服从泊松分布。但是，由于与比例有关的原因，我获得的值的最小值为 11。
我注意到，当我使用 R 函数（例如 fitdistrplus::fitdist）估计我的数据与泊松分布的拟合度时，我的数据最适合泊松分布（遵循 AIC 值），但只有当我从观测向量中减去最小值 11 时（这样做的理由是泊松中的值从零开始）。
例如，以下内容与泊松分布的拟合度很差：
obs &lt;- c(15, 15, 13, 14, 13, 12, 12, 14, 14, 12, 11, 13, 11, 12, 12, 
13, 14, 14, 13, 11, 12, 14, 17, 12, 14, 12, 12, 12, 12, 
13, 16, 15, 15, 17, 13, 13, 13, 13, 14, 14, 13, 15)
fitdist(obs, &quot;pois&quot;)

但减去最小值后，拟合效果更好。
fitdist(obs-11, &quot;pois&quot;)

然而，这当然会改变 lambda 参数，在泊松分布中，我相信这也会改变分布的形状。我不仅不确定我的转换是否正确，而且如果不正确，为什么拟合度会提高。
有人可以指出关于这个主题的参考资料，以了解我的转换是否正确吗？即泊松减常数是否仍以泊松分布？
编辑：为了澄清起见，我处理的变量是基因组中新生突变的发生率。这些是罕见事件，通常被建模为泊松过程。在每个单倍体基因组和代的突变数量尺度上，每个单倍体基因组和代（obs向量）观察到几十个突变。这就是最小值为 11 的原因。但是，请注意，这里有尺度的影响。在二倍体基因组的尺度上，obs 中的值将会翻倍，而在每个核苷酸位点（而不是每个基因组）的尺度上，obs 中的值都会非常小（例如 ~6*10e-8），以至于会四舍五入为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</guid>
      <pubDate>Tue, 11 Jun 2024 22:57:56 GMT</pubDate>
    </item>
    <item>
      <title>如何用外行人能理解的术语解释风险比</title>
      <link>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</link>
      <description><![CDATA[在 Cox 回归的背景下，我最近听到有人说“两个治疗组之间的风险比为 0.70，这表明在整个随访期间，对照组中发生事件的 100 人中，只有干预组中的 70 人发生事件。”这是 HR 的有效简化吗？还是还有其他非技术性的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</guid>
      <pubDate>Tue, 11 Jun 2024 11:46:22 GMT</pubDate>
    </item>
    </channel>
</rss>