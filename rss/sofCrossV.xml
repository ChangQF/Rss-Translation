<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 21 Apr 2024 18:17:19 GMT</lastBuildDate>
    <item>
      <title>结构矩阵的导数</title>
      <link>https://stats.stackexchange.com/questions/645505/derivative-of-structure-matrices</link>
      <description><![CDATA[我正在尝试遵循“高级多元矩阵统计”，第 1.4 章。我知道这本书已经很老了，但是我的时间相当有限，而且我正在阅读的论文引用了这本书。此外，我在数学领域问了一个相关但不同的问题，但我想因为这是一本统计书我会在这里得到更多答案。自从问了另一个问题以来，我有了一些进一步的了解，但仍然无法回答一些问题。
在这本书中，我们将矩阵的导数定义为 $$\frac{dY}{dX} = \frac{d\text{vec}^T(Y)} {d\text{vec}(X)}.$$ 然后我们定义了一个结构化（toep/symm/etc）矩阵$X$，图案化矩阵 $X(K)$，其中的想法是图案化矩阵 $X(K)$ span&gt;是“子集” $X$。例如，如果 $X$ 是对称的，则 $X(K)$ 可以是上三角形部分。经过第 1.3 章中的大量理论构建后，自然地出现了模式矩阵彼此微分的定义，$$\frac{dY(K_2)}{dX(K_1)} = T(K_1)\frac{dY}{dX}T^T(K_2),$$ 其中 $T(K)$ 是这样的$T(K)\text{vec}(X) = \text{vec}(X(K))$。
现在这是我的问题。至少，据我了解，上述定义中存在的导数 $\frac{dY}{dX}$ 仍然是“结构化矩阵与结构化矩阵的导数” &#39;。例如，如果 $Y=X \in \mathbb{R}^{p\times p}$ 对称，则  $\frac{dY}{dX} \neq I$ 而是 $\frac{dY}{dX} = I_{p^2} + K_{p, p} - \text{diag}\left(K_{p, p}\right) $，其中 $K_{d,d}$ 是交换矩阵和 $\text{diag}$ 表示仅取对角线元素。我知道已经提出了一个框架来取（结构化矩阵的特定部分）wrt（结构化矩阵的特定部分）的导数，但我仍然不知道如何取（结构化矩阵）wrt的导数（结构化矩阵）。
例如，给定对称 $\Psi$，$\frac{d\Psi^{-1 }}{d\Psi}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/645505/derivative-of-structure-matrices</guid>
      <pubDate>Sun, 21 Apr 2024 17:18:39 GMT</pubDate>
    </item>
    <item>
      <title>SuperLearner 中的元模型采用哪种算法？</title>
      <link>https://stats.stackexchange.com/questions/645504/which-algorithm-for-meta-model-in-superlearner</link>
      <description><![CDATA[您使用哪种算法作为 SuperLearner 的元模型？我总是经常看到回归，但我没有得到很好的预测。我在 SuperLearner 中尝试了所有其他算法，并获得了越来越好的预测性能，直到我运行随机森林，这使我的 ROC AUC = 1。最有可能的是，这是过度拟合。我如何知道其他算法是否可能过度拟合？如果 RF 过度拟合，我如何证明它们的使用合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/645504/which-algorithm-for-meta-model-in-superlearner</guid>
      <pubDate>Sun, 21 Apr 2024 17:12:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将模型系数的对比集转换为两个嵌套模型的定义以进行似然比测试？</title>
      <link>https://stats.stackexchange.com/questions/645502/how-to-translate-the-set-of-contrasts-over-model-coefficients-into-definitions-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645502/how-to-translate-the-set-of-contrasts-over-model-coefficients-into-definitions-o</guid>
      <pubDate>Sun, 21 Apr 2024 16:31:45 GMT</pubDate>
    </item>
    <item>
      <title>如何确定从图像中提取的特征向量是否代表特定任务？</title>
      <link>https://stats.stackexchange.com/questions/645501/how-can-you-determine-whether-a-feature-vector-extracted-from-an-image-is-repres</link>
      <description><![CDATA[在视频摘要项目中根据视频帧的特征对其进行评分的任务中，
如果使用预训练的 CNN（例如 GoogleNet、VGG 和 ResNet）提取帧特征，如何确定哪个网络最适合摘要任务？
我知道仅靠特征无法确定帧的重要性，因此我将视频分成多个片段，并在摘要中考虑得分较高的片段。
我的问题是，有一种方法可以根据这些模型的重要性得分来评估帧的特征表示质量，还是我应该对每个模型进行试验并根据最佳性能进行选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/645501/how-can-you-determine-whether-a-feature-vector-extracted-from-an-image-is-repres</guid>
      <pubDate>Sun, 21 Apr 2024 16:18:00 GMT</pubDate>
    </item>
    <item>
      <title>Cox 或 Fine-Gray 模型可以包含观察期间发生的曝光吗？</title>
      <link>https://stats.stackexchange.com/questions/645500/can-cox-or-fine-gray-model-include-exposure-that-occurs-during-observation</link>
      <description><![CDATA[我正在制作一个关于怀孕的Fine-Gray模型，但我注意到一些妊娠并发症可能会在观察过程中而不是在开始时出现，因为这些并发症通常是在观察过程中通过检查发现的，而且很难发现找到确切的发生时间，此外，在达到诊断标准之前，它们往往已经产生了一些潜在的影响。我做过ph测试，都没有什么意义，我是不是觉得这些并发症虽然在观察过程中可能会出现，但是有“预诊断影响”呢？和 ph 测试显示它们的效果不会随时间变化，因此可以将其视为观察开始时发生的暴露并包含在 Fine-Gray 模型中吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645500/can-cox-or-fine-gray-model-include-exposure-that-occurs-during-observation</guid>
      <pubDate>Sun, 21 Apr 2024 15:48:47 GMT</pubDate>
    </item>
    <item>
      <title>我的列联表标准化残差图不是标准正态分布，为什么？</title>
      <link>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</link>
      <description><![CDATA[我正在学习列联表中的标准化残差。
在“分类数据分析简介”中作者：Alan Agresti (2007) 我发现了以下内容：

我想验证上述陈述，即在零假设下，较大列联表的标准化残差分布为标准正态分布。
作为验证我的代码的教科书示例参考，我使用 Eric Naioti 和 Erika Mudrak 使用调整后的标准化残差解释列联表：

这里还显示标准化残差的数字：

我可以用自己的代码重现：
数组([[ 6.13651969, -4.25381552, -0.57502606, -2.28789602],
       [ 2.16428238, -3.39788279, 2.05021621, -0.50826301],
       [-0.10082422、-2.31105226、0.9895118、2.5765686]、
       [-8.32824833、9.96755012、-2.73797698、0.73202319]])

现在我知道该部分没有错误，我生成了一个相当大的列联表，有 4000 行和 3000 列。我画出了“观察到的”单元格条目均匀分布在 10 到 100 之间，我认为这应该会产生独立的单元格内容。
然后我应用了与上面相同的代码，完全期望单元格标准化残差的直方图显示标准正态分布。
但是，我得到了这个：

问题：为什么我的直方图不是标准正态分布或者我遗漏了什么？
我用来生成绘图的代码是这样的：
将 numpy 导入为 np
从 scipy 导入统计数据
导入 matplotlib
从 matplotlib 导入 pyplot 作为 plt

matplotlib.use(&#39;TkAgg&#39;)


plt.ion()


N_ROWS = 4000
N_COLS = 3000

# 生成独立的 (??) 观察结果
rng = np.random.default_rng(1)
df_obs = rng.integers(低=10，高=100，大小=(N_ROWS，N_COLS))

# 获取期望值，观察低 p 值 (??)
chi2, pvalue, dof, df_exp = stats.chi2_contingency(df_obs, Correction=False)

# 获取边际值，用于计算标准化残差（如下）
margin_col = df_obs.sum(轴=1)
margin_row = df_obs.sum(轴=0)
sum_tot = margin_col.sum()

# 循环每个单元格，记录其残差和标准化残差
resids_lst = 列表()
resids_std_lst = 列表()
对于范围内的 irow(N_ROWS)：
    对于范围内的 icol(N_COLS)：

        obs = df_obs[irow, icol]
        exp = df_exp[irow, icol]

        marg_col = margin_col[irow]
        marg_row = margin_row[icol]
        std_fac = exp * (1.-marg_col/sum_tot) * (1.-marg_row/sum_tot)

        残差 = obs - exp
        resid_std = resid / np.sqrt(std_fac)

        resids_std_lst.append(resid_std)

# 绘制记录的残差
plt.figure()
plt.suptitle(&#39;期望标准化残差的标准正态分布？&#39;)
plt.hist(resids_std_lst, alpha=0.5, label=&#39;标准化残差&#39;)
plt.图例()
]]></description>
      <guid>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</guid>
      <pubDate>Sun, 21 Apr 2024 15:36:52 GMT</pubDate>
    </item>
    <item>
      <title>理解“求 100 次抛硬币的 95% 置信区间”的问题</title>
      <link>https://stats.stackexchange.com/questions/645497/understanding-the-question-of-find-the-95-confidence-interval-of-100-coin-flip</link>
      <description><![CDATA[我一直看到这个问题...
&lt;块引用&gt;
求 100 次抛硬币的 95% 置信区间

这是一个经典的数据科学或统计面试问题。所以，我相信你应该使用方法来找到答案，并使用 CLT。
但是...我该如何解释这个问题？我是否认为这是询问抛硬币次数或 $\hat{p}$ 的置信区间？
对于伯努利，标准误差与平均值相同......对于公平的硬币：
$$SE = \frac{\sigma}{\sqrt{n}} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\压裂{.5(1-.5)}{100}} = 0.05$$
$$CI = \hat{x} \pm 1.96 SE \implies .5 \pm 1.96 \cdot 0.05 \implies (0.402, 0.598)$$
假设我们想要翻转次数的置信区间...如果有足够的翻转次数，我们是否可以仅使用 z 分数来表示成功次数（好吧，写出来似乎并不是 z 分数）？
$$ \mu = n \cdot p \quad \sigma = \sqrt{n\cdot p \cdot (1-p)} \意味着 z = \frac{n \cdot p }{\sqrt{n\cdot p \cdot (1-p)}} = 10$$
$$CI = (30.4, 69.6)$$
当我模拟这个时，我找到了与我在网上看到的相匹配的答案......我得到：
$$CI = (40, 60)$$
该值非常接近 $p$ 的置信区间，但乘以 $100$。我可以将 $p$ 的 CI 乘以 $100$ 吗？
将 numpy 导入为 np
将 pandas 导入为 pd

def Bernoulli_ci(n, p =.5, ci=1.96):
  se = (p*(1-p)/n)**.5
  我=ci*se
  返回（p - 我，p + 我）

def binom_ci(n, p =.5, ci=1.96):
    zscore = (n*p)/(n*p*(1-p))**.5
    我 = ci*zscore
    返回（n*p - 我，n*p + 我）


S = 100000
N = 100
df = pd.DataFrame(np.random.random(size=(S, N)))
df = (df &gt; .5).sum(axis=1) # 头数
print(&quot;伯努利 CI&quot;, bernoulli_ci(N))
print(&quot;binom CI&quot;, binom_ci(N))

阿尔法 = .05
df = df.sort_values()
print(&quot;emerical ci&quot;, (df.quantile(alpha/2), df.quantile(1-alpha/2)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/645497/understanding-the-question-of-find-the-95-confidence-interval-of-100-coin-flip</guid>
      <pubDate>Sun, 21 Apr 2024 15:21:46 GMT</pubDate>
    </item>
    <item>
      <title>如何通过没有外部包的嵌套*模型的比较来测试 R 中分类变量级别的具体对比？</title>
      <link>https://stats.stackexchange.com/questions/645496/how-to-test-specific-contrasts-about-levels-of-categorical-variables-in-r-throug</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645496/how-to-test-specific-contrasts-about-levels-of-categorical-variables-in-r-throug</guid>
      <pubDate>Sun, 21 Apr 2024 13:43:55 GMT</pubDate>
    </item>
    <item>
      <title>理解Logistic回归公式</title>
      <link>https://stats.stackexchange.com/questions/645494/understanding-the-logistic-regression-formula</link>
      <description><![CDATA[逻辑回归旨在转换线性回归公式并将 s 曲线或逻辑函数拟合到特定数据集，以便在给定多个预测变量的情况下计算分类结果变量的概率。
还有一个公式旨在演示需要发生什么才能产生所需的结果（s 曲线）。使回归模型逻辑回归的标准公式是什么？我有点困惑，因为它们的写法似乎不同（尽管在不同的来源中可能表示相同的意思）。经过一番研究，下面的公式似乎就是我正在寻找的（docs.tibco.com/pub/sfire- dsc/6.5.0/doc/html/TIB_sfire-dsc_user-guide/GUID-C4D05ED0-3392-4407-B62A-7D29B26DC566.html）。首先应用下面的逻辑函数将线性转换为逻辑；

然后得到下面的最终公式，这就是我打算用作标准 Logistic 回归公式。这是正确的吗？

这被解释为 P = 事件概率，并且 X1,X2,… 是自变量值。
这个想法是在我的方法论部分中提供从理论到实践的模型的整体基础。]]></description>
      <guid>https://stats.stackexchange.com/questions/645494/understanding-the-logistic-regression-formula</guid>
      <pubDate>Sun, 21 Apr 2024 12:11:37 GMT</pubDate>
    </item>
    <item>
      <title>检测大型逻辑回归模型中的交互</title>
      <link>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</link>
      <description><![CDATA[我有一个包含数百万个二元响应观察值的数据集，“成功”概率平均为 1% 到 2%。该数据集包含多个分类变量（约 20 个类别，其中有多达 50 个类别）和数值变量（约 10 个）。我安装了主效应逻辑广义线性模型（GLM）作为基线和梯度提升树（GBT）。根据测试集上的对数损失来衡量，GBT 明显优于 GLM。然而，当仅比较它们的边际效应（通过观察合适的图来测量）时，这两个模型似乎非常相似。因此，GBT 优于 GLM 的一个潜在原因可能是包含了交互作用。我想验证这一点，并最好找到（其中一些）这些交互。
我的问题

有哪些可能的方法可以在 GBT 模型中找到交互作用？
更一般性的信息：我在哪里可以找到关于寻找交互的最新技术以及当前可行和不可行的信息？

我的目标非常务实：

我不需要找到所有交互，只需找到一些“重要”的交互即可。这将是一个很好的开始。
我不需要对研究结果进行假设检验。
但是方法需要在给定“标准”的情况下是可实现的。计算资源。

到目前为止我的尝试

考虑到数据集的大小和输入的数量，任何详尽的搜索方法（例如逐步回归）似乎都是徒劳的。
与 Lasso 等正则化选择存在同样的问题。特别是，由于数字输入，稀疏设计矩阵是不可能的。
我知道弗里德曼的 H 统计量，但尚未尝试过。我看到的问题是它基于方差分解而不是对数损失。这也是一种详尽的搜索，并且（最多？）仅适用于成对交互。此外，其估计基于排列，并且某些输入表现出很强的依赖性。
数据集很复杂，并且没有先验的理由说明交互应限制为对。我“猜测”的成功在于基于我的一般领域知识的交互以及通过包含在 GLM 中进行验证的交互受到限制。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</guid>
      <pubDate>Sun, 21 Apr 2024 11:22:16 GMT</pubDate>
    </item>
    <item>
      <title>力矩比和 L 力矩比：</title>
      <link>https://stats.stackexchange.com/questions/645492/moment-ratios-and-l-moment-ratios</link>
      <description><![CDATA[我想知道力矩比图和L力矩比图之间的区别。
据我了解，矩比图的目的是检测概率密度函数的类型，查看偏度和峰度系数的值。
L 力矩比与力矩比相比有何优势？
为什么要考虑订单统计。
我发现 L 矩的语法很难理解
力矩比图和L力矩图是如何生成的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645492/moment-ratios-and-l-moment-ratios</guid>
      <pubDate>Sun, 21 Apr 2024 11:04:05 GMT</pubDate>
    </item>
    <item>
      <title>两种治疗多种途径？</title>
      <link>https://stats.stackexchange.com/questions/645491/two-kinds-of-treatment-with-multiple-ways-administered</link>
      <description><![CDATA[作为一名本科生，我正在制定一项研究计划。我想看看两种不同类型的消息传递对行为的影响。然而，每条消息将通过不同的方法进行管理。例如：一条信息是关于鼓励女孩上学，另一条信息是鼓励学生上学，列出了上学的好处。我希望以四种不同的方式进行管理：要么只对母亲，要么只对父亲，分别对母亲和父亲，对母亲和父亲一起。如果希望女孩的学校注册成为我的因变量，我应该创建什么样的回归？我很困惑。
应该是：
girlregistrations = 常量 + 交互：mother_only*girl_message +father_only*girl_message + motherfather_separate*girl_message + motherfather_together*girl_message + 错误
其中每个术语都是虚拟人之间的交互：如果仅对母亲进行治疗，则 mother_only 将为 1。如果管理的消息是鼓励女孩上学而不是性别中立的福利消息，则 Girl_message 将为 1。
我错过了什么吗？
任何意见都将非常感激。
非常感谢。
编辑：实验单位为2名家长+1名女童（年龄符合入学年龄）的家庭，以个人为单位衡量登记结果。 （在只有 1 所学校的某些村庄，通过挨家挨户游说的方式进行治疗。对照是只有 1 所学校的其他村庄，但不进行治疗）。对于分配到治疗组 1（女孩信息）或治疗组 2（一般信息）的村庄，家庭被随机分配到 4 种不同的治疗管理方式。
女孩注册的定义是该家庭中的女孩是否已在即将到来的截止日期之前注册送孩子上学]]></description>
      <guid>https://stats.stackexchange.com/questions/645491/two-kinds-of-treatment-with-multiple-ways-administered</guid>
      <pubDate>Sun, 21 Apr 2024 10:40:46 GMT</pubDate>
    </item>
    <item>
      <title>具有规范链接的 GLM：为什么对自然参数进行线性回归？</title>
      <link>https://stats.stackexchange.com/questions/645490/glm-with-canonical-link-why-linear-regression-over-the-natural-parameter</link>
      <description><![CDATA[所以我一直想知道为什么它是“自然的”？扩展线性模型，我们假设 $Y\sim N(\mu,\Sigma)$ 并尝试拟合 $E [Y|X]=X\beta$ 到广义线性模型，我们假设 $Y_i\sim P_{\theta_i,\phi a_i}$ 为$$P_{\theta_i,\phi a_i}(t)=f_0(t;\phi a_i)\exp\left(\frac{\theta_i t-K(\theta)}{ \phi a_i}\right)$$
我从两种不同的角度思考了这个问题，我不知道其中一种是否准确：

我的第一直觉是认为 $\theta_i$ 是（唯一？）参数，使得 $Y$ 是线性的，与 $\mu$ 是线性的，如果  $Y\sim N(\mu,\Sigma)$。因此具有规范联系的 GLM 相当于正态性假设上的线性回归。但为什么这种对数线性总体上很有趣，它与我的问题的第 2 点有何关系？

我们在 X 上搜索回归函数，该回归函数是可训练的线性函数与固定的任意不同函数的组合，这本质上就是我们在大多数更高级的模型中所做的事情。所以我们希望 $E[Y|X]=h(X\beta)$ 用于某些函数 $h$&lt; /span&gt;，我们知道如果 $h=(K&#39;)^{-1}$ 则 $E[ Y]=g^{-1}(\theta)$ 所以我们只需制作 $\theta=X\beta$ 然后通过 &lt; span 类=“math-container”&gt;$h$。因此，对于当我们对数据有指数离散假设时选择什么回归函数这个问题来说，这是最自然的选择？


但即使这样对我来说似乎也不太令人信服。证明此规范链接 GLM 合理的理由是什么。我知道这只是一个定义，与许多其他可能的定义一样，必须检查它产生的拟合是否良好，并且我不会寻找其工作原理的通用解释。我只是想知道为什么这是线性模型的自然推广，即使它从来没有起作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/645490/glm-with-canonical-link-why-linear-regression-over-the-natural-parameter</guid>
      <pubDate>Sun, 21 Apr 2024 10:07:21 GMT</pubDate>
    </item>
    <item>
      <title>证明样本方差的估计量为 MVUE</title>
      <link>https://stats.stackexchange.com/questions/645489/proving-an-estimator-of-the-sample-variance-to-be-mvue</link>
      <description><![CDATA[问题：证明$\hat{\sigma}_x^2=\displaystyle\frac{1}{N-1}\sum_{ i=1}^N(X_i-\overline{X})^2$，其中 $\overline{X}=\frac{1}{N}\ sum_{i=1}^N X_i$ 是方差的无偏最小方差估计量，估计量的方差为
$\operatorname{Var}[\hat{\sigma}_x^2]=\displaystyle\frac{N}{(N-1)^2}E[(X_i-\ mu)^4]+\frac{\sigma_x^4}{N-1}$。
&lt;小时/&gt;
到目前为止，我已经能够证明 $E[\sigma_x^2]=\sigma^2$，但要证明它确实是估计器最小方差，我被困住了。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/645489/proving-an-estimator-of-the-sample-variance-to-be-mvue</guid>
      <pubDate>Sun, 21 Apr 2024 10:03:16 GMT</pubDate>
    </item>
    <item>
      <title>树状图的名称，显示变量聚类如何影响解释的方差</title>
      <link>https://stats.stackexchange.com/questions/645486/name-for-a-dendrogram-showing-how-variable-clustering-affects-variance-explained</link>
      <description><![CDATA[这是来自 Harrell 的 RMS：

我确信我见过类似的树状图，用于说明变量聚类对 $R$ /  的影响$R^2$。它的 x、y 轴与刚刚显示的图表相反，但在其他方面看起来非常相似。它的轴上不是 $\rho^2$ ，而是 $R$ 或 $R^2$，以便您可以看到组合变量如何减少$R^2$。
我已经尝试了我能想到的所有搜索词，但找不到此类树状图的具体名称或可能生成它的包。有谁知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645486/name-for-a-dendrogram-showing-how-variable-clustering-affects-variance-explained</guid>
      <pubDate>Sun, 21 Apr 2024 08:30:44 GMT</pubDate>
    </item>
    </channel>
</rss>