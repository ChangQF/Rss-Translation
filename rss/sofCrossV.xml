<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 22 Jun 2024 03:17:55 GMT</lastBuildDate>
    <item>
      <title>测量非正定相关矩阵与其近似正定相关矩阵之间的差异（在 R 中）</title>
      <link>https://stats.stackexchange.com/questions/649694/measuring-difference-between-a-non-positive-definite-correlation-matrix-and-its</link>
      <description><![CDATA[当遇到非正定 (NPD) 相关矩阵时，我经常想使用 Matrix::nearPD(NPD, corr=TRUE)$mat 将我的 NPD 相关矩阵转换为近似正定相关矩阵（见下文）。
问题：有没有办法衡量这会给原始 NPD 相关矩阵带来多大的变化，从而确定这种策略的合理程度？
R 代码：
NPD_MATRIX &lt;- structure(c(0.58, 0.55, 0.52, 0.34, 0.56, 0.45, 0.52, 0.42, 0.55, 
0.64, 0.36, 0.2, 0.4, 0.29, 0.35, 0.29, 0.52, 0.36, 0.58, 0.53, 
0.58, 0.36, 0.55, 0.57, 0.34, 0.2, 0.53, 0.77, 0.52, 0.33, 0.63, 
0.57, 0.56, 0.4, 0.58, 0.52, 0.32, 0.42, 0.52, 0.5, 0.45, 0.29, 
0.36, 0.33, 0.42, 1, 0.4, 0.33, 0.52, 0.35, 0.55, 0.63, 0.52, 
0.4, 0.62, 0.52, 0.42, 0.29, 0.57, 0.57, 0.5, 0.33, 0.52, 0.73
), dim = c(8L, 8L), dimnames = list(c(&quot;L2DA&quot;,&quot;L2DF&quot;,&quot;L2G&quot;,&quot;, 
&quot;L2L&quot;,&quot;L2M&quot;,&quot;L2P&quot;,&quot;L2R&quot;,&quot;L2V&quot;,&quot;), c(&quot;L2DA&quot;,&quot;L2DF&quot;,&quot;L2G&quot;,&quot;, 
&quot;L2L&quot;,&quot;L2M&quot;,&quot;L2P&quot;,&quot;L2R&quot;,&quot;, &quot;L2V&quot;)))

as.matrix(Matrix::nearPD(NPD_MATRIX, corr=TRUE)$mat)
]]></description>
      <guid>https://stats.stackexchange.com/questions/649694/measuring-difference-between-a-non-positive-definite-correlation-matrix-and-its</guid>
      <pubDate>Sat, 22 Jun 2024 01:20:33 GMT</pubDate>
    </item>
    <item>
      <title>假设检验有限样本空间高斯混合模型</title>
      <link>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</link>
      <description><![CDATA[我有 $n$ 对 $(x, y)$ 的观测值和三个不同的模型，我想进行比较。模型 0 嵌套在模型 1 中。模型 0 也嵌套在模型 2 中。我想对模型 1 和模型 2 分别进行假设检验，使用模型 0 作为零假设。我最初的方法是使用似然比检验，但我得到的 1 类错误率过高。我相信这个 stack overflow 答案 中解释了其原因。因此，我尝试使用该答案中建议的修正，例如 Satorra 和 Bentler 2010 修正或 Bartlett 修正，但无济于事，因为这些修正似乎都是针对与我自己的问题不同的指定问题。因此，我需要帮助，要么将修正转换为问​​题的公式，要么以与修正兼容的方式重新表述我的问题，老实说，我不介意有人仔细检查我的分析，以确保所引用的答案实际上与我的问题有关，因为也许我弄错了。
因此，我的三个模型如下：
首先，它们都是$(2n x 2n)$多元正态分布，对于观测向量$(x_{1},...,x_{n},y_{1},...,y_{n})$，它们给出第 i 行、第 j 列（矩阵为半正定）中观测 i 和 j 之间的协方差。
模型 0：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; 0_{n x n} \\
0_{n x n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$ 和 $\mathbb{I}_{n}$ 是 $(n x n)$ 已知矩阵（$\mathbb{I}_{n}$ 是单位矩阵），$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 是未知方差缩放因素。
模型 1：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; c_{1}C_{n} \\
c_{1}C_{n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$、$\mathbb{I}_{n}$ 和 $C_{n}$ 为 $(n x n)$ 已知矩阵，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$c_{1}$ 是 $[-1,1]$ 中的未知相关性。
模型 2：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; c_{1}K_{n} \\
c_{1}K_{n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$、$\mathbb{I}_{n}$ 和 $K_{n}$ 为 $(n x n)$ 已知矩阵，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$c_{1}$ 是 $[-1,1]$ 中的未知相关性。
总之，我对 X 和 Y 之间可能存在的相关性类型有几个不同的假设，我希望能够通过拒绝零假设来支持这些假设。非常感谢任何帮助，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</guid>
      <pubDate>Sat, 22 Jun 2024 00:53:33 GMT</pubDate>
    </item>
    <item>
      <title>如何对机器学习模型执行置换检验以获得其性能的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</link>
      <description><![CDATA[这个问题与上一篇文章中的问题类似。但由于没有回复，而且我很难找到答案，所以我想再问一次。
我正在 caret 中训练回归模型（SVM 线性核）。我曾多次使用名为 PRONTO 的软件，它可以运行置换测试以获得预测模型指标（R²、MSE 等）的 p 值。
如何在 R 中重现此问题？是否可以在 caret 包中执行此操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</guid>
      <pubDate>Fri, 21 Jun 2024 23:31:13 GMT</pubDate>
    </item>
    <item>
      <title>我想了解一下我在这里从事的工作</title>
      <link>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</link>
      <description><![CDATA[我从事屋顶销售工作，入门级需要上门推销。我们分行的 GroupMe 聊天中会打印每日数据。我主动对这些数字进行了一些分析。有敲门、谈话、走访和偶发事件（达成的交易）。
我不会向你介绍我所做的一切，但我会告诉你，我发现敲门次数和偶发事件之间的相关性为 -0.41，这意味着我们敲的门越多，达成的交易就越少；上门推销的差异也很大，远远超出了每日数字的范围。我对此非常感兴趣，因为销售工作几乎总是“数字游戏”，这意味着他们使用平均法则 - 如果你敲了很多门，最终你就会达成交易。
我告诉领导层这件事，他们给了我“焚书”式的回应。他们告诉我不要分享任何“负面”信息或者告诉人们不要为了赚更多的钱而努力工作；我放弃了和他们讨论这个问题，而是自己深入研究它。
首先，我计算了平均每敲 100 扇门，有多少个意外事件被签署。它是 ~2.59。我用它作为二项分布函数中的“假定概率”，并绘制了每次敲门（0 - 100）的销售概率。我发现，最有可能产生 ~2.59 笔销售，2 笔销售的概率约为 25% 左右。负相关性告诉我，收益递减点已经存在，所以我仍然不相信越多越好。
其次，我决定对每 100 扇门进行预期值计算。当然，每扇门 2.59% 的销售概率保持不变；但是，惩罚（使用的资源，如汽油和时间等）确实会随着每扇门而增加。我称之为每扇门 1 美元的汽油，因为这就是我所花费的。这告诉我，在 52 次敲门后，你真的没有什么可获得的了。这让我意识到二项分布概率会随着试验次数的变化而变化……
第三，我回到电子表格并将试验次数改为 52；这表明最有可能的结果是 1 次销售，概率略高于 33%（这大于 100 次试验中 2 次销售的约 25% 的概率）。
由于这一切都基于我们分行的实际绩效数据，我觉得我已经证明（至少在统计上）我已经解释了负相关性，并证明了“上升和磨砺”每天尽可能多地敲门是一种策略，但这种策略会适得其反，导致销售代表产生不一致的数字（解释了高方差）。
我现在的假设是，如果所有销售代表每个周期（一天、一周或其他时间段）敲门 52 次，方差将更接近于零或至少在数据范围内，销售额将会增加，相关性可能会显示敲门次数和意外事件之间存在正相关关系，因为敲门次数通常会较低，意外事件的数量会较高。
我希望从更有经验的人那里了解我的发现是否有价值，或者我是否遗漏了什么。在非正式场合，我很乐意编写 Python 代码来绘制所有这些。]]></description>
      <guid>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</guid>
      <pubDate>Fri, 21 Jun 2024 21:04:41 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，我想研究三元变量 x 与二元变量 y 交互的影响。三元变量是分类变量，出于某些原因，我想对 3 个组进行 3 次比较。
我明白要进行一次比较，我必须进行 2 次对比。例如，如果我对组 1 与组 3 感兴趣，我定义 C1= (-1,0,1) 和 C2=(-1,2,-1)。如果我想测试所有的比较，那么我应该做 6 次对比吗？在这种情况下，回归量不是共线的吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>使用二分法 Y 解释 SPSS PROCESS 输出的资源 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</link>
      <description><![CDATA[我目前正在使用 SPSS 中的 PROCESS 宏扩展进行中介分析。我最近了解到，此扩展中可以使用二分 Y。话虽如此，使用逻辑回归可以改变输出。有人知道任何使用二分 Y 解释 PROCESS 宏输出的资源吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</guid>
      <pubDate>Fri, 21 Jun 2024 20:39:42 GMT</pubDate>
    </item>
    <item>
      <title>RCT 的线性混合模型中的插补[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</link>
      <description><![CDATA[我有一项研究，其中参与者被随机分配到两种条件之一（参与者条件）。他们在测试前和测试后都完成了调查。我想看看条件和时间之间是否存在显著的相互作用，看看一种条件是否比另一种条件导致 DV 从测试前到测试后的变化更大。数据是长格式。
数据也被输入了 50 次，并存储在以下 mids 对象中：impmids。
有人可以确认这是否是测试所提研究问题的正确代码吗：
library(mice)
library(lme4)

P.eddi &lt;- with(impmids, lmer(EDDI_Total ~ ParticipantCondition * Time + (1|Participant_ID_New)))
BP.eddi.pooled &lt;- pool(BP.eddi)
summary(BP.eddi.pooled)

谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</guid>
      <pubDate>Fri, 21 Jun 2024 19:47:04 GMT</pubDate>
    </item>
    <item>
      <title>使用什么指标来丢弃与所有其他注释者具有较低 IAA（注释者间一致性）的注释者？</title>
      <link>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</link>
      <description><![CDATA[此问题特定于在李克特量表上收集的序数数据
丢弃与其他人的注释者之间注释者一致性 (IAA) 较低的注释者的最佳指标是什么？例如，Cohen 的 Kappa、Fleiss 的 Kappa、Krippendorff 的 Alpha
是成对计算每对注释者之间的注释者一致性更好，还是可以对 1 个注释者与其他注释者进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</guid>
      <pubDate>Fri, 21 Jun 2024 19:19:02 GMT</pubDate>
    </item>
    <item>
      <title>GAM 分析有两种方式：使用正态分布作为生存百分比，使用二项分布作为存活/死亡，但得到的结果截然不同</title>
      <link>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</link>
      <description><![CDATA[我的问题与鲑鱼种群数据有关。我想了解海洋变量如何影响鲑鱼的回归。我用两种不同的方法分析了数据。第一个响应变量是返回的鲑鱼数量与外出鲑鱼数量的比例，但这是有问题的，因为我们将每年数千个数据点压缩成一个数字。
gam_hatcherySAR_cuti &lt;- gam(sar ~ s(CUTI), data = hatcherySAR, method = &quot;REML&quot;)

 out_yr SAR CUTI
1 2008 0.003664542 -0.03291667
2 2009 0.010083530 -0.04575000
3 2010 0.005462051 -0.29100000
4 2011 0.004414756 -0.12783333
5 2012 0.002900364 -0.20225000
6 2013 0.005570978 0.09850000
7 2014 0.012547544 -0.07283333
8 2015 0.006963657 0.07700000
9 2016 0.004722142 -0.04975000
10 2017 0.002127052 -0.00575000
11 2018 0.007220002 0.03550000`

系列：高斯
链接函数：身份

公式：
SAR ~ s(CUTI)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距） 0.0059706 0.0009768 6.112 0.000177 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似重要性：
edf Ref.df F p 值
s(CUTI) 1 1 0.207 0.66

R-sq.(adj) = -0.0861 偏差解释 = 2.25%
-REML = -36.422 尺度估计 = 1.0496e-05 n = 11

因此，我想通过另一种方式对其进行分析，即使用逻辑回归方法将响应变量视为活着的还是死去的。
但是，这两种分析方法都得到了截然不同的结果，即 CUTI 在上述高斯示例中不是一个重要的预测因子，而二项式示例则非常重要。我还看到了与我评估过的许多其他海洋变量类似的结果。显然，考虑到不同的分布，我预计结果会略有不同，但不会像我看到的那么剧烈。有人能帮我理解这是为什么吗？
gam_hatcherySARbin_cuti &lt;- gam(cbind(hatcherySARbin$alive,hatcherySARbin$dead) ~ s(CUTI), data=hatcherySARbin,family=binomial(),method = &quot;REML&quot;)

 年份 存活 死亡 剪切
[19,] &quot;2008&quot; &quot;15750&quot; &quot;4282232&quot; &quot;-0.032916667&quot;
[20,] &quot;2009&quot; “42239” “4146665” “-0.04575” 
[21,] “2010” “23290” “4240634” “-0.291” 
[22,] “2011” “16367” “3682322” “-0.127833333” 
[23,] “2012” “11699” “4021761” “-0.20225” 
[24,] “2013”​​ “18701” “3338073” &quot;0.0985&quot; 
[25,] &quot;2014&quot; &quot;48229&quot; &quot;3795423&quot; &quot;-0.072833333&quot;
[26,] &quot;2015&quot; &quot;20134&quot; &quot;2870199&quot; &quot;0.077&quot; 
[27,] &quot;2016&quot; &quot;13130&quot; &quot;2786228&quot; &quot;-0.04975&quot; 
[28,] &quot;2017&quot; &quot;6219&quot; &quot;3032885&quot; &quot;-0.00575&quot; 
[29,] &quot;2018&quot; &quot;18603&quot; &quot;2558000&quot; &quot;0.0355&quot;
`

系列：二项式

链接函数：logit

公式：
cbind(hatcherySARbin$alive, hatcherySARbin$dead) ~ s(CUTI)

参数系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -5.208502 0.002349 -2217 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(CUTI) 8.994 9 44821 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = -0.958 偏差解释 = 82.9%
-REML = 5057 尺度估计 = 1 n = 11``` 
]]></description>
      <guid>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</guid>
      <pubDate>Fri, 21 Jun 2024 19:10:08 GMT</pubDate>
    </item>
    <item>
      <title>导致非线性回归引导问题的“重要”数据点</title>
      <link>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</link>
      <description><![CDATA[我正在尝试模拟行星表面的雷达反向散射。散射回仪器的功率取决于它观察表面的角度。由此产生的功率与角度曲线的形状由表面的特性决定。
这是我的所有数据的图表，其中包含一个 5 参数模型。

上图中的每个点都显示为单个点，但这只是为了显示。这些点中的每一个实际上都是由包含数千个像素的雷达图像组成的，其中每个像素都有指定的角度和功率。
以下是实际拟合的完整数据：

请注意，每个像素在图像的平均功率附近都是嘈杂的 - 这部分是由于雷达图像固有的“斑点噪声”，并且是乘性噪声。这意味着功率测量值越大，噪声就越大。 （这不是很明显，因为绘图是以 dB 为单位的，这是一个对数刻度。）
使用 MATLAB 的 fit 函数将表面模型拟合到所有数据，对 5 个模型参数给出了非常非常严格的限制。例如，它估计表面的介电常数为 1.329（1.326, 1.332）。对于数据的稀疏性和噪声性来说，这是一个不切实际的置信度，尤其是在第一张图中看到数据点的“真实”分布时。
我尝试使用引导法获得更准确的拟合参数不确定性。我尝试的第一件事是通过从 500,000 个像素池中进行 500,000 次替换采样来创建引导样本。每个引导拟合的结果实际上与第一次拟合完全相同，拟合参数的分布同样很小（+- 0.01）。我可以理解为什么会这样（我认为）。通过选择这么多像素，每个雷达图像的分布基本上完全重建，并且最终的拟合不会改变。
然后我认为我应该将大约 30 张雷达图像中的每一个都视为一个测量值，并通过从图像集中进行替换选择来制作引导样本。如果选择了图像，则将其所有像素都包含在拟合向量中，而不仅仅是其平均值。我这样做是因为我认为像素分布中有重要的角度信息，尤其是在斜率陡峭的低角度。
但是，当我使用此方法时，控制低角度行为的参数是极其双峰的。结果几乎完全取决于引导样本中是否包含 0 度和 5 度左右的图像。如果包括它们，则有一个拟合，如果不包括它们，则有另一个拟合。在低入射角时会出现指数衰减，因此包含/排除这几个点对于模拟该行为非常重要。


我应该如何处理这个问题？这几个重要的点决定了模型该状态的行为，因此我的参数估计中的不确定性更多地与“是否包含该点”有关比任何东西都重要，这似乎在科学上没有什么用。不幸的是，我可用的数据非常有限，特别是在低入射角的情况下。
在这种情况下，引导法是否是我获取参数不确定性的正确方法？我也研究了引导残差，但我认为它无效，因为散斑噪声是乘性的，并且取决于观察的功率。统计学的这个领域对我来说很新，所以任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</guid>
      <pubDate>Fri, 21 Jun 2024 18:50:21 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中交换预测变量和结果变量会有什么变化</title>
      <link>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，其中包含一个表示细菌分离源的变量，该变量有 2 个因子，以及多个其他二进制变量，表示该细菌是否对某些抗生素具有耐药性（是或否）。
我一直在进行逻辑回归，最初将分离源视为预测因子。
glm &lt;- glm(antibiotic1 ~ source, data = df, family = binomial()) 

但是，我正在考虑将分离源视为结果的可能性。这样，我可以使用多种抗生素耐药性变量作为预测因子，让我能够对一些抗生素进行分组并进行多元逻辑回归，看看是否能得到更好的见解。
glm &lt;- glm(source ~ antibiotic1 + antibiotic2, data = df, 
family = binomial()) 

这种方法可行吗？在可解释性方面会发生什么变化？以这种方式进行是否可取？]]></description>
      <guid>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</guid>
      <pubDate>Fri, 21 Jun 2024 17:12:15 GMT</pubDate>
    </item>
    <item>
      <title>心率测量 (bpm) 的 Bland-Altman 图遵循某些“线”模式</title>
      <link>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</link>
      <description><![CDATA[我正在比较不同设备在不同活动期间（5 分钟休息、5 分钟锻炼和 5 分钟恢复）的心率测量值。
为了分析设备之间的一致性，我想制作 Bland Altman 图（使用极坐标 H10 作为黄金标准）。
但是，在使用所有参与者的数据制作 H10 与 Vantage V3 的 Bland Altman 图时，我注意到图中有一些奇怪的线条图案，我不完全确定为什么会出现这些图案/这意味着什么？

我还为每个参与者制作了图，如下所示：

创建 Bland Altman 图时对于此参与者，出现了以下线条模式：

在某种程度上，这些线条对我来说是有意义的，因为您可以清楚地看到，当开始锻炼时，平均心率会增加，设备之间的差异也会变大。而当完成锻炼时，平均心率以及差异会再次下降。
然而，在我读过的所有论文中，我都没有看到出现如此精确的线条模式，这让我怀疑我是否在这里做错了什么？
例如，我是否需要排除某些数据点，或者首先进行一些标准化？
任何想法或帮助，都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</guid>
      <pubDate>Fri, 21 Jun 2024 15:06:25 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    <item>
      <title>使用预测风速进行风能预测的模型评估策略</title>
      <link>https://stats.stackexchange.com/questions/649623/model-evaluation-strategies-for-wind-energy-prediction-using-forecast-wind-speed</link>
      <description><![CDATA[我正在研究一个回归问题，根据每小时数据预测特定位置产生的风能。该数据集包含四年的观测数据，每小时一行，每天共计 24 行。响应变量是每个特定时间的“发电量”，唯一的预测因子是前一天由数值天气预报 (NWP) 系统生成的该时间预测的风速。
值得注意的是，该模型不使用任何滞后变量；它仅使用每小时预测的风速来预测同一小时的发电量。主要目标是建立预测风速（输入）和发电量（输出）之间的直接关系。
鉴于这种设置，我正在考虑几种模型评估策略：

前三年训练，第四年测试
时间序列交叉验证：实施时间序列交叉验证策略，类似于 scikit-learn 提供的方法（详情请见此处）。这将涉及一个滑动时间窗口，用于逐步训练和测试模型。
将每月的前三周分配给训练集，将每月的第四周分配给测试集。此过程将产生一个综合训练集和一个最终测试集。因此，这意味着模型在整个训练集上进行一次训练，随后在完整测试集上仅评估一次。

虽然我承认选项 1 和 2 是正确的，第二个选项非常耗时，但考虑到模型不包含过去的响应值或任何滞后预测变量，我对选项 3 的正确性感到疑惑。虽然数据具有时间顺序，但模型的非自回归性质是否使选项 3 适合模型评估？
任何有关类似评估策略的见解或经验都将不胜感激。
问题更新：
我特别想确定策略 3 中是否存在任何统计缺陷。例如，我理解随机抽样数据来创建训练集和测试集在统计上是不正确的，因为数据的时间顺序、非独立同分布性质以及自相关的存在。随机抽样不会保留固有序列，这就是为什么在这种情况下通常建议使用时间序列交叉验证（保持数据顺序）（如策略 2）。但是，策略 3 还通过使用特定的时间块进行测试（每月的第四周）来保留时间顺序。
为了说明，我们假设我的模型的操作应用如下：该模型使用迄今为止的数据进行训练，并用于预测未来一周每天的每个小时（这种情况有点复杂，但我使用它是为了论证）。在这种情况下，评估我的模型（估计未来表现）最合适的方法是使用策略 2，它模拟其未来的操作用途。
但正如我所说，我对策略 3 感兴趣。因此，我的问题是：

从根本上讲，它是否存在统计上的错误？
它是否可以作为策略 2 的合理近似，同时具有计算量较少的优势？（假设每个月的第四周没有什么特别之处）

更新 2：
顺便说一句，我的问题的设置与 GEFCOM2014 的设置非常相似，在风能预测的背景下，要求您使用过去的数据来预测下个月每天每小时的发电量。
GEFCOM2014 风能]]></description>
      <guid>https://stats.stackexchange.com/questions/649623/model-evaluation-strategies-for-wind-energy-prediction-using-forecast-wind-speed</guid>
      <pubDate>Thu, 20 Jun 2024 19:31:57 GMT</pubDate>
    </item>
    <item>
      <title>将动物目击情况与土地覆盖联系起来——泊松分布、负二项分布、零膨胀分布，然后是 LOST</title>
      <link>https://stats.stackexchange.com/questions/649531/relating-animal-sightings-with-land-cover-poisson-negative-binomial-zero-inf</link>
      <description><![CDATA[我在一个地方（一个岛屿）看到过许多动物。这些目击事件都是偶然发生的（人们偶然发现的尸体），发生在不同的土地覆盖层中。我应该调查土地覆盖层和发现死亡动物的几率之间是否存在联系（只是为了看看是否有一些奇怪的事情发生，比如在路上发现的鱼比在湖里发现的鱼多）。所以只是为了看看我的数据是否合理，或者收集/采样这些动物的过程是否太糟糕，以至于我们无法用它来推断栖息地对动物的重要性。
我有 145 个地点，大小都一样。对于每个位置，我都有 n（动物目击次数）和每个位置的土地覆盖率百分比。
我对统计的知识还在萌芽阶段，我是一个狂热爱好者，但请随意批评我（只需使用我能理解的术语）。
计数数据表示泊松分布，分布类似于泊松分布，我进行了单样本 K-S 检验，分布与泊松分布没有显著差异。预测变量之间没有多重共线性。我检查了均值与方差，差别太大（1.02 vs 1.8）。泊松回归证实了这一点（值/df=1.459）。所以我查阅了文献，文献中说做一个负二项式，但事先检查零。事实上，在 145 个分析单位中，有 80 个是零目击。我不知道哪些是真正的零，哪些是多余的零。我是否应该放弃做负二项式的想法？有没有更简单的方法可以做到这一点？因为我没有信心（知识不够）来处理这些零。它们是否相关？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649531/relating-animal-sightings-with-land-cover-poisson-negative-binomial-zero-inf</guid>
      <pubDate>Wed, 19 Jun 2024 15:39:58 GMT</pubDate>
    </item>
    </channel>
</rss>