<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 18:22:05 GMT</lastBuildDate>
    <item>
      <title>在二元变量上对模型输出进行测试</title>
      <link>https://stats.stackexchange.com/questions/653982/test-between-model-output-over-a-binary-variable</link>
      <description><![CDATA[我有一组特征，包括一个二进制变量（称为 $B$）和一些其他变量（二进制或数值变量，我们称这些协变量为 $X$）。
我有一个目标变量，可以是二进制的，也可以是数值的，但我们简单来说，它是数值的，称为 $Y$。
我拟合了一个模型 $M$，以根据特征 $X$ 和 $B$ 预测 $Y$。该模型可以是“优化的”，也可以是垃圾，这无关紧要。事实是模型是拟合的。
现在我预测（使用相同的训练数据或一些看不见的测试数据，我不认为它真的改变了问题？）两个数量。

$Y_{B=1}$ 是当对于个体，我保持其为协变量 $X$，但我强制二元特征 $B$ 为 $1$（即使个体的 $B$ 的实际值不是 $1$）。
$Y_{B=0}$ 是当对于个体，我保持其为协变量 $X$ 但我强制二元特征 $B$ 为 $0$。

然后我想知道平均而言这两个量是否不同。因此，从统计上看，$Y_{B=1} = Y_{B=0}$ 是否等同于 $Y_{B=1} - Y_{B=0} = 0$，并得到该假设的 p 值。
例如，使用没有交互项的简单线性回归，我可以检查 $B$ 的系数和相关的 p 值（并且差值 $Y_{B=1} - Y_{B=0}$ 在这种情况下始终相同，并且等于 $B$ 系数）。
但对于更复杂的模型（随机森林等），通常会有一些相互作用。
所以，我的问题是：哪种统计检验（或测试）似乎合适吗？

数据不独立（$Y_{B=1}$ 和 $Y_{B=0}$ 仍然依赖于同一模型 $M$ 和协变量 $X$）。
组间方差（$B=1$ 和 $B=0$）可能不同。

我寻找了治疗效果（ATE、ATT 等）的估计，但没有找到我可以使用哪种测试的明确解释，因为在这些情况下通常使用简单的线性回归模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/653982/test-between-model-output-over-a-binary-variable</guid>
      <pubDate>Fri, 06 Sep 2024 18:12:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 r 中的 glmer 函数进行预测（二项式数据）</title>
      <link>https://stats.stackexchange.com/questions/653981/predicting-with-the-glmer-function-in-r-binomial-data</link>
      <description><![CDATA[我正在尝试使用 glmer 函数对嵌套数据进行预测。我有来自田地中多个设备的纵向数据，这些设备要么是控制设备，要么是封闭设备。我创建了验证，这样训练集和验证集就不会有相同的设备，因为设备之间存在相关性。在我建立模型并进行预测后，它只预测了控制处理。我不确定我做了什么。总共有 60 000 个观测值，50 个设备，其中 39 个是控制设备，11 个是封闭设备。下面是代码以及前 6 个预测值的样子
cont_data_st = filter(evening_data,treatment==&quot;control&quot;) ##control data
exc_data_st = filter(evening_data,treatment==&quot;exclusion&quot;) ##exclosure data 
devices_cont_st = unique(cont_data_st$station_id) ##control devices
devices_exc_st = unique(exc_data_st$station_id) ##exclosure devices

set.seed(1000)
a = sample(devices_cont_st,27)
b = sample(devices_exc_st,8)

train_devices_st = c(a,b)
train_st &lt;- filter(evening_data,station_id %in% train_devices_st) 
valid_st &lt;- filter(evening_data,!station_id %in% train_devices_st) 

glm_st = glmer(treatment ~ total_ent + aci + bi + ndsi + (1|station_id),
data = train_st,
family =binomial(link = &#39;logit&#39;))

pred = predict(glm_st, type=&quot;response&quot;,newdata=valid_st,allow.new.levels=TRUE)
pred
1 2 3 4 5 6 
1.915576e-09 8.840530e-10 7.312132e-10 6.585357e-09 3.300025e-09 3.662728e-09 

]]></description>
      <guid>https://stats.stackexchange.com/questions/653981/predicting-with-the-glmer-function-in-r-binomial-data</guid>
      <pubDate>Fri, 06 Sep 2024 17:59:20 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑回归模型中的膨胀固定效应</title>
      <link>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</link>
      <description><![CDATA[我有一个数据集，每个 ID 有多个观测值，并且有一个二元结果。我试图拟合混合效应逻辑回归，但是，截距的固定效应估计值与我的预期相比非常大。无论我使用的是哪个统计软件包或 R 版本，这都是正确的：
library(lme4)
library(glmmTMB)
library(brms)

fit_lme4 &lt;- glmer(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_TMB &lt;- glmmTMB(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_brm &lt;- brm(outcome ~ (1 | ID), data = data, family = bernoulli(link=&quot;logit&quot;))

mean(data$outcome) # 0.7371429
plogis(fixef(fit_lme4)) # 0.9993405
plogis(fixef(fit_lme4)$cond) # 0.9993405
plogis(summary(fit_brm)$fixed[[1]]) # 0.9452537

以下是用于重现上述脚本的 data 的内容。
我怀疑这可能是因为许多 ID 总是有相同的结果（例如，对于 ID 1，结果始终为 1），但我不确定。
对此有什么潜在的解决方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</guid>
      <pubDate>Fri, 06 Sep 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>使用聚类层次数据的中介分析（在 JASP 中）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653974/mediation-analysis-with-clustered-hierarchical-data-in-jasp</link>
      <description><![CDATA[我有一个三级层次结构（参与者来自不同的班级和学校）。我想执行中介分析，以便解释我的聚类数据，最好是在 JASP 中。
我在 JASP 中有两个选项：SEM 模块中的“中介分析”，或 PROCESS，现在也已添加到 JASP 中。
有人知道如何执行此操作（在 JASP 中）吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653974/mediation-analysis-with-clustered-hierarchical-data-in-jasp</guid>
      <pubDate>Fri, 06 Sep 2024 15:53:46 GMT</pubDate>
    </item>
    <item>
      <title>R 包文档命名空间和说明[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653972/r-package-documentation-namespace-and-description</link>
      <description><![CDATA[早上好，
我正在编写 R 包的初稿，我已经从包 corrplot 中导入了函数 corrplot，并将其添加到 NAMESPACE（使用 roxygen2）。即：
importFrom(corrplot,corrplot)

我不再需要这个函数（我使用 ggplot2），但我无法从 NAMESPACE 文件中删除它。我尝试从DESCRIPTION文件中删除包corrplot（如下所示），但当我重新记录包时，它给了我一个错误并且没有从NAMESPACE中删除该函数。
导入： 
stats,
pracma,
GB2,
acid,
methods,
tidyr,
ggplot2, 
ggcorrplot, 
gridExtra, 
grid, 
corrplot

我也尝试运行devtools::clean_all()但这也不起作用。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653972/r-package-documentation-namespace-and-description</guid>
      <pubDate>Fri, 06 Sep 2024 15:01:33 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 VAR 模型中的高峰度</title>
      <link>https://stats.stackexchange.com/questions/653969/how-to-deal-with-high-kurtosis-in-var-model</link>
      <description><![CDATA[我试图在 Stata 上建立一个 VAR 模型，以找出一些变量（汇率、波动性、贸易开放度、GDP 和入学率）对 FDI 流入的影响。虽然它们中的大多数在 ADF 测试的水平上不是平稳的，但它们在微分之后都是平稳的（至少在滞后 0 和 1 时是平稳的：有些在滞后 2 时不是）。
由于它们处于相同的积分阶数，我决定建立一个 VAR 模型，但 R² 太低了（19%）。当我开始进行诊断时：残差没有自相关，模型是稳定的，但这些残差的分布不正常（jarque bera 检验的 p 值为 0.0000，偏度很好，但峰度也是 0.000）
我尝试过使用对数变换（除了 FDI，因为它上面有负数），但这并没有解决问题。那么有没有什么方法可以降低峰度？异方差检验（Breusch–Pagan/Cook–Weisberg 检验）为 0.0599，但我不确定这是否与此有关]]></description>
      <guid>https://stats.stackexchange.com/questions/653969/how-to-deal-with-high-kurtosis-in-var-model</guid>
      <pubDate>Fri, 06 Sep 2024 14:21:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解释独立变量编码实验组的偏相关性？</title>
      <link>https://stats.stackexchange.com/questions/653968/how-to-interpret-a-partial-correlation-where-the-independent-variable-codes-expe</link>
      <description><![CDATA[假设我有 3 个变量：实验组 (A/B)、态度和年龄。我将它们全部放入回归分析中，得到 Y 轴上实验组的偏相关，X 轴上态度的偏相关。我们可以对这张图做出任何解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653968/how-to-interpret-a-partial-correlation-where-the-independent-variable-codes-expe</guid>
      <pubDate>Fri, 06 Sep 2024 13:50:38 GMT</pubDate>
    </item>
    <item>
      <title>样本中未观察到任何事件时的患病率上限</title>
      <link>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</link>
      <description><![CDATA[在 2000 个观察样本中，未发现阳性病例，但我仍然希望能够提供患病率的上限。
人们似乎使用的一般规则是简单地取 3/n，但这与样本中发现 1 个病例的 95% 上限相同。
3/2000=0.15%，2000 年患病率为 1 例的 95% 上限为 0.15%。
如果观察到 0 个病例，上限肯定应该低于发现 1 个病例的情况？我可以使用其他方法来与其他频率结果在一定置信水平下的上限保持一致吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</guid>
      <pubDate>Fri, 06 Sep 2024 12:04:43 GMT</pubDate>
    </item>
    <item>
      <title>我们是否可以将 Mann–Whitney U 检验的零值，即 $P(x_i > y_j) = P(y_j > x_i)$ 解释为等同于 $F = G$（其中 $F$ 和 $G$ 是 ECDF）？</title>
      <link>https://stats.stackexchange.com/questions/653962/can-we-interpret-the-null-of-the-mann-whitney-u-test-i-e-px-i-y-j-py-j</link>
      <description><![CDATA[简介。

让我们考虑一个 $n$ 个观测样本 $\{x_i\} = \{x_1, x_2, \ldots x_n\}$，它们来自总体 $X$，以及一个 $m$ 个观测样本 $\{y_j\} = \{y_1, y_2, \ldots y_m\}$，它们来自总体 $Y$。

让我们考虑 Mann–Whitney $\displaystyle U$ 检验（也称为 Wilcoxon 秩和检验），以及其零假设和备择假设：

$H_0$：$P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ $\quad$ $\bigl($
即&quot;$x$ 和 $y$&quot; $\bigl)$
$H_A$: $P(x_i &gt; y_j) \neq P(y_j &gt; x_i)$ $\;$ $\bigl($ 即 &quot;$x$ 将
随机大于/小于 $y$&quot; $\bigl)$


让我们考虑一下 Mann &amp; Whitney (1947) 论文：




简介。设 $x$ 和 $y$ 分别为具有连续累积分布函数 $F$ 和 $G$ 的两个随机变量。
如果对于每个 $a$ 都有 $F(a) &gt; G(a)$，则变量 $x$ 将被称为随机小于 $y$。我们希望检验假设 $F = G$
与备选假设 $x$ 随机小于 $y$ 的对立面。


问题。

我们能否将 $H_0$: $P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ 解释为等同于 $F = G$?
$\bigl($或者， ... class=&quot;math-container&quot;&gt;$H_A$: $P(x_i &gt; y_j) \neq P(y_j &gt; x_i)$ 是否等同于 $F &gt; 或 &lt; G$?$\bigl)$
如果是，则零值 $P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ 将对应于 ECDFs 点位于 p-p 图，因为$F = G$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653962/can-we-interpret-the-null-of-the-mann-whitney-u-test-i-e-px-i-y-j-py-j</guid>
      <pubDate>Fri, 06 Sep 2024 10:53:17 GMT</pubDate>
    </item>
    <item>
      <title>当仅观察到数据的最大值时，统计量完整且充分</title>
      <link>https://stats.stackexchange.com/questions/653960/complete-and-sufficient-statistic-when-only-the-maximum-of-the-data-is-observed</link>
      <description><![CDATA[
我找到了联合 PDF，但之后无法应用分解。
我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/653960/complete-and-sufficient-statistic-when-only-the-maximum-of-the-data-is-observed</guid>
      <pubDate>Fri, 06 Sep 2024 10:05:12 GMT</pubDate>
    </item>
    <item>
      <title>Riley 等人提出的计算样本量的公式存在错误</title>
      <link>https://stats.stackexchange.com/questions/653958/an-error-in-formula-proposed-by-riley-et-al-to-calculate-the-sample-size</link>
      <description><![CDATA[我使用以下函数来查找 cox 比例风险比（由 Riley 等人提出）的最小样本量。令人惊讶的是，估计的事件数量超过了预期的样本量。我想知道您是否知道原因？ 这是由于事件率值过高吗？估计的结果事件为 2131，估计的样本量为 1715。
 library(pmsampsize)
pmsampsize(type = &quot;s&quot;, csrsquared = 0.051, parameters = 10, rate = 0.6, timepoint = 2, meanfup = 2.07)

* s 指生存模型。
* 参数指模型中的参数数量
* 速率指事件发生率
* 平均值指平均随访时间（年）
* 时间点指预测感兴趣的时间点

注意：假设表观和平均值的差异为 0.05，可接受调整后的 R 平方 
NB：假设在时间点 = 2 时估计总体风险的误差幅度为 0.05 
NB：每个预测参数的事件数 (EPP) 假设总体事件率 = 0.6 

样本大小收缩参数 CS_Rsq Max_Rsq Nag_Rsq EPP
标准 1 1715 0.900 10 0.051 0.857 0.06 213.0
标准 2 223 0.543 10 0.051 0.857 0.06 27.7
标准 3 * 1715 0.900 10 0.051 0.857 0.06 213.0
最终 SS 1715 0.900 10 0.051 0.857 0.06 213.0

根据用户输入，新模型开发所需的最小样本量 = 1715，
相当于 3550 人次**的随访，2131 个结果事件
假设总体事件率 = 0.6，因此 EPP = 213
总体风险的 95% CI = (0.683, 0.714)，真实值为 0.699，样本量 n = 1715
其中时间的单位为平均随访时间
]]></description>
      <guid>https://stats.stackexchange.com/questions/653958/an-error-in-formula-proposed-by-riley-et-al-to-calculate-the-sample-size</guid>
      <pubDate>Fri, 06 Sep 2024 09:43:43 GMT</pubDate>
    </item>
    <item>
      <title>平均随访时间</title>
      <link>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</link>
      <description><![CDATA[*我正在使用 R 中的 pmsampsize 函数来计算 cox 比例风险模型（试点研究）的样本量。我需要输入 meanfup 的值（type=&quot;s&quot; 选项）指定模型开发数据集中个人预期的平均（均值）随访时间。但我仍然不确定如何计算平均（均值）随访时间。任何建议都将不胜感激。
例如：假设包括 T0、T3、T6、T9、T12、....、T24（月）患者的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</guid>
      <pubDate>Fri, 06 Sep 2024 06:55:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信度 > 50% 还不是“足够好”？</title>
      <link>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</link>
      <description><![CDATA[我上过研究生水平的统计学课程，所以问这个问题感觉自己很蠢，但我不明白 95% 置信度背后的含义。（请对我好一点。）
我目前正在对两张图片进行 A/B 测试，用于营销。测试将运行并收集数据，直到它能够在 95% 的置信度下做出决定。
当前置信率为 76.55%，其中 A 的点击率为 2.5%，B 的点击率为 4.55%。
由于 A 和 B 在 50% 的置信度下大致相等（一个设计没有显示出比另一个更好），为什么我要等到 95% 的置信度？在 50% 的置信度下，我选择哪种设计并不重要，而在 76.55% 的置信度下，我已经显示 B 的表现优于 A。
我想我不明白为什么我现在不能做出决定。如果是在制药情况下进行测试，比如生死攸关场景中的药物，我觉得我应该等待 95%，但对于像图像选择这样低风险的事情...]]></description>
      <guid>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</guid>
      <pubDate>Fri, 06 Sep 2024 01:33:52 GMT</pubDate>
    </item>
    <item>
      <title>百分比比较和数量级</title>
      <link>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</link>
      <description><![CDATA[也许这是一个过于简单的问题。
假设有以下两个案例：
案例 1：患者人数/患者总数：63.080/1.335.636 = 4.7%
案例 2：患者人数/患者总数：5.840.431/59.030.133 = 9.8%
我如何比较这两个百分比？换句话说，如果可以将案例 1 的分子和分母设置为与案例 2 具有相同的数量级，或者最好是反之亦然，那么它们可能并没有太大的不同。既然如此，它们当然是不同的，因为数量级不同。
有人能帮帮我吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</guid>
      <pubDate>Thu, 05 Sep 2024 14:46:51 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\sum_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\sum_i x_i^2}{n}$。
在大多数文本中我看到前者，但在财务数据的背景下我有时看到后者。两者似乎也都有意义，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    </channel>
</rss>