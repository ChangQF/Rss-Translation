<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 15:17:55 GMT</lastBuildDate>
    <item>
      <title>m模型的目标函数</title>
      <link>https://stats.stackexchange.com/questions/654107/objective-function-of-m-model</link>
      <description><![CDATA[我试图将多变量指数模型拟合到一些观察面板数据（m 个点和 n 个时间观察的空间和纵向数据）。我想为每个观察（每个点的 n_j 不同）拟合一个跨时间（n 维或垂直）的独立模型，以最小化某个目标函数 (1)。我对目标函数 (1) 使用梯度下降和平方误差和
$\ SSE=\sum_{i=1}^n (y_i - \hat{y_i})^2 \\:$ ...(1)
但是，我的总体目标是最小化所有 m 个模型（水平）中的误差。
我正在考虑使用与目标函数 (1) 相关的目标函数 (2) 来同时评估所有模型，作为梯度下降的目标函数。在这种情况下，这可以是目标函数 (1) 的 SSE 的均方误差
$\ MSE&#39; = \frac{1}{m}\sum_{j=1}^m (SSE_j)^2 \\:$ ...(2)
我想对此类问题有一些既定的研究，但我找不到来源来找到我的情况的直接答案！我仍然想知道这是否有意义，或者在使用这种总体目标时我应该注意哪些缺点？我将不胜感激见解和建议
*我选择平方误差的“总和”是因为在我的案例中，每个模型的 n 都不同。因此，在评估目标函数 (2) 时，总和作为与 n 维度中包含的观测值数量相对应的加权值。]]></description>
      <guid>https://stats.stackexchange.com/questions/654107/objective-function-of-m-model</guid>
      <pubDate>Mon, 09 Sep 2024 14:58:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决贝叶斯分析中有关 beta 分布的这个问题？</title>
      <link>https://stats.stackexchange.com/questions/654106/how-to-solve-this-question-about-the-beta-distribution-in-a-bayesian-analysis</link>
      <description><![CDATA[该问题出现在 Babak Shahbaba 教授的书（使用 R 进行生物统计学：通过生物数据进行统计学入门）第 13 章的问题中。

Q4。假设我们对皮马印第安妇女中受糖尿病影响的人口比例感兴趣。让我们用随机变量 X 表示每个人的糖尿病状况，其中如果该人患有糖尿病，则 X = 1，如果该人没有糖尿病，则 X = 0。然后我们可以假设 X 具有参数 μ 的伯努利分布。我们知道整个美国糖尿病女性的人口比例约为 10%。我们希望使用此信息来指定 μ 的先验。使用 R-Commander 找到具有相对较高概率密度值（约为 0.1）的 beta 分布。为此，通过更改参数绘制不同的 beta 分布，直到找到一个分布，该分布的概率密度曲线下面积在 0.05 到 0.15 的区间内较大。然后，使用 Pima.tr 数据（可从 MASS 包获得）找到 μ 的后验概率分布。使用后验概率分布获得 μ 的点估计和 95% 可信区间。

我的试验
library(tidyverse)
library(MASS)

x &lt;- seq(0, 1, by = 0.01)
dfb1 &lt;- tibble(x, prob = dbeta(x, shape1 = 1, shape2 = 9), curve = &quot;Beta(1, 9)&quot;, line = 1, sh1 = 1, sh2 = 9)
dfb2 &lt;- tibble(x, prob = dbeta(x, shape1 = 0.5, shape2 = 5), curve = &quot;Beta(0.5, 5)&quot;, line = 1, sh1 = 0.5, sh2 = 5)
dfb3 &lt;- tibble(x, prob = dbeta(x, shape1 = 10, shape2 = 90), 曲线 = &quot;Beta(10, 90)&quot;, 线 = 1, sh1 = 10, sh2 = 90)
dfb4 &lt;- tibble(x, prob = dbeta(x, shape1 = 0.1, shape2 = 0.9), 曲线 = &quot;Beta(0.1, 0.9)&quot;, 线 = 1, sh1 = 0.1, sh2 = 0.9)
dfb5 &lt;- tibble(x, prob = dbeta(x, shape1 = 100, shape2 = 900), 曲线 = &quot;Beta(100, 900)&quot;, 线 = 1, sh1 = 100, sh2 = 900)

df &lt;- dfb1 %&gt;%
dplyr::bind_rows(dfb2) %&gt;%
dplyr::bind_rows(dfb3) %&gt;%
dplyr::bind_rows(dfb4) %&gt;%
dplyr::bind_rows(dfb5) %&gt;%
dplyr::mutate(curve = factor(curve)) %&gt;%
dplyr::mutate(line = factor(line)) %&gt;%
group_by(curve) %&gt;%
dplyr::mutate(xhigh = sh1 / (sh1 + sh2), highest = dbeta(x = xhigh, shape1 = sh1, shape2 = sh2)) %&gt;%
ungroup()

ggplot(df) +
geom_line(aes(x, prob, color = curve, linetype = line), size = 0.5) +
geom_point(aes(xhigh, highest, color = curve), size = 3) + 
scale_color_brewer(palette = &quot;Dark2&quot;, name = &quot;Curve&quot;) +
scale_linetype(guide = &quot;none&quot;) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) + 
theme_minimal()

绘图

我的试验答案
pbeta(q = 0.15, shape1 = 0.1, shape2 = 0.9, lower.tail = TRUE) - pbeta(q = 0.05, shape1 = 0.1, shape2 = 0.9, lower.tail = TRUE) #0.08547915
pbeta(q = 0.15, shape1 = 0.5, shape2 = 5, lower.tail = TRUE) - pbeta(q = 0.05, shape1 = 0.5, shape2 = 5, lower.tail = TRUE) #0.2712344
pbeta(q = 0.15, shape1 = 1, shape2 = 9, lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 1，shape2 = 9，lower.tail = TRUE) #0.3986325
pbeta(q = 0.15，shape1 = 10，shape2 = 90，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 10，shape2 = 90，lower.tail = TRUE) #0.9139534
pbeta(q = 0.15，shape1 = 100，shape2 = 900，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 100，shape2 = 900，lower.tail = TRUE) #0.9999987
pbeta(q = 0.15，shape1 = 1000，shape2 = 9000，lower.tail = TRUE) - pbeta(q = 0.05，shape1 = 1000，shape2 = 9000，lower.tail = TRUE) #1

因此，我猜测参数shape1和shape2应该分别为100和900，因为它们在0.1附近具有较大的概率密度面积（p = 0.9999987）。我的结论对吗？
需要什么？
我有兴趣解决这一部分：

为此，通过更改参数绘制不同的beta分布，直到找到一个概率密度曲线下面积在0.05到0.15区间内较大的分布。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654106/how-to-solve-this-question-about-the-beta-distribution-in-a-bayesian-analysis</guid>
      <pubDate>Mon, 09 Sep 2024 14:55:39 GMT</pubDate>
    </item>
    <item>
      <title>计算逆伽马分布的熵</title>
      <link>https://stats.stackexchange.com/questions/654105/computing-entropy-of-inverse-gamma-distribution</link>
      <description><![CDATA[我在数学上问过这个问题，没有得到答案，但也许这里更好。
我试图计算逆伽马分布的熵，结果总是负数。显然这是错误的，因为熵总是正数。维基百科有逆伽马熵的推导，据我所知是正确的：公式
但当我用较大的 alpha 计算时，结果通常为负数。此外，此处还有一个标准 JS 函数，它给出了输出为负的示例，如下所示：

@example
var v = entropy( 8.0, 2.0 );
// 返回 ~-0.922

我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654105/computing-entropy-of-inverse-gamma-distribution</guid>
      <pubDate>Mon, 09 Sep 2024 14:55:18 GMT</pubDate>
    </item>
    <item>
      <title>对大数据集进行子采样和多重测试</title>
      <link>https://stats.stackexchange.com/questions/654103/subsampling-large-data-set-and-multiple-testing</link>
      <description><![CDATA[考虑一组点$X=\{x_{1},...,x_{N}\}\subset [0,1]^{d}$，这些点独立于分布$P$进行采样。设$T$为检验统计量，$C\in\mathbb{R}$为相关检验。如果 $N$ 很大，并且 $T$ 难以计算，则一个（可能很简单？）策略是考虑 $K$ 个大小为 $n$ 的子样本，这些子样本来自 $X$，表示为 $X^{(1)}$, ..., $X^{(K)}$，并对每个子样本使用检验 $\phi$。
它可能需要以某种方式假设子样本 $X^{(1)}$, ..., $X^{(K)}$（无替换？独立性？）。但是，是否有任何工作为此类方法提供理论保证（例如，对第一类和第二类错误的约束）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654103/subsampling-large-data-set-and-multiple-testing</guid>
      <pubDate>Mon, 09 Sep 2024 14:19:37 GMT</pubDate>
    </item>
    <item>
      <title>具有时间变化协变量的 Cox 回归与离散时间 Cox 模型之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654101/difference-between-a-cox-regression-with-a-time-varying-covariate-and-discrete-t</link>
      <description><![CDATA[我很好奇离散时间 Cox 模型和具有时间依赖性协变量的 Cox 回归之间的区别。我的数据集包含一个单一事件变量和一个二元协变量，如下所示。我可以将治疗视为时间依赖性协变量吗？我知道风险比的值 = 0.4（来自类似研究）。我想知道哪种方法是正确的选择。
ID 时间 事件 治疗（协变量）
1 0 0 0
1 1 0 1
1 2 1 1
2 0 0 0
2 1 0 0
2 2 0 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/654101/difference-between-a-cox-regression-with-a-time-varying-covariate-and-discrete-t</guid>
      <pubDate>Mon, 09 Sep 2024 13:58:34 GMT</pubDate>
    </item>
    <item>
      <title>如何确定因素和相互作用内的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</link>
      <description><![CDATA[我的研究结构如下（虚假信息，相同想法）：
因素 A：3 个水平（3 种细菌菌株）
因素 B：3 个水平（3 种抗菌剂）
因素 C：2 个水平（细菌生长阶段：早期、老年）
因素 D：6 个水平（抗菌剂剂量：5、10、15、20 毫克）
感兴趣的测量：存活人口，$X$
我想知道：

在考虑因素 A 或因素 B 时，因素 C 是否会显著影响存活人口的测量，$X$？
在比较因素 A（或因素 B）的 3 个水平时，是否存在存活人群中存在显著差异，$X$？

我的直觉是将数据分成子集并进行多次方差分析，以比较因子 A 和因子 B 在每种剂量（因子 D）下的效果。并通过进行多次 t 检验来比较两种治疗水平。但我觉得这是错的。我从未使用过“复杂”（对我来说）的模型，感觉很迷茫。]]></description>
      <guid>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</guid>
      <pubDate>Mon, 09 Sep 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能求解 $\|X-A\|_2+\lambda_n\|X\|_1$？</title>
      <link>https://stats.stackexchange.com/questions/654099/is-it-possible-to-solve-x-a-2-lambda-n-x-1</link>
      <description><![CDATA[在深入了解了套索之后，我想到了一个想法：我们能否得到一个估计量$\hat{X}$，其谱范数与目标矩阵$A$相似？添加惩罚项以获得稀疏/低秩估计量，我认为这可以表示为解决以下优化问题
$$
\hat{X}=\underset{X\in\mathbb{R}^{n\times n}}{\operatorname{arg\,min}}\|X-A\|_2+\lambda_n\|X\|_1
$$
或
$$
\hat{X}=\underset{X\in\mathbb{R}^{n\times n}}{\operatorname{arg\,min}}\|X-A\|_2+\lambda_n\|X\|_{\text{nuclear}}.
$$
其中 $\|\cdot\|_2$ 表示谱范数，$\|X\|_1=\underset{i,j}{\sum}|X_{ij}|$ 和 $\|\cdot\|_{\text{nuclear}}$ 表示核范数。
这个问题有得到很好的研究吗？如果是，我应该用什么关键词来查找相应的论文？]]></description>
      <guid>https://stats.stackexchange.com/questions/654099/is-it-possible-to-solve-x-a-2-lambda-n-x-1</guid>
      <pubDate>Mon, 09 Sep 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>使用伪回归来检验 MANOVA 假设</title>
      <link>https://stats.stackexchange.com/questions/654097/pseudo-regression-as-a-way-of-checking-manova-assumptions</link>
      <description><![CDATA[我偶然发现了一个在线教程（YT 系列，据说是统计学研究生课程），用于在 R 中实现 MANOVA 测试。在进行测试之前，需要测试一些重要的假设。作者部署了一个假回归，作为测试响应变量（因变量/DV）的线性组合是否满足正态性、线性和同质性/同方差性的假设的一种手段。
与帖子相关的假设：
$\mathbf{假设\ 1}$：因变量（即误差向量）是从多元正态分布中抽样的。
$\mathbf{假设\ 2}$：假设/预期这两个或多个连续因变量（DV）之间存在某种相关性。理想情况下，它们之间的关系是线性的，否则 MANOVA 将无法捕获和利用它（这里没有疑问，因为有些文献没有将其作为这些假设的一部分）。
$\mathbf{假设 3}$：所有因变量 (DV) 都显示协方差和方差的同质性。
以下是 R 代码中的具体设置以及作者的进行方式：
假设我们有一个设计矩阵 $\mathbf{X}$，包含三列，分别对应于 $DV_1$、$DV_2$、$DV_3$。
作者在 R 中基于卡方分布模拟了具有相同数量随机观测值的样本。
random &lt;- rchisq( nrow($\mathbf{X}$), df)
然后，此“随机”用作以下假回归的响应变量，其中$DV_1$、$DV_2$、$DV_3$：
fake &lt;- lm(random ~. , data=$\mathbf{X}$)
通过使用 rstudent()，标准化残差（作者称之为）被检索用于残差分析/诊断分析。
标准化 &lt;- rstudent(fake)
合理的原因是，模拟响应变量“随机”是卡方分布的，并且与$DVs$的相关性最小，回归线只是一条直线，残差也是具有卡方分布的随机变量。另一方面，标准化残差 (rstudent(fake)) 呈正态分布，这使我们能够通过检查直方图和 QQ 图来检查正态性和线性假设是否合理满足。
R 代码
正态性：
hist(标准化)
线性：
qqnorm(标准化)
然后，作者根据以下代码对假回归的拟合值进行标准化，以便于进行视觉比较，并检查共享常数方差和协方差的假设。
R 代码
同质性/同方差性：
fitted &lt;- scale(fake$fitted.values)
plot(fitted, 标准化)
所以这是我们通常看到的拟合与残差图OLS 回归。
问题：
1，为什么是卡方分布？为什么不是正态分布，这样残差就是正态分布？如果 QQ 图和直方图确实显示出合理的正态分布，那么它们对于 DV 到​​底意味着什么？
2，为什么使用 rstudent()？rstudent() 函数相当于用于检测异常值的折刀检验。我不明白它如何以这种方式用于残差诊断。
3，它是否是一种适合测试这些假设的技术，还是我误解了作者的意思？我对这种检查上述假设的方式的底层逻辑有些困惑。
我们通常只查看椭圆和协方差-方差矩阵的$DVs$的成对联合分布的图，并发现它们相当相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/654097/pseudo-regression-as-a-way-of-checking-manova-assumptions</guid>
      <pubDate>Mon, 09 Sep 2024 13:21:07 GMT</pubDate>
    </item>
    <item>
      <title>如果我的 ARDL 结果与文献不符该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/654096/what-if-my-ardl-results-doesnt-follow-the-litterature</link>
      <description><![CDATA[我实际上正在写一篇关于货币政策的论文，我正在通过 Eviews 使用 ARDL 进行估算。我的结果表明，政策利率对通货膨胀率产生正向影响，这与文献所说的相反。我已经检查了所有测试，该模型是有效的。什么可以解释这种情况，或者我应该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/654096/what-if-my-ardl-results-doesnt-follow-the-litterature</guid>
      <pubDate>Mon, 09 Sep 2024 13:11:29 GMT</pubDate>
    </item>
    <item>
      <title>条件剩余事件时间悖论</title>
      <link>https://stats.stackexchange.com/questions/654095/conditional-remaining-time-to-event-paradox</link>
      <description><![CDATA[事件发生的条件预期剩余时间似乎随着等待时间的增加而增加。这似乎是错误的，或者像某种悖论。
让我们以 Lomax 分布为例。假设我们正在等待一个事件，事件的等待时间分布为
$$f(x)=\frac{a}{b}\left[1+\frac{x}{b}\right]^{-(a+1)}$$
其中 $a&gt;2$ 和 $b&gt;0$。还假设我们在时间 $T$ 观察到事件尚未发生。等待时间的条件密度变为
$$f(x|x\geq T)=\frac{f(x)}{f(x\geq T)}=\frac{f(x)}{1-f(x&lt; T)}=\frac{\frac{a}{b}\left[1+\frac{x}{b}\right]^{-(a+1)}}{\left[1+\frac{T}{b}\right]^{-a}}$$
假设我们观察到事件在时间 $T$ 未发生，则等待时间的预期值为
$$E[X|x\geq T]=\int_{T}^{\infty}xg(x|x\geq T)=\left[1+\frac{T}{b}\right]^{a}\int_{T}^{\infty}\frac{a}{b}x\left[1+\frac{x}{b}\right]^{-(a+1)}dx$$
积分可以用分部积分法求得。
$$\int_{T}^{\infty}\frac{a}{b}x\left[1+\frac{x}{b}\right]^{-(a+1)}dx=-x(1+\frac{x}{b})^{-a}\vert_{T}^{\infty}+\frac{b}{-a+1}(1+\frac{x}{b})^{-a+1}\vert_{T}^{\infty}$$
$$=T(1+\frac{T}{b})^{-a}-\frac{b}{-a+1}(1+\frac{T}{b})^{-a+1}$$
我使用了以下操作来评估 $\infty$。
$$x(1+\frac{x}{b})^{-a}=x^{-a}x^{a+1}(1+\frac{x}{b})^{-a}=x^{a+1}\left[x(1+\frac{x}{b})\right]^{-a}=x^{a+1}\left[\frac{x^{2}}{b}+x\right]^{-a}$$
应该清楚的是，当 $x\rightarrow\infty$ 为 $a&gt;2$ 时，这会趋于零，尽管它可能更严格。
那么最终的预期值为
$$\left[1+\frac{T}{b}\right]^{a}\left[T(1+\frac{T}{b})^{-a}-\frac{b}{-a+1}(1+\frac{T}{b})^{-a+1}\right]=T+\frac{b}{a-1}\left[1+\frac{T}{b}\right]^{a}$$
如果我们关心的是观察后的等待时间，而不是总等待时间
$$\frac{b}{a-1}\left[1+\frac{T}{b}\right]^{a}$$
因此，在我们注意到事件尚未发生之后，预期的额外等待时间至少会呈二次增长 ($a&gt;2$) 与我们观察的时间有关。这对我来说似乎非常违反直觉。通常，如果您等待某个事件发生一段时间并且它还没有发生，您会假设它会很快发生。我想知道我是否错过了什么或搞砸了什么？也许这是 Lomax 分布尾部较重的结果？这个结果有直观的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654095/conditional-remaining-time-to-event-paradox</guid>
      <pubDate>Mon, 09 Sep 2024 13:04:30 GMT</pubDate>
    </item>
    <item>
      <title>预测下一个客户的购买日期（以及可能的购买金额）</title>
      <link>https://stats.stackexchange.com/questions/654094/predicing-next-customers-purchase-dates-and-possibly-amount</link>
      <description><![CDATA[我需要一些帮助。我有一个数据集，其中包含客户、购买日期和金额的简单列表。我想预测每个客户的下一次购买日期以及可能的金额。



客户
购买日期
金额




A
05/05/2024
100000


A
16/05/2024
50000 


B
05/05/2024
75000


B
05/06/2024
75000



有些客户每个月都会买东西，有些客户每个月会买两次，等等。在一年中的某些时期，客户会有不同的高峰期，购买量会大得多。例如，有些客户在夏天买的东西多得多，而有些客户在冬天或特定月份买的东西多得多。
我尝试过但没有成功：auto arima 和 prophecy
我尝试使用 python auto arima 训练模型，但结果不佳。我也尝试过 facebook prophecy。似乎这些模型在处理这种零散数据时并不是最好的？他们给了我每个日期的预测金额，我试图只过滤“高峰”日期。
你能和我分享一些适合这种目标的模型吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654094/predicing-next-customers-purchase-dates-and-possibly-amount</guid>
      <pubDate>Mon, 09 Sep 2024 12:59:09 GMT</pubDate>
    </item>
    <item>
      <title>在调节分析中调节变量和因变量之间是否需要直接关系？</title>
      <link>https://stats.stackexchange.com/questions/654093/is-a-direct-relationship-between-the-moderator-and-dependent-variable-necessary</link>
      <description><![CDATA[我目前正在与一位朋友讨论回归分析中的调节效应，我想对此进行一些澄清。假设我们有兴趣通过实证检验 X 和 Y 之间是否存在关系，并且我们假设这种影响可能取决于第三个变量 M（调节变量）。我的问题是：在制定我们的假设以说明 X 对 Y 的影响为何取决于 M 时，是否还需要论证 M 和 Y 之间存在直接关系？我的理解是，调节关注的是 M 如何改变 X-Y 关系，而不一定要求 M 对 Y 产生直接影响。但是，我的朋友坚持认为，为了引入调节变量，M 和 Y 之间必须始终存在直接关系。要求这种直接的 M-Y 关系是标准做法吗？还是说，即使没有这样的要求，假设调节效应也足够了？]]></description>
      <guid>https://stats.stackexchange.com/questions/654093/is-a-direct-relationship-between-the-moderator-and-dependent-variable-necessary</guid>
      <pubDate>Mon, 09 Sep 2024 12:52:32 GMT</pubDate>
    </item>
    <item>
      <title>如何计算平均差异的标准差？</title>
      <link>https://stats.stackexchange.com/questions/654092/how-to-calculate-standard-deviation-of-mean-difference</link>
      <description><![CDATA[我有一篇论文，其中报告了参与者的反应时间任务数据。任务条件有两种：“一致”和“不一致”。还有另一种任务时间操纵，有 4 个级别（0、100、200、600）。这两个都是参与者内部变量。
不一致平均值 (sd)：



时间
RT




0
559 (103)


100
538 (106)


200
523 (102)


600
516 (102)



一致平均值 (sd)：



时间
RT




0
543 (104)


100
508 (106)


200
503 (95)


600
514 (100)



我想跨时间折叠以计算不一致和一致条件之间的 RT 平均差异。因此，我得到了以下每个组的平均值和 SD。
不一致：534 (103.26)
一致：517 (101.34)

这里的 SD 是通过对每个 SD 求平方，除以 4 并取平方根来计算的。

因此，平均差异为 534-517=17。
如何计算标准差？
我发现了以下内容，但不确定样本大小 n 指的是什么：
样本均值差异的标准差 (σd) 大约等于：
σd = sqrt( σ1^2 / n1 + σ2^2 / n2 )]]></description>
      <guid>https://stats.stackexchange.com/questions/654092/how-to-calculate-standard-deviation-of-mean-difference</guid>
      <pubDate>Mon, 09 Sep 2024 12:09:37 GMT</pubDate>
    </item>
    <item>
      <title>逐步回归 $R^2$：它有偏差还是不一致？</title>
      <link>https://stats.stackexchange.com/questions/654089/stepwise-regression-r2-is-it-biased-or-inconsistent</link>
      <description><![CDATA[在 Frank Harrell 对逐步回归的歪曲中，他提到通常的$R^2$ 有较高的偏差（我假设当它被计算为通常调整的$R^2$ 时，参数数量设置为逐步选择中幸存的参数数量）。
这听起来很糟糕，但我们一直使用有偏差的估计量。例如，岭回归会导致有偏的参数估计，希望方差的减少足以使均方误差更低，尽管存在偏差。
因此，有偏估计量并不是一个交易破坏者。
但是，如果逐步回归$R^2$估计收敛到高偏差值，那么这种不一致似乎是一个交易破坏者。
那么逐步回归$R^2$估计只是有偏的还是也不一致？]]></description>
      <guid>https://stats.stackexchange.com/questions/654089/stepwise-regression-r2-is-it-biased-or-inconsistent</guid>
      <pubDate>Mon, 09 Sep 2024 11:13:08 GMT</pubDate>
    </item>
    <item>
      <title>通过逐步消除具有“不显著”系数的预测因子来简化线性回归中的模型</title>
      <link>https://stats.stackexchange.com/questions/654085/model-reduction-in-linear-regression-by-stepwise-elimination-of-predictors-with</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654085/model-reduction-in-linear-regression-by-stepwise-elimination-of-predictors-with</guid>
      <pubDate>Mon, 09 Sep 2024 10:21:21 GMT</pubDate>
    </item>
    </channel>
</rss>