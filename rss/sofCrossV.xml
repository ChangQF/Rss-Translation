<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 21:17:29 GMT</lastBuildDate>
    <item>
      <title>关于通过 PCA 投影数据的问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658280/question-about-projecting-down-data-via-pca</link>
      <description><![CDATA[对于问题 C，一旦我将特征向量乘以原始数据矩阵，投影数据的新坐标是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658280/question-about-projecting-down-data-via-pca</guid>
      <pubDate>Wed, 04 Dec 2024 19:47:38 GMT</pubDate>
    </item>
    <item>
      <title>比较 4 x 300 个多元线性回归之间的方差解释</title>
      <link>https://stats.stackexchange.com/questions/658279/compare-variance-explained-between-4-x-300-multiple-linear-regressions</link>
      <description><![CDATA[我计算了四个不同的多元线性回归（模型 1-4），每个回归都有一组不同的独立变量。模型 2 包含模型 1 的所有独立变量，还有一些额外的变量。模型 3 包含模型 2 的所有独立变量，还有一些其他变量，依此类推。我想知道添加更多独立变量是否会导致对因变量方差的预测明显更好。
现在问题来了：每个模型不仅包含一个多元回归，还包含 300 个，每个回归都有一个不同的因变量。这四个模型中的 300 个因变量都是相同的，只是从模型 1 到模型 4 的独立变量越来越多。
如果每个模型都包含 300 个多元回归，那么比较四个模型解释的方差的简单方法是什么？是否可以选择

为每个模型计算一个平均调整后的 R2，即 R2(模型 1) = [R2 (第一次回归，模型 1) + R2(第二次回归，模型 1)+….R2(第 300 次回归，模型 1)] / 300？ 

或

对每个模型的所有调整后的 R2 求和，即 R2(模型 1) = R2 (第一次回归，模型 1) + R2(第二次回归，模型 1)+….R2(第 300 次回归，模型 1)

 获得每个模型的“总 R2”，然后将其与 F 检验进行比较？
另外/另外：我找不到任何可靠且易于理解的来源来获得这个“总 R2”，您知道可以帮助我的论文或关键词吗？
非常感谢大家的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658279/compare-variance-explained-between-4-x-300-multiple-linear-regressions</guid>
      <pubDate>Wed, 04 Dec 2024 18:55:08 GMT</pubDate>
    </item>
    <item>
      <title>调整混杂变量后对 COVID-19 前后 GBS 的分析</title>
      <link>https://stats.stackexchange.com/questions/658276/analysis-of-gbs-before-and-after-covid-19-while-adjusting-for-confounding-variab</link>
      <description><![CDATA[我是统计学新手，希望得到帮助！我正在使用 SPSS，正在开展一个项目，我想分析 COVID-19 对 B 组链球菌 (GBS) 的影响。因此，我有 4 个组（COVID 之前和之后 GBS 阳性，COVID 之前和之后 GBS 阴性）。我有几个变量，既有连续变量也有分类变量（例如：COVID 之前和之后的转诊次数、转诊原因、分娩时的孕周、APGAR 评分等）。我还有这些组的人口统计数据（例如：母亲年龄、孕妇、产妇、之前剖腹产的次数等），我认为这些数据可能是混杂变量。我对这些混杂因素以及其他变量进行了 Mann-Whitney U 和卡方检验，发现其中一些变量很重要（这意味着 COVID 之前和之后 GBS 阳性/阴性的人口统计数据在统计上存在差异）。有没有办法在调整这些因素的同时进行分析？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658276/analysis-of-gbs-before-and-after-covid-19-while-adjusting-for-confounding-variab</guid>
      <pubDate>Wed, 04 Dec 2024 17:50:51 GMT</pubDate>
    </item>
    <item>
      <title>偏移分布单变量时间序列数据的 ACF 诊断</title>
      <link>https://stats.stackexchange.com/questions/658275/acf-diagnostic-for-shifted-distribution-univariate-time-series-data</link>
      <description><![CDATA[我有这些 1920 个具有偏移分布的观测值。出于某些原因，我想使用所有观测值进行时间序列建模，但我很难阅读 ACF 图。我需要详细说明 ACF 图是否存在任何季节性或长期依赖性，我需要指出哪些滞后，或者是否存在任何特定的特征模式。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658275/acf-diagnostic-for-shifted-distribution-univariate-time-series-data</guid>
      <pubDate>Wed, 04 Dec 2024 17:45:54 GMT</pubDate>
    </item>
    <item>
      <title>离散时间马丁格尔 - Tower Property</title>
      <link>https://stats.stackexchange.com/questions/658273/discrete-time-martingale-tower-property</link>
      <description><![CDATA[我遇到了以下问题：
设$X$为离散时间$(\mathcal{F}_n)$适应随机过程，满足：

$\forall n \in \mathbb{N}, \mathbb{E}[|X_n|] &lt; \infty. (X_n \in L^1)$
$\forall n \in \mathbb{N}, \mathbb{E}[X_{n+1}|\mathcal{F}_n] = X_n \quad \mathbb{P}$-a.s.

证明 $X$ 是一个 $(\mathcal{F}_n)$-鞅。
为了证明这一点，我们只需要证明：$\forall n, m \in \mathbb{N}, m&gt;n, \mathbb{E}[X_{m}|\mathcal{F}_n] = X_n$
当我尝试展示这一点时，我无法继续进行，除非假设 $\mathcal{F}_n \subseteq \mathcal{F}_{n+1}$，而且我不知道我们能从哪里得到这个（我们没有被告知 $\mathcal{F}$ 是一个过滤）。
我看到的证明是：
$$\mathbb{E}[X_m|\mathcal{F}_n] = X_n + \sum_{k=n}^{m-1}\mathbb{E}[X_{k+1}-X_k|\mathcal{F}_n] = X_n + \sum_{k=n}^{m-1}\mathbb{E}[\:\mathbb{E}\:[X_{k+1}-X_k |\mathcal{F}_k]\:|\:\mathcal{F}_n] = X_n$$
因为上面我们已经知道 $\mathbb{E}[X_{k+1}-X_k |\mathcal{F}_k] = 0$。不过，在我看来，这就像我们在使用塔属性结合 $\mathcal{F_n} \subseteq \mathcal{F}_k$ 来得到 $k \geq n$。我们能在没有子集相等的情况下得到这个结果吗，或者有什么隐含的东西可以给我们这个结果？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658273/discrete-time-martingale-tower-property</guid>
      <pubDate>Wed, 04 Dec 2024 17:29:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么比例差异的 95% 可信区间和独立性的 2x2 卡方检验不一致</title>
      <link>https://stats.stackexchange.com/questions/658270/why-a-95ci-for-difference-of-proportions-and-a-2x2-chi-square-test-of-independe</link>
      <description><![CDATA[比例差异的 95% 置信区间和独立性的 2x2 卡方检验都试图在基本情况下使用相同的分布（即标准正态分布）回答相同的问题。
在进行计算时，您会认为它们出于某种原因而存在根本差异，或者它们完全等价，尽管呈现方式不同。但事实证明，得到的数学表达式几乎相同，但并不完全相同。所以我的问题是：

这有什么深层次的原因吗？

以下是实际计算。为了简化计算，我假设从两个群体（比如男性和女性）中抽取了两个大小相同的样本 $N$，其中 $a$ 名男性和 $b$ 名女性是左撇子。
$$\matrix{&amp;\text{left}&amp;\text{right}\\ \text{males}&amp;a&amp;N-a \\\text{females}&amp;b &amp; N-b}$$
一方面，95% C.I.由 $$\frac{a-b}{N}\pm 1.96 \sqrt {\frac{a(N-a)}{N^3}+\frac{b(N-b)}{N^3}}$$ 给出
因此，当 $$0\notin \text{C.I.} \Leftrightarrow \frac{(a-b)^2}{\frac{a(N-a)}{N}+\frac{b(N-b)}{N}}&gt; 时，零假设（左撇子的比例在两种性别中相同）被拒绝3.842$$
您可以将其简化为
$$0\notin \text{C.I.} \Leftrightarrow \frac{N(a-b)^2 }{(a+b)N-{\color{red}{(a^2+b^2)}}}&gt; 3.842$$
在卡方方法中，只有红色部分会略有不同，我发现这很令人着迷。通常这意味着我在某个地方犯了错误，但这里看起来不是这种情况。
另一方面，预期计数是$$\matrix{&amp;\text{left}&amp;\text{right}\\ \text{males}&amp;\frac{a+b}{2}&amp;N-\frac{a+b}{2} \\\text{females}&amp;\frac{a+b}{2} &amp; N-\frac{a+b}{2}}$$
卡方统计量由 $$\chi^2 = 2\left[\frac{\left(\frac{a-b}{2}\right)^2}{\frac{a+b}{2}}+\frac{\left(\frac{a-b}{2}\right)^2}{N-\frac{a+b}{2}}\right]$$
因此，当
$$(a-b)^2 \times\left[\frac{1}{a+b}+\frac{1}{2N-a-b}\right] &gt; 给出3.842$$
或
$$ \left[\frac{N(a-b)^2}{(a+b)N-{\color{red}{\frac{(a+b)^2}{2}}}}\right] &gt; 3.842$$
如果这只是一些计算错误，我会很高兴；如果对此有一个深刻的解释，我会很高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/658270/why-a-95ci-for-difference-of-proportions-and-a-2x2-chi-square-test-of-independe</guid>
      <pubDate>Wed, 04 Dec 2024 15:20:13 GMT</pubDate>
    </item>
    <item>
      <title>为贝叶斯推理生成协方差</title>
      <link>https://stats.stackexchange.com/questions/658269/generate-covariance-for-baysesian-inference</link>
      <description><![CDATA[我目前正在做一个项目，我想使用贝叶斯推理来推导一组参数的分布。我假设这些参数在某种程度上是相关的，我想使用贝叶斯推理来推导多元正态分布的协方差矩阵。但是，我并不完全确定从数字数组生成正定协方差矩阵的最佳方法是什么。我目前没有寻找矩阵的先验。
我目前的方法如下：

我使用数字数组通过将数组的值插入上三角部分来生成三角矩阵$A$。例如，给定数组 $ (a_1, \dots, a_6)$，我构造矩阵：

$
A = \begin{pmatrix}
a_1 &amp; a_2 &amp; a_3 \\
0 &amp; a_4 &amp; a_5 \\
0 &amp; 0 &amp; a_6
\end{pmatrix}
$ 
with $a_i &gt; 0$。

然后，我通过计算 $AA^T$ 生成一个正定对称矩阵，并将其用作协方差矩阵。

但是，在这种方法中，值 $a_i$ 没有明确的解释，而且我不确定这种方法是否可以生成所有可能的半正定协方差矩阵。有没有更好的方法可以使用？
另一种具有更好解释性的方法可能涉及首先创建一个包含每个参数方差的对角矩阵和一个相关矩阵。例如，给定数组 $(a_1, \dots, a_6)$，我可以构造矩阵：
$
A = \begin{pmatrix}
a_1 &amp; 0 &amp; 0 \\
0 &amp; a_2 &amp; 0 \\
0 &amp; 0 &amp; a_3
\end{pmatrix}, \quad 
B = \begin{pmatrix}
1 &amp; a_4 &amp; a_5 \\
a_4 &amp; 1 &amp; a_6 \\
a_5 &amp; a_6 &amp; 1
\end{pmatrix}
$ 
with $ a_1, a_2, a_3 &gt; 0$ 和 $|a_4|, |a_5|, |a_6| \leq 1 $。
协方差矩阵将由 $ABA$ 给出。但是，这个矩阵不一定是正定的。我如何确保得到的矩阵是正定的？]]></description>
      <guid>https://stats.stackexchange.com/questions/658269/generate-covariance-for-baysesian-inference</guid>
      <pubDate>Wed, 04 Dec 2024 15:11:33 GMT</pubDate>
    </item>
    <item>
      <title>R 期刊现状</title>
      <link>https://stats.stackexchange.com/questions/658264/status-of-r-journal</link>
      <description><![CDATA[这可能有点离题，但也许有人有关于 R 期刊当前状态的信息。
网站上列出的最后一期来自 2023 年 12 月，所以我想知道该期刊是否仍然活跃。主页上显示待提交数量的图表仅持续到 2022 年：

但它表明可能存在失控问题，导致待提交的存量不断增加，有一天可能不再可管理。然而，这是否与 2024 年缺乏问题有关仅仅是猜测。该网站没有关于问题的评论或提示。
有没有什么信息可以说明发生了什么（没有发生）？]]></description>
      <guid>https://stats.stackexchange.com/questions/658264/status-of-r-journal</guid>
      <pubDate>Wed, 04 Dec 2024 14:02:06 GMT</pubDate>
    </item>
    <item>
      <title>使用卡方分布构建置信区间时的问题</title>
      <link>https://stats.stackexchange.com/questions/658263/issues-when-constructing-a-confidence-interval-using-chi-squared-distribution</link>
      <description><![CDATA[想象一个随机对照试验，采用二元治疗和多个协变量$X_1,...,X_n$。
随机化后，通常会对两个治疗组之间的协变量进行平衡比较。这种平衡度量例如是 z 差，如下所示
$$ z_i = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$
这些 z 差遵循正态分布$Z_i\sim N(0,1)$。这给出了 $i=1,...,n$ 的协变量特定平衡 $X_i$。
最近引入了一个聚合平衡度量 - 即 $SSQ$ - 它将平方 $z_i$ 相加：
$ssq = \sum_{i=1}^n z_i^2$
由于 z 差异遵循标准正态分布，因此 $SSQ \sim \chi^2_n$。
我现在对 $1-\alpha$ 置信度感兴趣间隔为 $ssq$，但我对构造感到很纠结。我有两种不同的方法，但对于一个点来说，它们似乎都是错误的。

方法：

$SSQ \sim \chi^2_n$，因此可以根据分位数直接估计置信区间 - 不需要进行任何变换，因为中心$\chi^2$分布已经存在
$$
\text{CI}_{95\%} = \left[ \chi^2_{1-\frac{\alpha}{2}, n}, \chi^2_{\frac{\alpha}{2}, n} \right]
$$
但是我对这种方法有所担忧，因为置信区间仅由分位数描述，该分位数指的是包含 95% 的区间ssq。此外，估计值未包含在该区间的构建中（例如，如果我估计 $ssq = 61$ 的 $n=10$ 个协变量，则上述区间将是 $[3.94,20.48]$，不包括估计值。此外，如果我运行模拟研究，包括例如 1,000 个 RCT 并估计 $SSQ$，则覆盖率将始终为 100%，因为真正的 SSQ（即 $n$）将始终包含在置信区间的定义中。因此这种方法不可能是正确的。

方法

与方差置信区间类似，它可能是：
$$[\frac{n\cdot ssq}{\chi^2_{1-\frac{\alpha}{2}, n}}; \frac{n\cdot ssq}{\chi^2_{\frac{\alpha}{2}, n}}]$$
但是，我不明白为什么这应该成立。因此，我还进行了一项小型模拟研究，并使用上述 95%CI 估计了 ssq。这里的覆盖率约为 95%，这就是为什么这个 CI 似乎是正确的。但我没有从数学上得出这个解决方案。
因此，如果您能帮助我构建 $ssq$ 的置信区间，我将不胜感激。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658263/issues-when-constructing-a-confidence-interval-using-chi-squared-distribution</guid>
      <pubDate>Wed, 04 Dec 2024 13:30:19 GMT</pubDate>
    </item>
    <item>
      <title>三个相关伯努利随机变量之和的分布，均具有相同的相关性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</link>
      <description><![CDATA[问题是这样的：
$\displaystyle \mathbb{P}\left(\sum_{j\neq 1}^{n}X_{j}=z\right)=\text{??}$.
$X_{j} \sim \text{Bernoulli}(p); j=2,3\ldots, n~$, $\text{Cor}(X_{i}, X_{j})=\rho~$,
$p=\frac{1}{4}$ 和 $\rho=\frac{7}{27}$.
$\mathbb{P}(X_{1}+X_{2}=z)=\text{?}$
$\mathbb{P}(X_{1}+X_{2}+X_{3}=z)=\text{?}$
$\mathbb{P}(X_{1}+X_{2}+X_{3}\ldots+ X_{n}=z)=\text{?}$]]></description>
      <guid>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</guid>
      <pubDate>Wed, 04 Dec 2024 01:41:00 GMT</pubDate>
    </item>
    <item>
      <title>减少线性指数衰减混合函数中的极端行为</title>
      <link>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</link>
      <description><![CDATA[我正在用 Python 编写用于残余气体分析质谱的数据缩减软件。该软件的主要目标之一是将测量的气体强度$y$与气体平衡时间$t=0$进行拟合，以确定理论平衡强度$y_0$。
我目前正在努力拟合一个指数线性方程来描述气体消耗：
$$y = a \exp(-pt) + bt + c$$
其中：

$y$是因变量，强度在 A 中
$t$是自变量，时间在$t=0$
$a$、$b$、$c$ 和 $p$ 是拟合参数

以下是一些“良好”的例子消耗曲线拟合：

其中数据为：
质量 2 amu y：[1.03151253e-10 1.02764656e-10 1.00429739e-10 9.97269907e-11
9.89678330e-11 9.94845128e-11 9.73211157e-11 9.67399363e-11
9.69838881e-11 9.57109351e-11 9.54086215e-11 9.57198459e-11
9.54274476e-11 9.59283426e-11 9.53714218e-11 9.29636333e-11
9.44152076e-11 9.35152455e-11 9.32533980e-11 9.30672260e-11]
质量 2 amu t：[7.028 14.238 21.45 28.667 35.874 43.077 50.384 57.389 64.593
71.901 79.01 86.215 93.419 100.627 107.831 115.035 122.243 129.354
136.657 143.768]

质量 3 amu y：[3.29778253e-10 3.26265256e-10 3.20505639e-10 3.16877521e-10
3.16086483e-10 3.13754743e-10 3.11454306e-10 3.09359856e-10
3.08538478e-10 3.06927955e-10 3.05987101e-10 3.03379296e-10
3.00944658e-10 3.02971263e-10 3.01609542e-10 2.99715203e-10
2.99172588e-10 2.97572855e-10 2.97728968e-10 2.97632036e-10]
质量 3 amu t：[ 8.116 15.326 22.538 29.755 36.962 44.165 51.472 58.477 65.681
72.989 80.098 87.303 94.507 101.715 108.919 116.123 123.331 130.442
137.745 144.856]

以及一些非物理或不切实际的“过度”示例拟合：

Mass 2 amu y：[8.92991171e-11 8.76522093e-11 8.61052948e-11 8.70397469e-11
8.71706708e-11 8.68983223e-11 8.70813401e-11 8.68469981e-11
8.60065722e-11 8.68007260e-11 8.69227029e-11 8.73408691e-11
8.64896431e-11 8.70329228e-11 8.60186671e-11 8.62989490e-11
8.67176164e-11 8.59189454e-11 8.64824077e-11 8.64498292e-11]
质量 2 amu t：[3.529 10.636 17.841 25.047 32.259 39.469 46.676 53.882 60.986
68.191 75.399 82.611 89.816 97.023 104.226 111.335 118.54 125.745
132.95 140.157]

或者更糟，像这样：

Mass 2 amu y：[9.37982279e-11 9.12279184e-11 9.11408812e-11 9.16890908e-11
 9.11226495e-11 9.11011735e-11 9.09514699e-11 9.17458313e-11
 9.07343618e-11 9.07010068e-11 8.98410055e-11 9.09835375e-11
 9.19705903e-11 9.08708285e-11 9.18843137e-11 9.03661067e-11
 8.99796615e-11 9.12228596e-11 9.02898722e-11 9.06567840e-11]
质量 2 amu t：[5.326 12.433 19.639 26.849 34.058 41.267 48.475 55.577 62.782
69.987 77.294 84.496 91.7 98.909 106.022 113.129 120.335 127.54
134.861 141.971]

我正在寻找一种可以缓解这种极端指数行为的技术，这种技术并非：
a. 任意。也就是说，我可以对 $a$ 强制实施 看起来合理的边界，限制极端行为。但是，除非该边界是物理上已知的（这是不可能的），否则这是“绘制”而不是数学；如果我可以在合理范围内的任何地方“绘制”截距，这不是找到截距的真正解决方案。
b. 迭代。我知道重采样/引导等技术可以减轻单个异常值对拟合的影响，但是，每个序列由数十到数百个分析组成，每个分析都有四条需要拟合的强度曲线。对每个分析的每次拟合进行迭代以收敛可能需要太长时间。
是否有一种技术可以解决极端拟合的问题，而不会牺牲统计严谨性，但每次拟合也不需要数万次迭代？如果没有，我最好选择相对快速的迭代解决方案是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</guid>
      <pubDate>Tue, 03 Dec 2024 19:48:05 GMT</pubDate>
    </item>
    <item>
      <title>给定许多图游走的总成本，如何估算每条边的成本？</title>
      <link>https://stats.stackexchange.com/questions/658217/given-the-total-cost-of-many-graph-walks-how-to-estimate-the-cost-of-each-edge</link>
      <description><![CDATA[我有一个实际问题，其中我有一个节点及其边的集合。这个集合由数百个节点和数千个连接组成。然后我有大约 10 K 个数据点，每个数据点代表此图中采用的一条路径和每条路径的总成本（每条路径中经过的边的成本总和）。我正在寻找一个函数，给定路径，估算每条边的成本。
现实世界的情况有点复杂，因为模型需要考虑其他特征，例如一天中的时间，以及每个节点的输入/输出，所以我猜它需要一些强化学习管道，但任何时候的任务主要取决于我上面定义的算法，而且它看起来相当简单。
这个问题容易解决吗？文献中是否有任何算法可以解决它？因为我在整整一天的研究中都没有找到一个。]]></description>
      <guid>https://stats.stackexchange.com/questions/658217/given-the-total-cost-of-many-graph-walks-how-to-estimate-the-cost-of-each-edge</guid>
      <pubDate>Tue, 03 Dec 2024 15:58:08 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算自相关</title>
      <link>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</link>
      <description><![CDATA[我学过滞后 $k$ 的时间序列中的自相关是所有以此滞后为间隔的值对之间的相关性。
假设我想试一试，并手动计算滞后 1。
模拟一些白噪声
set.seed(123)
TS &lt;- ts(rnorm(1e3))

然后手动计算自相关并使用内置函数。
calc_autocorrelation_manually &lt;- function(x) { cor(x[-1], x[-length(x)]) }

&gt; calc_autocorrelation_manually(TS)
[1] -0.02741628
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.000 -0.027

两者给出相同或几乎相同的结果（我知道 acf() 中的计算并不完全相同，因为它不使用偏差调整。不过，我认为这不会产生实质性差异）。
但是，如果我对模拟 AR(1) 过程执行此操作，结果就不一样了！例如，使用没有噪音的“理想”AR(1)：
&gt; TS &lt;- ts(99999) # 初始值
&gt; for (i in 1:350) { TS &lt;- c(TS, TS[i] * 0.3) }
&gt; 
&gt; calc_autocorrelation_manually(TS)
[1] 1
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.0 0.3 

我认为手动计算自相关是不正确的，但正确的方法是什么？为什么在第一个例子中它仍然运行良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</guid>
      <pubDate>Tue, 03 Dec 2024 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 p 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？
编辑：可能对偶然发现这一点的其他人有帮助：FPR 可以描述为基准率、准确率和 PPV 的函数。对于 PPV &gt; 0.5，基准率和 FPR 之间的关联将始终为正。对于 0 &lt; 准确率 &lt; 1：fpr = ((base+acc-1)*(ppv-1))/((base-1)*(2*ppv-1))]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    </channel>
</rss>