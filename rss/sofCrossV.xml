<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Feb 2025 03:20:32 GMT</lastBuildDate>
    <item>
      <title>具有大学学分的统计课程 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661311/statistic-course-with-college-credit</link>
      <description><![CDATA[有人知道有哪些在线入门统计学课程可以提供大学学分吗？
我被一个硕士项目录取了，但在入学之前我需要先学习一门入门统计学课程。我找到了一些选择，但很多课程的费用超过 1,000 美元。我正在寻找一门价格低于 500 美元且可以转学分的更实惠的课程。
任何建议都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661311/statistic-course-with-college-credit</guid>
      <pubDate>Thu, 13 Feb 2025 02:26:24 GMT</pubDate>
    </item>
    <item>
      <title>样本分布的变异性如何取决于样本大小</title>
      <link>https://stats.stackexchange.com/questions/661307/how-variability-of-sample-distribution-depends-on-sample-size</link>
      <description><![CDATA[据我所知，对于许多统计量而言，随着样本量的增加，这些量平均值的抽样分布的变异性会降低（例如，如果基础分布属于高斯普遍性类别和/或所讨论的统计数据增长速度不太快）。然而，单个（经验）样本分布的变异性如何取决于样本量则不太清楚。我看到比我更有经验的人说过，随着样本量的增加，样本分布的变异性降低。但是，在我看来，如果将样本分布解释为来自单个样本的经验概率分布，那么变异性应该随着样本大小的增加而平均增加（或者在较大的$n$极限下“通常”增加），因为经验方差（除以$1/n$而不是$1/(n-1)$）往往会低估真实的总体方差，并且因为分布边缘的（渐近）罕见事件往往会在经验分布中被低估。这种理解准确吗？如果不准确，应该如何解释样本分布的概念？]]></description>
      <guid>https://stats.stackexchange.com/questions/661307/how-variability-of-sample-distribution-depends-on-sample-size</guid>
      <pubDate>Thu, 13 Feb 2025 00:36:00 GMT</pubDate>
    </item>
    <item>
      <title>GEE 对分类变量建模时的聚类数量和大小</title>
      <link>https://stats.stackexchange.com/questions/661304/cluster-number-and-size-in-modelling-a-categorical-variable-by-gee</link>
      <description><![CDATA[我必须学习统计模型才能完成我接手的一个遗传学项目：我们获得了 16 个家族（群体）中 120 名患有遗传性疾病的患病成员的数百个双等位基因 SNP（每个 SNP 的可能值：0 = 非携带者，1 = 携带者）的基因型，我想为每个 SNP 的携带者和非携带者之间的疾病等级建模。疾病等级范围从 1（= 轻度）递增到 10（= 重度），可以将其缩小到 4 个有序类别（如果需要，可以更少）。我对分类变量应用了一种扩展的广义估计方程法（Wang et al. BMC Genomics 22, 873, 2021），使用家庭成员之间的遗传关系作为每个簇内的相关矩阵。
(Q1) 不幸的是，对于 1/4 的 SNP，模型没有收敛，虽然我不是统计模型专家，但我敢猜测两个潜在原因可能是 (a) 16 是一个较低的簇数，(b) 簇大小异质性大（从 2 到 28 个成员）；(c) 可能是其他因素？（我的问题）。
(Q2) 这里已经讨论了簇大小和数量的主题，但我看不出有增加簇数量和获得权力的方法。拆分家庭以增加簇数量似乎不是一个有效的选择，因为在大多数情况下，它会生成彼此相关的子簇（可能由非常远的亲属组成的簇除外）。例如，由母亲和儿子组成的子簇将与由他的兄弟和女儿（即长子的侄女）组成的不同子簇相关。即使这两个子簇中的遗传是一个独立的生物事件，但两个兄弟仍然共享约 50% 的基因组。有什么想法可以绕过这个问题吗？
(Q3) 至于疾病等级，我的想法是将其减少到 4 个类别，以简化操作，也许将其增加到 10 个类别，并将模型性能与 AIC 等进行比较。但是，使用 4 个级别的响应变量的频率分布与任何经典分布都不一样，这与 G(generalized)EE 相关吗？(Q4) 我应该尝试转换响应变量吗？
任何建议、参考资料等都可以提高模型收敛性或处理这些主题，我们将不胜感激。我已经准备好听到我被这个（几乎没有计划的）学习设计困住了，我应该寻找远离 GEE 的替代方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/661304/cluster-number-and-size-in-modelling-a-categorical-variable-by-gee</guid>
      <pubDate>Wed, 12 Feb 2025 22:45:30 GMT</pubDate>
    </item>
    <item>
      <title>帮助我理解双指数拟合中的截距</title>
      <link>https://stats.stackexchange.com/questions/661302/help-me-understand-the-intercepts-in-a-bi-exponential-fit</link>
      <description><![CDATA[我已将双指数函数拟合到一些药代动力学数据，模型系数（使用 SSbiexp() 和 nls()）如下：
&gt; params
截距初始 log_slope_initial 截距终端 log_slope_terminal 
-8423.742038 -3.177209 56673.303774 -4.273009 

我已在数据点上绘制了拟合图（将其延伸到 x = 0 之前以显示函数形状）。
我无法理解的是截距在这种情况下的含义。我手动绘制了我认为粗略的初始和终端斜率，并假设截距反映了它们与 y 轴的交叉位置。难道不是这样吗？
我注意到，我通过目测图绘制的斜率与拟合输出的斜率不一致 - 即终端斜率更大。所以我不确定我在这里遗漏了什么
此外，查看有关双指数拟合的各种教科书，我一直认为初始截距 (C0) 会大于终端截距 (C1)，但显然我的理解中缺少了一些东西。有人可以帮我吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661302/help-me-understand-the-intercepts-in-a-bi-exponential-fit</guid>
      <pubDate>Wed, 12 Feb 2025 21:45:06 GMT</pubDate>
    </item>
    <item>
      <title>样本量，SPSS 19 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661300/sample-size-spss-19</link>
      <description><![CDATA[为获得可接受的结果解释，每个组的最小样本量是多少？我们正在讨论方差分析、独立检验、Dipendet 检验、非参数检验 - Kruskal-Wallis、Mann-Whitney、Wilcoxon、Fridman。]]></description>
      <guid>https://stats.stackexchange.com/questions/661300/sample-size-spss-19</guid>
      <pubDate>Wed, 12 Feb 2025 21:31:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要对所有样本取条件对数似然的平均而不是按 x 分组？</title>
      <link>https://stats.stackexchange.com/questions/661299/why-do-we-average-the-conditional-log-likelihood-over-all-samples-rather-than-gr</link>
      <description><![CDATA[我偶然看到了一篇文章（MSE 的核心是交叉熵：最大似然估计解释），其中指出：

&quot;在训练神经网络时，我们试图找到尽可能接近训练集分布的概率分布参数。&quot;

对于条件模型，我们通常将负对数似然（或交叉熵）写为
$$
-\frac{1}{n}\sum_{i=1}^{n} \log q(y_i \mid x_i)
$$
由于我们正在建模 $q(y \mid x)$（将 $x$ 视为给定值），因此将所有具有相同 $x$ 的观测值分组在一起似乎很自然，并且对于每个固定的 $x$，计算
$$
-\sum_y \frac{N(x,y)}{N(x)} \log q(y \mid x)
$$
其中 $N(x,y)$ 是对 $(x,y)$ 出现的次数，并且 $N(x)$ 是 $x$ 出现的总次数。此表达式通过比较经验条件分布得出特定$x$的损失
$$
\hat{p}(y \mid x) = \frac{N(x,y)}{N(x)}
$$
与模型$q(y \mid x)$。
我的问题是：
为什么我们要通过对所有样本取平均值（除以$n$）来计算损失，而不是按$x$分组并在每个组内进行归一化？
我理解对样本取平均值会隐式地根据每个$n$的频率对贡献进行加权？ class=&quot;math-container&quot;&gt;$x$，但我试图理解直觉和任何实际原因，以便更喜欢
$$
-\frac{1}{n}\sum_{i=1}^{n} \log q(y_i \mid x_i)
$$
而不是明确的分组$x$方法。
任何见解或参考都将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661299/why-do-we-average-the-conditional-log-likelihood-over-all-samples-rather-than-gr</guid>
      <pubDate>Wed, 12 Feb 2025 21:20:09 GMT</pubDate>
    </item>
    <item>
      <title>t 检验和方差分析检验 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661298/a-t-test-and-anova-test</link>
      <description><![CDATA[t 检验有什么用？
使用 t 检验的条件是什么？
t 检验和方差分析有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/661298/a-t-test-and-anova-test</guid>
      <pubDate>Wed, 12 Feb 2025 21:04:37 GMT</pubDate>
    </item>
    <item>
      <title>双变量面板模型 - 平稳性问题</title>
      <link>https://stats.stackexchange.com/questions/661293/two-variable-panel-model-stationarity-issue</link>
      <description><![CDATA[我来介绍一下这个模型，从这个标准的CES（恒定替代弹性）规范中，我们推导出一个要估计的模型。
$ Y = B[\alpha K^{-\varphi}+(1-\alpha)L^{-\varphi}]^{-1/\varphi}$
使用FOC（一阶条件），我们最终得到劳动份额$(a)$与资本/产出比率（$K/Y$）之间的简单关系：
$a=\alpha (Bx)^{-\varphi}$，
其中$x = K/Y$。取对数，并假设 TFP $(B)$（全要素生产率，一种粗略衡量技术进步的指标，可提高生产率）可分解为国家和时间特定效应，并添加时间和国家下标以及误差项，我们得到：
$\ln a_{it} = c_i + d_t -\varphi \ln x_{it}+\epsilon_{it}$，
我们希望使用固定效应来估计。$-\varphi$ 用于计算替代弹性。请注意，这些变量在经济背景下是自然平稳的，即它们在很长一段时间内接近恒定（卡尔多，程式化事实）。
我们面临的问题是平稳性问题，因为我们有一个 T&gt;N（T=60，N=30）的宏观面板。它们自然平稳是可以的，但我认为统计数据并不关心这一点，所以我使用 CIPS（横截面增强 Im-Pesaran-Shin）和 Peseran CADF（Pesaran 横截面增强 Dickey Fuller）检验（以调整横截面依赖性）来测试平稳性，但也使用第一代面板单位根检验；LLC（Levin-Lin-Chu）、Breitung、Fisher Type DF、Hadri - 所有四个都尽可能去除横截面均值和/或稳健，以减轻横截面依赖性问题，以及异方差性（只有 Hadri 在 Stata 中有此选项）。结果是混合的，第二代测试表明一个是 I(1)，另一个是 I(0)，后四个测试显示混合结果，一些测试表明两者都是 I(1)，一些测试表明它们具有混合的积分阶数。
如果它们是不同阶数的积分，我该如何解决这个问题？协整是不可能的，因为我们至少需要两个 I(1) 变量才能存在平稳线性组合。我担心添加滞后（面板 ARDL（自回归分布滞后模型））或新变量（倾向于协整），因为我需要能够提取替代参数，并且因为该模型源自经济理论。我找到的唯一解决方案是简单的差分，但它并不令人满意，因为一个是 I(0)，导致过度差分？
任何帮助或建议都将不胜感激，它已经困扰了我近一年，我一直碰壁。我是否可以用当前的问题模拟模型，以评估对估计的影响，推断呢？也许我应该拿出纸笔，看看渐近线？我现在不知所措。
问候 Mathias]]></description>
      <guid>https://stats.stackexchange.com/questions/661293/two-variable-panel-model-stationarity-issue</guid>
      <pubDate>Wed, 12 Feb 2025 19:54:52 GMT</pubDate>
    </item>
    <item>
      <title>对于 BERT 微调（迁移学习），数据集中每个类别/标签需要多少个 obs/examples？</title>
      <link>https://stats.stackexchange.com/questions/661289/how-many-obs-examples-per-class-label-in-a-dataset-is-necessary-for-bert-fine-tu</link>
      <description><![CDATA[我寻求有关生产环境中标签分类问题的建议（使用点分隔的级别，如“x.x.x.x.x.x.x”）。如果我没有准确提出我的问题，请耐心等待，即“迁移学习”是否不是那么重要。
在每个业务周期中，数据集中的行都必须标记 - 它缺少目标/列。对于每个周期，都会提供一个数据集作为此练习的输入。数据集包括一些变量，最重要的是 1. ID 变量和 2. 简短的文本描述。当数据集被正确标记或分类时，ID 将与标签完美对应。在每次迭代中，大多数 ID--- 标签链接作为身份将会延续，但有些不会：会有新的标签，一些标签会被重新定义。基本上，每次迭代都会有未标记的行。
标签/类别使用变量 2 分配，即文本描述（除其他几个之外）与循环新数据集附带的评分手册的内容进行比较。（好吧，数据集和密钥来自两个独立的业务流程，但我们可以在这里忽略这一点。）作为事实上的评分手册，标签是唯一的，并且仅使用少量描述描述一次，这些描述是关于标识标签的内容（=）和对比标签的内容（!=）的简短文本字段。因此每个标签仅描述一次。
希望尽可能自动地对数据集进行无限分类/标记。数据集在时间 T0 已经标记，但在 T1 需要更多新标签。可以在第一批上监督学习算法。 问题在于后续批次是否需要专家进行标记以训练模型，或者理想情况下，每个标签/类别一行的“评分手册”是否足够（这比迁移学习需要多少数据？更精确）？
如果不参考特定软件（或架构）就无法回答该问题，请考虑 pytorch 和 BERT。据我所知，该软件通过微调其他语料库来实现“迁移学习”。然而，我不确定在实践中需要多少文本才能发挥作用。
其他模型可能相关 - 欢迎评论：

强化学习（其中专家被提示决定预测的目标标签是否正确）有帮助吗？
半监督学习（其中模型使用它从标记目标中学到的知识来预测未标记的目标）有帮助吗？
...但是是否有任何实质性地减少手动标记或只是用一个花哨的、要求苛刻的层使过程复杂化？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661289/how-many-obs-examples-per-class-label-in-a-dataset-is-necessary-for-bert-fine-tu</guid>
      <pubDate>Wed, 12 Feb 2025 18:36:25 GMT</pubDate>
    </item>
    <item>
      <title>小样本，方差分析，SPSS 19</title>
      <link>https://stats.stackexchange.com/questions/661288/small-samples-anova-spss-19</link>
      <description><![CDATA[我正在处理三组小样本 - n=3。我使用的是 SPSS 19。我应用了单向方差分析，因为发现存在正态分布和方差相等。我担心在检查正态分布时无法计算峰度。箱线图中没有异常情况。我知道，对于这样的样本量，除了单向方差分析测试的小效果外，我别无所求。在这种情况下，我做得对吗？

有三组 - 对照组和 2 个实验组。研究膳食补充剂对血液的影响。在确定正态分布时，SPSS 仅计算 Shapiro-Wilk 检验统计量 (p&gt;0.05) 和 Kolmogorov-Smirnov 检验 - 不，它只是空的。当我使用描述性统计数据测试偏度和峰度时 - 信息仅显示偏度，而不显示峰度。

在这种情况下，更合理的解决方案是什么？我应该保留结果原样（单向方差分析）还是切换到非参数 Kruskal-Wallis 检验（我测试过，与方差分析几乎没有区别）？]]></description>
      <guid>https://stats.stackexchange.com/questions/661288/small-samples-anova-spss-19</guid>
      <pubDate>Wed, 12 Feb 2025 18:17:27 GMT</pubDate>
    </item>
    <item>
      <title>从正态分布中抽样时的分位数分布[重复]</title>
      <link>https://stats.stackexchange.com/questions/661284/distribution-of-quantile-when-sampling-from-a-normal-distribution</link>
      <description><![CDATA[我对从正态分布中抽取的样本的分位数分布感兴趣。例如，下面的 R 代码根据 10,000 次模拟为 300 点样本的第 5 个百分位数创建直方图。乍一看，这似乎是一个正态分布，但有分析结果或证据吗？
set.seed(1)
x &lt;- numeric()
for(i in 1:10000){
x &lt;- c(x, quantile(rnorm(300), probs=.05))
}
hist(x)

]]></description>
      <guid>https://stats.stackexchange.com/questions/661284/distribution-of-quantile-when-sampling-from-a-normal-distribution</guid>
      <pubDate>Wed, 12 Feb 2025 17:36:26 GMT</pubDate>
    </item>
    <item>
      <title>假设检验，其中零假设表明两个比例之间的差异等于一个常数</title>
      <link>https://stats.stackexchange.com/questions/661283/hypothesis-test-where-the-null-hypothesis-states-that-the-difference-between-two</link>
      <description><![CDATA[我正在寻找一种统计检验来比较两个比例，但我不需要测试它们的差异是否为零，而是需要测试它们的差异是否等于特定常数（d ≠ 0）。最常见的两个比例检验（例如 z 检验或卡方检验）假设零假设为 p1 - p2 = 0。
但是，在我的例子中，零假设是：H0：p1 - p2 = d，备择假设是：Ha：p1 - p2 ≠ d
我最初考虑使用标准的双比例 z 检验（例如，使用 R 中的 prop.test），但它通常测试比例之间的差异是否为零，而不是特定常数。是否有标准方法或成熟的方法来测试两个比例之间的差异是否等于特定常数？]]></description>
      <guid>https://stats.stackexchange.com/questions/661283/hypothesis-test-where-the-null-hypothesis-states-that-the-difference-between-two</guid>
      <pubDate>Wed, 12 Feb 2025 17:34:50 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 R 中进行引导 PLS 并提取载荷？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661294/is-there-a-way-to-conduct-bootstrapped-pls-and-extract-loadings-in-r</link>
      <description><![CDATA[我正在分析栖息地类型（%）的存在对鸟类密度的影响，并希望使用偏最小二乘分析（PLS）进行分析并查看产生的载荷。
我有包含栖息地类型的解释矩阵和物种密度的响应矩阵（我一次处理一个物种，所以这里只有一列）。我让原始数据上的 PLS 工作并且可以很好地读取载荷。我设法同时使用 pls 包中的函数 plsr() 和 plsRglm 包中的 plsR() 函数来实现这一点。
当尝试使用 data4PCCAR 和 plsRglm 包通过引导运行 pls 时，我设法提取了权重。是否可以提取载荷？你们当中有谁知道如何做到这一点，或者可以推荐任何合适的软件包吗？
更新：
PS 这是我为 plsRglm 包使用的一些代码：
# 拟合常规 PLS 回归
plsR_model &lt;- plsR(Species_matrix, habitat_types, nt = 1, modele = &quot;pls&quot;, typeVC = &quot;none&quot;)

plsR_model$pp # 提取预测变量的载荷

#Bootstrap PLS
pls_boot_results &lt;- bootpls(plsR_model, statistic = NULL, typeboot = &quot;plsmodel&quot;, R = 10000) 

我想更改统计参数，以便函数从中提取载荷plsR_model。这可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661294/is-there-a-way-to-conduct-bootstrapped-pls-and-extract-loadings-in-r</guid>
      <pubDate>Wed, 12 Feb 2025 11:09:29 GMT</pubDate>
    </item>
    <item>
      <title>Q-Learning TicTacToe Bot [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661258/q-learning-tictactoe-bot</link>
      <description><![CDATA[我想教神经网络使用 Q-learning 玩井字游戏。我见过这种方法在基本的 cartpole 环境中实现，我想试试井字游戏。我的问题是我应该如何编码棋盘；我应该简单地在 3x3 numpy 数组中编码 Xs、Os 和空值吗？也许有一些更好的编码方法可以从一开始就放大重要的依赖关系（编码本身）。我知道像 ESM 这样的模型对蛋白质序列编码做了类似的事情，但那是一个比井字游戏复杂得多的情况。
和围棋一样，井字游戏的规则是“根据棋盘上点之间的邻接对应的自由度来定义的”（Silver 等人）。我计划通过在我的网络中添加卷积层来利用此属性。
有什么编码建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661258/q-learning-tictactoe-bot</guid>
      <pubDate>Wed, 12 Feb 2025 00:04:03 GMT</pubDate>
    </item>
    <item>
      <title>治疗组和对照组的倾向评分分布不正确？</title>
      <link>https://stats.stackexchange.com/questions/661256/incorrect-propensity-score-distribution-in-both-treatment-and-control-groups</link>
      <description><![CDATA[我正在计算倾向得分来解决观察性非随机研究中的选择偏差。当使用逻辑回归模型（具有治疗与对照的二元结果变量）时，对照组和治疗组的倾向得分都非常低，而治疗组的整体得分略高。
下面的直方图总结了对照组（顶部）与干预/治疗组（底部）的倾向得分分布：

每组 PS 分布的平均值 ± SD：
对照组：0.16 ± 0.08
治疗组：0.21 ± 0.10
每个组中 PS 分布的范围（最小-最大）：
对照组：0.09 至 0.74
治疗组：0.09 至 0.65
我使用 SAS（PROC LOGISTIC）和 R（glm 函数，family=binomial 和 logit 链接）使用相同的数据集和协变量复制了这些结果。
我预计干预组的治疗概率会更高，但分布与对照组相似是意料之外的。据我了解，结果表明，无论实际分配如何，几乎所有观察结果都将被预测为在对照组中。
这是个问题吗？我将如何调查以改善模型拟合度，这些 PS 分数是否“合理”？我根据领域专业知识/理论选择了协变量。
使用这些 PS 分数创建治疗权重的逆概率 (IPTW) 时，得到的协变量在研究组之间似乎是平衡的。
我进行了广泛的搜索，但没有看到这种特定情况出现。我非常感谢可以提供的任何帮助。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661256/incorrect-propensity-score-distribution-in-both-treatment-and-control-groups</guid>
      <pubDate>Tue, 11 Feb 2025 22:55:23 GMT</pubDate>
    </item>
    </channel>
</rss>