<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 04 Feb 2025 15:17:49 GMT</lastBuildDate>
    <item>
      <title>对称狄利克雷序统计量的一阶矩</title>
      <link>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</link>
      <description><![CDATA[设 $\mathbf q\in[0,1]^n$ 为服从对称狄利克雷分布的随机向量，其参数为 $\alpha$:
$$
\mathbf{q}\sim \operatorname{Dir}(\alpha,\cdots,\alpha).
$$
将 $q_{(i)}$ 定义为 $\mathbf{q}$ 的 $i$ 阶统计量，按升序排列：
$$
q_{(1)}\le\cdots\le q_{(n)}.
$$
问题。 $E[q_{(i)}]$ 是什么？
我们可以将 $q_i$ 表示为
$$
q_i=\frac{z_i}{\sum_{k=1}^nz_k}
$$
对于 i.i.d. $z_i\sim\operatorname{Gamma}(\alpha,\lambda)$。
当 $\alpha=1$ 时，$E[q_{(i)}]$ 的表达式很简单。 Rényi 的表述表明
$$
z_{(i)}=\sum_{k=1}^i\frac{d_i}{n-k+1}
$$
其中 i.i.d. $d_i\sim\operatorname{Exp}(\lambda)$ 和 $\sum_{k=1}^nd_k=\sum_{k=1}^nz_k$。现在我们有
$$
q_{(i)}=\frac{z_{(i)}}{\sum_{k=1}^nz_k}=\sum_{k=1}^i\frac1{n-k+1}\underbrace{\frac{d_i}{\sum_{t=1}^nd_t}}_{:=D_i}。
$$
由于
$$
(D_1,\cdots,D_n)\sim\operatorname{Dir}(1,\cdots,1),
$$
$D_i$ 的一阶矩为
$$
E[D_i]=\frac1n,
$$
且
$$
E[q_{(i)}]=\frac1n\sum_{k=1}^i\frac1{n-k+1}。
$$
我试图将其推广到任何 $\alpha&gt;0$。我发现一些论文从伽马分布中得出了顺序统计的一阶矩。但在 $q_{(i)}$ 的表达式中，分子 $z_{(i)}$ 和分母 $\sum_{k=1}^nz_k$ 显然不是独立的；我需要推导出 $q_{(i)}$ 整体的矩。
如能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</guid>
      <pubDate>Tue, 04 Feb 2025 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>使用小样本校正估计双选择后套索中的标准误差</title>
      <link>https://stats.stackexchange.com/questions/660954/estimating-standard-errors-in-post-double-selection-lasso-using-small-sample-cor</link>
      <description><![CDATA[后双重选择是一种在高维稀疏模型中对低维参数进行推理的方法。原始论文之一由Belloni、Chernozhukov 和 Hansen (2014) 在 ReStud 中撰写。他们考虑了一个部分线性模型：
\begin{align*} 
y_i &amp;= d_i \alpha_0 + g(z_i) + \zeta_i, &amp;E[\zeta_i | z_i, d_i] = 0 \\
d_i &amp;= m(z_i) + \nu_i, &amp;E[\nu_i | z_i] = 0。
\end{align*&gt;
用他们的话来说，该方法可以总结如下：

在第一步中，我们选择一组可用于预测治疗$d_i$的控制变量。此步骤有助于通过查找与治疗密切相关的控制变量（因此可能是重要的混杂因素）来确保模型选择后推断的有效性。
在第二步中，我们通过选择预测$y_i$的控制变量来选择其他变量。此步骤有助于确保我们已捕获感兴趣的方程中的重要元素，理想情况下有助于保持残差方差较小，并提供额外的机会来找到重要的混淆因素。
在最后一步中，我们通过$y_i$对治疗$d_i$的线性回归以及在两个变量选择步骤中选择的变量集的并集来估计感兴趣的治疗效果$\alpha_0$。

他们的主要理论结果如下图所示。这里 $\widehat{s}$ 表示上述算法中回归步骤 3 中包含的回归量的数量（即步骤 1 和 2 的并集）。

可以看出，为了估计估计量的方差，人们使用 $\widehat{\zeta}_i$ 和 $\widehat{\nu}_i$ 来估计残差。为了估计 $\widehat{\zeta}_i$，我们使用了小样本偏差校正，类似于用于估计经典样本方差的偏差校正。这在高维设置中很有意义，因为可以想象 $\widehat{s}$ 可能很接近（或与 $n$ 大致相同）。当使用$\widehat{s} \geq n$时，可以得到全为零的残差，这将提供模型中真实误差的非常差的估计。
有谁知道或直觉为什么不应用这种偏差校正$\widehat{\nu}_i$？我们还针对此回归采用了变量选择，并且非零回归量的数量可能相对接近$n$？
我的问题与此帖子有关，但略有不同，因为该问题侧重于特定的 stata 实现，而我的问题是关于不使用偏差校正$\widehat{\nu}_i$背后的直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660954/estimating-standard-errors-in-post-double-selection-lasso-using-small-sample-cor</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:16 GMT</pubDate>
    </item>
    <item>
      <title>survminer 中的 ggadjustedcurves() 不适用于 strata [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660952/ggadjustedcurves-in-survminer-does-not-work-with-strata</link>
      <description><![CDATA[我正尝试使用我的 cox 拟合打印一条预测曲线。我必须分层以消除时间依赖性。我无法绘制曲线函数。
我收到以下错误。这只是一个简单的例子，但在 cox-hazard 建模期间添加分层来处理比例违规似乎会破坏所有工具。有人有解决方法吗？
缺少变量参数。使用从 strata 中提取的 karno:tgroup
`[.data.frame`(data, , variable) 中的错误：未定义选定的列

最小示例
library(&quot;survival&quot;) 
library(&quot;survminer&quot;)

vet2 &lt;-survSplit(Surv(time, status) ~., data= veteran, cut=c(90, 180), episode= &quot;tgroup&quot;, id=&quot;id&quot;)
vfit2 &lt;-coxph(Surv(tstart, time, status) ~ trt + Prior + karno:strata(tgroup),data=vet2)
ggadjustedcurves(vfit2, data =vet2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660952/ggadjustedcurves-in-survminer-does-not-work-with-strata</guid>
      <pubDate>Tue, 04 Feb 2025 13:58:21 GMT</pubDate>
    </item>
    <item>
      <title>如何比较联合概率分布？</title>
      <link>https://stats.stackexchange.com/questions/660951/how-to-compare-joint-probability-distributions</link>
      <description><![CDATA[假设我有两类数据，以成对的列表形式给出：
$$
\begin{align}
D&amp;=\{(d_1,t_1),(d_2,t_2),\cdots,(d_N,t_N)\}\\
\tilde{D}&amp;=\{(\tilde{d}_1,\tilde{t}_1),(\tilde{d}_2,\tilde{t}_2),\cdots,(\tilde{d}_\tilde{N},\tilde{t}_\tilde{N})\}
\end{align}
$$
对于任意长度 $N,\tilde{N}$。假设 $d_i,\tilde{d}_i$ 是误差值（某种度量），$t_i,\tilde{t}_i$ 是时间点。我怀疑 $D$ 中的数据与 $\tilde{D}$ 中的数据相比，在较晚的时间点，其误差会更大。但是，我想量化这一点，并以某种统计显著的方式表明情况确实如此。
最好的方法是什么？如何比较这些联合分布？我听说过配对$t$检验，但我想知道是否还有其他方法我应该考虑，因为我具体假设后期时间点的误差会更大。
我不太熟悉统计学，所以如果有我应该尝试的自然测试，我提前道歉。任何指导都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660951/how-to-compare-joint-probability-distributions</guid>
      <pubDate>Tue, 04 Feb 2025 13:33:26 GMT</pubDate>
    </item>
    <item>
      <title>“计时”偏向轮盘赌 - 最常见数字概率的（1 - \alpha）分位数的渐近上限，Ethier（2010）</title>
      <link>https://stats.stackexchange.com/questions/660949/clocking-biased-roulette-wheels-asymptotic-upper-bound-on-1-alpha-qua</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660949/clocking-biased-roulette-wheels-asymptotic-upper-bound-on-1-alpha-qua</guid>
      <pubDate>Tue, 04 Feb 2025 13:17:38 GMT</pubDate>
    </item>
    <item>
      <title>什么是合适的设计[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660948/what-is-appropriate-design</link>
      <description><![CDATA[建议将轮作作为一种良好的耕作方法，尤其是当使用固氮豆科植物作为替代作物时。为了证明这一建议的有效性，一位农学家进行了一项实验，其中根据随机完全区组设计在五个区块中种植了豇豆、绿豆和非豆科植物。这些种植后来作为第二年的整块地，当时在每个主地块上随机种植了四种玉米品种。因此，每个分割地块都可以通过第一年种植的作物和第二年种植的作物来识别。专家希望能够证明前一年使用一块土地是否会影响下一年的作物产量。提供玉米作物品种的产量；
提供研究的零假设和备择假设
完成实验的方差分析
使用的设计是否合理？解释你的答案]]></description>
      <guid>https://stats.stackexchange.com/questions/660948/what-is-appropriate-design</guid>
      <pubDate>Tue, 04 Feb 2025 13:04:04 GMT</pubDate>
    </item>
    <item>
      <title>CLR 和 ALR 转换何时适用？</title>
      <link>https://stats.stackexchange.com/questions/660944/when-are-the-clr-and-alr-transformations-applicable</link>
      <description><![CDATA[在三种对数比变换（ALR/CLR/ILR）中，我发现大多数人都推荐使用 ILR，因为它在数学上是“正确”的。但是，我仍然想知道，ALR 和 CLR 变换何时真正有用？
我注意到在地球化学中，CLR 很受欢迎，因为它保留了原始数据集的所有变量。我知道，这种变换在许多分析中可能不合适，但它何时真正有用？
对于 ALR 也是如此 - 它减少了变量的数量，并且不允许使用基于距离的统计方法。但是，我是否可以假设，当选择一个元素作为参考变量（因此是分母）有意义并且我不打算使用任何基于距离的方法时，ALR 变换应该适用于我的数据？在我看来，与 ILR 相比，它会使结果的解释更容易。]]></description>
      <guid>https://stats.stackexchange.com/questions/660944/when-are-the-clr-and-alr-transformations-applicable</guid>
      <pubDate>Tue, 04 Feb 2025 11:50:07 GMT</pubDate>
    </item>
    <item>
      <title>我应该在我的分析中报告 q 值还是调整后的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/660943/should-i-report-q-values-or-adjusted-p-values-in-my-analysis</link>
      <description><![CDATA[我目前正在处理一个涉及多重假设检验的数据集，我对是否要报告 q 值或调整后的 p 值 (p.adjust) 有点困惑。我了解技术差异，但我不确定哪一个更适合在我的结果中呈现。我很感激任何有关这方面的指导。
我目前的理解：
调整后的 p 值 (p.adjust)：这是针对多重比较进行校正的 p 值。它表示在零假设下，根据执行的测试次数进行调整后，观察到至少与获得的结果一样极端的结果的概率。
示例：对于我的第一个测试，p.adjust 为 0.02，这意味着只有当我接受校正后的 2% 的显着性水平时，它才会被视为显着。
q 值：这测量了错误发现率 (FDR)，表示在所有被声明为显著的结果中预期的假阳性比例。
示例：第一次测试的 q 值为 0.01，这意味着如果我将所有 q ≤ 0.01 的结果视为显著，则其中约 1% 预计为错误发现。
鉴于此，报告 q 值或调整后的 p 值是否更有意义？是否存在其中一种优于另一种的特定场景？
在 miRNA 分析的背景下，目标通常是识别一组差异表达的 miRNA 以进行进一步的生物学解释。我有 111 个 miRNA，它们在不同途径中具有不同的相互作用。从一个考虑了对我们研究有意义的协变量的详细模型中，我们选择了 15 个 miRNA 来考虑我们模型的重要性。这 15 个 miRNA 被描述为调节几种途径中的基因，产生不同的重要性指标（padj、qvalue……）
提前感谢您的任何见解！如有需要，请进一步说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660943/should-i-report-q-values-or-adjusted-p-values-in-my-analysis</guid>
      <pubDate>Tue, 04 Feb 2025 11:48:14 GMT</pubDate>
    </item>
    <item>
      <title>向非统计同事解释随机森林结果[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660942/random-forest-outcome-explanation-to-non-stat-colleagues</link>
      <description><![CDATA[您如何向非技术同事解释随机森林（来自 R::party 包）的结果是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660942/random-forest-outcome-explanation-to-non-stat-colleagues</guid>
      <pubDate>Tue, 04 Feb 2025 10:50:12 GMT</pubDate>
    </item>
    <item>
      <title>根据百分比减少 (%) 计算平均值和 SD</title>
      <link>https://stats.stackexchange.com/questions/660941/from-percentage-reduction-to-calculate-the-mean-and-sd</link>
      <description><![CDATA[我有一个变量，其基线值为 2148 ± 604。我还有一段时间内的百分比减少量 (%) 及其 SD。
是否可以使用基线值和百分比减少量 (%) 计算此时间段内变量的平均值和 SD？]]></description>
      <guid>https://stats.stackexchange.com/questions/660941/from-percentage-reduction-to-calculate-the-mean-and-sd</guid>
      <pubDate>Tue, 04 Feb 2025 09:34:49 GMT</pubDate>
    </item>
    <item>
      <title>计算 4-5 年的平均值以及标准差 (SD)</title>
      <link>https://stats.stackexchange.com/questions/660939/calculate-the-mean-value-at-4-5-years-along-with-the-standard-deviation-sd</link>
      <description><![CDATA[我有一个基线值为 2148 ± 604 的变量。五年内的年度损失如下：
0–1 年：228.1 ± 319.7
1–2 年：93.1 ± 129.3
2–3 年：80.7 ± 125.3
3–4 年：47.8 ± 83.3
4–5 年：18.7 ± 93.5
是否可以计算 4–5 年的平均值以及标准差 (SD)？]]></description>
      <guid>https://stats.stackexchange.com/questions/660939/calculate-the-mean-value-at-4-5-years-along-with-the-standard-deviation-sd</guid>
      <pubDate>Tue, 04 Feb 2025 08:00:12 GMT</pubDate>
    </item>
    <item>
      <title>具有多个分类独立变量的方差分析（正态分布检验）</title>
      <link>https://stats.stackexchange.com/questions/660938/anova-with-multiple-categorical-independent-variables-testing-for-normal-distri</link>
      <description><![CDATA[我有一个数据集，由一个因变量（X，观察到的个体数量）和四个独立分类变量（A、B、C、D）（位置、方法、栖息地处理等）组成。不幸的是，“组”在某些情况下只有一个或几个样本，每个独立变量的水平相同，缺少一些数据，并且通常只有一个样本是在分类变量的某个组合下制作的。
我会尝试在 R 中运行方差分析，例如 aov( X ~ A + B + C + D)，但在这种情况下，我不知道应该对哪个“组”进行正态分布测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/660938/anova-with-multiple-categorical-independent-variables-testing-for-normal-distri</guid>
      <pubDate>Tue, 04 Feb 2025 06:15:34 GMT</pubDate>
    </item>
    <item>
      <title>什么不是马尔可夫链？</title>
      <link>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</link>
      <description><![CDATA[不久前我学习了马尔可夫链，它对我来说很有意义。如果系统状态之间的转换和这些转换的概率不依赖于系统的先前状态，那么系统所遵循的任何过程都被归类为马尔可夫链。但后来我学习了高阶马尔可夫链，据我所知，它总是可以表示为一阶马尔可夫链，尽管这在实践中可能并不理想，因为这种表示将具有更多节点。所以现在我想知道哪些过程不能表示为马尔可夫链。]]></description>
      <guid>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</guid>
      <pubDate>Mon, 03 Feb 2025 20:09:37 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是参数检验还是非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</link>
      <description><![CDATA[也许是一个微不足道的问题，但我一直收到一些相互矛盾的信息，这让我有些困惑。
首先，关于参数和非参数检验之间的区别似乎存在一些相互矛盾的信息。即，

一些来源表明，参数检验对样本所来自的总体分布的参数做出了假设（a，b）
其他来源表明，参数检验仅适用于正态分布的数据（a，b, c, d, e)

我个人认为第一个说法是正确的，而第二个说法不正确，但我希望对此有清晰的认识。
如果第一点是正确的，这就引出了我的第二个问题。我看到多个来源都这么说：

卡方检验是一种非参数检验（a、b、c）

但是我想知道为什么卡方检验是非参数的，如果像 Z 检验、t 检验、ANOVA 等参数检验一样，它假设总体分布遵循特定分布，不是吗？我认为卡方检验假设检验统计量来自卡方分布，因此由于它做出了分布假设，所以它是参数化的。但我肯定是误解了什么。有人能帮忙澄清一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</guid>
      <pubDate>Sat, 01 Feb 2025 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>样本与总体平均治疗效果抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</link>
      <description><![CDATA[我读到Gerber 和 Green 2012 年的田野实验时，了解到了随机化推断的概念，即在进行随机化实验时，可以有两个推断目标。其样本平均治疗效果与研究参与者的有限群体有关。以及与研究参与者所取样的人群相关的人口平均治疗效果。
我的问题是关于如何估计这两个量的抽样变异性。
将平均治疗效果估计量定义为以下形式，其中 $Y_i(t=0)$ 和 $Y_i(t= 1)$ 分别是如果给予治疗 $t = 0$、治疗 $t=1$，则观察 $i$ 的潜在结果：
$$
ATE = \mathbb{E} [Y_i(1)] - \mathbb{E} [Y_i(0)]
$$
该数量是通过假设稳定单位值假设 (SUTVA) 的样本平均值估算的。其中 $t_i$ 是观察到的处理分配，处理时为 1，未处理时为 0。 $N$ 是观测总数，$m$ 是处理过的观测数。
$$
\widehat{ATE} = \frac{1}{m}\sum_{i=1}^m{Y_i(1)|}t_i=1 + \frac{1}{N-m}\sum_{i=m+1}^N{Y_i(0)|t_i = 0}
$$
$\widehat{ATE}$ 的方差如下：
$$
\text{Var}[\widehat{ATE}] = \frac{1}{N-1}\left [\frac{(N-m) \text{Var}[Y_i(1)]}{m} + \frac{m \text{Var}[Y_i(0)]}{N-m} + 2\text{Cov}(Y_i(0), Y_i(1))\right] 
$$
我从现场实验 Gerber and Green 2012 eq 3.4 中得到了方差公式
在教科书中，这种变异性的特点是基于随机化推理。变异性来自随机分配，导致潜在结果的样本平均值不同。
我们没有观察到$\text{Cov}(Y_i(0), Y_i(1))$，因此我们可以估计方差如下：
$$
\widehat{\text{Var}}[\widehat{ATE}] = \frac{\widehat{\text{Var}}[Y_i(1)]}{m} + \frac{\widehat{\text{Var}}[Y_i(0)]}{N-m}
$$
在教科书中，这种变异性是真实抽样方差的保守估计。教科书提到，在以下情况下，该变异性估计量是无偏的：

治疗效果对每个人都是恒定的，或者
实验中的样本是较大总体的随机样本，推论以此为基础。

总体平均治疗效果的方差为 Gerber and Green 2012 实地实验 等式 11.1：
$$
\text{Var}[\widehat{PATE}] = \frac{\text{Var}[Y_i(1)]}{m} + \frac{\text{Var}[Y_i(0)]}{N-m}
$$
我的问题是，如果治疗效果对每个人都是恒定的，那么为什么$\widehat{\text{Var}}[\widehat{ATE}] = \text{Var}[\widehat{PATE}]$]]></description>
      <guid>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</guid>
      <pubDate>Fri, 31 Jan 2025 21:39:56 GMT</pubDate>
    </item>
    </channel>
</rss>