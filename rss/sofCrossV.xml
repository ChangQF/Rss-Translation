<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 13 Jul 2024 21:14:08 GMT</lastBuildDate>
    <item>
      <title>使用什么标准来比较二元变量的多重相关性？</title>
      <link>https://stats.stackexchange.com/questions/650990/what-criterion-to-use-to-compare-multiple-correlations-of-binary-variables</link>
      <description><![CDATA[我有一个测试，其中有 $k$ 个 是/否 道题，有 $N$ 名学生参加。我想测试测试问题的一致性，即不同的考生是否以相同的方式解释这些问题（我认为所有问题的复杂性都相似）。我的零假设是所有问题的表述都同样清晰，而我的备选假设是其中一个问题的表述不如其他问题清晰。作为清晰度的衡量标准，我想使用不同考生对同一问题的答案之间的某种相关性。我的问题是：1) 我应该使用什么相关性指标，2) 我应该采用什么统计标准来测试相关性的同质性？
附言：为了避免误解，我需要补充一点，我实际上想测试定义的一致性，方法是让受访者决定某种情况是否符合定义。我发现在统计背景下思考考试的例子更加直观，但它会引入与考生是否了解正确答案有关的不必要的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/650990/what-criterion-to-use-to-compare-multiple-correlations-of-binary-variables</guid>
      <pubDate>Sat, 13 Jul 2024 20:33:56 GMT</pubDate>
    </item>
    <item>
      <title>如果我们需要整个批次的平均值和方差来进行批次标准化，那么在获得这些值之前我们如何进行单次前向传递？</title>
      <link>https://stats.stackexchange.com/questions/650989/if-we-need-the-mean-and-variance-of-the-entire-batch-for-batch-normalization-ho</link>
      <description><![CDATA[如果我理解正确的话，该模型有多个隐藏层，中间有批量归一化层。当尝试计算前向传递以进行反向传播时，我们如何知道 BN 层应该具有的均值和方差？我们是否只对特定实例应用归一化？]]></description>
      <guid>https://stats.stackexchange.com/questions/650989/if-we-need-the-mean-and-variance-of-the-entire-batch-for-batch-normalization-ho</guid>
      <pubDate>Sat, 13 Jul 2024 19:57:21 GMT</pubDate>
    </item>
    <item>
      <title>评估概率回归模型的黄金标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-a-probabilistic-regression-model</link>
      <description><![CDATA[让我解释一下我的意思和背景：

我所说的“概率”是指“准确性”和“不确定性”都需要很好地校准（例如贝叶斯建模）。
我最关心的是贝叶斯深度学习，我想要一种可以扩展到非常高维度的方法&amp;参数计数。。
有许多方法可用于分类（例如 Brier 评分），但我要求一些可与回归相媲美的方法。

一个有前途的想法是后验预测检查，但老实说，鉴于大多数贝叶斯模型输出样本而不是显式 pdf，我不确定如何以实用的方式实现它……
有什么想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-a-probabilistic-regression-model</guid>
      <pubDate>Sat, 13 Jul 2024 19:51:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们通常用卡方统计量来检验列联表的行/列变量的独立性？</title>
      <link>https://stats.stackexchange.com/questions/650983/why-do-we-usually-test-independence-of-row-column-variables-of-a-contingency-tab</link>
      <description><![CDATA[对于 $r \times c$ 列联表，单元格包含观察到的频率，通常使用 $\chi^2$ 卡方检验来检验零假设“行和列变量是独立的”。数量
$$X^2 = \sum{\dfrac{(O-E)^2}{E}}$$
被使用，其中 $O$ 表示单元格中的观察到的频率，$E$ 表示独立情况下单元格中的预期频率；总和是针对表中所有单元格的。在独立性零假设下（以及所有预期频率“足够大”的附加条件），$X^2$ 服从 $\chi^2$ 分布，自由度为 $(r-1) \times (c-1)$，我们可以使用它来统计检验独立性零假设。
现在假设我们不使用 $X^2$，而是使用另一个量，例如：
$$Q_1 =\sum(O-E)^2$$
或者
$$Q_2 = \sum|O-E|$$
检验假设独立性。出于某种原因，这会是“错误的”吗？我们不使用这些（或其他）替代方案中的任何一个，是因为它们在零假设下的分布是未知的，而不是 $X^2$ 的零分布？也就是说，如果我们在独立性的零假设下生成例如 $Q_1$ 的分布，那么我们是否也可以使用 $Q_1$ 来测试独立性？显然，在独立性下生成例如 $Q_1$ 的精确分布，对于列联表中的大量观测值来说可能是不可行的，但我们可以抽取一个大样本（例如使用 R 中的 r2dtable）。但是，也许还有另一个重要的原因，说明为什么 $X^2$ 是测试独立性的更好甚至最佳选择。如果是这样，那么我想知道这一点。
为了清楚起见，我并不提倡任何其他数量，只是想知道从理论上讲这些替代方案是否也可以使用。感谢您的指导！]]></description>
      <guid>https://stats.stackexchange.com/questions/650983/why-do-we-usually-test-independence-of-row-column-variables-of-a-contingency-tab</guid>
      <pubDate>Sat, 13 Jul 2024 18:58:16 GMT</pubDate>
    </item>
    <item>
      <title>非齐次几何分布方法</title>
      <link>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</link>
      <description><![CDATA[我正尝试通过考虑概率不等的几何分布来解决这个问题。
首先，我使用 Irwin-Hall 分布来推导，对于 n 个独立的均匀随机变量，$P(U_{1}+U_{2} + ... + U_{2} \geq 1) = 1 - \frac{1}{n!}$
因此，如果我们让 $X$ = 成功前的试验次数，那么
\begin{equation}
\begin{aligned}
P(X=2) &amp;= P(U_{1} + U_{2} \geq 1) \\
&amp; = 1-\frac{1}{2} \\
&amp; = \frac{1}{2}
\end{aligned}
\end{equation&gt;
\begin{equation}
\begin{aligned}
P(X=3) &amp;= (1-P(X=2))P(U_{1} + U_{2} + U_{3} \geq 1) \\
&amp; = (1-\frac{1}{2}) (1-\frac{1}{6}) \\
&amp; = \frac{5}{12}
\end{aligned}
\end{equation
一般来说，如果 n &gt; 2，则似乎 $P(X = n) = (1-\frac{1}{n!})\displaystyle \prod_{k=2}^{n-1} (1-P(X=k))$
我读到这个问题的答案应该是 $e$。但使用这种方法，我得到的预期值为 $\approx$ 2.6。这种方法有什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</guid>
      <pubDate>Sat, 13 Jul 2024 18:57:55 GMT</pubDate>
    </item>
    <item>
      <title>GAM 模型看起来还好吗？将两个级别的因子设置为随机效应可以吗？</title>
      <link>https://stats.stackexchange.com/questions/650981/gam-model-look-okay-is-factor-with-two-levels-set-as-random-effect-okay</link>
      <description><![CDATA[如果有人能帮我的话，我想再检查一下我的代码。除了检查模型结构之外：
a. 具有 2 个级别（是/否）且每年都会改变空间位置的因素/类别是否可以具有“re”的平滑基础（bs=re）？
b.将平滑基设置为“cr”有何好处？
进入 gam 的数据：

物种计数 = 丰度，沿河流长度计数数据
逐年
协变量 1 = 连续，在河流中逐年变化
协变量 2 = 计数数据（0-100+，沿河流长度逐年变化
协变量 3 = 因子/类别，存在
或不存在（1=是，0=否），沿河流长度逐年变化
协变量 4 = 因子/类别，沿河流长度收集的五年数据（1-5）


Gam_run &lt;- gam(Species_count~ 
s(log10(Covariate1+1), bs=&quot;cr&quot;, k=7)+
s(Covariate2, bs=&quot;cr&quot;, k=6)+
s(Covariate3, bs=&quot;re&quot;, k=6)+
s(Covariate4, bs=&quot;re&quot;,k=6)+

data=dat,
family=nb(link = &quot;log&quot;),
method=&quot;ML&quot;, optimizer=&quot;efs&quot;, select=TRUE)

非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650981/gam-model-look-okay-is-factor-with-two-levels-set-as-random-effect-okay</guid>
      <pubDate>Sat, 13 Jul 2024 17:52:17 GMT</pubDate>
    </item>
    <item>
      <title>如何根据 ML 模型的预测生成 95% 的预测区间？</title>
      <link>https://stats.stackexchange.com/questions/650980/how-to-generate-95-prediction-interval-around-predictions-from-ml-model</link>
      <description><![CDATA[我有来自 ML 模型的预测，并且想要围绕模型生成的每个预测生成 95% 的预测区间，这样我就可以声称这些是每个观察值可能期望的合理值范围。
我看到一些资源表明它应该是：
Yhat +- 1.96 * std(residuals)
我看到另一个资源表明它应该是 yhat，而不是范围的残差：
Yhat +- 1.96 * std(yhat)
我还看到另一个资源表明它应该是标准误差而不是标准偏差
Yhat +- 1.96 * se(Yhat)
我还看到其他资源表明您需要使用设置为 .05 的分位数参数来拟合 Sklearn 模型以生成上限和下限，这表明我需要训练再次检查模型，这是您在训练期间要做的事情。
总的来说，我现在有点困惑，不确定在预测周围生成预测区间的最佳或最合适方法，以反映每个预测周围的合理值范围。有人有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650980/how-to-generate-95-prediction-interval-around-predictions-from-ml-model</guid>
      <pubDate>Sat, 13 Jul 2024 17:34:31 GMT</pubDate>
    </item>
    <item>
      <title>多类分类的假阴性与假阳性</title>
      <link>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</link>
      <description><![CDATA[假设我有三个类别 1、2、3。
并且有如下评估，其中第二个元素是错误预测，其中模型预测类别 3，而基本事实是 2。
y_true = [1,2,3]
y_pred = [1,3,3]

我正在制作可视化工具，其中

如果模型预测为类别 1 而基本事实不是类别 1，则为红色
如果模型预测为类别 2 而基本事实不是类别 2，则为绿色
如果模型预测为类别 3 而基本事实不是类别 3，则为红色
真实预测无颜色

第二个元素的错误类型是什么？假阳性还是假阴性？
从我上面的案例来看，第二个元素将是蓝色。]]></description>
      <guid>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</guid>
      <pubDate>Sat, 13 Jul 2024 16:44:51 GMT</pubDate>
    </item>
    <item>
      <title>前测试和后测试应使用什么方法？</title>
      <link>https://stats.stackexchange.com/questions/650976/what-methods-to-use-in-pre-and-post-testing</link>
      <description><![CDATA[嗨，我目前正在进行干预前后的研究。我的假设是干预是否有效果，以及人格特质是否会缓和干预的效果。
我有 253 个预样本，后续只有 102 个。我的分析计划是 t 检验，比较效果，然后进行分层分析，最后进行调节分析。
我的问题是
我是否只讨论我分析中的 102 名参与者？
我是否使用后测分数作为因变量？
我是否需要使用前测分数作为分层回归中的协变量？
我是否需要使用前测分数作为独立变量或计算前后之间的差异分数？
非常感谢您的帮助。如果有人能向我指出一篇使用类似分析的论文那就太好了，因为我已经研究这个问题好几个星期了。]]></description>
      <guid>https://stats.stackexchange.com/questions/650976/what-methods-to-use-in-pre-and-post-testing</guid>
      <pubDate>Sat, 13 Jul 2024 15:35:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAM 建模空间自相关</title>
      <link>https://stats.stackexchange.com/questions/650974/modelling-spatial-autocorrelation-with-gams</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650974/modelling-spatial-autocorrelation-with-gams</guid>
      <pubDate>Sat, 13 Jul 2024 14:05:02 GMT</pubDate>
    </item>
    <item>
      <title>对于拟泊松回归来说，多少分散才算太多？</title>
      <link>https://stats.stackexchange.com/questions/650973/how-much-dispersion-is-too-much-for-quasipoisson-regression</link>
      <description><![CDATA[拟泊松回归超越了标准泊松回归，考虑了过度离散（即因变量的方差远大于其均值）。本文对此进行了解释。
但是离散程度要达到什么程度才算太大，以至于应该排除使用拟泊松回归？
在此网站上一个获得高度点赞的答案中，即使方差是均值的 206 倍，也会使用拟泊松。这是声音吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650973/how-much-dispersion-is-too-much-for-quasipoisson-regression</guid>
      <pubDate>Sat, 13 Jul 2024 13:37:26 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析电视剧集的受欢迎程度并兼顾时间因素？</title>
      <link>https://stats.stackexchange.com/questions/650909/how-should-i-analyse-tv-episode-popularity-while-accounting-for-time</link>
      <description><![CDATA[我有一个玩具数据集，其中包含电视剧集、发布日期以及收到的流媒体数量：



剧集
日期
流媒体




暗影领域
2024-03-08
5987


禁书
2024-03-01
6315


魔鬼的茶
2024-02-23
9584


魔法师的鞋子
2024-02-16
8996


魔法森林​​
2024-02-09
7564


回响深渊
2024-02-02
7982


失落文明
2024-01-26
8456


次元裂隙
2024-01-19
8834


水晶迷宫
2024-01-12
9215


扎尔萨的权杖
2024-01-05
9763



我有兴趣分析每集的流媒体数量接收。
具体来说，从数据中我们可以看到，一集播出的时间越长，它收到的流媒体就越多（一般来说）。同时，一些较新的剧集的流媒体播放量高于“预期”流媒体数量与发布日期的关系（此处的剧集是《魔鬼的茶》和《魔法师的鞋子》）。
我应该使用什么分析方法来确定每集的受欢迎程度（更高的流媒体 = 更受欢迎），同时考虑/控制时间的影响（较早的发布日期 = 更高的流媒体）？
如果有帮助，数据也以 R dput 格式提供。
structure(list(episode = c(&quot;The Shadow Realm&quot;, &quot;The Forbidden Tome&quot;, 
&quot;The Devil&#39;s Tea&quot;, &quot;The Sorcerer&#39;s Shoes&quot;, &quot;The Enchanted Forest&quot;, 
&quot;The Echoing Abyss&quot;, &quot;The Lost Civilization&quot;, &quot;The Dimensional Rift&quot;, 
&quot;The Crystal迷宫”、“扎尔萨的权杖”），date = structure(c(19790, 
19783, 19776, 19769, 19762, 19755, 19748, 19741, 19734, 19727
), class = “日期”），streams = c(5987, 6315, 9584, 8996, 7564, 
7982, 8456, 8834, 9215, 9763)), class = “data.frame”，row.names = c(NA, 
-10L))
]]></description>
      <guid>https://stats.stackexchange.com/questions/650909/how-should-i-analyse-tv-episode-popularity-while-accounting-for-time</guid>
      <pubDate>Fri, 12 Jul 2024 00:13:49 GMT</pubDate>
    </item>
    <item>
      <title>来自多个传感器的多变量时间序列数据的异常检测</title>
      <link>https://stats.stackexchange.com/questions/650888/anomaly-detection-for-multivariate-time-series-data-from-multiple-sensors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650888/anomaly-detection-for-multivariate-time-series-data-from-multiple-sensors</guid>
      <pubDate>Thu, 11 Jul 2024 15:48:09 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系仍然成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    <item>
      <title>如何对密度（计数/面积）数据进行功率分析？</title>
      <link>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-count-area-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-count-area-data</guid>
      <pubDate>Mon, 08 Jul 2024 18:27:16 GMT</pubDate>
    </item>
    </channel>
</rss>