<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 22 Jun 2024 18:18:35 GMT</lastBuildDate>
    <item>
      <title>通货膨胀因素与标准误差的关系</title>
      <link>https://stats.stackexchange.com/questions/649721/relation-variation-inflation-factor-to-standard-error</link>
      <description><![CDATA[我正在阅读 ISLP 书中的第 3 章“线性回归”。
第 6 节。共线性对我来说非常令人困惑。首先，它显示了与 $\beta_i$ 的可能估计值相关的 RSS 等高线图：如果两个系数高度相关，则等高线沿着一个狭窄的山谷延伸，这意味着 $SE(\beta_i)$ 很高。
但是我不明白给定样本的 RSS 变异性如何与不同样本的 $beta_i$ 的标准误差相关。

然后引入 VIF（变异膨胀因子的缩写），即拟合完整模型时的方差 $\beta_j$ 与单独拟合时的方差 $\beta_j$ 之比。
还引入了一个计算 VIF 的公式：
$$\text{VIF}(\hat{\beta}_j) = \frac{1}{1 - R^2_{X_j | X_{-j}}}$$
这只是一个基于 R2 的公式，它表明我们能根据其余预测因子将 $x_j$ 拟合得多好。我不明白如果拟合整个模型时 $\beta_j$ 除以单独拟合时 $\beta_j$ 的方差，这个公式如何等于方差比。因为这两件事对我来说完全是分开的，我无法将它们联系起来。
我很感激任何直观的解释来理解这些概念。]]></description>
      <guid>https://stats.stackexchange.com/questions/649721/relation-variation-inflation-factor-to-standard-error</guid>
      <pubDate>Sat, 22 Jun 2024 16:50:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 RMSE 确定 PLSR 的理想成分数量？</title>
      <link>https://stats.stackexchange.com/questions/649720/how-to-determine-the-ideal-number-of-components-for-plsr-using-rmse</link>
      <description><![CDATA[我想确定一种非视觉的、基于数字的方法来确定我的 PLSR 模型的理想组件数量。
模型中有 10 个组件，每个组件对应 1 个目标变量。
如果我仅取最小 RMSE，则有可能会导致过度拟合。
我创建的解决方案是将所有 RMSE 相对于初始 RMSE 值进行标准化。
然后，我将每个组件计数的 RMSE 改进评估为百分比。如果某个组件的 RMSE 与前一个组件计数 RMSE 相比下降幅度超过 0.2%，而其余组件计数 RMSE 的下降幅度小于 0.2%，则当前组件计数将被确定为理想组件计数。
以下是一张显示 RMSE 下降与模型中组件数量的关系的图像。

初始值为 时相对下降1：
[1，
0.004658795584743515，
0.004425848412019989，
0.0038956684834532893，
0.002636942279393668，
-0.003304257338957214，
0.0005941970353721279，
-0.005115285683331376，
0.006326001921934667，
-0.0004789479534198631]
在组件编号 6 处，相对 RMSE 值为负，表明组件编号 5 是局部最小值。如果我们评估剩余组件数量的 RMSE 值，则减少量不到 0.2%。
这是一种确定理想组件数量的方法吗？
此外，当从第一个组件到最后一个组件的增加相对于初始 RMSE 仅增加 3% 时，仅选择第一个组件是否合理，因为这将以最小的泛化成本减少过度拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/649720/how-to-determine-the-ideal-number-of-components-for-plsr-using-rmse</guid>
      <pubDate>Sat, 22 Jun 2024 15:17:11 GMT</pubDate>
    </item>
    <item>
      <title>计算涉及不同估计量和分位数的相关测量的平均值和误差</title>
      <link>https://stats.stackexchange.com/questions/649719/calculating-the-mean-and-error-for-correlated-measurements-involving-different-e</link>
      <description><![CDATA[我的目标是找到一种方法来报告同一分布（相同测量值）的不同估计量和分位数的平均$\pm$误差。
我正在用不同的估计量（检查稳定性）和不同的分位数（越来越多地限制在内核）测量分布的宽度（高斯核心和长尾）。
我发现了两个稳定的估计量：

各种分位数的高斯拟合的西格玛：从 100%（考虑拟合的完整分布）到 80% 内核——基本上是切割越来越多的尾部。
中位数绝对偏差（中位数），同样适用于相同的
分位数。

为了完整起见，下面是分布的图片。在那里，我用高斯拟合蓝色部分（98％分位数，通过从分布的两侧去除 1％）。对于这个 98% 的核心，除了用红色报告的高斯西格玛外，我还得到了 AAD、RMS 和 MAD 等估计量。
对于不同的估计量和分位数，我得到了一个值及其不确定性的列表，我将其报告如下：
估计量、分位数、值、误差
MAD，100，0.371，0.018
MAD，99，0.364，0.017
MAD，98，0.367，0.017
MAD，97，0.347，0.017
MAD，95，0.363，0.017
MAD，93，0.345，0.017
MAD，90，0.378，0.018
MAD，85， 0.363，0.017
MAD，80，0.383，0.018
Gauss_sigma，100，0.335，0.017
Gauss_sigma，99，0.335，0.017
Gauss_sigma，98，0.334，0.017
Gauss_sigma，97，0.339，0.017
Gauss_sigma，95，0.357，0.017
Gauss_sigma，93，0.351，0.017
Gauss_sigma，90，0.337，0.017
Gauss_sigma，85，0.332， 0.017
Gauss_sigma，80，0.314，0.016

现在，这些测量值都属于同一分布。因此，误差是完全相关的。
我正在尝试找出一种方法来报告这些测量值的平均值和误差。
我认为对于误差，我可以进行误差传播，考虑到相关系数为 1。我会得到：$\sigma = \sqrt{\sigma_A^2 + \sigma_B^2 + 2\sigma_A\sigma_B}$
对于平均值，我不确定从这些值计算平均值是否有意义，因为我上面报告的值不是不同的测量值，而是同一测量值的不同估计量和分位数。
任何提示都值得赞赏 :) 谢谢！

稍后编辑：
对分布的性质以及选择估计量/分位数的原因进行一些澄清。
分布反映了莫里哀理论给出的散射角。当基本带电粒子穿过某种材料时，它们会与原子核的电场发生数千次弹性碰撞。这些无数相互作用的总和称为多重散射。
大量单个单次散射导致高斯散射角分布（根据中心极限定理），平均值为 0。还有单次散射事件（硬散射），导致大角度。此类事件更为罕见，是您在分布中看到的尾部的原因。
莫里哀理论能够完整地解释分布。但是，我正在研究一种广泛使用的（在我们社区中）参数化方法（由 Highland-Lynch-Dahl 提供），该方法是将有效散射角投影到其中一个横向维度上的概率密度函数。
在此参数化方法中，分布中心部分的宽度（通常是内部 98% 分位数）由一个方程描述，该方程将分布的宽度与称为辐射长度的参数联系起来，该参数是材料特定的。因此，如果要在照射材料样品时测量分布的宽度，则可以推断出该特定样品的辐射长度。
莫里哀理论与我感兴趣的参数没有这样的关系。因此，我必须使用参数化。
此外，据观察，这可能并不适用于所有情况，这正是我试图理解的。
因此，我的目标不是拟合这样的分布，而是从中提取一些信息。
为了完整起见，我有更好地拟合分布的方法（例如高斯 + 学生 t 分布的卷积）。我还从中提取了一个估计量。
最后，我有多个估计量，每个估计量对应多个分位数。我的目标是看看哪些是稳健的，它们能给我带来什么精度，等等……]]></description>
      <guid>https://stats.stackexchange.com/questions/649719/calculating-the-mean-and-error-for-correlated-measurements-involving-different-e</guid>
      <pubDate>Sat, 22 Jun 2024 13:49:42 GMT</pubDate>
    </item>
    <item>
      <title>解释有无聚类调整的置信区间之间的差异。调整后的置信区间应该更宽吗？</title>
      <link>https://stats.stackexchange.com/questions/649717/interpreting-differences-between-confidence-intervals-with-and-without-adjustmen</link>
      <description><![CDATA[我正在尝试解释一篇涉及集群随机试验数据的文章，其中效应大小的置信区间据说已经“使用回归系数的标准误差进行了调整，并转化为效应大小以产生效应大小的上限和下限”与计算 ES 的 CI 的更常用方法相比，这会导致更窄的置信区间和更具统计意义的结果。我感到困惑的是，如果这个测量应该纠正 CSBias，那么考虑到 CSBias 的通常方向，它肯定会导致更宽的置信区间。除此之外，如何解决以不同方式计算的置信区间之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/649717/interpreting-differences-between-confidence-intervals-with-and-without-adjustmen</guid>
      <pubDate>Sat, 22 Jun 2024 13:29:57 GMT</pubDate>
    </item>
    <item>
      <title>计算 GLM 的 QAIC</title>
      <link>https://stats.stackexchange.com/questions/649716/calculating-qaic-for-glm</link>
      <description><![CDATA[我正在尝试使用此处提供的代码来计算 DLNM 模型的 QAIC。
但我对这个公式与其他 R 包中的 QAIC 公式之间的区别感到困惑，就像对这个问题的回答一样。
前者将弥散参数添加到 AIC 公式的似然项中，而另一个则添加到 df 项中，尽管增加弥散会导致两者均采用 QAIC。]]></description>
      <guid>https://stats.stackexchange.com/questions/649716/calculating-qaic-for-glm</guid>
      <pubDate>Sat, 22 Jun 2024 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表答案中问题组的相关性</title>
      <link>https://stats.stackexchange.com/questions/649714/correlation-of-group-of-questions-in-likert-scale-answers</link>
      <description><![CDATA[假设我们有一个包含 6 列的响应调查数据框。每列是一个问题：Q1、Q2、Q3、...、Q6。响应从 1 到 5。1 表示非常差，4 表示差，3 表示一般，2 表示好，1 表示非常好。另外，考虑 A 是 q1、q2、q3 的一组问题，B 单独包含问题 q4，C 包含 q5 和 q6。我的最终任务是找出所有组之间的相关性。A 与 B、B 与 C、A 与 C 等等，如相关矩阵所示。我的问题是：响应是因素的级别。等级。每个响应都是一个等级。它可能是数字，但它是一个等级。如果我取问题的平均值，那么可以使用 Spearman 相关系数吗？还是我必须取中位数？如果我不使用 Spearman（处理等级）我可以使用 Pearson 系数吗？

likert_levels &lt;- c(1,2,3,4,5)
set.seed(42)
library(dplyr)
df &lt;-
tibble(
&quot;q1&quot; = sample(likert_levels, 150, replace = TRUE),
&quot;q2&quot; = sample(likert_levels, 150, replace = TRUE, prob = 5:1),
&quot;q3&quot; = sample(likert_levels, 150, replace = TRUE, prob = 1:5),
&quot;q4&quot; = sample(likert_levels, 150, replace = TRUE, prob = 1:5),
&quot;q5&quot; =样本（c（likert_levels，NA），150，替换 = TRUE），
“q6”= 样本（likert_levels，150，替换 = TRUE，prob = c（1，0，1，1，0））
）%&gt;%
突变（across（everything（），~factor（.x，levels = likert_levels）））

df2 = tibble（类别 = c（“A”，“A”，“A”，“B”，“C”，“C”），
问题 = c(&quot;q1&quot;,&quot;q2&quot;,&quot;q3&quot;,&quot;q4&quot;,&quot;q5&quot;,&quot;q6&quot;))

df2
df%&gt;%
mutate(id = row_number())%&gt;%
tidyr::pivot_longer(!id,names_to = &quot;questions&quot;,values_to = &quot;responses&quot;)%&gt;%
left_join(.,df2,by=&quot;questions&quot;)

df_cor=df%&gt;%
mutate_if(is.factor,as.double)%&gt;%
rowwise() %&gt;%
mutate(QA = mean(c(q1, q2, q3)),
QB = mean(c(q4)),
QC =平均值（c（q5，q6）））％＆gt;％
选择（QA，QB，QC）

cor（df_cor，方法=＆quot;spearman＆quot;，使用=＆quot;pairwise.complete.obs＆quot;）
cor（df_cor，方法=＆quot;pearson＆quot;，使用=＆quot;pairwise.complete.obs＆quot;）
]]></description>
      <guid>https://stats.stackexchange.com/questions/649714/correlation-of-group-of-questions-in-likert-scale-answers</guid>
      <pubDate>Sat, 22 Jun 2024 11:55:19 GMT</pubDate>
    </item>
    <item>
      <title>单位根平稳性和建模 AR(p) 过程</title>
      <link>https://stats.stackexchange.com/questions/649711/unit-root-stationarity-and-modelling-arp-process</link>
      <description><![CDATA[我正在阅读 Gary Koop 的《计量经济学导论》。我对 AR(p) 过程的建模过程有点困惑。希望有人能帮我澄清一下。让我阐述一下我的理解和我有点困惑的地方。
假设我们有一个 AR(p) 过程：
$$ Y_t = \alpha +\rho_1 Y_{t-1} + \ldots +\rho_p Y_{t-p}+\varepsilon_t \tag{1}.$$
然后我们可以将其一阶差分视为：
$$\Delta Y_t = \alpha + \theta Y_{t-1} + \gamma_1\Delta Y_{t-1} + \ldots + \gamma_{p-1}\Delta Y_{t-p+1} + \varepsilon_t \tag{2}$$
其中 $\theta = \rho_1+\dots +\rho_{p} - 1$。
如果我们有一组数据，那么我们可以使用 OLS 将 $(2)$ 拟合到数据中，使用顺序 t 检验或似然函数（例如 BIC）选择滞后和参数。
完成此操作后，我们需要对参数 $\theta$ 使用 Dickey-Fuller 检验，其中零假设为 $H_0\colon\ \theta = 0$。如果我们找不到任何证据来拒绝原假设，那么这意味着我们的原始模型 $(1)$ 有一个单位根。在模型 $(2)$ 中，我们将得到 $\theta = 0$，并且 $\Delta Y_t$ 将是平稳的，因为我们知道具有单位根的 AR(p) 模型的一阶差分是平稳的。
但是，如果我们拒绝 $\theta = 0$ 的原假设，我有点搞不清楚我们该怎么做。在这种情况下，我们可以得出结论，原始序列没有单位根。那么我们可以继续使用 OLS 直接对其进行建模吗？我们是否必须进一步假设它不是一个爆炸性过程？除非我遗漏了某些内容，否则教科书似乎没有涵盖这些内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/649711/unit-root-stationarity-and-modelling-arp-process</guid>
      <pubDate>Sat, 22 Jun 2024 11:08:17 GMT</pubDate>
    </item>
    <item>
      <title>情景还原技术</title>
      <link>https://stats.stackexchange.com/questions/649703/scenario-reduction-techniques</link>
      <description><![CDATA[我有一个包含 7 个特征和 500 个样本的数据集，即一个包含 7 个特征场景的 7 x 500 矩阵。场景是指“随机变量的潜在结果”，在我的例子中，它是产品的需求。
由于在我的模型中处理 500 个样本计算量很大，我想知道哪些方法最适合将场景数量减少到 7 x 50。
我知道 PCA 通常用于降维，但是否可以使用 PCA 来减少场景数量？例如，是否可以计算主成分并沿着下图中的主要成分 $u_1$ 和 $u_2$ 选择场景？这有意义吗？

截断点反映了所选的 PCA 转换数据点 - 在运行我的模型之前将其转换回原始坐标。
我的模型基本上由以下推论给出：

正是由于半正定 (PSD) 约束，我的问题才变得计算复杂很重。决策变量 $\Lambda$ 是一个 7 x 7 矩阵，因此，对于每个 $i \in N$ 和 $N=500$（即样本/场景的数量），PSD 约束变为 8 x 8 矩阵。
一般来说，这对于线性程序来说不是问题，但是，这是一个线性和凸 PSD 程序，其求解难度要大得多。因此，500 个 PSD 约束相当重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/649703/scenario-reduction-techniques</guid>
      <pubDate>Sat, 22 Jun 2024 09:48:06 GMT</pubDate>
    </item>
    <item>
      <title>对 PCA、FA 和 PCR 感到困惑？</title>
      <link>https://stats.stackexchange.com/questions/649701/confusion-regarding-pca-fa-and-pcr</link>
      <description><![CDATA[我在这里学到了：PCA 后跟旋转（例如方差最大）是否仍是 PCA？
关于 PCA 和 FA 之间的关系，以及它们各自如何提供观察同一事物的视角。然而，在工作中，我遇到了一些遗留代码，它们做了一些奇怪的事情，至少在上述帖子中描述的框架内是这样的（将进行总结）。
在帖子中，作者说 SVD 给了我们
$X=USV^⊤$
然后我们可以将其分解为正交基和成分分数（PCA 视图）或潜在单位方差变量及其载荷（FA 视图），通过将 $S$ 矩阵与 $U$ 分组（$US$ = PCA 中的成分分数，$V$ 有基础）或与 $V$ 分组（$VS$ 是载荷矩阵，$U$ 有因子）。
这很有道理，但我看到的代码中有人计算 PCA，提取如上所述的载荷（特征向量按 sqrt(特征值) 缩放），然后在这些载荷上对原始矩阵进行回归以找到因子，结果当然是不同的。这种差异意味着什么？每个有什么优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/649701/confusion-regarding-pca-fa-and-pcr</guid>
      <pubDate>Sat, 22 Jun 2024 08:45:25 GMT</pubDate>
    </item>
    <item>
      <title>假设检验有限样本空间高斯混合模型</title>
      <link>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</guid>
      <pubDate>Sat, 22 Jun 2024 00:53:33 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    <item>
      <title>mgcv 中的多项回归拟合错误 - [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649563/error-with-multinomial-regression-fit-in-mgcv</link>
      <description><![CDATA[数据位于 https://file.io/th7TXDPopc5Y
响应列“y”是多项式，其余的是预测变量。当我尝试拟合以下模型时，我收到错误 --
 &gt; b &lt;- gam(list(y ~ s(dur) + s(gly) + s(bmi) +
+ ti(dur,gly) + ti(dur,bmi) + ti(gly,bmi), ~ -1, ~ -1, ~ -1, ~ -1, ~ -1), 
+ select = TRUE, data=dta_df, family = multinom(K=6), method = &quot;REML&quot;)
x[, jj[[k]], drop = FALSE] 中的错误：下标超出范围

我已尝试使用方法参数的 NCV 选项，但仍然出现相同的错误。如能得到任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649563/error-with-multinomial-regression-fit-in-mgcv</guid>
      <pubDate>Thu, 20 Jun 2024 04:57:43 GMT</pubDate>
    </item>
    <item>
      <title>面板数据的工具变量</title>
      <link>https://stats.stackexchange.com/questions/641581/instrumental-variable-for-panel-data</link>
      <description><![CDATA[我试图量化金融制裁对跨境资本流动的影响。我建立了一个按国家对和年份划分的制裁和资本流动二元数据集。我的样本期跨越 20 年。
我进行了固定效应回归，其中制裁的解释变量是一个虚拟变量，在给定国家对之间实施制裁的每一年取值为 1。我在样本中包括了每个国家对和每年的固定效应。
\begin{equation*}
\text{Capital_flows}_{c_1, c_2, t} = \beta_0 + \beta_1 \text{sanction}_{c_1, c_2, t} + \eta_{c_1, c_2} + \varphi_t + \varepsilon_{c_1, c_2, t}
\end{equation*&gt;
（其中 $\eta_{c_1, c_2}$ 是一组特定于国家组合的固定效应，而 $\varphi_{t}$ 是一组特定于时间的固定效应。）
据我了解，我的固定效应将删除之前包含在我的误差项中的所有决定资本流动的时间不变因素。因此，我现在被各种决定资本流动的时间变化因素所困扰。
读过一些资料后，我发现我的方法的主要问题似乎是内生性，即我的制裁虚拟变量将与我的误差项相关。我计划通过小心地向我的模型添加额外的（时间变化的）控制变量来解决这个问题。
然而，在与我的一位教授交谈后，他提到解决这个问题的方法是通过工具变量方法和广义矩估计量。
关于这一切，我有几个问题，非常感谢任何建议：

我通过额外的（时间变化的）控制变量解决内生性的想法是错误的吗？
使用 GMM 估计量的工具变量方法到底需要我做什么？据我所知，找到合适的工具变量通常非常困难。
从我的阅读来看，研究人员有时似乎使用滞后因变量作为工具变量。这种情况适用于我的情况吗？
还有其他方法可以获得一致的估计量吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/641581/instrumental-variable-for-panel-data</guid>
      <pubDate>Fri, 01 Mar 2024 14:51:53 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫转移场的解释</title>
      <link>https://stats.stackexchange.com/questions/558998/interpretation-of-markov-transition-field</link>
      <description><![CDATA[马尔可夫转换场来自这篇文章：
https://www.researchgate.net/publication/282181246_Spatially_Encoding_Temporal_Correlations_to_Classify_Temporal_Data_Using_Convolutional_Neural_Networks
它们在这里得到了很好的解释：https://lazyprogrammer.me/convert-a-time-series-into-an-image/
M_kl（转换字段的一个元素）只是我们在时间序列中看到从 q_k 到 q_l 的直接一步（即马尔可夫）转换的概率。
但文章指出：
通过在每个像素 M_ij 处分配从时间步骤 i 的分位数到时间步骤 j 的分位数的概率，MTF M 实际上编码了时间序列的多步转换概率。 M_i,j||i−j|=k 表示时间间隔为 k 的点之间的转换概率。
并且
通过将一阶转换概率分散到时间有序矩阵中，MTF 编码了不同时间滞后 k 之间的转换动态。

我不明白这些句子的意思，因为转换矩阵实际上只包含时间序列中相邻元素分位数之间转换的概率，即根据定义，步数始终被视为 1，所以我不明白它如何能“编码不同时间滞后 k 之间的转换动态” - k 是时间序列中两个时间戳之间的差异。马尔可夫转换场的定义中没有考虑 k（达到另一个分位数的步数）。
实际上，如果考虑到这一点，我会觉得很有意义，我们会将一个分位数在 k 步内变为另一个分位数的概率放入马尔可夫转换场中。为什么不是那样呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/558998/interpretation-of-markov-transition-field</guid>
      <pubDate>Sun, 02 Jan 2022 18:07:58 GMT</pubDate>
    </item>
    <item>
      <title>滚动自相关与整个序列自相关</title>
      <link>https://stats.stackexchange.com/questions/461408/rolling-autocorrelation-vs-whole-series-autocorrelation</link>
      <description><![CDATA[假设我们有一些金融时间序列。当我们计算标准 ACF 时，$\mu$ 被视为所有序列值的平均值。但是，如果我们有一个波动性序列，平均值可能会偏向很久以前的高价，直观地说，“局部”平均值（例如，本周价格的平均值）似乎更适合计算自相关性。
你能解释一下吗，我试图预测第二天的回报，我说得对吗？为什么计算整个序列的 ACF 比滚动序列更标准（至少在教科书中）？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/461408/rolling-autocorrelation-vs-whole-series-autocorrelation</guid>
      <pubDate>Sun, 19 Apr 2020 10:35:25 GMT</pubDate>
    </item>
    </channel>
</rss>