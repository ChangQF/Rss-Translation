<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 23 Nov 2024 01:16:45 GMT</lastBuildDate>
    <item>
      <title>防止最小二乘模型过度拟合</title>
      <link>https://stats.stackexchange.com/questions/657704/preventing-overfitting-in-a-least-squares-model</link>
      <description><![CDATA[以下方程使用双指数或“双对数”描述了残余气体分析质谱测量过程中气体强度的变化。模型：
$$y = a \ln(t + 32) - b \ln(t+30) + c$$
其中：

$y$ 是测量的强度（因变量）
$t$ 是气体平衡后的时间（自变量）
术语 $a \ln(t+32)$ 表示从内存中生长的气体，开始于气体平衡时间 $t=0$ 前 32 秒。
术语 $-b \ln(t+30)$ 表示电离气体的消耗，开始于气体平衡时间 $t=0$ 前 30 秒。
$c$ 表示项 $p$ 和 $q$，如原始方程 $y=a\ln(p(t+32)) - b\ln(q(t+30)) = a\ln(t+32) - b\ln(t+30) + \ln(p) - ln(q)$ 中所述，因此 $c = \ln(p) - \ln(q)$

此模型的目标是尽可能准确地测量$t=0$时$y$的“截距”。该值反映了理论上的平衡气体强度。它通常可以产生极好的拟合效果：

然而，在其他情况下，它表现出不切实际的行为：

在上述情况下，4 amu 和 40 amu 在低$t$值下显示这些“俯冲”。虽然这些骤降来自最小二乘拟合程序，但它们并未描绘预期的物理现实，因此产生了不切实际的截距。虽然内生和消耗同时活跃，但通常其中一种占主导地位。在它们相对平衡的情况下，预期是一种嘈杂的趋势，而不是先大幅下降然后上升：

因此，这些“骤降”被认为是过度拟合的产物，并不反映系统的物理现实。我的目标是减轻或消除这种过度拟合以获得更好的截距。
我可以想到几种方法来解决这个问题：

对$b$强制执行边界，以使消费可能不会太激进。我对此进行了一些实验，并得到了合理的结果，如下所示：

$0 &lt; b &lt; \infty$

$0 &lt; b &lt; 6$

虽然通过强制 $0&lt;b&lt;6$ 消除了这种倾斜，但我牺牲了准确拟合更高 $t$ 值的能力。这导致截距看起来太低。此外，当我向我的一个朋友介绍这种方法时，他反驳道：“那是绘图，不是拟合”。

限制拟合的总曲率。换句话说，让算法远离具有大量曲率的参数空间部分。我不知道如何在 Python 中实现这一点。同样，这感觉更像是绘图而不是拟合。

根据平均强度为消耗项添加阻尼/加权因子。这反映了物理现实，即总压力越高，消耗越强，因此对于较低的信号（低信号=内生长占主导地位，高信号=消耗占主导地位）应该越弱。但是，由于模型将仅通过调整 $b$ 并返回相同的最小二乘拟合来补偿简单的权重，因此我不确定如何在不诉诸边界的情况下实现这一点，这基本上只是方法 #1 的额外步骤。


我在这里很迷茫，我已经原地踏步了一段时间。任何建议、指示等都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657704/preventing-overfitting-in-a-least-squares-model</guid>
      <pubDate>Fri, 22 Nov 2024 23:52:27 GMT</pubDate>
    </item>
    <item>
      <title>Freeman-Tukey 变换的 Metafor 发生率的反向变换</title>
      <link>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</link>
      <description><![CDATA[问题描述
我正在使用 metafor 包对同一疾病的不同治疗方法的术后复发率进行荟萃分析，但我正在努力编写 Freeman-Tukey 变换的发生率的反向变换代码，我们将其用作结果测量。
代码
使用以下方法计算效果大小
 ies = escalc(measure = &quot;IRFT&quot;, add = 0, data = Data, xi = total.recurrences,
ti = time)

我们指定了以下模型并将其拟合到我们不同的治疗组。
模型 1：
 pes.sg = rma.mv(yi, vi, data = ies,
subset = treatment == &quot;insert subgroup&quot;, 
random = ~1 | study.id/es.id,
method = &quot;REML&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;, 
cvvc = TRUE) 

我们还对整个数据集使用了多变量参数化，并使用分组变量作为调节器，以获得与单独分析相同的结果。
模型 2：
 pes = rma.mv(yi, vi, 
random = list(~treatment|study.id, ~treatment|es.id), 
mods = ~0+treatment,
data = ies, 
method = &quot;REML&quot;, struct = &quot;DIAG&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;,
sparse = TRUE)

现在我想使用 predict() 和 transf.iirft() 函数来获取反向转换的结果，但我不知道如何正确指定 xi 和 ti。我认为 xi 指的是转换后的发病率，而 ti 指的是患者时间。
 predict(pes.sg, transf = transf.iirft(xi = ?, ti = ?))
predict(pes, transf = transf.iirft(xi = ?, ti = ?))

如果您能帮助我们对结果进行反向转换，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</guid>
      <pubDate>Fri, 22 Nov 2024 22:28:48 GMT</pubDate>
    </item>
    <item>
      <title>当所有数量已知时，如何确定样本总体缺陷率代表总体缺陷率</title>
      <link>https://stats.stackexchange.com/questions/657701/how-to-determine-that-sample-population-defect-rate-represents-total-population</link>
      <description><![CDATA[我不知道如何正确表述这个问题，所以提前致歉。
假设我有两个总体的数据。总体 1 代表我制造的所有产品，每个产品都可以告诉我它是否有缺陷（使用属性数据，产品要么有缺陷，要么没有，每个产品只能出现一个缺陷）。因此，我有一个总样本量和整个总体的所有缺陷计数。我对此产品进行了更改，我想知道此更改是否会影响我的缺陷率。我使用较小的样本量对修改后的产品进行了一些试验，并统计了此较小样本量中发生的所有缺陷。
总体 1：100000
缺陷 A 数量：400，0.4%
缺陷 B 数量：8，0.008%
缺陷 C 数量：0，0%

总体 2：500
缺陷 A 数量：2，0.4%
缺陷 B 数量：1，0.2%
缺陷 C 数量：0，0%

如何确定两个总体之间的缺陷率是否相似，以及在这种情况下我可以有多大信心说它们相似？对于缺陷 A，当然，它们具有相同的缺陷率，但总体 2 中缺陷 A 的缺陷数量非常少，因此这在统计上可能并不显著。]]></description>
      <guid>https://stats.stackexchange.com/questions/657701/how-to-determine-that-sample-population-defect-rate-represents-total-population</guid>
      <pubDate>Fri, 22 Nov 2024 20:57:19 GMT</pubDate>
    </item>
    <item>
      <title>没有真实标签的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</link>
      <description><![CDATA[领域是天气建模。我有 4 个不同的模型，其中一个是我的，而其他 3 个是独立模型，我认为这些模型相对熟练（即比随机模型好得多）。每个模型在 1000 个感兴趣的空间位置（我将它们称为节点）中的每一个上预测一个值。遗憾的是，每个节点的真实值是无法测量的，因此无法明确地说出哪个模型最好。
但是，我可以说我的模型的预测（模型 A）与其他模型的相关性比任何其他模型都更好：




A
B
C
D




A
1
0.636338
0.571829
0.569591


B
0.636338
1
0.251786
0.283723


C
0.571829
0.251786
1
0.299746


D
0.569591
0.283723
0.299746
1



模型 A 比其他任何模型都更善于预测模型 B，A 与 C 和 A 与 D 也是如此。由于每个模型的预测都是一些预测的组合“真实”信号和一些噪音/错误，我假设我更好的整体相关性意味着我的模型可能比任何其他模型捕获更多的“真实”信号和更少的噪音。
这是一个有效的结论吗？如果是这样，有没有办法量化它，或者我可以引用一个参考资料来支持这个说法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</guid>
      <pubDate>Fri, 22 Nov 2024 20:20:57 GMT</pubDate>
    </item>
    <item>
      <title>支持混合数据类型和先验知识的因果发现包</title>
      <link>https://stats.stackexchange.com/questions/657698/causal-discovery-packages-supporting-mixed-data-types-and-prior-knowledge</link>
      <description><![CDATA[我是因果发现领域的新手，想将标准算法应用于我的数据集，该数据集包含分类变量和连续变量。我正在寻找可以处理混合数据类型并结合先验知识的 Python 包。但是，我发现大多数现有的因果发现 Python 包本身并不支持混合数据。
首先，对于基于约束的方法（如 PC 算法），Causal-Learn 包仅支持一种条件独立性测试。
基于约束的方法：实现 PC 算法的 Causal-Learn 包似乎仅支持一种条件独立性测试。这种限制在处理混合数据时可能会带来挑战。
结构方程模型 (SEM)：LiNGAM 系列中的许多方法都假设连续噪声，这可能使它们不适合包含离散变量的数据集（如果我错了，请纠正我）。虽然 LiNGAM 包确实为混合数据类型提供了类似 LiM 的方法，但这些方法似乎不支持纳入先验知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/657698/causal-discovery-packages-supporting-mixed-data-types-and-prior-knowledge</guid>
      <pubDate>Fri, 22 Nov 2024 19:24:12 GMT</pubDate>
    </item>
    <item>
      <title>针对未观测数据的分层 Dirichlet Gibbs 采样</title>
      <link>https://stats.stackexchange.com/questions/657696/heirarchical-dirichlet-gibbs-sampling-for-unobserved-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657696/heirarchical-dirichlet-gibbs-sampling-for-unobserved-data</guid>
      <pubDate>Fri, 22 Nov 2024 18:39:38 GMT</pubDate>
    </item>
    <item>
      <title>比较不同季节中不同温度区间内所花的时间</title>
      <link>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</guid>
      <pubDate>Fri, 22 Nov 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析、斜向旋转、方差解释</title>
      <link>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</link>
      <description><![CDATA[如何计算通过探索性因子分析获得的因子模型解释的方差的问题时常出现。这里有一个包含多种可能性的摘要：在 R 中使用斜旋转进行探索性因子分析后计算因子解释的方差
我使用的是 R，带有 psych 包，如代码片段所示：
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
mean(fa_results$communalities)
print(fa_results)


平均共同体数量：0.7418824
摘要表还报告了 0.74 作为解释的斜交旋转方差：
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00


如果我使用正交旋转（例如方差最大法）进行相同的分析，那么我会得到相同的总方差解释值。据我了解，正交旋转会在因子之间重新分配载荷，但总方差解释对于整个系统保持不变。但是，我不确定斜向旋转，因为因子在它们解释的方差方面重叠。在上面的例子中，我发现一些因子之间存在显著的相关性，但与方差最大法相比，我得到的总方差解释值相同。在这种情况下，总解释方差是否也相同，或者我做错了什么？我需要反馈。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</guid>
      <pubDate>Fri, 22 Nov 2024 17:10:04 GMT</pubDate>
    </item>
    <item>
      <title>如何将收缩应用于非中心二阶矩估计</title>
      <link>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</link>
      <description><![CDATA[我有一组 $N$ 个样本 $X_i \in \mathbb{R}^m$，属于随机变量 $X$，其中 $m$ 和 $N$ 具有可比性。我想估计二阶矩矩阵$\mathbb{E}\left[XX^T\right]$。
对于估计均值$\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$（其中$\mu=\mathbb{E}[X]$）周围协方差的相关问题，当$m$和$N$具有可比性时，通常最好不要直接使用样本协方差，而是在估计中应用收缩，例如Ledoit-Wolf 协方差估计。
我想知道的是，我将如何使用这种收缩方法对非中心二阶矩矩阵进行处理。因为
$$\mathbb{E}\left[XX^T\right] = \mathbb{E}\left[(X-\mu)(X-\mu)^T\right] +\mu\mu^T$$
并表示 $A=\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$ 和 $B=\mu\mu^T$，我认为一个选项是：

使用收缩获得 $A$
使用样本估计的平均值获得 $B$
将它们加在一起以获得估计$\mathbb{E}\left[XX^T\right]$的收缩。

这听起来像是一种合理的方法吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</guid>
      <pubDate>Fri, 22 Nov 2024 15:57:16 GMT</pubDate>
    </item>
    <item>
      <title>我是否以正确的方式对加权分类调查数据进行统计显着性检验？</title>
      <link>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</guid>
      <pubDate>Fri, 22 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>两组样本数不同但增长至相同值的相关性</title>
      <link>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</link>
      <description><![CDATA[如何获取两个不同长度的集合之间的相关性？我知道皮尔逊相关性不起作用。但是如果它们增长到相同的值，我可以做些什么吗？这就是我的意思。
假设我有两个集合：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
我们可以看到它们的长度不同，但总和相同。
[1, 3, 6, 10] 和 [1, 2, 4, 6, 7, 10]
我们可以看到它们都累积到 10。
我在想，如果我将它们绘制成 x 轴上的累积和以及 y 轴上的原始点。我可以像“连接点”一样。之后，我在想也许我可以对它们进行卷积或者类似的事情，或者像它们的内积？不太确定我在说什么。
这能行得通吗？你能建议一些可以帮助解决这个问题的方法吗？
非常感谢！
编辑：
在回答这些数据代表什么的问题时，这个问题是一个信号处理问题。
系统的工作方式如下。我在一段时间内收到随机数量的尖峰。就我上面的示例而言，假设为 10 秒。
每 10 秒，我都会读取一些尖峰，但尖峰到达的时间与前一个尖峰的时间不同。这就是这个集合所代表的内容：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
现在的问题是，这两个有多大关系？
编辑 2：
在这种情况下，“相关”是什么意思？
对于我的应用程序，“相关”的概念看起来像这样：
[5, 4, 3, 2, 1]
与...略有关系
[4, 3, 2, 1, 1, 2, 2]
如果我绘制到达时间的曲线，一个只是另一个的延迟版本。
我不知道如何称呼我试图描述的这个属性。希望这个描述有所帮助！
编辑 3：
给定：[5, 4, 3, 2, 1]
我们还可以说它与以下内容相关：
[3.9, 3.1, 2, 0.8, 1.2, 2, 2]
此外，我需要能够判断采样是晚还是早。
我们可以说
[3.9, 3.1, 1.9, 0.8, 1.2, 2, 2]
与给定值相比晚了。
并且
[2.5, 5, 4, 3, 0.5]
与给定值相比早了。
编辑4：
抱歉，这有点令人困惑。
什么是晚，什么是早？
给定 A = [5, 4, 3, 2, 1]
B = [4, 3, 2, 1, 1, 2, 2]
且 C = [1, 5, 4, 3, 2]
与 A 相比，B 晚了。
与 A 相比，C 早了。
直觉是这样的。

[5, 4, 3, 2, 1] -&gt; A：完美时机
[4, 3, 2, 1, 1, 2, 2] -&gt; B：晚时机
[1, 5, 4, 3, 2] -&gt; C：早期时间

看到 B 的某些部分与 A 相似，C 同样与 A 相似。它们有相似之处，但索引发生了偏移。
B 和 C 与 A“相关”。
此外，我们可以说
D = [3.9, 3.1, 2, 0.8, 1.2, 2, 2]
D 是 B 的一个略微不准确的版本。
在我的“相关”上下文中，D 也与 A 相关。
希望有所帮助！
编辑 5：
关于“早期”和“晚期”的更多说明
这是 MATLAB 代码及其结果。注意 C 图中与 A 相似的部分位于 A 的右侧。这就是我所说的“早”的意思。B 中的相同部分位于 A 的左侧。这就是“晚”的意思。就像想象时间域中的信号一样。如果信号是早的，它位于参考的右侧。如果它是晚的，它位于参考的左侧。
A = [5 4 3 2 1];
B = [4 3 2 1 1 2 2];
C = [1 5 4 3 2];
D = [3.9 3.1 2 0.8 1.2 2, 2];

cuA = cumsum(A);
cuB = cumsum(B);
cuC = cumsum(C);
cuD = cumsum(D);

图;
plot(cuA, A, &#39;y&#39;);
等待;
plot(cuB, B, &#39;r&#39;);
plot(cuC, C, &#39;b&#39;);
plot(cuD, D, &#39;g&#39;);

legend(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;);

]]></description>
      <guid>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</guid>
      <pubDate>Fri, 22 Nov 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>如何从 N-2 边际生成 N 维多元正态样本</title>
      <link>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</link>
      <description><![CDATA[我的“计算器”遇到了一个问题，它使用通过 N 维多元正态分布生成的样本。我在下面附上了一个代码片段来说明这个问题。
我的计算器从 sample_1 中提取：

M：对 sample_1 中的每个数字都敏感的数字
M_n：一个由 N 个数字组成的向量，每个数字都对 sample_1 中的一列且仅一列敏感

现在，我需要分析我的计算器对相关矩阵中一个特定元素的敏感度。我通过将 correlation_matrix_1 中的 (0, 1) 元素从 0.0 更改为 0.02 来实现。简而言之，问题在于 sample_2 中的第 3 列与 sample_1 中的第 3 列不同。这会导致 M_2 发生更改，这是不理想的结果。两个示例的屏幕截图都位于本消息的末尾，
现在的问题是：我如何从以下位置生成 sample_2 的第 0 列和第 1 列：

sample_1 的第 2 列 -&gt;修复 M_2
correlation_matrix_2

请注意，我必须能够对更大的矩阵执行此操作，尽管仍然需要每次更改一个矩阵元素。
import numpy as np

def main(correlation_matrix: np.ndarray, mc_seed: int = 1234,
n_trials: int = 10):
generator = np.random.default_rng(seed=mc_seed)
segment_factor_sample = generator.multivariate_normal(
mean=[0] * correlation_matrix.shape[0],
cov=correlation_matrix,
size=n_trials,
check_valid=&#39;raise&#39;)
returnsegment_factor_sample

if __name__ == &#39;__main__&#39;:
correlation_matrix_1 = np.array([[1.0, 0.0, 0.0],
[0.0, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_1 = main(correlation_matrix_1)

correlation_matrix_2 = np.array([[1.0, 0.02, 0.0],
[0.02, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_2 = main(correlation_matrix_2)


sample_1


sample_2]]></description>
      <guid>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</guid>
      <pubDate>Fri, 22 Nov 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的二项式家族（link="log"）的 glm 有时需要起始值？</title>
      <link>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</guid>
      <pubDate>Fri, 22 Nov 2024 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>检查两组比例是否_无差异_的检验</title>
      <link>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</link>
      <description><![CDATA[是否有检验方法可以检查两组小比例是否显著无差异？
例如，考虑两组比例
(0.2,0.3,0.25,0.35,0.19)
(0.31, 0.25, 0.21,0.17, 0.22) 
我想证明两组显著无差异。这意味着零假设必须是它们不同。
如果对数据来源​​感兴趣，那就是各种样本的细胞类型比例。我想表明，经过治疗后，各种细胞类型比例的分布没有改变。
之所以选择零假设和备择假设，是因为我感兴趣的实质性主张是两种情况之间没有发生任何变化。无法拒绝无变化的零假设并不等同于接受无变化的假设，后者才是我感兴趣的。]]></description>
      <guid>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</guid>
      <pubDate>Fri, 22 Nov 2024 08:15:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的某个 GAM 响应与数据不太吻合？</title>
      <link>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</guid>
      <pubDate>Thu, 21 Nov 2024 20:10:18 GMT</pubDate>
    </item>
    </channel>
</rss>