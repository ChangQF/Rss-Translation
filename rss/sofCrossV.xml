<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 15 Dec 2023 01:01:14 GMT</lastBuildDate>
    <item>
      <title>请帮忙回答一下有关回归模型分析的问题？</title>
      <link>https://stats.stackexchange.com/questions/634962/help-please-answer-the-question-regarding-regression-model-analysis</link>
      <description><![CDATA[[![回归模型。][1]][1]
[解决此处给出的问题。]
[1]: https://i.stack.imgur.com/f2LHc.png]]></description>
      <guid>https://stats.stackexchange.com/questions/634962/help-please-answer-the-question-regarding-regression-model-analysis</guid>
      <pubDate>Fri, 15 Dec 2023 00:45:03 GMT</pubDate>
    </item>
    <item>
      <title>这是多元方差分析吗？如果是，我该如何将其放入 GPower 中？</title>
      <link>https://stats.stackexchange.com/questions/634961/is-this-a-manova-and-if-it-is-how-do-i-put-it-in-gpower</link>
      <description><![CDATA[我有一项研究，其中有 2 个自变量，每个变量分为两组。参与者将被分配两种“治疗”中的一种，然后被分配来自另一个 IV 的两种“治疗”中的另一种，这意味着 IV 会有四种可能的组合。对于 DV，我想测量干预前后的态度，以确定哪些治疗可能会导致改变，以及事前的态度是否会影响事后态度的改变程度。我还想衡量另一个 DV，它可以与之前和之后的态度联系起来。我的直觉告诉我这是多元方差分析，但我不确定，如果是的话，我不确定到底要在 GPower 中输入什么来进行功效计算。我正在研究交互作用，还有 IV 的主要影响...我需要一些帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/634961/is-this-a-manova-and-if-it-is-how-do-i-put-it-in-gpower</guid>
      <pubDate>Fri, 15 Dec 2023 00:17:50 GMT</pubDate>
    </item>
    <item>
      <title>我们如何在去噪扩散概率模型（DDPM）论文中基于 epsilon 和 x_t 导出 x_0 bsed？</title>
      <link>https://stats.stackexchange.com/questions/634960/how-can-we-derive-x-0-bsed-on-epsilon-and-x-t-in-denoising-diffusion-probabilist</link>
      <description><![CDATA[在方程中。 DDPM 论文的第 15 部分，它派生出 $x_o$  直接基于 $\epsilon$ 和 $x_t$。

我理解实现 $x_{t-1}\leftarrow x_{x}$ 的迭代去噪：
$$
x_{t - 1} = \frac{1}{\sqrt{\bar{\alpha}_t}}\big(x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t} }\epsilon_{\theta}(x_t)\big) + \beta_t\mathbf{I}\cdot \mathbf{z}。
$$
但是我们怎样才能边缘化所有步骤并直接实现$x_0$？我尝试自己推导出公式 15，但未能得到该结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/634960/how-can-we-derive-x-0-bsed-on-epsilon-and-x-t-in-denoising-diffusion-probabilist</guid>
      <pubDate>Fri, 15 Dec 2023 00:14:24 GMT</pubDate>
    </item>
    <item>
      <title>使用哪些技术对社交媒体数据进行建模？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/634958/what-techniques-are-used-to-model-social-media-data</link>
      <description><![CDATA[动机
我一直在为 Medium 撰写文章，但我不喜欢他们的数据呈现方式。这些都是汇总统计数据，并没有为您提供足够的信息来确定您应该采取哪些措施来提高您的覆盖面、收入等。
Medium 的流量比 Google 或 YouTube 少得多，而且数据科学团队的规模可能更小、专业程度也更低。因此，他们在内容呈现方面的风险似乎较小。他们的推荐系统偏向于新近度，并根据标签、您关注的用户以及您之前看过的内容的粗略想法来推送内容。而不是 YouTube 的向量相似度系统。
因此，我认为如果您想成功，就需要更深入地了解您的数据。
我收集了有关我所有帖子、互动和历史记录的数据。我想对其进行分析，以确定我可以做出哪些改变来提高我在平台上的效率。
数据
因变量
我有几个因变量：

阅读 - 有人花费了&gt; 30 秒查看您的帖子，
观看次数 - 有人花费了&lt; 30 秒查看您的帖子，
回复 - 有人对您的帖子进行了回复，
推荐 - 有人对您的帖子进行了投票，
关注 - 有人关注了您的帐户，
收入 - Medium 已向您付款。

所有这些值均按时间序列排列并分为天。 Reads、Views、Responses、Recommendations 和 Follows 均用于派生收入变量。
因此，我正在考虑使用收入作为唯一的因变量。然而，如果我觉得它掩盖了重要的模式，这可能会改变。
还可以在 2 小时内获取阅读、查看和推荐。
自变量
我收集了以下自变量：

OtherUsers - 与我互动过的其他人，
通知 - 由与我交互的OtherUsers生成，
OtherUsersRecentPosts - OtherUsers 最近创建的帖子
InterestDistribution - OtherUsers 最近创建的帖子中使用的标签分布，
MyResponses - 我回复 OtherUsers 内容的帖子，
OtherUsersContentDetail - 有关我所写回复的帖子、鼓掌次数、用户关注者、发布日期等的详细信息，
推荐 - 我对 OtherUsers 内容投了赞成票，
OtherUsersRecommendationsDetail - 有关我推荐的帖子的额外详细信息以及有关撰写该帖子的 OtherUser 的摘要信息。
MyArticles - 我自己创建的类似故事的帖子、标题、标签等、概述指标、带时间戳的详细指标和推荐信息（浏览量的来源）。
HomePageDistributions - Medium 主页给出的推荐内容的原因（针对我）以及获得推荐内容的帖子类型和用户。

大部分数据也带有时间戳，因此我有自变量和因变量的时间戳历史记录。很多数据都是背景信息，我想将它们用作以过去（所有背景数据）为条件的模型的输入，并使用它来预测一些新输入将来会做什么。
我对媒介社交系统的抽象想法
下面是我对 Medium 社交系统的看法：

系统中我用紫色圈出的部分是我想要建模的连接。我想预测给定的 X 输入，我可以期望什么 y 输出。然后使用这些信息在一定程度上确定我应该做出哪些更改来改进我的帐户。
问题
我应该使用什么技术在这样的系统上构建预测模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/634958/what-techniques-are-used-to-model-social-media-data</guid>
      <pubDate>Thu, 14 Dec 2023 23:31:42 GMT</pubDate>
    </item>
    <item>
      <title>对具有许多真 0 的计数数据执行 PCA</title>
      <link>https://stats.stackexchange.com/questions/634953/performing-pca-on-count-data-with-many-true-0%c2%b4s</link>
      <description><![CDATA[我有一个包含行为观察的数据集，每个类别内分为不同类型。
例如，一个类别是：“大胆”。在“大胆”之内存在 7 种不同类型的行为，这将是我的不同变量（列）。对于每个变量，我都有计数数据，这些数据通常是真 0。这些行是对不同个体的重复测量。
我想将数据减少到每个类别一个最终分数（例如“大胆”）。在文献中，我发现研究人员进行 PCA 并使用第一个组件的单位尺度载荷，例如分数。
但是，我的问题是：

我的数据分布（泊松）
我的数据中存在真正的 0（我相信）

下面是我尝试对数据进行 box-cox 转换时的示例：

任何有关如何实现这一潜在最终分数/如何在 R 中使用此类数据进行 PCA 的帮助，将不胜感激。也许这已经可以继续了？]]></description>
      <guid>https://stats.stackexchange.com/questions/634953/performing-pca-on-count-data-with-many-true-0%c2%b4s</guid>
      <pubDate>Thu, 14 Dec 2023 22:34:25 GMT</pubDate>
    </item>
    <item>
      <title>$\frac{X^2}{Y^2}$ 的分布，其中 $X$ 和 $Y$ 是 iid 标准正态分布</title>
      <link>https://stats.stackexchange.com/questions/634951/distribution-of-fracx2y2-where-x-and-y-are-iid-standard-normal</link>
      <description><![CDATA[让 $X,Y\in \mathcal{N}(0,1)$ 与 $X$&lt; /span&gt; 和 $Y$ 独立。我对 $Z=X^2/Y^2$ 的 pdf 感兴趣，其中有一个 $\mathcal{F }(1,1)$ Fisher 分布。我知道他可以通过首先找到 $U=X^2$ 和 $V=Y^ 的 pdf 来完成2$ 并找到 $U/V$ 的 pdf。但是，我对以下方法感兴趣：让 $h$ 为任何 Borel 可测量函数
$$E[h(Z)]=E[h(X^2/Y^2)]=\int_0^\infty\int_0^\infty h\left(\frac {x^2}{y^2}\right)e^{-x^2/2-y^2/2}\frac{1}{2\pi}dxdy.$$
我不确定，但我的直觉告诉我，可以通过更改变量来获得
$$E[h(Z)]=\int_0^\infty h(z)\cdot f(z)dz,$$
因此 $f(z)$ 将是 $Z$ 的 pdf。你认为有人能发现这一变量的变化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634951/distribution-of-fracx2y2-where-x-and-y-are-iid-standard-normal</guid>
      <pubDate>Thu, 14 Dec 2023 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>如何用python组建一个专业项目？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/634947/how-to-form-a-professional-project-in-python</link>
      <description><![CDATA[我正在学习Python，特别是在机器学习和计算机视觉方面。最近在尝试查看Github上的一些论文的代码。我得到的一件事是，为论文编写代码与互联网上的教程有很大不同。它们要复杂得多，由许多不同的文件夹和 .py 文件组成，例如 utils.py、main.py、train.py、init.py 等。我对此事有一些疑问。首先，这些文件的名称是使用某些东西自动创建的还是由编写者手动创建的？其次，如果是自动的，我如何创建这样的编码风格，如果它们是手动完成的，是否有我应该使用的命名或编码的标准格式？最后，有没有参考资料可以教如何创建这样的标准编码风格？]]></description>
      <guid>https://stats.stackexchange.com/questions/634947/how-to-form-a-professional-project-in-python</guid>
      <pubDate>Thu, 14 Dec 2023 20:15:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练准确率保持很高，但验证准确率没有变化？</title>
      <link>https://stats.stackexchange.com/questions/634946/why-the-training-accuracy-stays-high-but-validation-accuracy-does-not-change</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/634946/why-the-training-accuracy-stays-high-but-validation-accuracy-does-not-change</guid>
      <pubDate>Thu, 14 Dec 2023 20:13:06 GMT</pubDate>
    </item>
    <item>
      <title>如何将非独立实验的结果与相同的零假设相结合（例如突变小鼠没有焦虑）</title>
      <link>https://stats.stackexchange.com/questions/634944/how-to-combine-results-from-non-independent-experiments-with-same-null-hypothesi</link>
      <description><![CDATA[我们对一群野生型和突变型小鼠进行了许多不同的行为测试。
在不同日期对同一组小鼠进行 5 项不同的测试，评估焦虑程度。
虽然 bonferonni 或其他一些多重测试校正会“惩罚”重复测试，将我们的 alpha 调整到 ~alpha/5，我认为通过以某种方式结合结果应该会增加信心。
Fisher 的组合 p 值方法（据我了解）无法应用，因为这些方法不是独立的：重复测试相同的小鼠。
我可以运行什么统计测试，或者推荐使用什么方法来结合 5 个（非独立）测试的结果来对显着差异进行总体评估？
因为测试不同，例如在长度和字符方面，我们无法汇集原始数据，但可以在这方面使用 z 分数吗？
在这些类型的实验中，我们通常可能会看到 2、3 或 4 个与 p&lt;0.05 一样显着（没有多重测试校正），但由于 n 较低，每个 p 值并不惊人靠自己。]]></description>
      <guid>https://stats.stackexchange.com/questions/634944/how-to-combine-results-from-non-independent-experiments-with-same-null-hypothesi</guid>
      <pubDate>Thu, 14 Dec 2023 19:32:01 GMT</pubDate>
    </item>
    <item>
      <title>多重插补后汇集假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/634943/pooling-p-values-from-hypothesis-tests-after-multiple-imputation</link>
      <description><![CDATA[我正在开发一个项目，该项目使用了一些比我通常习惯的更先进的统计方法和编码，并且希望得到一些帮助。该项目要求我进行多重插补，这是我使用 mouse r 包完成的。我现在有一个 mids 对象，其中包含 10 个估算数据集（1,200 行，123 个变量）。
我正在制作表 1，其中包含人口统计学差异和性别（男性与女性）其他变量差异的汇总统计数据和 p 值。因为我的连续变量不是正态分布的，所以我计划进行 Mann Whitney U/Wilcoxon 检验来比较它们并提取 p 值。
我的问题在于如何使用乘法插补数据集来执行此操作并汇集 p 值。取中位数就足够了，还是应该使用更高级的方法？我在这里遇到了一种方法：(如何获取在多个估算数据集中完成的测试的汇总 p 值？ - 请参阅 Stef van Buuren 的评论），但此方法声明它仅适用于单方面测试，我我正在进行双边测试，以检测性别之间年龄、体重和身高等特征的任何差异。
据我所知，考虑到我的样本量，t 检验可能足够稳健（并且在 R 中合并这些 p 值的方法似乎更简单），但除年龄之外的所有连续变量都显着偏斜。 
有人知道这里什么是合适的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634943/pooling-p-values-from-hypothesis-tests-after-multiple-imputation</guid>
      <pubDate>Thu, 14 Dec 2023 19:31:39 GMT</pubDate>
    </item>
    <item>
      <title>作为最接近线性表面的主成分与作为二维最佳线性近似的回归线之间的差异</title>
      <link>https://stats.stackexchange.com/questions/634941/difference-between-principal-component-as-closest-linear-surface-and-regression</link>
      <description><![CDATA[我目前正在做一个有关 PCA 的演示，作为研讨会计划的一部分，其中一张幻灯片是关于在任意二维数据集上构建的第一个主成分的解释。在我的一本名为“统计学习与应用简介”的参考书中，作者：Gareth James、Daniela Witten、Trevor Hastie、Robert，自 2015 年起，作者在第 14 页给出了另一种解释。 [第 379 章] 第 379 章
&lt;块引用&gt;
“p 维空间中最接近 n 个观测值的线（使用平均平方欧几里得距离作为接近度的度量）”。

我认为这意味着将第一条 PC 线添加到我的数据的二维散点图中，该数据是在我的缩放和居中的原始数据集上从 R 中的 PCA 获得的，将是等效的在缩放和居中的数据集上添加简单线性回归的回归线（=最佳线性近似），但我的示例中的值/结果反对它。在数字中，当我在基R中使用prcomp(x)对我的数据执行PCA时，它产生了加载向量$\对于第一台 PC，phi_1 = (-0.7071068, -0.7071068)$，但简单的线性回归产生的斜率参数为 $\hat{\beta}_1 = 0.7843085$ 。 
因此，我不得不问我的方法/思维是否有问题，这种关于 PC 的解释是否大约成立，或者我是否搞砸了编码？我的代码示例：
ex.df &lt;- 结构(列表(x = c(70.7, 82.5, 36.5, 97.2, 52.7, 56, 61.3,
59.6、32.5、33.6、70.7、31.3、67、47.6、98.5、64.4、78.7、71.4、
88.7、83.4、44.7、44、56.4、69、30.8、54.5、67.3、56.7、40.7、
36.7, 57.8, 84.7, 35.9), y = c(16, 23.2, 12.2, 18.2, 16.2, 13.5,
14.8、17.3、8、11.7、21.8、10、21.9、13、19.1、14.7、20.2、22.1、
20.5、16.7、9.4、12.2、9.4、18.4、5.8、15.8、13、16、12.5、8.1、
16.4, 14.9, 10.5)), row.names = c(NA, -33L), class = c(“tbl_df”,
“tbl”、“data.frame”））

ex.df &lt;- as.data.frame(scale(ex.df, center = T, scale = T))
apply(ex.df, 2,mean) # 检查 ~0
apply(ex.df, 2, var) # 检查 1
ex.pca &lt;- prcomp(ex.df)
ex.pca # 第一次加载 = (−0.7071068,−0.7071068)
coef(lm(y ~ x, 数据 = ex.df))

编辑：显然，在二维情况下对缩放数据集执行 PCA 时，“加载”会发生变化。只会反映特征向量，如下所述：PCA 中的相同载荷，这使得这个例子毫无用处。尽管如此，我认为这仍然是一个有趣的问题]]></description>
      <guid>https://stats.stackexchange.com/questions/634941/difference-between-principal-component-as-closest-linear-surface-and-regression</guid>
      <pubDate>Thu, 14 Dec 2023 19:24:37 GMT</pubDate>
    </item>
    <item>
      <title>从样本中重新采样以匹配所需的分布</title>
      <link>https://stats.stackexchange.com/questions/634940/resample-from-a-sample-to-match-a-desired-distribution</link>
      <description><![CDATA[假设我有观察$x_1,\dots,x_n$，从$\mathbb{上的某些分布中采样了iid R}$，带有 pdf $p(x)$。假设我希望有一个 pdf $q(x)$ 发行版的样本。有没有办法从 $x_1,\dots,x_n$ 中选择子样本，以便子样本可以被视为来自 $q(x)$?
动机：也许我的观察来自有偏差的分布，我想消除它的偏差。也许现实世界的分布发生了变化，我会观察以匹配更新的分布。不幸的是，我无法“称重”个人观察；我所能做的就是为我的子样本选择观察结果的子集。
换句话说，我想要一个概率过程，将 $x_1,\dots,x_n$ 作为输入，并输出 $x_1,\dots,x_n$，如果给定 $n$ iid 则从 $p(x)$，那么其输出的分布与从 $q(x)$ 中提取的一些 iid 相同。这里 $p(x),q(x)$ 是已知的。我很高兴对 $p(x),q(x)$ 做出任何有用的假设，例如，它们是平滑的、连续可微的，等等。]]></description>
      <guid>https://stats.stackexchange.com/questions/634940/resample-from-a-sample-to-match-a-desired-distribution</guid>
      <pubDate>Thu, 14 Dec 2023 19:20:55 GMT</pubDate>
    </item>
    <item>
      <title>取得成功的迭代次数分布</title>
      <link>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</link>
      <description><![CDATA[设 $Z=X+jY$ （$j$ 是虚数单位），其中$X\sim\mathcal{N}(\mu,1)$ 和 $Y\sim\mathcal{N} (0,1)$.
我正在运行一个算法，在每次迭代时 $k$ 对复数进行采样 $z_k$ 紧随 $Z$ 并计算统计数据：
\begin{方程}
\xi_k = \frac{k\left|\bar{z}\right|^2}{s_z^2}
\end{方程}
与 $$\bar{z}=\frac{\sum_{i=1}^k z_i}{k}\quad\text{and}\quad s_z^ 2 = \frac{1\sum_{i=1}^k \left|z_i-\bar{z}\right|^2}{k-1}$$
我知道 $\xi_k \sim F^\prime_{2,2(k-1)}(\lambda)$ 是一个非中心 &lt; span class=&quot;math-container&quot;&gt;$F$ 分布，分子自由度为 $2$，$2(k-1)$ 分母自由度和与 $\lambda$容器&quot;&gt;$\mu$。
当原假设 $\mu=0$ 被固定的预定义 p 值拒绝时，算法停止（获得成功）$\alpha$。
对于给定的 $\mu$ 和 $\alpha$，算法停止所需的迭代次数$k$？
到目前为止，我已经得到了一个粗略的近似值，考虑到如果算法在第 k 次迭代中获得成功，那么如果我进行第 (k+1) 次迭代，它肯定会继续获得成功，即对于大型 $\mu$ 来说确实如此，但对于较小的则不然。考虑到这一点，我发现了以下成功迭代次数的累积分布的近似值：
\begin{方程}
CDF(k) = 1-g_k(h_k^{-1}(1-\alpha))
\end{方程}
其中 $g_k$ 是 $F&#39;_{2,2(k-1)} 的累积分布(\lambda)$ 和 $h_k$ 是 $F_{2,2(k -1)}$（集中式 F 分布）。
我认为如果我发现 $P(\xi_k\geq\xi_\text{thresh} |\ \xi_i&lt;\xi_\text{thresh}\ \text{对于每次迭代}\ i，其中 $\xi_\text{thresh}$ 是给出期望值的统计值p值，但我不知道如何计算它。]]></description>
      <guid>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</guid>
      <pubDate>Thu, 14 Dec 2023 14:34:09 GMT</pubDate>
    </item>
    <item>
      <title>多元回归 - 分类和连续输出？</title>
      <link>https://stats.stackexchange.com/questions/634906/multivariate-regression-categorical-and-continuous-outputs</link>
      <description><![CDATA[我正在对焊机进行过程表征，并希望构建系统输入与输出的模型。
目前，我正在使用 4 个输入（所有连续数值）和 1 个输出（2 个通过/失败分类和 1 个连续数值）执行单独的多重回归。其间也有一些互动。有什么方法可以将其合并为一个统一的模型吗？输出是相关的，我希望能够近似设置“通过”/“通过”/0.5 秒结果。
下图解释了输入与输出（还有额外的不太可控但仍然有影响力的预测因素）。绿色是可控输入，红色是不可控，黄色受绿色和/或红色影响，紫色是输出。

是否有任何软件具有这样的内置功能，或者我需要用 python 创建一些东西？尝试执行多元回归在此应用程序中是否有意义，或者我应该考虑制作一个神经网络（对此经验较少）。]]></description>
      <guid>https://stats.stackexchange.com/questions/634906/multivariate-regression-categorical-and-continuous-outputs</guid>
      <pubDate>Thu, 14 Dec 2023 13:47:59 GMT</pubDate>
    </item>
    <item>
      <title>OLS：我们是否测试残差的正态性*因为*那么误差项也可以假设为正常？这有证据吗？</title>
      <link>https://stats.stackexchange.com/questions/634887/ols-do-we-test-the-residuals-for-normality-because-then-the-error-terms-can-b</link>
      <description><![CDATA[有很多资源将残差与错误混为一谈，这些术语可以互换使用，或者说“残差错误”，或者不承认残差的存在根本没有错误。 （此处有一个示例。）在这篇文章关于交叉验证，已接受答案下的一条评论说：
&lt;块引用&gt;
毕竟，正态性检验是对残差进行的，以衡量正态分布误差的假设是否合理；误差的正态性将导致残差的正态性。

我的问题是：

是这样吗？我们为什么这么认为？
据我了解，错误的关键在于它们是随机且未知的（“噪声”），我们如何假设有关它们的任何事情？
]]></description>
      <guid>https://stats.stackexchange.com/questions/634887/ols-do-we-test-the-residuals-for-normality-because-then-the-error-terms-can-b</guid>
      <pubDate>Thu, 14 Dec 2023 10:47:58 GMT</pubDate>
    </item>
    </channel>
</rss>