<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Sep 2024 03:18:15 GMT</lastBuildDate>
    <item>
      <title>anova（）和summary（）之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</guid>
      <pubDate>Tue, 03 Sep 2024 01:59:06 GMT</pubDate>
    </item>
    <item>
      <title>经过超参数调整、数据集平衡和卷积分层后，模型仍然过拟合</title>
      <link>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</link>
      <description><![CDATA[我尝试将堆叠在一起的 25x25 像素图像分类为 50x25 像素图像是相同 (1) 还是不同 (0)。我使用 keras 创建 NN 层。训练集中有 1 和 0 的实例 10,000 个，而验证集中有 2000 张 1 的图像和 500 张 0 的图像。
相同 (1) 的示例数据集：

不同 (0) 的示例数据集：

Keras 顺序层如下所示：
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2,imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 
layers.Flatten(), 
layers.Dense(16,activation=&#39;relu&#39;), 
layers.Dense(2,activation=&#39;softmax&#39;) 

然后我使用 adam 优化器编译了这些层，损失和准确率如下：
ml.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), 
metrics=[&#39;accuracy&#39;])
ml_hist = ml.fit(x=training_dataset, epochs=20, validation_data = validation_dataset, shuffle=True)

之后，我使用 epoch=20 和 batch_size=100 训练模型。我根据 epoch 绘制了这些结果。
结果

尝试将验证集平衡为 500 个 1 和 500 个 0 后，结果仍然过度拟合

我甚至删除了正则化并添加了卷积和池化层可用。
layers.Input((2*imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 
layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activity=&#39;relu&#39;, padding=&#39;same&#39;),
layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=&#39;same&#39;),
layers.Flatten(), 
layers.Dense(16,activation=&#39;relu&#39;), 
layers.Dense(2,activation=&#39;softmax&#39;) 


我的问题是：我该如何解决这个过度拟合问题？我不知道我做错了什么，我尝试将学习率更改为 0.1、0.01 和 0.001。我还尝试在 ReLu 之前在 Flatten() 之后添加 0.2、0.5 和 0.7 的 Dropout 层。]]></description>
      <guid>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</guid>
      <pubDate>Tue, 03 Sep 2024 00:30:42 GMT</pubDate>
    </item>
    <item>
      <title>如果你得了一种疾病，存活 5 年的几率为 50%，存活 10 年的几率为 30%，那么 5 年后存活 10 年的几率是多少？</title>
      <link>https://stats.stackexchange.com/questions/653770/if-you-had-a-disease-with-a-50-chance-of-living-5-years-and-a-30-chance-of-liv</link>
      <description><![CDATA[请参阅标题以获取所需的所有信息。另请提供方法/数学。]]></description>
      <guid>https://stats.stackexchange.com/questions/653770/if-you-had-a-disease-with-a-50-chance-of-living-5-years-and-a-30-chance-of-liv</guid>
      <pubDate>Mon, 02 Sep 2024 22:15:14 GMT</pubDate>
    </item>
    <item>
      <title>模拟第一类错误率，以及如何检查第二类错误率</title>
      <link>https://stats.stackexchange.com/questions/653769/simulation-of-type-1-error-rate-and-how-to-check-type-2-error-rate</link>
      <description><![CDATA[当 $H_{0}:\mu = 0$ 时，
iter = 100
n = 500
# alpha, beta
a = .05 # b(0.5) = .95（问题中给出）

并且 $x{\sim}\mathcal{N}(0.5, \sigma)$，对于任意 $\sigma{&gt;}0$，我们应用统计检验来测试 $H_{0}$，并期望

5 次测试产生 1 类错误，或者
5 次测试产生 2 类错误错误，或者
5 个测试拒绝 $H_{0}$?

这些选项是真/假语句。为了检查 (1)，我做了
set.seed(1)
replicate(iter, t.test(rnorm(500, .5, 5))$p.value &lt; a) |&gt; sum()

## 例如返回
# [1] 63

我注意到结果在很大程度上取决于 $\sigma$ 的选择，也就是说，很难得出一些普遍的结论。我认为 (1.) 和 (3.) 都不正确。如何检查 (2.)？]]></description>
      <guid>https://stats.stackexchange.com/questions/653769/simulation-of-type-1-error-rate-and-how-to-check-type-2-error-rate</guid>
      <pubDate>Mon, 02 Sep 2024 21:02:33 GMT</pubDate>
    </item>
    <item>
      <title>关于回归的问题</title>
      <link>https://stats.stackexchange.com/questions/653766/question-about-regression</link>
      <description><![CDATA[假设我有大量关于产品价格和数量的数据样本。我对这些数据进行回归分析，发现相关性为 1。由于相关性为 1 时线性回归中的残差为 0，我现在可以得出存在因果关系的结论吗？如果不能，我还需要什么才能得出存在因果关系的结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/653766/question-about-regression</guid>
      <pubDate>Mon, 02 Sep 2024 19:49:56 GMT</pubDate>
    </item>
    <item>
      <title>递归随机搜索和分类成本函数</title>
      <link>https://stats.stackexchange.com/questions/653765/recursive-random-search-and-categorical-cost-functions</link>
      <description><![CDATA[我目前正在开展一个项目，该项目涉及优化默认的 Spark 提交配置以最大限度地缩短执行时间。我开发了两个模型来帮助完成此过程：
二元分类模型：此模型预测给定的一组配置是否会比默认配置表现更好。
改进预测模型：使用第一个模型的输出，此模型会筛选出更好的配置，然后预测相对于默认配置的改进程度。改进分类如下：
类别 1：0-10% 改进
类别 2：10-20% 改进
类别 3：20-30% 改进
类别 4：30%+ 改进
由于最终目标是确定最佳配置，我正在考虑使用递归随机搜索之类的算法。但是，我不确定哪种分类函数对此类问题最有效，尤其是因为预测确切的执行时间极具挑战性。
此外，我想知道是否有可能将召回率作为变量纳入成本函数中。具体来说，我想使用召回率作为置信度指标来帮助选择我最有信心的类别。
如能就最佳方法提出任何建议或意见，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/653765/recursive-random-search-and-categorical-cost-functions</guid>
      <pubDate>Mon, 02 Sep 2024 19:22:31 GMT</pubDate>
    </item>
    <item>
      <title>需要指导来为教育人力资源技术项目开发推荐系统</title>
      <link>https://stats.stackexchange.com/questions/653764/need-guidance-to-develop-a-recommendation-system-for-an-edu-hr-tech-project</link>
      <description><![CDATA[TLDR：寻求有关如何将用户的问题陈述转化为机器学习问题以及如何准备解决该问题的指导。

大家好！


我目前是一家初创公司的 Web 开发人员。我的任务是为公司高级管理层创建推荐系统的 POC。初步审查后，我们可能会将其推销给客户。


我对基本的机器学习算法及其背后的数学知识有理论了解，但我从未研究过或阅读过推荐系统的工作原理。
这是一家非常小的初创公司，我以项目为基础为我们的内部使用和客户开发系统。所以请善待我，把我看作一个正在寻求已经在这个领域工作的人的帮助和指导的人。


我们的要求和问题陈述非常明确。我的主要挑战是我无法将其转化为机器学习问题。以机器学习可用的格式表示数据并使用适当的技术超出了我目前的知识范围。

问题陈述：

作为教育人力资源技术平台，我们有不同类型的实体，如课程、工作、实习、指导计划、编码问题等。我想根据用户与我们平台上这些实体的互动以及他们的个人资料数据，向他们推荐特定实体，例如他们的学术课程（对于学生而言）或工作资料（对于专业人士而言）。
这是一个粗略的映射：


类别（1）----- 有许多 ---- (m) --&gt; 子类别（m）------ 有许多 ---- (n) --&gt; 技能


实体映射到子类别以及特定技能。


用户：

如果是专业人士，则具有映射到子类别的工作资料，该子类别进一步映射到某些技能。
如果是学生或新生，则具有映射到类别的学术课程专业化，该类别进一步映射到某些技能。

用户还与不同的实体进行交互。某些交互比其他交互更重要，因此需要为此保持加权分数。


因此，总而言之，技能是两个事物之间的共同特征：用户和实体（假设一种实体类型，如课程）。


我不是在寻求完整的解决方案（或者也许我是），但您能否指导我创建推荐系统的方向？


从我目前发现的情况来看，我可以使用类似矩阵分解法的方法来预测用户会给某个实体（某个实体类型）打出的分数。但是，我认为我需要创建一个输出矩阵，以某种方式为用户与之交互的每个实体分配一个分数，然后分解该矩阵。


再次强调，我不是在寻找解决方案，只是在为我的研发和这个 POC 的开发提供指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/653764/need-guidance-to-develop-a-recommendation-system-for-an-edu-hr-tech-project</guid>
      <pubDate>Mon, 02 Sep 2024 18:55:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么我没有得到使用拒绝采样方法生成的正确的 PDF？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653760/why-i-am-not-getting-correct-pdf-generated-using-rejection-sampling-method</link>
      <description><![CDATA[我有一个 PDF，如下所示：
$$f_\Theta(\theta)=\frac{\Gamma(m)|sin(2\theta)|^{m-1}}{2^m \Gamma^2(m/2)}$$ 分布在区间 $\theta=[-\pi,\pi]$ 上。我想使用拒绝抽样生成其样本。我将提议密度设为正态分布 $Y\sim f_{Y}(y)=\mathcal{N}(0,12)$，常数为 $K=3$，使得 $f_\Theta(\theta)\leq Mf_Y(y)$ 在 theta 的范围内。我已经验证并得到了。
但是，在 MATLAB 中使用拒绝抽样时，代码如下，我无法生成所需的 PDF。事实上，PDF 与所需的分布不匹配。
代码：
 m=2;
N=10^5;
K=3;
u=rand(1,N);
g=normrnd(0,sqrt(12),1,N);
loopj=0;
对于 iloop=1:N
sampf=gamma(m)*((abs(sin(2*g(1,iloop))))^(m-1))/((2^m)*(gamma(m/2))^2);
if(u(1,iloop)&lt;(sampf)/((K./(sqrt(2*pi*12)))*exp(-(g(1,iloop)).^2/(24))))
loopj=loopj+1;
sampf(loopj)=g(1,iloop);
end
end
[f,xi] = ksdensity(sampf);
plot(f)

其中 pdf 使用 MATLAB 中的 ksdensity 命令绘制。

这里可以看出，轴不同，但形状也不匹配所需的分布形状。]]></description>
      <guid>https://stats.stackexchange.com/questions/653760/why-i-am-not-getting-correct-pdf-generated-using-rejection-sampling-method</guid>
      <pubDate>Mon, 02 Sep 2024 17:30:44 GMT</pubDate>
    </item>
    <item>
      <title>随机截距交叉滞后面板模型的替代方案</title>
      <link>https://stats.stackexchange.com/questions/653758/alternative-to-random-intercept-cross-lagged-panel-model</link>
      <description><![CDATA[我正在寻找一些灵感，以了解如何最好地模拟给定的现象，我想在这里问一下。
这是一项研究，我们将在疾病进展过程中收集 5 次重复测量（例如血压，BP）。在这 5 次测量中，我们还将收集特定的血液标记物 (BM)。我们相信这种血液标记物会导致血压变化。有几种可能性（1. 高且持续的平均 BM 水平会导致血压随时间变化；2. 血压之前的 BM 将解释血压的未来变化；3. BM 随时间线性增加，导致血压变化增加。血压变化发生的确切时间尚不清楚（我们知道它发生在时间 0 和时间 5 之间，但不知道它发生在时间 2、3 还是 4）。
我考虑过使用随机截距交叉滞后面板模型 (RI-CPLM)，但我正在寻找一种更简单的方法。例如，我对血压 -&gt; BM 变化不感兴趣，所以我认为我不需要 CLPM 的“交叉”部分。另一个限制是，虽然我们观察到的效果通常很大，但我们的样本量非常有限（50-100 个受试者），因此基于蒙特卡罗模拟的 RI-CPLM 没有足够的动力。
理想情况下，最后，我还想评估一下适度性（例如，当疾病严重程度越大时，BM 和 BP 之间的关联是否越大）
有什么建议、推荐读物等吗？
非常感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/653758/alternative-to-random-intercept-cross-lagged-panel-model</guid>
      <pubDate>Mon, 02 Sep 2024 17:11:36 GMT</pubDate>
    </item>
    <item>
      <title>3-D 图表适合于什么情况？</title>
      <link>https://stats.stackexchange.com/questions/653752/in-what-instances-are-3-d-charts-appropriate</link>
      <description><![CDATA[多年来，我读过的所有与数据分析相关的文章都建议在几乎所有情况下都不要使用三维图表。引用其中一句话，“当二维图表就足够时，永远不要使用三维图表。”
这引出了一个问题：在什么情况下三维图表是合适的？]]></description>
      <guid>https://stats.stackexchange.com/questions/653752/in-what-instances-are-3-d-charts-appropriate</guid>
      <pubDate>Mon, 02 Sep 2024 15:41:10 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用 beta 二项分布代替 MCMC 吗？</title>
      <link>https://stats.stackexchange.com/questions/653748/can-you-use-the-beta-binomial-distribution-instead-of-mcmc</link>
      <description><![CDATA[因此，我有一个项目要测试以下假设：采用新艺术的营销活动比旧广告产生更多的购买量，我有 2 个数据样本，一个使用标准广告，一个使用新广告。因此，我们有总展示次数和购买次数。我们可以将其估计为$\text{Binomial}(\text{impressions}, \text{purchases} / \text{impressions})$。
因此，如果我们说：
$$
\begin{align}
&amp;X_{c} \sim \text{Binomial}(I_{c},\theta_{c})\\
&amp;X_{t} \sim \text{Binomial}(I_{t},\theta_{t})
\end{align}
$$
并且我们使用$\theta \sim \text{Beta}(1,1)$作为先验，我们可以得到测试和控制的相应后验。所以，我的问题是，我可以使用 beta-二项分布作为进行假设检验的分析方法吗？还是我必须使用蒙特卡洛马尔可夫链模拟并以通常的方式进行？
我的理由是，给定数据，我们可以计算出购买数量 $\tilde{x}$ 的概率为
$$
P(\tilde{x}=x \ |X_{t},\theta&#39;_{t})\sim \text{Beta-Bin}(I_t,1+x_t,1+I_t-x_t)
$$
其中 $\theta&#39;_t$ 是 $f(X_t \ | \ \theta_t)$ 的后验，而 $x_t$ 是测试广告的购买数量。因此我可以使用它来计算 BayesFactor
$$
BF_{10}=\frac{P(\tilde{x}\geq x_t \ | X_t ,\theta_t&#39;)}{P(\tilde{x}\geq x_t \ | X_c ,\theta_c&#39;)}
$$
而不是使用通常的 MCMC 模拟并比较结果。
注意：我已将此发布在 Math stack 上，但在被告知这一点后，我觉得它会更合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/653748/can-you-use-the-beta-binomial-distribution-instead-of-mcmc</guid>
      <pubDate>Mon, 02 Sep 2024 14:41:12 GMT</pubDate>
    </item>
    <item>
      <title>对正定协方差矩阵的元素取绝对值后形成的矩阵还是正定的吗？</title>
      <link>https://stats.stackexchange.com/questions/653745/is-the-matrix-formed-by-taking-the-absolute-values-of-the-elements-of-a-positive</link>
      <description><![CDATA[假设我有一个正定协方差矩阵 $\boldsymbol{\Sigma}$。我构造一个新矩阵 $\boldsymbol{\Lambda}$，其中 $\boldsymbol{\Lambda}$ 中的每个元素 $(i,j)$ 等于 $\boldsymbol{\Sigma}$ 中对应元素的绝对值。$\boldsymbol{\Lambda}$ 是否仍然是有效的协方差矩阵？
如果不是，在什么条件下它为真？]]></description>
      <guid>https://stats.stackexchange.com/questions/653745/is-the-matrix-formed-by-taking-the-absolute-values-of-the-elements-of-a-positive</guid>
      <pubDate>Mon, 02 Sep 2024 14:01:30 GMT</pubDate>
    </item>
    <item>
      <title>进行显著性检验，结果以与组内对照组的比率表示</title>
      <link>https://stats.stackexchange.com/questions/653741/testing-for-significance-where-results-are-expressed-as-a-ratio-to-an-in-group-c</link>
      <description><![CDATA[我最初在生物学堆栈交换网站上问了这个问题，但后来意识到在统计网站中这个问题可能更有意义：
我有一个大型数据集，它代表了一个酵母缺失突变体库及其在化合物处理下的生长情况。在突变体旁边的库中有一个野生型菌株，我想将每个突变体对治疗的反应表示为与野生型反应的比率，以突出显示对化合物表现出异常敏感性（超敏或抗性）的突变体。到目前为止，我已经确定了一个计算比率的公式，但很难想出一种方法来测试结果的显著性。
例如（不是实际数据，仅用于演示数据结构）：

其中我计算校正比率的方式如下：
((处理突变体的生长)/(处理 WT 的生长))/((对照突变体的生长)/( WT at control))

即通过处理校正比率以解释控制条件下的生长差异
这样我就可以将灵敏度定义为校正比率&lt;1，将抗性定义为&gt;1
有没有办法将简单的统计测试纳入其中，以突出显示与 WT 有显着差异的比率（其中比率始终等于 1）？我对每个突变体和 WT 都有重复（通常 N=4），因此可以轻松计算 SD/SEM 等。]]></description>
      <guid>https://stats.stackexchange.com/questions/653741/testing-for-significance-where-results-are-expressed-as-a-ratio-to-an-in-group-c</guid>
      <pubDate>Mon, 02 Sep 2024 12:40:03 GMT</pubDate>
    </item>
    <item>
      <title>验证数据点是否来自给定的分布</title>
      <link>https://stats.stackexchange.com/questions/653738/validate-if-the-data-points-are-from-a-given-distribution</link>
      <description><![CDATA[我有一个 KDE 对象，它是使用 5000 个训练数据点（三维）计算得出的。KDE 是使用 Statsmodel 计算得出的。
我有 35 个测试数据点（也是三维的）。
MWE 的数据：

训练数据 KDE 文件：GitHub 链接
35 个测试数据点：Github Link

问题：如何验证 35 个测试数据点是否来自给定的 KDE？我正在考虑使用 Kolmogorov–Smirnov 检验，但常见的实现（例如在 Scipy、statsmodel 等中）是针对 1D 的。此外，我很困惑是否应该像下面的 MWE 中那样对各个维度使用 ks_2samp 测试。执行 ks_2samp 测试更容易实现，但不确定这是否是进行验证的正确方法。或者我应该计算边际 CDF 并进行比较（在大型网格上计算它们需要太长时间）。
MWE:
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import joblib

# 加载训练 KDE（使用 5000 个数据点计算）
training_kde = joblib.load(r&quot;PATH-TO-DOWNLOADED_GITHUB-FILE/training_data_kde.pkl&quot;)
training_kde_df = pd.DataFrame(training_kde.data, columns=[&#39;x&#39;, &#39;y&#39;, &#39;size&#39;])
training_kde_df[&#39;DataType&#39;] = &#39;Training&#39;

# 加载测试数据
import pandas as pd

test_data_df = pd.read_csv(r&quot;PATH-TO-DOWNLOADED_GITHUB-FILE/test_data_points.csv&quot;, names=[&#39;x&#39;, &#39;y&#39;, &#39;size&#39;], header=0)
test_data_df[&#39;DataType&#39;] = &#39;Test&#39;

# 组合数据
combined_data = pd.concat([training_kde_df, test_data_df], ignore_index=True)

# 绘制 KDE 以进行比较
plt.figure(figsize=(10, 6))
sns.kdeplot(data=combined_data, x=&#39;x&#39;, hue=&#39;DataType&#39;, common_norm=False)
plt.title(&#39;X 维度的 KDE 比较&#39;)

# 执行 KS 测试
from scipy.stats import ks_2samp
x_statistic, x_pvalue = ks_2samp(training_kde_df[&#39;x&#39;], test_data_df[&#39;x&#39;])
y_statistic, y_pvalue = ks_2samp(training_kde_df[&#39;y&#39;], test_data_df[&#39;y&#39;])
size_statistic, size_pvalue = ks_2samp(training_kde_df[&#39;size&#39;], test_data_df[&#39;size&#39;])

如果 x_pvalue &gt; 0.05 且 y_pvalue &gt; 0.05 且 size_pvalue &gt; 0.05:
print(&quot;测试数据来自同一分布&quot;)

plt.show()
print

]]></description>
      <guid>https://stats.stackexchange.com/questions/653738/validate-if-the-data-points-are-from-a-given-distribution</guid>
      <pubDate>Mon, 02 Sep 2024 12:03:36 GMT</pubDate>
    </item>
    <item>
      <title>我可以比较 4 点李克特量表和 5 点李克特量表的数据吗？</title>
      <link>https://stats.stackexchange.com/questions/652914/can-i-compare-data-from-a-4-point-likert-scale-and-a-5-point-likert-scale</link>
      <description><![CDATA[我正在计划撰写一份政策文件，比较一组国家/地区公众的政策偏好，并试图解释为什么某些国家/地区倾向于强烈支持冰淇淋，但不支持披萨，反之亦然。（这些是任意示例，实际类别与特定政策问题有关。）
为了说明我的论点，我想将每个国家/地区的数据散点图，以便冰淇淋认可的百分比在 x 轴上，披萨认可的百分比在 y 轴上。
我自己没有进行过任何调查（本文旨在探讨未来开展此类项目的可行性）。目前，我对每个问题都进行了单独的调查。两项调查都声称提供了相关国家人口的代表性样本，并且是在大致相同的时间进行的。
冰淇淋调查要求参与者在 4 点李克特量表上表示赞成或反对，没有中立选项；披萨调查要求参与者在 5 点李克特量表上表示赞成或反对，有中立选项。
我想通过将两个样本的“非常赞成”和“有点赞成”加在一起来绘制每个选项的净赞成率。当然，由于冰淇淋调查没有中立选项，它可能迫使一些人选择“有点赞成”或“有点反对”而不是中性选项。
是否有某种方法可以规范化数据，以使两个数据集具有可比性，或者我是否需要做更多研究来找到在李克特量表上具有相同点数的研究？]]></description>
      <guid>https://stats.stackexchange.com/questions/652914/can-i-compare-data-from-a-4-point-likert-scale-and-a-5-point-likert-scale</guid>
      <pubDate>Fri, 16 Aug 2024 04:49:23 GMT</pubDate>
    </item>
    </channel>
</rss>