<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 02 Apr 2024 03:16:53 GMT</lastBuildDate>
    <item>
      <title>在这种情况下（单变量）是否需要对多重比较进行校正？</title>
      <link>https://stats.stackexchange.com/questions/644072/is-correction-for-multiple-comparisons-necessary-in-this-instance-single-variab</link>
      <description><![CDATA[从更具分析化学的背景来到这里，但我想我应该先在这里思考一下我目前的想法，然后再环顾四周后做出任何决定。我习惯于总是使用经过修正的事后方差分析检验（例如，用于成对比较的 Tukey 的 HSD），但现在面临着一种至少以前一直使用 Fisher 的 LSD 的方法。
例如，我有在 5 个不同位置测量的化学物质 A； Fisher 的 LSD 用于将站点浓度分组为彼此显着不同的浓度。然后对测量的每种化学物质重复此操作。因此，在每种情况下，不同组之间仅比较一个变量（化学浓度）（k=5）。 （在很多情况下，您可以简单地查看数据并判断，所以我认为有些人可能会首先质疑是否需要方差分析，但我认为重点实际上只是让一些易于分析的组识别。）
因为只有一个变量（因此每个 LSD 测试都是单变量测试），所以不需要对多重比较进行校正，这种说法是否正确？但是，例如，如果我们要询问采样点之间的一组化学浓度 (A-Z) 是否显着不同，那么我们需要使用 Benjamini-Hochberg 等方法来纠正多重比较或者这样，对吗？不幸的是，我所掌握的方法中的大部分信息并没有解释太多，因为它只是这样完成的，因为它总是这样完成的：P]]></description>
      <guid>https://stats.stackexchange.com/questions/644072/is-correction-for-multiple-comparisons-necessary-in-this-instance-single-variab</guid>
      <pubDate>Tue, 02 Apr 2024 02:50:28 GMT</pubDate>
    </item>
    <item>
      <title>测试两个等效分布</title>
      <link>https://stats.stackexchange.com/questions/644071/testing-two-equivalent-distributions</link>
      <description><![CDATA[假设 $P$ 和 $Q$ 是两个等效的概率度量（在相同的可度量上定义）空间），即他们就零测度事件达成一致。令 $X_1,\cdots, X_n$ 为独立同分布。根据其中之一生成的随机变量。是否有可能得出一个测试统计量 $T_n(X_1,\cdots,X_n)$ 使得
$$Prob_P(T_n = P) \ 到 1$$
和
$$Prob_Q(T_n = Q)\至 1$$
为 $n\to \infty$？
我对“等价”很困惑概念。一方面，我们似乎无法根据“等价”的名称来区分这两种分布。另一方面，“等价”是指“等价”。并不意味着他们在所有事件上都意见一致，对吗？
告诉我这个方程是否没有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/644071/testing-two-equivalent-distributions</guid>
      <pubDate>Tue, 02 Apr 2024 02:47:25 GMT</pubDate>
    </item>
    <item>
      <title>每层的单位太少是否存在问题（例如，<5）？</title>
      <link>https://stats.stackexchange.com/questions/644069/is-there-a-problem-with-having-too-few-units-per-strata-e-g-5</link>
      <description><![CDATA[如果某些层中只有 &lt;5 个单位，它们的稳健性是否会较差 - 例如，当没有响应等时可能会导致问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/644069/is-there-a-problem-with-having-too-few-units-per-strata-e-g-5</guid>
      <pubDate>Tue, 02 Apr 2024 02:26:12 GMT</pubDate>
    </item>
    <item>
      <title>给定包含引理情感数据的变量 A 和 B，包含 var A 和 var B 平均值的变量的正确术语是什么？</title>
      <link>https://stats.stackexchange.com/questions/644068/given-variable-a-and-b-containing-data-of-lemma-sentiments-what-is-the-correct</link>
      <description><![CDATA[我有一个数据可视化，显示了两个引理“gay”的情绪(var a)和“跨性别者” (var b) 全年新闻语料库中。
这是我的数据的数据框示例：
 orientasi tahun 情感
  &lt;chr&gt;  
1 同性恋 1991 1.7
2 同性恋 1993 3.3
3 同性恋 1995 -0.8
4 同性恋 1996 1.58
5 同性恋 1997 0.606
6 同性恋 1998 1.8
...
36 变性人 2016 -1.97
37 变性人 2017 -1.98
38 变性人 2018 -0.73
39 变性人 2019 -0.63
40 变性人 2020 -0.982
41 变性人 2021 0

R 中数据帧的可重现代码：
df &lt;- 结构(list(orientasi = c(“同性恋”, “同性恋”, “同性恋”, “同性恋”,
“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，
“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，
“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，“同性恋”，
“同性恋”、“同性恋”、“同性恋”、“跨性别者”、“跨性别者”、
“跨性别者”、“跨性别者”、“跨性别者”、
“跨性别者”、“跨性别者”、“跨性别者”、
“跨性别者”、“跨性别者”、“跨性别者”、
“跨性别者”，“跨性别者”，tahun = c(1991L,
1993L、1995L、1996L、1997L、1998L、1999L、2000L、2001L、2002L、
2003L、2004L、2005L、2006L、2007L、2008L、2009L、2010L、2011L、
2012L、2013L、2014L、2015L、2016L、2017L、2018L、2019L、2020L、
2007L、2008L、2011L、2012L、2013L、2014L、2015L、2016L、2017L、
2018L, 2019L, 2020L, 2021L), 情感 = c(1.7, 3.3, -0.8, 1.57777777777778,
0.605555555555556, 1.8, 0.836363636363637, 0.708955223880597,
0.682666666666666、0.56875、-0.744354838709678、0.292857142857143、
-0.36625、-0.273484848484848、0.221608040201005、0.17319587628866、
-0.0928571428571431、0.178169014084507、0.00859374999999992、
-0.48110599078341, -0.738417266187049, -1.14406779661017, -0.665037593984962,
-0.424671052631579, -1.50236686390533, -0.525233644859813, -1.03368794326241,
-0.536619718309859, 2.76666666666667, -1.65, 2.76666666666667,
0.10625, -0.919047619047619, -2.94137931034483, -0.842528735632184,
-1.96549295774648, -1.98392857142857, -0.73, -0.63, -0.982191780821917,
0)), class = c(&quot;grouped_df&quot;, &quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;), row.names = c(NA,
-41L), groups = Structure(list(orientasi = c(“同性恋”, “跨性别者”)
), .rows = 结构(列表(1:28, 29:41), ptype = 整数(0), 类 = c(“vctrs_list_of”,
“vctrs_vctr”，“列表”)))，class = c(“tbl_df”，“tbl”，“data.frame”)
), row.names = c(NA, -2L), .drop = TRUE))

这是它的数据可视化

现在我想显示这两个变量的情绪，或者换句话说，“平均”变量两个变量的值 (var c)。目前我将 var c 定义为 var a 和 var b 的平均值。以下是 var c 的数据帧示例：
 东方情感
    &lt;chr&gt;
1 1991 平均 1.7
2 1993 平均 3.3
3 1995 年 -0.8 平均
4 1996 年 1.58 平均
5 1997 年 0.606 平均
6 1998 年 1.8 平均

用于制作数据框的可重现代码：
#avg 同性恋和跨性别者
df_avg &lt;- df %&gt;%
  group_by(tahun) %&gt;%
  总结（情感 = 平均值（分数）） %&gt;%
  突变（orientasi =“平均”）

之后，我绑定 df 和 df_avg，以便可以可视化 var a、var b、var c。这是我使用的代码：
#bind df 和 df_avg
df_2 &lt;- rbind(df, df_avg)

这是 df_2 的可视化，包含 var a、var b 和 var c：

我的问题看似微不足道，但却是“平均”的问题。 var c 的合适术语？我想到的另一个选择是“同性恋和跨性别者”。但我有一种感觉，这可能会让人们感到困惑。我应该为 var c 使用名称有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644068/given-variable-a-and-b-containing-data-of-lemma-sentiments-what-is-the-correct</guid>
      <pubDate>Tue, 02 Apr 2024 02:14:43 GMT</pubDate>
    </item>
    <item>
      <title>混合方差分析的方差分析类型 (1 v 2 v 3)</title>
      <link>https://stats.stackexchange.com/questions/644065/anova-type-1-v-2-v-3-for-mixed-anova</link>
      <description><![CDATA[我知道之前已经发布过与此问题相关的内容，但它们没有回答我的具体情况。此外，我咨询了大学统计学家，但未能得到答案。
我有一个后续 2（治疗）x 10（天）混合方差分析，严重违反球形度（因为这是 10 次重复测量）。是的，我知道这应该作为传销运行，但应顾问的要求，我仅限于方差分析。我的顾问在 GraphPadPrism 中运行统计数据，默认情况下运行带有球形度校正的 1 型方差分析。我使用 R，我们必须使用 R，因为综合测试无法在 Prism 中运行（因子级别太多）。我已经搜索了高低，统计学家也搜索了包/函数，但是我们找不到在 R 中运行具有球形校正的 I 型方差分析的方法。你可以告诉 R 这样做，它不会抛出警告，但是它也只是不应用修正。
这就是我们面临的问题。在 Prism 中运行 2 x 10，因此带有 Greenhouse-Geiser 校正的类型 1 给出了显着的交互作用项。在 R 中将其作为类型 2 或 3 运行不会返回显着的交互项。我们没有缺失数据，所以设计应该是平衡的。我的顾问想确切地知道哪种方差分析类型适合该数据，因为它改变了他非常关心的交互项的重要性。从我的阅读来看，类型 2 似乎不是最佳选择，因为我们对交互感兴趣（尽管它给出了与类型 2 相同的 p 值）。但在类型 1 和类型 3 之间，我不知道哪一个最适合数据。
提前非常感谢大家。]]></description>
      <guid>https://stats.stackexchange.com/questions/644065/anova-type-1-v-2-v-3-for-mixed-anova</guid>
      <pubDate>Mon, 01 Apr 2024 23:19:32 GMT</pubDate>
    </item>
    <item>
      <title>比较“fish”数据集中的两个模型</title>
      <link>https://stats.stackexchange.com/questions/644063/comparing-two-models-from-the-fish-dataset</link>
      <description><![CDATA[数据
我正在使用 fish 数据集构建线性模型“nofollow noreferrer”&gt;此数据具有以下变量：

res_var：响应变量权重
exp_var1：解释变量Length
exp_var2：解释变量物种

库(dplyr)

鱼 &lt;- read_fst(“Fish.csv”)

鱼 &lt;- 鱼 %&gt;%
变异（长度=（长度1+长度2+长度3）/3）


模型 1
我试图了解以下两个模型的系数之间的差异。第一个是具有两个解释变量及其相互作用的模型：
lm(重量 ~ 长度 + 物种 + 物种:长度 + 0, 数据 = 鱼)

输出：
系数：
             长度种类鳊鱼种类鲈鱼种类梭子鱼种类蟑螂长度:种类鲈鱼长度:种类梭子鱼长度:种类蟑螂
             50.869 -1107.791 -640.845 -1560.734 -342.989 -13.979 -0.836 -28.994

模型 2
第二个模型仅包含一个解释变量及其与另一个解释变量的相互作用：
lm(重量 ~ 物种 + 物种:长度 + 0, 数据 = 鱼)

输出：
系数：
       种类鳊鱼种类鲈鱼种类梭子鱼种类蟑螂种类鳊鱼:长度种类鲈鱼:长度种类梭子鱼:长度种类蟑螂:长度
           -1107.79 -640.85 -1560.73 -342.99 50.87 36.89 50.03 21.88

为了理解上面的第二个模型，我首先过滤了每个 Species 的 fish 数据集：
鳊鱼&lt;-鱼%&gt;%
  过滤器（物种==“鳊鱼”）

鲈鱼 &lt;- 鱼 %&gt;%
  过滤器（物种==“鲈鱼”）

梭子鱼 &lt;- 鱼 %&gt;%
  过滤器（物种==“梭子鱼”）

蟑螂 &lt;- 鱼 %&gt;%
  过滤器（物种==“蟑螂”）

然后，我为上面的每个子集数据集构建了一个简单的线性模型：
mdl_bream &lt;- lm（重量 ~ 长度，数据 = 鳊鱼）

mdl_perch &lt;- lm(重量 ~ 长度, 数据 = 栖息处)

mdl_pike &lt;- lm(重量 ~ 长度, 数据 = pike)

mdl_roach &lt;- lm(重量 ~ 长度, 数据 = roach)

然后我查看了它们的系数。
系数(mdl_bream)

系数(mdl_perch)

系数(mdl_pike)

系数(mdl_roach)

输出：
（截距）长度
-1107.79052 50.86892
（截距）长度
 -640.84506 36.89006
（截距）长度
-1560.73352 50.03289
（截距）长度
 -342.98917 21.87535

这些对应于我提到的第二个模型：lm(Weight ~ Length + Species + Species:Length + 0, data = Fish)。
谁能帮我理解第一个模型的系数应该如何解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/644063/comparing-two-models-from-the-fish-dataset</guid>
      <pubDate>Mon, 01 Apr 2024 23:10:20 GMT</pubDate>
    </item>
    <item>
      <title>使用没有聚类数据的 GEE 模型</title>
      <link>https://stats.stackexchange.com/questions/644061/using-gee-models-without-clustered-data</link>
      <description><![CDATA[我正在使用 N-of-1 方法研究一组纵向数据。这意味着分别研究数据中的每个患者。我知道我的响应变量存在相关性，并且我希望使用 GEE 模型通过 QIC 选择特定的相关结构。然而，在分离不同患者的数据时，我肯定删除了数据集中的多级结构？我正在使用 geeglm() 函数，并为独立相关结构的每个测量指定一个单独的 id 变量，它似乎工作正常，给出与线性模型相同的估计。 “ar1”相关结构似乎并不以相同的方式工作，并且将所有观察值的 id 变量指定为相同的值对我的数据来说是有意义的，但标准误差和 p 值非常小，而估计值和 phi 估计值接近我用过的其他型号（GLS）。我已经研究过使用折刀估计来代替，但这会导致系数的标准误差为 0。是否有另一种方法可以使用“ar1”来代替？这种 N-of-1 设置中的 GEE 结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/644061/using-gee-models-without-clustered-data</guid>
      <pubDate>Mon, 01 Apr 2024 22:42:23 GMT</pubDate>
    </item>
    <item>
      <title>对复杂调查中的变量进行标准化</title>
      <link>https://stats.stackexchange.com/questions/644060/standardizing-variables-from-complex-surveys</link>
      <description><![CDATA[我想要分析一项调查中的几个连续变量。我将使用调查权重进行回归。但我想首先标准化这些变量。我应该使用加权平均值和标准差还是未加权平均值和标准差进行标准化？]]></description>
      <guid>https://stats.stackexchange.com/questions/644060/standardizing-variables-from-complex-surveys</guid>
      <pubDate>Mon, 01 Apr 2024 22:34:02 GMT</pubDate>
    </item>
    <item>
      <title>评估两个变量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/644059/assessing-the-relationship-between-two-variables</link>
      <description><![CDATA[我一直在尝试分析学习时完成的问题数量与多次测试后用户的平均结果之间可能存在的关联。 平均增长变量是多次测试后的平均值。与直觉相反，我并不认为完成的问题数量会对结果产生重大影响。
根据中心极限定理，这种均值分布预计接近正态分布。似乎“收敛”了趋于均值。我可以尝试检查一下是否存在“天花板”。在收益开始微乎其微后，应该回答多少个问题，但我不能说这是一个公平的角度，因为做更多问题后没有趋势，它不是向上也不是向下，可以双向。
我得到的另一种感觉是，“重度用户”，也就是回答了几十个问题的人，往往会更接近平均值，而不会得到极端的结果。
简而言之，感觉我可以忽略 $X$ 变量，而 $Y$ 会仍然表现相同（当我单独绘制 $Y$ 的直方图时，它的行为是一样的。似乎没有直接关系，如果有的话，它不是线性的，因此查看相关性似乎毫无意义。如何建模这种关系？是否有任何我没有看到的警告？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644059/assessing-the-relationship-between-two-variables</guid>
      <pubDate>Mon, 01 Apr 2024 22:06:30 GMT</pubDate>
    </item>
    <item>
      <title>包含截距时线性回归符号切换</title>
      <link>https://stats.stackexchange.com/questions/644058/linear-regression-switch-in-sign-when-including-intercept</link>
      <description><![CDATA[我正在对 x 进行 y 的简单回归。当我包含截距时，x 的 beta 为负且显着；当我不包含截距时，beta 为正且显着。由此可以推断出什么？
使用其他变量时，该论坛上有类似的问题，但我仅使用截距找不到任何内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/644058/linear-regression-switch-in-sign-when-including-intercept</guid>
      <pubDate>Mon, 01 Apr 2024 21:57:09 GMT</pubDate>
    </item>
    <item>
      <title>均匀尺寸偏差的统计测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/644039/statistical-test-for-bias-to-even-sizes</link>
      <description><![CDATA[我正在研究一项遵循某种出生-死亡过程的实验，该过程告诉我同一谱系在特定时间的细胞数量。
因此，我有一个离散的经验分布，随着时间的推移，它大致遵循几何分布。根据解释其他一些观察结果的模型，我们认为它们可能偏向偶数计数而不是奇数计数，我们确实看到了这一点。对于不同时间点的样本中均匀计数具有统计显着性的偏差，适当的假设检验是什么？
我想到了一个单样本比例测试，我根据给定时间点的平均值与几何分布中偶数计数的预期分数进行比较。但我不是统计学家，所以我不知道这是否有效，或者是否有更好的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/644039/statistical-test-for-bias-to-even-sizes</guid>
      <pubDate>Mon, 01 Apr 2024 16:35:40 GMT</pubDate>
    </item>
    <item>
      <title>最小描述长度、归一化最大似然和最大后验估计</title>
      <link>https://stats.stackexchange.com/questions/644029/minimum-description-length-normalized-maximum-likelihood-and-maximum-a-posteri</link>
      <description><![CDATA[TL;DR：我相信使用 NML 的 MDL 是模型和参数联合 MAP 的特例，需要验证这一点并找到承认这一点的来源。
这就是我对最小描述长度（MDL）的理解：我们有一组模型 $M_i\in M$ 以及之前的 $P(M_i)$，每个都由 $\Theta_i$ 参数化，即 $ 对(M_i,\theta\in\Theta_i)$ 完全指定似然函数 $P(z|M_i,\theta)$ 其中 $z$ 是数据。对于每个 $M_i$，我们定义一个函数 $f_i(z)$，然后选择 $\arg\max_{M_i\in M}P(M_i)f_i(z)$。如果我们定义 $f_i(z):=P(z|M_i)=\int_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i, \theta)d\theta$，这相当于 MAP。
但是，我们可以通过其他方式定义 $f_i$。一种方法是归一化最大似然（NML）：
$$f_i(z):=g^{NML}_i(z):=\frac{\max_{\theta\in\Theta_i}P(\theta| M_i)P(z|M_i,\theta)}{\int\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)dz}$$
（一般来说，$P(\theta|M_i)$实际上是用更通用的“幸运函数”代替的。但在这个问题中我们还是坚持这个公式吧）&lt; /p&gt;
这里的分母（我们称之为$I_i$）应该对值进行标准化以防止过度拟合。对于更复杂的模型，它应该更大，本质上是模型复杂性的度量（尽管我不确定这是否是我们定义复杂性的方式，或者只是模型复杂性的另一个独立定义的含义）。
人们看待模型复杂性的一种方式是使用其先前的 $P(M_i)$。从这个角度来看，较小的先验意味着更复杂的模型，因为最佳代码需要更长的消息来对具有较小先验的模型进行编码。现在，采用我们在模型上已有的任何内容，即 $P(M_i)$ 并定义 $P_{new} (M_i)=\frac{P(M_i)}{I_i}$ 作为模型的新先验。另外，我们定义 $f_i(z):=\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)$。与 MDL 一样，我们继续发现：
$$\arg\max_{M_i\in M}P_{new}(M_i)f_i(z)=\arg\max_{M_i\in M}\frac{ P(M_i)}{I_i}\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)=\\\arg\max_{M_i\in M}P(M_i )\frac{\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)}{I_i}=\arg\max_{M_i\in M}P(M_i)g_i ^{NML}(z)$$
这相当于具有先验的 NML 解决方案 $P(M_i)$。然而，我们也可以将其视为发现：
$$\arg\max_{M_i\in M}P_{new}(M_i)f_i(z)=\arg\max_{M_i\in M}P_{new}(M_i )\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)=\\\arg\max_{M_i\in M}\max_{\theta\in\Theta_i} P_{new}(M_i)P(\theta|M_i)P(z|M_i,\theta)=\arg\max_{M_i\in M}\max_{\theta\in\Theta_i}P(M_i, \theta )P(z|M_i,\theta)=\\\arg\max_{M_i\in M}\max_{\theta\in\Theta_i}P(M_i,\theta|z)=\\\arg\max_{ (M_i\in M,\theta\in\Theta_i)}P(M_i, \theta|z)$$
这只是对 $(M_i,\theta\in\Theta_i)$ 上的 MAP 解决方案，而不是仅在 $ 上M_i$，先验 $P_{new}(M_i)$
然而，这实际上是比 NML 更通用的解决方案，因为现在我们不需要通过引用 $M_i$ 的复杂性-container&quot;&gt;$I_i$ 根本没有。因此，只要 $P_{new}(M_i)$ 正确捕获了复杂度，我们就可以选择模型和参数对上的 MAP 解作为描述的解消息最短的数据。
我的问题是，是否有来源承认这一点，以某种方式使用它进行模型选择，并断言它是有效的 MDL 解决方案（即在某种意义上最小化数据的描述长度）？在我的工作中，我喜欢以这种方式描述我的程序，但如果没有相关文献，就很难让人们相信这是有道理的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644029/minimum-description-length-normalized-maximum-likelihood-and-maximum-a-posteri</guid>
      <pubDate>Mon, 01 Apr 2024 14:48:13 GMT</pubDate>
    </item>
    <item>
      <title>聚合数据与非聚合数据</title>
      <link>https://stats.stackexchange.com/questions/644026/aggrregated-vs-non-aggregated-data</link>
      <description><![CDATA[我正在运行 TWFE 逻辑回归来回归公司的退出状态，这意味着如果被投资公司进行了 IPO，则为 1，如果没有，则为 0。我正在运行以下代码规范：
logit_model_exit &lt;- feglm(dv_success ~ ddd | 公司名称 +
    Investment_date, data=data2, family = 二项式(link = &quot;logit&quot;))

我有一个不平衡面板数据集，其中包含约 150 家公司（75 家处理公司和 75 家对照公司，通过粗化精确匹配进行匹配）长达 23 年。原始数据集包含这些公司（风险投资公司）参与的所有交易及其特征。我汇总了一些数据，并创建了每年每个风险投资公司的编译数据集以及相应的汇总数据，例如其投资的退出率。
我使用聚合数据和交易级别数据运行了 TWFE logit。我不确定为什么我得到的估计如此不同，以及为什么在使用聚合数据时估计很重要，而在使用原始数据时估计器根本不重要。我的交易级别数据包含 63k 个观察值，我的汇总数据约为 2300 个。
估计器。标准错误。 z 值。 Pr(&gt;|z|)
0.24363 0.128339 -1.8983。 0.057653。 -&gt;用于汇总数据
-0.071454 0.083729 -0.853397 0.39344 --&gt;用于交易级别数据

知道如何理解这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644026/aggrregated-vs-non-aggregated-data</guid>
      <pubDate>Mon, 01 Apr 2024 14:19:14 GMT</pubDate>
    </item>
    <item>
      <title>在有限的价格信息下实现利润最大化的鲁棒或随机优化方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/643999/robust-or-stochastic-optimization-approach-for-maximizing-profit-with-limited-pr</link>
      <description><![CDATA[我正在解决一个线性最大化问题，在给定某些限制的情况下，我需要在几周内从多个选项中选择最佳产品，以便最大化未来利润。决策变量是二元的，指示是否选择特定产品。
目标函数表示为：
$$
\max_{j} \sum_{i} 选择(j) \cdot c_{i,j}^T p_{i,j}$$
地点：
$c_{i,j}$表示产品$j$在一周内的生产数量$i$,
$p_{i,j}$ 表示产品 $j$ 在一周内的价格 $i$,
$choice(j)$ 是一个二进制变量，指示产品 $j$ 的选择，以及求和整个星期$i$。
但是，我遇到了挑战，因为 $p_{i,j}$ 并不完全已知。这是一个时间序列，我缺乏未来值以及广泛的历史数据。为了解决这个问题，我正在考虑稳健优化或随机优化技术。在这种情况下我应该采取哪种方法？如何有效实施以实现利润最大化？]]></description>
      <guid>https://stats.stackexchange.com/questions/643999/robust-or-stochastic-optimization-approach-for-maximizing-profit-with-limited-pr</guid>
      <pubDate>Mon, 01 Apr 2024 02:01:06 GMT</pubDate>
    </item>
    <item>
      <title>指数 $p$ 上有哪些条件使得 $\underset{\mu}{\arg\min}\left\{\mathbb E\left\vert X-\mu\right\vert^p\right\} $ 必须存在吗？</title>
      <link>https://stats.stackexchange.com/questions/643991/what-conditions-are-there-on-the-exponent-p-such-that-underset-mu-arg-min</link>
      <description><![CDATA[令 $X\sim F(x)$ 为由分布函数 $F 定义的（单变量）随机变量$。如果期望值存在，则等于 $
\mathbb E[X] = \underset{\mu}{\arg\min}\left\{\mathbb E\left\vert X-\mu\right\vert^2\right\}
$.
但是，期望值不一定存在。
指数 $p$ 上有哪些条件使得 $ \underset{\mu}{\arg\ min}\left\{\mathbb E\left\vert X-\mu\right\vert^p\right\}
$ 必须存在吗？在它必须存在之前我们必须达到多低？如果 $p=0$ 并获取 $\arg\min$ 的中位数作为 $p=1$。 $p=1.5$ 或 $1.9$ 或 $1.99 怎么样？ $？
我想知道 $2$ 是否是 $p$ 的最高值，但不在集合中保证 $\arg\min$，并且任何 $p&lt;2$ 必须有一个定义的$\arg\min$。如果有关于独特性的有趣评论，我会同意深入那个兔子洞。
我的灵感来自这里，我想知道链接问题的合理答案是否是降低&lt; span class=&quot;math-container&quot;&gt;$p$ 直到 $\arg\min$ 必须存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/643991/what-conditions-are-there-on-the-exponent-p-such-that-underset-mu-arg-min</guid>
      <pubDate>Sun, 31 Mar 2024 22:56:27 GMT</pubDate>
    </item>
    </channel>
</rss>