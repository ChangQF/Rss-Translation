<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 07 Apr 2024 15:13:41 GMT</lastBuildDate>
    <item>
      <title>在没有 X_test 的情况下预测 RNN 和 LSTM</title>
      <link>https://stats.stackexchange.com/questions/644499/forecasting-rnn-and-lstm-without-x-test</link>
      <description><![CDATA[亲爱的 StackExchange 社区，
我的数据仅由 1 个时间序列变量（资产的股票价格）组成
我已将其拆分为训练和测试子集。
我已经使用 X_train 和 Y_train 训练了 RNN 和 LSTM 模型。
我使用的资源（书籍、课程和博客）建议使用 X_test 进行预测。 RMSE 预测好得令人难以置信。我想这是因为我使用与 Y_test 相同的数据集（X_test）进行预测。
您建议我使用什么书、课程、博客来预测未来价值而不使用 X_test。（我认为多步前进？）
最诚挚的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/644499/forecasting-rnn-and-lstm-without-x-test</guid>
      <pubDate>Sun, 07 Apr 2024 14:43:58 GMT</pubDate>
    </item>
    <item>
      <title>帮助计算 PLS 检测限</title>
      <link>https://stats.stackexchange.com/questions/644497/help-with-calculation-of-pls-limit-of-detection</link>
      <description><![CDATA[我正在尝试根据 Allegrini 和 Olivieri 论文（[https://pubs.acs.org/doi/epdf/10.1021/ac501786u]）计算 PLS 模型检测上限和下限，但不知道如何这样做（对我来说太数学解释了）。
如何解方程 12 和 13？我究竟需要向其中输入什么？
编辑：添加论文中的屏幕截图

公式 12 和 13：


SEN参数：


var(x) 是仪器信号的方差

h0min 和 h0max 参数：


]]></description>
      <guid>https://stats.stackexchange.com/questions/644497/help-with-calculation-of-pls-limit-of-detection</guid>
      <pubDate>Sun, 07 Apr 2024 14:26:35 GMT</pubDate>
    </item>
    <item>
      <title>动量 SGD：特征值 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</link>
      <description><![CDATA[我正在阅读《动量如何真正发挥作用》一文（https://distill.pub/2017/momentum/），我很困惑点：

我正在尝试从以下方程推导出动量的收敛速度：

&lt;块引用&gt;
$\min_{\alpha, \beta}\max\lbrace \parallel \begin{pmatrix}
\beta &amp; \lambda_1 \\
-\alpha\beta &amp; 1-\alpha\lambda_1
\end{pmatrix} \parallel, ..., \parallel \begin{pmatrix}
\beta &amp; \lambda_n \\
-\alpha\beta &amp; 1-\alpha\lambda_n
\end{pmatrix} \并行\rbrace$

$\parallel\parallel$ 这里表示最大特征值的大小，当对极值对应的矩阵重复特征多项式的根时出现特征值。所以我们知道 R 的特征值：
$\sigma_i =\frac{1}{2}(1-\alpha\lambda+\beta\pm\sqrt{(-\alpha\lambda+\beta+1) ^2-4\测试版})$
但不知何故，我不知道如何在这里进行代数。首先，我想知道等于特征值是否正确（一个用 $\lambda_1$ 表示，另一个用 $\lambda_n$) 然后你需要找到 alpha 和 beta 的解决方案？然后我真的不知道该应用哪种技巧来使代数用 alfa 来写？]]></description>
      <guid>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</guid>
      <pubDate>Sun, 07 Apr 2024 10:08:17 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>了解样本量计算中的名义 p 值</title>
      <link>https://stats.stackexchange.com/questions/644496/understanding-of-nominal-p-values-in-sample-size-calculation</link>
      <description><![CDATA[我需要你的帮助来理解 R 输出。在此示例中，计划了两次中期分析。调整后的 p 值如下所示。但是，我仍然不清楚名义 p 值的含义。这些是未调整的值吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644496/understanding-of-nominal-p-values-in-sample-size-calculation</guid>
      <pubDate>Sun, 07 Apr 2024 08:17:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 mlexperiments 和 mllrnrs 对多变量 lightgbm 机器学习模型进行交叉验证</title>
      <link>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</link>
      <description><![CDATA[我尝试使用轻型 GBM 模型来拟合多元时间序列。为了构建模型，我使用 mlexperiments 和 mllrnrs。

使用 timetk 和 Sample 分割时间序列

 分割 &lt;- 生产 %&gt;%time_series_split(date_var = newdate,assess=&quot;4 个月&quot;,cumulative = TRUE)
训练 &lt;- rsample::training(splits)%&gt;% select(-newdate)
测试 &lt;- rsample::testing(splits)%&gt;% select(-newdate)


创建时间序列折叠

fold_list&lt;- splitTools::create_timefolds(y = unlist(train_y),k = 5L, use_names = T, type =c (“扩展”))


设置参数和参数网格

#必需的学习者参数，未优化
learner_args &lt;- 列表(
  最大深度=-1L，
  详细 = -1L，
  目标=“回归”，
  公制＝“l2”
）

为mlexperiments::MLCrossValidation 和mlexperiments::MLNestedCV 所需的预测函数和性能指标设置参数
predict_args &lt;- NULL
Performance_metric &lt;- metric(“rmse”)
Performance_metric_args &lt;- NULL
return_models &lt;- TRUE

网格搜索所需
parameter_grid &lt;- Expand.grid(
  bagging_fraction = seq(0.6, 0.8, .2),
  特征分数 = seq(0.6, 0.8, .2),
  min_data_in_leaf = seq(20, 40, 4),
  学习率 = seq(0.1, 0.2, 0.1),
  num_leaves = seq(2, 20, 4))

optim_args &lt;- 列表（
  iters.n = ncores,
  卡帕 = 3.5，
  acq=“ucb”；
）


调整模型

 调谐器 &lt;- mlexperiments::MLTuneParameters$new(
  学习者 = mllrnrs::LearnerLightgbm$new(
        metric_optimization_higher_better = FALSE)，策略 = “网格”，ncores = ncores，seed = 种子)

    调谐器$parameter_grid &lt;-parameter_grid
调谐器$learner_args &lt;- learner_args
调谐器$set_data(x = train_x,y = train_y)
tuner_results_grid &lt;-tuner$执行(k = 3)

在此之前我可以完美地运行代码。
但是当我开始进行交叉验证时
验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器$parameter_grid &lt;-parameter_grid
&gt;验证器$learner_args &lt;- learner_args
&gt; validator$split_type &lt;- &quot;分层&quot;
&gt;验证器$predict_args &lt;-predict_args
&gt;验证器$performance_metric &lt;- Performance_metric
&gt;验证器$performance_metric_args &lt;- Performance_metric_args
&gt;验证器$return_models &lt;- return_models
&gt;验证器$set_data(
+ x = 火车_x,
+ y = 火车_y
+)
&gt; validator_results &lt;- validator$execute()

我收到一个错误
&lt;块引用&gt;
CV 折叠：kdry::mlh_subset(private$x, train_index) 中的 Fold1 错误：
ids 必须是整数

当我检查验证器环境时，我发现......
我的代码中的以下行
fold_list = Fold_list

不工作。 mlexperiment 和 mllrns 尚未准备好接受时间序列分割输出，每次折叠都有样本内和样本外。
如何解决这个问题。为什么 mlexperiment 和 mllrns 不支持时间序列分割？]]></description>
      <guid>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</guid>
      <pubDate>Sun, 07 Apr 2024 06:57:48 GMT</pubDate>
    </item>
    <item>
      <title>估计 2 个随机变量的商 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</link>
      <description><![CDATA[我是一名数学家，统计学知识为零。那么问题来了
假设我有 3 个随机变量，$X$（噪声图像的像素矩阵），$Y$ （去噪未知图像的像素矩阵），$Z$（高斯噪声的像素矩阵），通过$$X=Y.Z$$
实际上，$X$ 数据是已知的，由特定审查员收集。审查器具有未知的噪声特征，由 $Z$ 表示。 $Z$ 的均值和方差已知，我们可以做出合理的假设 $Z$ 独立于 $X$ 和 $Y$。
估计 $Y$ 的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</guid>
      <pubDate>Sun, 07 Apr 2024 06:48:46 GMT</pubDate>
    </item>
    <item>
      <title>每个分类因素还是所有分类因素的对比？</title>
      <link>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</link>
      <description><![CDATA[我有以下模型：
Cmic_mg_cm2 ~ 组*样本日期 +mean_ph +mean_shan_veg +mean_tree_shandiv + (1|图)
group 和sample_date 都是分类因子变量
我用它来检查以下问题：
对于给定的样本日期，各组之间是否存在差异？
给定组的样本日期之间是否存在差异？
协变量是否有影响？
该模型纯粹用于推断，而不是用于预测 - 包含随机效应来处理采样的伪复制。
当检查与 R emmeans 包的对比时，可以选择检查所有配对，仅检查“组”。对并且仅“sample_date”对。我的问题是，哪个更有效，因为当然将所有对组合起来会导致更多的多次测试，因此在对此进行调整时会受到更高的惩罚。]]></description>
      <guid>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</guid>
      <pubDate>Sun, 07 Apr 2024 05:34:52 GMT</pubDate>
    </item>
    <item>
      <title>标准化基于树的模型或逻辑回归的特征</title>
      <link>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</link>
      <description><![CDATA[我试图了解是否应该标准化所有模型的功能以及何时这样做有意义。
下面的说法正确吗？如果是的话，请您稍微解释一下。
逻辑回归和基于树的算法（例如决策树、随机森林和梯度提升）对变量的大小不敏感。因此在拟合此类模型之前不需要标准化。
在上面的此链接中找到。&lt; /p&gt;
这是否意味着异常值不会影响基于树的算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</guid>
      <pubDate>Sun, 07 Apr 2024 00:13:52 GMT</pubDate>
    </item>
    <item>
      <title>解释流行病学模型的泊松 GAM</title>
      <link>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</link>
      <description><![CDATA[我正在开展一个项目，调查 PM2.5（一种污染形式）与缺血性中风住院治疗（即每天收集的住院总人数）之间的关系。我的模型如下所示，结果图也是如此：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_model &lt;- gam(行程 ~ s(PM2.5) +
        因素（地区）+
        ns(日期, df= 7) +
        偏移量（日志（人口）），
                 数据=区域数据，
                 家庭=泊松（链接=“日志”））

绘图（gam_model，trans = exp，xlab =“PM2.5”，ylab =“相对风险”，rug = TRUE）


因为我想根据相对风险（相对于零基线 PM2.5 水平）来解释模型，所以我设置了 trans = exp。然而，我不明白如何解释结果，该结果表明，PM2.5 时，因缺血性中风住院的相对风险较低 $\approx 20$ 比 0 低。我犯错了吗？
如果这是一个愚蠢的问题，我很抱歉，我对这一切都很陌生。]]></description>
      <guid>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</guid>
      <pubDate>Sat, 06 Apr 2024 22:31:38 GMT</pubDate>
    </item>
    <item>
      <title>用配对数据比较两组</title>
      <link>https://stats.stackexchange.com/questions/644471/compairing-two-groups-with-paired-data</link>
      <description><![CDATA[我有两组样本：健康组和患病组。每个人都接受了 X 治疗。所以，我有一个健康的基线和健康的 X 治疗。对于疾病组也是如此。分析它们的最佳方法是什么？如果我使用单向方差分析，它只会测量平均值。但它没有考虑到它们是成对测量。健康组确实有变化，但均值较低；因此，它不被认为是重要的。如果我进行配对 T 检验，我可以了解每组对治疗的反应，但无法比较健康与疾病。希望你能帮助我。]]></description>
      <guid>https://stats.stackexchange.com/questions/644471/compairing-two-groups-with-paired-data</guid>
      <pubDate>Sat, 06 Apr 2024 20:51:29 GMT</pubDate>
    </item>
    <item>
      <title>三个连续变量 + 2 个因素与五个连续变量来控制混杂因素？</title>
      <link>https://stats.stackexchange.com/questions/644438/three-continous-variables-2-factors-vs-five-continous-variables-to-control-fo</link>
      <description><![CDATA[我正在尝试理解我的硕士论文的设计。
我正在研究三种不同类型的游戏与儿童焦虑的关系。因此，我有三个连续的自变量，以每种类型花费的时间来衡量，而且我还有两个可能对焦虑产生影响的潜在混杂因素，我想解释它们也是连续的（量表上的分数）。
什么是最好的设计来解释我感兴趣的三个自变量的个体影响，同时平衡两个混杂因素的影响？运行多元回归来显示五个自变量中每一个的单独贡献是否会有帮助？或者，我也许可以对两个混杂变量进行分层，并将所有参与者分配到两个因素的不同级别，这样我的设计将有两个因素和三个连续变量可供查看，这似乎过于复杂。请在这里就可能的方法提出建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644438/three-continous-variables-2-factors-vs-five-continous-variables-to-control-fo</guid>
      <pubDate>Sat, 06 Apr 2024 11:24:21 GMT</pubDate>
    </item>
    <item>
      <title>SEM 有 50% 缺失数据（由于项目在各种调查选票/浪潮中的分布）</title>
      <link>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</link>
      <description><![CDATA[我想使用一般社会调查中调查的主要分类变量来测试多级中介（特别是测试关于社会阶级对右翼威权主义影响的可能中介因素的一些假设），为此，我将喜欢使用结构方程模型。但是，由于缺少数据，我对其可行性表示怀疑。
事实上，没有一个参与者拥有我想要包含的所有变量的数据，因为每个项目都是在不同的浪潮或选票中提出的。例如，我有一个项目仅在选票 A 和 B 中询问，第二个项目仅在选票 B 和 C 中出现，第三个项目在选票 A 和 C 中出现。因为我正在处理分类数据，所以我正在考虑Mplus 中的 WLSMV，使用成对删除。理论上，我可以绘制一个协方差矩阵，因为每个变量都与一次或另一次选票中的所有其他变量同时出现。对于每对变量（因此对于我需要的每个协方差），我至少有 900 名参与者（尽管总共有超过 10,000 名参与者）。因此，直观上，使用成对删除对我来说似乎不是很有问题，因为大多数缺失应该是 MCAR（它们是由某些选票/模块管理中的随机化造成的）——也许除了一些没有被询问的变量之外特别是年份/波浪。然而，当我读到这篇文章时，通常建议当缺失超过 10% 时（我远远超过了这里的阈值），成对删除是不合理的。
是否有一种处理缺失的方法可以让我估计这个模型，即使每个受访者都有大约 50% 的变量随机缺失数据？或者在我的情况下使用 SEM 不可行/不建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</guid>
      <pubDate>Fri, 05 Apr 2024 19:08:50 GMT</pubDate>
    </item>
    <item>
      <title>被测角度半角余弦不确定度的测定</title>
      <link>https://stats.stackexchange.com/questions/644407/determination-of-the-uncertainty-of-the-cosine-of-the-half-angle-of-a-measured-a</link>
      <description><![CDATA[当测量的角度为$\beta$容器&quot;&gt;$2\beta$。如果 $2\beta$ 测量的不确定度为 1 度，则 $\beta$ 的不确定度为 1 度span&gt; 二分之一度？]]></description>
      <guid>https://stats.stackexchange.com/questions/644407/determination-of-the-uncertainty-of-the-cosine-of-the-half-angle-of-a-measured-a</guid>
      <pubDate>Fri, 05 Apr 2024 17:06:26 GMT</pubDate>
    </item>
    <item>
      <title>如何比较从不等长的时间序列获得的AR(1)模型系数？</title>
      <link>https://stats.stackexchange.com/questions/644393/how-compare-ar1-models-coefficients-obtained-from-time-series-with-unequal-le</link>
      <description><![CDATA[假设我有两个时间序列，$\{X\}_{t}$ 和 $\{Y \}_{t}$ 长度显着不同，$n$ 和 $m$ 分别观察 ($n&gt;m$)。我想估计以下 AR(1) 模型：
$$X_{t}=\alpha_0+\alpha_1X_{t-1}+\epsilon_t,$$
$$Y_{t}=\beta_0+\beta_1X_{t-1}+\eta_t.$$
接下来，我需要比较 $\hat{\alpha_1}$ 和 $\hat{\beta_1 }$ 系数。然而，这并不“公平”。直接和明确地比较估计参数，因为观察数量显着不同（并且这种类型的时间序列可以显示相当大的峰值，并且短时间序列无法反映相对于较长时间序列的这种峰值 - 较长的历史意味着更高的机会时间序列中存在大峰值）。
问题：有没有办法制作 $\hat{\alpha_1}$ 和 $\hat{\beta_1}$ 通过控制观察之间的差异更具可比性？我突然想到要比较 $\frac{\hat{\alpha_1}}{n}$ 和 $\frac{\hat{\beta_1}}{m}$，但不确定这是否有意义。此外， $\hat{\alpha_1}$ 和 $\hat{\beta_1}$ 的大小为不重要。唯一重要的是哪个系数更大。这意味着转换系数是完全合法的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644393/how-compare-ar1-models-coefficients-obtained-from-time-series-with-unequal-le</guid>
      <pubDate>Fri, 05 Apr 2024 12:28:00 GMT</pubDate>
    </item>
    </channel>
</rss>