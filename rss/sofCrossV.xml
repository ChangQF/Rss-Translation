<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 Jan 2025 06:23:15 GMT</lastBuildDate>
    <item>
      <title>使用 Baum-Welch 进行 HMM 学习</title>
      <link>https://stats.stackexchange.com/questions/660753/hmm-learning-with-baum-welch</link>
      <description><![CDATA[我正在尝试从头开始为 HMM 学习实现 Baum-Welch 算法，我有两个问题：

我读到过，可以将数值优化应用于算法以减少运算次数，具体方法是消除期望最大化步骤中的分母。我相信这可以通过归纳法来证明，但我不确定如何正式处理它。有人可以提供一些见解或为我指出这方面的严格参考吗？

为了解决算法中的数值下溢，我们可以使用基于对数的计算或缩放。我的理解是前者速度较慢，但​​仍仅用于向后兼容。对数方法还有其他优势吗？会比缩放更受青睐吗？


提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660753/hmm-learning-with-baum-welch</guid>
      <pubDate>Thu, 30 Jan 2025 05:53:36 GMT</pubDate>
    </item>
    <item>
      <title>PCA 中的标准化与非标准化：它如何影响聚类结果？</title>
      <link>https://stats.stackexchange.com/questions/660752/standardization-vs-non-standardization-in-pca-how-does-it-affect-clustering-re</link>
      <description><![CDATA[我正在研究聚类，有一个问题，即在应用 PCA 之前是否要对数据进行标准化。当我不进行标准化时，轮廓得分为 47.5，而当我进行标准化时，它为 34。我还注意到，在标准化之前，百分比最高的特征向量来自具有最大值的变量。此外，当根据聚类查看多变量箱线图时，我可以观察到低幅度变量之间的更多差异。但是，当我进行标准化时，这些变量之间的差异变得不那么明显。即使变量的百分比范围相同，但有些变量的变异性比其他变量高得多。您能帮助我了解在这种情况下标准化是否必要以及标准化如何影响聚类结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660752/standardization-vs-non-standardization-in-pca-how-does-it-affect-clustering-re</guid>
      <pubDate>Thu, 30 Jan 2025 05:32:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来选择岭回归参数 $k$：如果 $\mathbf x_i$ 和 $y_i$ 的平均值在测试/训练集上可能为非零怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</link>
      <description><![CDATA[考虑一个回归模型$$ Y= X\beta+ u.\tag{$\star$} $$
$Y$是一个长度为$n$的列向量，包含$n$个观测值。
$X$是一个$n\times p$矩阵，每行对应一个观测值，每列对应一个特征。
$\beta$是回归系数。
$u$是一个长度为$n$的列向量，包含误差。
对于参数为 $k&gt;0$ 的岭回归，$\beta$ 的估计值为 $$\hat\beta= (X^TX +kI)X^TY .$$
我知道正则化参数 $k$ 的选择可以通过交叉验证来选择，例如论文 变量选择与数据增强之间的关系以及预测方法。
我的问题是，假设我们使用十倍交叉验证，数据集的子集为 $S_1,\cdots, S_{10}$。
$(\star)$ 的右侧没有均值项 $\mu$ 的原因是数据 $X,Y$ 被标准化为具有零均值。
但是当应用交叉验证时（例如，使用 $S_{10}$ 进行测试，使用其他数据进行训练），
则 $\cup_{i=1}^9 S_i$ 中的 $\mathbf x_i$ 和 $y_i$ 的均值可能不为零。
$S_{10}$ 中的 $\mathbf x_i$ 和 $y_i$ 的平均值也可能为非零。
那么我们如何仍然使用公式 $$\hat\beta= (X^TX +kI)X^TY$$ 来计算 $\cup_{i=1}^9 S_i$ 上的 $\hat\beta$，以及使用 $$ \sum\nolimits_{(\mathbf x_i, y_i)\in S_{10}} \|y_i- \langle \hat\beta, \mathbf x_i \rangle\|^2 $$
作为测试集 $S_{10}$ 上的误差？
我认为均值项 $\mu$ 也应该考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</guid>
      <pubDate>Thu, 30 Jan 2025 04:05:46 GMT</pubDate>
    </item>
    <item>
      <title>这是生态谬误吗？</title>
      <link>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</link>
      <description><![CDATA[
使用历史数据，我有一个模型，它根据一些个人特征/协变量告诉我单个单位在某个 $t$ 后存活的概率：

$$\hat{S}_j(t) = [\hat{S}_0(t)]^{\exp(x_j^{new^T}\hat{\beta})}$$

现在，$n$ 个新单位进来，我只有它们的预测因子（与之前相同的预测因子），即它们都还活着。
一般来说，每天要花费 $j$ 美元来维持这些 $n$ 个单位活着。
一旦单位不再活着，就不会产生任何相关成本。此外，单位死亡也不会产生任何相关成本。

我想估算一下这些 $n$ 单位明年会花多少钱。我正在尝试推导成本函数
使用预期值，我为每个新单元和所有新单元定义了一个预期成本函数（如果需要，我可以展示我的工作）：
$$E[\text{Cost}_i] = j\int_0^T tf_i(t)dt + jTS_i(T)$$
$$E[\text{Total Cost}] = \sum_{i=1}^n \left(j\int_0^T tf_i(t)dt + jTS_i(T)\right)$$
我不禁想到，我使用旧模型来估计新数据的成本，可能会陷入类似生态谬误的东西。这是因为我实际上是在为每个单独的单元恢复单独的生存函数，这可能会导致非常不稳定的预测。
例如，我认为如果我的历史模型非常简单（例如，仅包含 A 类与 B 类的预测变量），那么我可以使用这个旧模型来预测新数据中所有 A 类和所有 B 类的预期成本（即所有 A 类单元的单一生存曲线和所有 B 类单元的单一生存曲线……然后通过将它们相加来估算成本）。旧模型将看到有关 A 类与 B 类的成本和时间的足够数据，因此可以更好地推断到新数据。
但如果我开始在历史模型中包含更多变量，我感觉我会开始将自己归类，历史模型将变得更适合仅提供对历史数据的推断，而不太适合新数据。
这是正确的想法吗？我是否陷入了生态谬误，或者我的做法是否正确？
我个人的观点是，我需要进行一些探索性数据分析，看看旧数据与新数据的相似程度，然后决定历史模型是否适合新数据……但这不是一种明确的方法，我也不确定如何客观地做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</guid>
      <pubDate>Thu, 30 Jan 2025 03:44:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中为不规则测量的功能数据制作功能箱线图？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660744/how-to-make-a-functional-boxplot-in-r-for-irregularly-measured-functional-data</link>
      <description><![CDATA[我有一个重复测量数值结果，其中结果是在不同时间点为每个患者测量的。
函数箱线图是可视化此类数据的一种方法，其中阴影区域表示曲线的中间 50% 以及第 10 和第 90 百分位数曲线（或您想要的任何百分位数）。
如何在 R 中为不规则测量的数据（即在每个患者的不同时间点测量结果）制作函数箱线图？我找到了一些 R 函数，但它们似乎要求在同一时间点对所有患者测量结果：

https://rdrr.io/cran/fda/man/fbplot.html

源论文：https://www.tandfonline.com/doi/abs/10.1198/jcgs.2011.09224


https://rdrr.io/cran/rainbow/man/fboxplot.html

来源论文：https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.08158



一种方法是将数据插入/归纳到一个共同的时间点网格中。但是，我不确定最好的方法是什么。
以下是一些您可以使用的示例数据：
# 设置可重复性的种子
set.seed(42)

# 患者人数
n_patients &lt;- 100

# 创建一个列表来存储每个患者的时间点和结果
time_points_list &lt;- list()
outcome_list &lt;- list()

# 为每个患者生成数据
for (i in 1:n_patients) {
# 每个患者的时间点的随机数（介于 5 和 10 之间）
n_time_points &lt;- sample(5:10, 1)

# 生成介于 0 和 1 之间的随机时间点（不规则时间点）
time_points &lt;- sort(runif(n_time_points, 0, 1))

# 生成结果数据（例如，带有随机噪声的正弦数据）
outcomes &lt;- sin(2 * pi * time_points) + rnorm(n_time_points, sd = 0.1) # 带有噪声的一些结果

# 将时间点和结果存储在列表中
time_points_list[[i]] &lt;- time_points
outcome_list[[i]] &lt;- results
}

# 现在，组装数据框，调整不同数量的时间点
patient_id &lt;- rep(1:n_patients, times = sapply(time_points_list, length)) # 按时间点数重复每个患者 ID
time_point &lt;- unlist(time_points_list) # 取消列出所有患者的时间点
outcome &lt;- unlist(outcome_list) # 取消列出所有患者的结果

# 将数据合并到数据框中
patient_data &lt;- data.frame(
patient_id =patient_id,
time_point =time_point,
outcome =outcome
)

# 查看数据集的前几行
head(patient_data)

``` 
]]></description>
      <guid>https://stats.stackexchange.com/questions/660744/how-to-make-a-functional-boxplot-in-r-for-irregularly-measured-functional-data</guid>
      <pubDate>Wed, 29 Jan 2025 23:15:30 GMT</pubDate>
    </item>
    <item>
      <title>赔率加倍和赔率之间有什么关系</title>
      <link>https://stats.stackexchange.com/questions/660741/what-is-the-relationship-between-doubling-your-chances-in-odds</link>
      <description><![CDATA[我正在向学生介绍赔率，我想展示概率和赔率之间的区别
我举的例子是一个游戏，如果你抛出公平的硬币并且至少有一个正面，你就赢了。我们可以通过抛 $n$ 枚硬币来增加获胜的机会。
$$
P(\text{Winning}) = 1 - \textrm{Binomial}(n = n, k = 0, p = .5)
$$



n
$P(\text{Winning})$
赔率




1
.5
1:1


2
.75
3:1


3
.875
7:1


4
.9375
15:1



我想向学生们展示从这个例子中可以清楚地看出，即使你抛两枚硬币，获胜的机会也不会翻倍。
我想讨论一下随着硬币数量的增加，赔率是如何变化的，并将其转化为我们如何看待外行人所说的“加倍我们的机会”。
$$
Odds_{n+1} = 2* Odds_{n} + 1
$$
当我们有 1 枚硬币到 2 枚硬币时，我们获胜的机会就会翻倍，也就是大约翻倍我们的赔率。额外的硬币会继续使我们的赔率翻倍。
但是当我们有 2 枚硬币到 4 枚硬币时，我们的机会就会翻倍，但这不会导致赔率翻倍。我可能遗漏了更高的关系，无法将赔率转化为增加我们获胜机会的想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660741/what-is-the-relationship-between-doubling-your-chances-in-odds</guid>
      <pubDate>Wed, 29 Jan 2025 21:36:07 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用稀疏分析来估计捕获样本方差所需的最小样本量吗</title>
      <link>https://stats.stackexchange.com/questions/660738/can-i-use-rarefaction-analysis-to-estimate-the-minimum-sample-size-needed-to-cap</link>
      <description><![CDATA[在生态学中，稀疏分析可用于估计发现种群中所有物种所需的最小样本量。我想知道这是否可用于估计捕获种群特定参数方差所需的最小样本量。
假设我有一个包含 100 个数据点的样本（假设这是种群）。要生成稀疏曲线，我可以将样本量从 1 增加到 100。在每个样本量 n 下，我可以从原始样本中随机生成 10000 个样本（大小 = n），并计算这 10000 个样本的平均方差。然后绘制平均方差与样本量的关系。我的问题是：似乎无论我有什么样的原始样本，覆盖 95% 种群方差所需的样本量总是相同的：大约 16 个样本。这对我来说似乎有点奇怪。
我的稀疏曲线代码：
sample_size = data.shape[0]

data_n_variance = [] #初始化列表以存储不同样本大小下该特定参数测量值的平均方差

#为 10000 次引导生成随机种子以实现可重复性
rng = np.random.RandomState(seed=42)
seed_list = rng.choice(10000, size=10000, replace=True)

for i in range(1, sample_size+1):
subsample_i_variance = [] #初始化列表以存储特定样本大小下 10000 个随机生成的子样本的方差

for j in range(10000):
rng = np.random.RandomState(seed=seed_list[j])
subsample = rng.choice(data, size=i, replace=False)
subsample_i_variance.append(np.var(subsample))

data_n_variance.append(sum(subsample_i_variance)/10000)

用于确定最小样本量的代码
for i in range(1, sample_size+1):
if data_n_variance[i] &gt; 0.95*data_n_variance[-1]:
print(i)
break

我尝试模拟两个不同的原始样本，最小样本量相同
正态分布：
data = np.random.normal(loc=100, scale=10, size=100)

双峰分布：
data1 = np.random.poisson(lam=1, size=60)
data2 = np.random.normal(loc=1000, scale=100, size=40)
data = np.concatenate((data1, data2))

我也尝试使用样本方差而不是总体方差（N-1 vs. N）来计算方差，但在这种情况下，稀疏曲线不再是增长曲线（先增加然后稳定）]]></description>
      <guid>https://stats.stackexchange.com/questions/660738/can-i-use-rarefaction-analysis-to-estimate-the-minimum-sample-size-needed-to-cap</guid>
      <pubDate>Wed, 29 Jan 2025 20:47:42 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，拟合残差与回归量正交</title>
      <link>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</link>
      <description><![CDATA[我正在研究伍尔德里奇的《计量经济学分析》中的回归问题。回归量被视为随机的。他说，最小二乘估计一致性的一个基本假设是“总体正交性条件”（“假设 OLS.1”），即
$$
E(x&#39;u)=0。
$$
此处的线性模型为$y = \beta&#39;x + u$，其中$u$是误差项的符号，prime 表示矩阵转置。
我的问题是，在此模型下，通过最小二乘估计获得的拟合残差$\hat u$是否与回归量$x$不相关，即$E(x&#39;\hat u)=0$。]]></description>
      <guid>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</guid>
      <pubDate>Wed, 29 Jan 2025 20:13:21 GMT</pubDate>
    </item>
    <item>
      <title>根据列联表计算两种评级方法之间的差异度量</title>
      <link>https://stats.stackexchange.com/questions/660736/compute-a-measure-of-difference-between-two-rating-methods-from-contingency-tabl</link>
      <description><![CDATA[四位评分员 A、B、C、D 将 10 条记录分为 3 类 a、b、c；请参阅下面代码中的 tb1。
这与 Gwet, K. L. (2014) 中的表 2.26 类似。评分员间信度手册：衡量评分员之间一致性程度的权威指南（第 4 版）。马里兰州盖瑟斯堡：高级分析。
它给出 Fleiss&#39; kappa=0.47。
在第二个但独立的评分程序中，盲测的相同评分员生成 tb2，其中 a 和 b 被交换。正如预期的那样，它给出了相同的 kappa，即使除了未交换的 c 之外评级不同。
当我使用 Kwet 的 t 检验时，这两个被认为是相等的，因为 kappa 的值是。这不是我想要的，因为 tb2 不同。
如何计算来自两个原始表的两种方法之间的这种成对比较的差异度量？
library(irrCAC)
if (!exists(&quot;ttest.fleiss&quot;))
source(&quot;https://www.agreestat.com/software/r/new/paired.ttest.r&quot;)

tb1 = structure(
list(
record = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
A = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;),
B = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;),
C = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;),
D = c(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;)
),
class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;),
row.names = c(NA, -10L)
)

print(tb1)
#&gt; 记录 A B C D
#&gt; 1 1 b b b a
#&gt; 2 2 b b b b
#&gt; 3 3 b b b b
#&gt; 4 4 b b a b
#&gt; 5 5 b b b c
#&gt; 6 6 a b a a
#&gt; 7 7 a a a a
#&gt; 8 8 c c a b
#&gt; 9 9 c c c b
#&gt; 10 10 c c c c

tb2 = 结构（
列表（
记录 = c（1、2、3、4、5、6、7、8、9、10），
A = c（“a”，“a”，“a”，“a”，“a”，“a”，“b”，“b”，“c”，“c”，“c”，“c”），
B = c（“a”，“a”，“a”，“a”，“a”，“a”，“a”，“a”，“b”，“c”，“c”，“c”），
C = c（“a”， &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;),
D = c(&quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;)
),
class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;),
row.names = c(NA, -10L)
)

# 不含 &quot;record&quot;列

cat(&quot;____\nTable 1\n&quot;)
#&gt; ____
#&gt; 表 1
fleiss.kappa.raw(tb1[,-1])$est[-8]
#&gt; coeff.name pa pe coeff.val coeff.se conf.int p.value
#&gt; 1 Fleiss&#39; Kappa 0.6666667 0.375 0.46667 0.15881 (0.107,0.826) 0.0165266

cat(&quot;____\nTable 2\n&quot;)
#&gt; ____
#&gt; 表 2
fleiss.kappa.raw(tb2[,-1])$est[-8]
#&gt; coeff.name pa pe coeff.val coeff.se conf.int p.value
#&gt; 1 Fleiss&#39; Kappa 0.6666667 0.375 0.46667 0.15881 (0.107,0.826) 0.0165266

ttest.fleiss(tb1[,-1], tb2[,-1])
#&gt; 配对 T 检验用于检验 2 个 Fleiss 一致性系数之间的差异
#&gt; --------------------------------------------------------------------------------
#&gt; Fleiss Kappa 系数：（组 1：0.4666667）--（组 2：0.4666667）
#&gt; 差异的标准误差：0
#&gt;测试统计量：T= NaN 
#&gt; P 值：NaN

我注意到这类似于
比较不同类别的评分者之间的评分者间一致性
主要区别在于原始帖子提到了“专家”和“非专家”，但我有一个完全配对的设计，在两种情况下都是相同的评分者。]]></description>
      <guid>https://stats.stackexchange.com/questions/660736/compute-a-measure-of-difference-between-two-rating-methods-from-contingency-tabl</guid>
      <pubDate>Wed, 29 Jan 2025 18:27:46 GMT</pubDate>
    </item>
    <item>
      <title>干预后测试群体的相似性 - 收敛还是方差？</title>
      <link>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</link>
      <description><![CDATA[我感兴趣的是测试一个群体在干预后是否变得更加相似。例如，假设我有一个连续变量干预前后的分数列表，该连续变量被合理地假设为正常。我感兴趣的是看看在经历这次干预后，这个群体是否变得更加相似。我不需要知道他们的平均值是否发生了变化，但我认为我需要了解的是他们的变异是如何变化的。（因此，如果我预期的结果已经实现，那么干预后该群体的方差就会减小，这表明该群体在结果变量上已经在某种程度上趋向于相似的分数）。
我最初的想法是 (1) 通过将参与者视为“评估者”并查看干预后的 ICC 是否比干预前更高来建立某种类间相关性。或者，(2) 方差分析来检验两组之间的差异。
与本论坛的许多人相比，我的统计知识相对有限 - 因此，如果您能提供任何链接或参考资料，以便我可以进一步阅读建议的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</guid>
      <pubDate>Wed, 29 Jan 2025 16:08:10 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中 ELBO 推导的澄清</title>
      <link>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</link>
      <description><![CDATA[我正在阅读一篇关于去噪扩散模型的论文，第 10 页有以下 ELBO 推导。
$$
\begin{aligned}
\log p(\mathbf{x}_0) &amp;= \log \int p(\mathbf{x}_{0:T}) \, d\mathbf{x}_{1:T} \\
&amp;= \log \int \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} q(\mathbf{x}_{1:T} | \mathbf{x}_0) \, d\mathbf{x}_{1:T} \\
&amp;= \log \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;\geq \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^{T} p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)}{\prod_{t=1}^{T} q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right]
\end{aligned}
$$
我只是想澄清一下几件事。$x_0$ 是随机变量 $X_0$ 的实现吗？如果是，$q(x_{0:T})$ 是否意味着 $x_0$ 是实现，而其余的 $x_{1:T}$ 是随机变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</guid>
      <pubDate>Wed, 29 Jan 2025 11:54:19 GMT</pubDate>
    </item>
    <item>
      <title>非参数方法检查观测值是否与平均值不同</title>
      <link>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</link>
      <description><![CDATA[我有一个随机变量的独立观测列表，我想检查这个变量的平均值是否与某个固定数字不同。我该怎么做？
分布不一定是正态的，甚至不是对称的。
有人建议我使用置换检验，但阅读更多内容后，我明白它是用来比较两个分布，而不是一个分布和一个固定数字。虽然我可以说另一个分布是固定的，但这不会有问题吗，因为方差当然是不同的？我的意思是，我想知道这个测试是否可以发现方差而不是平均值的差异，这不是我想要的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</guid>
      <pubDate>Wed, 29 Jan 2025 10:39:34 GMT</pubDate>
    </item>
    <item>
      <title>比较偏好与 3 个价值观（包括中性）的差异</title>
      <link>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</link>
      <description><![CDATA[比较包括中性在内的 3 个值的偏好差异
场景：分析具有 3 个值的偏好数据（例如：您更喜欢哪个：足球、棒球还是没有偏好（即中性）？）
主要研究问题：

是否大于中性？
足球比棒球更受欢迎还是反之亦然？

奇怪的是，与连续数据不同，我没有看到很多关于这种情况的强烈建议。
我的问题是：
哪种统计数据最适合分析具有 3 个值（例如足球、中性、棒球）的偏好数据？
如果答案依赖于“弥补”预期值（例如，将响应分为 3 个值（33%，33%，33%），那么您建议使用什么值（或它们的计算）？（注意：我不喜欢 33%，33%，33%，因为不喜欢任何一个与喜欢其中一个的结果不同（参见上述主要研究问题）。
其他注意事项：
只是指出它不是因子设计（就像我们比较 2 个成功率，例如球队 1 的胜/负与球队 2 的胜/负），所以我们不能通过“平均”足球和棒球的成功来计算预期值。
我的数据集中的响应数量可能非常低。在一个例子中，当足球 = 12 和棒球 = 13 时，卡方显着。
McNemar 检验：Sauro/MeasuringU 推荐此检验。虽然它适用于名义变量，它采用 2x2 形式，并带有成对样本（重复测量）。因此，他的建议似乎适用于其他场景。
我考虑过的选项：
选项 A1 - 中性预期 = 观察值
首先，目测（或置信区间）中性和足球/棒球之间的差异。
其次，将中性预期值设置为等于观察值。将剩余的预期值分为足球和棒球（50/50 分割）以“删除”中性，但保持样本量。 （例如，见图片）



偏好
观察到的
预期的




足球
36
(58/2) =29


中立
42
42


棒球
22
(58/2) =29



一个问题似乎是统计数据本身，因为尝试解释它确实很棘手。就像，“在消除中性反应的影响后，参与者对足球和棒球的偏好不同（或没有不同）。”
选项 A2。中性与其他以及中性预期 = 观察到
除了上面的第一步，要么 (A2a) 取足球和棒球中较大的一个，(A2b) 将足球和棒球加在一起，看看它们加起来是否不同于中性，或者 (A2c) 取足球和棒球的平均值，看看该平均值是否不同于中性。一个问题是 A2a、A2b 和 A2c 的可解释性是……它们很难解释和/或需要大量语言来解释。然后使用上面的第二步。因此，可解释性问题与 A1 相同。
选项 B1 - 置信区间与预期值的重叠[不完整的解决方案]
计算置信区间并与预期值进行比较。与上述问题相同：如何计算对 3 个值有意义的预期值（我认为 33,33,33 不是）。那么预期值是什么？
选项 B2 - 置信区间与 3 个观察值的重叠
类似于使用置信区间来目测连续数据之间的差异
选项 C。您的建议！
想法、意见、建议？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</guid>
      <pubDate>Wed, 29 Jan 2025 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>具有 beta geom 分布分位数函数的 CDF</title>
      <link>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</link>
      <description><![CDATA[我有一个带 CDF 的 beta 几何 (BG) 分布：
$$F(x) = \Bigg( 1 - \frac{\text{B}(a,b+x)}{\text{B}(a,b)} \Bigg)
\quad \quad \quad 
\text{for } x \geqslant 0,$$
其中 $\text{B}$ 是 beta 函数。有没有办法在不借助数值方法和求根算法的情况下找到上述分布的分位数。我知道 beta 分布与 F 分布相关，我正在尝试看看我们是否可以找到与 BG 分布的类似关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</guid>
      <pubDate>Tue, 28 Jan 2025 20:03:16 GMT</pubDate>
    </item>
    </channel>
</rss>