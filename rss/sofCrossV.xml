<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Apr 2024 06:18:57 GMT</lastBuildDate>
    <item>
      <title>如何测量功率检验的标准差</title>
      <link>https://stats.stackexchange.com/questions/646154/how-to-measure-standard-deviation-for-a-power-test</link>
      <description><![CDATA[我有一个“太笨了，我很尴尬”的想法关于计算能力的问题。
假设一篇论文告诉我，在“表 1”中，$y$ 的标准差是 0.8。然后它报告 $y$ 的效果大小为 0.2，$N$ 为 100每个治疗组和对照组。
现在我的假设是我可以运行，例如在 R 中：
power.t.test(n = 100, delta = 0.2, sd = 0.8)

并发现
&lt;前&gt;&lt;代码&gt;功率 = 0.4204383

但是，这是正确的标准差吗？因为两组的标准差包含了两组之间的差异，即效应大小本身。这似乎有些奇怪。当我模拟这样的情况时，我的本能是这样做：
y &lt;- rnorm(200, sd = 0.8)
y[1:100] &lt;- y + 0.2
组&lt;-rep(c(“治疗”，“对照”)，每个= 100)
lm(y ~ 组)

但在这里我创建了一个标准变量，其 sd 为 0.8 但不包括效果大小本身。所以这不一样，对吧？
我很困惑，尽管我感觉这在某种程度上确实是一个愚蠢的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/646154/how-to-measure-standard-deviation-for-a-power-test</guid>
      <pubDate>Tue, 30 Apr 2024 05:27:44 GMT</pubDate>
    </item>
    <item>
      <title>使用事件发生时间作为协变量</title>
      <link>https://stats.stackexchange.com/questions/646153/using-time-to-event-as-a-covariate</link>
      <description><![CDATA[处理右删失生存终点的技术已经很成熟。
如果我有兴趣使用右删失生存时间作为协变量而不是响应怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/646153/using-time-to-event-as-a-covariate</guid>
      <pubDate>Tue, 30 Apr 2024 05:20:05 GMT</pubDate>
    </item>
    <item>
      <title>glm.fit 中的权重参数是什么？</title>
      <link>https://stats.stackexchange.com/questions/646150/what-is-the-weights-argument-in-glm-fit</link>
      <description><![CDATA[我真的不明白glm.fit中的weights参数是什么。您能给我一个非常简单的例子，让我知道如何解释它并知道它是如何工作的吗？
如果您认为这真的超出了我的知识范围，请向我推荐您认为可能有用的其他文章或视频。
我尝试阅读一些文章（例如，下面的文章），但我仍然不明白
https://www.r-bloggers.com/2023/12/conquering-unequal-variance-with-weighted-least-squares-in-r-a-practical-guide/
估计加权数据的分布
如何找到加权最小二乘回归分析的权重？
https://www.youtube.com/watch?v=Ghs69kGWwAA
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646150/what-is-the-weights-argument-in-glm-fit</guid>
      <pubDate>Tue, 30 Apr 2024 04:51:34 GMT</pubDate>
    </item>
    <item>
      <title>具有演化方程的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/646149/state-space-models-with-evolution-equations</link>
      <description><![CDATA[是否有 R 包可以使用演化方程对状态空间模型进行建模？一个例子是依赖于来自先验和进化方程的某些参数的变量。
如果有，是否有相关例子？]]></description>
      <guid>https://stats.stackexchange.com/questions/646149/state-space-models-with-evolution-equations</guid>
      <pubDate>Tue, 30 Apr 2024 03:56:06 GMT</pubDate>
    </item>
    <item>
      <title>高度不平衡安全数据的二元分类器实现了较高的 ROC AUC 和 Recall，但 Precision、F1 和 PR AUC 较差</title>
      <link>https://stats.stackexchange.com/questions/646148/binary-classifier-for-highly-imbalanced-security-data-achieves-high-roc-auc-and</link>
      <description><![CDATA[我正在开发一个二元分类器，用于从高度不平衡的安全日志中预测可疑活动，少数类与多数类的比例为1:50。
应用了几种处理类不平衡问题的技术，例如用于过采样的SMOTE和用于对数据进行欠采样的NeighbourhoodCleaningRule +随机欠采样。我已经使用常见的 ML 算法、RF、KNN、LR、NB、SVM 进行了测试，并使用 imblearn 库中的 BalancedRandomForestClassifier 进行了测试，该算法给出了最佳结果。
问题是我获得了大约 0.92 的高 ROC_AUC 分数，召回率 0.8-0.9。其他指标，F1、精度和PR_AUC分数确实很差，分别为0.3、0.18 和大约 0.3-0.5 分别。
我的混淆矩阵如下所示（类别 0 - 11082，类别 1 - 502）：
TN 9010 | 457 | TP FP 45 | FN 2072
这是我的问题：

重采样后建议少数群体与多数群体的比例是多少？
PR_AUC 得分为 0.5 是否表明模型较差？
这些分数实际上很差吗？您有什么建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/646148/binary-classifier-for-highly-imbalanced-security-data-achieves-high-roc-auc-and</guid>
      <pubDate>Tue, 30 Apr 2024 03:26:59 GMT</pubDate>
    </item>
    <item>
      <title>如何合并标准误差</title>
      <link>https://stats.stackexchange.com/questions/646147/how-to-combine-standard-errors</link>
      <description><![CDATA[我无法理解一个非常简单的概念。如果我只给出（独立）平均值 A、B 和 C 及其相关的标准误差和样本大小，目的是估计 D = A + B + C，我如何计算标准误差的 D?它真的就像标准误差平方求和一样简单（就像计算标准差一样），还是标准误差更复杂？]]></description>
      <guid>https://stats.stackexchange.com/questions/646147/how-to-combine-standard-errors</guid>
      <pubDate>Tue, 30 Apr 2024 02:41:27 GMT</pubDate>
    </item>
    <item>
      <title>DDPM 中的反向分布</title>
      <link>https://stats.stackexchange.com/questions/646146/reverse-distribution-in-ddpms</link>
      <description><![CDATA[在去噪扩散概率模型中，我们希望反转前向过程，将高斯噪声混合到数据点 $\mathbf{x}_0$ 经过 $T$ 个步骤。应用于输入 $\mathbf{x}_{t-1}$ 的每个前向步骤的结果根据 $q(\mathbf{x}_t | \mathbf{x}_{t-1})$，逆向按照 $q(\ mathbf{x}_{t-1} | \mathbf{x}_t)$。每个步骤根据步长 $\beta_t$ 混合高斯噪声，以便：
$q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_T; \ sqrt{1 - \beta_t}\mathbf{x}_{t-1}; \beta_T\mathbf{I})$

在迪克斯坦和Ho 论文和一些其他在线处理方法，反向过程被建模为高斯，因为（来自 Dickstein，它引用了 Feller 1949):
&lt;块引用&gt;
由于 $q(\mathbf{x}_t|\mathbf{x}_{t−1})$ 是高斯（二项式）分布，并且如果 $\beta_t$ 很小，则 $q(\mathbf{x}_{t-1}|\mathbf {x}_{t})$ 也将是高斯（二项式）分布。

但是，条件概率 $q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)$ 可以通过将贝叶斯规则应用于前向过程分布来证明是高斯分布，而不需要对步长进行假设 $\beta_t$&lt; /span&gt; （请参阅此博文中的公式 53）。通过总概率，我们可以将 $q(\mathbf{x}_{t-1} | \mathbf{x}_t)$ 计算为以上的总和我们数据集中的所有样本$\mathbf{x}_0$，并且独立高斯的总和是高斯的。
那么当我们断言反向步长是高斯分布时，我们真的需要参考步长吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646146/reverse-distribution-in-ddpms</guid>
      <pubDate>Tue, 30 Apr 2024 02:35:27 GMT</pubDate>
    </item>
    <item>
      <title>如果我的函数具有可分离的函数结构，是否可以利用有效的采样技术？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/646145/are-there-efficient-sampling-techniques-to-leverage-if-my-function-has-a-seperab</link>
      <description><![CDATA[我正在通过贝叶斯方法考虑参数模型的后验。更具体地说，我有一个参数模型 $u(p_1,p_2, p_3) = u_1(p_1) \times u_2(p_2) \times u_3(p_3)$ 和我想研究给定一些数据 $\mathbf{p}= \{p_1, p_2, p_3\}$ 的后验分布 $\mathcal {D}$。因此贝叶斯公式返回：
$$p(\mathbf{p}|D) = \frac{p(D|\mathbf{p})\times p(\mathbf{p})} {\text{证据}}.$$
假设我之前的 $p(\mathbf{p})$ 可以写成 $p(p_1) \ times p(p_2) \times p(p_3)$，我的似然函数是以模型输出为中心的高斯函数：$$p(D|\mathbf{ p}) = \mathcal{N}(u(\mathbf{p}),\sigma^2)$$
是否有有效的采样技术来利用可分离的结构
$$u(p_1,p_2, p_3) = u_1(p_1) \times u_2(p_2) \times u_3(p_3)$$
这是一个例子。假设每个维度有 5 个采样点，总共有 125 个点。
如果 $u(p_1,p_2, p_3)$
是不可分离的，我们可能必须遍历 3 维空间中的每个数据点。这对于高维情况来说可能具有挑战性。然而，如果 $u(p_1,p_2, p_3)$ 可分离，我们可以只遍历每个一维域，然后使用张量积来计算 ue 到变量的分离，我们可以使用张量积来计算u(p1,p2,p3)]]></description>
      <guid>https://stats.stackexchange.com/questions/646145/are-there-efficient-sampling-techniques-to-leverage-if-my-function-has-a-seperab</guid>
      <pubDate>Tue, 30 Apr 2024 02:08:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAM 进行热点映射</title>
      <link>https://stats.stackexchange.com/questions/646144/using-gam-for-hotspot-mapping</link>
      <description><![CDATA[我要以此作为序言，我不是广义加性模型或空间统计专家......我知道的足够“危险”......也许这是一件坏事😉
今天，我在思考热点映射时进行了一些思想实验。我最近深入研究了时空广义加性模型 (GAM) 世界，并且一直想知道是否可以使用 GAM 框架来识别热点。一般来说，在空间统计中，热点被定义为值大于平均值的区域。通常，这是使用 Getis-Ord Gi 统计量来执行的，该统计量通常是修改后的 z 分数，以考虑空间网络中的最近邻居距离。 Getis-Ord 统计数据还可用于识别冷点（值小于平均值）。
如果我们有一个像这样的通用 GAM 模型
yi ~ s(yr) + s(x,y) + ti(x,y,yr)

其中我们有时间 (yr)、位置 (x,y) 以及位置和时间之间的交互项 (x,y,yr)，以评估空间和时间的变化。给定此模型，位置效应图显示了数据在空间上的变化情况。这不能用来识别（统计上）显着大于或小于平均值（或某个缩放值）的位置吗？我知道当尝试从 GAM 检测时间序列中的重大变化时，您需要使用导数来确定它是否与 0 显着不同（...我认为）基于 辛普森博士的帖子。是否必须对 s(x,y) 项执行类似的操作？
&lt;小时/&gt;
这里是一些基本的 R 代码，其中包含一个可重现的示例，可以让事情顺利进行。在代码中，有一个部分包含 Getis-Ord Gi 统计计算。代码的 GAM 部分相对较短，因为我不确定下一个最佳步骤是什么...如效果图中所示，有一些负区域和正区域与 Getis-Ord 统计数据非常接近。
## 空间数据/分析
库（光栅）
图书馆（SF）
库（spdep）
库（spatstat）

## 首选 GAM 魔法
库（mgcv）
图书馆（谢谢）

## 制作一些数据
## https://www.r-bloggers.com/2020/02/spatial-predictions-with-gams-and-rasters/

rbase &lt;- 栅格（范围（c（0,1,0,1）），nrow = 50，ncol = 50）
rx1 &lt;- rx2 &lt;- rbase
rx1[] &lt;- xFromCell(rbase, 1:ncell(rbase))
rx2[] &lt;- yFromCell(rbase, 1:ncell(rbase))
rtrue &lt;- 6*rx1 - 7*rx1^2- 4*rx2
par(mfrow = c(2,2))
绘图（rx1，col = RColorBrewer::brewer.pal（11，“RdBu”），main =“x1”）
绘图（rx2，col = RColorBrewer::brewer.pal（11，“RdBu”），main =“x2”）
情节（rtrue，col = RColorBrewer ::brewer.pal（11，“RdBu”），main =“真实值”）

设置.种子(42)
site_means &lt;- data.frame(x = runif(50), y = runif(50)) |&gt;;
  突变（站点= 1:50，
         x1 = 提取(rx1, cbind(x,y)),
         x2 = 提取(rx2, cbind(x,y)),
         eta = 提取(rtrue, cbind(x,y)),
         z = rnorm(50，sd = 1)，
         yhat = eta + z)

dat &lt;- merge(site_means,expand.grid(site = 1:50, yr = 1:5),“site”)|&gt;
  变异（b = rnorm（250，平均值 = yhat，sd = 0.5））
dat$b&lt;-dat$b+5 #（添加 5 以获得正值......我知道我可以做一个 rlnorm）

## Getis Ord 分析
## 参考 https://swampthingecology.org/blog/hot-spot-analysis-geospatial-data-analysis-in-rstats.-part-3/
# 将数据转换为空间点数据类型
# spstats 包需要空间数据来进行最近邻分析

p.sf &lt;- st_as_sf(dat, 坐标 = c(“y”, “x”), crs = 4326)

# 求距离范围
ptdist=点距离(p.sf)

min.dist&lt;-min(ptdist); ＃ 最低限度
均值.dist&lt;-均值(ptdist); ＃ 意思是

nb&lt;-dnearneigh(st_坐标(p.sf),最小距离,平均距离)

nb_lw&lt;-nb2listw(nb,style=&quot;B&quot;)

## 全球地理标志
globalG.test(p.sf$b,nb_lw,alternative=“双面”)

# 本地G
nb_lw&lt;-nb2listw(nb)
local_g&lt;-localG(p.sf$b,nb_lw)

# 转换为矩阵
local_g=as.matrix(local_g)

# 列绑定 local_g 数据
p.sf&lt;-cbind(p.sf,local_g)

# 两侧 ρ 值
p.sf$pval&lt;- 2*pnorm(-abs(p.sf$local_g))

# 应该识别几个重要的热点（点）

## 简单的游戏
m1=gam(b~
         s(yr,k=5,bs=“tp”)+
         s(x,y,bs=“ds”)+
         ti(x,y,yr,d=c(2,1),bs=c(“ds”,“tp”)),
       数据=数据）
摘要(m1)

绘制(m1)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/646144/using-gam-for-hotspot-mapping</guid>
      <pubDate>Tue, 30 Apr 2024 01:41:07 GMT</pubDate>
    </item>
    <item>
      <title>泊松/二项分布有什么特别之处，以至于它们具有特殊的回归估计技术？</title>
      <link>https://stats.stackexchange.com/questions/646141/what-is-special-about-the-poisson-binomial-distributions-such-that-they-have-spe</link>
      <description><![CDATA[您可以使用最大似然估计来估计具有泊松或二项分布的随机变量的回归参数，但我没有听说过卡方回归或伽马函数分布。是什么让泊松和二项分布如此特别以至于拥有自己的回归技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/646141/what-is-special-about-the-poisson-binomial-distributions-such-that-they-have-spe</guid>
      <pubDate>Tue, 30 Apr 2024 00:25:56 GMT</pubDate>
    </item>
    <item>
      <title>流量匹配相对于整流流量有什么好处</title>
      <link>https://stats.stackexchange.com/questions/646140/whats-the-benefit-of-flow-matching-over-rectified-flow</link>
      <description><![CDATA[在 Tong 等人，2024 中，他们表明独立的 CFM（I-当设置 $\sigma = 0$ 时（CFM）相当于整流流（RF）（第 3.2.2 节）。在表 2 中，在许多情况下，I-CFM 似乎优于 RF。那么在路径中引入噪声$\sigma$有什么好处呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/646140/whats-the-benefit-of-flow-matching-over-rectified-flow</guid>
      <pubDate>Mon, 29 Apr 2024 23:13:59 GMT</pubDate>
    </item>
    <item>
      <title>多重比较汇总统计中的 I 类错误</title>
      <link>https://stats.stackexchange.com/questions/646135/type-i-error-in-multiple-comparisons-summary-statistics</link>
      <description><![CDATA[我知道如果我们运行“多重比较”，I 类错误可能会增加。但这是指多类别变量内的比较吗？或使用相同变量的多个（亚组）分析？在描述性统计中，我们通常对每个预测变量与结果进行单变量检验。这算不算多重比较？我们需要采取一些措施来控制 I 类错误吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/646135/type-i-error-in-multiple-comparisons-summary-statistics</guid>
      <pubDate>Mon, 29 Apr 2024 22:00:49 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 R 中使用 NMDS 执行分层分区？</title>
      <link>https://stats.stackexchange.com/questions/646132/is-there-a-way-to-perform-a-hierarchical-partitioning-with-nmds-in-r</link>
      <description><![CDATA[我对我的生态数据执行了非度量多维标度 (NMDS)，我对结果感到满意，但我被告知我应该在分析中使用分层分区来检查单个变量贡献，因为该方法考虑了生态变量中可能的自相关。我最终在 R 中使用了 rdacca.hp 包，它似乎可以满足我的需要。我对结果以及执行 rdacca.hp 后下一步该做什么感到犹豫。
我所做的是超过三年（2021-2023）的完整数据集的rdacca.hp。我知道年份很重要，因此我也对每年的数据再次执行rdacca.hp。与我的 NMDS 指示的重要变量相比，我在完整数据 rdacca.hp 结果中得到的结果通常不同。这让我不确定自己在做什么以及我是否在做正确的事情。
我没有可以咨询的统计学家，所以我想知道是否有人可以给我一些关于我所做的事情是否正确的建议或建议替代方案。
RDCCA 2021-2023 数据：
# Method_Type：“CCA” “adjR2”
# 总解释变量：0.066 (6.6%)

变量 唯一平均.份额 个体 I.perc(%)
jcollect 0.0042 0.0221 0.0263 39.85
时间.收集 -0.0018 0.0023 0.0005 0.76
时间.collr 0.0008 0.0019 0.0027 4.09
上午.下午 0.0012 -0.0007 0.0005 0.76
胸径.厘米 0.0038 -0.0026 0.0012 1.82
纵横比 -0.0076 0.0009 -0.0067 -10.15
年-0.0028 0.0043 0.0015 2.27
周 -0.0001 0.0034 0.0033 5
月 0.0006 0.0033 0.0039 5.91
温度收集 0.0025 -0.0013 0.0012 1.82
年.jcollect 0.0029 0.0259 0.0288 43.64
湿度估算 -0.0055 0.0047 -0.0008 -1.21
年周 -0.0008 0.0047 0.0039 5.91

去除一些稀有影响物种后，NMDS 在清理站点级（2021-2023）数据上的输出：
&lt;前&gt;&lt;代码&gt;***矢量
                    
    NMDS1 NMDS2 r2 Pr(&gt;r)
胸径.cm -0.32437 0.94593 0.026 0.059 .
温度收集 0.35088 -0.93642 0.0249 0.0664 。
湿度估算 -0.69403 0.71995 0.0388 0.0143 *
---
Signif.codes:0‘***’0.001‘**’0.01‘*’0.05‘.’0.1‘’1
排列：自由
排列数：9999
----------------
拟合优度：
    r2 Pr(&gt;r)
jcollect 0.398 0.0479 *
时间.收集 0.0654 0.0866 。
时间.collr 0.0186 0.095 。
上午.下午 0.007 0.2177
纵横比 0.0315 0.3145
年 0.0224 0.0484 *
周 0.0409 0.0087 **
月 0.0139 0.5923
年.jcollect 0.4841 0.0249 *
年周 0.1002 0.0075 **
---
Signif.codes:0‘***’0.001‘**’0.01‘*’0.05‘.’0.1‘’1
排列：自由
排列数：9999
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/646132/is-there-a-way-to-perform-a-hierarchical-partitioning-with-nmds-in-r</guid>
      <pubDate>Mon, 29 Apr 2024 21:27:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 Rao-Blackwell 改进 P(X/Y < t) 的估计量</title>
      <link>https://stats.stackexchange.com/questions/646111/using-rao-blackwell-to-improve-the-estimator-of-px-y-t</link>
      <description><![CDATA[X 和 Y 是独立的 N (0, 1) 个随机变量，我们想要近似 P (X/Y ≤ t)，对于固定数字 t。
问题的第一部分是描述朴素的蒙特卡罗估计。我描述过，您应该独立地获取 X 和 Y 的样本（大小均为 n），获取样本值的比率，然后找到该比率小于 t 的次数，并将其除以总样本大小 n。&lt; /p&gt;
下一部分是提出一种基于 Rao-Blackwellization 的更复杂的蒙特卡洛方法。我对如何做到这一点感到非常困惑，因为我们从未深入讨论过 Rao-Blackwell。我发现的所有例子都与这样的问题无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/646111/using-rao-blackwell-to-improve-the-estimator-of-px-y-t</guid>
      <pubDate>Mon, 29 Apr 2024 16:22:27 GMT</pubDate>
    </item>
    <item>
      <title>均值差 置信区间 重复测量方差分析</title>
      <link>https://stats.stackexchange.com/questions/646074/mean-difference-confidence-interval-repeated-measures-anova</link>
      <description><![CDATA[我在相同条件下对每个受试者进行 4 次重复测量（T1、T2、T3 和 T4），以计算重复性。我有 10 个科目。
报告重复测量方差分析（如重复性值）的事后均值差异 95% 置信区间是否正确？
T1-T2：CI95 MD = -1.1 | 2.3
T1-T3：...
T1-T4：...
T2-T3：...
T2-T4：...
T3-T4：...
例如，在此数据中，我们将确定在 95% 的情况下，差异将在 -1.1 和 2.3 之间，并且与我们的最大不确定性为 2.3 相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/646074/mean-difference-confidence-interval-repeated-measures-anova</guid>
      <pubDate>Mon, 29 Apr 2024 08:35:48 GMT</pubDate>
    </item>
    </channel>
</rss>