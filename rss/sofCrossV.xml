<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 29 Nov 2024 15:18:44 GMT</lastBuildDate>
    <item>
      <title>有没有办法按子组进行预测，而不用分别预测每个子组？</title>
      <link>https://stats.stackexchange.com/questions/658030/is-there-a-way-to-forecast-by-subgroup-without-forecasting-each-subgroup-separat</link>
      <description><![CDATA[我正在尝试找到一个合适的模型，根据之前的招聘周期和本周期迄今为止收到的申请数量来预测招聘周期结束时收到的申请数量 - 如果能够将最终预测细分为不同的子组（例如，我们预计有 1,000 份申请，其中 200 份申请该职位，其中 50 份来自该地区，其中 1 份拥有博士学位），这将非常有帮助。
我们当前数据中的子组数据非常好，但有些子组非常小（许多子组的申请人数少于 10 人），所以我不确定单独预测它们是否可靠（我相信大多数自回归模型都需要这样做）。
有没有一种方法可以做到这一点，既可靠又能产生准确的预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/658030/is-there-a-way-to-forecast-by-subgroup-without-forecasting-each-subgroup-separat</guid>
      <pubDate>Fri, 29 Nov 2024 13:01:38 GMT</pubDate>
    </item>
    <item>
      <title>原始协方差与多个 MCMC 链上均值的协方差之间的等价性</title>
      <link>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</guid>
      <pubDate>Fri, 29 Nov 2024 11:56:15 GMT</pubDate>
    </item>
    <item>
      <title>RWE：使用目标试验模拟框架：为什么要模拟 RCT？</title>
      <link>https://stats.stackexchange.com/questions/658027/rwe-use-of-target-trial-emulation-framework-why-aiming-to-emulate-rct</link>
      <description><![CDATA[Hernán 和 Robins [1] 于 2016 年引入了目标试验模拟框架，以定义观察性研究中感兴趣的问题。目标试验框架要求研究人员指定 RCT 方案的关键要素，这些要素理想情况下将用于解决感兴趣的问题。但是，如果无法模拟目标 RCT，那么因果问题就无法制定。为什么他们的目标是完全模拟 RCT？是因为在 RCT 中定义因果问题所需的假设较少吗？
[1] Hernán, M. A. 和 Robins, J. M. (2016)，“当无法进行随机试验时使用大数据模拟目标试验”，美国流行病学杂志，183，758–764。]]></description>
      <guid>https://stats.stackexchange.com/questions/658027/rwe-use-of-target-trial-emulation-framework-why-aiming-to-emulate-rct</guid>
      <pubDate>Fri, 29 Nov 2024 11:51:32 GMT</pubDate>
    </item>
    <item>
      <title>如何为多元荟萃分析假设两种精神疾病之间的协方差 (rho)</title>
      <link>https://stats.stackexchange.com/questions/658022/how-can-i-assume-covariance-rho-between-two-psychiatric-disorders-for-multivar</link>
      <description><![CDATA[我想进行多变量荟萃分析，因为每个研究都有几种效应大小。例如，我想调查品行障碍 (CD) 和对立违抗性障碍 (ODD) 对物质使用障碍（包括酒精使用障碍 [AUD] 和药物使用障碍 [DUD]）的风险（比值比）。例如，
研究 A 研究了 AUD 上的 ODD 风险、DUD 上的 ODD 风险、AUD 上的 ODD 风险和 DUD 上的 CD 风险。
研究 B 研究了 AUD 上的 ODD/CD 风险和 DUD 上的 ODD/CD 风险（因此不是 ODD 和 CD 的两种不同测量方法，而是合二为一）
研究 C 研究了 AUD/DUD 上的 ODD 风险和 AUD/DUD 上的 CD 风险
通过多变量荟萃分析，我可以控制预测因子（ODD 和 CD）和结果（物质使用障碍）的相关结构，因为它考虑了嵌套结构。问题是我必须假设构造之间存在协方差，以便正确校正相关结构。个别研究未报告此协方差。
我如何假设足够的协方差？有关于例如 ODD 和 CD 之间遗传相关性的文献，我应该使用这种遗传相关性作为协方差吗？
或者，只要使用稳健方差估计，在不考虑协方差矩阵的情况下进行多元荟萃分析是否有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/658022/how-can-i-assume-covariance-rho-between-two-psychiatric-disorders-for-multivar</guid>
      <pubDate>Fri, 29 Nov 2024 09:44:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验给出不直观的结果？</title>
      <link>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-is-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据在 R 中如下所示：
 a &lt;- c(66,97, 48)
b &lt;- c(145,174,58)
c &lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异：
X-squared = 8.6905, df = 4, p-value = 0.06932

但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[, 1:2]
X-squared = 6.0153, df = 2, p-value = 0.04941

数据：M3[, c(1, 3)]
X-squared = 5.2093，df = 2，p 值 = 0.07393

我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大。但我不确定是否以及如何解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-is-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 $\beta$ 系数对模型中的特征进行优先级排序</title>
      <link>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</link>
      <description><![CDATA[我想知道 - 如果您有一个模型，它为您提供了每个变量的 $\beta$ 估计值，但没有 p 值，那么如何优先考虑对结果影响更大的变量？
请注意，我不希望集中和缩放所有变量，我有不同性质的数据，这些数据已进行了相应的标准化。
对于连续变量，我正在考虑考虑系数 &lt;​​span class=&quot;math-container&quot;&gt;$\tilde{\beta}=\beta_X \cdot range(X)$ 或 $\tilde{\beta}=\beta_X \cdot sd(X)$，以消除变量范围与 $\beta$ 之间的高度依赖性估计。
对于分类变量，我考虑考虑$\beta$本身，因为它们不依赖于变量的范围。
这种方法正确吗？如果正确，如何客观地比较连续变量与分类变量的影响？
谢谢！
我的想法是进行特征选择，他们根据模型中的重要性提供了所选特征的列表。]]></description>
      <guid>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</guid>
      <pubDate>Fri, 29 Nov 2024 07:59:06 GMT</pubDate>
    </item>
    <item>
      <title>基于专家建议的在线二元决策的下限</title>
      <link>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</link>
      <description><![CDATA[假设我们想要根据 $k$ 位专家的建议，对 $n$ 个二元决策进行排序。我们根据从其处获得建议的最佳专家来定义遗憾。现在我想证明我们将至少享受 $\Omega(m)$ 个遗憾，其中 $m=\min \{n,\log k\}$。当 $n&gt;\log k$ 时，情况对我来说很清楚，但对于其他情况，我不知道该如何进行。]]></description>
      <guid>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</guid>
      <pubDate>Fri, 29 Nov 2024 07:51:02 GMT</pubDate>
    </item>
    <item>
      <title>带有插值数据的回归模型？</title>
      <link>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</link>
      <description><![CDATA[我有一个国家，里面有很多城市（层级结构：国家-省-城市）。我只有 2010 年和 2020 年每个城市的平均社会经济信息（例如就业率、中位数收入等）。
2016 年举行了选举。我知道从 2010 年到选举期间每个城市的政治倾向，以及选举后政治倾向的变化。
我想建立一个回归模型，研究社会经济条件的变化如何影响投票选择（我知道生态谬误，我只对研究总体趋势感兴趣，而不是将其推广到总体中的个人）。
如果我每年都有数据，我会尝试使用一些技术，例如差异差异或回归不连续性，以查看选举前后的情况。但是，就我而言，这不可用。
我对该怎么做有这个天真的想法。

我认为我可以创建一个基于增长率的插值回归模型。我首先假设每个社会经济变量有一个简单的纵向模型（假设它只依赖于自身而不依赖于其他因素，遵循单调/均匀变化的线性增长）：

$$ \frac{x_{i,2020} - x_{i,2010}}{x_{i,2010}} = \alpha_0 + u_{px} + v_{ix} + \epsilon_{ix} $$
其中：

$\alpha_0$ 是所有城市的平均增长率
$u_{px}$ 是各省与平均增长率的偏差
$v_{ix}$ 是城市与其所在省份增长率的偏差
$\epsilon_{ix}$ 是误差项

现在，对于 2010 年至 2020 年之间任何时间 $t$ 的插值，我们想要计算到时间 $t$ 时应该发生的总变化的百分比。公式变为：
$$ \hat{x}_{it} = x_{i,2010}\left(1 + \frac{t-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
例如具体计算：
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{2015-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{5}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}(1 + 0.5(\alpha_0 + u_{px} + v_{ix})) $$

从这里开始，我使用第 1 部分中的插值来创建一个模型，该模型研究城市在选举前/后如何改变其政治倾向（基于其选举前的倾向和第 1 部分中插值的社会经济预测因素）。我想用多项逻辑回归模型来做这件事：

$$ \log\left(\frac{P(Y_i = k)}{P(Y_i = K)}\right) = \beta_{0k} + \beta_{1k}j_i + \beta_{2k}\hat{x}_{i,2016} + \beta_{3k}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pk} $$
其中：

$Y_i$ 是城市 $i$
$k$ 代表各政党类别（参考类别 $K$ 除外）
$j_i$ 为城市 $i$ 的选举前政党归属
$\hat{x}_{i,2016}$ 和 $\hat{x}_{i,2016} - \hat{x}_{i,2015}$ 来自模型 1
$u_{pk}$ 为政党的省级随机效应 $u_{pk}$ class=&quot;math-container&quot;&gt;$k$

选举后，一个城市加入$k$政党的概率为：
$$ P(Y_i = k) = \frac{\exp(\beta_{0k} + \beta_{1k}j_i + \beta_{2k}\hat{x}_{i,2016} + \beta_{3k}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pk})}{\sum_{m=1}^K \exp(\beta_{0m} + \beta_{1m}j_i + \beta_{2m}\hat{x}_{i,2016} + \beta_{3m}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pm})} $$
我感觉我的建模方法简直是一场灾难，哈哈。插值值有误差，而第二步没有考虑到这一点。我确信这里存在很多问题。有人能告诉我我到底搞砸了多少吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</guid>
      <pubDate>Fri, 29 Nov 2024 05:34:47 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使用反向传播可以学习布尔公式吗？</title>
      <link>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</link>
      <description><![CDATA[我一直在研究神经网络和布尔公式。从我的努力来看，神经网络似乎通常无法使用反向传播来学习布尔公式。这在直觉上是有道理的，因为布尔公式的输出可以根据输入值表现出巨大的变化，因此会有很多不连续性，从而导致局部最优。
另一方面，我也明白，任何布尔公式都可以用神经网络来表示，根据通用近似定理，所以神经网络没有内在原因不能表示，因此可能学习任意的布尔公式。问题似乎出在学习算法上，所有通用的机器学习算法似乎都会陷入局部最优，无论我使用梯度下降、进化算法、期望最大化等，因为它们都基于局部增量改进是通向全局最优解的途径这一前提。
话虽如此，我也知道还有其他类型的算法，如 Quine-McCluskey 和 Espresso，它们可以从真值表中得出最小布尔公式。可以使用这些算法随后生成一个神经网络，该神经网络嵌入从真值表中得出的算法的最小布尔公式。或者，更简单，只需将真值表转换为神经网络。然而，据我所知，这些都是非常具体的算法，专门针对布尔公式，在更通用的机器学习环境中没有使用。
所以，这让我想到了我的问题。是否有任何证据表明神经网络能够或不能使用反向传播和梯度下降或任何其他通用机器学习算法来学习任意布尔公式？
我检查了 Cross Validated，并在 Google 上搜索了这个问题，但未能找到任何明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</guid>
      <pubDate>Thu, 28 Nov 2024 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>具有无限上限的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</link>
      <description><![CDATA[因此，我想尝试找到一个具有已知均值的未知分布的方差置信区间（n 非常大）。因此，我首先使用中心极限定理，使得均值为 $\mu$ 且方差为 $\sigma^2$ 的分布 X 具有
$\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \xrightarrow{D} N(0,1)$
现在，我们可以找到 1-$\alpha$ 置信区间，其中随机区间为：
$ \begin{align*}
Pr\left(-z_{\frac{\alpha}{2}}&lt;\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left|\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right|&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left(\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right)^2&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\frac{(\bar{X}-\mu)^2}{\frac{\sigma^2}{n}}&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(\frac{1}{z_{\frac{\alpha}{2}}^2}&lt;\frac{\frac{\sigma^2}{n}}{(\bar{X}-\mu)^2}&lt;\infty\right) &amp;= 1-\alpha \\
Pr\left(\frac{n(\bar{X}-\mu)^2}{z_{\frac{\alpha}{2}}^2}&lt;\sigma^2&lt;\infty\right) &amp;= 1-\alpha
\end{align*}$
因此，$\bar{x} = \frac{\sum_{i=1}^n x_i}{n}$，我们有一个 (1-$\alpha$) 置信区间，即 $\left(\frac{n(\bar{x}-\mu)^2}{z_{\frac{\alpha}{2}}^2}, \infty\right)$
这有什么问题吗？如果没有，我们可以为置信区间设置无限上限吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</guid>
      <pubDate>Wed, 27 Nov 2024 17:13:58 GMT</pubDate>
    </item>
    <item>
      <title>需要使用结束标记来使 Ngram 模型正确</title>
      <link>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</link>
      <description><![CDATA[标准二元模型（例如定义于此处）基于以下原则在语料库$V$上定义概率分布：

单词$w$的边际概率定义为其在$V$中的计数除以$V$中的单词总数（计算重复次数）：$P(w) = \text{count}(w) / |V|$
一个单词跟随另一个单词的条件概率直观地定义为二元组计数与第一个单词计数之比：$p(w_2|w_1) = \text{count}(w_1 w_2) / \text{count}(w_1)$
（马尔可夫假设）：一个句子（一个单词序列）的概率可以通过链式法则计算：$p(w_1 w_2 ... w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1 w_2)... \approx p(w_1) p(w_2|w_1) p(w_3|w_2) ...$

然而，这似乎并没有定义一个适当的概率分布。例如，取一个语料库 $V = \text{&quot;foo bar baz&quot;}$。然后，取所有可能的二元组上定义的联合分布 $w_1 w_2$。根据我们的原则：
\begin{equation}
p(w_1 w_2) = p(w_1) p(w_2|w_1) = [\text{count}(w_1) / 3][\text{count}(w_1 w_2) / \text{count}(w_1)]
\end{equation&gt;
如果 $w_1 w_2$ 不在语料库中，则显然 $p(w_1 w_2) = 0$。因此，联合分布中唯一非零的条目是 $p(\text{foo bar}) = p(\text{bar baz}) = 1/3$。这些的总和是$2/3 \neq 1$，那么这种分配是否不合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</guid>
      <pubDate>Wed, 27 Nov 2024 13:18:18 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>如何制作一个能够抵御数据不平衡变化的分类器？</title>
      <link>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</link>
      <description><![CDATA[我正在为通常非常不平衡的数据编写一个二元分类器，例如大多数类别中 99% 的数据（使用梯度提升），但我希望有一个分类器至少对不平衡的严重程度具有一定的鲁棒性。一个数据集与另一个数据集之间的不平衡率差异很大。A 类分数可能 &gt;99% 或低至 75%。理想情况下，我希望在单个训练集上训练我的分类器，然后让它在类别频率差异很大的测试集上表现得相当好。有没有既定的方法可以做到这一点？或者我只需要根据预期的不平衡程度为每个新数据集重新训练模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</guid>
      <pubDate>Tue, 26 Nov 2024 20:26:32 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的属性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 R 中具有交互项的多项式 Logit 模型中的缺失标准差、z 值和 p 值？</title>
      <link>https://stats.stackexchange.com/questions/657322/how-to-resolve-missing-std-error-z-value-and-p-value-in-multinomial-logit-mod</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657322/how-to-resolve-missing-std-error-z-value-and-p-value-in-multinomial-logit-mod</guid>
      <pubDate>Fri, 15 Nov 2024 15:13:32 GMT</pubDate>
    </item>
    </channel>
</rss>