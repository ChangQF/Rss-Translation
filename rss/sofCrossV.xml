<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 12:34:11 GMT</lastBuildDate>
    <item>
      <title>使用 CNN 自动编码器和格拉姆角场图像编码对时间序列数据进行异常检测</title>
      <link>https://stats.stackexchange.com/questions/656407/anomaly-detection-using-cnn-autoencoder-along-with-gramian-angular-field-image-e</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656407/anomaly-detection-using-cnn-autoencoder-along-with-gramian-angular-field-image-e</guid>
      <pubDate>Mon, 28 Oct 2024 11:19:00 GMT</pubDate>
    </item>
    <item>
      <title>了解负部分依赖值</title>
      <link>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</link>
      <description><![CDATA[负部分依赖值（例如随着输入的增加从 -0.7 变为 -0.5）对于参数来说意味着什么？
这是否意味着该参数与输出呈负相关，还是意味着预测通常低于平均值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</guid>
      <pubDate>Mon, 28 Oct 2024 10:08:51 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟具有 L1 和 L2 方差分量的多层预测变量？</title>
      <link>https://stats.stackexchange.com/questions/656404/how-to-simulate-a-multilevel-predictor-variable-with-both-l1-and-l2-variance-com</link>
      <description><![CDATA[我正在模拟多级数据，其中我有一个在级别 1 (L1) 上测量的预测变量，它同时具有 L1 和 L2 方差分量。例如，我想模拟在学校班级内以个人级别测量的社会经济地位 (SES) 变量。在多级模型中，我通常使用组均值中心化来分离此预测变量的组内 (L1) 和组间 (L2) 方差。
具体来说，我感兴趣的是模拟 L1 预测变量（例如，个人 SES）及其以组均值为中心的对应变量，以捕获组级 (L2) 方差。我的目标是创建以下数据：
反映 SES 的组内和组间变异性。
允许我使用多级建模方法来解开这些方差分量，类似于组均值中心化在实际数据中的工作方式。
我的问题是：
我该如何模拟具有 L1 和 L2 方差的 L1 预测变量？
我应该遵循哪些步骤来生成 L2 上的组均值中心版本？
这里是一篇关于类似问题的精彩帖子。
模拟 L1 预测器然后在 L2 上创建它的中心版本并不难。但是，在这种方法中，L1 没有真正的 L2 方差：
# 定义模拟参数
n_groups &lt;- 50 # 组数（级别 2）
n_individuals &lt;- 10 # 每组个体数（级别 1）
total_n &lt;- n_groups * n_individuals

# 定义方差
between_var &lt;- 1 # 组间方差
within_var &lt;- 0.5 # 组内方差

# 模拟每个组的随机截距（级别 2 随机效应）
group_effect &lt;- rnorm(n_groups, mean = 0, sd = sqrt(between_var))

# 创建一个数据框来存储模拟数据
data &lt;- data.frame(
group_id = rep(1:n_groups, each = n_individuals),
individual_id = 1:total_n
)

# 生成具有组内和组间变异性的 1 级预测因子 `x1ij`
data$x1ij &lt;- group_effect[data$group_id] + rnorm(total_n, mean = 0, sd = sqrt(within_var))

# 计算 `x1ij` 的组平均值（2 级组件）
data$x1j_mean &lt;- ave(data$x1ij, data$group_id, FUN = mean)

# 创建以组平均值为中心的 `x1ij` 版本
data$x1ij_centered &lt;- data$x1ij - data$x1j_mean

# 显示数据集的前几行
head(data)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656404/how-to-simulate-a-multilevel-predictor-variable-with-both-l1-and-l2-variance-com</guid>
      <pubDate>Mon, 28 Oct 2024 10:00:42 GMT</pubDate>
    </item>
    <item>
      <title>使用倾向评分时的假设</title>
      <link>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</link>
      <description><![CDATA[一位研究人员进行了倾向得分匹配分析，其中暴露的是性别（即男性与女性）。这并不是一个因果分析，结果仅以“关联”的形式描述 - 手稿中没有提到因果推断。
评论中提出，由于女性成为男性的可能性为零，反之亦然，因此阳性假设被违反。我想知道人们对此的看法，因为我认为，如果倾向得分匹配实际上被用作因果推断分析的一个步骤，那么从技术上讲这是正确的。但这里的情况并非如此 - 相反，其意图更像是一个数据缩减步骤。
我认为诸如阳性、可交换性等假设是因果推断的假设，而不是倾向得分本身的使用假设，对吗？还是我没抓住重点？ - 如果我是的话，我禁不住认为这是一个语义问题（即倾向得分实际上只是一个预测概率，人们通常只是假设在计算倾向得分时，会进行因果分析）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</guid>
      <pubDate>Mon, 28 Oct 2024 09:57:47 GMT</pubDate>
    </item>
    <item>
      <title>函数中是否存在一组紧凑的充分必要标准，可以保证梯度下降找到*全局*最小值？</title>
      <link>https://stats.stackexchange.com/questions/656402/is-there-a-compact-set-of-sufficient-and-necessary-criteria-a-function-can-have</link>
      <description><![CDATA[显然，我们需要所讨论的函数是可微的，这样这个概念才有意义。
现在，凸性是一个充分条件。（强）拟凸性是一个较弱的条件，但我认为仍然是充分条件。
但这两个条件都太强了。当你考虑高维空间时，会存在非常复杂、高度非凸的函数，其中梯度下降对于任何初始化总是收敛的。
例如，一个向下倾斜的地形，上面有一座山。（任何东西要么滚过山，要么滚下山，然后滚下地形）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656402/is-there-a-compact-set-of-sufficient-and-necessary-criteria-a-function-can-have</guid>
      <pubDate>Mon, 28 Oct 2024 09:46:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释子样本分析和交互作用分析得出的截然不同的结果</title>
      <link>https://stats.stackexchange.com/questions/656401/how-to-explain-the-totally-different-results-from-subsample-analysis-and-interac</link>
      <description><![CDATA[我正在运行面板数据回归。
主要独立变量 A 是治疗指标。还有另一个变量 B，可以将样本分为两个在线和离线观察。
在运行子样本分析时，A 对在线观察的影响不显著（col 5,6）。A 对离线观察的影响显著为负（col 7,8）。
然而，在运行 B 与 A 交互的回归时，在线观察的影响显著为负，而离线观察的影响显著为正（col 9,10）。
为什么结果会这样？
我知道辛普森悖论，但我似乎无法理解这种情况。
Ps。我使用的是双向固定效应模型。
这是我的结果的屏幕截图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/656401/how-to-explain-the-totally-different-results-from-subsample-analysis-and-interac</guid>
      <pubDate>Mon, 28 Oct 2024 09:33:08 GMT</pubDate>
    </item>
    <item>
      <title>如何解决多重假设检验问题？</title>
      <link>https://stats.stackexchange.com/questions/656399/how-to-solve-a-multiple-hypothesis-test-problem</link>
      <description><![CDATA[我们在进行多重假设检验时遇到了一个问题。我们有一个向量 $x$，当假设 H0 为真时，该向量中的分量服从标准正态分布。我们构建了三个卡方分布检验统计数据 $T_1$、$T_2$ 和 $T_3$，其中 $T_1=x^T(A-B)x$、$T_2=x^T(A-C)x$ 和 $T_3=x^T(A-D)x$。 $A$、$B$和$C$为半正定矩阵，秩分别为6、3、3。根据卡方分布的性质，$T_1$、$T_2$和$T_3$的自由度分别为6、3、3。四个假设定义如下

如果$T_1&lt;=Th_1$或（$T_1&gt;Th_1$ &amp; $T_2&lt;=Th_2$ &amp; $T_3&lt;=Th_3$），则假设$H_0$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&gt;Th_2$ &amp; $T_3&lt;=Th_3$，假设$H_1$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&lt;=Th_2$ &amp; $T_3&gt;Th_3$，假设$H_2$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&gt;Th_2$ &amp; $T_3&gt;Th_3$，假设 $H_3$ 为真。

I 类错误的概率定义为 $Pr(H_1 \cup H_2 \cup H_3 | H_0)$。这个问题的难点在于检验统计量 $T_1$、$T_2$ 和 $T_3$ 是相关的，因为它们“共享”项 $x^TAx$。此外，每个假设都涉及多个检验统计量
我们如何设置阈值$T_1$、$T_2$和$T_3$来控制 I 型错误的概率，使其等于显着性水平 α。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656399/how-to-solve-a-multiple-hypothesis-test-problem</guid>
      <pubDate>Mon, 28 Oct 2024 08:41:05 GMT</pubDate>
    </item>
    <item>
      <title>使用非参数检验时，要报告配对样本的哪些描述性统计数据？</title>
      <link>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</link>
      <description><![CDATA[我有两个变量，A 和 B（配对样本，前后），我需要进行配对样本非参数检验，因为 A 和 B 之间的差异分布不正常（配对值之间的差异的正态性假设不成立）。大约有 14 条记录。我的问题是：为了在表格中提供描述性统计数据，我是否应该提供 A 和 B 的中位数和 IQR，因为我们正在进行配对样本非参数检验，或者我应该首先分别检查每个变量的分布，如果它们遵循正态分布，则在表格中提供平均值和 SD 的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</guid>
      <pubDate>Mon, 28 Oct 2024 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>设置分布积分的界限</title>
      <link>https://stats.stackexchange.com/questions/656395/setting-bounds-on-distribution-integrals</link>
      <description><![CDATA[假设我有 3 个独立的概率分布，$P_X(x), 0 \leq x \leq 2$，$Q_Y(y), -1 \leq y \leq 0$，$R_Z(z), 0 \leq z \leq 1$，我想要找到 $X + Y &gt; \sqrt{2} Z$ 的概率。积分显然是$\int \int \int P_X(x) Q_Y(y) R_Z(z) dx dy dz$，但如何为积分本身设置界限呢？
如果有$\int^{0}_{-1} dy$和$\int^1_0 dz$，为了满足条件，最终积分应该是$\int^2_{\sqrt{2}z - y} dx$。但是，这没有意义，因为在 $z = 1$ 和 $y = -1$ 的情况下，您的 $x$ 积分界限不起作用。同样，如果您考虑到这一点，例如您只积分 $\int^{\sqrt{2}-2}_{-1} dy$，那么您并没有对 $Q_Y$ 的完整分布进行积分。
您究竟如何纠正这个问题？有没有办法完全避免它，例如尝试通过对分布求和来合并它们？提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656395/setting-bounds-on-distribution-integrals</guid>
      <pubDate>Mon, 28 Oct 2024 06:58:54 GMT</pubDate>
    </item>
    <item>
      <title>在拉普拉斯近似中近似 Hessian</title>
      <link>https://stats.stackexchange.com/questions/656384/approximating-the-hessian-in-laplaces-approximation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656384/approximating-the-hessian-in-laplaces-approximation</guid>
      <pubDate>Sun, 27 Oct 2024 18:15:17 GMT</pubDate>
    </item>
    <item>
      <title>将对数应用于指数和线性拟合[重复]</title>
      <link>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</link>
      <description><![CDATA[根据评论进行编辑。
我使用或不使用转换来拟合一些数据。
转换时，我会考虑误差传播。
在这两种情况下，我都使用 nls 并得到不同的结果。
代码如下：
# 清除环境
rm(list=ls())

# 生成 x 值、y 值以及 y 上的相应误差
x_values_exp &lt;- c(0.1, 0.2, 0.5, 1, 2, 3, 4) 
y_values_exp &lt;- c(9, 8.5, 7.5, 6.4, 5.2, 4.7, 4.5)
# 创建数据框
my_data &lt;- data.frame(x = x_values_exp, y = y_values_exp)

# 使用未知权重拟合非线性模型 (exp)
mod_exp &lt;- nls(y ~ A * exp(B * x), data = my_data, start = list(A = 1, B = 1))

# 估计 mod_exp 上的误差（因为我有 2 个参数，所以是 2）
residuals &lt;- residuals(mod_exp)
y_error_estimated &lt;- sqrt(sum(residuals^2)/(length(residuals)-2))
my_data$y_error_estimated &lt;- y_error_estimated

# 应用对数
y_lin &lt;- log(y_values_exp)
# 我必须计算 y 上的相应误差（使用误差传播）
y_lin_errors &lt;- y_error_estimated / y_values_exp
my_data$y_lin_errors &lt;- y_lin_errors

# 拟合线性模型（使用转换后的数据并考虑估计的误差）
mod_lin&lt;- nls(log(y) ~ A + B * x, data = my_data，start = list(A = 1, B = 1)，weights = 1/(y_lin_errors^2))

# 打印
log( coef(mod_exp)[1]) # log
coef(mod_lin)[1] # lin

结果如下：
&gt; log( coef(mod_exp)[1]) # log
A 
2.151668 
&gt; coef(mod_lin)[1] # lin
A 
2.154402 
]]></description>
      <guid>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</guid>
      <pubDate>Sun, 27 Oct 2024 11:52:18 GMT</pubDate>
    </item>
    <item>
      <title>变分推理描述的难解性问题中的混淆[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</link>
      <description><![CDATA[（已在 reddit 上发布）
我阅读 VAE 论文 已经有一段时间了，并且查阅了各种资料，以便对指定的难解性问题有清晰的了解。然而，在试图理解它时，我仍然面临很多困惑。我会解释，但这里只是一些符号，以确保我们的观点一致：

z - 维度为 M 的潜在变量
Z - 表示潜在变量集 z 的随机变量
x - 输入变量（比如说图像）
X - 输入图像数据集

目标是了解潜在空间 Z 的分布，以便从该空间采样时，可以使用某个函数 f(z)（神经网络）生成新的数据点 x&#39;，该函数也属于 P(X) 的输入分布。因此，问题建模如下：

P(Z|X) = P(Z) * P(X|Z) / P(X)

然后，作者声称 P(Z|X) 是难解的，因为 P(X) 是难解的。从高层次上讲，我想了解整体公式的难解性方面：

为什么 P(Z) 在这里不可解？事实上，P(Z) 甚至都不知道，那么为什么它不被认为是难解的？
我假设，P(X|Z) 可以通过应用 f(Z) 来计算，因此如果 P(Z) 是可解的，那么 P(X|Z) 也可以被认为是可解的。这个假设正确吗？
为什么 P(X) 是难解的？假设 X 类似于输入数据集，该数据集具有足够的样本，大致代表实际分布（假设数据集是 0 到 9 的数字的二进制图像，每个数字有 100 个样本），为什么不能简单地将 P(X) 视为每个单独像素的二项分布？
此外，为什么 P(X) 在这里甚至值得关注？就像它不是一个可以假设为整个 P(Z|X) 常数的标准化因子吗？

我相信我之所以有这些疑问，是因为我无法非常清楚地理解基本问题或基本目标，并且以不同的方式理解问题，如果由于我缺乏理解而导致问题没有意义，我真的很抱歉。
此外，如果有人可以通过举例而不是仅仅使用抽象符号来增加清晰度来解释这一点，那将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</guid>
      <pubDate>Sun, 27 Oct 2024 06:04:08 GMT</pubDate>
    </item>
    <item>
      <title>条件分布的可视化</title>
      <link>https://stats.stackexchange.com/questions/656358/visualisation-of-a-conditional-distribution</link>
      <description><![CDATA[由于在多重插补的背景下阅读了一些关于 JM 与 FCS 的资料，我试图更好地理解 MVN。有人可以告诉我如何可视化条件分布吗？我了解理论和属性。但如果我以维基百科中的 2D MVN 图像为例

边际密度 f(X) 和 f(Y) 对应于蓝色和红色的单变量正态分布，联合密度 f(X,Y) 对应于 2D 平面中点的分布。但是，如何开发 f(X|Y) 或 f(Y|X) 的直觉/视觉图像？]]></description>
      <guid>https://stats.stackexchange.com/questions/656358/visualisation-of-a-conditional-distribution</guid>
      <pubDate>Sat, 26 Oct 2024 22:34:35 GMT</pubDate>
    </item>
    <item>
      <title>样本相关矩阵与其真实值的偏差</title>
      <link>https://stats.stackexchange.com/questions/656344/the-deviation-of-the-sample-correlation-matrix-from-its-true-value</link>
      <description><![CDATA[在HDP 书中，我发现了协方差矩阵的集中不等式
$$
\mathbb{P}\left(\|\Sigma_n-\Sigma\|_2\le C_K\sqrt{\frac{p}{n}}\right)\ge1-2\exp\left(-p\right)
$$
其中$\|\cdot\|_2$表示谱范数。
现在，我对相关系数矩阵的集中不等式感兴趣：边界$\|\Gamma_n-\Gamma\|_2$ 的概率很大，其中 $\Gamma=D^{-\frac{1}{2}}\Sigma D^{-\frac{1}{2}}$ 和 $D=\operatorname {diag}\left(\Sigma\right)$。那么我可以阅读哪些论文？目前最好的结果是什么？相关矩阵的结果可以直接从协方差矩阵的结果中获得吗？

什么统计问题需要相关矩阵的浓度不等式，特别是谱范数形式的浓度不等式。我猜这是一个研究得很好的问题，但我不知道如何找到它。
更新
我的尝试：
在本文第 42 页 (THM II.13) 中提供了一个有用的定理。

给定 $m,n\in \mathbb{N}$ 和 $m\le n$，将 $\beta=m/n$ 置于 $n\times m$ 随机矩阵 $\Gamma$ 其条目是遵循 $\mathcal{N}\left(0,1/n\right)$ 定律的实数、独立高斯随机变量。令奇异值为 $s_1\left(\Gamma\right)\ge\cdots\ge s_1\left(\Gamma\right)$。然后对于任何 $t &gt;0$，
$$
\max\left\{\mathcal{P}\left(s_1\left(\Gamma\right)\ge 1+\sqrt{\beta}+t\right),\mathcal{P}\left(s_m\left(\Gamma\right)\le 1-\sqrt{\beta}-t\right)\right\}\le \exp\left(-nt^2/2\right)
$$

我想知道
${\Gamma}_n$ 是否可以分解为 ${\Gamma}_n=XX^{\top}$ 其中 $X$ 表示一个 $p\times n$ 矩阵，其中高斯元素的均值为零，方差为 $\frac{1}{n}$。如果此分解正确，则可直接使用上述定理。]]></description>
      <guid>https://stats.stackexchange.com/questions/656344/the-deviation-of-the-sample-correlation-matrix-from-its-true-value</guid>
      <pubDate>Sat, 26 Oct 2024 14:00:54 GMT</pubDate>
    </item>
    <item>
      <title>如何根据检验结果计算假设的后验概率？</title>
      <link>https://stats.stackexchange.com/questions/656193/how-do-i-calculate-the-posterior-probability-of-a-hypothesis-given-the-result-of</link>
      <description><![CDATA[我理解，p 值是在零假设成立的情况下获得数据（或更多极值）的概率。然而，研究人员真正想知道的是，在给定数据的情况下，零假设成立的概率。因此，需要基于对零假设的基本概率的估计和对“获得数据的总概率”之类的权重来计算反向概率。
我可以使用贝叶斯推理，结合测试的敏感度、基准率和阳性总数：
$$\mathbb{P}(\text{sick}|\text{positive}) = \frac{\mathbb{P}(\text{positive}|\text{sick}) \cdot \mathbb{P}(\text{sick})}{\mathbb{P}(\text{positive})}。$$
例如，如果一种疾病影响 100 人中的 1 人，测试的敏感度为 99%，我随机测试 100 人，我会得到两个阳性结果（一个真，一个假），以及一个逆概率：
$$\mathbb{P}(\text{sick}|\text{positive}) \approx \frac{0.99 \cdot 0.01}{0.02} \approx 0.5.$$
现在，我的问题是，如何使用贝叶斯推理来计算 p 值的逆概率？例如，我对 $H_0$ 没有任何先验知识，因此假设 $\mathbb{P}(H_0) = 0.5$，我得到了一个显著性检验（例如，显著性水平为 0.01）。我想知道在这种情况下如何找到假设的后验概率：
$$\mathbb{P}(H_0|\text{test}) 
= \frac{\mathbb{P}(\text{test}|H_0) \cdot \mathbb{P}(H_0)}{\mathbb{P}(\text{of what?})} 
= \frac{0.01 \cdot 0.5}{\text{?}}.$$]]></description>
      <guid>https://stats.stackexchange.com/questions/656193/how-do-i-calculate-the-posterior-probability-of-a-hypothesis-given-the-result-of</guid>
      <pubDate>Wed, 23 Oct 2024 12:13:59 GMT</pubDate>
    </item>
    </channel>
</rss>