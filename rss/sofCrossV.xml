<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 07 Mar 2025 12:33:58 GMT</lastBuildDate>
    <item>
      <title>将LFT结果的不确定性建模为药物使用的预测指标</title>
      <link>https://stats.stackexchange.com/questions/662312/modelling-uncertainty-around-lft-results-as-predictors-of-drug-use</link>
      <description><![CDATA[我有一些横向流程测试，具有（低）测试特征：
灵敏度= 0.78 
特异性= 0.63 
 i每个样品（即1或0）和实际使用药物（1或0）具有LFT结果。鉴于LFT不是100％SE/SP，我想确定正确预测实际使用的LFT结果的可能性。
我假设某种形式的贝叶斯分析，但我对药物的“真实流行”不感兴趣。在整个人口中。例如，如果LFT为阳性，是否可以预测使用使用，反之亦然？
我一直在尝试（失败）在r。中提出一个明智的模型代码]]></description>
      <guid>https://stats.stackexchange.com/questions/662312/modelling-uncertainty-around-lft-results-as-predictors-of-drug-use</guid>
      <pubDate>Fri, 07 Mar 2025 11:09:57 GMT</pubDate>
    </item>
    <item>
      <title>Rasch/2PL ItemFit和可靠性的哪种因子得分估计方法？</title>
      <link>https://stats.stackexchange.com/questions/662308/which-factor-score-estimation-method-for-rasch-2pl-itemfit-and-reliability</link>
      <description><![CDATA[我想为Rasch和2PL模型计算物品拟合值（INFIT和服装）和使用R的人分离可靠性（PSR）。我的目标是开发可靠且良好的合适量表，可以用作测试，我可以将原始分数（Rasch）或加权分数（2PL）衡量，以便了解个人参与者的能力。
我看到Item -fit值和PSR（通过（SSD -MSE） / SSD）都大不相同，具体取决于MIRT :: ItemFit（）和Mirt（）和Mirt :: fscores（）中使用的因子得分估计方法（）。例如，使用默认方法“ EAP”我的PSR为0.60，而使用“ ML”导致PSR仅为0.46 
鉴于很大的差异：有人可以为我提供“ EAP”之间选择背后的概念理性。或“ Ml＆quot”而且，鉴于我的上下文，是否有任何决策迹象可以遵循非专家？
此外，我看到 debelak等。 2022 （第78、135ff和159页）提出了一些项目拟合的截止值，同时指的是基于“ Ml＆quot”的方法。作为估计方法（通过ERM包装）。例如，在0.5-1.5范围内提供和服装值。它们（以及其他拟合适应症/截止建议）是否也适用于其他因素得分估计方法？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662308/which-factor-score-estimation-method-for-rasch-2pl-itemfit-and-reliability</guid>
      <pubDate>Fri, 07 Mar 2025 09:19:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么对测试β和R的方程式相同？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662307/why-is-the-equation-the-same-for-testing-beta-and-r</link>
      <description><![CDATA[在您的演示的某个时刻，您解释说，第二个方程不假定双变量高斯，而是一个经典的回归模型，x可以免费假设任何形式，y等于线性方程和高斯误差。
但是，如果双变量高斯模型不成立，则R在其解释中是不透明的（问题的一个典型例子是，如果X在实验中被操纵，那么关于“ X和Y之间的自然冗余程度”的问题，没有任何效果）。因此，我无法理解为什么R的t统计数据来自回归模型。
一个相关的问题是，为什么beta和r的测试统计量与R相同？您是否还具有beta的标准误差的推导，以便两个方程的收敛原因，即r和beta的t，将变得透明？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662307/why-is-the-equation-the-same-for-testing-beta-and-r</guid>
      <pubDate>Fri, 07 Mar 2025 09:07:45 GMT</pubDate>
    </item>
    <item>
      <title>合奏神经网络 - 与基本模型相比</title>
      <link>https://stats.stackexchange.com/questions/662306/ensemble-neural-network-stacking-ensemble-neural-network-accuracy-is-significa</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662306/ensemble-neural-network-stacking-ensemble-neural-network-accuracy-is-significa</guid>
      <pubDate>Fri, 07 Mar 2025 07:41:37 GMT</pubDate>
    </item>
    <item>
      <title>引导程序适用于非线性功能？</title>
      <link>https://stats.stackexchange.com/questions/662304/does-the-bootstrap-work-for-non-linear-functions</link>
      <description><![CDATA[这是我对统计中基本的引导方法的理解：


我们有一个原始样本**： $ \ mathbf {x} =（x_1，x_2，...，x_n）$ 。。
一般而言，我们定义一个引导程序样本**： $ \ Mathbf {X}}^*=（x_1^*，x_2^*，...，...，x_n^*）$ 。
每个 $ x_i^*$ 是从原始样本中随机选择的，概率 $ \ frac {1} {n} {n} $    
原始估计值： $ \ hat {\ theta} = S（\ Mathbf {x}）$   
 bootstrap估算： $ \ hat {\ theta}^* = s（\ Mathbf {x}^*）$   
生成   $ b $  bootstrap样本并计算 $ \ hat {\ theta}^*_ 1，\ hat {\ hat {\ theta}
引导分布代表这些值的传播
平均值： $ \ bar {\ theta}^* = \ frac {1} {b} {b} \ sum_ {b = 1}^b \ hat {\ theta}
标准错误： $ se _ {\ hat {\ theta}} = \ sqrt {\ frac {\ frac {1} {b-1} {b-sum_} \ sum_ {b = 1} \ bar {\ theta}^*）^2} $  


我对以下几点感到困惑：有一个数学证明，表明随着样品数量的增加，Bootstrap方法估计会收敛到它们的真实价值（ https://www.stat.cmu.edu/~larry/=sml/boot.pdf ）。但这仅适用于线性函数？ 
 i可以观察到线性函数的以下内容。

 i将线性函数定义为： $ g（x）= ax + b $ 。使用詹森的
不等式：
  $$ g（e [x]）= a \ cdot e [x] + b $$   $$ e [g（x）] = e [ax + b]
 b $$   $$ g（e [x]）= e [g（x）] $$   
对于引导程序，我使用相同的线性函数： $ g（x）= ax + b $ 。
原始示例估计值为 $ \ hat {\ theta} = g（\ bar {x}）= a \ bar {x}
 + b $ 。 Bootstrap估计值为 $ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} \ sum_ {i = 1}^b g（\ bar {x}}^*_ I）$ 。通过操纵：
  $$ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} {b} \ sum_ {i = 1}
 a \ left（\ frac {1} {b} \ sum_ {i = 1}^b \ bar {x}^*_ i \ right） + b $$
任何引导程序的期望值等于原始样本
平均（在第三个方程中，LHS使用bootstrap样品，而
RHS就像使用原始）：
  $$ e [\ bar {x}^*] = \ bar {x} $$
  $$ e [\ hat {\ theta} _ {boot}] = a \ cdot e [\ bar {x}^*] + b = a \ bar {x} + b = a \ bar {x} + b =
 \ hat {\ theta} $$  
  $$ e [g（\ bar {x}^*）] = g（e [\ bar {x}^*]）$    

对于非线性情况

如果我采用二次函数： $ g（x）= x^2 $ ，原始示例
估计为 $ \ hat {\ theta} = g（\ bar {x}）=（\ bar {x}）^2 $ 
Bootstrap估算为 $ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} \ sum_ {i = 1}^b
 g（\ bar {x}^*_ i）= \ frac {1} {b} {b} \ sum_ {i = 1}^b（\ bar {x}}^*_ i）^2 $ 。。
使用Jensen的不平等用于此凸功能，我想我可以看到
引导程序偏见：
  $$ e [g（x）] \ geq G（e [x]）$$
 （\ bar {x}）^2 $$  
  $$ e [\ hat {\ theta} _ {boot}] = e \ left [\ frac {1} {b} {b} \ sum_ {i = 1}^b
 （\ bar {x}^*_ i）^2 \ right] = \ frac {1} {b} {b} \ sum_ {i = 1}^b e [（\ bar {x}^*_ i）^2]
 \ geq（\ bar {x}）^2 = \ hat {\ theta} $$  

 这意味着与非线性函数相比，Bootstrap方法对线性函数的效果更好。这是为什么存在诸如偏见校正的加速bootstrap方法以解决标准bootstrap的缺点？ 的原因是为什么]]></description>
      <guid>https://stats.stackexchange.com/questions/662304/does-the-bootstrap-work-for-non-linear-functions</guid>
      <pubDate>Fri, 07 Mar 2025 03:41:49 GMT</pubDate>
    </item>
    <item>
      <title>进行模拟时如何修改身份协方差矩阵？</title>
      <link>https://stats.stackexchange.com/questions/662303/how-to-modify-an-identity-covariance-matrix-when-conducting-a-simulation</link>
      <description><![CDATA[我正在两个假设和零假设之间进行统计检验，我有标准的多元高斯 $ n（0，i）$   - 我正在测试分布的变化。我想在替代假设中更改协方差矩阵，以使协方差条目并非全部为零。一个关键条件是我希望将方差条目保留为1。
将整个协方差矩阵更改为所有的协方差矩阵都太极端了，这使得测试太容易了。我想进行增量更改。是否有一种明智的方法可以从身份矩阵开始对协方差矩阵进行增量更改（这也使方差为1）？]]></description>
      <guid>https://stats.stackexchange.com/questions/662303/how-to-modify-an-identity-covariance-matrix-when-conducting-a-simulation</guid>
      <pubDate>Fri, 07 Mar 2025 03:04:52 GMT</pubDate>
    </item>
    <item>
      <title>是否有标准方法来构建随机矩阵的随机表示？</title>
      <link>https://stats.stackexchange.com/questions/662301/is-there-a-standard-method-to-construct-stochastic-representations-for-random-ma</link>
      <description><![CDATA[正如标题所说，我想知道如何构建已知分布的随机矩阵的随机表示。由于它可能不存在一种通用方法，因此我非常感谢与该主题有关的参考，这将使我能够更好地理解构建随机表示的过程。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662301/is-there-a-standard-method-to-construct-stochastic-representations-for-random-ma</guid>
      <pubDate>Thu, 06 Mar 2025 23:50:57 GMT</pubDate>
    </item>
    <item>
      <title>相关系数增加</title>
      <link>https://stats.stackexchange.com/questions/662300/multiplying-correlation-coefficients</link>
      <description><![CDATA[想象一下这样的场景：
  a  - ＆gt; b（a导致b）
c  - ＆gt; D（C导致D）
b＆lt;  - ＆gt; D（B和D呈正相关）
 
所以图将是这样的：
  b＆lt; -------＆gt; d
|          |
|          |
|          |
A c
 
是否可以通过它们之间的间接路径来解释A和C的观察到的相关性（这是不可预见的）（因此A-＆gt; b＆lt;  - ＆gt; d＆lt; d＆lt; -c）？在这种情况下，是 corr（a，b）*corr（b，c）*corr（c，d）一个很好的预测器？
我在路径分析中知道类似的事情。但这不是路径分析，主要是因为我认为该系统不遵守赖特的规则。但是我想知道我的推理是否正确，还是乘以相关系数是没有意义的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662300/multiplying-correlation-coefficients</guid>
      <pubDate>Thu, 06 Mar 2025 23:44:52 GMT</pubDate>
    </item>
    <item>
      <title>确定样品是否由两组组成</title>
      <link>https://stats.stackexchange.com/questions/662298/determining-if-sample-is-composed-of-two-groups</link>
      <description><![CDATA[说我有一个数据集，其中每一行都由测试分数和测试准备水平组成。得分是整数范围从0到100，包括包含在内，测试准备水平是一个具有三个可能值的分类变量（无测试准备，完整的测试准备和未知的测试准备）。
我强烈怀疑，测试准备水平未知的小组由做准备的人和没有做准备的人组成。我将如何证明或证明这一点？我最初的倾向是比较未知准备组的平均值与其他两个组的平均值之间的百分比差异，但我不确定。
如果有帮助，我已经使用了两个样本 t   - 检验来表明无准备和全准备群体的平均值是不同的（相当明显的是；  $ t_&gt; $ t_ {calc} {calc} \ 37 $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/662298/determining-if-sample-is-composed-of-two-groups</guid>
      <pubDate>Thu, 06 Mar 2025 22:59:36 GMT</pubDate>
    </item>
    <item>
      <title>关于时间序列的统一弱法律条件的问题</title>
      <link>https://stats.stackexchange.com/questions/662292/question-about-a-condition-for-the-uniform-weak-law-of-large-numbers-for-time-se</link>
      <description><![CDATA[ 我的设置：在“案例“）为依赖观察值（即时间序列）提供了大数均匀弱法（UWLLN）的有效性的条件。条件（iv）的条件之一指出：对于所有 $ \ theta_1，\ theta_2 \ in \ theta $  in \ theta $ ，有一个函数 \ begin {align}
（a）＆amp; \ quad | q_t（w_t，\ theta_1）-q_t（w_t，\ theta_2）| \ leq c_t（w_t）|| \ theta_1- \ theta_2 ||
\\
（b）＆amp; \ quad \ {c_t（w_t）\} _ t \ quad \ text {满足通常的wlln}。
\ end {align} 
其中

  $ \ theta $ 是紧凑的参数空间
  $ w_t $ 是载体，其中包含时间点的观察值 $ t $ ， $ w_t $ w_t $   $ W_1 =（X_1）$ ， $ W_2 =（x_1，x_2）$ 。这与具有远距离内存的模型相关，例如ma  $（q）$  -model。
  $ Q_T $ 是时间点 $ t $ ，例如。在时间点观察的可能性 $ t $ 。请注意：这不是总的可能性，只是在时间点上评估的单变量密度 $ t $ 。

 我的困惑：我想知道条件 $（a）$  and  $（b）$（b）$ 不仅会自动实现 $ q_t $ qu_t $  contance conter class =“ Math-Container”&gt; $ \ theta $ ？证明IDEA如下：因为 $ q_t $ 在 $ \ theta $ 和 $ \ theta $ span&gt; clast clast clast clast clast clast clast clast  $ q_T $ 是Lipschitz-continuule（以下来自 $ \ theta_1，\ theta_2 \ in \ theta $ ，有 $ k＆gt; 0 $ k＆gt; 0 $ 
 \ begin {align}
| q_t（w_t，\ theta_1）-q_t（w_t，\ theta_2）| \ leq k || \ theta_1- \ theta_2 ||
\ end {align} 
设置 $ c_t（w_t）$ 从条件 $（a）$（a）$（a）$  $ c_t（w_t） class =“ Math-Container”&gt; $ K $ 是确定性的，它也可以满足WLLN。 （严格地说，我应该写 $ k_t $ 而不是 $ k $ ，但是我只能选择 $ k = $ k = \ max_t k_t k_t $ 。
 我的问题：我缺少什么吗？我之所以问这个，是因为在原始论文中，提出了使用均值定理的建议。然后 $ c_t $ 是 $ \ theta $ ）的函数。我不明白为什么在论文中给出建议，而不是使用平滑度。特别是，因为定理下面有以下语句：
 ;因为大多数时间序列应用程序都涉及光滑的客观功能，因此应用定理4.2通常在于验证 $ \ {q_t（w_t，\ theta，\ theta）任何 $ \ theta \ in \ theta $ 。  
，但从它自动遵循的平滑度， $ c_t $ 可以选择为恒定，可以满足wlln。当然，必须检查 $ q_t $ 的wlln，这是定理中的另一个条件，当然必须检查。所以我想我缺少一些东西，但我不知道那是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/662292/question-about-a-condition-for-the-uniform-weak-law-of-large-numbers-for-time-se</guid>
      <pubDate>Thu, 06 Mar 2025 20:55:28 GMT</pubDate>
    </item>
    <item>
      <title>解释具有较低差异的随机森林，但特征很重要</title>
      <link>https://stats.stackexchange.com/questions/662272/interpreting-random-forest-with-low-variance-explained-but-significantly-import</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662272/interpreting-random-forest-with-low-variance-explained-but-significantly-import</guid>
      <pubDate>Thu, 06 Mar 2025 14:36:36 GMT</pubDate>
    </item>
    <item>
      <title>适当的符号和方法在模型中使用固定（已知）截距或预测变量进行OLS？</title>
      <link>https://stats.stackexchange.com/questions/662253/proper-notation-and-methods-to-perform-ols-with-fixed-known-beforehand-interce</link>
      <description><![CDATA[如何在诸如威尔金森（Wilkinson）的符号中表达，模型中的术语具有固定的值和错误，而不是回归中的变量，而是保持恒定的态度？例如，我可能想在模型 $ y_i = \ y_i = \ alpha + sum_j \ sum_j \ beta_j x_j x_ x_ x_ {ij} $  $ \ alpha $ 。或者，我可能想保持固定的预测变量 $ \ beta_k $ ，其价值和不确定性事先已知。欢迎有关如何执行此操作的建议，尤其是标准，推荐或常见的建议。  wilkinson符号似乎是为了描述拟合常规的输入，而不是为了拟合某些标准，我可能会符合某种标准，并且我可能不知道该标准，并且我是否有误解，并且我是不对劲的，我是不对的。固定。
一个相关的第二个问题：如何使用固定的某些术语来实现LS回归，例如，当截距或预测变量具有事先已知的值和相关错误时？如果确切知道截距（无错误），则该解决方案很简单，减去它并拟合 $ y_i&#39;= y_i- \ alpha $ 。但这是不确定的，这是不合适的。同样，对于先验价值的协变量。这个问题包括使用哪种方法和哪种软件以常规方式实现。例如，MATLAB  lmfit 似乎不允许这样做。我正在研究 lsqlin ，但我不知道如何应用表达参数不确定的紧密约束（我想放宽了约束？）。我遇到了进行类似约束优化并实现贝叶斯方法的Python库，但这似乎比要求的要复杂得多。还是不可避免的复杂性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662253/proper-notation-and-methods-to-perform-ols-with-fixed-known-beforehand-interce</guid>
      <pubDate>Thu, 06 Mar 2025 10:10:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将分布的可能性与不同的传播进行比较？</title>
      <link>https://stats.stackexchange.com/questions/662250/how-to-compare-likelihood-of-distributions-with-different-spread</link>
      <description><![CDATA[当我们计算样品的可能性与分布相对于分布时，可能性数取决于分布的传播。
它使得直接不可能比较n个样品的可能性与n个分布的可能性：
 可能性（sample1，inter1）vs可能性（Sample1，distr1）... 。
如何使可能性数字标准化以使其可比？我们不知道发行的形式，它是经验的。
 简单示例：有两个正常分布，平均值= 0，sigma1 = 1，sigma2 = 2。我们从每个生成1000个样本，然后将可能性计算为：
  $均值（log（\ operatatorName {pdf}（x__ {i}）））。exp（）$ 。
我们将获得2个0.25和0.12的数字。这是不同的，即使我们知道“合适”在这两种情况下都是相同的。
一种可能的方法是通过乘以扩散（或sigma）将其归一化，对于正态分布，它似乎产生了近距离数字0.25和0.24。
我想知道这样的归一化程度有多好，是否有更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/662250/how-to-compare-likelihood-of-distributions-with-different-spread</guid>
      <pubDate>Thu, 06 Mar 2025 07:41:32 GMT</pubDate>
    </item>
    <item>
      <title>在部分相关分析中处理分类变量</title>
      <link>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</link>
      <description><![CDATA[我正在分析具有两个条件的实验的数据：野生型（WT）和突变基因型。每个基因型大约有25个样本。
对于每个样品，测量了〜15个基因和〜5代谢产物的表达。
目的是研究基因与代谢产物之间的关系，以及基因本身之间的关系。
但是，我注意到基因型之间的基因和代谢产物水平的主要差异。这意味着简单的相关分析将主要捕获基因型驱动的差异而不是真实的关联。
我遇到了部分相关（ ppcor :: pcor.test  in R），该在R）中计算两个变量之间的相关性，同时控制第三个变量（在这种情况下，基因型）。该方法可以应用于所有变量对，并在具有多测试校正的相关图中可视化。 Spearman的等级相关性（似乎是适当的选择）可以计算。
但是， ppcor 要求控制变量是数字的，而基因型为分类（WT/MUT）。
一种方法是将基因型编码为（0,1），但我不确定这种转换的含义。

 将基因型（WT，MUT）转换为（0,1）的统计后果是什么？？

 是否有任何有效性检查以确保此方法合适？

]]></description>
      <guid>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</guid>
      <pubDate>Mon, 03 Mar 2025 07:55:24 GMT</pubDate>
    </item>
    <item>
      <title>在分层的采样中，为什么通过划分比地层大小少1个获得层群差异</title>
      <link>https://stats.stackexchange.com/questions/638770/in-stratified-sampling-why-is-the-stratum-population-variance-obtained-by-divid</link>
      <description><![CDATA[我知道这个问题的口味会经常问很多，例如， $ n-1 $ ，这就是使其成为人口差异的公正估计器的原因。到目前为止，一切都很好。
但是，当查看分层采样时，许多资源， $ n_h -1 $ 获得。目前尚不清楚为什么要这么做。不是整个阶层在自己内部和它们之间的异质性的整个想法吗？因此，不应该单独将每个阶层本身视为一个全部人口
供参考，为该资源的人口差异提供的公式为：
  $ s_h^2 = \ frac {1} {n_h-1} \ sum_ {i = 1}^{n_h} \ left（y__ {h i}  -  \ bar {y}  -  \ bar {y}
和
  $ \ bar {y} _h = \ frac {1} {n_h} {n_h} \ sum_ {i = 1}]]></description>
      <guid>https://stats.stackexchange.com/questions/638770/in-stratified-sampling-why-is-the-stratum-population-variance-obtained-by-divid</guid>
      <pubDate>Wed, 07 Feb 2024 16:15:57 GMT</pubDate>
    </item>
    </channel>
</rss>