<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 09 Mar 2024 00:55:01 GMT</lastBuildDate>
    <item>
      <title>如何解释和解决卡尔曼滤波器的非高斯测量后拟合残差？</title>
      <link>https://stats.stackexchange.com/questions/642188/how-to-interpret-and-address-non-gaussian-measurement-post-fit-residuals-of-a-ka</link>
      <description><![CDATA[我正在使用卡尔曼滤波器，通过对特征矩阵（在我最近的超参数网格搜索后大约有 300 个变量）、基于岭回归的观察模型和噪声协方差矩阵的收缩估计器的超参数搜索进行优化。尽管（看似）足够适合，但我的适合后测量残差 ($y_{k|k} = z_k - \mathbf{H}_k \hat{x}_{k| k}$) (https://en.wikipedia.org/wiki/Kalman_filter #Update）显示非高斯分布，由图表和统计测试证明。
这是否表明我的模型不是最优的，可能是由于指定错误、遗漏非线性、噪声协方差估计不准确或异常值造成的？
为了提高模型精度，我正在考虑：a）增强特征矩阵以更好地捕获依赖性，b）探索用于非线性状态测量关系的扩展卡尔曼滤波器，以及c）改进过程和测量噪声的估计方法协方差矩阵。
我在下面添加了残差图。我的测量包括三个通道，我的特征矩阵由三百个变量组成：

]]></description>
      <guid>https://stats.stackexchange.com/questions/642188/how-to-interpret-and-address-non-gaussian-measurement-post-fit-residuals-of-a-ka</guid>
      <pubDate>Fri, 08 Mar 2024 22:16:30 GMT</pubDate>
    </item>
    <item>
      <title>机器学习和深度学习的计算时间非常短</title>
      <link>https://stats.stackexchange.com/questions/642187/very-short-computational-time-in-ml-and-dl</link>
      <description><![CDATA[谁能解释一下论文中提到的计算时间为何如此之短，比如训练整个数据集不到 1 秒？我在此表中提供了一个取自文章的示例：[
论文链接
编辑：嗯，对于我提供的示例，数据集包含样本数量相对较少（7532 个样本）的时间序列数据（传感器测量值），但我仍然很难理解如何在 3.32 毫秒内训练它。好吧，除非引用的时间不是用于训练整个数据集（仅针对一批，如 @Firebug 所建议的示例）。此外，本文并不是唯一一篇计算时间如此短的论文，还有很多其他论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/642187/very-short-computational-time-in-ml-and-dl</guid>
      <pubDate>Fri, 08 Mar 2024 22:09:30 GMT</pubDate>
    </item>
    <item>
      <title>负二项式回归与调查权重的交互作用的事后检验？</title>
      <link>https://stats.stackexchange.com/questions/642186/post-hoc-tests-of-interaction-for-a-negative-binomial-regression-with-survey-wei</link>
      <description><![CDATA[我使用 R 包 survey 和函数 svyglm() 运行了带有调查权重的负二项式回归，并观察到了显着的交互效应（woohoo！）。现在我想使用事后测试来了解交互。我尝试使用包 emmeans 但出现错误。有什么想法如何做这种事情（最好是在 R 中，尽管手动/准手动或其他软件系统也很好）？下面是 MWE。
install.packages(c(“调查”, “emmeans”))
图书馆（调查）
图书馆（emmeans）

# 模拟一些数据
设置.种子(123)
n &lt;- 200
df &lt;- data.frame(
  y = rpois(n, lambda = 2), # 模拟计数数据
  预测器1 =因子（样本（c（“A”，“B”，“C”），n，替换= TRUE）），
  预测器2 =因子（样本（c（“X”，“Y”），n，替换= TRUE）），
  weights = runif(n, 0.5, 2), # 模拟权重
  cluster = Factor(rep(1:20,each = 10)), # 模拟的簇 ID
  地层 = 因子(rep(1:4,each = 50)) # 模拟地层
）

# 创建调查设计
des &lt;- svydesign(ids = ~cluster, 层 = ~strata, 权重 = ~weights, 数据 = df)

# 拟合模型
模型 &lt;- svyglm(响应 ~ 预测器 1 * 预测器 2, 设计 = 设计, 系列 = quasipoisson())

# 估计交互项的边际均值
emm_interaction &lt;- emmeans(模型, ~预测器1 * 预测器2)

# 交互项的成对比较
pairs_interaction &lt;-pairs(emm_interaction)

# 比较总结
摘要（pairs_interaction）

当我执行 emm_interaction &lt;- emmeans(model, ~ Predictor1 * Predictor2) 时，我收到以下错误消息。
ref_grid(object, ...) 中的错误：我们无法重建数据。
需要的变量是：
    预测器 1 预测器 2
这些实际上是常数吗？ （通过“params=”指定）
 尝试使用 &#39;data = &quot;&lt;数据集名称&gt;&quot;&#39; 重新运行
]]></description>
      <guid>https://stats.stackexchange.com/questions/642186/post-hoc-tests-of-interaction-for-a-negative-binomial-regression-with-survey-wei</guid>
      <pubDate>Fri, 08 Mar 2024 20:37:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么直观上标准差是获得中心极限定理的正确尺度？</title>
      <link>https://stats.stackexchange.com/questions/642185/why-intuitively-is-standard-deviation-the-correct-thing-to-scale-to-get-central</link>
      <description><![CDATA[首先我要说的是，我已经知道了所有严格的公式，但让我解释一下为什么我仍然感觉我的理解中缺少一些东西。没有必要 &gt; 对于任何答案，例如i.i.d 总和的方差计算随机变量！这不是这个问题的目的。
基本上，这可以归结为@whuber的惊人答案中的这个问题https://stats.stackexchange.com/a/ 3904/264044：
&lt;块引用&gt;

这个总和有什么特别之处？为什么我们没有其他数字数学组合（例如它们的乘积或最大值）的中心极限定理？ （事实证明我们确实如此，但它们并不那么普遍，也不总是有如此清晰、简单的结论，除非它们可以简化为 CLT。） $m_n 的序列$ 和 $s_n$ 不是唯一的，但它们几乎是唯一的，因为最终它们必须接近期望$n$ 票的总和以及总和的标准差分别...

标准差是衡量值分布的一种方法，但它绝不是唯一的方法，也不是最“自然”的方法。无论是历史上还是许多应用程序。 （例如，许多人会选择与中位数的中值绝对偏差之类的值。 ）

为什么 SD 以如此重要的方式出现？



更严格地说：我们有 $S_n$ i.i.d 总和。 $X_n$。例如，我们可以绘制二项式系数（伯努利/拉德马赫的 i.i.d. 和），并注意到它们似乎具有“相同的形状” --- 事实上，一旦缩放$\tilde S_n:=\frac{S_n-m_n}{s_n}$，就越来越像同一个形状。找到 $m_n$ 很容易：这是一个线性转变，并且期望是线性的，一切都很好。我们假设 $X_n$ 被转换为平均值 $0$。
但现在我们必须弄清楚是什么$s_n$“保持形状”。我们的想法是“接近某种极限形状”。当然是关于分布收敛的陈述，分布收敛意味着特别是所有时刻都会收敛/稳定到某个值，事实上更一般地说，所有 $\mathbb E[f (\tilde S_n)]$ 应该收敛/稳定到某个值。
不知何故，在 $f$ 的所有这些选择中，我们选择 $ f(x)=x^2$，并且由于一些代数奇迹，事情完美地进行，我们看到 $s_n$ 必须是（或至少收敛到 $n\to\infty$) 的某个常数倍数 $\sqrt n$ .
所以基本上，从这个角度来看，我们看到 $s_n$ 在某种意义上是非常基本/普遍的（正是这些价值观使得 $\mathbb E[f(\tilde S_n)]$ 对所有“nice”稳定 $f$)，但只是由于对于一些代数奇迹来说，只有对于 $f(x)=x^2$ ，我们才能显式计算 $s_n$。所以它几乎看起来像“2”。 $s_n \asymp n^{1/2}$ 的性质是偶然的，但“通用性”却是偶然的。另一方面，$s_n$ 的结果告诉我们，这并非偶然——这是完全不可避免的。
&lt;块引用&gt;
问题：有人可以阐明为什么 $s_n \asymp n^{1/2}$ 的更深层次原因吗？也许即使可以使用不同的 $f$ 进行计算，并看到仍然 $n^{1/2 }$ 弹出，这会很有洞察力吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642185/why-intuitively-is-standard-deviation-the-correct-thing-to-scale-to-get-central</guid>
      <pubDate>Fri, 08 Mar 2024 20:24:58 GMT</pubDate>
    </item>
    <item>
      <title>是否应该使用整个数据集的迁移学习来调整单个模型？</title>
      <link>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</link>
      <description><![CDATA[我有一个包含许多时间序列的数据集，我想使用神经网络为每个单独的时间序列开发异常检测。
首先在整个数据集上训练通用模型，然后使用迁移学习为每个时间序列创建单独的模型有什么好处吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</guid>
      <pubDate>Fri, 08 Mar 2024 18:09:36 GMT</pubDate>
    </item>
    <item>
      <title>我想使用 5 个数据点创建波动率分数</title>
      <link>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</link>
      <description><![CDATA[我想使用过去 5 年的活动来衡量客户群的波动性。即 5 年期间按年计算的购买总额。
我计划使用这个公式来计算方差（即找到平方偏差的平均值）。
[![方差计算][1]][1]
我想知道这是否是回答这个问题的正确计算方法 - 哪些客户每年波动性最大。我主要看到与证券/股票相关的波动性，但这是一个不同的用例。这是正确的方法还是有更好的方法？
编辑：我不确定这是正确的公式。考虑这些例子：

记录 1：2020、2020、2080、2020、2020
记录 2：4、8、26、50、13

我认为记录 1 非常一致，因此它应该具有较低的方差，但方差为 576。记录 2 具有较高的变异性，但方差低于记录 1 (277)。我们有非常大的客户和非常小的客户，我想显示出无论大小的差异。有没有办法做到这一点？
[1]: https://i.stack.imgur.com/mkRLO.png]]></description>
      <guid>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</guid>
      <pubDate>Fri, 08 Mar 2024 17:23:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 1-范数进行采样？</title>
      <link>https://stats.stackexchange.com/questions/642181/how-to-sample-with-the-1-norm</link>
      <description><![CDATA[我目前正在研究岭回归，可以使用贝叶斯统计来解释（DOI：10.1016/j.electacta.2015.03.123）。特别是，我知道最大后验（MAP）估计可以通过其不确定性来计算。
但是，当使用 1-范数而不是 2-范数（即套索回归）时，是否可以评估 MAP？此外，如何使用 1-范数进行采样？]]></description>
      <guid>https://stats.stackexchange.com/questions/642181/how-to-sample-with-the-1-norm</guid>
      <pubDate>Fri, 08 Mar 2024 15:37:55 GMT</pubDate>
    </item>
    <item>
      <title>根据查找事件的概率查找事件日期</title>
      <link>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</link>
      <description><![CDATA[我有一组临床记录，其中包含每位患者的日期和一个 NLP 模型，该模型对记录中存在的特定事件给出 0.0 到 1.0 之间的分数。根据分数，确定事件发生日期的最佳方法是什么。
基本思想是，一旦事件发生，我们将在后续访问期间看到它至少在一段时间内被提及。
一种简单的方法是采用我们看到高概率的第一个日期，但鉴于基础数据不是很好，如果这样做，我们会失去一些精度。另一方面，我们只考虑具有多个高概率注释的患者，然后我们会错过一些可能是新患者且注释较少的患者。]]></description>
      <guid>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</guid>
      <pubDate>Thu, 07 Mar 2024 23:51:51 GMT</pubDate>
    </item>
    <item>
      <title>如何计算起点不寻常的 P-R 曲线的 AUC</title>
      <link>https://stats.stackexchange.com/questions/638214/how-to-calculate-auc-for-a-p-r-curve-with-unusual-starting-point</link>
      <description><![CDATA[我正在使用一个二元分类器，根据模型输出 0 到 1 之间的分数，指示类别成员的概率。我制作了一条P-R曲线，第一个点（即阈值=1）是（0.49，0.62），如下图所示。

我不确定如何计算该曲线的 AUC。根据 scikit-learn 约定，我可以添加 (0, 1) 点，但随后我只得到一条从 (0, 1) 到 (0.49, 0.62) 的（错误）对角线，这似乎不真实。处理这样的曲线有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/638214/how-to-calculate-auc-for-a-p-r-curve-with-unusual-starting-point</guid>
      <pubDate>Wed, 31 Jan 2024 16:37:36 GMT</pubDate>
    </item>
    <item>
      <title>我应该解释 SEM (lavaan) 中的缩放模型还是标准模型？</title>
      <link>https://stats.stackexchange.com/questions/629776/should-i-interpret-the-scaled-or-the-standard-model-in-sem-lavaan</link>
      <description><![CDATA[我正在尝试在lavaan中拟合结构方程模型。我的模型如下所示：
型号 &lt;- &#39;
  # 测量模型
    OCI =~ OCI_排序 + OCI_痴迷 + OCI_检查 + OCI_囤积 + OCI_洗涤 + OCI_中和
    SPQ =~ SPQBR_NCA + SPQBR_IRS + SPQBR_ESA + SPQBR_MT + SPQBR_OS + SPQBR_EB + SPQBR_UD
  # 回归
    IMIS_negval ~ OCI + SPQ + Music_ed_year
    INMI_freq_num ~ OCI + SPQ + Music_ed_year
    INMI_ep_num ~ OCI + SPQ + Music_ed_year
  # 残差相关性
    OCI ~~ SPQ
    IMIS_negval ~~ INMI_freq_num + INMI_ep_num
    INMI_freq_num ~~ INMI_ep_num
&#39;
拟合 &lt;- sem(模型，数据 = data1，ordered=c(“INMI_freq_num”，“INMI_ep_num”))
摘要（拟合，标准化= TRUE，fit.measures = TRUE）

由于我的一些变量不是正态分布，并且我有一些序数变量，lavaan 使用 DWLS 估计器。因此，对于卡方统计数据和模型拟合指数，输出中会出现标准模型和缩放模型：
估计器 DWLS
  优化方法NLMINB
  模型参数数量 62

  观察次数 4301

模型测试用户模型：
                                              标准比例
  检验统计量 1199.752 1676.356
  自由度 110 110
  P 值（卡方） 0.000 0.000
  比例修正系数 0.728
  移位参数 28.507
    简单的二阶校正

用户模型与基线模型：

  比较适合指数 (CFI) 0.956 0.856
  塔克刘易斯指数 (TLI) 0.952 0.843

近似均方根误差：

  均方根误差 0.048 0.058
  90% 置信区间 - 较低 0.046 0.055
  90% 置信区间 - 上限 0.050 0.060

在尝试解释模型拟合时，我应该查看缩放模型值还是标准模型值？如果我应该查看缩放值，我该如何改进模型拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/629776/should-i-interpret-the-scaled-or-the-standard-model-in-sem-lavaan</guid>
      <pubDate>Fri, 27 Oct 2023 11:04:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在混合效应模型中计算固定效应的标准误？</title>
      <link>https://stats.stackexchange.com/questions/619497/how-are-the-standard-errors-of-fixed-effects-computed-in-a-mixed-effects-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/619497/how-are-the-standard-errors-of-fixed-effects-computed-in-a-mixed-effects-model</guid>
      <pubDate>Thu, 22 Jun 2023 19:28:33 GMT</pubDate>
    </item>
    <item>
      <title>两个程序的结果在我的多元逻辑回归中的收敛问题上存在冲突，我该如何处理？</title>
      <link>https://stats.stackexchange.com/questions/589285/the-results-from-2-programs-are-conflicting-on-convergence-issues-in-my-multivar</link>
      <description><![CDATA[目前，我正在使用逻辑回归分析数据集，我使用 glm 函数在 R 中运行它，以运行具有 12 个预测变量的多元逻辑回归。其中一些是相当共线的，因为它们是特征工程的结果。因此，对于我的算法没有收敛并且某些工程特征结果不适用，我并不感到惊讶。我继续分两部分运行它并以这种方式报告结果。
但是，我的合作者想要检查结果以确保没有发生错误。她更喜欢使用 JMP，因此在该软件中运行它并提供内置分析。 JMP 报告了所有参数的估计值，并且没有抱怨收敛问题。
我的问题是，我该如何处理这个问题？获得的参数估计是否合理，或者这可能表明隐藏的收敛问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/589285/the-results-from-2-programs-are-conflicting-on-convergence-issues-in-my-multivar</guid>
      <pubDate>Mon, 19 Sep 2022 14:03:22 GMT</pubDate>
    </item>
    <item>
      <title>如果使用平坦先验（Mplus 默认值），进行先验敏感性分析是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/583503/does-it-make-sense-to-do-a-prior-sensitivity-analysis-if-using-flat-priors-mplu</link>
      <description><![CDATA[如果进行敏感性分析确实有意义，那么应该如何确定使用哪些先验？如果是平淡的“非信息性”由于缺乏信息而选择先验，那么似乎很假设选择不同的知情先验来进行敏感性检查？]]></description>
      <guid>https://stats.stackexchange.com/questions/583503/does-it-make-sense-to-do-a-prior-sensitivity-analysis-if-using-flat-priors-mplu</guid>
      <pubDate>Thu, 28 Jul 2022 11:56:10 GMT</pubDate>
    </item>
    <item>
      <title>使用分层多元回归分析进行调节分析</title>
      <link>https://stats.stackexchange.com/questions/571592/moderation-analysis-with-a-hierarchical-multiple-regression-analysis</link>
      <description><![CDATA[在我的论文中，我通过层次多元回归分析进行了调节分析。更具体地说，我想调查亲子关系的亲密程度是否是师生关系冲突与小学生工作记忆表现之间关系的调节因素。在分析中，我使用两个模型（没有交互的模型 1 和有交互的模型 2，如以下文件所示： https://www.sheffield.ac.uk/polopoly_fs/1.885172!/file/90_Moderation_Meditation.pdf)
我想要另一篇与我进行相同分析的论文或论文的好例子，但我还没有找到。
此外，对于第二个模型，在添加交互作用后，我没有得出统计上显着的 R2 变化。我可以继续进行适度分析还是应该停止？据我的发起人说，有些文章使用的标准不太严格，并且确实继续进行了适度分析，但我还没有找到它们。
提前谢谢您！
问候，
伊莉丝]]></description>
      <guid>https://stats.stackexchange.com/questions/571592/moderation-analysis-with-a-hierarchical-multiple-regression-analysis</guid>
      <pubDate>Thu, 14 Apr 2022 13:59:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在R中的多项逻辑回归中选择替代特定常数（ASC）？ （未标记的选择实验）</title>
      <link>https://stats.stackexchange.com/questions/560812/how-to-choose-alternative-specific-constant-asc-in-multinomial-logistic-regres</link>
      <description><![CDATA[我正在尝试使用 R 复制我同事的 NLOGIT 分析。该分析用于离散选择实验，其中渔民选择是否选择加入假设的环境保护计划。在基线时，保护有限，资源可用性减少。我们向他们提供了各种替代方案，他们将获得报酬来保护该地区，但获得资源（鱼类）的机会会减少。
我的问题是，我希望只有一个常数 (ASC) 并指定来自我们未标记选择实验的现状选项（始终为替代方案 3）作为基线水平。使用 mlogit 包，它似乎总是生成 n-1 个常量（其中 n 是替代项的数量）或 0 个常量，具体取决于您使用的选项。我有三个因变量，但我只想要一个常量（因为替代方案 1 和 2 彼此之间没有未观察到的差异，它们都代表相同的环境程序，但参数不同）。
我的问题是：如何限制为一个常量（截距）以及如何指定截距应引用哪个替代项？
以下是代码和数据集的屏幕截图（长格式，每行代表一个替代方案，受访者正在选择三行之一）：
数据：

代码：

结果：

相比之下，我同事的结果（有一个常数）：

如您所见，由于有两个截距的问题，结果相似但不相同（我猜测它们为何不同）。我正在尝试复制这个项目的结果，希望在我们的下一个项目中使用 R，因为如果我们使用该程序，更多的人将能够访问我们的数据。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/560812/how-to-choose-alternative-specific-constant-asc-in-multinomial-logistic-regres</guid>
      <pubDate>Mon, 17 Jan 2022 17:03:45 GMT</pubDate>
    </item>
    </channel>
</rss>