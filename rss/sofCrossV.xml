<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 12:27:50 GMT</lastBuildDate>
    <item>
      <title>证明自然三次样条函数是平滑问题的最佳解决方案</title>
      <link>https://stats.stackexchange.com/questions/648753/proving-that-a-natural-cubic-spline-is-the-optimal-solution-to-the-smoothing-pro</link>
      <description><![CDATA[在 Hastie 和 Tibshirani 1990 年出版的 GAM 一书中，有这样的说法，即最小化惩罚最小二乘目标的函数
$$ \sum_{i=1}^n(y_i-f(x_i))^2 +\lambda\int_a^b f&#39;&#39;(t)^2dt
$$
是自然三次样条函数。他们把它当作一个练习，其中定义了拉格朗日函数
$$F(f) = \int_a^b f&#39;&#39;(x)^2dx +\rho[\sum_{i=1}^n(y_i-f(x_i))^2 - \sigma +z^2]
$$
($\sigma$ 是一些松弛变量，而 $z$ 是一个“辅助”变量) 并给出了一些提示：

他们还提到Reinsch 1967。
我仍然停留在部分 (i)，我假设它不涉及 $\sigma$ 和 $z$。这是我的推导，但如果你有更好的推导，请告诉我！
如果我关注 $F$ 中的第一个项，在添加 $\delta h(x)$ 后，通过 $\delta$ 进行区分（并等于 $\delta=0$，他们没有提到）我剩下
$$ 2\int_a^b f&#39;&#39;(x)h&#39;&#39;(x)dx = 2\sum_{i=1}^n \int_{x_i}^{x_{i+1}} f&#39;&#39;(x)h&#39;&#39;(x)dx
$$
由于 $h$仅可二阶微分，我假设分部积分是为了找到 $h$ 的反导数。这样做两次，结果为：
$$ = 2\sum_{i=1}^n [f&#39;&#39;(x)h&#39;(x)|_{x_i}^{x_{i+1}} - f&#39;&#39;&#39;(x)h(x)|_{x_i}^{x_{i+1}} +\int_{x_i}^{x_{i+1}} f&#39;&#39;&#39;&#39;(x)h(x)dx]
$$
由于 $h(x)$ 是任意函数，我可以以某种方式推断出为什么 $f&#39;&#39;&#39;&#39;(x)=0 \; \forall x$。对 $F$ 的第二项执行相同操作将导致
$$2\rho\sum_{i=1}^n (f(x_i)-y_i)h(x_i)$$
因此，我可以从中推断出 $f&#39;&#39;&#39;({x_i}_-)-f&#39;&#39;&#39;({x_i}_+)=\rho \cdot (y_i-f(x_i))$
也许我可以推断出 $f&#39;&#39;$ 在结点处也必须相等。但是，$f&#39;$ 呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/648753/proving-that-a-natural-cubic-spline-is-the-optimal-solution-to-the-smoothing-pro</guid>
      <pubDate>Thu, 06 Jun 2024 11:45:00 GMT</pubDate>
    </item>
    <item>
      <title>如何比较不同聚类方法得到的同一领域的多个点模式？</title>
      <link>https://stats.stackexchange.com/questions/648751/how-to-compare-multiple-point-patterns-of-the-same-realm-resulting-from-differen</link>
      <description><![CDATA[我有一个包含 500 个采样点的数据集，我对其应用了多种不同的聚类方法进行分类。如何比较聚类组标签所产生的空间点模式？我寻求一种恢复空间相似性的单数统计，而不管实际的组标签，因为实际的组标签通常与不同的聚类不对应（即，聚类 1 的聚类 A 不一定对应于聚类 2 的聚类 A）。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/648751/how-to-compare-multiple-point-patterns-of-the-same-realm-resulting-from-differen</guid>
      <pubDate>Thu, 06 Jun 2024 10:32:42 GMT</pubDate>
    </item>
    <item>
      <title>交叉滞后面板分析多变量</title>
      <link>https://stats.stackexchange.com/questions/648750/cross-lagged-panel-analysis-many-variables</link>
      <description><![CDATA[我计划进行一项分析，研究个人应对策略，特别是预测后续幸福感的策略（反之亦然）。我认为交叉滞后面板分析可能是最好的方法，这样我们就可以对影响的方向做出一些说明。下面是我正在考虑的模型，但我对几件事不确定：
这些变量对于交叉滞后面板分析来说是否太多了？（我们的样本量约为 600）
我是否也需要所有应对策略之间的路径？（我认为这可能会变得非常复杂）。
如果有人能就解决这个问题的最佳方法提出任何建议，我将不胜感激！
]]></description>
      <guid>https://stats.stackexchange.com/questions/648750/cross-lagged-panel-analysis-many-variables</guid>
      <pubDate>Thu, 06 Jun 2024 10:21:25 GMT</pubDate>
    </item>
    <item>
      <title>如何在成对 Fisher 精确检验后正确注释条形图中的显着性水平 python [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648747/how-to-properly-annotate-significance-levels-in-a-bar-plot-after-pairwise-fisher</link>
      <description><![CDATA[我正在使用 matplotlib 和 pandas 在 Python 中可视化一些分类数据。我需要对不同类别进行成对 Fisher 精确检验，然后在条形图上标注重要性水平。虽然我已经编写了一些代码来实现这一点，但我不确定我是否做得正确。我将不胜感激任何指导或改进，以确保我的可视化的准确性和清晰度。
按照这篇文章 https://journals.asm.org/doi/10.1128/msystems.00252-19 我正在尝试做同样的事情
这是我的代码的当前版本：
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import fisher_exact
from statsmodels.stats.multitest import multipletests

# 创建 DataFrame
data = {
&#39;category&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, ],
&#39;core&#39;: [1, 1, 1644, 522, 2498, 969, 1720],
&#39;uniq&#39;: [2, 1, 759, 247, 1032, 193, 1377],
&#39;accessory&#39;: [25, 1, 5954, 1449, 7871, 2027, 11384]
}

df = pd.DataFrame(data)

df = pd.DataFrame(data)

# 绘制条形图
categories = df[&#39;category&#39;]
core_stats = df[&#39;core&#39;]
uniq_stats = df[&#39;uniq&#39;]
accessory_stats = df[&#39;accessory&#39;]

bar_width = 0.25
x = np.arange(len(categories))

plt.figure(figsize=(14, 8))
bars1 = plt.bar(x - bar_width, core_stats, width=bar_width, label=&#39;core&#39;)
bars2 = plt.bar(x, uniq_stats, width=bar_width, label=&#39;uniq&#39;)
bars3 = plt.bar(x + bar_width, accessory_stats, width=bar_width, label=&#39;accessory&#39;)

plt.xlabel(&#39;category&#39;)
plt.ylabel(&#39;Counts&#39;)
plt.title(&#39;Comparison Stats&#39;)
plt.xticks(x, categories, rotation=90)
plt.legend()

# 执行 Fisher 精确检验并注释 p 值
p_values = []
for i in range(len(categories)):
contingency_table = np.array([
[core_stats[i], uniq_stats[i], accessory_stats[i]],
[sum(core_stats) - core_stats[i], sum(uniq_stats) - uniq_stats[i], sum(accessory_stats) - accessory_stats[i]]
])

# 对每对 (core vs uniq, core vs accessory, uniq vs accessory) 进行 Fisher 精确检验
_, p_core_uniq = fisher_exact(contingency_table[:, [0, 1]])
p_values.append(p_core_uniq)
_, p_core_accessory = fisher_exact(contingency_table[:, [0, 2]])
p_values.append(p_core_accessory)
_, p_uniq_accessory = fisher_exact(contingency_table[:, [1, 2]])
p_values.append(p_uniq_accessory)

# 使用 Benjamini-Hochberg 方法调整 p 值以进行多重比较
_, adapted_p_values, _, _ = multipletests(p_values, method=&#39;fdr_bh&#39;)

# 在图上注释重要性水平
significance_levels = [&#39;ns&#39;, &#39;*&#39;, &#39;**&#39;, &#39;***&#39;]

for i in range(len(categories)):
for j, p_value in enumerate(adjusted_p_values[i*3:i*3+3]):
if p_value &lt; 0.001:
symbol = &#39;***&#39;
elif p_value &lt; 0.01:
symbol = &#39;**&#39;
elif p_value &lt; 0.05:
symbol = &#39;*&#39;
else:
symbol = &#39;ns&#39;

# 注释重要性
if j == 0: # 核心 vs 唯一
plt.text(x[i] - bar_width, core_stats[i] + max(core_stats) * 0.05, symbol, ha=&#39;center&#39;)
elif j == 1: # 核心 vs 附件
plt.text(x[i] + bar_width, accessory_stats[i] + max(accessory_stats) * 0.05, symbol, ha=&#39;center&#39;)
else: # 唯一 vs 附件
plt.text(x[i], uniq_stats[i] + max(uniq_stats) * 0.05, symbol, ha=&#39;center&#39;)

plt.tight_layout()
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/648747/how-to-properly-annotate-significance-levels-in-a-bar-plot-after-pairwise-fisher</guid>
      <pubDate>Thu, 06 Jun 2024 09:44:04 GMT</pubDate>
    </item>
    <item>
      <title>证明马尔可夫不等式</title>
      <link>https://stats.stackexchange.com/questions/648744/proof-markovs-inequality</link>
      <description><![CDATA[我对马尔可夫不等式的证明有一个问题，该证明以图片形式附在帖子中，非常基础：
可以理解的是，$\int_{a}^{\infty} xf(x) \, dx \geq \int_{a}^{\infty} af(x) \, dx$ 成立。但我该如何用数学方法证明这一点？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648744/proof-markovs-inequality</guid>
      <pubDate>Thu, 06 Jun 2024 09:19:57 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合模型中选择样本量。伦理考量</title>
      <link>https://stats.stackexchange.com/questions/648743/choose-sample-size-in-linear-mixed-models-ethical-considerations</link>
      <description><![CDATA[此主题没有参考文章，线性混合模型需要结果的真实数据来计算样本量，而方差分析模型则需要功效、显著性和效应量数据。
您是否可以根据虽然不相同但相似的研究来确定样本量，并计算后验功效？或者这不再是必要的，因为报告结果和效应量就足够了？
在这种情况下，选择线性混合模型的样本量最推荐的选项是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648743/choose-sample-size-in-linear-mixed-models-ethical-considerations</guid>
      <pubDate>Thu, 06 Jun 2024 09:08:27 GMT</pubDate>
    </item>
    <item>
      <title>适合周期性时期的数据类型（例如一周中的某几天和每个季节）[重复]</title>
      <link>https://stats.stackexchange.com/questions/648742/appropriate-datatype-for-cyclical-periods-like-days-of-the-week-and-seasons</link>
      <description><![CDATA[我正在尝试找出编码周期性时间指标（如一周中的天数和季节）的最佳方法。（其他示例包括月份中的天数和一年中的周数，但我会尽量让这个问题简单而有针对性。）为了保持重点，让我们考虑一个回归分析，其中一周中的天数（周日至周六）是一些感兴趣的结果变量的预测因子（等等）。
我在统计 SE 上看过类似的问题，但找不到完全相同的问题。最接近的是这个
日期是什么类型的数据？，但它询问的是按时间顺序排列的日期，而不是周期性时间段。 （我提供了该问题的答案，它区分了我的问题：https://stats.stackexchange.com/a/648740/81392.）
让我们考虑一下一周中的日子（周日到周六）通常是如何编码的，以及我在这些典型方法中遇到的问题：

整数（例如，周日 = 1，周一 = 2，...，周六 = 7）。这种编码的好处是任何回归算法都可以处理它，因为日子被编码为数字，日子的顺序基本保持不变。但并非完全如此——没有迹象表明周日在周六之后，这会丢失重要信息。然而，整数编码的最大问题是它假设星期三（4）是星期一（2）的两倍，这毫无意义。然而，如果将此编码插入回归分析，这正是算法将假设的。

无序类别（例如，“星期日”、“星期一”等没有固有顺序，例如 R 中的无序因子）。这消除了无意义的算术运算，这很好，但它完全忽略了星期四晚于星期日且星期一紧随星期日的事实。这样的编码会丢弃有关顺序的关键信息。

有序类别（例如，“星期日”、“星期一”到“星期六”的顺序严格，例如 R 中的有序因子）。这是前两个选项中最好的：它保持相同的整数偏序，但排除了无意义的算术运算。然而，它最终还是失败了：没有迹象表明星期六之后是星期日，然后又回到星期六。


（同样的论点也适用于其他周期性时期，如四季。）
所以，我的问题是：如何对像星期几这样的周期性时间段进行适当编码，以保持连续几天的顺序和第一天严格跟随最后一天的周期性？鉴于这些周期是均匀分布的（相隔 24 小时），间隔类型是可以接受的，但我缺少的是周期性。]]></description>
      <guid>https://stats.stackexchange.com/questions/648742/appropriate-datatype-for-cyclical-periods-like-days-of-the-week-and-seasons</guid>
      <pubDate>Thu, 06 Jun 2024 08:40:34 GMT</pubDate>
    </item>
    <item>
      <title>随机变量 $\mathbb{P}(Y|X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/648741/distribution-of-the-random-variable-mathbbpyx</link>
      <description><![CDATA[设 $(\Omega, \mathcal{A}, \mathbb{P})$ 为概率空间，设 $X:(\Omega, \mathcal{A})\rightarrow(\mathcal{X}, \mathcal{F})$ 和 $Y:(\Omega, \mathcal{A})\rightarrow(\mathcal{Y}, \mathcal{G})$ 为随机变量。考虑条件分布$\mathbb{P}(Y|X):\Omega\times\mathcal{G}\rightarrow [0,1]$，它是从$(\Omega, \sigma(X))$到$(\mathcal{Y}, \mathcal{G})$的马尔可夫核。
那么，对于每个$G\in\mathcal{G}$，这个条件分布就是一个从$\Omega$到$[0,1]$的随机变量。但是这个随机变量的分布是什么呢？它只是 $\mathbb{P}$ 吗？
还有一个密切相关的问题：如果 $f:\mathcal{X}\rightarrow \mathbb{R}$ 是一个可测函数（与上述设置相同），那么随机变量 $f(X)$ 的分布是什么？它是 $\mathbb{P}_X$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648741/distribution-of-the-random-variable-mathbbpyx</guid>
      <pubDate>Thu, 06 Jun 2024 08:30:17 GMT</pubDate>
    </item>
    <item>
      <title>利用随时间变化来估计需求曲线</title>
      <link>https://stats.stackexchange.com/questions/648739/demand-curve-estimation-using-variation-over-time</link>
      <description><![CDATA[我对需求价格弹性感兴趣，即 Di 中的 β=a+β*pi+εi。
假设我观察两个时间段，但两年中都有不同的个体（即我没有小组）。在 t=1 时，所有个体 i 都面临相同的固定价格：pi,0=p0。在 t=2 期间，个体面临遵循某些定价规则的个体特定价格：pi,1=b+c*X1i,1+d*X2i,1，其中 X1 和 X2 是 i 的可观察特征，b、c 和 d 是常数。假设 X1 有 n 种不同的实现，X2 有 m 种。此外，假设对于所有 i，pi,1 都严格大于 pi,0。
我想使用价格的这种变化来确定 β。我的想法是按 X1 和 X2 对个人进行分组，这样我就有了 n*m 个组，然后只需运行标准回归来估计组内的需求曲线：Di,g=ag+βg*pi,g+εi,g。
我的问题是是否可以确定 βg，以及如何得出平均 β 来绘制一些总需求曲线。]]></description>
      <guid>https://stats.stackexchange.com/questions/648739/demand-curve-estimation-using-variation-over-time</guid>
      <pubDate>Thu, 06 Jun 2024 08:02:36 GMT</pubDate>
    </item>
    <item>
      <title>预测包含两个周期成分的时间序列</title>
      <link>https://stats.stackexchange.com/questions/648737/predicting-a-time-series-containing-two-periodic-components</link>
      <description><![CDATA[我正在对一系列系统进行建模，这些系统的输出是两个具有不同周期的时间序列的总和。
考虑两个平稳过程 $X_{1i}$ 和 $X_{2i}$。由此，我为系统 ${i}$ 生成一个时间序列：$$x_i[n] \sim X_{i1} + X_{i2} \text{ if } n\bmod N_i = 0 , \text{else } x_i[n] \sim X_{1i}$$
因此，样本始终来自一个时间序列，另一个时间序列定期添加到该时间序列中。 $N_i$ 是未知的，在不同系统之间会发生变化，但我知道每个系统都有一些周期性加法器组件 $X_{2i}$。如果有帮助，可以假设 $\{N_i\}$ 的一些上限。
我想部署一种可以处理整个系统系列中任何一个的算法。该算法从一个系统获取时间序列 $x[n]$，而无需知道 $i$，并预测下一个值 $x[n+1]$。
有没有办法预测 $x_i[n]$，而无需使用自相关为系统明确找到 $N_i$？
理想情况下，寻找一些 ARMA/ARIMA 类型的模型来解决这个问题。这看起来像一个季节性时间序列，但季节性未知。尝试通过差分来处理这个问题，但无法想出任何适用于未知 $N$ 的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/648737/predicting-a-time-series-containing-two-periodic-components</guid>
      <pubDate>Thu, 06 Jun 2024 07:45:12 GMT</pubDate>
    </item>
    <item>
      <title>测试数据精度计算</title>
      <link>https://stats.stackexchange.com/questions/648736/precision-calculation-for-test-data</link>
      <description><![CDATA[我有一个经过训练的多分类（4 个不同标签）ML 模型，我使用混淆矩阵为其计算准确度和精确度。现在，对于开发的模型，我提供了一些没有标签的测试数据。它返回所有 4 个标签（分类）的计数。在这种情况下，由于我不知道 TP 和 FP，我该如何计算精确度？是否应该仅针对验证数据计算精确度？请帮忙]]></description>
      <guid>https://stats.stackexchange.com/questions/648736/precision-calculation-for-test-data</guid>
      <pubDate>Thu, 06 Jun 2024 07:36:00 GMT</pubDate>
    </item>
    <item>
      <title>STAR 比对后，BAM 文件质量序列为“？”且文件大小非常小 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648735/bam-file-quality-sequences-are-and-file-size-is-very-small-after-star-alignm</link>
      <description><![CDATA[我使用来自公共数据库的原始双端 RNA-seq Fastq 文件进行基因表达量化。使用 STAR 比对序列后，我注意到生成的 BAM 文件存在一些问题：
BAM 文件非常小，只有大约 20 MB（对于人类来说太小了）。BAM 文件中的优质序列都显示为“？”。

当我继续使用 RSEM 量化基因表达时，绝大多数基因的表达水平为零，只有几百个基因显示非零表达。
这是我遵循的工作流程：

使用 trim_galore 预处理数据。
使用 STAR 对齐序列。所用代码如下：

STAR --runThreadN 5 --genomeDir STAR_genome \
--readFilesCommand zcat \
--readFilesIn clean_data/Sample1_1_val_1.fq.gz \
clean_data/Sample1_2_val_2.fq.gz \
--outFileNamePrefix align_out/sample1_ \
--outSAMtype BAM SortedByCoordinate \
--outBAMsortingThreadN 5 \
--quantMode TranscriptomeSAM GeneCounts


使用RSEM定量基因表达。

我的问题是：
为什么BAM文件这么小，为什么质量序列显示为“？”？我该如何解决这些问题以确保准确的基因表达量化？
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/648735/bam-file-quality-sequences-are-and-file-size-is-very-small-after-star-alignm</guid>
      <pubDate>Thu, 06 Jun 2024 07:16:00 GMT</pubDate>
    </item>
    <item>
      <title>似然比未呈具有正确自由度的卡方分布（威尔克斯定理）</title>
      <link>https://stats.stackexchange.com/questions/648715/likelihood-ratios-not-distributed-as-a-chi2-distribution-with-the-correct-dof-w</link>
      <description><![CDATA[我对混合模型进行贝叶斯推理，使得$\mu$是混合中特征的混合权重
$p(x | \mu, \theta) = \mu p_{f}(x|\theta) + (1-\mu)p_{nf}(x|\theta)$
我有先前的$p(\theta)$和一个隐式似然函数$\mathcal{N} (f(\mu, \theta), \epsilon)$，其中 f 是一个确定性模拟器。
所以基本上，$p_{f}(x|\theta) = \mathcal{N} (f_{f}(\mu, \theta), \epsilon)$ 和 $p_{nf}(x|\theta) = \mathcal{N} (f_{nf}(\mu, \theta), \epsilon)$。
我计算 $T(\mu) =-2* ( \; \log p(x|\mu=0, \theta(\mu=0)) - \log p(x | \mu^*, \theta^*) )$，其中 x 固定，通过替换 $p(x | \mu, \theta) = p(\mu, \theta|x) / p(\mu, \theta)$。后验是摊销的，所以我可以根据任何模拟观察来调节它。我只有一个观测值 $x_{obs}$，我试图在模拟 x 的 $\chi^2$ 分布上绘制它的 p 值，以评估哪个模型更适合它。
这里，
$\theta(\mu=0) = \arg max_{\theta} p(x | \mu=0, \theta) $（零假设）
$\mu^{*}, \theta^{*} = \arg max_{\mu,\theta} p(x | \mu, \theta) $
我可以访问后验分布 $p(\theta|x)$，我可以从中抽样并计算其密度。
我通过从 $\theta$ 的先验中抽样，计算几个 $x_{obs}$ 和几个模拟 x 的 LLR 统计量，因为 $x= f(\mu, \theta)$。https://towardsdatascience.com/the-likelihood-ratio-test-463455b34de9 告诉我，我应该获得一个卡方分布，其中 dof 是整个模型的模型参数之间的差异 - 零假设。但是，这是我从两个自由度为 6 的独立模型获得的结果。


我得到的自由度卡方值为 19，而第二个模型的卡方值为 19。我期望自由度卡方值为 6。我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648715/likelihood-ratios-not-distributed-as-a-chi2-distribution-with-the-correct-dof-w</guid>
      <pubDate>Wed, 05 Jun 2024 21:21:27 GMT</pubDate>
    </item>
    <item>
      <title>如何调整未调整的朗之万算法？</title>
      <link>https://stats.stackexchange.com/questions/648699/how-to-tune-the-unadjusted-langevin-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648699/how-to-tune-the-unadjusted-langevin-algorithm</guid>
      <pubDate>Wed, 05 Jun 2024 18:36:41 GMT</pubDate>
    </item>
    <item>
      <title>关于积分极限的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648680/question-about-integral-limit</link>
      <description><![CDATA[设$p_{X}(x)$和$p_{E}(y)$为两个多元概率密度，设$f(x)$为连续函数，则$max_{\alpha,\beta}\left | \frac{1}{\lambda} \int \int e^{i(\alpha^{T}x + \beta^{T}y)}p_{X}(x)p_{E}(\frac{y - f(x)}{\lambda})dxdy \right | \rightarrow 0$，当 $\lambda \rightarrow \infty$ 时（此处 $i^2 = -1$）？
p.s. 通过在所有 $\alpha,\beta$ 上添加最大值来更新问题。
p.p.s. 这个问题与概率/统计有关，因为它询问（如果我的计算没有错误），$(X, f(X) + \lambda E)$ 的联合特征函数的绝对值是否对所有参数都收敛到 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/648680/question-about-integral-limit</guid>
      <pubDate>Wed, 05 Jun 2024 12:33:16 GMT</pubDate>
    </item>
    </channel>
</rss>