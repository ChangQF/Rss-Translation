<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Dec 2024 15:18:59 GMT</lastBuildDate>
    <item>
      <title>Copula 实证估计</title>
      <link>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</link>
      <description><![CDATA[我正在研究这篇论文。
考虑以下数据：
$X : 0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87
$
$Y : 0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33, 0.34, 0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63
$
分析的第一步是估算${I}_{\overline{C}}$。我们考虑随机样本 $(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)$ 的经验生存 copula，该样本来自连续双变量分布：
$$
\overline{C}\left(\frac{i}{n}, \frac{j}{n}\right) = \frac{\text{(样本中 x &gt; x_{(i)}, y \geq y_{(j)} 的对数)}{n},
$$
其中 $ x_{(i)} ( y_{(j)}) $ 是第 $i$ 个 ($j$ ) 顺序统计量，用于对 $X$ 和 $Y$ 进行观测。使用$\overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) $作为$\overline{C}(u, v) $的估计量，$I_{\overline{C}}$的再代入估计量为：
$$
\widehat{I}_{\overline{C}} = \frac{2}{n^2} \sum_{i=1}^n \sum_{j=1}^n \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) \log \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right),
$$
在那些点上，$ \frac{i}{n} + \frac{j}{n} - 1 &gt; 0 $。给定样本的估计值为 $\widehat{I}_{\overline{C}} = 0.3049$。
有人可以纠正我试过的这段代码吗：
X &lt;- c(0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 
0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87)
Y &lt;- c(0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33, 0.34, 
0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63)
n &lt;- length(X)
X_sorted &lt;- sort(X)
Y_sorted &lt;- sort(Y)
C_bar &lt;- function(i, j, X_sorted, Y_sorted) {
count &lt;- sum((X_sorted &gt; X_sorted[i]) &amp; (Y_sorted &gt; Y_sorted[j]))
return(count / n)
}
I_C_hat &lt;- 0
for (i in 1:n) {
for (j in 1:n) {
u &lt;- i / n
v &lt;- j / n
C_val &lt;- C_bar(i, j, X_sorted, Y_sorted)
if (!is.na(C_val) &amp;&amp; C_val &gt; 0 &amp;&amp; (u + v - 1) &gt; 0) {
I_C_hat &lt;- I_C_hat + C_val * log(C_val)
}
}
}

I_C_hat &lt;- 2 / (n^2) * I_C_hat
cat(&quot;I_C_hat 的估计值：&quot;, I_C_hat, &quot;\n&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</guid>
      <pubDate>Wed, 18 Dec 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[我正在研究一个混合效应模型来分析
反应时间 ~ 种族 * 身份 + (1 | id)

使用 R。种族 和 身份 是效应编码分类变量 (+1/-1)，因变量遵循逆高斯分布。
我做了什么：

模拟数据：将数据集扩展到 250 名参与者。添加随机截距以模拟随机效应中的实际变化。
功效分析：使用 simr 模拟几种效应大小（例如 -0.1、-0.5、-1、-1.67）的功效。值得注意的是，原始模型中的交互项并不显著。
问题：在功效曲线中，功效不会随着样本量的增加而持续增加。例如，随着样本量的增大，功效有时会稳定下来，甚至会略有下降。

set.seed(111)
n_participants &lt;- 150 

extended_data &lt;- data_clean %&gt;%
slice(rep(1:n(), length.out = n() * n_participants / 
length(unique(data_clean$id)))) %&gt;%
mutate(id = rep(1:n_participants, length.out = n()))

set.seed(111) 
extended_data &lt;- extended_data %&gt;%
group_by(id) %&gt;%
mutate(
random_intercept = rnorm(1,mean = 0,sd = sqrt(16.5^2)), 
# 根据需要调整方差
反应时间 = 反应时间 + 随机截距
) %&gt;%
ungroup()

model_updated &lt;- glmer(
反应时间 ~ 种族 * 身份 + (1 | id),
data = extended_data,
family = inverse.gaussian(link = &quot;identity&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;, 
optCtrl = list(maxfun = 1e5))
) 

生成负面效应大小的功效曲线：-0.5 
计算沿 id 的 6 个样本大小的功效
预测因子“种族 1：身份 1”的功效，(95% 置信区间)，=========================================|
按 id 的最大值排序：
100：82.00% (73.05, 88.97) - 2814 行
110：84.00% (75.32, 90.57) - 3094 行
120：91.00% (83.60, 95.80) - 3374 行
130：80.00% (70.82, 87.33) - 3654 行
140：78.00% (68.61, 85.67) - 3934 行
150：82.00% (73.05, 88.97) - 4214 行

已用时间：0 小时 8 分 47 秒

负面效应大小的生成功率曲线： -1.67 
计算沿 id 的 6 个样本大小的功效
预测因子“种族 1：身份 1”的功效，
(95% 置信区间)，
=======================================|
按 id 的最大值排序：
100：85.00% (76.47, 91.35) - 2814 行
110：85.00% (76.47, 91.35) - 3094 行
120：83.00% (74.18, 89.77) - 3374 行
130：79.00% (69.71, 86.51) - 3654 行
140：84.00% (75.32, 90.57) - 3934 行
150：78.00% (68.61, 85.67) - 4214 行

已用时间：0 小时 10 分 12 秒
]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>如何计算每种混合物成分的 BIC</title>
      <link>https://stats.stackexchange.com/questions/658922/how-to-calculate-the-bic-for-each-mixture-component</link>
      <description><![CDATA[我想将高斯混合拟合到模拟数据。然后，我需要计算每个混合成分的贝叶斯信息标准。我的观点是，在模型收敛后，我根据给定的估计值计算每个混合成分的可能性。这在理论上正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658922/how-to-calculate-the-bic-for-each-mixture-component</guid>
      <pubDate>Wed, 18 Dec 2024 13:02:48 GMT</pubDate>
    </item>
    <item>
      <title>我有两个实验针对两个不同的用户群进行。我的目标是了解实验是否效果更好。如何进行？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</link>
      <description><![CDATA[我有两个实验，针对两个不同的用户群。我的目标是了解哪个实验效果更好。我每天跟踪两个指标。一个是关于留存率 - 基本上是今天使用我们应用的 100 名用户中，第二天有多少人使用。另一个是用户在两个实验中完成的活动数量。我希望活动数量更高。这里要注意的一点是，两个实验的组大小可能不同。考虑到我每天都会测量这些指标，并且这些测量结果可能不独立于时间，因此应该使用哪种统计测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</guid>
      <pubDate>Wed, 18 Dec 2024 12:40:44 GMT</pubDate>
    </item>
    <item>
      <title>为 iv+survival ipdma 创建合成数据 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658920/creating-synthetic-data-for-ivsurvival-ipdma</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658920/creating-synthetic-data-for-ivsurvival-ipdma</guid>
      <pubDate>Wed, 18 Dec 2024 11:59:10 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程中未知点协方差矩阵导数的近似值</title>
      <link>https://stats.stackexchange.com/questions/658911/approximation-for-the-derivative-of-the-covariance-matrix-for-unknown-points-in</link>
      <description><![CDATA[我希望标题足够具有描述性，我现在感觉有点愚蠢。在我进行有关导数的推导时，出现了以下术语
$$
K_{x*,x}K^{-1}_{xx} \frac{\partial K_{xx}}{\partial q} K^{-1}_{xx} K_{x,x*}
$$
其中 $x$ 为训练点，$x*$ 为未知点，$q$ 为该点所依赖的坐标。$K$ 为协方差矩阵。我的直觉告诉我，这个表达式至少在最小二乘拟合意义上近似于
$$
\frac{\partial K_{x*x*}}{\partial q}
$$
但目前我无法证明这一点。也许我只是希望它是真的，因为它会简化我推导中的最终表达式。
欢迎提出任何想法。也许我走错了路。]]></description>
      <guid>https://stats.stackexchange.com/questions/658911/approximation-for-the-derivative-of-the-covariance-matrix-for-unknown-points-in</guid>
      <pubDate>Wed, 18 Dec 2024 10:30:09 GMT</pubDate>
    </item>
    <item>
      <title>调整超参数以尽量减少过度拟合时的目标应该是什么？</title>
      <link>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</link>
      <description><![CDATA[我正在研究一个包含约 90k 行数据和 12 个特征的分类问题。我正在尝试调整 XGBoost 模型的超参数以尽量减少过度拟合。我使用 ROC_AUC 作为评估模型性能的指标。使用默认的 XGBoost 参数，5 倍 CV 结果分别显示训练 auc 为 0.782 和测试 auc 为 0.739。这表明过度拟合，因为训练集的表现优于测试集。
我开始调整超参数，因为 a) 应该调整，b) 已知超参数可用于减少过度拟合。但是，像许多其他人一样，我将验证 auc 设置为目标并在目标函数中实现交叉验证。使用的库是 Optuna 和 Hyperopt。有趣的是，对于这两种情况，我发现当算法试图将验证 auc 推向 0.745 时，训练测试 auc 差距（过度拟合指标）会扩大。如果我按验证 auc 降序绘制训练和验证 auc，验证 auc 会从 0.745 降至 0.729，而训练 auc 会从 0.868 降至 0.742。
我对结果感到很困惑。我将验证 auc 设置为 Optuna 优化的目标是否正确？我是否应该选择（训练 auc - 验证 auc），但我在网上没有找到类似的例子。而且我是否应该查看结果并选择最低的验证 auc 和相关的超参数值作为“最佳参数”，因为训练验证指标差距最小？
请在这里分享您的想法，因为在我输入时，我不确定我对过度拟合的理解是否正确。
我的代码：
X, y = df[features], df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 42, stratify = y)
dtrain = xgb.DMatrix(X_train, label = y_train, enable_categorical = True)
dtest = xgb.DMatrix(X_test, label = y_test, enable_categorical = True)

def objective(trial):

params = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 3, 10),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 100),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0, 2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.5, 1),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.5, 1),
&#39;reg_alpha&#39;: trial.suggest_float(&#39;reg_alpha&#39;, 1e-8, 10, log = True),
&#39;reg_lambda&#39;: trial.suggest_float(&#39;reg_lambda&#39;, 1e-8, 10, log = True),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.001, 0.3),
&#39;objective&#39;: &#39;binary:logistic&#39;}

cv_results = xgb.cv(
params, dtrain, num_boost_round = 10000, early_stopping_rounds = 50, 
metrics = &#39;auc&#39;, nfold = 5, stratified = True, shuffle = False
)

trial.set_user_attr(&#39;n_estimators&#39;, len(cv_results))
trial.set_user_attr(&#39;train-auc&#39;, cv_results[&#39;train-auc-mean&#39;].iloc[-1])

return cv_results[&#39;test-auc-mean&#39;].iloc[-1]

study = optuna.create_study(
direction =&#39;maximize&#39;, sampler = optuna.samplers.TPESampler(seed = 42))

study.optimize(objective, n_trials = 500, n_jobs = -1)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</guid>
      <pubDate>Wed, 18 Dec 2024 09:28:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最小化平均绝对误差的最佳拟合线的斜率？</title>
      <link>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</link>
      <description><![CDATA[我有 25 个数据点，形式为 $(x,y)$，其中 $x$ 为 $1,2,3,...,25$，$y$ 为因变量。
我需要确定 $y$ 值是增加、减少还是保持不变。
最常用的方法是将这些点拟合成一条线。如果斜率为正，则 $y$ 增加，如果斜率为负，则 $y$ 减少，等等。
我一直在使用普通最小二乘回归来绘制线，但在某些情况下，异常值会导致问题。我不想忽略异常值，因为它们相关且重要；我只是不希望它们产生如此巨大的影响。我不想使用 Theil-Sen 回归，因为这实际上忽略了异常值。
似乎我想要的是一种最小化平均绝对误差或 L1 误差（而不是平方误差）的回归。这种回归似乎要困难得多。我读过几个资料，但一般分位数回归的微积分让我很费解。
我的问题是：如何计算使 L1 误差最小化的最佳拟合线的斜率？
我正在寻找的答案有一些限制：

我正在寻找一个输出直线斜率的过程（可能包括伪代码或实际代码）。
我只需要直线的斜率。
我只有 25 个点，而且它们是二维的，因此，只要它们可以处理这种小情况，效率低下且无法扩展的解决方案也可以。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</guid>
      <pubDate>Tue, 17 Dec 2024 16:12:39 GMT</pubDate>
    </item>
    <item>
      <title>有目的地将纵向数据建模为 iid？</title>
      <link>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</link>
      <description><![CDATA[我正在考虑开展一个项目，其中有重复测量的个体（即多个个体，每个个体都有多个测量值）。响应是二进制（0,1），我正在考虑使用逻辑回归。我正在考虑考虑相关性的不同建模策略，但我也担心错误地将响应包含在模型中会违反统计假设。

1) 非标准方法：将每个人的每次测量视为具有先前响应变量和偏移变量比率的 iid。
这是我自己的想法。
这是基本模型：
$$ P(y_i = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1)}} $$
现在，进行以下修改以考虑相关性：

让 $x_2$ 表示人员 $i$
让 $x_3$ 表示 $i$ 个人之前测量结果中 1 与 0 的比率

这些就像个人层面的累积运行变量。例如对于个体 i，response_4 ~ f（来自时间点 1、2、3 的个体 i 的信息）。
$x_2$ 用于解释观察次数较多的个体与观察次数较少的个体（例如，一个有 3 次测量结果且所有 3 次都是 1 的个体，与同一个体有 10 次测量结果且所有测量结果仍为 1 的个体相比）：
$$ P(y_i = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3)}} $$
$$ \text{logit}[P(y_i = 1)] = \ln\left(\frac{P(y_i = 1)}{1 - P(y_i = 1)}\right) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 $$
为了处理 0 除法问题，此模型要求每个个体至少有 2 个观察值。
2) 标准策略：使用纵向模型。
针对个体 $i$ 和时间点 $t$ 进行重复测量的标准逻辑回归：
$$ P(y_{it} = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_{it})}} $$
$$ \text{logit}[P(y_{it} = 1)] = \ln\left(\frac{P(y_{it} = 1)}{1 - P(y_{it} = 1)}\right) = \beta_0 + \beta_1x_{it} $$
现在通过使用每个个体的随机效应项$u_i$来解释同一个体测量值之间的相关性：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + u_i $$
$$ u_i \sim N(0, \sigma^2_u) $$
可以添加额外的时间效应：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + \beta_2t + u_i $$
3) 自回归误差结构
对于 AR(1) 误差结构，将误差项 $\epsilon_{it}$ 定义为：
$$ \epsilon_{it} = \rho\epsilon_{i,t-1} + \eta_{it} $$
其中：

$\rho$ 是自相关参数（其中 $|\rho| &lt; 1$)
$\epsilon_{i,t-1}$ 是来自前一个时间点的误差项
$\eta_{it}$ 是一个新的随机误差项：$\eta_{it} \sim N(0, \sigma^2_\eta)$

把所有东西放在一起：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + \rho\epsilon_{i,t-1} + \eta_{it} $$
$$ \text{Cov}(\epsilon_{is}, \epsilon_{it}) = \sigma^2_\epsilon\rho^{|t-s|} $$

我想知道第一种建模方法是否有意义？我认为使用方法 1 在计算上更简单，因为它将所有内容视为 iid。它也可能更容易解释模型，并且不需要对相关结构做出相同类型的假设。但总的来说，有人遇到过方法 1 吗？它在统计上有效吗？还是它违反了一些统计假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:22 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 R 中一个变量的 McFadden r 平方？</title>
      <link>https://stats.stackexchange.com/questions/658874/how-to-calculate-mcfaddens-r-squared-for-just-one-variable-in-r</link>
      <description><![CDATA[对于我的逻辑回归，我使用 McFadden 的 R 平方（类似于 R 平方，但用于逻辑模型）。但是，McFadden 的 R 平方计算的是整体模型的效果，而我想知道模型中单个变量的效果。我已经设法计算了线性回归模型中单个变量的偏 R 平方（使用包：sensemakr），但我不知道如何使用 McFadden 的 R 平方进行逻辑回归。有人有什么想法吗？我在 RStudio 工作。]]></description>
      <guid>https://stats.stackexchange.com/questions/658874/how-to-calculate-mcfaddens-r-squared-for-just-one-variable-in-r</guid>
      <pubDate>Tue, 17 Dec 2024 12:40:35 GMT</pubDate>
    </item>
    <item>
      <title>参数复发事件分析中的马丁格尔和偏差残差？</title>
      <link>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</guid>
      <pubDate>Tue, 17 Dec 2024 11:24:19 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 mediate() 是否适用于多分类预测因子？</title>
      <link>https://stats.stackexchange.com/questions/658844/does-mediate-in-r-work-with-a-multicategorical-predictor</link>
      <description><![CDATA[我的数据是多级的（每个条件内的每个参与者有多个测量值），有 3 个条件。
DV = 连续；中介 = 连续；IV = 分类（有 3 个条件：控制、条件 A、条件 B；ss 内）。
对于 IV，我为分析创建了虚拟变量（A = 0, 1；B = 0, 1；控制 = 0, 1）。
mediate() 是否适用于多分类预测因子？假设我的模型在理论上是合理的，运行以下分析来计算变量的间接影响、总影响、直接影响等中介路径是否合适？
分析：
fit.mediator=lmer(Mediator ~ IV.A + IV.B + 
(1 | id), data=data1)

summary(fit.mediator)

fit.dv=lmer(DV ~ IV.A + IV.B + Mediator + 
(1 | id), data=data1)

summary(fit.dv)

summary(mediate(fit.mediator, fit.dv, 
treat=&#39;IV.A&#39;, mediator=&#39;Mediator&#39;))

summary(mediate(fit.mediator, fit.dv, 
treat=&#39;IV.B&#39;, mediator=&#39;Mediator&#39;))
]]></description>
      <guid>https://stats.stackexchange.com/questions/658844/does-mediate-in-r-work-with-a-multicategorical-predictor</guid>
      <pubDate>Mon, 16 Dec 2024 22:09:37 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林预测 FPL 球员总得分</title>
      <link>https://stats.stackexchange.com/questions/658730/predicting-fpl-player-total-points-using-random-forest</link>
      <description><![CDATA[我有一个数据集，其中包含英超联赛（2016-2023 年）大约 100k 个比赛周统计数据。我的目标是预测一名球员在某个比赛周/比赛中将获得多少总分。
我将数据分为训练/测试集，其中训练集包含赛季 &lt; 2022 的统计数据，测试集包含赛季 &gt; 的统计数据2022.
为了说明某位球员的当前状态，我计算了过去 3 个比赛周以下变量的滚动平均值：
进球数、助攻数、零封数、失球数、分钟数、自进球数、罚球数、罚失球数、黄牌、红牌、扑救数、影响力、创造力、威胁和 ict_index
然后，我使用这些变量和一些其他变量运行随机森林：
was_home、player_team、opponent_team、opponent_strength、element_type（后卫/中场等）
模型如下所示：
rf &lt;- randomForest(
as.formula(paste(target, &quot;~&quot;, 
paste(predictors, collapse = &quot; + &quot;))),
data = train,
ntree = 500,
mtry = 7,
nodesize = 10,
significance = TRUE)

这样做我只得到 R^2 约为 57%。所以我的问题是这是否正常，或者我的方法是否出错？我想知道我可以在哪里改进模型，机器学习是否是预测总分的好方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658730/predicting-fpl-player-total-points-using-random-forest</guid>
      <pubDate>Sat, 14 Dec 2024 11:25:11 GMT</pubDate>
    </item>
    <item>
      <title>减少线性指数衰减混合函数中的极端行为</title>
      <link>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</guid>
      <pubDate>Tue, 03 Dec 2024 19:48:05 GMT</pubDate>
    </item>
    <item>
      <title>提取 gam 中的 hessian/协方差矩阵（R 包 mgcv），包括与分布离散度相关的参数</title>
      <link>https://stats.stackexchange.com/questions/657934/extracting-the-hessian-covariance-matrix-in-gam-r-package-mgcv-including-the-p</link>
      <description><![CDATA[在包 mgcv 中拟合 gams 时（带或不带平滑器），我想提取 hessian 矩阵（或方差-协方差矩阵），包括与分布分散相关的参数（正态分布中的 sigma、负二项分布中的 k、beta 分布中的 phi 等）。我怎样才能得到这些？函数 vcov 似乎只提取与分布均值相关的参数。
任何指示都将不胜感激。
下面显示了一个带有 beta 分布的最小示例：
# 生成数据
set.seed(30);
n &lt;- 200
x &lt;- runif(n, 0, 5)
mu &lt;- exp(-4+1*x)/(1 + exp(-4+1*x))
phi &lt;- 4
a &lt;- mu*phi; b &lt;- (1-mu)*phi;
y &lt;- rbeta(n, shape1=a, shape2=b) 
dat &lt;- data.frame(x, y)
# 使用 betareg 包拟合模型
library(betareg)
br1 &lt;- betareg(y ~ x, data=dat)
logLik(br1)
vcov(br1)
# 使用 mgcv 包拟合模型
library(mgcv)
bm &lt;- gam(y ~ x, family=betar(link=&quot;logit&quot;), 
data=dat)
summary(bm)
logLik(bm)
vcov(bm)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657934/extracting-the-hessian-covariance-matrix-in-gam-r-package-mgcv-including-the-p</guid>
      <pubDate>Wed, 27 Nov 2024 14:42:15 GMT</pubDate>
    </item>
    </channel>
</rss>