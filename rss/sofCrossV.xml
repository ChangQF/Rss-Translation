<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 01 Nov 2024 06:26:05 GMT</lastBuildDate>
    <item>
      <title>SPSS 是否支持线性混合模型中交互项的成对比较？</title>
      <link>https://stats.stackexchange.com/questions/656578/does-spss-support-pairwise-comparisons-for-interaction-terms-in-linear-mixed-mod</link>
      <description><![CDATA[我尝试的代码如下。当我为交互项添加 COMPARE 命令时，它给出错误，说指定了多个因素。谢谢。
MIXED Ki67 BY group sex
/CRITERIA = DFMETHOD(SAT​​TERTHWAITE) CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001, ABSOLUTE)
/FIXED = group sex group*sex | SSTYPE(3)
/METHOD = REML
/PRINT = DESCRIPTIVES
/RANDOM = INTERCEPT | SUBJECT(sub_no) COVTYPE(VC)
/EMMEANS = TABLES(性别) 比较 ADJ(LSD)
/EMMEANS = TABLES(群体) 比较 ADJ(LSD)
/EMMEANS = TABLES(群体 * 性别) 比较 ADJ(LSD)]]></description>
      <guid>https://stats.stackexchange.com/questions/656578/does-spss-support-pairwise-comparisons-for-interaction-terms-in-linear-mixed-mod</guid>
      <pubDate>Fri, 01 Nov 2024 06:08:58 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析数据</title>
      <link>https://stats.stackexchange.com/questions/656577/principal-component-analysis-data</link>
      <description><![CDATA[我试图了解 PCA 的输入变量。我的问题是，如果我有一个以不同规模收集的数据集，并且可能具有不同的“n”个点。我还能将 PCA 数据集用于机器学习吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656577/principal-component-analysis-data</guid>
      <pubDate>Fri, 01 Nov 2024 05:44:09 GMT</pubDate>
    </item>
    <item>
      <title>具有信息先验概率的继承规则</title>
      <link>https://stats.stackexchange.com/questions/656575/rule-of-succession-with-informative-prior-probability</link>
      <description><![CDATA[假设我执行 $n\geq 0$ 次条件独立伯努利试验，概率未知为 $1\geq p\geq 0$，并测量到 $n \geq s \geq 0$ 次成功。此外，假设如果 $n=0$，则 $1\geq\tilde{p}\geq 0$ 是我对 $p$ 的最佳估计。
我希望获得有关继承规则的有用先验概率，以便估计 $p$。我的想法是使用 Beta 分布 $\text{Beta}(\tilde{p},1-\tilde{p})$，其平均值为 $\tilde{p}$。问题是我的分布与 Jeffreys 的先验概率 $\text{Beta}(\frac{1}{2},\frac{1}{2})$ 相匹配，其中 $\tilde{p}=\frac{1}{2}$ 通常被认为是无信息的先验。
无论我选择什么先验概率，我都希望将结果推广到伯努利试验，其中 $k\geq 2$ 个可能结果，其中 $1\geq p_1,\dots,p_k \geq 0$ 和 $\sum_{i=1}^{k} p_i = 1$ 是相应的未知概率，并且 ... class=&quot;math-container&quot;&gt;$1\geq \tilde{p}_1,\dots,\tilde{p}_k \geq 0$ 和 $\sum_{i=1}^{k} \tilde{p}_i = 1$ 分别是如果 $n=0$ 时我的最佳估计。
我相信有许多不同的信息先验概率可以使用，但我很难找到令人满意的解决方案。我最感兴趣的是继承规则的公式。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656575/rule-of-succession-with-informative-prior-probability</guid>
      <pubDate>Fri, 01 Nov 2024 01:50:59 GMT</pubDate>
    </item>
    <item>
      <title>恒定均值过程的后验预测分布</title>
      <link>https://stats.stackexchange.com/questions/656574/posterior-predictive-distribution-for-constant-mean-process</link>
      <description><![CDATA[考虑一个恒定均值过程
$$y_i = \mu + \varepsilon_i,$$
其中误差项是独立同分布的高斯分布，方差相同$\sigma^2$。假设我们得到数据$ y = y_1, \ldots, y_t$。从贝叶斯的角度来看，我想获得总和 $z = \sum_{i=t+1}^{t+\tau} y_i$ 的后验预测分布的明确表达式，对于任何 $\tau \geq 1$。
现在后验预测分布如下
$$ p(z | y) = \int p(z | \mu, \sigma^2) p(\mu, \sigma^2 | y) \,d\mu \, d\sigma^2.$$
由于独立性假设，我们有
$$p(z | \mu, \sigma^2) = \mathrm{N}(\tau \mu, \tau\sigma^2).$$
此外，假设$\mu$和$\sigma$的标准不当先验，它们的后验分布为
$$p(\mu, \sigma^2 | y) \propto \sigma^{-n-2} \exp \Big( - \frac{1}{2 \sigma^2} [(n-1)s^2 + n(\bar{y} - \mu)^2] \Big),$$
其中$\bar{y} = \frac{1}{n}\sum_{i=1}^t y_i$是样本平均值，$s^2 = \frac{1}{n-1}\sum_{i=1}^t (y_i - \bar{y})^2$ 是样本方差。

当我尝试使用这些表达式来计算积分时，我陷入了困境。具体来说，我尝试将 $p(z | \mu, \sigma^2)$ 中的项 $(z - \tau \mu)^2$ 扩展为 $((z - \tau \bar{y}) + (\tau \bar{y} - \tau \mu))^2$，但我不确定如何处理“交叉项”。
对于 $\tau = 1$，$p(z | y)$ 是一个 $t$ 分布，位置为 $\bar{y}$，尺度为 $(1 + \frac{1}{n})^{\frac{1}{2}}s$，以及 $t - 1$ 自由度（Gelman 等人，贝叶斯数据分析，第 66 页）。因此，我怀疑，一般来说，$p(z | y)$ 也是一个 $t$ 分布。位置将是 $\tau \bar{y}$，自由度将是相同的，尺度将是 $\tau$ 的某个函数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656574/posterior-predictive-distribution-for-constant-mean-process</guid>
      <pubDate>Fri, 01 Nov 2024 01:23:59 GMT</pubDate>
    </item>
    <item>
      <title>$R^2$ 与相互信息之间的联系</title>
      <link>https://stats.stackexchange.com/questions/656573/connection-between-r2-and-mutual-information</link>
      <description><![CDATA[将 MI 解释为“通过添加一些信息消除的不确定性量”，我希望与 $R^2$ 有某种联系，它是“通过添加一些信息解释的方差量”。
特别是，$I(X,Y) = H(Y)-H(Y|X)$，其表述不当，即“您对 $Y$ 一开始有多不确定” - “在了解 $X$ 之后，您对 $Y$ 有多不确定”
另一方面，$R^2 = 1-\frac{\sum (y_i - f(x_i))^2}{\sum (y_i - \bar{y})^2}$，对我来说，这可能是错误的，它有点假设 $p(Y|X) \sim N(0, \sigma_1^2)$ 其中 $\sigma_1^2 = N^{-1}\sum (y_i - f(x_i))^2$ 和 $p(Y)\sim N(0, \sigma_2^2)$ 其中 $\sigma_2^2 = N^{-1}\sum (y_i - \bar{y})^2$... 这给我们留下了 $R^2 = 1-Var[p(y|x)]/Var[p(y)]$
现在，如果我们定义 $\hat{R^2} = \frac{Var[p(y)]}{Var[p(y|x)]} \propto R^2$（以非线性方式成比例），我会说它看起来像这样：
$$
I(X,Y) \stackrel{?}{=} \alpha\ln \hat{R^2} = \alpha(\ln(Var[p(y)]) -\ln(Var[p(y|x)])),\,\, \text{for some }\alpha \in \mathbb{R}^+
$$
事实上，高斯分布的熵是 $\ln c\sigma^2$
换句话说，如果我们假设 $p(y)$ 和 $p(y|x)$ 是，那么 $R^2$（或者至少是其虚构的兄弟 $\hat{R^2}$）和相互信息之间似乎确实存在联系高斯
我是不是做错了什么/说了什么胡编乱造的话？]]></description>
      <guid>https://stats.stackexchange.com/questions/656573/connection-between-r2-and-mutual-information</guid>
      <pubDate>Fri, 01 Nov 2024 01:00:27 GMT</pubDate>
    </item>
    <item>
      <title>通过 R 中 udpipe 包中的 udpipe_annotate 生成的句法网络解释</title>
      <link>https://stats.stackexchange.com/questions/656571/interpretation-of-syntactic-network-generated-through-udpipe-annotate-from-udpip</link>
      <description><![CDATA[我正在尝试使用 udpipe 在 R 中对语音数据进行句法网络分析。
以下是存储在 ordered.txt 文件中的示例数据。
你叫什么名字？
我叫什么名字？
我叫 Neeraj。

以下是我的代码片段：
# 加载库
library(udpipe)
library(igraph)
library(ggraph)

# 加载转录本（假设您已经将文本读入变量）
transcript &lt;- readLines(&quot;ordered.txt&quot;)

# 预处理文本：清理和标记（您可以根据需要修改清理）
transcript_clean &lt;- gsub(&quot;(unintelligible|\\.|\\?|,|!|:)&quot;, &quot;&quot;, transcript) # 删除标点符号和难以理解的标记

# 加载预先训练的英语模型进行句法分析
ud_model &lt;- udpipe_download_model(language = &quot;english&quot;)
udpipe_model &lt;- udpipe_load_model(ud_model$file_model)

# 执行句法解析
parsed_transcript &lt;- udpipe_annotate(udpipe_model, x = transcript_clean)
parsed_df &lt;- as.data.frame(parsed_transcript)

# 检查句法解析结果
head(parsed_df)

# 使用 head 依赖关系创建句法网络
edges &lt;- parsed_df[!is.na(parsed_df$head_token_id), c(&quot;token&quot;, &quot;head_token_id&quot;, &quot;dep_rel&quot;)]
colnames(edges) &lt;- c(&quot;from&quot;, &quot;to&quot;, &quot;relation&quot;)

# 构建图表
syntactic_graph &lt;- graph_from_data_frame(edges, focused = TRUE)

# 可视化句法网络
ggraph(syntactic_graph, layout = &quot;fr&quot;) +
geom_edge_link(aes(label = relation), arrow = arrow(length = unit(4, &#39;mm&#39;))) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_minimal()

此代码生成如下所示的网络。

在此代码中，使用 parsed_df 创建边，具体使用列token、head_token_id 和 dep_rel。但是，我无法正确解释网络。在右下角，节点“whatandneeraj连接到名为 0（表示根）的节点，其中 head_token_id 为 0，因为这两个词在语法上不依赖于任何其他词。此外，udpipe_annotate` 对文本进行词形还原，结果派生词被转换为其基本形式，例如，is 和 was 都转换为其基本形式“be”。但是，在网络中，它们都是单独的节点。我该如何解决这个问题？
此外，在左下角，我看到 My 连接到标记为 2 的节点，而我原本期望“my”连接到单词节点“name”如下面的parsed_df的输出截图所示。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656571/interpretation-of-syntactic-network-generated-through-udpipe-annotate-from-udpip</guid>
      <pubDate>Thu, 31 Oct 2024 22:59:25 GMT</pubDate>
    </item>
    <item>
      <title>互相关 SD</title>
      <link>https://stats.stackexchange.com/questions/656570/cross-correlation-sd</link>
      <description><![CDATA[是否有已知的最佳实践或数学上定义良好的方法来计算互相关的连续 SD？或者您只是在每个采样点计算 SD？我很好奇，因为出于重要性的目的，例如当信号变得明显不同或不再明显不同时，您需要应用多个测试校正，我只是想知道这在连续时间内如何发挥作用？
这是在 numpy 中绘制它的模拟：
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import relate

# 生成用于可视化的合成数据
np.random.seed(0)
signal_1 = np.sin(np.linspace(0, 10, 1000)) + 0.1 * np.random.normal(size=1000)
signal_2 = np.sin(np.linspace(0, 10, 1000) + np.pi / 4) + 0.1 * np.random.normal(size=1000)

# 计算互相关
cross_corr = relate(signal_1, signal_2, mode=&#39;full&#39;)
lags = np.arange(-len(signal_1) + 1, len(signal_2))

# 计算 1000 个 bootstrap 样本的标准差
bootstrap_samples = 1000
sample_sd = np.zeros(len(cross_corr))

for i in range(bootstrap_samples):
# 为 bootstrap 生成随机样本
sampled_signal_1 = signal_1 + np.random.normal(scale=0.1, size=len(signal_1))
sampled_signal_2 = signal_2 + np.random.normal(scale=0.1, size=len(signal_2))
sampled_corr =相关（sampled_signal_1，sampled_signal_2，mode=&#39;full&#39;）
sample_sd += (sampled_corr - cross_corr) ** 2

sample_sd = np.sqrt(sample_sd / bootstrap_samples)

# 绘制带有 SD 的互相关
plt.figure(figsize=(10, 6))
plt.plot(lags, cross_corr, label=&#39;Cross-correlation&#39;)
plt.fill_between(lags, cross_corr - sample_sd, cross_corr + sample_sd, color=&#39;gray&#39;, alpha=0.3, label=&#39;SD over 1000 samples&#39;)
plt.xlabel(&#39;Lags&#39;)
plt.ylabel(&#39;Cross-correlation&#39;)
plt.title(&#39;带有标准差的互相关偏差&#39;)
plt.legend()
plt.grid()
plt.show()

请注意，另一个 slack 上发布了一个关于此问题的问题，但从未得到回答，而且写得很糟糕：https://stackoverflow.com/questions/78669859/how-to-calculate-the-confidence-intervals-for-a-time-lagged-cross-correlation]]></description>
      <guid>https://stats.stackexchange.com/questions/656570/cross-correlation-sd</guid>
      <pubDate>Thu, 31 Oct 2024 22:25:00 GMT</pubDate>
    </item>
    <item>
      <title>检测峰值是否及时出现</title>
      <link>https://stats.stackexchange.com/questions/656569/test-for-presence-of-peak-in-time</link>
      <description><![CDATA[我有许多基因的 RNA-Seq 计数数据，这些数据通常用负二项式建模，并随时间测量。我想找出哪些基因具有“峰值”模式。
处理此类数据的方法是具有负二项式家族的 GAM。但是，它捕获了随时间变化的不同基因模式。例如，这里我对 gene_2 感兴趣，它在特定时间点附近达到峰值，但我对 gene_1 不感兴趣：尽管它随时间变化，但它不是峰值模式。两者在 GAM 拟合中都具有显著的 p 值。

当然，在许多情况下，我有数千个基因需要测试，因此有几万个测试，其中大约三分之一我预计是显著的。我不知道先验脉冲的确切形状，有时可能更宽或更窄。
问题：我如何测试具有这种“脉冲”形状的基因？零形状可以是随时间恒定的基因，也可以是变化但不出现峰值的基因（如 gene_1）。
想法：
我首先想到的是调整 mgcv::gam 中使用的样条基础进行拟合，但找不到合适的方法，也找不到形状先验的平滑器。
我还考虑过使用 GLM 来拟合二阶和三阶多项式并比较它们的 AIC（即我们是否“需要”三阶多项式），但在这两种情况下，AIC 都会随着三阶多项式而降低，我不确定有没有更好的方法来进行这种比较。
也许另一种方法可能是某种形式的拟合优度，但我不确定如何进行。计算到模拟的“峰值”的 Wasserstein 距离形状？
最后一个想法可能是对拟合的曲线进行聚类并识别正确的聚类（例如使用 {funHDDC），我还没有探索这个想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656569/test-for-presence-of-peak-in-time</guid>
      <pubDate>Thu, 31 Oct 2024 22:16:32 GMT</pubDate>
    </item>
    <item>
      <title>保留或归纳包含愿意或不愿意回答的数据的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/656568/what-would-be-the-best-way-to-retain-or-impute-data-containing-willing-or-not-wi</link>
      <description><![CDATA[我想在调查中填补缺失数据。
在我的数据集中，参与者可以选择不回答某些个人问题（例如年龄、家庭背景），从而导致数据有意缺失和无意缺失。鉴于这种结构，建议采用哪些填补策略来确保数据完整性并尽量减少偏差？
我最初的方法是使用 Little 的 MCAR 测试来对数值进行测试。如果数据被确认为 MCAR，单一填补方法 EM（期望最大化）填补可能会有效，因为它们会引入最小的偏差。如果测试表明数据为非 MCAR，我们可以假设 MAR，根据我们对数据的假设，MNAR 的可能性较小，从而使 EM 填补仍然可行。
这种方法也适用于分类响应，尽管数据的结构至关重要，因为有些值是故意缺失的。鉴于此，首先根据参与者是否同意分享信息对数据进行细分，然后在这些子组内应用归因分析是否合理？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656568/what-would-be-the-best-way-to-retain-or-impute-data-containing-willing-or-not-wi</guid>
      <pubDate>Thu, 31 Oct 2024 22:10:07 GMT</pubDate>
    </item>
    <item>
      <title>如何找到 Beta_1 帽子和 Beta_3 帽子之间相关性的估计值</title>
      <link>https://stats.stackexchange.com/questions/656567/how-to-find-the-estimate-of-the-correlation-between-beta-1-hat-and-beta-3-hat</link>
      <description><![CDATA[我正在研究多元线性回归，并致力于寻找 Beta_1 帽子和 Beta_3 帽子之间相关性的估计值。
给定回归模型 y = B_0 + Beta_1x_1 + Beta_2x_2 + Beta_3*x_3 + 15 个案例的误差。我们有 MSE s^2 = 3。我们有
(X^T X)^(-1) =
[0.5 0.3 0.2 0.6]
[0.3 6.0 0.5 0.4]
[0.2 0.5 0.2 0.7]
[0.6 0.4 0.7 3.0]
我正在寻找 Corr(Beta_1 帽、Beta_3 帽) 的估计值。请帮忙，因为我不知道该使用哪个公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/656567/how-to-find-the-estimate-of-the-correlation-between-beta-1-hat-and-beta-3-hat</guid>
      <pubDate>Thu, 31 Oct 2024 21:59:15 GMT</pubDate>
    </item>
    <item>
      <title>根据实际值和预测值得出倍数</title>
      <link>https://stats.stackexchange.com/questions/656566/deriving-a-multiple-based-on-actuals-and-forecast-values</link>
      <description><![CDATA[就上下文而言，我们正在使用 DeepAR 模型进行需求规划预测。目前的预测往往低估了实际需求。有人建议我们使用更高的分位数来高估需求。尽管如此，我认为我们不应该向另一个方向走得太远，所以我的评估是，我们应该让预测超过实际需求，但前提是它不低于实际需求的几倍。如果这清楚的话请告诉我。
现在，我需要以某种方式使用数字得出这个倍数。作为第一步，我计算了预测值和实际值之间的绝对差，然后我可以得到一些指标，如平均值、中位数绝对偏差和标准偏差，它们分别是
平均值：10661.739321234914
中位数绝对偏差：181.05746332806666
标准偏差：391088.08675914136

我有点困惑，不知道该如何制定一个倍数。我原本打算只使用 1.5 或 2 作为倍数，但我需要量化我的推理，否则它只是凭空而来。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656566/deriving-a-multiple-based-on-actuals-and-forecast-values</guid>
      <pubDate>Thu, 31 Oct 2024 21:57:18 GMT</pubDate>
    </item>
    <item>
      <title>如何处理非常罕见的检测事件的数据？</title>
      <link>https://stats.stackexchange.com/questions/656565/how-to-analyze-data-with-very-rare-detection-events</link>
      <description><![CDATA[我正在分析几个样本中按大小排列的颗粒。我需要确定两组样本（每组 n=50）之间的平均颗粒数是否存在统计差异。
数据是通过测量落入特定尺寸箱中的颗粒来收集的。例如，&gt;5um、&gt;15um、&gt;30um 等。对于最大尺寸箱（&gt;500um），很少检测到颗粒。在 100 个样本中，大约有 20 个检测到颗粒；其余的没有。对于我的特定样本，每个样本检测到的 &gt;500um 颗粒从未超过一个。这导致数据不符合 Anderson-Darling 正态分布。对于所有其他颗粒尺寸，分布为正态分布。
我希望能够对每个颗粒尺寸箱中的所有样本进行方差分析，以确定平均值是否显著不同。当然，如果数据是非正态的，这种方法就不适用了。
是否可以假设，不管样本数据如何，较大粒径粒子群的实际分布也像较小粒径粒子一样遵循正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/656565/how-to-analyze-data-with-very-rare-detection-events</guid>
      <pubDate>Thu, 31 Oct 2024 21:49:40 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 从以子集约束为条件的分布中抽样</title>
      <link>https://stats.stackexchange.com/questions/656564/metropolis-hastings-to-sample-from-a-distribution-conditioned-on-a-subset-constr</link>
      <description><![CDATA[我有一个分布$p(\mathbf{y}) = \prod_{i=1}^n p(y_i|y_{&lt;i})$。我对从条件分布中抽取样本很感兴趣
$$
p(\mathbf{y}| \mathcal{C}_{p}) \propto p(\mathbf{y}, \mathcal{C}_{p})\{\mathbf{y} \in \mathcal{C}_{p}\}
$$
其中 $\mathcal{C}_{p}$ 是根据某些标准对分布 $p(\mathbf{y})$ 进行的限制。例如，$\mathcal{C}_{p}$ 可以是 $p(\mathbf{y})$ 到 100 个最可能实现的限制。既然我们无法提前计算 $p(\mathbf{y},\mathcal{C}_{p})$，那么如何为该目标分布设计马尔可夫链呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656564/metropolis-hastings-to-sample-from-a-distribution-conditioned-on-a-subset-constr</guid>
      <pubDate>Thu, 31 Oct 2024 21:11:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有 model="between" 和权重的包 plm？</title>
      <link>https://stats.stackexchange.com/questions/656549/how-to-use-package-plm-with-model-between-and-weights</link>
      <description><![CDATA[最近我读了一篇论文，它使用 R 展示了一些国家之间的面板固定效应。我试图重现他的结果，但 plm
总是出错。然后我在 plm 手册中测试了一些例子，发现 plm 根本无法处理带有权重的“between”模型。
下面复制了 Baltagi (2013) 表 3.1 中的一些结果
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
p &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;pooling&quot;)

当设置模型&quot;within&quot;带权重，plm 没问题
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
p &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;pooling&quot;)

update(p, model = &quot;within&quot;)

模型公式：inv ~ value + capital

系数：
value capital 
0.11012 0.31007 

update(p, model = &quot;within&quot;, weights = 1:200)

模型公式：inv ~ value + capital

系数：
value capital 
0.09545 0.20708 


当设置模型&quot;between&quot;时没有权重，plm 也行
update(p, model = &quot;between&quot;) 

模型公式：inv ~ value + capital

系数：
(截距) value capital 
-8.527114 0.134646 0.032031 

但是当设置带有权重的模型 &quot;between&quot; 时，plm 失败
update(p, model = &quot;between&quot;, weights = 1:10) |&gt; try() 
# 变量长度不同（找到 &#39;(weights)&#39;）

update(p, model = &quot;between&quot;, weights = 1:30) |&gt; try() 
# 变量长度不同（找到 &#39;(weights)&#39;）

update(p, model = &quot;between&quot;, weights = 1:200) |&gt; try() 
# dims [product 30] 与 object [200] 的长度不匹配

我花了两天时间寻找此错误的解决方法，但一无所获。我是不是犯了什么错误？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656549/how-to-use-package-plm-with-model-between-and-weights</guid>
      <pubDate>Thu, 31 Oct 2024 15:54:27 GMT</pubDate>
    </item>
    <item>
      <title>2 级 svyglm/svylm 中的 FIML？</title>
      <link>https://stats.stackexchange.com/questions/656572/fiml-in-2-level-svyglm-svylm</link>
      <description><![CDATA[我正在学习 R 中的数据分析，所以如果这是一个奇怪的问题，请告诉我。
我正在使用 survey 包分析复杂的调查数据。我还希望我的模型是 2 级的，这意味着我的一个变量处于集群级别。我偶然发现了这种全信息最大似然 (FIML) 方法，并认为在我的分析中使用它来处理缺失数据会很好。然而，当我深入研究它时，我发现 lavaan 包（通常用于 FIML）是用于 SEM 的。我想知道是否有办法在复杂的调查中使用 FIML 方法做类似 svyglm 或 svylm 的事情？
或者，我可以使用 lavaan 包做逻辑或线性模型吗？我对 SEM 也是新手，我担心它可能有太多我不需要的额外假设。
如果它很重要 - 我的结果（因变量）可以是二分或连续的（0-5 个整数），因此逻辑或线性模型都可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/656572/fiml-in-2-level-svyglm-svylm</guid>
      <pubDate>Thu, 31 Oct 2024 04:22:08 GMT</pubDate>
    </item>
    </channel>
</rss>