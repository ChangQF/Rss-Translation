<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Jan 2024 09:14:24 GMT</lastBuildDate>
    <item>
      <title>总规模是一个重要的中介因素，但子规模不是？</title>
      <link>https://stats.stackexchange.com/questions/638091/total-scale-is-a-significant-mediator-but-not-subscales</link>
      <description><![CDATA[我正在运行中介分析，其中对我正在查看的结构的总规模有显着的中介效应。但是，当我使用相同度量的子量表运行并行中介时，所有间接路径都不重要。我怎样才能最好地解释这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/638091/total-scale-is-a-significant-mediator-but-not-subscales</guid>
      <pubDate>Tue, 30 Jan 2024 08:22:41 GMT</pubDate>
    </item>
    <item>
      <title>关于多元方差分析中自由度的问题</title>
      <link>https://stats.stackexchange.com/questions/638090/question-about-degrees-of-freedom-in-manova</link>
      <description><![CDATA[res &lt;-manova(cbind(Sepal.Length, Sepal.Width) ~ 物种，data=iris)
摘要（研究）

运行上面的代码，结果如下：
 Df Pillai 约 F num Df den Df Pr(&gt;F)
物种 2 0.94531 65.878 4 294 &lt; 2.2e-16***
残差147
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

现在我对“num Df”的结果感到困惑和“den Df”。
由于iris只有150行数据，我认为dfs的总和应该是149。
然而，“den Df”的值是0。超过这个值，它们的总和似乎是该值的两倍。
那么，这些值的含义是什么以及它们与“Df”之间的关系是什么？在最左边的列中？
我应该在论文中报告哪些价值观？
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/638090/question-about-degrees-of-freedom-in-manova</guid>
      <pubDate>Tue, 30 Jan 2024 07:55:54 GMT</pubDate>
    </item>
    <item>
      <title>线性模型的加权最小二乘法</title>
      <link>https://stats.stackexchange.com/questions/638085/weighted-least-squares-for-a-linear-model</link>
      <description><![CDATA[背景
我有一个二维数据集 $\{y_i, x_i\}_{i=1}^N$ 在坐标 $y,x$。我试图用简单的模型来拟合数据集
$$\tag{*}y=mx$$
其中 $m$ 是必须从数据集中学习的（标量）参数。最小二乘估计器给出了一个简单的解决方案，它选择 $m$ 作为
$$\hat{m}_1\triangleq \arg \min_m \sum_{i=1}^N (y_i-m x_i)^2=\frac{X&#39;Y}{ X&#39;X}
$$
与 $X\triangleq[x_1,\dots, x_N]&#39;$, $Y\triangleq [y_1, \dots, y_N]&#39;$ 和 $&#39;$ 表示转置运算符。该解决方案运行良好，并且计算速度极快（只是几个标量乘积的比率！）。但是，为了提高估计的准确性，我只想将注意力集中在相关点的子集上，因为我知道作为一个点 $(y_i, x_i)$&lt; /span&gt; 远离原点则变得不可靠。因此，我想简单地用加权策略替换以前的估计策略，即选择 $m$ 作为
$$
\hat{m}_2 \triangleq \arg \min_m \sum_{i=1}^N w_i (y_i-m x_i)^2
$$
其中权重例如为 $w_i\triangleq 1/\sqrt{x_i^2 + y_i^2}$。
问题
由于拟合模型的具体形式$(*)$，我们有
$$
\hat{m}_2 \triangleq \arg \min_m \sum_{i=1}^N (\tilde{y}_i-m \tilde{x}_i)^2=\frac{\tilde{X}&#39;\波浪线{Y}}{\波浪线{X}&#39;\波浪线{X}}=\frac{X&#39; W Y}{X&#39;W X}
$$
其中 $\tilde{X}\triangleq [\sqrt{w_1}x_1,\dots,\sqrt{w_N}x_N]&#39;$, $\tilde{Y}\triangleq [\sqrt{w_1}y_1,\dots,\sqrt{w_N}y_N]&#39;$ 和 $W\ triangleq \textrm{diag}(w_1,\dots,w_N)$。问题是，从数字上看，我发现 $\hat{m}_2=\hat{m}_1$ ，因此权重在估计过程中没有影响。 
我不确定我的计算或代码实现中是否犯了一些错误，但我对这种现象的理解如下。如果 $w_i\neq 0$，则点 $(y_i, x_i)$ 替换为新的 $(\tilde{y}_i, \tilde{x}_i)$，与 $( y_i, x_i)$。因此， $(\tilde{y}_i, \tilde{x}_i)$ 与 $(y_i, x_i)$ ，因此， $(\tilde{y}_i, \tilde{x}_i)$ 执行的信息是相同的正如 $(y_i, x_i)$ 执行的那样。因此，估计过程独立于权重值。
另一方面，我不明白两件事：

假设所有 $w_i\neq 0$ 为所有 $i$，我不明白为什么
$$\tag{**}\frac{X&#39;W Y}{X&#39; W X}=\frac{X&#39; Y}{X&#39;X}$$
就像 $W$ 在除法中取消一样，但我不明白为什么这应该是真的（如果是真的）。​​
假设 $(**)$ 为真。那么，考虑到某些数据集点应该具有“低影响力”，我该如何估计 $m$ 呢？估算的最终价值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638085/weighted-least-squares-for-a-linear-model</guid>
      <pubDate>Tue, 30 Jan 2024 04:12:25 GMT</pubDate>
    </item>
    <item>
      <title>SMOTE 和顺序特征选择顺序</title>
      <link>https://stats.stackexchange.com/questions/638083/smote-and-sequential-feature-selection-order</link>
      <description><![CDATA[早上好，
我正在执行以下过程：
分割训练测试数据集
X_train、X_test、y_train、y_test = train_test_split(X_pre、y、random_state=0、stratify=y、train_size=training_fraction)
应用 SMOTE 或其他平衡算法
X_impulated_train_df, y_train = Balancing_algorithm.fit_resample(X_impulated_train_df, y_train)
应用顺序特征选择
sss = StratifiedShuffleSplit(n_splits=8, test_size=0.2, random_state=42)
&lt;前&gt;&lt;代码&gt; sfsLR = SFS(估计器=lr1,
                                   k_features=&#39;最佳&#39;,
                                   前进=布尔_sfs，
                                   浮动=假，
                                   得分=&#39;f1&#39;,
                                   简历=SSS)

sfs = sfs.fit(X_ADASYN3, labels6)
selected_feature_indices = 列表(sfs.k_feature_idx_)
sfsFinal = X_ADASYN3.iloc[:, selected_feature_indices]
sfsFinal.columns = X_ADASYN3.columns[selected_feature_indices]
进行超参数调整
pipeline_lr = 管道([(&#39;lr2&#39;,lr2)])
管道.fit（sfsFinal，标签6）
pipeline_lr = 管道([(&#39;lr2&#39;,lr2)])
lr_grid_search = GridSearchCV(估计器=pipe_lr,
param_grid=lr_param_grid,
得分=&#39;f1&#39;,
简历=sss）
我的问题是：我将 SMOTE 应用于我的完整数据集，但不仅仅针对交叉验证的训练集。这是必须的吗？如果是这样，我如何将其合并到我的代码中？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638083/smote-and-sequential-feature-selection-order</guid>
      <pubDate>Tue, 30 Jan 2024 03:54:13 GMT</pubDate>
    </item>
    <item>
      <title>解释为什么优势比 1 独立 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638082/explain-why-odds-ratio-1-independence</link>
      <description><![CDATA[我想知道如何证明
优势比 1 意味着独立性。
预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/638082/explain-why-odds-ratio-1-independence</guid>
      <pubDate>Tue, 30 Jan 2024 02:33:49 GMT</pubDate>
    </item>
    <item>
      <title>表格数据上的超维计算与梯度提升和神经网络</title>
      <link>https://stats.stackexchange.com/questions/638081/hyperdimensional-computing-versus-gradient-boosting-and-nn-on-tabular-data</link>
      <description><![CDATA[我一直在尝试学习超维计算（又名矢量符号架构）。那里没有太多资源。我找到了一些例子，但我自己的实验似乎无法得到很好的结果。我发现的最接近的是超维计算教程中的配方示例
我想做的实验是目前正在 Kaggle 上运行的使用银行流失数据集进行二元分类。这似乎是一个简单的二元分类问题。我首先尝试了神经网络并得到了 0.87506。我使用 CatBoost 获得了 0.89176 的分数。虽然这些都是不错的结果，但我想看看 HDC 是如何工作的。不幸的是我的分数是 0.73927。我不知道这是因为 HDC 无法解决此类问题，还是我只是不明白如何正确编码它。
这是我的 HDC 算法的描述：
构建模型（训练）：

为每列创建种子向量。
为每行创建向量。

为每个单元格值创建向量。

二进制列的 True/False 种子向量。
分类列中每个类别的种子向量。
连续的列被分成大小相等的容器。每个 bin 都有一个种子向量。


列向量和值向量之间的绑定运算，得到单元向量。
对所有单元向量进行捆绑操作以获得行向量。


为两个输出分类（已退出和未退出）中的每一个创建向量。

按退出列中的值对所有行向量进行分组。
对于每个组，对所有向量运行捆绑操作以获得代表该类的向量。



查询模型（测试）：

对于每一行（也称为测试用例）：

生成行向量（与上面的步骤 2 相同）。这将是查询向量。
执行查询向量与第 3 步中的两个分类向量之间的余弦相似度。
哪个分类向量更接近，就决定测试用例获得什么标签。


计算准确度（选择正确向量的测试用例数量）/测试用例数量。

我仍然不确定何时绑定以及何时捆绑。我不确定排列是否会发挥作用。我认为它不适用于这种特殊类型的问题。
我尝试过不同的尺寸。 10k 似乎是一个常见的数字，所以我期待它会很好。看来我可以使用 1k 并且看不到准确性有任何显着变化。
我的算法有什么明显错误的地方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638081/hyperdimensional-computing-versus-gradient-boosting-and-nn-on-tabular-data</guid>
      <pubDate>Tue, 30 Jan 2024 02:33:13 GMT</pubDate>
    </item>
    <item>
      <title>澄清“理解训练深度前馈神经网络的难度”的论点[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638075/clarifying-the-arguments-of-understanding-the-difficulty-of-training-deep-feedf</link>
      <description><![CDATA[编辑：
根据 Sycorax 的评论，我假设方程 (4) 是方程 (4) 的“直接结果”。假设“制度”下 $f$ 的相对线性度我们的投入。我仍然对证明前一段的假设的合理性感兴趣，并且理想地希望看到一些关于为什么我们假设线性制度的讨论。 （请原谅我可能的误解，但是如果我们达到饱和，我们不是进入了非线性部分吗？或者说我们正在强迫自己脱离线性部分，这是不可取的？）
&lt;小时/&gt;
我决定尝试推动这篇论文“理解训练深度前馈神经网络”。 （这篇论文在训练章节的“机器学习实践”中作为参考，考虑到它的简洁性和我的数学背景，我想我应该尝试一下它作为练习。）在第 4.2 节挂断。
主要是，我无法理解所介绍的设置，这是我希望密切关注的主要部分。作者提到了“线性机制”。或线性激活，鉴于上一节的重点是非线性激活函数，这让我感到困惑；他们的 $f$ 是否应该被视为线性？特别是，方程 $(4)$ 和 $(5)$ 是如何遵循的？ （作为理由的前面的段落对我来说非常不清楚。）在这种情况下，成本函数是否完全通用？
（感谢您的任何澄清！:)）]]></description>
      <guid>https://stats.stackexchange.com/questions/638075/clarifying-the-arguments-of-understanding-the-difficulty-of-training-deep-feedf</guid>
      <pubDate>Tue, 30 Jan 2024 01:12:08 GMT</pubDate>
    </item>
    <item>
      <title>计算具有交互作用的实验中的样本量</title>
      <link>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</link>
      <description><![CDATA[我需要进行功耗分析，但我不确定我做得是否正确。最初，我有四个单元，每个单元将分为两半。在单元 1 和 2 中，将施加刺激 (S)，而在单元 3 和 4 中，将不施加刺激 (NS)。这些单位的每一半将接受两种治疗中的一种：治疗 1 (T1)，即对照，以及治疗 2 (T2)。这些处理的具体应用如图所示。

在单元 1 中，处理 1 将应用于侧 1，处理 2 将应用于侧 2。对于单元 2，处理安排相反。单元 3 和单元 4 将遵循相同的模式，在各自的侧面进行交替处理。
在我的实验中，（通过机器）施加力并测量所有单元的每一侧。我的想法是，我需要测量切割单元所需的力。目的是检验以下假设：

$H_0:$ 处理 1 和 2 所施加的力没有差异 ($T_1 = T_2$）。

$H_1:$ 处理 1 施加的力大于处理 2 施加的力 ($ T_1 &gt; T_2$）。


然后，我需要测试治疗2在有刺激和无刺激的情况下是否有差异。

$H_0:$ 处理 2 有或没有刺激时施加的力没有差异（ $T_2 \times S = T_2 \times S$)。

$H_1:$ 处理 2 和刺激时施加的力小于处理 2 无刺激时施加的力 ($T_2 \times S &lt; T_2 \times S $)。


我从文献中找到了文章的平均值、标准差和样本量，但我不确定如何计算效应大小以及如何确定正确的样本量（考虑 $0.80$ 和显着性水平 $a = 0.05$）。在我的示例中，我有四个单元，但我需要计算出需要重复实验多少次（即，我需要重复这组四个单元多少次）。
我最初使用 R 中 pwr 包中的 pwr.anova.test 函数计算了此值，但我不确定结果是否正确。谁能建议我可以用来计算样本量的任何方法？或者我使用的方法听起来正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</guid>
      <pubDate>Mon, 29 Jan 2024 22:54:54 GMT</pubDate>
    </item>
    <item>
      <title>协变量作为预测变量的固有部分</title>
      <link>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</link>
      <description><![CDATA[我想比较两种疾病类别的脑容量：年轻发病与老年发病。我知道，一般来说，年龄是脑容量的协变量。也就是说，年龄越大，大脑越小。然而，根据定义，它也是我的分组变量的一部分。无论我做什么，老发病组的年龄 $&gt; 50$ 岁，另一个是 $&gt; 岁20 岁。我是否仍然应该将年龄作为协变量，或者是否有任何其他模型可以克服这种高年龄组关系/定义？]]></description>
      <guid>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</guid>
      <pubDate>Mon, 29 Jan 2024 22:28:18 GMT</pubDate>
    </item>
    <item>
      <title>关于高斯过程分类器优化最佳实践的建议？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</guid>
      <pubDate>Mon, 29 Jan 2024 22:06:32 GMT</pubDate>
    </item>
    <item>
      <title>BERT 的均值池化是否需要使用注意力掩模？</title>
      <link>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</link>
      <description><![CDATA[我正在开展一个项目，涉及使用“emilyalsentzer/Bio_ClinicalBERT”分析临床文本。来自 Hugging Face 变形金刚库的模型。我的目标是从模型中提取有意义的句子嵌入以用于下游任务。我知道 BERT 嵌入的几种池化策略，但我不确定哪种策略对我的特定用例最有效。
普遍的方法是使用 CLS 令牌进行嵌入。然而，受到最近一篇使用均值池和最佳层选择算法的论文的启发，我&#39;一直在考虑最后一个隐藏状态层的平均池化。许多存储库的常见做法是直接计算最后一层的平均值。但我相信，这可能会忽略一个关键方面：注意力面具。
直观上，在池化之前，首先将最后一个隐藏状态与注意掩码相乘，有效地过滤掉填充序列似乎更准确。根据我的理解，这将确保只有重要的令牌嵌入才会对平均值做出贡献。
这种将注意力掩模纳入均值池的修改方法是否比典型的直接均值计算更有效？我正在寻求有关此方法是否可以提高下游应用程序的句子嵌入质量的见解。
代码示例
导入 torch.nn 作为 nn
从 Transformer 导入 AutoModel、AutoTokenizer

项目_dim = 512
bert_model = AutoModel.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”，output_hidden_​​states=True)
tokenizer = AutoTokenizer.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”)
tokenizer.model_max_length = 256
projection_head = nn.Linear(768, proj_dim)

defmean_pooling(model_output,attention_mask):
    token_embeddings = model_output[0] # model_output 的第一个元素包含所有 token 嵌入
    input_mask_expanded=attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    返回 torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

# 用法示例
输出= bert_model（input_ids=input_ids，attention_mask=attention_mask）
嵌入=mean_pooling（输出，attention_mask）
]]></description>
      <guid>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</guid>
      <pubDate>Mon, 29 Jan 2024 19:58:48 GMT</pubDate>
    </item>
    <item>
      <title>抽样误差和测量误差有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638036/what-is-the-difference-between-sampling-error-and-measurement-error</link>
      <description><![CDATA[统计领域中的术语“抽样误差”和“测量误差”非常相关，对于数据分析和报告至关重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/638036/what-is-the-difference-between-sampling-error-and-measurement-error</guid>
      <pubDate>Mon, 29 Jan 2024 17:20:00 GMT</pubDate>
    </item>
    <item>
      <title>是否存在形状类似于倒 sigmoid pdf 但 X 值超过 1 的数学函数？</title>
      <link>https://stats.stackexchange.com/questions/638026/is-there-a-mathematical-function-with-a-shape-like-an-inverted-sigmoid-pdf-but-x</link>
      <description><![CDATA[我正在寻找一个可以产生如下形状的数学函数：

上面的曲线的概率范围在 0 到 1 之间，x 值可以取任意正整数。 X 的实际值或分布曲线的位置并不那么重要（尽管定义这些的能力是必要的）。
是否有一个函数可以产生与此类似的形状？]]></description>
      <guid>https://stats.stackexchange.com/questions/638026/is-there-a-mathematical-function-with-a-shape-like-an-inverted-sigmoid-pdf-but-x</guid>
      <pubDate>Mon, 29 Jan 2024 15:29:22 GMT</pubDate>
    </item>
    <item>
      <title>计数数据回归的误差度量：泊松偏差还是均方误差？</title>
      <link>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</link>
      <description><![CDATA[我想了解，如果我使用均方误差或泊松偏差作为计数数据回归的误差度量/损失函数，会产生什么差异。是否有任何先验或理论上的原因让我们更喜欢一种指标而不是另一种指标？
背景
我确实有一个很大的计数数据数据集（即事件和暴露的数量），具体取决于各种协变量。我想将各种模型（经典 GLM 以及机器学习模型）拟合到该数据集并评估它们的质量。我的主要目标是根据协变量对分布的条件均值进行点预测。相应的比率通常很小（比如 0 到 10% 之间），并且在许多情况下观察到的事件为零。我没有任何特定领域的原因（例如成本函数）来选择我的错误度量，并且我对推理不太感兴趣（还）。此刻，我只想要一个“最好的”。预测，无论这意味着什么。
据我了解，我应该选择一个“适当的评分函数”为条件均值。我进一步了解到均方误差和泊松偏差都满足这个要求。
我的问题

除了适当的均值评分函数之外，我还应该注意其他要求吗？
是否还有其他相关指标可以（或应该）用于评估预测的质量？
与其他指标相比，更喜欢泊松偏差或均方误差等一种误差指标的可能原因是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</guid>
      <pubDate>Mon, 29 Jan 2024 09:57:27 GMT</pubDate>
    </item>
    <item>
      <title>如果 OLS 估计器使 MSE 最小化，那么 James-Stein 估计器如何实现更低的 MSE？</title>
      <link>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</link>
      <description><![CDATA[OLS 估计器解决了以下最小化问题：
$$\min ||y-X\beta||^2.$$
通过采用 FOC，我们获得 $\hat{\beta}$，它最小化了目标函数。
但是 James-Stein 估计器的 MSE 较低。我知道 James-Stein 的证明，但如何将其与 OLS 估计中平方误差损失已最小化这一事实相协调？我在这里缺少什么？
如果 James-Stein 估计器实现了较低的 MSE，为什么我们仍然使用 OLS？虽然 James-Stein 要求分布是正态的，但是根据某些版本的中心极限定理可以满足近似正态性，它不是仍然有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</guid>
      <pubDate>Sun, 28 Jan 2024 23:22:26 GMT</pubDate>
    </item>
    </channel>
</rss>