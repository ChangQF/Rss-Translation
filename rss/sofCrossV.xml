<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Sep 2024 12:32:54 GMT</lastBuildDate>
    <item>
      <title>各变量不平等问题的统计检验</title>
      <link>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</link>
      <description><![CDATA[我们的问卷有 5 个问题针对自变量，10 个问题针对因变量。是否可以测试这两个变量之间的相关性？如果可以，我们应该使用什么统计测试？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</guid>
      <pubDate>Mon, 23 Sep 2024 12:21:15 GMT</pubDate>
    </item>
    <item>
      <title>估计标准差并得到置信概率</title>
      <link>https://stats.stackexchange.com/questions/654773/estimate-standard-deviation-and-get-a-confidence-probability</link>
      <description><![CDATA[我没有统计学背景，所以请您多多包涵。凭借我有限的知识，我也没有找到任何类似的帖子，或者至少是我能理解的帖子。
这是我的问题，我有各种没有明确趋势的信号，从简单的收敛指数到看起来像跳跃的随机游走（最坏情况），见下文。这些信号很嘈杂，或多或少是恒定的噪声，我知道它遵循正态分布。

我想测量这种噪声的标准偏差，我对它的平均值不感兴趣，因为它不稳定。
我使用一种非常规的方法来估计标准偏差，但效果很好。我也快速检查了数学；理论上，输出是标准偏差。一开始，我使用 2 个点的移动标准差的标准差和贝塞尔校正，即 std(movstd(x,2,0),1)，可以在以下代码中简化。
time = linspace(0,80,300)&#39;;
true_sigma = 1;
noise = true_sigma*randn(size(time));
true_sigma = std(noise);
process = cumsum(0.3*randn(size(time)));
jump_point = 50;
process(time&gt;jump_point) = process(time&gt;jump_point)+15;
signal = process+noise;

s_list = nan(size(time));
for k=1:length(time)
d = gradient(signal(1:k));
s_list(k) = std(d)*2/sqrt(2);
end
subplot(2,1,1);
plot(time,signal); grid on; xlim([time(1) time(end)]); title(&#39;信号&#39;); xlabel(&#39;时间 (分钟)&#39;)
subplot(2,1,2);
plot(s_list); grid on; xlim([1 length(s_list)]); title(&#39;估计标准偏差&#39;); xlabel(&#39;样本&#39;); yline(true_sigma,&#39;--r&#39;);
legend(&#39;\sigma_{est}&#39;,&#39;\sigma_{true}&#39;)

这是此代码的输出。信号代表最坏情况，但仍有可能发生。您可以看到，当信号跳跃时，估计的标准偏差也会跳跃，并且需要很长时间才能再次收敛。
这就是我想要的：
解决方案 1：不受这种跳跃的影响或减轻它们的影响或更快地收敛
解决方案 2：有一个置信度指标，让我可以选择运行中最佳/最可能的猜测。
我确实研究过贝叶斯干扰，但说实话，我不明白该怎么做，也不知道从哪里开始。

谢谢你的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/654773/estimate-standard-deviation-and-get-a-confidence-probability</guid>
      <pubDate>Mon, 23 Sep 2024 12:12:22 GMT</pubDate>
    </item>
    <item>
      <title>如何控制模型中的观测次数？</title>
      <link>https://stats.stackexchange.com/questions/654771/how-control-for-the-number-of-observations-in-the-models</link>
      <description><![CDATA[假设我们有两个时间序列，即 $Y^{(1)}$ 和 $Y^{(2)}$，分别具有 $n^{(1)}&gt;&gt;n^{(2)}$ 个观测值（换句话说，$Y^{(1)}$ 比 $Y^{(2)}$ 具有更多的观测值）。对于每个时间序列，我们估计一个 AR(1) 模型，然后我们的目标是比较系数的大小：
$$Y^{(1)}_{t}=\alpha^{(1)}+\beta^{(1)}Y^{(1)}_{t-1}+\epsilon^{(1)}_{t},$$
$$Y^{(2)}_{t}=\alpha^{(2)}+\beta^{(2)}Y^{(2)}_{t-1}+\epsilon^{(2)}_{t},$$
我们想要确定 $sgn(\hat{\beta}^{(1)}-\hat{\beta}^{(2)})$。
这个简单问题的复杂性在于，观测值的数量差异很大，并且它产生了 AR(1) 系数估计值之间的一致差异。我估计了几千对时间序列的 AR(1) 模型，并通过统计证实，在其他条件相同的情况下，时间序列长度较短的时间序列的系数小于时间序列长度较长的时间序列（该结果是通过回归和随机森林实现的）。对于上面的这一对，我们有 $|\hat{\beta}^{(1)}&gt;\hat{\beta}^{(2)}|$。因此，我想在进行任何比较之前以某种方式调整 AR(1) 系数。
我想到的一个方法是根据标准误差调整相应的系数，因为后者考虑了观测次数。换句话说，该方法是计算 $\hat{\beta}^{(1)}/SE^{(1)}$ 和 $\hat{\beta}^{(2)}/SE^{(2)}$，然后确定 $sgn(\hat{\beta}^{(1)}/SE^{(1)} - \hat{\beta}^{(2)}/SE^{(2)})$。但是，这种方法并不有效，因为标准误差（可以预料）对于较长的时间序列来说较小，并且小于 1。因此，相对于 $\hat{\beta}^{(1)}$，$\hat{\beta}^{(1)}/SE^{(1)}$ 的增加幅度远远大于 $\hat{\beta}^{(2)}/SE^{(2)}$ 与 $\hat{\beta}^{(2)}$ 相比，这意味着我们进一步增加了系数之间的差距，但 $sgn(\cdot)$ 函数仍然产生相同的结果结果。
问题：

您将使用什么方法根据观察次数调整 AR(1) 系数？

您将如何改进/修改我在此处描述的方法，以使其可行且有效？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654771/how-control-for-the-number-of-observations-in-the-models</guid>
      <pubDate>Mon, 23 Sep 2024 11:42:34 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该在线性回归中对二元预测变量进行标准化？</title>
      <link>https://stats.stackexchange.com/questions/654770/should-you-normalize-binary-predictors-in-linear-regression</link>
      <description><![CDATA[我有一个线性回归 y=ax+c 和一个多元回归 y=ax+bz+c。在这两个回归中，x 都是二进制变量 (0,1)。y 已进行协变量校正和标准化。x 也应该标准化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654770/should-you-normalize-binary-predictors-in-linear-regression</guid>
      <pubDate>Mon, 23 Sep 2024 11:22:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么指数平滑预测是预测密度的中值？</title>
      <link>https://stats.stackexchange.com/questions/654766/why-is-exponential-smoothing-forecast-the-median-of-the-forecast-density</link>
      <description><![CDATA[我正在阅读 Hyndman &amp; Athanasopoulos 的《预测：原理与实践》第二版 (FPP2)。（我知道有第三版。）在关于指数平滑的章节中，第 7.7 节讨论了使用指数平滑状态空间模型进行预测，并说道：

ETS 点预测等于预测分布的中位数。对于仅具有加性成分的模型，预测分布为正态分布，因此中位数和均值相等。对于具有乘性误差或乘性季节性的 ETS 模型，点预测将不等于预测分布的均值。
（重点是我加的）

我对第一句话感到疑惑。状态空间模型中是否存在某种固有的东西使得点预测成为中位数？或者这仅仅是 ETS 方法作者的选择？由于状态空间模型无缝地（？）生成密度预测，因此用户（例如作者）可以选择分布的任何派生特征作为点预测，中位数就是其中之一。]]></description>
      <guid>https://stats.stackexchange.com/questions/654766/why-is-exponential-smoothing-forecast-the-median-of-the-forecast-density</guid>
      <pubDate>Mon, 23 Sep 2024 09:17:04 GMT</pubDate>
    </item>
    <item>
      <title>给定一个矩阵变量正态分布作为似然函数，一个正态逆 Wishart 作为先验函数，那么后验也为正态逆 Wishart 吗？</title>
      <link>https://stats.stackexchange.com/questions/654765/given-a-matrix-variate-normal-distribution-for-the-likelihood-and-a-normal-inver</link>
      <description><![CDATA[正如标题所述，我想知道，给定一个矩阵变量正态分布的似然函数和一个正态逆 Wishart 的先验函数，后验是否也是正态逆 Wishart？
在文献中已知，当我们处理多元变量正态分布的似然函数和一个正态逆 Wishart 的先验函数时，这种说法是正确的，但我不知道当我们处理矩阵变量版本时它是否仍然成立。
任何帮助都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/654765/given-a-matrix-variate-normal-distribution-for-the-likelihood-and-a-normal-inver</guid>
      <pubDate>Mon, 23 Sep 2024 09:08:51 GMT</pubDate>
    </item>
    <item>
      <title>Tobit 模型正态性假设</title>
      <link>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</link>
      <description><![CDATA[对于 tobit 模型，我对正态性假设有点困惑。是不是我的因变量必须服从正态分布？还是我的模型的潜在残差必须服从正态分布？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</guid>
      <pubDate>Mon, 23 Sep 2024 09:07:10 GMT</pubDate>
    </item>
    <item>
      <title>使用观察到的效应量计算功效时样本量不一致</title>
      <link>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</link>
      <description><![CDATA[我最初的目标是确认我的功效计算的输入是正确的。
为此，我使用了从分析中获得的数字，并将它们放入 R 的功效计算函数 power.t.test() 中。
我的预期是，我将获得与研究中使用的样本量相同的样本量（假设我使用来自分析的输入参数）。然而，始终存在微小的差异。造成这种差异的原因是什么？
详细信息
我的直觉告诉我，如果观察到的效应大小（差异和残差标准误差）与真实效应大小（$H_A$）相对应，那么在未来的一半实验中，我们应该得到比观察到的更小的 p 值，而在一半实验中，我们应该得到比观察到的更大的 p 值。因此，我们应该在具有观察到的参数（包括 p 值作为显着性水平）的功效分析中获得 50% 的功效。

或者，我也可以固定 50% 的功效，并且应该获得与观察到的相同的样本量。
下面是分析的输出，我从中获取了输入参数。
set.seed(1)
sample_size &lt;- 5
dat &lt;- data.frame(y = rnorm(sample_size*2, mean = rep(c(0,1), each = sample_size), sd = 0.8),
x = rep(c(&quot;a&quot;, &quot;b&quot;), each = sample_size))
(s &lt;- summary(lm(y ~ x, data = dat)))
## 
## 调用：
## lm(formula = y ~ x, data = dat)
## 
## 残差：
## 最小值 1Q 中位数 3Q 最大值 
## -0.7719 -0.5415 0.1018 0.3348 1.1728 
## 
## 系数：
## 估计标准误差 t 值 Pr(&gt;|t|) 
## (截距) 0.1034 0.2962 0.349 0.7360 
## xb 1.0047 0.4189 2.398 0.0433 *
## ---
## 显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1
## 
## 残差标准误差：8 个自由度上的 0.6623
## 多重 R 平方：0.4183，调整后的 R 平方：0.3456 
## F 统计量：1 和 8 DF 上的 5.752，p 值：0.04329

p 值除以 2，这样它就对应于单侧检验。
power.t.test(delta = 1.004693, sd = 0.662344, sig.level = 0.04328541/2,
power = 0.5, alternative = &quot;one.sided&quot;)
## 
## 双样本 t 检验功效计算 
##
## n = 4.759026
## delta = 1.004693
## sd = 0.662344
## sig.level = 0.02164271
## power = 0.5
## alternative = one.sided
## 
## 注意：n 是*每个*组中的数字

正如您在输出中看到的那样，样本大小略有偏差 ≈ 0.25（n = 4.76 而不是 5）。如果我针对不同的样本量重复模拟，我会得到以下图片

差异始终为 0.25（采样量越大，方差越小）。
问题

为什么功效计算会导致样本量较小？我的直觉有什么问题？
为什么是 0.25？也许与自由度以及残差标准误差（$\frac{SSR}{n-2}$）的估计方式有关？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</guid>
      <pubDate>Mon, 23 Sep 2024 08:36:54 GMT</pubDate>
    </item>
    <item>
      <title>这是贝叶斯分类器最优的证明吗？</title>
      <link>https://stats.stackexchange.com/questions/654760/is-this-the-proof-the-the-bayes-classifier-is-optimal</link>
      <description><![CDATA[在“统计学习简介”中，他们说贝叶斯分类器是最优的证明超出了本书的范围：

在“统计学习要素”中有这个：

我想知道他们所说的证明是否超出了《统计学习简介》一书的范围，第二张图片中提供的是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654760/is-this-the-proof-the-the-bayes-classifier-is-optimal</guid>
      <pubDate>Mon, 23 Sep 2024 07:46:10 GMT</pubDate>
    </item>
    <item>
      <title>理解具有右删失的双重稳健估计量（Tsiatis，2006 年）</title>
      <link>https://stats.stackexchange.com/questions/654756/understand-doubly-robust-estimator-with-right-censoring-by-tsiatis-2006</link>
      <description><![CDATA[在 Tsiatis 2006 的第 10.4 章第 254 页中，定义了一个针对右删失数据的双重稳健估计函数。它也被称为增强 IPCW (AIPCW) 估计函数。
本书是关于在数据普遍粗化的情况下开发有效的估计器，但我特别关注右删失数据的情况，这是一种单调粗化。
让 $m\left(Z_i, \beta\right)$ 成为完整数据估计函数。以下是相应的 AIPCW 估计方程：
$$
\sum_{i=1}^n\left[\frac{\Delta_i}{K_{U_i}\left\{\bar{X}_i\left(U_i\right)\right\}} m\left(Z_i, \beta\right)+\int_0^{\infty} \frac{d M_{\tilde{C}_i}\left\{r, \bar{X}_i(r)\right\}}{K_r\left\{\bar{X}_i(r)\right\}} E\{m(Z, \beta) \mid T \geq r, \bar{X}(r)\}
\right]=0
$$
我的问题是关于术语 $E\{m(Z, \beta) \mid T \geq r, \bar{X}(r)\}$。为简单起见，令 $m(Z, \beta) = Z-\beta$ 并假设仅测量基线协变量 $X$。此外，由于 $\beta$ 是确定性的，我的问题实际上是关于以下数量 $$E\{T\mid T \geq r, X\}.$$
估计这个数量的一种方法（老实说，这是我唯一熟悉的方法）是 - 首先重写 $$E\{T\mid T \geq r, X\} = \frac{\int_r^\infty tdF(t\mid X)}{1-F(r|X)},$$ 然后注意到 $1- F(\cdot \mid X) = S(\cdot \mid X),$ 这是条件生存函数。
此外，$$S(r\mid X) = \exp\left\{ - \int_0^r \lambda(m)\,dm \right\},$$
其中 $$ \lambda(t) = \lim_{0\to 0^+} h^{-1} P(t\le T\le t+h\mid T\ge t, X)$$ 是给定 $X$ 时 $T$ 的风险函数。
当然这是不可估计的，但随机审查 (CAR) 假设成立，我们将得到（现在我们可以将其视为 CAR 的定义）
$$ \lambda(t) = \lim_{0\to 0^+} h^{-1} P(t\le T\le t+h\mid T\ge t, X) = \lim_{0\to 0^+} h^{-1} P(t\le T\le t+h\mid T\ge t,C\ge t, X),$$ 这取决于可观察数据，因此是可估计的。
请注意，到目前为止，我可以“灵活切换”由于 CAR 假设，在仅以 $T\ge t$ 为条件与以 $T\ge t, C\ge t$ 为条件之间有所差异。
我的问题：有时我听到和看到人们在 AIPCW 估计方程中将 $E\{T \mid T \geq r, X\}$ 写为 $E\{T \mid T \geq r, C\ge r, X\}$。但这种写法让我很困惑。
在我看来，$E\{T \mid T \geq r, C\ge r, X\}$的写法表明这个量可以直接从风险版本$\lim_{0\to 0^+} h^{-1} P(t\le T\le t+h\mid T\ge t,C\ge t, X)$计算出来，而不需要使用CAR假设来“灵活切换”。然而我不认为这是真的。
更详细地说，假设现在我们没有 CAR 假设，我们能够估计风险的版本$\lambda(t)=\lim_{0\to 0^+} h^{-1} P(t\le T\le t+h\mid T\ge t,C\ge t, X)$。我理解数量 $$\exp\left\{ - \int_0^r \lambda(m)\,dm \right\}$$ 不再具有 $S(r\mid X)$ 的含义，但它将是 $T,C,X$ 的函数，将其表示为 g(r, T, C,X)。
$$E\{T\mid T \geq r, C\ge r, X\} \stackrel{?}{ =} \frac{\int_r^\infty t d\{1-g(t,T, C,X)\}}{g(r, T, C,X)}.$$]]></description>
      <guid>https://stats.stackexchange.com/questions/654756/understand-doubly-robust-estimator-with-right-censoring-by-tsiatis-2006</guid>
      <pubDate>Mon, 23 Sep 2024 07:26:30 GMT</pubDate>
    </item>
    <item>
      <title>监督学习与无监督学习 - 难道所有数据都不是贴有标签的吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/654755/supervised-vs-unsupervised-learning-is-not-all-data-labelled</link>
      <description><![CDATA[我从来没有真正清楚地理解过监督学习和无监督学习之间的区别。
如果你问搜索引擎这两个类别的区别是什么，你会得到类似以下的答案：

监督学习需要标记数据，而无监督学习则不需要

这对我来说仍然不清楚。
难道不是所有数据都带有标签吗？如果你有数据，那么这些数据必须具有一些数值或分类值。因此，它被标记，并带有值。
这可能看起来很迂腐，也许答案似乎很明显。我的猜测是，这里的表达标记意味着带有一些辅助分类标签。
有人可以对此发表评论或进一步澄清吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654755/supervised-vs-unsupervised-learning-is-not-all-data-labelled</guid>
      <pubDate>Mon, 23 Sep 2024 07:25:37 GMT</pubDate>
    </item>
    <item>
      <title>观测值对的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/654753/maximum-likelihood-estimation-for-pairs-of-observations</link>
      <description><![CDATA[我有 $n$ 对观测值$(x_i,y_i)$，其中每个$y_i$ 都按照$Poi(\theta x_i)$ 分布，我希望仅基于这些数据对$\theta$ 进行最大似然估计。对于 $x_i$ 没有已知分布，因此我认为我无法进行条件最大似然，因为我没有 $x_i$ 的边际概率。
我的方法是找到对数似然函数 $L(\theta x_i)$，然后仅根据 $\theta$ 进行推导，这样我就有了 $\theta$ 的估计量 - 对于此，我的对数似然函数是 $\sum[-\theta x_i + y_ilog(\theta x_i) - log(y_i!)]$，这给了我估计量 $\hat{\theta} = \frac{\sum y_i}{\sum x_i}$。这是一种合适的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654753/maximum-likelihood-estimation-for-pairs-of-observations</guid>
      <pubDate>Mon, 23 Sep 2024 06:08:45 GMT</pubDate>
    </item>
    <item>
      <title>影响 1/2 结果的多个相关变量的统计分析方法</title>
      <link>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</link>
      <description><![CDATA[我将抽象化这个问题以隐藏我实际的研究内容，但我绝对是统计分析方面的菜鸟，我想向这个网站的大神们学习更多。
我目前正在研究睡眠时间、是否生病以及白天的工作时间，以及这些因素在一年的时间内如何导致抑郁症的发展。另一个结果是他们因抑郁而产生暴力倾向。
我想调查的是这些因素对每个结果的独立影响，以解释潜在的混杂因素（因为抑郁是众所周知的暴力倾向的诱因，但我想看看这些因素是否会导致即使没有抑郁也会产生暴力倾向）。
我最初在 MANCOVA 和多元线性回归之间争论，但我不确定我应该如何处理这个问题。对所用方法还有其他建议吗？在此先向那些愿意帮助我的人表示感谢。这对我来说意义重大，是一次学习经历。]]></description>
      <guid>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</guid>
      <pubDate>Mon, 23 Sep 2024 02:39:35 GMT</pubDate>
    </item>
    <item>
      <title>如何判断分类变量或变量之间的相互作用是否影响连续结果变量</title>
      <link>https://stats.stackexchange.com/questions/654748/how-to-see-if-a-categorical-variable-or-interactions-between-variables-affects-a</link>
      <description><![CDATA[(1) 通常，如果我有一个非序数的、具有许多唯一值的分类变量 (X)，以及一个连续、高度偏斜（根本不是正态分布）的结果变量，那么应该使用哪种测试或技术来查看是否存在任何关系？
(2) 我正在尝试进行推断研究，目前处于测试每个独立变量对结果连续变量的影响的阶段（然后我将尝试一些方法来测试某些变量之间的相互作用）。我的下一个问题是，我们如何将一个分类变量（例如，已经编码的）和一个连续变量（非正态分布）结合起来，并使用这种相互作用或新创建的特征来查看它如何影响结果变量？
对于第一种情况，我遇到了 Kruskal-Wallis 检验，但仍在努力仔细理解。但是您处理此类案件的经验是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654748/how-to-see-if-a-categorical-variable-or-interactions-between-variables-affects-a</guid>
      <pubDate>Mon, 23 Sep 2024 02:20:55 GMT</pubDate>
    </item>
    <item>
      <title>R 包 aTSA 中的 ARCH-LM 检验统计量</title>
      <link>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</link>
      <description><![CDATA[我想执行 ARCH-LM 测试。首先，我自己计算了 LM 统计量，方法是将平方残差回归为常数和 p 滞后值。根据 Engle (1982)，LM 统计量是 TR^2，其中 T 个观测值和 R^2 作为辅助回归的判定系数。
然后，我尝试了 aTSA 中的 arch.test() 函数，它返回了完全不同的值，行为完全相反。顺序越大，统计量越小。此外，考虑到顺序=自由度、统计量和 p 值的组合，统计量似乎不是卡方分布。以下是我的步骤：
#访问数据

library(yfR)
CVX_data=yf_get(
tickers = &quot;CVX&quot;,
first_date = &quot;2020-01-02&quot;,
last_date = &quot;2021-12-31&quot;)

#计算数据

attach(CVX_data)
close_ln=c(log(price_adjusted))
close_ln_d=c(NA, diff(log(price_adjusted)*100))

#新格式

new_df=data.frame(ref_date, price_adjusted, close_ln, close_ln_d)
new_df_2=new_df[-c(1),]
comp_data=new_df_2[,4]

#内置 ARCH测试

ARM=arima(comp_data, order=c(2,0,0))
library(aTSA)
arch.test(ARM)

#ARCH 测试“手动”

AR=ar(comp_data, aic=FALSE, order.max=2)

uhat2=(AR$resid)^2
obs=length(uhat2)

ch1 &lt;- function(p){
uhat2[-c(obs:(obs-p+1))]
}
ch2 &lt;- function(p){
c(seq(1:p), ch1(p))
}
ch3 &lt;- function(p){
replace(ch2(p), ch2(p)[1:p], NA)
}
ch4 &lt;- function(p){
c(1:p)
}
U &lt;- function(p){
sapply(ch4(p), ch3)
}
reg2 &lt;- function(p){
lm(uhat2 ~ U(p))
}
T &lt;- function(p){
503-2-p
}
R2 &lt;- function(p){
summary(reg2(p))$r.squared
}
Statistic &lt;- function(p){
T(p)*R2(p) 
}
Statistic(2)

有人能解释一下这个差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</guid>
      <pubDate>Mon, 23 Sep 2024 00:30:45 GMT</pubDate>
    </item>
    </channel>
</rss>