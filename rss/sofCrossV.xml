<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 19 Dec 2024 15:18:05 GMT</lastBuildDate>
    <item>
      <title>概率有界于确定性常数表达式</title>
      <link>https://stats.stackexchange.com/questions/658970/bounded-in-probability-with-the-deterministic-constant-expression</link>
      <description><![CDATA[我研究了下面链接中的论文：
https://projecteuclid.org/journals/bernoulli/volume-24/issue-2/Smooth-backfitting-for-additive-modeling-with-small-errors-in-variables/10.3150/16-BEJ898.full
本文中命题1（第1241页）的结果是
\begin{aligned}
\max_{1 \leq i \leq n}|\hat{\xi}^i_{jk}-{\xi}_{jk}^i|=O_p(n^{-(\beta-1)/(2\beta)}), \quad 1\leq j\leq d,1 \leq k \leq L_j, \beta \geq 2.
\end{aligned&gt;
但是，在引理 1（第 1256 页）的证明中，论文是这样陈述的：
我们可以假设 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| \leq C_0 n^{−(\beta−1)/(2\beta)}$
对于某个正常数 $C_0$ ，根据命题 1。
我想知道这是怎么可能的。通常 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| = O_p(n^{−(\beta−1)/(2\beta)})$ 并不意味着 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| \leq C_0 n^{−(\beta−1)/(2\beta)}$。我正在考虑使用$C_0$来定义该事件，概率趋向于一，但我仍然找不到解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/658970/bounded-in-probability-with-the-deterministic-constant-expression</guid>
      <pubDate>Thu, 19 Dec 2024 14:56:38 GMT</pubDate>
    </item>
    <item>
      <title>模拟面板数据时解释间接滞后治疗效应</title>
      <link>https://stats.stackexchange.com/questions/658969/interpreting-indirect-lagged-treatment-effects-when-simulating-panel-data</link>
      <description><![CDATA[考虑以下 DAG，我感兴趣的是估计当前 (X2) 和滞后 (X1) 治疗对 Y2 的影响：

接下来，考虑 DAG 隐含的以下数据生成过程：
library(dplyr)

set.seed(12345)
n &lt;- 2000

dgp2_wide &lt;- tibble(id = 1:n) %&gt;% 
# 创建滞后和当前治疗和结果值
mutate(Z1 = rnorm(n, 0, 1),
X1 = (0.1 * Z1) + rnorm(n, 0, sqrt(0.99)),
Y1 = (0.1 * Z1) + (0.4 * X1) + rnorm(n, 0, sqrt(0.822)),
Z2 = (0.2 * Z1) + (0.4 * X1) + rnorm(n, 0, 1),
X2 = (0.1 * Z2) + (0.4 * X1) + rnorm(n, 0, sqrt(0.5196)),
# X1 对 Y2 的间接影响是什么？
Y2 = (0.2 * Z2) + (0.4 * X2) + (0.4 * Y1) + rnorm(n, 0, sqrt(0.4582)))

我如何确定 X1 的间接影响 -&gt; Y2？X1 导致 Z2 发生一些变化，进而导致 Y2 发生一些变化。我如何确定 X1 对 Y2 的影响，经过 Z2 过滤后如何？
请注意，我并不是在寻求一种估算方法（我现在正在学习边际结构模型）。我想知道如何根据我模拟的信息确定滞后间接效应是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658969/interpreting-indirect-lagged-treatment-effects-when-simulating-panel-data</guid>
      <pubDate>Thu, 19 Dec 2024 14:40:12 GMT</pubDate>
    </item>
    <item>
      <title>曲线拟合 SCILAB/MATHLAB 散度解释</title>
      <link>https://stats.stackexchange.com/questions/658968/curve-fitting-scilab-mathlab-divergence-explenation</link>
      <description><![CDATA[大家下午好，
我正在完成一个研讨会，会上我会得到一组数据。然后我必须预测数据范围之外的未来数据点。
我以图形方式解释数据，并发现它可以用以下类型的正弦函数来近似：
f(t) = Asin(WT + k) + at + b
我编写了代码来执行以下操作：
找到函数参数的粗略初始拟合以确保更快的收敛，然后编写代码使用 L2 范数评估 f(t) 和每个数据点之间的误差幅度。之后，通过递归算法，它将创建一些噪声并评估新噪声参数的误差，并将其与初始拟合进行比较。并确定哪个误差较小，然后继续进行新的拟合。
现在我的问题来了，根据噪音的大小和我运行算法的次数，我会得到荒谬的结果。
在当前模型中，我运行 100 次循环会得到很好的结果，但 1000 次循环的精度会低于初始拟合！此外，如果我从一条线开始，我会发散我输入的任何噪声/迭代。
有没有关于曲线拟合收敛/发散的论文可以读，因为我对这个领域非常陌生。还有谁知道为什么会发生这种情况？
我的代码已经过审查，没有任何逻辑缺陷，但我确实认为我缺乏曲线拟合理论……
以下是使用 PARA 作为初始参数的代码。
function y = MODEL(x, PARA)

y = PARA(1)*sin(A(:,1)&#39;*PARA(2))+PARA(4) + PARA(5)*A(:,1)&#39; + PARA(6)

endfunction

function err = myerror(PARA,A)
B=zeros(size(A,1))
B = PARA(1)*sin(A(:,1)&#39;*PARA(2))+PARA(4) + PARA(5)*A(:,1)&#39; + PARA(6) - A(:,1)&#39;
err = norm(B,2)

endfunction

function NPARA = fit_rand(PARA, A, err, N)
    M = 零(1,N+1)
    
    M(1) = myerror(PARA,A)
    噪音=0.2
    对于 i = 1:N
        我 = 兰特(1,6) - 0.5
        I = I*噪声
        NPARA = PARA + I.*PARA
        M(i+1) = myerror(NPARA,A)
        if (err(NPARA, A) &lt; err(PARA, A)-1)
            帕拉 = 尼帕拉
        结尾
    结尾
    
结束函数
]]></description>
      <guid>https://stats.stackexchange.com/questions/658968/curve-fitting-scilab-mathlab-divergence-explenation</guid>
      <pubDate>Thu, 19 Dec 2024 14:29:32 GMT</pubDate>
    </item>
    <item>
      <title>具有多个预测变量的 OLS 模型的成对检验</title>
      <link>https://stats.stackexchange.com/questions/658967/pairwise-tests-for-ols-model-with-multiple-predictors</link>
      <description><![CDATA[我想请教以下问题：
我的 LR 模型 ols(formula=&quot;Income~ Major + Experience&quot;)，其中 Major 是分类预测因子，而 Experience 是尺度预测因子。
这两个预测因子都很重要，我想知道分类预测因子在哪些层面上有所不同。
问题是，经典的 Python 事后检验不会根据其他预测因子的贡献进行固有调整，而是仅基于正在检查的预测因子。
我只找到了 statsmodels.regression.linear_model.OLSResults.t_test_pairwise，但我不确定它在存在交互的情况下如何工作。
有人能告诉我在具有多个预测因子（有和没有交互）的 OLS 模型中进行成对测试的最佳方法是什么吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658967/pairwise-tests-for-ols-model-with-multiple-predictors</guid>
      <pubDate>Thu, 19 Dec 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中的部分合并过程中，聚类估计值消失或超出总体估计值</title>
      <link>https://stats.stackexchange.com/questions/658964/cluster-estimates-going-away-or-beyond-grand-estimates-during-partial-pooling-in</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/cluster-estimates-going-away-or-beyond-grand-estimates-during-partial-pooling-in</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>我得到的部分 McFadden 伪 R^2 为负数。这可能吗？</title>
      <link>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</link>
      <description><![CDATA[对于 R 中的逻辑回归，我尝试分别计算一个预测变量的 McFadden 偏 R 平方。我使用了以下代码，该代码来自这个问题：如何计算 R 中仅一个变量的 McFadden r 平方？
model1 &lt;- glm(Q22_factor ~ Q24_1 + age, family = &quot;binomial&quot;, data = subset_data&quot;)
model_age &lt;- glm(Q22_factor ~ age, family = &quot;binomial&quot;, data = subset_data)

loss_full &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model1, type = &quot;response&quot;)
)

loss_reduced &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model_age, type = &quot;response&quot;)
)
(loss_reduced - loss_full)/(loss_reduced)

在我的数据上使用此代码，我得到了负结果 (-0.269)。有人知道这是否可能，或者我的代码是否出了什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</guid>
      <pubDate>Thu, 19 Dec 2024 12:32:24 GMT</pubDate>
    </item>
    <item>
      <title>藤蔓系动词的三维密度图[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658961/3d-density-plot-for-vine-copula</link>
      <description><![CDATA[有人可以分享 R 代码或命令来绘制 Vine Copula 的 3D 密度图吗？就我而言，VineCopula 包中的代码或命令仅涵盖双变量 3D 图。如何继续绘制 2 级、3 级和 4 级的 3D 密度图？]]></description>
      <guid>https://stats.stackexchange.com/questions/658961/3d-density-plot-for-vine-copula</guid>
      <pubDate>Thu, 19 Dec 2024 11:31:48 GMT</pubDate>
    </item>
    <item>
      <title>具有（非平方）L2 惩罚的正则化属性</title>
      <link>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</link>
      <description><![CDATA[我一直在寻找有关线性回归设置中 L2 范数惩罚的正则化属性的资料。我的意思是，例如，当使用 L2 范数而不是平方 L2 范数作为惩罚时的收缩属性（所以我不是在谈论岭回归）。我正在思考的问题如下：
$$
min_{\beta} \frac{1}{n}\|y - X\beta\|_2^2 + \lambda\|\beta\|_2,
$$
其中 $\beta$ 是实数向量，$X$ 是实数矩阵，$y$ 是实数向量，$\lambda$ 是正实数标量。
有谁知道关于这个问题的正则化性质的讨论好的资料吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</guid>
      <pubDate>Thu, 19 Dec 2024 11:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Python中的线性规划优化问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658959/linear-programming-optimization-problem-in-python</link>
      <description><![CDATA[我有以下 pandas 数据框，它代表 10 个人 (ids) 7 天的消费情况（day_0 是今天，day_-1 是昨天等）：
import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randint(8, 15, size=(10, 7)))
df.columns = [&#39;day_0&#39;, &#39;day_-1&#39;, &#39;day_-2&#39;, &#39;day_-3&#39;, &#39;day_-4&#39;, &#39;day_-5&#39;, &#39;day_-6&#39;]
df.index.name = &#39;id&#39;

print(df.reset_index())

id day_0 day_-1 day_-2 day_-3 day_-4 day_-5 day_-6
0 0 10 10 14 8 14 14 14
1 1 10 13 11 11 8 10 10
2 2 10 12 9 12 9 10 10
3 3 12 12 9 11 9 12 13
4 4 12 13 8 12 8 11 9
5 5 13 9 8 13 9 12 10
6 6 8 9 8 14 8 13 14
7 7 13 10 14 12 8 9 11
8 8 8 8 10 12 11 14 14
9 9 14 13 13 9 11 14 13

我想查找每日体重（因此总共有 7 个权重：w_0、w_-1、w_-2、w_-3、w_-4、w_-5、w_-6），它们需要具有以下属性：

w_0 &gt; w_-1 &gt; w_-2 &gt; ... &gt; w_-6 &gt; 0
w_0 + w_-1 + w_-2 + ... + w_-6 = 7
10 个 ids 中 恰好 k 个的加权平均值严格高于阈值（例如 11）

我可以实现先决条件 1 和2 通过使用指数衰减函数并随后进行规范化：
import numpy as np

n = 7

_lambda = 0.5

# 使用指数衰减计算权重
weights = np.exp(-_lambda * np.arange(n))

# 对权重进行规范化，使它们的总和等于时间序列的长度
weights *= n / np.sum(weights)

但我不知道如何应用先决条件 3。
这可能吗？我如何在 python 中做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658959/linear-programming-optimization-problem-in-python</guid>
      <pubDate>Thu, 19 Dec 2024 09:21:55 GMT</pubDate>
    </item>
    <item>
      <title>X-meta 学习器和 CATE 估计器</title>
      <link>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</link>
      <description><![CDATA[在 X-learner 中，使用适当的模型估算治疗样本和对照样本（使用对照样本估算治疗样本响应，反之亦然）。
然后使用两个模型来估计 CATE，每组估算值一个模型（通常使用倾向得分组合）。我添加了从 Kunzel 等人 2019 年获得的 X-learner 伪代码。

为什么我们使用单独的 CATE 模型？为什么不将所有估算结果组合起来并拟合单个模型（例如，使用逆倾向对观察结果进行加权）。有没有探讨这个想法的作品？]]></description>
      <guid>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</guid>
      <pubDate>Thu, 19 Dec 2024 08:55:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 MERF 进行超参数调整不起作用 - fit 函数仅接受两个参数，但函数需要更多</title>
      <link>https://stats.stackexchange.com/questions/658956/hyperparameter-tuning-with-merf-doesnt-work-fit-function-only-takes-two-argume</link>
      <description><![CDATA[我正在尝试使用混合效应随机森林 (MERF) 执行嵌套交叉验证。但是，我遇到了一个问题：RandomizedSearchCV 的拟合函数仅接受两个参数（X 和 y），而 MERF 模型需要四个参数（X、Z、cluster 和 y）。
这种差异使我无法成功实施嵌套交叉验证。有人对如何修改工作流程以适应向 fit 函数传递两个以上参数有什么建议吗？
model = MERF()
search = RandomizedSearchCV(model, random_grid, n_iter=10, cv=inner_cv, refit=True,scoring = &#39;r2&#39;, n_jobs=-1,random_state=42)
result = search.fit(X= X_train, Z=Z_values_train, clusters=ID_train,y=y_train)]]></description>
      <guid>https://stats.stackexchange.com/questions/658956/hyperparameter-tuning-with-merf-doesnt-work-fit-function-only-takes-two-argume</guid>
      <pubDate>Thu, 19 Dec 2024 08:51:19 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中使用 Loess 平滑变量与其他预测因子</title>
      <link>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</link>
      <description><![CDATA[我正在运行一个普通最小二乘回归分析，其中有 9 个预测变量，2 个数值变量，5 个二进制 (1/0) 变量和 2 个分类变量。我的一个预测变量 (pred3) 与响应具有明显的非线性关系，如所附散点图所示。我拟合了一个线性模型，没有转换任何预测变量，并得到了 $R^2$ 值为 0.57。我希望我的模型具有较高的 $R^2$ 值。如果可能的话，我想避免交互项。为了解释 pred 3 和响应之间的非线性关系，我遵循了 ChatGPT 的建议，其中我拟合了一个形式为 pred3 ~ response 的 loess 平滑模型，然后在 lm() 模型语句中使用了 pred3 的 loess 预测值（参见下面的代码片段）。这导致 $R^2$ 值为 0.95。但是，我并不完全确定这是否是预测我的反应的有效方法。有人同意这个想法或有什么建议吗？我尝试过使用广义加性模型和多项式模型，但它们似乎并没有改善我的模型拟合度。请让我知道！
loess_fit=loess(pred3 ~ response,data=data)
loess_pred3=predict(loess_fit)
model=lm(response ~ pred1+pred2+loess_pred3+pred4+pred5+pred6+pred7+pred8+pred9,data=data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</guid>
      <pubDate>Thu, 19 Dec 2024 06:24:15 GMT</pubDate>
    </item>
    <item>
      <title>轻松理解混合模型中聚类变量和随机变量之间的区别</title>
      <link>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</link>
      <description><![CDATA[假设我们有一个数据集，其中我们根据社会经济地位对一系列不同学校的数学成绩分数进行建模。使用 lme4 的适当模型将是：
lmer(math~ses + (ses | school), data=d)
我的学生经常混淆 ses 和 school 的位置。为了解决这个问题，我制作了一个 YouTube 视频，帮助学生识别他们的“聚类变量”。该视频为他们提供了三条规则来帮助识别他们的聚类变量：

这个变量在您的数据集中是否经常重复出现？（聚类变量将重复出现）
这个变量是否识别一个人？ （如果是，那就是您的聚类变量，跳过 #3）
此变量是否表示特定组？（如果是，那就是您的聚类变量）

对于此示例，学校将被重复（该学校的每个学生一行），它不会识别特定的人，但会识别特定的组。
我对我的解释一直不太满意，因为它留下了一些歧义。让我们修改示例以使我的规则失败。假设我们正在预测数学成绩，但这次，我们想添加种族作为预测因素。合适的模型可以是：
lmer(math~ses + ethnicity + (ses + ethnicity | school), data=d)
（假设 ses 和 ethnicity 的斜率实际上因学校而异）。
这个例子的问题是学生会感到困惑，特别是如果数据集尚未按学校排序。ethnicity 和 school 都符合标准：两者都重复，都不能识别一个人，并且都表示一个“群体”。当他们问为什么 ethnicity 不是时，我有点不知道如何解释为什么 ethnicity 不是一个群体。
关于如何使差异更具体，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</guid>
      <pubDate>Wed, 18 Dec 2024 15:33:06 GMT</pubDate>
    </item>
    <item>
      <title>调整超参数以尽量减少过度拟合时的目标应该是什么？</title>
      <link>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</link>
      <description><![CDATA[我正在研究一个包含约 90k 行数据和 12 个特征的分类问题。我正在尝试调整 XGBoost 模型的超参数以尽量减少过度拟合。我使用 ROC_AUC 作为评估模型性能的指标。使用默认的 XGBoost 参数，5 倍 CV 结果分别显示训练 auc 为 0.782 和测试 auc 为 0.739。这表明过度拟合，因为训练集的表现优于测试集。
我开始调整超参数，因为 a) 应该调整，b) 已知超参数可用于减少过度拟合。但是，像许多其他人一样，我将验证 auc 设置为目标，并在目标函数中实现交叉验证。使用的库是 Optuna 和 Hyperopt。有趣的是，对于这两种情况，我发现当算法试图将验证 auc 推向 0.745 时，训练测试 auc 差距（过度拟合指标）会扩大。如果我按验证 auc 降序绘制训练和验证 auc，验证 auc 会从 0.745 降至 0.729，而训练 auc 会从 0.868 降至 0.742。
我对结果感到很困惑。我将验证 auc 设置为 Optuna 优化的目标是否正确？我是否应该选择（训练 auc - 验证 auc），但我在网上没有找到类似的例子。而且我是否应该查看结果并选择最低的验证 auc 和相关的超参数值作为“最佳参数”，因为训练验证指标差距最小？
请在这里分享您的想法，因为在我输入时，我不确定我对过度拟合的理解是否正确。
我的代码：
X, y = df[features], df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 42, stratify = y)
dtrain = xgb.DMatrix(X_train, label = y_train, enable_categorical = True)
dtest = xgb.DMatrix(X_test, label = y_test, enable_categorical = True)

def objective(trial):

params = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 3, 10),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 100),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0, 2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.5, 1),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.5, 1),
&#39;reg_alpha&#39;: trial.suggest_float(&#39;reg_alpha&#39;, 1e-8, 10, log = True),
&#39;reg_lambda&#39;: trial.suggest_float(&#39;reg_lambda&#39;, 1e-8, 10, log = True),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.001, 0.3),
&#39;objective&#39;: &#39;binary:logistic&#39;}

cv_results = xgb.cv(
params, dtrain, num_boost_round = 10000, early_stopping_rounds = 50, 
metrics = &#39;auc&#39;, nfold = 5, stratified = True, shuffle = False
)

trial.set_user_attr(&#39;n_estimators&#39;, len(cv_results))
trial.set_user_attr(&#39;train-auc&#39;, cv_results[&#39;train-auc-mean&#39;].iloc[-1])

return cv_results[&#39;test-auc-mean&#39;].iloc[-1]

study = optuna.create_study(
direction =&#39;maximize&#39;, sampler = optuna.samplers.TPESampler(seed = 42))

study.optimize(objective, n_trials = 500, n_jobs = -1)


]]></description>
      <guid>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</guid>
      <pubDate>Wed, 18 Dec 2024 09:28:26 GMT</pubDate>
    </item>
    <item>
      <title>针对群体数据/种族数据的最自然机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级大小 学生编号 智商 小时数 分数 前几名
1 3 3 101 10 98 1
1 3 4 99 19 80 0
1 3 6 130 3 95 0
2 5 4 93 5 50 0
2 5 5 103 9 88 0
2 5 8 112 12 99 0
2 5 1 200 10 100 1
2 5 2 90 19 78 0
3 2 5 100 12 84 0
3 2 7 102 13 88 1

我想建立一个机器学习模型，试图预测谁将成为前几名对于任何给定的 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征，计算班级（即具有最高 Score 的学生）的得分。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中得分最高的概率。
这是我尝试过的：

最简单的方法是对 Score 使用回归，然后确定谁将在班级中取得最高分数。这种方法的问题在于，它不会产生谁最有可能在任何给定类别中获得最高分数的概率。

由于这是一个排名问题，因此自然的学习模型类别是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性分数 列表，而不是概率列表，概率列表在概率方面没有自然解释。


解决这个问题的一个明显方法是在 xgboost 中的相关性分数上应用 softmax，但没有直接有意义的概率解释，如基于能量的模型（如 RBM 的能量函数）。事实上，我曾尝试过这样做，但概率变得非常极端（大多数概率集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是Top上的分类模型，如逻辑回归/决策树。但是，这种方法有两个主要问题。

首先，将每个学生视为训练样本不是一个好方法，因为例如，同一个班级可能有两个非常聪明（高智商）和勤奋（高小时数）的学生，如果很多班级都有很多这样的学生，那么传统的模型（如基于逻辑/树的模型）可能会难以进行训练。
为了解决上述将单个学生视为训练样本的问题，我们可以将每个班级视为一个训练样本。为此，我们“扁平化”我们的数据集并对 Top 进行多类分类：
Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 Hours_1 Hours_2 Hours_3 Hours_4 Hours_5 Score_1 Score_2 Score_3 Score_4 Score_5 Top
1 3 101 99 130 NaN NaN 10 19 3 NaN NaN 98 80 95 NaN NaN 3 
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78 1
3 2 100 102 NaN NaN NaN 12 13 NaN NaN NaN 84 88 NaN NaN NaN 7

这种方法的问题在于，数字每个班级的学生人数不同，因此特征矩阵变得非常稀疏（因为不同班级的学生人数可能非常不同）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</guid>
      <pubDate>Tue, 17 Dec 2024 11:40:53 GMT</pubDate>
    </item>
    </channel>
</rss>