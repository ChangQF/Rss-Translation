<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 24 Jul 2024 09:16:04 GMT</lastBuildDate>
    <item>
      <title>均匀先验和泊松似然，会产生什么后验分布？</title>
      <link>https://stats.stackexchange.com/questions/651660/uniform-prior-and-poisson-likelihood-what-posterior-distribution-will-be-produc</link>
      <description><![CDATA[如果我有一个固定指定和有限范围内的均匀分布以及泊松似然分布，那么会产生什么后验？]]></description>
      <guid>https://stats.stackexchange.com/questions/651660/uniform-prior-and-poisson-likelihood-what-posterior-distribution-will-be-produc</guid>
      <pubDate>Wed, 24 Jul 2024 08:45:11 GMT</pubDate>
    </item>
    <item>
      <title>在医学研究中是否有可能从真实数据生成数据？</title>
      <link>https://stats.stackexchange.com/questions/651658/would-it-be-possible-to-generate-data-from-real-data-in-medical-research</link>
      <description><![CDATA[我们正在尝试开发一些医学研究中的预测模型。我们仅针对 40 名患者就拥有临床和 RNA-seq 数据的组合。问题在于分类。在特征选择之后，我们从真实数据中生成数据，然后将合成数据添加到真实数据中进行分析。结果变得更好。我们还检查了合成数据与真实数据的密度（参见附件）。看起来不错。我们的方法正确吗？在这种情况下生成数据的方法正确吗？如果是，我们应该在特征选择之后还是之前生成数据？
提前感谢您的帮助和时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/651658/would-it-be-possible-to-generate-data-from-real-data-in-medical-research</guid>
      <pubDate>Wed, 24 Jul 2024 08:30:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元前馈神经网络中的 S 型输出层表示正类（标签 = 1）的概率？</title>
      <link>https://stats.stackexchange.com/questions/651657/why-does-the-sigmoid-output-layer-in-a-binary-feedforward-neural-network-represe</link>
      <description><![CDATA[我是一个刚开始学习深度学习的初学者，最近了解到，在具有二值输出和伯努利分布的前馈神经网络中，sigmoid函数的输出表示标签为1的概率。`我很好奇为什么不能反过来（标签为0的概率），只是为了方便吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651657/why-does-the-sigmoid-output-layer-in-a-binary-feedforward-neural-network-represe</guid>
      <pubDate>Wed, 24 Jul 2024 08:12:27 GMT</pubDate>
    </item>
    <item>
      <title>“奇怪”数据的预测方法是什么</title>
      <link>https://stats.stackexchange.com/questions/651656/what-is-the-forecasting-approach-about-weird-data</link>
      <description><![CDATA[我有一个每小时时间序列数据集，包含 4000 行和 3 列（它们也是我的目标列）。我试图使用 XGBoost 来预测未来。我使用过 ARIMA-SARIMA-ETS，但无济于事。主要问题是我的数据显示出我以前从未见过的不规则、奇怪的模式。它给出了非常高的 RMSE 分数，MAE 给出了相对更好的结果。下面是我的一列的 STL 分解图。

我应该怎么做？按 d=1 进行差分？使用不同的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/651656/what-is-the-forecasting-approach-about-weird-data</guid>
      <pubDate>Wed, 24 Jul 2024 08:09:30 GMT</pubDate>
    </item>
    <item>
      <title>参数模型误差分析</title>
      <link>https://stats.stackexchange.com/questions/651655/error-analysis-of-parametric-model</link>
      <description><![CDATA[我有这个模型：
$$
u =\frac{x}{V_x}
$$
假设我知道$V_x = 0.02$和$x \in [0,1]$我想分析这个方程对噪声的敏感度。
我通过在区间 [0,1] 上选择 N 个线性间隔的点$x_i$并计算相应的 u 值来实现此目的。
接下来，我将正态分布的噪声添加到 x 和 u 值：
$$
xn = x + N(0,\sigma_x)
$$
$$
un = u + N(0,\sigma_u)
$$
接下来，我估计 $V_x$：
$$
\hat{V_x} =\frac{xn}{un}
$$
我使用最小二乘法 ($\texttt{numpy.polyfit(xn, un, 1)}$) 找到我的估计值 $\hat{V_x}$。
作为估计值好坏的衡量标准 $\hat{V_x}$ 是我引入的错误：
$$
\epsilon(x) = \hat{u} - u = \frac{x}{\hat{V_x}} - \frac{x}{V_x} = x(\frac{1}{\hat{V_x}} - \frac{1}{V_x})
$$
定义：
$$
\alpha := \frac{1}{\hat{V_x}} - \frac{1}{V_x}
$$
我正在寻找界限：$\alpha \in [\alpha_{min}(\sigma_x,\sigma_u,N),\alpha_{max}(\sigma_x,\sigma_u,N)]$
置信度为 95%。
$\alpha(\sigma_x,\sigma_u,N)$ 分布的解析表达式也很有趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/651655/error-analysis-of-parametric-model</guid>
      <pubDate>Wed, 24 Jul 2024 07:56:54 GMT</pubDate>
    </item>
    <item>
      <title>平均准确率与平均召回率</title>
      <link>https://stats.stackexchange.com/questions/651654/average-precision-vs-average-recall</link>
      <description><![CDATA[物体检测有两个常用指标：平均准确率和平均召回率。你能举例说明一下哪些情况需要使用 AP，哪些情况需要使用 AR 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651654/average-precision-vs-average-recall</guid>
      <pubDate>Wed, 24 Jul 2024 07:47:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在逐步选择过程中应用Bonferroni校正方法？</title>
      <link>https://stats.stackexchange.com/questions/651653/how-to-apply-bonferroni-correction-method-in-step-wise-selection-process</link>
      <description><![CDATA[为了清晰起见，让我用一个容易理解的例子来提供这个问题。
我有 4 种表型（响应变量），因此有 4 种不同的模型。每个模型都分别经过逐步选择过程，以选择最重要的模型组件。假设我们在 10 个（公共）独立变量中分别在模型 1 中选择了 3 个独立变量，在模型 2 中选择了 5 个独立变量，在模型 3 中选择了 2 个独立变量，在模型 4 中选择了 5 个独立变量。

当我对整个设置应用 Bonferroni 校正时，我需要将 alpha（显着性水平）除以 4 还是 10 还是 4*10=40 或任何其他数字？为什么？

请提供在逐步回归模型上应用此类 Bonferroni 校正方法的参考资料。

在这种情况下，我是否可以说 Bonferroni 校正是不必要的，因为它已经从选择程序中过滤掉了，因此不太可能出现假阳性？


请提供意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/651653/how-to-apply-bonferroni-correction-method-in-step-wise-selection-process</guid>
      <pubDate>Wed, 24 Jul 2024 07:23:19 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯规则与先验分布查询</title>
      <link>https://stats.stackexchange.com/questions/651649/bayes-rule-and-prior-distribution-query</link>
      <description><![CDATA[以下内容取自一篇研究论文（第 2 页）：
假设我们已经将一个连续随机变量$\theta$离散化，使得$\theta_1,...,\theta_d \in [0, \pi]$。然后，我们得到贝叶斯规则给出的后验分布
$$P(\theta_j|\mu) = \frac{P(\mu|\theta_j)P(\theta_j)}{P(\mu)},$$
其中 $\sum_{i}^{d}P(\theta_j|\mu)\delta \theta = 1$ 和 $\delta \theta = \theta_d/(d-1)$。
我们根据其定义计算先验$P(\theta_j)$，即边际分布$P(\theta_j) = \sum_\mu P(\theta_j|\mu)P(\mu)$，其总和涵盖所有可能的测量结果$\mu$（假设为离散随机变量）。由于 $P(\mu)$ 也是未知的，我们可以通过再次插入边际表达式 $P(\mu) = \sum_{k=1}^{d-1}P(\mu|\theta_k)P(\theta_k) \delta \theta$ 来消除它，从而得到隐式积分方程
$$P(\theta_j) = \sum_{\mu}P(\theta_j|\mu)\sum_{k=1}^{d}P(\mu|\theta_k)P(\theta_k)\delta \theta$$
我的问题是，为什么求和极限从 $d-1$ 变为 $P(\mu)$ 到 $d$ 的最终方程式 $P(\theta_j)$ 中？我猜最终方程式中的求和极限也应该是 $d-1$？
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651649/bayes-rule-and-prior-distribution-query</guid>
      <pubDate>Wed, 24 Jul 2024 05:46:07 GMT</pubDate>
    </item>
    <item>
      <title>算法应该进行多少次迭代才能超过其平均迭代次数？</title>
      <link>https://stats.stackexchange.com/questions/651647/how-many-iterations-should-an-algorithm-go-over-its-average-number-of-iterations</link>
      <description><![CDATA[简介。Pollard 的 Rho 是一种因式分解算法。给定一个整数（例如 $77$），它将该整数拆分为两个因数。在本例中，如果成功，它将 $77$ 拆分为 $(7, 11)$。这是一种概率算法。如果失败，您可以随时重新启动它，更改方法的随机输入，但保持要分解的整数不变，以便该方法最终拆分整数。
有一个启发式论点，表明该方法拆分 $N$ 所需的迭代次数为 $\sqrt[4]{N}$ 平均。
问题。考虑该方法的实现，计算它执行了多少次迭代。当它接近 $\sqrt[4]{N}$ 次迭代时，我们可以说它（平均而言）正在接近所需的答案。但是，由于该方法在某些情况下可能永远找不到答案，因此如果它尚未找到正确答案，我们也需要在某个时候停止它。我见过的实现都是随意设定一个限制，没有任何数学或统计论据。如何正确选择这个限制？
我对概率和统计学知之甚少，但我的一点知识告诉我，我可以从成功概率的角度回答这个问题。假设我希望算法在一定大小的数字中成功率为 95%。我必须了解该方法的哪些内容才能确定何时停止该方法，放弃该整数？]]></description>
      <guid>https://stats.stackexchange.com/questions/651647/how-many-iterations-should-an-algorithm-go-over-its-average-number-of-iterations</guid>
      <pubDate>Wed, 24 Jul 2024 02:39:21 GMT</pubDate>
    </item>
    <item>
      <title>我们如何处理包含与零假设和备择假设一致的值的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/651644/how-do-we-deal-with-confidence-intervals-containing-values-that-are-consistent-w</link>
      <description><![CDATA[例如，假设在测试对照组和治疗组之间某些测量值的均值是否存在显著差异时，我观察到均值差异为 0.5，这表明治疗可能产生了效果。95% 置信区间为 (-1, 1)。
我对这个结果的解释是，由于 CI 包含 0，因此我不能拒绝零假设（均值无差异）。
但是，到目前为止，我只找到了一些例子和解释，如果 CI 包含 0，则它不包含观察值，反之亦然。我现在想知道，如果 CI 同时包含 0 和 观察值（如我的例子所示），是否会改变解释，暗示数据的一些有趣质量，需要进一步测试等。
（相反，如果 CI 不包含这两个值，该怎么办？）]]></description>
      <guid>https://stats.stackexchange.com/questions/651644/how-do-we-deal-with-confidence-intervals-containing-values-that-are-consistent-w</guid>
      <pubDate>Wed, 24 Jul 2024 00:33:47 GMT</pubDate>
    </item>
    <item>
      <title>如何将一个模型（标准曲线）的后验预测用作另一个模型的结果变量？</title>
      <link>https://stats.stackexchange.com/questions/651642/how-to-use-posterior-predictions-from-one-model-standard-curve-as-an-outcome-v</link>
      <description><![CDATA[我正在处理一个数据集，该数据集涉及混合物中大量不同化合物的浓度，使用贝叶斯方法（使用 R 中的 brms）。测量化合物的仪器记录具有特定高度的峰，其中峰高与浓度相关。每种化合物都有不同的（未知的）浓度~峰高关系，因此我们使用标准（已知浓度）来尝试推导这种关系，以便后续估计浓度。因此，在给定的实验处理中，我可以读取测量的峰高并推断该化合物的浓度。然后，在第二个模型中，我想使用实验独立变量作为化合物浓度的预测因子。因为预测化合物浓度存在一些显著的不确定性，所以我想在第二个模型中准确地表示这一点。
因此，举一个例子来说明我的代码如何查找单个化合物的标准曲线：
#dummy standard data
standards = tibble(concentration = c(0.1, 0.25, 0.5, 0.75, 1),
peak = c(1,6, 12, 16, 25))

mod = brm(data =standards,
family = lognormal(link = &quot;identity&quot;),
density ~ peak,
prior = c(prior(normal(0, 1), class = &quot;Intercept&quot;),
prior(normal(0, 0.5), class = &quot;b&quot;),
prior(exponential(0.5), class = &quot;sigma&quot;)),
iter = 2000, warmup = 1000，链 = 4，核心 = 4)

然后，有了这个模型，我知道我可以用 posterior_predict() 插入新数据，并生成化学物质浓度的后验预测。这本质上是给我们测量误差，但它不一定是参数分布。那么我如何在第二个模型中使用这个预测呢？我希望能够使用另一个连续预测器（即 pH）在每种化合物中做到这一点，并且也能跨化合物做到这一点。我正在为单个化合物设想类似的东西：
#简化单个化合物的虚拟数据
experiment = tibble(pH = c(1, 3, 5, 7, 9),
peak = c(2, 4, 6, 9 , 15))

mod2 = brm(data = experiment,
family = lognormal(link = &quot;identity&quot;),
***posterior_predict(mod, experiment$peak) ~ pH,
Prior = c(prior(normal(0, 1), class = &quot;Intercept&quot;),
Prior(normal(0, 0.5), class = &quot;b&quot;),
Prior(exponential(0.5), class = &quot;sigma&quot;)),
iter = 2000, warmup = 1000, chains = 4, cores = 4)

在化合物中，每种化合物都会有一个不同的化合物特定模型，根据新数据告知其后验预测分布，所以我也不确定如何指定它。但最终我想建立一个类似于上面的mod2的模型，可以比较不同的化合物，其中浓度（因变量）来自第一个标准曲线模型中的后验预测，我可以使用化合物的属性（如分子量）作为独立变量。我可以在新模型中使用posterior_predict()中的后验绘图作为数据吗？或者有没有更好的方法将所有这些指定为单个多级模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/651642/how-to-use-posterior-predictions-from-one-model-standard-curve-as-an-outcome-v</guid>
      <pubDate>Wed, 24 Jul 2024 00:06:16 GMT</pubDate>
    </item>
    <item>
      <title>1 vs 2 源检测似然比检验的零分布</title>
      <link>https://stats.stackexchange.com/questions/651640/null-distribution-for-1-vs-2-source-detection-likelihood-ratio-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651640/null-distribution-for-1-vs-2-source-detection-likelihood-ratio-test</guid>
      <pubDate>Tue, 23 Jul 2024 23:59:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的 copula 生成的多变量数据没有表现出预先指定的相关性？</title>
      <link>https://stats.stackexchange.com/questions/651626/why-does-the-multivariate-data-generated-by-a-copula-in-r-not-exhibit-the-prespe</link>
      <description><![CDATA[我正在使用 R 中的包 copula 生成双变量样本。边际分布为二项式分布（p=0.5）和指数分布（rate=1）。在预先指定的 rho=0.5 的情况下，我生成的数据仅具有 0.35 的相关性；实际上，当我改变rho的值时，我发现样本相关性始终是预先指定的rho的70％。
代码如下所示：
library(copula)
library(MASS)
library(psych)

rho = 0.5
cop_control &lt;- normalCopula(param = rho, dim = 2)
bi_control &lt;- mvdc(copula=cop_control, margins=c(&quot;binom&quot;, &quot;exp&quot;),
paramMargins=list(list(size=1, prob=0.5),list(rate=1)))
u_control &lt;- rMvdc(5000, bi_control)
colnames(u_control) &lt;- c(&quot;x1&quot;, &quot;x2&quot;)
pairs.panels(u_control)

copula 双变量分布的样本难道不应该具有预先指定的相关性吗？
我应该如何更改代码以准确采样？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651626/why-does-the-multivariate-data-generated-by-a-copula-in-r-not-exhibit-the-prespe</guid>
      <pubDate>Tue, 23 Jul 2024 20:50:31 GMT</pubDate>
    </item>
    <item>
      <title>用得分函数写出 Kullback–Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/651590/writing-kullback-leibler-divergence-in-terms-of-the-score-function</link>
      <description><![CDATA[假设我们有两个密度函数$p(x)$和$p&#39;(x)$，其中$x\in R^d$。
我会根据对数密度梯度之间的差异，发现两个密度之间的 Kullback–Leibler 散度之间存在联系：$\nabla_{x} \log p(x)$和$\nabla_{x} \log p&#39;(x)$。
类似于
$$\int p(x)\log\frac{p(x)}{p&#39;(x)}dx\le \frac{1}{2}E_{x}||\nabla_{x} \log p(x)-\nabla_{x} \log p&#39;(x)||_2^2.$$
有人能帮我吗？我已经尝试过开始定义 KL，然后分部分积分，但我在某些点卡住了。]]></description>
      <guid>https://stats.stackexchange.com/questions/651590/writing-kullback-leibler-divergence-in-terms-of-the-score-function</guid>
      <pubDate>Tue, 23 Jul 2024 13:06:49 GMT</pubDate>
    </item>
    <item>
      <title>通过拉普拉斯变换证明 mgf 确定分布</title>
      <link>https://stats.stackexchange.com/questions/651587/proving-that-mgf-determines-distribution-via-laplace-transform</link>
      <description><![CDATA[我正在阅读这个问题以及那里提供的关于矩生成函数 (mgf) 的答案，以及如何通过拉普拉斯变换的唯一性来证明其唯一性。在我的书测度理论、概率和随机过程（作者：Le Gall）中，证明了非负随机变量的拉普拉斯变换的唯一性，但我真的很难理解如何将这个结果扩展到任意符号的随机变量，即 mgf（实际上是一个双面拉普拉斯变换）决定了 $X$ 的定律。
我认为链接帖子中的答案做出了错误的陈述。答案声称

$$M_X(-t)=\mathcal{L}\{f(x)\}(t)+\mathcal{L}\{f(-x)\}(-t),$$且 $M_X(t)$ 是唯一的当且仅当 $\mathcal{L}\{f(x)\}(t)$ 和 $\mathcal{L}\{f(-x)\}(-t)$ 都是唯一的。

但加法不是单射。假设$Y$的密度为$g(x)$。如果 $M_X(-t)=M_Y(-t)$ 且其中 $|t|&lt;h$ 其中 $h&gt;0$，且如果 $F(t)=\mathcal{L}\{f(x)\}(t)$，$G(t)=\mathcal{L}\{f(-x)\}(-t)$，$H(t)=\mathcal{L}\{g(x)\}(t)$ 且 $K(t)=\mathcal{L}\{g(-x)\}(-t)$，然后$$F(t)+G(t)=H(t)+K(t)\rlap{\ \quad\not\ }\implies F(t)=H(t),G(t)=K(t),$$所以看起来我们不能使用拉普拉斯变换的唯一性来得出这样的结论：$f(x)=g(x)$和$f(-x)=g(-x)$在$x&gt;0$上，所以$f(x)=g(x)$。
我的推理正确吗？还是我误解了什么？例如Casella 和 Berger 也将这个结果称为拉普拉斯变换理论的结果，但我不明白上面引用的陈述如何正确，也不知道如何证明 mgf 决定了 $X$ 的定律，因为我们知道单边拉普拉斯变换决定了 $X$ 的定律。]]></description>
      <guid>https://stats.stackexchange.com/questions/651587/proving-that-mgf-determines-distribution-via-laplace-transform</guid>
      <pubDate>Tue, 23 Jul 2024 12:04:15 GMT</pubDate>
    </item>
    </channel>
</rss>