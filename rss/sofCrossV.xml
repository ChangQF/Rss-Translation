<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 06 Mar 2025 03:28:17 GMT</lastBuildDate>
    <item>
      <title>当比例中的分母也有不确定性时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662243/what-to-do-when-the-denominator-in-a-proportion-also-has-uncertainty</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662243/what-to-do-when-the-denominator-in-a-proportion-also-has-uncertainty</guid>
      <pubDate>Thu, 06 Mar 2025 02:02:53 GMT</pubDate>
    </item>
    <item>
      <title>如何处理这个非常非正常的响应变量？</title>
      <link>https://stats.stackexchange.com/questions/662239/how-do-i-handle-this-very-non-normal-response-variable</link>
      <description><![CDATA[在R中，我想使用重复的测量分析与混合回归模型分析我的响应变量的平均值（平均蜜蜂授粉评分）如何根据1）而变化，因为1）周，2）蜂巢数量，3）杀菌剂剂量，4）4）剂量剂量的昆虫剂 +位置的随机效应。
这是我最初认为写模型的方式：
  mod＆lt;  -  lmer（平均〜周 +蜂箱 +杀菌剂 +杀虫剂 + 
            （1 |位置），data = pp22_wide） 
 
问题是我的响应变量“平均”实际上并不像连续价值，而是离散变量也不是。它在1543个数据点中只有5个唯一值。
  unique（pp22_wide $均值）
1.50 2.75 3.00 1.25 2.50

长度（pp22_wide $均值）
1543年 
 
因此，您可以想象它不是正态分布的，因此不符合我的模型假设，我不能相信模型输出，因为它不合适。我尝试在日志刻度上进行转换，取平方根或立体，这无助于使我的数据更正态分布。
建议我如何处理这个或应该运行哪种模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/662239/how-do-i-handle-this-very-non-normal-response-variable</guid>
      <pubDate>Wed, 05 Mar 2025 20:59:57 GMT</pubDate>
    </item>
    <item>
      <title>当iv和DV之间的二次关系时，用于持续变量的统计能力分析</title>
      <link>https://stats.stackexchange.com/questions/662238/statistical-power-analyss-for-moderation-of-continious-variables-when-a-quadric</link>
      <description><![CDATA[当IV和DV之间具有连续变量的二次关系时，如何运行统计能力分析？？]]></description>
      <guid>https://stats.stackexchange.com/questions/662238/statistical-power-analyss-for-moderation-of-continious-variables-when-a-quadric</guid>
      <pubDate>Wed, 05 Mar 2025 20:09:47 GMT</pubDate>
    </item>
    <item>
      <title>Python频率分析 - 拟合度良好，尽管有多种分布</title>
      <link>https://stats.stackexchange.com/questions/662235/python-frequency-analysis-aic-of-infinity-for-several-distributions-despite-a</link>
      <description><![CDATA[ 0 
我正在对许多雪数据进行频率分析，这些雪数据有时在年度最大值系列中具有（有效）零值。
为了帮助指导分布的选择，我正在计算包​​括AIC和BIC在内的拟合统计数据的一些优点。我发现，即使对于显然合理的分布拟合，我的数据中的零观察结果也会在计算AIC/BIC时产生问题。计算零观测值的概率返回零，其log为-Inf，因此log -libielies是-inf，而AIC和BIC最终是无限的。即使我为输入数据中的零值分配了很小的非零值，这似乎也会发生。
下面的最低可再现示例。我想知道是否有某种可辩护的解决方法可以在发生这种情况的情况下获得代理AIC/BIC（经常使用Weibull，但偶尔有其他分布 -  GEV  -  GEV）。）。
 导入numpy作为NP
导入lmoments3.Dist作为LD
导入matplotlib.pyplot作为PLT

data = np.Array（[[279，244，226，216，216，300，208，267，267，239，277，277，277，135，79，201，15，15，198，231，231，231，251，277，277，277，168 ,,
      43、53、160、366、163、239、287、197、117、0、208]）

数据[data == 0] = 1E-07

return_periods = np.Array（[[1.1111，1.2500，1.4286,2,3,5,10,20,50,50,100,200,1000]）

＃将GEV分布适合数据
params = ld.gev.lmom_fit（数据）
＃计算给定返回期的分位数
分位数= ld.gev.ppf（1-1 / return_periods，** params）

＃计算数据的Cunnane绘图位置
n = len（数据）
sorted_data = np.sort（数据）
等级= np.Arange（1，N + 1）
经验性_cdf =（排名-0.4） /（n + 0.2）＃cunnane绘图位置
data_return_periods = 1 /（1-经验性_cdf）

＃绘制分位数图
plt.figure（无花果=（8，6））
plt.plot（return_periods，分位数，标记=&#39;o&#39;，linestyle =&#39; - &#39;，color =&#39;b&#39;，label =&#39;gev nterials&#39;）
plt.scatter（data_return_periods，sorted_data，color =&#39;r&#39;，label =&#39;输入数据（cunnane）&#39;）
plt.xscale（&#39;log&#39;）
plt.yscale（&#39;linear&#39;）
plt.xlabel（&#39;返回期（年）&#39;，fontsize = 12）
plt.ylabel（&#39;分数值&#39;，fontsize = 12）
plt.title（&#39;带有输入数据（cunnane）的GEV分布的片段图&#39;，fontsize = 14）
plt.grid（true，wher =; bot bot d of bots; ls =;  - 
plt.legend（）
plt.show（）



n = len（数据）
经验性_cdf =（np.Arange（1，n + 1）-0.4） /（n + 0.2）＃cunnane绘图位置
return_periods = 1 /（1-经验性_cdf）＃将CDF转换为返回周期


logpdf_values = ld.gev.logpdf（sorted_data，** params）
pdf_values = ld.gev.pdf（sorted_data，** params）
log_likelihood = np.sum（logpdf_values）
打印（f＆quot“ log似然：{log_likelihood}＆quot”）
k = len（params）＃模型中的参数数

aic = 2 * k -2 * log_likelione
bic = k * np.log（n）-2 * log_likelione

打印（f＆quot; aic：{aic}＆quot;）
打印（f＆quot; bic：{bic}＆quot;）
 
  &lt;img alt =“ Quantiles”]]></description>
      <guid>https://stats.stackexchange.com/questions/662235/python-frequency-analysis-aic-of-infinity-for-several-distributions-despite-a</guid>
      <pubDate>Wed, 05 Mar 2025 17:35:07 GMT</pubDate>
    </item>
    <item>
      <title>使用三角洲方法的帮助</title>
      <link>https://stats.stackexchange.com/questions/662231/help-using-the-delta-method</link>
      <description><![CDATA[我有以下信息：

  $ r_1 $  =第一年的响应计数
  $ r_5 $  =响应计数5 
  $ p_1 $  = 1年的人口
  $ p_5 $  = 5年级的人口
  $ \ text {rate} _1 = \ frac {r_1} {p_1} $  = 1年中的速率=速率
  $ \ text {rate} _5 = \ frac {r_5} {p_5} $  = rate 5 pear in 5年

我将百分比更改定义为：
  $$ \ text {百分比cange} = \ frac {\ text {速度} _5  -  \ text {速度} {rese} _1} {\ text {rese} _1} _1} _1} \ times times 100 \％$ $ $ $ $ $ $ pas&gt;     我想计算此百分比变化的置信区间。由于价格 $ \ text {rate} _1 $ 和 $ \ text {rate {速度} _5 $ 可以被视为二项式分布的比例，我希望使用大量群体使用正常分布，我可以大致使用正常分布。          
我认为我需要使用Delta方法来解决此问题，因为我们具有随机变量的比例。我定义一个函数 $$ g = \ frac {\ text {rate} _5- \ text {rate} _1} {\ text {rese} _1} _1} $$
 i然后以 $ g $ 相对于两个费率的第一个衍生物：
  $$ \ frac {\ partial g} {\ partial \ text {速度} _5} = \ frac {1} {1} {\ text {速度} _1 _1} $$
  $$ \ frac {\ partial g} {\ partial \ text {rese} _1} =  -  \ frac {\ frac {\ text {rese} _5} _5} {\ text {\ text {rese}
这部分使我感到困惑，但是我认为 $ g $ 的差异然后可以近似为（通过delta方法，我相信协方差术语应该是 $ 0 $  $ 0 $ 出于逻辑的原因）：）
  $$ \ text {var}（g）\ of \左（\ frac {\ frac {\ partial g} {\ partial \ partial \ text {速度} _5} _5} _5} \ right） \ text {rate} _1} \ right）^2 \ text {var}（\ text {速度} _1）$$  
对于二项式比例，差异为：
  $$ \ text {var}（\ text {速度} _1）= \ frac {\ frac {\ text {速度} _1 \ times \ times（1  -  \ text {速度} _1）}
  $$ \ text {var}（\ text {rese} _5）= \ frac {\ frac {\ text {速度} _5 \ times（1  -  \ text {rese} {速度} _5）}
所以当我将所有内容结合在一起时：
  $$ \ text {var}（g）\ of左右（\ frac {1} {1} {\ text {速度} _1} _1} \ right）^2 \ frac {\ frac {\ frac {\ text {rese} \ left（ -  \ frac {\ text {rate} _5} {\ text {速度} _1^2} \ right）^2 \ frac {\ frac {\ text {速度} _1 _1 \ times（1  -  \ text}
  $$ \ text {var}（g）\ of frac {\ frac {\ text {速度} _5 \ times（1- \ text {速度} _5）} {p_5 \ times \ times \ times \ text \ text} \ text {rate} _1 \ times（1  -  \ text {速度} _1）}} {p_1 \ times \ text \ text {速度} _1^4} $$
  $$ \ text {var}（g）\ of of frac {\ frac {\ text {速度} _5 \ times（1  -  \ text {速度} _5）} {p_5 \ times \ times \ times \ times \ text {速度} _1^2} _1^2} _1^2} + frac \ frac \ frac \ frac \ frac \ frac \ frac \ frac \ f act \ text {速度} _1）}} {p_1 \ times \ text {速度} _1^3} $$  
最后，我可以使用标准CLT近似值：
在
在
  $$ \ text {ci} _ {95 \％} = \ frac {\ frac {\ text {速度} _5  -  \ text {rate} _1} _1} {\ text {\ text {rese} \ sqrt {\ frac {\ text {速度} _5 \ times（1  -  \ text {速度} _5）} {p_5 \ times \ times \ text {速率} _1^2} + \ frac { \ text {rate} _1^3}} $$  
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662231/help-using-the-delta-method</guid>
      <pubDate>Wed, 05 Mar 2025 16:38:50 GMT</pubDate>
    </item>
    <item>
      <title>比较2个分布时，将一个样本中的额外数据合并？</title>
      <link>https://stats.stackexchange.com/questions/662210/incorporating-extra-data-from-one-sample-when-comparing-2-distributions</link>
      <description><![CDATA[给定我有3个样本 $ x_1^{（1）}，\ dots，x_n^{（1）} \ sim p_x $ ， $ x_1^{（2）  $ y_1，\ dots，y_n \ sim p_y $   - 让我们假设 $ p_x $ 与 $ p_y $ 。我想进行测试（例如，t检验，kolmogorov smirnov测试等），以表明样品 $ \ {x_1^{（2）}，\ dots，x_n^{（2）} {（2）} \} $ span&gt; span  $ \ {y_1，\ dots，y_n \} $ 。
在此处保留确切的测试通用，我进行了3种不同类型的2样品测试：

 测试1：测试 $ \ {x_1^{（2）}，\ dots，x_n^{（2）} \} $  fit  $ \ \ {y_1 clast，
 测试2： testing  $ \ {x_1^{（2）}  -  x_1^{（1）}，\ dots，x_n^{（2）}  -  x_n^{（2）}  -  x_n^{（1）} {（1）}} $ 反对 $ \ {y_1-x_1^{（1）}，\ dots，y_n-x_n^{（1）} \} $ 通过选择的测试。
 测试3： testing  $ \ {x_1^{（1）}，\ dots，x_n^{（1）} \} \ cup \ cup \ {x_1^{（x_1^{（2）}，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，x_n^=  $ \ {y_1，\ dots，y_n \} $ 通过选择的测试。

进行2个样本KS测试的实验：

 无检测：我使用 $ p_x \ sim n（0,1）$ 和 $ p_y \ sim n（0,1） class =“ Math-Container”&gt; $ n = 1000 $ 并运行模拟 $ 100 $  times。令FPR为假阳性率，FNR为假负率。结果是：test1 fpr = 0.04，test2 fpr = 0.0，test3 fpr = 0.02。
 得到检测：我使用 $ p_x \ sim n（0,1）$   and  $ p_y \ sim n（0,1.1.1）$  $ n = 1000 $ 并运行模拟 $ 100 $  times。结果是：test1 fnr = 0.83，test2 fnr = 0.98，test3 fnr = 0.75。

似乎测试3给出了FPR-FNR权衡取得的最佳结果，测试2给出了最佳FPR。这是真的的理论/数学原因吗？谢谢。也可以奏效。
用于测试的代码：
 导入numpy作为NP
从scipy.stats导入ks_2samp

np.random.seed（0）

def ks_test（sample1，sample2，sig_lvl）：
    _，p_val = ks_2samp（Sample1，Sample2）
    如果p_val＆lt; sig_lvl：
        返回true
    别的：
        返回false
    
＃FPR测试
FPR1 = 0
FPR2 = 0
FPR3 = 0
sig_lvl = 0.05
对于我的范围（100）：
    x1_samples = np.random.normal（0，1，1000）
    x2_samples = np.random.normal（0，1，1000）
    y_samples = np.random.normal（0，1，1000）
    test1 = ks_test（x2_samples，y_samples，sig_lvl）
    test2 = ks_test（x2_samples-x1_samples，y__samples-x1_samples，sig_lvl）
    x_sample = np.concatenate（（x1_samples，x2_samples），axis = 0）
    test3 = ks_test（x_sample，y__samples，sig_lvl）
    如果test1：
        FPR1 += 1
    如果test2：
        FPR2 += 1
    如果test3：
        FPR3 += 1
打印（fpr1＆quot＆quot fpr1 / 100）
打印（fpr2＆quot＆quot fpr2 / 100）
打印（fpr3＆quot&#39;fpr3 / 100）

＃FNR测试
FNR1 = 0
FNR2 = 0
FNR3 = 0
sig_lvl = 0.05
对于我的范围（100）：
    x1_samples = np.random.normal（0，1，1000）
    x2_samples = np.random.normal（0，1，1000）
    y_samples = np.random.normal（0，1.1，1000）
    test1 = ks_test（x2_samples，y_samples，sig_lvl）
    test2 = ks_test（x2_samples-x1_samples，y__samples-x1_samples，sig_lvl）
    x_sample = np.concatenate（（x1_samples，x2_samples），axis = 0）
    test3 = ks_test（x_sample，y__samples，sig_lvl）
    如果test1 == false：
        FNR1 += 1
    如果test2 == false：
        FNR2 += 1
    如果test3 == false：
        FNR3 += 1
打印（fnr1＆quot; fnr1 / 100）
打印（fnr2＆quot; fnr2 / 100）
打印（fnr3＆quot; fnr3 / 100）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662210/incorporating-extra-data-from-one-sample-when-comparing-2-distributions</guid>
      <pubDate>Wed, 05 Mar 2025 07:40:39 GMT</pubDate>
    </item>
    <item>
      <title>RMSE与非线性模型选择的AIC</title>
      <link>https://stats.stackexchange.com/questions/662208/rmse-vs-aic-for-non-linear-model-selection</link>
      <description><![CDATA[想知道有人在使用RMSE与AIC选择“最合适的”模型时是否可以在协议（或分歧）方面可以提出建议？这些指标显然正在测量不同的事物，我得到了RMSE的直觉，但对于AIC而言，这可能是如何相关的，如果有的话。
我通常使用AIC评估模型拟合。对于我目前正在进行的项目，我们正在比较 nls（）模型的单指数拟合。我被要求将RMSE视为适合度量指标。有趣的是，我发现单模型的AIC较低，但RMSE较高。
您是否应该期望他们都指向相同的方向？
 ＆gt; qpcr :: rmse（nls_mod_mono）
[1] 147.9371
＆gt; AIC（nls_mod_mono）
[1] 95.82016

＆gt; qpcr :: rmse（nls_mod_bi）
[1] 141.389
＆gt; AIC（nls_mod_bi）
[1] 99.18635
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662208/rmse-vs-aic-for-non-linear-model-selection</guid>
      <pubDate>Wed, 05 Mar 2025 06:48:40 GMT</pubDate>
    </item>
    <item>
      <title>椭圆形双变量高斯分布的瑞利近似预测与经验差异</title>
      <link>https://stats.stackexchange.com/questions/662199/rayleigh-approximation-of-elliptical-bivariate-gaussian-distribution-predicted-v</link>
      <description><![CDATA[给定两个随机变量 $ x \ sim n（0，\ sigma_x^2）$ ， $ y \ sim n（0，\ sigma_y^2） y^2} $ ，我正在尝试循环 $ r $ ，以进一步比较其他较小的椭圆形双变量高斯。
 dherrera 在这里 建议 $ r^2 $ r^2 $ 的 $ P = 0.5 $ 查找 $ r^2 $ 。将结果划分为查找 $ \ sigma_r $ 从1.1774中摘自Rayleigh Distribution  $ q（f; \ sigma）= \ sigma \ sigma \ sigma \ sigma \ sqrt \ sqrt {-2 \ s {-2 \ ln（f;我可以改为解决其他 $ p $ 以实现相同效果的CDF。
该过程假设上述帖子给出的关节PDF与 $ s = x^2+y^2 $ 是正确的：
 $ p（s）= \ left \ {\ begin {array} {cc} {cc} \ hfill \ frac {e^{ -  s/（2 \ sigma_x^2）}} {} _1f_1 \ left [\ frac {1} {2}，1，\ frac {1} {2} {2} \ left（\ frac {1} {\ sigma_x^2}}  - ，\ hfill s＆gt; 0 \ hfill \\ {} \ hfill 0＆amp; ，\ hfill s \ le 0 \ end {array} \ right。$  
  $ p（s）= \ int _ { -  \ infty}^s P（t）dt = 0.5 $  
  $ \ sigma_r = \ frac {\ sqrt {s}}} {\ sqrt {-2 \ ln（1-0.5）}}} $   
我已经在python中做到了这一点，并绘制了 $ \ sigma_ {y}/\ sigma_ {x} $  $  $  1。与预测的结果相矛盾。经验测量是通过采样 $ x $ 和 $ y $ ，计算 $ r_i = $ r_i = \ sqrt = \ sqrt class =“ nath-container”&gt; $ std（r）$ ，最后 $ \ sigma_r = \ frac {std（r）} {\ sqrt {\ sqrt {2- \ \ pi/2}}}}} $  。
对于那些对详细信息感兴趣的人，使用了以下代码：
 导入matplotlib.pyplot作为PLT
导入numpy作为NP
来自Scipy.pexial Import Hyp1f1
导入scipy，集成为集成
导入scipy.ptimize优化

DEF PDF_SUM_OF_GAMMAS（S，SX，SY）：
    返回np.exp（-s /（2*sx ** 2）） /（2*sx*sy）*hyp1f1（1/2，1，（1 / sx ** 2-1 / sy ** 2）*s / 2）如果s＆gt; 0其他0

def cdf_sum_of_gammas（s，sx，sy）：
    返回Integrate.Quad（Lambda X，SX，SY：PDF_SUM_OF_GAMMAS（X，SX，SY），0，S，（SX，SY））[0]

Def Quantile_sum_of_gammas（p，sx，sy）：
    返回优化。Bisect（lambda x：cdf_sum_of_gammas（x，sx，sy） -  p，0，999）

sigma_x = 1.0
sigma_y_over_x = np.linspace（0.001，1.0，100）
n = 1000000
经验性_sigma_r_over_x = []
predicted_sigma_r_over_x = []
对于sigma_y_over_x中的sigma_y * sigma_x：
    x = np.random.normal（0，sigma_x，n）
    y = np.random.normal（0，sigma_y，n）
    r = np.sqrt（x ** 2 + y ** 2）
    std_r_empirical = np.std（r，ddof = 1，dtype = np.float64）
    sigma_r = std_r_r_erpirical / np.sqrt（2 -np.pi / 2）
    经验性_sigma_r_over_x.append（sigma_r / sigma_x）
    
    predicted_sigma_r_over_x.append（np.sqrt（Quantile_sum_of_gammas（0.5，sigma_x，sigma_y））） / 1.1774 / sigma_x）

＃情节结果
plt.figure（无花果=（8，5））
plt.title（“椭圆形分布的瑞利近似”）
plt.gca（）。set_aspect（&#39;quare&#39;）
plt.plot（sigma_y_over_x，经验性_sigma_r_over_x，linestyle =&#39; - &#39;，color =&#39;r&#39;，label = r&#39;prialical  $ \ sigma_r $ ， $ n =％d $ &#39;％n）
plt.plot（sigma_y_over_x，prediction_sigma_r_over_x，linestyle =&#39; - &#39;，color =&#39;b&#39;，label = r&#39;prendicted  $ \ sigma_r $ &#39;）
plt.xlabel（r&#39; $ \ sigma_y / \ sigma_x $ &lt; / span&gt;&#39;）
plt.ylabel（r&#39; $ \ sigma_r / \ sigma_x $ &lt; / span&gt;&#39;）
plt.legend（）
plt.grid（true）
plt.show（）
 
  
使用Julia的同事对经验结果进行了独立验证，在 $ \ sigma_ {y}/\ sigma_ {x} $ 。
如何纠正这个看似矛盾的结果？我不是在寻找对我的代码的评论，而是我的方法论。对我使用的分布正确计算的预测结果的PDF是否正确？我还有其他一些假设（例如互相关）？]]></description>
      <guid>https://stats.stackexchange.com/questions/662199/rayleigh-approximation-of-elliptical-bivariate-gaussian-distribution-predicted-v</guid>
      <pubDate>Tue, 04 Mar 2025 23:58:39 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何方法可以计算或说明每个样本的自动相关，每个样本只有2个观察结果？</title>
      <link>https://stats.stackexchange.com/questions/662183/is-there-any-way-to-calculate-or-account-for-auto-correlation-of-many-samples-th</link>
      <description><![CDATA[森林碳已经针对100多个独立地点进行了测量，并且在相距10年的两个时间点上测量了每个地点。在观察1中，每个地点都有一定数量的碳，它们独立于其他每个地点。但是，在观察2中，理论上应与该地点观察1测得的碳量相关。
是否有任何方法可以通过在所有站点之间的观测值之间纳入碳的变化来计算观测1和观察2之间的相关性？
另外，是否可以在线性回归模型中说明这种理论自动相关？
编辑：
这是一些示例数据，是我的数据和我的意图的体面表示。
  set.seed（42）
n_sites＆lt;  -  100＃站点数量
c1＆lt;  -  abs（rnorm（n_sites，平均= 50，sd = 30））＃初始碳（t = 0）是随机分布的
c2＆lt;  -  c1 *（0.9 + rnorm（n_sites，平均值= 0，sd = 0.02））＃t = 10的碳与C1 +一些噪声自动相关
site_temps＆lt;  -  rnorm（n_sites，平均值= 15，sd = 5）＃每个站点都有其自己的基线温度
＃用长格式创建数据框架
df＆lt;  -  data.frame（
  站点= rep（1：n_sites，每个= 2），＃每个站点都有2个时间段
  时间= rep（c（0，10），times = n_sites），＃timeSteps 0和10
  temp = rep（site_temps，每个= 2） + rnorm（2 * n_sites，平均值= 0，sd = 1）＃添加位点内部变化到基线温度
）％＆gt;％
  ＃分配长格式的碳值，其中碳值略微取决于温度
  group_by（site）％＆gt;％
  突变（碳= ifelse（time == 0，c1 [site] *（temp^0.01），c2 [site] *（temp^0.01）））％＆gt;％
  突变（deltac =碳 - 第一（碳））％＆gt;％
  ungroup（）
 
这是示例数据的样子：
  我正在创建一个线性模型来查看碳和气候变量之间的相关性：
 模型＆lt;  -  lm（碳〜TEMP，DF）
摘要（模型）
 
这给碳的温度显着影响
  lm（公式=碳〜Temp，data = df）
系数：
            估计标准。错误t值pr（＆gt; | t |）    
（截距）63.3868 5.6790 11.162＆lt; 2e-16 ***
温度-0.7653 0.3586 -2.134 0.0341 *  
 
但是，当我向模型添加deltac时，这种重要效果被掩盖：
  lm（公式=碳〜Temp + deltac，data = df）

系数：
            估计标准。错误t值pr（＆gt; | t |）    
（截距）55.5996 5.9006 9.423＆lt; 2E-16 ***
温度-0.6308 0.3540 -1.782 0.0763。  
Deltac -2.0674 0.5160 -4.006 8.77E -05 ***
 
我将其解释为意味着该数据集中有足够的自相关以掩盖气候变量在分析中的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/662183/is-there-any-way-to-calculate-or-account-for-auto-correlation-of-many-samples-th</guid>
      <pubDate>Tue, 04 Mar 2025 18:45:12 GMT</pubDate>
    </item>
    <item>
      <title>判别模型的特定LLN条件是什么？为什么需要它们？</title>
      <link>https://stats.stackexchange.com/questions/661990/what-are-the-specific-lln-conditions-for-discriminative-models-and-why-are-they</link>
      <description><![CDATA[我一直在阅读统计学习中大量法律（LLN）提供的融合保证，并遇到了一个有见地的答案
“理论结果都依赖于关于数据集中观测值的联合分布的假设。通常是在上述提到的工作建模假设（也就是说，判别建模的有条件独立性，以及用于生成建模的I.I.D.）。对于判别建模，一致性和错误界限将要求 $ x_i $ 满足某些条件。

我想了解以下内容：

  为什么需要这些某些条件？&lt; /strong&gt; 
我正在寻找一个直观的解释，说明为什么需要这样的假设才能确保模型 $ p（y | x）$ 

  这些条件与完整 $（x_i，y_i）$ 观察生成模型的条件有何不同？ 
我特别感兴趣地了解仅关注功能 $ x_i $ 的判别模型与生成模型的联合分布（功能和标签）之间的对比。


任何详细的解释，直观的示例或相关参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661990/what-are-the-specific-lln-conditions-for-discriminative-models-and-why-are-they</guid>
      <pubDate>Sat, 01 Mar 2025 11:04:27 GMT</pubDate>
    </item>
    <item>
      <title>请帮助我了解在讨论结果时使用引导[封闭]</title>
      <link>https://stats.stackexchange.com/questions/661339/please-help-me-understand-the-use-of-bootstrapping-in-discussing-results</link>
      <description><![CDATA[我想寻求您的帮助，因为我坚持硕士论文，而我的主管对我几乎没有时间。  当涉及到数据的推理时
 长话短说：我有圆形数据的样本（时间），我正在比较它们之间的重叠，从而导致索引。然后，我引导原始数据以获得95％的置信区间（以及带有自举数据的相同索引）。然后，我计算了第25个，第50和75个百分位数（从原始数据）进行对所获得的索引进行排名。
 我的问题是：我应该使用“自举索引”来计算百分位数，并围绕上述自举索引来讨论我的结果，或者我应该从原始数据中坚持索引？
请让我知道这听起来是否令人困惑，我会尝试更好地解释😊]]></description>
      <guid>https://stats.stackexchange.com/questions/661339/please-help-me-understand-the-use-of-bootstrapping-in-discussing-results</guid>
      <pubDate>Thu, 13 Feb 2025 17:44:24 GMT</pubDate>
    </item>
    <item>
      <title>为不规则的时间序列数据创建因果关系</title>
      <link>https://stats.stackexchange.com/questions/661337/creating-a-causal-dag-for-irregular-time-series-data</link>
      <description><![CDATA[我喜欢使用动态贝叶斯网络构建因果结构的想法，但是不确定如何在有不规则采样分辨率的情况下处理时间序列数据。具体而言，在有2个团队的运动场景中，数据是事件的数据，其中这些事件（例如传球）从比赛开始到结束时依次发生。最终，我想探索此数据中干预措施的因果影响。
有人建议使用SSM。据我了解，当它被离散化时，它可以表示为DAG？然后我有一个代表这些因果关系的结构。
其他工作流程可能是：

 此库： https：//github.com/jakobrunge/jakobrunge/tigramite 

 使用Arima降低时间序列数据，然后使用某种贝叶斯推断来捕获因果效应

 使用SSM创建因果结构和贝叶斯推断以捕获因果效应

 利用Causalimpact库

 也是GSP，然后使用图形信号作为因果模型的输入，例如BART 


尽管我建议了2个库，但我喜欢设置适当的因果工作流而不是让图书馆做所有事情的想法。这是为了更好地理解因果推论。
我最初遇到了这篇有趣的论文： https://arxiv.org/pdf/pdf/pdf/2312.09604 与irregular cons cons cons conspect
也有时间序列数据，这将导致信息丢失。在这些数据中不会立即发生原因效应，因此将其置于半秒或秒时可以起作用。
我是因果推断的新手，因此欢迎任何批评或建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/661337/creating-a-causal-dag-for-irregular-time-series-data</guid>
      <pubDate>Thu, 13 Feb 2025 16:43:29 GMT</pubDate>
    </item>
    <item>
      <title>大流行对能源欺诈的影响（所有单位）</title>
      <link>https://stats.stackexchange.com/questions/661099/causal-inference-for-pandemic-impact-on-energy-fraud-all-units-treated</link>
      <description><![CDATA[我正在写我的MSC论文，需要一些帮助，了解如何对COVID-19的因果估计，对大流行对能源欺诈的影响。
 上下文：我有一个商业损失的数据集，也称为非技术损失，由巴西不同能源分销商每月报告。  这些分销商在同一州内的大面积上运行，我无法在城市一级获得数据。
非技术损失通常归因于能量盗窃或测量误差。我假设Covid-19大流行导致了这些损失的增加，我想使用因果推断来证明这一点。
 问题：我已经将Causalimpact和Causalarima应用于此数据，并获得了一些结果。但是，这些结果不足以支持我的论点，因此我想探索不同的方法，例如差异差异（ID）或其他因果推理方法。  挑战在于，“治疗”“ covid-19-19大流行 - 受到所有单位（分销商/州）的影响。目前，我的平均收入数据按州和季度以及失业率的百分比。我试图使用这些社会经济数据来区分受到更严重影响的状态，并可能将其用作治疗和对照组的基础。  我不确定如何采用这种方法或其他合适的方法，因为大流行是广泛的事件。]]></description>
      <guid>https://stats.stackexchange.com/questions/661099/causal-inference-for-pandemic-impact-on-energy-fraud-all-units-treated</guid>
      <pubDate>Fri, 07 Feb 2025 17:37:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在K-均值聚类中群集/处理B-Splines的不同长度系数向量</title>
      <link>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</link>
      <description><![CDATA[我想根据3或4次点进行的血压测量（BP）测量来群集数据集。为此，我使用二次B-Splines（通过 scipy.interpaly.splrep ）对每个人的BP轨迹进行建模，然后用K-Means（ sklearn.cluster.cluster.cluster.kmean.kmean.kmeans ）聚类所得的样条系数。我从下面的论文中采用了该方法 https://ieeexplore.ieee.ieee.orgg/document/8031156/8031156     
然而，对于具有4个测量值的人来说，这是长度4的样条系数矢量，而缺少一个时间点的长度为3。导致执行k的问题意味着聚类，需要向量为相同的维度。
在这里，我想避免多次插补并限制我的分析以完成案例。然后我遇到了本文 https://www.sciendirect.com/science/article/pii/s1532046421002185#b0025 说
＆quot“ luong and Chandola（上述论文）提出了一种使用数据的b-spline基础表示的方法，以学习具有K-均值聚类的单个轨迹的群集。此方法允许在不需要归纳或分配零的情况下提供不同的向量长度和缺少数据。它假设可以使用平衡或多项式功能集合的加权总和来近似群集中的时间序列。我没有完全掌握它们如何处理不同长度系数向量的方式。任何指导或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</guid>
      <pubDate>Fri, 31 Jan 2025 13:24:05 GMT</pubDate>
    </item>
    <item>
      <title>总序数数据？</title>
      <link>https://stats.stackexchange.com/questions/660802/aggregate-ordinal-data</link>
      <description><![CDATA[在我的研究中，我正在研究AI标签（与无）对各种品牌知觉和行为意图的影响。具体来说，我分析了刺激（IV，4个亚组中的4个刺激）如何影响品牌信誉（DV，2维度），在线参与意愿（DV1）和购买意图（DV2）。对AI和品牌透明度作为主持人的态度，而品牌信誉是对其他变量影响的调解人。
样本量约为248名参与者（每组约120个），并且所有以5点李克特量表进行测量的构造，我正在使用jamovi进行统计分析。
首先，我认为通过计算项目的均值来汇总测量量表成连续变量是完全罚款。但是，我已经意识到，将序数量表汇总成均值可能是有问题的，因为在顺序尺度中类别之间相等距离的假设并不总是存在。这使我重新考虑了我的方法。
认识到这个问题后，我质疑以这种方式汇总是否真正有效。事实证明，序数数据的平均聚合经常在实践中使用，并且经常被认为是有效的，尤其是在内部一致性很高的情况下，就像我的情况下一样。尽管这一发现提供了一些保证，但我仍然不确定正态性假设和类别之间的距离如何影响结果。
为了进行分析，我使用了非参数测试和应用引导。但是，这里的问题是我使用连续的汇总变量作为测试的基础，这不是理想的，因为这些测试通常用于序数数据。
为了调查主持人和调解，我测试了对AI和品牌透明度作为主持人的态度，并将品牌信誉视为我的分析中的调解人（在Jamovi中使用MedMod）。
最后，我考虑了对控制变量（例如年龄，买方身份和性别）进行序数逻辑回归。但是，我意识到，因变量现在被视为连续汇总，这使该方法有问题。这就提出了一个问题，即我是否可以将项目绕过将变量再次视为序数并应用非参数测试的问题，但这将导致精确度的丧失。考虑到变量的不同测量水平，我正在考虑使用Mancova，但我也面临着违反正常性的挑战。
我听说我可以使用中位数将序数数据汇总到一个构造中吗？也许是IQR？]]></description>
      <guid>https://stats.stackexchange.com/questions/660802/aggregate-ordinal-data</guid>
      <pubDate>Fri, 31 Jan 2025 12:52:29 GMT</pubDate>
    </item>
    </channel>
</rss>