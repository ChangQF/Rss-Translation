<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 26 Jan 2024 12:23:06 GMT</lastBuildDate>
    <item>
      <title>训练损失达到零，然后突然增加，然后减少到零</title>
      <link>https://stats.stackexchange.com/questions/637814/training-loss-reach-to-zero-then-suddenly-increases-then-decreases-to-zero</link>
      <description><![CDATA[在使用默认 Adam 和默认学习对某些合成数据进行均方误差损失训练多层感知器时，我得到以下损失行为。 （我正在处理 1 维数据）
我使用训练数据==验证数据，因为我希望我的模型能够在国际范围内过度拟合：
我没有使用批量归一化和丢失
]]></description>
      <guid>https://stats.stackexchange.com/questions/637814/training-loss-reach-to-zero-then-suddenly-increases-then-decreases-to-zero</guid>
      <pubDate>Fri, 26 Jan 2024 11:50:52 GMT</pubDate>
    </item>
    <item>
      <title>将离散优化问题转化为连续优化问题</title>
      <link>https://stats.stackexchange.com/questions/637812/transforming-discrete-optimisation-problem-into-continuous-optimisation-problem</link>
      <description><![CDATA[在稀疏希尔伯特-施密特独立准则回归中（Poignard 和 Yamada，AISTATS 2020 ），作者考虑了一种通过采用特征子集来执行特征选择的方法，该子集最大化每个特征与目标变量之间的依赖关系之和减去每个特征之间的成对依赖关系之和。这是一个离散优化问题，对应于第 2.2 节中的方程 (1)，为了方便起见，我将其重现如下：
&lt;块引用&gt;
$ \hat{\mathcal{S}} = \text{argmax}_{\mathcal{S}}\left[
\frac{1}{|\mathcal{S}|} \sum_{k \in \mathcal{S}}
\text{D}\left(\text{X}^{(k)}, \text{Y} \right) -
\frac{1}{|\mathcal{S}|^2} \sum_{k \in \mathcal{S}} \sum_{j \in
\mathcal{S}} \text{D}\left(\text{X}^{(k)}, \text{X}^{(j)} \right)
\right]~~~ (A)$

其中 argmax 取自完整特征集的子集，D 是依赖性的度量。作者选择使用经验 HSIC 作为依赖性 D 的度量，我对此没有任何问题。
该优化问题是一个离散优化问题。离散优化问题通常很难解决。
在第 2.4 节中，作者将离散优化问题转化为连续优化问题。首先，他们以严格等效的形式 (B) 重写原始问题 (A)：
&lt;块引用&gt;
$\text{argmax}_{\beta \in \{0, 1\}^d} \left[ \frac{1}{\beta^T \mathbf {1}} \sum_{k=1}^d \beta_k \text{D}\left(\text{X}^{(k)}, \text{Y} \right) - \frac{1}{ \left(\beta^T \mathbf{1}\right)^2} \sum_{k=1}^d \sum_{j=1}^d \beta_k \beta_j \text{D}\left(\text {X}^{(k)}, \text{X}^{(j)} \right)\right] ~~~~ (B)$。

到目前为止一切顺利，(A) 和 (B) 只是表达同一件事的两种方式。然而，作者随后“放松”了。 $\beta$ 在连续空间上进行优化，从而导致连续优化问题 (C)：
&lt;块引用&gt;
$\text{argmax}_{\theta \in [0, \infty[^d} \left[\sum_{k=1}^d \theta_k \text {D}\left(\text{X}^{(k)}, \text{Y} \right) - \frac{1}{2} \sum_{k=1}^d \sum_{j=1 }^d \theta_k \theta_j \text{D}\left(\text{X}^{(k)}, \text{X}^{(j)} \right) - \lambda ||\theta|| _1\right]~~~~ (C)$.

从直觉上来说，这个连续公式 (C) 对我来说是有意义的。然而，我的脑海中我无法提出一个正式的论据，为什么进行这种放松并考虑连续优化问题（C）而不是离散优化问题（B）是有效的。 p&gt;
有人可以解释一下将离散优化问题替换为连续优化问题的有效性条件吗？该技术有具体名称吗？欢迎参考文献！]]></description>
      <guid>https://stats.stackexchange.com/questions/637812/transforming-discrete-optimisation-problem-into-continuous-optimisation-problem</guid>
      <pubDate>Fri, 26 Jan 2024 10:52:13 GMT</pubDate>
    </item>
    <item>
      <title>证明最有效的测试同样是最有效的</title>
      <link>https://stats.stackexchange.com/questions/637809/proving-that-a-most-powerful-test-is-uniformly-most-powerful</link>
      <description><![CDATA[这个例子来自李普曼的书“概率与统计的元素”
三姐妹每天都被妈妈要求洗碗。一年之内，就看到4个盘子被打破。测试的假设是针对最小的妹妹，她是否“笨拙”？或不。如果她打碎盘子的概率为 1/3，则认为她并不笨拙。如果她打碎盘子的概率&gt; 1，则她被认为是笨手笨脚的。 1/3。最大类型 1 错误为 0.12。
&lt;前&gt;&lt;代码&gt;H0：p = 1/3
Ha：1/3＜ p &lt;= 1

李普曼表明，之间
&lt;前&gt;&lt;代码&gt;H0：p = 1/3
哈：p = 4/5

区域 R = {x: x1 + x2 + x3 + x4 &gt;= 3} 是最强大的，其中 x 是 4 个指示变量的向量，每个指示变量为 1 或 0，具体取决于最小的妹妹是否打破了相应的菜肴。在原假设下，最小的妹妹打破盘子的数量为Bin(4,1/3)。
然后，他在没有证据的情况下指出，该地区也是最强大的地区
&lt;前&gt;&lt;代码&gt;H0：p = 1/3
Ha：1/3＜ p &lt;= 1

本质上，我意识到我必须证明对于任何 p &gt; 1/3，表明该区域的 2 类误差最小化。然而，这似乎是一个不平凡的问题。我的想法是我必须计算
$P_{\theta=1/3}(R_1^c), P_{\theta=1/3}(R_2^c), P_{\theta=1 /3}(R_3^c),...$ 对于不同可能的可行拒绝区域，并表明作为 $\theta &gt; 的函数\frac{1}{3}$，这些总是这样 $P_{\theta}(R^c) \le P_{\theta}(R_i^ c)$ 对于所有可行的拒绝区域$R_i$。
有没有一种方法可以轻松做到这一点，或者是否有不同的方法来证明测试的一致性？]]></description>
      <guid>https://stats.stackexchange.com/questions/637809/proving-that-a-most-powerful-test-is-uniformly-most-powerful</guid>
      <pubDate>Fri, 26 Jan 2024 09:57:04 GMT</pubDate>
    </item>
    <item>
      <title>将连续响应变量转换为离散响应变量</title>
      <link>https://stats.stackexchange.com/questions/637807/transforming-a-continous-respond-variable-into-a-discrete-one</link>
      <description><![CDATA[我在水下目视估计鱼的长度，通过适当的长度-重量关系将其转换为鱼的生物量。显然，我的准确性并不完美。在对影响鱼类生物量的因素进行假设时，将生物量数据四舍五入到最接近的整数是否正确，从而能够在预测模型中使用泊松分布或负二项分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/637807/transforming-a-continous-respond-variable-into-a-discrete-one</guid>
      <pubDate>Fri, 26 Jan 2024 09:28:03 GMT</pubDate>
    </item>
    <item>
      <title>测试 RxC 列联表中与 1 个序数变量的关联</title>
      <link>https://stats.stackexchange.com/questions/637805/testing-for-association-in-rxc-contingency-tables-with-1-ordinal-variable</link>
      <description><![CDATA[我目前正在尝试分析类似于以下示例的数据：
&lt;块引用&gt;
假设我有来自美国各州 (~10) 的一项调查的统计数据
他们的民众对当前州政府的感受
自当选以来一直在做的事情。该变量是序数变量（“Made
事情有些/更糟，事情大致相同，制造的东西
稍微/好多了”）。

我希望能够首先找出州和这个序数变量之间是否存在关联，如果存在关联，则得出“X Y Z 各州表现是否较差/”的结论比没有关联时的预期要好”。
我知道卡方检验可以完成第一项任务，但由于 Likert 变量是序数，我觉得这可能是“留下一些东西”就我能得到的结果而言。同样，我知道我可以分析卡方检验的残差来完成第二个任务，但我觉得这遇到了与上面相同的问题。
如果可能的话，我还担心要保持这种分析相对简单，因为观众不擅长统计。]]></description>
      <guid>https://stats.stackexchange.com/questions/637805/testing-for-association-in-rxc-contingency-tables-with-1-ordinal-variable</guid>
      <pubDate>Fri, 26 Jan 2024 08:48:09 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中添加和解释协变量</title>
      <link>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，我想在连续变量“A”和“A”之间进行逻辑回归。以及分类变量“B”。然而，我还想包括“年龄”和“性”在我的统计分析中，变量是混杂因素。你能解释一下我该如何在 R 中做到这一点吗？另外，如何在考虑协变量的影响的同时获得每个变量的调整后优势比？
这是正确的统计分析吗？我还应该包括这些变量之间的相互作用吗？
模型 &lt;- glm(B ~ A + 年龄 + 性别，数据 = 数据，家庭 = 二项式())

那我该如何正确解读呢？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</guid>
      <pubDate>Fri, 26 Jan 2024 08:32:45 GMT</pubDate>
    </item>
    <item>
      <title>ELI5 泊松分布</title>
      <link>https://stats.stackexchange.com/questions/637803/eli5-poisson-distribution</link>
      <description><![CDATA[我认为这是所有发行版中最难掌握的一个。
看起来它也会变形，例如。没有任何一张图可以描述它。
我知道它最相似的对等分布是二项式分布（两者都仅用于离散值）。
有人可以在这里提供更多信息并举例吗？

与二项式分布和正态分布的基本差异非常有帮助。
在现实世界中，泊松分布有哪些其他分布无法发挥作用的用例？谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/637803/eli5-poisson-distribution</guid>
      <pubDate>Fri, 26 Jan 2024 06:34:20 GMT</pubDate>
    </item>
    <item>
      <title>一个受试者可以在重复事件分析的风险集中多次出现吗？</title>
      <link>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</link>
      <description><![CDATA[为了使 Cox 模型适合重复事件数据 (Andersen &amp; Gill)，使用 R 生存包，需要用户将数据转换为计数过程格式（请参阅 [1]）。
对于重复事件分析，一个主题可以在此数据集中出现多次。
我理解这是一种编程技巧，允许人们通过 cox 比例风险模型来拟合第一个事件时间的循环模型（可能使用三明治方差估计器，以补偿事件中的受试者内相关性）次）。
在首次事件发生时间的设置下，cox 模型的部分可能性可以用风险集来表示。在这种编程技巧下，如何在重复事件场景中填充风险集？计数过程格式是否会用于转移时间，将一个受试者的多个危险期视为实际上具有重叠危险期的多个受试者？
例如，假设某个主题在计数过程格式中出现 3 次，(0,15]、(15,40] 和 (40,100])，并且在每次间隔结束时都发生一个事件。
该数据是否会被拟合为三个不同的受试者，首次事件的时间分别为 15、25 和 60，并且在时间 15 时，受试者实际上在风险集中出现了 3 次？同样，相关性是通过分组折刀法或稳健的三明治方差估计来补偿的吗？
我试图以编程方式和直观地理解这一点，上面的间隔数据框会发生什么，将使用哪些转换以编程方式将其视为首次事件模型的时间？凭直觉，为什么它会这样工作？
谢谢。
[1] https://cran.r- project.org/web/packages/survival/vignettes/timedep.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</guid>
      <pubDate>Fri, 26 Jan 2024 05:22:36 GMT</pubDate>
    </item>
    <item>
      <title>如何对提高里程时间所需的平均练习次数进行建模？</title>
      <link>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</link>
      <description><![CDATA[假设我们的朋友想要提高他的里程时间。他跑了一英里 $n$ 次，然后根据他记录的 $n$ 英里时间构建了一个经验累积分布函数 (CDF)并发现他的 $0.7$ 分位数估计为 8 分钟。他现在想再跑一英里 $k$ 次。我们的朋友问：我们如何估计 $k$ 的平均值，以便在 $0.7$ 的情况下发生改进所有 $n+k$ 英里时间中的 span&gt; 分位数现在是 6 分钟？
这个问题实用吗？我们是否需要知道他的第一个 $n$ 英里时间的分布？我们是否通过建议他在第一次 $n$ 试验（或者可能在任何试验之后）后有所改善来引入依赖性？如果我们能够访问他的第一个 $n$ 英里时间，我们该如何解决这个问题？他的进步率必须是对数的，这样在足够的练习后 $0.7$ 分位数就不会变成 1 分钟。
感谢您的阅读！我感谢任何帮助:)]]></description>
      <guid>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</guid>
      <pubDate>Fri, 26 Jan 2024 05:09:06 GMT</pubDate>
    </item>
    <item>
      <title>估计甜甜圈爱好者百分比的贝叶斯概率[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</guid>
      <pubDate>Fri, 26 Jan 2024 05:02:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么BERT权重初始化的标准差默认为0.02</title>
      <link>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</link>
      <description><![CDATA[神经网络中权重初始化的目的是使各层计算输出的方差保持在1.0，这取决于各层所涉及的计算。
使用Xavier初始化初始化权重W对于 Transformer Architecture 中的自注意力矩阵乘法 X@W.T 将使用标准差 $\frac{1}{\sqrt{D}}$ 从 $N(\ mu=0,\sigma=\frac{1}{\sqrt{D}})$ 以便 假设 X 和 W 的维度均为 D 并且 X 服从正态分布，则乘积的方差为 1.0。
基于 Transformer 的 BERT 的维度 D 为 768，因此 $\sigma$ 预计为0.036。但 BertConfig 表示它正在使用 0.02。 0.02 来自哪里？

BertConfig

&lt;块引用&gt;
initializer_range（浮点型，可选，默认为 0.02）— 用于初始化所有权重矩阵的 truncated_normal_initializer 的标准差。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</guid>
      <pubDate>Fri, 26 Jan 2024 04:48:53 GMT</pubDate>
    </item>
    <item>
      <title>函数积分 微分熵</title>
      <link>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</link>
      <description><![CDATA[假设有一些功能：
\begin{方程}
f(t) = p(x)
\end{方程}
其中 $p(x)$ 是 $x$ 的 PDF，位于 $t$。一些示例是具有误差范围的线性回归或高斯过程（通常 $p(x)$ 是高斯分布），例如：

如何量化 $x \sim f(t) \ \ st. 的微分熵。 \ \t_1 &lt; t &lt; t_2$？
直觉上我会执行以下操作：
\begin{方程}
   \mathcal{H}(f(t) | t_1 &lt; t &lt; t_2) = \int_{t_1}^{t_2} H(f(t)) \; dt
\end{方程}
其中 $H(f(t))$ 是 $x$ 处的微分熵$t$。
如果我的表述不清楚。我希望量化 $x$ 在 $t$ 区间内的不确定性。这个有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</guid>
      <pubDate>Fri, 26 Jan 2024 01:09:44 GMT</pubDate>
    </item>
    <item>
      <title>eta 平方的分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</link>
      <description><![CDATA[我正在尝试找到 eta 平方统计量的分布及其抽样分布的推导。
一篇较旧的论文 Murray, L. W., &amp;多瑟，D.A.（1987）。显着性差异有多显着？影响程度测量的问题。咨询心理学杂志。 https://psycnet.apa.org/journals/cou/34/1/ 68 声称它是 beta 分发的，并引用了一篇提交发表的论文，但我找不到该论文的踪迹。
有人有这方面的指点吗？我知道它当然可以模拟，但我更喜欢分析推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</guid>
      <pubDate>Thu, 25 Jan 2024 22:41:09 GMT</pubDate>
    </item>
    <item>
      <title>先前实验的贝叶斯使用</title>
      <link>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</link>
      <description><![CDATA[假设我有两项研究，例如 $\mathcal{S}_1$ 和 $\mathcal{S}_2 $，带有各自的数据集$\mathcal{D}_1，\mathcal{D}_2$，参数 $\theta^{(1)}、\theta^{(2)}$ 和响应变量 $y, z$。我有以下问题：

如果我有兴趣使用第一项研究的响应 $y$ 作为第二项研究的协变量，这是推荐的方式我可以继续吗？对后验预测进行正态逼近并计算平均值和方差并将其用作与协变量 $y$ 相关的参数的先验是否有意义，在第二项研究中说$\theta_y^{(2)}$？我遇到的主要问题是我的后验分布看起来并不正态。

此外，假设 $\mathcal{D}_2$ 有一组出现在  中的协变量$\mathcal{D}_1$。如果我想在第二个研究 $\theta^{(1)}$ 子集的后验信息，建议采用哪种方式进行class=&quot;math-container&quot;&gt;$\mathcal{S}_2$？

]]></description>
      <guid>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</guid>
      <pubDate>Thu, 25 Jan 2024 21:50:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Harrell 主张“在数据缩减过程中忽略 Y”？</title>
      <link>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</link>
      <description><![CDATA[在回归建模策略第 79 页（4.7 数据缩减）中写道：
&lt;块引用&gt;
数据缩减的目的是减少模型中要估计的参数数量，而不扭曲参数的统计推断。这是通过在数据缩减期间忽略 Y 来实现的。无监督学习中对 X 的操作可能会导致预测 Y 的信息丢失，但当信息丢失很小时，功效的增益和过拟合的减少足以抵消损失

无监督学习不会增加丢弃相关变量的风险吗？您如何向没有统计背景的研究人员/PI 争论，失去这些数据足以被功效的增加和过度拟合的缓解所抵消？
最后是否存在这种交易不值得的情况？如果研究人员主要关心的是找出“正确的”例如，变量。
我相信文本的建议是合理的，但我想充分理解它，以便我可以向持怀疑态度的外行观众解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</guid>
      <pubDate>Thu, 25 Jan 2024 20:30:40 GMT</pubDate>
    </item>
    </channel>
</rss>