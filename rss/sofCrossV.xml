<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 12:35:27 GMT</lastBuildDate>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[我一直在研究 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时 $Y=-\log(X)$ 的分布，因此 $\mathbb R_{\ge 0}$ 支持 $Y$。这可以称为 负 exp-Beta 分布吗？
对于 $\beta=1$，众所周知 $Y \sim \operatorname{Exp}(\alpha)$ 即 $\operatorname{Gamma}(1,\alpha)$。我对 $\beta$ 取其他值的情况很感兴趣。
从经验上讲，对于整数 $\beta$，似乎 $m=\mathbb E[Y] = \sum\limits_{k=\alpha}^{\alpha+\beta-1} \frac1k$ 和 $v=\operatorname{Var}(Y)=\sum\limits_{k=\alpha}^{\alpha+\beta-1} \frac1{k^2}$，或者至少这些是非常接近的近似值。这些是精确的吗？对于非整数 $\beta$，其等价项是什么？
再次从经验上看，$Y$ 分布的近似值似乎是 $\operatorname{Gamma}\left(\frac{m^2}{v},\frac{m}{v}\right)$，并且当 $\alpha \not \ll \beta$ 时，这似乎是一个更好的近似值。这种近似值有依据吗？当 $\beta \not = 1$ 时，是否有确切分布的描述？
例如，使用 R，
alpha &lt;- 5.6789
beta &lt;- 8
cases &lt;- 10^6
X &lt;- qbeta(ppoints(cases), alpha, beta)
Y &lt;- -log(X)
mean(Y)
# 0.9327204
print(m &lt;- sum(1/(alpha:(alpha+beta-1))))
# 0.9327205
var(Y)
# 0.1166561
print(v &lt;- sum(1/(alpha:(alpha+beta-1))^2))
# 0.1166563

查看黑色的 $Y$ 密度和红色的相应 Gamma 分布，可以看出它们有多接近：
plot(density(Y))
curve(dgamma(x, shape=m^2/v, rate=m/v), 
from=0, to=max(Y), col=&quot;red&quot;, add=TRUE)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>多参数最大似然估计的渐近正态性证明</title>
      <link>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</link>
      <description><![CDATA[我有一个问题，关于如何证明多个 MLE 估计量的渐近性质。您在网上找到的大多数资源都提供了仅估计一个参数的情况的证明（例如此处：https://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/）。在这个证明中，将参数方面的均值定理应用于似然的一阶导数，得到类似$(\hat{\theta} - \theta_0) = - \frac{L_n&#39;(\theta_0)}{L_n&#39;&#39;(\tilde{\theta})}$的表达式，然后将渐近结果应用于似然。我将这种证明扩展到多参数情况的问题是均值定理仅适用于标量函数。对于矢量值函数，只有不等式成立，参见例如。 https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions。
有人能告诉我如何证明多个参数的渐近正态性吗？当然，如果能提供参考，我也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</guid>
      <pubDate>Fri, 13 Dec 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>OR、se、CI 之间有什么关系</title>
      <link>https://stats.stackexchange.com/questions/658663/what-is-the-relationship-between-or-se-and-ci</link>
      <description><![CDATA[如果这是一个重复的问题，请原谅，但我一直无法找到明确的答案。
比值比、标准误差和置信区间之间的关系是什么？
我尝试对汇总统计数据进行荟萃分析。一些研究报告 OR + se，一些研究报告 OR + CI。
我理解 se = (log(CI 较高) - log(CI 较低)) / 3.92，但我不明白如何使用 OR 的 se 来获取 OR 的 CI。和/或如何在不使用 CI 的情况下获取对数转换 OR 的 se？
执行 CI = OR +/- 1.96 * se 似乎不正确。或者这只适用于对数变换后的 OR？
如果我使用 se of log OR = se / OR 来反向计算 Log OR +/- 1.96*se of log OR 和 exp(CI bounds)，我似乎仍然无法获得正确的置信区间]]></description>
      <guid>https://stats.stackexchange.com/questions/658663/what-is-the-relationship-between-or-se-and-ci</guid>
      <pubDate>Fri, 13 Dec 2024 10:12:21 GMT</pubDate>
    </item>
    <item>
      <title>模拟多级数据以获得特定的边际 R 平方值</title>
      <link>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</link>
      <description><![CDATA[我正在致力于模拟多级数据，目标是通过模拟实现特定的边际 R 平方值。鉴于多级建模中的方差分解在调整不同级别的参数时会变得相当复杂，我一直在尝试通过模拟来近似边际 R 平方值。
以下是 R 代码片段，用于具有两个 1 级预测因子（X1ij、X2ij）和两个 2 级预测因子（Z1j、Z2j）的两级模型的基本数据生成过程：
# 加载必要的库
library(lme4) # 用于拟合混合模型

# # 设置种子以实现可重复性
# set.seed(12654)

# 模拟参数
n_groups &lt;- 30 # 2 级组数
n_per_group &lt;- 30 # 每组的 1 级单元数
n &lt;- n_groups * n_per_group # 总数观察

# 固定效应
gamma_00 &lt;- 0 # 截距
gamma_10 &lt;- 1 # 1 级预测器的初始斜率（X1ij - 待调整）
gamma_01 &lt;- 1 # 2 级预测器的初始斜率（Z1j - 待调整）
gamma_20 &lt;- 0 # 附加 1 级预测器的斜率（X2ij）
gamma_02 &lt;- 0 # 附加 2 级预测器的效应（Z2j）

# 方差分量
sigma2_e &lt;- 1 # 残差方差（epsilon）
sigma2_U0j &lt;- 0.5 # 随机截距方差

# 数据生成过程函数
dgp_function &lt;- function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) {

# 模拟 2 级预测因子 (Z1j 和 Z2j)
Z1j &lt;- rnorm(n_groups, mean = 0, sd = 1)
Z2j &lt;- rnorm(n_groups, mean = 0, sd = 1)

# 初始化数据存储
data &lt;- data.frame()

# 为每个组生成数据
for (j in 1:n_groups) {
# 组 j 的随机截距
b_j &lt;- rnorm(1, mean = 0, sd = sqrt(sigma2_U0j))

# 1 级预测因子 (X1ij 和 X2ij)
X1ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)
X2ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)

# 1 级残差
epsilon &lt;- rnorm(n_per_group, mean = 0, sd = sqrt(sigma2_e))

# 生成结果变量 Y
Y &lt;- (gamma_00 + b_j) + gamma_10 * X1ij + gamma_01 * Z1j[j] + gamma_20 * X2ij + gamma_02 * Z2j[j] + epsilon

# 为该组创建数据框
group_data &lt;- data.frame(
group = j,
X1ij = X1ij,
X2ij = X2ij,
Z1j = Z1j[j],
Z2j = Z2j[j],
Y = Y
)

# 与主数据框合并
data &lt;- rbind(data, group_data)
}

return(data)
}

我的目标是通过使用缩放因子更新模型参数 gamma_10 和 gamma_01，以迭代调整它们，以近似所需的边际 R 平方值。但是，我使用的方法产生了一些奇怪的结果，我不确定是否有更可靠的方法。
这是我的代码的一部分，我调整了 gamma_10 和 gamma_01 以尝试达到所需的 R 平方：
不幸的是，我没有这种模拟的经验，因此任何想法或文献参考都值得赞赏。
# 期望的边际 R 平方
desired_marginal_R2 &lt;- 0.25

# 实现的 R2 和迭代容差和计数器的占位符
achieved_R2 &lt;- 0
容差 &lt;- 0.01
迭代 &lt;- 1
max_iterations &lt;- 100

# 迭代调整 gamma_10 和 gamma_01 以实现所需的边际R2
while (abs(achieved_R2 - desire_marginal_R2) &gt; tolerance &amp;&amp; iteration &lt;= max_iterations) {
# 生成数据
data &lt;- dgp_function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) 

# 拟合混合模型
model &lt;- lmer(Y ~ X1ij + Z1j + (1 | group), data = data)

# 使用 performance 包计算边际 R2
reached_R2 &lt;- performance::r2(model, details = TRUE)$R2_marginal

# 根据实现的 R2 调整 gamma_10 和 gamma_01（启发式）
scaling_factor &lt;- sqrt(desired_marginal_R2 / reached_R2)
gamma_10 &lt;- gamma_10 * scaling_factor
gamma_01 &lt;- gamma_01 * scaling_factor

# 增加迭代计数器
iteration &lt;- iteration + 1
}

# 输出结果
cat(&quot;Achieved Marginal R2:&quot;, reached_R2, &quot;\n&quot;)
cat(&quot;Desired Marginal R2:&quot;, desire_marginal_R2, &quot;\n&quot;)
cat(&quot;迭代次数：&quot;, 迭代次数 - 1, &quot;\n&quot;)
cat(&quot;调整后的 gamma_10：&quot;, gamma_10, &quot;\n&quot;)
cat(&quot;调整后的 gamma_01：&quot;, gamma_01, &quot;\n&quot;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</guid>
      <pubDate>Fri, 13 Dec 2024 08:24:27 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况会越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为组 1（2022），包含 207 个样本，组 2（2023），包含 250 个样本。 y 轴变量以整数形式测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，组 2 中有 9 个点高于 10（约为组 1 的平均值），组 2 中有 10 个点约为 10（总共 12 个高异常值），其中组 2 中的顶级异常值高于组 1。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些都表明平均值有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，而不管平均值的行为如何。有人要求我在不同性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些统计数据最适合用于评估基于常模的能力评估的有效性和可靠性？</title>
      <link>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</link>
      <description><![CDATA[我计划评估常模参照能力评估的有效性和可靠性。该工具有 5 个与能力相关的子量表。有现成的常模，但我想对我拥有的样本进行一些额外的研究，以增加对该工具的研究内容。
对于标准参照评估，我会考虑的两个统计数据是每个项目的 Cronbach&#39;s alpha 和因子分析。一般来说，这些是否也构成能力评估的最佳实践？]]></description>
      <guid>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</guid>
      <pubDate>Fri, 13 Dec 2024 05:44:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) \hat{\bf V}^{-1} (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X - \bf M)^\top \hat{\bf U}^{-1} (\bf X - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\, \mathrm{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X - \bf M)^\top (\bf X - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>基于密度比估计的分类</title>
      <link>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</link>
      <description><![CDATA[考虑分类问题 $p(y \mid x)$，其中 $y$ 是标签，$x$ 是特征向量，例如图像。通常，我们会拟合卷积网络，并根据 $x$ 预测 $y$。昨天我突然想到，根据贝叶斯规则，$\log p(y \mid x) = \log p(y) + \color{blue}{\log \frac{p(x \mid y)}{p(x)}}$。由于$\log p(y)$可以从数据集中轻松估算出来，因此找到对数密度比（蓝色）将等同于找到分类器$p(y \mid x)$。根据密度比技巧（Sugiyama 等人， 2012；Dhuliawala 等人， 2023），可以通过拟合一组分类器 $T_y(x)$（也可以选择拟合一个摊销分类器）来找到对数密度比，该分类器区分 $p(x \mid y)$ 样本和 $p(x)$ 样本。 $T_y(x)$ 的优化条件是 $\mathbb E_{p(x \mid y)}[\log \sigma(T_y(x))] + \mathbb E_{p(x)}[\log (1-\sigma(T_y(x)))]$ 最大化，其中 $\sigma(\cdot)$ 为 S 型函数。因此，$\log p(y \mid x) = \log p(y) + T_y(x)$。一个优点可能是校准标签偏移很简单。
这种方法在实践中使用过吗？如果有人能给我指出相关文献，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</guid>
      <pubDate>Fri, 13 Dec 2024 03:36:18 GMT</pubDate>
    </item>
    <item>
      <title>与回归分析相比，生存分析在预测方面有哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</link>
      <description><![CDATA[我最近遇到了生存分析，它似乎对于模拟事件发生时间和/或处理审查非常有用。文献中激励性的例子很有意义，例如在临床试验中，我们可能会有参与者退出，或者那些可能经历了不良影响但研究提前结束的人。
在我的应用程序中，我使用机器学习对事件发生时间进行建模并将其视为回归问题。然而，审查在这里并不是一个真正的问题，我想知道生存分析是否会比标准回归方法提供任何优势。
为了简化设置，假设我们有来自小部件工厂的数据。小部件发生故障的平均时间为$\bar{Y} = 40$天（最多 100 天），而数据集可以追溯到几年前，并且有几百万个观察值。因此，确实存在一些右删失，但考虑到数据的大小，这相对微不足道。我们还观察到小部件级协变量 $X$，它们会影响故障时间。
目前，我只是将其建模为非参数回归问题，即学习函数 $f : X \to Y$，该函数可最小化 $L^2$ 经验风险/MSE。如果这里的目标只是预测故障时间 $Y$，而不考虑推理，那么生存分析是否会比回归方法有任何优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</guid>
      <pubDate>Fri, 13 Dec 2024 01:17:45 GMT</pubDate>
    </item>
    <item>
      <title>与基线纵向模型的变化</title>
      <link>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</link>
      <description><![CDATA[我正在研究一个纵向模型，以分析变量 Y 的相对于基线的变化，该变量在基线 Y1 和后续时间点 (Y2、Y3、Y4 ...) 处针对一组患者进行测量。对于每个测量值，我都有相应的标准差 (Y1_SD、Y2_SD、Y3_SD ...)。
(相对于基线的变化) 平均差异 (MD) 很容易计算为 ( Y1 ) 与每个后续 ( Y_i ) 之间的差异。但是，我很难正确定义 平均差异的标准差 (SD_diff)，因为这需要 ( Y1 ) 和 ( Y2、Y3、...) 之间的相关性 ( r )；编码协方差矩阵（例如自回归矩阵）也需要相关性
我引用的 SD_diff 公式是：
SD_diff = sqrt(S1² + S2² - 2 * r * S1 * S2)
我的问题是：

我需要两个元素来构建纵向模型吗？
纵向模型可以只用协方差矩阵编码吗？

方差和协方差矩阵应该如何定义？
假设任何协方差矩阵（例如 AR(1)）在其公式中包含变量方差；这应该由 SD_diff 定义吗？还是由 Yi_SD 定义？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</guid>
      <pubDate>Fri, 13 Dec 2024 00:07:57 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据进行因果关系检验的算法/测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</link>
      <description><![CDATA[我有两份在 18 个采样点和 20 个采样日期收集的观测数据，我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经完成了双向方差分析与交互作用（编辑），现在我想做一个事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它能给出组别和字母，说明各组之间的差异。但我不确定这个函数是否可以用于两个因素，或者它是否只适用于单向方差分析。有人知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>重复测量二元变量的 Cohen Kappa</title>
      <link>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</link>
      <description><![CDATA[我进行了一项实验，展示了两种类型的广告信息：第一种类型具有理性风格，第二种具有感性风格。样本多次接触这些信息（重复测量），每次我都会进行问卷调查，询问这些信息是理性的还是感性的。所以我有一个 2x2 矩阵，其中变量 1 是信息类型（理性/感性），变量 2 是信息的识别（理性/感性）。因此，两个变量都是二元名义分类变量。
我想进行操纵检查，看看受试者是否正确识别了信息风格，我应该使用哪种一致性测试？我考虑过 Cohen 的 kappa，但就我而言，我进行了重复测量，并且我读到这可能不是正确的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:46 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以准确地找到我所寻找的内容。
由于缺乏估计量的封闭公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$n\hat{p}$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。
（这是我对此的第一个问题论坛）]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    <item>
      <title>当我想比较矩阵问题（每行一个答案，5pt 李克特量表，相关样本）的均值时，进行重复测量方差分析是否有效？</title>
      <link>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</link>
      <description><![CDATA[我们要求参与者对不同的项目进行评分（矩阵问题，12 个项目（行）和 5 分李克特量表（每行一个答案））。调查中的行是随机的。
问题：如何比较项目的平均值？我想知道它们是否比其他项目高/低。
这听起来很简单。如果只有两个平均值，我只需进行 t 检验。但不知何故，我不知道我可以使用什么测试来检查 12 个组织（=我的因变量）之间的平均值是如何不同的。请记住，样本是因变量（我没有 UV/组）。
我想到的是重复测量方差分析……您觉得怎么样？我知道，通常 RM Anova 的示例是“在不同时间点测量相同的因变量”。我有“不同的因变量，在略有不同的时间点进行测量”。
或者还有其他您要检查的内容吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</guid>
      <pubDate>Thu, 12 Dec 2024 15:29:06 GMT</pubDate>
    </item>
    </channel>
</rss>