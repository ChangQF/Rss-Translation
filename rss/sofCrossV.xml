<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Jan 2024 06:17:59 GMT</lastBuildDate>
    <item>
      <title>在statsmoldes中，移动平均模型是如何实现的？</title>
      <link>https://stats.stackexchange.com/questions/636035/in-statsmoldes-how-is-the-moving-average-model-implemented</link>
      <description><![CDATA[从维基百科，我检查了移动平均模型定义。
我试图检查 statsmodels 的移动平均模型的实现，以便明确地理解它。
https://github.com/statsmodels /statsmodels/blob/main/statsmodels/tsa/statespace/sarimax.py
但是，很难找到如何计算移动平均系数的代码。我相信我对代码和公式的了解还不够。
有人看过移动平均模型的代码吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636035/in-statsmoldes-how-is-the-moving-average-model-implemented</guid>
      <pubDate>Wed, 03 Jan 2024 06:15:29 GMT</pubDate>
    </item>
    <item>
      <title>异方差性</title>
      <link>https://stats.stackexchange.com/questions/636034/heteroscedasticity</link>
      <description><![CDATA[我正在尝试建立一个回归模型，以使用不同抵押贷款利率的变化来解释抵押贷款数量的变化。为了解释宏观经济环境的巨大变化：从接近零的利率到正利率，我使用了一个权重变量，相对于旧数据，对最近的观察结果给予更多的权重。正如预期的那样，这有助于模型在准确预测最近的观测结果方面比未加权模型表现更好。然而，问题是该模型未能通过同方差性测试。任何有关如何解决此问题的建议将不胜感激。可根据需要提供更多详细信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/636034/heteroscedasticity</guid>
      <pubDate>Wed, 03 Jan 2024 05:41:03 GMT</pubDate>
    </item>
    <item>
      <title>预测器（回归）性能面临的挑战：MAE 持续为 0.26 且二元向量预测不准确</title>
      <link>https://stats.stackexchange.com/questions/636033/challenges-with-predictor-regression-performance-persistent-mae-of-0-26-and-i</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636033/challenges-with-predictor-regression-performance-persistent-mae-of-0-26-and-i</guid>
      <pubDate>Wed, 03 Jan 2024 05:20:33 GMT</pubDate>
    </item>
    <item>
      <title>为了避免二元变量的完美多重共线性问题，为什么可以在线性回归中为它们创建单独的变量？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/636031/to-avoid-the-problem-of-perfect-multicollinearity-in-binary-variables-why-is-it</link>
      <description><![CDATA[我正在阅读伍尔德里奇的计量经济学教科书。他提供了以下例子：假设我们有一个将工资与性别和教育水平联系起来的回归模型。
工资 = b0 + d0 女性 + b1educ + u
对于性别变量，我们可以创建一个二元变量，其中female = 0，male = 1。教科书上说我们不应该创建2个虚拟变量，以避免虚拟变量陷阱（完美多重共线性）。
同时Wooldridge表示这样做也可以：工资=b0male + a0female + b1educ + u。为什么每组包含 2 个虚拟变量可以？这是否也会导致完美的多重共线性？]]></description>
      <guid>https://stats.stackexchange.com/questions/636031/to-avoid-the-problem-of-perfect-multicollinearity-in-binary-variables-why-is-it</guid>
      <pubDate>Wed, 03 Jan 2024 03:41:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 TWFE 方法调整 diff-in-diff 中的时不变协变量</title>
      <link>https://stats.stackexchange.com/questions/636030/adjusting-for-time-invariant-covariates-in-diff-in-diff-using-twfe-approach</link>
      <description><![CDATA[我正在计划进行一项交错的双重差异分析，以检验县级卫生政策变化的影响。该政策在不同的县实施的时间不同，还有很多县根本没有实施。我有很多县的数据，只有一小部分县实施了该政策。
我想利用 TWFE 模型（我已经阅读了许多对此方法的批评，但至少想实现它，即使它不是我的最终分析模型），但我对这种方法感到困惑，因为我也想要针对县级协变量调整我的模型。似乎在 TWFE 模型中这是不可能的，因为任何时不变的县级协变量都将与特定于县的固定效应完全共线，但我一直在阅读声称调整基线协变量以满足并行的资料来源趋势假设是 TWFE diff-in-diff 中的常见做法（例如）。
这是实现该模型的 R 代码示例，其中 Outcome 是我的结果变量，TimeToTreat 是政策实施之前或之后的月数，Treated 是实施该政策的县的虚拟变量，Time 是结果测量的时间， CountyID 标识县（哈哈）：
model.twfe &lt;- feols(结果 ~
                    i(治疗时间，已治疗，参考=-1) |时间+县ID，
                    集群 = ~CountyID,
                    数据 = 玩具数据）

这似乎按预期工作。但是，如果我尝试在模型公式中添加额外的项，这些项是县（例如地区）的时不变特征，它们会自动从模型中删除，以实现完美的共线性。
我在这里缺少什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636030/adjusting-for-time-invariant-covariates-in-diff-in-diff-using-twfe-approach</guid>
      <pubDate>Wed, 03 Jan 2024 02:11:00 GMT</pubDate>
    </item>
    <item>
      <title>如何估计 OLS 中的系数（所有步骤）[重复]</title>
      <link>https://stats.stackexchange.com/questions/636026/how-to-estimate-the-coefficients-in-ols-all-steps</link>
      <description><![CDATA[我是学士。数学毕业生，喜欢（尝试）利用自己的时间自学统计学，因为我买不起硕士学位。
当我无法从根本上理解某些东西如何以及为何起作用时，这真的让我很困扰，因此在这篇文章中，我想提供如何使用线性回归中的最小二乘法导出系数的每一步。这里的大多数人可能比我更了解这类事情，但看到这一切结合在一起很令人满意，我希望它也适合你。
这涵盖了多变量（n 维）情况，因为 1 变量情况只是其更简单的版本。最后有一个简单的R例子，说明从头开始得到的结果是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/636026/how-to-estimate-the-coefficients-in-ols-all-steps</guid>
      <pubDate>Tue, 02 Jan 2024 22:30:07 GMT</pubDate>
    </item>
    <item>
      <title>分解时间序列</title>
      <link>https://stats.stackexchange.com/questions/636025/decomposition-time-series</link>
      <description><![CDATA[我正在研究一款游戏的每日数据集，其中包含 2013-2023 年玩家高峰期的信息。这是我第一次尝试应用分解来查看时间序列组件的行为。后来我想使用一些模型进行预测，我应用了 ADF 测试，它显示该序列是平稳的。我有一些问题需要确定哪些值更适合每日数据的周期参数。
这是整个系列的全部内容

我使用了 statsmodelsseasonal_decompose()，周期值为 365，这是使用加法和乘法模型获得的结果。
加法模型：

乘法模型：

针对年、月、日等不同类型的时间序列数据，应该如何选择周期？]]></description>
      <guid>https://stats.stackexchange.com/questions/636025/decomposition-time-series</guid>
      <pubDate>Tue, 02 Jan 2024 21:45:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么解码器网络中每个注意力层周围都有一个残差连接，然后是一个层归一化步骤？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</link>
      <description><![CDATA[我在测验中得到了以下问题，看来我的答案不正确。我不明白为什么：
为什么解码器网络中的每个注意层周围都有一个残差连接，然后是一个层归一化步骤？

答案：
帮助提高可解释性。
加快训练速度，并显着减少整体处理时间。
打破后支撑的对称性。
在培训期间帮助并行计算组件。

我回答“打破后向传播的对称性。”，但他们的回答似乎是错误的！
我不明白为什么我的答案是错误的。另外，我不明白其他答案怎么可能是正确的！]]></description>
      <guid>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</guid>
      <pubDate>Tue, 02 Jan 2024 21:03:04 GMT</pubDate>
    </item>
    <item>
      <title>用于小样本和功效计算的线性混合模型方差分析的非参数方法</title>
      <link>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</link>
      <description><![CDATA[我有一个小数据，其中有 3 个组（A、B、C），每组有 5 名参与者。所有这些参与者在 7 项不同的考试中每项都被测量 6 次，因此每个参与者总共得到 6*7=42 分。构建了一个简单的线性混合模型 mylmm&lt;-lmer(score ~1+group+exam+group*exam+(1|participant), data = mydata)。我可以使用 anova(mylmm) 和多重比较函数获得分组、考试和交互的方差分析结果和事后成对比较。
但是数据很小（只有5个参与者）并且mylmm的残差不正常，所以威力不足。我知道使用 robustlmm 的稳健混合模型和使用 lmeresampler 的残差引导混合模型。但是，我无法使用这些包执行方差分析和多重比较。有人可以帮我解决以下问题吗？实在是太感谢了。

是否有方法和可用的 R 软件包来执行线性混合模型的引导方差分析（和事后比较）？
是否还需要计算 bootstrap 或非参数方差分析的功效？如果可以的话，功率怎么计算？
我还了解对齐排名转换方差分析。这种方法在这里有效吗，特别是对于小数据？另外，如何计算功率？
还有另一个相关但不太重要的问题。对于直接从 lme 构建的模型（无需引导），我能够使用 simr 和 anova 方法来计算测试组、考试和交互的功效。 simr 是否也可用于查找事后成对比较的功效？谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</guid>
      <pubDate>Tue, 02 Jan 2024 20:23:38 GMT</pubDate>
    </item>
    <item>
      <title>拟合值与实际值较差</title>
      <link>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</link>
      <description><![CDATA[我正在使用 BART 模型（贝叶斯加性回归树）来预测控制 388 个特征的结果（21,384 个观察值）的相对风险，并且我得到的实际值与拟合值图非常差，与任何 I&#39; 都不同。之前在其他模型中已经得到过不同的结果。
DV = 记录的相对风险 + 1 人口普查区层面的租户驱逐率。我的第一个模型（未显示）使用原始相对风险（风险是与该州所有其他区域相比的区域驱逐率），但我的拟合效果不佳，因此最后一轮我将 DV 转换为 log(RR +1)，其中在记录之前将 +1 添加到所有 RR 值，以避免由于大量零而出现无穷大。
IV = 388 个变量中除一个之外的所有变量都是连续的。变量涉及住房市场、人口统计、建筑环境、地方政策以及与驱逐相关的其他变量。
目标 = 拟合该国其他地区的相对风险预测值，这些地区没有基于相应地区控制措施的数据。
流程 = 我从基线数量的控件（最多包含 388 个）开始，运行交叉验证的 BART 模型以获得最佳超参数，然后使用这些参数循环 20 个 BART 模型每个都用不同的种子来找到最重要的变量，在查看几个变量重要性因素后减少变量。然后我重复这个过程，直到找到满意的模型集。最后一次模型迭代的 R^2 约为 0.64，RMSE 约为 0.28。
问题我该如何改进这个模型？

编辑：澄清情节。这些是可信的区间点。蓝色表示在可信范围内，红色表示在可信范围外。这里我们的覆盖率是 45.06%。我之前遇到的最差情况是 95%（绘图看起来大部分是蓝色）。]]></description>
      <guid>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</guid>
      <pubDate>Tue, 02 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>竞争获胜的概率</title>
      <link>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</link>
      <description><![CDATA[我想象这样一个场景：两支球队互相比赛并取得历史胜率。 $1$ 团队相当出色，赢得了 $60\%$ 的比赛。然而，$2$ 团队确实非常出色，赢得了 $90\%$ 的比赛。当两队相遇时，每队获胜的概率是多少？
我尝试使用多变量方法解决此问题，但事实证明这不是一个多变量问题。只有两种结果： $1)$ $\text{团队 1 获胜，团队 2 失败}$ ，或 $2)$ $\text{团队 2 获胜，团队 1 失败}$。这是伯努利分布（a 的简单变体）： $P(\text{队伍 1 获胜，队伍 2 失败}) = p$ 和 $P(\text{团队 2 获胜，团队 1 失败}) = 1 - p$。
应该如何计算$p$？
在上述情况下，我认为两支球队中较差的一支球队的获胜概率一定小于其历史胜利概率$0.6$。然而，由于更好的球队面对的是一支相当不错的球队（赢多于输），因此它的胜利概率也必须低于其历史比率 $0.9$.
我的幼稚方法是将概率计算为“团队拥有的胜利概率的比例” （正如我所说的）。
$$
P(\text{队伍 1 获胜，队伍 2 失败}) = \dfrac{0.6}{0.6 + 0.9} = 0.4\\
P(\text{队伍 2 获胜，队伍 1 失败}) = \dfrac{0.9}{0.6 + 0.9} = 0.6
$$
这个计算有多合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</guid>
      <pubDate>Tue, 02 Jan 2024 19:20:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么在分析语料库时使用每百万计数的日志？</title>
      <link>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</link>
      <description><![CDATA[这对你来说可能是一个微不足道的问题，但请告诉我，因为我没有统计学背景。所以我对语料库语言学很好奇，尤其是在这个例子中如何使用语料库来证明简洁法则，也称为Zip&#39;f缩写法则。简而言之，该定理假设单词越短，它们在语言中出现的频率越高。当然，可视化对于证明定理非常有意义，所以我从维基百科上看到了这个可视化：

x 轴代表单词字符长度，y 轴代表单词数，以每百万对数计数。
我的问题是，为什么要使用每百万对数计数？是为了标准化，以便在分析中很好地代表计数较少的单词吗？任何对此有见解的人以及一些小读物，我们将不胜感激。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</guid>
      <pubDate>Tue, 02 Jan 2024 17:53:22 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>如何识别样本正态分布的直方图</title>
      <link>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</link>
      <description><![CDATA[我完成了一个行动研究项目，并使用 DART 提高了学生的阅读理解能力。我只是为了结果而比较手段。现在我要写一篇文章，我将应用 $t$ 测试以获得更好的结果。我正在使用 Google Sheets 检查样本的正态分布。我制作了一个图表，但不明白。
我把全班分成了两组，即对照组（不进行治疗）和实验组（进行治疗）。我制作了图表只是为了检查对照组的结果，但我无法理解分布是否正常。查看下图，请说明它是否显示正态分布。
我上传了一张图像，仅显示对照组的结果：
]]></description>
      <guid>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</guid>
      <pubDate>Mon, 25 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>如何激励人工智能做出危险的预测</title>
      <link>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</link>
      <description><![CDATA[我正在尝试构建一个天气预报人工智能。我有一个包含每天峰值温度的数据集。我用 MSE 作为损失函数来训练它，效果相当好。但我确实注意到，它往往更喜欢“安全”的东西。预测，即该时期平均温度附近的预测。我也对做出正确的意外预测感兴趣，因此我一直在尝试激励它做出风险更高的预测，但我没有运气。
我尝试使用指数和高阶多项式损失函数而不是平方，认为值的更快增加会奖励精确性。我尝试通过扩大平均温度附近预测的损失来惩罚安全预测。我尝试用阶跃函数包围平均温度。我不知道还能尝试什么，也不知道在线搜索答案的术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</guid>
      <pubDate>Thu, 07 Dec 2023 18:26:00 GMT</pubDate>
    </item>
    </channel>
</rss>