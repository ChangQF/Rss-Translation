<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 Jan 2025 01:15:46 GMT</lastBuildDate>
    <item>
      <title>U 统计量和独立性检验</title>
      <link>https://stats.stackexchange.com/questions/659742/u-statistics-and-independence-testing</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659742/u-statistics-and-independence-testing</guid>
      <pubDate>Thu, 09 Jan 2025 00:25:27 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我从 Statista 下载数据吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</link>
      <description><![CDATA[我现在正在做一个大学项目，但我付不起订阅费。我需要做一个机器学习模型。有人能从 Statista 给我发一份数据吗？
https://www.statista.com/statistics/1251338/share-female-board-directors-it/]]></description>
      <guid>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</guid>
      <pubDate>Wed, 08 Jan 2025 23:47:17 GMT</pubDate>
    </item>
    <item>
      <title>对于分类变量，PCA、因子分析或其他方法？</title>
      <link>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</link>
      <description><![CDATA[我有关于公司政治关系的调查数据，分为两个模块，希望您就以下方面提出建议：
1. 模块 1：此模块包含所有分类变量的调查问题。虽然我了解到从技术上讲可以使用 PCA 处理分类变量，但一般不建议这样做。是否有其他方法更适合在此背景下分析分类数据？
2. 模块 2：此模块包含多种变量：2 个是序数变量，1 个是分类变量。PCA 或因子分析能否有效地处理这种组合？
我一直在研究 PCA 和因子分析之间的差异，但仍然不确定哪个更合适。我的直觉是政治联系可能不是潜在的构造，因此 PCA 在概念上似乎更有意义。但是，我想听听您的想法，PCA 或因子分析是否是更好的方法——或者另一种方法是否更合适。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</guid>
      <pubDate>Wed, 08 Jan 2025 23:40:48 GMT</pubDate>
    </item>
    <item>
      <title>通过中间变量估计干预与结果之间的关系</title>
      <link>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</link>
      <description><![CDATA[设 $X$ 为实验性疫苗的剂量水平，$Z$ 为二元结果（感染与未感染）。目标是通过随机为参与者接种 $k$ 个不同剂量水平的疫苗，$X_1, ..., X_k$，来估计 $X$ 和 $Z$ 之间的关系。 $n$ 名受试者在每个剂量水平上接种疫苗，因此总共有 $nk$ 名受试者。
通常，$X$ 和 $Z$ 之间的逻辑回归就足够了，但这里的问题是 $X$ 被视为目标剂量水平，并且相同目标剂量水平的每种疫苗中的实际浓度（表示为 $Y$）可能有很大差异。
对 $X$ 和 $Z$ 之间关系进行建模的最佳方法是什么？这看起来像是一系列回归$X-&gt;Y-&gt;Z$，其中$Y$和$Z$通过逻辑模型关联，而$X$和$Y$可以通过线性模型建模？
任何带有参考的建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</guid>
      <pubDate>Wed, 08 Jan 2025 23:27:39 GMT</pubDate>
    </item>
    <item>
      <title>缩小的整数格点是否可以作为概率单纯形中的无偏样本点？</title>
      <link>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</link>
      <description><![CDATA[我一直在努力证明一个看起来直观明显但实际上并不容易严格建立的陈述。
$(n-1)$维概率单纯形$X$是集合
$$
X=\left\{\mathbf{x}\in[0,1]^n:\sum_{i=1}^nx_i=1\right\}。
$$
设 $U$ 为单纯形中按比例缩小的整数格点集：
$$
U=X\cap\frac{\mathbb{Z}^n}s
$$
其中 $s\in\mathbb{Z}^+$。
我的主张是，当 $s\to\infty$ 时，$U$ 可作为 $X$ 中无偏的样本点集。也就是说，对于子集 $P\subseteq X$，其质心（未加权平均值）由
$$
\tag{1}
\bar{\mathbf{p}}=\frac{1}{\int_{P}dV}\int_{P}\mathbf{p}\,dV
$$
其中 $\mathbf{p}\in P$ 和 $dV$ 是 $(n-1)$ 维体积元素，渐近等于
$$
\tag{2}
\bar{\mathbf{u}}=\frac1{\#U}\sum_{i=1}^{\#U}\mathbf{u}_i
$$
其中 $\mathbf{u}_i\in U$，即 $s\to\infty$；即
$$
\tag{3}
\lim_{s\to\infty}\bar{\mathbf{u}}=\bar{\mathbf{p}}。
$$
这里，$(1)$可视为真实均值，$(2)$可视为样本均值，如果集合$U$提供的样本点在极限上无偏，则$(3)$成立。
对于我的具体情况，该语句不必对$X$中的所有子集都成立，而只对这个特定集合成立：
$$
\tag{4}
{P}=\left\{\mathbf{p}\in[0,1]^n: p_1\le p_2\le\cdots\le p_c\ge\cdots\ge p_n\text{ 和} \sum_{i=1}^n p_i=1\right\}\subset X
$$
顺便说一句，它恰好是凸的。
简而言之，我试图证明$(3)$，无论是在一般情况下，还是当$P$给出为$(4)$时。
任何帮助都将不胜感激。指导我任何相关的关键字或书籍也将很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</guid>
      <pubDate>Wed, 08 Jan 2025 22:56:09 GMT</pubDate>
    </item>
    <item>
      <title>如何更好地测试数据是否接受多参数分布的简化？</title>
      <link>https://stats.stackexchange.com/questions/659732/how-can-i-better-test-whether-the-data-accepts-simplification-of-a-many-paramete</link>
      <description><![CDATA[我有一些数据，它们与特定的五参数分布非常吻合，该分布包括许多常见的 2 和 3 参数分布以及一些四参数分布，作为某些参数的特定值的特殊情况，通常为零或一，作为特殊情况。我一直在尝试看看我是否可以通过使用重采样来获得参数值的经验分布并从经验 CDF 创建置信区间来简化分布，但我怀疑有一些更简单的方法可以做到这一点。（我有很多数据 - 大约 60,000 个观测值）。我对五参数分布的估计方法的优点是易于理解，但计算量非常大。因此，重采样后的重新估计既慢又乏味。有没有一种常规方法来完成这项任务，即查看数据是否接受这些简化中的任何一种，如果可以，它是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659732/how-can-i-better-test-whether-the-data-accepts-simplification-of-a-many-paramete</guid>
      <pubDate>Wed, 08 Jan 2025 19:21:02 GMT</pubDate>
    </item>
    <item>
      <title>FE 解释中的相互作用项</title>
      <link>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</link>
      <description><![CDATA[我正在估算固定效应回归，如下所示：
$$
\text{unemployment}_{ict} \sim b_1 \text{wage}_{ict} + b_2 \text{heat}_{ict} + b_3 \text{wage}_{ict} \times \text{heat}_{ict} + \text{FEc} + \text{error}_{ict}
$$
其中 $i$ 为个人，$c$ 为国家，$t$ 为时间。
假设您获得以下效果：$b_1=0.7$，$b_2=1.2$, $b_3=-0.4$
现在您想要解释交互效应。一种思考方式是边际效应：
这里您已估计出给定工资和热量的失业预期值
$$
E[y|a,b]=0.7a+1.2b-0.4ab
$$
如果对上述表达式求导，求 a 的值：
$$
\frac{d}{d a} E[y|a,b] =0.7-0.4b
$$
此表达式在 $b$（热量）中递减。然后您可以将 b 设置为“有趣”的值以进行解释。通常，这些有趣的值是 $b$ 中样本的平均值。
我想知道这在具有固定效应的应用中是否有意义。国家平均值已从固定效应中移除。在热度水平上评估 b 是否有意义。或者最好以 b 的平均增长率或标准差而不是水平来评估？
如果有人能对此发表评论，非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</guid>
      <pubDate>Wed, 08 Jan 2025 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解释两个时间协变量中的时间自相关性？</title>
      <link>https://stats.stackexchange.com/questions/659724/how-to-account-for-temporal-auto-correlation-in-2-time-covariates</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659724/how-to-account-for-temporal-auto-correlation-in-2-time-covariates</guid>
      <pubDate>Wed, 08 Jan 2025 16:41:35 GMT</pubDate>
    </item>
    <item>
      <title>当得到自由度的十进制值时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/659723/what-to-do-when-one-gets-a-decimal-value-as-degrees-of-freedom</link>
      <description><![CDATA[我正在尝试找到 2 个随机变量的样本均值差异的置信区间的 t 值。这里的方差是未知且不相等的，因此必须使用的 v 公式是：

完成此计算后，我确信它是正确的，我得到的是一个十进制值。在 t 分布表中，我只能看到 v 的整数值，所以我的问题是我应该向上舍入还是向下舍入。此外，这有什么逻辑吗，还是向上舍入或向下舍入完全是随机的？]]></description>
      <guid>https://stats.stackexchange.com/questions/659723/what-to-do-when-one-gets-a-decimal-value-as-degrees-of-freedom</guid>
      <pubDate>Wed, 08 Jan 2025 15:58:56 GMT</pubDate>
    </item>
    <item>
      <title>不带 MAR 假设计算临床试验的敏感性和特异性</title>
      <link>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</link>
      <description><![CDATA[如周氏《诊断医学中的统计方法》第 337-338 页所述，假设 $D$ 是一个随机变量，如果受试者患有疾病，则假设其值为 $1$。假设 $T$ 是一个随机变量，如果疾病检测结果为阳性，则假设其值为 $1$。假设 $V$ 是一个随机变量，如果受试者已对该疾病进行了进一步验证，则假设其值为 $1$。给定以下参数的值$\lambda_{11} = P(V=1|T=1,D=1)$, $\lambda_{01} = P(V=1|T=1,D=0)$, $\lambda_{10} = P(V=1|T=0,D=1)$, $\lambda_{00} = P(V=1|T=0,D=0)$, $\phi_1 = P(T=1)$, $\phi_{20} = P(D=1|T=0)$, $\phi_{21} = P(D=1|T=1)$，根据这些参数计算敏感度和特异性的正确方法是什么？例如，我知道敏感度是 $P(T=1|D=1)$，不考虑 $V$，它应该计算为 $P(T=1|D=1)P(D=1)/P(T=1)$，但如果必须考虑随机变量 $V$，公式会如何变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</guid>
      <pubDate>Wed, 08 Jan 2025 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>分子转化的逻辑回归建模</title>
      <link>https://stats.stackexchange.com/questions/659688/logistic-regression-modeling-of-molecule-conversion</link>
      <description><![CDATA[一个最近的问题涉及一种回归分析，其中一种化学物质用具有特定浓度的混合物处理，以查看转化为新物质的化学物质的比例。
回归分析使用浓度作为唯一特征，比例作为结果，而 OP 选择将比例强行塞入逻辑回归的结果变量中。
但是，假设我们知道分子的起始数量。然后，通过了解比例，我们就知道转化的分子数量。然后，我们可以使用更自然的逻辑回归，其中每个转化/非转化都是一个单独的结果，对应于浓度的特征值，例如$x = (0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.4, 0.6, 0.6, 0.6, 0.6)$，$y = (0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1)$。
但是，每个浓度水平不会有四个分子。会有数不清的分子。从计算的角度来看，这让我很担心，但从统计上讲，这也感觉像是作弊。我们一开始有三个双变量观测值：$x = (0.2, 0.4, 0.6)$，$y = (0.25, 0.5, 0.75)$。我们最终得到了无数个观测值。
但是，如果我们在三个浓度水平上有不同数量的分子，我可以看到这会给反应更多的反应混合物更高的权重，例如如果我们对一升原始分子进行一次反应，对一毫升进行一次反应。我认为在高浓度物质有恶臭，并且其使用量有限，无法使用一升的大反应混合物的情况下，这是一种合理的实验做法。
如果这样做会增加样本量并降低标准误差，那么这样做是否是作弊？那么，每个浓度水平的分子数量可能不同吗？
（从化学物理学的角度来看，我担心这些转化不太可能是独立事件。答案可以但不必解决这个问题。）]]></description>
      <guid>https://stats.stackexchange.com/questions/659688/logistic-regression-modeling-of-molecule-conversion</guid>
      <pubDate>Tue, 07 Jan 2025 21:37:38 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准差比平均值绝对偏差更受青睐？</title>
      <link>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</link>
      <description><![CDATA[第一部分
在探索了各种资源和论坛之后，我了解到标准差是一种广泛使用的离散度测量方法，通常比绝对平均偏差更受欢迎（我个人认为后者更简单、更直观），原因如下：
1. 方差的加性：
同意。
2. 平均值最小化平方偏差之和，而中位数（有时不是唯一的）最小化绝对偏差之和：
有点同意，但我不完全理解为什么在这里实现最小值是相关的。有人能解释一下为什么这个属性在选择离散度测量方法时很重要吗？
3.平方偏差在 𝑥 = 0 时可微分，而绝对偏差则不可微分：
有点同意，但我还是不明白为什么可微分性如此重要。这个属性在哪些方面有实际用途？
第二部分
我的独立想法/问题：
方差定义为与平均值的平方偏差的平均值，标准偏差是其平方根（“实际 SD”）。但是，如果标准偏差是平方偏差的平方根的平均值，那不是更有意义吗？ （我提议的是标准差的新定义“建议的 SD”）
(1 / n) * √ Σ((xᵢ - μ)²) 而不是 √(Σ (xᵢ - μ)² / n)

我的理由如下：
平方偏差主要是为了确保：

所有值都是正数。
偏差越大，权重越大。
平均值是使平方偏差之和最小化的数字。

绝对平均偏差达到点 (1)，绝对中位数偏差达到点 (1) 和 (3)。在这些情况下，我们将偏差相加，然后除以 𝑛 得到平均值。
但是，在方差和标准差的情况下，类似的“平均值”就是方差本身。但方差作为一个数字并不能直观地传达分布的扩展。这就是为什么我们要取方差的平方根来得到标准差。
所以，我的问题是：
为什么不使用&quot;建议 SD&quot;作为分散度的度量？
&quot;建议 SD&quot;有什么缺陷？
&quot;实际 SD&quot;为什么比&quot;建议 SD&quot;更适合作为分散度的度量？]]></description>
      <guid>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</guid>
      <pubDate>Tue, 07 Jan 2025 05:23:59 GMT</pubDate>
    </item>
    <item>
      <title>使用相机陷阱记录动物活动对火灾的反应——缺乏空间独立性的问题以及如何分析</title>
      <link>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</link>
      <description><![CDATA[我正在尝试为我的博士论文找出最佳的数据分析方法，但遇到了一些困难。
我从事生态学领域的工作，试图了解火灾前后动物群的反应。我正在使用 BACI 方法，并一直使用相机陷阱来捕捉动物的检测/活动。我遇到的问题是，我正在处理的火灾现场非常小，所以我必须制作一个高密度相机陷阱网格（即每个地点有 6 个相机，4 个监测点，相机间隔约 20 米，非常近）。到目前为止，我已经考虑了 60 分钟内在同一台相机上出现的动物（这是相机陷阱的标准做法，用于考虑可能在 60 分钟内被相机多次捕捉到的个体），但我正在努力解决每个站点的相机之间的空间自相关性 - 即动物可能在彼此相似的时间段内在相机之间移动的现实。
我读到我可以将每个站点视为重复，而不是每个站点内的每个相机，这样即使有动物在相机之间移动，它们在 60 分钟内被多个相机计数也无关紧要。这听起来合理吗？
有人有什么想法可以通过我的分析来解决这个问题吗？为了便于理解，我计划使用 GLMM（同样，许多其他人已经使用过），并且认为也许我可以使用相机编号作为随机效应？想看看是否还有其他人有什么我可以探索的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</guid>
      <pubDate>Tue, 10 Dec 2024 23:13:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？
编辑：可能对偶然发现这一点的其他人有帮助：FPR 可以描述为基准率、准确率和 PPV 的函数。对于 PPV &gt; 0.5，基准率和 FPR 之间的关联将始终为正。对于 0 &lt; 准确率 &lt; 1：fpr = ((base+acc-1)*(ppv-1))/((base-1)*(2*ppv-1))]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    </channel>
</rss>