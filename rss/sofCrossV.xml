<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Apr 2024 18:17:38 GMT</lastBuildDate>
    <item>
      <title>使用 glmer 模型无法收敛</title>
      <link>https://stats.stackexchange.com/questions/646117/model-failed-to-converge-using-glmer</link>
      <description><![CDATA[我的因变量是每分钟对 55 个人进行的 actigtraph 测量（计数数据 - 右偏，大多数值为 0）。我有大约 1.2m 行。这是我的简单随机拦截模型：
model1 &lt;-glmer.nb(activity ~ rescale_minute+(1|individual), data = data, glmerControl(optimizer=“bobyqa”,optCtrl=list(maxfun=2e5, maxIter = 1000)))


这是我遇到的错误：
f_refitNB(lastfit, theta = exp(t), control = control) 中的错误：
  (maxstephalfit) PIRLS 减半未能减少 pwrssUpdate 中的偏差
另外： 警告消息：
1：在 checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, 中：
  模型未能与 max|grad| 收敛= 0.794566（tol = 0.002，分量 1）

有人可以帮我解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646117/model-failed-to-converge-using-glmer</guid>
      <pubDate>Mon, 29 Apr 2024 18:09:13 GMT</pubDate>
    </item>
    <item>
      <title>确认 jagsUI 包中正确指定了 0 膨胀泊松模型</title>
      <link>https://stats.stackexchange.com/questions/646115/confirmation-that-0-inflated-poisson-model-is-specified-correctly-in-jagsui-pack</link>
      <description><![CDATA[我有表示栅格给定像元内道路数量的数据（值），我想检查它如何响应年份的固定效应（缩放，year_sc）以及单元 ID 和网格单元 ID（栅格和网格）的两种随机效应。我之前曾在 rjags 工作过，但为了与同事更好地协作，我已切换到 jagsUI。我想确保我编写的模型被正确指定。我知道我的数据是 0 膨胀的，因此我尝试在此处指定 0 膨胀的泊松分布。
&lt;前&gt;&lt;代码&gt;模型{
    for (i in 1:N) {
    
      # 某些 0 的 Logit 模型
      mu[i] &lt;- exp(beta0 + beta1 *year_sc[i] + rasterRE[raster[i]] + gridRE[grid[i]])
      
      # 伯努利分布，确定 i 是否为 0 膨胀
      zi[i] ~ dbern(z)
      
      # 通货膨胀模型
      值[i] ~ dpois(mu[i] * (1 - zi[i]))

    }
  
    # 先验
    beta0 ~ dnorm(0, 0.01)
    beta1 ~ dnorm(0, 0.01)
    
    for (j in 1:nCells) {
      rasterRE[j] ~ dnorm(0, tau_rast)
    }
    
    for (k in 1:nTiles) {
      gridRE[k] ~ dnorm(0, tau_grid)
    }
    
    tau_rast ~ dgamma(0.001, 0.001)
    tau_grid ~ dgamma(0.001, 0.001)
    
    z ~ dbeta(1, 1) # 零通货膨胀参数的先验
}

如果这看起来不正确或任何确认这是正确的，我将非常感谢任何帮助解决此问题！]]></description>
      <guid>https://stats.stackexchange.com/questions/646115/confirmation-that-0-inflated-poisson-model-is-specified-correctly-in-jagsui-pack</guid>
      <pubDate>Mon, 29 Apr 2024 18:04:16 GMT</pubDate>
    </item>
    <item>
      <title>多元 Fréchet 分布的期望</title>
      <link>https://stats.stackexchange.com/questions/646112/expectation-of-the-multivariate-fr%c3%a9chet-distribution</link>
      <description><![CDATA[我有多元 Fréchet 分布
$$F(z_1,...,z_n)=\exp{-\left[\sum_{i=1}^{n}(T_i Z_i^{-\theta} )^\frac{1}{\rho}\right]^\rho}$$
我想找到 $\mathrm E(Z_i) $ 和 $\mathrm E( Z_i\mid a Z_i &gt; b Z_j) $ 其中 a 和 b 是常数。]]></description>
      <guid>https://stats.stackexchange.com/questions/646112/expectation-of-the-multivariate-fr%c3%a9chet-distribution</guid>
      <pubDate>Mon, 29 Apr 2024 16:32:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Rao-Blackwell 改进 P(X/Y < t) 的估计量</title>
      <link>https://stats.stackexchange.com/questions/646111/using-rao-blackwell-to-improve-the-estimator-of-px-y-t</link>
      <description><![CDATA[X 和 Y 是独立的 N (0, 1) 个随机变量，我们想要近似 P (X/Y ≤ t)，对于固定数字 t。
问题的第一部分是描述朴素的蒙特卡罗估计。我描述过，您应该独立地获取 X 和 Y 的样本（大小均为 n），获取样本值的比率，然后找到该比率小于 t 的次数，并将其除以总样本大小 n。&lt; /p&gt;
下一部分是提出一种基于 Rao-Blackwellization 的更复杂的蒙特卡洛方法。我对如何做到这一点感到非常困惑，因为我们从未深入讨论过 Rao-Blackwell。我发现的所有例子都与这样的问题无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/646111/using-rao-blackwell-to-improve-the-estimator-of-px-y-t</guid>
      <pubDate>Mon, 29 Apr 2024 16:22:27 GMT</pubDate>
    </item>
    <item>
      <title>构建一个算法来使用贝叶斯条件概率结合关联规则来构建预测模型？</title>
      <link>https://stats.stackexchange.com/questions/646109/building-an-algorithm-to-use-bayes-conditional-probability-in-conjunction-with-a</link>
      <description><![CDATA[关联规则是一种数据挖掘技术，用于识别大型数据集中变量之间的有趣关系。这些规则采用“if-then”的形式。陈述，其中某些项目的存在意味着其他项目的存在。用于评估这些关联的常见措施包括支持、信心和提升。关联规则主要是描述性的而不是预测性的。它们描述了数据中发现的关系和模式。例如，虽然提升可以指示项目之间关联的可能性，但它更多的是关于数据集中的关联强度，而不是单个实例的预测能力。
贝叶斯概率是一个统计概念，表示对事件发生的信念或置信度，结合了先验知识和观察到的证据。
是否可以结合使用贝叶斯概率和关联规则来构建预测模型？
我们可以使用关联规则来识别模式，并根据这些关联规则计算先验概率。当新数据可用时，使用贝叶斯推理更新先验概率。这些来自贝叶斯推理的更新后验概率可用于预测未来事件。使用新数据不断评估模型的性能并根据需要进行改进。
这对于高维数据特别有用，因为其他建模技术可能会受到影响。
这个构建起来有趣吗？我们如何将关联规则度量转换为先验概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/646109/building-an-algorithm-to-use-bayes-conditional-probability-in-conjunction-with-a</guid>
      <pubDate>Mon, 29 Apr 2024 16:02:19 GMT</pubDate>
    </item>
    <item>
      <title>ipw 分析中标准化均值差异较大怎么办</title>
      <link>https://stats.stackexchange.com/questions/646108/what-to-do-with-large-standardized-mean-difference-in-ipw-analysis</link>
      <description><![CDATA[我正在处理队列数据，我正在尝试评估丢失对后续值和缺失值的影响。因此，我首先使用链式方程进行多重插补，然后使用插补数据集来计算倾向得分（使用 r 中的 MatchThem 包中的 weightthem 函数）。我按照这个包的教程进行操作，并评估了平衡性。我的倾向得分的绝对标准化平均差为 1.04，柯尔莫哥洛夫-斯米尔诺夫统计为 0.37。所有其他协变量看起来都不错。我想知道我应该继续使用数据进行因果效应估计，还是应该对这种不平衡采取一些措施？]]></description>
      <guid>https://stats.stackexchange.com/questions/646108/what-to-do-with-large-standardized-mean-difference-in-ipw-analysis</guid>
      <pubDate>Mon, 29 Apr 2024 15:56:58 GMT</pubDate>
    </item>
    <item>
      <title>获胜概率的逻辑回归：参数化</title>
      <link>https://stats.stackexchange.com/questions/646107/logistic-regression-for-win-probability-parameterization</link>
      <description><![CDATA[我正在使用逻辑回归对棒球比赛的结果进行建模。我正在努力理解分析的结果，我相信这与模型的参数化有关。具体来说，我观察到了不对称的预测准确性，并且我正在尝试诱导准确性的对称性。
假设我们有一组主队的协变量 $\mathbf{x}_h$ 和另一组客队的协变量 $\mathbf{x}_a$。我能想到的第一个模型设置 $y = 1(\text{主队获胜})$，并且让
$$
y \sim f(\beta_0 + \beta_1 \mathbf{x}_1 + \beta_2 \mathbf{x}_2), \quad \mathbf{x}_1 = \mathbf{x}_h, \enspace \mathbf{x} _2 = \mathbf{x}_a
$$
在该模型中，主队被编码为第一个位置向量，客队被编码为第二个向量。
为了分析模型的性能，我考虑了预测概率在不同阈值下的条件准确性$\hat{p} = P(y=1)$。让 $\hat{y} = 1(\hat{p})&gt;0.5$。对于给定阈值 $\tau$，用 $n_\tau$ 表示 &lt; 的值的数量span class=&quot;math-container&quot;&gt;$\hat{p}_i$ 大于 $\tau$ - 即 $n_\tau = \sum_i 1(\hat{p}_i &gt; \tau)$。然后，我计算精度 $\alpha_\tau = (1/n_\tau) \sum_i 1(\hat{y}_i = y_i | \hat{p}_i &gt; \tau)$。我对 $\tau &gt; 的值执行了此操作0.5$；我也为 $\tau $\tau  这样做了0.5$ 条件 $\hat{p}_i  \tau$.
根据经验，该模型存在一些偏差：
 侧面精度 n
6＜ 0.300 0.727 11
7 &lt; 0.350 0.562 48
8＜ 0.400 0.545 165
9 &lt; 0.450 0.531 426
10&gt; 0.500 0.553 1404
11&gt; 0.550 0.578 948
12&gt; 0.600 0.630 506
13&gt; 0.650 0.684 215
14&gt; 0.700 0.793 58
15&gt; 0.750 0.733 15
16&gt; 0.800 0.667 3

例如，当 $\hat{p} 时，预测 $y=1$ 的准确度为 63% &gt; 0.6$；但当 $\hat{p} $\hat{p}  时，预测 $y=0$ 的准确度为 55%。 0.4 美元。也许这是有道理的：我们重视主场胜利。但在模型中这是不可取的，因为两个团队的准确度并不对称。
所以我做了一个练习：随机选择哪支球队是主场还是客场。这与上面的模型等效，但 $\mathbf{x}_1$ 可以是 $\mathbf{x} _h$ 或 $\mathbf{x}_a$ 随机。这将从模型中消除任何主队优势，但我很好奇发生了什么。
当我使用 $\mathbf{x}_1 = \mathbf{x}_h$ 考虑所有样本外评估的数据时，结果相似： 
 侧面精度 n
5＜ 0.250 0.000 1
6＜ 0.300 0.500 2
7 &lt; 0.350 0.528 36
8＜ 0.400 0.543 186
9 &lt; 0.450 0.539 575
10&gt; 0.500 0.586 1060
11&gt; 0.550 0.618 471
12&gt; 0.600 0.722 144
13&gt; 0.650 0.818 22
14&gt; 0.700 0.833 6
15&gt; 0.750 1.000 3
16&gt; 0.800 1.000 1

但是，如果我也对样本外进行随机化，那么准确度路径（最终）是对称的：
&lt;前&gt;&lt;代码&gt;
   侧面精度 n
5＜ 0.250 1.000 1
6＜ 0.300 1.000 2
7 &lt; 0.350 0.655 29
8＜ 0.400 0.617 175
9 &lt; 0.450 0.586 539
10&gt; 0.500 0.547 1124
11&gt; 0.550 0.566 505
12&gt; 0.600 0.641 156
13&gt; 0.650 0.704 27
14&gt; 0.700 0.833 6
15&gt; 0.750 0.667 3
16&gt; 0.800 1.000 1

我注意到在非对称版本中，有 $n_{0.55}=471$ 个预测高于 $\tau =0.55$，而有 331 个预测为 $&lt;0.4$ 或 $&gt;0.5 $.
我担心 $\mathbf{x}_1 = \mathbf{x}_h$ 的参数化会导致预测精度不对称，我会喜欢引起对称性。如何解释这些结果？还有其他方法可以诱导对称吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646107/logistic-regression-for-win-probability-parameterization</guid>
      <pubDate>Mon, 29 Apr 2024 15:49:20 GMT</pubDate>
    </item>
    <item>
      <title>分解 lavaan 顺序中介中解释的方差</title>
      <link>https://stats.stackexchange.com/questions/646106/decompose-variance-explained-in-sequential-mediation-in-lavaan</link>
      <description><![CDATA[我正在 R 中的 lavaan 中使用顺序中介分析（又名串行中介）。
下面是我的模型
模型 &lt;- &quot;y ~ a*x1 + b*x2 + c*x3 + d*x4
x1 ~ b1*x2 + c2*x3 + d2*x4
x2 ~ c3*x3 + d3*x4

x2_y := b1*a + b
x3_y := c2*a + c3*b + c
x4_y := d2*a + d3*b + d
”

拟合 &lt;- SEM（模型）

我想进行诸如显性分析之类的事情来分解结果变量解释的方差，类似于线性多元回归中每个预测变量的 R^2。
对于基线回归模型，我现在知道一个可以给出我预期结果的函数：
model_baseline &lt;- &quot;
y〜x1+x2+x3+x4”
fit_baseline &lt;- sem(model_baseline)
fit_baseline.cor &lt;- lavCor(fit_baseline)
迷雾::统治.手册(fit_baseline.cor)

我的问题是，当添加更多中介路径时，如何获得每个因素解释的方差？中介因素的值可能较低，而被中介因素的值可能较高。任何有关包、函数或手动计算的建议将不胜感激。
我知道我的模型并不完全相同，但这项工作[https://www.econ.cam.ac.uk/research-files/repec/cam/pdf/cwpe2171.pdf]与什么高度相关我打算实现。我想知道添加中介路径的模型是否在解释方差方面改善了模型性能，以及通过添加中介路径如何改变结果变量解释的方差份额。]]></description>
      <guid>https://stats.stackexchange.com/questions/646106/decompose-variance-explained-in-sequential-mediation-in-lavaan</guid>
      <pubDate>Mon, 29 Apr 2024 15:37:59 GMT</pubDate>
    </item>
    <item>
      <title>作为线性回归中的序数预测变量在层次结构中的位置</title>
      <link>https://stats.stackexchange.com/questions/646105/position-in-hierarchy-as-ordinal-predictor-in-linear-regression</link>
      <description><![CDATA[我正在写论文，但我不确定分析过程。其中一个假设是：“死者在死者的依恋层次中的位置越高，预示着复杂的悲伤程度就越高。”在依恋层次中的位置是一个变量，作为三项综合得分的中位数创建，其中0表示死者不在死者的依恋层次中（依恋层次是一个心理学概念），1=排名第四，2=排名第四第三，3 = 排名第二，4 = 在层次结构中排名第一。我想使用多元线性回归（我还有其他预测变量）来确定较高的排名是否预示着较高程度的复杂悲伤。复杂悲伤程度是一个连续变量。因此，“层级中的位置”是指“层级中的位置”。变量只接受 0 到 4 之间的值。虚拟编码对我来说没有意义，因为它不是名义变量而是序数变量。当我尝试为层次结构变量中的位置生成一些描述性统计数据或散点图时，与其他连续自变量相比，这些图表看起来很奇怪。我做错了什么吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/646105/position-in-hierarchy-as-ordinal-predictor-in-linear-regression</guid>
      <pubDate>Mon, 29 Apr 2024 15:22:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么笛卡尔积空间上的统计模型会产生预测下一个元素的可能性？</title>
      <link>https://stats.stackexchange.com/questions/646104/why-does-statistical-model-over-cartesian-product-space-yield-likelihood-for-pre</link>
      <description><![CDATA[这不是一个如何估计可能性的问题，而是一个弥合直觉和理论之间差距的问题。
激励设置
假设我们观察 10 位的样本 $\{1,0,1,0,0,1,0,0,1,1\}$，并据此我们估计 $\mathbf{p}(x=1) = 0.5$。因此，鉴于第 11 位 $x_{11}$，我们知道它是 1 的可能性是 $0.5$.
现在更正式地，让有一个向量 $\mathbf{x}$，在笛卡尔积样本空间中取值$\Omega^n$，其中每个 $\Omega = \{0,1\}$。现在假设分布处于指数族中，具有足够的统计量 $\mathbb{\phi}(x) = x$，均值 $\mu = 1/n \sum_{i=1}^n x_i$，以及形式 $\mathbf{p}(\mathbf{x} ;\mu) = exp( \mathbf{\phi}(\mathbf{x})\mu + A(\mu) )$，其中 $A$&lt; /span&gt; 是日志分区函数。观察了许多 $\mathbf{x} \in \Omega^n$ 的例子后，我们估计了什么？观察 $\Omega^n$ 中的示例后，单个位 $1$ 的可能性是多少？
问题
这是直觉与上面所写内容之间存在一些不匹配的部分。因为 $\Omega^n$ 中的样本是 n 位字符串，所以但是样本的足够统计数据是单个位的可能性1. 然而概率函数 $ \mathbf{p}(\mathbf{x};\mu)$ 实际上是单个 $n$ $\Omega^n$ 中的位字符串可以采用任何值。例如，如果分布是均匀的，则：
\begin{方程}
\mathbf{p}(\mathbf{x};\mu) = \frac{1}{2^n}
\end{方程}
对于每个 n 位字符串。我们无法从中获得 $1/2$ ，除非我们要求一组 $n$&lt; /span&gt; 位字符串，其中一半位为 1，并再次假设在所有 $n$ 位字符串上均匀分布。你当然不能基于此编写 $\mathbf{p}(\mathbf{x}=1;\mu)$ ，因为 $\mathbf{p}$ 这里测量的是样本空间$\Omega^n$，而不是单个$\Omega$。
有关指数族和样本空间构造的其他阅读引起了我的困惑

为什么我们需要西格玛代数定义概率空间？

https://www.youtube.com/watch?v=7WvdpFqptZk&lt; /a&gt;

https://cba.mit。 edu/events/03.11.ASE/docs/Wainwright.1.pdf

]]></description>
      <guid>https://stats.stackexchange.com/questions/646104/why-does-statistical-model-over-cartesian-product-space-yield-likelihood-for-pre</guid>
      <pubDate>Mon, 29 Apr 2024 15:18:20 GMT</pubDate>
    </item>
    <item>
      <title>横截面数据的内生性</title>
      <link>https://stats.stackexchange.com/questions/646100/endogeneity-in-cross-sectional-data</link>
      <description><![CDATA[作为计量经济学的新手，我目前面临着构建理论上有说服力的模型来识别因果效应的挑战。
我感兴趣的是家庭 i (X1) 的农业劳动力需求是否会影响儿童在家务农业工作 (Y) 中的工作。
我的假设是，如果教育机会成本高，孩子很可能会从事家务农活。
另一个潜在的决定因素是家庭收入水平（X2），这可能会影响儿童的农业劳动。
数据是横截面数据。
每个观察结果都对应于家庭 i 中的一个孩子。我处理了辅助数据来创建这个。原始数据来自泰国越南社会经济小组 (TVSEP)，如有需要，可向所有人提供。
鉴于X1和X2都是内生的，而且我还没有找到合适的工具变量，我们可以讨论一下建立X1和Y之间因果关系的策略吗？
此外，根据我的理解，倾向得分匹配可能不适合，因为X1是连续变量。
此外，非常欢迎对我所提出的问题进行建模的替代解决方案。
附注
TVSEP 数据是面板数据，但有关劳动力需求的信息只能从 2017 年收集的第二个最新数据集中获得。最近一次调查是在 2022 年进行的。由于 2022 年恰逢 COVID-19 大流行，这可能会影响儿童的工作状态，我选择不使用它来构建面板数据。这就是为什么我使用 2017 年数据作为横截面数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/646100/endogeneity-in-cross-sectional-data</guid>
      <pubDate>Mon, 29 Apr 2024 14:53:36 GMT</pubDate>
    </item>
    <item>
      <title>您如何对 ARMA(1,1)-EGARCH(1,1) 中从风险到回报的溢出效应进行建模？</title>
      <link>https://stats.stackexchange.com/questions/646098/how-would-you-model-a-spill-over-effect-from-risk-to-returns-in-the-arma1-1-eg</link>
      <description><![CDATA[
在 Yt 中添加风险溢价因子（如图所示）？]]></description>
      <guid>https://stats.stackexchange.com/questions/646098/how-would-you-model-a-spill-over-effect-from-risk-to-returns-in-the-arma1-1-eg</guid>
      <pubDate>Mon, 29 Apr 2024 13:53:11 GMT</pubDate>
    </item>
    <item>
      <title>使用套索回归实现 SEM</title>
      <link>https://stats.stackexchange.com/questions/646096/implementing-a-sem-with-lasso-regression</link>
      <description><![CDATA[我想到了以下结构方程模型 (SEM) 结构：

实际上，有超过 3,2 个。 3 个变量，所以我想对箭头使用套索回归。可以在python中实现吗？我在R中看到了一些包（例如lavaan、regsem），但这似乎是一个基本任务，在Python中也应该是可能的。我对 R 不太精通，所以我更喜欢 python 实现。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646096/implementing-a-sem-with-lasso-regression</guid>
      <pubDate>Mon, 29 Apr 2024 13:48:24 GMT</pubDate>
    </item>
    <item>
      <title>我想通过模拟证明，对于非正态分布数据，Wilcoxon 检验比 Student 检验更稳健</title>
      <link>https://stats.stackexchange.com/questions/646091/i-want-to-show-by-simulation-that-the-wilcoxon-test-is-more-robust-than-the-stud</link>
      <description><![CDATA[我想通过模拟来测试，对于非正态分布数据，Wilcoxon 检验比 Student 检验更稳健。
例如，我正在测试均匀分布和指数分布。不知道是我模拟错了还是漏掉了什么。但我找不到 Wilcoxon 检验与 Student 检验相比的稳健性？
我进行了模拟，使得群体 A 的平均值比群体 B 的平均值高出 1 个点。
&lt;前&gt;&lt;代码&gt;##统一格式------
人口A&lt;-轮(runif(100000, 73,75),1)
人口B&lt;-轮(runif(100000, 72,74),1)
t.test(群体A,群体B)

绘图（密度（人口A））
绘图（密度（人口B））

n＜-5
n＜-10

sub_popA&lt;-样本(populationA,size = n)
sub_popB&lt;-样本(populationB,size = n)

t.test(sub_popA,sub_popB)$p.value
wilcox.test(sub_popA,sub_popB)$p.value

在不同的样本量下，我发现 Student 检验比 Wilcoxon 检验更接近事实。
指数分布也是一样，我没有发现 Wilcoxon 检验与 Student 检验相比有什么优越性。即使重复采样 100 次并计算数量
&lt;前&gt;&lt;代码&gt;##
人口A&lt;-reexp(100000,1)
人口B&lt;-rexp(100000,1/2)
t.test(群体A,群体B)

sub_popA&lt;-样本(populationA,大小 = 10)
sub_popB&lt;-样本(populationB,大小 = 10)
t.test(sub_popA,sub_popB)
wilcox.test(sub_popA,sub_popB)
]]></description>
      <guid>https://stats.stackexchange.com/questions/646091/i-want-to-show-by-simulation-that-the-wilcoxon-test-is-more-robust-than-the-stud</guid>
      <pubDate>Mon, 29 Apr 2024 12:25:42 GMT</pubDate>
    </item>
    <item>
      <title>何时应在 Cox 比例风险回归中使用 R 中的稳健误差函数？</title>
      <link>https://stats.stackexchange.com/questions/646086/when-should-the-robust-error-function-in-r-be-used-in-cox-proportional-hazard-re</link>
      <description><![CDATA[让我们考虑这样一个场景：我计算的 HR 似乎违反了根据 cox.zph 测试的比例风险假设，但在绘制平滑缩放 Schoenfeld 残差图时，发现违反情况不是“真实的”，这是通过检查残差图来评估系数随时间的偏差而确定的，在这种情况下，偏差很小。
我一直在根据之前的交叉验证讨论来研究这个问题 链接上。尽管违反了假设，只要在 Cox 模型中应用函数robust=T，风险比 (HR) 仍然可以用于解释。那么，HR 将被称为失效时间平均风险比。
但是，虽然我不是统计学家，但我尝试了解何时使用 robust=T 的概念。
我的问题如下：

根据我的理解，鲁棒误差用于计算异方差数据中的标准差。因此，如果违反比例风险假设，是否可以假设用于 Cox 分析的数据是异方差的？这就是为什么建议在这种情况下计算鲁棒误差吗？换句话说，违反比例风险假设是否表明异方差性，或者是否暗示异方差性？

即使不违反比例风险假设，robust=T 函数是否应该始终包含在 cox 模型中？

时间平均 HR 是否应始终称为“故障时间平均风险比”，还是仅当 Cox 模型中隐含 robust=T 函数时才称为“故障时间平均风险比”？ 

]]></description>
      <guid>https://stats.stackexchange.com/questions/646086/when-should-the-robust-error-function-in-r-be-used-in-cox-proportional-hazard-re</guid>
      <pubDate>Mon, 29 Apr 2024 11:00:26 GMT</pubDate>
    </item>
    </channel>
</rss>