<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 18 Apr 2024 03:14:26 GMT</lastBuildDate>
    <item>
      <title>ARMA$\left(2,2\right)$ 模型的方差</title>
      <link>https://stats.stackexchange.com/questions/645272/variance-of-arma-left2-2-right-model</link>
      <description><![CDATA[&lt;块引用&gt;
如果 $Y_t = 5 + 2Y_{t-1} - 1.7Y_ 则求 $Var(∇Y_t)$ {t-2} + 0.7Y_{t-3} + e_t - 0.5e_{t-1} + 0.25e_{t-2}$。

我已将其减少为 $∇Y_t = 5 + ∇Y_{t-1} - 0.7∇Y_{t-2} + e_t - 0.5e_{t- 1} + 0.25e_{t-2}$。现在，假设 $W_t = ∇Y_t - \mu$，其中 $\mu$ 是某个常数，我们可以将其改造成 ARMA$\left(2,2\right)$ 模型：$$W_t = W_{t-1} - 0.7W_{t-2} + e_t - 0.5e_{t-1} + 0.25e_{t-2}$$
将模型分解为 AR/MA 特征多项式形式：
$(1 - B_1 + 0.7B_1^2)W_t = (1 - 0.5B_2 + 0.25B_2^2)e_t$，我们找到所有根$|B_1|&gt;1$ 和 $|B_2|&gt;1$，因此满足平稳和可逆的要求。因此，$E(W_t) = 0$，因此 $Var(∇Y_t) = Var(W_t) = E( W_t^2) = E\left(W_t(W_{t-1} - 0.7W_{t-2} + e_t - 0.5e_{t-1} + 0.25e_{t-2}) \right)$。我无法进一步简化它。]]></description>
      <guid>https://stats.stackexchange.com/questions/645272/variance-of-arma-left2-2-right-model</guid>
      <pubDate>Thu, 18 Apr 2024 02:42:08 GMT</pubDate>
    </item>
    <item>
      <title>多实例时间序列数据区间分类</title>
      <link>https://stats.stackexchange.com/questions/645270/classification-of-intervals-in-time-series-data-of-multiple-instances</link>
      <description><![CDATA[我有一个问题正在尝试解决。我有来自心电图的信号数据（随时间变化的经典信号数据）。这里有一个接近的例子：https://github.com/jjongjjong/ECG_segmentation_1DUnet
我主要对识别心电图数据中的片段（t 波、QRS 等）感兴趣。
因此数据来自多个患者（重复测量或独立患者），每个患者都有自己的元数据。输出是一个one-hot编码的x轴（时间），指示要分类的间隔（比上一个链接中的数据更简单）
我的想法是，我需要一个具有简单层或两个卷积层的神经网络，然后是循环层或变压器层。据我所知，添加状态保持层对于这个问题来说是一个好主意，但似乎很难实现。
那么我如何实现具有患者特征的神经网络以获得感兴趣的输出？]]></description>
      <guid>https://stats.stackexchange.com/questions/645270/classification-of-intervals-in-time-series-data-of-multiple-instances</guid>
      <pubDate>Thu, 18 Apr 2024 01:51:17 GMT</pubDate>
    </item>
    <item>
      <title>事后效应大小与 p 值是否冗余？</title>
      <link>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-effect-size-redundant-with-the-p-value</link>
      <description><![CDATA[为了简单起见，假设我们正在对 2 个正态分布总体进行 2 样本 t 检验，从中收集 2 个 i.i.d 样本。 （首先；我们可以稍后扩展到更复杂的情况）。我们知道，一项研究的事后观察功效完全由观察到的 p 值决定。请参阅此处，或此处，以及此网站上的多个参考。
然后，事后我们得到了计划的 $\alpha$ （传统上为 0.05），实际样本大小 $N $ 和 p 值 $p$。但从 $p$ 中我们可以获得电源 ($1-\beta$)，如链接。我们有观察到的标准差 ($sd$)。我将其插入任何功耗分析软件中，它将给出研究所支持的最小效应：我们称之为 $\delta$。我们观察到了效果 ($\delta&#39;$)。
认为 $\delta&#39;$ 与 $p$？ （正如功率与 p 的链接所示）。也许用 $\delta&#39;=\delta$ 来表示 $p$=.05？ （即功率=50%）。或者事后效应大小是一个随机变量吗？在这种情况下，它的分布可能是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-effect-size-redundant-with-the-p-value</guid>
      <pubDate>Thu, 18 Apr 2024 01:40:12 GMT</pubDate>
    </item>
    <item>
      <title>给定回归参数的点估计的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/645268/confidence-interval-over-point-estimate-given-regression-parameters</link>
      <description><![CDATA[在贝叶斯分析中，当 PDF 不难处理时（经常），通常会对海报分布进行采样。如果样本的长度为 $n$ 则 $range(1,n)$ 中的每个索引都对应从该（通常是多维的）分布中获取有效样本。在简单线性回归的背景下，斜率、截距和噪声是后验分布的三个维度（假设没有超先验）。
要计算给定点周围的可信分布$P(\hat{y}|x, \beta_0, \beta_1)$，可以运行模拟其中可以对 $range(1,n)$ 中的索引进行采样并检索参数值；随后，可以计算 $\hat{y}$ 的值并将其附加到数组中。最后，可以根据需要对数组进行排序和处理（例如 95% 的可信区间。）
我的问题是，频率统计的类似过程是什么？即使斜率或系数具有统计显着性并且每个的置信区间已知，这也不是模型参数之间的联合分布。因此，我怀疑无法独立地从每个置信区间中采样参数来计算点估计的分布。
这可以通过Frequentist工具包实现吗？或者问这样的问题纯粹是贝叶斯构造，而频率论者除了知道参数值的含义是什么以及它们是否重要之外不会感兴趣？]]></description>
      <guid>https://stats.stackexchange.com/questions/645268/confidence-interval-over-point-estimate-given-regression-parameters</guid>
      <pubDate>Thu, 18 Apr 2024 00:18:14 GMT</pubDate>
    </item>
    <item>
      <title>是否可以根据精确率和召回率值估计正例的数量？</title>
      <link>https://stats.stackexchange.com/questions/645264/is-it-possible-to-estimate-the-number-of-positives-from-precision-and-recall-val</link>
      <description><![CDATA[假设我有一个二元预测器，并且从之前的研究中可以得知它在精确度和召回率方面的表现。现在，我们将预测器应用于包含 1000 个样本的新（未知）数据集，并获得了 80 个预测正值。
根据我们之前的研究，我们知道精度 = 0.99，召回率 = 0.6。
因为准确率 = TP/PP，召回率 = TP/P。为了计算正样本总数（P），我可以计算：
80 * 精度/召回率 = 132
显然，我必须假设预测器的工作方式与新数据集中的预测器完全相同。
以上论点合理吗？我在这里遗漏了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645264/is-it-possible-to-estimate-the-number-of-positives-from-precision-and-recall-val</guid>
      <pubDate>Wed, 17 Apr 2024 21:05:04 GMT</pubDate>
    </item>
    <item>
      <title>缩放二元逻辑回归的优势比</title>
      <link>https://stats.stackexchange.com/questions/645255/scaling-the-odds-ratio-of-a-binary-logistic-regression</link>
      <description><![CDATA[简单说一下 - 简而言之，我正在开展一项有关年龄和婚姻的研究。
我发现，通过二元逻辑回归（因变量是否已婚），年龄的优势比为 1.01（p &lt; 0.001 时显着）。注：年龄范围为 18 岁（最年轻的受访者）到 82 岁（最年长的受访者）。
我很确定我的解释是正确的：“在所有其他控制不变的情况下，年龄每增加一年，结婚的可能性就会增加 1%”。我的困惑是，我最初将此解释为基本上具有统计显着性结果的指示，但实质性价值较低（假设只有 1%）。
但我发现有些人可能会调整他们的优势比 - 即。表明年龄增加 20 岁意味着结婚的可能性增加 1.01^20 = 1.22。这表明 40 岁的人结婚的可能性比 20 岁的人高 22%。
这是正确的吗？在我看来，你可以简单地按比例放大它并假设优势比在所有情况下保持不变，这似乎是误导？如果是这样的话，那么这个发现对“现实生活”的影响可能比我想象的更大？]]></description>
      <guid>https://stats.stackexchange.com/questions/645255/scaling-the-odds-ratio-of-a-binary-logistic-regression</guid>
      <pubDate>Wed, 17 Apr 2024 18:51:52 GMT</pubDate>
    </item>
    <item>
      <title>如果树上的某些物种在数据集中出现多次，是否可以进行 PGLS 分析？</title>
      <link>https://stats.stackexchange.com/questions/645263/is-it-possible-to-do-a-pgls-analysis-if-some-species-on-the-tree-appear-more-tha</link>
      <description><![CDATA[我正在尝试对苍蝇的保真度和相对大小进行 PGLS 回归，但是某些苍蝇种类在数据集中出现不止一次（它们的相对大小与不同的事物进行比较，因此虽然该物种出现的次数超过一旦，它仍然应该是一个单独的数据点，因为数据代表不同的东西）。但是，我不知道如何处理分析中某些物种的重复。
我有我的系统发育树，但是在使用 ape/nlme 包进行分析时，我的 R 经常完全崩溃。我也尝试使用 caper 包，但它说不允许重复的行名称。
这是我用于雀跃的代码，但我不知道如何更改它，以便它允许物种复制。
data&lt;-read.csv(“dataset.csv”, header=TRUE, row.names = NULL)
comp.data&lt;-比较.data（树，数据，names.col =“物种”，vcv.dim = 2，warn.dropped = TRUE）
模型&lt;- pgls(Fidelity~Size, data=comp.data)
摘要（模型）

是否还有更好的方法来进行此分析？谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/645263/is-it-possible-to-do-a-pgls-analysis-if-some-species-on-the-tree-appear-more-tha</guid>
      <pubDate>Wed, 17 Apr 2024 17:35:40 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟非标准化人工数据进行逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/645246/how-to-simulate-non-standardized-artificial-data-for-logistic-regression</link>
      <description><![CDATA[我想使用原始规模的预测变量来模拟逻辑回归的数据。
当然，之前还有一连串类似的问题（例如，此处，此处和此处）。但我的问题集中在反向链接函数的操作上。
原始（未居中且未缩放）X
将原始规模的预测变量与标准反向链接函数相结合会产生阻止总体 beta 值恢复的结果。当然，我知道这个特定问题主要是反向链接函数与 xb 不匹配，因此生成的 p 值始终几乎或实际上等于 1。例如：
set.seed(42)

n &lt;- 10000

贝塔 &lt;- c(1, 2, 3)

数据 &lt;- data.frame(
  x1 = 样本(c(0,1), 大小 = n, 替换 = TRUE),
  x2 = 轮(runif(n, 18, 80)),
  x3 = rnorm(n, 100, 10)
）

# 在第二个示例中取消注释
#data$x2 &lt;- 比例(data$x2)
#data$x3 &lt;- 比例(data$x3)

x &lt;- as.matrix(数据)

xb &lt;- x %*% 贝塔
p &lt;- 1 / (1 + exp(-xb))
数据$y &lt;- rbinom(n, 1, p)

glm(y ~ -1 + x1 + x2 + x3, data = data, family = “二项式”) |&gt;
  系数()
#&gt;警告：glm.fit：算法未收敛
#&gt;警告：glm.fit：出现数字 0 或 1 的拟合概率
#&gt; x1 x2 x3
#&gt; 0.68776594 0.04537462 0.27567873

创建于 2024 年 4 月 17 日，使用 reprex v2.1.0
缩放（居中并缩放）X
但是，首先缩放连续预测变量可以防止此问题。例如：
set.seed(42)

n &lt;- 10000

贝塔 &lt;- c(1, 2, 3)

数据 &lt;- data.frame(
  x1 = 样本(c(0,1), 大小 = n, 替换 = TRUE),
  x2 = 轮(runif(n, 18, 80)),
  x3 = rnorm(n, 100, 10)
）

数据$x2 &lt;- 比例(data$x2)
数据$x3 &lt;- 比例(data$x3)

x &lt;- as.matrix(数据)

xb &lt;- x %*% 贝塔
p &lt;- 1 / (1 + exp(-xb))
数据$y &lt;- rbinom(n, 1, p)

glm(y ~ -1 + x1 + x2 + x3, data = data, family = “二项式”) |&gt;
  系数()
#&gt; x1 x2 x3
#&gt; 0.9732245 1.9205790 2.8166412

创建于 2024 年 4 月 17 日，使用 reprex v2.1.0
我尝试过的

将总体截距设置为 xb 的负均值
居中和缩放 xb
将反向链接函数以 xb 的平均值为中心
根据 xb 上计算的各种统计数据对反向链接函数进行居中和缩放

但是，这些方法都不允许我生成一个模拟数据集，其中包含原始规模的预测变量以及可以通过逻辑回归轻松直接建模的响应变量。
我想要什么
我想了解如何利用截距和/或修改标准形式的反向链接函数，而不是缩放，以便生成 p 值的分布，然后导致 y 值允许恢复总体贝塔值。我想我更感兴趣的是了解如何操纵反向链接函数来“自动”操作。生成具有所需属性的 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/645246/how-to-simulate-non-standardized-artificial-data-for-logistic-regression</guid>
      <pubDate>Wed, 17 Apr 2024 17:13:30 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析配对且重复测量的数据？</title>
      <link>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</link>
      <description><![CDATA[我在 11 天内从同一受试者 (n=10) 收集数据，每天在两种条件下进行测量：训练后立即 (D0) 和训练后 30 分钟 (D30)。数据是有序的，范围从 1 到 10。我想了解训练后立即进行的测量和训练后 30 分钟进行的测量之间是否存在差异。我应该如何分析这些数据，我应该使用哪种测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</guid>
      <pubDate>Wed, 17 Apr 2024 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>如何计算出有多少项目会超出错误阈值？</title>
      <link>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</link>
      <description><![CDATA[让我解释一下我正在使用哪些数字，然后我会解释问题。

我计算了一家商店去年所有商品的第 99 个百分位预测误差阈值。
然后，我报告过去两周内错误大于该阈值的项目数。 （无论是一天还是十四天，如果预测误差大于阈值，就会被标记。）

好的，就这样了。问题是，我想知道，在统计上，如何在给定计算方法的一般细节的情况下计算将标记的预期项目数量，以便我可以看到何时出现偏差。
我想到了泊松，因为这基本上是一个到达率问题，但这在我的脑海中感觉是循环的，因为 λ 是我开始想要的，而且我不确定我会使用什么无论如何，对于其余参数。
我的经理认为会是 1%，但我认为这是天真的地将一年内计算的 99% 的交易预测为未来 2 周内的到达率。如果这是真的，你会期望 1% 的物品会触发一天、一周、一个月，这显然是不可能的，对吧？时间越长，触发的项目就越多，时间越短，触发的项目就越少。我不确定这两周时间是否是用于计算阈值的数据的一部分是否相关？
我可以通过什么统计方法来确定预期比例？
澄清编辑：我已经在我的数据上运行了这个，所以我知道我的具体案例的基线是什么。但我不知道如何计算一般情况下触发的预期项目数。我只是想知道你会如何做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</guid>
      <pubDate>Wed, 17 Apr 2024 12:59:24 GMT</pubDate>
    </item>
    <item>
      <title>我应该什么时候进行标准化，在回归之前还是之后？</title>
      <link>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对两个变量的影响特别感兴趣，即农业中的田园重点（以变量“田园”为代表）和马的存在（以“马”为代表）。这些变量的影响随着时间的推移而变化，我运行一个带有交互项的模型：
模型 &lt;- lm(logitshare ~ 田园 + 田园:因子(年份) + 马 + 马:因子(年份) +
其他变量，数据= mydata）
我需要比较变量的相对重要性并使用两种方法，在运行回归之前或之后进行标准化。结果明显不同。
。
“模型”列显示了对非标准化系数运行回归并使用 lm.beta 进行事后标准化的情况。 ModelST 在使用 R 尺度函数转换的系数上运行。哪种方法更可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</guid>
      <pubDate>Tue, 16 Apr 2024 23:50:11 GMT</pubDate>
    </item>
    <item>
      <title>单变量特征选择[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645107/univariate-feature-selction</link>
      <description><![CDATA[在决策树机器学习中，特征选择是构建决策树模型的重要步骤，因为它有助于识别要包含在模型中的最相关变量。单变量特征选择涉及根据个体重要性来选择特征。
使用基于信息增益标准的决策树机器学习算法的单变量特征选择，可以使用什么统计技术来检测大型数据集中的模式和关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/645107/univariate-feature-selction</guid>
      <pubDate>Tue, 16 Apr 2024 03:33:19 GMT</pubDate>
    </item>
    <item>
      <title>“基因匹配”有哪些缺点，特别是在因果推理设置之外？</title>
      <link>https://stats.stackexchange.com/questions/645101/what-are-downsides-to-genetic-matching-particularly-outside-of-causal-inferen</link>
      <description><![CDATA[多变量匹配方法通常涉及两个步骤。首先，用户计算 $D$，单位之间的多元距离矩阵。其次，用户应用匹配函数（例如，1:1 最近邻）来输入 $D$ 以生成单元之间的匹配。用户通常将 $D$ 基于欧几里得距离或马哈拉诺比斯距离，因为后者会降低相关变量的权重，即那些提供冗余（费舍尔）信息的人。
一种广受欢迎的匹配方法是“基因匹配”。 (钻石和 Sekhon 2013）。遗传匹配的贡献之一是通过广义马氏距离(GMD)计算$D$，通过添加矩阵来区分$W$ 加权每个变量对距离计算的贡献。鉴于遗传匹配起源于因果推理，$W$ 是通过“遗传算法”计算的。搜索权重，最小化处理和未处理单元之间匹配的协变量不平衡的汇总度量（例如，平均值或距离总和）。一旦算法找到 $W$，就会计算 $D$ 矩阵，并使用以下公式匹配单位：相同的匹配功能。
问题
我的理解是，遗传匹配很有吸引力，因为它（1）使用GMD，它允许更灵活地对变量进行加权以找到最佳匹配，并且（2）使用相对快速的（遗传）算法来最终最佳 $W$。

使用 GMD 是否有任何非计算方面的缺点？某种过度拟合？我可以看到对某些变量进行精确匹配的渴望，从而导致倾向于精确匹配，但除此之外看不到太多。
我们如何在因果推断之外使用基因匹配？假设我们对无监督聚类感兴趣，以找到相似的单元，而不是通过匹配来促进因果推理中的协变量平衡。在这种情况下，我们感兴趣的是找到能够最小化匹配之间差异的某些汇总度量的匹配。一个合理的例子可能是我们想要最小化匹配单元之间的总距离，使用 GMD 作为我们的距离度量。在这种情况下，基因匹配是否仍会收敛于最佳$W$？遗传算法实际上是否存在唯一的（一组）解决方案？
]]></description>
      <guid>https://stats.stackexchange.com/questions/645101/what-are-downsides-to-genetic-matching-particularly-outside-of-causal-inferen</guid>
      <pubDate>Tue, 16 Apr 2024 00:10:47 GMT</pubDate>
    </item>
    <item>
      <title>在 F1 分数和精确召回曲线下面积 (AUPRC) 之间选择正确的评估指标</title>
      <link>https://stats.stackexchange.com/questions/645005/choosing-the-correct-evaluation-metric-between-f1-score-and-area-under-the-preci</link>
      <description><![CDATA[我们目前正在致力于从卫星图像中检测特定物体（例如家禽养殖场、医院）。我们已将该问题建模为二值图像分类任务（即将图像分类为农场/非农场），并使用梯度加权类激活图 (CAM) 来进一步定位图像内的对象。我们这样做是为了避免手动注释对象周围的边界框的高成本，因为获取二进制标签要便宜得多。到目前为止，CAM 非常适合本地化对象，无需边界框注释。
对于图像分类任务，我们首先优化 F1 分数，将概率阈值设置为默认值 0.5。但我们后来意识到，由于最佳阈值取决于最终用户对误报和漏报的容忍度，因此优化精确召回曲线下的面积 (AUPRC) 实际上可能会更好。当我们集成人机交互验证时，我们目前正在开发一个用户界面，用户可以根据他们有多少预测资源在现场验证来动态更改阈值。
现在，可调整阈值的范围是从 0.5 到 1.0，因为我们只为正预测生成 CAM，即概率 &gt; 的预测。 0.5 为正类。为所有预测生成 CAM 似乎没有意义（即使是那些对正类的置信度分数较低的预测），因为它的计算量很大，并且不太可能产生有意义的输出，因为这些低概率图像可能不包含该对象.
有了这个，优化 AUPRC 是否仍然有意义，还是应该继续优化 F1 分数？我们是否应该根据我们独特的用例生成自己的自定义性能指标？谢谢！
编辑：鉴于我们只为概率 &gt; 的预测生成 CAM。 0.5，仅考虑概率 &gt; 来计算 AUPRC 是否有意义？ 0.5？]]></description>
      <guid>https://stats.stackexchange.com/questions/645005/choosing-the-correct-evaluation-metric-between-f1-score-and-area-under-the-preci</guid>
      <pubDate>Sun, 14 Apr 2024 19:23:28 GMT</pubDate>
    </item>
    <item>
      <title>通过具有时空相关性的二元测量进行重复横截面调查来预测未观察年份的区域水平比率</title>
      <link>https://stats.stackexchange.com/questions/644832/predicting-area-level-rates-during-an-unobserved-year-from-repeated-cross-sectio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644832/predicting-area-level-rates-during-an-unobserved-year-from-repeated-cross-sectio</guid>
      <pubDate>Thu, 11 Apr 2024 19:28:44 GMT</pubDate>
    </item>
    </channel>
</rss>