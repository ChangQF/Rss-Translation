<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 27 Nov 2024 06:26:27 GMT</lastBuildDate>
    <item>
      <title>测试计划进行图像上传[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657917/test-%ec%a7%84%ed%96%89-%ec%98%88%ec%a0%95%ec%9e%85%eb%8b%88%eb%8b%a4-image-uplaad</link>
      <description><![CDATA[
我会写一篇帖子进行测试。
确认后，帖子将被删除。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657917/test-%ec%a7%84%ed%96%89-%ec%98%88%ec%a0%95%ec%9e%85%eb%8b%88%eb%8b%a4-image-uplaad</guid>
      <pubDate>Wed, 27 Nov 2024 05:38:39 GMT</pubDate>
    </item>
    <item>
      <title>财务：投资分析</title>
      <link>https://stats.stackexchange.com/questions/657912/finance-investment-analysis</link>
      <description><![CDATA[
如果股票的贝塔系数为 1.714，股票标准差为 12%，市场标准差为 20%，那么相关系数是多少？

我正在解决这个问题，我使用了相关系数公式：“(市场标准差 * 股票贝塔系数)/股票标准差”，我得到的相关系数大于 1，这是不可能的。
我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657912/finance-investment-analysis</guid>
      <pubDate>Wed, 27 Nov 2024 04:21:13 GMT</pubDate>
    </item>
    <item>
      <title>理解基于启发式的异常值检测[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection</guid>
      <pubDate>Wed, 27 Nov 2024 03:48:42 GMT</pubDate>
    </item>
    <item>
      <title>Ngram 模型背后的概率分布</title>
      <link>https://stats.stackexchange.com/questions/657910/probability-distribution-underlying-ngram-model</link>
      <description><![CDATA[介绍 ngram 模型的文本通常直接操纵条件概率。例如，给定一个语料库 $V$，其单词具有二元模型，我们将计算句子 $W_1 W_2 ... W_n$ 的概率，如下所示：
\begin{equation}
\begin{split}
P(W_1W_2...W_n) &amp;= P(W_1)P(W_2|W_1)P(W_3|W_1W_2)...P(W_n|W_1...W_{n-1}) \\
&amp;\approx P(W_1)P(W_2|W_1)P(W_3|W_2)...P(W_n|W_{n-1})
\end{split}
\end{equation&gt;
那么，大多数文本会将 $P(W_a|W_b)$ 计算为 $COUNT(W_aW_b)/COUNT(W_b)$，并且它们会通过简单地使用起始标记 $P(W_1) = P(W_1|\text{&lt;s&gt;})$ 来绕过 $P(W_1)$ 的边际概率计算。
但是，这种模型背后的实际概率分布是什么？我们实际上如何计算边际概率 $P(W)$？当我们谈到“一个句子的概率”时，它是否与语料库中所有单词组合形成的所有可能句子的概率进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/657910/probability-distribution-underlying-ngram-model</guid>
      <pubDate>Wed, 27 Nov 2024 02:04:47 GMT</pubDate>
    </item>
    <item>
      <title>结果难以辨别的多项式回归模型</title>
      <link>https://stats.stackexchange.com/questions/657909/multinomial-like-regression-model-with-indiscernible-outcomes</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657909/multinomial-like-regression-model-with-indiscernible-outcomes</guid>
      <pubDate>Wed, 27 Nov 2024 01:58:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们通常不担心具有固定效应的面板数据模型中的平稳性？</title>
      <link>https://stats.stackexchange.com/questions/657907/why-dont-we-typically-worry-about-stationarity-in-panel-data-models-with-fixed</link>
      <description><![CDATA[为什么我们通常不担心具有固定效应的面板数据模型中的平稳性？
在时间序列分析中，平稳性通常是一个关键假设。然而，我注意到，在面板数据的应用微观计量经济学中，研究人员似乎不太关心变量$y_{it}$和$x_{it}$是否是平稳的。
考虑一个典型的固定效应模型：
$$y_{it} = \alpha_i + \alpha_t + \sum_{l=1}^L \beta_l x_{i,t-l} + \epsilon_{it}$$
在这种情况下，我们似乎常常不关心：

$y_{it}$是否满足传统的平稳性假设

协方差结构$Cov(y_{it}, y_{i,t+k})$是时不变的

条件期望$E[y_{it}|\alpha_i,\alpha_t]$
与 $t$ 无关


这与 VAR 文献形成鲜明对比，在 VAR 文献中平稳性起着核心作用。
为什么我们经常可以在面板数据环境中忽略平稳性？
拥有较大的 $N$（横截面单位）是否会使平稳性变得不那么重要？
有人可以提供直观的解释，如果可能的话，提供一些数学推理？我熟悉基本的面板数据方法和时间序列概念，但我试图理解这两个领域对平稳性的处理之间的具体区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/657907/why-dont-we-typically-worry-about-stationarity-in-panel-data-models-with-fixed</guid>
      <pubDate>Wed, 27 Nov 2024 00:13:54 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法包括以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除“物种”变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不平等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>处理格兰杰因果关系中的非平稳时间序列</title>
      <link>https://stats.stackexchange.com/questions/657899/dealing-with-non-stationary-time-series-in-granger-causality</link>
      <description><![CDATA[我正在努力确定两个时间序列的 Granger 因果关系。
需要注意的一点是，对于我的具体项目，我有大约 100k 个时间序列，涉及两个不同的维度，例如产品名称和销售类型，我正在尝试确定不同的销售类型是否会对一种特定的销售类型造成 Granger 影响。
到目前为止，在我进行的分析中，我通过采用指数移动平均线来平滑时间序列，然后通过查看指数移动平均线的逐日变化对其进行归一化。我将查看每个产品名称的不同销售类型的指数移动平均线逐日变化的 Granger 因果关系。
从理论上讲，我相信逐日变化已经是一种差异形式，因此大概这应该会迫使时间序列保持平稳。话虽如此，我已经运行了 ADF 测试，大约 10% 的时间序列是非平稳的，阈值为 0.05。
我想知道如何继续，因为我不想通过另一轮标准化来过多地改变解释。出现了两个问题：

可以丢弃所有非平稳时间序列吗？
由于指数移动平均线将自相关引入序列，这可能是我的序列非平稳的原因吗？

请原谅我在这方面的无知，我只是想迈出合理的下一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/657899/dealing-with-non-stationary-time-series-in-granger-causality</guid>
      <pubDate>Tue, 26 Nov 2024 20:29:56 GMT</pubDate>
    </item>
    <item>
      <title>弹性净惩罚分位数回归模型效果不佳的原因及解决方法</title>
      <link>https://stats.stackexchange.com/questions/657894/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</link>
      <description><![CDATA[我正在使用 rqPen 包对我的数据集执行弹性净惩罚分位数回归 (EN-QR)，该数据集有 6,782 行和 227 列（即预测因子）。其中 195 个预测因子是代谢物，我的目标是找出哪些代谢物与接触空气污染物 PM2.5 有关。我选择执行 QR 而不是线性回归，因为 PM2.5 数据存在偏差且不呈正态分布，即使在执行对数转换和标准化之后也是如此。我将数据集按 70:30 的比例分为训练集 (n = 4,747) 和测试集 (n = 2,035)。
我遇到的问题是，当我将训练集中的 EN-QR 对象应用于测试集以预测 PM2.5 值（下图）时，我得到了一个奇怪的多峰分布，它与测试集中的实际 PM2.5 值（上图）不符。我已在下面附上这些分布的屏幕截图。

我想知道是否有人对此有解决问题的建议。有哪些潜在原因会导致模型分裂成多峰分布而不是（近似）正态分布？是否有我没有考虑纳入训练集模型的内容？是否有其他策略可以让我实现变量选择的目标？理想情况下，我希望 EN-QR 模型能够发挥作用，因为它为我的研究问题提供了最多的信息。
我尝试根据数据属于多峰分布的哪个模式将数据分成四个集群。我发现美国人口普查区域与预测的 PM2.5 值的模式之间存在关系。例如，几乎所有 z 得分最低的模式中的人员都来自南部，而几乎所有 z 得分最高的模式中的人员都来自中西部。我发现这很奇怪，因为美国人口普查区域被作为协变量纳入，因此模型不应该按地区分层。我在下面附上了这张图片和表格。

这是我用来在训练集上执行 EN-QR 的 R 代码。下面是我用来预测测试集中 PM2.5 值的代码。
trainingset.ENQR &lt;- rq.pen.cv(
x = as.matrix(trainingset[, c(4:5, 27, 29:251)]),
y = trainingset[, 18],
tau = c(0.1, 0.5, 0.9),
penalty = &quot;ENet&quot;,
a = c(0.50, 0.75, 0.90),
nfolds = 10,
printProgress = TRUE,
penalty.factor = c(rep(0, 32), rep(1, 194))
)

lambda.min.training &lt;- trainingset.ENQR$gtr$lambda1se[2]

testingset.ENQR.50 &lt;- rqPen:::predict.rq.pen.seq.cv(object = trainingset.ENQR,
newx = as.matrix(testingset[, c(4:5, 27, 29:251)]),
tau = 0.50,
a = 0.50,
lambda = lambda.min.training,
cvmin = FALSE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657894/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</guid>
      <pubDate>Tue, 26 Nov 2024 18:49:07 GMT</pubDate>
    </item>
    <item>
      <title>多元正态分布之间的柯西-施瓦茨散度</title>
      <link>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-multivariate-normal-distributions</link>
      <description><![CDATA[我试图使用本文中正态分布混合之间的柯西-施瓦茨散度的推导来推导两个多元正态分布之间的柯西-施瓦茨散度：CLOSED-FORM CAUCHY-SCHWARZ PDF DIVERGENCE FOR
MIXTURE OF GAUSSIANS by CLOSED-FORM CAUCHY-SCHWARZ PDF DIVERGENCE FOR
MIXTURE OF GAUSSIANS
Kittipat Kampa、Erion Hasanbelliu 和 Jose C. Principe
考虑$p(x) = \mathcal{N}(x|\mu,\Lambda^{-1})=\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\mu)^{\top}\Lambda(x-\mu)\Big)$ 和 $q(x) = \mathcal{N}(x|\nu,\Omega^{-1})=\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\nu)^{\top}\Omega(x-\nu)\Big)$。
使用论文中的公式柯西-施瓦茨散度可以简化为：
\begin{align}
D_{CS}(p,q) &amp;=-\log\Big(\mathcal{N}\big(\mu|\nu,(\Lambda^{-1}+\Omega^{-1}\big)\Big) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= -\log\Bigg(\frac{\big|\Lambda^{-1}+\Omega^{-1}\big|^{-1/2}}{(2\pi)^{D/2}}\Bigg) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= \frac{1}{2}\log\Big(\big|\Lambda^{-1}+\Omega^{-1}\big|\Big) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{4}\log\big(|\Lambda|\big) + \frac{1}{4}\log\big(|\Omega|\big)
\end{align&gt;
但是，如果我将 $p$ 插入 $q$，我会得到：
\begin{align}
D_{CS}(p,p)= \frac{1}{2}\log\Big(\big|2\Lambda^{-1}\big|\Big) + \frac{1}{2}\log\big(|\Lambda|\big) = \frac{D}{2}\log(2) \neq0
\end{align&gt;
我哪里犯了错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-multivariate-normal-distributions</guid>
      <pubDate>Tue, 26 Nov 2024 15:19:24 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中拟合已知和未知非线性形状的模型</title>
      <link>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</link>
      <description><![CDATA[我正尝试使用 mgcv 在 R 中拟合一个假设检验模型。
响应 Y 被假设为 x1 和 x2 的线性函数。这是一个空间数据集，其某些结构我先验不知道，因此我另外添加了一个纬度和经度的平滑项。
到目前为止，我们有这个模型，以 R / mgcv 语法表示：
Y ~ x1 + x2 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;)

我必须向这个模型添加另外 2 个项。第一个是饱和曲线，具有 2 个参数，形式如下：
beta1 * ( (x3 ^ beta2) - 1) / beta2)

其中 beta1 和 beta2 是要估计的参数，x3 是数据向量。下一个是过度分散参数/观察级随机效应，用于吸收残差方差。再次以 mgcv 术语表示：
s(obs, bs=&quot;re&quot;)

首先，我使用 nimble 编写了一个模型，其中代表了所有这些组件。我提到这一点只是为了解释这不是未来的选择。该模型没有收敛（或者收敛速度极慢），我认为采样器在决定将方差归因于何处（空间平滑或过度分散参数）时会遇到一些困难，即使有信息丰富的先验。好吧，那只是一厢情愿。
接下来，我尝试用非线性曲线拟合模型，没有空间平滑，并且 brms 中有过度分散项；但是，该模型应该以某种方式考虑空间结构。我似乎无法使用 brms 在非线性模型中写入平滑项。这是通过 bf 得到的非线性 brms 公式的结构：
bf(Y ~ b0 + b1*x1 + b2*x2 + b3*( (x3 ^ b4) - 1) / b4), b0 ~ (1|overdisp), b1 + b2 + b3 ~ 1, nl = T)

其中 b0 是全局截距，其中针对此平均值周围的每个观测值估计了一个额外的过度分散参数。但同样，我现在缺少未知形式和复杂性的空间结构。我尝试使用 mgcv 进行 GAM：
bam(Y ~ x1 + x2 + x3 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;) + s(overdisp, bs=&quot;re&quot;), data = dat, ...)

此模型运行，产生合理的输出，并解释 99% 的偏差。一切都很好——只是我似乎无法为 x3 包含具有 2 个参数的非线性项。是否有某种方法可以做到这一点，而我在 mgcv 的文档中遗漏了？或者也许有一种方法可以在非线性 brms 模型中表达 GAM 项？或者是否存在一些理论/统计原因，说明我不应该像以前那样进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 06:01:50 GMT</pubDate>
    </item>
    <item>
      <title>Beta 回归中的权重</title>
      <link>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</link>
      <description><![CDATA[我在 R 中使用 betareg 来评估覆盖时间百分比与年龄和性别等基线特征之间的关系。
结果测量是测试覆盖时间百分比 (PTC)：每个测试覆盖一名参与者 6 个月。如果参与者在研究期间进行了几次测试，则他们的总覆盖时间是所有覆盖时间 (TC) 的总和。PTC 是 TC 除以他们在研究中的总时间 (TT)。由于参与者之间的 TT 不同；范围从 6 个月到几年，我使用权重来更加强调那些在研究中时间较长的人。我检查了两个权重选项：第一个选项是 TT，第二个选项是 TT/SUM(TT)：对于每个参与者，他们的 TT 除以所有参与者的 TT 总和。因此，第二个选项本质上是第一个选项除以一个常数值 (SUM(TT))。
选项 1：
 调用：
betareg(formula = PTC ~ Sex + Age, data = Test, weights = 
Test$TT, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-10.9333 -3.1518 -0.0751 4.8051 18.9835 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.1771340 0.0281138 -6.301 2.96e-10 ***
性别女性 -0.0323812 0.0114639 -2.825 0.00473 ** 
年龄 0.0169218 0.0004632 36.532 &lt; 2e-16 ***

Phi 系数（带身份链接的精度模型）：
估计标准误差 z 值 Pr(&gt;|z|) 
(phi) 1.94438 0.01234 157.5 &lt;2e-16 ***
---
显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：4 Df 上的 1.267e+04
伪 R 平方：0.01633
迭代次数：17（BFGS）+ 1（Fisher 评分）

选项 2：
 调用：
betareg（公式 = PTC ~ Sex + Age，数据 = Test，权重 = 
Test$TT/T，链接 = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-0.0548 -0.0158 -0.0004 0.0241 0.0952 

系数（带 logit 链接的均值模型）：
估计标准差误差 z 值 Pr(&gt;|z|)
（截距） -0.17713 5.60469 -0.032 0.975
性别女性 -0.03238 2.28541 -0.014 0.989
年龄 0.01692 0.09234 0.183 0.855

Phi 系数（具有身份链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(phi) 1.944 2.461 0.79 0.429

估计量类型：ML（最大似然）
对数似然：4 Df 上的 0.3188
伪 R 平方：0.01633
迭代次数：28（BFGS）+ 3（Fisher 评分）
警告消息：
在 betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, 
control) 中：
未找到精度参数的有效起始值，改用 1 


为什么将权重乘以常数会导致结果如此不同？哪一个是正确的？
编辑：我现在明白重新调整权重、重新调整方差，因此也重新调整 p 值。我现在的问题是哪个选项是正确的？我应该标准化权重吗（选项 2）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</guid>
      <pubDate>Mon, 25 Nov 2024 15:03:37 GMT</pubDate>
    </item>
    <item>
      <title>Freeman-Tukey 变换发生率的反向变换（在 metafor 中）</title>
      <link>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</link>
      <description><![CDATA[问题描述
我正在使用 metafor 包对同一疾病的不同治疗方法的术后复发率进行荟萃分析，但我很难将估计的平均结果反向转换为原始比例，因为我们使用 Freeman-Tukey 变换后的发生率作为结果测量。
代码
使用以下公式将个体效应大小计算为 Freeman-Tukey 变换后的发生率：
 ies = escalc(measure = &quot;IRFT&quot;, add = 0, data = Data, xi = total.recurrences,
ti = time)

我们指定了一个三级模型来解释研究间和研究内的异质性，并将其拟合到我们不同的治疗组，以获得每个治疗组的汇总效应大小。
模型1：
 pes.sg = rma.mv(yi, vi, data = ies,
subset = treatment == &quot;插入子组&quot;, 
random = ~1 | study.id/es.id,
method = &quot;REML&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;, 
cvvc = TRUE) 

我们还对整个数据集使用了另一种多元回归参数化方法，将分组变量作为调节器，以获得与单独分析相同的结果。
模型 2：
 pes = rma.mv(yi, vi, 
random = list(~treatment|study.id, ~treatment|es.id), 
mods = ~0+treatment,
data = ies, 
method = &quot;REML&quot;, struct = &quot;DIAG&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;,
sparse = TRUE)

我们希望获得模型 1 的反向转换估计平均结果，或模型 2 的每个调节器治疗级别的反向转换估计平均结果。每个结果都有相应的置信区间和预测区间，因为我们希望报告原始量表上每个治疗组的估计平均发生率（及其 CI 和 PI），以使我们的结果易于解释。
方程式
根据文档，发生率$ r_i $由escalc计算，其中$ r_i=c_i/t_i $，其中$ c_i $ 和 $ t_i $ 分别表示事件计数和患者时间。
然后使用以下代码对个体发生率进行 Freeman-Tukey 变换：
$$
y_i=1/2(\sqrt{r_i} + \sqrt{r_i+1/t_i})
$$
在 transf.iirft 中，使用以下代码实现个体发生率的反向变换：
$$
r_i = \frac {1/t_i - 8 y_i^2 + 16 t_i y_i^4}{16 y_i^2 t_i}
$$
我的问题是：

是否可以按预期将估计的平均发生率、CI 和 PI 反向变换为原始比例？
如果可以，您将如何计算反向变换，以及哪种方法信息/需要哪些值才能做到这一点？

我很感激有关这个主题的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</guid>
      <pubDate>Fri, 22 Nov 2024 22:28:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的累积链接混合模型的阈值系数看起来很大？</title>
      <link>https://stats.stackexchange.com/questions/657284/why-are-the-threshold-coefficients-of-my-cumulative-link-mixed-model-seemingly-v</link>
      <description><![CDATA[我正在使用 ordinal 包拟合累积链接混合模型。数据是重复测量（在三个时间点进行的调查）。该模型收敛没有问题，估计值在我看来是合理的，但阈值系数似乎非常夸大，我很想知道潜在原因和后果（即，该模型是否仍然可能提供信息）。
library(ordinal)

data(q1_data)

head(q1_data)

id day response sex glp weight1 weight2
&lt;dbl&gt; &lt;fct&gt; &lt;ord&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 1 day7 5 m 100. -1.40 -1.45
2 1 day2 4 m 100. -1.40 -1.45
3 1 day0 3 m 100. -1.40 -1.45
4 2 day7 5 f 97.8 -1.10 -1.55
5 2 day2 5 f 97.8 -1.10 -1.55
6 2 day0 6 f 97.8 -1.10 -1.55 

运行模型：
q1_clmm &lt;- clmm(response ~ day + weight1 * weight2 + glp + 
(1 | id),
data = q1_data,
link = &quot;logit&quot;,
nAGQ = 5)
summary(q1_clmm)

不确定我应该粘贴多少，但要给出完整的上下文：
采用自适应高斯-埃尔米特拟合的累积链接混合模型 
具有 5 个求积点的求积近似 

公式：响应 ~ day + weight1 * weight2 + glp + (1 | id)

数据：q1_data

链接阈值 nobs logLik AIC niter max.grad cond.H 
logit 灵活 159 -219.91 465.82 793(3020) 4.28e-04 6.3e+06

随机效应：
组名称方差标准差
id（截距）1.194 1.093 
组数：id 53 

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
dayday2 -0.59368 0.37344 -1.590 0.11189 
dayday7 -0.07920 0.38261 -0.207 0.83602 
weight1 -1.41946 0.46628 -3.044 0.00233 **
weight2 0.39884 0.16354 2.439 0.01473 * 
glp 0.06027 0.02302 2.618 0.00884 **
weight1:weight2 -0.50004 0.17551 -2.849 0.00438 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
估计标准误差 z 值
0|1 -0.2991 2.4189 -0.124
1|2 0.8646 2.2783 0.379
2|3 2.2481 2.2304 1.008
3|4 3.4143 2.2253 1.534
4|5 5.1067 2.2478 2.272
5|6 7.2607 2.3074 3.147

我担心的是阈值估计值和 SE 非常高。越来越高的值也与我预期的方向相反，因为数据在 1-3 左右有点稀疏，而在 4-6 左右响应频率较高。我的理解是，这些是 logdds，指数结果为 1423 的 OR 和 5|6 截止值的上限 OR 为 131018。
我推测这是一个问题？这是否意味着模型很难准确地建模数据？我的建模过程出了什么问题？过度拟合的可能性（性能指标似乎合理，例如，R2 cond 为 0.4，RMSE = 4.34，并且这些值不会因进一步简化模型而发生显着改变）？
如果需要其他信息，请告诉我，我会更新此 OP。]]></description>
      <guid>https://stats.stackexchange.com/questions/657284/why-are-the-threshold-coefficients-of-my-cumulative-link-mixed-model-seemingly-v</guid>
      <pubDate>Thu, 14 Nov 2024 08:16:37 GMT</pubDate>
    </item>
    <item>
      <title>cdf $F(x)$ 的完全充分统计量概念</title>
      <link>https://stats.stackexchange.com/questions/656151/concept-of-complete-sufficient-statistic-for-the-cdf-fx</link>
      <description><![CDATA[我正在学习 Hogg 和 McKean 的《数理统计学导论》。在 $7.7$ 节末尾，他们讨论了多参数情况的完备性、充分性等，并提到（特别是在示例 $7.7.5.$ 中）给定随机样本 $\{X_i\}_{i=1}^n$ 的顺序统计量 $\{Y_i\}_{i=1}^n$ 已知，则条件分布与 cdf $F(x)$ 无关。然后他们提到

因此，根据充分性的定义，顺序统计量对于$F(x)$是充分的。

我很难理解这句话。到目前为止，充分性是针对从中抽取随机样本的分布的参数定义的。因此，在充分性定义（定义 $7.2.1$）中，作者提到

... 那么 $Y_1$ 就是 $\theta$ 的充分统计量...&quot;

其中 $f(x;\theta)$ 是从中抽取样本的 pdf 或 pmf。现在，我们突然开始谈论cdf 的充分统计量。这从未被定义过。
如果你拿枪指着我的头，我会证实这一点，说“由于条件分布不依赖于 cdf，因此它不能依赖于用于定义 cdf 的任何参数。”但令我感到不安的是，作者们没有给出正式定义，却突然谈论“cdf 的充分统计量”。
这对你来说明显吗？既然我已经知道我们也可以有“cdf 的充分统计量”，那么充分性究竟是如何定义的呢？最重要的是，如何定义完整性和充分性以使其适用于 cdf/pdf/参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/656151/concept-of-complete-sufficient-statistic-for-the-cdf-fx</guid>
      <pubDate>Tue, 22 Oct 2024 15:41:26 GMT</pubDate>
    </item>
    </channel>
</rss>