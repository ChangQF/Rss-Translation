<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 17 May 2024 06:20:11 GMT</lastBuildDate>
    <item>
      <title>为什么 $\epsilon (X - X')$ 和 $(X - X')$ 具有完全相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</link>
      <description><![CDATA[设 $\epsilon \in \{-1, 1\}$ 为 Rademacher 随机变量，
$X$ 是一个随机变量，$X&#39;$ 是 $X$。
为什么 $\epsilon (X - X&#39;)$ 和 $(X - X&#39;)$ 有相同的分布？
鉴于 $X-X&#39;$ 围绕 $0$ 对称，直观上这是正确的，但如何证明呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</guid>
      <pubDate>Fri, 17 May 2024 05:35:50 GMT</pubDate>
    </item>
    <item>
      <title>多状态生存分析</title>
      <link>https://stats.stackexchange.com/questions/647398/multi-state-survival-analysis</link>
      <description><![CDATA[我想知道我的用例是否适合这个问题。我有一群零售消费者，我想对他们的购买间隔进行建模。因为它是一个在线平台，所以我们还可以观察他们购买期间的其他行为，例如浏览、查看优惠等。消费者可以多次购买，我们无法观察他们何时完全不再是消费者。下面是一个可能的状态转换图，基本上您可以从一种状态转换到另一种状态，如果一个状态在另一个状态之后重复，也可能是它本身。

我正在考虑将其建模为一个多状态生存分析问题，可能的事件是购买、浏览、查看优惠......没有明确的死亡事件。由于不同的事件也可能发生多次，因此这也是一个经常出现的问题。这是一种合适的方法吗？它是否能够对不同的事件序列进行建模，或者我是否必须将自动功能纳入其中？任何有关此问题的相关阅读资源也将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/647398/multi-state-survival-analysis</guid>
      <pubDate>Fri, 17 May 2024 02:46:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyMC 中的新数据点对后验进行重新采样</title>
      <link>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</link>
      <description><![CDATA[我有一些数据
X = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
y = np.array([0, 1, 0, 1, 1])

我适合模特
以 pm.Model() 作为模型：
    X_shared = pm.Data(“X_data”, X)
    beta_0 = pm.Normal(“beta_0”, mu=0, sigma=1)
    beta_1 = pm.Normal(“beta_1”, mu=0, sigma=1)
    mu = beta_0 + beta_1 * X_shared
    p = pm.math.sigmoid(mu)
    y_obs = pm.Bernoulli(“y_obs”, p=p, 观察=y)
    跟踪 = pm.sample(100)

现在我想根据新的数据点重新采样后验
型号：
    pm.set_data({“X_data”: [1.69]})
    y_new_simulated = pm.sample_posterior_predictive(trace).posterior_predictive.y_obs
    y_new_obs_name = f“y_new_obs_1” # 为伯努利变量创建一个唯一的名称
    y_new_obs = pm.Bernoulli(y_new_obs_name, p=pm.math.sigmoid(beta_0 + beta_1 * 1.69), 观察=y_new.posterior_predictive.y_obs)
    new_trace = pm.sample(100)

但我收到广播错误：
ValueError：不允许运行时广播。

我的目标是尝试找出新数据点 X（并假装我们没有观察到 y 而必须模拟它）通过比较来添加信息旧痕迹和新痕迹]]></description>
      <guid>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</guid>
      <pubDate>Fri, 17 May 2024 02:31:21 GMT</pubDate>
    </item>
    <item>
      <title>BerHu XGBoost 的自定义损失函数</title>
      <link>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</link>
      <description><![CDATA[我想要一个损失函数，它可以惩罚像 平方损失 这样的异常值，同时处理较小的损失误差不那么严重，例如绝对损失。看来我正在寻找一个 Huber loss 函数，但反过来，所谓的BerHu （提供我第一次看到它使用的论文，你可以在部分找到它&gt;3.2. 损失函数):
$$\mathrm{BerHu}_{\delta}(x)=\begin{cases} |x|, \text{ if } x\le \delta \\ \frac{ x^2 + \delta^2}{2\delta}, \text{ if } x&gt; \delta \end{案例}$$
我想将其实现为 XGBoost 的自定义损失。对于这个实现，如果我没有记错的话，您需要提供损失的梯度和粗麻布。然而，BerHu 不可二次微分，因为它包含绝对值项。 
我认为正是由于这个原因，XGBoost 不会 甚至有一个 Huber 损失的实现，而不是使用 Pseudo-Huber 损失。 
基本上我有两个问题：

尝试实现 XGBoost 的 BerHu 损失函数的最佳方法是什么？也许我错了，有一种方法可以完全按原样实现它。
如果不可能，“Pseudo-BerHu”的类似物将如何实现？看起来像？我不太明白 Pseudo-Huber 损失如何近似 Huber 损失，所以我正在努力想出类似的方法。

非常感谢有关此事的任何建议。如果已经存在另一个具有相同目的的函数，该函数是二次可微的，那么我也很想知道它]]></description>
      <guid>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</guid>
      <pubDate>Thu, 16 May 2024 23:57:49 GMT</pubDate>
    </item>
    <item>
      <title>如何处理导致数据漂移的功能？</title>
      <link>https://stats.stackexchange.com/questions/647392/what-to-do-with-features-causing-data-drift</link>
      <description><![CDATA[我处理了标记的训练数据和未标记的测试数据。我想调整和验证训练数据上的分类器，使其在测试中具有良好的性能。
通过进行一些调查，我注意到训练和测试的分布有很大不同。我针对识别数据点是否属于训练或测试的任务训练了分类算法。这会产生 AUC_score = 0.95。
y = np.zeros(len(total_df_all))
y[train_idx] = 1
XGBdata = xgb.DMatrix(数据=total_df_all, 标签=y)
params = {“目标”：“二进制：逻辑”，
          &quot;eval_metric&quot;:&quot;对数损失&quot;,
          “学习率”：0.05，
          &#39;最大深度&#39;: 8, }
# 使用 XGBoost 进行交叉验证
cross_val_results = cv(dtrain=XGBdata, params=params,
                       nfold=5，指标=“auc”，
                       num_boost_round=200,early_stopping_rounds=20,
                       as_pandas=真）
print((cross_val_results[“test-auc-mean”]).tail(1))

然后我提取了该分类器中具有较高重要性的特征的名称。
def prune_divergent_features(数据):
    Total_df_all = 数据
    发散特征 = []
    分数 = 1
    当分数 &gt;= 0.7 时：
        XGBdata = xgb.DMatrix(数据=total_df_all, 标签=y)
        params = {“目标”：“二进制：逻辑”，
                &quot;eval_metric&quot;:&quot;对数损失&quot;,
                “学习率”：0.05，
                &#39;最大深度&#39;: 8, }
        # 使用 XGBoost 进行交叉验证
        cross_val_results = cv(dtrain=XGBdata, params=params,
                            nfold=5，指标=“auc”，
                            num_boost_round=200,early_stopping_rounds=20,
                            as_pandas=真）
        valid_auc = (cross_val_results[&quot;test-auc-mean&quot;]).tail(1).values[0]
        分类器 = XGBClassifier(eval_metric=&#39;logloss&#39;,use_label_encoder=False)
        分类器.fit(total_df_all, y)
        发散 = 排序(classifier.get_booster().get_fscore().items()，reverse=True，key=lambda item:item[1])[0][0]
        divergent_features.append（发散）
        分数 = valid_auc
        Total_df_all = Total_df_all.drop([发散], axis=1)
       
    返回（分数，divergent_features）

当 AUC 分数达到 0.7 时，此代码将停止提取。这让我从 280 个特征中得到了大约 149 个特征。

很明显，在训练模型时，删除这么多特征将导致大量信息丢失。那么我该怎么做才能减轻训练和测试之间的这种差异呢？

我听说过一种技术，即根据训练集与测试集的 KL 散度对训练集进行加权，但这不会被视为数据泄漏吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/647392/what-to-do-with-features-causing-data-drift</guid>
      <pubDate>Thu, 16 May 2024 23:43:05 GMT</pubDate>
    </item>
    <item>
      <title>何时以及如何分层？</title>
      <link>https://stats.stackexchange.com/questions/647391/when-and-how-of-stratification</link>
      <description><![CDATA[我对分层的理解处于新手水平。例如，如果我们想在实验后推理中以性别为条件，我们可能会对性别进行分层或阻止。据我了解，我们采用块变量可以采用的每个值，检索过滤器为真的所有单位，并随机分配给治疗和控制。结果，变量要么被均匀分割，要么在 $+/-1$ 一个单位内（如果样本大小为奇数）。
一些问题

什么时候有必要这样做？ （又名纯随机化不应该“足够接近”吗？）
在未进行分层的情况下以变量为条件是否错误？
对于连续变量，有一致同意的方法吗？

对于最后一个问题，我想数据可以分为分位数，然后将纯随机化应用于每个分位数块。
最后，据我了解，ANCOVA 可以纠正因变量及其协变量的不平衡；分层是否完全阻止了其中的任何强相关性？ （虽然只是假设这是极不可能的，但通过纯粹的随机化并非不可能？）]]></description>
      <guid>https://stats.stackexchange.com/questions/647391/when-and-how-of-stratification</guid>
      <pubDate>Thu, 16 May 2024 23:13:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 nls() 对非常嘈杂的数据进行非线性回归</title>
      <link>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</link>
      <description><![CDATA[我正在尝试将噪声数据拟合到具有两个我想估计的参数的特定模型。不幸的是，模型拟合很糟糕，噪声也增加了。我可以做些什么来改善这种契合度吗？
公式/模型如下所示：
model_form &lt;- as.formula(y ~ 1/((1/i)-(r*x)))
下面我创建了一些添加了噪声的示例数据。如果没有此噪音，nls() 拟合效果良好，最终估计 r 和 i 足够好。但随着噪声的增加，尽管热图中存在可见的模式，但模型拟合和参数估计很差。
使用示例参数 i 和 r 创建样本数据（这些参数实际上未知，但仅限于特定的已知区间）：
my_i &lt;- 0.5 # i 参数示例
my_r &lt;- 100 # r 参数示例
d &lt;- data.frame(x=c(-rexp(500,rate=10),
                    seq(-1,0,length.out = 500))) %&gt;%
    突变（y=抖动（1/（（1/my_i）-（my_r * x）），1000））
噪声 &lt;- data.frame(x=runif(1000,-1,0),
                    y=runif(1000,0,0.5))
d &lt;-bind_rows(d,噪声)

以下函数使用上面的 model_form 将该数据拟合为 nls。
fitPlot &lt;- 函数（数据）{
    适合 &lt;- nls(model_form,数据,
               开始=列表(r=10,i=0.3))

    fit_r &lt;- 摘要(fit)$系数[“r”,1]
    fit_i &lt;- 摘要(fit)$coefficients[“i”,1]

    预测 &lt;- data.frame(x=seq(-1,0,length.out=1000)) %&gt;%
        变异(y=1 / (1/fit_i - fit_r * x))

    p &lt;- ggplot(数据)+
        geom_bin2d(aes(x,y),bins=14)+
        geom_line(数据=预测,aes(x,y))+
        注释（“标签”，x=-0.7，y=0.5，
                 标签=paste0(“r:”,fit_r,”, i:”,fit_i))
    p
}

拟合图(d)

此时我能做些什么吗？我已经尝试过了

具有可能的 i 和 r 值的网格搜索 = 与 nls 相同的结果
optim具有不同的优化方法，具有最小化SS的功能
nlrob 来自使用不同方法的Robustbase

我在这一点上迷失了，不知何故必须有一种方法来创建一个强大的模型？不知何故，我需要减少对异常值的惩罚，但是怎么做呢？欢迎任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</guid>
      <pubDate>Thu, 16 May 2024 23:02:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么 n 个 iid 随机变量 (X1, X2,…, Xn) 的最大值 (Y) 的 cdf G(y) 的 cdf F(X<=y) 提高到 n 次方，而不是 F(X<=y) )^(n-1)*f(X=y)？</title>
      <link>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-gy-for-the-maximum-y-of-n-iid-random-variables-x1-x2-xn</link>
      <description><![CDATA[当我从精算概率问题样本库中解决问题#64时，我想到了这个问题：https://www.soa.org/globalassets/assets/Files/Edu/edu-exam-p-sample-quest.pdf 
这里也给出了解决方案：https://www.soa.org/499179/globalassets/assets/files/edu/edu-exam-p-sample-sol.pdf
如果您有任何疑问，请告诉我，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-gy-for-the-maximum-y-of-n-iid-random-variables-x1-x2-xn</guid>
      <pubDate>Thu, 16 May 2024 22:56:54 GMT</pubDate>
    </item>
    <item>
      <title>观测数据的隆起建模/条件平均治疗效果 (CATE) 估计技术</title>
      <link>https://stats.stackexchange.com/questions/647389/techniques-for-uplift-modelling-conditional-average-treatment-effectcate-estim</link>
      <description><![CDATA[我最近开始学习 CI，正在阅读这篇非常著名的论文：https:/ /proceedings.mlr.press/v67/gutierrez17a.html 其中提到随机对照试验是提升建模的重要组成部分。
我的问题如下：一家公司开展了 WhatsApp 营销活动，他们仅向那些最有可能（高概率）使用其某项服务的客户发送消息。
此概率是使用 ML 模型计算的。我们试图建议我们不要将消息发送给那些在没有任何此类推动的情况下就会这样做的用户，这将降低获取成本。
这需要估算每个客户的 CATE，并仅向 CATE 估算较高的客户发送消息。我找不到任何用于估计观测数据中的 CATE 的既定技术。
关于观测数据的 CATE 估计，我发现的所有内容如下：https://youtu.be/0GK6IZut6K8 ?si=Ha1klt_kQaCILyGO 但他们没有引用任何论文（我认为）。 uber 的因果机器学习库也提到他们支持根据观测数据进行 CATE 估计，但我没有看到任何示例。
如果有人能给我指出一些已在行业中实施的论文，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/647389/techniques-for-uplift-modelling-conditional-average-treatment-effectcate-estim</guid>
      <pubDate>Thu, 16 May 2024 22:17:20 GMT</pubDate>
    </item>
    <item>
      <title>Delta 方法与实际期望</title>
      <link>https://stats.stackexchange.com/questions/647386/delta-method-vs-actual-expectation</link>
      <description><![CDATA[如果
&lt;块引用&gt;
$x \sim N(\mu,\sigma^2)$

然后根据第一原则，
&lt;块引用&gt;
$E(e^x) = e^{\mu + \sigma^2 / 2}$

我正在尝试找出“Delta 方法”在哪里。这里错了：
如果
&lt;块引用&gt;
$(x-\mu) \sim N(0,\sigma^2)$

然后
&lt;块引用&gt;
$(f(x)-f(\mu)) \sim N(0,\sigma^2 * f&#39;(\mu)^2)$

使用 $f(x) = e^x$ 的 Delta 方法将意味着
&lt;块引用&gt;
$(e^x-e^\mu) \sim N(0,\sigma^2 * (e^\mu)^2 )$

这意味着
$E(e^x) = e^\mu$]]></description>
      <guid>https://stats.stackexchange.com/questions/647386/delta-method-vs-actual-expectation</guid>
      <pubDate>Thu, 16 May 2024 21:00:56 GMT</pubDate>
    </item>
    <item>
      <title>什么统计方法可以评估已知测量误差变量的影响？</title>
      <link>https://stats.stackexchange.com/questions/647368/what-statistical-method-for-assessing-the-effect-of-a-known-measurement-error-va</link>
      <description><![CDATA[我有 95 个受试者的数据集的大量重复测量数据。
这些数据涉及形态学的医学成像测量。
医学成像是一种棘手的数据 - 由于受试者位置的随机差异，在不同日期拍摄的同一身体部位可能看起来完全不同。
因此，我对每张图像进行了额外的测量，以显示（并量化）图像之间身体位置的差异。
这意味着除了形态测量之外，我现在还有2 个明确的“测量误差”测量（我将其称为 MEM）。
我可以假设我所有的形态测量都受到这些已知 MEM 的影响。但还会有其他类型的测量误差（可能是空间误差），我没有（也许不能？）直接量化。
我怀疑某些形态测量比其他测量更容易受到 MEM（和看不见的 MEM）的影响。
在理想的世界中 - 形态测量不会随时间变化 - 它们将保持不变。因此我们可以假设形态的波动很大程度上是由测量误差驱动的。
如果我观察测量值的变化，我会发现 MEM 发生了很大变化。我的形态测量也是如此：

（单个受试者随时间的 7 个观察结果。MEM 是虚线。形态测量是实线。所有值都已标准化）
目前，我正在尝试找出哪种类型的分析可以帮助我找出 MEM 对整体测量误差的贡献。特别是哪些形态测量受 MEM 影响最大。
由于这些误差很大程度上是空间误差，因此随着 3D 空间中位置和方向的变化，不同测量之间可能会发生交互。
我能想到的就是查看某些测量值变化的峰值，看看变化的峰值是否与 MEM 中的峰值相关。
任何人都可以建议一种方法来解决这个问题吗？能否指定 LMER 来探索这个问题？
非常感谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/647368/what-statistical-method-for-assessing-the-effect-of-a-known-measurement-error-va</guid>
      <pubDate>Thu, 16 May 2024 15:42:47 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用 ANCOVA 评估适度吗？</title>
      <link>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</link>
      <description><![CDATA[我正在使用 SPSS 进行 1 组 IV（4 个水平）的分析，在时间 1 和时间 2 为每组中的每位参与者测量一个 DV，并在时间 2 或为每组中的每位参与者测量一次协变量。每个组在时间 1 和时间 2 之间接受不同类型的干预。
我计划使用组内变量作为时间进行 2 x 4 混合 ANCOVA。我可以使用相同的模型来评估 CV 的调节效果吗？我想根据 CV 水平了解哪组/（干预类型）的 DV 增加幅度更大。
我正在考虑进行后续审核；但是，我不确定是否可以通过将时间 1 DV 分数作为受试者内因素来计算模型中的时间 1 DV 分数。
CV与DV、IV与CV之间已建立关系；然而，人们对 IV（组）各水平与 DV 之间的关系程度知之甚少。
我想知道：

我想看看当我调整 CV 时，IV 对 DV 的影响是否显着（各组从时间 1 到时间 2 增加 DV 的能力是否存在差异）
我想查看各组从时间 1 到时间 2 增加 DV 能力的顺序（哪一组最好，第二，第三，最后）。
我想看看 IV 和 IV 之间的关系在不同 CV 点是否发生变化。 （对于不同级别的 CV/调节器，哪个组/（干预类型）的 DV 增加更大）。

我不确定这两项调查是否从根本上相互对立（例如，由于违反了彼此的模型假设，两者不可能同时具有显着性）。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</guid>
      <pubDate>Thu, 16 May 2024 15:13:02 GMT</pubDate>
    </item>
    <item>
      <title>有向边可见吗？</title>
      <link>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</link>
      <description><![CDATA[
以上两个 PAG（部分祖先图）都是在相同条件下使用 FCI（快速因果推理）算法生成的，唯一的区别是右边的是在从数据集中排除变量 5 后生成的。
有人能帮我确定右边 PAG 中 9 和 11 之间的有向边是否可见，并解释此分析所涉及的步骤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</guid>
      <pubDate>Thu, 16 May 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>当使用人类身高的正态近似值时，两个身高未知但大致相等的人都很高的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</link>
      <description><![CDATA[基本上，我看到了一张两个身高大致相等的人的照片，并突然想到“他们都很高的可能性有多大？”。这就是我想回答的问题。
我承认我的想法可能犯了错误，但我认为这只是我不知道如何进行最后一步。
我在数学上思考这个问题的方式是，我们可以假设高度的法线，即 $X \sim N(\mu_X,\sigma^2_X), Y \sim N (\mu_Y,\sigma^2_Y)$，因此我的问题是：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2} \space \cap \space x_1 &gt; \mu_X \space \cap \space y_1 &gt; \mu_Y)$$
其中 $\epsilon$ 是一些小的正常数，代表视觉等效的限制，例如如果约翰身高 181 厘米，亨利身高 182 厘米，当你站在一起时，你真的能看出他们的身高不同吗？我认为不是，因此 $\epsilon$。
现在，虽然我怀疑一起拍照的两个人实际上并没有独立的高度，但我可以假设他们是独立的，因此：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2}) \cdot\mathbb{P}(x_1 &gt; ; \mu_X)\cdot \mathbb{P}(y_1 &gt; \mu_Y)$$
我相信最后两个可以简单地计算为 $\mathbb{P}(x_1 &gt; \mu_X) = \mathbb{P}(X &gt; \mu_X)$  = 1 - rnorm(mu, mu, sigma) （使用 R）但我不知道如何做第一个，特别是在 $X = 的情况下Y$，这是如果两个人都是男性或都是女性时我会做出的假设。特别是，起点似乎是这样的：
$$\mathbb{P}(X &gt; Y) =&gt; X - Y \sim N(\mu_X - \mu_Y, \sigma_X^2 - \sigma_Y^2) $$
但当 $X = Y 时，显然会是 $X - Y \sim N(0, 0)$ $，我不知道如何使用。我更不知道如何合并我的 $\epsilon$ 广泛的视觉等价区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</guid>
      <pubDate>Thu, 16 May 2024 13:02:16 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用 Lasso，或者向我指出适合这项工作的正确工具。
&lt;小时/&gt;
编辑
x 坐标
坐标
我还认为值得一提的是，调查论文中也提到了 group lasso 破裂库]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    </channel>
</rss>