<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 31 Jan 2024 15:13:21 GMT</lastBuildDate>
    <item>
      <title>混合水平模型中正确的随机因子结构</title>
      <link>https://stats.stackexchange.com/questions/638203/correct-random-factor-structure-in-mixed-level-model</link>
      <description><![CDATA[我有数据显示小鼠已接受多次研究，每只小鼠重复 4 次试验。
是正确的随机结构，假设随机截距，(1 | 鼠标) 或 (1 | 鼠标/试验)，其中试验嵌套在鼠标内。我的第一个猜测是，在小鼠体内进行嵌套试验会过度指定。]]></description>
      <guid>https://stats.stackexchange.com/questions/638203/correct-random-factor-structure-in-mixed-level-model</guid>
      <pubDate>Wed, 31 Jan 2024 15:09:40 GMT</pubDate>
    </item>
    <item>
      <title>使用最小数据点对时变系数进行建模</title>
      <link>https://stats.stackexchange.com/questions/638202/modelling-for-time-varying-coefficients-using-minimal-data-points</link>
      <description><![CDATA[在 3 年的聚合数据集中，我有一个因变量和大约 50 个预测变量。如何将时变协变量应用于这样的数据集。
请注意，这将是一个相对较小的数据集，包含约 36 个数据点，按月汇总。
另外是否有任何包/框架可以做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/638202/modelling-for-time-varying-coefficients-using-minimal-data-points</guid>
      <pubDate>Wed, 31 Jan 2024 15:00:57 GMT</pubDate>
    </item>
    <item>
      <title>当不同的方法得出完全不同的排名时，应该优先考虑哪种相关分析方法？</title>
      <link>https://stats.stackexchange.com/questions/638198/which-correlation-analysis-method-should-be-prioritized-when-different-methods-y</link>
      <description><![CDATA[我一直在处理与行业相关的数据集，我需要分析特定输出 (y) 和多个输入（x1、x2、x3 等）之间的相关性。在我的搜索过程中，我遇到了各种相关分析方法，例如 Pearson、Kendall、Spearman 和互信息。然而，我面临着一个挑战：不同的方法会产生完全不同的相关性排名。在某些情况下，差异非常显着。例如，根据互信息方法，一个输入可能与 y 最相关，但在其他方法中它被列为最不相关的输入之一。
这种不一致给我的分析带来了困境，这对于行业相关的数据集至关重要。他们需要清楚地了解输入如何与 y 相关。我正在考虑合并所有方法的结果，但我担心有些方法可能不太适合我的数据集，从而导致得出不准确的结论。
您能否建议最适合进行一般分析的相关方法？互信息是否可以被认为是最好的方法，因为它量化了“信息量”？通过观察另一个随机变量获得一个随机变量？有哪些方法是我应该避免的，因为它们是针对特定情况而设计的？
此外，如果您提供有关如何有效总结和整合不同方法的研究结果的提示，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/638198/which-correlation-analysis-method-should-be-prioritized-when-different-methods-y</guid>
      <pubDate>Wed, 31 Jan 2024 14:18:38 GMT</pubDate>
    </item>
    <item>
      <title>获得非常大的相对风险比值</title>
      <link>https://stats.stackexchange.com/questions/638197/getting-a-very-big-relative-risk-ratio-value</link>
      <description><![CDATA[我们已经将多级多项逻辑回归模型拟合到我们的数据中。我们获得了相对风险比率（RRR）。对于大多数自变量，RRR 具有通常的值，如 0.49、0.78、2.45、1.78 等。但是，仅对于具有三个类别的序数变量，其中一个类别的 RRR 值为 115590.5。为什么它比通过多项式逻辑回归模型拟合得到的其余 RRR 值大得多且异常？你有没有发现过像RRR这样大的数字？其背后可能的原因是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638197/getting-a-very-big-relative-risk-ratio-value</guid>
      <pubDate>Wed, 31 Jan 2024 14:05:02 GMT</pubDate>
    </item>
    <item>
      <title>协变量相关模型回归中的最小二乘法[重复]</title>
      <link>https://stats.stackexchange.com/questions/638196/least-squares-in-regression-with-covariate-dependent-model</link>
      <description><![CDATA[经典最小二乘法导致统计回归，如果 $(Y, X)$ 遵循一个模型，其中 $ $\mathbb{E}[Y\mid X=x] = \alpha + \beta x,$$ 我们可以估计 $\beta$明确使用 LS 作为 $\hat{\beta} = (\textbf{X}^t\textbf{X})^{-1}\textbf 的第二个组成部分的随机样本{X}^t\textbf{Y}$，其中 $\textbf{X}$ 是 1 的矩阵，$X_i$。
我的问题如下：让 $(Y, X, Z)$ 遵循模型 $$\mathbb {E}[Y\mid Z=z, X=x] = (\alpha x) + (\beta x) z.$$
考虑来自 $(Y, X, Z)$ 的随机样本。我们可以估计 $\hat{\beta}$ 并给出一个明确的表达式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638196/least-squares-in-regression-with-covariate-dependent-model</guid>
      <pubDate>Wed, 31 Jan 2024 14:01:16 GMT</pubDate>
    </item>
    <item>
      <title>比较 OLS 模型和随机森林模型来预测房价的最佳指标是什么？</title>
      <link>https://stats.stackexchange.com/questions/638194/what-are-the-best-metrics-to-compare-an-ols-model-and-random-forest-model-to-pre</link>
      <description><![CDATA[我正在做一项任务，其目标是预测房价。我最初的方法涉及使用普通最小二乘模型。接下来，我计划制作一个随机森林模型进行比较。
一般来说，这些“黑盒”机器学习算法提供了更好的预测能力，但缺乏 OLS 模型的可解释性。
我想量化他们预测能力的差异。但是，我不确定最合适的评估标准。
问题 1：比较两个 OLS 模型的预测能力的最合适指标是什么？
问题 2：比较 OLS 模型与随机森林模型的预测能力的最合适指标是什么？
如果能推荐相关文献那就太好了，但非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/638194/what-are-the-best-metrics-to-compare-an-ols-model-and-random-forest-model-to-pre</guid>
      <pubDate>Wed, 31 Jan 2024 13:22:41 GMT</pubDate>
    </item>
    <item>
      <title>如何计算额外特征与主成分的相关性</title>
      <link>https://stats.stackexchange.com/questions/638192/how-to-compute-the-correlations-of-extra-features-with-respect-to-the-principal</link>
      <description><![CDATA[我有一个包含 4 个特征和 n 个观察值的数据集。我仅使用 3 个特征完成了主成分分析。现在我需要找到额外特征和我已有的主成分之间的相关性。我怎样才能做到这一点？我对数学解释比 Python 代码更感兴趣。
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd

从 sklearn.decomposition 导入 PCA
从 sklearn.preprocessing 导入 StandardScaler
从sklearn导入数据集

# 加载鸢尾花数据集
iris = datasets.load_iris(as_frame=True)

# 选择前3个特征
数据 = iris.data.iloc[:, 0:3]

缩放器 = StandardScaler().fit(数据)
标准化数据=缩放器.变换（数据）
y = 虹膜.目标

# 应用主成分分析
主成分分析=主成分分析()
pca_transformed = pca.fit_transform(归一化数据)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/638192/how-to-compute-the-correlations-of-extra-features-with-respect-to-the-principal</guid>
      <pubDate>Wed, 31 Jan 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要在 k 折交叉验证中进行最终评估？</title>
      <link>https://stats.stackexchange.com/questions/638191/why-do-we-require-a-final-evaluation-in-k-fold-cross-validation</link>
      <description><![CDATA[我知道有关此主题的许多帖子都有很多答案（请参阅：1,2，3）。一般来说，常见的答案是这是“最佳实践”，它可以避免“数据泄漏”或过度拟合。
这些说法有科学依据和证据吗？提到的一个学术来源是这本书的第 222 页，但我不明白为什么应该在最终测试集上计算绝对拟合度（例如 R2）。
同样，我查看了这个论文仅在讨论中提到了对最终测试数据集的潜在需求。]]></description>
      <guid>https://stats.stackexchange.com/questions/638191/why-do-we-require-a-final-evaluation-in-k-fold-cross-validation</guid>
      <pubDate>Wed, 31 Jan 2024 13:12:44 GMT</pubDate>
    </item>
    <item>
      <title>条件密度估计的参考数据集</title>
      <link>https://stats.stackexchange.com/questions/638188/reference-datasets-for-conditional-density-estimation</link>
      <description><![CDATA[[如果您因为我要一个数据集而想要结束这个问题 - 我正在寻找 这个关于在 CVMeta 上请求数据集的问题。]
我正在寻找参考数据集来展示条件密度估计。
许多统计库（statsmodels、sklearn, ...) 包含一组数据集，在讨论特定方法时通常用作参考数据集。虽然我在许多实例中看到它们用于分类和回归，但我几乎没有看到它们用于条件密度估计。
有用于分类的鸢尾花数据集，加州住房数据集 用于回归 - 是否有类似的数据集（或者甚至可能是其中的列表）条件密度估计问题？如果有一个数据集可能不是非常常见的参考，但它特别适合展示条件密度估计的任务，那也会很有帮助。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638188/reference-datasets-for-conditional-density-estimation</guid>
      <pubDate>Wed, 31 Jan 2024 12:21:51 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据中一个变量的自相关</title>
      <link>https://stats.stackexchange.com/questions/638186/autocorrelation-of-one-variable-in-time-series-data</link>
      <description><![CDATA[我想检查变量多年来的自相关性（时间序列数据）。在检查自相关性（Durbin-Watson）之前我们是否需要运行 Arima 模型？
在运行 AC 和 PAC 表时，我们还没有看到该变量的自相关吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638186/autocorrelation-of-one-variable-in-time-series-data</guid>
      <pubDate>Wed, 31 Jan 2024 12:10:38 GMT</pubDate>
    </item>
    <item>
      <title>2xN 卡方检验后的事后分析</title>
      <link>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</link>
      <description><![CDATA[我有两组人，我想确定他们的语言是否存在显着差异。我的数据由词频组成（一个人在给定时间范围内说出给定单词的次数），因此他们的列联表如下所示：

我使用卡方检验来比较词频的总和（向量 $x$ 和 $y$ ），并发现两组之间存在显着差异（非常低的 $p$ 值）。现在，我正在考虑仅对两组进行事后分析是否有意义。在这种情况下如何进行事后分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</guid>
      <pubDate>Wed, 31 Jan 2024 08:58:16 GMT</pubDate>
    </item>
    <item>
      <title>与常规 Copula 相比，使用 Vine Copula 有何优势？</title>
      <link>https://stats.stackexchange.com/questions/638164/advantages-of-using-vine-copulas-over-regular-copulas</link>
      <description><![CDATA[我是 Copula 的新手，我试图从概念上理解两种主要类型的 Copula 之间的差异：常规 Copula 和 Vine Copula。两者都用于模拟相关多元概率分布的数据（这是一个难题） - 特别是在边际分布不是同一类型的情况下（例如正态分布和指数分布的联合分布）。
据我所知，Vine Copula 似乎比常规 Copula 更复杂。这让我想知道：与常规 Copulas 相比，使用 Vine Copulas 可以获得哪些优势？
这是我自己尝试回答这个问题：
定义： Copula 是将边际分布与其多元分布联系起来的函数。如果我们有两个具有累积分布函数的随机变量 $X$ 和 $Y$ $F_X(x)$ 和 $F_Y(y)$ ，以及一个 copula 函数 $C(u, v)$，则联合 CDF 为：
$$
F(x, y) = C[F_X(x), F_Y(y)]
$$
为了说明使用 Vine Copula 相对于常规 Copula 的额外优势，我尝试创建以下示例：
示例：考虑以下 3 维概率分布：
$$f(x, y, z)$$
使用链式法则https://en.wikipedia.org/wiki/Chain_rule_(概率） - 我们可以将其分为两部分：
$$
f(x, y, z) = f_X(x) f_{Y|X}(y|x) f_{Z|XY}(z|x, y)
$$
现在，比较使用 Vine Copula 与常规 Copula 的优势：

如果我们使用常规 Copula，我们可以使用单个 Copula 函数来表示此概率分布（即有 1 个 copula 函数是各个分布的函数）：

$$
F(x, y, z) = C[F_X(x) , F_{Y|X}(y|x) , F_{Z|XY}(z|x, y)]
$$

使用 Vine Copula，我认为我们可以使用多个 Copula 函数来表示此概率分布（即，我们将 3 个不同的 Copula 彼此相乘）：

$$
F(x, y, z) = C_{12}[F_X(x), F_{Y|X}(y|x)] \cdot C_{13}[(F_X(x), F_{Z|XY} (z|x, y)] \cdot C_{23|1}[F_{Y|X}(y|x), F_{Z|XY}(z|x, y)|F_X(x)]
$$
因此，与常规 Copula 相比，使用 Vine Copula 的优势在于您可以更灵活地决定要在各个分布集之间拟合哪些 Copula 函数。
结论：因此，这是 Vine Copulas 相对于常规 Copulas 的主要优势吗？我们有能力将不同的 Copula 函数（例如高斯函数、阿基米德函数）组合在一起，使我们能够捕获数据中更复杂的关系？
我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638164/advantages-of-using-vine-copulas-over-regular-copulas</guid>
      <pubDate>Wed, 31 Jan 2024 05:07:45 GMT</pubDate>
    </item>
    <item>
      <title>关于二元随机变量的问题</title>
      <link>https://stats.stackexchange.com/questions/638162/a-problem-on-bivariate-random-variables</link>
      <description><![CDATA[假设我们有绝对连续的随机向量 $X=(X_1,X_2)$ 和 $Y=(Y_1, Y_2)$。我们有 $Y_i=a_iX_i+b_i$ 和 $a_i&gt;0, b_i\geq 0$ $i=1,2$ 。令 ${F}$ 为分布函数，使得
${F}_X(x_1,x_2)=P(X_1\leq x_1,X_2\leq x_2).$
我们知道$\frac{\partial^2}{\partial x_1\partial x_2}F_X(x_1,x_2)=f_X(x_1,x_2).$&lt; /p&gt;
现在，\begin{align}
F_Y(y_1,y_2)&amp;=P(Y_1\leq y_1,Y_2\leq y_2)\\
&amp;=P(a_1X_1+b_1\leq y_1,a_2X_2+b_2\leq y_2)\\
&amp;=P(X_1\leq(y_1-b_1)/a_1,X_2\leq(y_2-b_2)/a_2)\\
&amp;=F_X((y_1-b_1)/a_1,(y_2-b_2)/a_2)\\
&amp;=F_X(x_1,x_2)
\end{对齐}
这里的形式我们可以说 $f(y_1,y_2)=f(x_1,x_2)$ 吗？
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638162/a-problem-on-bivariate-random-variables</guid>
      <pubDate>Wed, 31 Jan 2024 04:45:38 GMT</pubDate>
    </item>
    <item>
      <title>Purging 和 Embargo 比 TimeSeriesSplit 更好吗？</title>
      <link>https://stats.stackexchange.com/questions/638157/are-purging-and-embargo-better-than-timeseriessplit</link>
      <description><![CDATA[众所周知，经典的 k 重 CV 在处理时间序列数据时效果不佳。我最近发现了两种名为 Purging and Embargo 的方法，其目的是修改k倍CV，避免数据泄露。
清除 k 倍 CV：
主要思想是“清除”（删除）训练集中的观察结果，这些观察结果在某个时间点与验证集中的观察结果一致。
禁运：
禁运放大了清除观察结果的想法。 Embargo 从训练集中删除了观察结果，这些观察结果紧随验证集之后。
我的问题是：

如果您可以简单地使用 TimeSeriesSplit，那么为什么要费力这样做呢？TimeSeriesSplit 更易于理解和实现？
是否有任何证据表明使用 Purging 和/或 Embargo 会产生更好的结果？

我特别有兴趣在金融时间序列的背景下回答这些问题。非常感谢任何对论文和/或直观论点的引用。
&lt;小时/&gt;
感兴趣的人还可以参考此 YouTube 视频 关于财务简历，解释了清除和禁运。
对于那些有权访问的人，我将引用包含我最初遇到的方法的论文：doi.org/10.1016/j.eswa.2023.121012
您还可以在 Marcos Lopes de Prado 的《金融机器学习进展》一书中找到讨论的这些方法。他还在此 YouTube 视频中简要讨论了这些内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/638157/are-purging-and-embargo-better-than-timeseriessplit</guid>
      <pubDate>Wed, 31 Jan 2024 02:09:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OpenAI 的缩放定律论文低估了数据在模型缩放中的重要性？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</link>
      <description><![CDATA[Chinchilla 论文（Hoffmann、Jordan 等人“训练计算优化大型语言模型”。arXiv 预印本 arXiv:2203.15556 (2022)。）著名地发现，在缩放模型时，您应该粗略地增加参数计数和数据量相等，而不是早期的 OpenAI 缩放定律论文，该论文表示您应该增加参数计数，其数量要远远多于数据量。
在第 3 页，Chinchilla 论文对 OpenAI 论文为何犯此错误给出了以下解释：
&lt;块引用&gt;
首先，作者对所有模型使用固定数量的训练标记和学习率计划；这
阻止他们对这些超参数对损失的影响进行建模。相比之下，我们发现
将学习率计划设置为大致匹配训练令牌结果的数量
无论模型大小如何，都能获得最佳的最终损失——见图 A1。对于固定学习率余弦时间表
对于 130B 代币，中间损失估计（对于 𝐷&#39; &lt;&lt; 130B）因此高估了
丢失使用与 𝐷&#39; 匹配的时间表长度进行训练的模型。使用这些中间损失会导致
低估了在少于 130B 代币的数据上训练模型的有效性，最终
得出这样的结论：随着计算的进行，模型大小应该比训练数据大小增加得更快
预算增加。

但是为什么会这样呢？如果您的学习率计划导致高估了少量训练数据的损失，那么这是否会导致您高估数据对损失的影响，从而建议比参数计数更快地增加数据大小，而不是相反？]]></description>
      <guid>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</guid>
      <pubDate>Tue, 30 Jan 2024 23:19:09 GMT</pubDate>
    </item>
    </channel>
</rss>