<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 16 Dec 2023 03:13:46 GMT</lastBuildDate>
    <item>
      <title>用于重复测量设计的基于精度的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</link>
      <description><![CDATA[请寻求帮助！
我正在根据估计的精度来计算一项研究所需的样本量，但我很难弄清楚到底如何做。主要让我失望的是 1) 需要考虑测量误差，2) 需要考虑同一参与者的重复测量。另外，我想根据估计精度而不是统计显着性来计算样本量。
设计：在基线时测量二头肌厚度，然后参与者进行 8 组阻力训练。每组结束后，参与者将被要求提供“感知的肌肉肿胀”的主观评分。并再次测量肌肉厚度。这样，我们最终将得到基线肌肉厚度，以及每个参与者的主观肌肉肿胀和测量的肌肉厚度的 8 个后续值。
计划分析：1）主观肌肉肿胀评分与测量的肌肉肿胀之间的相关性。 2) 检查随着进行更多组阻力训练，主观评分和测量的肌肉厚度的变化。
根据之前也使用同一设备测量肌肉厚度的研究，我收集了测量设备的典型重测 ICC 为 ~0.988，典型标准偏差为 ~4.96，以及测量的典型标准误差约为 0.459。我的目标是达到 95% 的置信度，精度高于测量误差（也就是说，我希望有很高的信心，如果观察到时间点之间存在任何差异，它们很可能是真正的差异，而不是简单地通过测量误差来解释）。
我不确定如何将所有这些整合到基于精度的样本量计算中。正如我上面提到的，我需要考虑测量误差和每个参与者的重复测量。一些在线阅读还提醒我，可能需要考虑这些重复测量中的相关模式，我认为在这种情况下，最好将其描述为线性指数自回归 (LEAR) 或一阶自回归 (AR1)。
如果有人有任何意见或建议，我们将不胜感激！非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</guid>
      <pubDate>Sat, 16 Dec 2023 00:07:58 GMT</pubDate>
    </item>
    <item>
      <title>几年内性别之间的多重比较方差分析或 t 检验？图基事后？邦费罗尼？</title>
      <link>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</link>
      <description><![CDATA[我正在进行一项遗传分析，比较 2013-2019 年雄性和雌性动物之间的 Fst 和相关系数值。每年分为季度，所以我总共有 40 个季度类别。每年的个体数量有所不同，每年的男性和女性数量也不相等。我想看看每个季度内和每个季度之间的性别价值观是否有所不同。我使用的是 R，所以我做了一个线性模型（Fst ~ Sex*Year），然后使用 Tukey 事后测试对模型进行方差分析，以查看每个季度内性别之间的比较。
Fst.test = lm(Fst ~ 性别*年份，数据 = Fst)
Fst.aov = aov(Fst.test)
摘要(Fst.aov)
Fst.posthoc = TukeyHSD(Fst.aov)

我对每个季度内的性别进行的许多事后比较并没有显着差异，尽管数值看起来相当不同。所以我随机选择了一些并做了标准的 t 检验，它们是显着的。
我应该在这里做哪些统计？方差分析和图基事后检验是最好的方法还是我应该为每个季度进行多次 t 检验并进行某种修正？如果是这样，哪个更正，我记得几年前做过 Bonferroni...]]></description>
      <guid>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</guid>
      <pubDate>Fri, 15 Dec 2023 22:35:23 GMT</pubDate>
    </item>
    <item>
      <title>局部平滑器的浓度不等式 (Nadaraya Watson)</title>
      <link>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</link>
      <description><![CDATA[令 $m(X)=E(Y|X)$ 为随机设计的回归函数，并令  $\hat{m}_h(x)$
\begin{方程}
\hat{m}_h(x)=\frac{\sum_{i=1}^n K_h\left(x-x_i\right) y_i}{\sum_{i=1}^n K_h\left(x- x_i\右）}
\end{方程}
是 Nadaraya Watson 估计器，带宽为 h。对于任何 $\epsilon &gt;0$，我想绑定 Nadaraya Watson 估计器的修改。我那方面，我首先要束缚
\begin{方程}
P (|\hat{m}_h(x) - m(x)|&gt;\epsilon)。
\end{方程}
我试图避免马尔可夫/切比雪夫等不等式和收敛结果的速度。我正在寻找集中不等式的证明。我正在通过偏差方差分解尝试 Hoeffding 不等式，但遇到了困难。
任何人都可以帮助我迈出有用的第一步吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</guid>
      <pubDate>Fri, 15 Dec 2023 21:51:45 GMT</pubDate>
    </item>
    <item>
      <title>对于软标签使用 KL 散度而不是交叉熵更好吗？</title>
      <link>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</link>
      <description><![CDATA[所以我正在阅读这篇论文：在 Fuse 之前对齐：利用动量蒸馏进行视觉和语言表示学习 (2017) 由 Junnan Li 等人提出，他们使用 KL 散度执行对比损失。
$$
L_{\text{ITC}} = (1 - \alpha) L_{\text{对比度}} + \frac{\alpha}{2} \left[ \text{KL} \left( q^{i2t} \平行 p^{i2t} \right) + \text{KL} \left( q^{t2i} \平行 p^{t2i} \right) \right]
$$
在此方程中，LITC-base​是基础图像文本对比损失，$\alpha$是权重因子，DKL表示KL散度，&lt; span class=&quot;math-container&quot;&gt;$q^{i2t}$ 和 $q^{t2i}$ 是预测分布（从图像到分别为文本和文本到图像），以及 $p^{i2t}$ 和 $p^{t2i}$&lt; /span&gt; 是 KL 散度项的目标分布。

但是，在实现中，交叉熵使用损失，而不是明确地使用KL散度。KL散度用于与软标签的对比损失。这种方法理论上可以避免损失图中出现大的恒定熵，如图所示，即使在反向传播时不使用熵，也可能会掩盖减少。
但是，该实现利用了交叉熵损失。这就提出了为什么选择交叉熵而不是论文中指定的 KL 散度的问题，特别是考虑到对解释训练损失曲线的影响，因为由于高熵掩盖了 KL 散度和论文，我们将无法看到 KL 散度的减少明确提到使用软伪标签进行对比学习。这是一个实际的实施决策，还是反映了模型学习过程的更深层次？
与 torch.no_grad():
            self._momentum_update()
            image_embeds_m = self.visual_encoder_m(图像)
            image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]),dim=-1)
            image_feat_all = torch.cat([image_feat_m.t(),self.image_queue.clone().detach()],dim=1)
            text_output_m = self.text_encoder_m.bert（text.input_ids，attention_mask = text.attention_mask，
                                                return_dict = True, 模式 = &#39;文本&#39;)
            text_feat_m = F.normalize(self.text_proj_m(text_output_m.last_hidden_​​state[:,0,:]),dim=-1)
            text_feat_all = torch.cat([text_feat_m.t(),self.text_queue.clone().detach()],dim=1)

            sim_i2t_m = image_feat_m @ text_feat_all / self.temp
            sim_t2i_m = text_feat_m @ image_feat_all / self.temp

            sim_targets = torch.zeros(sim_i2t_m.size()).to(image.device)
            sim_targets.fill_diagonal_(1)

            sim_i2t_targets = alpha * F.softmax(sim_i2t_m, dim=1) + (1 - alpha) * sim_targets
            sim_t2i_targets = alpha * F.softmax(sim_t2i_m, dim=1) + (1 - alpha) * sim_targets

        sim_i2t = image_feat @ text_feat_all / self.temp
        sim_t2i = text_feat @ image_feat_all / self.temp
                             
        loss_i2t = -torch.sum(F.log_softmax(sim_i2t, dim=1)*sim_i2t_targets,dim=1).mean()
        loss_t2i = -torch.sum(F.log_softmax(sim_t2i, dim=1)*sim_t2i_targets,dim=1).mean()
]]></description>
      <guid>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</guid>
      <pubDate>Fri, 15 Dec 2023 21:37:22 GMT</pubDate>
    </item>
    <item>
      <title>滚动平均值是否有助于将时间序列变量的广义线性模型简化为 OLS？</title>
      <link>https://stats.stackexchange.com/questions/635026/does-rolling-average-help-reduce-generalize-linear-model-on-timeseries-variable</link>
      <description><![CDATA[我有一个数据$Y_t$，它基本上衡量了任何一天某些事件的数量，并且我有一个从 2015 年至今所有国家/地区的时间序列。我试图将 $Y_t$ 适合我拥有的一些 $X_t$ 并添加一个国家变量的虚拟变量（也考虑对国家进行随机/固定效应，但国家越大通常意味着事件越重要）。我尝试使用一些 GLM，如泊松或零膨胀泊松，但结果不太有希望，较小的国家通常有很多天没有事件发生，并且当天产生很多噪音（拟合系数没有意义）。然后我对事件计数进行 30 天的滚动平均值，并进行 OLS，模型系数确实有意义。我想寻求一些关于这是否正确的建议。
所以原因基本上是，每天您实现的 $Y_t$ 类似于泊松参数的样本估计，而采用滚动平均值肯定会对此有所帮助，因为它通过 CLT 变为正态分布。我知道它使你的日期自相关，但至少你得到了正确的系数，或者我可以做一些事情，比如按月重新采样，然后做 OLS。这种方法有哪些注意事项？]]></description>
      <guid>https://stats.stackexchange.com/questions/635026/does-rolling-average-help-reduce-generalize-linear-model-on-timeseries-variable</guid>
      <pubDate>Fri, 15 Dec 2023 19:46:41 GMT</pubDate>
    </item>
    <item>
      <title>规划图和经典图有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/635023/what-is-the-difference-between-planning-graph-and-the-classical-graph</link>
      <description><![CDATA[两者在各方面都有自己的优势，我想知道哪一个更可行且最适合实时使用。如果它们都不够好，请建议我任何其他比这两个更好的规划算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/635023/what-is-the-difference-between-planning-graph-and-the-classical-graph</guid>
      <pubDate>Fri, 15 Dec 2023 19:15:04 GMT</pubDate>
    </item>
    <item>
      <title>独立的特征，但 PCA 显着提高了分类器的准确性。为什么？</title>
      <link>https://stats.stackexchange.com/questions/635022/independent-features-but-pca-improves-classifiers-accuracy-significantly-why</link>
      <description><![CDATA[这是我的第一个问题:)
我正在使用 kNN 分类器对多元正态分布的数据集进行处理。我必须将来自 N(mu_1,I) 和 N(mu_2,I) 的组与不同的期望向量 mu_i 和两个单位矩阵作为协方差（因此特征是独立的）。维度为 1000。一个数据集由来自第 1 组的 3500 个随机抽取条目和来自第 2 组的 1500 个随机抽取条目组成。我想研究 kNN 在不同配置的 mu_i 的高维数据上的性能.
显然，我与维度的诅咒作斗争，但这就是目标。
仍然只是为了好玩，我对前两个分量进行了 PCA 投影，因此有效地降低到了二维，并且分类器的准确度提高了约 10%。
怎么会？我的特征是独立的。这难道不应该使 PCA 不适合吗？
提前感谢您启发我；）]]></description>
      <guid>https://stats.stackexchange.com/questions/635022/independent-features-but-pca-improves-classifiers-accuracy-significantly-why</guid>
      <pubDate>Fri, 15 Dec 2023 19:12:47 GMT</pubDate>
    </item>
    <item>
      <title>二项分布样本的方差估计器</title>
      <link>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</link>
      <description><![CDATA[我想对一些数据进行贝叶斯分析。假设我们有一个样本，我们认为该样本来自二项式总体。我们有 $m$ 个观察值
$$X_i \sim Bin(n,p) \text{ 对于某些 } i \in \{1,2,\dots,m\}$$
我选择了之前的测试版本。我不确定如何选择参数以使我的分布更好地符合我的信念。我假设我会取样本均值并将贝塔先验的均值设置为等于该数字。但我不确定如何计算方差。任何人都可以提供建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</guid>
      <pubDate>Fri, 15 Dec 2023 17:55:09 GMT</pubDate>
    </item>
    <item>
      <title>相对差异的置信区间</title>
      <link>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</link>
      <description><![CDATA[我知道两个样本 $X_1$ 和 $X_2$，但我不知道这些值。如何计算平均值相对差的置信区间界限$(m_1-m_2)/m_1$？
当我尝试进行直接计算时，我必须计算比率的方差。在线发表的论文中提供了一个基于泰勒级数的公式，但在我的情况下，相应的一阶近似并不准确，因为与平均值相比方差相当大。
我想到了一种替代方案，即将参考样本 $X_1$ 的均值和方差视为理论常数值而不是随机变量。这类似于将 $X_2$ 与理论分布进行比较，而不是比较两个样本。在这种情况下，不再有比率，但我不确定该方法是否有意义。
感谢您的反馈]]></description>
      <guid>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</guid>
      <pubDate>Fri, 15 Dec 2023 13:58:15 GMT</pubDate>
    </item>
    <item>
      <title>我的非线性问题的最大似然估计量是多少？</title>
      <link>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</link>
      <description><![CDATA[在区域 $0\leq x\leq 1$ 和 $0\leq y\leq 1$ 我在 $(x_b,y_b)$ 中放置了 1 个无线电广播电台和 N 个接收器。广播公司的立场尚不清楚。
然而，每个接收器的位置是已知的： $(x_i,y_i)$ 以及从接收器到广播器的距离：$d_i$。
距离测量中存在一些噪声，我假设这些噪声呈正态分布，均值为 0，并且所有接收器的方差相同：
$$
\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} = d_i + \epsilon_i
$$
在哪里
$$
\epsilon_i \sim \mathcal{N}(0,\,\sigma^{2})
$$
我的目标是估计无线电广播公司最可能的位置：$(x_b,y_b)$。
我想通过将其表述为一个最小化问题来做到这一点。
到目前为止，我正在最小化：
$$
SE = \sum_i \left[\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} - d_i\right]^2
$$
我读到，对于线性回归，最小二乘估计器也是正态分布误差假设下的最大似然估计器。
但是这对于我的非线性问题也适用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</guid>
      <pubDate>Fri, 15 Dec 2023 08:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比率的自然对数和双向固定效应模型偏差</title>
      <link>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</link>
      <description><![CDATA[Bartlett 和 Partnoy (BP) (2020) 表明自然对数因变量（即比率）的 OLS 必须在 RHS 上包含 Ln（分母），以避免偏差（请参阅第 24-28 页），除非假设分子和分母具有精确的线性关系，即 &lt; (E1) 中的 span class=&quot;math-container&quot;&gt;$\beta_2 = 1$。这是因为 $Ln(ratio)$，例如 $Ln(\frac{GDP_{it}}{population_ {it}})$ 相当于 $Ln(GDP_{it})-Ln(population_{it})$。因此，任何在 LHS 上具有 $Ln(\frac{GDP_{it}}{population_{it}})$ 的 OLS 模型都隐式假设：
$$Ln(GDP_{i})= \beta_0 + X_i + 1Ln(population_{i}) + \epsilon_{i}$$
解决方案是在 RHS 上包含 $Ln(denominator)$，就像在 TWFE 5 中一样。他们不会在面板数据的上下文中讨论这些问题具有双向固定效应 (TWFE)，如 (E1)。
问题
在 OLS 背景下是否有任何理由怀疑 BP？ (E1) 和模型 TWFE 5 是否低于正确的模型来识别 TWFE 面板环境中治疗的无偏效应？ TWFE 2 模型确实给出了治疗的有偏系数吗？是否有任何方法文献在 OLS 或 TWFE 上下文中讨论 $Ln(ratio)$ 的问题？
在模型 TWFE 5 中，$\beta_2$ 并不接近 1，但在中为 $0.92$ OLS 版本没有单位FE的模型。在单位固定效应的背景下，我如何理解 BP 关于 $Ln(\frac{numerator}{denominator})$ 之间线性的观点？
下面的模型 TWFE 4 方程修正了线性假设的偏差：
$$
Ln(\frac{GDP_{it}}{人口_{it}}) = \beta_1 治疗_{it} + \beta_2 Ln(人口_{it}) + \lambda_{t} + \alpha_i + \epsilon_{it}
\标签{E1}
$$
双向固定效应模型：
&lt;前&gt;&lt;代码&gt;============================================== =================================
                                     因变量：
                 -------------------------------------------------- ---------
                  log_gdp log_gdp_pc (log_gdp-log_pop) log_gdp log_gdp_pc
                  TWFE 1 TWFE 2 TWFE 3 TWFE 4 TWFE 5
-------------------------------------------------- --------------------------
处理 -0.025 -0.025 0.059*** 0.059***
                            (0.028) (0.028) (0.020) (0.020)
                                                                            
log_pop -0.264*** -0.281*** -1.281***
                  (0.041) (0.042) (0.042)
                                                                            
-------------------------------------------------- --------------------------
TWFE 是 是 是 是 是
观察次数 1,155 1,155 1,155 1,155 1,155
R2 0.712 0.508 0.508 0.714 0.750
=================================================== =========================
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</guid>
      <pubDate>Fri, 15 Dec 2023 03:57:04 GMT</pubDate>
    </item>
    <item>
      <title>混合设计实验：中值缩减还是线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</link>
      <description><![CDATA[我从混合设计的声学定位实验中收集了数据，其中因素是人群（一个带有助听器 (HA)，一个带有人工耳蜗 (CI)）和条件，第一组人群有四个（带有左 HA、右 HA、两者 HA、无 HA），以及第二个群体的三个（左 CI、右 CI、两者 CI）。在每种情况下，对于 13 个收集的项目（目标定位答案）有 5 次重复测量。并非所有参与者都在每种情况下都进行了测试。我想分析不同条件下受试者内部、受试者之间以及人群之间的差异。混合方差分析不是一种选择，即使它可以容纳丢失的数据，因为数据严重倾斜，并且违反了球形和正态分布假设。我看到两种可能的选择：

通过中位数将每个参与者每个条件的重复测量值减少到一个值。在这种情况下，一些统计功效就会丧失。如何计算和报告效应大小或统计功效？考虑到通过这种减少，所执行的测试不是参数化的。
拟合线性混合效应模型，并随机截取受试者 ID。在这种情况下，没有直线的 Q-Q 图是否违反了必要的假设？如果关系比线性关系更复杂，LMM 是否是一个可行的选择？如果 Q-Q 图是线性的，我会选择 R，如下所示：

&lt;前&gt;&lt;代码&gt;
# 拟合混合效应模型
# - 响应：因变量
# - 总体：受试者间因素（2 个级别）
# - 条件：受试者内因素
# - subjectID：受试者的随机效应

模型 &lt;- lmer(响应 ~ 总体 * 条件 + (1 | subjectID), data = data)

我分析了四个不同的响应变量：头部距离、头部旋转、有符号误差和无符号误差。
平均值 + 2*标准差（针对每种条件）的异常值已被删除。数据已进行对数转换。
以下是 Q-Q 图、残差直方图以及残差与四个变量的拟合值的关系。四个变量残差的偏度值分别为：0.98、-2.69、-4.26、-0.58。











]]></description>
      <guid>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</guid>
      <pubDate>Wed, 13 Dec 2023 10:28:47 GMT</pubDate>
    </item>
    <item>
      <title>具有二元结果的纵向数据的变量选择</title>
      <link>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</link>
      <description><![CDATA[我有一个大型纵向数据集（100,000 观测值），其中包含固定 ID 和年份，以及大约 1000 特征（大多数数字和一些因子）。我一直在使用一小部分可用功能对此数据运行一些分类任务（随机森林、xgboost、svm）。我希望能够使用这些模型来进行一些特征选择/变量重要性，但是，使用全部或大多数可用预测变量运行这些模型似乎并不可行。
在纵向数据集的上下文中，我可以采用哪些可能的方法来选择相关特征，其中特征随 ID 的不同而变化，也随时间的变化而变化。
我是否要硬着头皮允许这些模型在所有功能上运行，然后检查变量重要性和其他指标？或者在对特征进行子集化之前我可以采取一些探索性数据分析步骤吗？
编辑：在特征子集上运行随机森林可能有意义吗，例如一次 100 个特征，因此 10 RF 模型并使用变量重要性对它们中的每一个进行了解，以了解我最终可以使用哪些预测因子？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</guid>
      <pubDate>Mon, 11 Dec 2023 22:34:43 GMT</pubDate>
    </item>
    <item>
      <title>是否应该使用 Wilcoxon 秩和检验来检验均值差异显着性？</title>
      <link>https://stats.stackexchange.com/questions/632708/should-the-wilcoxon-rank-sum-test-be-used-for-testing-the-mean-difference-signif</link>
      <description><![CDATA[我正在寻找论文 DOI:10.3905/jpm.2014.40.3.087 的重复结果（探索宏观经济敏感性：投资如何响应不同的经济环境，Ilmanen Maloney Ross 2014 年《投资组合管理杂志》）。
例如，我想调查美国国债指数（LUATTRUU指数 - 彭博巴克莱美国国债总回报指数）的每月总回报是否取决于美国通胀读数的大小（CPI YOY指数 - 美国城市CPI消费者同比 NSA »）。
于是我下载了过去50年的美国CPI YOY月度数据以及同期美国国债指数的月度总回报。
然后，我将样本分区为“UP”如果美国每月通胀数据高于过去 12 个月的平均水平，则“下降”如果相反的情况发生。
然后，我计算了每个子样本中美国国债指数的平均月总回报。
我得到了以下结果。

美国消费者物价指数“上涨” -&gt;美国国债指数月平均总回报率为0.40%
美国消费物价指数“下跌” -&gt;美国国债指数月平均总回报率为0.65%

因此，数据似乎证实，正如经济理论所暗示的那样，当通胀较高时，债券回报率低于相反情况。
我想进行统计测试，两次回报的差异是否具有统计显着性。
但是，由于我使用的是金融时间序列，因此我不确定应该使用哪种统计测试。
这是我的 R 代码，它以美国 CPI 同比和美国财政部总回报指数的时间序列作为输入：
CPI_YOY_roll&lt;- rollmean(CPI_YOY,k=12, fill=NA,align=“右”)
a&lt;-ifelse(CPI_YOY[13:nrow(ds)]&gt;=CPI_YOY_roll[12(nrow(ds)-1)],“向上”,“向下”)
平均值（na.omit（ifelse（a==“向上”，ds  $treasury_return，NA）））* 100
平均值(na.omit(ifelse(a==&quot;down&quot;,ds$treasury_return,NA)))*100

例如，Ilmanen Maloney Ross（2014，探索宏观经济敏感性：投资如何响应不同的经济环境，投资组合管理杂志）使用我相同的程序并得到以下结果（使用平均夏普比率而不是平均回报，但概念相同）：

所以我想测试这些差异是否具有统计显着性！]]></description>
      <guid>https://stats.stackexchange.com/questions/632708/should-the-wilcoxon-rank-sum-test-be-used-for-testing-the-mean-difference-signif</guid>
      <pubDate>Thu, 30 Nov 2023 14:52:20 GMT</pubDate>
    </item>
    <item>
      <title>独立但非同分布随机变量的中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</link>
      <description><![CDATA[我的问题是关于证明Lyapunov CLT（每个均值都是$0$，$\delta = 1$）。它类似于这个问题，但没有对遵循伯努利分布的随机变量进行任何假设。
这个想法是使用泰勒展开式：
$\psi_{X_1}(t) = 1 - \frac{1}{2}\mathbb{E}X_1^2t^2 - \frac{i}{6}\ mathbb{E}X_1^3t^3 + o(t^3)$。
与维基百科条目一样，定义 $s_n^2 = \Sigma_{i = 1}^n\sigma_i^2$。然后 $\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t ^2}{s_n^2} - \frac{i}{6}\mathbb{E}X_1^3\frac{t^3}{s_n^3} + o(\frac{t^3}{s_n^ 3})$.
如果满足李亚普诺夫条件 ($\delta = 1$)，我会看到 $\lim_{n\ rightarrow\infty}\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t^2}{s_n^2} + o(\frac{t^3}{s_n^3})$。
定义$S_n = X_1 + \dots + X_n$。如果随机变量是 i.i.d.，则缩放后方差为 $1$、$\psi_{\frac{S_n} {\sqrt{n}}}$ 涉及将泰勒展开式提高到 $n$ 次方。但由于随机变量分布不同，$\psi_{\frac{S_n}{s_n}}$ 是 $n$ 条款。如何操作它以便我可以使用 $e^x = \lim_{n\rightarrow\infty}(1 + \frac{x}{n})^n$&lt; /跨度&gt;？
（如何将 $s_n^2$ 除法转换为除以 $n$，这是通过在 i.i.d. 情况下对 $\sqrt{n}$ 进行平方来实现的吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</guid>
      <pubDate>Wed, 29 Nov 2023 06:56:54 GMT</pubDate>
    </item>
    </channel>
</rss>