<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 20 Dec 2023 00:49:45 GMT</lastBuildDate>
    <item>
      <title>寻找泊松分布之间的相关性的适当归一化是什么？</title>
      <link>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</link>
      <description><![CDATA[我有兴趣使用这个算法，glm-pca，来找到一个较低的维度嵌入时间序列数据，特别是神经元尖峰数据，这是泊松分布的。我看过一些关于查找两个泊松分布的协方差的帖子 https://math.stackexchange.com/questions/3707140/joint-distribution-and-covariance-of-poisson-process-and-waiting-time 我只是好奇如果有标准化的话会怎样应该应用于我的数据。基本上这将是一个非常稀疏的计数时间序列。我可能会减小窗口大小以减小矩阵的大小并加快计算速度。]]></description>
      <guid>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</guid>
      <pubDate>Tue, 19 Dec 2023 23:45:02 GMT</pubDate>
    </item>
    <item>
      <title>排列测试图分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</link>
      <description><![CDATA[我需要将来自矩阵引导的值与原始的唯一值进行比较，但我不知道如何对我的数据执行此操作。
为了我需要做：
测量原始网络上的目标变量并保存它洗牌我的原始数据（相关矩阵） - 随机（100x）创建测量该随机网络的目标变量的图表保存循环结束的数据比较分布随机目标变量，并在请求时保存原始变量。那么如果原始数据在随机变量的 95% 分布范围之外，则意味着它是显着的（随机数与原始变量不同）。
我在 R 中使用了 t.teste 这种形式。
pval_eq[k] &lt;- t.test(rand, mu = obs)$p.value
我如何无法进行统计来比较这些数据：观察值以及该值的排列。
我可以使用这种形式来计算 p 值：大于或等于观察值的值（统计量）的数量，然后除以值的数量。在代码中，pval = sum(s &gt;= s0)/N;
我在互联网上找到了其他几个公式。但基本上总的来说，我只是想知道一个正确的公式来计算 p 的值，考虑到我想比较原始值和该值的排列 100x]]></description>
      <guid>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</guid>
      <pubDate>Tue, 19 Dec 2023 22:37:17 GMT</pubDate>
    </item>
    <item>
      <title>采样：如果多个样本产生一个输出，我实际上需要处理多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</link>
      <description><![CDATA[解释一下，假设我根据 $n$ 个连续的现实世界样本计算单个测试统计数据。想象一下，我在实验过程中总共获得了 $m \gg n$ 个真实世界样本。
我是否有 $m$ 或 $m \over n$ 个样本用于假设测试？
&lt;小时/&gt;
就上下文而言，我正在考虑以下声明，摘自采样有关：如果一个样本产生多个输出，我实际上需要工作多少个样本与？ 但它完全相反。]]></description>
      <guid>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</guid>
      <pubDate>Tue, 19 Dec 2023 22:36:54 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习中学习损失衰减的损失函数的推导</title>
      <link>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</link>
      <description><![CDATA[我对贝叶斯深度学习相当陌生，如果这是一个愚蠢的问题，我很抱歉。
我正在尝试实现本文中的工作：我们在计算机视觉的贝叶斯深度学习中需要哪些不确定性？

在整篇论文中，他们给出了最小化目标，使模型能够学习任意不确定性，但他们没有给出任何关于它们来自何处的正式推导。它们不是临时构造，因此必须有一种方法来派生它们。
哪里可以找到推导？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</guid>
      <pubDate>Tue, 19 Dec 2023 22:26:42 GMT</pubDate>
    </item>
    <item>
      <title>预先登记已收集的数据</title>
      <link>https://stats.stackexchange.com/questions/635298/pre-registration-of-data-that-is-already-collected</link>
      <description><![CDATA[我在 2018 年底到 2019 年中期收集了调查数据。由于疫情和其他项目，我除了输入数据之外没有时间做任何事情。我还没有分析数据，甚至没有查看基本的描述或相关性。我确实有 2018 年产生的假设和理论。
现在预注册研究是否太晚了？当我收集数据时，预注册还不是主流做法。遗憾的是，我当时没有预先注册。]]></description>
      <guid>https://stats.stackexchange.com/questions/635298/pre-registration-of-data-that-is-already-collected</guid>
      <pubDate>Tue, 19 Dec 2023 21:58:57 GMT</pubDate>
    </item>
    <item>
      <title>测量程序的标准误差（SEM）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</link>
      <description><![CDATA[在同一尺度上计算不同重量的 SEM 是否正确？例如，比较 10 公斤的所有测量值，然后比较 20 公斤的所有测量值...并取平均值 SEM？或者应该单独报告每个重量的 SEM？]]></description>
      <guid>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</guid>
      <pubDate>Tue, 19 Dec 2023 21:45:42 GMT</pubDate>
    </item>
    <item>
      <title>如何计算标准。 Logit 模型的优势比的估计误差和 95% 置信区间？</title>
      <link>https://stats.stackexchange.com/questions/635295/how-to-calculate-the-std-error-of-estimates-and-95-confidence-interval-of-the</link>
      <description><![CDATA[对于简单的数据集：
anthers.sum &lt;- 结构(列表(存储 = c(1, 2), n = c(309, 247), y = c(164,
155)), row.names = c(NA, -2L), 类 = &quot;data.frame&quot;)
logit_model &lt;- glm(cbind(y, n-y) ~ 存储, data=anthers.sum, family=binomial(link=&#39;logit&#39;))
摘要（logit_model）

&lt;前&gt;&lt;代码&gt;调用：
glm(公式 = cbind(y, n - y) ~ 存储，族 = 二项式(link = &quot;logit&quot;),
    数据 = 花药.sum)

系数：
            估计标准。误差z值Pr(&gt;|z|)
（截距）-0.2754 0.2632 -1.046 0.2955
存储 0.3985 0.1741 2.289 0.0221 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式族的色散参数取1）

    零偏差：1 自由度上为 5.2790e+00
残余偏差：-3.7748e-14（0 自由度）
工商登记号码：16.079

Fisher 评分迭代次数：2

如何手动计算标准。这个 Logit 模型的估计有误吗？
比值比：
x &lt;- anthers.sum$storage
#Logit 模型优势比常数
exp(系数(summary(logit_model))[“(截距)”,1]+系数(summary(logit_model))[“存储”,1]*x[1])
#Logit 模型比值比治疗与对照
exp(系数(summary(logit_model))[“存储”,1]*(x[2]-x[1]))

&lt;前&gt;&lt;代码&gt;[1] 1.131034
[1]1.489594

questionr::odds.ratio(logit_model, level=0.95)

正在等待分析完成...
                 或 2.5% 97.5% p
（截距）0.75929 0.45311 1.2725 0.29553
存储 1.48959 1.06015 2.0989 0.02209 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

当我计算优势比的 95% 置信区间时：
#95% CI 常数
exp(系数(summary(logit_model))[“(截距)”,1]*qnorm(c(0.025,0.975))*系数(summary(logit_model))[“(截距)”,2]+系数(summary(logit_model))[“存储”,1]*x[1]*qnorm(c(0.025,0.975))*系数(summary(logit_model))[“存储”,2])
#95% 治疗组与恒定组的 CI
exp(系数(summary(logit_model))[“存储”,1]*(x[2]-x[1])*qnorm(c(0.025,0.975))*系数(summary(logit_model))[&quot;存储”,2])

&lt;前&gt;&lt;代码&gt;[1] 1.0061048 0.9939322
[1] 0.8728501 1.1456720

它们无法匹配questionr::odds.ratio的结果]]></description>
      <guid>https://stats.stackexchange.com/questions/635295/how-to-calculate-the-std-error-of-estimates-and-95-confidence-interval-of-the</guid>
      <pubDate>Tue, 19 Dec 2023 20:54:46 GMT</pubDate>
    </item>
    <item>
      <title>如何从变分自动编码器进行降维</title>
      <link>https://stats.stackexchange.com/questions/635292/how-to-do-dimension-reduction-from-a-variational-autoencoder</link>
      <description><![CDATA[我正在考虑变分自动编码器。据我了解，在编码部分中，您压缩为 px1 张量，然后创建一个 $\mu$ 和 $\sigma$ 我选择的维度（尽管小于 $p$）。解码层则相反。
但是如果我想使用 VAE 进行降维怎么办？显然，我不会从 $\mu$ 和 $\sigma$ 中随机采样。我是否只转到 px1 张量？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635292/how-to-do-dimension-reduction-from-a-variational-autoencoder</guid>
      <pubDate>Tue, 19 Dec 2023 19:51:26 GMT</pubDate>
    </item>
    <item>
      <title>何时表示中心变量[重复]</title>
      <link>https://stats.stackexchange.com/questions/635291/when-to-mean-center-variables</link>
      <description><![CDATA[我最近了解到您需要表示回归的中心变量。我有几个后续问题：

您指的是任何高级分析（例如 SEM、MLM、LGM）之前的中心变量还是只是回归？
回归是否需要均值居中，或者可以不均值中心变量吗？
均值中心化是否仅对于名义回归或连续预测变量是必要的？

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/635291/when-to-mean-center-variables</guid>
      <pubDate>Tue, 19 Dec 2023 19:43:24 GMT</pubDate>
    </item>
    <item>
      <title>路径分析相当于一系列回归吗？</title>
      <link>https://stats.stackexchange.com/questions/635287/is-path-analysis-equivalent-to-a-series-of-regressions</link>
      <description><![CDATA[我最近才接触到路径分析。假设我有一个像这样的简单因果模型：

我不确定这个 q 是否需要它，但为了简单起见，我们假设 X、Y、Z 是多元正态分布。
我分析影响强度的常用方法是在 X 上回归 Y，然后在 X 和 Y 上回归 Z。路径分析是否会做与此相同的事情？
更一般地说，路径分析只是在 dag 上运行一系列回归的一种方法，还是在做一些根本不同的事情？
&lt;小时/&gt;
我问这个问题的一个具体原因是，我看到了关于结构方程建模（路径分析是其中一个子集）的样本大小为 200 的建议。但对于线性回归，样本大小取决于估计的参数数量，通常采用 10:1 规则。如果路径分析相当于一系列回归，则很难将它们平方。]]></description>
      <guid>https://stats.stackexchange.com/questions/635287/is-path-analysis-equivalent-to-a-series-of-regressions</guid>
      <pubDate>Tue, 19 Dec 2023 19:09:04 GMT</pubDate>
    </item>
    <item>
      <title>我可以将大型 SEM 模型拆分为较小的 SEM 模型吗？</title>
      <link>https://stats.stackexchange.com/questions/635281/am-i-able-to-split-up-a-large-sem-model-into-smaller-sem-models</link>
      <description><![CDATA[我在 SPSS AMOS 中有一个 SEM 模型，正在测试信息共享对可信度（能力、诚信和仁慈）三个维度与创新之间关系的中介作用。下图描绘了我的 SEM 模型。

当我在 SPSS AMOS 上运行完整的结构模型时，结果不是我所期望的，并且几乎所有我的假设都没有得到支持。然而，当我将大型模型分成 3 个较小的模型来运行 SEM 分析（如下所示）时，大多数结果都支持我的假设。我是否可以将大型模型拆分为 3 个独立的较小模型？在什么条件下可以将大型模型拆分为较小的模型？除了进行 3 个单独的测试之外，将较大的模型拆分为三个较小的模型是否有任何缺点？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635281/am-i-able-to-split-up-a-large-sem-model-into-smaller-sem-models</guid>
      <pubDate>Tue, 19 Dec 2023 18:06:58 GMT</pubDate>
    </item>
    <item>
      <title>二元逻辑回归中的权重</title>
      <link>https://stats.stackexchange.com/questions/635276/weights-in-binary-logistic-regression</link>
      <description><![CDATA[我正在进行一项计票荟萃分析，其中我从每项研究中获得的唯一信息是治疗效果的方向（正面或负面）和样本量。我的计划是拟合二元逻辑回归，其中治疗效果方向作为响应变量，几个研究级别特征作为预测变量。我想根据样本大小对研究进行加权（即，对较大的研究给予更多的权重），但我不确定如何在二元逻辑回归中做到这一点。
有了连续响应变量，就可以使用 glm 在 R 中添加这样的权重：
glm(y ~ x,权重=样本大小,族=高斯)
但是，对于二元响应 (family = binomial)，权重被视为试验次数，这在我的情况下没有意义（每个研究都是单个伯努利试验）。 
是否有合理的方法为二元逻辑回归中的观测值分配权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/635276/weights-in-binary-logistic-regression</guid>
      <pubDate>Tue, 19 Dec 2023 17:23:52 GMT</pubDate>
    </item>
    <item>
      <title>典型相关分析 - 载荷与系数</title>
      <link>https://stats.stackexchange.com/questions/635251/canonical-correlation-analysis-loadings-vs-coefficients</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635251/canonical-correlation-analysis-loadings-vs-coefficients</guid>
      <pubDate>Tue, 19 Dec 2023 13:35:35 GMT</pubDate>
    </item>
    <item>
      <title>ROC 综合生物标志物</title>
      <link>https://stats.stackexchange.com/questions/635204/integrated-biomarkers-for-roc</link>
      <description><![CDATA[我正在寻找组合多个定量值的方法，以便构建具有特异性和敏感性的 ROC 曲线。这似乎在多种生物标记论文中很常见，但我找不到任何直接的方法来做到这一点。 CombiROC 似乎就是为此而设计的，但是 Shiny 应用程序不再工作，软件包也没有更新，这让我质疑它的用途。
我从一组具有二元表现（可能是对照与患病）的患者中获得了给定时间点（无随访）的多个蛋白质浓度。单独使用这些蛋白质，我可以构建 ROC 曲线。我发现有些与我的疾病有关。我想进一步推进我的分析，建立一个模型，在其中我可以组合/整合这些标记中的 2 或 3 个，从而完善诊断并获得更好的 AUC/Spe/Sen 值。
例如，在某个时刻，A 和 B 都升高可能比仅升高 A 的预后更差。
到目前为止，这是我发现的方法：我首先构建一个 glm 模型，从中预测落入该组的机会。最后，我通过绘制预测结果与实际结果来计算 ROC。
#与临床组一起构建 glm（二元结果）
组合.glm &lt;- glm(数据集$Group1 ~
                               数据集$分析物1 +
                               数据集$Analyte2 +
                               数据集$分析3，
                               家庭=“二项式”）

#使用模型预测小组结果
数据集$prob.Group1=预测(Combined.glm,type=c(“响应”))

#建立ROC
roc&lt;- roc(数据集$Group1, dataset$prob.Group1)

我想知道这是否是正确的方法，如果不是，应该怎么做？
谢谢！
编辑：添加说明并重新措辞]]></description>
      <guid>https://stats.stackexchange.com/questions/635204/integrated-biomarkers-for-roc</guid>
      <pubDate>Mon, 18 Dec 2023 16:48:22 GMT</pubDate>
    </item>
    <item>
      <title>比较两个样本的第 90 个百分位数（置信区间、检验）</title>
      <link>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</link>
      <description><![CDATA[我有一个质量改进更改前后的救护车响应时间数据集。我想看看更改前后的响应时间是否有差异。具体来说，我试图报告两组（之前和之后）中的第 90 个百分位数值、两个第 90 个百分位数之间的差异、$95$% 置信区间（ CI) 围绕这个差异，以及一个 $p$ 值。
在 R 中，数据集可能如下所示：
set.seed(123)
数据 &lt;- data.frame(
  组=样本（c（“之前”，“之后”），100，替换= TRUE），
  响应时间 = rnorm(100, 平均值 = c(10, 15), sd = 2)
）

我可以使用 t.test 函数轻松测试均值差异：
t.test(data$ResponseTime[data$Group == “之前”],
       数据$ResponseTime[数据$Group ==“之后”])

我还可以像这样计算第 90 个百分位数：
之前 &lt;- 分位数(a$ResponseTime[a$Group==“之前”], probs = 0.9, na.rm = T)
&lt;- 分位数（a$ResponseTime[a$Group==“之后”]，probs = 0.9，na.rm = T）

但我不知道如何比较两者。
我的问题：

这有意义吗？
如果确实有意义，我会使用什么测试来比较第 90 个百分位数？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</guid>
      <pubDate>Sun, 17 Dec 2023 02:55:47 GMT</pubDate>
    </item>
    </channel>
</rss>