<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 11 Nov 2024 12:32:37 GMT</lastBuildDate>
    <item>
      <title>交叉验证中测试集的用途</title>
      <link>https://stats.stackexchange.com/questions/657078/purpose-of-test-set-in-cross-validation</link>
      <description><![CDATA[k 倍交叉验证中的测试集有什么用处？我能找到的最常见支持测试集的论点是训练和测试之间不存在任何数据泄漏。但无论如何，交叉验证中都没有这个……？
交叉验证期间的每次折叠，您都会在单独的集合上训练和测试/验证数据，而不会出现泄漏。对 k 个单独结果取平均值仍然不会导致任何泄漏（还是我太蠢了）？因此，在另一个单独的集合上测试整个结果是完全无用的。
如果您的数据因群体而产生偏差（例如，医学分析中的不同医生），您甚至可以使用分组交叉验证。如果您担心在交叉验证期间出现过度拟合，并且只是“幸运”地获得了良好的结果，您可以监控每个单独折叠之间的差异，或者 - 更好的是 - 只需重复进行交叉验证并比较结果。无论如何，这应该只发生在小数据样本上，在这些样本中，分离一些额外的数据只会对整个过程造成更大的伤害。
那么测试集如何能改善我对一组模型的评估呢？它如何帮助我找到最佳模型？
或者
其他人说它只是“一旦你通过交叉验证选择一个模型，就验证你的模型”。这是什么意思？要么我得到与交叉验证相似的结果；此时，将额外的数据纳入交叉验证只会使其更加稳健，或者我会得到不同的结果，然后我所知道的只是整个交叉验证过程都是欺诈性的，尽管此时再次有更好的方法来检查这一点。
有一个例子让我阅读了这个主题，并真正开始思考所有不同的看法（尽管此时我非常确定它实际上是使用交叉验证的一个非常糟糕的例子）：
作者想比较不同的模型并选择最好的一个。因此，他将数据分为训练集和测试集。他使用 10 倍交叉验证来确定最佳模型，有 2 个质量相似的模型，然后使用测试数据在这两个模型之间做出决定。有什么理由使用此程序吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657078/purpose-of-test-set-in-cross-validation</guid>
      <pubDate>Mon, 11 Nov 2024 12:28:32 GMT</pubDate>
    </item>
    <item>
      <title>变量可以是平稳的但不协整的吗？</title>
      <link>https://stats.stackexchange.com/questions/657077/can-variables-be-stationary-but-not-cointegrated</link>
      <description><![CDATA[这可能是一个幼稚的问题，但我有一个包含两个独立变量的线性回归，并且各个变量的时间序列已经过测试并显示为平稳的。
但是我制作了一个图，似乎显示了两个独立变量之间的关系随时间的变化。这让我有点困惑，因为如果它们是平稳的，为什么它们之间的关系不是平稳的？我的一个测试出错了吗？我认为答案可能是这种情况有可能发生，但我无法提出有效的支持论据。
我通过将它们相互回归并对残差运行 ADF 测试来测试它们之间的平稳性。]]></description>
      <guid>https://stats.stackexchange.com/questions/657077/can-variables-be-stationary-but-not-cointegrated</guid>
      <pubDate>Mon, 11 Nov 2024 12:23:15 GMT</pubDate>
    </item>
    <item>
      <title>空间变异指数</title>
      <link>https://stats.stackexchange.com/questions/657076/index-of-spatial-variability</link>
      <description><![CDATA[我有一个地理区域，分为多个市镇。每个市镇都有一种疾病的发生次数。该过程重复了四次，针对四种疾病（我们可以将它们称为 A、B、C、D）。因此，我有四张地图，其中包含四种疾病的四种地理分布。
问题是这些疾病的聚类程度如何，以及是否有衡量这一点的指标。我知道有聚类分析，可以识别聚类，但问题是它们聚类的程度如何？
因此，问题是是否有某种指标可以衡量空间变异性，例如“聚类指数” A = 27，B = 15，C = 8，D = 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/657076/index-of-spatial-variability</guid>
      <pubDate>Mon, 11 Nov 2024 12:09:33 GMT</pubDate>
    </item>
    <item>
      <title>如何检验相关观测值的方差是否相等？</title>
      <link>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</link>
      <description><![CDATA[我有 2 个协方差估计值：$\Omega_a$ 和 $\Omega_b$。
我想评估其中哪一个是更好的协方​​差估计值。我选择的方法之一是计算 $x$ 的值，使 $x&#39;\Omega x$ 最小化，并且 $sum(x) = 1$。
因此，我在每个时间段内获得 2 个向量 $x_a$ 和 $x_b$，并且我可以观察到 $r$，这是我想要估计协方差的随机变量。
然后，对于每个时间段，我可以计算缩放器 $a_t=x_{a,t}&#39;r_t$ 和 $b_t=x_{b,t}&#39;r_t$。
如果我假设这些数据呈正态分布（实际上它的尾部略微肥大），我可以使用通常的 F 检验吗？我不这么认为，因为 $a$ 和 $b$ 并不独立。
还有其他测试，例如

Barletts 测试
Ansari 测试
情绪测试
Fligner 测试

但我不清楚这些是否适用于相关数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</guid>
      <pubDate>Mon, 11 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    <item>
      <title>如何对各组进行比较，同时考虑所有组的每日波动？</title>
      <link>https://stats.stackexchange.com/questions/657074/how-to-compare-groups-while-accounting-for-daily-fluctuations-in-all-groups</link>
      <description><![CDATA[有一项新技术可以从地表水中获取和储存热量：
在夏季，一台机器将湖中的热水泵送到热交换器。热量被转移到地下水库（例如，在冬季可用于加热建筑物）。
在某些情况下，在热交换器前放置过滤器，以防止水生生物和碎屑穿过或堵塞热交换器。
因此，这台机器有 2 或 3 个部件：泵、热交换器和（可能）过滤器。
在机器之前和每个机器部件之后都有关于水的化学参数的数据。例如：叶绿素 a 浓度或溶解氧浓度。
每两周在机器内/周围的至少两个位置测量一次化学参数。测量一个位置和另一个位置之间间隔 30 分钟。
现在，我想知道是否有任何机器部件影响化学参数。例如：叶绿素浓度是否会因过滤器、热交换器和/或泵而下降？如果会，下降多少？
问题在于，天然湖泊中的化学参数波动很大。叶绿素浓度可能在几分钟内很高，而在下几分钟内很低。而且某一天的浓度可能通常高于另一天。这实际上没有简单的（线性）模式。
我不知道我是否可以校正一天中的变化。
为了校正天之间的变化，我想我需要分别比较每个机器部件在每个测量日的测量值。例如，2024 年 11 月 11 日，过滤后的叶绿素 a 浓度明显低于湖中的浓度，但在 2024 年 8 月 9 日和 2024 年 10 月 5 日则并非如此。
但是，我如何使用所有这些 p 值来得到一个答案：过滤器是否降低了叶绿素 a 浓度？
非常感谢您的帮助！
图：我尝试分析的数据示例
]]></description>
      <guid>https://stats.stackexchange.com/questions/657074/how-to-compare-groups-while-accounting-for-daily-fluctuations-in-all-groups</guid>
      <pubDate>Mon, 11 Nov 2024 12:00:47 GMT</pubDate>
    </item>
    <item>
      <title>医学统计中的每个发现是否都需要在独立的数据集中进行验证？</title>
      <link>https://stats.stackexchange.com/questions/657073/does-every-finding-in-medical-statistics-need-to-be-validated-in-an-independent</link>
      <description><![CDATA[我正在对500 个独立变量和 1 个因变量进行医学统计分析。样本量为 1200。变量与结果之间的关系较弱（例如，饮食和疾病），因此我只能使用 p 值来获取一些重要的相关变量作为我的发现。
由于关系较弱，并且我有另一个包含 300 个样本的数据集，因此我想使用新数据集作为验证数据集。我发现大约一半的重要变量在验证数据集中具有相同的趋势，但它们大多数都具有较高的 p 值。
我认为这是合理的，因为 p 值可以随着样本量减小而增加。但我的问题是：1200 个样本中的其他重要发现（p &lt; 0.05）是否可靠，即使未在验证数据集中得到验证？]]></description>
      <guid>https://stats.stackexchange.com/questions/657073/does-every-finding-in-medical-statistics-need-to-be-validated-in-an-independent</guid>
      <pubDate>Mon, 11 Nov 2024 11:27:22 GMT</pubDate>
    </item>
    <item>
      <title>是否将泊松模型估计值解释为半弹性或预测计数</title>
      <link>https://stats.stackexchange.com/questions/657072/whether-to-interprete-poisson-model-estimates-as-semielasticities-or-as-predicte</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657072/whether-to-interprete-poisson-model-estimates-as-semielasticities-or-as-predicte</guid>
      <pubDate>Mon, 11 Nov 2024 11:20:01 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 MatchThem 和混合效应逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</link>
      <description><![CDATA[R 中的 MatchThem 和混合效应逻辑回归
我正在开展一项非随机研究，以评估两种治疗方法之间并发症发生率的差异。观察到的并发症发生率在两组之间有显著差异（22% vs. 50%）。为了考虑潜在的混杂因素，我计划使用二项逻辑回归模型。鉴于样本量相对较小（130 名患者，分为 53 名和 77 名），并且我的一个协变量（合并症）中存在 7 个缺失值，我选择使用 MICE（链式方程多重插补）方法插补缺失数据，以避免失去这些患者。代码如下：
# 估算缺失值
new_df_imputed &lt;- mice(selected_data, m = 5, maxit = 50, method = &quot;pmm&quot;, seed = 123)

接下来，我使用 MatchThem 包执行倾向得分匹配 (PSM)：
# 在每个估算数据集中执行匹配
m.out_model1 &lt;- matchthem(Treatment_type_tumor_near_gallbladder ~ age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2) 

匹配过程实现了良好的平衡，结果令人满意：
平衡平均差异计数
count
平衡，&lt;0.1 16
不平衡，&gt;0.1 2

平均差异最大的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1602 不平衡，&gt;0.1

插补的平均样本量
0 1
全部 53. 77. 
匹配 (ESS) 45.45 42.4
匹配 (未加权) 49. 42.4
不匹配 4. 34.6

因为我使用了 replace = TRUE 和 ratio = 3，我猜 glm() 函数不再合适了。相反，我计划使用 lme4 包中的 glmer() 函数。
直接在 with() 函数中使用 glmer() 是否正确，如下所示？
results &lt;- with(m.out_model1, glmer(complications ~ Treatment_type_tumor_near_gallbladder + age + sex + bmi + ASA +
comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage + (1 | matching_set_id), # Random cut for matching sets
family = binomial))

output &lt;- pool(results, dfcom = NULL)

或者先提取匹配的数据集会更好吗：
# 访问匹配的数据集
matched_data_list &lt;- complete(m.out_model1, action = &quot;all&quot;)

# 查看第一个插补和匹配数据集的前几行
head(matched_data_list[[1]])

然后继续对提取的数据集进行分析？首先对 PSM 中包含的变量进行单变量分析以确定重要的预测因子，然后在随后的多变量分析中仅使用这些变量（以及临床上重要的变量）是否合理？
任何建议都值得赞赏 :)。]]></description>
      <guid>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</guid>
      <pubDate>Mon, 11 Nov 2024 10:50:46 GMT</pubDate>
    </item>
    <item>
      <title>多个经验分布的假设检验</title>
      <link>https://stats.stackexchange.com/questions/657070/hypothesis-testing-for-multiple-empirical-distributions</link>
      <description><![CDATA[有没有办法评估单个经验分布在统计上是否与一组经验分布（比如说 5 个）不同？类似于方差分析，但针对的是整个分布，这样我就能判断哪个分布与其他分布不同，而不是判断是否存在至少一个与其他分布不同的分布，或者所有分布是否都是从同一分布中抽样的（如 Anderson-Darling k 样本检验）]]></description>
      <guid>https://stats.stackexchange.com/questions/657070/hypothesis-testing-for-multiple-empirical-distributions</guid>
      <pubDate>Mon, 11 Nov 2024 10:20:20 GMT</pubDate>
    </item>
    <item>
      <title>一致性在高维设置中意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/657069/what-does-consistency-mean-in-high-dimensional-settings</link>
      <description><![CDATA[在一些关于$\mathcal{l}_1$惩罚回归的论文中，
$$
\hat{\beta}=\underset{\beta\in\mathbb{R}^{p}}{\operatorname{\arg\min}}\|Y-X\beta\|_2^2+\lambda\|\beta\|_1,
$$
作者说他们获得了一些估计量的理论结果。一个是估计量$\hat{\beta}$的一致性。
在高维设置中，一致性到底意味着什么？一致性在不同的地方有不同的含义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657069/what-does-consistency-mean-in-high-dimensional-settings</guid>
      <pubDate>Mon, 11 Nov 2024 09:37:06 GMT</pubDate>
    </item>
    <item>
      <title>多项逻辑回归：用概率来表示实际人群中各类的比例</title>
      <link>https://stats.stackexchange.com/questions/657068/multinomial-logistic-regression-probability-to-represent-the-proportion-of-type</link>
      <description><![CDATA[我对多项逻辑模型生成的概率有疑问。我想使用该模型预测某些城市的工厂类型比例。我有一些来自城市的独立变量（例如基础设施、劳动力和 GDP 等）。因变量是每个样本城市的工厂类型数量（例如，在城市 1 中，我有 10 个 A 型工厂、5 个 B 型工厂和 5 个 C 型工厂；在城市 2 中，我有 5 个 A 型工厂、8 个 B 型工厂和 7 个 C 型工厂，在城市 3 中……）。总共，样本城市数量为 30 个。
当前分析由多项逻辑模型完成。数据集结构是一行只有一个因变量（例如，十行具有相同的因变量工厂类型 A，其独立变量与我有十个 A 型工厂相同）。在结果中，我可以看到模型对工厂类型的概率进行了预测，例如工厂类型 A 为 0.7，工厂类型 b 为 0.2，工厂类型 C 为 0.1。我的问题是，我是否可以在这里使用概率来表示城市中工厂类型的比例。
提前非常感谢！欢迎使用任何其他方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657068/multinomial-logistic-regression-probability-to-represent-the-proportion-of-type</guid>
      <pubDate>Mon, 11 Nov 2024 09:19:25 GMT</pubDate>
    </item>
    <item>
      <title>当某一层中抽样的单位数为 $\leq$ 1 时，计算总体估计量</title>
      <link>https://stats.stackexchange.com/questions/657065/calculating-population-estimators-when-number-of-units-sampled-in-a-stratum-is</link>
      <description><![CDATA[对某国 20 个州的 100 所房屋进行调查，每个州作为一个层。为了找到总体均值，我知道我需要使用公式
$$\bar{y}_{str}=\sum^{20}_{h=1} \frac{N_h}{N}\bar{y}_h$$
其中 h 表示每个层，$N_h$ 表示层大小，N 表示总人口大小，$\bar{y}_h$ 表示样本均值。
然而，在两个层中，0 所房屋被抽样，这意味着它们没有样本均值。在计算$\bar{y}_{str}$时，我是否将各层的总体包括在总总体中？
此外，我需要计算此结果的 95% CI。我知道这包括查找每个层的样本方差并使用以下公式：
$$\Bbb{V}(\bar{y}_{str})=\sum_{h=1}^{20}\frac{N_h}{N}^2\left(1-\frac{n_h}{N_h}\right)\frac{s_h^2}{n_h}$$
但是，其中 3 个层只有一个观测值，因此无法计算样本方差。因此，在计算 $\Bbb{V}(\bar{y}_{str})$ 时，我是否应将这些阶层的人口规模包括在总人口中。
此外，CI 需要 $\bar{y}_{str}$ 和 $\Bbb{V}(\bar{y}_{str})$，因此这些中使用的 N 值肯定必须相同？那么 N 是所有阶层的总人口吗，包括具有 $\leq$ 1 个采样单位的阶层，还是我不会包括这些阶层？]]></description>
      <guid>https://stats.stackexchange.com/questions/657065/calculating-population-estimators-when-number-of-units-sampled-in-a-stratum-is</guid>
      <pubDate>Mon, 11 Nov 2024 07:41:55 GMT</pubDate>
    </item>
    <item>
      <title>处理不同数据级别的最佳实践[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657062/best-practice-to-handle-different-data-levels</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657062/best-practice-to-handle-different-data-levels</guid>
      <pubDate>Mon, 11 Nov 2024 06:30:29 GMT</pubDate>
    </item>
    <item>
      <title>对于 t 分布，df = n-1。n 代表什么？</title>
      <link>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</link>
      <description><![CDATA[根据 2 人的建议从 Math Stack Exchange 交叉发布。
我知道 $t$ 分布有一个参数：自由度 (df) 的数量。
我还知道 $\mathrm{df} = n - 1$。
但是，$n$ 究竟代表什么？
我听说过几种含义：

&quot;数据集中的数据点数量。&quot; 这听起来不对。如果我有 $100$ 个数据点，但 $t$ 分布（其中 $\mathrm{df}=50$）比 $\mathrm{df}=99$ 更能模拟该分布，那么我为什么要强制 $\mathrm{df}$ 为 99？

&quot;您用来从样本平均值 $\bar{x}$ 定义 $t$ 统计量的正态随机变量的数量。&quot; 这听起来也不对。我知道
$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}.$$
然而，这看起来更像是一个数学关系，而不是$t$的定义。如果我不从正态随机变量开始会怎样？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</guid>
      <pubDate>Sun, 10 Nov 2024 22:38:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么回归模型比 LSTM 效果更好？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657050/why-regression-models-working-so-well-over-lstm</link>
      <description><![CDATA[我关注的是这个问题。

以下是我关注的问题的摘要。
我有以下任务要做：通过连续 3 天的训练来预测每个第 4 天。每天的数据代表一个尺寸为 24x25 的 CSV 文件。每个 CSV 文件的每个数据点都是像素。
现在，我需要这样做，使用训练数据第 1 天、第 2 天、第 3 天（即连续三天）预测第 4 天（即第 4 天），然后计算预测的第 4 天数据和原始第 4 天数据之间的 mse。我们称之为 mse1。
同样，我需要使用训练数据 day2、day3、day4 预测 day5（即第 5 天），然后计算 mse2（预测的第 5 天数据与原始的第 5 天数据之间的 mse）
我需要使用训练数据 day3、day4、day5 预测 day6（即第 6 天），然后计算 mse3（预测的第 6 天数据与原始的第 6 天数据之间的 mse）
..........
最后，我想使用训练数据 day90、day91、day92 预测 day93，计算 mse90（预测的第 93 天数据与原始的第 93 天数据之间的 mse）。
我想使用 Ridge 回归，线性回归和 LSTM 模型。每个模型都有 90 mse。
在随后的问题中，@Dave 给了我满意的答案。并且我按照@Dave实现我的模型。
准备数据：
# 为范围 (3, 93) 准备数据
X = np.array([data_flattened_scaled[i-3:i].flatten() for i in range(3, 93)]) # 形状：(90, 1800)
y = data_flattened_scaled[3:93] # 目标是每个序列中的第 4 天

LSTM 模型：
# ---------- LSTM 模型 ----------
X_lstm = np.array([data_flattened_scaled[i-3:i] for i in range(3, 93)]) # 形状：(90, 3, 600)
y_lstm = data_flattened_scaled[3:93].reshape(len(y), 1, 600) # 形状：(90, 1, 600)

lstm_model = Sequential()
lstm_model.add(LSTM(64, 激活=&#39;relu&#39;, 输入形状=(X_lstm.shape[1], X_lstm.shape[2])))
lstm_model.add(Dense(600))
lstm_model.compile(优化器=&#39;adam&#39;, 损失=&#39;mse&#39;)
lstm_model.fit(X_lstm, y_lstm, epochs=50, batch_size=8, verbose=1)
y_pred_lstm = lstm_model.predict(X_lstm)
residuals_lstm = [np.mean((y_lstm[i][0] - y_pred_lstm[i]) ** 2) for i in range(len(y_lstm))]

线性回归模型：
# ---------- 线性回归 ----------
lr_model = LinearRegression()
lr_model.fit(X, y)
y_pred_lr = lr_model.predict(X)
residuals_lr = [np.mean((y[i] - y_pred_lr[i]) ** 2) for i in range(len(y))]

岭回归模型：
# ---------- 岭回归 ----------
ridge_model = Ridge()
ridge_model.fit(X, y)
y_pred_ridge = ridge_model.predict(X)
residuals_ridge = [np.mean((y[i] - y_pred_ridge[i]) ** 2) for i in range(len(y))]


实施上述模型后我得到了什么：

问题是什么：当我为每个模型绘制 90 天的 90 mse 图表时，lstm 在整个 90 天内都出现峰值（这是正确的），但两个回归模型的 mse 最接近 0，我的问题是为什么回归模型效果这么好？
我的理解：我们不能使用 Ridge 和线性回归在这里，它们无法有效地捕获时间依赖性，并且缺乏对数据中的顺序模式进行建模的能力，因此不适合涉及每日模式的时间序列预测。因此，即使我们使用这些模型，我们也只能始终获得 MSE 0。除此之外，LSTM 模型是专门为顺序数据设计的。
我说得对吗？有人能帮我了解这里到底发生了什么吗？
我的数据样本例如第 1 天、第 2 天、第 3 天,第 4 天]]></description>
      <guid>https://stats.stackexchange.com/questions/657050/why-regression-models-working-so-well-over-lstm</guid>
      <pubDate>Sun, 10 Nov 2024 21:53:14 GMT</pubDate>
    </item>
    </channel>
</rss>