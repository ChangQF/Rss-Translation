<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 23 Oct 2024 15:18:06 GMT</lastBuildDate>
    <item>
      <title>时间序列的局部异常值因子</title>
      <link>https://stats.stackexchange.com/questions/656203/local-outlier-factor-for-time-series</link>
      <description><![CDATA[我希望这有意义。我发现了 LOF 并在 R 中尝试了它。但是，由于我处理的是时间序列，所以邻居不能是当前观察的“未来”邻居。我想知道使用 LOF 检测时间序列中的异常值是否会因此而出现问题。基本上，给定一个按日期排序的一维数据集，我希望 LOF 给出一个因子，该因子仅考虑当前观察左侧的邻居，而不是右侧的邻居。
我试图在我的时间序列中查找异常。异常是时间序列中的一个值，该值在（仅）给定序列的先前值的情况下非常出乎意料。]]></description>
      <guid>https://stats.stackexchange.com/questions/656203/local-outlier-factor-for-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 14:47:24 GMT</pubDate>
    </item>
    <item>
      <title>部署后生成的分发</title>
      <link>https://stats.stackexchange.com/questions/656201/generated-distribution-after-deployment</link>
      <description><![CDATA[设$\mathcal{D}$表示乘积空间$\mathcal{X} \times \mathcal{Y}$上的联合分布，其中$\mathcal{X}$和$\mathcal{Y}$分别表示输入源和输出源。
假设$h$是在样本$S \sim \mathcal{D}^m $上训练的某些学习规则的输出。现在标签取决于$h$，则$\mathcal{X} \times \mathcal{Y}$上产生的新分布是什么？我们如何才能正确定义这个分布？
我的尝试：
我将定义结果分布 $\mathcal{D}_h$：
$$\mathcal{D}_h(\langle x ,y \rangle) = \mathcal{D}_{\mathcal{X}}(x) \times \mathcal{D}(h(x) = y|x) $$
但是如果 $h$ 是随机的，这意味着 $h$ 在给出输出之前使用了一些随机过程（抛硬币），该怎么办？如果 $h$ 是密度，该怎么办？如果 $h$ 是单纯形 $\Delta_\mathcal{Y}$ 上的密度分布，那么表达式是否简单地变为 $\mathcal{D}_h(\langle x ,y \rangle) = \mathcal{D}_{\mathcal{X}}(x) \times h^y(x) $? 其中 $h^y(x)$ 是概率密度。
特别是，保留相同的边际分布 $\mathcal{D}_{\mathcal{X}}$ 是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/656201/generated-distribution-after-deployment</guid>
      <pubDate>Wed, 23 Oct 2024 14:34:58 GMT</pubDate>
    </item>
    <item>
      <title>Ngram - 良好平滑概率问题</title>
      <link>https://stats.stackexchange.com/questions/656200/ngram-good-smoothing-probability-problem</link>
      <description><![CDATA[我正在为单字母组、二字母组和三字母组创建一个 n-gram 模型。但是，我有两个问题：
未见概率与观察到的概率之和是否应始终等于 1？
如果 𝑁𝑐+1 不存在，那么 Good-Turing 平滑方法中 𝑐∗ 的值应该是多少？
for syllable in unigram:
c = unigram[syllable]

if c+1 in Nc and c in Nc:
unigram[syllable] = ((c+1) * Nc[c+1] / Nc[c] ) / totalOfunigram
else:
unigram[syllable] = (c) / totalOfunigram # / Nc[c]`
]]></description>
      <guid>https://stats.stackexchange.com/questions/656200/ngram-good-smoothing-probability-problem</guid>
      <pubDate>Wed, 23 Oct 2024 13:36:43 GMT</pubDate>
    </item>
    <item>
      <title>使用（非常）有限样本的最佳统计分析：MLR 与 GLM 与 GAM 以及其他？</title>
      <link>https://stats.stackexchange.com/questions/656196/best-statistical-analysis-with-very-limited-samples-mlr-vs-glm-vs-gam-vs-som</link>
      <description><![CDATA[我的数据集非常有限（11 个观测值）。我试图获取响应变量和环境协变量之间的关系（我有一组 14 个环境协变量可以使用）。最终目标是能够通过环境协变量的组合来预测响应变量。
我运行了 MLR，得到了非常有趣的结果，但我不确定它们在统计上是否足够稳健，因为我的数据不是参数化的。
我还运行了 GLM 和 GAM，也获得了有趣的关系。
我知道我的数据非常有限，但这种数据通常都是这样，因为每个点都很难获得（时间和金钱昂贵）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656196/best-statistical-analysis-with-very-limited-samples-mlr-vs-glm-vs-gam-vs-som</guid>
      <pubDate>Wed, 23 Oct 2024 12:49:35 GMT</pubDate>
    </item>
    <item>
      <title>控制由诱导矩阵 $L_1$ 范数衡量的估计误差</title>
      <link>https://stats.stackexchange.com/questions/656194/control-the-estimation-error-measured-by-induced-matrix-l-1-norm</link>
      <description><![CDATA[当我使用套索法逐列估计矩阵（例如 $A$）时，我观察到在数值实验中估计误差 $\|\hat{A}-A\|_{L_1}=\underset{1\le j \le p}{\max}|\hat{a}_{\cdot j}-a_{\cdot j}|_1$ 似乎受 $cM_p$ 限制，其中 $\|A\|_{L_1}=M_p$ 且 c 为常数。
我不确定这个观察结果是否正确。我知道 $\|\hat{A}-A\|_{L_1}$ 可以被 $s\|\hat{A}-A\|_{\max}$ 所限制，其中 $s $ 表示列中非零元素的数量，但数值实验的结果似乎有所不同。
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656194/control-the-estimation-error-measured-by-induced-matrix-l-1-norm</guid>
      <pubDate>Wed, 23 Oct 2024 12:18:51 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 p 值的逆概率？</title>
      <link>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</link>
      <description><![CDATA[我理解，如果零假设为真，p 值就是获得数据（或更多极端值）的概率。
然而，研究人员真正想知道的是，在给定数据的情况下，零假设为真的概率。
因此，需要计算逆概率，该逆概率基于对零假设基本概率的估计，并对诸如“获得数据的总概率”之类的内容进行加权。
我可以使用贝叶斯推理，结合测试的敏感度、基准率和阳性总数：
P（患病|阳性）= P（阳性|患病）* P（患病）/ P（阳性）
例如，如果一种疾病影响 100 人中的 1 人，测试的敏感度为 99%，我随机测试 100 人，我会得到两个阳性（一个真，一个假），逆概率~0.5：
0.99 * 0.01 / ~0.02 = ~0.5
现在，我的问题是，我应该如何使用贝叶斯推理来计算 p 值的逆概率？
例如，我对 H0 没有任何先验知识，因此假设 P(H0) = 0.5，然后我得到一个显著性检验，假设 p 值 = 0.01。我想知道在这种情况下 P(positif) 对应的是什么：
P(H0|data) = P(data|H0) * P(H0) / P(of what?) = 0.01 * 0.5 / 具体是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</guid>
      <pubDate>Wed, 23 Oct 2024 12:13:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么大学统计课上仍然教授变量的逐步选择？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656192/why-is-stepwise-selection-of-variable-still-taught-in-university-statistics-clas</link>
      <description><![CDATA[我不止一次碰到最近出版的教科书和课程，它们教授使用分步法构建模型。考虑到这种方法带来的问题，为什么还要这样做呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656192/why-is-stepwise-selection-of-variable-still-taught-in-university-statistics-clas</guid>
      <pubDate>Wed, 23 Oct 2024 12:01:59 GMT</pubDate>
    </item>
    <item>
      <title>如何估计数据的平均值和方差？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656191/how-do-i-estimate-the-mean-and-variance-from-data</link>
      <description><![CDATA[我有一些 1D 数据，想估计它的均值和方差。我没有底层模型，也没有真实值/目标值可以比较。为了进行比较，我该如何估计数据的偏差和方差。
例如，

此处的橙色和蓝色曲线表示经过后处理的相同数据集，但更改了变量。如何确保偏差和方差最小？]]></description>
      <guid>https://stats.stackexchange.com/questions/656191/how-do-i-estimate-the-mean-and-variance-from-data</guid>
      <pubDate>Wed, 23 Oct 2024 11:44:32 GMT</pubDate>
    </item>
    <item>
      <title>当协方差矩阵非正定义时如何处理VAR模型？</title>
      <link>https://stats.stackexchange.com/questions/656185/how-to-deal-with-var-model-when-covariance-matrix-is-not-positive-define</link>
      <description><![CDATA[当我尝试将 VAR 模型应用于多变量时间序列时，我遇到了一些复杂情况。
数据集：数据集由来自多个用户的时间序列数据组成。对于每个用户，我都有许多特征（例如 F1、F2、...F32），其中一个是预测的目标特征，例如F29.
training_set：它通过 90 天的滑动时间窗口构建，为每个用户生成不同的块，例如，对于用户 i，Xi=[&lt;day1,...day89&gt;, &lt;day2,...day90&gt;,...] Yi=[, , ,...]
Python 代码（经过规范化并使每个特征平稳，最多二阶导数）：
 try: 
model: VAR(training_set) 
x = model.select_order(maxlags=90) 
print(x.summary()) 
except Exception as error: 
print(error)

问题 1：对于大多数用户，我得到：“数组的第 17 或第 31t 个前导子项不是正定的。”
问题 2：对于那些我能够无错误地运行上述代码的用户，当分析 F29（目标变量）的结果时，结果发现，p 值 &lt;= 0.05 与不同用户的不同滞后有关，对应于同一特征。例如，对于特征 F20，用户 3 的滞后为 10，用户 4 的滞后为 12。
关于问题 1，我搜索了一下，似乎“当协方差矩阵在数值上不呈正定时，就会发生错误。”。由此，我了解到在对应于协方差计算时存在相反的信号特征。您知道如何解决这个问题吗？
关于问题 2：我找不到任何有用的方法来解决它。有什么想法或帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656185/how-to-deal-with-var-model-when-covariance-matrix-is-not-positive-define</guid>
      <pubDate>Wed, 23 Oct 2024 10:01:11 GMT</pubDate>
    </item>
    <item>
      <title>使用单向受试者间 MANOVA 与裂区重复测量 ANOVA 相比有哪些优点和缺点？</title>
      <link>https://stats.stackexchange.com/questions/656184/what-are-the-advantages-and-disadvantages-of-using-a-one-way-between-subjects-ma</link>
      <description><![CDATA[例如，我想分析三个物种（猫、狗和老鼠）之间的心率、呼吸频率、身高、体重和毛发数量的差异。这当然是一个荒谬的例子，但进行单向受试者间 MANOVA 与进行裂区方差分析相比有什么优势？
对于 MANOVA，受试者间因子将是物种，DV 如上所述。
对于裂区方差分析，受试者间因子将是物种，受试者内因子的每个级别将是不同的 DV。]]></description>
      <guid>https://stats.stackexchange.com/questions/656184/what-are-the-advantages-and-disadvantages-of-using-a-one-way-between-subjects-ma</guid>
      <pubDate>Wed, 23 Oct 2024 09:59:24 GMT</pubDate>
    </item>
    <item>
      <title>回归汇总数据（beta系数）的元分析</title>
      <link>https://stats.stackexchange.com/questions/656182/meta-analysis-about-regression-summary-databeta-coefficient</link>
      <description><![CDATA[关于元分析，如果我有三项研究都使用线性回归模型来分析收入和支出之间的关系，但每项研究使用的协变量都不同——第一项研究包括年龄和教育，第二项研究包括年龄和性别，第三项研究包括教育、税率和是否有孩子——考虑到这些具有不同协变量的模型，我还能进行元分析吗？
对于这种类型的研究，我考虑过以下策略：使用元回归，将 beta 系数视为因变量，将协变量的存在与否视为虚拟变量。例如，回归模型是否包含教育（是 = 1；否 = 0）等。我想知道这种方法是否合适，或者有更好的建议吗？
$BETA_i = constant + b_1*EDU + e_i$
哪个EDU是虚拟的[0或1]。
我主要关心的是确保beta系数不受协变量的影响，或者协变量对荟萃分析可能根本不重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/656182/meta-analysis-about-regression-summary-databeta-coefficient</guid>
      <pubDate>Wed, 23 Oct 2024 09:26:29 GMT</pubDate>
    </item>
    <item>
      <title>对于时间序列来说，样本外验证是否也应该超出时间范围？</title>
      <link>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</link>
      <description><![CDATA[简介
在训练模型时，“样本”通常是指用于拟合模型的数据，因此...
样本：用于训练模型的数据
样本外：未用于训练模型的数据
超出时间：未用于训练模型的数据，晚于用于训练模型的数据
有时规定必须对模型进行“样本外”和“超出时间”验证。但不清楚“超出时间”是什么意思，已经是“样本外”了。我认为“样本外”可以解释为对不属于训练“样本”的客户的验证。
解释 1
这里的解释是进行两次独立的验证运行：

对“及时”的“样本外”数据进行验证
对同样“样本外”的“时间外”数据进行验证


我认为这里最大的缺陷是“样本外”验证将是“及时的”，因此绩效指标可能会被夸大。例如，如果“及时”期间是在 covid 期间，那么您将获得“样本外”验证结果，表明您在这些未见过的客户上做得很好，而实际上，该模型在生产环境中对未见过的客户表现会很糟糕（这是超时的）。
解释 2
这里的解释是，报告“及时”和“样本外”数据中的任何数字都没有意义，因为这些数字实际上并没有说明现实世界的表现。相反，向监管机构报告的所有验证数字都是超时的。

仅对“样本外”数据进行“超时”验证。这是对现实世界表现最保守的估计。它也是通用性的最佳指标。这里的“样本外”是指甚至没有“及时”进入训练样本的客户。
对所有“超出时间”的客户进行验证数据，因为这是对近期业绩的最佳估计，因为客户群在近期（例如未来 2-3 年）通常相当稳定。


根据这种解释，您报告的最保守的数字很可能最能反映现实世界的表现并反映普遍性（例如对未见过的客户）。
问题
您会使用哪种解释？您认为这两种解释同样有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 07:39:33 GMT</pubDate>
    </item>
    <item>
      <title>协方差矩阵估计的样本要求</title>
      <link>https://stats.stackexchange.com/questions/656179/sample-requirements-for-covariance-matrix-estimation</link>
      <description><![CDATA[我有一个输入信号矩阵 $X$，其形状为 4 x N，每行包含相同的信号，但具有恒定的时间延迟（与阵列信号处理相关）
$$X[i, :] = X(t-i\tau)$$
我的目标是找到信号的逆协方差矩阵，
$$ R^{-1} = (XX^H)^{-1}$$
我想知道的是，是否有任何统计方法可以找到使矩阵可逆所需的最小时间样本和最大样本，直到信号不再平稳。
该应用是无线通信，因此在基带，$\mu_i = 0$ 或接近于零，因此被忽略。]]></description>
      <guid>https://stats.stackexchange.com/questions/656179/sample-requirements-for-covariance-matrix-estimation</guid>
      <pubDate>Wed, 23 Oct 2024 06:37:14 GMT</pubDate>
    </item>
    <item>
      <title>关于多元密度函数的估计</title>
      <link>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</link>
      <description><![CDATA[设 $(X,Y)$ 为非负绝对连续随机向量，概率密度函数为 $f(x,y)$。随机样本 $\{X_{1i},X_{2i}\}$ 也为独立同分布。然后 $f$ 的核密度估计量由以下公式给出
$$\widehat{f}(x,y)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x},\frac{y-y_i}{h_y}\right)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x}\right)k\left(\frac{y-y_i}{h_y}\right),$$
其中 $h_x$ 和 $h_y$ 表示带宽参数，$K$ 是核。
使用一些数据，我估算了核密度估计：
library(ks)

# 您对 X 和 Y 的缩放数据
X &lt;- c(0.95230999, 0.00596125, 0.00298063, 0.89716841, 0.16244411, 0.01490313, 
0.1609538, 0.16244411, 0.29508197, 0.05812221, 0.5633383, 0.60804769, 
0.05365127, 0.30849478, 1, 0.04023845, 0.12965723, 0.37853949, 0, 0.57824143)

Y &lt;- c(0.01195652, 0.27318841, 0.21557971, 0.12318841, 0.21630435, 0.22572464, 
0.03550725, 0.32971014, 0.13007246, 0.22644928, 0.22427536, 0, 
1, 0.54311594, 0.36775362, 0.18152174, 0.0884058, 0.19565217, 
0.08514493, 0.0807971)

# 将 X 和 Y 组合成一个矩阵
data_matrix &lt;- cbind(X, Y)

# 使用插件方法 (Hpi) 进行带宽选择
H &lt;- Hpi(x = data_matrix) # 插件带宽选择方法
print(H)
kde_result &lt;- kde(x = data_matrix, H = H)
plot(kde_result, cont = c(50, 75, 95)) # 50%、75% 和 95% 水平的轮廓

我的问题是“我们如何估计$$G(x,t)=\frac{\partial}{\partial x} F(x,t),$$ 其中 $F$ 是联合分布函数，$t$ 是某个正实数。
$G(x,t)$ 的核估计如下
$$\widehat{G}(x,t)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x}\right)K\left(\frac{y-y_i}{h_y}\right),$$
其中 $$K(z)=\int_0^z k(x)dx.$$ 有关更多详细信息，请参阅这里。
问题：我的问题是如何为这个估计选择带宽？就像我在 R 代码中对 𝑓(𝑥,𝑦) 所做的那样，我想以类似的方式使用 R 估计 𝐺(𝑥,𝑡)。]]></description>
      <guid>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</guid>
      <pubDate>Wed, 23 Oct 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对二维数据进行聚类[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</link>
      <description><![CDATA[我在一个数据框中有 35 个线性模型（b 是截距，a 是系数）：
xy &lt;- structure(list(b = c(2045.08, 2045.58, 2045.33, 2045.29, 2045.39, 
1991.67, 2053.54, 2048.3, 2049.76, 2003.74, 2021.51, 1984.74, 
2038.64, 2053.64, 2011.17, 2039.31, 1891.7, 1745.42, 1712.83, 
1119.93, 1097.59, 1629.34, 1638.34, 1038.81, 1673.84, 1663.97, 
784.72, 885.24, 1800.33, 1723.93, 1017.47, 1014.38, 1651.5, 2969.72, 
3254.87), a = c(2.48, 2.36, 2.42, 2.43, 2.4, 3.67, 2.29, 2.41, 
2.38, 2.69, 2.55, 2.84, 2.47, 2.35, 2.68, 2.52, 3.4, 4.33, 4.53, 
8.05, 8.18, 4.94, 4.89, 8.51, 4.7, 4.76, 9.94, 9.36, 4.04, 4.48, 
8.63, 8.19, 4.82, -1.94, -2.52)), row.names = c(NA, -35L), class = &quot;data.frame&quot;)

其中一些非常相似，我想通过聚类来减少模型数量。

数据看起来高度相关。
我尝试过 kmeans()，但它会为密集的点云生成许多聚类，并为视觉上分离的点生成一个聚类points.
kmeans(xy, 12)$centers |&gt; points(pch = 3, col = &quot;red&quot;)


可以看出，所有小于 1500 的 b 值都只有一个聚类。两个高 b 值也是如此。而 2000 左右的 b 值在视觉上密集的云被分成了几个聚类。
还有其他方法可以对此类数据进行聚类吗？
编辑：在我的情况下，3 个聚类是不够的。我的目标不是平均数据，而是丢弃相似的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</guid>
      <pubDate>Tue, 22 Oct 2024 14:53:15 GMT</pubDate>
    </item>
    </channel>
</rss>