<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 09 Aug 2024 15:18:09 GMT</lastBuildDate>
    <item>
      <title>为什么在梯度提升算法中使用梯度下降？</title>
      <link>https://stats.stackexchange.com/questions/652542/why-use-gradient-descent-in-gradient-boosting-algorithm</link>
      <description><![CDATA[梯度提升算法概述：

初始化：从初始模型开始。对于回归问题，这通常是目标值$(\bar{y})$的平均值。
迭代（提升轮次）：
对于每次迭代$m$，根据当前模型的预测计算残差，即$f_m(x_i)$。也就是说，计算$r_i=y_i-f_{m}(x_i)$。
训练一个新的弱学习器（例如，决策树）来预测残差$r_i(x_i)$。
更新模型的预测，$f_{m+1}(x)=f_m(x)+\alpha \times newlearner(x)$。

在上述算法中，我们根据$x_i$s 预测残差。我们可以证明，步骤 2 中给出的残差相当于二次损失函数的负梯度，因此我们使用负梯度来训练树（从 $x$ 预测负梯度）。因此，该方法的名称“梯度提升”由此而来。
问题：我们可以明确计算残差 $r_i$，而无需应用任何梯度下降算法，为什么我们要使方法复杂化，而直接可观察的残差则使用负梯度？]]></description>
      <guid>https://stats.stackexchange.com/questions/652542/why-use-gradient-descent-in-gradient-boosting-algorithm</guid>
      <pubDate>Fri, 09 Aug 2024 14:59:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么“mirt”和“eRm”对 Rasch 模型的 infit 和 outfit 指数给出的结果不同？（R 代码）</title>
      <link>https://stats.stackexchange.com/questions/652540/why-dont-mirt-and-erm-give-the-same-results-for-infit-and-outfit-indices-fo</link>
      <description><![CDATA[library(mirt)
library(eRm)

# 二分数据模拟
set.seed(3)
n_items &lt;- 40
n_cand &lt;- 1000
diff &lt;- rnorm(n_items, 0, 1) |&gt; sort() 
能力 &lt;- rnorm(n_cand, 0, 1)
sim_data &lt;- sapply(1:n_items, \(i) as.numeric(1 / (1 + exp ((diff[i] - capacities))) &gt; 
runif(n_cand, 0, 1)))
colnames(sim_data) &lt;- paste0(&quot;Item &quot;, seq_len(n_items))

## MIRT
model.mirt &lt;- mirt(sim_data, 1, itemtype = &quot;Rasch&quot;, verbose = FALSE)
res.mirt &lt;- mirt::itemfit(model.mirt, &#39;infit&#39;)

# eRM
model.erm &lt;- RM(sim_data)
res.erm &lt;- person.parameter(model.erm) |&gt; eRm::itemfit()

# 以下所有相关性都不等于 1（并且远非如此）
cor(res.mirt[, &quot;infit&quot;], res.erm$i.infitMSQ, method = &quot;spearman&quot;)
cor(res.mirt[, &quot;z.infit&quot;], res.erm$i.infitZ, method = &quot;spearman&quot;)
cor(res.mirt[, &quot;outfit&quot;], res.erm$i.outfitMSQ, method = &quot;spearman&quot;)
cor(res.mirt[, &quot;z.outfit&quot;], res.erm$i.outfitZ, method = &quot;spearman&quot;)

题目难度相同
item_mirt &lt;- coef(model.mirt, IRTpars = TRUE, simply = TRUE)$items[, &quot;b&quot;]
item_erm &lt;- - coef(model.erm)
cor(item_mirt, item_erm, method = &quot;spearman&quot;)
# [1] 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/652540/why-dont-mirt-and-erm-give-the-same-results-for-infit-and-outfit-indices-fo</guid>
      <pubDate>Fri, 09 Aug 2024 14:37:00 GMT</pubDate>
    </item>
    <item>
      <title>您能测量两个时间序列的季节性成分之间的相关性吗？</title>
      <link>https://stats.stackexchange.com/questions/652538/can-you-measure-correlation-between-only-the-seasonal-components-of-2-time-serie</link>
      <description><![CDATA[我有蝎子螫伤事故的时间序列数据和环境数据（降雨）。蝎子螫伤事件呈上升趋势，但也有季节性成分似乎与降雨相匹配（降雨没有任何趋势，但气候季节性很强，有许多干旱月份）。
我在 R-studio 中分解了这两个时间序列，并对它们的季节性成分进行了 Spearman-rho 相关性分析，发现相关性很强（~0,80）；我的想法是：无论降雨多少，病例都在增加，但在雨季病例更多。这是一种统计有效方法（测量季节性成分的相关性）还是虚假相关性？这也是一个有效的结论吗？
另一项显示一定相关性的分析是一年中的病例百分比与一年中的降雨百分比；这是一种更好的方法吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/652538/can-you-measure-correlation-between-only-the-seasonal-components-of-2-time-serie</guid>
      <pubDate>Fri, 09 Aug 2024 14:17:36 GMT</pubDate>
    </item>
    <item>
      <title>空气质量指数类别多级分类方法论及 RMSE、MAE 回顾</title>
      <link>https://stats.stackexchange.com/questions/652536/review-of-methodology-and-rmse-mae-for-multi-class-classification-of-air-qualit</link>
      <description><![CDATA[我正在撰写我的大学论文，并提出了以下方法来预测空气质量指数 (AQI)，然后将其分类。AQI 类别有六个，每个类别的范围如下：良好 (0-50)、中等 (51-100) 等。考虑到我使用了随机森林模型。这些是实现我的目标的步骤。

使用时间序列分割数据

将浓度（PM2.5、PM10、CO）作为 X（输入），将 AQI 作为 Y（目标/输出）。
初始 RFR 模型训练，然后进行交叉验证和超参数调整（网格搜索）。
使用 R2、RMSE、MAE 评估模型。
使用最佳模型预测所有数据集的 AQI，并使用标准 AQI 范围对这些值进行分类。
使用分层 k 折分割数据（预测的 AQI 及其类别）。
将 AQI（预测的 AQI）作为 X（输入），将类别作为 Y（目标/输出）。
初始 RFC 模型训练，然后进行交叉验证和超参数调整（网格搜索）搜索）。
使用准确度、MCC、F1、精确度、召回率评估模型。



我使用随机森林实现了它，得到了以下我无法理解的评论：

测试集上的 MAE (4) 和 RMSE (7) 的测试分数更高，那么 F1 (.99) 和 MCC (.99) 怎么会如此优秀呢。
我的整体方法是错误的，因为我执行的是分类任务（我让它看起来像一个回归+分类任务。此外，它不是分类，而是标签。
MAE 和 RMSE 应该在分类任务上计算。

我需要对我的实现发表评论。这里可能有什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652536/review-of-methodology-and-rmse-mae-for-multi-class-classification-of-air-qualit</guid>
      <pubDate>Fri, 09 Aug 2024 12:55:30 GMT</pubDate>
    </item>
    <item>
      <title>如果两组测量的是相同的结构，为什么一个变量有显著差异，而另一个变量没有显著差异？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652535/how-can-for-two-groups-one-variable-be-significantly-different-but-another-not-i</link>
      <description><![CDATA[概述：

使用两种不同的可用性测量方法收集的两组序数数据
这两个测量方法已被证明是相关的（对于此数据集也已证实）
每个数据集可以分为两个独立的组（总共约 30 个数据点）
使用统计显着性检验，一个测量的结果显示出显着差异，而其他测量的结果则没有

问题：
我们如何解释这一点，这告诉我们什么？从相关性和统计差异背后的概念来看，这是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/652535/how-can-for-two-groups-one-variable-be-significantly-different-but-another-not-i</guid>
      <pubDate>Fri, 09 Aug 2024 12:44:16 GMT</pubDate>
    </item>
    <item>
      <title>变压器 添加订单</title>
      <link>https://stats.stackexchange.com/questions/652532/transformer-add-order</link>
      <description><![CDATA[目前，Transformer 块具有以下结构（忽略所有规范、掩码、dropout...）：
x
y1 = x +tention(x)
y2 = y1 + linear(y1)

为什么不在 x 上添加一个变化，而不是两个不同的变化？
x
y1 = x +tention(x)
y2 = x + linear(y1)

没有看到这种替代方案。
这显然不好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652532/transformer-add-order</guid>
      <pubDate>Fri, 09 Aug 2024 11:31:45 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是假设检验吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652530/is-the-chi-squared-test-an-hypothesis-test</link>
      <description><![CDATA[有人能给我解释一下假设检验和 $\chi^2$ 检验之间的区别吗？还有什么是 Karl-Pearson 检验？它是 $\chi^2$ 检验的一种吗？如果是，所有这些类型的检验之间有什么区别？我读到还有 Fisher 检验。我真的很困惑]]></description>
      <guid>https://stats.stackexchange.com/questions/652530/is-the-chi-squared-test-an-hypothesis-test</guid>
      <pubDate>Fri, 09 Aug 2024 10:45:28 GMT</pubDate>
    </item>
    <item>
      <title>帮助了解 CFA 拟合指数和解释</title>
      <link>https://stats.stackexchange.com/questions/652528/help-with-cfa-fit-indices-and-interpretation</link>
      <description><![CDATA[这是这里的第一篇文章，如果格式不正确，请提前致歉。
为了便于理解，我总共招募了 227 名参与者，并随机将其分成两部分。前半部分用于 EFA，后半部分用于 CFA。我刚刚运行了 CFA，根据之前 EFA 的结果，我对输出结果有点困惑。由于我的样本量相对较小（CFA 的 n = 113）并且 5 点李克特量表（序数）上的数据为非正态数据，因此我使用 DWLS。
具体来说，我担心的是 RMSEA 置信区间。我不知道，这些指数看起来好得令人难以置信……
如能提供任何指导，我们将不胜感激。

JASP 输出

拟合指数-
卡方检验：
X2 = 16.43，df = 34，p = 1.00
CFI = 1.00
TLI = 1.01
RMSEA = 0.00
RMSEA 90% CI 下限 = 0.00
RMSEA 90% CI 上限 = 0.00
RMSEA p 值 = 1.00
SRMR = 0.04

因子载荷
因子 1-
项目 1：0.71
项目 2：0.81
项目 3：0.86
项目 4：0.81
项目 5：0.79
因子 2-
项目 1：0.82
项目 2：0.83
项目 3：0.80
项目 4： 0.76
项目 5：0.77
所有标准误差都是 0.03，这很奇怪吗？
如果有帮助的话，我也可以提供其他输出。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652528/help-with-cfa-fit-indices-and-interpretation</guid>
      <pubDate>Fri, 09 Aug 2024 10:20:56 GMT</pubDate>
    </item>
    <item>
      <title>比较概率估计函数</title>
      <link>https://stats.stackexchange.com/questions/652527/comparing-probabilistic-estimation-functions</link>
      <description><![CDATA[起源
在巧妙计算坦克数量的方法 - Numberphile中，
James Grime 博士介绍了盟军如何用数学方法估算二战期间德国生产的坦克数量。
该视频非常有趣，我建议大家看一下。
第一直觉
存在 N 个对象，编号从 1 到 N。目标是通过抽样一些对象并使用它们的“序列号”来估计对象的总数。此抽样是无放回抽样。
长话短说，估计公式如下：$E_T = max\;observation + average\;gap$。
这里我们使用$ max\;observation $，即样本中的最大序列号，以及$ average\;gap $，即样本中序列号之间的平均间隙（包括与最小可能元素 1 的间隙）。
与此同时，我想知道我们如何将其与钟形曲线联系起来。虽然情况并不完全相同，但它让我想起了两个骰子的总和，产生了这样的曲线。
我知道没有替换会影响结果，但我还是想测试一下。
我的估算公式是：$ E_P = 平均值\;观察值 * 2 $。
这里我使用$ 平均值\;观察值 $，这是样本中的平均序列号。
现在的目标是比较它们并找出哪个是最好的（以及好多少）。
第一次测试
在视频中，对第一个估算公式进行了 2 次测试。样本为：$ S1 = [1, 15, 16, 23, 30] $ 和 $ S2 = [3, 10, 15, 18, 24] $。
使用第一个估算公式，我们得到：$ E_T(S1) = 30 + (0 + 13 + 0 + 6 + 6) / 5 = 30 + 5 = 35 $ 和 $ E_T(S2) = 24 + (1 + 6 + 4 + 2 + 5) / 5 = 24 + 18 / 5 \approx 28 $
使用第二个估算公式，我们得到：$ E_P(S1) = (1 + 15 + 16 + 23 + 30) / 5 * 2 = 85 / 5 * 2 = 17 * 2 = 34 $ 和 $ E_P(S2) = (3 + 10 + 15 + 18 + 24) / 5 * 2 = 70 / 5 * 2 = 14 * 2 = 28 $
这似乎是一个很有希望的估算公式。
更多测试
虽然这似乎比前面两个例子更适合作为估算公式，但这还远远不够（我预计不会胜过一个数学家团队）。
我使用 Python 对两个估算公式的大量 N 和 #S 数组进行了测试（N 范围从 $ 30 $ 到 $ 100&#39;000 $，而 #S 的范围从 $ 0.1 * N $ 到 $ N $）。对于每组参数，我制作了 1&#39;000 个不同的样本并计算了平均误差（以 $ N $ 的百分比表示）。
正如预期的那样，前一个估算公式在几乎所有情况下都优于我的。
您可以在此处找到我的代码并自行调整参数，但以下是一些结果视图（红色是视频中的估算公式，蓝色是我的）。




在每一个公式中，我们都看到第一个公式（几乎）在任何地方都更好。
我们如何证明这个
如果不实际进行测试（/ 针对一般情况），我们如何才能按精度对估算公式进行排序。我们能证明一个比另一个好吗？如果可以，如何证明？
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652527/comparing-probabilistic-estimation-functions</guid>
      <pubDate>Fri, 09 Aug 2024 10:02:26 GMT</pubDate>
    </item>
    <item>
      <title>在模型选择中执行内部 CV 的“元”学习器的性能如何？</title>
      <link>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</link>
      <description><![CDATA[我试图理解证明，即在模型选择期间将 CV 性能报告为性能估计存在乐观偏差。证明步骤如下：

设 $p_i, \pi_i$ 为样本真实表现 $\forall i$（每个 $i$ 对应一个配置，又称学习器，例如 $C=1$ 的 SVM、$C=10$ 的 SVM 等）
$\mathbb{E}[p_i] = \pi_i, \forall i$（无偏估计）
我们返回估计值 $\max(p_1, \ldots, p_n)$
我们平均回报$\mathbb{E}[\max(p_1, \ldots, p_n)]$
真正的最佳表现$\max(\pi_1, \ldots, \pi_n) =
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])$ 为什么？

\begin{align*}
&amp;\mathbb{E}[\max(p_1, \ldots, p_n)]
\geq
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])
\\
&amp;\therefore \text{Overestimation}
\end{align*&gt;
我不明白为什么内部执行 CV 的学习者的真实表现必须是 $\max(\pi_1, \ldots, \pi_n)$。
为了获得这个“元”的表现学习器，我们需要以下内容：

将数据集拆分为训练和测试
在训练中通过 CV 调整超参数
估计测试集中最佳选定模型的性能
对不同的数据集重复 1-3 的所有步骤，并平均步骤 3 的性能（这应该是期望等于“元”学习器的真实性能）

有人能证明为什么这个性能必须等于 $\max(\pi_1, \ldots, \pi_n)$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</guid>
      <pubDate>Fri, 09 Aug 2024 09:20:53 GMT</pubDate>
    </item>
    <item>
      <title>双向方差分析或配对 t 检验</title>
      <link>https://stats.stackexchange.com/questions/652520/two-way-anova-or-paired-t-tests</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652520/two-way-anova-or-paired-t-tests</guid>
      <pubDate>Fri, 09 Aug 2024 06:45:34 GMT</pubDate>
    </item>
    <item>
      <title>高斯混合与高斯（单变量）的 KL 散度的下界</title>
      <link>https://stats.stackexchange.com/questions/652518/lower-bound-of-kl-divergence-of-gaussian-mixture-with-gaussian-univariate</link>
      <description><![CDATA[我对高斯混合$q$和标准高斯$p(x) = \mathcal N(x \mid 0,1)$之间的非零 Kullback-Leibler 散度下限感兴趣，均为单变量：$D_{KL}(q \parallel p)$。我知道​​这个问题，但我推测，如果加上一些约束，问题可能会变得更容易。我的约束：

保证高斯混合具有均值为零
保证高斯混合的方差下限为 $\gamma^2$。

我浏览了 Hershey &amp; Olsen (2007)，其中在第 4 节中提到了一个非常简单的 KL 散度高斯近似，其中 $q$ 由高斯 $\bar q(x) = \mathcal N(x \mid \mu, \sigma^2)$ 近似，（此处，$\mu \triangleq \mathbb E_q[x] = 0, \sigma^2 \triangleq \mathbb E_q[x^2] - \mathbb E_q[x]^2 \ge \gamma^2$）；然后目标 KL 被近似为 $D_{KL}(\bar q \parallel p)$。然而，论文称这是一个糟糕的近似，也没有提到它是否是一个界限。
在 Melbourne et al. (2018) 中，作者提出了混合分布熵的上限。因为$D_{KL}(q \parallel p) = -\mathbb H(q) - \mathbb E_q[\log p(x)]$，我可以利用它，前提是我知道如何确定预期对数密度项的上限，这又超出了我的职权范围。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652518/lower-bound-of-kl-divergence-of-gaussian-mixture-with-gaussian-univariate</guid>
      <pubDate>Fri, 09 Aug 2024 04:59:34 GMT</pubDate>
    </item>
    <item>
      <title>事件研究实施</title>
      <link>https://stats.stackexchange.com/questions/652488/event-study-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652488/event-study-implementation</guid>
      <pubDate>Thu, 08 Aug 2024 11:48:39 GMT</pubDate>
    </item>
    <item>
      <title>选择正确的效应大小 (Cohen's d) 进行功效分析</title>
      <link>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</link>
      <description><![CDATA[根据 Blevins 等人 (2015)，《精神障碍诊断和统计手册》第五版创伤后应激障碍检查表 (PCL-5) 在其两项研究中显示内部一致性 alpha 值 分别为 .94 和 .95。作者表明，该工具的重测信度为 .82（似乎被认为是强的），表明结果随时间推移稳定且一致。作者提到，聚合效度表明，它与创伤后应激障碍 (PTSD) 测量指标具有高度相关性（例如，与 PCL 的 .85、与 PDS 的 .85 和与 DAPS 的 .84），这表明 PCL-5 似乎测量与其他已建立的 PTSD 测量指标相同的结构。作者表示，该工具与相关结构显示出中等相关性（例如，抑郁症 r = .60），与不相关结构显示出较低相关性（例如，躁狂症 r = .31），所有这些似乎都显示出良好的判别效度。
我的目标是在一项研究中使用 PCL-5（Blevins 等人，2015 年），以测量在武装冲突环境中工作的人员样本中的 PTSD 症状水平。
但是，在执行此操作之前，我需要进行功效分析以计算获得可靠结果所需的先验最小样本量。为此，我需要以下内容：

显著性水平 (α = .05)
功效 (1-β = .80)
Cohen&#39;s d (尚不清楚)

我的问题：

根据上述描述，我可以自己决定 d 效果大小吗？
如果可以，值是多少，我该如何证明它（参考文献）？
如果不是，选项和/或替代方案是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</guid>
      <pubDate>Thu, 08 Aug 2024 10:43:46 GMT</pubDate>
    </item>
    <item>
      <title>如何比较 csv 文件中的 2 个字典[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652461/how-to-compare-2-dictionaries-in-a-csv-file</link>
      <description><![CDATA[我正在从事一个涉及分析汽车 CAN 总线跟踪数据的项目。目标是根据 ECU 通信跟踪从票证（公司的票证工具）中聚类出类似的问题。详情如下：
数据：

格式：.blf（二进制日志格式）用于主票，.asc（ASCII）用于从票
大小：大文件，每个约 350MB
内容：时间戳、通道、协议、消息 ID、解码信号等。

当前方法：

解析 .blf 和 .asc 文件
识别主动传输的 ECU 信号
从时间序列数据中提取特征
使用 PCA 降维
使用 K-means 进行聚类

挑战：

有效处理大文件
识别相关信号聚类
处理主从票证之间的不同时间戳
选择适当的特征来聚类 ECU 通信模式

问题：

从 ECU 跟踪中聚类时间序列数据的有效技术是什么？
如何优化大型 .blf 和 .asc 文件的处理？
是否有适合汽车 CAN 总线数据的特定特征提取方法？
在此背景下验证聚类结果的好方法是什么？

任何见解、改进建议或资源都将不胜感激！
技术堆栈：Python、pandas、scikit-learn
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652461/how-to-compare-2-dictionaries-in-a-csv-file</guid>
      <pubDate>Wed, 07 Aug 2024 20:54:23 GMT</pubDate>
    </item>
    </channel>
</rss>