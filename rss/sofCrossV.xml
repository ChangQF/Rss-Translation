<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 06:25:58 GMT</lastBuildDate>
    <item>
      <title>这个肘部图的拐点在哪里？</title>
      <link>https://stats.stackexchange.com/questions/656388/where-is-the-inflection-point-here-in-this-elbow-chart</link>
      <description><![CDATA[您认为该图表上的拐点在哪里？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656388/where-is-the-inflection-point-here-in-this-elbow-chart</guid>
      <pubDate>Sun, 27 Oct 2024 21:48:31 GMT</pubDate>
    </item>
    <item>
      <title>如何根据历史数据设计一个新的指标来评估每月的防损绩效？</title>
      <link>https://stats.stackexchange.com/questions/656386/how-can-i-devise-a-new-metric-to-evaluate-monthly-loss-prevention-performance-ba</link>
      <description><![CDATA[我每个月都会报告公司的损失数字，我希望创建一个指标，可以清楚地表明我们在防止损失方面做得更好还是更差。目标不仅是反映绩效变化的方向（改善或下降），还要反映变化的幅度。
我正在考虑使用三个月移动平均线与当月损失数据之间的差异作为标准化变量来评估这一点。我这样做是因为随着时间的推移，我们的数字在增加，例如销售数字和损失数字。但是，我想知道这是否是一种统计上合理的方法，或者是否有更好的替代方案。
哪些统计方法可以帮助我量化我们随时间推移的绩效改进（或下降）？如果有人对更强大的指标或其他实现此目标的方法有建议，我将不胜感激您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/656386/how-can-i-devise-a-new-metric-to-evaluate-monthly-loss-prevention-performance-ba</guid>
      <pubDate>Sun, 27 Oct 2024 19:43:14 GMT</pubDate>
    </item>
    <item>
      <title>在拉普拉斯近似中近似 Hessian</title>
      <link>https://stats.stackexchange.com/questions/656384/approximating-the-hessian-in-laplaces-approximation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656384/approximating-the-hessian-in-laplaces-approximation</guid>
      <pubDate>Sun, 27 Oct 2024 18:15:17 GMT</pubDate>
    </item>
    <item>
      <title>将对数应用于指数和线性拟合</title>
      <link>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</link>
      <description><![CDATA[从指数开始，我进行拟合（非线性拟合）以估计参数。在第二步中，我应用对数以便执行线性拟合。我想知道为什么估计的参数不同。
# 清除环境
rm(list=ls())
# 加载所需的库
library(ggplot2)

# 生成 x 值、y 值和 y 上的相应误差
x_values_exp &lt;- c(0.1, 0.2, 0.5, 1, 2, 3, 4) 
y_values_exp &lt;- c(9, 8.5, 7.5, 6.4, 5.2, 4.7, 4.5)
y_values_exp_error &lt;- rep(0.58, length(x_values_exp))
# 创建数据框
my_data &lt;- data.frame(x = x_values_exp, y = y_values_exp , y_error = y_values_exp_error)

在这里我知道错误 (y_values_exp_error)，然后我可以使用或不使用权重进行拟合。
# 使用已知权重拟合非线性模型 (exp)
nlMMERROR_known_weigths &lt;- nls(y ~ A * exp(B * x), data = my_data, start = list(A = 1, B = 1), weights = 1/(y_values_exp_error^2))
# 使用未知权重拟合非线性模型 (exp)
nlMMERROR_unknown_weigths &lt;- nls(y ~ A * exp(B * x), data = my_data, start = list(A = 1, B = 1))

对于第二次拟合，我可以估计错误使用：
# 估计 nlMMERROR_unknown_weigths 上的误差（因为我有 2 个参数，所以是 2）
残差 &lt;- residuals(nlMMERROR_unknown_weigths)
y_error_estimated &lt;- sqrt(sum(residuals^2)/(length(residuals)-2))
y_error_estimated

结果为：
&gt; y_error_estimated
[1] 0.5640254

此值非常接近预期值 (0.58)。
现在，让我们应用 log：
y_lin &lt;- log(y_values_exp)
# 我必须计算 y 上的相应误差（使用误差传播）
y_values_exp_known_error &lt;- y_values_exp_error/y_values_exp
y_values_exp_estimated_error &lt;-y_error_estimated / y_values_exp
my_data_lin &lt;- data.frame(x = x_values_exp, y = y_lin, y_values_exp_known_error = y_values_exp_known_error, y_values_exp_estimated_error = y_values_exp_estimated_error)

并拟合：
# 拟合线性模型（使用转换后的数据并考虑已知误差）
nlMMERROR_lin_weigths_known &lt;- nls(y ~ A + B * x, data = my_data_lin, start = list(A = 1, B = 1), weights = 1/(y_values_exp_known_error^2))
# 拟合线性模型（使用转换后的数据并考虑估计误差）
nlMMERROR_lin_weigths_estimated &lt;- nls(y ~ A + B * x, data = my_data_lin, start = list(A = 1, B = 1), weights = 1/(y_values_exp_estimated_error^2))


# print A (线性)
A_values &lt;- c(
&quot;A (线性化已知权重)&quot; = coef(nlMMERROR_lin_weigths_known)[1],
&quot;A (线性化估计权重)&quot; = coef(nlMMERROR_lin_weigths_estimated)[1]
)

print(A_values)

# 这是已知权重的 nls 拟合
print(log(coef(nlMMERROR_known_weigths)[1]))
# 这是未知权重的 nls 拟合
print(log(coef(nlMMERROR_unknown_weigths)[1]))

结果为：
&gt; print(A_values)
A (线性化已知权重).A A (线性化估计权重).A 
2.154402 2.154402 
&gt; 
&gt; # 这是已知权重的 nls 拟合
&gt; print(log(coef(nlMMERROR_known_weigths)[1]))
A 
2.151668 
&gt; # 这是具有未知权重的 nls 拟合
&gt; print(log(coef(nlMMERROR_unknown_weigths)[1]))
A 
2.151668 

然后我想知道为什么我得到不同的 A 值（2.151668 与 2.154402）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</guid>
      <pubDate>Sun, 27 Oct 2024 11:52:18 GMT</pubDate>
    </item>
    <item>
      <title>小样本观察结果的重要性</title>
      <link>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</link>
      <description><![CDATA[在 10000 人的群体中，我测试了 30 个人，发现他们全都患有一种疾病。基于这个样本量，我能否进行一些统计测试，以找出在 30 个受试个体都患有这种疾病的情况下，人口中可能患有这种疾病的比例是多少？
我正在进行类似 Cochrane 测试的测试，以找到给定重要性的样本量，但我无法找到上述问题的确切解决方案]]></description>
      <guid>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</guid>
      <pubDate>Sun, 27 Oct 2024 11:06:11 GMT</pubDate>
    </item>
    <item>
      <title>变分推理描述的难解性问题中的混淆[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</link>
      <description><![CDATA[（已在 reddit 上发布）
我阅读 VAE 论文 已经有一段时间了，并且查阅了各种资料，以便对指定的难解性问题有清晰的了解。然而，在试图理解它时，我仍然面临很多困惑。我会解释，但这里只是一些符号，以确保我们的观点一致：

z - 维度为 M 的潜在变量
Z - 表示潜在变量集 z 的随机变量
x - 输入变量（比如说图像）
X - 输入图像数据集

目标是了解潜在空间 Z 的分布，以便从该空间采样时，可以使用某个函数 f(z)（神经网络）生成新的数据点 x&#39;，该函数也属于 P(X) 的输入分布。因此，问题建模如下：

P(Z|X) = P(Z) * P(X|Z) / P(X)

然后，作者声称 P(Z|X) 是难解的，因为 P(X) 是难解的。从高层次上讲，我想了解整体公式的难解性方面：

为什么 P(Z) 在这里不可解？事实上，P(Z) 甚至都不知道，那么为什么它不被认为是难解的？
我假设，P(X|Z) 可以通过应用 f(Z) 来计算，因此如果 P(Z) 是可解的，那么 P(X|Z) 也可以被认为是可解的。这个假设正确吗？
为什么 P(X) 是难解的？假设 X 类似于输入数据集，该数据集具有足够的样本，大致代表实际分布（假设数据集是 0 到 9 的数字的二进制图像，每个数字有 100 个样本），为什么不能简单地将 P(X) 视为每个单独像素的二项分布？
此外，为什么 P(X) 在这里甚至值得关注？就像它不是一个可以假设为整个 P(Z|X) 常数的标准化因子吗？

我相信我之所以有这些疑问，是因为我无法非常清楚地理解基本问题或基本目标，并且以不同的方式理解问题，如果由于我缺乏理解而导致问题没有意义，我真的很抱歉。
此外，如果有人可以通过举例而不是仅仅使用抽象符号来增加清晰度来解释这一点，那将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</guid>
      <pubDate>Sun, 27 Oct 2024 06:04:08 GMT</pubDate>
    </item>
    <item>
      <title>在 SEM 中，如果模型一开始就显示出较差的拟合度，那么解释路径系数还有什么意义吗？</title>
      <link>https://stats.stackexchange.com/questions/656366/in-sem-is-there-any-point-in-interpreting-path-coefficients-if-the-model-shows</link>
      <description><![CDATA[如果有些路径系数很重要，但整个模型拟合度较差，我还能使用重要路径的结果吗？
进一步说，如果模型在结构方程模型 (SEM) 中拟合度较差，使用 Hayes 的 PROCESS 宏来分析数据是否合适，因为它不提供像 SEM 那样的拟合指数？]]></description>
      <guid>https://stats.stackexchange.com/questions/656366/in-sem-is-there-any-point-in-interpreting-path-coefficients-if-the-model-shows</guid>
      <pubDate>Sun, 27 Oct 2024 04:57:43 GMT</pubDate>
    </item>
    <item>
      <title>关于有向图模型定义中“循环性”的澄清</title>
      <link>https://stats.stackexchange.com/questions/656361/clarification-on-circularity-in-definition-of-a-directed-graphical-model</link>
      <description><![CDATA[我正在研究有向图模型 (DGM) 的定义，我们首先将 DGM 定义为：
设 $G = (V, E)$ 为有向无环图 (DAG)，其中 $V = \{1, \dots, n\}$。有向图模型 (DGM)，也称为贝叶斯网络，是 $X_V$ 上的一类分布，定义如下：
$$
L(G) \triangleq \{ p \text{ 是 } X_V 上的分布： \exists \text{ 合法因子 } f_i \text{&#39;s}
$$
$$
\text{s.t. } p(x_V) = \prod_{i=1}^n f_i(x_i | x_{\pi_i}) \, \forall x_V \} 
$$
然后使用叶子采摘属性，我们证明上面的定义等同于下面的定义：

图 $G$ 上的 DGM 是根据 $G$ 分解的分布集 $p(x)$，表示为 $p(x) \in $ $L(G)$，如果：
$$p(x) = \prod_{i=1}^n p(x_i | x_{\pi_i})$$
其中 $x_{\pi_i}$ 表示图 $G$ 中 $x_i$ 的父节点。

换句话说，我们表明第一个定义中的因子必须是从联合定义的条件概率。但为什么要经历所有这些麻烦，为什么我们不直接从第二个定义开始呢？根据我的课堂笔记，

原因是，如果没有证明 [使用 DGM 的叶子拔除属性]，我们就不知道我们的定义是否有意义，因为这个定义是循环的。确实，条件 $p(x_i | x_{\pi_i})$ 是从联合 $p(x)$ 定义的。因此，我们通常不允许通过乘以条件来定义联合（因为您可能无法获得满足此属性的分布）。

但是，我很难看出这里的循环性。据我所知，如果我们从已知的联合分布中获得条件 $p(x_i | x_{\pi_i})$，但这些条件的乘积与联合分布不匹配，那么它只会意味着该联合分布不是此 DGM 的成员（即，它不满足图 $G$ 指定的因式分解）。我认为我们只是将这种分解用作标准来识别$L(G)$中的有效分布，而不是将其用作联合分布的构造方法。
有人可以解释为什么这个定义被认为是循环的以及这种担忧是否有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656361/clarification-on-circularity-in-definition-of-a-directed-graphical-model</guid>
      <pubDate>Sun, 27 Oct 2024 00:26:48 GMT</pubDate>
    </item>
    <item>
      <title>条件分布的可视化</title>
      <link>https://stats.stackexchange.com/questions/656358/visualisation-of-a-conditional-distribution</link>
      <description><![CDATA[由于在多重插补的背景下阅读了一些关于 JM 与 FCS 的资料，我试图更好地理解 MVN。有人可以告诉我如何可视化条件分布吗？我了解理论和属性。但如果我以维基百科中的 2D MVN 图像为例

边际密度 f(X) 和 f(Y) 对应于蓝色和红色的单变量正态分布，联合密度 f(X,Y) 对应于 2D 平面中点的分布。但是，如何开发 f(X|Y) 或 f(Y|X) 的直觉/视觉图像？]]></description>
      <guid>https://stats.stackexchange.com/questions/656358/visualisation-of-a-conditional-distribution</guid>
      <pubDate>Sat, 26 Oct 2024 22:34:35 GMT</pubDate>
    </item>
    <item>
      <title>样本相关矩阵与其真实值的偏差</title>
      <link>https://stats.stackexchange.com/questions/656344/the-deviation-of-the-sample-correlation-matrix-from-its-true-value</link>
      <description><![CDATA[在HDP 书中，我发现了协方差矩阵的集中不等式
$$
\mathbb{P}\left(\|\Sigma_n-\Sigma\|_2\le C_K\sqrt{\frac{p}{n}}\right)\ge1-2\exp\left(-p\right)
$$
其中$\|\cdot\|_2$表示谱范数。
现在，我对相关系数矩阵的集中不等式感兴趣：边界$\|\Gamma_n-\Gamma\|_2$ 的概率很大，其中 $\Gamma=D^{-\frac{1}{2}}\Sigma D^{-\frac{1}{2}}$ 和 $D=\operatorname {diag}\left(\Sigma\right)$。那么我可以阅读哪些论文？目前最好的结果是什么？相关矩阵的结果可以直接从协方差矩阵的结果中获得吗？

什么统计问题需要相关矩阵的浓度不等式，特别是谱范数形式的浓度不等式。我猜这是一个研究得很好的问题，但我不知道如何找到它。
更新
我的尝试：
在本文第 42 页 (THM II.13) 中提供了一个有用的定理。

给定 $m,n\in \mathbb{N}$ 和 $m\le n$，将 $\beta=m/n$ 置于 $n\times m$ 随机矩阵 $\Gamma$ 其条目是遵循 $\mathcal{N}\left(0,1/n\right)$ 定律的实数、独立高斯随机变量。令奇异值为 $s_1\left(\Gamma\right)\ge\cdots\ge s_1\left(\Gamma\right)$。然后对于任何 $t &gt;0$，
$$
\max\left\{\mathcal{P}\left(s_1\left(\Gamma\right)\ge 1+\sqrt{\beta}+t\right),\mathcal{P}\left(s_m\left(\Gamma\right)\le 1-\sqrt{\beta}-t\right)\right\}\le \exp\left(-nt^2/2\right)
$$

我想知道
${\Gamma}_n$ 是否可以分解为 ${\Gamma}_n=XX^{\top}$ 其中 $X$ 表示一个 $p\times n$ 矩阵，其中高斯元素的均值为零，方差为 $\frac{1}{n}$。如果此分解正确，则可直接使用上述定理。]]></description>
      <guid>https://stats.stackexchange.com/questions/656344/the-deviation-of-the-sample-correlation-matrix-from-its-true-value</guid>
      <pubDate>Sat, 26 Oct 2024 14:00:54 GMT</pubDate>
    </item>
    <item>
      <title>零通胀：OLS 与泊松</title>
      <link>https://stats.stackexchange.com/questions/656279/zero-inflation-ols-vs-poisson</link>
      <description><![CDATA[我正在处理一个数据集，结果变量中有许多零（从 50% 到 95% 的零）。我正在使用 glmmTMB 包来运行零膨胀泊松模型。一半的时间，这些模型无法收敛并产生大量带有估计值的 NA。我注意到，运行没有零膨胀组件的泊松模型会产生更少的错误消息。
我知道零膨胀估计是由于这些收敛困难而失效的。我需要从概念上证明使用标准泊松而不是 OLS 的合理性。泊松是否比 OLS 更适合处理大量零？您能给我指出任何相关文献吗？
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/656279/zero-inflation-ols-vs-poisson</guid>
      <pubDate>Thu, 24 Oct 2024 20:09:51 GMT</pubDate>
    </item>
    <item>
      <title>样本来自时间序列时两样本均值差异检验</title>
      <link>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</link>
      <description><![CDATA[我有两组观察值，A 组和 B 组。我可以使用 t 检验来检验 B 组的平均值大于 A 组的假设。但这里的固有假设是两组中的样本是独立的。如果样本来自两个时间序列，情况会怎样？那么，它们是相关的，它们独立的假设不再有效。是否可以修改测试以解释自相关？如果可以以某种方式估计相关系数，则可以调整两个样本 t 检验中使用的方差。我找不到任何好的参考资料。有一些标准测试可以查看其中一个序列是否预测另一个序列，但我找不到任何比较均值或其他汇总统计数据的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 20:17:18 GMT</pubDate>
    </item>
    <item>
      <title>如何根据检验结果计算假设的后验概率？</title>
      <link>https://stats.stackexchange.com/questions/656193/how-do-i-calculate-the-posterior-probability-of-a-hypothesis-given-the-result-of</link>
      <description><![CDATA[我理解，p 值是在零假设成立的情况下获得数据（或更多极值）的概率。然而，研究人员真正想知道的是，在给定数据的情况下，零假设成立的概率。因此，需要基于对零假设的基本概率的估计和对“获得数据的总概率”之类的权重来计算反向概率。
我可以使用贝叶斯推理，结合测试的敏感度、基准率和阳性总数：
$$\mathbb{P}(\text{sick}|\text{positive}) = \frac{\mathbb{P}(\text{positive}|\text{sick}) \cdot \mathbb{P}(\text{sick})}{\mathbb{P}(\text{positive})}。$$
例如，如果一种疾病影响 100 人中的 1 人，测试的敏感度为 99%，我随机测试 100 人，我会得到两个阳性结果（一个真，一个假），以及一个逆概率：
$$\mathbb{P}(\text{sick}|\text{positive}) \approx \frac{0.99 \cdot 0.01}{0.02} \approx 0.5.$$
现在，我的问题是，如何使用贝叶斯推理来计算 p 值的逆概率？例如，我对 $H_0$ 没有任何先验知识，因此假设 $\mathbb{P}(H_0) = 0.5$，我得到了一个显著性检验（例如，显著性水平为 0.01）。我想知道在这种情况下如何找到假设的后验概率：
$$\mathbb{P}(H_0|\text{test}) 
= \frac{\mathbb{P}(\text{test}|H_0) \cdot \mathbb{P}(H_0)}{\mathbb{P}(\text{of what?})} 
= \frac{0.01 \cdot 0.5}{\text{?}}.$$]]></description>
      <guid>https://stats.stackexchange.com/questions/656193/how-do-i-calculate-the-posterior-probability-of-a-hypothesis-given-the-result-of</guid>
      <pubDate>Wed, 23 Oct 2024 12:13:59 GMT</pubDate>
    </item>
    <item>
      <title>在 10 个样本中，从 21 个列表中选择少于 4 个唯一数字的概率（有放回）</title>
      <link>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</link>
      <description><![CDATA[我有 21 个数字的列表，编号为 0 到 20（或 1 到 21，无所谓）。我随机挑选 10 次，每次都使该选择可用于下一次选择。这 10 次选择中唯一数字少于 4 个的概率是多少？
我用一个我认为正确的公式来解决组合问题，但是当我在电子表格上模拟该过程时，我得到了一个非常不同的结果：请问​​正确的公式是什么？以下是我对如何获得公式和模拟结果的解释。
选择少于 4 个唯一数字的概率是始终选择相同数字的概率 + 选择 2 个不同数字的概率 + 选择 3 个不同数字的概率。
$$P(&lt;4) = P(1) + P(2) +P(3)$$
我第一次从 10 个数字中挑选出 1 个唯一数字。第二次挑选时，我可以选择相同的数字，概率为 $\frac1{21}$，也可以选择不同的数字，概率为 $\frac{20}{21}$。在第一次选择之后的 9 次选择中始终选择相同数字的概率为
$$P(1) = \left(\frac1{21}\right)^9$$
在第二次选择之后，我选择了一个与第一次不同的数字，然后我还有第三次选择，我可以选择前 2 个数字中的一个，概率为 $\frac2{21}$，或者选择第三个不同的数字，概率为 $\frac{19}{21}$。在前 2 个数字之后，我在剩余的 8 次选择中继续选择相同的 2 个数字的概率为
$(\frac{2}{21})^8$，因此
$$P(2) = \frac{20}{21}\left(\frac{2}{21}\right)^8$$
继续同样的思路，在第 4 次选择时，我可以选择之前选择的 3 个数字之一，概率为 $\frac3{21}$，或者选择第 4 个不同的数字，概率为 $\frac{18}{21}$。在前 3 个数字之后，我在剩余的 7 次选择中继续选择相同的 3 个数字的概率为
$(\frac{3}{21})^7$，因此
$$P(3) = \frac{20}{21}\frac{19}{21}\left(\frac3{21}\right)^7$$
将三项相加
$$P(&lt;4) = \left(\frac1{21}\right)^9 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^8 + \frac{19}{21}\left(\frac3{21}\right)^7\right] = $$
这给了我大约 $P(&lt;4) = 0.00011\%$
当我尝试通过在 Google 表格中模拟该过程来验证结果时，我无法模拟足够的试验进行计算；上面的概率意味着大约 909,000 次试验的平均值是 1，但我发现 Google 表格允许我模拟大约 47,500 次试验。因此，我将问题从 10 次选择缩减为 8 次选择，通过归纳法获得
$$P(&lt;4) = \left(\frac1{21}\right)^7 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^6 + \frac{19}{21}\left(\frac3{21}\right)^5\right] = 0.0052\%$$
但是当我模拟它时，我得到 $P(&lt;4) = 0.016\%$
我用来模拟上述结果的 Google Sheets 公式是
=countif( byrow( map(RANDarray(55000, 8), lambda(x, int(x*21))), lambda(trial,COUNTUNIQUE(trial)) ), &quot;&lt;4&quot;) / 55000
]]></description>
      <guid>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</guid>
      <pubDate>Tue, 08 Oct 2024 18:49:31 GMT</pubDate>
    </item>
    <item>
      <title>如何从 family=binomial 的 glm 模型中计算 lsmeans？</title>
      <link>https://stats.stackexchange.com/questions/606203/how-to-calculate-lsmeans-from-a-glm-model-with-family-binomial</link>
      <description><![CDATA[我想从 family = binomial 的 glm 模型计算调整后的均值。
这是我的脚本：
data$Phenotype&lt;- as.factor(data$Phenotype)
data$Batch&lt;- as.factor(data$Batch)
data$Tray&lt;- as.factor(data$Tray)
data$Genotype&lt;- as.factor(data$Genotype)
model = glm((Phenotype)~ Batch + Tray + Genotype, data=data, family = binomial())

leastsquare = lsmeans(model,&quot;Genotype&quot;, rg.limit = 200000)
leastsquare = lsmeans(model,~Genotype, rg.limit = 200000)
leastsquare = emmeans(model,&quot;Genotype&quot;, rg.limit = 200000)
leastsquare = emmeans(model,~Genotype, rg.limit = 200000)
leastsquare 

无论哪一行，它都不会计算 lsmeans...我得到这个：
Genotype lsmean SE df asymp.LCL asymp.UCL
LM1_1_1 nonEst NA NA NA NA
LM1_1_2 nonEst NA NA NA NA
LM1_1_3 nonEst NA NA NA NA
LM1_2_1 nonEst NA NA NA NA
LM1_2_2 nonEst NA NA NA NA
LM1_2_3 nonEst NA NA NA NA
LM1_2_4 nonEst NA NA NA NA

结果在以下级别上取平均值：托盘、批次

结果以 logit（而非响应）量表给出。

使用的置信度：0.95


你能帮我吗？有人知道如何从 glm 模型计算 lsmeans 吗？
我希望获得我的表型的调整平均值，并根据定位效应进行校正，这要归功于具有二项分布的 glm 模型。
谢谢，
LM]]></description>
      <guid>https://stats.stackexchange.com/questions/606203/how-to-calculate-lsmeans-from-a-glm-model-with-family-binomial</guid>
      <pubDate>Wed, 22 Feb 2023 06:40:21 GMT</pubDate>
    </item>
    </channel>
</rss>