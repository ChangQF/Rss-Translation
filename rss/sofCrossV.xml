<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 05 Apr 2024 15:14:32 GMT</lastBuildDate>
    <item>
      <title>从部分依赖性导出弹性</title>
      <link>https://stats.stackexchange.com/questions/644395/derive-elasticities-from-partial-dependences</link>
      <description><![CDATA[我正在根据随机森林 (RF) 二元分类模型生成部分依赖图，该模型产生预测的观察概率 $i$ 属于 A 类结果变量 Z。根据我的理解，所讨论的部分依赖图提供了变量 Z 的 A 类在两个特征（X 和 Y 变量）的值的条件下发生的概率（通过颜色显示），同时假设所有其他功能保持不变：

我的问题是我是否可以推导出局部偏弹性（Z 属于 A 类的概率的 % 变化到 $X$ 的 1% 变化）基于如图所示的点阵为：
$\epsilon^{X}_{ij} = \frac{\frac{PD_{i,j}}{PD{i-1, j}} - 1 }{\frac{X_{i}}{X{i-1}} - 1} $
其中 $PD$ 是 Z 在 $i,j$ 坐标处的部分依赖值X 和 Y。
或者有一些数学原因导致这个推理不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/644395/derive-elasticities-from-partial-dependences</guid>
      <pubDate>Fri, 05 Apr 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对与会者缺席率进行建模</title>
      <link>https://stats.stackexchange.com/questions/644394/modeling-no-show-rates-of-attendees-in-r</link>
      <description><![CDATA[我正在尝试确定（过去）活动的注册候选人缺席率在多大程度上取决于活动举办的工作日。
鉴于过去在工作日（周一至周五）发生的许多事件，我有一个结构如下的矩阵：

5 列：星期一、...、星期五
一行中的每个条目代表该工作日过去发生的活动的缺席率

举个例子：
&lt;前&gt;&lt;代码&gt;#数据
df1 &lt;- data.frame(星期一 = runif(10,0,0.2),
                  星期二 = runif(10,0.2,0.4),
                  星期三= runif(10,0.4,0.6),
                  星期四 = runif(10,0.6,0.8),
                  星期五 = runif(10,0.8,1))

根据这些信息，我一直在尝试了解 R 中的哪些函数可以让我：

了解活动举办日对缺席率的统计显着影响程度
如果有显着影响，我如何根据工作日预测未来活动的缺席率

到目前为止，我一直在尝试使用 R 中的 glm 等函数进行对数回归，但收效甚微，因为我的输入不是 0 或 1，而是介于两者之间的 %。
有什么建议吗？这是否是正确的方法，或者我还可以尝试什么？
非常感谢您的支持！]]></description>
      <guid>https://stats.stackexchange.com/questions/644394/modeling-no-show-rates-of-attendees-in-r</guid>
      <pubDate>Fri, 05 Apr 2024 12:36:16 GMT</pubDate>
    </item>
    <item>
      <title>如何比较不同长度时间序列得到的AR(1)模型系数？</title>
      <link>https://stats.stackexchange.com/questions/644393/how-compare-ar1-models-coefficients-obtained-from-time-series-with-different</link>
      <description><![CDATA[假设我有两个时间序列，$\{X\}_{t}$ 和 $\{Y \}_{t}$ 长度显着不同，$n$ 和 $m$ 分别观察 ($n&gt;m$)。我想估计以下 AR(1) 模型：
$$X_{t}=\alpha_0+\alpha_1X_{t-1}+\epsilon_t,$$
$$Y_{t}=\beta_0+\beta_1X_{t-1}+\eta_t.$$
接下来，我需要比较 $\hat{\alpha_1}$ 和 $\hat{\beta_1 }$ 系数。然而，这并不“公平”。直接和明确地比较估计参数，因为观察数量显着不同（并且这种类型的时间序列可以显示相当大的峰值，并且短时间序列无法反映相对于较长时间序列的这种峰值 - 较长的历史意味着更高的机会时间序列中存在大峰值）。
问题有没有办法制作 $\hat{\alpha_1}$ 和 通过控制观察之间的差异，$\hat{\beta_1}$ 更具可比性？我突然想到要比较 $\frac{\hat{\alpha_1}}{n}$ 和 $\frac{\hat{\beta_1}}{m}$，但不确定这是否有意义。此外， $\hat{\alpha_1}$ 和 $\hat{\beta_1}$ 的大小为不重要。唯一重要的是哪个系数更大。这意味着转换系数是完全合法的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644393/how-compare-ar1-models-coefficients-obtained-from-time-series-with-different</guid>
      <pubDate>Fri, 05 Apr 2024 12:28:00 GMT</pubDate>
    </item>
    <item>
      <title>仿制 R 包删除基于 LASSO 的所有变量，为什么？</title>
      <link>https://stats.stackexchange.com/questions/644392/knockoff-r-package-removing-all-variables-based-on-lasso-why</link>
      <description><![CDATA[我正在模拟线性回归模型的数据集，并使用 LASSO (glmnet) 选择变量。该选择在 lambda.1se 和 lambda.min 中效果相对较好，但与 LASSO 一样，它包含一些误报。结果在下面的 R 代码中重现。
库（仿冒品）
图书馆（glmnet）

# 模拟数据
设置.种子(2024)
p &lt;- 100 # 特征数量
n &lt;- 80 # 样本数
k &lt;- 15 # 真正相关特征的数量

# 生成一些相关特征的数据
mu &lt;-rep(0, p)
西格玛 &lt;- diag(p)
X &lt;- 矩阵(rnorm(n * p), n)
非零 &lt;- 样本(p, k)
beta &lt;- 3.5 * (1:p %in% 非零)
y &lt;- X %*% beta + rnorm(n)
其中（β&gt;0）


# 定义响应变量（假设它存储在“y”中）
模型 &lt;- cv.glmnet(X, y, alpha = 1)

# 使用以下方法探索模型系数和其他属性：
coef(模型, s = &#39;lambda.min&#39;)
coef(模型, s = &#39;lambda.1se&#39;)

cbind(beta, coef(模型, s = &#39;lambda.min&#39;)[-1])
cbind(beta, coef(模型, s = &#39;lambda.1se&#39;)[-1])

所以，我想到创建一个仿冒矩阵（https://web.stanford. edu/group/candes/knockoffs/）来检查这是否会减少误报（FDR），但最终会删除所有变量！请参阅下面的代码。任何提示将不胜感激。
# 运行仿冒过滤器
结果 &lt;- knockoff.filter(X, y)

# 仿冒矩阵存储在 result$Xk 中
# 运行knockoff.filter后（来自前面的示例）
knockoff_matrix &lt;- 结果$Xk

# 定义响应变量（假设它存储在“y”中）
modelk &lt;- cv.glmnet(knockoff_matrix, y, alpha = 1)

# 使用以下方法探索模型系数和其他属性：
coef(modelk, s = &#39;lambda.min&#39;)
coef(modelk, s = &#39;lambda.1se&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644392/knockoff-r-package-removing-all-variables-based-on-lasso-why</guid>
      <pubDate>Fri, 05 Apr 2024 12:21:44 GMT</pubDate>
    </item>
    <item>
      <title>类内相关性是基于项目还是基于尺度？</title>
      <link>https://stats.stackexchange.com/questions/644390/intraclass-correlation-item-or-scale-based</link>
      <description><![CDATA[我有嵌套数据（学校班级），因此想知道我是否需要在以下分析中控制多层结构。因此我想计算类内相关性。对各个项目进行计算是否有意义，还是使用量表的总分更好？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644390/intraclass-correlation-item-or-scale-based</guid>
      <pubDate>Fri, 05 Apr 2024 11:30:07 GMT</pubDate>
    </item>
    <item>
      <title>VECM 的脉冲响应</title>
      <link>https://stats.stackexchange.com/questions/644388/impulse-response-for-a-vecm</link>
      <description><![CDATA[我使用MatLAB来计算广义脉冲响应函数（参见https://se.mathworks.com/help/econ/vecm.irf.html#mw_ef2bb791-5500-4738-b2de-49df99f3a990_sep_shared-mw_85c3ba 24-ff12 -4a90-b585-838dc341359a)
但是，每当我计算 irfs 时，引导的confidensintervals（2000 次代表）就会出现偏差。
有谁知道为什么会这样吗？
提前致谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/644388/impulse-response-for-a-vecm</guid>
      <pubDate>Fri, 05 Apr 2024 10:41:37 GMT</pubDate>
    </item>
    <item>
      <title>字母 T 的二进制掩码的最大方差方向是什么？</title>
      <link>https://stats.stackexchange.com/questions/644387/what-is-the-maximum-variance-direction-of-a-binary-mask-of-the-letter-t</link>
      <description><![CDATA[我正在对二元掩模执行 PCA 分析，目的是确定形状的长轴。我试图了解此过程中生成的第一个特征向量是否有意义。第一个特征向量应该指向 T 的顶部吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644387/what-is-the-maximum-variance-direction-of-a-binary-mask-of-the-letter-t</guid>
      <pubDate>Fri, 05 Apr 2024 10:10:02 GMT</pubDate>
    </item>
    <item>
      <title>综合变量的平均分</title>
      <link>https://stats.stackexchange.com/questions/644374/mean-score-of-the-composite-variable</link>
      <description><![CDATA[我有三个项目（李克特量表从 5 到 1）来衡量机会识别。我得到了负的 cronbachs alpha 值。因此，我进行反向编码并得到 Cronbach&#39;s alpha 为 0.83。
我将使用这些项目的平均分作为复合变量来衡量机会识别。复合变量将成为回归分析中的因变量。那么，要计算平均分，我应该使用未反转的数据还是反转的数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/644374/mean-score-of-the-composite-variable</guid>
      <pubDate>Fri, 05 Apr 2024 06:30:59 GMT</pubDate>
    </item>
    <item>
      <title>优惠券收集器内的优惠券收集器</title>
      <link>https://stats.stackexchange.com/questions/644353/coupon-collector-inside-the-coupon-collector</link>
      <description><![CDATA[考虑优惠券收集问题，其中必须收集 $n$ 优惠券，并且每天随机出现一张优惠券。
众所周知，收集所有优惠券平均需要 $n H_n$ 天，其中 $ H_n$是n次谐波数。我的问题如下：
假设我删除所有只出现一次的优惠券 - 调用这些单例优惠券。已知平均有 $H_n$ 个。删除这些单例优惠券后，我看一下以所需的最短顺序收集所有非单例优惠券需要多长时间。这个数字是多少？
为了让事情更清楚，如果优惠券是$[1,2,\ldots,10]$，则一个序列可以是
&lt;前&gt;&lt;代码&gt; 3 9 4 10 9 9 7 6 7 2 10 7 10 9 8 3 5 9 9 3 8 1

在这种情况下，单例是
&lt;前&gt;&lt;代码&gt; 1 2 4 5 6

收集所有其他优惠券的最短（子）序列是
&lt;前&gt;&lt;代码&gt; 3 9 10 9 9 7 7 10 7 10 9 8

长度为 12，这是我们感兴趣的。
这是第二个例子。考虑优惠券是从 1 到 9 的整数。序列可以是
&lt;前&gt;&lt;代码&gt; 3 1 3 1 1 6 8 7 3 1 4 7 9 2 6 2 3 8 3 4 5

单例是
&lt;前&gt;&lt;代码&gt; 5 9

最短子序列是
&lt;前&gt;&lt;代码&gt; 3 1 3 1 1 6 8 7 3 1 4 7 2

其长度、大小或元素数量为 13（从 21 减少）。
这是第三个例子，优惠券是从 1 到 5 的整数
&lt;前&gt;&lt;代码&gt; 3 1 4 1 5 4 4 5 2

单例集合是
&lt;前&gt;&lt;代码&gt; 2 3

没有单例的子序列是
&lt;前&gt;&lt;代码&gt; 1 4 1 5

其长度为4。
子序列的平均长度是多少？
对于 $n=100$，使用模拟，该子序列的长度为 376，而对于 $n=200 $ 是 898。有没有办法使用已知的结果推导一个简单的公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/644353/coupon-collector-inside-the-coupon-collector</guid>
      <pubDate>Thu, 04 Apr 2024 22:00:51 GMT</pubDate>
    </item>
    <item>
      <title>不同样本量的 2 比例测试中的连续性校正</title>
      <link>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</link>
      <description><![CDATA[在 2 个比例的检验中（二项式 -&gt; 正态），当样本大小不同时，连续性校正是什么样的？
通常，在 1 个样本测试中，我们将除以 $n$（样本大小）$\frac {1}{2}$ 术语。但是，对于不同的样本量，我们该怎么办？
为了了解更多背景信息，我们假设我们有一个来自离散分布 $F_{X}$ 的样本，其中 $ E(X)=\mu$ 和 $Var(X) = \sigma^2$，我们将通过 $\frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}}\sim^a N(0,1)$。
我正在读的一本书指出，在这种情况下，我们应该使用以下连续性校正：
$P(\sum X_i \leq c) = P(\sum X_i \leq c+1/2) = P\left(\frac{\bar X - \mu}{ \frac{\sigma}{\sqrt{n}}} \leq \frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{n}}}\right) $
最后一个表达式可以近似为 $\Phi\left(\frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{ n}}}\右）$
无论$X$遵循泊松分布还是伯努利分布，都可以应用此方法...
我的问题涉及这种技术如何推广到 2 个离散总体的情况，$X_1 \sim F_1, X_2\sim F_2$ （目前都是伯努利） ...我将搜索看看它对于其他类型的分布（例如泊松分布）是否有意义）
$\frac{\bar X_1 - \bar X_2 - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2 }{n_1}+ \ frac{\sigma_2^2}{n_2}}}\sim^a N(0,1)$
与$n_1\neq n_2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</guid>
      <pubDate>Thu, 04 Apr 2024 21:11:25 GMT</pubDate>
    </item>
    <item>
      <title>Pitman-Koopman-Darmois 定理对于离散随机变量有效吗？</title>
      <link>https://stats.stackexchange.com/questions/644313/is-pitman-koopman-darmois-theorem-valid-for-discrete-random-variables</link>
      <description><![CDATA[我对 Pitman-Koopman-Darmois 定理感兴趣。
我很难找到这个定理的简单严格版本，因为我很难找到来源。
这篇有用的帖子 为定理提供了三个来源：

Pitman 的一篇：皮特曼，E.J.G. (1936) 足够的统计数据和内在准确性，《剑桥哲学会报》，32, 567-579。
Koopman 的一篇：库普曼，B.O. (1936) 关于承认足够统计量的分布，美国数学会汇刊，卷。 39、第3号。
Darmois 的一篇：Darmois, G. (1935) Sur les lois de probabilité à 详尽的估计，Comptes Rendus de l&#39;Académie des Sciences, 200, 1265-1266。

（还有一个来自 Don Fraser 的参考，我之所以发布它，是因为它似乎有点有争议）
Darmois 的最后一个参考文献没有提供任何证明，而只是对该定理的简短非正式陈述。我认为该定理在作者的其他出版物中得到了证明，但我在网上找不到。
Pitman 的第一个参考文献提供了证明，但没有明确说明结果。而且我发现它不够严谨，符号松散，假设没有明确表述，还有一些“……很明显……”的内容。我发现这一点根本不明显。
Koopman的参考文献清晰而严谨（仅在足够的统计量为2维的特定情况下给出证明），但定理的陈述有点技术性，仅处理连续的一维实随机变量。
因此我的问题是，Pitman-Koopman-Darmois 对于离散随机变量也有效吗？
更一般地说，还有其他参考文献来陈述和证明这个定理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644313/is-pitman-koopman-darmois-theorem-valid-for-discrete-random-variables</guid>
      <pubDate>Thu, 04 Apr 2024 14:36:43 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯认为样本是固定的吗？</title>
      <link>https://stats.stackexchange.com/questions/644312/does-bayesian-regard-samples-as-fixed</link>
      <description><![CDATA[来自 zedstatistics 的关于置信区间的视频表示样本从贝叶斯观点来看是固定的。但我怀疑这个说法是否正确，因为不可能构造后验概率 $P(\theta | X=x)$ if $X$ 不被视为 r.v.下面附上视频中此类讨论的摘录，供参考：

编辑：
我修改为 $P(\theta | X=x)$ 以避免混淆。]]></description>
      <guid>https://stats.stackexchange.com/questions/644312/does-bayesian-regard-samples-as-fixed</guid>
      <pubDate>Thu, 04 Apr 2024 14:28:31 GMT</pubDate>
    </item>
    <item>
      <title>倾向评分匹配 R 交换控制和治疗</title>
      <link>https://stats.stackexchange.com/questions/644336/propensity-score-matching-r-swap-control-and-treatment</link>
      <description><![CDATA[我正在分析观察数据并想要执行倾向得分匹配。我想比较年龄、吸烟状况、体重指数等匹配的男性和女性。当我将男性编码为 0，女性编码为 1 时，匹配后我的协变量非常不平衡。然而，当我将女性编码为 0，男性编码为 1 时，匹配后我的协变量是平衡的。怎么会这样？我正在 R 中使用 matchit 函数。
我交换了对照和治疗的编码，并收到了不同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/644336/propensity-score-matching-r-swap-control-and-treatment</guid>
      <pubDate>Thu, 04 Apr 2024 12:08:50 GMT</pubDate>
    </item>
    <item>
      <title>多中心 RCT 的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/644294/sample-size-calculation-for-a-multicenter-rct</link>
      <description><![CDATA[我对统计世界非常陌生，对于我有限的知识提前表示歉意。我希望你不介意帮助我。
我们目前正在 8 家医院开展治疗 A 与安慰剂对比的多中心随机对照试验。主要结局是治疗持续时间（从随机化到停止治疗的时间 = 分娩），由治疗医生（基于方案和个人意见）和患者相关因素（告诉我们患者不适程度的 3 个变量）决定包含在内）。我们认为，治疗持续时间延长 5 天具有临床意义（“越长越好”）。
我们从之前的试验中获得的数据主要是中位数（安慰剂组的中位治疗持续时间为 10 天），因为治疗持续时间存在很大偏差（大多数治疗在几天后停止，只有少数治疗时间更长）。
我看到这篇文章：https://pubmed.ncbi.nlm.nih。政府/29197347/
他们的样本量计算方法似乎适合我们的情况。然而，我很难找到正确的方法来计算样本量，并考虑到中心之间治疗持续时间差异的（大）影响以及如何纠正这一点。
我已按中心进行了分层随机化，但我知道必须进行额外的修正，以解释通过分层引入的数据中的相关性。
非常感谢大家提前投入的时间和精力，
凯瑟琳娜]]></description>
      <guid>https://stats.stackexchange.com/questions/644294/sample-size-calculation-for-a-multicenter-rct</guid>
      <pubDate>Thu, 04 Apr 2024 10:42:36 GMT</pubDate>
    </item>
    <item>
      <title>伪 R2 值显着不同</title>
      <link>https://stats.stackexchange.com/questions/644289/significantly-different-pseudo-r2-values</link>
      <description><![CDATA[在我参与的一个项目中，逻辑回归模型的 Nagelkerke R2 值用于比较一组分数在解释某些二进制数据时的性能。回归很简单：logic_vector = betas*scores。分数以多种方式生成，因此模型不能真正被视为嵌套。始终使用相同的样本，N=1227。现在，如果我有两个模型的 Nagelkerke R2 值，并且其中一个模型高于另一个模型，是否有某种方法可以计算它是否明显更高？示例：如果我要比较的 R2 值是 0.1 和 0.8，直观上它们似乎显着不同，并且第二组分数更好，因为它解释了更多。将此与 R2 分别为 0.41 和 0.42 的两组分数进行比较，直观上看差异是随机的。有一些方法可以做到这一点吗？我研究过 F 变化、费舍尔变换和引导法，但由于逻辑回归只是对分数的评估，即只有一个解释变量，所以我无法确定它们是否合适。可以获得回归的 P 值和 AIC 值。
&lt;小时/&gt;
谢谢你的回答。问题是我无法执行 logic_vector = Score1 + Score2 + Score3 ... 因为我无法访问所有分数。这也回答了上面彼得斯的问题。我有我制作的所有模型的分数，因此我可以与完整模型进行比较，但最重要的部分是与旧模型进行比较。我基本上拥有的是一系列模型的 R2 分数、回归的 p 值和 AIC 值。我知道样本大小始终为 1227。在我看来，不清楚 AIC 值在非嵌套模型之间是否具有可比性，或者以这种方式使用 R2 值进行比较的整个想法是否合理。因此，仅给出 R2 值列表，是否可以确定显着差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/644289/significantly-different-pseudo-r2-values</guid>
      <pubDate>Thu, 04 Apr 2024 09:45:58 GMT</pubDate>
    </item>
    </channel>
</rss>