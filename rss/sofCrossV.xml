<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 21:14:31 GMT</lastBuildDate>
    <item>
      <title>对此有任何封闭的公式吗？</title>
      <link>https://stats.stackexchange.com/questions/660826/is-there-any-closed-formula-for-this</link>
      <description><![CDATA[在某些假设下，Robins-Monro 算法是回归函数的顺序根估计方法；即形式为
$$
f(\theta) = \mathbb{E}[z|\theta] = \int_{D}zp(z|\theta)dz 的函数。
$$
其中一个假设（我认为？）是 ${f(\theta)}$ 的单调性。
我想知道如果我们将该算法应用于一个更奇怪的示例，例如（非常）嘈杂的正弦函数，会发生什么：
$$
z = \sin(\theta) + x,\ x\sim \mathcal{N}(0,1)。
$$
这里，${f(\theta) = \sin(\theta)}$ 有无穷多个根。我编写了一个模拟程序来跟踪给定各种起始值 ${\theta_0}$ 时发生的情况，使用 R.M. 更新规则
$$
\theta_N = \theta_{N-1} \pm \frac{1}{N}z(x_N,\theta_{N-1})。
$$
似乎，如果上面使用负号，我们会收敛到形式为 ${2n\pi}$ 的根，如果使用正号，我们会收敛到形式为 ${n\pi}$ 的根。我限制只查看形式为 ${2n\pi}$ 的根，因此我使用
$$
\theta_N = \theta_{N-1} - \frac{1}{N}z(x_N,\theta_{N-1})。
$$
花了相当长一段时间才生成大量数据来观察结果，但我发现，给定一个根${\widehat{\theta} = 2n\pi}$和一个起始值${\theta_0}$，我们大致有
$$
p(\widehat{\theta}|\theta_0)\approx \frac{1}{1+e^{-3(\pi - |\widehat{\theta}-\theta_0|)}}。
$$
下面给出了 ${\widehat{\theta} = 0}$ 和 ${-2\pi \leq \theta_0\leq 0}$ 的图：

当 ${\theta_0}$ 距离 ${\widehat{\theta}}$ 不太远或太近时，此近似效果非常好，但似乎在“端点”。即使在这些奇怪的极端情况下生成更多数据后，我的逻辑曲线近似似乎也会在这些端点处失效，并且偏离了数量级。我想我还应该指出，如果我们在总和中使用我的近似值
$$
\sum_{n \in \mathbb{N}}p(\widehat{\theta} = 2n\pi|\theta_0)
$$
它不会收敛到$1$（经过几个项后，它略高于 1）。
我的问题是：有没有办法得出概率${p(\widehat{\theta}|\theta_0)}$的解析解？我的另一个不安是，从技术上讲，我认为，即使经过 10,000 次迭代，我们仍然可能最终转向不同的根（这种可能性极小）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660826/is-there-any-closed-formula-for-this</guid>
      <pubDate>Fri, 31 Jan 2025 20:30:13 GMT</pubDate>
    </item>
    <item>
      <title>以调整后的 $R^2$ 作为变量选择标准的问题</title>
      <link>https://stats.stackexchange.com/questions/660824/problem-with-adjusted-r2-as-criterion-for-variable-selection</link>
      <description><![CDATA[我在研究线性回归时遇到了一个问题。在《复杂问题的平面答案》（Christensen，2020）一书中，他提到：

如果$F$统计量大于1，则删除变量将增加残差均方。根据调整后的$R^2$标准，不应删除该变量。但是，除非$F$值大大大于1，否则可能应该删除这些变量。调整后的$R^2$标准往往会在模型中包含太多变量。

我正试图从数学上理解这一点。我已经完成了这个并设法自己得出：
$$R^2 = 1 - \frac{1}{1 + F\cdot \frac{p-1}{n-p}}$$
其中$p = k + 1$，随后调整后的 R^2 为：
$$\bar{R}^2 = 1 - \frac{n - 1}{n - p + F\cdot (p - 1)}$$
给定一个完整模型$M_k$具有 $k$ 个预测因子，以及一个候选模型 $M_p$，该模型具有 $p$ 个预测因子，$p &lt; k$，我理解 $F$-检验用于测试 $M_k$ 中的附加预测因子是否显著降低残差平方和。我的问题是：

为什么作者在讨论调整后的 $R^2$ 的弱点时引入 $F$ 检验来证明调整后的 $R^2$ 实际上在模型中包含了太多预测因子？我可以理解这种直觉，因为虽然调整后的 $R^2$ 会因为额外的复杂性（即更多的预测因子）而惩罚模型，但它不会因为预测因子的大小而惩罚它们。因此，任何减少残差平方和的预测因子，无论减少大小，都将被包括在内。我如何从上面的等式中理解这一点？或者还有什么我应该研究的？
据我所知，当 $F &gt; 1$，这意味着额外的预测因子显著降低了残差平方和，因此应该将它们包括在模型中（即，完整模型 $M_k$ 优于 $M_p$）。然而，Christensen 提到，除非 $F &gt;&gt; 1$，否则可能应该删除这些变量。从我所学的知识来看，如果 $F$ 显著（在本例中为 $&gt; 1$），则完整模型比简化模型解释的方差要大得多。既然根据检验它已经具有统计显著性，那为什么 $F &gt; 1$ 不足以根据克里斯滕森的观点确立这一事实？
如果我从我推导的模型中理解这一点，我是否应该只考虑 $F$ 而保持其他 ($n, p$) 不变？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660824/problem-with-adjusted-r2-as-criterion-for-variable-selection</guid>
      <pubDate>Fri, 31 Jan 2025 19:00:24 GMT</pubDate>
    </item>
    <item>
      <title>与子集相比，glmer() 模型中固定效应对较大数据集的放大作用</title>
      <link>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
#pooled data (no subsets) -- best model 
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W), family = Gammma(link = &quot;log&quot;), data = d)
#scale(X)estimate = -1.1341, pval ~0
#Random effects: Z variance = 1.76056, Z Std. dev = 1.3269; W variance = 0.09249, W Std. dev = 0.3041 

#数据子集 -- 最佳模型 
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q), family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329, Z Std. dev = 0.2476; Q 方差 = 0.020675, Q Std. dv = 0.1438 

#注意：Q 和 W 都以略有不同的单位来测量时间。

我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化，并以某种方式放大了固定效应，即使这种关系不是那么强？但这些随机效应是有意义的，并且包含结构，所以我不想忽视这一点。有什么建议或资源可以解决此问题吗？
编辑：我还使用 allFit() 来调查收敛问题是否非常成问题，但事实并非如此，所以我尝试使用未转换的数据，结果相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:49:22 GMT</pubDate>
    </item>
    <item>
      <title>关于通过初始值（高值）和最终值（低值）进行归一化后查找方差的问题</title>
      <link>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</link>
      <description><![CDATA[所以，我不太懂统计学，所以我 90% 肯定这是一个愚蠢的问题，但它已经困扰我有一段时间了，所以我非常感激帮助！我有来自许多“个人”的数据；在 0 到 1 的范围内，每个人最初的得分都很高，假设平均得分为 0.8，然后经过多次试验，他们在最后一次试验中的“最终”得分很低，假设平均得分为 0.2。休息一段时间后，他们的分数会有所恢复，假设平均得分为 0.6。
通过这三种方法，我想计算恢复百分比（即，初始得分和最终得分之间的差异中有多少百分比是通过恢复得分恢复的）。使用这个标准化方程式很容易计算：（平均恢复分数 - 平均最终分数/平均初始分数 - 平均最终分数）* 100。结果是 0.6-0.2/0.8-0.2 * 100 = 67%。
很好。但是，我想用这个来计算统计数据以比较不同组的数据，为此我需要这个百分比恢复值的方差（在本例中为 67%）。我不确定该怎么做。初始值、最终值和恢复值存在差异，所以我要使用误差传播吗？还是别的什么？如果能澄清这一点，我将不胜感激，我觉得这不是人们所做的非常罕见的标准化，但我还没有在任何地方找到这个特定问题的解决方案 :(]]></description>
      <guid>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</guid>
      <pubDate>Fri, 31 Jan 2025 17:14:41 GMT</pubDate>
    </item>
    <item>
      <title>与子集相比，glmer() 模型中固定效应对较大数据集的放大作用</title>
      <link>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
#pooled data (no subsets) -- best model 
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W), family = Gammma(link = &quot;log&quot;), data = d)
#scale(X)estimate = -1.1341, pval ~0
#Random effects: Z variance = 1.76056, Z Std. dev = 1.3269; W variance = 0.09249, W Std. dev = 0.3041 

#数据子集 -- 最佳模型 
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q), family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329, Z Std. dev = 0.2476; Q 方差 = 0.020675, Q Std. dv = 0.1438 

#注意：Q 和 W 都以略有不同的单位来测量时间。

我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化，并以某种方式放大了固定效应，即使这种关系不是那么强？但这些随机效应是有意义的，并且包含结构，所以我不想忽视这一点。有什么建议或资源可以配合使用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:08:18 GMT</pubDate>
    </item>
    <item>
      <title>依赖数据的引导 - 距离矩阵的均值</title>
      <link>https://stats.stackexchange.com/questions/660816/bootstrapping-of-dependent-data-mean-of-means-of-a-distance-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660816/bootstrapping-of-dependent-data-mean-of-means-of-a-distance-matrix</guid>
      <pubDate>Fri, 31 Jan 2025 16:54:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0-1。最初，我认为 Beta 回归会是一个不错的选择，所以我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)
我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，似乎 prop_score 并不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

偏度(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布“beta”
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我转向变换后的线性回归而不是 beta 回归是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中，预测变量严重偏斜可以吗？还是应该进行变换？</title>
      <link>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</link>
      <description><![CDATA[我有 7 个预测变量和一个二进制 y。我在 r 中使用逻辑回归，想知道我的 4 个变量高度偏斜是否重要？我可以对它们进行对数变换以减少偏斜，虽然这肯定不是正常的，而且这会稍微提高我的分类准确性，但这通常可以做到吗，还是我应该不进行变换以降低准确性但提高可解释性？我的模型不是用于预测的，但我也希望它是准确的，所以这是逻辑回归的假设吗？此外，如果我对它们进行对数转换，这对于解释模型的输出意味着什么？
我的代码：
at_least1 &lt;- glm(
at_least_1 ~ log(no_of_employees) + log(board_size) +
sqrt(relative_board_size) + log(company_age) + 
average_age + FTSE, 
data = company_data, 
family = binomial(link = &quot;logit&quot;)
)

尝试了转换和不转换预测变量。不转换时，预测准确率为 0.7051，而随机准确率为 0.4999。转换后，准确率为 0.7690576。]]></description>
      <guid>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</guid>
      <pubDate>Fri, 31 Jan 2025 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>作为 SMAPE 的替代品，$\min(a,f)/\max(a,f)$ 叫什么名字？</title>
      <link>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-mina-f-maxa-f-as-an-alternative-to-smape</link>
      <description><![CDATA[我的一位同事要求我提供准确度测量。过去我被教导使用绝对百分比误差 (ape) ... 实际上是补充 (1 - ape)。这样，数字越大越好。
这很有效，但预测值是实际值的 2 倍时除外。他提出了另一种方法。min(a,f)/max(a,f)，其中 a 是实际值，f 是预测值。
起初我建议使用 1 - 对称绝对百分比误差 (1 - (abs(a - f)/ (abs(a) + abs(f))))。SMAPE 是一种经过充分研究的指标。我从未见过他建议的指标，所以一开始我很犹豫。
与另一位数据科学家交谈后，生成了以下图表。它表明 min(a,f)/max(a,f) 具有与 smape 准确度相同/相似的属性，同时更简单。

这个指标有名字吗？
这个指标如何存在无法预见的缺陷？

对我来说，这看起来像是一个很好的错误指标，但我是一名实践者，而不是学者。我肯定我遗漏了一些东西。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-mina-f-maxa-f-as-an-alternative-to-smape</guid>
      <pubDate>Fri, 31 Jan 2025 14:54:54 GMT</pubDate>
    </item>
    <item>
      <title>重新缩放特征增加了其进入 LASSO 模型的机会</title>
      <link>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</link>
      <description><![CDATA[假设我们将 LASSO 回归拟合到一个数据集，该数据集具有 $100$ 个特征 $(X_1, \dots X_{100})$。现在，我们通过乘以 $10$（例如 $X_1$）来重新缩放其中一个特征，然后使用相同的正则化参数重新拟合 LASSO 回归。 $X_1$ 是否更有可能被纳入模型？
考虑到以下情况，我猜答案是否定的，但由于不太正式，我不确定

当将 $X_1$ 乘以 $10$ 时，我们将其在 OLS 中的系数除以 $10$。从示意图上看，LASSO 是通过最小化目标函数直到它达到 L1 范数的界限而获得的。我想到这种情况，其中 $\beta_{\text{LASSO}}$ 首先接近（$0.5,0.5$）。实际上，确切的值并不重要，但很明显 $X_1$ 将包含在模型中。然而，在将 $X_1$ 的 OLS 系数除以 10 后，相同的过程将不可避免地将新的 $\beta_{\text{LASSO}}$ 带到 $\approx(0,1)$，它将不会被包括在内。]]></description>
      <guid>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</guid>
      <pubDate>Fri, 31 Jan 2025 09:55:29 GMT</pubDate>
    </item>
    <item>
      <title>在估算缺失值时，变量之间的时间关系重要吗？</title>
      <link>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</link>
      <description><![CDATA[我现在的情况是，我有多个变量，包含缺失值，在时间 $t_0$ 测量，还有一些变量在时间 $t_1$ 测量，这可能是几年后。
我需要在 $t_0$ 时估算变量中的缺失值，为此我将使用当时可用的任何信息。是否还应该使用时间上在之后出现的变量的信息？我知道关于是否包括响应变量的讨论，但在这种情况下，变量之间的关系具有明显的方向性。目标（下游分析）是估计时间 0 时的一些暴露对时间 $1.$ 时的一些结果的因果影响。结果在估算过程中用于估算其他变量，但本身不会被估算。]]></description>
      <guid>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</guid>
      <pubDate>Fri, 31 Jan 2025 08:07:24 GMT</pubDate>
    </item>
    <item>
      <title>测试两个 AUC 之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</link>
      <description><![CDATA[测试两个 AUC 之间的差异似乎很简单。有一些相关来源，例如这个和其中的链接。
我有一个非常简单的两个 ROC 案例，类似于此示例：
。
使用梯形规则计算 AUC 非常容易。但是，差异检验假设计算了方差，我无法理解如何做到这一点。方差是什么？我拥有的数据就是这样（当然，数据是聚合的）：
命中 FalseAlarms
0.0 0.0
0.9 0.3
1.0 1.0

如何使用上述输入数据在 R 中解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</guid>
      <pubDate>Fri, 31 Jan 2025 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么在之前的抛硬币过程中，下一次抛硬币的不确定性会随着测量次数的增加而增加？</title>
      <link>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</link>
      <description><![CDATA[我对与根据先前的抛硬币结果预测抛硬币结果后验相关的一些问题感到有些困惑。假设我在 N 次抛硬币中看到 k 次正面，我想找出下一次抛硬币结果为正面的概率。我不仅想量化下一次抛硬币结果为正面的概率，还想量化下一次抛硬币结果为正面的不确定性。如果我假设先验均匀并进行一些数学运算，我可以得出下一次抛掷的预期值为
$$
E_p[E_H[H|p]] = \frac{k+1}{N+2}
$$
其中$H$为正面，方差的预期值为
$$
E_p[Var_H[H|p]] = \frac{(k+1)(N-k+1)}{(N+2)(N+3)}。
$$
但是当我尝试几个 k 和 N 的值，使 k=N/3 保持不变时，我注意到不确定性会随着翻转次数的增加而增加。
 k N E[E[H|p]] E[Var[H|p]]
1 3 0.400000 0.200000
2 6 0.375000 0.208333
4 12 0.357143 0.214286
8 24 0.346154 0.217949
16 48 0.340000 0.220000

为什么我获得更多数据时不确定性会增加？这似乎不正确。我猜想使用方差的期望值作为不确定性的代理肯定是有缺陷的，但我不知道更好的指标是什么。如果是这样的话，您能否在下一次抛硬币时提出一个更好的不确定性指标，以符合不确定性应该随着数据增加而减少的直觉？否则这里还有其他问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</guid>
      <pubDate>Thu, 30 Jan 2025 17:24:09 GMT</pubDate>
    </item>
    <item>
      <title>前瞻性和回顾性数据（偏差、研究设计）</title>
      <link>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-bias-study-design</link>
      <description><![CDATA[*我们正在开展一项研究，通过观察 3 个月和 6 个月的结果来评估癌症治疗中治疗转换的有效性。该研究是单组设计，没有对照组。
几周前，我们开始收集患者数据，包括那些在基线时转换到新治疗的患者。然而，许多患者在研究正式开始之前就已经转换了治疗方案。为了增加样本量，我们计划前瞻性地跟踪这些早期患者，但我们需要回顾性地评估他们的基线（转换时间）。对于其中许多患者，T3 和 T6 结果是在研究开始前收集的，因此这些结果将保持回顾性。一些患者在研究开始前会有 T3 结果，在研究开始后会有 T6 结果，而其他患者在研究开始后会同时拥有这两种结果，即使他们在研究开始前转换了治疗方案。
关于缺失数据，我们不希望有任何缺失数据点。然而，一个问题是，之前多次注射的患者可能在研究开始前就改用新疗法，因为那时新疗法已经可用。相比之下，新患者在转换之前可能注射的次数较少，这可能会引入偏差。
我们想知道这项研究是否包括偏差，特别是因为它是一项没有对照组的单组研究，并且我们正在将 3 个月和 6 个月的结果与基线进行比较。如果有偏差，我们如何控制它，我们如何改进研究设计？
非常感谢您的帮助。*]]></description>
      <guid>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-bias-study-design</guid>
      <pubDate>Thu, 30 Jan 2025 06:31:15 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归系数是否均匀收敛，均匀收敛的速度是多少？</title>
      <link>https://stats.stackexchange.com/questions/660579/does-logistic-regression-coefficient-uniformly-converge-and-what-is-the-rate-of</link>
      <description><![CDATA[假设我有一个回归方程
$$y = 1\{X\beta + \xi\}, \text{ where } \xi \sim \text{Logistic}(0,1).$$
将估计量表示为 ($\hat{\beta}$)。我是否得到了均匀收敛结果：
$$\sup_{\beta \in \Theta} |\hat{\beta} - \beta| \to 0 \text{ in probability}?$$
更好的是，我能得到一个比率吗？例如：
$$\sup_{\beta \in \Theta} \sqrt{n}|\hat{\beta} - \beta| = O_P(1).$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660579/does-logistic-regression-coefficient-uniformly-converge-and-what-is-the-rate-of</guid>
      <pubDate>Sun, 26 Jan 2025 20:42:50 GMT</pubDate>
    </item>
    </channel>
</rss>