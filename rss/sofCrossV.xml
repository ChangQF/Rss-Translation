<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Mon, 10 Mar 2025 21:17:25 GMT</lastBuildDate>
    <item>
      <title>尽管使用种子[封闭]，但多项式套索仍会产生不同的拉索输出</title>
      <link>https://stats.stackexchange.com/questions/662429/multinomial-lasso-producing-different-lasso-output-despite-using-seed</link>
      <description><![CDATA[ i使用潜在类混合建模（LCMM 1.7.8软件包）完成了轨迹分析，现在使用自适应套索（GLMNET 4.1-8软件包）来减少预测轨迹成员的自变量的数量。 。
根据多项式示例的自适应拉索代码： https://rpubs.coms.com/kaz_yos/kaz_yos/alass/alasso/alasso     
我的总样本为5,181，完整的情况为662。在用10倍CV进行脊回归以确定最佳的套索系数后，我每次运行适应性套件时都会获得可变的最终结果（即不同的预测变量），尽管在代码中提供了种子。有人有建议保持一致的结果吗？
以下是我的完整代码：
  ridge＆lt;  -  cv.glmnet（seed = 12345，x = x = x，y = y，type.measure =＆quot; class; class; class; 
   nfolds = 10，family =＆quot;多项式＆quot; alpha = 0） 
#select type.measure =＆quot; class; quot;最小化分类错误 
COEF（Ridge，S = RidgesLambda.min） - （为了发布，S代替美元签名操作员）
＃从系数列表中截然
bestridgecoef＆lt; -do.call（cbind，coef（ridge，s = ridge $ lambda.min）））
bestRidgeWeights＆lt; -1/abs（as.matrix（bestridgecoef）[-1，]）

Alasso＆lt; cv.glmnet（种子= 12345，x = x，y = y，type.measure =; class; class; class; nfolds = 10，family =&#39;family =＆quord; alpha = 1，type.multinomial = mmultinomial = molet =; mmultinomial =;
Alasso  $ lambda.min
bestalassocoef＆lt; -do.call（cbind，coef（Alasso，s = alasso $  lambda.min）））
Bestalassocoef
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662429/multinomial-lasso-producing-different-lasso-output-despite-using-seed</guid>
      <pubDate>Mon, 10 Mar 2025 21:06:28 GMT</pubDate>
    </item>
    <item>
      <title>调整Rstudio中的X轴标签[封闭]</title>
      <link>https://stats.stackexchange.com/questions/662428/adjusting-x-axis-labels-in-rstudio</link>
      <description><![CDATA[我为我的工作操作地下水监视传感器。他们每15分钟阅读一次。我每月将数据绘制一次，然后将其添加到我在Rstudio中使用的运行CSV文件。
我在X轴上遇到的标签占用了太多空间。我不确定如何使它们较小，以免它们与X轴标题重叠，“日期/时间”。
  https://i.sstatic.net/coyyyjbrk.png.png 
这是我正在使用的代码块：
  #plot econn no3数据绘图（econ_15  $ date.Time，Econ_15 $  no3.n，
     type =; o o＆quort
     col =“ blue＆quot”，
     xlab =“日期/时间”
     ylab =; no3-n浓度（mg/l）＆quot;
     main =;
     cex = 0.25，
     xaxt =“ n＆quot”，
     网格= false）


#determine x-axis time_ticks＆lt;  -  seq（来自= min_15  $ date.time）， 
                  to = max（econ_15 $  date.time）， 
                  =“ 24小时”

＃将日期/时间变量转换为可读格式的图形axis.posixct（1，在= time_ticks，格式=;％m-％d-％d-％y％h：％m＆quort;％m＆quot，las = 2，cex.axis.axis = 0.7）

#ADD网格线Abline（h = pretty（range_15 $ no3.n）），col =; lightgray; lightgray; lty = 2）＃水平网格线abline abline abline（v = time_ticks，col =; lightgray&#39;
 
 注意：因为我在工作计算机上，并且它们非常严格，因为我下载到机器上的内容，所以我无法在rstudio下载和安装软件包。我正在使用R的基本功能来完成这项工作。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662428/adjusting-x-axis-labels-in-rstudio</guid>
      <pubDate>Mon, 10 Mar 2025 21:04:07 GMT</pubDate>
    </item>
    <item>
      <title>使用正常近似的时间依赖性AUC置信区间</title>
      <link>https://stats.stackexchange.com/questions/662427/time-dependant-auc-confidence-interval-using-normal-approximation</link>
      <description><![CDATA[ IM对特定原因COX模型进行外部验证，并希望呈现AUC及其置信区间。
我已经看到了几个地方，其中描述了如何使用正常近似来计算置信区间，例如在r软件包中：PR​​OC和TIMEROC。
 AUC在0到1之间的界限，因此我为为什么我们可以使用标准正态分布来得出其置信区间感到困惑。如果计算是在返回转换之前以logit量表进行的，但事实并非如此，这可能更有意义。我最感谢有关此建议的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/662427/time-dependant-auc-confidence-interval-using-normal-approximation</guid>
      <pubDate>Mon, 10 Mar 2025 20:59:54 GMT</pubDate>
    </item>
    <item>
      <title>AUC真的是一种有缺陷的模型比较方法吗？</title>
      <link>https://stats.stackexchange.com/questions/662426/is-auc-really-a-flawed-model-comparison-method</link>
      <description><![CDATA[  2009年有影响力的论文， 测量分类器绩效：在Roc courve ucure  em em em em em em em em em em em em em em em em em em em&gt; “从根本上说，在错误分类成本方面，使用“不同分类器的不同分类成本分布”。
详细介绍了论证和数学推导，我发现很难说服自己中心点。这是我的分析。

 本文表明，通过评估每个可能的模型得分错误分类的概率，可以将AUC表示为损失函数，通过模型得分分布的PDF加权并集成以获得预期的损失。 。

 另一方面，它表明，使用其他功能而不是分数PDF来加权该积分等同于将各种错误分类成本概率的信念纳入损失函数中。 

 我摆脱了这一点，即AUC可以被视为关于错误分类成本的特殊案例。但是，我不相信这很重要。 AUC不承担错误分类成本，而成本敏感的损失计算没有参考AUC。


如果上述扣除是合理的，我认为使用AUC作为模型比较的手段没有问题。本文认为，在应用于每个模型的情况下，AUC量度任意改变了与错误分类成本有关的假设。但是，尽管第1点中提到的模型得分分布的PDF可以看作是错误分类成本比率，但没有理由这样做，因为成本在AUC量度中没有任何作用。如果我们 do 决定将其视为错误分类的成本比率，那么一致的方法是将其固定在模型之间，而简单地将其视为AUC度量。
其他人同意，还是我没有想到的东西？也许AUC与 Mann-Wilcoxon U统计的双重性可以提供另一个角度？欢迎一些想法 - 我很高兴详细介绍。]]></description>
      <guid>https://stats.stackexchange.com/questions/662426/is-auc-really-a-flawed-model-comparison-method</guid>
      <pubDate>Mon, 10 Mar 2025 20:51:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么统计输出中的信心频段不更常见 /默认</title>
      <link>https://stats.stackexchange.com/questions/662424/why-arent-confidence-bands-more-common-default-in-statistical-output</link>
      <description><![CDATA[我记得我在研究生院校参加的真正基本回归课程中，如果我们想成为“正确”当我们制作了相对于因变量的模型预测的响应图，该响应是从线性模型得出的（通常使用＆gt; 1自变量），我们应该真正地围绕均值绘制置信频段，而不仅仅是代表预测CI的线。这样做的方法是计算工作型置信频段。
如果这是“正确”方式，为什么不是更统计的例程中的默认值？它是否给像我这样的非统计学家喜欢适合过度参数的模型提供了太宽的乐队（/讽刺）？是因为它不推广到混合模型或GLM吗？混合/GLM模型是否有等效的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662424/why-arent-confidence-bands-more-common-default-in-statistical-output</guid>
      <pubDate>Mon, 10 Mar 2025 18:48:06 GMT</pubDate>
    </item>
    <item>
      <title>在几个特定时间点上平均的有效模型/测试治疗效果？</title>
      <link>https://stats.stackexchange.com/questions/662423/efficient-model-test-for-treatment-effect-averaged-across-several-specific-timep</link>
      <description><![CDATA[在一个假设的临床试验中，有三个基线后时间点。如果我想利用重复的措施设计以最大化检测对嘈杂结果的真实影响的能力，那么我可以拟合形式的模型
结果〜Arm*访问 +我们（访问| subjid）
并测试是否有Armtrt的效果。
但是，假设我希望该药物在第一个时间点会产生很小的效果，我想专注于最后两个时间点的效果的平均值。在这种情况下，我认为我想对Armtrt + 1/2之类的事情进行测试（Armtrt：访问2 + Armtrt：visit3）。但是我不确定如何执行此测试。有什么建议吗？我认为我唯一的限制是由于缺失而需要使用MMRM。我正在使用R MMRM软件包。]]></description>
      <guid>https://stats.stackexchange.com/questions/662423/efficient-model-test-for-treatment-effect-averaged-across-several-specific-timep</guid>
      <pubDate>Mon, 10 Mar 2025 18:46:30 GMT</pubDate>
    </item>
    <item>
      <title>MCMC的贝叶斯分析是否是定量分类的方式？</title>
      <link>https://stats.stackexchange.com/questions/662418/is-bayesian-analysis-with-mcmc-a-way-of-quantitative-classification</link>
      <description><![CDATA[用我自己的话来说，蒙特卡洛·马尔可夫链（MCMC）可用于使后验分布在许多变量中可以访问：：
例如，给出的患者数据包括年龄，血压，血糖水平和心脏病发作的发生，MCMC将使我能够计算后验分布的参数（在这种情况下可能是泊松分布），以推断患有给定参数的患者患有心脏病患者的可能性（将来）。
在这方面，贝叶斯分析在我看来就像解决了一个分类问题，包括分类的可靠性。
在这种情况下，我（天真地）想知道贝叶斯分析的好处将是其他机器学习或神经网络方法的好处。]]></description>
      <guid>https://stats.stackexchange.com/questions/662418/is-bayesian-analysis-with-mcmc-a-way-of-quantitative-classification</guid>
      <pubDate>Mon, 10 Mar 2025 16:59:50 GMT</pubDate>
    </item>
    <item>
      <title>了解一致MLE的判别模型中X条件的数学必要性</title>
      <link>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</link>
      <description><![CDATA[我以前曾问了两个问题，可以解决相关问题：

In this answer to my question about the intuition behind the conditions on the design matrix $X$ (or the predictors), the answer provided insight into why such conditions are needed to ensure consistency of discriminative model估算器。
我从这个答案是，如果log-likelihoodhiehoodhiehienhiphienhighiehiend proments（即 $ log（f_i logi log 
问题是：
   $ x $ 在派别模型中施加的详细数学推理是什么？具体？并使用相同的条件模型 $ p（y | x）$ ？
我正在寻找一种严格的解释或派生，将第一个答案中提供的直觉与数学要求联系起来，以确保可能性贡献不会“吹”。或消失，从而影响估计程序的整体一致性。
对有关此主题的进一步文献的任何见解，证明或参考，都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</guid>
      <pubDate>Mon, 10 Mar 2025 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>带有聚合预测指标的回归</title>
      <link>https://stats.stackexchange.com/questions/662422/regression-with-aggregated-predictors</link>
      <description><![CDATA[说我有有关学生（例如年龄，性别）和学校（例如，数学考试失败的学生）的个人级别信息。我想调查学生协变量对学校级指标的影响。这看起来像是一个多层次的分析问题（学生嵌套在学校内），只是在学校级别（而不是学生级别）测量了因变量（​​y）。
您将如何解决此问题？
我的直觉是，在进入通用线性模型之前，学生级变量首先需要在学校级别进行汇总（例如计算平均年龄；计算男性％）。
但是，我担心手段或比例可能还不够。您还将包括分散措施（例如年龄的标准偏差）吗？
另外，群体规模不平等呢？假设我在School_1中有30名学生，而School_2中只有5名。我认为该模型应该考虑到这一点。您会运行加权回归（重量与组大小成正比，例如权重_school_1 = 30/（30+5）= 0.85）？
我已经编写了以下R代码来说明问题。
  set.seed（12345）

Math_test = rnorm（n = 100，平均= 50，SD = 10）＃100学校
group_size = round（runif（n = 100，min = 1，max = 50））＃每个学校的学生数量不同（1-50）

l_student_age = lapply（1：100，function（x）rnorm（n = group_size [x]，平均= 15，sd = 1））

student_age = sapply（1：100，函数（x）平均值（student_age [[x]]））

data = data.frame（
  Math_test = Math_test，
  group_size = group_size，
  Student_age = student_age）

数据$权重=数据$ group_size/sum（数据$ group_size）

数据$ mc_student_age =比例（数据$ student_age，center = t，scale = f）

fit0 = lm（Math_test〜MC_STUDENT_AGE，数据=数据）
摘要（fit0）

fit1 = lm（Math_test 〜mc_student_age，data = data，striges = stright）
摘要（fit1）
 
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662422/regression-with-aggregated-predictors</guid>
      <pubDate>Mon, 10 Mar 2025 16:33:47 GMT</pubDate>
    </item>
    <item>
      <title>p = 1/2是否总是导致clopper-pearson间隔的最差案例样本量？</title>
      <link>https://stats.stackexchange.com/questions/662413/does-p-1-2-always-lead-to-the-worst-case-sample-size-for-clopper-pearson-interva</link>
      <description><![CDATA[我想对获得获得置信区间的样本数量进行先验限制，其中（a）预期宽度和（b）最差的宽度为 $ \ leq \ leq \ lepsilon $ 使用clopper-pearson间隔，以使某些置信级别对于（a），预期的宽度当然取决于真正的成功概率，该概率通常被指定为“初始猜测”  $ P_0 $ 。我已经看到很多次，如果不确定建议选择 $ p_0 = 1/2 $ ，例如。在本文（第8页的最后一行）。这是有意义的直觉，因为 $ p = 1/2 $ 使方差最大化，但是我找不到任何确认，无论始终是否存在，无论 nath-container“&gt; $ \ v varepsilon $ span&gt; $ span&gt; and class class class class clast clast =”
对于（b），我怀疑当试验中的一半成功而出于类似原因而获得最坏情况，但我又无法找到此确认。
是否有任何论文或教科书特别表明 $ p = 1/2 $ 确实总是最坏的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/662413/does-p-1-2-always-lead-to-the-worst-case-sample-size-for-clopper-pearson-interva</guid>
      <pubDate>Mon, 10 Mar 2025 15:48:25 GMT</pubDate>
    </item>
    <item>
      <title>参数G-Formula的ICE版本：如何应用干预措施？</title>
      <link>https://stats.stackexchange.com/questions/662412/ice-version-of-the-parametric-g-formula-how-to-apply-the-intervention</link>
      <description><![CDATA[参数G形式的传统版本，也称为NICE（非著作条件期望），需要为每个随时间变化的暴露和混杂因素规范参数模型。为了克服这一点，已经提出了ICE版本（在这里 [3.2]和在这里 [第17页]）。这个想法是，从结果 $ y $ 开始，我们会根据预测值（即，伪结果）递归对其进行回归， $ y \ y \ y \ y \ sim a + l $  $ L $ 一组混杂因素。
特别是Zivich等。 &#39;24提供以下算法：

  
我想专门关注

生成 $ y _ _ {\ tau} $ 的预测值， $ \ bar {a}^*_ {i {i，\ tau -1}}

其中 $ \ bar {a}^*_ {\ tau -1} =（a^*_ 0，\ dots，a^*_ {\ tau-tau-1}）$正是我的理解是，对于算法的第2点，我应该使用回归模型来预测 $ y _ _ {\ tau} $ 在介入跨越时间点的处理后。
尽管如此，在霍夫曼等人中。 &#39;24，它们为冰参数G-Formula提供以下伪算法：

  
在第2点中，具体来说，他们建议预测结果 $ y $ 在时间 $ t $ 使用回归模型仅通过在暴露范围上介绍 $ a_1^d $ 在论文中）。这似乎与以前的算法相矛盾。我知道Hoffman &#39;24中的算法是一个简化的版本，因为没有审查 $ c $ ，但是关于使用参数g-formula并重复进行暴露量的概念的想法应相同。我想念什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/662412/ice-version-of-the-parametric-g-formula-how-to-apply-the-intervention</guid>
      <pubDate>Mon, 10 Mar 2025 14:40:06 GMT</pubDate>
    </item>
    <item>
      <title>T-SNE嵌入的问题</title>
      <link>https://stats.stackexchange.com/questions/662411/the-problem-with-t-sne-for-embedding</link>
      <description><![CDATA[阅读在T-sne 上进行聚类，我已经看到了关于使用T-sne; forpect＆quffect; forpect;作为集群算法的嵌入。但是许多例子似乎都有标签，用作T-SNE评估的基础真相。但是，与T-SNE嵌入的问题正是通过原始转换无法正确转换新数据。
“的确，我的一些T-SNE图仅在两个维度上显示了数据的巨大分离。问题在于，T-SNE没有能力将新点映射到低维空间中，例如PCA，它为您提供了线性转换，以应用于新点。因此，您无法对新数据进行预测，甚至无法执行标准技术，例如使用测试集，交叉验证或引导程序验证。” （ t-sne dimensiveality dismensivality dismensivality distemenization ））
据我所知，只有Opentsne允许您转换新的观点，并且可以考虑以下内容：
&#39;此过程仅相对于现有嵌入的每个点优化了每个点，即忽略x中点之间的任何相互作用。
因此，除了我们可以使用t-sne进行无监督学习之外，该过程非常“本地”，仅用于分析特定数据，对吗？使用T-SNE作为表示技术是一种危险方法，对]]></description>
      <guid>https://stats.stackexchange.com/questions/662411/the-problem-with-t-sne-for-embedding</guid>
      <pubDate>Mon, 10 Mar 2025 14:28:11 GMT</pubDate>
    </item>
    <item>
      <title>Dixon Massey评估ED50的方法的先验样本量计算</title>
      <link>https://stats.stackexchange.com/questions/662414/a-priori-sample-size-calculation-for-dixon-masseys-method-of-evaluating-ed50</link>
      <description><![CDATA[我正在努力抓住Dixon-Masseys方法的问题，用于评估样本中的ED50。我希望使用这种方法来估计药物的最低剂量诱导所需的最小减少（如果这些药物诱导反应较高（即减少60 bpm，所需的基线效应为40 bpm），这是比所需的，它实际上并不重要，实际上是可取的）。如何在确定此类效果的样本量的先验计算中进行操作……然后如何计算诱导响应所需的剂量以可重复可重复的...根据我的研究的研究，狄克逊·梅西的方法可以评估剂量依赖性的效果，因为我可以使用一个小样本，因为我可以使用它的限制。
根据我的能力，我观察到的变量的标准偏差为10，生物学显着效果为20，我将使用1-beta = 0.8，因为它是一项试验研究，而alfa = 0.05。使用这些变量值，您可以使用先验的Wilcoxon-Mann-Whitney，一个尾巴，2组比较测试获得最小样本量。我发现一篇论文声称Dixon Masseys的样本量是针对小组比较的常规A的两倍（DOI：10.1007/S00101-017-0370-9）。
欢迎任何建议。另外，如果任何人比迪克森·梅西（Dixon Masseys）更好地确定（不错，不是完美地）使用如此小样本的药物效应，请随时发表评论。
谢谢大家，我非常感谢所有评论，批评和建议
伊万]]></description>
      <guid>https://stats.stackexchange.com/questions/662414/a-priori-sample-size-calculation-for-dixon-masseys-method-of-evaluating-ed50</guid>
      <pubDate>Mon, 10 Mar 2025 13:24:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个解决方案至少是正式的？</title>
      <link>https://stats.stackexchange.com/questions/662410/why-is-this-solution-to-least-squares-the-least-norm</link>
      <description><![CDATA[ 我已经在此数学答案最小二乘的一般解决方案是（从链接的答案中提取）：
  $$ \ lvert
 X_ {LS}
\ rvert_ {2}^{2} 
=
\ lvert
 \ color {blue} {\ mathbf {a}^{\ Dagger} b} + 
 \ color {red} {\ left（\ mathbf {i} _ {n}  -  \ mathbf {a}^{\ dagger} \ dagger} \ mathbf {a} \ right）y} y}
\ rvert_ {2}^{2} 
=
\ lvert
\ color {blue} {\ mathbf {a}^{\ Dagger} b}
\ rvert_ {2}^{2} 
+
\ UnderBrace {\ lvert
 \ color {red} {\ left（\ mathbf {i} _ {n}  -  \ mathbf {a}^{\ dagger} \ dagger} \ mathbf {a} \ right）y} y}
\ rvert_ {2}^{2}} _ {y = \ Mathbf {0}} $$  
和最小规范是右手术语，即使用 $ y = 0 $ 。
但从向量之和的平方
一个人如何从单个规范到这里的规范之和？]]></description>
      <guid>https://stats.stackexchange.com/questions/662410/why-is-this-solution-to-least-squares-the-least-norm</guid>
      <pubDate>Mon, 10 Mar 2025 13:06:49 GMT</pubDate>
    </item>
    <item>
      <title>实验样本量接近人群 - 如何进行推理？ （+FPC）</title>
      <link>https://stats.stackexchange.com/questions/662407/experiment-with-sample-sizes-close-to-population-how-to-approach-inference</link>
      <description><![CDATA[这是我过去想过的一个问题，但我无法说服答案的正确性。
假设您正在一个小国的所有学校中进行（真实的）实验，并且具有简单的2x2实验设计。假设您有兴趣在干预之前在整个数据集上运行回归模型。最后，假设我对将结果概括为其他国家不感兴趣 - 从理论上讲，我的样本”现在相当于100％的人口。它基本上是人口普查数据。
现在，运行实验i  am 处理两个子组，该子组已被随机分配，因此我有两个随机的子样本。但是我应该在这里进行有限的人口更正吗？我不能相信自己应该将人口视为无限，甚至比我的样本大的数量级。我该如何估计我的人口规模？
在使用我的回归模型时，我一定会使用大小接近〜90％人群的样本（假设缺失或无法使用的数据）。使用未经校正的经典推论意味着要考虑更多的人口，这只会意味着未来+过去的学校。但是我想那样做吗？我可以很容易地说，我的研究将来不能被推广到25年，因为事情可能发生了足够的变化以需要复制和重新评估。
那么，我该怎么办？谢谢！
（变化：如果我的数据来自每所学校，但是由于某些原因，实验仅在5％的学生身上进行？）]]></description>
      <guid>https://stats.stackexchange.com/questions/662407/experiment-with-sample-sizes-close-to-population-how-to-approach-inference</guid>
      <pubDate>Mon, 10 Mar 2025 12:18:22 GMT</pubDate>
    </item>
    </channel>
</rss>