<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 11 Jul 2024 21:16:23 GMT</lastBuildDate>
    <item>
      <title>在语义分割中，不使用注意力机制的情况下使用 U-Net 作为特征金字塔网络 (FPN) 的骨干是一种好方法吗？</title>
      <link>https://stats.stackexchange.com/questions/650903/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpnwithout-attention</link>
      <description><![CDATA[我目前正在进行一项用于研究目的的图像分割任务，我正在考虑构建一个没有注意力的特征金字塔网络 (FPN)，使用 U-Net 作为主干模型。我已经基于这种方法实现了一个模型，但我不确定这是否是最好的方法。请告诉我使用 U-Net 作为 FPN 的主干是否是语义分割的好方法？我将不胜感激您的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650903/is-using-u-net-as-a-backbone-for-feature-pyramid-network-fpnwithout-attention</guid>
      <pubDate>Thu, 11 Jul 2024 21:10:12 GMT</pubDate>
    </item>
    <item>
      <title>我可以利用数据的时间序列属性，而不产生滞后吗？</title>
      <link>https://stats.stackexchange.com/questions/650901/can-i-utilise-time-series-properties-of-the-data-without-creating-lags</link>
      <description><![CDATA[我正在做一个项目，项目人员给我提供了训练集和测试集。数据（股票收益）本质上是时间序列，但关键是我无法创建滞后，因为这意味着丢弃前 k 个观测值，因为它们无法产生滞后。

为什么这对我来说是个问题？因为我将通过测试集上的 MSE 进行判断，该 MSE 由具有真实值的预定义脚本计算得出（我无法访问）。所以这意味着我不能从测试数据集中删除任何值。我很乐意在数据上实现 LSTM 或 AR(I)MA，但由于这意味着为了进行预测，我也必须在测试集中创建滞后，所以我只能使用随机森林和 XGBoost。
有没有什么方法可以利用数据的时间序列属性，而不会产生滞后，或者是否存在任何深度学习方法可以让我做到这一点（我不知道）？
谢谢，感谢您的善意意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/650901/can-i-utilise-time-series-properties-of-the-data-without-creating-lags</guid>
      <pubDate>Thu, 11 Jul 2024 20:30:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么 scikit-learn 梯度提升分类器的默认参数不同？（GradientBoostingClassifier 和 HistGradientBoostingClassifier）</title>
      <link>https://stats.stackexchange.com/questions/650899/why-the-different-default-parameters-for-scikit-learn-gradient-boosting-classifi</link>
      <description><![CDATA[为什么梯度提升分类器 (GradientBoostingClassifier) 和基于直方图的梯度提升分类器 (HistGradientBoostingClassifier) 在 scikit-learn 中有显著不同的默认超参数值，以及如何最好地协调这些差异？
鉴于这两个前提：

scikit-learn 设计原则包括 合理的默认值 适用于其对象
据我所知，基于直方图的梯度提升分类器在概念上与普通梯度提升分类器几乎相同，只是输入是分箱的

如果上述前提正确，我很难理解为什么默认超参数会不同。以下是两个分类器（以下称为 Gradient 和 HistGradient）之间的最大区别：



参数
渐变
HistGradient




max_depth
3
无


min_samples_le af
1
20


max_leaf_nodes
None
31


n_iter_no_change
None
10



不同的 max_depth 默认值是一个巨大的变化；Gradient 分类器的 max_depth=3 是一棵非常浅的树，而 max_depth=None 根本不限制树的深度。另一方面，HistGradient 分类器上的 min_samples_leaf 和 max_leaf_nodes 约束似乎是任意的，并且可能比根据数据限制树的深度更不合理。不同的 n_iter_no_change 默认值意味着 HistGradient 分类器默认使用提前停止，而 Gradient 分类器则不这样做。
我应该如何理解这些不同的默认值？在梯度提升方法中，是否有理论或算法上的理由来限制 max_depth 与 min_samples_leaf 与 max_leaf_nodes？
当然，我应该探索适合我的数据的最佳超参数值，但这些差异似乎违反了“合理的默认值”设计原则，同时也使得超参数搜索从截然不同的地方开始。]]></description>
      <guid>https://stats.stackexchange.com/questions/650899/why-the-different-default-parameters-for-scikit-learn-gradient-boosting-classifi</guid>
      <pubDate>Thu, 11 Jul 2024 19:40:01 GMT</pubDate>
    </item>
    <item>
      <title>给定起点和终点的随机游动的条件方差</title>
      <link>https://stats.stackexchange.com/questions/650898/conditional-variance-of-random-walk-with-given-start-points-and-ending-points</link>
      <description><![CDATA[如果我有一个漂移为 0 的随机游走，并且我观察到 $X_1 = x_1$ 和 $X_k = x_k$，但我没有 $X_i$ 中 $i \in \{2, ..., k-1 \}$ 的所有点，我该如何估计它们并给出 CI？我知道预期值只是从 $X_1$ 到 $X_k$ 的线性插值，那么条件方差如何？它将小于随机游走的固有方差，但我不确定要小多少。任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650898/conditional-variance-of-random-walk-with-given-start-points-and-ending-points</guid>
      <pubDate>Thu, 11 Jul 2024 19:14:28 GMT</pubDate>
    </item>
    <item>
      <title>测试/验证集</title>
      <link>https://stats.stackexchange.com/questions/650897/test-validation-set</link>
      <description><![CDATA[我一直在与同事讨论，想征求您的意见。如果我使用保留和交叉验证来构建和测试我的模型。在此过程中，训练集用于调整超参数并评估模型。然后，从每个候选算法中选择一个模型（例如，ANN、SVM 等，即为每个算法选择一组最终超参数）。假设我尝试了 10 种不同的算法，最终得到了 10 个最终模型。
在测试集上评估每个最终候选模型是否可以接受？或者我只能在测试集上评估单个最终候选模型？如果是这样，假设单个最终候选模型在训练集上的表现不会在测试集上复制，我应该如何进行？我觉得只要测试集不暴露给模型，它就应该对从一堆模型中选择最终模型有效。但是，这可能类似于统计学中的多重检验。
如能提供任何参考，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650897/test-validation-set</guid>
      <pubDate>Thu, 11 Jul 2024 18:52:44 GMT</pubDate>
    </item>
    <item>
      <title>如何得出 KL-UCB 老虎机的即时相关遗憾？</title>
      <link>https://stats.stackexchange.com/questions/650896/how-to-derive-instant-dependent-regret-for-kl-ucb-bandit</link>
      <description><![CDATA[我正在阅读 Lattimore 所著的 Bandit Algorithms 一书中的带有伯努利奖励的 Bandit 的 KL-UCB 算法（第 10.2 节），该算法提供的遗憾值是即时相关的，并且取决于所有臂的最优性差距。我想知道我们如何确定此算法的即时独立界限，它仅取决于臂的数量和时间范围。此外，给定 UCB 的定义，置信度是多少？
此外，无论是从理论上还是从经验上讲，该算法都是所有带有伯努利奖励的 Bandit 算法中最好的算法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650896/how-to-derive-instant-dependent-regret-for-kl-ucb-bandit</guid>
      <pubDate>Thu, 11 Jul 2024 18:36:20 GMT</pubDate>
    </item>
    <item>
      <title>使用整个训练集来选择模型</title>
      <link>https://stats.stackexchange.com/questions/650894/using-whole-training-set-for-choosing-model</link>
      <description><![CDATA[我正在研究一个分类问题，我理解这是一个大数据集。我首先将它分成“训练”数据集和“测试”数据集。（实际上，我确信我应该在 EDA 之前这样做，但不确定）。我已经完成了所有预处理，现在我必须选择一个模型。我正在尝试以下模型：

使用网格搜索对 C 参数进行逻辑回归 [10e-3、10e-2、10e-1、1、10、100、1000]
使用网格搜索对最大深度进行决策树分类器 [None、3、5、7、9]
使用网格搜索对 C 参数 [10e-2、1、100] 和内核 [&#39;linear&#39;、&#39;rbf&#39;] 进行支持向量机
使用大型网格搜索的随机森林分类器：

&#39;clas__n_estimators&#39;：[100、200、300]，
&#39;clas__max_depth&#39;：[None、10、20、 30],
&#39;clas__min_samples_split&#39;: [2, 5, 10],
&#39;clas__min_samples_leaf&#39;: [1, 2, 4],
&#39;clas__bootstrap&#39;: [True, False]


梯度提升分类器也有很多参数:

&#39;clas__n_estimators&#39;: [100, 200, 300],
&#39;clas__learning_rate&#39;: [0.01, 0.1, 0.2],
&#39;clas__max_depth&#39;: [3, 5, 7],
&#39;clas__min_samples_split&#39;: [2, 5, 10]，
&#39;clas__min_samples_leaf&#39;: [1, 2, 4]



还有一些更简单的模型，如 GaussianNB 和 KNN。
我在预处理后通过 cv=10 的交叉验证对我的“训练”数据集进行评估。这个数据集的大小约为 90 个特征的 70,000 个观测值，我正在我的计算机本地计算训练。我担心完成所有训练会花费太长时间，我想知道是否可以使用数据集的一小部分样本来选择我缺少的模型或其他技术。非常感谢您的帮助。
我不得不说，我还有大约一周的时间来完成这个问题，所以我担心每次训练都需要等待几天，即使我想用更少的特征重新训练随机森林或梯度提升或类似的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/650894/using-whole-training-set-for-choosing-model</guid>
      <pubDate>Thu, 11 Jul 2024 18:34:39 GMT</pubDate>
    </item>
    <item>
      <title>高斯集合的算子范数的界限（Wainwright 示例 6.2）</title>
      <link>https://stats.stackexchange.com/questions/650893/bound-of-operator-norm-for-gaussian-ensemble-wainwright-example-6-2</link>
      <description><![CDATA[考虑用 i.i.d 生成的$W \in \mathbb{R}^{n \times d}$。 $N(0,1)$ 项，Martin Wainwright HDS 中的定理 6.1 意味着
$$
\frac{\sigma_\max(W)}{\sqrt{n}} \leq 1 + \delta + \sqrt{\frac{d}{n}}
$$
并且
$$
\frac{\sigma_\min(W)}{\sqrt{n}} \leq 1 - \delta - \sqrt{\frac{d}{n}}
$$
其中两个边界都成立的概率大于 $1 - 2 e^{-n\delta^2/2}$。
wainwright 中的示例 6.2 声称这些$W$ 奇异值的界限意味着
$$
||\frac{1}{n} W^TW - I_d||_2 \leq 2 \left(\sqrt{\frac{d}{n}} + \delta \right)+ \left(\sqrt{\frac{d}{n}} + \delta \right)^2.
$$
概率大于 $1 - 2e^{-n\delta^2/2}$。
为什么这是真的？]]></description>
      <guid>https://stats.stackexchange.com/questions/650893/bound-of-operator-norm-for-gaussian-ensemble-wainwright-example-6-2</guid>
      <pubDate>Thu, 11 Jul 2024 18:19:05 GMT</pubDate>
    </item>
    <item>
      <title>我的流行病学研究应该使用什么标准人群？</title>
      <link>https://stats.stackexchange.com/questions/650892/what-standard-population-to-use-in-my-epidemiological-study</link>
      <description><![CDATA[我需要标准化我的死亡率比率。针对某个欧洲国家 2000-2022 年期间的死亡率比率。但是，我不知道该使用什么标准人口？Sagi 过时了吗？此外，我发现这个网站 https://seer.cancer.gov/stdpopulations/world.who.html 上有 WHO 2002-2025 标准人口？我应该使用“四舍五入为整数”列进行标准化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650892/what-standard-population-to-use-in-my-epidemiological-study</guid>
      <pubDate>Thu, 11 Jul 2024 18:16:37 GMT</pubDate>
    </item>
    <item>
      <title>Beta 后验分布强一致性的证明</title>
      <link>https://stats.stackexchange.com/questions/650889/proof-of-strong-consistency-of-beta-posterior-distribution</link>
      <description><![CDATA[假设我们有随机变量 $X_{1}, X_{2}, ..., X_{n} \sim^{iid} \text{Bernoulli}(p_{0})$，其中 $p_{0}$ 的真实未知概率位于 $[0,1]$ 中。现在，我想实现贝叶斯机制来推断真实的未知概率 $p_{0}$。要做到这一点，第一步是在我的随机变量$p$上定义一个先验分布，它是$p_{0}$的猜测，并且我放置一个$\text{Beta}(a,b)$分布，其中$a,b&gt;0$。然后我可以推导出基于实现的后验分布 $X_{1}=x_{1}, X_{2}=x_{2}, ..., X_{n}=x_{n}$
$$p|X_{1}=x_{1}, X_{2}=x_{2}, ..., X_{n}=x_{n}\sim \text{Beta}(a+\sum_{i=1}^{n}x_{i}, b + n - \sum_{i=1}^{n}x_{i})$$
到目前为止，一切正常。我们将后验分布的均值表示为$T_{n} = \frac{a+\sum_{i=1}^{n}X_{i}}{a+b+n}$，我使用大写$X_{i}$，因为它是一个随机变量。
我不确定的部分是如何证明$T_{n}$的强一致性。我这样说的意思是
$$\mathbb{P}(\lim_{n\rightarrow \infty }T_{n} = p_{0}) = 1 \ \ (*)$$

我的想法：
首先，我想检查一下 $\lim_{n\rightarrow \infty }T_{n}$ 发生了什么情况
$$\lim_{n\rightarrow \infty }\frac{a+\sum_{i=1}^{n}X_{i}}{a+b+n} = \lim_{n\rightarrow \infty}\frac{\sum_{i=1}^{n}X_{i}}{n} \ \ (1)$$
我们知道 $(X_{i})_{i=1}^{n}$ 是 iid 的，并且 $\mathbb{E}[X_{i}= p] &lt; \infty$ 和 $\mathbb{E}[X_{i}] =p_{0}$。然后，我们可以利用强大数定律，它指出
$$\mathbb{P}(\lim \frac{\sum_{i=1}^{n}X_{i}}{n} = p_{0}) = 1$$
这正是我们在$(*)$中所需要的那种收敛。然后我们可以重写 $(*)$ 我们得到了
想要的结果
$$\mathbb{P}(\lim_{n\rightarrow \infty }T_{n} = \lim \frac{\sum_{i=1}^{n}X_{i}}{n} = p_{0}) = 1$$

这是证明强一致性的有效方法吗？而且 $p_{0}$ 是一个未知值，我们如何解释并显示 $p_{0}$ 可以取的所有可能值的一致性？]]></description>
      <guid>https://stats.stackexchange.com/questions/650889/proof-of-strong-consistency-of-beta-posterior-distribution</guid>
      <pubDate>Thu, 11 Jul 2024 16:07:23 GMT</pubDate>
    </item>
    <item>
      <title>来自多个传感器的多变量时间序列数据的异常检测</title>
      <link>https://stats.stackexchange.com/questions/650888/anomaly-detection-for-multivariate-time-series-data-from-multiple-sensors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650888/anomaly-detection-for-multivariate-time-series-data-from-multiple-sensors</guid>
      <pubDate>Thu, 11 Jul 2024 15:48:09 GMT</pubDate>
    </item>
    <item>
      <title>比较两组间多种疾病的比例</title>
      <link>https://stats.stackexchange.com/questions/650886/compare-the-proportion-of-multiple-diseases-between-2-groups</link>
      <description><![CDATA[我正在对来自处于不同环境条件下的两组人的数据进行分析。以下是简要概述：

A 组：750 人暴露于烟雾中。
B 组：1500 人暴露于清洁空气中。
两组人均在两个不同的时间点招募，每个时间点各招募一半人。
研究中的每个人都会患上三种相互排斥的疾病之一。我的目标是确定两组之间的总体疾病比例是否存在显着差异。

我最初考虑对每种疾病进行简单的比例测试，比较 A 组和 B 组的患病率。但是，这种方法似乎是多余的，因为由于相互排斥性，组中一种疾病的患病率增加本质上会降低其他疾病的患病率。
这是我使用的代码片段：
# 加载必要的库
library(dplyr)

# 设置可重复性的种子
set.seed(123)

# 定义每个组中的个体数量
n_group_a &lt;- 750
n_group_b &lt;- 1500

# 定义招募时间点
timepoints_a &lt;- c(rep(1, n_group_a / 2), rep(2, n_group_a / 2))
timepoints_b &lt;- c(rep(1, n_group_b / 2), rep(2, n_group_b / 2))

# 定义疾病
diseases &lt;- c(&quot;DiseaseX&quot;, &quot;DiseaseY&quot;, &quot;DiseaseZ&quot;)

prob_group_a &lt;- c(0.7, 0.15, 0.15) # Disease1 在 A 组中更常见
prob_group_b &lt;- c(0.33, 0.33, 0.34) # B 组中的概率相等

# 为 A 组创建数据框
group_a &lt;- data.frame(
id = 1:n_group_a,
group = rep(&quot;A&quot;, n_group_a),
exponence = rep(&quot;smoke&quot;, n_group_a),
timepoint = timepoints_a,
disease = sample(diseases, n_group_a, replace = TRUE, prob = prob_group_a)
)

# 为 Group B 创建数据框
group_b &lt;- data.frame(
id = (n_group_a + 1):(n_group_a + n_group_b),
group = rep(&quot;B&quot;, n_group_b),
Exposure = rep(&quot;clean_air&quot;, n_group_b),
timepoint = timepoints_b,
disease = sample(diseases, n_group_b, replace = TRUE, prob = prob_group_b)
)

# 将两组合并为一个数据框
combined_data &lt;- bind_rows(group_a, group_b)

# 显示合并的数据
head(combined_data, 20) # 显示前 20 行

# 创建比例 DF
proportion_df &lt;- combined_data %&gt;%
group_by(disease, Exposure) %&gt;%
tally() %&gt;%
left_join(., combined_data %&gt;%
group_by(, Exposure) %&gt;%
tally(n = &quot;n_total&quot;)) %&gt;%
mutate(fraction = n / n_total)

# 可视化结果比例
ggplot(proportion_df, aes(x=disease,y=fraction, fill=disease))+
geom_col()+
facet_wrap(~exposure, ncol=1) + 
theme(legend.position = &quot;none&quot;)+
ylab(&quot;Fraction of disease&quot;)+
geom_text(aes(label = round(fraction,2)), vjust = -0.5, position = position_dodge(0.9), size = 3.5) +
theme_minimal() %+%
theme(legend.position = &quot;none&quot;) + 
ylim(0, max(proportion_df$fraction) * 1.15) # 调整标签空间的 y 轴限制

# 计算每种疾病的差异
pro_test_res &lt;- lapply(unique(proportion_df$disease), function(disease) {
n_success &lt;- percentage_df %&gt;%
filter(disease == !!disease) %&gt;%
pull(n)
n_total &lt;- percentage_df %&gt;%
filter(disease == !!disease) %&gt;%
pull(n_total)
res &lt;- prop.test(x = n_success, n = n_total) %&gt;%
broom::tidy() %&gt;%
mutate(disease = disease)
}) %&gt;%
bind_rows() %&gt;%
select(-c(contains(&quot;conf&quot;), &quot;method&quot;, &quot;parameter&quot;, &quot;alternative&quot;))

虽然上述方法很简单，但我觉得我缺少一种更简化的方法，可以通过一次测试抓住分析的本质。
有人对这种情况下可能更有效的统计方法有什么建议或见解吗？
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/650886/compare-the-proportion-of-multiple-diseases-between-2-groups</guid>
      <pubDate>Thu, 11 Jul 2024 15:35:40 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据中非常特殊的平台期</title>
      <link>https://stats.stackexchange.com/questions/650885/very-specific-plateaus-in-time-series-data</link>
      <description><![CDATA[我正在查看不同管道中水深的时间序列数据。有一种罕见的情况，即大量的水试图进入管道，但由于管道已满，水会流到其他地方，这是一个问题。这种情况只发生在水位比正常水平高很多的时候。考虑到这一点，我决定使用 z 分数来尝试创建一个模型来检测这种情况何时发生。我还需要能够在实时数据上检测这些。我遇到的问题是，通过今年早些时候的一场风暴中的几个例子，z 分数似乎变化很大，所以我想知道是否有办法可以缩放它，以便我可以找到一个准确的阈值来预测未来的这种情况？以下是我计算的一些可能有用的值：
名称：管道 1
所有值的平均值：1.6845702429333351
高于阈值的 z 分数的平均值：38.66435012815608
高于 z 分数阈值的值的平均值：99.30582815151514
高于阈值的计数：33
高于 95 的值的数量：23
名称：管道 2
所有值的平均值：8.057098070279554
高于阈值的 z 分数的平均值：22.411958576390177
高于 z 分数阈值的值的平均值：101.77036324675325
高于阈值的计数：77
高于 95 的值的数量： 48
名称：管道 3
所有值的平均值：2.8228191822640967
高于阈值的 z 分数的平均值：15.52506391321617
高于 z 分数阈值的值的平均值：98.46318181818182
高于阈值的计数：22
高于 95 的值的数量：23

在此示例中，我的 z 分数阈值设置为 15。如您所见，z 分数从 15 到接近 40 不等，第一个管道甚至达到超过 50 z 分数。如果该值在一段时间内很高，我想这是有道理的，但我不确定如何在模型中解释这一点。我也在寻求有关实际预测这些事件的建议，以及最好的方法是什么，或者是否只需找到一个合适的阈值即可。我是否能够根据先前的值为每个管道计算出一个好的阈值？还有许多其他管道，但这种情况的例子很少。]]></description>
      <guid>https://stats.stackexchange.com/questions/650885/very-specific-plateaus-in-time-series-data</guid>
      <pubDate>Thu, 11 Jul 2024 15:21:54 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系仍然成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    <item>
      <title>具有随机效应的多元负二项式协方差</title>
      <link>https://stats.stackexchange.com/questions/650882/covariance-of-multivariate-negative-binomial-with-random-effects</link>
      <description><![CDATA[我正在拟合一个负二项式-2 回归模型，其中有一个多元正态随机效应项。我想找到两个结果的协方差方程。在“多元泊松对数正态分布”中，Atchison 和 Ho 找到了泊松分布的解，但我想将其扩展到负二项式，但我找不到任何以前的研究。
$$
Y_{i} \sim \text{negative-binomial}(\mu_{i} = \exp(X_i^T \beta + \phi_i), \theta) \text{ for } i = 1..n\\
% \log \left[\mathbb{E}(​​Y_{i}) \right] = X_{i}^T \beta^{\text{c}}_i + \phi_{i}\\
\phi \sim \mathcal{N}(0, \Sigma) \\
\Sigma \in \mathbb{R}^{n x n}
% \phi_{.,t}|\phi_{.,t-1} \sim \mathcal{N}(\alpha^{\text{c}} \phi_{.,t-1}, \tau^2 \tilde{Q}^{-1}) \\
$$
什么是$Cov(Y_i, Y_j)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/650882/covariance-of-multivariate-negative-binomial-with-random-effects</guid>
      <pubDate>Thu, 11 Jul 2024 14:33:13 GMT</pubDate>
    </item>
    </channel>
</rss>