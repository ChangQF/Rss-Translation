<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 12:31:34 GMT</lastBuildDate>
    <item>
      <title>LGBM 回归器中的残差随预测值范围而变化</title>
      <link>https://stats.stackexchange.com/questions/653849/residuals-changes-with-predicted-values-range-in-lgbm-regressor</link>
      <description><![CDATA[我正在做一个回归问题，其中目标变量的范围在 0.01 到 0.15 之间。当预测值在 0.1 左右时，模型给出最佳值。绘制残差似乎显示出异方差。但是我找不到解决这个问题的方法。是否有任何进一步的步骤来分析和调试这个]]></description>
      <guid>https://stats.stackexchange.com/questions/653849/residuals-changes-with-predicted-values-range-in-lgbm-regressor</guid>
      <pubDate>Wed, 04 Sep 2024 12:14:35 GMT</pubDate>
    </item>
    <item>
      <title>我的 Javascript 神经网络没有按预期学习</title>
      <link>https://stats.stackexchange.com/questions/653848/my-javascript-neural-network-is-not-learning-as-expected</link>
      <description><![CDATA[我正在用 JavaScript 创建一个神经网络类来解决一个简单的问题，例如 XOR。问题是，无论训练迭代次数如何，训练后预测的值总是在 0.5 左右。我相当确定问题出在网络的反向传播中。
我搜索了参考资料并检查了运行中的神经网络代码，但无法确定问题所在。
这是神经网络类：

function sigmoid(x) {
return 1 / (1 + Math.exp(-x));
}

function sigmoid_d(x) {
let s = sigmoid(x);
return s * (1 - s);
}

class NeuralNetwork {
constrained_size, hidden_​​size, output_size) {
this.input_size = input_size;
this.hidden_​​size = hidden_​​size;
this.output_size = output_size;
this.input = [];

// 初始化权重并随机化
this.weights_ih = new Matrix(this.hidden_​​size, this.input_size); // 输入层和隐藏层之间的权重
this.weights_ho = new Matrix(this.output_size, this.hidden_​​size); // 隐藏层和输出层之间的权重
this.weights_ih.randomize();
this.weights_ho.randomize();

// 初始化偏差
this.bias_h = new Matrix(this.hidden_​​size, 1);
this.bias_o = new Matrix(this.output_size, 1);
this.bias_h.randomize();
this.bias_o.randomize();

this.learning_rate = 0.1;
}

feedForward(inputs, weights, bias) {
let output = Matrix.multiply(weights, input);
output.add(bias);
output.map(sigmoid);

return output;
}

fullFeedForward(inputs) {
inputs = Matrix.fromArray(inputs);
let hidden = this.feedForward(inputs, this.weights_ih, this.bias_h);
let output = this.feedForward(hidden, this.weights_ho, this.bias_o);

return output;
}

train(inputs, target) {
// 将数组转换为矩阵
inputs = Matrix.fromArray(inputs);
target = Matrix.fromArray(targets);

// 通过网络传播并记录每层的输出
let hidden = this.feedForward(inputs, this.weights_ih, this.bias_h);
let output = this.feedForward(hidden, this.weights_ho, this.bias_o);

// 计算输出层的误差
let output_errors = Matrix.subtract(targets, output);

// 计算输出梯度
let gradients = Matrix.map(outputs, sigmoid_d);
gradients.multiply(output_errors);
gradients.multiply(this.learning_rate);

// 计算隐藏增量
let hidden_​​T = Matrix.transpose(hidden);
let weight_ho_deltas = Matrix.multiply(gradients, hidden_​​T);

// 调整权重和偏差
this.weights_ho.add(weight_ho_deltas);
this.bias_o.add(gradients);

// 计算隐藏层的误差
let weights_ho_T = Matrix.transpose(this.weights_ho);
let hidden_​​errors = Matrix.multiply(weights_ho_T, output_errors);

// 计算隐藏梯度
let hidden_​​gradient = Matrix.map(hidden, sigmoid_d);
hidden_​​gradient.multiply(hidden_​​errors);
hidden_​​gradient.multiply(this.learning_rate);

// 计算输入增量
let input_T = Matrix.transpose(inputs);
let weight_ih_deltas = Matrix.multiply(hidden_​​gradient, input_T);

this.weights_ih.add(weight_ih_deltas);
this.bias_h.add(hidden_​​gradient);
}

}

以下是主要代码
const nn = new NeuralNetwork(2, 2, 1);

let input = [[1, 0], [0, 1], [1, 1], [0, 0]];
让目标 = [[1], [1], [0], [0]];

for(让 i = 0; i &lt; 50000; i++) {
让 random_index = Math.floor(Math.random() * 输入.length);
nn.train(输入[random_index], 目标[random_index]);
}

nn.fullFeedForward([1, 0]).print();
nn.fullFeedForward([0, 1]).print();
nn.fullFeedForward([1, 1]).print();
nn.fullFeedForward([0, 0]).print();
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653848/my-javascript-neural-network-is-not-learning-as-expected</guid>
      <pubDate>Wed, 04 Sep 2024 12:09:36 GMT</pubDate>
    </item>
    <item>
      <title>WGEE 中因死亡或住院而删除数据</title>
      <link>https://stats.stackexchange.com/questions/653847/drop-out-data-due-to-death-or-hospitalization-in-wgee</link>
      <description><![CDATA[我有一个 RCT 数据集，其中包含 60 岁或以上的老年人，他们因心血管事件住院，并在进入研究之前出院。参与者被随机分配到对照组或治疗组，为期 12 个月。我想估计干预对一些次要结果（连续）的影响，包括生活质量和孤独感，以及一些生物标志物（HbA1c、CRP 等）。
问题是由于再次入院或死亡而缺少观察值。我想通过加权 GEE 来解决这个问题，但我看到的关于由于再次入院或死亡而导致的结构性辍学的文献很少，我也不知道 R 中有任何函数可以直接处理这个问题。有没有关于 R 中可以充分处理这个问题的包的建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/653847/drop-out-data-due-to-death-or-hospitalization-in-wgee</guid>
      <pubDate>Wed, 04 Sep 2024 11:36:41 GMT</pubDate>
    </item>
    <item>
      <title>带有和不带有样条函数的 coxPH 模型的非线性解释</title>
      <link>https://stats.stackexchange.com/questions/653846/interpretation-of-coxph-model-with-and-without-splines-for-non-linearity</link>
      <description><![CDATA[我正在拟合 Cox 比例风险模型，以调查外部军事支持（我的协变量）对内战后和平协议（我感兴趣的事件）的“风险”的影响。
我预计更高的军事支持会降低和平协议的风险。在建模之前，我绘制了累积发生率函数，以了解数据中发生的情况，下图和风险表似乎证实了我的预期：
1]1
我建立了第一个基本 Cox 模型。我会从这个结果解释，支持确实显著降低了案件从状态 1（战斗）过渡到状态 2（和平协议）的风险：
support_fit1 &lt;- coxph(Surv(tstart, tstop, consequence_event) ~ avg_support_per_year,data = only_major_dyads_set, id = dyad_id, istate = istate)
summary(support_fit1)
调用：
coxph(formula = Surv(tstart, tstop, consequence_event) ~ avg_support_per_year, 
data = only_major_dyads_set, id = dyad_id, istate = istate)

n= 395, 事件数= 212 

coef exp(coef) se(coef) robust se z Pr(&gt;|z|)
avg_support_per_year_1:2 -0.1203942 0.8865708 0.0452338 0.0469175 -2.566 0.0103 *
avg_support_per_year_1:3 -0.0004054 0.9995946 0.0220274 0.0218498 -0.019 0.9852 

现在，正如我从上图所想的那样，这种影响可能是非线性的，我首先使用 cox.zph 测试了比例风险假设
&gt; support_zp &lt;- cox.zph(support_fit1)
&gt; support_zp
chisq df p
avg_support_per_year_1:2 0.03614 1 0.85
avg_support_per_year_1:3 0.00172 1 0.97
GLOBAL 0.03786 2 0.98

尽管结果没有表明这一点，我仍然在第二个模型中实施了 12 个月时结点的自然三次样条函数，以检查非线性效应。
only_major_dyads_set &lt;- only_major_dyads_set %&gt;%
mutate(time_spline_1 = ns(tstop, knots = 12)[, 1],
time_spline_2 = ns(tstop, knots = 12)[, 2])

support_fit2 &lt;- coxph(Surv(tstart, tstop, consequence_event) ~ avg_support_per_year +
avg_support_per_year:time_spline_1 + 
avg_support_per_year:time_spline_2,
data = only_major_dyads_set, id = dyad_id, istate = istate)

&gt; summary(support_fit2)
调用：
coxph(formula = Surv(tstart, tstop, consequence_event) ~ avg_support_per_year + 
avg_support_per_year:time_spline_1 + avg_support_per_year:time_spline_2, 
data = only_major_dyads_set, id = dyad_id, istate = istate)

n= 395, 事件数= 212 

coef exp(coef) se(coef) robust se z Pr(&gt;|z|) 
avg_support_per_year_1:2 0.11671 1.12379 0.06016 0.06513 1.792 0.0731 . 
avg_support_per_year：time_spline_1_1：2 -1.60309 0.20127 0.40637 0.39979 -4.010 6.08e-05 ***
avg_support_per_year：time_spline_2_1：2 -0.50001 0.60652 1.03835 0.82466 -0.606 0.5443 
avg_support_per_year_1：3 0.25356 1.28860 0.02781 0.02691 9.421 &lt; 2e-16 ***
avg_support_per_year:time_spline_1_1:3 -2.02472 0.13203 0.18918 0.26033 -7.778 7.39e-15 ***
avg_support_per_year:time_spline_2_1:3 0.04356 1.04452 0.30711 0.22598 0.193 0.8472

您如何解释第二个模型的结果？我的直觉是，支持的主要影响现在只是略微显著，但即使现在也是正向的（因此更高的支持率更有可能达成和平协议）？与第一个样条线（第二行）的显著负向相互作用是否仅告诉我影响会随着时间的推移而减小？最让我困惑的是，第一个模型的效果似乎被逆转了。实现样条线是否可取，因为上面的 cox.zph() 表示不需要？（但是，AIC(support_fit1) = 1923.281，而 AIC(support_fit2) = 1614.28）。
任何关于这些方面的见解都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653846/interpretation-of-coxph-model-with-and-without-splines-for-non-linearity</guid>
      <pubDate>Wed, 04 Sep 2024 11:28:51 GMT</pubDate>
    </item>
    <item>
      <title>如何对数据进行建模，其中个体可能属于数据中的多个组，但更可能只出现一次？</title>
      <link>https://stats.stackexchange.com/questions/653845/how-to-model-data-where-an-individual-could-be-in-more-than-one-group-within-the</link>
      <description><![CDATA[我有多个具有不同指标症状/事件的患者队列，并且希望预测每个单独队列的癌症风险，包括某些感兴趣的协变量，以查看哪些指标事件和协变量的组合会带来最高风险。但是，某些队列的样本量非常小，因此我一直在研究将所有队列合并到一个数据框中，以提高系数估计的置信度。有一个“随机”组我想用它来模拟基线风险，但是，从这个组中选择了几个队列，因此患者 ID 100% 重叠。其他一些队列与这个基线组更加不同，重叠的患者更少。
数据框看起来像：



患者
群组
性别
吸烟状况
体重指数
贫血
血小板计数
白细胞计数
咳嗽
呕吐
体重减轻
食欲不振
消化不良
腹痛




001
1 
1
2
3
0
0
1
1
0
1
1
0
1


002
1
1
3
2
0
1
0
0
1
0
0
0
1



总体合并样本量约为 130 万，其中约有 90 万名独特患者。每个指数队列的规模从约 2000 名患者到约 45 万名患者不等。随机样本约为 45 万名患者。此外，癌症结果在人群中非常罕见，从一个队列中的约 0.2% 到发​​病率最高的队列中的 3.4% 不等。
有人建议我使用混合效应模型，患者 ID 是随机效应，并包括一列表示队列成员身份。但是，即使是最简单的模型形式也会导致较大的 RE SD 和风险预测，这些预测基于先前的知识和单个队列模型是不准确的。
我以前只使用 ME 模型来对个体随时间变化的多个测量值进行建模，而这些数据更具横断面性，大多数患者没有多个测量值。
我正在考虑对随机样本进行子抽样，然后从主要队列中移除这些患者以运行正常的 glm()，但有没有更好的模型形式？混合效应模型是否适用于我的数据？
希望这些信息足够了，但如果我遗漏了什么，我可以提供更多信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/653845/how-to-model-data-where-an-individual-could-be-in-more-than-one-group-within-the</guid>
      <pubDate>Wed, 04 Sep 2024 10:38:52 GMT</pubDate>
    </item>
    <item>
      <title>你能帮我计算接吻问题右侧偏好中的卡方吗？</title>
      <link>https://stats.stackexchange.com/questions/653843/could-you-help-me-with-calculating-chi-square-in-this-right-side-preference-whil</link>
      <description><![CDATA[这是一篇来自《自然》杂志的著名文章：链接
作者观察了 124 对情侣。其中 80 对接吻时将头移到右侧。其余 44 对接吻时将头移到左侧。
当我使用 50% 预期频率 (62 + 62) 计算卡方统计量时，我得到的卡方统计量为 10.45。但本文报告的卡方统计量为 5.34。
我的计算：




右
左




观察值
80
44


预期值
62
62



$\chi^2 = \frac{(80-62)^2}{62} + \frac{(44-62)^2}{62}$
$\chi^2 = 10.45 $
我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653843/could-you-help-me-with-calculating-chi-square-in-this-right-side-preference-whil</guid>
      <pubDate>Wed, 04 Sep 2024 10:24:23 GMT</pubDate>
    </item>
    <item>
      <title>我们如何从监督（条件）学习环境中的负对数似然中得出标准交叉熵损失？</title>
      <link>https://stats.stackexchange.com/questions/653842/how-do-we-derive-the-standard-cross-entropy-loss-from-negative-log-likelihood-in</link>
      <description><![CDATA[我知道在优化神经网络（监督）时，交叉熵损失等同于负对数似然，与 MLE 等同，但我无法将所有数学知识整合在一起。
我试图找出如何使用条件概率从负对数似然 (NLL) 到交叉熵损失 (CE) 进行监督学习。如何从 $\log q(y_n|x_n, \omega)$ 得到 $y_n \log \hat{y}_n$ ？
以下符号来自 Murphy 的《概率机器学习》一书：

简介&#39;：有一个概率模型 $q(D, \omega)$，用于监督学习数据集 $D=\{(x_n, y_n)_{n=1}^N\}$，其中有 $N$ 个样本（$\omega$ 为参数）
$$
q(\omega|X,Y) = \frac{q(Y|X,\omega)\cdot q(\omega)}{q(Y|X)}
$$
和经验分布（在观察到的训练点处的一系列 delta 函数或“尖峰”）
$$
\begin{eqnarray}
p_D(x,y) = \frac{1}{N} \sum_{n=1}^N \delta(x-x_n) \delta(y-y_n), \\
\delta(x) = \begin{cases}
\infty &amp; \text{if } x = 0\\
0 &amp; \text{if } x \neq 0 
\end{cases}, \quad \int_{-\infty}^{\infty} \delta(x)dx = 1
\end{eqnarray}
$$
在书中，Murphy 从 Kullbach-Leibler 散度的期望值中推导出 NLL。
\begin{align}
\hat{\omega} &amp;= \arg \min_\omega \mathbb{E}_{p_D (x)} [ D_{KL} (p_D(Y|x)||q(Y|x, \omega)] \\
&amp;= \arg \min_\omega -\sum_x p_D (x) \cdot \sum_y p_D(y|x) \log q(y|x, \omega) \quad \textit{(dropped const entropy)}\\
&amp;= \arg \min_\omega -\sum_{x,y} p_D (x,y) \log q(y|x, \omega)\\
(&amp;= \arg \min_\omega -\sum_{n=1}^N \underbrace{p_D (x_n,y_n)}_{=\textit{const}} \log q(y_n|x_n, \omega) \quad \textit{(此行不在书中))}\\
&amp;= \arg \min_\omega - \frac{1}{N}\sum_{n=1}^N \underbrace{\log q(y_n|x_n, \omega)}_{\textit{这似乎是 $y_n \log \hat{y}_n$，但如何？}} \quad \text{是 NLL}
\end{align&gt;


这是我尝试过的：
$$
p_D(x) = \frac{1}{N} \sum_{n=1}^N \delta(x-x_n)
$$
\begin{align}
\hat{\omega} &amp;= \arg \min_\omega \mathbb{E}_{p_D (x)} [ D_{KL} (p_D(Y|x)||q(Y|x, \omega)] \\
&amp;= \arg \min_\omega -\sum_x p_D (x) p_D(Y|x) \log q(Y|x, \omega) \quad \textit{(dropped const entropy)}\\
&amp;= \arg \min_\omega -\sum_{n=1}^N \underbrace{p_D(x_n)}_{=const} \underbrace{p_D(Y|x_n)}_{=y_n?} \log \underbrace{q(Y|x_n, \omega)}_{=\hat{y}_n?}
\end{align&gt;

问题：

这样对吗？如果是，我的符号是否正确（小写字母和大写字母）？
为什么您要采用 KLD 的预期值而不是使用普通的 KLD？
我理解 $q(y|x_n, \omega)$ 是输入 $x_n$ 的模型输出 $\hat{y_n}$，但您如何计算 $q(y_n|x_n, \omega)$？——据我理解，这是我的模型实际预测真实标签的可能性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653842/how-do-we-derive-the-standard-cross-entropy-loss-from-negative-log-likelihood-in</guid>
      <pubDate>Wed, 04 Sep 2024 10:23:41 GMT</pubDate>
    </item>
    <item>
      <title>如果没有给出 p 值和其他信息，则决定是否拒绝 $H_{0}$</title>
      <link>https://stats.stackexchange.com/questions/653841/decide-on-h-0-rejection-if-p-value-and-further-information-is-not-given</link>
      <description><![CDATA[我尝试回答以下教科书问题：
如果我运行如下测试
set.seed(123)
DescTools::VarTest(rnorm(100, mean = 3, sd = sqrt(4)), sigma.squared = 3)

给出
 方差单样本卡方检验

数据：rnorm(100, mean = 3, sd = sqrt(4))
X-squared = 148.7, df = 99, p-value = 0.001387
备选假设：真实方差不等于 3
95% 置信区间：
3.473594 6.080687
样本估计：
x 的方差 
4.505917 

如果输出为，我该如何获得测试决策
数据：...........................
X 平方 = 148.7，df = 99，p 值 = ........
备选假设：真实方差 ........ 3
95% 置信区间：
3.473594 6.080687
样本估计：
x 的方差 
4.505917 

相反。此外，是否有可能争论测试是左、右还是双面？

编辑：
我怀疑，我使用哪种测试并不重要，例如
t.test(1:10, y = c(7:20)) 
t.test(1:10, y = 2:11)

可能是替代方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/653841/decide-on-h-0-rejection-if-p-value-and-further-information-is-not-given</guid>
      <pubDate>Wed, 04 Sep 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯反演与校准</title>
      <link>https://stats.stackexchange.com/questions/653839/bayesian-inversion-vs-calibration</link>
      <description><![CDATA[假设我们有一个计算机模型 $G$，其输入为 $\theta$，并且假设我们有一些数据 $\mathbf{y}$。假设 $$\mathbf{y} = G(\theta) + \eta, $$，其中 $\eta$ 对应于噪声，并且具有已知概率密度 $f_{\eta}$，并且该分布独立于 $\theta \sim f_\theta$。然后我们使用贝叶斯规则得到$$ f_{\theta|\mathbf{y}}(.) \propto f_{\eta}(\mathbf{y} - G(\theta))f_{\theta}(.)$$
这是执行贝叶斯反演时的典型设置，我们通常使用 MCMC 设备估计密度$f_{\theta|\mathbf{y}}$。
这与 Kennedy 和 O&#39;Hagan 在他们 2002 年的开创性论文中定义的计算机模型的贝叶斯校准之间是否存在概念差异（https://www.asc.ohio-state.edu/statistics/comp_exp/jour.club/kennedy01.pdf）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653839/bayesian-inversion-vs-calibration</guid>
      <pubDate>Wed, 04 Sep 2024 10:03:18 GMT</pubDate>
    </item>
    <item>
      <title>根据时间序列数据建立二元选择决策模型</title>
      <link>https://stats.stackexchange.com/questions/653838/model-binary-choice-decision-from-time-series-data</link>
      <description><![CDATA[我正在寻找一些建议来对以下决策问题进行建模：
在随机对照试验中，受试者在做决定时有两种选择。决策过程可能需要几秒钟。在试验期间，记录了受试者的时间序列数据（~10 Hz）；这些数据通常随时间缓慢变化（主要表示身体运动）。我不知道受试者在进行试验时的决定，但我知道每次试验结束时的决定。
我所追求的是该二元选择决策的模型，该模型也可用于预测任何给定时间新数据的决策结果（理想情况下甚至是其概率/不确定性/时间）。任何想法/建议（理想情况下包括软件包）都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653838/model-binary-choice-decision-from-time-series-data</guid>
      <pubDate>Wed, 04 Sep 2024 09:41:45 GMT</pubDate>
    </item>
    <item>
      <title>双样本 Kolmogorov-Smirnov、双样本 Anderson-Darling 和（双样本）Wilcoxon 秩和检验的零假设</title>
      <link>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</link>
      <description><![CDATA[据我所知，双样本 Kolmogorov-Smirnov (KS) 检验和双样本 Anderson-Darling (AD) 检验的零假设 $H_0$ 是相同的，即两个样本来自同一分布/总体。
我们可以说（双样本）Wilcoxon 秩和 (WRS) 检验的零假设 $H_0$ 与 KS 和 AD 检验的零假设相同，只是“附加条件”是两个样本的中位数应该相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</guid>
      <pubDate>Wed, 04 Sep 2024 09:23:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用“lme4”R 包中的 lmer() 最好地拟合我的线性混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/653836/how-do-i-best-fit-my-linear-mixed-effect-model-with-lmer-from-the-lme4-r-pac</link>
      <description><![CDATA[所以，我对 R 和使用“lme4”包中的 lmer 进行建模还很陌生。我希望得到一些帮助，了解如何拟合我的模型来回答我的研究问题；不同的抓取类型是否具有可比性，即抓取是否会对我的响应变量丰度、生物量和底栖无脊椎动物的物种丰富度产生影响。我想比较使用 van Veen 抓取的常见软沉积物采样方法是否与使用另一种称为 Ekman 抓取的采样方法不同。
我有使用两个抓取器在三个不同站点（深度不同）对底部沉积物进行现场采样的数据，我在每个站点使用 Ekman 采集了 10 个样本，使用 van Veen 采集了 5 个样本。所以，总共有 45 个样本；30 个使用 Ekman，15 个使用 van Veen。我只对抓取对响应变量的影响感兴趣，但我想在我的模型中考虑站点之间的差异。这是使用 lmer() 的合理模型拟合吗？我想考虑站点的随机截距，以及抓取和站点之间可能的相互作用。或者其他模型更合适？这不是一个非常复杂的模型，我只有两个因素，但我不确定如何以最佳方式拟合我的模型。如果我想将“站点”视为随机的，那么相互作用也应该是随机的吗？谢谢！
lmer.model5 &lt;- lmer(Abundance ~ Grab + (1|Station) + (1|Grab:Station)
我尝试过拟合几个模型，但不确定要使用哪一个。我需要一些关于如何拟合模型来回答我的研究问题的指导。
lmer.model1 &lt;- lmer(Abundance ~ Grab + (1|Station))
lmer.model2 &lt;- lmer(Abundance ~ Grab * Station + (1|Station))
lmer.model3 &lt;- lmer(Abundance ~ Grab + Station + (1|Station))
lmer.model4 &lt;- lmer(Abundance ~ Grab + (Grab|Station))
lmer.model5 &lt;- lmer(Abundance ~ Grab + (1|Station) + (1|Grab:Station))
交叉发布]]></description>
      <guid>https://stats.stackexchange.com/questions/653836/how-do-i-best-fit-my-linear-mixed-effect-model-with-lmer-from-the-lme4-r-pac</guid>
      <pubDate>Wed, 04 Sep 2024 09:10:43 GMT</pubDate>
    </item>
    <item>
      <title>训练准确率提高至 99%，但验证准确率停止得更早</title>
      <link>https://stats.stackexchange.com/questions/653835/training-accuracy-increases-up-to-99-but-validation-accuracy-stops-much-earlier</link>
      <description><![CDATA[我尝试使用自己实现的 Resnet 模型对 CIFAR-100 数据集进行分类。
我尝试了多种不同的超参数配置，更改了学习率、批量大小、辍学率、数据增强和正则化，但我所做的一切都无法将验证准确率提高 40% 以上，而训练准确率可以达到 99%。
我意识到训练准确率高但验证准确率低是过度拟合的标志，但在增加正则化参数和辍学率后，我仍然没有看到任何改善。训练、验证和测试的分割由 CIFAR-100 提供，因此分别为 40000、10000、10000。
有人知道如何突破这个瓶颈吗？或者有人知道我哪里可能出错了吗？
以下是我一直在尝试的超参数类型：
learning_rates = [0.001, 0.0001]
batch_sizes = [16, 32]
dropout_rates = [0.3,0.5]
decay = [0.001, 0.0001]
optimiser = [&#39;Adam&#39;, &#39;SGD&#39;]

以下是我一直在增强数据的方式：
transform = transforms.Compose([
transforms.RandomCrop(32, padding=4),
transforms.RandomHorizo​​ntalFlip(),
transforms.RandomRotation(10),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

DATA_ROOT_FOLDER = &#39;./cifar-100-python&#39; 

train_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=True, download=True, transform=transform)
test_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=False, download=True, transform=transform)

train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)

batch_size = 64
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)

这些是我得到的结果。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653835/training-accuracy-increases-up-to-99-but-validation-accuracy-stops-much-earlier</guid>
      <pubDate>Wed, 04 Sep 2024 09:00:43 GMT</pubDate>
    </item>
    <item>
      <title>不同维度的聚类之间 x-means 的 BIC 和似然分数是否可以比较？</title>
      <link>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</link>
      <description><![CDATA[我目前正在实施 x-means 变体，在计算贝叶斯信息准则的对数似然（通过 scipy 的多元正态 logpdf）时遇到了问题，该问题在低空间集群上失败。
用例是通过 3D 笛卡尔坐标对地理点进行类似 k-means 的聚类，但具有可配置的最大 k 个集群。坐标系以 (0,0,0) 为地球中心，所有点都相距约 6371 个单位。因此，集群可以是平坦的、非常弯曲的，甚至有点像 1D，但永远不会是真正的 3D 高斯。因此，目前的计划是在计算 BIC 分数时尝试通过子集群上的 PCA 进行降维。
问题是：当使用此实现（大概基于 Ishioka (2000) 的扩展）时，不同维度的集群之间的 BIC 和对数似然分数是否最具有可比性？请注意，此实现在单个集群上计算 BIC，然后通过它们单独缓存的协方差/似然/BIC 对 2 个新集群执行某种合并的 BIC。
如果不是，最大 k 聚类的其他选项可能是什么（替代似然函数、聚类算法等）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</guid>
      <pubDate>Wed, 04 Sep 2024 08:58:43 GMT</pubDate>
    </item>
    <item>
      <title>当交错 DID 是我的主要经验方法时，有哪些适当的方法进行稳健性检验？</title>
      <link>https://stats.stackexchange.com/questions/653833/what-are-the-appropriate-methods-to-do-robustness-check-when-a-staggered-did-is</link>
      <description><![CDATA[我正在研究一项健康政策对健康结果指标的因果影响。一个国家的不同地区在不同的时间点采用这项政策，这是使用交错差异法估计该政策因果影响的理想环境。我还想做一些稳健性检验，以表明我的结果对我使用的计量经济学方法具有稳健性。我可以考虑哪些合理的替代方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653833/what-are-the-appropriate-methods-to-do-robustness-check-when-a-staggered-did-is</guid>
      <pubDate>Wed, 04 Sep 2024 08:29:51 GMT</pubDate>
    </item>
    </channel>
</rss>