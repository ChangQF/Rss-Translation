<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 03 Apr 2025 12:36:01 GMT</lastBuildDate>
    <item>
      <title>为什么可能的精度如此之差？</title>
      <link>https://stats.stackexchange.com/questions/663451/why-likelihood-have-such-poor-precision</link>
      <description><![CDATA[ 相同的数据与两个不同的正常分布相匹配，可能性数非常相似。
数据 -  AMD股票的年收益，历史和近期波动率和无风险率作为平均值（全部在日志转换之后）。
The mean is the same for both distributions, the sigmas - numbers in hist and recent columns - are visibly different, like 0.594 and 0.844, yet, if we calculate log likelihood $E[log p(x)]$ for the these two distributions, it will be almost相同的 llh最近：-1.0211  vs  llh历史：-0.9591 。
 历史LR_ACTUAL LRF_RETURN最近
0.594 -0.017 0.02 0.556
0.594 0.477 0.011 0.693
0.594 0.933 0.012 0.771
0.594 1.337 0.005 0.844
0.594 1.414 0.004 0.865
...
 
 为什么？这是很小的差异，如果我们考虑这两个分布 - 差异很大，一个用于股票的完整历史，而另一种则改变了，但是，可能性几乎相同？！！
甚至很奇怪，它表明，仅静态数字，全部库存历史记录 LLH历史记录：-0.9591 ，预测未来的回报比库存更高的库存近期波动率 llh最近：-1.0211 。那是不正确的：）。
此数据集来自非固定随机过程，因此，当我们计算可能性时，每个点都会更改分布。我不确定是否可以通过这种方式计算可能性？ （如果没有，可以使用什么？）。
 
和用于计算的Python代码a）日志似然和b）将其归一化为 log pseudo pseudo概率：
 导入pandas作为pd
导入numpy作为NP
从scipy.stats进口规范

def mean_log_pseudo_prob_and_loglh（df，nee_col，sigma_col，actual_col）：
  ＃原始可能性
  lh = norm.pdf（df [muthate_col]，loc = df [mean_col]，scale = df [sigma_col]）
  log_lh = np.log（LH）

  ＃标准化的伪探针
  pseudo_prob = lh / lh.sum（）
  log_pseudo_prob = np.log（pseudo_prob）

  ＃返回：平均日志伪游行和预期的日志可能性
  返回log_pseudo_prob.mean（），log_lh.mean（）

＃阅读数据
df = pd.read_csv（&#39;tmp/data.tsv&#39;，sep =&#39;\ t&#39;）

＃计算值
a_lpp，a_llh = mean_log_pseudo_prob_and_loglh（df，&#39;lrf_return&#39;，&#39;aster&#39;s&#39;，&#39;lr_actual&#39;）
b_lpp，b_llh = mean_log_pseudo_prob_and_loglh（df，&#39;lrf_return&#39;，&#39;hist&#39;，&#39;lr_actual&#39;）

打印（&#39;a：&#39;）
print（f&#39;E [log pseudo-prob]：{a_lpp：.4f}&#39;）
print（f&#39;E [log -libiles]：{a_llh：.4f}&#39;）

打印（&#39;B：&#39;）
打印（f&#39;E [log pseudo-prob]：{b_lpp：.4f}&#39;）
print（f&#39;E [log -libiles]：{b_llh：.4f}&#39;）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663451/why-likelihood-have-such-poor-precision</guid>
      <pubDate>Thu, 03 Apr 2025 12:05:51 GMT</pubDate>
    </item>
    <item>
      <title>样本量低后，量化不确定性</title>
      <link>https://stats.stackexchange.com/questions/663449/quantifying-uncertainty-after-friedman-test-with-low-sample-size</link>
      <description><![CDATA[我们正在测试使用两个顺序过滤器过滤湖水的水过滤机。目的是确定机器是否有效去除某些化学物质。
为了测试这一点，我们每天收集三个水样，持续六天：
未过滤的水（进入机器之前）
曾经过滤的水（第一个过滤器之后）
两次过滤的水（第二个过滤器之后）
由于湖中的化学浓度每天都有不同，因此应将在同一天收集的样品作为一组。这意味着我们有六组三个配对样品（每天一个）。
统计方法
为了确定过滤过程是否显着改变了化学浓度，我们进行了弗里德曼测试。该测试检查了在六天的未过滤，曾经过滤和两次过滤的水之间是否存在系统的差异。
结果，在校正多次测试后，我们获得了具有相应P值的化学物质列表。
关注：小样本量
由于我们只有六个配对样品（n = 6天），因此我们预计很高的风险是：
误报（I型错误）：检测不是真实的效果。
假否定性（II型错误）：无法检测到实际效果。
这使我们的结果不那么可靠，我们需要一种量化这种不确定性的方法。
如何解释样本量较小的结果？
置信区间将很有用，但是我们的数据不遵循正态分布（其中包含多个不是真实异常值的极端值）。
相反，我们正在考虑估计最小可检测差的差异 - 弗里德曼测试可以可靠地检测到80％功率在α= 0.05时可靠地检测到的最小化学浓度变化，给定n = 6。
这可能吗？如果是这样，怎么样？
考虑到我们的样本量和显着性水平，是否可以计算每种化学物质的最小检测差？如果是这样，我们该如何计算？
 r用于分析数据]]></description>
      <guid>https://stats.stackexchange.com/questions/663449/quantifying-uncertainty-after-friedman-test-with-low-sample-size</guid>
      <pubDate>Thu, 03 Apr 2025 11:47:15 GMT</pubDate>
    </item>
    <item>
      <title>间隔审查时间较弱的事件数据的时间</title>
      <link>https://stats.stackexchange.com/questions/663446/interval-censored-time-to-event-data-with-frailty-term</link>
      <description><![CDATA[我有在3年期间收集的6个月间隔，旨在估算特定事件的时间。我们假设数据是间隔审查的，这意味着已知事件的情况属于两个随访访问之间。样本中的一些参与者收集了2眼的数据，而另一些参与者只有一只眼睛的数据。我正在寻找一个统计模型，该模型可容纳两种审查结果数据的间隔性质，并使我能够占据脆弱的术语以说明患者内聚类吗？我遇到了使用IC_SP（）或IC_PAR（）函数的贝叶斯模型以及ICENREG套件，以适合半参数和参数模型，但从文档中尚不清楚IC_SP（）如何实现脆弱的术语，我担心试图在诸如脆弱的术语中不得不产生Intera dymented Intera-correlation correlation。
例如。我运行了模型：
 fit_semiparametric＆lt;  -  ic_sp（surn，start，end，type =; interval2＆quot; quast2＆quot;
此运行并产生了一些输出，但是从文档中，尚不清楚模型中是否或如何处理脆弱（患者）项。
我还使用FrailTypenal（）遇到了R中的FrailTypack软件包，但一直在努力使其运行，并且由于我们有单个集群观察，因此尚不清楚是否对建模可能是有问题的。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663446/interval-censored-time-to-event-data-with-frailty-term</guid>
      <pubDate>Thu, 03 Apr 2025 10:21:23 GMT</pubDate>
    </item>
    <item>
      <title>根据Royston-Parmar模型的暴露水平估计时间依赖时间危险比的差异</title>
      <link>https://stats.stackexchange.com/questions/663444/difference-in-the-time-dependent-hazard-ratios-estimates-according-to-exposure-l</link>
      <description><![CDATA[我很难理解为什么根据我选择的曝光水平，我的stpm2模型中时间相关的协变量的危险比有所不同。
我遵循RSTPM2软件包的R文档中提供的示例：
 库（rstpm2）

数据（BRCANCER）

##时变系数
摘要（fit.tvc＆lt;  -  stpm2（surch（Rectime，censrec == 1）〜荷尔蒙，data = brcancer，df = 3，
                         TVC = list（荷尔蒙= 3））））
 
现在，如果我使用模型在特定时间点计算人力资源（T_0），同时改变“暴露组”，我得到：
  rectime＆lt; -500
df＆lt;  -  data.frame（hormon = 0，Rectime）＃这是“未暴露”数据

预测1＆lt;  - 预测（fit.tvc， 
                       newdata = df， 
                       var =&#39;荷尔蒙＆quot&#39;
                       se.fit = true）＃，
                      ＃exposed =函数（数据）变换（数据，荷尔蒙= 1））  


预测2＆lt;  - 预测（fit.tvc，newdata = df％＆gt;％突变（荷尔蒙= 1），， 
                       var =“荷尔蒙” 
                       se.fit = true）  

预测1
预测2

＆gt;预测1
   估计下部
1 0.7079504 0.4847274 1.03397

＆gt;预测2
   估计下部
1 0.7022285 0.4864745 1.01367
 
这里有更多时间点：
  rectime＆lt;  -  seq（100，2500，200）
df＆lt;  - 数据 

预测1＆lt;  - 预测（fit.tvc， 
                       newdata = df， 
                       var =“荷尔蒙” 
                       se.fit = true））
                       


预测2＆lt;  - 预测（fit.tvc，newdata = df％＆gt;％突变（荷尔蒙= 1），， 
                       var =“荷尔蒙” 
                       se.fit = true）  

摘要（预测1）
摘要（预测2）

＆gt;摘要（预测1）
    估计下部      
 最小。   ：0.3848分钟。   ：0.05744分钟。   ：1.016  
 1st Qu.:0.7080 1st Qu.:0.38906 1st Qu.：1.055  
 中值：0.7403中位数：0.44222中位数：1.182  
 平均值：0.7112平均值：0.41312平均值：1.362  
 3rd Qu.:0.7691 3rd Qu.:0.48003 3rd Qu.:1.547  
 最大限度。   ：0.7864最大   ：0.52052最大   ：2.578  

＆gt;摘要（预测2）
    估计下部       
 最小。   ：0.3762分钟。   ：0.04823分钟。   ：0.9937  
 1st Qu.:0.7022 1st Qu.:0.39782 1st Qu.：1.0303  
 中值：0.7372中位数：0.46511中位数：1.1264  
 平均值：0.7065平均值：0.42628平均值：1.3308  
 第三QU.:0.7646第三Qu.:0.48904 3rd Qu.:1.4322  
 最大限度。   ：0.7816最大   ：0.52844最大   ：2.9345 
 
随着时间的推移，点估计和分布都不同。我不明白发生了什么以及比较危害的参考级别是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/663444/difference-in-the-time-dependent-hazard-ratios-estimates-according-to-exposure-l</guid>
      <pubDate>Thu, 03 Apr 2025 09:48:05 GMT</pubDate>
    </item>
    <item>
      <title>如何绕过功夫用视觉变压器扔刀敌人NES，ML [封闭​​]</title>
      <link>https://stats.stackexchange.com/questions/663443/how-to-bypass-kung-fu-throwing-knife-enemy-nes-with-vision-transformer-ml</link>
      <description><![CDATA[我正在通过训练一个模型来围绕机器学习，该模型希望绕过功夫中的第1阶段。  repo   
 atm，我被敌人扔刀所困在1级。 （到目前为止，关闭战斗还不错，距离是一个问题）
  我有这个培训 script   
这是我从AI中获得的步骤函数。它首先建议火车简单的奖励，然后再提出更复杂的奖励功能。
  def步骤（自我，操作）：
    obs，_，完成，info = super（）。步骤（操作）
    ram = self.env.get_ram（）
    
    ＃提取游戏状态信息
    current_score = ram [self.ram_positions [&#39;score&#39;]] * 100
    current_scroll = ram [self.ram_positions [&#39;scroll&#39;]]
    current_hp = ram [self.ram_positions [&#39;herio_hp&#39;]]
    current_pos_x = ram [self.ram_positions [&#39;herio_pos_x&#39;]]
    current_stage = ram [self.ram_positions [&#39;stage&#39;]]
    
    ＃计算三角洲
    score_delta = current_score -self.last_score
    scroll_delta = current_scroll- self.last_scroll如果current_scroll＆gt; = self.last_scroll else else（current_scroll + 256 -self.last_scroll）
    hp_loss = max（0，int（self.last_hp） -  int（current_hp））如果self.last_hp不是其他0
    pos_delta = current_pos_x -self.last_pos_x
    
    ＃计算奖励组件
    奖励= 0
    奖励 += score_delta * 5＃获得的积分
    奖励 += scroll_delta * 10＃进展到级别
    奖励 += pos_delta * 0.1＃运动（移动的小奖励）
    奖励 -  = HP_LOSS * 50＃失去健康的罚款
    
    ＃更新跟踪变量
    self.last_score = current_score
    self.last_scroll = current_scroll
    self.last_hp = current_hp
    self.last_pos_x = current_pos_x
    
    ＃计算生存时间
    rovival_time = time.time（） -  self.episode_start_time如果self.episode_start_time else 0 0
    
    ＃将详细信息添加到信息dict
    info [&#39;score&#39;] = current_score
    info [&#39;hp&#39;] = current_hp
    info [&#39;scroll&#39;] = current_scroll
    info [&#39;pos_x&#39;] = current_pos_x
    info [&#39;stage&#39;] = current_stage
    info [&#39;roverival_time&#39;] = rovervial_time
    info [&#39;score_delta&#39;] = score_delta
    info [&#39;scroll_delta&#39;] = scroll_delta
    info [&#39;hp_loss&#39;] = hp_loss
    info [&#39;情节&#39;] = {
        &#39;r&#39;：奖励， 
        &#39;L&#39;：1，＃情节长度（步骤）
        &#39;t&#39;：restival_time，
        “得分”：current_score，
        &#39;scroll&#39;：current_scroll，
        &#39;hp&#39;：current_hp
    }
    
    返回观察，奖励，完成，信息
 
以前，我用5_000_000培训了更复杂的奖励功能，但仍然无法通过。我将使用奖励来训练更多，但我担心这是另一个浪费时间。我需要一些有关如何过来的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/663443/how-to-bypass-kung-fu-throwing-knife-enemy-nes-with-vision-transformer-ml</guid>
      <pubDate>Thu, 03 Apr 2025 09:05:26 GMT</pubDate>
    </item>
    <item>
      <title>上限为两个随机变量的产物的期望值</title>
      <link>https://stats.stackexchange.com/questions/663441/upper-bound-for-expected-value-of-product-of-two-random-variables</link>
      <description><![CDATA[给定两个非阴性随机变量 $ x $ 和 $ y $ 。对于某些常数 $ c $ 和 $ \ forall \ omega \ in \ omega $ 。以下语句正确：
 $$
e [xy] \ leq c e [y]
$$ 
我们是否需要其他假设来做出此声明？
事先感谢您的任何帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/663441/upper-bound-for-expected-value-of-product-of-two-random-variables</guid>
      <pubDate>Thu, 03 Apr 2025 06:30:44 GMT</pubDate>
    </item>
    <item>
      <title>哪些聚类方法将零充气和连续变量处理在一起？</title>
      <link>https://stats.stackexchange.com/questions/663439/what-clustering-methods-handle-zero-inflated-and-continuous-variables-together</link>
      <description><![CDATA[我对数据科学的新手相对较新，目前正在从事一个基于暴露于各种气候危害的全球城市的项目。我已经从参与CMIP6以及世界银行和WRI的GCM中采购了气候数据。总共我正在考虑30多个变量。
我的数据集包括：的混合

连续气候变量（例如，年度降水，干旱等）
零充气变量（例如，海平面上升，风暴潮的沿海洪水 - 内陆城市的值为0）

到目前为止，我在Python中的过程涉及：

使用气候横梁 +城市Shapefile的区域统计数据为每个城市获取危险价值
使用QuantileTransFormer进行高偏斜的值（| skew |＆gt; 1）
应用Min-Max归一化
使用Pearson的相关性去除高度相关变量（+/- 0.8或更高）

我一直在使用PCA + K-均值，但是，我最近了解到，K均值不是混合数据的理想选择，尤其是在涉及零通气时。我正在寻找有关如何从这里进行的指导。
 tl; dr：
对于零充气和连续变量的数据集建议使用哪些聚类方法或预处理技术？我应该使用不同的聚类算法，以不同的方式转换变量或两者？]]></description>
      <guid>https://stats.stackexchange.com/questions/663439/what-clustering-methods-handle-zero-inflated-and-continuous-variables-together</guid>
      <pubDate>Wed, 02 Apr 2025 23:46:39 GMT</pubDate>
    </item>
    <item>
      <title>拉索线性回归的截距是否与其人口一致？</title>
      <link>https://stats.stackexchange.com/questions/663438/is-the-intercept-of-the-lasso-linear-regression-consistent-to-its-population-ols</link>
      <description><![CDATA[假设人口回归：
  $ y = \ beta_0+\ boldsymbol {\ beta}^\ prime \ boldsymbol {x}+\ epsilon $ ，
其中 $ y $  and  $ \ boldsymbol {x} $ 不标准化（平均值可以是非零）。截距的解决方案用 $ \ beta_0^\ star $ 。表示
进一步实施数据 $ \ boldsymbol {y} $  and  $ \ boldsymbol {x} $  $ n \ times p $  plass（ class =“ Math-Container”&gt; $ \ boldsymbol {y} $  and  $ \ boldsymbol {x} $ 可以作为多个I.I.D查看。 class =“ Math-Container”&gt; $ \ boldsymbol {x} $ ）：
  $ \ BOLDSYMBOL {y} = \ BETA_0 \ BOLDSYMBOL {1}+\ BOLDSYMBOL {X} \ BOLDSYMBOL {\ BETA}+\ BOLDSYMBOL {\ BOLDSYMBOL {\ epsilon}，\ Qquad \ left \ | \ boldsymbol {\ beta} \ right \ | \ leq \ lambda。$  
  $ \ boldsymbol {y} $  and  $ \ boldsymbol {x} $  $ \ wideHat {\ beta} _0 $ 。表示
我现在期望 $ \ widehat {\ beta} _0 $ 渐近地脱离 $ \ beta_0^^$ \ beta_0^\ star $ $n$ large for fixed $p$), or $\widehat{\beta}_0\rightarrow \beta_0^\star$ or  $（\ wideHat {\ beta} _0- \ beta_0^\ star）^2 \ rightArrow 0 $ 。这个陈述（可能）是真的吗？或者需要任何假设才能得出此（例如， $ y $ 和 $ \ boldsymbol {x} $ 
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663438/is-the-intercept-of-the-lasso-linear-regression-consistent-to-its-population-ols</guid>
      <pubDate>Wed, 02 Apr 2025 23:02:25 GMT</pubDate>
    </item>
    <item>
      <title>单调收敛定理的线性函数</title>
      <link>https://stats.stackexchange.com/questions/663433/monotone-convergence-theorem-for-a-linear-function</link>
      <description><![CDATA[根据单调收敛理论（beppo levi），对于任何单调，随机变量 $ x_n：\ omega \ omega \ rightarrow [0，∞] $ 保持：
 $$ \ MATHBB E [\ lim_ {n \ rightarrow \ infty} x_n] = \ lim_ {n \ rightArrow \ rightarrow \ infty} \ mathbb e [x_n]
我知道，单调也同样降低序列。
但是，当我尝试使用简单的线性函数进行测试时
态 
n（1-n \ omega）＆amp;＆amp; \ text {for} \ omega \ in（0，\ frac 1n）\\
0＆amp;＆amp; \ text {else}
\ end {case} $$  
由于某种原因，单调收敛定理不再存在：
  $$ \ MATHBB E [\ LIM_ {N \ RICKERARROW \ INFTY} X_N] = 0 \ neq \ frac12 = \ lim_ {n \rightarrow∞}
即使此函数满足单调，端接限制 $ x（ω）= \ lim_ {n \rightArrow∞} x_n（ω）$ 。。]]></description>
      <guid>https://stats.stackexchange.com/questions/663433/monotone-convergence-theorem-for-a-linear-function</guid>
      <pubDate>Wed, 02 Apr 2025 18:29:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在Gamlss中为Lasso执行交叉验证以找到最佳的$ \ lambda $？</title>
      <link>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</link>
      <description><![CDATA[我正在使用用于位置，比例和形状（GAMLSS）的通用加法模型，并试图确定最佳的 $ \ lambda $ 使用交叉验证的套索式回归的值。但是，我正在努力了解如何在这种情况下正确设置交叉验证程序。
对于标准的广义线性模型（GLM），可以使用cv.glmnet（）进行此操作，该步骤遵循以下步骤：

数据集分为 $ k $  folds。
对于每个折叠，使用一个模型对剩余数据进行训练
100  $ \ lambda $ 值的网格。
这些 $ k $  per  $ \ lambda $ 然后在
对应 $ k $ 测试集。
  $ k $  folds均计算每个 $ \ lambda $ 。
  $ \ lambda $ 最小化平均测试错误的选择。

我无法弄清楚如何使用gamlss2软件包实现套索回归，但是我找到了gamlss.lasso，似乎有相同的目的。但是，我的主要问题不是套索实施本身，而是如何正确设置交叉验证过程以选择最佳 $ \ lambda $  。
对于GLM，我们只调整一个 $ \ lambda $ ，但是对于gamlss，我们需要调整第二个：一个：一个用于位置参数 $ \ mu $ $ $ $ $  scale/scale/disperersion parametion参数这表明我们应该使用二维网格的 $ \ lambda $ 值，这意味着，如果我们为 $ \ lambda_ \ lambda_ \ lambda_ \ mu $ 和100 class =“ Math-Container”&gt; $ 100 \ times 100 = 10,000 $ 不同的组合。给定的 $ k = 10 $ 折叠，这将导致培训100,000款模型，这似乎在计算上昂贵。
我试图在没有交叉验证的情况下实施套索，如下所示：
  set.seed（123）
N＆lt; -500
d＆lt; -50
x＆lt;  - 矩阵（rnorm（n*d），n，d）
beta＆lt;  -  cbind（&#39;mu&#39;= rbinom（d，1，.1），sigma&#39;= rbinom（d，1，.1） * .3）
ysd＆lt;  -  Exp（1 + tcrossprod（beta [，2]，x））
data＆lt;  -  cbind（y = as.numeric（rnorm（n，sd = ysd））） + t（tcrossprod（beta [，1]，x）），as.data.frame（x））

＃使用GNET默认设置估算模型
mod＆lt;  -  gamlss（y〜gnet（x.vars = names = names（data）[ -  1]），
              sigma.fo = 〜gnet（x.vars = names（data）[ -  1]）， 
              数据=数据， 
              家庭=不，
              i.control = glim.control（cyc = 1，bf.cyc = 1））

mu_betas＆lt;  -  as.matrix（mu [[1]]  $ beta）
mu_lambdas＆lt;  -  mu [[1]] $  lambda

sigma_betas＆lt;  -  as.matrix（sigma [[1]]  $ beta）
sigma_lambdas＆lt;  -  sigma [[1]] $  lambda
 
从每个 $ \ lambda $ 值的估计系数中，可以评估测试数据的性能并构建交叉验证过程。但是，我尚不清楚以下几点：

由于我们在gamlss中建模两个参数，我们需要一个
 $ \ lambda $ 值的二维网格？也就是说，我们应该测试
所有 $ 100 \ times 100 $ 组合 $（\ lambda_ \ mu，\ lambda_ \ lambda_ \ theta）$ 
独立？例如，这将允许
 $ \ lambda_ \ mu $ 很大，而 $ \ lambda_ \ lambda_ \ theta $ 很小，如果
取决于许多变量，而 $ \ mu $ 取决于很少。
在上述实施中，似乎只有100个组合
经过测试，按照序列 $（\ lambda _ {\ Mu} [1]，
\ lambda _ {\ theta} [1]），...（\ lambda _ {\ mu} [100]，
\ lambda _ {\ theta} [100]）$ ，而不是评估所有可能的成对
来自两个独立网格的组合。这是正确的吗
方法，或应全部 $ 10,000 $ 组合
明确？
我读到可以将套索和交叉验证结合在一起
使用gamlss2，但我找不到有关如何如何
到
这样做。如果有人知道如何使用gamlss2进行交叉验证
有了拉索，我将感谢任何指导！
]]></description>
      <guid>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</guid>
      <pubDate>Wed, 02 Apr 2025 17:51:04 GMT</pubDate>
    </item>
    <item>
      <title>通过伽马分布得出无偏估计器的标准偏差</title>
      <link>https://stats.stackexchange.com/questions/663421/deriving-unbiased-estimator-for-standard-deviation-with-gamma-distribution</link>
      <description><![CDATA[对于某个 $ x_1，...，x_n \ sim n（\ mu，\ sigma^2）$  $ ，这两个参数都未知，我正在尝试为 $ \ sigma $ 我们知道 $ \ hat {\ sigma} = \ sqrt {\ frac {\ frac {1} {n} {n} \ sum_ {i = 1}^n（x_i--- \ bar {x}} 2} 2} 2} $ span&gt;是 $ \ sigma $ 。我正在尝试遵循计算 $ \ hat {\ sigma} = \ sigma \ sigma \ sqrt {\ frac {\ frac {2} {n}} {n}} {n}} {n}} \ sqrt {y} {y} $ span class 要获得 $ k_n \ sigma $ 的结果class =“ Math-Container”&gt; $ \ frac {1} {k_n} \ hat {\ sigma} $ 。
为此，我发现通过在pdf上进行集成， $ e [\ sqrt {y}] = \ frac {\ gamma（\ frac {n} {n} {2} {2} {2} {2}）}} class =“ Math-Container”&gt; $ e [\ hat {\ sigma}] = \ sigma \ sqrt {\ frac {2} {n}}} \ frac {\ gamma（\ frac {n} {2} {2}）} {\ gamma {（\ frac {n-1}}}}}} $  $ 。但是，我们已经知道， $ \ sigma $ 的无偏估计器应为 $ \ sqrt {\ frac {n-1} {n} {n}} \ sqrt {\ frac {1} {n -1} \ sum（x_i  -  \ bar {x}）^2} $ 。因此，我想知道如何将涉及伽马功能比例的比率倒入 $ \ sqrt {\ frac {n-1} {n} {n}} $ 的系数？或者我是否无法以这种方式找到估计器？]]></description>
      <guid>https://stats.stackexchange.com/questions/663421/deriving-unbiased-estimator-for-standard-deviation-with-gamma-distribution</guid>
      <pubDate>Wed, 02 Apr 2025 12:40:51 GMT</pubDate>
    </item>
    <item>
      <title>非静止分布的后部？分布校准</title>
      <link>https://stats.stackexchange.com/questions/663408/posterior-for-non-stationary-distribution-distribution-calibration</link>
      <description><![CDATA[如何估计非固定分布的后验？也许最好称其为分配校准？
问题是分布不是固定的，因此需要找到的不是参数，而是变换函数。这改变了先前的分布，可能改变其平均值，扩散，不对称性，偏斜。
 给定：非固定高斯混合物作为先验和观察的值。
 参数：sigma1，sigma2，速率。  PIROR ： $ 0.5N（{速度}，\ sigma_1）+0.5n（{速度}，\ sigma_2）$ 。
 目标：返回。的后验分布的最佳可能性
  sigma1 sigma2速率返回
0.091 0.231 0.018 0.08
0.097 0.223 0.018 0.28
...
 
 结果：转换函数 $ t $ 为每个数据点生成PDF（即每个数据点需要其自己的PDF）。 PDF可以是分析的或调整后的高斯混合物或数值（矢量）近似函数的。
  $ t（\ sigma_1，\ sigma_2，{rate}）=＆gt; \ mbox {postterior_pdf}（x：number）：数字$  
可能使用贝叶斯推断或其他方法，例如分布校准，分数映射。
 P.S。
数据 - 金融市场，股票日志返回波动率估算，无风险利率和实际日志收益。]]></description>
      <guid>https://stats.stackexchange.com/questions/663408/posterior-for-non-stationary-distribution-distribution-calibration</guid>
      <pubDate>Wed, 02 Apr 2025 09:18:14 GMT</pubDate>
    </item>
    <item>
      <title>什么是神经网络的深度？输入层数吗？</title>
      <link>https://stats.stackexchange.com/questions/663369/what-is-a-neural-networks-depth-does-the-input-layer-count</link>
      <description><![CDATA[神经网络depth = #hidden_​​layers [+1  [+1]]在不同的令人信服的来源中。
问题A.没有针对“ 网络深度”的领先定义？
 =;隐藏层的数量; +0
https://eitca.org/artificial-intelligence/eitc-ai-dltf-deep-learning-with-tensorflow/training-a-neural-network-to-play-a-game-with-tensorflow-and-open-ai/training-model/考试审查训练模型/何种调整的调整量 - 数量符合数量的人 - 在台上 - 纳德人和淘汰 - 淘汰 - 淘汰 - 超级size in-a-a-a-a-a-a-a-a-a-a-a-a-network-model/  
 +1（“我们不计算第一层。当我们说3层时，我们实际上是指2个隐藏层和一个输出层。＆quot“因为输入层通常不会处理 /具有权重）
 https://datascience.stackexchange.com/a/a/14032   
 +2（“层的数量”，包括输入＆amp;输出层） http://ufldl.stanford.edu/tutorial/supervise/multilayernearalnetworks/ 
 chatgpt支持+0，其链接具有权威。其他测试的AIS支持+1。我想我看过许多大学课程+2。
问题B.关于“ 层数”的定义相同的问题; 
问题C：对于 llm  s，“模型深度”和“＃layers”总是表示 #transformer_blocks （又称变压器层），即使每个块包含多个网络层？
我猜是“是”对于C和“始终指定您的意思”在A＆amp; B.如果是这样，是否有明确的领导定义（或两个）？ b呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/663369/what-is-a-neural-networks-depth-does-the-input-layer-count</guid>
      <pubDate>Tue, 01 Apr 2025 09:04:20 GMT</pubDate>
    </item>
    <item>
      <title>需要的建议：建模超过100％的测量比例数据</title>
      <link>https://stats.stackexchange.com/questions/663362/advice-needed-modelling-measured-proportion-data-that-goes-beyond-100</link>
      <description><![CDATA[我一直被任命从海洋探险中分析使用CTD收集水概况的数据集。收集的变量之一是饱和百分比的氧饱和度。我正在寻找一种在空间域上插入数据的方法。但是，覆盖的区域因岛屿而破裂，因此，像Kriging和IDW这样的海洋学中的传统方法不起作用。 I&#39;m currently using a gam with a soap smoother in mgcv::gam to model the surface layer of the water column across the study area (the survey area is fractured by islands, therefore IDW is not适用）。
这是问题：
直觉（以及诸如Cullen Frey图）的诊断表明，应使用Beta家族对饱和值进行建模。但是，水可能过饱和，例如找到值＆gt并不少见。 100％。
      
  将数据扩展到（0,1）然后将响应缩放为“合法”吗？我可以看到这种方法很多。
您将如何解决这个问题？
如果可以替代平滑数据 /插值（包括边界），我很想听听！&lt; / p&gt;
 ps：经验分布表示双峰性。可能是这种情况。但是，我不在乎测量的潜在效果，我正在寻找整个空间域的平滑测量。通常，您将在海洋学中使用IDW。但是，在这种情况下，调查区域和地点被裂缝并被岛屿部分切断。]]></description>
      <guid>https://stats.stackexchange.com/questions/663362/advice-needed-modelling-measured-proportion-data-that-goes-beyond-100</guid>
      <pubDate>Tue, 01 Apr 2025 05:14:23 GMT</pubDate>
    </item>
    <item>
      <title>过多（或错误）精度有什么问题吗？</title>
      <link>https://stats.stackexchange.com/questions/663351/is-there-any-problem-with-too-much-or-false-precision</link>
      <description><![CDATA[例如，我经常与成人和婴儿一起工作。对于成年人，0.001年不到一天。我们很少需要知道成年人的年龄到一个小时。 But, often databases store ages down to many decimal places, since dividing almost any number of days by $365$ or $365.25$ results in decimal places that represent sub-hour-resolution &quot;ages&quot;.
同样，对于几天中年龄更重要的婴儿，0.01个月的年龄为7.2小时。在最初的几天之后，这不是很重要。
这看起来很愚蠢，但是在对五个小数点的年龄进行分析时，是否有任何可衡量的危害（或任何能力更分辨率的值），而实际上最多只有两个是远程相关的？ 
换句话说，假设我有一个年龄列表，这些年龄均由 $ \ frac {\ textrm {today}}  -  \ textrm {textrm {firtaght}} {365} $  $ 。因此，我的年龄看起来像这样： $ x_1 = \ {27.39726，30.13699，32.87671，35.61644，38.35616 \} $ 。 （这是五分钟的分辨率。）
与使用 $ x_2 = \ {27.4，37.4，30.1，32.9，35.6，35.6，35.6，35.6，35.6，38.4 \ p&gt;相比]]></description>
      <guid>https://stats.stackexchange.com/questions/663351/is-there-any-problem-with-too-much-or-false-precision</guid>
      <pubDate>Mon, 31 Mar 2025 22:50:12 GMT</pubDate>
    </item>
    </channel>
</rss>