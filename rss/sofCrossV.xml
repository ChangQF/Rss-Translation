<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 May 2024 21:15:00 GMT</lastBuildDate>
    <item>
      <title>将两个相关变量的联合 pmf 建模为 p(x)*pmf(E(y|x))</title>
      <link>https://stats.stackexchange.com/questions/648320/modelling-the-joint-pmf-of-2-correlated-variables-as-pxpmfeyx</link>
      <description><![CDATA[让 x,y 为 2 个相关计数。我们想要对联合 pmf p(x,y) 进行建模。我们知道 p(x,y) = p(x)p(y|x) = p(y)(x|y)。但是，当我们不知道 y|x，但可以估计 E(y|x) 时会发生什么？我们不能使用 p(x)*pmf(E(y|x) 来对 p(x,y) 进行建模吗？
下面，我生成两个相关的泊松变量。然后，我估计给定 x 的预期 y，E(y|x)。之后，我生成 x 的边际 pmf。最后，我计算 p(x)*pmf(E(y|x) 来创建一个矩阵，该矩阵用于表示联合 pmf p(x,y)。
我正在对 pXY 矩阵的行和列求和，希望得到边际分布。这对于 p(x) 是正确的。然而，对于 p(y) 来说，情况并非如此，它的方差明显更高，表明我的逻辑存在问题。有人能解释一下我做错了什么，以及在这个例子中我们如何才能得到 (x,y) 的正确联合 pmf 吗？
import numpy as np
from scipy.stats import norm, poisson

def generate_correlated_poisson(N, mu, rho):
# 步骤 1：生成相关的高斯随机变量
mean = [0, 0] # 高斯变量的平均值
cov = [[1, rho], [rho, 1]] # 协方差矩阵

# 从二元正态分布生成 N 个样本
gaussian_samples = np.random.multivariate_normal(mean, cov, N)

# 步骤 2：使用 CDF 将高斯变量转换为均匀变量
uniform_samples = norm.cdf(gaussian_samples)

# 步骤 3：使用逆 CDF (PPF) 将均匀变量转换为泊松变量
poisson_samples_x = poisson.ppf(uniform_samples[:, 0], mu)
poisson_samples_y = poisson.ppf(uniform_samples[:, 1], mu)

return poisson_samples_x, poisson_samples_y

# 参数
N = 100000 # 样本大小
mu = 2.5 # 泊松分布的平均值
rho = 0.5 # 期望相关性

# 生成相关泊松变量
x, y = generate_correlated_poisson(N, mu, rho)

# 估计 E(y|x)
df = pd.DataFrame(columns=[&#39;y&#39;,&#39;x&#39;],data=np.vstack((y,x)).T)
ols = smf.ols(&#39;y~x&#39;,data=df).fit() # 也可以使用 smf.poisson(&#39;y~np.log(x+1)&#39;,data=df).fit()
betas = ols.params.values

# 为 X 生成边际 pmf
pX = poisson.pmf(np.arange(0,21),2.5)

#生成联合分布 p(x)*pmf(E(y|x))
pXY = np.array([(pX[i]*poisson.pmf(np.arange(0,21),betas[0]+betas[1]*i)).tolist() for i in range(0,21)])

print(np.sum(pXY,axis=0)) #通过对矩阵行求和得到边际 pmf p(y)
print(np.sum(pXY,axis=1)) #通过对矩阵列求和得到边际 pmf p(x)
print(pX) #真实边际 p(x)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648320/modelling-the-joint-pmf-of-2-correlated-variables-as-pxpmfeyx</guid>
      <pubDate>Thu, 30 May 2024 20:47:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 K 均值方法解决时间序列的维数灾难</title>
      <link>https://stats.stackexchange.com/questions/648319/curse-of-dimensionality-in-time-series-with-k-means</link>
      <description><![CDATA[我一直在查看以下笔记本：时间序列聚类
其中作者说数据集受到“维度诅咒”的影响，因此应用tslearn提供的 TimeSeriesKMeans 是不正确的。相反，PCA 应用于列“值”时间序列的 2 个成分，然后使用普通的 k 均值函数划分聚类。
我在网上查了一下，似乎只有当数据集具有许多特征和少量数据时，才会发生“维数灾难”。文章中的数据集只有 2 个特征（时间戳、值）和许多数据，所以在我看来，不存在“维数灾难”，因此对所有“值”进行 PCA列是无用的。
我是否遗漏了重要的东西？
另一方面，如果文章是正确的，每次我想研究时间序列时，我可能会对所有值应用 PCA，然后使用经典的 k-means，而不是 tslearn 提供的 TimeSeriesKMeans 函数]]></description>
      <guid>https://stats.stackexchange.com/questions/648319/curse-of-dimensionality-in-time-series-with-k-means</guid>
      <pubDate>Thu, 30 May 2024 20:45:25 GMT</pubDate>
    </item>
    <item>
      <title>统计确定粒子数量</title>
      <link>https://stats.stackexchange.com/questions/648318/statistically-determining-a-count-of-particles</link>
      <description><![CDATA[我进行实验来测量各种药物。其中一项测量是对限制在小体积内的粒子数量感兴趣。
我实验中的原始数据是 32 x 32 像素大小的视频，其背景噪音较高，并且包含多个随机扩散的粒子。然后，我使用局部最大值轨迹跟踪粒子。
跟踪方法产生以下一组信息：
$$\vec p = \begin{bmatrix} x\\ y\\ \text{mass}
\\\ \text{ecc}\\ \text{raw_mass} \end{bmatrix}$$
其中 x、y 为位置，质量、raw_mass 为粒子强度（围绕选定半径 $r$ 积分）。ecc（偏心率）表示粒子的圆度。
现在，统计问题出现了。给定单个图像/帧中的一组 $N$ 粒子测量值，我很难从统计上形成一种方法来确定存在 $N$ 个粒子。例如，可能存在噪声，这会影响计数的决定，或者可能存在粒子聚集。
简而言之，给定一个图像和一组算法确定的向量 $\vec p$，每次测量真正反映粒子的概率是多少，以及该测量的置信度是多少。
尝试的想法
1.
在确定是否有粒子方面，必须有一种方法可以将相邻的强度与粒子进行比较。即，粒子的信号应该比背景/漏检的信号明显多。
2.
我还尝试集思广益，如何创建一种方法来调整一组参数以统计地推断这一决定。即，让阈值确定一个最小值，从而可以区分最不明亮的粒子。这需要动态地完成，因为每个训练集都应该非常大。由于实验的性质（荧光标记），这也存在物理限制
如果有任何统计参考/建议可以帮助我解决这个问题，请告诉我。
谢谢，
附言：标签的选择是我认为应该的，如果我应该更改任何内容，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/648318/statistically-determining-a-count-of-particles</guid>
      <pubDate>Thu, 30 May 2024 20:31:52 GMT</pubDate>
    </item>
    <item>
      <title>计算比例数据的置信区间（多个数据点）</title>
      <link>https://stats.stackexchange.com/questions/648316/calculating-confidence-intervals-for-proportion-data-multiple-data-points</link>
      <description><![CDATA[各位 -
我正在寻找一种方法来计算数据系列（多个数据点的样本）的置信区间（例如 95%）或其他变异性指标，其中数据都是比例（即每个数据都在零和一之间）。我认为这种方法不同于计算连续数据的标准 CI，可以是任何数值等。请注意，我并不是要求对单个比例进行 CI 估计（例如，Clopper-Pearson 方法）。R 代码或 Excel 公式会有所帮助。似乎在任何基础教科书中都找不到这个。谢谢。
示例数据集：
0.12、0.24、0.93、0.56、0.02]]></description>
      <guid>https://stats.stackexchange.com/questions/648316/calculating-confidence-intervals-for-proportion-data-multiple-data-points</guid>
      <pubDate>Thu, 30 May 2024 20:21:41 GMT</pubDate>
    </item>
    <item>
      <title>比较具有不同拟合分布的 GLM</title>
      <link>https://stats.stackexchange.com/questions/648315/comparing-glms-with-different-fitted-distributions</link>
      <description><![CDATA[我有一个场景，我需要将一些广义线性模型（具有相同的链接函数、目标变量，但不一定嵌套）与 k 倍交叉验证进行比较，使用成本函数比较预测值与保留集中的实际数据的“接近度”。据我所知，给出此度量的指标是 GLM 范式中的偏差，因为与 OLS 不同，方差不被假定为常数。但是，正如我在文本中看到的那样，偏差似乎是底层分布拟合的函数，因此其函数（数学）形式可能因分布而异。
那么，我说偏差（作为损失函数）不能用于比较具有不同拟合分布（例如 m1 - Gamma、m2 - 逆高斯）的模型的“实际数据与预测值的接近度”是否正确？如果是，在这种情况下使用的首选指标（损失函数）是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648315/comparing-glms-with-different-fitted-distributions</guid>
      <pubDate>Thu, 30 May 2024 20:17:58 GMT</pubDate>
    </item>
    <item>
      <title>找到具有 cursed 支持度的随机样本的最小充分统计量</title>
      <link>https://stats.stackexchange.com/questions/648312/find-minimal-sufficient-statistic-of-this-random-sample-with-cursed-support</link>
      <description><![CDATA[假设 $X_1,X_2,...,X_n$ 是一个 i.i.d 随机样本，其概率质量函数为 $p(x_i,\theta)$，其中 $x_i \in \{\theta,\theta+1,\theta+2,...\}$ 且 $\theta \in \mathbb{R}$。我声称最小充分统计量为 $(X_{(1)},...,X_{(n)})$。我说得对吗？
特殊情况
如果很难找到该问题的最小充分统计量，则可以考虑一种特殊情况，即 $p(x_i,\theta)=p(x_i)$，这意味着 p 不依赖于 $\theta$。
一般情况
我还认为，当 $\theta \in A$ 其中 $card(A) \ge 2$ 时，我的说法是正确的。
我的方法
如果您尝试使用因式分解定理：
$$P(\textbf{X}=\textbf{x}) = {\displaystyle \prod_{i=1}^{n} p(x_i,\theta) I_{ \{ \theta,\theta+1,...\} }(x_i) }$$其中 $I_{ \{ \theta,\theta+1,...\} }(x_i)$ 是指示函数。这是我们无能为力的地方，因为我们无法分解指示函数的乘积，所以我猜最小充分统计量是$(X_{(1)},...,X_{(n)}) $。
我的解释
我认为${\displaystyle \prod_{i=1}^{n} I_{ \{ \theta,\theta+1,...\} }(x_i) }$意味着&quot;为了找出$x_i$是一个有效的观察结果，我们需要知道$\theta$&quot;
我的问题
是${\displaystyle \prod_{i=1}^{n} I_{ \{ \theta,\theta+1,...\} }(x_i) } ... class=&quot;math-container&quot;&gt;$(X_{(1)},...,X_{(n)})$ 最小充分统计量？
我也在 math stackexchange 中问过这个问题，但没有得到答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/648312/find-minimal-sufficient-statistic-of-this-random-sample-with-cursed-support</guid>
      <pubDate>Thu, 30 May 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>带聚类的个体水平横断面数据的差异分析的功效分析</title>
      <link>https://stats.stackexchange.com/questions/648309/power-analysis-for-difference-in-differences-analysis-with-individual-level-cros</link>
      <description><![CDATA[我计划使用个体层面的横断面数据进行差异分析。我的结果变量是二分的。
我目前无法访问数据，因此我必须使用模拟数据进行功效分析。
我的 DID 将有两组，治疗前 12 个时间段（月），治疗后 12 个时间段。我的总样本量大概在 N=5,000 左右，我将有 73 个聚类。
我的模型还将包括 5 或 6 个控制变量以及月-年固定效应。
我的模型的数学表达式如下：
Yit = α + β1Treatmenti + β2Postt + β3(Treatmenti × Postt) + δt + γ′Xit + ϵit
如何对这样的模型进行功效分析（我假设我应该运行几个参数略有不同的分析？）以及如何报告结果？
最后，我还想运行补充分析来估计异质性治疗效果（基于个体是否具有某种特征），基于以下公式：
Yit = α + β1Treatmenti + β2Postt + β3(治疗i × 治疗后t) + β4Ci + β5(治疗i × 治疗后Ci) + β6(治疗后T × 治疗后Ci) + β7(治疗i × 治疗后T × 治疗后Ci) + δt + γ′Xit + ϵit)
我还不知道具有和不具有该特征的人的比例。如何对这个补充 DID 模型进行功效分析？
我主要使用 R 和 Stata，因此 R 或 Stata 代码会很有帮助 - 但我也会很感激只是概念上分解该怎么做。
到目前为止，我有这个，它似乎有效，但我不确定这是否是正确的方法：
library(lme4) # 用于 glmer
library(dplyr) # 用于数据操作

# 参数
set.seed(123) # 用于可重复性
N &lt;- 5000 # 个体数量
T &lt;- 24 # 时间段数（治疗前 12 个，治疗后 12 个）
P &lt;- 0.5 # 治疗组比例
num_simulations &lt;- 1000 # 模拟次数
effect_size &lt;- log(1.5) # 预期对数优势比（效应大小） beta3
alpha &lt;- 0.05 # 显著性水平

# 模拟数据和拟合模型的函数
simulate_DiD &lt;- function(N, T, P, effect_size) {
# 创建个体和时间段
individuals &lt;- rep(1:N, each = T)
time &lt;- rep(1:T, N)

# 治疗分配
treatment &lt;- rbinom(N, 1, P)
treatment &lt;- rep(treatment, each = T)

# 治疗后指标
post &lt;- ifelse(time &gt; 12, 1, 0)

# 控制变量（5 个分类变量）
X1 &lt;- rep(sample(1:3, N, replace = TRUE), each = T)
X2 &lt;- rep(sample(1:2, N, replace = TRUE), each = T)
X3 &lt;- rep(sample(1:4, N, replace = TRUE), each = T)
X4 &lt;- rep(sample(1:5, N, replace = TRUE), each = T)
X5 &lt;- rep(sample(1:3, N, replace = TRUE), each = T)

# 线性预测器
linear_predictor &lt;- 1 + 1*treatment + 1*post + effect_size*(treatment * post) + 
0.5*X1 + 0.5*X2 + 0.5*X3 + 0.5*X4 + 0.5*X5

# 概率
prob &lt;- 1 / (1 + exp(-linear_predictor))

# 结果变量（二进制）
Y &lt;- rbinom(N * T, 1, prob)

# 创建数据框
data &lt;- data.frame(individuals, time, treatment, post, Y, X1, X2, X3, X4, X5)

# 拟合逻辑回归模型
model &lt;- glm(Y ~ treatment * post + X1 + X2 + X3 + X4 + X5, data = data, family = binomial)

# 返回是否拒绝零假设
p_value &lt;- summary(model)$coefficients[&quot;treatment:post&quot;, 4]
return(p_value &lt; alpha)
}

# 运行模拟
结果 &lt;- replicate(num_simulations, mock_DiD(N, T, P, effect_size))

# 计算功效
功效 &lt;- mean(results)
print(paste(&quot;估计功效：&quot;, power))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648309/power-analysis-for-difference-in-differences-analysis-with-individual-level-cros</guid>
      <pubDate>Thu, 30 May 2024 19:24:06 GMT</pubDate>
    </item>
    <item>
      <title>非常低的 p 值的正确格式是什么？</title>
      <link>https://stats.stackexchange.com/questions/648307/what-is-the-proper-formatting-of-very-low-p-values</link>
      <description><![CDATA[一般来说，我相信应该给出精确的 p 值，而不是像“p &lt; 0.05”这样的值。但是，有时 p 值非常低，大约为 $10^{-10}$ 甚至更低。在什么情况下我们应该 a) 四舍五入并说“$p &lt; 10^&quot;-5$”或 b) 以科学计数法给出完整的估计值，例如“$p = 3.46*10^{-7}$”？]]></description>
      <guid>https://stats.stackexchange.com/questions/648307/what-is-the-proper-formatting-of-very-low-p-values</guid>
      <pubDate>Thu, 30 May 2024 19:10:14 GMT</pubDate>
    </item>
    <item>
      <title>在多重共线性设置中，套索是否比岭回归或主成分回归更可取？</title>
      <link>https://stats.stackexchange.com/questions/648305/is-lasso-preferable-to-ridge-or-principal-component-regression-in-multicollinear</link>
      <description><![CDATA[考虑一个 $N\times p$ 数据矩阵 $\mathbf X$，其列为 $\mathbf x_j$。ESL 建议在执行岭回归之前对输入进行标准化，我的理解是将列 $\mathbf x_j$ 居中，使其均值为 0，并重新缩放它们，使其方差为 $\|\mathbf x_j\|^2/N=1$。所以让我们假设情况就是这样。我正在思考 $\mathbf X$ 的列跨度 $V\subset\mathbf R^N$ 中的主要成分方向（$\mathbf R^N$ 的线性子空间）。这些主成分方向 $v\in\mathbf R^N$ 具有这样的属性：它们是 $V$ 中的范数为 1 的向量，因此 $Xv$ 的方差最大化（即，我们希望最大化 $\|Xv\|$）。
请注意，如果我通过在末尾添加 $n-1$ 个 $\mathbf x_p$ 副本来扩充 $\mathbf X$（因此 $\mathbf X$ 现在是 $N\times(p+n-1)$)，则向量 $v=(0,\ldots,0,1/\sqrt n,\ldots,1/\sqrt n)$ 的范数为 1，其中有 $p-1$ 个零，后跟 $n$ 个值为 $1/\sqrt n$ 的条目。
现在 $Xv=\frac{n}{\sqrt n}\mathbf x_p$，范数为 $\sqrt{nN}$，方差为 $(Xv\cdot Xv)/N=n$.因此，对于足够大的 $n$，$v$ 到 $V$ 的投影将确定一个主成分方向，并且 $\mathbf x_p$ 的一些重新缩放将成为 $\mathbf X$ 的主成分。
将其与套索进行对比，如果我们遵循修改后的最小角度回归算法，套索应该对添加额外列完全不敏感，因为 LAR 算法将分析哪一列与任何给定时刻的残差最相关。
这是一个完全人为的构造，但它是否反映了在多重共线情况下更喜欢套索而不是岭回归的原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/648305/is-lasso-preferable-to-ridge-or-principal-component-regression-in-multicollinear</guid>
      <pubDate>Thu, 30 May 2024 18:57:44 GMT</pubDate>
    </item>
    <item>
      <title>巴苏定理的应用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648303/basu-theorems-application</link>
      <description><![CDATA[设 X 和 Y 为独立的 N(0,1) 变量。求 Pr[ (X+Y)/(X-Y) &gt; 0.5]。]]></description>
      <guid>https://stats.stackexchange.com/questions/648303/basu-theorems-application</guid>
      <pubDate>Thu, 30 May 2024 18:24:59 GMT</pubDate>
    </item>
    <item>
      <title>尽管类别不平衡，Logit 模型仍未预测任何 < 0 的值</title>
      <link>https://stats.stackexchange.com/questions/648302/logit-model-not-predicting-any-values-0-despite-class-imbalance</link>
      <description><![CDATA[我正在建立一个逻辑回归模型来识别潜在的渠道因素，这些因素可以预测患者是否会在疾病的特定阶段开始使用两种抗糖尿病药物中的一种。我的数据集非常不平衡，97.5% (n = 15292) 的患者开始属于 B 类，只有 2.5% (n = 394) 的患者开始属于 A 类。
logit_model &lt;- glm(class_A ~ centered_age + female + creat*days_to_first_fill + 
cause + centered_bmi + dgf + LiverDisease + 
fill_era, 
family = binomial(link = &quot;logit&quot;),
data = dt)

在拟合逻辑回归模型并使用 expit 函数将预测的对数几率转换为概率后，我发现所有预测概率均不低于 0.5（即所有对数几率均不小于 0）。预测概率的范围也很窄，绝大多数患者的概率约为 50%。
summary(dt$pred_prob)
最小值 第 1 组 中位数 平均值 第 3 组 最大值 
0.5002 0.5014 0.5029 0.5063 0.5054 0.6724

鉴于数据的不平衡性质，我预计预测概率将反映观察到的类别分布，胰岛素启动类别的大多数概率低于 0.5。然而，该模型似乎为大多数患者分配了 0.5 左右的概率，表明这两个类别之间的区分度较差。几乎感觉模型的拟合值是概率而不是对数几率。
summary(logit_model$fitted.values)
最小值 第 1 组中位数 平均值 第 3 区 最大值 
0.0007501 0.0057085 0.0115473 0.0251822 0.0214111 0.7189886 

作为参考，这是我的模型输出：
系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -5.56850007 0.17583038 -31.670 &lt; 0.0000000000000002 ***
centered_age 0.00007974 0.00480505 0.017 0.986759 
female女性 0.04008379 0.11260580 0.356 0.721866 
creat -0.08360708 0.03568126 -2.343 0.019121 * 
days_to_first_fill 0.01944154 0.00120843 16.088 &lt; 0.0000000000000002 ***
原因肾小球肾炎 1.51663048 0.19201817 7.898 0.0000000000000283 ***
原因高血压性肾硬化 1.30805147 0.14719779 8.886 &lt; 0.000000000000002 ***
原因其他 1.08617629 0.14338594 7.575 0.00000000000003586 ***
centered_bmi -0.02047943 0.01071770 -1.911 0.056030 . 
dgf 延迟移植物功能 -0.54979993 0.14787923 -3.718 0.000201 ***
LiverDisease 中度至重度肝病 -0.43294637 0.24443026 -1.771 0.076520 . 
fill_era 首次填充 2013-2020 1.10826539 0.14895235 7.440 0.00000000000010038 ***
centered_mrcreat:days_to_first_fill 0.00101324 0.00036170 2.801 0.005089 ** 
---
Signif.代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

（二项式系列的分散参数取为 1）

零偏差：15645 个自由度上的 3679.1

残差偏差：15633 个自由度上的 2975.4

AIC：3001.4

Fisher 评分迭代次数：7

有人遇到过类似的事情吗？我不确定如何解决这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/648302/logit-model-not-predicting-any-values-0-despite-class-imbalance</guid>
      <pubDate>Thu, 30 May 2024 18:17:09 GMT</pubDate>
    </item>
    <item>
      <title>k 倍时间序列交叉验证的某些分割中高度不平衡的测试数据如何影响模型性能？</title>
      <link>https://stats.stackexchange.com/questions/648298/how-does-highly-imbalanced-test-data-in-certain-splits-of-k-fold-time-series-cro</link>
      <description><![CDATA[我正在研究一个时间序列分类 (TSC) 问题，使用 k 倍时间序列交叉验证 (TSCV) 来评估我的模型的性能。我每个分割的训练数据都相当平衡，类别分布范围从 40% 到 60%，少数情况为 30/70%。但是，我注意到某些分割中的测试数据高度不平衡。例如，在 6 倍 TSCV 设置中，分割 2、5 和 6 具有高度不平衡的测试集。我担心这种不平衡会如何影响我的模型评估。
以下是我的设置的简要概述：
训练和测试数据中的类别分布：
训练数据：平衡（40-60% 的类别分布）。测试数据：在某些分割中高度不平衡（例如，分割 2、5 和 6）。我使用标准指标来评估性能；准确度、精确度、召回率、F1 分数、AUC-ROC 分数。
我使用前向时间序列交叉验证方法来分割数据。我使用 Python 和 pandas 以及 scikit-learn 分析分割过程中的类分布和模型性能。我使用 LSTM-FCN、InceptionTime、ResNet、TCN 和 ROCKET 等模型进行 TSC 分析。在此示例中，我处理时间序列数据，其中每个时间步骤代表一个数据点。目标变量 Fault_Status 指示每个时间步骤中是否存在故障 (1) 或不存在故障 (0)。
下面是一个与我的问题相关的虚拟示例，它不是实际的数据集。它只是传达观点的一种手段。
具体问题：

对实验的影响：

某些分组（例如分组 2、5 和 6）中的不平衡测试数据会如何影响我的 TSC 模型的整体评估？

缓解策略：

我可以使用哪些策略来缓解这种不平衡的负面影响？
分层拆分是否适合 TSC，我该如何实现它？
任何见解或建议都将不胜感激！

import numpy as np
from sklearn.model_selection import TimeSeriesSplit

def walk_forward_tscv(X, y, n_splits=7):
tscv = TimeSeriesSplit(n_splits=n_splits)
splits = []

for i, (train_index, test_index) in enumerate(tscv.split(X)):
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]

unique, counts_train = np.unique(y_train, return_counts=True)
train_distribution = dict(zip(unique, counts_train))

unique, counts_test = np.unique(y_test, return_counts=True)
test_distribution = dict(zip(unique, counts_test))

splits.append((train_index, test_index))

print(f&quot;拆分 {i+1}：&quot;)
print(f&quot;训练集类别分布：{train_distribution}&quot;)
print(f&quot; 测试集类别分布：{test_distribution}&quot;)
print(&quot;-&quot; * 50)

返回分割

]]></description>
      <guid>https://stats.stackexchange.com/questions/648298/how-does-highly-imbalanced-test-data-in-certain-splits-of-k-fold-time-series-cro</guid>
      <pubDate>Thu, 30 May 2024 16:52:39 GMT</pubDate>
    </item>
    <item>
      <title>“独立关联”和“独立预测因子”之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648296/is-there-any-difference-between-an-independent-association-and-to-be-independ</link>
      <description><![CDATA[我想知道作为变量或特定事件的独立预测因子与独立相关之间是否存在差异，即激素是总胆固醇水平的独立预测因子，还是激素与总胆固醇不独立相关。
因为在我看来，从语义角度（甚至临床角度）来看，这两者是相同的，或者至少是两种方式。但魔鬼在细节中，如果从统计学上讲不一样，那么从医学或流行病学上讲也不应该一样。
我已经浏览过线程]]></description>
      <guid>https://stats.stackexchange.com/questions/648296/is-there-any-difference-between-an-independent-association-and-to-be-independ</guid>
      <pubDate>Thu, 30 May 2024 16:06:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中执行（流行病学）等时替代分析？</title>
      <link>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</guid>
      <pubDate>Thu, 30 May 2024 07:26:18 GMT</pubDate>
    </item>
    <item>
      <title>具有聚类 SE 或 GLMER 的 GLM</title>
      <link>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</link>
      <description><![CDATA[我正在对 113 名受试者进行行为经济学实验，每人回答从 10 个问题中随机挑选出的 6 个问题。我的因变量是二进制的（错误 = 0 或错误 = 1），我正在使用逻辑回归。我不知道在具有个体随机效应的 GMLER 或 GLM 之间选择什么，然后在个体层面上聚类 SE。我认为两者都可以控制个体内相关性 + GMLER 还增加了个体间变异性。我尝试了这两种模型，但得到了非常不同的结果，我不确定如何解释它以及选择哪种模型......特别是我不明白为什么我的所有系数在 GMLER 中都是显著的，但在 GLM 中却不是。这是否意味着随机效应捕获了部分无法解释的方差？因此 GMLER 是一个更好的模型？感觉我的 p 值“好得令人难以置信”......感谢您的帮助
我使用 GLM（上）和 GLMER（下）进行了两次逻辑回归，并比较了结果。我得到了非常不同的标准错误和 p 值……我应该相信哪一个？

# glm
model2 &lt;- glm(Error ~ Complexity + Response_time +Response_time:Complexity, family = binomial(&quot;logit&quot;), data = B)
clustered_se2 &lt;- coeftest(model2, vcov. = vcovCR(model2, cluster = B$Individual, type = &quot;CR2&quot;))
p_values2 &lt;- clustered_se2[, 4]

# glmer
model &lt;- glmer(Error ~ Complexity + Response_time +Response_time:Complexity+ (1 | Individual), family = binomial(&quot;logit&quot;), data = B)

]]></description>
      <guid>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</guid>
      <pubDate>Wed, 29 May 2024 16:08:04 GMT</pubDate>
    </item>
    </channel>
</rss>