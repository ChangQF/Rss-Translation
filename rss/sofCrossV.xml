<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 17 May 2024 12:25:34 GMT</lastBuildDate>
    <item>
      <title>RCT中的多重插补方法</title>
      <link>https://stats.stackexchange.com/questions/647423/multiple-imputation-method-in-rct</link>
      <description><![CDATA[我们决定在随机对照试验中使用多重插补方法来解决一些后续缺失数据的问题（由于完全随机的原因）。我计划使用 SPSS 的多重插补方法，默认情况下运行 5 次迭代。我的问题是：在这种情况下这 5 次迭代足够吗？有人对此有经验吗？我以前从来没有这样做过，也不是很有信心。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647423/multiple-imputation-method-in-rct</guid>
      <pubDate>Fri, 17 May 2024 12:19:10 GMT</pubDate>
    </item>
    <item>
      <title>从高斯分布中获取的一式三份样本中观测值分布的分布</title>
      <link>https://stats.stackexchange.com/questions/647422/distribution-of-a-spread-of-observations-in-triplicate-sample-taken-from-gaussia</link>
      <description><![CDATA[假设从具有已知均值和 SD 的高斯分布中随机抽取一式三份样本。每个样本中 3 个可能的观测值对之间的最大绝对差应该是什么分布（一式三份的范围）？]]></description>
      <guid>https://stats.stackexchange.com/questions/647422/distribution-of-a-spread-of-observations-in-triplicate-sample-taken-from-gaussia</guid>
      <pubDate>Fri, 17 May 2024 11:25:49 GMT</pubDate>
    </item>
    <item>
      <title>我可以将中心极限定理的两个独立结果相加吗？</title>
      <link>https://stats.stackexchange.com/questions/647420/can-i-add-two-independent-results-from-the-central-limit-theorems</link>
      <description><![CDATA[我正在阅读 R. Hogg 等人撰写的数理统计简介。
我很难理解极限分布。
设 $X_1,\cdots,X_{n_1}$ 为来自 $Bernoulli(p_1)$ 的独立同分布随机变量 并让 $Y_1,\cdots,Y_{n_2}$ 为来自 $Bernoulli(p_2) 的 iid 随机变量）$。感兴趣的假设如下：
$$H_0: p_1=p_2\ \text{vs}.\ H_1: p_1\ne p_2.$$
根据中心极限定理，我认为我们可以有
$$\frac{\sqrt{n_i}(\hat{p}_i-p_i)}{\sqrt{p_i(1-p_i)}}\to Z_i\ \text{分布},\ i=1,2,$$
由于 $\hat{p_1}=(\sum_{i=1}^{n_1} x_i)/n_1$，那么它是独立随机变量的总和 (当然它有 $1/n$)。
假设$i=1,2$，为$n\to\infty,\ n_i/n\到 \lambda_i$，其中 $0&lt;\lambda_i&lt;1$ 和 $\lambda_1+\lambda_2=1 $。然后我想证明一下
$$\sqrt{n}[(\hat{p_1}-\hat{p_2})-(p_1-p_2)]\to N(0,\frac{1}{ \lambda_1}p_1(1-p_1)+\frac{1}{\lambda_2}p_2(1-p_2)).$$
我尝试过的
我认为我不能只从 CLT 中添加两个限制分布，因为该加法并不适用于分布收敛。
我也尝试用 CLT 来证明它，但我认为我不能使用它，因为 $\hat{p_1}-\hat{p_2}$ 不是总和尽管 $\hat{p_1}-\hat{p_2}=(\sum X_i)/{n_1} - (\sum Y_j)/{n_2}$ 是独立的。
你能解释一下如何证明分布收敛吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647420/can-i-add-two-independent-results-from-the-central-limit-theorems</guid>
      <pubDate>Fri, 17 May 2024 11:11:46 GMT</pubDate>
    </item>
    <item>
      <title>两个骰子都是 6 的概率是 1/36。 $\alpha = .05$ 具有统计显着性吗？</title>
      <link>https://stats.stackexchange.com/questions/647419/probability-of-two-dice-being-6-is-1-36-is-that-statistically-significant-for</link>
      <description><![CDATA[在一个样本 t 检验中，当样本均值过于极端时，我们称其具有统计显着性。
虽然这对骰子的例子不满足单样本 t 检验的假设，但我们可以说：

$P(\text{样本平均值} \geq 5) = \frac{4}{36}$
$P(\text{样本平均值} \geq 6) = \frac{1}{36}$

让我们设置$\alpha = .05$。
对于第一种情况，骰子似乎是公平的，因为获得如此极端的样本均值的可能性是 $\geq .05$。
对于第二种情况，我们是否应该说骰子不公平？
我一定错过了一些东西，因为这有点类似于在 21 面公平骰子中获得 21，这不应该直接表明骰子不公平。]]></description>
      <guid>https://stats.stackexchange.com/questions/647419/probability-of-two-dice-being-6-is-1-36-is-that-statistically-significant-for</guid>
      <pubDate>Fri, 17 May 2024 10:59:57 GMT</pubDate>
    </item>
    <item>
      <title>具有 BF 相关性的单尾贝叶斯相关假设，解释输出？</title>
      <link>https://stats.stackexchange.com/questions/647418/one-tailed-bayesian-correlation-hypothesis-with-bfcorrelation-interpretation-ou</link>
      <description><![CDATA[对于以下命令：
correlationBF(df$var1, df$var2, nullInterval = c(-1, 0))

我得到了结果输出
贝叶斯因子分析
--------------
[1]替代，r=0.333 -1＜rho＜0：96.40458±NA%
[2]替代，r=0.333!(-1＜rho＜0)：0.06047267±NA%

反对分母：
  空，rho = 0
---
贝叶斯因子类型：BFcorrelation、Jeffreys-beta*

我现在想要获得假设相关性  的 BF。 0. 起初我以为是 96.4，但我很困惑，因为备择假设的 BF 不应该是 1/96.4 而不是 0.06 吗？
或者我需要将两个结果相除，但为什么？
非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647418/one-tailed-bayesian-correlation-hypothesis-with-bfcorrelation-interpretation-ou</guid>
      <pubDate>Fri, 17 May 2024 10:23:46 GMT</pubDate>
    </item>
    <item>
      <title>相关数据的排名概率</title>
      <link>https://stats.stackexchange.com/questions/647414/rank-probabilities-for-dependent-data</link>
      <description><![CDATA[众所周知，对于 iid 样本 $X_1, \dots, X_T$ 排名概率在 $1 上是均匀的， \点，T$。换句话说，固定$1 \le i_0 \le T$，概率为$X_{i_0}$排名为 $k$（即 $X_{i_0} = X_{(k)}$）是 $1/n$。
我对这样的概率感兴趣，但对于非独立同分布随机变量的情况。即，令 $\hat{z}_1, \dots, \hat{z}_T$ 为估计的 GARCH 残差（它们显然是非独立同分布的）。我想绑定 $\mathcal{P}(\hat{z}_{i_0} = \hat{z}_{(k)})$ （理想情况下我正在寻找订单的界限 $1/T$)。
如果有任何有助于估计相关数据的排名概率的文献/提示，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/647414/rank-probabilities-for-dependent-data</guid>
      <pubDate>Fri, 17 May 2024 09:57:19 GMT</pubDate>
    </item>
    <item>
      <title>具有连续时间观测的高斯过程的贝叶斯推理</title>
      <link>https://stats.stackexchange.com/questions/647413/bayesian-inference-of-a-gaussian-process-with-a-continuous-time-obervations</link>
      <description><![CDATA[在许多关于基于高斯过程的贝叶斯推理的书中，都假设人们只能在离散点上观察一组数据/信号。这是一个非常现实的假设。然而，在一些理论模型中，我们可能想要假设数据/信号的连续体。在这种情况下，我发现编写联合分布矩阵非常困难。谁能提供一些处理这种情况的指导或教科书？预先感谢您的帮助！
具体来说，考虑最简单的独立同分布情况。令 $\theta_x$ 为未知的真实兴趣状态，其中 $x\in[0,1]$ 是一个连续标签。先前的信念是 $\theta_x$ 遵循高斯过程。观察到根据 $s_x=\theta_x+\epsilon$$s_x$ &gt; 其中 $\epsilon$ 是高斯误差。我如何将后验信念导出为高斯过程？我凭直觉知道它与离散情况非常相似，但我就是不知道如何严格证明它。]]></description>
      <guid>https://stats.stackexchange.com/questions/647413/bayesian-inference-of-a-gaussian-process-with-a-continuous-time-obervations</guid>
      <pubDate>Fri, 17 May 2024 09:51:25 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/647410/confidence-interval-for-glmm</link>
      <description><![CDATA[我正在为我的学士论文进行 GLMM，我想知道如何计算以及报告模型估计的置信区间是否常见。
这是我根据数据拟合的模型：
glmer(response_time ~ 1 + 饥饿评级 + 篮子大小 + 饥饿评级:篮子大小 + (1|prolific_id), data = GLMM_data, family=“inverse.gaussian”(link=&#39;identity&#39;), control = glmerControl(优化器=“bobyqa”,optCtrl=list(maxfun=2e9),calc.derivs = FALSE))
]]></description>
      <guid>https://stats.stackexchange.com/questions/647410/confidence-interval-for-glmm</guid>
      <pubDate>Fri, 17 May 2024 08:55:11 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中嵌套项的灵活协方差结构</title>
      <link>https://stats.stackexchange.com/questions/647407/flexible-covariance-structure-of-the-nested-term-in-linear-mixed-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647407/flexible-covariance-structure-of-the-nested-term-in-linear-mixed-model</guid>
      <pubDate>Fri, 17 May 2024 08:15:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $\epsilon (X - X')$ 和 $(X - X')$ 具有完全相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</link>
      <description><![CDATA[设 $\epsilon \in \{-1, 1\}$ 为 Rademacher 随机变量，
$X$ 为随机变量，$X&#39;$ 为 $X$ 的独立副本。
为什么 $\epsilon (X - X&#39;)$ 和 $(X - X&#39;)$ 具有相同的分布？
鉴于 $X-X&#39;$ 围绕 $0$ 对称，这在直观上是正确的，但如何证明呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</guid>
      <pubDate>Fri, 17 May 2024 05:35:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyMC 中的新数据点对后验进行重新采样 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</link>
      <description><![CDATA[我有一些数据
X = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
y = np.array([0, 1, 0, 1, 1])

我拟合了一个模型
使用 pm.Model() 作为模型：
X_shared = pm.Data(&quot;X_data&quot;, X)
beta_0 = pm.Normal(&quot;beta_0&quot;, mu=0, sigma=1)
beta_1 = pm.Normal(&quot;beta_1&quot;, mu=0, sigma=1)
mu = beta_0 + beta_1 * X_shared
p = pm.math.sigmoid(mu)
y_obs = pm.Bernoulli(&quot;y_obs&quot;, p=p, perceived=y)
trace = pm.sample(100)

现在我想根据新的数据点重新采样后验
使用模型：
pm.set_data({&quot;X_data&quot;: [1.69]})
y_new_simulated = pm.sample_posterior_predictive(trace).posterior_predictive.y_obs
y_new_obs_name = f&quot;y_new_obs_1&quot; # 为伯努利变量创建一个唯一的名称
y_new_obs = pm.Bernoulli(y_new_obs_name, p=pm.math.sigmoid(beta_0 + beta_1 * 1.69), perceived=y_new.posterior_predictive.y_obs)
new_trace = pm.sample(100)

但我收到广播错误：
ValueError：不允许运行时广播。

我的目标是尝试弄清楚新数据点 X（并假装我们没有观察到 y 而是必须模拟它）是否通过比较旧轨迹和新轨迹来添加信息]]></description>
      <guid>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</guid>
      <pubDate>Fri, 17 May 2024 02:31:21 GMT</pubDate>
    </item>
    <item>
      <title>BerHu XGBoost 的自定义损失函数</title>
      <link>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</link>
      <description><![CDATA[我想要一个损失函数，它可以惩罚像 平方损失 这样的异常值，同时处理较小的损失误差不那么严重，例如绝对损失。看来我正在寻找一个 Huber loss 函数，但反过来，所谓的BerHu （提供我第一次看到它使用的论文，你可以在部分找到它&gt;3.2. 损失函数):
$$\mathrm{BerHu}_{\delta}(x)=\begin{cases} |x|, \text{ if } x\le \delta \\ \frac{ x^2 + \delta^2}{2\delta}, \text{ if } x&gt; \delta \end{案例}$$
我想将其实现为 XGBoost 的自定义损失。对于这个实现，如果我没有记错的话，您需要提供损失的梯度和粗麻布。然而，BerHu 不可二次微分，因为它包含绝对值项。 
我认为正是由于这个原因，XGBoost 不会 甚至有一个 Huber 损失的实现，而不是使用 Pseudo-Huber 损失。 
基本上我有两个问题：

尝试实现 XGBoost 的 BerHu 损失函数的最佳方法是什么？也许我错了，有一种方法可以完全按原样实现它。
如果不可能，“Pseudo-BerHu”的类似物将如何实现？看起来像？我不太明白 Pseudo-Huber 损失如何近似 Huber 损失，所以我正在努力想出类似的方法。

非常感谢有关此事的任何建议。如果已经存在另一个具有相同目的的函数，该函数是二次可微的，那么我也很想知道它]]></description>
      <guid>https://stats.stackexchange.com/questions/647393/berhu-custom-loss-function-for-xgboost</guid>
      <pubDate>Thu, 16 May 2024 23:57:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 nls() 对非常嘈杂的数据进行非线性回归</title>
      <link>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</link>
      <description><![CDATA[我正在尝试将噪声数据拟合到具有两个我想估计的参数的特定模型。不幸的是，模型拟合很糟糕，噪声也增加了。我可以做些什么来改善这种契合度吗？
公式/模型如下所示：
model_form &lt;- as.formula(y ~ 1/((1/i)-(r*x)))
下面我创建了一些数据的示例。 噪声只是随机的附加噪声，也出现在我的真实数据集中（生物起源）。如果没有此噪音，nls() 拟合效果良好，最终估计 r 和 i 足够好。但随着噪声的增加，尽管热图中存在可见的模式，但模型拟合和参数估计很差。
使用示例参数 i 和 r 创建样本数据（这些参数实际上未知，但仅限于特定的已知区间）：
## 创建示例数据
my_i &lt;- 0.5 # i 参数示例
my_r &lt;- 100 # r 参数示例
d &lt;- data.frame(x=c(-rexp(500,rate=10),
                    seq(-1,0,length.out = 500))) %&gt;%
    突变（y=抖动（1/（（1/my_i）-（my_r * x）），1000））
噪声 &lt;- data.frame(x=runif(1000,-1,0),
                    y=runif(1000,0,0.5))
d &lt;-bind_rows(d,噪声)

以下函数使用上面的 model_form 将该数据拟合为 nls。
fitPlot &lt;- 函数（数据）{
    适合 &lt;- nls(model_form,数据,
               开始=列表(r=10,i=0.3))

    fit_r &lt;- 摘要(fit)$coefficients[&quot;r&quot;,1]
fit_i &lt;- 摘要(fit)$系数[“i”,1]

    预测 &lt;- data.frame(x=seq(-1,0,length.out=1000)) %&gt;%
        变异(y=1 / (1/fit_i - fit_r * x))

    p &lt;- ggplot(数据)+
        geom_bin2d(aes(x,y),bins=14)+
        geom_line(数据=预测,aes(x,y))+
        注释（“标签”，x=-0.7，y=0.5，
                 标签=paste0(“r:”,fit_r,”, i:”,fit_i))
    p
}

拟合图(d)


尽管随机添加了噪声，但函数生成的主要模式（靠近 0 和 x 轴）在热图中仍然可见。我希望模型能够很好地适应这个地方。
此时我能做些什么吗？我已经尝试过了

具有可能的 i 和 r 值的网格搜索 = 与 nls 相同的结果
optim具有不同的优化方法，具有最小化SS的功能
nlrob 来自使用不同方法的Robustbase

我在这一点上迷失了，不知何故必须有一种方法来创建一个强大的模型？不知何故，我需要减少对异常值的惩罚，但是怎么做呢？欢迎任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</guid>
      <pubDate>Thu, 16 May 2024 23:02:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么 cdf $F$ 的最大 n 个 iid 随机变量的 cdf 是 $F^n$ 而不是 $F(\cdot)^{n-1}f(\cdot)$？</title>
      <link>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-of-the-maximum-of-n-iid-random-variables-with-cdf-f-is-fn-an</link>
      <description><![CDATA[当我从精算概率问题样本库中解决问题#64时，我想到了这个问题：https://www.soa.org/globalassets/assets/Files/Edu/edu-exam-p-sample-quest.pdf 
这里也给出了解决方案：https://www.soa.org/499179/globalassets/assets/files/edu/edu-exam-p-sample-sol.pdf
如果您有任何疑问，请告诉我，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/647390/why-is-the-cdf-of-the-maximum-of-n-iid-random-variables-with-cdf-f-is-fn-an</guid>
      <pubDate>Thu, 16 May 2024 22:56:54 GMT</pubDate>
    </item>
    <item>
      <title>有向边可见吗？</title>
      <link>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</link>
      <description><![CDATA[
以上两个PAG（部分祖先图）都是在相同条件下使用FCI（快速因果推理）算法生成的，唯一的区别是右边的PAG是在从数据集中排除变量5后生成的。

有人可以帮我确定右侧 PAG 中 9 到 11 之间的有向边是否可见并解释一下此分析中涉及的步骤吗？
对于 9 和 11 可能存在不可测量的混杂因素，上述分析意味着什么？
正确的 PAG 是否表示 9 是 11 的父代或祖先？请解释一下。

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647364/is-the-directed-edge-visible</guid>
      <pubDate>Thu, 16 May 2024 15:07:50 GMT</pubDate>
    </item>
    </channel>
</rss>