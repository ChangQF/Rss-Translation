<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 05 Mar 2024 15:14:02 GMT</lastBuildDate>
    <item>
      <title>我们什么时候可以计算 Westfall 和 Young 的 $p$ 值？</title>
      <link>https://stats.stackexchange.com/questions/641894/when-can-we-compute-westfall-and-youngs-p-values</link>
      <description><![CDATA[Westfall和Young提供了调整$p$ - 多个假设检验后的值。我有两个关于何时可以应用此方法的问题：

当（未更正的）$p$值时，可以计算更正的$p$值吗？ span&gt;-值本身是使用引导标准错误计算的吗？我认为这至少在计算上非常昂贵。

在我只估计一个回归模型但想要测试的情况下，是否可以计算修正后的$p$值与几个不同的解释变量相关的一系列假设？ （例如，假设我估计回归 $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + u$ 并想要测试 $\beta_1 = 0$ 和 $\beta_2 = 0$。）我假设第二个的答案问题是“是”。但是，我之所以这么问，是因为据我所知，Stata 中唯一的实现（wyoung）不会计算 $p$-值在这种情况下。

]]></description>
      <guid>https://stats.stackexchange.com/questions/641894/when-can-we-compute-westfall-and-youngs-p-values</guid>
      <pubDate>Tue, 05 Mar 2024 14:33:08 GMT</pubDate>
    </item>
    <item>
      <title>成对的概率</title>
      <link>https://stats.stackexchange.com/questions/641893/probability-of-pairs</link>
      <description><![CDATA[假设$N$个人每人生成一个随机数$[1,\cdots,N]$。平均而言，会有多少对，因为一对意味着 $i$ 生成了 $j$ 和人 $j$ 生成 $i$？]]></description>
      <guid>https://stats.stackexchange.com/questions/641893/probability-of-pairs</guid>
      <pubDate>Tue, 05 Mar 2024 14:11:25 GMT</pubDate>
    </item>
    <item>
      <title>同时发生事件的比例测试</title>
      <link>https://stats.stackexchange.com/questions/641892/proportion-testing-for-co-occuring-events</link>
      <description><![CDATA[我有一个数据集，其中测试了 4 组是否存在 15 种细菌感染：

&lt;标题&gt;

组
病毒1
病毒2


&lt;正文&gt;

第一个
8
8


第二个
2
1



目标是测试不同群体是否因病毒流行情况而存在差异。问题是这些组中的受试者同时感染了多种病毒（例如第二组中的 A 人同时感染了病毒 1、2、3...）。
考虑到事件不是不相交的，可以应用什么样的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/641892/proportion-testing-for-co-occuring-events</guid>
      <pubDate>Tue, 05 Mar 2024 14:02:10 GMT</pubDate>
    </item>
    <item>
      <title>调整理论1型误差使测试有效是否正确？</title>
      <link>https://stats.stackexchange.com/questions/641890/is-it-correct-to-adjust-theoretical-type-1-error-to-make-test-valid</link>
      <description><![CDATA[假设我有两个预定义的组：A 和 B，我正在对它们执行 AB 测试。我有他们的历史数据，我想调查新功能的效果：B 组打开了此功能，而 A 组没有。问题是小组分配不是随机的，并且正常的 AB 测试不适用。因此，我尝试了一些因果推理方法。
我尝试根据历史数据验证我的方法（在新功能发布之前），但所有方法都产生了具有统计显着性的结果（默认 p 值阈值 = 0.05）。我的解释是 CI 方法未能消除群体之间的偏见。
我所做的是对历史数据执行 bootstrap，选择调整后的 pvalue 阈值（假设为 0.00001），这样只有 5% 的 bootstrap 样本产生了显着的结果。按照设计，历史数据的 I 类错误为 0.05，这正是我想要的。
然后我在试点期间（当该功能发布时）使用了这个阈值。如果 p 值 &lt;= 调整后的 p 值阈值，我将结果标记为显着，而不是与默认阈值 0.05 进行比较。我认为通过调整 pvalue 阈值，我也增加了 II 类错误，但我主要担心的是这种方法的正确性，因为有些结果仍然很显着。
所以我想知道：

我的方法是否正确，即我是否仍然遇到 I 类错误 试点期间为 0.05？
此方法有广为人知的名称吗？我可以查阅任何文献吗？或者如何通过 Google 搜索？
似乎您可以使任何统计测试“有效”通过此 p 值阈值调整，无论是否违反假设。我是不是漏掉了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/641890/is-it-correct-to-adjust-theoretical-type-1-error-to-make-test-valid</guid>
      <pubDate>Tue, 05 Mar 2024 13:22:33 GMT</pubDate>
    </item>
    <item>
      <title>对具有强季节性的时间序列进行建模</title>
      <link>https://stats.stackexchange.com/questions/641889/modeling-timeseries-with-strong-seasonality</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/641889/modeling-timeseries-with-strong-seasonality</guid>
      <pubDate>Tue, 05 Mar 2024 13:18:21 GMT</pubDate>
    </item>
    <item>
      <title>最后一步的误分类概率是怎么推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/641888/how-the-misclassification-probability-of-this-last-step-is-derived</link>
      <description><![CDATA[设 $\bar{\beta}_1$ 和 $\bar{\beta}_2$ 表示两种不同的大效应。我们假设这两种效应的实现遵循正态分布，
$$
\开始{对齐}
&amp; \beta_{1, i} \mid \bar{\beta}_1 \sim \mathrm{N}\left(\bar{\beta}_1, \phi^2\right) i=1,2, \ldots \ \
&amp; \beta_{2, j} \mid \bar{\beta}_2 \sim \mathrm{N}\left(\bar{\beta}_2, \phi^2\right) j=1,2, \ldots,
\结束{对齐}
$$
分别。这里， $\beta_{1, i}$ 表示宏大效果的实现 $\beta_1$ 在每个 $i^{\text {th }}$ 实验中，这也代表了每个实验中潜在的真实效果。类似地， $\beta_{2, j}$ 是 $\beta_2$ 的实现。不失一般性，我们假设两种效应的异质性相同，并通过方差参数 $\phi^2$ 进行量化。
基于该生成模型，误分类概率为 $P_{\mathrm{mis}}\left(\bar{\beta}_1, \bar{\beta}_2 , \phi^2\right)$，可以通过以下方式计算
$$
P_{\text {mis }}\left(\bar{\beta}_1, \bar{\beta}_2, \phi^2\right)
$$
$$
\开始{对齐}
&amp; =\operatorname{Pr}(\text { 效果 } \beta \text { 从其生成效果中被错误分类 }) \\
&amp; =\operatorname{Pr}\left(\beta \mapsto \bar{\beta}_1 \mid \beta \cong \bar{\beta}_2\right) \operatorname{Pr}(\beta \cong \bar{\ beta} 2)+\operatorname{Pr}\left(\beta \mapsto \bar{\beta}_2 \mid \beta \cong \bar{\beta}_1\right) \operatorname{Pr}(\beta \cong \bar{\beta} 1),
\结束{对齐}
$$
其中 $\beta \mapsto \bar{\beta}_1$ 表示 $\beta$ 已分类/映射到$\bar{\beta}_1$; $\beta \cong \bar{\beta}_1$ 表示生成 $\beta$来自 $\bar{\beta}_1$。假设 $\bar{\beta}_1$ 和 $\bar{\beta}_2$ 具有可互换性span&gt;，这意味着
$$
\operatorname{Pr}(\beta \cong \bar{\beta} 1)=\operatorname{Pr}(\beta \cong \bar{\beta} 2)=\frac{1}{2}
$$
此外，
$$
\开始{对齐}
&amp; \operatorname{Pr}\left(\beta \mapsto \bar{\beta}_1 \mid \beta \cong \bar{\beta}_2\right)=\operatorname{Pr}\left(\beta \mapsto \bar {\beta}_2 \mid \beta \cong \bar{\beta}_1\right) \\
&amp; =\int_{-\infty}^{\infty} \frac{\mathrm{N}\left(\beta ; \bar{\beta}_1, \phi^2\right) \mathrm{N}\left( \beta ; \bar{\beta}_2, \phi^2\right)}{\mathrm{N}\left(\beta ; \bar{\beta}_1, \phi^2\right)+\mathrm{ N}\left(\beta ; \bar{\beta}_2, \phi^2\right)} d \beta
\结束{对齐}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/641888/how-the-misclassification-probability-of-this-last-step-is-derived</guid>
      <pubDate>Tue, 05 Mar 2024 13:02:41 GMT</pubDate>
    </item>
    <item>
      <title>作为一组线性变换的简单 ANN</title>
      <link>https://stats.stackexchange.com/questions/641885/simple-ann-as-a-set-of-linear-transformations</link>
      <description><![CDATA[我们无法使用隐藏层中的单个感知器对 XOR 问题的点进行分类。然而，我们可以通过在隐藏层使用两个感知器和在输出层使用一个感知器来实现这一点，而不使用激活函数。输入层由两个感知器组成。有一个隐藏层和一个输出层，有两个权重矩阵：第一个矩阵 $A$ 是 $2*2$ ，第二个矩阵$B$是$1*2$。让我们考虑 $A=[[1,1],[0,1]]$ 和 $B=[-2 ,2]$。在前向传播过程中，我们通过矩阵 $A$ 对 $X$ 向量进行线性变换，得到在 $R²$ 中的新向量中。然后这个新向量通过矩阵 $B$ 进行线性变换以产生输出。这意味着我们需要做的就是 $B(AX)$。这就是我的问题出现的地方：
经过研究，发现矩阵乘法是结合律的，即$B(AX)=(BA)X$，并且两个线性变换的组合是线性变换。 $A$ 和 $B$ 的组合会产生另一个矩阵，表示为 $K$ 形状为 1x2。因此，$B(AX)=KX$。这里的关键是学习 $K$ ；最初，我们通过处理单独的线性变换来实现这一目标，但我们可以通过在隐藏层中仅选择一个感知器来让人工神经网络 (ANN) 一步完成此任务。然而，这种做法是不正确的。那么，我的问题出在哪里？”.]]></description>
      <guid>https://stats.stackexchange.com/questions/641885/simple-ann-as-a-set-of-linear-transformations</guid>
      <pubDate>Tue, 05 Mar 2024 12:40:55 GMT</pubDate>
    </item>
    <item>
      <title>自定义 pytorch DataFrame 时 pandas 发出警告 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/641884/warning-in-pandas-when-customizing-pytorch-dataframe</link>
      <description><![CDATA[我正在编写一个自定义（但简单）数据集，用于使用 PyTorch 训练 MLP。基本上，我的数据是两个类的数值向量，因此整个数据集是一个 pandas.DataFrame ，其第一列是 0 或 1 （代表两个类），其余列是向量的数值分量。由于每一行代表一个数据，我认为自然的 PyTorch 的数据集类将是：
类 MatrixDataset(数据集):
    def __init__(self, 数据: pd.DataFrame, 设备):
        self.data = 数据
        self.device = 设备

    def __len__(自身):
        返回 self.data.shape[0]

    def __getitem__(self, ind):
        行 = self.data.iloc[ind]
        x = torch.tensor(row.iloc[1:], dtype=torch.float32, device=self.device)
        y = torch.tensor(row.iloc[0], dtype=torch.float32, device=self.device)
        返回 x、y

实际上，这个数据集工作正常，但我收到以下警告
/path_to_my_script/script.py：FutureWarning：Series.__getitem__ 将键视为位置已被弃用。在未来的版本中，整数键将始终被视为标签（与 DataFrame 行为一致）。要按位置访问值，请使用 `ser.iloc[pos]`
  x = torch.tensor(row.iloc[1:], dtype=torch.float32, device=self.device)

搜索完这个警告后，我仍然不明白为什么它会触发，因为很多人都说这个警告是不言自明的：“使用 .iloc 方法”，但我已经在使用它了。此外，我尝试在终端中使用 Python 解释器复制该错误，但它没有触发。
如有任何帮助，我们将不胜感激，提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/641884/warning-in-pandas-when-customizing-pytorch-dataframe</guid>
      <pubDate>Tue, 05 Mar 2024 12:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用统计软化逻辑含义</title>
      <link>https://stats.stackexchange.com/questions/641882/softened-logical-implication-using-statistics</link>
      <description><![CDATA[在机器学习应用程序中，我有以下布尔含义 $$\forall\,x,y:I_b(x,y)\rightarrow E_b(x,y), $$ 其中 $I_b(x,y)$ 为 true 意味着 $x$ 并且$y$ 是同构的，并且 $E_b(x,y)$ 为 true 意味着之间的距离$x$ 和 $y$ 模型生成的嵌入为零。
现在，我想通过引入 $I(x,y)$ 来软化这种条件，它现在是 $x$ 和 $y$ 使得 $I(x, y)$$x$ 和 $y$ 同构时，&gt; 为 0，而该数较小且为正数“几乎”同构 $x&#39;$ 和 $y&#39;$，对于其他情况则较大且为正值。我还将介绍 $E(x,y)$，它只是 $L_2$ 距离在 $x$ 和 $y$ 的嵌入之间。有了这个，我仍然可以声明 $$\forall\,x,y:\text{Low } I(x,y)\rightarrow\text{Low }E(x, y).$$ 我有 $I(x,y)$ 和 $E( x,y)$ 对于我的所有 $x$ 和 $y$ 对数据集。我如何以统计方式验证上述含义在我的数据集中是否成立。
我想过使用相关性，但相关性是对称的，而含义是单向的。另外，我知道我必须对 $I(x,y)$ 和 $E(x ,y)$ 也使它们成为布尔值，但是这个阈值如何影响含义的真实性？我不知道如何解决最后一个问题。我还在 x- 上绘制了 $I_{\text{similarity}}(x,y)=e^{-I(x,y)}$ 的值axis 和 y 轴上的 $E(x,y)$ （因为我的同事计算了 $I_{\text{similarity }}(x,y)$ 而不是原始的 $I(x,y)$），我应该看到与 $I_\text{相似度}(x,y)$ 和 $E(x,y)$，但是我现在无法理解该图表。
任何解决此问题的方向都值得赞赏。
]]></description>
      <guid>https://stats.stackexchange.com/questions/641882/softened-logical-implication-using-statistics</guid>
      <pubDate>Tue, 05 Mar 2024 11:02:18 GMT</pubDate>
    </item>
    <item>
      <title>在纵向线性混合模型中根据 t 分数计算 Cohen d 的有效性</title>
      <link>https://stats.stackexchange.com/questions/641878/validity-of-calculating-cohens-d-from-t-score-in-longitudinal-linear-mixed-mode</link>
      <description><![CDATA[我正在使用纵向线性混合模型分析来自试点研究的一些数据。由于心理学中的惯例，为了可解释性，通常在 Cohen 的 $d$ 中报告效果大小。我发现这篇文章让我了解了 EMAtools 包和函数 lme.dscore()。
为了帮助澄清我的问题，它可能有助于描述我想要描述的数据结构和效应大小的类型。我对 20 名患者进行了为期 10 周的随访，每周进行评分。我想描述组内变化效应的大小。使用 lme4 包，我对模拟数据进行了建模，如下所示：lmer(y ~weeks + (weeks | id), data = df)，因此随机截距和随机斜率以及时间/周的固定效应。
模拟数据的直观描述也可能有助于澄清：

以下是 20 名模拟个体在 10 周内的随机效应示例（随机截距和斜率）。
我想用$d$来描述固定效应。 lme.dscore() 函数似乎使用以下公式：
$$d=\frac{2t}{\sqrt{df}}$$
我在从简单的 t 检验中提取 Cohen d 的背景下很熟悉，但我不确定它在这种情况下是否有意义？
为了进行比较，我的一位同事引用了Feingold (2013) 并使用了一个如下所示的公式（如果我解释正确的话）：
$$d=\frac{b*duration}{SD_{pre}}$$
这两种方法会产生截然不同的估计，并且可能存在很大差异。例如，lme.dscore() 方法更容易受到斜率方差的影响，而 Feingold 方法几乎不会受到影响 - 只要斜率的平均效果 $b$ 与方法产生相同的 d 分数相同。如果我们将效应大小视为个体进步概率的衡量标准，这对我来说似乎很奇怪。就效果的确定性而言，斜率之间具有低变异性的情况似乎与斜率之间具有高变异性的情况有所不同。 （或者换句话说，个体内相关性，或者在更简单的设置前后相关性中，不应该影响估计吗？）
很高兴了解转换为 $d$ 的方法是否存在问题，或者至少有人为我指明了正确的方向。我目前正在学习 Feingold 方法，因为我的同事在那里工作有先例。]]></description>
      <guid>https://stats.stackexchange.com/questions/641878/validity-of-calculating-cohens-d-from-t-score-in-longitudinal-linear-mixed-mode</guid>
      <pubDate>Tue, 05 Mar 2024 10:26:09 GMT</pubDate>
    </item>
    <item>
      <title>如何确定系统是否平衡？</title>
      <link>https://stats.stackexchange.com/questions/641876/how-can-i-determine-if-a-system-is-equilibrated</link>
      <description><![CDATA[交叉发布于SCSE和MMSE
我正在尝试新的 MCMC 协议和新的研究。
在蒙特卡罗模拟的背景下，“平衡状态”指被模拟的系统已达到稳定配置或属性分布且不会随时间显着变化的情况。这种状态代表作用于系统的各种力、相互作用和约束之间的平衡或平衡。
我编写了以下函数来测试系统是否平衡：
将 numpy 导入为 np

def is_equilibrate(数据, shave_size=50000):
    返回 = 假
    mid_index = len(数据) // 2

    第一个半 = 数据[:mid_index]
    第二半=数据[中间索引：]

    小数 = 6

    而真实：
        first_auto_corr = np.correlate(first_half,first_half,mode=&#39;full&#39;)
        secondary_auto_corr = np.correlate(second_half, secondary_half, mode=&#39;full&#39;)

        corr1 = np.corrcoef(first_auto_corr, secondary_auto_corr)[0, 1]

        print(f&quot;大小 {len(first_half)} 与 {len(second_half)}&quot;)
        打印（f“corr = {corr1}”）

        第一半=第一半[剃须尺寸：]
        第二半=第二半[剃须尺寸：]

        如果 corr1 == 1.0：
            休息

    返回返回

该函数迭代地比较输入数据两半的自相关性，在每次迭代时缩短数据集，直到两半之间实现完美的相关（平衡）或直到手动终止循环。
我编写这个函数是为了检查我的模拟数据是否“成熟”足以进行分析，即足以通过计算提取更多信息。换句话说，它让我知道我运行模拟的时间是否足够长以获得有用的数据集。
该算法的缺点是它使用自相关计算，无论使用哪种编程语言，都会花费大量时间。
您能提出任何替代技术吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641876/how-can-i-determine-if-a-system-is-equilibrated</guid>
      <pubDate>Tue, 05 Mar 2024 09:49:47 GMT</pubDate>
    </item>
    <item>
      <title>使用校准砝码来纠正单位无响应偏差？</title>
      <link>https://stats.stackexchange.com/questions/641872/use-calibration-weights-to-correct-for-unit-non-response-bias</link>
      <description><![CDATA[我有一个关于如何使用校准权重来充分纠正单位无响应偏差的问题。假设样本为s，响应集为r。
校准应用于响应集r以生成尽可能接近原始采样权重的权重并且同时可以重现所选辅助变量的总体总数。如果辅助变量与单位响应概率和研究变量（强）相关，则将有助于纠正单位无响应偏差并减少方差。但是，我发现理解这一点并不直观。
另一种更直观的方法：首先，使用逻辑回归模型估计响应概率，然后除以估计的响应概率来更新采样权重，从而纠正单位无响应偏差；其次，使用校准进一步调整更新后的权重，以匹配某些变量的已知总体总数，从而减少方差。
总的来说，校准方法（第一种方法）似乎大大简化了过程，这让我想知道在处理单位无响应时它可能不是理想的方法。&lt; /p&gt;
任何想法或评论将不胜感激！ :)]]></description>
      <guid>https://stats.stackexchange.com/questions/641872/use-calibration-weights-to-correct-for-unit-non-response-bias</guid>
      <pubDate>Tue, 05 Mar 2024 08:53:56 GMT</pubDate>
    </item>
    <item>
      <title>将自定义（类似方差分析）对比应用于混合模型（具有堆叠数据集）中的所有交互</title>
      <link>https://stats.stackexchange.com/questions/641871/apply-custom-anova-like-contrasts-to-all-interactions-in-a-mixed-model-with-a</link>
      <description><![CDATA[我正在使用多类别 X（2×2 设计的 4 个级别）进行多级中介分析，我想应用自定义对比来编码两个主要效果和一个交互。对于具有两个指标变量（Sm 和 Sy）、数值结果（Y）和中介变量（M）的堆叠数据集，我有以下“问题”：调用 lmer 时：
下面的 model.matrix 显示 X 的对比仅应用于一个交互项 (Sy:X)，而不应用于其余交互项 (Sm:X)。因此，模型系数反映了 Sy:X 相互作用的这种对比，但对于 Sm:X，它们显示了与参考水平的比较。
&lt;预置&gt;&lt;代码&gt; Sm Sy Sm:X1 Sm:X2 Sm:X3 Sy:X1 Sy:X2 Sy:X3 Sy:M
1 0 1 0 0 0 -1 -1 1 1.5902378
2 0 1 0 0 0 -1 1 -1 0.8355516
3 0 1 0 0 0 1 -1 -1 0.7563719
4 0 1 0 0 0 1 1 1 0.3320396
5 0 1 0 0 0 -1 -1 1 1.4224360
....
121 1 0 1 0 0 0 0 0 0.000000
122 1 0 0 1 0 0 0 0 0.000000
123 1 0 0 0 1 0 0 0 0.000000
124 1 0 0 0 0 0 0 0 0.000000
125 1 0 1 0 0 0 0 0 0.000000
126 1 0 0 1 0 0 0 0 0.000000
127 1 0 0 0 1 0 0 0 0.000000

但是，我的想法是将 X 的自定义对比应用于涉及变量 X 的所有交互。我哪里遗漏了什么？
下面应该是一个可重现的示例：
DF 示例，包含 X（预测变量；分类）、M（中介变量；数值）、Y（结果；数值）、ID（分组变量；因素）：
库(lme4)
库（重塑2）
# 科目数量
n_科目 &lt;- 30

# 条件数
n_条件 &lt;- 4

# 条件级别
条件 &lt;- 因子(rep(1:n_conditions, times = n_subjects))

# 为具有主题和条件效应的中介变量 M 生成随机数据
M &lt;- rnorm(n_subjects * n_conditions, 平均值=rep(1:n_conditions,each = n_subjects), sd = 0.5)

# 为具有主题和条件影响的结果变量 Y 生成随机数据
Y &lt;- rnorm(n_受试者 * n_条件，平均值 = 代表(1:n_条件，每个 = n_受试者)，sd = 1)

# 创建一个数据框
DF &lt;- data.frame(ID = rep(1:n_subjects,each = n_conditions),
                   X = as.factor(条件),
                   中号=中号，
                   Y = Y）

创建自定义对比度并应用于 X：
 custom_contrasts &lt;- 矩阵(c(-1, -1, 1,
                                   -1, 1, -1,
                                   1、-1、-1、
                                   1, 1, 1),
                                 nrow = 4，byrow = TRUE）
对比(DF$X) &lt;- custom_contrasts

现在堆叠数据集：
DF$fid &lt;- 1:nrow(DF)
堆叠&lt;-melt(DF，id.vars＝c(“fid”，“ID”，“Y”，“X”，“M”)，
                measure.vars = c(&quot;Y&quot;, &quot;M&quot;), value.name = &quot;Z&quot;)
堆叠 &lt;- 内（堆叠，{
  Sy &lt;- as.integer(变量 == &quot;Y&quot;)
  Sm &lt;- as.integer(变量 == &quot;M&quot;)
})

堆叠数据集的原因是为了重新制定两个公式......
model.m = lme4::lmer(M ~ 1 + X + (1 | ID) , data = DF)
model.y = lme4::lmer(Y ~ 1 + X + M + (1|ID), data = DF)
...将新的响应变量 Z 转化为一个公式，其中 Y 堆叠在 M 上并估计模型*：
mm = lme4::lmer(Z ~ 0 + Sm + Sy + Sm:X+ Sy:X+ Sy:M+ (0 + Sm + Sy | ID) ，数据 = 堆叠)

Sm：M 的截距
Sy：Y 的截距 // Sm 和 Sy 是指示变量。
SmX：X-&gt;M（一条路径）的回归系数
SyM：M-&gt;Y 的回归系数（b 路径）
SyX：X-&gt;Y 的回归系数（cprime 路径）

参见：多级中介示例，了解如何以及为何堆叠数据集的另一个示例（在本例中，X 是数字，因此不需要对比）
现在，在检查 model.matrix 时，Sy:X1 到 Sy:X3 的对比度已正确编码。对于 Sm:X1 到 Sm:X3，对比度仍然是处理（？）对比度：
# 检查模型矩阵
m.matrix = getME(mm &quot;X&quot;)
视图(m.矩阵)

谢谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/641871/apply-custom-anova-like-contrasts-to-all-interactions-in-a-mixed-model-with-a</guid>
      <pubDate>Tue, 05 Mar 2024 08:51:13 GMT</pubDate>
    </item>
    <item>
      <title>模型选择：多级模型与具有交互作用的线性模型</title>
      <link>https://stats.stackexchange.com/questions/641856/model-choice-multilevel-vs-linear-model-with-interaction</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对以可变田园为代表的田园重点对农业的影响特别感兴趣。困难在于这个变量的影响会随着时间的推移而变化。我有两个模型，一个是多层次的，另一个是田园和年份之间相互作用的线性回归：
model1 &lt;- lmer(logitshare ~ 田园 + 其他变量 + (田园 | 年),
               数据=我的数据）
model2 &lt;- lm(logitshare ~ 田园+其他变量+田园：因子(年份)，
             数据=我的数据）

模型的输出相似。我想知道它们之间有什么区别。即，与基本 LM 相比，更复杂的多级模型有什么优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/641856/model-choice-multilevel-vs-linear-model-with-interaction</guid>
      <pubDate>Tue, 05 Mar 2024 03:59:10 GMT</pubDate>
    </item>
    <item>
      <title>查看泊松回归是否遵循必要的假设</title>
      <link>https://stats.stackexchange.com/questions/641830/seeing-if-a-poisson-regression-follows-the-necessary-assumptions</link>
      <description><![CDATA[我试图了解当错误没有精确分布时，模拟如何在检查模型假设方面发挥作用。
我采用了这个泊松回归模型：
$$\lambda_i = e^{(\beta_0 + \beta_1X_i)}$$
$$P(Y_i | X_i) \sim Poisson(\lambda_i = e^{(\beta_0 + \beta_1X_i)})$$
如何查看模型假设是否得到满足？
我想到了一些想法：

方法 1：我可以引导数据，在每个引导样本上拟合模型。如果满足模型假设，则所有模型的引导误差均值为 0，方差为 $\lambda_i$。 （这种方法似乎是计算量最大的方法，因为正在拟合多个模型）

方法 2：我将模型拟合到原始数据上，然后根据模型模拟新数据集...并比较真实的所有真实 $Y$与模拟的 $Y$ 相比。如果满足模型假设，则模型将能够非常接近地“再现”模型。观察到的数据。 （我不知道如何衡量所有 $x_i$ 的“接近度”）。这种方法似乎工作量较少，因为只适合一个模型。

方法 3（DHARMA 方法 https:/ /cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html)：我将模型拟合到原始数据上。拟合模型后，我在每个 $x_i$ 处生成多个 $y_i$ 值。对于给定的 $x_i$ ，我制作了模拟的 $y_i$ 的经验 CDF。对于在 $x_i$ 处实际观察到的 $y_i$，我找出了这个 $y_i$ 位于 CDF 上。如果模型很好地拟合数据，则此 $y_i$ 应该处于 50% 的水平（我不确定为什么 - 这是因为残差具有均匀分布吗？ ）。然后，我对每个 $x_i$ 重复此经验 CDF，并平均查看真实的 $y_i$ 是否为平均每个 CDF 接近 50% 的水平。 （这种方法也只涉及拟合一个模型）


这 3 种方法都正确吗？当误差没有精确分布时，这是正确使用模拟来验证模型假设的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641830/seeing-if-a-poisson-regression-follows-the-necessary-assumptions</guid>
      <pubDate>Mon, 04 Mar 2024 22:10:10 GMT</pubDate>
    </item>
    </channel>
</rss>