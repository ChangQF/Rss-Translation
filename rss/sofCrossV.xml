<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 31 Jul 2024 18:19:16 GMT</lastBuildDate>
    <item>
      <title>仅具有分类数据的混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/652104/mixed-effects-models-with-only-categorical-data</link>
      <description><![CDATA[这是我第一次尝试运行任何类型的混合效应模型。我有一个数据集，其中指示我使用某种形式的混合效应建模（lme4 包）来查看我的物种的功能性状（响应变量）是否因环境（城市化水平）而以某种方式传播。
这意味着我的响应变量将是功能性状（但我有大约 4 个，分类数据），我的固定效应将是城市化水平（低、中、高水平的因素），然后我的随机效应我认为只是物种。
我尝试使用以下方法，但它不起作用，我很确定这是因为我的数据是分类的。那么这是否意味着使用 glmer 之类的东西根本行不通？
我的数据有以下类别，我正在尝试使用以下公式：
 # 我的数据子集

属 性别 城市强度 社会性 嵌套 饮食 体型
&lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; 
1 Ceratina M 中等 亚社会性 腔内 通才 小 
2 Xenoglossa F 低 独居 地面 专家 大 
3 Bombus F 高 社会性 地面 通才 大 
4 Agapostemon F 低 独居 地面 通才 小 
5 Ceratina M 低 亚社会性 腔内 通才 小 
6 Xenoglossa F 低 独居 地面 专家 大 

# 功能性状是否受城市强度水平影响？
模型 &lt;- glmer((BodySize,Sociality,Nesting,Diet) ~ UrbanIntensity + (1|Genus), data=data)

但我的模型显然是错误的，因为我也不认为我可以一次拥有多个响应变量。我确实也拥有每个属的丰度，我认为可以将其用作响应变量，但是有没有办法对具有多个响应变量（分类或非分类）的东西运行 glmm？我可以尝试将这些变量转换为数字因子值。]]></description>
      <guid>https://stats.stackexchange.com/questions/652104/mixed-effects-models-with-only-categorical-data</guid>
      <pubDate>Wed, 31 Jul 2024 18:09:53 GMT</pubDate>
    </item>
    <item>
      <title>合并两组正态分布样本后的分布</title>
      <link>https://stats.stackexchange.com/questions/652103/distribution-after-combining-two-sets-of-normal-distribution-samples</link>
      <description><![CDATA[假设我从分布 $N(\mu_1,\sigma_1^2)$ 中抽取 $N1$ 个样本，从分布 $N(\mu_2,\sigma_2^2)$ 中抽取 $N2$ 个样本。这两个分布是独立的。
可以将$N1+N2$个观测值的组合样本视为来自单个正态分布$N(\mu,\sigma^2)$的样本吗？
其中$\mu = \frac{N1}{N1+N2}\mu_1+\frac{N2}{N1+N2}\mu_2$，$\sigma^2=(\frac{N1}{N1+N2})^2\sigma_1^2+(\frac{N2}{N1+N2})^2\sigma_2^2$。
如果是，那就太好了；如果不是，其分布情况如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/652103/distribution-after-combining-two-sets-of-normal-distribution-samples</guid>
      <pubDate>Wed, 31 Jul 2024 17:59:41 GMT</pubDate>
    </item>
    <item>
      <title>使用混合模型与其他方法的多元分析</title>
      <link>https://stats.stackexchange.com/questions/652098/multivariate-analyses-using-mixed-models-vs-other-approaches</link>
      <description><![CDATA[可以使用混合效应模型执行多变量分析（即多个因变量）。简而言之，表示因变量的列堆叠在一起形成一个名为“值”的列，并创建另一个名为“名称”的变量，该变量指示每个原始因变量。然后可以使用“单变量”混合模型分析现在长格式的数据，其中“值”是因变量，“名称”与感兴趣的协变量交互，以及随机效应（例如受试者 ID）以解释来自同一受试者的多个观察结果。此处显示 就是一个例子。
我想知道是否可以对上述长格式数据使用其他方法来解释非独立性？具体来说，我在考虑 1) 工作独立模型，然后是聚类标准误差；(2) 广义最小二乘法；及 (3) 广义估计方程。]]></description>
      <guid>https://stats.stackexchange.com/questions/652098/multivariate-analyses-using-mixed-models-vs-other-approaches</guid>
      <pubDate>Wed, 31 Jul 2024 17:21:20 GMT</pubDate>
    </item>
    <item>
      <title>使用比例响应数据和分类预测因子处理 GAM 中的自相关</title>
      <link>https://stats.stackexchange.com/questions/652097/dealing-with-autocorrelation-in-gams-with-proportional-response-data-and-categor</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652097/dealing-with-autocorrelation-in-gams-with-proportional-response-data-and-categor</guid>
      <pubDate>Wed, 31 Jul 2024 16:22:00 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost：使用嵌套交叉验证的贝叶斯优化（tidymodels）</title>
      <link>https://stats.stackexchange.com/questions/652095/xgboost-bayesian-optimisation-using-nested-cross-validation-tidymodels</link>
      <description><![CDATA[有人能解释一下如何使用 tidymodels 包的嵌套交叉验证进行贝叶斯优化吗？我不确定如何编写贝叶斯优化函数。我写了部分代码。这是官网的一个示例：https://www.tidymodels.org/learn/work/nested-resampling/index.html#nested-resampling
library(mlbench)
library(dplyr)
library(magrittr)
library(tidyverse)
library(tidymodels)

sim_data &lt;- function(n) {
tmp &lt;- mlbench.friedman1(n, sd = 1)
tmp &lt;- cbind(tmp$x, tmp$y)
tmp &lt;- as.data.frame(tmp)
names(tmp)[ncol(tmp)] &lt;- &quot;y&quot;
tmplibrary(mlbench)
library(dplyr)
library(magrittr)
library(tidyverse)
library(tidymodels)

sim_data &lt;- function(n) {
tmp &lt;- mlbench.friedman1(n, sd = 1)
tmp &lt;- cbind(tmp$x, tmp$y)
tmp &lt;- as.data.frame(tmp)
names(tmp)[ncol(tmp)] &lt;- &quot;y&quot;
tmp
}

set.seed(9815)
train_dat &lt;- sim_data(100)
large_dat &lt;- sim_data(10^5)

## NESTED CV
set.seed(14)
nested_cv &lt;- nested_cv(train_dat, 
outside = vfold_cv(v = 10, repeats = 100),
inside = bootstraps(times = 25)) 

## 内部循环
xgb_inner &lt;-
boost_tree(
trees = tune(),
learn_rate = tune(),
tree_depth = tune(), 
min_n = tune(),
loss_reduction = tune(),
sample_size = tune(),
mtry = tune(),
) %&gt;%
set_mode(&quot;classification&quot;) %&gt;%
set_engine(&quot;xgboost&quot;)

## recipe
model_recipe &lt;- recipe(y ~ ., data = train_dat)

xgb_FUN &lt;- function(params, analysis_set) {
trees &lt;- params$trees[[1]]
learn_rate &lt;- params$learn_rate[[1]]
tree_depth &lt;- params$tree_depth[[1]]
min_n &lt;- params$min_n[[1]]
loss_reduction &lt;- params$loss_reduction[[1]]
sample_size &lt;- params$sample_size[[1]]
mtry &lt;- params$mtry[[1]]
boost_tree(mode = &quot;classification&quot;, trees = trees, learn_rate = learn_rate, tree_depth = tree_depth,
min_n = min_n, loss_reduction = loss_reduction, sample_size = sample_size, mtry = mtry) %&gt;%
set_engine(&quot;xgboost&quot;) %&gt;%
fit(y ~ ., data = analysis_set)
}

xgb_grid &lt;- grid_latin_hypercube(
trees(range = c(500,1500)),
learn_rate(),
tree_depth(),
min_n(),loss_reduction(),
sample_size=sample_prop(),
finalize(mtry(), nested_cv.controls),
size = 100)

params_list &lt;- list(xgb = xgb_grid)
mod_FUN_list &lt;- list(xgb = xgb_FUN)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652095/xgboost-bayesian-optimisation-using-nested-cross-validation-tidymodels</guid>
      <pubDate>Wed, 31 Jul 2024 15:39:58 GMT</pubDate>
    </item>
    <item>
      <title>如何量化百分比排序数据集的重要性？</title>
      <link>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</link>
      <description><![CDATA[我正在考虑针对给定数据集的七种不同的预测模型，这些模型经过多次预测迭代，并量化每个预测模型总体上最准确的次数。
我需要某种方法来量化结果的重要性。例如，如果给定的预测模型在 7 个预测中排名第一的概率为 23%（7 个预测中平均分布为 14.2%），那么这有多重要？
我希望能够为这些结果的重要性建立某种基线。我怀疑这可能涉及某种正态分布，但我不知道如何计算。由于我总是使用百分比，并且总是考虑 7 个预测，因此一个参考表将是理想的选择 — 如果我能够指出 23% 是高度重要的，但 18% 是有点重要的或类似的情况。
就其本身而言，这些百分比缺乏足够的背景信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</guid>
      <pubDate>Wed, 31 Jul 2024 15:26:20 GMT</pubDate>
    </item>
    <item>
      <title>计算分类变量的 RERI？</title>
      <link>https://stats.stackexchange.com/questions/652093/calculate-reri-for-categorical-variables</link>
      <description><![CDATA[我想检查两个变量之间的相互作用，一个是连续变量（均值中心化），另一个是分类变量（具有三个级别）。我将使用负二项回归。我搜索了很多论文，但我不确定 RERI 是否适用于此。通常，如果变量是二进制的，则很容易，只需 b11 - b10 - b01 + 1。但由于我在一个变量中有三个级别，如何计算 RERI？]]></description>
      <guid>https://stats.stackexchange.com/questions/652093/calculate-reri-for-categorical-variables</guid>
      <pubDate>Wed, 31 Jul 2024 15:16:55 GMT</pubDate>
    </item>
    <item>
      <title>对于两个相关性较弱的变量，且简单回归没有显著的预测率，下一步的研究步骤是什么？</title>
      <link>https://stats.stackexchange.com/questions/652092/between-two-variables-with-weak-correlations-and-no-significant-prediction-rate</link>
      <description><![CDATA[我正在努力利用收入等级来确定犯罪率和经济不平等之间的关联。我发现一些犯罪率与不同收入等级家庭的犯罪率相关性很弱，或者几乎中等。我还发现，使用简单线性回归根据不同收入等级家庭的犯罪率（相关值最大）来预测犯罪率并不能显著预测犯罪率。例如，收入在 0-10,000 美元范围内的家庭百分比与入室盗窃的相关值约为 0.32，但该家庭百分比对入室盗窃率的预测值并不显著。下一步的统计研究步骤是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652092/between-two-variables-with-weak-correlations-and-no-significant-prediction-rate</guid>
      <pubDate>Wed, 31 Jul 2024 15:16:14 GMT</pubDate>
    </item>
    <item>
      <title>如何更好地分析二进制和对数尺度数据之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/652090/how-to-better-analyze-the-correlation-between-binary-and-log-scaled-data</link>
      <description><![CDATA[假设我有两个数据集，如图所示：

data1 是一个由零和一组成的数组，而 data2 是一个实数数组（以对数刻度显示，范围从 10^-12 到 10^5）。
这些数据集之间似乎可能存在某种负相关性。使用 Pearson 的 R，我获得了 -0.0583 的相关系数，p 值为 6.595e-172，表明存在弱负相关性。
我正在寻找一种更可靠的统计方法来描述这些数据集之间的关系，因为 Pearson 相关性可能无法完全捕捉我们视觉上观察到的内容。
我考虑过 Spearman 等级相关性 和 点双序列相关性，但不确定最佳方法或如何进行。您能否就最合适的统计测试或分析提供指导，以更好地理解这种关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/652090/how-to-better-analyze-the-correlation-between-binary-and-log-scaled-data</guid>
      <pubDate>Wed, 31 Jul 2024 14:41:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不能直接进行 Dunnet 测试？</title>
      <link>https://stats.stackexchange.com/questions/652087/why-cant-i-perform-a-dunnets-test-directly</link>
      <description><![CDATA[我读到 Dunnett 检验基本上是一种事后检验，应该在方差分析（统计显著性）之后进行。
在这里，我表明方差分析在我的环境中无效，因为均值的显著差异发生在非对照组之间。
运行此简单代码：
rm(list=ls())
# 加载包
if (!require(DescTools)) install.packages(&#39;DescTools&#39;)
if (!require(ggplot2)) install.packages(&#39;ggplot2&#39;)

# 创建示例数据集
set.seed(1)
data &lt;- data.frame(
treatment = rep(c(&quot;Control&quot;, &quot;Treatment1&quot;, &quot;Treatment2&quot;, &quot;Treatment3&quot;), each = 20),
response = c(rnorm(20, 平均值 = 5, sd = 1),
rnorm(20, 平均值 = 5.1, sd = 1),
rnorm(20, 平均值 = 5.4, sd = 1),
rnorm(20, 平均值 = 4.4, sd = 1))
)

boxplot(数据$response ~data$treatment)


# 执行 ANOVA
anova_model &lt;- aov(响应 ~ 治疗，数据 = 数据)
summary(anova_model)

给出：
 Df 总和 Sq 均值 Sq F 值 Pr(&gt;F) 
治疗 3 11.15 3.715 4.433 0.00632 **
残差 76 63.69 0.838 
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

这告诉我，我的数据中的组均值之间存在统计上的显著差异（查看图表，我会说 Treatment2 和 Treatment3 的均值之间）。
# 执行 Dunnett 检验
DunnettTest(x=data$response, g=data$treatment)

给出：
 Dunnett 检验用于将几种治疗方法与对照组进行比较：
95% 家族置信水平

$Control
diff lwr.ci upr.ci pval 
Treatment1-Control -0.09699539 -0.7908913 0.596900528 0.9750 
治疗2-对照 0.34827290 -0.3456230 1.042168819 0.4880 
治疗3-对照 -0.68878697 -1.3826829 0.005108952 0.0522 . 

---
Signif. 代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

这告诉我，治疗组和对照组的平均值均值均无差异。因此，方差分析在这里毫无帮助，因此我想知道为什么应该先进行方差分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/652087/why-cant-i-perform-a-dunnets-test-directly</guid>
      <pubDate>Wed, 31 Jul 2024 14:02:50 GMT</pubDate>
    </item>
    <item>
      <title>SAS 在这里做什么以及什么时候可以或者有用？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652085/what-is-sas-doing-here-and-when-is-this-ok-or-useful</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652085/what-is-sas-doing-here-and-when-is-this-ok-or-useful</guid>
      <pubDate>Wed, 31 Jul 2024 13:56:02 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归：具有多个级别的分类预测器 - 适当的组大小</title>
      <link>https://stats.stackexchange.com/questions/652082/logistic-regression-categorical-predictor-with-many-levels-appropriate-group</link>
      <description><![CDATA[我正在估计一个包含 11 个组的分类预测因子的逻辑回归模型。我想知道我是否可以/应该排除其中一些组（D-K，也许还有 C；见下文），因为每个事件的 n 较小。组 D-K 反正没那么有趣，我最感兴趣的是 A、B 和 C 的比较。这是我的数据分布（A-K：组；Y/N：事件）：
 Y N
A 96 246
B 13 103
C 2 69
D 1 6
E 2 4
F 1 3
G 1 2
H 1 1
I 0 1
J 0 1
K 0 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/652082/logistic-regression-categorical-predictor-with-many-levels-appropriate-group</guid>
      <pubDate>Wed, 31 Jul 2024 13:19:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 LME4 建模干预研究，参与者仅嵌套在一个组中的子组中</title>
      <link>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</link>
      <description><![CDATA[我们使用以下变量进行了行为改变现场实验：

两个时间点（T0，T1）
两组（干预组与对照组）
个人 ID（第 1 组中 n = 62，第 2 组中 n = 53）
研讨会 ID（8 个研讨会）

我们正在使用此模型分析 lme4 中的数据：
lmer(DV_T1 ~ 1 + group + DV_T0 + (1|workshop_id), data=df)

但是，只有第 1 组的参与者嵌套在子组中（而不是对照组参与者），因此为了模拟研讨会日的随机效应，我们为所有对照组参与者创建了一个假子组。这种随机效应结构（让所有对照组参与者参加同一个“研讨会日”）可能会反映出主组效应（干预组与对照组），从而掩盖干预组的部分主效应。
您认为这是一个问题吗？是否有办法以不同的方式对随机子组效应进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</guid>
      <pubDate>Wed, 31 Jul 2024 11:22:22 GMT</pubDate>
    </item>
    <item>
      <title>时间序列 AR(1) 预测与具有外生变量的 AR(1) 预测与随机森林预测，为什么性能如此不同？</title>
      <link>https://stats.stackexchange.com/questions/652072/prediction-of-a-time-series-ar1-vs-ar1-with-exogenous-variables-vs-random-fo</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652072/prediction-of-a-time-series-ar1-vs-ar1-with-exogenous-variables-vs-random-fo</guid>
      <pubDate>Wed, 31 Jul 2024 09:27:44 GMT</pubDate>
    </item>
    <item>
      <title>隔离森林需要规范化实时数据吗？</title>
      <link>https://stats.stackexchange.com/questions/652034/normalizing-live-data-necessary-for-isolation-forests</link>
      <description><![CDATA[我正在研究一个使用孤立森林检测实时数据异常的模型。我不确定是否需要对数据进行规范化，或者如何实时进行规范化。目标是识别特定的异常，特别是当值明显高于平均值并长期超过管道直径时。数据表示管道中的水深，每个管道的直径从 10 以下到 110 以上不等。在过去的例子中，700 多根管道中几乎没有异常，大多发生在直径较小的管道中，峰值在 113 左右。我担心的是，如果不进行规范化，这些峰值可能会被视为直径为 114 的管道的正常值，或者在这些情况下正常值将被视为异常值。我不确定是否需要进行规范化，或者孤立森林是否可以自动调整这些变化。
更新：我已经在更大的管道上进行了测试，我的担心是真的。在对具有感知异常的较小数据集训练孤立森林模型时，几乎较大管道的每个值都被标记为异常。我尝试了 MinMax 缩放和标准缩放，但都没有给我理想的结果，即使在非实时数据上也是如此。我该怎么做才能使这些数据标准化？]]></description>
      <guid>https://stats.stackexchange.com/questions/652034/normalizing-live-data-necessary-for-isolation-forests</guid>
      <pubDate>Tue, 30 Jul 2024 21:41:53 GMT</pubDate>
    </item>
    </channel>
</rss>