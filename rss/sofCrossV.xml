<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 22 Nov 2024 01:19:40 GMT</lastBuildDate>
    <item>
      <title>对偶自然对数模型中的过度拟合</title>
      <link>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</link>
      <description><![CDATA[我有这个函数
$$y = a \ln(p(t + 32)) - b \ln(q(t+30))$$
其中：

$t,y$ 是测量值
$a, b, p$ 和 $q$ 是拟合值
$30$ 和 $32$ 是偏移项

我使用此函数拟合质谱数据，其中 $y$ 是强度，$t$ 是气体平衡后的时间。目标是尽可能准确地测量 $t=0$ 时的 $y$。
使用标准曲线拟合程序，特别是 scipy.optimize.curve_fit，在绝大多数情况下会产生理想的结果。示例：
函数：
 def natural_log_func(self, t, a, b, p, q):
return a * np.log(p*(t + self.pos_lneq_time)) - b * np.log(q*(t + self.neg_lneq_time))

def fit(self):
return curve_fit(self.natural_log_func, self.t, self.y, maxfev=100000)


然而，在少数情况下，我看到了过度拟合：

其中数据是：
7.083,3.63E-12
14.291,3.49E-12
21.494,3.48E-12
28.709,3.59E-12
35.915,3.79E-12
43.02,3.60E-12
50.226,3.80E-12
57.431,3.84E-12
64.639,3.76E-12
71.846,3.79E-12
79.05 6,3.84E-12
86.262,3.71E-12
93.467,4.05E-12
100.578,3.93E-12
107.783,4.12E-12
114.992,4.01E-12
122.2,4.12E-12
129.403,4.30E-12
136.606,4.12E-12
143.812,4.28E-12

另一个两个例子：

其中数据为：
$t$ = 7.208,14.411,21.624,28.833,36.038,43.142,50.347,57.553,64.759,71.964,79.173,86.378,93.583,100.785,107.892,115.095,122.303,129.51,136.711,143.92
4 amu = 5.48E-14,3.60E-14,2.75E-14,5.22E-14,5.87E-14,5.14E-14,5.70E-14,5.17E-14,5.41E-14,5.53E-14,4.58E-14,7.52E-14,4.85E-14,7.06E-14,9.48E-14,6.42E-14,8.56E-14,6.71E-14,8.48E-14,9.84E-14
40 amu = 3.66E-12,3.73E-12,3.94E-12,3.94E-12,4.02E-12,3.92E-12,3.90E-12,4.09E-12,4.18E-12,4.17E-12,4.24E-12,4.13E-12,4.35E-12,4.32E-12,4.51E-12,4.41E-12,4.74E-12,4.62E-12,4.68E-12,4.64E-12
我可以做些什么来防止这些“骤降”在低$t$值时形成？]]></description>
      <guid>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</guid>
      <pubDate>Fri, 22 Nov 2024 00:53:34 GMT</pubDate>
    </item>
    <item>
      <title>rugarch 包中条件方差的初始值如何计算</title>
      <link>https://stats.stackexchange.com/questions/657651/how-are-initial-values-of-conditional-variance-calculated-in-rugarch-package</link>
      <description><![CDATA[我正在尝试使用 rugarch 库验证我的 0 均值 GARCH(1,1) 模型的计算，起初我认为条件方差的初始值与非条件方差（python 中的 arch 包使用）是相同的值，但当我重新检查条件方差的第一个初始值时，它与非条件方差不同。
我尝试使用计算器手动计算它，它给了我与 uncvariance(garch_fit) 相同的输出，这不是来自模型的条件方差的初始值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657651/how-are-initial-values-of-conditional-variance-calculated-in-rugarch-package</guid>
      <pubDate>Fri, 22 Nov 2024 00:48:50 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型和平稳性</title>
      <link>https://stats.stackexchange.com/questions/657649/time-series-model-and-stationarity</link>
      <description><![CDATA[考虑一个非常简单的模型，该模型预测$y_t$作为$x_t$上的函数，使用真实数据构建，如下所示：
$y_t = a + b.x_t$
对于这样的系统，我们需要$y_t$和$x_t$都是I(0)，但这里我谈论的是具有真实噪声数据的实际应用。在我的例子中，使用ADF、PP和KPSS测试，$y_t$绝对是平稳的。问题是$x_t$“看起来”平稳且“直观地”是平稳的，但根据用于构建我的模型的时间范围，它在 3 次平稳性测试中没有通过 2 次。
如果我扩大范围来评估平稳性，那么 $x_t$ 会通过 2 或 3 次测试，这意味着从长期来看 $x_t$ 是平稳的。请注意，如果我将范围从 1980 年推至 2024 年，它将再次变为非平稳。
问题：

扩大范围以评估平稳性的论点是否有效，以支持使用 $x_t$？

有关于这个主题的文献吗？

如果可以在与用于构建有效模型的范围不同的范围内评估平稳性，那么我如何将其与回归系数不变的事实相协调，同时论证 $x_t$ 在较长时期内是平稳的，甚至 $x_t$ 是“直观地”平稳的。因此，如何通过论证模型在数学上合理？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657649/time-series-model-and-stationarity</guid>
      <pubDate>Fri, 22 Nov 2024 00:14:27 GMT</pubDate>
    </item>
    <item>
      <title>我应该为梦幻英超联赛模型预测个人数据还是整体得分？</title>
      <link>https://stats.stackexchange.com/questions/657648/should-i-predict-individual-stats-or-points-as-a-whole-for-a-fantasy-premier-lea</link>
      <description><![CDATA[我正在做一项大学作业，目的是使用历史比赛数据预测梦幻英超联赛球员的得分。在 FPL 中，球员根据各种比赛统计数据（例如，上场时间、进球、助攻、零封）获得积分。得分公式很简单，但因位置而异（例如，后卫零封对手的得分高于中场球员）。
我的方法是使用 XGBoost 为各个统计数据（例如，助攻、扑救）训练单独的模型，然后结合这些预测，使用已知方程计算得分。例如：
预测预期助攻的特征：
player_id、gameweek、value、home_crowd_effect、opponent_defense_strength、own_attack_strength、rolling_xa_5、season、position
预测扑救的特征：
player_id、gameweek、value、home_crowd_effect、opponent_attack_strength、own_defense_strength、rolling_saves_5、season
这与我在网上看到的大多数例子不同，人们只训练一个模型来直接预测得分。例如，在这篇文章中，他们训练了一个积分模型，并得到了 ~0.74 的 R 平方。另一方面，我的方法似乎无法超过 ~0.33，这感觉差距很大。
现在我想知道：

使用多个模型来处理单个统计数据而不是使用单个模型来处理积分，是否有理论或实践优势？
是否有任何资源或研究论文详细讨论这种建模权衡？我还没有找到任何关于 Fantasy Premier League 的资源或研究论文，但也许同样的情况可能发生在不同的问题中。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657648/should-i-predict-individual-stats-or-points-as-a-whole-for-a-fantasy-premier-lea</guid>
      <pubDate>Thu, 21 Nov 2024 23:49:32 GMT</pubDate>
    </item>
    <item>
      <title>对物理学家来说有效的逻辑分析？</title>
      <link>https://stats.stackexchange.com/questions/657647/valid-logistic-analysis-for-physicists</link>
      <description><![CDATA[我是一名物理学家，正在撰写一篇论文，论文内容涉及蒙特卡罗引擎计算辐射场中击中目标的辐射量的结果。有趣的是，虽然结果通常是准确的，但在某些情况下，结果会大相径庭。据我们所知，没有确切的参数集会导致错误，但有些参数集会使错误更有可能发生 - 例如，将计算网格大小设置为更粗会导致这些错误更有可能发生，但这种情况并不总是发生，即使计算网格大小很细，也可能发生。
我现在有大约 20,000 个来自各种计算的数据点。对于每次计算，我都记录了大约 15 个不同输入参数的值。我稍微知道哪些与输出变量相关，即此计算与已知对几何正确的基准情况之间的计算辐射剂量差异，但许多我不确定它们会如何影响输出变量。我知道我的许多变量是相关的。我敢打赌我的一些变量是多重共线性的。
该项目的最终目标是为在放射治疗领域使用这些计算提供粗略的经验法则 - 也就是说，让计划进行放射治疗的人可以遵循一些规则，例如“当目标这么大，或者离另一个东西这么近时，那么你必须像这样设置参数 Y 以降低计算错误的概率”。为了获得这些，我试图从输入参数创建一个逻辑回归模型，这样我就可以说“当使用参数集 Y、Z、W 时，计算错误的几率小于 X”。
我不知道最好的解决方法。目前，我正尝试通过迭代计算 VIF 来消除多重共线性，然后删除具有最高 VIF 的解释变量，重复此过程，然后，一旦所有变量的 VIF 都低于 10，就对所有剩余的变量组合运行 BIC 以找到最简约的集合，然后通过使用该集合创建逻辑模型（当然是缩放和居中数据）来创建我的经验法则，然后根据我的逻辑模型检查参数空间的哪些区域具有最低概率。
但是，这个想法只是我从各种 CrossValidated 帖子和阅读教科书的片段中拼凑起来的。真的，我不知道最好的方法是什么。
对于不太了解统计学的物理学家来说，什么方法最能防错？获得我想要的最终结果（经验法则）的正确方法是什么？
我确实读过此处的帖子，该帖子与此相关，但并未明确给出前进的方向。我知道“进行统计分析的最佳方法”这一想法将极具争议，但我主要在寻找对我当前方法的批评、对统计学以外专业的人提出的防错方法的建议以及进一步的阅读。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657647/valid-logistic-analysis-for-physicists</guid>
      <pubDate>Thu, 21 Nov 2024 23:35:22 GMT</pubDate>
    </item>
    <item>
      <title>作业数据挖掘/需要帮助[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657646/assignment-data-mining-need-help</link>
      <description><![CDATA[希望你们都很好。
我迫切需要你们中一个对数据挖掘有所了解的人的帮助，足以帮助我回答作业上的问题……几天后我必须向我的数据挖掘老师提交一份作业，但我真的很难决定我做得对不对。我担心我的所有结果都是错的，我会得到一个很差的分数……
我附上了作业说明和包含完成作业所需的所有数据的文件。我无法在此处附上我的 Jupyter Notebook，因为格式不起作用，但如果您要求我这样做，我很乐意通过电子邮件或其他方式将其发送给您。
我真的需要帮助，我本学期的成功真的取决于我这份作业的分数。有人能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657646/assignment-data-mining-need-help</guid>
      <pubDate>Thu, 21 Nov 2024 23:18:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 Hausman-McFadden 检验结果解决不相关替代独立性 (IIA) 偏差的有效性</title>
      <link>https://stats.stackexchange.com/questions/657645/validity-of-using-hausman-mcfadden-test-results-for-addressing-departures-from-t</link>
      <description><![CDATA[上下文正在运行多项 Logit 模型，主要目的是衡量案例特定变量 A 对多项结果 B 的影响。运行 Hausman-McFadden 检验显示完整模型与 B 的替代方案减少（违反 IIA 的程度）的每个模型有何不同。理想情况下，系数不会改变。我的问题是，使用这些测试和比较来显示违反 IIA 的程度是否足够，同时论证在这些变化中持续存在的影响仍然有效？例如，假设在 5 个系数中，4 个没有变化或变化不大，但 1 个有变化，或者对于所有系数，方向在简化模型中没有变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/657645/validity-of-using-hausman-mcfadden-test-results-for-addressing-departures-from-t</guid>
      <pubDate>Thu, 21 Nov 2024 23:01:57 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的代码仅适用于较小的值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657643/code-in-python-works-only-with-small-values</link>
      <description><![CDATA[我有一个 python 代码，它对我的​​主变量（表示为 m）的小整数值很有效，但对于较大的整数值（m&gt;6），它从不给我结果，猜想问题出在库上，有什么建议吗？
我的代码：
...
import sympy as sp

# 使用 m 指定类别数
m = 6

# 使用 i 变量指定预期副本数的间隔 o) 最小值和最大值
i_min = 1
i_max = 10

# 计算预期的文章数量以获得每个类别的至少一个副本。
E_m = m * sum(1 / i for i in range(1, m + 1))

# 定义辅助变量 t 进行泰勒展开
t = sp.symbols(&#39;t&#39;)

# 生成公式的定义
def calculate_probability(m, i_min, i_max):
# 生成公式成分
numerator = sp.factorial(m)
denominator = 1
# 分母为 (j - t) 的乘积，j=2 到 m
for j in range(2, m + 1):
denominator *= (j - t)

# 生成公式的比率
generative = t - 1 + numerator / denominator

# 生成公式的泰勒展开为幂级数
expansion = sp.series(generative, t, 0, m) # 使用 t=0，展开为 t^m

# 显示 m 和区间的值，使用 i_min 到i_max
print(f&quot;对于具有 {m} 个类别和副本数 (i) 从 = {i_min} 到 {i_max} 的集合：&quot;)

# 显示扩展
#print(f&quot;生成系列的泰勒扩展：&quot;)
#print(expansion)

# 显示结果
print(f&quot;预期论文数量：{E_m:.6f}&quot;)

# 在 i 的间隔内进行迭代（从 i_min 到 i_max）
for i in range(i_min, i_max + 1):
# 获取 t^i 的系数
coef_ti = extension.coeff(t, i)

# 显示四舍五入到小数点后 6 位的预期数字
probability_num = coef_ti.evalf(6)

# 具有恰好 i 个副本的元素的预期数量。
print(f&quot;具有 {i} 个副本的元素的预期数量：{probability_num}&quot;)

# 调用函数计算参考间隔的概率
calculate_probability(m, i_min, i_max)

...]]></description>
      <guid>https://stats.stackexchange.com/questions/657643/code-in-python-works-only-with-small-values</guid>
      <pubDate>Thu, 21 Nov 2024 22:58:06 GMT</pubDate>
    </item>
    <item>
      <title>如何计算非正态分布的数据的条件功效？</title>
      <link>https://stats.stackexchange.com/questions/657641/how-to-calculate-conditional-power-for-data-that-is-not-normally-distributed</link>
      <description><![CDATA[研究信息：
两个平行组，活性组和安慰剂组。计划样本量为 168 = 84*2。由于我们的主要终点不呈正态分布（从其他先前的类似研究中得知），因此指定的主要分析是 Wilcoxon 秩和检验。计划进行中期分析 (IA)，在 ~50% 的受试者完成 DB 期间进行。计划计算条件功效。统计分析计划中指定的公式如下。
正常CDF [ Zn/sqrt(t(1-t)) - Zα/2/sqrt(1-t)]。
CDF = 累积分布函数。
Zn 是 Wilcoxon 秩和检验的 z 统计量，用于比较活性药物与安慰剂。
t 是信息因子，即中期分析时研究中的实际受试者数量除以研究中计划的受试者数量（168 = 84*2），即 n/168。
现在决定提前进行 IA。也就是说，总共会有 78 或 80 名受试者。每只手臂将是 39 或 40。
我已经在网上搜索、阅读论文并使用了 ChatGPT，但我仍然有问题想在这里寻求专家的帮助。
1. 如果按照计划将 Wilcoxon 秩和检验中的“z”作为 Zn 代入上述公式来计算条件功效，那么对于我们在 IA 的样本量，这是否是一种有效的方法？

这个公式是否适合我们的数据，尤其是在这样的样本量下？如果不适合，还有其他公式吗？

我目前的想法是，由于我的样本量不够大，我应该进行模拟，至少作为计划的“插入 z”方法的备份。看看会有多少差异。但我不知道该怎么做。有人能帮我吗？


提前谢谢大家。
珍妮特]]></description>
      <guid>https://stats.stackexchange.com/questions/657641/how-to-calculate-conditional-power-for-data-that-is-not-normally-distributed</guid>
      <pubDate>Thu, 21 Nov 2024 22:19:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有历史比例数据的情况下预测子地点的销售额？</title>
      <link>https://stats.stackexchange.com/questions/657640/how-to-forecast-sales-for-sub-locations-without-historical-proportion-data</link>
      <description><![CDATA[我有一个时间序列数据集，记录了商店中某个产品在一段时间内的总销售额。该产品在商店内的两个不同位置有售：一个位于收银台附近，另一个位于商店中心。
目前，我只有整个商店的产品总销售数据。我需要分别预测每个摊位的销售额。这似乎是一个使用自上而下方法的分层预测问题，其中总销售额被分解到子位置。
但是，我没有每个摊位的历史数据，所以我不知道每个位置的销售额比例。
我可以使用哪些方法或途径来估计这些比例并为每个摊位做出准确的预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/657640/how-to-forecast-sales-for-sub-locations-without-historical-proportion-data</guid>
      <pubDate>Thu, 21 Nov 2024 21:01:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的某个 GAM 响应与数据不太吻合？</title>
      <link>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</guid>
      <pubDate>Thu, 21 Nov 2024 20:10:18 GMT</pubDate>
    </item>
    <item>
      <title>使用线性混合模型时，输出变量中缺失多少数据是可以接受的？</title>
      <link>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</link>
      <description><![CDATA[我有重复测量数据，但由于缺失，我计划使用线性混合模型。我唯一的预测因子是时间，结果变量是定量测量的幸福感得分。目标是确定幸福感是否随着时间的推移而发生整体变化。
幸福感得分是通过四个时间点的季度调查收集的，参与人数如下：

时间 1：25 名参与者
时间 2：54 名参与者
时间 3：70 名参与者
时间 4：120 名参与者

由于大量缺失数据，近 80% 的答复不完整。许多参与者只参加了一次，特别是在时间 4，缺乏后续数据。为了解决这个问题，我过滤了数据集以仅包含至少参加过两个时间点的参与者。经过筛选后，参与人数如下：

时间 1：21 名参与者
时间 2：35 名参与者
时间 3：46 名参与者
时间 4：47 名参与者

此调整将缺失数据减少至约 36%。排除仅参加过一次的参与者是否合适？缺失数据多少才合适？
我非常感谢任何反馈或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:52 GMT</pubDate>
    </item>
    <item>
      <title>在 SEM 模型中应用聚类稳健标准误差需要多少个聚类？</title>
      <link>https://stats.stackexchange.com/questions/657623/how-many-clusters-are-needed-for-applying-cluster-robust-standard-errors-in-a-se</link>
      <description><![CDATA[我正在研究一个 SEM 模型，该模型的数据来自 13 所学校（集群）的 1078 名学生。我想应用集群稳健标准误差，但我不确定 13 个集群是否足以让这种方法提供可靠的估计值。集群规模从每所学校 19 名学生到 165 名学生不等。
鉴于集群数量相对较少（13），我是否应该担心集群稳健标准误差的可靠性？]]></description>
      <guid>https://stats.stackexchange.com/questions/657623/how-many-clusters-are-needed-for-applying-cluster-robust-standard-errors-in-a-se</guid>
      <pubDate>Thu, 21 Nov 2024 15:46:12 GMT</pubDate>
    </item>
    <item>
      <title>包含原始数据的混合模型与包含聚合数据的线性模型</title>
      <link>https://stats.stackexchange.com/questions/657615/mixed-model-with-raw-data-vs-linear-model-with-aggregated-data</link>
      <description><![CDATA[我有一个设计实地研究，其中在 4 个区块（Bk A-D）中应用了 4 种处理方法（Tx = CT、RT、RL 和 TS）。在每个实验单元的 4 个位置进行了测量；虽然每个单元至少有 2 次测量，但有些测量失败了。响应变量是 Rv。我接受 alpha = 0.1，可能是 I 类错误。
我通过比较治疗 + 区块与单独治疗来分析 lme4 中的数据（完整数据集“ds1”，n=54）
m1 = lmer(Rv ~ Tx + (1|Bk)) 
m0 = lmer(Rv ~ (1|Bk), 
anova(m1, m0), 

anova() 的似然比检验给出 p=0.3，表明治疗不可能显著。尽管如此，治疗图鼓励我进一步研究，因此我尝试了 Simon Wood (2006) 概述的程序，即按治疗和区块取平均值，并使用线性模型估计治疗效果，然后从残差方差估计随机区块 (bk) 效应的方差。（汇总数据集 n = 16）
ds2 &lt;- ds1[ , .(Rv = mean(Rv)), by =c(&#39;Bk&#39;, &#39;Tx&#39;)] # 按 Tx 和 Bk 聚合 
lm1 = lm(rv ~ tx + bk)

此处，治疗 (tx) 在 p = 0.07 时显著，这与 lme4 提供的答案不同。Wood (2006) 说“假设数据相对于模型是平衡的，这意味着对于模型中的每个因素或交互作用，在其每个级别都收集了相同数量的数据”。这似乎不适用于我的情况，因为每个实验单元的测量次数各不相同。我应该将治疗 (Tx) 视为不显著，还是有任何理由使用聚合数据/线性模型分析？
Tx=c(&#39;TS&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;TS&#39;,&#39;TS&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RL&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;RT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;CT&#39;,&#39;TS&#39;,&#39;TS&#39;)
Bk= c(&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,
&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;D&#39;,&#39;D&#39;,&#39;D&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;)
Rv=c(2.08,2.08,2.52,3.42,2 .8,5.57,2.53,3.69,1.55,1.45,3.98,3.19,2.3,2.09,2.26,2.1,3.21,2.99,2.11,2.09,1.64,1.74,1.66,6.41,1.86,2.71,1.83,0.86,2.37,1.05,1.37,2.08,1.09,1.44,0.6,1.24,3.32,1.34,1.86,4.54,2.7,2.5,4.93,2.85,3.42,2.77,2.71,4.11,5.29,2.16,3.15,4.58,2.89）]]></description>
      <guid>https://stats.stackexchange.com/questions/657615/mixed-model-with-raw-data-vs-linear-model-with-aggregated-data</guid>
      <pubDate>Thu, 21 Nov 2024 14:05:12 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归/如何组合成两个预测向量</title>
      <link>https://stats.stackexchange.com/questions/657638/logistic-regression-how-to-combine-to-2-predictive-vectors</link>
      <description><![CDATA[我有一个包含 2 个结果类别的数据集。其中有 2 个变量本身来自先前的分析，因此是 0-1 之间的数值“预测向量”输出。我已附上数据快照。
structure(list(Var_1 = c(0.297573347, 0.183398828, 0.183398828, 
0.113579286, 0.075940712, 0.134212409, 0.334044957, 0.467858463, 
0.578200128, 0.334044957, 0.113579286, 0.334044957, 0.813665485, 
0.113579286, 0.438854129, 0.435003261, 0.527288318、0.183398828、 
0.183398828、0.713573381、0.388899362、0.438854129、0.183398828、 
0.183398828、0.574378093、0.574378093、0.213658368、0.527288318、 
0.795261213, 0.134212409), Var_2 = c(0.183566667, 0.044266667, 
0.124066667、0.059233333、 0.111233333、0.116066667、0.051766667、 
0.214866667、0.177766667、0.216633333、0.200633333、0.12、0.2006、 
0.029766667、0.153066667、0.196066667、0.020333333、0.119633333、 
0.234066667、0.089566667、0.137433333、0.1807、0.111866667、0.142566667、
0.0767, 0.078933333, 0.101933333, 0.240233333, 0.127666667, 0.152633333
), Outcome = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L)), row.names = c(NA, 30L), class = &quot;data.frame&quot;)

我之前运行过类似的代码在评估与二项式因变量相关的多个输入变量时（如下）：
模型 &lt;- glm(结果 ~ as.numeric(Var_1) + as.numeric(Var_2), 
data=Train, 
family=binomial(link=&quot;logit&quot;))

出于某种原因，我得到的输出表明 p 值为 0.98，AIC 为 4，尽管粗略地查看原始数据，似乎存在明显的显着关系。此外，当我使用线性回归模型时，我得到了一个有意义的输出（p 值 &lt;0.001）。
有人可以建议我的 Logistic 回归代码做错了什么，或者分析与结果类相关的 2 个数值向量的另一种方法并在分析中加​​入权重？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657638/logistic-regression-how-to-combine-to-2-predictive-vectors</guid>
      <pubDate>Thu, 21 Nov 2024 12:02:17 GMT</pubDate>
    </item>
    </channel>
</rss>