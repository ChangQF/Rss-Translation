<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 14 Mar 2025 21:16:42 GMT</lastBuildDate>
    <item>
      <title>检查核密度估计的L2标准的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</link>
      <description><![CDATA[让  $ \ hat {f} _n $ ， $ n \ in \ Mathbb {n} $ 是kernel密度估计器和 $ f $ f $  true dement&gt; true dementy。我想检查 $$ \ sqrt {nh}（\ lvert \ hat {f} _n \ rvert_2- \ lvert f \ rvert f \ rvert_2）
收敛到 $ \ mathbb {r} $   $ nh \ rightarrow \ rightarrow \ infty $ 时，收敛到任何普通的随机变量， $ \ mathbb {r} $ ，并且找不到任何结果。。
我们无法使用功能增量方法来证明这一点，因为通过 $ \ sqrt {nh}（\ hat {f} _n-f）$ 收敛到功能空间上的任何内容，它可能是0。因此，我尝试使用中心限制定理。第一个问题是 $ \ lvert \ hat {f} _n \ rvert $ ， $ n \ in \ in \ mathbb {n} $ 是独立的。但是我找不到随机函数独立性的定义。另外，我们没有像中心限制定理中的随机变量总和。因此，我不确定我是否处于正确的方式。非常感谢您的提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</guid>
      <pubDate>Fri, 14 Mar 2025 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>椭圆形的数据或随机变量的示例？</title>
      <link>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</link>
      <description><![CDATA[我正在研究一些神经科学模型，这些模型可以被认为是在椭球上分布数据。在这些模型中（例如， 1 ，， 2 ）有一些随机变量 $ \ sqrt {y^t b y} $ ，其中 $ b $ 是一种对称的正定矩阵。结果变量 $ z = y / \ sqrt {y^t b y} $ &lt; / span&gt;在椭圆形的表面上。一个相关的替代变量 $ z = y/\ sqrt {y^t b y + c} $ 其中 $ c $ 是一个积极的标量，是一个积极的标量。
我想知道在其他领域的椭圆机上是否有类似的数据示例或随机变量。例如，一些深度学习应用程序项目高维特征在球体上（例如 href =“ https://academic.up.com/biostatistics/article/9/1/66/253727” rel =“ nofollow noreferrer”&gt;一些生物信息学应用程序。但是，我还没有找到将向量投射到椭圆上的一个示例。有这样的例子吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</guid>
      <pubDate>Fri, 14 Mar 2025 20:24:01 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移比较4种处理中的事件频率</title>
      <link>https://stats.stackexchange.com/questions/662639/comparing-event-frequencies-in-4-treatments-over-time</link>
      <description><![CDATA[我进行了一个实验，其中4种治疗方法我每周一次在所有处理中计算同一事件的频率，而我有26周的数据。 Y轴是每周经历活动的受试者的百分比。我想比较每个系列。我认为我想要的是创建每个模型并测试以查看模型是否相同...基本上，在频率，循环等方面，治疗方法之间是否存在差异。。
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662639/comparing-event-frequencies-in-4-treatments-over-time</guid>
      <pubDate>Fri, 14 Mar 2025 20:17:26 GMT</pubDate>
    </item>
    <item>
      <title>在有限样本中模拟完整的随机分配到$ K $处理</title>
      <link>https://stats.stackexchange.com/questions/662637/simulating-complete-random-assignment-in-a-finite-sample-to-k-treatments</link>
      <description><![CDATA[我正在尝试创建一个模拟，该模拟随机将有限的样本 $ n $ 进入 $ k $ 处理，并努力地数学上没有这样的任务。我知道如何实施该程序，但是定义了我正在努力的治疗成员的随机变量。
说我们有 $ k = 3 $ 治疗组的总体样本大小为 $ n = 30 $ 。我们希望在每个组中具有平衡的样本量 $ n_k = 10 $ 。
随机变量 $ k_i \ in \ {1,2,3 \} $ 是一个分类变量，代表 $ i $  $  th person。
我们可以建模：
 $$
k_i \ sim多项式（{\ bf {p}} = 1/3，n = 1，k = 3）
$$  
但这不容易 $ n_k $ 仅在期望中常数才能等于 $ n_k $ 。
我将如何注意随机变量 $ k_i $ 给定 $ k_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/662637/simulating-complete-random-assignment-in-a-finite-sample-to-k-treatments</guid>
      <pubDate>Fri, 14 Mar 2025 19:52:47 GMT</pubDate>
    </item>
    <item>
      <title>得分匹配算法</title>
      <link>https://stats.stackexchange.com/questions/662635/score-matching-algorithim</link>
      <description><![CDATA[我一直在阅读有关得分匹配的信息，我有一个非常基本的问题，即一个人（天真地）如何通过梯度下降实现算法。
说，我有某种神经网络，这些神经网络会输出（不符合）概率 $ p_ \ theta（\ Mathbf {x}）$ 对于某些Input  $ \ \ Mathbf {x Mathbf {x} $ 我们试图最大程度地减少损失
 $$ \ MATHBB {E} _ {p _ {\ text {data}}}} \ left [
\ text {tr}（\ nabla _ {\ mathbf {x}}}^2 \ log p_ \ theta（\ mathbf {x}））） + \ frac {1} {2} {2} {2} \ nabla _ {\ Mathbf {x}} \ log p_ \ theta（\ Mathbf {x}）\ | _2^2
\ right]。$$  
其中一个术语是 $ \ nabla _ {\ Mathbf {x}}} \ log p_ \ theta（\ Mathbf {x}）$ 。我可以看到如何通过一个反向传播来估计此梯度的 value （取出输出，应用 $ \ log $  $ 并将一路分化为输入）。但这只是给了我们一个数字。那么，我们应该如何将梯度相对于 $ \ theta $ 并更新参数？看来这似乎需要我们能够将 $ \ nabla _ {\ mathbf {\ mathbf {x}}} \ log p_ \ theta（\ mathbf {x}）$ 
在我看来，对于第一学期，计算Hessian的对角线条目甚至很困难，因为我们需要了解 $ \ nabla _ {\ nabla _ {\ Mathbf {x}}}}} \ log p_ \ p_ \ theta（ class =“ Math-Container”&gt; $ \ Mathbf {X} $ ，但我们只能拿出值。
我问这件事的主要原因是因为我正在阅读 nofollow noreferrer“
可以通过应用反射 $ D $ 来计算跟踪
时代to  $ \ nabla _ {\ MathBf {x}} \ log P_ \ theta（\ Mathbf {x}）$ 其中 $ d $ d $ d $ d $ d $ 是空间的尺寸，我无法做到&lt;/cone dow/de cand of per &lt;/come de cond of per。]]></description>
      <guid>https://stats.stackexchange.com/questions/662635/score-matching-algorithim</guid>
      <pubDate>Fri, 14 Mar 2025 18:59:58 GMT</pubDate>
    </item>
    <item>
      <title>残差图和Breusch-Pagan测试之间的矛盾结果</title>
      <link>https://stats.stackexchange.com/questions/662631/conflicting-results-between-residuals-plot-and-breusch-pagan-test</link>
      <description><![CDATA[我正在使用内置女性数据集（包括15行，2列 - 身高和重量）来说明某些基本的诊断技术，以验证线性模型中的均质性假设。在残差图中有一个dinstint曲线图 $ \ hat {height {height} = a + b \ b \ times strige strige proge $ 型号，即模型1，所以自然而然地，我在模型中添加了一个Quicdratic术语
  data（“女性”）
model1 = lm（公式=女性$ height〜女性$体重，数据=女性）
model2 = lm（公式=女性$ height〜女人$ strige + i（女性$ strage^2），data = women）
 
  在针对拟合和标准化残差的两个残差中，模型1似乎具有明显的不同模式，而模型2在两个图中具有更多随机模式。但是，由学生化的Breusch-Pagan测试对同质性的结果是矛盾的。我最初将其归结为样本量，但这是Breusch-Pagan测试的学生变化，据说这对于小样本案例或偏离正常性的差异更为强大。
有什么想法吗？
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662631/conflicting-results-between-residuals-plot-and-breusch-pagan-test</guid>
      <pubDate>Fri, 14 Mar 2025 18:39:53 GMT</pubDate>
    </item>
    <item>
      <title>GridSearch结果与学习曲线</title>
      <link>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</link>
      <description><![CDATA[我正在使用GridSearchCV来优化XGBoost模型上的一些超级参数。但是，尽管根据域知识，logloss（我正在优化的度量）似乎还不错，但学习曲线显示出过度拟合的经典迹象。为了减少过度拟合，手动调整超出拟合的参数（可能是XGBOOSTING，由于其对过度拟合的敏感性）是正常的吗？还是我不正确地解释学习曲线？
  &lt;img alt =“用于neg log损失的优化”]]></description>
      <guid>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</guid>
      <pubDate>Fri, 14 Mar 2025 18:27:23 GMT</pubDate>
    </item>
    <item>
      <title>当我将Sigma术语模拟GLMM时，正在发生什么，在BRMS中具有高斯分布</title>
      <link>https://stats.stackexchange.com/questions/662626/what-is-happening-when-i-model-the-sigma-term-in-a-glmm-with-a-gaussian-distribu</link>
      <description><![CDATA[如果我有兴趣了解治疗与协变量之间的相互作用对我的响应方差的影响，以及它们如何影响我的响应平均值，我可以写这样的glmm吗？
  brm（bf（响应〜处理 *距离 +处理 *方向 +（1 |个体），sigma〜处理 *距离 +处理 *方向，family = gaussian） 
有人可以解释一下是否可以以这种方式可靠地使用Sigma来了解我的协变量对响应的影响？这种Sigma响应如何在模型中起作用？
如果我有不平衡的治疗组（即治疗1的观察值比治疗0比0），或者较小的组始终显示出更大的方差？，是否可以信任Sigma输出？
如果有人知道任何资源用于了解如何使用此Sigma术语，这将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662626/what-is-happening-when-i-model-the-sigma-term-in-a-glmm-with-a-gaussian-distribu</guid>
      <pubDate>Fri, 14 Mar 2025 17:31:43 GMT</pubDate>
    </item>
    <item>
      <title>仅使用线性SVM进行特征分类</title>
      <link>https://stats.stackexchange.com/questions/662625/using-linear-svm-only-for-feature-classification</link>
      <description><![CDATA[我确实使用线性SVM功能具有Selintion，然后我使用带有RBF内核的线性SVM的选定功能训练模型，即使我绘制DECSION边界的绘制，它也具有Agood的精度，结果很好，我的问题是正确的吗？正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662625/using-linear-svm-only-for-feature-classification</guid>
      <pubDate>Fri, 14 Mar 2025 17:12:07 GMT</pubDate>
    </item>
    <item>
      <title>如何在线性模型中以不同的重测间隔收集的数据？</title>
      <link>https://stats.stackexchange.com/questions/662624/how-to-account-for-data-collected-at-different-remeasurement-intervals-in-a-line</link>
      <description><![CDATA[我需要在不同的重新测量间隔收集的数据集上运行线性模型。
示例：
 2014-2017-2020-2021-2021-2023 
在此模型中，我应该尝试考虑时间（年） +另一个因素（因子1）效果及其相互作用。
示例：
 mod.1＆lt;  -  lmer（参数〜因子1*年 +（1 | id_rep），data = db）
但是，我的数据尚未定期收集。
我如何在模型中说明这一点？
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662624/how-to-account-for-data-collected-at-different-remeasurement-intervals-in-a-line</guid>
      <pubDate>Fri, 14 Mar 2025 17:10:32 GMT</pubDate>
    </item>
    <item>
      <title>将覆盖率分布与R中的分类变量进行比较 -  KS测试会工作吗？</title>
      <link>https://stats.stackexchange.com/questions/662621/comparing-the-percent-cover-distribution-with-categorical-variables-in-r-will</link>
      <description><![CDATA[我希望确定覆盖冠层/生长形式类别的分布的百分比是否在ForestType1和ForestType2之间有显着不同。  在每种森林类型中，我都有大约10个没有特定排名/顺序的冠层/增长形式类别（C1，C2，C3 ... H1）。我的目标是查看这些类别中的总体结构和覆盖率的分布是否不同（ForestType1和ForestType2）。前任。与ForestType2相比，ForestType1是否具有在类之间的分布更多的分布？然后从那里，也许能够量化/识别这些差异的位置。
我一直在考虑运行两样本KS测试，但不确定这是否是增长形式类别的分类性质，这是否是最佳测试。覆盖率的百分比范围为80％至0.01％。由于冠层重叠，所有10个类总计为100％以上。
我的数据框的结构：
  strataCode＆lt;  -  c（c1; 
ForestType1＆lt;  - ＃10％覆盖值对应于每个Stratacode
ForestType2＆lt;  - ＃10％覆盖值对应于每个Stratacode
 
我尝试使用以下代码运行KS测试：
  ks.test（数据$ ForestType1，数据$ forestType2） 
，但我不确定这是运行的最佳测试（或格式化的正确方法）。如果相关，则ForestType1和2列是来自属于该森林类型的地点的平均值。
欢迎任何建议！我目前正在r。工作]]></description>
      <guid>https://stats.stackexchange.com/questions/662621/comparing-the-percent-cover-distribution-with-categorical-variables-in-r-will</guid>
      <pubDate>Fri, 14 Mar 2025 16:30:15 GMT</pubDate>
    </item>
    <item>
      <title>订购最小二平方估计</title>
      <link>https://stats.stackexchange.com/questions/662620/ordered-least-square-estimation</link>
      <description><![CDATA[让让 $ {x_ {1}，x_ {2}，\ ldots，x_ {n}} $ 是来自Distribution  $ {\ MU} $ 和 $ {\ sigma} $ 是位置和比例参数，然后让是样本的相应订单统计信息，并定义
  $ {z_ {r：n} = \ frac {x_ {r：n}  -  \ mu}  -  \ mu} {\ sigma}} $   
带有 $ { z_ {s：n}）= v_ {r，s}} $ 。
 Now  $ {x_ {r：n} = \ mu + \ sigma z_ {r：n}} $ 我们有
  $ {
 $ {var（x_ {r：n}）= \ sigma^{2} v_ {r，r}} $  and  $ {cov（x__ {x_ {r. n}，x______ {s：n}，x：n} = \ sig sigmma^2 v_ {r，s}} $ 。
现在写作 $ {z = [z_ {1：n}，z_ {2：n}，\ ldots，z_ {n：n}]^{&#39;}} $ 我们有  $ {e（z）= \ alpha} $ ， $ {cov = v} $  and span class =“ nath-container” class =“数学 - 容器”&gt; $ {cov（x）= \ sigma^2 v} $ 。
其中 $ {1} $ 是 $ {（n \ times 1）} $   $ {（n \ times 1）} $   $ {  $ {z__ {r：n}} $ 的方差和协方差矩阵。利用一个事实，即模型参数的最小平方估计 $ {y = x \ beta + \ epsilon} $  with  $ {cov（\ epsilon）= v} $ span&gt; $ 。  $ {\ mu} $  and  $ {\ sigma} $ 是 $
e（x）= \ left [1 \ quad \ alpha \ right]
\ left [\ begin {array} {1} \ mu \\ \ \ sigma \ end {array} \ right] = x \ beta
$  
简化后
  $
\ hat {\ mu} = \ frac {1} {\ delta} \ { -  { -  \ alpha^{&#39;} v^{ -  1}（1 \ alpha^{&#39;} {&#39;}  -  \ alpha 1^{&#39;}
$  
和
  $
\ hat {\ sigma} = \ frac {1} {\ delta} \ {1^{&#39;} v^{ -  1}（1}（1 \ alpha^{&#39;}  -  \ alpha 1^{&#39;} {&#39;} {&#39;}）
$  
其中 $ {\ delta =（1^{&#39;} v^{ -  1} 1）（\ alpha^{&#39;} v^{ -  1} \ alpha） - （1^{&#39;}
如果父母分布是对称的，则我们有 $ \ alpha_ {r} =  -  \ alpha_ {n+r-1} $ ，因此我们有 $ {$ {1^{1^{1^{&#39;} v^{ -  1} {&#39;} { -  1} = 0} = 0}估算值还原为 $ {\ hat {\ mu} = \ frac {1^{&#39;} v^{ -  1} y} y} Y} {1^{&#39;} v^{ -  1} 1} 1} 1} 1}}}}} $ span&gt; $  and 。

请详细地提供该参数的分析说明（如果父母的分布对称，那么我们有 $ \ alpha_ {r} =  -  \ \ alpha_ {n+r-r-1} $ ） 
]]></description>
      <guid>https://stats.stackexchange.com/questions/662620/ordered-least-square-estimation</guid>
      <pubDate>Fri, 14 Mar 2025 16:28:45 GMT</pubDate>
    </item>
    <item>
      <title>如何使用小鼠将排除标准应用于R中的Refate数据集？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662619/how-to-apply-exclusion-criteria-to-imputed-datasets-in-r-using-mice</link>
      <description><![CDATA[我有三个排除条件，需要应用于这些数据集。我正在使用R中的小鼠包装，进行了50次迭代。我需要将数据集限制为

居民=​​ 1，
年龄15-49岁，
删除变量counter_fip的值等于“99999。” 

从这里的另一个线程中，我有适用于第一步的代码：
  uhbs_clean＆lt;  -  with（uhbs_imp8，
             {dat＆lt;  -  data.frame（bfacil，hosp_ob，agecont，mateduc，race_hispan，urban_rural3，婚姻，prev_children，dplural，dlural，county_fips，居民）
             dat＆lt;  -  dat [dat $ endent == 1，]}）
 
但是，当我尝试为下一步做同样的事情时（使用uhbs_clean作为输入数据集并将居民== 1更改为agecont＆gt; 14）时，我会发现一个错误，即找不到第一个变量Bfacil，bfacil，bfacil bfacil bfacilt＆gt; 14）。我还尝试在一个代码块中执行所有步骤：
  uhbs_clean＆lt;  -  with（uhbs_imp8，
             {dat＆lt;  -  data.frame（bfacil，hosp_ob，agecont，mateduc，race_hispan，urban_rural3，婚姻，prev_children，dplural，dlural，county_fips，居民）
             dat＆lt;  -  dat [dat $居民== 1，]
             dat＆lt;  -  dat [dat $ agecont＆gt; 14，]
             dat＆lt;  -  dat [dat $ agecont＆lt; 50，]
             dat＆lt;  -  dat [dat $ county_fips！=＆quot; 99999＆quot;]}）
 
但这也没有起作用，它说数据框的行零。 r不是我的第一种编码语言，所以我有点卡住了！任何帮助都将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662619/how-to-apply-exclusion-criteria-to-imputed-datasets-in-r-using-mice</guid>
      <pubDate>Fri, 14 Mar 2025 16:11:01 GMT</pubDate>
    </item>
    <item>
      <title>低坡/歧视问题：IRT的有用性？</title>
      <link>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</link>
      <description><![CDATA[在项目响应理论中，2-PL模型同时捕获了斜率和截距，而Rasch模型仅捕获截距，将曲线左/右移动（下面捕获）。。
   IRT的一般背景是推断问题难度和学生能力。尽管X轴范围为（-inf，inf），但可以将其转换为范围（0,1）。换句话说， $ x = 0 $ 捕获中位学生能力（或物品难度，因为它们在同一潜在空间中映射。）
通常，给定曲线的歧视力在其拐点处是最大的。关于上面的红色曲线，拐点位于 $ x = 0 $ ，这意味着，如果一个学生真正处于中间位置，则该问题将提供最大的信息，并随着给定的学生的能力增加或降低信息，从而提供了最大的信息。     。
上下文，我的问题很简单：陡峭的斜坡在实践中总是更喜欢？
假设地，如果给定的问题可以通过零差异返回学生的能力（知道学生在拐点以上或低于拐点以上），则可以使用二进制搜索在 $ o（log（log log（log log  time。
当然，这些问题不是确定性的，因此我们绝对可以确定学生没有超出他们的能力问题。但是，我认为，随着这些曲线的斜率接近无穷大（ $ lim：b \ to \ infty）$ 。
考虑到这一假设，较小的歧视性问题（较低的斜率）有用吗？在什么情况下？
我问了一个类似的问题在这里]]></description>
      <guid>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</guid>
      <pubDate>Fri, 14 Mar 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys扔硬币的示例</title>
      <link>https://stats.stackexchange.com/questions/662616/jeffreys-prior-example-for-coin-tossing</link>
      <description><![CDATA[我了解Jeffreys Prior和“不变性”背后的想法。在重新构度下。但是，我试图通过实际示例来理解这种修复的实践含义。
让我们假设将硬币扔掉，以通过贝叶斯的后部更新来估算其公平性。我可以从一个平坦的先验开始，一切都是直观和清晰的。从Jeffreys Prior开始的含义呢？ “公平性”的有趣重新构度将是有趣的。属性？
 jeffreys Prior将在这种情况下是beta分布 jeffreys&#39;尾巴）。这不是违反直觉吗？我会（也许是天真的）期望在1/2中以平坦或以中心为中心。您为什么认为情况并非如此？]]></description>
      <guid>https://stats.stackexchange.com/questions/662616/jeffreys-prior-example-for-coin-tossing</guid>
      <pubDate>Fri, 14 Mar 2025 15:48:24 GMT</pubDate>
    </item>
    </channel>
</rss>