<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 09:16:47 GMT</lastBuildDate>
    <item>
      <title>比较两个回归模型？</title>
      <link>https://stats.stackexchange.com/questions/652320/comparing-two-regression-models</link>
      <description><![CDATA[我有两个测量值（C 和 D）的数据集，它们分别用于两个区域（A 和 B）。我将它们分别绘制在散点图上，以获得两个正相关的图。但我真正想要的是它们彼此之间的差异，与测量值之间的相关性无关，只是 A 和 B 站点之间的测量值有何不同。
我觉得我可以使用方差分析来比较平均值，但事实上，我比较整个图的大小，这样比较它们感觉更准确。
两者的回归模型然后比较它们是否有效，我不知道要进行什么统计测试来测试它们，甚至不知道如何在 R 中测试它们。我主要使用 Rcmdr，因此除非代码解释得非常透彻，否则我对它不是很熟悉。 Rcmdr 确实做了大部分测试，我想我可以指定要使用的模型，除非有人也帮助我，否则我可能只需要查找它。
如果我进行回归，我应该为回归做什么统计测试，我相信我的数据是非参数的，但我不确定我是否做了正确的测试并正确地进行了正态性测试，如果我必须这样做的话。
对不起，我一点也不擅长这些，只是想了解一下。
如果有人能回答这个乱七八糟的问题那就太好了！]]></description>
      <guid>https://stats.stackexchange.com/questions/652320/comparing-two-regression-models</guid>
      <pubDate>Mon, 05 Aug 2024 09:03:31 GMT</pubDate>
    </item>
    <item>
      <title>细胞比例或差异表达的变化？</title>
      <link>https://stats.stackexchange.com/questions/652319/change-of-cell-proportions-or-differential-expression</link>
      <description><![CDATA[假设给出了两种条件下的大量 RNA-Seq，以及各种细胞类型的典型基因表达谱。有人想比较两种条件下的细胞类型比例。
可以从批量数据中解卷积细胞类型比例（使用参考更容易），例如通过 CibersortX。

是否可以区分细胞类型比例的变化（两种条件下的细胞类型组成不同）和基因表达的变化（两种条件下的细胞类型相同，但基因表达模式在两种条件下发生了变化）？

从概念上讲，这如何可能？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652319/change-of-cell-proportions-or-differential-expression</guid>
      <pubDate>Mon, 05 Aug 2024 08:39:21 GMT</pubDate>
    </item>
    <item>
      <title>在随机森林中添加尽可能多的预测因子是一个好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/652315/is-it-a-good-idea-to-add-as-many-predictors-as-possible-in-a-random-forest</link>
      <description><![CDATA[在回归上下文中，回归方程的指定非常重要。当我们将不相关的预测因子添加到回归规范中时，可能会导致错误指定问题，从而损害模型的准确性。
我想知道，在随机森林框架中这是否是一个大问题？我的数据集中有很多预测因子，我应该将它们全部包括进去吗？如果不是，原因是什么？以及如何选择应该包括哪些预测因子？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652315/is-it-a-good-idea-to-add-as-many-predictors-as-possible-in-a-random-forest</guid>
      <pubDate>Mon, 05 Aug 2024 08:04:43 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV 测试错误因手动“for() 循环”或 cv.glm() 而异</title>
      <link>https://stats.stackexchange.com/questions/652314/loocv-test-error-is-different-by-mannually-for-loop-or-cv-glm</link>
      <description><![CDATA[这是关于《统计学习简介及其在 R 中的应用》一书第 5 章中的第 7 个问题。以下是问题文本的一部分：


在第 5.3.2 和 5.3.3 节中，我们看到可以使用 cv.glm() 函数来计算 LOOCV 测试误差估计。
或者，可以仅使用 glm()
和 predict.glm() 函数以及 for 循环来计算这些数量。现在，您将采用这种方法来
计算Weekly数据集上简单逻辑回归模型的 LOOCV 误差。


解决方案 1：使用 glm()、predict.glm() 和 for 循环
library(ISLR2)
error &lt;- numeric(nrow(Weekly))

for (i in 1:nrow(Weekly)) {

fit &lt;- glm(Direction ~ Lag1 + Lag2,
data = Weekly[-i, ],
family = &quot;binomial&quot;)

# &quot;Up&quot;为 TRUE
p &lt;- predict(fit, 
newdata = Weekly[i,,drop = FALSE],
type = &quot;response&quot;) &gt; 0.5

# 错误：错误分类的项目
error[i] &lt;- ifelse(p, &quot;Down&quot;, &quot;Up&quot;) == Weekly$Direction[i]

}

# LOOCV 测试误差估计
mean(error)
# [1] 0.4499541

解决方案 2：直接使用 cv.glm()
library(boot)
fit2 &lt;- glm(Direction ~ Lag1 + Lag2,
data = Weekly,
family = &quot;binomial&quot;)

cv.err.fit2 &lt;- cv.glm(Weekly, fit2)

# LOOCV 测试误差估计
cv.err.fit2$delta[1]
# [1] 0.2464536

这是我的问题：
为什么解决方案 1和解决方案 2的 LOOCV 测试误差估计结果差别很大（0.4499541 V.S. 0.2464536）？它们应该是相同的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652314/loocv-test-error-is-different-by-mannually-for-loop-or-cv-glm</guid>
      <pubDate>Mon, 05 Aug 2024 07:04:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用三次样条函数的 NLME 复制拟合值计算？</title>
      <link>https://stats.stackexchange.com/questions/652313/how-to-replicate-fitted-value-calculation-using-nlme-with-cubic-splines</link>
      <description><![CDATA[我正在使用 R 中的 SITAR 拟合 nlme 模型，
library(sitar)
#&gt;正在加载所需包：nlme
ff &lt;- na.omit(berkeley[berkeley$sex == 2 &amp; berkeley$age &gt;= 8 &amp; berkeley$age &lt;= 18, 
c(&#39;id&#39;, &#39;age&#39;, &#39;height&#39;)])
fh1 &lt;- sitar(x = age, y = height, id = id, data = ff, df = 3, fixed = &quot;a + b + c&quot;, random = &quot;a&quot;)

根据 SITAR 的文档，它表示模型规范为：

在我的代码中，有 3 个固定效应，$\alpha_0、\beta_0、\gamma_0$ 和一个随机效应，$\alpha_i$。所以我的模型是：
$$y_{ij} = \alpha_0 + \alpha_i + h\left(\frac{age_{ij}-\beta_0}{exp(-\gamma_0)}\right) + \epsilon_{ij}$$
我想确保我理解如何计算 SITAR 的预测值。首先，predict.sitar 为我提供了以下内容
模型拟合的预测值：
ages &lt;- seq(0, 18, 0.1)
predicted_height &lt;- predict(fh1, newdata = data.frame(age = ages),, type = &quot;response&quot;, level = 0)
&gt; head(predicted_height)
301 301 301 301 301 301 
85.86228 86.40480 86.94732 87.48984 88.03236 88.57488 

手工计算的预测值：
这些是我估计的固定效应：
&gt; fixef(fh1)
s1 s2 s3 a b c 
35.1254398 55.2275889 32.2892681 124.2293895 -1.3156610 0.1576641 

我根据公式 (1) 获得自然三次样条拟合，即计算 $h\left(\frac{age_{ij}-\beta_0}{exp(-\gamma_0)}\right)$ 并将其存储在 basis 中。
basis &lt;- ns((ages - fixef(fh1)[5])/exp(-fixef(fh1)[6]), df = 3)

将所有内容放在一起：
predicted_height_hand_calculate &lt;- fixef(fh1)[4] + fixef(fh1)[1] * basis[, 1] + fixef(fh1)[2] * basis[, 2] + fixef(fh1)[3] * basis[, 3]
&gt; head(predicted_height_hand_calculate)
[1] 124.2294 124.5082 124.7871 125.0660 125.3449 125.6241

但是，这些与 predicted_height 不匹配。是什么导致了这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/652313/how-to-replicate-fitted-value-calculation-using-nlme-with-cubic-splines</guid>
      <pubDate>Mon, 05 Aug 2024 06:36:38 GMT</pubDate>
    </item>
    <item>
      <title>当相关系数为正时，copula 所求的条件期望是否严格增加，反之亦然？</title>
      <link>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</link>
      <description><![CDATA[我使用 copula 来评估 $\mathbb{E}[Y|X]$，从我对一些 copula 的实验中，我观察到当随机变量具有正相关系数时，$\mathbb{E}[Y|X]$ 严格增加，而当它们负相关时，$\mathbb{E}[Y|X]$ 严格减少。此外，这篇文章中的条件期望图也显示了严格的行为。我想知道这是否正确以及如何证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</guid>
      <pubDate>Mon, 05 Aug 2024 06:12:13 GMT</pubDate>
    </item>
    <item>
      <title>尝试定义一个迭代函数来使用不同的 n 值重复调用 KNeighboursClassifier</title>
      <link>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</link>
      <description><![CDATA[当我运行代码并使用 KNN 而不调用函数时，如果 n 的值是固定的，则不会出现任何错误，准确度得分为 1.0。但是，我想绘制具有不同 n_neighbours 值的准确度得分图。为此，我创建了一个函数，该函数每次迭代都会使用不同的 n_neighbours 值调用分类器。



请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</guid>
      <pubDate>Mon, 05 Aug 2024 06:00:06 GMT</pubDate>
    </item>
    <item>
      <title>如何测试序列中的事件是否均匀（有规律）或随机分布？</title>
      <link>https://stats.stackexchange.com/questions/652309/how-can-one-test-whether-events-in-a-sequence-are-evenly-regularly-or-randomly</link>
      <description><![CDATA[假设有一个长线性分子（例如 DNA 或 RNA），其中位置具有从 1 到 n（最大长度）的增量整数值，我感兴趣的是了解哪些统计测试最适合用于确定某些事件（例如特定碱基的存在或某些其他属性/标准）是否在分子位置之间相对均匀（有规律）间隔发生，或以簇形式发生（可能在局部稍微随机地定位），或仅仅纯粹在分子上的随机间隔发生。如果是这样，那么在确定某些特定的统计分布是否能最好地解释观察到的间隔长度（观察到属性/事件的位置之间的碱基对数）时，某些测试是否比其他测试更有力（更有效）？
从一些阅读中可以看出，非参数检验（例如累积分布函数的 Kolomogorov-Smirnov 检验或 Wald-Wolfowitz 运行检验）可能适合将观察到的分布与某些预期分布进行比较，但我不太清楚是否有更合适（更强大）的参数检验来确定此类事件沿分子的分布是随机的、均匀的，还是以簇的形式分布，簇本身可能也是随机分布的。
我也不清楚，鉴于分子在功能上分为长度为 3 的密码子，其中已知第 3 个或摆动碱基可能与其他两个不同，此类测试在多大程度上可以假设事件发生在任何特定位置的概率与相邻或近相邻位置的概率无关位置，并且代码中存在冗余，因此可能需要对偏差进行一些校正（某些事件在给定位置上发生的可能性可能高于其他位置）。
对于最直接感兴趣的分子，最大长度在 500-5000 之间变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/652309/how-can-one-test-whether-events-in-a-sequence-are-evenly-regularly-or-randomly</guid>
      <pubDate>Mon, 05 Aug 2024 04:44:52 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据超过 50% 的填补理由</title>
      <link>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</link>
      <description><![CDATA[我希望就以下情况获得一些建议/想法：假设我有一项前瞻性观察性研究，旨在评估在两年的随访中 BMI 的变化（主要结果），该研究针对按照护理标准使用药物 A 和药物 B 的人群。重点不是比较 A 组和 B 组之间的 BMI，而是评估每个组内的 BMI 变化。
身高和体重收集的访问应该每六个月进行一次（基线、六个月、12 个月、18 个月和 24 个月），持续 24 个月。然而，由于退出率高，只有 40% 的参与者进行了完整的 24 个月随访，因此未达到主要结果的样本量目标。
考虑到研究的纵向性质，我考虑使用混合效应模型来解释参与者内部的相关性，其中
固定效应与时间（自基线以来的月份）、药物组及其相互作用有关。
随机效应：每个参与者的随机截距和斜率，以解释个体差异。
然而，研究人员也在推动缺失数据填补，但我不确定这是否可行，或者如何向监管机构证明这一点，因为我们必须填补超过 50% 的数据。
您将如何处理这种情况？这里是否需要填补，如果是，哪种填补方法最适合（也许是模式混合模型，因为缺失数据模式是 MNAR？）？您是否推荐我阅读一些关于其他人如何处理和解决类似问题的文章？
任何建议/参考都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</guid>
      <pubDate>Mon, 05 Aug 2024 02:49:05 GMT</pubDate>
    </item>
    <item>
      <title>选择轨迹模型中的组数</title>
      <link>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</link>
      <description><![CDATA[我正在研究基于组的多轨迹模型，该模型有两个二元结果，每个结果在四个时间点进行测量。结果似乎在多大组数（四个或六个 - 五个组更差）最适合方面存在一些冲突，我不确定如何判断。
具体来说，六组解决方案具有更好的 BIC（约 100 分，因此证据确凿），并且正确分类的几率通常更高（OCC - 六组的 8.5-15 vs 四组的 5.7-12），但分配的平均后验概率 (APPA) 低于 Nagin 推荐的阈值 &gt;0.7（六组为 .54 - .81，四组为 .69-.84）。
我该如何选择/证明这个决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</guid>
      <pubDate>Mon, 05 Aug 2024 01:41:26 GMT</pubDate>
    </item>
    <item>
      <title>在联合建模与单独建模中寻找真正的“致病”协变量</title>
      <link>https://stats.stackexchange.com/questions/652255/finding-the-true-causative-covariate-in-joint-versus-separate-modeling</link>
      <description><![CDATA[这是关于一些遗传分配的。
假设我们有两个随机协变量 (SNP) $X1,X2$，以及一个随机响应 $Y$（疾病）。我相信 $X1,X2$ 中只有一个对 $Y$ 具有“因果性”，
但不知道哪一个，目标是基于 $n$ 个 $X1$、$X2$、$Y$ 的随机样本，找出它是 $X1$。
为此，我们有两种可能的策略：
(I) 两个单变量模型：$Y\sim X_{1},Y\sim X_{2}$，并在它们之间进行选择（使用$p_{val}$ 比较或其他）。
(II) 单一回归模型 $Y\sim X_{1}+X_{2}$（并选择具有较低 $p$ 值或更高的模型）。
我需要在以下情况下证明/不证明使用每种策略的合理性：
(a) $X_1,X_2$ 是独立的（例如，两个 SNP 位于不同的染色体上）。
(b) $X_1,X_2$ 是正相关的（例如，两个相邻的 SNP）。

我尝试使用线性回归的基础知识，寻找at
$$
I:\hat{\beta}=X^{T}Y\ \ \ \ \ II:\hat{\beta}=\left(X^{T}X\right)^{-1}X^{T}Y
$$
由此我认为在情况 (a) 中没有太大区别，而在情况 (b) 中我们必须使用 II，因为方法 (I) 没有考虑协变量之间的相关性。但这是“预测”方面，而不是“因果”方面。因此我很难“形式化”这一点。

编辑
感谢大家的回答！
但我觉得我表达得不够清楚。

这个问题不是因果推理的问题，而是回归和建模的问题。我认为我的讲师在这个问题上更多的是指“联想”而不是“因果”。
作为建模者，我们知道其中一个是联想的。现在假设这是$X_1$。问题是哪种策略能更有效地找到它（从错误和功率方面来看）。
这应该是合理的理论问题，而不是实际问题。模拟的想法也是可以接受的。
非常感谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652255/finding-the-true-causative-covariate-in-joint-versus-separate-modeling</guid>
      <pubDate>Sat, 03 Aug 2024 18:34:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么修改后的 z 分数没有发现明显的异常值？</title>
      <link>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</link>
      <description><![CDATA[希望借鉴您对用于检测异常值的修改后的 z 分数的一些见解。
据我从研究中得知，当分布可能不正常（例如偏斜）时，修改后的 z 分数比 z 分数本身更能指示异常值。这是因为，如果分布不为正态分布，则使用中位数而不是均值，中位数是集中趋势的稳健估计量。
我正在针对一个值列表测试这两种算法以及其他一些异常值检测算法，其中我知道一个值是极端异常值。为了帮助我，我创建了一个小型 Python 程序，它根据该列表计算 z 分数和修改后的 z 分数，然后使用它来检查列表中的任何项目是否看起来像异常值。基本上，我检查了这些算法是否能成功检测到我知道存在的极端异常值。
为了检查我的数据的分布，程序创建了一个箱线图，异常值（值 = 200）非常明显。作为参考，该数据集的中位数为 58。

异常值 200 的修改后的 z 分数仅为 2.81，这大大低于被视为异常值的 3.5，因此它不会被标记为异常值。仅供参考，我使用 3.5，因为这似乎是最推荐的截止值。
异常值 200 的 z 分数为 3.40，这高于被视为异常值的 3.0，因此它确实被标记为异常值。仅供参考，我使用 3.0 作为截止值，因为这似乎最受欢迎。
我的问题是，为什么 z 分数算法可以检测到我的数据集中的异常值，而修改后的 z 分数算法却不能？这对我来说似乎是违反直觉的，尤其是当异常值从箱线图中显而易见时。
这是我的 Python，以防我犯了错误：
import matplotlib as plt
import numpy as np
from scipy.stats import zscore

def z_score_mod(obs):
# 修改后的 z-score = 0.6745(xi – x̃) / MAD
med = np.median(obs)
med_abs_dev = np.median(np.abs(obs - med))
z_score_mod = 0.6745 * ((obs - med) / med_abs_dev)
return z_score_mod

# 具有相当大的异常值 = 200 和索引 = 的观察列表13
list_of_obs = [58,71,11,18,90,97,15,53,39,22,62,51,10,200,20,64,94,71,73,18,95,96,92,38,26]

# 将观察列表转换为 numpy 数组
array_of_obs = np.array(list_of_obs)

# 创建箱线图以显示异常值
plt.pyplot.boxplot(array_of_obs)

median = np.median(array_of_obs)

# 计算每个数组项的修改后的 z 分数
array_of_z_score_mod = z_score_mod(array_of_obs)

# 对于生成的修改后的 z 分数，确定是否有任何异常值
array_of_outlier_evals = abs(array_of_z_score_mod) &gt; 3.5

# 索引 = 13 处的观测值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;修改后的 z 分数值 = {array_of_z_score_mod[13]:.2f}&#39;)
print(f&#39;在修改后的 z 分数阈值 3.5 处，值是否为异常值：{array_of_outlier_evals[13]}&#39;)

# 计算每个数组项的 z 分数
array_of_z_score = zscore(list_of_obs)

# 对于生成的 z 分数，确定是否有任何异常值
array_of_outlier_evals_2 = abs(array_of_z_score) &gt; 3

# 索引 = 13 处的观察值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;值的 z-score = {array_of_z_score[13]:.2f}&#39;)
print(f&#39;在 z-score 阈值 3.0 处，值是否为异常值：{array_of_outlier_evals_2[13]}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</guid>
      <pubDate>Fri, 02 Aug 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
&amp; P(M_n &gt; t) \leq P\left(\bigcup_{i=1}^n (Z_i &gt; t) \right) \\ \leq {} &amp; \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align&gt;
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量出现错误时会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</link>
      <description><![CDATA[我昨天问了这个问题，但现在无法登录我的账户了：在未来模型中使用响应变量作为预测变量？
在思考了这个问题（估计雇用新员工对工厂生产率的净成本效益影响）之后，我想到了一种看待这个问题的新方法（即当预测变量有错误时该怎么办？）。我认为也许可以使用工具变量？
方法 1：直接使用工具变量分析净收益

对员工和已处理订单之间的关系进行建模：
$$\hat{P}_t = \hat{\alpha} \hat{E}_t + \hat{\epsilon}_t$$
其中 $\hat{E}_t$ 是 $E_t$ 的仪表化版本。我们使用第一阶段回归：
$$E_t = \gamma_0 + \gamma_1 Z_t + \nu_t$$
$$\hat{E}_t = \hat{\gamma}_0 + \hat{\gamma}_1 Z_t$$
此处，$Z_t$ 为工具变量（例如，招聘的滞后预算分配）。

模型的其余部分保持不变，但在所有部分中使用 $\hat{E}_t$ 代替 $E_t$方程。


我认为工具变量$Z_t$（或$Z_{t-1}$）应该与员工人数相关，但不应直接与主方程中的误差项相关。这可能有助于解决潜在的内生性问题？
这就是工具变量的使用方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</guid>
      <pubDate>Thu, 01 Aug 2024 05:19:04 GMT</pubDate>
    </item>
    <item>
      <title>调查（病例对照？）数据的生存分析</title>
      <link>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</link>
      <description><![CDATA[我有一个数据集，其中包含大约 500 名患有大约 10 种不同疾病的患者，可能具有相关结果，以及 200 名健康对照者。患者数据来自医院，而对照数据来自志愿者，并且不匹配。我们有各种生活事件的全面记录，包括患者和对照者的具体日期（例如，首次非法使用毒品的年龄）和诊断日期。但是，没有可用的抽样权重。
作为第一步，我计划将 Cox 比例风险 (PH) 模型分别应用于每种疾病，使用出生作为时间参考（时间 = 0）。事件是二元的（无论是否诊断出疾病）。数据集包括大约 10 个潜在预测因子，例如性别、种族和教育程度，一些协变量可能与时间有关（例如，婚姻史和就业情况）。
(A) 鉴于病例抽样过多，我可以根据外部来源的患病率或发病率对样本进行加权吗？ （以前做过此类研究的论文链接将非常有帮助。）
(B) 即使这项研究不符合传统定义，它是否可以被视为病例队列研究？
(C) 虽然逻辑回归通常用于病例对照研究（仅产生比值比），但在生存分析中是否有类似的方法来处理此类数据？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</guid>
      <pubDate>Wed, 31 Jul 2024 19:36:40 GMT</pubDate>
    </item>
    </channel>
</rss>