<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 07 Dec 2023 03:15:46 GMT</lastBuildDate>
    <item>
      <title>样本内误差和乐观情绪</title>
      <link>https://stats.stackexchange.com/questions/633275/in-sample-error-and-the-optimism</link>
      <description><![CDATA[我目前正在阅读统计学习的要素的第228页，其中涵盖了训练误差、样本内误差和乐观度。下面我引用一下课本上的一些内容。
&lt;块引用&gt;
$Y^{0}$ 符号表示我们在每个训练点观察到N 个新响应值 $x_i$。我们将乐观度定义为 $\text{Err}_{in}$ 与训练误差 $\overline 之间的差异{\text{err}}$ 为
$$\text{op} = \text{Err}_{in} - \overline{\text{err}}.$$
最后，平均乐观度是对训练集乐观度的期望：
$$w = \mathbb E_{\mathbf y}[\text{op}].$$
这里训练集中的预测变量是固定的，期望是
在训练集结果值上，因此我们使用了符号 $\mathbb E_{\mathbf y}$ 而不是 $\mathbb E_{\tau}$。

我不确定“训练集结果值”的含义。根据我的理解， $Y^0$ 和 $\mathbf y$ 具有相同的含义。即 $Y^0$ 和 $\mathbf y$ 可以视为 iid 随机变量。如果是这样，为什么作者故意使用不同的符号来表达相同的含义？如果不是，符号 $\mathbf y$ 是否指的是训练集中的所有 $y_i$ $\tau$？
我对这个概念感到困惑，因此我们将不胜感激。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/633275/in-sample-error-and-the-optimism</guid>
      <pubDate>Thu, 07 Dec 2023 01:38:13 GMT</pubDate>
    </item>
    <item>
      <title>比较 glmnet 模型</title>
      <link>https://stats.stackexchange.com/questions/633272/comparing-glmnet-models</link>
      <description><![CDATA[anova 函数不允许比较 glmnet 模型：
数据（快速启动示例）
x &lt;- QuickStartExample$x; y &lt;- QuickStartExample$y
设置.种子(11)
fit1 = glmnet(x[,1:10], y, lambda=0.1)
fit2 = glmnet(x[,11:20], y, lambda=0.1)

方差分析（拟合1，拟合2）

UseMethod(“anova”) 中的错误：
  没有适用于“anova”的方法应用于类“c(&#39;elnet&#39;, &#39;glmnet&#39;)”的对象

还有其他选择吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633272/comparing-glmnet-models</guid>
      <pubDate>Thu, 07 Dec 2023 00:37:41 GMT</pubDate>
    </item>
    <item>
      <title>如何比较不同大小的数据集的模型性能？</title>
      <link>https://stats.stackexchange.com/questions/633271/how-can-i-compare-model-performance-across-datasets-of-varying-sizes</link>
      <description><![CDATA[我有一个人戴着 2 个传感器。我创建了两个模型，一个使用 Sensor-1，另一个使用 Sensor-2 数据

我有多个人用不同的数字重复相同的实验。如何根据数据可用性和模型性能对两个传感器进行统计比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/633271/how-can-i-compare-model-performance-across-datasets-of-varying-sizes</guid>
      <pubDate>Wed, 06 Dec 2023 23:56:03 GMT</pubDate>
    </item>
    <item>
      <title>这两个估计的回归系数渐近等价吗？如果不是，哪一种效率更高？</title>
      <link>https://stats.stackexchange.com/questions/633269/are-these-two-estimated-regression-coefficient-asymptotically-equivalent-if-not</link>
      <description><![CDATA[假设我有 $Y=\beta_1X_1+\beta_2X_1X_2+g(X_2)+u$，其中 $E( u|X_1,X_2)=0$ 和 $S=g(X_2)+e$ 和 $ E(e|X_2)=0$。我有一个随机样本 $\{Y_i,X_{1i},X_{2i},S_i\}_{i=1}^n$。假设我首先使用非参数方法（例如核回归或级数回归）来拟合 $\widehat{g}(X_2)$，然后考虑以下两个 $\beta_1,\beta_2$:

由于$Y-g(X_2)=\beta_1X_1+\beta_2X_1X_2+u$，我可以回归$Y -\widehat{g}(X_2)$ 位于 $X_1$ 和 $X_2$并获取 $\beta_1$ 和 $\beta_2$ 的估计器 1。

自 $Y-E(Y|X_2)=\beta_1(X_1-E(X_1|X_2))+\beta_2(X_1-E(X_1|X_2)) X_2$，我可以在 $X_1- 上回归 $Y-\widehat{g}(X_2)$ \widehat{E}(X_1|X_2)$ 和 $(X_1-\widehat{E}(X_1|X_2))X_2$ 并获取我的$\beta_1$ 和 $\beta_2$ 的估计器 2，其中 $\widehat{E}(X_1|X_2)$ 也使用非参数拟合。


我的问题是估计器 1 和估计器 2 渐近等价吗？如果不是，哪一个更有效？为什么？
我的猜测是，由于两个原因，它们并不渐近等价。首先，它们涉及使用非参数方法估计的不同未知函数。其次，由于一些符号的滥用，假设让 $X$ 为两个回归中回归量的 2 × 1 向量，那么这两个回归需要不同的排名条件（$E(XX&#39;)$ 可逆）。
这看起来正确吗？
我也不知道哪一种更有效，哪一种在实践中更受青睐。]]></description>
      <guid>https://stats.stackexchange.com/questions/633269/are-these-two-estimated-regression-coefficient-asymptotically-equivalent-if-not</guid>
      <pubDate>Wed, 06 Dec 2023 23:53:16 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归预测变量可以是名义变量吗？</title>
      <link>https://stats.stackexchange.com/questions/633268/can-logistic-regression-predictor-variables-be-nominal</link>
      <description><![CDATA[逻辑回归预测变量可以是名义变量（如 charlson 合并症指数，范围为 0-6）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633268/can-logistic-regression-predictor-variables-be-nominal</guid>
      <pubDate>Wed, 06 Dec 2023 23:42:04 GMT</pubDate>
    </item>
    <item>
      <title>在技​​术问题中模拟变量（比例）的统计或机器学习方法</title>
      <link>https://stats.stackexchange.com/questions/633267/statistical-or-machine-learning-approach-for-simulating-variable-proportion-am</link>
      <description><![CDATA[我目前面临着分析来自电力驱动生产设施的客户满意度数据的挑战。在本月的特定时期，我们的机械遇到了技术问题，导致客户满意度低于预期。
为了提供背景信息，我们在每月 1 日到 11 日进行最佳运营，并且在这些日子里的每一天，我们都会记录满意客户的百分比。然而，从12日到19日，出现了技术问题，影响了客户满意度。本质上，我们经历了 8 天的“非最佳性能”。以及 22 天的最佳性能。
我正在寻求有关最合适的统计或机器学习方法的建议，以模拟或推断在未发生技术问题的情况下整个月的总体满意度。
我正在考虑的方法：

以 95% 置信区间进行引导重采样、重采样
正常时期客户满意度调查数据
操作来推断我们的预期性能。
蒙特卡罗模拟，假设二项式分布
使用输入的满意度百分比的理论分布
最佳性能时期的数据。

我还听说过使用其他月份的数据进行机器学习或时间序列预测。我希望能够就解决这个问题的最佳方法提供消息灵通且有学术支持的观点。我是一位受人尊敬且经常使用的用户，渴望参与讨论，澄清任何疑问，并真诚地感谢您的时间和见解。预先感谢您。
我想要的输出将是该特定月份的客户满意度比例的置信区间，其中是模拟、推断、预测等。目标是在技术困难未发生的假设下获取此信息]]></description>
      <guid>https://stats.stackexchange.com/questions/633267/statistical-or-machine-learning-approach-for-simulating-variable-proportion-am</guid>
      <pubDate>Wed, 06 Dec 2023 23:40:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该认为这是正常现象还是异常现象？ [迁移]</title>
      <link>https://stats.stackexchange.com/questions/633264/should-i-consider-this-a-normal-phenomenon-or-should-i-consider-it-an-anomaly</link>
      <description><![CDATA[我正在进行网络架构搜索 (NAS)。
我有两个目录，train_data_npy 和 valid_data_npy，其中分别有 3013 个和 1506 个 *.npy 文件。
每个*.npy文件有11列float类型，其中前八列是特征，后三列是三个类的one-hot编码标签（字符）。&lt; /p&gt;
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- --------------------------
f1 f2 f3 f4 f5 f6 f7 f8 ---类---
-------------------------------------------------- --------------------
0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 1.0
6.559 9.22 0.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 1.0
5.512 6.891 10.589 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
7.082 8.71 7.227 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
6.352 9.883 12.492 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
6.711 10.422 13.44 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
7.12 9.283 12.723 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
6.408 9.277 12.542 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
6.608 9.686 12.793 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
6.723 8.602 12.168 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
………………

鉴于数据的格式，我编写了两个脚本。
cnn_autokeras_by_chunk_with_ohe.py 按原样使用 OHE 标签，cnn_autokeras_by_chunk_without_ohe.py 将 OHE 数据转换为整数。即，我使用八列作为特征，仅使用一列作为标签，并且 OHE 转换为数字 $1$、$2 $，$3$。我想预测 $1$、$2$、$3$ 。
第一个的准确度为 0.40，第二个的准确度为 0.97。
我应该认为这是正常现象，还是异常现象？
两个脚本使用相同的功能和类，并寻找最佳架构来解决分类问题。一种是将类表示为 OHE，另一种是将类表示为整数。我的期望是它们会产生类似的准确性，因为这些规范之间的唯一实际差异是标签的表示。但是，由于准确性不同，我很好奇可能是什么导致了这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/633264/should-i-consider-this-a-normal-phenomenon-or-should-i-consider-it-an-anomaly</guid>
      <pubDate>Wed, 06 Dec 2023 22:40:26 GMT</pubDate>
    </item>
    <item>
      <title>关于从 MCMC 获取的样本</title>
      <link>https://stats.stackexchange.com/questions/633228/regarding-samples-gotten-from-mcmc</link>
      <description><![CDATA[在一篇解释MCMC的文章中，我曾经读到过以下的说法。
&lt;块引用&gt;
采样方法的思路如下。我们先假设
我们有一种方法（MCMC）从概率中抽取样本
分布定义为一个因子。然后，而不是试图处理
通过涉及后验的棘手计算，我们可以得到
来自该分布的样本（仅使用未归一化的部分
定义）并使用这些样本来计算各种准时
统计数据，例如平均值和方差，甚至近似
通过核密度估计进行分布。

基于上述解释，我的理解是MCMC从非正态分布中获取样本，但这些样本可以用来计算相应正态分布的函数统计量。我的理解正确吗？如何证明使用非正态分布样本计算出的函数统计量与正态分布样本计算出的函数统计量相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/633228/regarding-samples-gotten-from-mcmc</guid>
      <pubDate>Wed, 06 Dec 2023 16:35:35 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯统计和多项测试</title>
      <link>https://stats.stackexchange.com/questions/633221/bayesian-stats-and-multiple-tests</link>
      <description><![CDATA[贝叶斯模型是否会遇到与常客模型相同的问题，即由于 I 类错误，我们无法运行一堆不同的模型？例如，假设我有一个关于飞机的大型数据框、因变量飞行里程、自变量总乘客数和航空公司的分组变量（虚构的示例）。对于频率统计，我真的不应该根据航空公司将数据框分成一堆较小的数据框，并为每个公司运行不同的回归，我应该以公司作为包含变量运行单个回归（否则，我会得到主要的结果） I 类错误增加）。如果我从贝叶斯角度处理相同的问题，是否适用相同的规则？
由于贝叶斯方法计算量更大，并且在较大的数据集上需要花费很长时间，因此能够拆分数据帧并运行多个模型，最后结合 CI 的结果将很有帮助。但我对贝叶斯统计数据很陌生，所以我不确定这是否是一件坏事。]]></description>
      <guid>https://stats.stackexchange.com/questions/633221/bayesian-stats-and-multiple-tests</guid>
      <pubDate>Wed, 06 Dec 2023 15:19:10 GMT</pubDate>
    </item>
    <item>
      <title>Bootstrapping 如何解释统计数据的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/633194/how-can-bootstrapping-explain-the-uncertainty-of-a-statistic</link>
      <description><![CDATA[我一直在阅读有关引导的内容，以及抽样分布，并发现人们使用这些技术来描述不确定性很奇怪。
据我了解，抽样分布显示了通过对样本进行放回重新抽样来测量的样本统计数据的不确定性。
因此，如果您引导样本，您真正得到的是统计数据的统计数据，具有不确定性界限。
但我们肯定只关心原始统计数据，因为它是总体参数的估计。我们想知道原始统计数据的不确定性界限，因为它告诉我们有关总体的一些信息。那么，为什么我们要关心原始统计量的统计量的不确定性界限呢？
这如何告诉我们有关总体参数的信息？
这里已经有一个对此问题的外行答案：
向外行解释引导为何有效
我的问题是上述问题的延伸。我想在更深的数学层面上了解它是如何工作的，最好有经验证据。]]></description>
      <guid>https://stats.stackexchange.com/questions/633194/how-can-bootstrapping-explain-the-uncertainty-of-a-statistic</guid>
      <pubDate>Wed, 06 Dec 2023 12:53:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算零截断和一膨胀的泊松回归</title>
      <link>https://stats.stackexchange.com/questions/633107/how-to-compute-a-poisson-regression-zero-truncated-and-one-inflated</link>
      <description><![CDATA[我正在处理每次旅行的行程数据，将旅行视为一个人连续进行的各种旅行。我正在尝试用计数模型对此进行建模。我的因变量是每次旅行的出行次数，自变量是出行者的特征（年龄、性别等），或旅行本身的特征（汽车百分比、公共交通百分比等） ）。我正在研究 R 并使用 VGAM 包。
我想使用泊松和负二项式对这种情况进行建模，并且由于数据不包含 0（不存在 0 次旅行的旅行），因此我使用了两个模型零截断。我用过
vglm( y ~ x1 + x2 + ..., family = pospoisson(), data = DB)
vglm( y ~ x1 + x2 + ..., 族 = 正二项式, 数据 = DB)

效果不太好。 Poisson ZT 发送一些关于变量 Hauck-Donner 效应的警告，当我删除该警告时，截距出现错误。在负二项式 ZT 的情况下，它永远不会停止运行，当我强制停止时，最后一条消息是
边界附近的解；要么不需要拟合正 NBD，要么分布以值 1 为中心。
正如我所见，我有很多，当我做直方图时，它非常明显，所以我不仅需要泊松和在 0 处截断的负二项式，而且还需要计算效果该数据被夸大为 1。
在互联网上进行研究后，我没有找到任何直接可以帮助我做到这一点的东西，例如 VGAM 包，所以我寻求帮助。如果你知道一种用一对代码行来做到这一点的方法，那就太棒了，但我不知道我的要求是否太多。无论如何，任何帮助都会有所帮助。
即使对我提出的警告（Hauck-Donner 效应）进行一些澄清也会有所帮助，它们是否只影响警告所针对的变量的重要性，还是也影响其他变量？对于效果（测试版）也有同样的问题。泰斯姆。]]></description>
      <guid>https://stats.stackexchange.com/questions/633107/how-to-compute-a-poisson-regression-zero-truncated-and-one-inflated</guid>
      <pubDate>Tue, 05 Dec 2023 12:50:23 GMT</pubDate>
    </item>
    <item>
      <title>nls 模型中的错误：初始参数估计时的奇异梯度矩阵。无法找出合适的起始值</title>
      <link>https://stats.stackexchange.com/questions/633037/error-in-nls-model-singular-gradient-matrix-at-initial-parameter-estimates-can</link>
      <description><![CDATA[我正在尝试实现本文中的公式 3 研究论文，为了方便起见，这里是方程的屏幕截图：

这是我的代码
taper_model = nls(d ~ (Is*((D^2)*(1 + (((b2 + (b3/D^3)))*( (1 -
    (h/H)^b1) - (1 - (1.37/H)^b1)))/(1 - (1 - (1.3/H))^b1)))) +
    (Ib*(((D^2) - ((((D^2) - (F^2))*(((1 - (1.37/H))^b4) -
    ((1 - (h/H))^b4)))/(((1 - (1.37/H))^b4) -
    ((1 - (F/H))^b4))))^0.5)) +
    (It*((F^2)*((b6*((((h - F)/(H - F)) - 1)^2)) +
    (Im*(((1 - b6)/(b5^2))*(b5 - ((h - F)/(H - F)))^2))))),
    数据=锥度，开始=列表（b1=1，b2=1，b3=1，b4=1，b5=1，b6=1））

我的数据看起来像这样：

当我运行这个程序时，我得到了“初始参数估计的奇异梯度矩阵”我相信这与起始值有关。
上下文，这是一个树锥模型。基本上，这样做是为了能够预测任意给定高度下树的直径。因此，您走到一棵树前，指向树干上的特定高度，然后使用回归系数来预测直径。
我尝试过使用随机起始值，但我不断收到错误。我尝试将指示符变量实现为 ifelse 语句，但仍然不起作用。
taper_model_ifelse = nls(d ~ ifelse(h &lt; 1.37,
       ((D^2)*(1 + (((b2 + (b3/D^3)))*((1 - (h/H)^b1) -
       (1 - (1.37/H)^b1)))/(1 - (1 - (1.3/H))^b1)))), 0)
       + ifelse(h &gt; 1.37 &amp; h &lt; F, (((D^2) -
       ((((D^2) - (F^2))*(((1 - (1.37/H))^b4) -
       ((1 - (h/H))^b4)))/(((1 - (1.37/H))^b4) -
       ((1 - (F/H))^b4))))^0.5), 0) + ifelse(h&gt;F,
       ((F^2)*((b6*((((h - F)/(H - F)) - 1)^2)) +
       否则(0 &lt; (b5-((h-F)/(H-F))),
       (((1 - b6)/(b5^2))*(b5 - ((h - F)/(H - F)))^2), 0))), 0),
       数据=锥度，开始=列表（b1=1，b2=1，b3=1，b4=1，b5=1，b6=1））

我知道我的数据很小，但我正在尝试先学习如何实现这一点，然后再继续处理更大的数据集。如果这有帮助的话，这是数据图：

您认为问题可能出在我的数据上吗？这是在现场收集的实际数据集。我们砍倒一棵树，砍掉顶部的树枝和树叶。茎被分成6英尺的部分。在每个段的顶部测量直径。在数据集中：

我已经围绕这个问题浏览了很多之前的问题和答案，但没有一个能完全解决我的情况，特别是因为我的模型需要估计 6 个系数而不是 2 个。如果有任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/633037/error-in-nls-model-singular-gradient-matrix-at-initial-parameter-estimates-can</guid>
      <pubDate>Mon, 04 Dec 2023 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>您如何解释用于 k 均值聚类分析的锯齿状持续增加轮廓图？</title>
      <link>https://stats.stackexchange.com/questions/632619/how-would-you-interpret-a-jagged-continually-increasing-silhouette-plot-for-k-me</link>
      <description><![CDATA[我正在对文本数据 (k = 750) 运行 k 均值聚类分析，以下是按聚类划分的轮廓得分图
我正在尝试确定最佳 k，我想知道如何解释这一点......

我不确定为什么它如此锯齿？
因为它在不断增加（除了一开始，这个簇数不会提供任何信息），我是否可以认为最佳 k 甚至超过 750 个簇？
]]></description>
      <guid>https://stats.stackexchange.com/questions/632619/how-would-you-interpret-a-jagged-continually-increasing-silhouette-plot-for-k-me</guid>
      <pubDate>Wed, 29 Nov 2023 14:44:52 GMT</pubDate>
    </item>
    <item>
      <title>在由 x 参数化的 z 分布下，P(x|z) 的期望是多少？</title>
      <link>https://stats.stackexchange.com/questions/632611/what-is-the-expectation-of-pxz-under-distribution-of-z-parameterized-by-x</link>
      <description><![CDATA[这个问题源于这个 VAE 教程的第 2.1 节。论文中提出的问题是使用全概率定律计算数据似然：
$$
P(X) = \int P(X,z) \,\mathrm dz = \int P(X \mid z;\theta) P(z) \,\mathrm d z\,。
$$
此处引用的段落：
&lt;块引用&gt;
对于大多数 $z$，$P(x \mid z)$ 将接近于零...这意味着我们需要一个新函数 $Q(z \mid X)$ ，它的值可以是  $X$ 并给出可能产生 $X$&lt; 的 $z$ 值的概率/span&gt; ...这让我们可以相对容易地计算 $\mathbb E_{z \sim Q} P(X \mid z)$。&lt; /p&gt;

但是从原始VAE论文中，我们知道$Q(z \mid X)$ 用于近似后验 $P(z \mid X)$。因此，如果近似成功，那么我们可以将 $Q(z \mid X)$ 替换为 $P(z \ mid X)$ 反之亦然。因此，引用中的期望变为：
$$
\mathbb E_{z \sim Q}[P(X \mid z)] = \int P(X \mid z) Q(z \mid X) \,\mathrm d z = \int P(X \mid z) P(z \mid X) \,\mathrm d z\,.
$$
我什至无法想象右手边是什么！]]></description>
      <guid>https://stats.stackexchange.com/questions/632611/what-is-the-expectation-of-pxz-under-distribution-of-z-parameterized-by-x</guid>
      <pubDate>Wed, 29 Nov 2023 12:24:55 GMT</pubDate>
    </item>
    <item>
      <title>随机傅里叶特征中的重缩放矩阵 W</title>
      <link>https://stats.stackexchange.com/questions/620639/rescaling-matrix-w-in-random-fourier-features</link>
      <description><![CDATA[在使用预测熵搜索优化我的 GP 模型时，我偶然发现了 Rahimi 和 Recht 提出的随机傅里叶特征这个美妙的想法。
我理解使用有限随机特征近似 NxN 核矩阵的总体思想。内核的傅里叶对偶需要适当缩放，以便它代表归一化密度函数。但是，我不清楚缩放的含义是什么以及它与正在近似的内核有何关系。明确地说，乘以矩阵 W 的缩放因子与确切的内核超参数有何关系？
缩放因子在实现中的处理方式不同。
例如，在 Hernández 的 源代码中-Lobato，这个W按长度缩放l：
l = 1 ./ gp_rec.cf{ 1 }.lengthScale.^2;

% 我们绘制随机特征

W = randn(nFeatures, d) .* repmat(sqrt(l(i,:)), nFeatures, 1);
b = 2 * pi * rand(nFeatures, 1);

还有一个很棒的关于 RFF 的教程由 Gregory Gundersen 编写，在他的实现中，W 按 sigma 缩放，而不是 lengthscale l：
Z = 范数 * np.sqrt(2) * np.cos(self.sigma * W @ X.T + B)

我的想法是
$2/D * \cos(\mathbf{\omega}^T \mathbf{x}+\mathbf{b}) * \cos(\mathbf{\omega} ^T \mathbf{x&#39;}+\mathbf{b}) = \exp(i\mathbf{\omega}^T(\mathbf{x}-\mathbf{x}&#39;))$
高斯核的形式为 $\sigma^2\exp(- \frac{\tau^2}{2l^2})$，格式为 rff我们使用 $\exp(-i w \tau)$ 形式，其 z 映射的形式为 $c\ cos(wx+b)$.
尚不清楚 $\sigma$ 和 $l$ 与 $w$ 或 $aw$。因为 $w$ 位于 $\cos$ 内部，这样缩放 $\cos(aw)$ 不是线性的，例如一般情况下 $\cos(2x) \neq 2\cos(x)$ 。类似地，$\cos(2x)*cos(2x) \neq 1/4\cos(x)*cos(x)$，而近似值为$c \cdot cos(wx+b)*cos(wx+b) = k(\cdot)$ = $\sigma ^2\exp(- \frac{\tau^2}{2l^2})$...
我的问题是：

如果我们通过将 W 缩放为标量 a 来缩放 z，这意味着什么？即 $z_{\omega}(\mathbf{x}) = \sqrt{2}\cos(a \mathbf{\omega}^T \mathbf{x}+\mathbf {b}) $。

$\exp(i\mathbf{\omega}^T(\mathbf{x}-\mathbf{x}&#39;))$ 链接到确切的内核及其超参数，例如 sigma（方差）和 l（长度比例）？换句话说，缩放因子 a 与超参数集 $\sigma$ 和 $l$？


或者我实际上误解了这里的意图？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/620639/rescaling-matrix-w-in-random-fourier-features</guid>
      <pubDate>Wed, 05 Jul 2023 20:43:14 GMT</pubDate>
    </item>
    </channel>
</rss>