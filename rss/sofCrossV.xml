<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Jan 2024 21:12:30 GMT</lastBuildDate>
    <item>
      <title>仅使用两侧置信区间的一侧</title>
      <link>https://stats.stackexchange.com/questions/636096/using-only-one-side-of-a-two-sided-confidence-interval</link>
      <description><![CDATA[假设我计算了双边置信区间。例如，假设我计算显着性水平 $\alpha$ 的二项式比例的置信区间为
下，上=conf_interval(count=95，试验=100，重要性=$\alpha$)
如果我只使用下界，我可以调用
较低，_ = conf_interval(count=95，试验=100，显着性=$2\alpha$)
如果我只使用上限，则类似。
现在，假设我正在计算一个函数
out = f(下、上)
其中输出保证等于 out = f(lower, 1) 或 out = f(0, upper) 但我事先不知道它是两者中的哪一个。换句话说，函数的输出与使用下限或上限相同。
在这种情况下我是否仍然可以使用 $2\alpha$ 因为我的函数永远不会“使用”下层和上层同时进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/636096/using-only-one-side-of-a-two-sided-confidence-interval</guid>
      <pubDate>Wed, 03 Jan 2024 20:51:41 GMT</pubDate>
    </item>
    <item>
      <title>使用没有 OTU 关联信息的丰富度表计算特定分类水平的多样性指数</title>
      <link>https://stats.stackexchange.com/questions/636093/calculating-diversity-indices-at-a-specific-taxonomic-level-using-richness-table</link>
      <description><![CDATA[我有一个关于使用特定级别的丰富度表在特定分类级别（例如科级别）计算指数的问题，例如香农指数、逆辛普森指数等。例如，如果我们有一个计数表，其中行代表主题，列代表家庭，那么我们如何导出行为主题、列为家庭的香农索引表？
据我所知，我只知道根据属于该家族的OTU计算指数的公式。但是，我当前的数据集缺乏指示哪个 OTU 属于哪个家族的信息。
有人可以指导我解决这个问题吗？或者，如果您有任何关于此的论文，可以与我分享吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636093/calculating-diversity-indices-at-a-specific-taxonomic-level-using-richness-table</guid>
      <pubDate>Wed, 03 Jan 2024 20:22:09 GMT</pubDate>
    </item>
    <item>
      <title>球面标准差的笛卡尔精度</title>
      <link>https://stats.stackexchange.com/questions/636092/cartesian-precisions-from-spherical-standard-deviations</link>
      <description><![CDATA[我必须模拟一个简单的传感器，它在球面框架中定义了 3 个标准差：西格玛方位角、西格玛仰角、西格玛距离。
当我模拟检测时，我使用这些标准偏差计算噪声位置。
然后我必须计算以传感器为中心的笛卡尔坐标系中的位置和精度。我可以为该位置做到这一点，但我找不到准确度的公式。
有人可以帮助我吗？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636092/cartesian-precisions-from-spherical-standard-deviations</guid>
      <pubDate>Wed, 03 Jan 2024 19:45:44 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡罗模拟进行 Skip-Bo 博弈分析 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</link>
      <description><![CDATA[我正在开展一个项目，探索纸牌游戏 Skip-Bo 中机会与技巧的影响。具体来说，我有兴趣了解玩家牌堆的大小如何影响游戏的结果。我的假设是，牌堆越小（例如，每个玩家 3 张牌），游戏就越依赖机会，这对于不同技能水平的玩家来说更加公平。相反，对于更大的牌堆，我怀疑技能和策略发挥更大的作用，可能有利于更有经验的玩家。
为了研究这个问题，我开始用 Python 编写蒙特卡罗模拟。这是我目前的方法：
随机导入

defsimulate_skip_bo（num_games，pile_size，skilled_player_advantage）：
    win_counts = {&#39;熟练玩家&#39;：0，&#39;新手玩家&#39;：0}

    对于 _ 在范围内（num_games）：
        熟练玩家堆 = 堆大小
        新手玩家堆 = 堆大小

        而 Skilled_player_pile &gt; 0 和 novice_player_pile &gt; 0:
            如果 random.random() &lt;熟练玩家优势：
                熟练玩家堆 -= 1
            别的：
                新手玩家堆 -= 1

        如果熟练玩家堆== 0：
            win_counts[&#39;熟练玩家&#39;] += 1
        别的：
            win_counts[&#39;新手玩家&#39;] += 1

    返回获胜次数

# 模拟参数
游戏数量 = 10000
小堆大小 = 3
熟练玩家优势 = 0.6

# 模拟小桩游戏
small_pile_results=simulate_skip_bo(num_games,small_pile_size,skilled_player_advantage)
打印（小堆结果）

我很确定代码没有回答问题，但我也不知道如何解决它。我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</guid>
      <pubDate>Wed, 03 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>关于计算标准偏差时对偏差进行平方[重复]</title>
      <link>https://stats.stackexchange.com/questions/636083/regarding-squaring-the-deviations-when-calculating-the-standard-deviation</link>
      <description><![CDATA[我了解到，出于多种原因，偏差是平方的。
(1) 它们使所有价值观变得积极。否则偏差之和将为零。但为什么不直接取偏差的绝对值呢？
(2) 保护装置。如果我们的数据以米为单位，则通过对偏差进行平方，然后取平方根，标准差的单位为米。
(3) 我的教科书上说了以下我无法理解的内容：“任何一组观测值与其平均值的偏差平方和是任何数字的偏差平方和所能达到的最小值。可能是。对于非平方距离来说，情况并非如此。因此，平方偏差以平均值为中心，而距离则不然。”
任何人都可以用另一种方式或更简单的方式解释这一点，以便我的小大脑可以理解吗？最好有一个带有数据的示例来补充解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/636083/regarding-squaring-the-deviations-when-calculating-the-standard-deviation</guid>
      <pubDate>Wed, 03 Jan 2024 18:20:12 GMT</pubDate>
    </item>
    <item>
      <title>如果效应规模如此之小，那么研究调节效应还有什么意义呢？</title>
      <link>https://stats.stackexchange.com/questions/636082/whats-the-point-in-studying-moderation-effects-if-effect-sizes-are-so-small</link>
      <description><![CDATA[.002 是中位数，0.009 是心理学中的平均调节效应大小，基于 Aguinis 等人。 2005，评估分类变量调节效应的效应大小和功效：30 年回顾，J。应用心理学，90 94-107。
我的意思是，影响是如此之小，我无法弄清楚它怎么可能有任何兴趣......而且社交世界也充满了噪音......
我正在寻找想法和建议。
提前感谢大家
编辑：感谢您的编辑。我正在添加一些上下文：

期刊：1969 年至 1998 年在《Journal of Applied Psychology》（JAP）、《Personnel Psychology》（PP）和《Academy of Management Journal》（AMJ）上发表的所有文章。选择这些期刊是因为其方法论严谨且强调理论；
纳入标准：(a) 至少一项 MMR 分析被纳入研究的一部分，(b) MMR 分析包括连续标准，(c) MMR 分析包括连续预测因子，以及 (d) MMR 分析分析包括分类调节器。 （NB MMR= 调节多元回归）
最终样本：“计算了 261 个 MMR 分析的效应量，其中样本量和基于调节器的亚组之间的预测因子-标准相关性可用。当可用时，我们使用 X 和 Y 方差信息，并假设该信息不可用的 MMR 分析的误差方差同质性。
在计算结构水平效应大小时（即基于无差错测量），我们在可用时使用可靠性信息，在该信息不可用时使用 0.80 值。
在计算能力方面，我们使用范围从 0.001 到 0.35 的目标 f 2 值，以涵盖应用心理学和管理研究中可被视为关键效应大小的广泛范围以及每项已发表研究中报告的样本大小。”

2°编辑：感谢@所有回答和评论的人。我要结束这个问题了。]]></description>
      <guid>https://stats.stackexchange.com/questions/636082/whats-the-point-in-studying-moderation-effects-if-effect-sizes-are-so-small</guid>
      <pubDate>Wed, 03 Jan 2024 17:59:13 GMT</pubDate>
    </item>
    <item>
      <title>使用核均值嵌入与内积交换积分</title>
      <link>https://stats.stackexchange.com/questions/636081/exchanging-integrals-with-inner-products-with-kernel-mean-embeddings</link>
      <description><![CDATA[我正在阅读一些有关内核均值嵌入的内容。我特别正在阅读 Muandet 等人的调查论文。在第 27 页（第 3.1 节），作者开始简要介绍基于狄拉克度量的核均值嵌入......当然，我们有熟悉的属性
$$
\int f(\mathbf{t})d\delta_{\mathbf{x}}(\mathbf{t}) = f(\mathbf{x})
$$
对于任何可测量的函数$f$。作者利用这一事实以及再现内核希尔伯特空间的再现属性（例如 $\mathcal{H}$）得出结论：
$$
\int f(\mathbf{t})d\delta_{\mathbf{x}}(\mathbf{t}) =
\int \angle f, k(\mathbf{t}, \cdot) \angle_{\mathbf{H}}d\delta_{\mathbf{x}}(\mathbf{t}) =
\left\angle f, \int k(\mathbf{t}, \cdot)d\delta_{\mathbf{x}}(t)\right\angle_{\mathcal{H}} = \angle f, k( \mathbf{x},\cdot)\range_{\mathcal{H}}
$$
其中 $k$ 是与 $\mathcal{H}$ 关联的核函数。从这个意义上说， $k(\mathbf{x}, \cdot)$ 是度量 $\delta_{ 的嵌入$\mathcal{H}$ 中的 \mathbf{x}}$。 我的问题是关于第二个等式。这一步如何严格证明？直观上，我知道这一步类似于使用线性将总和转换为内积，但我不确定这里如何用积分证明类似的逻辑？&gt;
编辑：当我写这个问题时，我想到了这个想法，所以我将其作为编辑包含在内。这是首先将 $k(\mathbf{t}, \cdot)$ 作为一个简单函数以便积分变为总和的情况吗？那么也许一个限制性的论点可以让你了解一般情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/636081/exchanging-integrals-with-inner-products-with-kernel-mean-embeddings</guid>
      <pubDate>Wed, 03 Jan 2024 17:03:45 GMT</pubDate>
    </item>
    <item>
      <title>选择与内生性</title>
      <link>https://stats.stackexchange.com/questions/636076/choice-and-endogeneity</link>
      <description><![CDATA[如果自变量与误差项相关，则该自变量是内生的（来源).
在回归框架中，这种情况可能（仅？）在因变量或自变量中遗漏变量、同时性或测量误差的情况下发生。 [1] 中提供了这些情况导致自变量与误差项相关的证明。
但在文献中，有时您会发现自变量是由所研究的主题选择的事实使其成为内生的。
例如，在[2]中，我们可以读到：
&lt;块引用&gt;
例如，研究人员可能有兴趣测试管理层盈利预测是否会影响资本成本。在这种情况下，内生指标变量（D）表示公司是否发布盈利预测，因变量
是资本成本。
[...]D 是内源性的。

因此，管理层选择盈利预测这一事实使得该变量成为内生的。
我想要一个数学证明，证明一个变量是由所研究的主题选择的这一事实使其与误差项相关，或者同等地，使其成为前面讨论的 3 种内生性情况的一个例子。
[1]：Roberts, M.R.、Whited, T.M.，2013 年。《实证公司金融的内生性》，载于：《金融经济学手册》。 Elsevier B.V.，第 493–572 页。 https://doi.org/10.1016/B978-0-44- 453594-8.00007-0
[2]：Lennox, C.S.、Francis, J.R.、Wang, Z.，2012。会计研究中的选择模型。会计评论 87, 589–616。]]></description>
      <guid>https://stats.stackexchange.com/questions/636076/choice-and-endogeneity</guid>
      <pubDate>Wed, 03 Jan 2024 15:43:55 GMT</pubDate>
    </item>
    <item>
      <title>使用杰弗里先验进行正态分布[重复]</title>
      <link>https://stats.stackexchange.com/questions/636069/using-jeffrey-prior-for-normal-distribution</link>
      <description><![CDATA[
我想使用贝叶斯推理方法进行一些数据分析。我假设数据呈正态分布，均值 $\mu$ 和方差 $\sigma^2$ 未知。对于贝叶斯方法，需要先验分布 $\mu$ 和 $\sigma^2 $。在这里我决定使用杰弗里的先验。然而，那时我对我之前的实际 $p$ 应该是什么样子有点困惑：

$p_1(\mu,\sigma^2)=1/\sigma^2$
或
$p_2(\mu,\sigma^2)=1/\sigma^3$
请参阅http://www.statslab .cam.ac.uk/Dept/People/djsteaching/2009/ABS-lect6-4.pdf。在我看来，第二个似乎更正确，但不知何故，第一个似乎是 Jeffreys（第 20 页）建议的，我并不完全理解。选择其中一种而不是另一种的理由是什么？
编辑：
我不完全理解为什么它在对数变换下是统一的很重要。 $p_1$ 和 $p_2$ 不应该导致不同的后验分布吗？
$p_1$ 经常被使用，只是因为它更简单吗？ 对此的旧讨论
谢谢并致以诚挚的问候
一月]]></description>
      <guid>https://stats.stackexchange.com/questions/636069/using-jeffrey-prior-for-normal-distribution</guid>
      <pubDate>Wed, 03 Jan 2024 15:15:09 GMT</pubDate>
    </item>
    <item>
      <title>因子载荷是回归权重还是相关性？ （正交旋转 EFA）</title>
      <link>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-weights-or-correlations-orthogonal-rotatet-efa</link>
      <description><![CDATA[“因子载荷”是否是“因子载荷”？探索性因素分析 (EFA) 中的（正交旋转）
相关性或标准化回归权重？
例如，在 r 中，如果变量的相关性很强（但与二元相关性不完全相同），则因子载荷非常高，并且标准化回归权重非常小。
图书馆(tidyverse)

数据 &lt;- tibble(id = 1:200) |&gt;;
变异（z1 = rnorm（200，均值 = 0，sd = 1），
      z2 = rnorm(200, 均值 = 0, sd = 1)) |&gt;
变异（v1_1 = z1 + rnorm（200，均值 = 0，sd = .1），
      v2_1 = z1 + rnorm(200, 平均值 = 0, sd = .1),
      v3_1 = z1 + rnorm(200, 平均值 = 0, sd = .1),
      v1_2 = z2 + rnorm(200, 均值 = 0, sd = .1),
      v2_2 = z2 + rnorm(200, 平均值 = 0, sd = .1),
      v3_2 = z2 + rnorm(200, 平均值 = 0, sd = .1)) |&gt;
 选择（-c（z1，z2））

fa &lt;-factanal(数据，因素= 2，分数=“回归”，旋转=“最大方差”)

F A

data_fa &lt;- cbind(数据, fa$scores)

科尔（数据_fa）

拟合 &lt;- lm(因子1 ~ v1_1 + v2_1 + v3_1 + v1_2 + v2_2 + v3_2, data = data_fa)

总结（适合）

负载：
     因素1 因素2
ID
v1_1 0.993
v2_1 0.995
v3_1 0.996
v1_2 0.994
v2_2 0.994
v3_2 0.992

相关性：
             因素1 因素2
编号 0.0568848249 0.0071987895
v1_1 0.9948765006 -0.0044600395
v2_1 0.9968916461 0.0119593283
v3_1 0.9975826189 0.0054520197
v1_2 0.0628987259 0.9952432981
v2_2 0.0607294808 0.9958072362
v3_2 0.0569253903 0.9936277082
系数1 1.0000000000 0.0002178429
因子2 0.0002178429 1.0000000000


标准化回归权重：
lm(公式 = 因子1 ~ v1_1 + v2_1 + v3_1 + v1_2 + v2_2 + v3_2,
    数据 = 数据_fa)

系数：
              估计标准。误差t值Pr(&gt;|t|)
（截距）-4.286e-02 1.348e-05 -3180.341 &lt;2e-16 ***
v1_1 2.506e-01 1.026e-04 2442.716 &lt;2e-16 ***
v2_1 3.587e-01 1.133e-04 3166.710 &lt;2e-16 ***
v3_1 4.233e-01 1.194e-04 3544.716 &lt;2e-16 ***
v1_2 -1.085e-03 1.085e-04 -9.992 &lt;2e-16 ***
v2_2 -1.888e-03 1.140e-04 -16.560 &lt;2e-16 ***
v3_2 -1.977e-03 9.964e-05 -19.845 &lt;2e-16 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-weights-or-correlations-orthogonal-rotatet-efa</guid>
      <pubDate>Wed, 03 Jan 2024 10:05:32 GMT</pubDate>
    </item>
    <item>
      <title>竞争获胜的概率</title>
      <link>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</link>
      <description><![CDATA[我想象这样一个场景：两支球队互相比赛并取得历史胜率。 $1$ 团队相当出色，赢得了 $60\%$ 的比赛。然而，$2$ 团队确实非常出色，赢得了 $90\%$ 的比赛。当两队相遇时，每队获胜的概率是多少？
我尝试使用多变量方法解决此问题，但事实证明这不是一个多变量问题。只有两种结果： $1)$ $\text{团队 1 获胜，团队 2 失败}$ ，或 $2)$ $\text{团队 2 获胜，团队 1 失败}$。这是伯努利分布（a 的简单变体）： $P(\text{队伍 1 获胜，队伍 2 失败}) = p$ 和 $P(\text{团队 2 获胜，团队 1 失败}) = 1 - p$。
应该如何计算$p$？
在上述情况下，我认为两支球队中较差的一支球队的获胜概率一定小于其历史胜利概率$0.6$。然而，由于更好的球队面对的是一支相当不错的球队（赢多于输），因此它的胜利概率也必须低于其历史比率 $0.9$.
我的幼稚方法是将概率计算为“团队拥有的胜利概率的比例” （正如我所说的）。
$$
P(\text{队伍 1 获胜，队伍 2 失败}) = \dfrac{0.6}{0.6 + 0.9} = 0.4\\
P(\text{队伍 2 获胜，队伍 1 失败}) = \dfrac{0.9}{0.6 + 0.9} = 0.6
$$
这个计算有多合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</guid>
      <pubDate>Tue, 02 Jan 2024 19:20:49 GMT</pubDate>
    </item>
    <item>
      <title>条件独立声明的表示</title>
      <link>https://stats.stackexchange.com/questions/635350/representation-of-conditional-independence-statement</link>
      <description><![CDATA[在[归纳集：祖先图马尔可夫模型的新视角] (http: //d-scholarship.pitt.edu/id/eprint/42158），有人提到
&lt;块引用&gt;
符号$V$表示非空变量集。令 $A, B, C \subseteq V(AB \neq \emptyset)$ 为不相交集合。 $N_{A,B |C} \equiv \bigcup_{T \subseteq ABC, T \nsubseteq AC, T \nsubseteq BC} \{T\}$,其中 $ABC =A \cup B \cup C$，$AC =A \cup C$， $BC =B \cup C$。然后使用 $N_{A, B |C}$ 定义与条件对应的集合的集合
独立声明$A, B|C$。

我们知道$A, B|C$表示给定C，A和B是条件独立的。
问题 1：为什么 $N_{A, B |C} $ 不包含 $AC$ 4和$BC$的子集？
问题 2：有人可以解释一下 $N_{A, B |C} $ 背后的直觉吗？
问题3：我认为条件独立语句$A, B|C$只存在于集合$AB$ 并设置 $ABC$，我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635350/representation-of-conditional-independence-statement</guid>
      <pubDate>Wed, 20 Dec 2023 15:38:31 GMT</pubDate>
    </item>
    <item>
      <title>协方差矩阵的迹/行列式是否受统计限制？</title>
      <link>https://stats.stackexchange.com/questions/635336/is-the-trace-determinant-of-the-covariance-matrix-limited-by-statistics</link>
      <description><![CDATA[我正在使用一些给定的实验数据，但有错误，我必须将其拟合到模型中。
给定的实验数据具有非对角协方差矩阵。
数据本质上由许多按能量标记的计数组成（例如，N1 计数为能量 1，N2 计数为能量 2...），并且应遵循不相关的泊松分布。然而，实验分析会受到箱迁移的影响，需要进行一些展开，从而产生非对角协方差矩阵。
现在的重点是，实验者确定的协方差矩阵的行列式很小。我检查发现这是由于生成的相关矩阵具有较小的特征值。
我的问题是：由于泊松误差应减少为 1/sqrt(N)，协方差矩阵行列式可以任意小，还是受实验统计数据（事件数）的限制？]]></description>
      <guid>https://stats.stackexchange.com/questions/635336/is-the-trace-determinant-of-the-covariance-matrix-limited-by-statistics</guid>
      <pubDate>Wed, 20 Dec 2023 12:31:41 GMT</pubDate>
    </item>
    <item>
      <title>回归问题：对 log(y) 进行 MAPE 反向转换</title>
      <link>https://stats.stackexchange.com/questions/613919/regression-question-backtransforming-mape-for-logy</link>
      <description><![CDATA[我正在两个变量之间拟合线性回归，为了减少异方差问题，我对结果变量 y 进行了对数转换。
但是，这让我这个非统计学家很难理解应该如何反向转换为 MAPE（平均绝对百分比误差），因为它是比较所需的指标。我知道，一般来说，应该对最终值进行反向转换，而不是部分计算。但我不知道这种转换应该采取什么形式：T（平均绝对百分比对数误差）= y 的 MAPE。
编辑：错误地写了百分位数而不是百分比，现在已更改。]]></description>
      <guid>https://stats.stackexchange.com/questions/613919/regression-question-backtransforming-mape-for-logy</guid>
      <pubDate>Mon, 24 Apr 2023 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>处理 GLMM 中的奇异性和过度离散？</title>
      <link>https://stats.stackexchange.com/questions/539559/dealing-with-singularity-and-overdispersion-in-glmm</link>
      <description><![CDATA[我正在通过 R 中的 lme4 包运行 GLMM，以检测出生前和出生后喂养（响应）所花费的时间差异（变量 inf_cat 中的 2 个类别）。
我从泊松 GLMM 开始，将女性 ID 作为随机效应（因为我进行了重复测量）以及观察块中女性的总时间的偏移量（以避免使用比例值）：
ba.feed &lt;- glmer(喂食 ~ inf_cat + offset(total_inf_cat) +
    (1|女性)，家庭=泊松，数据=mothers_beforeafter)

摘要显示我的数据过度分散，因此我切换到负二项式 GLMM，但它给了我以下错误消息：
边界（单数）拟合：参见 ?isSingular

摘要显示我的随机效应的方差为 1.255e-11。
根据我的理解，这种奇异的拟合要么来自于模型过于复杂，要么来自于随机效应水平不够。我一直在对此进行故障排除 site 但我仍然对下一步能做什么感到困惑。我认为我无法简单地删除固定效应变量并重新运行模型，因为我的数据集中有重复的测量。]]></description>
      <guid>https://stats.stackexchange.com/questions/539559/dealing-with-singularity-and-overdispersion-in-glmm</guid>
      <pubDate>Sun, 08 Aug 2021 18:50:07 GMT</pubDate>
    </item>
    </channel>
</rss>