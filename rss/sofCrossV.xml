<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 25 Nov 2024 18:23:45 GMT</lastBuildDate>
    <item>
      <title>样本均值的中位数顺序</title>
      <link>https://stats.stackexchange.com/questions/657818/order-of-the-median-of-sample-mean</link>
      <description><![CDATA[令 $X_1,\ldots,X_n$ 为具有正中位数的 iid 样本（为简单起见，均值为 0，方差为 1），令 $\overline X_n = 1/n \sum_{i=1}^nX_i$ 为样本均值。
让 $\text{Med}(\overline X_n)$ 成为 $\overline X_n$ 分布的中位数。

对于 $n$ 而言，$\text{Med}(\overline X_n)$ 可能有哪些顺序？

我对非渐近结果感兴趣，但也欢迎渐近结果。
我已经通过实验检查过，似乎对于各种不对称分布，$\text{Med}(\overline X_n)\gtrsim 1/n$ 都成立。
然而，根据切比舍夫不等式，我知道$\text{Med}(\overline X_n) \lesssim 1/\sqrt{n}$。
然而，从CLT来看，不可能有$\text{Med}(\overline X_n) \gtrsim 1/\sqrt{n}$。
尽管如此，我还是想尽可能接近切比舍夫不等式。

对于所有$\varepsilon&gt;0$，是否有可能找到满足$\text{Med}(\overline X_n) \gtrsim 1/n^{1/2+\varepsilon}$的分布？

在中位数定义不明确的情况下，是否有可能找到满足$\mathbb{P}(\overline X_n \lesssim 1/n^{1/2+\varepsilon})\leq 1/2$的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657818/order-of-the-median-of-sample-mean</guid>
      <pubDate>Mon, 25 Nov 2024 17:59:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使用最大似然估计从数据中拟合/学习非平稳泊松过程？</title>
      <link>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</guid>
      <pubDate>Mon, 25 Nov 2024 17:34:09 GMT</pubDate>
    </item>
    <item>
      <title>同时使用统计抽样和机器学习？</title>
      <link>https://stats.stackexchange.com/questions/657810/using-statistical-sampling-and-machine-learning-together</link>
      <description><![CDATA[我有带标签 $y_i \in \{0,1\}$ 的数据和一些特征 $x_i$。大多数 $y$ 为 0（例如 99% 到 1%）。我想在这个数据上拟合一个随机森林分类模型。
我想知道这种方法是否用于统计学，以避免数据不平衡的问题（例如装袋和重采样的组合）：

获取所有 $y_i = 1$ 的行（我们称这个集合为 $B$）
从 $y_i = 0$ 行中随机抽样，得到一个与 $B$ 大小相同的集合（称每个样本为 $S_k$）
在 $f_k$ 上训练模型 $f_k$ class=&quot;math-container&quot;&gt;$B \cup S_k$
执行此操作$K$次以获得模型$f_1, f_2, ..., f_K$

然后对于任何新输入$x_{new}$，我们的预测只是平均值：
$$ \text{prediction} = \frac{f_1(x_{new}) + f_2(x_{new}) + ... + f_K(x_{new})}{K} $$
然后：对于任何新观察$x_{new}$，如果我们有$K$ 模型，我们可以将一致性得分 $A(x_{new})$ 定义为：
$$ A(x_{new}) = \max\left(\frac{\sum_{k=1}^K I(f_k(x_{new}) = 0)}{K}, \frac{\sum_{k=1}^K I(f_k(x_{new}) = 1)}{K}\right) $$
这给了我们一个介于 0.5（完全不一致）和 1.0（完全一致）之间的分数。可以选择一个阈值来决定应接受什么级别的一致性作为阈值（例如，看看更高的模型一致性是否与更准确的预测相关）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657810/using-statistical-sampling-and-machine-learning-together</guid>
      <pubDate>Mon, 25 Nov 2024 15:15:34 GMT</pubDate>
    </item>
    <item>
      <title>什么是适当的统计测试来比较 ML 模型与 CV 折叠的性能？</title>
      <link>https://stats.stackexchange.com/questions/657809/what-s-the-appropriate-statistical-test-to-compare-ml-model-performance-over-cv</link>
      <description><![CDATA[我正在使用 MSE 等指标比较 10 个 ML 模型在 15 倍交叉验证中的表现。每个模型的表现按倍数排序，我想确定性能是否存在显著差异。
我正在考虑：
Friedman 检验模型之间的总体差异，然后：

Conover
Nemenyi
Wilcoxon 符号秩检验和多重检验校正（例如 Bonferroni）
]]></description>
      <guid>https://stats.stackexchange.com/questions/657809/what-s-the-appropriate-statistical-test-to-compare-ml-model-performance-over-cv</guid>
      <pubDate>Mon, 25 Nov 2024 15:10:48 GMT</pubDate>
    </item>
    <item>
      <title>Beta 回归中的权重</title>
      <link>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</link>
      <description><![CDATA[我在 R 中使用 betareg 来评估覆盖时间百分比与年龄和性别等基线特征之间的关系。
结果测量是测试覆盖时间百分比 (PTC)：每个测试覆盖一名参与者 6 个月。如果参与者在研究期间进行了几次测试，则他们的总覆盖时间是所有覆盖时间 (TC) 的总和。PTC 是 TC 除以他们在研究中的总时间 (TT)。由于参与者之间的 TT 不同；范围从 6 个月到几年，我使用权重来更加强调那些在研究中时间较长的人。我检查了两个权重选项：第一个选项是 TT，第二个选项是 TT/SUM(TT)：对于每个参与者，他们的 TT 除以所有参与者的 TT 总和。因此，第二个选项本质上是第一个选项除以一个常数值 (SUM(TT))。
选项 1：
 调用：
betareg(formula = PTC ~ Sex + Age, data = Test, weights = 
Test$TT, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-10.9333 -3.1518 -0.0751 4.8051 18.9835 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.1771340 0.0281138 -6.301 2.96e-10 ***
性别女性 -0.0323812 0.0114639 -2.825 0.00473 ** 
年龄 0.0169218 0.0004632 36.532 &lt; 2e-16 ***

Phi 系数（带身份链接的精度模型）：
估计标准误差 z 值 Pr(&gt;|z|) 
(phi) 1.94438 0.01234 157.5 &lt;2e-16 ***
---
显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：4 Df 上的 1.267e+04
伪 R 平方：0.01633
迭代次数：17（BFGS）+ 1（Fisher 评分）

选项 2：
 调用：
betareg（公式 = PTC ~ Sex + Age，数据 = Test，权重 = 
Test$TT/T，链接 = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-0.0548 -0.0158 -0.0004 0.0241 0.0952 

系数（带 logit 链接的均值模型）：
估计标准差误差 z 值 Pr(&gt;|z|)
（截距） -0.17713 5.60469 -0.032 0.975
性别女性 -0.03238 2.28541 -0.014 0.989
年龄 0.01692 0.09234 0.183 0.855

Phi 系数（具有身份链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(phi) 1.944 2.461 0.79 0.429

估计量类型：ML（最大似然）
对数似然：4 Df 上的 0.3188
伪 R 平方：0.01633
迭代次数：28（BFGS）+ 3（Fisher 评分）
警告消息：
在 betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, 
control) 中：
未找到精度参数的有效起始值，改用 1 


为什么将权重乘以常数会导致结果如此不同？哪一个是正确的？
编辑：我现在明白重新调整权重、重新调整方差，因此也重新调整 p 值。我现在的问题是哪个选项是正确的？我应该标准化权重吗（选项 2）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</guid>
      <pubDate>Mon, 25 Nov 2024 15:03:37 GMT</pubDate>
    </item>
    <item>
      <title>输入随机数据的随机权重神经网络输出的几何结构</title>
      <link>https://stats.stackexchange.com/questions/657806/geometric-structure-of-the-output-of-a-random-weight-neural-network-fed-with-ran</link>
      <description><![CDATA[采用具有随机权重的模型：
 const create_model = () =&gt; {
const model = tf.sequential();
model.add(tf.layers.dense({ inputShape: [10], unit: 4,activation: &#39;sigmoid&#39; }));
model.add(tf.layers.dense({ inputShape: [10], unit: 16,activation: &#39;sigmoid&#39; }));
model.add(tf.layers.dense({ unit: 2,activation: &#39;sigmoid&#39; })); // 输出层
return model;
};

从正态分布中抽取随机数据并计算随机权重 NN 的输出：
 const size = 25000;

const model = create_model();

const generate_points = async () =&gt;; {
const input = tf.randomNormal([size, 10], 0, 10); 
const output = model.predict(inputs); 
const points = await output.array(); 
input.dispose(); 
output.dispose(); 
r​​eturn points;
};

如果绘制此输出，它将看起来像某种超立方体 2D 投影（请参阅此处的示例 https://imgur.com/a/tBZKeYf）。
为什么超立方体会从随机数据/随机权重中“出现”，什么样的 NN 架构会导致这样的结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/657806/geometric-structure-of-the-output-of-a-random-weight-neural-network-fed-with-ran</guid>
      <pubDate>Mon, 25 Nov 2024 14:10:22 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证在 Python 中拟合零膨胀负二项式时出错</title>
      <link>https://stats.stackexchange.com/questions/657805/error-in-fitting-zero-inflated-negative-binomial-in-python-using-cross-validatio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657805/error-in-fitting-zero-inflated-negative-binomial-in-python-using-cross-validatio</guid>
      <pubDate>Mon, 25 Nov 2024 13:56:01 GMT</pubDate>
    </item>
    <item>
      <title>用于计算效应大小方差（平均差异）的相关值</title>
      <link>https://stats.stackexchange.com/questions/657804/correlation-value-for-calculating-the-variance-of-effect-size-mean-differences</link>
      <description><![CDATA[这是统计问题
我目前正在进行一项荟萃分析，主要使用受试者内/重复测量行均值差异作为效应量。
在一项参考研究中，数据和代码用于调查训练干预前后下肢力量的绝对平均差异。
&gt; https://insidethenumbers.netlify.app/post/meta-analysis/
根据我的理解，数据结构是配对的（例如，治疗前后），只有一个治疗组（如果我错了，请纠正我）。要计算配对数据（例如前后分数）中效应量（平均差异）的方差，我们需要前后分数之间的相关值。但是，下面的函数没有输入相关值的选项。
我的问题是：库（meta）中的 metacont 函数可以用于独立样本和配对样本吗？如果可以用于成对样本，为什么没有相关值的输入？*
library(tidyverse)
library(meta)
library(plyr)

set.seed(10)
study &lt;- paste(&quot;Study&quot;, LETTERS[1:12])
post_mean &lt;- round_any(c(rnorm(n = 4, mean = 130, sd = 5),
rnorm(n = 4, mean = 80, sd = 5),
rnorm(n = 4, mean = 110, sd = 10)), 2.5)
post_sd &lt;- round_any(rnorm(n = length(study), mean = 7.5, sd = 2.5), 2.5)
pre_mean &lt;- round_any(c(rnorm(n = 4, 平均值 = 100, sd = 5),
rnorm(n = 4, 平均值 = 110, sd = 5),
rnorm(n = 4, 平均值 = 110, sd = 10)), 2.5)
pre_sd &lt;- round_any(rnorm(n = length(study), 平均值 = 7.5, sd = 2.5), 2.5)
post_n &lt;- round(rnorm(n = length(study), 平均值 = 25, sd = 10))
pre_n &lt;- post_n
method &lt;- rep(c(&quot;方法 1&quot;, &quot;方法 2&quot;, &quot;方法 3&quot;), each = 4)

dat &lt;- data.frame(study, post_mean, post_sd, pre_mean, pre_sd, post_n,
pre_n, method)

dat 

ma &lt;- metacont(post_n,
post_mean,
post_sd,
pre_n,
pre_mean,
pre_sd,
studlab = study,
data = dat,
sm = &quot;MD&quot;,
comb.fixed = FALSE,
comb.random = TRUE,
hakn = TRUE,
method.tau = &quot;DL&quot;,
byvar = method) 

该函数使用随机效应并计算绝对平均差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657804/correlation-value-for-calculating-the-variance-of-effect-size-mean-differences</guid>
      <pubDate>Mon, 25 Nov 2024 13:53:24 GMT</pubDate>
    </item>
    <item>
      <title>如何确定一个阈值来标记一些数据？</title>
      <link>https://stats.stackexchange.com/questions/657803/how-to-determine-a-threshold-value-to-label-some-data</link>
      <description><![CDATA[我有一组数据，即人体肢体的位置和旋转。我想标记这些数据，以表明哪个肢体与表面接触（例如，如果一只脚与地面接触，则标记相应的 foot_label = 1，另一只脚的 foot_label = 0）。因此，如果它在表面（地面）上方，则意味着它没有与地板接触。目前，我能想到的是一种 kth 百分位数方法，它可以测量 50、20 和 70 的阈值（如果有意义的话）。有什么更好的方法可以解决这个问题？有人知道这种分类的更好的统计方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657803/how-to-determine-a-threshold-value-to-label-some-data</guid>
      <pubDate>Mon, 25 Nov 2024 13:00:39 GMT</pubDate>
    </item>
    <item>
      <title>单一结果，随时间重复的协变量：线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</link>
      <description><![CDATA[我有一个数据集，我想预测一个结果（最后一次随访的 EDSS，以 0 到 10 的数字尺度测量，仅包括 0.5 个小数）。对于每个患者，我有每个患者的 2 个生物标志物测量值。我想创建一个使用生物标志物预测最后一次随访的 EDSS 的预测模型。
我尝试了线性混合模型，但由于未实现收敛，因此会引发错误。这是我使用的公式
EDSS_lastfollow ~ nfl + (1|ID)
我尝试过使用高斯链接函数，也尝试过将结果用作序数变量，但无法达到收敛。我怀疑这是因为我实际上没有重复的结果，而是重复的协变量。我想考虑协变量的 ID 变异性来对其进行建模。你知道我该如何继续建模吗？只要拍一部简单的电影就更好了？]]></description>
      <guid>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</guid>
      <pubDate>Mon, 25 Nov 2024 12:04:23 GMT</pubDate>
    </item>
    <item>
      <title>失败发生在个人身上的概率</title>
      <link>https://stats.stackexchange.com/questions/657800/probability-that-the-failure-is-on-the-individual-as-observe</link>
      <description><![CDATA[David Cox 在其论文《回归模型和生命表》中引入了比例风险模型，他指出：

对于时间 $t_{(i)}$ 处的特定失败，在风险集 $\mathscr{R}(t_{(i)})$ 的条件下，观察到的失败发生在个人身上的概率为

$$
\frac{e^{\vec\beta\cdot\vec{z}_{(i)}}}{\sum_{l\in \mathscr{R}(t_{(i)})} e^{\vec{\beta}\cdot\vec{z}_{(l)}}} 。
\tag{$\ast$}
$$
这里 $\mathscr R(t_{(i)})$ 表示集合风险集，定义为 $t -0$ 时刻处于风险中的个体集合。
指数函数是风险函数的一部分。在 Cox 模型中，我们假设
$$
\lambda(t) = \lambda_0(t) e^{\vec\beta\cdot\vec z},
$$
其中 $\lambda_0(t)$ 是一个“通用”未知函数，用于处理风险函数的时间依赖性，$\vec z$ 是每个个体可用的测量值。
正如 Cox 自己提到的，

本文考虑的主要问题是评估故障时间分布与 $\vec z$ 之间的关系。
这将通过一个模型来实现，其中风险为
$$
\lambda(t) = \lambda_0(t) e^{\vec\beta\cdot\vec z},
$$
其中 $\vec\beta$ 是一个未知参数向量，$\lambda_0(t)$ 是一个未知函数
给出标准条件集 $\vec z = \vec 0$ 的风险函数。

对于每个单独的 $\vec{z}$，获得一个风险函数 $\lambda(t,\vec z)$，并且$(\ast)$可以看作
$$
\frac{\lambda(t,\vec{z}_{(i)})}{\sum_{l\in \mathscr{R}(t_{(i)})}\lambda(t,\vec{z}_{(l)})}。
\tag{$\dagger$}
$$
问题。我们在$(\ast)$中计算的概率（以符号表示）是多少，为什么可以使用风险函数来表示，如$(\dagger)$所示？
正如Cox所定义的那样，
$$
\lambda(t) = \lim_{h\to 0} \frac{\mathbf{P}(t\leq T&lt; t+h \mid T\geq t)}{h} = - \frac{S&#39;(t)}{S(t)},
$$
其中$S(t)$表示生存函数。
根据这个定义，我明白没有概率应该用$\lambda$来描述。]]></description>
      <guid>https://stats.stackexchange.com/questions/657800/probability-that-the-failure-is-on-the-individual-as-observe</guid>
      <pubDate>Mon, 25 Nov 2024 11:32:57 GMT</pubDate>
    </item>
    <item>
      <title>训练神经网络来预测分割模型的假阳性率</title>
      <link>https://stats.stackexchange.com/questions/657799/train-a-neural-network-to-predict-the-false-positive-rate-of-a-segmentation-mode</link>
      <description><![CDATA[我正在尝试训练一个神经网络，根据输入图像和阈值推断图像分割模型的假阳性率。
为此，我正在考虑按以下方式组织的数据集
img1;th1;fpr11
img1;th2;fpr12
img1;th3;fpr13
---------------
img2;th1;fpr21
img2;th2;fpr22

我正在尝试训练一个卷积神经网络，该神经网络由一个特征提取阶段和一个完全连接阶段组成，该阶段可获得提取的特征和阈值参数。
但是，按照这种方式进行，我无法获得良好的推理性能。有没有众所周知的方法来解决这类问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/657799/train-a-neural-network-to-predict-the-false-positive-rate-of-a-segmentation-mode</guid>
      <pubDate>Mon, 25 Nov 2024 10:54:24 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯 (STAN) 与多层模型 (nlme) 得到相反的结果。这怎么可能呢？</title>
      <link>https://stats.stackexchange.com/questions/657798/opposite-results-using-bayesian-stan-vs-multilevel-model-nlme-how-is-this-p</link>
      <description><![CDATA[我的数据集包含 20 年期间 4000 个县的平均工资和累计风力发电装机容量。工资在此期间趋于上涨，而各县之间的发电容量差异很大。作为第一步，我想分析广泛的影响，然后按州和其他类别对各县进行分组。
我在 R 中使用贝叶斯马尔可夫链蒙特卡罗 (MCMC) 模拟和 STAN 进行了基础分析，并得到了小的正相关性，其他研究也支持这一结论。代码一定是正确的，因为它几乎 100% 复制了另一项研究。
现在我尝试使用 nlme 的分层线性模型复制相同的结果，但得到了完全相反的结果。
 model &lt;- lme(median_wage ~ cum_installed_wind + period,
random = ~ period | county_id,
correlation = corAR1(form = ~ period | county_id),
data = obs_level,
method = &quot;ML&quot;)


此代码对我的分析来说正确吗？
这些相反的结果怎么可能呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657798/opposite-results-using-bayesian-stan-vs-multilevel-model-nlme-how-is-this-p</guid>
      <pubDate>Mon, 25 Nov 2024 10:43:45 GMT</pubDate>
    </item>
    <item>
      <title>计算净生存率：应该使用 relsurv 还是 popEpi 包？</title>
      <link>https://stats.stackexchange.com/questions/657796/calculating-net-survival-should-one-use-the-relsurv-or-popepi-package</link>
      <description><![CDATA[Pohar Perme 估计量于 2012 年提出，作为净生存率的无偏估计量，最初用于癌症研究。净生存率估计了在没有癌症诊断的情况下与预期的背景死亡率相比的生存率，与标准相对生存率等其他指标相比具有优势，尤其是在国际比较中。然后，该团队创建了 relsurv R 包，以便轻松计算净生存率。
popEpi 包还通过其 survtab 函数 提供使用 Pohar Perme 方法计算生存率的功能。
对于评估净生存率的特定目的，使用一个包比另一个包有什么优势吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657796/calculating-net-survival-should-one-use-the-relsurv-or-popepi-package</guid>
      <pubDate>Mon, 25 Nov 2024 10:15:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列做了一个回归分析，然后做了 Breusch-Godfrey（BG）检验和 White 检验，检验结果显示既有自相关，又有异方差，因此我选择用 HAC（Newey-West）标准误差来分析。结果让我吃惊的是，HAC（Newey-West）标准误差比普通的标准误差还要小，这是为什么呢？这种情况下，我应该用哪种标准误差呢？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    </channel>
</rss>