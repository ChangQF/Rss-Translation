<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 31 Jul 2024 06:18:46 GMT</lastBuildDate>
    <item>
      <title>样本规模每日交通量</title>
      <link>https://stats.stackexchange.com/questions/652058/sample-size-daily-traffic-volumes</link>
      <description><![CDATA[需要多少样本量来评估每日的交通路口流量，以便为下一年提供真实的情况]]></description>
      <guid>https://stats.stackexchange.com/questions/652058/sample-size-daily-traffic-volumes</guid>
      <pubDate>Wed, 31 Jul 2024 06:14:07 GMT</pubDate>
    </item>
    <item>
      <title>在未来模型中使用响应变量作为预测变量？</title>
      <link>https://stats.stackexchange.com/questions/652053/using-a-response-variable-as-a-predictor-variable-in-a-future-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652053/using-a-response-variable-as-a-predictor-variable-in-a-future-model</guid>
      <pubDate>Wed, 31 Jul 2024 03:36:29 GMT</pubDate>
    </item>
    <item>
      <title>情境学习中的突发性</title>
      <link>https://stats.stackexchange.com/questions/652052/burstiness-in-in-context-learning</link>
      <description><![CDATA[我正在阅读论文上下文分类任务中数据依赖性和突发学习的机制基础。我对参数化数据分布部分感到非常困惑。

这个“数据分布”是指训练数据还是测试数据？（两者都是一批输入序列。）
对于那些突发序列，类别究竟是如何分布的？是不是像来自特定（随机选择的）类别的 B 个项目，然后其余的 N-B 个项目遵循剩余类别的秩频率分布？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652052/burstiness-in-in-context-learning</guid>
      <pubDate>Wed, 31 Jul 2024 03:08:17 GMT</pubDate>
    </item>
    <item>
      <title>这个 Kaplan-Meier 思想实验违反了哪些假设？</title>
      <link>https://stats.stackexchange.com/questions/652048/what-assumptions-does-this-kaplan-meier-thought-experiment-violate</link>
      <description><![CDATA[我一直在思考，假设被审查的受试者仍然活着，那么在跟踪时间的某个特定点，与乘积极限估计值相比，简单的逻辑回归总是会高估生存比例。
但是，我该如何合理化这个荒谬的例子（我假设有关审查的基本假设被打破了）？
想象一下，你有 100 个受试者，你跟踪了（几乎）100 天。在第 99 天，99 人退出了研究，在第 100 天，最后一个离开的人死了。根据乘积极限估计器，生存率是 0%，对吗？ （即事件发生率（累积发生率）为 100%。
但实际上，生存率基本上是 99%，而事件发生率只有 1%。而使用逻辑回归，错误地假设那些被审查的人在研究结束时仍然活着，这样你就更接近真相了。
我认为我没有正确思考问题，但有兴趣纠正。]]></description>
      <guid>https://stats.stackexchange.com/questions/652048/what-assumptions-does-this-kaplan-meier-thought-experiment-violate</guid>
      <pubDate>Wed, 31 Jul 2024 01:58:39 GMT</pubDate>
    </item>
    <item>
      <title>正常性评估中的冲突</title>
      <link>https://stats.stackexchange.com/questions/652047/conflicts-in-normality-assesment</link>
      <description><![CDATA[我有一个小数据集（n=11），当我对正态分布进行评估时，我遇到了这个问题：

偏度和峰度介于（+2，-2）之间
shapiro - wilk p&gt;0,05，表示正态性

但是，直方图和Q-Q图告诉我数据分布不正常。
我计划根据分布进行 wilxocon 排序符号检验或 t 检验。我检查了两个结果，一个结果是 p&gt;0,05，另一个结果是 &lt;0,05，这完全改变了结果。
在某些来源中；有一条一般讨论的规则，即当样本量 &lt; 30i 数据应被假定为非正态分布。
那么在我的问题中，我应该如何得出结论，是正态分布还是非正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/652047/conflicts-in-normality-assesment</guid>
      <pubDate>Wed, 31 Jul 2024 01:48:20 GMT</pubDate>
    </item>
    <item>
      <title>如何正确计算百分比的平均数？</title>
      <link>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</link>
      <description><![CDATA[我正在处理基因组数据；百分比拼接 (psi) 值可以通过包含计数与排除计数的比例找到。为了获得样本的平均 psi 值，我只是计算百分比的平均值，现在我意识到这是错误的，因为它们不是来自相等的权重。
我是一个纯粹的“计算人”，不太擅长统计，所以我只是把东西扔进去，看看结果。分数 2（z 标准化 psi 的平均值）和分数 4（psi 的几何平均值）在实际数据中效果最好；我通过将另一个测量值与分数关联起来来实现这一点。我希望并感谢你们指导我正确的方法，也许解释为什么它是正确的。也欢迎提出更复杂的方法（也许是 Cohen D？）。非常感谢。实际数据非常嘈杂且庞大，下面是我在 R 中尝试的一个例子：
inc &lt;- data.frame(sampleA = c(1755,175 ,11 ,35),
sampleB = c(1500,199,15,20),
sampleC = c(1768,900,122,60),
sampleD = c(1808,881,123,65))

exc &lt;- data.frame(sampleA = c(11311,706 ,257 ,8900),
sampleB = c(12000,706,257,8780),
sampleC = c(2958,354,257,7000),
sampleD = c(2800,354,257,7990))
psi &lt;- inc / (inc + exc)

得分1 &lt;- colMeans(psi)
得分2 &lt;- colMeans(t(scale(t(psi))))
得分3 &lt;- colSums(inc)/(colSums(inc)+colSums(exc))
geometric.mean &lt;- function(x,na.rm=TRUE){exp(mean(log(x),na.rm=na.rm))} 
得分4 &lt;- apply(psi, 2, geometry.mean)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</guid>
      <pubDate>Wed, 31 Jul 2024 00:41:01 GMT</pubDate>
    </item>
    <item>
      <title>包含所有观测因素的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</link>
      <description><![CDATA[我见过当我们想要揭示潜在/未观察到的因素时实施的状态空间模型，这些因素共同解释了因变量时间序列的动态。我也见过混合了可观察和未观察因素的状态空间模型。拟合一个所有因素都可观察的状态空间模型是否有意义？这意味着我有一个因子 f_t 的数据矩阵 X，我想拟合一个状态空间模型，其中的因子遵循 AR(1) 过程，然后从给定 f_t 的 f_t+1 分布中抽样。]]></description>
      <guid>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</guid>
      <pubDate>Tue, 30 Jul 2024 23:35:03 GMT</pubDate>
    </item>
    <item>
      <title>给定一个预测变量 $x$，在什么情况下，你会得到较高的 $R^2$ 但较低的 $\beta$</title>
      <link>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</link>
      <description><![CDATA[假设我有一个时间序列 $y$ 和一个预测变量 $x$。假设它们都以零为中心。
$$R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$$
现在我运行一个新的回归 $y \sim \beta x$，试图“重新调整”我的预测变量。
$\beta = \frac{\operatorname{cov}(x,y)}{\operatorname{var}(x)} = \frac{\sum x_i y_i}{\sum x_i^2}$
我想找到 $\beta$ 和 $R^2$ 之间的关系 （请注意，此 $R^2$ 是我在上面计算的 $R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$，而不是我的新回归的 $R^2$，它产生了 $\beta$，$x$ 已经是一个预测因子 )
我的假设是 $\beta = 1$ 时 $R^2$ 最大化。因为这意味着我的预测因子 $x$ 是“尺度良好的”。但我很难证明这一点……如果这不是真的，为什么当我的预测变量是“最佳缩放”时，$R^2$ 不会最大化？
$$\sum x_i y_i = \beta \sum x_i^2,$$
插入
\begin{align}
R^2 &amp; = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2} \\[6pt] &amp; = 1 - \frac{ \sum x_i^2 - 2\sum x_i y_i + \sum y_i^2 }{\sum y_i^2} \\[6pt] &amp; = \frac{ 2 \sum x_i y_i - \sum x_i^2 }{\sum y^2_i} = (2\beta-1) \frac{ \sum x_i^2 }{ \sum y_i^2}。
\end{align&gt;
没有任何迹象表明 $\beta = 1$ 时 $R^2$ 最大化，但正如我所提到的，不确定为什么当我的预测器“最佳缩放”时 $R^2$ 没有最大化？]]></description>
      <guid>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</guid>
      <pubDate>Tue, 30 Jul 2024 22:09:04 GMT</pubDate>
    </item>
    <item>
      <title>控制变量时的多重共线性</title>
      <link>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</link>
      <description><![CDATA[我对数据中的多重共线性有几个问题：我正在查看 MRI 扫描中发现的某种类型的病变；对于每位患者，我都知道这些病变的体积以及捕捉其分布模式的指标。我对模式指标对临床评分的影响感兴趣，而不仅仅是体积的影响。然而，模式指标与体积高度相关（r = 0.7），这是事物的本质，因为病变在大脑中覆盖的面积越大，它们就越成为一个有凝聚力的区域的一部分，而不是单独的斑点。这让我想知道一些事情：

在像临床评分 ~ 模式 + 体积这样的回归中是否存在多重共线性问题？缓解这样的问题似乎违背了我想要看到的目的。
模式指标已根据体积进行了校正，即每个人的指标已除以该人的病变体积。如果体积已经以某种方式纳入，我是否仍需要在回归中考虑体积？
如果我想进行相关性而不是回归，那么 a) 考虑体积后临床评分和模式指标的偏相关性与 b) 临床评分和残差模式指标的相关性（在将模式指标回归到体积后）之间有什么区别？
当我计算临床评分和残差模式指标的相关性时，相关性高于残差之前，这是正常观察结果吗？我注意到临床评分和体积的相关性为负，而临床评分和模式的相关性为正，鉴于模式和体积的相关性为正且很大，我不确定这是否表明出了问题。也许这就是为什么残差化后与临床评分的相关性更高的原因？有没有更深入的分析方法？

提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</guid>
      <pubDate>Tue, 30 Jul 2024 11:23:33 GMT</pubDate>
    </item>
    <item>
      <title>温度矩阵的比较-统计结果不是实际情况？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</link>
      <description><![CDATA[我遇到了以下问题：我想在 Python 中比较热图像（数据以大矩阵的形式存在/每个像素一个值，50x300，数字在 800 到 1000,0 摄氏度之间）并确定它们是否不同。只有在实际发生相关变化时，图片才应该传输到服务器。因此，比较的是新图片和前一张图片。我想找到一种自动执行此过程的方法。
我有几个数据集，并且知道其中一些数据应该在测试中被视为不同，而另一些数据则被视为相似（由专家事先评估）。我尝试了配对 t 检验、Wilcoxon 检验，并对图片中的不同感兴趣区域进行检验。结果总是图像明显不同。这不是实际情况。有些图片实际上没有区别。
是否有其他未考虑的测试/修改测试的方法？统计测试不适合这个问题吗？有什么建议可以帮助我继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</guid>
      <pubDate>Tue, 30 Jul 2024 09:28:46 GMT</pubDate>
    </item>
    <item>
      <title>测量误差模型中“朴素”估计量的渐近方差</title>
      <link>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</link>
      <description><![CDATA[考虑经典测量误差模型：
$$Y= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \varepsilon$$
其中 $W=X+U$ 是观测值。X 是“真实”量，U 是测量误差。 Var$(X) = \Sigma_x$，Var$(U) = \Sigma_U$。
“朴素”估计量$\hat{\beta}_{\text{naive}} = (W^TW)^{-1}W^TY$是$\beta = (\beta_1, \beta_2)^T$的 OLS 估计量。一个众所周知的结果是 E$(\hat{\beta}_{\text{naive}}) = \Lambda \beta$，其中 $\Lambda = \Sigma_x (\Sigma_x + \Sigma_u)^{-1}$
我对“朴素”估计量的渐近方差感兴趣，其中 $\Sigma_x$ 和 $ \Sigma_u$ 已知。根据非线性模型中的测量误差 - Carrol (2006)中的结果，我相当有信心，$p=1$ 情况下的渐近方差由$\frac{\sigma^2_\epsilon + \beta^2 \sigma^2_x \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_x}}{n (\sigma^2_u + \sigma^2_x)}$ 给出，如果这有帮助的话。]]></description>
      <guid>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</guid>
      <pubDate>Tue, 30 Jul 2024 07:55:40 GMT</pubDate>
    </item>
    <item>
      <title>既然我们现在拥有无限的计算能力（相对于历史规范），我们是否需要使用统计方法而不是模拟？</title>
      <link>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</link>
      <description><![CDATA[Allen Downey 于 2016 年撰写了一篇博客文章，标题为“仍然只有一个测试”，其中讨论了运行模拟相对于传统统计测试的优势。它认为，由于计算速度现在比历史标准快了数万倍，因此统计中的传统分析方法不再有意义。例如，当 t 检验于 1908 年被发现时，它非常有用，因为所有计算都是手工完成的。但如今，iPhone 运行统计计算的速度比 1908 年人类手工计算的速度快约 10 万倍。
引用 Downey 的话：

当计算速度慢且成本高时，这些分析方法是必要的，但随着计算变得更便宜、更快，它们的吸引力就降低了，因为：

它们不灵活：如果您使用标准测试，则必须使用特定的测试统计量和零假设的特定模型。您可能不得不使用不适合您问题领域的测试统计量，只是因为它适合分析。如果您试图解决的问题不适合现成的模型，那么您就倒霉了。

它们不透明：零假设是一个模型，这意味着它是对世界的简化。对于任何现实世界场景，都存在许多基于不同假设的可能模型。在大多数标准测试中，这些假设都是隐含的，很难知道某个模型是否适合特定场景。


模拟方法最重要的优势之一是它们使模型明确化。当您创建模拟时，您不得不考虑您的建模决策，而模拟本身会记录这些决策。

他还在这篇博文中提供了此类模拟的实际示例。这让我感到疑惑：

在当今的计算能力如此强大的情况下，为什么我们仍然要运行传统的统计测试，而不是创建明确的模型并运行数百万次模拟来找出观察结果的真实 p 值？
是否还存在传统统计方法优于模拟的情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</guid>
      <pubDate>Mon, 29 Jul 2024 16:59:39 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布中的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</link>
      <description><![CDATA[变量 $x$ 在区间 $(a-1,a+1)$ 内均匀分布，其中 $a$ 的值未知。对 $x$ 的一次观察给出了值 $x_1$。
如何（有证据）使用 $x_1$ 的这个值来确定 $a$ 的无偏估计，并确定 $a$ 的 $99\%$ 置信限度？
我知道
$$E(x)=\frac{\int_{a-1}^{a+1} xf(x) \;\mathrm{d}x}{\int_{a-1}^{a+1} f(x) \;\mathrm{d}x}=a$$但接下来该怎么做呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</guid>
      <pubDate>Mon, 29 Jul 2024 16:07:54 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟评估功效 - 敏感度</title>
      <link>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</link>
      <description><![CDATA[我正在开展一个项目，该项目比较了两个给出二元结果的不同测试，我们想根据它们的灵敏度来评估这些测试。毫不奇怪，需要多少样本才能达到一定程度的功效的问题出现了。幸运的是，它是先验出现的，因此这不是事后功效计算。
我知道有很多方法可以比较两个具有二元结果的测试的灵敏度 - Fisher 精确检验、McNemar 检验和比例检验。此外，我们对第一个测试的灵敏度进行了估计，约为 75%。为了计算不同样本量的功效，我编写了如下所示的 R 函数。
我尝试将我的结果与一些文献资料进行比较，但到目前为止我发现的所有资料都没有指定测试的一些细节，例如使用哪种特定测试，是否假设测试独立（两个测试是针对同一个人还是针对两组不同的人？），重要性水平等。
对于我的代码，我假设两个测试在不同的组上运行，并且我在代码中指定了所有其他假设。这看起来正确吗？如果不正确，我将不胜感激任何建议。如果两个测试在同一受试者上运行，我将如何进行模拟？我假设我需要考虑两个测试之间的预期相关性，但我不确定如何做到这一点。此外，我是否正确地认为可以进行相同的模拟来估计特异性比较的功效？
set.seed(303)

se1 &lt;- .75 # 测试 1 的灵敏度（或特异性）
se2 &lt;- .80 # 测试 2 的灵敏度（或特异性）

Nd &lt;- 60 # 每组的 dz 数量
Z &lt;- 10000 # 试验次数
alpha = 0.05 # 目标显着性水平

powercalc(se1, se2, Nd, Z, alpha, &#39;fisher&#39;)

#####
powercalc &lt;- function(se1, se2, Nd, Z, alpha, 
test = c(&#39;fisher&#39;, &#39;mcnemar&#39;, &#39;proportion&#39;)){
p_vals &lt;- sapply(1:Z, function(z) {
s1_pos &lt;- rbinom(1, Nd, se1) 
# 使用二项式抽样可能的测试结果
s1_neg &lt;- Nd - s1_pos
s2_pos &lt;- rbinom(1, Nd, se2)
s2_neg &lt;- Nd - s2_pos

# 创建一个矩阵，行对应于两个测试
# 列对应于这些测试的结果
# 这些是具有条件的受试者的结果
# 敏感性
# 或不具有特异性条件的受试者
m &lt;- matrix(c(s1_pos, s1_neg,
s2_pos, s2_neg),
nrow = 2, byrow = TRUE)

if(test == &#39;fisher&#39;)
fisher.test(m)$p.value
else if(test == &#39;mcnemar&#39;)
mcnemar.test(m)$p.value
else if(test == &#39;proportion&#39;)
prop.test(c(s1_pos, s2_pos), c(Nd, Nd))$p.value
})

# 计算我们看到极端排列的次数

# 对于双侧测试
lte_alpha = mean(p_vals &lt;= alpha / 2)
gte_alpha = mean(p_vals &gt;= 1 - (alpha /2))
power_2sided = lte_alpha + gte_alpha
beta_2sided = 1 - power_2sided

# 对于单侧，假设测试二具有更高的敏感度
beta_1sided = mean(p_vals &gt;= alpha)
power_1sided = 1 - beta_1sided

c(one_sided = power_1sided, two_sided = power_2sided)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</guid>
      <pubDate>Sun, 28 Jul 2024 23:03:29 GMT</pubDate>
    </item>
    <item>
      <title>从长数据集（而非宽数据集）分析 ACE 孪生模型</title>
      <link>https://stats.stackexchange.com/questions/651823/analyzing-ace-twin-models-from-a-long-data-set-rather-than-wide-data-set</link>
      <description><![CDATA[我想知道我们是否可以从长数据集而不是通常的宽数据集（R lavaan、mplus）分析 ACE 双胞胎模型。
例如，我发现您可以从此处在 R 中创建 ACE 双胞胎数据。
library(lavaan)
library(MASS)

A &lt;- matrix(1,2,2) # MZ 的遗传相关性 = 1
C &lt;- matrix(1,2,2)
E &lt;- diag(2)
Adz &lt;- matrix(c(1,.5,.5,1),2,2) # DZ 的遗传相关性 = 0.5

# 制作 5 对 MZ 双胞胎
MZ &lt;- MASS::mvrnorm(5,mu=c(0,0),Sigma = A+C+E)

# 添加一列标记为 MZ:
MZ&lt;- cbind.data.frame(&quot;MZ&quot;,MZ)
colnames(MZ) &lt;- c(&quot;zyg&quot;,&quot;P1&quot;,&quot;P2&quot;) 

# 制作 6 对 DZ 双胞胎
DZ &lt;- MASS::mvrnorm(6,mu=c(0,0),Sigma = Adz+C+E)

# 添加变量标记为 DZ:
DZ &lt;- cbind.data.frame(&quot;DZ&quot;,DZ)
colnames(DZ) &lt;- c(&quot;zyg&quot;,&quot;P1&quot;,&quot;P2&quot;)

# 合并 MZ 和 DZ双胞胎
数据集 &lt;- rbind(MZ,DZ)

看起来像这样（双胞胎类型，来自 11 个家庭的双胞胎 1 P1 和双胞胎 P2 的得分）：
数据集

zyg P1 P2
1 MZ 0.77171255 -1.2686729
2 MZ 0.38038471 0.9908333
3 MZ 0.62147499 1.4215385
4 MZ -1.88684235 -1.2684852
5 MZ 2.43757587 2.5915099
6 DZ -0.08042972 0.3650863
7 DZ -0.58447878 -1.6588859
8 DZ -1.59459223 0.5592639
9 DZ 0.94105014 -1.4935118
10 DZ -3.45143197 -3.6395244
11 DZ -0.68945343 1.6007301

可以通过lavaan中的此模型分析数据集，
ace.model&lt;-&quot;
A1=~ NA*P1 + c(a,a)*P1 
A2=~ NA*P2 + c(a,a)*P2 
C1 =~ NA*P1 + c(c,c)*P1
C2 =~ NA*P2 + c(c,c)*P2
# 方差
A1 ~~ 1*A1
A2 ~~ 1*A2
C1 ~~ 1*C1
C2 ~~ 1*C2 
P1~~c(e2,e2)*P1 
P2~~c(e2,e2)*P2
# 协方差
A1 ~~ c(1,.5)*A2 
A1 ~~ 0*C1 + 0*C2 
A2 ~~ 0*C1 + 0*C2 
C1 ~~ c(1,1)*C2
&quot;
ace.fit &lt;- lavaan::cfa(ace.model, data = dataset,group = &quot;zyg&quot;)
summary(ace.fit)

是否有可能从长数据集而不是宽数据集来分析同一模型。
new.dateset &lt;- tidyr::pivot_longer(dataset,
cols = c(&quot;P1&quot;,&quot;P2&quot;),
values_to = &quot;P&quot;)

如果可能的话，我还想找到如何像 $P = A+C+E$ 那样线性生成数据，而不是从协方差矩阵生成数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/651823/analyzing-ace-twin-models-from-a-long-data-set-rather-than-wide-data-set</guid>
      <pubDate>Fri, 26 Jul 2024 17:29:37 GMT</pubDate>
    </item>
    </channel>
</rss>