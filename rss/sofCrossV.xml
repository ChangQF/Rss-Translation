<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 04 May 2024 09:14:41 GMT</lastBuildDate>
    <item>
      <title>有限事件集上不重复的事件链的概率</title>
      <link>https://stats.stackexchange.com/questions/646476/probability-of-chain-of-events-over-a-finite-set-of-event-with-no-repetition</link>
      <description><![CDATA[我正在尝试解决一个我怀疑与我不熟悉的其他问题相似的问题。我希望得到进一步阅读的指导。问题如下：
我们可以采取一组有限的操作$\mathcal{A}=\{A_i\}_{i=1}^n$。&lt; br /&gt;
我们从一个遵循分布 $ P_x$ 的随机变量 $ X$ 开始。然后，我们将随机选择且不重复的一系列操作应用于 $ X$ 以创建一个新的随机变量 $ Y $ 遵循分布 $ P_Y$。 
令 $Z_0, \ldots, Z_n$ 为在此过程中创建的随机变量链，其中 $Z_0=X$  和 $Z_n=Y$。
我可以计算转换概率$p(Z_{j}|Z_{j-1},A_i)$。
我有兴趣计算特定观察对 $p(Y=y|X=x)$ 的可能性  $(x,y)$.
由于该过程涉及所有步骤和所有操作排列的边缘化，因此我也在寻找蒙特卡洛可能性的估计过程，因为它很容易从$p(Z_{j}|Z_{j-1}, A_i)$。
您知道这个问题是否与我可以查看的已知问题相似吗？还有其他建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646476/probability-of-chain-of-events-over-a-finite-set-of-event-with-no-repetition</guid>
      <pubDate>Sat, 04 May 2024 08:36:58 GMT</pubDate>
    </item>
    <item>
      <title>关于均匀分布的阶次统计的练习</title>
      <link>https://stats.stackexchange.com/questions/646475/exercise-about-order-statistics-from-uniform-distribution</link>
      <description><![CDATA[我正在尝试解决有关订单统计的练习。
练习如下：
&lt;块引用&gt;
令 $U_{(1)}&lt; \ldots  是均匀分布 U(0,1) 的阶次统计量。
显示 $(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d }}{}}{=}Z_{n-r+1}$ 其中 $Z_1, Z_2, \ldots ,Z_n$ 是来自 &lt; span class=&quot;math-container&quot;&gt;$\rm Exp(1).$

解决方案首先显示 $(-\log U_{(r)}) \overset{\underset{\mathrm{d}}{}}{=}\ frac{1}{n}Z_1+\cdots+\frac{1}{r}Z_{n-r+1}$ 其中 $Z_1,\ldots,Z_n$  是来自 $\rm Exp(1) $ 的 iid，到目前为止我也明白。
然后解决方案说 $(-\log[U_{(r)}/U_{(r+1)}]) \overset{\underset{\mathrm {d}}{}}{=}(\frac{1}{n}Z_1+\cdots+\frac{1}{r}Z_{n-r+1})-(\frac{1}{n}Z_1+ \cdots+\frac{1}{r+1}Z_{n-r})=\frac{1}{r}Z_{n-r+1}$。因此 $(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d}}{} }{=}Z_{n-r+1}$。
但是我们能做这么简单的减法吗？
无论如何，我知道从一个著名的（？）结果得出的结论是正确的

（这是霍格著名著作《数理统计导论》中的练习之一。）
由此可知 $(-\log U_{(r)}) \overset{\underset{\mathrm{d}}{}}{=} X_{(n-r+1)}$ 其中 $X_1,\dots,X_n$ 是来自 Exp(1) 的 iid。和 $(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d}}{} }{=}r(X_{(n-r+1)}-X_{(n-r)})\overset{\underset{\mathrm{d}}{}}{=}\mathrm{Exp}(1) 。 $
但是我无法理解解决方案中的减法声明。]]></description>
      <guid>https://stats.stackexchange.com/questions/646475/exercise-about-order-statistics-from-uniform-distribution</guid>
      <pubDate>Sat, 04 May 2024 06:05:34 GMT</pubDate>
    </item>
    <item>
      <title>2组协变比较</title>
      <link>https://stats.stackexchange.com/questions/646473/comparison-of-2-groups-with-covariant</link>
      <description><![CDATA[我比较了两组，发现他们的测试成绩有显着差异。然而，我也发现他们的平均年龄有显着差异。我想看看去掉年龄的影响后，各组之间的分数是否仍然存在显着差异。分数和年龄之间的相关性非常小，0.03。
一种选择是使用 ANCOVA，但在我看来，这是有点过时的技术。
我的另一个选择是使用回归模型，但我无法弄清楚模型，具体来说我的 DV 是什么，我的 IV 是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/646473/comparison-of-2-groups-with-covariant</guid>
      <pubDate>Sat, 04 May 2024 05:26:46 GMT</pubDate>
    </item>
    <item>
      <title>总体 KMO 与因子解释的方差之间的关系</title>
      <link>https://stats.stackexchange.com/questions/646472/relationship-between-overall-kmo-and-variance-explained-by-factors</link>
      <description><![CDATA[Kaiser–Meyer– 的维基百科页面Olkin 检验 表示 KMO“是对可能是共同方差的变量之间方差比例的度量。”
因此，您会看到人们的总体 KMO 为 0.9，然后他们说“这意味着共同因素可以解释我观察到的变量中 90% 的变异性”。
其他问题已经讨论了 KMO。据我所知，高 KMO 意味着完全相关性相对于部分相关性更大。从这个问题我知道对于因子来说这是有道理的分析中，我们不应该希望相对于完全相关的高偏相关，因为高偏相关意味着存在仅加载两个变量的因素。
但是，我不明白这如何映射到整体 KMO 衡量“可能是共同方差的变量之间的方差比例”的想法。根据维基百科。
为什么是可能是共同方差的变量之间的方差比例？这个“可能”取决于什么假设？
获取总体 KMO 值不需要指定要提取的因子数量。但是，如果因子数量等于变量数量，则所有 100% 的方差都由因子解释，那么因子解释的方差量不是由我们提取的因子数量决定吗？我知道实际上计算机程序一般不会允许有那么多的因素。]]></description>
      <guid>https://stats.stackexchange.com/questions/646472/relationship-between-overall-kmo-and-variance-explained-by-factors</guid>
      <pubDate>Sat, 04 May 2024 04:30:44 GMT</pubDate>
    </item>
    <item>
      <title>Matplotlib 图表将不会显示 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646471/matplotlib-chart-will-not-display</link>
      <description><![CDATA[如果这是一个错误的论坛，我们深表歉意。她是 Python 和数据科学初学者，正在使用 matplotlib 制作基本图表。我在 Mac OS 上使用 Visual Studio Code。
一般来说，我可以创建一个使用 matplotlib 绘制图表的 Python 脚本。我直接在 VSC 的终端窗口中从 VS Code 运行脚本。当我调用绘图的 show() 方法时，输出会在其自己的窗口中弹出。
此代码不会向我显示图表：
&lt;前&gt;&lt;代码&gt;plot_lm_1 = plt.figure(1)

plot_lm_1.set_fightheight(8)
plot_lm_1.set_figwidth(12)
plot_lm_1.axes[0] = sns.residplot(x=model_fitted_y, y=model_residuals,
                          低=真，
                          scatter_kws={&#39;alpha&#39;: 0.5},
                          line_kws={&#39;颜色&#39;: &#39;红色&#39;, &#39;lw&#39;: 1, &#39;alpha&#39;: 0.8})
plot_lm_1.axes[0].set_title(&#39;残差与拟合&#39;)
plot_lm_1.axes[0].set_xlabel(&#39;拟合值&#39;)
plot_lm_1.axes[0].set_ylabel(&#39;残差&#39;)

plot_lm_1.show()

调试语句显示已到达最后一行。但绘图窗口中什么也没有显示。我确信这非常简单 - 提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/646471/matplotlib-chart-will-not-display</guid>
      <pubDate>Sat, 04 May 2024 03:23:56 GMT</pubDate>
    </item>
    <item>
      <title>如何证明多变量情况（即维度 $d\ge 2$）的后验概率？</title>
      <link>https://stats.stackexchange.com/questions/646469/how-to-prove-the-posterior-probability-for-multivariate-case-i-e-dimension-d</link>
      <description><![CDATA[假设有 $k$ 个组，$\pi_1, \pi_2, \cdots, \pi_k$，组 $\pi_i$ 的概率密度函数为 $f_i(\boldsymbol{x})$&lt; /span&gt;，其中 $\boldsymbol x\in R^d$。样本 $\boldsymbol{x}$ 属于组 $\pi_i$ 的先验概率表示为为 $p_i$，其中 $i=1,2, \cdots, k$，且满足条件为 $p_1+p_2+\cdots+p_k=1$。利用贝叶斯理论，可以证明后验概率（即样本$\boldsymbol{x}$属于$\pi_i$ 鉴于 $\boldsymbol{x}$ 已知）的 $\boldsymbol属于 $\pi_i$ 的 {x}$ 计算如下
$$
P\left(\pi_i \mid \boldsymbol{x}\right)=\frac{p_i f_i(\boldsymbol{x})}{\sum_{j=1}^k p_j f_j(\boldsymbol{x})} , \quad i=1,2, \cdots, k。 \标签{1}
$$
当$d=1$时，根据贝叶斯公式
&lt;块引用&gt;
定理（贝叶斯公式）如果事件 $A_1, A_2, \cdots, A_n$ 互斥且 $B$ 是它们并集 $\bigcup_{j=1}^n A_j$ 的子集，那么当$P(B)&gt;0$，则认为
$$
P\left(A_j \mid B\right)=\frac{P\left(A_j\right) P\left(B \mid A_j\right)}{\sum_{i=1}^n P\left(A_i \right) P\left(B \mid A_i\right)}, \quad 1 \leq j \leq n。
$$

我们有
$$
\开始{对齐}
P\left(\pi_i\mid x\right) &amp; =\lim _{\Delta x \rightarrow 0+} P\left(\pi_i \mid x
当$d\ge 2$时如何证明(1)？]]></description>
      <guid>https://stats.stackexchange.com/questions/646469/how-to-prove-the-posterior-probability-for-multivariate-case-i-e-dimension-d</guid>
      <pubDate>Sat, 04 May 2024 02:35:25 GMT</pubDate>
    </item>
    <item>
      <title>这是多重共线性吗？我怎样才能更好地指定我的模型？</title>
      <link>https://stats.stackexchange.com/questions/646464/is-this-multicollinearity-and-how-can-i-specify-my-model-better</link>
      <description><![CDATA[我正在分析阶梯式楔形整群随机试验的仅常规护理期的数据。目标是将常规护理期描述为队列研究，因为收集的有关参与者和结果的保真度数据比其他方式高得多。结果将与试验的结果相同，并且感兴趣的暴露将是收集的基线协变量。
该试验研究了预防医院获得性感染的干预措施，有十家医院参与。每行数据代表一次入院。因为有些患者不止一次住院，所以我为患者指定了随机效应。因为我们对医院级别的变化感兴趣，所以我将每家医院作为固定效应（因子变量）包括在内。当前的收敛模型如下所示：
m0 &lt;- gam(感染 ~
            年龄+性别+had_surgery+hospital_id+s(patent_id,bs=“re”),
            数据=df,
            家庭=“二项式”）

但是，我想将阶梯楔形试验设计中的 step 变量合并为协变量，以解释研究期间可能的长期趋势。因为我不期望感染率会随时间线性变化，所以我将 step 编码为一个因素。当我将其添加到上面的模型时，它无法收敛。
我怀疑这与多重共线性有关，因为 hospital_id 与 step 的交叉表如下所示（凭借阶梯楔形设计 - 回想一下我们有数据仅从通常护理期间起）：
&lt;前&gt;&lt;代码&gt; 1 2 3 4 5 6 7 8 9 10
 1 183 73 92 66 23 64 23 46 38 88
 2 284 934 639 937 837 777 374 256 356 0
 3 92 37 35 95 85 47 72 37 0 0
 4 17 78 23 40 11 93 28 0 0 0
 5 123 345 685 234 203 111 0 0 0 0
 6 34 22 15 32 99 0 0 0 0 0
 7 32 94 23 15 0 0 0 0 0 0
 8 175 633 17 0 0 0 0 0 0 0
 9 239 34 0 0 0 0 0 0 0 0
10 374 0 0 0 0 0 0 0 0 0

当我将 step 作为连续变量而不是因子时，模型会毫无问题地收敛 - 我无意在最终模型中执行此操作（对我来说这样做没有意义）以这种方式解释变量），但它向我表明，step 的分类性质正在推动收敛问题。我走在正确的轨道上吗？考虑到数据的结构和分析的目标，更好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646464/is-this-multicollinearity-and-how-can-i-specify-my-model-better</guid>
      <pubDate>Sat, 04 May 2024 00:45:29 GMT</pubDate>
    </item>
    <item>
      <title>解读多元逻辑回归中的箱线图</title>
      <link>https://stats.stackexchange.com/questions/646456/reading-boxplots-in-multiple-logistic-regression</link>
      <description><![CDATA[假设逻辑回归的范例，我在理解一些并行箱线图建议的特定模型时遇到一些困难。例如，这里：

我被告知建议的模型是：
$$\text{log(odds)} = \beta 0 + \beta 1(\text{AHigh}) + \beta 2(\text{AHigh} \times X)$$
换句话说，只有分类变量 (\text{A=High/Low}) 和交互项，而不是连续变量 ($X$) ，但我不知道为什么。 $X$ 组的平均 $Y=1$ 值明显高于 $Y=0$ 组，那么它不应该很重要吗？什么表明分类变量显着？我该如何判断交互项是否重要？还有第二个情节我同样感到困惑 - 这里建议什么模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/646456/reading-boxplots-in-multiple-logistic-regression</guid>
      <pubDate>Fri, 03 May 2024 20:48:45 GMT</pubDate>
    </item>
    <item>
      <title>随机实验中分支均值比率的推论</title>
      <link>https://stats.stackexchange.com/questions/646454/inferences-on-ratio-of-branch-means-in-randomized-experiment</link>
      <description><![CDATA[众所周知，均值差是随机实验中平均治疗效果的无偏估计：$\mathbb{E}[Y|A=1]-\ mathbb{E}[Y|A=0]$ 对于 $\mathbb{E}[Y(1) - Y(0)]$ 其中 $A\in{0,1}$ 表示处理分支，$Y(1),Y(0) $分别是治疗和控制下的潜在结果（潜在结果框架）。因此，可以使用标准 t 检验构建 ATE 的置信区间。
众所周知，这相当于具有单个指示变量的线性回归：在以下模型中对 $\hat{\delta}$ 进行推断： $y_i=\alpha + \delta\cdot t_i$ 其中 $t_i\in{0,1}$ 是第 $i$ 个单元的处理指标。
我对随机实验中均值相对差异的推论感兴趣：
$$f(Y_t,Y_c)=\frac{\bar{Y}_t - \bar{Y}_c}{\bar{Y}_c}=\frac {\bar{Y}_t}{\bar{Y}_c}-1$$
我们可以为 $f$ 构建置信区间 分析（Fieller定理的应用）或通过引导。
众所周知，协变量调整（添加预后或基线变量）可以提高 OLS 模型 ATE 估计的精度。这通常用于工业在线实验平台。
很容易看出协变量调整如何改进 ATE 的估计，即均值差异的估计。
我的问题是：有没有办法从相对差异推论的协变量调整中受益（统计$f$，上面）？例如，您可以使用引导程序对 $f(Y_t^{cv},Y_c^{cv})$ 进行推断，其中 $Y_t^{cv},Y_c^{cv}$ 是经过 CUPED 调整的指标值。]]></description>
      <guid>https://stats.stackexchange.com/questions/646454/inferences-on-ratio-of-branch-means-in-randomized-experiment</guid>
      <pubDate>Fri, 03 May 2024 20:37:56 GMT</pubDate>
    </item>
    <item>
      <title>如何计算组间变量的相关性？</title>
      <link>https://stats.stackexchange.com/questions/646436/how-do-i-calculate-the-correlation-of-a-variable-between-groups</link>
      <description><![CDATA[我有一个关于在 spss 中计算相关性的问题。
我所在的小组进行了一项实验研究，其中存在三种条件（因此我们分为三组：1、2 和 3）。
主要假设之一与变量“时间”有关。
所以我有一个包含变量“Time”的数据库和变量“组”。
我想知道我是否可以或如何计算组1的时间、组2的时间和组3的时间之间的相关性。
我已经尝试使用“计算变量”创建新变量（因此组时间 1、组时间 2 和组时间 3）但是当我尝试将这三个变量相互关联时，相关性的输出表显示其中一个变量是常量。
预先感谢您的帮助！
我还添加了我的桌子的图片：

还有我的数据图片：
]]></description>
      <guid>https://stats.stackexchange.com/questions/646436/how-do-i-calculate-the-correlation-of-a-variable-between-groups</guid>
      <pubDate>Fri, 03 May 2024 15:20:02 GMT</pubDate>
    </item>
    <item>
      <title>分析无替换抽样与替换抽样中的累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/646199/analyzing-cumulative-distribution-functions-in-sampling-without-replacement-vs</link>
      <description><![CDATA[最初询问数学。
我正在研究 $N$ 位的总体，包括 $K$ 位和 $N-K$ 个零。对于不放回采样 $n$ 位，情况符合超几何分布。这些 $n$ 位的总和 $S_n$ 得出 $n\frac{K}{N}$ 和方差 $n \frac{K}{N} \frac{N-K}{ N}\frac{N-n}{N-1}$。相反，通过替换对 $n&#39;$ 位进行采样与二项分布对齐，总和为 $S_{n&#39;}$  均值为 $n&#39;\frac{K}{N}$ ，方差为 $n &#39; \frac{K}{N} \frac{N-K}{N}$。
为了进行分析，我绘制了归一化和 $\frac{S_n}{n}$ 和 $\frac{S_{n&#39;}}{n&#39;}$，考虑 $n&#39;$ 的值在 &lt; 范围内span class=&quot;math-container&quot;&gt;$\left[n,\lfloor n\frac{N-1}{N-n}\rfloor\right]$。我观察到，对于超过 $\frac{K}{N}$ 的标准化总和，二项式 CDF 始终低于超几何 CDF。 $n&#39;&gt;n\frac{N-1}{N-n}$ 的趋势跟踪时间更长。
如果 $X$ 是一个超几何分布，其中 n 次从大小为 $N 的总体中进行无替换的抽取$ 与 $K$ 成功，并且 $Y$ 是二项式分布 $B(n&#39;,K/N)$，那么 $n&#39;$ 的最大值是多少=&quot;math-container&quot;&gt;$F_Y(f n&#39;)\leq F_X(f n)$ 代表 $f\geq K/N$？&lt; /strong&gt;.
我认为最大 $n&#39;= \lfloor n\frac{N-1}{N-n}\rfloor$。
这是 $\frac{K}{N}=0.5$ 的动画，其中 $N=50$  其中二项式试验的数量固定为 $n&#39;=n\frac{N-1}{N-n}=21$ 和超几何试验的数量固定为 $n=15$。标记为绿色的部分是归一化总和大于 $p=\frac{K}{N}$ 的区域。在此区域中，二项式 CDF 低于超几何 CDF。

我很好奇分布 CDF 之间的这种关系是否是一种公认​​的现象。值得注意的是，如果 $n&#39;。也许这在某种程度上是相关的？有谁知道有关该主题的相关研究文章吗？
以下是用于生成这些图的 Mathematica 代码，可针对不同的 $p=K/N$ 值进行调整：
操纵[Nx = 10^2;
 n = 30；
 x = p Nx;
 ListPlot[{表[{k/Floor[二项式试验],
     CDF[BinomialDistribution[Floor[二项式试验], p], k]}, {k, 1,
     地板[二项式试验]}],
   表[{k/n,
     CDF[HypergeometricDistribution[n, Floor[x], Nx], k]}, {k, 1,
     n}]}，已加入 -&gt;正确，PlotRange -&gt;全部，
  情节图例 -&gt; {“垃圾箱”，“炒作”}，
  结语 -&gt; {RGBColor[0, 1, 0, 0.25], 矩形[{p, 0}, {1, 1}], 红色,
    Line[{{p, 0}, {p, 1}}]}], {二项式试验, n, n (Nx - 1)/(Nx - n),
   1}, {p, 10^-2, 1}]


有人有可以解释这种模式的见解或参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646199/analyzing-cumulative-distribution-functions-in-sampling-without-replacement-vs</guid>
      <pubDate>Tue, 30 Apr 2024 13:14:46 GMT</pubDate>
    </item>
    <item>
      <title>当备择假设不是原假设的补集时接受备择假设</title>
      <link>https://stats.stackexchange.com/questions/645828/accepting-the-alternative-hypothesis-when-it-is-not-the-complement-of-the-null</link>
      <description><![CDATA[在查看假设检验文献时，我注意到在完成测试后有不同的方式来表达你的结论。
当测试未能拒绝时，似乎存在强烈的共识，即我们不能说我们“接受无效”。这是有充分理由的。这主要源于假设检验基本上是“给定特定显着性水平的矛盾证明”的想法。如果我们未能在空值下拒绝（即，在给定空值的情况下，数据不是非常“极端”，但这仍然不意味着空值是真的）。​​
当测试被拒绝时，我们通常会说“在 $\alpha$% 显着性水平上，我们可以说 $H_1$ 得出什么结论。我知道所有这些结论都不是“证据”。并且仅保持在特定的显着性水平 $\alpha$ 下，这是限制测试的 I 类错误的结果。我区分两种情况：

$H_1$ 是 $H_0$ 的补集（这当然取决于底层参数空间）。一个例子是我们测试 $H_0: \theta =0 $ 与 $H_1: \theta \ 的经典案例neq 0.$ 我认为大多数人会说，当你的测试在这里被拒绝时，你可以说 $H_0$ 不正确，因此 $H_1$ 必须为 true。请注意，后者对于经典示例来说并不是一个非常有力的主张，因为它几乎包含了整个参数空间。尽管如此，当零也是一个复合假设时，我认为我们仍然可以说，当 $H_1$ 是 $H_1$。

$H_1$ 不是 $H_0$ 的补集。一个典型的例子是简单的 null 和简单替代方案，但底层参数空间还包含其他值。在这里，我想说的是，当我们拒绝时，我们不能得出替代方案，我们只能说 null 不为真。


大家对以上说法有异议或者有其他想法吗？我认为这一切都归结于这样一个事实：我们正在处理随机数据，很难对底层 DGP 做出明确的声明。但是，对于政策建议等，我们仍然想提出某种主张，这就是我问这个问题的原因。
编辑：在标准 NHST 框架中，备择假设始终是原假设的补集。因此，第(2)点的表述并不完善。感谢所有提供有用见解的评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/645828/accepting-the-alternative-hypothesis-when-it-is-not-the-complement-of-the-null</guid>
      <pubDate>Thu, 25 Apr 2024 15:38:13 GMT</pubDate>
    </item>
    <item>
      <title>固定效应导致多重共线性</title>
      <link>https://stats.stackexchange.com/questions/631126/fixed-effects-causes-multicollinearity</link>
      <description><![CDATA[我对我的回归模型有疑问，如果您能提供帮助，我将不胜感激。
我有一个数据集，其中包含交易的每个部分（一个交易可能包含多个部分）及其变量，例如池大小、评级等。这些部分在交易启动时包含在数据集中，并且来自所有交易过去 10 年的数据，因此每次观察都是不同的部分，是交易的一部分。每个部分仅收集一次，这意味着 5 年后收集的部分是来自不同交易的部分。
这就是为什么我相信我的数据集是汇总的横截面数据而不是面板数据。
考虑到这一点，我使用 lm 包在 R 中运行了回归：
MR1111 &lt;- lm(Credit_Spread ~ log_Poolgroesse + Anzahl_Tranchen_Deal +
             Zwei_Ratingagenturen + Anzahl_Finanzinstitute +
             Anzahl_Arten_Gewerbeimmobilien + Regel_144A_SEC +
             Pool_LTV + Uneinigkeit_Ratingagenturen + WAL +
             Waehrungsrisiko + log_Tranchevolumen + Arbeitslosenquote，
             数据 = Datensatz_neu6)

然后我使用 VIF 命令检查了多重共线性。一切都很好，没有值超过 5，大部分在 1 到 1.5 之间。
然后我运行了与上面相同的回归，但对于交易启动的季度和交易启动的国家/地区（Land_der_Sicherheiten）具有固定效应：
MR1111 &lt;- lm(Credit_Spread ~ log_Poolgroesse + (...) +
              as.factor(FE_Quartal) +
              as.factor(Land_der_Sicherheiten), 数据 = Datensatz_neu6)

在测试多重共线性时，除了 as.factor(FE_Quartal) 的值为 51367.27 和 as.factor(Land_der_Sicherheiten) 320.326 之外，所有变量仍低于 5。
我该如何处理这个问题？
可能很重要的信息：同一季度推出了多项观察结果。对于发起交易的国家/地区也是如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/631126/fixed-effects-causes-multicollinearity</guid>
      <pubDate>Sun, 12 Nov 2023 15:24:12 GMT</pubDate>
    </item>
    <item>
      <title>如何对两个不同事件的到达时间进行建模？</title>
      <link>https://stats.stackexchange.com/questions/626209/how-can-you-model-the-arrival-times-of-2-different-events</link>
      <description><![CDATA[我正在研究泊松过程并使用指数分布来模拟事件的到达时间。
例如，一个人到达公交车站的可能性。然后，在简单的情况下，我想对公交车的到达进行建模，并为此使用另一个指数。
我想的是如果发生其他事情怎么办。
例如，这个人改变了主意并决定步行。
在这种情况下，简单地说：

有人到达
发生以下情况之一，以先到者为准

公交车来了
某人感到无聊并决定步行



我可以想象上述情况是独立的，也可以是不独立的情况 - 即，如果这个人已经等待了 1 小时，那么他们更有可能感到无聊。
你会如何处理这个问题？
我想到的一种方法是模拟每一“分钟”。会发生什么。即公共汽车到达的一些可能性，然后他们感到无聊并创建状态转换类型设置的一些可能性。]]></description>
      <guid>https://stats.stackexchange.com/questions/626209/how-can-you-model-the-arrival-times-of-2-different-events</guid>
      <pubDate>Mon, 11 Sep 2023 14:47:04 GMT</pubDate>
    </item>
    <item>
      <title>GPT-2 中神经元的计算：了解方法</title>
      <link>https://stats.stackexchange.com/questions/617654/calculation-of-neurons-in-gpt-2-understanding-the-methodology</link>
      <description><![CDATA[在 OpenAI 最近的更新中，他们提到在 GPT-2 模型中发现了 N 个神经元。这一发现提出了一个问题：他们是如何得出这个计算的？在他们的出版物中，他们没有明确提及确定神经元数量背后的方法。
经过进一步调查，我发现了一组公式，这些公式通常用于估计 GPT-2 等基于 Transformer 的模型中的神经元和参数数量。这些公式虽然 OpenAI 没有具体提及，但为理解计算提供了一个很好的起点。
公式如下：
$$\text{神经元}= H * A * L$$
$$\text{参数} = A * (H^2 / A) * L$$
这里，“H”是表示隐藏尺寸，“A” “L”指模型中注意力头的数量，“L”表示模型中注意力头的数量。表示模型中的层数。
值得注意的是，这些公式对模型架构做出了某些假设。他们假设每个注意力头和层中的神经元数量是恒定的，但实际情况可能并非如此。此外，它们没有考虑 Transformer 模型特有的其他架构元素，例如位置编码和前馈网络。
虽然所提供的公式提供了估计神经元数量的通用方法，但有必要考虑具体的模型架构并参考实际的实现细节以获得更准确的计算。
考虑到这一点，谁能更详细地说明 OpenAI 如何计算 GPT-2 模型中的 N 个神经元？ OpenAI 是否明确提到了他们的方法或提供了对该过程的更多见解？如果对这个主题有任何进一步的澄清，我们将不胜感激。
预先感谢您的意见和专业知识！]]></description>
      <guid>https://stats.stackexchange.com/questions/617654/calculation-of-neurons-in-gpt-2-understanding-the-methodology</guid>
      <pubDate>Fri, 02 Jun 2023 10:15:07 GMT</pubDate>
    </item>
    </channel>
</rss>