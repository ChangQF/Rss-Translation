<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Sep 2024 21:16:15 GMT</lastBuildDate>
    <item>
      <title>具有 G 幂分类预测因子的逻辑回归样本大小</title>
      <link>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</link>
      <description><![CDATA[我想弄清楚 G 幂是否适合我的情况，以及我是否做对了。我希望计算先验样本量。
我即将使用注册数据进行队列研究，使用逻辑回归对疾病是/否进行二元结果分析。但是我的预测因子 (x) 有 3 个类别/组。据我所知，我应该“将这些视为”2 个变量（一个参考）。这些组也可能不均衡。
此外，我可能还有多达 7 个其他协变量。
我的问题：
使用 G 幂是否可行？如果可以……
当有 3 个不均匀组时，如何设置我的“x parm”？
即使预测因子有多个类别，x 分布仍然是二项式的？
解释协变量的唯一方法是使用“R2 其他 x”？或者有没有其他方法/应用程序可以做得更好？
在我的测试中，效果大小为 OR 1.27（我希望检测到 2% 的 ARR）。仍然是均等匹配的组。我需要 6703 名患者，似乎很高？或者由于差异如此之小，可能是正确的？对于 x 分布“正态”或“泊松”，样本量要低得多。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</guid>
      <pubDate>Wed, 25 Sep 2024 20:15:55 GMT</pubDate>
    </item>
    <item>
      <title>多项逻辑回归中的参数识别</title>
      <link>https://stats.stackexchange.com/questions/654914/parameter-identification-in-multinomial-logit</link>
      <description><![CDATA[我正在估算$\beta$以下模型：
$$
p_1=\frac{\exp(\beta x_1)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_2=\frac{\exp(\beta x_2)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_3=\frac{\exp(\beta x_3)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
此模型中是否识别出$\beta$？
如果没有，要识别$\beta$，我是否需要将选择标准化为 1？例如：
$$
p_1=\frac{1}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_2=\frac{\exp(\beta x_2)}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_3=\frac{\exp(\beta x_3)}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
如果在第一个模型中识别出$\beta$，则两个模型中的$\beta$测量的是不同的东西吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654914/parameter-identification-in-multinomial-logit</guid>
      <pubDate>Wed, 25 Sep 2024 20:12:15 GMT</pubDate>
    </item>
    <item>
      <title>多层次建模？</title>
      <link>https://stats.stackexchange.com/questions/654913/multi-level-modelling</link>
      <description><![CDATA[在一项教学研究中，我对写作质量进行了前测和后测测量——没有控制条件。10 个班级中有 110 名学生。我对拼写技能和手写流畅度进行了前测测量，作为协变量。我想测试：
-从前测到后测，分数是否有所提高？
-每个协变量是否预测了文本质量水平？
-每个协变量是否预测了从前测到后测的文本质量增益？
-从前测到后测，各个班级的文本质量增益是否不同？
-如果可能，测试班级之间在文本质量增益方面的差异是否受到手写和拼写的影响
只有两个时间点，我可以使用多级建模吗？在 SPSS 中？
感谢您对此提出的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654913/multi-level-modelling</guid>
      <pubDate>Wed, 25 Sep 2024 20:09:10 GMT</pubDate>
    </item>
    <item>
      <title>解释交叉表摘要</title>
      <link>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</link>
      <description><![CDATA[我正在生成一个简单的 2 x N 列联表，总结女性在 COVID-19 之前和期间/之后的就业状况。列代表两个时间段：1) COVID 之前和 2) COVID 期间/之后。
就业状况摘要如下：
就业状况 COVID 之前 COVID 期间/之后
缺失响应 41% 18.6%
失业（家庭主妇） 301 (8.8%) 443 (20%)
就业 1315 (49.9%) 1276 (61.4%)

数据显示，失业家庭主妇的百分比（从 COVID 之前的 8.8% 增加到 COVID 期间/之后的 20%）和就业女性的百分比（从 49.9% 增加到 61.4%）都有所增加。这似乎违反直觉，因为我们预计失业率上升与就业率下降同时发生。
我该如何解释这些结果？任何建议都非常感谢。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</guid>
      <pubDate>Wed, 25 Sep 2024 19:58:04 GMT</pubDate>
    </item>
    <item>
      <title>识别时间序列的平衡点</title>
      <link>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</link>
      <description><![CDATA[我正在对新产品发布进行分析，特别是新产品发布的生命周期是否随着时间的推移而发生变化。
我感兴趣的一个问题是，用于确定新产品何时达到平衡的统计方法。通常，对于每种新产品，我们都会看到最初的收入激增，最终达到某种平衡点。据我所知，大多数方法都需要知道平衡点是什么，而在这种情况下，我们不知道。
任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:27 GMT</pubDate>
    </item>
    <item>
      <title>RA Fisher（或“Fisherian”）如何选择样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</link>
      <description><![CDATA[正如许多其他 CV.SE 帖子（例如此处或此处）中所述，RA Fisher 和 Neyman &amp; Pearson 的统计假设检验框架在实践和解释上存在差异。
我很好奇他们在如何设计您的研究方面的差异。为了简单起见，我将重点关注样本量（但当然，功效和精度也会受到研究设计的其他方面的影响，例如阻塞等）。
在 N-P 框架下，一般方法对我来说很清楚：首先确定您想要的功效，您感兴趣的特定替代点假设 $H_A$（例如，就您想要检测的最小效应大小而言），以及您可以容忍的 I 类错误率 $\alpha$。从那里，您可以计算出实现 $\alpha$ 和 $H_A$ 所需功效所需的样本量。
但据我了解，在 Fisher 方法中，没有 $\alpha$、没有 $H_A$，也没有明确的功效计算。那么 Fisher 如何为自己的研究选择样本量？（或者他如何建议其他人规划样本量？）

我很好奇，尤其是因为 Fisher 确实写过“一个设计合理的实验”通常会产生较低的 p 值。

就我个人而言，作者更喜欢将显着性标准设定为 5%。点，并完全忽略所有未达到该水平的结果。只有当经过适当设计的实验很少失败时，科学事实才应被视为实验确定的。

-- Fisher, R. A. 田间实验的安排。《农业部期刊》，1926 年，33，第 504 页。
对我来说，这句 1926 年的引言（尤其是“很少失败”）听起来很像说精心设计的实验应该具有很高的功效：尽管他没有指定特定的$H_A$，但 Fisher 想象在相同的人群中重复使用相同设计的相同实验（尽管在这句话中，这些实验是否重复是假设的或应该实际执行的），并反复获得等于或低于 5% 显著性水平的结果。
如果 Fisher 同意设置显著性水平，并且 Fisher 也致力于实现高功效——那么他还能做什么来选择样本量来实现这些目标，同时又与 N-P 的整体方法有实质性的不同？
（当然，还有贝叶斯方法、似然法，也许还有其他非 Fisher 和非 NP 方法。但我特别想问的是，什么才算是 Fisher 但非 NP。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 SPSS 计算广义倾向得分</title>
      <link>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</link>
      <description><![CDATA[我正在为一项包含大量混杂变量的医学研究计算 Cox 回归。我已经计算了具有二进制值的变量的倾向得分，以调整混杂因素。但也有一些度量变量。为此，我需要计算广义倾向得分。我在互联网上进行了广泛搜索，但我只能找到我不理解的公式，没有实用指南。显然有不同的方法可以做到这一点。我不希望我的连续变量有子类。我了解到我必须为连续变量和可能的混杂因素计算线性回归。之后，应该计算残差的方差。但我不知道如何从那里继续。
有人知道如何在 SPSS 中计算 GPS 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</guid>
      <pubDate>Wed, 25 Sep 2024 16:21:34 GMT</pubDate>
    </item>
    <item>
      <title>用连续给定条件概率建模</title>
      <link>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</link>
      <description><![CDATA[我目前正在努力解决这个方程式
$$ p(x; \theta) = P(Y = 1 | X = x) $$
其中 $p$ 是右侧条件概率的模型。如果 $X$ 是连续随机变量，那么这个方程式肯定没有意义。我们是否简单地将 $X$ 视为离散变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</guid>
      <pubDate>Wed, 25 Sep 2024 16:19:27 GMT</pubDate>
    </item>
    <item>
      <title>应该用置信区间还是 t 检验来评估统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</link>
      <description><![CDATA[我对评估温差的统计显著性感兴趣。
为了这个目标，我生成了历史和未来时期的平均值的引导时间序列。
然后我遵循了两种方法：
A. 计算引导差异的 95% 置信区间，并认为零不在置信区间内的区域具有统计显著性。
B. 使用历史和未来引导均值之间的配对 t 检验 (scipy.stats.ttest_rel) 来计算 p 值，并认为 p 值低于 .05 的区域具有统计显著性
以下哪个选项是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</guid>
      <pubDate>Wed, 25 Sep 2024 15:15:05 GMT</pubDate>
    </item>
    <item>
      <title>bfastlite 函数的参数调整</title>
      <link>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</link>
      <description><![CDATA[我正在使用 bfast 包的 bfastlite() 函数来运行时间序列 (ts) 分析。我从作者的论文（表 2）中引用：

需要调整参数来优化性能，不区分季节性和趋势的中断

到目前为止，我一直在手动微调模型，也就是说，我一个接一个地更改参数，这很耗时。有人对模型的微调有更好的解决方案吗？
为了查看模型的哪些参数可以实现最佳结果，我检查了检测到的断点中的日期（目视检查）。
library(bfast)

plot(simts) # 包含模拟 NDVI 时间序列的 stl 对象
datats &lt;- ts(rowSums(simts$time.series))
# 所有组件的总和（季节、突变、剩余）
tsp(datats) &lt;- tsp(simts$time.series) # 分配正确的时间序列属性
plot(datats)

# 检测断点。默认参数
bp = bfastlite(datats)
plot(bp)

# 优化模型 ??????
bp_opt &lt;- bfastlite()

R 4.4.1，bfast 1.6.1，Windows 11。]]></description>
      <guid>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</guid>
      <pubDate>Wed, 25 Sep 2024 14:48:51 GMT</pubDate>
    </item>
    <item>
      <title>球体上的采样角度：从广义协方差矩阵到浓度参数</title>
      <link>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</link>
      <description><![CDATA[我正在尝试使用 Python 提取球体上的点。
我必须在天空中定位事件并使用 healpy 生成地图。
在测试期间，我使用了 von Mises-Fisher，因为我假设 $\theta$ 的方差与 $\phi$ 的方差相同。一切运行良好，我能够通过使用 $\kappa=1/\sigma^2$ 获得浓度参数 $\kappa$。
我用于评估像素中概率的函数是
def Mises_Fisher(theta,phi,DS_theta,DS_phi,conc):
meanvec=hp.ang2vec(DS_theta,DS_phi)
meanvec=np.asarray(meanvec,dtype=np.float128)
norm=np.sqrt(np.dot(meanvec,meanvec))
meanvec=meanvec/norm

var=hp.ang2vec(theta,phi)
var=np.asarray(var,dtype=np.float128)
norm=np.sqrt(np.dot(var,var))
var=var/norm

factor=np.dot(conc*var,meanvec)
factor=np.float128(factor)
#归一化是徒劳的，我们将除以总和
#fullnorm=conc/(2*np.pi*(np.exp(conc)-np.exp(-conc)))
ret=np.float128(np.exp(factor))#/fullnorm
#ret=factor
return ret

然后，对于 healpy 图中的每个像素，我可以分配一个概率。
现在我有一个不再各向同性的协方差矩阵，在这种情况下，我如何在球体上生成点？我知道Kent 分布的存在，但我没有所需的数量，例如$\gamma$、$\beta$ 和 $\kappa$。我不知道是否有办法根据协方差矩阵获得这些。
为了进一步复杂化问题，矩阵是 11 维的，但我只需要投影到 (distance,$\theta$,$\phi$) 空间，然后生成地图。
现在我尝试从多元高斯中提取，但由于高斯在切平面上，对于某些方差，分布产生的角度超出了 $\theta$ 和 $\phi$ 的范围。
这是我用来提取点的代码
num_samples = 10**7
samples = np.random.multivariate_normal(perm_mean, perm_cov, num_samples)

phi = samples[:, 2]
theta = samples[:, 1]
print(np.min(theta),np.max(theta))
print(np.min(phi),np.max(phi))
print(&#39;starting mean values&#39;)
print(&#39;theta={}, phi={}&#39;.format(perm_mean[1],perm_mean[2]))

关键是，对于某些矩阵，方差使得角度可以超出范围。我无法对矩阵采取行动，这些矩阵是由其他一些代码提供给我的，应被视为固定数据。
提前感谢大家！
*编辑
在这里我澄清一下，使我的陈述更加严格。
因此，矩阵是另一段代码给我的协方差矩阵，我无法更改。我必须评估引力波 (GW) 事件的天空定位。在我的例子中，这意味着将包括天空位置在内的 11 个参数提供给程序，并且此代码会返回一个协方差矩阵。对于这个问题的范围，该程序可以被视为一个黑匣子，因为我无法修改那里的任何东西。
现在我可以从这个矩阵中采样并获得 $\theta$ 和 $\phi$，即天空位置。
让我们以单位球体为中心，表面上的每个点都由指向引力波事件天空坐标的向量标识。我们现在可以忘记其他参数。
如果事件定位良好，这意味着如果角度的变化“很小”，我们可以想象建立一个与天空相切的平面，法向量沿径向，从引力波位置开始。现在，如果我们对高斯分布进行采样，该分布的参数为 $\mu$ 和 $\Sigma$，其中 $\mu$ 为 11 个起始参数给出的均值向量，$\Sigma$ 为 cov 矩阵，我们可以获得 $\theta$ 和 $\phi$ 的样本。这种方法效果很好，但是一旦方差足够大，我们开始“感觉”我们在球体上而不是在平面上，这种方法就会失效。解决这个问题的分布是 Kent 分布。我的问题是
给定一个均值向量$\mu$和一个协方差矩阵$\Sigma$，是否可以构造肯特分布中所需的必要量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</guid>
      <pubDate>Wed, 25 Sep 2024 13:00:09 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>一般时间序列模型估计量的渐近性质</title>
      <link>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</link>
      <description><![CDATA[我的问题涉及时间序列分析中估计量的渐近性质。特别是，我对时间序列（不是 ARMA 时间序列）的估计量的行为感兴趣。因此，让 $(Y_t)_{t \in I \subset \mathbb{N}}$ 成为单变量时间序列。我们可以假设时间序列遵循以下形式的更新方程：
$Y_t = g(Y_{t-1}, ..., Y_{t-p}, f(\epsilon_{t-1}, ..., \epsilon_{t-q}), \epsilon_t)$
其中 $\epsilon_t$ 是 $iid$ 创新，其中 $\epsilon_t \sim (0, \sigma^2)$。 $f(\epsilon_{t-1}, ..., \epsilon_{t-q})$ 是某种类似于移动平均的部分，用于使时间序列具有衰减的自相关性（而不是截止）。$g$ 是处理自相关的函数。请注意，对于特殊选择，其中 $g$ 和 $f$ 是线性函数，我们得到经典的 ARMA 模型。我们可以假设 $g$ 由参数 $\phi$ 参数化，而 $f$ 由参数 $\theta$ 参数化。我感兴趣的是足以满足 $\phi$ 和 $\theta$ 的 MLE 估计量的一致性和渐近正态性的条件。在几篇论文中（对函数 $g$ 和 $f$ 做出特殊选择），我遇到了平稳性和混合条件。但是，我想知道这些条件是否足以满足我在此处给出的相当通用的模型。
任何有关论文/书籍/网站等的提示都将不胜感激。当然，直接回答也很好 :D。]]></description>
      <guid>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:48 GMT</pubDate>
    </item>
    <item>
      <title>从多个分布中提取的一个数据集</title>
      <link>https://stats.stackexchange.com/questions/654863/one-data-set-drawn-from-multiple-distributions</link>
      <description><![CDATA[我不清楚如何拟合至少从视觉上看是从多个分布中提取的数据集。
我尝试使用 GaussianMixture，但结果看起来并不令人信服。我不擅长统计，也不想争辩说它是错误的，但这不是我所期望的。代码在这里：
import numpy as np
from pylab import *
from sklearn.mixture import GaussianMixture
from pylab import concatenate, normal
import pandas as ps

from scipy.stats import norm

df = ps.read_csv(&#39;Book6.csv&#39;)
multimodal_dist = df.E.to_numpy()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

components = 2

gm = GaussianMixture(n_components=components)
gm.fit(multimodal_dist.reshape(-1, 1))

means = gm.means_
standard_deviations = gm.covariances_**0.5 
weights = gm.weights_ 

new_X = np.linspace(min(multimodal_dist), max(multimodal_dist), 100)

对于 zip(means, standard_deviations, weights) 中的平均值、标准差、权重：
print(weight,mean, std)
pdf = 2*weight * norm.pdf(new_X, mean, std)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

pdf_full = np.zeros(len(new_X))
对于范围(components) 中的 i：
pdf_full = pdf_full + weights[i] * norm.pdf(new_X, means[i], standard_deviations[i])

plt.plot(new_X.reshape(100,1), 2*pdf_full.reshape(-1, 1))

plt.show()

我根据 GaussianMixture 拟合系数生成的图是

整体曲线确实看起来正确，但底层分布不是我所期望的。
我期望的图是手动拟合的，没有统计支持，但我认为，应该是这样的：

我的期望是错误的，还是我没有使用好的方法，或者误用了它们？首先，在这两种情况下，我的标准化都是手动完成的。我不明白如何标准化我的拟合以匹配分布。
数据在这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654863/one-data-set-drawn-from-multiple-distributions</guid>
      <pubDate>Tue, 24 Sep 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>检验统计量适中，但 F 检验的 p 值较低</title>
      <link>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</link>
      <description><![CDATA[我正在 R 中对模拟数据运行多元回归。样本大小为 100。有一个相关回归量和 18 个不相关回归量。我正在使用 Newey-West 协方差矩阵测试 18 个不相关回归量的联合显著性。
谜题 1：我发现 18 个不相关回归量具有高度统计显著性。
谜题 2：我在 18 自由度下获得了 6.8814 的检验统计量，这对我来说似乎是适中的（在 F(18, 80) 分布的右尾不远），那么这怎么会产生非常低的 p 值 4.5e-10？
我能够解决谜题 1。显然，Newey-West 是问题所在。使用 vanilla 协方差矩阵，结果更加合理。但是，我仍然对谜题 2感到困惑，而这是我的问题。
library(car)
library(sandwich)

m &lt;- 20
n &lt;- 100
set.seed(9999)
x &lt;- rnorm(m * n)
X &lt;- matrix(x, ncol = m)
X[, 2] &lt;- X[, 1] + X[, 2]
# 现在，第二列是第一列 + 一些噪音，
# 而所有其他列都是纯噪音。
# 因此，如果我们尝试预测第一列，那么只有第二列应该有用。
m1 &lt;- lm(X[, 1] ~ X[, -1])
(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;,
vcov. = NeweyWest(m1)
))

结果：
线性假设检验

假设：

模型 1：受限模型

模型 2：X[, 1] ~ X[, -1]

注意：提供系数协方差矩阵。

Res.Df Df F Pr(&gt;F) 
1 98 
2 80 18 6.8814 4.494e-10 ***

不使用 Newey-West：

(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;
))

结果：
线性假设检验

假设：

模型 1：受限模型
模型 2：X[, 1] ~ X[, -1]

Res.Df RSS Df Sq F 之和Pr(&gt;F)
1 98 38.856 
2 80 31.982 18 6.8739 0.9552 0.5178

编辑：感谢 Lukas Lohse 的精彩评论。当非正式地评估检验统计量的大小时，我考虑的是 $\chi^2$ 对 $F$ 分布的近似，但忘记了必须将 $F$ 值乘以分子自由度（此处为 18）才能得到相应的 $\chi^2$ 统计量... 好的，因此，我们现在有了新的 谜题 3，而不是 谜题 2：为什么使用 Newey-West 的检验使用 6.8 作为 $F$ 统计量，而使用普通方差估计量的检验使用平方和。]]></description>
      <guid>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</guid>
      <pubDate>Tue, 24 Sep 2024 15:26:30 GMT</pubDate>
    </item>
    </channel>
</rss>