<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 08 Mar 2024 09:13:17 GMT</lastBuildDate>
    <item>
      <title>如何绘制和解释基于分割的目标检测模型的 ROC 曲线？</title>
      <link>https://stats.stackexchange.com/questions/642128/how-to-plot-and-interpret-the-roc-curve-for-segmentation-based-object-detection</link>
      <description><![CDATA[我正在尝试绘制许多目标/物体检测模型的 ROC 曲线并比较它们的性能。所讨论的预训练模型采用输入图像，并输出每个像素为白色或黑色的掩模图像。我修改了这些模型的代码，以便在模型决定每个像素是白色还是黑色（1 或 0）之前，我应用 100 点阈值（[0.00, 1.00] 之间的值）并相应地获得 100 组掩模，然后我根据应用阈值的结果计算 TP、TN、FP、FN、TPR 和 FPR，其中我设置另一个阈值（如半径）来判断掩模中每个白色斑点的中心是否位于圆形区域内地面实况坐标。因此，在获得 100 组 TPR 和 FPR 对后，我绘制了 ROC 曲线，但曲线的特征似乎有点偏离。我认为这里存在逻辑问题，我需要一些建议。我所知道的是，TPR 峰值会稍微下降，因为随着阈值变松，相应掩模中的白色斑点会变大，因此它们的中心会发生移动，从而导致错误的预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/642128/how-to-plot-and-interpret-the-roc-curve-for-segmentation-based-object-detection</guid>
      <pubDate>Fri, 08 Mar 2024 08:19:29 GMT</pubDate>
    </item>
    <item>
      <title>如果任何东西都适合单样本 t 检验怎么办？</title>
      <link>https://stats.stackexchange.com/questions/642127/what-if-anything-is-being-fit-in-a-one-sample-t-test</link>
      <description><![CDATA[我正在重新审视一些涉及 t 检验和方差分析的基本概念，但很早就被绊倒了。我想将 缺乏拟合平方和 的概念应用于单样本 t 检验，但想知道如何将其视为普通 LS 问题 ，如果有的话。在线性最小二乘中，有可调整的拟合参数和最小化的误差平方和。拟合结果明显满足的一个条件是
$$\sum_i \epsilon_i =\sum_i (y_i-\hat{y_i})=0 $$
其中 $\epsilon_i$ 是与响应变量 $y_i$ 和模型之间的差异相关的错误$\hat{y_i}$。
然后，当将 SSE 划分为纯误差和回归项，然后用于计算比率检验（t 或更普遍的 F 检验）所基于的比率。至少这就是我理解这些概念之间联系的方式（例如在此 Wikipedia 页面中概述） .
然而，在单个或两个样本 t 检验中，根本没有可调整的参数，因为我们规定了一个刚性模型（假设总体均值或均值差等于固定值）。如何证明误差之和等于 0，证明平方和的划分合理？这对于显示与最小二乘法的联系似乎至关重要，或者也许不是？也许一个初步的问题是，如果任何东西都适合单样本 t 检验怎么办？
我意识到有相关 问题我正在经历其中一些，但我猜我的问题有很大不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/642127/what-if-anything-is-being-fit-in-a-one-sample-t-test</guid>
      <pubDate>Fri, 08 Mar 2024 08:19:00 GMT</pubDate>
    </item>
    <item>
      <title>违反广义加性模型 (GAM) 中的假设</title>
      <link>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</guid>
      <pubDate>Fri, 08 Mar 2024 07:53:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解释二阶多元增长模型？</title>
      <link>https://stats.stackexchange.com/questions/642124/how-do-i-interpret-a-second-order-multi-variate-growth-model</link>
      <description><![CDATA[我正在运行一个多变量二阶增长模型。
我有两个因素，它们在概念上是相互关联的，在 7 个不同的场合进行了测量。
为了了解这两个因素如何随着时间的推移一起发展，我运行了一个多元变量
两个因素的增长曲线。
当我第一次运行模型时，模型拟合度不好。
为了重新指定模型，我在一阶因子之间添加了协方差。
（所以不属于二阶增长因素，这些因素从第一次运行就已经存在了。
我将时间 1 因子 A 与时间 1 因子 B 协变，并且所有时间点都相同）
模型拟合度得到改善，拟合度现在可以接受。
我的问题是，这种重新规范的解释是什么？
根据我的理解，一阶因子的协方差反映在
二阶增长因子如截距和斜率。由于它们之间已经存在协方差，那么一阶因子之间的协方差到底是多少？
感谢任何帮助我加深对此理解的人。]]></description>
      <guid>https://stats.stackexchange.com/questions/642124/how-do-i-interpret-a-second-order-multi-variate-growth-model</guid>
      <pubDate>Fri, 08 Mar 2024 07:47:41 GMT</pubDate>
    </item>
    <item>
      <title>KL 散度的期望仅作为概率的对数比</title>
      <link>https://stats.stackexchange.com/questions/642122/expectation-of-kl-divergence-only-as-the-log-ratio-of-the-probabilities</link>
      <description><![CDATA[在 DPO 论文中，特别是在下面所附的证明中，我们如何扩展KL 散度仅作为两个分布的概率的对数比？

根据定义，日志还应该乘以 $\pi(y|x)$ 项。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642122/expectation-of-kl-divergence-only-as-the-log-ratio-of-the-probabilities</guid>
      <pubDate>Fri, 08 Mar 2024 07:28:33 GMT</pubDate>
    </item>
    <item>
      <title>大数定律与布朗运动之间的联系</title>
      <link>https://stats.stackexchange.com/questions/642120/connection-between-law-of-large-numbers-and-brownian-motion</link>
      <description><![CDATA[我正在尝试理解维纳过程的二次变分公式：
$$\lim_{n \to \infty} \sum_{i=1}^{n} (W_{t_{i+1}} - W_{t_i} )^2 = E\left[\sum_{i=1}^{n} (W_{t_{i+1}} - W_{t_i})^2\right]$$
我无法理解无限总和的极限如何等于有限期望的总和。
可以用大数定律来证明这一点吗？
例如：设 $X_1, X_2, \ldots, X_n$ 是一系列独立且同分布的随机变量，每个变量都有有限的期望值$E[X_i] = \mu$。大数定律指出：
$$\lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^{n} X_i = E(X_i) = \mu$$
正如我们所见，LLN 将无限和的极限与期望联系起来。
LLN 是关于简单求和，而不是平方差和。但它还能用来说明为什么无限和的极限可以等于有限期望的和吗？一般来说，我们可以用什么来证明为什么这个无限总和等于有限期望？]]></description>
      <guid>https://stats.stackexchange.com/questions/642120/connection-between-law-of-large-numbers-and-brownian-motion</guid>
      <pubDate>Fri, 08 Mar 2024 06:57:36 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中对冗余分组数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/642117/modeling-redundant-grouped-data-in-linear-regression</link>
      <description><![CDATA[我开始对另一个词汇数据库进行验证性分析，但在对回归进行建模之前，我意识到我在 OSF 上预先注册的模型可能存在潜在问题。作为参考，我的先验指定模型很简单，它指定了两个主要效果以及它们之间的相互作用：
$$
\text{频率} = \beta_0 + \beta_1 \text{复杂度} + \beta_2 \text{脚本} + \beta_3 \text{复杂度} \times \text{脚本} + \epsilon
$$
其中“频率”是指“频率”。是字符频率，复杂性是字符的视觉复杂性，脚本是简体字或繁体字。因此，我们有一个数字 DV、一个数字 IV 和一个两级分类变量。对脚本争论不休的原因是传统脚本通常更复杂。作为示例，表示“身体”的词可以是“body”。是繁体字“身体”和简体字“身体”。
然而，我没有深入考虑的主要问题是，众所周知，两个脚本也共享许多相同的角色。作为示例，表示“你”的词可以是“你”。是你吗，有简体字和繁体字两种形式。这不是一个小问题，因为两个脚本之间可能有数百甚至数千个共享字符。由于这个问题，这些字符的复杂度和频率将完全相同，这在数据集中将是高度冗余的。
我的问题是如何对此类数据进行建模？我的想法是，按照我最初考虑的方式进行建模意味着两个脚本之间的几个观察结果将完全相同，但我不完全确定是否合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/642117/modeling-redundant-grouped-data-in-linear-regression</guid>
      <pubDate>Fri, 08 Mar 2024 05:06:51 GMT</pubDate>
    </item>
    <item>
      <title>是什么困扰着统计学家晚上？</title>
      <link>https://stats.stackexchange.com/questions/642115/what-haunts-statisticians-at-night</link>
      <description><![CDATA[我在 YouTube 上观看了这段名为“夜间困扰统计学家的事情”的视频：https://www.youtube.com/watch?v=SGGLkrJa9_w
@12:01，他们展示了一个带有混杂因素的回归模型示例：
$$Y = B_0 + B_1 X + B_2 C + \epsilon$$
我想知道，你如何估计上面等式中的$C$？是否可以使用 $C$ 编写标准 OLS 或 MLE 方程，并将 $C$ 估计为如果是 beta 回归系数？
在视频中，他们指出了这一点并表示“收集尽可能多的数据并将其粘贴到模型中并不是一个好主意”。对我来说，这就像写作（其中 $X_2$ 是与混杂因素相对应的变量，例如视频示例中的朋友或没有朋友）：
$$Y = B_0 + B_1 X_1 + B_2 X_2 + \epsilon$$
因此，如何在第一个方程中估计 $C$ ？您还能使用 OLS 和 MLE 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642115/what-haunts-statisticians-at-night</guid>
      <pubDate>Fri, 08 Mar 2024 02:24:54 GMT</pubDate>
    </item>
    <item>
      <title>如何从$E[X^n]$求概率？</title>
      <link>https://stats.stackexchange.com/questions/642113/how-to-find-probability-from-exn</link>
      <description><![CDATA[已知 $E[X^n] = \frac{2}{5}(-1)^n + \frac{2^{n+1} }{5}+\frac{1}{5}$，其中 $n=1,2,3,\ldots.$
我需要找到 $P(|X-\frac{1}{2}| &gt; 1)$。
我的方法是：
我打开了模不等式，并将该概率等同于 $1-P(\frac{-1}{2}。这只有在 X=0 且 X=1 时才会发生，所以这就是我需要找到的。所以，我想我可以使用期望并扩展它来找到 MGF，即 $
M_x(t) = \sum_{n=1}^{\infty} \frac{t^n}{n!}E(X^n).$
然后用它直接从我获得的总和中找到 PMF，或相应的概率。
但是，我被困在这里，无法继续。我的做法有错吗？如果不是，那么我应该如何进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/642113/how-to-find-probability-from-exn</guid>
      <pubDate>Fri, 08 Mar 2024 02:07:19 GMT</pubDate>
    </item>
    <item>
      <title>校准图的 Y 轴：每个 X 的发生率与风险百分比</title>
      <link>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</link>
      <description><![CDATA[我正在考虑通过在 x 轴上绘制风险的第 10 个百分位数与每 100,000 的发生率来显示 cox 比例风险模型的校准有多么错误。对于 x 中的每个 bin，我可以绘制预测发生率和观察到发生率的数据点，以比较它们每 100,000 人的发生率。然而，在文献中似乎更常见的是绘制风险百分比（或经历过该事件的百分比），以便您获得一个很好的 45 度角（理想模型）进行比较。
哪个是更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</guid>
      <pubDate>Fri, 08 Mar 2024 01:18:00 GMT</pubDate>
    </item>
    <item>
      <title>按患者进行随机森林交叉验证</title>
      <link>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</link>
      <description><![CDATA[我有一个包含 10 名患者和 10 名对照者的各种特征的数据集。每个患者都有很多数据点。
当使用随机 70%-30% 训练测试分割或 10 K 折叠交叉验证时，随机森林在预测数据点是来自患者还是来自对照方面表现出色。
然后我意识到这是因为部分训练数据和测试数据重叠。也就是说，训练集中的一些数据点来自患者A，当然用这个模型来预测患者A自己的数据时，它是非常准确的。
我尝试按患者拆分数据并使用“LOOCV”，每次留下一名患者作为测试集。但是，当我这样做时，随机森林模型无法运行，因为在测试集中只有一个类别（即“患者”，并且没有“对照”）。
我使用R
rftrain &lt;- randomForest(group ~ person_id + 许多其他功能，
                    数据 = 火车，localImp = TRUE）

# 使用测试数据进行 Pyellowictive 模型评估
混乱 &lt;- 混乱矩阵（预测（rftrain，测试），测试$组，阳性=“患者”）
困惑

是否有更好的包或更好的方法来进行此评估？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</guid>
      <pubDate>Fri, 08 Mar 2024 00:49:13 GMT</pubDate>
    </item>
    <item>
      <title>Prophet 算法是否需要假期的历史数据来预测未来的假期？</title>
      <link>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</link>
      <description><![CDATA[我计划使用 Prophet 算法进行预测，因为它似乎非常适合季节性数据。
我正在专门阅读这篇有关假期影响的文章 https:/ /facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html
我想使用holidays来确保模型针对假期进行调整。
我的问题：我需要提供包含假期的历史数据吗？
例如，如果我的训练数据来自 2023 年 10 月至 12 月，我想对 1 月进行预测并确保针对 2024 年 1 月 3 日的年度假期进行调整。考虑到没有 2023 年 1 月的训练数据，这是否可能2023 年 1 月 3 日？
如果有人可以帮助我理解这一点 - 我将非常感激！谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</guid>
      <pubDate>Thu, 07 Mar 2024 21:57:02 GMT</pubDate>
    </item>
    <item>
      <title>应该使用什么方法来比较不同GAM的拟合度？</title>
      <link>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</link>
      <description><![CDATA[我正在构建以下形式的 GAM（使用 R 的 mgcv 表示法），并希望比较每个模型之间的拟合度。
model1 &lt;- gam(dependent_var ~ metric +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)
model2 &lt;- gam(dependent_var ~ metric2 +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)

我通常会考虑使用 AIC 或 LRT 来比较拟合度，但请注意，模型之间的差异仅是 metric 和 metric2，即模型是不是彼此的截断版本。
我考虑过的另一个选择是构建训练和测试数据集，并比较测试数据集中的残差总和以比较拟合度。是否有正确的方法来使用两个未截断的 GAM 来比较拟合度？]]></description>
      <guid>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</guid>
      <pubDate>Thu, 07 Mar 2024 21:43:44 GMT</pubDate>
    </item>
    <item>
      <title>$E(XY)$ 表示截断的二元正态分布</title>
      <link>https://stats.stackexchange.com/questions/642094/exy-for-a-truncated-bivariate-normal</link>
      <description><![CDATA[如果 $(X, Y)$ 遵循均值 ${\bf \mu}$ 的二元高斯分布 和带有截断边界的协方差 ${\bf \Sigma}$ $(a_x, b_x, a_y, b_y )$，我们可以以封闭形式计算 $E(XY)$ 吗？如果没有，我们可以快速有效地计算/估计它吗？
就上下文而言，我需要进行数千（或更多）这些积分，因此我希望能够比通过（例如）蒙特卡罗更快地计算这些积分。]]></description>
      <guid>https://stats.stackexchange.com/questions/642094/exy-for-a-truncated-bivariate-normal</guid>
      <pubDate>Thu, 07 Mar 2024 19:04:44 GMT</pubDate>
    </item>
    <item>
      <title>剂量反应函数估计何时比简单回归更有效？</title>
      <link>https://stats.stackexchange.com/questions/642091/when-does-dose-response-function-estimation-work-better-than-simple-regression</link>
      <description><![CDATA[最近有人问我，剂量反应函数 (DRF) 估计（如 此链接 和 本文）和统计回归方法。因此，我尝试创建一些玩具综合示例，以展示回归方法无法估计治疗影响的某些情况，而 DRF 估计具有这种能力。但我没能找到。
特别是，我创建了此笔记本来测试这两者引用了与线性回归 (LR) 进行比较的方法，并发现以下结果：

在无混杂且没有碰撞器的场景中，没有什么比回归更准确
DRF 估算方法存在偏差/不如我预期的准确
如果我在分析中包含对撞机，将其混淆为混杂因素，那么 DRF 估计方法（仍然有偏差，但更）比 LR 更稳健

鉴于这些发现，我有几个问题。

如果在没有碰撞器的场景中传统回归方法效果更好，那么使用这些方法有什么意义？ （当然，如果用户认为不会出现这种情况，他/她可以执行分析来删除碰撞器）
是否存在 DRF 估计方法比回归方法偏差更小的情况？

欢迎下载并使用我的笔记本，其他一些笔记本示例将不胜感激，谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/642091/when-does-dose-response-function-estimation-work-better-than-simple-regression</guid>
      <pubDate>Thu, 07 Mar 2024 18:31:09 GMT</pubDate>
    </item>
    </channel>
</rss>