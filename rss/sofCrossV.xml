<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 03:17:25 GMT</lastBuildDate>
    <item>
      <title>策略梯度方法中的目标函数是否正是期望值函数？</title>
      <link>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</link>
      <description><![CDATA[
我正在阅读 DRL 中的 Spinning Up。我想知道策略梯度算法中的目标 $J_\theta$ 是否正是期望值函数 $E_{s_0}[V^\pi(s_0)]$。我从未见过有人将目标写为 V，但我觉得它们是一样的。有人可以证实这一点吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</guid>
      <pubDate>Sun, 07 Jul 2024 02:45:34 GMT</pubDate>
    </item>
    <item>
      <title>如何估计用于训练和推理的 GPU 内存、数据要求以及大型语言模型的训练时间？</title>
      <link>https://stats.stackexchange.com/questions/650614/how-to-estimate-gpu-memory-for-training-and-inference-data-requirements-and-tr</link>
      <description><![CDATA[今天面试 ML 工程师时遇到这个问题，当时答得不是很完美，理想情况下应该怎么回答？
假设我们有 Transformer、BERT、GPT 等模型，每个模型有 x 亿个参数，参数为 FP32 精度。

GPU 内存要求：

如果使用 Adam 作为优化器，训练（考虑激活、优化器状态，​​如动量等）和推理（考虑 KV Cache 等）需要多少 GPU 内存？
请提供 x = 7B 和 x = 70B 的具体值，至少需要多少个 H100 GPU 才能满足内存需求？ （H100 80GB 内存）


数据要求：

如果您的经理为您分配此任务，您需要多少文本训练数据（TB）来确保 x 亿参数模型收敛？
请提供 x = 7B 和 x = 70B 的具体值。


训练时间：

如果您的经理希望使用上述数量的训练数据在一个月（30 天）内完成训练，您需要多少个 H100 GPU？
考虑 H100 规格（FP32 67 TFLOPS，带宽 ~ 3TB/s）和并行效率（加速）适用于多个 GPU。


]]></description>
      <guid>https://stats.stackexchange.com/questions/650614/how-to-estimate-gpu-memory-for-training-and-inference-data-requirements-and-tr</guid>
      <pubDate>Sun, 07 Jul 2024 01:51:13 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 GMM 估计</title>
      <link>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</link>
      <description><![CDATA[我正在尝试执行 GMM 估计，但在 R 中。在我的上下文中，我做了几个协方差限制。举一个简单的例子：$Var(y)=a$ 和 $Cov(y, Ly))=b$。现在的问题是，对于任何给定的数据集，可以制作这些样本等价物的观察次数对于两个矩将有所不同 () 通常，STATA 和 R 都会采用样本矩矩阵并通过除以 1/NT 或 1/N(T-1) 来找到平均值，但在这种情况下，这将不起作用！但是，在 STATA 中，可以使用 nocommonsample 选项来解决这个问题。我的问题是，R 中可用的等效选项或方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</guid>
      <pubDate>Sat, 06 Jul 2024 23:46:26 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 AR(p) 模型无法拟合数据</title>
      <link>https://stats.stackexchange.com/questions/650609/arp-model-in-r-not-fitting-data</link>
      <description><![CDATA[我有一组数据，我正尝试用一个简单的 AR(p) 模型来建模。我已经对单位根平稳性进行了 Dickey Fuller 检验并拒绝了零假设。
但是，当我在 R 中运行一个简单的 ar 命令时，我似乎得到了一个只有截距的模型。我不知道这是为什么，希望有人能给出一些建议。代码如下。
数据和 R 代码如下：
data &lt;- c(-2.93, -1.86, 0.45, -1.07, 5.92, 3.90, 1.28, -0.13, 1.33, 
2.05, 17.69, -16.59, -3.84, -5.67, 4.76, -0.58, 1.06, 
-0.63, 3.21, 1.06, -4.25, -6.24, -2.33, -6.64, 
-4.56, -5.83, -1.99, 3.10, 7.82, 1.99, 4.42, -1.22, -7.52, 
4.37, -3.24, -0.37, -2.77, -0.72, 0.10, -3.78, 1.35, -1.48, 
-3.66, -1.87, -1.98, -2.39, -0.06, -0.16, 0.97, 3.79, 0.10, 
-3.94, -2.00, 14.47, 5.29, -1.59, 6.86, -2.38, -9.99, -1.29, 
-0.44, -4.45, 1.37, 6.36, 3.43, -0.60, 7.55, 5.34, -7.85, 
8.52, 5.34, -13.36, 4.64, -0.61, 2.96, 4.90, 10.89, -7.19, 
-2.16, -0.63, -6.03, -10.62, -7.78, -4.33, -3.55, -3.47, 
1.64, -1.85, -2.88, 0.78, 12.39, -5.90)

time_series_data &lt;- ts(data, start = c(2012, 5), frequency = 12)

ar_model &lt;- ar(time_series_data, order.max = 3)

summary(ar_model)

残差 &lt;- ar_model$resid

fitted_values &lt;- time_series_data -残差

打印（fitted_values）

一月 二月 三月 四月 五月 六月 七月 八月 九月 十月
2012 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2013 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2014 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
-0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2015 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2016 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2017 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2018 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2019 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
十一月 十二月
2012 -0.3021739 -0.3021739
2013 -0.3021739 -0.3021739
2014 -0.3021739 -0.3021739
2015 -0.3021739 -0.3021739
2016 -0.3021739 -0.3021739
2017 -0.3021739 -0.3021739
2018 -0.3021739 -0.3021739
2019 -0.3021739 -0.3021739 
]]></description>
      <guid>https://stats.stackexchange.com/questions/650609/arp-model-in-r-not-fitting-data</guid>
      <pubDate>Sat, 06 Jul 2024 23:01:46 GMT</pubDate>
    </item>
    <item>
      <title>估计在移动应用程序中发现新的可访问性问题的可能性</title>
      <link>https://stats.stackexchange.com/questions/650608/estimating-the-likelihood-of-finding-new-accessibility-issues-in-mobile-applicat</link>
      <description><![CDATA[我设计了一种算法，用于识别移动应用程序中的可访问性问题。该算法本身存在一些错误（问题），我的目标是在给定置信区间的情况下，预测在测试其他移动应用程序时发现该算法新问题的可能性。本质上，我需要确定是否需要测试 5 个或 5000 个应用程序才能实现可靠的算法。
问题背景：

移动应用程序总数：1,000,000（类似于一个装有 1,000,000 个不同颜色弹珠的桶）。
测试的应用程序：Y（类似于从桶中挑选 Y 个弹珠）。
发现的不同问题：Z（类似于在挑选的弹珠中找到 Z 种不同颜色）。

问题背景：

发现新问题的可能性：如何计算在挑选 Y 个弹珠后，我找到至少 X 种不同颜色弹珠的可能性（99%）信心？
总问题预测：挑选 Y 颗弹珠并识别 Z 种不同颜色后，如何预测桶中不同颜色的总数？此预测的相关信心是多少？

我的研究
我已探索捕获-重新捕获模型和超几何分布作为潜在解决方案。我很乐意找到适合用于此问题的模型，以及有关该模型的视频的任何建议。
感谢您的指导！]]></description>
      <guid>https://stats.stackexchange.com/questions/650608/estimating-the-likelihood-of-finding-new-accessibility-issues-in-mobile-applicat</guid>
      <pubDate>Sat, 06 Jul 2024 22:34:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么具有随机效应的动态面板数据模型会根据 R 包（plm 与 lme4）产生不同的效果？</title>
      <link>https://stats.stackexchange.com/questions/650607/why-do-dynamic-panel-data-models-with-random-effects-yield-different-effects-dep</link>
      <description><![CDATA[我正在比较 R 包 plm 和 lme4 的结果，估计动态面板的形式为
$$y_{it} = \alpha_i + \theta y_{it-1} + x_{it}\beta + \epsilon_{it}$$
其中 $\alpha_i$ 为随机效应，并应用通常的假设（例如，参见 Wooldridge 2002 第 677 页）。
如果我有一个包含两个预测变量 x1 和 x2 的数据集，并且单位由变量 id 索引，则该模型将在 lme4 中估计
lmer(y~ lag_y + x1 + x2 + (1|id), data = my_data)

在 plm 中也是如此
plm(y ~ lag_y + x1 + x2, index = &quot;id&quot;, model = &quot;random&quot;, data = my_data)

结果不同，我不明白为什么。我知道它们使用了不同的似然性，但我没想到 lme4 接近恢复参数而 plm 没有。我以为我会找到类似的结果，但我没有。为什么？
如果您想尝试，这里有可重现的代码：
library(lme4)
library(plm)

gen_one_unit = function(TT, theta = 0.7, beta = c(0.5, -1), s = 1){
# 此函数为一个“单元”生成观测值面板
x1 = runif(TT) - .5
x2 = runif(TT) - .5
alpha_i = sample(seq(-2, 2, by = .5), size = 1) # 任意 
y = rep(1, TT) # 初始化
for(t in 2:TT){
y[t] = alpha_i + theta*y[t-1] +
beta[1]*x1[t] + beta[2]*x2[t] + rnorm(1, 0, s)
}
ind_df = data.frame(alpha_i = rep(alpha_i, TT), x1, x2,
y, lagy = c(NA,y[1:(TT-1)]))
return(ind_df) 
}

H = 50 # 单位数
TT = 20 # 时间段数

dyn_linear_list = list()
for(i in 1:H){
temp_df = gen_one_unit(TT = TT, theta= .5)
temp_df$id = rep(i, TT)
dyn_linear_list[[i]] = temp_df
}

dyn_df = do.call(rbind, dyn_linear_list)
dyn_df = dyn_df[!is.na(dyn_df$lagy),] # 去掉第一个 obs
reg_plm = plm(y ~ x1 + x2 + lagy,
model = &quot;random&quot;, index = &quot;id&quot;,
data = dyn_df)
reg_lme = lmer(y ~ x1 + x2 + lagy + (1|id),
data = dyn_df)

summary(reg_plm) # 查看系数lagy
summary(reg_lme) # 查看 lagy 的系数
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650607/why-do-dynamic-panel-data-models-with-random-effects-yield-different-effects-dep</guid>
      <pubDate>Sat, 06 Jul 2024 22:14:17 GMT</pubDate>
    </item>
    <item>
      <title>增强状态空间滤波问题中的 Hessian 表示</title>
      <link>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</link>
      <description><![CDATA[问题
设 $z_t := (x_t, x_{t-1}, x_t^2, x_{t-1}x_t,x_{t-1}x_t,x_{t-1}^2)$，且
$R(x_t) := \sum_{(i,j) \in \{\{0,1,2,3,4\} \otimes \{0,1,2,3,4\} : i+j \le 4\}} w_{i,j} x_t^i x_{t-1}^j$，
因此 $R(\cdot)$ 在 $x_t, x_{t-1}$，但在 $z_t$ 中是二次函数。
在 $R(z)$ 的二阶泰勒展开式中，$R(z^*)$，
$R(z) = R(z^*) + J_R(z^*)(z - z^*) + 0.5 (z - z^*)^\prime H_R(z^*) (z - z^*) $
如何表达雅可比矩阵 $J_R$ 和 Hessian，$H_R$，$R(z_t)$，来解释$z_t$中的项是彼此的函数这一事实？
背景
我正在解决一个困难的过滤问题。
让$x_t$和$y_t$成为标量随机变量。
状态转换动力学可以用以下方式来表征：$x_t | x_{t-1} \sim \mathcal{N}(\Phi x_{t-1},Q)$。
测量方程具有以下动态，$y_t | y_{t-1}, x_t, x_{t-1} \stackrel{\text{approx}}{\sim} \mathcal{N}(A + B y_{t-1} + f(x_t,x_{t-1}), R(x_t,x_{t-1})),$ 其中 $f(\cdot)$ 在 $\tilde{x}_t := (x_t, x_{t-1})^\prime$ 中为 二次 方程，而 $R(\cdot)$ 在 $\tilde{x}_t$ 中为 四次 方程。近似值来自匹配随机积分的矩，但我们现在可以忽略它并假设它完全是高斯的。
到目前为止，我的解决方案是用状态的二阶项来扩充状态空间，$z_t := (\tilde{x}_t^\prime,vec(\tilde{x}_t^\prime \tilde{x}_t)^\prime)^\prime = (x_t, x_{t-1}, x_t^2, x_t x_{t-1},x_{t-1} x_t, x_{t-1}^2 )^\prime$。我可以跟踪 $z_t | z_{t-1}$ 恰好，则 $f(\cdot)$ 在 $z_t$ 中是仿射的，而 $R(\cdot)$ 在 $z_t$ 中是二次的。
据我所知，在我的设置中，卡尔曼滤波器在计算创新的协方差时会失效。设$f(z_t) = \alpha_f + \beta_f z_t$，且$\mathcal{Y}_{t-1} := \{y_{\tau}\}_{\tau = t_0}^{t-1}$则
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + \mathbb{E}[R(z_t) | \mathcal{Y}_{t-1}]$，
其中 $S_t := \mathbb{E}[(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])^\prime | \mathcal{Y}_{t-1}]$。
我目前的计划是取二阶泰勒展开式的期望值 $R(\hat{z}_{t|t-1})$，
$\mathbb{E}[R(z_t)|\mathcal{Y}_{t-1}] = \mathbb{E}[ R(\hat{z}_{t|t-1}) + J_R(\hat{z}_{t|t-1}) (z_t - \hat{z}_{t|t-1}) + 0.5 (z_t - \hat{z}_{t|t-1})^\prime H_R(\hat{z}_{t|t-1})(z_t - \hat{z}_{t|t-1}) |\mathcal{Y}_{t-1}] = R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$
其中 $\hat{z}_{t|t-1} := \mathbb{E}[z_t | \mathcal{Y}_{t-1}]$，从而得到精确的创新协方差公式，
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$。
最后，我的问题是，如果 $z_t$ 中的几个元素是其他元素的函数，那么如何计算 Hessian $H_R(z_t)$？特别是如果，
$R(z_t) = \sum_{(i,j) \in \{0,1,2,3,4\} \otimes \{0,1,2,3,4\}} w_{i,j} x_t^i x_{t-1}^j$，
如何表达 $R(z_t),$ $H_R(z_t)$ 的 Hessian？]]></description>
      <guid>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</guid>
      <pubDate>Sat, 06 Jul 2024 21:17:18 GMT</pubDate>
    </item>
    <item>
      <title>随机变量线性系统中的方差</title>
      <link>https://stats.stackexchange.com/questions/650605/variance-in-a-linear-systems-of-random-variables</link>
      <description><![CDATA[设 $Y_1 = \{3, 5, 4, 2, 3, 4, 2, 4\}$，$Y_2 = \{7, 6, 10, 8, 9, 7, 10, 7\}$，且设 $U = Y_2 - Y_1 = \{y_{2,1} - y_{1,1}, y_{2,2} - y_{1,2}, ...\} = \{4, 1, 6, 6, 6, 3, 8, 3\}$。然后 $U$ 的方差等于
$V(U) = \sum{a_i^2V(Y_i)} + 2\sum{\sum{a_ia_jCov(Y_i, Y_j)}}$
方差也可以通过使用标准公式 $V(U) = \frac{\sum{(u_i - \mu_u)^2}}{N}$ 来找到，其中 $\mu_u$ 是 $U$ 的平均值。
问题是在 python 中使用这两种方法（实际上不仅在 python 中）会产生不同的结果：
import numpy as np

Y1 = [3, 5, 4, 2, 3, 4, 2, 4]
Y2 = [7, 6, 10, 8, 9, 7, 10, 7]

U = [y2 - y1 for y1, y2 in zip(Y1, Y2)]

print(np.var(u)) # 4.484375

print(np.var(Y1) + np.var(Y2)) # 2.984375


根据第一种方法（作为线性系统）$a_1 = 1$ 和 $a_2 = -1$，因此即使 $Y_1$ 和 $Y_2$ 不是独立的，也就是说，如果 $Cov(Y_1, Y_2) \neq 0$，则第二个值将小于现在的值，因此也小于 $U$。
我哪里做错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/650605/variance-in-a-linear-systems-of-random-variables</guid>
      <pubDate>Sat, 06 Jul 2024 21:09:42 GMT</pubDate>
    </item>
    <item>
      <title>测量治疗异质性</title>
      <link>https://stats.stackexchange.com/questions/650602/measuring-treatment-heterogeneity</link>
      <description><![CDATA[这是第一个问题，发布于此处
我正在研究信息对当地价格和搬到某些城市的选择的影响。我认为这些信息会对那些感到惊喜的人（他们认为当地价格比实际价格高）的结果（搬家）产生积极影响，而对那些感到惊喜的人（他们认为当地价格比实际价格便宜）则产生消极影响。我可以测量治疗组的先验和后验信念，但显然不能测量对照组。我是否仍然可以通过观察人们是感到惊喜还是感到惊喜的异质性来探索治疗的效果？
即，它是否估计：
Movei​=β0​+β1​Treatmenti​+β2​PosSurprisei​×Treatmenti​+β3​NegSurprisei​×Treatmenti​+ei​
对我来说，异质性意味着与对照组进行比较，但我无法理解这种情况。
编辑：如果我能够找到关于先前（但不是后验）信念的数据，我可以将其添加为控制，作为一种想法]]></description>
      <guid>https://stats.stackexchange.com/questions/650602/measuring-treatment-heterogeneity</guid>
      <pubDate>Sat, 06 Jul 2024 18:46:26 GMT</pubDate>
    </item>
    <item>
      <title>Stata 或 R 中的循环回归和推理</title>
      <link>https://stats.stackexchange.com/questions/650594/looped-regression-and-inference-in-stata-or-r</link>
      <description><![CDATA[我有一个面板数据样本，正在循环运行特定分类变量值的回归分析。举例来说：
$$ y_{it} = \alpha_i + \eta_t + \beta^C D_{it} + \epsilon_{it} $$
其中 $y_{it}$ 是感兴趣的结果，$\alpha_i, \eta_t$ 是单位和时间固定效应，$D_{it}$ 是治疗虚拟变量，$\epsilon_{it}$ 是误差项。假设还有一个分类 $C$ 变量，其支持集为 $\{1,2...,10\}$，并且根据此变量的值对不同的子样本运行此回归（即运行 10 个不同的回归）。
每次迭代后，我都会保存每个回归的系数、标准误差和样本大小。然后，我会找到这些系数的平均值，从而得到一个估计值（我确实有这样做的理由）。结果，我有变量：
$$ \tau = \frac{1}{10} \sum_{C=1}^{10}\beta^C $$
我的问题是，我希望为这个回归系数平均值得出标准误差/t 统计量。但是，我不确定是否很容易得出此估计的解析表达式，还是最好使用引导程序？如果是后者，有人可以指出一些 R 或 Stata 中的资源来执行此操作吗？我在这方面没有太多经验，而且这种情况似乎有些不标准。]]></description>
      <guid>https://stats.stackexchange.com/questions/650594/looped-regression-and-inference-in-stata-or-r</guid>
      <pubDate>Sat, 06 Jul 2024 13:13:24 GMT</pubDate>
    </item>
    <item>
      <title>局部线性核回归</title>
      <link>https://stats.stackexchange.com/questions/650588/local-linear-kernel-regression</link>
      <description><![CDATA[已知给定点 $x$ 的预测由以下公式给出：
$$\hat{f}_h(x) = \hat{\beta}_0(x)$$
其中
$$\hat{\beta}(x) = \arg\min_{\beta_0, \beta_1}\sum_{i=1}^nK\left(\frac{x - x_i}{h}\right)(Y_i - \beta_0 - \beta_1(x_i - x))^2.$$
我直观地理解了为什么对于预测我们只考虑截距：局部线性模型正在回归 $x_i$ 和 $x$，因此对于预测，我们认为距离回归线的值等于 0 是有道理的。
我不明白的是，为什么我们不直接解决这个问题呢（这是我接触这个主题时首先想到的）？
$$\hat{f}_h(x) = \hat{\beta}_0(x) + \hat{\beta_1}(x)x$$
其中
$$\hat{\beta}(x) = \arg\min_{\beta_0, \beta_1}\sum_{i=1}^nK\left(\frac{x - x_i}{h}\right)(Y_i - \beta_0 - \beta_1x_i)^2.$$
因此，我们不会对距离进行回归，而是对单个点进行局部回归，然后使用所有回归线进行预测。
这种方法错误吗？有人能帮我吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650588/local-linear-kernel-regression</guid>
      <pubDate>Sat, 06 Jul 2024 12:01:14 GMT</pubDate>
    </item>
    <item>
      <title>某些 p 值可能不可能吗？（因为参数引导生成的统计数据大多是相同的值。）</title>
      <link>https://stats.stackexchange.com/questions/650536/is-it-possible-for-some-p-values-to-be-impossible-because-statistic-generated</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650536/is-it-possible-for-some-p-values-to-be-impossible-because-statistic-generated</guid>
      <pubDate>Fri, 05 Jul 2024 16:22:18 GMT</pubDate>
    </item>
    <item>
      <title>最可能结果的可能性有一个名称吗？</title>
      <link>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</link>
      <description><![CDATA[在流行统计学中，我们通常会将最可能的结果描述为一个非常有意义的属性。
但如果不知道最可能的结果有多大的可能性，它实际上就没有那么大的意义。
例如，在四次抛硬币中，最可能的结果是一半正面，一半反面，
但实际得到该结果的可能性只有 37.5%；几乎三分之二的时间里，结果会是其他的。
硬币数量越多，最可能的结果就越不可能发生，但实现该结果的可能性就越接近于零。
也就是说，最可能发生的事情可能非常不可能。
这似乎是几乎从未被提及过的事情，但是这个最可能结果的（不）可能程度的概念有名字吗？
（对于预期值，可以提出类似的问题。）
澄清：
我对实际值本身不太感兴趣，但我对值可能被歪曲或误解的方式很感兴趣。
例如，如果我从一副牌中取出黑桃 A，我可以如实地说，随机抽一张牌最有可能的结果是红色。
或者我可以删除除黑桃之外的所有 A，并声称随机选择的最可能结果是黑桃。
这两个陈述都是准确的，但远没有听起来那么精确。
这些陈述的实际真实性、有用性、价值、价值等接近于零。
我正在寻找这种统计数据的术语，它听起来很重要，但几乎毫无意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</guid>
      <pubDate>Thu, 04 Jul 2024 00:35:03 GMT</pubDate>
    </item>
    <item>
      <title>用测试对象分离的数据测试两个分类变量的依赖性</title>
      <link>https://stats.stackexchange.com/questions/650068/testing-dependence-of-two-categorical-variables-with-data-separated-by-test-subj</link>
      <description><![CDATA[这与我正在开展的一个真实世界实验有关。假设在我的实验中，测试对象会看红色或蓝色太阳镜的图片，然后给它们贴上“酷”或“不酷”的标签。我想测试受试者是否更有可能将某种颜色的太阳镜标记为“酷”。
我的第一个想法是汇总所有数据，并对颜色标签列联表进行卡方检验，以了解独立性，如下所示（带有示例数字）：




红色
蓝色




酷
50
35


不酷
45
45



但是，这并没有告诉我们如果个别受试者的判断受到颜色的影响。如果每个个体受试者的偏见并不明显，但总体而言，这些偏见加起来具有统计意义，该怎么办？或者一半受试者明显偏向一个方向，另一半偏向另一个方向，而总体而言，这相互抵消了？这感觉就像辛普森悖论的领域。
如何严格测试样本中的受试者的判断是否受到汽车颜色的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/650068/testing-dependence-of-two-categorical-variables-with-data-separated-by-test-subj</guid>
      <pubDate>Thu, 27 Jun 2024 17:45:51 GMT</pubDate>
    </item>
    </channel>
</rss>