<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 03:20:26 GMT</lastBuildDate>
    <item>
      <title>是否可以将具有截距的指数关系的数据转换为线性关系？</title>
      <link>https://stats.stackexchange.com/questions/656813/is-it-possible-to-transform-data-following-an-exponential-relationship-with-an-i</link>
      <description><![CDATA[在估计非线性关系的参数时，我经常发现以可以使用 OLS 线性回归的方式转换数据很有用。例如，将指数关系 $y=ax^b$ 转换为 $\ln{y}=\ln{a}+b\ln{x}$ 或将 II 型功能响应 $y=\frac{ax}{1+ahx}$ 转换为 $y^{-1}=h+a^{-1}x^{-1}$。
我有一些数据，我预计它们会遵循指数关系。我尝试使用这种方法，但预期关系有一个截距：
$$y=\frac{a}{b}(e^{-bx}-1)$$
我似乎无法弄清楚如何将其转换为线性。
我知道我可以使用 GLM，但是否可以通过将数据转换为线性来估计参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/656813/is-it-possible-to-transform-data-following-an-exponential-relationship-with-an-i</guid>
      <pubDate>Wed, 06 Nov 2024 03:06:16 GMT</pubDate>
    </item>
    <item>
      <title>估计一个向量 $\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}}$</title>
      <link>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</link>
      <description><![CDATA[在高维设置中，我们使用依赖于稀疏性假设的套索方法解​​决线性回归，
$$
\hat{\beta}=\underset{\beta\in \mathbb{R}^{p}}{\arg \min}\|Y-X\beta\|_2^2+\lambda\|\beta\|_1 。
$$
现在我对一个新模型感兴趣，其中$\beta$分解为一个稀疏向量和一个密集向量
$$
\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}},
$$
并获得估计量
$$
\left(\hat{\beta}_1,\hat{\beta}_2\right)=\underset{\beta_1,\beta_2}{\arg \min}\|Y-X\left(\beta_1+\beta_2\right)\|_2^2+\lambda_1\|\beta_1\|_a+\lambda_2\|\beta_2\|_b
$$
其中$\|\cdot\|_a$和$\|\cdot\|_b$鼓励估计量稀疏和密集。
我猜这个模型已经得到很好的研究了。现在这个模型的最佳结果是什么？你能给我提供一些相关的论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</guid>
      <pubDate>Wed, 06 Nov 2024 02:42:52 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 二元分类模型的 AUC 值低</title>
      <link>https://stats.stackexchange.com/questions/656810/low-auc-value-for-xgboost-binary-classification-model</link>
      <description><![CDATA[我正在使用 XGBoost 构建二元分类模型，以根据体重、每日平均步数、年龄等因素识别具有诊断的个人。我的模型非常小（只有 200 个案例），并且不平衡（负数与正数之比为 4:1）。我构建了一个 XGBoost 模型，但我注意到通过调整，我只实现了小于 .5 的测试 AUC 结果，有些模型提供的测试 AUC 值为 .2-.3。训练 AUC 值从 .3-.6 不等。我曾尝试使用 SMOTE，但它并没有大大提高分类准确性。标签没有被切换，也没有编码错误。我正在使用 gamma、lambda 和正权重缩放参数来降低过度拟合的可能性。但是，似乎没有任何东西能够将模型的 AUC 提高到 .5 以上。
从概念上讲，我不太确定我是否理解二元分类模型如何能够实现完全错误的猜测，但不能实现完全正确的猜测。如果模型在判别方面几乎完全不准确（AUC &lt; .2），那么它是否也能获得良好的结果（AUC &gt; .8）？]]></description>
      <guid>https://stats.stackexchange.com/questions/656810/low-auc-value-for-xgboost-binary-classification-model</guid>
      <pubDate>Wed, 06 Nov 2024 00:06:50 GMT</pubDate>
    </item>
    <item>
      <title>具有随机变化的生物时间序列数据：回归是否合适以及中心变量是否能消除年份效应</title>
      <link>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</link>
      <description><![CDATA[我有多年树木作物的数据：产量、树冠体积等。还有 2 个因素（品种、管理）。
我试图找出我的一些变量之间是否存在相关性，例如树冠和产量。我接触过一位非常严格和严谨的统计学家。他提出了一些主张，我想知道这些主张是否完全正确，是否必须像他建议的那样严格遵守。现在，另一方面，我的老板正在挑战统计学家希望我这样做的方式，并希望我能说服他。统计学家的说法是：

我必须将数据居中（从每个数据点中减去年平均值并添加总体平均值）以消除年份效应。我的老板对此不满意，因为这意味着散点图中的值不再是真实值，并且具有误导性。此外，它还缩小了数据的范围。树冠体积和产量从早年的接近零上升到树木成熟时的很高数字。统计学家说，如果我不将数据集中，就会产生误导，因为产量的增加是由于年龄（即年份）而不是树冠。从生物学的角度来看，我认为这有点愚蠢，但我确实理解这个概念。

我无法拟合回归模型。原因显然是我的实验没有设计成解释变量被复制，因此没有错误。我的解释变量（树冠）是一个观察值，而不是设计值。他让我参考了一篇论文（Powers 2021，《应用生物学年鉴》编辑部），但在同一篇论文中写道：“在其他研究中，将研究由成对的观察值组成的收集数据，以考虑它们之间的关系，而不一定在每个级别都进行复制[就像我的实验中的情况一样]……重要的是评估所提出的关系的统计质量。首先，实际上，应该问是否真的需要拟合关系。&#39;这意味着拟合模型是一种选择，尽管并非总是最佳选择。而统计学家说这是错误的，就是这样。他引用了一本书（Draper 和 Smith 的《应用回归分析》）：“回归分析的一个假设是预测变量不受随机变化的影响”[在我看来它们是]。我的统计学书（Crawley 的《统计学。使用 R 的介绍》）说：“也许知道何时回归是合适的分析的最简单方法是看散点图是否是合适的图形。&#39;[在我看来，它绝对是]另一个重要的事实是，我所在领域的大量其他论文都在做同样的事情：将回归线拟合到像我这样的数据中。这就是我老板使用的论点：人们期望看到直线和 r2，而你需要有一个很好的理由来以不同的方式去做。统计学家建议我使用带有皮尔逊相关系数的散点图，但没有线。


我感觉自己陷入了进退维谷的境地（两个非常强大和自信的个性），我需要更多的解释/意见，才能感觉自己可以更好地辩论。]]></description>
      <guid>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</guid>
      <pubDate>Tue, 05 Nov 2024 23:17:29 GMT</pubDate>
    </item>
    <item>
      <title>变换后的 $y$（S 型 $y$）的线性回归是否应与响应的变换（S 型）相同</title>
      <link>https://stats.stackexchange.com/questions/656807/should-the-linear-regression-of-a-transformed-y-sigmoid-y-be-identical-to</link>
      <description><![CDATA[线性模型的预测变量 $\hat y$ 的 S 形函数 $(1/(1+e^{-y}))$ 是否应与 S 形函数 $y$ 的线性回归相同。下面的 Python 示例演示了二进制数据的 S 形函数的线性回归和响应 $\hat y$ 的 S 形变换。它们很接近但不完全相同（参见绿线和红线/曲线）。然而，一般来说，响应的转换$\operatorname{sigmoid}(\hat y)$是否应该与 S 形的回归（$\operatorname{sigmoid} (y) = a\cdot x + \varepsilon)$相同。请记住，我没有使用线性广义模型。
谢谢

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from scipy.special import expit

# 绘制逆对数函数。
#plt.figure();plt.plot(expit(np.arange(100)))

x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])

################
# 线性回归的逆 logit (Sigmoid) 
linearReg = LinearRegression().fit(x,y)
y_hat_linear = x * linearReg.coef_ + linearReg.intercept_
# 逆 logit (Sigmoid) # 1/(1+exp(-y))
inverselogit_linear = expit(y_hat_linear) 
print(linearReg.coef_)
print(linearReg.intercept_)

#############
# 逆 logit (Sigmoid) 的线性回归
linearlogReg = LinearRegression().fit(x,expit(y))
y_hat_linearlog = x * linearlogReg.coef_ + linearlogReg.intercept_
print(linearlogReg.coef_)
print(linearlogReg.intercept_)
###################
plt.figure()
plt.scatter(x,y)
plt.plot(x,y_hat_linear,label=&#39;线性回归&#39;)
plt.plot(x,inverselogit_linear,label=&#39;响应的 S 形 (OLS)&#39;)
plt.plot(x,y_hat_linearlog,label=&#39;响应的 S 形 (OLS)&#39;)
plt.legend()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656807/should-the-linear-regression-of-a-transformed-y-sigmoid-y-be-identical-to</guid>
      <pubDate>Tue, 05 Nov 2024 22:08:34 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{Z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>分层 2x2 全因子试验的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</link>
      <description><![CDATA[我需要计算分层 2x2 全因子试验所需的样本量（簇数和每个簇的平均观察数）。试验中心将随机分配到四种条件（基数、基数 + A、基数 + B、基数 + A + B）。在每个中心，将针对多个个体测量主要结果（指标，可能有偏差）。A 和 B 对结果的影响以及它们的相互作用将引起人们的兴趣。
如果残差分布允许，我打算使用混合线性效应模型（我希望不必求助于广义模型或其他替代方案，但我想还是有可能的）。我将对 ICC（预计相当低，介于 0.02 和 0.04 之间）和簇大小变化做出假设。 Alpha=0.05，power=0.8。
我熟悉具有分层数据结构的集群随机试验的功效计算，这些试验通过混合线性效应模型进行分析，其中单一治疗效果是感兴趣的，但不熟悉因子试验。我也在一定程度上熟悉 2x2 全因子试验的功效计算，但不熟悉分层数据结构。
我使用 Stata 和 R。
非常感谢您的帮助！如果您可以为该方法添加可引用的参考文献，那就更好了。
Marco]]></description>
      <guid>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</guid>
      <pubDate>Tue, 05 Nov 2024 21:40:50 GMT</pubDate>
    </item>
    <item>
      <title>在干预之前重复测量能在多大程度上提高我的统计能力？</title>
      <link>https://stats.stackexchange.com/questions/656804/how-much-will-repeating-a-measure-before-an-intervention-improve-my-statistical</link>
      <description><![CDATA[我正在一项有数千名参与者的干预研究中测量 PHQ-9 抑郁量表的基线和四周随访。
我正在考虑在基线前几天再测量一次，以提高研究的统计能力。但是，我不确定这会对统计能力产生多大的影响。PHQ-9 的重测信度据说非常好，如果在几天内重新测试，则约为 r=0.85。是否值得再测量一次？
根据 Goulet &amp; Cousineau (2019)，我猜测相关性太高，以至于不会产生太大影响，但样本量大让我重新考虑了一下。

Goulet, M. A., &amp; Cousineau, D. (2019). 重复测量的效力可提高统计能力。心理科学方法与实践进展，2(3)，199-213。

谢谢，
Benji]]></description>
      <guid>https://stats.stackexchange.com/questions/656804/how-much-will-repeating-a-measure-before-an-intervention-improve-my-statistical</guid>
      <pubDate>Tue, 05 Nov 2024 21:29:47 GMT</pubDate>
    </item>
    <item>
      <title>场景中，X（训练）和 X（测试）上的 PCA 不是数据泄漏</title>
      <link>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</link>
      <description><![CDATA[有无数（转）帖讨论使用主成分分析 (PCA) 作为交叉验证 (CV) 中回归/分类问题特征的预处理方法的问题。我知道在执行 CV 之前将 PCA 应用于整个特征数据集会导致数据泄漏，因为测试数据集与训练数据集并不完全独立。这会影响我们准确评估模型如何推广到新鲜和未见过的数据的能力。
然而，在某种情况下，我认为这并不成立，但我没有发现无数关于这个主题的帖子中提到过这个问题。我认为这甚至可能不是一种罕见的情况：
假设我们想知道特定地理研究区域（$G$）内目标变量（$Y$）的值，例如创建空间地图。对于 $G$，特征 ($X$) 是详尽可用的，例如，将高维遥感特征视为 $X$ 的输入。
我们可以在某些位置 ($Y(s)$) 采样并确定 $Y$；以预测未知的 $Y(u)$。通过这样做，我们能够拟合模型 ($F$) $F: X(s) -&gt; Y(s)$。接下来，我们可以使用该模型预测给定$X(u)$的$Y(u)$，其中预测的$\hat{Y}(u)$ = $F(X(u)$)。我们只对使用我们的模型一次感兴趣，例如创建一个映射，其中 $X(u) ⊆ G$。
为了获得最佳的 $\hat{Y}(u)$，我们将在拟合 $F$ 之前对整个特征数据集 $X(s+u)$ 应用 PCA，因为我们有 $X(u)$ 可用。
接下来，我们要检查我们的 $\hat{Y}(u)$（或 $F$）有多准确。由于我们没有从 $G$ 中抽取的进一步独立样本 $Y$，我们可以使用 CV。
如果我们在 CV 中仅对 $X(train)$ 应用 PCA 并将其投射到 $X(test)$ 上，我们不会得到悲观的结果吗？在我们的实际流程中，我们对 $X(u+s)$ 使用了 PCA，那么在 CV 中，是否有理由以不同的方式执行此操作，因为我们只想知道我们的模型在给定 $X(u) ⊆ G$ 的情况下如何推广到 $X(u)$。
我的想法是不是错了？与典型情况不同的底层概念的名称是什么，我们希望 $F$ 能够很好地推广到新鲜和独立的样本？有人知道任何针对这种特定场景的文献吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</guid>
      <pubDate>Tue, 05 Nov 2024 18:18:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么加权最小二乘（WLS）回归中的逆方差权重会给出“最佳”估计量？</title>
      <link>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</link>
      <description><![CDATA[这是我目前对 WLS 的理解。
在 OLS 中，我们给每个数据点相同的权重。这在某些假设下给出了最佳的线性无偏估计量——其中之一是误差项的方差为常数（同方差性）
但是当残差具有异方差性时，我们确定回归系数的 OLS 估计量不再是“最佳”的估计量。这意味着它具有更多的方差。因此，然后使用 WLS 找到这个最佳估计量（考虑到误差仍然不相关）。
我读到，当权重是误差项的逆方差时，WLS 会给出回归系数的最佳估计量。这意味着我们给 OLS 模型预测高误差方差（由残差方差估计）的数据点赋予较少的权重。误差方差较小的点会获得更大的权重。
我明白这在理论上是可行的。我想更直观地理解它：为什么给予方差较小的点更大的权重会改善估计量？
为什么在执行 WLS 回归时，方差较小的点被认为更“可靠”？
谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</guid>
      <pubDate>Tue, 05 Nov 2024 16:42:54 GMT</pubDate>
    </item>
    <item>
      <title>联合检验复合零假设</title>
      <link>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</link>
      <description><![CDATA[假设我们有一个 GLM，其 $g^{-1}(\mathbb{E}[y|x]) = \beta_0+x_A\beta_A+x_b\beta_B$。我想检验以下假设：$H_0:\beta_A \leq 0 \cup\beta_B\leq0$ $H_1:\beta_A&gt;0\cap \beta_B&gt;0$。有人能指点我如何构建一个检验方法，在这些情况下得出有效的 p 值吗？如果我没错的话，我正在检验两个复合零假设，但我不知道还能用这些信息做什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</guid>
      <pubDate>Tue, 05 Nov 2024 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 与交叉验证来评估机器学习模型的预测性能</title>
      <link>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</link>
      <description><![CDATA[我正在尝试在引导和交叉验证之间做出选择，以便彻底评估预测模型性能。
引导：

使用替换对数据进行采样，创建 B &gt; 1000（或更多）个不同的训练集，其中由于使用替换采样，每个观察结果都被独立处理！这意味着经验分布函数被用作抽取样本的真实世界分布的替代品。
动态使用袋外 (OOB) 观测值作为保留集：这消除了对单独保留集的需求，并且可以提供更可靠的样本外预测性能估计。
可能捕获更多真实世界方差（通过替换采样，即利用经验分布函数）

如果我必须评估两个不同的模型，我会

生成 B=1000 ... 训练数据集的引导重采样
在 B 个不同的袋外测试样本集上评估这两个模型
计算配对模型性能差异（性能模型 1 - 性能模型 2，其中差异取自相同的 OOB 测试集），配对将用于https://en.wikipedia.org/wiki/Variance_reduction
制作配对模型性能差异的直方图
如果模型性能的密度明显偏离 0，则其中一个模型优于另一个模型（由此也可以设计一些测试以获得 95% 的改进确定性...）

交叉验证：

将数据分成几部分，使用不同的部分进行训练和测试。
可以更有效率，尤其是在数据有限的情况下。
可能导致“相关”训练集，尤其是在 LOOCV 中（训练集几乎没有变化，除了一个观察值）

为了比较两个模型，我会做与 bootstrap 情况相同的事情（只是没有袋外测试样本，但在 LOOCV 的情况下，最大 N= 观察值不同的保留集）。
问题：
鉴于 bootstrap 可以在训练集中引入更多变化（通过替换重采样）并利用 OOB 数据进行验证，与交叉验证（本质上是无替换重采样）相比，它是否会提供更现实的样本外性能估计？尤其是潜在的“相关性” 交叉验证训练集之间是否存在重大问题？
PS：我尝试搜索 stackoverflow 并提出了类似的问题，但它们没有讨论 CV 训练集的潜在相关性问题：

Bootstrap 或 jack-knife 用于预测模型的交叉验证？（无答案）
了解用于验证和模型选择的 bootstrapping
交叉验证和引导法在估计预测误差方面的差异（没有明确的答案哪个更可靠）
交叉验证或引导法评估分类性能？（这个问题似乎很直接，但公认的答案主要涉及只有一个测试训练分割（CV 的退化形式，显然没有像 k 倍 CV 那样的多个测试训练分割），Frank Harell 有一个答案 https://stats.stackexchange.com/a/71189/298651 链接 https://hbiostat.org/doc/simval.html 得出一个结论“普通引导法优于或等于所有尝试过的交叉验证策略”，但这在他的回答中没有明确讨论...)
分类测试的交叉验证与随机抽样（没有明确的结论，无所谓，但有趣的论文？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</guid>
      <pubDate>Mon, 04 Nov 2024 07:58:08 GMT</pubDate>
    </item>
    <item>
      <title>使用正交勒让德多项式进行 Copula 密度估计和绘图</title>
      <link>https://stats.stackexchange.com/questions/656746/copula-density-estimation-and-plotting-using-orthogonal-legendre-polynomials</link>
      <description><![CDATA[我一直尝试根据以下步骤复制 copula 密度图，但没有成功：
对 I=[0,1] 使用均匀测度
使用移位勒让德多项式的正交基，公式如下：

[移位勒让德多项式]
对于 d=2，定义

[移位Legendre 多项式应用于数据]
和

[移位 Legendre 多项式的平均值应用于数据 - 新的相关系数。]
copula 密度函数是

[移位 Legendre 变换的 copula 密度函数数据多项式]
对于

其经验对应物是

[新相关系数的样本对应物]
而 copula 密度经验对应物是

[copula 密度的样本对应项。]
现在我的情况只涉及二维数据，即 d=2。在这种情况下，rho_m 只是将移位勒让德多项式变换应用于数据后的相关系数。
我想使用模拟数据绘制 copula 密度 c 的非参数估计量。
它必须看起来像下面的情节（或多或少）

论文可以在这里找到：
https://arxiv.org/pdf/2010.15351
我的情节是

这肯定看起来不对！！
您对如何正确编写 R 函数 (7) 有什么建议吗？您能找到问题吗？无需处理 m&lt;N 的总和

因为在我的例子中，是一个标量！

# 生成双变量样本：
set.seed(1)
datX &lt;- mvrnorm(n=n, mu=mymeans, Sigma, empirical=TRUE)

# Legendre 多项式变换：
library(orthopolynom)

Kcop_pol &lt;- function(m, x) {
legend = slegendre.polynomials(m, normalized = TRUE) # [m+1]?
unlist(polynomial.values(legend, x))
} 

Kcop_rhat &lt;- function(j, datX) {
datX &lt;- pobs(datX)
n1 = nrow(datX)
p1 = ncol(datX)
A = matrix(rep(0, n1 * p1), ncol = p1)
for (i in 1:p1) {
A[, i] &lt;- Kcop_pol(j[i], datX[, i])
} 
sum(apply(A, 1, prod)) / n1
}

# 计算 m=c(1,2) 的 rho_m 
Kcop_rhat(j = c(1,2), datX = datX) 

orthog.poly.copula.surface = function(u,v,n) {
s = seq(1/(n+1), length = n, by = 1/(n+1))
mat = matrix(0, nrow = n, ncol = n)
for (i in 1:n) {
a = s[i]
for (j in 1:n) {
b = s[j]
mat[i, j] = 
Kcop_rhat(j = c(1,2), datX = datX) * 
mean(outer(Kcop_pol(m, a), Kcop_pol(m, b))) 
}
}
list(x=s,y=s,z=data.matrix(mat))
}

z = orthog.poly.copula.surface(u = datX[, 1], v = datX[, 2], n = n)$z

persp(seq(0,1,length = n),
seq(0,1,length = n),
z,
col = &quot;green&quot;,
shade = TRUE,
ylab = &quot;GDP 增长&quot;,
zlab = &quot;Copula 密度&quot;,
xlab = &quot;债务/GDP&quot;,
axis = TRUE,
theta = 150,
phi = 20,
main = &quot;正交多项式 Copula 密度&quot;,
ticktype = &quot;detailed&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656746/copula-density-estimation-and-plotting-using-orthogonal-legendre-polynomials</guid>
      <pubDate>Mon, 04 Nov 2024 05:54:07 GMT</pubDate>
    </item>
    <item>
      <title>在反向传播中对权重矩阵进行区分时避免使用张量</title>
      <link>https://stats.stackexchange.com/questions/656649/avoiding-tensors-when-differentiating-with-respect-to-weight-matrices-in-backpro</link>
      <description><![CDATA[考虑一个仅由单个仿射变换组成且没有非线性的神经网络。使用以下符号：

$\textbf{输入}：x \in \mathbb{R}^n$
$\textbf{权重}：W \in \mathbb{R}^{h \times n}$
$\textbf{偏差}：b \in \mathbb{R}^h$
$\textbf{输出}：z = W x + b \in \mathbb{R}^h$
$\textbf{损失函数}：\ell(z) \in \mathbb{R}$

我们试图计算损失相对于权重的梯度$\frac{\partial \ell}{\partial W}$。在进行反向传播时，我们将此梯度分解为两个因子：
$$
\frac{\partial \ell}{\partial W} = \frac{\partial \ell}{\partial z} \cdot \frac{\partial z}{\partial W}
$$
但是，$\frac{\partial z}{\partial W}$是向量相对于矩阵的导数，而将产生三维张量。我们如何才能在保持事物处于二维状态的同时继续计算$\frac{\partial \ell}{\partial W}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/656649/avoiding-tensors-when-differentiating-with-respect-to-weight-matrices-in-backpro</guid>
      <pubDate>Sat, 02 Nov 2024 18:53:31 GMT</pubDate>
    </item>
    <item>
      <title>结合加权均匀分布和正态分布变量的复杂概率分布建模</title>
      <link>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</link>
      <description><![CDATA[最近，我一直在尝试为视频游戏中的随机分布提出一个准确的概率模型。我试图建模的过程如下：

从加权战利品表中随机选择三个物品（有替换）
每个物品都被分配一个正态分布的大小
然后比较这三个物品的大小，并将其中最大的一个交给玩家

在这个过程中，我已经知道从战利品表中选中每个物品的概率，以及每个物品大小分布的平均值和标准差。我如何将这个基本概率与大小分布结合起来，找出考虑到大小分布后选中某个物品的真实概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</guid>
      <pubDate>Sat, 02 Nov 2024 14:33:55 GMT</pubDate>
    </item>
    </channel>
</rss>