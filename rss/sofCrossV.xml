<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 28 May 2024 18:18:55 GMT</lastBuildDate>
    <item>
      <title>$\sigma^2$ 未知的简单线性回归的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</link>
      <description><![CDATA[假设我们有以下形式的简单线性回归模型：
$$Y_i = \beta X_i +\varepsilon_i$$
以下一组“经典假设”成立：

$E(\varepsilon_i)=0$

$Var(\varepsilon_i) = {E}(\varepsilon_i^2)-{E}(\varepsilon_i)^2= {E}(\varepsilon_i^2) = \sigma^2$

$Cov(\varepsilon_i, \varepsilon_j)=0$ 对所有 $i\neq j$

$\varepsilon_i$ 是正态的

$X_i$ 是常数，而不是随机变量。


我想找到 $\sigma^2$ 的最大似然估计量（假设它是未知的），以及 $\beta$ 的最大似然估计量（假设 $\sigma^2$ 是未知的）。
$##########$
作为背景，假设 $\sigma^2$ 已知，我有以下内容显示 OLS 估计量是 MLE 估计量。
由此，我们可以看到 $\beta$ 的 OLS 估计量是通过求解以下公式得出的：
$$ \text{minimize s.t.} \beta: f(\beta) =\sum (\hat{\varepsilon_i}^2) = \sum (Y_i - \beta X_i)^2$$
我们可以很容易地看到，因为 $\frac{df}{d\beta} = \sum (-2Y_iX_i + \beta^2 X_i^2)$ 且 $\frac{d^2f}{d\beta^2} = 2X_i^2 \geq 0$ 则 $\beta$ 的 OLS 估计量由下式给出：
$$\hat{\beta} = \dfrac{\sum X_iY_i}{\sum X_i^2}$$
我们可以轻松证明这也是最大似然估计量。我们首先查看似然函数，它定义为$Y_i&#39;s$的联合概率密度函数，并回想一下，$\varepsilon_i$为正常的假设意味着$Y_i$为正常的。我们有：
$$L(\beta) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
$$ \therefore L(\beta) \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} exp (\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
如果我们考虑对数似然函数，我们得到：
$$l(\beta) = \text{ln} \left [ \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \right ]\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
这又是一个相当简单的问题，最大化$l(\beta)$，这再次表明$$\hat{\beta} = \frac{\sum Y_iX_i}{\sum X_i^2}$$
$##########$
这是我有点困惑的地方。我是否应该将最大似然函数视为：
$$L(\beta\sigma^2) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
然后根据 $\sigma^2$ 和 $\beta$ 找到最大值。此外，我不清楚我实际上在哪里使用了 $\sigma^2$ 已知的假设？这在考虑置信区间、假设检验等时显然是相关的。但我不清楚 $\sigma^2$ 已知或未知如何影响上述推导。
谢谢您的帮助，
Hmmm16]]></description>
      <guid>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</guid>
      <pubDate>Tue, 28 May 2024 18:12:44 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归 - 分类预测变量</title>
      <link>https://stats.stackexchange.com/questions/648162/logistic-regression-categorical-predictors</link>
      <description><![CDATA[我正在寻找有关如何使用 SPSS 执行和解释多元逻辑回归的一般指导资源，使用分类预测因子。我有 2 个分类预测变量。每个分类预测因子都有三个组或类别。（我的结果是二进制的，是或否。）每个预测因子类别都是李克特类型类别。
预测因子 1
不太可能，
既不可能也不可能，
可能
预测因子 2
有点担心，
有点担心，
非常担心]]></description>
      <guid>https://stats.stackexchange.com/questions/648162/logistic-regression-categorical-predictors</guid>
      <pubDate>Tue, 28 May 2024 17:56:46 GMT</pubDate>
    </item>
    <item>
      <title>根据预测变量数量调整后的逻辑回归中的 R 平方</title>
      <link>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</link>
      <description><![CDATA[对于 OLS，我们有一个调整后的 R 平方，可根据模型中包含的预测变量数量进行调整。
对于逻辑回归，有一些 R 平方等价项（Tjur 的 R 平方、McFadden 的 R 平方、Cox-Snell 的 R 平方和 Nagelkerke 的 R 平方）。但是逻辑回归是否有一个 R 平方度量来调整模型中包含的预测变量的数量？
这篇关于逻辑回归 R 平方的文章没有回答我的问题，因为它没有关于根据模型中预测变量数量进行调整的 R 平方的信息。 “调整”是指这里提到的是上限为1的度量尺度。这不是我的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</guid>
      <pubDate>Tue, 28 May 2024 16:21:54 GMT</pubDate>
    </item>
    <item>
      <title>如何找到具有无限类别评估的线性可分问题的线性决策边界？</title>
      <link>https://stats.stackexchange.com/questions/648159/how-to-find-a-linear-decision-boundary-of-a-linearly-separable-problem-with-unli</link>
      <description><![CDATA[我有一个二元分类问题，我的目标是找到一个线性决策边界（我假设存在）。问题的背景是我有一个迭代优化过程，我需要找到约束的模型。此约束仅产生二进制值（可行或不可行）。为了让我的算法发挥作用，我需要找到一个线性决策边界 $\hat{g}: \mathbb{R}^d \to \mathbb{R}$，其中超平面 $\hat{g}(x) = 0$ 对应于可行性边界。
在每次迭代中，我都有一个初始数据集，其中包含点 $\mathbf{X}^{(t)}_{1:\lambda} \in \mathbb{ R}^{\lambda \times d}$ 由已知正态分布生成 $\mathcal{N}(m^{(t)}, \textbf{C }^{(t)})$。我可以在函数 $g$ 上评估这些点以获得类标签。这个问题的特殊性是我可以评估 $\mathbf{Y}_{1:n}$ 上的任意数量的新点 $\mathbf{Y}_{1:n}$ container&quot;&gt;$g$ 并获取它们的类标签。
为了让我的算法发挥作用，我需要有一个非常精确的模型边界，它也适用于下一次迭代的样本，该样本在所有方向上可能具有较低的方差。请注意，数据集的边际通常非常低。
您对如何解决这个问题有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648159/how-to-find-a-linear-decision-boundary-of-a-linearly-separable-problem-with-unli</guid>
      <pubDate>Tue, 28 May 2024 16:12:33 GMT</pubDate>
    </item>
    <item>
      <title>2SLS：它只是重新调整工具变量吗？</title>
      <link>https://stats.stackexchange.com/questions/648158/2sls-does-it-just-rescale-the-instrument-variable</link>
      <description><![CDATA[我正在研究使用仪器变量来纠正数据中一些已知的测量误差来源（反映我们认为直接影响我们感兴趣的主要测量值的错误/不一致的测量值）。
我尝试过手动进行 2SLS 并使用 Linnearmodels IV2SLS。
但是，当我查看 X_hat 变量并将其与工具变量进行比较时。所发生的只是仪器的重新调整：
X1 = 我感兴趣的自变量
DSC_2 = 仪器变量（测量误差源的度量）
res_first = IV2SLS(data[“X1”], data[[“const”, “DSC_2”]], None, None).fit(
    cov_type=“未调整”
）
打印（res_first）
数据[“X_hat”] = data.X1 - res_first.resids 


无论我使用手动 2SLS 还是 IV2SLS，结果都是相同的。
我真的不明白这如何改进我们的模型（但我想了解！）。
我是否错误地指定了 2SLS？或者这是重新调整效果？这如何改变事情？ 2SLS 的“调整”效果只是重新调整到更合适的位置吗？
*有关我的数据的更多信息可以在此处查看 什么统计方法来评估已知测量误差变量的影响？ . 2SLS 遵循了这篇文章中有关结构方程建模的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/648158/2sls-does-it-just-rescale-the-instrument-variable</guid>
      <pubDate>Tue, 28 May 2024 16:11:37 GMT</pubDate>
    </item>
    <item>
      <title>将多变量 PDF 转换为基于异常的风险评分（范围为 0 到 1）</title>
      <link>https://stats.stackexchange.com/questions/648157/convert-multivariate-pdf-to-anomaly-based-risk-score-on-scale-0-to-1</link>
      <description><![CDATA[我定义了多个风险因素的多变量正态分布。
目前，风险因素观测值的 PDF 范围从无穷小到最大值 ~2.1。
虽然较小的 PDF 确实表明了观察结果的异常程度，但我希望在可解释的从 0 到 1 的“风险等级”上，其中 1 表示它高度异常，0 表示它符合预期（所有风险）因子值为 0)。
我尝试对 PDF 值使用以下逻辑：
(max_PDF - obs_PDF)/(max_PDF - min_PDF)。
然而，这里的问题是，一部分观测值四舍五入到 1 并接近 1，然后急剧下降到 0。换句话说，尺度本身是非线性的（可能是由于正常假设） ？）。
如果您能提供任何帮助，我们将不胜感激。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648157/convert-multivariate-pdf-to-anomaly-based-risk-score-on-scale-0-to-1</guid>
      <pubDate>Tue, 28 May 2024 15:57:02 GMT</pubDate>
    </item>
    <item>
      <title>3组之间的测量不变性和潜在均值比较</title>
      <link>https://stats.stackexchange.com/questions/648155/measurement-invariance-and-latent-mean-comparison-between-3-groups</link>
      <description><![CDATA[我在 R 中执行了探索性因子分析 (EFA)，然后执行了验证性因子分析 (CFA)，成功使用 TLI、CFI、RMSEA 等指数对双因子结构评估了模型拟合。随后，我将数据分为三个不同的组。然后，我确保了这些组之间的测量不变性，实现了配置、度量和标量不变性。
在最终分析阶段，我的目标是比较这些组中两个因素的潜在均值。例如，我有兴趣确定第 2 组中的因子 1 是否在统计上高于第 3 组。
我的问题是：我应该如何继续比较两个因素和三个组的潜在均值？此外，在进行这些比较时，我应该基于标量模型还是配置模型？
这是我的代码：
适配型号：
odelCFA3_3 &lt;- &#39;
  PTSD_stigma_Factor1 =~ PTperstigma_3 + PTperstigma_2
  
  PTSD_stigma_Factor2 =~ PTperstigma_9 + PTperstigma_8 + PTperstigma_6
  &#39;

适合 &lt;- cfa(modelCFA3_3, 数据 = CFA, 缺失 = &#39;ML&#39;)
摘要（适合，fit.measures = TRUE，标准化=T）

例如：
fitConfigural_PTSD &lt;- cfa(modelCFA3_3, data = mydata, Missing = “ML”, group = “Sample_Group”)
摘要（fitConfigural_PTSD，fit.measures = TRUE，标准化= TRUE）
]]></description>
      <guid>https://stats.stackexchange.com/questions/648155/measurement-invariance-and-latent-mean-comparison-between-3-groups</guid>
      <pubDate>Tue, 28 May 2024 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该控制差异中的单位特定线性时间趋势</title>
      <link>https://stats.stackexchange.com/questions/648153/should-i-control-for-unit-specific-linear-time-trends-in-difference-in-differenc</link>
      <description><![CDATA[我有一个交错的双重差异设置，并且一直在想是否应该在我的模型中包含特定于组/单位的线性时间趋势。
这似乎是文献中的一个常见特征，但也有论文认为这些特定于单位的时间趋势可能会导致负权重和其他问题。
关于何时在双重差分模型中使用/不使用特定于单位的线性时间趋势是否存在共识？
任何总体建议将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648153/should-i-control-for-unit-specific-linear-time-trends-in-difference-in-differenc</guid>
      <pubDate>Tue, 28 May 2024 14:25:15 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型，调查数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648150/linear-mixed-effect-model-survey-data</link>
      <description><![CDATA[使用调查加权数据的混合效应模型！]]></description>
      <guid>https://stats.stackexchange.com/questions/648150/linear-mixed-effect-model-survey-data</guid>
      <pubDate>Tue, 28 May 2024 13:33:32 GMT</pubDate>
    </item>
    <item>
      <title>xy 的平方和大于 x 的平方和 - 怎么可能？</title>
      <link>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</link>
      <description><![CDATA[我按照此教程来可视化 R 平方。该网站表示，我们可以使用 xSS= sum((x -mean(x))^2) 计算 x 的平方和。要找出 x 变量不属于 y 的比例，我们可以采用 x 和 y 的重叠变体code&gt;并从x的平方和中减去它，即我们可以做xSS - xySS。对 ySS 执行相同操作后，我们可以使用欧拉图可视化方差，如 此图（链接到教程中的图）。
但是如果我这样做xSS - xySS我会得到负值！ x 与 y 共享的变体怎么可能比 x 的整个变体还要大呢？
这是我在 R 中所做的：
&lt;前&gt;&lt;代码&gt;库(magrittr)
设置.种子(1)
df &lt;- data.frame(x= rnorm(n= 1000，平均值= 28，sd= 4))
df$y &lt;- 2*df$x + 10*rnorm(n= n，平均值= 0，sd= 1)

ss_xy &lt;- lm(公式= y ~ x, 数据= df)%&gt;% aov() %&gt;% 摘要() %&gt;% .[[1]] %&gt;% .[“x” ，“平方和”]
ss_x &lt;- sum((df$x - 平均值(df$x))^2)
ss_x &lt; ss_xy
＃ 真的
]]></description>
      <guid>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</guid>
      <pubDate>Tue, 28 May 2024 12:27:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GLM 拟合与使用逻辑函数的直接拟合不同</title>
      <link>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</link>
      <description><![CDATA[我在数据中发现，使用逻辑函数的直接拟合与使用二项式分布和 logit 链接函数的 GLM 拟合相比，提供了不同且更好的 (R^2) 拟合。我天真地期望得到相同的结果，但现在无法解释为什么情况并非如此。
正如下面评论中所指出的，这可能是由于不同的最小化过程造成的。
假设 fit 和 glm 使用的最小化是相同的，人们期望相同的拟合结果吗？
下面的示例假设相同的最小化过程。
这里有一些 matlab 代码来说明这个问题
直接配合
&lt;预&gt;&lt;代码&gt;x=[-50.4 -39.6 -29.7 -21.6 -18.0 -14.4 -9.9 -8.1 -6.3 -3.6 -1.8 0.0 1.8 3.6 6.3 8.1 9.9 14.4 18.0 21.6 29.7 39.6 50.4]&#39;;
y=[0.0 0.0 0.0 0.0 0.1 0.1 0.2 0.2 0.2 0.3 0.3 0.4 0.5 0.5 0.6 0.6 0.7 0.8 0.9 0.9 1.0 1.0 1.0]&#39;;

ft=fittype(&#39;exp(b0+b1*x)/(1 + exp(b0+b1*x))&#39;,&#39;indep&#39;,&#39;x&#39;);
stp=[-0.5 0.1];
[mo, gf] = fit(x,y,ft,&#39;起始点&#39;,stp);

莫= 

     通用型号：
     mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
     系数（95% 置信区间）：
       b0 = -0.4201 (-0.4983, -0.3419)
       b1 = 0.1268 (0.1167, 0.1368)

GLM部分
data=表(y,x);

modelspec{1}=&#39;y ~ x&#39;;
mdl1 = fitglm(数据,模型规格{1},...
    &#39;分布&#39;,&#39;二项式&#39;,&#39;链接&#39;,&#39;logit&#39;);

广义线性回归模型：
    logit(y) ~ 1 + x
    分布 = 二项式

估计系数：
                   估计 SE tStat pValue 
                   ________ ________ ________ ________

    （截距）-0.42089 0.60619 -0.69432 0.48748
    × 0.13401 0.060266 2.2236 0.026175

差异并不大，但很明显，尤其是在预期结果相同的情况下。
这是另一个数据示例（这个是不对称的，我知道根据定义拟合将是对称的）。
&lt;预&gt;&lt;代码&gt;y=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 0.7, 0.8 , 0.8, 1.0];

结果
&lt;前&gt;&lt;代码&gt;莫= 
     通用型号：
     mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
     系数（95% 置信区间）：
       b0 = 0.07416 (-0.793, 0.9413)
       b1 = 1.606 (-0.1469, 3.359)

mdl1= 
广义线性回归模型：
    logit(y) ~ 1 + x
    分布 = 二项式

估计系数：
                   估计 SE tStat pValue 
                   ________ ________ ________ ________

    （截距）-0.35437 0.61901 -0.57247 0.567
    × 0.14666 0.066227 2.2145 0.026791

这里的差异是巨大的。
对于输出不同的原因有什么简单的解释吗？
（我使用 nlsLM 和 glm 在 R 中检查相同的数据，并得到相同的结果）]]></description>
      <guid>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</guid>
      <pubDate>Tue, 28 May 2024 12:20:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中将 IV 回归与 ivreg 进行交互？</title>
      <link>https://stats.stackexchange.com/questions/648152/how-do-i-interperate-iv-regressions-with-ivreg-in-r</link>
      <description><![CDATA[我无法理解 R 中 ivreg 包中 ivreg 函数的回归输出。
例如...

如果我担心变量“收入”可能存在的内生性，所以我使用“平衡”作为IV，Wu-Hausman测试具有静态显着性，例如模型iv.reg中的测试支持变量“收入”是变量。是内生的，还是只是 IV 模型与 OLS 模型不同？

弱工具测试是否提供了变量“收入”的证据？和“平衡”考虑到它具有统计显着性（如 iv.reg 中的那样），它们是否相关？

当我使用的工具变量多于解释性内生变量时，如何解释摘要，例如 iv.reg2 中的摘要？


预先感谢您提供的任何帮助。
库(ISLR2)
库（ivreg）

iv.reg&lt;-ivreg(评级~限额+收入|限额+​​余额,数据=信用)
摘要(iv.reg)

称呼：
ivreg(公式 = 评级 ~ 限额 + 收入 | 限额 + 余额, 数据 = 信用)

残差：
    最小 1Q 中值 3Q 最大 
-34.720 -8.625 -1.202 8.616 31.687 

系数：
              估计标准。误差t值Pr(&gt;|t|)    
(截距) 37.3754873 1.5089830 24.769 &lt;2e-16 ***
限值 0.0679431 0.0005658 120.073 &lt;2e-16 ***
收入 -0.0925933 0.0410875 -2.254 0.0248 *  

诊断测试：
                 df1 df2 统计 p 值    
弱工具 1 397 396.05 &lt; 2e-16 ***
吴-豪斯曼 1 396 16.42 6.11e-05 ***
萨甘 0 不适用 不适用    



iv.reg2&lt;-ivreg(评级~限制+收入|限制+收入+评级,数据=信用)
摘要(iv.reg2)

称呼：
ivreg(公式 = 评级 ~ 限额 + 收入 | 限额 + 收入 + 评级, 
    数据=信用）

残差：
    最小 1Q 中值 3Q 最大 
-31.895 -8.542 -1.302 8.540 29.729 

系数：
             估计标准。误差t值Pr(&gt;|t|)    
(截距) 3.874e+01 1.439e+00 26.918 &lt;2e-16 ***
极限 6.657e-02 4.348e-04 153.124 &lt;2e-16 ***
收入 2.075e-02 2.847e-02 0.729 0.467    
---


]]></description>
      <guid>https://stats.stackexchange.com/questions/648152/how-do-i-interperate-iv-regressions-with-ivreg-in-r</guid>
      <pubDate>Tue, 28 May 2024 12:05:42 GMT</pubDate>
    </item>
    <item>
      <title>使用收缩估计的 GAM 中的有效置信区间</title>
      <link>https://stats.stackexchange.com/questions/648136/valid-confidence-intervals-in-gam-s-using-shrinkage-estimation</link>
      <description><![CDATA[在此博客文章中：
https://www.fharrell.com/post/improve-research/
它指出：
“当参数受到惩罚时，频率论范式不提供置信区间或 p 值”。
我想知道这如何应用于广义可加模型（GAM）。标准软件例如当使用收缩（惩罚）估计时，R 中的 gam 和 mgcv 包提供置信区间，即使我们在 mgcv::gam() 中指定附加惩罚 (select=TRUE)。
那么这些置信区间如何有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/648136/valid-confidence-intervals-in-gam-s-using-shrinkage-estimation</guid>
      <pubDate>Tue, 28 May 2024 09:33:04 GMT</pubDate>
    </item>
    <item>
      <title>在这个特定案例中学到了什么概率分布？</title>
      <link>https://stats.stackexchange.com/questions/648135/what-probability-distribution-is-learned-in-this-specific-case</link>
      <description><![CDATA[我一直在阅读论文和博客文章，其中神经网络的训练被定义为学习数据的一些潜在概率分布。
想象一下，您编写了 CNN 来输出硬币的图像是正面还是反面。
这里学习的概率分布是什么？您能举出其他具体例子吗？
这是我认为的一个例子。
想象一个骰子，其输出取决于输入，因此 P(2|1) 与 P(3|1) 不同。
因此，网络被训练来学习 P(X|Y)，但在这种情况下，我们可以很容易地看到每个输入值都有一个潜在的概率分布，并且模型将学习这些分布，因为我们借用了来自该分布。
因此，人们可以想象在现实世界中，每个骰子的数字都具有相关的概率分布。
但我无法想象将猫的特定图像映射到猫或狗的概率。
我在图像示例中没有看到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/648135/what-probability-distribution-is-learned-in-this-specific-case</guid>
      <pubDate>Tue, 28 May 2024 09:32:22 GMT</pubDate>
    </item>
    <item>
      <title>分层生存模型的后验不一致</title>
      <link>https://stats.stackexchange.com/questions/648123/inconsistent-posterior-from-hierarchical-survival-model</link>
      <description><![CDATA[我在斯坦论坛上问过这个问题，但没有人回复，所以在这里双重发帖。我真的很感激一些见解，因为我完全陷入困境。
我正在尝试使用威布尔模型进行分层生存建模。我可以很好地拟合非池化模型和分层模型，但我对后一个模型产生的后验感到困惑。
我使用 R 包生存中的肺部数据集，以年龄和 ph.karno 作为协变量。在分层模型中，我为 ph.karno 拟合了单独的效果。
合并模型产生 ph.karno 效应的集中 (sd = 0.06) 后验，其中 90% CI 不包含 0。在分层模型中，性别特异性效应 sd &gt; 2、人口分布的sd&gt; 3. 为两性拟合单独的模型会产生与合并模型类似的后验结果。
下面是池模型（左）和分层模型（右）后验的比较。对我来说，分层模型的后验没有意义，因为我希望它与池化模型一致。您能分享一下为什么会发生这种情况吗？

代码如下：
图书馆（生存）
图书馆（tidyverse）

＃＃ 数据 **************************

my_data &lt;- 肺
my_data &lt;- my_data[, c(“年龄”, “ph.karno”, “状态”, “时间”, “性别”)]
my_data &lt;- my_data %&gt;% drop_na

# 标准化
my_data[, c(&quot;年龄&quot;, &quot;ph.karno&quot;)] &lt;- apply(my_data[, c(&quot;年龄&quot;, &quot;ph.karno&quot;)],
                                          保证金 = 2，
                                          FUN = 函数(X) {(X-均值(X))/sd(X)})


## 合并************************

＃ 公式
公式1 &lt;- Paste0(“时间 | cens(1-状态) ~ 年龄 + ph.karno”)


＃ 合身
fit1 &lt;-brm(公式1,
           数据=我的数据，
           家庭=威布尔（），
           先验 = 先验(正常(0, 1), 类别 = b), 
           链条 = 1)


## 分层 ******************

＃ 公式
Formula2 &lt;- Paste0(&quot;时间 | cens(1-status) ~ 年龄 + ph.karno + (1 + ph.karno || 性别)&quot;)


＃ 合身
fit2 &lt;-brm(公式2,
           数据=我的数据，
           家庭=威布尔（），
           先验 = 先验(正常(0, 1), 类别 = b), 
           链= 1， 
           控制=列表（adapt_delta = 0.99））


＃＃ 阴谋 ***********************

p1 &lt;- mcmc_areas(fit1, regex_pars = &quot;b&quot;, prob = 0.9)
p2 &lt;- mcmc_areas(fit2, regex_pars = &quot;b_|r_&quot;, prob = 0.9)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648123/inconsistent-posterior-from-hierarchical-survival-model</guid>
      <pubDate>Tue, 28 May 2024 06:56:58 GMT</pubDate>
    </item>
    </channel>
</rss>