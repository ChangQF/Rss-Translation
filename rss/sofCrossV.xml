<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 08 Jul 2024 06:22:21 GMT</lastBuildDate>
    <item>
      <title>理解经验贝叶斯</title>
      <link>https://stats.stackexchange.com/questions/650654/understanding-empirical-bayes</link>
      <description><![CDATA[我正在尝试理解经验贝叶斯的基础知识。我发现自己很难理解这一点，所以我尝试创建一个涉及估计硬币成功概率的玩具示例。
1) 传统贝叶斯分析（Beta-二项式共轭）：
考虑一系列 $n$ 次硬币抛掷，其中我们观察到 $X$ 次正面。假设正面朝上的真实概率为 $\theta$，则观察到 $X$ 正面朝上的可能性为二项式：
$$
P(X|\theta) = \binom{n}{X} \theta^X (1-\theta)^{n-X}
$$
为正面朝上概率选择 Beta 先验分布 $\theta$：
$$
P(\theta) = \text{Beta}(\alpha, \beta) = \frac{\theta^{\alpha-1} (1-\theta)^{\beta-1}}{B(\alpha, \beta)}
$$
使用贝叶斯定理，后验分布与似然乘以先验成正比：
$$
P(\theta|X) \propto P(X|\theta) P(\theta)
$$
代入二项式似然和 Beta 先验，我们得到：
$$
P(\theta|X) \propto \theta^X (1-\theta)^{n-X} \cdot \theta^{\alpha-1} (1-\theta)^{\beta-1}
$$
$$
P(\theta|X) \propto \theta^{X+\alpha-1} (1-\theta)^{n-X+\beta-1}
$$
因此，后验分布也是一个Beta 分布：
$$
P(\theta|X) = \text{Beta}(X + \alpha, n - X + \beta)
$$
2) 经验贝叶斯：
在经验贝叶斯中，先验的参数似乎是根据数据估计出来的，而不是事先选择的。
对我来说，使用矩量法（而不是 MLE）来估计 Beta 先验的参数 $\alpha$ 和 $\beta$ 更有意义。
成功的样本均值 $\hat{\theta}$ 和样本方差 $s^2$可以使用概率：
$$
\hat{\theta} = \frac{\sum_{i} X_i}{\sum_{i} n_i}
$$
$$
s^2 = \frac{\sum_{i} X_i (n_i - X_i)}{n_i^2 (n_i - 1)}
$$
使用矩方法，我们将样本均值和方差等同于 Beta 分布的均值和方差：
$$
\hat{\theta} = \frac{\alpha}{\alpha + \beta}
$$
$$
s^2 = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}
$$
求解这些方程中的 $\alpha$ 和 $\beta$，我们得到：
$$
\alpha = \hat{\theta} \left( \frac{\hat{\theta} (1 - \hat{\theta})}{s^2} - 1 \right)
$$
$$
\beta = (1 - \hat{\theta}) \left( \frac{\hat{\theta} (1 - \hat{\theta})}{s^2} - 1 \right)
$$
现在，我们继续分析，就像它是常规贝叶斯：
可能性保持不变：
$$
P(X_i|\theta_i) = \binom{n_i}{X_i} \theta_i^{X_i} (1 - \theta_i)^{n_i - X_i}
$$
先验现在基于数据：
$$
P(\theta_i) = \text{Beta}(\hat{\alpha}, \hat{\beta})
$$
后验分布为：
$$
P(\theta_i|X_i) \propto \theta_i^{X_i + \hat{\alpha} - 1} (1 - \theta_i)^{n_i - X_i + \hat{\beta} - 1}
$$
$$
P(\theta_i|X_i) = \text{Beta}(X_i + \hat{\alpha}, n_i - X_i + \hat{\beta})
$$
这是正确的想法吗？经验贝叶斯与传统贝叶斯完全相同......但它使用数据来估计先验的参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/650654/understanding-empirical-bayes</guid>
      <pubDate>Mon, 08 Jul 2024 05:39:30 GMT</pubDate>
    </item>
    <item>
      <title>基于二次型的相关系数分布</title>
      <link>https://stats.stackexchange.com/questions/650649/distribution-of-the-correlation-coefficient-based-on-quadratic-forms</link>
      <description><![CDATA[令 $x,y$ 为两个独立随机相关向量，服从同一多元（实数或复数）中心正态分布，令 $A$ 为非负线性算子。
我们可以在这里、这里和那里读到二次型$x^\ast Ax$（带共轭转置）以卡方加权和的形式分布。我的问题如下：
$\displaystyle \frac{|y^\ast Ax|^2}{x^\ast Ax \cdot y^\ast Ay}$ 的分布是什么？
我不指望得到一个很好的闭式，但也许可以得到一些关于超越 beta 定律的渐近近似的见解，这是 $(\text{Tr}A)^2\gg Tr(AA^\ast)$ 的正确近似。]]></description>
      <guid>https://stats.stackexchange.com/questions/650649/distribution-of-the-correlation-coefficient-based-on-quadratic-forms</guid>
      <pubDate>Mon, 08 Jul 2024 00:37:21 GMT</pubDate>
    </item>
    <item>
      <title>第一/第二选择与简单概率的等价性——我不这么认为</title>
      <link>https://stats.stackexchange.com/questions/650647/equivalence-of-first-second-choice-with-naive-probability-i-dont-buy-it</link>
      <description><![CDATA[我希望更好地理解Blitzstein and Huang (2015)（第 1 章，练习 31，第 35 页）中的以下问题：

一个罐子里有 $r$ 个红球和 $g$ 个绿球，其中 $r$ 和 $g$ 是固定的正整数。从罐子中随机抽取一个球（所有可能性都相同），然后随机抽取第二个球。
(a) 直观地解释为什么第二个球是绿色的概率与第一个球是绿色的概率相同。

现在，我明白了，在进行实验之前，理论上没有证据可以作为条件，并且这两个概率是等价的。没有哪个球比其他球更容易被选中。但在实践中，我不这么认为。
第一个球是绿色的几率是 $g/(r + g)$。抽取一个球时，严格来说只有两种可能的结果：要么是绿色，要么是红色。如果是绿色，第二个球是绿色的几率是$(g-1) / (r + g - 1)$。如果第一个球是红色的，第二个球是绿色的几率是$g/ (r + g -1)$。这两个都不等同于$g/(r + g)$。虽然这确实是关于已经发生的实验的说法，而不是尚未发生的实验的说法，但它仍然让我感觉作者的说法实际上不包含任何信息，类似于：“我们不知道如何在实验前调整几率，因为实验还没有发生。”
有人能帮我理解一下，不是我为什么错了，而是为什么作者的说法包含有用的信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/650647/equivalence-of-first-second-choice-with-naive-probability-i-dont-buy-it</guid>
      <pubDate>Sun, 07 Jul 2024 23:16:53 GMT</pubDate>
    </item>
    <item>
      <title>事件比例的抽样分布</title>
      <link>https://stats.stackexchange.com/questions/650646/sampling-distribution-of-the-proportion-of-events</link>
      <description><![CDATA[对于具有 $l \ge 2$ 个类别的分类变量，每个类别中事件比例的抽样分布是什么？这些显然不是独立的，因为它们加起来为 1。
这些变量是否为序数有关系吗？
对于二元变量，众所周知的结果是事件比例具有正态分布，其平均值为 $p$，方差为 $p(1-p)/n$。
对于任意数量的类别，结果是这个结果的概括吗？

我见过提到的多元正态分布，具有特定的协方差矩阵。但我不确定它是如何工作的，因为抽取的结果不能保证总和为 1。
我知道在贝叶斯估计中狄利克雷分布用于此。理想情况下，对于我的应用程序，我正在寻找一个频率论解决方案，只是为了让事情变得简单。
一个“自然”的解决方案可能是从多项式中抽取（将概率参数设置为样本比例），然后除以试验次数。我没见过任何地方提到过这一点。这有名字吗？如果这确实是解决方案，为什么它不是 $l = 2$ 类别（我们将使用二项式）的解决方案？

好的参考是一个加分项。有人已经在 R 中实现的解决方案也是一个加分项。]]></description>
      <guid>https://stats.stackexchange.com/questions/650646/sampling-distribution-of-the-proportion-of-events</guid>
      <pubDate>Sun, 07 Jul 2024 22:56:04 GMT</pubDate>
    </item>
    <item>
      <title>ICC 和 Pearson r 相关性的解释</title>
      <link>https://stats.stackexchange.com/questions/650644/interpretation-of-icc-and-pearsons-r-correlation</link>
      <description><![CDATA[我正在计算两个不同时间点的响应值的组内相关系数 (ICC) 值。我还使用 Pearson 的 $r$ 对不同时间点的响应值进行关联。得出的值几乎相同。这在概念上有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650644/interpretation-of-icc-and-pearsons-r-correlation</guid>
      <pubDate>Sun, 07 Jul 2024 21:08:28 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中日期作为随机效应会极大地改变系数估计</title>
      <link>https://stats.stackexchange.com/questions/650642/date-as-random-effect-in-mixed-model-strongly-changes-coefficient-estimates</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650642/date-as-random-effect-in-mixed-model-strongly-changes-coefficient-estimates</guid>
      <pubDate>Sun, 07 Jul 2024 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>一组可能相关的随机变量的平均值的方差是否小于它们各自方差的平均值？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</link>
      <description><![CDATA[一组可能相关的随机变量的均值的方差是否小于或等于它们各自方差的平均值？
从数学上讲，给定可能相关的随机变量$X_1, X_2, ..., X_n$：
设$\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$为这些随机变量的均值。
以下说法是否正确：
$$\text{Var}(\bar{X}) \leq \frac{1}{n}\sum_{i=1}^n \text{Var}(X_i)$$
我知道对于独立随机变量，我们有以下等式：
$$\text{Var}(\bar{X}) = \frac{1}{n^2}\sum_{i=1}^n \text{Var}(X_i)$$
这显然满足不等式。但是，我不确定这是否适用于因变量。
如果这个不等式成立，是否有证明或直观的解释？
如果它并非总是成立，那么在哪些条件下它成立？以下不等式呢？
$$\text{Var}(\bar{X}) \leq \text{Max}_{i=1}^n \text{Var}(X_i)$$
任何见解、证明或反例都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</guid>
      <pubDate>Sun, 07 Jul 2024 15:39:10 GMT</pubDate>
    </item>
    <item>
      <title>关于推导 MAP 估计量的基本问题</title>
      <link>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</link>
      <description><![CDATA[假设我们有一个随机过程$X(t, u)$，其由$t$和$u$参数化，并生成数据$x$。我们对 $u$ 也有一个先验，$p(u)$。
我说得对吗？找到 仅 $t$ 的最大后验 (MAP) 估计的表达式应该是
$$
t_{MAP} = \underset{t}{\operatorname{argmax}} \int p(x | t, u) p(u) du = \underset{t}{\operatorname{argmax}} p(x|t)
$$
也就是说，你会将干扰参数边缘化，对吗？
现在假设 $U\sim \mathcal{N}[\hat{u}, C_u]$ 和 $X \mid u, t \sim \mathcal{N}[M(t) u, C_x]$。
说 $p(x | t)$ 等于 $M(t) U$ 的 pdf 正确吗？也就是说，
$$X \mid t \sim \mathcal{N}[M(t)\hat{u}, M(t)C_uM(t)^\top]$$
换一种说法，更一般地说，推导出 $f(U, t)$ 的分布是否会得到与 $\int p(x|t, u)p(u)du$ 相同的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</guid>
      <pubDate>Sun, 07 Jul 2024 12:46:11 GMT</pubDate>
    </item>
    <item>
      <title>评估测试图像的最佳时期是什么时候？</title>
      <link>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</link>
      <description><![CDATA[我为图像分类任务创建了一个训练集、一个验证集和一个测试集。然后，我使用训练集进行训练，并对验证集进行评估。因此，下一步是评估测试集，基本上是为了推理。为了选择最佳的 epoch 模型，我通常会检查验证损失。但是，我不确定这种方式是否正确。我将结果添加为图片，并标记了最佳的 train/val 准确率和最低的 train/val 损失。损失函数是交叉熵。

后面的步骤显然是过度拟合，但训练损失仍然越来越低，直到第 25 个 epoch。如果我只检查 val 损失，我可能会选择第 13 个 epoch。或者最高的验证准确率也可能很重要。
我读过一些文章或论坛问题，比如这个、这个、这个和其他几个，但这个话题没有真正的结论。那么，对于这种情况，有没有通用的解决方案，或者我应该以不同的方式考虑每个分类/对象检测任务并做出相应的决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</guid>
      <pubDate>Sun, 07 Jul 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆倾向得分加权有效？</title>
      <link>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</link>
      <description><![CDATA[假设某些治疗 $D = 0, 1$ 对结果 $Y = 0,1$ 的影响受到性别 $S = 0,1$ 的混淆。对 $D$ 对 $Y$ 的因果影响的无混淆估计将使我们估计层内风险，然后在计算其差异之前根据层的流行程度对这些风险进行加权。从数学上讲，我们会计算
$$ E[Y(D=d)] = \sum_s E[Y \mid D=d, S=s] P(S=s) $$
对每个 $d$ 计算差值。如果简单地写出均值估计量的简单差异，就会发现权重不正确，这是造成混杂的原因
$$ E[Y\mid D=d] = \sum_s E[Y \mid D=d, S=s] P(S=s \mid D=D) $$
请注意，通过贝叶斯规则
$$ P(S=s \mid D=D) = \dfrac{P(D=D \mid S=S) P(S=s)}{P(D=d)} $$
它是倾向得分和正确权重的函数$P(S=s)$。但是，简单地用倾向得分的倒数对 $E[Y \mid D=d]$ 的估计值进行加权，就会在 $E[Y \mid D=d]$ 的表达式中留下一个 $1/P(D=d)$ 因子。
那么，为什么 IPTW 会得出正确的因果对比估计值呢？我希望得到一个符合我在此处所写的期望加权和的答案。具体来说，我希望证明 IPTW 可以得出与我提出的第一个方程类似的表达式。

编辑：
这是我自己的尝试
让每个和的权重为
$$ w(s) = \dfrac{1}{\Pr(D=d \mid S=s)}$$
这些不能保证总和为 1，所以让我们计算它们的总和并创建新的、标准化的权重。
$$ \sum_s w(s, d) = \dfrac{1}{\Pr(D=d \mid S=0)} + \dfrac{1}{\Pr(D=d \mid S=1)}$$
寻找共同点...
$$ \sum_s w(s, d) = \dfrac{\Pr(D=d \mid S=1) + \Pr(D=d \mid S=0)}{\Pr(D=d \mid S=1) \times \Pr(D=d \mid S=0)}$$
现在，事情变得糟糕起来。首先我们来承认
$$ \Pr(D=d \mid S=s) = \dfrac{\Pr(S=s \mid D=d) \Pr(D=d)}{\Pr(S=s)}$$
如果我们用分子和分母替换$D$的条件概率，那么$\Pr(D=d)$的因子就会出现。我们在分子中得到一个因子，在分母中得到 2，因此
$$ \sum_s w(s, d) = \dfrac{f(s, d)}{\Pr(D=d)} $$
其中 $f$ 是使用贝叶斯规则重写的表达式。重要的是，我们得到了 $\Pr(D=d)$ 的因子。
现在，定义 $\Omega(s, d) = \dfrac{w(s, d)}{\sum_s w(s, d)} = \dfrac{w(s) \Pr(D=d)}{f(s, d)} = \dfrac{\Pr(D=d)}{\Pr(D=d \mid S=s) f(s, d)} $
因此，使用 $\Omega(s, d)$ 作为权重的加权和具有我们需要抵消“错误”的因子均值差异中的权重。
我的直觉告诉我 $f(s, d) = 1$，但我不确定，而且尚未证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</guid>
      <pubDate>Sun, 07 Jul 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>增强状态空间滤波问题中的 Hessian 表示</title>
      <link>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</link>
      <description><![CDATA[问题
设 $z_t := (x_t, x_{t-1}, x_t^2, x_{t-1}x_t,x_{t-1}x_t,x_{t-1}^2)$，且
$R(x_t) := \sum_{(i,j) \in \{\{0,1,2,3,4\} \otimes \{0,1,2,3,4\} : i+j \le 4\}} w_{i,j} x_t^i x_{t-1}^j$，
因此 $R(\cdot)$ 在 $x_t, x_{t-1}$，但在 $z_t$ 中是二次函数。
在 $R(z)$ 的二阶泰勒展开式中，$R(z^*)$，
$R(z) = R(z^*) + J_R(z^*)(z - z^*) + 0.5 (z - z^*)^\prime H_R(z^*) (z - z^*) $
如何表达雅可比矩阵 $J_R$ 和 Hessian，$H_R$，$R(z_t)$，来解释$z_t$中的项是彼此的函数这一事实？
背景
我正在解决一个困难的过滤问题。
让$x_t$和$y_t$成为标量随机变量。
状态转换动力学可以用以下方式来表征：$x_t | x_{t-1} \sim \mathcal{N}(\Phi x_{t-1},Q)$。
测量方程具有以下动态，$y_t | y_{t-1}, x_t, x_{t-1} \stackrel{\text{approx}}{\sim} \mathcal{N}(A + B y_{t-1} + f(x_t,x_{t-1}), R(x_t,x_{t-1})),$ 其中 $f(\cdot)$ 在 $\tilde{x}_t := (x_t, x_{t-1})^\prime$ 中为 二次 方程，而 $R(\cdot)$ 在 $\tilde{x}_t$ 中为 四次 方程。近似值来自匹配随机积分的矩，但我们现在可以忽略它并假设它完全是高斯的。
到目前为止，我的解决方案是用状态的二阶项来扩充状态空间，$z_t := (\tilde{x}_t^\prime,vec(\tilde{x}_t^\prime \tilde{x}_t)^\prime)^\prime = (x_t, x_{t-1}, x_t^2, x_t x_{t-1},x_{t-1} x_t, x_{t-1}^2 )^\prime$。我可以跟踪 $z_t | z_{t-1}$ 恰好，则 $f(\cdot)$ 在 $z_t$ 中是仿射的，而 $R(\cdot)$ 在 $z_t$ 中是二次的。
据我所知，在我的设置中，卡尔曼滤波器在计算创新的协方差时会失效。设$f(z_t) = \alpha_f + \beta_f z_t$，且$\mathcal{Y}_{t-1} := \{y_{\tau}\}_{\tau = t_0}^{t-1}$则
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + \mathbb{E}[R(z_t) | \mathcal{Y}_{t-1}]$，
其中 $S_t := \mathbb{E}[(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])^\prime | \mathcal{Y}_{t-1}]$。
我目前的计划是取二阶泰勒展开式的期望值 $R(\hat{z}_{t|t-1})$，
$\mathbb{E}[R(z_t)|\mathcal{Y}_{t-1}] = \mathbb{E}[ R(\hat{z}_{t|t-1}) + J_R(\hat{z}_{t|t-1}) (z_t - \hat{z}_{t|t-1}) + 0.5 (z_t - \hat{z}_{t|t-1})^\prime H_R(\hat{z}_{t|t-1})(z_t - \hat{z}_{t|t-1}) |\mathcal{Y}_{t-1}] = R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$
其中 $\hat{z}_{t|t-1} := \mathbb{E}[z_t | \mathcal{Y}_{t-1}]$，从而得到精确的创新协方差公式，
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$。
最后，我的问题是，如果 $z_t$ 中的几个元素是其他元素的函数，我该如何计算 Hessian $H_R(z_t)$？特别是如果，
$R(z_t) = \sum_{(i,j) \in \{0,1,2,3,4\} \otimes \{0,1,2,3,4\}} w_{i,j} x_t^i x_{t-1}^j$，
如何表达 $R(z_t),$ $H_R(z_t)$ 的 Hessian？]]></description>
      <guid>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</guid>
      <pubDate>Sat, 06 Jul 2024 21:17:18 GMT</pubDate>
    </item>
    <item>
      <title>在高方差对数正态分布的总和中，哪个分数来自第一项？</title>
      <link>https://stats.stackexchange.com/questions/650589/in-a-sum-of-high-variance-lognormals-what-fraction-comes-from-the-first-term</link>
      <description><![CDATA[如果 $X_i \overset{\textrm{iid}}{\sim} \text{Lognormal}(0, \sigma^2)$ 其中 $i=1,\ldots,n$ 且 $Y_1 = X_1 / \sum_{j=1}^n X_j$，那么我预期 $Y_1$ 的一个特定*极限分布，即 $ \lim_{\sigma \to \infty} Y_1$，将会非常简单：$1$ 的概率为 $1/n$ 且 $1/n$ 且 $0$ 的概率为 $1-1/n$。有没有（简单的）方法可以证明这一点？
*NB：我感兴趣的是 $\sigma$ 的极限，而不是 $n$。$n$ 不一定很大。]]></description>
      <guid>https://stats.stackexchange.com/questions/650589/in-a-sum-of-high-variance-lognormals-what-fraction-comes-from-the-first-term</guid>
      <pubDate>Sat, 06 Jul 2024 12:05:40 GMT</pubDate>
    </item>
    <item>
      <title>有界变量的非参数单样本均值检验（基于切比雪夫不等式？）</title>
      <link>https://stats.stackexchange.com/questions/650583/non-parametric-one-sample-mean-test-for-a-bounded-variable-based-on-chebyshevs</link>
      <description><![CDATA[问题
我有 $x_1, \ldots , x_n$ i.i.d. 从 r.v. $X$ 中抽取，使得 $0 \leq X \leq 1$，但我无法对分布做出任何其他假设。
我想检验零假设 $E(X) = \mu$。
值得注意的是，我想处理 $P(x_1 = x_2 = \ldots = x_n)$ 不可忽略但存在低概率“极端”的情况观察结果“拯救”总体平均值。
尝试的解决方案
看来，Chebyshev 不等式可用于推导平均值的一般检验（参见 Saw et
al. 1984, https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Finite_samples, ），但该检验的功效有些低，并且没有利用 $X$ 的有界性（因此上限方差约束等）
也有随机算法来确定一定误差内的平均值（例如https://dl.acm.org/doi/abs/10.1016/j.matcom.2019.01.011），但这些算法优化了样本数量，我想在给定固定样本数量的情况下优化功效。
似乎应该知道这个测试的某个版本（甚至在某个地方实施），我觉得我可能缺少一个关键字来搜索这些结果。
在实践中，我发现对于我关心的大多数情况，运行 t 检验效果很好，除了以下情况：$X$ 具有较小的有限支持，而我只观察到少量样本，因此有时会得到所有/几乎所有具有相同值的样本，因此 t 检验的方差估计值不好。
问题基于切比雪夫不等式的广义随机均值估计看起来有些相关，但目前没有答案。
编辑（评论中的示例）：假设我的 $H_0$ 是 $E(X) = 0.5$。我观察了十个样本$x_1 = x_2 = \ldots = x_{10} = 0.49$。我不应该拒绝，因为数据与真实分布完全一致，例如$P(X=0.49) = 19/20, P(X=0.69)=1/20$ 并且对于此分布 $H_0$ 成立。
但是如果我观察到 $x_1 = x_2 = \ldots = x_{10} =0.01$，我会高度自信地拒绝，因为数据意味着 $P(X \leq 0.01) \geq \frac{1}{2}$ 因此要满足 $H_0$ 我需要类似 $P(X \geq 0.99) \geq \frac{1}{2}$，数据与 $p \approx 2^{-10}$ 相矛盾。
我想形式化这种推理。切比雪夫不等式的有界扩展似乎是一个起点。
请注意，对于 t 检验/符号置换检验/引导检验，上述两种情况看起来相同 - 它们会在两种情况下以高置信度拒绝零假设。
还请注意，分布的离散性主要是一种干扰 - 如果我考虑连续密度函数中的窄峰而不是点质量，问题几乎相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/650583/non-parametric-one-sample-mean-test-for-a-bounded-variable-based-on-chebyshevs</guid>
      <pubDate>Sat, 06 Jul 2024 09:38:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么从后验抽样可以很好地估计似然值，而从先验抽样却不好？</title>
      <link>https://stats.stackexchange.com/questions/650506/why-sampling-from-the-posterior-is-a-good-estimate-for-the-likelihood-but-sampli</link>
      <description><![CDATA[在变分自动编码器 (VAE) 中，我们有：
$$
\log p_\theta(x) = \log \left[ \int p_\theta(x \mid z)p(z) \, dz \right]
$$
其中 $ p_\theta(x \mid z) = \mathcal{N}(x; \mu_\theta(z), I) $ 和 $ p(z) = \mathcal{N}(0, I)$。当推导证据下限 (ELBO) 时，通过 Jensen 等式，我们得到：
$$
\log p_\theta(x) \geq \int \log [p_\theta(x \mid z)] p(z) \, dz
$$
据称该积分难以估计，因为 $z$ 是高维的。但是，通过使用重要性抽样和变分分布 $q_\phi(z \mid x)$，ELBO 变为：
$$
\log p_\theta(x) \geq \int \log [p_\theta(x \mid z)] q_\phi(z \mid x) \, dz - \text{KL}(q_\phi(z \mid x) \parallel p(z))
$$
Kullback-Leibler (KL) 散度具有封闭形式，因为 $ q_\phi(z \mid x) = \mathcal{N}(z; \mu_\phi(x), \sigma_\phi(x) I) $。这应该使估计变得容易处理。这怎么可能呢？$p(z) $ 和 $q_\phi(z \mid x)$ 是高斯分布，易于采样。我猜这一切都归结为估计积分所需的样本数量。我认为 $L_2\gg L_1$ 必须具有相似的准确性？如果是这样，为什么会这样？
$$
\mathbb{E}_{q_\phi(x|z)} [p_\theta(x|z)] \approx \frac{1}{L_1} \sum_{l=1}^{L_1} \log p_\theta(x \mid z^{(l)}), \quad z^{(l)} \sim q_\phi(z \mid x) \rightarrow \text{好的估计？}
$$
$$
\mathbb{E}_{p(z)} [p_\theta(x|z)] \approx \frac{1}{L_2} \sum_{l=1}^{L_2} \log p_\theta(x \mid z^{(l)}), \quad z^{(l)} \sim p(z) \rightarrow \text{估计错误？}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/650506/why-sampling-from-the-posterior-is-a-good-estimate-for-the-likelihood-but-sampli</guid>
      <pubDate>Fri, 05 Jul 2024 00:09:57 GMT</pubDate>
    </item>
    <item>
      <title>在数据拆分之前删除异常值还是仅在训练集中删除？</title>
      <link>https://stats.stackexchange.com/questions/623753/deleting-outliers-prior-to-data-splitting-or-only-in-the-training-set</link>
      <description><![CDATA[
我正在处理一个数据集，其中响应变量中有一些异常值，这些异常值实际上是自然结果（不是错误）。我想校准一个模型，然后可以使用该模型来预测训练数据集之外的人群。因此，为了评估其性能，我将我的数据集按 0.85 的比例分为训练和测试组。
我的问题是，是否应该在数据分割之前或之后在训练数据集中删除异常值？我想删除我的异常值，因为它们会降低我的模型对我所谓的普通个体的性能。]]></description>
      <guid>https://stats.stackexchange.com/questions/623753/deleting-outliers-prior-to-data-splitting-or-only-in-the-training-set</guid>
      <pubDate>Fri, 11 Aug 2023 13:01:00 GMT</pubDate>
    </item>
    </channel>
</rss>