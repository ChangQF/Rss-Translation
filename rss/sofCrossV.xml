<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Dec 2024 12:32:13 GMT</lastBuildDate>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受青睐（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，尽管我们刚刚在 CFA 中表明这种类型的测量模型无法很好地拟合我们的数据。
我的问题：
有人能否提供一些合理的解释，为什么对于由同等权重项目组成的分数，报告麦当劳的 omega 是有意义的？

来源：
McNeish，D. (2017)。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>rm-ANOVA 中的事后 Bonferroni 校正：常规调整多少次</title>
      <link>https://stats.stackexchange.com/questions/659007/post-hoc-bonferroni-correction-in-rm-anova-how-many-times-to-adjust-for-convent</link>
      <description><![CDATA[我以为，方差分析后的后验 Bonferroni 校正将需要调整研究中进行的所有统计比较（例如，2 个成对比较 * 10 个变量 = 20）。
然而，我越来越多地注意到，后验 Bonferroni 校正仅适用于对单个变量进行的测试次数的论文。
本文的表 2 就是一个例子。根据脚注，尽管测试了如此多的变量，但调整后的 p 值截止值为 0.0125。
如果有人可以对此进行一些说明，我将不胜感激，非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659007/post-hoc-bonferroni-correction-in-rm-anova-how-many-times-to-adjust-for-convent</guid>
      <pubDate>Fri, 20 Dec 2024 09:58:38 GMT</pubDate>
    </item>
    <item>
      <title>策略改进定理的使用问题</title>
      <link>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</link>
      <description><![CDATA[在 Sutton 和 Barto 的《强化学习》一书（2018 年版）第 99-100 页中，需要证明 $\epsilon$-greedy 是对 $\epsilon$-soft 策略的改进，他们是如何使用策略改进定理的，因为之前讨论的定理适用于确定性策略，而这里并非如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</guid>
      <pubDate>Fri, 20 Dec 2024 08:44:36 GMT</pubDate>
    </item>
    <item>
      <title>使用重复横断面调查数据进行回归分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659004/regression-analysis-using-repeated-cross-sectional-survey-data</link>
      <description><![CDATA[我有一个使用相同调查工具连续 5 年收集的数据集。每年的受访者各不相同，但调查问题保持不变。
我有兴趣研究几个独立变量与分类结果变量 (Y) 之间的关系。

为这五年中的每一年运行单独的逻辑回归模型是否合适？

是否有必要验证受访者的资料在五年内是否一致？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659004/regression-analysis-using-repeated-cross-sectional-survey-data</guid>
      <pubDate>Fri, 20 Dec 2024 08:32:25 GMT</pubDate>
    </item>
    <item>
      <title>E[X|XY] 其中 (X,Y) 是从单位正方形 [0,1]^2 中均匀选取的任意坐标</title>
      <link>https://stats.stackexchange.com/questions/659003/exxy-where-x-y-is-any-coordinate-uniformly-selected-from-the-unit-square-0</link>
      <description><![CDATA[我正在尝试解决这个问题，但不确定我是否正确。
问题：查找 $E[X|XY]$，其中 $(X,Y)$ 是从单位正方形 $[0,1]^2$ 中均匀选择的任何坐标
我尝试过的方法：让 $Z=XY$ 然后 $P(X \leq x | Z=z) = 1 - \int^{1}_{z} \int^{1}_{z/x} dy dx = 1-z+zln(z)$，$ 0&lt;z&lt;1$
我卡在这里，因为我不知道如何获取 $X|Z=z$ 的 PDF，以便我可以继续计算 $E[X|Z=z]$。我做错了什么？还有其他正确的方法吗？（也许我应该使用双重期望定理？）]]></description>
      <guid>https://stats.stackexchange.com/questions/659003/exxy-where-x-y-is-any-coordinate-uniformly-selected-from-the-unit-square-0</guid>
      <pubDate>Fri, 20 Dec 2024 08:00:07 GMT</pubDate>
    </item>
    <item>
      <title>lmer 中嵌套随机效应的排序</title>
      <link>https://stats.stackexchange.com/questions/659002/ordering-of-nested-random-effects-in-lmer</link>
      <description><![CDATA[我在许多不同的来源中读到，在 lmer() 中指定嵌套随机效应可以通过“(1|A) + (1|A:B)”或“(1|A/B)”来完成，其中 B 嵌套在 A 中。然而令人困惑的是，当我使用任一语法运行模型时，随机效应是相同的，但嵌套的顺序在输出中以及在使用 ranef() 函数提取随机效应时会发生变化。任何帮助都将不胜感激，我在下面提供了一个示例输出。]]></description>
      <guid>https://stats.stackexchange.com/questions/659002/ordering-of-nested-random-effects-in-lmer</guid>
      <pubDate>Fri, 20 Dec 2024 07:55:40 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型中，前向过程如何定义马尔可夫链？</title>
      <link>https://stats.stackexchange.com/questions/658991/how-does-the-forward-process-in-diffusion-models-define-a-markov-chain</link>
      <description><![CDATA[我正在尝试对去噪扩散模型形成某种严谨的理解。根据我的理解，前向扩散过程是一个离散时间连续状态空间马尔可夫过程。转换核由给出，
$$
q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I) \tag{1}
$$
但是，我很难将其与我所学的马尔可夫核的定义相协调。

让$\{X_i, i = 1, 2, \ldots\}$成为具有连续状态空间的离散时间马尔可夫过程$S$.然后，马尔可夫核对所有 $x \in S$ 定义为 $P(x, A)$，即从状态 $x$ 到达可测集 $A$ 的概率。


我们也可以根据转换核密度 $p(x, .)$ 来定义它
$$
P(x, A) = \int_{y \in A} p(x, y) \, dy
$$

如何将 $(1)$ 等同于上述定义？此外，在论文中，$x_t$ 被作为样本讨论，但作者指出 $x_T \sim \mathcal{N}(0, I)$ 对于足够大的 $T$。那么 $x_t$ 是随机变量吗？感觉这里有很多概念滥用，所以如果有人能帮助让它更清楚和严谨，那就太好了。感谢您的阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/658991/how-does-the-forward-process-in-diffusion-models-define-a-markov-chain</guid>
      <pubDate>Fri, 20 Dec 2024 02:53:11 GMT</pubDate>
    </item>
    <item>
      <title>多元 PDF 变量变化证明</title>
      <link>https://stats.stackexchange.com/questions/658990/proof-change-of-variables-for-multivariate-pdf</link>
      <description><![CDATA[在阅读规范化流时，我熟悉了一维分布的变量变化。如果 $Z$ 是随机变量，并且 $X=f(Z)$ 是单调的，逆为 $Z = h(X) = f^{-1}(X)$，则我们有：
$$
p_X(x) = \frac{\partial P(X \le x)}{\partial x} = \frac{\partial P(Z \le z)}{\partial z}\big|\frac{\partial z}{\partial x}\big| = p_Z\big(h(x)\big)\big|h&#39;(x)\big|
$$
对于随机向量 $Z$ 和 $X=\mathbf{f}(Z)$，有一个非常相似的公式。
$$
p_X(\mathbf{x}) = p_Z\big(\mathbf{f}^{-1}(\mathbf{x})\big)\Big| \det\big( \frac{\partial\mathbf{f}^{-1}(\mathbf{x})}{\partial \mathbf{x}} \big) \Big|
$$
但我无法正式证明这一点。有什么建议吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658990/proof-change-of-variables-for-multivariate-pdf</guid>
      <pubDate>Fri, 20 Dec 2024 01:46:59 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该产生第 95 分位数的不确定性估计？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>如何针对伽马分布改进 DKW 不等式？</title>
      <link>https://stats.stackexchange.com/questions/658981/how-can-the-dkw-inequality-be-refined-for-the-gamma-distribution</link>
      <description><![CDATA[Dvoretzky-Kiefer-Wolfowitz (DKW) 不等式为经验 CDF $\hat F_n(x)$ 和分布支持面上任意位置的总体 CDF $F_n(x)$ 之间的绝对误差提供了一个统一的、不受分布影响的界限。但是，DKW 界限对于特定分布通常比较宽松。从一般意义上讲，它对于收敛速度最慢的情况也必须成立，但我预计这些界限对于常用分布（如伽马分布）来说过于悲观。
伽马分布对我来说是一个值得入手的起点，因为它与事件发生时间分布相关。我研究了各种离散事件模拟，随着时间的推移，我注意到事件发生时间分布通常与 Gamma 分布（或指数分布等特殊情况）非常吻合。最糟糕的情况是，我看到了似乎是 Gamma 的混合，但这比我想在这篇文章中介绍的内容更为宏大。
对于 Gamma 分布 $\operatorname{Gamma}(\alpha,\beta)$，是否有更严格的误差容差可以利用 Gamma CDF 的属性？例如：

我们能否利用伽马 CDF 的平滑度或尾部行为来推导出更严格的界限？
作为 DKW 不等式的特殊情况，伽马分布是否有具体结果？


我通常通过模拟来处理这类事情。我选择一组总体参数、一系列样本大小和一些重复（例如，根据判断，在 $[10^4, 10^6]$ 中），然后估计所述绝对误差和概率。这些模拟研究并不难设置，但最好只选择一个样本大小，并至少知道我保证的结果正确性的界限。另一件事是，这些模拟研究在样本大小和公差方面也存在估计（抽样）误差，这就引发了一个元问题：我的模拟研究需要多大才能估计样本量？🤭]]></description>
      <guid>https://stats.stackexchange.com/questions/658981/how-can-the-dkw-inequality-be-refined-for-the-gamma-distribution</guid>
      <pubDate>Thu, 19 Dec 2024 18:45:43 GMT</pubDate>
    </item>
    <item>
      <title>本文中的随机分位数残差</title>
      <link>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</link>
      <description><![CDATA[我正在阅读 Emrah Altun 和 Gauss M. Cordeiro 撰写的文章“单位改进的二阶林德利分布：推理和回归建模”。我想复制他们的一个结果。我正在尝试为 Beta 回归制作随机分位数残差图，但我没有得到相同的结果。他们有这个图
$\hskip2in$ 
但是我明白了

使用 qqPlot 和 residuals。并且至少从视觉上看它们并不相似，例如有一个大约为 -3 的值，但在我的例子中却不是这样。我的代码是
y = c(2.640, 0.596, 0.680, 2.190, 4.560, 2.140, 0.410, 
0.530, 0.750, 0.280, 4.390, 3.390, 5.190, 0.800, 2.160, 
2.640, 0.060, 2.549, 0.930, 0.310, 0.540, 7.750, 0.470, 
2.810, 1.760, 3.170, 1.760, 1.010, 0.990, 1.318, 0.550, 
                  0.040、1.374、2.890)
y = y/100
x = c(30.78, 57.87, 121.52, 90.17, 45.39, 11.08, 55.92, 51.54, 
                56.31、43.34、11.64、20.85、21.99、276.22、28.81、27.56、 
                30.6、21.02、5.93、7.24、380.1、15.76、305.44、8.94、 
                48.05、5.41、23.68、3.56、14.53、41.9、 71.7, 162.75, 
61.86, 40.43)
x = x/100
beta_model = betareg(y ~ x)
r_i = residuals(beta_model, type = &quot;quantile&quot;)
car::qqPlot(r_i, main = &quot;Beta&quot;, ylab = &quot;r_i&quot;)

如有任何关于此主题的帮助或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</guid>
      <pubDate>Thu, 19 Dec 2024 16:56:41 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中，部分合并聚类估计值消失或超出总体估计值</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>我得到的部分 McFadden 伪 R^2 为负数。这可能吗？</title>
      <link>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</link>
      <description><![CDATA[对于 R 中的逻辑回归，我尝试分别计算一个预测变量的 McFadden 偏 R 平方。我使用了以下代码，该代码来自这个问题：如何计算 R 中仅一个变量的 McFadden r 平方？
model1 &lt;- glm(Q22_factor ~ Q24_1 + age, family = &quot;binomial&quot;, data = subset_data&quot;)
model_age &lt;- glm(Q22_factor ~ age, family = &quot;binomial&quot;, data = subset_data)

loss_full &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model1, type = &quot;response&quot;)
)

loss_reduced &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model_age, type = &quot;response&quot;)
)
(loss_reduced - loss_full)/(loss_reduced)

在我的数据上使用此代码，我得到了负结果 (-0.269)。有人知道这是否可能，或者我的代码是否出了什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</guid>
      <pubDate>Thu, 19 Dec 2024 12:32:24 GMT</pubDate>
    </item>
    <item>
      <title>针对群组数据的最自然机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级大小 学生编号 智商 小时数 分数 前几名
1 3 3 101 10 98 1
1 3 4 99 19 80 0
1 3 6 130 3 95 0
2 5 4 93 5 50 0
2 5 5 103 9 88 0
2 5 8 112 12 99 0
2 5 1 200 10 100 1
2 5 2 90 19 78 0
3 2 5 100 12 84 0
3 2 7 102 13 88 1

我想建立一个机器学习模型，试图预测谁将成为前几名对于任何给定的 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征，计算班级（即具有最高 Score 的学生）的得分。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中得分最高的概率。
这是我尝试过的：

最简单的方法是对 Score 使用回归，然后确定谁将在班级中取得最高分数。这种方法的问题在于，它不会产生谁最有可能在任何给定类别中获得最高分数的概率。

由于这是一个排名问题，因此自然的学习模型类别是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性分数 列表，而不是概率列表，概率列表在概率方面没有自然解释。


解决这个问题的一个明显方法是在 xgboost 中的相关性分数上应用 softmax，但没有直接有意义的概率解释，如基于能量的模型（如 RBM 的能量函数）。事实上，我曾尝试过这样做，但概率变得非常极端（大多数概率集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是Top上的分类模型，如逻辑回归/决策树。但是，这种方法有两个主要问题。

首先，将每个学生视为训练样本不是一个好方法，因为例如，同一个班级可能有两个非常聪明（高智商）和勤奋（高小时数）的学生，如果很多班级都有很多这样的学生，那么传统的模型（如基于逻辑/树的模型）可能会难以进行训练。
为了解决上述将单个学生视为训练样本的问题，我们可以将每个班级视为一个训练样本。为此，我们“扁平化”我们的数据集并对 Top 进行多类分类：
Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 Hours_1 Hours_2 Hours_3 Hours_4 Hours_5 Score_1 Score_2 Score_3 Score_4 Score_5 Top
1 3 101 99 130 NaN NaN 10 19 3 NaN NaN 98 80 95 NaN NaN 3 
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78 1
3 2 100 102 NaN NaN NaN 12 13 NaN NaN NaN 84 88 NaN NaN NaN 7

这种方法的问题在于，数字每个班级的学生人数不同，因此特征矩阵变得非常稀疏（因为不同班级的学生人数可能非常不同）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data</guid>
      <pubDate>Tue, 17 Dec 2024 11:40:53 GMT</pubDate>
    </item>
    <item>
      <title>Copula 模型是否适合解释橄榄种植园数据的时间动态？</title>
      <link>https://stats.stackexchange.com/questions/658446/is-copula-modeling-suitable-for-accounting-for-temporal-dynamics-in-olive-planta</link>
      <description><![CDATA[我正在开展一个分析橄榄种植园数据的项目，目的是模拟投资成本（Costs）、收入（Revenues）和温度（Temp）随时间的变化关系，并考虑数据的特定时间动态。 目标是为未来的树木种植园生成现实的情景。我的想法是使用 copula。
我拥有的数据包括 10 年的年度记录，其中：

成本代表橄榄种植园所需的投资。
收入代表橄榄销售的回报。
温度是年平均温度。
TempCng是年度温度变化。

由于数据本质上是时间性的（即，成本和收入不是独立的，也不是随时间相同分布的），我的目标是捕捉时间结构，特别是重要的初始投资（成本），其次是收入（收入），只有由于树木需要时间生长，因此需要几年时间才能实现。为了解决这个问题，我在分析中加​​入了时间趋势变量。
这是我目前的方法：
# 软件包
library(VineCopula)
library(copula)

# 为方便起见，使用合成数据
成本 &lt;- c(100, 0, 150, 50, 0, 0, 0, 0, 0)
收入 &lt;- c(0, 0, 0, 50, 0, 225, 100, 0, 150, 5)
温度 &lt;- c(20.00, 21.60, 16.05, 15.68, 17.40, 19.51, 19.87, 19.02, 18.21, 18.18)
TempCng &lt;- c(0.001464764, diff(Temp) / head(Temp, -1))
Years &lt;- seq(2008,2017)

# 创建数据框
OliveTrees &lt;- data.frame(Costs, Revenues, Temp, TempCng, row.names = Years)

# 计算平均值和标准差
mu_C &lt;- mean(Costs)
mu_R &lt;- mean(Revenues)
mu_T &lt;- mean(TempCng)

sigma_C &lt;- sd(Costs)
sigma_R &lt;- sd(Revenues)
sigma_T &lt;- sd(TempCng)

# 规范化数据
OliveTrees$CNorm &lt;- (OliveTrees$成本 - mu_C) / sigma_C
OliveTrees$RNorm &lt;- (OliveTrees$收入 - mu_R) / sigma_R
OliveTrees$TNorm &lt;- (OliveTrees$TempCng - mu_T) / sigma_T

# 应用经验分布
C_dist &lt;- pobs(OliveTrees$CNorm)
R_dist &lt;- pobs(OliveTrees$RNorm)
T_dist &lt;- pobs(OliveTrees$TNorm)

# 时间趋势（年份序列）
S_dist &lt;- pobs(1:nrow(OliveTrees))

# 合并分布
U &lt;- cbind(C_dist, R_dist, T_dist, S_dist)

# 拟合高斯 copula
CopulaModel &lt;- normalCopula(dim = 4, dispstr = &#39;un&#39;)
FittedCopula &lt;- fitCopula(CopulaModel, U, method = &#39;ml&#39;)
CopulaModel@parameters &lt;- coef(FittedCopula)

# 从 copula 进行模拟
set.seed(321)
U &lt;- rCopula(n = nrow(OliveTrees), CopulaModel)

# 对模拟值进行排序以说明时间趋势
U &lt;- U[order(U[, 4]), ]

# 应用逆 CDF 来获取模拟值
C_sim &lt;- quantile(OliveTrees$CNorm, U[, 1])
R_sim &lt;- quantile(OliveTrees$RNorm, U[, 2])
T_sim &lt;- quantile(OliveTrees$TNorm, U[, 3])

# 对模拟值进行非规范化
C_sim &lt;- round(C_sim * sigma_C + mu_C, 2)
R_sim &lt;- round(R_sim * sigma_R + mu_R, 2)
T_sim &lt;- T_sim * sigma_T + mu_T

# 为模拟结果创建数据框
OliveTrees_sim &lt;- data.frame(C_sim, R_sim, T_sim, row.names = Years)
OliveTrees_sim$Temp &lt;- round(OliveTrees$Temp[1] * c(1, cumprod(1 + OliveTrees_sim$T_sim[2:length(OliveTrees_sim$T_sim)])), 2)

我的问题：

这种 copula 方法是否适用于解释橄榄种植园数据的时间动态？具体而言，时间动态是指初始成本很高，随后收入不断增长，由于时间结构的原因，两者并非 IID。

包括时间趋势（以年序列的形式）是否是建模时间依赖性的合适解决方案？

是否有任何文献或研究支持这种方法，或者是否有更好的方法来对数据中的时间依赖性进行建模？

是否有更好的建模方法或改进可以更好地捕捉成本、收入和温度之间的时间动态？


感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658446/is-copula-modeling-suitable-for-accounting-for-temporal-dynamics-in-olive-planta</guid>
      <pubDate>Sun, 08 Dec 2024 10:45:46 GMT</pubDate>
    </item>
    </channel>
</rss>