<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 31 Dec 2024 15:16:19 GMT</lastBuildDate>
    <item>
      <title>降秩回归的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/659397/asymptotic-normality-of-reduced-rank-regression</link>
      <description><![CDATA[我正在尝试遵循 Reinsel、Velu 和 Chen 编写的《多元降秩回归》教科书。我从降秩回归开始
$$
Y_t = C X_t + \epsilon_t \quad \Leftrightarrow \quad Y_t = A B X_{t} + \epsilon_t
$$
我对 $A \in \mathbb{R}^{N \times r}$ 和 $B \in \mathbb{R}^{r \times N}$ 的渐近协方差感兴趣。
我知道基于矩阵的扰动展开，$M = \Sigma_{\epsilon \epsilon}^{-1/2} \widehat{\Sigma}_{yx} \widehat{\Sigma}_{xx}^{-1} \widehat{\Sigma}_{xy} \Sigma_{\epsilon \epsilon}^{-1/2}$ 的特征向量可以围绕 $N = \Sigma_{\epsilon \epsilon}^{-1/2} \Sigma_{yx} \Sigma_{xx}^{-1} \Sigma_{xy} \Sigma_{\epsilon 的特征向量 $V_j$ 展开\epsilon}^{-1/2}$ 获得
$$
\widehat{V}_j \sim V_j + \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[V_j&#39;(M - N)V_i\right] \quad (j = 1, \ldots, r)。
$$
其中 $\lambda^2$ 是与特征向量相关的特征值。然后我就可以得到
$$
\widehat{\Sigma}_{yx} \widehat{\Sigma}_{xx}^{-1} \widehat{\Sigma}_{xy} - \Sigma_{yx} \Sigma_{xx}^{-1} \Sigma_{xy} = C U_T + U_T&#39; C&#39; + U_T&#39; \widehat{\Sigma}_{xx}^{-1} U_T + C (\widehat{\Sigma}_{xx} - \Sigma_{xx}) C&#39;,
$$
其中 $U_T = T^{-1} \sum_{k=1}^T X_k \epsilon_k$ 我删除了最后两个项，因为我假设预测变量是非随机的。然后我可以使用 $\Sigma_{\epsilon \epsilon}^{-1/2}C = \Sigma_{\epsilon \epsilon} A B = V B$ 来获得
$$
\widehat{V}_j \sim V_j + \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[\underbrace{V_j&#39; V B U_T \Sigma_{\epsilon \epsilon}^{-1/2} V_i}_{(a)} + \underbrace{V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2} U_T&#39; B&#39; V&#39; V_i}_{(b)} \right] \quad (j = 1, \ldots, r)。
$$
然后使用克罗内克乘积规则，我可以将 $(a)$ 矢量化为
$$
(V_i&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_j&#39; V B) \text{vec}(U_T)，
$$
并且 $(b)$ 矢量化为
$$
(V_i&#39; V B \otimes V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2}) \text{vec}(U_T&#39;)。
$$
但是，我不知道如何从 $(b)$ 项中删除转置，以分解出 $\text{vec}(U_T)$。我的一个想法是使用交换矩阵 $K_{mn} \text{vec} (U_T&#39;) = \text{vec}(U_T)$，但这无法解释最后一个大 $O_p$ 部分。最终结果应为
$$
T^{1/2} (\widehat{V}_j - V_j) = 
$$
$$
T^{1/2} \sum_{\substack{i \neq j}}^{m} \frac{1}{(\lambda_j^2 - \lambda_i^2)} V_i \left[(V_i&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_j&#39; V B) + (V_j&#39; \Sigma_{\epsilon \epsilon}^{-1/2} \otimes V_i&#39; V B)\right] \operatorname{vec}(U_T) + O_p(T^{-1/2})。
$$
此外，我不确定缩放$T^{1/2}$是如何实现的。这是从$M-N$来的吗？提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659397/asymptotic-normality-of-reduced-rank-regression</guid>
      <pubDate>Tue, 31 Dec 2024 12:04:03 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都不是）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以任何我们所知为真的事物为条件（例如，婴儿出生在银河系），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>线性 PDF 近似 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</link>
      <description><![CDATA[我有一个不完整的数据向量（即缺失数据）。我知道整个数据集遵循帕累托分布，但由于我有缺失数据，因此很难拟合 PDF 并恢复分布的形状参数 alpha（这是我需要的）。
但是，帕累托分布的特征意味着如果我们对 PDF 的 x 和 y 取 log10，结果将是完全线性的。这条线的斜率为 = -(alpha + 1)，所以如果我能找出这条线与我的不完整数据集的关系，我就可以抓住斜率并计算 alpha。
不幸的是，我们无法将“线性分布”拟合到 log10（我的数据），因为线性分布实际上并不存在，违反了 PDF 要求，即分布线下的所有内容都必须 = 1。
是否有可能做这样的事情，可能通过限制线性“分布”来实现到最小值（我的数据）-最大值（我的数据）并标准化为 1？我也尝试了另一种方法，即使用 R 的密度函数进行平滑，并将 y 乘以我拥有的数据点总数（近似“丰度”，见下文），但我想这似乎有点...不雅致。我很感激您对改进或其他前进道路的建议。


# 数据的核密度估计
kde &lt;- density(observed_dbhs, bw = &quot;nrd0&quot;) # 根据需要调整带宽
xmin&lt;-min(observed_dbhs)
kde &lt;- list(
x = kde$x[kde$x &lt;= max(observed_dbhs) &amp; kde$x&gt;=xmin],
y = kde$y[kde$x &lt;= max(observed_dbhs) &amp; kde$x&gt;=xmin]
)

# 过滤 KDE 结果以仅保留接近观察数据的值
filtered_kde &lt;- data.frame(
x = kde$x,
y = kde$y
) %&gt;%
rowwise() %&gt;%
filter(any(abs(x - perceived_dbhs) &lt;= 0.5)) %&gt;%
ungroup()

# 使用过滤值更新 kde$x 和 kde$y
kde &lt;- list(
x = adopted_kde$x,
y = adopted_kde$y
)

# 观察到的总数据
total&lt;- length(observed_dbhs)

# 通过将密度乘以树木总数来估计丰度
estimated_abundance &lt;- kde$y * total

# 应用 log10 转换
log_x &lt;- log10(kde$x) 
log_y &lt;- log10(estimated_abundance)

# 创建一个带有对数转换值的数据框
df &lt;- data.frame(x = log_x, y = log_y) %&gt;%
filter(is.infinite(y) == FALSE)

]]></description>
      <guid>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</guid>
      <pubDate>Tue, 31 Dec 2024 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>统计学中帽子符号的混淆</title>
      <link>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</link>
      <description><![CDATA[学习统计学中的不同符号让我感到困惑。
在基本的线性回归中，我们写：
$$Y = \beta_0 + \beta_1 X + \epsilon$$
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X$$
$$\hat{\epsilon} = y - \hat{y}$$
这是因为误差仅存在于理论模型中，上限位于估计值之上，而残差（$\hat{\epsilon}$）取决于估计量，因此它有一个上限。
除此之外，我越来越困惑。
例如，关于 $Y$ 的边际分布，这两个陈述是否正确？

$$Y \sim N(X^T \beta, \sigma^2) \implies E(Y) = X^T \beta$$
$$Y \sim N(X^T \hat{\beta}, \hat{\sigma}^2) \implies E(Y) = X^T \beta$$

关于 $Y$ 的条件分布，这两个陈述是否正确？

$$E(Y \mid X) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \beta, \sigma^2) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \hat{\beta}, \hat{\sigma}^2) = \beta_0 + \beta_1 X$$

一般来说，我知道一旦你对左边的某个东西取期望，右边就会失去帽子。但我想知道，也许这些陈述中的一些实际上是等价的，只是陈述 1)（在条件和边际陈述中）是简写符号，而其他陈述实际上等同于 1)？
如能帮助澄清有关帽子符号和期望的困惑，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</guid>
      <pubDate>Tue, 31 Dec 2024 02:39:46 GMT</pubDate>
    </item>
    <item>
      <title>分层简单随机抽样的推断</title>
      <link>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</link>
      <description><![CDATA[我想使用分层随机抽样来估计总体概率 $p$，因为我的数据由许多层 $h$ 组成。
在这种情况下，如果我们选择总共 $n$ 个样本，则每层的最佳样本数 $n_h$ 优化如下
$n_h = n\cdot \sqrt{T_h} /(\sum_h \sqrt{T_h})$
其中 $T_h$ 如下
$T_h = (N_h/N)^2({{N_h}\over{N_h -1}}p_h(1-p_h))$
其中 $N$ 为总人口，$N_h$ 为各阶层的数量，$p_h$ 为各阶层的真实概率。因此，当使用分层随机抽样确定来自每个层 $h$ 的最佳样本数 $n_h$ 时，假设每个层 $p_h$ 的真实概率已经已知。 $n_h$ 取决于层大小 $N_h$ 和概率 $p_h$，因此如果 $N_h$ 很大，我们会抽样更多。此外，如果$p_h$在0.5左右，换句话说，如果方差很大，我们就会抽样更多。
那么我想知道使用分层简单随机抽样进行抽样和推断有什么意义？既然我们假设我们知道总体中各层的概率，以便确定最佳样本数，那么是否可以使用$p_h$找出总体的概率？
所以我自己想..我们不假设我们确切地知道$p_h$，但我们几乎知道（可能误差在5％左右？），并使用抽样来计算总体。]]></description>
      <guid>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</guid>
      <pubDate>Tue, 31 Dec 2024 01:10:11 GMT</pubDate>
    </item>
    <item>
      <title>通过比较 R 中的两个热图来计算 Earth Mover 距离得分的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/659384/compute-p-value-of-earth-movers-distance-score-comparing-two-heatmaps-in-r</link>
      <description><![CDATA[我试图比较两个热图，但找不到获得具有统计意义的值的方法。
这里是我的问题：我测量了对 5 种药物的单一反应。单个细胞属于两种条件 A 和 B。基于单细胞反应的总体收集，我生成了这些反应的聚类并确定了“10”个反应概况（此处称为“聚类”）。
为了评估条件 A 和 B 之间的差异，我为每种条件生成了一个热图，表示与每种聚类相关的每种药物作用的细胞比例。
这在某种程度上代表了每种条件对药物组的细胞反应的足迹。我看到模式中存在明显差异，想知道是否有办法定义在接受各种处理的两组中是否分布。
在网上查找，我找到了有关地球移动距离 (EMD) 的信息，并使用 emddist R 包比较两个矩阵。我获得了一个值（如果我理解正确的话），它在某种程度上是我的两个热图之间的差异指数。
现在，我想知道是否有办法将这个值的显著 p 值关联起来？
我如何得出结论，两个热图/分布都“显著”不同（或相同）？
对于我最初的问题，即比较细胞对不同药物的反应分布，我是否走在正确的道路上？
实例胜于文字，因此请在此处找到我当前问题的最小可重现示例：
set.seed(123)
mat1 &lt;- matrix(rnorm(50, 2), 10, 5)
mat1 &lt;- apply(mat1,2, function(x) x/sum(x))
mat1

mat2 &lt;- matrix(rnorm(50, 2), 10, 5)
mat2 &lt;- apply(mat2,2, function(x) x/sum(x))
mat2

这里是生成“足迹”的代码每种情况：
library(ComplexHeatmap)
HT1 &lt;- Heatmap(mat1, cluster_rows = FALSE, cluster_columns = FALSE, name = &quot;matrix1&quot;,column_title = &quot;Condition A&quot;,
column_labels = paste0(&quot;Drug &quot;,1:5), row_labels = paste0(&quot;Cluster &quot;,1:10))
HT2 &lt;- Heatmap(mat2, cluster_rows = FALSE, cluster_columns = FALSE, name = &quot;matrix2&quot;,column_title = &quot;Condition B&quot;,
column_labels = paste0(&quot;Drug &quot;,1:5), row_labels = paste0(&quot;Cluster &quot;,1:10))
HT1 + HT2

最后，我目前尝试的 EMD 计算：
library(emddist)
&gt; emd2d(mat1,mat2)
[1] 0.42168


注意：我正在使用 R，因此非常感谢您提供解决方案或暗示 R 包的建议]]></description>
      <guid>https://stats.stackexchange.com/questions/659384/compute-p-value-of-earth-movers-distance-score-comparing-two-heatmaps-in-r</guid>
      <pubDate>Mon, 30 Dec 2024 22:31:04 GMT</pubDate>
    </item>
    <item>
      <title>在处理现实世界数据时，统计推断中关于总体分布存在的错误假设的后果</title>
      <link>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</link>
      <description><![CDATA[统计推断方法，例如统计假设检验，假设观察到的数据是从总体分布中抽样的。对于现实世界的数据，这是一个很大的简化。例如，imdb.com 上特定电影的评分不是从任何分布中抽样的。相反，它们是多种因素的组合，如演员阵容、演技、声音、观众的情绪等。
据我所知，只要我们能够评估这些假设引入了什么错误，对数据做出错误的假设是完全可以的。例如，我们在机器学习中有一个朴素贝叶斯模型，它假设在给定目标类的情况下，特征是条件独立的。对于许多数据集来说，这是错误的。但我们有一个测试集，即整个数据集的一部分，它使我们能够评估建立在错误假设基础上的这种模型的错误。
在统计假设检验的情况下，我们没有提供评估此类错误的方法。据我所知，当测试集缺失时，统计推断方法的任何结果（例如拒绝零假设）都会受到未知大小的误差的影响，从而使结果完全无用。
我大胆地说统计假设检验对现实世界数据无用，对吗？还是我在这里遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</guid>
      <pubDate>Mon, 30 Dec 2024 21:21:18 GMT</pubDate>
    </item>
    <item>
      <title>哪个包适用于有序 probit 模型（Polr 还是 Odinal）？</title>
      <link>https://stats.stackexchange.com/questions/659381/which-package-to-apply-for-ordered-probit-model-polr-or-odinal</link>
      <description><![CDATA[我正在开发一个有序 probit 模型。我很好奇应该使用哪个包。我正在研究 R 中 MASS 包中的 polr 函数和 ordinal 包中的 clm 函数。考虑到我的研究目标，这两个模型的输出系数水平都是可以解释的。
我想知道研究人员如何决定使用哪个包。]]></description>
      <guid>https://stats.stackexchange.com/questions/659381/which-package-to-apply-for-ordered-probit-model-polr-or-odinal</guid>
      <pubDate>Mon, 30 Dec 2024 20:24:13 GMT</pubDate>
    </item>
    <item>
      <title>如果我们知道总体分布不正常，那么创建参考 Z 分布的置信区间是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</link>
      <description><![CDATA[我正在学习生物学学位的入门统计学课程，在学习生成总体均值的置信区间时，我开始怀疑，如果我们知道原始总体不服从正态分布，这样做是否有意义。据我所知，CLT 在这种情况下没有任何效用，因为我们关心的是创建一个置信区间，其假定机会与原始概率分布（即总体的概率分布）一致。
我遗漏了什么吗？如果没有，评估引用此类理论分布来构建置信区间的正确性的程序是什么？
澄清编辑：
我不是在问 CLT 对抽样分布及其估计量的影响，而是在我们知道总体根本不服从正态分布的情况下，使用渐近正态抽样分布对总体参数进行推断的效用。因此，我的问题是：当抽样分布具有如此不同的分布概率，以至于两个分布看起来完全不同时，我们如何使用正态抽样分布来尝试估计非正态总体的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</guid>
      <pubDate>Sat, 28 Dec 2024 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>ELI5：PCA 和时间序列（股票）数据以及分数和载荷的含义 [重复]</title>
      <link>https://stats.stackexchange.com/questions/659204/eli5-pca-and-timeseries-stock-data-and-the-meanings-of-scores-and-loadings</link>
      <description><![CDATA[我尝试使用 PCA 对时间序列数据（一段时间内的股票收盘价）进行聚类。到目前为止，我所做的是：

获取大量股票的数据（每列代表一只股票，每行代表一个观察值）
规范化数据
获取系数矩阵
对矩阵进行 pca

我现在的步骤是了解结果，尤其是分数和载荷，并使用它来对股票进行聚类，而不是对观察值进行聚类。
虽然我读了很多书，也和 chatGPT 讨论了很多这个话题，但我就是搞不懂在这种情况下载荷和分数的含义，以及这些值中的哪些可以帮助我进行聚类。一旦我得到这个，我就可以简单地使用像 k-means 聚类这样的聚类机制来完成最后的实际步骤。
所以基本上我的问题是：你能解释一下我的例子中分数和负载的含义以及它们的用途吗？
编辑：读了你的评论后，我清楚地意识到，我缺乏对分数的一般了解。遗憾的是，即使阅读了其他帖子的建议答案，我还是无法理解，所以我只会展示我的问题，并希望有人能直接解释它
使用正常数据的 PCA 结果：

基本上，我对我的时间序列数据进行了 pca（每列包含 1 股的时间序列数据）并得到了这个结果。对我来说，载荷（左侧）完全没问题，但显示分数的图表显示的是每个观察值，而不是每个份额
使用转置数据的 PCA 结果：

在这里，我对转置数据做了同样的事情，因此每行都包含有关份额的时间序列信息。因此，载荷是针对每个观察值进行的，但分数图向我展示了每个份额。
由于我的目标是对份额（而不是观察值）进行聚类，并分析结果，因此我想要载荷和份额的分数图。
那么，ELI5，请问这有什么数学原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659204/eli5-pca-and-timeseries-stock-data-and-the-meanings-of-scores-and-loadings</guid>
      <pubDate>Wed, 25 Dec 2024 21:28:19 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习要素（第 44 页），并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i \mid \theta)。
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n \mid \theta)。
$$



观察：

边际：
在情况 1中，由于独立性假设，输入的边际分布分解为$\prod_{i=1}^n P(x_i \mid \theta)$。
在情况 2中，输入的边际分布写为单个项$P(x_1, x_2, \dots, x_n \mid \theta)$，因为没有假设$x_i$。

条件：
在这两种情况下，除去边际，给定$x_i$的$y_i$的条件分布是相同的：
$$
\prod_{i=1}^n P(y_i \mid x_i, \theta)。
$$


这表明，尽管对边际的假设不同，但条件结构并没有不同。

问题：

两种情况下的联合似然方程是否准确，它们是否正确反映了各自的独立性或条件独立性假设？

如果是这样，那么假设$(x_i, y_i)$完全独立（情况 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性，如观察结果所示？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>关于连续值随机变量贝叶斯规则的使用</title>
      <link>https://stats.stackexchange.com/questions/645980/about-the-use-of-bayes-rule-for-continuous-valued-random-variables</link>
      <description><![CDATA[我目前正在学习《统计学习简介及其在 Python 中的应用》这本书，目前我读到的是第 4 章第 4 部分，其中解释了线性判别分析的一般框架：“在这种新方法中，我们分别对每个响应类（即每个 $Y$ 值）中的预测变量 $X$ 的分布进行建模。然后，我们使用贝叶斯定理将这些转换为 $\Pr(Y = k\mid X = x)$ 的估计值”。在书中，我们指出 $f_k(X) ≡ \Pr(X\mid Y = k)$ 是 X 的密度函数，而 $\pi_k$ 表示随机选择的观察结果来自先前
$k$个类（$Y$ 取有限值）的总体
或先验概率。公式为 $$\Pr(Y = k\mid X = x) = \frac{\pi_kf_k(x)}
{\sum_{\ell=1}^K \pi_\ell f_\ell(x)}$$
我完全理解 $X$ 是否取离散值，但是我有点困惑 $X$ 是否取连续值。如果 $Y$ 是离散的，而 $X$ 是连续的，那么贝叶斯规则的等效陈述是什么？您能提供证明的参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645980/about-the-use-of-bayes-rule-for-continuous-valued-random-variables</guid>
      <pubDate>Sat, 27 Apr 2024 21:45:56 GMT</pubDate>
    </item>
    <item>
      <title>面板数据估计与控制变量</title>
      <link>https://stats.stackexchange.com/questions/632380/panel-data-estimation-and-control-variables</link>
      <description><![CDATA[我的本​​科论文与所选东盟国家的排放、减排相关官方发展援助和治理变量之间的关系有关。因此，根据估计模型，我的（不平衡）数据集涉及 9 个国家和大约 10-14 年的数据。我的变量包括：
独立：

减排援助（5 个滞后），
控制腐败/法治
两者之间的相互作用（减排援助 * 控制腐败，5 个滞后）

控制：

lngdpc，
lngdpc^2，
（出口+进口）/gdp，
森林面积占土地面积的百分比（？），
和能源强度/可再生能源消耗（？）`

我的选项包括固定效应、随机效应和合并 OLS。最后两个控制是新增加的。直观地讲，我知道在包含这两个变量之前，我会采用固定效应模型，因为误差项与我的 X（例如，能源强度和 lngdpc）非常明显相关。然而，豪斯曼检验表明，即使控制项很少，我也应该采用随机效应 (Ho)。
在包含后两个控制项（特别是能源强度或可再生能源消耗）后，豪斯曼检验会发生变化。控制能源强度会导致备择假设（和不显著的关键变量），而控制可再生能源消耗会导致零假设。控制后者还会导致 Breusch-Pagan LM 检验表明，合并 OLS 可能更合适。符号也各不相同（例如：固定效应的森林面积为负，随机效应的森林面积为正）。
考虑到数据可用性限制了我可以使用的控制项数量，并且符号不再遵循假设的结果，那么该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/632380/panel-data-estimation-and-control-variables</guid>
      <pubDate>Sun, 26 Nov 2023 19:02:52 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 多输出回归器的超参数调整</title>
      <link>https://stats.stackexchange.com/questions/595657/hyperparameter-tuning-for-xgboost-multi-output-regressor</link>
      <description><![CDATA[我正在尝试使用 RandomizedSearchCV 调整 XGBoost 的超参数。我有五个输出，我猜这可能是我无法运行 RandomizedSearchCV 或 GridSearchCV 来调整超参数的原因。运行此代码：
params = { &#39;max_depth&#39;: [3, 5, 6, 10, 15, 20],
&#39;learning_rate&#39;: [0.01, 0.1, 0.2, 0.3],
&#39;subsample&#39;: np.arange(0.5, 1.0, 0.1),
&#39;colsample_bytree&#39;: np.arange(0.4, 1.0, 0.1),
&#39;colsample_bylevel&#39;: np.arange(0.4, 1.0, 0.1),
&#39;n_estimators&#39;: [100, 500, 1000]}

xgbr = xgb.XGBRegressor(seed = 20)

clf = RandomizedSearchCV(estimator=xgbr,
param_distributions=params,
scoring=&#39;neg_mean_squared_error&#39;,
n_iter=25,
verbose=1)

clf.fit(X_train, Y_train)
print(&quot;最佳参数：&quot;,clf.best_params_)
print(&quot;最低 RMSE：&quot;,(-clf.best_score_)**(1/2.0))

我收到此错误：
UserWarning：一个或多个测试分数是非有限的：[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
nan nan nan nan nan nan nan]
warnings.warn(

Y_train 中有多个输出是导致此问题的原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/595657/hyperparameter-tuning-for-xgboost-multi-output-regressor</guid>
      <pubDate>Mon, 14 Nov 2022 15:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何计算转置卷积？</title>
      <link>https://stats.stackexchange.com/questions/587634/how-to-calculate-the-transposed-convolution</link>
      <description><![CDATA[正在为深度学习的期末考试做准备。我正在尝试解决以下问题：

计算输入 $A$ 和内核 $K$ 的转置卷积：
$$
A=\begin{pmatrix}1 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 1
\end{pmatrix},\quad K=\begin{pmatrix}1 &amp; 0\\
1 &amp; 1
\end{pmatrix}
$$

我似乎找不到用于计算转置卷积的公式（只找到了计算维度的公式）。我知道卷积公式是：
$$
G(i,j)=\sum_{u=-k}^{k}\sum_{v=-k}^{k}K(u,v)A(i-u,j-v)
$$
但是如何计算转置卷积呢？
在视频中，我看到了以下示例：

对于$2\times2$ 内核和图像可看到：
$$
\begin{align*}
&amp;K_{0,0}\star^{T}A=2\star^{T}\begin{pmatrix}3 &amp; 1\\
1 &amp; 5
\end{pmatrix}=\begin{pmatrix}6 &amp; 2 &amp; 0\\
2 &amp; 10 &amp; 0\\
0 &amp; 0 &amp; 0
\end{pmatrix}&amp;&amp;K_{0,1}\star^{T}A=0\star^{T}\begin{pmatrix}3 &amp; 1\\
1 &amp; 5
\end{pmatrix}=\begin{pmatrix}0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0
\end{pmatrix}\\&amp;K_{0,1}\star^{T}A=4\star^{T}\begin{pmatrix}3 &amp; 1\\
1 &amp; 5
\end{pmatrix}=\begin{pmatrix}0 &amp; 12 &amp; 4\\
0 &amp; 4 &amp; 20\\
0 &amp; 0 &amp; 0
\end{pmatrix}&amp;&amp;K_{1,1}\star^{T}A=1\star^{T}\begin{pmatrix}3 &amp; 1\\
1 &amp; 5
\end{pmatrix}=\begin{pmatrix}0 &amp; 0 &amp; 0\\
0 &amp; 3 &amp; 1\\
0 &amp; 1 &amp; 5
\end{pmatrix}
\end{align*}
$$
然后你有：
$$
A&#39;=\begin{pmatrix}6 &amp; 2 &amp; 0\\
2 &amp; 10 &amp; 0\\
0 &amp; 0 &amp; 0
\end{pmatrix}+\begin{pmatrix}0 &amp; 12 &amp; 4\\
0 &amp; 4 &amp; 20\\
0 &amp; 0 &amp; 0
\end{pmatrix}+\begin{pmatrix}0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0
\end{pmatrix}+\begin{pmatrix}0 &amp; 0 &amp; 0\\
0 &amp; 3 &amp; 1\\
0 &amp; 1 &amp; 5
\end{pmatrix}=\begin{pmatrix}6 &amp; 14 &amp; 4\\
2 &amp; 17 &amp; 21\\
0 &amp; 1 &amp; 5
\end{pmatrix}
$$
但我似乎无法弄清楚如何为 $3\times 3$ 图像和 $2\times 2$ 内核制作它。
我确实知道输出的暗淡应该是 $4\times 4$，因为：
$$
\begin{cases}
H=(3-1)\cdot1+2-2\cdot0=4\\
W=(3-1)\cdot1+2-2\cdot0=4
\end{cases}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/587634/how-to-calculate-the-transposed-convolution</guid>
      <pubDate>Sat, 03 Sep 2022 10:00:01 GMT</pubDate>
    </item>
    </channel>
</rss>