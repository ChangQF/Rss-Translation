<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 22 Dec 2023 15:13:40 GMT</lastBuildDate>
    <item>
      <title>MDS 和 Isomap 应用于相同的预计算距离</title>
      <link>https://stats.stackexchange.com/questions/635510/mds-and-isomap-applied-to-the-same-precomputed-distances</link>
      <description><![CDATA[我对 Isomap 的理解是，它是一个两步过程：首先计算样本之间的成对（测地线）距离，然后通过 MDS 来表示较低维空间中的距离矩阵。
下面，我提供sklearn MDS 和 Isomap 与相同的预先计算的距离矩阵，我恢复了 2D 表示：

结果表明，当 MDS 和 Isomap 提供相同的预计算距离矩阵时，尽管距离排名大致相同，但确切的结果可能有质的不同。例如，BD 使用 MDS 时距离较远，但使用 Isomap 时距离较近，并且 Isomap 也比 MDS 具有更强的聚类性。差异不仅仅是轮换的。
在相同的预先计算距离上出现不同行为的原因是什么？
图中的测试数据和代码：
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
从 sklearn.manifold 导入 MDS、Isomap

#测试数据-5个特征之间的Spearman r矩阵
特征名称 = [&#39;A&#39;、&#39;B&#39;、&#39;C&#39;、&#39;D&#39;、&#39;E&#39;、&#39;F&#39;]
Spearman_r = np.random.uniform(size=[len(feature_names)] * 2)

#将相关性转换为距离
距离 = 1 - 绝对值(spearman_r)

#确保距离矩阵对称
距离 = (距离 + 距离.T) / 2
np.fill_diagonal（距离，0）

#Fit MDS 和 Isomap
np.随机.种子(0)
mds_坐标 = MDS(n_components=2,
                      相异性=&#39;预先计算&#39;,
                      random_state=0).fit_transform(距离)
np.随机.种子(0)
isomap_coordinates = Isomap(n_components=2, metric=&#39;预先计算&#39;).fit_transform(距离)

#绘制结果
f, axs = plt.subplots(1, 2, Figsize=(6, 3), sharey=True, sharex=True, 布局=&#39;紧&#39;)
对于轴中的轴：
    标题, 坐标 = (&#39;MDS&#39;, mds_坐标) if ax == axs[0] else (&#39;Isomap&#39;, isomap_坐标)
    坐标 = np.array(坐标) #output_type 可以是 df
    ax.scatter(坐标[:, 0], 坐标[:, 1], 标记=&#39;s&#39;, s=30,
               c=范围(len(feature_names)), cmap=&#39;Set1&#39;)
    ax.set_title(标题)
    [ax.annotate(名称, xy, fontsize=10, fontweight=&#39;bold&#39;)
     对于名称，zip 中的 xy（要素名称，坐标）
     ]
f.suptitle(&#39;MDS 和 Isomap 应用于预先计算的距离矩阵&#39;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/635510/mds-and-isomap-applied-to-the-same-precomputed-distances</guid>
      <pubDate>Fri, 22 Dec 2023 15:11:31 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试设置中 Diff-in-Diff 的推断</title>
      <link>https://stats.stackexchange.com/questions/635509/inference-of-a-diff-in-diff-in-an-a-b-test-setting</link>
      <description><![CDATA[我有一个将运行很长时间的实验，其中用户有平等的机会被分配到治疗组或对照组，并且新用户一直加入实验，但我想计算一个无偏的指标实验开始前选择的用户群体。然后，我将使用该队列计算比率指标的差异。
使用这个预定义队列的原因是，这样的指标比简单地比较治疗组和对照组要敏感得多。该指标的定义如下：
$ \text{比率指标 (RM) } = \space \frac{\text{实验期间的计数指标 } - \text{ 实验前的计数指标}}{\ text{群组中的用户数量}} $
$ \text{对 RM 的影响} = RM_{治疗} - RM_{控制}$
如何计算该效应的置信区间和 p 值？如何运行功耗分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/635509/inference-of-a-diff-in-diff-in-an-a-b-test-setting</guid>
      <pubDate>Fri, 22 Dec 2023 15:06:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么鲁汶方法是非确定性的？</title>
      <link>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</link>
      <description><![CDATA[我正在 R 中的 igraph 中使用 Louvain 算法的实现进行社区检测。我观察到多次运行它会产生不同的答案。然而，当我读到算法时
Louvain 方法 - 维基百科，没有任何东西具有任何明显的随机性。我的猜测是，以不同的顺序遍历点可能会产生不同的答案，并且 igraph 代码在处理顶点之前会随机化顶点的顺序。这就是它产生多个答案的原因 - 还是还有其他原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</guid>
      <pubDate>Fri, 22 Dec 2023 14:37:42 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡罗假设检验：$H_0: \sigma = 1$ 与 $H_1: \sigma < 1$</title>
      <link>https://stats.stackexchange.com/questions/635506/montel-carlo-hypothesis-test-h-0-sigma-1-vs-h-1-sigma-1</link>
      <description><![CDATA[$Z_{i,1},...,Z_{i,5}$ 是 iid $N (\mu , \sigma^2)$，其中 $\mu$ 和 $\sigma^ 2$ 未知。
$X_i=max\{Z_{i,1},...,Z_{i,5}\}-min\{Z_{i,1},. ..,Z_{i,5}\}$
给定观察样本$X_{1,obs},...,X_{10,obs}$ 我想做蒙特卡罗假设检验： $H_0: \sigma = 1$ 与 $H_1: \sigma  1$.
&lt;小时/&gt;
我的想法如下：

#1 计算观察到的$T$-观测值$X_{1,obs},...的统计量,X_{10,obs}$，例如：$T_{obs}=\sum_{i=1}^{10} |X_{i,obs}| $

然后，对 $j=1,...,99$ 执行步骤#2：

#2 模拟来自 $N(\mu , 1) 的一组五个 $Z$ 值$ 对于一些 $\mu$ （它看起来像 $\mu$ 的值对此没有影响）。然后计算$X_{1,j}$的值。同样，再模拟九组五个 $Z$ 值，最终计算出 $X_{2,j} 的值， ...,X_{10,j}$。接下来，计算模拟 $X$ 的 $T$ 统计量，例如：$T_j=\sum_{i=1}^{10} |X_{i,j}|$ 。

#3 按升序排列：$T_{obs}$ 和 $T_1,.. .,T_{99}$.那么对于 $\alpha=5\%$ 我们可以拒绝原假设，如果 $T_{obs}$ 排在五个最小值之列；否则我们没有证据来拒绝原假设。


&lt;小时/&gt;
这听起来不错，还是由于我对如何进行蒙特卡罗假设检验的潜在误解而存在任何根本缺陷？
您是否会提出另一种 $T$ 统计数据，或者看起来我选择的统计数据（即 $X$&#39;s) 可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635506/montel-carlo-hypothesis-test-h-0-sigma-1-vs-h-1-sigma-1</guid>
      <pubDate>Fri, 22 Dec 2023 14:32:02 GMT</pubDate>
    </item>
    <item>
      <title>期望最大化中的特征重要性</title>
      <link>https://stats.stackexchange.com/questions/635505/feature-importance-in-expectation-maximization</link>
      <description><![CDATA[上下文使用 EM 算法进行混合模型 - 更准确地说是狄利克雷多项式混合，如 狄利克雷多项式混合物：微生物宏基因组学的生成模型。这里通常处理数百个样本和可能数十到数百个特征，尽管这些特征中只有少数被认为是重要的（在引用的论文的上下文中，它是几个微生物属，它们在某些混合物中最显着地表达）组件。）
是否有系统的方法根据特征的重要性对特征进行排名（使用 EM 时）？或者选择功能的基本组合？
例如，我找到了这篇论文：高斯混合模型功能选择：一种嵌入式方法，但我无法访问它，并且我不确定它是否提供了一种主流/足够可靠的方法来花时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/635505/feature-importance-in-expectation-maximization</guid>
      <pubDate>Fri, 22 Dec 2023 14:22:28 GMT</pubDate>
    </item>
    <item>
      <title>优化统计测试</title>
      <link>https://stats.stackexchange.com/questions/635503/optimization-statitical-test</link>
      <description><![CDATA[我有计算输出的公式，公式中的变量之一是“m”截至目前，该变量的值设置为 0.5。我想用统计测试来证明这是理想的数字。变量的范围可以从 0.01 到 1。您能否建议一下测试，这可以帮助我得到我想要的结论。]]></description>
      <guid>https://stats.stackexchange.com/questions/635503/optimization-statitical-test</guid>
      <pubDate>Fri, 22 Dec 2023 14:10:34 GMT</pubDate>
    </item>
    <item>
      <title>SEM：正态理论最大似然拟合函数</title>
      <link>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</link>
      <description><![CDATA[我参加了一些课程，其中讨论了结构方程建模中通过最大似然进行的模型估计。我在经典文献中也发现了正态理论 ML 拟合函数的一个定义（例如 博伦，1989）：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p $
其中 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 是模型隐含的协方差矩阵，$\mathbf{S}$ 是观察到的样本协方差矩阵，$p$ 是明显变量的数量。
Bollen (1989) 证明，当 $\hat{\boldsymbol{\Sigma}} = \mathbf{S}$ （且 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 替换为 $\hat{\boldsymbol{\Sigma}}$ )，$\hat{F}_{ML}$ 为零，因此代表完美拟合。
但是，在课程中我看到了这样的规范：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p + [\mathbf{m}-\boldsymbol {\mu}(\boldsymbol{\theta})]&#39;\boldsymbol{\Sigma}^{-1}[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})] $
看起来平均结构也被添加到拟合函数中，其中 $\mathbf{m}$ 是观察到的平均向量，$\boldsymbol{\mu}(\boldsymbol{\theta})$ 是模型隐含的均值向量。
我的假设是，为什么有这两种不同的定义，因为在经典的 CFA（以及许多其他类型的更一般的 SEM）中，均值结构是饱和的，并且模型失配不可能来自均值结构。这意味着 $[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})]$ 为零，因为 $\mathbf{m}=\boldsymbol{\mu}(\boldsymbol{\theta})$ 并且附加项将消失。然而，我找不到任何文献证实这一点，所以如果有人知道第二个（更一般的）规范来自哪里或者可以更详细地解释它，我将非常感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</guid>
      <pubDate>Fri, 22 Dec 2023 13:33:48 GMT</pubDate>
    </item>
    <item>
      <title>删除多个组和多个特征中的异常值</title>
      <link>https://stats.stackexchange.com/questions/635501/removing-outliers-in-several-groups-and-for-several-features</link>
      <description><![CDATA[我不确定如何删除或缩小异常值。假设我有两组，治疗组和对照组。我测量了两者的特征 1 和特征 2。
我应该如何处理异常值？分别针对每个组和每个功能？
含义：特征1组1、特征1组2、特征2组1和特征2组2
还是作为一个整体？]]></description>
      <guid>https://stats.stackexchange.com/questions/635501/removing-outliers-in-several-groups-and-for-several-features</guid>
      <pubDate>Fri, 22 Dec 2023 13:32:21 GMT</pubDate>
    </item>
    <item>
      <title>在进行PCA之前如何减少连续变量的数量？</title>
      <link>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-doing-pca</link>
      <description><![CDATA[哪组变量最能预测女性的握力？
-&gt;我有 18 个变量，现在想要进行 PCA，但首先我必须：“在进行分析之前减少连续变量的数量。”
如果我根据相关系数进行减少，我只会保留 5 个超过 0.1 的变量，因此在开始 PCA 之前可能会减少太多？
谁能帮我解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-doing-pca</guid>
      <pubDate>Fri, 22 Dec 2023 13:07:48 GMT</pubDate>
    </item>
    <item>
      <title>R：MASS::glm.nb 和 glmmTMB“nbinom2”之间的参数化差异</title>
      <link>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</link>
      <description><![CDATA[我想了解有关 RStudio 中两个不同 GLM 输出的意见。
我使用样方计算为面积偏移，对 21 个地点的计数数据（粪便颗粒）进行了建模。我首先使用 GLM 泊松回归来定义模型结构，该模型具有严重的过度分散性和严重的过度分散性。零膨胀。我转向负二项式，它解决了这两个问题，但根据使用的包（MASS：glm.nb 和 glmmTMB nbinom2），我得到了不同的结果。他们给出相同的 theta 估计、相同的 AIC，但不同的 SE 和z 值，特别是对于一个预测变量，它在一个包中显得重要，但在另一个包中则不然。这是在模型选择之前。
因此，我想知道所使用的两个包之间的参数化有什么区别？根据我的阅读，他们似乎使用相同的方差公式，都是通过最大似然估计的：

glmmTMB：方差 = µ(1 + µ/k)
MASS：方差 = μ+μ²/θ，使得 θ=1/k

我怀疑这与 MASS::glm.nb 从对数似然计算中删除常量有关，而 glmmTMB 则不然，但我无法确认。
我倾向于坚持使用 MASS，因为我在这里不使用任何 RE，但我想知道发生了什么。
代码输出：
&lt;前&gt;&lt;代码&gt;&gt; # 海量包
&gt; mod.nbmass &lt;- glm.nb(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), link = &quot;log&quot;, data=data_site)
&gt;摘要（mod.nbmass）

称呼：
glm.nb(公式 = 颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats)),
    数据 = data_site，链接 =“日志”，init.theta = 0.9808088892）

残差偏差：
    最小 1Q 中值 3Q 最大
-2.6923 -0.9313 -0.1119 0.2173 1.5372

系数：
            估计标准。误差z值Pr(&gt;|z|)
（截距） 0.17109 0.22170 0.772 0.4403
RS1 -0.04392 0.34372 -0.128 0.8983
RS2 0.21905 0.31118 0.704 0.4815
RS4 -0.04524 0.31740 -0.143 0.8866
RS5 0.21135 0.34775 0.608 0.5433
RS6 -0.67892 0.33963 -1.999 0.0456 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（负二项式(0.9808)族的色散参数取为1）

    零偏差：20 自由度上为 29.252
残余偏差：15 个自由度上为 24.854
注册会计师：246.43

Fisher 评分迭代次数：1


              西塔：0.981
          标准。误差：0.290

 2 x 对数似然：-232.429
&gt; # glmmTMB 包
&gt; mod.nbTMB&lt;-glmmTMB(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), family=“nbinom2”, data=data_site)
&gt;摘要(mod.nbTMB)
 家族：nbinom2（日志）
公式：颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats))
数据：data_site

     AIC BIC logLik 偏差 df.resid
   246.4 253.7 -116.2 232.4 14


nbinom2 系列的色散参数 ()：0.981

条件模型：
            估计标准。误差z值Pr(&gt;|z|)
（截距）0.17109 0.22163 0.772 0.440
RS1 -0.04393 0.39138 -0.112 0.911
RS2 0.21905 0.26685 0.821 0.412
RS4 -0.04525 0.30701 -0.147 0.883
RS5 0.21135 0.40676 0.520 0.603
RS6 -0.67892 0.48995 -1.386 0.166

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</guid>
      <pubDate>Fri, 22 Dec 2023 12:42:43 GMT</pubDate>
    </item>
    <item>
      <title>解释线性回归（文法学校是否会增加弱势学生的学业成绩差距？）</title>
      <link>https://stats.stackexchange.com/questions/635495/interpreting-linear-regression-do-grammar-schools-increase-the-attainment-gap-f</link>
      <description><![CDATA[周一，教育政策研究所发布了英格兰教育年度报告https:// epi.org.uk/annual-report-2023/。重点关注贫困学生与同龄人之间的成绩差距。结果针对 150 个地方当局进行了细分。有人告诉我，“很明显，最具选择性的†洛杉矶的差距比正常水平更大。”我被要求寻找支持证据。 （†选择是指孩子们参加“11+”入学考试，进入以学术为重点的“语法”学校。）
英格兰有 150 个地方当局。我创建了一个连续变量，其中包含每个权威中选择性位置的比例。其中 115 人根本没有精英中学名额。 35 家的比例介于略高于零和低于 40% 之间。我首先使用 Seaborn 的 regplot() 和 jointplot() 进行绘图（缺点 ~ %选择性）。趋势线显示轻微正相关，但该线几乎是水平的。我看不到任何可以远程描述为模式的东西。

仅对选定的 35 个 LA 使用 OLS 回归，得到 R 平方 0.009 和 F 统计量 0.581。
我认为正确的解释是。 R 方显示生成的模型解释的实际结果不到百分之一。 F 统计量显示，预测相关性由数据中的随机方差引起的可能性约为十分之六。结论：没有证据表明存在相关性。
自从我正式研究这个问题以来已经很长时间了，在我回复提问者之前，我真的很感激第二个意见。
我还在完整的 150 上尝试过 OLS。改进的 F 统计量 0.404，但更差的 R 方 0.005。
我尝试了解释变量的不同转换。我认为这些不值得讨论，因为从根本上来说，散点图看起来就像罗夏墨迹测试一样随机。]]></description>
      <guid>https://stats.stackexchange.com/questions/635495/interpreting-linear-regression-do-grammar-schools-increase-the-attainment-gap-f</guid>
      <pubDate>Fri, 22 Dec 2023 12:31:29 GMT</pubDate>
    </item>
    <item>
      <title>什么是样品近似硬度的度量？</title>
      <link>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</link>
      <description><![CDATA[假设有一个很大的实数向量$\mathbf{x}$，我想估计某个聚合函数$f(\mathbf{x})$ 通过从总体中抽取一小部分样本$\mathbf{x}$。我想知道我需要多少样本才能知道 $f(\mathbf{x})$ 例如$1\%$ 准确度。样本数量可能取决于函数 $f$：较大的数字表示 $f$ 是“通过采样更难近似”。这个样本数的术语是什么？在哪里可以找到有关哪些函数 $f$ 更容易/更难近似的数据？
我想到的一个术语是样本复杂度，但从我所看到的来看，它不一样：它测量从给定的函数类别中学习函数所需的训练样本数量。就我而言，函数是固定且给定的，我想知道将函数值估计到给定精度所需的样本数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</guid>
      <pubDate>Fri, 22 Dec 2023 12:09:45 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|X^3-3X]=0$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635492/exx3-3x-0</link>
      <description><![CDATA[用 $f(x) 证明 $E[X|X^3-3X]=0$ =\frac{|x^2-1|}{4}$ 是区间 $X$ 的密度函数数学容器&quot;&gt;$[-2,2]$。]]></description>
      <guid>https://stats.stackexchange.com/questions/635492/exx3-3x-0</guid>
      <pubDate>Fri, 22 Dec 2023 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>如何通过重复导出拉丁方的平方和</title>
      <link>https://stats.stackexchange.com/questions/635489/how-to-derive-the-sum-of-square-for-latin-square-with-repetition</link>
      <description><![CDATA[我正在学习拉丁方设计，其中 https://online.stat.psu.edu/stat503/lesson/4/4.4
假设我们讨论重复情况 3，即我们的行因子和列因子都有不同的级别。我有 2 个问题

为什么行/列的 DF 是 $n \left(t-1 \right)$？不应该是 $nt - 1$ 吗？
如何得出行/列平方和？

任何提示/指导都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635489/how-to-derive-the-sum-of-square-for-latin-square-with-repetition</guid>
      <pubDate>Fri, 22 Dec 2023 11:21:41 GMT</pubDate>
    </item>
    <item>
      <title>先前的信念有多主观？</title>
      <link>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</link>
      <description><![CDATA[我发现术语“先验信念”有点模糊，贝叶斯分析中的先验信念可以接受什么？例如，我无法查看任何数据并自行决定“我相信总体平均值将约为 60 个单位”，无论这是基于直觉还是缺乏关心。对于“可靠”的先验信念是否有任何标准？]]></description>
      <guid>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</guid>
      <pubDate>Fri, 22 Dec 2023 09:19:08 GMT</pubDate>
    </item>
    </channel>
</rss>