<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 03 Jul 2024 06:22:01 GMT</lastBuildDate>
    <item>
      <title>将 MCMC 样本回收用于来自同一分布的另一个数据集</title>
      <link>https://stats.stackexchange.com/questions/650374/recycling-mcmc-samples-for-another-data-set-from-the-same-distribution</link>
      <description><![CDATA[假设我得到 $\theta_0$ 并且我想要从密度 $f(Y|\theta_0)$ 中采样数据，然后从 $\theta|Y$ 的后验中采样（显然，给定一些先验）。我想多次这样做，以获得后验分布摘要的抽样分布。
如果我有一个 MCMC 样本 $M$ 实现，$\theta_1,\ldots,\theta_M$，对于样本 $Y_1,\dots,Y_n$，似乎我应该能够使用似然比为另一个样本 $Y&#39;_1,\dots, Y_n$ 重新加权：$\theta_i$ 的权重将是
$$w_i=\frac{f(Y&#39;_1,\dots,Y&#39;_n|\theta_i)}{f(Y_1,\dots,Y_n|\theta_i)}$$
如果我从 $\theta_1,\dots,\theta_M$ 中抽样，概率与 $w_i$ 成比例，我应该从 $\theta|Y&#39;$ 的后验中得到某种近似样本。这有点让人想起重要性抽样和粒子滤波器。
这一定已经尝试过了。关于它的有效性我们知道什么？对于表现良好的单峰低维后验来说，它有多糟糕？]]></description>
      <guid>https://stats.stackexchange.com/questions/650374/recycling-mcmc-samples-for-another-data-set-from-the-same-distribution</guid>
      <pubDate>Wed, 03 Jul 2024 06:07:34 GMT</pubDate>
    </item>
    <item>
      <title>R 中的关键驱动因素分析 - 不同的包产生略有不同的结果：这是可以预料的吗？</title>
      <link>https://stats.stackexchange.com/questions/650372/key-driver-analysis-in-r-different-packages-produce-slightly-different-results</link>
      <description><![CDATA[我正在使用客户体验数据进行关键驱动因素分析。我使用 R 中的三个不同包运行了分析：rwa、relaimpo::calc.relimp 和 iopsych::relWt
每种方法对每个协变量的相对重要性产生的值略有不同。这些差异是针对排名中间具有相似重要性权重的协变量（最重要和最不重要对于所有包都是一致的） - 这是可以预料的吗？我想使用计算效率最高的包/函数 - 这是选择哪个选项的合理标准吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650372/key-driver-analysis-in-r-different-packages-produce-slightly-different-results</guid>
      <pubDate>Wed, 03 Jul 2024 04:15:04 GMT</pubDate>
    </item>
    <item>
      <title>有限数据集的对象检测</title>
      <link>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</link>
      <description><![CDATA[考虑以下场景

如果我想训练一个模型来检测和计算这些方块：

这些方块永远不会不同。它们看起来总是一模一样，大小也完全相同，永远不会有某种重叠或障碍，也不会改变颜色等 - 它们总是完全相同。
但是反复训练同一张图片（因为您会使用其他什么图片来制作数据集？它永远不会改变），它无法正确识别这些框。如果您拍摄图像并制作扭曲的版本以便获得数据集，它仍然无济于事。
我该如何针对这种简单的场景训练算法？或者对象检测（或分类，如果我们包括标记的对象，那么我们将有 2 个类）是否仅适用于可以“在视觉上改变/扭曲”的事物，而不适用于始终相同的事物？
我一直在尝试查找有关它的文献、论文和文章，但我不知道这个问题叫什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</guid>
      <pubDate>Wed, 03 Jul 2024 03:04:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要使用零假设下假设的值来计算比例的标准差？</title>
      <link>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</link>
      <description><![CDATA[在计算 2 类误差时，为什么即使我们将备择假设作为可能的真实值，我们也要使用零假设下的假设值来计算标准差？
如果零假设 u = 20，备择假设 u = 24，且采样 x = 21，则 H0σ（基于零假设计算）。我们通过“(x-24)/H0σ”计算 2 类误差。我的问题是为什么不使用 H1σ...？
示例案例 - https://www.youtube.com/watch?v=BJZpx7Mdde4]]></description>
      <guid>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</guid>
      <pubDate>Wed, 03 Jul 2024 00:31:40 GMT</pubDate>
    </item>
    <item>
      <title>加权风险比 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650369/the-weighted-hazard-ratio</link>
      <description><![CDATA[如何在 R 中获得真实加权风险比，尤其是对于 Fleming &amp; Harrington 系列权重？一个简单的例子可能会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650369/the-weighted-hazard-ratio</guid>
      <pubDate>Tue, 02 Jul 2024 23:49:16 GMT</pubDate>
    </item>
    <item>
      <title>稀疏、有序、二进制向量的相似度测量，对真值的权重更大</title>
      <link>https://stats.stackexchange.com/questions/650367/similarity-measure-for-sparse-ordered-binary-vectors-with-more-weighting-to-t</link>
      <description><![CDATA[我有两个稀疏、有序的二进制向量。向量的大小约为 ~100。
我的印象是余弦相似度对于稀疏、有序的二进制向量很有用。就我的目的而言，它很好，但并不是我所寻找的。
假设我有两组向量对：A =：{{0,0,0}, {0,0,0}} 和 B =：{{1,1,1}, {1,1,1}}。 (A1, A2) 和 (B1, B2) 之间的余弦相似度相同，因为两对是相同的，但是，我想要一个对 B 更重要的度量，因为它对 1 的观察更多。
我可以通过总结向量中 1 的数量，然后将其乘以余弦相似度来创建一个基本的度量。
我只是好奇是否有一个更深思熟虑（可能准确）的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/650367/similarity-measure-for-sparse-ordered-binary-vectors-with-more-weighting-to-t</guid>
      <pubDate>Tue, 02 Jul 2024 23:18:58 GMT</pubDate>
    </item>
    <item>
      <title>加权平均值的误差是多少？</title>
      <link>https://stats.stackexchange.com/questions/650364/what-is-the-error-on-the-weighted-mean</link>
      <description><![CDATA[我正在组合直方图中的箱体。我有一些代码使用此公式来计算加权平均值的误差：
$$\sigma = \frac{\sqrt{\sum \frac{w_{i}(w_{i}\sigma_{i}^{2}+x_{i}^{2})}{\sum w_{i}}-(\frac{\sum w_{i}x_{i}}{\sum w_{i}})^{2}}}{\sqrt{\sum w_{i}}}$$
有人能告诉我这是如何得出的吗？我在哪里可以找到有关此公式的更多信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/650364/what-is-the-error-on-the-weighted-mean</guid>
      <pubDate>Tue, 02 Jul 2024 23:08:17 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 适用于非高斯数据</title>
      <link>https://stats.stackexchange.com/questions/650362/glmm-for-not-so-gaussian-data</link>
      <description><![CDATA[我遇到了 GLMM 问题，希望您能给我一些建议。
因此，基本上，我有来自三个独立组（变量：子文件夹）的显微镜实验数据，这些组嵌套在 4 个实验重复（变量：文件名）中：在 4 个单独的实验中一起测量了一组细胞。
下图显示了三个实验组的值，每个测量值的颜色代表每个实验。
我想比较实验组之间的差异（我知道在这种情况下非常明显）。因此，我使用 glmmTMB 中的 GLMM 来建模此数据集：m &lt;- glmmTMB(mean_new_deltaR ~ subfolder+(1 | file_name), dispformula=~ subfolder, data=mean_deltaR)，然后使用 emmeans。由于方差肯定不均匀，因此我使用 dispformula 进行建模。但是，当我使用 DHAMRa 进行诊断时，残差看起来不太好。有什么真诚的方法吗？稳健 GLM 是一种选择吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650362/glmm-for-not-so-gaussian-data</guid>
      <pubDate>Tue, 02 Jul 2024 22:16:27 GMT</pubDate>
    </item>
    <item>
      <title>对 Fisher 评分算法的困惑</title>
      <link>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</link>
      <description><![CDATA[给定一个概率模型$f(X;\theta)$和一组 i.i.d.观测值$x_1,\ldots,x_n$我们假设这些观测值来自某个真实参数$f(X; \theta_0)$，我们可以使用牛顿法进行最大似然估计：
$$
\theta_{t+1} = \theta_t + \eta (\nabla^2 \ell(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
其中$\eta$表示步长，$\ell(\theta) = \sum_{i=1}^n \log f(x_i;\theta)$
另一方面另一方面，Fisher 评分算法用 Fisher 信息矩阵代替了对数似然的 Hessian，$\nabla^2 \ell(\theta)$
$$
\mathcal{I}(\theta) = - \mathbb{E}_{X \sim f(X;\theta)} \nabla^2 \ell(\theta)
$$
因此，Fisher 评分算法是
$$
\theta_{t+1} = \theta_t + \eta (\mathcal{I}(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
我的问题是：鉴于一般而言，Fisher 评分算法的迭代次数$\theta_t$ 并不接近 MLE 和真实参数 $\theta_0$，为什么 Fisher 信息矩阵 $\mathcal{I}(\theta_t) = - \mathbb{E}_{X \sim f(X;\theta_t)} \nabla^2 \ell(\theta_t)$ 是 Hessian 的合理近似值？具体而言，在我看来，对分布 $X \sim f(X;\theta_t)$ 取期望根本不会对在观测值 $x_1,\ldots,x_n \sim f(X; \theta_0)$ 处评估的对数似然的 Hessian 矩阵产生良好的估计，除非 $\theta_t$ 已经接近 MLE，从而接近真实参数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</guid>
      <pubDate>Tue, 02 Jul 2024 21:33:58 GMT</pubDate>
    </item>
    <item>
      <title>非独立同分布数据的 MLE 收敛</title>
      <link>https://stats.stackexchange.com/questions/650355/convergence-of-mle-for-non-iid-data</link>
      <description><![CDATA[考虑使用 MLE 计算以下 2 种情况下的最佳模型参数 $\theta$：

数据生成过程独立但不相同：

$L(y;\theta) = \prod_{i=2}^{n} f_{i}(y_i;\theta)$。

数据生成过程具有顺序依赖性，可能不平稳：

$L(y;\theta) = \prod_{i=2}^{n} f_{i}(y_i|y_{i-};\theta) f_{1}(y_1)$。
下标 $i$ 表示每个项 $f$ 的分布可能不同。如果模型指定得当，MLE 是否会收敛于 1. 和 2.？是否有任何证据证明 1. 和 2. 收敛（或不收敛）？]]></description>
      <guid>https://stats.stackexchange.com/questions/650355/convergence-of-mle-for-non-iid-data</guid>
      <pubDate>Tue, 02 Jul 2024 20:40:12 GMT</pubDate>
    </item>
    <item>
      <title>简单随机抽样和组内比较</title>
      <link>https://stats.stackexchange.com/questions/650339/simple-random-sampling-and-in-group-comparison</link>
      <description><![CDATA[我们正在我们的托管网站上进行 A/B 测试，我们出售四种不同的计划（A、B、C 和 D）。我们网站的访问者被随机分配到基本 UI（控制）或修改后的 UI（变体）。在分配之前，我们不知道访问者购买特定计划的意图。
我的问题是：分配后，比较每个组内每个计划的购买率是否有效？例如，我们可以比较看到原始 UI 的用户和看到修改后的 UI 的用户之间的计划 A 的购买率吗？
提前感谢您的见解！
PS：我主要关心的是确保任何观察到的购买行为变化都是由于 UI 更改本身造成的，而不是因为 UI 更改影响了用户切换计划。具体来说，我们如何确定计划 A 的购买量增加或减少是由于 UI 更改造成的，而不是因为新 UI 导致用户改变了他们原来的购买意图？]]></description>
      <guid>https://stats.stackexchange.com/questions/650339/simple-random-sampling-and-in-group-comparison</guid>
      <pubDate>Tue, 02 Jul 2024 17:05:50 GMT</pubDate>
    </item>
    <item>
      <title>BFAST Lite 算法中的稳定期：优点和缺点</title>
      <link>https://stats.stackexchange.com/questions/650334/stable-period-in-the-bfast-lite-algorith-benefits-and-drawbacks</link>
      <description><![CDATA[我即将使用 BFAST Lite 算法执行卫星时间序列分析 (STSA)。我必须指定的参数之一是稳定期的长度（时间序列数据中假定没有重大结构变化的时间段）。
我即将使用的数据是 2013 年至 2023 年的每月卫星夜间灯光 (NTL)。从基本的目视检查中，我发现在 2014 年，我的研究区域变亮了，而在 2019 年变暗了（由于 COVID？）。问题是我想使用 2013 年至 2018 年作为稳定期，但现在不能。
如果我使用它们，算法不会识别出 2019 年的中断（如果我缩短稳定期的长度，我还没有测试该方法的行为）。
我的问题是：BFAST 方法中较小的稳定期有什么好处和缺点？有推荐的时间长度吗？我打算使用 2018-2023 年期间的数据。
注意：BFAST Lite 需要至少 4 年的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/650334/stable-period-in-the-bfast-lite-algorith-benefits-and-drawbacks</guid>
      <pubDate>Tue, 02 Jul 2024 16:00:12 GMT</pubDate>
    </item>
    <item>
      <title>不同条件边际对的均匀联合分布</title>
      <link>https://stats.stackexchange.com/questions/650328/equal-joint-distribution-for-different-conditional-marginal-pairs</link>
      <description><![CDATA[设$(\Omega, \mathcal{A}, \mathbb{P})$为概率空间，设$X:(\Omega, \mathcal{A})\rightarrow (\mathcal{X}, \mathcal{F})$和$Y:(\Omega, \mathcal{A})\rightarrow (\mathcal{Y}, \mathcal{G})$为随机变量。
现在我知道了最常用的结果
$$\mathbb{P}_{X,Y}(A, B) = \int_A \mathbb{P}_{Y|X=x}(B)d\mathbb{P}_X$$
并且
$$\mathbb{P}_{X,Y}(A, B) = \int_B \mathbb{P}_{X|Y=y}(A)d\mathbb{P}_Y.$$
我感兴趣的是，在更一般的环境中，我们何时可以判断这样构建的联合分布是否相等？即，上述两个条件和两个边际的结构是什么，使得它们通过上述两个方程产生相同的联合分布？
更准确地说：设 $\mu$ 为（常规）条件分布，使得 $\mu(A,y)$ 是 $A\in \mathcal{F}$ 中的概率测度和 $y\in \mathcal{Y}$ 中的可测函数。设 $\nu$ 是 $\mathcal{X}$ 上的边际分布。此外，让 $\rho$ 成为（常规）条件分布，使得 $\rho(B,x)$ 是 $B\in \mathcal{G}$ 中的概率测度和 $x\in \mathcal{X}$ 中的可测函数，并让 $\eta$ 成为 $\mathcal{Y}$ 上的边际分布。
在什么情况下联合分布
$$\int_A \mu(A, y) d\nu(y)$$
且
$$\int_B \rho(B, x) d\eta(x)$$
相等吗？
也许是一个密切相关的问题：如果我只有 $\int_A \mu(A, y) d\nu(y)$，我如何确定 $\mathcal{Y}$ 上的条件和 $\mathcal{X}$ 上的边际分布，从而给出相同的联合分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/650328/equal-joint-distribution-for-different-conditional-marginal-pairs</guid>
      <pubDate>Tue, 02 Jul 2024 14:46:10 GMT</pubDate>
    </item>
    <item>
      <title>需要 Bonferroni 校正吗？回归预测一个结果</title>
      <link>https://stats.stackexchange.com/questions/650323/bonferroni-correction-necessary-regression-to-predict-one-outcome</link>
      <description><![CDATA[我正在开展一个样本量较小的项目，其中我在基线处有多个预测因子和一个 IV。我试图看看是否有任何 DV 可以很好地预测 IV（连续）上的得分。这个想法是使用多个线性回归模型，每个模型都有一个 DV。我们只是想看看是否有任何预测因子具有潜力，因此它具有很强的探索性，但基于某种理论，我们将变量缩小到几个。
由于我正在做单独的模型（从技术上讲每个模型都有自己的假设），我是否需要对多次测试进行校正？为什么或为什么不？]]></description>
      <guid>https://stats.stackexchange.com/questions/650323/bonferroni-correction-necessary-regression-to-predict-one-outcome</guid>
      <pubDate>Tue, 02 Jul 2024 14:33:13 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的权重初始化——每个观察值的权重应该不同还是相同？</title>
      <link>https://stats.stackexchange.com/questions/650320/weight-initialisation-for-neural-networks-should-they-be-different-for-each-ob</link>
      <description><![CDATA[我正在实现一个带有前馈和反向传播的神经网络，并使用梯度下降来更好地理解事物的工作原理。
在设置了整个算法之后，我仍然有很大的疑问。当我初始化权重时，我会这样做，以便网络的每个节点都有自己的初始分配权重。我对数据集中的每个样本都这样做，这意味着对于每个样本，我都会初始化不同的权重。这是正确的吗，还是所有样本的初始权重都应该相同？
举个例子来澄清我的问题：假设我有一个非常简单的网络，只有输入层和输出层。输入有 2 个节点。数据集有 2 个观测值。我现在要做的是，对于每个观测值，我初始化 2 个权重并将它们分配给输入节点，这样最终我就有了 4 个不同的权重。我是否应该只初始化 2 个权重并将它们分配给两个观测中的相应节点，以便两个节点在所有观测中都具有相同的权重值？
我现在正在做什么：
-observation1
-node1：weight1
-node2：weight2
-observation2
-node1：weight3
-node2：weight4

我想知道我应该做什么：
-observation1
-node1：weight1
-node2：weight2
-observation2
-node1：weight1
-node2：weight2
]]></description>
      <guid>https://stats.stackexchange.com/questions/650320/weight-initialisation-for-neural-networks-should-they-be-different-for-each-ob</guid>
      <pubDate>Tue, 02 Jul 2024 14:06:35 GMT</pubDate>
    </item>
    </channel>
</rss>