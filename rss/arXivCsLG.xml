<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 16 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>状态空间模型中的状态幻象</title>
      <link>https://arxiv.org/abs/2404.08819</link>
      <description><![CDATA[arXiv:2404.08819v1 公告类型：新
摘要：与以前普遍存在的 Transformer 架构相比，状态空间模型（SSM）已成为构建大型语言模型（LLM）的潜在替代架构。 Transformer 的一个理论上的弱点是它们无法表达某些类型的顺序计算和状态跟踪（Merrill 和 Sabharwal，2023），SSM 被明确设计为通过其与循环神经网络（RNN）的密切架构相似性来解决这些问题。但是，SSM 在状态跟踪的表达能力方面真的（相对于 Transformer）有优势吗？令人惊讶的是，答案是否定的。我们的分析表明，SSM 的表达能力与 Transformer 非常相似：SSM 无法表达复杂性类别 $\mathsf{TC}^0$ 之外的计算。特别是，这意味着它们无法解决简单的状态跟踪问题，例如排列组合。由此可见，SSM 无法准确跟踪具有特定符号的国际象棋棋步、评估代码或跟踪长叙述中的实体。为了补充我们的正式分析，我们报告了实验，表明曼巴式 SSM 确实在状态跟踪方面遇到困难。因此，尽管有循环表述，SSM 中的“状态”是一种幻觉：SSM 与 Transformer 等非循环模型具有类似的表达能力限制，这可能从根本上限制了它们解决现实世界状态跟踪问题的能力。]]></description>
      <guid>https://arxiv.org/abs/2404.08819</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>根据人类偏好进行奖励学习的事后诸葛亮</title>
      <link>https://arxiv.org/abs/2404.08828</link>
      <description><![CDATA[arXiv:2404.08828v1 公告类型：新
摘要：基于偏好的强化学习（PbRL）通过从策略行为的偏好反馈中学习奖励，消除了手动指定奖励函数的需要。当前的 PbRL 方法没有解决确定行为的哪些部分对偏好最有贡献时所固有的信用分配问题，从而导致数据密集型方法和低于标准的奖励函数。我们通过引入信用分配策略（Hindsight PRIOR）来解决这些限制，该策略使用世界模型来近似轨迹内的状态重要性，然后通过辅助预测回报再分配目标引导奖励与状态重要性成比例。将状态重要性纳入奖励学习可以提高策略学习的速度、整体策略性能以及运动和操纵任务的奖励恢复。例如，Hindsight PRIOR 在 MetaWorld (20%) 和 DMC (15%) 上平均显着 (p&lt;0.05) 恢复更多奖励。性能提升和我们的消融表明，即使是简单的信用分配策略也可以对奖励学习产生好处，并且前向动态预测中的州重要性是州对偏好决策的贡献的有力代表。代码存储库可以在 https://github.com/apple/ml-rlhf-hindsight-prior 找到。]]></description>
      <guid>https://arxiv.org/abs/2404.08828</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>多种后验模态的可微分且稳定的长距离跟踪</title>
      <link>https://arxiv.org/abs/2404.08789</link>
      <description><![CDATA[arXiv:2404.08789v1 公告类型：新
摘要：粒子滤波器通过一组加权样本以非参数方式灵活地表示多个后验模式，但通常应用于跟踪已知动态和观察可能性的问题。对于图像等高维观察，此类生成模型可能不准确或不可用。相反，我们利用训练数据来有区别地学习潜在对象状态中基于粒子的不确定性表示，并以通过深度神经网络编码器进行的任意观察为条件。虽然先前的判别性粒子滤波器使用了离散粒子重采样的启发式松弛，或通过在重采样步骤中截断梯度来进行有偏学习，但我们通过将后验表示为连续混合密度来实现无偏和低方差的梯度估计。我们的理论和实验揭示了现有的基于重新参数化的混合梯度估计器的严重失败，我们通过重要性采样梯度估计器解决了这个问题。与标准循环神经网络不同，我们的混合密度粒子滤波器代表连续潜在状态中的多模态不确定性，从而提高了准确性和鲁棒性。在一系列具有挑战性的跟踪和机器人定位问题上，我们的方法在准确性方面取得了显着提高，同时在多次训练运行中也表现出了更高的稳定性。]]></description>
      <guid>https://arxiv.org/abs/2404.08789</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>Megalodon：具有无限上下文长度的高效 LLM 预训练和推理</title>
      <link>https://arxiv.org/abs/2404.08801</link>
      <description><![CDATA[arXiv:2404.08801v1 公告类型：新
摘要：Transformers 的二次复杂度和弱长度外推限制了它们扩展到长序列的能力，虽然存在线性注意力和状态空间模型等次二次解决方案，但根据经验，它们在预训练效率和下游任务准确性方面表现不佳。我们引入了 Megalodon，一种用于高效序列建模的神经架构，具有无限的上下文长度。 Megalodon继承了Mega（带有门控注意力的指数移动平均）的架构，并进一步引入了多种技术组件来提高其能力和稳定性，包括复杂指数移动平均（CEMA）、时间步标准化层、标准化注意力机制和具有两个特征的预标准化-hop 剩余配置。在与 Llama2 的受控头对头比较中，Megalodon 在 70 亿个参数和 2 万亿个训练 token 的规模上取得了比 Transformer 更好的效率。巨齿鲨的训练损失达到 1.70，落在 Llama2-7B (1.75) 和 13B (1.67) 之间。代码：https://github.com/XuezheMax/megalodon]]></description>
      <guid>https://arxiv.org/abs/2404.08801</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>利用粘性 Hamilton-Jacobi PDE 进行科学机器学习中的不确定性量化</title>
      <link>https://arxiv.org/abs/2404.08809</link>
      <description><![CDATA[arXiv:2404.08809v1 公告类型：新
摘要：科学机器学习 (SciML) 中的不确定性量化 (UQ) 将 SciML 强大的预测能力与量化学习模型可靠性的方法相结合。然而，仍然存在两个主要挑战：可解释性有限和昂贵的培训程序。我们通过在 SciML 中出现的一些贝叶斯推理问题和粘性 Hamilton-Jacobi 偏微分方程 (HJ PDE) 之间建立新的理论联系，为 UQ 问题提供了新的解释。也就是说，我们证明后验均值和协方差可以从粘性 HJ PDE 解的空间梯度和 Hessian 矩阵中恢复。作为对这种联系的首次探索，我们专门研究线性模型、高斯似然和高斯先验的贝叶斯推理问题。在这种情况下，相关的粘性 HJ 偏微分方程可以使用 Riccati ODE 求解，并且我们开发了一种新的基于 Riccati 的方法，该方法在持续更新模型预测时提供计算优势。具体来说，我们基于 Riccati 的方法可以有效地向训练集中添加或删除数据点，且与数据顺序无关，并持续调整超参数。此外，这两种更新都不需要重新训练或访问先前合并的数据。我们提供了来自 SciML 的几个涉及噪声数据和 \textit{认知不确定性} 的示例，以说明我们方法的潜在优势。特别是，这种方法对数据流应用程序的适用性证明了其实时推理的潜力，这反过来又允许使用预测的不确定性来动态改变学习过程的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2404.08809</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>使用度量约束 Eikonal 方法计算流形上的距离和均值</title>
      <link>https://arxiv.org/abs/2404.08754</link>
      <description><![CDATA[arXiv:2404.08754v1 公告类型：新
摘要：计算黎曼流形上的距离是一个具有挑战性的问题，涉及从物理学、统计学到机器学习的众多应用。在本文中，我们引入度量约束 Eikonal 求解器来获得流形上距离函数的连续、可微的表示。这些表示的可微性质允许直接计算流形上的全局长度最小化路径。我们展示了度量约束 Eikonal 求解器在一系列流形中的使用，并演示了其应用。首先，我们证明度量约束 Eikonal 求解器可用于获取流形上的 Fr&#39;echet 均值，采用高斯混合模型的定义，该模型具有解析解来验证数值结果。其次，我们演示了如何使用获得的距离函数在流形上进行无监督聚类——现有方法在计算上无法完成这项任务。这项工作为流形上的距离计算提供了机会。]]></description>
      <guid>https://arxiv.org/abs/2404.08754</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>将视觉语言模型训练为智能手机助手</title>
      <link>https://arxiv.org/abs/2404.08755</link>
      <description><![CDATA[arXiv:2404.08755v1 公告类型：新
摘要：为了解决能够执行各种用户任务的数字助理的挑战，我们的研究重点是基于指令的移动设备控制领域。我们利用大型语言模型 (LLM) 的最新进展，提出了一种可以在移动设备上完成各种任务的视觉语言模型 (VLM)。我们的模型仅通过与用户界面（UI）交互来发挥作用。它使用来自设备屏幕的视觉输入并模仿类人交互，包括点击和滑动等手势。输入和输出空间的这种通用性允许我们的代理与设备上的任何应用程序进行交互。与以前的方法不同，我们的模型不仅在单个屏幕图像上运行，而且在根据过去的屏幕截图序列以及相应的动作创建的视觉语言句子上运行。在具有挑战性的 Android in the Wild 基准测试中评估我们的方法，证明了其有希望的功效和潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.08755</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>CATS：大型语言模型中稀疏性的上下文感知阈值</title>
      <link>https://arxiv.org/abs/2404.08763</link>
      <description><![CDATA[arXiv:2404.08763v1 公告类型：新
摘要：大型语言模型（LLM）具有显着先进的人工智能应用，但由于其巨大的推理成本，其部署仍然具有挑战性。最近的研究通过增加 LLM 的激活稀疏性来改善 LLM 的计算成本，但下游任务的性能显着下降。在这项工作中，我们引入了一个新的框架，用于稀疏化基础 LLM 的激活并降低推理成本，称为稀疏上下文感知阈值（CATS）。 CATS相对简单、易于实施且高效。我们框架的核心是一个新的非线性激活函数。我们证明 CATS 可以应用于各种基础模型，包括 Mistral-7B 和 Llama2-7B，并且在下游任务性能方面优于现有的稀疏化技术。更准确地说，基于 CATS 的模型通常会在不进行任何微调的情况下，甚至在激活稀疏度为 50% 的情况下，实现下游任务性能在其基本模型的 1-2% 范围内。此外，在应用微调时，基于 CATS 的模型收敛速度更快，并且比竞争技术显示出更好的任务性能。最后，我们开发了一个定制的 GPU 内核，用于高效实现 CATS，将 CATS 稀疏性的激活转化为真正的挂钟时间加速。我们的 CATS 自定义内核实现使 Llama-7B 和 Mistral-7B 上令牌生成的挂钟推理延迟提高了约 15%。]]></description>
      <guid>https://arxiv.org/abs/2404.08763</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>超越一刀切：根据用户目标调整反事实解释</title>
      <link>https://arxiv.org/abs/2404.08721</link>
      <description><![CDATA[arXiv:2404.08721v1 公告类型：新
摘要：可解释人工智能（XAI）已成为旨在提高人工智能系统透明度和可解释性的关键研究领域。反事实解释 (CFE) 通过探索某些因素不同的替代场景，为机器学习算法的决策过程提供有价值的见解。尽管 CFE 在 XAI 社区中越来越受欢迎，但现有文献常常忽视不同应用程序和领域的用户的不同需求和目标，导致缺乏充分解决不同用例的定制解释。在本文中，我们主张对 CFE 进行细致入微的理解，认识到基于用户目标和目标应用程序所需属性的可变性。我们确定了三个主要用户目标，并探讨了每种情况下 CFE 所需的特征。通过解决这些差异，我们的目标是设计更有效、更有针对性的解释，以满足用户的特定需求，从而增强与人工智能系统的协作。]]></description>
      <guid>https://arxiv.org/abs/2404.08721</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>FastLogAD：使用掩码引导的伪异常生成和辨别进行日志异常检测</title>
      <link>https://arxiv.org/abs/2404.08750</link>
      <description><![CDATA[arXiv:2404.08750v1 公告类型：新
摘要：当今大型计算机广泛输出日志来记录运行状态，从实时日志提供的信息中识别任何可疑或恶意活动变得至关重要。因此，快速日志异常检测是实现不可行的手动检测自动化的必要任务。大多数现有的无监督方法仅在正常日志数据上进行训练，但它们通常需要额外的异常数据用于超参数选择或辅助数据集用于判别模型优化。在本文中，为了实现快速异常检测的高效判别模型，我们提出了FastLogAD，这是一种经过训练的生成器-判别器框架，可以通过掩模引导异常生成（MGAG）模型高效地展示生成伪异常日志的能力通过判别性异常分离（DAS）模型识别异常日志。特别是，伪异常日志是通过用不太可能的候选者替换正常序列中随机屏蔽的标记来生成的。在判别阶段，FastLogAD 根据嵌入规范学习正常样本和伪异常样本之间的明显区别，从而允许在不接触任何测试数据的情况下选择阈值并实现有竞争力的性能。对几个常见基准的广泛实验表明，我们提出的 FastLogAD 优于现有的异常检测方法。此外，与之前的方法相比，FastLogAD 的异常检测速度至少比之前的工作提高了 10 倍。我们的实现可在 https://github.com/YifeiLin0226/FastLogAD 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.08750</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以从错误中继续发展</title>
      <link>https://arxiv.org/abs/2404.08707</link>
      <description><![CDATA[arXiv:2404.08707v1 公告类型：新
摘要：大型语言模型（LLM）在各种下游任务中表现出了令人印象深刻的性能。然而，由于知识的缺乏和预训练数据的缺陷，它们在某些场景下仍然可能产生错误的响应。持续学习（CL）是解决这个问题的常用方法。传统的 CL 是面向任务的，使用新颖的或事实上准确的数据从头开始重新培训法学硕士。然而，这种方法需要更多与任务相关的训练数据，并且会产生昂贵的训练成本。为了应对这一挑战，受“总结错误”学习技巧的启发，我们提出了“从错误中继续进化”（CEM）方法，以实现法学硕士的迭代完善。具体来说，法学硕士的错误回答表明了与问题相关的知识缺陷。因此，我们从多个数据源收集这些知识的语料，并进行迭代补充训练，持续、有针对性地更新和补充知识。同时，我们制定了两种策略来构建补充训练集，以增强法学硕士对语料库的理解并防止灾难性遗忘。我们进行了大量的实验来验证这种 CL 方法的有效性。在最好的情况下，我们的方法使 LLM 的准确性提高了 17.00%。]]></description>
      <guid>https://arxiv.org/abs/2404.08707</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>$F_\beta$-plot——评估不平衡数据分类器的可视化工具</title>
      <link>https://arxiv.org/abs/2404.08709</link>
      <description><![CDATA[arXiv:2404.08709v1 公告类型：新
摘要：与不平衡数据分类相关的重大问题之一是缺乏可靠的指标。这主要是因为对于大多数现实生活（以及常用的基准）问题，我们没有从用户那里获得有关应最小化的损失函数的实际形式的信息。尽管指示每个类别内的分类质量的指标很常见，但对于最终用户来说，需要对多个此类指标进行分析，这在实践中会导致难以解释给定分类器的有用性。因此，针对不平衡数据分类问题，已经提出或采用了许多聚合指标，但对于应该使用哪些指标仍没有达成共识。另一个缺点是它们对某一类的模糊性和系统性偏见。此外，它们在分析实验结果以识别那些对于所选聚合指标表现良好的分类模型中的使用存在上述缺点。因此，本文提出了一种简单的方法来分析流行的参数度量 $F_\beta$。我们指出，对于给定的分析分类器池，可以根据用户需求指示何时应首选给定模型。]]></description>
      <guid>https://arxiv.org/abs/2404.08709</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>探索长尾多标签文本分类的对比学习</title>
      <link>https://arxiv.org/abs/2404.08720</link>
      <description><![CDATA[arXiv:2404.08720v1 公告类型：新
摘要：学习多标签文本分类（MLTC）中的有效表示是 NLP 中的一个重大挑战。这一挑战源于任务固有的复杂性，该复杂性由两个关键因素决定：标签之间错综复杂的联系和数据广泛的长尾分布。为了克服这个问题，一种可能的方法是将监督对比学习与经典监督损失函数相结合。尽管对比学习在多类分类中表现出了显着的性能，但其在多标签框架中的影响尚未得到彻底研究。在本文中，我们深入研究了监督对比学习及其对 MLTC 背景下表征的影响。我们强调考虑长尾数据分布来构建强大的表示空间的重要性，这有效地解决了我们确定的与对比学习相关的两个关键挑战：“缺乏积极因素”和“吸引-排斥不平衡”。基于这一见解，我们为 MLTC 引入了一种新颖的对比损失函数。它获得的 Micro-F1 分数与其他常用损失函数获得的分数相匹配或超过，并且在三个多标签数据集上展示了 Macro-F1 分数的显着改进。]]></description>
      <guid>https://arxiv.org/abs/2404.08720</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>对比学习可以细化嵌入吗</title>
      <link>https://arxiv.org/abs/2404.08701</link>
      <description><![CDATA[arXiv:2404.08701v1 公告类型：新
摘要：对比学习的最新进展彻底改变了自监督表示学习，并在基准任务上实现了最先进的性能。虽然大多数现有方法侧重于将对比学习应用于图像、自然语言句子或网络等输入数据模态，但它们忽视了利用先前训练的编码器输出的潜力。在本文中，我们介绍了 SIMSKIP，这是一种新颖的对比学习框架，专门针对下游任务细化输入嵌入。与传统的无监督学习方法不同，SIMSKIP 利用编码器模型的输出嵌入作为输入。通过理论分析，我们提供的证据表明，与作为 SIMSKIP 输入的原始嵌入相比，应用 SIMSKIP 不会导致下游任务错误的上限更大。各种开放数据集上的实验结果表明，SIMSKIP 生成的嵌入提高了下游任务的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.08701</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习对印度不同城市和邦的空气质量指数 (AQI) 进行预测建模：调查旁遮普邦焚烧秸秆对 AQI 变异的影响</title>
      <link>https://arxiv.org/abs/2404.08702</link>
      <description><![CDATA[arXiv:2404.08702v1 公告类型：新
【摘要】：空气污染是当今社会普遍存在的严重问题,对人类健康造成的危害不容忽视。为了主动解决这个问题，人们应该了解他们的周围环境，即他们赖以生存的环境。出于这个动机，本研究根据大气中不同空气污染物浓度预测了AQI。本研究使用的数据集取自CPCB官方网站。该数据集包含德里、哈里亚纳邦和旁遮普邦不同城市 22 个不同监测站的空气污染物浓度。检查此数据是否有空值和异常值。但是，最需要注意的是对这些价值观的正确理解和归因，而不是忽视或错误的归因。本研究使用了时间序列数据，并使用迪基-富勒检验来测试平稳性。其他不同的 ML 模型（如 CatBoost、XGBoost、随机森林、SVM 回归器、时间序列模型 SARIMAX 和深度学习模型 LSTM）已被用于预测 AQI。对于不同模型的性能评估，我使用了MSE、RMSE、MAE和R2。据观察，与其他模型相比，随机森林表现更好。]]></description>
      <guid>https://arxiv.org/abs/2404.08702</guid>
      <pubDate>Tue, 16 Apr 2024 06:17:18 GMT</pubDate>
    </item>
    </channel>
</rss>