<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 31 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>解读 SDXL Turbo：使用稀疏自动编码器解释文本到图像模型</title>
      <link>https://arxiv.org/abs/2410.22366</link>
      <description><![CDATA[arXiv:2410.22366v1 公告类型：新
摘要：稀疏自动编码器 (SAE) 已成为大型语言模型 (LLM) 逆向工程的核心要素。对于 LLM，它们已被证明可以将通常无法直接解释的中间表示分解为可解释特征的稀疏和，从而有助于更好的控制和后续分析。然而，文本到图像模型缺乏类似的分析和方法。我们研究了使用 SAE 学习可解释特征的可能性，用于几步文本到图像扩散模型，例如 SDXL Turbo。为此，我们在 SDXL Turbo 的去噪 U-net 中的变压器块执行的更新上训练 SAE。我们发现它们学习到的特征是可解释的，对生成过程有因果影响，并揭示了块之间的专业化。特别是，我们发现一个块主要处理图像合成，一个块主要负责添加局部细节，一个块负责颜色、照明和风格。因此，我们的工作是更好地理解生成文本到图像模型（如 SDXL Turbo）内部结构的重要第一步，并展示了 SAE 学习到的视觉领域特征的潜力。
代码可在 https://github.com/surkovv/sdxl-unbox 获得]]></description>
      <guid>https://arxiv.org/abs/2410.22366</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的随机微分方程中不确定性传播的误差界限</title>
      <link>https://arxiv.org/abs/2410.22371</link>
      <description><![CDATA[arXiv:2410.22371v1 公告类型：新
摘要：随机微分方程通常用于描述随机过程的演变。此类过程的不确定性最好由概率密度函数 (PDF) 表示，其演变受 Fokker-Planck 偏微分方程 (FP-PDE) 控制。然而，通常无法以封闭形式求解 FP-PDE。在这项工作中，我们表明可以使用现有方法训练物理信息神经网络 (PINN) 来近似解 PDF。主要贡献是对近似误差的分析：我们开发了一种理论来用 PINN 构建任意紧密的误差界限。此外，我们推导出一个实际的误差界限，可以用现有的训练方法有效地构建。最后，我们解释了这种误差界限理论推广到其他线性 PDE 的近似解。进行了几次数值实验来证明和验证所提出的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.22371</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于可解释图形推理的分层语言模型</title>
      <link>https://arxiv.org/abs/2410.22372</link>
      <description><![CDATA[arXiv:2410.22372v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于图形任务。尽管 LLM 在基于文本的任务中取得了显著的成功，但它们在理解显式图形结构方面的能力仍然有限，尤其是对于大型图形。在这项工作中，我们引入了图形的分层语言模型 (HLM-G)，它采用双块架构来捕获以节点为中心的局部信息和以交互为中心的全局结构，从而有效地增强了图形结构理解能力。所提出的方案允许 LLM 以高效率、高效率和高鲁棒性处理各种图形查询，同时降低大规模图形任务的计算成本。此外，我们使用内在注意力权重和已建立的解释器证明了我们模型的可解释性。对节点、链接和图形级别的各种图形推理和实际任务的全面评估凸显了我们方法的优越性，标志着 LLM 在图理解中的应用取得了重大进展。]]></description>
      <guid>https://arxiv.org/abs/2410.22372</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态损坏的分析连续测试时间自适应</title>
      <link>https://arxiv.org/abs/2410.22373</link>
      <description><![CDATA[arXiv:2410.22373v1 公告类型：新 
摘要：测试时间自适应 (TTA) 旨在帮助预训练模型仅使用预训练模型和未标记的测试数据来弥合源数据集和目标数据集之间的差距。TTA 的一个关键目标是解决由损坏（例如天气变化、噪音或传感器故障）引起的测试数据域变化。多模态连续测试时间自适应 (MM-CTTA) 是 TTA 的扩展，具有更好的实际应用，它进一步允许预训练模型处理多模态输入并适应不断变化的目标域。MM-CTTA 通常面临的挑战包括错误累积、灾难性遗忘和可靠性偏差，现有的方法很少能有效地解决多模态损坏场景中的这些问题。在本文中，我们为 MM-CTTA 任务提出了一种新方法，即多模态动态分析适配器 (MDAA)。我们创新性地将分析学习引入 TTA，使用分析分类器 (AC) 来防止模型遗忘。此外，我们开发了动态选择机制 (DSM) 和软伪标签策略 (SPS)，使 MDAA 能够动态过滤可靠样本并整合来自不同模态的信息。大量实验表明，MDAA 在 MM-CTTA 任务上实现了最佳性能，同时确保了可靠的模型自适应。]]></description>
      <guid>https://arxiv.org/abs/2410.22373</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用遗忘神经网络进行机器反学习</title>
      <link>https://arxiv.org/abs/2410.22374</link>
      <description><![CDATA[arXiv:2410.22374v1 公告类型：新
摘要：现代计算机系统存储了大量个人数据，推动了人工智能和机器学习的发展，但也冒着侵犯用户隐私和信任的风险。出于隐私原因，有时希望机器学习模型忘记部分训练数据。本文介绍了一种使用遗忘神经网络 (FNN) 进行机器反学习的新方法。FNN 是具有特定遗忘层的神经网络，其灵感来自于人类大脑遗忘的过程。虽然 FNN 已被提出作为一种理论构造，但它们以前从未被用作机器反学习方法。我们描述了四种不同类型的遗忘层并研究了它们的属性。在我们的实验评估中，我们报告了在 MNIST 手写数字识别和时尚数据集上的结果。使用成员推理攻击 (MIA) 测试了未学习模型的有效性。成功的实验结果证明了我们提出的方法在处理机器反学习问题方面的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.22374</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从稀有到频繁：在法学硕士的指导下解锁稀有概念扩散模型的组合生成能力</title>
      <link>https://arxiv.org/abs/2410.22376</link>
      <description><![CDATA[arXiv:2410.22376v1 公告类型：新
摘要：最先进的文本到图像 (T2I) 扩散模型通常难以生成罕见的概念组合，例如具有不寻常属性的对象。在本文中，我们表明，通过大型语言模型 (LLM) 指导可以显着增强扩散模型对此类罕见概念的组合生成能力。我们从实证和理论分析开始，证明在扩散采样过程中暴露与目标稀有概念相关的频繁概念可以产生更准确的概念组合。基于此，我们提出了一种无需训练的方法 R2F，该方法利用 LLM 中丰富的语义知识在整个扩散推理过程中规划和执行整体从稀有到频繁的概念指导。我们的框架在任何预训练的扩散模型和 LLM 中都是灵活的，并且可以与区域引导的扩散方法无缝集成。在包括我们新提出的基准 RareBench 在内的三个数据集上进行了大量实验，其中包含具有罕见概念组合的各种提示，R2F 在 T2I 对齐方面显著超越了现有模型（包括 SD3.0 和 FLUX），最高可达 28.1%。代码可在 https://github.com/krafton-ai/Rare2Frequent 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.22376</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于时间序列预测和分类的时空图神经网络模型的系统文献综述</title>
      <link>https://arxiv.org/abs/2410.22377</link>
      <description><![CDATA[arXiv:2410.22377v1 公告类型：新
摘要：近年来，时空图神经网络 (GNN) 因其能够捕捉变量之间和跨时间点的依赖关系而引起了时间序列分析领域的极大兴趣。因此，本系统文献综述的目的是全面概述 GNN 用于时间序列分类和预测的各种建模方法和应用领域。进行了数据库搜索，并选择了 150 多篇期刊论文，以详细研究该领域的当前最新技术。本次审查旨在为读者提供全面的拟议模型集合、相关源代码链接、可用数据集、基准模型和拟合结果。希望所有这些信息能够帮助研究人员进行未来的研究。据我们所知，这是第一篇系统的文献综述，详细比较了不同领域的当前时空 GNN 模型的结果。此外，本评论的最后一部分讨论了时空 GNN 应用中当前的局限性和挑战，例如可比性、可重复性、可解释性、信息容量差和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2410.22377</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过边界条件扩散过程进行离散建模</title>
      <link>https://arxiv.org/abs/2410.22380</link>
      <description><![CDATA[arXiv:2410.22380v1 公告类型：新
摘要：我们提出了一个新颖的框架，可以有效地将强大的连续扩散过程扩展到离散建模。以前的方法受到离散数据和连续建模之间差异的影响。我们的研究表明，学习概率轮廓时缺乏离散边界的指导是主要原因之一。为了解决这个问题，我们提出了一个两步前向过程，首先将边界估计为先验分布，然后重新调整前向轨迹以构建边界条件扩散模型。反向过程按比例调整，以保证学习到的轮廓产生更精确的离散数据。实验结果表明，我们的方法在语言建模和离散图像生成任务中都取得了很好的效果。在语言建模方面，我们的方法在三个翻译任务和一个总结任务中超越了以前最先进的连续扩散语言模型，同时与自回归变压器相比也表现出了竞争力。此外，我们的方法在使用离散序数像素时实现了与连续扩散模型相当的结果，并为 Cifar-10 数据集上的分类图像生成建立了新的最先进技术。]]></description>
      <guid>https://arxiv.org/abs/2410.22380</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有不变统计损失的多元重尾分布隐式生成模型的稳健训练</title>
      <link>https://arxiv.org/abs/2410.22381</link>
      <description><![CDATA[arXiv:2410.22381v1 公告类型：新
摘要：传统的隐式生成模型能够学习高度复杂的数据分布。然而，它们的训练涉及使用对抗性鉴别器区分真实数据和合成生成的数据，这可能导致不稳定的训练动态和模式丢失问题。在这项工作中，我们基于 \cite{de2024training} 中引入的 \textit{不变统计损失} (ISL) 方法，并将其扩展为处理重尾和多变量数据分布。
许多现实世界现象生成的数据只能使用重尾概率分布来正确表征，而传统的隐式方法难以有效捕捉它们的渐近行为。为了解决这个问题，我们引入了一个用 ISL 训练的生成器，它使用来自广义帕累托分布 (GPD) 的输入噪声。为了简洁起见，我们将这种生成方案称为 Pareto-ISL。我们的实验表明，Pareto-ISL 可以准确地对分布的尾部进行建模，同时仍然有效地捕捉它们的核心特征。
原始 ISL 函数是为 1D 数据集设计的。当实际数据为 $n$ 维时，通过针对数据的 $n$ 个边际分布，可以获得该方法的直接扩展。这种方法在高维空间中在计算上不可行且无效。为了克服这个问题，我们使用随机投影扩展了 1D 方法，并定义了一个适合多变量数据的新损失函数，通过调整投影数量使问题易于处理。我们评估了它在多维生成建模中的表现，并探索了它作为生成对抗网络 (GAN) 的预训练技术的潜力，以防止模式崩溃，报告了有希望的结果并强调了它在各种超参数设置中的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.22381</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FNDEX：利用可解释的人工智能检测虚假新闻和网络人肉搜索</title>
      <link>https://arxiv.org/abs/2410.22390</link>
      <description><![CDATA[arXiv:2410.22390v1 公告类型：新
摘要：广泛而多样的在线媒体平台和其他互联网驱动的通信技术在界定言论自由的界限方面提出了重大挑战。因此，互联网已转变为潜在的网络武器。在这个不断发展的环境中，出现了两种特别危险的现象：假新闻和人肉搜索。尽管这些威胁已成为广泛学术分析的主题，但它们相交的十字路口仍未被探索。这项研究通过引入一个新系统来解决这种融合问题。可解释人工智能的假新闻和人肉搜索检测 (FNDEX) 系统利用三种不同的转换器模型的功能来实现对假新闻和人肉搜索的高性能检测。为了增强数据安全性，采用了严格的三步匿名化过程，该过程植根于一种基于模式的方法来匿名化个人身份信息。最后，这项研究强调了为两种检测模型产生的结果生成连贯解释的重要性。我们在现实数据集上的实验表明，我们的系统明显优于现有基线]]></description>
      <guid>https://arxiv.org/abs/2410.22390</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型循环动作模型：xLSTM 助力机器人任务快速推理</title>
      <link>https://arxiv.org/abs/2410.22391</link>
      <description><![CDATA[arXiv:2410.22391v1 公告类型：新
摘要：近年来，强化学习 (RL) 领域出现了一种趋势，即通过序列建模在大型数据集上离线训练大型动作模型。现有模型主要基于 Transformer 架构，从而产生强大的代理。然而，由于推理时间较慢，基于 Transformer 的方法不适用于机器人等实时应用。最近，人们提出了现代循环架构，如 xLSTM 和 Mamba，它们在训练过程中表现出与 Transformer 架构类似的并行化优势，同时提供快速推理。在这项工作中，我们研究了这些现代循环架构对大型动作模型的适应性。因此，我们提出了一个以 xLSTM 为核心的大型循环动作模型 (LRAM)，它具有线性时间推理复杂度和自然序列长度外推能力。对来自 6 个领域的 432 个任务进行的实验表明，LRAM 在性能和速度方面与 Transformers 相比具有优势。]]></description>
      <guid>https://arxiv.org/abs/2410.22391</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过深度神经网络对抗训练实现功率侧信道泄漏定位</title>
      <link>https://arxiv.org/abs/2410.22425</link>
      <description><![CDATA[arXiv:2410.22425v1 公告类型：新
摘要：监督式深度学习已成为对加密实现进行功率侧信道攻击的有效工具。虽然越来越强大的基于深度学习的攻击定期发布，但使用深度学习来防御这些攻击的工作相对较少。在这项工作中，我们提出了一种技术来识别功率轨迹中哪些时间步长负责泄露加密密钥，通过基于深度学习的侧信道攻击者与可训练噪声生成器之间的对抗游戏，攻击者试图从加密期间记录的功率轨迹中对敏感变量进行分类，而可训练噪声生成器试图通过在功率轨迹中引入最少量的噪声来阻止这种攻击。我们在合成数据集上证明，在存在布尔掩码和轨迹去同步等常见对策的情况下，我们的方法可以胜过现有技术。由于该技术对超参数和早期停止点高度敏感，并且我们缺乏用于模型选择的具有泄漏点基本事实知识的保留数据集，因此在真实数据集上的结果较差。尽管如此，我们相信我们的工作代表了向深度侧信道泄漏定位迈出的重要一步，而无需依赖对实施或泄漏性质的强假设。我们提供了实验的开源 PyTorch 实现。]]></description>
      <guid>https://arxiv.org/abs/2410.22425</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习可识别的细胞反应因果表示</title>
      <link>https://arxiv.org/abs/2410.22472</link>
      <description><![CDATA[arXiv:2410.22472v1 公告类型：新
摘要：研究细胞及其对遗传或化学扰动的反应有望加速发现治疗靶点。然而，为此类数据设计充分且有见地的模型很困难，因为细胞对扰动的反应本质上取决于其生物学背景（例如遗传背景或细胞类型）。例如，在发现治疗靶点时，人们可能希望丰富专门针对特定细胞类型的药物。这一挑战强调了明确考虑药物和环境之间潜在相互作用的方法的必要性。为了实现这一目标，我们提出了一种新颖的因果分解因果表示 (FCR) 学习方法，揭示了来自多个细胞系的单细胞扰动数据中的因果结构。基于可识别深度生成模型的框架，FCR 学习多个解开的细胞表征，包括协变量特定 ($\mathbf{z}_x$)、治疗特定 ($\mathbf{z}_{t}$) 和交互特定 ($\mathbf{z}_{tx}$) 块。基于非线性 ICA 理论的最新进展，我们证明了 $\mathbf{z}_{tx}$ 的组件可识别性以及 $\mathbf{z}_t$ 和 $\mathbf{z}_x$ 的块可识别性。然后，我们介绍了 FCR 的实现，并通过经验证明它在四个单细胞数据集的各种任务中都优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2410.22472</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过点集扩散解锁点过程</title>
      <link>https://arxiv.org/abs/2410.22493</link>
      <description><![CDATA[arXiv:2410.22493v1 公告类型：新
摘要：点过程模拟数学空间（例如空间和时间域）中随机点集的分布，可应用于地震学、神经科学和经济学等领域。现有的点过程统计和机器学习模型主要受制于对特征强度函数的依赖，从而引入了效率和灵活性之间的固有权衡。在本文中，我们介绍了点集扩散，这是一种基于扩散的隐变量模型，它可以表示一般度量空间上的任意点过程，而无需依赖强度函数。通过直接学习在噪声和数据点集之间随机插值，我们的方法能够对度量空间上定义的复杂条件任务进行高效、并行采样和灵活生成。在合成和真实世界数据集上进行的实验表明，点集扩散在无条件和有条件生成空间和时空点过程方面实现了最先进的性能，同时提供比自回归基线快几个数量级的采样。]]></description>
      <guid>https://arxiv.org/abs/2410.22493</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态结构保存学习</title>
      <link>https://arxiv.org/abs/2410.22520</link>
      <description><![CDATA[arXiv:2410.22520v1 公告类型：新
摘要：在实际应用中选择数据来构建机器学习模型时，可用性、获取成本和判别能力等因素是至关重要的考虑因素。不同的数据模式通常会捕捉到潜在现象的独特方面，从而使它们的效用互补。另一方面，一些数据源承载着对其价值至关重要的结构信息。因此，有时可以通过匹配另一种数据类型的结构来增强一种数据类型的效用。我们提出了多模态结构保存学习 (MSPL) 作为一种学习数据表示的新方法，它利用一种数据模式提供的聚类结构来增强另一种模态数据的效用。我们证明了 MSPL 在揭示合成时间序列数据中的潜在结构以及使用质谱数据从全基因组测序和抗菌素耐药性数据中恢复聚类以支持流行病学应用方面的有效性。结果表明，MSPL 可以为学习到的特征注入外部结构，并有助于获得跨不同数据模式发生的有益协同作用。]]></description>
      <guid>https://arxiv.org/abs/2410.22520</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>