<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>不断学习的准牛顿方法</title>
      <link>https://arxiv.org/abs/2503.19939</link>
      <description><![CDATA[ARXIV：2503.19939V1公告类型：新 
摘要：当神经网络依次学习任务时，灾难性的遗忘仍然是一个重大挑战。弹性重量巩固（EWC）试图通过引入贝叶斯风格的正则化损失来解决此问题，以保留以前学到的任务的知识。但是，EWC依赖于laplace近似，在该拉普拉斯近似中，假设模型参数不相关，则将Hessian简化为Fisher Information矩阵的对角线。这种过于简单的假设通常会导致黑森州的估计差，从而限制了其有效性。为了克服这一限制，我们使用采样的准Newton（CSQN）介绍了持续的学习，该方法利用了准Newton方法来计算更准确的Hessian近似值。 CSQN捕获了对角线以外的参数交互，而无需特定于体系结构的修改，从而使其适用于各种任务和体系结构。四个基准测试的实验结果表明，CSQN始终优于EWC和其他最先进的基线，包括基于排练的方法。 CSQN将EWC的遗忘减少了50％，并将其绩效平均提高了8％。值得注意的是，CSQN在四个基准中的三个（包括最具挑战性的场景）上取得了卓越的成果，突出了其作为持续学习的强大解决方案的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.19939</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>logQuant：较高精度保存的对数分布的KV缓存的2位量化</title>
      <link>https://arxiv.org/abs/2503.19950</link>
      <description><![CDATA[ARXIV：2503.19950V1公告类型：新 
摘要：我们介绍了logquant，这是一种针对大型语言模型（LLM）推断的KV缓存的开创性的2位量化技术，在保留出色的性能的同时，可节省大量内存。先前的方法要么假设以后的令牌更重要，要么试图根据早期的注意模式预测重要的令牌。但是，两种方法都可以导致性能瓶颈或频繁的错误预测。
  logquant采用了不同的方法。通过应用基于日志的过滤机制，它可以在整个上下文中有选择地压缩KV缓存，与现有方法相比，通过相同甚至减少的内存足迹实现更好的性能。在基准测试中，它可将吞吐量提高25％，并使批次大小增加60％，而不会增加记忆消耗。对于诸如数学和代码完成之类的具有挑战性的任务，LogQuant在相同的压缩率下将准确性提高了40％至200％，表现优于可比较的技术。Logquant毫不费力地与Python的Transformers库库（如Python&#39;s Transformers库）毫不费力地集成。实施可以在https://github.com/concyclics/logquantkv中提供。]]></description>
      <guid>https://arxiv.org/abs/2503.19950</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Excot：使用执行反馈优化文本到SQL的推理</title>
      <link>https://arxiv.org/abs/2503.19988</link>
      <description><![CDATA[ARXIV：2503.19988V1公告类型：新 
摘要：文本到SQL需要精确的推理将自然语言问题转换为结构化查询。尽管大型语言模型（LLMS）在许多推理任务中都表现出色，但它们利用文本到SQL的思想链（COT）推理的能力仍未得到充实。我们确定临界局限性：零射cot提供最小的收益，而直接偏好优化（DPO）不带COT产生边缘改善。我们提出了Excot，这是一个新颖的框架，它通过将COT推理与外部和政策的DPO相结合，从而迭代地优化开源LLM，仅依赖于执行精度作为反馈。这种方法消除了对奖励模型或人类宣传的偏好的需求。
  我们的实验结果表明了绩效的显着增长：Excot将鸟类开发的执行精度从57.37％提高到68.51％，蜘蛛测试集从78.81％到Llama-3 70B的78.81％到86.59％，QWEN-2.5-ECODER证明了相似的改进。我们的最佳模型在鸟类和蜘蛛数据集的单模设置中实现了最先进的性能，在鸟类测试集中尤其达到68.53％。]]></description>
      <guid>https://arxiv.org/abs/2503.19988</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经验重播解决了持续学习中可塑性的丧失</title>
      <link>https://arxiv.org/abs/2503.20018</link>
      <description><![CDATA[ARXIV：2503.20018V1公告类型：新 
摘要：可塑性的丧失是深层神经网络不断学习的主要挑战之一，在该网络中，通过反向传播训练的神经网络逐渐失去了其适应新任务的能力，并且比新刚开始初始化的同行训练。本文的主要贡献是提出一个新的假设，该假设重播了持续学习中可塑性的丧失。在这里，体验重播是一种记忆的一种形式。我们为这一假设提供了支持证据。特别是，我们在多个不同的任务中演示了包括回归，分类和政策评估，即通过简单地添加体验重播并处理经验中的数据重播中的数据，可塑性的丧失就消失了。值得注意的是，我们不会改变深度学习的任何标准组成部分。例如，我们不会改变反向传播。我们不修改激活函数。而且我们不使用任何正则化。我们猜测，由于存在膜的学习现象，经验重播和变压器可以解决可塑性的丧失。]]></description>
      <guid>https://arxiv.org/abs/2503.20018</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习方法跨造血谱系的血液疾病诊断</title>
      <link>https://arxiv.org/abs/2503.20049</link>
      <description><![CDATA[ARXIV：2503.20049V1公告类型：新 
摘要：我们提出了一个基础建模框架，该框架利用深度学习来揭示整个造血等级的潜在遗传特征。我们的方法在多能祖细胞上训练完全连接的自动编码器，将超过20,000个基因特征降低到256维的潜在空间，从而捕获祖细胞和下游分化细胞（如单核细胞和淋巴细胞）的预测信息。我们通过训练前进，变压器和图形卷积架构来验证这些嵌入的质量，以实现血液疾病诊断任务。我们还使用祖细胞疾病状态分类模型来探索零拍的预测，以对下游细胞条件进行分类。对于多类分类，我们的模型达到了超过95％的精度，在零射击设置中，我们在二进制分类任务上取得了超过0.7 f1得分。未来的工作应进一步改善嵌入，以提高淋巴细胞分类的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2503.20049</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>抽象地理特定地形以扩展强化学习</title>
      <link>https://arxiv.org/abs/2503.20078</link>
      <description><![CDATA[ARXIV：2503.20078V1公告类型：新 
摘要：多代理增强学习（MARL）在训练动态和适应性合成特征中越来越无处不在，用于在地理特定地形上进行交互式模拟。 Unity的ML代理等框架有助于使模拟社区更容易获得这样的加强学习实验。军事训练模拟也从MARL的进步中受益，但由于它们的复杂，连续，随机，可观察到的，非平稳和基于学说的本性，它们具有巨大的计算要求。此外，这些模拟需要特定地理地形，进一步加剧了计算资源问题。在我们的研究中，我们利用Unity的路点自动生成地理特定地形的多层表示抽象来扩展强化学习，同时仍允许在不同表示之间传递学术策略。我们对新型MARL场景的早期探索结果，双方都有不同的目标，这表明基于Waypoint的导航可以更快，更有效地学习，同时产生与CSGO游戏环境中专家人类玩家相似的轨迹。这项研究指出了基于路点的导航的潜力，用于减少用于军事训练模拟的MALL模型的计算成本，在该模型中，特定地理地形和不同目标至关重要。]]></description>
      <guid>https://arxiv.org/abs/2503.20078</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于在线多内核学习的随机基于功能的双Vovk-azoury-gorhuth算法</title>
      <link>https://arxiv.org/abs/2503.20087</link>
      <description><![CDATA[ARXIV：2503.20087V1公告类型：新 
摘要：我们介绍了一种新颖的多内核学习算法，VAW $^2 $，用于在线最小二乘在复制内核Hilbert Spaces（RKHS）中回归。 VAW $^2 $在两级过程中利用基于随机傅立叶功能的功能近似和Vovk-azoury-warmuth（VAW）方法：VAW用于从第一级为每个内核生成的随机特征构建专家策略，然后再次将其预测组合到第二级。当随机特征的数量缩放为$ t^{1/2} $时，理论分析在$ o（t^{1/2} \ ln t）$方面产生的后悔限制。一些基准数据集的经验结果表明，与现有的在线多内核学习算法：Raker和OMKL-GF以及其他理论上基础的方法相比，VAW $^2 $的性能优于较高的性能，这些方法涉及第二级专家预测的凸组合。]]></description>
      <guid>https://arxiv.org/abs/2503.20087</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>完美概念擦除的基本限制</title>
      <link>https://arxiv.org/abs/2503.20098</link>
      <description><![CDATA[ARXIV：2503.20098V1公告类型：新 
摘要：概念擦除是从表示集中删除有关概念（例如性别或种族）信息的任务，同时保留了最大可能的实用程序 - 来自原始表示的信息。概念擦除在几种应用中很有用，例如删除敏感概念以实现公平性并解释特定概念对模型性能的影响。以前的概念擦除技术优先考虑坚固的概念，而不是保留所得代表的实用性。但是，在擦除和保留效用之间似乎存在一个内在的权衡，这使得如何在保持高效用的同时如何实现完美的概念擦除。在本文中，我们通过通过信息理论镜头来量化概念擦除的基本限制来解决解决此问题的新观点。使用这些结果，我们研究了对数据分布的限制以及达到完美概念擦除限制所需的擦除功能。从经验上讲，我们表明衍生的擦除函数达到了最佳的理论界限。此外，我们表明，使用GPT-4表示，我们的方法在一系列合成和现实世界数据集上的现有方法优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.20098</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可扩展的长胜压计划通过分层多尺度扩散</title>
      <link>https://arxiv.org/abs/2503.20102</link>
      <description><![CDATA[ARXIV：2503.20102V1公告类型：新 
摘要：本文解决了一个新的问题，可扩展的长匹能计划代理，以计划轨迹比训练数据中的轨迹更长，而没有复杂的错误。为了解决这个问题，我们提出了层次多尺度扩散器（HM-Diffuser）和渐进轨迹扩展（PTE），这是一种增强方法，它通过缝制较短的方法来迭代地产生较长的轨迹。 HM-Diffuser使用分层结构对这些扩展轨迹进行训练，并有效地处理多个时间尺度的任务。此外，我们引入了自适应计划思考和递归HM-Diffuser，该计划将分层层巩固到单个模型中，以递归处理时间尺度。实验结果证明了我们的方法的有效性，可以推进基于扩散的规划师进行可扩展的长马计划。]]></description>
      <guid>https://arxiv.org/abs/2503.20102</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于转动移动计数估算的域适应框架有限的数据</title>
      <link>https://arxiv.org/abs/2503.20113</link>
      <description><![CDATA[ARXIV：2503.20113V1公告类型：新 
摘要：城市交通网络对于人们和商品的有效运输至关重要，需要有效的交通管理和计划。交通管理的一个不可或缺的一部分是了解交叉点处的转弯运动数（TMC），交叉点的准确TMC对于交通信号控制，缓解拥堵和道路安全至关重要。通常，使用安装在十字路口的物理传感器获得TMC，但是这种方法可能会过于良性且技术上具有挑战性，尤其是对于拥有广泛道路网络的城市而言。机器学习和数据驱动方法的最新进展为估计TMC提供了有希望的替代方案。由于道路几何形状，交通信号设置和本地驾驶员行为等因素，交通模式在不同的交叉点之间可能会有很大差异。当应用于新的或看不见的交叉点时，该域差异限制了机器学习模型的普遍性和准确性。针对这些局限性，本研究提出了一个新颖的框架，利用域适应性（DA）来通过使用基于交通控制器事件的​​数据，道路基础架构数据和利益点（POI）数据来估算交叉点的TMC。在亚利桑那州图森的30个交叉点上进行了评估，将提出的DA框架的性能与最先进的模型进行了比较，并以平均绝对误差和根平方误差的方式达到了最低的值。]]></description>
      <guid>https://arxiv.org/abs/2503.20113</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从解释到校正：一个分散的优化框架，用于联合学习中的精确收敛</title>
      <link>https://arxiv.org/abs/2503.20117</link>
      <description><![CDATA[ARXIV：2503.20117V1公告类型：新 
摘要：这项工作引入了一个新颖的分散框架，以解释联邦学习（FL），因此，纠正了由任意客户参与和数据异质性引入的偏见，这是实用FL中的两个典型特征。具体而言，我们首先将FedAvg的核心过程重新制定为客户参与，本地更新和模型聚合 - 作为随机矩阵乘法。这种重新制定使我们能够将FedAvg解释为一种分散的算法。利用分散的优化框架，我们能够提供简洁的分析，以量化任意客户参与和数据异质性对FedAvg收敛点的影响。这种洞察力激发了通过推动策略（Focus）精确收敛的联合优化的发展，这是一种受分散算法启发的新型算法，消除了这些偏见并实现了精确的收敛而无需有限的异质性假设。此外，从理论上讲，无论客户参与的任意性质如何，焦点都表现出对polyak-lojasiewicz条件的强烈凸电（指数衰减）的线性收敛（指数衰减）。]]></description>
      <guid>https://arxiv.org/abs/2503.20117</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>犯罪时空预测的创新LSGTime模型基于思维框架框架</title>
      <link>https://arxiv.org/abs/2503.20136</link>
      <description><![CDATA[ARXIV：2503.20136V1公告类型：新 
摘要：随着城市化的加速，犯罪活动的时空特征变得越来越复杂。准确的犯罪分配预测对于优化警察资源的分配和预防犯罪至关重要。本文提出了LGStime，这是一种犯罪时空预测模型，该模型整合了长期记忆（LSTM），封闭式复发单元（GRU）和多头稀疏的自我注意力专门机制。 LSTM和GRU通过其独特的门控机制捕获了犯罪时间序列（例如季节性和周期性）的长期依赖性。另一方面，多头稀疏的自我注意力专业机制通过并行处理和稀疏技术同时着重于犯罪事件的时间和空间特征，从而显着提高了计算效率和预测准确性。集成模型利用每种技术的优势更好地处理复杂的时空数据。实验发现表明，该模型在四个真正的世界犯罪数据集中达到了最佳性能。与CNN模型相比，它在平均平方误差（MSE），平均绝对误差（MAE）和根平方误差（RMSE）指标中表现出2.8 \％，1.9 \％和1.4 \％的性能增强。这些结果为应对犯罪预测的挑战提供了宝贵的参考。]]></description>
      <guid>https://arxiv.org/abs/2503.20136</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解锁分散数据的价值：模型聚合的联合双重学习方法</title>
      <link>https://arxiv.org/abs/2503.20138</link>
      <description><![CDATA[ARXIV：2503.20138V1公告类型：新 
摘要：人工智能（AI）技术彻底改变了许多领域，但它们的应用通常依赖于昂贵且耗时的数据收集过程。联合学习（FL）通过使AI模型可以在分散数据的数据（分布式节点）散布的分散数据上进行培训，从而提供了有希望的替代方案。但是，由于诸如异质数据分布和沟通延迟之类的挑战，现有的FL方法难以符合集中培训的表现，从而限制了它们突破的潜力。我们观察到，许多现实世界中的用例都涉及混合数据制度，其中服务器（中心节点）可以访问某些数据，而大量数据则在关联的客户端分发。为了改善该制度下的分散数据的利用，解决数据异质性问题，并促进服务器与客户之间的异步通信，我们提出了一种双重学习方法，该方法利用服务器上的集中数据指导客户的模型更新与客户的合并。我们的方法适应服务器数据相对于分散客户数据的各个域外的方案，从而适用于广泛的用例。我们提供理论分析，证明与现有方法相比，我们方法的收敛速度更快。此外，各种情况下的实验结果表明，我们的方法显着胜过现有技术，突出了其释放大量分散数据价值的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.20138</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在飞跃之前查看：在增强学习中不确定性的观察计划</title>
      <link>https://arxiv.org/abs/2503.20139</link>
      <description><![CDATA[ARXIV：2503.20139V1公告类型：新 
摘要：基于模型的增强学习（MBRL）与无模型增强学习（MFRL）相比，样品效率优于样品效率。但是，不准确模型的存在可能会在政策学习过程中引入偏见，从而造成误导性轨迹。挑战在于由于有限的培训数据有限，尤其是在访问有限的地区（不确定区域），因此获得了准确的模型。现有方法可以被动地量化样本后的不确定性，无法积极收集不确定的样本，这些样本可以增强状态覆盖范围并提高模型的准确性。此外，MBRL经常在做出准确的多步预测方面面临困难，从而影响整体性能。为了解决这些限制，我们通过基于模型的探索性计划提出了一个新颖的框架，以实现不确定性感知政策优化。在基于模型的计划阶段，我们引入了一种不确定性感知的K-Step LookAhead计划方法，以指导每个步骤的行动选择。该过程涉及模型不确定性和价值函数近似错误之间的权衡分析，从而有效地增强了策略绩效。在政策优化阶段，我们利用不确定性驱动的探索性政策积极收集各种培训样本，从而提高了RL代理的模型准确性和整体性能。我们的方法为具有不同状态/行动空间和奖励结构的任务提供了灵活性和适用性。我们通过对挑战机器人操纵任务和Atari游戏的实验来验证其有效性，超过了互动较少的最先进方法，从而导致了显着的性能提高。]]></description>
      <guid>https://arxiv.org/abs/2503.20139</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有未知部分微分方程的物理信息神经网络：多元时间序列中的应用</title>
      <link>https://arxiv.org/abs/2503.20144</link>
      <description><![CDATA[ARXIV：2503.20144V1公告类型：新 
摘要：神经网络（NN）研究的重大进步是通过自定义损失函数整合了域特异性知识。这种方法解决了一个至关重要的挑战：在处理稀疏，嘈杂或不完整数据时，模型如何利用物理学或数学原理来增强预测？物理知识的神经网络（PINNS）通过将物理方程（例如部分微分方程（PDE））作为软约束来付诸实践。该指南可帮助网络找到与既定法律保持一致的解决方案。最近，研究人员将该框架扩展到了包括贝叶斯NNS（BNN）的框架，该框架可以进行不确定性定量，同时仍遵守物理原则。但是，当系统的管理方程未知时会发生什么？在这项工作中，我们介绍了从历史数据中自动提取PDE的方法。然后，我们将这些学习的方程式整合到三种不同的建模方法中：Pinn，贝叶斯细胞（B-Pinns）和贝叶斯线性回归（BLR）。为了评估这些框架，我们将它们评估为现实世界中的多元时间序列（MTS）数据集。我们比较了它们在不同情况下的预测未来状态中的有效性：有和没有PDE的限制和准确性考虑。这项研究旨在弥合数据驱动的发现与物理指导学习之间的差距，从而为实用应用提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.20144</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>