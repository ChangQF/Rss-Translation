<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 08 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>NeuroSteiner：用于线长估计的图形变换器</title>
      <link>https://arxiv.org/abs/2407.03792</link>
      <description><![CDATA[arXiv:2407.03792v1 公告类型：新
摘要：物理设计的核心目标是在将芯片组件放置在画布上时最小化线长 (WL)。计算布局的最小 WL 需要找到直线 Steiner 最小树 (RSMT)，这是一个 NP 难问题。我们提出了 NeuroSteiner，这是一个神经模型，它提炼了最佳 RSMT 求解器 GeoSteiner，以导航 WL 估计的成本-精度边界。NeuroSteiner 在 GeoSteiner 标记的合成网络上进行训练，从而减轻了在实际芯片设计上进行训练的需要。此外，NeuroSteiner 的可微性允许通过梯度下降最小化 WL 来布局。在 ISPD 2005 和 2019 上，NeuroSteiner 可以获得 0.3% 的 WL 误差，同时比 GeoSteiner 快 60%，或 0.2% 和 30%。]]></description>
      <guid>https://arxiv.org/abs/2407.03792</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>采用新举措进行短期-长期政策评估</title>
      <link>https://arxiv.org/abs/2407.03674</link>
      <description><![CDATA[arXiv:2407.03674v1 公告类型：新
摘要：从将法学硕士纳入教育，到发现新药和改进电池充电方式，创新者不断尝试新策略，以寻求对学生、患者和消费者更好的长期结果。这一创新周期中的一个主要瓶颈是观察包含新干预措施的决策政策的下游效应所需的时间。关键问题是我们是否可以在不进行长期观察的情况下快速评估新决策政策的长期结果。组织通常可以访问有关过去决策政策及其结果的先前数据，这些数据是在整个关注范围内进行评估的。受此启发，我们引入了一种新的设置，用于对顺序决策任务进行短期-长期策略评估。我们提出的方法在 HIV 治疗、肾透析和电池充电模拟器上的表现明显优于先前的结果。我们还证明了我们的方法可以用于 AI 安全应用，因为它可以快速识别新决策政策何时可能比过去的政策性能低得多。]]></description>
      <guid>https://arxiv.org/abs/2407.03674</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>用于非线性动态系统中数据驱动损伤检测的深度学习架构</title>
      <link>https://arxiv.org/abs/2407.03700</link>
      <description><![CDATA[arXiv:2407.03700v1 公告类型：新
摘要：结构健康监测的主要目标是在损伤达到临界水平之前检测出损伤。本研究的深入研究涉及深度学习在非线性动态系统中数据驱动损伤检测的应用。特别是，自动编码器 (AE) 和生成对抗网络 (GAN) 是利用 1D 卷积神经网络实现的。在所研究的非线性动态系统中，通过激发不同强度的随机振动来检测损伤的发生，而无需事先了解系统或激励，并且以无监督的方式进行。对表现出不同类型非线性行为的动态系统进行了全面的数值研究。还提出了与磁弹性非线性系统相关的实验应用，以证实结论。]]></description>
      <guid>https://arxiv.org/abs/2407.03700</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>测量生成模型表示中的正交性</title>
      <link>https://arxiv.org/abs/2407.03728</link>
      <description><![CDATA[arXiv:2407.03728v1 公告类型：新
摘要：在无监督表示学习中，模型旨在通过归纳偏差将高维数据中的必要特征提炼为低维学习表示。了解构成良好表示的特征仍然是正在进行的研究的主题。长期以来，人们认为独立生成过程的解缠可以产生高质量的表示。然而，仅仅关注符合大多数解缠指标严格要求的表示，可能会导致忽略许多高质量的表示，这些表示非常适合各种下游任务。这些指标通常要求将生成因子编码为与表示空间的规范基础一致的不同单一维度。
受这些观察的启发，我们提出了两个新的指标：重要性加权正交性 (IWO) 和重要性加权等级 (IWR)。这些指标评估生成因子子空间的相互正交性和等级。在对常见下游任务、多个基准数据集和模型进行大量实验的过程中，IWO 和 IWR 始终表现出比传统解缠指标更强的下游任务性能相关性。我们的研究结果表明，表征质量与独立生成过程的正交性关系更密切，而不是与它们的解缠关系更密切，这为评估和改进无监督学习模型提供了新的方向。]]></description>
      <guid>https://arxiv.org/abs/2407.03728</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>基于可靠投影的半定 QCQP 无监督学习及波束成形优化应用</title>
      <link>https://arxiv.org/abs/2407.03668</link>
      <description><![CDATA[arXiv:2407.03668v1 公告类型：新
摘要：本文研究了一类具有半正定约束的特殊二次约束二次规划 (QCQP)。传统上，由于此类问题是非凸的且 N 难的，神经网络 (NN) 被认为是获得高性能解决方案的有前途的方法。然而，由于固有的预测误差，确保 NN 输出的所有解决方案都是可行的具有挑战性。虽然一些现有方法提出了一些简单的方法，但它们只注重降低约束违反概率，而不能保证所有解决方案都是可行的。为了应对上述挑战，本文提出了一种计算高效、可靠的投影，确保 NN 输出的所有解决方案都是可行的。此外，使用无监督学习，因此无需标签即可有效、高效地训练 NN。理论上证明了投影后NN的求解是可行的，并且证明了投影方法可以提高NN的收敛性能和速度。为了评估我们提出的方法，研究了包含服务质量（QoS）的波束成形场景，仿真结果表明所提出的方法可以实现与下限相媲美的高性能。]]></description>
      <guid>https://arxiv.org/abs/2407.03668</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>数据合成方法综述</title>
      <link>https://arxiv.org/abs/2407.03672</link>
      <description><![CDATA[arXiv:2407.03672v1 Announce Type: new 
摘要：本文对合成数据技术进行了详细的综述。我们首先讨论了使用合成数据进行数据增强的预期目标，可分为四个部分：1）提高多样性，2）数据平衡，3）解决领域转移，4）解决边缘情况。合成数据与当时流行的机器学习技术密切相关，因此，我们将合成数据技术的领域总结为四类：1）专家知识，2）直接训练，3）预训练然后微调，4）无需微调的基础模型。接下来，我们将合成数据过滤的目标分为四类进行讨论：1）基本质量，2）标签一致性，3）数据分布。在本文的第 5 部分中，我们还讨论了合成数据的未来方向，并指出了我们认为重要的三个方向：1）更加关注质量，2）合成数据的评估，3）多模型数据增强。]]></description>
      <guid>https://arxiv.org/abs/2407.03672</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>人类情感识别的生成技术：范围回顾</title>
      <link>https://arxiv.org/abs/2407.03640</link>
      <description><![CDATA[arXiv:2407.03640v1 公告类型：新
摘要：情感计算站在人工智能（AI）的最前沿，旨在赋予机器理解和响应人类情感的能力。该领域的核心是情感识别，它致力于从语音、面部图像、文本和生理信号等不同模态中识别和解释人类的情绪状态。近年来，生成模型取得了重要进展，包括自动编码器、生成对抗网络、扩散模型和大型语言模型。这些模型凭借其强大的数据生成能力，成为推进情感识别的关键工具。然而，到目前为止，仍然缺乏系统性的努力来回顾情感识别的生成技术。本调查旨在通过对 2024 年 6 月之前的 320 多篇研究论文进行全面分析来弥补现有文献中的空白。具体来说，本调查将首先介绍不同生成模型的数学原理和常用的数据集。随后，通过分类，本文将深入分析生成技术如何从数据增强、特征提取、半监督学习、跨领域等多个方面基于不同模态解决情绪识别问题。最后，本文将概述未来的研究方向，强调生成模型在推动情绪识别领域发展和增强人工智能系统情商方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.03640</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>单 GPU 上的可扩展学习模型汤：一种高效的子空间训练策略</title>
      <link>https://arxiv.org/abs/2407.03641</link>
      <description><![CDATA[arXiv:2407.03641v1 公告类型：新
摘要：预训练后进行微调在实践中被广泛采用。通过探索各种超参数配置，“模型汤”~\cite{wortsman2022model} 可以提高性能。Learned-Soup 是模型汤的一种变体，它显著提高了性能，但由于 (i) 必须同时加载所有微调模型，以及 (ii) 包含所有微调模型的大型计算图的要求，导致内存和时间成本大幅增加。在本文中，我们提出了内存高效超平面学习汤 (MEHL-Soup) 来解决这个问题，它将学习汤公式化为超平面优化问题，并引入块坐标梯度下降来学习混合系数。在每次迭代中，MEHL-Soup 只需要加载几个微调模型并用一个组合模型构建计算图。我们进一步以分层方式将 MEHL-Soup 扩展为 MEHL-Soup+。在各种 ViT 模型和数据集上的实验结果表明，MEHL-Soup(+) 在测试准确率方面优于 Learned-Soup(+)，同时内存使用量减少了 13 倍以上。此外，MEHL-Soup(+) 可以在单个 GPU 上运行，与 Learned-Soup 相比，其汤构建速度提高了 9 倍。代码发布于 https://github.com/nblt/MEHL-Soup。]]></description>
      <guid>https://arxiv.org/abs/2407.03641</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>MSfusion：一种用于资源受限的机器协作训练更大模型的动态模型分割方法</title>
      <link>https://arxiv.org/abs/2407.03622</link>
      <description><![CDATA[arXiv:2407.03622v1 公告类型：新
摘要：训练大型模型需要大量数据以及丰富的计算资源。虽然协作学习（例如联邦学习）提供了一种有前途的范例来利用来自许多参与者的集体数据，但对于资源有限的参与者（如移动设备）来说，训练大型模型仍然是一项重大挑战。我们引入了 MSfusion，这是一种有效且高效的协作学习框架，专门用于通过模型拆分在资源受限的机器上训练更大的模型。具体而言，设计了一种双移位模型拆分方案，使得在每一轮训练中，每个参与者都被分配一个模型参数子集来对本地数据进行训练，并与其他同行的子模型在公共参数上进行聚合。虽然模型拆分显着降低了单个参与者的计算和通信成本，但自适应模型重叠和对比损失函数方面的额外新颖设计有助于 MSfusion 保持训练效果，而不会在参与者之间进行模型转移。在图像和 NLP 任务上进行的大量实验表明，MSfusion 在训练大型模型的性能和效率方面具有显著优势，并且具有强大的可扩展性：随着参与者数量的增加，每个参与者的计算成本显著降低。]]></description>
      <guid>https://arxiv.org/abs/2407.03622</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>HERA：通过元素替换实现高效矩阵压缩</title>
      <link>https://arxiv.org/abs/2407.03637</link>
      <description><![CDATA[arXiv:2407.03637v1 公告类型：新
摘要：大型语言模型 (LLM) 显著提高了自然语言处理任务，例如机器翻译、文本生成和情感分析。然而，它们的庞大规模（通常包含数十亿个参数）对存储、计算和部署提出了挑战，尤其是在资源受限的环境中，如移动设备和边缘计算平台。此外，用于加速查询处理的键值 (k-v) 缓存需要大量内存和存储空间，这加剧了这些挑战。向量数据库已成为有效管理和检索 LLM 生成的高维向量的关键技术，有助于加快数据访问速度并减少计算需求。
有效的压缩和量化技术对于解决这些挑战至关重要，因为它们可以减少内存占用和计算要求，而不会显著影响性能。将参数均匀映射到压缩空间的传统方法通常无法解释参数的不均匀分布，从而导致相当大的准确性损失。因此，需要创新方法来实现更好的压缩比，同时保持模型性能。
在本文中，我们提出了一种采用启发式元素替换来压缩矩阵的新算法——HERA。HERA 使用启发式方法系统地替换模型中的元素，从而简化模型结构并使后续压缩更加有效。通过分层分割、压缩和重组矩阵数据集，我们的方法可以在相同的压缩率下有效地将量化误差降低到原来的 12.3%。]]></description>
      <guid>https://arxiv.org/abs/2407.03637</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>JEPA 如何避免噪声特征：深度线性自蒸馏网络的隐性偏差</title>
      <link>https://arxiv.org/abs/2407.03475</link>
      <description><![CDATA[arXiv:2407.03475v1 公告类型：新
摘要：在数据表示的自监督学习中存在两种相互竞争的范式。联合嵌入预测架构 (JEPA) 是一类架构，其中语义相似的输入被编码成可以相互预测的表示。JEPA 框架下最近成功的方法是自我蒸馏，其中在线编码器经过训练可以预测目标编码器的输出，有时使用轻量级预测器网络。这与蒙版自动编码器 (MAE) 范式形成对比，在蒙版自动编码器 (MAE) 范式中，编码器和解码器经过训练以重建数据空间中输入的缺失部分，而不是其潜在表示。使用 JEPA 方法而不是 MAE 的一个常见动机是，JEPA 目标优先考虑抽象特征而不是细粒度像素信息（这可能是不可预测和不具信息性的）。在这项工作中，我们试图通过分析深度线性模型的训练动态来了解这种经验观察背后的机制。我们发现了一种令人惊讶的机制：在简化的线性设置中，两种方法都学习类似的表示，JEPA 倾向于学习高影响力特征，即具有高回归系数的特征。我们的结果表明，在潜在空间中进行预测存在明显的隐性偏见，这可能有助于其在实践中的成功。]]></description>
      <guid>https://arxiv.org/abs/2407.03475</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>以决策为中心的最坏情况分布转变评估</title>
      <link>https://arxiv.org/abs/2407.03557</link>
      <description><![CDATA[arXiv:2407.03557v1 公告类型：新
摘要：分布转移是预测模型在实践中面临的一个关键挑战，因此需要在部署之前识别潜在的有害转移。现有工作通常将这些最坏情况的转移定义为最能降低模型个体级准确性的转移。然而，当模型用于做出下游人口级决策（如稀缺资源的分配）时，个体级准确性可能不能很好地代表手头任务的表现。我们引入了一个新框架，该框架采用分层模型结构，通过捕获决策问题实例内部和跨实例的转移来识别预测资源分配设置中的最坏情况分布转移。由于组合相互作用，这项任务比标准分布转移设置更困难，其中决策取决于分配任务中个人的共同存在。我们表明，该问题可以重新表述为子模块优化问题，从而能够有效地近似最坏情况损失。将我们的框架应用于真实数据，我们发现经验证据表明，由一个指标确定的最坏情况变化往往与由其他指标确定的最坏情况分布存在显著差异。]]></description>
      <guid>https://arxiv.org/abs/2407.03557</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>NEBULA：潜在表示下的神经经验贝叶斯，用于高效、可控的分子库设计</title>
      <link>https://arxiv.org/abs/2407.03428</link>
      <description><![CDATA[arXiv:2407.03428v1 公告类型：新 
摘要：我们提出了 NEBULA，这是第一个潜在的 3D 生成模型，用于围绕感兴趣的种子化合物可扩展地生成大型分子库。这样的库对于科学发现至关重要，但有效地生成大量高质量样本仍然具有挑战性。基于 3D 体素的方法最近显示出从随机噪声中从头生成高质量样本的巨大希望（Pinheiro 等人，2023 年）。然而，在 3D 体素空间中采样计算成本高昂，并且在库生成中使用速度极慢。在这里，我们改为在矢量量化变分自动编码器的学习潜在空间中执行神经经验贝叶斯采样（Saremi &amp; Hyvarinen，2019 年）。NEBULA 生成大型分子库的速度比现有方法快近一个数量级，而不会牺牲样本质量。此外，NEBULA 可以更好地推广到未见过的类药物分子，正如两个公共数据集和多种最近发布的药物所证明的那样。我们预计本文的方法将为基于机器学习的药物发现提供极大的支持。代码可在 https://github.com/prescient-design/nebula 上找到]]></description>
      <guid>https://arxiv.org/abs/2407.03428</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>环境复杂性对深度强化学习代理中表征学习的作用</title>
      <link>https://arxiv.org/abs/2407.03436</link>
      <description><![CDATA[arXiv:2407.03436v1 公告类型：新
摘要：个人生活的环境可能带来不同的导航挑战，从而导致不同的导航能力和策略。受不同城市布局和用于人类导航的双解决方案范式测试的启发，我们开发了一个模拟导航环境来训练深度强化学习代理执行快捷方式使用任务。我们调节了接触捷径和导航提示的频率，从而开发出具有不同能力的人工智能体。我们检查了驱动这些代理的人工神经网络中的编码表示，揭示了表示学习中的复杂动态，并将它们与快捷方式使用偏好相关联。此外，我们展示了分析节点群中表示的方法，这些方法被证明可以有效地在原本嘈杂的单节点数据中找到模式。这些技术在研究神经活动方面也可能有更广泛的应用。从我们对表示学习动态的观察中，我们提出了人类导航学习的见解，强调导航挑战在发展强大的地标知识方面的重要性，而不仅仅是反复接触地标。]]></description>
      <guid>https://arxiv.org/abs/2407.03436</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>HEMM：多模式基础模型的整体评估</title>
      <link>https://arxiv.org/abs/2407.03418</link>
      <description><![CDATA[arXiv:2407.03418v1 公告类型：新
摘要：多模态基础模型可以全面处理文本以及图像、视频、音频和其他感官模态，越来越多地用于各种实际应用。然而，考虑到可能的建模决策、任务和领域的范围，描述和研究多模态基础模型的进展具有挑战性。在本文中，我们引入了多模态模型的整体评估 (HEMM)，以系统地评估多模态基础模型在三个维度上的能力：基本技能、信息流和实际用例。基本多模态技能是解决问题所需的内部能力，例如跨模态学习交互、细粒度对齐、多步骤推理和处理外部知识的能力。信息流研究多模态内容在任务过程中如何通过查询、翻译、编辑和融合发生变化。用例涵盖现实世界多媒体、情感计算、自然科学、医疗保健和人机交互应用中引入的领域特定挑战。通过对 HEMM 中的 30 项任务进行全面实验，我们 (1) 确定了对当今模型构成挑战的关键数据集维度（例如基本技能、信息流和用例），以及 (2) 提炼出不同建模维度（例如规模、预训练数据、多模态对齐、预训练和指令调整目标）如何影响性能的性能趋势。我们关于具有挑战性的多模态交互、用例和需要推理和外部知识的任务、数据和模型规模的好处以及指令调整的影响的结论为多模态基础模型的未来工作提供了可行的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.03418</guid>
      <pubDate>Mon, 08 Jul 2024 06:21:26 GMT</pubDate>
    </item>
    </channel>
</rss>