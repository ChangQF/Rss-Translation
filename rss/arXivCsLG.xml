<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 22 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>因果赌博机中低复杂度的非对称图误差控制</title>
      <link>https://arxiv.org/abs/2408.11240</link>
      <description><![CDATA[arXiv:2408.11240v1 公告类型：新
摘要：本文研究了因果匪徒问题，其目标是在因果图中的节点上选择最佳干预序列。假设图由线性结构方程控制；进一步假设因果拓扑和干预的分布都是未知的。通过利用信号对奖励有贡献的节点之间的因果关系，可以优化干预。首先，基于两种类型的图识别错误（假阳性和假阴性）之间的差异，提出了一种因果图学习方法，该方法通过学习子图大大降低了相对于现有技术的样本复杂度。在高斯外生输入和最小均方误差权重估计的假设下，推导出一种针对因果匪徒问题量身定制的新不确定性界限。该不确定性界限驱动基于上限置信界限的干预选择以优化奖励。为了应对非平稳赌博机，提出了一种子图变化检测机制，具有较高的样本效率。数值结果将新方法与现有方案进行了比较，结果表明在平稳和非平稳设置中性能都有显著提高。与现有方法相比，所提出的方案学习因果结构所需的样本减少了 67%，平均奖励增益达到 85%。]]></description>
      <guid>https://arxiv.org/abs/2408.11240</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:06 GMT</pubDate>
    </item>
    <item>
      <title>图自监督学习中是否存在神经缩放定律？</title>
      <link>https://arxiv.org/abs/2408.11243</link>
      <description><![CDATA[arXiv:2408.11243v1 公告类型：新
摘要：自监督学习（SSL）对于通过有效利用大规模未标记数据中的知识来获得 NLP 和 CV 领域的基础模型至关重要。其成功的原因是合适的 SSL 设计可以帮助模型遵循神经缩放定律，即随着模型和数据集大小的增加，性能不断提高。然而，图域中现有的 SSL 是否可以遵循构建具有大规模预训练的图基础模型（GFM）的缩放行为仍然是一个谜。在本研究中，我们检查现有的图 SSL 技术是否可以遵循神经缩放行为，并有可能成为 GFM 的基本组成部分。我们的基准包括全面的 SSL 技术实现，并对传统 SSL 设置和其他领域采用的许多新设置进行了分析。令人惊讶的是，尽管 SSL 损失不断减少，但没有现有的图 SSL 技术在下游性能上遵循神经缩放行为。模型性能仅在不同的数据规模和模型规模上波动。影响性能的关键因素不是规模，而是模型架构和前置任务设计的选择。本文研究了现有的 SSL 技术，以了解图形 SSL 技术在开发 GFM 中的可行性，并使用新的评估原型为图形 SSL 设计开辟了新的方向。我们的代码实现可在线获取，以方便在 https://github.com/GraphSSLScaling/GraphSSLScaling 上进行重现。]]></description>
      <guid>https://arxiv.org/abs/2408.11243</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:06 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分类中对抗攻击的相关性分析</title>
      <link>https://arxiv.org/abs/2408.11264</link>
      <description><![CDATA[arXiv:2408.11264v1 公告类型：新
摘要：本研究调查了时间序列分类模型对对抗性攻击的脆弱性，重点研究了这些模型在这种情况下如何处理局部信息和全局信息。通过利用归一化自相关函数 (NACF)，对神经网络的倾向进行了探索。结果表明，正则化技术，特别是采用快速傅里叶变换 (FFT) 方法并针对扰动频率分量的技术，显著提高了攻击的有效性。同时，噪声引入和高斯滤波等防御策略被证明可以显著降低攻击成功率 (ASR)，而基于噪声引入的方法在对抗高频失真方面尤其有效。此外，旨在优先考虑全局信息的模型被揭示出具有更强的抵抗对抗性操纵的能力。这些结果强调了设计攻击和防御机制的重要性，这些机制是基于频域分析的，可以大大增强神经网络模型抵御对抗性威胁的弹性。]]></description>
      <guid>https://arxiv.org/abs/2408.11264</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:06 GMT</pubDate>
    </item>
    <item>
      <title>UKAN：非约束柯尔莫哥洛夫-阿诺德网络与加速库</title>
      <link>https://arxiv.org/abs/2408.11200</link>
      <description><![CDATA[arXiv:2408.11200v1 公告类型：新
摘要：在这项工作中，我们提出了一个用于 Kolmogorov-Arnold 网络 (KAN) 底层组件的 GPU 加速库，以及一种消除 KAN 中有界网格的算法。与现有代码相比，GPU 加速库将基样条 (B 样条) 评估的计算复杂度降低了 $\mathcal{O}$（网格大小），从而实现了大规模学习的批量计算。为了克服传统 KAN 的局限性，我们引入了无界 KAN (UKAN)，它消除了对有界网格和固定数量的 B 样条系数的需求。为此，我们用系数生成器 (CG) 模型替换 KAN 参数（B 样条系数）。CG 模型的输入是基于从负无穷到正无穷的无限对称网格的想法设计的。网格组的位置编码（B 样条网格索引的顺序集合）被输入到 CG 模型中，系数由 B 样条函数的有效实现（矩阵表示）使用来生成输出。我们对回归、分类和生成任务进行了几次实验，结果很有希望。特别是，UKAN 不需要数据规范化或有界域进行评估。此外，我们的基准测试结果表明，与现有代码相比，我们的库具有卓越的内存和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2408.11200</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:05 GMT</pubDate>
    </item>
    <item>
      <title>一点信心就能带来很大的进步</title>
      <link>https://arxiv.org/abs/2408.11239</link>
      <description><![CDATA[arXiv:2408.11239v1 公告类型：新
摘要：我们介绍了一组相关方法，用于使用大型语言模型 (LLM) 中的隐藏状态激活探针进行二元分类任务。性能与目前可用的最大和最先进的 LLM 相当，但所需的计算资源要少几个数量级，并且不需要标记数据。这种方法涉及将类标签转换为语义丰富的描述，自发破坏多层感知器探针的对称性以进行无监督学习和推理，训练探针以通过熵最大化从受已知约束的隐藏状态激活中生成置信度分数（先验概率），并从集合中选择最有信心的探测模型进行预测。使用五个基本 LLM 在四个数据集上评估这些技术。]]></description>
      <guid>https://arxiv.org/abs/2408.11239</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:05 GMT</pubDate>
    </item>
    <item>
      <title>一种基于完整 DAG 分数的算法，用于学习具有潜在混杂因素的因果贝叶斯网络</title>
      <link>https://arxiv.org/abs/2408.11181</link>
      <description><![CDATA[arXiv:2408.11181v1 公告类型：新
摘要：因果贝叶斯网络 (CBN) 是一种流行的图形概率模型，可对变量之间的因果关系进行编码。从观测数据中学习它们的图形结构已在文献中受到广泛关注。当不存在潜在（未观察到的）混杂因素时，即不存在某些观察到的变量的未观察到的直接共同原因时，学习算法基本上可以分为两类：基于约束的方法和基于分数的方法。后者通常被认为比前者更稳健，并能产生更好的结果。然而，据我们所知，当变量是离散的时，没有基于分数的算法能够处理潜在混杂因素。本文介绍了第一个完全基于分数的结构学习算法，该算法搜索 DAG（有向无环图）空间，能够识别某些潜在混杂因素的存在。它在数学上是合理的，实验突出了它的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.11181</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>CRACKS：用于分析和分类主要地下断层的众包资源</title>
      <link>https://arxiv.org/abs/2408.11185</link>
      <description><![CDATA[arXiv:2408.11185v1 公告类型：新
摘要：众包注释在机器学习标记数据的可用性方面创造了范式转变。大型数据集的可用性加速了涉及视觉和语言数据的常识应用的进展。然而，需要专家标签的专门应用在数据可用性方面滞后。地下成像中的断层分割就是这样一种应用。检测、跟踪和分析断层在预测流体流动、地震和储存过量的大气 CO$_2$ 方面具有广泛的社会意义。然而，用目前的实践来描绘断层是一项劳动密集型活动，需要地球物理学家对地下成像数据进行精确分析。在本文中，我们提出了 $\texttt{CRACKS}$ 数据集，利用众包资源来检测和分割地下图像中的断层。我们利用 Amazon Mechanical Turk 从荷兰北海地下图像的部分区域获取断层轮廓，这些图像来自 (i) 26 名从未接触过地下数据的新手，他们观看了一段描述和标记断层的视频，(ii) 8 名之前曾与地下数据进行过交互和工作过的从业者，(iii) 一名地球物理学家标记该地区的 7636 个断层。请注意，所有新手、从业者和专家都在同一地下体积上分割断层，新手和从业者之间存在分歧。此外，每个断层注释都配备了注释者的置信度。本文提供了在给定新手和从业者标签的情况下检测和分割专家标签的基准。有关更多详细信息以及数据集链接和代码，请访问 $\href{https://alregib.ece.gatech.edu/cracks-crowdsourcing-resources-for-analysis-and-categorization-of-key-subsurface-faults/}link}$。]]></description>
      <guid>https://arxiv.org/abs/2408.11185</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>针对特定任务目标的分子数据主动学习</title>
      <link>https://arxiv.org/abs/2408.11191</link>
      <description><![CDATA[arXiv:2408.11191v1 公告类型：新
摘要：主动学习 (AL) 已显示出成为一种特别高效的机器学习方法的前景。然而，它的性能取决于应用程序，目前尚不清楚 AL 从业者何时可以节省计算量。在这里，我们对三个不同的分子数据集和两个常见的科学任务进行了系统的 AL 性能评估：编译紧凑、信息丰富的数据集和有针对性的分子搜索。我们使用高斯过程 (GP) 实现了 AL，并使用多体张量作为分子表示。对于第一个任务，我们测试了不同的数据采集策略、批量大小和 GP 噪声设置。AL 对采集批量大小不敏感，我们观察到将不确定性减少与聚类相结合以促进多样性的采集策略具有最佳的 AL 性能。然而，对于最佳 GP 噪声设置，AL 的表现并不优于随机选择数据点。相反，对于有针对性的搜索，AL 的表现优于随机抽样，并实现了高达 64% 的数据节省。我们的分析深入了解了目标分布和数据收集策略方面特定任务的性能差异。我们确定 AL 的性能取决于目标分子相对于总数据集分布的相对分布，当它们的重叠最小时，可以实现最大的计算节省。]]></description>
      <guid>https://arxiv.org/abs/2408.11191</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>利用降阶深度学习替代模型获得逆 PDE 解中的总不确定性量化</title>
      <link>https://arxiv.org/abs/2408.11145</link>
      <description><![CDATA[arXiv:2408.11145v1 公告类型：新
摘要：我们提出了一种近似贝叶斯方法来量化使用机器学习替代模型（包括算子学习模型）获得的逆 PDE 解中的总不确定性。所提出的方法考虑了观测值和 PDE 和替代模型中的不确定性。首先，我们使用替代模型在缩减空间中为最大后验 (MAP) 逆解制定最小化问题。然后，我们随机化 MAP 目标函数并通过最小化目标函数的不同实现来获得后验分布的样本。我们通过将所提出的框架与具有未知空间相关扩散系数的非线性扩散方程的迭代集合平滑器和深度集合方法进行比较来测试所提出的框架。除其他问题外，该方程描述了非承压含水层中的地下水流。根据训练数据集和集成大小，与迭代集成平滑方法相比，所提出的方法提供了类似或更多的参数和状态的描述性后验。深度集成低估了不确定性，并且提供的信息量比其他两种方法要少。]]></description>
      <guid>https://arxiv.org/abs/2408.11145</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:03 GMT</pubDate>
    </item>
    <item>
      <title>SubgoalXL：基于子目标的定理证明专家学习</title>
      <link>https://arxiv.org/abs/2408.11172</link>
      <description><![CDATA[arXiv:2408.11172v1 公告类型：新
摘要：形式化定理证明是数学和计算机科学交叉领域的一个领域，随着大型语言模型 (LLM) 的进步，人们对此产生了新的兴趣。本文介绍了 SubgoalXL，这是一种新方法，它将基于子目标的证明与专家学习相结合，以增强 LLM 在 Isabelle 环境中进行形式化定理证明的能力。SubgoalXL 解决了两个关键挑战：专业数学和定理证明数据的稀缺性，以及对 LLM 中改进多步推理能力的需求。通过优化数据效率和采用子目标级监督，SubgoalXL 从有限的人工生成证明中提取了更丰富的信息。该框架将面向子目标的证明策略与专家学习系统相结合，迭代地改进形式化语句、证明和子目标生成器。 SubgoalXL 利用 Isabelle 环境在基于子目标的证明方面的优势，在标准 miniF2F 数据集上，在 Isabelle 中实现了 56.1\% 的全新最佳性能，绝对提升了 4.9\%。值得注意的是，SubgoalXL 成功解决了 miniF2F 中的 41 个 AMC12、9 个 AIME 和 3 个 IMO 问题。这些结果强调了在形式定理证明中最大化有限数据效用和采用针对性指导进行复杂推理的有效性，有助于不断提高 AI 推理能力。实现可在 \url{https://github.com/zhaoxlpku/SubgoalXL} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.11172</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:03 GMT</pubDate>
    </item>
    <item>
      <title>DOMBA：通过最小边界聚合实现访问控制语言模型的双模型平衡</title>
      <link>https://arxiv.org/abs/2408.11121</link>
      <description><![CDATA[arXiv:2408.11121v1 公告类型：新
摘要：大型语言模型 (LLM) 的实用性在很大程度上取决于其训练数据的质量和数量。许多组织拥有大量数据语料库，可以利用这些语料库来训练或微调适合其特定需求的 LLM。但是，这些数据集通常带有基于用户权限并由访问控制机制强制执行的访问限制。在这样的数据集上训练 LLM 可能会导致敏感信息暴露给未经授权的用户。防止此类暴露的一种直接方法是为每个访问级别训练一个单独的模型。然而，这可能会导致模型的实用性较低，因为与整个组织语料库中的数量相比，每个模型的训练数据量有限。另一种方法是在所有数据上训练单个 LLM，同时限制未经授权信息的暴露。然而，目前 LLM 的暴露限制方法对于访问控制数据无效，因为敏感信息经常出现在许多训练示例中。我们提出了 DOMBA（双模型平衡）——一种简单的训练和部署 LLM 的方法，它提供高实用性和访问控制功能以及安全保障。DOMBA 使用“最小有界”平均函数（受较小值限制的函数，例如调和平均值）汇总两个模型的概率分布，每个模型都针对具有（可能有很多）不同访问级别的文档进行训练。详细的数学分析和广泛的评估表明，DOMBA 保护了受限信息，同时提供了与非安全模型相当的实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.11121</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:02 GMT</pubDate>
    </item>
    <item>
      <title>MS$^3$D：基于 RG 流的正则化，用于有限数据的 GAN 训练</title>
      <link>https://arxiv.org/abs/2408.11135</link>
      <description><![CDATA[arXiv:2408.11135v1 公告类型：新
摘要：生成对抗网络 (GAN) 在图像生成方面取得了令人瞩目的进步，但它们通常需要大规模训练数据来避免因判别器过度拟合而导致的退化。为了解决这个问题，我们研究了使用有限数据训练 GAN 的挑战，并提出了一种基于物理学中重正化群 (RG) 思想的新型正则化方法。我们观察到，在有限数据设置中，生成器从判别器获得的梯度模式随着时间的推移变得更加聚合。在 RG 上下文中，这种聚合模式与其粗粒度版本表现出很大的差异，这意味着高容量和敏感的系统容易过度拟合和崩溃。为了解决这个问题，我们引入了 \textbf{多}尺度 \textbf{结构 \textbf{s}自\textbf{d}异同 (MS$^3$D) 正则化，它限制梯度场在不同尺度上具有一致的模式，从而促进更冗余和更强大的系统。我们表明，我们的方法可以有效提高 GAN 在有限数据场景下的性能和稳定性，甚至允许它们使用很少的数据生成高质量的图像。]]></description>
      <guid>https://arxiv.org/abs/2408.11135</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:02 GMT</pubDate>
    </item>
    <item>
      <title>ConFIG：面向物理信息神经网络的无冲突训练</title>
      <link>https://arxiv.org/abs/2408.11104</link>
      <description><![CDATA[arXiv:2408.11104v1 公告类型：新
摘要：许多学习问题的损失函数包含多个加法项，这些项可能会不一致并产生冲突的更新方向。对于物理信息神经网络 (PINN)，初始/边界条件和物理方程上的损失项特别有趣，因为它们是公认的高度困难的任务。为了改进学习 PINN 提出的具有挑战性的多目标任务，我们提出了 ConFIG 方法，该方法通过确保最终更新和每个特定于损失的梯度之间的正点积来提供无冲突更新。它还保持所有损失项的一致优化率，并根据冲突水平动态调整梯度幅度。我们还利用动量通过交替反向传播不同的损失项来加速优化。所提出的方法在一系列具有挑战性的 PINN 场景中进行了评估，与基线方法相比，始终表现出卓越的性能和运行时间。我们还在经典的多任务基准中测试了所提出的方法，其中 ConFIG 方法同样表现出非常有希望的性能。源代码可在 \url{https://tum-pbs.github.io/ConFIG} 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.11104</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:01 GMT</pubDate>
    </item>
    <item>
      <title>实验、部署和监控机器学习模型：应用 MLOps 的方法</title>
      <link>https://arxiv.org/abs/2408.11112</link>
      <description><![CDATA[arXiv:2408.11112v1 公告类型：新
摘要：近年来，数据科学作为行业支持工具的重要性日益提高，以前所未有的方式显著增强了决策能力。在这种背景下，MLOps 学科应运而生，成为自动化机器学习模型生命周期的解决方案，从实验到生产环境中的监控。研究结果表明，MLOps 是一门不断发展的学科，在集成开发和生产环境、在生产环境中发布模型以及在整个端到端开发生命周期中监控模型方面面临挑战和解决方案。本文有助于理解 MLOps 技术及其最广泛的应用。]]></description>
      <guid>https://arxiv.org/abs/2408.11112</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:01 GMT</pubDate>
    </item>
    <item>
      <title>通过软约束物理信息神经网络和小数据求解振子微分方程</title>
      <link>https://arxiv.org/abs/2408.11077</link>
      <description><![CDATA[arXiv:2408.11077v1 Announce Type: new 
摘要：本文通过文献研究，比较了物理信息神经网络（PINN）、传统神经网络（NN）和数值离散化方法在求解微分方程中的应用。我们形式化了软约束PINN方法求解微分方程（例如，ODE/PDE）的数学框架和计算流程。通过求解典型的线性和非线性振子ODE，实验验证了其工作机制及其准确性和效率。基于DeepXDE实现的PINN方法不仅代码量轻、训练效率高，而且跨平台灵活。PINN大大减少了对标记数据的需求：当ODE的非线性较弱时，非常少量的监督训练数据加上少量的搭配点就足以预测解；在极简情况下，一阶或二阶ODE分别只需要一个或两个训练点（具有初始值）。强非线性ODE也只需要适当增加训练点和配置点的数量，与传统NN相比仍然具有明显的优势。借助配置点和物理信息，PINN能够对训练集覆盖的时间域之外的数据进行外推，并且对噪声数据具有鲁棒性，从而具有增强的泛化能力。当数据量减少所获得的收益大于损失函数项增加所导致的延迟时，训练就会加速。软约束PINN方法可以通过在总损失函数中添加正则化项来轻松地施加物理定律（如能量守恒）约束，从而提高遵循该物理定律的ODE的求解性能。]]></description>
      <guid>https://arxiv.org/abs/2408.11077</guid>
      <pubDate>Thu, 22 Aug 2024 06:21:00 GMT</pubDate>
    </item>
    </channel>
</rss>