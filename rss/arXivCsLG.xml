<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 20 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LoRA 忘掉更多，保留更多（学生摘要）</title>
      <link>https://arxiv.org/abs/2411.11907</link>
      <description><![CDATA[arXiv:2411.11907v1 公告类型：新
摘要：由于隐私法规和法规遵从性的增加，机器反学习 (MU) 变得至关重要。反学习的目标是从模型中删除与特定类别相关的信息。传统方法通过在剩余数据集上重新训练模型来实现精确的反学习，但会产生高昂的计算成本。这推动了更有效的反学习技术的发展，包括模型稀疏化技术，这些技术提高了计算效率，但降低了模型在剩余类别上的性能。为了缓解这些问题，我们提出了一种新方法 PruneLoRA，它引入了一种新的 MU 范式，称为先修剪，然后适应，然后反学习。LoRA (Hu et al. 2022) 通过对模型应用低秩更新来减少对大规模参数更新的需求。我们利用 LoRA 选择性地修改已修剪模型的参数子集，从而降低计算成本和内存需求，并提高模型在剩余类别上保持性能的能力。各种指标的实验结果表明，我们的方法优于其他近似 MU 方法，并弥补了精确和近似反学习之间的差距。我们的代码可在 https://github.com/vlgiitr/LoRA-Unlearn 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.11907</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AIGS：利用人工智能自动证伪技术生成科学</title>
      <link>https://arxiv.org/abs/2411.11910</link>
      <description><![CDATA[arXiv:2411.11910v1 公告类型：新 
摘要：人工智能的快速发展极大地加速了科学发现的发展。通过大规模观测数据进行训练，深度神经网络以端到端的方式提取底层模式，并帮助人类研究人员在未见过的场景中进行高精度预测。最近兴起的大型语言模型 (LLM) 和赋能自主代理使科学家能够在研究的不同阶段通过交互获得帮助，包括但不限于文献综述、研究构思、想法实施和学术写作。然而，由基础模型赋能代理实例化的具有全流程自主性的人工智能研究人员仍处于起步阶段。在本文中，我们研究了$\textbf{人工智能生成的科学}$ (AIGS)，其中代理独立自主地完成整个研究过程并发现科学规律。通过重新审视科学研究的定义，我们认为$\textit{证伪}$是人类研究过程和 AIGS 系统设计的本质。从证伪的角度来看，先前尝试实现人工智能生成科学的系统要么在设计中缺乏这部分内容，要么严重依赖现有的验证引擎，而这些引擎将使用范围缩小到专业领域。在这项工作中，我们提出了 Baby-AIGS 作为全流程 AIGS 系统的初步演示，这是一个多智能体系统，其中的智能体代表着关键的研究过程。通过引入 FalsificationAgent 来识别并验证可能的科学发现，我们为系统赋予了明确的证伪能力。三项任务的实验初步表明，Baby-AIGS 可以产生有意义的科学发现，尽管与经验丰富的人类研究人员相比还不够。最后，我们详细讨论了当前 Baby-AIGS 的局限性、可行的见解以及相关的道德问题。]]></description>
      <guid>https://arxiv.org/abs/2411.11910</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ModeSeq：利用序列模式建模实现稀疏多模态运动预测</title>
      <link>https://arxiv.org/abs/2411.11911</link>
      <description><![CDATA[arXiv:2411.11911v1 公告类型：新
摘要：预测未来事件的多模态性为安全自动驾驶奠定了基础。然而，由于缺乏多模态基本事实，交通代理的多模态运动预测一直受到困扰。现有工作主要采用赢家通吃训练策略来应对这一挑战，但仍然受到轨迹多样性有限和模式置信度不一致的影响。虽然一些方法通过生成过多的轨迹候选来解决这些限制，但它们需要一个后处理阶段来识别最具代表性的模式，这个过程缺乏普遍原则并损害了轨迹准确性。因此，我们引入了 ModeSeq，这是一种新的多模态预测范式，将模式建模为序列。与一次解码多个合理轨迹的常见做法不同，ModeSeq 要求运动解码器逐步推断下一个模式，从而更明确地捕捉模式之间的相关性并显著增强推理多模态的能力。利用顺序模式预测的归纳偏差，我们还提出了 Early-Match-Take-All (EMTA) 训练策略来进一步多样化轨迹。ModeSeq 不依赖密集模式预测或基于规则的轨迹选择，在获得令人满意的轨迹精度的同时，显著提高了多模态输出的多样性，从而在运动预测基准上实现了均衡的性能。此外，ModeSeq 自然而然地具备模式外推能力，支持在未来高度不确定的情况下预测更多行为模式。]]></description>
      <guid>https://arxiv.org/abs/2411.11911</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>阿联酋基于深度学习和Sentinel-2卫星数据的人工智能红树林监测系统（2017-2024）</title>
      <link>https://arxiv.org/abs/2411.11918</link>
      <description><![CDATA[arXiv:2411.11918v1 公告类型：新
摘要：红树林在维持沿海生态系统健康和保护生物多样性方面发挥着至关重要的作用。因此，对红树林进行持续测绘对于了解其动态至关重要。地球观测图像通常是一种经济有效的监测红树林动态的方法。然而，阿联酋缺乏对红树林地区的区域研究。本研究利用 UNet++ 深度学习模型结合 Sentinel-2 多光谱数据和手动注释标签，监测 2017 年至 2024 年阿联酋分布密集的红树林（覆盖率大于 70%）的时空动态，在验证集上实现了 87.8% 的 mIoU。结果显示，2024年阿联酋红树林总面积约为9142.21公顷，较2017年增加2061.33公顷，碳固存量增加约194383.42吨。阿布扎比拥有最大的红树林面积，在阿联酋的红树林增长中发挥着主导作用，2017年至2024年间增加了1855.6公顷，而其他酋长国也通过红树林面积的稳定和可持续增长为红树林扩张做出了贡献。这种全面的增长模式反映了所有酋长国在红树林恢复方面的共同努力。]]></description>
      <guid>https://arxiv.org/abs/2411.11918</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据集蒸馏器是实际应用中良好的标签去噪器</title>
      <link>https://arxiv.org/abs/2411.11924</link>
      <description><![CDATA[arXiv:2411.11924v1 公告类型：新
摘要：从嘈杂的数据中学习对于将深度学习模型应用于实际应用至关重要。传统方法通常首先涉及评估噪声，然后应用诸如丢弃噪声样本、重新加权或重新标记等策略。但是，当初始噪声评估不准确时，这些方法可能会陷入恶性循环，导致性能不佳。为了解决这个问题，我们提出了一种利用数据集蒸馏来消除噪声的新方法。该方法避免了现有技术中常见的反馈循环并提高了训练效率，同时还通过离线处理提供了强大的隐私保护。我们在各种噪声条件下严格评估了三种代表性数据集蒸馏方法（DATM、DANCE 和 RCIG），包括对称噪声、非对称噪声和现实世界的自然噪声。我们的实证研究结果表明，数据集蒸馏有效地充当了随机噪声场景中的去噪工具，但可能难以处理结构化的非对称噪声模式，这些噪声模式可能会被吸收到蒸馏样本中。此外，干净但具有挑战性的样本（例如不平衡数据集中尾部类别的样本）在蒸馏过程中可能会经历有损压缩。尽管存在这些挑战，但我们的结果突出表明，数据集蒸馏对于稳健的模型训练具有重要前景，尤其是在噪声普遍存在的高隐私环境中。]]></description>
      <guid>https://arxiv.org/abs/2411.11924</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>唤醒沉睡的记忆：通过理性指导难度研究语言模型中的灾难性遗忘</title>
      <link>https://arxiv.org/abs/2411.11932</link>
      <description><![CDATA[arXiv:2411.11932v1 公告类型：新
摘要：尽管人们已经做出了巨大努力来减轻持续学习中的灾难性遗忘，但其内在机制尚不清楚。在本文中，我们发现，当遗忘模型被动地接收外部提供的部分适当原理时，其在遗忘任务上的性能可以恢复。此外，只需在原始指令中添加与任务无关的前缀，遗忘模型就可以主动生成适当的原理以得出正确答案。这些发现表明，该模型实际上并没有“忘记”任务知识；相反，性能下降可以归因于原始指令未能指导模型生成适当的原理。基于这一见解，我们提出了原理指导难度指标来评估给定指令指导模型生成适当原理的有效性。我们应用此指标来优化基于重放的持续学习算法中重放数据的分配。实验结果表明，我们的数据分配方法有效地减轻了灾难性遗忘，同时在跨模型之间保持了更好的模型可塑性。]]></description>
      <guid>https://arxiv.org/abs/2411.11932</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>METEOR：大型语言模型从引导到自我成长的进化之旅</title>
      <link>https://arxiv.org/abs/2411.11933</link>
      <description><![CDATA[arXiv:2411.11933v1 公告类型：新
摘要：模型演化使模型能够从反馈中学习以完善经验并更新技能，将模型从没有领域知识转变为成为领域专家。然而，目前还没有统一有效的方法来指导这一演化过程。为了解决这一空白，我们提出了 Meteor 方法，该方法包括三个训练阶段：从弱到强的数据提炼、迭代训练和自我演化策略。每个阶段都最大限度地发挥模型固有的领域能力，使其能够自主地完善其领域知识并提高性能。实验表明，我们的方法显著提高了跨领域特定任务的准确性、完整性、相关性、连贯性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2411.11933</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>价值印记：一种审计 RLHF 数据集中嵌入的人类价值观的技术</title>
      <link>https://arxiv.org/abs/2411.11937</link>
      <description><![CDATA[arXiv:2411.11937v1 公告类型：新
摘要：LLM 越来越多地使用 RLHF 数据集进行微调，以使其与人类的偏好和价值观保持一致。然而，只有非常有限的研究调查了哪些特定的人类价值观是通过这些数据集实现的。在本文中，我们介绍了 Value Imprint，这是一个用于审核和分类 RLHF 数据集中嵌入的人类价值观的框架。为了研究该框架的可行性，我们进行了三个案例研究实验，通过审核 Anthropic/hh-rlhf、OpenAI WebGPT Comparisons 和 Alpaca GPT-4-LLM 数据集来检查其中嵌入的人类价值观。我们的分析涉及一个两阶段的过程。在第一阶段，我们通过综合回顾哲学、价值论和伦理学的先前著作，开发了人类价值观的分类法。然后，我们应用这个分类法来注释 6,501 个 RLHF 偏好。在第二阶段，我们使用注释生成的标签作为基本事实数据来训练基于 Transformer 的机器学习模型，以审核和分类三个 RLHF 数据集。通过这种方法，我们发现信息效用价值观（包括智慧/知识和信息寻求）是所有三个 RLHF 数据集中最主要的人类价值观。相比之下，亲社会和民主价值观（包括福祉、正义和人权/动物权利）是代表性最低的人类价值观。这些发现对于开发符合社会价值观和规范的语言模型具有重要意义。我们贡献我们的数据集来支持该领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2411.11937</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Milabench 介绍：AI 基准测试加速器</title>
      <link>https://arxiv.org/abs/2411.11940</link>
      <description><![CDATA[arXiv:2411.11940v1 公告类型：新
摘要：AI 工作负载，尤其是由深度学习驱动的工作负载，正在为高性能计算 (HPC) 系统引入新的使用模式，而标准 HPC 基准测试无法全面捕捉这些模式。作为致力于深度学习的最大学术研究中心之一，Mila 发现需要开发一个定制的基准测试套件来满足其社区的多样化需求，该社区由 1,000 多名研究人员组成。本报告介绍了由此产生的基准测试套件 Milabench。它的设计基于一份涵盖 867 篇论文的广泛文献综述以及对 Mila 研究人员进行的调查。这一严格的过程导致选择了 26 个针对采购评估量身定制的主要基准测试，以及 16 个用于深入分析的可选基准测试。我们详细介绍了设计方法、基准测试套件的结构，并使用 NVIDIA、AMD 和 Intel 的 GPU 提供性能评估。 Milabench 套件是开源的，可以通过 github.com/mila-iqia/milabench 访问。]]></description>
      <guid>https://arxiv.org/abs/2411.11940</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>受覆盖范围限制的多位专家人机合作</title>
      <link>https://arxiv.org/abs/2411.11976</link>
      <description><![CDATA[arXiv:2411.11976v1 公告类型：新
摘要：人机协作分类 (HAI-CC) 方法旨在开发混合智能系统，通过利用人类专业知识和人工智能能力来增强各种高风险现实场景中的决策能力。当前的 HAI-CC 方法主要侧重于学习延迟 (L2D)，其中决策推迟给人类专家，以及学习补充 (L2C)，其中人工智能和人类专家合作进行预测。然而，在多样化专家知识下有效探索 L2D 和 L2C 以改进决策方面仍然存在一个明显的研究空白，特别是在受到实现仅人工智能选择的目标概率（即覆盖率）所需的合作成本的限制时。在本文中，我们通过提出覆盖率受限的学习延迟和与特定专家互补 (CL2DC) 方法来解决这一研究空白。根据输入数据，CL2DC 可以单独通过 AI 预测或听从或补充特定专家来做出最终决策。此外，我们提出了一种覆盖范围约束优化来控制合作成本，确保它接近仅 AI 选择的目标概率。这种方法能够在指定的预算内有效评估系统性能。此外，CL2DC 旨在解决训练集包含多个嘈杂标签注释而没有任何干净标签参考的情况。对合成和真实世界数据集的全面评估表明，与最先进的 HAI-CC 方法相比，CL2DC 实现了卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.11976</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Peter-Clark 贝叶斯结构学习预测极端事件下的输电线路停电概率</title>
      <link>https://arxiv.org/abs/2411.11980</link>
      <description><![CDATA[arXiv:2411.11980v1 公告类型：新
摘要：近年来，极端天气事件的频率和强度显着增加。随着这些事件导致的停电次数不断增加，准确预测电力线停电对于电网的安全可靠运行至关重要。贝叶斯网络是一种概率模型，对于预测天气相关不确定性下的线路停电非常有效。然而，该领域的大多数现有研究都提供了一般的风险评估，但未能提供具体的停电概率。在这项工作中，我们介绍了一种使用贝叶斯网络结合 Peter-Clark (PC) 结构学习来预测输电线路停电概率的新方法。我们的方法不仅可以精确计算停电概率，而且即使在数据有限的情况下也表现出更好的可扩展性和稳健的性能。使用来自 BPA 和 NOAA 的数据的案例研究证明了该方法的有效性，而与几种现有方法的比较进一步凸显了它的优势。]]></description>
      <guid>https://arxiv.org/abs/2411.11980</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法的泛化误差</title>
      <link>https://arxiv.org/abs/2411.12030</link>
      <description><![CDATA[arXiv:2411.12030v1 公告类型：新
摘要：本文介绍了一种用于推导机器学习算法泛化误差信息度量闭式表达式的技术——缺口法。该方法依赖于两个核心观察：$(a)$~泛化误差是预期经验风险相对于概率测度（用于期望）变化的变异的平均值；以及~$(b)$~这些变异，也称为缺口，以信息测度的形式表现出闭式表达式。经验风险的期望可以相对于模型上的测度（具有固定数据集）或相对于数据集上的测度（具有固定模型），这导致缺口法的两种变体。第一种变体侧重于模型上预期经验风险与某个度量之间的差距，这似乎是最普遍的，因为没有对数据集的分布做出任何假设。第二种变体是在数据集由独立且相同分布的数据点组成的假设下发展起来的。使用所提出的方法可以获得机器学习算法泛化误差的所有现有精确表达式。此外，该方法还可以获得许多新的精确表达式，从而提高对泛化误差的理解；与统计学中的其他领域（例如假设检验）建立联系；并且可能指导算法设计。]]></description>
      <guid>https://arxiv.org/abs/2411.12030</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不同编程语言及其组件之间的机器学习评估指标差异：需要标准化</title>
      <link>https://arxiv.org/abs/2411.12032</link>
      <description><![CDATA[arXiv:2411.12032v1 公告类型：新 
摘要：本研究评估了分类、回归、聚类、相关分析、统计测试、分割和图像到图像 (I2I) 转换等任务的指标。在 Python 库、R 包和 Matlab 函数中比较了指标，以评估它们的一致性并突出显示差异。研究结果强调需要制定统一的路线图来标准化指标，确保跨平台的可靠和可重复的 ML 评估。本研究检查了各种任务中的广泛评估指标，发现只有一些指标在各个平台上是一致的，例如 (i) 二元分类中的准确度、平衡准确度、Cohens Kappa、F-beta 分数、MCC、几何平均值、AUC 和对数损失；(ii) 多类分类中的准确度、Cohens Kappa 和 F-beta 分数； (iii) 回归中的 MAE、MSE、RMSE、MAPE、解释方差、中位数 AE、MSLE 和 Huber；(iv) 聚类中的 Davies-Bouldin 指数和 Calinski-Harabasz 指数；(v) 相关分析中的 Pearson、Spearman、Kendall&#39;s Tau、相互信息、距离相关、Percbend、Shepherd 和偏相关；(vi) 统计检验中的配对 t 检验、卡方检验、方差分析、Kruskal-Wallis 检验、Shapiro-Wilk 检验、Welchs t 检验和 Bartlett 检验；(vii) 2D 分割中的准确度、精确度和召回率；(viii) 3D 分割中的准确度；(ix) 2D-I2I 翻译中的 MAE、MSE、RMSE 和 R 平方；以及 (x) 3D-I2I 翻译中的 MAE、MSE 和 RMSE。鉴于观察到许多指标的差异（例如二元分类中的精度、召回率和 F1 分数、聚类中的 WCSS、多项统计测试和分割中的 IoU 等多个指标），本研究得出结论，ML 评估指标需要标准化，并建议未来的研究对不同的任务使用一致的指标，以有效地比较 ML 技术和解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.12032</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 NRP Nautilus HyperCluster 上的 Kubernetes 扩展深度学习研究</title>
      <link>https://arxiv.org/abs/2411.12038</link>
      <description><![CDATA[arXiv:2411.12038v1 公告类型：新
摘要：在整个科学计算领域，深度学习算法在广泛的应用中表现出色。随着这些深度神经网络 (DNN) 不断成熟，训练它们所需的必要计算量也在不断增长。如今，现代 DNN 需要数百万 FLOP 和数天到数周的训练才能生成训练有素的模型。DNN 所需的训练时间通常是各种深度学习应用的 DNN 研究的瓶颈，因此，加速和扩展 DNN 训练可以实现更稳健和更快速的研究。为此，在这项工作中，我们探索利用 NRP Nautilus HyperCluster 为 DNN 的三个独立应用自动化和扩展深度学习模型训练，包括头顶物体检测、烧毁区域分割和森林砍伐检测。总共有 234 个深度神经模型在 Nautilus 上进行训练，总时间为 4,040 小时]]></description>
      <guid>https://arxiv.org/abs/2411.12038</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Softmax 策略镜像上升的快速收敛</title>
      <link>https://arxiv.org/abs/2411.12042</link>
      <description><![CDATA[arXiv:2411.12042v1 公告类型：新
摘要：自然策略梯度 (NPG) 是一种常见的策略优化算法，可以看作是概率空间中的镜像上升。最近，Vaswani 等人 [2021] 引入了一种策略梯度方法，它对应于 logits 对偶空间中的镜像上升。我们改进了该算法，消除了对动作进行规范化的需要，并分析了生成的方法（称为 SPMA）。对于表格 MDP，我们证明具有恒定步长的 SPMA 与 NPG 的线性收敛相匹配，并且比恒定步长（加速）softmax 策略梯度实现了更快的收敛。为了处理较大的状态动作空间，我们扩展了 SPMA 以使用对数线性策略参数化。与 NPG 不同，将 SPMA 推广到线性函数近似 (FA) 设置不需要兼容函数近似。与 MDPO（NPG 的实际推广）不同，具有线性 FA 的 SPMA 仅需要解决凸 softmax 分类问题。我们证明 SPMA 实现了线性收敛到最优值函数的邻域。我们扩展了 SPMA 以处理非线性 FA，并在 MuJoCo 和 Atari 基准上评估了其经验性能。我们的结果表明，与 MDPO、PPO 和 TRPO 相比，SPMA 始终实现类似或更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.12042</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>