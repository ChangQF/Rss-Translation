<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 14 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>银行交易流程中多模态环境下的自注意力机制</title>
      <link>https://arxiv.org/abs/2410.08243</link>
      <description><![CDATA[arXiv:2410.08243v1 公告类型：新
摘要：银行交易流 (BTF) 是一系列银行活动中的顺序数据，例如营销、信用风险或银行欺诈。它是一种由三种模态组成的多模态数据：日期、数值和措辞。我们在这项工作中提出了一种自注意力机制在 BTF 处理中的应用。我们以自监督的方式在大量 BTF 上训练了两个通用模型：一个基于 RNN 的模型和一个基于 Transformer 的模型。我们提出了一种特定的标记化方法，以便能够处理 BTF。在两个银行下游任务上评估了这两个模型的性能：交易分类任务和信用风险任务。结果表明，对这两个预训练模型进行微调可以使这两个任务的表现优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.08243</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Flex-MoE：通过灵活的专家混合模型对任意模态组合进行建模</title>
      <link>https://arxiv.org/abs/2410.08245</link>
      <description><![CDATA[arXiv:2410.08245v1 公告类型：新
摘要：多模态学习在各个领域的重要性日益增加，它能够整合来自不同来源的数据，例如图像、文本和个性化记录，这些来源在医学领域经常出现。然而，在某些模态缺失的情况下，许多现有框架难以适应任意模态组合，通常严重依赖单一模态或完整数据。这种对潜在模态组合的忽视限制了它们在现实世界中的适用性。为了应对这一挑战，我们提出了 Flex-MoE（灵活混合专家），这是一个新框架，旨在灵活地整合任意模态组合，同时保持对缺失数据的鲁棒性。Flex-MoE 的核心思想是首先使用新的缺失模态库来解决缺失模态问题，该库将观察到的模态组合与相应的缺失模态组合相结合。接下来是一个独特设计的稀疏 MoE 框架。具体来说，Flex-MoE 首先使用具有所有模态的样本训练专家，以通过广义路由器 ($\mathcal{G}$-Router) 注入广义知识。然后，$\mathcal{S}$-Router 通过将 top-1 门分配给与观察到的模态组合相对应的专家，专门处理较少的模态组合。我们在 ADNI 数据集（该数据集涵盖阿尔茨海默病领域的四种模态）以及 MIMIC-IV 数据集上评估了 Flex-MoE。结果证明了 Flex-MoE 的有效性，突出了它能够在各种缺失模态场景中对任意模态组合进行建模的能力。代码可在 https://github.com/UNITES-Lab/flex-moe 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.08245</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测急诊室拥挤相关的死亡率</title>
      <link>https://arxiv.org/abs/2410.08247</link>
      <description><![CDATA[arXiv:2410.08247v1 公告类型：新
摘要：急诊科 (ED) 拥挤是一个全球公共卫生问题，与死亡率增加一再相关。预测未来的服务需求将有助于采取预防措施，旨在消除拥挤及其有害影响。我们急诊科的最新发现表明，占用率超过 90% 与 10 天死亡率增加有关。在本文中，我们旨在使用来自大型北欧急诊科的回顾性数据和 LightGBM 模型来预测这些危机时期。我们为整个急诊科及其不同运营部门提供预测。我们证明，下午拥挤可以在上午 11 点预测，AUC 为 0.82（95% CI 0.78-0.86），上午 8 点的 AUC 高达 0.79（95% CI 0.75-0.83）。因此，我们表明，使用匿名管理数据预测与死亡率相关的拥挤是可行的。]]></description>
      <guid>https://arxiv.org/abs/2410.08247</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨域推荐的联合图学习</title>
      <link>https://arxiv.org/abs/2410.08249</link>
      <description><![CDATA[arXiv:2410.08249v1 公告类型：新
摘要：跨域推荐 (CDR) 通过实现跨源域和目标域的知识转移，为数据稀疏问题提供了一种有希望的解决方案。然而，许多最近的 CDR 模型忽略了隐私等关键问题以及负转移的风险（这会对模型性能产生负面影响），尤其是在多域设置中。为了应对这些挑战，我们提出了 FedGCDR，这是一种新颖的联合图学习框架，可以安全有效地利用来自多个源域的积极知识。首先，我们设计了一个积极的知识转移模块，以确保域间知识传输过程中的隐私。该模块采用基于差异隐私的知识提取与特征映射机制相结合，将来自联合图注意网络的源域嵌入转换为可靠的领域知识。其次，我们设计了一个知识激活模块来过滤掉来自源域的潜在有害或冲突知识，解决负转移问题。该模块通过扩展目标域的图来增强目标域训练，以生成可靠的域注意力，并微调目标模型以改进负面知识过滤和更准确的预测。我们对亚马逊数据集的 16 个热门域进行了广泛的实验，表明 FedGCDR 的表现明显优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.08249</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从饥饿中概括：LLM 知识图谱学习中的普遍性提示</title>
      <link>https://arxiv.org/abs/2410.08255</link>
      <description><![CDATA[arXiv:2410.08255v1 公告类型：新
摘要：受可解释性和可靠性的启发，我们研究了神经网络在图学习过程中如何表示知识，我们发现了普遍性的迹象，即在一系列模型大小（从 10^2 到 10^9 参数）和上下文（MLP 玩具模型、LLM 上下文学习和 LLM 训练）中学习等效表示。我们表明，这些吸引子表示通过利用知识图关系的属性（例如对称性和元传递性）优化了对未见过的示例的泛化。我们通过展示 LLM 和更简单的神经网络可以拼接来找到对这种普遍性的实验支持，即通过将一个模型的第一部分拼接到另一个模型的最后一部分，仅通过仿射或几乎仿射变换介导。我们假设，这种趋向简单化和泛化的动态是由“饥饿产生的智慧”所驱动的：通过尽量减少使用稀缺资源或与其他任务竞争的资源的压力，可以最大限度地减少过度拟合。]]></description>
      <guid>https://arxiv.org/abs/2410.08255</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AdaShadow：非平稳移动环境中的响应式测试时间模型自适应</title>
      <link>https://arxiv.org/abs/2410.08256</link>
      <description><![CDATA[arXiv:2410.08256v1 公告类型：新
摘要：对于自动驾驶和增强现实等移动应用而言，设备上适应持续、不可预测的领域转变对于在不断变化的环境中提供无缝的用户体验至关重要。通过在预测之前立即使用未标记的实时数据调整模型参数，测试时间自适应 (TTA) 成为了一个有前途的解决方案。然而，TTA 独特的前向-后向-再前向管道显着增加了标准推理的延迟，从而削弱了时间敏感的移动应用程序的响应能力。本文介绍了 AdaShadow，这是一种响应式测试时间自适应框架，通过选择性更新适应关键层来实现非平稳移动数据分布和资源动态。虽然该策略在通用设备上训练中得到认可，但 TTA 的无监督和在线环境在估计层重要性和延迟以及安排最佳层更新计划方面提出了独特的挑战。 AdaShadow 解决了这些挑战，它使用无反向传播评估器来快速识别关键层，使用基于单元的运行时预测器来考虑延迟估计中的资源动态，以及使用在线调度程序来及时规划层更新。此外，AdaShadow 还采用了内存 I/O 感知计算重用方案，以进一步减少转发过程中的延迟。结果表明，AdaShadow 在连续移位下实现了最佳的准确率-延迟平衡。在低内存和能源成本下，Adashadow 比最先进的 TTA 方法提供了 2 倍到 3.5 倍的速度提升（毫秒级），同时具有可比的准确率，比具有类似延迟的高效监督方法的准确率提高了 14.8% 到 25.4%。]]></description>
      <guid>https://arxiv.org/abs/2410.08256</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合整数线性规划的基础模型</title>
      <link>https://arxiv.org/abs/2410.08288</link>
      <description><![CDATA[arXiv:2410.08288v1 公告类型：新
摘要：混合整数线性规划 (MILP) 对于建模复杂的决策问题至关重要，但在计算可处理性方面面临挑战，并且需要专家制定。当前针对 MILP 的深度学习方法专注于特定的问题类别，而不会推广到看不见的类别。为了解决这个缺点，我们采用了基础模型训练方法，我们在不同的 MILP 问题集上训练单个深度学习模型，以在问题类别中推广。由于现有的 MILP 数据集缺乏多样性和数量，我们引入了 MILP-Evolve，这是一种基于 LLM 的新型进化框架，能够生成具有无限数量实例的大量不同 MILP 类。我们在三个关键学习任务上研究了我们的方法，这些任务捕捉了 MILP 的不同方面：(1) 完整性差距预测，(2) 学习分支，以及 (3) 将 MILP 实例与自然语言描述对齐的新任务。我们的实证结果表明，使用 MILP-Evolve 生成​​的数据训练的模型在前所未见的问题（包括 MIPLIB 基准）上取得了显著的进步。我们的工作凸显了迈向 MILP 基础模型方法的潜力，该方法可以推广到广泛的 MILP 应用。我们致力于完全开源我们的工作，以推动进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2410.08288</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>循环变换器 (Looped Transformers) 能否学习实现多步梯度下降以进行上下文学习？</title>
      <link>https://arxiv.org/abs/2410.08292</link>
      <description><![CDATA[arXiv:2410.08292v1 公告类型：新
摘要：Transformers 无需任何微调即可进行推理和少量学习，这种非凡的能力被广泛推测源于它们能够在一次前向传递中用权重隐式模拟多步骤算法（例如梯度下降）。最近，从表达力的角度理解这一复杂现象取得了进展，证明了 Transformers 可以表达这种多步骤算法。然而，除了单层模型之外，我们对它的可学习性的更基本方面的了解非常有限。特别是，训练 Transformers 能否实现算法解决方案的收敛？在这项工作中，我们解决了上下文线性回归与线性循环 Transformers 的问题——这是一个具有权重共享的多层模型，据推测它具有归纳偏差来学习定点迭代算法。更具体地说，对于这种设置，我们表明种群训练损失的全局最小化器实现了多步预处理梯度下降，其中预处理器适应数据分布。此外，我们通过证明一种新的梯度优势条件，证明了梯度流在回归损失上的快速收敛，尽管地形不凸。据我们所知，这是这种设置下多层 Transformer 的首次理论分析。我们通过综合实验进一步验证了我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2410.08292</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中缺失值的影响：全面分析</title>
      <link>https://arxiv.org/abs/2410.08295</link>
      <description><![CDATA[arXiv:2410.08295v1 公告类型：新
摘要：机器学习 (ML) 已成为数据挖掘和大数据分析各个领域的一种普遍工具。ML 模型的有效性在很大程度上取决于高质量的数据集，而这些数据集通常因缺失值的存在而变得复杂。因此，面对这样的数据集，ML 模型的性能和泛化面临风险。本文旨在研究缺失值对 ML 工作流程的细微影响，包括其类型、原因和后果。我们的分析重点是缺失值带来的挑战，包括有偏差的推断、预测能力下降和计算负担增加。本文进一步探讨了处理缺失值的策略，包括归纳技术和删除策略，并研究了缺失值如何影响模型评估指标并引入了交叉验证和模型选择的复杂性。该研究采用案例研究和现实世界的例子来说明解决缺失值的实际意义。最后，讨论延伸到未来的研究方向，强调需要以合乎道德和透明的方式处理缺失值。本文的主要目标是深入了解缺失值对 ML 模型的普遍影响，并指导从业者采取有效的策略来实现稳健可靠的模型结果。]]></description>
      <guid>https://arxiv.org/abs/2410.08295</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图谱私密学习及其在大型语言模型微调中的应用</title>
      <link>https://arxiv.org/abs/2410.08299</link>
      <description><![CDATA[arXiv:2410.08299v1 公告类型：新
摘要：图形提供了对实体之间关系和交互的独特见解，补充了文本、图像和视频等数据模式。通过整合图形数据中的关系信息，AI模型可以将其功能扩展到传统任务之外。然而，金融和医疗保健等敏感领域的关系数据通常包含私人信息，因此隐私保护至关重要。现有的隐私保护方法（例如依赖于梯度解耦假设的 DP-SGD）由于耦合训练样本之间固有的依赖关系而不适合关系学习。为了应对这一挑战，我们提出了一种隐私保护关系学习流程，该流程在训练期间解耦采样关系中的依赖关系，通过定制的 DP-SGD 应用确保差异隐私。我们将此方法应用于敏感图形数据上的大型语言模型 (LLM) 微调，并解决相关的计算复杂性。我们的方法在不同大小的 LLM（例如 BERT、Llama2）上使用来自四个文本属性图的真实关系数据进行评估。结果表明，关系学习任务得到了显著改善，同时在训练期间保持了强大的隐私保证。此外，我们探索了隐私、实用性和计算效率之间的权衡，为我们的方法的实际部署提供了见解。代码可在 https://github.com/Graph-COM/PvGaLM 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.08299</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>支持 DNN 中算法设计选择探索的框架</title>
      <link>https://arxiv.org/abs/2410.08300</link>
      <description><![CDATA[arXiv:2410.08300v1 公告类型：新
摘要：深度学习技术，特别是深度神经网络 (DNN)，已在许多领域取得了重大成功。这一成功伴随着 DNN 所需操作背后的算法的重大进步和创新。这些增强的算法有可能大大提高 DNN 的性能。然而，发现 DNN 的最佳性能算法并改变 DNN 以使用这种算法是一项困难且耗时的任务。为了解决这个问题，我们引入了一个开源框架，它为 DNN 提供了易于使用的细粒度算法控制，从而实现了算法探索和选择。除了内置的常见深度学习操作的高性能实现外，该框架还使用户能够实现和选择自己的算法以供 DNN 使用。该框架的内置加速实现被证明可以产生与流行的 DNN 框架 PyTorch 中的实现相当的输出并表现出类似的性能。此外，该框架不会产生额外的性能开销，这意味着性能完全取决于用户选择的算法。]]></description>
      <guid>https://arxiv.org/abs/2410.08300</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全局李雅普诺夫函数：数学中一个长期存在的开放性问题，具有符号变换器</title>
      <link>https://arxiv.org/abs/2410.08304</link>
      <description><![CDATA[arXiv:2410.08304v1 公告类型：新
摘要：尽管语言模型取得了惊人的进步，但它们在复杂的推理任务（例如高等数学）上仍然举步维艰。我们考虑数学中一个长期存在的未解决的问题：发现一个确保动态系统全局稳定性的 Lyapunov 函数。这个问题没有已知的通用解决方案，算法求解器只存在于一些小的多项式系统。我们提出了一种从随机解生成合成训练样本的新方法，并表明在这样的数据集上训练的序列到序列转换器在多项式系统上的表现优于算法求解器和人类，并且可以为非多项式系统发现新的 Lyapunov 函数。]]></description>
      <guid>https://arxiv.org/abs/2410.08304</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LoRA 的随机非对称链：第一个有意义的低秩适应理论框架</title>
      <link>https://arxiv.org/abs/2410.08305</link>
      <description><![CDATA[arXiv:2410.08305v1 公告类型：新
摘要：微调已成为将大型基础模型适应特定任务的流行方法。随着模型和数据集的大小不断增长，参数高效的微调技术变得越来越重要。最广泛使用的方法之一是低秩自适应 (LoRA)，其自适应更新表示为两个低秩矩阵的乘积。虽然 LoRA 在微调方面表现出色，但与全参数微调 (FPFT) 相比，它的表现往往不佳。尽管 LoRA 的许多变体已经得到了广泛的实证研究，但它们的理论优化分析却严重不足。我们工作的出发点是证明 LoRA 及其两个扩展，非对称 LoRA 和 LoRA 链，确实遇到了收敛问题。为了解决这些问题，我们提出了 LoRA 的随机非对称链 (RAC-LoRA)——一种通用优化框架，可严格分析基于 LoRA 的方法的收敛速度。我们的方法继承了 LoRA 式启发式方法的经验优势，但引入了一些虽小但重要的算法修改，将其转变为可证明的收敛方法。我们的框架充当了 FPFT 和低秩自适应之间的桥梁。我们提供了与 FPFT 相同的解决方案的收敛可证明保证以及收敛速度。此外，我们还对平滑、非凸损失函数进行了收敛分析，涵盖了梯度下降、随机梯度下降和联邦学习设置。我们的理论发现得到了实验结果的支持。]]></description>
      <guid>https://arxiv.org/abs/2410.08305</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UNIQ：离线逆 Q 学习，用于避免不良演示</title>
      <link>https://arxiv.org/abs/2410.08307</link>
      <description><![CDATA[arXiv:2410.08307v1 公告类型：新
摘要：我们解决了离线学习避免不良演示的策略的问题。与旨在模仿专家或接近最佳演示的传统离线模仿学习方法不同，我们的设置涉及避免不良行为（使用不良演示指定）。为了解决这个问题，与旨在最小化学习策略和专家演示之间距离的标准模仿学习不同，我们将学习任务制定为在状态动作平稳分布空间中最大化学习策略和不良策略之间的统计距离。这种截然不同的方法产生了一种新颖的训练目标，需要一种新的算法来解决它。我们的算法 UNIQ 通过构建逆 Q 学习框架来解决这些挑战，将学习问题构建为合作（非对抗）任务。然后，我们演示如何有效地利用未标记的数据进行实际训练。我们的方法在标准基准环境中进行了评估，其表现始终优于最先进的基准。代码实现可从以下网址访问：https://github.com/hmhuy0/UNIQ。]]></description>
      <guid>https://arxiv.org/abs/2410.08307</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缺失值插补的机器学习</title>
      <link>https://arxiv.org/abs/2410.08308</link>
      <description><![CDATA[arXiv:2410.08308v1 公告类型：新
摘要：近年来，已经开展了大量研究来解决缺失值插补 (MVI) 问题。MVI 旨在为具有一个或多个缺失属性值的数据集提供主要解决方案。人工智能 (AI) 的进步推动了新的和改进的机器学习 (ML) 算法和方法的发展。ML 的进步为有效地插补这些缺失值开辟了重要的机会。本文的主要目的是对 MVI 方法中最先进的 ML 应用进行全面而严格的审查和分析。该分析旨在增强研究人员对该主题的理解，并促进开发用于数据分析的数据预处理的强大而有影响力的干预措施。审查是按照系统评价和荟萃分析 (PRISMA) 技术的首选报告项目进行的。本书对 2014 年至 2023 年期间发表的 100 多篇文章进行了严格审查，并考虑了其中的方法和发现。此外，本书还研究了最新文献，以审视 MVI 方法及其评估的趋势。本书详细讨论了现有文献的成就和局限性。本书最后指出了当前研究的差距，并为相关领域的未来研究方向和新兴趋势提供了建议。]]></description>
      <guid>https://arxiv.org/abs/2410.08308</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>