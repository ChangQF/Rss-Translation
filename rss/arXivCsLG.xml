<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 21 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>广义快速调整：调整冻结单变量时间序列基础模型以适应多变量医疗保健时间序列</title>
      <link>https://arxiv.org/abs/2411.12824</link>
      <description><![CDATA[arXiv:2411.12824v1 公告类型：新
摘要：时间序列基础模型是在大型数据集上预先训练的，能够在各种任务中实现最先进的性能。然而，到目前为止，很少有工作能证明这些模型在医疗应用中的表现如何，因为标记数据可能很少。此外，我们观察到，目前大多数时间序列基础模型要么本质上是单变量的，要么假设通道独立，这意味着它们处理多变量时间序列，但不模拟不同变量之间的关系。在本文中，我们提出了一种受快速调整启发的微调技术，即广义快速调整 (Gen-P-Tuning)，它使我们能够调整现有的单变量时间序列基础模型（视为冻结）来处理多变量时间序列预测。我们的方法提供了一种跨多变量时间序列的通道（变量）组合信息的方法。我们证明了我们的微调方法在两个 MIMIC 分类任务和流感样疾病预测中针对各种基线的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.12824</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有序反馈的奖励建模：群体智慧</title>
      <link>https://arxiv.org/abs/2411.12843</link>
      <description><![CDATA[arXiv:2411.12843v1 公告类型：新
摘要：从人类偏好中学习奖励模型 (RM) 一直是对齐大型语言模型 (LLM) 的重要组成部分。从成对偏好数据中学习 RM 的规范设置植根于经典的 Bradley-Terry (BT) 模型，该模型接受二元反馈，即标签要么是响应 1 优于响应 2，要么是相反的。这样的设置不可避免地会丢弃潜在的有用样本（例如两个响应之间“并列”）并丢失更多细粒度信息（例如“略好”）。在本文中，我们提出了一个在序数反馈下学习 RM 的框架，该框架将二元偏好反馈的情况推广到任意粒度。具体而言，我们首先确定一个边际无偏条件，该条件将现有二元反馈设置中的 BT 模型假设推广。该条件通过群体智慧的社会学概念得到验证。在此条件下，我们为序数反馈下的成对偏好数据开发了一个自然概率模型并分析了其性质。与二元反馈的情况相比，我们证明了序数反馈在降低 Rademacher 复杂度方面的统计优势。提出的学习目标和理论还扩展到铰链损失和直接策略优化 (DPO)。特别是，当应用于看似不相关的知识提炼问题以解释其中的偏差-方差权衡时，理论分析可能具有独立的兴趣。该框架还为人类注释者的写作指导提供了启示。我们的数值实验验证了细粒度反馈可以为分布内和分布外设置带来更好的奖励学习。进一步的实验表明，结合一定比例的具有绑定偏好的样本可以促进 RM 学习。]]></description>
      <guid>https://arxiv.org/abs/2411.12843</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>mDAE：改进的去噪自动编码器，用于缺失数据插补</title>
      <link>https://arxiv.org/abs/2411.12847</link>
      <description><![CDATA[arXiv:2411.12847v1 公告类型：新
摘要：本文介绍了一种基于去噪自动编码器 (DAE) 的缺失数据填补方法。所提出的方法（以下称为 mDAE）源于对损失函数的修改和选择超参数的简单程序。一项消融研究在多个 UCI 机器学习存储库数据集上显示了使用这种修改后的损失函数和过完备结构在重建的均方根误差 (RMSE) 方面的好处。这项数值研究是通过将 mDAE 方法与其他八种方法（四种标准方法和四种较新的方法）进行比较来完成的。提出了一种称为平均最佳距离 (MDB) 的标准来衡量一种方法在所有数据集上的全局表现。该标准定义为所考虑方法的 RMSE 与最佳方法的 RMSE 之间的距离的平均值（在数据集上）。根据这一标准，mDAE 方法始终位居顶级方法之列（与 SoftImput 和 missForest 并列），而较新的四种方法则排在最后。数值研究的 Python 代码将在 GitHub 上提供，以便可以重现结果或将其推广到其他数据集和方法中。]]></description>
      <guid>https://arxiv.org/abs/2411.12847</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将二级结构信息整合到三角空间关系 (TSR) 中以实现高级蛋白质分类</title>
      <link>https://arxiv.org/abs/2411.12853</link>
      <description><![CDATA[arXiv:2411.12853v1 公告类型：新
摘要：蛋白质结构是解释生物功能的关键。传统的结构比较方法有时会忽略这些蛋白质之间更详细的相似性形式。相比之下，三角空间关系 (TSR) 等更先进的方法已被证明可以做出更精细的区分。尽管如此，TSR 的经典实现并不能整合二级结构信息，而这对于更详细地了解蛋白质的折叠模式非常重要。为了克服这些限制，我们开发了 SSE-TSR 方法。所提出的方法将二级结构元素 (SSE) 整合到基于 TSR 的蛋白质表示中。通过考虑 18 种不同的螺旋、链和线圈排列组合，这可以丰富蛋白质结构的表示。我们的结果表明，使用 SSE 可以不同程度地提高蛋白质分类的准确性和可靠性。我们分别处理了 9.2K 和 7.8K 个样本的两个大型蛋白质数据集。我们采用了 SSE-TSR 方法，并使用神经网络模型进行分类。有趣的是，引入 SSE 改善了数据集 1 的性能统计数据，准确率从 96.0% 提高到 98.3%。对于性能统计数据已经很好的数据集 2，引入 SSE 后发现进一步的小幅改进，准确率从 99.4% 提高到 99.5%。这些结果表明，SSE 集成可以显著提高 TSR 关键识别率，在初始准确率较低的数据集中具有显著优势，而在基线性能较高的数据集中仅获得增量收益。因此，SSE-TSR 是一种强大的生物信息学工具，可改善蛋白质分类以及对蛋白质功能和相互作用的理解。]]></description>
      <guid>https://arxiv.org/abs/2411.12853</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CDI：扩散模型中的版权数据识别</title>
      <link>https://arxiv.org/abs/2411.12858</link>
      <description><![CDATA[arXiv:2411.12858v1 公告类型：新
摘要：扩散模型 (DM) 受益于大型和多样化的数据集进行训练。由于这些数据通常是在未经数据所有者许可的情况下从互联网上抓取的，这引发了对版权和知识产权保护的担忧。虽然对于由 DM 在推理时完美重建的训练样本，很容易检测到数据的（非法）使用，但当可疑 DM 的输出不是近似副本时，数据所有者很难验证他们的数据是否用于训练。从概念上讲，成员推理攻击 (MIA) 可以检测给定数据点是否在训练期间使用，它们是解决这一挑战的合适工具。然而，我们证明现有的 MIA 不足以可靠地确定大型、最先进的 DM 中单个图像的成员资格。为了克服这一限制，我们提出了 CDI，这是一个供数据所有者识别他们的数据集是否用于训练给定 DM 的框架。 CDI 依赖于数据集推理技术，即，CDI 不使用来自单个数据点的成员信号，而是利用这样一个事实：大多数数据所有者（例如图片提供商、视觉媒体公司甚至个人艺术家）都拥有包含多个公开数据点的数据集，这些数据点可能全部包含在给定 DM 的训练中。通过有选择地汇总来自现有 MIA 的信号并使用新的手工方法提取这些数据集的特征，将它们输入评分模型并应用严格的统计测试，CDI 允许数据所有者使用少至 70 个数据点以超过 99% 的置信度识别他们的数据是否用于训练给定的 DM。因此，CDI 是数据所有者声称其版权数据被非法使用的重要工具。]]></description>
      <guid>https://arxiv.org/abs/2411.12858</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于张量的普通最小二乘法和神经网络回归模型的基础</title>
      <link>https://arxiv.org/abs/2411.12873</link>
      <description><![CDATA[arXiv:2411.12873v1 公告类型：新
摘要：本文介绍了一种数学开发普通最小二乘法和神经网络回归模型的新方法，与当前机器学习文献中的传统方法不同。通过利用张量分析和基本矩阵计算，这两个模型的理论基础都得到了细致的阐述，并扩展到完整的算法形式。这项研究最终介绍了三种算法，包括神经网络反向传播算法的精简版本，说明了这种新数学方法的好处。]]></description>
      <guid>https://arxiv.org/abs/2411.12873</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Puppet-CNN：使用常微分方程进行模型压缩的输入自适应卷积神经网络</title>
      <link>https://arxiv.org/abs/2411.12876</link>
      <description><![CDATA[arXiv:2411.12876v1 Announce Type: new 
摘要：卷积神经网络（CNN）在很多机器学习任务中表现出色，尤其是在结构较深、结构复杂的任务中，被应用到越来越多的场景中。然而，随着网络的深入，需要存储和优化的参数也越来越多。此外，几乎所有常见的CNN模型都采用“训练即用”的策略，即结构是预定义的，训练后核参数是固定的，所有数据都使用相同的结构和参数集，而不考虑内容的复杂性。在本文中，我们提出了一种新的CNN框架，名为$\textit{Puppet-CNN}$，它包含两个模块：一个$\textit{puppet module}$和一个$\textit{puppeteer module}$。 puppet 模块和其他工作一样，是一个用于实际处理输入数据的 CNN 模型，但其深度和核每次都是由 puppeteer 模块（用常微分方程 (ODE) 实现）根据输入复杂度生成的。通过在 puppet 模块中循环生成核参数，我们可以利用不同卷积层核之间的依赖关系，通过仅存储和训练小得多的 puppeteer ODE 模块的参数来显著减小 CNN 模型的大小。通过在多个数据集上的实验，我们的方法已被证明在性能和效率上都优于传统的 CNN。模型大小可以缩小 10 倍以上。]]></description>
      <guid>https://arxiv.org/abs/2411.12876</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>选择性注意：通过原则性上下文控制增强 Transformer</title>
      <link>https://arxiv.org/abs/2411.12892</link>
      <description><![CDATA[arXiv:2411.12892v1 公告类型：新
摘要：Transformer 架构中的注意力机制使模型能够根据与查询的相关性对标记进行加权和组合。虽然自注意力取得了巨大成功，但它通过应用映射 $V^\top\text{softmax}(Kq)$ 以相同的方式处理所有查询 $q$，其中 $V,K$ 分别是值和键嵌入。在这项工作中，我们认为这种统一处理阻碍了控制上下文稀疏性和相关性的能力。作为一种解决方案，我们引入了 $\textit{Selective Self-Attention}$ (SSA) 层，它通过原则性的温度缩放策略增强了 softmax 非线性。通过控制温度，SSA 将注意力图的上下文稀疏性调整到查询嵌入及其在上下文窗口中的位置。通过理论和实验，我们证明这可以减轻注意力稀释，有助于优化过程，并增强模型控制单个查询的 softmax 尖峰的能力。我们还结合了值嵌入的温度缩放，并表明它提高了模型抑制不相关/嘈杂标记的能力。值得注意的是，SSA 是一种轻量级方法，它通过权重共享策略引入了不到 0.5% 的新参数，并且可以在现有的 LLM 上进行微调。大量的实证评估表明，配备 SSA 的模型在语言建模基准上实现了显着且一致的准确性改进。]]></description>
      <guid>https://arxiv.org/abs/2411.12892</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习和 3D 断层扫描 SAR 进行树种分类——以北欧为例</title>
      <link>https://arxiv.org/abs/2411.12897</link>
      <description><![CDATA[arXiv:2411.12897v1 公告类型：新
摘要：树种分类在自然保护、森林清查、森林管理和濒危物种保护中发挥着重要作用。在过去的四十年里，遥感技术被广泛应用于树种分类，其中合成孔径雷达 (SAR) 成为一项关键技术。在本研究中，我们使用了 3D 断层扫描数据集 TomoSense，它利用 SAR 的副产品单视复合 (SLC) 图像堆栈，以不同的入射角捕获这些图像来生成地形的三维表示。我们的研究重点是使用从断层扫描图像强度中得出的高度信息来评估多个表格机器学习模型，以对八种不同的树种进行分类。在不同的极化配置和地理分割配置中分析了 SLC 数据和断层扫描图像。我们研究了这些变化对分类准确性的影响，比较了各种表格机器学习模型的性能，并使用贝叶斯优化对它们进行了优化。此外，我们还使用来自光检测和测距 (LiDAR) 的点云数据，加入了实际树高的代理，以提供与模型预测相关的高度统计数据。通过此比较，我们可以了解断层扫描数据在根据高度预测树种分类方面的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2411.12897</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MLDGG：图领域泛化的元学习</title>
      <link>https://arxiv.org/abs/2411.12913</link>
      <description><![CDATA[arXiv:2411.12913v1 公告类型：新
摘要：图上的领域泛化旨在开发具有强大泛化能力的模型，确保在测试集上具有有效的性能，尽管测试和训练分布之间存在差异。然而，现有的方法通常依赖于直接应用于目标域的静态编码器，限制了其灵活的适应性。与专注于开发特定泛化模型的传统方法相比，我们的框架 MLDGG 致力于通过将跨多领域元学习与结构学习和语义识别相结合，实现跨不同领域的适应性泛化。首先，它引入了一个广义结构学习器来减轻与任务无关的边缘的不利影响，增强了图神经网络 (GNN) 学习到的表示的全面性，同时捕获跨域共享的结构信息。随后，设计了一个表示学习器，通过利用因果推理进行语义识别，解开节点嵌入中的域不变语义和域特定变化信息，进一步增强泛化。在元学习的背景下，两个学习器的元参数都经过优化，以促进知识迁移，并通过在目标域内进行微调来有效适应图，其中目标图在训练期间无法访问。我们的实证结果表明 MLDGG 超越了基线方法，展示了其在三种不同的分布偏移设置中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.12913</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经崩溃的特洛伊木马清理</title>
      <link>https://arxiv.org/abs/2411.12914</link>
      <description><![CDATA[arXiv:2411.12914v1 公告类型：新
摘要：特洛伊木马攻击是对神经网络的复杂训练时攻击，它嵌入后门触发器，迫使网络对包括触发器在内的任何输入产生特定输出。随着深度网络的相关性不断增加，这些深度网络太大而无法使用个人资源进行训练，并且训练的数据太大而无法彻底审核，这些训练时攻击构成了重大风险。在这项工作中，我们将特洛伊木马攻击与神经崩溃联系起来，神经崩溃是一种现象，其中过度参数化的神经网络的最终特征表示收敛到一个简单的几何结构。我们提供实验证据表明，特洛伊木马攻击会破坏各种数据集和架构的这种收敛。然后，我们利用这种破坏来设计一种轻量级、广泛可推广的机制，用于清除来自各种不同网络架构的特洛伊木马攻击，并通过实验证明其有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.12914</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>损失对损失预测：所有数据集的缩放定律</title>
      <link>https://arxiv.org/abs/2411.12925</link>
      <description><![CDATA[arXiv:2411.12925v1 公告类型：新
摘要：虽然缩放定律为预测单个数据分布的跨计算规模的训练损失提供了一种可靠的方法，但对于这些预测应该如何随着分布的变化而变化，人们知之甚少。在本文中，我们推导出一种从一种损失预测另一种损失的策略，并将其应用于预测不同的预训练数据集以及从预训练数据到下游任务数据。即使在用于拟合曲线的最大 FLOP 预算的 20 倍下，我们的预测也能很好地推断出来。更准确地说，我们发现 (1) 当模型通过训练计算配对（训练到训练）时，在两个单独的数据集上训练的两个模型的训练损失、(2) 单个模型在任何下游分布上的训练损失和测试损失（训练到测试）以及 (3) 在两个单独的训练数据集上训练的两个模型的测试损失（测试到测试）之间存在简单的移位幂律关系。结果适用于差异很大的预训练数据集（有些完全是代码，有些则根本没有代码）和各种下游任务。最后，我们发现在某些情况下，这些移位幂律关系可以产生比推断单数据集缩放定律更准确的预测。]]></description>
      <guid>https://arxiv.org/abs/2411.12925</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LEDRO：LLM 增强型模拟电路设计空间缩减和优化</title>
      <link>https://arxiv.org/abs/2411.12930</link>
      <description><![CDATA[arXiv:2411.12930v1 公告类型：新
摘要：设计模拟电路的传统方法非常耗时，并且需要大量的人力专业知识。现有的使用贝叶斯优化 (BO) 和强化学习 (RL) 等方法的自动化工作不是最优的，而且在不同的拓扑和技术节点上推广的成本很高。在我们的工作中，我们引入了一种新方法 LEDRO，利用大型语言模型 (LLM) 结合优化技术来迭代细化模拟电路尺寸的设计空间。与其他 RL 和 BO 基线相比，LEDRO 具有高度的可推广性，无需针对不同的拓扑或技术节点进行设计注释或模型训练。我们对四个 FinFET 技术节点上的 22 种不同运算放大器拓扑对我们提出的框架和基线进行了全面评估。结果表明，LEDRO 的性能非常出色，它比我们的最佳基准性能平均高出 13%，低复杂度运算放大器的 FoM 性能提升了 2.15 倍，而高复杂度运算放大器的 FoM 性能提升了 48%，速度提高了 1.7 倍。这凸显了 LEDRO 的高效性能、效率和通用性。]]></description>
      <guid>https://arxiv.org/abs/2411.12930</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过稀疏观测数据，机器学习重建海啸动态</title>
      <link>https://arxiv.org/abs/2411.12948</link>
      <description><![CDATA[arXiv:2411.12948v1 公告类型：新
摘要：我们研究了使用 Senseiver（一种专为稀疏传感应用而设计的变压器神经网络）从稀疏观测中估计海啸波的全场表面高度测量值。该模型在通过浅水方程求解器生成的大量模拟数据上进行训练，我们通过与历史事件进行比较，表明这些数据忠实地再现了底层动态。我们在一个由 8 个海啸模拟组成的数据集上训练该模型，这些模拟的震中对应于历史 USGS 地震记录，并且模型输入仅限于在主动部署的浮标位置获得的测量值。我们在由 8 个未包含在训练中的模拟组成的数据集上测试了 Senseiver，证明了其外推能力。结果显示，只要至少有几个传感器获得了非零信号，就可以从真实场中获得精细尺度相位和振幅特征的显着分辨率。自始至终，我们讨论了哪些预测技术可以通过这种方法改进，并提出了如何利用架构的灵活性来整合任意遥感数据（例如高频雷达和卫星测量）以及研究最佳传感器位置的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.12948</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一的城市时空流量预测基础模型</title>
      <link>https://arxiv.org/abs/2411.12972</link>
      <description><![CDATA[arXiv:2411.12972v1 公告类型：新
摘要：城市时空流量预测包括交通流量和人群流量，对于优化城市基础设施和管理交通和应急响应至关重要。传统方法依赖于针对基于网格的数据（将城市表示为统一单元）或基于图形的数据（将城市建模为节点和边的网络）量身定制的单独模型。在本文中，我们构建了 UniFlow，这是一个用于通用城市流量预测的基础模型，它将基于网格的数据和基于图形的数据统一起来。我们首先设计一种多视图时空修补机制，将不同的数据标准化为一致的顺序格式，然后引入时空转换器架构来捕获复杂的相关性和动态。为了利用不同数据类型之间的共享时空模式并促进有效的交叉学习，我们提出了时空记忆检索增强 (ST-MRA)。 ST-MRA 通过创建结构化记忆模块来存储共享的时空模式，通过自适应记忆检索增强预测能力。大量实验表明，UniFlow 在基于网格和基于图形的流量预测方面均优于现有模型，尤其是在数据可用性有限的场景中表现出色，展示了其卓越的性能和广泛的适用性。数据集和代码实现已在 https://github.com/YuanYuan98/UniFlow 上发布。]]></description>
      <guid>https://arxiv.org/abs/2411.12972</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>