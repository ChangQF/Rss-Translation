<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 机器学习 (cs.LG) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Wed, 06 Dec 2023 03:14:31 GMT</lastBuildDate>
    <item>
      <title>用于边缘推理的低精度混合计算模型。 （arXiv：2312.02210v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02210</link>
      <description><![CDATA[本文提出了一种混合计算神经网络处理方法
适用于包含低精度（低宽度）Posit 和
低精度定点 (FixP) 数字系统。这种混合计算
方法采用 4 位 Posit (Posit4)，它在零附近具有更高的精度，
用于表示高灵敏度的权重，同时使用 4 位 FixP
(FixP4) 用于表示其他权重。用于分析的启发式
提出了权重的重要性和量化误差来分配
不同权重的正确数字系统。另外，还有一个梯度
引入Posit表示的近似来提高
反向传播过程中的权重更新。由于能量高
完全基于Posit的计算、神经网络操作的消耗
在 FixP 或 Posit/FixP 中执行。高效的硬件实现
具有第一 Posit 操作数和 FixP 的第二操作数的 MAC 操作，以及
累加器被提出。所提出的低精度的功效
混合计算方法在视觉和语言方面进行了广泛评估
楷模。结果表明，平均而言，准确率
混合计算比FixP高约1.5%，成本低0.19%
能源开销。
]]></description>
      <guid>http://arxiv.org/abs/2312.02210</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:31 GMT</pubDate>
    </item>
    <item>
      <title>JarviX：用于表格数据分析和优化的 LLM 无代码平台。 （arXiv：2312.02213v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02213</link>
      <description><![CDATA[在这项研究中，我们介绍了 JarviX，一个复杂的数据分析框架。
JarviX 旨在采用大型语言模型 (LLM) 来促进
自动指导并对表格数据集执行高精度数据分析。
该框架强调不同列类型的重要性，
利用最先进的法学硕士来生成简明的数据洞察力
总结、提出相关分析查询、有效地可视化数据，以及
对从大量数据中得出的结果提供全面的解释
分析管道。此外，JarviX 还集成了自动化机器学习
用于预测建模的 (AutoML) 管道。这种整合形成了
全面且自动化的优化周期，这证明特别
有利于优化机器配置。功效与
JarviX的适应性通过一系列实际用例得到证实
学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.02213</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:31 GMT</pubDate>
    </item>
    <item>
      <title>学习大脑区域的高阶关系。 （arXiv：2312.02203v1 [q-bio.NC]）</title>
      <link>http://arxiv.org/abs/2312.02203</link>
      <description><![CDATA[发现大脑区域之间可靠且信息丰富的相互作用
功能磁共振成像 (fMRI) 信号对于
认知的神经科学预测。目前的大部分方法都无法
准确地描述这些相互作用，因为它们只关注成对的
的连接而忽略了大脑区域的高阶关系。我们
深入研究这个问题并认为这些高阶关系应该是
最大信息量和最小冗余（MIMR）。然而，识别此类
高阶关系具有挑战性，而且尚未得到充分探索。方法
可以根据我们的情况进行定制的也是不存在的。针对这一差距，
我们提出了一种名为 HyBRiD 的新方法，旨在提取 MIMR 高阶
fMRI 数据的关系。 HyBRiD 使用构造函数来识别
超边结构，以及计算每个超边权重的权重器。
HyBRiD 通过创新的信息瓶颈实现 MIMR 目标
具有理论保证的名为多头下降瓶颈的框架。我们的
综合实验证明了我们模型的有效性。我们的模型
平均优于最先进的预测模型 12.1%，
关于通过 CPM（一种标准协议）测量的超边缘质量
研究大脑连接。
]]></description>
      <guid>http://arxiv.org/abs/2312.02203</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>我们可以学习高效沟通的优化器吗？ （arXiv：2312.02204v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02204</link>
      <description><![CDATA[SGD 的通信高效变体，特别是本地 SGD，具有
近年来受到了极大的兴趣。这些方法计算
在对模型进行平均之前，在本地（即每个工作人员上）执行多个梯度步骤
参数，有助于缓解关键的通信瓶颈
分布式深度学习训练。尽管这些方法有很多变体
已经被提出，它们有时可能落后于最先进的自适应
深度学习的优化器。在这项工作中，我们调查最近是否
学习优化器这一新兴领域的进展可能会解决这个问题
差距，同时保持沟通效率。具体来说，我们元学习如何
根据本地 SGD 迭代的更新执行全局更新。我们的成果
证明学习优化器可以大大优于本地 SGD，并且
其复杂的变体，同时保持其通信效率。
学习的优化器甚至可以推广到看不见的和更大的数据集
架构，包括 ImageNet 和 ViTs，以及看不见的模式，例如
语言建模。因此，我们展示了学习优化器的潜力
用于提高通信效率的分布式学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.02204</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>解开数据增强和格式转换在图像表示自监督学习中的影响。 （arXiv：2312.02205v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02205</link>
      <description><![CDATA[自我监督学习 (SSL) 支持使用以下方法训练高性能模型
有限的标记数据。 SSL 愿景的支柱之一是使用
输入的数据增强/扰动不会显着改变
它的语义内容。对于音频和其他时间信号，增强是
通常与格式变换（例如傅里叶变换或小波）一起使用
转变。与增强不同，格式转换不会改变
数据中包含的信息；相反，它们表达相同的信息
不同的坐标。在本文中，我们研究格式转换的影响
以及视觉 SSL 上单独和一起的增强。我们定义
频率空间的增强称为傅里叶域增强（FDA）和
表明结合这些和图像增强来训练 SSL 模型
可以将下游分类准确率提高高达 1.3%
ImageNet-1K。我们还展示了在几次测试中相对于 SSL 基线的改进
使用 FDA 的迁移学习设置。令人惊讶的是，我们也观察到这种格式
即使没有，变换也可以提高学习表示的质量
增强；然而，两种技术的结合会产生更好的结果
质量。
]]></description>
      <guid>http://arxiv.org/abs/2312.02205</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:30 GMT</pubDate>
    </item>
    <item>
      <title>通过整合多组学数据中数据集间和数据集内的关系来识别癌症亚型。 （arXiv：2312.02195v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02195</link>
      <description><![CDATA[多组学数据的整合已成为一种有前途的方法
获得对癌症等复杂疾病的全面见解。这张纸
提出了一种通过整合来识别癌症亚型的新方法
用于聚类的多组学数据。所提出的方法名为 LIDAF，利用
基于不同之间和内部的线性关系的亲和力矩阵
组学数据集（线性数据集间和数据集内亲和融合 (LIDAF)）。
本文采用典型相关分析来创建距离
基于典型变量之间的欧几里得距离的矩阵。距离
矩阵转换为亲和矩阵，并通过三步融合
过程。所提出的 LIDAF 解决了现有方法的局限性
导致聚类性能的提高（通过调整后的测量值来衡量）
兰德指数和标准化互信息得分。此外，我们提出的
LIDAF 方法显示 log10 等级的 50% 显着增强
从 Cox 生存分析中获得的 p 值，超越了
最佳报告方法，强调其识别不同癌症的潜力
亚型。
]]></description>
      <guid>http://arxiv.org/abs/2312.02195</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:29 GMT</pubDate>
    </item>
    <item>
      <title>USat：用于多传感器卫星图像的统一自监督编码器。 （arXiv：2312.02199v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02199</link>
      <description><![CDATA[大型、自我监督的视觉模型已经带来了显着的进步
自动解释自然图像。近期作品已开始剪裁
这些方法对具有丰富结构的遥感数据
多传感器、多光谱和时间信息提供海量
可用于自我监督预训练的大量自标记数据。
在这项工作中，我们开发了一种名为 USat 的新编码器架构，它可以输入
来自多个传感器的多光谱数据用于自我监督预训练。
USat 是一个视觉转换器，具有修改后的补丁投影层和
位置编码来模拟具有不同空间尺度的光谱带
多个传感器。我们将 USAt 集成到掩码自动编码器 (MAE) 中
自监督预训练程序并发现预训练的 USAt
优于在远程训练的最先进的自监督 MAE 模型
多个遥感基准数据集的传感数据（高达 8%）和线索
改善低数据状况（高达 7%）。代码和预训练权重
可在 https://github.com/stanfordmlgroup/USat 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.02199</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:29 GMT</pubDate>
    </item>
    <item>
      <title>具有平滑裁剪的类 Adam 算法达到全局最小值：基于函数 SDE 遍历性的分析。 （arXiv：2312.02182v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02182</link>
      <description><![CDATA[在本文中，我们证明了一种具有平滑裁剪的 Adam 型算法
接近正则化非凸损失函数的全局最小化。
添加平滑裁剪并将状态空间作为所有的集合
轨迹，我们可以为此应用马尔可夫半群的遍历理论
算法并研究其渐近行为。我们的遍历理论
本文建立减少了评估收敛性的问题，
该算法对问题的泛化误差和离散化误差
评估两个函数随机微分之间的差异
具有不同漂移系数的方程（SDE）。由于我们的
分析，我们已经证明该算法最小化了正则化
非凸损失函数，其误差形式为 $n^{-1/2}$、$\eta^{1/4}$，
$\beta^{-1}\log (\beta + 1)$ 和 $e^{- c t}$。这里，$c$是一个常数，$n$，
$\eta$、$\beta$ 和 $t$ 分别表示训练数据集的大小、学习率、
分别为温度和时间的倒数。
]]></description>
      <guid>http://arxiv.org/abs/2312.02182</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>下行链路 FD-RAN 的信道无反馈传输：基于无线电映射的复值预编码网络方法。 （arXiv：2312.02184v1 [cs.IT]）</title>
      <link>http://arxiv.org/abs/2312.02184</link>
      <description><![CDATA[随着对高质量服务的需求激增，创新网络
完全解耦 RAN (FD-RAN) 架构的出现是为了更加灵活
频谱资源利用率高，网络成本低。然而，随着
FD-RAN中上行基站和下行基站的解耦，
传统的传输机制，依赖于实时的通道反馈，
不适合，因为接收者无法准确及时地反馈
向发射机发送信道状态信息。本文提出了一种小说
不依赖物理层信道反馈的传输方案。
具体来说，我们设计了一种基于无线电图的复值预编码
network~(RMCPNet)模型，输出基于用户的基站预编码
地点。 RMCPNet由多个子网组成，每个子网负责
从不同的输入模态中提取独特的模态特征。此外，
来自这些不同子网的多模态嵌入被集成
在信息融合层内，最终形成统一的表示。
我们还开发了一种特定的 RMCPNet 训练算法，该算法采用负
频谱效率作为损失函数。我们评估了
在公共 DeepMIMO 数据集上提出的方案并表明 RMCPNet 可以
与传统技术相比，性能分别提高 16\% 和 76\%
分别是实值神经网络和统计码本方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.02184</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>基于单一传感器的活动识别的虚拟融合与对比学习。 （arXiv：2312.02185v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02185</link>
      <description><![CDATA[各种类型的传感器可用于人类活动识别（HAR），
他们每个人都有不同的优点和缺点。有时单个
传感器无法从其角度完全观察用户的动作，这
导致错误的预测。虽然传感器融合提供了更多信息
HAR，它具有许多固有的缺点，例如用户隐私和接受度，
设置、操作和维护成本高昂。为了解决这个问题，我们
提出虚拟融合——一种利用未标记数据的新方法
训练期间来自多个时间同步传感器，但只需要一个
传感器进行推理。采用对比学习来开发
传感器之间的相关性。虚拟融合显着提高了准确性
比使用相同的单个传感器进行训练要好，在某些情况下，它甚至超过了
在测试时使用多个传感器进行实际融合。我们也扩展这个方法
到一个更通用的版本，称为虚拟融合中的实际融合（AFVF），
它在推理过程中使用训练传感器的子集。我们的方法实现了
UCI-HAR 和 PAMAP2 基准上最先进的准确度和 F1 分数
数据集。可根据要求实施。
]]></description>
      <guid>http://arxiv.org/abs/2312.02185</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>使用反事实对齐识别虚假相关性。 （arXiv：2312.02186v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02186</link>
      <description><![CDATA[由虚假相关性驱动的模型通常会产生较差的泛化能力
表现。我们提出了反事实对齐方法来检测和
探索黑盒分类器的虚假相关性。反事实图像
针对一个分类器生成的结果可以输入到其他分类器中
看看它们是否也会引起这些分类器输出的变化。这
这些响应之间的关系可以量化并用于识别
存在虚假相关性的特定实例以及计算
数据集的聚合统计数据。我们的工作展示了我们的能力
检测面部属性分类器中的虚假相关性。这是经过验证的
通过观察面部属性分类器的直观趋势以及
制造虚假相关性并检测它们的存在，无论是视觉上
和定量。此外，利用 CF 对齐方法，我们证明了
我们可以纠正分类器中发现的虚假相关性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02186</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:28 GMT</pubDate>
    </item>
    <item>
      <title>用于极端 MIMO 波束管理的分层 ML 码本设计。 （arXiv：2312.02178v1 [eess.SP]）</title>
      <link>http://arxiv.org/abs/2312.02178</link>
      <description><![CDATA[波束管理是一种统一波束成形和信道状态的策略
5G 中大型天线阵列的信息 (CSI) 采集。密码本服务
波束管理中的多种用途，包括波束成形参考信号、CSI
报告和模拟波束训练。在本文中，我们提出并评估了
机器学习精炼的超大型码本设计流程
多输入多输出（X-MIMO）系统。我们提出一个神经网络
和波束选择策略来设计初始访问和细化
使用波束空间表示的端到端学习的码本。这
称为极限波束管理 (X-BM) 的算法可以显着改善
6G 和捕获所设想的超大型阵列的性能
现实的无线和物理层方面。我们的结果显示 8dB
初始接入和整体有效频谱效率的改进
与传统密码本方法相比的改进。
]]></description>
      <guid>http://arxiv.org/abs/2312.02178</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>通过潜变量推理训练思维链。 （arXiv：2312.02179v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02179</link>
      <description><![CDATA[大型语言模型 (LLM) 可以更准确、更可解释地解决问题
当被指示使用a逐步计算出答案时
“思想链”（CoT）提示。人们还可以提高法学硕士在以下方面的表现：
通过监督微调来完成特定任务，即通过对某些任务使用梯度上升
可调参数以最大化正确答案的平均对数似然
来自标记的训练集。天真地将 CoT 与监督调优结合起来
不仅需要监督正确答案，还需要监督细节
得出这些答案的理由；这些理由的代价是昂贵的
手工制作。相反，我们提出了一个微调策略，试图
最大化生成正确答案的 \emph{marginal} 对数似然
使用 CoT 提示，对所有可能的理由进行近似平均。这
核心挑战是从后验的基础上进行采样
正确答案;我们使用简单的马尔可夫链蒙特卡罗来解决它
（MCMC）期望最大化（EM）算法的灵感来自于自学
推理机 (STaR)、记忆唤醒睡眠、马尔可夫分数攀爬和持久性
对比分歧。该算法还允许一种新颖的控制变量
将梯度估计的方差驱动为零的技术
模型得到改善。将我们的技术应用于 GSM8K 和 BIG-Bench 中的任务
很难，我们发现这种 MCMC-EM 微调技术通常可以提高
模型在保留示例上的准确性高于 STaR 或使用 或 进行提示调整
没有 CoT。
]]></description>
      <guid>http://arxiv.org/abs/2312.02179</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在政府聊天机器人中有效使用生成式人工智能。 （arXiv：2312.02181v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02181</link>
      <description><![CDATA[随着人工智能的快速发展和突破
机器学习和自然语言处理，智能
问答机器人在政务领域得到广泛应用。这
论文对广东省政府进行了横向比较
聊天机器人ChatGPT和文心Ernie这两个大型语言模型，来分析
现有政府聊天机器人和 AIGC 技术的优点和缺点。
研究发现政府聊天机器人与大型聊天机器人之间存在显着差异
语言模型。中国政务聊天机器人仍处于探索阶段
并有差距要接近才能实现“智能”。探索未来
政府聊天机器人的发展方向更加深入，本研究提出了有针对性的
帮助生成式人工智能在政府中有效应用的优化路径
聊天机器人对话。
]]></description>
      <guid>http://arxiv.org/abs/2312.02181</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:27 GMT</pubDate>
    </item>
    <item>
      <title>由于分布不匹配，SVHN 数据集对于概率生成模型具有欺骗性。 （arXiv：2312.02168v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02168</link>
      <description><![CDATA[街景门牌号 (SVHN) 数据集是一个流行的基准数据集
在深度学习中。 SVHN 最初是为数字分类任务而设计的
数据集已被广泛用作各种其他任务的基准，包括
生成建模。然而，通过这项工作，我们的目的是警告社区
关于 SVHN 数据集作为生成建模基准的问题
任务：我们发现官方分为训练集和测试集
SVHN 数据集不是从同一分布中得出的。我们凭经验表明
这种分布不匹配对分类任务影响很小
（这可以解释为什么之前没有检测到这个问题），但它
严重影响概率生成模型的评估，例如
变分自动编码器和扩散模型。作为解决方法，我们建议
当SVHN用于任务时混合并重新分割官方训练和测试集
除了分类之外。我们发布了新的分割和我们以前使用的指数
在 https://jzenn.github.io/svhn-remix/ 创建它。
]]></description>
      <guid>http://arxiv.org/abs/2312.02168</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:26 GMT</pubDate>
    </item>
    </channel>
</rss>