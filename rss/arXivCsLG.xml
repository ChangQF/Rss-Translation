<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用最佳传输克服公平感知数据修复中的表征偏差</title>
      <link>https://arxiv.org/abs/2410.02840</link>
      <description><![CDATA[arXiv:2410.02840v1 公告类型：新
摘要：最佳传输 (OT) 在以公平的方式转换数据分布方面发挥着重要作用。通常，OT 运算符是从不公平的属性标记数据中学习的，然后用于修复它们。这种方法有两个显着的局限性：(i) 代表性不足的子群的 OT 运算符学习得不好（即它们容易受到表征偏差的影响）；(ii) 这些 OT 修复不能对相同分布但样本外（即档案）数据进行。在本文中，我们通过采用贝叶斯非参数停止规则来学习数据分布的每个属性标记组件来解决这两个问题。然后可以使用诱导的 OT 最优量化运算符来修复档案数据。我们制定了公平分布目标的新定义，以及允许我们在转换数据中以公平换取损害的量化器。这些用于揭示我们的表示偏差容忍方案在模拟和基准数据集中的优异性能。]]></description>
      <guid>https://arxiv.org/abs/2410.02840</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有可学习延迟的神经 DDE，适用于部分可观测的动力系统</title>
      <link>https://arxiv.org/abs/2410.02843</link>
      <description><![CDATA[arXiv:2410.02843v1 公告类型：新
摘要：最近引入了许多从数据中学习动态系统的成功方法。这些方法通常依赖于系统完整状态的可用性。然而，这个基本假设相当严格，因为它通常不会在实践中得到证实，只留下部分观察到的系统。利用统计物理学中的 Mori-Zwanzig (MZ) 形式，我们证明恒定滞后神经延迟微分方程 (NDDE) 自然可作为部分观察状态的合适模型。在实证评估中，我们表明此类模型在合成数据和实验数据上都优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2410.02843</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向分层个性化联邦学习：通过冲突梯度实现自适应层解缠</title>
      <link>https://arxiv.org/abs/2410.02845</link>
      <description><![CDATA[arXiv:2410.02845v1 公告类型：新
摘要：在个性化联邦学习 (pFL) 中，数据高度异质性会导致设备间出现显著的梯度发散，从而对学习过程产生不利影响。这种发散，尤其是当来自不同用户的梯度在聚合过程中形成钝角时，可能会抵消进展，导致严重的权重和梯度更新退化。为了解决这个问题，我们引入了一种新的 pFL 设计方法，即通过梯度分析进行分层聚合的联邦学习 (FedLAG)，利用层级的梯度冲突概念。具体而言，当不同客户端的分层梯度形成锐角时，这些梯度会沿同一方向对齐，从而实现跨不同客户端的更新以识别客户端不变特征。相反，当分层梯度对形成钝角时，这些层倾向于专注于特定于客户端的任务。事后看来，FedLAG 根据分层梯度冲突的程度分配用于个性化的层。具体而言，具有梯度冲突的层被排除在全局聚合过程之外。理论评估表明，当集成到其他 pFL 基线中时，FedLAG 会在一定程度上提高 pFL 性能。因此，与其他基线相比，我们提出的方法实现了更出色的收敛行为。大量实验表明，我们的 FedLAG 优于几种最先进的方法，并且可以轻松地与许多现有方法结合以进一步提高性能。]]></description>
      <guid>https://arxiv.org/abs/2410.02845</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>下游预测任务中 ECG 表示的自动编码器编码比较</title>
      <link>https://arxiv.org/abs/2410.02937</link>
      <description><![CDATA[arXiv:2410.02937v1 公告类型：新
摘要：心电图 (ECG) 是一种廉价且广泛使用的心血管评估工具。尽管其格式标准化且文件大小较小，但 ECG 信号（通常为 60,000 大小的向量）的高复杂性和个体间变异性使其难以在深度学习模型中使用，尤其是在只有小型数据集可用的情况下。本研究通过探索代表性心跳心电图的特征生成方法来应对这些挑战，重点是主成分分析 (PCA) 和自动编码器以降低数据复杂性。我们介绍了三种新型变分自动编码器 (VAE) 变体：随机自动编码器 (SAE)、退火 beta-VAE (Abeta-VAE) 和循环 beta-VAE (Cbeta-VAE)，并比较它们在保持信号保真度和增强下游预测任务方面的有效性。 Abeta-VAE 实现了卓越的信号重建，将平均绝对误差 (MAE) 降低至 15.7 正负 3.2 微伏，处于信号噪声水平。此外，当与 ECG 摘要特征结合时，SAE 编码改善了对降低左心室射血分数 (LVEF) 的预测，实现了 0.901 的受试者工作特征曲线下面积 (AUROC)。这一性能几乎与最先进的 CNN 模型的 0.910 AUROC 相匹配，但所需的数据和计算资源要少得多。我们的研究结果表明，这些 VAE 编码不仅可以有效简化 ECG 数据，而且还为在具有有限规模标记训练数据的情况下应用深度学习提供了实用的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.02937</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SymmetricDiffusers：学习有限对称群上的离散扩散</title>
      <link>https://arxiv.org/abs/2410.02942</link>
      <description><![CDATA[arXiv:2410.02942v1 公告类型：新
摘要：有限对称群 $S_n$ 在组合学、物理学和化学等领域至关重要。然而，由于其难以处理的规模和离散性质，学习 $S_n$ 上的概率分布带来了重大挑战。在本文中，我们介绍了 SymmetricDiffusers，这是一种新颖的离散扩散模型，它通过将其分解为使用深度神经网络学习更简单的反向扩散转换来简化学习 $S_n$ 上复杂分布的任务。我们将 riffle shuffle 确定为有效的前向转换，并根据有限群上的随机游走理论为选择扩散长度提供经验指导。此外，我们为反向转换提出了一种广义的 Plackett-Luce (PL) 分布，该分布比 PL 分布更具表现力。我们进一步引入了理论上的“去噪计划”，以提高采样和学习效率。大量实验表明，我们的模型在解决包括排序 4 位 MNIST 图像、拼图游戏和旅行商问题等任务上实现了最佳或相当的性能。我们的代码发布在 https://github.com/NickZhang53/SymmetricDiffusers。]]></description>
      <guid>https://arxiv.org/abs/2410.02942</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMCO2：提高 LLM 推理中碳足迹的准确预测能力</title>
      <link>https://arxiv.org/abs/2410.02950</link>
      <description><![CDATA[arXiv:2410.02950v1 公告类型：新
摘要：在其整个生命周期中，大型语言模型 (LLM) 在推理过程中产生的碳足迹远大于训练。LLM 推理请求的批处理大小、提示长度和令牌生成数量各不相同，而云提供商则使用不同的 GPU 类型和数量来满足准确性和延迟的不同服务级别目标。对于用户和云提供商来说，拥有一个工具来快速准确地估计 LLM 推理的碳影响至关重要，该工具可以在执行之前根据推理请求和硬件配置的组合来估计 LLM 推理的碳影响。由于模型 FLOPS 利用率较低且变化很大，因此估计 LLM 推理的碳足迹比训练更复杂，导致以前基于方程的模型不准确。此外，现有的机器学习 (ML) 预测方法要么缺乏准确性，要么需要大量的训练数据，因为它们不能充分处理不同的预填充和解码阶段，忽略了特定于硬件的功能，并且对不常见的推理配置进行低效采样。我们引入了 \coo，这是一个基于图神经网络（GNN）的模型，与以前的方法相比，它大大提高了 LLM 推理碳足迹预测的准确性。]]></description>
      <guid>https://arxiv.org/abs/2410.02950</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoML-Agent：用于全流程 AutoML 的多智能体 LLM 框架</title>
      <link>https://arxiv.org/abs/2410.02958</link>
      <description><![CDATA[arXiv:2410.02958v1 公告类型：新
摘要：自动机器学习 (AutoML) 通过自动执行开发流程中的任务（例如最佳模型搜索和超参数调整）来加速 AI 开发。现有的 AutoML 系统通常需要技术专业知识来设置复杂的工具，这通常很耗时并且需要大量的人力。因此，最近的研究开始利用大型语言模型 (LLM) 来减轻这种负担，并通过自然语言界面提高 AutoML 框架的可用性，让非专家用户能够构建他们的数据驱动解决方案。然而，这些方法通常只为 AI 开发流程中的特定过程而设计，不能有效地利用 LLM 的固有容量。本文提出了 AutoML-Agent，这是一种新型的多代理框架，专为全流程 AutoML（即从数据检索到模型部署）量身定制。 AutoML-Agent 接受用户的任务描述，促进专门的 LLM 代理之间的协作，并提供可部署的模型。与现有工作不同，我们引入了检索增强规划策略来增强探索，以寻找更优的计划，而不是制定单一计划。我们还将每个计划分解为子任务（例如，数据预处理和神经网络设计），每个子任务都由我们通过提示并行执行构建的专门代理来解决，从而使搜索过程更加高效。此外，我们提出了一种多阶段验证来验证执行结果并指导代码生成 LLM 实施成功的解决方案。使用十四个数据集对七个下游任务进行的大量实验表明，AutoML-Agent 在自动化整个 AutoML 流程方面取得了更高的成功率，从而产生了在不同领域具有良好性能的系统。]]></description>
      <guid>https://arxiv.org/abs/2410.02958</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>F-Fidelity：可解释人工智能忠实度评估的稳健框架</title>
      <link>https://arxiv.org/abs/2410.02970</link>
      <description><![CDATA[arXiv:2410.02970v1 公告类型：新 
摘要：最近的研究已经开发了许多可解释的人工智能 (XAI) 技术。尽管从深度学习模型中提取了有意义的见解，但如何正确评估这些 XAI 方法仍然是一个悬而未决的问题。最广泛使用的方法是扰动甚至删除 XAI 方法认为是输入中最重要的特征，并观察输出预测的变化。这种方法虽然有效，但却遭受分布外 (OOD) 问题，因为扰动的样本可能不再遵循原始数据分布。最近的方法 RemOve And Retrain (ROAR) 通过使用由解释引导的扰动样本重新训练模型来解决 OOD 问题。然而，考虑到分布差异，训练可能并不总是收敛。此外，使用基于 XAI 方法重新训练的模型来评估这些解释器可能会导致信息泄露，从而导致不公平的比较。我们提出了微调保真度 F-Fidelity，一种针对 XAI 的稳健评估框架，它利用 i) 与解释无关的微调策略，从而减轻信息泄漏问题；ii) 随机掩蔽操作，确保删除步骤不会生成 OOD 输入。我们设计了受控实验，使用最先进 (SOTA) 的解释器及其降级版本来验证我们框架的正确性。我们对多种数据结构进行了实验，例如图像、时间序列和自然语言。结果表明，F-Fidelity 在恢复解释器的真实排名方面显著改进了之前的评估指标。此外，我们从理论和经验上都表明，给定一个忠实的解释器，F-Fidelity 度量可用于计算有影响力的输入组件的稀疏性，即提取真实的解释大小。]]></description>
      <guid>https://arxiv.org/abs/2410.02970</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习具有扩散模型的全局轨迹搜索问题的最优控制和动态结构</title>
      <link>https://arxiv.org/abs/2410.02976</link>
      <description><![CDATA[arXiv:2410.02976v1 公告类型：新
摘要：航天器轨迹设计是一个全局搜索问题，以前的工作揭示了可以用数据驱动方法捕获的特定解决方案结构。本文探讨了圆形限制三体问题中的两个全局搜索问题：最小燃料/飞行时间的混合成本函数和转移到能量依赖的不变流形。这些问题在最优控制曲线或动态结构的使用中显示了基本结构。我们在之前的生成机器学习框架的基础上，应用扩散模型来学习搜索问题的条件概率分布，并分析模型捕捉这些结构的能力。]]></description>
      <guid>https://arxiv.org/abs/2410.02976</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种可解释的方法，用于在 HUDOC 数据库中检测有关住房和驱逐问题的判例法</title>
      <link>https://arxiv.org/abs/2410.02978</link>
      <description><![CDATA[arXiv:2410.02978v1 公告类型：新
摘要：判例法有助于我们理解人权，包括适足住房权。HUDOC 数据库提供欧洲人权法院 (ECtHR) 判例法的文本内容以及一些元数据。虽然这些元数据包含有价值的信息，例如申请编号和案件中涉及的文章，但它往往缺乏详细的实质性见解，例如案件涵盖的具体问题。这强调了需要进行详细分析以提取此类信息。然而，考虑到数据库的规模——包含超过 40,000 个案例——自动化解决方案是必不可少的。
在这项研究中，我们关注适足住房权，旨在建立模型来检测与住房和驱逐问题相关的案件。我们的实验表明，生成的模型不仅提供与更复杂的方法相当的性能，而且也是可解释的，通过突出显示最有影响力的词语为其决策提供解释。这些模型的应用导致识别出最初在数据收集过程中被忽视的新案例。这表明可以有效地应用 NLP 方法根据判例法所解决的具体问题对其进行分类。]]></description>
      <guid>https://arxiv.org/abs/2410.02978</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DecTrain：决定何时在线训练 DNN</title>
      <link>https://arxiv.org/abs/2410.02980</link>
      <description><![CDATA[arXiv:2410.02980v1 公告类型：新
摘要：当部署数据与训练数据不同时，深度神经网络 (DNN) 的准确性会下降。虽然在所有时间步骤进行在线训练可以提高准确性，但计算成本很高。我们提出了 DecTrain，这是一种新算法，它决定何时使用低开销的自监督在线训练单目深度 DNN。为了在每个时间步骤做出决定，DecTrain 将训练成本与预测的准确度增益进行比较。我们在分布外数据上评估 DecTrain，发现 DecTrain 与在线训练相比在所有时间步骤都保持了准确性，而平均训练时间仅为 44%。我们还比较了使用 DecTrain 的低推理成本 DNN 和更通用的高推理成本 DNN 在各种序列上的恢复情况。与仅恢复 66% 的高推理成本 DNN 相比，DecTrain 在所有时间步骤中恢复了在线训练的大部分 (97%) 准确度增益，同时减少了计算量。使用更小的 DNN，我们实现了 89% 的恢复率，同时将计算量减少了 56%。DecTrain 可以以低成本在线训练较小的 DNN，使其以较低的总体计算成本获得与较大、更通用的 DNN 相媲美的准确率。]]></description>
      <guid>https://arxiv.org/abs/2410.02980</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过精细的局部学习系数实现注意力头的分化和专业化</title>
      <link>https://arxiv.org/abs/2410.02984</link>
      <description><![CDATA[arXiv:2410.02984v1 公告类型：新
摘要：我们引入了局部学习系数 (LLC) 的精炼变体，这是一种基于单一学习理论的模型复杂性度量，用于研究 Transformer 语言模型在训练过程中内部结构的发展。通过将这些 \textit{精炼 LLC} (rLLC) 应用于双层仅注意 Transformer 的各个组件，我们对注意力头的逐步分化和专业化有了新的见解。我们的方法揭示了注意力头如何在训练过程中分化为不同的功能角色，分析了这些头专门处理的数据类型，并发现了以前未被发现的多字母电路。这些发现表明，rLLC 为 \textit{发展可解释性} 提供了一个原则性的定量工具包，旨在通过模型在学习过程中的演变来理解模型。更广泛地说，这项工作朝着建立数据分布结构、损失景观的几何特性、学习动态和神经网络中出现的计算结构之间的对应关系迈出了一步。]]></description>
      <guid>https://arxiv.org/abs/2410.02984</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强化学习蒙特卡罗探索启动算法的有限样本分析</title>
      <link>https://arxiv.org/abs/2410.02994</link>
      <description><![CDATA[arXiv:2410.02994v1 公告类型：新
摘要：蒙特卡洛探索起点 (MCES) 旨在仅使用样本回报来学习最佳策略，是强化学习中一种简单而自然的算法，已被证明可以在各种条件下收敛。然而，以样本复杂度形式进行的 MCES 风格算法的收敛速度分析很少受到关注。在本文中，我们为解决随机最短路径问题的改进 MCES 算法开发了一个有限样本界限。为此，我们证明了策略迭代算法收敛速度的一个新结果。该结果意味着，在 $\tilde{O}(SAK^3\log^3\frac{1}{\delta})$ 次采样事件后，算法以至少 $1-\delta$ 的概率返回最优策略，其中 $S$ 和 $A$ 分别表示状态和动作的数量，$K$ 表示事件长度，$\tilde{O}$ 隐藏了取决于已知环境奖励的对数因子和常数。]]></description>
      <guid>https://arxiv.org/abs/2410.02994</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Q-SCALE：基于量子计算的传感器校准，实现高级学习和效率</title>
      <link>https://arxiv.org/abs/2410.02998</link>
      <description><![CDATA[arXiv:2410.02998v1 公告类型：新
摘要：在一个空气污染严重的世界里，利用量子计算 (QC) 和机器学习 (ML) 的最先进的传感器校准技术的集成有望提高智能城市空气质量监测系统的准确性和效率。本文研究了通过深度学习 (DL) 和量子机器学习 (QML) 等先进方法校准廉价光学细尘传感器的过程。该项目的目标是比较来自经典和量子领域的四种复杂算法，以辨别它们的差异，并探索可能的替代方法，以提高城市空气质量监测中颗粒物测量的精度和可靠性。经典前馈神经网络 (FFNN) 和长短期记忆 (LSTM) 模型与它们的量子对应物：变分量子回归器 (VQR) 和量子 LSTM (QLSTM) 电路进行评估。通过超参数优化和交叉验证等细致的测试，本研究评估了量子模型改进校准性能的潜力。我们的分析表明：FFNN 模型在测试集上实现了优于 VQR 模型的校准精度，L1 损失函数更低（2.92 vs 4.81）；尽管使用的可训练权重较少（66 vs 482），但 QLSTM 的表现略优于 LSTM 模型（测试集损失：2.70 vs 2.77）。]]></description>
      <guid>https://arxiv.org/abs/2410.02998</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多范式训练实现通用认证稳健性</title>
      <link>https://arxiv.org/abs/2410.03000</link>
      <description><![CDATA[arXiv:2410.03000v1 公告类型：新
摘要：现有的认证训练方法只能训练模型对某种类型的扰动（例如 $l_\infty$ 或 $l_2$）具有鲁棒性。然而，一个 $l_\infty$ 可认证鲁棒模型可能对 $l_2$ 扰动不具有可认证鲁棒性（反之亦然），并且对其他扰动（例如几何变换）的鲁棒性也很低。为此，我们提出了第一个多范数认证训练框架 \textbf{CURE}，由一个新的 $l_2$ 确定性认证训练防御和几种多范数认证训练方法组成，以在从头开始训练或微调预训练认证模型时获得更好的 \emph{联合鲁棒性}。此外，我们设计了边界对齐并将自然训练与认证训练联系起来，以获得更好的联合鲁棒性。与 SOTA 认证的训练相比，\textbf{CURE} 将 MNIST 上的联合稳健性提高到 $22.8\%$，CIFAR-10 上的 $23.9\%$，TinyImagenet 上的 $8.0\%$。此外，它还可以更好地泛化一系列具有挑战性的未见过的几何扰动，CIFAR-10 上的 $6.8\%$。总体而言，我们的贡献为 \textit{通用认证的稳健性} 铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.03000</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>