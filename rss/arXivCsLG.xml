<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>混合曲率决策树和随机森林</title>
      <link>https://arxiv.org/abs/2410.13879</link>
      <description><![CDATA[arXiv:2410.13879v1 公告类型：新
摘要：决策树 (DT) 及其随机森林 (RF) 扩展是欧几里得空间中分类和回归的主力。然而，用于非欧几里得空间学习的算法仍然有限。我们将 DT 和 RF 算法扩展到乘积流形：多个双曲、超球面或欧几里得分量的笛卡尔积。这样的流形可以处理异质曲率，同时仍然可以整齐地分解为更简单的组件，使其成为复杂数据集的引人注目的嵌入空间。我们对 DT 的新颖角度重新表述尊重乘积流形的几何形状，产生测地凸、最大边距和可组合的分割。在单组分流形的特殊情况下，我们的方法简化为其欧几里得或双曲对应物，或引入超球面 DT 算法，具体取决于曲率。我们在合成数据、图嵌入、混合曲率变分自动编码器潜在空间和经验数据的各种分类、回归和链接预测任务上对我们的方法进行了基准测试。与其他六种分类器相比，乘积 DT 和 RF 在 22 个单流形基准测试中的 21 个和 35 个乘积流形基准测试中的 18 个中排名第一，在 57 个基准测试中的 53 个中排名前 2。这凸显了乘积 DT 和 RF 作为乘积流形数据分析的简单而强大的新工具的价值。我们的论文代码可在 https://github.com/pchlenski/embedders 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.13879</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>外生匹配：学习易于处理的反事实估计的良好建议</title>
      <link>https://arxiv.org/abs/2410.13914</link>
      <description><![CDATA[arXiv:2410.13914v1 公告类型：新
摘要：我们提出了一种重要性抽样方法，用于在一般环境中对反事实表达式进行易于处理和有效的估计，称为外生匹配。通过最小化反事实估计量的共同上限，我们将方差最小化问题转化为条件分布学习问题，从而能够将其与现有的条件分布建模方法相结合。我们通过各种类型和设置的结构因果模型 (SCM) 下的实验验证了理论结果，并证明了与其他现有重要性抽样方法相比，它在反事实估计任务上的表现更佳。我们还探讨了注入结构先验知识（反事实马尔可夫边界）对结果的影响。最后，我们将该方法应用于可识别的代理 SCM，并证明了估计的无偏性，从经验上说明了该方法在实际场景中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2410.13914</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GBCT：一种高效、自适应的复杂数据粒度球聚类算法</title>
      <link>https://arxiv.org/abs/2410.13917</link>
      <description><![CDATA[arXiv:2410.13917v1 Announce Type: new 
摘要：传统的聚类算法往往关注最细粒度的信息，通过计算每对数据点之间的距离或者基于点进行其他计算来实现聚类，这种方式不符合人脑“全局优先”的认知机制，导致这些方法在效率、泛化能力和鲁棒性方面表现不佳。针对这一问题，我们提出了一种基于粒球计算的新型聚类算法——粒球聚类（GBCT）。首先，GBCT生成较少数量的粒球来表示原始数据，并根据粒球之间的关系而不是传统的点关系形成聚类。同时，其粗粒度特性不易受噪声影响，算法高效且鲁棒；此外，由于粒球可以拟合各种复杂数据，GBCT在非球形数据集上的表现远远优于其他传统聚类方法。 GBCT的全新粗粒度表示方法和聚类形成模式也可以用来改进其他传统方法。]]></description>
      <guid>https://arxiv.org/abs/2410.13917</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FiTv2：可扩展且改进的扩散模型灵活视觉变换器</title>
      <link>https://arxiv.org/abs/2410.13925</link>
      <description><![CDATA[arXiv:2410.13925v1 公告类型：新
摘要：\textit{自然界是无限分辨率的}。在这种现实背景下，现有的扩散模型（例如扩散变换器）在处理其训练域之外的图像分辨率时经常面临挑战。为了解决这一限制，我们将图像概念化为具有动态大小的标记序列，而不是将图像视为固定分辨率网格的传统方法。这种观点使灵活的训练策略成为可能，该策略可以在训练和推理过程中无缝适应各种纵横比，从而促进分辨率泛化并消除图像裁剪引入的偏差。在此基础上，我们提出了\textbf{灵活视觉变换器}（FiT），这是一种专门为生成具有\textit{不受限制的分辨率和纵横比}的图像而设计的变换器架构。我们进一步将 FiT 升级为 FiTv2，并进行了多项创新设计，包括 Query-Key 向量归一化、AdaLN-LoRA 模块、整流调度器和 Logit-Normal 采样器。通过精心调整的网络结构，FiTv2 的收敛速度是 FiT 的 $2\times$。当结合先进的免训练外推技术时，FiTv2 在分辨率外推和多样化分辨率生成方面都表现出了显著的适应性。此外，我们对 FiTv2 模型可扩展性的探索表明，模型越大，计算效率越高。此外，我们引入了一种有效的后训练策略，使预训练模型适应高分辨率生成。全面的实验证明了 FiTv2 在各种分辨率下的卓越性能。我们已经在 \url{https://github.com/whlzy/FiT} 发布了所有代码和模型，以促进用于任意分辨率图像生成的扩散变压器模型的探索。]]></description>
      <guid>https://arxiv.org/abs/2410.13925</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动解释大型语言模型中的数百万个特征</title>
      <link>https://arxiv.org/abs/2410.13928</link>
      <description><![CDATA[arXiv:2410.13928v1 公告类型：新
摘要：虽然深度神经网络中神经元的激活通常没有简单的人类可理解的解释，但稀疏自动编码器 (SAE) 可用于将这些激活转换为可能更容易解释的高维潜在空间。然而，这些 SAE 可能具有数百万个不同的潜在特征，因此人类无法手动解释每一个特征。在这项工作中，我们构建了一个开源自动化管道，以使用 LLM 生成和评估 SAE 特征的自然语言解释。我们在大小、激活函数和损失各不相同的 SAE 上测试了我们的框架，并在两个不同的开放权重 LLM 上进行了训练。我们引入了五种新技术来对解释的质量进行评分，这些技术比以前的最先进技术运行成本更低。其中一种技术，干预评分，评估干预对特征的影响的可解释性，我们发现这解释了现有方法无法回忆的特征。我们提出了生成更好解释的指导方针，这些解释对于更广泛的激活环境仍然有效，并讨论了现有评分技术的缺陷。我们使用我们的解释来衡量独立训练的 SAE 的语义相似性，并发现在残差流的附近层上训练的 SAE 非常相似。我们的大规模分析证实，即使使用 top-$k$ 后处理将神经元稀疏化，SAE 潜伏层确实比神经元更易于解释。我们的代码可在 https://github.com/EleutherAI/sae-auto-interp 获得，我们的解释可在 https://huggingface.co/datasets/EleutherAI/auto_interp_explanations 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.13928</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体部分可观测性的扩散模型：共享吸引子、误差界限和复合流</title>
      <link>https://arxiv.org/abs/2410.13953</link>
      <description><![CDATA[arXiv:2410.13953v1 公告类型：新
摘要：多智能体系统努力解决部分可观测性 (PO) 问题，而分散式 POMDP (Dec-POMDP) 模型凸显了这一挑战的根本性质。尽管解决 PO 的最新方法吸引了深度学习模型，但严格理解这些模型及其近似误差如何影响智能体对 PO 及其交互的处理仍然是一个挑战。在应对这一挑战时，我们研究使用扩散模型从 ​​Dec-POMDP 中的局部动作观察历史重建全局状态。我们首先发现以局部历史为条件的扩散模型将可能状态表示为稳定的不动点。在集体可观察 (CO) Dec-POMDP 中，以智能体局部历史为条件的单个扩散模型共享一个与全局状态相对应的唯一不动点，而在非 CO 设置中，共享不动点会产生给定联合历史的可能状态分布。我们进一步发现，由于深度学习近似误差，固定点可能会偏离真实状态，并且偏差与雅可比秩呈负相关。受此低秩特性的启发，我们通过构建替代线性回归模型来限制偏差，该模型近似于扩散模型的局部行为。有了这个界限，我们提出了一种复合扩散过程，该过程在代理上进行迭代，并保证理论上收敛到真实状态。]]></description>
      <guid>https://arxiv.org/abs/2410.13953</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非线性随机梯度下降和重尾噪声：统一框架和高概率保证</title>
      <link>https://arxiv.org/abs/2410.13954</link>
      <description><![CDATA[arXiv:2410.13954v1 公告类型：新
摘要：我们研究在线学习中存在重尾噪声的情况下的高概率收敛。为了对抗重尾，我们考虑了非线性 SGD 方法的通用框架，其中包括几种流行的非线性，如符号、量化、逐分量和联合剪辑。在我们的工作中，非线性以黑盒方式处理，使我们能够为广泛的非线性方法建立统一的保证。对于对称噪声和非凸成本，我们以速率 $\widetilde{\mathcal{O}}(t^{-1/4})$ 建立梯度范数平方的收敛，而对于强凸成本的最后一次迭代，我们以速率 $\mathcal{O}(t^{-\zeta})$ 建立到种群最优的收敛，其中 $\zeta \in (0,1)$ 取决于噪声和问题参数。此外，如果噪声是对称和非对称成分的（有偏）混合，我们会显示收敛到平稳邻域，其大小取决于混合系数、非线性和噪声。与仅考虑裁剪并要求具有有界 $p$ 个矩 $p \in (1,2]$ 的无偏噪声的最新技术相比，我们为广泛的非线性提供了保证，而无需对噪声矩做任何假设。虽然最先进技术中的速率指数取决于噪声矩并且随着 $p \rightarrow 1$ 消失，但当非凸时 $p &lt; 6/5$ 和强凸成本时 $p &lt; 8/7$，我们的指数是常数并且严格更好。实验验证了我们的理论，在现实生活中展示了噪声对称性，并表明裁剪并不总是最佳非线性，进一步强调了一般框架的价值。]]></description>
      <guid>https://arxiv.org/abs/2410.13954</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扰动分析的转录组学基础模型基准测试：一个 PCA 仍然统治所有模型</title>
      <link>https://arxiv.org/abs/2410.13956</link>
      <description><![CDATA[arXiv:2410.13956v1 公告类型：新
摘要：由于技术限制和生物数据的复杂性，对生物体内基因、化合物及其相互作用之间的关系的理解仍然有限。深度学习在使用各种数据类型探索这些关系方面显示出了希望。然而，转录组学提供了对细胞状态的详细见解，由于其高噪声水平和有限的数据可用性，仍未得到充分利用。转录组学测序的最新进展为发现有价值的见解提供了新的机会，特别是随着许多新的转录组学基础模型的兴起，但尚未制定基准来稳健地评估这些新兴模型对扰动分析的有效性。本文提出了一种新颖的生物学激励评估框架和扰动分析任务层次结构，用于比较预训练基础模型的性能以及与从转录组学数据中学习的更经典技术的性能。我们从不同的测序技术和细胞系中汇编了不同的公共数据集来评估模型的性能。我们的方法表明，与现有的基础模型相比，scVI 和 PCA 是更适合理解生物扰动的模型，尤其是在现实场景中的应用中。]]></description>
      <guid>https://arxiv.org/abs/2410.13956</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强稀疏混合专家模型的泛化能力：增强组合任务中专家激活的案例</title>
      <link>https://arxiv.org/abs/2410.13964</link>
      <description><![CDATA[arXiv:2410.13964v1 公告类型：新
摘要：随着 Transformer 模型的复杂性不断增加，它们推广到新颖的组合任务的能力变得至关重要。这项研究挑战了稀疏混合专家 (SMoE) 模型在面对日益复杂的组合任务时稀疏激活的传统观点。通过对 SRAVEN 符号推理任务和 SKILL-MIX 基准的实验，我们证明激活更多专家可以提高困难任务的表现，激活专家的最佳数量会随着任务复杂性而变化。我们的研究结果表明，通过增加每个 token 的专家数量，基于 SMoE 的预训练大型语言模型在具有挑战性的组合任务上取得了更好的结果。]]></description>
      <guid>https://arxiv.org/abs/2410.13964</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>木马病毒对图神经网络发起攻击</title>
      <link>https://arxiv.org/abs/2410.13974</link>
      <description><![CDATA[arXiv:2410.13974v1 公告类型：新
摘要：图形提示学习（GPL）是一种很有前途的方法，它使用提示将预训练的 GNN 模型适应特定的下游任务，而无需对整个模型进行微调。尽管 GPL 有诸多优势，但很少有人关注它容易受到后门攻击，攻击者可以通过嵌入隐藏触发器来操纵模型的行为。现有的图形后门攻击依赖于在训练期间修改模型参数，但这种方法在 GPL 中不切实际，因为 GNN 编码器参数在预训练后被冻结。此外，下游用户可以在干净的数据集上微调自己的任务模型，这进一步使攻击复杂化。在本文中，我们提出了专为 GPL 设计的后门攻击框架 TGPA。TGPA 在不修改预训练的 GNN 编码器的情况下将后门注入图形提示中，并确保高攻击成功率和干净的准确性。为了解决用户微调模型的挑战，我们引入了一种抗微调的毒化方法，即使在下游模型调整后也能保持后门的有效性。在不同设置下对多个数据集进行的大量实验证明了 TGPA 在破坏具有固定 GNN 编码器的 GPL 模型方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.13974</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于 Transformer 在上下文稀疏恢复中的学习优化能力</title>
      <link>https://arxiv.org/abs/2410.13981</link>
      <description><![CDATA[arXiv:2410.13981v1 公告类型：新
摘要：Transformer 的一个有趣特性是它能够执行上下文学习 (ICL)，其中 Transformer 可以根据相应输入输出演示对提供的上下文信息解决不同的推理任务而无需更新参数。理论上已经证明，ICL 是由 Transformers 执行梯度下降算法的能力实现的 (Von Oswald 等人，2023a；Bai 等人，2024)。这项工作更进一步，表明 Transformers 可以执行学习优化 (L2O) 算法。具体来说，对于 ICL 稀疏恢复（表述为 LASSO）任务，我们表明 K 层 Transformer 可以执行 L2O 算法，且可证明收敛速度与 K 呈线性关系。这提供了一个新的视角，解释了 Transformers 即使​​只有几层也具有卓越的 ICL 能力，而这是标准梯度下降算法无法实现的。此外，与传统的 L2O 算法要求训练中涉及的测量矩阵与测试中的测量矩阵匹配不同，训练后的 Transformer 能够解决由不同测量矩阵生成的稀疏恢复问题。此外，作为一种 L2O 算法，Transformers 可以利用训练任务中嵌入的结构信息来加速其在 ICL 期间的收敛，并跨不同长度的演示对进行推广，而传统的 L2O 算法通常难以解决或失败。我们的实验结果支持这些理论发现。]]></description>
      <guid>https://arxiv.org/abs/2410.13981</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习中针对有界后门投毒的对抗性初始策略</title>
      <link>https://arxiv.org/abs/2410.13995</link>
      <description><![CDATA[arXiv:2410.13995v1 公告类型：新
摘要：最近的研究证明了深度强化学习 (DRL) 算法在训练时容易受到后门毒害攻击。这些攻击在部署期间观察到固定触发器时，会在代理中引发预定的对抗行为，同时允许代理在训练期间解决其预期任务。先前的攻击依赖于对代理奖励的任意大扰动来实现这两个目标 - 使它们容易被发现。因此，在这项工作中，我们提出了一类针对 DRL 的新后门攻击，这些攻击在最大限度地改变代理的奖励的同时实现了最先进的性能。这些“初始”攻击通过在训练期间诱导代理选择的动作与环境中执行的真实动作之间的分离，训练代理将目标对抗行为与高回报联系起来。我们正式定义了这些攻击并证明它们可以实现两个对抗目标。然后，我们设计了一种在线初始攻击，其在有界奖励约束下的表现明显优于之前的攻击。]]></description>
      <guid>https://arxiv.org/abs/2410.13995</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过情境偏好学习实现个性化适应</title>
      <link>https://arxiv.org/abs/2410.14001</link>
      <description><![CDATA[arXiv:2410.14001v1 公告类型：新
摘要：强化学习从人类反馈 (RLHF) 被广泛用于将语言模型 (LM) 与人类偏好保持一致。然而，现有的方法往往忽视了个人用户的偏好，导致个性化程度不理想。我们提出了偏好预训练变压器 (PPT)，这是一种使用在线用户反馈进行自适应个性化的新方法。PPT 利用变压器的上下文学习能力来动态适应个人偏好。我们的方法包括两个阶段：(1) 离线阶段，我们使用历史相关损失函数训练单一策略模型，(2) 在线阶段，模型通过上下文学习适应用户偏好。我们展示了 PPT 在上下文强盗设置中的有效性，表明它实现了优于现有方法的个性化适应，同时显着降低了计算成本。我们的结果表明，上下文学习在大型语言模型中具有可扩展和高效个性化的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.14001</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有缺失邻居信息的联邦图神经网络的共形预测</title>
      <link>https://arxiv.org/abs/2410.14010</link>
      <description><![CDATA[arXiv:2410.14010v1 公告类型：新
摘要：图在数据挖掘和机器学习中起着至关重要的作用，代表了现实世界的对象和交互。随着图数据集的增长，管理大型、分散的子图变得至关重要，尤其是在联邦学习框架中。这些框架面临着重大挑战，包括缺少邻居信息，这可能会损害安全关键环境中的模型可靠性。在这种环境中训练的联邦学习模型的部署需要量化模型的不确定性。本研究将共形预测 (CP)（一种成熟的不确定性量化方法）的适用性扩展到联邦图学习。我们专门解决分布式子图中的缺失链接问题，以尽量减少其对 CP 集大小的不利影响。我们讨论了分布式子图中的数据依赖关系，并建立了 CP 有效性和精确测试时间覆盖的条件。我们引入了一种基于变分自动编码器的方法来重建缺失的邻居，以减轻缺失数据的负面影响。对真实数据集的经验评估证明了我们方法的有效性，在确保覆盖范围保证的同时产生了更小的预测集。]]></description>
      <guid>https://arxiv.org/abs/2410.14010</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别隐私角色</title>
      <link>https://arxiv.org/abs/2410.14023</link>
      <description><![CDATA[arXiv:2410.14023v1 公告类型：新
摘要：隐私角色捕捉用户群体在知识、行为模式、自我效能水平和对隐私保护重要性的认知方面的差异。对这些差异进行建模对于适当选择有关隐私的个性化沟通（例如提高识字率）和定义隐私增强技术（PET）的合适选择至关重要。虽然文献中已经衍生出各种隐私角色，但它们将在重要属性（例如感知或期望的控制水平以及使用 PET 的动机）方面彼此不同的人归为一类。为了解决描述角色时缺乏粒度和全面性的问题，我们提出了八个角色，这些角色是我们通过结合对交互式教育问卷的回答的定性和定量分析得出的。我们设计了一个分析流程，该流程使用分裂层次聚类和 Boschloo 的比例同质性统计检验来确保所引出的聚类基于统计测量彼此不同。此外，我们提出了一种计算问卷答案之间距离的新方法，该方法考虑了用于得出特征的问题类型（封闭式与开放式）。我们表明，所提出的隐私角色在统计上彼此不同。我们对所提出的角色进行了统计验证，并将其与文献中的角色进行了比较，表明它们提供了对用户细分的更细致和全面的理解，这将使我们能够更好地帮助用户满足他们的隐私需求。]]></description>
      <guid>https://arxiv.org/abs/2410.14023</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>