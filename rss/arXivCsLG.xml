<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 20 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在文本流中生成漂移的方法</title>
      <link>https://arxiv.org/abs/2403.12328</link>
      <description><![CDATA[arXiv:2403.12328v1 公告类型：新
摘要：系统和个人不断产生数据。在互联网上，人们分享他们的知识、情感和观点，提供对服务和产品的评论等等。例如，从这些文本数据中自动学习可以为组织和机构提供见解，从而防止财务影响。为了随着时间的推移从文本数据中学习，机器学习系统必须考虑概念漂移。概念漂移是现实世界数据集中的常见现象，对应于数据分布随时间的变化。例如，当情绪发生变化或词义随着时间的推移而调整时，就会发生概念漂移。尽管概念漂移在现实应用中很常见，但带有标记漂移的基准数据集在文献中很少见。为了弥补这一差距，本文提供了四种文本漂移生成方法，以简化带有标记漂移的数据集的生成。这些方法应用于 Yelp 和 Airbnb 数据集，并使用尊重流挖掘范式的增量分类器进行测试，以评估它们从漂移中恢复的能力。结果表明，所有方法在漂移后性能都会下降，增量 SVM 运行速度最快，并且在准确性和宏 F1 分数方面恢复到之前的性能水平。]]></description>
      <guid>https://arxiv.org/abs/2403.12328</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>在嵌入式设备上使用超维计算增强透皮酒精含量检测</title>
      <link>https://arxiv.org/abs/2403.12323</link>
      <description><![CDATA[arXiv:2403.12323v1 公告类型：新
摘要： 饮酒对个人健康有重大影响，过量饮酒会产生更明显的后果。促进更健康饮酒习惯的一种方法是实施及时干预，即在酗酒期间及时发送表明中毒的通知。然而，干预机制的复杂性或侵入性可能会阻止个人在实践中使用它们。之前的研究使用收集的运动数据和传统的机器学习 (ML) 算法来应对这一挑战，对酗酒事件进行分类，但对于移动设备而言，准确性和计算效率不切实际。因此，我们选择使用超维计算（HDC）来设计一种适用于智能手机、智能可穿戴设备和物联网部署的实时干预方法。 HDC 是一个在有效处理实时传感器数据方面已得到证实的框架。这种方法具有多种优点，包括低延迟、最小功耗和高并行性。我们探索各种 HDC 编码设计，并将它们与各种 HDC 学习模型相结合，为移动设备创建最佳且可行的方法。我们的研究结果表明准确率达到 89%，比当前最先进的技术提高了 12%。]]></description>
      <guid>https://arxiv.org/abs/2403.12323</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>使用可学习的提示删除文本到图像生成模型中不需要的概念</title>
      <link>https://arxiv.org/abs/2403.12326</link>
      <description><![CDATA[arXiv:2403.12326v1 公告类型：新
摘要：生成模型在从文本描述生成视觉上令人印象深刻的内容方面表现出了巨大的潜力。然而，在未经过滤的互联网数据上训练这些模型会带来学习并随后传播不良概念的风险，例如受版权保护或不道德的内容。在本文中，我们提出了一种新颖的方法，通过将可学习的提示合并到交叉注意模块中，从文本到图像生成模型中删除不需要的概念。这种可学习的提示充当附加记忆，将不需要的概念的知识转移到其中，并减少这些概念对模型参数和相应文本输入的依赖性。由于这种知识转移到提示中，擦除这些不需要的概念更加稳定，并且对其他概念的负面影响最小。我们在稳定扩散模型上证明了我们的方法的有效性，展示了其在删除不需要的内容同时保留其他不相关元素方面相对于最先进的擦除方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.12326</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>改进 LoRA 在隐私保护联邦学习中的应用</title>
      <link>https://arxiv.org/abs/2403.12313</link>
      <description><![CDATA[arXiv:2403.12313v1 公告类型：新
摘要：低秩适应（LoRA）因其良好的性能和计算效率而成为预训练语言模型上最流行的特定任务参数高效微调（PEFT）方法之一。 LoRA 在每个冻结的预训练模型模块的顶部注入两个可训练的秩分解矩阵的乘积。然而，当应用于隐私保护联邦学习（FL）的设置时，LoRA 可能会由于以下事实而变得不稳定：1）数据异构性和多步本地更新的影响不可忽略，2）强制加性噪声更新梯度以保证差分隐私（DP）可以被放大，3）最终性能容易受到超参数的影响。导致这些现象的一个关键因素是本地客户端联合优化两个低秩矩阵与中央服务器单独聚合它们之间的不一致。因此，本文提出了一种高效且有效的 LoRA 版本，即联邦冻结 A LoRA (FFA-LoRA)，以缓解这些挑战，并将联邦微调 LLM 的通信成本进一步减半。 FFA-LoRA的核心思想是修复随机初始化的非零矩阵，仅对零初始化矩阵进行微调。与 LoRA 相比，FFA-LoRA 的动机是保护隐私的 FL 中的实践和理论优势。我们的实验表明，FFA-LoRA 在各种 FL 任务中比普通 LoRA 提供更一致的性能和更好的计算效率。]]></description>
      <guid>https://arxiv.org/abs/2403.12313</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>近似似然比：用于促进神经网络训练的仅前向并行框架</title>
      <link>https://arxiv.org/abs/2403.12320</link>
      <description><![CDATA[arXiv:2403.12320v1 公告类型：新
摘要：由于高计算复杂性和关于神经网络的额外假设等问题，神经网络训练中反向传播的高效且生物学上合理的替代方案仍然是一个挑战，这些问题限制了更深网络的可扩展性。似然比方法提供了一种很有前途的梯度估计策略，但受到大量内存消耗的限制，特别是在部署多个数据副本以减少估计方差时。在本文中，我们引入了似然比（LR）方法的近似技术，以减轻梯度估计中的计算和内存需求。通过利用 LR 后向传递过程中的自然并行性，我们进一步提供了一种高性能训练策略，该策略将前向和后向传递进行管道化，使其更适合专用硬件上的计算。大量的实验证明了近似技术在神经网络训练中的有效性。这项工作强调了似然比方法在实现高性能神经网络训练方面的潜力，并提出了进一步探索的途径。]]></description>
      <guid>https://arxiv.org/abs/2403.12320</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>使用超维图分类进行分子分类</title>
      <link>https://arxiv.org/abs/2403.12307</link>
      <description><![CDATA[arXiv:2403.12307v1 公告类型：新
摘要：我们的工作通过利用超维计算引入了一种创新的图学习方法。图作为一种广泛接受的信息传递方法，其在学习中的应用引起了广泛关注。这在化学信息学领域值得注意，从图表示中学习起着关键作用。该领域的一个重要应用涉及跨不同分子结构的癌细胞的识别。
  我们提出了一种基于 HDC 的模型，与图神经网络 (GNN) 或 Weisfieler-Lehman 图内核 (WL) 等最先进的模型相比，该模型展示了可比的曲线下面积结果。此外，它优于之前提出的超维计算图学习方法。此外，它还实现了显着的速度提升，与 GNN 和 WL 模型相比，训练阶段的加速提高了 40 倍，推理时间缩短了 15 倍。这不仅强调了基于 HDC 的方法的有效性，还凸显了其快速且资源高效的图学习的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.12307</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>通过世界模型从延迟观察中强化学习</title>
      <link>https://arxiv.org/abs/2403.12309</link>
      <description><![CDATA[arXiv:2403.12309v1 公告类型：新
摘要：在标准强化学习设置中，智能体通常会在采取行动后立即获得有关其行动效果的反馈。然而，在实践中，由于物理限制，这一假设可能不成立，并且会显着影响 RL 算法的性能。在本文中，我们重点解决部分可观测环境中的观测延迟问题。我们建议利用世界模型来处理观察延迟，该模型在整合过去的观察和学习动态方面取得了成功。通过使用世界模型将延迟的 POMDP 减少为延迟的 MDP，我们的方法可以有效地处理部分可观测性，其中现有方法实现了次优性能，甚至随着可观测性的降低而迅速退化。实验表明，我们的一种方法比基于简单模型的方法性能高出 30%。此外，我们在基于延迟环境的视觉输入上评估了我们的方法，首次展示了视觉观察上的延迟感知强化学习。]]></description>
      <guid>https://arxiv.org/abs/2403.12309</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>通过硬样本元学习提高泛化能力</title>
      <link>https://arxiv.org/abs/2403.12236</link>
      <description><![CDATA[arXiv:2403.12236v1 公告类型：新
摘要：监督学习的学习重加权（LRW）方法使用优化标准为训练实例分配权重，以便最大限度地提高代表性验证数据集的性能。我们提出并形式化了 LRW 训练中使用的验证集的优化选择问题，以提高分类器的泛化能力。特别是，我们表明，在验证集中使用难以分类的实例既具有理论联系，又具有强有力的泛化经验证据。我们提供了一种有效的算法来训练这种元优化模型，以及一种简单的两次训练启发式方法来进行仔细的比较研究。我们证明，具有简单验证数据的 LRW 的性能始终比具有硬验证数据的 LRW 差，从而确立了我们的元优化问题的有效性。我们提出的算法在一系列数据集和领域转移挑战（Imagenet-1K、CIFAR-100、Clothing-1M、CAMELYON、WILDS 等）上优于各种基线，在 Imagenet 上使用 VIT-B 时获得约 1% 的增益。我们还表明，在 Imagenet 的 LRW 训练中使用自然困难示例进行验证（Imagenet-R / Imagenet-A），可以将干净测试实例和自然困难测试实例的性能提高 1-2%。二次分析表明，在 LRW 框架中使用硬验证数据可以提高测试数据的利润率，这暗示了我们实证收益背后的机制。我们相信这项工作为监督学习环境中元学习的元优化开辟了新的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2403.12236</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>针对资源受限的物联网环境的基于 Transformer 的高效超参数优化</title>
      <link>https://arxiv.org/abs/2403.12237</link>
      <description><![CDATA[arXiv:2403.12237v1 公告类型：新
摘要：超参数优化（HPO）过程对于寻找性能最佳的卷积神经网络（CNN）至关重要。 HPO 的自动化过程的特点是计算量大且缺乏透明度；这都是资源有限的物联网 (IoT) 环境中的重要因素。在本文中，我们通过提出一种结合了 Transformer 架构和 Actor-Critic 强化学习 (RL) 模型 TRL-HPO 的新方法来解决这些问题，该方法配备了多头注意力机制，可以实现并行化和渐进式层生成。这些假设是通过在 MNIST 数据集上评估 TRL-HPO 并将其与从头开始构建 CNN 模型的最先进方法进行比较而根据经验建立的。结果表明，TRL-HPO 在相同时间范围内比这些方法的分类结果高出 6.8%，证明了 TRL-HPO 对于 HPO 过程的效率。对结果的分析确定了由于堆叠全连接层而导致性能下降的主要原因。本文确定了在资源受限环境中改进基于强化学习的 HPO 流程的新途径。]]></description>
      <guid>https://arxiv.org/abs/2403.12237</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>随机舍入隐式正则化又高又薄的矩阵</title>
      <link>https://arxiv.org/abs/2403.12278</link>
      <description><![CDATA[arXiv:2403.12278v1 公告类型：新
摘要：受机器学习和大规模深度神经网络模型训练中随机舍入的流行的推动，我们考虑行数多于列数的真实矩阵 $\mathbf{A}$ 的随机邻近舍入。我们提供了新颖的理论证据，并得到广泛的实验评估的支持，即随机舍入矩阵的最小奇异值很有可能远离零——无论 $\mathbf{A}$ 有多接近秩亏即使 $\mathbf{A}$ 是秩不足的。换句话说，随机舍入 \textit{隐式正则化} 高而瘦的矩阵 $\mathbf{A}$ ，以便舍入版本具有完整的列秩。我们的证明利用了随机矩阵理论的强大结果，以及随机舍入误差不集中在低维列空间中的想法。]]></description>
      <guid>https://arxiv.org/abs/2403.12278</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>PETScML：用于科学机器学习中训练回归问题的二阶求解器</title>
      <link>https://arxiv.org/abs/2403.12188</link>
      <description><![CDATA[arXiv:2403.12188v1 公告类型：新
摘要：近年来，我们见证了科学机器学习作为一种数据驱动工具的出现，它通过深度学习技术来分析计算科学和工程应用产生的数据。这些方法的核心是用于学习神经网络实现的监督训练算法，这是一个通常使用随机梯度方法解决的高度非凸优化问题。然而，与深度学习实践不同，科学机器学习训练问题具有大量的平滑数据和更好的经验风险函数特征，这使得它们适合传统求解器进行无约束优化。我们引入了一个构建在可移植和可扩展科学计算工具包之上的轻量级软件框架，以弥合深度学习软件和传统求解器之间的差距，以实现无约束最小化。我们凭经验证明，在学习各种科学机器学习技术和测试用例的代理模型时，基于 Hessian 高斯-牛顿近似的信任域方法在改善回归任务产生的泛化误差方面具有卓越的功效。所有测试的传统二阶求解器，包括 L-BFGS 和带线搜索的不精确牛顿求解器，无论是在成本还是精度方面，都与用于验证代理模型的自适应一阶方法相比具有优势。]]></description>
      <guid>https://arxiv.org/abs/2403.12188</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 FloodCast 进行大规模洪水建模和预测</title>
      <link>https://arxiv.org/abs/2403.12226</link>
      <description><![CDATA[arXiv:2403.12226v1 公告类型：新
摘要： 大型水动力模型通常依赖于固定分辨率的空间网格和模型参数，计算成本较高。这限制了他们准确预测洪峰和发布时间紧迫的危险警报的能力。在这项工作中，我们建立了一个快速、稳定、准确、分辨率不变、几何自适应的洪水建模和预测框架，可以大规模执行，即FloodCast。该框架包括两个主要模块：多卫星观测和水动力建模。在多星观测模块中，提出了一种实时无监督变化检测方法和降雨处理分析工具，以充分发挥多星观测在大规模洪水预报中的潜力。在流体动力学建模模块中，引入了几何自适应物理通知神经求解器（GeoPINS），受益于物理通知神经网络中不需要训练数据，并具有快速、准确和分辨率不变的架构傅里叶神经算子。 GeoPINS 在常规和不规则域的流行偏微分方程上展示了令人印象深刻的性能。在 GeoPINS 的基础上，我们提出了一种序列到序列的 GeoPINS 模型来处理大规模洪水建模中的长期时间序列和广泛的空间域。接下来，我们建立 2022 年巴基斯坦洪水的基准数据集来评估各种洪水预测方法。最后，我们从三个维度验证了模型——洪水淹没范围、深度和时空降尺度的可传递性。传统的水动力和序列到序列的 GeoPINS 在高水位期间表现出异常的一致性，而与基于 SAR 的洪水深度数据的比较评估表明，序列到序列的 GeoPINS 优于传统的水动力，且预测误差更小。]]></description>
      <guid>https://arxiv.org/abs/2403.12226</guid>
      <pubDate>Wed, 20 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>用于学习神经网络等变表示的图神经网络</title>
      <link>https://arxiv.org/abs/2403.12143</link>
      <description><![CDATA[arXiv:2403.12143v1 公告类型：新
摘要：处理其他神经网络参数的神经网络在多种领域都有应用，例如分类隐式神经表示、生成神经网络权重和预测泛化误差。然而，现有的方法要么忽略了神经网络中固有的排列对称性，要么依赖复杂的权重共享模式来实现等变，而忽略了网络架构本身的影响。在这项工作中，我们建议将神经网络表示为参数的计算图，这使我们能够利用强大的图神经网络和保持排列对称性的变压器。因此，我们的方法使单个模型能够编码具有不同架构的神经计算图。我们展示了我们的方法在各种任务上的有效性，包括隐式神经表示的分类和编辑、预测泛化性能以及学习优化，同时始终优于最先进的方法。源代码在 https://github.com/mkofinas/neural-graphs 上开源。]]></description>
      <guid>https://arxiv.org/abs/2403.12143</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>少数人的力量：通过核心集选择加速和增强数据重新加权</title>
      <link>https://arxiv.org/abs/2403.12166</link>
      <description><![CDATA[arXiv:2403.12166v1 公告类型：新
摘要：随着机器学习任务的不断发展，收集更大的数据集并训练越来越大的模型已成为趋势。虽然这提高了准确性，但也将计算成本提升到了不可持续的水平。为了解决这个问题，我们的工作旨在在计算效率和模型准确性之间取得微妙的平衡，这是该领域持续存在的挑战。我们引入了一种新颖的方法，该方法采用核心子集选择来重新加权，有效地优化计算时间和模型性能。通过专注于战略选择的核心集，我们的方法提供了强大的代表性，因为它有效地最小化了异常值的影响。然后重新校准的权重被映射回并传播到整个数据集。我们的实验结果证实了这种方法的有效性，强调了其作为可扩展且精确的模型训练解决方案的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.12166</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>GCAM：食品细粒度识别的高斯和因果注意力模型</title>
      <link>https://arxiv.org/abs/2403.12109</link>
      <description><![CDATA[arXiv:2403.12109v1 公告类型：新
摘要：目前，大多数食物识别都依赖深度学习进行类别分类。然而，这些方法很难有效区分视觉上相似的食品样本，这凸显了解决食品识别中细粒度问题的迫切需要。为了缓解这些挑战，我们建议采用高斯和因果注意力模型进行细粒度对象识别。特别是，我们训练以获得目标区域的高斯特征，然后从对象中提取细粒度特征，从而增强目标区域的特征映射能力。为了抵消数据分布不均匀导致的数据漂移，我们采用反事实推理方法。通过使用反事实干预，我们分析了学习到的图像注意力机制对网络预测的影响，使网络能够获得更有用的注意力权重以进行细粒度图像识别。最后，我们设计了一种可学习的损失策略来平衡各个模块之间的训练稳定性，最终提高最终目标识别的准确性。我们在四个相关数据集上验证了我们的方法，展示了其在这四个数据集上的出色性能。我们通过实验表明，GCAM 在 ETH-FOOD101、UECFOOD256 和 Vireo-FOOD172 数据集上超越了最先进的方法。此外，我们的方法还在 CUB-200 数据集上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.12109</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:58 GMT</pubDate>
    </item>
    </channel>
</rss>