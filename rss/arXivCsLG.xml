<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 21 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>打开黑匣子：利用重构熵预测深度神经网络的可训练性</title>
      <link>https://arxiv.org/abs/2406.12916</link>
      <description><![CDATA[arXiv:2406.12916v1 公告类型：新
摘要：机器学习中的一个重要挑战是预测给定神经网络可训练的初始条件。我们提出了一种预测深度前馈神经网络参数空间中可训练状态的方法，该方法基于通过单层辅助网络级联重建后续激活层的输入。对于 MNIST 和 CIFAR10，我们表明浅级联网络的单次训练足以预测深度前馈网络的可训练性，从而显著减少总体训练时间。我们通过计算重建图像和原始输入之间的相对熵来实现这一点，并表明这种信息丢失探测对网络的相位行为很敏感。我们的结果提供了信息流和深度神经网络可训练性之间的具体联系，进一步阐明了临界性在这些系统中的作用。]]></description>
      <guid>https://arxiv.org/abs/2406.12916</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>脑启发尖峰回波状态网络动力学用于航空发动机智能故障预测</title>
      <link>https://arxiv.org/abs/2406.12918</link>
      <description><![CDATA[arXiv:2406.12918v1 公告类型：new 
摘要：航空发动机故障预测旨在准确预测航空发动机未来状态的发展趋势，从而提前诊断故障。传统的航空发动机参数预测方法主要利用时间序列数据的非线性映射关系，但一般忽略了航空发动机数据中蕴含的充分的时空特征。为此，提出了一种受大脑启发的尖峰回声状态网络（Spike-ESN）航空发动机智能故障预测模型，用于在时空动力学框架下有效捕捉航空发动机时间序列数据的演化过程。在所提出的方法中，我们受生物神经元的尖峰神经编码机制启发，设计了一个基于泊松分布的尖峰输入层，该层可以提取航空发动机序列数据中有用的时间特征。然后，通过当前神经元中尖峰积累的计算方法将时间特征输入到尖峰储存器中，将数据投影到高维稀疏空间中。此外，利用岭回归方法读出脉冲储层的内部状态，最后通过航空发动机状态预测的实验结果证明了所提方法的优越性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.12918</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>潜在数据差异在预测系统退化中的重要性</title>
      <link>https://arxiv.org/abs/2406.12914</link>
      <description><![CDATA[arXiv:2406.12914v1 公告类型：新
摘要：基于条件的维护对于尽早发现工程系统中的潜在故障至关重要，其中准确预测剩余使用寿命对于有效的维护和操作至关重要。然而，该领域的主要重点是使用未处理或最低限度处理的数据来预测剩余使用寿命，经常忽略数据集中固有的复杂动态。在这项工作中，我们引入了一种基于系统组件潜在数据统计相似性的分析的新方法。利用基于矢量量化变分自动编码器的专门设计的架构，我们创建了一系列离散向量，用于估计特定于系统的先验。我们通过评估这些先验的差异来推断系统之间的相似性，从而提供对单个系统行为的细致入微的理解。我们的方法的有效性通过对 NASA 商用模块化航空推进系统模拟 (C-MAPSS) 数据集的实验得到证明。我们的验证不仅强调了我们的方法在推动潜在统计分歧研究方面的潜力，而且还证明了其相对于现有技术的优越性。]]></description>
      <guid>https://arxiv.org/abs/2406.12914</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>GROD：通过分布外检测增强 Transformer 的通用性</title>
      <link>https://arxiv.org/abs/2406.12915</link>
      <description><![CDATA[arXiv:2406.12915v1 公告类型：新 
摘要：Transformer 网络在自然语言处理 (NLP) 和计算机视觉 (CV) 任务中表现出色。然而，它们在推广到分布外 (OOD) 数据集方面面临挑战，即分布与训练期间看到的分布不同的数据。OOD 检测旨在区分偏离预期分布的数据，同时保持分布内 (ID) 数据的最佳性能。本文介绍了一种基于 OOD 检测的新方法，称为生成舍入 OOD 数据 (GROD) 算法，该方法显着增强了 Transformer 网络在各种任务中的泛化性能。GROD 的动机是我们针对 Transformer 的新 OOD 检测可能近似正确 (PAC) 理论。Transformer 在 OOD 检测方面具有可学习性，也就是说，当数据充足时，异常值可以得到很好的表示。通过在损失函数中惩罚 OOD 数据的错误分类并生成合成异常值，GROD 保证了可学习性并细化了正常值和异常值之间的决策边界。该策略展示了跨不同数据类型的强大适应性和普遍适用性。在 NLP 和 CV 中的各种 OOD 检测任务中进行评估后，无论数据格式如何，GROD 都能实现 SOTA。平均而言，它将 SOTA FPR@95 从 21.97% 降低到 0.12%，并将图像分类任务上的 AUROC 从 93.62% 提高到 99.98%，在检测语义文本异常值时将 SOTA FPR@95 提高了 12.89%，AUROC 提高了 2.27%。代码可在 https://anonymous.4open.science/r/GROD-OOD-Detection-with-transformers-B70F 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.12915</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>模拟深度学习的前景：最新进展、挑战和机遇</title>
      <link>https://arxiv.org/abs/2406.12911</link>
      <description><![CDATA[arXiv:2406.12911v1 公告类型：新
摘要：当今的人工智能 (AI) 大部分都使用人工神经网络，这是一种复杂的计算模型，旨在通过从数据中学习来识别模式和解决复杂问题。然而，在设备计算前向传播的加权和和反向传播的优化过程时，会出现一个主要瓶颈，尤其是对于深度神经网络或具有多层的网络。探索实现神经网络的不同方法对于该领域的进一步发展是必要的。虽然在模拟和数字实现两个方向的人工智能硬件方面存在大量研究，但现有的许多调查工作缺乏对模拟深度学习进展的讨论。为此，我们试图评估和指定模拟实现的优缺点以及深度学习的当前进展。在本文中，我们的重点是对八种不同的模拟深度学习方法在多个关键参数上的全面检查。这些参数包括达到的准确度水平、应用领域、算法进步、计算速度以及对能效和功耗的考虑。我们还确定了使用这些硬件设备实施的基于神经网络的实验，并讨论了不同模拟深度学习方法所实现的比较性能以及对它们当前局限性的分析。总体而言，我们发现模拟深度学习在未来的消费级应用方面具有巨大潜力，但在可扩展性方面还有很长的路要走。大多数当前实现更多的是概念验证，尚未实际部署到大规模模型中。]]></description>
      <guid>https://arxiv.org/abs/2406.12911</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>T-JEPA：用于轨迹相似度计算的联合嵌入预测架构</title>
      <link>https://arxiv.org/abs/2406.12913</link>
      <description><![CDATA[arXiv:2406.12913v1 公告类型：新
摘要：轨迹相似度计算是分析交通管理、野生动物追踪和基于位置的服务等各种应用中空间数据移动模式的重要技术。现代方法通常应用深度学习技术来近似启发式指标，但难以从大量未标记的轨迹数据中学习更稳健、更通用的表示。最近的方法侧重于自监督学习方法，例如对比学习，这些方法在轨迹表示学习方面取得了重大进展。然而，基于对比学习的方法严重依赖于手动预定义的数据增强方案，限制了生成的轨迹的多样性，并导致从二维欧几里得空间中的这种变化中学习，从而无法捕获高级语义变化。为了解决这些限制，我们提出了 T-JEPA，这是一种自监督轨迹相似度计算方法，采用联合嵌入预测架构 (JEPA) 来增强轨迹表示学习。 T-JEPA 在表示空间中对轨迹信息进行采样和预测，使模型无需依赖领域知识或人工干预，即可推断出高级语义中缺失的轨迹成分。在三个城市轨迹数据集和两个 Foursquare 数据集上进行的大量实验证明了 T-JEPA 在轨迹相似度计算中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.12913</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>原子材料建模图形基础模型的可扩展训练：HydraGNN 案例研究</title>
      <link>https://arxiv.org/abs/2406.12909</link>
      <description><![CDATA[arXiv:2406.12909v1 公告类型：新
摘要：我们介绍了使用多头图卷积神经网络架构 HydraGNN 开发和训练可扩展图基础模型 (GFM) 的工作。HydraGNN 在训练规模和数据多样性方面扩展了图神经网络 (GNN) 的边界。它抽象了消息传递算法，允许在定义 GNN 卷积的算法创新之间进行复制和比较。这项工作讨论了一系列优化，这些优化允许将 GFM 训练扩展到数以亿计的图组成的数据集上的数万个 GPU。我们的 GFM 使用多任务学习 (MTL) 同时学习原子结构的图级和节点级属性，例如总能量和原子力。我们使用超过 1.5 亿个原子结构进行训练，说明了我们方法的性能以及在美国能源部 (US-DOE) 的两台超级计算机上获得的经验教训，即国家能源研究科学计算中心的 Perlmutter 千万亿次级系统和橡树岭国家实验室的 Frontier 百亿亿次级系统。HydraGNN 架构使 GFM 能够使用 Perlmutter 上的 2,000 多个 GPU 和 Frontier 上的 16,000 多个 GPU 实现近乎线性的强大扩展性能。在 Frontier 上的 64,000 多个 GPU 上执行了超参数优化 (HPO)，以高精度选择 GFM 架构。在每个 GFM 架构上都应用了早期停止，以在执行这种极端规模任务时提高能源意识。对排名最高的 GFM 架构集合的训练持续到收敛，以通过集成学习建立不确定性量化 (UQ) 能力。我们的贡献为使用大规​​模计算资源快速开发、训练和部署 GFM 打开了大门，从而实现 AI 加速的材料发现和设计。]]></description>
      <guid>https://arxiv.org/abs/2406.12909</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>分子基因进化驱动的人类水平分子优化</title>
      <link>https://arxiv.org/abs/2406.12910</link>
      <description><![CDATA[arXiv:2406.12910v1 公告类型：新
摘要：从头分子生成允许在广阔的化学空间中搜索更多类似药物的命中。然而，仍然需要先导优化，优化分子结构的过程面临着平衡结构新颖性和药理特性的挑战。本研究介绍了深度遗传分子修饰算法 (DGMM)，将结构修饰提升到药物化学家的水平。DGMM 使用离散变分自动编码器 (D-VAE) 将分子编码为量化代码 mol-gene，它将深度学习融入遗传算法中，实现灵活的结构优化。mol-gene 允许发现药理学相似但结构不同的化合物，并揭示药物发现中结构优化的权衡。我们在几个应用中证明了 DGMM 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.12910</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>调和卡普兰和钦奇利亚缩放定律</title>
      <link>https://arxiv.org/abs/2406.12907</link>
      <description><![CDATA[arXiv:2406.12907v1 公告类型：新
摘要：Kaplan 等人 [2020]（“Kaplan”）和 Hoffmann 等人 [2022]（“Chinchilla”）研究了在下一个标记语言预测上训练的 Transformer 的缩放行为。这些研究对如何设置参数数量（N$）和训练标记（D$）以在给定的计算预算（C$）下实现尽可能低的损失产生了不同的估计。Kaplan：$N_\text{optimal} \propto C^{0.73}$，Chinchilla：$N_\text{optimal} \propto C^{0.50}$。本文发现，这种差异很大程度上可以归因于 Kaplan 计算非嵌入参数而不是总参数，并且它们的分析是在小规模上进行的。在这些条件下模拟 Chinchilla 研究会产生接近 Kaplan 的偏差缩放系数。因此，本文通过解释 Kaplan 最初高估的原因，重申了 Chinchilla 的缩放系数。]]></description>
      <guid>https://arxiv.org/abs/2406.12907</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>通过因果视角评估多模态时间序列预测模型 (MM-TSFM) 的稳健性</title>
      <link>https://arxiv.org/abs/2406.12908</link>
      <description><![CDATA[arXiv:2406.12908v1 公告类型：新
摘要：人工智能系统因其脆弱性而臭名昭著；微小的输入变化可能会导致输出发生重大波动。当此类系统部署在金融等关键领域时，其不确定行为的后果可能是严重的。在本文中，我们重点关注多模态时间序列预测，其中由于噪声或不正确的数据而导致的不精确性可能导致错误的预测，从而影响分析师、投资者和交易员等利益相关者。最近，已经表明，除了数字数据之外，图形转换还可以与高级视觉模型一起使用以实现更好的性能。在此背景下，我们引入了一种评级方法，通过因果分析来评估多模态时间序列预测模型 (MM-TSFM) 的稳健性，这有助于我们理解和量化各种属性对 MM-TSFM 预测准确性的孤立影响。我们将新颖的评级方法应用于大型实验设置中的各种数字和多模态预测模型（六种控制和扰动输入设置、十种数据分布、三个行业六只领先股票一年内的时间序列数据以及五个时间序列预测器），以深入了解稳健预测模型及其优势背景。在我们的研究范围内，我们的主要结果是，多模态（数字 + 视觉）预测在之前的研究中被发现比数字预测更准确，并且在不同的环境中也可以更稳健。我们的工作将帮助时间序列预测的不同利益相关者了解模型在信任（稳健性）和准确性维度上的行为，以便使用我们的评级方法选择合适的预测模型，从而改善决策。]]></description>
      <guid>https://arxiv.org/abs/2406.12908</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>Meent：用于机器学习的可微分电磁模拟器</title>
      <link>https://arxiv.org/abs/2406.12904</link>
      <description><![CDATA[arXiv:2406.12904v1 公告类型：新
摘要：电磁 (EM) 模拟在分析和设计具有亚波长尺度结构的设备（例如太阳能电池、半导体器件、图像传感器、未来显示器和集成光子设备）中起着至关重要的作用。具体而言，诸如估计半导体器件结构和设计纳米光子器件等光学问题提供了具有深远现实世界影响的有趣研究课题。此类任务的传统算法需要通过模拟迭代地细化参数，由于算法和 EM 模拟的计算成本都很高，因此通常会产生次优结果。机器学习 (ML) 成为缓解这些挑战的有希望的候选者，光学研究界越来越多地采用 ML 算法来获得超越各种任务中的传统方法的结果。为了促进光学和 ML 社区之间的协同合作，必须拥有一个对两个研究社区都友好的 EM 模拟软件。为此，我们推出了 Meent，这是一款采用严格耦合波分析 (RCWA) 的 EM 模拟软件。Meent 用 Python 开发，具有自动微分 (AD) 功能，是一个将 ML 集成到光学研究中以及将 ML 集成到光学研究中的多功能平台。为了展示其作为研究平台的实用性，我们介绍了 Meent 的三种应用：1) 生成用于训练神经算子的数据集，2) 用作纳米光子器件优化强化学习的环境，3) 为基于梯度的优化器的逆问题提供解决方案。这些应用凸显了 Meent 在推进 EM 模拟和 ML 方法方面的潜力。该代码可在 https://github.com/kc-ml2/meent 上获得，并获得了 MIT 许可，旨在促进学术研究人员和行业从业者之间的思想交流。]]></description>
      <guid>https://arxiv.org/abs/2406.12904</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:48 GMT</pubDate>
    </item>
    <item>
      <title>PufferLib：让强化学习库和环境发挥更好的作用</title>
      <link>https://arxiv.org/abs/2406.12905</link>
      <description><![CDATA[arXiv:2406.12905v1 公告类型：新
摘要：您有一个环境、一个模型和一个强化学习库，它们被设计为协同工作，但实际上却不能协同工作。PufferLib 让它们发挥出良好的作用。该库提供了一行环境包装器，可消除常见的兼容性问题，并可快速矢量化以加速训练。借助 PufferLib，您可以使用熟悉的库（如 CleanRL 和 SB3）从 Atari 和 Procgen 等经典基准扩展到 NetHack 和 Neural MMO 等复杂模拟器。我们发布了 pip 包和预构建映像，其中包含数十种环境的依赖项。我们所有的代码都是 MIT 许可下的免费开源软件，并在 pufferai.github.io 上提供完整的基线、文档和支持。]]></description>
      <guid>https://arxiv.org/abs/2406.12905</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:48 GMT</pubDate>
    </item>
    <item>
      <title>使用边缘计算硬件控制混沌</title>
      <link>https://arxiv.org/abs/2406.12876</link>
      <description><![CDATA[arXiv:2406.12876v1 公告类型：新
摘要：机器学习提供了一种数据驱动的方法来创建系统的数字孪生——一种用于预测系统行为的数字模型。拥有准确的数字孪生可以推动许多应用，例如控制自主系统。通常，数字孪生或相关控制器的尺寸、重量和功耗必须最小化，理想情况下，在无需云计算连接即可运行的嵌入式计算硬件上实现。在这里，我们展示了基于下一代储层计算的非线性控制器可以解决一个困难的控制问题：将混沌系统控制为任意时间相关状态。该模型是准确的，但它足够小，可以在嵌入式设备中常见的现场可编程门阵列上进行评估。此外，即使没有系统功率优化，该模型每次评估仅需要 25.0 $\pm$ 7.0 nJ，远低于其他算法。我们的工作代表了将高效机器学习算法部署到计算“边缘”的第一步。]]></description>
      <guid>https://arxiv.org/abs/2406.12876</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>推进基于组织病理学的乳腺癌诊断：深入了解多模态性和可解释性</title>
      <link>https://arxiv.org/abs/2406.12897</link>
      <description><![CDATA[arXiv:2406.12897v1 公告类型：新
摘要：必须准确及时地检测乳腺癌以改善患者的治疗效果。诊断方法传统上依赖于单模态方法；然而，医学数据分析正在整合传统成像之外的各种数据源。使用多模态技术，整合图像和非图像数据，标志着乳腺癌诊断的变革性进步。本综述的目的是探索多模态技术的新兴领域，特别是组织病理学图像与非图像数据的融合。此外，可解释的人工智能 (XAI) 将用于阐明复杂算法的决策过程，强调诊断过程中可解释性的必要性。本综述利用多模态数据并强调可解释性，以提高诊断准确性、临床医生信心和患者参与度，最终促进乳腺癌更加个性化的治疗策略，同时还确定多模态和可解释性方面的研究差距，指导未来研究，并为该领域的战略方向做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2406.12897</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>AI 能在入门级 Java 作业中击败本科生吗？在 JavaBench 上对大型语言模型进行基准测试</title>
      <link>https://arxiv.org/abs/2406.12902</link>
      <description><![CDATA[arXiv:2406.12902v1 公告类型：新
摘要：代码生成基准测试（例如 HumanEval）被广泛用于评估 LLM 的能力。然而，在整合最新的 24 个基准测试后，我们注意到三个显著的不平衡。首先，编程语言不平衡。95.8% 的基准测试涉及 Python，而只有 5 个基准测试涉及 Java。其次，代码粒度不平衡。函数/语句级基准测试占基准测试的 83.3% 以上。只有极少数扩展到类/项目级别，并且都仅限于 Python。第三，缺乏高级功能。现有基准测试主要评估基本的编码技能，而忽略了高级面向对象编程 (OOP) 特性（即封装、继承和多态性）。
为了填补这些空白，我们提出了 JavaBench，这是一个项目级 Java 基准测试，可锻炼 OOP 特性。它包含四个 Java 项目，包含 106 个 Java 类中的 389 个方法。测试覆盖率高达92%，JavaBench经过282名本科生验证，平均得分（即通过率）达到90.93/100，确保了文档、代码骨架和测试的质量。为了更好地评估LLM相对于JavaBench的能力，我们引入了一个系统的评估设计，涵盖三种上下文设置和五种综合策略，两种粒度，使用三个层次的指标。通过广泛的实验，我们得到了几个有趣的发现。首先，我们注意到在项目级Java编程方面，LLM远远落后于本科生（所有学习的LLM都无法正确完成任何项目，在更宽松的评估中Pass@5的比例最多为41.17％）。其次，使用方法签名作为提示上下文可能会在项目级代码生成中达到理想的平衡。JavaBench的公开网址为https://github.com/java-bench/JavaBench。]]></description>
      <guid>https://arxiv.org/abs/2406.12902</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:47 GMT</pubDate>
    </item>
    </channel>
</rss>