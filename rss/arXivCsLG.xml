<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>差分编码用于改进图形表示学习</title>
      <link>https://arxiv.org/abs/2407.02758</link>
      <description><![CDATA[arXiv:2407.02758v1 公告类型：新
摘要：将消息传递范式与全局注意机制相结合已成为一种有效的图学习框架。消息传递范式和全局注意机制从根本上基于从节点的局部邻域或整个图聚合的信息生成节点嵌入。最基本和最常用的聚合方法是从节点的局部邻域或整个图中取信息的总和。然而，不知道主要信息是来自节点本身还是来自节点的邻居（或其余的图节点）。因此，在嵌入生成的每一层都存在信息丢失，并且当模型中使用更多层时，这种信息丢失可能会累积并变得更加严重。在本文中，我们提出了一种差分编码方法来解决信息丢失的问题。我们方法的思想是对来自节点邻居（或其余的图节点）的信息与来自节点本身的信息之间的差分表示进行编码。然后将得到的差分编码与原始的聚合局​​部或全局表示相结合，生成更新的节点嵌入。通过集成差分编码，生成的节点嵌入的表示能力得到了提高。在七个基准数据集上的不同图任务上对差分编码方法进行了实证评估。结果表明，它是一种改进消息传递更新和全局注意力更新的通用方法，提高了这些数据集上图表示学习的当前最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2407.02758</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟退火过程的深度神经网络输出范围分析</title>
      <link>https://arxiv.org/abs/2407.02700</link>
      <description><![CDATA[arXiv:2407.02700v1 公告类型：新
摘要：本文解决了深度神经网络 (DNN) 输出范围估计​​的难题，介绍了一种基于模拟退火 (SA) 的新算法。我们的方法解决了 DNN 中局部几何信息缺乏和高度非线性的问题，使其适用于各种架构，尤其是残差神经网络 (ResNets)。我们提出了一种简单、易于实现的算法，避免了对网络架构的限制性假设。通过理论分析和实验评估，包括对 Ackley 函数的测试，我们证明了我们的算法在导航复杂、非凸表面和准确估计 DNN 输出范围方面的有效性。此外，支持我们结果的此实验评估的 Python 代码可在我们的 GitHub 存储库 (https://github.com/Nicerova7/output-range-analysis-for-deep-neural-networks-with-simulated-annealing) 中找到。]]></description>
      <guid>https://arxiv.org/abs/2407.02700</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>相互学习中贝叶斯神经网络的模型和特征多样性</title>
      <link>https://arxiv.org/abs/2407.02721</link>
      <description><![CDATA[arXiv:2407.02721v1 公告类型：新
摘要：贝叶斯神经网络 (BNN) 为模型参数提供概率分布，从而实现预测中的不确定性量化。然而，与确定性神经网络相比，它们的表现往往不佳。利用相互学习可以有效提高对等 BNN 的性能。在本文中，我们提出了一种通过深度相互学习来提高 BNN 性能的新方法。所提出的方法旨在增加网络参数分布和特征分布的多样性，促进对等网络获得捕捉输入不同特征的不同特征，从而提高相互学习的有效性。实验结果表明，与传统的 BNN 相互学习相比，分类准确率、负对数似然和预期校准误差均有显著改善。]]></description>
      <guid>https://arxiv.org/abs/2407.02721</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>曲率线索：利用输入损失曲率解码深度学习隐私</title>
      <link>https://arxiv.org/abs/2407.02747</link>
      <description><![CDATA[arXiv:2407.02747v1 公告类型：新
摘要：在本文中，我们探讨了深度神经网络中损失曲率相对于输入数据的属性。损失相对于输入的曲率（称为输入损失曲率）是损失相对于输入的 Hessian 的轨迹。我们研究了输入损失曲率在训练集和测试集之间的变化情况，以及它对训练测试可区分性的影响。我们开发了一个理论框架，该框架根据隐私和训练集的大小推导出训练测试可区分性的上限。这一新颖的见解推动了利用输入损失曲率的新型黑盒成员推理攻击的发展。我们通过计算机视觉分类任务中的实验验证了我们的理论发现，表明输入损失曲率在成员推理有效性方面优于现有方法。我们的分析强调了成员推理攻击 (MIA) 方法的性能如何随训练集的大小而变化，表明基于曲率的 MIA 在足够大的数据集上优于其他方法。真实数据集通常满足此条件，我们在 CIFAR10、CIFAR100 和 ImageNet 上的结果证明了这一点。这些发现不仅增进了我们对深度神经网络行为的理解，还提高了测试机器学习中隐私保护技术的能力。]]></description>
      <guid>https://arxiv.org/abs/2407.02747</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>没有训练，没有问题：重新思考无分类器指导的扩散模型</title>
      <link>https://arxiv.org/abs/2407.02687</link>
      <description><![CDATA[arXiv:2407.02687v1 公告类型：新
摘要：无分类器指导 (CFG) 已成为提高条件扩散模型质量的标准方法。但是，使用 CFG 需要在主扩散模型旁边训练无条件模型，或者通过定期插入空条件来修改训练过程。CFG 也没有明确的扩展到无条件模型。在本文中，我们重新审视 CFG 的核心原则，并介绍一种新方法，即独立条件指导 (ICG)，它提供了 CFG 的好处，而无需任何特殊的训练程序。我们的方法简化了条件扩散模型的训练过程，也可以在任何预先训练的条件模型上进行推理时应用。此外，通过利用所有扩散网络中编码的时间步长信息，我们提出了 CFG 的扩展，称为时间步长指导 (TSG)，它可以应用于任何扩散模型，包括无条件模型。我们的指导技术易于实施，并且具有与 CFG 相同的采样成本。通过大量实验，我们证明了 ICG 在各种条件扩散模型中的表现与标准 CFG 相当。此外，我们还表明 TSG 以与 CFG 类似的方式提高了生成质量，而无需依赖任何条件信息。]]></description>
      <guid>https://arxiv.org/abs/2407.02687</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>加速分布式优化：局部步骤的原始对偶视角</title>
      <link>https://arxiv.org/abs/2407.02689</link>
      <description><![CDATA[arXiv:2407.02689v1 公告类型：新
摘要：在分布式机器学习中，跨具有不同数据分布的多个代理进行有效训练带来了重大挑战。即使使用集中式协调器，当前实现最佳通信复杂度的算法通常也需要大批量或在梯度复杂度上做出妥协。在这项工作中，我们解决了强凸、凸和非凸目标的集中式和分散式设置。我们首先证明，应用于分布式优化的拉格朗日的基本原始对偶方法（加速）梯度上升多重随机梯度下降（GA-MSGD）固有地结合了局部更新，因为在原始变量上运行随机梯度下降的内部循环不需要代理间通信。值得注意的是，对于强凸目标，我们表明（加速）GA-MSGD 在通信轮次中实现了线性收敛，尽管拉格朗日在对偶变量中仅是线性的。这是由于独特的结构特性，其中对偶变量被限制在耦合矩阵的跨度内，从而使对偶问题具有强烈的凹性。当与 Catalyst 框架集成时，我们的方法可以在各种设置中实现近乎最佳的通信复杂度，而无需使用小批量。此外，在随机分散问题中，它实现了与确定性设置相当的通信复杂度，比现有算法有所改进。]]></description>
      <guid>https://arxiv.org/abs/2407.02689</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>LLM-Select：使用大型语言模型进行特征选择</title>
      <link>https://arxiv.org/abs/2407.02694</link>
      <description><![CDATA[arXiv:2407.02694v1 公告类型：新
摘要：在本文中，我们展示了大型语言模型 (LLM) 的惊人能力：仅给定输入特征名称和预测任务的描述，它们就能够选择最具预测性的特征，其性能可与数据科学的标准工具相媲美。值得注意的是，这些模型在各种查询机制中都表现出这种能力。例如，我们零样本提示 LLM 输出特征（例如“血压”）在预测感兴趣的结果（例如“心力衰竭”）时的数值重要性分数，而无需其他背景信息。特别是，我们发现最新的模型（例如 GPT-4）可以始终如一地识别最具预测性的特征，无论查询机制如何，也无论使用何种提示策略。我们通过对真实数据进行大量实验来说明这些发现，我们表明基于 LLM 的特征选择始终如一地实现了与 LASSO 等数据驱动方法相媲美的强大性能，尽管从未查看过下游训练数据。我们的研究结果表明，LLM 不仅有助于选择最佳训练特征，还有助于决定首先收集哪些特征。这可能会让医疗保健等领域的从业者受益，因为在这些领域，收集高质量数据的成本很高。]]></description>
      <guid>https://arxiv.org/abs/2407.02694</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>考虑稀疏性的大规模分层工业需求时间序列预测</title>
      <link>https://arxiv.org/abs/2407.02657</link>
      <description><![CDATA[arXiv:2407.02657v1 公告类型：新
摘要：分层时间序列预测 (HTSF) 是许多现实世界商业应用的一个重要问题，其目标是同时预测通过层次关系相互关联的多个时间序列。然而，最近的研究并没有解决大公司许多需求预测应用中通常观察到的两个重要挑战。首先，层次结构较低级别的许多时间序列具有高稀疏性，即它们具有大量零。大多数 HTSF 方法都没有解决层次结构中这种变化的稀疏性。此外，它们不能很好地扩展到现实世界层次结构的大尺寸，这在文献中使用的基准中通常是看不到的。我们通过提出 HAILS 来解决这两个挑战，HAILS 是一种新颖的概率分层模型，它通过自适应地对具有不同分布假设的稀疏和密集时间序列进行建模并协调它们以遵守分层约束，从而实现整个层次结构中准确且经过校准的概率预测。我们通过根据现实世界的需求预测数据集对我们方法的评估来展示方法的可扩展性和有效性。我们在一家大型化学制造公司部署了 HAILS，用于包含一万多种产品的产品需求预测应用程序，并观察到预测准确度显著提高了 8.5%，稀疏时间序列提高了 23%。增强的准确性和可扩展性使 HAILS 成为改进业务规划和客户体验的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2407.02657</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>统一变换：改进变分自动编码器中的潜在表征</title>
      <link>https://arxiv.org/abs/2407.02681</link>
      <description><![CDATA[arXiv:2407.02681v1 公告类型：新
摘要：潜在空间中的不规则分布会导致变分自动编码器 (VAE) 中的后验崩溃、后验和先验之间的错位以及不良采样问题。在本文中，我们引入了一种新颖的自适应三阶段均匀变换 (UT) 模块——高斯核密度估计 (G-KDE) 聚类、非参数高斯混合 (GM) 建模和概率积分变换 (PIT)——以解决不规则的潜在分布。通过将不规则分布重新配置为潜在空间中的均匀分布，我们的方法显着增强了潜在表示的解缠和可解释性，克服了传统 VAE 模型在捕获复杂数据结构方面的局限性。实证评估证明了我们提出的 UT 模块在改进基准数据集（dSprites 和 MNIST）中的解缠指标方面的有效性。我们的研究结果为推进表示学习技术指明了有希望的方向，对未来将该框架扩展到更复杂的数据集和下游任务的研究具有指导意义。]]></description>
      <guid>https://arxiv.org/abs/2407.02681</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>面向 8 位浮点设备上训练和通信的联邦学习</title>
      <link>https://arxiv.org/abs/2407.02610</link>
      <description><![CDATA[arXiv:2407.02610v1 公告类型：新
摘要：最近的研究表明，与 FP32/FP16 中的训练相比，8 位浮点 (FP8) 可用于高效训练神经网络，同时减少计算开销。在这项工作中，我们研究了在联邦学习环境中使用 FP8 训练。这不仅带来了 FP8 通常的优势，这对于边缘设备上的训练是理想的，而且还由于显着的权重压缩而降低了客户端-服务器通信成本。我们提出了一种结合 FP8 客户端训练的新方法，同时保持全局 FP32 服务器模型并提供收敛分析。对各种机器学习模型和数据集的实验表明，与 FP32 基线相比，我们的方法在各种任务和模型中始终将通信减少至少 2.9 倍。]]></description>
      <guid>https://arxiv.org/abs/2407.02610</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>学习图形结构和不确定性，实现准确且校准的时间序列预测</title>
      <link>https://arxiv.org/abs/2407.02641</link>
      <description><![CDATA[arXiv:2407.02641v1 公告类型：新
摘要：多变量时间序列预测是一个具有广泛应用的重要问题。最近的研究将时间序列之间的关系建模为图形，并表明在关系图上传播信息可以改善时间序列预测。然而，在许多情况下，关系信息不可用或嘈杂且可靠。此外，大多数研究都忽略了时间序列的潜在不确定性，无论是结构学习还是推导预测，导致结构无法捕捉不确定性，从而导致预测分布具有较差的不确定性估计。我们应对这一挑战并引入 STOIC，它利用时间序列之间的随机相关性来学习时间序列之间的潜在结构并提供经过良好校准和准确的预测。在广泛的基准数据集上，STOIC 提供了大约 16% 更准确和 14% 更校准的预测。
STOIC 还表现出在推理过程中对数据噪声的更好适应性，并在各种基准测试中捕获重要且有用的关系信息。]]></description>
      <guid>https://arxiv.org/abs/2407.02641</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>表格数据归纳和合成数据生成的扩散模型</title>
      <link>https://arxiv.org/abs/2407.02549</link>
      <description><![CDATA[arXiv:2407.02549v1 公告类型：新
摘要：数据插补和数据生成在许多领域都有重要的应用，例如医疗保健和金融，其中不完整或缺失的数据会妨碍准确的分析和决策。扩散模型已经成为强大的生成模型，能够捕获各种数据模式（例如图像、音频和时间序列数据）中的复杂数据分布。最近，它们也被改编为生成表格数据。在本文中，我们提出了一种表格数据的扩散模型，该模型引入了三个关键增强功能：（1）条件注意机制，（2）编码器-解码器变压器作为去噪网络，以及（3）动态掩蔽。条件注意机制旨在提高模型捕捉条件和合成数据之间关系的能力。变压器层有助于模拟条件（编码器）或合成数据（解码器）内的交互，而动态掩蔽使我们的模型能够在统一框架内有效地处理缺失数据插补和合成数据生成任务。我们通过在基准数据集上将具有变压器条件的扩散模型的性能与最先进的技术（例如变分自动编码器、生成对抗网络和扩散模型）进行比较来进行全面评估。我们的评估侧重于根据三个重要标准对生成的样本进行评估，即：（1）机器学习效率，（2）统计相似性和（3）隐私风险缓解。对于数据插补任务，我们考虑了生成样本在不同缺失特征水平上的效率。]]></description>
      <guid>https://arxiv.org/abs/2407.02549</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>带强盗反馈的线性子模最大化</title>
      <link>https://arxiv.org/abs/2407.02601</link>
      <description><![CDATA[arXiv:2407.02601v1 公告类型：新
摘要：最近在各种情况下研究了具有强盗反馈的子模块优化。在许多实际应用中，例如多样化的推荐系统和数据摘要，子模块函数表现出额外的线性结构。我们考虑开发近似算法来最大化子模块目标函数 $f:2^U\to\mathbb{R}_{\geq 0}$，其中 $f=\sum_{i=1}^dw_iF_{i}$。假设我们可以通过值预言机访问函数 $F_i$，但系数 $w_i$ 未知，并且只能通过嘈杂查询访问 $f$。我们为这种设置开发了算法，其灵感来自线性老虎机最佳臂识别中的自适应分配算法，近似保证任意接近我们可以通过值预言机访问 $f$ 的设置。最后，我们通过经验证明，与不利用 $f$ 线性结构的算法相比，我们的算法在移动推荐实例中样本效率有了很大的提高。]]></description>
      <guid>https://arxiv.org/abs/2407.02601</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动的功率流线性化：理论</title>
      <link>https://arxiv.org/abs/2407.02501</link>
      <description><![CDATA[arXiv:2407.02501v1 公告类型：新
摘要：本教程分为两部分，深入探讨了数据驱动的功率流线性化 (DPFL) 领域，该领域越来越受到关注。DPFL 以其更高的近似精度、广泛的适应性和更好的隐式整合最新系统属性的能力而脱颖而出。这使得 DPFL 成为管理可再生能源大幅波动的潜在更好选择，通过将更高的模型精度转化为更高的经济效率和更少的能源损失，朝着实现更可持续的能源未来迈出了一步。为了进行深入而严格的重新审查，本教程首先将现有的 DPFL 方法分为 DPFL 训练算法和支持技术。系统地检查、讨论和总结了它们的数学模型、分析解决方案、能力、局限性和普遍性。此外，本教程还回顾了现有的 DPFL 实验，检查了测试系统的设置、数据集的保真度以及对有限数量的 DPFL 方法的比较。此外，本教程对所有现有的 DPFL 方法（共 40 种方法）和四种经典的物理驱动方法进行了广泛的数值比较，重点关注它们的通用性、适用性、准确性和计算效率。通过这些模拟方法，本教程旨在揭示所有方法的实际性能（包括暴露于数据噪声或异常值的性能），指导选择合适的线性化方法。此外，本教程根据获得的理论和数值见解讨论了未来的方向。作为第一部分，本文重新审视了 DPFL 理论，涵盖了所有训练算法和支持技术。已经确定了以前在文献中未提及的功能、局限性和通用性方面。]]></description>
      <guid>https://arxiv.org/abs/2407.02501</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>减少具有统计意义的区域共置挖矿中的错误发现：结果摘要</title>
      <link>https://arxiv.org/abs/2407.02536</link>
      <description><![CDATA[arXiv:2407.02536v1 公告类型：新
摘要：给定一个空间特征类型集合 \emph{S}、其特征实例、研究区域和邻居关系，目标是找到对 $&lt;$a 区域 ($r_{g}$)，\emph{S}$&gt;$ 的子集 \emph{C}，使得 \emph{C} 是 $r_{g}$ 中具有统计意义的区域共置模式。这个问题对于生态学、经济学和社会学等各个领域的应用都很重要。由于区域共置模式和候选区域的数量呈指数级增长，因此该问题在计算上具有挑战性。之前，我们提出了一个挖掘器 \cite{10.1145/3557989.3566158}，它可以找到具有统计意义的区域共置模式。然而，大量同时进行的统计推断会增加错误发现的风险（也称为多重比较问题），并且计算成本很高。我们提出了一种新算法，即使用 Bonferroni 校正的多重比较区域共置挖掘器 (MultComp-RCM)。理论分析、实验评估和案例研究结果表明，所提出的方法既降低了错误发现率，又降低了计算成本。]]></description>
      <guid>https://arxiv.org/abs/2407.02536</guid>
      <pubDate>Thu, 04 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    </channel>
</rss>