<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 05 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>迈向大规模脉冲神经网络：全面概述和未来方向</title>
      <link>https://arxiv.org/abs/2409.02111</link>
      <description><![CDATA[arXiv:2409.02111v1 公告类型：新 
摘要：深度学习彻底改变了人工智能 (AI)，在计算机视觉、语音识别和自然语言处理等领域取得了显着进步。此外，大型语言模型 (LLM) 的最新成功推动了对大规模神经网络的研究热潮。然而，对计算资源和能源消耗的不断增长的需求促使人们寻找节能的替代方案。受人脑的启发，脉冲神经网络 (SNN) 有望通过事件驱动的脉冲实现节能计算。为了为构建节能的大型 SNN 模型提供未来方向，我们对开发深度脉冲神经网络的现有方法进行了调查，重点关注新兴的脉冲变压器。我们的主要贡献如下：（1）深度脉冲神经网络的学习方法概述，按 ANN 到 SNN 的转换和使用代理梯度的直接训练分类； (2) 深度脉冲神经网络的网络架构概述，按深度卷积神经网络 (DCNN) 和 Transformer 架构分类；(3) 全面比较最先进的深度 SNN，重点关注新兴的 Spiking Transformer。然后，我们进一步讨论并概述了大规模 SNN 的未来发展方向。]]></description>
      <guid>https://arxiv.org/abs/2409.02111</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tiny-Toxic-Detector：一种基于变压器的紧凑型有毒物质检测模型</title>
      <link>https://arxiv.org/abs/2409.02114</link>
      <description><![CDATA[arXiv:2409.02114v1 公告类型：新
摘要：本文介绍了 Tiny-toxic-detector，这是一种基于 Transformer 的紧凑型模型，专为检测有毒内容而设计。尽管只有 210 万个参数，但 Tiny-toxic-detector 在基准数据集上实现了具有竞争力的性能，在 ToxiGen 上的准确率为 90.97%，在 Jigsaw 数据集上的准确率为 86.98%，可与其大小超过 50 倍的模型相媲美。这种效率使其能够在资源受限的环境中部署，满足了对有效内容审核工具的需求，这些工具可在性能和计算效率之间取得平衡。该模型架构具有 4 个 Transformer 编码器层，每个编码器层都有 2 个注意头，嵌入维度为 64，前馈维度为 128。Tiny-toxic-detector 在公共和私人数据集上进行了训练，展示了高效、特定于任务的模型在解决在线毒性方面的潜力。论文介绍了模型架构、训练过程、性能基准和局限性，强调了其适用于社交媒体监控和内容审核等应用。Tiny-toxic-detector 实现了与大型模型相当的结果，同时显著降低了计算需求，代表了朝着更可持续、更可扩展的 AI 驱动内容审核解决方案迈出的一步。]]></description>
      <guid>https://arxiv.org/abs/2409.02114</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TSO：基于尺度偏好优化的自我训练</title>
      <link>https://arxiv.org/abs/2409.02118</link>
      <description><![CDATA[arXiv:2409.02118v1 公告类型：新
摘要：增强大型语言模型 (LLM) 与人类偏好的一致性仍然是一项持续的研究挑战。最近，诸如直接偏好优化 (DPO) 之类的离线方法已成为有吸引力的选择，因为它们在简单、高效和稳定方面提供了有效的改进，而无需与奖励模型进行交互。然而，这些离线偏好优化方法高度依赖于成对偏好样本的质量。同时，许多迭代方法需要对奖励模型进行额外的训练，以从模型自己生成的响应中选择正样本和负样本进行偏好学习。此外，随着 LLM 功能的进步，由于缺乏多样性，从模型的输出中持续构建高质量的正负偏好实例非常具有挑战性。为了应对这些挑战，我们提出了 TSO，即具有缩放偏好优化的自我训练，这是一个偏好优化框架，它进行自我训练偏好学习而无需训练额外的奖励模型。TSO 通过构建模型矩阵并结合人类偏好响应来增强响应的多样性。此外，TSO 通过人工和 AI 反馈来纠正模型偏好错误。最后，TSO 采用迭代和双重剪辑奖励策略来更新参考模型及其响应，自适应地调整偏好数据并平衡优化过程。实验结果表明，TSO 在各种对齐评估基准上均优于现有的主流方法，为对齐领域的偏好数据构建和模型训练策略提供了实用见解。]]></description>
      <guid>https://arxiv.org/abs/2409.02118</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoRA：利用大型语言模型的公共子空间优化低秩自适应</title>
      <link>https://arxiv.org/abs/2409.02119</link>
      <description><![CDATA[arXiv:2409.02119v1 公告类型：新
摘要：在微调大型语言模型 (LLM) 时，在保持有效性的同时节省计算资源并在相同的计算约束内改善结果至关重要。低秩自适应 (LoRA) 策略通过减少可训练参数的数量和计算成本来平衡微调大型模型的效率和性能。然而，LoRA 目前的进展可能集中在其微调方法上，而对进一步压缩 LoRA 的探索并不像预期的那样多。由于 LoRA 的大多数参数可能仍然是多余的，这可能会导致不必要的计算资源浪费。在本文中，我们提出了 \textbf{CoRA}：利用共享知识优化 LoRA 训练，用大型模型的公共子空间替换其矩阵 $B$。我们的双重方法包括：（1）冻结替代矩阵 $B$ 以将参数减半，同时训练矩阵 $A$ 以完成特定任务；（2）使用替代矩阵 $B$ 作为原始矩阵 $B$ 的增强初始状态，以相同的参数获得更好的结果。我们的实验表明，第一种方法实现了与原始 LoRA 微调相同的效果，同时比将参数减半更有效。同时，第二种方法与 LoRA 原始微调性能相比有一些改进。它们普遍证明了我们工作的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.02119</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度知识注入，实现可解释的抑郁症检测</title>
      <link>https://arxiv.org/abs/2409.02122</link>
      <description><![CDATA[arXiv:2409.02122v1 公告类型：新
摘要：在社交媒体上发现个人抑郁症变得越来越重要。研究人员采用 ML/DL 或基于词典的方法进行自动抑郁症检测。基于词典的方法可解释且易于实施，无需考虑上下文即可将用户帖子中的单词与抑郁症词典进行匹配。虽然 DL 模型可以利用上下文信息，但它们的黑盒性质限制了它们在该领域的采用。虽然像 LIME 和 SHAP 这样的代理模型可以为 DL 模型提供解释，但这些解释只适合开发人员，对最终用户的用处有限。我们提出了一种知识注入神经网络 (KiNN)，将来自抑郁特征本体 (DFO) 的领域特定知识融入神经网络，使模型具有临床医生理解的概念和过程的用户级可解释性。此外，还注入了在 ATOMIC 上训练的 Commonsense Transformer (COMET) 的常识知识，以考虑抑郁症检测中用户帖子的一般情感方面。该模型在三个与抑郁症相关的专家策划的数据集上进行了评估。我们观察到，在 CLEF e-Risk 上，该模型的性能比最佳领域特定模型 MentalBERT 具有统计上显着的 (p&lt;0.1) 提升（MCC 增加 25%，F1 增加 12%）。在 PRIMATE 数据集中也观察到了类似的趋势，其中所提出的模型表现优于 MentalBERT（MCC 增加 2.5%，F1 增加 19%）。与事后模型解释相比，观察结果证实了生成的解释对 MHP 具有参考价值。结果表明，KiNN 的用户级可解释性也超越了基线模型的性能，并且可以在其他基线不足的地方提供解释。在 KiNN 中注入领域和常识知识可以增强 GPT-3.5 等模型生成与应用相关的解释的能力。]]></description>
      <guid>https://arxiv.org/abs/2409.02122</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PuYun：利用大核注意力卷积网络进行中期全球天气预报</title>
      <link>https://arxiv.org/abs/2409.02123</link>
      <description><![CDATA[arXiv:2409.02123v1 公告类型：新
摘要：准确的天气预报对于理解和减轻与天气有关的影响至关重要。在本文中，我们提出了 PuYun，这是一种利用大核注意力卷积网络的自回归级联模型。该模型的设计本质上支持扩展的天气预报范围，同时扩大了有效的接受域。卷积层内大核注意力机制的集成增强了模型捕获细粒度空间细节的能力，从而提高了其对气象现象的预测准确性。
我们介绍了 PuYun，包括用于 0-5 天预报的 PuYun-Short 和用于 5-10 天预报的 PuYun-Medium。这种方法提高了 10 天天气预报的准确性。通过评估，我们证明 PuYun-Short 本身在生成准确的 10 天预报方面的表现优于 GraphCast 和 FuXi-Short。具体来说，在第 10 天，PuYun-Short 将 Z500 的 RMSE 降低至 720 $m^2/s^2$，而 GraphCast 为 732 $m^2/s^2$，FuXi-Short 为 740 $m^2/s^2$。此外，T2M 的 RMSE 降低至 2.60 K，而 GraphCast 为 2.63 K，FuXi-Short 为 2.65 K。此外，当采用级联方法集成 PuYun-Short 和 PuYun-Medium 时，我们的方法比 FuXi-Short 和 FuXi-Medium 的组合性能取得了更好的结果。在第 10 天，Z500 的 RMSE 进一步降低至 638 $m^2/s^2$，而 FuXi 为 641 $m^2/s^2$。这些发现凸显了我们的模型组合在推进中期天气预报方面的有效性。我们的训练代码和模型将开源。]]></description>
      <guid>https://arxiv.org/abs/2409.02123</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TrajWeaver：利用状态传播扩散模型进行轨迹恢复</title>
      <link>https://arxiv.org/abs/2409.02124</link>
      <description><![CDATA[arXiv:2409.02124v1 公告类型：新
摘要：随着位置感知设备的普及，当人、车辆和货物等代理在城市环境中流动时，会产生大量轨迹。这些原始轨迹通常从汽车 GPS、个人移动设备和公共交通等各种来源收集，由于采样率有限、基础设施覆盖范围和数据丢失，这些轨迹通常稀疏且分散。在这种情况下，轨迹恢复旨在将这些稀疏的原始轨迹重建为密集且连续的轨迹，以便可以忠实地捕捉代理在空间和时间上的细粒度移动。现有的轨迹恢复方法通常依赖于对出行方式或运动模式的先验知识，并且在没有精确地图的人口密集的城市地区经常失败。在本文中，我们提出了一种基于概率扩散模型的新型恢复框架 TrajWeaver，该框架能够根据沿途的兴趣区域、用户身份和运单信息等各种辅助特征，从稀疏的原始轨迹中恢复密集且精细的轨迹。TrajWeaver 的核心是一种新颖的状态传播扩散模型 (SPDM)，它在标准扩散模型之上引入了一种新的状态传播机制，以便在早期扩散步骤中计算的知识可以在以后重复使用，从而提高恢复性能并减少所需的步骤数。大量实验表明，所提出的 TrajWeaver 可以从各种长度、稀疏程度和异构旅行模式的原始轨迹中恢复，并且在恢复精度方面明显优于最先进的基线。我们的代码可在以下网址获得：https://anonymous.4open.science/r/TrajWeaver/]]></description>
      <guid>https://arxiv.org/abs/2409.02124</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过图神经网络检测同胚 3 流形</title>
      <link>https://arxiv.org/abs/2409.02126</link>
      <description><![CDATA[arXiv:2409.02126v1 公告类型：新
摘要：受某些 3d $\mathcal{N}=2$ 超对称量子场论的 BPS 谱的枚举启发，这些 BPS 谱是从三流形上 6d 超共形场论的紧化中获得的，我们使用图神经网络技术研究了一类图流形的同胚问题。利用 JSJ 分解，从图流形中提取通过管道图的唯一表示。同胚图流形通过该图上的一系列冯·诺依曼移动相关联；这些移动的算法应用可以在超多项式时间内确定两个图是否对应于同胚图流形。然而，通过使用图神经网络 (GNN)，同样的问题可以在多项式时间内解决，但代价是准确性。我们构建了一个由多对管道图组成的数据集，以及一个隐藏标签，用于编码该对是否同态。我们在监督学习环境中训练和基准测试了各种网络架构，方法是测试两个卷积层（GEN、GCN、GAT、NNConv）的不同组合，然后是聚合层和分类层。我们讨论了不同 GNN 对于这个同态问题的优势和劣势。]]></description>
      <guid>https://arxiv.org/abs/2409.02126</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在工业物联网中实现值得信赖的联合学习：弥合可解释性与稳健性之间的差距</title>
      <link>https://arxiv.org/abs/2409.02127</link>
      <description><![CDATA[arXiv:2409.02127v1 公告类型：新
摘要：联邦学习 (FL) 代表了机器学习的范式转变，允许协作模型训练，同时保持数据本地化。这种方法在工业物联网 (IIoT) 环境中尤其适用，因为数据隐私、安全性和分布式资源的有效利用至关重要。IIoT 中 FL 的本质在于它能够从各种分布式数据源中学习，而无需中央数据存储，从而增强隐私并减少通信开销。然而，尽管 FL 具有潜力，但仍存在一些挑战阻碍其在 IIoT 中的广泛采用，特别是在确保可解释性和稳健性方面。本文重点介绍如何通过弥合可解释性和稳健性之间的差距来实现 IIoT 中值得信赖的 FL，这对于增强信任、改善决策和确保遵守法规至关重要。此外，本文总结的设计策略确保 IIoT 中的 FL 系统透明可靠，这在决策具有重大安全和经济影响的工业环境中至关重要。提供了由可信 FL 模型驱动的 IIoT 环境中的案例研究，其中强调了 IIoT 系统与其最终用户之间可信通信的实际见解。]]></description>
      <guid>https://arxiv.org/abs/2409.02127</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络模型在长期实验室动力学试验中预测酸性矿山废水的应用</title>
      <link>https://arxiv.org/abs/2409.02128</link>
      <description><![CDATA[arXiv:2409.02128v1 公告类型：新
摘要：酸性矿井排水（AMD）是煤炭开采行业常见的环境问题之一，是由覆盖层或废石中的硫化矿物氧化形成的。通过 AMD 预测酸的产生对于覆盖层管理和规划采矿后的土地使用非常重要。预测 AMD 的方法之一是实验室规模的动力学测试，使用现场代表性样品确定酸随时间形成的速率。然而，这种测试需要长时间的过程，大量的化学试剂会导致成本低下。另一方面，机器学习有潜力学习实验室规模动力学测试数据背后的模式。本研究描述了一种使用人工神经网络（ANN）建模来预测实验室规模动力学测试结果的方法。基于 83 周的实验室规模动力学测试实验，使用 100% 潜在成酸岩，使用了各种 ANN 模型。该模型用于监测 pH、ORP、电导率、TDS、硫酸盐和重金属（Fe 和 Mn）。本研究获得的训练和验证数据的整体 Nash-Sutcliffe 效率 (NSE) 为 0.99，与实际实验室规模动力学测试数据相比，具有很强的相关性和准确的预测。这表明 ANN 能够从过去的数据中学习模式、趋势和季节性，从而进行准确的预测，从而凸显其对解决 AMD 问题的重大贡献。这项研究还有望为一种预测 AMD 的新方法奠定基础，在未来的应用中具有时间效率高、准确和成本效益高的特点。]]></description>
      <guid>https://arxiv.org/abs/2409.02128</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从预测重要性到因果关系：哪种机器学习模型反映现实？</title>
      <link>https://arxiv.org/abs/2409.02130</link>
      <description><![CDATA[arXiv:2409.02130v1 公告类型：新
摘要：本研究使用 CatBoost 和 LightGBM 模型分析了 Ames Housing 数据集，以探索房价预测中的特征重要性和因果关系。我们研究了 SHAP 值与 EconML 预测之间的相关性，从而实现了价格预测的高精度。我们的分析表明，基于 SHAP 的特征重要性和因果显著特征之间的 Spearman 等级相关性为 0.48，这凸显了在住房市场分析中将预测模型与因果理解相结合的复杂性。通过广泛的因果分析，包括异质性探索和政策树解释，我们深入了解了门廊等特定特征如何影响各种情景下的房价。这项工作强调了将预测能力与房地产估值中的因果洞察力相结合的综合方法的必要性，为行业利益相关者提供了宝贵的指导。]]></description>
      <guid>https://arxiv.org/abs/2409.02130</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Edge AI：卷积神经网络模型压缩技术评估</title>
      <link>https://arxiv.org/abs/2409.02134</link>
      <description><![CDATA[arXiv:2409.02134v1 公告类型：新
摘要：这项工作使用 CIFAR-10 数据集评估了图像分类任务中 ConvNeXt 模型的压缩技术。评估了结构化剪枝、非结构化剪枝和动态量化方法，以在保持准确性的同时减小模型大小和计算复杂度。在基于云的平台和边缘设备上进行的实验评估了这些技术的性能。结果表明，模型大小显著减小，使用结构化剪枝技术可减少高达 75%。此外，动态量化可将参数数量减少高达 95%。微调模型表现出更好的压缩性能，表明预训练与压缩技术相结合的好处。非结构化剪枝方法揭示了准确性和压缩的趋势，但计算复杂度的降低有限。 OTOV3 修剪和动态量化的结合进一步增强了压缩性能，大小减少了 89.7%，参数和 MAC 数量减少了 95%，准确率提高了 3.8%。最终压缩模型在边缘设备上的部署展示了 92.5% 的高准确率和 20 毫秒的低推理时间，验证了压缩技术对实际边缘计算应用的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.02134</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度采样的并行准量子退火优化</title>
      <link>https://arxiv.org/abs/2409.02135</link>
      <description><![CDATA[arXiv:2409.02135v1 公告类型：新
摘要：基于学习的方法作为通用求解器引起了人们的关注，因为它们可以自动学习特定于问题的启发式方法，从而减少了对手工制作启发式方法的需求。然而，这些方法往往面临可扩展性的挑战。为了解决这些问题，提出了使用离散朗之万动力学的改进的组合优化采样算法 (iSCO)，其性能优于几种基于学习的求解器。本研究提出了一种不同的方法，该方法结合了通过连续松弛进行基于梯度的更新，并结合了准量子退火 (QQA)。QQA 将目标函数从简单的凸形式（半积分解占主导地位）平滑地过渡到原始目标函数（变量限制为 0 或 1）。此外，我们结合了利用 GPU 的并行运行通信，增强了探索能力并加速了收敛。数值实验表明，我们的方法是一种具有竞争力的通用求解器，在各种基准问题上实现了与 iSCO 相当的性能。值得注意的是，与 iSCO、商业求解器和专用算法相比，我们的方法在大规模实例中表现出速度和解决方案质量之间的良好平衡。]]></description>
      <guid>https://arxiv.org/abs/2409.02135</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型与传统机器学习：使用高维表格数据进行 COVID-19 死亡率预测的表现</title>
      <link>https://arxiv.org/abs/2409.02136</link>
      <description><![CDATA[arXiv:2409.02136v1 公告类型：新
摘要：背景：本研究旨在利用高维表格数据集评估和比较经典机器学习模型 (CML) 和大型语言模型 (LLM) 在预测与 COVID-19 相关的死亡率方面的表现。
材料和方法：我们分析了来自四家医院的 9,134 名 COVID-19 患者的数据。对包括 XGBoost 和随机森林 (RF) 在内的七个 CML 模型进行了训练和评估。结构化数据被八个 LLM（包括 GPT-4 和 Mistral-7b）转换为文本以进行零样本分类。此外，使用 QLoRA 方法对 Mistral-7b 进行了微调以增强其预测能力。
结果：在 CML 模型中，XGBoost 和 RF 的准确率最高，内部验证的 F1 得分为 0.87，外部验证的 F1 得分为 0.83。在 LLM 类别中，GPT-4 表现最佳，F1 得分为 0.43。微调 Mistral-7b 后，其召回率显著提高，从 1% 提高到 79%，F1 得分为 0.74，在外部验证期间保持稳定。
结论：虽然 LLM 在零样本分类中表现中等，但微调可以显著提高其有效性，可能使其更接近 CML 模型。然而，在高维表格数据任务中，CML 仍然优于 LLM。]]></description>
      <guid>https://arxiv.org/abs/2409.02136</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散模型的金融时间序列去噪器</title>
      <link>https://arxiv.org/abs/2409.02138</link>
      <description><![CDATA[arXiv:2409.02138v1 公告类型：新
摘要：金融时间序列通常表现出较低的信噪比，这对准确的数据解释和预测以及最终的决策提出了重大挑战。生成模型作为模拟和预测复杂数据模式的强大工具而受到关注，其中扩散模型是一种特别有效的方法。本文介绍了一种利用扩散模型作为金融时间序列去噪器的新方法，以提高数据的可预测性和交易性能。通过利用条件扩散模型的正向和反向过程逐步添加和消除噪声，我们从噪声输入中重建原始数据。我们的大量实验表明，基于扩散模型的去噪时间序列显着提高了下游未来回报分类任务的性能。此外，从去噪数据中得出的交易信号可以以更少的交易产生更有利可图的交易，从而最大限度地降低交易成本并提高整体交易效率。最后，我们表明，通过使用在去噪时间序列上训练的分类器，我们可以识别市场的噪声状态并获得超额回报。]]></description>
      <guid>https://arxiv.org/abs/2409.02138</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>