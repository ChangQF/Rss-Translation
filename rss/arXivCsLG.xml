<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 11 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>双路径神经网络模型构建时间域内火焰非线性热声响应</title>
      <link>https://arxiv.org/abs/2409.05885</link>
      <description><![CDATA[arXiv:2409.05885v1 公告类型：新 
摘要：传统的数值模拟方法需要大量的计算资源才能准确确定火焰对各种扰动频率和幅度的完整非线性热声响应。在本文中，我们开发了深度学习算法，可以从有限的数值模拟数据中构建全面的火焰非线性响应。为此，我们建议使用频率扫描数据类型作为训练数据集，该数据集在受限数据集内包含丰富的可学习信息。为了提高从训练数据中学习火焰非线性响应模式的精度，我们引入了双路径神经网络。该网络由时间特征路径和时间细节特征路径组成。双路径网络专门设计用于集中关注速度扰动序列的时间特性，从而产生更准确的火焰响应模式和增强的泛化能力。验证证明，即使在显著的非线性条件下，我们的方法也能准确地模拟火焰非线性响应，并且在各种测试场景中表现出强大的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2409.05885</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>支持 Simplex 的安全持续学习机</title>
      <link>https://arxiv.org/abs/2409.05898</link>
      <description><![CDATA[arXiv:2409.05898v1 公告类型：新
摘要：本文提出了 SeC-Learning Machine：针对安全关键型自主系统的基于 Simplex 的安全持续学习。SeC-learning 机器基于 Simplex 逻辑（即“使用简单性来控制复杂性”）和物理调节的深度强化学习 (Phy-DRL)。因此，SeC-learning 机器构成了 HP（高性能）-Student、HA（高保证）-Teacher 和 Coordinator。具体而言，HP-Student 是一种经过预先训练的高性能但尚未完全验证的 Phy-DRL，它在实际工厂中继续学习以调整行动策略以确保安全。相比之下，HA-Teacher 是一种任务简化、基于物理模型且经过验证的设计。作为补充，HA-Teacher 有两个任务：支持安全性和纠正不安全的学习。协调器触发 HP-Student 和 HA-Teacher 之间的交互和切换。在三个交互组件的支持下，SeC-learning 机器可以 i) 确保终身安全（即，无论 HP-Student 是否成功或收敛，在任何持续学习阶段都能保证安全），ii) 解决 Sim2Real 差距，以及 iii) 学会容忍真实工厂中的未知未知数。在推车杆系统和真实四足机器人上进行的实验展示了 SeC-learning 机器的显著特点，与基于最先进的安全 DRL 框架构建的持续学习相比，这些框架采用了解决 Sim2Real 差距的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.05898</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内存优化的 Once-For-All 网络</title>
      <link>https://arxiv.org/abs/2409.05900</link>
      <description><![CDATA[arXiv:2409.05900v1 公告类型：新 
摘要：由于资源限制不同，在不同的硬件平台上部署深度神经网络 (DNN) 具有挑战性。除了旨在使深度模型硬件友好的手工方法之外，神经架构搜索正在成为一种在不牺牲性能的情况下制作更高效 DNN 的工具箱。其中，Once-For-All (OFA) 方法提供了一种解决方案，它允许从单个超网中对性能良好的子网络进行采样——这在计算方面具有明显的优势。然而，OFA 并没有充分利用目标设备的潜在内存容量，而是专注于限制每层的最大内存使用量。这为模型的通用性留下了未开发的潜力。在本文中，我们介绍了一种内存优化的 OFA (MOOFA) 超网，旨在通过最大化不同配置中的内存使用率（例如，特征多样性）来增强资源有限设备上的 DNN 部署。经过 ImageNet 测试，我们的 MOOFA 超级网络与原始 OFA 超级网络相比，在内存利用率和模型准确性方面均有所提高。我们的代码可在 https://github.com/MaximeGirard/memory-optimized-once-for-all 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.05900</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OPAL：用于生成大型语言模型的异常值保留微尺度量化加速器</title>
      <link>https://arxiv.org/abs/2409.05902</link>
      <description><![CDATA[arXiv:2409.05902v1 公告类型：新 
摘要：为了克服大型语言模型 (LLM) 规模不断增加带来的内存大小和带宽负担，最近研究了激进的权重量化，但缺乏对量化激活的研究。在本文中，我们提出了一种硬件-软件协同设计方法，该方法为生成任务生成了一种节能的 LLM 加速器，名为 OPAL。首先，提出了一种新颖的激活量化方法，该方法利用微尺度数据格式，同时保留每个子张量块的几个异常值（例如，128 个元素中的 4 个）。其次，除了保留异常值之外，还利用混合精度，将 LLM 解码器块中敏感层的输入设置为 5 位，同时将不太敏感层的输入保持为 3 位。最后，我们介绍了 OPAL 硬件架构，该架构由用于处理异常值的 FP 单元和用于主要非异常值相关操作的矢量化 INT 乘法器组成。此外，OPAL 在 softmax 操作中使用基于 log2 的近似值，只需移位和减法即可最大限度地提高能效。因此，我们能够将能效提高 1.6~2.2 倍，并将面积减少 2.4~3.1 倍，而准确度损失几乎可以忽略不计，即困惑度增加 &lt;1。]]></description>
      <guid>https://arxiv.org/abs/2409.05902</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缩小深度布尔网络中泛化差距</title>
      <link>https://arxiv.org/abs/2409.05905</link>
      <description><![CDATA[arXiv:2409.05905v1 公告类型：新
摘要：深度神经网络的规模和复杂性快速增长，急剧增加了计算需求，对其在现实场景中的有效部署提出了挑战。由逻辑门构建的布尔网络提供了一种硬件友好的替代方案，可以实现更高效的实现。然而，它们是否能达到传统网络的性能仍不确定。本文探讨了增强深度布尔网络的策略，旨在超越传统网络。我们提出了新方法，包括逻辑跳过连接和空间保持采样，并使用广泛采用的数据集在视觉任务上对其进行验证，结果显示与现有方法相比有显著改进。我们的分析表明，深度布尔网络如何通过 1 位逻辑运算保持高性能，同时最大限度地降低计算成本。这些发现表明，布尔网络是高效、高性能深度学习模型的一个有前途的方向，具有推动硬件加速人工智能应用的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.05905</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过条件激活转向实现编程拒绝</title>
      <link>https://arxiv.org/abs/2409.05907</link>
      <description><![CDATA[arXiv:2409.05907v1 公告类型：新
摘要：LLM 已展现出卓越的能力，但精确控制其响应行为仍然具有挑战性。现有的激活控制方法会不加区分地改变 LLM 行为，限制了它们在选择性响应至关重要的环境中的实际适用性，例如内容审核或特定领域的助手。在本文中，我们提出了条件激活控制 (CAST)，它在推理过程中分析 LLM 激活模式，以根据输入上下文有选择地应用或保留激活控制。我们的方法基于以下观察：不同类别的提示会激活模型隐藏状态中的不同模式。使用 CAST，人们可以使用“如果输入是关于仇恨言论或成人内容，则拒绝”或“如果输入不是关于法律建议，则拒绝”等规则系统地控制 LLM 行为。这允许选择性地修改对特定内容的响应，同时保持对其他内容的正常响应，所有这些都不需要权重优化。我们发布了我们框架的开源实现。]]></description>
      <guid>https://arxiv.org/abs/2409.05907</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对不安分的土匪的更快 Q 学习算法</title>
      <link>https://arxiv.org/abs/2409.05908</link>
      <description><![CDATA[arXiv:2409.05908v1 公告类型：新
摘要：我们研究了多臂老虎机 (RMAB) 的 Whittle 指标学习算法。我们首先介绍 Q 学习算法及其变体——快速 Q 学习 (SQL)、广义快速 Q 学习 (GSQL) 和阶段 Q 学习 (PhaseQL)。我们还讨论了探索策略——$\epsilon$-greedy 和上置信边界 (UCB)。我们扩展了 Q 学习及其变体与 UCB 策略的研究。我们使用数值示例说明，具有 UCB 探索策略的 Q 学习具有更快的收敛速度，而具有 UCB 的 PhaseQL 具有最快的收敛速度。接下来，我们将索引学习的 Q 学习变体研究扩展到 RMAB。索引学习算法是随机近似的双时间尺度变体，在较慢的时间尺度上我们更新索引学习方案，在较快的时间尺度上我们假设固定索引值更新 Q 学习。我们研究了恒定步长双时间尺度随机近似算法。我们使用数值示例描述了我们的算法的性能。它说明了使用 UCB 的 Q 学习的索引学习比 $\epsilon$ 贪婪算法收敛速度更快。此外，PhaseQL（使用 UCB 和 $\epsilon$ 贪婪算法）比其他 Q 学习算法具有最佳收敛性。]]></description>
      <guid>https://arxiv.org/abs/2409.05908</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开发可解释的人工智能 (XAI) 模型来预测曼谷地下打桩振动</title>
      <link>https://arxiv.org/abs/2409.05918</link>
      <description><![CDATA[arXiv:2409.05918v1 公告类型：新
摘要：本研究提出了一种可解释的人工智能 (XAI) 模型，用于预测曼谷软粘土底土中的打桩振动。使用 1,018 个真实世界打桩测量的数据集开发了一个深度神经网络，涵盖了桩尺寸、锤子特性、传感器位置和振动测量轴的变化。该模型实现了 0.276 的平均绝对误差 (MAE)，优于传统经验方法和其他机器学习方法，例如 XGBoost 和 CatBoost。采用 SHapley 加法解释 (SHAP) 分析来解释模型的预测，揭示了输入特征和峰值粒子速度 (PPV) 之间的复杂关系。距离打桩位置的距离成为最有影响力的因素，其次是锤子重量和桩大小。观察到非线性关系和阈值效应，为软粘土中的振动传播提供了新的见解。开发了一款基于网络的应用程序，方便执业工程师采用，缩小了先进机器学习技术与实际工程应用之间的差距。这项研究为岩土工程领域做出了贡献，提供了一种更准确、更细致的方法来预测打桩振动，对优化施工实践和减轻城市地区的环境影响具有重要意义。该模型及其源代码是公开的，提高了岩土研究的透明度和可重复性。]]></description>
      <guid>https://arxiv.org/abs/2409.05918</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>STLLM-DF：一种用于增强多模式交通系统预测的具有扩散的时空大型语言模型</title>
      <link>https://arxiv.org/abs/2409.05921</link>
      <description><![CDATA[arXiv:2409.05921v1 公告类型：新
摘要：智能交通系统 (ITS) 的快速发展带来了挑战，特别是多式联运中缺少数据以及在集中框架内处理各种连续任务的复杂性。为了解决这些问题，我们提出了时空大型语言模型扩散 (STLLM-DF)，这是一种创新模型，利用去噪扩散概率模型 (DDPM) 和大型语言模型 (LLM) 来改进多任务交通预测。DDPM 强大的去噪功能使其能够从嘈杂的输入中恢复底层数据模式，使其在复杂的交通系统中特别有效。同时，非预训练的 LLM 可动态适应多式联运网络中的时空关系，使系统能够有效地管理长期和短期预测中的各种交通任务。大量实验表明，STLLM-DF 的表现始终优于现有模型，MAE 平均降低 2.40%，RMSE 降低 4.50%，MAPE 降低 1.51%。该模型通过提高多个任务的预测准确性、稳健性和整体系统性能，显著推进了集中式 ITS，从而为通过整合冻结的 Transformer 语言模型和扩散技术实现更有效的时空交通预测铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.05921</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SVFit：使用奇异值对大型预训练模型进行参数高效微调</title>
      <link>https://arxiv.org/abs/2409.05926</link>
      <description><![CDATA[arXiv:2409.05926v1 公告类型：新 
摘要：大型预训练模型 (LPM) 在各种自然语言处理和计算机视觉任务中表现出色。然而，完全微调这些模型会带来巨大的内存挑战，尤其是在资源受限的环境中。参数高效微调 (PEFT) 方法（例如 LoRA）通过仅调整一小部分参数来缓解此问题。然而，这些方法通常对低秩矩阵采用随机初始化，这可能导致梯度下降效率低下，并且由于起点不理想而导致通用性降低。为了解决这些限制，我们提出了 SVFit，这是一种新颖的 PEFT 方法，它利用奇异值分解 (SVD) 使用关键奇异值作为可训练参数来初始化低秩矩阵。具体来说，SVFit 对预训练权重矩阵执行 SVD 以获得最佳秩 r 近似矩阵，强调捕获矩阵 99% 以上信息的最关键奇异值。然后，这些前 r 个奇异值被用作可训练参数来缩放矩阵的基本子空间，从而促进快速领域适应。在自然语言理解、文本到图像生成和图像分类任务中对各种预训练模型进行的大量实验表明，SVFit 的表现优于 LoRA，而所需的可训练参数却减少了 16 倍。]]></description>
      <guid>https://arxiv.org/abs/2409.05926</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的纤维胶粘剂优化设计</title>
      <link>https://arxiv.org/abs/2409.05928</link>
      <description><![CDATA[arXiv:2409.05928v2 公告类型：新
摘要：在甲虫、蜘蛛和壁虎等动物中观察到的纤维状粘附依靠纳米级或微观纤维通过“接触分裂”增强表面粘附。这一概念启发了机器人、交通和医学领域的工程应用。最近的研究表明，纤维特性的功能分级可以提高粘附性，但这是一个复杂的设计挑战，仅在简化的几何形状中进行过探索。虽然机器学习 (ML) 在粘合剂设计中获得了关注，但之前没有尝试针对纤维阵列规模优化。在本研究中，我们提出了一种基于 ML 的工具，可优化纤维柔顺性的分布以最大限度地提高粘合强度。我们的工具具有两个深度神经网络 (DNN)，可恢复先前针对简单几何形状的设计结果，并为复杂配置引入新颖的解决方案。预测器 DNN 根据随机柔顺性分布估计粘合强度，而设计师 DNN 使用基于梯度的优化来优化柔顺性以实现最大强度。我们的方法显著减少了测试误差并加速了优化过程，为通过实现均等负载分担（ELS）来实现抗断裂的纤维粘合剂和微结构材料的设计提供了高性能的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2409.05928</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Alt-MoE：通过多方向 MoE 与单峰模型交替优化实现多峰对齐</title>
      <link>https://arxiv.org/abs/2409.05929</link>
      <description><![CDATA[arXiv:2409.05929v1 公告类型：新 
摘要：最近的大型多模态模型（LMM）通过采用轻量级连接模块来促进现有预训练单模态模型中知识的表示和融合，在多模态对齐方面取得了重大进展。然而，这些方法仍然依赖于特定于模态和特定于方向的连接器，导致知识表示被划分为不同的区域并降低了计算效率，从而限制了模型形成统一的多模态表示的能力。为了解决这些问题，我们引入了一个新颖的训练框架 Alt-MoE，它采用混合专家（MoE）作为跨模态的统一多向连接器，并采用多步骤顺序交替单向对齐策略，该策略在迭代过程中收敛到双向对齐。广泛的实证研究揭示了以下关键点：1）Alt-MoE 通过整合来自单模态模型的多种知识表示取得了有竞争力的结果。这种方法无缝融合了现有高性能单模态模型的专业知识，有效地将它们的特定领域知识综合成一个有凝聚力的多模态表示。2) Alt-MoE 可以高效地扩展到新任务和模态，而无需改变其模型架构或训练策略。此外，Alt-MoE 在潜在空间中运行，通过轻量级多向 MoE 支持向量预存储和实时检索，从而促进海量数据处理。我们的方法已在多个性能良好的单模态模型（LLAMA3、Qwen2 和 DINOv2）上得到验证，并在广泛的下游任务和数据集上取得了有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2409.05929</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 eKAN 网络进行实时交通事故预测的自监督状态空间模型</title>
      <link>https://arxiv.org/abs/2409.05933</link>
      <description><![CDATA[arXiv:2409.05933v1 公告类型：新 
摘要：准确预测不同时间和地区的交通事故对公共安全至关重要。然而，现有的方法面临两个关键挑战：1）泛化：当前的模型严重依赖手动构建的多视图结构，如 POI 分布和道路网络密度，这些结构劳动密集型且难以跨城市扩展。2）实时性能：虽然一些方法可以通过复杂的架构提高准确性，但它们通常会产生高昂的计算成本，从而限制了它们的实时适用性。为了应对这些挑战，我们提出了 SSL-eKamba，一种高效的自监督交通事故预测框架。为了增强泛化能力，我们设计了两个自监督辅助任务，通过时空差异感知自适应地改进交通模式表示。为了实现实时性能，我们引入了 eKamba，这是一种重新设计 Kolmogorov-Arnold 网络 (KAN) 架构的高效模型。这涉及使用可学习的单变量函数进行输入激活，并应用选择性机制（选择性 SSM）来捕获多变量相关性，从而提高计算效率。对两个真实世界数据集进行的大量实验表明，SSL-eKamba 的表现始终优于最先进的基线。该框架还可能为其他时空任务提供新的见解。我们的源代码可在 http://github.com/KevinT618/SSL-eKamba 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.05933</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用高斯过程的随机游动预测电力消耗</title>
      <link>https://arxiv.org/abs/2409.05934</link>
      <description><![CDATA[arXiv:2409.05934v1 公告类型：新
摘要：我们考虑数据稀缺、难以收集或计算成本过高的时间序列预测问题。作为首次尝试，我们专注于法国的短期电力消耗，这对能源供应商和公共利益相关者具有战略意义。这个问题的复杂性和多层次的地理空间粒度促使我们使用一组高斯过程 (GP)。虽然 GP 是出色的预测器，但它们的训练计算成本很高，这需要一种节俭的少量学习方法。通过考虑在数据集上训练的 GP 的性能并设计随机游走，我们降低了整个贝叶斯决策过程的训练成本。我们介绍了一种称为 \textsc{Domino}（高斯过程随机游走）的算法，并提出了数值实验来支持其优点。]]></description>
      <guid>https://arxiv.org/abs/2409.05934</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoDiCast：具有不确定性量化的天气预报条件扩散模型</title>
      <link>https://arxiv.org/abs/2409.05975</link>
      <description><![CDATA[arXiv:2409.05975v1 公告类型：新
摘要：准确的天气预报对科学和社会至关重要。然而，现有的方法还未能同时兼具高精度、低不确定性和高计算效率的特性。一方面，为了量化天气预报中的不确定性，通常采用集合预报的策略（即生成一组不同的预测）。然而，传统的集合数值天气预报 (NWP) 计算量大。另一方面，大多数现有的基于机器学习的天气预报 (MLWP) 方法高效准确。然而，它们是确定性的，无法捕捉天气预报的不确定性。在这项工作中，我们提出了 CoDiCast，这是一种条件扩散模型，用于生成准确的全球天气预报，同时通过集合预报和适中的计算成本实现不确定性量化。关键思想是模拟扩散模型中逆去噪过程的条件版本，该过程从纯高斯噪声开始，为未来时间点生成真实的天气情景。每个去噪步骤都以最近的观测结果为条件。通过从随机高斯噪声中反复采样来表示不确定性量化，可以实现集合预报。CoDiCast 是基于欧洲中期天气预报中心 (ECMWF) 十年的 ERA5 再分析数据进行训练的。实验结果表明，我们的方法在准确性方面优于现有的几种数据驱动方法。我们的条件扩散模型 CoDiCast 可以在一台具有 80GB 内存的商用 A100 GPU 机器上，在大约 12 分钟内，以 6 小时为步长，以 $5.625^\circ$ 纬度-经度分辨率，针对 5 个以上的变量生成 3 天的全球天气预报。开源代码位于 \url{https://github.com/JimengShi/CoDiCast}。]]></description>
      <guid>https://arxiv.org/abs/2409.05975</guid>
      <pubDate>Wed, 11 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>