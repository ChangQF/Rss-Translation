<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Nteasee：一项关于专家和普通民众对在非洲国家部署人工智能医疗的看法的混合方法研究</title>
      <link>https://arxiv.org/abs/2409.12197</link>
      <description><![CDATA[arXiv:2409.12197v1 公告类型：新
摘要：人工智能 (AI) 可用于医疗健康领域，有可能显著改变和改善医疗保健。然而，在大多数非洲国家，人们对于确定部署这些解决方案的文化和环境适应方法还不是很了解。为了弥补这一差距，我们进行了一项定性研究，以调查在非洲国家部署人工智能用于医疗健康时的最佳做法、公平指标和潜在偏见，并探索人工智能可以对健康产生积极影响的机会。我们采用了一种结合深度访谈 (IDI) 和调查的混合方法。我们与 17 个国家的 50 名健康、政策和人工智能专家进行了 1.5-2 小时的 IDI，并通过归纳法对专家 IDI 的回答进行了定性主题分析。我们对非洲 5 个国家的 672 名普通人群参与者进行了 30 分钟的盲测，并附有案例研究，然后对回答进行定量分析，统计比较了不同国家、年龄、性别和对 AI 的熟悉程度。我们按主题总结了调查中的开放式回答。我们的研究结果发现，普通人群参与者对非洲使用 AI 进行健康护理的态度普遍积极，信任度高，同时担忧程度适中。这与专家的回应形成了鲜明对比，专家的回应主要围绕信任/不信任、道德问题以及系统性整合障碍等。这项工作从算法公平性的角度，结合专家和普通人群的观点，首次对 AI 在非洲健康护理方面的潜力进行了定性研究。我们希望这项工作能够指导政策制定者，并让他们认识到需要进一步研究，并在有关 AI 使用的决策中纳入普通人群的观点。]]></description>
      <guid>https://arxiv.org/abs/2409.12197</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不同规模专家的混合</title>
      <link>https://arxiv.org/abs/2409.12210</link>
      <description><![CDATA[arXiv:2409.12210v1 公告类型：新
摘要：稀疏激活混合专家 (MoE) 因在不增加计算成本的情况下扩展大型语言模型 (LLM) 而越来越受欢迎。尽管它取得了成功，但当前的设计面临着一个挑战，即所有专家都具有相同的大小，这限制了 token 选择最适合生成下一个 token 的专家的能力。在本文中，我们提出了混合不同大小专家 (MoDSE)，这是一种新的 MoE 架构，其层设计为拥有不同大小的专家。我们对困难的 token 生成任务的分析表明，不同规模的专家可以实现更好的预测，并且专家的路由路径在训练期后趋于稳定。但是，拥有不同规模的专家可能会导致工作负载分配不均。为了解决这个限制，我们引入了一个专家对分配策略，以在多个 GPU 上均匀分配工作负载。跨多个基准的综合评估证明了 MoDSE 的有效性，因为它通过自适应地将参数预算分配给专家，同时保持相同的总参数大小和专家数量，表现优于现有的 MoE。]]></description>
      <guid>https://arxiv.org/abs/2409.12210</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SemAI：物联网语义人工智能增强型 DNA 存储</title>
      <link>https://arxiv.org/abs/2409.12213</link>
      <description><![CDATA[arXiv:2409.12213v1 公告类型：新
摘要：随着物联网 (IoT) 等技术的快速发展，全球数据格局呈指数级增长，推动 DNA 存储成为当代云存储应用的潜在介质。本文介绍了一种语义人工智能增强型 DNA 存储 (SemAI-DNA) 范式，通过两个关键修改将其与流行的基于深度学习的方法区分开来：1) 在编码端嵌入语义提取模块，促进细致的语义信息的编码和存储；2) 在解码端构思一个深思熟虑的多读取过滤模型，利用 DNA 分子固有的多拷贝倾向来增强系统的容错能力，再加上战略性优化的解码器架构框架。数值结果证明了 SemAI-DNA 的有效性，与传统的基于深度学习的方法相比，峰值信噪比 (PSNR) 提高了 2.61 dB，结构相似性指数 (SSIM) 提高了 0.13。]]></description>
      <guid>https://arxiv.org/abs/2409.12213</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>常见正则化技术对开集识别的影响</title>
      <link>https://arxiv.org/abs/2409.12217</link>
      <description><![CDATA[arXiv:2409.12217v1 公告类型：新
摘要：近年来，人们对开放集识别领域的兴趣日益浓厚，开放集识别允许分类模型在遇到不在训练集中的对象或类时将输入识别为“未知”。这种标记未知输入的能力对于许多现实世界的分类应用至关重要。由于几乎所有现代神经网络训练方法都使用大量正则化进行泛化，因此研究正则化技术如何影响模型执行开放集识别的能力非常重要。在这项工作中，我们研究了常见的正则化技术与开放集识别性能之间的关系。我们的实验与特定的开放集检测算法无关，并检查了各种数据集的影响。我们通过经验表明，正则化方法可以显着提高开放集识别性能，并且我们对准确性和开放集性能之间的关系提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.12217</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的数据子集选择以推广跨模型训练：传导和归纳网络</title>
      <link>https://arxiv.org/abs/2409.12255</link>
      <description><![CDATA[arXiv:2409.12255v1 公告类型：新
摘要：现有的高效学习子集选择方法主要采用离散组合和模型特定方法，缺乏通用性。对于看不见的架构，不能使用为不同模型选择的子集。为了解决这个问题，我们提出了一个可训练的子集选择框架 $\texttt{SubSelNet}$，它可以跨架构进行推广。在这里，我们首先介绍一个基于注意力的神经小工具，它利用架构的图形结构并充当训练有素的深度神经网络的替代品，以进行快速模型预测。然后，我们使用这些预测来构建子集采样器。这自然为我们提供了两种 $\texttt{SubSelNet}$ 变体。第一个变体是传导性的（称为传导性-$\texttt{SubSelNet}$），它通过解决一个小的优化问题为每个模型分别计算子集。由于用模型近似器代替了显式模型训练，这种优化仍然非常快。第二种变体是归纳的（称为 Inductive-$\texttt{SubSelNet}$），它使用经过训练的子集选择器计算子集，而无需任何优化。我们的实验表明，我们的模型在几个真实数据集上的表现优于几种方法]]></description>
      <guid>https://arxiv.org/abs/2409.12255</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检测 LGBTQ+ 网络欺凌行为</title>
      <link>https://arxiv.org/abs/2409.12263</link>
      <description><![CDATA[arXiv:2409.12263v1 公告类型：新
摘要：社交媒体继续影响着人类的发展轨迹。然而，它的引入也使键盘武器化，使通常用于面对面欺凌的辱骂性语言跳上了屏幕，即网络欺凌。网络欺凌对全球青少年构成了重大威胁，影响了许多人的精神健康和幸福。一个特别危险的群体是 LGBTQ+ 社区，因为研究人员发现，将自己认定为 LGBTQ+ 与遭受更严重的网络骚扰之间存在很强的相关性。因此，开发能够准确辨别发生在 LGBTQ+ 成员身上的网络欺凌事件的机器学习模型至关重要。本研究的目的是比较几种 Transformer 模型在识别针对 LGBTQ+ 个体的网络欺凌方面的有效性。我们试图通过使用真实的社交媒体数据评估这些现有方法的有效性来确定它们在解决复杂而微妙的网络欺凌行为方面的相对优点和缺点。]]></description>
      <guid>https://arxiv.org/abs/2409.12263</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多元时间序列分类的用户友好型基础模型适配器</title>
      <link>https://arxiv.org/abs/2409.12264</link>
      <description><![CDATA[arXiv:2409.12264v1 公告类型：新
摘要：基础模型虽然非常有效，但通常资源密集，需要大量的推理时间和内存。本文通过探索降维技术来解决在有限的计算资源下使这些模型更易于访问的挑战。我们的目标是让用户能够在标准 GPU 上运行大型预训练基础模型，而不会牺牲性能。我们研究了经典方法（例如主成分分析）以及基于神经网络的适配器，旨在降低多元时间序列数据的维数，同时保留关键特征。我们的实验表明，与基线模型相比，速度提高了 10 倍，而性能没有下降，并且使单个 GPU 能够容纳多达 4.5 倍的数据集，为更用户友好和可扩展的基础模型铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.12264</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 模型掌握国际象棋</title>
      <link>https://arxiv.org/abs/2409.12272</link>
      <description><![CDATA[arXiv:2409.12272v1 公告类型：新
摘要：Transformer 模型在大规模训练时表现出令人印象深刻的能力，在需要复杂推理和理性决策的困难认知任务中表现出色。在本文中，我们探讨了 Transformer 模型在国际象棋中的应用，重点关注位置编码在注意力机制中的关键作用。我们表明，在国际象棋中，具有足够通用位置编码的 Transformer 可以以极低的计算成本匹配现有的国际象棋模型。我们的架构在 FLOPS 减少 8 倍的情况下显著优于 AlphaZero，并且在 FLOPS 减少 30 倍的情况下与之前的大师级基于 Transformer 的代理相匹配。]]></description>
      <guid>https://arxiv.org/abs/2409.12272</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MetaPix：以数据为中心的人工智能开发平台，用于高效管理和利用非结构化计算机视觉数据</title>
      <link>https://arxiv.org/abs/2409.12289</link>
      <description><![CDATA[arXiv:2409.12289v1 公告类型：新
摘要：在当今先进的人工智能技术世界中，数据管理是任何人工智能/机器学习解决方案的关键组成部分。有效的数据管理对于创建和维护高质量、多样化的数据集至关重要，这可以显著增强预测能力并带来更智能的业务解决方案。在这项工作中，我们介绍了 MetaPix，这是一个以数据为中心的人工智能平台，提供专为非结构化数据设计的全面数据管理解决方案。MetaPix 为数据提取、处理、存储、版本控制、治理和发现提供了强大的工具。该平台基于四个关键概念运行：数据源、数据集、扩展和提取器。数据源是 MetaPix 的顶级资产，代表特定用途的狭义数据源。数据集是 MetaPix 的第二级对象，是结构化的数据集合。提取器是集成到 MetaPix 后端处理中的内部工具，有助于数据处理和增强。此外，MetaPix 支持扩展，可以与外部第三方工具集成以增强平台功能。本文详细探讨了 MetaPix 的每个概念，说明了它们如何共同为平台的目标做出贡献。通过提供管理和利用非结构化计算机视觉数据的全面解决方案，MetaPix 为组织提供了一套强大的工具集，以有效地开发 AI 应用程序。]]></description>
      <guid>https://arxiv.org/abs/2409.12289</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 进行线性系统和线性椭圆偏微分方程的可证明上下文学习</title>
      <link>https://arxiv.org/abs/2409.12293</link>
      <description><![CDATA[arXiv:2409.12293v1 公告类型：新
摘要：由 Transformer 架构驱动的自然语言处理基础模型表现出卓越的上下文学习 (ICL) 能力，允许预训练模型使用少量提示适应下游任务而无需更新其权重。最近，基于 Transformer 的基础模型也已成为解决科学问题的多功能工具，特别是在偏微分方程 (PDE) 领域。然而，这些科学模型中 ICL 能力的理论基础仍然很大程度上未被探索。这项工作为基于 Transformer 的 ICL 开发了一种严格的误差分析，该 ICL 应用于与线性椭圆 PDE 系列相关的解算子。我们首先证明，由线性自注意层定义的线性 Transformer 可以证明在上下文中学习以反转由 PDE 的空间离散化产生的线性系统。这是通过推导所提出的线性变压器的预测风险的理论缩放定律来实现的，这些理论缩放定律包括空间离散化大小、训练任务数量以及训练和推理期间使用的提示长度。这些缩放定律还使我们能够为学习 PDE 解建立定量误差界限。此外，我们量化了预训练变压器对下游 PDE 任务的适应性，这些任务在任务（由 PDE 系数表示）和输入协变量（由源项表示）中都会经历分布变化。为了分析任务分布变化，我们引入了一个新概念任务多样性，并根据任务变化的幅度来表征变压器的预测误差，假设预训练任务具有足够的多样性。我们还建立了确保任务多样性的充分条件。最后，我们通过大量数值实验验证了变压器的 ICL 能力。]]></description>
      <guid>https://arxiv.org/abs/2409.12293</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SANE：多模态和不可微黑盒函数中多重最优发现的战略自主非平滑探索</title>
      <link>https://arxiv.org/abs/2409.12295</link>
      <description><![CDATA[arXiv:2409.12295v1 公告类型：新
摘要：计算和实验材料发现都带来了探索多维和多模态参数空间的挑战，例如具有多个相互作用的汉密尔顿相图、组合库的组成空间、材料结构图像空间和分子嵌入空间。这些系统通常是黑盒的，评估起来很耗时，这引起了人们对贝叶斯优化 (BO) 等主动学习方法的浓厚兴趣。然而，这些系统通常很嘈杂，这使得黑盒函数严重多模态且不可微分，其中普通 BO 可能会过度集中在单一或伪最优值附近，偏离科学发现的更广泛目标。为了解决这些限制，我们在此开发了战略自主非平滑探索 (SANE)，以促进智能贝叶斯优化导航，并提出成本驱动的概率获取函数来找到多个全局和局部最优区域，避免陷入单一最优值的倾向。为了区分由于实验测量噪声而产生的真最佳区域和假最佳区域，将人类（领域）知识驱动的动态代理门与 SANE 集成。我们将 SANE 门应用于预先获取的铁电组合库的压电响应光谱数据（特定区域的噪声水平较高）和压电响应力显微镜 (PFM) 高光谱数据中。SANE 表现出比传统 BO 更好的性能，有助于探索多个最佳区域，从而优先学习具有更高科学价值覆盖率的自主实验。我们的工作展示了该方法在现实世界实验中的潜在应用，其中这种结合战略和人为干预的方法对于解锁自主研究中的新发现至关重要。]]></description>
      <guid>https://arxiv.org/abs/2409.12295</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SplitVAE：针对随机优化问题的孤立数据分散式场景生成</title>
      <link>https://arxiv.org/abs/2409.12328</link>
      <description><![CDATA[arXiv:2409.12328v1 公告类型：新
摘要：大规模多利益相关者网络系统（例如电网和供应链）中的随机优化问题依赖于数据驱动的场景来封装复杂的时空相互依赖关系。然而，由于计算和物流瓶颈导致的数据孤岛的存在，利益相关者数据的集中聚合具有挑战性。在本文中，我们提出了 SplitVAEs，这是一个分散的场景生成框架，它利用变分自动编码器在不移动利益相关者数据的情况下生成高质量的场景。借助分布式内存系统上的实验，我们证明了 SplitVAEs 在由大量利益相关者主导的各种领域中的广泛适用性。我们的实验表明，SplitVAEs 可以学习大规模网络中的空间和时间相互依赖关系，以分散的方式生成与利益相关者数据的联合历史分布相匹配的场景。我们的实验表明，与集中式、最先进的基准方法相比，SplitVAE 提供了强大的性能，同时显著降低了数据传输成本，从而为场景生成提供了一种可扩展、增强隐私的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2409.12328</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过最大规律的 ReLU MLP 的最佳近似弥合近似与学习之间的差距</title>
      <link>https://arxiv.org/abs/2409.12335</link>
      <description><![CDATA[arXiv:2409.12335v1 公告类型：新
摘要：深度学习的基础由近似或学习理论这两个看似对立的观点所支持。前者主张不需要泛化的大型/富有表现力的模型，而后者则考虑具有泛化能力但可能太小/受限而无法成为通用近似器的类。受现实世界中既具有表现力又具有统计可靠性的深度学习实现的启发，我们问：“是否存在一类神经网络，它既足够大以具有通用性，又足够结构化以具有泛化能力？”
本文通过识别一类高度结构化的 ReLU 多层感知器 (MLP)，建设性地为这个问题提供了肯定的答案，它们是最佳函数近似器，并且在统计上表现良好。我们表明，任何从 $[0,1]^d$ 到 $[-n,n]$ 的 $L$-Lipschitz 函数都可以近似为 $[0,1]^d$ 上的均匀 $Ld/(2n)$ 误差，其中稀疏连接的 $L$-Lipschitz ReLU MLP 宽度为 $\mathcal{O}(dn^d)$，深度为 $\mathcal{O}(\log(d))$，具有 $\mathcal{O}(dn^d)$ 个非零参数，其权重和偏差取值范围为 $\{0,\pm 1/2\}$，但第一层和最后一层除外，它们的幅度最多为 $n$。与之前已知的“大型”通用 ReLU MLP 类不同，即使深度和宽度变得任意大，我们类的经验 Rademacher 复杂度仍然有界。此外，当给定 $N$ 个 i.i.d. 正则化亚高斯训练样本时，我们的 MLP 类实现了接近最佳的样本复杂度 $\mathcal{O}(\log(N)/\sqrt{N})$。
我们通过避免构建最佳 ReLU 近似器的标准方法来实现这一点，这种方法通过依赖小尖峰而牺牲了规律性。相反，我们引入了一种新的构造，它使用 Kuhn 三角剖分将线性部分完美地组合在一起，并避免了这些小尖峰。]]></description>
      <guid>https://arxiv.org/abs/2409.12335</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过分解提取记忆的训练数据</title>
      <link>https://arxiv.org/abs/2409.12367</link>
      <description><![CDATA[arXiv:2409.12367v1 公告类型：新
摘要：大型语言模型 (LLM) 在社会中的广泛使用为开发人员、组织和最终用户带来了新的信息安全挑战。LLM 是在大量数据上进行训练的，它们很容易泄露源训练数据集的确切内容，这会带来安全风险。尽管当前的对齐程序限制了常见的危险行为，但它们并不能完全防止 LLM 泄露数据。先前的研究表明，LLM 可能会被诱骗使用分布外查询或对抗技术泄露训练数据。在本文中，我们演示了一种简单的基于查询的分解方法，用于从两个前沿 LLM 中提取新闻文章。我们使用指令分解技术逐步提取训练数据片段。在 3723 篇《纽约时报》文章中，我们从 73 篇文章中提取了至少一个逐字句子，从 6 篇文章中提取了超过 20% 的逐字句子。我们的分析表明，这种方法成功地诱导 LLM 生成可靠的新闻文章再现文本，这意味着它们很可能来自源训练数据集。这种方法简单、可推广，并且不会微调或更改生产模型。如果可以大规模复制，这种训练数据提取方法可能会暴露新的 LLM 安全漏洞，包括隐私风险和未经授权的数据泄露。这些影响需要从模型开发到最终使用都仔细考虑。]]></description>
      <guid>https://arxiv.org/abs/2409.12367</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通信高效的联邦低秩更新算法及其与隐式正则化的联系</title>
      <link>https://arxiv.org/abs/2409.12371</link>
      <description><![CDATA[arXiv:2409.12371v1 公告类型：新
摘要：联邦学习 (FL) 面临着与通信效率和异构性相关的重大挑战。为了解决这些问题，我们探索了使用低秩更新的潜力。我们的理论分析表明，与服务器的损失相比，客户端的损失表现出更高的秩结构（梯度跨越 Hessian 的高秩子空间）。基于这一见解，我们假设将客户端优化限制在低秩子空间可以提供隐式正则化效果。因此，我们提出了 FedLoRU，一种用于联邦学习的通用低秩更新框架。我们的框架强制执行低秩客户端更新并累积这些更新以形成更高秩的模型。此外，FedLoRU 的变体可以通过采用多个或分层的低秩更新来适应具有统计和模型异构性的环境。实验结果表明，FedLoRU 的性能与全秩算法相当，并且对异构和大量客户端表现出鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2409.12371</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>