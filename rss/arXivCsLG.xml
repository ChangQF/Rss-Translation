<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用大型语言模型用于自动化因果循环图生成：通过策划提示技术增强系统动力学建模</title>
      <link>https://arxiv.org/abs/2503.21798</link>
      <description><![CDATA[ARXIV：2503.21798V1公告类型：新 
摘要：将动态假设转换为因果环图（CLD）对于系统动力学建模至关重要。从文本中提取关键变量和因果关系来构建CLD通常对新手建模者来说通常是具有挑战性的，并且限制了SD工具的采用。本文介绍并测试了一种使用大型语言模型（LLMS）自动化动态假设将动态假设自动化为CLD的方法。我们首先描述了LLM的工作原理以及它们如何使用标准的Digraph结构进行构建CLD所需的推论。接下来，我们从领先的SD教科书中开发了一组简单的动态假设和相应的CLD。然后，我们比较了提示技术的四种不同组合，从而评估了它们与专家建模者标记的CLD的性能。结果表明，对于简单的模型结构并使用策划的提示技术，LLM可以生成与专家构建的质量相似的CLD，从而加速CLD创建。]]></description>
      <guid>https://arxiv.org/abs/2503.21798</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的多个未来代币的联合预测</title>
      <link>https://arxiv.org/abs/2503.21801</link>
      <description><![CDATA[Arxiv：2503.21801V1公告类型：新 
摘要：在此简短的报告中，我们引入了联合多言预测（JTP），这是对旨在通过共同预测多个将来的代币来丰富隐藏状态表示的标准下一个预测的轻巧修改。与以前的多言预测方法不同，JTP通过精心设计的表示瓶颈策略性地采用了教师的强迫，从而使模型可以在培训期间用最小的计算开销来编码丰富的预测信息。我们表明，JTP方法实现了短暂的信念状态表示，而多token预测的流行替代方案未能做到这一点。我们证明了我们的方法对来自Bachmann和Nagarajan [2024]的合成星导航任务的有效性，突出了对现有方法的显着性能改善。该手稿提出了有希望的初步结果，旨在刺激进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2503.21801</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯正规化神经网络在Fuego火山的预测火山辐射能力（VPR）</title>
      <link>https://arxiv.org/abs/2503.21803</link>
      <description><![CDATA[ARXIV：2503.21803V1公告类型：新 
摘要：预测火山活动对于危害评估和减轻风险至关重要。来自热遥感数据的火山辐射功率（VPR）是火山活动的重要指标。在这项研究中，我们采用贝叶斯正规化神经网络（BRNN）根据Fuego火山的历史数据来预测未来的VPR值，将其与缩放的共轭梯度（SCG）和Levenberg-Marquardt（LM）模型进行了比较。结果表明，BRNN胜过SCG和LM，达到了最低平方误差（1.77E+16）和最高的R平方值（0.50）（0.50），这表明其捕获VPR变异性的卓越能力，同时最小化过度拟合。尽管这些有希望的结果，但仍在提高模型的预测准确性方面仍然存在挑战。未来的研究应着重于整合其他地球物理参数，例如地震和气体排放数据，以提高预测精度。这些发现突出了机器学习模型，尤其是BRNN的潜力，可以预测火山活动，这有助于更有效的火山危害预警系统。]]></description>
      <guid>https://arxiv.org/abs/2503.21803</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>元数据表示模型的知识图嵌入模型的比较</title>
      <link>https://arxiv.org/abs/2503.21804</link>
      <description><![CDATA[ARXIV：2503.21804V2公告类型：新 
摘要：超关系知识图（HRKGS）将传统的KG扩展到二进制关系之外，从而可以在域中的上下文，出处和时间信息的表示，例如历史事件，传感器数据，视频内容和叙述。可以使用多种元数据表示模型（MRMS）来构建HRKG，包括重新化（REF），Singleton属性（SGP）和RDF-Star（RDR）。但是，不同MRM对KG嵌入（KGE）和链接预测（LP）模型的影响尚不清楚。这项研究在LP任务的背景下评估了MRM，确定了现有评估框架的局限性，并引入了一项新任务，以确保MRM的公平比较。此外，我们提出了一个有效反映潜在空间中三个MRM的知识表示的框架。在两种类型的数据集上进行的实验表明，REF在简单的HRKG中表现良好，而SGP的效率较低。但是，在复杂的HRKG中，LP任务中MRM的差异很小。我们的发现有助于LP任务中HRKG的最佳知识表示策略。]]></description>
      <guid>https://arxiv.org/abs/2503.21804</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LERO：具有混合奖励的LLM驱动的进化框架，并增强了对多代理增强学习的观察</title>
      <link>https://arxiv.org/abs/2503.21807</link>
      <description><![CDATA[ARXIV：2503.21807V1公告类型：新 
摘要：多机构增强学习（MARL）面对两个与单一AGENT RL不同的关键瓶颈：合作任务中的信用分配和环境状态的部分可观察性。我们提出了Lero，这是一个将大型语言模型（LLM）与进化优化集成的框架，以应对这些特定于MARL的挑战。该解决方案集中在两个LLM生成的组件上：一种混合奖励函数，通过奖励分解动态分配个人信用，以及一种观察增强功能，可以通过推断的环境环境增强部分观察。进化算法通过迭代MARL训练周期优化了这些组件，在该周期中，表现最佳的候选人引导后来的LLM世代。多代理粒子环境（MPE）的评估证明了Lero优于基线方法，并提高了任务性能和训练效率。]]></description>
      <guid>https://arxiv.org/abs/2503.21807</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IPGO：对具有较高数据效率的文本到图像生成模型的间接及时梯度优化</title>
      <link>https://arxiv.org/abs/2503.21812</link>
      <description><![CDATA[ARXIV：2503.21812V1公告类型：新 
摘要：文本到图像扩散模型在从文本提示中生成图像方面表现出色，但通常缺乏与内容语义，美学和人类偏好的最佳对齐。为了解决这些问题，在本研究中，我们介绍了一个新颖的框架，间接及时梯度优化（IPGO），以及时进行微调。 IPGO通过在提示嵌入的开始和结尾处注入连续可区分的令牌来增强提示嵌入，同时利用旋转的低级别优势和灵活性。它允许基于梯度的注射令牌优化，同时实施价值，正常值和合格约束，从而促进连续更新并赋予计算效率。为了评估IPGO的性能，我们在三个不同复杂性的三个数据集中进行了三个奖励模型，以三种奖励模型进行迅速和及时的培训。结果表明，IPGO始终匹配或优于尖端基准测试，包括稳定的扩散v1.5，具有原始提示，基于培训的方法（草稿和DDPO）以及无培训方法（DPO扩散，促使，促使主义者和CANTGPT-4O）。此外，我们证明了IPGO在提高图像生成质量方面的有效性，同时需要最少的培训数据和有限的计算资源。]]></description>
      <guid>https://arxiv.org/abs/2503.21812</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的订单以获取最大集团</title>
      <link>https://arxiv.org/abs/2503.21814</link>
      <description><![CDATA[ARXIV：2503.21814V1公告类型：新 
摘要：我们通过将基于置换的框架框架来学习最大集团问题的无监督方法来学习最大集团问题。我们将组合约束转换为几何关系，以使顶点的顺序与集团结构保持一致。通过将这种面积的订购集成到分支结合的搜索中，我们提高了搜索效率并减少了计算步骤的数量。我们的结果表明，对顶点排序的无监督学习如何在各种图形实例上提高搜索效率。我们进一步研究了不同大小的概括。]]></description>
      <guid>https://arxiv.org/abs/2503.21814</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有宽敞稀疏模型的有效培训算法</title>
      <link>https://arxiv.org/abs/2503.21928</link>
      <description><![CDATA[ARXIV：2503.21928V1公告类型：新 
摘要：大规模机器学习（ML）模型越来越多地用于教育，贷款，招聘，医疗保健，刑事司法等的关键领域。但是，这些模型的培训，部署和利用需要大量的计算资源。为了降低计算和记忆成本，文献中广泛使用具有稀疏重量矩阵的机器学习模型。在稀疏模型中，具有特殊稀疏结构（例如具有块稀疏重量矩阵的模型）的模型与硬件加速器更适合，并且可以在推理过程中降低内存和计算成本。不幸的是，尽管有几种有效的训练方法，但它们都没有设计用于有效地培训稀疏模型。结果，当前的培训稀疏模型的方法始于完整而密集的模型，导致效率低下的培训。在这项工作中，我们专注于\ textIt {块稀疏矩阵}的培训模型，并提出了一种有效的培训算法，以降低训练和推理期间的计算和记忆成本。此外，我们将证明我们提出的方法使我们能够在训练过程中有效地找到适合稀疏模式的块大小。我们广泛的经验和理论分析表明，与基线相比，我们的算法可以大大降低计算和记忆成本，而无需性能下降。]]></description>
      <guid>https://arxiv.org/abs/2503.21928</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加固学习者的奖励设计</title>
      <link>https://arxiv.org/abs/2503.21949</link>
      <description><![CDATA[ARXIV：2503.21949V1公告类型：新 
摘要：奖励功能在加强学习（RL）中是核心，指导代理人实现最佳决策。 RL任务的复杂性需要精心设计的奖励功能，这些功能有效地推动学习，同时避免意外后果。有效的奖励设计旨在提供信号，以加速代理商与最佳行为的融合。制定与任务目标，促进所需行为和防止不良行动保持一致的奖励本质上是具有挑战性的。该论文深入研究了奖励信号在RL中的关键作用，强调了它们对代理商的行为和学习动态的影响，并应对诸如延迟，模棱两可或复杂的奖励等挑战。在这篇论文的工作中，我们解决了奖励成型的不同方面。首先，我们从教师/专家的角度（教师驱动）来解决设计信息丰富且可解释的奖励信号的问题。在这里，配备了最佳策略和相应价值功能的专家设计奖励信号，这些信号加快了代理商与最佳行为的融合。其次，我们通过引入一种新颖的自适应解释奖励设计的方法来基于这种教师驱动的方法。在这种情况下，专家根据学习者的当前政策来量身定制奖励，以确保对齐和最佳进步。第三，我们提出了一种元学习方法，使代理商可以在没有专家投入（代理驱动的）的情况下自我设计其奖励信号。这种自我驱动的方法考虑了代理商的学习和探索，以建立自我改进的反馈循环。]]></description>
      <guid>https://arxiv.org/abs/2503.21949</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Neurolip：fMRI和表型文本的可解释和公平的跨模式对齐</title>
      <link>https://arxiv.org/abs/2503.21964</link>
      <description><![CDATA[ARXIV：2503.21964V1公告类型：新 
摘要：将功能性磁共振成像（fMRI）连接数据与表型文本描述符（例如疾病标签，人口统计数据）具有巨大的潜力，可以提高我们对神经系统状况的理解。但是，现有的跨模式对准方法通常缺乏可解释性和风险来引入偏见，并通过编码敏感属性以及与诊断相关的特征。在这项工作中，我们提出了一种新型的跨模式对比学习框架Neurolip。我们通过每个与疾病相关的表型令牌介绍了文本令牌条件的注意（TTCA）和通过局部令牌（CALT）的跨模式对齐。它通过令牌级别的注意图提高了可解释性，从而揭示了大脑区域疾病的关联。为了减轻偏见，我们提出了敏感属性分离的损失，以最大程度地提高疾病令牌与敏感属性令牌之间的注意力距离，从而减少了下游预测中意外的相关性。此外，我们结合了一种负梯度技术，该技术逆转了敏感属性上CALT损失的迹象，进一步阻止了这些特征的对齐。关于神经成像数据集的实验（Abide和ADHD-200）证明了Neurolip在公平指标方面的优越性，同时保持总体最佳的标准度量性能。注意图的定性可视化突出了与诊断特征相一致的神经解剖模式，并通过神经科学文献验证。我们的工作推动了透明和公平的神经影像AI的发展。]]></description>
      <guid>https://arxiv.org/abs/2503.21964</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Rocketppa：在代码级抽象时，超快速LLM的PPA估计器</title>
      <link>https://arxiv.org/abs/2503.21971</link>
      <description><![CDATA[ARXIV：2503.21971V1公告类型：新 
摘要：大型语言模型最近改变了硬件设计，但是弥合了代码合成与PPA（功率，性能和区域）估计之间的差距仍然是一个挑战。在这项工作中，我们介绍了一个新颖的框架，该框架利用21k数据集的彻底清洁和合成的Verilog模块，每个模块都以详细的功率，延迟和面积指标注释。通过采用思想链技术，我们会自动调试并策划该数据集，以确保在下游应用程序中高保真。然后，我们使用基于LORA的参数效率方法对Codellama进行微调，将任务作为回归问题构建，以准确预测Verilog代码中的PPA指标。此外，我们通过融合洛拉（Lora）和额外的MLP专家层来进一步完善预测，以增强体系结构的混合物来增强我们的方法。实验结果表明了显着的改进：在误差阈值20％的情况下，功率估计精度提高了5.9％，在10％阈值时提高了7.2％，延迟估计提高了5.1％和3.9％，面积估计分别为20％和10％的阈值的增长率为4％和7.9％。值得注意的是，融合到专家的混合物模块在这些任务中贡献了3--4％的改善。我们的结果为PPA感知的Verilog生成建立了一个新的基准测试，突出了我们集成数据集的有效性和对下一代EDA工作流的建模策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.21971</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用概率对称性破坏来改善均值网络</title>
      <link>https://arxiv.org/abs/2503.21985</link>
      <description><![CDATA[ARXIV：2503.21985V1公告类型：新 
摘要：模棱两可将已知对称性编码到神经网络中，通常会增强概括。但是，均值网络不能打破对称性：按照定义，等效网络的输出必须至少具有与输入相同的自我对称性。这构成了一个重要的问题，这两种问题（1）对于自我对称是常见的域上的预测任务，以及（2）对于生成模型，必须打破对称性才能从高度对称的潜在空间重建。可以通过考虑模棱两可的条件分布而不是均衡功能来解决这种基本限制。我们提出了新的理论结果，这些结果建立了代表此类分布的必要条件。具体而言，该表示形式提供了一个实用的框架，可以通过随机规范化在任何e夫网络中打破对称性。我们的方法，Sympe（破坏对称性的位置编码），在位置编码方面接受了一种简单的解释。这种方法扩大了模棱两可的网络的代表力，同时保留了对称性的电感偏见，我们通过概括范围证明这是合理的。实验结果表明，Sympe显着提高了图形，图形自动编码器和晶格旋转系统建模的扩散模型的组等级和图神经网络的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.21985</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过模块化培训的经常性网络中的低级和稀疏傅立叶结构</title>
      <link>https://arxiv.org/abs/2503.22059</link>
      <description><![CDATA[ARXIV：2503.22059V1公告类型：新 
摘要：模块化添加任务是一个有用的测试床，可在深度学习中观察经验现象，包括\ emph {grokking}的现象。先前的工作表明，一层变压器体系结构学习傅立叶乘法电路以求解模块化的添加任务。在本文中，我们表明在模块化添加任务上训练的经过培训的复发性神经网络（RNN）也使用傅立叶乘法策略。我们将模型权重的低等级结构确定为特定的傅立叶频率，并将模型组件归因于特定的傅立叶频率，从而在傅立叶空间中稀疏表示。我们还从经验上表明，RNN可以强大地消除单个频率，而性能会大大降低，因为更多的频率是从模型中消失的。]]></description>
      <guid>https://arxiv.org/abs/2503.22059</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Arch-llm：通过无监督的离散表示学习来驯服神经建筑生成的LLM</title>
      <link>https://arxiv.org/abs/2503.22063</link>
      <description><![CDATA[ARXIV：2503.22063V1公告类型：新 
摘要：无监督的表示学习已在包括神经体系结构在内的各种方式中广泛探索，它在神经体系结构搜索（NAS）等下游应用中起关键作用。这些方法通常在生成/采样体系结构以进行下游搜索之前学习无监督的表示空间。一种常见的方法涉及使用变异自动编码器（VAE）将离散体系结构映射到连续的表示空间上，但是，从这些空间进行采样通常会导致高度无效或重复的神经体系结构。这可能是由于将固有离散的架构空间不自然的映射到连续空间上，这强调了对这些架构的强大离散表示的需求。为了解决这个问题，我们介绍了量化的量化变量自动编码器（VQ-VAE），以学习一个离散的神经体系结构更自然地对齐的离散潜在空间。与VAE相反，VQ-VAE（i）将每个体系结构映射到离散的代码序列中，并且（ii）允许任何生成模型都学到之前，而不是假设正态分布。然后，我们将这些架构潜在代码表示为数值序列，并训练文本到文本模型，该模型利用大型语言模型来学习和生成代表体系结构的序列。我们使用Inception/ Resnet样细胞的搜索空间（即NAS Bench-101和NAS Bench-2010）实验我们的方法。与基于VAE的方法相比，我们的方法在NASBENCH-101上将有效和独特体系结构的生成增长了80％，而NASBENCH-2010则超过8％。最后，我们使用基于序列模型的NAS算法的NAS中证明了我们的方法的适用性。]]></description>
      <guid>https://arxiv.org/abs/2503.22063</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个能够持续学习的网络的建议</title>
      <link>https://arxiv.org/abs/2503.22068</link>
      <description><![CDATA[ARXIV：2503.22068V1公告类型：新 
摘要：我们分析了计算单元在参数更新之后保留过去响应的能力，这是一个范围内持续学习的关键属性。接受梯度下降训练的神经网络缺乏这种能力，促使我们提出了Modelleyen，这是一种具有固有响应保存的替代方法。我们通过实验对简单环境的动力学进行建模和MNIST的实验证明，尽管计算复杂性增加了，并且在当前阶段的某些表示局限性，但Modelleyen在不依赖样本重播或预定义的任务范围的情况下实现了持续的学习。]]></description>
      <guid>https://arxiv.org/abs/2503.22068</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>