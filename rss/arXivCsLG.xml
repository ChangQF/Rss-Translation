<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 06 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MADOD：通过 G-Invariance 元学习将 OOD 检测推广到未知域</title>
      <link>https://arxiv.org/abs/2411.02444</link>
      <description><![CDATA[arXiv:2411.02444v1 公告类型：新
摘要：现实世界的机器学习应用经常面临同时发生的协变量和语义转变，这对传统的领域泛化和分布外 (OOD) 检测方法提出了挑战。我们引入了跨领域元学习分布外检测 (MADOD)，这是一个旨在同时解决这两种转变的新框架。MADOD 利用元学习和 G 不变性来增强模型的泛化能力和在未见域中的 OOD 检测。我们的关键创新在于任务构建：我们在每个元学习任务中随机将分布内类别指定为伪 OOD，使用现有数据模拟 OOD 场景。这种方法与基于能量的正则化相结合，能够学习稳健的领域不变特征，同时校准决策边界以进行有效的 OOD 检测。MADOD 在与测试域无关的环境中运行，消除了推理过程中进行自适应的需要，使其适用于测试数据不可用的场景。在现实世界和合成数据集上进行的大量实验表明，MADOD 在跨看不见的域的语义 OOD 检测方面具有卓越的性能，实现了 8.48% 至 20.81% 的 AUPR 提升，同时保持了有竞争力的分布内分类准确率，代表了在处理协变量和语义转变方面取得的显着进步。]]></description>
      <guid>https://arxiv.org/abs/2411.02444</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习无约束目标导航的世界模型</title>
      <link>https://arxiv.org/abs/2411.02446</link>
      <description><![CDATA[arXiv:2411.02446v1 公告类型：新
摘要：学习世界模型为具有稀疏奖励的目标条件强化学习提供了一条有前途的途径。通过允许代理在不与环境直接交互的情况下计划行动或探索目标，世界模型提高了探索效率。世界模型的质量取决于代理重放缓冲区中存储的数据的丰富性，期望在记录轨迹周围的状态空间中进行合理的概括。然而，在将学习到的世界模型推广到沿记录轨迹向后的状态转换或跨不同轨迹的状态之间的状态转换时，出现了挑战，阻碍了它们准确模拟现实世界动态的能力。为了应对这些挑战，我们引入了一种新颖的目标导向探索算法 MUN（“无约束目标导航的世界模型”的缩写）。该算法能够在重放缓冲区中对任意子目标状态之间的状态转换进行建模，从而促进学习在任何“关键”状态之间导航的策略。实验结果表明，MUN 增强了世界模型的可靠性，并显著提高了策略在新的目标设置中的推广能力。]]></description>
      <guid>https://arxiv.org/abs/2411.02446</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你脱离上下文了！</title>
      <link>https://arxiv.org/abs/2411.02464</link>
      <description><![CDATA[arXiv:2411.02464v1 公告类型：新
摘要：本研究基于数据向量空间表示中的“变形”概念，提出了一种用于机器学习 (ML) 模型的新型漂移检测方法。认识到新数据可以充当拉伸、压缩或扭曲模型学习到的几何关系的力，我们探索了各种数学框架来量化这种变形。我们研究了诸如协方差矩阵的特征值分析等措施来捕捉全局形状变化、使用核密度估计 (KDE) 进行局部密度估计以及 Kullback-Leibler 散度来识别数据集中细微的变化。此外，我们从连续力学中汲取灵感，提出了一种“应变张量”类比来捕捉不同数据类型的多面变形。这需要仔细估计位移场，我们深入研究了从基于密度的方法到流形学习和神经网络方法等策略。通过持续监控这些变形指标并将它们与模型性能关联起来，我们旨在提供一个敏感、可解释且适应性强的漂移检测系统，该系统能够区分良性数据演变和真实漂移，从而实现及时干预并确保机器学习系统在动态环境中的可靠性。针对此方法的计算挑战，我们讨论了降维、近似算法和并行化等缓解策略，用于实时和大规模应用。该方法的有效性通过对真实文本数据的实验得到证明，重点是检测生成式人工智能中的上下文变化。我们的结果由公开可用的代码支持，突出了这种基于变形的方法在捕捉传统统计方法经常遗漏的细微漂移方面的优势。此外，我们还在医疗保健领域提供了一个详细的应用示例，展示了该方法在不同领域的潜力。未来的工作将侧重于进一步提高计算效率并探索不同 ML 领域的其他应用。]]></description>
      <guid>https://arxiv.org/abs/2411.02464</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>看到它，思考它，分类：大型多模态模型是小样本时间序列异常分析仪</title>
      <link>https://arxiv.org/abs/2411.02465</link>
      <description><![CDATA[arXiv:2411.02465v1 公告类型：新
摘要：由于各个行业的时间序列数据快速增长，时间序列异常检测 (TSAD) 变得越来越重要。例如，Web 服务数据中的异常可能预示着系统故障或服务器故障等重大事件，需要及时检测和响应。然而，大多数现有的 TSAD 方法严重依赖手动特征工程或需要大量标记的训练数据，同时提供有限的可解释性。为了应对这些挑战，我们引入了一个称为时间序列异常多模态分析器 (TAMA) 的开创性框架，它利用大型多模态模型 (LMM) 的强大功能来增强对时间序列数据中异常的检测和解释。通过将时间序列转换为 LMM 可以有效处理的视觉格式，TAMA 利用少量上下文学习功能来减少对大量标记数据集的依赖。我们的方法通过对多个真实数据集的严格实验得到验证，其中 TAMA 在 TSAD 任务中始终优于最先进的方法。此外，TAMA 提供丰富的基于自然语言的语义分析，为检测到的异常的性质提供更深入的见解。此外，我们贡献了首批开源数据集之一，其中包括异常检测标签、异常类型标签和上下文描述，促进了这一关键领域的更广泛探索和进步。最终，TAMA 不仅在异常检测方面表现出色，而且还提供了一种全面的方法来了解异常的根本原因，通过创新方法和见解推动 TSAD 向前发展。]]></description>
      <guid>https://arxiv.org/abs/2411.02465</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无论人口统计学如何，追求无害的罗尔斯公平</title>
      <link>https://arxiv.org/abs/2411.02467</link>
      <description><![CDATA[arXiv:2411.02467v1 公告类型：新
摘要：出于隐私和安全方面的考虑，群体公平性方面的最新进展主张无论人口统计信息如何，都要进行模型训练。然而，大多数方法仍然需要事先了解人口统计数据。在这项研究中，我们探索了在没有向训练集提供先前人口统计数据的情况下实现公平而不损害其效用的潜力，即 \emph{无害的罗尔斯公平}。我们确定，这种不需要先前人口统计信息的公平要求会促使训练损失呈现狄拉克德尔塔分布。为此，我们提出了一种简单但有效的方法，称为 VFair，以最小化最佳经验损失集内的训练损失方差。然后通过一种在损失和梯度维度上运行的定制动态更新方法优化这个问题，将模型引向相对公平的解决方案，同时保留其完整的效用。我们的实验结果表明，回归任务（文献中相对较少探索）可以通过 VFair 实现显著的公平性改进，而不管之前是否有任何改进，而分类任务通常由于其量化效用测量而无法实现。我们方法的实现可在 \url{https://github.com/wxqpxw/VFair} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.02467</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>能量感知动态神经推理</title>
      <link>https://arxiv.org/abs/2411.02471</link>
      <description><![CDATA[arXiv:2411.02471v1 公告类型：新
摘要：对网络边缘以外智能应用的需求不断增长，再加上对可持续运行的需求，正在推动深度学习 (DL) 算法无缝集成到能量受限甚至能量收集的终端设备中。然而，环境能源的随机性往往导致收集率不足，无法满足推理的能量要求，并导致能量无关系统的性能显著下降。为了解决这个问题，我们考虑了一种配备能量收集器和有限容量能量存储的设备自适应推理系统。然后，我们允许设备按需降低运行时执行成本，方法是在不同大小的神经网络之间切换（称为多模型选择 (MMS)），或者在中间层启用早期预测（称为早期退出 (EE)。然后根据能量存储和收集过程状态动态选择要使用的模型或退出点。我们还研究了将预测置信度整合到决策过程中的有效性。我们推导出一个原则性策略，并为置信度感知和置信度不可知控制器提供理论保证。此外，在多出口网络中，我们通过设计一个基于强化学习的轻量级控制器，研究了逐步、逐个出口地做出决策的优势。实验结果表明，随着环境能量速率的增加，与能量感知置信度不可知控制方案相比，能量感知和置信度感知控制方案的准确度提高了约 5%。增量方法可以实现更高的准确度，尤其是当能量存储容量相对于推理模型的能量消耗有限时。]]></description>
      <guid>https://arxiv.org/abs/2411.02471</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于脑图超分辨率的强拓扑保持 GNN</title>
      <link>https://arxiv.org/abs/2411.02525</link>
      <description><![CDATA[arXiv:2411.02525v1 公告类型：新
摘要：脑图超分辨率 (SR) 是网络神经科学中一项尚未得到充分探索但高度相关的任务。它避免了昂贵且耗时的医学影像数据收集、准备和处理的需要。当前的 SR 方法利用图神经网络 (GNN)，因为它们能够原生处理图结构数据集。然而，大多数 GNN 执行节点特征学习，这有两个显著的​​限制：(1) 它们需要计算成本高昂的方法来学习能够推断连接强度或边缘特征的复杂节点特征，而这些特征无法扩展到更大的图；(2) 节点空间中的计算无法充分捕捉高阶大脑拓扑，如团块和中心。然而，许多研究表明，脑图拓扑对于识别阿尔茨海默病和帕金森病等各种神经退行性疾病的发病和存在至关重要。受这些挑战和应用的启发，我们提出了 STP-GSR 框架。这是第一个在高阶拓扑空间中执行表示学习的图形 SR 架构。具体来说，使用图论中的原始对偶图公式，我们开发了一种从低分辨率 (LR) 脑图的边缘空间到高分辨率 (HR) 对偶图的节点空间的有效映射。这种方法确保此对偶图上的节点级计算自然对应于我们 HR 脑图上的边缘级学习，从而在我们的框架内实现强大的拓扑一致性。此外，我们的框架与 GNN 层无关，可以轻松地从较小、可扩展的 GNN 中学习，从而降低计算要求。我们全面评估了七个关键拓扑度量的框架，并观察到它明显优于以前最先进的方法和基线。]]></description>
      <guid>https://arxiv.org/abs/2411.02525</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型量化技术的综合研究</title>
      <link>https://arxiv.org/abs/2411.02530</link>
      <description><![CDATA[arXiv:2411.02530v1 公告类型：新
摘要：自从 Transformer 模型流行起来并展示出在 AI 中的出色性能以来，大型语言模型 (LLM) 已在学术界和工业界得到广泛研究和使用。然而，LLM 的计算需求巨大，而运行它们所需的能源资源往往有限。例如，像 GPT-3 这样的流行模型，有 1750 亿个参数和 350 GB 的存储要求，对于在资源受限的物联网设备和嵌入式系统上部署提出了重大挑战。这些系统通常缺乏处理如此大模型的计算能力。量化是一种将模型值的精度降低为一组较小的离散值的技术，它通过减小 LLM 的大小和加速推理提供了一种有希望的解决方案。在这项研究中，我们对机器学习领域的量化技术进行了全面的分析，特别关注它们在 LLM 中的应用。我们首先探索量化的数学理论，然后回顾常见的量化方法及其实现方式。此外，我们研究了应用于 LLM 的几种著名量化方法，详细介绍了它们的算法和性能结果。]]></description>
      <guid>https://arxiv.org/abs/2411.02530</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphXAIN：解释图神经网络的叙述</title>
      <link>https://arxiv.org/abs/2411.02540</link>
      <description><![CDATA[arXiv:2411.02540v1 公告类型：新
摘要：图神经网络 (GNN) 是一种强大的图结构数据机器学习技术，但它们带来了可解释性挑战，尤其是对于非专家用户而言。现有的 GNN 解释方法通常会产生子图和特征重要性分数等技术输出，这些输出不易理解。基于社会科学和其他可解释 AI (XAI) 方法的最新见解，我们提出了 GraphXAIN，这是一种解释 GNN 做出的个体预测的自然语言叙述。我们提出了一种与模型无关和与解释器无关的 XAI 方法，该方法通过生成 GraphXAIN、使用大型语言模型 (LLM) 并集成图数据、GNN 的个体预测、解释子图和特征重要性来补充图解释器。我们定义了 XAI 叙述和 XAI 描述，突出了它们的区别，并强调了叙述原则在有效解释中的重要性。通过结合自然语言叙述，我们的方法支持图形从业者和非专家用户，与可解释性的社会科学研究保持一致，并增强用户对复杂 GNN 模型的理解和信任。我们在现实世界的图形数据集上展示了 GraphXAIN 的功能，说明了与传统图形解释器输出或其他描述性解释方法相比，其生成的叙述如何有助于理解。]]></description>
      <guid>https://arxiv.org/abs/2411.02540</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用并发假设增强图神经网络在大规模交通事件分析中的作用</title>
      <link>https://arxiv.org/abs/2411.02542</link>
      <description><![CDATA[arXiv:2411.02542v1 公告类型：新
摘要：尽管最近在减少道路交通事故死亡率方面取得了进展，但持续居高的交通相关死亡率凸显了改进安全干预措施的必要性。我们的研究利用美国 49 个州的大规模基于图的全国道路网络数据，首先从直观观察中提出并发假设，表明事故发生在道路网络内的相邻节点的可能性很大。为了量化这一现象，我们引入了两个新指标，即平均邻居碰撞密度 (ANCD) 和平均邻居碰撞连续性 (ANCC)，随后在统计测试中使用它们来严格验证该假设。在此基础上，我们提出了并发先验 (CP) 方法，这是一种强大的方法，旨在增强一般图神经网络 (GNN) 模型在半监督交通事故预测任务中的预测能力。我们的方法允许 GNN 通过标记化合并并发事件信息（如假设中所述），且额外参数可忽略不计。
利用美国各州和城市的真实数据进行的大量实验表明，将 CP 集成到 12 个最先进的 GNN 架构中可带来显著的改进，F1 得分可提高 3% 至 13%，AUC 指标可提高 1.3% 至 9%。代码可在 https://github.com/xiwenc1/Incident-GNN-CP 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.02542</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预训练的 Transformer 可在上下文中高效学习低维目标函数</title>
      <link>https://arxiv.org/abs/2411.02544</link>
      <description><![CDATA[arXiv:2411.02544v1 公告类型：新
摘要：Transformers 可以从示例演示中有效地进行上下文学习。大多数现有的理论分析研究了 Transformers 对线性函数类的上下文学习 (ICL) 能力，其中通常表明预训练损失的最小化器在最小二乘目标上实现了一个梯度下降步骤。然而，这种简化的线性设置可能并没有证明 ICL 的统计效率，因为预训练的 Transformer 在测试提示上的表现并不优于直接解决线性回归。在本文中，我们通过具有非线性 MLP 层的变换器研究了非线性函数类的 ICL：给定一类 \textit{单索引} 目标函数 $f_*(\boldsymbol{x}) = \sigma_*(\langle\boldsymbol{x},\boldsymbol{\beta}\rangle)$，其中索引特征 $\boldsymbol{\beta}\in\mathbb{R}^d$ 来自 $r$ 维子空间，我们表明，通过梯度下降优化的非线性变换器（其预训练样本复杂度取决于链接函数 $\sigma_*$ 的 \textit{信息指数}）在上下文中学习 $f_*$，其提示长度仅取决于目标函数 $r$ 分布的维数；相反，任何在测试提示上直接学习 $f_*$ 的算法都会产生与环境维度 $d$ 成比例的统计复杂度。我们的结果强调了预训练变换器对函数类低维结构的适应性，这使得样本高效的 ICL 优于只能访问上下文数据的估计器。]]></description>
      <guid>https://arxiv.org/abs/2411.02544</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用风险损失功能增强变压器的风险评估</title>
      <link>https://arxiv.org/abs/2411.02558</link>
      <description><![CDATA[arXiv:2411.02558v1 公告类型：新 
摘要：在金融领域，精确的风险评估工具对于决策至关重要。最近的研究挑战了传统网络损失函数（如均方误差 (MSE)）是否足够的观点，尤其是在极端风险条件下，这些条件可能导致市场动荡期间的重大损失。Transformers 和基于 Transformer 的模型因其在时间序列相关预测中的出色表现而广泛应用于金融预测。然而，这些模型通常对极端风险缺乏敏感性，并且经常低估巨大的财务损失。为了解决这个问题，我们引入了一种新的损失函数，即 Loss-at-Risk，它将风险价值 (VaR) 和条件风险价值 (CVaR) 纳入 Transformer 模型。这种集成使 Transformer 模型能够识别潜在的极端损失，并进一步提高其处理高风险财务决策的能力。此外，我们利用高度波动的金融数据集进行了一系列实验，以证明我们的风险损失函数可以提高 Transformers 的风险预测和管理能力，同时又不会损害其决策准确性或效率。结果表明，在训练过程中整合风险感知指标可以增强 Transformers 的风险评估能力，同时保留其在不同场景中决策和推理的核心优势。]]></description>
      <guid>https://arxiv.org/abs/2411.02558</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态权重调整深度 Q 网络以实现实时环境适应</title>
      <link>https://arxiv.org/abs/2411.02559</link>
      <description><![CDATA[arXiv:2411.02559v1 公告类型：新
摘要：深度强化学习在为复杂任务生成有效解决方案方面表现出色。然而，其功效往往受到静态训练模式和对稳定环境中大量数据的严重依赖的限制。为了解决这些缺点，本研究探索将动态权重调整集成到深度 Q 网络 (DQN) 中以增强其适应性。我们通过修改经验重放中的采样概率来实现这些调整，使模型更加关注实时环境反馈和性能指标所指示的关键转换。我们为 DQN 设计了一种新颖的交互式动态评估方法 (IDEM)，该方法通过根据环境反馈和学习进度对重要转换进行优先排序，成功驾驭动态环境。此外，当面对环境条件的快速变化时，IDEM-DQN 与基线方法相比表现出更好的性能。我们的结果表明，在需要快速适应的情况下，IDEM-DQN 可以更有效地概括和稳定学习。在各种环境下进行的大量实验证实，IDEM-DQN 的表现优于标准 DQN 模型，尤其是在频繁且不可预测的变化的环境中。]]></description>
      <guid>https://arxiv.org/abs/2411.02559</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>算法公平性的交叉性问题</title>
      <link>https://arxiv.org/abs/2411.02569</link>
      <description><![CDATA[arXiv:2411.02569v1 公告类型：新
摘要：算法公平性中尚未解决的一个挑战是交叉性问题，即在多个群体的交叉点上实现公平性——并验证这种公平性是否已经实现。由于交叉群体往往较小，因此验证模型是否公平提出了统计和道德方法论方面的挑战。本文 (1) 阐明了算法公平性中的交叉性问题，(2) 制定了必要条件以阐明问题背后的挑战并指导寻找潜在解决方案，(3) 通过使用简单的假设检验勾勒出一个提案来说明必要条件和潜在解决方案，以及 (4) 部分地根据所提出的需求对该提案进行实证评估。]]></description>
      <guid>https://arxiv.org/abs/2411.02569</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ViTally Consistent：扩展细胞显微镜的生物表征学习</title>
      <link>https://arxiv.org/abs/2411.02572</link>
      <description><![CDATA[arXiv:2411.02572v1 公告类型：新摘要：大规模细胞显微镜筛选用于药物发现和分子生物学研究，以研究数百万种化学和遗传扰动对细胞的影响。为了在下游分析中使用这些图像，我们需要能够将每张图像映射到一个特征空间中的模型，该特征空间可以一致地表示不同的生物表型，即具有相似生物效应的扰动具有相似的表示。在这项工作中，我们提出了迄今为止最大的细胞显微镜数据基础模型，即一个新的 19 亿参数 ViT-G/8 MAE，该模型在超过 80 亿张显微镜图像裁剪上进行了训练。与之前发布的 ViT-L/8 MAE 相比，我们的新模型在遗传扰动的线性可分离性方面提高了 60%，并在全基因组生物关系回忆和重复一致性基准上获得了最佳的整体性能。除了扩展之外，我们还开发了两种提高性能的关键方法：(1) 在精选的多样化数据集上进行训练；以及 (2) 使用生物学激励的线性探测任务在每个转换器块中搜索全基因组筛选的最佳候选表示。我们发现，许多在自然图像或显微镜图像上进行预训练的自监督视觉转换器在其中间块中产生的显微镜图像的生物学意义显著高于其通常使用的最终块。更广泛地说，我们的方法和结果为成功构建大规模生物数据基础模型的一般策略提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2411.02572</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>