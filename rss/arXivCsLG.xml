<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 06 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>神经架构搜索的延迟预测器</title>
      <link>https://arxiv.org/abs/2403.02446</link>
      <description><![CDATA[arXiv:2403.02446v1 公告类型：新
摘要：神经网络（NN）的有效部署需要精度和延迟的共同优化。例如，硬件感知神经架构搜索已用于自动查找满足特定硬件设备上的延迟约束的神经网络架构。这些搜索算法的核心是预测模型，旨在为候选神经网络架构提供硬件延迟估计。最近的研究表明，通过在一些具有许多样本的 \textit{training} 设备上进行预训练，然后将预测器转移到 \textit{test} （目标）设备上，可以大大提高这些预测模型的样本效率。迁移学习和元学习方法已用于此目的，但通常表现出显着的性能变化。此外，现有延迟预测器的评估主要是在手工制作的训练/测试设备集上完成的，这使得很难确定构成稳健且通用的延迟预测器的设计特征。为了解决这些问题，我们引入了一套全面的延迟预测任务，这些任务是通过硬件设备集的自动分区以原则性的方式获得的。然后，我们设计一个通用延迟预测器来全面研究（1）预测器架构，（2）NN样本选择方法，（3）硬件设备表示，以及（4）NN操作编码方案。基于我们研究的结论，我们提出了一种端到端延迟预测器训练策略，该策略在 12 个困难延迟预测任务中的 11 个上优于现有方法，延迟预测平均提高了 22.5%，最高可达 87.6%在最艰巨的任务上。我们的 HW-Aware NAS 专注于延迟预测，报告显示挂钟时间加速了 5.8 美元\倍$。我们的代码可以在 \href{https://github.com/abdelfattah-lab/nasflat_latency}{https://github.com/abdelfattah-lab/nasflat\_latency} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2403.02446</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>通过约束直接偏好优化增强 LLM 安全性</title>
      <link>https://arxiv.org/abs/2403.02475</link>
      <description><![CDATA[arXiv:2403.02475v1 公告类型：新
摘要：大型语言模型（LLM）的能力迅速增强，迫切需要使人工智能系统与不同的人类偏好保持一致，以同时增强其实用性和安全性，尽管这些目标经常存在冲突。为了解决这个重要问题，一种有前途的方法是通过人类反馈的约束强化学习（RLHF）框架在微调阶段强制执行安全约束。然而，这种方法的计算成本很高并且通常不稳定。在这项工作中，我们引入了约束 DPO (C-DPO)，这是最近提出的直接偏好优化 (DPO) 方法的一种新颖扩展，用于微调 LLM，既高效又轻量。通过整合双梯度下降和 DPO，我们的方法在不使用强化学习的情况下确定了有用和无害之间的近乎最佳的权衡。根据经验，我们的方法为法学硕士提供了 DPO 中所缺少的安全保证，同时与最近提出的安全 RLHF 方法相比，在相同的安全约束下获得了更高的回报。
  警告：本文包含可能令人反感或有害的示例数据。]]></description>
      <guid>https://arxiv.org/abs/2403.02475</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>SoK：联邦遗忘的挑战和机遇</title>
      <link>https://arxiv.org/abs/2403.02437</link>
      <description><![CDATA[arXiv:2403.02437v1 公告类型：新
摘要：联邦学习（FL）于 2017 年推出，促进了非信任方之间的协作学习，无需各方明确共享数据。这允许对用户数据进行模型训练，同时尊重 GDPR 和 CPRA 等隐私法规。然而，新出现的隐私要求可能会要求模型所有者能够\emph{忘记}一些学习到的数据，例如，当数据所有者或执法部门要求时。这催生了一个活跃的研究领域，称为\emph{机器取消学习}。在 FL 的背景下，许多为在集中设置中忘却学习而开发的技术并不是那么适用！这是由于集中式学习和分布式学习之间的独特差异，特别是 FL 中的交互性、随机性、异质性和有限的可访问性。作为回应，最近的工作重点是开发适合 FL 的遗忘机制。
  这篇 SoK 论文旨在深入研究 \emph{federated unlearning} 文献，旨在确定这一新兴领域的研究趋势和挑战。通过对 FL 取消学习（自 2020 年以来）上发表的论文进行仔细分类，我们的目标是查明联合取消学习的独特复杂性，强调直接应用集中式取消学习方法的局限性。我们比较了现有的关于影响消除和性能恢复的联合遗忘方法，比较了它们的威胁模型和假设，并讨论了它们的含义和局限性。例如，我们从多个角度分析 FL 去学习研究的实验设置，包括数据异质性及其模拟、用于演示的数据集和评估指标。我们的工作旨在为未来联合取消学习的研究提供见解和建议。]]></description>
      <guid>https://arxiv.org/abs/2403.02437</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>使用可解释的人工智能导致预测异常的根源</title>
      <link>https://arxiv.org/abs/2403.02439</link>
      <description><![CDATA[arXiv:2403.02439v1 公告类型：新
摘要：本文提出了一种可解释人工智能（XAI）的新颖应用，用于从根本上解决从用户参与数据中学习的机器学习模型中导致性能下降的问题。在此类系统中，单个功能损坏可能会导致级联功能、标签和概念漂移。我们已成功应用该技术来提高个性化广告中使用的模型的可靠性。此类系统的性能下降表现为模型中的预测异常。这些模型通常使用数百个实时数据处理管道生成的或从其他上游模型派生的特征进行连续训练。这些管道中的任何一个故障或任何上游模型的不稳定都可能导致特征损坏，从而导致模型的预测输出偏离实际输出，并且训练数据被损坏。特征与预测输出之间的因果关系很复杂，并且由于系统的规模和动态性，根本原因具有挑战性。我们演示了全局特征重要性分布的时间变化如何有效地隔离预测异常的原因，并且比模型到特征相关方法具有更好的召回率。即使使用简单的基于扰动的方法来近似局部特征重要性并聚合数千个示例，该技术似乎也是有效的。我们发现这种技术是一种与模型无关、廉价且有效的方法来监控生产中的复杂数据管道，并部署了一个系统来持续分析持续训练模型的全局特征重要性分布。]]></description>
      <guid>https://arxiv.org/abs/2403.02439</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>从零到英雄：原始初始条件下的局部曲率如何远离糟糕的最小值</title>
      <link>https://arxiv.org/abs/2403.02418</link>
      <description><![CDATA[arXiv:2403.02418v1 公告类型：新
摘要：我们研究了非凸和高维环境中梯度下降的优化动力学，重点关注相位检索问题作为复杂损失景观的案例研究。我们首先研究高维极限，其中数据的数量 $M$ 和维度 $N$ 在固定信噪比 $\alpha = M/N$ 下都将趋于无穷大。通过分析优化过程中局部曲率的变化，我们发现对于中间 $\alpha$，Hessian 矩阵在下降的第一个状态中显示出指向良好最小值的向下方向，然后在最后陷入不良最小值。因此，在梯度下降将系统带入无信息迷宫之前，局部景观最初是良性且信息丰富的。两种状态之间的转换与时间相关的 Hessian 矩阵中的 BBP 型阈值相关。通过理论分析和数值实验，我们表明，在实际情况下，即对于有限但甚至非常大的$N$，通过相位检索中的梯度下降成功优化是通过在达到坏最小值之前先下降到好的最小值来实现的。这种机制解释了为什么在对应于高维限制的算法转换之前就获得了成功的恢复。从技术上讲，这与大 $N$ 处的算法转换相对于 $N\to\infty$ 限制中预期的算法转换的强对数校正相关。我们的分析揭示了这种促进有限大维度中梯度下降动力学的新机制，也强调了光谱属性良好初始化对于复杂高维景观优化的重要性。]]></description>
      <guid>https://arxiv.org/abs/2403.02418</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>您需要更多的 LLM 电话吗？复合推理系统的扩展定律</title>
      <link>https://arxiv.org/abs/2403.02419</link>
      <description><![CDATA[arXiv:2403.02419v1 公告类型：新
摘要：语言任务中的许多最新成果都是使用执行多个大型语言模型（LLM）调用并聚合其响应的复合系统取得的。然而，人们对 LLM 调用的数量（例如，当要求 LLM 多次回答每个问题并达成共识时）如何影响这种复合系统的性能知之甚少。在本文中，我们启动了复合推理系统标度律的研究。我们从理论上和经验上分析了 LLM 调用的数量如何影响单层投票推理系统的性能——这是最简单的复合系统之一，它通过多数投票聚合 LLM 响应。我们凭经验发现，令人惊讶的是，在多种语言任务中，投票推理系统的性能首先随着 LLM 调用数量的变化而增加，但随后又下降。我们的理论结果表明，这种非单调性是由于任务中查询难度的多样性造成的：更多的 LLM 调用会导致“简单”查询的性能更高，但“困难”查询的性能较低，并且当以下情况出现时，就会出现非单调行为：一个任务包含两种类型的查询。然后，这种洞察力使我们能够从少量样本中计算出最大化系统性能的 LLM 调用数量，并定义投票推理系统的缩放法则。实验表明，我们的缩放定律可以预测投票推理系统的性能并找到进行 LLM 调用的最佳数量。]]></description>
      <guid>https://arxiv.org/abs/2403.02419</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>面向多元时间序列异常检测的高效深度自动编码器</title>
      <link>https://arxiv.org/abs/2403.02429</link>
      <description><![CDATA[arXiv:2403.02429v1 公告类型：新
摘要：多元时间序列异常检测是许多工业和研究应用中的关键问题。例如，及时检测异常可以防止制造过程中的缺陷和网络物理系统中的故障。深度学习方法因其在复杂多变量数据分析方面的准确性和鲁棒性而受到青睐。然而，一个关键方面是能够及时提取预测，以适应不同应用程序中的实时要求。就深度学习模型而言，模型缩减对于在时间和内存限制有限的实时系统中实现最佳结果极其重要。在本文中，我们通过提出一种新颖的深度自动编码器压缩方法来解决这个问题，该方法涉及三个关键因素。首先，剪枝减少了权重的数量，同时通过识别高稀疏性水平的快速搜索过程来防止准确性的灾难性下降。其次，线性和非线性量化通过减少每个权重的位数来降低模型复杂性。这三个方面的综合贡献允许通过删除权重子集（修剪）并减少其位宽（量化）来减小模型大小。因此，压缩模型在高度受限的硬件环境中更快、更容易采用。在流行的多元异常检测基准上进行的实验表明，我们的方法能够实现显着的模型压缩率（80% 到 95% 之间），而不会显着降低异常检测性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02429</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>用于工业 4.0 应用中预测优化的新型混合特征重要性和特征交互检测框架</title>
      <link>https://arxiv.org/abs/2403.02368</link>
      <description><![CDATA[arXiv:2403.02368v1 公告类型：新
摘要：先进的机器学习算法越来越多地用于在工业 4.0 中提供基于数据的预测和决策支持。然而，现有模型所达到的预测精度不足以保证在实际应用中的实际实施。这是因为并非现实数据集中存在的所有特征都与正在进行的预测分析直接相关。因此，仔细结合选定的特征有可能对结果产生重大的积极影响。为了解决研究空白，本文提出了一种新颖的混合框架，该框架结合了特征重要性检测器 - 局部可解释模型不可知解释（LIME）和特征交互检测器 - 神经交互检测（NID），以提高预测精度。通过应用所提出的框架，可以消除不必要的特征，并对交互进行编码以生成更有利于预测目的的数据集。随后，部署所提出的模型来完善铸造加工中电力消耗的预测。实验结果显示，R2 分数提高了 9.56%，均方根误差降低了 24.05%。]]></description>
      <guid>https://arxiv.org/abs/2403.02368</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>OTClean：使用最佳传输来清除条件独立性违规的数据</title>
      <link>https://arxiv.org/abs/2403.02372</link>
      <description><![CDATA[arXiv:2403.02372v1 公告类型：新
摘要：确保条件独立（CI）约束对于开发公平且值得信赖的机器学习模型至关重要。在本文中，我们介绍了 \sys，一个利用最佳传输理论在 CI 约束下进行数据修复的框架。最优传输理论提供了一个严格的框架来测量概率分布之间的差异，从而确保对数据效用的控制。我们将有关 CI 的数据修复问题表述为二次约束线性程序 (QCLP)，并提出了一种替代方法来解决其问题。然而，由于与计算最佳传输距离（例如 Wasserstein 距离）相关的计算成本，该方法面临可扩展性问题。为了克服这些可扩展性挑战，我们将问题重新定义为正则化优化问题，使我们能够开发受 Sinkhorn 矩阵缩放算法启发的迭代算法，该算法可以有效地处理高维和大规模数据。通过大量的实验，我们证明了我们提出的方法的功效和效率，展示了它们在现实世界数据清理和预处理任务中的实用性。此外，我们还提供了与传统方法的比较，强调了我们的技术在保留数据实用性方面的优越性，同时确保遵守所需的 CI 约束。]]></description>
      <guid>https://arxiv.org/abs/2403.02372</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>超复杂空间中时间敏感关系的时态知识图补全</title>
      <link>https://arxiv.org/abs/2403.02355</link>
      <description><![CDATA[arXiv:2403.02355v1 公告类型：新
摘要：时态知识图补全（TKGC）旨在填充特定时间给定时态知识图中缺失的事实。在真实或复杂空间中运行的现有方法在这项任务中表现出了良好的性能。本文通过在超复杂空间中引入更具表现力的 TKGC 四元数表示，超越了传统方法。与现有的基于四元数的方法不同，我们的研究重点是捕获时间敏感关系而不是时间感知实体。具体来说，我们通过时间感知旋转和周期性时间平移来建模时间敏感关系，有效捕获复杂的时间变化。此外，我们从理论上证明了我们的方法模拟对称、不对称、逆、组合和演化关系模式的能力。对公共数据集的综合实验验证了我们提出的方法在 TKGC 领域实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02355</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>对比云边模型解耦实现异构联邦学习的最优定制架构</title>
      <link>https://arxiv.org/abs/2403.02360</link>
      <description><![CDATA[arXiv:2403.02360v1 公告类型：新
摘要：联邦学习作为一种有前途的分布式学习范式，可以跨多个网络边缘客户端协作训练全局模型，而无需中央数据收集。然而，边缘数据分布的异质性将模型拖向局部最小值，这可能远离全局最优值。这种异构性通常会导致收敛缓慢和大量的通信开销。为了解决这些问题，我们提出了一种名为 FedCMD 的新型联邦学习框架，这是一种针对云边缘支持的联邦学习量身定制的模型解耦，它将深度神经网络分为用于捕获云中共享表示的主体和用于迁移数据异构性的个性化头部。我们的动机是，通过深入研究选择不同神经网络层作为个性化头部的性能，我们发现在当前研究中严格指定最后一层作为个性化头部并不总是最佳的。相反，有必要通过考虑相邻层之间的表示差异来动态选择能够最大化训练性能的个性化层。为了找到最佳的个性化层，我们利用每层的低维表示来对比特征分布转移，并引入基于 Wasserstein 的层选择方法，旨在识别个性化的最佳匹配层。此外，针对FedCMD的实际应用，基于所选的个性化层提出了加权全局聚合算法。与九个最先进的解决方案相比，对十个基准的广泛实验证明了我们的解决方案的效率和卓越性能。所有代码和结果均可在 https://github.com/elegy112138/FedCMD 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.02360</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>解决长尾噪声标签学习问题：考虑标签稀有性的标签翻新的两阶段解决方案</title>
      <link>https://arxiv.org/abs/2403.02363</link>
      <description><![CDATA[arXiv:2403.02363v1 公告类型：新
摘要：现实世界的数据集通常表现出噪声标签和类别不平衡，例如长尾分布。虽然之前的研究通过区分噪声样本和干净样本来解决这个问题，但依赖基于噪声长尾数据的预测信息会带来潜在的错误。为了克服先前工作的局限性，我们通过将软标签翻新与多专家集成学习相结合，引入了一种有效的两阶段方法。在鲁棒软标签翻新的第一阶段，我们通过对比学习获得无偏特征，使用经过精心设计的平衡耐噪交叉熵（BANC）损失训练的分类器进行初步预测。在第二阶段，我们的标签翻新方法被应用于获得用于多专家集成学习的软标签，为长尾噪声标签问题提供了原则性的解决方案。跨多个基准进行的实验验证了我们的方法的优越性，考虑标签稀有性（LR^2）的标签翻新，在模拟噪声 CIFAR-10 和 CIFAR-100 长尾数据集以及在真实噪声长尾数据集 Food-101N 和 Animal-10N 上分别达到 77.74% 和 81.40%，超越了现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2403.02363</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>ATP：通过关注顶级主键实现快速 LLM 服务</title>
      <link>https://arxiv.org/abs/2403.02352</link>
      <description><![CDATA[arXiv:2403.02352v1 公告类型：新
摘要：我们提出了一种具有线性复杂度的新注意力机制 ATP，它将 \textbf{A} 注意力固定在 \textbf{T}op \textbf{P} 主要密钥上，而不是每个单独的令牌上。特别是，ATP 是由一个重要的观察驱动的，即输入序列通常是低秩的，即输入序列可以由几个主要碱基表示。因此，ATP 不是直接迭代所有输入标记，而是将输入转换为正交空间并仅计算顶部主基（键）的注意力。由于观察到输入序列中的低秩结构，ATP 能够使用几个主键捕获输入序列中的语义关系。此外，注意力复杂度从\emph{quadratic}降低到\emph{线性}，而不会导致性能明显下降。 ATP 进一步降低了具有低秩输入的其他线性层的复杂性，与之前仅针对注意力模块的工作相比，速度更快。我们对各种模型（例如 BERT 和 Llama）的评估表明，与标准注意力机制相比，ATP 以低得多的计算和内存复杂度实现了相当的精度。特别是，ATP 在仅使用 $1/2$ 主密钥时几乎没有损失准确性，并且在使用 $1/4$ 主密钥时仅导致约 $2\%$ 准确性下降。]]></description>
      <guid>https://arxiv.org/abs/2403.02352</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>用于空气质量推断的时空场神经网络</title>
      <link>https://arxiv.org/abs/2403.02354</link>
      <description><![CDATA[arXiv:2403.02354v1 公告类型：新
摘要：空气质量推断问题旨在利用有限数量观测点的历史数据来推断未知位置的空气质量指数。考虑到站点维护成本较高导致数据稀疏，良好的推理算法可以有效节省成本并细化数据粒度。虽然时空图神经网络在这个问题上取得了巨大的进展，但它们对现实的非欧几里得和离散数据结构建模限制了其潜力。在这项工作中，我们首次尝试结合两种不同的时空视角、场和图，提出一种新模型——时空场神经网络及其相应的新框架——金字塔推理。大量实验验证了我们的模型在中国大陆全国空气质量推断中取得了最先进的性能，证明了我们提出的模型和框架的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.02354</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>论无数据相似性的联邦学习算法的收敛性</title>
      <link>https://arxiv.org/abs/2403.02347</link>
      <description><![CDATA[arXiv:2403.02347v1 公告类型：新
摘要：传统上依赖数据相似性假设来理解联邦学习方法的收敛行为。不幸的是，这种方法通常需要根据数据相似程度微调步长。当数据相似度较低时，这些小步长会导致联合方法的收敛速度慢得令人无法接受。在本文中，我们提出了一种新颖且统一的框架，用于分析联邦学习算法的收敛性，而无需数据相似性条件。我们的分析集中在一个不等式上，该不等式捕捉了步长对算法收敛性能的影响。通过将我们的定理应用于众所周知的联合算法，我们得出了三种广泛使用的步长计划的精确表达式：固定步长、递减步长和步长衰减步长，它们与数据相似性条件无关。最后，我们对这些联邦学习算法的性能进行了综合评估，采用所提出的步长策略在不同数据相似性条件下的基准数据集上训练深度神经网络模型。我们的研究结果表明收敛速度和整体性能显着提高，标志着联邦学习研究的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2403.02347</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:17 GMT</pubDate>
    </item>
    </channel>
</rss>