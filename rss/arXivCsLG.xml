<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>教语言模型通过加强学习来批评</title>
      <link>https://arxiv.org/abs/2502.03492</link>
      <description><![CDATA[ARXIV：2502.03492V1公告类型：新 
摘要：教导大语模型（LLMS）批评和完善其产出对于可以迭代改进的建筑系统至关重要，但是它在根本上受到提供准确的判断和可行建议的能力的限制。在这项工作中，我们研究了代码生成的LLM评论家，并提出$ \ texttt {ctrl} $，$ \ texttt {c} $ ritic $ \ texttt {t} $通过$ \ texttt {r texttt {r} \ texttt {l} $ ginning，该奖励模型生成反馈，该反馈最大程度地提高了固定发电机模型的校正性能，而无需人工监督。我们的结果表明，经过$ \ texttt {ctrl} $培训的评论家显着提高了通过率，并减轻基本和更强的发电机模型的复合错误。此外，我们表明这些评论家模型充当准确的生成奖励模型，并通过迭代批判性革命进行测试时间扩展，从而在挑战性的代码生成基准中实现了高达106.1％的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2502.03492</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>蒙版扩散模型采样的路径计划</title>
      <link>https://arxiv.org/abs/2502.03540</link>
      <description><![CDATA[ARXIV：2502.03540V1公告类型：新 
摘要：在本文中，我们研究了在掩盖扩散模型（MDMS）推断期间如何揭示令牌的顺序会影响生成质量。我们得出了一个扩展的证据下限（ELBO），该证据介绍了计划者，负责选择哪些代币在每个步骤中揭示哪些令牌。我们的分析表明，替代揭露策略可以改善生成性能。基于这些见解，我们提出了路径计划（P2），这是一个利用预培训的BERT或DENOISER本身指导揭露决策的抽样框架。 P2概括了所有已知的MDM抽样策略，并在不同的领域（包括语言生成，代码生成，故事填充，数学推理，反向诅咒校正）和生物学序列产生（蛋白质和RNA序列）（蛋白质和RNA序列）进行了重大改进。]]></description>
      <guid>https://arxiv.org/abs/2502.03540</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TD-M（PC）$^2 $：通过策略约束改善时间差异MPC</title>
      <link>https://arxiv.org/abs/2502.03550</link>
      <description><![CDATA[ARXIV：2502.03550V1公告类型：新 
摘要：基于模型的增强学习算法结合了基于模型的计划和学习价值/政策先验的知名度/政策，这对其高数据效率和在连续控制中的卓越表现获得了重大认可。但是，我们发现，使用计划者生成的数据直接依靠标准的SAC风格的策略迭代来进行价值学习的现有方法通常会导致\ emph {持续价值高估}。通过理论分析和实验，我们认为这个问题深深植根于数据生成政策之间的结构性策略不匹配，而数据生成策略始终由计划者​​和学到的政策提前进行。为了以极简主义的方式减轻这种不匹配，我们提出了一个策略正规化术语，以减少分布（OOD）查询，从而改善价值学习。我们的方法涉及现有框架之上的最小更改，并且不需要其他计算。广泛的实验表明，所提出的方法通过大边缘（尤其是在61多种类人动物的任务中）提高了基准（例如TD-MPC2）的性能。在https://darthutopian.github.io/tdmpc_square/上查看定性结果。]]></description>
      <guid>https://arxiv.org/abs/2502.03550</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代码仿真作为大语模型中高级任务的代理</title>
      <link>https://arxiv.org/abs/2502.03568</link>
      <description><![CDATA[ARXIV：2502.03568V1公告类型：新 
摘要：许多推理，计划和解决问题的任务具有内在算法的性质：正确模拟每个步骤是正确解决它们的足够条件。我们收集成对的自然主义和综合推理任务，以评估大语言模型（LLM）的能力。虽然自然主义任务通常需要仔细的人工手工制作，但我们表明，在许多情况下，合成数据是一个良好的代理，它更容易在大规模上收集。我们利用编程中的共同构造作为自然主义推理任务的构件的对应物，例如直线程序，包含关键路径的代码以及近似和冗余指令。我们进一步评估了LLMS通过对算法和嵌套循环进行分类问题和重复操作的能力。我们的合成数据集进一步表明，尽管最强大的LLM具有相对强大的执行功能，但该过程却是脆弱的：它会受到记忆的负面影响，并且似乎在很大程度上依赖于模式识别。我们的贡献是基于合成测试LLM的推理能力的基础，作为对手工宣传的问题的可扩展补充。]]></description>
      <guid>https://arxiv.org/abs/2502.03568</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实生成的可控序列编辑</title>
      <link>https://arxiv.org/abs/2502.03569</link>
      <description><![CDATA[ARXIV：2502.03569V1公告类型：新 
摘要：序列模型通过根据给定条件修改序列的部分来生成反事实，从而实现有关“如果”场景的推理。尽管这些模型在有条件生成时表现出色，但它们缺乏对何时何地进行编辑的细粒度控制。现有方法要么关注单变量序列，要么假设干预措施在全球范围内影响整个序列。但是，许多应用需要精确的局部修改，其中仅在指定时间后才生效，并且仅影响同时发生变量的一部分。我们介绍了CLEF，这是一种可控的序列编辑模型，用于有关立即和延迟效应的反事实推理。 CLEF学习了编码如何以及何时干预应影响序列的时间概念。通过这些概念，Clef有选择地编辑相关的时间步骤，同时保留了序列的未影响部分。我们在细胞和患者轨迹数据集上评估CLEF，其中基因调节仅在特定时间步骤中影响某些基因，否则医疗干预措施仅改变了实验室测量的一部分。与基准相比，CLEF的即时序列编辑的MAE最高可提高36.01％。与先前的方法不同，CLEF在未来的任何时间步骤中都可以实现一步生成反事实序列，在MAE中，基本线的表现高达65.71％。对1型糖尿病患者的案例研究表明，CLEF确定了将患者轨迹转移到更健康的预后的临床干预措施。]]></description>
      <guid>https://arxiv.org/abs/2502.03569</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性多元预测的多任务学习方法</title>
      <link>https://arxiv.org/abs/2502.03571</link>
      <description><![CDATA[ARXIV：2502.03571V1公告类型：新 
摘要：对多元时间序列数据的准确预测在许多工程和科学应用中很重要。最新的最新作品忽略了变体之间的相互关系，使用它们的模型在每个变体上独立。这提出了与多元数据正确建模有关的几个研究问题。在这项工作中，我们建议将多元预测视为一个多任务学习问题，从而通过考虑任务梯度及其平衡之间的角度来促进预测的分析。为此，我们分析线性模型以表征任务的行为。我们的分析表明，可以通过将相似变体分组在一起来定义任务，我们通过简单的聚类来实现，该聚类取决于基于相关的相似性。此外，为了平衡任务，我们就其预测错误扩展了梯度。然后，在我们的mtlinear框架中使用线性模型求解每个任务。与强基础相比，我们评估了有关具有挑战性的基准测试方法的方法，并且我们表明它在多变量预测问题上获得了更好的结果或更好的结果。该实施可用：https：//github.com/azencot-group/mtlinear]]></description>
      <guid>https://arxiv.org/abs/2502.03571</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>度量空间中的克隆重量：处理冗余偏差的框架</title>
      <link>https://arxiv.org/abs/2502.03576</link>
      <description><![CDATA[ARXIV：2502.03576V1公告类型：新 
摘要：我们在度量空间中获得了一组元素。元素的分布是任意的，可能是对抗性的。我们可以以抵抗这种（对抗性的）操纵的方式权衡元素吗？这个问题在各种情况下出现。例如，这些元素可以表示数据点，需要强大的域适应性。另外，它们可能代表要汇总为基准的任务。或在投票建议申请中有关个人政治意见的问题。本文介绍了解决此类问题的理论框架。我们提出了防克隆的表示作为解决方案概念。这些函数分布在集合的元素上的重要性，以使其权重（其中一些）的相似对象（``克隆&#39;&#39;）共享（其中一些），从而避免了其多重性引入的潜在偏见。我们的框架扩展了最大的不确定性原理，以适应一般的度量空间，并包括一组公理 - 对称性，连续性和防弹性 - 可指导代表功能的构建。最后，我们解决了在欧几里得空间的重要情况下满足您公理的表示功能的存在，并提出了一种用于其构建的通用方法。]]></description>
      <guid>https://arxiv.org/abs/2502.03576</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督域适应的Stein差异</title>
      <link>https://arxiv.org/abs/2502.03587</link>
      <description><![CDATA[ARXIV：2502.03587V1公告类型：新 
摘要：无监督的域适应（UDA）利用标签源数据集的信息来提高相关但未标记的目标数据集的准确性。 UDA的一种常见方法是通过最大程度地减少其数据分布之间的距离来对齐表示形式。先前的方法采用了距离，例如瓦斯坦距离和最大平均差异。但是，当目标数据明显稀缺时，这些方法的有效性较小。 Stein差异是分布之间的不对称距离，仅通过其得分函数依赖一个分布。在本文中，我们提出了一种新颖的\ ac {uda}方法，该方法使用Stein差异来测量源和目标域之间的距离。我们使用非内分和内核的Stein差异来开发学习框架。从理论上讲，我们为概括误差提供了上限。数值实验表明，我们的方法在只有少量的目标数据可用时，使用其他域差异量度优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.03587</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>二重Zofo：有效LLM微调和元训练的桥接参数效率和零级技术</title>
      <link>https://arxiv.org/abs/2502.03604</link>
      <description><![CDATA[ARXIV：2502.03604V1公告类型：新 
摘要：使用一阶（FO）优化器的微调预训练的大型语言模型（LLM）提出了重大的计算挑战。已经提出了参数有效的微调方法（PEFT）方法来解决这些挑战，通过冷冻大多数模型参数并仅训练一个小子集。尽管PEFT是有效的，但是当需要高任务性能时，它可能不会超越全面的微调。 Zeroth-order（ZO）方法提供了一种替代方案，可通过仅使用正向通行证近似梯度来微调整个预训练模型，从而消除了一阶方法中反向传播的计算负担。但是，在实施ZO方法时，硬提示至关重要，并且依靠简单的，固定的硬提示可能不是最佳的。在本文中，我们提出了一个双重优化框架，该框架与PEFT相辅相成，以减轻对硬提示的敏感性，同时有效，有效地微调LLM。我们的二线Zofo（Zeroth-rorder-stord-ford-sterd-sterd-sterd-sterd-sterd-sterd-ford-terd-sterd-sterd-sterd-sterd-sterd-sterf-tord-sterd-sterd-sterd-sterd-sterd-sterd-sterd-sterd-sterf-tord-sterf-tord-sterf-tord-sterf-tord-sterf-tord-sterf-tord-sterd-sterd-sterd-sterd-sterd-pertient策略，其中只需要PEFT模型的梯度和基本模型的正向通行证。我们为二线Zofo提供收敛保证。从经验上讲，我们证明，在保持相似的内存效率的同时，双重Zofo在单任务设置中均优于PEFT和ZO方法。此外，我们展示了其在多任务学习中的强大潜力。与当前的多任务学习一阶元训练算法相比，我们的方法在维持或提高性能的同时的计算需求大大降低。]]></description>
      <guid>https://arxiv.org/abs/2502.03604</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>（GG）MOE vs. MLP在表格数据上</title>
      <link>https://arxiv.org/abs/2502.03608</link>
      <description><![CDATA[ARXIV：2502.03608V1公告类型：新 
摘要：近年来，已经致力于调整现代神经网络体系结构以获取表格数据。然而，尽管它们的参数数量越大，训练时间更长，但这些模型通常无法始终超过香草多层感知器（MLP）神经网络。此外，与先进的深度学习方法相比，基于MLP的合奏最近表现出了卓越的性能和效率。因此，我们建议在不牺牲性能的情况下，不再专注于建立更深入，更复杂的深度学习模型，而是建议研究MLP神经网络是否可以用更有效的体系结构取代。在本文中，我们首先引入GG MOE，这是具有Gumbel-Softmax门控函数的Experts（MOE）模型的混合物。然后，我们证明，与标准的MOE和MLP型号相比，带有嵌入层的GG MOE在$ 38 $数据集中达到了最高的性能。最后，我们表明，MOE和GG MOE都比MLP都使用明显少的参数，这使它们成为缩放和集合方法的有前途的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2502.03608</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个新颖的零触摸，零值，AI/ML的IOT网络安全性</title>
      <link>https://arxiv.org/abs/2502.03614</link>
      <description><![CDATA[ARXIV：2502.03614V1公告类型：新 
摘要：物联网促进了一个联系，聪明和可持续的社会；因此，必须保护物联网生态系统。基于物联网的5G和6G将更多地利用机器学习和人工智能（ML/AI）的使用来为自动和协作的安全物联网网络铺平道路。使用AI和机器学习（ML）启用框架为零，零态度的物联网安全性，提供了一种有力的方法来确保物联网（IoT）设备的扩展景观。本文介绍了一个基于零信任，零触摸和AI/ML的集成的新颖框架，该框架可用于在现代物联网生态系统中探测，缓解和预防DDOS攻击。重点将通过为所有物联网流量，固定和移动5G/6G IoT网络流量以及数据安全性（Partine-Zero-Zero-Zero Touch和Dynamic Policy Seconfordions）建立零信任，将重点放在新的集成框架上。我们通过基于准确性，精度，回忆，F1得分和ROC-得分来比较这些模型，对五个机器学习模型，即X GBOOST，随机森林，最新邻居，随机梯度下降和天然贝叶斯进行了比较分析。 AUC。结果表明，检测和缓解不同DDOS矢量的最佳性能来自基于整体的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.03614</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有关变压器生成条件干预措施的逻辑含义转向方法</title>
      <link>https://arxiv.org/abs/2502.03618</link>
      <description><![CDATA[ARXIV：2502.03618V1公告类型：新 
摘要：预先训练的变压器模型中的机械解释性领域已证明了支持“线性表示假设”的大量证据，这是将高级概念在模型激活空间中编码为向量的想法。研究还表明，模型生成行为可以通过将概念向量添加到相应的激活中来转向给定概念。我们展示了如何利用这些属性将逻辑含义的形式构建到模型中，从而实现透明且可解释的调整，从而响应任何给定概念的存在，从而诱导所选的生成行为。我们的方法，即逻辑含义模型转向（LIMS），通过将神经符号逻辑集成到预训练的变压器模型中，从而解锁了新的手工推理功能。]]></description>
      <guid>https://arxiv.org/abs/2502.03618</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用强大的神经网络和优化的可控输入的群体特征分类</title>
      <link>https://arxiv.org/abs/2502.03619</link>
      <description><![CDATA[ARXIV：2502.03619V1公告类型：新 
摘要：具有推断自主代理人特征的能力将深刻彻底改变防御，安全和民事应用。我们以前的工作是第一个证明了监督的神经网络时间序列分类（NN TSC）可以迅速预测在军事环境中蜂拥而至的自治药物的策略，从而提供了情报以告知反手。但是，大多数自主互动，尤其是军事互动，充满了不确定性，提出了有关使用预审计分类器的实用性的问题。本文通过利用预期的操作变化来构建更丰富的数据集来解决这一挑战，从而使NN更加强大，并且在以重要不确定性为特征的场景中提高了推理性能。具体而言，不同的数据集是通过模拟防御者数字，防御者运动和测量噪声水平的变化而创建的。关键发现表明，在丰富的数据集中训练的强大NNS具有增强的分类精度并提供操作灵活性，例如减少所需的资源并提供遵守轨迹约束。此外，我们提出了一个新的框架，用于最佳地部署捍卫者训练有素的NN。该框架涉及优化辩护轨迹，从而引起对手反应，从而最大程度地提高了正确的NN战术分类的可能性，同时还满足了对捍卫者施加的操作约束。]]></description>
      <guid>https://arxiv.org/abs/2502.03619</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的最佳PAC学习</title>
      <link>https://arxiv.org/abs/2502.03620</link>
      <description><![CDATA[ARXIV：2502.03620V1公告类型：新 
摘要：Hanneke [2016b]和Larsen [2023]的二进制分类环境的最新进展已导致最佳PAC学习者。这些学习者分别利用了一个聪明的确定性亚采样计划和Bagging Breiman [1996]的经典启发式。两位最佳PAC学习者都将其用作亚条件，是经验风险最小化的自然算法。因此，这些最佳PAC学习者的计算成本与经验风险最小化算法的计算成本相关。在这项工作中，我们试图提供有关通过经验风险最小化算法链接所施加的计算成本的替代观点。为此，我们显示了一个最佳PAC学习者的存在，该研究者在经验风险最小化器引起的计算成本方面提供了不同的权衡。]]></description>
      <guid>https://arxiv.org/abs/2502.03620</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于私有梯度的优化成本</title>
      <link>https://arxiv.org/abs/2502.03652</link>
      <description><![CDATA[ARXIV：2502.03652V1公告类型：新 
摘要：我们考虑了差异私人（DP）凸经验风险最小化（ERM）的问题。尽管标准的DP-SGD算法在理论上是良好的，但实用的实现通常依赖于改组的梯度方法，这些方法会依次遍历训练数据，而不是在每次迭代中替换。尽管使用了广泛使用，但理论上的隐私准确性的权衡取舍了私人洗牌梯度方法（\ textit {dp-shuffgleg}）仍然知之甚少，从而导致理论与实践之间存在差距。在这项工作中，我们利用迭代（PABI）的隐私放大，以及Stein的Lemma的新颖应用，以提供\ textit {dp-shuffleg}的第一个经验性多余风险限制。我们的结果表明，与DP-SGD相比，与DP-SGD相比，数据改组会导致\ textit {dp-shuffleg}的经验过剩风险较差。为了解决此限制，我们提出\ textit {Interleaved-shuffleg}，这是一种混合方法，将公共数据样本集成为私人优化。通过交替使用私人和公共样本的优化步骤，\ textit {交织shuffleg}有效地降低了经验多余的风险。我们的分析介绍了一个新的优化框架，具有替代目标，自适应噪声注入和相似性指标，这可能具有独立的兴趣。我们对各种数据集和任务的实验证明了\ textit {交织shuffleg}的优越性，而不是几个基线。]]></description>
      <guid>https://arxiv.org/abs/2502.03652</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>