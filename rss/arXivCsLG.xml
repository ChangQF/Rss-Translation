<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 28 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过神经架构搜索进行个性化联合指令调整</title>
      <link>https://arxiv.org/abs/2402.16919</link>
      <description><![CDATA[arXiv:2402.16919v1 公告类型：新
摘要：联合指令调优（FIT）已经展示了在不共享私有数据的情况下在海量数据所有者之间实现协作模型指令调优的能力。然而，它仍然面临着数据和资源异构性两个关键挑战。由于数据所有者之间的数据分布和偏好不同，FIT无法适应个体所有者的个性化数据。此外，具有卓越计算能力的客户端受到限制，因为它们需要与较弱的客户端保持相同的微调架构。为了解决这些问题，我们提出了一种基于架构搜索的新型个性化联合指令调优（PerFIT）框架。具体来说，PerFIT 允许每个客户通过扩展全局模型的可训练参数空间，然后将参数修剪到原始状态来搜索个性化架构。该过程允许在扩展的参数空间内进行个性化指令微调，同时保留相同数量的可训练参数。此外，为了释放异构计算资源的能力并增强本地数据的个性化性能，我们利用个性化参数方式聚合。对多个法学硕士非独立同分布场景的评估表明，与最先进的 FIT 方法相比，我们的方法可以将困惑度降低高达 23%。]]></description>
      <guid>https://arxiv.org/abs/2402.16919</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>PDETime：从偏微分方程的角度重新思考长期多元时间序列预测</title>
      <link>https://arxiv.org/abs/2402.16913</link>
      <description><![CDATA[arXiv:2402.16913v1 公告类型：新
摘要：深度学习的最新进展导致了各种长期多元时间序列预测（LMTF）模型的发展，其中许多模型已经显示出有希望的结果。一般来说，重点是基于历史值的模型，该模型依靠过去的观察来预测未来的序列。值得注意的是，基于时间指数的模型出现了一种新趋势，可以更细致地理解时间序列背后的连续动态。与这两类聚合空间域或时间域信息的模型不同，在本文中，我们将多元时间序列视为从连续动力系统定期采样的时空数据，可以用偏微分方程（PDE）表示，空间域被固定。基于这个观点，我们提出了 PDETime，这是一种受神经 PDE 求解器原理启发的新型 LMTF 模型，遵循编码-积分-解码操作。我们对七个不同的现实世界 LMTF 数据集进行的广泛实验表明，PDETime 不仅有效地适应了数据的内在时空性质，而且还设定了新的基准，实现了最先进的结果]]></description>
      <guid>https://arxiv.org/abs/2402.16913</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>不仅仅是路线：用于细化轨迹表示学习的联合 GPS 和路线建模</title>
      <link>https://arxiv.org/abs/2402.16915</link>
      <description><![CDATA[arXiv:2402.16915v1 公告类型：新
摘要：轨迹表示学习在支持各种下游任务中发挥着关键作用。过滤 GPS 轨迹中的噪声的传统方法往往侧重于用于简化轨迹的基于路由的方法。然而，这种方法忽略了 GPS 数据中包含的运动细节，限制了轨迹表示学习的表示能力。为了填补这一空白，我们提出了一种基于自监督技术的联合 GPS 和路线建模的新型表示学习框架，即 JGRM。我们将GPS轨迹和路线视为单一运动观测的两种模式，并通过多模态信息交互来融合信息。具体来说，我们开发了两个编码器，每个编码器分别用于捕获路线和 GPS 轨迹的表示。两种模态的表示被输入到共享转换器中以进行模态间信息交互。最终，我们设计了三个自监督任务来训练模型。我们基于大量的实验验证了所提出的方法在两个真实数据集上的有效性。实验结果表明，JGRM 在路段表示和轨迹表示任务上均优于现有方法。我们的源代码可以在 Anonymous Github 上找到。]]></description>
      <guid>https://arxiv.org/abs/2402.16915</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>m2mKD：模块化变压器的模块到模块知识蒸馏</title>
      <link>https://arxiv.org/abs/2402.16918</link>
      <description><![CDATA[arXiv:2402.16918v1 公告类型：新
摘要：模块化神经架构由于其强大的泛化能力和样本高效适应新领域的能力而受到越来越多的关注。然而，训练模块化模型，特别是在早期阶段，由于其固有的稀疏连接性而产生优化困难，因此带来了挑战。利用整体模型中的知识，使用知识蒸馏等技术，可能会促进模块化模型的训练，并使它们能够集成来自不同来源预训练的多个模型的知识。然而，传统的知识蒸馏方法并不适合模块化模型，并且由于独特的架构和涉及的大量参数，直接应用时可能会失败。受这些挑战的启发，我们提出了一种通用的模块到模块知识蒸馏（m2mKD）方法，用于在模块之间传输知识。我们的方法涉及从预训练的整体模型中分离出来的教师模块和模块化模型的学生模块。 m2mKD 将这些模块与共享元模型分开组合，并鼓励学生模块模仿教师模块的行为。我们评估了 m2mKD 在两种不同的模块化神经架构上的有效性：神经注意电路（NAC）和视觉专家混合（V-MoE）。通过将 m2mKD 应用于 NAC，我们在 Tiny-ImageNet 上的 IID 准确性（高达 5.6%）和 Tiny-ImageNet-R 上的 OOD 鲁棒性（高达 4.2%）上实现了显着提高。平均而言，我们观察到 ImageNet 和 ImageNet-R 都有 1% 的增益。使用 m2mKD 训练的 V-MoE-Base 模型的准确率也比 ImageNet 上的端到端训练高出 3.5%。实验结果表明，我们的方法为连接模块化网络与预训练的整体模型提供了一种有前途的解决方案。代码可在 https://github.com/kamanphoebe/m2mKD 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.16918</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>选择性任务卸载可实现最大推理精度和节能的实时物联网传感系统</title>
      <link>https://arxiv.org/abs/2402.16904</link>
      <description><![CDATA[arXiv:2402.16904v1 公告类型：新
摘要：小型推理模型的最新进展促进了人工智能在边缘的部署。然而，边缘设备的有限资源性质带来了新的挑战，尤其是对于实时应用程序。除了边缘服务器推理模型之外，部署大小不同、因此准确度和功耗也不同的多个推理模型（或单个可调模型）可以提供一个动态系统，其中推理模型到推理作业的分配是根据当前的资源条件。因此，在这项工作中，我们解决了有选择地将推理模型分配给作业或将它们卸载到边缘服务器的问题，以在时间和能量限制下最大化推理精度。该问题被证明是无界多维背包问题的一个实例，被认为是强 NP 难问题。我们提出了一种轻量级混合遗传算法（LGSTO）来解决这个问题。我们引入了终止条件和邻域探索技术，以实现种群的更快进化。我们将 LGSTO 与朴素和动态编程解决方案进行比较。除了使用不同繁殖方法（包括 NSGA-II）的经典遗传算法之外，最后我们还与粒子群优化（PSO）和蚁群优化（ACO）等其他进化方法进行比较。实验结果表明，LGSTO 的执行速度比最快的同类方案快 3 倍，同时生成平均准确度更高的时间表。]]></description>
      <guid>https://arxiv.org/abs/2402.16904</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>体力活动对怀孕期间生活质量的影响：因果机器学习方法</title>
      <link>https://arxiv.org/abs/2402.16909</link>
      <description><![CDATA[arXiv:2402.16909v1 公告类型：新
摘要：生活质量（QoL）的概念是指对个人福祉的整体衡量，包括心理和社会方面。孕妇，尤其是肥胖且有压力的孕妇，生活质量通常较低。体力活动 (PA) 已显示出提高生活质量的潜力。然而，超重和肥胖的孕妇很少能达到建议的 PA 水平。研究使用基于相关性的方法调查了妊娠期间 PA 和 QoL 之间的关系。这些方法旨在发现变量之间的虚假相关性，而不是因果关系。此外，现有方法主要依赖身体活动参数，忽略了母亲（医疗）史和背景数据等不同因素的使用，导致估计有偏差。此外，这些估计缺乏对可能影响它们的调解因素和反事实情景的理解。在本文中，我们研究了怀孕期间和产后身体活动（治疗变量）与生活质量（结果）之间的因果关系。为了估计因果效应，我们开发了一种因果机器学习方法，集成了因果发现和因果推理组件。我们的调查数据来自一项针对超重和肥胖孕妇的长期可穿戴健康监测研究。机器学习（元学习器）估计技术用于估计因果效应。我们的结果表明，在怀孕期间和产后进行足够的身体活动，在身体健康和心理领域的生活质量分别平均提高 7.3 和 3.4 个单位。在最后一步中，采用四种反驳分析技术来验证我们的估计。]]></description>
      <guid>https://arxiv.org/abs/2402.16909</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>通过后验微调的值得信赖的个性化贝叶斯联合学习</title>
      <link>https://arxiv.org/abs/2402.16911</link>
      <description><![CDATA[arXiv:2402.16911v1 公告类型：新
摘要：由于数据异构性和低输出可解释性导致的性能下降是联邦学习在实际应用中面临的最重大挑战。个性化联邦学习与传统方法不同，它不再寻求训练单一模型，而是为每个客户量身定制独特的个性化模型。然而，之前的工作仅从神经网络参数的角度关注个性化，缺乏鲁棒性和可解释性。在这项工作中，我们建立了一个新颖的个性化联合学习框架，结合贝叶斯方法论，增强了算法量化不确定性的能力。此外，我们从参数后验角度引入归一化流来实现个性化，并从理论上分析了归一化流对贝叶斯神经网络的分布外（OOD）检测的影响。最后，我们在异构数据集上评估了我们的方法，实验结果表明，由于贝叶斯方法的可靠输出，新算法不仅提高了准确性，而且在 OOD 检测中显着优于基线。]]></description>
      <guid>https://arxiv.org/abs/2402.16911</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>连续时间强化学习中深度残差网络的先验估计</title>
      <link>https://arxiv.org/abs/2402.16899</link>
      <description><![CDATA[arXiv:2402.16899v1 公告类型：新
摘要：深度强化学习在众多大规模实际应用中表现出色。然而，现有的性能分析忽略了连续时间控制问题的独特特征，无法直接估计贝尔曼最优损失的泛化误差，并且需要有界假设。我们的工作重点是连续时间控制问题，并提出了一种适用于所有此类问题的方法，其中过渡函数满足半群和 Lipschitz 性质。在这种方法下，我们可以直接分析贝尔曼最优损失的\emph{先验}泛化误差。该方法的核心在于损失函数的两次变换。为了完成转换，我们提出了最大算子的分解方法。此外，该分析方法不需要有界假设。最后，我们获得了\emph{先验}泛化误差，而没有维数灾难。]]></description>
      <guid>https://arxiv.org/abs/2402.16899</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>PRoLoRA：部分旋转使 LoRA 参数效率更高</title>
      <link>https://arxiv.org/abs/2402.16902</link>
      <description><![CDATA[arXiv:2402.16902v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的快速扩展，同时服务多个 LoRA 变得越来越不切实际，导致成本难以承受，并且需要更高效的参数微调方法。在这项工作中，我们引入了部分旋转增强低秩自适应（PRoLoRA），这是一种层内共享机制，包含四个基本组成部分：广播减少、旋转增强、部分共享细化和纠正初始化策略。作为 LoRA 的超集，PRoLoRA 继承了 LoRA 的优点，并有效规避了对等参数共享方法的弊端，具有优越的模型容量、实际可行性和广泛的适用性。实证实验证明了 PRoLoRA 在特定参数预算和性能目标场景中显着提高的参数效率，以及其可扩展至更大的 LLM。值得注意的是，在可训练参数减少一倍的情况下，PRoLoRA 在多指令调整数据集上仍然优于 LoRA。随后，进行了消融研究，以验证各个组件的必要性，并强调 PRoLoRA 相对于三种潜在变体的优越性。希望明显更高的参数效率能够使 PRoLoRA 成为 LoRA 的资源友好型替代方案。]]></description>
      <guid>https://arxiv.org/abs/2402.16902</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>一种用于深度算子网络代理建模的新颖数据生成方案</title>
      <link>https://arxiv.org/abs/2402.16903</link>
      <description><![CDATA[arXiv:2402.16903v1 公告类型：新
摘要：基于算子的神经网络架构（例如 DeepONet）已成为物理系统代理建模的有前途的工具。一般来说，对于算子代理建模，训练数据是通过使用有限元法 (FEM) 等技术求解偏微分方程来生成的。数据生成的计算密集性是在实际应用中部署这些代理模型的最大瓶颈之一。在这项研究中，我们提出了一种新颖的方法来减轻与 DeepONets 训练数据生成相关的计算负担。与现有文献不同，所提出的数据生成框架不使用任何偏微分方程积分策略，从而显着降低了与为 DeepONet 生成训练数据集相关的计算成本。在所提出的策略中，首先，使用高斯过程回归（GPR）随机生成输出场，满足边界条件。根据输出场，可以使用有限差分技术轻松计算输入源场。所提出的方法可以扩展到其他算子学习方法，使得该方法具有广泛的适用性。为了验证所提出的方法，我们采用热方程作为模型问题，并为许多边值问题开发替代模型。]]></description>
      <guid>https://arxiv.org/abs/2402.16903</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>生成模型是自水印的：通过重新生成声明模型身份验证</title>
      <link>https://arxiv.org/abs/2402.16889</link>
      <description><![CDATA[arXiv:2402.16889v1 公告类型：新
摘要：随着机器和人工智能生成的内容激增，保护生成模型的知识产权已势在必行，但验证数据所有权带来了巨大的挑战，特别是在未经授权重用生成数据的情况下。使用机器学习即服务 (MLaaS)（通常充当黑盒系统）进一步放大了验证数据所有权的挑战。
  我们的工作致力于检测单个样本的数据重用。传统上，水印被用来检测人工智能生成的内容。然而，与将附加信息作为触发器嵌入到模型或生成内容中的水印技术不同，这可能会损害输出质量，我们的方法通过重新生成来识别输出中固有存在的潜在指纹。我们提出了一种可解释的验证程序，通过重新生成来归属数据所有权，并通过迭代数据重新生成进一步放大生成模型中的这些指纹。该方法具有理论基础，并使用最新的高级文本和图像生成模型证明了可行性和鲁棒性。我们的方法意义重大，因为它不仅限于保护 API 的知识产权，还解决了错误信息传播和学术不端行为等重要问题。它提供了一个有用的工具来确保来源和作者的完整性，并将其应用扩展到需要真实性和所有权验证的不同场景中。]]></description>
      <guid>https://arxiv.org/abs/2402.16889</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>具有交叉问题零样本泛化的路由问题的多任务学习</title>
      <link>https://arxiv.org/abs/2402.16891</link>
      <description><![CDATA[arXiv:2402.16891v1 公告类型：新
摘要：车辆路径问题（VRP）在许多实际应用中都存在，几十年来一直是一个重要的研究课题。最近，神经组合优化（NCO）方法利用基于学习的模型来解决 VRP，无需手动算法设计，受到了广泛关注。然而，当前的 NCO 方法通常需要为每个路由问题构建一个模型，这极大地阻碍了它们在具有不同属性的现实行业问题中的实际应用。在这项工作中，我们首次尝试解决跨问题泛化的关键挑战。特别是，我们将 VRP 制定为一组共享底层属性的不同组合，并通过属性组合通过单个模型同时解决它们。通过这种方式，我们提出的模型可以以零样本泛化方式成功地解决具有未见过的属性组合的VRP。对 11 个 VRP 变体、基准数据集和行业物流场景进行了广泛的实验。结果表明，统一模型在 11 个 VRP 中表现出卓越的性能，将现有方法的平均差距从 20% 以上缩小到 5% 左右，并在基准数据集和实际物流应用中实现了显着的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2402.16891</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>可靠的冲突多视图学习</title>
      <link>https://arxiv.org/abs/2402.16897</link>
      <description><![CDATA[arXiv:2402.16897v1 公告类型：新
摘要：多视图学习旨在结合多种特征来实现对数据更全面的描述。大多数以前的作品都假设多个视图严格对齐。然而，现实世界的多视图数据可能包含低质量的冲突实例，这些实例在不同视图中显示冲突信息。以前解决此问题的方法主要集中于通过删除冲突的数据实例或替换冲突的视图来消除冲突的数据实例。然而，现实世界的应用程序通常需要对冲突实例做出决策，而不仅仅是消除它们。为了解决这个问题，我们提出了一个新的可靠冲突多视图学习（RCML）问题，它要求模型为冲突多视图数据提供决策结果和附加可靠性。我们针对这个问题开发了一种证据冲突多视图学习（ECML）方法。 ECML 首先学习特定视图的证据，这可以称为从数据收集的每个类别的支持量。然后，我们可以构建由决策结果和可靠性组成的特定于视图的意见。在多视图融合阶段，我们提出了一种冲突意见聚合策略，并从理论上证明该策略可以准确地建模多视图共同可靠性和特定视图可靠性的关系。在6个数据集上进行的实验验证了ECML的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.16897</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>BESA：通过分块参数高效稀疏分配修剪大型语言模型</title>
      <link>https://arxiv.org/abs/2402.16880</link>
      <description><![CDATA[arXiv:2402.16880v1 公告类型：新
摘要：大型语言模型（LLM）在文本摘要、文本问答等各种任务中表现出了出色的性能。虽然它们的性能令人印象深刻，但由于参数数量庞大，计算量可能令人望而却步。 SparseGPT 和 Wanda 等现有解决方案试图通过权重修剪来缓解这个问题。然而，它们的分层方法会对模型的输出产生显着的扰动，并且需要细致的超参数调整，例如剪枝率，这可能会对模型的整体性能产生不利影响。为了解决这个问题，本文通过应用块式重建损失引入了一种新颖的 LLM 剪枝技术，称为块式参数高效稀疏分配（BESA）。与典型的逐层剪枝技术相比，BESA 具有两个独特的属性：i）它针对各个变压器块的总体剪枝误差，ii）它以可微分的方式分配特定于层的稀疏性，两者都确保减少修剪后的性能下降。我们的实验表明，BESA 实现了最先进的性能，在短短五个小时内在单个 A100 GPU 上高效地修剪了 LLaMA1 和 LLaMA2 等具有 7B 到 70B 参数的 LLM。代码可在 \href{https://github.com/OpenGVLab/LLMPrune-BESA}{here} 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.16880</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>使用小水库的混沌吸引子重建 - 拓扑的影响</title>
      <link>https://arxiv.org/abs/2402.16888</link>
      <description><![CDATA[arXiv:2402.16888v1 公告类型：新
摘要：基于测量数据的预测时间序列在广泛的应用中需要，并且已经成为广泛研究的主题。一项特别具有挑战性的任务是预测混沌动力学生成的时间序列。近年来，储层计算已被证明是预测混沌动力学和从数据重建混沌吸引子的有效方法。在这项工作中，我们朝着更小、更低复杂性的储层方向迈进，目标是提高硬件的可实施性，并更可靠地生成足够的替代模型。我们表明，非耦合节点的水库比复杂的水库拓扑更可靠地产生长期时间序列预测。然后，我们将改进的非耦合储层吸引子重建与所得替代系统的较小光谱半径联系起来。这些结果表明，节点度在确定通过训练的水库闭环运行获得的自主代理系统中所需的动态是否稳定方面起着重要作用。就硬件可实现性而言，非耦合节点将在硬件架构中提供更大的自由度，因为不需要复杂的耦合设置，并且因为对于非耦合节点，系统响应对于空间和时间复用来说是等效的。]]></description>
      <guid>https://arxiv.org/abs/2402.16888</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    </channel>
</rss>