<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 23 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>提高低数据条件下 3D 结合亲和力模型的通用性</title>
      <link>https://arxiv.org/abs/2409.12995</link>
      <description><![CDATA[arXiv:2409.12995v1 公告类型：新
摘要：预测蛋白质-配体结合亲和力是计算机辅助药物设计的重要组成部分。然而，通用且性能良好的全局结合亲和力模型仍然难以捉摸，特别是在低数据情况下。尽管模型架构不断发展，但当前的基准测试并不适合探究 3D 结合亲和力模型的通用性。此外，GNN 等 3D 全局架构尚未达到性能预期。为了研究这些问题，我们引入了 PDBBind 数据集的新分割，最大限度地减少了训练集和测试集之间的相似性泄漏，并允许在各种模型架构之间进行公平和直接的比较。在这个低相似性分割中，我们证明，一般来说，在低数据情况下，3D 全局模型优于蛋白质特定的局部模型。我们还证明了 GNN 的性能得益于三项新贡献：通过量子力学数据进行监督预训练、通过小分子扩散进行无监督预训练以及在输入图中显式建模氢原子。我们相信这项工作引入了有前途的新方法，以释放 GNN 架构在结合亲和力建模方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.12995</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>pyrtklib：一个用于城市峡谷定位的紧密耦合深度学习和 GNSS 集成开源软件包</title>
      <link>https://arxiv.org/abs/2409.12996</link>
      <description><![CDATA[arXiv:2409.12996v1 公告类型：新
摘要：人工智能 (AI) 正在彻底改变众多领域，通过深度学习，全球导航卫星系统 (GNSS) 定位算法在智能交通系统 (ITS) 中的应用越来越多。然而，存在显著的技术差距，因为传统的 GNSS 算法通常是用 Fortran 或 C 开发的，而深度学习工具中普遍采用基于 Python 的实现。为了解决这一差异，本文介绍了 pyrtklib，这是广泛使用的开源 GNSS 工具 RTKLIB 的 Python 绑定。此绑定使所有 RTKLIB 功能都可以在 Python 中访问，从而促进无缝集成。此外，我们提出了一个基于 pyrtklib 的深度学习子系统，这是一个新颖的深度学习框架，利用 pyrtklib 准确预测 GNSS 定位过程中的权重和偏差。使用 pyrtklib 使开发人员能够轻松快速地制作原型并实现深度学习辅助 GNSS 算法，展示其显著提高定位精度的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.12996</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VCAT：利用漏洞感知和好奇心驱动的对抗性训练来增强自动驾驶汽车的稳健性</title>
      <link>https://arxiv.org/abs/2409.12997</link>
      <description><![CDATA[arXiv:2409.12997v1 公告类型：新
摘要：自动驾驶汽车 (AV) 在复杂的交通环境中面临着对其安全运行的重大威胁。对抗性训练已成为一种有效的方法，使 AV 能够先发制人地加强其对恶意攻击的鲁棒性。使用对抗性策略训练攻击者，让 AV 通过与该攻击者的交互来学习鲁棒驾驶。然而，现有方法中的对抗性策略经常陷入过度利用已建立的漏洞的循环中，导致 AV 的改进不佳。为了克服这些局限性，我们引入了一个称为漏洞感知和好奇心驱动的对抗性训练 (VCAT) 的开创性框架。具体而言，在交通车辆攻击者训练阶段，使用代理网络来拟合 AV 受害者的价值函数，提供有关受害者固有漏洞的密集信息。随后，使用随机网络蒸馏来表征环境的新颖性，构建内在奖励以引导攻击者探索未开发的领域。在受害者防御训练阶段，自动驾驶汽车在关键场景中进行训练，其中预先训练的攻击者位于受害者周围以产生攻击行为。实验结果表明，VCAT 提供的训练方法显著提高了基于学习的自动驾驶汽车的稳健控制能力，优于传统训练模式和其他强化学习方法，并且崩溃率显著降低。代码可在 https://github.com/caixxuan/VCAT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.12997</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型医疗模型简介：使用针对患者事件序列进行训练的 transformer 进行最先进的医疗成本和风险预测</title>
      <link>https://arxiv.org/abs/2409.13000</link>
      <description><![CDATA[arXiv:2409.13000v1 公告类型：新 
摘要：随着美国医疗保健支出接近 5 万亿美元（NHE 情况说明书 2024），其中 25% 估计是浪费（美国医疗保健系统的浪费：估计成本和节省潜力，无日期），更好地预测风险和最佳患者护理的需求变得越来越重要。本文介绍了大型医疗模型 (LMM)，这是一种生成式预训练转换器 (GPT)，旨在指导和预测患者护理和医疗保健管理的广泛方面。该模型使用来自超过 1.4 亿条纵向患者索赔记录的医疗事件序列进行训练，使用由医学术语系统构建的专业词汇，并展示了预测医疗保健成本和识别潜在风险因素的卓越能力。通过实验和验证，我们展示了 LMM 不仅在成本和风险预测方面的能力，而且还展示了在复杂医疗条件下辨别复杂模式的能力以及识别患者护理中的新关系的能力。在预测多种疾病的研究中，LMM 能够将成本预测提高 14.1%，比最佳商业模型高，将慢性疾病预测提高 1.9%，比最佳变压器模型高。LMM 是医疗分析领域的一项重大进步，具有显著增强风险评估、成本管理和个性化医疗的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.13000</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习中的数据中毒与泄漏分析</title>
      <link>https://arxiv.org/abs/2409.13004</link>
      <description><![CDATA[arXiv:2409.13004v1 公告类型：新
摘要：数据中毒和泄漏风险阻碍了联邦学习在现实世界中的大规模部署。本章揭示了理解两个主要威胁的真相和陷阱：{\em 训练数据隐私入侵} 和 {\em 训练数据中毒}。我们首先调查训练数据隐私威胁，并介绍我们对在联邦训练过程中何时以及如何泄露训练数据的观察。一种有前途的防御策略是在每轮联邦学习期间共享之前通过添加一些受控的随机噪声来扰乱原始梯度更新。我们讨论了确定适当数量的随机噪声和添加此类噪声的适当位置的重要性，以有效减轻针对训练数据隐私的梯度泄漏威胁。然后，我们将回顾和比较不同的训练数据中毒威胁，并分析为什么以及何时此类数据中毒引起的模型特洛伊木马攻击会对全局模型的性能造成有害损害。我们将对代表性的毒药攻击及其缓解技术的有效性进行分类和比较，从而深入了解数据毒药的负面影响。最后，我们展示了动态模型扰动在同时确保隐私保护、毒药恢复能力和模型性能方面的潜力。本章最后讨论了联邦学习中的其他风险因素，包括偏斜、数据和算法偏差以及训练数据中的错误信息的负面影响。在实证证据的支持下，我们的分析研究为抗攻击联邦学习中的有效隐私保护和安全保障策略提供了一些变革性见解。]]></description>
      <guid>https://arxiv.org/abs/2409.13004</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>iCost：一种基于实例复杂度的新型不平衡分类成本敏感学习框架</title>
      <link>https://arxiv.org/abs/2409.13007</link>
      <description><![CDATA[arXiv:2409.13007v1 公告类型：新
摘要：数据中的类别不平衡对分类任务提出了重大挑战。它相当常见，需要小心处理才能获得理想的性能。传统的分类算法会偏向多数类。缓解这种情况的一种方法是使分类器具有成本敏感性。这是通过为少数类实例分配更高的错误分类成本来实现的。此实现的一个问题是，所有少数类实例都被平等对待，并分配了相同的惩罚值。然而，所有实例的学习难度并不相同。位于决策边界附近的实例更难分类，而那些更远的实例则更容易分类。如果不考虑实例复杂性并天真地对所有少数类样本进行统一加权，会导致不必要的偏差，从而导致多数类实例的错误分类数量增加。这是不可取的，为了克服这种情况，我们在本研究中提出了一种基于实例复杂性的新型成本敏感方法。我们首先根据难度对所有少数类实例进行分类，然后对实例进行相应的惩罚。这确保了更公平的实例权重并防止过度惩罚。在 66 个不平衡数据集上对所提出方法的性能进行了测试，并与传统的成本敏感型学习框架进行了比较，结果发现性能有显著提高，证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.13007</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列异常检测器的无偏评估</title>
      <link>https://arxiv.org/abs/2409.13053</link>
      <description><![CDATA[arXiv:2409.13053v1 公告类型：新
摘要：时间序列异常检测 (TSAD) 是一个不断发展的研究领域，其动机是其关键应用，例如检测地震活动、工业工厂中的传感器故障、预测股市崩盘等。在各个领域，异常发生的频率明显低于正常数据，这使得 F1 分数成为异常检测最常用的指标。​​然而，在时间序列的情况下，由于“时间点”和“时间事件”之间的分离，使用标准 F1 分数并不简单。为了适应这一点，在 $F_1$ 分数评估之前调整异常预测，称为点调整 (PA)。然而，这些调整是基于启发式的，并且偏向于真正的阳性检测，导致检测器性能被高估。在这项工作中，我们提出了一种称为“平衡点调整”（BA）的替代调整协议。它解决了现有点调整方法的局限性，并通过 TSAD 评估的公理定义提供了公平性的保证。]]></description>
      <guid>https://arxiv.org/abs/2409.13053</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在现代工业中的应用全面概述</title>
      <link>https://arxiv.org/abs/2409.13059</link>
      <description><![CDATA[arXiv:2409.13059v1 公告类型：新
摘要：人工智能 (AI) 通过增强决策流程、优化运营和释放新的创新机会，从根本上重塑了各个行业。本文探讨了人工智能在四个关键领域的应用：医疗保健、金融、制造业和零售业。每个部分都深入探讨了这些行业面临的具体挑战、用于解决这些挑战的人工智能技术以及对业务成果和社会福利的可衡量影响。我们还讨论了人工智能集成的影响，包括道德考虑、人工智能发展的未来轨迹，以及它在推动经济增长的同时带来需要负责任地管理的挑战的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.13059</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用流形神经网络改进图像分类</title>
      <link>https://arxiv.org/abs/2409.13063</link>
      <description><![CDATA[arXiv:2409.13063v1 公告类型：新
摘要：图神经网络 (GNN) 在各种学习任务中越来越受欢迎，并在分子生物学、交通系统和电网等领域取得了成功应用。这些领域自然使用图形数据，受益于 GNN 的消息传递框架。然而，GNN 在更一般的数据表示（尤其是在图像领域）中的潜力仍未得到充分开发。利用流形假设，即高维数据位于低维流形中，我们探索了 GNN 在此背景下的潜力。我们使用变分自动编码器构建图像流形，然后对流形进行采样以生成每个节点都是图像的图。这种方法降低了数据维数，同时保留了几何信息。然后，我们训练 GNN 来预测分类任务中与图像标签相对应的节点标签，并利用 GNN 与流形神经网络的收敛来分析 GNN 泛化。在 MNIST 和 CIFAR10 数据集上进行的实验表明，GNN 可以有效地推广到未见图，并在分类任务中实现具有竞争力的准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.13063</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指导有什么作用？简单环境中的细粒度分析</title>
      <link>https://arxiv.org/abs/2409.13074</link>
      <description><![CDATA[arXiv:2409.13074v1 公告类型：新
摘要：在扩散模型中使用指导最初是出于这样的前提：指导修正分数是数据分布的分数，该分数由条件似然的某个幂倾斜。在这项工作中，我们通过严格证明指导无法从预期的倾斜分布中采样来澄清这一误解。
我们的主要结果是对两种情况下的指导动态进行细粒度表征，(1) 紧支撑分布的混合和 (2) 高斯分布的混合，它们反映了指导在现实世界数据上表现出来的显着特性。在这两种情况下，我们都证明，随着指导参数的增加，指导模型从条件分布的支持边界进行更大量的采样。我们还证明，对于任何非零水平的分数估计误差，足够大的指导将导致远离支持的采样，从理论上证明了大指导会导致扭曲的生成这一经验发现。
除了在合成环境中通过经验验证这些结果之外，我们还展示了我们的理论见解如何为实际部署提供有用的建议。]]></description>
      <guid>https://arxiv.org/abs/2409.13074</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对比语言图像预训练的嵌入几何</title>
      <link>https://arxiv.org/abs/2409.13079</link>
      <description><![CDATA[arXiv:2409.13079v1 公告类型：新
摘要：自 CLIP 发布以来，使用 InfoNCE 损失进行对比预训练的方法已广泛用于连接两种或多种模态。尽管 CLIP 被广泛采用，但其最初的设计选择 L2 正则化和余弦相似性逻辑很少被重新审视。我们系统地试验了用于语言图像预训练的替代几何和 softmax 逻辑，并发现具有直观欧几里得几何的变体欧几里得 CLIP (EuCLIP) 的性能与 CLIP 相当或超过其性能，并且至少支持与更复杂的双曲替代一样多的层次关系。]]></description>
      <guid>https://arxiv.org/abs/2409.13079</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对儿童的个性化语音识别，具有测试时间自适应功能</title>
      <link>https://arxiv.org/abs/2409.13095</link>
      <description><![CDATA[arXiv:2409.13095v1 公告类型：新
摘要：准确的儿童自动语音识别 (ASR) 对于有效的实时儿童与人工智能互动至关重要，尤其是在教育应用中。然而，由于数据域从成人转移到儿童，现成的 ASR 模型主要在成人数据上进行预训练，往往不能很好地推广到儿童语音。最近的研究发现，对儿童语音数据进行监督微调可以帮助弥合这种领域转变，但人工注释可能不适用于实际应用，并且在训练时进行调整可能会忽略测试时发生的额外领域转变。我们设计了一种新颖的 ASR 流程，将无监督的测试时自适应 (TTA) 方法应用于儿童语音识别，以便对成人语音进行预训练的 ASR 模型可以在测试时持续适应每个儿童说话者，而无需进一步的人工注释。我们的结果表明，采用 TTA 方法进行调整的 ASR 模型在单个儿童说话者中，无论是平均水平还是统计水平，都显著优于未调整的现成 ASR 基线。我们的分析还发现，儿童说话者之间以及每个儿童说话者内部都存在显著的数据域偏移，这进一步激发了对测试时调整的需求。]]></description>
      <guid>https://arxiv.org/abs/2409.13095</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解开基于图像的强化学习中的识别和决策遗憾</title>
      <link>https://arxiv.org/abs/2409.13108</link>
      <description><![CDATA[arXiv:2409.13108v1 公告类型：新
摘要：在基于图像的强化学习 (RL) 中，策略通常分两个步骤运行：首先从原始图像中提取低维特征（“识别”步骤），然后根据提取的特征采取行动（“决策”步骤）。提取与性能虚假相关或与决策无关的特征会导致泛化性能不佳，这在基于图像的 RL 中称为观察过度拟合。在这种情况下，很难量化有多少错误可以归因于糟糕的特征提取与糟糕的决策。为了解开这两个错误来源，我们引入了识别遗憾和决策遗憾的概念。利用这些概念，我们描述并消除了观察性过度拟合背后的两个不同原因：过度特定的表征，包括最佳决策不需要的特征（导致决策遗憾度高）；与缺乏特定表征，仅包括一组有限的特征，这些特征与训练期间的表现虚假相关（导致识别遗憾度高）。最后，我们提供了在迷宫环境以及 Atari 游戏 Pong 中由于过度特定和缺乏特定表征而导致的观察性过度拟合的说明性示例。]]></description>
      <guid>https://arxiv.org/abs/2409.13108</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CorBin-FL：一种使用通用随机性的差分隐私联邦学习机制</title>
      <link>https://arxiv.org/abs/2409.13133</link>
      <description><![CDATA[arXiv:2409.13133v1 公告类型：新
摘要：联邦学习 (FL) 已成为分布式机器学习的一个有前途的框架。它利用分布式数据和计算资源，实现多个客户端之间的协作学习。然而，FL 在平衡隐私保证、通信效率和整体模型准确性方面面临挑战。在这项工作中，我们介绍了 CorBin-FL，这是一种使用相关二进制随机量化来实现差异隐私同时保持整体模型准确性的隐私机制。该方法使用安全的多方计算技术，使客户端能够对其本地模型更新执行相关量化，而不会损害个人隐私。我们提供理论分析，表明 CorBin-FL 实现了参数级局部差异隐私 (PLDP)，并且它渐近地优化了均方误差效用度量和 PLDP 隐私度量之间的隐私效用权衡。我们进一步提出了 AugCorBin-FL，这是一种扩展，除了 PLDP 之外，它还实现了用户级和样本级中央差异隐私保证。对于这两种机制，我们都推导出隐私参数和均方误差性能指标的界限。在 MNIST 和 CIFAR10 数据集上进行的大量实验表明，在同等 PLDP 隐私预算下，我们的机制在模型准确度方面优于现有的差分隐私 FL 机制，包括高斯和拉普拉斯机制。]]></description>
      <guid>https://arxiv.org/abs/2409.13133</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>带有标签掩蔽蒸馏的联邦学习</title>
      <link>https://arxiv.org/abs/2409.13136</link>
      <description><![CDATA[arXiv:2409.13136v1 公告类型：新
摘要：联邦学习提供了一种隐私保护的方式，通过全局服务器的协调，在分布于多个本地客户端上的数据上协作训练模型。在本文中，我们关注联邦学习中的标签分布偏差，由于客户端的用户行为不同，不同客户端之间的标签分布存在显著差异。面对这种情况，大多数现有方法会因为客户端中标签分布信息的利用不足而导致次优优化。受此启发，我们提出了一种标签屏蔽蒸馏方法（称为 FedLMD），通过感知每个客户端的各种标签分布来促进联邦学习。在训练过程中，我们根据每个类别的示例数量将标签分为多数标签和少数标签。客户端模型从本地数据中学习多数标签的知识。蒸馏过程掩盖了全局模型中多数标签的预测，使其可以更专注于保留客户端的少数标签知识。一系列实验表明，所提出的方法在各种情况下都能达到最佳性能。此外，考虑到客户端的资源有限，我们提出了一种不需要额外教师的变体 FedLMD-Tf，其性能优于以前的轻量级方法，而不会增加计算成本。我们的代码可在 https://github.com/wnma3mz/FedLMD 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.13136</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>