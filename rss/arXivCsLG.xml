<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>逻辑和属性自我反射的长摩根视觉指导生成</title>
      <link>https://arxiv.org/abs/2503.13500</link>
      <description><![CDATA[ARXIV：2503.13500V1公告类型：新 
摘要：长马任务的视觉说明至关重要，因为它们直观地阐明复杂的概念并增强了扩展步骤的保留率。直接使用文本对图像模型直接生成一系列图像，而无需考虑上述步骤的上下文会导致图像不一致，从而增加了认知负载。此外，生成的图像通常会错过对象或诸如对象的颜色，形状和状态之类的属性。为了应对这些挑战，我们提出了Liger，这是逻辑和属性自我反思的第一个无训练框架。 Liger首先使用先前步骤的历史提示和视觉记忆为每个步骤生成草稿图像。这种逐步生成方法在长距离任务中保持图像之间的一致性。此外，Liger利用各种图像编辑工具来纠正错误，包括错误属性，逻辑错误，对象冗余和身份不一致。通过这种自我反射机制，Liger改善了图像的逻辑和对象属性。为了验证生成的图像是否有助于人类的理解，我们手动策划了一个由各种长途任务组成的新基准。人类宣告的地面真理表达式反映了人类定义的标准，即形象应该如何说明性。实验证明了与基线方法相比，Liger产生的视觉指令更全面。]]></description>
      <guid>https://arxiv.org/abs/2503.13500</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Scihorizo​​n：从科学数据到大语言模型的基准测试AI科学的准备就绪</title>
      <link>https://arxiv.org/abs/2503.13503</link>
      <description><![CDATA[ARXIV：2503.13503V1公告类型：新 
摘要：近年来，人工智能（AI）技术的快速发展，尤其是大型语言模型（LLMS），彻底改变了科学发现的范式，将AI-Science（AI4Science）建立为动态和不断发展的领域。但是，仍然缺乏对AI4Science进行整体评估的有效框架，尤其是从数据质量和模型能力的整体角度来看。因此，在这项研究中，我们提出了Scihorizo​​n，这是一个全面的评估框架，旨在从科学数据和LLM的角度来基准准备AI4Science。首先，我们介绍了一个可概括的框架，用于评估AI准备就绪的科学数据，涵盖了四个关键维度：质量，公平性，解释性和合规性，并将其细分为15个细分。借鉴了2018年至2023年之间在同行评审期刊上发表的数据资源论文，我们介绍了针对地球和生命科学的AI-Ready数据集的建议列表，对该领域做出了新颖和原始的贡献。同时，为了评估跨多个科学学科的LLM的能力，我们基于五个核心指标知识，理解，推理，多模式以及跨越数学，物理学，化学，生命科学以及地球和空间科学的五个核心指标知识，理解，推理，多模式以及值。使用开发的基准数据集，我们对20多个代表性的开源和封闭源LLM进行了全面评估。所有结果均可公开可用，可以在www.scihorizo​​n.cn/en上在线访问。]]></description>
      <guid>https://arxiv.org/abs/2503.13503</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>COCMT：用于协作感知的沟通式跨模式变压器</title>
      <link>https://arxiv.org/abs/2503.13504</link>
      <description><![CDATA[ARXIV：2503.13504V1公告类型：新 
摘要：多代理协作感知通过共享感应信息来合作执行机器人感知任务，从而增强了每个代理的感知能力。事实证明，这种方法在应对诸如传感器缺陷，遮挡和远程感知等挑战方面有效。但是，现有的代表性协作感知系统传输了中间特征图，例如鸟眼视图（BEV）表示，其中包含大量非关键信息，从而导致高通信带宽要求。为了提高沟通效率的同时，我们引入了COCMT，这是一种基于对象的协作框架，该框架通过选择性提取和传输基本功能来优化通信带宽。在COCMT中，我们介绍了有效的查询变压器（EQFORMER），以有效地融合多代理对象查询并实施协同的深度监督，以增强阶段之间的积极强化，从而改善整体性能。 OPV2V和V2V4REAL数据集的实验显示，COCMT的表现优于最先进的方法，同时大大减少了通信需求。在V2V4REAL上，我们的模型（前50个对象查询）仅需要0.416 MB带宽，比SOTA方法少83倍，同时将AP70提高了1.1％。这种效率突破使得在带宽受限环境中的实用协作感知部署而无需牺牲检测准确性。]]></description>
      <guid>https://arxiv.org/abs/2503.13504</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超参数在预测多重性中的作用</title>
      <link>https://arxiv.org/abs/2503.13506</link>
      <description><![CDATA[ARXIV：2503.13506V1公告类型：新 
摘要：本文研究了超参数在预测多样性中的关键作用，其中在同一数据集上训练的不同机器学习模型对相同的输入产生了不同的预测。这些不一致会严重影响高风险决策，例如信用评估，招聘和医学诊断。专注于六个广泛使用的表格数据模型 - 弹性网，决策树，k -nearest邻居，支持向量机，随机森林和极端梯度的增强 - 我们探索了超参数调整如何影响预测性多样性，这是通过基准标准跨基准数据集的预测差异表达的。关键的超参数，例如弹性网中的lambda，支持向量机中的伽玛和极端梯度增强中的alpha在塑造预测多样性方面起着至关重要的作用，通常会损害特定算法中预测的稳定性。我们在21个基准数据集上进行的实验表明，调整这些超参数会导致显着改善，但也会增加预测差异，极端的梯度增强表现出最高的差异和实质性的预测不稳定。这突出了性能优化和预测一致性之间的权衡，从而引起了人们对任意预测风险的担忧。这些发现提供了有关超参数优化如何导致预测多重性的见解。尽管预测性多重性允许优先考虑特定于域的目标，例如公平性并降低对单个模型的依赖，但它也使决策复杂化，可能导致任意或不合理的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.13506</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Chenterchat16k：用于对话心理健康援助的基准数据集</title>
      <link>https://arxiv.org/abs/2503.13509</link>
      <description><![CDATA[ARXIV：2503.13509V1公告类型：新 
摘要：我们介绍了Chenterchat16k，这是一个英语基准数据集，结合了合成心理健康咨询数据集和匿名成绩单的数据集，该数据集来自行为健康教练与姑息治疗或临终关怀护理患者的护理人员之间的干预措施。该策划的数据集涵盖了抑郁症，焦虑和悲伤等各种疾病，旨在促进大型语言模型的发展和评估，以进行对话心理健康援助。通过提供针对这个关键领域的高质量资源，MentalChat16K旨在提高对善解人意的个性化AI解决方案的研究，以改善获得心理健康支持服务的访问。数据集优先考虑患者隐私，道德考虑和负责任的数据使用情况。 Chenterchat16k为研究界提供了一个宝贵的机会，可以创新可以积极影响心理健康的AI技术。]]></description>
      <guid>https://arxiv.org/abs/2503.13509</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的认知激活和混乱动力学：推理机制的准裂解分析</title>
      <link>https://arxiv.org/abs/2503.13530</link>
      <description><![CDATA[ARXIV：2503.13530V1公告类型：新 
摘要：大语言模型（LLMS）表现出的类似人类的推理能力挑战了传统的神经网络理论对固定参数系统灵活性的理解。本文提出了“认知激活”理论，从动态系统的角度揭示了LLMS推理机制的本质：模型的推理能力源于参数空间中动态信息提取的混乱过程。通过引入准Lyapunov指数（QLE），我们定量分析模型在不同层的混乱特征。实验表明，该模型的信息积累遵循非线性指数定律，而多层感知器（MLP）在最终输出中的比例比注意机制更高。进一步的实验表明，较小的初始价值扰动将对模型的推理能力产生重大影响，从而证实了理论分析，即大语言模型是混乱的系统。这项研究为LLMS推理的解释性提供了混乱理论框架，并揭示了平衡模型设计中创造力和可靠性的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2503.13530</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在部分标记的目标域下，电动机中复合故障诊断的多输出分类</title>
      <link>https://arxiv.org/abs/2503.13534</link>
      <description><![CDATA[ARXIV：2503.13534V1公告类型：新 
摘要：本研究提出了一种新型的多输出分类（MOC）框架，旨在在故障诊断中适应域的适应性，以解决由部分标记的（PL）目标域数据集提出的挑战，并在旋转机械中遇到了故障。与常规的多类分类（MCC）方法不同，MOC框架独立地分类了每个故障的严重性，从而提高了诊断精度。通过整合多内核最大平均差异损失（MKMMD）和熵最小化损失（EM），提出的方法可改善源和目标域之间的特征可传递性，而频率层归一化（FLN）通过利用机械特性来有效处理固定振动信号。跨六个领域适应案例的实验评估包括部分标记（PL）方案，证明了MOC方法在宏F1评分方面的优越性能。]]></description>
      <guid>https://arxiv.org/abs/2503.13534</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FEDTILT：致力于多层次公平和强大的联邦学习</title>
      <link>https://arxiv.org/abs/2503.13537</link>
      <description><![CDATA[ARXIV：2503.13537V1公告类型：新 
摘要：联邦学习（FL）是一种新兴的分散学习范式，可以部分解决传统的集中和分布式学习无法处理的隐私问题。此外，要使FL实用，也有必要考虑公平和稳健性等约束。但是，现有的强大FL方法通常会产生不公平的模型，而现有的公平FL方法仅考虑一级（客户）公平性，并且对在现实世界中常见的持续异常值（即注入每个训练回合）的持续异常值（即注入每个训练回合）。我们提出\ texttt {fedilt}，这是一种新颖的fl，可以保留多层次的公平性并使异常值坚固。特别是，我们考虑了两个共同的公平级别，即\ emph {client figness}  - 跨客户的绩效统一性，\ emph {client data fairness}  - 客户端中不同类别数据的性能的统一性。 \ texttt {fedilt}的灵感来自最近提出的倾斜经验风险最小化，该风险最小化引入了可以灵活调整的倾斜高参数。从理论上讲，我们展示了调整倾斜值如何实现两级公平性并减轻持久的离群值，并得出\ texttt {fedilt}的收敛条件。从经验上讲，我们在不同设置中的一系列现实联合数据集上的评估结果表明，\ texttt {fedilt}框架的有效性和灵活性以及对最先进的框架的优越性。]]></description>
      <guid>https://arxiv.org/abs/2503.13537</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从示范到奖励：没有明确的人类偏好的对准</title>
      <link>https://arxiv.org/abs/2503.13538</link>
      <description><![CDATA[ARXIV：2503.13538V1公告类型：新 
摘要：将大型模型与人类偏好保持一致的挑战之一在于数据要求和当前方法的技术复杂性。主要方法（例如RLHF）涉及多个步骤，每个步骤都需要不同类型的数据，包括演示数据和偏好数据。在RLHF中，通常通过奖励模型对人类的偏好进行建模，该奖励模型可以在强化学习阶段指导政策学习的代理，最终产生与人类偏好保持一致的政策。但是，在本文中，我们提出了基于逆增强学习原则的学习对齐方式的新观点，在这种学习原理中，最佳政策仍然来自奖励最大化。但是，我们直接从演示数据中学习了奖励模型，而不是依靠偏好数据。即使只有演示数据，当前RLHF方法所缺乏的功能，这种新的配方也可以灵活地应用，并且还表明，演示数据提供了比传统智慧所建议的更多的实用性。我们的广泛评估基于公共奖励基准，HuggingFace Open LLM排行榜和MT Bench，这表明我们的方法与仅依赖于演示数据的最新方法相比有利。]]></description>
      <guid>https://arxiv.org/abs/2503.13538</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MSCMHMST：基于变压器的交通流预测模型</title>
      <link>https://arxiv.org/abs/2503.13540</link>
      <description><![CDATA[ARXIV：2503.13540V1公告类型：新 
摘要：本研究提出了一个基于变压器的混合模型，该模型名为MSCMHMST，旨在应对交通流量预测的关键挑战。传统的单方法方法显示出流量预测任务的局限性，而混合方法通过整合不同模型的优势可以提供更准确，更强大的预测。 MSCMHMST模型引入了多头，多尺度的注意机制，使该模型可以并行处理数据的不同部分，并从多个角度从多个角度学习其内在表示，从而增强了模型处理复杂情况的能力。这种机制使该模型能够有效地捕获各种尺度的特征，了解短期变化和长期趋势。 MSCMHMST模型通过PEMS04/08数据集的实验进行了验证，在长，中和短期交通流量预测中，MSCMHMST模型表现出极好的鲁棒性和准确性。结果表明，该模型具有巨大的潜力，为交通流量预测的领域提供了一种新的有效解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.13540</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Har-Doremi：优化数据混合物，以跨异构IMU数据集进行自我监督的人类活动识别</title>
      <link>https://arxiv.org/abs/2503.13542</link>
      <description><![CDATA[ARXIV：2503.13542V1公告类型：新 
摘要：跨数据集人类活动识别（HAR）遭受有限的模型概括，阻碍了其实际部署。为了应对这一关键挑战，灵感来自Doremi在大语言模型（LLMS）中的成功启发，我们引入了用于培训预训练HAR模型的数据混合物优化策略，旨在提高异构数据集的识别性能。但是，由于IMU传感器数据的连续，多渠道和固有的异质特征，直接将Doremi应用于HAR场遇到了新的挑战。为了克服这些局限性，我们提出了一个新颖的框架har-doremi，该框架基于均方误差（MSE）损失引入了掩盖的重建任务。通过将离散的语言序列预测任务提取，该任务依赖于原始的DOREMI框架中的负模样（NLL）损失，提出的框架本质上更适合处理IMU数据的连续和多通道特征。此外，Har-Doremi将Mahony Fusion算法整合到自我监管的HAR预训练中，以减轻不同传感器方向的异质性。这是通过估算每个数据集中的传感器方向并与统一坐标系促进对齐的实现，从而提高了HAR模型的跨数据集概括能力。与当前的最新方法相比，对多个跨数据库HAR转移任务进行的实验评估表明，Har-Doremi平均提高了6.51％的精度，只有大约30％至50％的数据使用。这些结果证实了Har-Doremi在提高预训练HAR模型的概括和数据效率方面的有效性，从而强调了其在促进HAR技术实际部署的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.13542</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过文本语义增强视觉表示：用于异质联盟学习的文本语义驱动原型</title>
      <link>https://arxiv.org/abs/2503.13543</link>
      <description><![CDATA[Arxiv：2503.13543v1公告类型：新 
摘要：联合原型学习（FEDPL）已成为处理联合学习（FL）中数据异质性的有效策略。在FEDPL中，客户协作构建了一组全球功能中心（原型），并让本地功能与这些原型保持一致，以减轻数据异质性的影响。 FEDPL的性能高度取决于原型的质量。现有方法假设原型之间的较大阶层距离会产生更好的性能，从而设计了不同的方法来增加这些距离。但是，我们观察到，尽管这些方法增加了原型距离以增强阶级歧视，但它们不可避免地破坏了类之间的基本语义关系，这对于模型概括至关重要。这就提出了一个重要的问题：如何构建原型，这些原型固有地保留了班级之间的语义关系？在FL中，从有限和异构客户数据中直接学习这些关系可能是有问题的。最近，预训练的语言模型（PLM）的成功表明了他们从广阔的文本语料库中捕获语义关系的能力。在此激励的情况下，我们提出了FedTSP，这是一种新型方法，它利用PLMS从文本模式中构建语义丰富的原型，从而在异质数据设置中更有效地合作。我们首先使用大型语言模型（LLM）为每个类生成细粒的文本描述，然后由服务器上的PLM处理以形成文本原型。为了解决客户端映像模型与PLM之间的模态差距，我们引入了可训练的提示，使原型可以更好地适应客户端任务。广泛的实验表明，FEDTSP会减轻数据异质性，同时显着加速收敛。]]></description>
      <guid>https://arxiv.org/abs/2503.13543</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度合奏的半决心学习：强大投资组合优化的实用框架</title>
      <link>https://arxiv.org/abs/2503.13544</link>
      <description><![CDATA[ARXIV：2503.13544V1公告类型：新 
摘要：我提出了以半决赛为中心的学习，这是对投资组合优化的决策学习的实际适应。我没有直接优化复杂的财务指标，而是采用简单的目标投资组合（Max-Sortino或一局），并使用凸面，交叉渗透损失的训练模型。我进一步结合了深层合奏方法，以降低方差和稳定性能。在两个宇宙（一个向上趋势和另一个范围结合）上的实验表现出比基线组合的一致性超过表现，这表明了我的方法的有效性和鲁棒性。代码可从https://github.com/sdflwde/sdflwde获得]]></description>
      <guid>https://arxiv.org/abs/2503.13544</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过参数迁移规则对黑框函数进行优化</title>
      <link>https://arxiv.org/abs/2503.13545</link>
      <description><![CDATA[ARXIV：2503.13545V1公告类型：新 
摘要：机器学习已在许多方面广泛应用，但是培训机器学习模型越来越困难。有更多的优化问题，名为“黑框”，其中模型参数和结果之间的关系不确定或复杂。当前，优化需要大量查询观测值和参数的黑框模型变得困难。为了克服现有算法的缺点，在这项研究中，我们提出了一种最初来自称为参数偏移规则的量子计算的零阶方法，该方法使用的参数数量比以前的方法少。]]></description>
      <guid>https://arxiv.org/abs/2503.13545</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CNCAST：利用3D Swin Transformer和DIT进行增强的区域天气预报</title>
      <link>https://arxiv.org/abs/2503.13546</link>
      <description><![CDATA[ARXIV：2503.13546V1公告类型：新 
摘要：这项研究介绍了基于Swintransformer 3D体系结构的尖端区域天气预报模型。该模型专门设计，可提供从1小时到5天的精确每小时天气预测，从而显着提高了短期天气预报的可靠性和实用性。与公认的全球模型Pangu相比，我们的模型通常表现出卓越的性能。评估表明，我们的模型在预测大多数天气变量方面表现出色，从而强调了其在有限面积建模领域的更有效替代方案的潜力。该模型的一个值得注意的特征是增强边界条件的整合，灵感来自传统的数值天气预测（NWP）技术。这种集成大大提高了模型的预测精度。此外，该模型还包括一种创新的方法，用于诊断小时总降水量，高空间分辨率约为5公里。这是通过潜在扩散模型实现的，它提供了一种生成高分辨率降水数据的替代方法。]]></description>
      <guid>https://arxiv.org/abs/2503.13546</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>