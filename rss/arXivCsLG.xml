<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 25 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用最近邻神经网络进行储层静态性质评价</title>
      <link>https://arxiv.org/abs/2409.15295</link>
      <description><![CDATA[arXiv:2409.15295v1 公告类型：新
摘要：本文介绍了一种使用最近邻神经网络估计储层建模中静态特性的空间分布的方法。该方法利用神经网络在近似复杂非线性函数方面的优势，特别是对于涉及空间插值的任务。它结合了最近邻算法来捕获数据点之间的局部空间关系，并引入了随机化来量化插值过程中固有的不确定性。这种方法解决了传统地质统计方法（例如反距离加权 (IDW) 和克里金法）的局限性，这些方法通常无法模拟储层数据中复杂的非线性依赖关系。通过整合空间接近度和不确定性量化，所提出的方法可以提高孔隙度和渗透率等静态特性预测的准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.15295</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态大型语言模型中的视觉提示：一项调查</title>
      <link>https://arxiv.org/abs/2409.15310</link>
      <description><![CDATA[arXiv:2409.15310v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 为预训练的大型语言模型 (LLM) 配备了视觉功能。虽然 LLM 中的文本提示已被广泛研究，但视觉提示已经出现，用于更细粒度和自由形式的视觉指令。本文首次全面调查了 MLLM 中的视觉提示方法，重点关注视觉提示、提示生成、组合推理和提示学习。我们对现有的视觉提示进行分类，并讨论在图像上自动提示注释的生成方法。我们还研究了能够更好地在视觉编码器和骨干 LLM 之间进行对齐的视觉提示方法，涉及 MLLM 的视觉基础、对象引用和组合推理能力。此外，我们还总结了模型训练和上下文学习方法，以提高 MLLM 对视觉提示的感知和理解。本文研究了 MLLM 中开发的视觉提示方法，并对这些方法的未来进行了展望。]]></description>
      <guid>https://arxiv.org/abs/2409.15310</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减少深度学习优化中的偏差：RSGDM 方法</title>
      <link>https://arxiv.org/abs/2409.15314</link>
      <description><![CDATA[arXiv:2409.15314v1 Announce Type: new 
摘要：目前广泛使用的一阶深度学习优化器包括非自适应学习率优化器和自适应学习率优化器，前者以SGDM（Stochastic Gradient Descent with Momentum）为代表，后者以Adam为代表。这两种方法都使用指数移动平均来估计整体梯度，但使用指数移动平均来估计整体梯度是有偏的，并且存在滞后。本文提出了一种基于差分修正的RSGDM算法。我们的贡献主要有三点：1）分析了SGDM算法中指数移动平均带来的偏差和滞后。2）利用差分估计项来修正SGDM算法中的偏差和滞后，提出了RSGDM算法。3）在CIFAR数据集上的实验证明了我们的RSGDM算法在收敛精度方面优于SGDM算法。]]></description>
      <guid>https://arxiv.org/abs/2409.15314</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于知识图谱注意力辅助网络的高效推荐模型（KGATAX）</title>
      <link>https://arxiv.org/abs/2409.15315</link>
      <description><![CDATA[arXiv:2409.15315v1 公告类型：新
摘要：推荐系统在帮助用户筛选海量信息方面起着至关重要的作用。然而，传统的推荐算法往往忽略了多源信息的整合和利用，限制了系统的性能。因此，本研究提出了一种新的推荐模型——知识图谱注意力辅助网络（KGAT-AX）。我们首先将知识图谱纳入推荐模型，引入注意力机制，更明确地探索高阶连通性。通过使用多层交互式信息传播，该模型聚合信息以增强其泛化能力。此外，我们通过全息嵌入将辅助信息集成到实体中，通过学习它们的推理关系为每个实体聚合相邻实体的信息。这允许更好地利用与实体相关的辅助信息。我们在真实数据集上进行了实验，以证明KGAT-AX模型的合理性和有效性。通过实验分析，我们观察到了KGAT-AX与其他基线模型相比在公共数据集上的有效性和潜力。 KGAT-AX表现出更好的知识信息捕获和关系学习能力。]]></description>
      <guid>https://arxiv.org/abs/2409.15315</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>块注意力机制助力高效 RAG</title>
      <link>https://arxiv.org/abs/2409.15355</link>
      <description><![CDATA[arXiv:2409.15355v2 公告类型：新
摘要：我们引入了 Block-Attention，这是一种注意力机制，旨在解决检索增强生成 (RAG) 场景中推理延迟和成本增加的问题。与对整个上下文进行编码的现有工作不同，它的主要思想在于将检索到的文档划分为块，其中除了最后一个块之外，每个块都独立计算键值 (KV) 状态。在 RAG 场景中，通过将每一段定义为一个块，Block-Attention 使我们能够预先计算所有段落的 KV 状态并将其缓存在内存中，从而显着降低推理过程中的延迟和计算成本。实现涉及块分割、位置编码计算和微调 LLM 以适应 Block-Attention 机制。在四个 RAG 基准测试上的实验表明，经过块微调后，Block Attention 模型可以达到与自注意力模型相当（68.4% vs 67.9% on Llama3）甚至更好的性能（62.8% vs 59.6% on Mistral）。值得注意的是，Block-Attention 将 TTFT（第一个 token 的时间）和 FLOP（浮点运算）降低到非常低的水平。对于总长度为 32K 的输入序列，仅需 45 毫秒即可输出第一个 token。与自注意力模型相比，时间消耗和相应的 FLOP 分别减少了 98.7% 和 99.8%。]]></description>
      <guid>https://arxiv.org/abs/2409.15355</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 中的奖励稳健 RLHF</title>
      <link>https://arxiv.org/abs/2409.15360</link>
      <description><![CDATA[arXiv:2409.15360v1 公告类型：新
摘要：随着大型语言模型 (LLM) 继续向更高级的智能形式发展，从人类反馈中进行强化学习 (RLHF) 越来越被视为实现通用人工智能 (AGI) 的关键途径。然而，由于奖励模型 (RM) 固有的不稳定性和不完善性，对基于奖励模型 (RM) 的对齐方法的依赖带来了重大挑战，这可能导致奖励黑客和与人类意图不一致等关键问题。在本文中，我们介绍了一个奖励稳健的 RLHF 框架，旨在解决这些基本挑战，为 LLM 中更可靠、更有弹性的学习铺平了道路。我们的方法引入了一个新颖的优化目标，通过结合贝叶斯奖励模型集成 (BRME) 来建模不确定的奖励函数集，从而仔细平衡性能和稳健性。这使得框架能够整合名义性能和最小奖励信号，确保即使在奖励模型不完善的情况下也能更稳定地学习。实证结果表明，我们的框架在各种基准上的表现始终优于传统的 RLHF，显示出更高的准确性和长期稳定性。我们还提供了理论分析，表明奖励稳健的 RLHF 接近恒定奖励设置的稳定性，这在随机案例分析中被证明是有效的。总之，这些贡献凸显了该框架在增强 LLM 与 RLHF 对齐的性能和稳定性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.15360</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于决策树的机器学习算法识别燃烧条​​件，应用于具有高剪切旋流喷射器的模型罐燃烧器</title>
      <link>https://arxiv.org/abs/2409.15363</link>
      <description><![CDATA[arXiv:2409.15363v1 公告类型：新
摘要：燃烧是燃气涡轮发动机的主要过程，需要高效的空气-燃料混合来提高性能。高剪切旋流喷射器通常用于改善燃料雾化和混合，这是决定燃烧效率和排放的关键因素。然而，在某些条件下，燃烧室可能会经历热声不稳定性。在本研究中，基于决策树的机器学习算法用于通过分析甲烷燃料单罐燃烧室的反向旋转高剪切旋流喷射器的声压和高速火焰成像来对燃烧条件进行分类。在雷诺数恒定和当量比变化的情况下，燃烧室表现出稳定和不稳定状态。使用时间序列分析从数据中提取特征，提供对燃烧动力学的洞察。训练有素的监督机器学习模型准确地对稳定和不稳定操作进行分类，展示了对研究参数范围内燃烧条件的有效预测。]]></description>
      <guid>https://arxiv.org/abs/2409.15363</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>前向算法的新型显著性分析</title>
      <link>https://arxiv.org/abs/2409.15365</link>
      <description><![CDATA[arXiv:2409.15365v1 公告类型：新
摘要：将 Forward Forward 算法纳入神经网络训练代表了传统方法的变革性转变，引入了双重前向机制，通过绕过导数传播的复杂性来简化学习过程。该方法以其简单性和效率而著称，涉及执行两次前向传递，第一次使用实际数据以促进正强化，第二次使用合成生成的负数据以实现判别学习。我们的实验证实，Forward Forward 算法不仅仅是一种实验上的新颖性，而且是一种可行的训练策略，可以与传统的多层感知器 (MLP) 架构进行强有力的竞争。为了克服传统显着性技术固有的局限性（主要依赖于基于梯度的方法），我们开发了一种专门针对 Forward Forward 框架定制的定制显着性算法。这种创新算法增强了对特征重要性和网络决策的直观理解，为模型预测中最有影响力的数据特征提供了清晰的可视化。通过利用这种专门的显着性方法，我们可以更深入地了解模型的内部工作原理，从而大大增强我们的解释能力，超越标准方法所提供的能力。我们利用 MNIST 和 Fashion MNIST 数据集进行的评估表明，我们的方法与传统的基于 MLP 的模型相当。]]></description>
      <guid>https://arxiv.org/abs/2409.15365</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型进行轨迹异常检测</title>
      <link>https://arxiv.org/abs/2409.15366</link>
      <description><![CDATA[arXiv:2409.15366v1 公告类型：新
摘要：本文提出了一种使用自回归因果注意模型进行轨迹异常检测的新方法，称为 LM-TAD。该方法利用语言语句和轨迹之间的相似性，两者都由有序元素组成，需要通过外部规则和上下文变化来实现连贯性。通过将轨迹视为标记序列，我们的模型可以学习轨迹上的概率分布，从而能够高精度地识别异常位置。我们结合了用户特定的标记来解释个人行为模式，增强了针对用户上下文的异常检测。我们的实验证明了 LM-TAD 在合成和现实世界数据集上的有效性。特别是，该模型通过检测用户上下文异常，在生活模式 (PoL) 数据集上的表现优于现有方法，并在波尔图出租车数据集上取得了有竞争力的结果，突显了其适应性和稳健性。此外，我们介绍了使用困惑度和意外率指标来检测异常值并精确定位轨迹内的特定异常位置。LM-TAD 框架支持各种轨迹表示，包括 GPS 坐标、停留点和活动类型，证明了其在处理各种轨迹数据方面的多功能性。此外，我们的方法非常适合在线轨迹异常检测，通过缓存注意力机制的键值状态，从而避免重复计算，显著减少计算延迟。]]></description>
      <guid>https://arxiv.org/abs/2409.15366</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Wasserstein 损失对时间序列基础模型进行微调</title>
      <link>https://arxiv.org/abs/2409.15367</link>
      <description><![CDATA[arXiv:2409.15367v1 公告类型：新 
摘要：受自然语言处理 (NLP) 大型语言模型 (LLM) 最新进展的启发，专注于开发时间序列预测基础模型的研究激增。一种方法是使用交叉熵损失在标记化时间序列数据上训练 LLM 架构。虽然这种方法已经显示出有希望的结果，但交叉熵损失主要用于分类任务，并不考虑类别之间的距离。为了解决这个限制，我们建议对此类架构使用 Wasserstein 损失。为了验证我们的方法，我们在 $22$ 个零样本数据集上微调了一个基础时间序列模型，比较了交叉熵损失和 Wasserstein 损失的性能。我们的结果表明，用 Wasserstein 损失代替交叉熵损失可以显着改善点估计。]]></description>
      <guid>https://arxiv.org/abs/2409.15367</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>几何关系嵌入</title>
      <link>https://arxiv.org/abs/2409.15369</link>
      <description><![CDATA[arXiv:2409.15369v1 公告类型：新
摘要：关系表示学习将关系数据转换为连续和低维向量表示。然而，基于向量的表示在捕捉复杂和符号化的关系数据的关键属性方面存在不足。我们提出了几何关系嵌入，这是一种尊重底层符号结构的关系嵌入范式。具体来说，这篇论文介绍了各种几何关系嵌入模型，能够捕捉：1）复杂的结构化模式，如网络和知识图中的层次结构和循环；2）本体中的逻辑结构和适用于约束机器学习模型输出的逻辑约束；3）实体和关系之间的高阶结构。我们从基准和真实世界数据集获得的结果证明了几何关系嵌入在熟练地捕捉关系数据固有的这些离散、符号和结构化属性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.15369</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Smirk：分子基础模型的原子完整标记器</title>
      <link>https://arxiv.org/abs/2409.15370</link>
      <description><![CDATA[arXiv:2409.15370v1 公告类型：新
摘要：分子基础模型正在成为加速分子设计、材料科学和化学信息学的强大工具，利用变压器架构来加速新材料和新药物的发现，同时降低传统从头算方法的计算成本。然而，当前的模型受到封闭词汇标记器的限制，无法捕捉分子结构的全部多样性。在这项工作中，我们系统地评估了十三个化学专用标记器对 SMILES 语言的覆盖范围，发现了巨大的差距。使用 N-gram 语言模型，我们访问了标记器选择对模型性能的影响，并量化了未知标记的信息丢失。我们引入了两个新的标记器，smirk 和 smirk-gpe，它们可以表示整个 OpenSMILES 规范，同时避免现有标记器的缺陷。我们的工作强调了开放词汇建模对于分子基础模型的重要性以及化学信息学对化学多样化基准的必要性。]]></description>
      <guid>https://arxiv.org/abs/2409.15370</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Jagged Flash Attention 增强大规模推荐系统的性能和可扩展性</title>
      <link>https://arxiv.org/abs/2409.15373</link>
      <description><![CDATA[arXiv:2409.15373v1 公告类型：新
摘要：硬件加速器的集成显著提升了现代推荐系统的功能，使得探索以前被认为不切实际的复杂排名范例成为可能。然而，基于 GPU 的计算成本带来了巨大的挑战。在本文中，我们展示了我们开发的一种效率驱动方法来探索这些范例，超越了传统上对原生 PyTorch 模块的依赖。我们解决了排名模型对分类特征的依赖所带来的特定挑战，这些特征的长度各不相同，并使 GPU 的使用变得复杂。我们引入了 Jagged Feature Interaction Kernels，这是一种新颖的方法，旨在通过有效处理动态大小的张量从长分类特征中提取细粒度的见解。我们通过将 Jagged 张量与 Flash Attention 相结合，进一步提高了注意力机制的性能。与密集注意力相比，我们新颖的 Jagged Flash Attention 实现了高达 9 倍的加速和 22 倍的内存减少。值得注意的是，它的表现也优于密集闪存注意力机制，速度提升高达 3 倍，内存效率提升 53%。在生产模型中，我们观察到 QPS 提升了 10%，内存节省了 18%，这使我们能够使用更长的特征和更复杂的架构来扩展我们的推荐系统。]]></description>
      <guid>https://arxiv.org/abs/2409.15373</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ControlMath：可控数据生成促进数学通才模型</title>
      <link>https://arxiv.org/abs/2409.15376</link>
      <description><![CDATA[arXiv:2409.15376v1 公告类型：新
摘要：利用大型语言模型 (LLM) 进行数据增强在数学推理方面取得了令人鼓舞的成果。然而，这些方法在问题多样性方面面临限制，可能会将它们限制在域内/分布数据生成中。为此，我们提出了 ControlMath，这是一种迭代方法，涉及一个方程生成器模块和两个基于 LLM 的代理。该模块创建不同的方程，然后 Problem-Crafter 代理将其转换为数学应用题。反向代理过滤并选择高质量数据，遵循“少即是多”的原则，用更少的数据点获得更好的结果。这种方法可以生成各种数学问题，而不局限于特定的领域或分布。因此，我们收集了 ControlMathQA，其中涉及 190k 个数学应用题。大量结果证明，将我们的数据集与 GSM8K 等域内数据集相结合可以帮助提高模型的数学泛化能力，从而提高特定领域内外的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.15376</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>街景图像在绘制城市环境地图中的覆盖范围和偏差</title>
      <link>https://arxiv.org/abs/2409.15386</link>
      <description><![CDATA[arXiv:2409.15386v1 公告类型：新
摘要：街景图像 (SVI) 已成为城市研究中一种有价值的数据形式，为绘制和感知城市环境提供了新方法。然而，关于 SVI 的代表性、质量和可靠性的基本问题仍未得到充分探索，例如，这些数据能在多大程度上捕捉到城市，数据缺口是否会导致偏差。这项研究定位在空间数据质量和城市分析的交叉点，通过提出一种新颖的工作流程来估计 SVI 对城市环境的特征级覆盖范围来解决这些问题。该工作流程整合了 SVI 与目标特征之间的位置关系以及环境障碍的影响。将数据质量领域扩展到 SVI，我们引入了一个评估覆盖范围的指标系统，重点关注完整性和频率维度。以伦敦为例，进行了三项实验，以确定 SVI 覆盖和表示城市特征的能力中的潜在偏差，重点是建筑物立面。该研究强调了传统空间数据质量指标在评估 SVI 方面的局限性，以及不同数据获取方式下 SVI 覆盖范围的变化。研究还强调了考虑 SVI 独特元数据和水平视角的定制方法。研究结果表明，虽然 SVI 提供了有价值的见解，但它并不是万能药——它在城市研究中的应用需要仔细考虑数据覆盖范围和特征级代表性，以确保可靠的结果。]]></description>
      <guid>https://arxiv.org/abs/2409.15386</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>