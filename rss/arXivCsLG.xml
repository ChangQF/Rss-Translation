<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 05 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>分布式神经网络中熵模型的弹性</title>
      <link>https://arxiv.org/abs/2403.00942</link>
      <description><![CDATA[arXiv:2403.00942v1 公告类型：新
摘要：分布式深度神经网络（DNN）已成为在不牺牲边缘计算系统性能的情况下减少通信开销的关键技术。最近，引入了熵编码以进一步减少通信开销。关键思想是与熵模型联合训练分布式 DNN，熵模型在推理期间用作辅助信息，以自适应地将潜在表示编码为可变长度的比特流。据我们所知，熵模型的弹性还有待研究。因此，在本文中，我们制定并研究了熵模型对有意干扰（例如，对抗性攻击）和无意干扰（例如，天气变化和运动模糊）的恢复能力。通过使用 3 种不同的 DNN 架构、2 种熵模型和 4 个速率失真权衡因素进行的广泛实验活动，我们证明熵攻击可以使通信开销增加高达 95%。通过分离频域和空间域的压缩特征，我们提出了一种新的防御机制，与未受干扰的数据相比，可以将受攻击输入的传输开销减少约 9%，而精度损失仅为约 2%。重要的是，所提出的防御机制是一种独立的方法，可以与对抗性训练等方法结合应用，以进一步提高鲁棒性。将共享代码以实现可重复性。]]></description>
      <guid>https://arxiv.org/abs/2403.00942</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>使用非常大的压差进行微调</title>
      <link>https://arxiv.org/abs/2403.00946</link>
      <description><![CDATA[arXiv:2403.00946v1 公告类型：新
摘要：今天不可能假装机器学习的实践与训练和测试数据遵循相同分布的想法兼容。几位作者最近使用集成技术来展示涉及多个数据分布的场景如何最好地通过表示来提供服务，这些表示既比通过正则化获得最佳分布内性能所获得的表示更丰富，又比在隐式稀疏偏差影响下获得的表示更丰富常见的随机梯度程序。
  该贡献研究了使用非常高的辍学率而不是集成来获得如此丰富的表示。尽管使用这样的丢失率从头开始训练深度网络实际上是不可能的，但在这种条件下对大型预训练模型进行微调不仅是可能的，而且还可以实现超过集成和权重平均方法的分布外性能比如模型汤。这一结果具有实际意义，因为近年来微调场景的重要性显着增长。这一结果还提供了关于丰富表示的性质以及使用相对较小的数据集微调大型网络的本质线性性质的有趣见解。]]></description>
      <guid>https://arxiv.org/abs/2403.00946</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>树正则化表格嵌入</title>
      <link>https://arxiv.org/abs/2403.00963</link>
      <description><![CDATA[arXiv:2403.00963v1 公告类型：新
摘要：表格神经网络（NN）引起了人们的广泛关注，其最新进展逐渐缩小了在许多公共数据集上与基于树的模型的性能差距。虽然主流关注于校准神经网络以适应表格数据，但我们强调同质嵌入的重要性，并交替关注通过监督预训练来规范表格输入。具体来说，我们扩展了最近的工作（DeepTLF），并利用预训练树集成的结构将原始变量转换为单个向量（T2V）或令牌数组（T2T）。在不损失空间效率的情况下，这些二值化嵌入可以被具有完全连接或基于注意力的构建块的规范表格神经网络使用。通过对 88 个具有二元分类任务的 OpenML 数据集进行定量实验，我们验证了所提出的树正则化表示不仅缩小了与基于树的模型的差异，而且与先进的 NN 模型相比，实现了同等且更好的性能。最重要的是，它具有更好的鲁棒性，并且可以轻松扩展和泛化为表格模态的独立编码器。代码：https://github.com/milanlx/tree-regularized-embedding。]]></description>
      <guid>https://arxiv.org/abs/2403.00963</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>一种基于正则化的通过指令图解码器进行信息提取的迁移学习方法</title>
      <link>https://arxiv.org/abs/2403.00891</link>
      <description><![CDATA[arXiv:2403.00891v1 公告类型：新
摘要：信息提取（IE）旨在从文本中提取复杂的结构化信息。为各种 IE 任务构建了大量数据集，导致数据注释耗时且费力。然而，大多数流行的方法侧重于训练特定于任务的模型，而不同 IE 任务之间的共同知识没有明确建模。此外，同一短语在不同任务中可能具有不一致的标签，这对使用统一模型的知识迁移提出了巨大的挑战。在本研究中，我们通过指令图解码器提出了一种基于正则化的 IE (TIE) 迁移学习方法。具体来说，我们首先为所有众所周知的 IE 任务的数据集构建一个指令池，然后提出一个指令图解码器，它根据相应的指令将各种复杂结构统一解码为图。通过这种方式，可以学习与现有数据集共享的常识并将其转移到具有新标签的新数据集。此外，为了缓解各种 IE 任务之间的标签不一致问题，我们引入了一种特定于任务的正则化策略，该策略不会更新具有“相反方向”的两个任务的梯度。我们对涵盖四个 IE 任务的 12 个数据集进行了广泛的实验，结果证明了我们提出的方法的巨大优势]]></description>
      <guid>https://arxiv.org/abs/2403.00891</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:22 GMT</pubDate>
    </item>
    <item>
      <title>无标度对抗性强化学习</title>
      <link>https://arxiv.org/abs/2403.00930</link>
      <description><![CDATA[arXiv:2403.00930v1 公告类型：新
摘要：本文启动了马尔可夫决策过程（MDP）中无标度学习的研究，其中奖励/损失的规模对于学习者来说是未知的。我们设计了一个通用算法框架，\underline{S}cale \underline{C}lipping \underline{B}ound (\texttt{SCB})，并在对抗性多臂强盗（MAB）设置和对抗性 MDP 设置。通过这个框架，我们实现了无标度对抗性 MAB 中的第一个极小最大最优预期遗憾界限和第一个高概率遗憾界限，解决了 \cite{hadiji2023adaptation} 中提出的开放问题。在对抗性 MDP 上，我们的框架还诞生了第一个具有 $\tilde{\mathcal{O}}(\sqrt{T})$ 高概率后悔保证的无标度 RL 算法。]]></description>
      <guid>https://arxiv.org/abs/2403.00930</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:22 GMT</pubDate>
    </item>
    <item>
      <title>通过合成文本生成进行差异化私有知识蒸馏</title>
      <link>https://arxiv.org/abs/2403.00932</link>
      <description><![CDATA[arXiv:2403.00932v1 公告类型：新
摘要：大型语言模型（LLM）在许多不同的下游任务中实现了最先进的性能。然而，数据隐私日益紧迫，要求法学硕士对私有数据进行差分隐私 (DP) 培训。同时，还需要压缩 LLM，以便在资源受限的设备或延迟敏感的应用程序上进行实际部署。差分隐私和模型压缩通常必须权衡效用损失才能实现其目标。此外，同时实现两者可能会导致更多的效用损失。为此，我们提出了一种新颖的差分隐私知识蒸馏算法，该算法利用差分隐私法学硕士生成的合成数据。教师模型的知识通过两种方式传递给学生：一种方式来自合成数据本身（硬标签），另一种方式是通过在合成数据（软标签）上评估的教师模型的输出分布。此外，如果教师和学生共享相似的架构结构，我们可以通过利用隐藏表示来进一步提炼知识。我们的结果表明，我们的框架通过强大的隐私参数 {\epsilon} = 2 显着提高了现有基线的实用性，验证了我们可以成功压缩自回归 LLM，同时保留训练数据的隐私。]]></description>
      <guid>https://arxiv.org/abs/2403.00932</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:22 GMT</pubDate>
    </item>
    <item>
      <title>FedRDMA：通过分块 RDMA 传输实现高效通信的跨筒仓联合 LLM</title>
      <link>https://arxiv.org/abs/2403.00881</link>
      <description><![CDATA[arXiv:2403.00881v1 公告类型：新
摘要：通信开销是联邦学习（FL）的一个重要瓶颈，随着人工智能模型规模的不断增大，这一瓶颈变得更加严重。在本文中，我们提出了 FedRDMA，这是一种通信高效的跨筒仓 FL 系统，它将 RDMA 集成到 FL 通信协议中。为了克服 RDMA 在广域网 (WAN) 中的局限性，FedRDMA 将更新后的模型划分为多个块，并设计了一系列优化技术来提高基于 RDMA 的通信的效率和鲁棒性。我们在工业联合学习框架之上实施 FedRDMA，并在现实世界的跨筒仓 FL 场景中对其进行评估。实验结果表明，与传统基于 TCP/IP 的 FL 系统相比，\sys 的通信效率可实现高达 3.8$\times$ 的加速。]]></description>
      <guid>https://arxiv.org/abs/2403.00881</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:21 GMT</pubDate>
    </item>
    <item>
      <title>通过因果域转移评估和纠正决策支持系统的执行效果</title>
      <link>https://arxiv.org/abs/2403.00886</link>
      <description><![CDATA[arXiv:2403.00886v1 公告类型：新
摘要：当根据特征 $X$ 预测目标变量 $Y$ 时，预测 $\hat{Y}$ 可以是执行性的：代理可能会根据此预测采取行动，影响我们最终观察到的 $Y$ 的值。执行预测在算法决策支持中非常普遍，其中决策支持系统 (DSS) 为代理提供影响目标变量值的预测。在高风险环境（例如医疗保健、法律、预测性警务或儿童福利筛查）中部署 DSS 时，必须仔细评估 DSS 的执行效果。在 DSS 作为预测负面结果的警报的情况下，由于先前模型的有效运作，对预测模型的简单再训练必然会导致模型低估风险。在这项工作中，我们建议将 DSS 的部署建模为因果域转移，并为条件期望 $E[Y | 提供新颖的跨域识别结果。 X]$，允许对 DSS 的部署进行事前和事后评估，并重新训练模型，以评估未部署 DSS 的基线政策下的风险。通过一个正在运行的例子，我们凭经验证明，即使数据受到样本选择偏差和选择性标签的影响，重复回归过程也为估计这些数量提供了一个实用的框架，为多种形式的目标变量偏差提供了实用的、统一的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.00886</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:21 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络激活区域精确枚举的并行算法</title>
      <link>https://arxiv.org/abs/2403.00860</link>
      <description><![CDATA[arXiv:2403.00860v1 公告类型：新
摘要：使用修正线性单元的前馈神经网络通过将其输入空间划分为一组凸区域来构造从输入到输出的映射，其中区域内的点共享单个仿射变换。为了了解神经网络如何工作、何时以及为何失败以及它们与生物智能的比较，我们需要了解这些区域的组织和形成。第一步是设计和实现在玩具示例之外的网络中精确区域枚举的算法。
  在这项工作中，我们提出了深度（和浅层）神经网络中精确枚举的并行算法。我们的工作有三个主要贡献：（1）我们提出了一种新颖的算法框架和用于区域枚举的并行算法； (2) 我们在各种网络架构上实现我们的算法之一，并通过实验展示区域数量如何决定运行时间； (3)我们使用算法的输出展示了区域仿射变换的维度如何影响更深层次的区域进一步划分。
  据我们所知，我们在比现有区域枚举文献中使用的所有网络更大的网络上运行我们实现的算法。此外，我们通过实验证明了并行性对于任何合理大小的网络的区域枚举的重要性。]]></description>
      <guid>https://arxiv.org/abs/2403.00860</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:20 GMT</pubDate>
    </item>
    <item>
      <title>通过互信息驱动的跨变量和时间建模增强多元时间序列预测</title>
      <link>https://arxiv.org/abs/2403.00869</link>
      <description><![CDATA[arXiv:2403.00869v1 公告类型：新
摘要：最近的进展强调了深度学习技术对多元时间序列预测（MTSF）的影响。一般来说，这些技术分为两类：通道独立方法和通道混合方法。尽管通道独立方法通常会产生更好的结果，但通道混合理论上可以通过利用变量间的相关性来提供改进。尽管如此，我们认为在通道混合方法中集成不相关信息可能会限制 MTSF 模型性能的潜在增强。为了证实这一说法，我们引入了用于通道混合方法的跨变量解相关感知特征建模（CDAM），旨在通过最小化通道之间的冗余信息同时增强相关互信息来完善通道混合。此外，我们引入了时间相关性感知建模（TAM）来利用时间相关性，这比传统的单步预测方法更进一步。该策略最大化了预测序列和目标序列的相邻子序列之间的互信息。结合 CDAM 和 TAM，我们的新颖框架在综合测试中显着超越了现有模型，包括以前被认为是最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2403.00869</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:20 GMT</pubDate>
    </item>
    <item>
      <title>分解多塔：用于高效大规模推荐的拓扑感知建模技术</title>
      <link>https://arxiv.org/abs/2403.00877</link>
      <description><![CDATA[arXiv:2403.00877v1 公告类型：新
摘要：我们研究了深度学习推荐模型的扁平架构、常见的分布式训练范式和分层数据中心拓扑之间的不匹配。为了解决相关的低效率问题，我们提出了分解多塔（DMT），这是一种建模技术，包括（1）语义保留塔变换（SPTT），这是一种新颖的训练范例，将整体全局嵌入查找过程分解为不相交的塔，以利用数据中心位置； (2) Tower Module (TM)，一个附加到每个塔的协同密集组件，通过分层特征交互来降低模型复杂性和通信量； (3) Tower Partitioner (TP)，一种特征分区器，用于系统地创建具有有意义的特征交互和负载平衡分配的塔，以通过学习的嵌入来保持模型质量和训练吞吐量。我们证明，与最先进的基准相比，DMT 可以实现高达 1.9 倍的加速，而不会损失大型数据中心规模的多代硬件的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.00877</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:20 GMT</pubDate>
    </item>
    <item>
      <title>犯罪预测数据挖掘技术的实证和实验见解：综合调查</title>
      <link>https://arxiv.org/abs/2403.00780</link>
      <description><![CDATA[arXiv:2403.00780v1 公告类型：新
摘要：这篇调查论文对犯罪预测方法进行了全面分析，探讨了该领域使用的各种技巧和技术。本文涵盖了用于分析犯罪数据的统计方法、机器学习算法和深度学习技术，同时也检验了它们的有效性和局限性。我们提出了一种方法分类法，将犯罪预测算法分为特定技术。该分类法分为四层，包括方法论类别、方法论子类别、方法论技术和方法论子技术。提供了经验和实验评估来对不同的技术进行排名。实证评估根据四个标准评估犯罪预测技术，而实验评估则对采用相同子技术的算法、采用相同技术的不同子技术、采用相同方法子类别的不同技术进行排名、同一类别内的不同方法子类别以及不同的方法类别。方法分类、实证评估和实验比较相结合，可以对犯罪预测算法有细致入微和全面的了解，帮助研究人员做出明智的决策。最后，本文展望了犯罪预测技术的未来，强调了该领域进一步研究的潜在进展和机会]]></description>
      <guid>https://arxiv.org/abs/2403.00780</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:19 GMT</pubDate>
    </item>
    <item>
      <title>有偏梯度估计下的分布式动量方法</title>
      <link>https://arxiv.org/abs/2403.00853</link>
      <description><![CDATA[arXiv:2403.00853v1 公告类型：新
摘要：分布式随机梯度方法在解决涉及分布在多个节点的数据的大规模机器学习问题中越来越受到重视。然而，获得无偏随机梯度一直是大多数理论研究的焦点，这在许多分布式机器学习应用中是具有挑战性的。梯度估计很容易产生偏差，例如，当梯度被压缩或剪切时、当数据被打乱时、以及在元学习和强化学习中。在这项工作中，我们在一般非凸和 $\mu$-PL 非凸问题上的有偏梯度估计下建立了分布式动量方法的非渐近收敛界。我们的分析涵盖了一般的分布式优化问题，并且我们计算出了梯度估计有偏差的特殊情况的影响，即在元学习中以及当梯度被压缩或裁剪时。我们通过 Top-$K$ 稀疏化和裁剪训练深度神经网络的数值实验验证了动量方法比传统偏置梯度下降更快的收敛性能。]]></description>
      <guid>https://arxiv.org/abs/2403.00853</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:19 GMT</pubDate>
    </item>
    <item>
      <title>用于推测性解码的草案模型与聊天微调 LLM 的直接对齐</title>
      <link>https://arxiv.org/abs/2403.00858</link>
      <description><![CDATA[arXiv:2403.00858v1 公告类型：新
摘要：众所周知，大型语言模型（LLM）的文本生成由于其自回归性质、巨大的参数数量和有限的内存带宽的结合而受到内存限制，通常会导致低标记率。推测性解码已被提议作为 LLM 推理加速的解决方案。然而，由于草稿模型在现代开源 LLM 系列中通常不可用，例如 Llama 2 7B，因此需要训练高质量的草稿模型才能通过推测解码实现推理加速。在本文中，我们提出了一个简单的模型训练框架草案，用于直接与支持聊天的目标模型对齐。利用所提出的框架，我们训练了 Llama 2 Chat Drafter 115M，这是 Llama 2 Chat 7B 或更大的草稿模型，尺寸仅为原始大小的 1.64%。我们的训练框架仅包含预训练、蒸馏数据集生成和知识蒸馏微调，没有额外的对齐过程。对于微调步骤，我们使用目标模型生成的指令响应对在合理的数据分布中进行蒸馏，并提出了一种新的总变异距离++（TVD++）损失，该损失结合了受强化学习中策略梯度方法启发的方差减少技术。我们的实证结果表明，相对于各种任务的自回归解码，具有推测性解码的 Llama 2 Chat Drafter 115M 可实现高达 2.3 的块效率和 2.4$\times$ 的加速，而无需进一步针对特定任务进行微调。]]></description>
      <guid>https://arxiv.org/abs/2403.00858</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:19 GMT</pubDate>
    </item>
    <item>
      <title>事后选择和深度学习中的不当行为</title>
      <link>https://arxiv.org/abs/2403.00773</link>
      <description><![CDATA[arXiv:2403.00773v1 公告类型：新
摘要：这是一篇关于“深度学习”不当行为和一般选后行为的理论论文。据作者所知，第一篇关于深度学习不当行为的同行评审论文是[32]、[37]、[36]。无论学习模式如何，例如监督式、强化式、对抗式和进化式，几乎所有机器学习方法（除了少数训练单一系统的方法）都源于相同的不当行为——作弊和隐藏——（1）作弊在没有测试的情况下（2）隐藏看起来不好的数据。 [32]、[37]、[36] 中提出，作者必须至少报告验证集上所有经过训练的网络（无论好坏）的平均误差（在本文中称为一般交叉验证）。更好的是，还报告排名错误的五个百分比位置。从这里的新分析中，我们可以看到隐藏的罪魁祸首是后选择。对于手动调整或搜索超参数的后选择也是如此，因为它们是随机的，取决于随机观察数据。数据分割的交叉验证是否可以挽救不当行为（1）和（2）中的后选择？这里的新结果是：不。具体来说，本文揭示了使用交叉验证进行数据分割不足以证明机器学习中的后选择是无罪的。一般来说，统计学习者根据验证集上的错误进行的后选择在统计上是无效的。]]></description>
      <guid>https://arxiv.org/abs/2403.00773</guid>
      <pubDate>Tue, 05 Mar 2024 15:13:18 GMT</pubDate>
    </item>
    </channel>
</rss>