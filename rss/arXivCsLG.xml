<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 09 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>负零的力量：量化大型语言模型的数据类型定制</title>
      <link>https://arxiv.org/abs/2501.04052</link>
      <description><![CDATA[arXiv:2501.04052v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种机器学习任务中表现出色，迅速成为最普遍的 AI 工作负载之一。然而，LLM 的大量内存需求严重阻碍了它们为最终用户部署。训练后量化 (PTQ) 是减轻 LLM 内存和计算需求的最硬件高效方法之一。虽然传统整数 (INT) 数据类型已在 PTQ 方法中得到广泛采用，但浮点 (FP) 量化已成为一种可行的替代方案，这要归功于它在拟合 LLM 数值分布方面的有效性。然而，符号幅度二进制表示中的 FP 数据类型包含正零和负零，这限制了它的表示能力，尤其是在低精度（3 和 4 位）下。在本文中，我们扩展了基本 FP 数据类型以执行冗余零重映射 (RaZeR)，它将负零 FP 编码重映射到一组预定义的特殊值，以最大限度地利用 FP 量化编码并更好地拟合 LLM 数值分布。通过精心选择特殊值，RaZeR 的表现优于传统的非对称 INT 量化，同时实现了高计算效率。我们证明 RaZeR 可以与权重和 KV 缓存的量化算法无缝集成，包括具有剪辑和变换的高级方法，并始终如一地实现更好的模型精度。此外，我们实现了具有融合反量化的快速 GEMV 内核，可通过新颖的位级操作将 4 位 RaZeR 值有效地转换为 FP16。在现代 GPU 上，我们的评估表明，与 FP16 实现相比，RaZeR 将 GEMV 速度提高了高达 7.56$\times$，同时在 LLM 解码吞吐量上实现了高达 2.72$\times$ 的加速。]]></description>
      <guid>https://arxiv.org/abs/2501.04052</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SFADNet：基于注意力解耦网络的时空融合图用于交通预测</title>
      <link>https://arxiv.org/abs/2501.04060</link>
      <description><![CDATA[arXiv:2501.04060v1 公告类型：新
摘要：近年来，交通流预测在智能交通系统管理中发挥着至关重要的作用。然而，传统的预测方法往往受限于静态空间建模，难以准确捕捉时间和空间之间的动态复杂关系，从而影响预测精度。本文提出了一种创新的交通流预测网络SFADNet，该网络基于时间和空间特征矩阵将交通流分为多种交通模式。对于每种模式，我们基于交叉注意机制构建一个独立的自适应时空融合图，采用残差图卷积模块和时间序列模块来更好地捕捉不同细粒度交通模式下的动态时空关系。大量的实验结果表明，SFADNet 在四个大规模数据集上的表现优于当前最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2501.04060</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于评估个性化治疗效果的因果机器学习方法——从两项大型试验中获得的有效性见解</title>
      <link>https://arxiv.org/abs/2501.04061</link>
      <description><![CDATA[arXiv:2501.04061v1 公告类型：新
摘要：因果机器学习 (ML) 方法通过估计个性化治疗效果，有望推动精准医疗的发展。然而，它们的可靠性在实证环境中仍未得到很大程度的验证。在这项研究中，我们使用两项大型随机对照试验的数据评估了 17 种主流因果异质性 ML 方法（包括元学习器、基于树的方法和深度学习方法）的内部和外部有效性：国际卒中试验 (N=19,435) 和中国急性卒中试验 (N=21,106)。我们的研究结果表明，无论是内部还是外部，没有任何 ML 方法能够可靠地验证其性能，在提出的评估指标上，训练数据和测试数据之间存在显著差异。即使在没有分布变化的情况下，从训练数据估计的个性化治疗效果也无法推广到测试数据。这些结果引发了人们对因果机器学习模型在精准医疗中当前适用性的担忧，并强调需要更强大的验证技术来确保普遍性。]]></description>
      <guid>https://arxiv.org/abs/2501.04061</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模糊信息熵和区域偏差矩阵分解用于 Web 服务 QoS 预测</title>
      <link>https://arxiv.org/abs/2501.04063</link>
      <description><![CDATA[arXiv:2501.04063v1 公告类型：新
摘要：如今，互联网上有许多类似的服务，服务质量（QoS）成为用户关注的重点。由于通过用户调用收集所有服务的 QoS 值是不切实际的，因此预测 QoS 值是一种更可行的方法。矩阵分解被认为是一种有效的预测方法。然而，大多数现有的矩阵分解算法侧重于捕获用户和服务之间的全局相似性，而忽略了用户与其相似邻居之间的局部相似性以及用户与服务之间的非交互作用。本文提出了一种基于用户信息熵和区域偏差的矩阵分解方法，该方法利用基于模糊信息熵的相似性测量方法来识别用户的相似邻居。同时，它将每个用户和服务之间的区域偏差线性地集成到矩阵分解中，以捕获用户和服务之间的非交互特征。该方法在更现实和复杂的网络环境中表现出更好的预测性能。此外，我们还在真实 QoS 数据集上进行了大量实验。实验结果表明，在矩阵密度为 5% 到 20% 的范围内，该方法的表现优于该领域的一些最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2501.04063</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedKD-hybrid：用于光刻热点检测的联合混合知识蒸馏</title>
      <link>https://arxiv.org/abs/2501.04066</link>
      <description><![CDATA[arXiv:2501.04066v1 公告类型：新
摘要：联邦学习（FL）为分布式隐私保护设置下基于机器学习（ML）的光刻热点检测（LHD）提供了新颖的解决方案。目前，已经研究了两种研究流程来聚合本地模型并实现全局共识，包括基于参数/非参数（也称为知识蒸馏，即KD）。虽然这两种方法在特定场景中显示出有效性，但我们注意到它们尚未充分利用和传输所学到的信息，因此基于FL的LDH的潜力仍未得到探索。因此，我们在本研究中提出了FedKDhybrid来弥补研究差距。具体而言，FedKD混合客户端在所有参与者和一个公共数据集上就几个相同的层达成一致，以实现全局共识。在训练期间，将在公共数据集上评估训练后的本地模型，并将生成的logits与相同的层参数一起上传。因此，聚合信息用于通过公共数据集作为媒介来更新本地模型。我们将我们提出的 FedKD-hybrid 与 ICCAD-2012 和 FAB（真实世界收集）数据集下具有不同设置的几种最先进的 (SOTA) FL 方法进行了比较；实验结果证明了 FedKD-hybrid 算法的卓越性能。我们的代码可在 https://github.com/itsnotacie/NN-FedKD-hybrid 上找到]]></description>
      <guid>https://arxiv.org/abs/2501.04066</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一级方程式赛车策略中轮胎能量的可解释时间序列预测</title>
      <link>https://arxiv.org/abs/2501.04067</link>
      <description><![CDATA[arXiv:2501.04067v1 公告类型：新
摘要：一级方程式赛车 (F1) 比赛策略是在高压和快节奏的环境中进行的，瞬间的决定可能会极大地影响比赛结果。比赛策略的两个核心决策是何时进站（即更换汽车轮胎）以及选择哪种轮胎化合物（正常情况下为硬、中或软）。最佳进站决策可以通过估计这些化合物的轮胎退化来确定，而轮胎退化又可以根据施加到每个轮胎上的能量（即轮胎能量）计算出来。在这项工作中，我们使用由遥测组成的梅赛德斯-AMG PETRONAS F1 车队的历史比赛数据训练深度学习模型，以预测比赛期间的轮胎能量。此外，我们将基于决策树的机器学习算法 XGBoost 拟合到同一数据集并比较结果，两者都给出了令人印象深刻的性能。此外，我们结合了两种不同的可解释 AI 方法，即特征重要性和反事实解释，以深入了解预测背后的原因。因此，我们的贡献产生了一种可解释的自动化方法，可以帮助 F1 车队优化比赛策略。]]></description>
      <guid>https://arxiv.org/abs/2501.04067</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的强化学习，用于一级方程式赛车策略</title>
      <link>https://arxiv.org/abs/2501.04068</link>
      <description><![CDATA[arXiv:2501.04068v1 公告类型：新
摘要：在一级方程式赛车中，各车队竞相开发自己的赛车，并在每场比赛中获得尽可能高的完赛位置。然而，在比赛期间，车队无法改变赛车，因此他们必须通过比赛策略来提高赛车的完赛位置，即优化选择在赛车上使用哪种轮胎配方以及何时使用。在这项工作中，我们引入了一种强化学习模型 RSRL（比赛策略强化学习），以控制模拟中的比赛策略，为行业标准的硬编码和基于蒙特卡罗的比赛策略提供更快的替代方案。控制赛车的速度相当于预期完赛位置 P5.5（其中 P1 代表第一名，P20 代表最后一名），RSRL 在我们的测试赛 2023 年巴林大奖赛上取得了 P5.33 的平均完赛位置，超过了 P5.63 的最佳基线。然后，我们在一项普遍性研究中展示了如何通过训练对一条或多条赛道的表现进行优先排序。此外，我们用特征重要性、基于决策树的代理模型和决策树反事实来补充模型预测，以提高用户对模型的信任度。最后，我们提供了一些例子来说明我们在现实世界中的方法，将模拟与现实进行比较。]]></description>
      <guid>https://arxiv.org/abs/2501.04068</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更多并不总是更好？通过差异化和重新加权目标增强多镜头情境学习</title>
      <link>https://arxiv.org/abs/2501.04070</link>
      <description><![CDATA[arXiv:2501.04070v1 公告类型：新
摘要：大型语言模型 (LLM) 在无需参数更新的情况下擅长少量上下文学习 (ICL)。然而，随着 ICL 演示的数量从少数增加到多数，性能趋于稳定并最终下降。我们确定了造成这种趋势的两个主要原因：次优负对数似然 (NLL) 优化目标和增量数据噪声。为了解决这些问题，我们引入了 DR-ICL，这是一种新颖的优化方法，它通过差异化学习和基于优势的重新加权目标来提高模型性能。从全局来看，DR-ICL 利用差异化学习来优化 NLL 目标，确保多次演示性能超过零次演示水平。在本地，它通过利用强化学习启发的累积优势动态调整多次演示的权重，从而提高泛化能力。这种方法允许模型有效地处理不同数量的演示，从而减轻噪声数据的影响。认识到缺乏具有多样化多镜头分布的多任务数据集，我们开发了多镜头 ICL 基准 (MICLB)，这是一个大规模基准，涵盖多达 8,000 个标记序列中从 1 到 350 的镜头数，用于微调目的。MICLB 有助于在七个主要 NLP 任务和 50 个不同的数据集中评估多镜头 ICL 策略。实验结果表明，使用 DR-ICL 增强的 LLM 在各种任务的多镜头设置中实现了显着改进，包括域内和域外场景。我们发布了代码和基准数据集，希望促进对多镜头 ICL 的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2501.04070</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于邻域位移的多类不平衡数据增强合成过采样</title>
      <link>https://arxiv.org/abs/2501.04099</link>
      <description><![CDATA[arXiv:2501.04099v1 公告类型：新
摘要：不平衡的多类数据集对机器学习算法提出了挑战。这些数据集通常包含对准确预测很重要的少数类。现有方法仍然受到稀疏数据的困扰，可能无法准确表示原始数据模式，从而导致噪声和模型性能不佳。本文提出了一种称为基于邻域位移的增强合成过采样 (NDESO) 的混合方法。该方法对噪声数据点使用位移策略，计算到其邻居的平均距离并将它们移近其质心。然后执行随机过采样以实现数据集平衡。广泛的评估比较了 9 个分类器上的 14 种替代方案，这些分类器跨越合成数据集和 20 个具有不同不平衡率的真实数据集。结果表明，我们的方法在平均 G 均值得分方面优于其竞争对手，并实现了最低的统计平均排名。这凸显了它在实际应用中解决数据不平衡的优越性和适用性。]]></description>
      <guid>https://arxiv.org/abs/2501.04099</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强图分布和标签一致性以实现非分布泛化</title>
      <link>https://arxiv.org/abs/2501.04102</link>
      <description><![CDATA[arXiv:2501.04102v1 公告类型：新
摘要：为了处理图数据中的分布变化，最近提出了各种图非分布 (OOD) 泛化技术。这些方法通常采用两步策略，首先创建增强环境，然后识别不变子图以提高泛化能力。然而，从一致性的角度来看，这种方法可能不是最优的。首先，通过改变图同时保留标签来增强环境的过程可能会导致图不切实际或与原始分布没有有意义的关系，从而缺乏分布一致性。其次，提取的子图是通过直接修改图获得的，可能不一定与其标签保持一致的预测关系，从而影响标签一致性。为了应对这些挑战，我们引入了一种创新方法，旨在增强图 OOD 泛化的这两种一致性。我们提出了一个修改器，以统一的方式获得增强图和不变图。利用增强图，我们可以丰富训练数据，同时又不损害标签图关系的完整性。我们框架中的标签一致性增强功能进一步保留了不变图中的监督信息。我们在真实数据集上进行了广泛的实验，以证明我们的框架优于其他最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2501.04102</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepVIVONet：使用深度神经算子优化传感器位置并应用于涡流引起的振动</title>
      <link>https://arxiv.org/abs/2501.04105</link>
      <description><![CDATA[arXiv:2501.04105v1 公告类型：新
摘要：我们介绍了 DeepVIVONet，这是一种使用现场数据对海洋立管的涡激振动 (VIV) 进行最佳动态重建和预测的新框架。我们证明了 DeepVIVONet 通过使用稀疏时空测量准确重建海上立管运动的有效性。我们还展示了我们的模型通过迁移学习推断到其他流动条件的泛化，强调了其简化运营效率和提高预测准确性的潜力。经过训练的 DeepVIVONet 可作为海洋立管的快速准确替代模型，我们在外环优化算法中使用它来获得放置传感器的最佳位置。此外，我们采用基于适当正交分解 (POD) 的现有传感器放置方法与我们的数据驱动方法进行比较。我们发现，虽然 POD 为初始传感器放置提供了一种良好的方法，但 DeepVIVONet 的自适应功能可以提供更精确、更具成本效益的配置。]]></description>
      <guid>https://arxiv.org/abs/2501.04105</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过操作流匹配进行随机过程学习</title>
      <link>https://arxiv.org/abs/2501.04126</link>
      <description><![CDATA[arXiv:2501.04126v1 公告类型：新
摘要：通过扩展神经算子，我们提出了一种跨任意领域的随机过程学习的新框架。具体来说，我们开发了算子流匹配 (\alg)，用于在函数空间上学习随机过程先验。\alg 提供任何点集值的概率密度，并实现在新点上进行数学上可处理的函数回归，并进行均值和密度估计。我们的方法在随机过程学习、函数回归和先验学习方面优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2501.04126</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BiasGuard：机器学习生产系统中的公平性保障</title>
      <link>https://arxiv.org/abs/2501.04142</link>
      <description><![CDATA[arXiv:2501.04142v1 公告类型：新
摘要：随着机器学习 (ML) 系统对招聘、金融风险评估和刑事司法等关键领域的影响越来越大，由于潜在的负面影响，确保公平的必要性也随之增强。虽然许多 ML 公平性研究都集中在增强训练数据和流程上，但解决已部署系统的输出问题却受到较少关注。本文介绍了一种新方法“BiasGuard”，旨在充当生产 ML 系统中的公平护栏。BiasGuard 利用由条件生成对抗网络 (CTGAN)（一种尖端的生成 AI 模型）提供支持的测试时间增强 (TTA) 来合成以倒置受保护属性值为条件的数据样本，从而促进不同群体之间的公平结果。该方法旨在为特权群体和非特权群体提供平等的机会，同时显着提高已部署系统的公平性指标，而无需重新训练。我们对各种数据集进行的全面实验分析表明，与未缓解的基准相比，BiasGuard 将公平性提高了 31%，而准确率仅降低了 0.09%。此外，BiasGuard 在提高公平性方面的表现优于现有的后处理方法，当重新训练模型不切实际时，它可以成为一种有效的工具来防止偏见。]]></description>
      <guid>https://arxiv.org/abs/2501.04142</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KGIF：利用知识图谱信息融合优化关系感知推荐</title>
      <link>https://arxiv.org/abs/2501.04161</link>
      <description><![CDATA[arXiv:2501.04161v1 公告类型：新
摘要：虽然支持深度学习的推荐系统表现出强大的性能基准，但由于用户-项目关系数据的使用有限以及推荐生成透明度不足，许多系统难以在现实环境中有效适应。传统的协同过滤方法无法整合多方面的项目属性，尽管分解机考虑了特定于项目的细节，但它们忽略了更广泛的关系模式。基于协作知识图谱的模型通过将用户-项目交互与项目-属性关系嵌入在一起而取得了进展，为相互关联的实体提供了整体视角。然而，这些模型经常以隐式方式聚合属性和交互数据，导致有价值的关系细微差别得不到充分利用。
本研究介绍了具有信息融合的知识图谱注意网络 (KGIF)，这是一个专门的框架，旨在通过量身定制的自注意力机制显式合并实体和关系嵌入。 KGIF 框架通过动态投影向量集成了重新参数化，使嵌入能够自适应地表示知识图谱中的复杂关系。这种显式融合增强了用户-项目交互和项目-属性关系之间的相互作用，在以用户为中心和以项目为中心的表示之间提供了细微的平衡。注意力传播机制进一步优化了知识图谱嵌入，捕获了多层交互模式。这项工作的贡献包括显式信息融合的创新方法、稀疏知识图谱的增强鲁棒性以及通过可解释的路径可视化生成可解释建议的能力。]]></description>
      <guid>https://arxiv.org/abs/2501.04161</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络的不动点：出现、稳定性和应用</title>
      <link>https://arxiv.org/abs/2501.04182</link>
      <description><![CDATA[arXiv:2501.04182v1 公告类型：新
摘要：我们给出了关于深度神经网络 (DNN) 不动点家族的形成和稳定性的数值和分析结果。当输入和输出向量的维度相同时，此类不动点会出现在一类 DNN 中。我们展示了此类网络在监督、半监督和无监督学习中的应用示例，例如图像的编码/解码、受损图像的修复等。
我们给出了几个数值和分析结果。首先，我们表明，对于权重和偏差由正态分布的随机变量初始化的未经训练的 DNN，只存在一个不动点。此结果适用于具有任何深度（层数）$L$、任何层宽度 $N$ 和 S 型激活函数的 DNN。其次，已经证明，对于其参数（权重和偏差）由权重的“轻尾”分布（例如正态分布）初始化的 DNN，经过训练后，这些参数的分布将变为“重尾”。这促使我们研究具有“重尾”初始化的 DNN。对于此类 DNN，我们通过数值证明了其存在性和稳定性，即训练会导致出现 $Q(N,L)$ 个不动点，其中 $Q(N,L)$ 是一个正整数，它取决于层数 $L$ 和层宽度 $N$。我们进一步从数值上观察到，对于固定的 $N = N_0$，函数 $Q(N_0, L)$ 是非单调的，也就是说，它最初随着 $L$ 的增加而增长，然后减小到 1。

$Q(N_0, L)$ 的这种非单调行为也是通过对输入输出雅可比矩阵的经验谱分布 (ESD) 方程进行解析推导，然后对该方程进行数值解而获得的。]]></description>
      <guid>https://arxiv.org/abs/2501.04182</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>