<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 28 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在基于预训练模型的类增量学习中集成双重原型以实现任务自适应</title>
      <link>https://arxiv.org/abs/2411.17766</link>
      <description><![CDATA[arXiv:2411.17766v1 公告类型：新
摘要：类增量学习 (CIL) 旨在获取新类，同时逐步保存历史知识。尽管现有的基于预训练模型 (PTM) 的方法在 CIL 中表现出色，但最好在下游增量任务上对它们进行微调，因为 PTM 不知道大量模式。然而，使用任务流进行微调可能会导致灾难性的遗忘，从而抹去 PTM 中的知识。本文提出了基于 PTM 的 CIL 任务自适应 (DPTA) 的双原型网络。对于每个增量学习任务，都会构建一个任务适配器模块来微调 PTM，其中中心自适应损失迫使表示更加集中聚类和类可分离。双原型网络通过测试时适配器选择改进了预测过程，其中原始原型推导出测试样本的几个可能的任务指标以选择适合 PTM 的适配器模块，并且使用可以分离高度相关类的增强原型来确定最终结果。在多个基准数据集上的实验证明了 DPTA 的领先性能。代码将在论文发表后开源。]]></description>
      <guid>https://arxiv.org/abs/2411.17766</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MTS-UNMixers：通过通道时间双​​重解混进行多元时间序列预测</title>
      <link>https://arxiv.org/abs/2411.17770</link>
      <description><![CDATA[arXiv:2411.17770v1 公告类型：新
摘要：多元时间序列数据通过利用跨多个维度的信息为未来预测提供了稳健的框架，确保在实际场景中的广泛适用性。然而，它们的高维性和混合模式对建立历史和未来序列之间可解释和明确的映射以及提取长距离特征依赖性提出了重大挑战。为了应对这些挑战，我们提出了一种用于多元时间序列预测的通道时间双​​解混网络（称为 MTS-UNMixer），它将整个序列分解为时间和通道维度上的关键基数和系数。这种方法在历史和未来序列之间建立了一个强大的共享机制，实现了准确的表示并增强了物理可解释性。具体而言，MTS-UNMixers 将随时间变化的序列表示为多种趋势和周期的混合，时间相关的表示系数在历史和未来时间段内共享。相比之下，通道序列可以分解为多个逐刻基，这些基表征通道相关性并在整个系列中共享。为了估计共享的时间相关系数，采用了 vanilla Mamba 网络，利用其与方向因果关系的一致性。相反，双向 Mamba 网络用于对共享通道相关基进行建模，以适应非因果关系。实验结果表明，MTS-UNMixers 在多个基准数据集上的表现明显优于现有方法。代码可在 https://github.com/ZHU-0108/MTS-UNMixers 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.17770</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用时变工具识别时间序列数据中的因果关系</title>
      <link>https://arxiv.org/abs/2411.17774</link>
      <description><![CDATA[arXiv:2411.17774v1 公告类型：新 
摘要：从时间序列数据中查询因果效应在医疗保健、经济学、气候科学和流行病学等各个领域都很重要。然而，这项任务在存在随时间变化的潜在混杂因素时变得复杂，这些混杂因素会随时间影响治疗和结果变量，并可能在因果效应估计中引入偏差。传统的工具变量 (IV) 方法在解决这种复杂性方面受到限制，因为需要预定义的 IV 或在动态设置中不成立的强假设。为了解决这些问题，我们开发了一种用于去偏因果效应估计的新型时变条件工具变量 (CIV)，称为 TDCIV。TDCIV 利用长短期记忆 (LSTM) 和变分自动编码器 (VAE) 模型来解开并学习时变 CIV 及其条件集的表示，而无需事先了解代理变量。在马尔可夫特性和代理变量可用性的假设下，我们从理论上建立了这些学习表征的有效性，以解决随时间变化的潜在混杂因素的偏差，从而实现准确的因果效应估计。我们提出的 TDCIV 是第一个有效学习随时间变化的 CIV 及其相关条件集而不依赖于特定领域知识的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.17774</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络反演及其应用</title>
      <link>https://arxiv.org/abs/2411.17777</link>
      <description><![CDATA[arXiv:2411.17777v1 公告类型：新
摘要：神经网络已成为各种应用中的强大工具，但它们的决策过程通常仍然不透明，导致它们被视为“黑匣子”。这种不透明性引发了人们对其可解释性和可靠性的担忧，尤其是在安全关键场景中。网络反演技术提供了一种解决方案，它允许我们窥视这些黑匣子内部，揭示网络在决策过程背后学习到的特征和模式，从而提供有关神经网络如何得出结论的宝贵见解，使它们更具可解释性和可信度。本文介绍了一种简单而有效的网络反演方法，使用精心调节的生成器来学习训练后的神经网络输入空间中的数据分布，从而能够重建最有可能导致所需输出的输入。为了捕捉给定输出的输入空间中的多样性，我们将条件标签信息编码为向量和中间矩阵，并进一步最小化生成图像特征之间的余弦相似度，而不是简单地向生成器透露条件标签。此外，我们将特征正交性作为正则化项来提高图像多样性，这会惩罚特征的 Gram 矩阵与单位矩阵的偏差，确保正交性并促进每个标签的独特、非冗余表示。本文最后探讨了所提出的网络反转方法在可解释性、分布不均检测和训练数据重建方面的直接应用。]]></description>
      <guid>https://arxiv.org/abs/2411.17777</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用块坐标下降对大型语言和视觉模型进行可扩展迭代修剪</title>
      <link>https://arxiv.org/abs/2411.17796</link>
      <description><![CDATA[arXiv:2411.17796v1 公告类型：新
摘要：修剪神经网络（涉及移除其权重的一小部分）通常可以保持高精度，同时显著降低模型复杂性，至少在一定限度内。我们提出了一种基于组合脑外科医生的神经网络修剪技术，但使用块坐标下降以迭代、逐块的方式解决网络权重子集的优化问题。这种修剪技术的迭代、基于块的特性，我们称之为“迭代组合脑外科医生”（iCBS），可以扩展到非常大的模型，包括大型语言模型（LLM），而一次性组合优化方法可能无法实现。当应用于 Mistral 和 DeiT 等大型模型时，与现有的修剪方法（如 Wanda）相比，iCBS 在相同密度水平下实现了更高的性能指标。这证明了这种迭代的逐块剪枝方法在压缩和优化大型深度学习模型性能方面的有效性，即使只优化一小部分权重也是如此。此外，我们的方法可以实现质量与时间（或成本）之间的权衡，而这在单独使用一次性剪枝技术时是无法实现的。优化问题的逐块公式化允许使用硬件加速器，与 Wanda 等一次性剪枝方法相比，这有可能抵消增加的计算成本。特别是，针对每个块解决的优化问题都是量子可行问题，因为原则上可以通过量子计算机解决。]]></description>
      <guid>https://arxiv.org/abs/2411.17796</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>STAR：定制架构的综合</title>
      <link>https://arxiv.org/abs/2411.17800</link>
      <description><![CDATA[arXiv:2411.17800v1 公告类型：新
摘要：模型架构的迭代改进是深度学习的基础：Transformers 首先实现了扩展，模型混合的最新进展推动了质量效率前沿。然而，优化架构仍然具有挑战性且成本高昂。当前的自动或手动方法存在不足，主要是由于搜索空间设计的进展有限，以及由此产生的模式和启发式方法过于简单。在这项工作中，我们提出了一种合成定制架构 (STAR) 的新方法。我们的方法结合了基于线性输入变化系统理论的新型搜索空间，支持对架构基因组进行分层数值编码。STAR 基因组会自动细化并与无梯度进化算法重新组合，以优化多种模型质量和效率指标。使用 STAR，我们优化了大量新架构，利用不同的计算单元和互连模式，在自回归语言建模的质量、参数大小和推理缓存方面改进了高度优化的 Transformers 和条带混合模型。]]></description>
      <guid>https://arxiv.org/abs/2411.17800</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从记忆到泛化：基于扩散的生成模型的理论框架</title>
      <link>https://arxiv.org/abs/2411.17807</link>
      <description><![CDATA[arXiv:2411.17807v1 公告类型：新
摘要：基于扩散的生成模型展示了随着训练集规模的增加，从记忆训练数据集到非记忆模式的转变。在这里，我们首先介绍这种转变在数学上的精确定义，即相对距离：如果生成的分布相对于采样分布几乎肯定远离与训练数据集的高斯核近似相关的概率分布，则该模型被称为处于非记忆/“泛化”模式。然后，我们开发了一个可分析处理的扩散模型，并建立了生成分布和采样分布之间 Kullback-Leibler 散度的下限。根据我们对相对距离的定义，当训练数据从各向同性的高斯分布中采样时，该模型还具有转变。此外，我们的研究表明，当生成分布和底层采样分布之间的个体距离随着更多训练样本的增加而开始减小时，就会发生这种转变。这与另一种情况形成了鲜明对比，在另一种情况下，模型的记忆性能会下降，但泛化性能不会提高。我们还提供了经验证据，表明现实的扩散模型表现出相同的尺度一致性。]]></description>
      <guid>https://arxiv.org/abs/2411.17807</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>卫星上分割模型的快速分布式微调</title>
      <link>https://arxiv.org/abs/2411.17831</link>
      <description><![CDATA[arXiv:2411.17831v1 公告类型：新
摘要：地球观测 (EO) 卫星数据的分割对于自然灾害分析和灾害响应至关重要。然而，由于数据传输瓶颈和通信窗口，地面站处理 EO 数据会导致延迟。因此，使用能够近乎实时地在卫星上进行数据分析的分割模型可以缩短响应时间。本研究提出了一个概念验证，使用 MobileSAM（一种轻量级、预先训练的分割模型）在 Unibap iX10-100 卫星硬件上进行。我们展示了从 Sentinel-2 卫星图像中分割水体的方法，并将 MobileSAM 与 PASEOS（一个模拟卫星操作的开源 Python 模块）集成。这种集成使我们能够在卫星星座的模拟条件下评估 MobileSAM 的性能。我们的研究调查了在多颗卫星上以分散方式微调 MobileSAM 以快速应对灾难的潜力。我们的研究结果表明，考虑到模拟轨道环境施加的限制，MobileSAM 可以快速微调并受益于分散式学习。我们观察到，当卫星频繁传达模型更新时，使用最少的训练数据和快速微调可以提高分割性能。这项研究强调了分散式学习和微调预训练模型对快速响应场景的好处，为机载人工智能领域做出了贡献。我们的工作建立在关键时刻的近期相关研究之上；随着极端天气事件的频率和强度增加，利用机载数据分析快速响应至关重要。]]></description>
      <guid>https://arxiv.org/abs/2411.17831</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应客户端选择与个性化通信高效联邦学习</title>
      <link>https://arxiv.org/abs/2411.17833</link>
      <description><![CDATA[arXiv:2411.17833v1 公告类型：新
摘要：联邦学习 (FL) 是一种分布式方法，用于协作训练机器学习模型。FL 需要设备和中央服务器之间的高水平通信，因此带来了一些挑战，包括通信瓶颈和网络可扩展性。本文介绍了 ACSP-FL (https://github.com/AllanMSouza/ACSP-FL)，这是一种降低在 FL 环境中训练模型的总体通信和计算成本的解决方案。ACSP-FL 采用客户端选择策略，可动态调整训练模型的设备数量和实现收敛所需的轮数。此外，ACSP-FL 支持模型个性化以提高客户端性能。基于人类活动识别数据集的用例旨在展示 ACSP-FL 与最先进方法相比的影响和优势。实验评估表明，ACSP-FL 最大限度地减少了训练模型的总体通信和计算开销，并有效地收敛系统。特别是，与文献方法相比，ACSP-FL 将通信减少了 95%，即使在数据在客户端设备之间以不同、非独立和相同方式分布的情况下也能提供良好的收敛。]]></description>
      <guid>https://arxiv.org/abs/2411.17833</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>震撼 KASBA：极速且准确的时间序列聚类</title>
      <link>https://arxiv.org/abs/2411.17838</link>
      <description><![CDATA[arXiv:2411.17838v1 公告类型：新
摘要：时间序列数据在众多领域变得越来越普遍，推动了对时间序列机器学习技术的需求不断增长。其中，时间序列聚类 (TSCL) 是最流行的机器学习任务之一。TSCL 是一种强大的探索性分析工具，也可用作各种任务的预处理步骤或子程序，包括异常检测、分割和分类。
最流行的 TSCL 算法要么速度快（就运行时间而言），但在基准问题上表现不佳，要么在基准测试中表现良好但扩展性较差。我们提出了一种新的 TSCL 算法，即 $k$-均值 (K) 加速 (A) 随机次梯度 (S) 重心 (B) 平均 (A) (KASBA) 聚类算法。 KASBA 是一种 $k$-均值聚类算法，它在聚类的所有阶段都使用移动-分裂-合并 (MSM) 弹性距离，应用随机次梯度下降来查找重心质心，链接聚类的每个阶段以加速收敛，并利用 MSM 距离的度量属性来避免大量的距离计算。它是一种多功能且可扩展的聚类器，专为现实世界的 TSCL 应用而设计。它允许从业者平衡运行时间和聚类性能。我们通过大量实验证明，KASBA 产生的聚类效果明显优于速度更快的最先进的聚类器，并且与性能最高的 $k$-均值替代方案相比，其运行时间提高了几个数量级。]]></description>
      <guid>https://arxiv.org/abs/2411.17838</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集成机器学习和量子电路进行质子亲和力预测</title>
      <link>https://arxiv.org/abs/2411.17856</link>
      <description><![CDATA[arXiv:2411.17856v1 公告类型：新
摘要：在解释气相离子迁移率与质谱 (IM-MS) 数据以预测未知结构时，关键步骤是确定最有利的质子化结构。在气相中，使用质子亲和力 (PA) 测量来确定质子化位点。目前，质谱和从头计算方法被广泛用于评估 PA；然而，这两种方法都是资源密集型和耗时的。因此，迫切需要有效的方法来估计 PA，以便快速识别具有多个质子结合位点的复杂有机分子中最有利的质子化位点。在这项工作中，我们开发了一种快速准确的 PA 预测方法，该方法结合使用多个描述符和机器学习 (ML) 模型。使用一组全面的 186 个描述符，我们的模型表现出强大的预测性能，R2 为 0.96，MAE 为 2.47kcal/mol，与实验不确定性相当。此外，我们还设计了量子电路作为经典神经网络的特征编码器。为了评估这种混合量子-经典模型的有效性，我们使用从全集派生出的精简特征集将其性能与传统 ML 模型进行了比较。结果表明，这种混合模型在无噪声模拟器和真实量子硬件上都实现了与具有相同精简特征集的传统 ML 模型相当的一致性能，凸显了量子机器学习在准确、高效 PA 预测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.17856</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用任务预测加速近端策略优化学习以解决具有延迟奖励的游戏</title>
      <link>https://arxiv.org/abs/2411.17861</link>
      <description><![CDATA[arXiv:2411.17861v1 公告类型：新
摘要：在本文中，我们解决了强化学习 (RL) 中延迟奖励的挑战性问题。虽然近端策略优化 (PPO) 已成为一种领先的策略梯度方法，但其性能在延迟奖励下可能会下降。我们引入了 PPO 的两个关键增强功能：将离线策略（在专家演示上训练）与在线 PPO 策略相结合的混合策略架构，以及使用时间窗口时序逻辑 (TWTL) 的奖励塑造机制。混合架构在整个训练过程中利用离线数据，同时保持 PPO 的理论保证。基于信任区域策略优化 (TRPO) 的单调改进框架，我们证明我们的方法可以确保比离线策略和之前的迭代都得到改进，性能差距在 $(2\varsigma\gamma\alpha^2)/(1-\gamma)^2$ 范围内，其中 $\alpha$ 是混合参数，$\gamma$ 是折扣因子，$\varsigma$ 限制预期优势。此外，我们证明基于 TWTL 的奖励塑造保留了原始问题的最佳策略。TWTL 可以将时间目标正式转化为指导学习的即时反馈信号。我们通过在倒立摆和月球着陆器环境中进行的大量实验证明了我们方法的有效性，与标准 PPO 和纯离线方法相比，学习速度和最终性能都有所提高。]]></description>
      <guid>https://arxiv.org/abs/2411.17861</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于训练 Transformer 的分布式符号动量和局部步骤</title>
      <link>https://arxiv.org/abs/2411.17866</link>
      <description><![CDATA[arXiv:2411.17866v1 公告类型：新
摘要：预训练 Transformer 模型需要大量资源，最近的研究表明，符号动量是训练大规模深度学习模型（尤其是 Transformer）的有效技术。然而，它在分布式训练或联邦学习中的应用仍未得到充分探索。本文研究了一种具有局部更新的新型通信效率高的分布式符号动量方法。我们提出的方法允许使用广泛的基础优化器进行局部更新，并在全局更新中使用符号动量，其中动量是由局部步骤中积累的差异产生的。我们在各种 GPT-2 模型的预训练中评估了我们的方法，与其他具有局部更新的分布式方法相比，实证结果显示出显着的改进。此外，通过用一个随机版本近似符号运算符，该版本在期望中充当连续模拟，我们为非凸光滑函数提出了一个 $O(1/\sqrt{T})$ 收敛方法。]]></description>
      <guid>https://arxiv.org/abs/2411.17866</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RankMap：用于异构嵌入式设备的优先级感知多 DNN 管理器</title>
      <link>https://arxiv.org/abs/2411.17867</link>
      <description><![CDATA[arXiv:2411.17867v1 公告类型：新
摘要：现代边缘数据中心同时处理多个深度神经网络 (DNN)，导致工作负载管理面临重大挑战。因此，当前的管理系统必须利用新嵌入式系统的架构异构性来有效处理多 DNN 工作负载。本文介绍了 RankMap，这是一种专为异构嵌入式设备上的多 DNN 任务设计的优先级感知管理器。RankMap 通过随机空间探索结合性能估计器来解决多 DNN 映射的广泛解决方案空间。实验结果表明，与现有方法相比，RankMap 实现了 3.6 倍更高的平均吞吐量，同时防止了重负载下的 DNN 饥饿，并将指定 DNN 的优先级提高了 57.5 倍。]]></description>
      <guid>https://arxiv.org/abs/2411.17867</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用机器学习技术增强项目绩效预测</title>
      <link>https://arxiv.org/abs/2411.17914</link>
      <description><![CDATA[arXiv:2411.17914v1 公告类型：新
摘要：准确预测项目绩效指标对于成功管理和交付城市道路重建项目至关重要。传统方法通常依赖于静态基线计划，而没有考虑项目进度和外部因素的动态性质。本研究提出了一种基于机器学习的方法来预测城市道路重建项目中每个工作分解结构 (WBS) 类别的项目绩效指标，例如成本差异和挣值。所提出的模型利用时间序列预测技术，包括自回归综合移动平均线 (ARIMA) 和长短期记忆 (LSTM) 网络，根据历史数据和项目进度预测未来绩效。该模型还结合了外部因素，例如天气模式和资源可用性，作为提高预测准确性的特征。通过应用机器学习的预测能力，绩效预测模型能够主动识别与基线计划的潜在偏差，从而使项目经理能够及时采取纠正措施。本研究旨在通过城市道路改造项目案例研究来验证所提方法的有效性，将模型的预测与实际项目绩效数据进行比较。本研究的结果有助于建筑行业项目管理实践的进步，为改善项目绩效监测和控制提供数据驱动的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.17914</guid>
      <pubDate>Thu, 28 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>