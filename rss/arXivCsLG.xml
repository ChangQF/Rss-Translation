<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>符号回归的可解释性：使用费曼数据集的解释方法的基准</title>
      <link>https://arxiv.org/abs/2404.05908</link>
      <description><![CDATA[arXiv:2404.05908v1 公告类型：新
摘要：在某些情况下，机器学习模型的可解释性与模型的准确性一样重要。可解释性来自于信任预测模型、验证其某些属性、甚至强制执行它们以提高公平性的需要。存在许多与模型无关的解释方法来为黑盒模型提供解释。在回归任务中，实践者可以使用白盒或灰盒模型来获得更可解释的结果，这就是符号回归的情况。在使用解释方法时，由于可解释性缺乏严格的定义，因此需要评估和比较解释者的质量和不同的解释者。本文提出了一个基准方案来评估解释回归模型（主要是符号回归模型）的解释方法。使用100个物理方程以及不同的可解释和不可解释回归方法以及流行的解释方法进行实验，通过多种解释措施来评估解释者的表现。此外，我们还进一步分析了 GP 社区的四个基准。结果表明，符号回归模型可以成为白盒和黑盒模型的有趣替代品，能够返回带有适当解释的准确模型。关于解释器，我们观察到部分效应和 SHAP 是最稳健的解释模型，而积分梯度仅在基于树的模型中不稳定。该基准可公开用于进一步的实验。]]></description>
      <guid>https://arxiv.org/abs/2404.05908</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>与合并树神经网络进行快速精确的拓扑比较</title>
      <link>https://arxiv.org/abs/2404.05879</link>
      <description><![CDATA[arXiv:2404.05879v1 公告类型：新
摘要：合并树是标量场科学可视化的一个有价值的工具。然而，当前的合并树比较方法在计算上是昂贵的，这主要是由于树节点之间的详尽匹配。为了应对这一挑战，我们引入了合并树神经网络（MTNN），这是一种专为合并树比较而设计的学习神经网络模型。 MTNN 可实现快速、高质量的相似性计算。我们首先演示如何训练作为图的有效编码器出现的图神经网络（GNN）以在向量空间中生成合并树的嵌入，从而实现有效的相似性比较。接下来，我们制定了新颖的 MTNN 模型，通过将树和节点嵌入与新的拓扑注意机制相结合，进一步改进了相似性比较。我们展示了我们的模型在不同领域的真实数据上的有效性，并检查了我们的模型在各种数据集上的通用性。我们的实验分析证明了我们的方法在准确性和效率方面的优越性。特别是，我们在基准数据集上将之前最先进的速度提高了 100 倍以上，同时将错误率保持在 0.1% 以下。]]></description>
      <guid>https://arxiv.org/abs/2404.05879</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>通过深度强化学习学习启发式交通网络设计和改进</title>
      <link>https://arxiv.org/abs/2404.05894</link>
      <description><![CDATA[arXiv:2404.05894v1 公告类型：新
摘要：世界各地的交通机构都面临着预算紧缩的问题。为了在降低成本的同时保持服务质量，高效的交通网络设计至关重要。但规划公共交通路线网络是一个具有挑战性的优化问题。迄今为止最成功的方法使用元启发式算法，通过应用随机改变网络中的路由的低级启发式方法来搜索解决方案的空间。这些低级启发式的设计对结果的质量有重大影响。在本文中，我们使用深度强化学习和图神经网络来学习进化算法的低级启发式方法，而不是手动设计它们。这些学习启发式改进了算法在具有 70 个或更多节点的基准合成城市上的结果，并在优化运营成本时获得了最先进的结果。他们还在加拿大拉瓦尔市真实交通网络的模拟基础上，在两个关键指标上分别提高了 54% 和 18%，并比该市现有的交通网络节省了高达 12% 的成本。]]></description>
      <guid>https://arxiv.org/abs/2404.05894</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>自然学习</title>
      <link>https://arxiv.org/abs/2404.05903</link>
      <description><![CDATA[arXiv:2404.05903v1 公告类型：新
摘要：我们介绍自然学习（NL），这是一种新颖的算法，它将机器学习的可解释性和可解释性提升到了极致。 NL 将决策简化为直观的规则，例如“我们拒绝了您的贷款，因为您的收入、就业状况和年龄总体上更类似于被拒绝的原型，而不是被接受的原型。”当应用于现实生活数据集时，NL 会产生令人印象深刻的结果。例如，在包含 1545 名患者和 10935 个基因的结肠癌数据集中，NL 通过针对 2 个发现的原型仅分析测试样本的 3 个基因，实现了 98.1% 的准确率，与 DNN 和 RF 相当。同样，在 UCI 的 WDBC 数据集中，NL 仅使用 7 个特征和 2 个原型就实现了 98.3% 的准确率。即使在 MNIST 数据集（0 vs. 1）上，NL 仅用 2 个原型图像中的 3 个像素即可实现 99.5% 的准确率。 NL 受到原型理论的启发，原型理论是认知心理学中的一个古老概念，表明人们学习单个稀疏原型来对对象进行分类。利用这种宽松的假设，我们重新设计了支持向量机（SVM），用完全基于最近邻的解决方案替换其数学公式，并且为了解决维数灾难，我们利用局部敏感哈希。遵循理论的泛化原则，我们提出了一种递归方法来修剪非核心特征。因此，NL 在 O(n^2pL) 中有效地发现了最稀疏的原型，并且具有以 n 为单位的高并行化能力。使用 17 个基准数据集对 NL 进行的评估表明，与决策树和逻辑回归相比，NL 的性能显着优于决策树和逻辑回归，这两种方法因其可解释性而在医疗保健领域广受青睐。此外，NL 在 40% 的情况下实现了与深度神经网络和随机森林等微调黑盒模型相当的性能，而平均准确度仅低 1-2%。该代码可通过 http://natural-learning.cc 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.05903</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>Softmax 注意力，每个代币成本恒定</title>
      <link>https://arxiv.org/abs/2404.05843</link>
      <description><![CDATA[arXiv:2404.05843v1 公告类型：新
摘要：我们对 Transformers 应用的传统注意力机制提出了一个简单的修改：我们不使用缩放点积来量化成对查询键相似性，而是使用指数的缩放点积的对数来量化它。注意力可以表达为可线性化的指数对数和的组合，具有恒定大小的潜在空间，从而使每个标记能够以恒定的时间和空间复杂度进行顺序应用。我们实施我们的修改，验证它在实践中是否有效，并得出结论，它是传统注意力的一个有前途的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2404.05843</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>负面偏好优化：从灾难性崩溃到有效遗忘</title>
      <link>https://arxiv.org/abs/2404.05868</link>
      <description><![CDATA[arXiv:2404.05868v1 公告类型：新
摘要：大型语言模型（LLM）通常在预训练期间记住敏感、私人或受版权保护的数据。 LLM 去学习旨在消除预训练模型中不需要的数据的影响，同时保留模型对其他任务的效用。最近提出了几种用于 LLM 去学习的实用方法，主要基于丢失不需要的数据的梯度上升（GA）。然而，在某些遗忘任务中，这些方法要么无法有效地遗忘目标数据，要么遭受灾难性崩溃——模型效用急剧下降。
  在本文中，我们提出了负偏好优化（NPO），这是一种简单的对齐启发方法，可以高效且有效地忘却目标数据集。我们从理论上表明，通过最小化 NPO 损失而导致灾难性崩溃的进程比 GA 慢得多。通过对合成数据和基准 TOFU 数据集的实验，我们证明基于 NPO 的方法在消除不需要的数据和维护模型的实用性之间实现了更好的平衡。我们还观察到，基于 NPO 的方法比基于 GA 的方法产生更合理的输出，后者的输出通常是无意义的。值得注意的是，在 TOFU 上，基于 NPO 的方法是第一个在忘记 50%（或更多）训练数据方面取得合理的忘却结果的方法，而现有方法已经很难忘记 10% 的训练数据。]]></description>
      <guid>https://arxiv.org/abs/2404.05868</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>自适应机器学习的多元因果关系和量化中的自我标记</title>
      <link>https://arxiv.org/abs/2404.05809</link>
      <description><![CDATA[arXiv:2404.05809v1 公告类型：新
摘要：自适应机器学习（ML）旨在让 ML 模型能够适应不断变化的环境，并在模型部署后可能出现概念漂移。传统上，自适应机器学习需要手动标记新数据集，以定制部署的模型以适应改变的数据分布。最近，提出了一种基于交互式因果关系的自标记方法，可以自动关联因果相关的数据流以进行领域适应，与传统的基于特征相似性的半监督学习相比，显示出有希望的结果。仍然有几个悬而未决的研究问题，包括自标签与多元因果关系的兼容性以及自标签中使用的辅助模型的定量分析。辅助模型、交互时间模型（ITM）和效应状态检测器（ESD）对于自标记的成功至关重要。本文进一步发展了自标签框架及其理论基础来解决这些研究问题。使用四种基本因果关系提出了一种将自标记应用于多元因果图的框架，并分析了非理想 ITM 和 ESD 性能的影响。基于多元因果图进行模拟实验，验证了所提出的理论。]]></description>
      <guid>https://arxiv.org/abs/2404.05809</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>物理信息神经网络和高斯过程的标签传播训练方案</title>
      <link>https://arxiv.org/abs/2404.05817</link>
      <description><![CDATA[arXiv:2404.05817v1 公告类型：新
摘要：本文提出了一种用于训练物理信息机器学习方法的半监督方法。这包括孤立地自我训练基于物理的神经网络和基于物理的高斯过程，以及通过协同训练将两者集成。我们通过大量的数值实验证明了这些方法如何改善及时向前传播信息的问题，这是物理信息机器学习的常见故障模式。]]></description>
      <guid>https://arxiv.org/abs/2404.05817</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>注意力驱动的多智能体强化学习：通过专业知识指导的任务增强决策</title>
      <link>https://arxiv.org/abs/2404.05840</link>
      <description><![CDATA[arXiv:2404.05840v1 公告类型：新
摘要：在本文中，我们介绍了一种通过整合领域知识和基于注意力的策略机制来增强多智能体强化学习（MARL）的替代方法。我们的方法侧重于将特定领域的专业知识纳入学习过程，从而简化协作行为的开发。这种方法旨在通过使代理能够专注于复杂任务的基本方面来降低通常与 MARL 相关的复杂性和学习开销，从而优化学习曲线。注意机制的利用在我们的模型中起着关键作用。它可以有效处理动态上下文数据和细致入微的代理交互，从而实现更精细的决策。我们的方法应用于标准 MARL 场景，例如斯坦福智能系统实验室 (SISL) Pursuit 和多粒子环境 (MPE) Simple Spread，已被证明可以提高学习效率和协作行为的有效性。结果表明，我们基于注意力的方法可以成为提高 MARL 训练过程效率、在行动层面整合特定领域知识的可行方法。]]></description>
      <guid>https://arxiv.org/abs/2404.05840</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>STMGF：一种有效的时空多粒度流量预测框架</title>
      <link>https://arxiv.org/abs/2404.05774</link>
      <description><![CDATA[arXiv:2404.05774v1 公告类型：新
摘要：由于道路网络的时空方面，准确的交通预测是智能交通中的一项具有挑战性的任务。道路网络的交通可能会受到长距离或长期依赖性的影响，而现有方法无法对其进行建模。在本文中，我们介绍了一种称为时空多粒度框架（STMGF）的新颖框架，以增强对道路网络长距离和长期信息的捕获。 STMGF充分利用道路网络的不同粒度信息，通过分层交互的方式收集信息，对长距离、长期信息进行建模。此外，它还利用交通序列固有的周期性，通过与最近的交通数据匹配来完善预测结果。我们在两个真实数据集上进行了实验，结果表明 STMGF 优于所有基线模型并实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.05774</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>AI 的数据准备情况：360 度调查</title>
      <link>https://arxiv.org/abs/2404.05779</link>
      <description><![CDATA[arXiv:2404.05779v1 公告类型：新
摘要：数据是人工智能（AI）模型的关键燃料。质量差的数据会产生不准确且无效的人工智能模型，可能导致不正确或不安全的使用。检查数据准备情况是提高数据质量的关键步骤。为了提高数据质量，我们投入了大量的研发工作。然而，用于评估人工智能训练数据准备情况的标准化指标仍在不断发展。在这项研究中，我们对用于验证人工智能数据准备情况的指标进行了全面调查。这项调查审查了 ACM Digital Library、IEEE Xplore 和其他知名期刊发表的 120 多篇论文，以及著名人工智能专家在网络上发表的文章。本调查旨在提出结构化和非结构化数据集的人工智能数据准备度 (DRAI) 指标分类法。我们预计这种分类法可以为 DRAI 指标制定新标准，用于提高人工智能训练和推理的质量和准确性。]]></description>
      <guid>https://arxiv.org/abs/2404.05779</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>训练过程中人工神经网络轨迹的动态稳定性和混沌</title>
      <link>https://arxiv.org/abs/2404.05782</link>
      <description><![CDATA[arXiv:2404.05782v1 公告类型：新
摘要：训练人工神经网络的过程涉及迭代调整其参数，以便在面临学习任务时最小化网络预测的误差。这种迭代变化可以自然地解释为网络空间中的轨迹（网络的时间序列），因此训练算法（例如合适的损失函数的梯度下降优化）可以解释为图空间中的动态系统。为了说明这一解释，在这里我们通过分析浅层神经网络的网络轨迹来研究该过程的动态特性，并通过学习简单的分类任务来研究其演化。我们系统地考虑学习率的不同范围，并探索所得网络轨迹的动态和轨道稳定性，根据学习率机制找到规则和混沌行为的暗示。我们的发现与神经网络和动力系统理论的收敛特性的常识形成鲜明对比。这项工作还有助于动力系统理论、网络理论和机器学习之间思想的交叉融合]]></description>
      <guid>https://arxiv.org/abs/2404.05782</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>提高大型语言模型的推理效率：研究优化策略和架构创新</title>
      <link>https://arxiv.org/abs/2404.05741</link>
      <description><![CDATA[arXiv:2404.05741v1 公告类型：新
摘要：大型语言模型的规模正在不断扩大，我们预计它们将继续这样做，因为更大的模型训练得更快。然而，规模的增加将严重影响推理成本。因此，模型压缩非常重要，可以保留较大模型的性能，同时降低运行模型的成本。在本文中，我们探索了模型压缩的方法，并凭经验证明，在 Transformer LLM 中跳过后面的注意力子层的简单方法是一种有效的模型压缩方法，因为这些层被证明是多余的，同时计算成本也非常高。我们观察到 Llama 2 7B 的单代币生成速度提高了 21%，同时与几个常见基准相比，性能也得到了令人惊讶和意外的提高。]]></description>
      <guid>https://arxiv.org/abs/2404.05741</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>使用傅里叶神经算子简化海洋动力学建模：多目标超参数和架构优化方法</title>
      <link>https://arxiv.org/abs/2404.05768</link>
      <description><![CDATA[arXiv:2404.05768v1 公告类型：新
摘要：训练有效的深度学习模型来学习海洋过程需要仔细选择各种超参数。我们利用 DeepHyper 的高级搜索算法进行多目标优化，简化为海洋建模量身定制的神经网络的开发。重点是优化傅里叶神经算子（FNO），这是一种能够模拟复杂海洋行为的数据驱动模型。选择正确的模型和调整超参数是一项具有挑战性的任务，需要付出很大的努力才能确保模型的准确性。 DeepHyper 允许高效探索与数据预处理相关的超参数、FNO 架构相关的超参数以及各种模型训练策略。我们的目标是获得一组最佳超参数，从而获得性能最佳的模型。此外，除了模型训练常用的均方误差之外，我们建议采用负异常相关系数作为附加损失项，以提高模型性能并研究两项之间的潜在权衡。实验结果表明，最佳超参数集增强了单时间步长预测中的模型性能，并大大超过了长达 30 天的长期预测的自回归部署中的基线配置。利用 DeepHyper，我们展示了一种增强 FNO 在海洋动力学预报中使用的方法，提供了精度更高的可扩展解决方案。]]></description>
      <guid>https://arxiv.org/abs/2404.05768</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>响应可持续土壤管理实践的土壤呼吸信号增强土壤有机碳储量</title>
      <link>https://arxiv.org/abs/2404.05737</link>
      <description><![CDATA[arXiv:2404.05737v1 公告类型：新
摘要：基于土壤温度、年度土壤湿度和土壤有机碳 (C) 估算，开发全球范围内的时空数据驱动的土壤呼吸模型。土壤呼吸的年预测（1991-2018）具有相对较高的准确度（NSE 0.69，CCC 0.82）。在实施可持续土壤管理实践的地区，土壤呼吸趋势较低，土壤呼吸强度较高，土壤有机碳储量较高。]]></description>
      <guid>https://arxiv.org/abs/2404.05737</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    </channel>
</rss>