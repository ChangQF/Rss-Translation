<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于数据分类的随机异构神经混沌学习架构</title>
      <link>https://arxiv.org/abs/2410.23351</link>
      <description><![CDATA[arXiv:2410.23351v1 公告类型：新
摘要：受人类大脑结构和功能的启发，人工神经网络 (ANN) 被开发用于数据分类。然而，现有的神经网络，包括深度神经网络，并没有模仿大脑的丰富结构。它们缺乏随机性和神经元异质性等关键特征，这些特征在它们的放电行为中本质上是混乱的。神经混沌学习 (NL) 是一种基于混沌的神经网络，最近采用了广义 L\&quot;uroth 系列 (GLS) 和 Logistic 映射等一维混沌映射作为神经元。我们首次提出了一种随机异构 NL 扩展，其中各种混沌神经元随机放置在输入层中，模仿人类大脑网络的随机性和异构性。我们评估了新提出的随机异构神经混沌学习 (RHNL) 架构与传统机器学习 (ML) 方法相结合的性能。在公共数据集上，RHNL 在几乎所有分类任务中都优于同质 NL 和固定异构 NL 架构。RHNL 在 Wine 数据集 (1.0)、钞票认证数据集 (0.99)、威斯康星州乳腺癌数据集 (0.99) 和自由口语数字数据集 (FSDD) (0.98) 上获得了较高的 F1 分数。这些 RHNL 结果是这些数据集文献中最好的。我们研究了 RHNL 在图像数据集上的性能，其中它优于独立 ML 分类器。在低训练样本情况下，RHNL 是独立 ML 中最好的。我们的架构弥合了现有 ANN 架构与人脑混沌、随机和异构特性之间的差距。我们预计未来几天将开发出几种以随机异构神经混沌学习为中心的新型学习算法。]]></description>
      <guid>https://arxiv.org/abs/2410.23351</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于时间序列预测的顺序稳健 Mamba</title>
      <link>https://arxiv.org/abs/2410.23356</link>
      <description><![CDATA[arXiv:2410.23356v1 公告类型：新
摘要：Mamba 最近成为 Transformers 的一个有前途的替代品，在处理顺序数据时提供近乎线性的复杂性。然而，虽然时间序列 (TS) 数据中的通道通常没有特定的顺序，但最近的研究采用 Mamba 来捕获 TS 中的通道依赖性 (CD)，从而引入了顺序偏差。为了解决这个问题，我们提出了 SOR-Mamba，这是一种 TS 预测方法，1) 结合正则化策略来最小化从具有反转通道顺序的数据生成的两个嵌入向量之间的差异，从而增强对通道顺序的鲁棒性，2) 消除了最初设计用于捕获顺序数据中的局部信息的 1D 卷积。此外，我们引入了通道相关性建模 (CCM)，这是一项预训练任务，旨在保留从数据空间到潜在空间的通道之间的相关性，以增强捕获 CD 的能力。大量实验证明了所提出的方法在标准和迁移学习场景中的有效性。代码可在https://github.com/seunghan96/SOR-Mamba 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.23356</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 Lipschitz 常数和架构敏感性估计神经网络鲁棒性</title>
      <link>https://arxiv.org/abs/2410.23382</link>
      <description><![CDATA[arXiv:2410.23382v1 公告类型：新
摘要：确保神经网络稳健性对于机器人学习系统的安全可靠运行至关重要，尤其是在现实环境中的感知和决策任务中。本文研究了感知系统中神经网络的稳健性，特别是检查了它们对有针对性的小规模扰动的敏感性。我们将 Lipschitz 常数确定为量化和增强网络稳健性的关键指标。我们推导出一个基于神经网络架构计算 Lipschitz 常数的解析表达式，为估计和提高稳健性提供了理论基础。几个实验揭示了网络设计、Lipschitz 常数和稳健性之间的关系，为开发更安全、更稳健的机器人学习系统提供了实用的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.23382</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用物理信息神经网络对心房纤维方向进行集成学习</title>
      <link>https://arxiv.org/abs/2410.23388</link>
      <description><![CDATA[arXiv:2410.23388v1 公告类型：新
摘要：心肌的各向异性结构是心脏功能的关键决定因素。迄今为止，尚无成像方式可以评估体内心脏纤维结构。我们最近提出了 Fibernet，这是一种从局部电记录中自动识别心房中各向异性传导（以及纤维）的方法。Fibernet 使用电解剖映射期间记录的心脏激活，使用物理信息神经网络推断局部传导特性。在这项工作中，我们扩展了 Fibernet 以应对估计纤维场中的不确定性。具体而言，我们使用一组神经网络来生成多个样本，所有样本都符合观察到的数据，并计算后验统计数据。我们还介绍了一种方法来选择最佳纤维取向成员并直接在心房表面定义神经网络的输入。通过这些改进，我们在 8 种不同心房解剖结构中的纤维取向误差方面优于以前的方法。目前，我们的方法可以在 7 分钟内以量化的不确定性估计纤维方向和传导速度，这为其在临床实践中的应用打开了大门。我们希望提出的方法能够进一步个性化心脏数字孪生，以实现精准医疗。]]></description>
      <guid>https://arxiv.org/abs/2410.23388</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从神经崩溃视角理解深度平衡模型的表征</title>
      <link>https://arxiv.org/abs/2410.23391</link>
      <description><![CDATA[arXiv:2410.23391v1 Announce Type: new 
摘要：深度平衡模型（DEQ）是一种典型的隐式神经网络，与显式神经网络相比，其内存效率更高，性能更佳。然而，对DEQ的表示的理论分析相对有限。本文利用神经崩溃（$\mathcal{NC}$）作为工具，系统地分析了平衡和不平衡条件下DEQ的表示。$\mathcal{NC}$是神经网络训练过程中一个有趣的现象，它描述了类特征和分类器权重的几何形状。虽然在传统的显式神经网络中得到了广泛的研究，但$\mathcal{NC}$现象在隐式神经网络的背景下并没有受到实质性的关注。我们从理论上证明了在平衡条件下DEQ中存在$\mathcal{NC}$。此外，在不平衡的设置中，尽管存在少数崩溃，但DEQ仍然比显式神经网络表现出优势。这些优势包括提取的特征在温和条件下收敛到单纯形等角紧框架的顶点和自对偶性质，凸显了 DEQ 在处理不平衡数据集方面的优势。最后，我们通过平衡和不平衡场景中的实验验证了我们的理论分析。]]></description>
      <guid>https://arxiv.org/abs/2410.23391</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过集成变分自动编码器和强化学习实现网络系统中的资源治理</title>
      <link>https://arxiv.org/abs/2410.23393</link>
      <description><![CDATA[arXiv:2410.23393v1 公告类型：新
摘要：我们引入了一个将变分自动编码器 (VAE) 与强化学习 (RL) 相结合的框架，通过随时间动态调整网络结构来平衡多智能体系统中的系统性能和资源使用情况。该方法的一个关键创新是它能够处理网络结构的巨大动作空间。这是通过结合变分自动编码器和深度强化学习来控制从网络结构编码的潜在空间来实现的。在各种场景下对修改后的 OpenAI 粒子环境进行评估后，所提出的方法不仅表现出与基线相比的卓越性能，而且还通过学习到的行为揭示了有趣的策略和见解。]]></description>
      <guid>https://arxiv.org/abs/2410.23393</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复杂系统的自适应网络干预：分层图强化学习方法</title>
      <link>https://arxiv.org/abs/2410.23396</link>
      <description><![CDATA[arXiv:2410.23396v1 公告类型：新
摘要：在复杂的多智能体系统 (MAS) 中，有效管理和引导行为对于管理系统范围的结果至关重要，特别是在交互由动态网络构成的环境中。在许多应用中，目标是促进智能体之间的亲社会行为，其中网络结构在塑造这些交互中起着关键作用。本文介绍了一种分层图强化学习 (HGRL) 框架，该框架通过对网络结构进行有针对性的干预来管理此类系统。在有限的管理权限约束下，HGRL 框架在一系列环境条件下表现出色，优于既定的基线方法。我们的研究结果强调了智能体对智能体学习（社会学习）对系统行为的关键影响：在低社会学习下，HGRL 管理者保持合作，形成由合作者主导的强大核心外围网络。相反，高社会学习会加速叛逃，导致网络更稀疏、更像链。此外，该研究强调了系统管理员的权限级别在防止系统范围的故障（例如代理叛乱或崩溃）方面的重要性，将 HGRL 定位为基于动态网络治理的有力工具。]]></description>
      <guid>https://arxiv.org/abs/2410.23396</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论扩展熵的最优性和扩展形式博弈中在线学习的下界</title>
      <link>https://arxiv.org/abs/2410.23398</link>
      <description><![CDATA[arXiv:2410.23398v1 公告类型：新
摘要：一阶方法 (FOM) 可以说是大型扩展形式游戏中均衡计算最具可扩展性的算法。为了使这些方法可操作，必须选择一个距离生成函数作为策略空间的正则化器。强凸度模量与正则化器直径之间的比率是 FOM 分析中的一个关键参数。一个自然的问题是：什么是扩展形式决策空间的最佳距离生成函数？在本文中，我们做出了许多贡献，最终确定权重一扩张熵 (DilEnt) 距离生成函数在对数因子范围内是最佳的。 DilEnt 正则化器之所以引人注目，是因为它与核化 OMWU (KOMWU)（一种在扩展形式游戏中对博弈树大小具有最先进依赖性的算法）在与在线镜像下降 (OMD) 算法结合使用时具有迭代等价性。然而，OMD 的标准分析无法建立这样的结果；目前唯一的分析是通过诉诸与 KOMWU 的迭代等价性。我们通过引入一对原始对偶树形范数来弥补这一差距，我们认为这对范数构成了研究 DilEnt 强凸性的自然分析观点。使用这些范数对，我们恢复了直径与强凸性之比，该比值可预测与 KOMWU 相同的性能。结合序列形式策略空间中在线学习的新遗憾下限，我们表明该比率接近最优。最后，我们通过改进与 DilEnt 结合使用的 Clairvoyant OMD 的分析来展示我们的分析技术，在 $n$ 人游戏中建立 $\mathcal{O}(n \log |\mathcal{V}| \log T/T)$ 近似率来达到粗相关均衡，其中 $|\mathcal{V}|$ 是玩家简化的标准形式策略的数量，从而建立了新的最先进技术。]]></description>
      <guid>https://arxiv.org/abs/2410.23398</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FlowLLM：以大型语言模型作为基础分布的材料生成流匹配</title>
      <link>https://arxiv.org/abs/2410.23405</link>
      <description><![CDATA[arXiv:2410.23405v1 公告类型：新
摘要：材料发现是一个关键的研究领域，有可能彻底改变碳捕获、可再生能源和电子等各个领域。然而，化学空间的巨大规模使得通过实验探索所有可能的材料具有挑战性。在本文中，我们介绍了 FlowLLM，这是一种新型生成模型，它结合了大型语言模型 (LLM) 和黎曼流匹配 (RFM) 来设计新型晶体材料。FlowLLM 首先对 LLM 进行微调，以学习文本表示中亚稳态晶体的有效基础分布。转换为图形表示后，RFM 模型从 LLM 中获取样本并迭代细化坐标和晶格参数。我们的方法明显优于最先进的方法，将稳定材料的生成率提高了三倍以上，并将稳定、独特和新型晶体的生成率提高了 $\sim50\%$ - 这对一个难题来说是一个巨大的进步。此外，与其他领先模型相比，FlowLLM 生成的晶体更接近其松弛状态，大大降低了事后计算成本。]]></description>
      <guid>https://arxiv.org/abs/2410.23405</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>走出阴影：影子模式下的强化学习</title>
      <link>https://arxiv.org/abs/2410.23419</link>
      <description><![CDATA[arXiv:2410.23419v1 公告类型：新
摘要：强化学习 (RL) 对于许多信息物理系统（例如机器人、过程自动化和电力系统）尚不具备竞争力，因为无法加速对具有物理组件的系统进行训练，并且模拟模型不存在或存在较大的模拟与现实差距。在漫长的训练时间内，昂贵的设备无法使用，甚至可能由于强化学习代理的不当操作而损坏。我们的新方法正是解决了这个问题：我们在现有的传统控制器的帮助下以所谓的影子模式训练强化代理，该控制器无需训练并且立即表现良好。在影子模式下，代理依靠控制器提供动作样本和朝着有利状态的指导来学习任务，同时估计学习到的代理在哪些状态下会比传统控制器获得更高的奖励。然后，RL 代理将控制系统的这些状态，而所有其他区域仍处于现有控制器的控制之下。随着时间的推移，强化学习智能体将接管越来越多的状态，同时将控制权留给基线，基线无法超越其性能。因此，我们在训练过程中保持较低的遗憾，并提高性能，与仅使用传统控制器或强化学习相比。我们提出并评估了两种机制，以决定是使用强化学习智能体还是传统控制器。我们的方法在到达-避免任务中得到了证明，我们能够有效地训练智能体，而标准方法则无法做到这一点。]]></description>
      <guid>https://arxiv.org/abs/2410.23419</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于决策支持的动态信息子选择</title>
      <link>https://arxiv.org/abs/2410.23423</link>
      <description><![CDATA[arXiv:2410.23423v1 公告类型：新
摘要：我们引入了动态信息子选择 (DISS)，这是一种新颖的 AI 辅助框架，旨在通过根据每个实例定制信息处理来提高黑盒决策者的表现。黑盒决策者（例如，人类或实时系统）在处理所有可能的信息时经常面临挑战（例如，由于认知偏差或资源限制），这可能会降低决策效率。DISS 通过动态选择最有效的特征和选项转发给黑盒决策者进行预测的策略来解决这些挑战。我们开发了一种可扩展的频率数据采集策略和一种决策者模仿技术，以提高预算效率。我们探索了 DISS 的几种有影响力的应用，包括有偏见的决策者支持、专家任务优化、大型语言模型决策支持和可解释性。我们提出的 DISS 方法的实证验证表明，在各种应用中，它的性能优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.23423</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过梯度草图实现无线信道上通信高效的联合学习</title>
      <link>https://arxiv.org/abs/2410.23424</link>
      <description><![CDATA[arXiv:2410.23424v1 公告类型：新
摘要：通过无线多址信道 (MAC) 进行的大规模联合学习 (FL) 已成为具有广泛应用的重要学习范例。然而，它的广泛采用受到几个主要挑战的阻碍，包括许多边缘设备共享的有限带宽、嘈杂和错误的无线通信以及边缘设备之间分布不同的异构数据集。为了克服这些根本挑战，我们提出了联合近端草图 (FPS)，它针对带宽受限的无线信道量身定制，并处理边缘设备之间的数据异构性。FPS 使用计数草图数据结构来解决带宽瓶颈并实现高效压缩，同时保持对重要坐标的准确估计。此外，我们修改了 FPS 中的损失函数，使其能够处理不同程度的数据异构性。我们在温和的技术条件下建立了 FPS 算法的收敛性，并描述了数据异质性和嘈杂无线信道等因素引起的偏差如何影响整体结果。我们通过数值实验补充了所提出的理论框架，这些实验证明了 FPS 与合成和真实数据集上最先进的方法相比的稳定性、准确性和效率。总体而言，我们的结果表明，FPS 是解决无线 MAC 上 FL 的上述挑战的有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.23424</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过利用逐项矩阵估计进行无模型低秩强化学习</title>
      <link>https://arxiv.org/abs/2410.23434</link>
      <description><![CDATA[arXiv:2410.23434v1 公告类型：新
摘要：我们考虑在具有低秩潜在结构的受控动态系统中学习 $\varepsilon$ 最优策略的问题。对于这个问题，我们提出了 LoRa-PI（低秩策略迭代），这是一种在策略改进和策略评估步骤之间交替的无模型学习算法。在后者中，该算法使用以下两阶段程序估计与当前策略的（状态，动作）值函数相对应的低秩矩阵。首先对矩阵的条目进行均匀随机采样，以通过谱方法估计其行和列的杠杆分数。然后使用这些分数提取一些重要的行和列，这些行和列的条目将被进一步采样。该算法利用这些新样本，使用类似 CUR 的方法完成矩阵估计。对于这种杠杆矩阵估计程序，我们建立了逐条目保证，这些保证不依赖于矩阵的一致性，而只依赖于矩阵的尖峰性。这些保证意味着 LoRa-PI 使用 $\widetilde{O}({S+A\over \mathrm{poly}(1-\gamma)\varepsilon^2})$ 个样本学习 $\varepsilon$ 最优策略，其中 $S$（分别为 $A$）表示状态数（分别为动作），$\gamma$ 表示折扣因子。我们的算法在比以前提出的方法假设的条件更温和的条件下实现了这种顺序最优（在 $S$、$A$ 和 $\varepsilon$ 中）样本复杂度。]]></description>
      <guid>https://arxiv.org/abs/2410.23434</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意差距：跨模态嵌入对齐的通用方法</title>
      <link>https://arxiv.org/abs/2410.23437</link>
      <description><![CDATA[arXiv:2410.23437v1 公告类型：新
摘要：检索增强生成 (RAG) 系统通过整合外部知识来增强文本生成，但由于语义差距，在跨不同文本模态检索上下文时往往会遇到困难。我们引入了一种基于广义投影的方法，该方法受到迁移学习中的适配器模块的启发，可以有效地弥合各种文本类型之间的差距，例如编程代码和伪代码，或英语和法语句子。我们的方法强调速度、准确性和数据效率，需要最少的资源进行训练和推理。通过轻量级投影网络将来自异构文本模态的嵌入对齐到统一空间，我们的模型明显优于传统检索方法，如 Okapi BM25 算法和密集段落检索 (DPR) 等模型，同时接近句子变换器的准确性。大量的评估证明了我们的方法在不同任务中的有效性和通用性，凸显了其在实时、资源受限应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.23437</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用线性变换器学习和迁移稀疏上下文二元组</title>
      <link>https://arxiv.org/abs/2410.23438</link>
      <description><![CDATA[arXiv:2410.23438v1 公告类型：新
摘要：Transformers 在自然语言建模方面表现出色，成功的原因之一是它们具有结合上下文非正式和全局知识的卓越能力。然而，其理论基础仍不清楚。在本文中，我们首先介绍稀疏上下文二元模型 (SCB)，它是经典二元模型的自然扩展，其中下一个标记的生成取决于由最后一个标记确定的一组稀疏的早期位置。然后，我们使用基于梯度的算法的单层线性变压器分析学习 SCB 的训练动态和样本复杂度。我们表明，当从头开始训练时，训练过程可以分为初始样本密集阶段，其中相关性从零提升到一个非平凡值，然后是更高效的样本进一步改进阶段。此外，我们证明，如果下游任务和预训练任务之间存在非平凡的相关性，那么从预训练模型进行微调可以让我们绕过初始样本密集阶段。我们还通过实证证明，我们的算法在这种情况下可以胜过 SGD，并讨论了它与通常基于 softmax 的变换器的关系。]]></description>
      <guid>https://arxiv.org/abs/2410.23438</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>