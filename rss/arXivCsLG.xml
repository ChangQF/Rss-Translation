<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 02 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>重新审视随机权重扰动以有效提高泛化能力</title>
      <link>https://arxiv.org/abs/2404.00357</link>
      <description><![CDATA[arXiv:2404.00357v1 公告类型：新
摘要：提高现代深度神经网络（DNN）的泛化能力是机器学习的一个基本挑战。人们提出了两种方法来寻求平坦最小值并提高泛化能力：一种是由锐度感知最小化（SAM）主导，通过对抗性权重扰动（AWP）最小化最坏情况的邻域损失，另一种是通过随机最小化预期贝叶斯目标重量扰动（RWP）。虽然 RWP 在计算方面具有优势，并且在数学基础上与 AWP 密切相关，但其经验性能始终落后于 AWP。在本文中，我们重新审视使​​用 RWP 来提高泛化能力，并从两个角度提出改进：i）泛化和收敛之间的权衡；ii）随机扰动生成。通过广泛的实验评估，我们证明了我们的增强型 RWP 方法在增强泛化方面实现了更高的效率，特别是在大规模问题中，同时还提供了与 SAM 相当甚至更好的性能。代码发布于 https://github.com/nblt/mARWP。]]></description>
      <guid>https://arxiv.org/abs/2404.00357</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:51 GMT</pubDate>
    </item>
    <item>
      <title>TG-NAS：利用变压器和图卷积网络的零成本代理进行高效的神经架构搜索</title>
      <link>https://arxiv.org/abs/2404.00271</link>
      <description><![CDATA[arXiv:2404.00271v1 公告类型：新
摘要：神经架构搜索（NAS）是发现新的卷积神经网络（CNN）架构的有效方法。然而，现有的方法通常需要耗时的培训或密集的采样和评估。零样本 NAS 旨在为架构性能预测创建免训练代理。然而，现有代理的性能欠佳，并且通常无法通过模型参数计数或浮点运算数量等简单指标来实现。此外，现有的基于模型的代理无法推广到新的搜索空间，其中包含未见过的新型运算符，没有黄金准确度事实。普遍最佳的代理仍然难以捉摸。我们引入了 TG-NAS，这是一种新型的基于模型的通用代理，它利用基于变压器的算子嵌入生成器和图卷积网络（GCN）来预测架构性能。这种方法可以指导神经架构在任何给定的搜索空间中进行搜索，而无需重新训练。与其他基于模型的预测子例程不同，TG-NAS 本身充当零成本（ZC）代理，指导架构搜索，具有数据独立性、成本效益和跨不同搜索空间的一致性方面的优势。我们的实验展示了它在各种 NAS 基准测试中相对于现有代理的优势，表明它作为高效架构搜索的基本元素的潜力。与之前的 SOTA ZC 代理方法相比，TG-NAS 的搜索效率提高了 300 倍。值得注意的是，它发现了在 NAS-Bench-201 空间上具有 93.75% CIFAR-10 准确度的竞争模型，在 DARTS 空间上具有 74.5% ImageNet top-1 准确度的竞争模型。]]></description>
      <guid>https://arxiv.org/abs/2404.00271</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:50 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型增强型强化学习综述：概念、分类和方法</title>
      <link>https://arxiv.org/abs/2404.00282</link>
      <description><![CDATA[arXiv:2404.00282v1 公告类型：新
摘要：凭借广泛的预训练知识和高水平的通用能力，大型语言模型（LLM）成为在多任务学习、样本效率和任务规划等方面增强强化学习（RL）的有前途的途径。在本次调查中，我们对$\textit{LLM-enhanced RL}$中的现有文献进行了全面回顾，并总结了其与传统强化学习方法相比的特点，旨在明确未来研究的研究范围和方向。利用经典的主体-环境交互范式，我们提出了一种结构化分类法，对 RL 中的 LLM 功能进行系统分类，包括四个角色：信息处理器、奖励设计者、决策者和生成器。此外，对于每个角色，我们总结了方法，分析了可以缓解的具体强化学习挑战，并提供了对未来方向的见解。最后，讨论了$\textit{LLM-enhanced RL}$的潜在应用、潜在机遇和挑战。]]></description>
      <guid>https://arxiv.org/abs/2404.00282</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:50 GMT</pubDate>
    </item>
    <item>
      <title>InfLoRA：用于持续学习的无干扰低阶适应</title>
      <link>https://arxiv.org/abs/2404.00228</link>
      <description><![CDATA[arXiv:2404.00228v1 公告类型：新
摘要：持续学习要求模型顺序学习多个任务。在持续学习中，模型应具备在旧任务上保持性能的能力（稳定性）和不断适应新任务的能力（可塑性）。最近，参数高效微调（PEFT）在持续学习中越来越受欢迎，它涉及冻结预训练模型并注入少量可学习参数以适应下游任务。尽管现有的基于PEFT的持续学习方法相对于不基于PEFT的持续学习方法表现出了优越的性能，但大多数都没有考虑如何消除新任务对旧任务的干扰，这阻碍了模型做出良好的权衡。稳定性和可塑性之间的差距。在这项工作中，我们提出了一种新的 PEFT 方法，称为无干扰低秩自适应（InfLoRA），用于持续学习。 InfLoRA 注入少量参数来重新参数化预训练权重，并表明微调这些注入的参数相当于微调子空间内的预训练权重。此外，InfLoRA设计这个子空间是为了消除新任务对旧任务的干扰，在稳定性和可塑性之间做出很好的权衡。实验结果表明，InfLoRA 在多个数据集上优于现有最先进的持续学习方法。]]></description>
      <guid>https://arxiv.org/abs/2404.00228</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:49 GMT</pubDate>
    </item>
    <item>
      <title>蛋白质表示学习的聚类</title>
      <link>https://arxiv.org/abs/2404.00254</link>
      <description><![CDATA[arXiv:2404.00254v1 公告类型：新
摘要：蛋白质表示学习是一项具有挑战性的任务，旨在从氨基酸序列中捕获蛋白质的结构和功能。以前的方法很大程度上忽略了这样一个事实：并非所有氨基酸对于蛋白质折叠和活性都同样重要。在本文中，我们提出了一种神经聚类框架，可以通过考虑蛋白质的一级和三级结构信息来自动发现蛋白质的关键成分。我们的框架将蛋白质视为一个图，其中每个节点代表一个氨基酸，每条边代表氨基酸之间的空间或顺序连接。然后，我们应用迭代聚类策略根据节点的 1D 和 3D 位置将节点分组为簇，并为每个簇分配分数。我们选择得分最高的聚类，并使用它们的中心节点进行下一次聚类迭代，直到我们获得蛋白质的层次结构和信息表示。我们评估四个与蛋白质相关的任务：蛋白质折叠分类、酶反应分类、基因本体术语预测和酶委托数预测。实验结果表明我们的方法实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.00254</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:49 GMT</pubDate>
    </item>
    <item>
      <title>通过密度估计进行多策略评估</title>
      <link>https://arxiv.org/abs/2404.00195</link>
      <description><![CDATA[arXiv:2404.00195v1 公告类型：新
摘要：在这项工作中，我们重点关注多策略评估问题，其中给定一组 $K$ 目标策略，目标是评估其性能（预期总奖励），其精度为 $\epsilon$ 和概率至少$1-\delta$。我们提出了一种名为 $\mathrm{CAESAR}$ 的算法来解决这个问题。我们的方法基于计算近似最优离线采样分布并使用从中采样的数据来执行策略值的同步估计。 $\mathrm{CAESAR}$ 由两个阶段组成。在第一个中，我们以低阶样本复杂度对目标策略的访问分布进行粗略估计，该复杂度随 $\tilde{O}(\frac{1}{\epsilon})$ 缩放。在第二阶段，我们近似最佳离线采样分布，并通过最小化受 DualDICE 目标启发的逐步二次损失函数来计算所有目标策略的重要性权重比。直到低阶和对数项 $\mathrm{CAESAR}$ 达到样本复杂度 $\tilde{O}\left(\frac{H^4}{\epsilon^2}\sum_{h=1}^H\ max_{k\in[K]}\sum_{s,a}\frac{(d_h^{\pi^k}(s,a))^2}{\mu^*_h(s,a)}\ right)$，其中$d^{\pi}$是策略$\pi$的访问分布，$\mu^*$是最优抽样分布。]]></description>
      <guid>https://arxiv.org/abs/2404.00195</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:48 GMT</pubDate>
    </item>
    <item>
      <title>基础模型及其他模型的异构对比学习</title>
      <link>https://arxiv.org/abs/2404.00225</link>
      <description><![CDATA[arXiv:2404.00225v1 公告类型：新
摘要：在大数据和人工智能时代，一种新兴的范式是利用对比自监督学习对大规模异构数据进行建模。许多现有的基础模型通过学习紧凑且高质量的表示而不依赖任何标签信息，受益于对比自监督学习的泛化能力。随着自然语言处理和计算机视觉等多个领域的基础模型取得爆炸性进展，迫切需要对基础模型的异构对比学习进行彻底的调查。作为回应，这项调查批判性地评估了基础模型的异构对比学习的现状，强调了对比学习的开放挑战和未来趋势。特别是，我们首先介绍了最新的基于对比学习的先进方法如何处理视图异质性，以及如何应用对比学习来训练和微调多视图基础模型。然后，我们转向任务异质性的对比学习方法，包括预训练任务和下游任务，并展示如何将不同的任务与对比学习损失结合起来以达到不同的目的。最后，我们通过讨论开放的挑战并阐明对比学习的未来方向来结束本次调查。]]></description>
      <guid>https://arxiv.org/abs/2404.00225</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:48 GMT</pubDate>
    </item>
    <item>
      <title>大规模步行和骑行网络建模：使用手机和众包数据的机器学习方法</title>
      <link>https://arxiv.org/abs/2404.00162</link>
      <description><![CDATA[arXiv:2404.00162v1 公告类型：新
摘要：众所周知，步行和骑自行车可以带来巨大的健康、环境和经济优势。然而，基于证据的主动交通规划和政策的制定受到了重大数据限制的阻碍，例如众包数据的偏差和手机数据的代表性问题。在这项研究中，我们开发并应用了基于机器学习的建模方法，用于估计澳大利亚新南威尔士州大型区域网络的每日步行和骑行量，其中包括 188,999 个步行链路和 114,885 个自行车链路。该建模方法利用众包和手机数据以及有关人口、土地利用、地形、气候等的一系列其他数据集。该研究讨论了与模型训练、测试和推理所有三个方面相关的独特挑战和局限性考虑到建模网络的地理范围很大，并且观察到的步行和骑自行车计数数据相对稀缺。该研究还提出了一种新技术来识别模型估计异常值并减轻其影响。总体而言，该研究为交通建模者、政策制定者和城市规划者提供了宝贵的资源，帮助他们利用先进的新兴数据驱动建模方法来加强积极的交通基础设施规划和政策。]]></description>
      <guid>https://arxiv.org/abs/2404.00162</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:47 GMT</pubDate>
    </item>
    <item>
      <title>比较用于预测有机太阳能电池效率下降的超优化机器学习模型</title>
      <link>https://arxiv.org/abs/2404.00173</link>
      <description><![CDATA[arXiv:2404.00173v1 公告类型：新
摘要：这项工作提出了一组最佳机器学习（ML）模型来表示具有多层结构 ITO/PEDOT:PSS/P3HT:PCBM 的聚合物有机太阳能电池（OSC）的功率转换效率（PCE）所遭受的时间退化。 /艾尔。为此，我们生成了一个包含 996 个条目的数据库，其中包括多达 7 个有关 180 多天的制造过程和环境条件的变量。然后，我们依靠一个软件框架，该框架汇集了一系列自动化机器学习协议，这些协议通过简单的命令行界面针对我们的数据库顺序执行。这可以轻松地通过详尽的基准测试对 ML 模型的种子进行超优化和随机化，从而获得最佳模型。所达到的精度达到系数确定值（R2）大大超过0.90，而均方根误差（RMSE）、误差平方和（SSE）和平均绝对误差（MAE）&gt;目标值的1%， PCE。此外，我们还提供经过验证的模型，能够筛选数据库中从未见过的 OSC 的行为。在这种情况下，R2~0.96-0.97和RMSE~1%，从而证实了该建议预测的可靠性。出于比较目的，还提出了基于非线性均方 (LMS) 的经典贝叶斯回归拟合，其仅适用于单个 OSC 的单变量情况。因此，它们无法超越机器学习模型所显示的功能广度。最后，借助机器学习框架提供的标准化结果，我们研究了数据集变量之间的依赖性及其对 OSC 最佳性能和稳定性的影响。标准化报告和数据集确保了可重复性，这些报告可在 Github 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.00173</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:47 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯非参数：深度学习的替代方案</title>
      <link>https://arxiv.org/abs/2404.00085</link>
      <description><![CDATA[arXiv:2404.00085v1 公告类型：新
摘要：贝叶斯非参数模型为统计模型选择提供了灵活而强大的框架，使模型复杂性能够适应各种数据集的复杂性。这项调查旨在深入探讨贝叶斯非参数的重要性，特别是在解决统计、计算机科学和电气工程等各个领域的复杂挑战方面。通过阐明这些非参数模型的基本属性和理论基础，本次调查旨在提供对贝叶斯非参数及其在解决复杂问题中的相关性的全面理解，特别是在多目标跟踪领域。通过这种探索，我们揭示了贝叶斯非参数方法的多功能性和有效性，为跨学科的复杂挑战的创新解决方案铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2404.00085</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:46 GMT</pubDate>
    </item>
    <item>
      <title>PikeLPN：缓解低精度神经网络被忽视的低效率问题</title>
      <link>https://arxiv.org/abs/2404.00103</link>
      <description><![CDATA[arXiv:2404.00103v1 公告类型：新
摘要：低精度量化因其在神经网络优化中的功效而受到认可。我们的分析表明，参数化激活函数、批量归一化和量化缩放等层中普遍存在的非量化元素运算在低精度模型的推理成本中占主导地位。这些非量化的元素运算在算术计算工作量 (ACE) 等 SOTA 效率指标中通常被忽视。在本文中，我们提出了 ACEv2 - ACE 的扩展版本，它可以更好地匹配量化模型的推理成本及其在 ML 硬件上的能耗。此外，我们还引入了 PikeLPN，该模型通过将量化应用于元素运算和乘法累加运算来解决这些效率问题。特别是，我们提出了一种名为 QuantNorm 的新型批量归一化层量化技术，它允许在不影响模型性能的情况下量化批量归一化参数。此外，我们建议应用双量化，其中量化缩放参数被量化。此外，我们通过引入分布异构量化来认识并解决可分离卷积层中的分布不匹配问题，该量化能够将它们量化到低精度。与 SOTA 低精度模型相比，PikeLPN 在效率与精度权衡方面实现了帕累托最优，效率提高了 3 倍。]]></description>
      <guid>https://arxiv.org/abs/2404.00103</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:46 GMT</pubDate>
    </item>
    <item>
      <title>用于快速模型选择的两阶段召回和选择框架</title>
      <link>https://arxiv.org/abs/2404.00069</link>
      <description><![CDATA[arXiv:2404.00069v1 公告类型：新
摘要：随着深度学习在各种机器学习应用中的普及，公共模型存储库上训练和共享的神经网络模型激增。在有针对性的机器学习任务中，利用合适的源模型作为起点通常优于从头开始训练的策略，特别是在训练数据有限的情况下。尽管在之前的工作中研究和开发了许多模型选择策略，但该过程仍然非常耗时，特别是考虑到模型存储库的规模不断扩大。在本文中，我们提出了一个两阶段（粗略召回和精细选择）模型选择框架，旨在通过利用模型在基准数据集上的训练性能来提高选择鲁棒模型的效率。具体来说，粗略回忆阶段集群模型以离线方式在基准数据集上展示了类似的训练性能。随后在此模型集群和目标数据集之间计算轻量级代理分数，这有助于快速召回潜在候选模型的小得多的子集。在接下来的微调阶段，通过连续减半对目标数据集上的召回模型进行微调来选择最终模型。为了加速这一过程，通过挖掘模型在基准数据集上的收敛趋势来预测每个潜在模型的最终微调性能，这有助于在微调过程中更早地过滤性能较低的模型。通过对自然语言处理和计算机视觉等任务的广泛实验，已经证明所提出的方法有助于以比传统基线方法快约 3 倍的速度选择高性能模型。我们的代码可在 https://github.com/plasware/two-phase-selection 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.00069</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>用于将微结构的弹性特性映射到其机械变形的有限算子学习技术</title>
      <link>https://arxiv.org/abs/2404.00074</link>
      <description><![CDATA[arXiv:2404.00074v1 公告类型：新
摘要：为了开发更快的求解器来控制固体力学中的物理方程，我们引入了一种参数化学习机械平衡解的方法。所引入的方法在计算成本方面优于传统方法，同时保持了可接受的精度。此外，它概括并增强了标准的物理信息神经网络，以学习具有相当尖锐不连续性的参数解决方案。我们以微观力学为例，其中微观力学解决方案的知识，即给定异质微观结构的变形和应力场，至关重要。所研究的参数是非均质固体系统内的杨氏模量分布。我们的方法受到算子学习和有限元方法的启发，展示了在不依赖其他数值求解器的数据的情况下进行训练的能力。相反，我们利用有限元方法的思想，以代数方式有效地设置损失函数，特别是基于控制方程的离散弱形式。值得注意的是，我们的研究表明，与纯粹的数据驱动方法相比，基于物理的训练对于看不见的微观结构具有更高的准确性。从本质上讲，该方法实现了对数据的独立性，并提高了超出训练范围的预测的准确性。上述观察结果适用于异质弹性微观结构。还与其他著名的算子学习算法（例如 DeepOnet）进行了比较，以进一步强调新提出的架构的优势。]]></description>
      <guid>https://arxiv.org/abs/2404.00074</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>BEACON：贝叶斯实验设计加速条件标准化流量 $-$ CO$_2$ 封存最佳监测井位置的案例研究</title>
      <link>https://arxiv.org/abs/2404.00075</link>
      <description><![CDATA[arXiv:2404.00075v1 公告类型：新
摘要：CO$_2$封存是减缓气候变化的重要工程解决方案。然而，储层性质的不确定性，需要对 CO$_2$ 羽流进行严格监测，以防止泄漏、诱发地震或突破许可边界等风险。为了解决这个问题，项目经理使用钻孔井进行直接 CO$_2$ 和特定位置的压力监测。鉴于钻井成本高昂，战略性地放置有限数量的井以确保在预算限制内实现最有效的监测至关重要。我们选择井位的方法将用于预测羽流轨迹的流体流动求解器与用于羽流推理不确定性的生成神经网络相结合。我们的方法可扩展到三维领域，并在贝叶斯框架内开发，以实现最佳实验设计，确保可扩展性和数学最优性。我们使用现实的案例研究来验证这些说法，通过展示我们的方法在大规模领域的应用以及与基线井位相比的最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2404.00075</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>使用粒度语义和人工智能驱动的破产预测管道进行缺失数据插补</title>
      <link>https://arxiv.org/abs/2404.00013</link>
      <description><![CDATA[arXiv:2404.00013v1 公告类型：新
摘要：这项工作的重点是设计破产预测的管道。缺失值、高维数据和高度类别不平衡数据库的存在是上述任务的主要挑战。这里介绍了一种具有粒度语义的缺失数据插补的新方法。这里探讨了粒度计算的优点来定义这种方法。缺失值是使用低维空间、粒度空间中的特征语义和可靠观察来预测的。颗粒围绕每个缺失条目形成，考虑一些高度相关的特征和最可靠的最接近的观察结果，以保留数据库针对缺失条目的相关性和可靠性、上下文。然后对这些上下文颗粒内的插补进行颗粒间预测。也就是说，上下文颗粒使得庞大数据库中的一小部分相关部分能够用于插补，并克服了针对每个缺失值重复访问整个数据库的需要。然后使用波兰破产数据集实施并测试该方法以预测破产。即使具有较大的插补率，它也为大型和高维数据集提供了有效的解决方案。然后，使用所提出的基于粒度语义的数据填充方法设计了人工智能驱动的破产预测管道，并解决了高维数据集和数据集中的高类别不平衡等问题。该流程的其余部分包括使用随机森林进行特征选择以降低维度、使用 SMOTE 进行数据平衡以及使用六种不同的流行分类器（包括深度神经网络）进行预测。此处定义的所有方法均已通过适当的比较研究进行了实验验证，并被证明对五年内捕获的所有数据集有效。]]></description>
      <guid>https://arxiv.org/abs/2404.00013</guid>
      <pubDate>Tue, 02 Apr 2024 21:11:44 GMT</pubDate>
    </item>
    </channel>
</rss>