<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>ADO-LLM：利用大型语言模型的上下文学习进行模拟设计贝叶斯优化</title>
      <link>https://arxiv.org/abs/2406.18770</link>
      <description><![CDATA[arXiv:2406.18770v1 公告类型：新
摘要：模拟电路设计需要大量的人力专业知识和参与，这是设计效率的重大障碍。贝叶斯优化 (BO) 是一种流行的基于机器学习的优化策略，由于其适用于各种电路拓扑和技术，已被用于自动化模拟设计。传统的 BO 方法采用黑盒高斯过程代理模型和优化的标记数据查询，通过在探索和利用之间进行权衡来找到优化解决方案。然而，从计算和数据使用的角度来看，在 BO 中寻找最佳设计解决方案的成本可能很高，尤其是对于高维优化问题。本文介绍了 ADO-LLM，这是第一项将大型语言模型 (LLM) 与贝叶斯优化相结合以进行模拟设计优化的工作。 ADO-LLM 利用 LLM 注入领域知识的能力来快速生成可行的设计点，以弥补 BO 在寻找高价值设计领域方面的低效率，尤其是在 BO 概率代理模型的设计空间覆盖有限的情况下。同时，在迭代 BO 过程中评估的设计点采样为 LLM 提供了质量证明，使其能够利用注入的广泛设计知识生成高质量的设计点。此外，BO 探索带来的多样性丰富了 LLM 的背景理解，使其能够更广泛地在设计空间中进行搜索，并防止重复和冗余的建议。我们在两种不同类型的模拟电路上评估了所提出的框架，并证明了设计效率和有效性的显着提高。]]></description>
      <guid>https://arxiv.org/abs/2406.18770</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:29 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络上的共形链接预测</title>
      <link>https://arxiv.org/abs/2406.18763</link>
      <description><![CDATA[arXiv:2406.18763v1 公告类型：新 
摘要：图神经网络 (GNN) 在不同的任务中表现出色，但它们在高风险领域的应用往往受到不可靠预测的阻碍。尽管已经提出了许多不确定性量化方法来解决这一限制，但它们往往缺乏 \textit{严格的} 不确定性估计。这项工作首次尝试引入一种无分布和与模型无关的不确定性量化方法来构建具有统计保证的基于 GNN 的链接预测的预测区间。我们将其称为 \textit{共形链接预测}。我们的方法建立在共形预测 (CP) 的基础上，这是一个有望构建统计上稳健的预测集或区间的框架。我们首先从理论和经验上为 CP 在链接预测任务中的应用建立了置换不变性条件，以及精确的测试时间覆盖率。利用图中的重要结构信息，我们随后确定了图对幂律分布的遵守与 CP 效率之间的新且关键的联系。这一见解促成了一种简单而有效的基于采样的方法的开发，用于在标准 CP 程序之前将图结构与幂律分布对齐。大量实验表明，对于共形链接预测，我们的方法实现了所需的边际覆盖率，同时与基线方法相比显著提高了 CP 的效率。]]></description>
      <guid>https://arxiv.org/abs/2406.18763</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:28 GMT</pubDate>
    </item>
    <item>
      <title>WV-Net：SAR WV 模式卫星图像的基础模型，使用对比自监督学习对 1000 万幅图像进行训练</title>
      <link>https://arxiv.org/abs/2406.18765</link>
      <description><![CDATA[arXiv:2406.18765v1 公告类型：新
摘要：欧洲航天局的哥白尼哨兵-1 (S-1) 任务是一组 C 波段合成孔径雷达 (SAR) 卫星，可为世界海洋提供前所未有的监测。S-1 的波浪模式 (WV) 以 5 米像素分辨率捕获 20x20 公里的图像块，不受云层覆盖或一天中的时间影响。该任务的开放数据政策使 SAR 数据易于用于各种应用，但对手动图像注释的需求是阻碍使用机器学习方法的瓶颈。这项研究使用近 1000 万张 WV 模式图像和对比自监督学习来训练一个名为 WV-Net 的语义嵌入模型。在多个下游任务中，WV-Net 的表现优于使用监督学习在自然图像 (ImageNet) 上进行预训练的类似模型。实验表明，在估计波高（使用线性探测时 0.50 vs 0.60 RMSE）、估计近地表气温（0.90 vs 0.97 RMSE）以及执行地球物理和大气现象的多标签分类（0.96 vs 0.95 微平均 AUROC）方面均有所改进。WV-Net 嵌入在无监督图像检索任务中也表现出色，并且在数据稀疏设置中具有更好的扩展性。总之，这些结果表明 WV-Net 嵌入可以通过为各种数据分析和探索任务提供方便的基础模型来支持地球物理研究。]]></description>
      <guid>https://arxiv.org/abs/2406.18765</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 RL 和 DQN 实现动态路障的 AV 分散式语义交通控制</title>
      <link>https://arxiv.org/abs/2406.18741</link>
      <description><![CDATA[arXiv:2406.18741v1 公告类型：新
摘要：自动驾驶汽车 (AV) 配备了能够捕捉速度、加速度和精确位置等基本车辆动态的传感器，能够在预测即将遇到的路障时执行智能操作，包括变道。然而，大量的传感数据和做出明智决策所需的处理往往会让车辆不堪重负，导致它们无法独立完成任务。因此，在交通场景中，一种常见的方法是将数据传输到服务器进行处理，这种做法带来了挑战，尤其是在需要实时处理的情况下。为了应对这一挑战，我们提出了一种基于 DL 的新型语义交通控制系统，将语义编码责任委托给车辆本身。该系统处理从强化学习 (RL) 代理获得的驾驶决策，从而简化决策过程。具体来说，我们的框架设想了由于道路维护、事故或车辆维修等因素而突然出现路障的场景，需要车辆做出有关车道保持或车道变换的决策，以绕过这些障碍。为了用数学方法表述这种场景，我们采用了马尔可夫决策过程 (MDP) 并利用深度 Q 学习 (DQN) 算法来发掘可行的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.18741</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>QBI：基于分位数的偏差初始化，用于联邦学习中高效的私有数据重建</title>
      <link>https://arxiv.org/abs/2406.18745</link>
      <description><![CDATA[arXiv:2406.18745v1 公告类型：新
摘要：联邦学习可以在分布式数据上训练机器学习模型，而不会损害用户隐私，因为数据保留在个人设备上，并且只有模型更新（例如梯度）与中央协调器共享。然而，最近的研究表明，中央实体可以通过恶意初始化模型的参数，从共享模型更新中完美地重建私有数据。在本文中，我们提出了 QBI，这是一种新颖的偏差初始化方法，可显着增强重建能力。这是通过直接求解产生稀疏激活模式的偏差值来实现的。此外，我们提出了一种基于 QBI 的算法 PAIRS。当有来自目标域的单独数据集可用时，可以部署 PAIRS，以进一步增加可以完全恢复的数据百分比。以能够从不同大小的批次中完美重建的样本百分比来衡量，我们的方法比以前的方法取得了显著的改进，在 ImageNet 上增益高达 50%，在 IMDB 情绪分析文本数据集上增益高达 60%。此外，我们为利用随机梯度稀疏性的攻击建立了理论极限，为理解这些攻击的基本限制奠定了基础。我们使用合成数据集对这些限制进行了实证评估。最后，我们提出并评估了 AGGP，这是一个旨在防止梯度稀疏性攻击的防御框架，有助于开发更安全、更私密的联邦学习系统。]]></description>
      <guid>https://arxiv.org/abs/2406.18745</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>具有简洁预测的在线背包竞争算法</title>
      <link>https://arxiv.org/abs/2406.18752</link>
      <description><![CDATA[arXiv:2406.18752v1 公告类型：新
摘要：在线背包问题中，目标是将在线到达的具有不同价值和重量的物品打包到容量有限的背包中，以最大化所接受物品的总价值。我们研究了针对此问题的 \textit{学习增强} 算法，旨在使用机器学习预测来超越悲观的最坏情况保证。现有的在线背包学习增强算法考虑了相对复杂的预测模型，这些模型为算法提供了有关输入的大量信息，例如每个值下物品的总重量。实际上，这种预测可能对错误敏感且难以学习。受此限制的启发，我们引入了一系列使用 \emph{简洁预测} 的在线背包学习增强算法。具体来说，给予算法的机器学习预测只是一个单一值或间隔，用于估计离线最优解决方案接受的任何项目的最小值。通过利用对在线 \emph{fractional} 背包的放松，我们设计了可以在可信设置（即具有完美预测）和不可信设置中利用这种简洁预测的算法，我们证明了一个简单的元算法实现了近乎最佳的一致性-鲁棒性权衡。从经验上讲，我们表明我们的算法明显优于不使用预测的基线，并且通常优于基于更复杂预测模型的算法。]]></description>
      <guid>https://arxiv.org/abs/2406.18752</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>使用阿拉伯语音译和 Arabizi 破解法学硕士课程</title>
      <link>https://arxiv.org/abs/2406.18725</link>
      <description><![CDATA[arXiv:2406.18725v1 公告类型：新
摘要：本研究确定了大型语言模型 (LLM) 可能遭受“越狱”攻击的漏洞，特别关注阿拉伯语及其各种形式。虽然大多数研究都集中在基于英语的提示操纵上，但我们的研究范围扩大到阿拉伯语。我们最初在标准阿拉伯语中测试了 AdvBench 基准，发现即使使用前缀注入等提示操纵技术，也不足以诱使 LLM 生成不安全的内容。然而，当使用阿拉伯语音译和聊天语言 (或 arabizi) 时，我们发现在 OpenAI GPT-4 和 Anthropic Claude 3 Sonnet 等平台上可能会产生不安全的内容。我们的研究结果表明，使用阿拉伯语及其各种形式可能会暴露可能隐藏的信息，从而可能增加越狱攻击的风险。我们假设这种暴露可能是由于模型与特定单词的学习联系，这凸显了对所有语言形式进行更全面的安全培训的必要性。]]></description>
      <guid>https://arxiv.org/abs/2406.18725</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>RetroGFN：使用 GFlowNets 进行多样化且可行的逆合成</title>
      <link>https://arxiv.org/abs/2406.18739</link>
      <description><![CDATA[arXiv:2406.18739v1 公告类型：新
摘要：单步逆合成旨在预测导致产生目标分子的一组反应，这是分子发现中的一项关键任务。虽然目标分子通常可以通过多种不同的反应合成，但尚不清楚如何验证反应的可行性，因为可用的数据集仅涵盖了可能解决方案的一小部分。因此，现有模型不鼓励充分探索可能的反应空间。在本文中，我们提出了一种新颖的单步逆合成模型 RetroGFN，该模型可以在有限的数据集之外进行探索，并通过在训练期间利用可行性代理模型返回一组多样化的可行反应。我们表明，RetroGFN 在标准 top-k 准确度上取得了有竞争力的结果，同时在往返准确度上优于现有方法。此外，我们提供了支持使用往返准确度的经验论据，这扩展了相对于标准 top-k 准确度指标的可行性概念。]]></description>
      <guid>https://arxiv.org/abs/2406.18739</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>学习还是放弃：持续学习的模块组成和修剪</title>
      <link>https://arxiv.org/abs/2406.18708</link>
      <description><![CDATA[arXiv:2406.18708v1 公告类型：新
摘要：在现实环境中，持续学习对于机器学习模型至关重要，因为它们需要逐步获取新知识而不会忘记已经学到的知识。虽然预训练语言模型在各种静态任务上表现出色，但将它们应用于持续学习带来了重大挑战，包括避免灾难性遗忘、促进知识转移和保持参数效率。在本文中，我们介绍了 MoCL-P，一种新颖的轻量级持续学习方法，可同时解决这些挑战。与不断扩展新任务参数的传统方法不同，MoCL-P 将任务表示引导的模块组合与自适应修剪相结合，有效地平衡了知识集成和计算开销。我们对三个持续学习基准（最多 176 个任务）的评估表明，MoCL-P 实现了最先进的性能，并将参数效率提高了三倍，展示了其在资源需求受限的实际应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.18708</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>学习使用黑盒法学硕士 (LLM) 纠正 QA 推理</title>
      <link>https://arxiv.org/abs/2406.18695</link>
      <description><![CDATA[arXiv:2406.18695v1 公告类型：新
摘要：最近机器学习的一个开放挑战是如何在黑盒设置中提高大型语言模型 (LLM) 的推理能力，即无法访问输出标记概率等详细信息。现有方法要么依赖于可访问性（这通常是不切实际的），要么涉及显著增加的训练和推理时间成本。本文通过提出一种新方法，即 CoBB（用于改进黑盒 LLM 的 QA 推理的正确方法），解决了这些限制或缺点。它使用经过训练的自适应模型执行 seq2seq 映射，从原始黑盒 LLM 通常不完美的推理到正确或改进的推理。具体而言，自适应模型使用相对较小的开源 LLM 初始化，并在子采样训练对集合上进行调整。为了选择正确和错误推理的代表性对，我们将数据集构建公式化为一个优化问题，以最小化采样子集和整个集合之间的统计差异，并通过遗传算法解决该问题。然后，我们通过对比正确和错误推理的可能性，对采样对训练自适应模型。我们的实验结果表明，与表现最佳的自适应基线相比，CoBB 显著提高了各种 QA 基准中的推理准确性。]]></description>
      <guid>https://arxiv.org/abs/2406.18695</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>快速优化器基准测试</title>
      <link>https://arxiv.org/abs/2406.18701</link>
      <description><![CDATA[arXiv:2406.18701v1 公告类型：新
摘要：在本文中，我们介绍了快速优化器基准 (FOB)，这是一种用于在开发过程中评估深度学习优化器的工具。基准测试支持来自多个领域的任务，例如计算机视觉、自然语言处理和图形学习。重点是方便使用，具有人性化可读的 YAML 配置、SLURM 集成和绘图实用程序。FOB 可以与现有的超参数优化 (HPO) 工具一起使用，因为它可以处理训练和运行恢复。模块化设计允许集成到自定义管道中，只需将其用作任务集合即可。我们展示了优化器比较作为我们工具的使用示例。FOB 可以在 GitHub 上找到：https://github.com/automl/FOB。]]></description>
      <guid>https://arxiv.org/abs/2406.18701</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>使用检查点模型权重改进超参数优化</title>
      <link>https://arxiv.org/abs/2406.18630</link>
      <description><![CDATA[arXiv:2406.18630v1 公告类型：新
摘要：在训练深度学习模型时，性能在很大程度上取决于所选的超参数。然而，超参数优化 (HPO) 通常是模型设计中最昂贵的部分之一。经典的 HPO 方法将其视为黑盒优化问题。然而，灰盒 HPO 方法包含了更多关于设置的信息，已成为更高效优化的一个有希望的方向。例如，使用中间损失评估来终止错误的选择。在这项工作中，我们提出了一种用于神经网络的 HPO 方法，使用训练权重的记录检查点来指导未来的超参数选择。我们的方法，预测模型搜索 (FMS)，将权重嵌入高斯过程深度核代理模型中，使用置换不变图元网络通过记录的网络权重实现数据效率。为了促进可重复性和进一步研究，我们在 https://github.com/NVlabs/forecasting-model-search 开放源代码。]]></description>
      <guid>https://arxiv.org/abs/2406.18630</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>RouteLLM：学习使用偏好数据路由法学硕士</title>
      <link>https://arxiv.org/abs/2406.18665</link>
      <description><![CDATA[arXiv:2406.18665v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种任务中表现出令人印象深刻的能力，但选择使用哪种模型通常涉及性能和成本之间的权衡。更强大的模型虽然有效，但成本更高，而能力较弱的模型更具成本效益。为了解决这一困境，我们提出了几种高效的路由器模型，它们在推理过程中动态选择更强和更弱的 LLM，旨在优化成本和响应质量之间的平衡。我们为这些路由器开发了一个训练框架，利用人类偏好数据和数据增强技术来提高性能。我们对广受认可的基准的评估表明，我们的方法显着降低了成本（在某些情况下降低了 2 倍以上），而不会影响响应质量。有趣的是，我们的路由器模型还展示了显着的迁移学习能力，即使在测试时更改强模型和弱模型时也能保持其性能。这凸显了这些路由器为部署 LLM 提供经济高效但高性能解决方案的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.18665</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>具有不一致响应的 LLM 的小样本个性化</title>
      <link>https://arxiv.org/abs/2406.18678</link>
      <description><![CDATA[arXiv:2406.18678v1 公告类型：新
摘要：随着用户多样性的增加，大型语言模型 (LLM) 提供个性化响应的能力变得越来越重要。由于缺乏个性化学习或依赖共享个人数据，现有方法在 LLM 个性化方面仅取得有限的成功。本文提出了一种新方法，用于对具有不一致响应的 LLM 进行少量个性化 (Fermi)。我们的主要思想是通过使用 LLM 逐步改进提示来为每个用户学习一组个性化提示，这些提示基于用户个人资料（例如人口统计信息）和一些先前意见的示例。在提示改进的迭代过程中，我们结合了 LLM 不一致响应的上下文，这对于 LLM 的有效个性化尤为重要。此外，我们开发了一种有效的推理方法来进一步利用测试查询和个性化提示的上下文。我们的实验结果表明，与表现最佳的基线相比，Fermi 在各个基准测试中的表现都有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2406.18678</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>Step-DPO：LLM 长链推理的分步偏好优化</title>
      <link>https://arxiv.org/abs/2406.18629</link>
      <description><![CDATA[arXiv:2406.18629v1 公告类型：新
摘要：数学推理对大型语言模型 (LLM) 提出了重大挑战，因为准确性需要广泛而精确的推理链。确保每个推理步骤的正确性至关重要。为了解决这个问题，我们旨在通过从人类反馈中学习来增强 LLM 的稳健性和真实性。然而，直接偏好优化 (DPO) 对长链数学推理的好处有限，因为采用 DPO 的模型很难识别错误答案中的细节错误。这种限制源于缺乏细粒度的过程监督。我们提出了一种简单、有效且数据高效的方法，称为 Step-DPO，它将单个推理步骤视为偏好优化的单位，而不是整体评估答案。此外，我们还为 Step-DPO 开发了一个数据构建管道，从而可以创建包含 10K 个逐步偏好对的高质量数据集。我们还观察到，在 DPO 中，由于后者的分布不均特性，自生成数据比人类或 GPT-4 生成的数据更有效。我们的研究结果表明，对于具有超过 700 亿个参数的模型，少至 10K 个偏好数据对和少于 500 个 Step-DPO 训练步骤就可以在 MATH 上使准确率提高近 3%。值得注意的是，当将 Step-DPO 应用于 Qwen2-72B-Instruct 时，在 MATH 和 GSM8K 的测试集上分别获得了 70.8% 和 94.0% 的分数，超越了一系列闭源模型，包括 GPT-4-1106、Claude-3-Opus 和 Gemini-1.5-Pro。我们的代码、数据和模型可在 https://github.com/dvlab-research/Step-DPO 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.18629</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:22 GMT</pubDate>
    </item>
    </channel>
</rss>