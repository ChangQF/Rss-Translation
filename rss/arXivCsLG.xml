<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 10 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>多保真替代模型、NARGP、数字孪生、水产养殖网箱、实时监控、图卷积网络</title>
      <link>https://arxiv.org/abs/2406.04519</link>
      <description><![CDATA[arXiv:2406.04519v1 公告类型：新
摘要：随着全球人口增长和气候变化加剧，可持续的粮食生产至关重要。海水养殖提供了一种可行的解决方案，提供了可持续的蛋白质来源。然而，该行业的扩张需要远程管理和自主运营的新技术。数字孪生技术可以推动水产养殖业的发展，但其采用受到限制。鱼网笼是一种灵活的浮动结构，是水产养殖场的关键但脆弱的组成部分。暴露在恶劣和动态的海洋环境中，笼子会承受巨大的负荷和风险损坏，导致鱼类逃逸、环境影响和财务损失。我们提出了一个多保真度替代建模框架，用于集成到数字孪生中，以实时监测随机海洋条件下的水产养殖网笼结构动力学。该框架的核心是非线性自回归高斯过程方法，它可以学习不同保真度模型之间复杂的非线性互相关。它将低保真模拟数据与一小组高保真现场传感器测量数据相结合，这些测量数据提供了真实的动态，但成本高昂且空间稀疏。我们的数字孪生在挪威的 SINTEF ACE 养鱼场进行了验证，它可以接收在线海洋气象数据，准确预测网箱位移和系泊缆载荷，与现场测量结果紧密结合。所提出的框架在应用特定数据稀缺的情况下非常有用，可以提供快速预测和实时系统表示。开发的数字孪生通过评估结构完整性来防止潜在损坏，并方便无人水下航行器的远程操作。我们的工作还比较了 GP 和 GCN 在预测网箱变形方面的表现，突出了后者在复杂结构应用中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.04519</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>FLUID-LLM：使用时空感知大型语言模型学习计算流体动力学</title>
      <link>https://arxiv.org/abs/2406.04501</link>
      <description><![CDATA[arXiv:2406.04501v1 公告类型：新
摘要：学习计算流体动力学 (CFD) 传统上依赖于对 Navier-Stokes 方程的计算密集型模拟。最近，大型语言模型 (LLM) 在自然语言处理 (NLP) 和计算机视觉 (CV) 中表现出了卓越的模式识别和推理能力。然而，这些模型难以应对流体动力学固有的复杂几何形状。我们引入了 FLUID-LLM，这是一个将预训练的 LLM 与时空感知编码相结合以预测非稳定流体动力学的新型框架。我们的方法利用 LLM 的时间自回归能力以及空间感知层，弥合了以前的 CFD 预测方法之间的差距。对标准基准的评估显示，各种流体数据集的性能都有显著提高。我们的结果表明，FLUID-LLM 有效地将时空信息集成到预训练的 LLM 中，从而提高了 CFD 任务的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.04501</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>多智能体流的在线联合微调</title>
      <link>https://arxiv.org/abs/2406.04516</link>
      <description><![CDATA[arXiv:2406.04516v1 公告类型：新
摘要：Flow 是组件模型（“代理”）的集合，它通过迭代通信构建复杂问题的解决方案。Flow 已成为代码生成的最新架构，也是 Autogen 等框架存在的理由。但是，目前，流程是通过手动提示工程和分阶段监督学习技术的组合构建的；后者仅限于具有细粒度节点监督的非循环流程。在本文中，我描述了一种受学习搜索框架启发的整个流程的在线联合微调过程。该方法利用模拟器访问将对整个情节的偏好减少为对单个节点输出的偏好；当组件是语言模型时，后者是一个经过充分研究的问题。如果情节评估器模型可用，该方法适用于无奖励设置（例如文本反馈）。我将其应用于多跳 QA 数据集 Musique，获得了最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.04516</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:27 GMT</pubDate>
    </item>
    <item>
      <title>音乐个性化的负面反馈</title>
      <link>https://arxiv.org/abs/2406.04488</link>
      <description><![CDATA[arXiv:2406.04488v1 公告类型：新
摘要：下一项推荐系统通常仅使用正反馈和随机采样的负反馈进行训练。我们展示了使用真实负反馈作为用户序列的输入以及作为训练互联网广播的下一首歌曲推荐系统的负目标的好处。特别是，在训练期间使用显式负样本有助于将训练时间缩短约 60%，同时将测试准确率提高约 6%；添加用户跳过作为额外输入也可以显着增加用户覆盖率，同时略微提高准确率。我们测试了使用大量随机负样本捕获“更难”样本的影响，发现测试准确率会随着更多随机采样的负样本而增加，但只会达到一定程度。太多的随机负样本会导致假负样本，从而限制提升，这仍然低于使用真实负反馈的情况。我们还发现，测试准确率对于不同反馈类型的比例相当稳健，并比较了不同反馈类型的学习嵌入。]]></description>
      <guid>https://arxiv.org/abs/2406.04488</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 CFLIS 和 MGR-LAU 的用户意图识别和基于语义缓存优化的查询处理框架</title>
      <link>https://arxiv.org/abs/2406.04490</link>
      <description><![CDATA[arXiv:2406.04490v1 公告类型：新
摘要：查询处理 (QP) 由基于云的缓存优化，将经常访问的数据存储在离用户更近的地方。然而，在现行工作中，查询中缺乏对用户意图类型的关注影响了 QP 的效率。因此，通过使用上下文模糊语言推理系统 (CFLIS)，本研究分析了查询中的信息、导航和基于事务的意图，以增强 QP。首先，使用标记化、规范化、停用词删除、词干提取和 POS 标记来解析用户查询，然后使用 WordNet 技术进行扩展。在扩展查询之后，为了增强查询理解并促进查询处理中更准确的分析和检索，使用双向编码器 UnispecNorm 表示从 Transformers (BEUNRT) 识别命名实体。接下来，为了高效地 QP 和从语义缓存数据库中检索查询信息，使用 Epanechnikov 核排序点识别聚类结构 (EK-OPTICS) 对数据进行结构化。从结构化数据中提取特征。现在，识别句子类型并从解析的查询中提取意图关键字。接下来，将提取的特征、检测到的意图和结构化数据输入到多头门控循环可学习注意力单元 (MGR-LAU)，该单元基于语义缓存数据库处理查询（存储先前解释的查询以加快有效的未来搜索）。此外，查询处理的最小延迟为 12856 毫秒。最后，分析检索到的查询和输入的用户查询之间的语义相似度 (SS)，该分析持续到相似度达到 0.9 及以上。因此，所提出的工作超越了以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.04490</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:26 GMT</pubDate>
    </item>
    <item>
      <title>神经网络 Hessian 矩阵的可证明界限：保持导数可达性分析</title>
      <link>https://arxiv.org/abs/2406.04476</link>
      <description><![CDATA[arXiv:2406.04476v1 公告类型：新
摘要：我们提出了一种新颖的可达性分析方法，专门用于具有可微分激活的神经网络。我们的想法取决于基于一阶泰勒展开和余数边界的神经网络图的合理抽象。为此，我们提出了一种计算网络一阶导数（梯度）和二阶导数（Hessian）的解析边界的方法。我们方法的一个关键方面是对激活函数进行循环变换，以有效利用它们的单调性。由此产生的端到端抽象在本地保留了导数信息，从而在小输入集上产生准确的边界。最后，我们采用分支定界框架对较大的输入集进行递归细化抽象。我们通过不同的示例对我们的方法进行了数值评估，并将结果与​​相关的最先进方法进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2406.04476</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:25 GMT</pubDate>
    </item>
    <item>
      <title>多核心边缘视角：通过相对中心性进行排名</title>
      <link>https://arxiv.org/abs/2406.04487</link>
      <description><![CDATA[arXiv:2406.04487v1 公告类型：新
摘要：社区和核心-边缘是两种广泛研究的图结构，在现实世界的图中观察到它们的共存（Rombach、Porter、Fowler \&amp; Mucha [SIAM J. App. Math. 2014, SIAM Review 2017]）。然而，这种共存的性质尚未得到很好的理解，并已被指出是一个悬而未决的问题（Yanchenko \&amp; Sengupta [Statistics Surveys, 2023]）。特别是，推断图的核心-边缘结构对理解其社区结构的影响没有得到很好的利用。在这个方向上，我们为具有地面真实社区的图引入了一种新的量化方法，其中每个社区都有一个紧密连接的部分（核心），其余部分更稀疏（边缘），边缘之间的社区间边缘更频繁。
基于此结构，我们提出了一种新的算法概念，我们称之为相对中心性来检测核心。我们观察到，基于流行的中心性度量（例如 PageRank 和度中心性）的核心检测算法会通过从某些核心中选择极少的顶点而在其结果中表现出一些偏差。我们表明，相对中心性解决了这个偏差问题，并提供了理论和模拟支持，以及对真实世界图形的实验。
众所周知，核心检测在核心-外围结构方面具有重要的应用。在我们的模型中，我们展示了一个新的应用：基于相对中心性的算法可以选择顶点的子集，使得它包含来自所有社区的足够顶点，并且该子集中的点可以更好地分离到各自的社区中。我们将这些方法应用于 11 个生物数据集，我们的方法可以更平衡地从所有社区中选择顶点，从而使聚类算法在这个集合上具有更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.04487</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:25 GMT</pubDate>
    </item>
    <item>
      <title>当噪声重尾时，梯度裁剪可以改善 AdaGrad</title>
      <link>https://arxiv.org/abs/2406.04443</link>
      <description><![CDATA[arXiv:2406.04443v1 公告类型：新
摘要：具有自适应步长的方法（例如 AdaGrad 和 Adam）对于训练现代深度学习模型（尤其是大型语言模型）至关重要。通常，随机梯度中的噪声对于后者来说是重尾的。梯度剪裁可证明有助于实现此类噪声的良好高概率收敛。然而，尽管 AdaGrad/Adam 与 Clip-SGD 相似，但在这种情况下尚未研究 AdaGrad/Adam 的高概率收敛。在这项工作中，我们证明，如果噪声是重尾的，AdaGrad（及其延迟版本）可以具有可证明的糟糕高概率收敛。为了解决这个问题，我们提出了一个新版本的 AdaGrad，称为 Clip-RAdaGradD（带延迟的裁剪重加权 AdaGrad），并证明了其高概率收敛界限，对具有重尾噪声的平滑凸/非凸随机优化具有多对数依赖性。我们的实证评估（包括 NLP 模型微调）突出了裁剪版本的 AdaGrad/Adam 在处理重尾噪声方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2406.04443</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:24 GMT</pubDate>
    </item>
    <item>
      <title>语言模型可以使用预测策略吗？</title>
      <link>https://arxiv.org/abs/2406.04446</link>
      <description><![CDATA[arXiv:2406.04446v1 公告类型：新
摘要：深度学习系统的进步使得大型模型能够在图像分类、基本编程和标准化考试等多项技能上达到或超过人类的准确度。随着最有能力的模型在人类已经达到高精度的任务上的性能开始饱和，有必要对模型进行越来越复杂的能力的基准测试。其中一项任务是预测事件的未来结果。在这项工作中，我们描述了使用现实世界事件和相关人类预测的新数据集、衡量预测能力的评估指标以及提供的数据集上许多不同的基于 LLM 的预测设计的准确性的实验。此外，我们分析了 LLM 预测器与人类预测的表现，发现模型仍然难以对未来做出准确的预测。我们的后续实验表明，这可能是由于模型倾向于猜测大多数事件不太可能发生（这对于许多预测数据集来说往往是正确的，但并不反映实际的预测能力）。我们思考下一步该如何开发一种系统而可靠的方法来研究 LLM 预测。]]></description>
      <guid>https://arxiv.org/abs/2406.04446</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:24 GMT</pubDate>
    </item>
    <item>
      <title>论概率神经符号学习的难度</title>
      <link>https://arxiv.org/abs/2406.04472</link>
      <description><![CDATA[arXiv:2406.04472v1 公告类型：新
摘要：纯神经学习的局限性引发了人们对概率神经符号模型的兴趣，该模型将神经网络与概率逻辑推理相结合。由于这些神经符号模型是用梯度下降训练的，我们研究了区分概率推理的复杂性。我们证明，虽然近似这些梯度一般是难以处理的，但在训练过程中变得容易处理。此外，我们引入了基于模型采样的无偏梯度估计器 WeightME。在温和的假设下，WeightME 使用对 SAT 求解器的对数调用次数以概率保证近似梯度。最后，我们评估了这些保证对梯度的必要性。我们的实验表明，即使精确求解仍然可行，现有的有偏近似确实难以优化。]]></description>
      <guid>https://arxiv.org/abs/2406.04472</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:24 GMT</pubDate>
    </item>
    <item>
      <title>通过自动编码器和随机森林近似度增强监督可视化以实现样本外扩展</title>
      <link>https://arxiv.org/abs/2406.04421</link>
      <description><![CDATA[arXiv:2406.04421v1 公告类型：新
摘要：监督降维的价值在于它能够发现数据特征和标签之间的有意义的联系。常见的降维方法嵌入了一组固定的潜在点，但无法推广到看不见的测试集。在本文中，我们为基于随机森林的监督降维方法 RF-PHATE 提供了一种样本外扩展方法，该方法将从随机森林模型中学习到的信息与自动编码器的函数学习能力相结合。通过对各种自动编码器架构的定量评估，我们发现重建随机森林邻近度的网络对于嵌入扩展问题更为稳健。此外，通过利用基于邻近度的原型，我们在不影响扩展质量的情况下将训练时间缩短了 40%。我们的方法不需要样本外点的标签信息，因此可以用作半监督方法，并且仅使用 10% 的训练数据即可实现一致的质量。]]></description>
      <guid>https://arxiv.org/abs/2406.04421</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:23 GMT</pubDate>
    </item>
    <item>
      <title>通过早期停止最小二乘回归进行正则化</title>
      <link>https://arxiv.org/abs/2406.04425</link>
      <description><![CDATA[arXiv:2406.04425v1 公告类型：新
摘要：机器学习中的一个基本问题是理解早期停止对获得的参数和模型泛化能力的影响。即使对于线性模型，对于任意学习率和数据的影响也没有完全理解。在本文中，我们分析了线性回归的离散全批量梯度下降的动态。在最少的假设下，我们描述了参数的轨迹和预期的超额风险。利用这种表征，我们表明，当使用学习率计划$ \ eta_k $和有限时间范围$ T $进行训练时，早期停止的解$ \ beta_T $相当于广义岭正则化问题的最小范数解。我们还证明，早期停止对具有任意频谱的通用数据和各种学习率计划都是有益的。我们提供了最佳停止时间的估计，并通过经验证明了我们估计的准确性。]]></description>
      <guid>https://arxiv.org/abs/2406.04425</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么预测大规模前沿人工智能模型的下游能力仍然难以实现？</title>
      <link>https://arxiv.org/abs/2406.04391</link>
      <description><![CDATA[arXiv:2406.04391v1 公告类型：新
摘要：扩展高级 AI 系统可预测的行为是一种非常理想的特性。尽管关于预训练性能如何扩展的文献已经很完善，但关于特定下游能力如何扩展的文献则显得模糊不清。在这项工作中，我们退一步问自己：为什么预测具有规模的特定下游能力仍然难以捉摸？虽然肯定有许多因素是造成这种情况的原因，但我们发现了一个新因素，该因素使得在广泛使用的多项选择问答基准上建模扩展行为具有挑战性。使用五个模型系列和十二个完善的多项选择基准，我们表明下游性能是通过一系列转换从负对数似然计算出来的，这些转换会逐步降低性能和规模之间的统计关系。然后，我们揭示了导致这种退化的机制：下游指标需要将正确的选择与少数特定的错误选择进行比较，这意味着准确预测下游能力不仅需要预测概率质量如何集中在具有规模的正确选择上，还需要预测概率质量如何随着规模的特定错误选择而波动。我们通过实证研究了随着计算量的增加，正确选择的概率质量与错误选择的概率质量如何共同变化，这表明错误选择的缩放定律可能是可以实现的。我们的工作还解释了为什么预训练缩放定律通常被认为比下游能力更可预测，并有助于建立前沿人工智能模型的可缩放预测评估。]]></description>
      <guid>https://arxiv.org/abs/2406.04391</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:22 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与自生成的偏好数据对齐</title>
      <link>https://arxiv.org/abs/2406.04412</link>
      <description><![CDATA[arXiv:2406.04412v1 公告类型：新
摘要：将大型语言模型 (LLM) 与人类偏好对齐成为获得最先进性能的关键要素，但构建大型人工注释偏好数据集的成本巨大。为了解决这个问题，我们提出了一个新框架，该框架仅使用极少量的人工注释偏好数据，通过自生成偏好数据 (Selfie) 来增强 LLM 的对齐。我们的主要思想是利用小型（种子）数据中的人类先验知识，通过迭代生成响应并使用自注释偏好数据从中学习，逐步改善 LLM 的对齐。具体来说，我们建议从 LLM 的 logits 中得出偏好标签，以明确提取模型的固有偏好。与以前使用外部奖励模型或隐式上下文学习的方法相比，我们观察到所提出的方法明显更有效。此外，我们引入了一种噪声感知偏好学习算法，以降低生成的偏好数据质量低下的风险。我们的实验结果表明，所提出的框架显著提高了 LLM 的对齐效果。例如，与使用整个数据或最先进基线的情况相比，我们在 Ultrafeedback 数据中仅使用 3.3% 的真实偏好标签，就实现了 AlpacaEval 2.0 上的出色对齐性能。]]></description>
      <guid>https://arxiv.org/abs/2406.04412</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:22 GMT</pubDate>
    </item>
    <item>
      <title>TSCMamba：Mamba 与多视图学习相结合，实现时间序列分类</title>
      <link>https://arxiv.org/abs/2406.04419</link>
      <description><![CDATA[arXiv:2406.04419v1 公告类型：新
摘要：多变量时间序列上的时间序列分类 (TSC) 是一个关键问题。我们提出了一种新颖的多视图方法，该方法集成了频域和时域特征，为 TSC 提供互补上下文。我们的方法将连续小波变换频谱特征与时间卷积或多层感知器特征融合在一起。我们利用 Mamba 状态空间模型进行高效且可扩展的序列建模。我们还引入了一种新颖的探戈扫描方案来更好地模拟序列关系。在 10 个标准基准数据集上进行的实验表明，我们的方法比最先进的 TSC 模型平均准确率提高了 6.45%。]]></description>
      <guid>https://arxiv.org/abs/2406.04419</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:22 GMT</pubDate>
    </item>
    </channel>
</rss>