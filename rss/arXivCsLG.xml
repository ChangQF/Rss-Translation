<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>对抗机器学习：攻击和保护图像数据集</title>
      <link>https://arxiv.org/abs/2502.05203</link>
      <description><![CDATA[ARXIV：2502.05203V1公告类型：新 
摘要：本文研究了卷积神经网络（CNN）对对抗性攻击的脆弱性，并探讨了一种保护其保护的方法。在这项研究中，CNN是在四个最常见的图像数据集上实施的，即CIFAR-10，Imagenet，Mnist和Fashion-Mnist，并达到了高基线准确性。为了评估这些模型的强度，使用了快速梯度符号方法，这是模型上的一种利用，用于通过在输入图像中添加极少的扰动来降低模型精度。为了应对FGSM攻击，采用了一种保护方法，其中包括在清晰，污染物或对抗图像上重新训练模型以提高其阻力能力。下一步涉及再次应用FGSM，但是这次是对对抗训练的模型，以了解模型的准确性已经下降并评估防御的有效性。看来，尽管在对抗训练后，对模型实现了大多数鲁棒性，但这些模型的性能仍有一些损失对抗扰动。这项工作强调了为在现实情况下针对对手而部署的模型创造更好的防御能力的必要性。]]></description>
      <guid>https://arxiv.org/abs/2502.05203</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多样本推理优化语言模型的温度</title>
      <link>https://arxiv.org/abs/2502.05234</link>
      <description><![CDATA[ARXIV：2502.05234V1公告类型：新 
摘要：多样本聚合策略，例如多数投票和最佳N采样，广泛用于当代大语模型（LLMS），以提高各种任务的预测准确性。此过程中的一个关键挑战是温度选择，这显着影响模型性能。现有方法要么依赖固定的默认温度，要么需要标记的验证数据进行调整，这些验证数据通常很少且难以获得。本文解决了使用多样本聚合策略自动识别不同LLM的（近）最佳温度的挑战，而无需依赖特定于任务的验证数据。我们考虑了温度在性能优化中的作用的全面分析，考虑了模型体系结构，数据集，任务类型，模型大小和预测精度的变化。此外，我们提出了一种基于新型的基于熵的度量，用于自动温度优化，该指标始终优于固定温度的基线。此外，我们合并了一个随机过程模型，以增强可解释性，从而更深入了解温度和模型性能之间的关系。]]></description>
      <guid>https://arxiv.org/abs/2502.05234</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合学习体系结构的原理和组成部分</title>
      <link>https://arxiv.org/abs/2502.05273</link>
      <description><![CDATA[ARXIV：2502.05273V1公告类型：新 
摘要：联合学习，也称为FL，是一个机器学习框架，其中大量客户（例如移动设备或整个企业）协作以协作培训模型，同时由中央服务器监督分散的培训数据（例如服务提供商）。这种分散的模型培训方法在隐私，安全，法规和经济方面具有优势。尽管似乎有希望，但佛罗里达州并不涉及瘟疫常规机器学习模型的缺陷。这项研究对联合学习体系结构的基本思想和要素进行了详尽的分析，强调了五个重要领域：通信体系结构，机器学习模型，数据分配，隐私方法和系统异质性。我们还解决了该地区未来研究的困难和潜在途径。此外，根据对文献的全面综述，我们为联合学习系统提供了一系列建筑模式。该分析将有助于了解联邦学习的基本，FL的主要组成部分以及几个架构细节。]]></description>
      <guid>https://arxiv.org/abs/2502.05273</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Rashomon集中的公平和稀疏性：无枚举的探索和特征</title>
      <link>https://arxiv.org/abs/2502.05286</link>
      <description><![CDATA[ARXIV：2502.05286V1公告类型：新 
摘要：我们引入了一种基于数学编程的无枚举方法，以精确表征“良好模型”集合中的各种属性，例如公平或稀疏性，称为Rashomon集合。这种方法通常适用于任何假设类别，只要存在模型学习任务的数学表述。它提供了一个结构化的框架来定义业务必要性的概念，并评估如何改善公平或向特定的保护群体降级，同时保留在Rashomon集合中并保持任何所需的稀疏水平。
  我们将方法应用于两个假设类别：评分系统和决策图，利用最近的数学编程公式用于培训此类模型。从我们的实验中可以看出，该方法可以全面和认证地量化预测性能，稀疏性和公平性之间的权衡。我们观察到，可以实现广泛的公平价值，范围从非常有利的到受保护的群体显着不利，同时停留在假设类别的最佳培训准确性的不到1％之内。此外，我们观察到稀疏性约束限制了这些权衡，可能会损害特定的亚组。正如我们所证明的那样，彻底表征这些关键方面之间的紧张关系对于知情和负责的模型选择至关重要。]]></description>
      <guid>https://arxiv.org/abs/2502.05286</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GST-UNET：时空因果关系推断与时变混杂因素</title>
      <link>https://arxiv.org/abs/2502.05295</link>
      <description><![CDATA[ARXIV：2502.05295V1公告类型：新 
摘要：从时空数据中估算因果关系是公共卫生，社会政策和环境科学等领域的关键挑战，在该领域中，受控实验通常是不可行的。但是，依赖观察数据的现有因果推理方法面临重大局限性：它们取决于强大的结构假设来应对时空挑战$ \ unicode {x2013} $，例如干扰，空间混淆和时间携带和时间遗留效果$ \ unicode $ \ unicode {x2013} $ {x2013} $ {x2013} $ {x2013} $ {x2013} $ {x2013} $ {x2013} $无法解释$ \ textit {时变混杂器} $。这些混杂因素受过去的治疗和结果影响，可以自己塑造未来的治疗方法和结果，从而创造出使传统调整策略复杂化的反馈循环。为了应对这些挑战，我们介绍$ \ textbf {gst-unet} $（$ \ textbf {g} $  -  cumputation $ \ textbf {s} $ patio- $ \ textbf {t} $），一种新型的端到端神经网络框架，旨在估计复杂的空间和时间环境中的治疗效果。 GST-UNET利用基于回归的迭代G-Compuntion来明确调整时间变化的混杂因素，从而对潜在的结果和治疗效果提供有效的估计。据我们所知，GST-UNET是第一个说明时空干预中复杂，非线性动力学和时变混杂因素的神经模型。我们通过广泛的模拟研究来证明GST-UNET的有效性，并通过对2018年加利福尼亚营地大火期间野火烟雾对呼吸道住院的影响进行现实分析，以展示其实用性。我们的结果突出了GST-UNET在广泛的政策驱动和科学应用中推进时空因果的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.05295</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数对称性破坏和恢复确定AI系统中的分层学习</title>
      <link>https://arxiv.org/abs/2502.05300</link>
      <description><![CDATA[ARXIV：2502.05300V1公告类型：新 
摘要：现代大型AI系统中的学习动力学是分层的，通常以突然的特征，定性转移类似于物理系统中观察到的相变。尽管这些现象有望揭示神经网络和语言模型背后的机制，但现有理论仍然分散，解决了具体情况。在本文中，我们认为参数对称性破坏和恢复是这些行为的统一机制。我们综合了先前的观察结果，并展示了这种机制如何解释神经网络中的三个不同的层次结构：学习动力学，模型复杂性和表示形成。通过连接这些层次结构，我们重点介绍了对称性 - 理论物理的基石 - 是现代AI中的潜在基本原理。]]></description>
      <guid>https://arxiv.org/abs/2502.05300</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多代理系统的高斯流程的分散在线合奏</title>
      <link>https://arxiv.org/abs/2502.05301</link>
      <description><![CDATA[ARXIV：2502.05301V1公告类型：新 
摘要：灵活且可扩展的分散学习解决方案在多代理系统的应用中至关重要。虽然最近在分布式设置中引入了内核机器（集合）的几种方法，但贝叶斯解决方案受到更大的限制。我们引入了一个完全分散的，渐近的精确解决方案，以计算高斯过程的随机特征近似。我们通过引入基于在线贝叶斯模型平均的贝叶斯多个内核学习的结合方案来进一步解决超参数的选择。在模拟和现实世界数据集上针对贝叶斯和频繁的方法测试了所得算法。]]></description>
      <guid>https://arxiv.org/abs/2502.05301</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>培训设置的重建来自差异私人森林：DP的效果如何？</title>
      <link>https://arxiv.org/abs/2502.05307</link>
      <description><![CDATA[ARXIV：2502.05307V1公告类型：新 
摘要：最近的研究表明，机器学习模型容易受到针对其培训数据的隐私攻击。差异隐私（DP）已成为一种广泛采用的对策，因为它提供了严格的隐私保护。
  在本文中，我们引入了针对最先进的$ \ varepsilon $ -DP随机森林的重建攻击。通过利用一种结合森林结构和DP机制特征知识的约束编程模型，我们的方法正式重建了可能产生给定森林的最可能的数据集。
  通过广泛的计算实验，我们研究了模型效用，隐私保证和各种配置之间的重建精度之间的相互作用。我们的结果表明，接受有意义的DP保证训练的随机森林仍然可以泄漏大量培训数据。具体而言，尽管DP降低了重建攻击的成功，但唯一对我们攻击的森林完全强大的展示了预测性能，却不比恒定分类器更好。在这些见解的基础上，我们为建造DP随机森林提供了实用的建议，这些森林对重建攻击更具弹性并保持非平凡的预测性能。]]></description>
      <guid>https://arxiv.org/abs/2502.05307</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于AI/ML的自动调制识别：最新趋势和未来可能性</title>
      <link>https://arxiv.org/abs/2502.05315</link>
      <description><![CDATA[ARXIV：2502.05315V1公告类型：新 
摘要：我们介绍了文献中提出的高性能自动调制识别（AMR）模型的评论，以对各种射频（RF）调制方案进行分类。我们复制了这些模型，并比较了它们在一定范围的信噪比中的准确性方面的性能。为了确保进行公平的比较，我们使用了相同的数据集（Radioml-2016a），相同的硬件以及测试准确性的一致定义与评估指标，从而为未来的AMR研究提供了基准。根据作者在关联的参考文献中的建议选择超参数，以尽可能接近原件。复制的模型可公开访问以进一步分析AMR模型。我们还介绍了所选模型的测试精度与它们的参数数量，表明其复杂性。在此比较分析的基础上，我们确定了增强这些模型性能的策略。最后，我们提供了改进的潜在机会，无论是通过新颖的架构，数据处理技术还是培训策略，以进一步提高AMR模型的功能。]]></description>
      <guid>https://arxiv.org/abs/2502.05315</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多电子Schr \“ Odinger方程的神经网络求解器的对角线对称性</title>
      <link>https://arxiv.org/abs/2502.05318</link>
      <description><![CDATA[ARXIV：2502.05318V1公告类型：新 
摘要：将群体对称性纳入神经网络一直是许多AI科学应用程序成功的基石。异构体的对角线组描述了多个物体同时运动下的不变性，自然出现在多体量子问题中。尽管它们的重要性很重要，但对角群体的关注很少，因为除了特殊情况外，它们缺乏自然的不变地图选择。我们研究了通过变异蒙特卡洛方法训练的神经网络中纳入对角线不变性的不同方法，并考虑了专门的数据增强，组平均和规范化。我们表明，与标准的ML设置相反，与标准的ML设置相反，对训练的训练和培训训练和培训和对称性可以导致我们的理论和数值结果更糟糕，表明这种意外的行为可能是由于在对称性的标准ML分析中未发现的独特计算统计折衷。作为改善神经网络求解器的简单，灵活和有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.05318</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在喷气发动机的预测维护中使用联合机器学习</title>
      <link>https://arxiv.org/abs/2502.05321</link>
      <description><![CDATA[ARXIV：2502.05321V1公告类型：新 
摘要：本文的目的是使用联合机器学习框架预测涡轮喷气发动机的剩余使用寿命（RUL）。联合学习使多个边缘设备/节点或服务器能够在不共享敏感数据的情况下协作训练共享模型，从而保留数据隐私和安全性。通过实施非线性模型，该系统旨在捕获发动机数据中的复杂关系和模式，以增强RUL预测的准确性。这种方法利用分散的计算，可以在每个设备上本地培训模型，然后再在中央服务器上汇总学习的权重。通过准确地预测喷气发动机的RUR，可以优化维护时间表，减少停机时间并提高运营效率，最终导致节省成本并提高航空业的性能。使用C-MAPSS数据集提供了计算结果，该数据集可在NASA网站上公开可用，并且是在各种操作方案中研究和分析引擎退化行为的宝贵资源。]]></description>
      <guid>https://arxiv.org/abs/2502.05321</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从反事实到树木：模型提取攻击的竞争分析</title>
      <link>https://arxiv.org/abs/2502.05325</link>
      <description><![CDATA[ARXIV：2502.05325V1公告类型：新 
摘要：机器学习作为服务的出现（MLAA）加强了模型解释性和安全性之间的权衡。特别是，解释性技术（例如反事实解释）无意中增加了模型提取攻击的风险，从而实现了专有模型的未经授权复制。在本文中，我们将模型重建的风险和固有复杂性形式化，重点关注忠实推断基本预测功能所需的“ Oracle”查询。我们通过竞争性分析的镜头进行了对模型提取攻击的首次正式分析，建立一个基础框架来评估其效率。我们基于添加性决策树（例如，决策树，梯度增强和随机森林），我们介绍了新颖的重建算法，这些算法可以实现可证明的完美忠诚度，同时表现出任何时间的表现为提取基于树的模型的查询复杂性提供了理论界限，从而提供了有关其部署安全漏洞的新见解。]]></description>
      <guid>https://arxiv.org/abs/2502.05325</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用自动编码器靶向对抗变压器（AT-AT）删除神经信号伪影（AT-AT）</title>
      <link>https://arxiv.org/abs/2502.05332</link>
      <description><![CDATA[ARXIV：2502.05332V1公告类型：新 
摘要：肌电（EMG）噪声是脑电图数据中的主要污染源，可以阻碍对大脑特异性神经活动的准确分析。有关EMG伪影的最新文献已超越了传统的线性算法，而支持基于机器学习的系统。但是，现有的基于深度学习的过滤方法通常具有较大的计算足迹和过长的训练时间。在这项研究中，我们提出了一种新的基于机器学习的系统，用于使用针对自动编码器的对抗变压器（AT-AT）过滤EEG数据的EMG干扰。通过利用自动编码器的轻量级表现性来确定最佳的时间序列变压器应用站点，与已发布的人工删除模型相比，我们的AT-AT体系结构可实现&gt; 90％的模型尺寸降低。对抗性训练的增加可确保过滤信号遵守脑电图数据的基本特征。我们使用来自67名受试者的已发表的神经数据培训了AT-AT，发现该系统能够实现与较大模型的可比测试性能。 AT-AT以2 dB的初始信号噪声比（SNR）的平均重建相关系数高于0.95，在-7 dB snr时为0.70。进一步的研究将这些结果推广到除这些孤立的测试案例以外的更广泛的样本量至关重要的情况下至关重要。在本研究范围之外，我们还包括附录中AT-AT的现实部署的结果。]]></description>
      <guid>https://arxiv.org/abs/2502.05332</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EEG信号上的几何机器学习</title>
      <link>https://arxiv.org/abs/2502.05334</link>
      <description><![CDATA[ARXIV：2502.05334V1公告类型：新 
摘要：大脑计算机界面（BCIS）具有变革性的潜力，但解码神经信号带来了重大挑战。本文的核心前提是围绕展示高维脑电波数据中存在的基本低维几何结构的方法来建立的，以帮助下游BCI与BCI相关的神经分类任务。我们演示了两个与脑电图（EEG）信号处理相关的管道：（1）初步管道从单个脑电图通道中删除噪声，以及（2）下游歧管学习管道在EEG通道网络中揭示几何结构。我们使用两个EEG数据集进行初步验证，并在与BCI相关的想象数字解码问题的背景下进行演示。我们的初步管道使用基于注意力的EEG过滤网络从单个脑电图通道中提取清洁信号。我们的主要管道使用快速的傅立叶变换，拉普拉斯（Laplacian eigenmap），通过Ollivier的RICCI曲率概念对RICCI流动的离散类似物以及图形卷积网络，以降低尺寸，以降低高维的多频道EEG EEG数据分类。我们的系统通过现有的信号处理和分类基准实现竞争性能；我们证明，在半合成神经denoising上，在2 dB时的平均测试相关系数&gt; 0.95&gt; 0.95，并且在区分数字和非数字思想方面，基于脑电图的下游分类精度为0.97。结果是初步的，我们的几何机器学习管道应通过更广泛的随访研究来验证；将这些结果推广到较大的受试者间样本量，不同的硬件系统和更广泛的用例将是至关重要的。]]></description>
      <guid>https://arxiv.org/abs/2502.05334</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向动态系统重建的基础模型：通过专家的混合物进行分层元学习</title>
      <link>https://arxiv.org/abs/2502.05335</link>
      <description><![CDATA[ARXIV：2502.05335V1公告类型：新 
摘要：随着基础模型的重塑科学发现，动态系统重建（DSR）的瓶颈持续存在：跨系统层次结构学习的能力。许多元学习方法已成功地应用于单个系统，但是在面对稀疏，松散相关的数据集时步履蹒跚，需要学习多个层次结构。专家（MOE）的混合物提供了一种自然的范式来应对这些挑战。尽管它们具有潜力，但我们证明了天真的Moes对层次DSR的细微差别需求不足，这在很大程度上是由于它们基于梯度下降的控球更新机制，从而导致更新缓慢并在培训过程中进行冲突。为了克服这一限制，我们介绍了混音器：专家重建器的混合物，专家重建器的混合物是一种基于$ k $  - 英镑和最小二乘的自定义门控更新算法的新颖稀疏顶部1 MOE层。广泛的实验验证了混合器的功能，证明了对多达十个参数的普通微分方程系统的有效训练和可伸缩性。但是，我们的一层表现不佳，在高数据制度中，最先进的元学习者，尤其是当每个专家都被限制以仅处理由高度相关数据点组成的数据集的一小部分时。对合成和神经科学时间序列的进一步分析表明，混合器产生的上下文表示的质量与数据中的层次结构的存在紧密相关。]]></description>
      <guid>https://arxiv.org/abs/2502.05335</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>