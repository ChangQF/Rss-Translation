<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Wed, 26 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>关于结构化状态空间序列（S4）模型的调查</title>
      <link>https://arxiv.org/abs/2503.18970</link>
      <description><![CDATA[ARXIV：2503.18970V1公告类型：新 
摘要：序列建模的最新进展导致结构化状态空间模型（SSM）的出现，作为复发神经网络（RNN）和变形金刚的有效替代方案，解决了长期依赖模型和计算效率的挑战。尽管RNN遭受了消失的梯度和顺序效率低下的影响，而变形金刚则面临二次复杂性，但SSMS利用结构性复发和状态空间表示，以线性或接近线性的复杂性实现出色的长期处理。这项调查提供了对SSM的全面审查，将其从基础S4模型转变为诸如Mamba，简化结构化状态空间序列模型（S5）和JAMBA之类的继任者，并突出了它们在计算效率，内存优化和推理速度方面的改善。通过将SSM与跨域之间的传统序列模型进行比较，例如自然语言处理（NLP），语音识别，视觉和时间序列预测，我们证明了它们在处理长期依赖性时的优势，同时减少了计算范围。尽管它们具有潜力，但仍在培训优化，混合建模和解释性等领域仍存在挑战。这项调查是研究人员和从业人员的结构化指南，详细介绍了AI和深度学习中基于SSM的建筑的进步，权衡以及未来的方向。]]></description>
      <guid>https://arxiv.org/abs/2503.18970</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FEDSKD：使用多维相似性知识蒸馏</title>
      <link>https://arxiv.org/abs/2503.18981</link>
      <description><![CDATA[ARXIV：2503.18981V1公告类型：新 
摘要：联合学习（FL）可实现隐私的协作模型培训，而无需直接数据共享。模型异构FL（MHFL）通过允许客户培训针对其计算资源和针对应用特定需求的异质体系结构来训练个性化模型，从而扩展了此范式。但是，现有的MHFL方法主要依赖于集中式聚合，该聚合引入了可扩展性和效率瓶颈，或施加限制，需要跨客户范围内部分相同的模型体系结构。当点对点（P2P）FL删除了服务器依赖性，但它遭受了模型漂移和知识稀释的影响，从而限制了其在异质设置中的有效性。为了应对这些挑战，我们提出了FedSKD，这是一个新型的MHFL框架，通过圆形旋转模型循环促进直接知识交流，从而消除了对集中式聚合的需求，同时允许跨客户跨越完全异构的模型架构。 FEDSKD的关键创新在于多维相似性知识蒸馏，这使得在FL中的异质模型的批处理，像素/体素，像素/体素和区域水平上实现了双向跨晶体知识转移。这种方法减轻了灾难性的遗忘，模型通过渐进式增强和分布对准，同时保留模型异质性。对基于功能磁共振成像的自闭症谱系障碍诊断和皮肤病变分类的广泛评估表明，FEDSKD的表现优于最先进的异质和同质FL基准，从而实现了卓越的个性化（客户特异性准确性）和普遍性（跨机构适应性）。这些发现强调了FedSkd作为现实世界联邦学习应用程序的可扩展和强大解决方案的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.18981</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用生成对抗归因网络稀疏学习者绩效数据的生成数据插补</title>
      <link>https://arxiv.org/abs/2503.18982</link>
      <description><![CDATA[ARXIV：2503.18982V1公告类型：新 
摘要：智能辅导系统（ITS）收集的学习者绩效数据，例如对问题的回答，对于建模和预测学习者知识状态至关重要。但是，由于跳过或不完整的尝试而缺少响应会产生数据稀疏性，挑战准确的评估和个性化的指导。为了解决这个问题，我们提出了一种使用生成的对抗归合网络（增益）的生成插补方法。我们的方法具有三维（3D）框架（学习者，问题和尝试），灵活地适应各种稀疏水平。通过卷积神经网络增强，并通过最小二乘损失函数进行了优化，基于增益的方法将输入和输出维度与学习者尺寸沿问答矩阵保持一致。使用来自自动化的成人阅读理解（ARC），辅助和MATHIA的数据集进行的广泛实验表明，我们的方法在不同尝试方案中的归纳精度极高地超过了张力分解和替代GAN方法。贝叶斯知识追踪（BKT）通过估计学习参数进一步验证了估计数据的有效性：初始知识（P（l0）），学习率（P（t）），猜测率（P（g））和滑移率（P（p（s））。结果表明，估算的数据增强了模型拟合，并密切反映了原始分布，从而可靠地捕获了潜在的学习行为。 Kullback-Leibler（KL）差异评估证实了最小的差异，显示了估算的数据可有效地保留基本学习特征。这些发现强调了收益作为ITS中强大的归纳工具的能力，减轻了数据稀疏性并支持适应性的，个性化的教学，最终导致了更精确，更敏感的学习者评估和改善的教育成果。]]></description>
      <guid>https://arxiv.org/abs/2503.18982</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>洛拉（Lora</title>
      <link>https://arxiv.org/abs/2503.18985</link>
      <description><![CDATA[ARXIV：2503.18985V1公告类型：新 
摘要：在持续学习（CL）中，由于特征漂移而经常出现灾难性遗忘。这一挑战在无示例性持续学习（EFCL）设置中尤为突出，在这种设置中，无法保留以前任务的样本，因此很难保留先验知识。为了解决这个问题，一些EFCL方法旨在识别特征空间，以最大程度地减少对先前任务的影响，同时容纳新任务。但是，它们依赖于静态特征或过时的统计数据，从旧任务中存储，这阻止了它们在CL中捕获功能空间的动态演变，从而导致性能随着时间的推移而降解。在本文中，我们介绍了防漂移空间（DRS），该空间有效地处理特征漂移而无需明确的功能建模或先前任务的存储。提出了一种新型的参数效率微调方法，称为低级适应减法（Lora-）来发展DRS。在处理新任务数据之前，该方法从初始预训练的权重中减去旧任务的洛拉权重以建立用于模型培训的DR。因此，洛拉（Lora）增强了稳定性，提高效率并简化实施。此外，稳定功能漂移可以通过三胞胎损失学习来更好地可塑性。我们的方法一致地取得了最新的结果，尤其是对于长达多个数据集的长任务序列而言。]]></description>
      <guid>https://arxiv.org/abs/2503.18985</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SplitFrozen：用设备端模型的分裂学习冻结在异构资源约束设备上的微调LLM</title>
      <link>https://arxiv.org/abs/2503.18986</link>
      <description><![CDATA[ARXIV：2503.18986V1公告类型：新 
摘要：私人，设备数据上的大型语言模型（LLM）可以增强量身定制的个性化AI代理。但是，在资源受限的边缘设备上进行微调LLM面临重大挑战，包括过度的计算开销，设备异质性和数据失衡。本文提出了SplitFrozen，这是一个分裂学习框架，通过战略性地冻结设备端模型层，同时将参数有效的微调在服务器上进行策略性冻结，从而实现有效的LLM微调。我们的框架将LLMS分配到设备侧冷冻层和服务器端微调层中，其中异质资源受限的设备仅执行正向传播。为了最大程度地减少服务器端培训成本，我们将低级适应（LORA）集成到服务器端层中。管道并行性策略通过将设备服务器计算取消并利用分解后的传播来进一步优化训练效率。在GPT-2上使用MRPC进行了MNLI匹配和SST-2数据集的实验表明，在极不平衡的数据下，SplitFrozen的表现优于Fedlora和Splitlora的69.4 \％模型精度，而最多减少了86.8 \％的设备侧计算以及50.2 \％的总培训时间。实验还使用GSM8K数据集上的Llama-3.2模型验证了在内容生成任务上拆分的可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2503.18986</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>来自多种选择的平衡方向：领域概括的算术元学习</title>
      <link>https://arxiv.org/abs/2503.18987</link>
      <description><![CDATA[ARXIV：2503.18987V1公告类型：新 
摘要：提出了域的概括来解决分布转移，这是由于训练源和看不见的目标域之间的统计差异而引起的。广泛使用的一阶元学习算法通过利用梯度匹配理论来证明域概括的强劲性能，该理论旨在在跨源域中建立平衡的参数，以减少对任何特定域的过度拟合。但是，我们的分析表明，实际上有许多方向可以实现梯度匹配，而当前的方法仅代表一个可能的路径。这些方法实际上忽略了一个关键因素，即平衡参数应接近每个源域的最佳参数的质心。为了解决这个问题，我们提出了一种简单而有效的算术元学习，并使用算术加权梯度。这种方法虽然遵守梯度匹配的原理，但通过估计域特异性最佳参数之间的质心来促进更精确的平衡。实验结果证明了我们策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.18987</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的新型帽子形设备云云协作框架</title>
      <link>https://arxiv.org/abs/2503.18989</link>
      <description><![CDATA[ARXIV：2503.18989V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展已促进了对LLM服务的需求激增。尽管传统的基于云的LLM服务满足了高精度要求，但它们在满足对低延迟和增强隐私的关键需求方面缺乏。为了解决这些限制，我们提出了HAT，这是一种新型的设备云协作推理框架，利用U形推理和投机解码的互补优势。 HAT将LLM划分为三个子模型，并且用轻量级适配器网络堆叠的输入和输出子模型将在每个端设备上部署为小语言模型（SLM）。同时，中间的子模型包括大多数LLM的解码器层，托管在云中以使用设备上的SLM进行投机解码。在推理期间，HAT交换了设备和云之间的输入或草稿令牌隐藏的状态（而不是原始令牌），从而产生了实质性的通信延迟。此外，处理长提示的隐藏状态将加剧云中的计算延迟，从而进一步损害推理效率。为了提高效率，我们引入了一种迅速的结构机制，该机制长时间促使块较短，从而实现并行的传输和处理。此外，实施HAT是为了动态确定处理较长提示的设备的最佳块尺寸，从而提高了整体推理速度。在包括30个NVIDIA JETSON设备的物理测试床上进行了广泛的实验，并具有8个NVIDIA A6000 GPU的服务器。实验结果表明，与基线相比，HAT可实现有希望的性能提高，将TTFT降低41％至54％，TBT降低41％至77％。]]></description>
      <guid>https://arxiv.org/abs/2503.18989</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用先进的机器学习技术和过采样方法对脊柱手术结果的预测增强</title>
      <link>https://arxiv.org/abs/2503.18996</link>
      <description><![CDATA[ARXIV：2503.18996V1公告类型：新 
摘要：该研究提出了一种先进的机器学习方法，以通过合并过度采样技术和网格搜索优化来预测脊柱手术结果。在244名患者的数据集上测试了包括GaussiannB，ReplementNB，KNN，决策树以及优化版本在内的各种模型，其中包括手术前，心理测量，社会经济经济和分析变量。增强的KNN型号的精度最高为76％和67％的F1得分，而网格搜索优化进一步提高了性能。这些发现强调了这些先进技术在决策中有助于医疗保健专业人员的潜力，未来的研究需要将这些模型改进大型，更多样化的数据集。]]></description>
      <guid>https://arxiv.org/abs/2503.18996</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>近乎最佳的主动重建</title>
      <link>https://arxiv.org/abs/2503.18999</link>
      <description><![CDATA[ARXIV：2503.18999V1公告类型：新 
摘要：随着对自主系统的基于视觉的任务的实际兴趣越来越大，对高效和复杂方法的需求越来越大。在急于开发新的方法以胜过现有的最新方法时，对基本理论的分析通常被忽略，并简单地被模拟或现实世界实验中的经验评估所取代。尽管这种方法在实践中可能会产生有利的表现，但它们通常不太了解它们，从而阻止它们被应用于安全至关重要的系统中。这项工作的目的是在主动对象重建的背景下为下一个最佳视图（NBV）问题设计算法，为此，我们可以为真正的最优性提供定性的性能保证。据我们所知，该领域的以前没有任何工作都针对其提出的方法解决了这样的分析。基于现有的高斯流程优化工作，我们严格地得出了sublinear的界限，以使我们的算法累积遗憾，这保证了近乎最佳的算法。与此相辅相成，我们在模拟框架内从经验上评估了算法的性能。我们通过广泛的潜在目标功能进行广泛研究，并分析相关工作结果的差异，从而提供其他见解。]]></description>
      <guid>https://arxiv.org/abs/2503.18999</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用LLM指导语义分层增强学习的期权发现学习</title>
      <link>https://arxiv.org/abs/2503.19007</link>
      <description><![CDATA[ARXIV：2503.19007V1公告类型：新 
摘要：大型语言模型（LLMS）在推理和决策方面表现出了巨大的希望，但是它们与加强学习（RL）进行复杂的机器人任务的集成仍然没有得到充实的态度。在本文中，我们提出了一个称为LDSC的LLM引导的层次RL框架，该框架利用LLM驱动的子目标选择和期权重用来提高样本效率，概括和多任务适应性。传统的RL方法通常遭受效率低下的探索和高计算成本的困扰。分层RL有助于解决这些挑战，但是现有方法在面对新任务时通常无法有效地重复使用选项。为了解决这些限制，我们引入了一个三阶段的框架，鉴于对任务的自然语言描述，可重复使用的选项学习和选择方法以及动作级别的策略，该框架将LLM用于亚目标生成，并实现了跨不同任务的更有效的决策。通过将LLM纳入子目标预测和政策指导，我们的方法提高了勘探效率并提高了学习绩效。平均而言，LDSC在平均奖励中优于基线55.9％，表明其在复杂的RL设置中的有效性。可以在\ href {https://raaslab.org/projects/ldsc/} {此链接\ footNote {https://raaslab.org/projects/ldsc}}}中找到更多详细信息和实验视频。]]></description>
      <guid>https://arxiv.org/abs/2503.19007</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>进化政策优化</title>
      <link>https://arxiv.org/abs/2503.19037</link>
      <description><![CDATA[ARXIV：2503.19037V1公告类型：新 
摘要：尽管样本效率极高，但在政策增强学习中，已成为现实世界应用中的基本工具。随着GPU驱动模拟的最新进展，收集大量RL培训数据的能力已成倍扩展。然而，研究表明，当前的政治方法（例如PPO）无法完全利用并行化环境的益处，从而导致性能饱和度超出了一定程度。相比之下，进化算法（EAS）通过随机化增加了多样性，使其自然而然地补充了RL。但是，由于其极端样本效率低下，现有的Evorl方法一直在努力获得广泛的采用。为了应对这些挑战，我们引入了进化政策优化（EPO），这是一种新型的政策梯度算法，结合了EA和政策梯度的优势。我们表明，EPO可以显着提高各种和具有挑战性的环境的性能，从而通过平行模拟证明了卓越的可伸缩性。]]></description>
      <guid>https://arxiv.org/abs/2503.19037</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仅图形标签的仅会员推断针对图形神经网络的攻击</title>
      <link>https://arxiv.org/abs/2503.19070</link>
      <description><![CDATA[ARXIV：2503.19070V1公告类型：新 
摘要：图形神经网络（GNN）广泛用于图形结构数据，但很容易受到图形分类任务中成员推理攻击（MIA）的影响，这些任务确定图形是否是训练数据集的一部分，可能导致数据泄漏。现有的MIA依赖于预测概率向量，但是当仅预测标签可用时，它们就变得无效。我们提出了一个仅图形标签的构件推理攻击（GLO-MIA），该攻击基于直觉，即目标模型对训练数据的预测比测试数据的预测更稳定。 GLO-MIA通过将扰动添加到其有效功能中，并使用扰动图来查询目标模型，从而为目标图生成一组扰动图，以获取其预测标签，然后将其用于计算目标图的稳健性得分。最后，通过将鲁棒性得分与预定义的阈值进行比较，可以在高概率上正确推断目标图的成员身份。我们在三个数据集和四个GNN模型上的评估表明，GLO-MIA达到的攻击精度高达0.825，即使仅具有预测标签，也超过了基线工作，超过了8.5％，并且与基于概率的MIA的性能紧密相匹配。]]></description>
      <guid>https://arxiv.org/abs/2503.19070</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>hingerlc-gan：与铰链损失和RLC正则化的斗争模式崩溃</title>
      <link>https://arxiv.org/abs/2503.19074</link>
      <description><![CDATA[ARXIV：2503.19074V1公告类型：新 
摘要：生成对抗网络（GAN）的最新进展证明了它们产生高质量图像的能力。但是，一个重大的挑战仍然是模式崩溃，这发生在发电机产生有限数量的数据模式时发生，这些数据模式不反映培训数据集的多样性。这项研究通过提出许多旨在提高GAN模型的多样性和稳定性的建筑变化来解决此问题。我们首先要通过Wasserstein损失和梯度惩罚来改善损失功能，以更好地捕获数据变化的全部范围。我们还研究了各种网络架构，并得出结论，重新NET会大大导致多样性的增加。在这些发现的基础上，我们引入了Hingerlc-Gan，这是一种结合RLC正则化和铰链损耗函数的新方法。我们的方法得分为18，孩子得分为0.001，我们的方法通过有效平衡训练稳定性和增加的多样性来优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.19074</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为科学基础模型铺平道路：增强PDE的概括和鲁棒性，并具有限制性的预培训</title>
      <link>https://arxiv.org/abs/2503.19081</link>
      <description><![CDATA[ARXIV：2503.19081V1公告类型：新 
摘要：部分微分方程（PDE）控制着广泛的物理系统，但是有效地解决它们仍然是一个主要挑战。科学基础模型（SCCIFM）的想法正在成为一种有前途的工具，用于学习跨不同领域的可转移表示。但是，SciFM需要大量的解决方案数据，这可能很少或计算昂贵。为了在减少数据依赖性的同时最大程度地提高概括，我们建议将PDE残差纳入预训练中作为唯一的学习信号或与数据丢失结合，以补偿有限或不可行的培训数据。我们在三个关键基准中评估了这种约束意识到的预训练：（i）对新物理学的概括，其中材料特性（例如扩散系数）在训练分布方面发生了变化； （ii）对全新的PDE的概括，需要对不同的操作员进行适应； （iii）对嘈杂的微调数据的鲁棒性，确保在现实世界中的稳定性。我们的结果表明，使用PDE约束的预训练显着增强了概括，超过了仅在所有基准测试的解决方案数据上训练的模型。这些发现证明了我们提出的约束意识到的预培训是SCIFM的关键组成部分的有效性，从而为数据有效，可推广的PDE求解器提供了可扩展的方法。]]></description>
      <guid>https://arxiv.org/abs/2503.19081</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于风险的阈值，可在浓缩太阳能发电厂中可靠的异常检测</title>
      <link>https://arxiv.org/abs/2503.19146</link>
      <description><![CDATA[ARXIV：2503.19146V1公告类型：新 
摘要：浓缩太阳能（CSP）工厂的有效和可靠的运行对于满足对可持续能源不断增长的需求至关重要。但是，高温太阳接收机面临着严重的操作风险，例如冻结，变形和腐蚀，导致昂贵的停机时间和维护。为了监视CSP植物，安装在太阳接收机上的摄像机以不规则的间隔为纪录红外图像，范围从一整天的一到五分钟。可以通过阈值对异常分数检测到异常图像，其中选择阈值以优化诸如验证集中的F1分数之类的指标。这项工作提出了一个框架，以生成更可靠的决策阈值，并在任何选择的风险功能上保证有限样本覆盖范围。我们的框架还结合了弃权机制，可以将高风险预测推迟到领域专家。其次，我们提出了一种密度预测方法，以使用这种可能性作为其异常得分来估计观察到的图像的可能性。第三，我们分析了两种CSP工厂的几个月内多种培训场景的框架的部署结果。该分析为我们的行业合作伙伴提供了宝贵的见解，以优化维护操作。最后，鉴于我们数据集的机密性质，我们提供了一个扩展的模拟数据集，利用生成建模的最新进步来创建模拟多个CSP工厂的多种热图像。我们的代码公开可用。]]></description>
      <guid>https://arxiv.org/abs/2503.19146</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>