<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 04 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Bayes-CATSI：一种用于医学时间序列数据插补的变分贝叶斯方法</title>
      <link>https://arxiv.org/abs/2410.01847</link>
      <description><![CDATA[arXiv:2410.01847v1 公告类型：新 
摘要：医学时间序列数据集具有缺失值，需要数据插补方法，然而，传统的机器学习模型由于预测中缺乏不确定性量化而无法达到预期效果。在这些模型中，CATSI（上下文感知时间序列插补）通过将上下文向量纳入插补过程，捕捉每个患者的全局依赖关系，以其有效性脱颖而出。在本文中，我们提出了一个贝叶斯上下文感知时间序列插补（Bayes-CATSI）框架，该框架利用变分推理提供的不确定性量化。我们考虑来自脑电图（EEG）、眼电图（EOG）、肌电图（EMG）、心电图（EKG）的时间序列。变分推理假设后验分布的形状，并通过最小化 Kullback-Leibler（KL）散度，找到最接近真实后验分布的变分密度。因此，我们将变分贝叶斯深度学习层集成到 CATSI 模型中。我们的结果表明，Bayes-CATSI 不仅提供了不确定性量化，而且与 CATSI 模型相比，还实现了更出色的插补性能。具体而言，Bayes-CATSI 的一个实例比 CATSI 的性能高出 9.57%。我们提供了一个开源代码实现，用于将 Bayes-CATSI 应用于其他医疗数据插补问题。]]></description>
      <guid>https://arxiv.org/abs/2410.01847</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成安全可靠的 AI 分类器的早期工作流程提案</title>
      <link>https://arxiv.org/abs/2410.01850</link>
      <description><![CDATA[arXiv:2410.01850v1 公告类型：新
摘要：生成和执行合格的安全可靠的人工智能模型，需要定义一个透明、完整但适应性强且最好是轻量级的工作流程。鉴于人工智能研究领域的快速发展和安全人工智能领域的相对不成熟，功能安全开发所依赖的过程稳定性必须与一定程度的适应性相结合。这项早期工作提出了这样一种工作流程，它基于扩展的 ONNX 模型描述。用例为这项工作提供了基础，我们希望其他第三方用例能够对其进行扩展。]]></description>
      <guid>https://arxiv.org/abs/2410.01850</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过神经符号整合实现可解释的诊断预测</title>
      <link>https://arxiv.org/abs/2410.01855</link>
      <description><![CDATA[arXiv:2410.01855v1 公告类型：新
摘要：诊断预测是医疗保健中的一项关键任务，及时准确地识别医疗状况可以显著影响患者的治疗结果。传统的机器学习和深度学习模型在这一领域取得了显著的成功，但往往缺乏可解释性，而可解释性是临床环境中的关键要求。在本研究中，我们探索使用神经符号方法，特别是逻辑神经网络 (LNN)，来开发可解释的诊断预测模型。本质上，我们设计和实施基于 LNN 的模型，通过具有可学习阈值的逻辑规则整合领域特定知识。我们的模型，特别是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，与 Logistic 回归、SVM 和随机森林等传统模型相比，表现出卓越的性能，在糖尿病预测案例研究中实现了更高的准确度（高达 80.52\%）和 AUROC 分数（高达 0.8457）。 LNN 模型中学习到的权重和阈值可直接洞察特征贡献，从而在不影响预测能力的情况下增强可解释性。这些发现凸显了神经符号方法在弥合医疗 AI 应用中准确性和可解释性之间的差距方面的潜力。通过提供透明且适应性强的诊断模型，我们的工作有助于精准医疗的发展，并支持公平医疗解决方案的开发。未来的研究将侧重于将这些方法扩展到更大、更多样化的数据集，以进一步验证它们在不同医疗条件和人群中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2410.01855</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习协作边缘推理的最佳路径和 DNN 分区</title>
      <link>https://arxiv.org/abs/2410.01857</link>
      <description><![CDATA[arXiv:2410.01857v1 公告类型：新
摘要：深度神经网络 (DNN) 的最新进展催化了众多智能移动应用程序和服务的发展。然而，它们也给资源受限的移动设备带来了巨大的计算挑战。为了解决这个问题，提出了协作边缘推理。该方法涉及将 DNN 推理任务划分为几个子任务，并将它们分布在多个网络节点上。尽管它有潜力，但大多数当前方法都假设已知的网络参数——如节点处理速度和链路传输速率——或依靠固定的节点序列来处理 DNN 子任务。在本文中，我们处理了一个更复杂的场景，其中网络参数未知且必须学习，并且有多个网络路径可用于分配推理任务。具体来说，我们探索选择最佳网络路径并将 DNN 层分配给该路径上的节点的学习问题，同时考虑潜在的安全威胁和切换路径的成本。我们首先从具有完整网络信息的 DNN 层分配中得出结构见解，从而缩小决策空间并提供对最佳分配的关键理解。然后，我们将具有不完整网络信息的学习问题视为具有切换成本的新型对抗组线性老虎机问题，其特点是通过组合随机和对抗过程来产生奖励。我们引入了一种新的老虎机算法 B-EXPUCB，它结合了经典的阻塞 EXP3 和 LinUCB 算法的元素，并展示了其亚线性遗憾。大量模拟证实了 B-EXPUCB 在协作边缘推理学习方面的表现优于现有算法。]]></description>
      <guid>https://arxiv.org/abs/2410.01857</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>《纸牌屋》：法学硕士的巨大权重</title>
      <link>https://arxiv.org/abs/2410.01866</link>
      <description><![CDATA[arXiv:2410.01866v1 公告类型：新
摘要：大规模激活表现在隐藏状态的特定特征维度中，在大型语言模型 (LLM) 中引入了显著的偏差，导致过分强调相应的标记。在本文中，我们发现大规模激活不是源自隐藏状态，而是源自早期层中前馈网络模块的中间状态。扩展之前的观察结果，即大规模激活仅发生在特定特征维度中，我们深入研究导致大规模激活的权重。具体而言，我们将 top-$k$ 大规模权重定义为对中间状态下具有 top-$k$ 量级的维度有贡献的权重。当这些大规模权重设置为零时，LLM 的功能将完全中断。但是，当除大规模权重之外的所有权重都设置为零时，即使将大量权重设置为零，也会导致相对较小的性能下降。这意味着在预训练过程中，学习主要集中在大量权重上。基于这一观察，我们提出了一种简单的即插即用方法，称为 MacDrop（大量权重课程 dropout），以在参数高效的微调过程中减少对大量权重的依赖。此方法将 dropout 应用于预训练的大量权重，从高 dropout 概率开始，并随着微调的进行逐渐降低。通过实验，我们证明 MacDrop 通常会提高零样本下游任务和生成任务的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.01866</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NEAT：预训练模型的非线性参数高效适应</title>
      <link>https://arxiv.org/abs/2410.01870</link>
      <description><![CDATA[arXiv:2410.01870v1 公告类型：新
摘要：微调预训练模型对于将大型模型适应下游任务至关重要，通常可以提供最先进的性能。然而，微调所有模型参数需要大量资源且费力，这导致了参数高效微调 (PEFT) 方法的出现。一种广泛采用的 PEFT 技术，低秩自适应 (LoRA)，冻结预训练模型权重并引入两个低秩矩阵，其秩明显小于原始权重矩阵的维度。这只需调整少量参数即可实现高效微调。尽管 LoRA 效率高，但它使用低秩分解来近似权重更新，这很难捕捉复杂的非线性成分和高效的优化轨迹。因此，与完全微调相比，基于 LoRA 的方法通常表现出明显的性能差距。缩小这一差距需要更高的秩，这会增加参数的数量。为了解决这些限制，我们提出了一种非线性参数高效自适应方法 (NEAT)。NEAT 引入了一种轻量级神经网络，该网络以预训练权重作为输入，并学习非线性变换以近似累积权重更新。这些更新可以解释为相应预训练权重的函数。非线性近似直接对累积更新进行建模，有效地捕获权重更新中的复杂和非线性结构。我们的理论分析表明，NEAT 可以比 LoRA 更高效，同时具有相同或更高的表达能力。对四个基准和二十多个数据集的广泛评估表明，NEAT 在视觉和文本任务中的表现都远远优于基线。]]></description>
      <guid>https://arxiv.org/abs/2410.01870</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>共形预测集可能造成不同的影响</title>
      <link>https://arxiv.org/abs/2410.01888</link>
      <description><![CDATA[arXiv:2410.01888v1 公告类型：新
摘要：虽然共形预测是一种量化机器学习模型不确定性的有前途的方法，但它输出的预测集本身并不是可操作的。许多应用程序需要一个输出来采取行动，而不是几个。为了克服这个问题，可以将预测集提供给人类，然后人类做出明智的决定。在任何这样的系统中，确保受保护群体之间结果的公平性都至关重要，研究人员已经提出将均衡覆盖作为公平的标准。通过对人类参与者进行实验，我们证明提供预测集会增加他们决策的不公平性。令人不安的是，我们发现，与边际覆盖相比，提供满足均衡覆盖的集合实际上会增加不公平性。我们建议在各个群体之间均衡集合大小，而不是均衡覆盖，这在经验上会带来更公平的结果。]]></description>
      <guid>https://arxiv.org/abs/2410.01888</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一表达能力是否太过严格？迈向图神经网络的高效表达能力</title>
      <link>https://arxiv.org/abs/2410.01910</link>
      <description><![CDATA[arXiv:2410.01910v1 公告类型：新
摘要：统一表达能力保证图神经网络 (GNN) 可以表达查询，而无需依赖输入图的大小的参数。此属性在应用程序中是可取的，以便拥有与输入图大小无关的可训练参数数量。一阶逻辑的两个变量保护片段 (GC2) 的统一表达能力是整流线性单元 (ReLU) GNN 的一个著名结果 [Barcelo &amp; al., 2020]。在本文中，我们证明对于具有广泛 Pfaffian 激活函数（包括 sigmoid 和 tanh）的 GNN，GC2 查询的统一表达能力是不可能的，这回答了 [Grohe, 2021] 提出的问题。我们还表明，尽管存在这些限制，但许多 GNN 仍可以高效地表达 GC2 查询，使得参数数量在输入图的最大度上保持对数关系。此外，我们证明，对于特定的激活函数选择，可以实现度的对数对数依赖性。这表明，通过覆盖实际应用中出现的大型图，可以成功放宽统一的表达能力。我们的实验表明，我们的理论估计在实践中是成立的。]]></description>
      <guid>https://arxiv.org/abs/2410.01910</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过杠杆分数抽样实现可证明准确的 Shapley 值估计</title>
      <link>https://arxiv.org/abs/2410.01917</link>
      <description><![CDATA[arXiv:2410.01917v1 公告类型：新 
摘要：Shapley 值最初是在博弈论中引入的，现已成为可解释机器学习的核心工具，用于将模型预测归因于特定的输入特征。然而，精确计算 Shapley 值的成本很高：对于具有 $n$ 个特征的一般模型，需要进行 $O(2^n)$ 次模型评估。为了解决这个问题，近似算法被广泛使用。其中最流行的算法之一是 Kernel SHAP 算法，它与模型无关，在实践中非常有效。然而，据我们所知，Kernel SHAP 没有强大的非渐近复杂性保证。我们通过引入 Leverage SHAP 来解决这个问题，这是 Kernel SHAP 的轻量级修改，只需 $O(n\log n)$ 次模型评估即可提供可证明准确的 Shapley 值估计。我们的方法利用了 Shapley 值估计与不可知主动学习之间的联系，采用了杠杆分数抽样（一种强大的回归工具）。除了理论保证之外，我们还表明 Leverage SHAP 的表现甚至优于无处不在的 SHAP 库中高度优化的 Kernel SHAP 实现 [Lundberg &amp; Lee, 2017]。]]></description>
      <guid>https://arxiv.org/abs/2410.01917</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扭曲序贯蒙特卡罗逐步推理数学问题</title>
      <link>https://arxiv.org/abs/2410.01920</link>
      <description><![CDATA[arXiv:2410.01920v1 公告类型：新
摘要：增强大型语言模型 (LLM) 的多步推理能力一直是一个挑战。最近，验证通过评估生成的输出显示出改善解决方案一致性的希望。然而，目前的验证方法存在采样效率低下的问题，需要大量样本才能达到令人满意的性能。此外，训练有效的验证者通常依赖于广泛的过程监督，而这需要高昂的成本。在本文中，我们通过引入一种基于扭曲顺序蒙特卡洛 (TSMC) 的新型验证方法来解决这些限制。TSMC 依次改进其采样工作，将探索重点放在有希望的候选者上，从而更有效地生成高质量的解决方案。我们通过估计部分解决方案的预期未来回报将 TSMC 应用于 LLM。这种方法产生了一个更直接的训练目标，消除了对逐步人工注释的需求。我们通过多个数学基准实证证明了我们的方法的优势，并验证了我们的方法和现有验证方法的理论分析。]]></description>
      <guid>https://arxiv.org/abs/2410.01920</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NTK-DFL：通过神经切线核增强异构环境中的分散式联邦学习</title>
      <link>https://arxiv.org/abs/2410.01922</link>
      <description><![CDATA[arXiv:2410.01922v1 公告类型：新
摘要：分散式联邦学习 (DFL) 是一种协作机器学习框架，用于在参与者之间训练模型，而无需中央服务器或原始数据交换。由于统计异质性，DFL 面临挑战，因为参与者通常拥有反映本地环境和用户行为的不同数据分布。最近的研究表明，神经正切核 (NTK) 方法应用于集中式框架中的联邦学习时可以提高性能。基于 NTK 的更新机制比典型的梯度下降方法更具表现力，可以实现更高效的收敛和更好地处理数据异质性。我们提出了一种利用 NTK 在分散环境中训练客户端模型的方法，同时引入基于 NTK 的进化和模型平均之间的协同作用。这种协同作用利用了模型间方差，并提高了异质环境中的准确性和收敛性。我们的模型平均技术显著提高了性能，与平均局部模型精度相比，精度提高了至少 10%。实证结果表明，在高度异构的环境中，我们的方法始终比基线实现更高的精度，而其他方法通常表现不佳。此外，它以 4.6 倍的通信轮次达到目标性能。我们在多个数据集、网络拓扑和异构设置中验证了我们的方法，以确保稳健性和通用性。]]></description>
      <guid>https://arxiv.org/abs/2410.01922</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MARPLE：长期推理的基准</title>
      <link>https://arxiv.org/abs/2410.01926</link>
      <description><![CDATA[arXiv:2410.01926v1 公告类型：新
摘要：重建过去事件需要跨长远推理。为了弄清楚发生了什么，我们需要利用我们对世界和人类行为的先验知识，并从各种证据来源（包括视觉、语言和听觉线索）中得出推论。我们引入了 MARPLE，这是一个使用多模态证据评估长远推理能力的基准。我们的基准以与模拟家庭互动的代理为特色，支持视觉、语言和听觉刺激，以及程序生成的环境和代理行为。受经典“谁是凶手”故事的启发，我们要求 AI 模型和人类参与者根据实际发生的事情的逐步重播推断哪个代理导致了环境的变化。目标是尽早正确识别罪魁祸首。我们的研究结果表明，人类参与者在这项任务上的表现优于传统的蒙特卡罗模拟方法和 LLM 基线 (GPT-4)。与人类相比，传统推理模型的稳健性和性能较差，而 GPT-4 难以理解环境变化。我们分析了哪些因素会影响推理性能，并消除了不同的证据模式，发现所有模式对性能都有价值。总体而言，我们的实验表明，基准测试中的长视界、多模态推理任务对当前模型提出了挑战。]]></description>
      <guid>https://arxiv.org/abs/2410.01926</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不要扁平化，而要标记化！揭开 SoftMoE 在深度强化学习中功效的关键</title>
      <link>https://arxiv.org/abs/2410.01930</link>
      <description><![CDATA[arXiv:2410.01930v1 公告类型：新
摘要：随着模型规模的增加，深度神经网络在强化学习 (RL) 中的使用通常会遭受性能下降的影响。虽然软专家混合 (SoftMoE) 最近显示出缓解在线 RL 的这一问题的希望，但其有效性背后的原因仍然很大程度上未知。在这项工作中，我们提供了深入的分析，确定了推动这一性能提升的关键因素。我们发现令人惊讶的结果，标记编码器输出，而不是使用多个专家，是 SoftMoE 有效性的背后原因。事实上，我们证明，即使使用适当缩放的单个专家，我们也能够保持性能提升，这在很大程度上要归功于标记化。]]></description>
      <guid>https://arxiv.org/abs/2410.01930</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TAEGAN：生成用于数据增强的合成表格数据</title>
      <link>https://arxiv.org/abs/2410.01933</link>
      <description><![CDATA[arXiv:2410.01933v1 公告类型：新
摘要：合成表格数据生成因其在数据增强、软件测试和隐私保护数据共享方面的潜力而备受关注。然而，大多数研究主要集中在较大的数据集上，并根据列统计分布和特征间相关性等指标来评估其质量，而往往忽视了其在数据增强方面的效用，特别是对于数据稀缺的数据集。在本文中，我们提出了表格自动编码器生成对抗网络 (TAEGAN)，这是一种基于 GAN 的改进框架，用于生成高质量的表格数据。虽然基于大型语言模型 (LLM) 的方法代表了合成表格数据生成的最新技术，但由于其规模大、复杂性高，它们对于小型数据集来说往往是过度的。 TAEGAN 采用​​掩码自动编码器作为生成器，首次在表格数据生成中引入了自监督预训练的强大功能，从而让网络能够获取更多信息。我们根据五种最先进的合成表格数据生成算法对 TAEGAN 进行了广泛的评估。10 个数据集的结果表明，在机器学习效率方面，TAEGAN 在 10 个数据集中的 9 个上优于现有的基于深度学习的表格数据生成模型，并在 8 个较小数据集中的 7 个上实现了出色的数据增强性能。]]></description>
      <guid>https://arxiv.org/abs/2410.01933</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CHASE-SQL：文本到 SQL 中的多路径推理和偏好优化候选选择</title>
      <link>https://arxiv.org/abs/2410.01943</link>
      <description><![CDATA[arXiv:2410.01943v1 公告类型：新
摘要：为了应对文本到 SQL 任务的大型语言模型 (LLM) 性能挑战，我们引入了 CHASE-SQL，这是一个采用创新策略的新框架，使用多代理建模中的测试时计算来改进候选生成和选择。CHASE-SQL 利用 LLM 的内在知识，使用不同的 LLM 生成器生成多样化和高质量的 SQL 候选：(1) 分而治之的方法，在单个 LLM 调用中将复杂查询分解为可管理的子查询；(2) 基于查询执行计划的思路推理，反映数据库引擎在执行过程中采取的步骤；(3) 一种独特的实例感知合成示例生成技术，它提供针对测试问题量身定制的特定少数样本演示。为了确定最佳候选人，使用选择代理通过与微调的二元候选选择 LLM 进行成对比较来对候选人进行排名。这种选择方法已被证明比其他方法更稳健。所提出的生成器-选择器框架不仅提高了 SQL 查询的质量和多样性，而且性能优于以前的方法。总体而言，我们提出的 CHASE-SQL 在著名的 BIRD Text-to-SQL 数据集基准的测试集和开发集上实现了 73.0% 和 73.01% 的当前最佳执行准确率，使 CHASE-SQL 成为排行榜的榜首（在提交论文时）。]]></description>
      <guid>https://arxiv.org/abs/2410.01943</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>