<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 19 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>无线联邦学习的绿色多属性客户端选择：灰狼优化器方法</title>
      <link>https://arxiv.org/abs/2409.11442</link>
      <description><![CDATA[arXiv:2409.11442v1 公告类型：新
摘要：联邦学习 (FL) 因其无需集中敏感数据即可训练机器学习模型的能力而受到各行各业的关注。虽然这种方法提供了隐私保护和减少通信开销等显着优势，但它带来了一些挑战，包括部署复杂性和互操作性问题，特别是在异构场景或资源受限的环境中。引入无线 (OTA) FL 来应对这些挑战，通过传播模型更新而无需直接的设备到设备连接或集中式服务器。然而，OTA-FL 带来了与增加的能耗和网络延迟相关的限制。在本文中，我们提出了一个多属性客户端选择框架，该框架采用灰狼优化器 (GWO) 来战略性地控制每轮参与者的数量并优化 OTA-FL 流程，同时考虑参与设备的准确性、能量、延迟、可靠性和公平性约束。我们从模型损失最小化、收敛时间减少和能源效率等方面评估了多属性客户端选择方法的性能。在我们的实验评估中，我们评估并比较了我们的方法与现有的最先进方法的性能。我们的结果表明，所提出的基于 GWO 的客户端选择在各个指标上都优于这些基线。具体而言，我们的方法显著减少了模型损失，加快了收敛时间，提高了能源效率，同时保持了较高的公平性和可靠性指标。]]></description>
      <guid>https://arxiv.org/abs/2409.11442</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>沃尔沃 Discovery 挑战赛将亮相 2024 ECML-PKDD</title>
      <link>https://arxiv.org/abs/2409.11446</link>
      <description><![CDATA[arXiv:2409.11446v1 公告类型：新
摘要：本文概述了在 ECML-PKDD 2024 会议期间举行的沃尔沃发现挑战赛。挑战赛的目标是使用新发布的数据集预测沃尔沃卡车中匿名组件的故障风险。测试数据包括两代（gen1 和 gen2）组件的观察结果，而训练数据仅为 gen1 提供。挑战赛吸引了来自世界各地的 52 位数据科学家，他们共提交了 791 份参赛作品。我们简要介绍了问题定义、挑战赛设置和提交的统计数据。在获奖方法部分，比赛的第一、第二和第三名获胜者简要介绍了他们提出的方法，并提供了他们实施代码的 GitHub 链接。共享代码可以作为预测性维护领域研究人员的高级方法。比赛在 Codabench 平台上举办。]]></description>
      <guid>https://arxiv.org/abs/2409.11446</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预训练语言模型对音乐理解的评估</title>
      <link>https://arxiv.org/abs/2409.11449</link>
      <description><![CDATA[arXiv:2409.11449v1 公告类型：新
摘要：音乐文本多模态系统为音乐信息研究 (MIR) 应用提供了新方法，例如音频到文本和文本到音频检索、基于文本的歌曲生成和音乐字幕。尽管据报道取得了成功，但很少有人投入精力来评估大型语言模型 (LLM) 的音乐知识。在本文中，我们证明 LLM 存在 1) 即时敏感性、2) 无法模拟否定（例如“没有吉他的摇滚歌曲”）和 3) 对特定单词存在的敏感性。我们将这些属性量化为基于三元组的准确性，评估在分层本体中建模标签相对相似性的能力。我们利用 Audioset 本体为流派和乐器子树生成由锚点、正（相关）标签和负（不太相关）标签组成的三元组。我们评估了六种通用 Transformer 模型的三连音音乐知识。通过这种方法获得的三连音需要过滤，因为有些三连音很难判断，因此对于评估目的而言信息量相对较少。尽管报告的准确率相对较高，但所有六个模型都存在不一致的情况，这表明现成的 LLM 在使用前需要适应音乐。]]></description>
      <guid>https://arxiv.org/abs/2409.11449</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球天气预报的超分辨率</title>
      <link>https://arxiv.org/abs/2409.11502</link>
      <description><![CDATA[arXiv:2409.11502v2 公告类型：新
摘要：天气预报是规划日常活动和灾难响应规划等任务的至关重要的工具。然而，由于天气的混乱和不可预测性，建模已被证明是一项具有挑战性的任务。从温度到降水再到​​风，每个变量都会影响环境的路径。因此，随着预测时间范围的增加，所有模型的准确性往往会迅速降低。经典预测方法使用大量基于物理、数值和随机技术来预测天气变量随时间的变化。然而，这样的预测通常需要大量的数据，而且计算成本极其高昂。此外，随着气候和全球天气模式的变化，经典模型在更新不断变化的环境时会变得更加困难和耗时。幸运的是，随着深度学习的最新进展和公开的高质量天气数据集，部署学习方法来估计这些复杂系统已经变得可行。目前最先进的深度学习模型的精度可与行业标准数值模型相媲美，并且由于其适应性，在实践中变得越来越普遍。我们的团队致力于通过提高全球天气预报的空间分辨率来改进现有的基于深度学习的预测方法。具体来说，我们感兴趣的是通过将全球精度从 1 度提高到 0.5 度（分别约为 111 公里和 55 公里）来对 GraphCast 温度预测执行超分辨率 (SR)。]]></description>
      <guid>https://arxiv.org/abs/2409.11502</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过分割计算图防止 MPNN 中的表征秩崩溃</title>
      <link>https://arxiv.org/abs/2409.11504</link>
      <description><![CDATA[arXiv:2409.11504v1 公告类型：新
摘要：消息传递神经网络 (MPNN) 在图上拟合复杂函数的能力是有限的，在简单图上每次迭代消息传递都会使表示更加相似，这种现象称为秩崩溃，过度平滑是一种特殊情况。大多数缓解过度平滑的方法都是通过利用残差连接、门控机制、规范化或正则化技术来扩展常见的消息传递方案，例如图卷积网络。相反，我们的工作建议通过修改消息传递方案并使用多关系图交换不同类型的消息来直接解决此问题的根源。我们确定了确保线性独立节点表示的必要和充分条件。作为一个实例，我们表明对多个有向无环图进行操作始终满足我们的条件，并建议通过定义节点的严格偏序来获得这些条件。我们进行了全面的实验，证实了在多关系图上进行操作以获得更具信息量的节点表示的好处。]]></description>
      <guid>https://arxiv.org/abs/2409.11504</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN-LSTM 根据走法和时间估算国际象棋等级分</title>
      <link>https://arxiv.org/abs/2409.11506</link>
      <description><![CDATA[arXiv:2409.11506v1 公告类型：新
摘要：当前的评级系统会逐步更新评级，并且可能无法始终准确反映玩家的真实实力，尤其是对于快速进步的玩家或非常生疏的玩家。为了克服这个问题，我们探索了一种直接从游戏动作和时钟时间估计玩家评级的方法。我们从 Lichess 汇编了一个基准数据集，涵盖了各种时间控制，包括移动序列和时钟时间。我们的模型架构包括一个 CNN 来学习位置特征，然后将其与时钟时间数据集成到双向 LSTM 中，预测每次移动后的玩家评级。该模型在测试数据中实现了 182 个评级点的 MAE。此外，我们将我们的模型应用于 2024 年 IEEE 大数据杯国际象棋谜题难度竞赛数据集，预测了谜题评级并取得了竞争性结果。该模型是第一个不使用手工制作的特征来估计国际象棋评级的模型，也是第一个为每一步输出评级预测的模型。我们的方法凸显了使用基于移动的评级估计来增强评级系统以及潜在的其他应用（例如作弊检测）的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.11506</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedNE：用于降维的代理辅助联邦邻居嵌入</title>
      <link>https://arxiv.org/abs/2409.11509</link>
      <description><![CDATA[arXiv:2409.11509v1 公告类型：新
摘要：联邦学习 (FL) 已迅速发展成为一种有前途的范式，它能够在分布式参与者之间进行协作模型训练，而无需交换他们的本地数据。尽管它在计算机视觉、图形学习和自然语言处理等领域有着广泛的应用，但开发一种可以有效地用于在 FL 环境中可视化数据的数据投影模型至关重要，但仍未得到充分探索。邻域嵌入 (NE) 是可视化复杂高维数据的重要技术，但协作学习联合 NE 模型很困难。关键挑战在于目标函数，因为像 NE 这样的有效可视化算法需要计算数据对之间的损失函数。在本文中，我们介绍了 \textsc{FedNE}，这是一种新颖的方法，它将 \textsc{FedAvg} 框架与对比 NE 技术相结合，而不需要任何可共享数据。为了解决客户端间排斥力的缺乏（这对于全局嵌入空间中的对齐至关重要），我们开发了一个替代损失函数，每个客户端都可以相互学习和共享。此外，我们提出了一种数据混合策略来增强本地数据，旨在放松由局部 $k$NN 图构建的不可见邻居和假邻居的问题。我们对合成数据集和真实数据集进行了全面的实验。结果表明，与几种基线方法相比，我们的 \textsc{FedNE} 可以有效地保留邻域数据结构并增强全局嵌入空间中的对齐。]]></description>
      <guid>https://arxiv.org/abs/2409.11509</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有线性收益的部分可观察情境老虎机</title>
      <link>https://arxiv.org/abs/2409.11521</link>
      <description><![CDATA[arXiv:2409.11521v1 公告类型：新
摘要：标准上下文强盗框架假设完全可观察和可操作的上下文。在这项工作中，我们考虑了一种具有部分可观察、相关上下文和线性收益的新强盗设置，其动机是金融中的应用，其中决策基于通常显示时间相关性且未完全观察到的市场信息。我们将统计信号处理与强盗的思想结合起来，做出了以下贡献：（i）我们提出了一种名为 EMKF-Bandit 的算法管道，它将系统识别、过滤和经典上下文强盗算法集成到一种在潜在参数估计和决策之间交替的迭代方法中。（ii）当我们选择汤普森采样作为强盗算法时，我们分析了 EMKF-Bandit，并表明它在过滤条件下会产生亚线性遗憾。（iii）我们进行了数值模拟，证明了所提出的管道的优势和实际适用性。]]></description>
      <guid>https://arxiv.org/abs/2409.11521</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 OpenAI 解锁 NACE 分类嵌入以增强分析和处理能力</title>
      <link>https://arxiv.org/abs/2409.11524</link>
      <description><![CDATA[arXiv:2409.11524v1 公告类型：新
摘要：欧洲共同体经济活动统计分类 (NACE) 是欧盟内经济和工业活动分类的标准分类系统。本文提出了一种新方法，使用最先进的模型和降维技术将 NACE 分类转换为低维嵌入。主要挑战是在减少维度的同时保留原始 NACE 分类中固有的层次结构。为了解决这个问题，我们引入了自定义指标，旨在量化嵌入和缩减过程中层次关系的保留。这些指标的评估证明了所提出的方法在保留深入分析所必需的结构信息方面的有效性。这种方法不仅有助于直观地探索经济活动关系，而且还提高了下游任务的效率，包括聚类、分类、与其他分类的集成等。通过实验验证，展示了我们提出的框架在保留 NACE 分类中的层次结构方面的实用性，从而为研究人员和政策制定者提供了理解和利用任何层次数据的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2409.11524</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有低秩张量分解和深度展开的网络流自适应异常检测</title>
      <link>https://arxiv.org/abs/2409.11529</link>
      <description><![CDATA[arXiv:2409.11529v1 公告类型：新
摘要：异常检测 (AD) 越来越被认为是确保未来通信系统弹性的关键组成部分。虽然深度学习已经展示了最先进的 AD 性能，但它在关键系统中的应用受到对训练数据效率、领域适应性和可解释性的担忧的阻碍。这项工作考虑了使用不完整测量的网络流中的 AD，利用强大的张量分解方法和深度展开技术来应对这些挑战。我们首先提出了一种基于正则化模型拟合目标的新型块连续凸近似算法，其中正常流被建模为低秩张量，异常被建模为稀疏张量。引入了目标的增强以降低计算成本。我们应用深度展开来基于我们提出的算法推导出一种新的深度网络架构，将正则化参数视为可学习的权重。受贝叶斯方法的启发，我们扩展了模型架构，以对每个流和每个时间步统计数据进行在线自适应，从而提高 AD 性能，同时保持较低的参数数量并保留问题的置换等方差。为了优化深度网络权重以提高检测性能，我们采用了一种基于接收器操作特性曲线下面积的有效近似的同伦优化方法。对合成数据和真实数据进行的大量实验表明，我们提出的深度网络架构表现出较高的训练数据效率，优于参考方法，并能无缝适应不同的网络拓扑。]]></description>
      <guid>https://arxiv.org/abs/2409.11529</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平衡最优性和多样性：通过生成性策展进行以人为本的决策</title>
      <link>https://arxiv.org/abs/2409.11535</link>
      <description><![CDATA[arXiv:2409.11535v1 公告类型：新
摘要：数据可用性的激增使决策者面临着大量的选择。虽然现有方法侧重于根据可量化指标优化决策，但实际决策通常需要在可衡量的定量标准与更广泛背景下不可衡量的定性因素之间取得平衡。在这种情况下，算法可以生成高质量的建议，但最终的决定权在于人，人必须权衡这两个维度。我们将在这种情况下选择最佳算法建议集的过程定义为以人为中心的决策。为了应对这一挑战，我们引入了一个称为生成性策展的新框架，它通过整合定量和定性方面来优化决策选项的真正可取性。我们的框架使用高斯过程来模拟未知的定性因素，并得出一个平衡定量最优性和定性多样性的多样性指标。这种权衡使得能够生成一组可管理的多样化、接近最优的操作，这些操作对于未知的定性偏好具有鲁棒性。为了使该框架可操作化，我们提出了两种实现方法：一种生成神经网络架构，它产生分布 $\pi$ 以有效地对一组多样化的接近最优的操作进行采样；一种顺序优化方法，它迭代地生成可以轻松纳入复杂优化公式的解决方案。我们用大量数据集验证了我们的方法，证明了它在增强一系列复杂环境中的决策过程方面的有效性，对政策和管理具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2409.11535</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的属性编码器</title>
      <link>https://arxiv.org/abs/2409.11554</link>
      <description><![CDATA[arXiv:2409.11554v1 公告类型：新
摘要：图机器学习，特别是使用图神经网络，从根本上依赖于节点特征。然而，许多现实世界的系统，例如社交网络和生物网络，由于各种原因，包括隐私问题、数据不完整或丢失以及数据收集的限制，往往缺乏节点特征。在这种情况下，研究人员通常采用结构和位置编码等方法来构建节点特征。然而，这些特征的长度取决于被编码属性中的最大值，例如最高节点度，在无标度网络等应用中，该值可能非常大。此外，这些编码方案仅限于分类数据，可能无法对返回其他类型值的指标进行编码。在本文中，我们介绍了一种新颖的、普遍适用的编码器，称为 PropEnc，它可以从任何给定的图形指标构建富有表现力的节点嵌入。PropEnc 利用直方图构造与反向索引编码相结合，为节点特征初始化提供了一种灵活的方法。它支持在维度和输入类型方面进行灵活的编码，证明了其在不同应用中的有效性。PropEnc 允许在低维空间中对指标进行编码，从而有效避免了稀疏性问题并提高了模型的效率。我们表明 \emph{PropEnc} 可以构建节点特征，这些特征要么精确复制独热编码，要么在各种设置下紧密近似索引。我们在缺乏节点特征的多个社交网络的图分类设置中进行了广泛的评估，支持了我们的假设。实证结果最终表明，PropEnc 是一种从各种图指标集构建节点特征的有效机制。]]></description>
      <guid>https://arxiv.org/abs/2409.11554</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>APPFL 的进展：全面且可扩展的联邦学习框架</title>
      <link>https://arxiv.org/abs/2409.11585</link>
      <description><![CDATA[arXiv:2409.11585v1 公告类型：新
摘要：联邦学习 (FL) 是一种分布式机器学习范例，可在保护数据隐私的同时实现协作模型训练。在当今的环境中，大多数数据都是专有、机密和分布式的，FL 已成为有效利用此类数据的一种有前途的方法，特别是在医学和电网等敏感领域。然而，异构性和安全性是 FL 面临的关键挑战；大多数现有的 FL 框架要么未能充分应对这些挑战，要么缺乏纳入新解决方案的灵活性。为此，我们介绍了开发 APPFL 的最新进展，APPFL 是一种可扩展的联邦学习框架和基准测试套件，它为异构性和安全性问题提供了全面的解决方案，以及用于集成新算法或适应新应用程序的用户友好界面。我们通过大量实验评估 FL 的各个方面来展示 APPFL 的功能，包括通信效率、隐私保护、计算性能和资源利用率。我们通过垂直、分层和分散式 FL 的案例研究进一步强调了 APPFL 的可扩展性。APPFL 在 https://github.com/APPFL/APPFL 上开源。]]></description>
      <guid>https://arxiv.org/abs/2409.11585</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自对比前向前向算法</title>
      <link>https://arxiv.org/abs/2409.11593</link>
      <description><![CDATA[arXiv:2409.11593v1 公告类型：新
摘要：前向-前向 (FF) 算法是一种近期的纯前向模式学习方法，它在本地和分层上更新权重，并支持监督和无监督学习。这些特性使其成为大脑启发学习、低功耗硬件神经网络和大型模型分布式学习等应用的理想选择。然而，虽然 FF 在书面数字识别任务上显示出良好的前景，但它在自然图像和时间序列上的表现仍然是一个挑战。一个关键的限制是需要为对比学习生成高质量的反例，特别是在目前缺乏通用解决方案的无监督任务中。为了解决这个问题，我们引入了自对比前向-前向 (SCFF) 方法，该方法受到自监督对比学习的启发。 SCFF 生成适用于不同数据集的正例和反例，在 MNIST（MLP：98.7%）、CIFAR-10（CNN：80.75%）和 STL-10（CNN：77.3%）上的无监督分类准确率超越了现有的局部前向算法。此外，SCFF 是第一个实现循环神经网络 FF 训练的算法，为更复杂的任务和连续时间视频和文本处理打开了大门。]]></description>
      <guid>https://arxiv.org/abs/2409.11593</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kaleidosope：一种具有 Pythonic 语法的 100% 即时神经网络编码语言</title>
      <link>https://arxiv.org/abs/2409.11600</link>
      <description><![CDATA[arXiv:2409.11600v1 公告类型：新
摘要：我们使用 C++、LLVM 和 Cuda 开发了一个用于训练人工神经网络的 jitted 编译器。它具有面向对象的特性、强类型、用于数据预处理的并行工作器、用于表达式的 Pythonic 语法、类似 PyTorch 的模型声明和自动微分。我们实现了缓存和池化机制来管理 VRAM、用于高性能矩阵乘法的 cuBLAS 和用于卷积层的 cuDNN。我们在 ImageNet 上使用残差卷积神经网络进行的实验，我们达到了相似的速度，但性能下降了。此外，GRU 网络实验显示出相似的准确性，但我们的编译器在该任务中的速度降低了。然而，我们的编译器在 CIFAR-10 基准测试中表现出了有希望的结果，我们达到了与 PyTorch 相同的性能和大致相同的速度。我们将代码公开发布在：https://github.com/NoSavedDATA/NoSavedKaleidoscope]]></description>
      <guid>https://arxiv.org/abs/2409.11600</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>