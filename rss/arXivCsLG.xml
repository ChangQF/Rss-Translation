<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Thu, 28 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在线策略分类中的错误、操纵和保证金</title>
      <link>https://arxiv.org/abs/2403.18176</link>
      <description><![CDATA[arXiv:2403.18176v1 公告类型：新
摘要：我们考虑一个在线策略分类问题，其中每个到达的代理可以操纵其真实特征向量以获得正预测标签，同时产生取决于操纵量的成本。学习者试图在仅访问被操纵的特征的情况下预测代理的真实标签。在学习者发布他们的预测后，代理的真实标签就会被揭示。诸如策略感知器之类的先前算法在代理真实特征向量的边际假设下保证了有限的许多错误。然而，这些并不能保证鼓励代理人说实话。促进真实性与获得足够的预测裕度密切相关，因此我们提供了两种新算法，旨在在存在策略代理行为的情况下恢复最大裕度分类器。我们证明了各种代理成本结构的收敛性、有限错误和有限操纵保证。我们还提供了策略感知器的通用版本，并为不同的成本提供了错误保证。我们对真实数据和合成数据的数值研究表明，新算法在余量、操纵数量和错误数量方面优于以前的算法。]]></description>
      <guid>https://arxiv.org/abs/2403.18176</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>HERTA：一种高效、严谨的展开图神经网络训练算法</title>
      <link>https://arxiv.org/abs/2403.18142</link>
      <description><![CDATA[arXiv:2403.18142v1 公告类型：新
摘要：作为图神经网络（GNN）的一种变体，Unfolded GNN 比传统设计提供了增强的可解释性和灵活性。尽管如此，在培训成本方面，他们仍然面临可扩展性的挑战。尽管已经提出了许多方法来解决可扩展性问题，但它们主要关注每次迭代的效率，没有最坏情况的收敛保证。此外，这些方法通常会向原始模型添加组件或修改原始模型，因此可能会破坏 Unfolded GNN 的可解释性。在本文中，我们提出了 HERTA：一种针对 Unfolded GNN 的高效且严格的训练算法，它加速了整个训练过程，实现了近线性时间的最坏情况训练保证。至关重要的是，HERTA 收敛到原始模型的最优值，从而保留了 Unfolded GNN 的可解释性。此外，作为 HERTA 的副产品，我们提出了一种新的谱稀疏化方法，适用于归一化和正则化图拉普拉斯算子，确保我们的算法比现有的谱稀疏化器具有更严格的界限。在真实数据集上的实验验证了 HERTA 的优越性及其对各种损失函数和优化器的适应性。]]></description>
      <guid>https://arxiv.org/abs/2403.18142</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>划分、征服、组合贝叶斯决策树采样</title>
      <link>https://arxiv.org/abs/2403.18147</link>
      <description><![CDATA[arXiv:2403.18147v1 公告类型：新
摘要：决策树由于其灵活性和可解释性而成为常用的预测模型。本文旨在通过采用贝叶斯推理方法来量化决策树预测的不确定性。这是具有挑战性的，因为这些方法需要探索树结构空间和与每个树结构相关的决策参数空间。这是通过使用马尔可夫链蒙特卡罗 (MCMC) 方法来处理的，其中构造马尔可夫链以提供来自所需贝叶斯估计的样本。重要的是，结构和决策参数是紧密耦合的；树结构的微小变化可能需要截然不同的决策参数来提供准确的预测。现有 MCMC 方法面临的挑战是提出树结构和决策参数的联合更改，以实现高效采样。本文采用了不同的方法，其中每个不同的树结构都与一组独特的决策参数相关联。所提出的名为 DCC-Tree 的方法受到 Zhou 等人的工作的启发。 [23] 概率程序和 Cochrane 等人。 [4] 基于哈密顿蒙特卡罗 (HMC) 的决策树采样。结果表明，DCC-Tree 的性能与其他基于 HMC 的方法相当，并且优于现有的贝叶斯树方法，同时提高了一致性并降低了每个提案的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2403.18147</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>哦！我们冻结：通过大型语言模型的信号传播分析改进量化知识蒸馏</title>
      <link>https://arxiv.org/abs/2403.18159</link>
      <description><![CDATA[arXiv:2403.18159v1 公告类型：新
摘要：大型生成模型，例如大型语言模型（LLM）和扩散模型，分别彻底改变了 NLP 和计算机视觉领域。然而，它们的推理速度慢、计算量和内存要求高，使得将它们部署在边缘设备上具有挑战性。在这项研究中，我们提出了一种使用知识蒸馏（KD-QAT）的轻量级量化感知微调技术，以提高 4 位权重量化 LLM 的性能，使用常用数据集在设备聊天应用程序上实现流行的语言用例。为了改进这种微调范式，作为主要贡献，我们通过实证研究训练期间的梯度传播来深入了解 KD-QAT 的稳定性，以更好地理解基于 KD-QAT 的方法在低位量化误差方面的漏洞。根据我们的见解，我们提出了 ov-freeze，这是一种稳定 KD-QAT 过程的简单技术。最后，我们在 4 位量化级别上对流行的 7B LLaMAv2-Chat 模型进行实验，并证明 ov-freeze 可以实现接近浮点精度的性能，即 Commonsense Reasoning 基准上的精度损失小于 0.7%。]]></description>
      <guid>https://arxiv.org/abs/2403.18159</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>保护 GNN 的安全：基于解释的后门训练图识别</title>
      <link>https://arxiv.org/abs/2403.18136</link>
      <description><![CDATA[arXiv:2403.18136v1 公告类型：新
摘要：图神经网络（GNN）在许多领域都得到了普及，但它们很容易受到后门攻击，从而损害其性能和道德应用。这些攻击的检测对于维护 GNN 分类任务的可靠性和安全性至关重要，但缺乏有效的检测技术。经过初步调查，我们观察到，虽然图形级解释可以提供有限的见解，但它们在检测后门触发器方面的有效性不一致且不完整。为了弥补这一差距，我们提取并转换 GNN 解释机制的二次输出，设计了七个新的指标来更有效地检测后门攻击。此外，我们开发了一种自适应攻击来严格评估我们的方法。我们在多个基准数据集上测试我们的方法，并检查其针对各种攻击模型的功效。我们的结果表明，我们的方法可以实现较高的检测性能，标志着在保护 GNN 免受后门攻击方面取得了重大进步。]]></description>
      <guid>https://arxiv.org/abs/2403.18136</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟未来数据推荐无数据类增量学习算法</title>
      <link>https://arxiv.org/abs/2403.18132</link>
      <description><![CDATA[arXiv:2403.18132v1 公告类型：新
摘要：类增量学习处理由批次类组成的顺序数据流。人们提出了各种算法来解决无法存储过去类别的样本的挑战性情况。然而，为用户定义的设置选择合适的算法是一个悬而未决的问题，因为这些算法的相对性能取决于增量设置。为了解决这个问题，我们引入了一种模拟未来数据流的算法推荐方法。给定一组初始类，它利用生成模型来模拟来自同一视觉域的未来类。我们在模拟流上评估最新的算法，并推荐在用户定义的增量设置中表现最佳的算法。我们使用六种算法和六种增量设置在三个大型数据集上说明了我们的方法的有效性。我们的方法优于竞争基线，并且性能接近于在每种设置中选择最佳算法的预言机的性能。这项工作有助于促进增量学习的实际部署。]]></description>
      <guid>https://arxiv.org/abs/2403.18132</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>AE SemRL：使用自动编码器学习语义关联规则</title>
      <link>https://arxiv.org/abs/2403.18133</link>
      <description><![CDATA[arXiv:2403.18133v1 公告类型：新
摘要：关联规则挖掘（ARM）是以逻辑规则的形式学习数据特征之间关联的任务。从高维数值数据（例如智能环境中大量传感器的时间序列数据）中挖掘关联规则是一项计算密集型任务。在本研究中，我们提出了一种基于自动编码器的方法来从时间序列数据（AE SemRL）中学习和提取关联规则。此外，我们认为，在存在与时间序列数据源相关的语义信息的情况下，语义可以促进学习可概括和可解释的关联规则。尽管用额外的语义特征丰富了时间序列数据，但 AE SemRL 使得从高维数据中学习关联规则变得可行。我们的实验表明，可以从自动编码器创建的潜在表示中提取语义关联规则，并且在许多场景中，该方法的执行时间比最先进的 ARM 方法快数百倍。我们相信这项研究提出了一种从表征中提取关联的新方法，并有可能激发该领域的更多研究。]]></description>
      <guid>https://arxiv.org/abs/2403.18133</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>伪对数似然法的修正</title>
      <link>https://arxiv.org/abs/2403.18127</link>
      <description><![CDATA[arXiv:2403.18127v1 公告类型：新
摘要：伪对数似然是一种最大似然估计（MLE）方法，应用于上下文强盗、社交网络影响最大化和因果强盗等各个领域。然而，在之前的文献\citep{li2017provively, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}中，对数似然函数可能不是有界的，这可能导致他们提出的算法没有明确定义。在本文中，我们给出了最大伪对数似然估计失败的反例，然后提供了纠正\citep{li2017provively, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}中算法的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.18127</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>HealthGAT：使用图注意网络的电子健康记录中的节点分类</title>
      <link>https://arxiv.org/abs/2403.18128</link>
      <description><![CDATA[arXiv:2403.18128v1 公告类型：新
摘要：虽然电子健康记录 (EHR) 广泛应用于医疗保健领域的各种应用程序，但大多数应用程序都以其原始（表格）格式使用 EHR。依赖原始或简单的数据预处理可能会极大地限制使用 EHR 的下游任务的性能甚至适用性。为了应对这一挑战，我们提出了 HealthGAT，这是一种新颖的图注意力网络框架，它利用分层方法从 EHR 生成嵌入，超越了传统的基于图的方法。我们的模型迭代地细化医疗代码的嵌入，从而改进 EHR 数据分析。我们还引入了以 EHR 为中心的定制辅助预训练任务，以利用数据中嵌入的丰富医学知识。这种方法提供了对复杂医疗关系的全面分析，并比标准数据表示技术提供了显着的进步。 HealthGAT 通过针对既定方法的综合评估，证明了其在各种医疗保健场景中的有效性。具体来说，我们的模型在节点分类和下游任务（例如预测再入院和诊断分类）中显示出出色的性能。
  我们的代码位于 https://github.com/healthylaife/HealthGAT]]></description>
      <guid>https://arxiv.org/abs/2403.18128</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>双向一致性模型</title>
      <link>https://arxiv.org/abs/2403.18035</link>
      <description><![CDATA[arXiv:2403.18035v1 公告类型：新
摘要：扩散模型（DM）能够通过迭代地对随机向量进行去噪来生成非常高质量的样本，这一过程对应于沿着概率流常微分方程（PF ODE）移动。有趣的是，DM 还可以通过沿着 PF ODE 向后移动，将输入图像反转为噪声，这是插值和图像编辑等下游任务的关键操作。然而，该过程的迭代性质限制了其速度，阻碍了其更广泛的应用。最近，一致性模型 (CM) 的出现通过近似 PF ODE 的积分来解决这一挑战，从而绕过了迭代的需要。然而，缺乏显式 ODE 求解器使反演过程变得复杂。为了解决这个问题，我们引入了双向一致性模型（BCM），它学习单个神经网络，能够沿着 PF ODE 进行向前和向后遍历，从而在一个框架内有效地统一生成和反演任务。值得注意的是，我们提出的方法能够实现一步生成和反演，同时还允许使用额外的步骤来提高生成质量或减少重建误差。此外，通过利用模型的双向一致性，我们引入了一种采样策略，可以增强 FID，同时保留生成的图像内容。我们进一步展示了我们的模型在插值和修复等几个下游任务中的功能，并展示了潜在应用，包括压缩图像的盲恢复和防御黑盒对抗攻击。]]></description>
      <guid>https://arxiv.org/abs/2403.18035</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>成像和视觉扩散模型教程</title>
      <link>https://arxiv.org/abs/2403.18103</link>
      <description><![CDATA[arXiv:2403.18103v1 公告类型：新
摘要：近年来，生成工具的惊人增长为文本到图像生成和文本到视频生成方面的许多令人兴奋的应用提供了支持。这些生成工具背后的基本原理是扩散的概念，这是一种特殊的采样机制，它克服了以前的方法中被认为难以解决的一些缺点。本教程的目标是讨论扩散模型的基本思想。本教程的目标受众包括对扩散模型研究或应用这些模型解决其他问题感兴趣的本科生和研究生。]]></description>
      <guid>https://arxiv.org/abs/2403.18103</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>混合人工智能和自然智能：从统计力学到人工智能，再回到湍流</title>
      <link>https://arxiv.org/abs/2403.17993</link>
      <description><![CDATA[arXiv:2403.17993v1 公告类型：新
摘要：本文反思了人工智能在科学研究中的未来作用，特别关注湍流研究，并研究了人工智能的演变，特别是通过植根于非平衡统计力学的扩散模型。它强调了人工智能通过深度神经网络的创新使用对推进简化的拉格朗日湍流模型的重大影响。此外，本文还回顾了人工智能在湍流研究中的各种其他应用，并概述了人工智能和统计流体动力学并行发展的潜在挑战和机遇。这次讨论为人工智能和湍流研究错综复杂地交织在一起的未来奠定了基础，从而在这两个领域带来更深刻的见解和进步。]]></description>
      <guid>https://arxiv.org/abs/2403.17993</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>从部分观测预测物种出现模式</title>
      <link>https://arxiv.org/abs/2403.18028</link>
      <description><![CDATA[arXiv:2403.18028v1 公告类型：新
摘要：为了解决相互关联的生物多样性和气候危机，我们需要了解物种出现的地点以及这些模式是如何变化的。然而，大多数物种的观测数据仍然非常有限，并且不同分类组之间的可用数据量差异很大。我们介绍了在给定（a）卫星图像和（b）有关其他物种出现的已知信息的情况下预测物种出现模式的问题。为了评估此任务的算法，我们引入了 SatButterfly，这是一个卫星图像、环境数据和蝴蝶观测数据的数据集，旨在与现有的鸟类观测数据 SatBird 数据集配对。为了解决这一任务，我们提出了一个通用模型 R-Tran，用于预测物种出现模式，该模型可以使用发现的部分观测数据。我们发现 R-Tran 在预测物种遭遇率方面优于其他方法，无论是在分类单元内（鸟类）还是跨分类单元（鸟类和蝴蝶）的部分信息。我们的方法开辟了新的视角，通过对它们共存的生态系统进行建模，利用从具有丰富数据的物种到其他具有稀缺数据的物种的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.18028</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>排序和切片：用于扩展连接指纹的基于哈希的折叠的简单而卓越的替代方案</title>
      <link>https://arxiv.org/abs/2403.17954</link>
      <description><![CDATA[arXiv:2403.17954v1 公告类型：新
摘要：扩展连接指纹（ECFP）是当前化学信息学和分子机器学习中普遍存在的工具，也是用于化学预测的最流行的分子特征提取技术之一。图神经网络学习到的原子特征可以使用大量图池方法聚合为复合级表示；相反，默认情况下，仅使用简单的基于哈希的折叠过程将检测到的 ECFP 子结构集转换为位向量。我们通过称为子结构池的形式操作引入了一个通用数学框架，用于结构指纹的矢量化，其中包括基于哈希的折叠、算法子结构选择和各种其他潜在技术。我们继续描述 Sort &amp; Slice，这是一种易于实现且无位冲突的替代方案，可替代基于哈希的折叠，用于 ECFP 子结构的池化。 Sort &amp; Slice 首先根据 ECFP 子结构在给定训练化合物集中的相对流行程度进行排序，然后切掉除 $L$ 最常见的子结构之外的所有子结构，这些子结构随后用于生成所需长度 $L$ 的二进制指纹。我们通过计算比较了基于哈希的折叠、排序和切片以及用于基于 ECFP 的分子属性预测的两种高级监督子结构选择方案（过滤和互信息最大化）的性能。我们的结果表明，尽管技术简单，Sort &amp; Slice 的性能（有时甚至大幅）优于传统的基于哈希的折叠以及其他在预测任务、数据分割技术、机器学习模型和 ECFP 超参数方面研究的方法。因此，我们建议 Sort &amp; Slice 规范地取代基于哈希的折叠作为默认的子结构池技术，以矢量化 ECFP 以进行监督分子机器学习。]]></description>
      <guid>https://arxiv.org/abs/2403.17954</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>具有时间注意力的深度生成域适应用于跨用户活动识别</title>
      <link>https://arxiv.org/abs/2403.17958</link>
      <description><![CDATA[arXiv:2403.17958v1 公告类型：新
摘要：在人类活动识别（HAR）中，一个主要假设是用于训练和评估目的的数据来自相同的分布。还假设所有数据样本都是独立且同分布的 ($\displaystyle i.i.d.$)。相反，实际实现常常挑战这一概念，表现出数据分布差异，特别是在跨用户 HAR 等场景中。域适应是解决跨用户 HAR 任务中固有的这些挑战的有前途的方法。然而，域适应技术的一个明显差距是在对齐数据分布阶段忽略了嵌入时间序列数据中的时间关系。为了解决这一疏忽，我们的研究提出了具有时间注意力的深度生成域适应（DGDATA）方法。这种新颖的方法在域适应过程中独特地识别和集成时间关系。通过将生成模型的功能与时间关系注意力机制相结合，我们的方法提高了跨用户 HAR 的分类性能。针对不同场景和应用，对三个基于公共传感器的 HAR 数据集进行了综合评估，以证明所提出的 DGDATA 方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.17958</guid>
      <pubDate>Thu, 28 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    </channel>
</rss>