<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Thu, 01 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过校准的视角理解不变风险最小化的变体</title>
      <link>https://arxiv.org/abs/2401.17541</link>
      <description><![CDATA[机器学习模型传统上假设训练和测试数据是独立且同分布的。然而，在实际应用中，测试分布通常与训练分布不同。这个问题被称为分布外泛化，对传统模型提出了挑战。不变风险最小化（IRM）作为一种解决方案出现，旨在识别不同环境中不变的特征，以增强分布外的鲁棒性。然而，IRM的复杂性，特别是其双层优化，导致了各种近似方法的发展。我们的研究研究了这些近似 IRM 技术，采用预期校准误差 (ECE) 作为关键指标。 ECE衡量模型预测的可靠性，作为模型是否有效捕获环境不变特征的指标。通过对具有分布变化的数据集的比较分析，我们观察到基于信息瓶颈的IRM压缩了表征信息，在提高ECE和相对保持准确性方面取得了平衡。这一发现至关重要，因为它展示了在不影响准确性的情况下保持鲁棒性的可行途径。尽管如此，我们的实验也警告不要过度正则化，这可能会降低准确性。这强调了评估分布外泛化指标的系统性方法的必要性，这种方法不仅限于准确性，还需要解决准确性和校准之间微妙的相互作用。]]></description>
      <guid>https://arxiv.org/abs/2401.17541</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:34 GMT</pubDate>
    </item>
    <item>
      <title>数据有效学习：综合医学基准</title>
      <link>https://arxiv.org/abs/2401.17542</link>
      <description><![CDATA[数据有效学习旨在以最有影响力的方式使用数据来训练人工智能模型，其中涉及注重数据质量而不是数量的策略，确保用于训练的数据具有较高的信息价值。数据有效学习在加速人工智能训练、降低计算成本和节省数据存储方面发挥着深远的作用，这在近年来医疗数据量增长超出许多人的预期的情况下非常重要。然而，由于缺乏标准和综合基准，医学数据有效学习的研究还很少。为了解决这一差距，我们的论文引入了一个专门用于评估医学领域数据有效学习的综合基准。该基准包括来自 31 个医疗中心的数百万数据样本的数据集 (DataDEL)、比较基线方法 (MedDEL) 和新的评估指标 (NormDEL)，以客观地衡量数据有效的学习绩效。我们广泛的实验结果表明，基线 MedDEL 仅需 5% 的数据即可实现与原始大型数据集相当的性能。建立这样一个开放的数据有效的学习基准对于医学人工智能研究社区至关重要，因为它有助于有效的数据使用，促进协作突破，并促进开发具有成本效益、可扩展和有影响力的医疗保健解决方案。该项目可以通过 https://github.com/shadow2469/Data-Effective-Learning-A-Compressive-Medical-Benchmark.git 访问。]]></description>
      <guid>https://arxiv.org/abs/2401.17542</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:34 GMT</pubDate>
    </item>
    <item>
      <title>博弈论无法学习的示例生成器</title>
      <link>https://arxiv.org/abs/2401.17523</link>
      <description><![CDATA[不可学习的示例攻击是数据中毒攻击，旨在通过向训练样本添加难以察觉的扰动来降低深度学习的干净测试准确性，这可以表述为双层优化问题。然而，对于深度神经网络来说，直接解决这个优化问题是很困难的。在本文中，我们通过将攻击表述为非零和 Stackelberg 博弈，从博弈论的角度研究了不可学习的示例攻击。首先，证明了正常设置和对抗训练设置下博弈均衡的存在。结果表明，当使用某些损失函数时，博弈平衡给出了最强大的毒害攻击，因为受害者在同一假设空间内的所有网络中具有最低的测试精度。其次，我们提出了一种新颖的攻击方法，称为游戏不可学习示例（GUE），它具有三个主要梯度。 (1) 毒物是通过用一阶算法直接求解Stackelberg博弈的均衡而得到的。 (2) 我们采用类似自动编码器的生成网络模型作为毒攻击者。 (3)引入了一种新颖的支付函数来评估毒药的性能。综合实验表明，GUE可以在各种场景下有效地毒害模型。此外，GUE 仍然使用相对较小比例的训练数据来训练生成器，并且毒物生成器可以很好地泛化到未见过的数据。我们的实现代码可以在https://github.com/hong-xian/gue找到。]]></description>
      <guid>https://arxiv.org/abs/2401.17523</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:33 GMT</pubDate>
    </item>
    <item>
      <title>使用集成增强基于分数的采样方法</title>
      <link>https://arxiv.org/abs/2401.17539</link>
      <description><![CDATA[我们在基于分数的采样方法中引入了集成，以开发无梯度近似采样技术，该技术利用粒子集成的集体动力学来计算近似反向扩散漂移。我们介绍了基本方法，强调了它与生成扩散模型和之前介绍的 F\&quot;ollmer 采样器的关系。我们通过各种示例证明了集成策略的有效性，范围从低维到中维采样问题，包括多模态和高度非高斯概率分布，并与 NUTS 等传统方法进行比较。我们的研究结果强调了集成策略在梯度不可用的情况下对复杂概率分布进行建模的潜力。最后，我们展示了其在贝叶斯反演问题中的应用地球物理科学。]]></description>
      <guid>https://arxiv.org/abs/2401.17539</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:33 GMT</pubDate>
    </item>
    <item>
      <title>渲染对梯度估计器有用的无线环境：一种零阶随机联邦学习方法</title>
      <link>https://arxiv.org/abs/2401.17460</link>
      <description><![CDATA[联邦学习 (FL) 是一种新颖的机器学习方法，允许多个边缘设备协作训练模型，而无需公开其原始数据。然而，一些挑战阻碍了这种方法的实际实施，特别是当设备和服务器通过无线通道进行通信时，因为在这种情况下它会遇到通信和计算瓶颈。通过利用通信高效的框架，我们提出了一种带有单点梯度估计器的新型零阶（ZO）方法，该方法利用无线通信信道的性质，而无需了解信道状态系数。这是第一种将无线信道纳入学习算法本身的方法，而不是浪费资源来分析它并消除其影响。这项工作的两个主要困难是，在 FL 中，目标函数通常不是凸的，这使得将 FL 扩展到 ZO 方法具有挑战性，并且需要额外注意包括无线信道的影响。然而，我们克服了这些困难并全面分析了所提出的零阶联邦学习（ZOFL）框架。我们从理论上建立了它的收敛性，并证明了非凸设置下的收敛率为 $O(\frac{1}{\sqrt[3]{K}})$。我们通过实验结果进一步证明了我们的算法的潜力，同时考虑了独立同分布（IID）和非 IID 设备数据分布。]]></description>
      <guid>https://arxiv.org/abs/2401.17460</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:32 GMT</pubDate>
    </item>
    <item>
      <title>CaMU：解开深度模型遗忘中的因果效应</title>
      <link>https://arxiv.org/abs/2401.17504</link>
      <description><![CDATA[机器遗忘需要去除遗忘数据的信息，同时保留剩余数据的必要信息。尽管该领域最近取得了进展，但现有的方法主要关注删除遗忘数据的效果，而没有考虑这可能对剩余数据的信息产生的负面影响，导致数据删除后性能显着下降。尽管有些方法尝试修复删除后剩余数据的性能，但被遗忘的信息也可以在修复后返回。这样的问题是由于遗忘数据和剩余数据错综复杂的交织造成的。如果没有充分区分这两种数据对模型的影响，现有算法就会面临无法充分去除遗忘数据或从剩余数据中不必要地丢失有价值信息的风险。为了解决这个缺点，本研究对遗忘进行了因果分析，并引入了一种称为因果机器遗忘（CaMU）的新颖框架。该框架增加了对剩余数据信息的干预，以理清遗忘数据和剩余数据之间的因果关系。然后，CaMU 消除与遗忘数据相关的因果影响，同时保留剩余数据的因果相关性。对各种数据集和模型的综合实证结果表明，CaMU 增强了剩余数据的性能，并有效地最小化了遗忘数据的影响。值得注意的是，这项工作首次从因果关系的新角度解释深度模型遗忘任务，并提供基于因果分析的解决方案，为深度模型遗忘的未来研究开辟了新的可能性。]]></description>
      <guid>https://arxiv.org/abs/2401.17504</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:32 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的时间之箭</title>
      <link>https://arxiv.org/abs/2401.17505</link>
      <description><![CDATA[我们从时间方向性的角度研究自回归大型语言模型执行的概率建模。我们凭经验发现此类模型在模拟自然语言的能力方面表现出时间不对称性：尝试预测下一个标记与尝试预测前一个标记时的平均对数困惑度存在差异。这种差异同时是微妙的，并且在各种模式（语言、模型大小、训练时间……）中非常一致。从理论上讲，这是令人惊讶的：从信息论的角度来看，不应该存在这样的差异。我们提供了一个理论框架来解释这种不对称性是如何从稀疏性和计算复杂性的考虑中出现的，并概述了我们的结果所带来的一些观点。]]></description>
      <guid>https://arxiv.org/abs/2401.17505</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:32 GMT</pubDate>
    </item>
    <item>
      <title>通过揭示二阶效应来解释预测不确定性</title>
      <link>https://arxiv.org/abs/2401.17441</link>
      <description><![CDATA[可解释的人工智能为复杂的机器学习黑匣子带来了透明度，特别是能够识别这些模型用于预测的特征。到目前为止，解释预测不确定性的问题，即模型为何“怀疑”，还很少被研究。我们的调查表明，预测不确定性主要由二阶效应主导，涉及单一特征或它们之间的产品相互作用。我们贡献了一种新方法来解释基于这些二阶效应的预测不确定性。在计算上，我们的方法简化为对一阶解释集合的简单协方差计算。我们的方法是普遍适用的，允许将常见的归因技术（LRP、梯度 x 输入等）转变为强大的二阶不确定性解释器，我们称之为 CovLRP、CovGI 等。我们的方法产生的解释的准确性通过以下方式证明：系统的定量评估，我们的方法的整体实用性通过两个实际展示得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2401.17441</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:31 GMT</pubDate>
    </item>
    <item>
      <title>用于低成本集成修剪的流动民主</title>
      <link>https://arxiv.org/abs/2401.17443</link>
      <description><![CDATA[我们认为，集成学习和委托投票范式（流动民主）之间存在密切联系，可以利用它来降低集成培训成本。我们提出了一种增量训练程序，通过受流动民主启发的委托机制，从集合中识别并删除冗余分类器。通过分析和广泛的实验，我们表明，与训练完整的集成相比，这个过程大大降低了训练的计算成本。通过仔细选择底层委托机制，可以避免分类器群体中的权重集中，从而比某些提升方法具有更高的准确性。此外，这项工作是如何将计算社会选择文献中的框架应用于非传统领域问题的范例。]]></description>
      <guid>https://arxiv.org/abs/2401.17443</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:31 GMT</pubDate>
    </item>
    <item>
      <title>多头注意力在上下文线性回归中的优越性</title>
      <link>https://arxiv.org/abs/2401.17426</link>
      <description><![CDATA[我们对具有 softmax 注意力的 Transformer 在线性回归任务的上下文学习中的性能进行了理论分析。虽然现有文献主要关注变压器与单头/多头注意力的融合，但我们的研究重点是比较它们的性能。我们进行了精确的理论分析，证明具有大量嵌入维度的多头注意力比单头注意力表现更好。当上下文示例 D 的数量增加时，使用单头/多头注意力的预测损失为 O(1/D)，并且多头注意力的预测损失具有较小的乘法常数。除了最简单的数据分布设置之外，我们还考虑更多场景，例如噪声标签、局部示例、相关特征和先验知识。我们观察到，一般来说，多头注意力优于单头注意力。我们的结果验证了 Transformer 架构中多头注意力设计的有效性。]]></description>
      <guid>https://arxiv.org/abs/2401.17426</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:30 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以取代经济选择预测实验室吗？</title>
      <link>https://arxiv.org/abs/2401.17435</link>
      <description><![CDATA[经济选择预测是一项重要的挑战性任务，通常受到获取人类选择数据的困难的限制。事实上，实验经济学研究主要集中在简单的选择设置上。人工智能社区最近以两种方式为这一努力做出了贡献：考虑法学硕士是否可以在上述简单选择预测设置中替代人类，以及通过机器学习镜头进行更详细但仍然严格的实验经济学设置的研究，采用不完整的信息，重复游戏和自然语言交流，特别是基于语言的说服游戏。这给我们一个重大启发：法学硕士是否可以用来完全模拟经济环境并生成数据以进行高效的人类选择预测，从而替代复杂的经济实验室研究？我们开创了该课题的研究，证明了其可行性。特别是，我们表明，仅根据法学硕士生成的数据训练的模型可以有效地预测基于语言的说服游戏中的人类行为，甚至可以优于根据实际人类数据训练的模型。]]></description>
      <guid>https://arxiv.org/abs/2401.17435</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:30 GMT</pubDate>
    </item>
    <item>
      <title>通过 Deep Black Litterman 模型优化时序供应商分配风险</title>
      <link>https://arxiv.org/abs/2401.17350</link>
      <description><![CDATA[我们引入 BL 模型和透视矩阵来优化供应商选择和订单分配，重点关注时间和空间动态。我们使用时空图神经网络开发供应商关系网络，增强了对复杂供应商相互依赖性的理解。此外，我们通过屏蔽排名机制解决零阶场景下的可信度问题，提高供应商排名效率。与传统模型相比，我们的模型在两个数据集上表现出了更好的结果。我们使用真实数据集进行的评估凸显了 DBLM 在提供准确预测和精确置信区间方面的优势，特别是在高分辨率场景中。]]></description>
      <guid>https://arxiv.org/abs/2401.17350</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:29 GMT</pubDate>
    </item>
    <item>
      <title>持续学习的步长优化</title>
      <link>https://arxiv.org/abs/2401.17401</link>
      <description><![CDATA[在持续学习中，学习者必须在一生中不断从数据中学习。一个关键问题是决定保留哪些知识以及放弃哪些知识。在神经网络中，这可以通过使用步长向量来缩放梯度样本改变网络权重的程度来实现。 RMSProp 和 Adam 等常见算法使用启发法（特别是归一化）来适应此步长向量。在本文中，我们表明这些启发式方法忽略了它们的适应对整体目标函数的影响，例如通过将步长向量移离更好的步长向量。另一方面，随机元梯度下降算法，如 IDBD (Sutton, 1992)，显式优化相对于整体目标函数的步长向量。在简单问题上，我们证明 IDBD 能够持续改进步长向量，而 RMSProp 和 Adam 则不能。我们解释了两种方法之间的差异及其各自的局限性。我们的结论是，结合这两种方法可能是提高神经网络在持续学习中的性能的一个有前途的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2401.17401</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:29 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习解决玻尔兹曼优化问题</title>
      <link>https://arxiv.org/abs/2401.17408</link>
      <description><![CDATA[高性能计算 (HPC) 效率数十年的指数级扩展即将结束。互补金属氧化物半导体 (CMOS) 技术中基于晶体管的逻辑正在接近物理极限，超过该极限就不可能进一步小型化。未来 HPC 效率的提高必然依赖于新技术和计算范式。伊辛模型显示出作为未来高能效计算框架的特殊前景。 Ising 系统能够在接近计算能耗热力学极限的能量下运行。 Ising 系统既可以充当逻辑系统，也可以充当存储器。因此，它们有可能通过消除昂贵的数据移动来显着降低 CMOS 计算固有的能源成本。创建基于 Ising 的硬件的挑战在于优化有用的电路，以便在根本上不确定的硬件上产生正确的结果。本文的贡献是一种新颖的机器学习方法，结合了深度神经网络和随机森林，用于有效解决优化问题，最大限度地减少伊辛模型中的误差源。此外，我们提供了将玻尔兹曼概率优化问题表示为监督机器学习问题的过程。]]></description>
      <guid>https://arxiv.org/abs/2401.17408</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:29 GMT</pubDate>
    </item>
    <item>
      <title>用于增强地球观测数据预测置信度的潜在空间度量</title>
      <link>https://arxiv.org/abs/2401.17342</link>
      <description><![CDATA[这项研究提出了一种估计机器学习模型预测置信度的新方法，特别是在利用地球观测（EO）数据的回归任务中，特别关注蚊子丰度（MA）估计。我们利用变分自动编码器架构，通过 EO 数据集的潜在空间表示导出置信度度量。该方法对于建立潜在表示中的欧几里得距离与单个 MA 预测中的绝对误差 (AE) 之间的相关性至关重要。我们的研究重点是意大利威尼托地区和德国莱茵河上游河谷的 EO 数据集，目标是受蚊子种群影响严重的地区。一个重要发现是 MA 预测的 AE 与所提出的置信度指标之间存在 0.46 的显着相关性。这种相关性意味着一种强大的新指标，可以在 EO 数据分析和蚊子丰度研究的背景下量化人工智能模型的预测可靠性并增强其可信度。]]></description>
      <guid>https://arxiv.org/abs/2401.17342</guid>
      <pubDate>Thu, 01 Feb 2024 12:23:28 GMT</pubDate>
    </item>
    </channel>
</rss>