<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 31 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>离线强化学习的数据集提炼</title>
      <link>https://arxiv.org/abs/2407.20299</link>
      <description><![CDATA[arXiv:2407.20299v1 公告类型：新
摘要：离线强化学习通常需要一个高质量的数据集，我们可以基于该数据集训练策略。然而，在许多情况下，不可能获得这样的数据集，也不可能轻易训练出在给定离线数据的实际环境中表现良好的策略。我们建议使用数据蒸馏来训练和蒸馏更好的数据集，然后将其用于训练更好的策略模型。我们表明，我们的方法能够合成一个数据集，在该数据集上训练的模型实现的性能与在完整数据集上训练的模型或使用百分位行为克隆训练的模型相似。我们的项目网站位于 https://datasetdistillation4rl.github.io。我们还在此 GitHub 存储库中提供了我们的实现：https://github.com/ggflow123/DDRL。]]></description>
      <guid>https://arxiv.org/abs/2407.20299</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>使用超网络和对抗性投资组合设计时间序列模型</title>
      <link>https://arxiv.org/abs/2407.20352</link>
      <description><![CDATA[arXiv:2407.20352v1 公告类型：新
摘要：本文介绍了在 M6 竞赛的预测和投资挑战中分别获得第 4 名和第 6 名的方法，最终在两项全能比赛中获得了第一名。在预测挑战中，我们测试了一种新颖的元学习模型，该模型利用超网络设计针对特定预测任务系列的参数模型。这种方法使我们能够利用在各个预测任务中观察到的相似性，同时也承认它们的数据生成过程中可能存在的异质性。该模型的训练可以直接通过反向传播进行，无需依赖高阶导数，相当于同时搜索参数函数空间及其最佳参数值。所提出的模型的功能超越了 M6，在正弦回归任务中表现出优于最先进的元学习方法的优势，并且在 M4 竞赛的时间序列上优于传统的参数模型。在投资挑战中，我们根据当前排名调整投资组合权重，以增加或减少我们提交的作品与其他参与者的作品之间的相关性，旨在最大限度地提高获得良好排名的概率。]]></description>
      <guid>https://arxiv.org/abs/2407.20352</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>从像素到规划：无标度主动推理</title>
      <link>https://arxiv.org/abs/2407.20292</link>
      <description><![CDATA[arXiv:2407.20292v1 公告类型：新
摘要：本文介绍了一种用于生成建模的离散状态空间模型及其相关方法。该模型将部分观察到的马尔可夫决策过程概括为将路径作为潜在变量，使其适用于动态环境中的主动推理和学习。具体而言，我们使用重正化群来考虑深度或分层形式。随后的重正化生成模型 (RGM) 可以被视为深度卷积神经网络的离散同源体或广义运动坐标中的连续状态空间模型。通过构造，这些尺度不变模型可用于学习空间和时间的组合性，提供路径或轨道模型；即时间深度和巡回性不断增加的事件。本技术说明说明了使用一系列应用程序自动发现、学习和部署 RGM。我们从图像分类开始，然后考虑电影和音乐的压缩和生成。最后，我们将相同的变分原理应用于类似 Atari 的游戏的学习。]]></description>
      <guid>https://arxiv.org/abs/2407.20292</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>用于化学任务的贝叶斯流网络框架</title>
      <link>https://arxiv.org/abs/2407.20294</link>
      <description><![CDATA[arXiv:2407.20294v1 公告类型：新
摘要：在这项工作中，我们引入了 ChemBFN，这是一种基于处理离散数据的贝叶斯流网络处理化学任务的语言模型。提出了一种新的准确度计划，通过显着降低重建损失来提高采样质量。我们证明了即使使用较少数量的采样步骤，我们的方法也适用于生成具有满意多样性的分子。无分类器指导方法适用于条件生成。还值得指出的是，经过生成训练后，我们的模型可以在回归和分类任务上进行微调，并具有最先进的性能，这为以单一模块风格构建一体化模型打开了大门。我们的模型已在 https://github.com/Augus1999/bayesian-flow-network-for-chemistry 上开源。]]></description>
      <guid>https://arxiv.org/abs/2407.20294</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>西澳大利亚西南部高分辨率网格风预报的时空方法</title>
      <link>https://arxiv.org/abs/2407.20283</link>
      <description><![CDATA[arXiv:2407.20283v1 公告类型：新
摘要：准确的风速和风向预报对农业、可再生能源发电和丛林火灾管理等许多领域都至关重要。然而，传统的预测模型在精确预测单个位置或小地理区域（&lt; 20 平方公里）的高空间分辨率风况以及捕捉中长期时间趋势和综合时空模式方面遇到了重大挑战。本研究重点研究了西澳大利亚西南部大片地区 3 米和 10 米高度的高分辨率网格风预报的时空方法，以克服这些挑战。该模型利用覆盖广阔地理区域的数据，并利用各种气象因素，包括地形特征、气压、欧洲中期天气预报中心的 10 米风速预报，以及来自分散气象站的有限观测数据（例如 3 米风速剖面、湿度和温度），该模型在整个关注区域的风速预报准确性和可靠性方面取得了令人鼓舞的进步。本文展示了我们的机器学习模型在各种预测范围和空间覆盖范围内进行风速预报的潜力。它可以帮助促进更明智的决策并增强关键部门的复原力。]]></description>
      <guid>https://arxiv.org/abs/2407.20283</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>基于监督学习的漏电流测量架空线路绝缘子状态监测方法</title>
      <link>https://arxiv.org/abs/2407.20288</link>
      <description><![CDATA[arXiv:2407.20288v1 公告类型：新 
摘要：作为解决架空线路（OHL）资产老化问题的一种新的实用且经济的解决方案，世界上大多数电网公司的技术政策都经历了从定期预防性维护到基于风险的资产管理方法的逐步过渡。尽管污染的积累在一定程度上是可以预测的，但目前还没有有效的方法来识别绝缘子闪络的风险以计划其更换。本文提出了一种基于机器学习（ML）的新型方法，用于估计杯针玻璃绝缘子串的闪络概率。所提出的方法基于极限梯度提升（XGBoost）监督ML模型，其中漏电流（LC）特征和施加电压用作输入。建立的模型可以估算不同电压等级的各种OHL绝缘子的临界闪络电压（U50％）。所提出的方法还能够准确确定绝缘子串的状况并指导资产管理工程师采取适当的措施。]]></description>
      <guid>https://arxiv.org/abs/2407.20288</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>使用可解释的人工智能探索仇恨言论和反制言论检测器的可行性</title>
      <link>https://arxiv.org/abs/2407.20274</link>
      <description><![CDATA[arXiv:2407.20274v1 公告类型：新
摘要：在本文中，我们研究了 Transformer 模型的可解释性及其在仇恨言论和反言论检测中的合理性。我们比较了四种不同可解释性方法的代表，即基于梯度、基于扰动、基于注意力和基于原型的方法，并通过消融研究对其进行定量分析，并在用户研究中对其进行定性分析。结果表明，基于扰动的可解释性表现最佳，其次是基于梯度和基于注意力的可解释性。基于原型的实验没有产生有用的结果。总体而言，我们观察到可解释性强烈支持用户更好地理解模型预测。]]></description>
      <guid>https://arxiv.org/abs/2407.20274</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>通过热启动神经架构搜索中的超网络迁移实现稳健而高效的迁移学习</title>
      <link>https://arxiv.org/abs/2407.20279</link>
      <description><![CDATA[arXiv:2407.20279v1 公告类型：新
摘要：手工设计神经网络是一个繁琐的过程，需要大量的专业知识。神经架构搜索 (NAS) 框架提供了一种非常有用且流行的解决方案，有助于实现人工智能的民主化。然而，这些 NAS 框架的运行通常需要耗费大量的计算资源，这限制了它们的适用性和可访问性。在本文中，我们提出了一种新颖的迁移学习方法，能够有效地迁移基于最佳传输或多数据集预处理的预训练超网络。该方法可以普遍应用于基于可微分架构搜索 (DARTS) 的 NAS 方法。通过在数十个图像分类任务中进行的大量实验，我们证明以这种方式传输预训练的超网络不仅可以大大加快超网络训练的速度，从而找到最佳模型（平均快 3 到 5 倍），甚至可以产生优于从头开始运行 DARTS 方法时发现的结果。我们还观察到几乎所有目标数据集的正迁移，使其非常健壮。这除了大大提高NAS方法的适用性之外，还为持续学习和相关领域开辟了新的应用。]]></description>
      <guid>https://arxiv.org/abs/2407.20279</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>NeuSemSlice：通过神经元级语义切片实现有效的 DNN 模型维护</title>
      <link>https://arxiv.org/abs/2407.20281</link>
      <description><![CDATA[arXiv:2407.20281v1 公告类型：新
摘要：深度神经网络 (DNN) 广泛应用于各个学科，其特点是集成和单片架构，与传统软件系统不同。这种架构差异给维护任务带来了特殊挑战，例如模型重构（例如模型压缩）、重新适应（例如拟合新样本）和增量开发（例如持续知识积累）。先前的研究通过识别任务关键型神经元层并将神经网络划分为语义相似的顺序模块来解决这些挑战。然而，这种层级方法无法准确识别和操纵神经元级语义组件，限制了它们在更细粒度的模型维护任务中的适用性。在这项工作中，我们实现了 NeuSemSlice，这是一个新颖的框架，它引入了语义切片技术，可以有效地识别 DNN 模型中关键的神经元级语义组件，以执行语义感知模型维护任务。具体而言，语义切片根据语义相似性识别、分类和合并不同类别和层中的关键神经元，从而使其在后续任务中具有灵活性和有效性。对于语义感知模型维护任务，我们提供了一系列基于语义切片的新策略来增强 NeuSemSlice。它们包括用于模型重构的语义组件（即关键神经元）保存、用于模型重新适应的关键神经元调整以及用于模型增量开发的非关键神经元训练。全面的评估表明，NeuSemSlice 在这三个任务中的表现都明显优于基线。]]></description>
      <guid>https://arxiv.org/abs/2407.20281</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>化学语言基础模型的大型编码器-解码器系列</title>
      <link>https://arxiv.org/abs/2407.20267</link>
      <description><![CDATA[arXiv:2407.20267v1 公告类型：新
摘要：化学语言模型的大规模预训练方法代表了化学信息学的突破。这些方法通过在大型未标记语料库上进行自监督学习来学习输入标记的语境化表示，从而在属性预测和分子生成等任务中表现出色。通常，这涉及对未标记数据进行预训练，然后对特定任务进行微调，减少对注释数据集的依赖并拓宽化学语言表示理解。本文介绍了一种大型编码器-解码器化学基础模型，该模型在来自 PubChem 的 9100 万个 SMILES 样本的精选数据集上进行了预训练，相当于 40 亿个分子标记。所提出的基础模型支持不同的复杂任务，包括量子属性预测，并通过两种主要变体（289M 和 $8\times289M$）提供灵活性。我们在多个基准数据集上进行的实验验证了所提出的模型在为不同任务提供最佳结果方面的能力。我们还对嵌入空间的组合性进行了初步评估，这是推理任务的先决条件。我们证明，与具有少量学习能力的最佳方法相比，生成的潜在空间是可分离的。]]></description>
      <guid>https://arxiv.org/abs/2407.20267</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>边学边忘：生成语言模型的迭代忘学框架</title>
      <link>https://arxiv.org/abs/2407.20271</link>
      <description><![CDATA[arXiv:2407.20271v1 公告类型：新
摘要：机器学习，尤其是自然语言处理 (NLP) 领域的最新进展，导致了在大量数据集上训练的复杂模型的开发，但这一进展引发了对潜在敏感信息泄露的担忧。作为回应，欧盟通用数据保护条例 (GDPR) 等监管措施推动了机器反学习技术的探索，旨在使模型能够有选择地忘记某些数据条目。虽然早期的方法侧重于预处理方法，但最近的研究已转向基于训练的机器反学习方法。然而，许多现有的方法需要访问原始训练数据，这在无法获得此类数据的情况下带来了挑战。此外，直接促进反学习可能会削弱语言模型的一般表达能力。为此，在本文中，我们引入了迭代对比反学习 (ICU) 框架，该框架通过结合三个关键组件来解决这些挑战。我们提出了一个知识反学习诱导模块，用于反学习特定目标序列，以及一个对比学习增强模块，以防止生成能力下降。此外，还集成了一个迭代反学习细化模块，使该过程更适应每个目标样本。实验结果证明了 ICU 在保持性能的同时有效反学习敏感信息的有效性，为注重隐私的机器学习应用提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2407.20271</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>COEFF-KANs：利用 KAN 解决电解质场的范例</title>
      <link>https://arxiv.org/abs/2407.20265</link>
      <description><![CDATA[arXiv:2407.20265v1 公告类型：新 
摘要：为减少化学研究人员的实验验证工作量，加速高能量密度锂金属电池的设计和优化，我们旨在利用模型根据液体电解质的组成自动预测库仑效率（CE）。现有方法主要有两种代表性范式：机器学习和深度学习。然而，前者需要智能的输入特征选择和可靠的计算方法，导致从特征估计到模型预测的误差传播，而后者（例如MultiModal-MoLFormer）由于增强数据的多样性有限而面临预测性能差和过度拟合的挑战。为了解决这些问题，我们提出了一种新方法COEFF（通过微调模型进行库仑效率预测），该方法包括两个阶段：预训练化学通用模型和对下游域数据进行微调。首先，我们采用公开的 MoLFormer 模型来获取电解质中每种溶剂和盐的特征向量。然后，我们对所有分子中的每个标记进行嵌入加权平均，权重由相应的电解质成分比决定。最后，我们将获得的电解质特征输入多层感知器或 Kolmogorov-Arnold 网络来预测 CE。在真实数据集上的实验结果表明，与所有基线相比，我们的方法在预测 CE 方面实现了 SOTA。本文中使用的数据和代码将在论文发表后公开。]]></description>
      <guid>https://arxiv.org/abs/2407.20265</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>加速低秩分解模型</title>
      <link>https://arxiv.org/abs/2407.20266</link>
      <description><![CDATA[arXiv:2407.20266v1 公告类型：新
摘要：张量分解是一种数学支持的数据压缩技术。它包括在张量或矩阵上应用某种低秩分解技术，以减少数据的冗余。然而，由于分解后架构中增加了大量新层，因此它不是一种流行的 AI 模型压缩技术。虽然参数数量可能会大幅减少，但可能会导致模型深度增加两倍以上，这可能会增加训练或推理的延迟。在本文中，我们全面研究了如何修改 AI 模型中的低秩分解技术，以便我们既能获得高精度和低内存消耗，又能加快训练和推理速度]]></description>
      <guid>https://arxiv.org/abs/2407.20266</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>聚类验证指标的全面回顾</title>
      <link>https://arxiv.org/abs/2407.20246</link>
      <description><![CDATA[arXiv:2407.20246v1 公告类型：新
摘要：数据聚类涉及识别数据集中的潜在相似性并将其组织成聚类或组。各种聚类算法的结果不同，因为它们易受原始数据集的固有特征（包括噪声和维数）的影响。此类聚类程序的有效性直接影响聚类的同质性，强调了评估算法结果的重要性。因此，聚类质量的评估是一项重大而复杂的工作。影响聚类验证的一个关键方面是聚类有效性指标，它有助于确定最佳聚类数。本研究的主要目标是全面回顾和解释内部和外部聚类有效性指标的数学运算（但不是全部），对这些指标进行分类并为未来聚类验证研究的进展提出建议。此外，我们还回顾和评估了内部和外部聚类验证指标对最常见聚类算法（例如进化聚类算法星 (ECA*)）的性能。最后，我们提出了一个分类框架，用于检查内部和外部聚类验证措施的功能，包括其理想值、用户友好性、对输入数据的响应能力以及跨各个领域的适用性。此分类可帮助研究人员选择适合其特定要求的适当聚类验证措施。]]></description>
      <guid>https://arxiv.org/abs/2407.20246</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>重新审视解决心脏病分类任务中的不平衡问题</title>
      <link>https://arxiv.org/abs/2407.20249</link>
      <description><![CDATA[arXiv:2407.20249v1 公告类型：新
摘要：在心脏病分类领域，出现了两个主要障碍。首先，现有的心电图 (ECG) 数据集在各种模式下始终表现出不平衡和偏差。其次，这些时间序列数据由不同的导联信号组成，导致卷积神经网络 (CNN) 过度拟合到功率更高的信号，从而降低了深度学习 (DL) 过程的性能。此外，当面对不平衡的数据集时，这种高维数据的性能可能容易出现过度拟合。尽管存在这些明显的挑战，但当前的努力主要集中在通过设计新颖的架构来增强 DL 模型，似乎忽视了核心问题，因此阻碍了心脏病分类的进步。为了解决这些障碍，我们提出的方法引入了两种直接的方法来增强分类任务。为了解决高维问题，我们在信号编码图像上采用了通道幅度均衡器 (CME)。该方法减少了特征数据范围内的冗余，突出了数据集的变化。同时，为了抵消数据不平衡，我们提出了倒权重对数损失（IWL）来缓解数据之间的不平衡。当应用 IWL 损失时，最新模型（SOTA）的准确率在 CPSC2018 数据集中提高了 5%。CME 与 IWL 的结合也超越了其他基线模型的分类结果 5% 到 10%。]]></description>
      <guid>https://arxiv.org/abs/2407.20249</guid>
      <pubDate>Wed, 31 Jul 2024 06:17:41 GMT</pubDate>
    </item>
    </channel>
</rss>