<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Thu, 03 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MpCritic：用于加固学习的插件MPC体系结构</title>
      <link>https://arxiv.org/abs/2504.01086</link>
      <description><![CDATA[ARXIV：2504.01086V1公告类型：新 
摘要：强化学习（RL）和模型预测控制（MPC）社区已经开发了有关解决最佳控制问题的理论方法和计算工具的广泛生态系统。鉴于他们的概念相似性但优势不同，人们对协同RL和MPC的兴趣越来越多。但是，由于各种原因，现有的方法往往受到限制，包括在RL算法中的计算成本以及针对MPC和RL工具无缝集成的软件障碍。这些挑战通常会导致使用“简单”的MPC方案或RL算法，从而忽略了这两个领域的最先进。本文介绍了MPCritic，这是一种机器学习友好的架构，与MPC工具无缝接口。 Mpcritic利用由参数化的MPC问题定义的损失景观，重点是“软”优化，而不是批处理训练步骤；从而更新MPC参数，同时避免昂贵的最小化和参数敏感性。由于在训练期间保留了MPC结构，因此可以轻松地将MPC代理用于在线部署，在线约束满意度至关重要。我们在经典控制基准上可以容纳MPCRITIT的多功能性，即它可以适应的MPC架构和RL算法。]]></description>
      <guid>https://arxiv.org/abs/2504.01086</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过傅立叶特征嵌入物理信息的神经网络中的neumann边界条件进行了严格限制</title>
      <link>https://arxiv.org/abs/2504.01093</link>
      <description><![CDATA[ARXIV：2504.01093V1公告类型：新 
摘要：我们提出了一种新的方法，用于使用傅立叶特征嵌入物理学的神经网络（PINN）中的neumann边界条件。 Neumann边界条件用于描述各种应用中的关键过程，但是与Dirichlet条件相比，它们对Pinns中的硬结构更具挑战性。我们的方法采用特定的傅立叶功能嵌入来将Neumann边界条件直接纳入神经网络的体系结构，而不是学习它们。嵌入可以自然地通过高频模式扩展，以更好地捕获高频现象。我们通过对扩散问题的实验来证明我们的方法的功效，我们的方法对此胜过现有的硬构方法和经典的PINN，尤其是在多尺度和高频方案中。]]></description>
      <guid>https://arxiv.org/abs/2504.01093</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FFSTRUC2VEC：扁平，灵活和可扩展的节点表示从结构身份进行的学习</title>
      <link>https://arxiv.org/abs/2504.01122</link>
      <description><![CDATA[ARXIV：2504.01122V1公告类型：新 
摘要：嵌入节点是指在图中生成节点的低维矢量表示的技术，同时保留节点的特定属性。该领域的一个关键挑战是开发可扩展的方法，该方法可以保留适用于给定下游应用程序任务的结构模式类型的结构属性。尽管大多数现有的方法都集中在保持节点接近度上，但是那些保留结构属性的方法通常缺乏保持下游应用程序任务所需的各种类型的结构模式的灵活性。本文介绍了FFSTRUC2VEC，这是一个可扩展的深度学习框架，用于学习保留结构身份的载体嵌入向量。它的平坦，有效的体系结构可在捕获各种类型的结构模式方面具有很高的灵活性，从而可以对各种下游应用程序任务进行广泛的适应性。所提出的框架在实际应用中的各种无监督和监督任务中大大优于现有方法。此外，FFSTRUC2VEC可以通过量化单个结构模式如何影响任务结果，提供可行的解释来实现解释性。据我们所知，没有现有的框架结合了这种灵活性，可扩展性和结构性解释性，强调了其独特的功能。]]></description>
      <guid>https://arxiv.org/abs/2504.01122</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用生成域对抗网络的表演性漂移分类</title>
      <link>https://arxiv.org/abs/2504.01135</link>
      <description><![CDATA[ARXIV：2504.01135V1公告类型：新 
摘要：表演性漂移是一种特殊的概念漂移类型，当模型的预测影响模型将遇到的未来实例时，就会发生。在这些环境中，再训练并不总是可行的。在这项工作中，我们将专注于漂移理解作为创建耐漂移分类器的一种方法。为此，我们介绍了结合域和生成对抗网络的生成域对抗网络（GDAN）。使用GDAN，创建了传入数据的域不变表示，并使用生成网络来扭转性能漂移的影响。使用半真实和合成数据生成器，我们从经验上评估了GDAN提供抗漂移分类的能力。最初的结果是有希望的，因为GDAN限制了几个时间段的性能降解。此外，GDAN的生成网络可与其他模型同时使用，以限制其在表演性漂移存在下的性能降解。最后，我们强调了模型再培训与表演性漂移的不可预测性之间的关系，从而更深入地了解在表演环境中使用传统概念漂移策略时所面临的挑战。]]></description>
      <guid>https://arxiv.org/abs/2504.01135</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用物理知情的图形神经网络有效的N体模拟</title>
      <link>https://arxiv.org/abs/2504.01169</link>
      <description><![CDATA[ARXIV：2504.01169V1公告类型：新 
摘要：本文通过将物理信息图神经网络（GNN）与传统的数值方法整合在一起，提出了一种新的方法来加速N体型模拟。我们的方法实现了基于跨越的仿真引擎，以从不同的天体物理场景中生成数据集，然后将其转换为图表。对定制设计的GNN进行了训练，以高精度预测粒子加速度。在60个训练和6个测试模拟上进行的实验从1000个时间步长到300个身体进行，这表明所提出的模型可以达到极低的预测错误误差值，同时保持强大的长期稳定性，并且累积的位置，速度，速度和加速度均保持不足。此外，我们的方法比传统的仿真技术产生的速度约为17％。这些结果表明，深度学习与传统的物理模拟方法的整合提供了一种有希望的途径，可以显着提高计算效率而不会损害准确性。]]></description>
      <guid>https://arxiv.org/abs/2504.01169</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SAT解决的神经方法：设计选择和解释性</title>
      <link>https://arxiv.org/abs/2504.01173</link>
      <description><![CDATA[ARXIV：2504.01173V1公告类型：新 
摘要：在这项贡献中，我们提供了用于布尔可满足问题的图形神经网络的全面评估，并伴随着对机制的直观解释，使该模型可以推广到不同的实例。我们介绍了几种培训改进，尤其是一种新型的最接近的分配监督方法，该方法动态适应了模型的当前状态，从而显着提高了较大解决方案空间问题的性能。我们的实验证明了具有复发性神经网络更新的可变条款图表表示的适用性，这在SAT分配预测的同时，可以在减少计算需求的同时获得良好的准确性。我们将基本图神经网络扩展到一个扩散模型，该模型有助于增量采样，并可以与单位传播等经典技术有效结合。通过分析嵌入空间模式和优化轨迹，我们展示了这些网络如何隐含地执行与MaxSat的连续放松非常相似的过程，从而对其推理过程提供了可解释的视图。这种理解指导了我们的设计选择，并解释了经常性体系结构在推理时间超出其训练分布之外有效扩展的能力，我们通过测试时间扩展实验证明了这一点。]]></description>
      <guid>https://arxiv.org/abs/2504.01173</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度放弃分类器的全球解释性</title>
      <link>https://arxiv.org/abs/2504.01202</link>
      <description><![CDATA[ARXIV：2504.01202V1公告类型：新 
摘要：我们提出了一种全局解释性方法，可以表征我们现实世界中多任务卷积神经网络（MTCNN）的组织学预测任务中的错误源，用于基于NCI-Seer注册的癌症病理学报告的自动化注释。对我们的分类器进行了104万个手工注销样本的培训和评估，并同时预测了每个报告的癌症部位，亚场，组织学，横向性和行为。 DAC框架使该模型能够在模棱两可的报告和/或混淆类中弃权，以在保留的（未固定的）样本上实现目标准确性，但要付出减少覆盖范围的成本。在组织学任务上需要97％的准确性导致我们的模型仅保留所有样本的22％，其中大部分是含糊不清的类别。使用Gradinp技术的局部解释性提供了一种计算有效的方法，可以为数千个个人预测获得上下文推理。我们的方法涉及降低大约13000个汇总的本地解释的维度，从而使错误源识别为阶级之间的层次复杂性，标签噪声，信息不足和证据相互冲突。这表明了几种策略，例如排除标准，重点注释以及减少涉及层次相关类别的错误，以迭代地改善我们的DAC，以改善我们的DAC。]]></description>
      <guid>https://arxiv.org/abs/2504.01202</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>库珀：深度学习中有限优化的库</title>
      <link>https://arxiv.org/abs/2504.01212</link>
      <description><![CDATA[ARXIV：2504.01212V1公告类型：新 
摘要：库珀是一个开源软件包，用于解决涉及深度学习模型的受限优化问题。库珀实施了几种基于拉格朗日的一阶更新方案，使得将受限的优化算法与Pytorch的高级功能（例如自动差异化）以及专门的深度学习架构和优化器相结合起来，变得容易将受约束的优化算法与高级功能结合起来。尽管Cooper是专门针对基于小批量估算梯度的深度学习应用而设计的，但它适用于一般非凸的连续约束优化。 Cooper的源代码可在https://github.com/cooper-org/cooper上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.01212</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提示忘记：通过文本指导在gan中学习</title>
      <link>https://arxiv.org/abs/2504.01218</link>
      <description><![CDATA[ARXIV：2504.01218V1公告类型：新 
摘要：最新的生成模型具有强大的图像生成能力，向主持这些模型的服务提供商引入了各种道德和法律挑战。因此，内容清除技术（CRT）已成为一个不断增长的研究领域，可以控制输出而无需全面的再训练。最近的工作探索了在生成模型中使用机器未学习来解决内容清除的方法。但是，此类研究的重点是扩散模型，并且在生成对抗网络（GAN）中进行了学习，但基本上仍未开发。我们通过提出文本到Unlearnn来解决这一差距，这是一个新颖的框架，仅使用文本提示从预先训练的gan中选择性地学习概念，从而使功能不学习，身份学习和精细粒度的任务，例如表达方式和在人脸上受过训练的模型中的多粒子删除。利用自然语言描述，我们的方法指导了学习过程，而无需其他数据集或监督微调，提供了可扩展和高效的解决方案。为了评估其有效性，我们引入了一种自动学习评估方法，该方法是根据最先进的图像文本对准指标进行的，从而对未学习方法进行了全面分析。据我们所知，文本到未学习是gan的第一个跨模式学习框架，代表了管理生成模型行为方面灵活而有效的进步。]]></description>
      <guid>https://arxiv.org/abs/2504.01218</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无梯度的持续学习</title>
      <link>https://arxiv.org/abs/2504.01219</link>
      <description><![CDATA[ARXIV：2504.01219V1公告类型：新 
摘要：持续学习（CL）在训练神经网络上的依次任务中提出了一个基本挑战，而不会遇到灾难性的遗忘。传统上，CL中的主要方法是基于梯度的优化，其中使用随机梯度下降（SGD）或其变体对网络参数进行更新。但是，当不再访问以前的数据时，就会出现一个主要限制，就像CL设置中通常假定的那样。在这种情况下，没有用于过去数据的梯度信息，导致参数不受控制，因此严重忘记了以前学习的任务。通过将重点从数据可用性转移到梯度可用性，这项工作开辟了解决CL中遗忘的新途径。我们探讨了这样的假设，即无梯度优化方法可以为基于常规梯度的持续学习方法提供可靠的替代方法。我们讨论了这种方法的理论基础，分析了它们的潜在优势和局限性，并提供了支持其有效性的经验证据。通过重新考虑遗忘的基本原因，这项工作旨在为持续学习的领域做出新的视角，并激发新的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2504.01219</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>较短的时间限制和提早停止的汽车基准测试</title>
      <link>https://arxiv.org/abs/2504.01222</link>
      <description><![CDATA[ARXIV：2504.01222V1公告类型：新 
摘要：自动化机器学习（AUTOML）自动在数据上构建机器学习（ML）模型。用于评估表格数据新的Automl框架的事实上的标准是Automl基准（AMLB）。 AMLB提议在104个任务中使用1个和4小时的时间预算评估Automl框架。我们认为，由于其实际价值，例如需要高频重新训练，并使AMLB更易于访问，因此应该考虑较短的时间限制。这项工作考虑了减少基准中使用的总体计算的两种方式：时间限制和早期停止的使用。我们对具有不同时间限制的104个任务进行了11个自动框架的评估，并且在时间限制之间发现Automl框架的相对排名相当一致，但是使用早期停滞的导致模型性能的变化更大。]]></description>
      <guid>https://arxiv.org/abs/2504.01222</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的训练后偏置缓解措施，并基于分配的公平度指标</title>
      <link>https://arxiv.org/abs/2504.01223</link>
      <description><![CDATA[ARXIV：2504.01223V1公告类型：新 
摘要：我们开发了一个新型的优化框架，具有基于分布的公平性约束，以有效地在广泛的公平层面上产生人口统计学盲目的，可解释的模型。这是通过后处理来实现的，避免了进行重新培训。我们的框架基于随机梯度下降，可以应用于多种模型类型，特别强调了梯度增强决策树的后处理。此外，我们通过构建以前的工作来设计与我们方法兼容的一系列可解释的全球偏见指标。我们从经验上测试了各种数据集的方法，并将其与其他方法进行比较。]]></description>
      <guid>https://arxiv.org/abs/2504.01223</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用尖峰神经网络学习多元点过程的动态图结构估计</title>
      <link>https://arxiv.org/abs/2504.01246</link>
      <description><![CDATA[ARXIV：2504.01246V1公告类型：新 
摘要：在神经科学，流行病学，金融和社会科学等领域中，建模和预测时间点过程（TPP）至关重要。我们介绍了尖峰动态图网络（SDGN），这是一个新型框架，利用尖峰神经网络（SNNS）和峰值依赖性可塑性（STDP）的时间处理能力（STDP）的动态估算为基础时空功能图。与依赖预定义或静态图结构的现有方法不同，SDGN直接从事件数据中学习动态时空依赖性来适应任何数据集，从而增强了普遍性和鲁棒性。尽管SDGN对先前方法提供了重大改进，但我们承认其在处理密集图和某些非高斯依赖性方面的局限性，为将来的改进提供了机会。我们对包括纽约市出租车，911，Reddit和堆栈溢出在内的合成和现实世界数据集进行的评估表明，SDGN在维持计算效率的同时可以实现卓越的预测准确性。此外，我们包括消融研究，以突出其核心成分的贡献。]]></description>
      <guid>https://arxiv.org/abs/2504.01246</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>R2DN：合同和Lipschitz的可扩展参数化反复的深网</title>
      <link>https://arxiv.org/abs/2504.01250</link>
      <description><![CDATA[ARXIV：2504.01250V1公告类型：新 
摘要：本文介绍了强大的经常性深网（R2DN），这是用于机器学习和数据驱动控制的可稳健复发神经网络的可扩展参数化。我们将R2DN构建为线性时间传播系统和1-Lipschitz深馈电网络的反馈互连，并直接将权重参数化，以使我们的模型稳定（合同），并且可以通过设计对小型输入扰动（Lipschitz）进行稳健。我们的参数化使用了类似于以前提供的复发平衡网络（RENS）的结构，但在每个时间步长以迭代求解均衡层的要求。这加快了GPU上的模型评估和反向传播，并使其在计算上可行，以扩大网络大小，批处理大小和输入序列长度与rens相比。我们将R2DNS与非线性系统识别，观察者设计和基于学习的反馈控制中的三个代表性问题进行比较，并发现训练和推理都具有相似的测试集性能的速度，并且对模型表现力的训练/推理时间更为优惠。]]></description>
      <guid>https://arxiv.org/abs/2504.01250</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>火焰：基于事件的学习中的自适应记忆保留的混合峰值状态空间模型</title>
      <link>https://arxiv.org/abs/2504.01257</link>
      <description><![CDATA[ARXIV：2504.01257V1公告类型：新 
摘要：我们建议\ textbf {Flames（基于事件的系统的快速长距离自适应内存）}，这是一个新型混合框架，将结构化状态空间动力学与事件驱动的计算集成在一起。 \ textit {spike-ware hippo（sa-hippo）机制}以\ textit {spike-aware hippo（sa-hippo）机制}根据尖峰间隔动态调整存储率，并保留短期和长距离依赖性。为了维持计算效率，我们引入了一个正常的加级（NPLR）分解，从而将复杂性从$ \ Mathcal {O}（n^2）$降低到$ \ Mathcal {o}（nr）$。火焰在远程竞技场基准和诸如HAR-DVS和CELEX-HAR之类的活动数据集上实现了最先进的结果。通过桥接神经形态计算和结构化序列建模，火焰可以在事件驱动的系统中实现可扩展的远程推理。]]></description>
      <guid>https://arxiv.org/abs/2504.01257</guid>
      <pubDate>Thu, 03 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>