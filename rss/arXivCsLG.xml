<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 18 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>贝尔曼扩散模型</title>
      <link>https://arxiv.org/abs/2407.12163</link>
      <description><![CDATA[arXiv:2407.12163v1 公告类型：新
摘要：扩散模型作为生成架构取得了巨大成功。最近，它们已被证明可以有效地为离线强化学习和模仿学习建模策略。我们探索使用扩散作为策略的后继状态度量 (SSM) 的模型类。我们发现强制实施贝尔曼流约束会导致对扩散步骤分布进行简单的贝尔曼更新。]]></description>
      <guid>https://arxiv.org/abs/2407.12163</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>用于预测湍流大气动力学的可扩展实时数据同化框架</title>
      <link>https://arxiv.org/abs/2407.12168</link>
      <description><![CDATA[arXiv:2407.12168v1 公告类型：新 
摘要：得益于 FourCastNet、GraphCast、ClimaX 和 Pangu-Weather 等基于人工智能的基础模型的进步，天气和气候领域正在发生重大转变。虽然这些模型显示出巨大的潜力，但它们尚未准备好用于天气预报或气候预测。这是因为缺乏数据同化方法作为其工作流程的一部分，以便实时同化传入的地球系统观测值。这一限制影响了它们在预测热带气旋和大气河流等复杂大气现象方面的有效性。为了克服这些障碍，我们引入了一个通用的实时数据同化框架，并在 Frontier 超级计算机上展示了其端到端性能。该框架包含两个主要模块：集合得分滤波器（EnSF），其性能明显优于最先进的数据同化方法，即局部集合变换卡尔曼滤波器（LETKF）；以及基于视觉变换器的替代品，它能够通过整合观测数据实现实时自适应。ViT 替代品可以表示基于物理的模型，也可以表示基于 AI 的基础模型。我们展示了我们的框架在百亿亿次超级计算机 Frontier 上最多 1024 个 GPU 的强扩展和弱扩展。我们的结果不仅说明了该框架在高性能计算系统上的卓越可扩展性，而且还证明了超级计算机在实时数据同化对天气和气候预测的重要性。尽管所提出的框架仅在基准表面准地转 (SQG) 湍流系统上进行了测试，但它有可能与现有的基于 AI 的基础模型相结合，使其适合未来的操作实施。]]></description>
      <guid>https://arxiv.org/abs/2407.12168</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>通过动态在线数据流实现完全测试时间自适应的分布对齐</title>
      <link>https://arxiv.org/abs/2407.12128</link>
      <description><![CDATA[arXiv:2407.12128v1 公告类型：新
摘要：给定一个在源数据上训练的模型，测试时间自适应 (TTA) 可以在与源域偏移的测试数据流中进行自适应和推理。当前方法主要使用自训练损失为每个传入的测试数据批次优化模型。虽然这些方法在理想的测试数据流中产生了值得称赞的结果，其中批次是从目标分布中独立且相同地采样的，但它们在非独立且相同分布（非 i.i.d.）的更实际的测试数据流下会失败。非 i.i.d. 流中的数据批次相对于彼此显示出显著的标签偏移。这导致在 TTA 过程中批次之间的优化目标发生冲突。考虑到将源模型适应不可预测的测试时间分布的固有风险，我们逆转了适应过程并提出了一种用于 TTA 的新型分布对齐损失。这种损失将测试时间特征的分布引导回源分布，从而确保与训练有素的源模型兼容，并消除与优化目标冲突相关的陷阱。此外，我们设计了一种域转移检测机制，以扩展我们提出的 TTA 方法在连续域转移场景中的成功率。我们大量的实验验证了我们方法的逻辑性和有效性。在六个基准数据集上，我们在非独立同分布场景中超越了现有的方法，并在理想的独立同分布假设下保持了有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.12128</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>分子拓扑轮廓（MOLTOP）——分子图分类的简单而强大的基线</title>
      <link>https://arxiv.org/abs/2407.12136</link>
      <description><![CDATA[arXiv:2407.12136v1 公告类型：新
摘要：我们重新审视了拓扑描述符对分子图分类的有效性，并设计了一个简单但强大的基线。我们证明了一种简单的特征工程方法——采用边缘描述符的直方图聚合和原子序数和键类型的独热编码——与随机森林分类器相结合，可以为图神经网络 (GNN) 建立强大的基线。新算法分子拓扑轮廓 (MOLTOP) 集成了边缘中介中心性、调整后的随机指数和 SCAN 结构相似性得分。与现代 GNN 相比，这种方法被证明具有非常强的竞争力，同时还简单、快速、低方差和无超参数。我们的方法使用 Open Graph Benchmark 提供的公平评估协议在 MoleculeNet 数据集上进行了严格测试。我们还展示了来自 Long Range Graph Benchmark 的肽分类任务的域外生成能力。在 11 个基准数据集上的评估表明，MOLTOP 具有强大的判别能力，在某些类别的图上超过了 $1$-WL 测试甚至 $3$-WL 测试。我们的结论是，基于描述符的基线（例如我们提出的基线）对于准确评估 GNN 领域的进步仍然至关重要。]]></description>
      <guid>https://arxiv.org/abs/2407.12136</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>在 8 个 GPU 上高效训练具有 100 万个序列长度的 7B LLM</title>
      <link>https://arxiv.org/abs/2407.12117</link>
      <description><![CDATA[arXiv:2407.12117v1 公告类型：新
摘要：如今，大型语言模型 (LLM) 已经使用扩展的上下文长度进行训练，以促进更具创造性的应用程序。然而，考虑到 GPU 内存的限制，长上下文训练带来了巨大的挑战。它不仅导致训练期间激活内存消耗大量，而且还会产生大量内存碎片。为了促进长上下文训练，现有框架采用了重新计算和各种形式的并行等策略。然而，这些技术依赖于冗余计算或大量通信，导致模型 FLOPS 利用率 (MFU) 较低。在本文中，我们提出了 MEMO，一种专为细粒度激活内存管理而设计的新型 LLM 训练框架。考虑到使用 FlashAttention 时计算的二次缩放和内存随序列长度的线性缩放，我们在每一层的前向传递之后将消耗内存的激活卸载到 CPU 内存，并在后向传递期间获取它们。为了在不妨碍计算的情况下最大限度地交换激活，并避免耗尽有限的 CPU 内存，我们实现了基于 token 的激活重新计算和交换机制。此外，我们采用双层混合整数规划 (MIP) 方法解决内存碎片问题，优化跨转换器层的内存重用。实证结果表明，与 Megatron-LM 和 DeepSpeed 相比，MEMO 分别实现了 2.42 倍和 2.26 倍的 MFU。这一改进归功于 MEMO 能够最大限度地减少内存碎片，减少重新计算和密集通信，并避免因碎片而导致的内存重组过程延迟。通过利用细粒度激活内存管理，MEMO 仅在 8 个 A800 GPU 上即可高效训练具有 100 万个序列长度的 7B LLM，实现 52.30% 的 MFU。]]></description>
      <guid>https://arxiv.org/abs/2407.12117</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>公平感知图学习的基准</title>
      <link>https://arxiv.org/abs/2407.12112</link>
      <description><![CDATA[arXiv:2407.12112v1 公告类型：新
摘要：近年来，公平感知图学习受到越来越多的关注。然而，缺乏一个全面的基准来评估和比较不同的公平感知图学习方法，这阻碍了从业者为更广泛的实际应用选择合适的方法。在本文中，我们对十种具有代表性的公平感知图学习方法进行了广泛的基准测试。具体来说，我们设计了一个系统的评估协议，并在七个真实世界的数据集上进行了实验，从多个角度评估这些方法，包括群体公平、个体公平、不同公平标准之间的平衡以及计算效率。我们的深入分析揭示了现有方法的优势和局限性的关键见解。此外，我们为在应用中应用公平感知图学习方法提供了实用指导。据我们所知，这项工作是全面了解代表性公平感知图学习方法的初步步骤，以促进该领域的未来发展。]]></description>
      <guid>https://arxiv.org/abs/2407.12112</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>基于图的对抗性模仿学习框架，用于城市空中交通中可靠且实时的机队调度</title>
      <link>https://arxiv.org/abs/2407.12113</link>
      <description><![CDATA[arXiv:2407.12113v1 公告类型：新
摘要：城市空中交通 (UAM) 的出现为城市交通领域的变革提供了空间。然而，它的广泛采用和经济可行性在一定程度上取决于在空域拥堵、天气条件变化和需求变化等不确定因素的影响下，在 UAM 网络中的垂直起降机场之间以最佳方式调度飞机的能力。本文提出了一种全面的机队调度问题优化公式，同时也确定了替代解决方法的需求，因为直接解决由此产生的整数非线性规划问题对于日常机队调度而言在计算上是无法承受的。先前的研究表明，使用 (图) 强化学习 (RL) 方法训练实时可执行的机队调度策略模型是有效的。然而，这种策略在分布外场景或边缘情况下往往很脆弱。此外，随着问题的复杂性 (例如约束数量) 的增加，训练性能也会下降。为了解决这些问题，本文提出了一种模仿学习方法，其中基于 RL 的策略利用通过使用遗传算法解决精确优化而产生的专家演示。该策略模型包括基于图神经网络 (GNN) 的编码器，该编码器嵌入了垂直起降机场和飞机的空间，Transformer 网络用于编码需求、乘客票价和运输成本概况，以及基于多头注意力 (MHA) 的解码器。专家演示通过生成对抗模仿学习 (GAIL) 算法使用。与涉及 8 个垂直起降机场和 40 架飞机的 UAM 模拟环境交互，就每日利润奖励而言，与纯 RL 结果相比，新的模仿方法在未见过的最坏情况下实现了更好的平均性能和显着改进。]]></description>
      <guid>https://arxiv.org/abs/2407.12113</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>平铺位网络：通过重用可学习二进制向量实现子位神经网络压缩</title>
      <link>https://arxiv.org/abs/2407.12075</link>
      <description><![CDATA[arXiv:2407.12075v1 公告类型：新
摘要：二元神经网络 (BNN) 通过节省存储和计算成本实现高效的深度学习。然而，随着神经网络规模的不断增长，满足计算要求仍然是一个挑战。在这项工作中，我们提出了一种新的量化形式，用比特序列对神经网络层进行平铺，以实现二进制加权神经网络的亚比特压缩。该方法通过聚合和重塑操作学习二进制向量（即图块）来填充模型的每一层。在推理过程中，该方法每层重用一个图块来表示完整的张量。我们对全连接层和卷积层都采用了这种方法，它们构成了大多数神经架构的空间宽度。从经验上看，该方法在各种架构（CNN、Transformers、MLP）和任务（分类、分割和时间序列预测）上实现了近乎全精度的性能，与二进制加权模型相比，其大小最多可减少 8 倍。我们为 Tiled Bit Networks 提供了两种实现：1) 我们将模型部署到微控制器以评估其在资源受限环境中的可行性，2) 与 GPU 兼容的推理内核，以方便在内存中重复使用每个层的单个图块。]]></description>
      <guid>https://arxiv.org/abs/2407.12075</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>大规模合成文本生成的隐私预测</title>
      <link>https://arxiv.org/abs/2407.12108</link>
      <description><![CDATA[arXiv:2407.12108v1 公告类型：新
摘要：我们提出了一种使用大型语言模型 (LLM) 通过隐私预测生成差异隐私合成文本的方法。在隐私预测框架中，我们只需要输出合成数据来满足差异隐私保证。这与在潜在敏感的用户提供的源数据上训练生成模型并寻求确保模型本身可以安全发布的方法形成对比。
我们使用源数据提示预训练的 LLM，但确保下一个标记预测具有差异隐私保证。该范式中的先前研究报告在合理的隐私级别生成少量示例（&lt;10），这种数据量仅对下游上下文学习或提示有用。相比之下，我们进行了更改，使我们能够生成数千个高质量的合成数据点，从而大大扩展了潜在应用集。我们的改进来自改进的隐私分析和更好的隐私选择机制，该机制利用了 LLM 中用于采样 token 的 softmax 层与指数机制之间的等价性。此外，我们通过稀疏向量技术引入了一种新颖的公开预测用法，其中我们无需为没有敏感数据即可预测的 token 支付隐私成本；我们发现这对结构化数据特别有效。]]></description>
      <guid>https://arxiv.org/abs/2407.12108</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型 (LLM) 进行图学习：深入探究模型鲁棒性</title>
      <link>https://arxiv.org/abs/2407.12068</link>
      <description><![CDATA[arXiv:2407.12068v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言处理任务中都表现出色。最近，已经开发了几种基于 LLM 的管道来增强具有文本属性的图形学习，并展示了令人鼓舞的性能。然而，众所周知，图容易受到对抗性攻击，而且 LLM 是否在图学习中表现出鲁棒性仍不清楚。为了解决这一差距，我们的工作旨在探索 LLM 在图对抗性攻击背景下的潜力。具体来说，我们从两个维度研究了对图结构和文本扰动的鲁棒性：LLM 作为增强器和 LLM 作为预测器。通过大量实验，我们发现，与浅层模型相比，LLM 作为增强器和 LLM 作为预测器都具有出色的结构和文本攻击鲁棒性。基于这些发现，我们进行了额外的分析以调查根本原因。此外，我们已公开我们的基准库，以便于快速、公平地进行评估，并鼓励该领域的持续创新研究。]]></description>
      <guid>https://arxiv.org/abs/2407.12068</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>共同设计二值化变压器和硬件加速器，实现高效的端到端边缘部署</title>
      <link>https://arxiv.org/abs/2407.12070</link>
      <description><![CDATA[arXiv:2407.12070v1 公告类型：新
摘要：Transformer 模型彻底改变了 AI 任务，但其庞大的规模阻碍了在资源受限且延迟关键的边缘设备上的实际部署。虽然二值化 Transformer 通过显着减小模型大小提供了一种有希望的解决方案，但现有方法存在算法与硬件不匹配的问题，且协同设计探索有限，导致边缘设备的性能不佳。因此，我们从算法、硬件和联合优化三个方面提出了一种协同设计方法，用于高效端到端边缘部署 Transformer。首先，我们提出了一种具有优化量化方法和组件的新型硬件友好型二值化 Transformer BMT，并通过利用加权三元权重分割训练技术进一步提高其模型精度。其次，我们开发了一种流处理器混合二值化 Transformer 加速器，即 BAT，它配备了专门的单元和调度管道，可以高效推理二值化 Transformer。最后，我们通过设计空间探索方法共同优化算法和硬件，以在实际部署中实现准确性、延迟和稳健性之间的全局权衡。实验结果表明，与最先进的 Transformer 加速器相比，我们的共同设计实现了高达 2.14-49.37 倍的吞吐量增益和 3.72-88.53 倍的能效提升，从而实现了高效的端到端边缘部署。]]></description>
      <guid>https://arxiv.org/abs/2407.12070</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>增强大规模模型的参数效率和泛化能力：一种正则化和掩蔽的低秩自适应方法</title>
      <link>https://arxiv.org/abs/2407.12074</link>
      <description><![CDATA[arXiv:2407.12074v1 公告类型：新 
摘要：大型预训练模型，例如大型语言模型 (LLM)，由于其参数规模庞大，在微调方面带来了巨大的资源挑战，尤其是对于移动系统中的应用。为了解决这个问题，开发了低秩自适应 (LoRA) 来减少资源消耗，同时保持令人满意的微调结果。尽管原始 LoRA 方法很有效，但它面临着性能不理想和过度拟合的挑战。本文研究了 LoRA 方法近似的矩阵更新的固有维度，并揭示了增加该固有维度的性能优势。通过采用正则化和鼓励更高固有维度的梯度掩蔽方法，所提出的方法称为正则化和掩蔽 LoRA (RM-LoRA)，与原始 LoRA 及其最新变体相比，在各种开源视觉和语言数据集上以相同或更低的可训练参数预算实现了卓越的泛化性能。]]></description>
      <guid>https://arxiv.org/abs/2407.12074</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>自动驾驶汽车评估的数据选择方法</title>
      <link>https://arxiv.org/abs/2407.12065</link>
      <description><![CDATA[arXiv:2407.12065v1 公告类型：新
摘要：随着自动驾驶汽车的普及，许多标准和监管机构（例如 ISO、NHTSA 和 Euro NCAP）都要求进行安全验证，以确保在将其部署到现实世界之前具有足够的安全级别。制造商为此收集了大量的公共道路数据。但是，大多数验证活动都是由人类手动完成的。此外，用于验证每个驾驶特征的数据可能不同。因此，必须有一种有效的数据选择方法，可以灵活、动态地用于验证和确认，同时还可以加速验证过程。在本文中，我们提出了一种实用、灵活、高效的数据选择方法，用于评估自动驾驶汽车。我们的想法是优化所选数据的元数据分布与预期用于验证的预定义元数据分布之间的相似性。我们在大型数据集 BDD100K 上的实验表明，我们的方法可以有效地执行数据选择任务。这些结果表明我们的方法高度可靠，可以用来选择合适的数据来验证各种安全功能。]]></description>
      <guid>https://arxiv.org/abs/2407.12065</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>改进 AlphaFlow 以实现高效的蛋白质集合生成</title>
      <link>https://arxiv.org/abs/2407.12053</link>
      <description><![CDATA[arXiv:2407.12053v1 公告类型：新
摘要：研究蛋白质的构象景观是了解其生物功能和特性的重要方法。AlphaFlow 是一种序列条件生成模型，通过在流匹配框架下微调 AlphaFold，为结构预测模型引入了灵活性。尽管流匹配具有高效采样的优势，但 AlphaFlow 仍然需要多次运行 AlphaFold 才能最终生成一个构象。由于 AlphaFold 的消耗很大，其适用性在对较大的蛋白质集合或受限时间范围内的较长链进行采样时受到限制。在这项工作中，我们提出了一种称为 AlphaFlow-Lit 的特征条件生成模型来实现高效的蛋白质集合生成。与对整个结构的全面微调相比，我们只关注轻量级结构模块来重建构象。 AlphaFlow-Lit 的性能与 AlphaFlow 相当，并且超越了其未经预训练的精简版本，同时实现了约 47 倍的显著采样加速。效率的提高展示了 AlphaFlow-Lit 在实现更快、更具可扩展性的蛋白质集合生成方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.12053</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>使用多方面元启发式优化方法和集成深度学习模型增强多步布伦特原油价格预测</title>
      <link>https://arxiv.org/abs/2407.12062</link>
      <description><![CDATA[arXiv:2407.12062v1 公告类型：新
摘要：准确的原油价格预测对于各种经济活动都至关重要，包括能源交易、风险管理和投资规划。尽管深度学习模型已成为原油价格预测的有力工具，但实现准确的预测仍然具有挑战性。深度学习模型的性能在很大程度上受到超参数调整的影响，并且它们在不同情况下的表现预计会有所不同。此外，价格波动也对世界事件等外部因素很敏感。为了解决这些限制，我们提出了一种混合方法，结合了元启发式优化和时间序列预测中使用的五种流行神经网络架构的集合。与现有的应用元启发式来优化神经网络架构中的超参数的方法不同，我们在四个层面上利用了 GWO 元启发式优化器：特征选择、数据准备、模型训练和预测混合。已经使用真实的布伦特原油价格数据对所提出的方法进行了三天预测评估，得到的结果表明，所提出的方法提高了使用各种基准测量的预测性能，达到了 0.000127 的 MSE。]]></description>
      <guid>https://arxiv.org/abs/2407.12062</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    </channel>
</rss>