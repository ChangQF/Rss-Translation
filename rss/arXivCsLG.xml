<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 14 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过扩散桥利用先验生成时间序列</title>
      <link>https://arxiv.org/abs/2408.06672</link>
      <description><![CDATA[arXiv:2408.06672v1 公告类型：新
摘要：时间序列生成广泛应用于现实世界的应用，如模拟、数据增强和假设检验技术。最近，扩散模型已成为时间序列生成的事实上的方法，强调基于历史或相关时间序列数据流的多种合成场景。由于时间序列具有独特的特征，例如固定的时间顺序和数据缩放，标准高斯先验可能不适合一般的时间序列生成。在本文中，我们利用不同的先验分布进行合成。然后，我们提出了 TimeBridge，这是一个通过利用扩散桥来学习所选先验和数据分布之间的传输来实现灵活合成的框架。我们的模型涵盖了时间序列扩散模型中的广泛场景，它利用 (i) 数据和时间相关的先验进行无条件合成，以及 (ii) 数据规模保持合成，并以约束作为条件生成的先验。实验表明，我们的模型在无条件和条件时间序列生成任务中都取得了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.06672</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>基于案例的随机森林可解释性：原型、批评、反事实和半事实</title>
      <link>https://arxiv.org/abs/2408.06679</link>
      <description><![CDATA[arXiv:2408.06679v1 公告类型：新
摘要：由于监管要求和商业实践透明度的需求，黑盒机器学习算法（通常称为可解释人工智能 (XAI)）的可解释性对于金融和其他受监管的工业应用至关重要。在 XAI 的各种范例中，可解释案例推理 (XCBR) 脱颖而出，成为一种实用的方法，它通过引用用于训练或测试模型的数据中的实际示例来阐明模型的输出。尽管 XCBR 具有潜力，但直到最近，它在许多算法（例如基于树的模型）中都相对未被充分探索。我们首先观察到大多数 XCBR 方法都是基于算法学习的距离度量来定义的。通过利用最近提出的一种技术来提取随机森林 (RF) 学习的距离度量，该技术既能保持几何形状，又能保持精度，我们研究了各种 XCBR 方法。这些方法相当于从训练数据集中识别出特殊点，例如原型、批评者、反事实和半事实，以解释 RF 给定查询的预测。我们使用各种评估指标来评估这些特殊点，以评估它们的解释力和有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.06679</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>面向大型语言模型的稳健且经济高效的知识忘却学习</title>
      <link>https://arxiv.org/abs/2408.06621</link>
      <description><![CDATA[arXiv:2408.06621v1 公告类型：新
摘要：大型语言模型 (LLM) 通过在大量文本语料库上进行预训练，展示了强大的推理和记忆能力。然而，在人工编写的文本上训练 LLM 会带来严重的隐私和版权侵犯风险，这需要一个有效的机器反学习框架来删除敏感数据的知识，而无需从头开始重新训练模型。虽然梯度上升 (GA) 被广泛用于反学习，因为它可以降低生成不需要的信息的可能性，但增加交叉熵损失的无界性不仅会导致不稳定的优化，还会导致需要保留的知识的灾难性遗忘。我们还发现，在低秩自适应下联合应用会导致计算成本与生成性能之间的权衡明显不理想。鉴于这一限制，我们提出了两种新技术，用于在 LLM 上进行稳健且经济高效的反学习。我们首先设计了一个 Inverted Hinge 损失，通过增加下一个最可能标记的概率来抑制不需要的标记，从而保持语言生成的流畅性和结构性。我们还建议根据 Fisher 加权低秩近似来初始化低秩适配器权重，这通过允许模型更新专注于在生成我们希望删除的文本数据时很重要的参数来加快学习速度并更好地保留知识。]]></description>
      <guid>https://arxiv.org/abs/2408.06621</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>COD：学习领域自适应回归的条件不变表示</title>
      <link>https://arxiv.org/abs/2408.06638</link>
      <description><![CDATA[arXiv:2408.06638v1 公告类型：新
摘要：域自适应回归 (DAR) 旨在将标签知识从具有连续输出的源域推广到未标记的目标域，用于解决复杂的实际学习问题。然而，由于回归中的连续性问题，现有的条件分布对齐理论和离散先验方法在分类设置中被证明是有效的，但不再适用。在本文中，我们针对 DAR 中的可行性问题，建立了回归模型的充分性理论，该理论表明泛化误差可以充分受跨域条件差异的影响。此外，为了表征具有连续条件变量的条件差异，提出了一种新的条件算子差异 (COD)，它通过核嵌入理论承认条件分布的度量属性。最后，为了最小化差异，提出了一种基于COD的条件不变表示学习模型，并推导出其重构模型，表明对矩统计量的合理修改可以进一步提高自适应模型的判别能力。在标准DAR数据集上的大量实验验证了理论结果的有效性和相对于SOTA DAR方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2408.06638</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>RW-NSGCN：一种针对负采样结构攻击的鲁棒方法</title>
      <link>https://arxiv.org/abs/2408.06665</link>
      <description><![CDATA[arXiv:2408.06665v1 公告类型：新
摘要：使用图神经网络 (GNN) 进行节点分类已广泛应用于各种实际场景，例如预测用户兴趣和检测社交网络中的社区。然而，最近的研究表明，图结构网络通常包含潜在的噪声和攻击，以拓扑扰动和权重扰动的形式出现，这可能导致 GNN 的分类性能下降。为了提高模型的鲁棒性，我们提出了一种新方法：随机游走负采样图卷积网络 (RW-NSGCN)。具体而言，RW-NSGCN 集成了带重启的随机游走 (RWR) 和 PageRank (PGR) 算法进行负采样，并采用基于行列式点过程 (DPP) 的 GCN 进行卷积操作。RWR 利用全局和局部信息来管理噪声和局部变化，而 PGR 评估节点重要性以稳定拓扑结构。基于 DPP 的 GCN 保证了负样本的多样性，并聚合了负样本的特征以产生鲁棒的节点向量，从而提升了分类性能。实验结果表明，RW-NSGCN 模型能够有效应对网络拓扑攻击和权重不稳定问题，提高异常检测的准确率和整体稳定性。在分类准确率方面，RW-NSGCN 明显优于现有方法，在各种场景下都表现出更强的弹性，有效缓解了此类漏洞的影响。]]></description>
      <guid>https://arxiv.org/abs/2408.06665</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>优先排序模式：联邦多模态学习中的灵活重要性调度</title>
      <link>https://arxiv.org/abs/2408.06549</link>
      <description><![CDATA[arXiv:2408.06549v1 公告类型：新
摘要：联邦学习 (FL) 是一种分布式机器学习方法，使设备能够协作训练模型而无需共享其本地数据，从而确保用户的隐私和可扩展性。然而，将 FL 应用于现实世界的数据带来了挑战，特别是因为大多数现有的 FL 研究都集中在单模态数据上。多模态联邦学习 (MFL) 的出现是为了解决这些挑战，利用特定于模态的编码器模型来处理不同的数据集。当前的 MFL 方法通常在所有模态中统一分配计算频率，这对于资源有限的物联网设备来说是低效的。在本文中，我们提出了 FlexMod，这是一种通过根据每个模态编码器的重要性和训练要求自适应地分配训练资源来提高 MFL 计算效率的新方法。我们使用原型学习来评估模态编码器的质量，使用 Shapley 值来量化每个模态的重要性，并采用深度强化学习中的深度确定性策略梯度 (DDPG) 方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化模型性能和资源利用率。在三个真实数据集上的实验结果表明，我们提出的方法显著提高了 MFL 模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.06549</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>揭开缺陷：对时间序列异常检测初始化效应的批判性分析</title>
      <link>https://arxiv.org/abs/2408.06620</link>
      <description><![CDATA[arXiv:2408.06620v1 公告类型：新
摘要：过去十年，时间序列异常检测 (TSAD) 的深度学习引起了广泛关注。尽管几篇论文报告了改进，但这些模型的实际应用仍然有限。最​​近的研究对这些模型产生了怀疑，将其结果归因于有缺陷的评估技术。然而，初始化的影响在很大程度上被忽视了。本文对初始化对 TSAD 模型性能的影响进行了批判性分析。我们大量的实验表明，TSAD 模型对窗口大小、种子数和规范化等超参数高度敏感。这种敏感性通常会导致性能的显著变化，可以利用这种变化来人为地夸大这些模型的报告功效。我们证明，即使初始化参数的微小变化也会导致性能变化，从而掩盖新模型架构所声称的改进。我们的研究结果强调了严格的评估协议和透明的预处理步骤报告的必要性，以确保异常检测方法的可靠性和公平性。本文呼吁更加谨慎地解读 TSAD 的进展，并鼓励开发更为强大和透明的评估实践，以推动该领域及其实际应用的发展。]]></description>
      <guid>https://arxiv.org/abs/2408.06620</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>利用输出改组攻击欺骗 SHAP</title>
      <link>https://arxiv.org/abs/2408.06509</link>
      <description><![CDATA[arXiv:2408.06509v1 公告类型：新
摘要：可解释的 AI~(XAI) 方法（例如 SHAP）可以帮助发现黑盒模型中的特征归因。如果该方法揭示了模型输出中“受保护特征”（例如性别、种族）的显著归因，则该模型被认为是不公平的。然而，对抗性攻击可以破坏 XAI 方法的检测。构建这种对抗模型的先前方法需要访问底层数据分布，这在许多实际场景中可能无法实现。我们放宽了这一限制，并提出了一种与数据无关的新型攻击系列，称为改组攻击。所提出的攻击策略可以适应任何经过训练的机器学习模型来欺骗基于 Shapley 值的解释。我们证明 Shapley 值无法检测到改组攻击。然而，估计 Shapley 值的算法，如线性 SHAP 和 SHAP，可以以不同程度的有效性检测这些攻击。我们通过使用真实数据集比较线性 SHAP 和 SHAP 的性能来证明攻击策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.06509</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>学习排名函数：从短期行为预测到长期用户满意度</title>
      <link>https://arxiv.org/abs/2408.06512</link>
      <description><![CDATA[arXiv:2408.06512v1 公告类型：新
摘要：我们提出了学习排名函数 (LRF)，该系统将短期用户项目行为预测作为输入，并输出一系列建议，直接优化长期用户满意度。大多数以前的工作都是基于优化启发式函数的超参数。我们建议将问题直接建模为一个优化问题，目标是最大化长期用户满意度。我们还开发了一种新颖的约束优化算法，可以稳定多目标优化的目标权衡。我们通过现场实验评估我们的方法，并描述其在 YouTube 上的部署。]]></description>
      <guid>https://arxiv.org/abs/2408.06512</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>利用随机特征进行算子学习：一种科学计算的工具</title>
      <link>https://arxiv.org/abs/2408.06526</link>
      <description><![CDATA[arXiv:2408.06526v1 公告类型：新
摘要：监督算子学习以输入输出对的形式使用训练数据来估计无限维空间之间的映射为中心。它正在成为补充传统科学计算的强大工具，而传统科学计算通常以函数空间之间的算子映射来构建。本文基于标量回归的经典随机特征方法，介绍了函数值随机特征方法。这导致了监督算子学习架构，该架构对于非线性问题实用，但结构足够完善，可以通过优化凸二次成本来促进高效训练。由于二次结构，训练后的模型具有收敛保证以及误差和复杂度界限，而这些属性对于大多数其他算子学习架构来说并不容易获得。从本质上讲，所提出的方法构建了随机算子的线性组合。事实证明，这是算子值核岭回归算法的低秩近似，因此该方法也与高斯过程回归有很强的联系。本文设计了函数值随机特征，这些特征适合参数偏微分方程产生的两个非线性算子学习基准问题的结构。数值结果证明了函数值随机特征方法的可扩展性、离散化不变性和可迁移性。]]></description>
      <guid>https://arxiv.org/abs/2408.06526</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>数据的核平方和自适应核学习：一种全局优化方法</title>
      <link>https://arxiv.org/abs/2408.06465</link>
      <description><![CDATA[arXiv:2408.06465v1 公告类型：新
摘要：本文研究了核平方和 (KSOS) 方法在增强数据核学习方面的应用，特别是在动态系统的背景下。传统的基于核的方法尽管理论上合理且数值效率高，但在选择最佳基核和参数调整方面经常遇到困难，尤其是基于梯度的方法容易陷入局部最优。KSOS 通过利用基于核的代理函数的全局优化框架来缓解这些问题，从而实现更可靠、更精确的动态系统学习。通过对 Logistic Map、Henon Map 和 Lorentz 系统进行全面的数值实验，KSOS 在最小化相对-$\rho$ 度量和提高核精度方面始终优于梯度下降。这些结果突出了 KSOS 在预测混沌动力系统行为方面的有效性，证明了它能够使内核适应底层动态，并增强基于内核的方法的稳健性和预测能力，使其成为各个科学领域时间序列分析的宝贵资产。]]></description>
      <guid>https://arxiv.org/abs/2408.06465</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>隐式神经表征助力精确 CFD 流场预测</title>
      <link>https://arxiv.org/abs/2408.06486</link>
      <description><![CDATA[arXiv:2408.06486v1 公告类型：新
摘要：尽管用于流场预测的深度学习框架众多，但其中大多数处理规则域上的流场，尽管最好的框架可以应对不规则域，但它们大多依赖于图网络，因此实际的工业应用目前仍然难以实现。我们提出了一个深度学习框架，用于预测飞机发动机涡轮机和压缩机叶片的三维流场。至关重要的是，我们将任何三维场视为坐标函数，该函数由我们称为骨干网的神经网络建模。它继承了基于坐标的 MLP 的属性，即在无限分辨率下任意拓扑域中离散化不可知的流场表示。首先，我们展示了骨干网在回归各种流态中单叶片排的三维稳态模拟中的性能：它可以准确地呈现重要的流动特性，例如边界层、尾流和冲击波。其次，我们引入了一个超网络，将叶片的表面网格映射到主干网络的参数。通过这样做，可以直接从叶片几何形状预测流动解决方案，而不管其参数化如何。主干网络和超网络共同构成了 CFD 求解器的高精度、内存效率高的数据驱动代理，对看不见的几何形状具有良好的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2408.06486</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>FedRobo：联邦学习驱动的自主机器人间通信，实现最佳化学喷雾</title>
      <link>https://arxiv.org/abs/2408.06382</link>
      <description><![CDATA[arXiv:2408.06382v1 公告类型：新
摘要：联邦学习使机器人能够从彼此的经验中学习，而无需依赖集中式数据收集。每个机器人独立维护一个作物状况和化学喷洒效果模型，并定期与车队中的其他机器人共享。通信协议旨在通过促进有关作物状况、天气和其他关键因素的信息交换来优化化学喷洒应用。联邦学习算法利用这些共享数据不断改进化学喷洒策略，减少浪费并提高作物产量。这种方法有可能通过提供可扩展且高效的作物保护解决方案来彻底改变农业行业。然而，仍然存在重大挑战，包括开发安全且强大的通信协议、设计有效整合来自多个来源的数据的联邦学习算法以及确保自主机器人的安全性和可靠性。所提出的基于集群的联邦学习方法还有效地减少了全局服务器上的计算负载并最大限度地减少了客户端之间的通信开销。]]></description>
      <guid>https://arxiv.org/abs/2408.06382</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>具有可学习间距的扩张卷积</title>
      <link>https://arxiv.org/abs/2408.06383</link>
      <description><![CDATA[arXiv:2408.06383v1 公告类型：新
摘要：本论文介绍并评估了可学习间距的扩张卷积 (DCLS) 方法。通过计算机视觉、音频和语音处理领域的各种监督学习实验，DCLS 方法被证明优于标准和高级卷积技术。研究分为几个步骤，首先分析文献和在 DCLS 方法开发之前的现有卷积技术。我们特别感兴趣的是与我们自己的方法密切相关并且对于捕捉我们方法的细微差别和独特性仍然至关重要的方法。我们研究的基石是将 DCLS 方法引入和应用于卷积神经网络 (CNN)，以及依赖于卷积和视觉注意方法的混合架构。DCLS 在分类、语义分割和对象检测等任务中被证明特别有效。该研究最初使用双线性插值，还探索了其他插值方法，发现高斯插值略微提高了性能。DCLS 方法进一步应用于脉冲神经网络 (SNN)，以实现神经网络内的突触延迟学习，最终可以转移到所谓的神经形态芯片。结果表明，对于该领域的某些基准任务，DCLS 方法作为 SNN 音频分类中的一种新技术脱颖而出。这些任务涉及具有高时间分量的数据集。此外，我们表明 DCLS 可以显著提高人工神经网络在多标签音频分类任务中的准确性。最后，我们讨论了所选的实验设置、其局限性、我们方法的局限性以及我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2408.06383</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>长期交通预测中连续时间流数据的多视图神经微分方程</title>
      <link>https://arxiv.org/abs/2408.06445</link>
      <description><![CDATA[arXiv:2408.06445v1 公告类型：新
摘要：长期交通流预测在智能交通中起着至关重要的作用，因为它允许交通管理人员提前调整决策。然而，由于连续时间流数据中的时空相关性和复杂的动态模式，这个问题具有挑战性。神经微分方程 (NDE) 是学习连续时间交通动态的最先进的方法之一。然而，传统的 NDE 模型在长期交通预测中面临问题，因为无法捕捉延迟交通模式、动态边缘（位置到位置相关性）模式和突变趋势模式。为了填补这一空白，我们提出了一种称为多视图神经微分方程的新 NDE 架构。我们的模型通过学习神经微分方程中的潜在多重表示来捕获不同状态变量（视图）中的当前状态、延迟状态和趋势。在多个真实世界交通数据集上进行的大量实验表明，我们提出的方法优于最先进的方法，并且在长期预测中实现了卓越的预测精度以及在输入有噪声或缺失的情况下的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2408.06445</guid>
      <pubDate>Thu, 15 Aug 2024 03:16:52 GMT</pubDate>
    </item>
    </channel>
</rss>