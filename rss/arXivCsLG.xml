<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 17 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于物理的植物性食品微尺度干燥机器学习：计算模型和实验见解的系统回顾</title>
      <link>https://arxiv.org/abs/2501.09034</link>
      <description><![CDATA[arXiv:2501.09034v1 公告类型：新
摘要：本综述研究了植物性食品材料 (PBFM) 干燥过程中微尺度细胞变化的研究现状，特别强调了计算建模方法。本综述解决了微尺度研究中对先进计算方法的迫切需求。我们系统地分析了 PBFM 干燥的实验研究，强调了它们在捕捉细胞级现象方面的贡献和局限性，包括在不同干燥条件下数据采集和测量精度方面的挑战。从传统的数值方法到当代最先进的方法，彻底研究了微观结构研究的计算模型的演变，特别关注它们处理植物细胞材料复杂非线性特性的能力。特别关注数据驱动模型的出现及其在预测 PBFM 干燥过程中微尺度细胞行为方面的局限性，特别是解决数据集获取和模型泛化方面的挑战。本综述深入分析了物理信息机器学习 (PIML) 框架，研究了它们的理论基础、相关领域的当前应用以及将物理原理与神经网络架构相结合的独特优势。通过这项全面评估，我们发现了现有方法中的关键差距，评估了不同建模方法之间的权衡，并为未来的研究方向提供了见解，以增进我们对 PBFM 干燥过程中细胞水平转变的理解。本综述最后提出了整合实验和计算方法以推进食品保鲜技术领域的建议。]]></description>
      <guid>https://arxiv.org/abs/2501.09034</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>熵正则化的平均奖励强化学习</title>
      <link>https://arxiv.org/abs/2501.09080</link>
      <description><![CDATA[arXiv:2501.09080v1 公告类型：新
摘要：近年来，强化学习 (RL) 的平均奖励公式因其能够在不打折的情况下解决时间延长的问题而引起了越来越多的关注。RL 算法独立地受益于熵正则化：一种用于使最佳策略随机化的方法，从而对噪声更具鲁棒性。尽管这两种方法具有明显的优势，但熵正则化与平均奖励目标的结合在文献中研究得并不充分，并且针对这种设置的算法开发有限。为了解决该领域的这一空白，我们开发了使用函数近似解决熵正则化平均奖励 RL 问题的算法。我们通过实验验证了我们的方法，并将其与 RL 标准基准上的现有算法进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2501.09080</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从价值函数推断转变动力学</title>
      <link>https://arxiv.org/abs/2501.09081</link>
      <description><![CDATA[arXiv:2501.09081v1 公告类型：新
摘要：在强化学习中，价值函数通常被训练来求解贝尔曼方程，该方程将当前值与未来值联系起来。这种时间依赖性暗示价值函数可能包含有关环境过渡动态的隐式信息。通过重新排列贝尔曼方程，我们表明收敛的价值函数编码了环境底层动态的模型。我们基于这一见解提出了一种直接从价值函数推断动态模型的简单方法，从而有可能减轻对显式模型学习的需求。此外，我们探讨了下一状态可识别性的挑战，讨论了推断的动态模型定义明确的条件。我们的工作为在动态建模中利用价值函数提供了理论基础，并为连接无模型和基于模型的强化学习开辟了一条新途径。]]></description>
      <guid>https://arxiv.org/abs/2501.09081</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相似量化相对差异学习用于改进分子活性预测</title>
      <link>https://arxiv.org/abs/2501.09103</link>
      <description><![CDATA[arXiv:2501.09103v1 公告类型：新 
摘要：准确预测分子活性对于有效的药物发现至关重要，但由于数据集有限且嘈杂，这仍然具有挑战性。我们引入了相似性量化相对学习 (SQRL)，这是一种学习框架，它将分子活性预测重新表述为结构相似的化合物对之间的相对差异学习。SQRL 使用预先计算的分子相似性来增强图神经网络和其他架构的训练，并显着提高药物发现中常见的低数据方案的准确性和泛化能力。我们通过对公共数据集以及专有行业数据进行基准测试，展示了其广泛的适用性和现实世界的潜力。我们的研究结果表明，利用相似性感知的相对差异为分子活性预测提供了有效的范例。]]></description>
      <guid>https://arxiv.org/abs/2501.09103</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考训练后量化：引入统计预校准方法</title>
      <link>https://arxiv.org/abs/2501.09107</link>
      <description><![CDATA[arXiv:2501.09107v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的计算复杂性日益增加，开发量化等高效部署策略变得至关重要。最先进的训练后量化 (PTQ) 技术通常依赖于校准过程来保持这些模型的准确性。然而，虽然这些校准技术可以提高某些领域的性能，但在其他领域可能不那么有效。本文旨在引起人们对可以缓解此类问题的稳健统计方法的关注。我们提出了一种权重自适应 PTQ 方法，该方法可以被视为基于校准的 PTQ 方法的前身，通过最小化量化权重和原始训练权重之间的 Kullback-Leibler 散度来指导量化过程以保持权重的分布。这种最小化确保量化模型在很大程度上保留了原始模型的香农信息内容，从而保证在许多任务中实现稳健而高效的部署。因此，我们提出的方法可以与大多数常见的基于校准的 PTQ 方法相媲美，建立了一个新的预校准步骤，用于进一步通过校准调整量化权重。我们表明，我们的预校准结果在各种 LLM 上达到了与一些现有的基于校准的 PTQ 方法相同的精度。]]></description>
      <guid>https://arxiv.org/abs/2501.09107</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多视图异构图注意网络进行多类交通分配</title>
      <link>https://arxiv.org/abs/2501.09117</link>
      <description><![CDATA[arXiv:2501.09117v1 公告类型：新
摘要：当使用传统的基于优化的方法时，解决大型网络的交通分配问题在计算上具有挑战性。在我们的研究中，我们开发了一种涉及多类车辆的交通分配创新代理模型。我们通过采用异构图神经网络来实现这一点，该网络使用针对不同车辆类别定制的多视图图注意机制，以及连接起点-目的地对的附加链接。我们还将基于节点的流守恒定律集成到损失函数中。因此，我们的模型遵循流量守恒定律，同时提供高度准确的链接流量和利用率预测。通过对城市交通网络进行的数值实验，我们证明我们的模型在用户平衡和系统优化版本的交通分配中，在收敛速度和预测准确性方面都超越了传统的神经网络方法。]]></description>
      <guid>https://arxiv.org/abs/2501.09117</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与浅线性网络中的梯度流相比，梯度下降线性收敛到更平坦的最小值</title>
      <link>https://arxiv.org/abs/2501.09137</link>
      <description><![CDATA[arXiv:2501.09137v1 公告类型：新
摘要：我们研究了具有单个输入和输出的深度 2 线性神经网络的梯度下降 (GD) 动态。我们表明，即使步长较大（约 $2/\textrm{sharpness}$），GD 也能以显式线性速率收敛到训练损失的全局最小值。它仍然可以收敛更大的步长，但速度可能非常慢。我们还描述了 GD 收敛到的解，该解的范数和锐度低于梯度流解。我们的分析揭示了收敛速度和隐式正则化幅度之间的权衡。这揭示了在“稳定边缘”进行训练的好处，它通过延迟收敛来诱导额外的正则化，并可能对训练更复杂的模型产生影响。]]></description>
      <guid>https://arxiv.org/abs/2501.09137</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用无人机群进行内容传播的联邦多臂老虎机学习</title>
      <link>https://arxiv.org/abs/2501.09146</link>
      <description><![CDATA[arXiv:2501.09146v1 公告类型：新
摘要：本文介绍了一种无人机支持的内容管理架构，适用于在各种灾难场景中通信隔离的用户社区中的关键内容访问。所提出的架构利用固定锚无人机和移动微型无人机的混合网络进行无处不在的内容传播。锚无人机配备了垂直和横向通信链路，为本地用户提供服务，而移动微型运输无人机则通过增强的移动性将覆盖范围扩大到整个社区。重点是开发一种内容传播系统，该系统可以动态学习最佳缓存策略以最大限度地提高内容可用性。核心创新是基于分布式联邦多臂老虎机学习的自适应内容传播框架。目标是根据地理时间内容流行度和用户需求变化优化无人机内容缓存决策。还引入了一种选择性缓存算法，通过结合无人机间信息共享来减少冗余内容复制。该方法策略性地保留了用户偏好的独特性，同时融合了分布式学习系统中的智能。这种方法提高了学习算法适应不同用户偏好的能力。功能验证和性能评估证实了所提出的架构在不同网络规模、无人机群和内容流行度模式中的实用性。]]></description>
      <guid>https://arxiv.org/abs/2501.09146</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解外推法：因果视角</title>
      <link>https://arxiv.org/abs/2501.09163</link>
      <description><![CDATA[arXiv:2501.09163v1 公告类型：新
摘要：处理分布偏移的规范工作通常需要整个目标分布位于训练分布内。然而，实际情况往往只涉及少数目标样本，可能位于训练支持之外，这需要外推能力。在这项工作中，我们旨在提供何时可以进行外推的理论理解，并提供实现外推的原则方法，而无需支持目标分布。为此，我们用体现因果机制最小变化原理的潜在变量模型来制定外推问题。在这个公式下，我们将外推问题转化为潜在变量识别问题。我们提供了关于偏移属性和估计目标的现实条件，即使只有一个非支持目标样本可用，也可以实现识别，从而解决最具挑战性的场景。我们的理论揭示了底层流形的平滑度和偏移属性之间错综复杂的相互作用。我们展示了我们的理论结果如何为实际自适应算法的设计提供参考。通过对合成数据和真实数据进行实验，我们验证了我们的理论发现及其实际意义。]]></description>
      <guid>https://arxiv.org/abs/2501.09163</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你所需要的只是注意力，直到你需要保留为止</title>
      <link>https://arxiv.org/abs/2501.09166</link>
      <description><![CDATA[arXiv:2501.09166v1 公告类型：新
摘要：这项工作为基于 Transformer 的架构引入了一种新颖的保留层机制，解决了它们固有的内在保留能力不足的问题。与可以编码和动态调用符号模板的人类认知不同，生成式预训练 Transformer 仅依赖于固定的预训练权重和短暂的上下文窗口，从而限制了它们的适应性。所提出的保留层包含一个持久内存模块，能够实时填充数据、动态调用和引导输出生成。此增强功能允许模型跨会话存储、更新和重用观察到的模式，从而实现增量学习并弥合静态预训练与动态上下文敏感适应之间的差距。保留层设计与社会学习过程并行，包括注意力、保留、再现和动机阶段。从技术上讲，它集成了记忆注意机制和情景缓冲区来管理记忆可扩展性、减轻过度拟合并确保有效调用。应用范围涵盖自适应个人助理、实时欺诈检测、自主机器人、内容审核和医疗诊断。在每个领域，保留机制使系统能够逐步学习、个性化输出并有效应对不断变化的现实世界挑战。通过模拟人类学习的关键方面，这种增强保留能力的架构促进了更流畅、响应更快的 AI 范式，为动态、会话感知模型铺平了道路，这些模型将传统 Transformer 的功能扩展到需要持续适应的领域。]]></description>
      <guid>https://arxiv.org/abs/2501.09166</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用局部拓扑特征增强图形表示学习</title>
      <link>https://arxiv.org/abs/2501.09178</link>
      <description><![CDATA[arXiv:2501.09178v1 公告类型：新
摘要：图上的表示学习是一个基本问题，在各种任务中都至关重要。图神经网络是图表示学习的主要方法，但其表示能力有限。因此，明确提取并将高阶拓扑和几何信息合并到这些模型中是有益的。在本文中，我们提出了一种基于持久同源性理论提取图的丰富连通性信息的原则性方法。我们的方法利用拓扑特征来增强图神经网络的表示学习，并在各种节点分类和链接预测基准上实现最先进的性能。我们还探索了拓扑特征端到端学习的选项，即在学习过程中将拓扑计算视为可微分算子。我们的理论分析和实证研究为在图学习任务中使用拓扑特征提供了见解和潜在指导。]]></description>
      <guid>https://arxiv.org/abs/2501.09178</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测试学习算法的噪声假设</title>
      <link>https://arxiv.org/abs/2501.09189</link>
      <description><![CDATA[arXiv:2501.09189v1 公告类型：新
摘要：我们提出了计算学习理论中的一个基本问题：我们能否有效地测试训练集是否满足给定噪声模型的假设？尽管数十年来一直在研究噪声条件下的学习，但这个问题仍然没有得到解决。在这项工作中，我们表明这项任务是可处理的，并提出了第一个有效的算法来测试训练数据上的各种噪声假设。
为了对这个问题进行建模，我们扩展了 Rubinfeld 和 Vasilyan (2023) 最近提出的可测试学习框架，并要求学习者运行满足以下两个条件的相关测试：(1) 每当测试接受时，学习者都会输出分类器以及最优性证书，以及 (2) 对于根据边际分布和噪声模型上的指定建模假设绘制的任何数据集，测试都必须通过。然后，我们考虑在具有 Massart 噪声的高斯边际上学习半空间的问题（其中每个标签可以以小于 $1/2$ 的概率翻转，具体取决于输入特征），并给出一个完全多项式时间可测试的学习算法。
我们还展示了在存在结构化噪声的情况下的经典学习设置与可测试学习之间的区别。事实上，对于随机分类噪声的简单情况（其中每个标签以固定概率 $\eta = 1/2$ 翻转），我们表明可测试学习需要超多项式时间，而经典学习则很简单。]]></description>
      <guid>https://arxiv.org/abs/2501.09189</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应基于规律的变换 (ALT)：一种用于时间序列分类的轻量级特征表示</title>
      <link>https://arxiv.org/abs/2501.09217</link>
      <description><![CDATA[arXiv:2501.09217v1 公告类型：新
摘要：时间序列分类 (TSC) 是众多领域的基础，包括金融、医疗保健和环境监测。然而，传统的 TSC 方法往往难以应对时间序列数据固有的复杂性和多变性。基于我们之前对线性基于法则的变换 (LLT) 的研究 - 通过基于关键数据模式变换特征空间来提高分类准确性 - 我们引入了自适应基于法则的变换 (ALT)。ALT 通过结合可变长度的移位时间窗口增强了 LLT，使其能够捕获不同长度的区别模式，从而更有效地处理复杂的时间序列。通过将特征映射到线性可分空间，ALT 提供了一种快速、稳健且透明的解决方案，仅使用几个超参数即可实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.09217</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语音进行年龄预测的网格线性模型</title>
      <link>https://arxiv.org/abs/2501.09229</link>
      <description><![CDATA[arXiv:2501.09229v1 公告类型：新
摘要：语音生物识别任务（例如年龄估计）需要对语音特征和生物识别变量之间通常复杂的关系进行建模。虽然深度学习模型可以处理这种复杂性，但它们通常需要大量准确标记的数据才能表现良好。对于基于语音的年龄预测等生物识别任务来说，此类数据通常很少。另一方面，线性回归等简单模型可以处理较小的数据集，但通常无法推广到数据中存在的底层非线性模式。在本文中，我们提出了镶嵌线性模型 (TLM)，这是一种分段线性方法，结合了线性模型的简单性和非线性函数的能力。TLM 将特征空间镶嵌为凸区域，并在每个区域内拟合线性模型。我们使用分层贪婪分区优化镶嵌和线性模型。我们在 TIMIT 数据集上对 TLM 进行了语音年龄预测任务评估，其表现优于最先进的深度学习模型。]]></description>
      <guid>https://arxiv.org/abs/2501.09229</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mono-Forward：利用局部误差进行高效神经网络训练的无反向传播算法</title>
      <link>https://arxiv.org/abs/2501.09238</link>
      <description><![CDATA[arXiv:2501.09238v1 公告类型：新
摘要：反向传播是实现神经网络训练中最佳精度的标准方法，但它通常会带来高昂的内存成本并且缺乏生物学上的合理性。在本文中，我们介绍了 Mono-Forward 算法，这是一种纯局部分层学习方法，灵感来自 Hinton 的 Forward-Forward 框架。与反向传播不同，Mono-Forward 仅使用本地可用信息优化每一层，消除了对全局误差信号的依赖。我们在多个基准测试中对多层感知器和卷积神经网络上的 Mono-Forward 进行了评估，包括 MNIST、Fashion-MNIST、CIFAR-10 和 CIFAR-100。测试结果表明，Mono-Forward 在所有任务中的精度始终与反向传播相当甚至超过反向传播，内存使用量显著减少且更均匀，可并行性更好，收敛速度相当。]]></description>
      <guid>https://arxiv.org/abs/2501.09238</guid>
      <pubDate>Fri, 17 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>