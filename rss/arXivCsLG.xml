<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 01 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>InfiniGen：通过动态 KV 缓存管理实现大型语言模型的高效生成推理</title>
      <link>https://arxiv.org/abs/2406.19707</link>
      <description><![CDATA[arXiv:2406.19707v1 公告类型：新 
摘要：基于 Transformer 的大型语言模型 (LLM) 在各种自然语言处理任务中表现出色。然而，为生成长内容提供 LLM 推理是一项挑战，因为瞬态状态（称为键值 (KV) 缓存）占用大量内存，并且会随着序列长度和批次大小而扩展。在本文中，我们提出了 InfiniGen，这是一种专为长文本生成量身定制的新型 KV 缓存管理框架，可与现代基于卸载的推理系统协同工作。InfiniGen 利用了关键见解，即可以通过对当前层的输入以及后续层的部分查询权重和键缓存进行最少的排练来推测对计算 Transformer 中的后续注意层至关重要的一些重要标记。这样，我们就可以只预取必要的 KV 缓存条目（而不是全部提取），从而减轻基于卸载的 LLM 服务系统中从主机内存提取的开销。我们对几个代表性 LLM 的评估表明，与之前的 KV 缓存管理方法相比，InfiniGen 将现代基于卸载的系统的整体性能提高了 3.00 倍，同时提供了更好的模型准确性。]]></description>
      <guid>https://arxiv.org/abs/2406.19707</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:12 GMT</pubDate>
    </item>
    <item>
      <title>ACES：事件流数据集的自动群组提取系统</title>
      <link>https://arxiv.org/abs/2406.19653</link>
      <description><![CDATA[arXiv:2406.19653v1 公告类型：新
摘要：可重复性仍然是医疗保健机器学习 (ML) 面临的重大挑战。在这个领域，数据集、模型管道甚至任务/队列定义通常都是私有的，这给共享、迭代和理解电子健康记录 (EHR) 数据集上的 ML 结果带来了重大障碍。在本文中，我们通过引入事件流数据集的自动队列提取系统 (ACES) 解决了这一问题的很大一部分。该工具旨在同时简化医疗保健中 ML 任务/队列的开发，并实现这些队列的复制，无论是在单个数据集的精确级别还是在跨数据集的概念级别。为了实现这一点，ACES 提供了 (1) 一种高度直观且富有表现力的配置语言，用于定义特定于数据集的概念和与数据集无关的纳入/排除标准，以及 (2) 一个管道，用于从真实世界数据中自动提取符合这些定义标准的患者记录。 ACES 可以自动应用于医疗事件数据标准 (MEDS) 或 EventStreamGPT (ESGPT) 格式的任何数据集，或可以以事件流形式提取必要任务特定谓词的*任何*数据集。ACES 有可能显著降低定义 ML 任务的门槛，重新定义研究人员与 EHR 数据集交互的方式，并显著改善这种模式下 ML 研究的可重复性状态。ACES 可在 https://github.com/justin13601/aces 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.19653</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>LLMEasyQuant——一款易于使用的 LLM 量化工具包</title>
      <link>https://arxiv.org/abs/2406.19657</link>
      <description><![CDATA[arXiv:2406.19657v1 Announce Type: new 
摘要：目前针对LLM量化的量化方法有很多，但易用性强、易于本地部署的量化方法很少。TensorRT、Quanto等包底层结构较多，内部函数自调用，不利于开发者个性化开发和学习部署。因此，我们开发了LLMEasyQuant，这是一款以易于量化部署为目标、易用性强、适合初学者学习的包。]]></description>
      <guid>https://arxiv.org/abs/2406.19657</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>有限基柯尔莫哥洛夫-阿诺德网络：数据驱动和物理信息问题的域分解</title>
      <link>https://arxiv.org/abs/2406.19662</link>
      <description><![CDATA[arXiv:2406.19662v1 公告类型：新
摘要：Kolmogorov-Arnold 网络 (KAN) 最近引起了人们的关注，作为科学机器学习中多层感知器 (MLP) 的替代品。然而，即使对于相对较小的网络，KAN 的训练成本也可能很高。受有限基物理信息神经网络 (FBPINN) 的启发，在这项工作中，我们开发了一种 KAN 的域分解方法，允许并行训练多个小型 KAN，以提供多尺度问题的准确解决方案。我们表明，有限基 KAN (FBKAN) 可以在有噪声数据的情况下提供准确的结果，并进行物理信息训练。]]></description>
      <guid>https://arxiv.org/abs/2406.19662</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习的个性化解读：一种虚拟概念方法</title>
      <link>https://arxiv.org/abs/2406.19631</link>
      <description><![CDATA[arXiv:2406.19631v1 公告类型：新
摘要：处理非IID数据是联邦学习研究中的一个开放挑战。现有的FL方法，包括鲁棒FL和个性化FL，旨在提高模型性能，而不考虑跨客户端解释非IID。本文旨在设计一种新颖的FL方法来稳健和解释跨客户端的非IID数据。具体来说，我们将每个客户端的数据集解释为概念向量的混合，每个概念向量都代表一个可解释的概念给最终用户。这些概念向量可以在人机循环过程中预定义或细化，也可以通过联邦学习系统的优化过程进行学习。除了可解释性之外，客户端特定个性化的清晰度还可以应用于增强FL系统训练过程的鲁棒性。所提出方法的有效性已在基准数据集上得到验证。]]></description>
      <guid>https://arxiv.org/abs/2406.19631</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>使用结构化图形模型和 Transformer 进行模型预测模拟</title>
      <link>https://arxiv.org/abs/2406.19635</link>
      <description><![CDATA[arXiv:2406.19635v1 公告类型：新
摘要：我们提出了一种基于变换器和概率图模型 (PGM) 模拟多个交互代理（道路使用者）轨迹的方法，并将其应用于 Waymo SimAgents 挑战。变换器基线基于 MTR 模型，该模型根据过去的轨迹和静态道路布局特征预测多个未来轨迹。然后，我们使用 PGM 改进这些生成的轨迹，其中包含编码先验知识的因素，例如对平滑轨迹的偏好以及避免与静态障碍物和其他移动代理发生碰撞。我们使用高斯-牛顿法在此 PGM 中执行（近似）MAP 推理。最后，我们在接下来的 $T=8 \Delta$ 个时间步骤中，为 $N \sim 100$ 个代理中的每一个代理采样 $K=32$ 条轨迹，其中 $\Delta=10$ 是每秒的采样率。遵循模型预测控制 (MPC) 范式，我们只返回每一步预测轨迹的第一个元素，然后重新规划，以便模拟可以不断适应不断变化的环境。因此，我们将我们的方法称为“模型预测模拟”或 MPS。我们表明 MPS 改进了 MTR 基线，尤其是在碰撞率等安全关键指标方面。此外，我们的方法与任何底层预测模型兼容，并且不需要额外的训练，因此我们相信它对社区做出了宝贵的贡献。]]></description>
      <guid>https://arxiv.org/abs/2406.19635</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习数据质量维度和工具综述</title>
      <link>https://arxiv.org/abs/2406.19614</link>
      <description><![CDATA[arXiv:2406.19614v1 公告类型：新
摘要：机器学习（ML）技术已在我们社会的几乎所有方面发挥重要作用，数据质量（DQ）对于ML模型的性能、公平性、稳健性、安全性和可扩展性至关重要。随着以数据为中心的AI中数据的庞大和复杂，探索性数据分析（EDA）和交叉验证（CV）等传统方法面临挑战，凸显了掌握DQ工具的重要性。在本次调查中，我们回顾了过去5年中的17种DQ评估和改进工具。通过介绍这些工具中嵌入的DQ维度、指标和主要功能，我们比较了它们的优势和局限性，并提出了开发用于ML的开源DQ工具的路线图。基于对挑战和新兴趋势的讨论，我们进一步强调了大型语言模型（LLM）和生成式AI在ML DQ评估和改进中的潜在应用。我们相信，这项全面的调查可以增强对机器学习中 DQ 的理解，并推动以数据为中心的人工智能的发展。本次调查中研究的文献的完整列表可在 GitHub 上找到：https://github.com/haihua0913/awesome-dq4ml。]]></description>
      <guid>https://arxiv.org/abs/2406.19614</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>VarteX：通过分布式变量表示增强天气预报</title>
      <link>https://arxiv.org/abs/2406.19615</link>
      <description><![CDATA[arXiv:2406.19615v1 公告类型：新
摘要：天气预报对各种人类活动至关重要。最近的数据驱动模型通过利用深度学习在预报性能上胜过数值天气预报。然而，在有效处理多个气象变量方面仍然存在挑战。本研究提出了一种新的变量聚合方案和一个有效的学习框架来应对这一挑战。实验表明，VarteX 在预测性能方面优于传统模型，需要的参数和资源明显更少。证明了通过多次聚合和区域分割训练进行学习的有效性，从而实现了更高效、更准确的基于深度学习的天气预报。]]></description>
      <guid>https://arxiv.org/abs/2406.19615</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>强凸性和 Lipschitz Hessian 下的随机零阶优化：极小最大样本复杂度</title>
      <link>https://arxiv.org/abs/2406.19617</link>
      <description><![CDATA[arXiv:2406.19617v1 公告类型：新
摘要：随机零阶反馈下的凸函数优化一直是在线学习中的主要和具有挑战性的问题。在这项工作中，我们考虑优化二阶光滑和强凸函数的问题，其中算法只能通过查询的目标函数的噪声评估来访问。我们通过开发匹配的上下限，为极小极大简单遗憾率提供了第一个严格的表征。我们提出了一种结合了引导阶段和镜像下降阶段的算法。我们的主要技术创新包括在高阶平滑条件下对球面采样梯度估计器的清晰表征，这使得算法能够最佳地平衡偏差-方差权衡，以及引导阶段的新迭代方法，这可以保持无界 Hessian 的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.19617</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动的 Lipschitz 连续性：一种提高对抗鲁棒性的经济有效方法</title>
      <link>https://arxiv.org/abs/2406.19622</link>
      <description><![CDATA[arXiv:2406.19622v1 公告类型：新
摘要：深度神经网络 (DNN) 的安全性和鲁棒性越来越受到关注。本文旨在提供理论基础和实用解决方案，以确保 DNN 的可靠性。我们探索 Lipschitz 连续性的概念来证明 DNN 对对抗性攻击的鲁棒性，对抗性攻击旨在通过在输入中添加不可察觉的扰动来误导网络。我们提出了一种新算法，将输入域重新映射到受限范围内，从而降低 Lipschitz 常数并潜在地增强鲁棒性。与现有的对抗性训练模型不同，这些模型通过从其他数据集或生成模型中引入额外的示例来增强鲁棒性，我们的方法几乎是免费的，因为它可以与现有模型集成而无需重新训练。实验结果证明了我们方法的通用性，因为它可以与各种模型相结合并实现鲁棒性的增强。此外，我们的方法在 RobustBench 排行榜上对 CIFAR10、CIFAR100 和 ImageNet 数据集实现了最佳稳健准确度。]]></description>
      <guid>https://arxiv.org/abs/2406.19622</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>元梯度搜索控制：一种提高动态规划效率的方法</title>
      <link>https://arxiv.org/abs/2406.19561</link>
      <description><![CDATA[arXiv:2406.19561v1 公告类型：新
摘要：我们研究强化学习 (RL) 系统如何在从不完善的环境模型中学习时保持样本效率。当学习系统资源受限且处于环境动态变化的连续设置中时，这尤其具有挑战性。为了应对这些挑战，我们的论文介绍了一种在线元梯度算法，该算法调整在 Dyna 式规划期间查询状态的概率。我们的研究将这种元梯度方法的总体经验性能与采用传统采样策略的基线进行了比较。结果表明，我们的方法提高了规划过程的效率，从而提高了整个学习过程的样本效率。总体而言，我们观察到我们的元学习解决方案避免了传统规划方法的几种病态，例如采样不准确的转换和那些阻碍信用分配的病态。我们相信这些发现在未来的工作中可能对大规模设计基于模型的 RL 系统有用。]]></description>
      <guid>https://arxiv.org/abs/2406.19561</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>Wasserstein 距离中的实例最优隐私密度估计</title>
      <link>https://arxiv.org/abs/2406.19566</link>
      <description><![CDATA[arXiv:2406.19566v1 公告类型：新
摘要：从样本估计分布的密度是统计学中的一个基本问题。在许多实际设置中，Wasserstein 距离是密度估计的合适误差度量。例如，在估计某个地理区域的人口密度时，较小的 Wasserstein 距离意味着估计值能够大致捕捉到人口质量的位置。在这项工作中，我们研究了 Wasserstein 距离中的差分隐私密度估计。我们设计并分析了可以适应简单实例的该问题的实例最优算法。
对于 $\mathbb{R}$ 上的分布 $P$，我们考虑了一个强大的实例最优性概念：对于某个分布 $Q_P$，均匀实现实例最优估计率的算法与被告知分布为 $P$ 或 $Q_P$ 的算法具有竞争力，其中 $Q_P$ 的概率密度函数 (pdf) 在 $P$ 的 pdf 的 2 倍以内。对于 $\mathbb{R}^2$ 上的分布，我们使用不同的实例最优性概念。如果一个算法与给定分布密度的常数因子乘法近似的算法具有竞争力，我们就说该算法是实例最优的。我们描述了这两种设置中的实例最优估计率，并表明它们是均匀可实现的（最多多对数因子）。我们对 $\mathbb{R}^2$ 的方法扩展到任意度量空间，因为它通过分层分离的树进行。作为一个特例，我们的结果导致离散分布的 TV 距离中的实例最优私人学习。]]></description>
      <guid>https://arxiv.org/abs/2406.19566</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>论向量自回归模型中的反事实干预</title>
      <link>https://arxiv.org/abs/2406.19573</link>
      <description><![CDATA[arXiv:2406.19573v1 公告类型：新
摘要：反事实推理使我们能够探索假设情景，以解释我们决策的影响。但是，如果不建立适当的数学框架，就不可能解决此类问题。在这项工作中，我们在向量自回归 (VAR) 过程的背景下引入了反事实推理问题。我们还将因果模型的推理制定为联合回归任务，其中我们使用有干预和无干预的数据进行推理。在学习模型后，我们利用 VAR 模型的线性来准确预测反事实干预的效果。此外，我们量化了过去反事实干预的总因果影响。该项目的源代码可在 https://github.com/KurtButler/counterfactual_interventions 免费获取。]]></description>
      <guid>https://arxiv.org/abs/2406.19573</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>好得难以置信？使用 DP 权重将任何模型转换为差分隐私</title>
      <link>https://arxiv.org/abs/2406.19507</link>
      <description><![CDATA[arXiv:2406.19507v1 公告类型：新
摘要：想象一下使用差分隐私随机梯度下降 (DP-SGD) 训练机器学习模型，结果发现训练后噪声水平要么太高，削弱了模型的效用，要么太低，损害了隐私。可怕的现实是：你必须从头开始漫长的训练过程。但如果你能避免这种再训练的噩梦呢？在这项研究中，我们介绍了一种突破性的方法（据我们所知），在训练后将差分隐私噪声应用于模型的权重。我们为这种新方法的隐私界限提供了全面的数学证明，使用形式化方法来验证其隐私保证，并使用成员推理攻击和性能评估对其有效性进行实证评估。该方法允许进行一次训练，然后进行事后噪声调整以实现最佳隐私效用权衡。我们将这种新颖的微调模型（DP-Weights 模型）与传统的 DP-SGD 模型进行了比较，结果表明我们的方法在统计上具有相似的性能和隐私保证。我们的结果验证了训练后噪声应用的有效性，有望在微调差分隐私参数方面节省大量时间并具有灵活性，使其成为在实际场景中部署差分隐私模型的实用替代方案。]]></description>
      <guid>https://arxiv.org/abs/2406.19507</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:07 GMT</pubDate>
    </item>
    <item>
      <title>适用于科学应用的可靠边缘机器学习硬件</title>
      <link>https://arxiv.org/abs/2406.19522</link>
      <description><![CDATA[arXiv:2406.19522v1 公告类型：新
摘要：极端数据速率科学实验会产生大量数据，需要高效的 ML 边缘处理。这为 ML 算法的 VLSI 实现带来了独特的验证挑战：在实验软件框架中启用位精确功能模拟以进行性能验证，验证这些 ML 模型在极端量化和修剪下是否稳健，以及启用超细粒度模型检查以实现高效的容错。我们讨论了在极端实验环境中在如此严格的延迟、资源、功率和面积要求下在科学边缘开发和验证可靠算法的方法。我们研究了开发稳健算法的指标，提出了初步结果和缓解策略，并总结了这些和未来研究方向的展望，以实现开发自主科学实验方法以加速科学发现的长期目标。]]></description>
      <guid>https://arxiv.org/abs/2406.19522</guid>
      <pubDate>Tue, 02 Jul 2024 03:16:07 GMT</pubDate>
    </item>
    </channel>
</rss>