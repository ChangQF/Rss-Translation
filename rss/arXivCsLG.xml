<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 机器学习 (cs.LG) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Tue, 09 Jan 2024 06:18:26 GMT</lastBuildDate>
    <item>
      <title>提高深度学习错误的再现性：一项实证研究。 （arXiv：2401.03069v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.03069</link>
      <description><![CDATA[背景：深度学习在各个领域都取得了显着的进展。
然而，与传统软件系统一样，深度学习系统也存在缺陷，
这可能会产生严重影响，涉及自动驾驶的碰撞事故就证明了这一点
汽车。尽管深度学习技术取得了巨大进步，但仍然很少
研究重点是重现深度学习错误，这阻碍了解决
他们。现有文献表明，只有 3% 的深度学习错误是由
可重复，强调需要进一步研究。

目标：本文检查深度学习错误的重现性。我们
识别可以改进深度学习的编辑操作和有用信息
错误重现性。

方法：首先，我们从 Stack 构建包含 668 个深度学习 bug 的数据集
跨 3 个框架和 22 个架构的 Overflow 和 Defects4ML。第二，我们
使用分层抽样选择 102 个错误并尝试确定它们
再现性。在重现这些错误时，我们识别编辑操作并
其繁殖所需的有用信息。第三，我们使用Apriori
识别有用信息并编辑重现所需操作的算法
特定的错误类型。最后，我们与 22 名开发人员进行了用户研究
评估我们的研究结果在现实生活中的有效性。

结果：我们成功重现了 85 个错误并确定了 10 个编辑操作
以及五个可以帮助我们重现深度学习的有用信息类别
错误。我们的研究结果将 bug 重现性提高了 22.92%，并减少了
根据我们的用户研究，再现时间缩短了 24.35%。

结论：我们的研究解决了深度学习错误的关键问题
再现性。从业者和研究人员可以利用我们的发现
提高深度学习错误的重现性。
]]></description>
      <guid>http://arxiv.org/abs/2401.03069</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>用于持续图学习的拓扑感知图粗化框架。 （arXiv：2401.03077v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03077</link>
      <description><![CDATA[图的持续学习解决了训练图神经网络的问题
网络（GNN），图数据以流方式到达，模型
当使用新数据更新时，往往会忘记以前任务中的知识。
传统的持续学习策略（例如体验重播）可以
然而，适应流图时，这些方法经常面临诸如
由于保存图拓扑的效率低下并且无法捕获
新旧任务之间的关联。为了应对这些挑战，我们建议
TA$\mathbb{CO}$，一个 (t)opology-(a)ware 图 (co)arsening 和 (co)ntinual
将先前任务的信息存储为简​​化的学习框架
图形。在每个时间段，这个简化的图都会通过与新的相结合来扩展
图形并对齐共享节点，然后它经历一个“缩小”过程
减少以保持稳定的规模。我们设计了一个图粗化算法
基于节点表示近似度来有效地减少图和
保留拓扑信息。我们通过实证证明学习
简化图上的过程可以近似于原始图的过程。我们的
实验验证了所提出的框架在三个方面的有效性
使用不同骨干 GNN 模型的真实世界数据集。
]]></description>
      <guid>http://arxiv.org/abs/2401.03077</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>URLLC 流量的可靠性优化用户准入控制：神经上下文强盗方法。 （arXiv：2401.03059v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03059</link>
      <description><![CDATA[超可靠的低延迟通信 (URLLC) 是
下一代无线网络中广泛的新兴服务。 URLLC
从根本上依赖于网络主动确定是否有能力
有足够的资源来支持 URLLC 流量，因此，
防止所谓的细胞过载。尽管如此，实现准确
URLLC 用户设备 (UE) 的服务质量 (QoS) 预测和
防止细胞过载是非常具有挑战性的任务。这是由于依赖性
流量和信道统计的 QoS 指标（延迟和可靠性），
用户的移动性以及 UE 之间相互依赖的性能。在本文中，一个
开发了新的 QoS 感知 UE 准入控制方法来主动
在将 URLLC UE 与小区关联之前估计它们的 QoS，以及
因此，仅接纳不会导致小区过载的UE子集。到
为此，制定了优化问题来找到高效的UE
准入控制策略，了解 UE 的 QoS 要求和小区级别
负载动态。为了解决这个问题，一种新的基于机器学习的方法是
提出建立在（深层）神经上下文强盗的基础上，这是一个合适的框架
用于处理非线性老虎机问题。事实上，UE准入
控制器被视为观察一组网络的强盗代理
测量（上下文）并根据
上下文相关的 QoS（奖励）预测。仿真结果表明
所提出的方案可以实现接近最佳的性能并产生可观的收益
在小区级服务可靠性和高效资源方面获得收益
利用率。
]]></description>
      <guid>http://arxiv.org/abs/2401.03059</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>CRUXEval：代码推理、理解和执行的基准。 （arXiv：2401.03065v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.03065</link>
      <description><![CDATA[我们提出 CRUXEval（代码推理、理解和执行）
评估），由 800 个 Python 函数（3-13 行）组成的基准测试。每个
函数带有一个输入输出对，导致两个自然任务：输入
预测和输出预测。首先，我们提出一个通用配方
生成我们的执行基准，可用于创建未来的变化
的基准。其次，我们在基准测试中评估了 20 个代码模型，
发现 HumanEval 上最近的许多高分模型并没有表现出相同的结果
我们的基准的改进。第三，我们展示了简单的 CoT 和微调
方案可以提高我们基准测试的性能，但距离解决问题还很远
它。最好的设置，带有思想链 (CoT) 的 GPT-4，获得了 75% 的 pass@1
输入和输出预测分别为 81% 和 81%。相比之下，Code Llama
34B 在输入和输出预测上实现了 50% 和 46% 的 pass@1，
突出了开源模型和闭源模型之间的差距。由于没有模型
接近 acing CRUXEval，我们提供了一致的 GPT-4 故障示例
简单的程序作为其代码推理能力和领域的镜头
改进。
]]></description>
      <guid>http://arxiv.org/abs/2401.03065</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>通过先验适应算法实现半无监督标定的收敛性。 （arXiv：2401.03051v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03051</link>
      <description><![CDATA[校准是机器学习的关键。半无人监督
通过先验适应校准（SUCPA）是一种校准算法，用于
（但不限于）由{系统定义的大规模语言模型
一阶差分方程。该系统导出的地图}具有
非双曲线的特性{具有非孤立的无界集合
固定点}。在这项工作中，我们证明了该方法的几个收敛特性
动力系统角度的算法。对于二进制
分类问题，可以证明算法总是收敛的，
{更准确地说，地图是全局渐近稳定的，并且轨道
收敛}到单行固定点。最后我们进行数值计算
现实世界应用的实验来支持所提出的结果。
实验代码可在线获取。
]]></description>
      <guid>http://arxiv.org/abs/2401.03051</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>Krylov 三次正则化牛顿：具有无量纲收敛率的子空间二阶方法。 （arXiv：2401.03058v1 [数学.OC]）</title>
      <link>http://arxiv.org/abs/2401.03058</link>
      <description><![CDATA[二阶优化方法，例如三次正则牛顿法，
以其快速收敛速度而闻名；尽管如此，他们还是成为
由于其大量的内存，在高维问题中不切实际
要求和计算成本。一种有希望的方法是执行
低维子空间内的二阶更新，从而产生
子空间二阶方法。然而，大多数现有的子空间
二阶方法随机选择子空间，从而导致
收敛速度较慢，具体取决于问题的维度 $d$。在这个
论文中，我们介绍了一种新颖的子空间三次正则化牛顿方法
实现了与维度无关的全局收敛速度
${O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$ 用于求解凸优化
问题。这里，$m$表示子空间维度，可以是
明显小于 $d$。我们没有采用随机子空间，
主要创新涉及执行三次正则牛顿更新
在与 Hessian 相关的 Krylov 子空间内以及
目标函数。这一结果标志着第一个实例
子空间二阶方法的与维数无关的收敛速度。
此外，当满足 Hessian 的特定光谱条件时，我们的
方法恢复全维三次正则化的收敛速度
牛顿法。数值实验表明我们的方法收敛速度比
现有的随机子空间方法，特别是对于高维问题。
]]></description>
      <guid>http://arxiv.org/abs/2401.03058</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>AST-T5：用于代码生成和理解的结构感知预训练。 （arXiv：2401.03003v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.03003</link>
      <description><![CDATA[大型语言模型 (LLM) 在以下方面取得了重大进展
与代码相关的任务，但许多法学硕士将代码视为简单的序列，忽略了
它的结构化性质。我们介绍 AST-T5，一种新颖的预训练范式
利用抽象语法树 (AST) 来增强代码生成，
翻译和理解。使用动态编程，我们的 AST-Aware
分段保留了代码结构，而我们的 AST 感知跨度损坏
目标使模型能够重建各种代码结构。与其他不同
模型，AST-T5 避免了复杂的程序分析或架构更改，因此
它与任何编码器-解码器 Transformer 无缝集成。评价显示
AST-T5 在各个方面始终优于类似大小的 LM
与代码相关的任务。结构意识使 AST-T5 在以下方面特别强大
代码到代码任务，在精确匹配分数上超过 CodeT5 2 分
Bugs2Fix 任务以及 Java-C# Transpilation 的精确匹配分数提高了 3 分
代码XGLUE。我们的代码和模型可在以下位置公开获取：
https://github.com/gonglinyuan/ast_t5。
]]></description>
      <guid>http://arxiv.org/abs/2401.03003</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中扩散模型的兴起。 （arXiv：2401.03006v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03006</link>
      <description><![CDATA[这项调查深入研究了扩散模型在时间序列中的应用
预测。扩散模型正在展示最先进的结果
生成人工智能的各个领域。该论文包括全面的背景
有关扩散模型的信息，详细说明其调节方法和
回顾它们在时间序列预测中的应用。分析涵盖 11 个具体方面
时间序列的实现，其背后的直觉和理论，
不同数据集上的有效性，以及相互之间的比较。钥匙
这项工作的贡献是对扩散模型的彻底探索
时间序列预测中的应用和按时间顺序排列的概述
这些模型。此外，本文还对以下问题进行了富有洞察力的讨论：
该领域当前的最新技术并概述了未来潜在的研究
方向。这对于人工智能和人工智能领域的研究人员来说是宝贵的资源。
时间序列分析，提供最新进展的清晰视图
扩散模型的未来潜力。
]]></description>
      <guid>http://arxiv.org/abs/2401.03006</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>AccidentGPT：用于交通事故分析的大型多模态基础模型。 （arXiv：2401.03040v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03040</link>
      <description><![CDATA[交通事故分析对于加强公共安全和
制定道路法规。传统方法虽然被广泛使用，但
通常受到手动分析过程、主观决策、单模态的限制
输出以及与敏感数据相关的隐私问题。这张纸
介绍了交通事故基础模型AccidentGPT的思想
分析，它结合了多模态输入数据来自动
重建具有动态细节的事故过程视频，并进一步
提供具有多模式输出的多任务分析。的设计
AccidentGPT 具有多模式提示和反馈功能
以任务为导向的适应性，一种混合​​培训模式，利用标记和
未标记的数据，以及用于数据隐私的边云分离配置。到
为了充分实现该模型的功能，我们提出了几项研究
机会。本文作为填补国内空白的垫脚石
交通事故分析的传统方法及其研究
社区对自动、客观和保护隐私的流量的关注
事故分析。
]]></description>
      <guid>http://arxiv.org/abs/2401.03040</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>桥接模式：将多模态情绪识别转化为单模态、纯语音情绪识别的知识蒸馏和掩蔽训练。 （arXiv：2401.03000v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.03000</link>
      <description><![CDATA[本文提出了一种创新方法来应对挑战
将多模态情感识别模型转化为更实用的模型
资源高效的单模对应，特别关注仅语音
情感识别。从语音信号中识别情绪是一个关键
人机交互、情感计算等应用的任务
心理健康评估。然而，现有的最先进的模型通常依赖于
多模式输入，整合来自多个来源的信息，例如
面部表情和手势，可能不容易获得或不可行
在现实场景中。为了解决这个问题，我们提出了一个新的框架
利用知识蒸馏和掩蔽训练技术。
]]></description>
      <guid>http://arxiv.org/abs/2401.03000</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>UnetTSF：性能更好的线性复杂性时间序列预测模型。 （arXiv：2401.03001v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.03001</link>
      <description><![CDATA[最近，基于 Transformer 的模型在该领域取得了重大进展
时间序列预测取得了良好的效果并成为基线
超越 D线性的模型。论文提出了U-Net时间序列预测模型
（UnetTSF）具有线性复杂度，采用U-Net架构。我们是
率先使用FPN技术从时间序列数据中提取特征，
替换将时间序列数据分解为趋势和季节性的方法
术语，同时设计适合时间序列数据的融合结构。后
在 8 个开源数据集上进行测试，与最佳线性模型 DLiner 进行比较。
在 32 个测试项目中，有 31 个取得了最好的结果。平均减少
MSE 平均下降 10.1%，而 MAE 平均下降 9.1%。与
基于复杂变压器的PatchTST，UnetTSF获得了9个mse的最佳结果
以及 32 个测试项目中 15 个 mae 的最佳结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.03001</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>关于深度学习物种分布建模的伪缺席的选择和有效性。 （arXiv：2401.02989v1 [q-bio.QM]）</title>
      <link>http://arxiv.org/abs/2401.02989</link>
      <description><![CDATA[物种分布建模是一种高度通用的理解工具
环境条件与物种之间错综复杂的关系
发生。然而，现有数据往往缺乏已证实的信息
物种不存在，仅限于机会性采样，仅存在
观察。为了克服这个限制，一个常见的方法是采用
伪缺席，即指定为负面的特定地理位置
样品。虽然单一物种的假缺席现象已经确定
分布模型及其在多物种神经环境中的应用
网络仍未得到充分探索。值得注意的是，严重的阶级不平衡
物种存在与假性不存在之间的问题往往没有得到解决。
此外，不同类型的伪缺席的存在（例如随机和随机）
目标群体背景点）增加了选择过程的复杂性。
确定假缺勤类型的最佳组合很困难，而且
取决于数据的特征，特别是考虑到
某些类型的假缺席可用于减轻地理偏见。在
在本文中，我们证明这些挑战可以通过以下方法有效解决：
在多物种神经网络的训练中整合伪缺席
通过修改损失函数。此次调整涉及分配
对损失函数的不同项赋予不同的权重，从而
解决类别不平衡和伪缺勤类型的选择。
此外，我们提出了一种使用空间设置这些损失权重的策略
阻止与仅存在数据的交叉验证。我们使用以下方法评估我们的方法
包含来自六个的独立存在/不存在数据的基准数据集
与竞争对手相比，不同地区的结果有所改善
接近。
]]></description>
      <guid>http://arxiv.org/abs/2401.02989</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>GLIDE-RL：通过强化学习演示进行基础语言教学。 （arXiv：2401.02991v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.02991</link>
      <description><![CDATA[复杂人类发展的最后前沿之一——人工智能
协作系统是人工智能体理解自然的能力
语言并相应地执行任务。但训练效率
基于自然语言的强化学习（RL）智能体一直是
由于语言的复杂性和模糊性，长期存在的挑战
奖励的稀疏性等因素。加固方面的几项进展
学习、课程学习、持续学习、语言模型有
独立地为各种驻地特工的有效培训做出了贡献
环境。利用这些发展，我们提出了一种新颖的算法，
通过强化学习演示进行扎根语言教学 (GLIDE-RL)
引入了教师-教师-学生的课程学习框架
训练一个能够遵循自然语言指令的强化学习代理
可以推广到以前未见过的语言指令。在这个多代理
框架中，教师和学生代理同时学习
学生当前的技能水平。我们进一步论证了必要性
不仅使用一个学生代理，还使用多个教师代理来训练学生代理。
复杂稀疏奖励环境的实验验证了有效性
我们提出的方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.02991</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>使用咳嗽音频的人工智能无偏差呼吸系统疾病诊断模型：COVID-19 案例研究。 （arXiv：2401.02996v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.02996</link>
      <description><![CDATA[使用人工技术对呼吸道疾病 (RD) 进行基于咳嗽的诊断
智能（AI）已引起广泛关注，但许多现有的
研究忽略了预测模型中的混杂变量。这些
变量可能会扭曲咳嗽记录（输入数据）之间的关系
和 RD 状态（输出变量），导致有偏见的关联和不切实际的
模型性能。为了解决这一差距，我们提出了 Bias Free Network
（RBFNet），一种端到端的解决方案，可以有效减轻
训练数据分布中的混杂因素。 RBFNet 确保准确且
无偏见的 RD 诊断特征，通过纳入
本研究中的 COVID19 数据集。该方法旨在提高可靠性
基于人工智能的 RD 诊断模型，应对混杂因素带来的挑战
变量。卷积神经网络 (CNN) 和长短网络的混合体
术语记忆（LSTM）网络被提出用于特征编码器模块
RBF 网络。分类中纳入了额外的偏差预测器
制定条件生成对抗网络（cGAN）的方案
有助于消除 RD 预测中混杂变量的影响。
通过比较分类性能证明了 RBFNet 的优点
训练后使用最先进的 (SoTA) 深度学习 (DL) 模型 (CNN LSTM)
不同的不平衡的 COVID-19 数据集，通过使用大规模创建
专有的咳嗽数据集。 RBF-Net 证明了其对极端情况的鲁棒性
通过实现测试集准确率 84.1%、84.6% 和
以下混杂变量性别、年龄和吸烟状况为 80.5%，
分别。 RBF-Net 的性能优于 CNN-LSTM 模型测试集精度
分别为 5.5%、7.7% 和 8.2%
]]></description>
      <guid>http://arxiv.org/abs/2401.02996</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>用于自由形式超表面设计中参数优化的代理辅助扩展生成对抗网络。 （arXiv：2401.02961v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.02961</link>
      <description><![CDATA[超表面在第五代（5G）微波领域有着广泛的应用
沟通。在超表面家族中，自由形式的超表面表现出色
与规则形状的对应物相比，可以实现复杂的光谱响应。
然而，自由形式超表面的传统数值方法是
耗时且需要专业知识。或者，最近的研究
证明深度学习具有加速和完善的巨大潜力
超表面设计。在这里，我们提出 XGAN，一种扩展的生成对抗
网络（GAN），具有高质量自由形式超表面设计的替代品。
所提出的替代方案为 XGAN 提供了物理约束，以便 XGAN 可以
根据输入光谱响应准确地整体生成超表面。
在涉及 20000 个自由形式超表面设计的比较实验中，XGAN
平均准确率达到0.9734，比传统方法快500倍
方法。该方法有利于超表面库的构建
特定的光谱响应，可以扩展到各种逆设计
问题，包括光学超材料、纳米光子器件和药物
发现。
]]></description>
      <guid>http://arxiv.org/abs/2401.02961</guid>
      <pubDate>Tue, 09 Jan 2024 06:18:20 GMT</pubDate>
    </item>
    </channel>
</rss>