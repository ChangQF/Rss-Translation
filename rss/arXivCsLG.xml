<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>卫星观测引导扩散模型，用于任意分辨率的精确气象状态</title>
      <link>https://arxiv.org/abs/2502.07814</link>
      <description><![CDATA[arXiv:2502.07814v1 公告类型：新
摘要：准确获取任意位置的地面气象状况对于天气预报和气候模拟具有重要意义。由于卫星观测得出的气象状态通常以低分辨率网格场的形式提供，直接应用空间插值来获取特定位置的气象状态与实际观测相比往往存在很大差异。现有的用于获取更高分辨率气象状态信息的降尺度方法通常忽略了与卫星观测的相关性。为了弥补这一差距，我们提出了卫星观测引导扩散模型（SGD），这是一种以卫星观测（GridSat）为条件在 ERA5 再分析数据上进行预训练的条件扩散模型，用于通过零样本引导采样策略和基于块的方法对降尺度气象状态进行采样。在训练过程中，我们建议通过注意力机制将来自 GridSat 卫星观测的信息融合到 ERA5 地图中，使 SGD 能够生成与实际情况更准确的大气状态。在采样过程中，我们使用可优化的卷积核来模拟上尺度过程，从而使用低分辨率 ERA5 地图以及气象站的观测结果作为指导来生成高分辨率 ERA5 地图。此外，我们设计的基于块的方法促进了 SGD 以任意分辨率生成气象状态。实验表明，SGD 实现了精确的气象状态降尺度至 6.25 公里。]]></description>
      <guid>https://arxiv.org/abs/2502.07814</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>隐式语言模型是 RNN：平衡并行化和表达力</title>
      <link>https://arxiv.org/abs/2502.07827</link>
      <description><![CDATA[arXiv:2502.07827v1 公告类型：新
摘要：状态空间模型 (SSM) 和转换器主导着语言建模领域。然而，与经典的循环神经网络 (RNN) 相比，它们的计算复杂度较低，限制了它们的表达能力。相比之下，RNN 在训练期间缺乏并行化，这引发了关于并行化和表达能力之间权衡的基本问题。我们提出了隐式 SSM，它迭代转换直到收敛到一个固定点。从理论上讲，我们表明隐式 SSM 实现了 RNN 的非线性状态转换。从经验上讲，我们发现仅近似的固定点收敛就足够了，从而可以设计一个可扩展的训练课程，该课程在很大程度上保留了并行化，只需要对一小部分 token 进行完全收敛。我们的方法展示了对常规语言的卓越状态跟踪能力，超越了转换器和 SSM。我们进一步将隐式 SSM 扩展到自然语言推理任务，并对大规模语言模型进行预训练，在 2070 亿个标记上最多有 13 亿个参数 - 据我们所知，这是迄今为止训练的最大隐式模型。值得注意的是，我们的隐式模型在标准基准上的表现优于显式模型。]]></description>
      <guid>https://arxiv.org/abs/2502.07827</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SHARP：通过使用恢复参数共享相邻层来加速语言模型推理</title>
      <link>https://arxiv.org/abs/2502.07832</link>
      <description><![CDATA[arXiv:2502.07832v1 公告类型：新 
摘要：虽然大型语言模型 (LLM) 具有先进的自然语言处理任务，但它们不断增长的计算和内存需求使得在资源受限的手机等设备上部署变得越来越具有挑战性。在本文中，我们提出了 SHARP（使用恢复参数共享相邻层），这是一种通过在相邻层之间共享参数来加速 LLM 推理的新方法，从而减少内存负载开销，同时引入低秩恢复参数以保持性能。受到连续层具有相似输出的观察结果的启发，SHARP 采用了两阶段恢复过程：单层预热 (SLW) 和监督微调 (SFT)。SLW 阶段使用 L_2 损失对齐共享层的输出，为接下来的 SFT 阶段提供良好的初始化以进一步恢复模型性能。大量实验表明，SHARP 可以使用不超过 50k 的微调数据恢复模型在各种分布内任务中的困惑度，同时将存储的 MLP 参数数量减少 38% 至 65%。我们还对 SHARP 进行了几项消融研究，结果表明，将层替换为模型的后半部分可以获得更好的性能保持率，并且当参数数量匹配时，不同的恢复参数化表现相似。此外，与移动设备上的原始 Llama2-7b 模型相比，SHARP 节省了 42.8% 的模型存储，并将总推理时间减少了 42.2%。我们的结果表明，SHARP 是一种有效的解决方案，可以在无需预训练规模资源的情况下降低部署 LLM 时的推理成本。]]></description>
      <guid>https://arxiv.org/abs/2502.07832</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用升级的连接矩阵进行情绪脑电图分类</title>
      <link>https://arxiv.org/abs/2502.07843</link>
      <description><![CDATA[arXiv:2502.07843v1 公告类型：新
摘要：在最近的情绪脑电图分类研究中，连接矩阵已成功用作卷积神经网络 (CNN) 的输入，可以有效地考虑脑电图中的区域间相互作用模式。然而，我们发现这种方法有一个局限性，即在 CNN 的卷积运算过程中，连接矩阵中的重要模式可能会丢失。为了解决这个问题，我们提出并验证了一种想法，即对连接矩阵进行升级以加强局部模式。实验结果表明，这个简单的想法可以显著提高分类性能。]]></description>
      <guid>https://arxiv.org/abs/2502.07843</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解无分类器指导：高维理论和非线性概括</title>
      <link>https://arxiv.org/abs/2502.07849</link>
      <description><![CDATA[arXiv:2502.07849v1 公告类型：新
摘要：最近的研究引起了人们对无分类器指导 (CFG) 有效性的担忧，表明在低维设置中，它可能导致目标分布超调并降低样本多样性。在这项工作中，我们证明在无限且足够高维的环境中，CFG 有效地再现了目标分布，揭示了维数增加的结果。此外，我们探索了有限维效应，精确地表征了超调和方差减少。基于我们的分析，我们引入了 CFG 的非线性泛化。通过对高斯混合的数值模拟以及对类条件和文本到图像扩散模型的实验，我们验证了我们的分析并表明我们的非线性 CFG 提供了更好的灵活性和生成质量而无需额外的计算成本。]]></description>
      <guid>https://arxiv.org/abs/2502.07849</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用注意力机制推进热需求预测：机遇与挑战</title>
      <link>https://arxiv.org/abs/2502.07854</link>
      <description><![CDATA[arXiv:2502.07854v1 公告类型：新
摘要：全球领导人和政策制定者一致明确承诺支持净零协议的脱碳工作。区域供热系统 (DHS) 虽然由于继续依赖化石燃料生产热量而导致碳排放，但正在采取更可持续的做法，尽管存在一些脆弱性，因为这可能会限制其适应动态需求和生产情景的能力。随着人口需求的增长和可再生能源成为供热行业脱碳的核心战略，对准确需求预测的需求也日益增加。数字化的进步为基于机器学习 (ML) 的解决方案成为建模复杂时间序列模式的行业标准铺平了道路。在本文中，我们专注于构建一个深度学习 (DL) 模型，该模型使用影响热需求的独立和因变量的解构成分作为特征来执行热能需求的多步预测。该模型在时频空间中表示输入特征，并使用注意机制来生成准确的预测。在真实数据集上对所提出的方法进行了评估，并根据基于 LSTM 和 CNN 的预测模型评估了预测性能。在不同的供应区域，基于注意力的模型在数量和质量上都优于基线，平均绝对误差 (MAE) 为 0.105，标准差为 0.06kW h，平均绝对百分比误差 (MAPE) 为 5.4%，标准差为 2.8%，而第二好的模型 MAE 为 0.10，标准差为 0.06kW h，MAPE 为 5.6%，标准差为 3%。]]></description>
      <guid>https://arxiv.org/abs/2502.07854</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAAT：具有时间序列关联差异的 Mamba 自适应异常变换器</title>
      <link>https://arxiv.org/abs/2502.07858</link>
      <description><![CDATA[arXiv:2502.07858v1 公告类型：新
摘要：时间序列中的异常检测对于工业监控和环境感知至关重要，但区分异常和复杂模式仍然具有挑战性。现有的方法如异常变换器和 DCdetector 已经取得了进展，但它们面临着诸如对短期上下文的敏感性以及在嘈杂、非平稳环境中效率低下等限制。
为了克服这些问题，我们引入了 MAAT，这是一种改进的架构，可增强关联差异建模和重建质量。MAAT 具有稀疏注意力，通过关注相关时间步骤来有效捕获长距离依赖关系，从而减少计算冗余。此外，Mamba 选择性状态空间模型被纳入重建模块，利用跳过连接和门控注意力来提高异常定位和检测性能。
大量实验表明，MAAT 明显优于以前的方法，在各种时间序列应用中实现了更好的异常可区分性和泛化性，为现实场景中的无监督时间序列异常检测树立了新的标准。]]></description>
      <guid>https://arxiv.org/abs/2502.07858</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BalanceKV：通过差异理论实现 KV 缓存压缩</title>
      <link>https://arxiv.org/abs/2502.07861</link>
      <description><![CDATA[arXiv:2502.07861v1 公告类型：新
摘要：大型语言模型 (LLM) 取得了令人瞩目的成功，但它们的高内存要求给长上下文标记生成带来了挑战。长上下文 LLM 的内存复杂性主要是由于需要在其 KV 缓存中存储键值 (KV) 嵌入。我们提出了 BalanceKV，这是一种基于几何采样过程的 KV 缓存压缩方法，源自 Banaszczyk 的向量平衡理论，它引入了由键和值标记的几何形状决定的依赖关系，并提高了精度。与现有方法相比，BalanceKV 提供了理论证明和经验验证的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2502.07861</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ADMN：用于动态输入噪声和计算资源的逐层自适应多模态网络</title>
      <link>https://arxiv.org/abs/2502.07862</link>
      <description><![CDATA[arXiv:2502.07862v1 公告类型：新
摘要：由于多种传感模式具有稳健性，多模态深度学习系统被部署在动态场景中。然而，它们仍面临着计算资源可用性变化（由于多租户、设备异质性等）和输入质量波动（来自传感器馈送损坏、环境噪声等）的困扰。当前的多模态系统采用静态资源配置，无法轻松适应计算资源随时间变化的情况。此外，它们依赖于使用固定特征提取器处理传感器数据，无法处理模态质量的变化。因此，无信息的模态（例如高噪声模态）会不必要地消耗分配给其他模态的资源。我们提出了 ADMN，这是一种分层自适应深度多模态网络，能够应对这两个挑战 - 它调整所有模态中的活动层总数以满足计算资源限制，并根据模态质量不断重新分配输入模态中的层。我们的评估表明，ADMN 可以匹配最先进网络的精度，同时将浮点运算减少高达 75%。]]></description>
      <guid>https://arxiv.org/abs/2502.07862</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransMLA：你所需要的只是多头潜在注意力</title>
      <link>https://arxiv.org/abs/2502.07864</link>
      <description><![CDATA[arXiv:2502.07864v1 公告类型：新
摘要：现代大型语言模型 (LLM) 经常在当前硬件上遇到通信瓶颈，而不仅仅是计算限制。多头潜在注意力 (MLA) 通过在键值 (KV) 层中使用低秩矩阵来解决这一挑战，从而允许缓存压缩的潜在 KV 状态。与传统的多头注意力相比，这种方法显着减少了 KV 缓存大小，从而加快了推理速度。此外，MLA 采用上投影矩阵来提高表现力，以额外的计算换取减少的通信开销。尽管 MLA 在 Deepseek V2/V3/R1 中已经证明了其效率和有效性，但许多主要模型提供商仍然依赖组查询注意力 (GQA)，并且尚未宣布任何采用 MLA 的计划。在本文中，我们表明 GQA 始终可以用 MLA 表示，同时保持相同的 KV 缓存开销，但反之则不成立。为了鼓励更广泛地使用 MLA，我们引入了 **TransMLA**，这是一种后训练方法，可将广泛使用的基于 GQA 的预训练模型（例如 LLaMA、Qwen、Mixtral）转换为基于 MLA 的模型。转换后，模型可以进行额外的训练以提高表现力，而无需增加 KV 缓存大小。此外，我们计划开发特定于 MLA 的推理加速技术，以在转换后的模型中保持低延迟，从而实现更高效的 Deepseek R1 提炼。]]></description>
      <guid>https://arxiv.org/abs/2502.07864</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用离线数据进行主动优势对齐的在线强化学习</title>
      <link>https://arxiv.org/abs/2502.07937</link>
      <description><![CDATA[arXiv:2502.07937v1 公告类型：新
摘要：在线强化学习 (RL) 通过与环境的直接交互来增强策略，但面临与样本效率相关的挑战。相比之下，离线 RL 利用大量预先收集的数据来学习策略，但由于数据覆盖范围有限，通常会产生次优结果。最近的努力试图整合离线和在线 RL，以利用两种方法的优势。然而，由于灾难性遗忘、缺乏鲁棒性和样本效率等问题，有效地结合在线和离线 RL 仍然具有挑战性。为了应对这些挑战，我们引入了 A3 RL，这是一种新颖的方法，它从组合的在线和离线源中主动选择数据以优化策略改进。我们提供理论保证来验证我们的主动采样策略的有效性，并进行彻底的实证实验，表明我们的方法优于现有的利用离线数据的最先进的在线 RL 技术。我们的代码将公开提供：https://github.com/xuefeng-cs/A3RL。]]></description>
      <guid>https://arxiv.org/abs/2502.07937</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VSC-RL：利用变分子目标条件强化学习推进自主视觉语言代理</title>
      <link>https://arxiv.org/abs/2502.07949</link>
      <description><![CDATA[arXiv:2502.07949v1 公告类型：新
摘要：最先进的 (SOTA) 强化学习 (RL) 方法使视觉语言代理能够在没有人工监督的情况下从与环境的交互中学习。然而，他们在处理现实世界中复杂的顺序决策任务时，尤其是在稀疏的奖励信号和长期依赖性的情况下，学习效率低下。为了有效地解决这个问题，我们引入了变分子目标条件 RL (VSC-RL)，它将视觉语言顺序决策任务重新表述为变分目标条件 RL 问题，使我们能够利用先进的优化方法来提高学习效率。具体来说，VSC-RL 优化了子目标证据下限 (SGC-ELBO)，它包括 (a) 通过 RL 最大化子目标条件回报和 (b) 使用参考策略最小化子目标条件差异。我们从理论上证明了 SGC-ELBO 与原始优化目标等同，确保提高学习效率而不牺牲性能保证。此外，对于现实世界的复杂决策任务，VSC-RL 利用视觉语言模型将目标自主分解为可行的子目标，实现高效学习。在各种基准测试中，包括具有挑战性的现实世界移动设备控制任务，VSC-RL 的表现明显优于 SOTA 视觉语言代理，实现了卓越的性能和学习效率的显著提高。]]></description>
      <guid>https://arxiv.org/abs/2502.07949</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ESPFormer：具有预期切片运输计划的双随机注意力机制</title>
      <link>https://arxiv.org/abs/2502.07962</link>
      <description><![CDATA[arXiv:2502.07962v1 公告类型：新
摘要：虽然自注意力机制对 Transformers 的成功起到了重要作用，但它可能导致训练期间过度集中于少数 token，从而导致信息流不理想。在注意力矩阵中强制实施双随机约束已被证明可以改善注意力分布的结构和平衡。然而，现有的方法依赖于迭代 Sinkhorn 归一化，这在计算上是昂贵的。在本文中，我们介绍了一种基于切片最优传输的新型、完全可并行的双随机注意力机制，利用预期切片传输计划 (ESP)。与之前的方法不同，我们的方法在没有迭代 Sinkhorn 归一化的情况下强制实施双随机性，从而显着提高了效率。为了确保可微性，我们采用了基于温度的软排序技术，从而能够无缝集成到深度学习模型中。在多个基准数据集上进行的实验，包括图像分类、点云分类、情感分析和神经机器翻译，表明我们增强的注意力正则化能够持续提高不同应用程序的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.07962</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于比较肿瘤生长的经典和神经 ODE 模型的新工具</title>
      <link>https://arxiv.org/abs/2502.07964</link>
      <description><![CDATA[arXiv:2502.07964v1 公告类型：新
摘要：介绍了一种用于建模肿瘤生长的新型计算工具 TumorGrowth.jl。该工具允许将标准教科书模型（例如 General Bertalanffy 和 Gompertz）与一些较新的模型进行比较，包括首次出现的神经 ODE 模型。作为一项应用，我们重新审视了一项关于接受两种不同治疗方案的患者的非小细胞肺癌和膀胱癌病变的人类元研究，以确定先前报告的性能差异是否具有统计意义，以及更新、更复杂的模型是否表现更好。在一组至少有四个时间体积测量可用于校准且平均值约为 6.3 的示例中，我们的主要结论是 General Bertalanffy 模型平均具有更优的性能。然而，在有更多测量可用的情况下，我们认为能够捕捉反弹和复发行为的更复杂的模型可能是更好的选择。]]></description>
      <guid>https://arxiv.org/abs/2502.07964</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图上分布外泛化的生成风险最小化</title>
      <link>https://arxiv.org/abs/2502.07968</link>
      <description><![CDATA[arXiv:2502.07968v1 公告类型：新
摘要：图上的分布外 (OOD) 泛化旨在处理测试图分布与训练图分布不同的情况。与图像等独立同分布数据相比，由于图上的非独立同分布属性和复杂的结构信息，图结构数据的 OOD 泛化问题仍然具有挑战性。最近，一些关于图 OOD 泛化的研究探索了提取在不同分布之间共享关键分类信息的不变子图。然而，这种策略对于完全捕获不变信息可能不是最优的，因为离散结构的提取可能会导致不变信息的丢失或虚假信息的参与。在本文中，我们提出了一个创新框架，称为生成风险最小化 (GRM)，旨在为每个要分类的输入图生成一个不变子图，而不是提取。为了解决在缺乏最优不变子图（即基本事实）的情况下进行优化的难题，我们通过引入潜在因果变量推导出所提出的 GRM 目标的可处理形式，并通过理论分析验证了其有效性。我们进一步在各种现实世界图数据集上进行了广泛的实验，以进行节点级和图级 OOD 泛化，结果证明了我们的框架 GRM 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2502.07968</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>