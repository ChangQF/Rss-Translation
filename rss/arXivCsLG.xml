<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>重新审视图同质性度量</title>
      <link>https://arxiv.org/abs/2412.09663</link>
      <description><![CDATA[arXiv:2412.09663v1 公告类型：新
摘要：同质性是一种图形属性，描述边连接相似节点的趋势。有几种用于评估同质性的措施，但众所周知，它们都具有某些缺点：特别是，它们不能可靠地用于比较具有不同数量类和类大小平衡的数据集。为了证明这一点，以前关于图同质性的工作提出了良好同质性度量的几个理想属性，同时指出没有现有的同质性度量具有所有这些属性。我们的论文通过引入一种新的同质性度量（无偏同质性）来解决这个问题，它具有所有理想的属性，因此可以可靠地用于具有不同标签分布的数据集。所提出的度量适用于无向（可能加权）图。我们从理论上和通过实证例子表明，现有的同质性度量具有严重的缺点，而无偏同质性对于所考虑的场景具有理想的行为。最后，当涉及到有向图时，我们证明一些理想的属性相互矛盾，因此不可能存在满足所有属性的度量。]]></description>
      <guid>https://arxiv.org/abs/2412.09663</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>主动学习中可复制性的成本</title>
      <link>https://arxiv.org/abs/2412.09686</link>
      <description><![CDATA[arXiv:2412.09686v1 公告类型：新
摘要：主动学习旨在通过选择性查询最初未标记的数据点的标签来减少机器学习算法所需的标记数据数量。确保结果的可重复性（即算法在不同运行中始终产生相同的结果）对于机器学习模型的可靠性至关重要，但通常会增加样本复杂性。本报告使用 CAL 算法（一种经典的基于分歧的主动学习方法）研究了主动学习中可重复性的成本。通过整合可复制的统计查询子程序和随机阈值技术，我们提出了两种版本的可复制 CAL 算法。我们的理论分析表明，虽然可复制性确实增加了标签复杂性，但即使有可复制性约束，CAL 算法仍然可以显著节省标签复杂性。这些发现为平衡机器学习模型的效率和稳健性提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.09686</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DQA：深度神经网络激活的深度量化有效方法</title>
      <link>https://arxiv.org/abs/2412.09687</link>
      <description><![CDATA[arXiv:2412.09687v1 公告类型：新
摘要：深度神经网络 (DNN) 激活量化是一种常用的技术，可减少 DNN 推理期间的计算和内存需求，这在资源受限的设备上尤其有益。为了实现高精度，现有的量化激活方法依赖于复杂的数学计算或对最佳超参数进行大量搜索。然而，这些昂贵的操作在计算能力、内存容量和能量预算有限的设备上是不切实际的。此外，许多现有方法并不关注 6 位以下（或深度）量化。
为了填补这些空白，我们在本文中提出了 DQA（DNN 激活的深度量化），这是一种专注于 6 位以下激活量化的新方法，并利用简单的基于移位的操作和霍夫曼编码来提高效率并实现高精度。我们对具有 3、4 和 5 位量化级别的 DQA 和三个不同的 DNN 模型进行了评估，以用于两个不同的数据集上的两个不同任务（图像分类和图像分割）。与直接量化方法和最先进的 NoisyQuant 相比，DQA 在 6 位以下量化方面表现出明显更高的准确率（高达 29.28%）。]]></description>
      <guid>https://arxiv.org/abs/2412.09687</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CUAL：持续不确定性意识主动学习者</title>
      <link>https://arxiv.org/abs/2412.09701</link>
      <description><![CDATA[arXiv:2412.09701v1 公告类型：新
摘要：在许多实际用例中部署的人工智能应该能够适应部署后遇到的新事物。在这里，我们考虑一个具有挑战性、尚未充分探索且现实的持续适应问题：部署的人工智能代理不断获得未标记的数据，这些数据可能不仅包含已知类别的未见样本，还包含来自新（未知）类别的样本。在这样一个具有挑战性的环境中，它只有很小的标记预算来查询最具信息量的样本以帮助它持续学习。我们通过我们的模型“CUAL”（持续不确定性感知主动学习者）为这个复杂问题提供了全面的解决方案。CUAL 利用不确定性估计算法优先考虑对模糊（不确定）预测的新类别样本进行主动标记，同时伪标记每个类别最确定的预测。跨多个数据集、消融、设置和主干（例如 ViT 基础模型）的评估证明了我们方法的有效性。我们将在接受后发布我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2412.09701</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中高斯分数近似的不合理有效性及其应用</title>
      <link>https://arxiv.org/abs/2412.09726</link>
      <description><![CDATA[arXiv:2412.09726v1 公告类型：新
摘要：通过学习平滑数据分布的梯度，扩散模型可以迭代地从复杂分布中生成样本。学习到的分数函数使其具有泛化能力，但学习到的分数与底层数据流形的分数之间的关系仍不清楚。在这里，我们旨在通过将学习到的神经分数与两种可分析分布的分数进行比较来阐明这种关系：高斯和高斯混合。高斯模型的简单性使其在理论上具有吸引力，我们表明它承认闭式解并预测样本生成动力学的许多定性方面。我们声称，学习到的神经分数由中到高噪声尺度的线性（高斯）近似主导，并提供理论和经验论据来支持这一说法。此外，高斯近似在经验上适用于比简单理论所认为的更大范围的噪声尺度，并且优先在训练早期学习。在较小的噪声尺度下，我们观察到学习到的分数更适合用训练数据的粗粒度（高斯混合）近似来描述，而不是用训练分布的分数来描述，这一发现与泛化一致。我们的研究结果使我们能够通过高斯近似准确预测训练模型采样轨迹的初始阶段。我们表明，这允许跳过前 15-30% 的采样步骤，同时保持高样本质量（在 CIFAR-10 无条件生成中，FID 分数接近最先进的 1.93）。这构成了一种新型混合采样方法的基础，称为分析传送，它可以无缝集成并加速现有采样器，包括 DPM-Solver-v3 和 UniPC。我们的研究结果提出了改进扩散模型设计和训练的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.09726</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机属性聚类的新方法</title>
      <link>https://arxiv.org/abs/2412.09748</link>
      <description><![CDATA[arXiv:2412.09748v1 公告类型：新
摘要：本文提出了一种新的相似性分析方法，从而提出了一种对不同类型的随机属性（包括数值属性和名义属性）进行聚类的新算法。但是，为了对名义属性进行聚类，必须正确编码它们的值。在编码过程中，名义属性以数字形式获得新的表示。只有数字属性才能进行因子分析，从而可以根据它们与因子的相似性对它们进行聚类。针对几个样本数据集测试了所提出的方法。结果发现，所提出的方法是通用的。一方面，该方法允许对数值属性进行聚类。另一方面，它提供了对名义属性进行聚类的能力。它还允许同时对数值属性和数值编码的名义属性进行聚类。]]></description>
      <guid>https://arxiv.org/abs/2412.09748</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算深度前馈神经网络高阶导数的拟线性算法</title>
      <link>https://arxiv.org/abs/2412.09752</link>
      <description><![CDATA[arXiv:2412.09752v1 公告类型：新
摘要：由于计算高阶导数时自动微分的运行时间呈指数增长，因此使用神经网络求解微分方程实际上很困难。我们提出了 $n$-TangentProp，这是 TangentProp 形式主义 \cite{simard1991tangent} 到任意多个导数的自然扩展。对于具有平滑、无参数激活函数的密集连接前馈神经网络 $f$，$n$-TangentProp 以准线性（而不是指数时间）计算精确导数 $d^n/dx^n f(x)$。我们在一系列深度、宽度和导数上通过经验验证了我们的算法。我们证明，我们的方法在物理信息神经网络的背景下特别有用，其中 \ntp 允许比以前的方法更快的训练时间，并且在模型大小和损失函数复杂度方面具有良好的扩展性（以所需导数的数量来衡量）。本文的代码可以在 https://github.com/kyrochi/n\_tangentprop 找到。]]></description>
      <guid>https://arxiv.org/abs/2412.09752</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从数据中选择联合图和采样集</title>
      <link>https://arxiv.org/abs/2412.09753</link>
      <description><![CDATA[arXiv:2412.09753v1 公告类型：新
摘要：我们探索了图结构未预定义且必须从数据中推断的场景中的图信号采样问题。在这种情况下，现有方法依赖于两步过程，首先学习图，然后进行采样。更一般地说，图学习和图信号采样在文献中被研究为两个独立的问题。这项工作为联合优化图结构和采样集提供了基础步骤。我们的主要贡献，顶点重要性采样 (VIS)，是表明可以从图学习中获得的顶点重要性（节点权重）有效地确定采样集。我们进一步提出了具有排斥力的顶点重要性采样 (VISR)，这是一种贪婪算法，其中选择空间上分离的“重要”节点以确保更好的重建。模拟数据的经验结果表明，使用 VIS 和 VISR 进行采样比传统的两步图学习然后进行图采样的方法具有竞争力的重建性能和更低的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2412.09753</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向多变量可穿戴生理信号传感的基础模型</title>
      <link>https://arxiv.org/abs/2412.09758</link>
      <description><![CDATA[arXiv:2412.09758v1 公告类型：新
摘要：时间序列基础模型能够对任何类型的时间序列数据进行推理（主要是预测），这要归功于由波形特征组成的信息表示。另一方面，可穿戴传感数据在感兴趣的模式和频带方面都包含更多可变性，并且通常更强调推断医疗相关结果的能力。为可穿戴传感生理信号设计基础模型的主要挑战是学习可泛化的表示，以支持跨异构传感配置和应用的有效适应。在这项工作中，我们提出了 NormWear，这是朝着这种基础模型迈出的一步，旨在提取通用且信息丰富的可穿戴传感表示。NormWear 已在来自各种公共资源的大量生理信号（包括 PPG、ECG、EEG、GSR 和 IMU）上进行了预训练。为了进行整体评估，我们对 11 个公共可穿戴传感数据集进行了下游评估，涵盖心理健康、身体状态推断、生物标志物估计和疾病风险评估领域的 18 个应用。我们证明，NormWear 在一般时间序列基础建模中比竞争基线实现了更好的性能改进。此外，利用一种新颖的基于表示对齐匹配的方法，我们将生理信号嵌入与文本嵌入对齐。这种对齐使我们提出的基础模型能够执行零样本推理，从而使其能够推广到以前从未见过的基于可穿戴信号的健康应用。最后，我们对模型在每个中间层提取的波形特征执行非线性动态分析。该分析量化了模型的内部过程，提供了对其行为的清晰洞察，并在最终用户中增强了对其推理的信任。]]></description>
      <guid>https://arxiv.org/abs/2412.09758</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>是模型还是度量——关于深度学习模型的鲁棒性度量</title>
      <link>https://arxiv.org/abs/2412.09795</link>
      <description><![CDATA[arXiv:2412.09795v1 公告类型：新
摘要：确定深度学习模型的稳健性是自动决策系统中既定且持续的挑战。随着支持高级深度学习 (DL) 的技术的出现和成功，这些模型被广泛应用于医疗保健、教育、边境管制等高风险领域。因此，了解这些模型的局限性并预测其故障区域至关重要，以便为成功和安全部署这些模型创建必要的护栏。在这项工作中，我们重新审视了稳健性，特别是在深度伪造检测的背景下研究了稳健精度 (RA) 的充分性。我们提出稳健比 (RR) 作为补充指标，可以量化输入扰动下归一化或概率结果的变化。我们对 RA 和 RR 进行了比较，并证明尽管模型之间的 RA 相似，但模型在不同的容忍度（扰动）水平下显示出不同的 RR。]]></description>
      <guid>https://arxiv.org/abs/2412.09795</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无限维下一代储层计算</title>
      <link>https://arxiv.org/abs/2412.09800</link>
      <description><![CDATA[arXiv:2412.09800v1 公告类型：新
摘要：下一代水库计算 (NG-RC) 因其在复杂系统的时空预测中的出色性能和易于实施而备受关注。本文表明，NG-RC 可以编码为核岭回归，即使所选多项式特征的空间非常大，也能使训练变得高效可行。此外，可以扩展到无限数量的协变量，这使得该方法与被视为解释因素的过去滞后以及传统 NG-RC 中的重要超参数多项式协变量的数量无关。我们表明，这种方法具有坚实的理论支持和良好的行为，基于文献中先前建立的核通用性。各种数值说明表明，NG-RC 的这些概括在几个预测应用中优于传统方法。]]></description>
      <guid>https://arxiv.org/abs/2412.09800</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>deepNoC：一种深度学习系统，用于分配短串联重复 DNA 谱贡献者的数量</title>
      <link>https://arxiv.org/abs/2412.09803</link>
      <description><![CDATA[arXiv:2412.09803v1 公告类型：新
摘要：法医生物学中的一项常见任务是解释和评估短串联重复 DNA 图谱。这些解释的第一步是将一定数量的贡献者分配给图谱，这项任务通常由科学家利用他们对 DNA 图谱行为的了解手动完成。使用构建的 DNA 图谱的研究表明，随着 DNA 图谱变得越来越复杂，DNA 捐赠者的数量增加，科学家分配目标数量的能力也随之增加。已经开发了许多机器学习算法，旨在将贡献者的数量分配给 DNA 图谱，但是由于在实验室中生成 DNA 图谱的实际限制，这些算法基于可用信息的摘要。在这项工作中，我们开发了一个分析流程，可以模拟 STR 图谱的电泳信号，从而可以生成几乎无限的预标记训练材料。我们表明，通过模拟 100,000 个配置文件并使用深度神经网络架构（在名为 deepNoC 的算法中）训练多个贡献者估计工具，可以实现高水平的性能（1 到 10 个贡献者的准确率为 89%）。然后，经过训练的网络可以仅使用几百个配置文件进行微调训练，以便在特定实验室内实现相同的准确率。我们还在 deepNoC 中构建了次级输出，为算法用户提供一定程度的可解释性，并展示了如何以直观的方式显示它们。]]></description>
      <guid>https://arxiv.org/abs/2412.09803</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过消除平滑性泛化困境实现通用的 Inceptive GNN</title>
      <link>https://arxiv.org/abs/2412.09805</link>
      <description><![CDATA[arXiv:2412.09805v1 公告类型：新
摘要：图神经网络 (GNN) 在交易和社交网络等各个领域都取得了显著的成功。然而，它们的应用往往受到不同顺序相邻节点之间同质性水平变化的阻碍，需要为同质和异质图设计单独的模型。在本文中，我们的目标是开发一个能够处理各种顺序和同质性水平的邻域的统一框架。通过理论探索，我们发现了多跳学习中一个以前被忽视的架构方面：级联依赖性，这导致了平滑性泛化困境。这种困境严重影响了学习过程，尤其是在高阶邻域和异质图的背景下。为了解决这个问题，我们提出了一个初始图神经网络 (IGNN)，这是一个通用的消息传递框架，用初始架构取代了级联依赖性。 IGNN 为每一跳提供独立的表示，允许个性化泛化能力，并捕获邻域关系以选择适当的接受域。大量实验表明，我们的 IGNN 优于 23 种基线方法，在同质和异质图上均表现出色，同时还能有效扩展到大型图。]]></description>
      <guid>https://arxiv.org/abs/2412.09805</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Grokking 的复杂性动态</title>
      <link>https://arxiv.org/abs/2412.09810</link>
      <description><![CDATA[arXiv:2412.09810v1 公告类型：新
摘要：我们通过压缩的视角研究泛化现象。特别是，我们研究神经网络的复杂性动态来解释 grokking，即网络在过度拟合训练数据后很长时间突然从记忆转变为泛化解决方案。为此，我们基于 Kolmogorov 复杂性理论引入了一种新的神经网络内在复杂性度量。在整个网络训练过程中跟踪该指标，我们发现训练动态中存在一致的模式，即复杂性的上升和下降。我们证明这对应于记忆然后是泛化。基于速率失真理论和最小描述长度原理的见解，我们提出了一种有损压缩神经网络的原则性方法，并将我们的复杂性度量与明确的泛化界限联系起来。基于对神经网络中信息容量的仔细分析，我们提出了一种新的正则化方法，通过惩罚网络的谱熵来鼓励网络走向低秩表示，并发现我们的正则化器在数据集的总体压缩方面优于基线。]]></description>
      <guid>https://arxiv.org/abs/2412.09810</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用联邦学习在动态贝叶斯网络中发现时间因果关系</title>
      <link>https://arxiv.org/abs/2412.09814</link>
      <description><![CDATA[arXiv:2412.09814v1 公告类型：新
摘要：传统上，学习动态贝叶斯网络的结构是集中的，所有数据都集中在一个位置。然而，在现实世界中，数据通常分散在多个参与方（例如，公司、设备）之间，这些参与方旨在协作学习动态贝叶斯网络，同时保护其数据隐私和安全。在本研究中，我们引入了一种联邦学习方法，用于从水平分布在不同参与方之间的数据中估计动态贝叶斯网络的结构。我们提出了一种分布式结构学习方法，该方法利用持续优化，以便在优化过程中仅交换模型参数。在合成和真实数据集上的实验结果表明，我们的方法优于其他最先进的技术，特别是在有许多客户端且单个样本量有限的情况下。]]></description>
      <guid>https://arxiv.org/abs/2412.09814</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>