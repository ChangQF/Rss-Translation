<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>pyBregMan：Bregman 流形的 Python 库</title>
      <link>https://arxiv.org/abs/2408.04175</link>
      <description><![CDATA[arXiv:2408.04175v1 公告类型：新
摘要：Bregman 流形是信息几何中对偶平坦空间的同义词，它承认 Bregman 散度为规范散度。Bregman 流形由光滑的严格凸函数诱导，例如正则指数族的累积量或配分函数、混合族的负熵或正则锥的特征函数，仅列出一些这样的凸 Bregman 生成器。我们描述了 pyBregMan 的设计，这是一个在 Bregman 流形上实现通用操作的库，并实例化了信息科学中使用的几个常见 Bregman 流形。该库的核心是 Legendre-Fenchel 对偶的概念，它诱导了一对规范的对偶势函数和对偶 Bregman 散度。该库还实现了分类/多项分布和多元正态分布的 Fisher-Rao 流形。为了演示如何使用 pyBregMan 内核操纵这些 Bregman 和 Fisher-Rao 流形，该库还提供了几种核心算法，用于统计、机器学习、信息融合等各种应用。]]></description>
      <guid>https://arxiv.org/abs/2408.04175</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:58 GMT</pubDate>
    </item>
    <item>
      <title>基于离线偏好的强化学习的列表奖励估计</title>
      <link>https://arxiv.org/abs/2408.04190</link>
      <description><![CDATA[arXiv:2408.04190v1 公告类型：新 
摘要：在强化学习 (RL) 中，设计精确的奖励函数仍然是一个挑战，特别是在与人类意图保持一致时。基于偏好的 RL (PbRL) 被引入来解决这个问题，它通过从人类反馈中学习奖励模型。然而，现有的 PbRL 方法有局限性，因为它们经常忽略表示偏好相对强度的二阶偏好。在本文中，我们提出了列表奖励估计 (LiRE)，这是一种新的离线 PbRL 方法，它通过构建轨迹排序列表 (RLT) 来利用二阶偏好信息，可以使用与传统方法相同的三元反馈类型有效地构建该列表。为了验证 LiRE 的有效性，我们提出了一个新的离线 PbRL 数据集，客观地反映了估计奖励的效果。我们对数据集进行的大量实验证明了 LiRE 的优越性，即即使在反馈预算适中的情况下也能超越最先进的基线，并且在反馈数量和反馈噪声方面具有稳健性。我们的代码可在 https://github.com/chwoong/LiRE 上找到]]></description>
      <guid>https://arxiv.org/abs/2408.04190</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:58 GMT</pubDate>
    </item>
    <item>
      <title>用于动态交通分配的异构图序列神经网络</title>
      <link>https://arxiv.org/abs/2408.04131</link>
      <description><![CDATA[arXiv:2408.04131v1 公告类型：新
摘要：交通分配和交通流预测为城市规划、交通管理和智能交通系统的发展提供了重要的见解。一个计算整个交通网络交通流量的有效模型可以提供对交通动态的更详细和更现实的理解。然而，现有的交通预测方法，例如利用图神经网络的方法，通常仅限于部署传感器的位置，无法预测传感器位置以外的交通流量。为了缓解这一限制，我们受到链接流和起点-目的地 (OD) 出行需求之间存在的基本关系的启发，提出了异构时空图序列网络 (HSTGSN)。HSTGSN 利用起点和目的地节点之间的依赖关系，即使是长距离的，并学习不同起点-目的地需求下的隐式车辆路线选择。该模型基于由道路链路、OD 链路（连接起点和目的地的虚拟链路）和时空图编码器-解码器组成的异构图，该图可捕获 OD 需求与流量分布之间的时空关系。我们将展示图编码器-解码器如何通过使用图解码器中的节点嵌入来预测流量分布的时间变化，从而恢复 OD 需求中的不完整信息。通过在具有完整/不完整 OD 需求的真实网络进行大量实验研究，我们证明了我们的方法不仅可以捕获链路交通流量与 OD 需求之间的隐式时空关系，还可以实现准确的预测性能和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2408.04131</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:57 GMT</pubDate>
    </item>
    <item>
      <title>数据添加难题</title>
      <link>https://arxiv.org/abs/2408.04154</link>
      <description><![CDATA[arXiv:2408.04154v1 公告类型：新
摘要：在许多用于医疗保健任务的机器学习中，标准数据集是通过收集许多通常根本不相似的来源的数据来构建的。但是，在现实环境中，添加更多数据何时有帮助，何时会阻碍期望的模型结果的进展？我们将这种情况定义为 \textit{数据添加困境}，表明在这种多源扩展环境中添加训练数据有时会导致整体准确性降低、公平性结果不确定以及最差子组性能下降。我们发现，这可能是由于数据扩展导致的模型性能改进与分布偏移导致的模型性能下降之间的经验观察到的权衡。因此，我们建立了解决这一困境的基线策略，引入分布偏移启发式方法来指导决策在数据扩展中添加哪些数据源，以产生预期的模型性能改进。最后，我们讨论了数据收集需要考虑的事项，并提出了在模型日益庞大的时代研究数据组成和规模的建议。]]></description>
      <guid>https://arxiv.org/abs/2408.04154</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:57 GMT</pubDate>
    </item>
    <item>
      <title>克服帕累托最优学习增强算法中的脆弱性</title>
      <link>https://arxiv.org/abs/2408.04122</link>
      <description><![CDATA[arXiv:2408.04122v1 公告类型：新
摘要：近年来，对具有机器学习预测的在线算法的研究引起了相当大的关注。此类算法的设计和分析的共同目标之一是在算法的一致性（即假设完美预测的性能）和稳健性（即对抗性预测下的算法性能）之间实现（帕累托）最优权衡。在这项工作中，我们证明了这种优化标准可能非常脆弱，因为即使在存在不可察觉的预测误差的情况下，帕累托最优算法的性能也可能急剧下降。为了弥补这个缺点，我们提出了一个新框架，其中通过用户指定的配置文件强制执行算法性能的平滑性。这使我们能够根据预测误差来调节算法的性能，同时保持适应配置文件设置的一致性/稳健性权衡的分析概念。我们将这种新方法应用于一个研究充分的在线问题，即单向交易问题。对于这个问题，我们进一步解决了最先进的帕累托最优算法的另一个限制，即它们是针对最坏情况和极度悲观的输入量身定制的。我们提出了一种新的帕累托最优算法，该算法利用与最坏情况输入的任何偏差来发挥其优势，并引入了一种新指标，使我们能够通过优势关系比较任何两个帕累托最优算法。]]></description>
      <guid>https://arxiv.org/abs/2408.04122</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:56 GMT</pubDate>
    </item>
    <item>
      <title>通过样本外扩展对大数据进行核心外降维</title>
      <link>https://arxiv.org/abs/2408.04129</link>
      <description><![CDATA[arXiv:2408.04129v1 公告类型：新
摘要：降维 (DR) 是一种成熟的高维数据集可视化方法。虽然 DR 方法在文献中经常应用于典型的 DR 基准数据集，但它们可能存在高运行时复杂性和内存要求，因此不适合大数据可视化，尤其是在高性能计算之外的环境中。为了对大型数据集执行 DR，我们建议使用样本外扩展。此类扩展允许将新数据插入现有投影，我们利用这些扩展将数据迭代投影到仅由一个小的可管理子集组成的参考投影中。此过程使得对大数据执行核外 DR 成为可能，否则由于内存和运行时限制，这是不可能的。对于度量多维缩放 (MDS)，我们贡献了一个具有样本外投影功能的实现，因为典型的软件库不支持它。我们使用文献中的质量指标对五种常见 DR 算法（MDS、PCA、t-SNE、UMAP 和自动编码器）的投影质量进行了评估，并分析了参考集大小与投影质量之间的权衡。算法的运行时行为也根据参考集大小、样本外批量大小和数据集的维数进行了量化。此外，我们将样本外方法与其他最近引入的 DR 方法（例如 PaCMAP 和 TriMAP）进行了比较，这些方法声称可以处理比传统方法更大的数据集。为了展示 DR 在如此大规模上的实用性，我们提供了一个用例，其中我们分析了多达十亿个投影实例的流线集合。]]></description>
      <guid>https://arxiv.org/abs/2408.04129</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:56 GMT</pubDate>
    </item>
    <item>
      <title>零延迟 QKV 压缩可缓解 LLM 推理中的 KV 缓存和网络瓶颈</title>
      <link>https://arxiv.org/abs/2408.04107</link>
      <description><![CDATA[arXiv:2408.04107v1 公告类型：新
摘要：在大型语言模型中，键值缓存 (KVC) 中的内存限制在推理过程中带来了挑战，尤其是在长提示的情况下。在这项工作中，我们观察到压缩 KV 值比压缩模型在准确性和作业完成时间 (JCT) 方面更有效。但是，量化 KV 值并删除不太重要的标记会导致显着的运行时计算时间开销，从而延迟 JCT。这些方法也无法减少长提示的序列并行 (SP) 框架中的计算时间或高网络通信时间开销。为了解决这些问题，基于我们从实验分析中获得的深刻观察，我们提出了 ZeroC，这是一种零延迟 QKV 压缩系统，可消除时间开销，甚至减少模型操作的计算和通信时间。ZeroC 创新地将压缩和解压缩操作嵌入模型操作中，并在混合层标记级别自适应地确定压缩率。此外，它还支持通信高效的 SP 推理框架。跟踪驱动的实验表明，与最先进的压缩方法相比，ZeroC 的平均 JCT 降低了 80%，平均困惑度降低了 35%，吞吐量提高了 2.8 倍，同时延迟相同。ZeroC 还将当前 LLM 服务系统的平均 JCT 降低了 91%，但困惑度的增加限制为 0.1。我们已将代码开源。]]></description>
      <guid>https://arxiv.org/abs/2408.04107</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:55 GMT</pubDate>
    </item>
    <item>
      <title>结合神经架构搜索和自动代码优化：一项调查</title>
      <link>https://arxiv.org/abs/2408.04116</link>
      <description><![CDATA[arXiv:2408.04116v1 公告类型：新
摘要：近年来，深度学习模型的复杂性和资源需求呈指数级增长。加速这些模型以在资源受限的设备上高效执行变得比以往任何时候都更加重要。实现这一目标的两种值得注意的技术是硬件感知神经架构搜索 (HW-NAS) 和自动代码优化 (ACO)。HW-NAS 自动设计准确且硬件友好的神经网络，而 ACO 涉及搜索最佳编译器优化以应用于神经网络，以便在目标硬件上进行高效映射和推理。本调查探讨了最近将这两种技术结合在一个框架内的工作。我们介绍了这两个领域的基本原理，并展示了它们在独立执行时的次优性。然后，我们研究将它们集成到一个联合优化过程中，我们称之为硬件感知神经架构和编译器优化共同搜索 (NACOS)。]]></description>
      <guid>https://arxiv.org/abs/2408.04116</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:55 GMT</pubDate>
    </item>
    <item>
      <title>PowerPM：电力系统基础模型</title>
      <link>https://arxiv.org/abs/2408.04057</link>
      <description><![CDATA[arXiv:2408.04057v1 公告类型：新
摘要：大量电力时间序列 (ETS) 数据的出现为电力系统中的各种应用提供了充足的机会，包括需求侧管理、电网稳定性和消费者行为分析。深度学习模型通过有效捕获序列依赖性来推进 ETS 建模。然而，由于 ETS 数据固有的复杂层次结构，学习用于各种应用的 ETS 数据的通用表示仍然具有挑战性。此外，ETS 数据表现出复杂的时间依赖性，易受外生变量的影响。此外，不同的实例表现出不同的电力消费行为。在本文中，我们提出了一个基础模型 PowerPM 来建模 ETS 数据，为电力系统提供大规模、现成的模型。PowerPM 由时间编码器和分层编码器组成。时间编码器捕获 ETS 数据中的时间依赖性，同时考虑外生变量。分层编码器模拟层次结构之间的相关性。此外，PowerPM 利用了一种新颖的自监督预训练框架，该框架由掩蔽 ETS 建模和双视图对比学习组成，使 PowerPM 能够捕获 ETS 窗口内的时间依赖性并了解 ETS 窗口之间的差异，从而提供两个不同的视角来学习通用表示。我们的实验涉及五个真实世界场景数据集，包括私有数据和公共数据。通过对大量 ETS 数据进行预训练，PowerPM 在私有数据集中的各种下游任务上实现了 SOTA 性能。令人印象深刻的是，当转移到公共数据集时，PowerPM 保持了其优势，展示了其在各种任务和领域的卓越泛化能力。此外，消融研究和小样本实验为我们模型的有效性提供了额外的证据。]]></description>
      <guid>https://arxiv.org/abs/2408.04057</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:54 GMT</pubDate>
    </item>
    <item>
      <title>树注意力：GPU 集群上长上下文注意力的拓扑感知解码</title>
      <link>https://arxiv.org/abs/2408.04093</link>
      <description><![CDATA[arXiv:2408.04093v1 公告类型：新
摘要：自注意力是现代 Transformer 架构的核心数学运算，由于其序列长度的二次复杂度，也是一个重要的计算瓶颈。在这项工作中，我们推导出标量能量函数，其梯度计算自注意力块，从而阐明自注意力的理论基础，提供操作的贝叶斯解释，并将其与 Hopfield 网络等基于能量的模型紧密联系起来。此外，由于这种公式，我们发现我们可以使用高效且优化的自动微分技术来推导一种高效的树注意力算法来计算能量的梯度，从而计算自注意力。我们的公式表明，通过树减少可以有效地并行计算跨序列轴的减少。我们的算法用于在多个 GPU 上并行化注意力计算，与 Ring Attention 等替代方法相比，它可以使跨设备解码的速度渐近更快（最高可快 8 倍），同时所需的通信量也显著减少，峰值内存占用也减少了 2 倍。我们的代码可在此处公开获取：\url{https://github.com/Zyphra/tree_attention}]]></description>
      <guid>https://arxiv.org/abs/2408.04093</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:54 GMT</pubDate>
    </item>
    <item>
      <title>无学习率强化学习：具有非平稳目标的模型选择案例</title>
      <link>https://arxiv.org/abs/2408.04046</link>
      <description><![CDATA[arXiv:2408.04046v1 公告类型：新
摘要：强化学习 (RL) 算法的性能对超参数的选择很敏感，其中学习率尤其有影响力。当学习率设置不理想时，RL 算法无法达到收敛或需要大量样本。在这项工作中，我们表明模型选择有助于改善由于学习率选择不理想而导致的 RL 失败模式。我们提出了一个无学习率强化学习的模型选择框架，该框架采用模型选择方法来动态选择最佳学习率。这种自适应学习率调整方法既不依赖于底层 RL 算法也不依赖于优化器，仅使用奖励反馈来选择学习率；因此，该框架可以输入任何 RL 算法并生成其无学习率版本。我们对策略优化方法进行实验，并评估我们框架内的各种模型选择策略。我们的结果表明，当超参数的最佳选择与时间相关且非平稳时，数据驱动的模型选择算法是标准强盗算法的更好替代方案。]]></description>
      <guid>https://arxiv.org/abs/2408.04046</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:53 GMT</pubDate>
    </item>
    <item>
      <title>用于子图预测的深度生成模型</title>
      <link>https://arxiv.org/abs/2408.04053</link>
      <description><![CDATA[arXiv:2408.04053v1 公告类型：新
摘要：图神经网络 (GNN) 在不同领域（例如社交网络分析和推荐系统）中都很重要，因为它们能够对复杂的关系数据进行建模。本文介绍了子图查询作为深度图学习的一项新任务。与专注于链接预测或节点分类等单个组件的传统图预测任务不同，子图查询基于观察到的子图所表示的证据联合预测目标子图的组件。例如，子图查询可以预测一组目标链接和/或节点标签。为了回答子图查询，我们使用概率深度图生成模型。具体而言，我们归纳训练变分图自动编码器 (VGAE) 模型，该模型经过增强以表示链接、节点特征和标签的联合分布。贝叶斯优化用于调整特定域中链接、节点特征和标签的相对重要性的权重。我们描述了一种确定性和基于采样的推理方法，用于以零样本方式从 VGAE 生成图分布中估计子图概率，无需重新训练。为了进行评估，我们将推理方法应用于六个基准数据集上的一系列子图查询。我们发现，从模型进行推理可实现卓越的预测性能，超越独立预测基线，AUC 分数的提高范围从 0.06 到 0.2 分不等，具体取决于数据集。]]></description>
      <guid>https://arxiv.org/abs/2408.04053</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:53 GMT</pubDate>
    </item>
    <item>
      <title>抑郁症预测中的多模式性别公平性：基于美国和中国数据的见解</title>
      <link>https://arxiv.org/abs/2408.04026</link>
      <description><![CDATA[arXiv:2408.04026v1 公告类型：新
摘要：社交代理和机器人越来越多地用于健康环境。然而，一个关键的挑战是，这些代理和机器人通常依赖机器学习 (ML) 算法来检测和分析个人的心理健康。ML 算法中的偏见和公平性问题正成为越来越令人担忧的问题。与此同时，现有文献也表明，心理健康状况在不同性别和文化中的表现可能不同。我们假设特征（声学、文本和视觉）的表示及其模态间关系会因来自不同文化和性别的受试者而异，从而影响各种 ML 模型的性能和公平性。我们通过对来自美国和中国的两个不同数据集进行研究，首次对抑郁症表现中的多模态性别公平性进行了评估。我们进行了彻底的统计和 ML 实验，并对几种不同的算法重复实验，以确保结果不依赖于算法。我们的研究结果表明，尽管两个数据集之间存在差异，但尚不能确定这是否是由于假设的抑郁症表现差异或其他外部因素（例如数据收集方法的差异）造成的。我们的研究结果进一步激发了人们对更一致、更具文化意识的数据收集过程的呼吁，以解决抑郁症检测中的机器学习偏见问题，并促进更公平的代理和机器人的开发，以造福人类。]]></description>
      <guid>https://arxiv.org/abs/2408.04026</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:52 GMT</pubDate>
    </item>
    <item>
      <title>增强输出多样性可改善基于共轭梯度的对抗性攻击</title>
      <link>https://arxiv.org/abs/2408.03972</link>
      <description><![CDATA[arXiv:2408.03972v1 公告类型：新
摘要：深度神经网络容易受到对抗性示例的攻击，并且在此背景下研究了生成对抗性示例的对抗性攻击。现有研究表明，增加模型输出的多样性有助于提高攻击性能。本研究重点关注自共轭梯度 (ACG) 攻击，该攻击受共轭梯度法启发，具有很高的多样化性能。我们假设增加两个连续搜索点之间的距离会增强输出多样性。为了检验我们的假设，我们提出了 Rescaling-ACG (ReACG)，它自动修改显着影响两个连续搜索点之间距离的两个组件，包括搜索方向和步长。ReACG 表现出比 ACG 更高的攻击性能，并且对于具有多个分类类别的 ImageNet 模型特别有效。实验结果表明，两个连续搜索点之间的距离增强了输出多样性，可能有助于开发新的强大攻击。代码可在 \url{https://github.com/yamamura-k/ReACG} 获取]]></description>
      <guid>https://arxiv.org/abs/2408.03972</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:51 GMT</pubDate>
    </item>
    <item>
      <title>通过最优传输从长尾数据的噪声标签中学习</title>
      <link>https://arxiv.org/abs/2408.03977</link>
      <description><![CDATA[arXiv:2408.03977v1 公告类型：新
摘要：现实世界数据集中常见的噪声标签会严重损害深度学习模型的训练。然而，最近的对抗性抗噪方法忽略了真实数据的长尾分布，这会严重损害去噪策略的效果。同时，噪声标签的管理不善进一步损害了模型处理长尾数据的能力。为了解决这个问题，我们提出了一种新方法来管理同时具有长尾分布和噪声标签的数据。首先，我们引入了一个损失距离交叉选择模块，它集成了类预测和特征分布来过滤干净的样本，有效地解决了噪声标签和长尾分布引入的不确定性。随后，我们采用最优传输策略以半监督训练的方式为噪声集生成伪标签，提高伪标签质量，同时减轻长尾分布导致的样本稀缺性的影响。我们在合成数据集和真实数据集上进行了实验，综合实验结果表明我们的方法超越了目前最先进的方法。我们的代码将在未来提供。]]></description>
      <guid>https://arxiv.org/abs/2408.03977</guid>
      <pubDate>Fri, 09 Aug 2024 06:21:51 GMT</pubDate>
    </item>
    </channel>
</rss>