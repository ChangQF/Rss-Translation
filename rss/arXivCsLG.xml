<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 28 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>面向基础模型：对具有不确定性的地球科学人工智能的评估</title>
      <link>https://arxiv.org/abs/2501.14809</link>
      <description><![CDATA[arXiv:2501.14809v1 公告类型：新
摘要：人工智能 (AI) 通过深度学习模型 (DLM) 改变了地球科学界，这些模型经过训练可以完成工作流中的特定任务。这一成功导致了地球科学基础模型 (FM) 的发展，这些模型有望在工作流中完成多项任务或完全取代工作流。然而，即使是传统的 DLM，也缺乏强大的评估框架，这使得地球科学界对不可避免的 FM 的采用准备不足。我们通过设计一个评估框架来解决这一差距，该框架共同结合了当前 DLM 和未来 FM 的三个关键方面：性能不确定性、学习效率和重叠的训练-测试数据分割。为了针对这三个方面，我们使用针对地球科学数据的聚类方法精心构建训练、验证和测试分割，并制定了广泛的训练设计，以隔离由随机训练过程和随机数据采样引起的性能不确定性。通过对 3 种训练方法下流行的地震相位拾取 DLM PhaseNet 进行评估，证明了该框架能够防止误导性模型优越性声明。此外，我们还展示了由于训练测试数据重叠而导致的性能提升如何导致 FM 评估出现偏差。我们的框架通过明确分析不同训练数据预算下的模型性能，帮助从业者为他们的问题选择最佳模型并设定性能预期。]]></description>
      <guid>https://arxiv.org/abs/2501.14809</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于切削力学的机器学习建模方法探索加工动力学控制方程</title>
      <link>https://arxiv.org/abs/2501.14817</link>
      <description><![CDATA[arXiv:2501.14817v1 公告类型：新
摘要：本文提出了一种基于切削力学的机器学习（CMML）建模方法来发现加工动力学的控制方程。CMML设计的主要思想是将切削力学中现有的物理和数据中的未知物理相结合，以实现自动模型发现，并有可能推进加工建模。基于切削力学中现有的物理，CMML首先建立一个控制加工动力学的通用建模结构，该结构由一组未知的微分代数方程表示。因此，CMML可以通过有效的基于切削力学的非线性学习函数空间设计和基于离散优化的学习算法实现数据驱动的这些未知方程的发现。经过实验验证的铣削时域模拟用于验证所提出的建模方法。数值结果表明，CMML可以从噪声数据中发现具有工艺阻尼和边缘力的精确铣削动力学模型。这表明，随着有效计量系统的发展，CMML 有潜力在实践中用于推进机械加工建模。]]></description>
      <guid>https://arxiv.org/abs/2501.14817</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>虫洞记忆：用于跨对话检索的魔方</title>
      <link>https://arxiv.org/abs/2501.14846</link>
      <description><![CDATA[arXiv:2501.14846v1 Announce Type: new 
摘要：针对当前大型语言模型在跨对话共享记忆方面的差距，本研究提出一种虫洞记忆模块（WMM），将记忆实现为魔方状，可在不同的对话之间任意检索。通过模拟实验，研究者基于Python环境搭建实验框架，通过设置记忆屏障来模拟当前LLM对话间记忆难以共享的情况。将CoQA开发数据集导入实验，针对WMM的非线性索引和动态检索验证其跨对话记忆检索功能的可行性，并与Titans和MemGPT记忆模块的能力进行对比分析。实验结果表明，WMM在8次实验中展现出了跨对话记忆检索的能力和量化指标的稳定性。为LLM内存管理的优化贡献了新的技术途径，为以后的实际应用提供了经验。]]></description>
      <guid>https://arxiv.org/abs/2501.14846</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过增量自适应评估进行迭代特征空间优化</title>
      <link>https://arxiv.org/abs/2501.14889</link>
      <description><![CDATA[arXiv:2501.14889v1 公告类型：新
摘要：迭代特征空间优化涉及系统地评估和调整特征空间以提高下游任务性能。然而，现有的工作有三个关键限制：1）忽视数据样本之间的差异会导致评估偏差；2）根据特定的机器学习模型定制特征空间会导致过度拟合和泛化不良；3）在每次优化迭代期间都需要从头开始重新训练评估者，这会显著降低优化过程的整体效率。为了弥补这些差距，我们提出了一种广义自适应特征空间评估器 (EASE)，以有效地生成最佳和广义的特征空间。该框架由两个关键组件组成：特征样本子空间生成器和上下文注意评估器。第一个组件旨在解耦特征空间内的信息分布以减轻评估偏差。为了实现这一点，我们首先根据后续评估者的反馈确定与预测任务最相关的特征和最具挑战性的样本。这种解耦策略使评估器始终以特征空间中最具挑战性的方面为目标。第二个组件旨在逐步捕获特征空间的演变模式，以实现高效评估。我们提出了一种加权共享多头注意力机制，将特征空间的关键特征编码为嵌入向量以供评估。此外，评估器会逐步更新，保留先前的评估知识，同时融入新见解，因为优化过程中的连续特征空间共享部分信息。在 14 个真实世界数据集上进行的大量实验证明了所提框架的有效性。我们的代码和数据是公开的。]]></description>
      <guid>https://arxiv.org/abs/2501.14889</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可行的学习</title>
      <link>https://arxiv.org/abs/2501.14912</link>
      <description><![CDATA[arXiv:2501.14912v1 公告类型：新
摘要：我们引入了可行学习 (FL)，这是一种以样本为中心的学习范式，其中通过解决可行性问题来训练模型，该问题限制了每个训练样本的损失。与针对平均性能进行优化的普遍经验风险最小化 (ERM) 框架不同，FL 要求每个单独的数据点都具有令人满意的性能。由于任何满足规定性能阈值的模型都是有效的 FL 解决方案，因此优化算法的选择及其动态在塑造最终解决方案的属性方面起着至关重要的作用。特别是，我们研究了一种原始对偶方法，它在训练过程中动态地重新加权每个样本的重要性。为了应对在实践中设置有意义的阈值的挑战，我们引入了一种 FL 的松弛方法，其中包含最小范数的松弛变量。我们的实证分析涵盖了大型语言模型中的图像分类、年龄回归和偏好优化，结果表明，通过 FL 训练的模型可以从数据中学习，同时与 ERM 相比表现出改进的尾部行为，对平均性能的影响极小。]]></description>
      <guid>https://arxiv.org/abs/2501.14912</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数空间中的可解释性：通过基于归因的参数分解最小化机械描述长度</title>
      <link>https://arxiv.org/abs/2501.14926</link>
      <description><![CDATA[arXiv:2501.14926v1 公告类型：新
摘要：机械可解释性旨在理解神经网络学习的内部机制。尽管最近在这一目标上取得了进展，但如何最好地将神经网络参数分解为机械组件仍不清楚。我们引入了基于归因的参数分解 (APD)，这种方法直接将神经网络的参数分解为 (i) 忠实于原始网络参数的组件，(ii) 需要最少数量的组件来处理任何输入，以及 (iii) 尽可能简单。因此，我们的方法优化了网络机制的最小长度描述。我们通过在多个玩具实验设置中成功识别地面真实机制来证明 APD 的有效性：从叠加中恢复特征；分离压缩计算；并识别跨层分布式表示。虽然将 APD 扩展到非玩具模型仍然存在挑战，但我们的结果为机械可解释性中的几个未解决的问题提供了解决方案，包括识别叠加中的最小电路、为“特征”提供概念基础以及为神经网络分解提供与架构无关的框架。]]></description>
      <guid>https://arxiv.org/abs/2501.14926</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变化环境中的决策：稳健性、基于查询的学习和差异隐私</title>
      <link>https://arxiv.org/abs/2501.14928</link>
      <description><![CDATA[arXiv:2501.14928v1 公告类型：新
摘要：我们研究交互式决策问题，其中底层环境会随给定约束而随时间变化。我们提出了一个框架，我们称之为 \textit{混合结构化观察决策} (混合 DMSO)，它在决策的随机性和对抗性设置之间提供插值。在这个框架内，我们可以分析局部差异隐私 (LDP) 决策、基于查询的学习（特别是 SQ 学习）以及同一保护伞下的稳健和平稳决策，根据决策估计系数 (DEC) 的变体得出上限和下限。我们进一步建立了 DEC 的行为、SQ 维度、局部极小最大复杂度、可学习性和联合差异隐私之间的紧密联系。为了展示该框架的强大功能，我们为 LDP 约束下的上下文老虎机提供了新结果。]]></description>
      <guid>https://arxiv.org/abs/2501.14928</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>E-Gen：利用 E-Graphs 改进符号表达式的连续表示</title>
      <link>https://arxiv.org/abs/2501.14951</link>
      <description><![CDATA[arXiv:2501.14951v1 公告类型：新摘要：由于向量表示在推进自然语言处理 (NLP) 方面发挥着关键作用，一些先前的研究集中在通过利用数学上等价的表达式来创建数学表达式的嵌入技术。虽然这些方法很有效，但它们受到训练数据的限制。在这项工作中，我们提出使用一种新的基于 e-graph 的生成方案，用更大的合成数据集来增强先前的算法。这种新的数学数据集生成方案 E-Gen 改进了先前在大小和运算符类型上有限的数据集生成方案。我们使用该数据集比较使用两种方法训练的嵌入模型：(1) 训练模型以生成数学上等价的表达式，以及 (2) 使用对比学习训练模型以明确对数学上等价的表达式进行分组。我们根据分布内和分布外语言处理任务的先前工作评估了这些方法生成的嵌入。最后，我们将我们的嵌入方案的性能与最先进的大型语言模型进行了比较，并证明基于嵌入的语言处理方法在多个任务上的表现优于 LLM，证明了针对数学数据模态优化嵌入方法的必要性。]]></description>
      <guid>https://arxiv.org/abs/2501.14951</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中任意性的奇怪案例</title>
      <link>https://arxiv.org/abs/2501.14959</link>
      <description><![CDATA[arXiv:2501.14959v1 公告类型：新
摘要：算法建模依赖于数据中的有限信息来推断未见过场景的结果，通常会在决策中嵌入任意性元素。最近引起人们兴趣的一种关于这种任意性的观点是多重性——研究一组“好模型”的任意性，即那些可能在实践中部署的模型。在这项工作中，我们通过以下方式系统化关于多重性的文献：(a) 形式化围绕模型设计选择及其对任意性的贡献的术语，(b) 扩展多重性的定义以纳入代表性不足的形式，而不仅仅是预测和解释，(c) 澄清多重性与其他传统任意性视角（即不确定性和方差）之间的区别，以及 (d) 将多重性的好处和潜在风险提炼为总体趋势，将其置于负责任的人工智能的更广阔领域中。最后，我们确定了开放的研究问题并强调了这一年轻但快速发展的研究领域的新兴趋势。]]></description>
      <guid>https://arxiv.org/abs/2501.14959</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM4DistReconfig：用于配电网络重构的精细调整大型语言模型</title>
      <link>https://arxiv.org/abs/2501.14960</link>
      <description><![CDATA[arXiv:2501.14960v1 公告类型：新
摘要：由于 DER 的整合和客户参与度的提高，配电网络正在不断发展。为了保持最佳运行，最大限度地减少损失并满足不同的负载需求，频繁的网络重新配置是必要的。传统上，重新配置任务依赖于优化软件和专家操作员，但随着系统变得越来越复杂，需要更快、更自适应的解决方案而无需专家干预。数据驱动的重新配置因其准确性、速度和对不完整网络数据的稳健性而受到关注。LLM 具有捕获复杂模式的能力，为不断发展的复杂电力网络中高效、响应迅速的网络重新配置提供了一种有前途的方法。
在这项工作中，我们介绍了 LLM4DistReconfig，这是一种基于深度学习的方法，利用微调的 LLM 来解决配电网络重新配置问题。通过精心设计提示和设计自定义损失函数，我们使用代表网络参数（例如总线、可用线路、开路线路、节点电压和系统损耗）的输入来训练 LLM。然后，该模型通过输出更新的网络配置来预测最佳重新配置，这些配置可在满足操作约束的同时最大限度地减少系统损失。与传统算法相比，我们的方法显著缩短了推理时间，允许在训练后实现近乎实时的最佳重新配置。实验结果表明，我们的方法可以为五个单独的和一个组合的测试数据集生成最佳配置，从而最大限度地减少系统损失。它还在所有数据集中生成最少的无效边、无循环或子图，满足特定领域的需求。此外，生成的响应在可见网络上包含不到 5% 的不正确输出，在未见网络上包含令人满意的结果，证明了其对重新配置任务的有效性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2501.14960</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的个性化层选择</title>
      <link>https://arxiv.org/abs/2501.14964</link>
      <description><![CDATA[arXiv:2501.14964v1 公告类型：新
摘要：图神经网络 (GNN) 将节点属性与节点周围局部图结构的固定粒度相结合，以预测其标签。但是，不同的节点可能与具有不同局部邻域粒度的节点级属性相关，并且对所有节点使用相同级别的平滑可能会不利于它们的分类。在这项工作中，我们挑战了一个普遍事实，即单个 GNN 层可以通过为每个节点训练具有不同个性化层的 GNN 来对图的所有节点进行分类。受度量学习的启发，我们提出了一种新算法 MetSelect1，以选择最佳表示层来对每个节点进行分类。具体而言，我们在转换后的 GNN 层中识别每个类的原型表示，然后使用该层的方差进行归一化后，使用与类原型距离最小的层进行分类。在 10 个数据集和 3 个不同的 GNN 上进行的结果表明，我们以即插即用的方式显著提高了 GNN 的节点分类准确率。我们还发现，使用可变层进行预测可以使 GNN 更深，并且对中毒攻击更具鲁棒性。我们希望这项工作能够启发未来的工作，以学习更具适应性和个性化的图形表示。]]></description>
      <guid>https://arxiv.org/abs/2501.14964</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于降雨径流模拟的深度状态空间模型</title>
      <link>https://arxiv.org/abs/2501.14980</link>
      <description><![CDATA[arXiv:2501.14980v1 公告类型：新
摘要：研究水循环中降雨径流过程的传统方法依赖于概念或基于物理的水文模型。深度学习 (DL) 最近作为一种替代方案出现，并在水文学界蓬勃发展，用于降雨径流模拟。然而，几十年前的长短期记忆 (LSTM) 网络仍然是这项任务的基准，其表现优于 Transformers 等较新的架构。在这项工作中，我们提出了一种状态空间模型 (SSM)，特别是频率调整对角状态空间序列 (S4D-FT) 模型，用于降雨径流模拟。提出的 S4D-FT 与已建立的 LSTM 和基于物理的萨克拉门托土壤水分核算模型进行了对比，涵盖了美国本土 (CONUS) 的 531 个流域。结果表明，S4D-FT 能够在不同地区胜过 LSTM 模型。我们率先引入了用于降雨径流模拟的 S4D-FT，挑战了 LSTM 在水文界的主导地位，并扩展了可用于水文建模的 DL 工具库。]]></description>
      <guid>https://arxiv.org/abs/2501.14980</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DepressionX：融合知识的残留注意力，用于可解释的抑郁症严重程度评估</title>
      <link>https://arxiv.org/abs/2501.14985</link>
      <description><![CDATA[arXiv:2501.14985v1 公告类型：新
摘要：在当今互联互通的社会中，社交媒体平台已成为我们生活中的重要组成部分，个人可以在其中虚拟地表达自己的想法、情感和情绪。这些表达为他们的心理健康提供了宝贵的见解。本文探讨了使用 Facebook、$\mathbb{X}$（以前称为 Twitter）和 Reddit 等平台进行心理健康评估。我们提出了一种名为 DepressionX 的领域知识注入残余注意力模型，用于可解释的抑郁症严重程度检测。现有的深度学习模型在这个问题上表现出了相当好的表现，但它们的决策过程往往缺乏透明度。在医疗保健领域，决策至关重要，对可解释性的需求至关重要。在我们的模型中，我们通过关注抑郁症严重程度检测的可解释性来解决关键差距，同时追求高性能准确性。除了可解释之外，我们的模型在平衡和不平衡数据集上的 $\text{F}_1$ 得分方面始终比最先进的模型高出 7% 以上。我们的最终目标是建立一个通过社交媒体对精神障碍进行可信且易于理解的分析的基础。]]></description>
      <guid>https://arxiv.org/abs/2501.14985</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集合函数学习的进展：技术与应用综述</title>
      <link>https://arxiv.org/abs/2501.14991</link>
      <description><![CDATA[arXiv:2501.14991v1 公告类型：新
摘要：集合函数学习已成为机器学习中的一个重要领域，解决了以集合为输入的函数建模挑战。与涉及固定大小输入向量且特征顺序很重要的传统机器学习不同，集合函数学习需要对输入集的排列不变的方法，这是一个独特而复杂的问题。本综述全面概述了集合函数学习的当前发展，涵盖了基础理论、关键方法和各种应用。我们对现有方法进行分类和讨论，重点关注深度学习方法，例如基于 DeepSets 和 Set Transformer 的方法，以及深度学习以外的其他值得注意的替代方法，提供当前模型的完整视图。我们还介绍了各种应用和相关数据集，例如点云处理和多标签分类，重点介绍了集合函数学习方法在这些领域取得的重大进展。最后，我们总结集合函数学习方法的现状并确定未来有希望的研究方向，旨在指导和启发这一有希望的领域的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2501.14991</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分层强化学习对复杂交通场景进行广泛探索</title>
      <link>https://arxiv.org/abs/2501.14992</link>
      <description><![CDATA[arXiv:2501.14992v1 公告类型：新
摘要：开发能够在复杂交通环境中导航的自动驾驶系统仍然是一项艰巨的挑战。与基于规则或监督学习的方法不同，基于深度强化学习 (DRL) 的控制器消除了对特定领域知识和数据集的需求，从而提供了对各种场景的适应性。尽管如此，现有基于 DRL 的控制器研究的一个常见限制是它们专注于具有简单交通模式的驾驶场景，这阻碍了它们有效处理具有延迟、长期奖励的复杂驾驶环境的能力，从而损害了其研究结果的普遍性。为了应对这些限制，我们的研究引入了一个开创性的分层框架，可以有效地将复杂的决策问题分解为可管理和可解释的子任务。我们采用两步训练过程，分别训练高级控制器和低级控制器。高层控制器通过长期延迟奖励展现出增强的探索潜力，而低层控制器则利用短期瞬时奖励提供纵向和横向控制能力。通过仿真实验，我们证明了我们的分层控制器在管理复杂的高速公路驾驶情况方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2501.14992</guid>
      <pubDate>Tue, 28 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>