<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Thu, 20 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>思考偏好优化</title>
      <link>https://arxiv.org/abs/2502.13173</link>
      <description><![CDATA[ARXIV：2502.13173V1公告类型：新 
摘要：监督的微调（SFT）是通过对相对较小的LLM中的长期思考链（COT）推理来通过对较大LLM的长COT响应进行微调来增强长期思考链（COT）推理的方法。为了持续提高推理能力，我们可以收集新的高质量的长床推理SFT数据，或者反复对现有的SFT数据集进行培训。但是，获取新的长COT SFT数据是昂贵且有限的，而重复培训通常会导致性能高原或下降。为了通过SFT数据进一步提高性能，我们提出了思维偏好优化（ThinkPo），这是一种简单而有效的后STF后方法，可增强长长的COT推理，而无需新的长COT响应。取而代之的是，ThinkPo使用随时可用或易于获得的短COT推理回答作为拒绝的答案和较长的COT答复，作为选择的答案。然后，它采用直接优化优化，以鼓励模型偏爱更长的推理输出。实验表明，ThinkPo进一步提高了SFT-ED模型的推理性能，例如它将SFT-ED模型的数学推理精度提高了8.6％，输出长度增加了25.9％。值得注意的是，ThinkPo能够不断将公开蒸馏的SFT模型的性能不断提高，例如，将官方的DeepSeek-R1-Distill-Qwen-Qwen-7b在Math500上的性能从87.4％提高到91.2％。]]></description>
      <guid>https://arxiv.org/abs/2502.13173</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成拓扑优化：探索结构设计中的各种解决方案</title>
      <link>https://arxiv.org/abs/2502.13174</link>
      <description><![CDATA[ARXIV：2502.13174V1公告类型：新 
摘要：拓扑优化（TO）是一种计算方法家族，从形式的问题描述中得出了近乎最佳的几何形状。尽管成功，但建立的方法仅限于生成单个解决方案，从而限制了替代设计的探索。为了解决此限制，我们引入了生成拓扑优化（GENTO） - 一种无数据的方法，该方法训练神经网络以生成结构符合结构的形状，并通过明确的多样性约束来探索各种解决方案。该网络经过培训，可以在环路中进行求解，从而优化了每次迭代中的材料分布。训练有素的模型产生的形状多种多样，非常遵守设计要求。我们在2D和3D上验证Gento是否有问题。我们的结果表明，Gento产生的解决方案比任何先前的方法都多，同时维持近乎优势，并且由于固有的并行性而更快。这些发现为工程和设计开辟了新的途径，为结构优化提供了增强的灵活性和创新。]]></description>
      <guid>https://arxiv.org/abs/2502.13174</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Baklava-长篇小说推断的KV缓存预算分配</title>
      <link>https://arxiv.org/abs/2502.13176</link>
      <description><![CDATA[ARXIV：2502.13176V1公告类型：新 
摘要：在大型语言模型（LLM）推理中，键值（KV）缓存（KV-CACHES）对于降低时间复杂性至关重要。但是，随着上下文长度的增长，它们导致GPU内存的线性增加。虽然最近的工作探讨了KV-CACHE驱逐和减少记忆使用量的压缩政策，但它们通常会考虑所有注意力头的统一KV-CACHES，从而导致次优性能。我们介绍了Baklava，这是一种通过估计每个KV-CACHE的重要性来分配模型中单个KV-CACHES的最佳内存的方法。我们的经验分析表明，并非所有KV-Caches对于LLM性能同样至关重要。使用一次性分析方法，Baklava为每个KV-CACHE分配了最佳的内存预算。我们在Llama-3-8B和QWEN2.5-7B模型上评估了我们的方法，达到了70 \％的压缩率，同时保持基线性能并在较高的压缩水平下提高速度的准确度。]]></description>
      <guid>https://arxiv.org/abs/2502.13176</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扰动进行直接偏好优化的KL罚款控制</title>
      <link>https://arxiv.org/abs/2502.13177</link>
      <description><![CDATA[ARXIV：2502.13177V1公告类型：新 
摘要：直接偏好优化（DPO）证明了仅使用离线数据集将大语言模型与人类偏好对齐的优点。但是，DPO的限制是，在整个训练过程中，KL惩罚防止过度偏离参考模型，这是静态的。几种方法试图将这种静态KL惩罚转变为动态惩罚，但是没有任何方法可以适应每个首选项对分配不同的KL惩罚。在本文中，我们提出了$ \ varepsilon $ -Direct首选项优化（$ \ varepsilon $ -dpo），该优化允许对每种偏好对的KL惩罚强度$ \ beta $自适应控制。具体来说，$ \ varepsilon $ -dpo根据logits的单调性作为每个优先级对$ \ beta $作为$ \ beta $的偏好模型的单调性，在培训期间，简单地仅利用当前策略的logit和参考文献，政策。实验结果表明，$ \ varepsilon $ -DPO优于一般聊天机器人基准上的现有直接比对算法和KL罚款放松方法，突出了DPO中实例级别自适应KL罚款放宽的重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.13177</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMS中的基准测试后培训量化：综合分类法，统一评估和比较分析</title>
      <link>https://arxiv.org/abs/2502.13178</link>
      <description><![CDATA[ARXIV：2502.13178V1公告类型：新 
摘要：培训后量化（PTQ）技术已被广泛用于大型语言模型（LLMS）压缩，这是由于其效率和低资源要求。但是，当前的研究缺乏对每种PTQ策略的上级和适用场景的深入分析。此外，现有算法主要关注性能，忽视模型大小，性能和量化位的权衡。为了减轻这些困惑，我们在本文中为LLMS PTQ提供了一种新颖的基准。首先，为了支持我们的基准，我们通过审查其计算策略（例如，基于优化的，基于薪酬等），为现有主流方法提出了全面的分类法。然后，我们对每个班级的基线进行了广泛的实验，涵盖了各种尺寸（7b-70b），位宽，训练水平（Llama1/2/2/3/3.1），建筑（Mixtral，DeepSeekmoe和Mamba）和Moditation（Llava11） .5和vila1.5）在广泛的评估指标上。通过对结果进行比较分析，我们总结了上级考虑性能的每种PTQ策略和模型化折衷。例如，我们的基准表明，基于补偿的技术表明，应重新审查超大型模型的出色跨体系结构鲁棒性和极低的PTQ。最后，我们进一步声称，薪酬和其他PTQ策略的实际结合可以实现SOTA各种鲁棒性。我们认为，我们的基准将为LLM的部署以及对PTQ方法的未来研究提供宝贵的建议。]]></description>
      <guid>https://arxiv.org/abs/2502.13178</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PTQ1.61：推动大语言模型的极低训练后训练量化方法的真正限制</title>
      <link>https://arxiv.org/abs/2502.13179</link>
      <description><![CDATA[ARXIV：2502.13179V1公告类型：新 
摘要：大型语言模型（LLMS）在面对极低位（亚2位）量化时遭受严重的性能降解。几种现有的子2位训练后量化（PTQ）方法通过利用非结构化的细粒面膜来明确区分出色的权重，而引入了每个重量的额外的1位或更多。为了探索PTQ的实际限制，我们提出了一种称为PTQ1.61的极低位PTQ方法，该方法将首次将权重量化为1.61位。具体而言，我们首先基于输入激活，从减少量化误差的上限以将相应的显着权重通道分配到4位的角度，基于输入激活，基于输入激活，基于输入激活，基于输入激活，首先引入一个一维结构化面膜。对于非偏好通道二进制，然后提出了有效的块缩放因子优化框架，以考虑隐式的行相关性和角度偏见。与以前集中于调整量化方法的先前作品不同，我们进一步提出了一种称为量化预处理的新型范式，我们认为在量化之前转换预审计模型的重量分布可以减轻每条通道的难度极低的PTQ。广泛的实验表明我们的PTQ1.61在极低的量化中实现了最先进的性能。代码可从https://github.com/zjq0455/ptq1.61获得。]]></description>
      <guid>https://arxiv.org/abs/2502.13179</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过正交元学习增强的贝叶斯优化的不确定多目标推荐</title>
      <link>https://arxiv.org/abs/2502.13180</link>
      <description><![CDATA[ARXIV：2502.13180V1公告类型：新 
摘要：推荐系统（RSS）在塑造我们的数字互动，影响我们如何访问和与各个领域的信息互动的方式中起着至关重要的作用。传统研究主要集中在最大化建议准确性上，通常会导致意想不到的副作用，例如回声室和受限的用户体验。从自主驾驶中汲取灵感，我们引入了一个新颖的框架，将RS自主权分为五个不同的级别，从基本的基于规则的准确性驱动系统到行为感知，不确定的多目标RSS，用户可能会有不同的需求，例如准确性，多样性和公平性。作为响应，我们提出了一种基于单个用户偏好的多个目标，可以动态识别和优化多个目标，从而促进了更具道德和智能的用户以用户为中心的建议。为了浏览多目标RSS中固有的不确定性，我们开发了一个贝叶斯优化（BO）框架，该框架捕获了不同目标之间的个性化权衡，同时考虑了其不确定的相互依存关系。此外，我们引入了正交元学习范式，以通过在类似任务中利用共同的知识并通过发现正交信息来减轻目标之间的冲突来提高BO效率和有效性。最后，广泛的经验评估证明了我们方法在为单个用户优化不确定的多目标，为更多自适应和以用户为中心的RSS铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.13180</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RINGFORMER：用自适应级信号重新思考反复变压器</title>
      <link>https://arxiv.org/abs/2502.13181</link>
      <description><![CDATA[Arxiv：2502.13181V1公告类型：新 
摘要：变形金刚在有效地处理顺序数据（例如文本）方面取得了巨大成功。它们的结构包括几个关注和前进块可以以并行方式模拟序列元素之间的关系，从而使它们非常有效地训练和有效地进行序列建模。即使它们在处理顺序数据中表现出很强的性能，与其他架构（例如基于RNN和CNN）的模型相比，其参数的大小也大大较大。因此，几种方法探索了变压器模型中的参数共享和复发，以满足其计算需求。但是，与原始变压器模型相比，这种方法难以保持高性能。为了应对这一挑战，我们提出了我们的新方法Ringformer，该方法采用一个变压器层，该层以圆形的，戒指的方式反复处理输入，同时利用低级矩阵来生成输入依赖性级别信号。这使我们能够大大减少模型参数，同时在实验中验证的各种任务（例如翻译和图像分类）中保持高性能。]]></description>
      <guid>https://arxiv.org/abs/2502.13181</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对RL中的SIM到现实方法的调查：基础模型的进度，前景和挑战</title>
      <link>https://arxiv.org/abs/2502.13187</link>
      <description><![CDATA[ARXIV：2502.13187V1公告类型：新 
摘要：深入强化学习（RL）已经过探索和验证，可有效解决各个领域的决策任务，例如机器人技术，运输，推荐系统等。收集的经验。但是，由于现实世界中的数据有限和采取有害行为的难以忍受的后果，RL策略的学习主要受模拟者的限制。这种实践保证了学习的安全性，但在部署方面引入了不可避免的SIM到现实差距，从而导致绩效下降和执行风险。试图通过各种技术从不同领域中解决SIM到现实的问题，尤其是在这个时代，具有新兴技术（例如大型基础或语言模型）在SIM到现实中启用了灯具。据我们所知，这本调查文件是第一个分类法，它正式将SIM到现实技术从马尔可夫决策过程的关键要素（状态，行动，过渡和奖励）中构成。基于框架，我们介绍了从经典方法到最先进的方法，包括基础模型授权的SIM卡至现实技术，我们还讨论了在SIM到现实问题的不同领域中值得关注的专业。然后，我们总结了使用可访问的代码或基准测试的SIM到现实性能的正式评估过程。还提出了挑战和机遇，以鼓励对此方向的未来探索。我们正在积极维护A，以包括最新的SIM到现实研究成果，以帮助研究人员的工作。]]></description>
      <guid>https://arxiv.org/abs/2502.13187</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOBA：长篇文化LLM的阻止注意力的混合</title>
      <link>https://arxiv.org/abs/2502.13189</link>
      <description><![CDATA[ARXIV：2502.13189V1公告类型：新 
摘要：扩展有效上下文长度对于将大型语言模型（LLM）推进到人工通用情报（AGI）至关重要。但是，传统注意力机制固有的计算复杂性的二次增加表现出了一个高度的开销。现有方法要么施加强烈偏见的结构，例如特定于任务的窗口或窗户注意力，要么从根本上将注意力机制修改为线性近似，在复杂的推理任务中的性能仍然不足。
  在这项工作中，我们提出了一种遵守``较少的结构&#39;&#39;原理的解决方案，允许模型确定自主参加的何处，而不是引入预定义的偏见。我们介绍了Block Coation（MOBA）的混合物，这是一种创新的方法，该方法将专家（MOE）的混合原理应用于注意机制。这种新颖的体系结构表明了长期文化任务上的出色性能，同时提供了一个关键优势：能够在全面和稀疏注意力之间无缝过渡，提高效率而不会损害绩效的风险。 MOBA已经被部署以支持Kimi的长篇文章请求，并在LLMS的有效注意计算方面表现出重大进步。我们的代码可在https://github.com/moonshotai/moba上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.13189</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法在温度场重建中的应用</title>
      <link>https://arxiv.org/abs/2502.13190</link>
      <description><![CDATA[Arxiv：2502.13190V1公告类型：新 
摘要：这项研究重点是储层水温的分层模式和动态演变，旨在使用有限和嘈杂的局部测量数据来估计和重建温度场。由于复杂的测量环境和技术局限性，获得储层的完整温度信息是高度挑战的。因此，准确地从少数本地数据点重建温度场已成为一个关键的科学问题。为了解决这个问题，研究采用适当的正交分解（POD）和稀疏表示方法来根据有限数量的局部测量点的温度数据来重建温度场。结果表明，当POD基函数的数量设置为2并且测量点的数量为10时，可以实现令人满意的重建。在不同的水分深度下，POD的重建误差和稀疏表示方法的重建误差保持在0.15左右。 ，完全验证这些方法在基于有限的局部温度数据基于温度场重建温度场中的有效性。此外，该研究进一步探讨了在不同水位间隔下POD和稀疏表示方法的重建误差的分布特征，分析了在这种情况下的最佳测量点布局方案以及重建方法的潜在局限性。这项研究不仅有效地降低了测量成本和计算资源消耗，而且为储层温度分析提供了一种新的技术方法，具有重要的理论和实际重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.13190</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于飙升神经网络的隐私风险：会员推理分析</title>
      <link>https://arxiv.org/abs/2502.13191</link>
      <description><![CDATA[ARXIV：2502.13191V1公告类型：新 
摘要：越来越多地探索了尖峰神经网络（SNN），因为它们在现实世界中的能源效率和稳健性，但它们的隐私风险在很大程度上尚未受到检查。在这项工作中，我们调查了SNN对会员推理攻击（MIA）的敏感性，这是对手试图确定给定样本是否是培训数据集的一部分的主要隐私威胁。虽然先前的工作表明，由于其离散，事件驱动的性质，SNN可能会提供固有的鲁棒性，但我们发现随着潜伏期（t）的增加，其弹性会降低。此外，我们在黑匣子设置下引入了一种输入辍学策略，从而大大提高了SNN的会员推断。我们的发现挑战了SNN本质上更加安全的假设，即使期望它们会更好，我们的结果表明，SNNS表现出与人工神经网络（ANN）同样可比的隐私脆弱性。我们的代码可从https://anonymon.4open.science/r/mia_snn-3610获得。]]></description>
      <guid>https://arxiv.org/abs/2502.13191</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过智能数据质量评估来增强机器学习性能：无监督的以数据为中心的框架</title>
      <link>https://arxiv.org/abs/2502.13198</link>
      <description><![CDATA[ARXIV：2502.13198V1公告类型：新 
摘要：数据质量差会限制机器学习（ML）的优势能力，并削弱了高性能的ML软件系统。如今，由于数量和复杂性的增加，数据更容易容易出现质量差的风险。因此，在ML管道中进一步移动之前，乏味且耗时的工作将用于数据制备和改进。为了应对这一挑战，我们提出了一个以数据为中心的评估框架，该框架可以识别高质量的数据并改善ML系统的性能。提出的框架结合了质量测量和无监督学习的策划，以区分高质量和低质量数据。该框架旨在集成灵活和通用方法，以便将其部署在各种域和应用中。为了验证设计框架的结果，我们在分析化学领域的现实用例中实现了它，在该案例中，在三个抗Sensens寡核苷酸的数据集中对其进行了测试。咨询域专家以确定相关质量测量并评估框架的结果。结果表明，以质量为中心的数据评估框架确定了指导有效的实验室实验进行的高质量数据的特征，从而提高了ML系统的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.13198</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自我监督学习学习与预测世界模型一起探索</title>
      <link>https://arxiv.org/abs/2502.13200</link>
      <description><![CDATA[ARXIV：2502.13200V1公告类型：新 
摘要：自主人造代理必须能够在没有人类设计任务和奖励的复杂环境中学习行为。为每个环境设计这些功能是不可行的，因此激发了内在奖励功能的发展。在本文中，我们建议使用多种认知元素，这些认知因素很长一段时间以内，为内在动机的代理人建立了内部世界模型。我们的代理商对环境进行了令人满意的迭代，学习复杂的行为而无需以前设计的奖励功能。我们使用18个Atari游戏来评估需要反应性和审议行为的游戏中出现的认知技能。我们的结果表明，与许多测试用例中的最先进的奖励相比，表现出色。]]></description>
      <guid>https://arxiv.org/abs/2502.13200</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构象异构质量对分子构象合奏的学说表示的影响</title>
      <link>https://arxiv.org/abs/2502.13220</link>
      <description><![CDATA[ARXIV：2502.13220V1公告类型：新 
摘要：训练机器学习模型预测分子构象异构体的特性，是一种越来越流行的策略，可以加速类似药物样的小分子，反应性有机底物和均匀催化剂的构象分析。尤其是对于高通量分析，训练有素的替代模型可以帮助规避依赖昂贵的构象异构搜索和几何形状优化的传统方法来构象分析。在这里，我们质疑替代模型的性能如何预测3D构象依赖性属性（单个活性构象异构体的）的性能受到用作输入的3D构象异构体的质量的影响。低质量的构象体如何为高质量构象体性质的预测提供了多大的预测？编码随机构象体时，几何优化的保真度是否重要？对于编码一组构象体的模型，如何诱导目标属性的活动构象异构体的存在影响模型的准确性？替代模型的预测与估算廉价合奏本身的属性相比如何？我们在预测用密度功能理论优化的构象合奏的sterimol参数的背景下探讨了这些问题。尽管答案将是特定于案例的，但我们的分析为3D表示模型提供了有价值的观点，并提出了关于构象质量何时重要的实际考虑。]]></description>
      <guid>https://arxiv.org/abs/2502.13220</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>