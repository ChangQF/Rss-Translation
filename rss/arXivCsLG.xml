<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Fri, 17 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>一种用于多组学数据不平衡类别处理和分类的自动编码器和生成对抗网络方法</title>
      <link>https://arxiv.org/abs/2405.09756</link>
      <description><![CDATA[arXiv:2405.09756v1 公告类型：新
摘要：在增强医疗诊断的不懈努力中，最先进的机器学习方法的集成已成为一个有前途的研究领域。在分子生物学领域，多组学测序产生的数据呈爆炸式增长。测序设备的出现可以为每个实验提供大量复杂的测量。因此，传统的统计方法在处理如此高维的数据时面临着挑战性的任务。然而，这些数据集中包含的大多数信息都是冗余或不相关的，并且可以有效地减少到明显更少的变量，而不会丢失太多信息。降维技术是允许这种降维的数学程序；它们主要是通过统计学和机器学习学科开发的。医学数据集中的另一个挑战是类别中样本数量不平衡，这会导致机器学习模型产生有偏差的结果。这项研究的重点是在神经网络中解决这些挑战，该神经网络结合自动编码器来提取特征的潜在空间，并结合生成对抗网络（GAN）来生成合成样本。潜在空间是捕获原始数据的有意义特征的降维空间。我们的模型从特征选择开始，在将它们输入神经网络之前选择判别特征。然后，该模型预测不同数据集的癌症结果。所提出的模型优于其他现有模型，膀胱癌数据集的准确度为 95.09%，乳腺癌数据集的准确度为 88.82%。]]></description>
      <guid>https://arxiv.org/abs/2405.09756</guid>
      <pubDate>Fri, 17 May 2024 06:19:14 GMT</pubDate>
    </item>
    <item>
      <title>非平滑非凸优化的随机缩放和动量</title>
      <link>https://arxiv.org/abs/2405.09742</link>
      <description><![CDATA[arXiv:2405.09742v1 公告类型：新
摘要：训练神经网络需要优化可能高度不规则的损失函数，特别是既不是凸函数也不是平滑函数。流行的训练算法基于动量随机梯度下降（SGDM），经典分析仅适用于损失是凸的或平滑的。我们证明，对 SGDM 的一个非常小的修改可以弥补这一差距：只需通过指数分布的随机标量来缩放每个时间点的更新。由此产生的算法实现了最佳收敛保证。有趣的是，这个结果并不是通过对 SGDM 的具体分析得出的：相反，它自然地脱离了将在线凸优化算法转换为非凸优化算法的更通用的框架。]]></description>
      <guid>https://arxiv.org/abs/2405.09742</guid>
      <pubDate>Fri, 17 May 2024 06:19:13 GMT</pubDate>
    </item>
    <item>
      <title>广义全息简化表示</title>
      <link>https://arxiv.org/abs/2405.09689</link>
      <description><![CDATA[arXiv:2405.09689v1 公告类型：新
摘要：深度学习近年来取得了令人瞩目的成功。其成功的核心是其学习保留任务相关结构的表示的能力。然而，学习一般表示需要大量的能源、计算和数据成本。本文探讨了超维计算（HDC），这是一种计算效率高、数据效率高、受大脑启发的替代方案。 HDC 充当人工智能 (AI) 联结主义和符号方法之间的桥梁，允许像符号方法一样明确指定表征结构，同时保留联结主义方法的灵活性。然而，HDC 的简单性给复杂的组合结构编码带来了挑战，特别是在其绑定操作中。为了解决这个问题，我们提出了广义全息简化表示（GHRR），它是傅立叶全息简化表示（FHRR）的扩展，是一种特定的 HDC 实现。 GHRR 引入了灵活的、非交换的绑定操作，能够改进复杂数据结构的编码，同时保留 HDC 所需的鲁棒性和透明度属性。在这项工作中，我们介绍了 GHRR 框架，证明了其理论特性及其对 HDC 特性的遵守，探索了其内核和绑定特性，并进行了实证实验，展示了其灵活的非交换性、增强的组合结构解码精度以及提高的记忆能力与胎心率相比。]]></description>
      <guid>https://arxiv.org/abs/2405.09689</guid>
      <pubDate>Fri, 17 May 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>通过不确定性量化改进标签错误检测和消除</title>
      <link>https://arxiv.org/abs/2405.09602</link>
      <description><![CDATA[arXiv:2405.09602v1 公告类型：新
摘要：识别和处理标签错误可以显着提高监督机器学习模型的准确性。最近用于识别标签错误的方法表明，模型对某个标签的低自信代表了错误标签的良好指标。然而，最新的工作是建立在 softmax 概率的基础上来衡量自信心的。在本文中，我们认为，由于 softmax 概率不能准确反映模型的预测不确定性，标签错误检测需要对模型不确定性进行更复杂的测量。因此，我们开发了一系列新颖的、与模型无关的算法，用于基于不确定性量化的标签错误检测（UQ-LED），该算法结合了置信学习（CL）、蒙特卡洛辍学（MCD）、模型不确定性测量（例如， 、熵）和集成学习以增强标签错误检测。我们分两个阶段在四个图像分类基准数据集上全面评估我们的算法。在第一阶段，我们证明我们的 UQ-LED 算法在识别标签错误方面优于最先进的置信学习。在第二阶段，我们表明，根据我们的方法从训练数据中删除所有已识别的错误，比对所有可用标记数据进行训练的准确性更高。重要的是，除了我们对标签错误检测的贡献之外，我们还特别提出了一种新颖的方法来综合生成真实的、依赖于类的标签错误。总体而言，我们的研究表明，与使用更大、噪声更大的数据集相比，使用 UQ-LED 算法选择性清理数据集可以实现更准确的分类。]]></description>
      <guid>https://arxiv.org/abs/2405.09602</guid>
      <pubDate>Fri, 17 May 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>LoRA 学到的东西更少，忘记的东西也更少</title>
      <link>https://arxiv.org/abs/2405.09673</link>
      <description><![CDATA[arXiv:2405.09673v1 公告类型：新
摘要：低秩适应（LoRA）是一种广泛用于大型语言模型的参数高效微调方法。 LoRA 通过仅训练对选定权重矩阵的低秩扰动来节省内存。在这项工作中，我们比较了 LoRA 和完全微调在两个目标领域（编程和数学）上的性能。我们考虑指令微调（$\approx$100K 提示响应对）和持续预训练（$\approx$10B 非结构化令牌）数据机制。我们的结果表明，在大多数设置中，LoRA 的性能明显低于完全微调。尽管如此，LoRA 展现了一种理想的正则化形式：它更好地保持了基础模型在目标域之外的任务上的性能。我们证明，与权重衰减和 dropout 等常用技术相比，LoRA 提供了更强的正则化能力；它还有助于维持更多样化的世代。我们表明，完全微调学习的扰动等级比典型 LoRA 配置高 10-100 倍，这可能解释了一些报告的差距。最后，我们提出了 LoRA 微调的最佳实践。]]></description>
      <guid>https://arxiv.org/abs/2405.09673</guid>
      <pubDate>Fri, 17 May 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>允许或禁止量化网络中对抗性攻击可转移的属性</title>
      <link>https://arxiv.org/abs/2405.09598</link>
      <description><![CDATA[arXiv:2405.09598v1 公告类型：新
摘要：众所周知，深度神经网络 (DNN) 容易受到对抗性示例的攻击。此外，这些对抗性示例被发现可以从它们被制作的源网络转移到黑盒目标网络。随着在嵌入式设备上使用深度学习的趋势日益增长，研究对抗性示例在压缩网络中的可转移性变得至关重要。在本文中，我们将量化视为一种网络压缩技术，并评估当源网络和目标网络以不同的位宽量化时基于转移的攻击的性能。我们通过考虑各种对抗性示例生成算法来探索算法特定属性如何影响可转移性。此外，我们在更现实的场景中检查可转移性，其中源网络和目标网络在位宽和其他与模型相关的属性（如容量和架构）方面可能有所不同。我们发现，尽管量化降低了可转移性，但某些攻击类型表现出增强可转移性的能力。此外，网络量化版本之间的对抗性示例的平均可转移性可用于估计具有不同容量和架构的量化目标网络的可转移性。]]></description>
      <guid>https://arxiv.org/abs/2405.09598</guid>
      <pubDate>Fri, 17 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>预测模型可重用性的聚合表示测量</title>
      <link>https://arxiv.org/abs/2405.09600</link>
      <description><![CDATA[arXiv:2405.09600v1 公告类型：新
摘要：在本文中，我们提出了一个预测量化器来估计分布变化中训练模型的再训练成本。所提出的聚合表示度量 (ARM) 量化了模型表示从旧数据分布到新数据分布的变化。在实际重新训练模型之前，它提供了重新训练所需的资源（时代、能源和碳排放）的单一简明索引。这使得重复使用模型的成本比从头开始训练新模型低得多。实验结果表明，ARM 合理地预测了不同噪声强度的再训练成本，并能够在多个模型架构之间进行比较，以确定最具成本效益和可持续性的选项。]]></description>
      <guid>https://arxiv.org/abs/2405.09600</guid>
      <pubDate>Fri, 17 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能吞噬自己时：关于生成式人工智能时代数据污染的警告</title>
      <link>https://arxiv.org/abs/2405.09597</link>
      <description><![CDATA[arXiv:2405.09597v1 公告类型：新
摘要：生成人工智能 (AI) 技术和大型模型正在跨多个领域产生真实的输出，例如图像、文本、语音和音乐。创建这些高级生成模型需要大量资源，特别是大型且高质量的数据集。为了最大限度地减少培训费用，许多算法开发人员使用模型本身创建的数据作为具有成本效益的培训解决方案。然而，并非所有合成数据都能有效提高模型性能，因此需要在使用真实数据与合成数据来优化结果方面保持战略平衡。
  目前，以前良好控制的真实数据和合成数据的集成正在变得不可控。合成数据在网上广泛且不受监管的传播导致传统上通过网络抓取编制的数据集受到污染，现在与未标记的合成数据混合在一起。这一趋势预示着未来生成式人工智能系统可能会越来越盲目地依赖消耗自我生成的数据，引发人们对模型性能和道德问题的担忧。如果生成式人工智能在没有洞察力的情况下不断消耗自己，会发生什么？我们可以采取哪些措施来减轻潜在的不利影响？
  关于生成人工智能中合成数据使用的影响，特别是在多模态信息的融合方面，科学文献中存在显着的差距。为了弥补这一研究空白，本综述调查了盲目整合合成数据对图像和文本模式的生成人工智能训练的后果，并探讨了减轻这些影响的策略。其目标是全面了解合成数据的作用，倡导平衡的使用方法，并探索在大模型时代促进生成人工智能技术可持续发展的实践。]]></description>
      <guid>https://arxiv.org/abs/2405.09597</guid>
      <pubDate>Fri, 17 May 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>数据增强的综合概述</title>
      <link>https://arxiv.org/abs/2405.09591</link>
      <description><![CDATA[arXiv:2405.09591v1 公告类型：新
摘要：数据增强是一系列通过操纵现有数据样本生成高质量人工数据的技术。通过利用数据增强技术，人工智能模型可以显着提高涉及稀缺或不平衡数据集的任务的适用性，从而大幅增强人工智能模型的泛化能力。现有文献调查仅关注某类特定模态数据，并从特定模态和以操作为中心的角度对这些方法进行分类，缺乏对跨多种模态的数据增强方法的一致总结，限制了对现有数据样本如何服务的理解数据增强过程。为了弥补这一差距，我们提出了一种更具启发性的分类法，其中包含针对不同常见数据模式的数据增强技术。具体来说，从以数据为中心的角度来看，本次调查通过研究如何利用数据样本之间的内在关系，提出了一种独立于模态的分类法，包括单样本、成对样本和总体样本数据增强方法。此外，我们通过统一的归纳方法对五种数据模式的数据增强方法进行分类。]]></description>
      <guid>https://arxiv.org/abs/2405.09591</guid>
      <pubDate>Fri, 17 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>时空数据挖掘生成技术综述</title>
      <link>https://arxiv.org/abs/2405.09592</link>
      <description><![CDATA[arXiv:2405.09592v1 公告类型：新
摘要：考虑到时空数据的显着增长和多样性，本文重点关注将生成技术集成到时空数据挖掘中。随着 RNN、CNN 和其他非生成技术的进步，研究人员已经探索了它们在捕获时空数据中的时间和空间依赖性方面的应用。然而，LLM、SSL、Seq2Seq 和扩散模型等生成技术的出现为进一步增强时空数据挖掘开辟了新的可能性。本文对基于生成技术的时空方法进行了全面分析，并介绍了专门为时空数据挖掘管道设计的标准化框架。通过利用生成技术对时空方法进行详细的回顾和新颖的分类，本文使人们能够更深入地了解该领域使用的各种技术。此外，论文还强调了未来有前景的研究方向，敦促研究人员更深入地研究时空数据挖掘。它强调需要探索未开发的机会并突破知识的边界，以释放新的见解并提高时空数据挖掘的有效性和效率。通过整合生成技术并提供标准化框架，本文有助于推动该领域的发展，并鼓励研究人员探索生成技术在时空数据挖掘中的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.09592</guid>
      <pubDate>Fri, 17 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>通过 H3 指数和因果语言模型 (CLM) 增强海洋轨迹预测</title>
      <link>https://arxiv.org/abs/2405.09596</link>
      <description><![CDATA[arXiv:2405.09596v1 公告类型：新
摘要：船舶轨迹预测是人工智能中一个不断发展的研究领域。传统方法依赖于使用 LSTM、GRU 网络，甚至 Transformer 架构来预测时空序列。这项研究提出了一种仅使用 GNSS 位置来预测这些轨迹的可行替代方案。它将这种时空问题视为自然语言处理问题。 AIS 消息的纬度/经度坐标使用 H3 索引转换为小区标识符。由于伪八进制表示，语言模型更容易学习 H3 索引的空间层次结构。该方法与海事领域广泛使用的经典卡尔曼滤波器进行比较，并引入Fr\&#39;echet距离作为主要评价指标。我们证明，利用 30 分钟的背景信息可以在长达 8 小时内非常精确地预测船舶轨迹。我们证明这种替代方案足以预测全球轨迹。]]></description>
      <guid>https://arxiv.org/abs/2405.09596</guid>
      <pubDate>Fri, 17 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>一种增强 Transformer 在作物育种基因组选择中性能的极其简单的方法</title>
      <link>https://arxiv.org/abs/2405.09585</link>
      <description><![CDATA[arXiv:2405.09585v1 公告类型：新
摘要：基因组选择（GS）作为重要的作物育种策略，在提高粮食产量和解决全球饥饿危机方面发挥着关键作用。目前 GS 的主要方法是采用统计方法进行预测。然而，统计方法通常有两个主要局限性：强统计先验和线性假设。最近的趋势是通过深度学习捕获标记之间的非线性关系。然而，由于作物数据集通常是样本有限的长序列，深度学习模型（尤其是 Transformer）的鲁棒性仍然是一个挑战。在这项工作中，为了释放注意力机制对感兴趣的任务的未开发潜力，我们提出了一个简单而有效的基于 Transformer 的框架，可以实现整个序列的端到端训练。通过在ice3k和wheat3k数据集上的实验，我们表明，通过k-mer标记化和随机掩码等简单技巧，Transformer可以在感兴趣的GS任务上实现相对于开创性方法的整体优越性能。]]></description>
      <guid>https://arxiv.org/abs/2405.09585</guid>
      <pubDate>Fri, 17 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>揭示文本、图像、视频和音频基础模型中的幻觉：全面回顾</title>
      <link>https://arxiv.org/abs/2405.09589</link>
      <description><![CDATA[arXiv:2405.09589v1 公告类型：新
摘要：基础模型（FM）在语言、图像、音频和视频领域的快速发展在各种任务中表现出了卓越的能力。然而，FM 的激增带来了一个严峻的挑战：有可能产生幻觉输出，特别是在高风险应用中。基础模型产生幻觉内容的倾向可以说是其在现实场景中广泛采用的最大障碍，特别是在可靠性和准确性至关重要的领域。这份调查报告全面概述了最新的进展，旨在识别和减轻 FM 中的幻觉问题，涵盖文本、图像、视频和音频模式。通过综合各种方式检测和减轻幻觉的最新进展，本文旨在为研究人员、开发人员和从业者提供有价值的见解。从本质上讲，它建立了一个清晰的框架，包括定义、分类和检测策略，用于解决多模态基础模型中的幻觉问题，为这一关键领域的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2405.09589</guid>
      <pubDate>Fri, 17 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>用于模型发现的可扩展稀疏回归：洞察的快车道</title>
      <link>https://arxiv.org/abs/2405.09579</link>
      <description><![CDATA[arXiv:2405.09579v1 公告类型：新
摘要：存在着无数具有大量可用数据和不令人满意的数学描述的动力系统的例子。应用于符号库的稀疏回归已迅速成为直接从数据学习控制方程的强大工具；这些学习的方程平衡了定量准确性与定性简单性和人类可解释性。在这里，我提出了一种通用的、与模型无关的稀疏回归算法，该算法利用迭代奇异值分解 (SVD) 扩展了最近提出的穷举搜索。这种加速方案，即用于快速识别空向量的可扩展修剪（SPRINT），使用具有分析边界的二分法来快速识别对空向量的最佳Rank-1修改。它的目的是保持对小系数的敏感性，并为大型符号库提供合理的计算成本。这项计算需要通过详尽的搜索来计算宇宙的年龄，但通过 SPRINT 可以在一天内完成。]]></description>
      <guid>https://arxiv.org/abs/2405.09579</guid>
      <pubDate>Fri, 17 May 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>隐藏神经元激活标签的误差幅度分析</title>
      <link>https://arxiv.org/abs/2405.09580</link>
      <description><![CDATA[arXiv:2405.09580v1 公告类型：新
摘要：理解人工神经网络中如何表示高级概念是人工智能领域的一个基本挑战。虽然可解释人工智能的现有文献强调用概念标记神经元以了解其功能的重要性，但它们主要关注于识别在大多数情况下什么刺激激活神经元，这对应于信息检索中的回忆概念。我们认为这只是两部分工作的第一部分，还必须研究神经元对其他刺激的反应，即它们的精度。我们称之为神经元标签误差幅度。]]></description>
      <guid>https://arxiv.org/abs/2405.09580</guid>
      <pubDate>Fri, 17 May 2024 06:19:06 GMT</pubDate>
    </item>
    </channel>
</rss>