<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>更大或较小的奖励利润率以选择对齐的偏好？</title>
      <link>https://arxiv.org/abs/2503.01864</link>
      <description><![CDATA[ARXIV：2503.01864V1公告类型：新 
摘要：偏好学习对于使大语言模型（LLM）与人类价值观保持一致至关重要，而偏好数据集的质量在此过程中起着至关重要的作用。尽管现有指标主要基于明确或隐式奖励利润率评估数据质量，但它们通常会为相同数据提供矛盾的评估。为了解决这个问题，我们介绍了对齐电位指标，该指标将差距从模型当前的隐式奖励利润率到目标显式奖励余量，从而估计该模型与偏好数据保持一致的潜力。经验结果表明，该指标选择的数据培训一致地增强了对齐性能，超过了不同基本模型和优化目标的现有指标。此外，我们的方法扩展到自我播放的数据生成框架，该框架用于识别LLMS中自生成内容中的高质量数据。在此数据生成方案下，我们的方法超过了各种培训环境中当前的最新结果（SOTA）结果，并证明随着数据集大小和训练迭代的增加，对齐性能的持续改进。]]></description>
      <guid>https://arxiv.org/abs/2503.01864</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指导不强迫：通过消除多余的约束来增强对LLM的越狱攻击的可转移性</title>
      <link>https://arxiv.org/abs/2503.01865</link>
      <description><![CDATA[ARXIV：2503.01865V1公告类型：新 
摘要：越狱攻击可以有效地引起大语言模型（LLMS）的不安全行为；但是，这些攻击在不同模型中的可传递性仍然有限。这项研究旨在了解和增强基于梯度的越狱方法的可传递性，这是攻击白盒模型的标准方法之一。通过对优化过程的详细分析，我们引入了一个新颖的概念框架，以阐明可转移性并特定于多余的约束，响应模式约束和令牌尾巴约束 - 作为改善可传递性的重要障碍。消除这些不必要的约束基本上增强了基于梯度的攻击的可转移性和可控性。我们的方法在Llama-3-8b-Instruct作为源模型中评估，在一组目标模型中提高了总体转移攻击成功率（T-ASR），其安全水平从18.4％到50.3％，同时也提高了源模型和目标模型上越狱行为的稳定性和可控性。]]></description>
      <guid>https://arxiv.org/abs/2503.01865</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>卷积多杂交语言模型的系统和算法大规模</title>
      <link>https://arxiv.org/abs/2503.01868</link>
      <description><![CDATA[ARXIV：2503.01868V1公告类型：新 
摘要：我们介绍了卷积多杂交结构，其设计基于两个简单的观测值。首先，混合模型中的运营商可以根据象征性的操纵任务进行量身定制，例如内在召回，多言式召回和压缩，并具有输入依赖性的卷积和提供互补性能的注意力。其次，共同设计的卷积操作员和硬件感知算法可以在以前的替代体系结构难以超越变形金刚的政权中提高效率。在400亿个参数量表上，我们端到端1.2至2.9倍的速度比优化的变压器快1.2倍，比上一代混合动力车快1.1至1.4倍。在H100 GPU和模型宽度4096上，提议的多杂交条纹2架构中的单个操作员比线性注意和状态空间模型实现了两倍的吞吐量改进。如EVO 2线模型所证明的那样，多杂交在序列建模上表现出色。我们讨论了启用这些结果的基础，包括体系结构设计，重叠量阻止了张量核心的内核，以及专门的全部和所有点对点上下文的平行策略。]]></description>
      <guid>https://arxiv.org/abs/2503.01868</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过轨迹分割的策略遵循指令的数据增强</title>
      <link>https://arxiv.org/abs/2503.01871</link>
      <description><![CDATA[ARXIV：2503.01871V1公告类型：新 
摘要：在机器人技术或游戏中，可伸缩代理的可伸缩性通常受到有限的数据与代理轨迹配对的有限数据。但是，通常可以使用大型未经注释的轨迹数据集，这些轨迹含有各种代理行为（游戏轨迹）的序列。在半监督的设置中，我们探索了从游戏轨迹中提取标记段的方法。目的是增加指令 - 横向对象对的小注释数据集，以提高通过模仿学习训练下游训练的指令跟随策略的性能。假设段长度几乎没有变化，最近的视频分割方法可以有效提取标记的段。为了解决段长度的约束，我们提出了播放分段（PS），这是一个概率模型，可以找到最大的扩展子细分段的细分，而仅对单个教学段进行培训。我们在游戏环境和模拟机器人抓手设置中的结果强调了细分的重要性；随机抽样的细分市场降低了性能，同时结合了PS的标签段，将政策绩效提高到对标记数据量的两倍培训的政策水平。]]></description>
      <guid>https://arxiv.org/abs/2503.01871</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FAIRGEN：通过自适应潜在指导在扩散模型中控制一代人的敏感属性</title>
      <link>https://arxiv.org/abs/2503.01872</link>
      <description><![CDATA[ARXIV：2503.01872V1公告类型：新 
摘要：文本到图像扩散模型通常会对特定的人口组显示出偏见，例如，当提示产生工程师的图像，提出道德问题并限制其采用时，产生比女性更多的男性。在本文中，我们应对在扩散模型中减轻任何目标属性值（例如“男性”）的挑战，同时保留发电质量。我们提出了Fairgen，这是一种自适应潜在的指导机制，可以控制推理过程中的发电分布。在Fairgen中，潜在的指导模块动态调整了扩散过程以执行特定属性，而内存模块则跟踪生成统计信息并引导潜在的指导，以与属性值的目标公平分布保持一致。此外，鉴于现有数据集在扩散模型中全面评估偏见中的局限性，我们引入了整体偏见评估基准HBE，涵盖了各种域，并在各种应用程序中结合了复杂的提示。对HBE和稳定偏置数据集的广泛评估表明，Fairgen的表现优于现有的缓解方法，从而实现了大幅度的偏差降低（例如，稳定扩散2的68.5％性别偏差减少2）。消融研究突出了费尔根（Fairgen）在任何用户指定的粒度上灵活，精确地控制发电分布的能力，从而确保适应性和有针对性的偏差缓解。]]></description>
      <guid>https://arxiv.org/abs/2503.01872</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线伪平均转移注意力（PASA）用于鲁棒的低精度LLM推断：算法和数值分析</title>
      <link>https://arxiv.org/abs/2503.01873</link>
      <description><![CDATA[ARXIV：2503.01873V1公告类型：新 
摘要：对于长期推断任务（例如文本或图像/视频生成），注意力计算非常耗时。为了加速这一过程，我们基于闪光的注意，开发了一种低精确的数学等效算法，称为PASA。 PASA介绍了两种新颖的技术：在线伪平均转移和全球恢复。这些技术可以在整个闪光注意过程中使用半精度计算，而不会产生溢出不稳定性或不可接受的数值精度损失。该算法通过减少数据移动和增加计算拖船来提高内存限制的AI硬件架构（例如上升神经网络处理单元（NPU））的性能。使用设计的随机基准和真实的大型模型对该算法进行验证。我们发现，注意力输入数据的巨大偏见和幅度是两个不同类别的大型模型（QWEN2-7B语言模型和稳定的Video-Diffusion Multioododal模型）的数值溢出（$&gt; 65504 $）的关键因素。具体而言，由于序列维度的偏差以及查询和键之间的共振机理的偏差很大，因此溢出是溢出的。共振机制定义为相巧合或查询和键矩阵之间的180度相位移位。它将显着扩大注意力评分矩阵的元素值。此问题也适用于QWEN模型。此外，通过均方根误差（RMSE）以及将最终生成的文本和视频与使用高精度关注的最终生成的文本和视频进行比较来评估数值精度。]]></description>
      <guid>https://arxiv.org/abs/2503.01873</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>出租车：冲突意识和平衡的稀疏，以增强模型合并</title>
      <link>https://arxiv.org/abs/2503.01874</link>
      <description><![CDATA[ARXIV：2503.01874V1公告类型：新 
摘要：基于任务向量的模型合并，即微调模型与共享基础模型之间的参数差异，提供了一种有效的方法，可以将多个特定于任务的模型集成到而无需重新培训的多任务模型中。最近的著作努力解决任务向量之间的冲突，这是模型合并，通过稀疏所面临的重大挑战之一。但是，两个问题大大限制了其性能：高参数重叠和不平衡的重量分布。为了解决这些问题，我们提出了一个简单而有效的框架，称为CAB（冲突意识和平衡的稀疏），包括冲突意识的稀疏（CA）和平衡的稀疏（BS）。 CA可以通过在顺序修剪过程中施加掩码来减少参数重叠，从而确保每个任务向量都保留不同的非重叠参数。 BS利用$ n $：$ m $修剪来保留关键权重的同时保持均匀分布的分配。我们的全面实验表明，驾驶室的表现优于各种任务和模型尺寸的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2503.01874</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性是免费的：通过扩散模型的人类在环境政策</title>
      <link>https://arxiv.org/abs/2503.01876</link>
      <description><![CDATA[ARXIV：2503.01876V1公告类型：新 
摘要：作为半自治的范式，人类的机器人部署在学术界和行业中都引起了人们的关注，使人类操作员能够在部署时间进行干预和调整机器人行为，从而提高成功率。但是，在部署大量机器人时，持续的人类监测和干预可能是高度劳动密集型和不切实际的。为了解决这一局限性，我们提出了一种允许扩散政策只能在必要时积极寻求人类援助的方法，从而减少对不断的人类监督的依赖。为了实现这一目标，我们利用扩散政策的生成过程来计算基于不确定性的度量，自主代理可以决定在部署时间请求操作员帮助，而无需在培训期间进行任何操作员交互。此外，我们表明，可以使用相同的方法来收集微调扩散策略，以提高其自主性能。模拟和现实世界环境的实验结果表明，我们的方法可以在各种情况下的部署过程中提高政策绩效。]]></description>
      <guid>https://arxiv.org/abs/2503.01876</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Starjob：针对LLM驱动的车间计划的数据集计划</title>
      <link>https://arxiv.org/abs/2503.01877</link>
      <description><![CDATA[ARXIV：2503.01877V1公告类型：新 
摘要：大型语言模型（LLMS）在各个领域显示出了显着的功能，但是它们解决组合优化问题的潜力仍然在很大程度上没有探索。在本文中，我们调查了LLMS对车间调度问题（JSSP）的适用性，这是组合优化的经典挑战，需要有效的工作分配给机器，以最大程度地减少MakePan。为此，我们介绍了第一个用于JSSP的监督数据集Starjob，该数据集由专门设计用于培训LLM的130K实例。利用此数据集，我们使用LORA方法微调Llama 8B 4位量化模型，以开发端到端的调度方法。我们对标准基准测试的评估表明，提出的基于LLM的方法不仅超过了传统的优先派遣规则（PDR），而且还可以取得明显的改善，而不是L2D（如L2D）的最先进的神经方法，平均提高了DMU的15.36％，而Taillard Benchmarks上的DMU为7.85％。这些结果凸显了LLM在解决组合优化问题方面尚未开发的潜力，为该领域的未来进步铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.01877</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习方法为城市规划师使用机器学习方法的区域索引</title>
      <link>https://arxiv.org/abs/2503.01878</link>
      <description><![CDATA[ARXIV：2503.01878V1公告类型：新 
摘要：城市领导人面临有关预算分配和投资优先事项的关键决定。他们如何确定哪些城市地区需要振兴？为了应对这一挑战，提出了当前的活力指数和长期活力指数。这些索引基于经过精心策划的一组指标。使用K-Nearest Neighbors插补丢失数据，而随机森林被用来识别最可靠和最重要的特征。此外，K-均值聚类用于生成有意义的数据分组，以增强对长期活力的监测。当前的活力通过交互式图可视化，而长期活力则在15年内通过使用多层感知器或线性回归进行预测。被城市规划师批准的结果已经很有希望和乐于助人，并且随着更多数据的可用性而有可能进一步改进。本文提出了利用机器学习方法来优化城市规划并增强公民的生活质量。]]></description>
      <guid>https://arxiv.org/abs/2503.01878</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语义对齐方式绘制增强式学习的映射表示</title>
      <link>https://arxiv.org/abs/2503.01881</link>
      <description><![CDATA[ARXIV：2503.01881V1公告类型：新 
摘要：深度强化学习（RL）模型通常在环境观察或任务要求中甚至发生小变化时也无法推广。解决这些转变通常需要昂贵的重新训练，从而限制了学习政策的可重复性。在本文中，我们以语义一致性的最新工作为基础，提出了一种零摄像方法，用于在不同的视觉和任务变化的不同代理之间绘制潜在空间之间的映射。具体来说，我们学习了一种转换，该转换将嵌入从一个代理的编码器映射到另一个代理商的编码器，而无需进行进一步的微调。我们的方法依赖于一系列具有语义对齐的“锚”观测值，我们用来估计仿射或正交变换。找到转换后，对一个域进行训练的现有控制器可以以零拍的方式从其他（现有）编码器中解释嵌入，从而跳过了其他培训。我们从经验上证明，我们的框架在视觉和任务域的变化下保留了高性能。我们从经验上证明了随着背景和任务的变化，在载载环境上零射击性能。通过允许对现有策略的模块化重新组装，它为在动态变化的环境中为更健壮的组成RL铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.01881</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建平衡数据集，以预测地震危害下结构系统中的故障模式</title>
      <link>https://arxiv.org/abs/2503.01882</link>
      <description><![CDATA[ARXIV：2503.01882V1公告类型：新 
摘要：在地震激发下对结构性故障模式的准确预测对于地震风险和弹性评估至关重要。传统的基于模拟的方法通常会导致以非失败或经常观察到的故障场景为主的不平衡数据集，从而限制了基于机器学习的预测的有效性。为了应对这一挑战，本研究提出了一个构建平衡数据集的框架，其中包括不同的故障模式。该框架由三个关键步骤组成。首先，确定临界地面运动特征（GMF）以有效地表示地面运动时间历史。其次，采用自适应算法来估计关键GMF和结构参数空间中各种故障域的概率密度。第三，通过使用缩放因子优化过程将这些概率密度产生的样品转化为地面运动时间历史。平衡数据集是通过对具有与生成样本相匹配的参数进行非线性响应历史记录分析来构建的，并受到相应的转换的地面运动时间历史。深度神经网络模型接受了平衡和不平衡数据集的培训，以突出数据集平衡的重要性。为了进一步评估该框架的适用性，使用受记录和合成地面运动的两个不同的结构模型进行了数值研究。结果证明了该框架在解决数据集不平衡和在地震故障模式预测中提高机器学习性能方面的鲁棒性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.01882</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过梯度匹配学习脱机黑盒优化的替代物</title>
      <link>https://arxiv.org/abs/2503.01883</link>
      <description><![CDATA[ARXIV：2503.01883V1公告类型：新 
摘要：脱机设计优化问题出现在许多科学和工程应用中，包括材料和化学设计，在此昂贵的在线实验需要在硅替代功能中使用用于预测和最大化候选人设计目标目标。尽管可以从离线数据中学到这些替代物，但它们的预测通常在离线数据制度之外不准确。这项挑战提出了一个基本问题，即不完善的替代模型对其Optima和真正的Optima之间的性能差距的影响以及在多大程度上可以减轻绩效损失。尽管先前的工作开发了改善替代模型及其相关优化过程的鲁棒性的方法，但是不完美的替代物与相应的性能差距以及先前的方法是否直接解决它之间的可证明可量化的关系仍然难以捉摸。为了阐明这个重要的问题，我们提出了一个理论框架，以根据替代物与强调离线数据的潜在梯度字段的匹配程度来明确界定优化质量，以理解离线黑框优化。受我们的理论分析的启发，我们提出了一种有原则的黑框梯度匹配算法，以创建有效的替代模型以进行离线优化，从而改善了各种现实世界基准的先前方法。]]></description>
      <guid>https://arxiv.org/abs/2503.01883</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>股票价格预测的上下文量子神经网络</title>
      <link>https://arxiv.org/abs/2503.01884</link>
      <description><![CDATA[ARXIV：2503.01884V1公告类型：新 
摘要：在本文中，我们使用量子机学习（QML）使用上下文量子神经网络来预测多个资产的股票价格。我们的方法捕获了最新趋势，以预测未来的股票价格分布，超越了关注整个历史数据的传统模型，从而增强了适应性和精度。利用量子叠加的原理，我们引入了一种称为量子批次梯度更新（QBGU）的新训练技术，该技术在量子应用中加速了标准随机梯度下降（SGD）并改善收敛性。因此，我们提出了一个量子多任务学习（QMTL）体系结构，特别是共享和指定的ANSATZ，该体系结构集成了由量子标签控制的特定于任务的操作员，从而使在同一量子电路上对多个资产的同时培训有效地培训，并使有效的投资组件与众多代码互不达相处。该体系结构代表了量子融资中的第一个，为多资产股价预测提供了出色的预测能力和计算效率。通过对Apple，Google，Microsoft和Amazon Stocks的S \＆amp; P 500数据进行广泛的实验，我们证明了我们的方法不仅超过了量子单任务（QSTL）模型（QSTL）模型，还可以有效捕获资产间的相关性，从而实现增强的预测准确性。我们的发现突出了QML在财务应用中的变革潜力，为股票价格预测和其他复杂的财务建模任务中更高级，资源有效的量子算法铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.01884</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习政策委员会在具有多种任务的MDP中有效个性化</title>
      <link>https://arxiv.org/abs/2503.01885</link>
      <description><![CDATA[ARXIV：2503.01885V1公告类型：新 
摘要：许多动态决策问题，例如机器人控制，都涉及一系列任务，其中许多任务在训练时未知。这些问题的典型方法，例如多任务和元加强学习，当任务多样化时，并不能很好地概括。另一方面，旨在解决任务多样性的方法，例如使用任务嵌入为政策上下文和任务聚类，通常缺乏绩效保证，并且需要大量的培训任务。为了应对这些挑战，我们提出了一种学习一种新方法来学习一个政策委员会，其中包括至少一个近乎最佳的政策，对于执行过程中遇到的任务很有可能。虽然我们表明这个问题通常是不易于的，但我们提出了两种实用的算法解决方案。当任务是低维时（由于不Xibibibibibility而我们可以做的最好的）时，第一个产量可证明的近似值和任务样本的复杂性保证，而第二种是基于一般和实用的基于梯度的方法。此外，我们还提供了可证明的样本复杂性，用于几次学习。我们在Mujoco和Meta-World上的实验表明，所提出的方法在训练，概括和几乎没有成功的学习中的最先进的多任务，元和任务群集基准通常是很大的利润。]]></description>
      <guid>https://arxiv.org/abs/2503.01885</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>