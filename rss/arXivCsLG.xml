<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 20 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>新西兰温室气体清单动态即时预报</title>
      <link>https://arxiv.org/abs/2402.11107</link>
      <description><![CDATA[arXiv:2402.11107v1 公告类型：新
摘要：随着减轻气候变化影响的努力不断增加，可靠、全面的温室气体排放报告对于衡量国际和国内减排目标的进展至关重要。目前新西兰国家排放清单报告已经过时 15 至 27 个月。我们在国家排放清单发布之前提出了一种机器学习方法，用于实时预测（动态估计）新西兰的国家温室气体排放量，由于当前数据的可用性，仅存在两个月的延迟。主要调查结果包括自 2020 年以来（截至 2022 年 7 月）全国总排放量预计减少 0.2%。我们的研究强调了排放密集型活动动态视图的预测能力。该方法证明了机器学习方法可以以相对较低的误差对各部门的国家温室气体排放量进行亚年度估计，这对政策制定者可能有价值。]]></description>
      <guid>https://arxiv.org/abs/2402.11107</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>私人 PAC 学习可能比在线学习更难</title>
      <link>https://arxiv.org/abs/2402.11119</link>
      <description><![CDATA[arXiv:2402.11119v1 公告类型：新
摘要：我们继续研究差分隐私 PAC 学习的计算复杂性以及它如何位于机器学习的基础中。最近的一系列工作揭示了私有 PAC 模型和 Littlestone 在线学习的错误边界模型之间的定性等价性，特别是表明 Littlestone 维度 $d$ 的任何概念类都可以使用 $\mathrm{poly} 进行私有 PAC 学习(d)$ 样品。这就提出了一个自然的问题：是否可能存在从在线学习者到私人 PAC 学习者的通用转换，同时也保留了计算效率。
  我们在合理的密码学假设下对这个问题给出否定的答案（粗略地说，可以为所有电路构建不可区分的混淆）。我们展示了一个概念类，它允许在线学习器在多项式时间内运行并具有多项式错误界限，但对于该学习器不存在计算效率高的差分私有 PAC 学习器。我们的构建和分析加强并概括了 Bun 和 Zhandry (TCC 2016-A) 的构建和分析，他们在私人和非私人 PAC 学习者之间建立了这种分离。]]></description>
      <guid>https://arxiv.org/abs/2402.11119</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过纯微调进行模型编辑</title>
      <link>https://arxiv.org/abs/2402.11078</link>
      <description><![CDATA[arXiv:2402.11078v1 公告类型：新
摘要：与更专业的方法相比，微调由于性能较差而被认为对模型编辑无效而被忽视。然而，微调很简单，与正在编辑的模型的架构细节无关，并且能够利用标准训练方法（例如 PEFT）的不断进步，这使其成为模型编辑器的有吸引力的选择。在这项工作中，我们证明纯粹的微调可以成为模型编辑的可行方法。我们建议用两个关键成分对天真的微调进行轻微修改。首先，我们优化条件似然而不是完全似然。其次，我们用随机释义和事实来扩充数据，以鼓励泛化和局部性。我们在 ZsRE 和 CounterFact 上的实验表明，这种简单的修改允许微调，以在编辑分数上经常匹配或优于专业编辑器。]]></description>
      <guid>https://arxiv.org/abs/2402.11078</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>通过在空间统计空间中优化来学习微观结构的潜变量表示</title>
      <link>https://arxiv.org/abs/2402.11103</link>
      <description><![CDATA[arXiv:2402.11103v1 公告类型：新
摘要：在材料科学中，材料开发涉及评估和优化材料的内部结构（通常称为微观结构）。微观结构是随机的，类似于图像纹理。特定的微观结构可以通过其空间统计来很好地表征，类似于通过对类傅里叶滤波器组的响应来表征图像纹理。 Paulson 等人的材料设计将受益于微观结构的低维表示。 （2017）。
  在这项工作中，我们训练变分自动编码器（VAE）来生成纹理重建，保留原始纹理的空间统计信息，而不必在数据空间中重建相同的图像。我们通过在成本函数中添加一个可微项来实现这一点，以最小化空间统计空间中原始数据和重建数据之间的距离。
  我们的实验表明，训练一个 VAE 来最小化原始图像和合成图像重建之间的空间统计空间距离是可能的。在未来的工作中，我们将把相同的技术应用于微观结构，目标是获得材料微观结构的低维表示。]]></description>
      <guid>https://arxiv.org/abs/2402.11103</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>使用稀疏子空间变分推理训练贝叶斯神经网络</title>
      <link>https://arxiv.org/abs/2402.11025</link>
      <description><![CDATA[arXiv:2402.11025v1 公告类型：新
摘要：贝叶斯神经网络（BNN）提供不确定性量化，但缺点是训练和推理成本大幅增加。稀疏 BNN 已被研究用于高效推理，通常通过在整个训练过程中缓慢引入稀疏性或通过密集 BNN 的训练后压缩来实现。如何削减大量培训成本的困境仍然存在，特别是考虑到需要了解不确定性。为了解决这一挑战，我们引入了稀疏子空间变分推理（SSVI），这是第一个完全稀疏的 BNN 框架，它在整个训练和推理阶段保持一致的高度稀疏贝叶斯模型。从随机初始化的低维稀疏子空间开始，我们的方法交替优化稀疏子空间基础选择及其相关参数。虽然基选择的特点是不可微的问题，但我们在基于权重分布统计的新标准的指导下，通过移除和添加策略来近似最佳解决方案。我们的大量实验表明，SSVI 在构建稀疏 BNN 方面树立了新的基准，例如，与密集 VI 训练相比，模型大小压缩了 10-20 倍，性能下降不到 3%，并且训练期间的 FLOPs 减少了高达 20 倍。值得注意的是，SSVI 还表现出对超参数的鲁棒性增强，减少了对 VI 进行复杂调整的需要，有时甚至在准确性和不确定性指标上超过了经过 VI 训练的密集 BNN。]]></description>
      <guid>https://arxiv.org/abs/2402.11025</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>通过域的正则化注释对带有域标签噪声的子群转移的鲁棒性</title>
      <link>https://arxiv.org/abs/2402.11039</link>
      <description><![CDATA[arXiv:2402.11039v1 公告类型：新
摘要：现有的最后一层再训练方法旨在优化最差组精度（WGA），这在很大程度上依赖于训练数据中注释良好的组。我们在理论和实践中都表明，使用下采样或上加权进行 WGA 的基于注释的数据增强很容易受到域注释噪声的影响，并且在高噪声情况下接近使用普通经验风险最小化训练的模型的 WGA。我们引入了域的正则化注释（RAD），以便在不需要显式域注释的情况下训练鲁棒的最后一层分类器。我们的结果表明，RAD 与其他最近提出的免域注释技术相比具有竞争力。最重要的是，即使几个公开可用数据集的训练数据中只有 5% 的噪声，RAD 的性能也优于最先进的依赖注释的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.11039</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>通过金融时间序列聚类实现普惠金融信贷产品</title>
      <link>https://arxiv.org/abs/2402.11066</link>
      <description><![CDATA[arXiv:2402.11066v1 公告类型：新
摘要：普惠金融确保个人能够获得满足其需求的金融产品和服务。作为经济增长和投资机会的关键因素，普惠金融增加了消费者支出，从而促进了商业发展。事实证明，当机构为边缘化社会群体提供金融服务时，它们的利润会更高。基于消费者交易数据的客户细分是用于促进普惠金融的众所周知的策略。虽然现代机构可以获得所需的数据，但挑战仍然是片段注释通常很难和/或昂贵。这阻止了使用基于领域专家知识的时间序列分类模型来进行客户细分。因此，集群是一种有吸引力的替代方案，可以根据交易数据中编码的消费行为将客户划分为同质组。在本文中，我们针对阻碍现代金融机构提供金融普惠信贷、储蓄和保险产品的关键挑战之一提出了一种解决方案：在不引入限制性传统信用评分技术的情况下，无法了解消费者的金融行为，进而了解风险。 。我们提出了一种新颖的时间序列聚类算法，使机构能够了解其客户的财务行为。这使得能够根据客户的需求提供独特的产品，而不依赖于限制性的信贷实践。]]></description>
      <guid>https://arxiv.org/abs/2402.11066</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>使用多类分类对患有 2 型糖尿病的老年人进行分析和死亡率预测</title>
      <link>https://arxiv.org/abs/2402.10999</link>
      <description><![CDATA[arXiv:2402.10999v1 公告类型：新
摘要：设计适当的治疗计划来管理糖尿病需要健康从业者关注患者的剩余生命以及影响他们的合并症。患有 2 型糖尿病 (T2DM) 的老年人很容易过早死亡，甚至出现低血糖。使用的结构化数据集为 275,190 名 65 岁或以上患有糖尿病的美国退伍军人提供了 68 个潜在的死亡预测因子。通过组合两个原始目标变量发明了一个新的目标变量。通过离散化连续变量来处理异常值。分类变量已被虚拟编码。类平衡是通过随机欠采样实现的。使用多项 Logistic 回归和 LASSO 构建基准回归模型。卡方和信息增益是所使用的基于滤波器的特征选择技术。采用多项式逻辑回归、随机森林、极限梯度提升 (XGBoost) 和一对一分类器等分类器来构建各种模型。与预期相反，所有模型的表现都持续不佳。 XGBoost 通过卡方特征选择给出了 53.03% 的最高准确率。所有型号均表现出 3 级（剩余寿命超过 10 年）可接受的性能，1 级（剩余寿命长达 5 年）显着较低，2 级最差（剩余寿命超过 5 年）但最多 10 年）。特征分析推断出几乎所有输入变量都与多个目标类相关联。虚拟编码后输入数据的高维度似乎混淆了模型，导致错误分类。本研究中采用的方法在生成高性能预测模型方面无效，但奠定了基础，因为这个问题从未从多类分类的角度来看待。]]></description>
      <guid>https://arxiv.org/abs/2402.10999</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>统计归纳头的演变：上下文学习马尔可夫链</title>
      <link>https://arxiv.org/abs/2402.11004</link>
      <description><![CDATA[arXiv:2402.11004v1 公告类型：新
摘要：大型语言模型能够生成模仿输入模式的文本。我们引入了一个简单的马尔可夫链序列建模任务，以研究这种上下文学习（ICL）能力是如何出现的。在我们的设置中，每个示例都是从马尔可夫链的先验分布中抽取的马尔可夫链中采样的。在此任务上训练的 Transformer 形成 \emph{统计归纳头}，根据上下文的二元统计数据计算准确的下一个标记概率。在训练过程中，模型会经历多个阶段：在预测一致的初始阶段之后，它们学习使用上下文中的单标记统计数据（一元组）进行次优预测；然后，快速相变到正确的上下文二元组解决方案。我们对这个多阶段过程进行了实证和理论研究，展示了变压器层之间的相互作用如何成功学习，并发现了更简单的一元组解决方案的存在可能会延迟最终二元组解决方案的形成的证据。我们研究了改变马尔可夫链上的先验分布如何影响学习，并考虑将我们的马尔可夫链上下文学习 (ICL-MC) 任务推广到 $n&gt; 2$ 的 $n$-grams。]]></description>
      <guid>https://arxiv.org/abs/2402.11004</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>神经网络漏洞的量子分析：共轭变量在系统攻击中的作用</title>
      <link>https://arxiv.org/abs/2402.10983</link>
      <description><![CDATA[arXiv:2402.10983v1 公告类型：新
摘要：神经网络表现出对小的非随机扰动的固有脆弱性，这些扰动表现为对抗性攻击。这种攻击源于损失函数相对于输入的梯度，被视为输入共轭，揭示了网络结构内的系统脆弱性。有趣的是，这种机制与量子物理学的不确定性原理之间存在数学一致性，揭示了迄今为止未曾预料到的跨学科性。神经网络系统内的这种固有的敏感性通常是内在的，不仅突出了这些网络的固有脆弱性，而且还表明在理解这些黑盒网络的跨学科领域中存在潜在的进步。]]></description>
      <guid>https://arxiv.org/abs/2402.10983</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>加速半异步联邦学习</title>
      <link>https://arxiv.org/abs/2402.10991</link>
      <description><![CDATA[arXiv:2402.10991v1 公告类型：新
摘要：联邦学习（FL）是一种分布式机器学习范例，允许客户在其数据上训练模型，同时保护其隐私。 FL 算法，例如联合平均 (FedAvg) 及其变体，已被证明在许多场景中都能很好地收敛。然而，这些方法要求客户端以同步方式将其本地更新上传到服务器，这在实际的 FL 设置中可能很慢且不可靠。为了解决这个问题，研究人员开发了异步 FL 方法，允许客户使用过时的全局模型继续对其本地数据进行训练。然而，这些方法中的大多数只是简单地聚合所有收到的更新，而不考虑它们的相对贡献，这可能会减慢收敛速度。在本文中，我们提出了一种贡献感知异步 FL 方法，该方法考虑了接收到的更新的陈旧性和统计异质性。我们的方法根据这些因素动态调整每次更新的贡献，与现有方法相比，这可以加快收敛速度​​。]]></description>
      <guid>https://arxiv.org/abs/2402.10991</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>具有共形事实性保证的语言模型</title>
      <link>https://arxiv.org/abs/2402.10978</link>
      <description><![CDATA[arXiv:2402.10978v1 公告类型：新
摘要：保证语言模型（LM）输出的正确性和真实性是一个主要的开放问题。在这项工作中，我们提出了共形事实性，这是一个通过连接语言建模和共形预测来确保 LM 的高概率正确性保证的框架。我们观察到，LM 输出的正确性相当于不确定性量化问题，其中不确定性集被定义为 LM 输出的蕴涵集。利用这种联系，我们表明语言模型中的保形预测对应于一种退避算法，该算法通过逐步降低 LM 输出的具体性（并扩展相关的不确定性集）来提供高概率正确性保证。这种方法适用于任何黑盒 LM，并且需要很少的人工注释样本。对我们的闭卷 QA（FActScore、NaturalQuestions）和推理任务（MATH）方法的评估表明，我们的方法可以提供 80-90% 的正确性保证，同时保留 LM 的大部分原始输出。]]></description>
      <guid>https://arxiv.org/abs/2402.10978</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>mshw，一个预测库，根据多个季节性 Holt-Winters 预测短期电力需求</title>
      <link>https://arxiv.org/abs/2402.10982</link>
      <description><![CDATA[arXiv:2402.10982v1 公告类型：新
摘要：输电系统运营商越来越需要更准确地预测电力需求。当前的电力系统很大程度上需要需求预测，以便电力市场确定电价以及生产单位的规划。电气系统的公司使用专有软件根据时间序列和预测工具（无论是统计工具还是人工智能）来获得预测。然而，最常见的预测形式是基于使用这两种技术的混合模型。无论如何，它是一种结构复杂、关联变量大量、需要高计算量才能进行预测的软件。它们所能提供的预测并不比简单模型所能提供的预测好多少。在本文中，我们提出了一个用于预测电力需求的 MATLAB 工具箱。该工具箱实现了多个季节性 Holt-Winters 指数平滑模型和神经网络模型。使用的模型包括使用离散区间移动季节性 (DIMS) 来改进特殊日子的预测。此外，还展示了其在欧洲各种电力系统中的应用结果，从中可以看到所获得的结果。该库的使用为在其他应用领域中使用具有离散和复杂季节性的模型开辟了新的研究途径。]]></description>
      <guid>https://arxiv.org/abs/2402.10982</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>基于神经网络的机器学习中的最优特征重缩放</title>
      <link>https://arxiv.org/abs/2402.10964</link>
      <description><![CDATA[arXiv:2402.10964v1 公告类型：新
摘要：本文提出了一种新方法，通过遗传算法（GA）对输入特征（OFR）进行最佳缩放，从而提高前馈神经网络（FFNN）的训练效率和泛化性能。 OFR 重塑了输入空间，改善了用于训练的基于梯度的算法的调节。此外，遗传算法试验和选择所带来的尺度因子探索对应于每次训练尝试时第一层权重的不同初始化，从而实现了多起点全局搜索算法（即使仅限于少数权重），从而促进了全局最小值。该方法已在模拟真实工业过程（无心磨削）结果的 FFNN 上进行了测试。]]></description>
      <guid>https://arxiv.org/abs/2402.10964</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能和流程系统工程：下一个前沿</title>
      <link>https://arxiv.org/abs/2402.10977</link>
      <description><![CDATA[arXiv:2402.10977v1 公告类型：新
摘要：本文探讨了新兴的生成人工智能 (GenAI) 模型，例如大语言模型 (LLM)，如何增强过程系统工程 (PSE) 中的解决方案方法。这些尖端的 GenAI 模型，特别是基础模型 (FM)，在广泛的通用数据集上进行了预训练，为广泛的任务提供了多功能的适应性，包括响应查询、图像生成和复杂的决策。鉴于 PSE 的进步与计算和系统技术的发展之间的密切关系，探索 GenAI 和 PSE 之间的协同作用至关重要。我们首先对经典和新兴 GenAI 模型（包括 FM）进行简要概述，然后深入探讨它们在关键 PSE 领域的应用：综合和设计、优化和集成以及过程监控和控制。在每个领域，我们探索 GenAI 模型如何潜在地推进 PSE 方法，为每个领域提供见解和前景。此外，本文还确定并讨论了在 PSE 中充分利用 GenAI 的潜在挑战，包括多尺度建模、数据要求、评估指标和基准以及信任和安全，从而加深了关于将 GenAI 有效集成到系统分析、设计、优化、运营中的讨论。 、监视和控制。本文为未来关注新兴 GenAI 在 PSE 中的应用的研究提供了指导。]]></description>
      <guid>https://arxiv.org/abs/2402.10977</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:25 GMT</pubDate>
    </item>
    </channel>
</rss>