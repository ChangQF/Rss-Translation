<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>RPS：通用储层模式采样器</title>
      <link>https://arxiv.org/abs/2411.00074</link>
      <description><![CDATA[arXiv:2411.00074v1 公告类型：新
摘要：由于数据流的持续快速发展，从流数据中高效学习对于现代数据分析非常重要。尽管流模式挖掘取得了重大进展，但挑战依然存在，特别是在管理复杂数据流（如顺序和加权项集）方面。虽然蓄水池抽样是从数据流中随机选择固定大小样本的基本方法，但它在这种复杂模式中的应用仍未得到广泛探索。在本研究中，我们介绍了一种利用加权蓄水池来促进从流式批量数据中直接进行模式抽样的方法，从而确保了可扩展性和效率。我们提出了一种通用算法，该算法能够解决时间偏差并处理各种模式类型，包括顺序、加权和无加权项集。通过对真实数据集进行的全面实验，我们评估了我们方法的有效性，展示了它为顺序数据构建准确的增量在线分类器的能力。我们的方法不仅使以前无法使用的序列数据在线机器学习模型达到与离线基线相当的精度，而且还代表了增量在线序列项集分类器开发的重大进展。]]></description>
      <guid>https://arxiv.org/abs/2411.00074</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$\boldsymbol{\mu}\mathbf{P^2}$：有效的清晰度感知最小化需要逐层扰动缩放</title>
      <link>https://arxiv.org/abs/2411.00075</link>
      <description><![CDATA[arXiv:2411.00075v1 公告类型：新
摘要：清晰度感知最小化 (SAM) 可增强各种神经架构和数据集的性能。随着模型不断扩大以提高性能，严格理解 SAM 的缩放行为至关重要。为此，我们使用张量程序框架研究使用 SAM 训练的神经网络的无限宽度极限。我们的研究结果表明，即使使用最佳超参数，标准 SAM 的动态也可以有效地减少到仅在宽神经网络的最后一层应用 SAM。相反，我们通过逐层扰动缩放确定了一种稳定的参数化，我们称之为 $\textit{最大更新和扰动参数化}$ ($\mu$P$^2$)，这确保所有层都是特征学习并在极限中有效扰动。通过对 MLP、ResNets 和 Vision Transformers 的实验，我们通过经验证明了 $\mu$P$^2$ 是实现跨模型尺度的学习率和扰动半径联合最优值的超参数迁移的第一个参数化。此外，我们提供了一个直观的条件来推导其他扰动规则（如自适应 SAM 和 SAM-ON）的 $\mu$P$^2$，同时确保所有层的扰动效果均衡。]]></description>
      <guid>https://arxiv.org/abs/2411.00075</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标签噪音：无知是福</title>
      <link>https://arxiv.org/abs/2411.00079</link>
      <description><![CDATA[arXiv:2411.00079v1 公告类型：新
摘要：我们建立了一个在多类、实例相关标签噪声下学习的新理论框架。该框架将标签噪声下的学习视为一种领域适应，特别是后验漂移下的领域适应。我们引入了 \emph{相对信号强度} (RSS) 的概念，这是一种逐点测量，可以量化从嘈杂到干净后验的可转移性。使用 RSS，我们建立了几乎匹配的超额风险上限和下限。我们的理论发现支持简单的 \emph{噪声忽略经验风险最小化 (NI-ERM)} 原则，该原则在忽略标签噪声的同时最小化经验风险。最后，我们将这一理论见解转化为实践：通过使用 NI-ERM 在自监督特征提取器之上拟合线性分类器，我们在 CIFAR-N 数据挑战中实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.00079</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非完整力学的拉格朗日神经网络</title>
      <link>https://arxiv.org/abs/2411.00110</link>
      <description><![CDATA[arXiv:2411.00110v1 公告类型：新
摘要：拉格朗日神经网络 (LNN) 是解决物理系统的强大工具，特别是那些受守恒定律支配的系统。LNN 可以参数化系统的拉格朗日量，以预测几乎能量守恒的轨迹。这些技术已被证明在无约束系统以及具有完整约束的系统中都是有效的。在这项工作中，我们将 LNN 技术应用于具有非完整约束的机械系统。我们在一些具有非完整约束的著名示例上测试了我们的方法，结果表明，将这些限制纳入神经网络的学习不仅可以提高轨迹估计精度，还可以确保遵守约束，并且与无约束系统相比表现出更好的能量行为。]]></description>
      <guid>https://arxiv.org/abs/2411.00110</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有限差分近似进行无导数优化：一项实验研究</title>
      <link>https://arxiv.org/abs/2411.00112</link>
      <description><![CDATA[arXiv:2411.00112v1 公告类型：新
摘要：无导数优化 (DFO) 在解决复杂优化问题中至关重要，因为通过 oracle 只能获得嘈杂的函数评估。在这个领域，通过有限差分 (FD) 近似的 DFO 已经成为一种强大的方法。两种经典方法是 Kiefer-Wolfowitz (KW) 和同时扰动随机近似 (SPSA) 算法，它们在每次迭代中仅使用两个样本来估计梯度以节省样本。然而，这种方法会产生不精确的梯度估计量，需要减小步长以确保收敛，这通常会导致优化进度缓慢。相比之下，由批量样本构建的 FD 估计量可以更准确地近似梯度。虽然使用基于批处理的 FD 估计量的梯度下降算法在每次迭代中都能获得更精确的结果，但它们需要更多的样本并允许更少的迭代。这就提出了一个基本问题：哪种方法更有效——KW 式方法还是基于批处理的 FD 估计器的 DFO？本文对这些方法进行了全面的实验比较，研究了梯度估计精度和迭代步骤之间的基本权衡。通过在低维和高维设置中进行的大量实验，我们得出了一个令人惊讶的发现：当应用高效的基于批处理的 FD 估计器时，其相应的梯度下降算法在我们的测试场景中通常比经典的 KW 和 SPSA 算法表现出更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.00112</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>训练和评估时间序列的因果预测模型</title>
      <link>https://arxiv.org/abs/2411.00126</link>
      <description><![CDATA[arXiv:2411.00126v1 公告类型：新
摘要：深度学习时间序列模型通常用于进行预测，为下游决策提供信息。由于这些决策可能与训练集中的决策不同，因此隐含的要求是时间序列模型将在其训练分布之外进行推广。尽管有这个核心要求，但时间序列模型通常在分布内预测任务上进行训练和评估。我们扩展了正交统计学习框架来训练因果时间序列模型，这些模型在预测训练分布之外的行为的影响时具有更好的泛化能力。为了评估这些模型，我们利用经济学中流行的回归不连续设计来构建因果处理效果的测试集。]]></description>
      <guid>https://arxiv.org/abs/2411.00126</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越准确性：用正确的理论确保正确的预测</title>
      <link>https://arxiv.org/abs/2411.00132</link>
      <description><![CDATA[arXiv:2411.00132v1 公告类型：新
摘要：大型预训练基础模型表现出色，在某些高风险应用中甚至超越人类专家。然而，目前大多数这些模型主要根据预测准确性进行评估，忽略了其准确预测背后的原理的有效性。为了安全部署基础模型，迫切需要确保双重正确预测，即正确的预测有正确的原理支持。为了实现这一点，我们提出了一个两阶段方案：首先，我们策划一个新的数据集，为视觉识别任务提供结构化原理。其次，我们提出了一种基于原理的优化方法来指导模型解开和定位每个原理的视觉证据，而无需手动注释。大量的实验和消融研究表明，我们的模型在广泛任务中的预测准确率比最先进的模型高出 10.1%。此外，我们的方法显著提高了模型的理论正确性，将定位提高了 7.5%，将解缠提高了 36.5%。我们的数据集、源代码和预训练权重：https://github.com/deep-real/DCP]]></description>
      <guid>https://arxiv.org/abs/2411.00132</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM-Inference-Bench：AI 加速器上大型语言模型的推理基准测试</title>
      <link>https://arxiv.org/abs/2411.00136</link>
      <description><![CDATA[arXiv:2411.00136v1 公告类型：新
摘要：大型语言模型 (LLM) 推动了多个领域的突破性进步，通常用于文本生成应用程序。然而，这些复杂模型的计算需求带来了重大挑战，需要高效的硬件加速。对不同硬件平台上的 LLM 性能进行基准测试对于了解其可扩展性和吞吐量特性至关重要。我们推出了 LLM-Inference-Bench，这是一个全面的基准测试套件，用于评估 LLM 的硬件推理性能。我们彻底分析了不同的硬件平台，包括 Nvidia 和 AMD 的 GPU 以及专用的 AI 加速器、Intel Habana 和 SambaNova。我们的评估包括来自 LLaMA、Mistral 和 Qwen 系列的几个 LLM 推理框架和模型，具有 7B 和 70B 参数。我们的基准测试结果揭示了各种模型、硬件平台和推理框架的优势和局限性。我们提供一个交互式仪表板，帮助确定针对给定硬件平台的最佳性能配置。]]></description>
      <guid>https://arxiv.org/abs/2411.00136</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在可解释设计的卷积神经网络中学习局部离散特征</title>
      <link>https://arxiv.org/abs/2411.00139</link>
      <description><![CDATA[arXiv:2411.00139v1 公告类型：新
摘要：我们提出的框架试图通过引入基于侧向抑制机制的可解释设计卷积神经网络 (CNN) 来打破性能和可解释性之间的权衡。ExplaiNet 模型由预测器（具有残差或密集跳过连接的高精度 CNN）和表达网络神经元空间相互作用的解释器概率图组成。每个图节点上的值都是局部离散特征 (LDF) 向量，这是一个补丁描述符，表示按激活强度排序的拮抗神经元的索引，这些索引是通过梯度下降学习的。使用 LDF 作为序列，我们可以通过重新利用 EXTREME（一种通常用于分子生物学的基于 EM 的序列基序发现方法）来提高解释的简洁性。为每个中间图像表示使用离散特征主题矩阵，而不是连续激活张量，使我们能够利用贝叶斯网络固有的可解释性。通过收集观察结果并直接计算概率，我们可以解释相邻级别主题之间的因果关系，并将模型的输出归因于全局主题。此外，在各种微小图像基准数据集上进行的实验证实，对于给定数量的参数和/或层，我们的预测器可确保与基线架构相同的性能水平。我们的新方法有望超越这一性能，同时提供额外的解释流。在解决的 MNIST 分类任务中，它达到了与单个模型的最新性能相当的性能，使用标准训练设置和 75 万个参数。]]></description>
      <guid>https://arxiv.org/abs/2411.00139</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>互信息保留神经网络修剪</title>
      <link>https://arxiv.org/abs/2411.00147</link>
      <description><![CDATA[arXiv:2411.00147v1 公告类型：新
摘要：模型修剪因其在资源消耗和成本方面的积极影响而受到越来越多的关注。过去几年已经开发了各种方法。特别是，结构化修剪技术可以辨别神经网络 (NN) 中的节点和卷积神经网络 (CNN) 中的过滤器的重要性。这些技术的全局版本对网络中的所有节点进行排名并选择前 k 个节点，这比仅在单个层内对节点进行排名的局部方法更具优势。通过同时评估所有节点，全局技术可以更好地控制网络架构，从而提高性能。然而，在全局修剪期间进行的排名和选择过程可能有几个主要缺点。首先，排名不是根据已经执行的修剪实时更新的，因此无法解释节点间的相互作用。其次，从模型中删除整个层的情况并不少见，这会导致网络无法训练。最后，全局修剪方法不提供任何有关重新训练的保证。为了解决这些问题，我们引入了互信息保留剪枝 (MIPP)。我们方法的基本原理是选择节点，以便保持相邻层激活之间的互信息 (MI)。我们在一系列视觉模型和数据集上评估了 MIPP，包括 ImageNet 上预先训练的 ResNet50，我们展示了 MIPP 超越最先进方法的能力。MIPP 的实现将在发布后提供。]]></description>
      <guid>https://arxiv.org/abs/2411.00147</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PSL：从成对角度重新思考和改进 Softmax 损失以实现推荐</title>
      <link>https://arxiv.org/abs/2411.00163</link>
      <description><![CDATA[arXiv:2411.00163v1 公告类型：新
摘要：Softmax Loss (SL) 广泛应用于推荐系统 (RS)，并已证明其有效性。这项工作从成对的角度分析了 SL，揭示了两个重要的局限性：1) SL 与 DCG 等传统排名指标之间的关系不够紧密；2) SL 对假阴性实例高度敏感。我们的分析表明，这些限制主要是由于指数函数的使用。为了解决这些问题，这项工作将 SL 扩展到一个新的损失函数系列，称为成对 Softmax Loss (PSL)，它用其他合适的激活函数替换 SL 中的指数函数。虽然修改很少，但我们强调了 PSL 的三个优点：1) 它可以作为具有合适激活函数的 DCG 的更紧密替代品；2) 它更好地平衡了数据贡献；3) 它充当由分布稳健优化 (DRO) 增强的特定 BPR 损失。我们通过实证实验进一步验证了PSL的有效性和稳健性。代码可从https://github.com/Tiny-Snow/IR-Benchmark获取。]]></description>
      <guid>https://arxiv.org/abs/2411.00163</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EARL-BO：用于多步前瞻、高维贝叶斯优化的强化学习</title>
      <link>https://arxiv.org/abs/2411.00171</link>
      <description><![CDATA[arXiv:2411.00171v1 公告类型：新
摘要：传统的贝叶斯优化 (BO) 方法主要涉及一步最优决策（例如，最大化下一步的预期改进）。为了避免短视行为，多步前瞻 BO 算法（例如推出策略）考虑了 BO 的顺序决策性质，即作为随机动态规划 (SDP) 问题，近年来取得了令人鼓舞的结果。然而，由于维数灾难，这些方法中的大多数都会产生显著的近似值或存在可扩展性问题，例如仅限于两步前瞻。本文提出了一种基于强化学习 (RL) 的新型框架，用于高维黑盒优化问题中的多步前瞻 BO。所提出的方法通过使用 RL 以近乎最优的方式高效地解决 BO 过程的 SDP，提高了多步前瞻 BO 的可扩展性和决策质量。我们首先引入 Attention-DeepSets 编码器来向 RL 代理表示知识状态，并采用离线策略学习来加速其初始训练。然后，我们提出了一种基于端到端 (编码器-RL) 在线策略学习的多任务微调程序。我们在合成基准函数和现实世界的超参数优化问题上评估了所提出的方法 EARL-BO（用于贝叶斯优化的编码器增强 RL），与现有的多步前瞻和高维 BO 方法相比，其性能显著提高。]]></description>
      <guid>https://arxiv.org/abs/2411.00171</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>什么造就了专家？回顾机器学习研究人员如何定义“专家”</title>
      <link>https://arxiv.org/abs/2411.00179</link>
      <description><![CDATA[arXiv:2411.00179v1 公告类型：新
摘要：人类专家经常参与机器学习系统的开发，以收集和验证数据、就算法开发提供咨询并评估系统性能。同时，谁算作“专家”以及什么构成“专业知识”并不总是明确定义的。在这项工作中，我们回顾了 112 篇明确提到“专家”和“专业知识”并描述机器学习 (ML) 系统开发的学术出版物，以调查专业知识的特征以及专家所扮演的角色。我们发现专业知识通常没有定义，并且很少寻求正规教育和专业认证之外的知识形式，这对在 ML 开发中被认可和合法化的知识类型有影响。此外，我们发现专家知识往往以专注于挖掘教科书知识的方式被利用，例如通过数据注释。我们讨论了专家参与 ML 开发的方式与技能降低、专业知识的社会建构以及对负责任的人工智能开发的影响。我们指出，在论证领域专家参与时需要进行反思和具体性，这既是为了记录和可重复性，也是为了扩大公认的专业知识范围。]]></description>
      <guid>https://arxiv.org/abs/2411.00179</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>APEBench：PDE 自回归神经模拟器的基准</title>
      <link>https://arxiv.org/abs/2411.00180</link>
      <description><![CDATA[arXiv:2411.00180v1 公告类型：新
摘要：我们介绍了自回归 PDE 模拟器基准 (APEBench)，这是一个全面的基准套件，用于评估用于解决偏微分方程的自回归神经模拟器。APEBench 基于 JAX，提供无缝集成的可微分模拟框架，采用高效的伪谱方法，支持 1D、2D 和 3D 中的 46 种不同的 PDE。为了促进对学习到的模拟器的系统分析和比较，我们提出了一种用于展开训练的新分类法，并引入了 PDE 动力学的唯一标识符，该标识符与经典数值方法的稳定性标准直接相关。APEBench 能够评估不同的神经架构，与现有基准不同，它与求解器的紧密集成能够支持可微分物理训练和神经混合模拟器。此外，APEBench 强调推出指标以了解时间泛化，从而深入了解模拟 PDE 动力学的长期行为。在几个实验中，我们强调了神经模拟器和数值模拟器之间的相似性。]]></description>
      <guid>https://arxiv.org/abs/2411.00180</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自我修复机器学习：现实环境中自主适应的框架</title>
      <link>https://arxiv.org/abs/2411.00186</link>
      <description><![CDATA[arXiv:2411.00186v1 公告类型：新
摘要：现实世界的机器学习系统经常会因为底层数据生成过程 (DGP) 中的分布变化而遇到模型性能下降的问题。现有的解决变化的方法，例如概念漂移适应，受到其原因不可知性的限制。通过从一组预定义的操作中进行选择，此类方法隐式地假设模型退化的原因与应采取的行动无关，从而限制了它们选择适当适应的能力。在本文中，我们提出了一种克服这些限制的替代范式，称为自修复​​机器学习 (SHML)。与以前的方法相反，SHML 可以自主诊断退化的原因并提出基于诊断的纠正措施。我们将 SHML 形式化为适应行动空间上的优化问题，以最小化转移 DGP 下的预期风险。我们引入了自愈系统的理论框架，并构建了代理自愈解决方案 H-LLM，该解决方案使用大型语言模型通过推理 DGP 底层结构进行自我诊断，并通过提出和评估纠正措施进行自适应。从实证上讲，我们分析了 H-LLM 的不同组件，以了解其工作原理和时间，展示了自愈 ML 的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.00186</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>