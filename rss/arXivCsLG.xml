<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>神经算法推理的马尔可夫性质：分析与方法</title>
      <link>https://arxiv.org/abs/2403.04929</link>
      <description><![CDATA[arXiv:2403.04929v1 公告类型：新
摘要：神经算法推理是一个新兴的研究方向，它赋予神经网络逐步模仿算法执行的能力。现有设计中的常见范例涉及使用历史嵌入来预测未来执行步骤的结果。我们在这项工作中的观察是，这种历史依赖性本质上与算法推理任务的马尔可夫性质相矛盾。基于这个动机，我们提出了 ForgetNet，它不使用历史嵌入，因此与任务的马尔可夫性质一致。为了解决早期阶段训练 ForgetNet 的挑战，我们进一步引入了 G-ForgetNet，它使用门控机制来允许选择性地集成历史嵌入。这种增强的功能在模型的早期训练阶段提供了有价值的计算路径。我们基于 CLRS-30 算法推理基准的大量实验表明，ForgetNet 和 G-ForgetNet 都比现有方法实现了更好的泛化能力。此外，我们研究了门控机制的行为，强调其与我们直觉的一致程度及其稳健性能的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.04929</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>无梯度神经拓扑优化</title>
      <link>https://arxiv.org/abs/2403.04937</link>
      <description><![CDATA[arXiv:2403.04937v1 公告类型：新
摘要：无梯度优化器允许解决问题，无论其目标函数的平滑度或可微性如何，但与基于梯度的算法相比，它们需要更多的迭代才能收敛。由于每次迭代的计算成本很高并且这些问题的维度很高，这使得它们无法进行拓扑优化。我们提出了一种预训练的神经重新参数化策略，与没有潜在重新参数化的传统方法相比，在优化潜在空间中的设计时，该策略可导致迭代次数至少减少一个数量级。我们通过训练数据分布内和分布外的广泛计算实验证明了这一点。尽管基于梯度的拓扑优化对于可微分问题（例如结构的顺应性优化）仍然更有效，但我们相信这项工作将为梯度信息不易获得的问题（例如断裂）开辟一条新途径。]]></description>
      <guid>https://arxiv.org/abs/2403.04937</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>堆叠作为加速梯度下降</title>
      <link>https://arxiv.org/abs/2403.04978</link>
      <description><![CDATA[arXiv:2403.04978v1 公告类型：新
摘要：堆叠是一种启发式技术，通过逐步增加层数并通过复制旧层的参数来初始化新层来训练深度残差网络，事实证明，它在提高训练深度神经网络的效率方面非常成功。在本文中，我们对堆叠的功效提出了理论解释：即堆叠实现了 Nesterov 加速梯度下降的一种形式。该理论还涵盖了更简单的模型，例如在 boosting 方法中构建的加性系综，并为在每轮 boosting 中初始化新分类器的类似广泛使用的实用启发式提供了解释。我们还证明，对于某些深度线性残差网络，通过对允许更新错误的 Nesterov 加速梯度方法的新势函数分析，堆叠确实提供了加速训练。我们还进行了概念验证实验来验证我们的理论。]]></description>
      <guid>https://arxiv.org/abs/2403.04978</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>通过注意力克罗内克分解进行高效的高分辨率时间序列分类</title>
      <link>https://arxiv.org/abs/2403.04882</link>
      <description><![CDATA[arXiv:2403.04882v1 公告类型：新
摘要：由于各个领域的详细时间数据的可用性不断增加，高分辨率时间序列分类问题至关重要。为了有效应对这一挑战，最先进的注意力模型必须具有可扩展性，以适应高分辨率时间序列数据中通常遇到的不断增长的序列长度，同时还证明在处理此类数据中普遍存在的固有噪声方面具有鲁棒性。数据集。为了解决这个问题，我们建议根据交互范围将长时间序列分层编码为多个级别。通过捕获不同级别的关系，我们可以构建更强大、更具表现力和更高效的模型，这些模型能够捕获数据中的短期波动和长期趋势。然后，我们提出了一种新的时间序列变压器主干（KronTime），通过引入克罗内克分解注意力来处理这种多级时间序列，从下层到上层顺序计算注意力。对四个长时间序列数据集的实验表明，与基线方法相比，分类结果优异，效率更高。]]></description>
      <guid>https://arxiv.org/abs/2403.04882</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>基于控制的图嵌入和数据增强用于对比学习</title>
      <link>https://arxiv.org/abs/2403.04923</link>
      <description><![CDATA[arXiv:2403.04923v1 公告类型：新
摘要：在本文中，我们通过利用图上定义的动态网络的控制特性来研究无监督图表示学习问题。我们的方法引入了一种新颖的对比学习框架，这是一种广泛流行的无监督表示学习技术。对比学习的关键步骤是从输入图创建“增强”图。虽然与原始图不同，但这些增强图保留了原始图的结构特征。在这里，我们提出了一种利用网络的控制属性来生成这些增强图的独特方法。核心概念围绕扰动原始图来创建新图，同时保留特定于网络和图的可控性属性。与现有方法相比，我们证明这种创新方法增强了对比学习框架的有效性，从而在分类任务的准确性方面取得了优异的结果。关键的创新在于我们能够使用这些控制属性解码网络结构，为无监督图表示学习开辟新途径。]]></description>
      <guid>https://arxiv.org/abs/2403.04923</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>在基于模型的架构中使用未经训练的神经网络解决模型不匹配的逆问题</title>
      <link>https://arxiv.org/abs/2403.04847</link>
      <description><![CDATA[arXiv:2403.04847v1 公告类型：新
摘要：基于模型的深度学习方法，例如 \emph{循环展开} (LU) 和 \emph{深度平衡模型} (DEQ) 扩展，在解决逆问题 (IP) 方面提供了出色的性能。这些方法将优化迭代展开为一系列神经网络，这些神经网络实际上从数据中学习正则化函数。虽然这些架构目前在许多应用中都是最先进的，但它们的成功在很大程度上依赖于前向模型的准确性。由于模型简化或设备的不确定性，这种假设在许多物理应用中可能受到限制。为了解决前向模型不匹配的问题，我们在基于模型的架构中引入了未经训练的前向模型残差块，以匹配每个实例的测量域中的数据一致性。我们在著名的基于模型的架构（LU 和 DEQ）中提出了两种变体，并证明了温和条件下的收敛性。实验表明，在三个不同的应用程序中，消除伪影和保留细节方面的质量显着提高，包括线性和非线性反演问题。此外，我们强调了中间步骤中的重建有效性，并展示了对残差块随机初始化的鲁棒性以及评估期间更高次数的迭代。]]></description>
      <guid>https://arxiv.org/abs/2403.04847</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>彩票假说调查</title>
      <link>https://arxiv.org/abs/2403.04861</link>
      <description><![CDATA[arXiv:2403.04861v1 公告类型：新
摘要：彩票假说（LTH）指出，密集的神经网络模型包含高度稀疏的子网络（即中奖彩票），在单独训练时可以实现比原始模型更好的性能。虽然 LTH 已在许多工作中得到了经验和理论的证明，但仍然存在一些悬而未决的问题有待解决，例如效率和可扩展性。此外，缺乏开源框架和一致的实验环境也给 LTH 的未来研究带来了挑战。我们首次从不同的角度审视以往对 LTH 的研究和研究。我们还讨论了现有工作中的问题并列出了进一步探索的潜在方向。这项调查旨在深入了解 LTH 的状况，并开发一个适当维护的平台来进行实验并与最新的基线进行比较。]]></description>
      <guid>https://arxiv.org/abs/2403.04861</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>限制贝叶斯神经网络</title>
      <link>https://arxiv.org/abs/2403.04810</link>
      <description><![CDATA[arXiv:2403.04810v1 公告类型：新
摘要：现代深度学习工具在解决复杂问题方面非常有效。然而，它们作为黑盒模型的操作增加了预测的不确定性。此外，他们还应对各种挑战，包括大型网络中需要大量存储空间、过度拟合、欠拟合、梯度消失等问题。本研究探讨了贝叶斯神经网络的概念，提出了一种新颖的架构，旨在显着降低网络的存储空间复杂性。此外，我们引入了一种善于有效处理不确定性的算法，确保稳健的收敛值，而不会陷入局部最优，特别是当目标函数缺乏完美凸性时。]]></description>
      <guid>https://arxiv.org/abs/2403.04810</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>TrafPS：一种基于 Shapley 的可视化分析方法来解释流量</title>
      <link>https://arxiv.org/abs/2403.04812</link>
      <description><![CDATA[arXiv:2403.04812v1 公告类型：新
摘要：深度学习（DL）的最新成就显示了其预测交通流的潜力。这样的预测有利于了解情况并做出交通控制决策。然而，大多数最先进的深度学习模型被认为是“黑匣子”，对于最终用户而言，底层机制几乎不透明。之前的一些工作试图“打开黑匣子”并增加预测生成方式的可解释性。然而，处理大规模时空数据的复杂模型并发现显着影响交通流的显着时空模式仍然具有挑战性。为了克服这些挑战，我们提出了 TrafPS，这是一种可视化分析方法，用于解释交通预测结果，以支持交通管理和城市规划的决策。提出了区域 SHAP 和轨迹 SHAP 测量方法，以量化流量模式对不同级别城市交通的影响。根据领域专家的任务要求，我们采用交互式可视化界面对重要的流程模式进行多方面的探索和分析。两个真实案例研究证明了 TrafPS 在确定城市规划关键路线和决策支持方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.04812</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>AI时代的风暴潮建模：利用基于LSTM的机器学习提高预报精度</title>
      <link>https://arxiv.org/abs/2403.04818</link>
      <description><![CDATA[arXiv:2403.04818v1 公告类型：新
摘要：自然过程的物理模拟结果通常不能完全反映现实世界。例如，这是由于模拟的物理过程及其精确度的限制造成的。在这项工作中，我们提出并分析了基于 LSTM 的深度学习网络机器学习 (ML) 架构的使用，用于捕获和预测风暴潮预报模型相对于来自测量站的真实水位观测的系统误差行为在飓风事件期间。这项工作的总体目标是预测物理模型的系统误差，并用它来提高事后模拟结果的准确性。我们在美国沿海地区 61 场历史风暴的数据集上训练了我们提出的 ML 模型，并测试了其在修正伊恩飓风（2022 年）建模水位数据预测偏差方面的性能。我们表明，我们的模型可以在用于初始数据的所有测量站坐标上持续提高飓风伊恩的预测精度（ML 模型未知）。此外，通过检查使用初始训练数据集的不同子集（包含许多在飓风轨迹方面相对相似或不同的飓风）的影响，我们发现仅使用六个飓风的子集就可以获得类似质量的偏差校正。这是一个重要的结果，意味着可以将预先训练的 ML 模型应用于实时飓风预报结果，以纠正偏差并提高生成的模拟精度。目前的工作是创建适用于全模拟区域的实时风暴潮预报偏差校正系统的重要第一步。它还提供了一种高度可移植且可操作适用的方法，用于提高风暴潮预报之外的各种物理模拟场景的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.04818</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>我们知道，并非所有门票都是平等的：用特定领域的知识指导修剪</title>
      <link>https://arxiv.org/abs/2403.04805</link>
      <description><![CDATA[arXiv:2403.04805v1 公告类型：新
摘要：神经结构学习对于科学发现和可解释性至关重要。然而，注重计算资源效率的当代剪枝算法在选择与领域专业知识相一致的有意义的模型时面临着算法障碍。为了缓解这一挑战，我们提出了 DASH，它通过可用的特定领域结构信息来指导修剪。在学习动态基因调控网络模型的背景下，我们表明，DASH 与现有的交互伙伴常识相结合，提供了与生物学一致的特定于数据的见解。对于这项任务，我们在具有真实信息的合成数据和两个现实世界应用中展示了 DASH 的有效性，它大大优于竞争方法，并提供了更有意义的生物学见解。我们的工作表明，特定领域的结构信息具有改善模型衍生的科学见解的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.04805</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>神经网络数学（研究生课程讲义）</title>
      <link>https://arxiv.org/abs/2403.04807</link>
      <description><![CDATA[arXiv:2403.04807v1 公告类型：新
摘要：这些是我 2021 年至 2023 年在埃因霍温理工大学教授的同名课程附带的讲义。该课程旨在为研究生阶段的数学学生介绍神经网络，旨在使对进一步研究神经网络感兴趣的数学学生。它由两部分组成：首先是深度学习的一般介绍，重点是以形式数学的方式介绍该领域。第二部分介绍了李群和齐次空间的理论，以及如何应用它来设计具有理想几何等方差的神经网络。讲义尽可能独立，以便任何具有中等数学背景的学生都可以理解。该课程还包括一组 Jupyter 笔记本形式的编码教程和作业，可在 https://gitlab.com/bsmetsjr/mathematics_of_neural_networks 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04807</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>一种高效的隐私漏斗凸差分求解器</title>
      <link>https://arxiv.org/abs/2403.04778</link>
      <description><![CDATA[arXiv:2403.04778v1 公告类型：新
摘要：我们利用其凸差（DC）结构，为隐私漏斗（PF）方法提出了一种有效的求解器。所提出的直流分离产生了一个封闭形式的更新方程，它允许直接应用于已知和未知的分布设置。对于已知的分布情况，我们证明了所提出的非贪婪求解器的收敛性（局部驻点），并凭经验表明它在表征隐私与效用权衡方面优于最先进的方法。我们的 DC 方法的见解适用于未知的分布设置，其中可以使用标记的经验样本。与之前基于变分推理的求解器相比，利用这些见解，我们的交替最小化求解器满足 PF 的基本马尔可夫关系。根据经验，我们使用 MNIST 和 Fashion-MNIST 数据集评估所提出的求解器。我们的结果表明，在可比较的重建质量下，对手通过对我们的压缩代码进行聚类而遭受比使用比较方法更高的预测误差。最重要的是，我们的求解器在推理阶段独立于私有信息，这与基线相反。]]></description>
      <guid>https://arxiv.org/abs/2403.04778</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>AutoDefense：针对越狱攻击的多代理 LLM 防御</title>
      <link>https://arxiv.org/abs/2403.04783</link>
      <description><![CDATA[arXiv:2403.04783v1 公告类型：新
摘要：尽管在道德一致性方面进行了广泛的预训练和微调，以防止根据用户请求生成有害信息，但大型语言模型（LLM）仍然容易受到越狱攻击。在本文中，我们提出了 AutoDefense，一种基于响应过滤的多代理防御框架，可过滤来自 LLM 的有害响应。该框架为LLM代理分配不同的角色，并利用它们协同完成防御任务。任务的划分增强了法学硕士的整体指令遵循能力，并能够将其他防御组件集成为工具。 AutoDefense 可以适应充当代理的各种规模和类型的开源 LLM。通过对大规模有害和安全提示进行广泛的实验，我们验证了所提出的自动防御在提高针对越狱攻击的鲁棒性，同时保持正常用户请求的性能方面的有效性。我们的代码和数据可在 https://github.com/XHMY/AutoDefense 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04783</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动的时间序列两阶段多分裂因果系综模型</title>
      <link>https://arxiv.org/abs/2403.04793</link>
      <description><![CDATA[arXiv:2403.04793v1 公告类型：新
摘要：因果推理是许多学科中发现因果关系的基础研究课题。然而，并非所有算法都同样适合给定的数据集。例如，某些方法可能只能识别线性关系，而其他方法则适用于非线性关系。算法对噪声的敏感性以及从耦合与非耦合时间序列推断因果信息的能力方面也存在差异。因此，不同的算法往往对相同的输入产生不同的因果关系。为了获得更稳健的因果推理结果，本出版物提出了一种新颖的数据驱动的两阶段多分割因果集成模型，以结合不同因果关系基础算法的优点。与现有方法相比，所提出的集成方法通过第一阶段的数据划分方案减少了噪声的影响。为了实现这一点，数据最初被分为几个分区，并将基本算法应用于每个分区。随后，使用高斯混合模型来识别从可能有效的不同分区导出的因果关系。在第二阶段，然后根据三个组合规则合并每个基本算法所识别的关系。所提出的集成方法使用多个指标进行评估，其中包括新开发的因果集成方法评估指数。我们使用三个具有不同数量和复杂度的合成数据集进行实验，这些数据集专门设计用于测试不同情况下的因果关系检测方法，同时了解真实的因果关系。在这些实验中，我们的因果集成优于其每个基本算法。在实际应用中，使用所提出的方法可以产生更稳健和可靠的因果关系结果。]]></description>
      <guid>https://arxiv.org/abs/2403.04793</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    </channel>
</rss>