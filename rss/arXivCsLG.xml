<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 05 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DEFT：通过学习广义 $h$ 变换对条件扩散模型进行有效微调</title>
      <link>https://arxiv.org/abs/2406.01781</link>
      <description><![CDATA[arXiv:2406.01781v1 公告类型：新
摘要：基于去噪扩散过程的生成建模范式已成为逆问题中条件采样的主要候选者。在许多实际应用中，我们经常可以使用大型、训练成本高昂的无条件扩散模型，我们旨在利用这些模型来改进条件采样。大多数最新方法都是启发式的，缺乏统一的框架，掩盖了它们之间的联系。此外，它们经常存在诸如对超参数非常敏感、训练成本高或需要访问隐藏在封闭 API 后面的权重等问题。在这项工作中，我们使用数学上易于理解的 Doob 的 h 变换统一条件训练和采样。这种新视角使我们能够将许多现有方法统一在一个共同的框架下。在这个框架下，我们提出了 DEFT（Doob 的 h 变换高效微调），这是一种新的条件生成方法，只需微调一个非常小的网络即可快速学习条件 $h$ 变换，同时保持较大的无条件网络不变。DEFT 比现有基线快得多，同时在各种线性和非线性基准上实现最先进的性能。在图像重建任务中，我们实现了高达 1.6$\times$ 的加速，同时在自然图像上具有最佳感知质量，在医学图像上具有重建性能。]]></description>
      <guid>https://arxiv.org/abs/2406.01781</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:13 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降如何学习特征——正则化两层神经网络的局部分析</title>
      <link>https://arxiv.org/abs/2406.01766</link>
      <description><![CDATA[arXiv:2406.01766v1 公告类型：新
摘要：学习有用特征的能力是神经网络的主要优势之一。尽管最近的研究表明神经网络可以在不允许特征学习的神经切线核 (NTK) 机制下运行，但许多研究也展示了神经网络超越 NTK 机制并执行特征学习的潜力。最近，一系列研究强调了基于梯度的训练早期阶段的特征学习能力。在本文中，我们通过局部收敛分析考虑了另一种通过梯度下降进行特征学习的机制。我们表明，一旦损失低于某个阈值，具有精心正则化目标的梯度下降将捕捉到真实方向。我们的结果表明，特征学习不仅发生在初始梯度步骤中，而且也可以在训练结束时发生。]]></description>
      <guid>https://arxiv.org/abs/2406.01766</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:12 GMT</pubDate>
    </item>
    <item>
      <title>立场：破解边缘化社区不平等现象的密码</title>
      <link>https://arxiv.org/abs/2406.01757</link>
      <description><![CDATA[arXiv:2406.01757v1 公告类型：新
摘要：基础模型的兴起为推动人工智能的发展带来了巨大的希望，但这一进展可能会加剧现有的风险和不平等，使边缘化社区落后。在这篇立场文件中，我们讨论了边缘化社区的差距——绩效、代表性、隐私、稳健性、可解释性和安全性——不是孤立的问题，而是连锁差距现象中相互关联的元素。我们将基础模型与传统模型进行对比，并强调了边缘化社区差距加剧的可能性。此外，我们强调了基础模型中连锁影响的独特威胁，其中相互关联的差距可能引发长期的负面影响，特别是对边缘人群。我们在机器学习背景下定义边缘化社区，并探讨差距的多面性。我们分析了这些差异的来源，从数据创建、培训和部署程序中进行追踪，以突出复杂的技术和社会技术格局。为了缓解紧迫的危机，我们最后呼吁大家采取行动，从源头上减轻差距。]]></description>
      <guid>https://arxiv.org/abs/2406.01757</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:11 GMT</pubDate>
    </item>
    <item>
      <title>具有兼容函数逼近的单环（自然）演员-评论家的非渐近分析</title>
      <link>https://arxiv.org/abs/2406.01762</link>
      <description><![CDATA[arXiv:2406.01762v1 公告类型：新
摘要：演员-评论家 (AC) 是强化学习中学习最佳策略的一种强大方法，其中评论家使用算法（例如，使用函数近似的时间差分 (TD) 学习）来评估当前策略，演员使用来自评论家的信息沿近似梯度方向更新策略。本文为 AC 和自然 AC (NAC) 算法提供了 \textit{最紧} 非渐近收敛界限。具体而言，现有研究表明，AC 收敛到驻点的 $\epsilon+\varepsilon_{\text{critic}}$ 邻域，其最佳样本复杂度为 $\mathcal{O}(\epsilon^{-2})$（最多为对数因子），而 NAC 收敛到全局最优的 $\epsilon+\varepsilon_{\text{critic}}+\sqrt{\varepsilon_{\text{actor}}}$ 邻域，其最佳样本复杂度为 $\mathcal{O}(\epsilon^{-3})$，其中 $\varepsilon_{\text{critic}}$ 为批评家的近似误差，$\varepsilon_{\text{actor}}$ 为参数化策略类的表达能力不足导致的近似误差。本文分析了具有兼容函数逼近的 AC 和 NAC 算法的收敛性。我们的分析将 $\varepsilon_{\text{critic}}$ 项从误差界限中消除，同时仍实现最佳已知样本复杂度。此外，我们专注于具有单个马尔可夫样本轨迹的具有挑战性的单循环设置。我们的主要技术创新在于分析了批评者中由于策略相关和时变兼容函数近似而导致的随机偏差，并处理了由于单个马尔可夫样本轨迹而导致的 MDP 的非遍历性。附录中还提供了数值结果。]]></description>
      <guid>https://arxiv.org/abs/2406.01762</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:11 GMT</pubDate>
    </item>
    <item>
      <title>优化最优加权平均值：高效分布式稀疏分类</title>
      <link>https://arxiv.org/abs/2406.01753</link>
      <description><![CDATA[arXiv:2406.01753v1 公告类型：新
摘要：虽然分布式训练通常被视为在越来越大的数据集上优化线性模型的解决方案，但随着数据维数的增加，流行的分布式方法的机器间通信成本可能占主导地位。最近对非交互式算法的研究表明，只需在机器之间进行一轮通信即可有效地获得线性模型的近似解。然而，随着机器数量的增加，这种近似值往往会退化。在本文中，我们基于最近的最优加权平均法，引入了一种新技术 ACOWA，它允许额外一轮通信以在运行时间略有增加的情况下实现明显更好的近似质量。结果表明，对于稀疏分布式逻辑回归，ACOWA 获得的解决方案更忠实于经验风险最小化器，并且比其他分布式算法具有更高的准确性。]]></description>
      <guid>https://arxiv.org/abs/2406.01753</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:10 GMT</pubDate>
    </item>
    <item>
      <title>更稀疏、更好、更深、更强：通过精确正交初始化改进稀疏训练</title>
      <link>https://arxiv.org/abs/2406.01755</link>
      <description><![CDATA[arXiv:2406.01755v1 公告类型：新
摘要：静态稀疏训练旨在从头开始训练稀疏模型，近年来取得了显著的成果。稀疏初始化给出了一个关键的设计选择，它通过二进制掩码确定可训练的子网络。现有方法主要根据预定义的密集初始化来选择此类掩码。这种方法可能无法有效地利用掩码对优化的潜在影响。受动态等距研究的启发，另一个方向是在稀疏子网络中引入正交性，这有助于稳定梯度信号。在这项工作中，我们提出了精确正交初始化 (EOI)，这是一种基于组合随机 Givens 旋转的新型稀疏正交初始化方案。与其他现有方法相反，我们的方法提供了精确（而非近似）的正交性，并能够创建具有任意密度的层。我们通过实验证明了 EOI 的卓越有效性和效率，其表现始终优于常见的稀疏初始化技术。我们的方法能够在没有残差连接或规范化技术的情况下训练高度稀疏的 1000 层 MLP 和 CNN 网络，强调权重初始化在静态稀疏训练中与稀疏掩码选择一起发挥的关键作用。代码可在 https://github.com/woocash2/sparser-better-deeper-stronger 上找到]]></description>
      <guid>https://arxiv.org/abs/2406.01755</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:10 GMT</pubDate>
    </item>
    <item>
      <title>基于联邦学习的 UTM 系统中无人机​​协作宽带频谱感知与调度</title>
      <link>https://arxiv.org/abs/2406.01727</link>
      <description><![CDATA[arXiv:2406.01727v1 公告类型：新
摘要：在本文中，我们提出了一个数据驱动的框架，用于联网无人机 (UAV) 的协作宽带频谱感知和调度，这些无人机充当次级用户 (SU)，以机会性地利用检测到的“频谱空洞”。我们的总体框架包括三个主要阶段。首先，在模型训练阶段，我们探索多小区环境中的数据集生成，并使用联邦学习 (FL) 架构训练机器学习 (ML) 模型。与现有的无线 FL 研究不同，这些研究假设数据集随时可用于训练，我们提出了一种新颖的架构，将无线数据集生成直接集成到 FL 训练过程中，这涉及从多小区环境中的无线信号中捕获 I/Q 样本。其次，在协作频谱推理阶段，我们提出了一种与无人机系统交通管理 (UTM) 生态系统兼容的协作频谱融合策略。最后，在频谱调度阶段，我们利用强化学习 (RL) 解决方案将检测到的频谱空洞动态分配给次要用户。为了评估所提出的方法，我们建立了一个综合模拟框架，该框架使用 MATLAB LTE 工具箱生成近乎真实的合成数据集，方法是在选定的感兴趣区域中合并基站 (BS) 位置、执行射线追踪并根据 I/Q 样本模拟主用户的信道使用情况。这种评估方法提供了一个灵活的框架来生成大型频谱数据集，可用于开发基于 ML/AI 的空中设备频谱管理解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.01727</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:09 GMT</pubDate>
    </item>
    <item>
      <title>学习缓存：通过层缓存加速扩散变换器</title>
      <link>https://arxiv.org/abs/2406.01733</link>
      <description><![CDATA[arXiv:2406.01733v1 公告类型：新
摘要：扩散变压器最近展示了前所未有的生成能力，可用于各种任务。然而，令人鼓舞的结果是以推理速度慢为代价的，因为每个去噪步骤都需要对具有大量参数的变压器模型进行推理。在这项研究中，我们做出了一个有趣且令人惊讶的观察：通过引入缓存机制，即使不更新模型参数，也可以轻松删除扩散变压器中很大一部分层的计算。例如，在 U-ViT-H/2 的情况下，我们可以删除缓存步骤中高达 93.68% 的计算（所有步骤为 46.84%），而 FID 下降不到 0.01。为了实现这一点，我们引入了一种名为学习缓存 (L2C) 的新方案，该方案学习以动态方式为扩散变压器进行缓存。具体来说，通过利用 Transformer 中相同的层结构和扩散的顺序性，我们将每层视为缓存的基本单位，探索时间步之间的冗余计算。为了解决深度模型中用于识别要缓存和删除的层的指数搜索空间的挑战，我们提出了一种新颖的可微分优化目标。然后优化输入不变但时间步变化的路由器，最终可以生成静态计算图。实验结果表明，在相同的推理速度下，L2C 的性能大大优于 DDIM 和 DPM-Solver 等采样器以及先前的基于缓存的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.01733</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:09 GMT</pubDate>
    </item>
    <item>
      <title>自我改进的稳健偏好优化</title>
      <link>https://arxiv.org/abs/2406.01660</link>
      <description><![CDATA[arXiv:2406.01660v2 公告类型：新
摘要：在线和离线 RLHF 方法（例如 PPO 和 DPO）在将 AI 与人类偏好相结合方面都非常成功。尽管取得了成功，但现有方法存在一个根本问题，即其最优解高度依赖于任务（即对分布外 (OOD) 任务不具有鲁棒性）。在这里，我们通过提出自我改进的鲁棒偏好优化 SRPO 来解决这一挑战，这是一个实用且数学原理化的离线 RLHF 框架，对任务的变化具有完全的鲁棒性。SRPO 的关键思想是将从人类偏好中学习的问题转化为自我改进过程，可以用最小-最大目标在数学上表示，旨在以对抗方式联合优化自我改进策略和生成策略。这个优化问题的解决方案与训练任务无关，因此它对其变化具有鲁棒性。然后，我们展示了该目标可以以非对抗性离线损失的形式重新表达，可以使用标准监督优化技术进行大规模优化，而无需任何奖励模型和在线推理。我们展示了 SRPO 在 AI 胜率 (WR) 方面相对于人类 (GOLD) 完成的有效性。特别是，当在 OOD XSUM 数据集上评估 SRPO 时，它在 5 次自我修订后以 15% 的明显优势超越了著名的 DPO，实现了 90% 的 WR。]]></description>
      <guid>https://arxiv.org/abs/2406.01660</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:08 GMT</pubDate>
    </item>
    <item>
      <title>无监督神经组合优化的扩散模型框架</title>
      <link>https://arxiv.org/abs/2406.01661</link>
      <description><![CDATA[arXiv:2406.01661v1 公告类型：新
摘要：学习从离散集上的难处理分布中进行采样而不依赖于相应的训练数据是包括组合优化在内的广泛领域的核心问题。目前，流行的基于深度学习的方法主要依赖于产生精确样本似然的生成模型。这项工作引入了一种解除此限制的方法，并为使用扩散模型等高度表达的隐变量模型提供了可能性。我们的方法在概念上基于一个上限为反向 Kullback-Leibler 散度的损失，并避免了对精确样本似然的要求。我们在无数据组合优化中通过实验验证了我们的方法，并证明我们的方法在广泛的基准问题上取得了新的领先水平。]]></description>
      <guid>https://arxiv.org/abs/2406.01661</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:08 GMT</pubDate>
    </item>
    <item>
      <title>具有输出约束的学习算法的统一公式分析</title>
      <link>https://arxiv.org/abs/2406.01647</link>
      <description><![CDATA[arXiv:2406.01647v1 公告类型：新
摘要：神经网络 (NN) 在不同的任务中表现良好，但有时会产生对人类毫无意义的结果。大多数 NN 模型“仅”从（输入、输出）对中学习，偶尔会与人类知识相冲突。许多研究表明，通过在训练期间减少输出约束来注入人类知识可以提高模型性能并减少约束违规。虽然已经多次尝试在相同的编程框架下比较不同的现有算法，但之前还没有统一的工作对具有输出约束的学习算法进行分类。我们的贡献如下：（1）我们根据三个轴对以前的研究进行分类：使用的约束损失类型（例如概率软逻辑、REINFORCE）、约束违规示例的探索策略以及来自主要任务和约束的学习信号的集成机制。（2）我们提出了新的算法来整合主要任务和约束注入的信息，受到持续学习算法的启发。 (3) 此外，我们提出了 $H\beta$ 分数作为同时考虑主要任务指标和约束违反的指标。为了提供全面的分析，我们检查了三个 NLP 任务上的所有算法：自然语言推理 (NLI)、合成传导示例 (STE) 和语义角色标记 (SRL)。我们探索并揭示了与实现高 $H\beta$ 分数相关的各种算法的关键因素。]]></description>
      <guid>https://arxiv.org/abs/2406.01647</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:07 GMT</pubDate>
    </item>
    <item>
      <title>CoLa-DCE——概念引导的潜在扩散反事实解释</title>
      <link>https://arxiv.org/abs/2406.01649</link>
      <description><![CDATA[arXiv:2406.01649v1 公告类型：新
摘要：生成式人工智能的最新进展带来了新的前景和实际实现。特别是扩散模型在生成多样化且同时具有真实性的特征方面表现出色，非常适合为计算机视觉模型生成反事实解释。回答“如果”问题，即需要改变什么才能使图像分类器改变其预测，反事实解释与人类理解非常吻合，因此有助于使模型行为更易于理解。当前的方法成功地生成了真实的反事实，但缺乏透明度，因为特征变化无法直接感知。为了解决这一限制，我们引入了概念引导的潜在扩散反事实解释 (CoLa-DCE)。CoLa-DCE 为任何分类器生成概念引导的反事实，对概念选择和空间条件具有高度控制。反事实通过最小的特征变化包含更大的粒度。参考特征可视化确保了更好的可理解性，而特征定位则提高了“哪里”改变了“什么”的透明度。我们展示了我们的方法在多个图像分类模型和数据集中在简洁性和可理解性方面的优势，并深入了解了我们的 CoLa-DCE 解释如何帮助理解模型错误（如错误分类情况）。]]></description>
      <guid>https://arxiv.org/abs/2406.01649</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:07 GMT</pubDate>
    </item>
    <item>
      <title>FNP：用于任意分辨率数据同化的傅里叶神经过程</title>
      <link>https://arxiv.org/abs/2406.01645</link>
      <description><![CDATA[arXiv:2406.01645v1 公告类型：新
摘要：数据同化是现代全球中期天气预报系统中的重要组成部分，通过结合短期预报和观测来获得对大气状态的最佳估计。最近，基于人工智能的数据同化方法因其在计算消耗方面比传统技术具有显著优势而受到越来越多的关注。然而，现有的基于人工智能的数据同化方法只能处理具有特定分辨率的观测，缺乏与其他分辨率观测同化的兼容性和泛化能力。考虑到复杂的现实世界观测通常具有不同的分辨率，我们在本文中提出了用于\textit{任意分辨率数据同化的}的\textit{\textbf{傅里叶神经过程}} (FNP)。利用设计模块的效率和神经过程的灵活结构，FNP 在同化不同分辨率的观测数据方面取得了最佳成果，并且随着分辨率和观测数据的增加，其优势也越来越明显。此外，我们在固定分辨率上训练的 FNP 可以直接处理分布外分辨率观测数据的同化和观测信息重建任务，而无需进行额外的微调，从而展示了其在数据分辨率和任务之间的出色泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2406.01645</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>iKAN：利用 KAN 进行全局增量学习，跨异构数据集实现人类活动识别</title>
      <link>https://arxiv.org/abs/2406.01646</link>
      <description><![CDATA[arXiv:2406.01646v1 公告类型：新
摘要：这项工作提出了一种用于可穿戴传感器人类活动识别 (HAR) 的增量学习 (IL) 框架，可同时解决两个挑战：灾难性遗忘和非均匀输入。可扩展框架 iKAN 率先使用 Kolmogorov-Arnold 网络 (KAN) 取代多层感知器作为分类器，利用样条的局部可塑性和全局稳定性。为了使 KAN 适应 HAR，iKAN 使用了特定于任务的特征分支和特征重新分配层。与主要调整输出维度或分类器节点数量以适应新任务的现有 IL 方法不同，iKAN 专注于扩展特征提取分支以适应来自不同传感器模式的新输入，同时保持一致的维度和分类器输出数量。在六个公共 HAR 数据集上的持续学习展示了 iKAN 框架的增量学习性能，最终性能为 84.9\%（加权 F1 分数），平均增量性能为 81.34\%，明显优于现有的两种增量学习方法，如 EWC（51.42\%）和经验重放（59.92\%）。]]></description>
      <guid>https://arxiv.org/abs/2406.01646</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>TimeCMA：通过跨模态对齐实现 LLM 支持的时间序列预测</title>
      <link>https://arxiv.org/abs/2406.01638</link>
      <description><![CDATA[arXiv:2406.01638v1 公告类型：新
摘要：可扩展移动传感的广泛采用为实际应用带来了大量时间序列数据。一个基本应用是多元时间序列预测 (MTSF)，旨在根据历史观察预测未来的时间序列值。现有的 MTSF 方法存在参数化有限和训练数据规模小的问题。最近，时间序列中引入了大型语言模型 (LLM)，它们实现了良好的预测性能，但计算成本很高。为了解决这些挑战，我们提出了 TimeCMA，这是一个基于 LLM 的跨模态对齐时间序列预测框架。我们设计了一个具有两个分支的双模态编码模块，其中时间序列编码分支通过倒置 Transformer 提取相对低质量但纯净的时间序列嵌入。此外，LLM 赋能的编码分支将相同的时间序列包装为提示，以通过预训练的 LLM 获得高质量但纠缠的提示嵌入。然后，我们设计了一个跨模态对齐模块，以从提示嵌入中检索高质量和纯时间序列嵌入。此外，我们开发了一个时间序列预测模块来解码对齐的嵌入，同时捕获多个变量之间的依赖关系以进行预测。值得注意的是，我们定制提示以将足够的时间信息编码到最后一个标记中，并设计最后一个标记嵌入存储以降低计算成本。对真实数据的大量实验可以深入了解所提框架的准确性和效率。]]></description>
      <guid>https://arxiv.org/abs/2406.01638</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:05 GMT</pubDate>
    </item>
    </channel>
</rss>