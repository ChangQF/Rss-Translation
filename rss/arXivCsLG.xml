<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 16 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>自信预测，正确预测：动态图学习中的弃权</title>
      <link>https://arxiv.org/abs/2501.08397</link>
      <description><![CDATA[arXiv:2501.08397v1 公告类型：新
摘要：许多现实世界的系统可以建模为动态图，其中节点和边会随着时间的推移而演变，需要专门的模型来有效捕捉它们在风险敏感应用中的演变动态。时间图神经网络 (GNN) 就是这样一种专门的模型。我们的方法首次在 GNN 框架内集成了拒绝选项策略，用于连续时间动态图。这允许模型在不确定性高且置信度低时策略性地放弃进行预测，从而最大限度地降低严重错误分类的风险并提高结果和可靠性。我们提出了一种基于覆盖范围的弃权预测模型来实现拒绝选项，该选项可在指定的覆盖范围内最大化预测。它提高了链接预测和节点分类任务的预测分数。时间 GNN 处理极度倾斜的数据集以进行下一个状态预测或节点分类任务。在类别不平衡的情况下，可以进一步调整我们的方法，为少数类提供更高的权重。在四个动态链接预测数据集和两个动态节点分类任务数据集上进行了详尽的实验。这证明了我们的方法在提高动态图场景中预测的可靠性和曲线下面积 (AUC)/平均精度 (AP) 得分方面的有效性。结果突出了我们的模型能够有效地处理预测置信度和覆盖率之间的权衡，使其成为在动态和不确定环境中需要高精度的应用程序的可靠解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.08397</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双向深度多模态神经网络：用于时空预测的双向深度深度学习架构</title>
      <link>https://arxiv.org/abs/2501.08411</link>
      <description><![CDATA[arXiv:2501.08411v1 公告类型：新
摘要：准确预测动态系统（例如城市流动性和天气模式）中的时空 (ST) 信息是一个至关重要但具有挑战性的问题。复杂性源于空间接近性和时间相关性之间错综复杂的相互作用，其中长期趋势和短期波动都以复杂的模式存在。现有方法（包括传统统计方法和传统神经网络）可能会提供不准确的结果，因为缺乏有效的机制来同时整合可变时间深度的信息并保持空间背景，从而导致全面的长期历史分析和对短期新信息的响应之间的权衡。为了弥补这一差距，本文提出了具有双向深度调制的双向多模态神经网络 (BDMNN)，可以全面了解长期季节性和短期波动，适应复杂的 ST 背景。使用真实世界公共数据的案例研究表明，预测准确度显著提高，与最先进的基准相比，城市交通预测的平均平方误差降低了 12%，降雨量预测提高了 15%，而且不需要额外的计算资源。]]></description>
      <guid>https://arxiv.org/abs/2501.08411</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 CVaR 的变分量子优化在切换感知车辆网络中的用户关联</title>
      <link>https://arxiv.org/abs/2501.08418</link>
      <description><![CDATA[arXiv:2501.08418v1 公告类型：新
摘要：高效的资源分配对于优化无线网络中的各种任务至关重要，这些任务通常被表述为广义分配问题 (GAP)。GAP 作为线性和分配问题的广义版本，涉及相等和不等式约束，这增加了计算挑战。在这项工作中，我们提出了一种基于条件风险价值 (CVaR) 的新型变分量子特征求解器 (VQE) 框架来解决车载网络 (VNets) 中的 GAP。我们的方法利用混合量子经典结构，集成了一个量身定制的成本函数，该函数平衡了目标和约束特定的惩罚，以提高解决方案的质量和稳定性。使用 CVaR-VQE 模型，我们通过将优化重点放在解决方案空间的下尾来有效地处理 GAP，从而增强了嘈杂的中型量子 (NISQ) 设备的收敛性和弹性。我们将该框架应用于 VNet 中的用户关联问题，与深度神经网络 (DNN) 方法相比，我们的方法实现了 23.5% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2501.08418</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机梯度下降有效吗？机器学习过程的 PDE 视角</title>
      <link>https://arxiv.org/abs/2501.08425</link>
      <description><![CDATA[arXiv:2501.08425v1 公告类型：新
摘要：在本文中，我们分析了随机梯度下降 (SGD) 的行为，这是一种在监督学习中广泛使用的方法，用于通过最小化非凸损失函数来优化神经网络权重。自 E、Li 和 Tai (2017) 的开创性工作以来，此类过程的底层结构可以通过 Fokker-Planck 类型的抛物线 PDE 来理解，这是我们分析的核心。即使 Fokker-Planck 方程历史悠久且文献丰富，但当势能非凸或扩散矩阵退化时，我们几乎一无所知，这是我们在分析中面临的主要困难。
我们确定了两种不同的状态：在 SGD 的初始阶段，损失函数驱动权重集中在最近的局部最小值附近。我们将此阶段称为漂移状态，并对这种集中现象提供定量估计。接下来，我们介绍扩散机制，其中随机波动有助于学习过程摆脱次优局部最小值。我们分析平均退出时间 (MET) 并证明 MET 的上限和下限。最后，我们解决了非凸成本函数和退化扩散矩阵的 SGD 渐近收敛问题，这不允许使用标准方法，需要新技术。为此，我们利用了两种不同的方法：对偶方法和熵方法。
我们提供了有关 SGD 动态和有效性的新结果，提供了随机优化和 PDE 理论之间的深层联系，以及机器学习过程中一些基本问题的答案和见解：SGD 需要多长时间才能摆脱不良最小值？神经网络参数是否使用 SGD 收敛？在使用 SGD 进行训练的第一阶段，参数如何演变？]]></description>
      <guid>https://arxiv.org/abs/2501.08425</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测因子的因果与非因果合并</title>
      <link>https://arxiv.org/abs/2501.08426</link>
      <description><![CDATA[arXiv:2501.08426v1 公告类型：新
摘要：我们研究使用相同数据在因果和反因果方向上合并预测因子所产生的差异。特别是，我们研究在简单模型中出现的不对称性，在该模型中，我们使用一个二元变量作为目标，两个连续变量作为预测因子来合并预测因子。我们使用因果最大熵 (CMAXENT) 作为归纳偏差来合并预测因子，但是，我们预计当我们使用其他考虑因果之间不对称的合并方法时，也会出现类似的差异。我们表明，如果我们观察所有双变量分布，CMAXENT 解决方案在因果方向上会简化为逻辑回归，在反因果方向上会简化为线性判别分析 (LDA)。此外，我们研究了当我们仅观察到一些双变量分布对变量外 (OOV) 泛化的影响时，这两个解决方案的决策边界如何不同。]]></description>
      <guid>https://arxiv.org/abs/2501.08426</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于实时预测复杂物理系统的物理信息潜在神经算子</title>
      <link>https://arxiv.org/abs/2501.08428</link>
      <description><![CDATA[arXiv:2501.08428v1 公告类型：新
摘要：深度算子网络 (DeepONet) 作为由偏微分方程 (PDE) 控制的系统的替代模型，表现出巨大的潜力，可以高精度地学习无限维函数空间之间的映射。然而，实现低泛化误差通常需要高度过度参数化的网络，这对大规模复杂系统构成了重大挑战。为了应对这些挑战，提出了潜在的 DeepONet，引入了一种两步方法：首先，使用降阶模型来学习低维潜在空间，然后在这个潜在空间上进行算子学习。虽然有效，但这种方法本质上是数据驱动的，依赖于大型数据集，很难将控制物理纳入框架。此外，这些步骤的解耦性质阻碍了端到端优化和处理数据稀缺的能力。这项工作引入了 PI-Latent-NO，这是一个基于物理的潜在算子学习框架，可以克服这些限制。我们的架构在端到端训练方案中采用了两个耦合的 DeepONet：第一个称为 Latent-DeepONet，用于识别和学习低维潜在空间，而第二个称为 Reconstruction-DeepONet，用于将潜在表示映射回原始物理空间。通过将控制物理直接集成到训练过程中，我们的方法需要的数据样本显著减少，同时实现高精度。此外，该框架在计算和内存方面非常高效，在单个 GPU 上表现出几乎恒定的扩展行为，并展示了通过分布式训练进一步提高效率的潜力。我们在高维参数 PDE 上验证了所提出的方法，证明了其作为概念证明的有效性及其对大规模系统的潜在可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2501.08428</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于相位分辨数据同化和非线性海浪预测的物理信息神经网络</title>
      <link>https://arxiv.org/abs/2501.08430</link>
      <description><![CDATA[arXiv:2501.08430v1 公告类型：新
摘要：相位分辨表面重力波的同化和预测是海洋科学和工程中的关键挑战。势流理论 (PFT) 已被广泛用于开发波浪模型和波浪预测的数值技术。然而，传统的波浪预测方法往往受到限制。例如，大多数简化的波浪模型捕捉强波非线性的能力有限，而完全非线性 PFT 求解器通常无法满足工程应用的速度要求。这种计算效率低下也阻碍了有效数据同化技术的发展，这些技术需要从稀疏测量中重建空间波信息以初始化波浪预测。为了应对这些挑战，我们提出了一种新颖的求解器方法，该方法利用物理信息神经网络 (PINN)，将 PFT 解决方案参数化为神经网络。这提供了一种计算成本低廉的同化和预测波浪数据的方法。通过与解析线性 PFT 解决方案和在实验室波浪水槽中收集的实验数据进行比较，验证了所提出的 PINN 框架。结果表明，我们的方法可以准确捕捉和预测不规则、非线性和色散性波浪表面动力学。此外，PINN 可以仅通过表面高程测量推断出整个流体体积的完全非线性速度势，从而能够计算难以通过实验测量的流体速度。]]></description>
      <guid>https://arxiv.org/abs/2501.08430</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Keras Sig：Keras 3 中 GPU 上的高效路径签名计算</title>
      <link>https://arxiv.org/abs/2501.08455</link>
      <description><![CDATA[arXiv:2501.08455v1 公告类型：新
摘要：在本文中，我们介绍了 Keras Sig，这是一个高性能的 Python 库，旨在为深度学习应用程序计算路径签名。\textit{Keras Sig} 完全基于 Keras 3 构建，可与最常用的深度学习后端（如 PyTorch、JAX 和 TensorFlow）无缝集成。受 Kidger 和 Lyons (2021) 的启发，我们提出了一种新方法，重塑签名计算以利用 GPU 并行性。与现有方法相比，这种调整使我们能够将训练时间缩短 55\%，并将直接签名计算提高 5 到 10 倍，同时保持相似的 CPU 性能。依靠高级张量运算而不是低级 C++ 代码，Keras Sig 显着减少了深度学习库中常见的版本控制和兼容性问题，同时在各种硬件配置中提供卓越或可比的性能。我们通过广泛的基准测试证明，我们的方法可以随着输入序列的长度有效地扩展，并在各种签名参数中保持有竞争力的性能，尽管受到非常大的签名维度的内存限制。]]></description>
      <guid>https://arxiv.org/abs/2501.08455</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在数字孪生中使用 GAN 和 BiLSTM 对多维遥测数据进行时间序列预测</title>
      <link>https://arxiv.org/abs/2501.08464</link>
      <description><![CDATA[arXiv:2501.08464v1 公告类型：新
摘要：近年来，与数字孪生相关的研究不断增加。除了将物理世界镜像到数字世界之外，还需要提供与收集并传输到虚拟世界的数据相关的服务。这些服务之一是预测物理部件的未来行为，这可能导致应用，例如防止有害事件或设计改进以获得更好的性能。用于预测任何系统操作的一种策略是使用 ARIMA 或 LSTM 等时间序列模型，并使用这些算法实现改进。最近，基于生成模型（如生成对抗网络 (GAN)）的深度学习技术已被提出来创建时间序列，并且 LSTM 的使用在时间序列预测中获得了更大的相关性，但两者都有限制预测结果的局限性。文献中发现的另一个问题是处理时间序列生成中的多变量环境/应用程序的挑战。因此，需要研究新方法来填补这些空白，从而为创建有用的数字孪生提供更好的资源。在本提案中，将研究 BiLSTM 层与 GAN 获得的时间序列的集成，以提高对数据集提供的所有特征的预测准确性，从而改善行为预测。]]></description>
      <guid>https://arxiv.org/abs/2501.08464</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索元学习的功效：揭示 MAML 相对于预训练的卓越数据多样性利用率</title>
      <link>https://arxiv.org/abs/2501.08506</link>
      <description><![CDATA[arXiv:2501.08506v1 公告类型：新
摘要：目前，数据和模型大小在超大型、强大模型的训练中占据主导地位。然而，对训练数据集的其他属性对模型性能的影响的探索还很缺乏。我们假设数据集多样性会影响视觉模型的性能。我们的研究表明测试集准确率和数据多样性之间存在正相关关系，这为进一步研究大小以外的数据集属性提供了论据。我们分析了 12 个流行视觉数据集（例如 Omniglot、CIFAR-FS、Aircraft）和 5 种模型配置上的预训练和模型无关元学习方法，包括具有不同数量内部梯度步骤和监督学习的 MAML 变体。我们表明准确率和数据多样性之间存在中等到强的正相关性（R 平方：0.15-0.42），损失和多样性之间存在较弱但显着的相关性（R 平方：~0.2）。这些发现支持了我们的假设，并展示了一种有希望的方法来更深入地探索形式数据多样性如何影响模型性能。这项初步研究强调了（Task2Vec）数据多样性作为快速发展的大规模学习领域中一项有价值的衡量标准的潜力，并强调了解数据集是构建更强大、更通用的模型的关键。]]></description>
      <guid>https://arxiv.org/abs/2501.08506</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于分数的神经场三维分子生成</title>
      <link>https://arxiv.org/abs/2501.08508</link>
      <description><![CDATA[arXiv:2501.08508v1 公告类型：新
摘要：我们根据连续原子密度场为 3D 分子引入了一种新表示。利用这种表示，我们提出了一种基于行走-跳跃采样的新模型，用于使用神经场在连续空间中无条件生成 3D 分子。我们的模型 FuncMol 使用条件神经场将分子场编码为潜在代码，使用朗之万 MCMC 从高斯平滑分布中采样噪声代码（行走），一步去噪这些样本（跳跃），最后将它们解码为分子场。与大多数方法不同，FuncMol 无需对分子结构进行假设即可执行 3D 分子的全原子生成，并且可以很好地随分子大小扩展。我们的方法在类药物分子上取得了有竞争力的结果，并且可以轻松扩展到大环肽，采样速度至少快一个数量级。代码可在 https://github.com/prescient-design/funcmol 获得。]]></description>
      <guid>https://arxiv.org/abs/2501.08508</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习超平面树：分段线性且完全可解释的决策框架</title>
      <link>https://arxiv.org/abs/2501.08515</link>
      <description><![CDATA[arXiv:2501.08515v1 公告类型：新
摘要：本文介绍了一种基于树的新型模型，即学习超平面树 (LHT)，该模型在多个公共数据集上的分类任务中优于最先进的 (SOTA) 树模型。LHT 的结构简单而高效：它使用多个超平面对数据进行分区，以逐步区分目标和非目标类样本。尽管每个阶段的分离并不完美，但 LHT 通过连续分区有效地提高了区分度。在测试期间，通过评估分支块中定义的超平面并向下遍历树直到到达相应的叶块来对样本进行分类。然后使用叶块中定义的分段线性成员函数确定测试样本的类别，该函数是通过最小二乘拟合和模糊逻辑得出的。LHT 具有高度透明性和可解释性——在每个分支块中，可以清楚地观察到每个特征对分类的贡献。]]></description>
      <guid>https://arxiv.org/abs/2501.08515</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过域内和域间原型缓解联邦学习中的域转移</title>
      <link>https://arxiv.org/abs/2501.08521</link>
      <description><![CDATA[arXiv:2501.08521v1 公告类型：新
摘要：联邦学习 (FL) 已成为一种分散的机器学习技术，允许客户端协作训练全局模型而无需共享私人数据。然而，大多数 FL 研究都忽略了异构域的关键挑战，其中每个客户端都有不同的特征分布，这在现实世界中很常见。原型学习利用同一类中的平均特征向量，已成为域倾斜下联邦学习的主要解决方案。然而，现有的联邦原型学习方法仅考虑服务器上的域间原型，而忽略了域内特征。在这项工作中，我们引入了一种新颖的联邦原型学习方法，即 I$^2$PFL，它结合了 $\textbf{I}$ntra-domain 和 $\textbf{I}$nter-domain $\textbf{P}$rototypes，以缓解域转移并在联邦学习中跨多个域学习通用全局模型。为了构建域内原型，我们提出了使用基于 MixUp 的增强原型进行特征对齐，以捕捉局部域的多样性并增强局部特征的泛化。此外，我们引入了域间原型的重新加权机制，以生成广义原型，从而提供域间知识并减少跨多个客户端的域偏差。在 Digits、Office-10 和 PACS 数据集上进行的大量实验表明，与其他基线相比，我们的方法具有卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.08521</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>同质性感知的异构图对比学习</title>
      <link>https://arxiv.org/abs/2501.08538</link>
      <description><![CDATA[arXiv:2501.08538v1 公告类型：新
摘要：异构图预训练 (HGP) 在各个领域都表现出色。然而，现实世界的异构图 (HG) 中的异质性问题在很大程度上被忽视了。为了弥补这一研究空白，我们提出了一种新的异构图对比学习框架，称为 HGMS，它利用连接强度和多视图自我表达来学习同质节点表示。具体来说，我们设计了一种异构边丢弃增强策略，以增强增强视图的同质性。此外，我们引入了一种多视图自我表达学习方法来推断节点之间的同质性。在实践中，我们开发了两种方法来解决自我表达矩阵。求解后的自我表达矩阵作为额外的增强视图来提供同质信息，并用于识别对比损失中的假阴性。大量实验结果证明了 HGMS 在不同的下游任务中的优势。]]></description>
      <guid>https://arxiv.org/abs/2501.08538</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有倒置多索引的自适应采样 Softmax：方法、理论和应用</title>
      <link>https://arxiv.org/abs/2501.08563</link>
      <description><![CDATA[arXiv:2501.08563v1 公告类型：新
摘要：softmax 函数是多类分类的基石，是各种机器学习应用不可或缺的部分，从大规模检索和排名模型到高级大型语言模型。然而，它的计算成本随着类别数量的增加而线性增长，在具有数百万甚至数十亿个类别的场景中，成本变得非常高昂。依赖于自归一化重要性抽样的抽样 softmax 已成为一种强大的替代方案，可显著降低计算复杂度。然而，只有当抽样分布与真正的 softmax 分布匹配时，其估计量才会保持无偏。为了提高近似精度和抽样效率，我们提出了 MIDX 抽样器，这是​​一种基于倒置多指标方法的新型自适应抽样策略。具体来说，我们将 softmax 概率分解为几个多项式概率，每个概率与一组特定的代码字相关联，最后一个与查询的残差分数相关联，从而将时间复杂度降低到代码字的数量而不是类的数量。为了进一步提高效率，我们用简单的均匀分布替换特定于查询的残差概率，简化计算同时保持高性能。我们的方法有严格的理论分析作为后盾，解决了采样偏差、梯度偏差、收敛速度和泛化误差界限等关键问题。结果表明，与理想 softmax 分布的偏差越小，收敛速度越快，泛化能力越强。在大规模语言模型、顺序推荐器和极端多类分类任务上进行的大量实验证实，与现有方法相比，MIDX-Sampler 具有卓越的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2501.08563</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>