<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 03 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在代理中创建需求的层次化配置</title>
      <link>https://arxiv.org/abs/2412.00044</link>
      <description><![CDATA[arXiv:2412.00044v1 公告类型：新
摘要：我们提出了一种学习分层抽象的新方法，该方法优先考虑竞争目标，从而提高全局预期奖励。我们的方法采用了具有多个标量输出的二级奖励代理，每个输出都与不同的抽象级别相关联。然后，传统代理学习以分层方式最大化这些输出，每个级别都取决于前一个级别的最大化。我们推导出一个方程，按优先级对这些标量值和全局奖励进行排序，从而得出一个需求层次结构，为目标的形成提供信息。在 Pendulum v1 环境中的实验结果与基线实现相比表现出卓越的性能。我们取得了最先进的成果。]]></description>
      <guid>https://arxiv.org/abs/2412.00044</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransFair：将公平性从眼部疾病分类转移到进展预测</title>
      <link>https://arxiv.org/abs/2412.00051</link>
      <description><![CDATA[arXiv:2412.00051v1 公告类型：新
摘要：人工智能 (AI) 在自动疾病分类中的应用显著降低了医疗成本并提高了服务的可及性。然而，这种转变引起了人们对人工智能公平性的担忧，它对某些群体，特别是来自贫困人口的患者产生了不成比例的影响。最近，已经提出了许多方法和大规模数据集来解决群体表现差异。虽然这些方法在疾病分类任务中表现出了有效性，但它们可能无法确保公平地预测疾病进展，主要是因为可用于训练稳健且公平的预测模型的纵向数据有限且人口统计数据多样。在本文中，我们引入了 TransFair 来增强眼部疾病进展预测的人口公平性。TransFair 旨在将公平性增强的疾病分类模型转移到进展预测任务中，同时保持公平性。具体来说，我们使用大量数据训练一个公平的 EfficientNet，称为 FairEN，它配备了公平意识注意力机制，用于眼部疾病分类。随后，通过知识提炼，将此公平分类模型调整为公平进展预测模型，旨在最小化分类和进展预测模型之间的潜在特征距离。我们使用二维 (2D) 和 3D 视网膜图像评估 FairEN 和 TransFair 在公平性增强型眼部疾病分类和进展预测方面的表现。大量实验以及考虑和不考虑公平学习的模型的比较表明，TransFair 可有效增强预测眼部疾病进展的人口公平性。]]></description>
      <guid>https://arxiv.org/abs/2412.00051</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LeMoLE：用于时间序列预测的 LLM 增强型线性专家组合</title>
      <link>https://arxiv.org/abs/2412.00053</link>
      <description><![CDATA[arXiv:2412.00053v1 公告类型：新
摘要：最近的研究表明，大型语言模型 (LLM) 因其强大的自然语言理解能力而可有效用于现实世界的时间序列预测。然而，将时间序列对齐到 LLM 的语义空间会带来高计算成本和推理复杂性，特别是对于长距离时间序列生成。基于最近使用线性模型进行时间序列预测的进展，本文介绍了一种 LLM 增强的线性专家混合模型，用于精确高效的时间序列预测。这种方法涉及开发具有多个回溯长度的线性专家混合模型和一种新的多模态融合机制。由于使用线性专家混合模型的简单性，因此效率较高，而多模态融合机制则根据从预训练的大型语言模型中学习到的文本模态特征自适应地组合多个线性专家。在实验中，我们重新思考了现有时间序列大型语言模型将时间序列与 LLM 对齐的必要性，并进一步讨论了它们在时间序列预测中的效率和有效性。我们的实验结果表明，与现有的 LLM 模型相比，提出的 LeMoLE 模型具有更低的预测误差和更高的计算效率。]]></description>
      <guid>https://arxiv.org/abs/2412.00053</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少即是多：通过二进制任务切换实现高效模型合并</title>
      <link>https://arxiv.org/abs/2412.00054</link>
      <description><![CDATA[arXiv:2412.00054v1 公告类型：新
摘要：作为一种无需额外训练即可使模型具备多任务能力的有效方法，模型合并引起了广泛关注。然而，现有方法面临着冗余参数冲突和参数存储负担过重的挑战。在本文中，通过控制实验，我们发现对于任务向量，只有那些幅度超过一定阈值的参数才会对任务产生正向贡献，表现出脉冲状特性。然后我们尝试利用此特性对任务向量进行二值化并减少存储开销。进一步的对照实验表明，二值化的任务向量几乎不会导致微调和合并性能的下降，甚至随着冗余参数比例的增加表现出更强的性能提升。基于这些见解，我们提出了任务切换（T-Switch），它将任务向量分解为三个部分：1）由二值化掩码向量实例化的激活开关，2）由二值化符号向量实例化的极性开关，3）由标量系数实例化的缩放旋钮。通过以二值化形式存储任务向量，T-Switch 缓解了参数冲突，同时确保了高效的任务参数存储。此外，为了在 T-Switch 中实现自动开关组合，我们进一步引入了自动切换，它通过从小型查询集中检索来实现无需训练的开关组合。实验表明，我们的方法比现有基线实现了显着的性能改进，仅需要全精度参数存储空间的 1-3％。]]></description>
      <guid>https://arxiv.org/abs/2412.00054</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>拟牛顿法的自适应坐标步长：一种学习优化方法</title>
      <link>https://arxiv.org/abs/2412.00059</link>
      <description><![CDATA[arXiv:2412.00059v1 公告类型：新
摘要：调整有效步长对于优化算法的稳定性和效率至关重要。虽然已经在一阶方法中探索了自适应坐标步长调整方法，但二阶方法仍然缺乏有效的技术。当前的方法，包括超梯度下降和切割平面方法，在二阶环境中提供的改进有限或遇到困难。为了应对这些挑战，我们在 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 框架内引入了一种新颖的学习优化 (L2O) 模型，该模型利用神经网络来预测最佳坐标步长。我们的模型整合了一个理论基础，为这些步长的稳定性和收敛建立了条件。大量实验表明，我们的方法比传统的回溯线搜索和基于超梯度下降的方法有了显着的改进，在各种优化任务中提供高达 7$\times$ 的速度和稳定性。]]></description>
      <guid>https://arxiv.org/abs/2412.00059</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 CTC 的草案模型进行推测解码以实现 LLM 推理加速</title>
      <link>https://arxiv.org/abs/2412.00061</link>
      <description><![CDATA[arXiv:2412.00061v1 Announce Type: new 
摘要：大型语言模型（LLM）的推理加速已在许多应用场景中被提出，推测解码在解决推理加速方面显示出其优势。推测解码通常引入草稿模型来辅助基础LLM，草稿模型生成草稿，基础LLM验证草稿以接受或拒绝。在该框架中，最终的推理速度由草稿模型的解码速度和草稿模型提供的草稿接受率决定。目前广泛使用的草稿模型通常以非自回归的方式为接下来的几个位置生成草稿token，而不考虑草稿token之间的相关性。因此，它具有较高的解码速度，但接受率不尽如人意。在本文中，我们关注如何提高草稿模型的性能，旨在通过高接受率来加速推理。为此，我们提出了一种基于 CTC 的选秀模型，在选秀阶段加强选秀 token 之间的相关性，从而生成更高质量的选秀候选序列。实验结果表明，与强基线相比，该方法可以实现更高的接受率，从而加快推理速度。]]></description>
      <guid>https://arxiv.org/abs/2412.00061</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的批发电力市场虚拟竞价电价预测</title>
      <link>https://arxiv.org/abs/2412.00062</link>
      <description><![CDATA[arXiv:2412.00062v1 公告类型：新 
摘要：虚拟竞价在双结算电力市场中发挥着重要作用，因为它可以减少日前市场和实时市场之间的差异。可再生能源的渗透增加了电价的波动性，准确预测对于虚拟竞标者至关重要，可以减少不确定性并实现利润最大化。本研究提出了一种基于 Transformer 的深度学习模型来预测 ERCOT（德克萨斯州电力可靠性委员会）市场中实时电价和日前电价之间的价差。所提出的模型利用各种时间序列特征，包括负荷预测、太阳能和风能发电预测以及时间属性。该模型在现实约束下进行训练，并使用步进方法通过每周更新模型进行验证。根据价差预测结果，提出了几种交易策略，并通过回测确定了在现实市场条件下最大化累积利润的最有效策略。结果表明，仅在高峰时段进行交易且准确率超过 50% 的策略在测试期间产生了几乎一致的利润。所提出的方法强调了准确的电价预测模型的重要性，并引入了一种从虚拟投标人的角度评估价格预测模型的新方法，为未来的研究提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.00062</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>压缩而不仅仅是修剪：提高 MoE 层修剪的效率和性能</title>
      <link>https://arxiv.org/abs/2412.00069</link>
      <description><![CDATA[arXiv:2412.00069v1 公告类型：新
摘要：混合专家 (MOE) 因其能够在使用相同甚至更少的活动参数的同时扩展神经网络的能力而备受关注。然而，MoE 并不能减轻网络对大量内存的需求，这限制了它们在实际应用中的实用性，尤其是在大型语言模型 (LLM) 时代。虽然最近的研究探索了删除整个 MoE 层以减少内存的可能性，但性能下降仍然很明显。在本文中，我们提出了 Condense-MoE（CD-MoE），它不会删除整个 MoE 层，而是将大而稀疏的 MoE 层压缩为一个小而密集的层，其中只有少数专家对所有 token 都处于激活状态。我们的方法是专门为具有共享专家的细粒度 MoE 设计的，其中前馈网络被分成许多小专家，某些专家被隔离出来作为始终处于激活状态的共享专家。我们在各种基准上证明了我们的方法在多个 MoE 模型（如 DeepSeekMoE 和 QwenMoE）中的有效性。具体来说，对于 DeepSeekMoE-16B 模型，我们的方法保持了近 90% 的平均准确率，同时将内存使用量降低了 30%，并将推理速度提高了 30%。此外，我们表明，通过轻量级专家微调，修剪后的模型可以在特定任务上实现进一步的改进。我们的代码可在 https://github.com/duterscmy/CD-MoE/tree/main 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.00069</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于非线性动力学建模的混合正则化循环随机配置网络</title>
      <link>https://arxiv.org/abs/2412.00070</link>
      <description><![CDATA[arXiv:2412.00070v1 公告类型：新
摘要：递归随机配置网络（RSCN）在建模具有不确定性的非线性动态系统方面表现出巨大潜力。本文提出了一种具有混合正则化的RSCN，以增强网络的学习能力和泛化性能。给定一组时间数据，采用众所周知的最小绝对收缩和选择算子（LASSO）来识别显着的顺序变量。随后，引入一种具有L2正则化的改进RSCN来近似目标工厂的输出和LASSO模型之间的残差。输出权重通过投影算法实时更新，从而有助于快速响应系统内的动态变化。提供了通用近似性质的理论分析，有助于理解网络在表示各种复杂非线性函数方面的有效性。非线性系统识别问题和两个工业预测任务的实验结果表明，所提出的方法在所有测试数据集上均优于其他模型。]]></description>
      <guid>https://arxiv.org/abs/2412.00070</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>COAP：利用相关感知梯度投影进行内存高效训练</title>
      <link>https://arxiv.org/abs/2412.00071</link>
      <description><![CDATA[arXiv:2412.00071v1 公告类型：新
摘要：在视觉和多模态领域训练大规模神经网络需要大量的内存资源，这主要是由于优化器状态的存储。虽然 LoRA 是一种流行的参数高效方法，可以减少内存使用量，但由于低秩更新的限制，它的性能往往不理想。低秩梯度投影方法（例如，GaLore、Flora）通过奇异值分解或随机投影将梯度和矩估计投影到低秩空间，从而减少优化器内存。然而，它们没有考虑到投影间的相关性，导致性能下降，而且它们的投影策略通常会产生高昂的计算成本。在本文中，我们提出了 COAP（相关感知梯度投影），这是一种内存高效的方法，可在保持训练性能的同时最大限度地减少计算开销。在各种视觉、语言和多模态任务中进行评估后，COAP 在训练速度和模型性能方面均优于现有方法。对于 LLaMA-1B，COAP 可将优化器内存减少 61%，而时间成本仅增加 2%，实现与 AdamW 相同的 PPL。通过 8 位量化，COAP 可将优化器内存减少 81%，并且 LLaVA-v1.5-7B 微调的速度比 GaLore 快 4 倍，同时提供更高的准确率。]]></description>
      <guid>https://arxiv.org/abs/2412.00071</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Muon 空间 GNSS-R 表面土壤水分产品</title>
      <link>https://arxiv.org/abs/2412.00072</link>
      <description><![CDATA[arXiv:2412.00072v1 公告类型：新
摘要：Muon Space (Muon) 正在建造一个小型卫星星座，其中许多卫星将搭载全球导航卫星系统反射测量 (GNSS-R) 接收器。为了准备发射这个星座，我们开发了一个通用的深度学习检索管道，现在使用来自 NASA 的 Cyclone GNSS (CYGNSS) 任务的数据生成可操作的 GNSS-R 近地表土壤水分检索。在本文中，我们描述了输入数据集、预处理方法、模型架构、开发方法，并详细介绍了从这些检索中生成的土壤水分产品。该产品的性能是根据现场测量量化的，并与目标数据集（来自土壤水分主动-被动 (SMAP) 卫星的检索）和来自 CYGNSS 任务的 v1.0 土壤水分产品进行了比较。 Muon Space 产品的空间分辨率比 SMAP 有所提高，在许多地区性能相当。图中显示，SMAP 核心验证站点的现场土壤湿度观测的 ubRMSE 为 0.032 cm$^3$ cm$^{-3}$，但在森林和/或山区比较时，其性能低于 SMAP。Muon Space 产品在几乎所有方面都优于 v1.0 CYGNSS 土壤湿度产品。此初始版本是我们运营土壤湿度产品的基础，该产品很快将包括来自 Muon Space 卫星的数据。]]></description>
      <guid>https://arxiv.org/abs/2412.00072</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>任务奇异向量：减少模型合并中的任务干扰</title>
      <link>https://arxiv.org/abs/2412.00081</link>
      <description><![CDATA[arXiv:2412.00081v1 公告类型：新
摘要：任务算法已成为一种简单而有效的模型合并方法，无需额外训练。然而，通过将整个网络视为平面参数向量，它忽略了关键的结构信息，并且容易受到任务干扰。在本文中，我们研究层级的任务向量，重点研究任务层矩阵及其奇异值分解。特别是，我们专注于由此产生的奇异向量，我们将其称为任务奇异向量 (TSV)。认识到层任务矩阵通常是低秩的，我们提出了 TSV-Compress (TSV-C)，这是一种简单的程序，可将它们压缩到原始大小的 10%，同时保留 99% 的准确率。我们进一步利用这个低秩空间来定义一种新的任务干扰度量，该度量基于来自不同任务的奇异向量的相互作用。基于这些发现，我们引入了 TSV-Merge (TSV-M)，这是一种将压缩与减少干扰相结合的新型模型合并方法，其性能明显优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2412.00081</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在看不见的目标条件下，使用领域和类原型进行情感脑机接口的双重原型设计</title>
      <link>https://arxiv.org/abs/2412.00082</link>
      <description><![CDATA[arXiv:2412.00082v1 公告类型：新
摘要：EEG 信号已成为情感脑机接口的强大工具，在情绪识别中发挥着至关重要的作用。然而，目前基于深度迁移学习的 EEG 识别方法面临着挑战，因为模型学习中依赖源数据和目标数据，这显著影响了模型的性能和泛化。为了克服这一限制，我们提出了一个新框架 (PL-DCP)，并引入了特征解缠和原型推理的概念。双原型机制结合了领域和类原型：领域原型捕获不同主体的个体差异，而类原型代表各自领域内的理想类分布。重要的是，所提出的 PL-DCP 框架在训练期间只使用源数据，这意味着目标数据在整个过程中完全不可见。为了解决标签噪声问题，我们采用了一种成对学习策略，对样本对之间的接近关系进行编码，有效地减少了错误标记数据的影响。在 SEED 和 SEED-IV 数据集上进行的实验验证表明，尽管 PL-DCP 在训练期间不使用目标数据，但其性能却可与需要源数据和目标数据的深度迁移学习方法相媲美。这凸显了 PL-DCP 作为一种基于 EEG 的情绪识别的有效且稳健的方法的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.00082</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态人工智能中的视觉错误模式：一种统计方法</title>
      <link>https://arxiv.org/abs/2412.00083</link>
      <description><![CDATA[arXiv:2412.00083v1 公告类型：新
摘要：人工智能 (AI) 在广泛领域取得了变革性的成功，彻底改变了医疗保健、教育和人机交互等领域。然而，推动人工智能性能的机制往往仍然不透明，特别是在大型语言模型 (LLM) 的背景下，近年来，大型语言模型以前所未有的速度发展。像 GPT-4o 这样的多模态大型语言模型 (MLLM) 体现了这种演变，它整合了文本、音频和视觉输入，以实现跨不同领域的交互。尽管这些模型具有非凡的能力，但它们在很大程度上仍然是“黑匣子”，对它们如何在内部处理多模态信息提供了有限的洞察。这种缺乏透明度带来了重大挑战，包括系统性偏见、有缺陷的关联和意外行为，需要仔细调查。了解 MLLM 的决策过程对于缓解这些挑战并确保它们在关键应用中的可靠部署既有益又必不可少。 GPT-4o 之所以被选为本研究的重点，是因为其先进的多模态能力，可以同时处理文本和视觉信息。这些能力使其成为研究机器驱动和人类驱动的视觉感知之间的相似之处和区别的理想模型。虽然 GPT-4o 在涉及结构化和完整数据的任务中表现良好，但它依赖于自下而上的处理，即对感官输入进行逐个特征的分析，这在解释复杂或模糊的刺激时带来了挑战。这种限制与人类视觉形成了鲜明对比，人类视觉非常擅长通过高级认知过程解决歧义并重建不完整的信息。]]></description>
      <guid>https://arxiv.org/abs/2412.00083</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解析扩散政策的各个组成部分</title>
      <link>https://arxiv.org/abs/2412.00084</link>
      <description><![CDATA[arXiv:2412.00084v1 公告类型：新
摘要：模仿学习为学习可推广和复杂的机器人技能提供了一种有前途的方法。最近提出的扩散策略通过条件去噪扩散过程生成机器人动作序列，与其他模仿学习方法相比，实现了最先进的性能。本文总结了扩散策略的五个关键组成部分：1）观察序列输入；2）动作序列执行；3）滚动视界；4）U-Net 或 Transformer 网络架构；5）FiLM 条件。通过在 ManiSkill 和 Adroit 基准上进行实验，本研究旨在阐明每个组成部分对扩散策略在不同场景中的成功的贡献。我们希望我们的研究结果能够为扩散策略在未来研究和工业中的应用提供有价值的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.00084</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>