<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>多合一：图神经网络的多任务提示（扩展摘要）</title>
      <link>https://arxiv.org/abs/2403.07040</link>
      <description><![CDATA[arXiv:2403.07040v1 公告类型：新
摘要：本文是我们在 KDD23 上发表的原创作品的扩展摘要，该论文获得了最佳研究论文奖（Xiangguo Sun、Hong Cheng、Jia Li、Bo Liu 和 Jihongguan。All in one: Multi-task Promoting for图神经网络。KDD 23) 受 NLP 即时学习成功的启发，本文介绍了一种新方法来弥合预训练图模型与它们所应用的各种任务之间的差距。认识到将预训练模型与不同的图任务（节点级、边级和图级）对齐的挑战可能导致负迁移和性能不佳，我们提出了一种图的多任务提示方法。该方法涉及统一图形和语言提示格式，使 NLP 的提示策略能够适应图形任务。通过分析图应用程序的任务空间，我们重新表述问题以适应图级任务，并应用元学习来改进多个任务的即时初始化。实验表明我们的方法在增强不同图形任务的模型性能方面是有效的。
  除了原始工作之外，在这个扩展摘要中，我们进一步从更大的角度讨论了图形提示，并提供了该领域的一些最新工作。]]></description>
      <guid>https://arxiv.org/abs/2403.07040</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 GFlowNets 进行蚁群采样进行组合优化</title>
      <link>https://arxiv.org/abs/2403.07041</link>
      <description><![CDATA[arXiv:2403.07041v1 公告类型：新
摘要：本文介绍了生成流蚁群采样器（GFACS），这是一种新颖的神经引导元启发式组合优化算法。 GFACS 将生成流网络 (GFlowNets) 与蚁群优化 (ACO) 方法相集成。 GFlowNets 是一种在组合空间中学习建设性策略的生成模型，通过提供以输入图实例为条件的决策变量的知情先验分布来增强 ACO。此外，我们引入了一种新颖的训练技巧组合，包括搜索引导的局部探索、能量标准化和能量整形，以改进 GFACS。我们的实验结果表明，GFACS 在七个 CO 任务中优于基线 ACO 算法，并且与针对车辆路径问题的特定问题启发式算法具有竞争力。源代码可在 \url{https://github.com/ai4co/gfacs} 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.07041</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>通过原型匹配解释典型故障信号的样子</title>
      <link>https://arxiv.org/abs/2403.07033</link>
      <description><![CDATA[arXiv:2403.07033v1 公告类型：新
摘要： 神经网络具有强大的非线性映射和分类能力，广泛应用于机械故障诊断以确保安全。然而，作为典型的黑盒模型，其应用在高可靠性要求的场景中受到限制。为了理解分类逻辑并解释典型的故障信号是什么样子，通过将人类固有的原型匹配与自动编码器（AE）相结合，提出了原型匹配网络（PMN）。 PMN将AE提取的特征与每个原型进行匹配，并选择最相似的原型作为预测结果。它具有分类逻辑、故障原型和匹配贡献三个解释路径。常规诊断和领域泛化实验证明了其具有竞争力的诊断性能和在表示学习中的显着优势。此外，学习到的典型故障信号（即样本级原型）展示了去噪和提取专家认为难以捕获的微妙关键特征的能力。这种能力拓宽了人类的理解，并提供了从可解释性研究到人工智能科学的有前景的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.07033</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>将自动编码器转换为边缘低延迟且节能的 DNN 推理</title>
      <link>https://arxiv.org/abs/2403.07036</link>
      <description><![CDATA[arXiv:2403.07036v1 公告类型：新
摘要：在保持预测精度的同时减少推理时间和能源使用已成为资源受限边缘设备上深度神经网络（DNN）推理的一个重要问题。为了解决这个问题，我们提出了一种基于“转换”自动编码器和轻量级 DNN 的新方法。这改进了最近的工作，例如早期退出的框架和 DNN 分区。早期存在的框架根据不同的输入数据的复杂性花费不同数量的计算能力。然而，在处理许多硬图像样本的现实场景中，它们可能效率低下。另一方面，利用云端和边缘设备计算能力的 DNN 分区算法可能会受到网络延迟以及云端和边缘之间的间歇性连接的影响。我们推出了 CBNet，这是一种专为边缘设备量身定制的低延迟且节能的 DNN 推理框架。它利用“转换”自动编码器有效地将困难图像转换为简单图像，随后由轻量级 DNN 进行处理以进行推理。据我们所知，这种自动编码器尚未被提出。我们在 Raspberry Pi 4、Google Cloud 实例和配备 Nvidia Tesla K80 GPU 的实例上使用三个流行的图像分类数据集进行的实验结果表明，与相比，CBNet 的推理延迟速度提高了 4.8 倍，能源使用量减少了 79%竞争技术，同时保持相似或更高的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.07036</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>利用图神经网络支持患者的自动分类</title>
      <link>https://arxiv.org/abs/2403.07038</link>
      <description><![CDATA[arXiv:2403.07038v1 公告类型：新
摘要： 患者分诊在急诊科中发挥着至关重要的作用，在正确评估患者病情紧急等级的基础上确保及时、适当的护理。
  分类方法通常由操作员根据自己的经验和从患者管理过程中收集的信息来执行。
  因此，该过程可能会在紧急级别关联中产生错误。最近，传统的分类方法严重依赖于人类的决定，这可能是主观的并且容易出错。
  最近，人们越来越关注利用人工智能 (AI) 开发能够最大限度地收集信息并最大限度地减少患者分诊处理中的错误的算法。
  我们定义并实施一个基于人工智能的模块来管理急诊科患者的紧急代码分配。它使用急诊科历史数据来训练医疗决策过程。包含相关患者信息（例如生命体征、症状和病史）的数据用于准确地将患者分类为分诊类别。实验结果表明，该算法的准确率优于传统的分类方法。通过使用所提出的方法，我们声称医疗保健专业人员可以预测严重程度指数，以指导患者管理处理和资源分配。]]></description>
      <guid>https://arxiv.org/abs/2403.07038</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>一种可与元启发法相媲美的基于学习的高效求解器，用于解决容量弧路由问题</title>
      <link>https://arxiv.org/abs/2403.07028</link>
      <description><![CDATA[arXiv:2403.07028v1 公告类型：新
摘要：最近，神经网络（NN）在组合优化方面取得了长足的进步。然而，他们在解决容量弧路由问题（CARP）时面临挑战，即在容量限制内找到覆盖图上所有所需边的最小成本路径。在处理 CARP 时，基于神经网络的方法往往落后于先进的元启发法，因为它们缺乏针对复杂 CARP 量身定制的有向弧建模和高效学习方法。在本文中，我们引入了一种基于神经网络的求解器，可以显着缩小与高级元启发法的差距，同时展现出卓越的效率。首先，我们提出方向感知注意力模型（DaAM），将方向性纳入嵌入过程，促进更有效的一阶段决策。其次，我们设计了一种监督强化学习方案，其中涉及监督预训练，为后续强化微调建立稳健的初始策略。事实证明，它对于解决比节点路由问题 (NRP) 复杂性更高的 CARP 特别有价值。最后，提出了一种路径优化方法来调整 DaAM 生成的路径内的仓库返回位置。实验表明，我们的方法超越了启发式方法，首次实现了与最先进的元启发式方法相当的决策质量，同时保持了卓越的效率。]]></description>
      <guid>https://arxiv.org/abs/2403.07028</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>AuG-KD：用于域外知识蒸馏的基于锚的混合生成</title>
      <link>https://arxiv.org/abs/2403.07030</link>
      <description><![CDATA[arXiv:2403.07030v1 公告类型：新
摘要：由于隐私或专利问题，越来越多的大型模型在未授予对其训练数据的访问权限的情况下发布，这使得知识转移效率低下且存在问题。为此，无数据知识蒸馏（DFKD）方法作为直接解决方案应运而生。然而，由于教师的训练数据与真实场景（学生领域）之间的差异，简单地将 DFKD 派生的模型应用于实际应用会导致性能显着下降。这种退化源于教师的部分知识不适用于学生领域。它们是教师领域特有的，会损害学生的表现。因此，有选择地传授教师适当的知识成为DFKD的主要挑战。在这项工作中，我们提出了一种简单但有效的方法 AuG-KD。它利用不确定性引导和特定于样本的锚来将学生领域数据与教师领域对齐，并利用生成方法通过混合学习逐步权衡 OOD 知识蒸馏和特定领域信息学习之间的学习过程。在 3 个数据集和 8 个设置中进行的广泛实验证明了我们方法的稳定性和优越性。代码可在 https://github.com/IshiKura-a/AuG-KD 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.07030</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>高效同步学习与评估的补习法</title>
      <link>https://arxiv.org/abs/2403.07031</link>
      <description><![CDATA[arXiv:2403.07031v1 公告类型：新
摘要：我们介绍了“cram”方法，这是一种使用通用机器学习（ML）算法进行同步学习和评估的通用且有效的方法。在批量数据的单次传递中，所提出的方法重复训练机器学习算法并测试其经验性能。因为它利用整个样本来进行学习和评估，所以临时抱佛脚比样本分割的数据效率要高得多。补习方法也自然地适应了在线学习算法，使其实现计算效率高。为了证明临时抱佛脚方法的威力，我们考虑了标准的策略学习设置，其中临时抱佛脚应用于相同的数据，以制定个性化治疗规则（ITR）并估计部署学习的 ITR 时会产生的平均结果。我们证明，在最小的假设集下，所得的填充评估估计量是一致的且渐近正态的。虽然我们的渐近结果需要 ML 算法相对较弱的稳定条件，但我们开发了一种简单、通用的方法，可以与任何策略学习算法一起使用来满足此条件。我们广泛的模拟研究表明，与样本分割相比，临时抱佛脚将评估标准误差降低了 40% 以上，同时提高了学习策略的性能。我们还将补习方法应用于随机临床试验，以证明其对现实问题的适用性。最后，我们简要讨论了临时补习方法在其他学习和评估环境中的未来扩展。]]></description>
      <guid>https://arxiv.org/abs/2403.07031</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>持续学习场景的自适应超参数优化</title>
      <link>https://arxiv.org/abs/2403.07015</link>
      <description><![CDATA[arXiv:2403.07015v1 公告类型：新
摘要：持续学习场景中的超参数选择是一个具有挑战性且尚未充分探索的方面，特别是在实际的非平稳环境中。传统方法，例如使用来自所有任务的验证数据进行网格搜索，对于构建准确的终身学习系统是不现实的。本文旨在探讨超参数选择在持续学习中的作用，以及根据手头任务的复杂性不断自动调整超参数的必要性。因此，我们建议利用序列任务学习的性质来提高超参数优化效率。通过使用基于方差的技术的功能分析，我们确定了对性能有影响的最关键的超参数。我们凭经验证明，这种与连续场景和策略无关的方法使我们能够持续加速跨任务的超参数优化，并且即使面对不同的连续任务顺序也能表现出鲁棒性。我们相信，我们的研究结果有助于推动持续学习方法的发展，为现实世界的应用提供更高效、稳健和适应性强的模型。]]></description>
      <guid>https://arxiv.org/abs/2403.07015</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>任意可修改面积单位的时空预测查询统一模型</title>
      <link>https://arxiv.org/abs/2403.07022</link>
      <description><![CDATA[arXiv:2403.07022v1 公告类型：新
摘要：时空（ST）预测对于在城市基于位置的应用（如乘车共享）中做出明智的决策至关重要。然而，现有的 ST 模型通常需要区域划分作为先决条件，从而导致两个主要缺陷。首先，基于位置的服务需要用于各种目的的临时区域，需要具有不同规模和区域的多个 ST 模型，支持成本可能很高。其次，不同的 ST 模型可能会产生相互冲突的输出，从而导致令人困惑的预测。在本文中，我们提出了 One4All-ST，这是一种仅使用一个模型即可对任意可修改区域单元进行 ST 预测的框架。为了降低获得多尺度预测的成本，我们设计了一个具有分层空间建模和尺度归一化模块的 ST 网络，以高效、平等地学习多尺度表示。为了解决跨尺度的预测不一致问题，我们提出了一种动态规划方案来解决公式化的最优组合问题，通过理论分析最小化预测误差。此外，我们建议使用扩展四叉树来索引最佳组合，以便在实际在线场景中快速响应任意可修改的区域单元。对两个真实世界数据集的大量实验验证了 One4All-ST 在任意可修改区域单元的 ST 预测中的效率和有效性。这项工作的源代码和数据可以在https://github.com/uctb/One4All-ST获取。]]></description>
      <guid>https://arxiv.org/abs/2403.07022</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>FWin 变压器用于气候和海洋影响下的登革热预测</title>
      <link>https://arxiv.org/abs/2403.07027</link>
      <description><![CDATA[arXiv:2403.07027v1 公告类型：新
摘要：登革热是最致命的蚊媒热带传染病之一。详细的长期预测模型对于控制疾病传播和采取缓解措施至关重要。在这项研究中，我们研究了用于预测登革热病例的长期预测方法。该数据集包含新加坡 2000 年至 2019 年的当地气候/天气以及全球气候指标。我们利用新开发的深度神经网络来学习特征之间的复杂关系。本研究中的基线模型属于用于长序列预测任务的最新转换器类别。我们发现，基于傅里叶混合窗口注意力 (FWin) 的变压器在长达 60 周的长期登革热预测中的均方误差和最大绝对误差方面表现最佳。]]></description>
      <guid>https://arxiv.org/abs/2403.07027</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>AutoEval 做得对：使用综合数据进行模型评估</title>
      <link>https://arxiv.org/abs/2403.07008</link>
      <description><![CDATA[arXiv:2403.07008v1 公告类型：新
摘要：使用人工标记的验证数据评估机器学习模型可能既昂贵又耗时。人工智能标记的合成数据可用于在称为自动评估的过程中减少为此目的所需的人工注释数量。为此，我们建议采用高效且具有统计原理的算法，以提高样本效率，同时保持公正。在 GPT-4 实验中，这些算法将有效的人工标记样本量增加了 50%。]]></description>
      <guid>https://arxiv.org/abs/2403.07008</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>基于张量分解的缺失数据插补的非侵入式负载监控</title>
      <link>https://arxiv.org/abs/2403.07012</link>
      <description><![CDATA[arXiv:2403.07012v1 公告类型：新
摘要：随着非侵入式负载监测（NILM）在建筑能源管理中的广泛采用，确保 NILM 数据的高质量已势在必行。然而，NILM 的实际应用面临与数据丢失相关的挑战，严重影响能源管理的准确性和可靠性。本文通过引入创新的张量完成（TC）模型 - 比例积分微分（PID）结合张量的非负潜在因子分解（PNLFT）来解决 NILM 数据丢失的问题，其具有双重思想：1）解决该问题为了解决使用随机梯度下降 (SGD) 的张量潜在分解 (LFT) 中的缓慢收敛问题，在学习过程中引入了比例积分微分控制器。 PID控制器利用历史和当前信息来控制学习残差。 2）考虑NILM数据的特点，在模型的学习方案中提出了非负更新规则。三个数据集的实验结果表明，与最先进的模型相比，所提出的模型在收敛速度和准确性方面都表现出显着的增强。]]></description>
      <guid>https://arxiv.org/abs/2403.07012</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>以正确的方式指导法学硕士：快速、非侵入性约束生成</title>
      <link>https://arxiv.org/abs/2403.06988</link>
      <description><![CDATA[arXiv:2403.06988v1 公告类型：新
摘要：为了确保大型语言模型（LLM）生成的文本采用预期的格式，约束解码建议在生成过程中强制执行严格的形式语言约束。然而，正如我们在这项工作中所展示的，这些方法不仅会在生成过程中产生性能开销，而且如果它们没有将底层 LLM 子词词汇表与外部约束正确对齐，它们中的许多方法还会显着损害任务准确性。为了解决这个问题，我们提出了一种新颖的解码算法 DOMINO，它可以以完全子字对齐的方式强制执行约束，同时利用预计算和推测解码来实现几乎没有开销，在某些情况下甚至可以实现几乎 2 倍的加速超越无约束解码——从而大大优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2403.06988</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习、机器学习和统计方法的生存建模：预测入院后死亡率的比较分析</title>
      <link>https://arxiv.org/abs/2403.06999</link>
      <description><![CDATA[arXiv:2403.06999v1 公告类型：新
摘要：生存分析对于研究事件发生时间结果以及动态了解事件随时间发生的概率至关重要。从传统统计模型到最先进的机器学习算法，各种生存分析技术支持医疗保健干预和政策决策。然而，关于它们的比较性能的讨论仍在继续。我们对几种生存分析方法进行了比较研究，包括Cox比例风险（CoxPH）、逐步CoxPH、弹性网惩罚Cox模型、随机生存森林（RSF）、梯度提升机（GBM）学习、AutoScore-Survival、DeepSurv、时间基于依赖Cox模型的神经网络（CoxTime），以及DeepHit生存神经网络。我们应用一致性指数（C-index）进行模型拟合优度，并应用积分 Brier 分数（IBS）进行校准，并考虑模型的可解释性。作为案例研究，我们对 2017 年至 2019 年通过某三级医院急诊科收治的患者进行了回顾性分析，根据患者人口统计、临床病理特征和历史数据预测 90 天全因死亡率。 C 指数的结果表明深度学习取得了可比的性能，其中 DeepSurv 产生了最好的区分度（DeepSurv：0.893；CoxTime：0.892；DeepHit：0.891）。 DeepSurv (IBS: 0.041) 的校准表现最好，其次是 RSF (IBS: 0.042) 和 GBM (IBS: 0.0421)，均使用完整变量。此外，AutoScore-Survival使用最小变量子集，易于解释，并且可以实现良好的区分和校准（C指数：0.867；IBS：0.044）。虽然所有模型都令人满意，但 DeepSurv 表现出了最佳的辨别力和校准能力。此外，AutoScore-Survival 提供了更简洁的模型和出色的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2403.06999</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:20 GMT</pubDate>
    </item>
    </channel>
</rss>