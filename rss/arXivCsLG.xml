<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 07 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>未标记的数据如何帮助分布外检测？</title>
      <link>https://arxiv.org/abs/2402.03502</link>
      <description><![CDATA[使用未标记的数据来规范机器学习模型已证明有望提高检测分布外（OOD）数据的安全性和可靠性。由于分布内 (ID) 和 OOD 数据的异质性，利用未标记的野外数据的力量并非易事。缺乏一组干净的 OOD 样本给学习最佳 OOD 分类器带来了重大挑战。目前，缺乏正式理解未标记数据如何帮助 OOD 检测的研究。本文通过引入新的学习框架 SAL（Separate And Learn）来弥补这一差距，该框架提供了强有力的理论保证和实证有效性。该框架将候选离群值与未标记数据分开，然后使用候选离群值和标记 ID 数据训练 OOD 分类器。理论上，我们从可分离性和可学习性的角度提供了严格的误差界限，正式证明了我们算法中的两个组成部分的合理性。我们的理论表明，SAL 可以以较小的错误率分离候选异常值，从而为学习到的 OOD 分类器提供泛化保证。根据经验，SAL 在通用基准上实现了最先进的性能，增强了我们的理论见解。代码可在 https://github.com/deeplearning-wisc/sal 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2402.03502</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:48 GMT</pubDate>
    </item>
    <item>
      <title>仓储中拣选员路线问题的深度强化学习</title>
      <link>https://arxiv.org/abs/2402.03525</link>
      <description><![CDATA[订单拣选员路由是仓库运营管理中的一个关键问题。由于问题的复杂性和快速解决方案的需要，实践中经常采用次优算法。然而，强化学习为传统启发式方法提供了一种有吸引力的替代方案，在速度和准确性方面可能优于现有方法。我们引入了一种基于注意力的神经网络，用于对采摘之旅进行建模，该神经网络是使用强化学习进行训练的。我们的方法根据一系列问题参数的现有启发式进行评估，以证明其有效性。我们提出的方法的一个关键优点是它能够提供降低路线感知复杂性的选项。]]></description>
      <guid>https://arxiv.org/abs/2402.03525</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:48 GMT</pubDate>
    </item>
    <item>
      <title>我们可以去除自适应梯度方法中的平方根吗？二阶视角</title>
      <link>https://arxiv.org/abs/2402.03496</link>
      <description><![CDATA[像 Adam(W) 这样的自适应梯度优化器是许多深度学习架构（例如 Transformer）的默认训练算法。他们的对角预处理器基于梯度外积，该外积通过平方根合并到参数更新中。虽然这些方法通常被视为近似二阶方法，但平方根代表了根本的区别。在这项工作中，我们研究了当我们去除根（即加强其二阶动机）时自适应方法的行为如何变化。令人惊讶的是，我们发现这种无平方根自适应方法缩小了卷积架构上与 SGD 的泛化差距，同时保持了基于根的对应方法在 Transformer 上的性能。二阶视角对于开发具有非对角预处理器的自适应方法也具有实际的好处。与 Shampoo 等基于根的对应物相比，它们不需要数值不稳定的矩阵平方根，因此在低精度下工作良好，我们通过经验证明了这一点。这就提出了关于当前被忽视的适应性对于适应性方法成功的作用的重要问题。]]></description>
      <guid>https://arxiv.org/abs/2402.03496</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:47 GMT</pubDate>
    </item>
    <item>
      <title>用于科学发现的万亿参数人工智能服务基础设施：调查与愿景</title>
      <link>https://arxiv.org/abs/2402.03480</link>
      <description><![CDATA[深度学习方法正在改变研究，支持新技术，并最终带来新发现。随着对更强大的人工智能模型的需求不断增长，我们现在正在进入万亿参数模型（TPM）的时代，或者具有超过万亿参数的模型——例如华为的PanGu-$\Sigma$。我们描述了 TPM 用户和提供商生态系统的愿景，以满足科学界的特定需求。然后，我们概述了为 TPM 服务以实现科学研究和发现的系统设计中的重大技术挑战和开放问题。具体来说，我们描述了全面的软件堆栈和接口的要求，以支持研究人员的多样化和灵活的需求。]]></description>
      <guid>https://arxiv.org/abs/2402.03480</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:46 GMT</pubDate>
    </item>
    <item>
      <title>临床环境中脓毒症发病的早期预测</title>
      <link>https://arxiv.org/abs/2402.03486</link>
      <description><![CDATA[本研究提出使用机器学习模型，利用美国纽约州布朗克斯蒙特菲奥里医疗中心的去识别化临床数据来预测脓毒症的早期发作。采用监督学习方法，其中利用 80% 的训练数据集训练 XGBoost 模型，包含 107 个特征（包括原始特征和派生特征）。随后，根据剩余 20% 的测试数据对模型进行评估。该模型在训练阶段完全看不到的预期数据上进行了验证。为了评估模型在个体患者水平上的性能和预测的及时性，采用了标准化效用评分，这是一种广泛认可的脓毒症检测评分方法，如 PhysioNet 脓毒症挑战论文中所述。还设计了 F1 分数、敏感性、特异性和标记率等指标。该模型在阈值 0.3 时，测试数据的归一化效用得分为 0.494，预期数据的归一化效用得分为 0.378。相同阈值的测试数据和前瞻性数据的 F1 分数分别为 80.8% 和 67.1%，凸显了其有效融入临床决策过程的潜力。这些结果证明了该模型强大的预测能力及其对临床决策过程产生重大影响的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.03486</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:46 GMT</pubDate>
    </item>
    <item>
      <title>部分随机无限深贝叶斯神经网络</title>
      <link>https://arxiv.org/abs/2402.03495</link>
      <description><![CDATA[在本文中，我们提出了部分随机无限深贝叶斯神经网络，这是一种新颖的架构家族，它将部分随机性集成到无限深神经网络的框架中。我们的新型架构旨在改善现有架构在训练和推理时的计算效率方面的局限性。为此，我们利用无限深度限制中部分随机性的优势，其中包括完全随机性的优势，例如鲁棒性、不确定性量化和内存效率，同时改善训练和推理时计算效率的局限性。我们提供了各种架构配置，为网络设计提供了灵活性，包括不同的权重划分方法。我们还通过确定我们的网络系列符合通用条件分布近似器的条件，为我们的模型的表达能力提供数学保证。最后，跨多个任务的实证评估表明，我们提出的架构比同类架构实现了更好的下游任务性能和不确定性量化，同时效率显着提高。]]></description>
      <guid>https://arxiv.org/abs/2402.03495</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:46 GMT</pubDate>
    </item>
    <item>
      <title>超扩散：用单一模型估计认知和任意不确定性</title>
      <link>https://arxiv.org/abs/2402.03478</link>
      <description><![CDATA[将机器学习 (ML) 应用于医学成像等高风险应用时，估计和解开认知不确定性（可以通过更多训练数据来减少的不确定性）和随意不确定性（手头任务固有的不确定性）至关重要。天气预报。条件扩散模型具有从数据集的后验分布中准确有效地采样的突破性能力，现在使得不确定性估计在概念上变得简单：人们只需要从大量扩散模型中进行训练和采样。不幸的是，随着模型架构复杂性的增加，训练这样的集成在计算上变得困难。
  在这项工作中，我们引入了一种新的集成方法，即超扩散，它允许人们使用单个模型准确估计认知和任意不确定性。与现有的基于蒙特卡洛丢失的单模型集成方法不同，超扩散提供与多模型集成相同的预测精度。我们在两个不同的任务上验证了我们的方法：X 射线计算机断层扫描 (CT) 重建和天气温度预测。]]></description>
      <guid>https://arxiv.org/abs/2402.03478</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:45 GMT</pubDate>
    </item>
    <item>
      <title>ICED：通过上下文环境设计实现强化学习中的零镜头迁移</title>
      <link>https://arxiv.org/abs/2402.03479</link>
      <description><![CDATA[使用深度强化学习（RL）训练的自主代理通常缺乏成功泛化到新环境的能力，即使它们与训练期间遇到的环境具有相同的特征。在这项工作中，我们研究了单个环境实例或级别的采样如何影响 RL 代理的零样本泛化 (ZSG) 能力。我们发现，对于共享基础层的深度行动者-批评家架构，根据其价值损失对级别进行优先级排序可以最大限度地减少代理的内部表示与生成的训练数据中的训练级别集之间的相互信息。这为通过某些自适应采样策略实现的隐式正则化提供了新颖的理论依据。然后我们将注意力转向无监督环境设计（UED）方法，它对数据生成机制有更多的控制。我们发现现有的 UED 方法可以显着改变训练分布，从而导致 ZSG 性能较低。为了防止过度拟合和分布偏移，我们引入了上下文环境设计（ICED）。 ICED 使用在初始级别参数集上训练的变分自动编码器生成级别，减少分布偏移，并在 ZSG 中实现相对于自适应级别采样策略和 UED 方法的显着改进。]]></description>
      <guid>https://arxiv.org/abs/2402.03479</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:45 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型几何信息</title>
      <link>https://arxiv.org/abs/2402.03471</link>
      <description><![CDATA[本文研究了大型语言模型（LLM）嵌入中编码的信息。我们进行模拟来分析表示熵并发现与模型大小的幂律关系。基于这一观察，我们提出了一种基于（条件）熵的理论来阐明标度律现象。此外，我们深入研究了 LLM 的自回归结构，并使用信息论和回归技术检查最后一个标记和先前上下文标记之间的关系。具体来说，我们在新令牌的信息增益和岭回归之间建立了理论联系。此外，我们还探讨了 Lasso 回归在选择有意义的标记方面的有效性，该回归有时优于密切相关的注意力权重。最后，我们进行了对照实验，发现信息分布在各个代币中，而不是仅仅集中在特定的“有意义”的代币中。]]></description>
      <guid>https://arxiv.org/abs/2402.03471</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:44 GMT</pubDate>
    </item>
    <item>
      <title>由任意线性变换支持的精确张量补全</title>
      <link>https://arxiv.org/abs/2402.03468</link>
      <description><![CDATA[在这项工作中，研究了张量完成问题，其目的是从部分观测中完美地恢复张量。现有的理论保证要求所涉及的变换是正交的，这阻碍了其应用。本文跳出了各向同性或自共轭性的约束，建立了任意线性变换精确张量完备的理论保证。为此，我们定义了一个新的张量-张量积，这导致我们对张量核范数有了新的定义。配备这些工具，设计了一种基于乘法器交替方向的高效算法来求解变换后的张量补全程序，并获得了理论界限。我们的模型和证明极大地增强了张量完成的灵活性，大量的实验验证了所提出方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.03468</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:43 GMT</pubDate>
    </item>
    <item>
      <title>具有规则化相关性奖励的无偏好对齐学习</title>
      <link>https://arxiv.org/abs/2402.03469</link>
      <description><![CDATA[从人类偏好中学习被认为是使大型语言模型 (LLM) 与人类价值观保持一致的关键。然而，与普遍的看法相反，我们的初步研究表明，在人类偏好数据集上训练的奖励模型往往会给长的偏离主题的回答比短的主题回答更高的分数。受这一观察的启发，我们探索了一种无偏好的方法，利用“相关性”作为对齐的关键目标。在我们的第一次尝试中，我们发现，当我们利用分数作为强化学习的奖励时，仅由检索器获得的相关性分数很容易受到奖励黑客攻击，即过度优化到不需要的捷径。为了缓解这个问题，我们将有效的归纳偏差整合到普通相关性中以相互规范化，从而产生奖励函数的混合：正则化相关性奖励（$R^3$）。 $R^3$ 通过提供强大的奖励信号，显着提高了偏好基准的性能。值得注意的是，$R^3$ 不需要任何人类偏好数据集（即无偏好），在改善人类偏好方面优于开源奖励模型。我们的分析表明，$R^3$ 在提高人类偏好同时最大限度地减少其副作用方面具有优势。最后，我们展示了 $R^3$ 的通用性，持续改进各种主干和大小的指令调整模型，而无需额外的数据集成本。我们的代码可在 https://github.com/naver-ai/RRR 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.03469</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:43 GMT</pubDate>
    </item>
    <item>
      <title>使用可解释的提升机进行高效且可解释的交通目的地预测</title>
      <link>https://arxiv.org/abs/2402.03457</link>
      <description><![CDATA[开发准确的交通轨迹预测模型对于实现完全自动驾驶至关重要。各种深度神经网络模型已被用来解决这一挑战，但它们的黑盒性质阻碍了已部署系统的透明度和调试能力。玻璃盒模型通过像 \ac{GAM} 这样的方法提供完全的可解释性，从而提供了一种解决方案。在本研究中，我们评估了一种名为 \ac{EBM} 的高效加性模型，用于在三个流行的混合流量数据集上进行流量预测：\ac{SDD}、\ac{InD} 和 Argoverse。我们的结果表明，\ac{EBM} 模型在预测 \ac{SDD} 和 \ac{InD} 内的行人目的地方面具有竞争力，同时为车辆主导的 Argoverse 数据集提供适度的预测。此外，我们透明的训练模型使我们能够分析特征重要性和交互作用，并提供预测解释的定性示例。完整的培训代码将在发布后公开。]]></description>
      <guid>https://arxiv.org/abs/2402.03457</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:42 GMT</pubDate>
    </item>
    <item>
      <title>黎曼随机梯度下降的随机修正流</title>
      <link>https://arxiv.org/abs/2402.03467</link>
      <description><![CDATA[我们对黎曼随机梯度下降 (RSGD) 到黎曼梯度流和扩散过程（即所谓的黎曼随机修正流 (RSMF)）的收敛速度进行定量估计。使用随机微分几何工具，我们表明，在小学习率范围内，RSGD 可以通过无限维维纳过程驱动的 RSMF 的解来近似。 RSMF 考虑了 RSGD 的随机波动，因此与确定性黎曼梯度流相比，增加了近似阶数。 RSGD 是使用回缩图的概念构建的，即指数图的成本有效的近似，并且我们在回缩图、流形几何形状的假设下证明了扩散近似的弱误差的定量界限，和梯度的随机估计器。]]></description>
      <guid>https://arxiv.org/abs/2402.03467</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:42 GMT</pubDate>
    </item>
    <item>
      <title>基于神经网络架构的广义决策树集成：分布式梯度提升森林（DGBF）</title>
      <link>https://arxiv.org/abs/2402.03386</link>
      <description><![CDATA[RandomForest 和 GradientBoosting 等树集成算法是目前离散或表格数据建模的主要方法，但是，由于其多层结构，它们无法像 NeuralNetworks 那样从原始数据中执行分层表示学习，而多层结构是深度学习问题和非结构化数据建模。这种限制是由于树算法由于其数学性质而无法通过反向传播进行训练。然而，在这项工作中，我们证明了 bagging 和 boosting 的数学公式可以结合在一起，定义一个图结构树集成算法，并自然地在树之间进行分布式表示学习过程（不使用反向传播）。我们将这种新颖的方法称为分布式梯度提升森林（DGBF），并且我们证明了随机森林和梯度提升都可以表示为 DGBT 的特定图架构。最后，我们看到分布式学习在 9 个数据集中的 7 个数据集中优于 RandomForest 和 GradientBoosting。]]></description>
      <guid>https://arxiv.org/abs/2402.03386</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:41 GMT</pubDate>
    </item>
    <item>
      <title>去中心化零星联邦学习：具有广义收敛保证的统一方法</title>
      <link>https://arxiv.org/abs/2402.03448</link>
      <description><![CDATA[去中心化联合学习 (DFL) 最近受到了广泛的研究关注，它捕获了由客户执行模型更新和模型聚合（两个关键 FL 过程）的设置。在这项工作中，我们提出了去中心化零星联合学习（$\texttt{DSpodFL}$），这是一种 DFL 方法，它概括了这两个过程中的零星性概念，对现实 DFL 设置中表现的不同形式的异质性的影响进行建模。 $\texttt{DSpodFL}$ 在单一建模框架下统一了许多著名的去中心化优化方法，例如分布式梯度下降（DGD）、随机八卦（RG）和去中心化联合平均（DFedAvg）。我们分析地描述了 $\texttt{DSpodFL}$ 的收敛行为，除其他见解外，表明我们可以在比现有工作更一般的假设下将几何收敛率与有限最优性差距相匹配。通过实验，我们证明与最先进的技术相比，$\texttt{DSpodFL}$ 显着提高了训练速度和对系统参数变化的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2402.03448</guid>
      <pubDate>Wed, 07 Feb 2024 15:12:41 GMT</pubDate>
    </item>
    </channel>
</rss>