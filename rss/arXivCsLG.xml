<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Fri, 05 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>凸和约束设置中的谱聚类</title>
      <link>https://arxiv.org/abs/2404.03012</link>
      <description><![CDATA[arXiv:2404.03012v1 公告类型：新
摘要：谱聚类方法因其在高维数据聚类方面的有效性而获得了广泛的认可。在这些技术中，约束谱聚类已成为一种重要的方法，通过集成成对约束展示了增强的性能。然而，将此类约束应用于半定谱聚类（一种利用半定规划来优化聚类目标的变体）在很大程度上仍未得到探索。在本文中，我们介绍了一种新颖的框架，用于将成对约束无缝集成到半定谱聚类中。我们的方法系统地扩展了半定谱聚类的能力，以捕获复杂的数据结构，从而更有效地解决现实世界的聚类挑战。此外，我们扩展了这个框架，以涵盖主动学习和自学学习场景，进一步增强其多功能性和适用性。对著名数据集进行的实证研究证明了我们提出的框架相对于现有谱聚类方法的优越性，展示了其在不同数据集和学习设置中的鲁棒性和可扩展性。通过弥合约束学习和半定谱聚类之间的差距，我们的工作有助于谱聚类技术的进步，为研究人员和从业者提供了解决各种实际应用中复杂聚类挑战的通用工具。提供对数据、代码和实验结果的访问以供进一步探索 (https://github.com/swarupbehera/SCCCS)。]]></description>
      <guid>https://arxiv.org/abs/2404.03012</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>参数化动作空间的基于模型的强化学习</title>
      <link>https://arxiv.org/abs/2404.03037</link>
      <description><![CDATA[arXiv:2404.03037v1 公告类型：新
摘要：我们提出了一种新颖的基于模型的强化学习算法——参数化动作的动态学习和预测控制（DLPA）——用于参数化动作马尔可夫决策过程（PAMDP）。代理学习参数化动作条件动力学模型，并使用修改后的模型预测路径积分控制进行规划。我们从理论上量化了规划过程中生成的轨迹和最佳轨迹之间的差异，即它们通过利普希茨连续性的镜头实现的价值。我们在几个标准基准上的实证结果表明，我们的算法比最先进的 PAMDP 方法实现了卓越的样本效率和渐近性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03037</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能本体：法学硕士辅助构建人工智能概念层次结构</title>
      <link>https://arxiv.org/abs/2404.03044</link>
      <description><![CDATA[arXiv:2404.03044v1 公告类型：新
摘要：人工智能本体（AIO）是人工智能（AI）概念、方法及其相互关系的系统化。 AIO 通过手动管理开发，并在大型语言模型 (LLM) 的额外帮助下，旨在通过提供涵盖人工智能技术的技术和伦理方面的全面框架来应对快速发展的人工智能领域。 AIO 的主要受众包括寻求 AI 领域标准化术语和概念的 AI 研究人员、开发人员和教育工作者。该本体围绕六个顶级分支构建：网络、层、函数、法学硕士、预处理和偏差，每个分支都旨在支持人工智能方法的模块化组合，并促进对人工智能中深度学习架构和道德考虑的更深入理解。
  AIO 的开发利用本体开发套件（ODK）进行创建和维护，其内容通过人工智能驱动的管理支持动态更新。这种方法不仅确保了本体在人工智能快速发展中的相关性，而且还通过简化新人工智能概念和方法的集成，显着增强了其对研究人员、开发人员和教育工作者的实用性。
  该本体的实用性通过在人工智能研究出版物目录中对人工智能方法数据的注释以及与 BioPortal 本体资源的集成来证明，突出了其跨学科研究的潜力。 AIO 本体是开源的，可在 GitHub (https://github.com/berkeleybop/artificial-intelligence-ontology) 和 BioPortal (https://bioportal.bioontology.org/ontologies/AIO) 上获取。]]></description>
      <guid>https://arxiv.org/abs/2404.03044</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>具有神经算子流的通用函数回归</title>
      <link>https://arxiv.org/abs/2404.02986</link>
      <description><![CDATA[arXiv:2404.02986v1 公告类型：新
摘要：函数空间的回归通常仅限于具有高斯过程先验的模型。我们引入了通用函数回归的概念，其中我们的目标是学习非高斯函数空间上的先验分布，该分布在数学上仍然易于函数回归处理。为此，我们开发了神经算子流（OpFlow），这是标准化流的无限维扩展。 OpFlow 是一个可逆算子，它将（可能未知的）数据函数空间映射到高斯过程中，从而可以对功能点评估进行精确的似然估计。 OpFlow 通过绘制高斯过程的后验样本并将其映射到数据函数空间，实现稳健且准确的不确定性量化。我们使用已知后验形式和非高斯过程的高斯过程生成的数据，以及具有未知闭合形式分布的真实世界地震图，实证研究了 OpFlow 在回归和生成任务上的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.02986</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>用于风力涡轮机异常检测的迁移学习应用</title>
      <link>https://arxiv.org/abs/2404.03011</link>
      <description><![CDATA[arXiv:2404.03011v1 公告类型：新
摘要：风力涡轮机的异常检测通常涉及使用正常行为模型来及早检测故障。然而，为每个涡轮机训练自动编码器模型非常耗时且资源密集。因此，迁移学习对于数据有限的风力涡轮机或计算资源有限的应用程序至关重要。本研究探讨了如何将跨涡轮机迁移学习应用于基于自动编码器的异常检测。在这里，自动编码器与重建误差的恒定阈值相结合，以确定输入数据是否包含异常。这些模型最初是根据一个或多个源风力涡轮机一年的数据进行训练的。然后使用来自另一台涡轮机的少量数据对它们进行微调。研究了三种微调方法：调整整个自动编码器、仅调整解码器或仅调整模型的阈值。将迁移学习模型的性能与根据目标风力涡轮机一年的数据进行训练的基线模型进行比较。本研究中进行的测试结果表明，与基于一台源风力涡轮机的数据训练的模型相比，基于多个风力涡轮机的数据训练的模型并没有提高异常检测能力。此外，与基线相比，修改模型的阈值可以带来可比甚至更好的性能，而微调解码器或自动编码器可以进一步增强模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03011</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>PiSSA：大型语言模型的主奇异值和奇异向量适应</title>
      <link>https://arxiv.org/abs/2404.02948</link>
      <description><![CDATA[arXiv:2404.02948v1 公告类型：新
摘要：随着法学硕士参数的扩展，微调整个模型的计算成本变得令人望而却步。为了应对这一挑战，我们引入了 PEFT 方法、主奇异值和奇异向量自适应（PiSSA），它可以优化显着减小的参数空间，同时实现或超越全参数微调的性能。 PiSSA 受到 Intrinsic SAID 的启发，它表明预先训练的、过度参数化的模型存在于低内在维度的空间中。因此，PiSSA 通过两个可训练矩阵 A 和 B 的乘积表示模型内的矩阵 W，加上用于误差校正的残差矩阵 $W^{res}$。采用SVD对W进行因式分解，并利用W的主奇异值和向量来初始化A和B。剩余奇异值和向量初始化剩余矩阵$W^{res}$，该矩阵在微调期间保持冻结。值得注意的是，PiSSA 与 LoRA 共享相同的架构。然而，LoRA 通过两个矩阵（用高斯噪声初始化的 A 和用零初始化的 B）的乘积来近似 Delta W，而 PiSSA 用主奇异值和原始矩阵 W 的向量初始化 A 和 B。PiSSA 可以更好地近似一开始就进行全参数微调的结果，改变重要的部分，同时冻结“嘈杂”的部分。相比之下，LoRA 冻结了原始矩阵并更新了“噪声”。这种区别使 PiSSA 的收敛速度比 LoRA 快得多，并最终实现了更好的性能。由于架构相同，PiSSA 继承了 LoRA 的许多优点，例如参数效率和与量化的兼容性。利用快速 SVD 方法，PiSSA 的初始化只需几秒钟，将 LoRA 切换到 PiSSA 的成本可以忽略不计。]]></description>
      <guid>https://arxiv.org/abs/2404.02948</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>SaTML '24 CNN 可解释性竞赛：概念级可解释性的新创新</title>
      <link>https://arxiv.org/abs/2404.02949</link>
      <description><![CDATA[arXiv:2404.02949v1 公告类型：新
摘要：可解释性技术对于帮助人类理解和监督人工智能系统很有价值。 SaTML 2024 CNN 可解释性竞赛征集了在 ImageNet 规模上研究卷积神经网络 (CNN) 的新方法。比赛的目的是帮助人类群众工作者识别 CNN 中的木马。本报告展示了四项特色竞赛参赛作品的方法和结果。通过可解释性工具帮助人类可靠地诊断木马仍然具有挑战性。然而，比赛的参赛作品贡献了新技术，并在 Casper 等人 2023 年的基准上创造了新纪录。]]></description>
      <guid>https://arxiv.org/abs/2404.02949</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>通过流形假设的视角进行深度生成模型：调查和新联系</title>
      <link>https://arxiv.org/abs/2404.02954</link>
      <description><![CDATA[arXiv:2404.02954v1 公告类型：新
摘要：近年来，人们对理解深度生成模型（DGM）和流形假设之间的相互作用越来越感兴趣。该领域的研究重点是了解常用 DGM 在学习未知低维流形支持的分布方面成功或失败的原因，以及开发明确设计用于解释流形支持数据的新模型。这种流形透镜既清晰地解释了为什么某些 DGM（例如扩散模型和一些生成对抗网络）在样本生成方面在经验上优于其他 DGM（例如基于似然性的模型，如变分自动编码器、归一化流或基于能量的模型），又提供了指导用于设计性能更高的 DGM。我们首次从这个角度对 DGM 进行了调查，并在此过程中做出了两项新颖的贡献。首先，我们正式确定在对低维数据建模时，高维可能性的数值不稳定性是不可避免的。然后，我们表明，学习到的自动编码器表示上的 DGM 可以解释为近似最小化 Wasserstein 距离：这一结果适用于潜在扩散模型，有助于证明其出色的实证结果。流形透镜提供了理解 DGM 的丰富视角，我们的目标是让 DGM 变得更容易获得和广泛使用。]]></description>
      <guid>https://arxiv.org/abs/2404.02954</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>结构健康监测的基础模型</title>
      <link>https://arxiv.org/abs/2404.02944</link>
      <description><![CDATA[arXiv:2404.02944v1 公告类型：新
摘要：结构健康监测（SHM）是确保民用基础设施安全可靠的一项关键任务，通常通过振动监测在桥梁和高架桥上实现。在本文中，我们首次提出使用带有 Masked Auto-Encoder 架构的 Transformer 神经网络作为 SHM 的基础模型。我们展示了这些模型通过自监督预训练从多个大型数据集中学习通用表示的能力，再加上特定于任务的微调，使它们能够在不同的任务上超越最先进的传统方法，包括异常检测（AD）和流量负载估计（TLE）。然后，我们广泛探索模型大小与准确性的权衡，并尝试知识蒸馏 (KD)，以提高较小 Transformer 的性能，使其能够直接嵌入到 SHM 边缘节点中。我们使用来自三个运营高架桥的数据展示了基础模型的有效性。对于 AD，我们在监控时间跨度仅为 15 个窗口的情况下实现了近乎完美的 99.9% 准确率。相比之下，基于主成分分析 (PCA) 的最先进方法仅考虑 120 个窗口就获得了第一个好的结果（95.03% 的准确度）。在两个不同的 TLE 任务中，我们的模型在多个评估指标（R$^2$ 分数、MAE% 和 MSE%）上获得了最先进的性能。在第一个基准测试中，我们在轻型和重型车辆交通方面分别获得了 0.97 和 0.85 的 R$^2$ 分数，而之前的最佳方法停留在 0.91 和 0.84。在第二个方法中，我们获得了 0.54 的 R$^2$ 分数，而现有最佳方法的分数为 0.10。]]></description>
      <guid>https://arxiv.org/abs/2404.02944</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>优化低功耗 MCU 上微型变压器的部署</title>
      <link>https://arxiv.org/abs/2404.02945</link>
      <description><![CDATA[arXiv:2404.02945v1 公告类型：新
摘要：Transformer 网络正在 NLP 和 CV 等许多领域迅速成为 SotA。与 CNN 类似，人们大力推动在极端边缘部署 Transformer 模型，最终适应 MCU 的微小功耗预算和内存占用。然而，这个方向的早期方法大多是临时的、特定于平台和模型的。这项工作旨在实现并优化编码器 Tiny Transformers 在商用 MCU 上的灵活多平台部署。我们提出了一个完整的框架，用于在单核和多核 MCU 上执行 Transformer 模型的端到端部署。我们的框架提供了一个优化的内核库，以最大限度地提高数据重用，并避免将不必要的数据编组操作放入关键的注意力块中。引入了一种新颖的 MHSA 推理计划，称为融合权重自注意力，离线融合线性投影权重，以进一步减少操作和参数的数量。此外，为了减轻注意力图计算所达到的内存峰值，我们提出了 MHSA 的深度优先平铺方案。我们在利用 ARM 和 RISC-V ISA 的三种不同 MCU 类别（即 STM32H7、STM32L4 和 GAP9 (RV32IMC-XpulpV2)）上评估我们的框架。与 SotA 库 CMSIS-NN (ARM) 和 PULP-NN (RISC-V) 相比，我们的平均延迟分别降低了 4.79 倍和 2.0 倍。此外，我们还表明，我们的 MHSA 深度优先切片方案将内存峰值降低了 6.19 倍，而融合权重注意力可以将运行时间减少 1.53 倍，并将参数数量减少 25%。我们报告了多个 Tiny Transformer 的显着改进：例如，在 GAP9 上执行基于雷达的手势识别任务的 Transformer 块时，我们实现了 0.14 毫秒的延迟和 4.92 微焦耳的能耗，降低了 2.32 倍与同一平台上的 SotA PULP-NN 库相比。]]></description>
      <guid>https://arxiv.org/abs/2404.02945</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>通过训练后层内多精度量化减少 DNN 内存占用</title>
      <link>https://arxiv.org/abs/2404.02947</link>
      <description><![CDATA[arXiv:2404.02947v1 公告类型：新
摘要：由于隐私问题，在资源受限的边缘设备上部署深度神经网络（DNN）模型的必要性变得越来越明显。为了促进从云计算到边缘计算的过渡，本文引入了一种有效减少 DNN 内存占用的技术，在保持模型准确性的同时适应资源受限的边缘设备的局限性。我们提出的技术称为训练后层内多精度量化（PTILMPQ），采用训练后量化方法，无需大量训练数据。通过估计网络内层和通道的重要性，所提出的方法可以在整个量化过程中实现精确的比特分配。实验结果表明，PTILMPQ 为在内存资源有限的边缘设备上部署 DNN 提供了一种有前途的解决方案。例如，在 ResNet50 的情况下，它的准确率达到了 74.57%，内存占用为 9.5 MB，与之前的类似方法相比减少了 25.49%，而准确率仅略有下降 1.08%。]]></description>
      <guid>https://arxiv.org/abs/2404.02947</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行可解释的交通流量预测</title>
      <link>https://arxiv.org/abs/2404.02937</link>
      <description><![CDATA[arXiv:2404.02937v1 公告类型：新
摘要：交通流量预测为智能交通系统的未来提供了重要的视角。可解释的预测为影响交通模式的因素提供了宝贵的见解，有助于城市规划者、交通工程师和政策制定者就基础设施发展、交通管理策略和公共交通规划做出明智的决策。尽管基于深度学习的预测方法广泛流行且准确性值得称赞，但其透明度和可解释性常常令人失望。最近，大规模时空数据的可用性和大型语言模型（LLM）的发展为城市交通预测开辟了新的机遇。随着法学硕士的流行，人们见证了基础模型在各种任务中潜在的推理和生成能力。将文本视为输入和输出，法学硕士在生成更直观和可解释的预测方面具有优势。因此，本文引入了TP-LLM，一种可解释的基于基础模型的交通预测方法，旨在更直接、更合理的预测。 TP-LLM 提出了一个将多模态因素统一为基于语言的输入的框架，TP-LLM 避免了复杂的时空数据编程，并且仅在微调基础模型下就优于最先进的基线。此外，TP-LLM 可以生成输入依赖性解释以实现更自信的预测，并且可以轻松推广到不同的城市动态，以使用类似的框架进行零样本预测。这些发现证明了法学硕士在可解释的交通预测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.02937</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>决策谓词图：增强树集成的可解释性</title>
      <link>https://arxiv.org/abs/2404.02942</link>
      <description><![CDATA[arXiv:2404.02942v1 公告类型：新
摘要：理解基于树的集成的决策及其关系对于机器学习模型解释至关重要。最近缓解人机循环解释挑战的尝试探索了利用图形简化和路径强调来提取模型基础的决策结构。然而，虽然这些努力增强了可视化体验，但它们可能会导致视觉上复杂的表示或损害原始集成模型的可解释性。为了应对这一挑战，特别是在复杂的场景中，我们引入了决策谓词图（DPG）作为与模型无关的工具，以提供模型的全局解释。 DPG 是一种图结构，它捕获基于树的集成模型和学习的数据集详细信息，保留特征、逻辑决策和预测之间的关系，以强调有洞察力的观点。利用众所周知的图论概念，例如中心性和社区的概念，DPG 为模型提供了额外的定量见解，补充了可视化技术，扩展了问题空间描述，并提供了多种扩展的可能性。实证实验证明了 DPG 在解决传统基准和复杂分类场景方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.02942</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>通过传递熵加速的卷积神经网络学习</title>
      <link>https://arxiv.org/abs/2404.02943</link>
      <description><![CDATA[arXiv:2404.02943v1 公告类型：新
摘要：最近，人们越来越关注应用传递熵（TE）来量化人工神经元之间的有效连接。在前馈网络中，TE 可用于量化位于不同层的神经元输出对之间的关​​系。我们的重点是如何将 TE 纳入卷积神经网络 (CNN) 架构的学习机制中。我们为 CNN 架构引入了一种新颖的训练机制，该机制集成了 TE 反馈连接。添加 TE 反馈参数可以加速训练过程，因为需要更少的 epoch。另一方面，它增加了每个时期的计算开销。根据我们对 CNN 分类器的实验，为了实现合理的计算开销和准确性权衡，仅考虑最后两个全连接层的神经元对的随机子集的神经间信息传输是有效的。 TE 充当平滑因子，产生稳定性并仅定期激活，而不是在处理每个输入样本后激活。因此，我们可以认为 TE 在我们的模型中是一个缓慢变化的元参数。]]></description>
      <guid>https://arxiv.org/abs/2404.02943</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>签名内核的高阶求解器</title>
      <link>https://arxiv.org/abs/2404.02926</link>
      <description><![CDATA[arXiv:2404.02926v1 公告类型：新
摘要：签名内核是用于分析多元时间序列的多种机器学习算法的核心。两个有界变化路径（例如时间序列数据的分段线性插值）的核通常通过求解两个独立时间变量中的双曲偏微分方程 (PDE) 的 Goursat 问题来计算。然而，这种方法对于高度振荡的输入路径来说变得不太实用，因为它们必须以足够精细的尺度进行解析才能准确地恢复其签名内核，从而导致显着的时间和内存复杂性。为了缓解这个问题，我们首先证明更广泛的路径类（称为 \emph{smooth rough paths}）的签名内核也满足 PDE，尽管是耦合方程组的形式。然后，我们使用这个结果引入新的算法来对签名内核进行数值逼近。由于有界变化路径（以及更一般的几何$p$-粗糙路径）可以通过分段平滑粗糙路径来近似，因此可以通过具有分段常数系数的显式耦合方程组来替换原始 Goursat 问题中具有快速变化系数的偏微分方程从原始输入路径的前几个迭代积分导出。虽然这种方法需要求解更多方程，但不需要回顾初始路径的复杂而精细的结构，这显着降低了与高振荡时间序列分析相关的计算复杂性。]]></description>
      <guid>https://arxiv.org/abs/2404.02926</guid>
      <pubDate>Fri, 05 Apr 2024 06:17:02 GMT</pubDate>
    </item>
    </channel>
</rss>