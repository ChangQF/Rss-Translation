<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>可解释的机器学习：柯尔莫哥洛夫-阿诺德网络模型在机翼升力预测中的应用</title>
      <link>https://arxiv.org/abs/2501.17896</link>
      <description><![CDATA[arXiv:2501.17896v1 公告类型：新
摘要：数据科学已成为科学探索的第四种范式。然而，许多机器学习模型都像黑匣子一样运行，对其预测背后的原因提供有限的洞察。这种缺乏透明度是从数据中生成新知识的缺点之一。最近，Kolmogorov-Arnold 网络或 KAN 被提出作为一种嵌入可解释人工智能的替代模型。这项研究展示了 KAN 在新的科学探索中的潜力。KAN 与其他五种流行的监督机器学习模型一起应用于航空航天工程中众所周知的翼型升力预测问题。使用早期对 2900 种不同翼型的研究生成的标准数据。KAN 在测试数据上的表现最好，R2 得分为 96.17%，超过了基线模型和多层感知器。通过修剪和符号化模型来显示 KAN 的可解释性，从而得到一个输入变量的升力系数方程。发现从 KAN 模型中检索到的可解释信息与已知的机翼产生升力的物理原理一致，从而证明了其在科学探索中具有潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.17896</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>共享 DIFF 变压器</title>
      <link>https://arxiv.org/abs/2501.17900</link>
      <description><![CDATA[arXiv:2501.17900v1 Announce Type: new 
摘要：DIFF Transformer 通过增强对相关上下文的关注同时抑制噪声来改善注意力分配。它引入了一种差分注意力机制，计算两个独立生成的注意力分布之间的差异，有效地降低了噪音并促进了稀疏注意力模式。然而，DIFF Transformer 中的独立信号生成导致参数冗余和信息利用率不理想。在本文中，我们提出了共享 DIFF Transformer，它借鉴了差分放大器的思想，通过引入共享基矩阵来建模全局模式并结合低秩更新来增强特定任务的灵活性。这种设计显着减少了参数冗余，提高了效率，并保留了强大的噪声抑制能力。实验结果表明，与 DIFF Transformer 相比，我们的方法在长序列建模、关键信息检索和上下文学习等任务中取得了更好的性能。我们的工作为优化差异注意力机制和推进强大的 Transformer 架构提供了一种新颖而有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2501.17900</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DReSS：数据驱动的大型语言模型的正则化结构化精简</title>
      <link>https://arxiv.org/abs/2501.17905</link>
      <description><![CDATA[arXiv:2501.17905v1 公告类型：新
摘要：大型语言模型 (LLM) 在各个领域都取得了重大进展，但其规模不断扩大导致计算和内存成本高昂。最近的研究表明，LLM 表现出稀疏性，可以通过修剪技术减小模型大小。然而，现有的修剪方法通常遵循先修剪后微调的范式。由于修剪后的组件仍包含有价值的信息，直接删除它们通常会导致不可逆的性能下降，从而给微调期间恢复性能带来巨大的计算负担。在本文中，我们提出了一种新颖的范式，首先应用正则化，然后修剪，最后微调。基于此范式，我们引入了 DReSS，一种简单有效的数据驱动的正则化结构化精简 LLM 方法。通过利用少量数据对要修剪的组件进行正则化，DReSS 会提前将重要信息明确地传输到模型的其余部分。与直接剪枝相比，这可以减少参数删除造成的信息损失，从而增强其语言建模能力。实验结果表明，即使在极端剪枝率下，DReSS 的表现也明显优于现有的剪枝方法，显著降低了延迟并提高了吞吐量。]]></description>
      <guid>https://arxiv.org/abs/2501.17905</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度集成秘密执行经验贝叶斯</title>
      <link>https://arxiv.org/abs/2501.17917</link>
      <description><![CDATA[arXiv:2501.17917v1 公告类型：新
摘要：量化神经网络中的不确定性是一个高度相关的问题，对许多应用至关重要。解决此任务的两个主要范例是贝叶斯神经网络 (BNN) 和深度集成。尽管这两种方法之间存在一些相似之处，但通常推测它们缺乏正式联系，因此被理解为根本不同。由于依赖贝叶斯范式，BNN 通常被吹捧为更具原则性，而集成则被认为更具临时性；然而，深度集成往往在经验上优于 BNN，但对于为什么会这样没有令人满意的解释。在这项工作中，我们通过展示深度集成执行精确的贝叶斯平均来弥合这一差距，其后验是通过隐式学习的数据相关先验获得的。换句话说，深度集成是贝叶斯的，或者更具体地说，它们实现了经验贝叶斯程序，其中先验是从数据中学习的。这种观点有两个主要好处：（i）它从理论上证明了深度集成的合理性，从而解释了它们强大的经验性能；（ii）对学习到的先验的检查表明它是由点质量的混合给出的——使用如此强大的先验有助于阐明观察到的集成现象。总的来说，我们的工作提供了对深度集成的新认识，这不仅本身很有趣，而且还可能产生推动这些模型经验改进的未来见解。]]></description>
      <guid>https://arxiv.org/abs/2501.17917</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双曲空间中贝叶斯系统发育的变分组合序贯蒙特卡罗</title>
      <link>https://arxiv.org/abs/2501.17965</link>
      <description><![CDATA[arXiv:2501.17965v1 公告类型：新
摘要：双曲空间自然编码层次结构，例如系统发育（二叉树），其中向内弯曲的测地线反映了通过最小共同祖先的路径，而邻域的指数增长反映了拓扑的超指数扩展。这种扩展挑战限制了基于欧几里得的近似推理方法的效率。受树和双曲空间之间几何连接的启发，我们开发了两种顺序搜索算法的新型双曲扩展：组合和嵌套组合顺序蒙特卡罗（\textsc{Csmc} 和 \textsc{Ncsmc}）。我们的方法引入了一致和无偏估计量，以及变分推理方法（\textsc{H-Vcsmc} 和 \textsc{H-Vncsmc}），它们的表现优于欧几里得方法。实证结果表明，高维系统发育推断任务的速度、可扩展性和性能有所提高。]]></description>
      <guid>https://arxiv.org/abs/2501.17965</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KoopAGRU：使用门控循环单元进行基于 Koopman 的时间序列异常检测</title>
      <link>https://arxiv.org/abs/2501.17976</link>
      <description><![CDATA[arXiv:2501.17976v1 公告类型：新
摘要：由于涉及复杂且非线性的时间动态，现实世界时间序列数据中的异常检测是一项具有挑战性的任务。本文介绍了一种新的深度学习模型 KoopAGRU，旨在通过结合快速傅里叶变换 (FFT)、深度动态模式分解 (DeepDMD) 和 Koopman 理论来解决此问题。FFT 允许 KoopAGRU 将时间数据分解为时变和时不变的组件，从而提供复杂模式的精确建模。为了更好地控制这两个组件，KoopAGRU 利用门循环单元 (GRU) 编码器来学习 Koopman 可观测量，从而增强了跨多个时间尺度的检测能力。KoopAGRU 在单个过程中进行训练并提供快速的推理时间。在各种基准数据集上进行的大量测试表明，KoopAGRU 的表现优于其他领先方法，在众所周知的时间序列数据集异常检测任务中获得了 90.88％ 的平均 F1 分数，并证明在现实场景中检测异常时高效可靠。]]></description>
      <guid>https://arxiv.org/abs/2501.17976</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态比对中对手的拓扑特征</title>
      <link>https://arxiv.org/abs/2501.18006</link>
      <description><![CDATA[arXiv:2501.18006v1 公告类型：新
摘要：多模态机器学习系统，尤其是那些对齐文本和图像数据的系统，如 CLIP/BLIP 模型，已经变得越来越普遍，但仍然容易受到对抗性攻击。虽然大量研究已经解决了单模态环境中的对抗性鲁棒性，但多模态系统的防御策略尚未得到充分探索。这项工作研究了图像和文本嵌入之间出现的拓扑特征，并展示了对抗性攻击如何破坏它们的对齐，从而引入独特的特征。我们特别利用了持久同源性，并引入了两种基于完全持久性和多尺度核方法的新型拓扑对比损失来分析对抗性扰动引入的拓扑特征。随着数据中引入更多的对抗性样本，我们观察到在对图像文本对齐的广泛攻击中出现的所提出的拓扑损失的单调变化模式。通过设计一种算法将这些签名反向传播到输入样本，我们能够将这些签名集成到最大平均差异测试中，从而创建一类利用拓扑签名进行更好的对抗检测的新型测试。]]></description>
      <guid>https://arxiv.org/abs/2501.18006</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少即是多：从小神经网络演化出大神经网络</title>
      <link>https://arxiv.org/abs/2501.18012</link>
      <description><![CDATA[arXiv:2501.18012v1 公告类型：新
摘要：与大型且结构静态的传统人工神经网络相比，我们研究小型且动态的前馈神经网络，其节点可以在训练期间添加（或减去）。网络中的单个神经元权重控制网络的大小，而权重本身由优化网络其他权重和偏差的相同梯度下降算法进行优化，但具有与大小相关的目标或损失函数。我们在非线性回归和分类任务上训练和评估这种灵活的神经网络，它们的表现优于相应的静态网络。在训练过程中将网络扩展到最小、适当或最佳大小可以阐明网络动态，并与在训练后但在部署之前修剪大型网络形成对比。]]></description>
      <guid>https://arxiv.org/abs/2501.18012</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>诱导 2:4 稀疏性的近端算子</title>
      <link>https://arxiv.org/abs/2501.18015</link>
      <description><![CDATA[arXiv:2501.18015v1 公告类型：新
摘要：AI 加速器和 GPU 的最新硬件进步允许高效计算稀疏矩阵乘法，尤其是当 4 个连续权重中的 2 个设置为零时。然而，这种所谓的 2:4 稀疏性通常会降低模型的准确性。我们推导出一个正则化器，它利用特征的局部相关性来在训练模型中找到更好的稀疏度掩码。我们通过推导近端算子将正则化器与局部平方损失联合最小化，我们证明它在 2:4 稀疏情况下有一个有效的解决方案。优化掩码后，我们使用 maskedgradient 更新来进一步最小化局部平方损失。我们在玩具问题上说明了我们的方法，并将其应用于修剪多达 70B 参数的整个大型语言模型。在高达 13B 的模型上，我们比以前最先进的算法有所改进，而在 70B 模型上，我们的性能与它们相当。]]></description>
      <guid>https://arxiv.org/abs/2501.18015</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基尼系数空间中的 KNN 和 K-means</title>
      <link>https://arxiv.org/abs/2501.18028</link>
      <description><![CDATA[arXiv:2501.18028v1 公告类型：新
摘要：本文基于基尼参数空间的概念，介绍了对 K 均值和 K 最近邻 (KNN) 算法的创新增强。与传统距离度量不同，基于基尼的度量结合了基于值和基于等级的信息，提高了对噪声和异常值的鲁棒性。这项工作的主要贡献包括：提出一种基于基尼的度量，可以捕获等级信息和值距离；提出一种基尼 K 均值算法，该算法已被证明可以收敛并表现出对噪声数据的弹性；并引入一种基尼 KNN 方法，其在噪声环境中的表现可与 Hassanat 距离等最先进的方法相媲美。对 UCI 存储库中的 14 个数据集进行的实验评估证明了基于基尼的算法在聚类和分类任务中的卓越性能和效率。这项工作为在机器学习和统计分析中利用基于排名的测量开辟了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2501.18028</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合定价和资源分配：一种最优在线学习方法</title>
      <link>https://arxiv.org/abs/2501.18049</link>
      <description><![CDATA[arXiv:2501.18049v1 公告类型：新
摘要：我们研究动态定价和资源分配的在线学习问题，我们做出联合定价和库存决策以最大化整体净利润。我们考虑需求对价格的随机依赖性，这使资源分配过程复杂化，并给问题带来了显着的非凸性和不平滑性。为了解决这个问题，我们开发了一种有效的算法，该算法利用多个 OCO 代理的“下置信边界 (LCB)”元策略。我们的算法实现了 $\tilde{O}(\sqrt{Tmn})$ 遗憾（对于 $m$ 个供应商和 $n$ 个消费者），这对于时间范围 $T$ 是最优的。我们的结果表明统计学习方法与复杂运筹学问题的有效结合。]]></description>
      <guid>https://arxiv.org/abs/2501.18049</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SAeUron：具有稀疏自动编码器的扩散模型中的可解释概念学习</title>
      <link>https://arxiv.org/abs/2501.18052</link>
      <description><![CDATA[arXiv:2501.18052v1 公告类型：新
摘要：最近的机器反学习方法为从扩散模型中去除不需要的概念提供了有希望的解决方案。然而，传统方法在很大程度上依赖于微调，对它们引入基础模型的变化提供的信息很少，因此不清楚概念是真正被删除了还是仅仅被掩盖了。在这项工作中，我们介绍了 SAeUron，这是一种利用稀疏自动编码器 (SAE) 学习的特征来反学习文本到图像扩散模型中不需要的概念的新方法。首先，我们证明，以无监督方式在扩散模型的多个去噪时间步的激活上训练的 SAE 可以捕获与特定概念相对应的稀疏且可解释的特征。在此基础上，我们提出了一种选择概念特定特征的方法。这使得能够对模型的激活进行精确干预，以阻止目标内容，同时保持模型的整体性能。在对象和风格反学习方面，对竞争性 UnlearnCanvas 基准的评估凸显了 SAeUron 的领先性能。此外，我们表明，使用单个 SAE，我们可以同时删除多个概念，并且与其他方法相比，SAeUron 消除了生成不想要的内容的可能性，即使在对抗性攻击下也是如此。]]></description>
      <guid>https://arxiv.org/abs/2501.18052</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当前的病理学基础模型无法适应医学中心的差异</title>
      <link>https://arxiv.org/abs/2501.18055</link>
      <description><![CDATA[arXiv:2501.18055v1 公告类型：新
摘要：病理基础模型 (FM) 对医疗保健有着巨大的前景。在将它们用于临床实践之前，必须确保它们能够适应不同医疗中心之间的差异。我们测量病理基础模型是关注组织和癌症类型等生物学特征，还是关注染色程序和其他差异引入的众所周知的混杂医疗中心特征。我们引入了稳健性指数。这种新颖的稳健性指标反映了生物学特征在多大程度上主导了混杂特征。对十个当前公开的病理基础模型进行了评估。我们发现，所有当前评估的病理基础模型都在很大程度上代表了医疗中心。观察到稳健性指数存在显著差异。到目前为止，只有一个模型的稳健性指数大于 1，这意味着生物学特征主导了混杂特征，但只是略微主导。描述了一种定量方法来衡量医疗中心差异对基于 FM 的预测性能的影响。我们分析了不稳健性对下游模型分类性能的影响，发现癌症类型分类错误不是随机的，而是具体归因于同一中心的混杂因素：来自同一医疗中心的其他类别的图像。我们对 FM 嵌入空间进行了可视化，发现这些空间由医疗中心组织起来的程度比由生物因素组织起来的程度更高。因此，对医疗中心的预测比对组织来源和癌症类型的预测更准确。这里介绍的稳健性指数旨在推动临床采用稳健可靠的病理 FM。]]></description>
      <guid>https://arxiv.org/abs/2501.18055</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过序贯概率比检验学习有限时间内早期分类的最佳停止方法</title>
      <link>https://arxiv.org/abs/2501.18059</link>
      <description><![CDATA[arXiv:2501.18059v1 公告类型：新
摘要：时间敏感的机器学习受益于序贯概率比检验 (SPRT)，它为时间序列的早期分类提供了最佳停止时间。然而，在输入长度有限的有限时间范围内，由于需要向后归纳，确定最佳停止规则变得计算密集，限制了实际适用性。因此，我们引入了 FIRMBOUND，这是一个基于 SPRT 的框架，可以有效地从训练数据中估计向后归纳的解决方案，弥合了最佳停止理论与实际部署之间的差距。它采用密度比估计和凸函数学习来为充分统计和条件期望提供统计一致的估计量，这两者对于解决向后归纳都是必不可少的；因此，FIRMBOUND 最小化了贝叶斯风险以达到最优。此外，我们提出了一种使用高斯过程回归的更快替代方案，它显着减少了训练时间，同时保持了较低的部署开销，尽管统计一致性可能会受到影响。在独立同分布 (i.i.d.)、非独立同分布、二元、多类、合成和真实世界数据集上进行的实验表明，FIRMBOUND 在贝叶斯风险和速度-准确度权衡方面实现了最优。此外，它会在可能的情况下将权衡边界推进至最优状态，并减少决策时间方差，从而确保可靠的决策。代码可在 https://github.com/Akinori-F-Ebihara/FIRMBOUND 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2501.18059</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FinanceQA：评估大型语言模型的财务分析能力的基准</title>
      <link>https://arxiv.org/abs/2501.18062</link>
      <description><![CDATA[arXiv:2501.18062v1 公告类型：新
摘要：FinanceQA 是一个测试套件，用于评估 LLM 在模拟现实世界投资工作的复杂数值金融分析任务上的表现。尽管最近取得了进展，但目前的 LLM 未能满足金融机构严格的准确性要求，模型在模拟对冲基金、私募股权公司、投资银行和其他金融机构在职分析的实际任务中约 60% 都失败了。主要挑战包括手动传播指标、遵守标准会计和公司估值惯例以及在信息不完整的情况下进行分析——特别是在需要生成假设的多步骤任务中。这种性能差距凸显了现有 LLM 功能与专业财务分析需求之间的脱节，而当前的测试架构尚未对这些需求进行充分测试。结果表明，需要更高质量的训练数据来支持此类任务，我们使用 OpenAI 的微调 API 进行了实验。 FinanceQA 已在 [此 https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA) 公开发布。]]></description>
      <guid>https://arxiv.org/abs/2501.18062</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>