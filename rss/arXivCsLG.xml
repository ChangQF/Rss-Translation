<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 06 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用大型多模态模型解释生成模型的潜在表示</title>
      <link>https://arxiv.org/abs/2402.01858</link>
      <description><![CDATA[学习数据生成潜在因素的可解释表示是人工智能发展的一个重要课题。随着大型多模态模型的兴起，它可以将图像与文本对齐以生成答案。在这项工作中，我们提出了一个框架，使用大型多模态模型来全面解释生成模型中的每个潜在因素。我们进一步测量生成的解释的不确定性，定量评估多个大型多模态模型中解释生成的性能，并定性可视化每个潜在因素的变化，以了解不同生成模型对解释的解缠结效果。最后，我们讨论最先进的大型多模态模型的解释能力和局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.01858</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:20 GMT</pubDate>
    </item>
    <item>
      <title>参数化特征迁移：使用基础模型的一次性联邦学习</title>
      <link>https://arxiv.org/abs/2402.01862</link>
      <description><![CDATA[在一次性联邦学习 (FL) 中，客户在一轮通信中协作训练全局模型。现有的一次性 FL 方法提高了通信效率，但代价是准确性下降。本文介绍了 FedPFT（参数化特征迁移联邦学习），这是一种利用基础模型的可迁移性来提高一次性 FL 的准确性和通信效率的方法。该方法涉及传输从基础模型中提取的特征的每个客户端参数模型（特别是高斯混合）。随后，采用每个参数模型来生成用于训练分类器头的合成特征。八个数据集的实验结果表明，FedPFT 增强了集中式和去中心化 FL 场景以及跨不同数据异质性设置（例如协变量转移和任务转移）的通信准确性前沿，提升幅度高达 20.6%。此外，FedPFT 遵循 FL 的数据最小化原则，因为客户端不发送真实特征。我们证明发送真实特征很容易受到有效的重建攻击。此外，我们表明 FedPFT 可以通过差分隐私来接受正式的隐私保证，这表明了有利的隐私与准确性权衡。]]></description>
      <guid>https://arxiv.org/abs/2402.01862</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:20 GMT</pubDate>
    </item>
    <item>
      <title>生态理性的元学习推理解释了人类类别学习</title>
      <link>https://arxiv.org/abs/2402.01821</link>
      <description><![CDATA[生态理性是指人类是适应环境的理性主体的观念。然而，由于两个原因，测试这一理论仍然具有挑战性：定义哪些任务在生态上有效以及为这些任务建立合理的模型存在困难。在这项工作中，我们证明大型语言模型可以生成与现实世界任务的统计数据相匹配的认知任务，特别是类别学习任务，从而解决第一个挑战。我们通过使用元学习框架派生适应这些任务的理性代理来解决第二个挑战，从而产生一类称为生态理性元学习推理（ERMI）的模型。在两个不同的实验中，ERMI 比其他七种认知模型更好地定量解释了人类数据。它还在定性水平上匹配人类行为：（1）它发现人类认为困难的相同任务很困难，（2）它变得更加依赖基于示例的策略来通过学习分配类别，以及（3）它概括为以类似人类的方式接受看不见的刺激。此外，我们还表明 ERMI 的生态有效先验使其能够在 OpenML-CC18 分类基准上实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.01821</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:19 GMT</pubDate>
    </item>
    <item>
      <title>多臂强盗与干扰</title>
      <link>https://arxiv.org/abs/2402.01845</link>
      <description><![CDATA[干扰实验对当代在线平台提出了重大挑战。先前对干扰实验的研究主要集中在政策的最终输出上。累积绩效虽然同样重要，但却不太为人所知。为了解决这个问题，我们引入了带有干扰的多臂老虎机（MABI）问题，其中学习者在 $T$ 轮的时间范围内为每个 $N$ 实验单元分配一个手臂。每轮中每个单元的奖励取决于{\em all}单元的处理，其中单元的影响随着单元之间的空间距离而衰减。此外，我们采用了一种通用设置，其中奖励函数由对手选择，并且可以在轮次和单位之间任意变化。我们首先证明，折回策略相对于最佳固定臂策略达到了最佳的{\em预期}遗憾$\tilde O(\sqrt T)$。尽管如此，任何折返政策的遗憾（作为随机变量）都会遭受很大的方差，因为它不考虑 $N$。我们提出了一种集群随机化策略，其遗憾 (i) 在 {\em 期望} 中是最优的，并且 (ii) 承认在 $N$ 中消失的高概率界限。]]></description>
      <guid>https://arxiv.org/abs/2402.01845</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:19 GMT</pubDate>
    </item>
    <item>
      <title>通过偏好学习获取适应度函数中的废物收集规划专家知识</title>
      <link>https://arxiv.org/abs/2402.01849</link>
      <description><![CDATA[本文涉及 COGERSA 废物收集过程。到目前为止，专家们已经使用试错机制手动设计了该流程。该流程并未在全球范围内进行优化，因为它是随着议会要求的出现而逐步在本地建立的。规划优化算法通常可以解决这个问题，但它们需要一个适应度函数来评估路线规划的质量。缺点是，由于过程的复杂性，即使是专家也无法以直接的方式提出建议。因此，本文的目标是利用现有的专家知识和专业知识，通过偏好框架构建适应度函数。专家们精心制定了几个关键绩效指标以及偏好判断，以学习有前景的适应度函数。特别是，它们的可加性属性使任务变得更加经济实惠，因为它允许使用路线而不是路线规划。此外，由于专家怀疑它们之间潜在存在（但未知）冗余，因此对这些指标进行了特征选择分析。实验结果证实了这一假设，因为当采用 21 个指标中的 6 或 8 个时，即可达到最佳 $C-$ 指数（$98\%$ 相对于 $94\%$ 左右）。特别是，卡车负载似乎是一个非常有前途的关键绩效指标，与沿非主要道路的行驶距离一起。与其他现有方法的比较表明，所提出的方法明显优于它们，因为 $C-$ 指数从 $72\%$ 或 $90\%$ 到 $98\%$。]]></description>
      <guid>https://arxiv.org/abs/2402.01849</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:19 GMT</pubDate>
    </item>
    <item>
      <title>立场文件：评估与基础模型集成的联邦学习的鲁棒性、隐私性和公平性</title>
      <link>https://arxiv.org/abs/2402.01857</link>
      <description><![CDATA[联邦学习（FL）虽然是去中心化机器学习的突破，但也面临着重大挑战，例如有限的数据可用性和计算资源的可变性，这些挑战可能会抑制模型的性能和可扩展性。将基础模型 (FM) 集成到 FL 中为这些问题提供了令人信服的解决方案，并有可能通过预训练和数据增强来增强数据丰富性并减少计算需求。然而，这种合并在鲁棒性、隐私性和公平性方面引入了新的问题，这些问题在现有的研究中尚未得到充分解决。我们通过系统地评估 FM-FL 集成在这些维度上的影响，对该领域进行了初步调查。我们分析所涉及的权衡，揭示这种集成带来的威胁和问题，并提出一套应对这些挑战的标准和策略。此外，我们还确定了推进该领域的潜在研究方向，为创建可靠、安全和公平的 FL 系统的未来发展奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2402.01857</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:19 GMT</pubDate>
    </item>
    <item>
      <title>更快、更轻松的法学硕士：对当前挑战和前进道路的调查</title>
      <link>https://arxiv.org/abs/2402.01799</link>
      <description><![CDATA[尽管法学硕士的性能令人印象深刻，但由于推理过程中大量的计算和内存需求，它们的广泛采用面临着挑战。模型压缩和系统级优化方法的最新进展旨在增强 LLM 推理。本调查概述了这些方法，强调了最新的发展。通过 LLaMA(/2)-7B 上的实验，我们评估了各种压缩技术，为在统一环境中高效部署 LLM 提供了实用见解。对LLaMA(/2)-7B的实证分析凸显了这些方法的有效性。根据调查见解，我们确定了当前的局限性并讨论了提高法学硕士推理效率的潜在未来方向。我们在 https://github.com/nyunAI/Faster-LLM-Survey 发布了代码库以重现本文中提出的结果]]></description>
      <guid>https://arxiv.org/abs/2402.01799</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:18 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的大型语言模型：调查</title>
      <link>https://arxiv.org/abs/2402.01801</link>
      <description><![CDATA[大型语言模型 (LLM) 在自然语言处理和计算机视觉等领域得到了广泛应用。除了文本、图像和图形之外，法学硕士还具有分析时间序列数据的巨大潜力，使气候、物联网、医疗保健、交通、音频和金融等领域受益。这篇调查论文对利用法学硕士进行时间序列分析的各种方法进行了深入的探索和详细的分类。我们解决了弥合法学硕士原始文本数据训练与时间序列数据的数值性质之间差距的固有挑战，并探索将法学硕士知识转移和提炼到数值时间序列分析的策略。我们详细介绍了各种方法，包括（1）法学硕士的直接提示，（2）时间序列量化，（3）对齐技术，（4）利用视觉模态作为桥接机制，以及（5）法学硕士与工具的结合。此外，这项调查还全面概述了现有的多模式时间序列和文本数据集，并深入探讨了这一新兴领域的挑战和未来机遇。我们维护一个最新的 Github 存储库，其中包含调查中讨论的所有论文和数据集。]]></description>
      <guid>https://arxiv.org/abs/2402.01801</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:18 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习中基于拍卖的模型交易市场</title>
      <link>https://arxiv.org/abs/2402.01802</link>
      <description><![CDATA[联邦学习 (FL) 因其在使用本地分布式数据训练模型方面的功效而日益得到认可。然而，在这个协作过程中共享数据的正确评估仍然没有得到充分解决。在这项工作中，我们将 FL 构建为一个模型市场，客户既充当买家又充当卖家，参与模型交易。这个 FL 市场允许客户通过销售自己的模型来获得金钱奖励，并通过购买其他模型来提高本地模型的性能。我们提出了一种基于拍卖的解决方案，以确保根据性能增益进行适当的定价。激励机制旨在鼓励客户如实披露其模型估值。此外，我们为营销运营引入了强化学习（RL）框架，旨在在动态和不断变化的市场状态下实现最大交易量。四个数据集的实验结果表明，所提出的 FL 市场可以实现高交易收入和公平的下游任务准确性。]]></description>
      <guid>https://arxiv.org/abs/2402.01802</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:18 GMT</pubDate>
    </item>
    <item>
      <title>公平信用评分的分布式鲁棒优化方法</title>
      <link>https://arxiv.org/abs/2402.01811</link>
      <description><![CDATA[信用评分已被欧盟委员会和美国总统行政办公室列为高风险分类任务，一个关键问题是基于对某些群体存在偏见的模型做出贷款审批决策的潜在危害。为了解决这个问题，最近的信用评分研究考虑了机器学习社区提出的一系列增强公平性的技术，以减少分类系统中的偏见和不公平待遇。虽然公平的定义或实施公平的方法可能有所不同，但大多数技术都忽视了结果的稳健性。这可能会造成这样的情况，即在训练集中有效纠正了不公平待遇，但在产生样本外分类时，又会出现不公平待遇。相反，在本文中，我们将研究如何将分布稳健优化（DRO）方法应用于信用评分，从而实证评估它们在公平性、正确分类能力以及解决方案针对边际变化的稳健性方面的表现。比例。通过这样做，我们发现 DRO 方法在公平性方面提供了实质性的改进，而性能几乎没有损失。因此，这些结果表明，只要在有效实施这些系统方面取得进一步进展，DRO 就可以提高信用评分的公平性。此外，我们的分析表明，许多常用的公平性指标不适合信用评分设置，因为它们取决于分类阈值的选择。]]></description>
      <guid>https://arxiv.org/abs/2402.01811</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:18 GMT</pubDate>
    </item>
    <item>
      <title>DoubleMLDeep：利用多模态数据估计因果效应</title>
      <link>https://arxiv.org/abs/2402.01785</link>
      <description><![CDATA[本文探讨了非结构化、多模态数据（即文本和图像）在因果推理和治疗效果估计中的使用。我们提出了一种适应双机器学习（DML）框架的神经网络架构，特别是部分线性模型。我们论文的另一个贡献是一种生成半合成数据集的新方法，该方法可用于评估存在文本和图像作为混杂因素的情况下因果效应估计的性能。所提出的方法和架构在半合成数据集上进行评估，并与标准方法进行比较，突出了在因果研究中直接使用文本和图像的潜在好处。我们的研究结果对经济学、市场营销、金融、医学和数据科学领域的研究人员和从业者具有重要意义，他们对使用非传统数据估计因果量感兴趣。]]></description>
      <guid>https://arxiv.org/abs/2402.01785</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:17 GMT</pubDate>
    </item>
    <item>
      <title>用于机械解释的图形张量表示法简介</title>
      <link>https://arxiv.org/abs/2402.01790</link>
      <description><![CDATA[图形张量表示法是一种表示张量线性运算的简单方法，源自物理学。现代深度学习几乎完全由张量上或张量之间的运算组成，因此轻松理解张量运算对于理解这些系统非常重要。当试图对神经网络学习的算法进行逆向工程以理解其行为时尤其如此：这个领域被称为机械可解释性。通常很容易对张量之间发生的操作感到困惑并忽略整体结构，但图形张量表示法可以更轻松地一目了然地解析事物并查看有趣的等价物。本文档的前半部分介绍了该符号并将其应用于一些分解（SVD、CP、Tucker 和张量网络分解），而后半部分则将其应用于一些现有的一些用于机械地理解语言模型的基础方法，大致遵循``变压器电路的数学框架”，然后用图形张量符号构建一个示例“感应头”电路。]]></description>
      <guid>https://arxiv.org/abs/2402.01790</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:17 GMT</pubDate>
    </item>
    <item>
      <title>通过圆锥优化实现稳健的支持向量机</title>
      <link>https://arxiv.org/abs/2402.01797</link>
      <description><![CDATA[我们考虑学习支持向量机对不确定性具有鲁棒性的问题。文献中已经确定，典型的损失函数（包括铰链损失）对数据扰动和异常值很敏感，因此在所考虑的设置中表现不佳。相反，使用 0-1 损失或合适的非凸近似会产生稳健的估计器，但代价是大量的计算成本。在本文中，我们使用混合整数优化技术来推导新的损失函数，与现有替代方案相比，该函数更好地逼近 0-1 损失，同时保留学习问题的凸性。在我们的计算结果中，我们表明所提出的估计器与标准 SVM 具有竞争力，在无异常值的情况下具有铰链损失，并且在存在异常值的情况下更好。]]></description>
      <guid>https://arxiv.org/abs/2402.01797</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:17 GMT</pubDate>
    </item>
    <item>
      <title>分布式学习中管理重尾梯度的改进量化策略</title>
      <link>https://arxiv.org/abs/2402.01798</link>
      <description><![CDATA[梯度压缩已成为解决分布式学习中通信效率挑战的关键技术。然而，在分布式深度学习中，我们发现梯度分布是重尾的，异常值会显着影响压缩策略的设计。当忽略这种重尾特征时，现有的参数量化方法会出现性能下降。在本文中，我们介绍了一种专门针对重尾梯度设计的新颖压缩方案，该方案有效地将梯度截断与量化结合起来。该方案在通信受限的分布式随机梯度下降（SGD）框架中得到了很好的实现。我们考虑遵循幂律分布的重尾梯度的一般族，我们的目标是最小化量化产生的误差，从而确定两个关键参数的最佳值：截断阈值和量化密度。我们对均匀和非均匀量化场景下的收敛误差界限进行了理论分析。与其他基准的比较实验证明了我们提出的方法在分布式学习环境中管理重尾梯度的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.01798</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:17 GMT</pubDate>
    </item>
    <item>
      <title>用于动态泊松-能斯特-普朗克系统的丰富物理信息神经网络</title>
      <link>https://arxiv.org/abs/2402.01768</link>
      <description><![CDATA[本文提出了一种无网格深度学习算法，即丰富的物理信息神经网络（EPINN），用于求解具有强耦合和非线性特性的动态泊松-能斯特-普朗克（PNP）方程。 EPINNs以传统的物理信息神经网络为基础框架，并添加自适应损失权重来平衡损失函数，通过基于最大似然估计更新每次迭代中的参数来自动分配损失权重。 EPINN 采用重采样策略来加速损失函数的收敛。同时，采用GPU并行计算技术来加速求解过程。提供了四个例子来证明所提出方法的有效性和有效性。数值结果表明，新方法在求解此类耦合非线性系统时比传统数值方法具有更好的适用性。更重要的是，EPINN 比传统的物理信息神经网络更准确、更稳定、更快速。这项工作提供了一种简单且高性能的数值工具，用于解决具有任意边界形状和边界条件的 PNP。]]></description>
      <guid>https://arxiv.org/abs/2402.01768</guid>
      <pubDate>Wed, 07 Feb 2024 00:55:16 GMT</pubDate>
    </item>
    </channel>
</rss>