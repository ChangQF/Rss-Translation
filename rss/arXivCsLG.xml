<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://arxiv.org/</link>
    <description>arXiv.org 电子打印档案上的计算机科学 - 机器学习 (cs.LG) 更新</description>
    <lastBuildDate>Mon, 27 Nov 2023 11:47:42 GMT</lastBuildDate>
    <item>
      <title>BackboneLearn：用于扩展基于混合整数优化的机器学习的库。 （arXiv：2311.13695v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13695</link>
      <description><![CDATA[我们推出 BackboneLearn：一个开源软件包和框架
将带有指标变量的混合整数优化 (MIO) 问题缩放为
高维问题。这种优化范式自然可以用于
提出可解释的监督学习中的基本问题（例如，
稀疏回归和决策树），在无监督学习中（例如，
聚类）等； BackboneLearn解决了上述问题
比精确方法更快，并且比常用方法具有更高的准确度
启发式。该包是用 Python 构建的，用户友好且易于使用
可扩展：用户可以直接为其 MIO 实现骨干算法
手头的问题。 BackboneLearn 的源代码可在 GitHub 上获取（链接：
https://github.com/chziakas/backbone_learn）。
]]></description>
      <guid>http://arxiv.org/abs/2311.13695</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:42 GMT</pubDate>
    </item>
    <item>
      <title>Bayes-xG：使用贝叶斯分层方法对预期进球 (xG) 进行球员和位置校正。 （arXiv：2311.13707v1 [stat.AP]）</title>
      <link>http://arxiv.org/abs/2311.13707</link>
      <description><![CDATA[本研究采用贝叶斯方法来探索玩家的影响
或预测击球概率的位置因素
目标，通过预期目标 (xG) 指标来衡量。利用公开可用的
来自 StatsBomb 的数据，贝叶斯分层逻辑回归是
构建，分析了英超联赛中大约 10,000 个镜头
联盟确定位置或球员水平的影响是否会影响预期进球数。这
研究结果揭示了仅包含距离的基本模型中的位置效应
以进球和射门角度作为预测指标，强调前锋和进攻
中场球员表现出更高的得分可能性。然而，这些影响
当引入更多信息的预测变量时，该值会减少。尽管如此，即使
有了额外的预测因素，玩家层面的影响仍然存在，这表明
某些球员具有显着的正或负 xG 调整，
影响他们在特定机会得分的可能性。该研究扩展了其
对西班牙西甲联赛和德国德甲联赛的数据进行分析，得出
可比较的结果。此外，本文还评估了先前的影响
结果的分布选择，得出的结论是，在
模型提供了良好的结果，但可以进行改进以增强采样
有效构建更复杂和更广泛的模型。
]]></description>
      <guid>http://arxiv.org/abs/2311.13707</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:42 GMT</pubDate>
    </item>
    <item>
      <title>节拍对齐的频谱图到节奏游戏图表的序列生成。 （arXiv：2311.13687v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13687</link>
      <description><![CDATA[“节奏游戏”的核心——玩家必须在其中执行动作的游戏
与一段音乐同步 - 是“图表”，即要给予的指令
玩家。我们新将图表生成制定为序列生成任务，并且
使用大型数据集训练 Transformer。我们还介绍了节奏通知
预处理和训练程序，其中一些建议是
成功培训不可或缺的一部分。我们的模型被发现优于
大型数据集的基线，并且还发现可以从预训练和
微调。
]]></description>
      <guid>http://arxiv.org/abs/2311.13687</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:41 GMT</pubDate>
    </item>
    <item>
      <title>用于图像分析的掩蔽条件扩散模型及其在婴儿虐待放射诊断中的应用。 (arXiv:2311.13688v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2311.13688</link>
      <description><![CDATA[经典的干骺端病变 (CML) 是一种明显的损伤，其严重程度
专门针对虐待婴儿。它通常发生在胫骨远端。帮助
放射科医生检测到这些细微的骨折，我们需要开发一个模型，可以
标记异常的远端胫骨 X 光片（即患有 CML 的）。很遗憾，
这种模型的开发需要一个庞大且多样化的训练数据库，
这通常是不可用的。为了解决这个限制，我们提出了一种新颖的
数据增强的生成模型。与以前的型号不同的是，
生成涵盖远端不同放射线外观的数据
胫骨 CML，我们提出的掩蔽条件扩散模型 (MaC-DM) 不仅
生成远端的逼真且范围广泛的合成图像
带或不带 CML 的胫骨 X 光片，它还生成其相关的
分段标签。为了实现这些任务，MaC-DM 结合了加权
胫骨和 CML 骨折部位的分割掩模作为附加
分类器指导的条件。我们模型的增强图像
提高了 ResNet-34 在分类正常放射线照片方面的性能
那些患有 CML 的人。此外，增强图像及其相关的
分割掩模增强了 U-Net 在标记区域中的性能
远端胫骨 X 光片上的 CML。
]]></description>
      <guid>http://arxiv.org/abs/2311.13688</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPU 张量核心进行张量学习的可扩展 CP 分解。 （arXiv：2311.13693v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13693</link>
      <description><![CDATA[CP分解是数据科学的强大工具，尤其是基因
分析、深度学习和量子计算。然而，应用
张量分解在很大程度上受到指数增量的阻碍
计算复杂度和存储消耗与张量的大小有关。
虽然我们现实世界中的数据通常以万亿甚至万亿级的形式呈现
百亿亿级张量，现有工作只能支持十亿级规模
张量。在我们的工作中，我们提出了百亿亿次张量来减轻
差距显着。具体来说，我们提出了一种基于压缩的张量
分解框架，即百亿亿次张量，支持百亿亿次张量
分解。然后，我们仔细分析了固有的并行性并提出
一系列提高计算效率的策略。最后，我们进行
分解从百万级到万亿级张量的实验
进行评估。与基线相比，百亿亿次张量支持 8,000 倍
更大的张量和高达 6.95 倍的加速。我们还将我们的方法应用于两个
现实世界的应用，包括基因分析和张量层神经网络
网络，其中的数值结果证明了可扩展性和
我们的方法的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2311.13693</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:41 GMT</pubDate>
    </item>
    <item>
      <title>推断示例：使用 Langevin Dynamics 进行预测编码。 （arXiv：2311.13664v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13664</link>
      <description><![CDATA[我们提出了一种新的通用深度参数学习算法
建立在预测编码（PC）框架之上的生成模型
计算神经科学。我们的方法将标准 PC 算法修改为
使性能达到标准变分的标准并超过
自动编码器（VAE）训练。通过将高斯噪声注入 PC 推理
我们将其重新设想为过阻尼朗之万采样，
促进严格证据下限 (ELBO) 的优化。
我们通过结合一个改进的无编码器训练方法
编码器网络为我们的朗之万采样提供摊销热启动
为此测试三个不同的目标。最后，为了增加鲁棒性
到采样步长并降低对曲率的敏感性，我们验证了
受黎曼启发的轻量级且易于计算的预处理形式
来自 SGD 文献的 Manifold Langevin 和自适应优化器。我们比较
使用我们的技术训练类似的生成模型来对抗 VAE
与接受过基于标准重新参数化技巧的 ELBO 训练的人进行对比。我们
观察我们的方法在许多方面的表现优于或匹配
指标，包括样本质量，同时收敛于数量的一小部分
SGD 训练迭代次数。
]]></description>
      <guid>http://arxiv.org/abs/2311.13664</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:40 GMT</pubDate>
    </item>
    <item>
      <title>基于联合梯度和损失的集群联邦学习设计。 （arXiv：2311.13665v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13665</link>
      <description><![CDATA[本文提出了一种新颖的集群 FL 框架，可实现分布式边缘
具有非 IID 数据的设备独立地形成多个集群
提出了分布式方式并在每个集群内实施 FL 训练。
特别是，我们设计的集群 FL 算法必须克服两个挑战
与 FL 训练相关。一、服务器FL训练有限
信息（即参数服务器只能获取FL模型
每个设备的信息）和有限的计算能力来查找
大量设备之间存在差异。二、每个设备没有
其他设备的数据信息用于设备集群，只能使用
从服务器接收到的全局FL模型参数及其数据信息
确定其集群身份，这会增加设备的难度
聚类。为了克服这两个挑战，我们提出了联合梯度和
基于损失的分布式聚类方法，其中每个设备确定其
考虑梯度相似性和训练损失的聚类标识。这
提出的聚类方法不仅考虑了一个局部 FL 模型如何
设备对每个簇都有贡献，而且对梯度下降的方向也有贡献
从而提高聚类速度。通过将集群决策委托给边缘
设备，每个设备都可以充分利用其私有数据信息
确定自己的集群身份，从而减少集群开销
提高整体集群性能。仿真结果表明
我们提出的聚类 FL 算法可以将聚类迭代减少多达
与现有基线相比，达到 99%。
]]></description>
      <guid>http://arxiv.org/abs/2311.13665</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:40 GMT</pubDate>
    </item>
    <item>
      <title>语言模型反转。 （arXiv：2311.13647v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13647</link>
      <description><![CDATA[语言模型生成下一个标记的分布；我们可以用这个吗
恢复提示令牌的信息？我们考虑语言问题
模型反演并表明下一个令牌概率包含令人惊讶的
有关前面文本的信息量。通常我们可以恢复文本
如果它对用户隐藏，则激发恢复方法
未知提示仅给出模型的当前分布输出。我们认为
各种模型访问场景，并展示即使没有预测
词汇表中的每个标记我们都可以通过以下方式恢复概率向量
搜索。在 Llama-2 7b 上，我们的反演方法用 BLEU 重建提示
$59$ 和 $78$ 的代币级 F1，并准确恢复 $27\%$ 的提示。代码
如需重现所有实验，请访问
此 http 网址
]]></description>
      <guid>http://arxiv.org/abs/2311.13647</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:39 GMT</pubDate>
    </item>
    <item>
      <title>评估可部署终身学习的预训练模型。 （arXiv：2311.13648v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13648</link>
      <description><![CDATA[我们创建了一个新颖的基准来评估可部署的终身学习
视觉强化学习（RL）系统，在精心策划的模型上进行预训练
数据集，并提出了一种新颖的可扩展终身学习系统，能够
保留先前学习的 RL 任务中的知识。我们的基准措施
可部署的终身学习系统的功效，该系统的评估依据
可扩展性、性能和资源利用率。我们提出的系统一旦
在数据集上进行预训练，可以部署以执行持续学习
看不见的任务。我们提出的方法由少量镜头类增量组成
基于学习（FSCIL）的任务映射器和完全训练的编码器/主干
使用预训练数据集。对应的策略参数
然后加载识别的任务来执行该任务。我们证明这个系统
由于内存较小，可以扩展以合并大量任务
占用空间和更少的计算资源。我们在 DeLL 上进行实验
（终身学习的部署）Atari 游戏的基准以确定
系统的功效。
]]></description>
      <guid>http://arxiv.org/abs/2311.13648</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:39 GMT</pubDate>
    </item>
    <item>
      <title>高效变压器知识蒸馏：性能审查。 （arXiv：2311.13657v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2311.13657</link>
      <description><![CDATA[随着预训练 Transformer 语言模型不断实现
最先进的性能，自然语言处理社区已经
推动模型压缩和高效注意力机制的进步
解决高计算要求和有限的输入序列长度。
尽管做出了这些单独的努力，但尚未对此事进行调查
这两个字段的交集。在这项工作中，我们提供了一个评估
通过有效注意力的知识蒸馏进行模型压缩
变压器。我们为压缩提供性价比权衡
最先进的高效注意力架构以及在
与全神贯注的同行相比的表现。此外，我们
引入新的长上下文命名实体识别数据集 GONERD 来训练
并测试 NER 模型在长序列上的性能。我们发现
蒸馏有效的注意力变压器可以保留大量
原始模型性能，在短上下文任务中保留高达 98.6%
（GLUE、SQUAD、CoNLL-2003），长上下文中高达 94.6%
问答任务（HotpotQA、TriviaQA），高达 98.8%
长上下文命名实体识别（GONERD），同时减少推理
倍，高达 57.8%。我们发现，对于大多数任务的大多数模型来说，执行
知识蒸馏是产生高性能的有效方法
低成本的高效注意力模型。
]]></description>
      <guid>http://arxiv.org/abs/2311.13657</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:39 GMT</pubDate>
    </item>
    <item>
      <title>变压器梯度泄漏攻击与防御的理论见解。 （arXiv：2311.13624v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13624</link>
      <description><![CDATA[梯度深度泄漏 (DLG) 攻击已成为一种普遍且普遍的攻击方式。
通过检查提取敏感训练数据的高效方法
交换梯度。这种做法对个人隐私构成了重大威胁
个人和组织都一样。这项研究提出了一个全面的
梯度泄漏法具体应用于时的分析
基于变压器的模型。通过细致的检查，我们展示了
能够仅从梯度准确恢复数据并严格
研究可以执行梯度攻击的条件，
提供令人信服的证据。此外，我们重新评估了
在梯度上引入额外的噪声作为保护措施
梯度攻击。为了解决这个问题，我们概述了一个理论证明来分析
差异隐私框架内的相关隐私成本。
此外，我们确认随机梯度下降的收敛性
(SGD) 扰动梯度下的算法。本研究的主要目的
是为了增强对梯度泄漏攻击和防御的理解
策略，同时积极促进隐私保护的发展
专门为基于变压器的模型量身定制的技术。通过脱落
浅谈与梯度相关的漏洞和对策
泄漏，这项研究旨在促进保护敏感信息的进步
在基于变压器的模型中保护数据和维护隐私。
]]></description>
      <guid>http://arxiv.org/abs/2311.13624</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:38 GMT</pubDate>
    </item>
    <item>
      <title>及时的风险控制：负责任地部署大型语言模型的严格框架。 （arXiv：2311.13628v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13628</link>
      <description><![CDATA[最近大型语言模型能力的爆炸性增长导致
对如何最好地促使模型执行给定任务的兴趣浪潮。尽管
简单地根据平均表现来选择提示可能很诱人
验证集，这可能会导致部署响应异常差
产生的，特别是对于境况最差的用户。为了缓解这种前景，
我们提出了 Prompt Risk Control，一个用于选择提示的轻量级框架
基于信息风险度量系列的严格上限。我们
提供在一组不同的指标上产生界限的方法，包括
衡量最坏情况反应和发电差异的数量
整个用户群体的质量。此外，我们还扩展了底层
统计边界技术以适应分布的可能性
部署上的转变。开放式聊天等应用程序的实验，
医学问题总结和代码生成突出了这样的
框架可以通过降低最坏情况的风险来促进负责任的部署
结果。
]]></description>
      <guid>http://arxiv.org/abs/2311.13628</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:38 GMT</pubDate>
    </item>
    <item>
      <title>跨越训练进度：用于增强数据集修剪的时间双深度评分 (TDDS)。 （arXiv：2311.13613v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.13613</link>
      <description><![CDATA[数据集剪枝旨在构建能够实现性能的核心集
与原始的完整数据集相当。大多数现有的数据集修剪方法
通常依靠基于快照的标准来识别代表性样本
导致各种修剪和跨架构的泛化能力较差
场景。最近的研究通过扩大范围来解决这个问题
考虑的训练动态，包括遗忘事件和
概率变化，通常使用平均方法。然而，这些作品
努力整合更广泛的训练动态而不忽视
概括性良好的样本，在
平均方式。在本研究中，我们提出了一种新颖的数据集修剪方法
称为时间双深度评分（TDDS）来解决这个问题。 TDDS
利用双深度策略来实现合并之间的平衡
广泛的训练动态并识别数据集的代表性样本
修剪。在第一个深度中，我们估计每个样本个体的序列
跨越培训进度的贡献，确保全面
整合训练动态。在第二个深度，我们重点关注
在第一深度中确定的样本贡献的可变性
突出显示普遍化的样本。在 CIFAR 上进行了大量实验
和ImageNet数据集验证了TDDS相对于之前SOTA的优越性
方法。特别是在 CIFAR-100 上，我们的方法达到了 54.51% 的准确率
仅 10% 训练数据，超过随机选择 7.83% 等
比较方法至少提高了 12.69%。
]]></description>
      <guid>http://arxiv.org/abs/2311.13613</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:37 GMT</pubDate>
    </item>
    <item>
      <title>用于解决在线持续学习挑战的基于密度分布的学习框架。 （arXiv：2311.13623v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.13623</link>
      <description><![CDATA[在本文中，我们通过以下方式解决在线持续学习 (CL) 的挑战：
引入基于密度分布的学习框架。 CL，特别是
类增量学习，能够适应新的测试分布，同时
从单遍训练数据流中不断学习，这更重要
符合现实场景的实际应用需求。
然而，现有的 CL 方法经常遭受灾难性遗忘和
由于算法设计复杂，计算成本较高，限制了其
实际使用。我们提出的框架通过实现克服了这些限制
卓越的平均精度和时空效率，提升性能
CL 和经典机器学习之间的差距。具体来说，我们采用
每个 CL 任务的独立生成核密度估计 (GKDE) 模型。
在测试阶段，GKDE 使用自我报告的最大概率
密度值来确定哪一个负责预测传入
测试实例。基于 GKDE 的学习目标可以确保样本具有
相同的标签被分组在一起，而不同的实例被推送
相距较远。在多个 CL 数据集上进行的大量实验验证了
我们提出的框架的有效性。我们的方法优于流行的 CL
以显着的优势接近，同时保持竞争性的时空
效率，使我们的框架适合实际应用。代码
将在 https://github.com/xxxx/xxxx 提供。
]]></description>
      <guid>http://arxiv.org/abs/2311.13623</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:37 GMT</pubDate>
    </item>
    <item>
      <title>使用文本到视频先验为草图注入生命力。 （arXiv：2311.13608v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.13608</link>
      <description><![CDATA[草图是人类用来表达的最直观、最通用的工具之一
以视觉方式传达他们的想法。动画草图打开了另一个维度
表达想法，并被设计师广泛用于各种目的。
动画草图是一个费力的过程，需要丰富的经验和
专业的设计能力。在这项工作中，我们提出了一种方法
自动为单个主题草图添加运动（因此，“呼吸生命
进入其中”），只需提供指示所需动作的文本提示即可。
输出是以矢量表示形式提供的短动画，可以是
轻松编辑。我们的方法不需要大量的培训，而是
利用大型预训练文本到视频扩散模型的运动先验
使用分数蒸馏损失来指导笔划的放置。推广
自然流畅的运动并更好地保留草图的外观，我们
通过两个组件对学习到的运动进行建模。第一个管理小型地方
变形，第二个控制全局仿射变换。
令人惊讶的是，我们发现即使是难以生成草图视频的模型
其本身仍然可以作为抽象动画的有用支柱
交涉。
]]></description>
      <guid>http://arxiv.org/abs/2311.13608</guid>
      <pubDate>Mon, 27 Nov 2023 11:47:36 GMT</pubDate>
    </item>
    </channel>
</rss>