<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过主动学习视角进行叠加</title>
      <link>https://arxiv.org/abs/2412.16168</link>
      <description><![CDATA[arXiv:2412.16168v1 公告类型：新
摘要：叠加或神经元多义性是可解释性领域的重要概念，可以说它们是我们解码机器学习黑匣子道路上最复杂、最美丽的障碍。本文背后的想法是研究是否可以使用主动学习方法解码叠加。虽然叠加似乎是一种在更小的空间中安排更多特征以更好地利用有限资源的尝试，但可能值得检查叠加是否依赖于任何其他因素。本文使用 CIFAR-10 和 Tiny ImageNet 图像数据集以及 ResNet18 模型，并比较了基线和主动学习模型，并通过多个标准检查了它们中叠加的存在，包括 t-SNE 可视化、余弦相似度直方图、Silhouette 分数和 Davies-Bouldin 指数。与我们的预期相反，主动学习模型在特征分离和整体准确性方面并没有显着优于基线。这表明，非信息性样本选择和对不确定样本的潜在过度拟合可能阻碍了主动学习模型更好地概括的能力，这表明可能需要更复杂的方法来解码叠加并可能减少它。]]></description>
      <guid>https://arxiv.org/abs/2412.16168</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文线索：评估 EHR 临床预测任务的长上下文模型</title>
      <link>https://arxiv.org/abs/2412.16178</link>
      <description><![CDATA[arXiv:2412.16178v1 公告类型：新
摘要：在电子健康记录 (EHR) 上训练的基础模型 (FM) 已在众多临床预测任务中取得了最先进的结果。但是，大多数现有的 EHR FM 的上下文窗口小于 1k 个标记。这阻止了它们对可能超过 10k 个事件的完整患者 EHR 进行建模。次二次长上下文架构（例如 Mamba）的最新进展提供了一种有希望的解决方案。但是，它们在 EHR 数据中的应用尚未得到很好的研究。我们通过首次系统地评估上下文长度对建模 EHR 数据的影响来解决这一差距。我们发现更长的上下文模型可以提高预测性能——我们的基于 Mamba 的模型在 EHRSHOT 预测基准上的 9/14 个任务上超越了之前的最新技术。然而，对于临床应用，仅靠模型性能是不够的——对 EHR 独特属性的稳健性至关重要。因此，我们还评估了 EHR 数据中三个以前未被充分探索的属性的模型：(1) “复制转发”诊断的普遍性，这会导致 EHR 序列中标记的人工重复；(2) EHR 事件之间的不规则时间间隔，这可能导致上下文窗口内的时间跨度范围很广；(3) 疾病复杂性随着时间的推移自然增加，这使得 EHR 中较晚的标记比较早的标记更难预测。对我们的 EHRSHOT 结果进行分层，我们发现每个属性的较高级别与模型性能呈负相关，但较长的上下文模型对这些属性的更极端级别更为稳健。我们的工作突出了使用长上下文架构对 EHR 数据进行建模的潜力，并提供了一个案例研究，用于识别由自然语言之外的领域驱动的序列数据建模的新挑战。我们在以下位置发布我们的模型和代码：https://github.com/som-shahlab/long_context_clues]]></description>
      <guid>https://arxiv.org/abs/2412.16178</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HashEvict：使用局部敏感哈希的预注意 KV 缓存驱逐策略</title>
      <link>https://arxiv.org/abs/2412.16187</link>
      <description><![CDATA[arXiv:2412.16187v2 公告类型：新
摘要：基于 Transformer 的大型语言模型 (LLM) 使用键值 (KV) 缓存通过存储过去 token 的键和值嵌入来显著加速推理。但是，此缓存会消耗大量 GPU 内存。在这项工作中，我们引入了 HashEvict，这是一种使用局部敏感哈希 (LSH) 来压缩 KV 缓存的算法。HashEvict 快速定位缓存中与当前查询 token 余弦不同的 token。这是通过计算当前 token 查询和缓存 token 键的二值化高斯投影之间的汉明距离来实现的，投影长度远小于嵌入维度。我们在 GPU 内存中维护一个轻量级二进制结构以方便这些计算。与计算注意力来确定 token 保留的现有压缩策略不同，HashEvict 会预先做出这些决定，从而降低计算成本。此外，HashEvict 是动态的 - 在每个解码步骤中，当前 token 的键和值都会替换预期产生最低注意力分数的 token 的嵌入。我们证明 HashEvict 可以将 KV 缓存压缩 30%-70%，同时在推理、多项选择、长上下文检索和摘要任务中保持高性能。]]></description>
      <guid>https://arxiv.org/abs/2412.16187</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习的十年：《七侠荡寇志》综述</title>
      <link>https://arxiv.org/abs/2412.16188</link>
      <description><![CDATA[arXiv:2412.16188v1 公告类型：新
摘要：过去十年来，深度学习从根本上重塑了人工智能的格局，在不同领域取得了显著成就。这些发展的核心是擅长自动特征提取的多层神经网络架构，从而显著改善了机器学习任务。为了揭开这些进步的神秘面纱并提供易于理解的指导，我们通过对该领域的广泛调查，全面概述了最具影响力的深度学习算法。我们的讨论集中在关键架构上，包括残差网络、Transformers、生成对抗网络、变分自动编码器、图神经网络、对比语言图像预训练和扩散模型。我们详细介绍了它们的历史背景，强调了它们的数学基础和算法原理，并研究了后续的变体、扩展和实际考虑因素，例如训练方法、规范化技术和学习率计划。除了历史和技术见解之外，我们还讨论了它们的应用、挑战和潜在的研究方向。本调查旨在为寻求进入尖端深度学习方法的新手和过渡到这个快速发展领域的经验丰富的研究人员提供实用手册。]]></description>
      <guid>https://arxiv.org/abs/2412.16188</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>直线的实值连分式</title>
      <link>https://arxiv.org/abs/2412.16191</link>
      <description><![CDATA[arXiv:2412.16191v1 公告类型：新
摘要：在无界平面中，直线被广泛用于数学分析。它们是方便的工具。然而，那些具有高斜率值的直线变得无界的速度比独立变量要快。因此，在这项工作中，通过引入一个正的参数非线性项使直线有界。直线被转换成有界的非线性曲线，其无界的速度比独立变量慢得多。这个变换方程可以表示为直线的连分式。连分式是实值的，收敛到变换方程的解。按照欧拉的方法，连分式被简化为无穷级数。通过解决图像分类问题证明了连分式有界性质的实用性。使用回归线的连分式在 Fashion-MNIST 灰度图像数据集上估计的参数比线性参数具有更小的方差、收敛速度更快、更准确。此外，该多维参数估计问题可以利用连分式的参数在$xy-$平面上表示，并且平面图上会出现模式。]]></description>
      <guid>https://arxiv.org/abs/2412.16191</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgroXAI：面向农业 4.0 的可解释 AI 驱动作物推荐系统</title>
      <link>https://arxiv.org/abs/2412.16196</link>
      <description><![CDATA[arXiv:2412.16196v1 公告类型：新
摘要：今天，农业作物多样化是满足日益增长的粮食需求和提高食品安全和质量的关键问题。由于自然资源的减少、可耕地的有限以及气候变化造成的不可预测的气候条件，这一问题被认为是下一代农业面临的最重要挑战。在本文中，我们采用物联网 (IoT)、机器学习 (ML) 和可解释人工智能 (XAI) 等新兴技术来提高农业部门的运营效率和生产力。具体来说，我们提出了一种基于边缘计算的可解释作物推荐系统 AgroXAI，该系统根据天气和土壤条件为某个地区推荐合适的作物。在这个系统中，我们使用 ELI5、LIME、SHAP 等方法为 ML 模型决策提供局部和全局解释，并将其集成到 ML 模型中。更重要的是，我们使用反事实可解释性方法提供区域替代作物建议。通过这种方式，我们设想我们提出的 AgroXAI 系统将成为下一代农业中提供区域作物多样性的平台。]]></description>
      <guid>https://arxiv.org/abs/2412.16196</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳定机器学习以获得可重复和可解释的结果：一种针对特定主题见解的新型验证方法</title>
      <link>https://arxiv.org/abs/2412.16199</link>
      <description><![CDATA[arXiv:2412.16199v1 公告类型：新
摘要：机器学习正在通过提高诊断准确性和个性化治疗来改变医学研究。在大型数据集上训练的通用 ML 模型可以识别出跨人群的广泛模式，但它们的有效性往往受到人类生物学多样性的限制。这引起了人们对使用个人数据进行更精确预测的受试者特定模型的兴趣。然而，这些模型成本高昂且难以开发。为了解决这个问题，我们提出了一种新颖的验证方法，该方法使用通用 ML 模型来确保在组和受试者特定级别上可重复的性能和强大的特征重要性分析。我们在九个数据集上测试了一个随机森林 (RF) 模型，这些数据集在领域、样本大小和人口统计数据方面各不相同。应用了不同的验证技术来评估准确性和特征重要性一致性。为了引入可变性，我们对每个受试者进行了多达 400 次试验，每次试验随机播种 ML 算法。这为每个主题生成了 400 个特征集，我们从中确定了最重要的主题特定特征。然后从所有受试者特定结果中得出一个组特定特征重要性集。我们在性能和特征重要性一致性方面将我们的方法与传统验证方法进行了比较。我们的重复试验方法采用随机种子变化，一致地识别受试者级别的关键特征，并使用单一通用模型改进组级别特征重要性分析。受试者特定模型解决了生物变异问题，但资源密集。我们的新验证技术在通用 ML 模型中提供了一致的特征重要性和更高的准确性，为临床研究提供了一种实用且可解释的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.16199</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>显著性方法是编码器：分析逻辑关系以进行解释</title>
      <link>https://arxiv.org/abs/2412.16204</link>
      <description><![CDATA[arXiv:2412.16204v1 公告类型：新
摘要：随着性能的提高，神经网络架构也变得更加复杂，需要可解释性。因此，目前出现了许多新的和改进的方法，这些方法通常会生成所谓的显着图以提高可解释性。这些方法通常通过视觉期望来评估，但这通常会导致确认偏差。由于缺乏解释质量的通用指标、模型推理的不可访问的真实数据以及涉及的大量假设，多项研究声称发现了这些方法的缺陷。然而，这往往会导致不公平的比较指标。此外，大多数数据集（主要是图像或文本）的复杂性通常很高，因此无法近似所有可能的解释。出于这些原因，本文介绍了一种显着图评估测试：基于多个简单逻辑数据集上所有可能的模型推理提出受控实验。利用所包含的逻辑关系，我们旨在了解不同的显著性方法如何在不同的类别判别场景中处理信息（例如通过互补和冗余信息）。通过引入多个新指标，我们分析了针对非信息归因分数基线的命题逻辑模式，以找到与典型期望的偏差。我们的结果表明，显著性方法可以将分类相关信息编码到显著性分数的排序中。]]></description>
      <guid>https://arxiv.org/abs/2412.16204</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的无人水面航行器波浪方向估计</title>
      <link>https://arxiv.org/abs/2412.16205</link>
      <description><![CDATA[arXiv:2412.16205v1 公告类型：新
摘要：无人水面航行器 (USV) 已成为海洋勘探、环境监测和自主导航的重要工具。准确估计波浪方向对于改善 USV 导航和确保操作安全至关重要，但传统方法通常成本高且空间分辨率有限。本文提出了一种基于机器学习的方法，利用 LSTM（长短期记忆）网络使用从 USV 收集的传感器数据来预测波浪方向。实验结果表明 LSTM 模型能够学习时间依赖性并提供准确的预测，优于更简单的基线。]]></description>
      <guid>https://arxiv.org/abs/2412.16205</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健应用的合成时间序列数据生成：PCG 案例研究</title>
      <link>https://arxiv.org/abs/2412.16207</link>
      <description><![CDATA[arXiv:2412.16207v1 公告类型：新
摘要：生成高质量的医疗时间序列数据对于推进医疗诊断和保护患者隐私至关重要。具体而言，合成逼真的心音图 (PCG) 信号具有巨大的潜力，可作为心脏病预筛查的经济高效工具。尽管具有潜力，但针对此特定应用的 PCG 信号合成在研究中受到的关注有限。在本研究中，我们使用并比较了三种来自不同类别的最先进的生成模型——WaveNet、DoppelGANger 和 DiffWave——以生成高质量的 PCG 数据。我们使用 George B. Moody PhysioNet Challenge 2022 的数据。我们的方法使用先前文献中在时间序列数据生成领域广泛使用的各种指标进行评估，例如平均绝对误差和最大平均差异。我们的结果表明，生成的 PCG 数据与原始数据集非常相似，表明我们的生成模型在生成逼真的合成 PCG 数据方面非常有效。在未来的工作中，我们计划将此方法纳入数据增强流程，以合成带有心脏杂音的异常 PCG 信号，以解决当前异常数据稀缺的问题。我们希望提高心脏病学诊断工具的稳健性和准确性，提高其检测心脏杂音的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.16207</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有永久故障的神经网络加速器可持续重用的算法策略</title>
      <link>https://arxiv.org/abs/2412.16208</link>
      <description><![CDATA[arXiv:2412.16208v1 公告类型：新
摘要：硬件故障是机器学习加速器面临的日益严峻的挑战，其中许多加速器都基于脉动阵列。当脉动阵列中发生永久性硬件故障时，现有的解决方案包括定位和隔离故障处理元件 (PE)、使用冗余 PE 重新执行，或者在某些极端情况下停用整个加速器以进行进一步调查。在本文中，我们提出了新颖的算法方法，通过独特地集成故障组件的行为而不是绕过它来缓解神经网络 (NN) 加速器中的永久性硬件故障。通过这样做，我们的目标是更可持续地使用加速器，其中故障硬件既不会被绕过也不会被丢弃，而是被赋予第二次生命。我们首先在 PyTorch 中引入了一个 CUDA 加速的脉动阵列模拟器，它使我们能够量化出现在连接两个 PE 的链路或权重寄存器中的永久故障的影响，其中一个位在 float32、float16 或 bfloat16 表示中卡在 0 或 1。然后，我们针对卡住故障子集提出了几种算法缓解技术，例如可逆缩放或激活和权重的移位，或对故障行为进行微调。值得注意的是，所提出的技术不需要任何硬件修改，而是依赖于广泛使用的基于脉动阵列的加速器的现有组件，例如规范化、激活和存储单元。使用在 MNIST、CIFAR-10 和 ImageNet 上训练的全连接和卷积 NN 进行大量实验评估表明，所提出的容错方法与原始无故障精度相匹配或非常接近。]]></description>
      <guid>https://arxiv.org/abs/2412.16208</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于树的模型从不平衡数据中学习的挑战：患病率估计系统地依赖于超参数，并且可能出现向上偏差</title>
      <link>https://arxiv.org/abs/2412.16209</link>
      <description><![CDATA[arXiv:2412.16209v1 公告类型：新
摘要：许多研究领域都出现了不平衡的二元分类问题。当使用机器学习模型解决这些问题时，通常对多数类进行子采样（即欠采样）以创建（更）平衡的数据集进行模型训练。这会使模型的预测产生偏差，因为模型从不遵循与新数据相同的数据生成过程的数据集中学习。解决这种偏差的一种方法是根据用于创建训练数据集的多数类的采样率将结果预测解析地映射到新值。虽然这种方法可能对某些机器学习模型很有效，但我们发现以这种方式校准随机森林会产生意想不到的负面后果，包括可能向上偏差的流行率估计。这些流行率估计取决于 i) 随机森林中每次分割时考虑的预测因子数量；以及 ii) 使用的采样率。我们使用随机森林的已知属性和分析校准来解释前者。然而，在研究后一个问题时，我们有了令人惊讶的发现——与决策树偏向多数类的普遍看法相反，它们实际上可能偏向少数类。]]></description>
      <guid>https://arxiv.org/abs/2412.16209</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FairTP：用于流量预测的长期公平框架</title>
      <link>https://arxiv.org/abs/2412.16214</link>
      <description><![CDATA[arXiv:2412.16214v1 公告类型：新
摘要：交通预测在智能交通系统中起着至关重要的作用。现有的方法主要侧重于提高整体准确性，往往忽略了一个关键问题：预测模型是否会导致交通部门做出有偏见的决策。在实践中，城市地区交通传感器的部署不均衡导致数据不平衡，导致预测模型在某些地区表现不佳，并导致不公平的决策。这种不平衡最终损害了居民的公平性和生活质量。此外，目前的公平意识机器学习模型只能确保特定时间点的公平性，无法在较长时间内保持公平性。随着交通状况的变化，这种静态公平方法变得无效。为了解决这一差距，我们提出了 FairTP，一个长期公平交通预测框架。我们引入了两个针对动态交通场景量身定制的新公平性定义。交通预测的公平性不是静态的；它随时间和地区而变化。每个传感器或城市区域可以在两种状态之间交替：“牺牲”（低预测精度）和“受益”（高预测精度）。当传感器的整体状态在给定时间段内保持相似时，即可实现长期公平性。我们定义了两种类型的公平性：基于区域的静态公平性和基于传感器的动态公平性。为了实现这一点，FairTP 集成了一个状态识别模块，将传感器的状态分类为“牺牲”或“收益”，从而实现长期的公平感知预测。此外，我们引入了一种状态引导的平衡采样策略来进一步增强公平性，解决了传感器分布不均匀的区域之间的性能差异。在两个真实数据集上进行的大量实验表明，FairTP 显著提高了预测公平性，同时最大限度地减少了准确度下降。]]></description>
      <guid>https://arxiv.org/abs/2412.16214</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphLoRA：通过 MoE 的图形协作增强 LLM 微调能力</title>
      <link>https://arxiv.org/abs/2412.16216</link>
      <description><![CDATA[arXiv:2412.16216v1 公告类型：新
摘要：低秩自适应（LoRA）是一种参数高效的微调方法，已广泛应用于LLM的各种下游应用中。与混合专家（MoE）技术相结合，微调方法已显示出模型能力的显着提高。然而，现有研究中多个专家的协调仅依赖于简单路由器功能分配的权重。由于MoE的不平衡负载问题，专家之间缺乏沟通和协作加剧了LLM的不稳定性。为了解决这个问题，我们提出了一种新颖的基于MoE图的LLM微调框架GraphLoRA，其中设计了一个图路由器功能来通过图神经网络（GNN）捕获专家之间的协作信号。GraphLoRA使所有专家都能理解输入知识并通过聚合操作与邻近专家共享信息。此外，为了提高每个专家的能力和协作能力，我们设计了两种新颖的协调策略：基于泊松分布的区分策略和基于正态分布的负载平衡策略。在四个真实数据集上进行的大量实验证明了我们的 GraphLoRA 在参数高效微调 LLM 方面的有效性，展示了在 GraphLoRA 的图路由器中促进多位专家协作的好处。]]></description>
      <guid>https://arxiv.org/abs/2412.16216</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于可信图对比学习的 GNN-Transformer 协作架构</title>
      <link>https://arxiv.org/abs/2412.16218</link>
      <description><![CDATA[arXiv:2412.16218v2 公告类型：新
摘要：图对比学习（GCL）已成为图表示学习领域的热门话题。与依赖大量标签的传统监督学习相比，GCL 利用增强策略来生成多个视图和正/负对，这两者都极大地影响了性能。不幸的是，常用的随机增强可能会扰乱图的底层语义。此外，传统的 GNN（GCL 中广泛使用的一种编码器）不可避免地面临过度平滑和过度压缩的问题。为了解决这些问题，我们提出了用于可信图对比学习的 GNN-Transformer 协作架构（GTCA），它继承了 GNN 和 Transformer 的优点，结合图拓扑来获得全面的图表示。理论分析验证了所提方法的可信度。在基准数据集上的大量实验证明了最先进的经验性能。]]></description>
      <guid>https://arxiv.org/abs/2412.16218</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>