<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 09 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>具有端到端强盗反馈的多级系统的分布式无悔学习</title>
      <link>https://arxiv.org/abs/2404.04509</link>
      <description><![CDATA[arXiv:2404.04509v1 公告类型：新
摘要：本文研究了具有端到端老虎机反馈的多级系统。在这样的系统中，每个作业在生成结果之前都需要经历多个阶段，每个阶段由不同的代理管理。每个智能体只能控制自己的行动并了解工作的最终结果。它既不了解也不控制代理在下一阶段采取的行动。本文的目标是开发分布式在线学习算法，在对抗环境中实现次线性遗憾。
  本文的设置显着扩展了传统的多臂老虎机问题，该问题仅考虑一个代理和一个阶段。除了传统多臂老虎机问题中的探索-利用困境之外，我们还表明，多阶段的考虑引入了第三个组成部分，即教育，其中智能体需要选择其动作以促进下一阶段智能体的学习。为了解决这个新引入的探索-利用-教育三难困境，我们提出了一种简单的分布式在线学习算法$\epsilon-$EXP3。我们从理论上证明$\epsilon-$EXP3算法是一种实现亚线性后悔的无后悔策略。仿真结果表明，对于传统的多臂老虎机问题，$\epsilon-$EXP3 算法显着优于现有的无悔在线学习算法。]]></description>
      <guid>https://arxiv.org/abs/2404.04509</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>长度控制的 AlpacaEval：消除自动评估器偏差的简单方法</title>
      <link>https://arxiv.org/abs/2404.04475</link>
      <description><![CDATA[arXiv:2404.04475v1 公告类型：新
摘要：与基于人工的评估相比，基于法学硕士的自动注释器由于其成本效益和可扩展性而成为法学硕士开发过程的关键组成部分。然而，这些自动注释器可能会引入难以消除的复杂偏差。即使是简单的、已知的混杂因素，例如对较长输出的偏好，仍然存在于现有的自动评估指标中。我们提出了一种简单的回归分析方法来控制自动评估中的偏差。作为一个真实的案例研究，我们专注于减少 AlpacaEval 的长度偏差，这是一种快速且经济实惠的聊天法学硕士基准，使用法学硕士来估计响应质量。尽管 AlpacaEval 与人类偏好高度相关，但众所周知，它更喜欢生成更长输出的模型。我们引入了一个长度控制的 AlpacaEval，旨在回答反事实问题：“如果模型和基线的输出具有相同的长度，偏好是什么？”。为了实现这一目标，我们首先拟合一个广义线性模型，根据我们想要控制的中介（长度差异）和其他相关特征来预测感兴趣的偏置输出（自动注释器偏好）。然后，我们通过预测偏好来获得长度控制的偏好，同时以零长度差异调节 GLM。长度控制不仅提高了模型冗长操作的稳健性，我们还发现它与 LMSYS 的 Chatbot Arena 的 Spearman 相关性从 0.94 增加到 0.98。我们在 https://tatsu-lab.github.io/alpaca_eval/ 发布了代码和排行榜。]]></description>
      <guid>https://arxiv.org/abs/2404.04475</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>DELTA：解耦长尾在线持续学习</title>
      <link>https://arxiv.org/abs/2404.04476</link>
      <description><![CDATA[arXiv:2404.04476v1 公告类型：新
摘要：实现无处不在的人工智能的一个重大挑战是模型在数据遵循长尾分布的现实场景中快速学习新信息的能力有限，同时避免忘记以前获得的知识。在这项工作中，我们研究了未充分探索的长尾在线持续学习（LTOCL）问题，该问题旨在从顺序到达的类不平衡数据流中学习新任务。每个数据仅观察一次用于训练，而不知道任务数据分布。我们提出了 DELTA，一种解耦学习方法，旨在增强学习表征并解决 LTOCL 中的严重不平衡问题。我们通过采用监督对比学习来吸引相似的样本并排斥不同的（类外）样本来增强学习过程。此外，通过在训练期间使用均衡损失平衡梯度，DELTA 显着提高了学习成果并成功减轻了灾难性遗忘。通过广泛的评估，我们证明 DELTA 提高了增量学习的能力，超越了现有的 OCL 方法。我们的结果表明 OCL 在实际应用中的应用前景广阔。]]></description>
      <guid>https://arxiv.org/abs/2404.04476</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>通过约束多目标联合学习实现 SecureBoost 的超参数优化</title>
      <link>https://arxiv.org/abs/2404.04490</link>
      <description><![CDATA[arXiv:2404.04490v1 公告类型：新
摘要：SecureBoost 是一种树增强算法，利用同态加密（HE）来保护垂直联邦学习中的数据隐私。 SecureBoost 及其变体已广泛应用于金融和医疗保健等领域。然而，假设隐私受到保护，SecureBoost 的超参数通常是启发式配置的，仅用于优化模型性能（即效用）。我们的研究发现 SecureBoost 及其一些变体仍然容易受到标签泄漏的影响。此漏洞可能会导致 SecureBoost 当前的启发式超参数配置在实用性、隐私性和效率之间进行次优权衡，而这些是构建值得信赖的联邦学习系统的关键要素。为了解决这个问题，我们提出了约束多目标 SecureBoost (CMOSB) 算法，该算法旨在逼近帕累托最优解，每个解都是一组超参数，实现效用损失、训练成本和隐私泄漏之间的最佳权衡。我们设计了三个目标的测量，包括一种名为实例集群攻击（ICA）的新型标签推理攻击来测量 SecureBoost 的隐私泄漏。此外，我们还提供了两种针对 ICA 的对策。实验结果表明，在效用损失、训练成本和隐私泄露之间的权衡方面，CMOSB 产生的超参数优于网格搜索和贝叶斯优化优化的超参数。]]></description>
      <guid>https://arxiv.org/abs/2404.04490</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>使用概率复合 B\'ezier 曲线生成多步轨迹预测的综合地面实况分布</title>
      <link>https://arxiv.org/abs/2404.04397</link>
      <description><![CDATA[arXiv:2404.04397v1 公告类型：新
摘要：适当的数据基础为训练和评估基于神经网络的概率轨迹预测模型提供了最重要的方面之一。在这方面，当前基准数据集的一个常见缺点是它们对样本轨迹集的限制以及缺乏实际的地面实况分布，这阻碍了使用更具表现力的误差指标，例如用于模型评估的 Wasserstein 距离。为此，本文提出了一种基于复合概率贝兹曲线的合成数据集生成新方法，该方法能够根据完整轨迹上的概率分布生成地面实况数据。这允许计算任意后验分布。该论文展示了使用生成的地面实况分布数据进行示例性轨迹预测模型评估。]]></description>
      <guid>https://arxiv.org/abs/2404.04397</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>用于无监督学习的动态切换层</title>
      <link>https://arxiv.org/abs/2404.04405</link>
      <description><![CDATA[arXiv:2404.04405v1 公告类型：新
摘要：设备上机器学习（ODML）可以在资源受限的设备上实现智能应用程序。然而，功耗带来了重大挑战，迫使模型精度和功率效率之间进行权衡，这通常限制了模型的复杂性。先前建立的门控压缩 (GC) 层提供了一种解决方案，通过选择性地门控缺乏感兴趣信号的样本，在不牺牲模型性能的情况下实现功率效率。然而，它们对真实标签的依赖限制了 GC 层的监督任务。这项工作引入了动态交换层（DSL），将GC层的优势扩展到无监督学习场景，并在不需要标记数据的情况下保持功效。 DSL 建立在 GC 架构之上，利用动态路径选择，并根据数据的固有结构调整模型复杂性。我们将 DSL 集成到 SoundStream 架构中，并证明，通过轻量级传递路由多达 80% 的样本，我们实现了 12.3 倍的计算量减少和 20.9 倍的模型大小减少。这可将设备上的推理延迟降低高达 26.5%，并将能效提高高达 21.4%，而不会影响模型性能。]]></description>
      <guid>https://arxiv.org/abs/2404.04405</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>AdamW 的隐式偏差：$\ell_\infty$ 范数约束优化</title>
      <link>https://arxiv.org/abs/2404.04454</link>
      <description><![CDATA[arXiv:2404.04454v1 公告类型：新
摘要： 具有解耦权重衰减的 Adam，也称为 AdamW，因其在语言建模任务中的优越性能而受到广泛好评，在泛化和优化方面超越了 $\ell_2$ 正则化的 Adam。然而，这种优势在理论上并没有得到很好的理解。这里的一个挑战是，尽管直观上 Adam 使用 $\ell_2$ 正则化优化了 $\ell_2$ 正则化损失，但尚不清楚 AdamW 是否优化了特定目标。在这项工作中，我们通过证明 AdamW 隐式执行约束优化，在理解 AdamW 的好处方面取得了进展。更具体地说，我们在全批次设置中表明，如果 AdamW 与任何部分和发散的非递增学习率计划收敛，则在 $\ell_\infty$ 的约束下，它必须收敛到原始损失的 KKT 点参数的范数受权重衰减因子的倒数限制。这个结果是基于这样的观察：Adam 可以被视为 SignGD 的平滑版本，这是相对于 $\ell_\infty$ 范数的归一化最速下降，以及权重衰减的归一化最速下降与 Frank-沃尔夫.]]></description>
      <guid>https://arxiv.org/abs/2404.04454</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>通过吉文斯旋转进行参数高效准正交微调</title>
      <link>https://arxiv.org/abs/2404.04316</link>
      <description><![CDATA[arXiv:2404.04316v1 公告类型：新
摘要：随着预训练语言模型（PLM）的性能日益强大且规模巨大，提高微调中的参数效率已成为有效且高效地适应各种下游任务的关键需求。微调方法的代表之一是正交微调（OFT），它严格保留参数空间内的角距离以保留预训练的知识。尽管具有经验有效性，OFT 仍然存在 $\mathcal{O}(d^2)$ 参数效率低和下游适应能力有限的问题。受吉文斯旋转的启发，在本文中，我们提出了准吉文斯正交微调（qGOFT）来解决该问题。我们首先使用$\mathcal{O}(d)$给定旋转来完成$SO(d)$中的任意正交变换并具有可证明的等价性，将参数复杂度从$\mathcal{O}(d^2)$降低到$\数学{O}(d)$。然后，我们在软正交正则化下引入灵活的范数和相对角度调整，以增强下游语义偏差的适应能力。对各种任务和 PLM 的大量实验验证了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.04316</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型上的逐像素强化学习：通过丰富反馈进行强化学习</title>
      <link>https://arxiv.org/abs/2404.04356</link>
      <description><![CDATA[arXiv:2404.04356v1 公告类型：新
摘要：潜在扩散模型是合成图像生成的最先进技术。为了使这些模型与人类偏好保持一致，利用人类反馈的强化学习来训练模型至关重要。布莱克等人。 al 2024 引入了去噪扩散策略优化（DDPO），它通过将其建模为具有最终奖励的马尔可夫链来解释生成的迭代去噪性质。由于奖励是决定模型在整个图像上的性能的单个值，因此模型必须在非常稀疏的奖励环境中导航，因此需要大量样本。在这项工作中，我们通过提出逐像素策略优化（PXPO）算法来扩展 DDPO，该算法可以获取每个像素的反馈，为模型提供更细致的奖励。]]></description>
      <guid>https://arxiv.org/abs/2404.04356</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>提示公共大语言模型为私有设备上应用程序合成数据</title>
      <link>https://arxiv.org/abs/2404.04360</link>
      <description><![CDATA[arXiv:2404.04360v1 公告类型：新
摘要：公共数据预训练是提高具有差分隐私（DP）的联邦学习（FL）性能的有效方法。本文研究了在公共数据上训练的大型语言模型 (LLM) 如何提高使用 DP 和 FL 训练的设备上语言模型的预训练数据质量。我们精心设计LLM提示来过滤和转换现有的公共数据，并生成新数据以类似于真实的用户数据分布。当对 Gboard（Google 键盘、生产移动键盘应用程序）。此外，我们的方法在对数百万移动设备进行 DP FL 微调期间实现了优于或与基线相当的评估精度，并且我们的最终模型在生产 A/B 测试中优于基线。我们的实验证明了法学硕士在合成接近私有分布的数据方面的优势，即使不访问私有数据，也提出了进一步缩小分配差距的未来研究方向。]]></description>
      <guid>https://arxiv.org/abs/2404.04360</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络 Lipschitz 常数的组合估计</title>
      <link>https://arxiv.org/abs/2404.04375</link>
      <description><![CDATA[arXiv:2404.04375v1 公告类型：新
摘要：Lipschitz 常数在证明神经网络对输入扰动和对抗性攻击的鲁棒性以及具有神经网络控制器的系统的稳定性和安全性方面发挥着至关重要的作用。因此，神经网络 Lipschitz 常数的紧界估计是一个经过充分研究的课题。然而，典型的方法涉及解决大型矩阵验证问题，对于更深的网络，其计算成本显着增加。在这封信中，我们提供了一种组合方法，通过将大型矩阵验证问题精确分解为较小的子问题来估计深度前馈神经网络的 Lipschitz 常数。我们进一步获得了适用于最常见的神经网络激活函数的封闭式解决方案，这将为在线控制设置中部署的神经网络提供快速的鲁棒性和稳定性证书。最后，我们通过数值实验证明，我们的方法大大减少了计算时间，同时产生的 Lipschitz 边界非常接近最先进的方法所实现的边界。]]></description>
      <guid>https://arxiv.org/abs/2404.04375</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>使用具有动态阈值的卷积自动编码器进行实时异常检测</title>
      <link>https://arxiv.org/abs/2404.04311</link>
      <description><![CDATA[arXiv:2404.04311v1 公告类型：新
摘要：现代消费级能源大部分是由实时智能计量系统产生的。这些经常包含异常现象，从而无法对系列的演变做出可靠的估计。这项工作引入了一种混合建模方法，将统计数据和具有动态阈值的卷积自动编码器相结合。该阈值是根据马哈拉诺比斯距离和移动平均值确定的。它已经使用从智能计量系统收集的现实能源消耗数据进行了测试。该解决方案包括连接到先进监控系统的实时米级异常检测系统。这通过检测异常数据移动并提供早期预警做出了重大贡献。早期检测和随后的故障排除可以为组织和消费者带来经济利益，并防止灾难发生。]]></description>
      <guid>https://arxiv.org/abs/2404.04311</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的半空间特征学习</title>
      <link>https://arxiv.org/abs/2404.04312</link>
      <description><![CDATA[arXiv:2404.04312v1 公告类型：新
摘要：目前对于神经网络特征学习存在两种极端观点——（i）神经网络简单地实现了核方法（如 NTK），因此没有学习到任何特征（ii）神经网络可以表示（并因此学习）复杂的层次结构适合数据的特征。我们在本文中认为，基于新颖的观点，这两种解释都不太可能是正确的。神经网络可以被视为专家的混合体，其中每个专家对应于通过一系列隐藏单元的（层数长度）路径。我们使用这种替代解释来激发一个模型，称为深度线性门控网络（DLGN），它位于深度线性网络和 ReLU 网络之间。与深度线性网络不同，DLGN 能够学习非线性特征（然后将其线性组合），并且与 ReLU 网络不同，这些特征最终很简单——每个特征实际上是一个区域的指示函数，该区域被紧凑地描述为（层数）输入空间中的半空间。与基于显着性/激活/梯度图的神经元局部可视化不同，该视点允许对特征进行全面的全局可视化。 DLGN 中的特征学习已被证明会发生，其发生机制是通过学习输入空间中包含目标函数平滑区域的半空间。由于 DLGN 的结构，后面层中的神经元与前面层中的神经元基本相同——它们都代表半空间——然而，梯度下降的动力学赋予后面层神经元不同的聚类。我们假设 ReLU 网络也具有类似的特征学习行为。]]></description>
      <guid>https://arxiv.org/abs/2404.04312</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>Faraday：用于智能电网的综合智能电表发生器</title>
      <link>https://arxiv.org/abs/2404.04314</link>
      <description><![CDATA[arXiv:2404.04314v1 公告类型：新
摘要：获取智能电表数据对于快速、成功地向电气化电网过渡至关重要，而电气化电网的基础是电动汽车 (EV) 和热泵等低碳技术提供的灵活性，并由可再生能源供电。然而，由于消费者隐私保护，这些数据很少可用于研究和建模目的。尽管许多人呼吁通过监管变革来解锁原始数据集，但我们认为这种方法将花费太长时间。合成数据通过克服隐私问题来直接应对这些挑战。在本文中，我们介绍了 Faraday，一种基于变分自动编码器 (VAE) 的模型，训练了来自英国一家能源供应商的 3 亿多个智能电表数据读数，其中包含财产类型和低碳技术 (LCT) 所有权等信息。该模型生成以这些标签为条件的家庭级综合负载曲线，我们将其输出与实际变电站读数进行比较，以展示对未来能源网格建模感兴趣的电网建模者如何将该模型用于实际应用。]]></description>
      <guid>https://arxiv.org/abs/2404.04314</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>研究自对弈语言模型的正则化</title>
      <link>https://arxiv.org/abs/2404.04291</link>
      <description><![CDATA[arXiv:2404.04291v1 公告类型：新
摘要：本文通过自我对弈探讨了各种形式的正则化在语言模型对齐背景下的影响。虽然来自人类反馈的强化学习 (RLHF) 和直​​接偏好优化 (DPO) 都需要收集成本高昂的人类注释的成对偏好，但自我游戏微调 (SPIN) 方法会用先前迭代生成的数据替换被拒绝的答案。然而，SPIN 方法在学习阶段存在性能不稳定的问题，可以通过混合前两个迭代来缓解这个问题。同样，我们建议在这项工作中从两个角度解决这个问题：首先，通过纳入额外的 Kullback-Leibler (KL) 正则化以保持在参考策略的附近；其次，通过使用虚拟游戏的想法，可以平滑之前所有迭代中的对手策略。特别是，我们表明基于 KL 的正则化器归结为用 SPIN 损失函数内部的基本策略的几何混合来替换先前的策略。最后，我们讨论 MT-Bench 以及 Hugging Face Open LLM Leaderboard 上的实证结果。]]></description>
      <guid>https://arxiv.org/abs/2404.04291</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:31 GMT</pubDate>
    </item>
    </channel>
</rss>