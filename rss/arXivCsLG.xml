<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Mon, 10 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>XMTC：可解释的多变量时间序列的早期分类在接触式手动运动学中</title>
      <link>https://arxiv.org/abs/2502.04398</link>
      <description><![CDATA[ARXIV：2502.04398V1公告类型：新 
摘要：可以在人类计算机相互作用（HCI）中测量手动运动学，目的是预测用户在触及式操作中的意图。使用多个手动传感器，正在捕获多元时间序列数据。给定许多对象上的许多可能的操作，目标是对多元时间序列数据进行分类，其中应尽早预测课程。已经为这种分类任务开发了许多机器学习方法，其中不同的方法在不同的数据集上产生了有利的解决方案。因此，我们采用包含不同方法的合奏方法。为了提供值得信赖的分类生产，我们提供了XMTC工具，该工具结合了协调的多视图可视化以分析预测。时间准确度图，混乱矩阵热图，时间信心热图和部分依赖图，可以鉴定早期预测和预测质量之间的最佳权衡，对挑战性分类条件的检测和分析以及对预测演变的研究概述和细节方式。我们在多种情况下采用XMTC到现实世界中的HCI数据，并表明可以在分类器以及哪些条件易于区分的情况下实现良好的分类预测，哪些多元时间序列测量构成了挑战，哪些功能具有最大的影响，并且具有最大的影响。]]></description>
      <guid>https://arxiv.org/abs/2502.04398</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI定义车辆的在线位置计划：优化订单服务的联合任务和时空异质模型微调</title>
      <link>https://arxiv.org/abs/2502.04399</link>
      <description><![CDATA[ARXIV：2502.04399V1公告类型：新 
摘要：包括基础模型（FMS）在内的人工智能（AI）的进步正在越来越多地改变人类社会，智能城市推动了城市生活的发展。和配备传感器的功能。特别是，尽管资源限制，乘车车辆可以有效地促进灵活的数据收集，并有助于城市情报。因此，这项工作探讨了一个有希望的方案，其中边缘辅助车辆执行订单服务的联合任务以及使用各种城市数据的新兴基金会模型进行微调。但是，由于其不一致的时空特征不一致，将VCS AI任务与常规订单服务任务集成在一起是具有挑战性的：（i）乘车订单和数据点点的分布（POIS）在地理上可能不一致，遵循先验未知的模式； （ii）它们具有不同形式的时间影响，即延长的等待使订单立即无效，而稳定性增加的数据逐渐降低了模型微调的实用性。要克服这些障碍，我们提出了一个基于多代理的在线框架加强学习（MARL），并仔细增强。新的服务质量（QOS）度量旨在表征和平衡这两个联合任务的实用性，这是在不同的数据量和陈旧性的影响下。我们还将图形神经网络（GNN）与MARL集成在一起，以增强状态表示形式，从而捕获车辆和跨地点之间的图形结构，时变的依赖关系。使用各种现实世界基础模型微调任务和纽约市出租车骑行订单数据集中的大量实验，证明了我们提出的方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.04399</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有混合方式和异质任务的联合学习的自适应原型知识转移</title>
      <link>https://arxiv.org/abs/2502.04400</link>
      <description><![CDATA[ARXIV：2502.04400V1公告类型：新 
摘要：多模式联合学习（MFL）使多个客户能够在多模式数据上协作培训模型，同时确保客户的隐私。但是，模式和任务异质性阻碍了客户学习统一表示，削弱了本地模型的概括，尤其是在MFL中，在具有混合方式的MFL中，只有某些客户只有多模式数据。在这项工作中，我们提出了一个基于自适应原型的多模式联合学习（APROMFL）框架，以解决混合方式和异质任务，以解决上述问题。我们的APOMFL通过没有以前的公共数据集的自适应构造的原型传递知识。客户端适应与任务一致的原型构建方法；服务器将客户端原型转换为统一的多模式原型，并将其汇总以形成全局原型，避免客户保留统一标签。我们将模型分为各种模块，仅汇总映射模块，以减少通信和计算开销。为了解决异质性的聚合问题，我们开发了一个基于客户关系图的方案，以动态调整聚合权重。代表性数据集的广泛实验APROMFL的证据有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.04400</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越插值：增强学习和图形神经网络的外推理</title>
      <link>https://arxiv.org/abs/2502.04402</link>
      <description><![CDATA[ARXIV：2502.04402V1公告类型：新 
摘要：尽管取得了不可思议的进展，但许多神经体系结构都无法正确推广其训练分布。因此，学习以正确且可推广的方式推理是机器学习中当前面临的基本挑战之一。在这方面，逻辑难题为我们充分理解和控制学习环境提供了出色的测试台。因此，他们允许评估遵循相同基础规则的以前看不见，更大，更困难的难题的性能。由于传统方法通常难以代表这种可扩展的逻辑结构，因此我们建议使用基于图的方法对这些难题进行建模。然后，我们研究了使所提出的模型能够在增强学习环境中学习可推广的解决方案的关键因素。我们的研究重点是体系结构的感应偏见，不同的奖励系统以及反复建模在启用顺序推理中的作用。通过广泛的实验，我们演示了这些元素如何在日益复杂的难题上成功推断出来。这些见解和框架为设计基于学习的系统的系统方式提供了一种能够超越插值的可推广推理的系统。]]></description>
      <guid>https://arxiv.org/abs/2502.04402</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FAS：快速的ANN-SNN转换大型语言模型</title>
      <link>https://arxiv.org/abs/2502.04405</link>
      <description><![CDATA[ARXIV：2502.04405V1公告类型：新 
摘要：在各种情况下，大型语言模型已被证明是LLM的良好替代方法。创建尖峰LLM的现有方法，即直接培训和ANN-SNN转换，通常会遭受性能降解和相对较高的计算成本。为了解决这些问题，我们提出了一种新颖的快速ANN-SNN转换策略（FAS），该策略将LLMS转化为两个阶段的尖峰LLM。第一阶段采用了预训练模型的全参数微调，因此它不需要从头开始进行任何直接培训。第二阶段引入了一种粗到精细的校准方法，以减少转化误差并提高准确性。我们对LLM四个不同尺度的语言和视觉任务进行的实验表明，FAS可以实现最先进的性能，但可以大大降低推理潜伏期和计算成本。例如，FAS仅需要8个时间段即可达到比OPT-7B模型高3％的精度，同时将能耗降低了96.63％。]]></description>
      <guid>https://arxiv.org/abs/2502.04405</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>校准的物理信息不确定性定量</title>
      <link>https://arxiv.org/abs/2502.04406</link>
      <description><![CDATA[ARXIV：2502.04406V1公告类型：新 
摘要：神经PDE提供了用于模拟复杂物理系统的计算昂贵数值PDE求解器的有效替代方案。但是，他们缺乏健壮的不确定性量化（UQ）限制了关键应用程序中的部署。我们引入了模型不合时宜的，物理信息的保形预测（CP）框架，该框架提供了保证的不确定性估计，而无需标记数据。通过利用基于物理的方法，我们能够量化和校准模型与PDE的不一致，而不是数据引起的不确定性。我们的方法将卷积层用作有限差分模板，并利用物理误差作为非符号得分，从而使无数据的UQ能够在一系列复杂的PDES范围内具有边际和关节覆盖范围的边际和关节覆盖范围。我们进一步验证了方法对融合反应器中血浆建模和射击设计的神经PDE模型的功效。]]></description>
      <guid>https://arxiv.org/abs/2502.04406</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>照明空间：建筑布局生成的深钢筋学习和激光墙分配</title>
      <link>https://arxiv.org/abs/2502.04407</link>
      <description><![CDATA[ARXIV：2502.04407V1公告类型：新 
摘要：在设计过程的早期阶段出现太空布局设计（SLD），但仍影响最终建筑结果的功能和美学。 SLD的复杂性需要创新的方法来有效探索庞大的解决方案空间。尽管基于图像的生成AI已成为潜在的解决方案，但它们通常依赖于缺乏建筑过程直观表示的基于像素的空间组成方法。本文提供了深入的增强学习（RL），因为它提供了一种程序性方法，可以直观地模仿人类设计师的过程。有效地将RL用于SLD需要一种探索空间构成方法来生成理想的设计解决方案。我们介绍了“激光墙”，这是一种新型的空间分配方法，将墙壁概念化为虚构光束的发射器，以分配空间。这种方法桥接了基于向量的基于矢量和基于像素的分区方法，在产生各种布局方面具有灵活性和探索性。我们提出了两种计划策略：单发计划，该计划在单个通行证中生成了整个布局，并且动态计划，可以通过不断改变激光墙来进行自适应的改进。此外，我们介绍了光滑和浅色的墙面转换，以进行光滑，快速的布局改进，以及无身份和身份的墙壁，用于多功能房间分配。我们开发了Spacelayoutgym，这是一种开源OpenAI健身房兼容模拟器，用于生成和评估太空布局。 RL代理处理输入设计方案并遵循平衡几何和拓扑要求的奖励功能，生成解决方案。我们的结果表明，基于RL的激光壁方法可以生成各种和功能性的空间布局，从而满足几何约束和拓扑要求，并且在架构上是直观的。]]></description>
      <guid>https://arxiv.org/abs/2502.04407</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将多模式转换为放射疗法的动作模型</title>
      <link>https://arxiv.org/abs/2502.04408</link>
      <description><![CDATA[ARXIV：2502.04408V1公告类型：新 
摘要：放射治疗是一种至关重要的癌症治疗方法，需要精确的计划平衡消除肿瘤和保存健康组织。传统的治疗计划（TP）是迭代，耗时的，并且依赖于人类专业知识，这可能会引入可变性和效率低下。我们提出了一个新颖的框架，以使用一些射击强化学习（RL）方法将大型多模式基础模型（MLM）转变为TP的动作模型。我们的方法利用了MLM广泛的物理，放射和解剖学知识，从而通过几次学习过程来增强它。这允许模型使用蒙特卡洛模拟器迭代改进治疗计划。我们的结果表明，这种方法在质量和效率方面都优于基于RL的常规方法，在前列腺癌数据的模拟中获得了更高的奖励分数和更优化的剂量分布。该概念验证表明，将高级AI模型集成到临床工作流程中，有可能提高放射治疗计划的速度，质量和标准化。]]></description>
      <guid>https://arxiv.org/abs/2502.04408</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于自动编码器的方法学习集合预测字段的低维表示</title>
      <link>https://arxiv.org/abs/2502.04409</link>
      <description><![CDATA[ARXIV：2502.04409V1公告类型：新 
摘要：大规模的数值模拟通常会产生高维网格数据，这对于下游应用程序的处理具有挑战性。一个典型的例子是数值天气预测，其中大气过程是使用物理变量和动力学的离散网格表示形式建模的。通过多次运行模拟来评估不确定性，从而将模拟字段的集合作为预测分布的高维随机表示。高维度和大量集合数据集对随后的预测阶段提出了重大的计算挑战。通过学习有意义和紧凑的表示，数据驱动的维度降低技术可以帮助减少数据量。但是，现有的降低方法通常是为确定性和单值输入而设计的，因此无法从多个随机模拟中处理集合数据。在这项研究中，我们提出了专门针对集合预测场格式定制的新颖维度降低方法。我们提出了两个替代框架，它们在尊重其概率特征的同时产生了合奏预测的低维表示。第一种方法通过以成员的方式应用标准维度降低技术并将成员表示形式合并为联合参数分布模型，从而得出了输入集合的基于分布的表示。第二种方法通过使用量身定制的变异自动编码器共同编码所有成员来实现类似的表示。我们使用欧洲的温度和风速预测10年的案例研究中评估和比较了这两种方法。这些方法保留了集合的关键空间和统计特征，并实现了预测字段的概率重建。]]></description>
      <guid>https://arxiv.org/abs/2502.04409</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>中介：记忆效率的LLM与参数冲突和基于不确定性的路由合并</title>
      <link>https://arxiv.org/abs/2502.04411</link>
      <description><![CDATA[ARXIV：2502.04411V1公告类型：新 
摘要：合并汇总的大型语言模型（LLMS）在不同任务上进行了填充。但是，模型之间的参数冲突导致平均性能下降。尽管模型路由在推理过程中选择单个模型来解决此问题，但它会施加过多的存储和计算成本，并且无法利用来自不同模型的常识。在这项工作中，我们观察到不同的层表现出不同级别的参数冲突。在这种见解的基础上，我们平均具有最小的参数冲突的层，并为具有重大冲突的层次使用新颖的任务级专家路由。为了进一步降低受到任务算术稀疏性的启发的存储成本，我们将多个微调专家脱离了一个密集的专家和几位稀疏的专家。考虑到分发样本，我们根据输入数据的任务不确定性选择并合并适当的专家。我们使用不同的参数量表对美洲驼和Qwen进行了广泛的实验，并对现实世界中的推理任务进行了评估。结果表明，与现有方法相比，我们的方法始终如一地取得了重大的性能改进，同时需要更少的系统成本。]]></description>
      <guid>https://arxiv.org/abs/2502.04411</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CMOE：高效LLM推理的Experts快速雕刻</title>
      <link>https://arxiv.org/abs/2502.04416</link>
      <description><![CDATA[ARXIV：2502.04416V1公告类型：新 
摘要：大型语言模型（LLMS）通过缩放模型参数实现了令人印象深刻的性能，但这带有明显的推理开销。主导LLM参数的前馈网络（FFN）在隐藏的神经元中表现出较高的激活稀疏性。为了利用这一点，研究人员提出了使用专家专家（MOE）结构的混合物，其中仅激活了一部分参数。但是，现有方法通常需要广泛的培训数据和资源，从而限制了它们的实用性。我们提出了CMOE（Carved Moe），这是一个新型框架，可以有效地从密集模型中雕刻Moe模型。 CMOE通过有效的专家分组和轻巧的适应来实现出色的性能。首先，根据激活率将神经元分为共享和路由专家。接下来，我们在不从头开始训练的情况下构建了一个路由机制，结合了可区分的路由过程和负载平衡。使用适中的数据，CMOE在五分钟内从7B密集的模型中生成了精心设计的可用启动。通过轻巧的微调，它可以在一个小时内实现高性能恢复。我们在https://github.com/jarvispei/cmoe上公开提供代码。]]></description>
      <guid>https://arxiv.org/abs/2502.04416</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeuralMoves：基于反向工程和替代学习的轻巧和微观车辆排放估算模型</title>
      <link>https://arxiv.org/abs/2502.04417</link>
      <description><![CDATA[ARXIV：2502.04417V1公告类型：新 
摘要：运输部门显着有助于温室气体排放，因此需要准确的排放模型来指导缓解策略。尽管具有现场验证和认证，但行业标准的机动车发射模拟器（Moves）仍面临与使用，高计算需求以及对微观实时应用的不适合性有关的挑战。为了解决这些局限性，我们提出了神经网络，这是一套全面的高性能，轻巧的替代模型，用于车辆二氧化碳排放。基于逆向工程和神经网络开发的神经媒体，相对于在超过200万个场景的广泛测试中，具有不同的轨迹以及有关环境和车辆的因素，平均百分比误差的平均百分比误差为6.013％。 NeuralMoves仅为2.4 MB，在很大程度上凝结了原始动作，而反向工程的移动又变成了紧凑的表示，同时保持高精度。因此，神经莫夫斯在保持移动准确性的同时显着增强了可访问性，简化了CO2评估进行运输分析，并在不同情况下实现了实时的，微观的应用，而无需依赖复杂的软件或广泛的计算资源。此外，本文首次提供了专门针对运输方案的逆向工程工业级软件的框架，超越了移动。替代模型可在https://github.com/edgar-rs/neuralmoves上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.04417</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动增强学习：探索开放式环境中技能获取的内在动机</title>
      <link>https://arxiv.org/abs/2502.04418</link>
      <description><![CDATA[ARXIV：2502.04418V1公告类型：新 
摘要：本文介绍了自动增强学习（RL）的全面概述，强调了内在动机在技能曲目的开放式形成中的作用。我们描述了基于知识的和基于能力的内在动机之间的区别，这说明了这些概念如何为能够产生和追求自定义目标的自主代理的发展提供信息。探索了本质上动机的目标探索过程（IMGEP）的类型，重点是对多目标RL和发展机器人技术的影响。自动学习问题是在无奖励的马尔可夫决策过程（MDP）中构建的，在该过程中，代理必须自主代表，产生和掌握自己的目标。我们应对评估此类代理的独特挑战，提出各种指标，以衡量复杂环境中的探索，概括和鲁棒性。这项工作旨在促进对自动RL代理的理解及其在各种动态环境中增强技能获取的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.04418</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解和减轻基于LLM的数据增强的偏差继承对下游任务</title>
      <link>https://arxiv.org/abs/2502.04419</link>
      <description><![CDATA[ARXIV：2502.04419V1公告类型：新 
摘要：通过大语言模型（LLMS）本身生成合成数据集作为改善LLM性能的有前途的方法。但是，LLM固有地反映了其培训数据中存在的偏见，从而导致了一个关键的挑战：当这些模型生成培训的合成数据时，它们可能会传播并扩大其固有的偏见，从而对下游任务产生严重影响模型的公平性和稳健性 - 这一现象 - 这一现象我们称偏见的继承。这项工作介绍了在理解，分析和减轻偏差遗传方面进行的首次系统调查。我们通过通过由原始和LLM增强数据组成的合并数据集进行微调LLM来研究这个问题，其中偏差比表示增强数据的比例。通过在10个分类和生成任务的系统实验中，我们分析了6种不同类型的偏见如何以不同的偏差比表现出来。我们的结果表明，偏见继承对下游任务有细微的影响，对分类任务和生成任务的影响有所不同。然后，我们的分析确定了三个关键的未对准因素：值，组数据和数据分布的未对准。基于这些见解，我们提出了三种缓解策略：基于令牌的，基于面具和基于损失的方法。实验表明，这些策略在各种任务和偏见上也有所不同，表明完全减轻偏见的遗传面临的重大挑战。我们希望这项工作可以为LLM数据增强研究提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.04419</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KVTUNER：敏感性 - 感知层的混合精度KV缓存量化，以实现有效且几乎无损的LLM推断</title>
      <link>https://arxiv.org/abs/2502.04420</link>
      <description><![CDATA[ARXIV：2502.04420V1公告类型：新 
摘要：KV缓存量化可以在长篇小说和大批量大小的场景中改善大型语言模型（LLMS）推理吞吐量和延迟，同时保持LLMS有效性。但是，当前方法有三个未解决的问题：忽略对KV缓存量化的层次敏感性，在线细粒度决策的高间接开销以及对不同LLM和约束的灵活性较低。因此，我们彻底分析了层变压器注意模式与KV缓存量化误差的固有相关性，并研究了为什么关键缓存比降低量化误差的价值缓存更重要。我们进一步提出了一个简单而有效的框架KVTuner，以适应性地搜索具有多目标优化的粗粒kV高速公路的最佳硬件kv量化精度对，并在线推理期间直接利用离线搜索的配置。为了降低离线校准的计算成本，我们利用层内KV精度对修剪和层间聚类来减少搜索空间。实验结果表明，对于LLAMA-3.1-8B-INSTRUCTION，例如QWEN2.5-7B教学，在数学推理任务上，我们可以实现几乎无损的3.25位混合精度KV高速缓存量化和4.0位。与KV8量化相比，在各种上下文长度上，最大推理吞吐量可以提高38.3％。]]></description>
      <guid>https://arxiv.org/abs/2502.04420</guid>
      <pubDate>Mon, 10 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>