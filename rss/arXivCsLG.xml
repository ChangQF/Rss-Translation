<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Fri, 03 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MESA：通过利用状态-动作空间结构进行多智能体学习中的协作元探索</title>
      <link>https://arxiv.org/abs/2405.00902</link>
      <description><![CDATA[arXiv:2405.00902v1 公告类型：新
摘要：多智能体强化学习（MARL）算法通常很难找到接近帕累托最优纳什均衡的策略，这很大程度上是由于缺乏有效的探索。由于政策学习中表现出较大的方差，这个问题在奖励稀疏的环境中更加严重。本文介绍了 MESA，一种用于协作多智能体学习的新型元探索方法。它通过首先从训练任务中识别代理的高回报联合状态动作子空间，然后学习一组不同的探索策略来“覆盖”子空间来学习探索。这些经过训练的探索策略可以与任何非策略 MARL 算法集成以执行测试时任务。我们首先展示 MESA 在多步矩阵游戏中的优势。此外，实验表明，通过学习探索策略，MESA 在多个多智能体粒子环境和多智能体 MuJoCo 环境中的稀疏奖励任务中取得了显着更好的性能，并表现出在测试时泛化到更具挑战性的任务的能力。]]></description>
      <guid>https://arxiv.org/abs/2405.00902</guid>
      <pubDate>Fri, 03 May 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>使用数据编码在云端进行量子联邦学习实验</title>
      <link>https://arxiv.org/abs/2405.00909</link>
      <description><![CDATA[arXiv:2405.00909v1 公告类型：新
摘要：量子联邦学习（QFL）是一个新兴概念，旨在通过量子网络展开联邦学习（FL），实现协作量子模型训练和本地数据隐私。我们探讨了在云平台上部署 QFL 的挑战，强调量子复杂性和平台限制。所提出的数据编码驱动的 QFL 以及在量子模拟器上使用基因组数据集进行的概念验证（GitHub 开源）显示了有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2405.00909</guid>
      <pubDate>Fri, 03 May 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>偏见决策的去偏见模型：使用抵押贷款申请数据的方法比较</title>
      <link>https://arxiv.org/abs/2405.00910</link>
      <description><![CDATA[arXiv:2405.00910v1 公告类型：新
摘要：预测模型可以通过自动化决策（例如批准贷款申请）来提高效率。然而，他们可能会从他们接受培训的数据中继承对受保护群体的偏见。本文将反事实（模拟）种族偏见添加到抵押贷款申请决策的真实数据中，并表明即使不将种族用作预测变量，机器学习模型 (XGBoost) 也会复制这种偏见。接下来，比较了其他几种去偏差方法：对禁止变量进行平均、对禁止变量进行最有利的预测（一种新颖的方法）、联合最小化误差以及预测与禁止变量之间的关联。去偏见可以恢复一些原始决策，但结果对偏见是否通过代理影响很敏感。]]></description>
      <guid>https://arxiv.org/abs/2405.00910</guid>
      <pubDate>Fri, 03 May 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>用于气候应用数据缩减的机器学习技术</title>
      <link>https://arxiv.org/abs/2405.00879</link>
      <description><![CDATA[arXiv:2405.00879v1 公告类型：新
摘要：科学家进行大规模模拟，从原始数据中计算出感兴趣的数量（QoI）。通常，QoI 与特定特征、区域或时间间隔相关，这样数据就可以自适应地减少，而不会影响 QoI 的完整性。对于许多时空应用来说，这些 QoI 本质上是二元的，代表物理现象的存在或不存在。我们提出了一种流水线压缩方法，该方法首先使用基于神经网络的技术来导出 QoI 极有可能出现的区域。然后，我们采用保证自动编码器（GAE）来压缩具有差分误差范围的数据。 GAE 使用 QoI 信息仅对这些区域应用低错误压缩。这导致整体高压缩比，同时仍然实现模拟或数据收集的下游目标。给出了 E3SM 模拟模型生成的气候数据的实验结果，用于热带气旋和大气河流检测和跟踪等下游量。这些结果表明我们的方法优于文献中的类似方法。]]></description>
      <guid>https://arxiv.org/abs/2405.00879</guid>
      <pubDate>Fri, 03 May 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>WHALE-FL：通过自适应子网调度在移动设备上进行无线和异构感知延迟高效联合学习</title>
      <link>https://arxiv.org/abs/2405.00885</link>
      <description><![CDATA[arXiv:2405.00885v1 公告类型：新
摘要：作为一种流行的分布式学习范式，移动设备上的联邦学习 (FL) 催生了大量应用，但它们的实际部署受到参与设备的计算和通信异构性的阻碍。一些开创性的研究工作提出从全局模型中提取子网络，并根据设备的全部计算和通信能力为其分配尽可能大的子网络进行本地训练。虽然这种固定大小的子网分配使得 FL 可以在异构移动设备上进行训练，但它无法感知 (i) 设备通信和计算条件的动态变化和 (ii) FL 训练进度及其对本地训练贡献的动态要求，这两者都可能导致非常长的 FL 训练延迟。受这些动态的启发，在本文中，我们开发了一种无线和异构感知延迟高效 FL (WHALE-FL) 方法，通过自适应子网调度来加速 FL 训练。 WHALE-FL 不再固守固定大小的子网络，而是引入了一种新颖的子网络选择实用函数来捕捉设备和 FL 训练动态，并引导移动设备根据 (a) 其计算和通信能力、(b) 其动态计算和/或通信条件以及 (c) FL 训练状态及其对本地训练贡献的相应要求，自适应地选择用于本地训练的子网络大小。我们的评估表明，与同类设计相比，WHALE-FL 有效地加速了 FL 训练，同时又不牺牲学习准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.00885</guid>
      <pubDate>Fri, 03 May 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>学习图中单音半空间的有效算法</title>
      <link>https://arxiv.org/abs/2405.00853</link>
      <description><![CDATA[arXiv:2405.00853v1 公告类型：新
摘要：我们研究了在图的顶点上学习二元分类器的问题。特别是，我们考虑由单音半空间给出的分类器，即在某种抽象意义上凸的顶点的划分。单音半空间以及测地线半空间等相关概念最近引起了人们的兴趣，并且在它们的属性（例如它们的 VC 维数）和底层图 $G$ 的结构之间建立了一些联系。我们证明了在监督、在线和主动环境中学习单音半空间的几个新颖结果。我们的主要结果是，可以在 $n = |V(G)|$ 的时间多项式中以近乎最优的被动样本复杂度来学习单音半空间。这要求我们基于对单音半空间的几种结构见解以及将可满足性降低到 2 美元来设计一种用于一致假设检查的多项式时间算法。我们证明了在线和活动设置的类似结果。我们还表明，概念类可以通过延迟 $\operatorname{poly}(n)$ 进行枚举，并且经验风险最小化可以在 $2^{\omega(G)}\operatorname{poly}(n) 时间内执行$ 其中$\omega(G)$ 是$G$ 的派系数量。这些结果回答了文献中的开放性问题（Gonz&#39;alez 等人，2020），并与测地半空间形成对比，其中一些问题是 NP 困难的（Seiffarth 等人，2023）。]]></description>
      <guid>https://arxiv.org/abs/2405.00853</guid>
      <pubDate>Fri, 03 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫流策略——深度MC</title>
      <link>https://arxiv.org/abs/2405.00877</link>
      <description><![CDATA[arXiv:2405.00877v1 公告类型：新
摘要：折扣算法由于依赖短期估计而经常遇到评估错误，这可能会妨碍其解决简单的短期任务的效率，并造成不希望的时间折扣（\(\gamma\)）。有趣的是，这些算法通常在不应用折扣的情况下进行测试，我们将这种现象称为\textit{训练测试偏差}。为了应对这些挑战，我们提出了马尔可夫流策略，它利用非负神经网络流来实现全面的前视预测。通过集成到 TD7 代码库并使用 MuJoCo 基准进行评估，我们观察到显着的性能改进，将 MFP 定位为平均奖励算法领域内简单、实用且易于实施的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2405.00877</guid>
      <pubDate>Fri, 03 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>局部正则化重建：结构化稀疏性和 Delaunay 三角剖分</title>
      <link>https://arxiv.org/abs/2405.00837</link>
      <description><![CDATA[arXiv:2405.00837v1 公告类型：新
摘要：线性表示学习由于其概念简单性和在压缩、分类和特征提取等任务中的经验实用性而被广泛研究。给定一组点 $[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n] = \mathbf{X} \in \mathbb{R}^{d \times n }$ 和一个向量 $\mathbf{y} \in \mathbb{R}^d$，目标是找到系数 $\mathbf{w} \in \mathbb{R}^n$ 使得 $\mathbf{ X} \mathbf{w} \approx \mathbf{y}$，受 $\mathbf{w}$ 上某些所需结构的影响。在这项工作中，我们寻求 $\mathbf{w}$ 通过解决正则化最小二乘回归问题来形成 $\mathbf{y}$ 的局部重建。我们通过局部性函数获得局部解，该函数促进使用 $\mathbf{X}$ 的列，这些列在用作正则化项时接近 $\mathbf{y}$。我们证明，对于所有级别的正则化，并且在 $\mathbf{X}$ 的列具有唯一的 Delaunay 三角剖分的温和条件下，最优系数的非零条目数上限为 $d+1$ ，从而在 $d \ll n$ 时提供局部稀疏解。在相同的条件下，我们还表明，对于 $\mathbf{X}$ 的凸包中包含的任何 $\mathbf{y}$，存在正则化参数的机制，使得最优系数支持在 Delaunay 的顶点上包含$\mathbf{y}$的单纯形。这提供了对稀疏性的解释，即具有从 $\mathbf{X}$ 的 Delaunay 三角剖分中隐式获得的结构。我们证明，我们的局部正则化问题可以在与识别包含 Delaunay 单纯形的其他方法相当的时间内解决。]]></description>
      <guid>https://arxiv.org/abs/2405.00837</guid>
      <pubDate>Fri, 03 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>用于分散式多智能体学习的高效通信训练工作负载平衡</title>
      <link>https://arxiv.org/abs/2405.00839</link>
      <description><![CDATA[arXiv:2405.00839v1 公告类型：新
摘要：去中心化多智能体学习（DML）可以在保护数据隐私的同时实现协作模型训练。然而，代理资源（计算、通信和任务大小）固有的异质性可能会导致训练时间的巨大差异。这种异质性造成了瓶颈，由于落后者效应而延长了整体训练时间，并可能浪费更快代理的备用资源。为了最大限度地减少异构环境中的训练时间，我们提出了一种用于分散式多代理学习的高效通信训练工作负载平衡（ComDML），它通过分散的方法平衡代理之间的工作负载。利用本地损失分割训练，ComDML 可以实现并行更新，其中速度较慢的代理将部分工作负载转移给速度较快的代理。为了最大限度地减少总体训练时间，ComDML 通过共同考虑代理的通信和计算能力来优化工作负载平衡，这取决于整数规划。开发了动态分散配对调度程序，以有效地配对代理并确定最佳卸载量。我们证明，在 ComDML 中，对于凸函数和非凸函数，较慢和较快代理的模型都会收敛。此外，在流行数据集（CIFAR-10、CIFAR-100 和 CINIC-10）及其非 I.I.D. 上进行了广泛的实验结果。 ResNet-56 和 ResNet-110 等大型模型的变体表明，与最先进的方法相比，ComDML 可以显着减少总体训练时间，同时保持模型准确性。 ComDML 在异构环境中表现出稳健性，并且可以无缝集成隐私措施以增强数据保护。]]></description>
      <guid>https://arxiv.org/abs/2405.00839</guid>
      <pubDate>Fri, 03 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>不可知 PAC 学习中的误差指数</title>
      <link>https://arxiv.org/abs/2405.00792</link>
      <description><![CDATA[arXiv:2405.00792v1 公告类型：新
摘要：统计学习理论和可能近似正确（PAC）准则是数学学习理论的常用方法。 PAC被广泛用于分析学习问题和算法，并且已经被深入研究。使用 VC 理论或 Radamacher 复杂度等方法已经很好地建立了收敛速度的统一最坏情况界限。然而，在典型情况下，性能可能会好得多。在本文中，我们考虑使用稍微不同的权衡方法进行 PAC 学习，即误差指数（信息论中一种完善的分析方法），它描述了风险超过特定阈值的概率的指数行为，作为样本大小的函数。我们专注于二元分类，并在一些稳定性假设下找到了一种适用于各种问题的改进的分布相关误差指数，建立了不可知学习中 PAC 误差概率的指数行为。有趣的是，在这些假设下，不可知学习可能与可实现学习具有相同的误差指数。误差指数准则可以用来分析知识蒸馏这一迄今为止缺乏理论分析的问题。]]></description>
      <guid>https://arxiv.org/abs/2405.00792</guid>
      <pubDate>Fri, 03 May 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>ICU 血流感染预测：基于 Transformer 的 EHR 分析方法</title>
      <link>https://arxiv.org/abs/2405.00819</link>
      <description><![CDATA[arXiv:2405.00819v1 公告类型：新
摘要：我们介绍了 RatchetEHR，这是一种基于 Transformer 的新型框架，旨在对重症监护室 (ICU) 环境中的电子健康记录 (EHR) 数据进行预测分析，特别关注血流感染 (BSI) 预测。利用 MIMIC-IV 数据集，RatchetEHR 与其他方法（包括 RNN、LSTM 和 XGBoost）相比表现出卓越的预测性能，特别是由于其对顺序和时间 EHR 数据的高级处理。 RatchetEHR 的一项关键创新是集成了图卷积变换器 (GCT) 组件，该组件显着增强了识别 EHR 数据中隐藏结构关系的能力，从而实现更准确的临床预测。通过 SHAP 值分析，我们深入了解 BSI 预测的影响特征。 RatchetEHR 集成了深度学习的多项进步，即使样本量相对较小且数据集高度不平衡，它们也能提供准确的预测。这项研究通过展示先进的人工智能技术在医疗保健中的应用，为医疗信息学做出了贡献，并为进一步研究以优化 EHR 数据分析中的这些功能奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2405.00819</guid>
      <pubDate>Fri, 03 May 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>关于学习网络的权重动态</title>
      <link>https://arxiv.org/abs/2405.00743</link>
      <description><![CDATA[arXiv:2405.00743v1 公告类型：新
摘要：神经网络已成为解决机器学习和人工智能领域各种问题的广泛采用的工具。在这篇文章中，我们使用局部稳定性分析的数学框架来更深入地了解前馈神经网络的学习动态。因此，我们推导了三层网络学习回归任务的学习动态的正切算子方程。结果对于任意数量的节点和任意选择的激活函数都是有效的。将结果应用到学习回归任务的网络中，我们以数值方式研究稳定性指标与最终训练损失的关系。尽管具体结果随着初始条件和激活函数的不同选择而变化，但我们证明，通过在训练过程中监控有限时间李雅普诺夫指数或协变李雅普诺夫向量，可以预测最终的训练损失。]]></description>
      <guid>https://arxiv.org/abs/2405.00743</guid>
      <pubDate>Fri, 03 May 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>利用次优数据进行人在环强化学习</title>
      <link>https://arxiv.org/abs/2405.00746</link>
      <description><![CDATA[arXiv:2405.00746v1 公告类型：新
摘要：为了创建有用的强化学习（RL）代理，第零步是设计一个合适的奖励函数来捕捉任务的细微差别。然而，奖励工程可能是一个困难且耗时的过程。相反，人机循环 (HitL) RL 允许智能体从人类反馈中学习奖励函数。尽管最近取得了成功，但许多 HitL RL 方法仍然需要大量的人类交互才能学习成功的奖励函数。为了提高 HitL RL 方法的反馈效率（即需要更少的反馈），本文引入了次优数据预训练（SDP），这是一种利用无奖励、次优数据来改进基于标量和偏好的方法HitL 强化学习算法。在 SDP 中，我们首先对所有低质量数据进行伪标记，奖励为零。通过这个过程，我们获得免费的奖励标签来预训练我们的奖励模型。这个预训练阶段为奖励模型提供了学习的先机，它可以识别出低质量的转换应该有较低的奖励，而所有这些都没有任何实际的反馈。通过与模拟教师进行的大量实验，我们证明了 SDP 可以在九个机器人操作和运动任务中使用最先进的 (SOTA) HitL RL 算法显着提高或实现竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2405.00746</guid>
      <pubDate>Fri, 03 May 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>软偏好优化：使语言模型与专家分布保持一致</title>
      <link>https://arxiv.org/abs/2405.00747</link>
      <description><![CDATA[arXiv:2405.00747v1 公告类型：新
摘要：我们提出了软偏好优化（SPO），一种将生成模型（例如大型语言模型（LLM））与人类偏好对齐的方法，而不需要奖励模型。 SPO 通过自然损失函数直接在偏好数据集上优化模型输出，该函数将偏好损失与模型整个输出分布的正则化项相结合，而不是将其限制于偏好数据集。尽管 SPO 不需要假设现有的基础奖励模型，但我们证明，在 Bradley-Terry (BT) 模型假设下，它收敛到缩放奖励的 softmax，并且分布的“软度”可通过 softmax 指数进行调整，算法参数。我们展示了SPO的方法、其理论基础以及其在简单性、计算效率和对齐精度方面的相对优势。]]></description>
      <guid>https://arxiv.org/abs/2405.00747</guid>
      <pubDate>Fri, 03 May 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么知识蒸馏有效？重新思考其注意力和保真度机制</title>
      <link>https://arxiv.org/abs/2405.00739</link>
      <description><![CDATA[arXiv:2405.00739v1 公告类型：新
摘要：知识蒸馏（KD）真的有用吗？传统观点将其视为一种知识转移过程，需要学生对老师进行完美模仿。然而，矛盾的研究表明，密切模仿教师的行为并不能持续提高学生的概括能力，这对其可能的原因提出了疑问。面对这一差距，我们假设教师的不同关注有助于更好地学生泛化，但代价是整体 KD 设置的保真度降低。通过增加数据增强强度，我们的主要发现揭示了教师模型之间注意力的交集（IoU）减少，从而减少了学生过度拟合和保真度降低。我们将这种低保真度现象视为训练 KD 时的潜在特征，而不是病态。这表明，更强的数据增强可以促进不同教师群体提供的更广阔的视角，并降低师生相互信息，从而有利于泛化性能。这些见解阐明了 KD 中低保真现象的机制。因此，我们通过强调增加教师注意力的多样性和减少教师和学生之间的模仿行为，为优化学生模型表现提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2405.00739</guid>
      <pubDate>Fri, 03 May 2024 06:18:30 GMT</pubDate>
    </item>
    </channel>
</rss>