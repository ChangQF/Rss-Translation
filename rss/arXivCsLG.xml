<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于野火预测的可解释人工智能集成特征工程</title>
      <link>https://arxiv.org/abs/2404.01487</link>
      <description><![CDATA[arXiv:2404.01487v1 公告类型：新
摘要：野火给预测带来了复杂的挑战，需要使用复杂的机器学习技术进行有效的建模\cite{jain2020review}。在我们的研究中，我们对与预测野火相关的分类和回归任务的各种机器学习算法进行了全面评估。我们发现，对于不同类型或阶段的野火分类，XGBoost 模型在准确性和鲁棒性方面优于其他模型。同时，随机森林回归模型在预测受野火影响的区域范围方面显示出优异的结果，在预测误差和解释方差方面均表现出色。此外，我们开发了一种混合神经网络模型，该模型集成了数值数据和图像信息以同时进行分类和回归。为了更深入地了解这些模型的决策过程并确定关键的贡献特征，我们利用了 eXplainable 人工智能 (XAI) 技术，包括 TreeSHAP、LIME、部分依赖图 (PDP) 和梯度加权类激活映射 (Grad) -CAM）。这些可解释性工具揭示了各种特征的重要性和相互作用，突出了影响野火预测的复杂因素。我们的研究不仅证明了特定机器学习模型在野火相关任务中的有效性，而且强调了模型透明度和可解释性在环境科学应用中的关键作用。]]></description>
      <guid>https://arxiv.org/abs/2404.01487</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>使用个性化层解决联合负载预测中的异构性</title>
      <link>https://arxiv.org/abs/2404.01517</link>
      <description><![CDATA[arXiv:2404.01517v1 公告类型：新
摘要：智能电表的出现使得能源消耗数据的普遍收集能够用于训练短期负荷预测模型。为了应对隐私问题，联邦学习（FL）被提出作为一种隐私保护的训练方法，但随着客户端数据变得异构，训练模型的质量会下降。在本文中，我们建议在称为 PL-FL 的通用框架中使用个性化层进行负载预测。我们证明 PL-FL 优于 FL 和纯本地训练，同时需要比 FL 更低的通信带宽。这是通过对 NREL ComStock 存储库中的三个不同数据集进行广泛模拟来完成的。]]></description>
      <guid>https://arxiv.org/abs/2404.01517</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>TS-CausalNN：从非线性非平稳时间序列数据中学习时间因果关系</title>
      <link>https://arxiv.org/abs/2404.01466</link>
      <description><![CDATA[arXiv:2404.01466v1 公告类型：新
摘要：环境科学、流行病学和经济学等各个领域的时间序列数据的可用性和重要性不断增加，导致对时间序列因果发现方法的需求不断增加，这些方法可以识别非平稳、非平稳的复杂关系。 -线性且通常是嘈杂的现实世界数据。然而，当前大多数时间序列因果发现方法都假设数据的平稳性和线性关系，这使得它们对于该任务不可行。此外，最近基于深度学习的方法依赖于传统的因果结构学习方法，这使得它们的计算成本很高。在本文中，我们提出了一种时间序列因果神经网络（TS-CausalNN）——一种同时发现同期和滞后因果关系的深度学习技术。我们提出的架构包括（i）包含并行自定义因果层的卷积块，（ii）非循环约束，以及（iii）使用增强拉格朗日方法的优化技术。除了简单的并行设计之外，所提出的模型的一个优点是它自然地处理数据的非平稳性和非线性。通过对多个合成和现实世界数据集的实验，我们证明了我们提出的方法与几种最先进的方法相比的经验熟练程度。现实世界数据集的推断图与领域理解非常一致。]]></description>
      <guid>https://arxiv.org/abs/2404.01466</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是超人化学家吗？</title>
      <link>https://arxiv.org/abs/2404.01475</link>
      <description><![CDATA[arXiv:2404.01475v1 公告类型：新
摘要：大型语言模型（LLM）因其处理人类语言和执行未经明确训练的任务的能力而引起了广泛的兴趣。这与化学科学相关，化学科学面临着通常采用文本形式的小而多样化的数据集的问题。法学硕士在解决这些问题方面表现出了希望，并且越来越多地被用来预测化学性质、优化反应，甚至自主设计和进行实验。然而，我们对法学硕士的化学推理能力的系统性了解仍然非常有限，这需要改进模型并减轻潜在危害。在这里，我们介绍“ChemBench”，这是一个自动化框架，旨在根据人类化学家的专业知识严格评估最先进的法学硕士的化学知识和推理能力。我们为化学科学的各个子领域策划了 7,000 多个问答对，评估了领先的开源和闭源法学硕士，发现在我们的研究中，最好的模型平均表现优于最好的人类化学家。然而，这些模型在处理一些对人类专家来说很容易的化学推理任务时遇到了困难，并提供了过于自信、误导性的预测，例如关于化学品安全概况的预测。这些发现强调了一个双重现实，即尽管法学硕士在化学任务方面表现出卓越的熟练程度，但进一步的研究对于提高其在化学科学中的安全性和实用性至关重要。我们的研究结果还表明需要对化学课程进行调整，并强调继续开发评估框架以提高安全和有用的法学硕士的重要性。]]></description>
      <guid>https://arxiv.org/abs/2404.01475</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>专家的及时提示混合，以实现高效的法学硕士生成</title>
      <link>https://arxiv.org/abs/2404.01365</link>
      <description><![CDATA[arXiv:2404.01365v1 公告类型：新
摘要：随着基于 Transformer 的大语言模型（LLM）的发展，由于其显着的实用性，它们已被应用于许多领域，但这在部署时需要相当大的计算成本。幸运的是，一些方法（例如修剪或构建专家混合 (MoE)）旨在利用变压器前馈 (FF) 块中的稀疏性来提高速度并减少内存需求。然而，这些技术在实践中可能非常昂贵且不灵活，因为它们通常需要培训或仅限于特定类型的架构。为了解决这个问题，我们引入了 GRIFFIN，一种新颖的免训练 MoE，它在序列级别选择独特的 FF 专家，以便跨大量具有不同非 ReLU 激活函数的 LLM 进行高效生成。这是可能的，因为一个重要的观察结果是，许多训练有素的法学硕士自然会在序列中产生高度结构化的 FF 激活模式，我们称之为聚集。尽管我们的方法很简单，但我们用 50\% 的 FF 参数证明，GRIFFIN 保持了原始模型的性能，在各种分类和生成任务上几乎没有降级，同时改善了延迟（例如 1.25$\times$ 加速在 NVIDIA L40 上的 Llama 2 13B 中）。代码可在 https://github.com/hdong920/GRIFFIN 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.01365</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>模型崩溃不可避免吗？通过积累真实数据和合成数据来打破递归魔咒</title>
      <link>https://arxiv.org/abs/2404.01413</link>
      <description><![CDATA[arXiv:2404.01413v1 公告类型：新
摘要：生成模型的激增，与网络规模数据的预训练相结合，提出了一个及时的问题：当这些模型根据自己生成的输出进行训练时会发生什么？最近对模型数据反馈循环的调查发现，此类循环可能导致模型崩溃，这种现象是每次模型拟合迭代时性能逐渐下降，直到最新模型变得无用。然而，最近研究模型崩溃的几篇论文假设新数据会随着时间的推移取代旧数据，而不是假设数据会随着时间的推移而积累。在本文中，我们比较了这两种设置，并表明积累数据可以防止模型崩溃。我们首先研究一个分析上易于处理的设置，其中一系列线性模型适合先前模型的预测。之前的工作表明，如果替换数据，测试误差会随着模型拟合迭代次数线性增加；我们通过证明如果数据累积，则测试误差具有与迭代次数无关的有限上限，从而扩展了该结果。接下来，我们通过在文本语料库上预训练语言模型序列来实证测试积累数据是否可以类似地防止模型崩溃。我们确认替换数据确实会导致模型崩溃，然后证明积累数据可以防止模型崩溃；这些结果适用于一系列模型大小、架构和超参数。我们进一步表明，类似的结果也适用于真实数据的其他深度生成模型：用于分子生成的扩散模型和用于图像生成的变分自动编码器。我们的工作提供了一致的理论和经验证据，表明数据积累可以减轻模型崩溃。]]></description>
      <guid>https://arxiv.org/abs/2404.01413</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>OpenChemIE：化学文献信息提取工具包</title>
      <link>https://arxiv.org/abs/2404.01462</link>
      <description><![CDATA[arXiv:2404.01462v1 公告类型：新
摘要：从化学文献中提取信息对于构建数据驱动化学的最新反应数据库至关重要。完整的提取需要结合文本、表格和图形中的信息，而之前的工作主要研究从单一模式中提取反应。在本文中，我们提出 OpenChemIE 来解决这一复杂的挑战，并能够在文档级别提取反应数据。 OpenChemIE 分两步解决该问题：从各个模式中提取相关信息，然后整合结果以获得最终的反应列表。第一步，我们采用专门的神经模型，每个模型都解决化学信息提取的特定任务，例如从文本或图形中解析分子或反应。然后，我们使用化学信息算法整合这些模块的信息，从而可以从反应条件和底物范围研究中提取细粒度的反应数据。我们的机器学习模型在单独评估时达到了最先进的性能，并且我们精心注释了具有 R 基团的具有挑战性的反应方案数据集，以评估我们的整个流程，实现了 69.5% 的 F1 分数。此外，直接与 Reaxys 化学数据库进行比较时，我们的反应提取结果的准确度为 64.3%。我们以开源包的形式以及通过 Web 界面向公众免费提供 OpenChemIE。]]></description>
      <guid>https://arxiv.org/abs/2404.01462</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>输入扰动对鲁棒精确公平性的双刃剑</title>
      <link>https://arxiv.org/abs/2404.01356</link>
      <description><![CDATA[arXiv:2404.01356v1 公告类型：新
摘要：众所周知，深度神经网络（DNN）对对抗性输入扰动敏感，导致预测准确性或个体公平性降低。为了共同表征预测准确性和个体公平性对对抗性扰动的敏感性，我们引入了一种新的鲁棒性定义，称为鲁棒精确公平性。非正式地说，鲁棒准确的公平性要求在受到输入扰动时，对实例及其类似对应物的预测始终与真实情况一致。我们提出了一种称为 RAFair 的对抗性攻击方法，以暴露 DNN 中虚假或有偏见的对抗性缺陷，这些缺陷要么欺骗准确性，要么损害个人公平性。然后，我们表明，可以通过精心设计的良性扰动来有效解决此类对抗性实例，从而将其预测纠正为准确和公平。我们的工作探索了输入扰动对 DNN 中鲁棒准确公平性的双刃剑，以及使用良性扰动来纠正对抗性实例的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.01356</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>通过传递熵进行深度学习中的信息平面分析可视化</title>
      <link>https://arxiv.org/abs/2404.01364</link>
      <description><![CDATA[arXiv:2404.01364v1 公告类型：新
摘要：在前馈网络中，传递熵（TE）可以通过量化训练期间各层之间的信息传递来衡量一层对另一层的影响。根据信息瓶颈原则，神经模型的内部表示应尽可能压缩输入数据，同时仍保留足够的输出信息。信息平面分析是一种可视化技术，用于通过绘制输入数据中的信息量与压缩表示的关系来了解信息瓶颈方法中压缩和信息保存之间的权衡。通过互信息测量，信息论压缩和泛化之间存在因果关系的说法是有道理的，但不同研究的结果是相互矛盾的。与互信息相反，TE 可以捕获变量之间的时间关系。为了探索这些联系，在我们的新方法中，我们使用 TE 来量化神经层之间的信息传输并执行信息平面分析。我们获得了令人鼓舞的实验结果，为进一步研究提供了可能性。]]></description>
      <guid>https://arxiv.org/abs/2404.01364</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>块对角引导 DBSCAN 聚类</title>
      <link>https://arxiv.org/abs/2404.01341</link>
      <description><![CDATA[arXiv:2404.01341v1 公告类型：新
摘要：聚类分析在数据库挖掘中起着至关重要的作用，该领域最广泛使用的算法之一是DBSCAN。然而，DBSCAN 存在一些局限性，例如难以处理高维大规模数据、对输入参数敏感以及生成聚类结果缺乏鲁棒性。本文介绍了 DBSCAN 的改进版本，它利用相似图的块对角线属性来指导 DBSCAN 的聚类过程。关键思想是构建一个图来测量高维大规模数据点之间的相似性，并有可能通过未知的排列转换为块对角形式，然后通过聚类排序过程来生成所需的排列。通过识别排列图中的对角块，可以轻松确定聚类结构。我们提出了一种基于梯度下降的方法来解决所提出的问题。此外，我们开发了一种基于 DBSCAN 的点遍历算法，该算法可识别图中具有高密度的簇并生成簇的增强排序。然后通过基于遍历顺序的排列实现图的块对角结构，为自动和交互式聚类分析提供灵活的基础。我们引入了一种分割和细化算法来自动搜索置换图中的所有对角块，并在特定情况下提供理论上的最佳保证。我们在十二个具有挑战性的现实世界基准聚类数据集上广泛评估了我们提出的方法，并在每个数据集上展示了与最先进的聚类方法相比其优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.01341</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>AETTA：测试时间适应的无标签准确度估计</title>
      <link>https://arxiv.org/abs/2404.01351</link>
      <description><![CDATA[arXiv:2404.01351v1 公告类型：新
摘要：测试时间适应（TTA）已成为一种可行的解决方案，可使用未标记的测试数据使预训练模型适应域转移。然而，TTA由于依赖于动态场景下对未知测试样本的盲目适应，面临适应失败的挑战。分布外性能估计的传统方法受到 TTA 环境中不切实际的假设的限制，例如需要标记数据或重新训练模型。为了解决这个问题，我们提出了 AETTA，一种 TTA 的无标签精度估计算法。我们提出预测不一致作为准确度估计，通过将目标模型预测与丢失推断进行比较来计算。然后，我们改进预测分歧，以扩展 AETTA 在适应失败情况下的适用性。我们对四种基线和六种 TTA 方法的广泛评估表明，与基线相比，AETTA 的估计准确度平均高出 19.8%p。我们通过模型恢复案例研究进一步证明了精度估计的有效性，展示了我们基于精度估计的模型恢复的实用性。源代码可在 https://github.com/taeckyung/AETTA 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.01351</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>为边缘应用高效提炼法学硕士</title>
      <link>https://arxiv.org/abs/2404.01353</link>
      <description><![CDATA[arXiv:2404.01353v1 公告类型：新
摘要：法学硕士的超网训练在工业应用中引起了极大的兴趣，因为它赋予了以恒定成本生成一系列较小模型的能力，而不管生成的模型数量（不同大小/延迟）如何。我们提出了一种称为多级低秩微调超级变压器（MLFS）的新方法，用于参数高效的超网训练。我们表明，可以获得适合商业边缘应用的高质量编码器模型，并且虽然仅解码器模型可以抵抗相当程度的压缩，但可以有效地对解码器进行切片，从而显着减少训练时间。]]></description>
      <guid>https://arxiv.org/abs/2404.01353</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>建筑设计的生成式人工智能：文献综述</title>
      <link>https://arxiv.org/abs/2404.01335</link>
      <description><![CDATA[arXiv:2404.01335v1 公告类型：新
摘要：生成人工智能（AI）在建筑设计中开创了新的方法论范式，显着扩展了设计过程的创新潜力和效率。本文探讨了生成式人工智能技术在建筑设计中的广泛应用，这一趋势受益于深度生成模型的快速发展。本文全面回顾了生成式人工智能和大规模模型的基本原理，并重点介绍了其在 2D 图像、视频和 3D 模型生成中的应用。此外，通过回顾 2020 年的最新文献，本文仔细审视了生成式 AI 技术在建筑设计不同阶段（从生成初始建筑 3D 形式到生成最终建筑图像）的影响。研究增长的显着趋势表明建筑设计界越来越倾向于拥抱生成式人工智能，从而激发了对研究的共同热情。这些研究案例和方法不仅被证明可以显着提高效率和创新，而且对建筑创造力的传统界限提出了挑战。最后，我们指出了设计创新的新方向，并阐明了在建筑领域应用生成式人工智能的新轨迹。本文提供了第一篇关于建筑设计生成人工智能的全面文献综述，我们相信这项工作可以促进关于这一建筑领域重要主题的更多研究工作。]]></description>
      <guid>https://arxiv.org/abs/2404.01335</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>从相似到优越：时间序列预测的通道聚类</title>
      <link>https://arxiv.org/abs/2404.01340</link>
      <description><![CDATA[arXiv:2404.01340v1 公告类型：新
摘要：近几十年来，时间序列预测引起了人们的广泛关注。先前的研究表明，通道无关（CI）策略通过单独处理不同的通道来提高预测性能，但它会导致对未见过的实例的泛化能力较差，并忽略通道之间潜在必要的交互。相反，渠道相关（CD）策略将所有渠道与甚至不相关和不加区别的信息混合在一起，但这会导致过度平滑问题并限制预测准确性。缺乏有效平衡各个渠道处理以提高预测性能而不忽视渠道之间基本相互作用的渠道策略。受我们对时间序列模型针对通道混合的性能提升与一对通道的内在相似性之间的相关性的观察的启发，我们开发了一种新颖且适应性强的通道聚类模块（CCM）。 CCM 对具有内在相似性的渠道进行动态分组，并利用集群身份而不是渠道身份，结合了 CD 和 CI 世界的优点。对真实世界数据集的大量实验表明，CCM 可以 (1) 将 CI 和 CD 模型的长期和短期预测性能平均分别提高 2.4% 和 7.2%； （2）利用主流时间序列预测模型实现零样本预测； (3)揭示通道之间内在的时间序列模式并提高复杂时间序列模型的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2404.01340</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>NeuroPrune：一种受神经启发的大型语言模型拓扑稀疏训练算法</title>
      <link>https://arxiv.org/abs/2404.01306</link>
      <description><![CDATA[arXiv:2404.01306v1 公告类型：新
摘要：基于 Transformer 的语言模型因其在各种任务上的出色表现而在自然语言处理（NLP）中变得无处不在。然而，昂贵的训练和推理仍然是其广泛应用的重大障碍。虽然在模型架构的各个级别上实施稀疏性在解决扩展和效率问题方面已经找到了希望，但稀疏性如何影响网络拓扑之间仍然存在脱节。受大脑神经元网络的启发，我们通过网络拓扑的角度探索稀疏方法。具体来说，我们利用生物网络中的机制，例如优先附着和冗余突触修剪，并表明有原则的、与模型无关的稀疏方法在不同的 NLP 任务中表现良好且高效，涵盖分类（例如自然语言推理）和生成（总结，机器翻译），尽管我们的唯一目标不是优化性能。 NeuroPrune 在性能方面与基线相比具有竞争力（或有时优于），并且在给定稀疏度水平的训练时间方面可以快 10 美元，同时在许多情况下在推理时间上表现出可测量的改进。]]></description>
      <guid>https://arxiv.org/abs/2404.01306</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>