<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>对抗性机器学习：攻击和保护图像数据集</title>
      <link>https://arxiv.org/abs/2502.05203</link>
      <description><![CDATA[arXiv:2502.05203v1 公告类型：新
摘要：本文研究了卷积神经网络 (CNN) 面对对抗性攻击的脆弱性，并探索了一种保护方法。在这项研究中，CNN 在四个最常见的图像数据集上实现，即 CIFAR-10、ImageNet、MNIST 和 Fashion-MNIST，并实现了较高的基线准确度。为了评估这些模型的强度，使用了快速梯度符号法，这是一种对模型的漏洞利用，用于通过对输入图像添加非常小的扰动来降低模型的准确性。为了对抗 FGSM 攻击，我们采取了一种保护方法，包括在清晰、污染或对抗性图像上重新训练模型以提高其抵抗能力。下一步是再次应用 FGSM，但这次是针对对抗性训练的模型，以查看模型的准确性下降了多少并评估防御的有效性。看来，虽然对抗训练后模型的鲁棒性达到了最高水平，但这些模型在对抗干扰时的性能仍有一些损失。这项研究强调了需要为在现实世界场景中部署的模型创建更好的防御措施来抵御对手。]]></description>
      <guid>https://arxiv.org/abs/2502.05203</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多样本推理优化语言模型的温度</title>
      <link>https://arxiv.org/abs/2502.05234</link>
      <description><![CDATA[arXiv:2502.05234v1 公告类型：新
摘要：多样本聚合策略（例如多数投票和 N 中最佳采样）广泛应用于当代大型语言模型 (LLM)，以提高各种任务的预测准确性。此过程中的一个关键挑战是温度选择，这会显著影响模型性能。现有方法要么依赖于固定的默认温度，要么需要标记的验证数据进行调整，而这些数据通常稀缺且难以获得。本文解决了使用多样本聚合策略自动识别不同 LLM 的（接近）最佳温度的挑战，而不依赖于特定于任务的验证数据。我们全面分析了温度在性能优化中的作用，考虑了模型架构、数据集、任务类型、模型大小和预测准确性的变化。此外，我们提出了一种基于熵的新型自动温度优化指标，其性能始终优于固定温度基线。此外，我们还结合了随机过程模型来增强可解释性，从而更深入地了解温度和模型性能之间的关系。]]></description>
      <guid>https://arxiv.org/abs/2502.05234</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习架构的原理和组成部分</title>
      <link>https://arxiv.org/abs/2502.05273</link>
      <description><![CDATA[arXiv:2502.05273v1 公告类型：新
摘要：联邦学习，也称为 FL，是一种机器学习框架，其中大量客户端（例如移动设备或整个企业）协作以协作训练模型，同时保持分散的训练数据，所有这些都由中央服务器（例如服务提供商）监督。这种分散的模型训练方法在隐私、安全、法规和经济方面具有优势。尽管 FL 看起来很有前途，但它并不能免受困扰传统机器学习模型的缺陷的影响。本研究对联邦学习架构的基本思想和要素进行了彻底的分析，强调了五个重要领域：通信架构、机器学习模型、数据分区、隐私方法和系统异构性。我们还讨论了该领域未来研究的困难和潜在路径。此外，基于对文献的全面回顾，我们提出了一系列联邦学习系统的架构模式。这个分析将有助于理解联邦学习的基础知识、联邦学习的主要组成部分以及一些架构细节。]]></description>
      <guid>https://arxiv.org/abs/2502.05273</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>罗生门集中的公平性和稀疏性：无枚举探索和表征</title>
      <link>https://arxiv.org/abs/2502.05286</link>
      <description><![CDATA[arXiv:2502.05286v1 公告类型：新
摘要：我们引入了一种基于数学规划的无枚举方法，以精确表征“良好模型”集（称为罗生门集）中的各种属性，例如公平性或稀疏性。只要存在模型学习任务的数学公式，这种方法通常适用于任何假设类。它提供了一个结构化的框架来定义业务必要性的概念，并评估如何针对特定受保护群体提高或降低公平性，同时保持在罗生门集内并保持任何所需的稀疏度水平。
我们将我们的方法应用于两个假设类：评分系统和决策图，利用最近的数学规划公式来训练此类模型。正如我们在实验中所看到的，该方法全面且可证明地量化了预测性能、稀疏性和公平性之间的权衡。我们观察到，公平值的范围很广，从对受保护群体非常有利到非常不利，同时保持在假设类最佳训练准确率的 1% 以下。此外，我们观察到稀疏性约束限制了这些权衡，并可能不成比例地损害特定子群体。正如我们所证明的，彻底描述这些关键方面之间的紧张关系对于明智和负责任地选择模型至关重要。]]></description>
      <guid>https://arxiv.org/abs/2502.05286</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GST-UNet：具有时变混杂因素的时空因果推理</title>
      <link>https://arxiv.org/abs/2502.05295</link>
      <description><![CDATA[arXiv:2502.05295v1 公告类型：新
摘要：从时空数据估计因果效应是公共卫生、社会政策和环境科学等领域面临的关键挑战，因为这些领域的受控实验通常不可行。然而，现有的依赖观察数据的因果推理方法面临着重大的局限性：它们依赖于强大的结构假设来解决时空挑战 $\unicode{x2013}$，例如干扰、空间混杂和时间遗留效应 $\unicode{x2013}$，或者无法解释 $\textit{随时间变化的混杂因素}$。这些混杂因素受过去治疗和结果的影响，它们本身可以影响未来的治疗和结果，从而形成反馈循环，使传统的调整策略复杂化。为了应对这些挑战，我们引入了 $\textbf{GST-UNet}$ ($\textbf{G}$-计算 $\textbf{S}$patio-$\textbf{T}$emporal $\textbf{UNet}$)，这是一种新颖的端到端神经网络框架，旨在估计复杂空间和时间设置中的治疗效果。GST-UNet 利用基于回归的迭代 G 计算来明确调整随时间变化的混杂因素，从而提供潜在结果和治疗效果的有效估计。据我们所知，GST-UNet 是第一个考虑时空干预中复杂、非线性动态和随时间变化的混杂因素的神经模型。我们通过广泛的模拟研究证明了 GST-UNet 的有效性，并通过对 2018 年加州 Camp Fire 期间野火烟雾对呼吸道住院率的影响进行真实分析展示了其实用性。我们的研究结果强调了 GST-UNet 在广泛的政策驱动和科学应用中推进时空因果推理的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.05295</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数对称性的破坏与恢复决定了人工智能系统中的分层学习</title>
      <link>https://arxiv.org/abs/2502.05300</link>
      <description><![CDATA[arXiv:2502.05300v1 公告类型：新
摘要：现代大型人工智能系统中的学习动态是分层的，通常以突然的定性转变为特征，类似于物理系统中观察到的相变。虽然这些现象有望揭示神经网络和语言模型背后的机制，但现有理论仍然支离破碎，只针对特定情况。在本文中，我们假设参数对称性破坏和恢复是这些行为背后的统一机制。我们综合了先前的观察结果，并展示了这种机制如何解释神经网络中的三个不同层次：学习动态、模型复杂性和表示形成。通过连接这些层次结构，我们强调对称性——理论物理学的基石——是现代人工智能的潜在基本原理。]]></description>
      <guid>https://arxiv.org/abs/2502.05300</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多智能体系统的高斯过程的分散在线集成</title>
      <link>https://arxiv.org/abs/2502.05301</link>
      <description><![CDATA[arXiv:2502.05301v1 公告类型：新
摘要：灵活且可扩展的分散式学习解决方案在多智能体系统的应用中至关重要。虽然最近的几种方法在分布式环境中引入了（一组）核机，但贝叶斯解决方案的限制要多得多。我们引入了一个完全分散的、渐近精确的解来计算高斯过程的随机特征近似。我们通过引入基于在线贝叶斯模型平均的贝叶斯多核学习的集成方案进一步解决了超参数的选择问题。在模拟和真实数据集上针对贝叶斯和频率论方法测试了所得算法。]]></description>
      <guid>https://arxiv.org/abs/2502.05301</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从差异私有森林重建训练集：DP 有多有效？</title>
      <link>https://arxiv.org/abs/2502.05307</link>
      <description><![CDATA[arXiv:2502.05307v1 公告类型：新
摘要：最近的研究表明，机器学习模型容易受到针对其训练数据的隐私攻击。差分隐私 (DP) 已成为一种广泛采用的对策，因为它提供了严格的隐私保护。
在本文中，我们介绍了一种针对最先进的 $\varepsilon$-DP 随机森林的重建攻击。通过利用结合了森林结构和 DP 机制特征知识的约束编程模型，我们的方法正式重建了可能产生给定森林的最可能数据集。
通过大量的计算实验，我们研究了模型效用、隐私保证和重建准确性在各种配置之间的相互作用。我们的结果表明，使用有意义的 DP 保证训练的随机森林仍然会泄露其训练数据的大量部分。具体而言，虽然 DP 降低了重建攻击的成功率，但唯一对我们的攻击完全稳健的森林的预测性能并不比常数分类器好。基于这些见解，我们为构建更能抵御重建攻击并保持非平凡预测性能的 DP 随机森林提供了实用建议。]]></description>
      <guid>https://arxiv.org/abs/2502.05307</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 AI/ML 的自动调制识别：最新趋势和未来可能性</title>
      <link>https://arxiv.org/abs/2502.05315</link>
      <description><![CDATA[arXiv:2502.05315v1 公告类型：新
摘要：我们回顾了文献中提出的用于对各种射频 (RF) 调制方案进行分类的高性能自动调制识别 (AMR) 模型。我们复制了这些模型，并比较了它们在一系列信噪比下的准确度性能。为了确保公平比较，我们使用相同的数据集 (RadioML-2016A)、相同的硬件和一致的测试准确度定义作为评估指标，从而为未来的 AMR 研究提供了基准。超参数是根据作者在相关参考文献中的建议选择的，以获得尽可能接近原始结果的结果。复制的模型可供公众访问，以便进一步分析 AMR 模型。我们还展示了所选模型与其参数数量的测试准确度，表明了它们的复杂性。在此比较分析的基础上，我们确定了提高这些模型性能的策略。最后，我们提出了潜在的改进机会，无论是通过新颖的架构、数据处理技术还是训练策略，以进一步提升 AMR 模型的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.05315</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多电子薛定谔方程神经网络求解器的对角对称化</title>
      <link>https://arxiv.org/abs/2502.05318</link>
      <description><![CDATA[arXiv:2502.05318v1 公告类型：新
摘要：将群对称性纳入神经网络是许多人工智能科学应用取得成功的基石。等距对角群描述了多个物体同时移动时的不变性，在多体量子问题中自然出现。尽管对角群很重要，但人们对此的关注相对较少，因为除了特殊情况外，它们缺乏对不变映射的自然选择。我们研究了在通过变分蒙特卡罗方法训练的神经网络中引入对角不变性的不同方法，并特别考虑了数据增强、组平均和规范化。我们表明，与标准 ML 设置相反，训练中的对称化会破坏训练的稳定性并导致性能下降。我们的理论和数值结果表明，这种意外行为可能源于标准 ML 对称化分析中未发现的独特计算统计权衡。同时，我们证明事后平均对此类权衡不太敏感，并且成为一种简单、灵活且有效的改进神经网络求解器的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.05318</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用联合机器学习进行喷气发动机的预测性维护</title>
      <link>https://arxiv.org/abs/2502.05321</link>
      <description><![CDATA[arXiv:2502.05321v1 公告类型：新
摘要：本文的目标是使用联合机器学习框架预测涡轮喷气发动机的剩余使用寿命 (RUL)。联合学习使多个边缘设备/节点或服务器能够协作训练共享模型而无需共享敏感数据，从而保护数据隐私和安全。通过实施非线性模型，系统旨在捕获引擎数据中的复杂关系和模式，以提高 RUL 预测的准确性。这种方法利用分散式计算，允许在每个设备上本地训练模型，然后在中央服务器上聚合学习到的权重。通过准确预测喷气发动机的 RUL，可以优化维护计划、减少停机时间并提高运营效率，最终节省航空业的成本并提高性能。计算结果是使用 C-MAPSS 数据集提供的，该数据集在 NASA 网站上公开提供，是研究和分析各种操作场景中发动机退化行为的宝贵资源。]]></description>
      <guid>https://arxiv.org/abs/2502.05321</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从反事实到树：模型提取攻击的竞争分析</title>
      <link>https://arxiv.org/abs/2502.05325</link>
      <description><![CDATA[arXiv:2502.05325v1 公告类型：新
摘要：机器学习即服务 (MLaaS) 的出现加剧了模型可解释性和安全性之间的权衡。特别是，可解释性技术（例如反事实解释）无意中增加了模型提取攻击的风险，从而导致未经授权复制专有模型。在本文中，我们形式化并描述了模型重建的风险和固有复杂性，重点关注忠实推断底层预测函数所需的“oracle”查询。我们通过竞争分析的视角首次对模型提取攻击进行了正式分析，建立了一个评估其效率的基础框架。我们专注于基于加法决策树（例如决策树、梯度提升和随机森林）的模型，引入了新颖的重建算法，这些算法可实现可证明的完美保真度，同时展示出强大的随时性能。我们的框架为提取基于树的模型的查询复杂性提供了理论界限，为其部署的安全漏洞提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.05325</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用自动编码器对抗变换器 (AT-AT) 去除神经信号伪影</title>
      <link>https://arxiv.org/abs/2502.05332</link>
      <description><![CDATA[arXiv:2502.05332v1 公告类型：新 
摘要：肌电 (EMG) 噪声是 EEG 数据中的主要污染源，会妨碍对大脑特定神经活动的准确分析。最近关于 EMG 伪影去除的文献已经超越了传统的线性算法，转而采用基于机器学习的系统。然而，现有的基于深度学习的过滤方法通常具有很大的计算占用空间和过长的训练时间。在本研究中，我们提出了一种新的基于机器学习的系统，用于使用针对自动编码器的对抗变换器 (AT-AT) 从 EEG 数据中过滤 EMG 干扰。通过利用自动编码器的轻量级表达能力来确定最佳时间序列变换器应用位置，我们的 AT-AT 架构与已发布的伪影去除模型相比，模型尺寸减少了 90% 以上。增加对抗性训练可确保滤波信号符合 EEG 数据的基本特征。我们使用来自 67 名受试者的已发布神经数据训练 AT-AT，发现该系统能够实现与更大模型相当的测试性能； AT-AT 在初始信噪比 (SNR) 为 2 dB 时的平均重构相关系数高于 0.95，在 -7 dB SNR 时的平均重构相关系数为 0.70。进一步研究将这些结果推广到这些孤立测试案例之外的更广泛样本量将至关重要；虽然超出了本研究的范围，但我们还在附录中包括了 AT-AT 的实际部署结果。]]></description>
      <guid>https://arxiv.org/abs/2502.05332</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>脑电图信号的几何机器学习</title>
      <link>https://arxiv.org/abs/2502.05334</link>
      <description><![CDATA[arXiv:2502.05334v1 公告类型：新
摘要：脑机接口 (BCI) 具有变革潜力，但解码神经信号面临重大挑战。本文的核心前提是围绕展示阐明高维脑电波数据中存在的底层低维几何结构的方法，以协助下游 BCI 相关的神经分类任务。我们展示了两个与脑电图 (EEG) 信号处理相关的管道：(1) 一个从单个 EEG 通道中去除噪声的初步管道，以及 (2) 一个下游流形学习管道，揭示 EEG 通道网络中的几何结构。我们使用两个 EEG 数据集进行初步验证，并将我们的演示置于与 BCI 相关的想象数字解码问题的背景下。我们的初步管道使用基于注意力的 EEG 过滤网络从单个 EEG 通道中提取干净的信号。我们的主要管道使用快速傅里叶变换、拉普拉斯特征图、通过 Ollivier 的 Ricci 曲率概念对 Ricci 流进行离散模拟以及图卷积网络对高维多通道 EEG 数据进行降维，以实现可正则化的下游分类。我们的系统与现有的信号处理和分类基准相比具有竞争力；我们在半合成神经去噪上证明了 2 dB 下的平均检验相关系数 &gt;0.95，并且在区分数字和非数字思维方面基于下游 EEG 的分类准确率为 0.97。结果是初步的，我们的几何机器学习管道应该通过更广泛的后续研究进行验证；将这些结果推广到更大的受试者间样本量、不同的硬件系统和更广泛的用例将至关重要。]]></description>
      <guid>https://arxiv.org/abs/2502.05334</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向动态系统重建的基础模型：通过混合专家进行分层元学习</title>
      <link>https://arxiv.org/abs/2502.05335</link>
      <description><![CDATA[arXiv:2502.05335v1 公告类型：新
摘要：随着基础模型重塑科学发现，动态系统重建 (DSR) 的瓶颈仍然存在：跨系统层次结构学习的能力。许多元学习方法已成功应用于单个系统，但在面对需要学习多个层次结构的稀疏、松散相关的数据集时会失败。混合专家 (MoE) 提供了一种自然的范例来应对这些挑战。尽管它们具有潜力，但我们证明，简单的 MoE 不足以满足分层 DSR 的细微需求，这主要是因为它们基于梯度下降的门控更新机制导致训练期间更新缓慢和路由冲突。为了克服这一限制，我们引入了 MixER：混合专家重建器，这是一种新颖的稀疏 top-1 MoE 层，采用基于 $K$ 均值和最小二乘的自定义门控更新算法。大量实验验证了 MixER 的功能，证明了其高效训练和可扩展性，可处理多达十个参数常微分方程系统。然而，在高数据环境下，我们的层表现不如最先进的元学习器，尤其是当每个专家只能处理由高度相关的数据点组成的数据集的一小部分时。对合成和神经科学时间序列的进一步分析表明，MixER 生成的上下文表示的质量与数据中是否存在层次结构密切相关。]]></description>
      <guid>https://arxiv.org/abs/2502.05335</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>