<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DiReDi：用于 AIoT 应用的蒸馏和逆蒸馏</title>
      <link>https://arxiv.org/abs/2409.08308</link>
      <description><![CDATA[arXiv:2409.08308v1 公告类型：新
摘要：通常，通过在各种实际场景中部署不同的边缘 AI 模型，而一些大型模型从云服务器远程管理这些边缘 AI 模型，可以实现显着的效率。然而，为每个用户的特定应用定制边缘 AI 模型或将当前模型扩展到新的应用场景仍然是一个挑战。用户对边缘 AI 模型进行不适当的本地训练或微调可能会导致模型故障，从而可能给制造商带来法律问题。为了解决上述问题，本文提出了一个创新框架“DiReD”，它涉及知识蒸馏和逆蒸馏。在初始步骤中，使用上层管理云服务器中的云 AI 模型使用假定数据和 KD 过程训练边缘 AI 模型。然后，该边缘 AI 模型被调度到边缘 AI 设备，仅用于在用户的应用场景中进行推理。当用户需要更新边缘 AI 模型以更好地适应实际场景时，采用逆向蒸馏 (RD) 过程，使用用户的独有数据从边缘 AI 模型中提取知识：用户偏好与制造商假设之间的差异。只有提取的知识才会报告回上层管理云服务器以更新云 AI 模型，从而不使用任何独有数据来保护用户隐私。然后，更新后的云 AI 可以使用扩展的知识更新边缘 AI 模型。仿真结果表明，所提出的“DiReDi”框架允许制造商通过使用私有数据从用户的实际场景中学习新知识来更新用户模型。由于重新训练强调用户私有数据，因此减少了初始冗余知识。]]></description>
      <guid>https://arxiv.org/abs/2409.08308</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedProphet：通过理论稳健性和低不一致性级联学习实现内存高效的联邦对抗训练</title>
      <link>https://arxiv.org/abs/2409.08372</link>
      <description><![CDATA[arXiv:2409.08372v1 公告类型：新
摘要：联邦学习（FL）通过跨边缘设备进行本地训练而无需共享训练数据来提供强大的隐私保障，而联邦对抗训练（FAT）进一步增强了对抗样本的鲁棒性，向值得信赖的人工智能迈进了一步。然而，FAT 需要一个大模型来保持高精度的同时实现强大的鲁棒性，并且由于内存交换延迟，直接使用内存受限的边缘设备进行训练时速度不切实际。此外，由于局部和全局模型不一致，即目标不一致，现有的内存高效的 FL 方法在 FAT 中精度差、鲁棒性弱。
在本文中，我们提出了 FedProphet，一种新颖的 FAT 框架，可以同时实现内存效率、对抗鲁棒性和目标一致性。FedProphet 将大模型划分为小的级联模块，以便内存受限的设备可以逐个模块地进行对抗训练。推导出强凸性正则化，从理论上保证整个模型的稳健性，并且我们表明强稳健性意味着 FedProphet 中的目标不一致性较低。我们还在 FL 服务器上开发了一个训练协调器，使用自适应扰动调整来平衡效用和稳健性，使用差异化模块分配来缓解目标不一致性。与以前的内存高效方法相比，FedProphet 在经验上显示出准确性和稳健性的显着提高，实现了几乎与端到端 FAT 相同的性能，内存减少了 80%，训练时间加快了 10.8 倍。]]></description>
      <guid>https://arxiv.org/abs/2409.08372</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高阶拓扑方向性和有向单纯形神经网络</title>
      <link>https://arxiv.org/abs/2409.08389</link>
      <description><![CDATA[arXiv:2409.08389v1 公告类型：新
摘要：拓扑深度学习 (TDL) 已成为一种处理和学习在高阶组合拓扑空间（例如单纯形或细胞复合体）上定义的信号的范例。尽管许多复杂系统具有不对称的关系结构，但大多数 TDL 模型都会强制对称化这些关系。在本文中，我们首先介绍了一种新的高阶方向性概念，然后基于它设计了有向单纯形神经网络 (Dir-SNN)。Dir-SNN 是在有向单纯形复合体上运行的消息传递网络，能够利用单纯形之间的有向和可能不对称的交互。据我们所知，这是第一个使用高阶方向性概念的 TDL 模型。我们从理论和经验上证明，在区分同构有向图方面，Dir-SNN 比有向图更具表现力。在合成源定位任务上的实验表明，当底层复杂是有向时，Dir-SNN 的表现优于无向 SNN，而当底层复杂无向时，其表现相当。]]></description>
      <guid>https://arxiv.org/abs/2409.08389</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分数作为行动：通过连续时间强化学习微调扩散模型的框架</title>
      <link>https://arxiv.org/abs/2409.08400</link>
      <description><![CDATA[arXiv:2409.08400v1 公告类型：新
摘要：从人类反馈中进行强化学习 (RLHF) 已被证明是将生成模型与人类意图相结合的一个有希望的方向，并且在最近的研究中也被用于扩散生成模型的对齐。在这项工作中，我们通过将微调扩散模型的任务（从人类反馈中学习到的奖励函数）制定为探索性连续时间随机控制问题来提供严格的处理。我们的关键思想在于将分数匹配函数视为控制/动作，在此基础上，我们从连续时间的角度开发了一个统一的框架，以使用强化学习 (RL) 算法来提高扩散模型的生成质量。我们还在随机不同方程驱动环境的假设下开发了相应的连续时间 RL 理论，用于策略优化和正则化。随附的论文将报告文本到图像 (T2I) 生成的实验。]]></description>
      <guid>https://arxiv.org/abs/2409.08400</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Wasserstein 分布稳健多类支持向量机</title>
      <link>https://arxiv.org/abs/2409.08409</link>
      <description><![CDATA[arXiv:2409.08409v1 公告类型：新
摘要：我们研究数据特征 $\mathbf{x}$ 及其标签 $\mathbf{y}$ 不确定的设置中的多类分类问题。我们发现，分布稳健的一对多 (OVA) 分类器在数据不平衡的环境中经常会遇到困难。为了解决这个问题，我们使用 Wasserstein 分布稳健优化来开发以 Crammer-Singer (CS) 损失为特征的多类支持向量机 (SVM) 的稳健版本。首先，我们证明对于所有 $\mathbf{x} \in \mathcal{X}$ 和 $\mathbf{y} \in \mathcal{Y}$，CS 损失都由 Lipschitz 连续函数从上方界定，然后我们利用强对偶结果来表达最坏情况风险问题的对偶，并表明由于 CS 损失的规律性，最坏情况风险最小化问题允许可处理的凸重构。此外，我们开发了我们提出的模型的内核版本来考虑非线性类分离，并表明它允许可处理的凸上界。我们还为我们提出的线性模型的特殊情况提出了一种投影次梯度方法算法，以提高可扩展性。我们的数值实验表明，在训练数据高度不平衡的环境中，我们的模型优于最先进的 OVA 模型。我们还通过在流行的现实世界数据集上进行的实验表明，我们提出的模型通常优于其正则化模型，因为前者考虑了不确定的标签，而后者则不然。]]></description>
      <guid>https://arxiv.org/abs/2409.08409</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CausalBench 介绍：用于因果分析和机器学习的灵活基准框架</title>
      <link>https://arxiv.org/abs/2409.08419</link>
      <description><![CDATA[arXiv:2409.08419v1 公告类型：新
摘要：在见证机器学习 (ML) 技术在许多应用中取得非凡成功的同时，用户开始注意到 ML 的一个关键缺点：相关性无法替代因果关系。发现因果关系的传统方法是使用随机对照实验 (RCT)；然而，在许多情况下，这些方法不切实际或有时不道德。从观察数据中进行因果学习提供了一种有希望的替代方案。虽然因果学习相对较新，但它旨在远远超越传统的机器学习，但仍存在几个主要挑战。不幸的是，由于缺乏统一的基准数据集、算法、指标和因果学习评估服务接口，进展受到阻碍。在本文中，我们介绍了一个透明、公平且易于使用的评估平台 {\em CausalBench}，旨在 (a) 通过促进新算法、数据集和指标方面的科学合作，推动因果学习研究的进步；(b) 促进因果学习研究中的科学客观性、可重复性、公平性和对偏见的认识。CausalBench 提供基准数据、算法、模型和指标的服务，影响广泛的科学和工程学科的需求。]]></description>
      <guid>https://arxiv.org/abs/2409.08419</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有前瞻信息的非平稳 MDP 的预测控制与遗憾分析</title>
      <link>https://arxiv.org/abs/2409.08434</link>
      <description><![CDATA[arXiv:2409.08434v1 公告类型：新
摘要：非平稳马尔可夫决策过程 (MDP) 中的策略设计本身就具有挑战性，因为时变系统转换和奖励引入了复杂性，这使得学习者难以确定最大化未来累积奖励的最佳行动。幸运的是，在许多实际应用中，例如能源系统，都可以进行前瞻预测，包括对可再生能源发电和需求的预测。在本文中，我们利用这些前瞻预测，并提出了一种通过结合此类预测来实现非平稳 MDP 中低遗憾的算法。我们的理论分析表明，在某些假设下，随着前瞻窗口的扩大，遗憾会呈指数下降。当系统预测出现错误时，即使预测误差随着预测范围的亚指数增长，遗憾也不会爆发。我们通过模拟验证了我们的方法，证实了我们的算法在非平稳环境中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.08434</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从学习角度重新思考元学习</title>
      <link>https://arxiv.org/abs/2409.08474</link>
      <description><![CDATA[arXiv:2409.08474v1 公告类型：新
摘要：元学习已成为一种利用先前任务中的知识来解决新任务的强大方法。主流方法侧重于训练一个广义的模型初始化，然后使用有限的数据和更新将其适应不同的任务。然而，它推动了模型在训练任务上的过度拟合。以前的方法主要将此归因于缺乏数据并使用增强来解决这个问题，但它们受到充分训练和有效增强策略的限制。在这项工作中，我们专注于更基本的“学会学习”元学习策略，以探索导致错误的原因以及如何在不改变环境的情况下消除这些错误。具体来说，我们首先从“学习”的角度重新思考元学习的算法过程。通过理论和实证分析，我们发现：（i）该范式面临过度拟合和欠拟合的风险；（ii）适应不同任务的模型会相互促进，任务越相似，效果就越强。基于这一见解，我们建议使用任务关系来校准元学习的优化过程，并提出了一种即插即用的方法，称为任务关系学习器 (TRLearner) 来实现这一目标。具体来说，它首先从提取的任务特定元数据中获得任务关系矩阵。然后，它使用具有关系感知一致性正则化的矩阵来指导优化。大量的理论和实证分析证明了 TRLearner 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.08474</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将神经算子与扩散模型相结合可改善湍流建模中的光谱表示</title>
      <link>https://arxiv.org/abs/2409.08477</link>
      <description><![CDATA[arXiv:2409.08477v1 公告类型：新
摘要：我们将神经算子与扩散模型相结合，以解决神经算子在湍流替代建模中的光谱限制。虽然神经算子提供了计算效率，但它们在捕捉高频流动动力学方面表现出不足，导致近似值过于平滑。为了克服这个问题，我们在神经算子上设定了扩散模型，以提高湍流结构的分辨率。我们的方法在不同数据集上针对不同的神经算子进行了验证，包括高雷诺数射流模拟和实验纹影测速。与单独的神经算子相比，所提出的方法显着改善了预测能量谱与真实分布的对齐。此外，适当的正交分解分析表明时空中的光谱保真度增强。这项工作为将生成模型与神经算子相结合以推进湍流系统的替代建模建立了一个新范式，并且可以用于涉及微观结构和高频内容的其他科学应用。查看我们的项目页面：vivekoommen.github.io/NO_DM]]></description>
      <guid>https://arxiv.org/abs/2409.08477</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>共享 LoRA 微调扩散模型权重时的风险</title>
      <link>https://arxiv.org/abs/2409.08482</link>
      <description><![CDATA[arXiv:2409.08482v1 公告类型：新 
摘要：随着生成模型的兴起以及在大型数据集上预先训练的扩散模型的方便公开访问，用户可以对这些模型进行微调以生成自然语言描述的新上下文中的个人面部或物品图像。参数高效微调（PEFT），例如低秩自适应（LoRA），已成为在微调期间节省用户端内存和计算使用量的最常用方法。然而，一个自然的问题是，在共享模型权重时，用于微调的隐私图像是否会泄露给对手。在本文中，我们研究了实际环境中微调扩散模型的隐私泄露问题，其中对手只能访问模型权重，而不能访问用于微调的提示或图像。我们设计并构建了一个变分网络自动编码器，它将模型权重作为输入并输出隐私图像的重建。为了提高训练这种自动编码器的效率，我们提出了一种借助时间步长嵌入的训练范式。结果对这一研究问题给出了令人惊讶的答案：对手可以生成包含与隐私图像相同身份的图像。此外，我们证明了现有的防御方法（包括基于差分隐私的方法）都无法在不损害微调模型效用的情况下保护用于微调扩散模型的隐私数据。]]></description>
      <guid>https://arxiv.org/abs/2409.08482</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于子图的链接预测扩散模型</title>
      <link>https://arxiv.org/abs/2409.08487</link>
      <description><![CDATA[arXiv:2409.08487v1 公告类型：新
摘要：去噪扩散概率模型 (DDPM) 代表了一类当代生成模型，在综合和最大化数据似然性方面都具有卓越的品质。这些模型通过遍历数据受到扰动的前向马尔可夫链来工作，然后进行反向过程，其中神经网络学习消除扰动并恢复原始数据。人们越来越多地探索 DDPM 在图域中的应用。然而，他们中的大多数都集中在生成视角上。在本文中，我们旨在构建一种用于链接预测的新型生成模型。具体而言，我们将一对节点之间的链接预测视为其封闭子图的条件似然估计。通过专门的设计通过贝叶斯公式分解似然估计过程，我们能够分离子图结构的估计及其节点特征。这样的设计使我们的模型能够同时享受归纳学习和强大的泛化能力的优势。值得注意的是，在各种数据集上进行的全面实验验证了我们提出的方法具有许多优势：（1）无需重新训练即可跨数据集迁移，（2）在有限的训练数据上具有良好的泛化能力，（3）对图对抗攻击具有鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2409.08487</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过分割学习增强 ControlNet 中的隐私和稳定扩散</title>
      <link>https://arxiv.org/abs/2409.08503</link>
      <description><![CDATA[arXiv:2409.08503v1 公告类型：新
摘要：随着大型生成模型的兴起，ControlNet 的引入使用户能够使用自己的数据针对各种用例对预训练模型进行微调。一个自然而然的问题出现了：我们如何训练 ControlNet 模型，同时确保用户在分布式设备上的数据隐私？探索不同的分布式训练方案，我们发现传统的联邦学习和拆分学习并不合适。相反，我们提出了一种新的分布式学习结构，消除了服务器发送梯度的需要。通过对现有威胁的全面评估，我们发现在使用拆分学习训练 ControlNet 的背景下，大多数现有攻击都是无效的，除了先前文献中提到的两种攻击。为了应对这些威胁，我们利用扩散模型的特性，并在前向过程中设计了一种新的时间步采样策略。我们进一步提出了一种隐私保护激活函数和一种防止私人文本提示离开客户端的方法，专门用于使用扩散模型生成图像。我们的实验结果表明，我们的算法和系统大大提高了 ControlNet 分布式训练的效率，同时确保了用户的数据隐私，且不影响图像生成质量。]]></description>
      <guid>https://arxiv.org/abs/2409.08503</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mamba 与 Transformer 的集成——MAT 用于长短期时间序列预测并应用于天气动力学</title>
      <link>https://arxiv.org/abs/2409.08530</link>
      <description><![CDATA[arXiv:2409.08530v1 公告类型：新
摘要：长短期时间序列预测对于预测长期未来趋势和模式至关重要。虽然 Transformers 等深度学习模型在推进时间序列预测方面取得了重大进展，但它们在捕捉长期依赖关系和有效管理稀疏语义特征方面经常遇到困难。状态空间模型 Mamba 通过熟练处理选择性输入和并行计算来解决这些问题，在计算效率和预测准确性之间取得平衡。本文研究了 Mamba 和 Transformer 模型的优缺点，并介绍了一种组合方法 MAT，该方法利用每个模型的优势来捕捉多元时间序列中独特的长短期依赖关系和固有的演化模式。具体而言，MAT 利用了 Mamba 的长期依赖能力和 Transformers 的短期特性。在基准天气数据集上的实验结果表明，MAT 在预测准确性、可扩展性和内存效率方面优于现有的同类方法。]]></description>
      <guid>https://arxiv.org/abs/2409.08530</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种高效的卫星通信隐私感知分割学习框架</title>
      <link>https://arxiv.org/abs/2409.08538</link>
      <description><![CDATA[arXiv:2409.08538v1 公告类型：新
摘要：在快速发展的卫星通信领域，集成先进的机器学习技术，特别是分割学习，对于提高卫星、空间站和地面站的数据处理和模型训练效率至关重要。传统的机器学习方法在卫星网络中经常面临重大挑战，原因是带宽和计算资源有限等限制。为了解决这一差距，我们提出了一个新框架，以提高卫星通信中 SL 的效率。我们的方法，动态拓扑知情剪枝，即 DTIP，将差异隐私与图和模型剪枝相结合，以优化图神经网络进行分布式学习。DTIP 策略性地将差异隐私应用于原始图数据并剪枝 GNN，从而优化跨网络层的模型大小和通信负载。在不同数据集上进行的大量实验证明了 DTIP 在增强隐私、准确性和计算效率方面的有效性。具体来说，在 Amazon2M 数据集上，DTIP 保持 0.82 的准确率，同时将每秒浮点运算次数减少了 50%。同样，在 ArXiv 数据集上，DTIP 在可比条件下实现了 0.85 的准确率。我们的框架不仅显著提高了卫星通信的运行效率，而且还为隐私感知分布式学习树立了新的标杆，有可能彻底改变太空网络中的数据处理方式。]]></description>
      <guid>https://arxiv.org/abs/2409.08538</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果 GNN：一种用于网络因果推理的 GNN 驱动的工具变量方法</title>
      <link>https://arxiv.org/abs/2409.08544</link>
      <description><![CDATA[arXiv:2409.08544v1 公告类型：新
摘要：随着网络数据应用的不断扩展，网络内的因果推理引起了越来越多的关注。然而，隐藏的混杂因素使因果效应的估计变得复杂。大多数方法依赖于强可忽略性假设，该假设假定不存在隐藏的混杂因素——这一假设在实践中既难以验证，又往往不切实际。为了解决这个问题，我们提出了 CgNN，这是一种新方法，它利用网络结构作为工具变量 (IV)，结合图神经网络 (GNN) 和注意力机制，以减轻隐藏的混杂因素偏差并改善因果效应估计。通过利用网络结构作为 IV，我们可以减少混杂因素偏差，同时保留与治疗的相关性。我们对注意力机制的整合增强了稳健性并提高了重要节点的识别能力。通过在两个真实数据集上的验证，我们的结果表明 CgNN 有效地减轻了隐藏的混杂偏差，并为复杂网络数据中的因果推理提供了一个强大的 GNN 驱动的 IV 框架。]]></description>
      <guid>https://arxiv.org/abs/2409.08544</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>