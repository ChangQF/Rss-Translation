<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Mon, 18 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>测试时图分布变化下的在线 GNN 评估</title>
      <link>https://arxiv.org/abs/2403.09953</link>
      <description><![CDATA[arXiv:2403.09953v1 公告类型：新
摘要：评估训练有素的 GNN 模型在现实世界图上的性能是可靠的 GNN 在线部署和服务的关键一步。由于缺乏测试节点标签和未知的潜在训练-测试图数据分布变化，传统模型评估在计算性能指标（例如测试误差）和测量图数据水平差异时遇到限制，特别是当训练图用于开发时GNN 在测试期间仍然未被观察到。在本文中，我们研究了一个新的研究问题，即在线 GNN 评估，旨在为训练有素的 GNN 在测试时图分布变化下有效泛化到现实世界未标记图的能力提供有价值的见解。具体来说，我们开发了一种有效的学习行为差异分数，称为 LeBeD，来估计训练有素的 GNN 模型的测试时泛化误差。通过一种具有无参数最优性标准的新型 GNN 重新训练策略，所提出的 LeBeD 从节点预测和结构重建的角度全面整合了学习行为差异。这使得能够有效评估训练有素的 GNN 捕获测试节点语义和结构表示的能力，使其成为在线 GNN 评估中估计泛化误差的表达指标。在不同图分布变化下对真实世界测试图进行大量实验可以验证该方法的有效性，揭示其与各种训练有素的 GNN 模型上的真实测试误差的强相关性。]]></description>
      <guid>https://arxiv.org/abs/2403.09953</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>FedComLoc：稀疏和量化模型的通信高效分布式训练</title>
      <link>https://arxiv.org/abs/2403.09904</link>
      <description><![CDATA[arXiv:2403.09904v1 公告类型：新
摘要：联邦学习（FL）因其独特的特性而受到越来越多的关注，即允许异构客户端在本地处理其私有数据并与中央服务器交互，同时尊重隐私。 FL 的一个关键瓶颈是通信成本。减轻这种负担的关键策略是\emph{本地训练}，它涉及在通信阶段之间运行多个本地随机梯度下降迭代。我们的工作受到创新的 \emph{Scaffnew} 算法的启发，该算法极大地促进了 FL 中通信复杂性的降低。我们引入FedComLoc（联合压缩和本地训练），将实用有效的压缩集成到\emph{Scaffnew}中，进一步提高通信效率。使用流行的 TopK 压缩器和量化进行的大量实验证明了其在大幅减少异构设置中的通信开销方面的能力。]]></description>
      <guid>https://arxiv.org/abs/2403.09904</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>质量多样性演员批评家：通过价值和继任者特征批评家学习高绩效和多样化的行为</title>
      <link>https://arxiv.org/abs/2403.09930</link>
      <description><![CDATA[arXiv:2403.09930v1 公告类型：新
摘要：智力的一个关键方面是表现出适应意外情况的广泛行为的能力。在过去的十年中，深度强化学习的进步在解决复杂的连续控制任务方面取得了突破性的成就。然而，大多数方法仅返回专门针对特定问题的一种解决方案。我们引入了质量多样性演员批评家（QDAC），这是一种离策略演员批评家深度强化学习算法，它利用价值函数批评家和后继特征批评家来学习高性能和多样化的行为。在这个框架中，参与者优化了一个目标，该目标使用约束优化无缝地统一了两个批评者，以（1）最大化回报，同时（2）执行不同的技能。与其他质量多样性方法相比，QDAC 在六种具有挑战性的连续控制运动任务上实现了显着更高的性能和更多样化的行为。我们还证明，我们可以利用学到的技能比其他基线更好地适应五种扰动环境。最后，定性分析展示了一系列显着的行为，可访问：http://bit.ly/qdac。]]></description>
      <guid>https://arxiv.org/abs/2403.09930</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>与对手联合策略梯度方法的全球收敛保证</title>
      <link>https://arxiv.org/abs/2403.09940</link>
      <description><![CDATA[arXiv:2403.09940v1 公告类型：新
摘要：联合强化学习（FRL）允许多个智能体协作制定决策策略，而无需共享原始轨迹。然而，如果这些代理中的一小部分是对抗性的，则可能会导致灾难性的结果。我们提出了一种基于策略梯度的方法，该方法对于可以向服务器发送任意值的对抗代理具有鲁棒性。在这种情况下，我们的结果形成了第一个具有一般参数化的全局收敛保证。这些结果证明了对手的弹性，同时实现了 $\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \ frac{f^2}{(N-f)^2}\right)\right)$，其中$N$是代理总数，$f$是对抗代理的数量。]]></description>
      <guid>https://arxiv.org/abs/2403.09940</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>平均场机制中缩放深度 ResNet 的推广</title>
      <link>https://arxiv.org/abs/2403.09889</link>
      <description><![CDATA[arXiv:2403.09889v1 公告类型：新
摘要：尽管 ResNet 取得了广泛的经验成功，但除了惰性训练机制之外，很少有人探索深度 ResNet 的泛化特性。在这项工作中，我们研究了无限深无限宽神经网络极限下的\emph{scaled} ResNet，其中梯度流由大神经网络极限下的偏微分方程描述，即\emph{mean -field} 政权。为了导出这种设置下的泛化界限，我们的分析需要从惰性训练机制中使用的传统时不变格拉姆矩阵转变为时变、分布相关的版本。为此，我们提供了平均场状态下 Gram 矩阵最小特征值的全局下界。此外，为了Kullback-Leibler (KL)散度动态的可追溯性，我们建立了经验误差的线性收敛性，并估计参数分布上KL散度的上限。最后，我们通过 Rademacher 复杂度构建泛化边界的一致收敛。我们的结果为深度 ResNet 超越惰性训练机制的泛化能力提供了新的见解，并有助于增进对深度神经网络基本属性的理解。]]></description>
      <guid>https://arxiv.org/abs/2403.09889</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>TimeMachine：时间序列值得 4 个曼巴进行长期预测</title>
      <link>https://arxiv.org/abs/2403.09898</link>
      <description><![CDATA[arXiv:2403.09898v1 公告类型：新
摘要：由于难以捕获长期依赖性、实现线性可扩展性和保持计算效率，长期时间序列预测仍然具有挑战性。我们推出了 TimeMachine，这是一种创新模型，它利用 Mamba（一种状态空间模型）来捕获多元时间序列数据中的长期依赖性，同时保持线性可扩展性和较小的内存占用。 TimeMachine 利用时间序列数据的独特属性来产生多尺度的显着上下文线索，并利用创新的集成四曼巴架构来统一对通道混合和通道独立情况的处理，从而能够有效地选择内容进行预测不同尺度的全球和地方背景。在实验上，TimeMachine 在预测准确性、可扩展性和内存效率方面实现了卓越的性能，并使用基准数据集进行了广泛验证。代码可用性：https://github.com/Atik-Ahamed/TimeMachine]]></description>
      <guid>https://arxiv.org/abs/2403.09898</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>通过监控早期训练表示进行鲁棒子图学习</title>
      <link>https://arxiv.org/abs/2403.09901</link>
      <description><![CDATA[arXiv:2403.09901v1 公告类型：新
摘要：图神经网络（GNN）因其在图学习和节点分类任务中的出色表现而引起了广泛关注。然而，它们容易受到对抗性攻击，特别是通过易受影响的节点，这给决策带来了挑战。在由于攻击在整个图中传播而产生的对抗性挑战中，对强大的图汇总的需求是显而易见的。在本文中，我们通过引入新技术 SHERD（通过早期训练表示距离进行子图学习 Hale）来解决图输入中的性能和对抗鲁棒性问题。 SHERD 利用来自部分训练的图卷积网络 (GCN) 各层的信息，使用标准距离度量在对抗性攻击期间检测易受影响的节点。该方法识别“脆弱（坏）”节点并删除此类节点以形成鲁棒子图，同时保持节点分类性能。通过我们的实验，我们通过将原始和子图输入的网络性能与各种基线以及现有的对抗性攻击进行比较，证明了 SHERD 在增强鲁棒性方面的性能提高。我们在多个数据集（包括 Cora、Citeseer 和 Pubmed 等引文数据集，以及胎盘细胞图的显微解剖组织结构）上进行的实验表明，SHERD 不仅在鲁棒性能方面实现了实质性改进，而且在以下方面优于多个基线：节点分类精度和计算复杂度。]]></description>
      <guid>https://arxiv.org/abs/2403.09901</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>白盒神经网络的概念框架</title>
      <link>https://arxiv.org/abs/2403.09863</link>
      <description><![CDATA[arXiv:2403.09863v1 公告类型：新
摘要：本文介绍了语义特征作为完全可解释的神经网络层的通用概念框架。 MNIST 相关子问题的一个动机良好的概念验证模型由 4 个这样的层组成，总共有 4.8K 个可学习参数。该模型易于解释，无需进行任何形式的对抗训练即可达到人类水平的对抗测试精度，几乎不需要超参数调整，并且可以在单个 CPU 上快速训练。该技术的一般性质有望实现向彻底民主化和真正通用的白盒神经网络的范式转变。代码可在 https://github.com/314-Foundation/white-box-nn 获取]]></description>
      <guid>https://arxiv.org/abs/2403.09863</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>iBRF：改进的平衡随机森林分类器</title>
      <link>https://arxiv.org/abs/2403.09867</link>
      <description><![CDATA[arXiv:2403.09867v1 公告类型：新
摘要：类不平衡给不同分类任务带来了重大挑战，这是许多实际应用中经常出现的场景。数据重采样被认为是解决这个问题的标准方法。该技术的目标是通过生成新样本或从数据中消除样本来平衡类别分布。多年来，人们提出了各种各样的采样技术来解决这一具有挑战性的问题。采样技术也可以合并到集成学习框架中以获得更通用的预测性能。平衡随机森林 (BRF) 和 SMOTE-Bagging 是一些流行的集成方法。在本研究中，我们提出对 BRF 分类器进行修改以增强预测性能。在原始算法中，利用随机欠采样（RUS）技术来平衡引导样本。然而，从数据中随机消除太多样本会导致大量数据丢失，从而导致性能大幅下降。我们建议通过采用一种新颖的混合采样方法来平衡每个引导子样本中不均匀的类别分布来缓解这种情况。我们提出的混合采样技术，当纳入随机森林分类器的框架时，称为 iBRF：改进的平衡随机森林分类器，与不平衡分类任务中使用的其他采样技术相比，可以实现更好的预测性能。在 44 个不平衡数据集上进行了实验，原始 BRF 分类器产生的平均 MCC 分数为 47.03%，F1 分数为 49.09%。我们提出的算法优于该方法，产生了更好的 MCC 分数（53.04%）和 F1 分数（55%）。获得的结果表明了 iBRF 算法的优越性及其成为不平衡学习中有效采样技术的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.09867</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的自我监督学习：对比还是生成？</title>
      <link>https://arxiv.org/abs/2403.09809</link>
      <description><![CDATA[arXiv:2403.09809v1 公告类型：新
摘要：自监督学习（SSL）最近成为一种从大规模未标记数据中学习表示的强大方法，在时间序列分析中显示出有希望的结果。自监督表示学习可以分为两大主流：对比式和生成式。在本文中，我们将对时间序列中的对比方法和生成方法进行全面的比较研究。我们首先分别介绍对比式SSL和生成式SSL的基本框架，并讨论如何获取指导模型优化的监督信号。然后，我们为每种类型实现经典算法（SimCLR 与 MAE），并在公平设置中进行比较分析。我们的结果深入了解了每种方法的优点和缺点，并为选择合适的 SSL 方法提供了实用建议。我们还讨论了我们的研究结果对更广泛的表征学习领域的影响，并提出了未来的研究方向。所有代码和数据均在 \url{https://github.com/DL4mHealth/SSL_Comparison} 发布。]]></description>
      <guid>https://arxiv.org/abs/2403.09809</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>走向因果表示的可重用性和组合性</title>
      <link>https://arxiv.org/abs/2403.09830</link>
      <description><![CDATA[arXiv:2403.09830v1 公告类型：新
摘要：因果表示学习（CRL）旨在从高维观察（例如图像）中识别高级因果因素及其关系。虽然大多数 CRL 工作侧重于在单一环境中学习因果表示，但在这项工作中，我们提出了从图像时间序列学习因果表示的第一步，这些图像可以适应新环境，或跨多个相关环境组成。特别是，我们引入了 DECAF，这是一个框架，用于检测哪些因果因素可以重用以及哪些需要根据之前学习的因果表示进行调整。我们的方法基于干预目标的可用性，该目标表明哪些变量在每个时间步骤受到干扰。对三个基准数据集的实验表明，将我们的框架与四种最先进的 CRL 方法相集成，可以在新环境中仅用少量样本实现准确的表示。]]></description>
      <guid>https://arxiv.org/abs/2403.09830</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>具有注意力感知自适应提示的少样本类增量学习</title>
      <link>https://arxiv.org/abs/2403.09857</link>
      <description><![CDATA[arXiv:2403.09857v1 公告类型：新
摘要：少样本类增量学习（FSCIL）模型旨在以稀缺样本增量学习新类，同时保留旧类的知识。现有的 FSCIL 方法通常会对整个主干进行微调，从而导致过度拟合并阻碍学习新课程的潜力。另一方面，最近基于提示的 CIL 方法通过在每个任务中使用足够的数据来训练提示来减轻遗忘。在这项工作中，我们提出了一种名为“注意感知自适应提示”（ASP）的新颖框架。 ASP 鼓励任务不变的提示通过减少注意力方面的特定信息来捕获共享知识。此外，ASP 中的自适应任务特定提示可提供特定信息，并将知识从旧课程转移到新课程，并实现信息瓶颈学习目标。总之，ASP 可以防止基本任务的过度拟合，并且在少量增量任务中不需要大量数据。对三个基准数据集的大量实验验证了 ASP 在学习新课程和减少遗忘方面始终优于最先进的 FSCIL 和基于提示的 CIL 方法。]]></description>
      <guid>https://arxiv.org/abs/2403.09857</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>MAMBA：元强化学习的有效世界模型方法</title>
      <link>https://arxiv.org/abs/2403.09859</link>
      <description><![CDATA[arXiv:2403.09859v1 公告类型：新
摘要：元强化学习（meta-RL）是一个很有前途的框架，用于解决需要高效探索的挑战性领域。现有的元强化学习算法的特点是样本效率低，并且大多关注低维任务分布。与此同时，基于模型的强化学习方法已经成功地解决了部分可观察的 MDP，其中元强化学习是一个特例。在这项工作中，我们利用这一成功，并基于现有最先进的基于模型和元强化学习方法的元素，提出了一种新的基于模型的元强化学习方法。我们展示了我们的方法在常见元强化学习基准领域的有效性，以更好的样本效率（高达 15 倍）获得更大的回报，同时只需要很少的超参数调整。此外，我们还在一系列更具挑战性、更高维度的领域验证了我们的方法，向现实世界的泛化智能体迈出了一步。]]></description>
      <guid>https://arxiv.org/abs/2403.09859</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>覆盖范围有限的混合强化学习在线算法的自然扩展</title>
      <link>https://arxiv.org/abs/2403.09701</link>
      <description><![CDATA[arXiv:2403.09701v1 公告类型：新
摘要：利用在线和离线数据的混合强化学习（RL）最近引起了人们的兴趣，但对其可证明的好处的研究仍然很少。此外，许多现有的混合强化学习算法（Song et al., 2023；Nakamoto et al., 2023；Amortila et al., 2024）对离线数据集施加了覆盖假设，但我们证明这是不必要的。一个精心设计的在线算法应该“填补离线数据集中的空白”，探索行为策略没有探索的状态和动作。与之前专注于估计离线数据分布以指导在线探索的方法不同（Li et al., 2023b），我们展示了标准乐观在线算法的自然扩展——通过将离线数据集包含在体验回放中来热启动它们buffer——即使离线数据集不具有单策略集中性，也能从混合数据中获得类似的可证明的收益。我们通过将状态-动作空间分为两部分来实现这一点，通过离线和在线复杂性度量来限制每个分区上的遗憾，并表明这种混合 RL 算法的遗憾可以通过最佳分区来表征——尽管该算法不知道分区本身。作为一个例子，我们提出了 DISC-GOLF，这是对现有乐观在线算法的修改，具有通用函数逼近，称为 GOLF，在 Jin 等人中使用。 （2021）；谢等人。 (2022a)，并表明它比仅在线和仅离线强化学习表现出可证明的收益，在专门用于表格、线性和块 MDP 情况时具有竞争界限。数值模拟进一步验证了我们的理论，即混合数据有助于更有效的探索，支持混合强化学习在各种场景中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.09701</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>通过多个时间池的选择实现多元化视角学习</title>
      <link>https://arxiv.org/abs/2403.09749</link>
      <description><![CDATA[arXiv:2403.09749v1 公告类型：新
摘要：在时间序列分类（TSC）中，提出了考虑顺序信息的时间池方法。然而，我们发现每个时间池都有独特的机制，并且可以根据时间序列数据表现得更好或更差。我们将这种固定池化机制称为时间池化的单一视角。在本文中，我们提出了一种具有不同视角学习的新颖时间池方法：多重时间池选择（SoM-TP）。 SoM-TP通过注意力为每个数据动态选择多种方法中的最佳时间池。动态池选择的动机是多重选择学习（MCL）的集成概念，它在多个输出中选择最好的。 SoM-TP 注意力的池化选择可以在单个分类器内实现非迭代池化集成。此外，我们定义了视角损失和多元化视角学习网络（DPLN）。损失作为正则化器来反映 DPLN 的所有池化观点。我们使用分层相关性传播（LRP）进行视角分析揭示了单一视角的局限性，并最终证明了 SoM-TP 的多样化视角学习。我们还表明，SoM-TP 优于基于其他时间池的 CNN 模型以及具有广泛 UCR/UEA 存储库的 TSC 中最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2403.09749</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:44 GMT</pubDate>
    </item>
    </channel>
</rss>