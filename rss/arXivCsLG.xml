<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Mon, 26 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>可验证的提升树集成</title>
      <link>https://arxiv.org/abs/2402.14988</link>
      <description><![CDATA[arXiv:2402.14988v1 公告类型：新
摘要：可验证学习提倡训练能够进行有效安全验证的机器学习模型。先前的研究表明，特定类别的决策树集成（称为大范围集成）允许在多项式时间内针对任何基于规范的攻击者进行鲁棒性验证。这项研究将之前的可验证学习工作从基本集成方法（即硬性多数投票）扩展到高级增强树集成，例如使用 XGBoost 或 LightGBM 训练的集成。我们的正式结果表明，当考虑基于 $L_\infty$-范数的攻击者时，鲁棒性验证可以在多项式时间内实现，但对于其他基于范数的攻击者来说仍然是 NP 困难的。尽管如此，我们提出了一种伪多项式时间算法，用于基于任何 $p \in \mathbb{N} \cup \{0\}$ 的 $L_p$-范数来验证针对攻击者的鲁棒性，这在实践中提供了出色的性能。我们的实验评估表明，大范围增强的集成对于实际采用来说足够准确，同时能够进行有效的安全验证。]]></description>
      <guid>https://arxiv.org/abs/2402.14988</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>针对人类偏好优化语言模型是一个因果推理问题</title>
      <link>https://arxiv.org/abs/2402.14979</link>
      <description><![CDATA[arXiv:2402.14979v1 公告类型：新
摘要：随着大型语言模型（LLM）在学术和商业环境中得到越来越多的应用，人们对允许语言模型生成符合人类偏好的文本的方法越来越感兴趣。在本文中，我们对来自直接结果数据集的人类偏好的语言模型优化进行了初步探索，其中每个样本都由文本和衡量读者反应的相关数字结果组成。我们首先提出，语言模型优化应该被视为因果问题，以确保模型正确地学习文本和结果之间的关系。我们形式化了这个因果语言优化问题，并开发了一种方法——因果偏好优化（CPO）——来解决该问题的无偏代理目标。我们用双重稳健的 CPO (DR-CPO) 进一步扩展了 CPO，这减少了替代目标的方差，同时保留了可证明的对偏差的强有力保证。最后，我们凭经验证明了 (DR-)CPO 在针对直接结果数据的人类偏好优化最先进的法学硕士方面的有效性，并验证了 DR-CPO 在困难的混杂条件下的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2402.14979</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>通过联邦学习增强隐私的协作信息共享——以保险行业为例</title>
      <link>https://arxiv.org/abs/2402.14983</link>
      <description><![CDATA[arXiv:2402.14983v1 公告类型：新
摘要：该报告展示了利用联邦学习 (FL) 的价值来学习跨多个保险行业数据集的单一模型的好处（在改进的索赔损失建模方面），而无需将数据集本身从一家公司共享到另一家公司。 FL 的应用解决了两个最紧迫的问题：有限的数据量和数据多样性，这是由隐私问题、索赔事件的稀有性、缺乏信息性评级因素等引起的。在每一轮 FL 中，合作者都会计算使用本地私有数据改进模型，并将这些见解结合起来更新全局模型。与每个合作者单独训练的模型相比，这种见解的聚合可以提高预测索赔损失的有效性。至关重要的是，这种方法可以实现机器学习协作，而无需原始数据离开每个数据所有者的计算基础设施。此外，我们实验中使用的开源框架 OpenFL 的设计使其可以使用机密计算运行，并具有额外的算法保护，防止通过共享模型更新泄露信息。通过这种方式，FL 被实现为一种增强隐私的协作学习技术，解决了传统机器学习解决方案中数据的敏感性和隐私带来的挑战。本文对 FL 的应用还可以扩展到其他领域，包括欺诈检测、灾难建模等，这些领域也需要将数据隐私纳入机器学习协作中。我们的框架和实证结果为保险公司、监管机构、学术研究人员和保险科技专家之间的未来合作奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2402.14983</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>SoK：分析对抗性例子：研究对手知识的框架</title>
      <link>https://arxiv.org/abs/2402.14937</link>
      <description><![CDATA[arXiv:2402.14937v1 公告类型：新
摘要：对抗性示例是机器学习模型的恶意输入，会触发错误分类。这种类型的攻击已经被研究了近十年，我们发现在发起攻击时缺乏对对手知识的研究和形式化。这产生了一个复杂的攻击研究领域，其中的威胁模型和攻击难以比较。我们专注于图像分类领域，并提供一个理论框架来研究受顺序理论启发的对手知识。我们提出了一个受加密游戏启发的对抗性示例游戏，以标准化攻击。我们调查了图像分类领域最近的攻击，并在我们的框架中对对手的知识进行了分类。通过这种系统化，我们编制的结果既证实了对手知识的现有信念，例如有关受攻击模型的信息的效力，又使我们能够得出与白盒和可转移威胁模型相关的难度的新结论，例如例如，可转移攻击可能并不像以前想象的那么困难。]]></description>
      <guid>https://arxiv.org/abs/2402.14937</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:08 GMT</pubDate>
    </item>
    <item>
      <title>利用 AI 变压器模型增强电能质量事件分类</title>
      <link>https://arxiv.org/abs/2402.14949</link>
      <description><![CDATA[arXiv:2402.14949v1 公告类型：新
摘要：最近，人们对利用机器学习对电能质量事件（PQE）进行准确分类越来越感兴趣。然而，大多数这些研究都是在假设理想情况下进行的，而实际上，我们可以测量噪声、直流偏移以及电压信号幅度和频率的变化。基于之前使用深度学习的 PQE 分类工作，本文提出了一种深度学习框架，利用支持注意力的 Transformer 作为工具，在上述考虑因素下对 PQE 进行准确分类。所提出的框架可以直接对电压信号进行操作，无需单独的特征提取或计算阶段。我们的结果表明，所提出的框架优于最近提出的基于学习的技术。它可以在上述条件下对 PQE 进行准确分类，准确度在 99.81%-91.43% 之间变化，具体取决于信噪比、直流偏移以及信号幅度和频率的变化。]]></description>
      <guid>https://arxiv.org/abs/2402.14949</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:08 GMT</pubDate>
    </item>
    <item>
      <title>Boosting 得到了关系学习的充分关注</title>
      <link>https://arxiv.org/abs/2402.14926</link>
      <description><![CDATA[arXiv:2402.14926v1 公告类型：新
摘要：在基准监督机器学习中，表格数据通常是扁平的，即由单个 $m \times d$ （行、列）文件组成，但在现实世界中，观察结果由一组表描述的情况比比皆是与结构关系。基于神经网络的深度模型是结合描述特征（像素、单词等）之间一般拓扑依赖性的经典方法，但它们与表格数据上基于树的模型的次优性仍然有充分的记录。在本文中，我们介绍了一种针对结构化数据的注意力机制，该机制在（梯度）提升的训练环境中与基于树的模型很好地融合。每个聚合模型都是一棵树，其训练涉及两个步骤：首先，以自上而下的方式学习简单的表格模型，并使用表特征上的 boosting 类残差来学习降序表。其次，所学到的内容通过注意力和聚合机制自下而上地进行，逐步构建新的特征，最终完成观察特征集的学习，在这些特征上学习单个树，增加Boosting的迭代时钟并计算新的类残差。模拟和现实世界领域的实验显示了我们的方法相对于包含基于树和基于神经网络的模型的最先进技术的竞争力。]]></description>
      <guid>https://arxiv.org/abs/2402.14926</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>无法触及敏感群体的联邦公平</title>
      <link>https://arxiv.org/abs/2402.14929</link>
      <description><![CDATA[arXiv:2402.14929v1 公告类型：新
摘要：当前联邦学习中群体公平的方法假设训练期间存在预定义和标记的敏感群体。然而，由于从新兴法规到受保护群体的动态和位置依赖性等因素，这种假设在许多现实场景中可能不合适。在这项工作中，我们提出了一种保证群体公平性的新方法，该方法不依赖于敏感群体或附加标签的任何预定义定义。我们的目标使联盟能够学习帕累托有效的全局模型，确保最坏情况下的群体公平性，并且它可以通过单个超参数在公平性和效用之间进行权衡，仅受到群体规模的限制。这意味着任何足够大的群体子集都保证从模型中获得至少最低水平的效用性能。拟议的目标包含作为特殊情况的现有方法，例如集中式机器学习的经验风险最小化和子组稳健性目标。我们提供了一种算法来解决联邦中的这个问题，该算法具有收敛性和超额风险保证。我们的实证结果表明，所提出的方法可以有效地改善可能存在的表现最差的群体，而不会不必要地损害平均表现，表现出优于或与相关基线相当的表现，并实现了具有不同公平性-效用贸易的大量解决方案-关闭。]]></description>
      <guid>https://arxiv.org/abs/2402.14929</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>MobileLLM：针对设备上用例优化数十亿参数语言模型</title>
      <link>https://arxiv.org/abs/2402.14905</link>
      <description><![CDATA[arXiv:2402.14905v1 公告类型：新
摘要：本文解决了由于云成本和延迟问题不断增加而导致的移动设备上对高效大型语言模型 (LLM) 日益增长的需求。我们专注于设计参数少于十亿的高质量 LLM，这是移动部署的实用选择。与强调数据和参数数量在确定模型质量方面发挥关键作用的普遍看法相反，我们的调查强调了模型架构对于数十亿规模的法学硕士的重要性。利用深而薄的架构，加上嵌入共享和分组查询注意机制，我们建立了一个强大的基线网络，称为 MobileLLM，与之前的 125M/350M 最先进技术相比，其准确率显着提高了 2.7%/4.3%楷模。此外，我们提出了一种立即按块权重共享的方法，不会增加模型大小，只有边际延迟开销。所得模型表示为 MobileLLM-LS，其精度比 MobileLLM 125M/350M 进一步提高了 0.7%/0.8%。此外，与之前的数十亿级模型相比，MobileLLM 模型系列在聊天基准测试中显示出显着改进，并在 API 调用任务中展示了与 LLaMA-v2 7B 接近的正确性，突出了小型模型针对常见设备上用例的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.14905</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:06 GMT</pubDate>
    </item>
    <item>
      <title>预训练模型知识蒸馏的实用见解</title>
      <link>https://arxiv.org/abs/2402.14922</link>
      <description><![CDATA[arXiv:2402.14922v1 公告类型：新
摘要：本研究研究了预训练模型中知识蒸馏（KD）过程的增强，这是知识转移的一个新兴领域，对分布式训练和联邦学习环境具有重大影响。这些环境受益于通信需求的减少并适应各种模型架构。尽管采用了多种 KD 方法在预训练模型之间传输知识，但仍缺乏对 KD 在这些场景中的应用的全面理解。我们的研究对多种 KD 技术进行了广泛的比较，包括标准 KD、调整 KD（通过优化温度和重量参数）、深度互学习和数据分区 KD。我们跨各种数据分发策略评估这些方法，以确定每种策略最有效的环境。通过对超参数调整的详细检查，并根据广泛的网格搜索评估，我们查明何时调整对于增强模型性能至关重要。本文阐明了不同数据分区场景的最佳超参数设置，并研究了 KD 在通过最小化通信次数和加快训练过程来改进联邦学习方面的作用。通过填补当前研究中的一个显着空白，我们的研究结果可以作为在协作和联合学习框架内的预训练模型中利用 KD 的实用框架。]]></description>
      <guid>https://arxiv.org/abs/2402.14922</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:06 GMT</pubDate>
    </item>
    <item>
      <title>应用强化学习来优化交通灯周期</title>
      <link>https://arxiv.org/abs/2402.14886</link>
      <description><![CDATA[arXiv:2402.14886v1 公告类型：新
摘要：交通灯周期的手动优化是一项复杂且耗时的任务，需要开发自动化解决方案。在本文中，我们提出应用强化学习来实时优化交通灯循环。我们提出了一个使用模拟城市交通模拟器来训练深度 Q 网络算法的案例研究。实验结果显示，紧急停车的平均数量减少了 44.16%，显示了我们的方法在减少交通拥堵和改善交通流量方面的潜力。此外，我们讨论了强化学习模型的未来研究和增强的途径。]]></description>
      <guid>https://arxiv.org/abs/2402.14886</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:05 GMT</pubDate>
    </item>
    <item>
      <title>采用基于语义相似性的图结构进行模型训练的高效数据选择</title>
      <link>https://arxiv.org/abs/2402.14888</link>
      <description><![CDATA[arXiv:2402.14888v1 公告类型：新
摘要：自然语言处理（NLP）的最新发展凸显了模型准确捕获文本信息需要大量数据。这引起了人们对训练此类模型所需的计算资源和时间的担忧。本文介绍了模型性能估计（SeSaME）中数据显着性的语义。它是一种仅基于文本信息的高效数据采样机制，无需通过计算量大的模型或其他密集的预处理转换来传递数据。这种方法的应用在低资源自动语音识别 (ASR) 模型的用例中得到了证明，该模型在使用增强数据时过度依赖文本到语音 (TTS) 调用。 SeSaME 通过消息传递，使用基于语义相似性的图结构和来自同源邻域的离散 ASR 信息，学习将新输入的数据点分类到语音识别难度桶中。结果表明，ASR 性能的预测是可靠的，与随机预测相比，使用所提出的方法时准确度提高了 93%，为语音模型中文本表示的影响提供了重要的信息。此外，一系列实验展示了使用传入数据的 ASR 信息来微调模型的好处和挑战。我们报告，与随机抽样相比，验证损失下降了 7%，在针对高度困难的数据集进行评估时，使用非本地聚合的 WER 下降了 7%，使用本地聚合和数据集之间的高语义相似性时，WER 下降了 1.8%。]]></description>
      <guid>https://arxiv.org/abs/2402.14888</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:05 GMT</pubDate>
    </item>
    <item>
      <title>使用内存学习训练人工智能系统的能源效率限制</title>
      <link>https://arxiv.org/abs/2402.14878</link>
      <description><![CDATA[arXiv:2402.14878v1 公告类型：新
摘要：内存学习（LIM）是最近提出的一种范式，用于克服训练机器学习系统中的基本内存瓶颈。虽然内存计算 (CIM) 方法可以解决所谓的内存墙问题（即由于重复的内存读取访问而消耗的能量），但它们对于训练所需的精度（即由于重复的内存写入而消耗的能量）是不可知的（更新墙），并且它们没有考虑在短期和长期记忆（巩固墙）之间传输信息时消耗的能量。 LIM 范式提出，如果物理记忆的能量势垒被自适应调节，使得记忆更新和巩固的动态与人工智能模型梯度下降训练的李亚普诺夫动态相匹配，那么这些瓶颈也可以被克服。在本文中，我们在使用不同的 LIM 方法训练 AI 系统时得出了新的能量耗散理论下限。这里提出的分析与模型无关，并强调了能源效率和训练速度之间的权衡。由此产生的非平衡能量效率边界与兰道尔能量耗散边界具有相似的风格。我们还通过考虑用于训练的浮点运算 (FLOP) 数量、AI 模型的大小以及训练参数的精度来扩展这些限制。我们的预测表明，使用 LIM 训练大脑规模 AI 系统（由 $10^{15}$ 参数组成）的能量耗散下限为 $10^8 \sim 10^9$ 焦耳，这与Landauer 的绝热下限和 6 美元到 7 美元的数量级比使用最先进的 AI 加速器硬件下限获得的预测低。]]></description>
      <guid>https://arxiv.org/abs/2402.14878</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>基于深度生成模型的目标条件四杆连杆机构综合</title>
      <link>https://arxiv.org/abs/2402.14882</link>
      <description><![CDATA[arXiv:2402.14882v1 公告类型：新
摘要：机构是设计用于在各种机械系统中执行特定任务的重要组件。然而，设计一种满足某些运动学或准静态要求的机构是一项具有挑战性的任务。运动学要求可能包括机构的工作空间，而机构的准静态要求可能包括其扭矩传递，扭矩传递是指机构有效传递动力和扭矩的能力。在本文中，我们提出了一种基于深度学习的生成模型，用于生成满足上述运动学和准静态要求的多个曲柄摇杆四杆连杆机构。所提出的模型基于条件生成对抗网络（cGAN），并对机制合成进行了修改，该模型经过训练以学习机制要求与链接长度之间的关系。结果表明，所提出的模型成功生成了满足特定运动学和准静态要求的多个不同机制。为了评估我们方法的新颖性，我们对所提出的 cGAN、传统 cVAE 和 NSGA-II 合成的样本进行了比较。与传统的设计方法相比，我们的方法有几个优点。它使设计人员能够在探索大型设计空间的同时，高效地生成多个多样化且可行的设计候选方案。此外，所提出的模型考虑了运动学和准静态要求，这可以为实际使用带来更高效和有效的机制，使其成为连杆机构设计的有前途的工具。]]></description>
      <guid>https://arxiv.org/abs/2402.14882</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>CloudNine：使用可解释图神经网络分析气象观测对天气预报的影响</title>
      <link>https://arxiv.org/abs/2402.14861</link>
      <description><![CDATA[arXiv:2402.14861v1 公告类型：新
摘要： 气象观测对天气预报的影响因传感器类型、位置、时间和其他环境因素而异。因此，观测影响的定量分析对于天气预报系统的有效和高效开发至关重要。然而，现有的影响分析方法由于对特定预测系统的高度依赖而难以广泛应用。此外，它们无法提供多个时空尺度的观测影响，只能提供观测类型的全局影响。为了解决这些问题，我们提出了一个名为“CloudNine”的新颖系统，它允许基于可解释的图神经网络（XGNN）分析个体观察对特定预测的影响。将基于 XGNN 的大气状态估计模型与数值天气预报模型相结合，我们提供了一个 Web 应用程序来搜索地球系统 3D 空间中的观测结果，并可视化单个观测结果对特定空间区域和时间段内的预测的影响。]]></description>
      <guid>https://arxiv.org/abs/2402.14861</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>APTQ：大型语言模型的注意力感知训练后混合精度量化</title>
      <link>https://arxiv.org/abs/2402.14866</link>
      <description><![CDATA[arXiv:2402.14866v1 公告类型：新
摘要：大型语言模型（LLM）极大地推进了自然语言处理范式。然而，高计算负载和巨大的模型尺寸对边缘设备上的部署提出了巨大的挑战。为此，我们提出了LLM的APTQ（Attention-aware Post-Training Mixed-Precision Quantization），它不仅考虑了每层权重的二阶信息，而且首次考虑了注意力输出的非线性效应在整个模型上。我们利用 Hessian 迹作为混合精度量化的灵敏度指标，确保在保持模型性能的同时进行明智的精度降低。实验表明，APTQ 超越了以前的量化方法，实现了平均 4 位宽度和 5.22 的困惑度，几乎相当于 C4 数据集中的全精度。此外，APTQ 在 LLaMa-7B 和 LLaMa-13B 中分别以 3.8 的平均位宽实现了最先进的零样本精度 68.24% 和 70.48%，证明了其产生高质量量化结果的有效性。法学硕士。]]></description>
      <guid>https://arxiv.org/abs/2402.14866</guid>
      <pubDate>Mon, 26 Feb 2024 06:18:03 GMT</pubDate>
    </item>
    </channel>
</rss>