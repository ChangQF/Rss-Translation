<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Thu, 29 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>常规收集的多变量 ICU 生理信号中常见潜在表征的协作学习</title>
      <link>https://arxiv.org/abs/2402.17917</link>
      <description><![CDATA[arXiv:2402.17917v1 公告类型：新
摘要：在重症监护病房 (ICU) 中，丰富的多变量时间序列为机器学习 (ML) 增强患者表型分析提供了机会。与之前专注于电子健康记录 (EHR) 的研究相比，我们在这里提出了一种使用常规收集的生理时间序列数据进行表型分析的 ML 方法。我们的新算法将长短期记忆 (LSTM) 网络与协作过滤概念相结合，以识别患者的常见生理状态。通过对脑损伤患者颅内高压 (IH) 检测的真实 ICU 临床数据进行测试，我们的方法实现了 0.889 的曲线下面积 (AUC) 和 0.725 的平均精度 (AP)。此外，我们的算法在学习生理信号的更结构化的潜在表示方面优于自动编码器。这些发现凸显了我们的患者表型分析方法的前景，利用常规收集的多变量时间序列来改善临床护理实践。]]></description>
      <guid>https://arxiv.org/abs/2402.17917</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>使用图神经网络预测当地文化</title>
      <link>https://arxiv.org/abs/2402.17905</link>
      <description><![CDATA[arXiv:2402.17905v1 公告类型：新
摘要：城市研究长期以来认识到社区是动态的和相关的。然而，数据、方法论和计算机处理能力的缺乏阻碍了对邻里关系动态的正式定量研究。为了在这个问题上取得进展，本研究提出了一种图神经网络（GNN）方法，该方法允许组合和评估有关社区内部特征、过去特征以及社区之间群体流动的多个信息源，从而有可能在以下方面提供更大的表达能力：预测模型。通过探索 Yelp 的公共大规模数据集，我们展示了我们的方法在预测邻里属性（特别是预测当地文化）时考虑结构连通性的潜力。从实质性和方法论的角度来看，结果都是有希望的。实质上，我们发现当地信息（例如地区人口统计）或群体概况（Yelp 评论者的口味）在预测当地文化方面给出了最佳结果，并且它们在所有研究案例中几乎是相同的。从方法上讲，在寻找特定区域的本地信息具有挑战性的情况下，探索群体概况可能是一种有用的替代方案，因为它们可以从多种形式的在线数据中自动提取。因此，我们的方法可以使研究人员和政策制定者在缺乏其他当地信息时能够使用一系列数据源。]]></description>
      <guid>https://arxiv.org/abs/2402.17905</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>多重图中的表示学习：在哪里以及如何融合信息？</title>
      <link>https://arxiv.org/abs/2402.17906</link>
      <description><![CDATA[arXiv:2402.17906v1 公告类型：新
摘要：近年来，无监督和自监督图表示学习在研究界越来越受欢迎。然而，大多数提出的方法都集中在同质网络上，而现实世界的图通常包含多个节点和边类型。多重图是一种特殊类型的异构图，拥有更丰富的信息，提供更好的建模功能并集成来自潜在不同来源的更详细的数据。多重图中不同的边类型为表示学习的底层过程提供了更多的背景和见解。在本文中，我们以无监督或自监督的方式解决了多路网络中节点的学习表示问题。为此，我们探索在图处理管道的不同级别上执行的各种信息融合方案。对各种场景的详细分析和实验评估启发我们提出如何构建处理多重图的 GNN 架构的改进方案。]]></description>
      <guid>https://arxiv.org/abs/2402.17906</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>从逆向优化到可行性再到 ERM</title>
      <link>https://arxiv.org/abs/2402.17890</link>
      <description><![CDATA[arXiv:2402.17890v1 公告类型：新
摘要：逆优化涉及从已知解推断优化问题的未知参数，广泛应用于交通、电力系统和医疗保健等领域。我们研究了上下文逆优化设置，该设置利用附加上下文信息来更好地预测未知问题参数。我们专注于上下文逆线性规划（CILP），解决 LP 的不可微性质带来的挑战。对于线性预测模型，我们将 CILP 简化为凸可行性问题，允许使用标准算法，例如交替投影。 CILP 的最终算法配备了线性收敛保证，无需额外的假设，例如简并性或插值。接下来，我们在满足 Polyak-Lojasiewicz 条件的平滑凸损失上将 CILP 简化为经验风险最小化 (ERM)。这种减少使得能够使用可扩展的一阶优化方法来解决大型非凸问题，同时保持凸设置中的理论保证。最后，我们通过实验验证了我们对合成问题和现实世界问题的方法，并证明了与现有方法相比性能的改进。]]></description>
      <guid>https://arxiv.org/abs/2402.17890</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>用于块稀疏化的 SequentialAttention++：可微剪枝满足组合优化</title>
      <link>https://arxiv.org/abs/2402.17902</link>
      <description><![CDATA[arXiv:2402.17902v1 公告类型：新
摘要：神经网络修剪是设计大型但可扩展、可解释和可泛化模型的关键技术。该主题的先前工作主要沿着两个正交方向发展：（1）可微剪枝，用于有效且准确地对参数的重要性进行评分；（2）组合优化，用于在稀疏模型空间上进行有效搜索。我们在理论和经验上结合这​​两种方法，为结构化神经网络修剪产生一个连贯的框架，其中可微修剪指导组合优化算法选择最重要的稀疏参数集。理论上，我们展示了有多少现有的可微剪枝技术可以被理解为组稀疏优化的非凸正则化，并证明对于一大类非凸正则化器，全局最优是唯一的、组稀疏的，并且可以证明产生一个近似解稀疏凸优化问题。我们提出的最终算法 SequentialAttention++ 推进了 ImageNet 和 Criteo 数据集上大规模神经网络分块修剪任务的最新技术。]]></description>
      <guid>https://arxiv.org/abs/2402.17902</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>受限马尔可夫势博弈中的自主学习</title>
      <link>https://arxiv.org/abs/2402.17885</link>
      <description><![CDATA[arXiv:2402.17885v1 公告类型：新
摘要：约束马尔可夫博弈为建模多智能体强化学习问题提供了一个正式的数学框架，其中智能体的行为受到约束。在这项工作中，我们重点关注最近引入的一类约束马尔可夫势博弈。虽然已经提出了集中式算法来解决此类受限博弈，但针对受限环境定制的收敛独立学习算法的设计仍然是一个悬而未决的问题。我们提出了一种独立的策略梯度算法，用于学习近似约束纳什均衡：每个代理观察自己的行为和奖励，以及共享状态。受优化文献的启发，我们的算法执行使用正则化约束集增强的近端点更新。使用随机切换梯度算法不精确地求解每个近端步骤。值得注意的是，我们的算法可以独立实现，无需需要轮流代理更新的集中协调机制。在某些技术约束条件下，我们建立了对约束近似纳什均衡的收敛保证。我们进行模拟来说明我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2402.17885</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ConjNorm：用于分布外检测的易于处理的密度估计</title>
      <link>https://arxiv.org/abs/2402.17888</link>
      <description><![CDATA[arXiv:2402.17888v1 公告类型：新
摘要：事后分布外（OOD）检测在可靠的机器学习中引起了广泛关注。许多努力致力于基于逻辑、距离或严格的数据分布假设来推导评分函数，以识别低分 OOD 样本。然而，这些估计分数可能无法准确反映真实的数据密度或施加不切实际的限制。为了提供基于密度的评分设计的统一视角，我们提出了一种基于布雷格曼散度的新颖理论框架，它将分布考虑因素扩展到涵盖指数分布族。利用定理中揭示的共轭约束，我们引入了 \textsc{ConjNorm} 方法，将密度函数设计重新定义为针对给定数据集搜索最佳范数系数 $p$。鉴于归一化的计算挑战，我们使用基于蒙特卡罗的重要性采样技术设计了一种无偏且分析上易于处理的配分函数估计器。跨 OOD 检测基准的大量实验凭经验证明，我们提出的 \textsc{ConjNorm} 在各种 OOD 检测设置中建立了新的最先进技术，比当前最佳方法高出 13.25$\%$ 和 28.19分别在 CIFAR-100 和 ImageNet-1K 上$\%$ (FPR95)。]]></description>
      <guid>https://arxiv.org/abs/2402.17888</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的预测驱动排序</title>
      <link>https://arxiv.org/abs/2402.17826</link>
      <description><![CDATA[arXiv:2402.17826v1 公告类型：新
摘要：大型语言模型通常根据其与人类偏好的一致程度进行排名——如果一个模型的输出更常被人类偏好，则该模型比其他模型更好。引发人类偏好的最流行方法之一是利用不同模型提供的输出与相同输入之间的成对比较。然而，由于人类收集成对比较既昂贵又耗时，因此通过强大的大型语言模型（与人类偏好密切相关的模型）收集成对比较已成为一种非常常见的做法。令人惊讶的是，从业者目前无法衡量人类和模型偏好之间的任何不匹配可能在构建的排名中引入的不确定性。在这项工作中，我们开发了一个统计框架来弥补这一差距。给定一小部分人类的成对比较和大量模型的成对比较，我们的框架为每个比较的模型提供了一个排名集——一组可能的排名位置。此外，它保证以大于或等于用户指定值的概率，排名集覆盖与人类成对偏好（的分布）一致的真实排名。我们的框架计算效率高，易于使用，并且不对人类偏好的分布或人类与强大的大语言模型之间的成对比较之间的对齐程度做出任何假设。]]></description>
      <guid>https://arxiv.org/abs/2402.17826</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>潜在神经偏微分方程求解器：偏微分方程的降阶建模框架</title>
      <link>https://arxiv.org/abs/2402.17853</link>
      <description><![CDATA[arXiv:2402.17853v1 公告类型：新
摘要：神经网络在加速偏微分方程（PDE）控制系统的数值模拟方面显示出了巨大的潜力。与许多现有的在高维离散域上运行的神经网络代理不同，我们建议以更粗糙的离散化来学习潜在空间中系统的动力学。在我们提出的框架 - 潜在神经偏微分方程求解器（LNS）中，首先训练非线性自动编码器将系统的全阶表示投影到网格缩减空间上，然后训练时间模型来预测未来状态这个网格减少的空间。这种简化过程通过大大降低伴随精细离散化的计算成本来简化时间模型的训练。我们研究了所提出的框架和其他几种流行的神经偏微分方程求解器在各种类型系统上的功能，包括单相流和多相流以及不同的系统参数。我们展示了与在全阶空间上运行的神经偏微分方程求解器相比，它具有具有竞争力的准确性和效率。]]></description>
      <guid>https://arxiv.org/abs/2402.17853</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型自动发现统计模型</title>
      <link>https://arxiv.org/abs/2402.17879</link>
      <description><![CDATA[arXiv:2402.17879v1 公告类型：新
摘要：统计模型发现涉及对受特定领域建模约束的大量模型进行具有挑战性的搜索。有效地搜索这个空间需要人类在建模和问题领域方面的专业知识。在大型语言模型（LM）的领域知识和编程能力的推动下，我们引入了一种语言模型驱动的自动统计模型发现方法。我们在 Box 循环的框架内构建我们的自动化程序：LM 在提出表示为概率程序的统计模型（充当建模者）和批评这些模型（充当领域专家）之间进行迭代。通过利用语言模型，我们不必定义特定领域的模型语言或设计手工搜索过程（这是以前系统的关键限制）。我们在概率建模的三种常见设置中评估我们的方法：在有限的模型空间内搜索、在开放式空间上搜索以及在自然语言约束下改进经典模型（例如，该模型应该可由生态学家解释）。我们的方法与以前系统的性能相匹配，识别与人类专家设计的模型相当的模型，并以可解释的方式扩展经典模型。我们的结果凸显了 LM 驱动模型发现的前景。]]></description>
      <guid>https://arxiv.org/abs/2402.17879</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络和算术电路</title>
      <link>https://arxiv.org/abs/2402.17805</link>
      <description><![CDATA[arXiv:2402.17805v1 公告类型：新
摘要：我们描述了遵循图神经网络（GNN）架构的神经网络的计算能力，不限于聚合组合 GNN 或其他特定类型。我们使用不同的激活函数和实数运算电路在 GNN 的表达能力之间建立了精确的对应关系。在我们的结果中，网络的激活函数成为电路中的门类型。我们的结果适用于所有常见激活函数的恒定深度电路和网络族，无论是均匀的还是非均匀的。]]></description>
      <guid>https://arxiv.org/abs/2402.17805</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>使用多模态先验 VAE 回归进行材料微观结构设计</title>
      <link>https://arxiv.org/abs/2402.17806</link>
      <description><![CDATA[arXiv:2402.17806v1 公告类型：新
摘要：我们提出了一种基于变分自动编码器（VAE）的模型，用于构建正向和反向结构-性质联系，这是计算材料科学中最重要的问题。我们的模型系统地将 VAE 与回归结合起来，通过以回归变量为条件的两级先验将两个模型联系起来。回归损失与变分自动编码器的重建损失联合优化，学习与属性预测和重建相关的微观结构特征。所得模型可用于正向和逆向预测，即用于预测给定微观结构的性能以及用于预测获得给定性能所需的微观结构。由于逆问题是病态的（一对多），因此我们使用多模态高斯混合推导目标函数，使模型能够推断一组目标属性的多个微观结构。我们表明，对于前向预测，我们的模型与最先进的仅前向模型一样准确。此外，我们的方法可以实现直接逆推理。我们表明，使用我们的模型推断的微观结构相当准确地实现了所需的属性，避免了昂贵的优化循环的需要。]]></description>
      <guid>https://arxiv.org/abs/2402.17806</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>DropBP：通过放弃反向传播加速大型语言模型的微调</title>
      <link>https://arxiv.org/abs/2402.17812</link>
      <description><![CDATA[arXiv:2402.17812v1 公告类型：新
摘要：训练深度神经网络通常在前向和后向传播过程中涉及大量的计算成本。传统的层丢弃技术在训练期间丢弃某些层以减少计算负担。然而，在前向传播过程中丢弃层会降低准确性，从而对训练过程产生不利影响。在本文中，我们提出了丢弃反向传播（DropBP），这是一种旨在降低计算成本同时保持准确性的新颖方法。 DropBP在后向传播过程中随机丢弃层，这不会偏离前向传播。此外，DropBP计算每一层的敏感性来分配适当的下降率，从而稳定训练过程。 DropBP 旨在通过反向传播提高训练过程的效率，从而能够使用反向传播加速完全微调和参数高效的微调。具体来说，在 QLoRA 中利用 DropBP 可减少 44% 的训练时间，将相同损失水平的收敛速度提高 1.5$\times$，并且可以在单个 NVIDIA-A100 80GiB GPU 上以大 6.2$\times$ 的序列长度进行训练在 LLaMA2-70B 中。代码可在 https://github.com/WooSunghyeon/dropbp 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.17812</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>基于压缩机的机器的时间序列分析：调查</title>
      <link>https://arxiv.org/abs/2402.17802</link>
      <description><![CDATA[arXiv:2402.17802v1 公告类型：新
摘要：在工业和住宅环境中，基于压缩机的机器（例如冰箱、暖通空调系统、热泵和冷水机组）对于满足生产和消费者的需求至关重要。传感器和物联网连接的普及支持监控系统的开发，该系统能够检测和预测故障、识别行为变化并预测机器及其组件的运行状态。本文的重点是调查最近关于故障检测、故障预测、预测和变化点检测等任务的研究，这些任务应用于表征压缩机机器运行的多变量时间序列。具体来说，故障检测检测和诊断故障，故障预测预测此类事件的发生，预测预测机器特征变量的未来值，变化点检测识别设备行为的显着变化，例如工作状态的变化。我们对上述任务的方法进行识别和分类，比较所采用的算法，突出当前技术现状的差距，并讨论该领域最有前途的未来研究方向。]]></description>
      <guid>https://arxiv.org/abs/2402.17802</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>从多变量时间序列预测机器故障：工业案例研究</title>
      <link>https://arxiv.org/abs/2402.17804</link>
      <description><![CDATA[arXiv:2402.17804v1 公告类型：新
摘要：非神经机器学习（ML）和深度学习（DL）模型通常用于预测工业维护中的系统故障。然而，只有少数研究联合评估了改变用于预测的过去数据量和预测未来的扩展的效果。本研究评估了读取窗口和预测窗口的大小对经过训练以预测三个数据集中的故障的模型性能的影响，这些数据集涉及以下操作：（1）在离散会话中工作的工业包装机，（2）连续工作的工业血液冰箱，(3)连续工作的氮气发生器。该问题被表述为二元分类任务，该任务根据在此类间隔内发生故障的概率将正标签分配给预测窗口。使用多元遥测时间序列对六种算法（逻辑回归、随机森林、支持向量机、LSTM、ConvLSTM 和 Transformers）进行比较。结果表明，在所考虑的场景中，预测窗口的维度起着至关重要的作用，并突出了 DL 方法在对故障前具有不同时间依赖模式的数据进行分类的有效性，以及 ML 方法在对相似和重复的数据进行分类时的有效性失败之前的模式。]]></description>
      <guid>https://arxiv.org/abs/2402.17804</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    </channel>
</rss>