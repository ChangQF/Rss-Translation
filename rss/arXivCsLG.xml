<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 12 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>增强后学习文本到图像生成模型的对齐</title>
      <link>https://arxiv.org/abs/2412.07808</link>
      <description><![CDATA[arXiv:2412.07808v1 公告类型：新
摘要：大规模生成模型在海量数据的推动下展现出了令人印象深刻的图像生成能力。然而，这往往会无意中导致有害或不适当内容的生成，并引发版权问题。在这些担忧的驱动下，机器学习已成为有效清除模型中不良知识的关键。虽然现有文献已经研究了各种机器学习技术，但由于这些目标的竞争性质，这些技术通常会遭受机器学习质量差或机器学习后文本图像对齐质量下降的困扰。为了应对这些挑战，我们提出了一个框架，在每次机器学习迭代中寻求最佳模型更新，确保两个目标的单调改进。我们进一步推导出这种更新的特征。
此外，我们还设计了程序来战略性地多样化机器学习和剩余数据集，以提高性能。我们的评估表明，我们的方法有效地从最近的基于扩散的生成模型中移除目标类别，并从稳定的扩散模型中移除概念，同时与模型的原始训练状态保持紧密一致，从而超越了最先进的基线。我们的代码将在 \url{https://github.com/reds-lab/Restricted_gradient_diversity_unlearning.git} 上提供。]]></description>
      <guid>https://arxiv.org/abs/2412.07808</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有注意力融合和对比学习的异构移动网络细粒度图形表示学习</title>
      <link>https://arxiv.org/abs/2412.07809</link>
      <description><![CDATA[arXiv:2412.07809v1 公告类型：新
摘要：随着即将到来的移动通信网络的复杂性不断增加，给网络运营商带来了巨大压力，人工智能对电信行业变得越来越重要。虽然越来越多的人认为智能网络自动驾驶是关键，但它在很大程度上依赖于专家经验和从网络数据中提取的知识。为了方便分析和利用无线大数据，我们将知识图谱的概念引入移动网络领域，产生了我们所说的无线数据知识图谱 (WDKG)。然而，通信网络的异构性和动态性使得手动构建 WDKG 成本过高且容易出错，这是一个根本性的挑战。在此背景下，我们提出了一个无监督的数据和模型驱动的图结构学习 (DMGSL) 框架，旨在自动优化和更新 WDKG。解决 WDKG 异构性需要将网络分层为同质层并以更细的粒度对其进行优化。此外，为了有效捕捉 WDKG 动态，我们根据相干时间将网络分割为静态快照，并利用循环神经网络的功能来整合历史信息。在已建立的 WDKG 上进行的大量实验证明了 DMGSL 优于基线，特别是在节点分类准确性方面。]]></description>
      <guid>https://arxiv.org/abs/2412.07809</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对抗性自动编码器在操作员学习中的应用</title>
      <link>https://arxiv.org/abs/2412.07811</link>
      <description><![CDATA[arXiv:2412.07811v1 公告类型：新
摘要：DeepONets 和 Koopman 自动编码器是两种流行的神经运算符架构。这些架构是自动编码器。对自动编码器的对抗性添加提高了自动编码器在机器学习各个领域的性能。本文研究了对抗性添加对这两种神经运算符架构的使用。]]></description>
      <guid>https://arxiv.org/abs/2412.07811</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动分子专利侵权评估智能系统</title>
      <link>https://arxiv.org/abs/2412.07819</link>
      <description><![CDATA[arXiv:2412.07819v1 公告类型：新
摘要：自动化药物发现通过用机器驱动的流程取代劳动密集型的人工工作流程，为加速新型疗法的开发提供了巨大的潜力。然而，当前的自动化框架无法评估新设计的分子是否侵犯了现有专利，这是一个关键的瓶颈，这带来了重大的法律和财务风险。我们推出了 PatentFinder，这是一种新型的工具增强型多代理框架，可以准确全面地评估小分子是否侵犯专利。它结合了启发式和基于模型的工具，专门针对分解子任务量身定制，包括：MarkushParser，能够对分子和 Markush 结构进行光学化学结构识别，以及 MarkushMatcher，可以增强大型语言模型准确从分子中提取取代基的能力。在我们的基准数据集 MolPatent-240 上，PatentFinder 的表现优于仅依赖大型语言模型的基线方法，F1 分数提高了 13.8%，准确率提高了 12%。实验结果表明，PatentFinder 可以减轻标签偏差，从而产生平衡的预测，并自动生成详细、可解释的专利侵权报告。这项工作不仅解决了自动药物发现中的关键挑战，还展示了将复杂的科学任务分解为专门的、工具增强的代理可管理的子任务的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.07819</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于超带的贝叶斯优化黑盒提示选择</title>
      <link>https://arxiv.org/abs/2412.07820</link>
      <description><![CDATA[arXiv:2412.07820v1 公告类型：新
摘要：最佳提示选择对于最大化下游任务中的大型语言模型 (LLM) 性能至关重要。由于最强大的模型是专有的，并且只能通过 API 调用，因此用户通常会在黑盒设置中手动优化提示，通过调整指令和少量样本示例，直到它们在验证集上获得良好的性能。最近解决静态黑盒提示选择的方法面临着重大限制：它们通常无法利用提示的固有结构，将指令和少量样本示例视为单个文本块。此外，它们通常缺乏查询效率，因为它们会评估所有验证实例上的提示，或者通过使用验证实例的随机子集冒着提示选择次优的风险。我们引入了 HbBoPs，这是一种基于超频带的新型贝叶斯优化方法，用于黑盒提示选择，解决了这些关键限制。我们的方法结合了结构感知深度核高斯过程来建模提示性能，并使用 Hyperband 作为多保真度调度程序来选择提示评估的验证实例数量。结构感知建模方法利用单独的嵌入来表示指令和少量样本，从而增强了代理模型捕获提示性能和预测下一个要以样本高效的方式评估哪个提示的能力。结合 Hyperband 作为多保真度调度程序，我们通过在不同保真度级别之间自适应地分配资源来进一步提高查询效率，同时保持提示评估的验证实例总数较低。对十个基准和三个 LLM 的广泛评估表明，HbBoP 优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.07820</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估联邦学习在玉米叶病预测中的潜力</title>
      <link>https://arxiv.org/abs/2412.07872</link>
      <description><![CDATA[arXiv:2412.07872v1 公告类型：新
摘要：基于机器学习的粮食作物疾病诊断似乎令人满意，适合大规模使用。考虑到作物叶片的图像捕获，卷积神经网络 (CNN) 在疾病预测方面表现准确，在文献中得到了广泛的增强。这些机器学习技术在数据隐私方面存在不足，因为它们需要在训练过程中与中央服务器共享数据，而无视竞争或监管问题。因此，联邦学习 (FL) 旨在支持分布式训练，以解决集中训练中公认的差距。据我们所知，本文开创了 FL 在玉米叶病中的应用和评估。我们评估了在分布式范式下训练的五个 CNN 的性能，并测量了它们的训练时间与分类性能的比较。此外，我们考虑了分布式训练的适用性，考虑了网络流量和每个 CNN 的参数数量。我们的结果表明，FL 有可能增强异构域中的数据隐私。]]></description>
      <guid>https://arxiv.org/abs/2412.07872</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用脑电图检测有害脑活动的深度学习方法的比较分析</title>
      <link>https://arxiv.org/abs/2412.07878</link>
      <description><![CDATA[arXiv:2412.07878v1 公告类型：新 
摘要：对有害脑活动（例如癫痫发作和周期性放电）的分类在神经重症监护中起着至关重要的作用，可以及时诊断和干预。脑电图 (EEG) 提供了一种监测大脑活动的非侵入性方法，但手动解释 EEG 信号非常耗时，并且严重依赖专家判断。本研究对深度学习架构进行了比较分析，包括卷积神经网络 (CNN)、视觉变换器 (ViT) 和 EEGNet，这些架构应用于使用原始 EEG 数据和通过连续小波变换 (CWT) 生成的时频表示对有害脑活动进行分类。我们使用多模态数据表示（包括高分辨率频谱图和波形数据）评估这些模型的性能，并引入多阶段训练策略来提高模型鲁棒性。我们的结果表明，训练策略、数据预处理和增强技术对于模型的成功与架构选择同样重要，其中多阶段 TinyViT 和 EfficientNet 表现出色。研究结果强调了强大的训练机制对于实现准确、高效的 EEG 分类的重要性，为在临床实践中部署 AI 模型提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.07878</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过正交归一化实现平方电路的更快边缘化</title>
      <link>https://arxiv.org/abs/2412.07883</link>
      <description><![CDATA[arXiv:2412.07883v1 公告类型：新
摘要：平方张量网络 (TN) 及其作为参数化计算图的泛化——平方电路——最近已被用作高维中的表达分布估计器。然而，平方运算在边缘化变量或计算分区函数时引入了额外的复杂性，这阻碍了它们在机器学习应用中的使用。流行 TN 的规范形式通过酉矩阵参数化，以简化特定边际的计算，但不能映射到一般电路，因为这些电路可能不对应于已知的 TN。受 TN 规范形式的启发，我们展示了如何参数化平方电路以确保它们编码已经标准化的分布。然后，我们使用这种参数化来设计一种算法来计算任何平方电路的边际，该算法比以前已知的算法更有效。最后，我们正式证明了所提出的参数化对许多电路类没有表现力损失。]]></description>
      <guid>https://arxiv.org/abs/2412.07883</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RUMC：受进化方法启发的基于规则的分类器</title>
      <link>https://arxiv.org/abs/2412.07885</link>
      <description><![CDATA[arXiv:2412.07885v1 公告类型：新
摘要：由于大量数据生成，数据分析领域迅速发展，有效的数据分类变得越来越重要。本文介绍了规则变异分类器 (RUMC)，它比规则聚合分类器 (RACER) 有了显着改进。RUMC 使用基于进化方法的创新规则变异技术来提高分类准确性。在使用来自 OpenML 和 UCI 机器学习存储库的 40 个数据集进行测试时，RUMC 的表现始终优于其他 20 个知名分类器，证明了其从复杂数据中发现有价值见解的能力。]]></description>
      <guid>https://arxiv.org/abs/2412.07885</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协议学习、分散前沿风险和无关闭问题</title>
      <link>https://arxiv.org/abs/2412.07890</link>
      <description><![CDATA[arXiv:2412.07890v1 公告类型：新
摘要：Frontier 模型目前主要通过两个渠道开发和分发：集中式专有 API 或预先训练权重的开源。我们确定了第三种范式 - 协议学习 - 其中模型在激励参与者的分散网络中进行训练。这种方法有可能比任何单个集中式实体聚集更多数量级的计算资源，从而实现前所未有的模型规模和能力。然而，它也带来了新的挑战：异构和不可靠的节点、恶意参与者、需要不可提取的模型来保留激励措施以及复杂的治理动态。到目前为止，还没有进行系统的分析来评估协议学习的可行性或相关风险，特别是由于无法单方面停止集体训练的模型而产生的“无关闭问题”。我们调查了最近的技术进步，这些进步表明分散训练可能是可行的 - 涵盖新兴的通信效率策略和容错方法 - 同时强调了仍然存在的关键未解决问题。与去中心化本质上会放大前沿风险的观点相反，我们认为，与当今的中心化体制相比，协议学习的透明度、分布式治理和民主化访问最终会降低这些风险。]]></description>
      <guid>https://arxiv.org/abs/2412.07890</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们应该如何在可解释的临床政策模型中展现历史？</title>
      <link>https://arxiv.org/abs/2412.07895</link>
      <description><![CDATA[arXiv:2412.07895v1 公告类型：新
摘要：基于观察数据的顺序临床决策建模策略对于描述治疗实践、标准化治疗中的常见模式以及评估替代策略非常有用。对于每个任务，策略模型的可解释性至关重要。学习准确的模型需要有效地捕捉患者的状态，无论是通过序列表示学习还是精心制作的病史摘要。虽然最近的研究倾向于前者，但对于可解释的策略建模，如何最好地表示历史仍然是一个问题。我们专注于模型拟合，系统地比较了总结患者病史的各种方法，以便在四个顺序决策任务中对临床政策进行可解释的建模。我们通过按患者亚组、关键状态和治疗阶段细分评估来说明使用各种表示学习到的策略的差异，强调了常见用例特有的挑战。我们发现使用学习表示的可解释序列模型在所有任务中的表现与黑盒模型相当。使用手工表示的可解释模型在完全忽略病史时表现会差很多，但通过仅纳入患者病史的少数汇总和近期元素，该模型具有竞争力。使用更丰富的表示的额外好处对于子组和特定用例而言更为明显。这强调了在预期用途背景下评估策略模型的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.07895</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变量得分变化</title>
      <link>https://arxiv.org/abs/2412.07904</link>
      <description><![CDATA[arXiv:2412.07904v1 公告类型：新 
摘要：我们推导出得分函数的一般变量变换公式，表明对于平滑、可逆变换 $\mathbf{y} = \phi(\mathbf{x})$，变换后的得分函数 $\nabla_{\mathbf{y}} \log q(\mathbf{y})$ 可以直接用 $\nabla_{\mathbf{x}} \log p(\mathbf{x})$ 来表示。利用这一结果，我们开发了两个应用：首先，我们为基于分数的扩散模型建立了逆时间 It\^o 引理，允许使用 $\nabla_{\mathbf{x}} \log p_t(\mathbf{x})$ 来反转变换空间中的 SDE，而无需直接学习 $\nabla_{\mathbf{y}} \log q_t(\mathbf{y})$。这种方法可以在一个空间中训练扩散模型，但在另一个空间中进行采样，从而有效地将正向和反向过程解耦。其次，我们引入了广义切片分数匹配，将传统的切片分数匹配从线性投影扩展到任意平滑变换。这为高维密度估计提供了更大的灵活性。我们通过在概率单纯形上的扩散中的应用来展示这些理论进步，并通过经验比较了我们的广义分数匹配方法与传统的切片分数匹配方法。]]></description>
      <guid>https://arxiv.org/abs/2412.07904</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解释和缓解对比多模态学习中的模态差距</title>
      <link>https://arxiv.org/abs/2412.07909</link>
      <description><![CDATA[arXiv:2412.07909v1 公告类型：新
摘要：多模态学习最近获得了极大的欢迎，在各种零样本分类任务以及一系列感知和生成应用中表现出色。对比语言-图像预训练 (CLIP) 等模型旨在通过对比学习来学习共享表示空间，从而桥接不同模态，例如图像和文本。尽管它们取得了成功，但多模态学习背后的工作机制尚不清楚。值得注意的是，这些模型通常表现出模态差距，其中不同模态占据共享表示空间内的不同区域。在这项工作中，我们通过表征梯度流学习动态对模态差距的出现进行了深入分析。具体而言，我们确定了不匹配的数据对和可学习的温度参数在训练期间导致和延续模态差距的关键作用。此外，我们的理论见解通过对实际 CLIP 模型的实验得到验证。这些发现为缩小模态差距提供了原则性指导，包括适当的温度安排和模态交换等策略。此外，我们还证明缩小模态差距可以提高图像文本检索等任务的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.07909</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非正态扩散模型</title>
      <link>https://arxiv.org/abs/2412.07935</link>
      <description><![CDATA[arXiv:2412.07935v1 公告类型：新
摘要：扩散模型通过逐步反转将数据变成噪声的过程来生成样本。我们表明，当步长趋近于零时，反转的过程对这些增量的分布是不变的。这揭示了扩散模型设计中以前未考虑的一个参数：扩散步骤的分布$\Delta x_k := x_{k} - x_{k + 1}$。在大多数扩散模型中，此参数默认隐式设置为正态分布。通过解除这一假设，我们概括了设计扩散模型的框架，并建立了一个扩展的扩散过程类，在训练期间使用的损失函数的选择上具有更大的灵活性。我们证明了这些模型在标准图像数据集上的密度估计和生成建模任务中的有效性，并表明对$\Delta x_k$分布的不同选择会导致生成不同质量的样本。]]></description>
      <guid>https://arxiv.org/abs/2412.07935</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根植于数据分布的神经尺度定律</title>
      <link>https://arxiv.org/abs/2412.07942</link>
      <description><![CDATA[arXiv:2412.07942v1 公告类型：新
摘要：深度神经网络表现出经验神经缩放定律，误差随着模型或数据大小的增加而呈幂律减小，适用于各种架构、任务和数据集。这种普遍性表明缩放定律可能是自然学习任务的一般性质的结果。我们开发了一个数学模型，旨在使用渗透理论描述自然数据集。出现了两种不同的临界状态，每种状态都产生最佳幂律神经缩放定律。这些状态对应于幂律分布的离散子任务和主要数据流形，可以与先前提出的神经缩放理论相关联，从而奠定和统一先前的工作。我们通过在从渗透理论模拟中得出的玩具数据集上训练回归模型来测试该理论。我们提出了定量预测语言模型缩放的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.07942</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>