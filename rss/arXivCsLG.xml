<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Mon, 07 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在噪音标签中隐藏和寻求：噪音稳定的协作积极学习，并提供LLM驱动的帮助</title>
      <link>https://arxiv.org/abs/2504.02901</link>
      <description><![CDATA[ARXIV：2504.02901V1公告类型：新 
摘要：从嘈杂的标签中学习（LNL）是一个挑战，在许多实际情况下，收集的培训数据可能包含不正确或损坏的标签。大多数现有的解决方案都确定了嘈杂的标签，并采用积极学习来查询人类专家以降级。在大型语言模型（LLMS）的时代，尽管我们可以减少人类改善这些方法的努力，但它们的性能仍可能准确地将清洁和嘈杂的样本与嘈杂的数据分开。在本文中，我们提出了一个创新的协作学习框架噪声基于积极学习，以结合LLM和小型模型（SMS），以从嘈杂的标签中学习。在协作培训期间，我们首先采用两次SMS形成共同预测网络，并提出动态增强的阈值策略，以将嘈杂的数据分为不同的子集，然后从这些子集中选择干净且嘈杂的样本，以喂养主动注释器LLMS以整流嘈杂的样品。最后，我们采用不同的优化目标来征服不同程度的标签噪声的子集。关于合成和现实世界噪声数据集的广泛实验进一步证明了我们的框架优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2504.02901</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉编码器在聊天微调期间引入的稳健识别概念</title>
      <link>https://arxiv.org/abs/2504.02922</link>
      <description><![CDATA[ARXIV：2504.02922V1公告类型：新 
摘要：模型差异是对微调如何改变模型表示和内部算法的研究。在微调过程中引入了许多感兴趣的行为，模型扩散为解释这种行为提供了有前途的镜头。交叉编码器是一种最近的模型扩散方法，它在基础和微调模型中学习了可解释的概念的共享词典，使我们能够跟踪概念在微调过程中的变化或出现。值得注意的是，先前的工作已经观察到基本模型中没有方向的概念，并且假设这些模型特定的潜在潜在是在微调过程中引入的概念。但是，我们确定了两个问题，这些问题源于跨编码器L1训练损失，这些损失可能会误导概念是微调模型所独有的，而它们确实存在于两个模型中。我们通过更准确地测量跨模型的每个潜在的存在来开发潜在缩放来标记这些问题。在比较Gemma 2 2b基础和聊天模型的实验中，我们观察到标准的交叉编码器在这些问题上遭受了巨大损失。在这些见解的基础上，我们培训了一个交叉编码器，以batchtopk的损失训练，并证明它大大减轻了这些问题，找到了更真实的聊天特定且高度可解释的概念。我们建议从业者采用类似的技术。使用batchtopk Crosscoder，我们成功地识别了一组真正的聊天特异性潜在的潜伏期，它们既可以解释又有效，代表了诸如$ \ textit {false {false Information} $和$ \ textit {persone ateys Quartion} $之类的概念，以及向不同的抗议者展示了不同抗议者的多个拒绝与不同的抗议者的偏爱。总体而言，我们的工作为基于跨编码器的模型扩散方法提供了最佳实践，并证明它可以为聊天调整如何修改语言模型行为提供具体的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.02922</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有位置编码的异质图的图形注意力</title>
      <link>https://arxiv.org/abs/2504.02938</link>
      <description><![CDATA[ARXIV：2504.02938V1公告类型：新 
摘要：图形神经网络（GNN）已成为对图形数据进行建模的事实标准，具有注意机制和变压器可显着提高其在基于图的任务上的性能。尽管取得了这些进步，但GNN在异质图上的性能通常仍然很复杂，与它们的同质对应物相比，网络的表现通常不足。这项工作基准了各种GNN体系结构，以识别异质图的最有效方法，特别关注节点分类和链接预测。我们的发现表明，图形注意力网络在这些任务中表现出色。作为主要贡献，我们通过集成节点嵌入的位置编码来探讨这些注意力网络的增强。这涉及利用完整的拉普拉斯频谱准确捕获图中每个节点的相对和绝对位置，从而进一步增强下游任务（例如节点分类和链接预测）上的性能。]]></description>
      <guid>https://arxiv.org/abs/2504.02938</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随机成对学习和自适应采样：Pac-Bayes分析</title>
      <link>https://arxiv.org/abs/2504.02957</link>
      <description><![CDATA[ARXIV：2504.02957V1公告类型：新 
摘要：我们使用数据自适应采样方案研究随机优化，以训练成对学习模型。成对学习无处不在，它涵盖了一些流行的学习任务，例如排名，度量学习和AUC最大化。来自点学习的成对学习的显着差异是输入对之间的统计依赖性，对于本文考虑的一般环境中，现有分析无法处理。为此，我们扩展了最新结果，将两个算法依赖性分析框架（算法稳定性和PAC-Bayes）融合在一起，这使我们能够处理优化器中的任何数据自适应采样方案。我们实例化该框架以分析（1）成对随机梯度下降，这是许多机器学习问题中的默认工作马，（2）成对随机梯度下降上升，这是一种在对抗训练中使用的方法。所有这些算法都利用在每个更新之前从离散分布（示例指数）中的随机采样。最近的文献已经提出了这些指数的不均匀抽样，我们的工作在光滑和非平滑凸问题方面提供了概括性保证。]]></description>
      <guid>https://arxiv.org/abs/2504.02957</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球订单Gflownets</title>
      <link>https://arxiv.org/abs/2504.02968</link>
      <description><![CDATA[ARXIV：2504.02968V1公告类型：新 
摘要：使用随机优化技术来解决复杂的多目标（MOO）黑盒优化问题，在解决复杂的多目标（MOO）黑盒优化问题方面取得了巨大成功。具体来说，可以在线培训它们，以有效地对帕累托阵线附近的各种候选人进行采样。 OP GFLOWNETS的一个关键优势是他们能够基于帕累托优势强加局部秩序训练样本，从而消除了对标量的需求 - 在其他方法中的共同需求，例如偏好条件gflownets。但是，我们确定了op gflownets的重要局限性：在培训样本上强加本地订单可能会导致相互矛盾的优化目标。为了解决这个问题，我们介绍了全球订单的Gflownets，将本地秩序转变为全球秩序，从而解决了这些冲突。我们对各种基准测试的实验评估证明了我们提出的方法的功效和希望。]]></description>
      <guid>https://arxiv.org/abs/2504.02968</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>局部定义和分布式推理：通过激活修补的概念验证机械性研究</title>
      <link>https://arxiv.org/abs/2504.02976</link>
      <description><![CDATA[ARXIV：2504.02976V1公告类型：新 
摘要：这项研究研究了通过激活补丁（CLAP）使用因果层归因（CLAP）在微调GPT-2模型中的知识表示的定位，该方法识别负责正确答案生成的关键神经层。该模型在9,958个PubMed摘要上进行了微调（癫痫：20,595个提及，脑电图：11,674次提及，癫痫发作：13,921个提及），使用两种配置具有验证损失监控，以备早停止。涉及的拍手（1）缓存清洁（正确答案）和损坏（错误的答案）激活，（2）计算logit差异以量化模型偏好，以及（3）用干净的激活修补损坏的激活以评估恢复。结果揭示了三个发现：首先，修补了第一个馈电层恢复了正确偏好的56％，表明关联知识分布在多层上。其次，修补最终输出层完全恢复了准确性（100％恢复），表明定义知识已定位。定义问题的更强的清洁logit差异进一步支持了此本地化表示。第三，从卷积层弥补（13.6％）中恢复的最小恢复表明，低水平的特征对高级推理有很小的贡献。统计分析证实了明显的层特异性效应（P &lt;0.01）。这些发现表明，事实知识是更本地化的，关联知识取决于分布式表示。我们还表明，编辑功效取决于任务类型。我们的发现不仅调解了关于模型编辑中本地化的相互矛盾的观察，而且还强调使用任务自适应技术来可靠，可解释的更新。]]></description>
      <guid>https://arxiv.org/abs/2504.02976</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过学习的自适应过滤器改善基于日志的异常检测</title>
      <link>https://arxiv.org/abs/2504.02994</link>
      <description><![CDATA[ARXIV：2504.02994V1公告类型：新 
摘要：日志消息记录重要的系统运行时信息，对于检测异常行为和管理现代软件系统非常有用。最近已经提出了许多监督和无监督的学习方法，用于基于日志的异常检测。最先进的无监督方法预测了下一个对数序列的下一个日志事件，并应用使用相同的滤波器条件的固定配置（即K，顶部K预测的日志事件是正常的下一个事件），这会导致在检测阶段中的性能较低，因为它将一个固定的固定序列设置为所有固定的k exection nog secorence，nog nog序列忽略了动态性质和不同对数序列中的动态性质和差异。最近，深入的增强学习（DRL）被广泛应用于在动态环境中做出明智的决策。在这项工作中，我们认为有必要对不同的日志序列应用自适应过滤器。为此，我们提出了一种基于DRL的新方法来构建学习的自适应滤波器，并为不同的对数序列应用不同的正常/异常滤波器阈值。我们定义了马尔可夫决策过程（MDP），并将学习的自适应过滤器作为DRL可以解决的问题。我们在两个基于日志的异常检测方法中评估了学习的自适应滤波器在两个数据集HDFS和BGL中的无监督方法和loganomaly。广泛的实验表明，我们的方法在基于日志的异常检测中的表现优于固定配置，并且在基于日志的异常检测中的性能明显更好。]]></description>
      <guid>https://arxiv.org/abs/2504.02994</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>噪音吸引的概括：对内域噪声和偏置概括的鲁棒性</title>
      <link>https://arxiv.org/abs/2504.02996</link>
      <description><![CDATA[ARXIV：2504.02996V1公告类型：新 
摘要：多源域概括（DG）旨在改善对新分布的模型鲁棒性。但是，DG方法通常会忽略标签噪声的效果，这会在训练过程中混淆模型，从而降低性能。有限的先前工作已经分析了DG方法的噪声 - 通常专注于对现有方法而不是新解决方案的分析。在本文中，我们研究了这个未经置换的空间，其中在分布偏移和标签噪声下都评估了模型，我们将其称为噪声感知的概括（NAG）。解决标签噪声的一种自然解决方案是将学习与嘈杂标签（LNL）方法与DG的方法相结合。许多LNL方法旨在检测班级样本中的分布变化，即，他们认为分布移位通常与标签噪声相对应。但是，在NAG分布中，可以归因于标签噪声或域移位，从而打破了LNL方法使用的假设。一个天真的解决方案是做出许多DG方法做出的类似假设，我们假定在训练过程中具有域标签，从而使我们能够隔离两种类型的偏移。但是，这忽略了有价值的跨域信息。具体而言，我们提出的DL4ND方法通过利用观察结果来改善噪声检测，即在单个域中可能无法区分的嘈杂样品在比较跨域时通常会显示出更大的变化。实验表明，DL4ND显着提高了四个不同数据集的性能，从而为解决NAG提供了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2504.02996</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用增强学习，变异自动编码器和主动学习的时间序列数据中的异常检测</title>
      <link>https://arxiv.org/abs/2504.02999</link>
      <description><![CDATA[ARXIV：2504.029999V1公告类型：新 
摘要：本文介绍了一种新的检测时间序列数据异常的方法。这种方法在数据中心，传感器网络和金融等领域中是关键的。传统方法通常会在手动参数调整中遇到困难，并且无法适应新的异常类型。我们的方法通过将深度加固学习（DRL）与各种自动编码器（VAE）和主动学习整合在一起来克服这些局限性。通过结合长期内存（LSTM）网络，我们的方法有效地模型的顺序数据及其依赖项模型，从而可以检测具有最小标记数据的新异常类。如我们对现实世界数据集的评估所示，我们的创新性DRL-VAE和主动学习组合可以显着改善现有方法，从而增强异常检测技术并进行推进时间序列分析。]]></description>
      <guid>https://arxiv.org/abs/2504.02999</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过以对象为中心的注意力进行深入的加强学习</title>
      <link>https://arxiv.org/abs/2504.03024</link>
      <description><![CDATA[ARXIV：2504.03024V1公告类型：新 
摘要：对原始像素输入进行培训的深入强化学习师通常无法超越其训练环境，依靠虚假的相关性和无关紧要的背景细节。为了解决这个问题，最近出现了以对象为中心的代理。但是，它们需要针对任务规格量身定制的不同表示形式。与深层代理相反，没有一个以对象为中心的架构可以应用于任何环境。受认知科学和Occam的剃须刀原则的启发，我们通过掩盖（OCCAM）引入了以对象为中心的关注，该注意力选择性地保留了与任务相关的实体，同时滤除了无关的视觉信息。具体而言，OCCAM利用以对象为中心的电感偏差。对Atari基准测试的经验评估表明，与基于常规像素的RL相比，OCCAM显着提高了对新型扰动的鲁棒性，并降低了样品复杂性，同时显示出相似或改善的性能。这些结果表明，结构化抽象可以增强概括，而无需明确的符号表示或特定于域特异性的对象提取管道。]]></description>
      <guid>https://arxiv.org/abs/2504.03024</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>安全调制：通过成本调整的奖励增强加强学习的安全性</title>
      <link>https://arxiv.org/abs/2504.03040</link>
      <description><![CDATA[ARXIV：2504.03040V1公告类型：新 
摘要：安全加强学习（安全RL）旨在训练RL代理，以最大程度地在现实世界环境中表现出色，同时遵守安全限制，因为超出安全性侵犯限制可能会导致严重的后果。在本文中，我们提出了一种称为安全调制政策优化（SMPO）的新型安全RL方法，该方法可以通过安全调制奖励在标准策略优化框架内实现安全的策略功能学习。特别是，我们将违反安全费用视为与标准奖励平行的RL环境的反馈，并引入Q-COST功能作为安全评论家，以估算预期的未来累积成本。然后，我们建议使用成本吸引力的加权功能调节奖励，该功能经过精心设计，以确保基于安全评论家的估计，同时最大程度地提高预期奖励。政策功能和安全评论家在与环境的在线互动期间通过渐变下降同时学习。我们使用多个RL环境进行实验，实验结果表明，就整体安全RL性能而言，我们的方法优于几种经典和最新的比较方法。]]></description>
      <guid>https://arxiv.org/abs/2504.03040</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM图书馆学习失败：一个乐高案例案例研究</title>
      <link>https://arxiv.org/abs/2504.03048</link>
      <description><![CDATA[ARXIV：2504.03048V1公告类型：新 
摘要：LLM的编码，推理和工具使用能力的最新进展激发了对图书馆学习的兴趣（即，通过创建，存储和检索可重复使用的可重复使用的功能，知识，清单或窃听的在线学习）。这样的系统通常通过自动创建广泛适用的工具以及通过缓存推理（即存储生成工具）来提高任务性能。但是，我们发现有力的理由是持怀疑态度。我们深入研究了一个这样的系统，即乐高流浪者，该系统声称可以学习可重复使用的数学推理引理。我们没有发现直接重复使用的诱饵的证据，也没有找到反对学到的引理的软重复使用的证据（即，通过修改相关示例来重复使用）。至关重要的是，我们发现LEGO -PROVER实际上并没有改善促使模型的简单基线 - 一旦计算计算成本，任务准确性的改善就消失了。我们的发现表明，对这些技术的有效性存在严重的误解，需要对基于LLM的图书馆学习状态进行认真的重新检查，并且我们需要更强大的评估标准来进行评估，包括行为分析并确保将同等的计算预算用于盆地。]]></description>
      <guid>https://arxiv.org/abs/2504.03048</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知的域概括自我适应</title>
      <link>https://arxiv.org/abs/2504.03064</link>
      <description><![CDATA[ARXIV：2504.03064V1公告类型：新 
摘要：域的概括旨在在源训练领域开发合适的学习算法，以便学到的模型可以很好地概括在不同的看不见的测试领域。我们提出了一种新型的两阶段方法，称为上下文感知自我适应（CASA），用于域概括。 CASA模拟了近似的元化场景，并结合了一个自动适应模块，以将预训练的元源模型调整为元目标域，同时保持其对元源域上的预测能力。自我适应的核心概念涉及利用上下文信息，例如迷你批次特征的平均值，作为域知识，可以自动调整在第一阶段训练的模型，以适应第二阶段的新上下文。最后，我们利用多个元源模型的集合在测试域上执行推断。实验结果表明，我们提出的方法在标准基准上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2504.03064</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>美国比特币钱包交易中可疑活动的基于机器学习的检测和分析</title>
      <link>https://arxiv.org/abs/2504.03092</link>
      <description><![CDATA[ARXIV：2504.03092V1公告类型：新 
摘要：在美国，比特币和其他加密货币的急剧采用彻底改变了财务格局，并提供了前所未有的投资和交易效率机会。该研究项目的主要目的是开发能够有效识别和跟踪比特币钱包交易中可疑活动的机器学习算法。通过高科技分析，该研究旨在创建一个模型，该模型具有识别可以暴露非法活动的趋势和离群值的功能。当前的研究特别关注美国的比特币交易信息，重点是了解此类交易通过和通过的重要性的重要性。该数据集由深入的比特币钱包交易信息组成，包括重要因素，例如交易值，时间戳，网络流和钱包的地址。数据集中的所有条目都揭示了有关钱包之间的财务交易的信息，包括已接收和发送交易，并且此类信息对于可以代表可疑活动的分析和趋势非常重要。这项研究部署了三种认可的算法，最著名的是逻辑回归，随机森林和支持向量机。回想起来，随机森林成为最佳F1分数的最佳模型，展示了其处理数据中非线性关系的能力。见解揭示了钱包活动中的重要模式，例如未赎回交易与最终平衡之间的相关性。机器算法在跟踪加密货币中的应用是创建透明且安全的美国市场的工具。]]></description>
      <guid>https://arxiv.org/abs/2504.03092</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过可解释的SVD进行公平回归的后处理</title>
      <link>https://arxiv.org/abs/2504.03093</link>
      <description><![CDATA[ARXIV：2504.03093V1公告类型：新 
摘要：本文介绍了一种用于培训统计奇偶校验的训练公平神经网络回归模型的后处理算法，并利用了权重矩阵的可解释的奇异价值分解（SVD）。我们提出了权重矩阵的线性转换，从而直接从转换矩阵的SVD得出的奇异值直接对应于两组输出分布的第一和第二矩中的差异。因此，我们可以将公平约束转换为对单数值的约束。我们通过分析解决了在这些约束下找到最佳权重的问题。与基线相比，各种数据集对各种数据集的实验验证表明，我们的方法实现了相似或出色的公平准确性权衡取舍，而无需在推理时使用敏感属性。]]></description>
      <guid>https://arxiv.org/abs/2504.03093</guid>
      <pubDate>Mon, 07 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>