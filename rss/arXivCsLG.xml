<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 05 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>增强型 N-BEATS 用于中期电力需求预测</title>
      <link>https://arxiv.org/abs/2412.02722</link>
      <description><![CDATA[arXiv:2412.02722v1 公告类型：新
摘要：本文介绍了一种增强型 N-BEATS 模型 N-BEATS*，用于改进中期电力负荷预测 (MTLF)。N-BEATS* 以原始 N-BEATS 架构的优势为基础，该架构擅长处理复杂的时间序列数据，而无需预处理或特定领域的知识，N-BEATS* 引入了两项关键修改。（1）一种新颖的损失函数 - 将基于 MAPE 的弹球损失与归一化 MSE 相结合，新的损失函数通过捕获 L1 和 L2 损失项来实现更平衡的方法。（2）一种改进的块架构 - 通过引入非标准化组件来调整 N-BEATS 块的内部结构，以协调不同时间序列的处理，从而实现更高效、更简单的预测任务。根据来自 35 个欧洲国家/地区的实际月度用电量数据进行评估，N-BEATS* 与其前身和其他成熟的预测方法（包括统计、机器学习和混合模型）相比表现出色。N-BEATS* 实现了最低的 MAPE 和 RMSE，同时还表现出最低的预测误差离散度。]]></description>
      <guid>https://arxiv.org/abs/2412.02722</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DYffCast：使用 IMERG 卫星数据进行区域降水预报。以南美洲为例</title>
      <link>https://arxiv.org/abs/2412.02723</link>
      <description><![CDATA[arXiv:2412.02723v1 公告类型：新
摘要：气候变化正在增加极端降水事件的频率，使洪水和山体滑坡等天气灾害更有可能发生。因此，准确预报降水的能力对于通过向决策者提供即时、准确的信息来保护社会变得更加重要。受生成模型在降水预报方面取得的最新成功的启发，本文：将 DYffusion 框架扩展到此任务并评估其在预测长达 4 小时的 IMERG 卫星降水数据方面的表现；修改 DYffusion 框架以提高其建模降雨数据的能力；并引入了一种结合 MSE、MAE 和 LPIPS 感知分数的新型损失函数。在对长达 4 小时的预测的定量评估中，使用新损失训练的修改后的 DYffusion 框架优于四个竞争模型。它对弱雨、中雨和大雨阈值的 CSI 得分最高，并且在整个发布过程中保持 LPIPS 得分 $&lt;$ 0.2，随着提前期的增加，降幅最小。所提出的即时预报模型在大雨案例研究中展示了长达 2 小时的视觉稳定和清晰的预报。代码可在 https://github.com/Dseal95/DYffcast 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.02723</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高性能计算系统上利用资源自适应连续加倍对大型数据集进行超参数优化</title>
      <link>https://arxiv.org/abs/2412.02729</link>
      <description><![CDATA[arXiv:2412.02729v1 公告类型：新
摘要：在高性能计算 (HPC) 系统上，可以并行评估多个超参数配置，以加速超参数优化 (HPO) 过程。最先进的 HPO 方法遵循基于 bandit 的方法并建立在连续减半的基础上，其中组合的最终性能是根据低于完全训练的保真度性能指标来估计的，并且随着时间的推移，更有希望的组合会分配更多资源。通常，epoch 的数量被视为一种资源，让更有希望的组合训练更长时间。另一种选择是使用工人数量作为资源，并通过数据并行训练直接将更多工人分配给更有希望的配置。本文提出了一种新颖的资源自适应连续加倍算法 (RASDA)，它将资源自适应连续加倍方案与普通异步连续减半算法 (ASHA) 相结合。该方法的可扩展性在现代 HPC 系统上最多 1,024 个图形处理单元 (GPU) 上得到体现。它应用于不同类型的神经网络 (NN)，并在计算机视觉 (CV)、计算流体动力学 (CFD) 和增材制造 (AM) 领域的大型数据集上进行训练，在这些领域中，执行多次完整的训练运行通常是不可行的。经验结果表明，在运行时间方面，RASDA 的性能比 ASHA 高出 1.9 倍。同时，RASDA 的隐式批量大小调度可以保持甚至超越最终 ASHA 模型的解决方案质量。借助 RASDA，系统性 HPO 首次在文献中应用于 TB 级科学数据集，从而能够高效优化海量科学数据上的复杂模型。RASDA 的实现可在 https://github.com/olympiquemarcel/rasda 上找到]]></description>
      <guid>https://arxiv.org/abs/2412.02729</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>钙钛矿忆阻器与稳健模拟计算算法的协同发展</title>
      <link>https://arxiv.org/abs/2412.02779</link>
      <description><![CDATA[arXiv:2412.02779v1 公告类型：新
摘要：使用非易失性忆阻器的模拟计算已成为节能深度学习的有前途的解决方案。钙钛矿基忆阻器等新材料最近因其成本效益、能源效率和灵活性而受到青睐。然而，材料多样性和不成熟制造方面的挑战需要对设备开发进行大量实验。此外，这些忆阻器中存在的重大非理想性通常会阻碍它们的计算。在这里，我们提出了一种协同方法来同时优化钙钛矿忆阻器的制造并开发强大的模拟 DNN，以有效解决这些忆阻器固有的非理想性。采用以可用性为重点的贝叶斯优化 (BO)，我们可以有效地确定钙钛矿忆阻器的最佳材料和制造条件。同时，我们开发了“BayesMulti”，这是一种利用 BO 引导噪声注入的 DNN 训练策略，以提高模拟 DNN 对忆阻器缺陷的抵抗力。我们的方法在理论上确保在由于忆阻器非理想性而导致的一定范围的参数扰动内，预测结果保持一致。我们的集成方法可以在更深、更广的网络中实现模拟计算，这在图像分类、自动驾驶、物种识别和大型视觉语言模型等各种任务中显著优于现有方法，实现了高达 100 倍的改进。我们进一步在 10$\times$10 优化的钙钛矿忆阻器交叉开关上验证了我们的方法，在分类任务中表现出高精度和低能耗。这项研究为各种模拟计算系统的高效优化提供了一种通用的解决方案，涵盖设备和算法。]]></description>
      <guid>https://arxiv.org/abs/2412.02779</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WxC-Bench：用于天气和气候下游任务的新型数据集</title>
      <link>https://arxiv.org/abs/2412.02780</link>
      <description><![CDATA[arXiv:2412.02780v1 公告类型：新 
摘要：高质量的机器学习 (ML) 就绪数据集在开发新的人工智能 (AI) 模型或微调现有模型以用于天气和气候分析等科学应用方面发挥着基础作用。不幸的是，尽管针对天气和气候的新深度学习模型不断发展，但精心策划的、预处理的机器学习 (ML) 就绪数据集却很少。策划这样的高质量数据集以开发新模型具有挑战性，特别是因为输入数据的模态对于处理不同大气尺度（空间和时间）的不同下游任务存在很大差异。在这里，我们介绍了 WxC-Bench（天气和气候台），这是一个多模态数据集，旨在支持为天气和气候研究的下游用例开发可推广的 AI 模型。WxC-Bench 被设计为用于开发复杂天气和气候系统的 ML 模型的数据集，将选定的下游任务作为机器学习现象来处理。 WxC-Bench 涵盖了从中观尺度（20 - 200 公里）到天气尺度（2500 公里）的多种大气过程，例如航空湍流、飓风强度和轨迹监测、天气模拟搜索、重力波参数化和自然语言报告生成。我们提供了数据集的全面描述，并提供了基线分析的技术验证。数据集和准备 ML 就绪数据的代码已在 Hugging Face 上公开发布 - https://huggingface.co/datasets/nasa-impact/WxC-Bench]]></description>
      <guid>https://arxiv.org/abs/2412.02780</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>地理信息对齐通过转置交叉注意力增强交通分析</title>
      <link>https://arxiv.org/abs/2412.02839</link>
      <description><![CDATA[arXiv:2412.02839v1 公告类型：新 
摘要：交通事故预测对于提高道路安全性和缓解交通拥堵至关重要，最近的图神经网络 (GNN) 在对固有的基于图的交通数据进行建模方面显示出良好的前景。然而，现有的基于 GNN 的方法往往忽视或没有明确利用地理位置信息，而地理位置信息通常在理解空间依赖性方面起着关键作用。这也与我们的观察结果一致，事故地点往往高度相关。为了解决这个问题，我们为常见的 GNN 框架提出了一个即插即用的模块，称为地理信息对齐 (GIA)。该模块可以通过一种新颖的转置交叉注意机制有效地融合节点特征和地理位置信息。由于交通数据的节点数量众多，在计算资源有限的情况下，执行节点对齐的传统交叉注意机制可能不可行。相反，我们在交叉注意机制中对查询、键和值进行转置操作，这在保持足够信息的同时大大降低了计算成本。在大型城市数据集上进行的交通发生预测和严重程度预测（基于记录的事故计数间隔的严重程度）实验结果证实了我们提出的方法的有效性。例如，我们的方法可以在 F1 得分中获得 1.3% 到 10.9% 的增益，在 AUC 中获得 0.3% 到 4.8% 的增益。]]></description>
      <guid>https://arxiv.org/abs/2412.02839</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>批量标准化分解</title>
      <link>https://arxiv.org/abs/2412.02843</link>
      <description><![CDATA[arXiv:2412.02843v1 公告类型：新
摘要：\emph{批量归一化} 是神经网络架构的成功构建块。然而，人们对它的理解还不够深入。具有批量归一化的神经网络层包含三个影响网络诱导表示的组件：\emph{将表示的平均值重新居中} 为零，\emph{将表示的方差重新缩放} 为 1，最后应用 \emph{非线性}。我们的工作遵循 Hadi Daneshmand、Amir Joudaki 和 Francis Bach [NeurIPS~&#39;21] 的工作，他们研究了深度 \emph{线性} 神经网络，在初始化时仅在层之间进行重新缩放阶段。在我们的工作中，我们分析了具有批量归一化的网络的另外两个关键组件，即重新居中和非线性。当存在这两个组件时，我们会在初始化时观察到一种奇怪的行为。通过这些层，批次的表示会收敛到单个集群，除了一个奇怪的数据点在正交方向上远离集群。我们从两个角度阐明了这种行为：（1）我们分析了简化指示模型的几何演化；（2）我们证明了上述配置的稳定性结果。]]></description>
      <guid>https://arxiv.org/abs/2412.02843</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测量网络过滤文本数据集的偏差以及通过训练传播偏差</title>
      <link>https://arxiv.org/abs/2412.02857</link>
      <description><![CDATA[arXiv:2412.02857v1 公告类型：新
摘要：我们通过数据集分类实验研究大型语言模型 (LLM) 预训练数据集中的偏差。基于先前的工作证明流行的计算机视觉数据集中存在偏差，我们分析了从 CommonCrawl 派生的 LLM 的流行开源预训练数据集，包括 C4、RefinedWeb、DolmaCC、RedPajama-V2、FineWeb 和 DCLM-Baseline。尽管这些数据集是通过类似的过滤和重复数据删除步骤获得的，但神经网络可以出奇地好地对单个文本序列属于哪个数据集进行分类，比人类要好得多。这表明流行的预训练数据集有自己独特的偏差或指纹。即使用 LLM 重写文本，这些偏差仍然存在。此外，这些偏差会通过训练传播：在这些数据集上训练的模型生成的随机序列可以通过在原始数据集上训练的分类器很好地分类。]]></description>
      <guid>https://arxiv.org/abs/2412.02857</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号自主网络代理的分布外检测</title>
      <link>https://arxiv.org/abs/2412.02875</link>
      <description><![CDATA[arXiv:2412.02875v1 公告类型：新
摘要：网络应用的自主代理通过采用具有传统和学习功能组件的智能代理来利用现代防御技术。这些智能代理通过强化学习 (RL) 算法进行训练，可以学习、适应、推理和部署安全规则来保护联网计算机系统，同时保持关键的操作工作流程。然而，在训练期间，关于运营网络及其环境的状态的知识可能有限。代理应该是值得信赖的，这样他们才能可靠地检测到他们无法处理的情况，并将其交给网络专家。在这项工作中，我们开发了一种分布外 (OOD) 监控算法，该算法使用概率神经网络 (PNN) 来检测具有离散状态和离散动作的基于 RL 的代理的异常或 OOD 情况。为了证明所提出方法的有效性，我们将 OOD 监控算法与使用具有学习功能组件的行为树的神经符号自主网络代理相结合。我们在模拟网络环境中使用不同的对抗策略评估了所提出的方法。大量实验结果证明了我们提出的方法的整体有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.02875</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立预测模型并发现直接原因</title>
      <link>https://arxiv.org/abs/2412.02878</link>
      <description><![CDATA[arXiv:2412.02878v1 公告类型：新
摘要：我们引入了一个因果建模框架，该框架通过使用因果图来表示预测模型（例如机器学习模型）的输入输出行为。该框架使我们能够定义和识别直接导致预测的特征，这对数据收集和模型评估具有广泛的意义。我们展示了两个可以从数据中发现直接原因的假设，其中一个进一步简化了发现过程。除了提供完善的算法外，我们还提出了一种基于独立性规则的优化技术，该技术可以与算法集成，以在理论和经验上加快发现过程。]]></description>
      <guid>https://arxiv.org/abs/2412.02878</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GUESS：用于自我监督的生成不确定性集成</title>
      <link>https://arxiv.org/abs/2412.02896</link>
      <description><![CDATA[arXiv:2412.02896v1 公告类型：新
摘要：自监督学习 (SSL) 框架由借口任务和损失函数组成，旨在从未标记的数据中学习有用的一般特征。大多数 SSL 基线的基本思想都围绕着通过损失函数强制对各种数据增强的不变性。然而，一个主要问题是，对任何类型的数据增强的不变性的不注意或确定性执行通常不仅效率低下，而且可能对下游任务的性能产生不利影响。在这项工作中，我们从不变性表示中的不确定性的角度研究了这个问题。在 SSL 架构和损失函数的设计中，不确定性表示还未被充分探索。我们在损失函数和架构设计中都加入了不确定性表示，旨在实现更多依赖于数据的不变性。前者以 SSL 损失函数中数据衍生的不确定性的形式表示，从而产生生成-判别损失函数。后者是通过将略有不同的样本扭曲版本输入到集成中来实现的，目的是学习更好、更稳健的表示。具体来说，在最近使用硬白化和软白化（又称冗余减少）的方法的基础上，我们引入了一种新方法 GUESS，这是一种伪白化框架，由受控不确定性注入、新架构和新损失函数组成。我们提供了详细的结果和消融分析，将 GUESS 确立为新的基线。]]></description>
      <guid>https://arxiv.org/abs/2412.02896</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高阶 Transformer：针对张量结构化数据的有效注意力机制</title>
      <link>https://arxiv.org/abs/2412.02919</link>
      <description><![CDATA[arXiv:2412.02919v1 公告类型：新
摘要：Transformers 现在在序列建模任务中无处不在，但由于注意力机制的二次成本，将其扩展到多维数据仍然是一个挑战。在本文中，我们提出了高阶 Transformers (HOT)，这是一种新颖的架构，旨在有效处理具有两个以上轴的数据，即高阶张量。为了解决与高阶张量注意力相关的计算挑战，我们引入了一种新颖的 Kronecker 分解注意力机制，将注意力成本降低到每个轴维度的二次方，而不是输入张量总大小的二次方。为了进一步提高效率，HOT 利用核化注意力，将复杂度降低到线性。这种策略在实现可扩展注意力计算的同时保持了模型的表现力。我们在两个高维任务上验证了 HOT 的有效性，包括多元时间序列预测和 3D 医学图像分类。实验结果表明，HOT 在显著提高计算效率的同时实现了具有竞争力的性能，展示了其处理各种复杂、多维数据的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.02919</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过深度神经网络利用损失分解进行长期波浪预测</title>
      <link>https://arxiv.org/abs/2412.02924</link>
      <description><![CDATA[arXiv:2412.02924v1 公告类型：新
摘要：长期准确预测对于建模复杂的物理过程（例如波传播）至关重要。尽管深度神经网络在实时预测方面表现出色，但随着预测持续很长一段时间，它们通常会遇到相位和振幅误差累积的问题。为了解决这个问题，我们提出了一种新颖的损失分解策略，将损失分解为单独的相位和振幅分量。该技术通过明确考虑数值误差、提高稳定性和减少长期预测中的误差累积，提高了神经网络在波传播任务中的长期预测准确性。]]></description>
      <guid>https://arxiv.org/abs/2412.02924</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>逆延迟强化学习</title>
      <link>https://arxiv.org/abs/2412.02931</link>
      <description><![CDATA[arXiv:2412.02931v1 公告类型：新
摘要：逆向强化学习 (IRL) 已在各种模仿任务中证明其有效性。在本文中，我们介绍了一个 IRL 框架，旨在从受延迟干扰影响的专家轨迹中提取有益特征。我们的方法不依赖直接观察，而是采用有效的离线对抗训练框架来获取专家特征并从增强延迟观察中恢复最佳策略。在不同延迟设置下对 MuJoCo 环境进行的经验评估验证了我们方法的有效性。此外，我们提供了理论分析，表明从增强延迟观察中恢复专家策略的效果优于使用直接延迟观察。]]></description>
      <guid>https://arxiv.org/abs/2412.02931</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BGTplanner：通过战略隐私预算分配最大化差异隐私联邦推荐系统的训练准确率</title>
      <link>https://arxiv.org/abs/2412.02934</link>
      <description><![CDATA[arXiv:2412.02934v1 公告类型：新 
摘要：为了缓解人们对隐私泄露日益增长的担忧，联合推荐 (FR) 范式应运而生，其中分散的客户端共同训练推荐模型而不暴露他们的原始用户项目评分数据。差分隐私联合推荐器 (DPFR) 通过向客户端注入差分隐私 (DP) 噪声进一步增强了 FR。然而，当前的 DPFR 受到噪声失真的影响，无法达到令人满意的准确性。人们已经做出了各种努力，通过在学习过程中自适应地分配隐私预算来改进 DPFR。然而，由于隐私预算分配和模型准确性之间的复杂关系，现有的工作还远远没有最大化 DPFR 准确性。为了应对这一挑战，我们开发了 BGTplanner（预算规划器）来战略性地分配每轮 DPFR 训练的隐私预算，从而提高整体训练性能。具体来说，我们利用高斯过程回归和历史信息来预测在分配一定隐私预算的情况下推荐准确性的变化。此外，上下文多臂老虎机 (CMAB) 可用于通过协调当前改进和长期隐私约束来做出隐私预算分配决策。我们在真实数据集上进行的大量实验结果表明，与最先进的基线相比，\emph{BGTplanner} 的训练性能平均提高了 6.76\%。]]></description>
      <guid>https://arxiv.org/abs/2412.02934</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>