<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Mon, 10 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>在小语言模型中增强数学推理的自我进化的偏好优化</title>
      <link>https://arxiv.org/abs/2503.04813</link>
      <description><![CDATA[ARXIV：2503.04813V1公告类型：新 
摘要：大型语言模型（LLM）已大大提高了其推理能力；但是，由于错误传播，缺乏自我纠正以及对各种推理方式的适应性有限，他们仍然在复杂的多步数数学问题解决方案中挣扎。现有的方法依赖于静态微调或及时工程，这些方法无法跨越问题的复杂性，而高质量偏好数据的稀缺性进一步阻碍了可靠的推理。
  我们介绍了Sphere，这是一种自我不断发展的数据生成管道，通过迭代产生，纠正和多元化的推理链来增强小语言模型（SLM）的推理。 Sphere分为三个阶段：（i）自动生成，该模型自主构建解决问题的步骤； （ii）自我纠正，使其能够识别和纠正错误； （iii）多样性诱导，通过多种有效的推理轨迹改善鲁棒性。这种自我进化的机制增强了数学推理并增强了模型的可靠性。对数学500，GSM8K，AIME，AMC和奥林匹克运动会的评估表明，受球体训练的模型在其基本版本上实现了显着增长，并在某些基准测试中匹配/超过GPT-4O。我们的发现表明，自我发展的模型可以缩小SLM和最先进的LLM之间的推理差距，从而使数学AI更可靠，可扩展和高效。]]></description>
      <guid>https://arxiv.org/abs/2503.04813</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于动力学的数据科学应用程序</title>
      <link>https://arxiv.org/abs/2503.04857</link>
      <description><![CDATA[ARXIV：2503.04857V1公告类型：新 
摘要：我们提出了一种受统计力学启发的基于物理学的正规化技术。通过在优化插装器的参数之间进行类比，并最小化系统的能量，我们引入了对数据分布的低阶矩施加限制的校正。这样可以最大程度地减少数据的离散和连续体表示之间的差异，从而允许访问更有利的能量景观，从而提高了插装器的准确性。我们的方法即使在高维空间中也可以提高插值和回归任务的性能。与传统方法不同，它不需要经验参数调整，这使其对于处理嘈杂数据特别有效。我们还表明，由于其本地性质，该方法提供了比径向基础功能插值器的计算和内存效率优势，尤其是对于大型数据集。]]></description>
      <guid>https://arxiv.org/abs/2503.04857</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过变异自动编码器在复合混乱和热噪声中的分布外雷达检测</title>
      <link>https://arxiv.org/abs/2503.04861</link>
      <description><![CDATA[ARXIV：2503.04861V1公告类型：新 
摘要：本文提出了一种使用变异自动编码器（VAE）的新型雷达目标检测方法。拟议的VAE架构以学习复杂分布和识别分布外样品的能力而闻名，有效地将雷达靶标与各种噪声类型（包括相关的高斯和复合高斯杂物）区分开来，通常与加多添加的白色高斯热噪声结合在一起。仿真结果表明，所提出的VAE的表现优于经典的自适应检测器，例如匹配的过滤器和归一化匹配的过滤器，尤其是在挑战性的噪声条件下，突出了其在雷达应用中的鲁棒性和适应性。]]></description>
      <guid>https://arxiv.org/abs/2503.04861</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合的逆概率治疗对个体治疗效果估计的加权</title>
      <link>https://arxiv.org/abs/2503.04946</link>
      <description><![CDATA[ARXIV：2503.04946V1公告类型：新 
摘要：个人治疗效果（ITE）估计是评估治疗策略对某些重要结果的因果影响，这在医疗保健中是一个至关重要的问题。大多数现有的ITE估计方法都是为集中设置而设计的。但是，在现实世界中的临床方案中，由于潜在的隐私风险和安全风险，原始数据通常无法共享医院，这使得该方法不适用。在这项工作中，我们在联合环境中研究了ITE估计任务，这使我们能够利用多家医院的分散数据。由于收集的数据中不可避免的混杂偏差，直接从中学到的模型将是不准确的。一个众所周知的解决方案是逆概率治疗加权（IPTW），它使用协变量将每个训练的条件性概率重新权重。但是，在联合环境中应用IPTW是非平凡的。我们发现，即使有了充分估计的条件概率，仅使用每个医院数据的本地模型培训步骤仍然会造成混淆。为了解决这个问题，我们提出了一种新颖的算法Fed-iptw，以将IPTW扩展到联合环境中，该环境可以实施全球（在所有数据上）和局部（在每个医院内）之间的协变量和治疗之间的去相关。我们验证了我们对比较机械通气对改善重症监护病房（ICU）广度困难患者生存率的治疗效果的任务的方法。我们对合成和现实世界的EICU数据集进行了实验，结果表明，关于事实预测和ITE估计任务的所有指标，Fed-iPTW优于最先进的方法，为机械气未经使用中的个性化处理策略设计铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2503.04946</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Safearena：评估自主网络代理的安全性</title>
      <link>https://arxiv.org/abs/2503.04957</link>
      <description><![CDATA[ARXIV：2503.04957V1公告类型：新 
摘要：基于LLM的代理商越来越熟练地解决基于Web的任务。有了这种功能，出于恶意目的而有更大的滥用风险，例如在在线论坛上发布错误信息或在网站上销售非法物质。为了评估这些风险，我们建议Safearena，这是第一个专注于故意滥用Web代理的基准。 Safearena在四个网站上包含250个安全和250项有害任务。我们将有害任务分为五个危害类别 - 错误信息，非法活动，骚扰，网络犯罪和社会偏见，旨在评估对网络代理的现实滥用。我们在我们的基准上评估了基于LLM的Web代理，包括GPT-4O，Claude-3.5 SONNEN，QWEN-2-VL 72B和LLAMA-3.2 90B。为了系统地评估他们对有害任务的敏感性，我们介绍了代理风险评估框架，该框架将四个风险水平的代理行为分类。我们发现代理商出奇地符合恶意要求，GPT-4O和QWEN-2分别完成了34.7％和27.3％的有害请求。我们的发现突出了对网络代理的迫切需求。我们的基准可在此处提供：https：//safearena.github.io]]></description>
      <guid>https://arxiv.org/abs/2503.04957</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>激励网络边缘基础模型的多租户分裂联邦学习</title>
      <link>https://arxiv.org/abs/2503.04971</link>
      <description><![CDATA[ARXIV：2503.04971V1公告类型：新 
摘要：基础模型（FMS）（例如GPT-4）通过微调通过微调在不同的下游任务中具有出色的生成能力。分裂联合学习（SFL）通过卸载部分FM计算以边缘服务器来促进对资源受限的本地设备进行隐私的FM微调，从而启用设备 - 设备边缘的协同性微调。实用的边缘网络通常托管多个SFL租户，以支持多元化的下游任务。 However, existing research primarily focuses on single-tenant SFL scenarios, and lacks tailored incentive mechanisms for multi-tenant settings, which are essential to effectively coordinate self-interested local devices for participation in various downstream tasks, ensuring that each SFL tenant&#39;s distinct FM fine-tuning requirements (e.g., FM types, performance targets, and fine-tuning deadlines) are met.为了解决这一差距，我们提出了一种新颖的价格提出机制（Prince），该机制指导多个SFL租户提供战略价格激励措施，该机制征集高质量设备的参与以进行有效的FM微调。具体而言，我们首先开发出偏见的全局SFL模型聚合方案，以消除由独立设备参与引起的模型偏差。然后，我们得出了一种严格的SFL收敛，以评估异质设备对FM性能改进的贡献，从而指导SFL租户的激励策略。此外，我们将租户间设备竞争模拟为Stackelberg平衡（SE）分析的拥塞游戏，从而得出了每个SFL租户的最佳激励策略。涉及各种数据方式（文本，图像和音频）的四种代表性SFL租户类型（VIT，BERT，WHISPER和LLAMA）的广泛模拟表明，与最新的方法相比，Prince可以加速高达3.07倍的FM微调，同时始终如一地符合良好的调整性能目标。]]></description>
      <guid>https://arxiv.org/abs/2503.04971</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>能量加权流与离线增强学习</title>
      <link>https://arxiv.org/abs/2503.04975</link>
      <description><![CDATA[ARXIV：2503.04975V1公告类型：新 
摘要：本文研究了生成模型中的能源指导，其中目标分布定义为$ q（\ Mathbf X）\ Propto P（\ MathBf X）\ Exp（ -  \ beta \ beta \ Mathcal E（\ Mathbf X））$，带有$ P（\ Mathbf X）$ p（\ Mathbf X）$是数据分布和$ \ nath aus aus us at $ as as us（$ ass）为了遵守能源指导，现有方法通常需要在扩散过程中学习中间指导的辅助程序。为了克服这一限制，我们探索了能源引导的流量匹配，这是扩散过程的广义形式。我们引入了能量加权流量匹配（EFM），这种方法可以直接了解无需辅助模型的能量引导流。理论分析表明，能量加权的流量匹配可以准确捕获引导流。此外，我们通过提出Q加​​权迭代策略优化（QIPO），将此方法扩展到能量加权扩散模型，并将其应用于离线增强学习（RL）。从经验上讲，我们证明了所提出的QIPO算法可以提高离线RL任务的性能。值得注意的是，我们的算法是第一个能够独立于辅助模型运行的能量引导的扩散模型，也是文献中第一个精确的能源引导的流动匹配模型。]]></description>
      <guid>https://arxiv.org/abs/2503.04975</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>万达++：通过区域梯度修剪大型语言模型</title>
      <link>https://arxiv.org/abs/2503.04992</link>
      <description><![CDATA[ARXIV：2503.04992V1公告类型：新 
摘要：大型语言模型（LLMS）修剪旨在消除不重要的重量以进行推理加速，并且性能最小。但是，现有的方法通常会遭受性能损失，而没有全模型的稀疏性微调。本文介绍了Wanda ++，这是一个新颖的修剪框架，通过利用解码器块级\ textbf {regional}梯度来超越最新方法。具体而言，Wanda ++首次使用区域梯度提高了修剪得分，并提出了一种有效的区域优化方法，以最大程度地减少密集和稀疏解码器输出之间的修剪诱导的输出差异。值得注意的是，Wanda ++在语言建模任务中最多比Wanda高达32 \％的困惑，并有效地将其推广到下游任务。进一步的实验表明，我们提出的方法与稀疏感知的微调是正交的，可以将Wanda ++与Lora微调结合使用，以实现与Wanda方法相似的困惑改善。所提出的方法是轻巧的，在单个NVIDIA H100 GPU上，在10分钟内修剪7B美洲驼模型。]]></description>
      <guid>https://arxiv.org/abs/2503.04992</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOES的持续预训练：您的路由器有多稳健？</title>
      <link>https://arxiv.org/abs/2503.05029</link>
      <description><![CDATA[ARXIV：2503.05029V1公告类型：新 
摘要：专家（MOE）变压器的稀疏激活混合物是基础模型的有前途的体系结构。与每个正向通行证需要相同数量的浮点操作（FLOP）的密集变压器相比，MOE受益于提高训练时样品效率并取得更强的性能。因此，许多封闭源和开源边界语言模型都采用了MOE架构。自然，从业者将希望通过大量新收集的数据扩展这些模型的功能，而不会完全重新培训它们。先前的工作表明，与全面的重新训练相比，重新播放和重新付费的简单组合可以使仅连续解码器的变压器的持续预训练（CPT）的持续训练（CPT）与性能降低最小。但是，对于仅解码器的MOE变压器，目前尚不清楚路由算法将如何影响持续的预训练性能：1）MOE变压器的路由器是否会加剧相对于密集模型的遗忘？ 2）路由器是否在CPT之后的先前发行版中保持平衡的负载？ 3）是否适用于足以持续预先培训的密集模型的密集模型？在接下来的内容中，我们在四个MOE变压器上进行了大规模（&gt; 2B参数开关和经过600B代币培训的DeepSeek Moe LLMS），以回答这些问题。我们的结果确立了令人惊讶的鲁棒性，即使在没有重播的情况下，即使在MOES不断预先训练的MOE中，Sinkhorn平衡和Z-and-aux-aloss平衡算法也是如此。此外，我们表明MOE LLM在CPT期间保持其样品效率（相对于flop匹配的密度模型），并且可以以一小部分成本匹配完全重新训练的MOE的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.05029</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可证明是正确的自动机嵌入，用于最佳自动化条件增强学习</title>
      <link>https://arxiv.org/abs/2503.05042</link>
      <description><![CDATA[ARXIV：2503.05042V1公告类型：新 
摘要：自动化条件增强学习（RL）为学习能够在训练下游策略之前预处理和冻结自动机嵌入的多任务策略提供了有希望的结果。但是，没有提供理论保证。这项工作为自动化条件的RL问题提供了一个理论框架，并表明它可能是正确的。然后，我们提出了一种学习的技术，可证明正确正确的自动机嵌入，以确保最佳的多任务策略学习。我们的实验评估证实了这些理论结果。]]></description>
      <guid>https://arxiv.org/abs/2503.05042</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>能力感知的推断：减轻专家混合物中的散曲效应</title>
      <link>https://arxiv.org/abs/2503.05066</link>
      <description><![CDATA[ARXIV：2503.05066V1公告类型：新 
摘要：专家（MOE）的混合是通过利用稀疏专家激活，优化性能和效率之间的权衡取舍来扩展大语言模型的有效体系结构。但是，在专家并行性的情况下，由于令牌到专家的分配不平衡，MOE遭受了推理效率低下的症状，其中一些专家被超载，而另一些专家仍然不足。这种不平衡导致资源利用率不佳和潜伏期的增加，因为最负担的专家决定了总体延迟，这是我们将这种现象定义为\ textbf {\ textit {straggler效应}}的现象。 To mitigate this, we propose Capacity-Aware Inference, including two key techniques: (1) \textbf{\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens to regulate the maximum latency of MoE, and (2) \textbf{\textit{Capacity-Aware Token Reroute}}, which reallocates overflowed tokens to未充分利用的专家，平衡令牌分布。这些技术共同优化了高负载和低负载的专家利用率，从而导致了更有效的MOE推理管道。广泛的实验证明了我们方法的有效性，显示了推理效率的显着提高，例如，在Mixtral-8 $ 8 $ \ times $ 7B的教学中，平均绩效提高和1.94 $ \ times $推理速度。]]></description>
      <guid>https://arxiv.org/abs/2503.05066</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种新的本地时间耦合平方WASSERSTEIN-2方法，用于训练随机神经网络，以重建动态系统中的不确定参数</title>
      <link>https://arxiv.org/abs/2503.05068</link>
      <description><![CDATA[ARXIV：2503.05068V1公告类型：新 
摘要：在这项工作中，我们提出和分析了一种新的局部时间耦合平方WASSERSTEIN-2方法，用于重建动态系统中未知参数的分布。具体而言，我们表明，可以通过使我们提出的局部时间耦合平方wasserstein-2损失函数最小化的随机神经网络模型是一种有效的模型，它是近似动态系统中不确定模型参数的分布的有效模型。通过几个数值示例，我们展示了我们提出的方法在重建不同动态系统中参数分布方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.05068</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于模仿学习与RLHF之间的联系</title>
      <link>https://arxiv.org/abs/2503.05079</link>
      <description><![CDATA[ARXIV：2503.05079V1公告类型：新 
摘要：这项工作从模仿学习的角度研究了大语言模型与偏好数据的一致性。我们建立了从人类反馈RLHF和模仿学习（IL）的强化学习之间的紧密理论联系，揭示了RLHF隐含地对偏好数据分布进行模仿学习。在此联系的基础上，我们提出了DIL，这是一个直接优化模仿学习目标的原则性框架。 DIL提供了关于对齐方式的统一模仿学习观点，涵盖了现有的对齐算法作为特殊情况，同时自然引入了新变体。通过桥接IL和RLHF，DIL提供了与RLHF保持一致性的新见解。广泛的实验表明，DIL在各种具有挑战性的基准上都优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.05079</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应最佳运输的部分分布对齐</title>
      <link>https://arxiv.org/abs/2503.05087</link>
      <description><![CDATA[ARXIV：2503.05087V1公告类型：新 
摘要：为了补救经典最佳运输中全质量或固定质量约束的缺点，我们提出了自适应最佳运输，这与经典的最佳运输具有自适应质量保存能力。它旨在回答如何在概率分布之间适应概率质量的数学问题，这在人工智能的各个领域都是一个基本话题。自适应最佳运输能够根据问题本身的内在结构来适应质量。理论结果阐明了大众运输的自适应机制。此外，我们通过尊重数据中的噪声，异常值和分布变化的普遍性来实例化机器学习应用中的自适应最佳传输，以部分和适应性地对齐源和目标分布。域适应基准的实验结果表明，所提出的方法显着胜过最新的算法。]]></description>
      <guid>https://arxiv.org/abs/2503.05087</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分组的顺序优化策略 - 超参数重要性评估在深度学习中的应用</title>
      <link>https://arxiv.org/abs/2503.05106</link>
      <description><![CDATA[ARXIV：2503.05106V1公告类型：新 
摘要：超参数优化（HPO）是机器学习管道的关键组成部分，严重影响模型的鲁棒性，稳定性和概括。但是，HPO通常是一项耗时且计算密集的任务。传统的HPO方法（例如网格搜索和随机搜索）通常会遇到效率低下。贝叶斯优化虽然更有效，但仍在高维搜索空间中挣扎。在本文中，我们通过探索如何利用从高参数重要性评估（HIA）中获得的见解来为该领域做出贡献，以加速HPO，减少时间和计算资源。在先前的工作基础上，通过使用10个常见的图像分类数据集评估CNN上的10个超参数，我们实施了一种名为“顺序分组”的新型HPO策略。这项先前的工作根据其对模型性能的影响评估了所研究的超参数的重要性权重，提供了宝贵的见解，我们利用这些见解来优化HPO流程。我们在六个附加图像分类数据集中验证的实验表明，与常规同时策略相比，合并超参数重要性评估（HIA）可以显着加速HPO，而无需损害模型性能，平均将优化时间降低31.9 \％。]]></description>
      <guid>https://arxiv.org/abs/2503.05106</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>