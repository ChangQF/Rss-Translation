<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Tue, 19 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于摊余变分推理中的包容性 KL 最小化的顺序蒙特卡罗</title>
      <link>https://arxiv.org/abs/2403.10610</link>
      <description><![CDATA[arXiv:2403.10610v1 公告类型：新
摘要：为了训练编码器网络执行摊销变分推理，Kullback-Leibler (KL) 从精确后验到其近似的散度（称为包容性或前向 KL）由于质量问题而成为变分目标越来越流行的选择。覆盖其最小化器的属性。然而，最小化这一目标具有挑战性。一种流行的现有方法，重新加权唤醒睡眠（RWS），受到严重偏差的梯度和导致高度集中的变异分布的循环病理的影响。作为替代方案，我们提出了 SMC-Wake，这是一种拟合摊销变分近似的过程，该过程使用似然调节顺序蒙特卡洛采样器来估计包含 KL 散度的梯度。我们提出了三个梯度估计器，所有这些估计器在迭代次数上都是渐近无偏的，并且其中两个是强一致的。我们的方法将随机梯度更新、SMC 采样器和归一化常数估计的迭代改进相结合，以减少自归一化带来的偏差。在模拟和真实数据集的实验中，SMC-Wake 拟合的变分分布比现有方法更准确地逼近后验。]]></description>
      <guid>https://arxiv.org/abs/2403.10610</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>DiPaCo：分布式路径组合</title>
      <link>https://arxiv.org/abs/2403.10616</link>
      <description><![CDATA[arXiv:2403.10616v1 公告类型：新
摘要：扩展神经网络模型推动了机器学习（ML）的进步。这种扩展是通过更加英勇的工程壮举实现的，这对于适应需要并行工作的设备之间的高带宽通信的机器学习方法是必要的。在这项工作中，我们提出了一种针对 ML 模型的共同设计的模块化架构和训练方法，称为分布式 PAth COmposition (DiPaCo)。在训练期间，DiPaCo 通过一组共享模块按路径分配计算。结合受本地 SGD 启发的优化 (DiLoCo)，使模块保持同步并大幅减少通信，我们的方法有助于对连接不良和异构的工作人员进行培训，其设计可确保对工作人员故障和抢占的鲁棒性。在推理时，每个输入只需执行一条路径，无需任何模型压缩。我们认为这种方法是迈向大规模学习新范式的第一个原型，这种范式不太同步，而且更加模块化。我们在广泛使用的 C4 基准测试上进行的实验表明，对于相同数量的训练步骤但更少的挂钟时间，DiPaCo 通过选择 256 条可能路径之一（每条路径都有一个1.5亿个参数的大小。]]></description>
      <guid>https://arxiv.org/abs/2403.10616</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>在资源受限的边缘环境中使用 DNN 的有效参数缩减实现帕累托最优</title>
      <link>https://arxiv.org/abs/2403.10569</link>
      <description><![CDATA[arXiv:2403.10569v1 公告类型：新
摘要：本文提出了对现有深度神经网络（DNN）的优化，以提高其硬件利用率并促进资源受限的边缘环境的设备上训练。我们在 Xception 上实施有效的参数减少策略，在不牺牲准确性的情况下缩小模型大小，从而减少训练期间的内存利用率。我们在两个实验中评估我们的模型：Caltech-101 图像分类和 PCB 缺陷检测，并将其性能与原始 Xception 和轻量级模型 EfficientNetV2B1 和 MobileNetV2 进行比较。 Caltech-101 图像分类的结果表明，我们的模型比 Xception (75.89%) 具有更好的测试精度 (76.21%)，平均使用内存 (847.9MB) 比 Xception (874.6MB) 更少，并且具有更快的训练和速度推理次数。轻量级模型过拟合，EfficientNetV2B1 的测试精度为 30.52%，MobileNetV2 的测试精度为 58.11%。两个轻量级模型都比我们的模型和 Xception 具有更好的内存使用率。在 PCB 缺陷检测上，与 Xception (88.10%)、EfficientNetV2B1 (55.25%) 和 MobileNetV2 (50.50%) 相比，我们的模型具有最好的测试精度 (90.30%)。 MobileNetV2 的平均内存使用量最少（849.4MB），其次是我们的模型（865.8MB），然后是 EfficientNetV2B1（874.8MB），Xception 最高（893.6MB）。我们进一步对预先训练的权重进行实验，并观察到内存使用量减少，从而显示了迁移学习的好处。对模型性能的帕累托分析表明，我们优化的模型架构满足准确性和低内存利用率的目标。]]></description>
      <guid>https://arxiv.org/abs/2403.10569</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>发现异嗜图的不变邻域模式</title>
      <link>https://arxiv.org/abs/2403.10572</link>
      <description><![CDATA[arXiv:2403.10572v1 公告类型：新
摘要：本文研究非同亲图上的分布偏移问题。大多数现有的图神经网络方法都依赖于同类假设，即来自同一类的节点更有可能被链接。然而，这种同质性假设并不总是在现实世界的图中成立，这导致了以前的方法中未考虑到的更复杂的分布变化。非齐次图上邻域模式的分布变化更加多样化。我们提出了一种新颖的不变邻域模式学习（INPL）来缓解非齐次图上的分布偏移问题。具体来说，我们提出了自适应邻域传播（ANP）模块来捕获自适应邻域信息，这可以缓解非同亲图上的邻域模式分布偏移问题。我们提出不变非同质图学习（INHGL）模块来约束 ANP 并学习非同质图上的不变图表示。对现实世界非同质图的大量实验结果表明，INPL 可以在大型非同质图上的学习中实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.10572</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>从算法到结果：回顾人工智能在非肌肉侵袭性膀胱癌复发预测中的作用</title>
      <link>https://arxiv.org/abs/2403.10586</link>
      <description><![CDATA[arXiv:2403.10586v1 公告类型：新
摘要：膀胱癌是主要的泌尿道癌症，在英国每天导致 15 人死亡。这种癌症主要表现为非肌肉浸润性膀胱癌（NMIBC），其特征是肿瘤尚未穿透膀胱壁的肌肉层。 NMIBC 的复发率高达 70-80%，因此治疗费用最高。当前用于预测复发的工具使用的评分系统高估了风险且准确性较差。不准确和延迟的复发预测会显着增加死亡的可能性。因此，准确预测复发对于具有成本效益的管理和治疗计划至关重要。这就是机器学习 (ML) 技术成为利用分子和临床数据预测 NMIBC 复发的一种有前景的方法的原因。本综述对预测 NMIBC 复发的 ML 方法进行了全面分析。我们的系统评估证明了多种机器学习算法和标记物（包括放射组学、临床、组织病理学、基因组和生化数据）在增强复发预测和个性化患者管理方面的潜力。我们总结了所使用的各种预测任务、数据模式和机器学习模型，强调了它们的性能、局限性以及结合成本效益的未来方向。讨论了与人工智能模型的通用性和可解释性相关的挑战，强调了协作努力和强大数据集的需要。]]></description>
      <guid>https://arxiv.org/abs/2403.10586</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>集成学习卫星降水空间插值的不确定性估计</title>
      <link>https://arxiv.org/abs/2403.10567</link>
      <description><![CDATA[arXiv:2403.10567v1 公告类型：新
摘要：概率分布形式的预测对于决策至关重要。分位数回归可以在空间插值设置中实现这一点，以合并遥感和测量降水数据。然而，在这种情况下，分位数回归算法的集成学习仍未得到探索。在这里，我们通过引入九个基于分位数的集成学习器并将它们应用于大型降水数据集来解决这一差距。我们采用了一种新颖的特征工程策略，结合位置高程，减少了相关位置距离加权卫星降水的预测因子。我们的集成学习器包括六种堆叠和三种简单方法（均值、中值、最佳组合器），组合了六种单独的算法：分位数回归（QR）、分位数回归森林（QRF）、广义随机森林（GRF）、梯度增强机（GBM） 、光梯度增强机 (LightGBM) 和分位数回归神经网络 (QRNN)。这些算法在不同的堆叠方法中既充当基础学习器又充当组合器。我们使用大型数据集中的分位数评分函数评估了 QR 的性能，该数据集包含美国本土 (CONUS) 15 年的月度测量和卫星降水量。与 QR 和 QRNN 叠加在感兴趣的分位数水平上产生了最佳结果（0.025、0.050、0.075、0.100、0.200、0.300、0.400、0.500、0.600、0.700、0.800、0.900、0.925、0.950、0.97 5）、超越参考方法3.91%至8.95%。这证明了堆叠在改善空间插值及其他领域的概率预测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.10567</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>MoPE：通过快速专家的混合实现参数高效且可扩展的多模式融合</title>
      <link>https://arxiv.org/abs/2403.10568</link>
      <description><![CDATA[arXiv:2403.10568v1 公告类型：新
摘要：即时调整已经证明了在融合多模态任务的单模态基础模型方面的参数效率。然而，与其他调整方法相比，其有限的适应性和表现力导致性能不佳。在本文中，我们通过解开普通提示以自适应地捕获数据集级和实例级特征来解决这个问题。在此基础上，我们引入了提示专家混合（MoPE）技术来增强表现力。 MoPE 利用多模式配对先验在每个实例的基础上路由最有效的提示。与普通提示相比，我们基于 MoPE 的条件提示在多模态融合方面表现出更大的表现力，可以更好地扩展训练数据和可训练参数的总数。我们还研究了专家路由的正则化术语，从而导致新兴的专家专业化，其中不同的专家专注于不同的概念，从而实现可解释的软提示。跨三个多模态数据集的大量实验表明，我们的方法实现了最先进的结果，匹配甚至超越了微调的性能，同时仅需要 0.8% 的可训练参数。代码将发布：https://github.com/songrise/MoPE。]]></description>
      <guid>https://arxiv.org/abs/2403.10568</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>生成模型以及联网和自动驾驶汽车：探索交通与人工智能交叉点的调查</title>
      <link>https://arxiv.org/abs/2403.10559</link>
      <description><![CDATA[arXiv:2403.10559v1 公告类型：新
摘要：本报告调查了生成模型和联网自动驾驶汽车 (CAV) 的历史和影响，这两种推动技术和交通进步的突破性力量。通过重点关注生成模型在 CAV 背景下的应用，该研究旨在揭示这种集成如何增强自动驾驶汽车的预测建模、模拟准确性和决策过程。本文讨论了在交通运输中集成生成模型和 CAV 技术的好处和挑战。它旨在强调所取得的进展、剩余的障碍以及安全和创新方面进步的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.10559</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>AAAI 2024 以人为中心的表征学习研讨会已接受论文集</title>
      <link>https://arxiv.org/abs/2403.10561</link>
      <description><![CDATA[arXiv:2403.10561v1 公告类型：新
摘要：这个非档案索引并不完整，因为一些被接受的论文选择退出。所有被接受论文的列表可在研讨会网站上找到。]]></description>
      <guid>https://arxiv.org/abs/2403.10561</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>电池排列的冷却引导扩散模型</title>
      <link>https://arxiv.org/abs/2403.10566</link>
      <description><![CDATA[arXiv:2403.10566v1 公告类型：新
摘要：我们的研究引入了一种生成式人工智能方法，该方法采用冷却引导扩散模型来优化电池单元的布局，这是提高电池热管理系统冷却性能和效率的关键一步。传统的设计过程严重依赖迭代优化和广泛的猜测，速度缓慢且效率低下，常常导致解决方案不理想。相比之下，我们的创新方法使用带有分类器和冷却引导的参数去噪扩散概率模型（DDPM）来生成具有增强冷却路径的优化电池布局，从而显着降低电池的最高温度。通过结合基于位置的分类器指导，我们确保了生成布局的可行性。同时，冷却引导直接优化冷却效率，使我们的方法独特有效。与两种先进模型——表格去噪扩散概率模型（TabDDPM）和条件表格 GAN（CTGAN）相比，我们的冷却引导扩散模型明显优于这两种模型。在可行性、多样性和冷却效率等关键指标上，它的效率比 TabDDPM 高五倍，比 CTGAN 高六十六倍。这项研究标志着该领域的重大飞跃，旨在优化电池单元布局以实现卓越的冷却效率，从而为开发更有效、更可靠的电池热管理系统奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2403.10566</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>学习通过强化学习为法学硕士生成的文本添加水印</title>
      <link>https://arxiv.org/abs/2403.10553</link>
      <description><![CDATA[arXiv:2403.10553v1 公告类型：新
摘要：我们研究如何对 LLM 输出添加水印，即将算法可检测信号嵌入到 LLM 生成的文本中以跟踪滥用情况。与当前使用固定 LLM 的主流方法不同，我们通过在水印管道中包含 LLM 调整阶段来扩展水印设计空间。虽然之前的工作主要关注将信号嵌入到输出中的令牌级水印，但我们设计了一种将信号嵌入到 LLM 权重中的模型级水印，并且此类信号可以由配对检测器检测到。我们提出了一种基于强化学习的协同训练框架，该框架迭代地（1）训练检测器以检测生成的带水印文本，以及（2）调整 LLM 以生成检测器易于检测的文本，同时保持其正常实用性。我们的经验表明，我们的水印更加准确、稳健且适应性强（针对新的攻击）。它还允许带水印的模型开源。此外，如果与对齐一起使用，引入的额外开销很低——只需训练额外的奖励模型（即我们的检测器）。我们希望我们的工作能够投入更多精力来研究更广泛的水印设计，而不仅仅是与固定的法学硕士合作。我们开源代码：https://github.com/xiaojunxu/learning-to-watermark-llm。]]></description>
      <guid>https://arxiv.org/abs/2403.10553</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>KARINA：全球天气预报的高效深度学习模型</title>
      <link>https://arxiv.org/abs/2403.10555</link>
      <description><![CDATA[arXiv:2403.10555v1 公告类型：新
摘要：基于深度学习的数据驱动模型在气候研究中越来越流行，特别是全球天气预报。然而，以高分辨率训练全球天气数据需要大量的计算资源。因此，我们提出了一个名为 KARINA 的新模型来克服该领域典型的大量计算需求。该模型的预测精度与更高分辨率的模型相当，但计算资源却少得多，仅需要 4 个 NVIDIA A100 GPU 和不到 12 小时的训练。 KARINA 结合了 ConvNext、SENet 和 Geocycling Padding，以 2.5{\deg} 分辨率增强天气预报，可以滤除高频噪声。地球循环填充保留输入图像横向边界处的像素，从而保持球形地球中的大气流连续性。 SENet 动态改进特征响应，推进大气过程建模，特别是在作为众多通道的垂直柱过程中。在这方面，KARINA 在天气预报准确性方面树立了新的基准，超越了 ECMWF S2S 等现有模型，提前时间长达 7 天。值得注意的是，即使与最近开发的使用 100 倍大像素的高分辨率数据训练的模型（Pangu-Weather、GraphCast、ClimaX 和 FourCastNet）相比，KARINA 也取得了具有竞争力的性能。最后，KARINA 通过有效地模拟地球大气层，提高了准确性和资源效率，显着推进了全球天气预报。]]></description>
      <guid>https://arxiv.org/abs/2403.10555</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>二阶信息很重要：重新审视大型语言模型的机器遗忘</title>
      <link>https://arxiv.org/abs/2403.10557</link>
      <description><![CDATA[arXiv:2403.10557v1 公告类型：新
摘要：随着大型语言模型（LLM）的快速发展，我们目睹了 ChatGPT、LLaMa 和 Gemini 等主要 LLM 产品之间的激烈竞争。然而，训练语料库的各种问题（例如隐私泄露和版权侵犯）仍未得到充分研究。例如，《泰晤士报》起诉 OpenAI 和微软使用其数百万篇文章进行训练，侵犯其版权。从法学硕士从业者的角度来看，处理此类无意的隐私侵犯可能具有挑战性。之前的工作使用梯度信息解决了LLM的“忘却”问题，但它们大多引入了数据预处理等显着开销或缺乏鲁棒性。在本文中，与基于一阶信息的方法相比，我们通过以下方式重新审视了“忘却”问题：我们的去学习算法受到经典牛顿更新的启发，不仅与数据无关/模型无关，而且在效用保存或隐私保证方面也被证明是鲁棒的。通过四个 NLP 数据集的评估以及对现实世界数据集的案例研究，我们的方法始终表现出优于一阶方法的优势。]]></description>
      <guid>https://arxiv.org/abs/2403.10557</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>通过双向归一化流进行异常流量检测的半监督学习</title>
      <link>https://arxiv.org/abs/2403.10550</link>
      <description><![CDATA[arXiv:2403.10550v1 公告类型：新
摘要：随着互联网的快速发展，各类异常流量正在威胁网络安全。我们考虑异常网络流量检测问题，并提出一种仅使用正常流量的三阶段异常检测框架。我们的框架可以在没有异常先验知识的情况下生成伪异常样本，从而实现异常数据的检测。首先，我们采用重建方法来学习正常样本的深度表示。其次，使用双向流模块将这些表示标准化为标准正态分布。为了模拟异常样本，我们将噪声添加到归一化表示中，然后将其通过双向流模块的生成方向传递。最后，训练一个简单的分类器来区分潜在空间中的正常样本和伪异常样本。在推理过程中，我们的框架仅需要两个模块来检测异常样本，从而大大减少了模型大小。根据实验，我们的方法在异常网络流量检测的常见基准数据集上取得了最先进的结果。代码在 https://github.com/ZxuanDang/ATD-via-Flows.git 中给出]]></description>
      <guid>https://arxiv.org/abs/2403.10550</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>通过师生无数据知识转移训练未见过的陌生地点的自我定位模型</title>
      <link>https://arxiv.org/abs/2403.10552</link>
      <description><![CDATA[arXiv:2403.10552v1 公告类型：新
摘要：最先进的自定位模型的一个典型假设是目标工作空间中存在带注释的训练数据集。然而，当机器人在一般的开放世界中旅行时，这并不总是成立。本研究介绍了一种开放世界分布式机器人系统的新颖训练方案。在我们的方案中，机器人（“学生”）可以向在陌生地方遇到的其他机器人（“老师”）寻求指导。具体来说，从教师模型重建伪训练数据集，然后用于学生模型的持续学习。与典型的知识转移方案不同，我们的方案仅对教师模型引入了最小的假设，因此它可以处理各种类型的开放教师，包括不合作的、不可训练的（例如图像检索引擎）和黑盒教师（即数据隐私） ）。我们建议利用在自定位任务中普遍存在的假设：“教师模型是一个自定位系统”并重用自定位系统，而不是像现有方法那样依赖教师私人数据的可用性教师作为唯一可访问的沟通渠道。我们特别专注于设计一个优秀的学生/提问者，其与教师的互动可以产生有效的问答序列，这些序列可以用作学生自我定位模型的伪训练数据集。当应用于通用递归知识蒸馏场景时，我们的方法表现出稳定且一致的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2403.10552</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    </channel>
</rss>