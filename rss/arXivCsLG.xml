<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 13 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于自注意的非线性基变换用于动态光纤传输矩阵的紧凑潜在空间建模</title>
      <link>https://arxiv.org/abs/2406.07775</link>
      <description><![CDATA[arXiv:2406.07775v1 公告类型：新
摘要：多模光纤是能高效传输光的细如发丝的玻璃线。它们有望成为下一代医疗内窥镜，在体内深处提供前所未有的亚细胞图像分辨率。然而，将光限制在这样的光纤中意味着图像在传输过程中本质上是混乱的。传统上，这种混乱是通过预先校准特定光纤如何扰乱光并求解代表光纤物理模型的静态线性矩阵方程来补偿的。然而，随着技术向现实世界部署发展，由于运动和温度变化等因素，以及由于光纤尖端在体内时无法接近而导致的非线性，解扰过程必须考虑表示光纤对光的影响的矩阵的动态变化。这种复杂、动态和非线性的行为非常适合用神经网络来近似，但大多数领先的图像重建网络都依赖于卷积层，而卷积层假设相邻像素之间存在强相关性，这种强烈的归纳偏差不适用于可以用具有长程相关性的任意坐标表示范围来表示的纤维矩阵。我们引入了一个新概念，它使用自注意层将不同纤维矩阵的坐标表示动态地转换为一个基础，该基础允许紧凑、低维表示，适合进一步处理。我们在不同的纤维矩阵数据集上证明了这种方法的有效性。我们表明，我们的模型显著改善了变换后基础中纤维基的稀疏性，参与率 p 作为稀疏度的度量，在 0.01 到 0.11 之间。此外，我们表明这些变换后的表示可以对原始矩阵进行重建，重建误差 &lt; 10%，证明了可逆性。]]></description>
      <guid>https://arxiv.org/abs/2406.07775</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:12 GMT</pubDate>
    </item>
    <item>
      <title>离散时间主动推理的简明数学描述</title>
      <link>https://arxiv.org/abs/2406.07726</link>
      <description><![CDATA[arXiv:2406.07726v1 公告类型：新
摘要：本文给出了离散时间主动推理的简明数学描述。本文的主要部分是该主题的一般介绍，包括一个说明动作选择理论的示例。附录中讨论了更微妙的数学细节。这部分针对的是已经研究过主动推理文献但难以理解数学细节和推导的读者。在整个手稿中，特别注意采用既精确又符合标准数学文本的符号。所有方程和推导都链接到有关该主题的其他流行文本中的特定方程编号。此外，还提供了实现本文所述动作选择机制并与 pymdp 环境兼容的 Python 代码。]]></description>
      <guid>https://arxiv.org/abs/2406.07726</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>利用实时 3D 感知和贝叶斯收益估计进行个性化产品分类</title>
      <link>https://arxiv.org/abs/2406.07769</link>
      <description><![CDATA[arXiv:2406.07769v2 公告类型：新
摘要：产品组合选择是实体零售商面临的一个关键挑战。有效地将库存与购物者的偏好相结合可以增加销售额并减少缺货。然而，在现实世界中，由于产品组合可能性的组合激增，这个问题具有挑战性。消费者偏好通常在空间和时间上是异质的，这使得库存偏好调整具有挑战性。此外，现有策略依赖于联合数据，这些数据往往是聚合的、低分辨率的，并且存在高延迟的问题。为了解决这些挑战，我们引入了一个实时推荐系统，我们称之为 EdgeRec3D。我们的系统利用 3D 计算机视觉的最新进展进行感知和自动、细粒度的销售估计。这些感知组件在网络边缘运行并促进实时奖励信号。此外，我们开发了一个贝叶斯收益模型来解释来自 3D LIDAR 数据的噪声估计。我们依靠空间聚类来让系统适应不同的消费者偏好，并依靠基于图的候选生成算法来解决组合搜索问题。我们在真实商店中对饮料产品进行了两次为期 6-8 周的 A/B 测试，结果显示销售额分别增长了 35% 和 27%。最后，我们通过观察性研究对部署的系统进行了为期 28 周的监控，结果显示销售额增长了 9.4%。]]></description>
      <guid>https://arxiv.org/abs/2406.07769</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>DualBind：用于蛋白质-配体结合亲和力预测的双损失框架</title>
      <link>https://arxiv.org/abs/2406.07770</link>
      <description><![CDATA[arXiv:2406.07770v1 公告类型：新
摘要：准确预测蛋白质-配体结合亲和力对于药物开发至关重要。机器学习的最新进展表明这项任务取得了令人鼓舞的成果。然而，这些方法通常严重依赖标记数据，而这些数据可能稀缺或不可靠，或者它们依赖于可能在实践中不成立的假设，如玻尔兹曼分布数据。在这里，我们提出了 DualBind，这是一个新颖的框架，它将监督均方误差 (MSE) 与无监督去噪分数匹配 (DSM) 相结合，以准确学习结合能函数。DualBind 不仅通过提供更准确的绝对亲和力预测解决了仅 DSM 模型的局限性，而且与仅 MSE 模型相比，它提高了通用性并减少了对标记数据的依赖。我们的实验结果表明，DualBind 在预测结合亲和力方面表现出色，并且可以有效利用标记和未标记数据来提高性能。]]></description>
      <guid>https://arxiv.org/abs/2406.07770</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>诊断并解决分子设计贝叶斯优化中的常见问题</title>
      <link>https://arxiv.org/abs/2406.07709</link>
      <description><![CDATA[arXiv:2406.07709v1 公告类型：新
摘要：贝叶斯优化 (BO) 是分子设计任务的一种原则性方法。在本文中，我们解释了 BO 的三个缺陷，这些缺陷可能导致经验性能不佳：先验宽度不正确、过度平滑和采集函数最大化不足。我们表明，解决这些问题后，即使是基本的 BO 设置也能够在分子设计的 PMO 基准上实现最高的整体性能（Gao 等人，2022 年）。这些结果表明，BO 可能会在分子机器学习社区中得到更多关注。]]></description>
      <guid>https://arxiv.org/abs/2406.07709</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>基于损失梯度高斯宽度的泛化和优化保证</title>
      <link>https://arxiv.org/abs/2406.07712</link>
      <description><![CDATA[arXiv:2406.07712v1 公告类型：新
摘要：机器学习中对种群损失的泛化和优化保证通常依赖于基于均匀收敛的分析，通常基于预测器的 Rademacher 复杂度。现代模型的丰富表示能力引发了人们对这种方法的担忧。在本文中，我们根据梯度的复杂性提出了泛化和优化保证，以损失梯度高斯宽度 (LGGW) 来衡量。首先，我们在灵活的梯度支配条件下直接根据 LGGW 引入泛化保证，我们证明这对于深度模型是经验性的。其次，我们表明，只要 LGGW 很小，有限和 (随机) 优化中的样本重用就不会使经验梯度偏离种群梯度。第三，专注于深度网络，我们展示了如何在温和假设下限制它们的 LGGW 的结果。具体来说，我们表明，它们的 LGGW 可以被 (a) 损失 Hessian 特征值的 $L_2$ 范数所限制，经验表明，对于常用的深度模型，该范数为 $\tilde{O}(1)$；以及 (b) 特征化器的高斯宽度，即倒数第二层的输出。据我们所知，我们在 LGGW 方面的泛化和优化保证是同类中的第一个结果，避免了基于预测器 Rademacher 复杂性分析的陷阱，并且有望为深度模型提供定量的严格界限。]]></description>
      <guid>https://arxiv.org/abs/2406.07712</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>Treeffuser：通过梯度提升树的条件扩散进行概率预测</title>
      <link>https://arxiv.org/abs/2406.07658</link>
      <description><![CDATA[arXiv:2406.07658v1 公告类型：新
摘要：概率预测旨在计算预测分布而不是单点预测。这些分布使从业者能够量化不确定性、计算风险和检测异常值。然而，大多数概率方法都假设参数响应，例如高斯或泊松分布。当这些假设失败时，这些模型会导致错误的预测和校准不佳的不确定性。在本文中，我们提出了 Treeffuser，这是一种易于使用的表格数据概率预测方法。这个想法是学习一个条件扩散模型，其中使用梯度提升树估计得分函数。条件扩散模型使 Treeffuser 灵活且非参数化，而梯度提升树使其稳健且易于在 CPU 上训练。Treeffuser 学习校准良好的预测分布，可以处理各种回归任务——包括具有多变量、多模态和倾斜响应的任务。 % ，以及分类预测因子和缺失数据我们在合成数据和真实数据上研究 Treeffuser，并表明它优于现有方法，提供更精确的概率预测。我们进一步展示了其多功能性，并使用沃尔玛的销售数据将其应用于不确定情况下的库存分配。我们在 \href{https://github.com/blei-lab/treeffuser}{https://github.com/blei-lab/treeffuser} 中实现了 Treeffuser。]]></description>
      <guid>https://arxiv.org/abs/2406.07658</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>对抗性机器学习</title>
      <link>https://arxiv.org/abs/2406.07687</link>
      <description><![CDATA[arXiv:2406.07687v1 公告类型：新
摘要：本文重点关注机器反学习的挑战，旨在消除特定训练数据对机器学习模型的影响。传统上，反学习算法的开发与成员推理攻击 (MIA) 的开发并行，MIA 是一种隐私威胁，用于确定数据实例是否用于训练。然而，这两条线索紧密相连：人们可以通过 MIA 成功移除数据的视角来看待机器反学习。认识到这种联系，我们提出了一个博弈论框架，将 MIA 集成到反学习算法的设计中。具体来说，我们将反学习问题建模为 Stackelberg 博弈，其中反学习者努力从模型中反学习特定的训练数据，而审计员使用 MIA 来检测表面上被移除的数据的痕迹。采用这种对抗性视角可以利用新的攻击进步，促进反学习算法的设计。我们的框架在两个方面脱颖而出。首先，它采用对抗性方法，主动将攻击纳入反学习算法的设计中。其次，它使用隐式微分来获得限制攻击者成功的梯度，从而有利于反学习过程。我们给出了实证结果来证明所提出的方法对机器学习反学习的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.07687</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>标签平滑改进了机器的学习能力</title>
      <link>https://arxiv.org/abs/2406.07698</link>
      <description><![CDATA[arXiv:2406.07698v1 公告类型：新
摘要：机器学习 (MU) 的目标是从模型中消除先前学习的数据。然而，在使用现有的 MU 技术时，很难在计算成本和性能之间取得平衡。从标签平滑对模型置信度和差异隐私的影响中汲取灵感，我们提出了一种简单的基于梯度的 MU 方法，该方法使用标签平滑的逆过程。这项工作引入了 UGradSL，这是一种使用平滑标签的简单、即插即用的 MU 方法。我们提供理论分析，说明为什么适当引入标签平滑可以提高 MU 性能。我们对六个不同大小和不同模态的数据集进行了广泛的实验，证明了我们提出的方法的有效性和鲁棒性。MU 性能的持续改进仅以额外计算的边际成本为代价。例如，UGradSL 在梯度上升 MU 基线上将学习准确率提高了 66%，而不会牺牲学习效率。]]></description>
      <guid>https://arxiv.org/abs/2406.07698</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>什么时候嵌入模型比另一个模型更有前景？</title>
      <link>https://arxiv.org/abs/2406.07640</link>
      <description><![CDATA[arXiv:2406.07640v1 公告类型：新
摘要：嵌入器在机器学习中起着核心作用，它将任何对象投影到数值表示中，而这些数值表示又可用于执行各种下游任务。嵌入模型的评估通常取决于利用下游任务的特定领域经验方法，这主要是因为缺乏标准化的比较框架。然而，获取足够大且具有代表性的数据集来进行这些评估并不总是可行的，而且可能非常昂贵且耗时。在本文中，我们提出了一种评估嵌入器的统一方法。首先，我们利用充分性和信息量的概念，为比较嵌入模型建立了理论基础。然后，我们利用这些概念来设计一个易于处理的比较标准（信息充分性），从而实现与任务无关且自我监督的排名程序。我们通过实验证明，我们的方法与嵌入模型在自然语言处理和分子生物学中促进各种下游任务的能力密切相关。这实际上为从业者提供了对模型试验进行优先排序的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2406.07640</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>为节点嵌入生成人类可理解的解释</title>
      <link>https://arxiv.org/abs/2406.07642</link>
      <description><![CDATA[arXiv:2406.07642v1 公告类型：新
摘要：节点嵌入算法生成图中节点的低维潜在表示。这些嵌入通常用于下游任务，例如节点分类和链接预测。在本文中，我们研究以下两个问题：（Q1）我们能否用人类可理解的图形特征（例如度、聚类系数和 PageRank）解释每个嵌入维度。（Q2）我们如何修改现有的节点嵌入算法以生成可以通过人类可理解的图形特征轻松解释的嵌入？我们发现 Q1 的答案是肯定的，并引入了一个名为 XM（eXplain eMbedding 的缩写）的新框架来回答 Q2。XM 的一个关键方面涉及最小化生成的解释的核范数。我们表明，通过最小化核范数，我们可以最小化生成的解释的熵的下限。我们在各种真实世界的图表上测试了 XM，并表明 XM 不仅保留了现有节点嵌入方法的性能，而且还增强了它们的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2406.07642</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>OPTune：高效的在线偏好调整</title>
      <link>https://arxiv.org/abs/2406.07657</link>
      <description><![CDATA[arXiv:2406.07657v1 公告类型：新
摘要：带有人类反馈的强化学习（RLHF）对于将大型语言模型（LLM）与人类偏好对齐至关重要。与广泛研究的离线版 RLHF，\emph{例如} 直接偏好优化 (DPO) 相比，最近的研究表明在线变体实现了更好的对齐。然而，在线对齐需要动态生成新的训练数据，这成本高昂、难以并行化，并且质量和效用参差不齐。在本文中，我们提出了一种更有效的在线偏好调整数据探索策略 (OPTune)，它不依赖于人工策划或预先收集的教师响应，而是动态采样信息响应以进行策略偏好对齐。在数据生成过程中，OPTune 仅选择那些（重新）生成的响应可能比现有响应提供更多信息和更高质量的训练信号的提示。在训练目标中，OPTune 根据其在改善对齐方面的效用重新加权每个生成的响应（对），以便将学习重点放在最有用的样本上。在我们的整个评估过程中，OPTune 的 LLM 保持了标准偏好调整提供的指令遵循优势，同时由于高效的数据探索策略，训练速度提高了 1.27-1.56 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.07657</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>MambaLRP：解释选择性状态空间序列模型</title>
      <link>https://arxiv.org/abs/2406.07592</link>
      <description><![CDATA[arXiv:2406.07592v1 公告类型：新
摘要：最近使用选择性状态空间序列模型（称为 Mamba 模型）的序列建模方法引起了人们的极大兴趣。这些模型可以在线性时间内高效处理长序列，并迅速被广泛采用，例如语言建模，表现出良好的性能。为了促进它们在现实世界场景中的可靠使用，增强它们的透明度至关重要。我们的工作通过将可解释性（尤其是分层相关性传播 (LRP)）引入 Mamba 架构来弥补这一关键差距。在相关性守恒公理的指导下，我们确定了 Mamba 架构中导致不忠实解释的特定组件。为了解决这个问题，我们提出了 MambaLRP，这是 LRP 框架内的一种新算法，可确保通过这些组件进行更稳定、更可靠的相关性传播。我们提出的方法在理论上是合理的，并且在各种模型和数据集中实现最先进的解释性能方面表现出色。此外，MambaLRP 有助于更深入地检查 Mamba 架构，发现各种偏差并评估其重要性。它还可以分析有关 Mamba 模型的长期能力的先前推测。]]></description>
      <guid>https://arxiv.org/abs/2406.07592</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:07 GMT</pubDate>
    </item>
    <item>
      <title>通过最小帧平均实现等变性，从而实现更多的对称性和效率</title>
      <link>https://arxiv.org/abs/2406.07598</link>
      <description><![CDATA[arXiv:2406.07598v1 公告类型：新
摘要：我们考虑通过帧平均在机器学习系统中实现等变性。当前的帧平均方法涉及对大帧进行昂贵的求和，或者依赖于仅产生近似等变性的基于采样的方法。在这里，我们提出了最小帧平均 (MFA)，这是一个用于构建可证明的最小帧的数学框架，这些帧完全等变。MFA 的一般基础还使我们能够将帧平均扩展到比以前考虑的更多的组，包括用于描述时空中对称性的 Lorentz 群和用于复值域的酉群。结果证明了通过 MFA 在各种任务中编码对称性的效率和有效性，包括 $n$ 体模拟、对撞机物理中的顶部标记和放松的能量预测。我们的代码可在 https://github.com/divelab/MFA 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.07598</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:07 GMT</pubDate>
    </item>
    <item>
      <title>StreamPrompt：可学习的提示引导数据选择，实现高效的流学习</title>
      <link>https://arxiv.org/abs/2406.07590</link>
      <description><![CDATA[arXiv:2406.07590v1 公告类型：新
摘要：流学习 (SL) 要求模型快速适应连续数据流，这与传统的持续学习 (CL) 不同。最近的 SL 方法通过选择数据子集进行训练来强调效率，但它们往往因依赖静态、基于规则的选择算法而苦苦挣扎，而这些算法无法有效适应数据不断变化的重要性。在这项工作中，我们介绍了 StreamPrompt，这是一种通过动态、可学习的提示增强数据选择的方法。这些动态提示除了指导模型推理外，还有两个目的：1) 优化数据选择，2) 指导排练缓冲区的更新。这种方法解决了处理连续数据流的适应性和计算效率的挑战。此外，StreamPrompt 引入了 Prompt Attunement，这是一种提高提示学习效率的机制。通过利用视觉转换器的注意层并将其输出与门单元软结合，Prompt Attunement 以最少的计算资源细化提示。综合评估表明，StreamPrompts 的性能优于最先进的技术，准确率显著提高，训练时间减少。这些结果强调了 StreamPrompt 的有效性和效率，确立了其作为可扩展且有效的解决方案的潜力，可满足 SL 不断变化的需求。我们的代码可在 https://github.com/intellistream/Efficient-Stream-Learning 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.07590</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:06 GMT</pubDate>
    </item>
    </channel>
</rss>