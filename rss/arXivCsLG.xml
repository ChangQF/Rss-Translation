<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 机器学习 (cs.LG) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Mon, 18 Dec 2023 03:15:00 GMT</lastBuildDate>
    <item>
      <title>利用对称时间稀疏 BPTT 进行高效 RNN 训练。 （arXiv：2312.09391v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09391</link>
      <description><![CDATA[循环神经网络 (RNN) 在时间序列任务中非常有用。
然而，训练 RNN 涉及密集矩阵乘法，这需要
可以支持大量算术运算和内存的硬件
访问。在边缘实施 RNN 在线训练需要优化
用于在硬件上高效部署的算法。受到尖峰的启发
神经元模型，Delta RNN 在推理过程中利用时间稀疏性
跳过那些失活神经元的隐藏状态更新
两个时间步长的激活变化低于定义的阈值。这
工作描述了一种利用时间的 Delta RNN 训练算法
后向传播阶段的稀疏性以减少计算需求
用于边缘训练。由于前向计算图的对称性
和训练期间的反向传播，梯度计算
可以跳过失活的神经元。结果显示，减少了 $\sim$80%
用于在 Fluent Speech 上训练 56k 参数 Delta LSTM 的矩阵运算
命令数据集的准确性损失可以忽略不计。硬件的逻辑模拟
专为训练算法设计的加速器在矩阵中显示出 2-10 倍的加速
计算激活稀疏度范围为 50%-90%。此外，我们还展示
所提出的 Delta RNN 训练对于在线增量很有用
在计算资源有限的边缘设备上学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.09391</guid>
      <pubDate>Mon, 18 Dec 2023 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>iOn-Profiler：带有强化学习的智能在线多目标 VNF 分析。 （arXiv：2312.09355v1 [cs.NI]）</title>
      <link>http://arxiv.org/abs/2312.09355</link>
      <description><![CDATA[利用虚拟化网络功能 (VNF) 的潜力需要
清楚地了解资源消耗和性能之间的联系。
当前的技术水平试图通过利用机器学习来做到这一点
(ML) 以及特定网络的监督学习 (SL) 模型
假设单目标优化目标的环境和 VNF 类型。
采用不同的方法提出了一种新颖的 VNF 分析器优化
使用适应的多资源类型分配和绩效目标
强化学习（RL）。我们的方法可以满足关键绩效指标
(KPI) 目标，同时最小化多资源类型消耗并优化
与现有单目标解决方案相比的 VNF 输出率。我们的
对总共 39 种现实世界中的三种 VNF 类型进行实验评估
研究场景（每个 VNF 13 个），针对三种资源类型（虚拟 CPU、内存、
和网络链路容量），验证资源分配的准确性
通过基准进行预测和相应的成功分析决策
我们的 RL 模型和 SL 模型之间的比较。我们还进行了补充
详尽的搜索空间研究揭示了不同资源的影响
每种 VNF 类型的性能都有所不同，这意味着有必要
多目标优化、每个 VNF 类型的个性化检查，以及
适应性强的在线档案学习，例如自主在线学习
iOn-Profiler 的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.09355</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>DSS：一种在课堂增量学习中保存知识的多样化样本选择方法。 （arXiv：2312.09357v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09357</link>
      <description><![CDATA[基于排练的技术通常用于减轻灾难性的后果
渐进学习（IL）中的遗忘（CF）。范例的质量
选择对于此目的很重要，并且大多数方法不能确保
所选范例的适当多样性。我们提出了一种新技术
“DSS”——从输入数据流中多样化选择样本
不相交和模糊任务下的类增量学习（CIL）设置
边界场景。我们的方法优于最先进的方法，并且
更容易理解和实施。
]]></description>
      <guid>http://arxiv.org/abs/2312.09357</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>RTRA：持续学习中基于正则化的方法的快速培训。 （arXiv：2312.09361v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09361</link>
      <description><![CDATA[灾难性遗忘（CF）是持续学习的重大挑战
（CL）。在基于正则化的缓解 CF 的方法中，需要修改
重要的训练参数在后续任务中使用
适当的损失函数。我们提出 RTRA，这是对广泛的
使用弹性权重合并（EWC）正则化方案，使用
用于损失函数优化的自然梯度。我们的方法改进了
在不牺牲测试数据的情况下训练基于正则化的方法
表现。我们使用以下方法将建议的 RTRA 方法与 EWC 进行比较：
iFood251 数据集。我们证明 RTRA 相对于最先进的技术具有明显的优势
接近。
]]></description>
      <guid>http://arxiv.org/abs/2312.09361</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>深度学习的现状和未来展望——2023 年。(arXiv:2312.09323v1 [cs.AI])</title>
      <link>http://arxiv.org/abs/2312.09323</link>
      <description><![CDATA[本系列的目标是记录该领域的观点和问题
机器学习的现状以及随着时间的推移而发生的变化。计划是
定期举办这项调查，直到人工智能奇点到来
回形针狂热驱动的世界末日，保留最新的热门问题列表
并采访每个版本的新社区成员。本期我们
调查了人们对可解释人工智能的看法，以及基准测试的价值
现代 NLP、理解深度学习的进展状况以及
学术界的未来。
]]></description>
      <guid>http://arxiv.org/abs/2312.09323</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>上下文强盗的分层最近邻方法。 （arXiv：2312.09332v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09332</link>
      <description><![CDATA[在本文中，我们考虑度量中的对抗性上下文强盗问题
空间。论文“Nearest Neighbor with Bandit Feedback”解决了这个问题
但是当比较器的决策边界附近有很多上下文时
政策使其遭受高度遗憾。在本文中，我们消除了这个问题，
设计一种算法，在该算法中我们可以在以下情况下保留任何上下文集：
计算我们的遗憾项。我们的算法建立在“最近邻居
具有强盗反馈”，因此继承了其极高的计算效率。
]]></description>
      <guid>http://arxiv.org/abs/2312.09332</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>PBES：基于 PCA 的持续学习示例采样算法。 （arXiv：2312.09352v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09352</link>
      <description><![CDATA[我们提出了一种基于主成分的新颖样本选择方法
分析（PCA）和中值采样，以及神经网络训练机制
课堂增量学习的设置。这种方法避免了由于以下原因而导致的陷阱
数据中的异常值，并且易于在各种不同的环境中实现和使用
增量机器学习模型。它也有独立的用途作为
采样算法。与最先进的技术相比，我们取得了更好的性能
方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.09352</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>权重亚克隆：使用较大的预训练变压器直接初始化变压器。 （arXiv：2312.09299v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09299</link>
      <description><![CDATA[为目标任务从头开始训练大型变压器模型需要
数据量大，计算量大。转让的通常做法
学习通过使用权重初始化模型来克服这一挑战
预训练相同尺寸和规格的模型以增加收敛性
和训练速度。但是，如果没有所需大小的预训练模型怎么办
有空吗？在本文中，我们介绍了一种简单而有效的技术
将预训练模型的知识转移到更小的变体。我们的方法
称为权重亚克隆的方法可加快按比例缩小的变压器的训练
从更大的预训练模型初始化它们的权重。

权重亚克隆涉及对预训练模型进行操作以获得
等效初始化的缩小模型。它包括两个关键步骤：首先，
我们引入神经元重要性排序来减少每个神经元的嵌入维度
预训练模型中的层。然后，我们从变压器中删除块
模型以匹配缩小网络中的层数。结果是
网络准备好接受培训，这在以下方面取得了显着改进
与随机初始化相比的训练速度。例如，我们实现了 4x
更快地训练图像分类和语言方面的视觉转换器
为下一个代币预测而设计的模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.09299</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>自我评估提高了大型语言模型中的选择性生成。 （arXiv：2312.09300v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.09300</link>
      <description><![CDATA[大型语言模型 (LLM) 的安全部署可能会受益于可靠的
评估其生成内容以确定何时放弃或放弃的方法
选择性地生成。虽然基于可能性的指标（例如困惑度）
广泛应用，最近的研究表明使用的局限性
法学硕士给出的序列水平概率估计作为可靠的指标
一代品质。相反，法学硕士在以下方面表现出了很强的校准能力：
令牌级别，特别是在选择正确答案时
多项选择题或评估真/假陈述。在这项工作中，我们
将开放式生成任务重新表述为代币级别的预测任务，以及
利用法学硕士在代币层面的卓越校准。我们指导法学硕士
自我评估其答案，采用多向比较或
逐点评估方法，可以选择包括“没有一个”
上述”选项明确表达模型的不确定性。我们对标
一系列基于自我评价的评分方法并评估他们的
使用 TruthfulQA 和 TL;DR 进行选择性生成的性能。通过
通过 PaLM-2 和 GPT-3 的实验，我们证明了基于自我评估的方法
分数不仅提高准确性，而且与整体更好地相关
生成内容的质量。
]]></description>
      <guid>http://arxiv.org/abs/2312.09300</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>具有大量标签的多标签文本分类的经过良好校准的置信度测量。 （arXiv：2312.09304v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09304</link>
      <description><![CDATA[我们将之前的归纳保形预测 (ICP) 工作扩展到
多标签文本分类并提出了一种解决该问题的新方法
Label Powerset (LP) ICP 的计算效率低下，出现在
处理大量独特的标签。我们展示实验结果
使用原始的和提议的高效 LP-ICP 来处理两个英语和一个
捷克语数据集。具体来说，我们将 LP-ICP 应用于三个深度
人工神经网络 (ANN) 分类器有两种类型：一种基于
上下文化（bert）和两个非上下文化（word2vec）词嵌入。
在 LP-ICP 设置中，我们将不合格分数分配给标签集，其中
确定相应的 p 值和预测集。我们的方法
通过消除来处理 LP 增加的计算负担
考虑大量肯定具有 p 值的标签集
低于指定的显着性水平。这大大减少了
该方法的计算复杂性，同时充分尊重标准 CP
保证。我们的实验结果表明，基于情境的
分类器超越了基于非上下文的分类器并获得
所有检查的数据集均具有最先进的性能。良好的表现
底层分类器的 ICP 对应项无需
任何显着的精度损失，但具有 ICP 的额外优势，即
封装在预测集中的置信信息。我们实验性地
证明所得到的预测集可以足够严格
尽管所有可能的标签集包含更多内容，但实际上很有用
比 $1e+16$ 组合。此外，经验错误率
获得的预测集证实我们的输出经过良好校准。
]]></description>
      <guid>http://arxiv.org/abs/2312.09304</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>基于随机电阻记忆的深度极值点学习机，用于统一视觉处理。 （arXiv：2312.09262v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.09262</link>
      <description><![CDATA[视觉传感器，包括 3D LiDAR、神经形态 DVS 传感器和
传统的帧相机越来越多地集成到边缘侧
智能机器。直接实现密集的多感官数据分析
边缘智能机器对于众多新兴边缘至关重要
应用，例如增强现实和虚拟现实以及无人机
车辆，这需要统一的数据表示，这是前所未有的
硬件能效和快速模型训练。然而，多感官
数据本质上是异构的，导致了显着的复杂性
边缘侧智能机器的系统开发。除此之外
传统数字硬件的性能受到物理条件的限制
分离的处理单元和内存单元，称为冯·诺依曼瓶颈，以及
晶体管缩放的物理极限，这有助于减慢
摩尔定律。繁琐的训练进一步加剧了这些限制
尺寸不断增加的模型。我们提出了一种新颖的硬件软件
共同设计，基于随机电阻记忆的深度极值点学习机
(DEPLM)，提供高效的统一点集分析。我们展示系统的
跨各种数据模式和两种不同学习任务的多功能性。
与传统的基于数字硬件的系统相比，我们的协同设计系统
实现巨大的能源效率提高和培训成本降低
与传统系统相比。我们基于随机电阻存储器的深度
极值点学习机可能为节能和
跨各种数据模式和任务的训练友好型边缘人工智能。
]]></description>
      <guid>http://arxiv.org/abs/2312.09262</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>基于神经变压器的巴西葡萄牙语语音声学模型。 （arXiv：2312.09265v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.09265</link>
      <description><![CDATA[声学模型，经过大量未标记数据的训练，
由自我监督学习的语音表示组成，可用于解决
下游任务，也许在对各自的模型进行微调之后
下游任务。在这项工作中，我们建立了巴西的声学模型
通过 Transformer 神经网络进行葡萄牙语语音。这个模型是
使用超过 800 小时的巴西葡萄牙语语音进行预训练
预训练技术的组合。使用收集的标记数据集
检测巴西葡萄牙语使用者的呼吸功能不全，我们
针对以下任务微调预训练的 Transformer 神经网络：
呼吸功能不全检测、性别识别和年龄组
分类。我们比较了预训练 Transformer 在这些方面的性能
任务与 Transformers 的任务没有事先预训练，注意到
巨大的进步。尤其是呼吸系统的表现
不足检测获得了迄今为止最好的报告结果，表明
这种声学模型作为语音生物标记的有前途的工具
方法。此外，性别识别的表现与
最先进的英语模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.09265</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用声学识别和知识蒸馏对环境音频进行有效的语音检测。 （arXiv：2312.09269v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.09269</link>
      <description><![CDATA[由土地利用变化等因素驱动的持续的生物多样性危机
和全球变暖，强调有效生态监测的必要性
方法。生物多样性的声学监测已成为重要的监测手段
监控工具。在音景监控项目中检测人声是
对于分析人为干扰和隐私过滤都很有用。尽管
近年来深度学习取得了重大进展，大规模部署
紧凑型设备上的神经网络因内存和延迟而面临挑战
限制。我们的方法侧重于利用知识蒸馏
设计高效、轻量级语音检测学生模型的技术
在生物声学中。特别是，我们采用 MobileNetV3-Small-Pi 模型来
创建紧凑而有效的学生架构以与
更大的 EcoVAD 教师模型，一种备受推崇的语音检测架构
生态声学监测。比较分析包括检查各种
MobileNetV3-Small-Pi 派生学生模型的配置以识别
最佳性能。此外，对不同的情况进行全面评估
进行蒸馏技术以确定最有效的方法
用于型号选择。我们的研究结果表明，蒸馏模型表现出
与 EcoVAD 教师模型的性能相当，表明有希望
克服实时生态计算障碍的方法
监控。
]]></description>
      <guid>http://arxiv.org/abs/2312.09269</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>受大脑启发的机器智能：神经生物学上合理的信用分配调查。 （arXiv：2312.09257v1 [cs.NE]）</title>
      <link>http://arxiv.org/abs/2312.09257</link>
      <description><![CDATA[在这项调查中，我们研究了在以下领域进行学分分配的算法：
受神经生物学启发或激发的人工神经网络，
将这些不同的过程统一在一种可能的分类法下。我们提出的
分类法是基于学习算法如何回答中心问题而构建的
支持复杂适应性突触可塑性机制的问题
神经元系统：驱动个体学习的信号在哪里
网络的要素从何而来以及如何产生？在这个统一的
治疗中，我们组织了不断增长的脑启发学习
过程分为六个一般家族，并在以下背景下考虑它们：
错误的反向传播及其已知的批评。本次审核结果
旨在鼓励神经模拟系统及其相关技术的未来发展
构成学习过程，其中存在建立强大的机会
机器学习、计算神经科学和认知之间的桥梁
科学。
]]></description>
      <guid>http://arxiv.org/abs/2312.09257</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>牲畜饲养行为：反刍动物监测自动化技术的教程回顾。 （arXiv：2312.09259v1 [eess.SP]）</title>
      <link>http://arxiv.org/abs/2312.09259</link>
      <description><![CDATA[牲畜饲养行为对于相关人员来说是一个有影响力的研究领域
在畜牧业和农业方面。近年来，有越来越多的
对监测反刍动物行为的自动化系统感兴趣。尽管
就过去十年所取得的进展而言，仍有许多工作要做
了解测量和分析牲畜饲养行为的方法。
自动化监控系统主要使用运动、声音和图像传感器来
收集动物行为数据。现有方法的性能评估
这是一项复杂的任务，研究之间的直接比较很困难。一些
从数据的多样性开始，因素阻碍了直接比较
实验中使用的性能指标。据我们所知，这
作品代表了对喂养分析的第一个教程式回顾
反刍动物的行为，强调感觉之间的关系
方法论、信号处理和计算智能方法。它
评估主要传感方法（即基于运动、声音、
图像/视频和压力）以及测量和分析的主要技术
与进食行为相关的信号，评估它们在不同情况下的使用
设置和情况。它还凸显了自动化的潜力
监控系统提供有价值的信息，改善我们的
了解牲畜的饲养行为。这些系统的相关性是
由于它们对生产系统和研究的影响而变得越来越重要。
最后，本文最后讨论了未来的挑战和机遇
牲畜饲养行为监测。
]]></description>
      <guid>http://arxiv.org/abs/2312.09259</guid>
      <pubDate>Mon, 18 Dec 2023 03:14:55 GMT</pubDate>
    </item>
    </channel>
</rss>