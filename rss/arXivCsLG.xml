<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 18 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>揭开感应头的面纱：Transformer 中可证明的训练动力学和特征学习</title>
      <link>https://arxiv.org/abs/2409.10559</link>
      <description><![CDATA[arXiv:2409.10559v1 公告类型：新
摘要：上下文学习 (ICL) 是大型语言模型 (LLM) 功能的基石，但由于 Transformer 架构的复杂性，其理论基础仍然难以捉摸。特别是，大多数现有工作仅在理论上解释了注意力机制如何在某些数据模型下促进 ICL。目前尚不清楚 Transformer 的其他构建块如何为 ICL 做出贡献。为了解决这个问题，我们研究了如何训练一个两注意力层 Transformer 对 $n$-gram 马尔可夫链数据执行 ICL，其中马尔可夫链中的每个标记在统计上都依赖于前 $n$ 个标记。我们分析了一个复杂的 Transformer 模型，该模型具有相对位置嵌入、多头 softmax 注意力和带规范化的前馈层。我们证明，关于交叉熵 ICL 损失的梯度流收敛到一个极限模型，该模型执行具有学习特征的感应头机制的广义版本，这是所有构建块一致贡献的结果。在极限模型中，第一个注意层充当 $\mathit{复印机}$，将给定窗口内的过去标记复制到每个位置，而具有规范化的前馈网络充当 $\mathit{选择器}$，它仅通过查看窗口中信息相关的父级来生成特征向量。最后，第二个注意层是一个 $\mathit{分类器}$，它将这些特征与输出位置的特征进行比较，并使用得到的相似度分数来生成所需的输出。我们的理论通过实验得到了进一步的验证。]]></description>
      <guid>https://arxiv.org/abs/2409.10559</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>尤里卡：评估和理解大型基础模型</title>
      <link>https://arxiv.org/abs/2409.10566</link>
      <description><![CDATA[arXiv:2409.10566v1 公告类型：新
摘要：严格且可重复的评估对于评估最新技术水平和指导人工智能的科学进步至关重要。由于多种原因，评估在实践中具有挑战性，包括基准饱和、用于测量的方法缺乏透明度、提取生成任务的测量值的开发挑战，以及更普遍地说，对模型进行全面比较所需的大量功能。我们为缓解上述挑战做出了三项贡献。首先，我们提出了 Eureka，这是一个开源框架，用于标准化大型基础模型的评估，而不仅仅是单一分数报告和排名。其次，我们引入了 Eureka-Bench 作为基准测试功能的可扩展集合，这些功能 (i) 对于最先进的模型来说仍然具有挑战性，(ii) 代表了基本但被忽视的语言和多模式功能。非饱和基准测试中固有的改进空间使我们能够在能力层面发现模型之间的有意义差异。第三，我们使用 Eureka 对 12 个最先进的模型进行了分析，深入了解了故障理解和模型比较，可以利用这些见解来规划有针对性的改进。与报告和排行榜中显示绝对排名并声称某个模型是最好的趋势相反，我们的分析表明，没有最好的模型。不同的模型有不同的优势，但有些模型比其他模型更经常出现在某些功能上表现最佳。尽管最近有所改进，但当前的模型仍然难以掌握几个基本功能，包括详细的图像理解、在可用时从多模式输入中受益而不是完全依赖语言、事实性和信息检索基础以及过度拒绝。]]></description>
      <guid>https://arxiv.org/abs/2409.10566</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保护医学预训练语言模型的版权：无需训练的后门水印</title>
      <link>https://arxiv.org/abs/2409.10570</link>
      <description><![CDATA[arXiv:2409.10570v1 公告类型：新
摘要：预训练语言模型，然后针对特定任务进行微调是 NLP 中的标准做法，但传统模型在应用于医学领域时往往表现不佳，这导致了专门的医学预训练语言模型 (Med-PLM) 的开发。这些模型是宝贵的资产，但容易被滥用和盗窃，需要版权保护。然而，现有的水印方法都不是专门为 Med-PLM 量身定制的，将通用 PLM 水印技术应用于医学领域面临着任务不兼容、保真度损失和效率低下等挑战。为了解决这些问题，我们提出了第一个无需训练的 Med-PLM 后门水印方法。我们的方法使用罕见的特殊符号作为触发词，这些符号不会影响下游任务的性能，通过在 Med-PLM 的词嵌入层中用特定医学术语的嵌入替换其原始嵌入来嵌入水印。在各种医学下游任务上对带水印的 Med-PLM 进行微调后，最终模型 (FM) 对触发词的响应方式与对相应医学术语的响应方式相同。此属性可用于提取水印。实验表明，我们的方法在各种医学下游任务中有效提取水印的同时实现了高保真度。此外，我们的方法对各种攻击具有很强的鲁棒性，并显著提高了水印嵌入的效率，将嵌入时间从 10 小时缩短到 10 秒。]]></description>
      <guid>https://arxiv.org/abs/2409.10570</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ASFT：通过绝对似然法进行对齐监督微调</title>
      <link>https://arxiv.org/abs/2409.10571</link>
      <description><![CDATA[arXiv:2409.10571v1 公告类型：新
摘要：直接偏好优化 (DPO) 是一种通过直接优化结果的偏好或排名来提高模型性能的方法，而不是传统的损失函数。这种方法已被证明可以有效地将大型语言模型 (LLM) 与人类偏好保持一致。尽管 DPO 广泛应用于各种任务，但它因对监督微调 (SFT) 的有效性的敏感性以及在使模型学习人类偏好的反应方面的局限性而受到批评，导致性能不太令人满意。为了解决这些限制，我们提出了对齐监督微调 (ASFT)，这是一种有效的方法，它通过优化每个响应的绝对可能性而不是使用 Bradley-Terry 模型来更好地将 LLM 与成对数据集对齐，并且消除了对参考模型的需求。通过理论梯度分析，我们证明 ASFT 可以缓解 DPO 损失函数降低生成人类不喜欢的数据的概率的速度比增加生成喜欢的数据的概率更快的问题。此外，我们使用最新的指令调整模型 Llama3（已在 UltraFeedback 和 HH-RLHF 上进行了微调）将 ASFT 与 DPO 及其最新变体（例如单步方法 ORPO）进行了比较。我们在 MT-Bench 等指令跟踪基准和 BLEU-4 和 ROUGE-L 等传统文本生成指标上评估了性能。大量实验表明 ASFT 是一种有效的对齐方法，其表现始终优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2409.10571</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医学基础模型的验证数据科学</title>
      <link>https://arxiv.org/abs/2409.10580</link>
      <description><![CDATA[arXiv:2409.10580v1 公告类型：新
摘要：大型语言模型 (LLM) 等基础模型 (FM) 的出现导致了医学和其他领域数据科学的文化转变。这种转变涉及从针对特定、定义明确的领域问题训练的专门预测模型转向对大量非结构化数据进行预训练的通用 FM，然后可以将其适应各种临床任务和问题。因此，医学中的标准数据科学工作流程发生了根本性的改变；基础模型生命周期 (FMLC) 现在包括不同的上游和下游流程，其中计算资源、模型和数据访问以及决策权分布在多个利益相关者之间。从本质上讲，FM 基本上是统计模型，这种新的工作流程挑战了 Veridical 数据科学 (VDS) 的原则，阻碍了透明和科学可重复的数据科学实践中期望的严格统计分析。我们根据 VDS 的核心原则（可预测性、可计算性和稳定性 (PCS)）批判性地审视医疗 FMLC，并解释它与标准数据科学工作流程的不同之处。最后，我们提出了重新构想医疗 FMLC 的建议，该建议扩展和完善了 VDS 的 PCS 原则，包括考虑 FM 固有的计算和可访问性限制。]]></description>
      <guid>https://arxiv.org/abs/2409.10580</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用拟双曲贴现进行强化学习</title>
      <link>https://arxiv.org/abs/2409.10583</link>
      <description><![CDATA[arXiv:2409.10583v1 公告类型：新
摘要：传统上，强化学习一直采用指数折扣或平均奖励设置进行研究，这主要是因为它们易于数学处理。然而，这种框架无法准确捕捉人类行为，因为人类行为倾向于即时满足。拟双曲线 (QH) 折扣是一种简单的替代方法来模拟这种偏见。然而，与传统折扣不同，从某个时间 $t_1,$ 开始的最佳 QH 策略可能与从 $t_2$ 开始的最佳 QH 策略不同。因此，如果代理的未来自我是天真的或不耐烦的，它可能会偏离一开始的最佳策略，导致整体回报次优。为了防止这种行为，另一种方法是使用锚定在马尔可夫完美均衡 (MPE) 中的策略。在这项工作中，我们提出了第一个用于寻找 MPE 的无模型算法。使用双时间尺度分析，我们表明，如果我们的算法收敛，那么极限一定是 MPE。我们还针对具有随机需求的标准库存系统对这一说法进行了数值验证。我们的工作大大推进了强化学习的实际应用。]]></description>
      <guid>https://arxiv.org/abs/2409.10583</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于模型的风险最小化进行运动预测</title>
      <link>https://arxiv.org/abs/2409.10585</link>
      <description><![CDATA[arXiv:2409.10585v1 公告类型：新 
摘要：预测周围代理的未来轨迹对于自动驾驶汽车确保安全、高效和舒适的路线规划至关重要。虽然模型集成提高了各个领域的预测精度，但由于预测的多模态性质，其在轨迹预测中的应用受到限制。在本文中，我们提出了一种基于多种模型预测的适用于轨迹预测的新型采样方法。我们首先表明，基于预测概率的传统采样会由于模型之间缺乏对齐而降低性能。为了解决这个问题，我们引入了一种从一组神经网络中生成最佳轨迹的新方法，将其定义为具有可变损失函数的风险最小化问题。通过使用最先进的模型作为基础学习者，我们的方法构建了多样化且有效的集成以实现最佳轨迹采样。在 nuScenes 预测数据集上进行的大量实验表明，我们的方法超越了当前最先进的技术，在排行榜上名列前茅。我们还对集成策略进行了全面的实证研究，深入了解了其有效性。我们的研究结果凸显了先进的集成技术在轨迹预测方面的潜力，显著提高了预测性能，并为更可靠的预测轨迹铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.10585</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>离线强化学习用于车间作业调度</title>
      <link>https://arxiv.org/abs/2409.10589</link>
      <description><![CDATA[arXiv:2409.10589v1 公告类型：新
摘要：车间作业调度问题 (JSSP) 是一个复杂的组合优化问题。人们对使用在线强化学习 (RL) 解决 JSSP 的兴趣日益浓厚。虽然在线 RL 可以快速找到可接受的解决方案，尤其是对于较大的问题，但它产生的结果质量低于约束编程 (CP) 等传统方法。在线 RL 的一个显着缺点是它无法从现有数据（例如从 CP 生成的解决方案）中学习，需要从头开始训练，导致样本效率低下，并使它们无法从更优化的示例中学习。我们引入了离线强化学习以学习调度 (Offline-LD)，这是一种解决这些限制的 JSSP 新方法。Offline-LD 为可屏蔽动作空间采用了两种基于 CQL 的 Q 学习方法（mQRDQN 和离散 mSAC），为离散 SAC 引入了新的熵奖励修改，并通过预处理利用了奖励规范化。我们的实验表明，离线 LD 在生成实例和基准实例上的表现均优于在线 RL。通过在数据集中引入噪声，我们获得了与专家数据集相似或更好的结果，这表明更多样化的训练集是可取的，因为它包含反事实信息。]]></description>
      <guid>https://arxiv.org/abs/2409.10589</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CSKV：长上下文场景下 KV 缓存的训练高效通道收缩</title>
      <link>https://arxiv.org/abs/2409.10593</link>
      <description><![CDATA[arXiv:2409.10593v1 公告类型：新 
摘要：大型语言模型（LLM）已被广泛用于处理长上下文任务。然而，键值（KV）缓存的大量内存开销在长上下文场景中带来了重大挑战。现有的无训练KV缓存压缩方法通常侧重于量化和标记剪枝，这存在压缩限制，过度的稀疏性会导致严重的性能下降。其他方法设计了具有较少KV开销的新架构，但需要大量的训练开销。为了解决上述两个缺点，我们进一步探索了通道维度中的冗余，并应用了具有较小训练成本的架构级设计。因此，我们引入了CSKV，一种用于KV缓存压缩的训练效率高的通道收缩技术：（1）我们首先分析KV缓存的奇异值分布，揭示了沿通道维度的显着冗余和压缩潜力。基于此观察，我们建议对键和值层使用低秩分解并存储低维特征。（2）为了保持模型性能，我们引入了双分支 KV 缓存，包括基于窗口的全精度 KV 缓存和低精度压缩 KV 缓存。（3）为了降低训练成本，我们最小化了压缩 KV 缓存的逐层重构损失，而不是重新训练整个 LLM。大量实验表明，CSKV 可以将 KV 缓存的内存开销减少 80%，同时保持模型的长上下文能力。此外，我们表明我们的方法可以无缝与量化结合，以进一步减少内存开销，实现高达 95% 的压缩率。]]></description>
      <guid>https://arxiv.org/abs/2409.10593</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>柯尔莫哥洛夫-阿诺德变压器</title>
      <link>https://arxiv.org/abs/2409.10594</link>
      <description><![CDATA[arXiv:2409.10594v1 公告类型：新 
摘要：Transformer 是现代深度学习的基石。传统上，这些模型依赖于多层感知器 (MLP) 层来混合通道之间的信息。在本文中，我们介绍了 Kolmogorov-Arnold Transformer (KAT)，这是一种新颖的架构，它用 Kolmogorov-Arnold 网络 (KAN) 层替换 MLP 层，以增强模型的表现力和性能。然而，将 KAN 集成到 Transformer 中并非易事，尤其是在扩大规模时。具体来说，我们确定了三个关键挑战：(C1) 基函数。KAN 中使用的标准 B 样条函数并未针对现代硬件上的并行计算进行优化，导致推理速度变慢。(C2) 参数和计算效率低下。KAN 要求每个输入输出对都有一个唯一的函数，这使得计算量非常大。(C3) 权重初始化。 KAN 中权重的初始化尤其具有挑战性，因为它们具有可学习的激活函数，而激活函数对于实现深度神经网络的收敛至关重要。为了克服上述挑战，我们提出了三个关键解决方案：（S1）有理基础。我们用有理函数替换 B 样条函数，以提高与现代 GPU 的兼容性。通过在 CUDA 中实现这一点，我们实现了更快的计算。（S2）组 KAN。我们通过一组神经元共享激活权重，以在不牺牲性能的情况下减少计算负荷。（S3）方差保留初始化。我们仔细初始化激活权重，以确保激活方差在各层之间保持不变。通过这些设计，KAT 可以有效扩展，并且轻松超越传统的基于 MLP 的 Transformer。]]></description>
      <guid>https://arxiv.org/abs/2409.10594</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应低秩适应的贝叶斯解释</title>
      <link>https://arxiv.org/abs/2409.10673</link>
      <description><![CDATA[arXiv:2409.10673v1 公告类型：新
摘要：受自适应低秩自适应 (AdaLoRA) 的基于灵敏度的重要性得分的启发，我们利用更多理论支持的指标，包括信噪比 (SNR)，以及改进的变分在线牛顿 (IVON) 优化器，进行自适应参数预算分配。由此产生的贝叶斯对应物不仅匹配或超越了使用基于灵敏度的重要性度量的性能，而且还是使用 Adam 的 AdaLoRA 的更快替代方案。我们的理论分析揭示了这两个指标之间的重要联系，为灵敏度作为重要性得分的有效性提供了贝叶斯视角。此外，我们的研究结果表明，幅度而不是方差是参数重要性的主要指标。]]></description>
      <guid>https://arxiv.org/abs/2409.10673</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻飞行员学员压力和疲劳建模中的性别偏见</title>
      <link>https://arxiv.org/abs/2409.10676</link>
      <description><![CDATA[arXiv:2409.10676v1 公告类型：新
摘要：虽然研究人员一直在试图了解飞行员，特别是飞行员学员的压力和疲劳，并开发压力/疲劳模型来自动化检测压力/疲劳的过程，但他们通常不会考虑这些模型中的性别等偏见。然而，在航空业这样重要的职业中，人口分布不成比例地偏向某一性别，迫切需要减轻偏见，以实现公平和安全的模型预测。在这项工作中，我们调查了 69 名大学生的感知压力/疲劳，其中包括 40 名飞行员学员，其中约 63% 为男性。我们首先使用决策树构建模型，没有偏差缓解，然后使用具有人口奇偶校验和均衡几率约束的阈值优化器使用随机实例构建偏差缓解模型 30 次。通过偏差缓解，我们实现了 88.31%（人口奇偶差异）和 54.26%（均等优势差异）的改善，这也被发现具有统计学意义。]]></description>
      <guid>https://arxiv.org/abs/2409.10676</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻音频数据驱动的 COPD 和 COVID-19 呼吸模式检测模型中的性别偏见</title>
      <link>https://arxiv.org/abs/2409.10677</link>
      <description><![CDATA[arXiv:2409.10677v1 公告类型：新
摘要：在医疗保健行业，研究人员一直在开发机器学习模型，以根据患者的呼吸模式自动诊断呼吸系统疾病患者。然而，这些模型没有考虑到人口统计学偏见，尤其是性别偏见，这种偏见经常发生在使用有偏差的患者数据集训练模型时。因此，在如此重要的行业中，减少这种偏见至关重要，这样模型才能做出公平的诊断。在这项工作中，我们研究了用于检测两种主要呼吸系统疾病（即慢性阻塞性肺病 (COPD) 和 COVID-19）呼吸模式的模型中的偏见。使用从两个开源数据集（包括 29 名 COPD 和 680 名 COVID-19 阳性患者）获得的呼吸模式录音训练的决策树模型，我们分析了性别偏见对模型的影响。使用阈值优化器和两个约束（人口奇偶性和均等赔率）来缓解偏差，我们观察到 81.43%（人口奇偶性差异）和 71.81%（均等赔率差异）的改善。这些发现具有统计学意义。]]></description>
      <guid>https://arxiv.org/abs/2409.10677</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 缓解自适应交通信号控制中的部分可观测性</title>
      <link>https://arxiv.org/abs/2409.10693</link>
      <description><![CDATA[arXiv:2409.10693v1 公告类型：新
摘要：高效的交通信号控制对于管理城市交通、最大限度地减少拥堵、提高安全性和可持续性至关重要。强化学习 (RL) 已成为增强自适应交通信号控制 (ATSC) 系统的一种有前途的方法，允许控制器通过与环境的交互来学习最佳策略。然而，由于交通网络中的部分可观测性 (PO)，代理的可见性有限，阻碍了有效性，因此出现了挑战。本文介绍了将基于 Transformer 的控制器集成到 ATSC 系统中以有效解决 PO。我们提出了提高训练效率和有效性的策略，在现实场景中展示了改进的协调能力。结果展示了基于 Transformer 的模型从历史观察中捕获重要信息的能力，从而可以制定更好的控制策略并改善交通流量。这项研究强调了利用先进的 Transformer 架构来加强城市交通管理的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.10693</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分布转移下分散式深度学习中相似性度量的影响</title>
      <link>https://arxiv.org/abs/2409.10720</link>
      <description><![CDATA[arXiv:2409.10720v1 公告类型：新
摘要：去中心化学习 (DL) 使组织或用户之间能够进行隐私保护协作，从而提高本地深度学习模型的性能。但是，当客户端数据是异构的时，模型聚合变得具有挑战性，并且在没有直接数据交换的情况下识别兼容的协作者仍然是一个紧迫的问题。在本文中，我们研究了 DL 中各种相似性指标在识别模型合并的对等点方面的有效性，并对具有分布变化的多个数据集进行了实证分析。我们的研究提供了对这些指标性能的见解，研究了它们在促进有效协作方面的作用。通过探索这些指标的优势和局限性，我们为开发强大的 DL 方法做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2409.10720</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>