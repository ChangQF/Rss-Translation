<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>微型机器学习：进步与未来</title>
      <link>https://arxiv.org/abs/2403.19076</link>
      <description><![CDATA[arXiv:2403.19076v1 公告类型：新
摘要：微型机器学习（TinyML）是机器学习的新领域。通过将深度学习模型压缩到数十亿个物联网设备和微控制器 (MCU) 中，我们扩大了人工智能应用的范围并实现了无处不在的智能。然而，由于硬件限制，TinyML 具有挑战性：微小的内存资源使得很难保存为云和移动平台设计的深度学习模型。对裸机设备的编译器和推理引擎支持也很有限。因此，我们需要共同设计算法和系统堆栈来启用TinyML。在这篇评论中，我们将首先讨论 TinyML 的定义、挑战和应用。然后，我们调查了 TinyML 和 MCU 深度学习的最新进展。接下来，我们将介绍MCUNet，展示如何通过系统算法协同设计在物联网设备上实现ImageNet规模的AI应用。我们将进一步将解决方案从推理扩展到训练，并引入微小的设备端训练技术。最后，我们提出了该领域的未来方向。今天的大型模型可能是明天的小型模型。 TinyML 的范围应该随着时间的推移而发展和适应。]]></description>
      <guid>https://arxiv.org/abs/2403.19076</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>通过过度拟合屏蔽自动编码器检测生成鹦鹉学舌</title>
      <link>https://arxiv.org/abs/2403.19050</link>
      <description><![CDATA[arXiv:2403.19050v1 公告类型：新
摘要：生成式人工智能模型的出现彻底改变了数字内容创作，但由于生成式模仿，模型过于模仿其训练数据，因此在维护版权完整性方面带来了挑战。我们的研究提出了一种解决这个问题的新方法，即采用过度拟合的掩蔽自动编码器（MAE）来有效检测此类重复样本。我们根据整个训练数据集的平均损失建立一个检测阈值，从而可以精确识别修改后的数据集中的重复内容。初步评估显示出有希望的结果，表明我们的方法有潜力确保道德使用并提高生成模型的法律合规性。]]></description>
      <guid>https://arxiv.org/abs/2403.19050</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健公平：分析机器学习预测糖尿病患者再入院的差异</title>
      <link>https://arxiv.org/abs/2403.19057</link>
      <description><![CDATA[arXiv:2403.19057v1 公告类型：新
摘要：本研究调查了机器学习 (ML) 模型如何公平、准确地预测不同人口统计数据（年龄、性别、种族）的糖尿病患者的再入院情况。我们比较了深度学习、广义线性模型、梯度提升机 (GBM) 和朴素贝叶斯等模型。 GBM 的 F1 分数为 84.3%，准确度为 82.2%，准确预测了不同人群的再入院情况。对所有模型进行了公平性分析。 GBM 最大限度地减少了预测差异，实现了跨性别和种族的平衡结果。结果显示，男女的错误发现率 (FDR) (6-7%) 和假阳性率 (FPR) (5%) 都很低。此外，非裔美国人 (8%) 和亚洲人 (7%) 等种族群体的 FDR 仍然较低。同样，对于 40 岁以下和 40 岁以上的患者，FPR 在各个年龄组中都是一致的 (4%)，这表明其精度和减少偏差的能力。这些发现强调了仔细选择机器学习模型的重要性，以确保所有患者的准确性和公平性。通过展示具有公平性指标的各种模型的有效性，这项研究促进了个性化医疗以及医疗保健领域对公平机器学习算法的需求。这最终可以减少差异并改善各种背景的糖尿​​病患者的治疗结果。]]></description>
      <guid>https://arxiv.org/abs/2403.19057</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>利用动力学中的对称性进行基于模型的具有不对称奖励的强化学习</title>
      <link>https://arxiv.org/abs/2403.19024</link>
      <description><![CDATA[arXiv:2403.19024v1 公告类型：新
摘要：强化学习领域的最新工作利用模型中的对称性来提高策略训练的样本效率。一个常用的简化假设是动态和奖励都表现出相同的对称性。然而，在许多现实环境中，动态模型表现出独立于奖励模型的对称性：奖励可能不满足与动态相同的对称性。在本文中，我们研究了仅假设动力学表现出对称性的场景，扩展了强化学习和控制理论学习中可以应用对称技术的问题范围。我们使用嘉当的移动框架方法来介绍一种学习动力学的技术，通过构造，该技术表现出特定的对称性。我们通过数值实验证明所提出的方法可以学习更准确的动力学模型。]]></description>
      <guid>https://arxiv.org/abs/2403.19024</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>使用方向感知 t-SNE 可视化高维时态数据</title>
      <link>https://arxiv.org/abs/2403.19040</link>
      <description><![CDATA[arXiv:2403.19040v1 公告类型：新
摘要：许多现实世界的数据集包含时间成分或涉及从状态到状态的转换。对于探索性数据分析，我们可以使用探索中的数据对象的嵌入并用有向边表示它们的时间关系，在二维图中表示这些高维数据集。大多数现有的降维技术，例如 t-SNE 和 UMAP，在构建嵌入时没有考虑数据的时间或关系性质，导致时间上混乱的可视化，从而掩盖了潜在有趣的模式。为了解决这个问题，我们在 t-SNE 的优化函数中提出了两个互补的方向感知损失项，它们强调数据的时间方面，指导优化和由此产生的嵌入，以揭示可能被忽视的时间模式。方向相干损失 (DCL) 鼓励连接两个相邻时间序列点的附近箭头指向同一方向，而边缘长度损失 (ELL) 根据箭头的长度来惩罚箭头 - 箭头有效地表示可视化嵌入中的时间间隙。两个损失项都是可微分的，并且可以很容易地合并到现有的降维技术中。通过促进有向边缘的局部方向性，我们的程序产生了更具时间意义和更少混乱的可视化。我们在一个玩具数据集和两个现实世界数据集上展示了我们的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19040</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>迈向可持续的 SecureML：量化对抗性机器学习的碳足迹</title>
      <link>https://arxiv.org/abs/2403.19009</link>
      <description><![CDATA[arXiv:2403.19009v1 公告类型：新
摘要：机器学习（ML）在各个行业的广泛采用因其大量的能源消耗和碳排放而引发了可持续性问题。这个问题在对抗性机器学习中变得更加紧迫，其重点是增强模型安全性以抵御不同的基于网络的攻击。在机器学习系统中实施防御通常需要额外的计算资源和网络安全措施，从而加剧了其对环境的影响。在本文中，我们率先对对抗性机器学习的碳足迹进行了首次调查，提供了将更高的模型稳健性与更高的排放联系起来的经验证据。为了满足量化这种权衡的迫切需要，我们引入了稳健性碳权衡指数（RCTI）。这一新颖的指标受到经济弹性原理的启发，捕捉了碳排放对对抗鲁棒性变化的敏感性。我们通过涉及规避攻击的实验演示了 RCTI，分析了针对攻击的鲁棒性、性能和碳排放之间的相互作用。]]></description>
      <guid>https://arxiv.org/abs/2403.19009</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>Thelxino\"e：使用瞳孔测量和机器学习识别人类情绪</title>
      <link>https://arxiv.org/abs/2403.19014</link>
      <description><![CDATA[arXiv:2403.19014v1 公告类型：新
摘要：在这项研究中，我们提出了一种使用瞳孔测量法在虚拟现实（VR）中进行情绪识别的方法。我们通过 VR 耳机分析瞳孔直径对视觉和听觉刺激的反应，并重点从 VR 生成的数据中提取时域、频域和时频域的关键特征。我们的方法利用最大相关性最小冗余（mRMR）进行特征选择来识别最具影响力的特征。通过应用梯度提升模型（一种使用堆叠决策树的集成学习技术），我们在使用特征工程时实现了 98.8% 的准确率，而没有使用特征工程时，准确率达到 84.9%。这项研究对 Thelxino\&quot;e 框架做出了重大贡献，旨在通过集成多个传感器数据以实现逼真且情感共鸣的触摸交互来增强 VR 体验。我们的研究结果为开发更具沉浸感和交互性的 VR 环境开辟了新途径，为未来的进步铺平了道路在虚拟触摸技术中。]]></description>
      <guid>https://arxiv.org/abs/2403.19014</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>混合传统和下一代油藏计算以准确有效地预测动力系统</title>
      <link>https://arxiv.org/abs/2403.18953</link>
      <description><![CDATA[arXiv:2403.18953v1 公告类型：新
摘要：水库计算机（RC）是用于时间序列预测的强大机器学习架构。最近，推出了下一代油藏计算机 (NGRC)，与 RC 相比，它具有明显的优势，例如减少计算费用和降低数据要求。然而，NGRC 有其与 RC 不同的实际困难，包括对采样时间和数据非线性类型的敏感性。在这里，我们引入了一种混合 RC-NGRC 方法，用于复杂混沌动力系统的时间序列预测。我们证明，在 RC 和 NGRC 组件单独不足的情况下，我们的混合方法可以产生准确的短期预测并捕获动力系统的长期统计数据。当两个组件的预测能力都受到限制时，例如，混合 RC-NGRC 方法的优势最为明显。对于训练数据中较小的 RC 和较大的采样时间。在这些条件下，我们证明，对于几个混沌系统，具有小水库（$N \approx 100$）的混合 RC-NGRC 方法可以实现与具有更大水库（$N \approx 1000）的纯 RC 相媲美的预测性能。 $），表明混合方法比传统 RC 显着提高了计算效率，同时解决了 NGRC 的一些局限性。]]></description>
      <guid>https://arxiv.org/abs/2403.18953</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>从结构上修剪任何东西：任何架构、任何框架、任何时间</title>
      <link>https://arxiv.org/abs/2403.18955</link>
      <description><![CDATA[arXiv:2403.18955v1 公告类型：新
摘要：神经网络剪枝是提高深度学习模型效率的关键技术。与仅将特定参数设置为零的非结构化剪枝不同，结构化剪枝消除了整个通道，从而产生直接的计算和存储优势。然而，残差连接和组卷积等不同的耦合参数模式、不同的深度学习框架以及可以执行剪枝的不同时间阶段，使得现有的剪枝方法不太适应不同的架构、框架和剪枝标准。为了解决这个问题，我们引入了 Structurally Prune Anything (SPA)，这是一种多功能的结构化剪枝框架，可以在任何训练阶段从任何框架中剪枝具有任何架构的神经网络。 SPA 利用标准化计算图和 ONNX 表示来修剪不同的神经网络架构，而无需手动干预。 SPA 采用组级重要性估计方法，该方法对依赖的计算运算符进行分组，估计其重要性，并修剪不重要的耦合通道。这使得能够将各种现有的修剪标准转移到结构化的组样式中。因此，SPA 支持随时剪枝，无论是在训练前、训练后（带微调）还是训练后（不带微调）。在后者的背景下，我们引入了 Optimal Brain SPA (OBSPA)，这种算法无需微调也无需校准数据即可实现最先进的修剪结果。在广泛的实验中，SPA 在不同的剪枝时间、跨流行框架的各种架构中显示出与最先进的剪枝性能相竞争的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.18955</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习实现黑盒图像、视频和心电图信号分类的鲁棒性和视觉解释</title>
      <link>https://arxiv.org/abs/2403.18985</link>
      <description><![CDATA[arXiv:2403.18985v1 公告类型：新
摘要：我们提出了一种通用的强化学习 (RL) 框架，该框架经过优化，可针对 ECG 信号分析 (1D)、图像分类 (2D) 和视频分类 (3D) 等不同模型类型进行对抗性攻击。该框架的重点是识别敏感区域并以最小的失真和各种失真类型诱导错误分类。新颖的强化学习方法在所有三种应用中都优于最先进的方法，证明了其效率。我们的强化学习方法可产生卓越的定位掩模，增强图像分类和心电图分析模型的可解释性。对于心电图分析等应用，我们的平台为临床医生突出显示了关键的心电图部分，同时确保抵御普遍扭曲的能力。这一综合工具旨在通过对抗性训练增强弹性，并提高各种应用程序和数据类型的透明度。]]></description>
      <guid>https://arxiv.org/abs/2403.18985</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>通过稀疏选择提高稀疏模型的效率</title>
      <link>https://arxiv.org/abs/2403.18926</link>
      <description><![CDATA[arXiv:2403.18926v1 公告类型：新
摘要：稀疏模型，包括稀疏专家混合 (MoE) 模型，已成为扩展 Transformer 模型的有效方法。然而，它们经常遭受计算效率低下的困扰，因为通过将值乘以零或低激活值，大量参数不必要地参与计算。为了解决这个问题，我们提出了 \tool，一种新颖的 MoE，旨在增强稀疏 MoE 模型的功效和效率。 \tool 利用小型专家和基于阈值的路由器来使令牌能够有选择地仅参与基本参数。我们对语言建模和机器翻译任务的大量实验表明，该工具可以增强模型性能，同时将 MoE 层的计算负载减少 50% 以上，而不会牺牲性能。此外，我们通过将 \tool 应用于密集模型来展示 \tool 的多功能性，从而在推理过程中实现稀疏计算。我们提供全面的分析，并在 https://anonymous.4open.science/r/XMoE 上提供我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2403.18926</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在功能模块化进行自我监督的可解释感觉运动学习</title>
      <link>https://arxiv.org/abs/2403.18947</link>
      <description><![CDATA[arXiv:2403.18947v1 公告类型：新
摘要：我们介绍 MoNet，这是一种将端到端学习与模块化网络架构相结合的新颖方法，用于自我监督和可解释的感觉运动学习。 MoNet 由三个功能不同的神经模块组成：感知、规划和控制。通过认知引导的对比损失函数，利用其固有的模块化性，MoNet 可以有效地学习潜在空间中特定于任务的决策过程，而无需任务级监督。此外，我们的方法采用了在线事后可解释性方法，该方法增强了端到端推理的可解释性，而无需权衡感觉运动性能。在真实的室内环境中，MoNet 展示了有效的视觉自主导航，在任务特异性分析方面比基线模型高出 11% 至 47%。我们通过感知显着性图和潜在决策向量的事后分析进一步深入研究网络的可解释性。这为将可解释的人工智能纳入机器人学习领域提供了见解，涵盖感知和行为的角度。]]></description>
      <guid>https://arxiv.org/abs/2403.18947</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>预训练模型的自我扩展与持续学习适配器的混合</title>
      <link>https://arxiv.org/abs/2403.18886</link>
      <description><![CDATA[arXiv:2403.18886v1 公告类型：新
摘要：持续学习的目的是从不断到达的数据流中学习，同时尽量减少对先前学到的知识的遗忘。虽然之前的工作已经探索了在持续学习中利用预训练模型中的通用知识的有效性，但现有的参数高效微调方法侧重于使用预先确定的或任务明智的适配器或提示集。然而，由于任务对联合使用的参数的干扰或灵活性的限制，这些方法仍然容易被遗忘。考虑到输入数据的规模和分布在持续学习中是不可预测的，对静态模型架构的依赖可能会导致分配过多的不必要的参数，或者相反，对下游任务的适应不足。我们提出了使用模块化适应（SEMA）对预训练模型进行自我扩展，这是一种新颖的微调方法，可以根据需要在持续学习中自动决定重用或添加适配器模块，具体取决于是否存在无法处理的剧烈分布变化现有模块在不同的表示级别上进行检测。我们设计每个适配器模块，由一个适配器和一个表示描述符组成，具体来说，作为自动编码器实现。表示描述符在训练期间充当分布移位指示器并触发适配器扩展。为了更好地使用适配器，联合学习可扩展的加权路由器以混合适配器输出。通过与基于视觉变换器的持续学习适应方法进行比较，我们证明所提出的框架在没有记忆排练的情况下优于最先进的框架。]]></description>
      <guid>https://arxiv.org/abs/2403.18886</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>似然 OOD 检测悖论的几何解释</title>
      <link>https://arxiv.org/abs/2403.18910</link>
      <description><![CDATA[arXiv:2403.18910v1 公告类型：新
摘要：基于似然的深度生成模型（DGM）通常表现出令人费解的行为：当在相对复杂的数据集上进行训练时，它们为来自较简单来源的分布外（OOD）数据分配更高的似然值。更神秘的是，尽管 OOD 样本的可能性更高，但这些 DGM 从未生成过 OOD 样本。这种双管齐下的悖论尚未得到最终解释，使得基于可能性的 OOD 检测不可靠。我们的主要观察是，如果高似然区域包含最小概率质量，则不会生成它们。我们证明了大密度与低概率质量的这种看似矛盾是如何在仅限于低维流形的数据周围发生的。我们还表明，可以通过局部固有维度 (LID) 估计来识别这种情况，并提出一种 OOD 检测方法，该方法将可能性和从预训练的 DGM 获得的 LID 估计配对。我们的方法可以应用于标准化流量和基于分数的扩散模型，并使用相同的 DGM 主干获得匹配或超越最先进的 OOD 检测基准的结果。我们的代码可在 https://github.com/layer6ai-labs/dgm_ood_detection 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.18910</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>编码器 LLM 骨干的定向可视化</title>
      <link>https://arxiv.org/abs/2403.18872</link>
      <description><![CDATA[arXiv:2403.18872v1 公告类型：新
摘要：基于注意力的大型语言模型（LLM）是自然语言处理（NLP）领域的最先进技术。两种最常见的架构是编码器（例如 BERT）和解码器（例如 GPT 模型）。尽管我们在这项工作中重点关注的编码器模型取得了成功，但它们也面临着一些风险，包括偏见问题或容易受到对抗性攻击的问题，这表明需要可解释的人工智能来检测此类问题。虽然确实存在各种专注于单个输入预测的局部可解释性方法，但基于降维进行分类检查的全局方法（这些方法已出现在其他领域，并且比仅在嵌入空间中使用 t-SNE 更进一步）并未得到广泛应用在NLP中传播。
  为了缩小这一差距，我们研究了 DeepView 在 NLP 领域的应用，这是一种将决策函数的一部分与二维数据集一起可视化的方法。虽然在之前的工作中，DeepView 已被用于检查深度图像分类模型，但我们演示了如何将其应用于基于 BERT 的 NLP 分类器，并研究其在该领域的可用性，包括使用对抗性扰动输入样本和预训练、精细的设置。调整和多任务模型。]]></description>
      <guid>https://arxiv.org/abs/2403.18872</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    </channel>
</rss>