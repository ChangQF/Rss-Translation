<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 12 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>信息论贝叶斯优化：综述和教程</title>
      <link>https://arxiv.org/abs/2502.06789</link>
      <description><![CDATA[arXiv:2502.06789v1 公告类型：新
摘要：有几种情况需要优化非凸黑盒函数，这些函数噪声大，评估具有未知解析表达式的函数的成本高，因此无法获得其梯度。例如，机器学习模型的超参数调整问题。贝叶斯优化是一类具有最先进性能的方法，可在实际场景中解决此问题。它使用迭代过程，该过程采用要优化的目标函数的概率代理模型（通常是高斯过程），计算黑盒函数的后验预测分布。基于该后验预测分布提供的信息，贝叶斯优化包括计算获取函数，该函数表示对于每个输入空间点，如果该过程的目标是检索全局极值，则在下一次迭代中评估该点的效用。本文是对信息理论获取函数的综述，其性能通常优于其他获取函数。本文还详细描述了信息理论领域的主要概念，以便让读者了解信息理论获取函数为何能在贝叶斯优化中取得优异成绩，以及当它们难以处理时我们如何对其进行近似。我们还介绍了如何将信息理论获取函数适应复杂的优化场景，例如多目标、约束、非短视、多保真度、并行和异步设置，并提供进一步的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2502.06789</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效文本到图像推理系统的提示感知调度</title>
      <link>https://arxiv.org/abs/2502.06798</link>
      <description><![CDATA[arXiv:2502.06798v1 公告类型：新
摘要：传统的 ML 模型在高负载期间使用受控近似值，在称为准确度扩展的过程中使用速度更快但准确度较低的模型。但是，这种方法对于生成文本到图像模型不太有效，因为它们对输入提示很敏感，并且由于模型加载开销较大而导致性能下降。这项工作引入了一种新颖的文本到图像推理系统，该系统可以在不同近似级别运行的同一模型的多个实例之间最佳地匹配提示，以在高负载和固定预算下提供高质量的图像。]]></description>
      <guid>https://arxiv.org/abs/2502.06798</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分析美国人群乳腺癌筛查的地理空间和社会经济差异：机器学习方法</title>
      <link>https://arxiv.org/abs/2502.06800</link>
      <description><![CDATA[arXiv:2502.06800v1 公告类型：新
摘要：乳腺癌筛查在早期发现和随后有效管理疾病方面起着关键作用，影响患者的预后和生存率。本研究旨在评估美国全国的乳腺癌筛查率，并调查社会健康决定因素对这些筛查率的影响。2018 年和 2020 年人口普查区乳房 X 线摄影筛查数据来自行为风险因素监测系统。我们开发了一个庞大的社会健康决定因素数据集，包含 72337 个人口普查区的 13 个变量。采用 Getis-Ord Gi 统计数据的空间分析用于识别高和低乳腺癌筛查率的聚类。为了评估这些社会决定因素的影响，我们实施了一个随机森林模型，目的是将其性能与线性回归和支持向量机模型进行比较。使用 R2 和均方根误差指标对模型进行评估。随后使用 Shapley 附加解释值评估变量的重要性及其影响方向。地理空间分析显示，美国东部和北部的筛查率较高，而中部和中西部地区的筛查率较低。与线性回归和支持向量机模型相比，随机森林模型表现出色，R2=64.53，均方根误差为 2.06。Shapley 附加解释值表明，黑人人口比例、10 英里半径范围内的乳房 X 线摄影设施数量以及至少拥有学士学位的人口比例是影响最大的变量，均与乳房 X 线摄影筛查率呈正相关。]]></description>
      <guid>https://arxiv.org/abs/2502.06800</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>情绪识别与生成：面部、语音和文本模式的全面回顾</title>
      <link>https://arxiv.org/abs/2502.06803</link>
      <description><![CDATA[arXiv:2502.06803v1 公告类型：新
摘要：情绪识别和生成已成为人工智能研究的重要课题，在增强医疗保健、客户服务和其他领域的人机交互方面发挥着重要作用。尽管已经对情绪识别和生成作为独立实体进行了多次审查，但其中许多工作要么支离破碎，要么局限于特定方法，缺乏对不同模式的最新发展和趋势的全面概述。在本次调查中，我们提供了全面的评论，旨在帮助研究人员开始探索情绪识别和生成。我们介绍了面部、声音和文本模式中情绪识别和生成的基本原理。这项工作将最近的最先进研究分为不同的技术方法，并解释了这些方法背后的理论基础和动机，从而更清楚地了解它们的应用。此外，我们讨论了评估指标、比较分析和当前的局限性，阐明了该领域研究人员面临的挑战。最后，我们提出了应对这些挑战的未来研究方向，并鼓励进一步探索开发强大、有效、符合道德规范的情感识别和生成系统。]]></description>
      <guid>https://arxiv.org/abs/2502.06803</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效扩散模型：综述</title>
      <link>https://arxiv.org/abs/2502.06805</link>
      <description><![CDATA[arXiv:2502.06805v1 公告类型：新
摘要：扩散模型已成为强大的生成模型，能够生成高质量的内容，例如图像、视频和音频，展示了它们彻底改变数字内容创作的潜力。然而，这些能力是以大量的计算资源和漫长的生成时间为代价的，这凸显了开发用于实际部署的有效技术的迫切需要。在本次调查中，我们对高效扩散模型的研究进行了系统而全面的回顾。我们将文献组织成一个由三个主要类别组成的分类法，分别从算法级、系统级和框架角度涵盖了不同但相互关联的高效扩散模型主题。我们还创建了一个 GitHub 存储库，我们在 https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey 上组织了本次调查中的论文。我们希望我们的调查可以成为一种宝贵的资源，帮助研究人员和从业者系统地了解高效扩散模型研究，并激励他们为这个重要而令人兴奋的领域做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2502.06805</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们只需要 Logits 即可适应封闭模型</title>
      <link>https://arxiv.org/abs/2502.06806</link>
      <description><![CDATA[arXiv:2502.06806v1 公告类型：新
摘要：许多商业大型语言模型 (LLM) 通常是闭源的，限制开发人员进行快速调整以使内容生成与特定应用程序保持一致。虽然这些模型目前不提供对 token logit 的访问，但我们认为，如果这种访问可用，它将支持超越快速工程的更强大的适应技术。在本文中，我们提出了一个 token 级概率重新加权框架，只要能够访问 logit 和少量特定于任务的数据，就可以有效地引导黑盒 LLM 实现特定于应用程序的内容生成。我们的方法通过监督分类的视角来看待下一个 token 预测。我们表明，将黑盒 LLM 与特定于任务的数据对齐可以表述为标签噪声校正问题，从而导致 \emph{Plugin} 模型——一种仅对 logit 进行操作的自回归概率重新加权模型。我们提供了理论依据，说明为什么仅重新加权 logit 就足以进行任务适应。使用多个数据集、LLM 和重加权模型进行的大量实验证明了我们方法的有效性，并主张更广泛地访问闭源模型中的标记日志。]]></description>
      <guid>https://arxiv.org/abs/2502.06806</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有大型推理模型的竞争性编程</title>
      <link>https://arxiv.org/abs/2502.06807</link>
      <description><![CDATA[arXiv:2502.06807v1 公告类型：新
摘要：我们表明，将强化学习应用于大型语言模型 (LLM) 可显著提高复杂编码和推理任务的性能。此外，我们将两个通用推理模型（OpenAI o1 和 o3 的早期检查点）与领域特定系统 o1-ioi 进行了比较，后者使用专为参加 2024 年国际信息学奥林匹克竞赛 (IOI) 而设计的手工推理策略。我们在 IOI 2024 上与 o1-ioi 进行了现场比赛，并使用手工制作的测试时间策略，排名在第 49 个百分位。在放宽竞争限制的情况下，o1-ioi 获得了金牌。然而，在评估 o3 等后期模型时，我们发现 o3 在没有手工制作领域特定策略或放宽限制的情况下获得了金牌。我们的研究结果表明，尽管 o1-ioi 等专用管道取得了显著的改进，但扩展的通用 o3 模型无需依赖手工推理启发式方法即可超越这些结果。值得注意的是，o3 在 2024 年 IOI 上获得了金牌，并获得了与人类精英选手相当的 Codeforces 评级。总体而言，这些结果表明，扩展通用强化学习，而不是依赖特定领域的技术，为在推理领域（例如竞技编程）实现最先进的 AI 提供了一条稳健的道路。]]></description>
      <guid>https://arxiv.org/abs/2502.06807</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论属性驱动图域自适应的好处</title>
      <link>https://arxiv.org/abs/2502.06808</link>
      <description><![CDATA[arXiv:2502.06808v1 公告类型：新
摘要：图域自适应 (GDA) 解决了跨网络学习中的一个紧迫挑战，由于现实世界图数据集中缺乏标记数据，这一挑战尤其重要。最近的研究试图通过消除图之间的结构转变来学习域不变表示。在这项工作中，我们表明现有方法忽视了图节点属性的重要性，这是图域对齐的关键因素。具体而言，我们首先通过理论证明除了域之间的图结构差异之外，节点属性差异在 GDA 中也起着关键作用，从而揭示了节点属性对 GDA 的影响。此外，我们还通过经验表明，属性偏移比拓扑偏移更为显著，这进一步强调了节点属性对齐在 GDA 中的重要性。受这一发现的启发，开发了一种新颖的跨通道模块来融合和对齐 GDA 的源图和目标图之间的两个视图。在多种基准上的实验结果验证了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.06808</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经元以范围说话：摆脱离散神经元归因</title>
      <link>https://arxiv.org/abs/2502.06809</link>
      <description><![CDATA[arXiv:2502.06809v1 公告类型：新
摘要：解释和控制大型语言模型 (LLM) 的内部机制对于提高其可信度和实用性至关重要。最近的努力主要集中在通过在神经元和语义概念之间建立离散映射来识别和操纵神经元。然而，这种映射难以处理 LLM 中固有的多义性，其中单个神经元编码多个不同的概念。这使得精确控制具有挑战性并使下游干预复杂化。通过对多个文本分类数据集中基于编码器和解码器的 LLM 进行深入分析，我们发现虽然单个神经元编码多个概念，但它们的激活幅度在不同概念之间以不同的高斯状模式变化。基于这一见解，我们引入了 NeuronLens，这是一种基于范围的新型解释和操纵框架，它提供了神经元激活分布的更精细视图，以定位神经元内的概念归属。大量的实证评估表明，NeuronLens 显著减少了意外干扰，同时保持了对目标概念操纵的精确控制，其表现优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.06809</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协调人类和机器的注意力以增强监督学习</title>
      <link>https://arxiv.org/abs/2502.06811</link>
      <description><![CDATA[arXiv:2502.06811v1 公告类型：新
摘要：注意力，或对某些信息项的优先排序，是人类和机器学习过程中的关键要素。鉴于人类在某些学习任务中的表现继续优于机器，似乎可以通过将机器注意力与人类注意力机制相结合来提高机器性能——然而，关于这个主题的研究很少，而且只取得了有限的成功。本文提出了一种解决这一差距的新方法，称为人机注意力学习 (HuMAL)。这种方法涉及依赖人类注释的数据来反映他们在特定任务期间自我感知的注意力。我们使用情绪分析任务（来自 Yelp 的评论数据）和性格类型分类任务（来自 myPersonality 的数据），评估了将此类人类注意力数据集成到机器学习 (ML) 算法中的几种替代策略。表现最佳的 HuMAL 策略显著提高了微调 Transformer 模型（BERT 以及 GPT-2 和 XLNET）的任务性能，并且在标签数据不平衡或稀疏的挑战条件下，这种优势尤为明显。这项研究有助于更深入地了解将人类注意力融入 ML 模型的策略，并强调了利用人类认知在实际应用中增强 ML 的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.06811</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用本地奖励实现全球利益：通过补丁级奖励模型实现有效的文本到视频生成一致性</title>
      <link>https://arxiv.org/abs/2502.06812</link>
      <description><![CDATA[arXiv:2502.06812v1 公告类型：新
摘要：扩散模型 (DM) 的出现显著提高了文本到视频生成模型 (VGM) 的质量。然而，目前的 VGM 优化主要强调视频的整体质量，忽略了局部错误，导致生成能力不理想。为了解决这个问题，我们提出了一种 VGM 的后训练策略 HALO，它明确地结合了来自补丁奖励模型的局部反馈，为高级 VGM 优化提供了视频奖励模型的详细而全面的训练信号。为了开发一个有效的补丁奖励模型，我们提炼了 GPT-4o 来持续训练我们的视频奖励模型，这提高了训练效率并确保了视频和补丁奖励分布之间的一致性。此外，为了将补丁奖励和谐地集成到 VGM 优化中，我们为 DM 引入了一种细粒度的 DPO（Gran-DPO）算法，允许在优化过程中协同使用补丁和视频奖励。实验结果表明，我们的补丁奖励模型与人工注释高度吻合，HALO 在两种评估方法中的表现远超基线。进一步的实验定量证明了补丁缺陷的存在，我们提出的方法可以有效缓解这一问题。]]></description>
      <guid>https://arxiv.org/abs/2502.06812</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>策略引导树搜索以增强 LLM 推理</title>
      <link>https://arxiv.org/abs/2502.06813</link>
      <description><![CDATA[arXiv:2502.06813v1 公告类型：新
摘要：尽管大型语言模型具有非凡的能力，但它们在需要复杂推理和规划的任务中往往举步维艰。虽然现有的方法（如思路链提示和树搜索技术）很有前景，但它们受限于对预定义启发式方法和计算成本高昂的探索策略的依赖。我们提出了策略引导树搜索 (PGTS)，这是一个将强化学习与结构化树探索相结合的框架，可以有效地导航推理路径。我们的主要创新是一种学习策略，它可以动态地决定扩展、分支、回溯或终止探索，从而无需手动启发式或穷举搜索。在数学推理、逻辑推理和规划基准测试中的实验表明，与现有方法相比，PGTS 实现了卓越的推理性能，同时显着降低了计算成本。这些结果确立了 PGTS 是一种可扩展且有效的解决方案，可用于使用 LLM 解决复杂的推理任务。]]></description>
      <guid>https://arxiv.org/abs/2502.06813</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散指令调整</title>
      <link>https://arxiv.org/abs/2502.06814</link>
      <description><![CDATA[arXiv:2502.06814v1 公告类型：新
摘要：我们介绍了一种简单的监督微调 (SFT) 方法 Lavender，它通过利用最先进的图像生成模型（如稳定扩散）来提高高级视觉语言模型 (VLM) 的性能。具体来说，Lavender 将 VLM 转换器中的文本视觉注意力与 SFT 期间稳定扩散使用的等效注意力对齐，而不是调整单独的编码器。这种对齐丰富了模型的视觉理解，并显著提高了分布内和分布外任务的性能。Lavender 只需要 0.13 百万个训练示例、典型大型 SFT 数据集的 2.5%，并在一天内在标准硬件（8 个 GPU）上进行微调。它不断改进最先进的开源多模态 LLM（例如 Llama-3.2-11B、MiniCPM-Llama3-v2.5），在具有挑战性的分布外医疗 QA 任务上实现了高达 30% 的增益和 68% 的提升。通过在最少监督的情况下高效地转移图像生成器的视觉专业知识，Lavender 为更准确的视觉语言系统提供了可扩展的解决方案。所有代码、训练数据和模型将在 https://astrazeneca.github.io/vlm/ 上共享。]]></description>
      <guid>https://arxiv.org/abs/2502.06814</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Honegumi：加速贝叶斯优化在实验科学中的应用的界面</title>
      <link>https://arxiv.org/abs/2502.06815</link>
      <description><![CDATA[arXiv:2502.06815v1 公告类型：新
摘要：贝叶斯优化 (BO) 已成为指导材料科学、化学和生物学等各个科学领域的实验设计和决策的有力工具。然而，尽管它越来越受欢迎，但现有 BO 库的复杂性及其相关的陡峭学习曲线可能会阻碍不熟悉机器学习或编程的研究人员。为了解决这一障碍，我们推出了 Honegumi，这是一款用户友好的交互式工具，旨在简化创建高级贝叶斯优化脚本的过程。Honegumi 提供了一个动态选择网格，允许用户配置其优化任务的关键参数，生成可立即使用的、经过单元测试的 Python 脚本，以满足他们的特定需求。界面附带一套全面的教程，提供概念和实践指导，弥合理论理解与实际实施之间的差距。 Honegumi 建立在 Ax 平台之上，充分利用了现有先进库的功能，同时重构了用户体验，使实验研究人员更容易获得先进的贝叶斯优化技术。通过降低准入门槛和提供教育资源，Honegumi 旨在加速各个领域采用先进的贝叶斯优化方法。]]></description>
      <guid>https://arxiv.org/abs/2502.06815</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepCell：后映射网表的多视图表示学习</title>
      <link>https://arxiv.org/abs/2502.06816</link>
      <description><![CDATA[arXiv:2502.06816v1 公告类型：新
摘要：后映射 (PM) 网表的表示学习是电子设计自动化 (EDA) 中的一个关键挑战，这是由现代电路设计的多样性和复杂性所驱动的。现有方法侧重于中间表示，如与-反相图 (AIG)，限制了它们在后综合阶段的适用性。我们引入了 DeepCell，这是一个多视图表示学习框架，它集成了来自 PM 网表和 AIG 的结构和功能见解，以学习丰富、可泛化的嵌入。DeepCell 的核心是采用新颖的掩模电路建模 (MCM) 机制，该机制使用预训练的 AIG 编码器以自监督的方式改进 PM 网表表示。DeepCell 在 PM 网表表示中设定了新的基准，在预测准确性和重建保真度方面优于现有方法。为了验证其有效性，我们将 DeepCell 应用于功能工程变更单 (ECO)，在提高补丁质量的同时，显著减少了补丁生成成本和运行时间。]]></description>
      <guid>https://arxiv.org/abs/2502.06816</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>