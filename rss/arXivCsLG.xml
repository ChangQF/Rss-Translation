<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Wed, 27 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用图神经网络进行制造服务能力预测</title>
      <link>https://arxiv.org/abs/2403.17239</link>
      <description><![CDATA[arXiv:2403.17239v1 公告类型：新
摘要：在当前情况下，识别制造商制造能力的主要方法严重依赖关键词匹配和语义匹配。然而，这些方法往往因忽略有价值的隐藏信息或误解关键数据而存在缺陷。因此，此类方法导致对制造商能力的识别不完整。这凸显了对数据驱动解决方案的迫切需求，以提高制造能力识别的准确性和完整性。为了满足这一需求，本研究提出了一种基于图神经网络的方法，用于通过知识图识别制造服务能力。为了提高识别性能，这项工作引入了一种新颖的方法，涉及聚合来自图节点邻域的信息以及对图数据进行过采样，该方法可以有效地应用于广泛的实际场景。对制造服务知识图进行的评估和随后的消融研究证明了所提出方法的有效性和稳健性。这项研究不仅为推断制造服务能力提供了一种创新方法，而且还显着提高了制造服务知识图的质量。]]></description>
      <guid>https://arxiv.org/abs/2403.17239</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>用于链路预测的基于扩散的图负采样</title>
      <link>https://arxiv.org/abs/2403.17259</link>
      <description><![CDATA[arXiv:2403.17259v1 公告类型：新
摘要：链接预测是图分析的一项基本任务，在网络上具有重要的应用，例如社交网络分析和推荐系统等。现代图链接预测方法通常采用对比方法来学习鲁棒的节点表示，其中负采样是关键。典型的负采样方法旨在基于预定义的启发式或自动对抗方法来检索困难示例，这可能不灵活或难以控制。此外，在链接预测的背景下，大多数先前的方法从图的现有子结构中对负节点进行采样，从而错过了潜在空间中可能更优化的样本。为了解决这些问题，我们研究了一种新颖的多级负采样策略，该策略能够从潜在空间生成具有灵活且可控的“硬度”级别的负节点。我们的方法称为基于条件扩散的多级负采样（DMNS），利用扩散模型的马尔可夫链特性来生成多个可变硬度级别的负节点，并协调它们以进行有效的图链接预测。我们进一步证明 DMNS 遵循稳健负采样的亚线性正性原理。对多个基准数据集的大量实验证明了 DMNS 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.17259</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>解释不确定性的健全性检查</title>
      <link>https://arxiv.org/abs/2403.17212</link>
      <description><![CDATA[arXiv:2403.17212v1 公告类型：新
摘要：机器学习模型的解释可能难以解释或错误。将解释方法与不确定性估计方法相结合会产生解释不确定性。评估解释的不确定性是很困难的。在本文中，我们提出了对不确定性解释方法的健全性检查，其中为不确定性的解释定义了权重和数据随机化测试，从而可以对不确定性和解释方法的组合进行快速测试。我们通过实验证明了这些测试在 CIFAR10 和加州住房数据集上的有效性和有效性，并注意到集成似乎始终通过引导反向传播、积分梯度和 LIME 解释的这两项测试。]]></description>
      <guid>https://arxiv.org/abs/2403.17212</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中基于梯度的解释的不确定性量化</title>
      <link>https://arxiv.org/abs/2403.17224</link>
      <description><![CDATA[arXiv:2403.17224v1 公告类型：新
摘要：解释方法有助于理解模型预测的原因。这些方法越来越多地涉及模型调试、性能优化以及深入了解模型的工作原理。随着这些方法的如此关键的应用，必须测量与这些方法产生的解释相关的不确定性。在本文中，我们提出了一种通过结合不确定性估计方法和解释方法来确定神经网络的解释不确定性的管道。我们使用此管道生成 CIFAR-10、FER+ 和加州住房数据集的解释分布。通过计算这些分布的变异系数，我们评估解释的置信度，并确定使用引导反向传播生成的解释具有较低的不确定性。此外，我们还计算修改后的像素插入/删除指标来评估生成的解释的质量。]]></description>
      <guid>https://arxiv.org/abs/2403.17224</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>使用量化整流器的神经图像压缩</title>
      <link>https://arxiv.org/abs/2403.17236</link>
      <description><![CDATA[arXiv:2403.17236v1 公告类型：新
摘要：神经图像压缩已被证明在率失真性能方面优于传统图像编解码器。然而，量化会在压缩过程中引入错误，从而降低压缩图像的质量。现有方法解决了量化过程中出现的训练-测试不匹配问题，但量化对图像特征表达能力的随机影响仍未解决。本文提出了一种新颖的图像压缩量化整流器（QR）方法，该方法利用图像特征相关性来减轻量化的影响。我们的方法设计了一种神经网络架构，可以从量化的特征中预测未量化的特征，保留特征表达力以获得更好的图像重建质量。我们开发了一种软预测训练技术，将 QR 集成到现有的神经图像编解码器中。在评估中，我们将 QR 集成到最先进的神经图像编解码器中，并在广泛使用的柯达基准上比较增强模型和基线。结果表明，QR 的编码效率得到了一致的提高，而运行时间的增加可以忽略不计。]]></description>
      <guid>https://arxiv.org/abs/2403.17236</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>社交学习只需要信念样本</title>
      <link>https://arxiv.org/abs/2403.17174</link>
      <description><![CDATA[arXiv:2403.17174v1 公告类型：新
摘要：在本文中，我们考虑了社会学习问题，其中嵌入社交网络的一组代理有兴趣学习世界的基本状态。智能体拥有不完整、嘈杂和异构的信息源，为他们提供了对世界基本状态的反复私人观察。智能体可以通过采取可观察到的行动与同伴分享他们的学习经验，并使用来自有限可行状态集的值。行为可以被解释为来自代理可能形成和更新的关于世界真实状态的信念的样本。共享样本代替完整的信念，是由于代理（尤其是在大群体中）可用的沟通、认知和信息处理资源有限而引发的。之前的工作（Salhab 等人）提出了这样的问题：如果仅允许智能体根据其信念交流样本，那么以概率 1 进行学习是否仍然可以实现。我们对这个问题提供了明确的肯定答案，假设有一个强连接的网络和一个“集体可区分性”假设，即使在完全信念共享的环境中，这也是学习所必需的。在我们提出的信念更新机制中，每个代理的信念是完全贝叶斯私人信念（聚合来自私人来源的信息）与邻居随时间共享的样本经验分布的集合之间的归一化加权几何插值。通过仔细构建与真实状态匹配或不匹配的共享样本频率的渐近几乎肯定的下界/上限，我们严格证明所有信念以概率一收敛到真实状态。]]></description>
      <guid>https://arxiv.org/abs/2403.17174</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>CADGL：用于预测药物相互作用的上下文感知深度图学习</title>
      <link>https://arxiv.org/abs/2403.17210</link>
      <description><![CDATA[arXiv:2403.17210v1 公告类型：新
摘要：检查药物间相互作用（DDI）是药物开发过程中的关键要素。当一种药物的特性受到其他药物的影响时，就会发生 DDI。检测有利的 DDI 有可能为创造和推进适用于实际环境的创新药物铺平道路。然而，现有的 DDI 预测模型继续面临与极端​​情况下的泛化、鲁棒特征提取和现实生活应用可能性相关的挑战。我们的目标是通过引入名为 CADGL 的新颖框架，利用上下文感知深度图学习的有效性来应对这些挑战。基于定制的变分图自动编码器（VGAE），我们使用两个上下文预处理器从两个不同的角度提取特征：局部邻域和分子上下文，在异构图形结构中捕获关键的结构和物理化学信息。我们定制的 VGAE 由图编码器、潜在信息编码器和 MLP 解码器组成。 CADGL 超越了其他最先进的 DDI 预测模型，在严格的案例研究的支持下，擅长预测具有临床价值的新型 DDI。]]></description>
      <guid>https://arxiv.org/abs/2403.17210</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>探索基于原型的软标签数据蒸馏对于不平衡数据分类的潜力</title>
      <link>https://arxiv.org/abs/2403.17130</link>
      <description><![CDATA[arXiv:2403.17130v1 公告类型：新
摘要：数据集蒸馏的目的是通过少量人工生成的数据项合成数据集，当将其用作训练数据时，可以重现或近似机器学习（ML）模型，就像在整个原始数据集上进行训练一样。因此，数据蒸馏方法通常与特定的机器学习算法相关联。虽然最近的文献主要涉及在神经网络模型的背景下对大量图像进行蒸馏，但表格数据蒸馏的代表性要少得多，并且主要集中在理论角度。本文探讨了先前在不到一次学习的背景下提出的简单蒸馏技术的潜力。主要目标是通过在蒸馏过程中集成优化步骤，进一步提高基于原型的软标签蒸馏在分类准确性方面的性能。该分析是在具有不同程度不平衡的现实数据集上进行的。实验研究追踪了该方法提取数据的能力，以及充当增强方法的机会，即生成新数据，当与原始数据结合使用（而不是代替原始数据）时，能够提高模型的准确性数据。]]></description>
      <guid>https://arxiv.org/abs/2403.17130</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>少即是多 - 论稀疏化对于 Transformers 和图神经网络对于 TSP 的重要性</title>
      <link>https://arxiv.org/abs/2403.17159</link>
      <description><![CDATA[arXiv:2403.17159v1 公告类型：新
摘要：最近大多数通过机器学习解决旅行商问题（TSP）等路由问题的研究都使用基于转换器或图神经网络（GNN）的编码器架构。然而，他们中的许多人天真地应用这些编码器，允许它们聚合整个 TSP 实例的信息。另一方面，我们提出了一种数据预处理方法，允许编码器仅关注 TSP 实例中最相关的部分。特别是，我们建议对传递给 GNN 的 TSP 图表示进行图稀疏化，并对传递给 Transformer 的 TSP 实例进行注意力掩码，其中掩码对应于稀疏 TSP 图表示的邻接矩阵。此外，我们提出了不同稀疏化级别的集成，允许模型专注于最有希望的部分，同时还允许 TSP 实例的所有节点之间的信息流动。在实验研究中，我们表明，对于 GNN 来说，适当的稀疏化和不同稀疏化级别的集成可以显着提高整体架构的性能。我们还设计了一种新的、最先进的变压器编码器，具有注意力屏蔽的集合。这些转换器将大小为 100 的 TSP 实例的模型性能从 $0.16\%$ 提高到 $0.10\%$，将大小为 50 的 TSP 实例的模型性能从 $0.02\%$ 提高到 $0.00\%$。]]></description>
      <guid>https://arxiv.org/abs/2403.17159</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>离线强化学习：状态聚合和轨迹数据的作用</title>
      <link>https://arxiv.org/abs/2403.17091</link>
      <description><![CDATA[arXiv:2403.17091v1 公告类型：新
摘要：我们重新审视具有价值函数可实现性但不具有贝尔曼完备性的离线强化学习问题。 Xie 和 Jiang (2021) 以及 Foster 等人之前的工作。 （2022）留下了一个问题：有界集中性系数和基于轨迹的离线数据是否承认多项式样本复杂性。在这项工作中，我们为离线政策评估任务提供了这个问题的否定答案。除了解决这个问题之外，我们还为离线政策评估提供了一个相当完整的图景，仅具有价值函数的可实现性。我们的主要发现有三个：1）离线政策评估的样本复杂性是由函数类和离线数据分布共同确定的聚合马尔可夫转移模型中的集中性系数决定的，而不是原始MDP中的集中性系数。这统一并概括了 Xie 和 Jiang（2021）以及 Foster 等人的思想。 (2022), 2) 即使原始 MDP 中的集中性系数很小并且离线数据是可接受的（即数据分布等于占用度量），聚合马尔可夫转移模型中的集中性系数也可能随着视界长度呈指数增长某些策略的），3）在价值函数可实现性下，有一个通用的约简，可以将任何具有可接受数据的硬实例转换为具有轨迹数据的硬实例，这意味着轨迹数据不会比可接受的数据提供额外的好处。这三部分共同解决了开放问题，尽管它们中的每一个都可能具有独立的利益。]]></description>
      <guid>https://arxiv.org/abs/2403.17091</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>通过零信任架构增强无人机安全：先进的深度学习和可解释的人工智能分析</title>
      <link>https://arxiv.org/abs/2403.17093</link>
      <description><![CDATA[arXiv:2403.17093v1 公告类型：新
摘要：在动态且不断变化的无人机（UAV）领域，最重要的是保证弹性和清晰的安全措施。这项研究强调了实施零信任架构 (ZTA) 来增强无人机 (UAV) 安全性的必要性，从而摆脱可能暴露漏洞的传统外围防御。零信任架构 (ZTA) 范例需要严格且持续的过程来验证所有网络实体和通信。我们的方法检测和识别无人机 (UAV) 的准确度为 84.59\%。这是通过在深度学习框架内利用射频 (RF) 信号来实现的，这是一种独特的方法。精确识别在零信任架构 (ZTA) 中至关重要，因为它决定网络访问。此外，使用SHApley Additive exPlanations (SHAP)和Local Interpretable Model-agnostic Explanations (LIME)等可解释人工智能(XAI)工具有助于提高模型的透明度和可解释性。遵守零信任架构 (ZTA) 标准可确保无人机 (UAV) 的分类可验证且易于理解，从而增强无人机领域的安全性。]]></description>
      <guid>https://arxiv.org/abs/2403.17093</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>随机梯度 Langevin 遗忘</title>
      <link>https://arxiv.org/abs/2403.17105</link>
      <description><![CDATA[arXiv:2403.17105v1 公告类型：新
摘要：法律保障的用户数据隐私“被遗忘权”变得越来越重要。机器去学习的目的是有效地消除某些数据点对训练后的模型参数的影响，使其与从头开始重新训练模型大致相同。这项工作提出了随机梯度 Langevin 失学习，这是第一个基于噪声随机梯度下降（SGD）的失学习框架，并在凸性假设下为近似失学习问题提供隐私保证。我们的结果表明，与全批量梯度更新相比，小批量梯度更新提供了卓越的隐私复杂性权衡。我们的取消学习方法有许多算法优势，包括与再训练相比节省了复杂性，以及支持顺序和批量取消学习。为了检查我们的方法的隐私-实用性-复杂性权衡，我们对基准数据集进行了与之前的工作进行比较的实验。与最先进的基于梯度的小批量和全批量近似遗忘方法相比，我们的方法在相同的隐私约束下实现了类似的效用，同时使用 $2\%$ 和 $10\%$ 的梯度计算分别设置。]]></description>
      <guid>https://arxiv.org/abs/2403.17105</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>SUDO：无需真实注释即可评估临床人工智能系统的框架</title>
      <link>https://arxiv.org/abs/2403.17011</link>
      <description><![CDATA[arXiv:2403.17011v1 公告类型：新
摘要：临床人工智能（AI）系统通常在一组以前从未接触过的数据（例如，来自具有不同电子健康记录系统的不同医院的数据）上进行验证。该评估过程旨在模仿人工智能系统在野外数据上的部署；那些目前系统未发现但预计会在临床环境中遇到的情况。然而，当野外数据与保留的数据集不同时（这种现象被称为分布变化）并且缺乏真实注释，基于人工智能的发现在多大程度上可以信任真实数据就变得不清楚。荒野。在这里，我们介绍 SUDO，一个用于在没有真实注释的情况下评估人工智能系统的框架。 SUDO 将临时标签分配给野外的数据点，并直接使用它们来训练不同的模型，其中性能最高的模型表示最可能的标签。通过针对皮肤学图像、组织病理学贴片和临床报告开发的 AI 系统进行实验，我们表明 SUDO 可以成为模型性能的可靠代理，从而识别不可靠的预测。我们还证明，SUDO 可以为模型的选择提供信息，并允许在没有真实注释的情况下对野外数据的算法偏差进行以前无法评估的评估。对不可靠的预测进行分类以进行进一步检查和评估人工智能系统的算法偏差的能力可以提高研究结果的完整性，并有助于在医学中部署道德人工智能系统。]]></description>
      <guid>https://arxiv.org/abs/2403.17011</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>RLHF 与 PPO 的 N+ 实现细节：TL;DR 总结案例</title>
      <link>https://arxiv.org/abs/2403.17031</link>
      <description><![CDATA[arXiv:2403.17031v1 公告类型：新
摘要：这项工作是第一个公开重现 OpenAI 开创性的 TL;DR 总结工作中报告的人类反馈强化学习 (RLHF) 缩放行为的工作。我们从头开始创建 RLHF 管道，列举了 20 多个关键实现细节，并在复制过程中分享了关键见解。我们经过 RLHF 训练的 Pythia 模型展示了响应质量的显着提升，该质量随模型大小而变化，我们的 2.8B、6.9B 模型的性能优于 OpenAI 发布的 1.3B 检查点。我们公开发布经过训练的模型检查点和代码，以促进进一步研究并加速该领域的进展 (\url{https://github.com/vwxyzjn/summarize_from_feedback_details})。]]></description>
      <guid>https://arxiv.org/abs/2403.17031</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>基于混合机器学习方法的随机参数降阶模型</title>
      <link>https://arxiv.org/abs/2403.17032</link>
      <description><![CDATA[arXiv:2403.17032v1 公告类型：新
摘要：为自然现象中的复杂系统建立适当的数学模型不仅有助于加深我们对自然的理解，而且可以用于状态估计和预测。然而，自然现象的极端复杂性使得开发全阶模型（FOM）并将其应用于研究许多感兴趣的数量变得极具挑战性。相比之下，适当的降阶模型（ROM）因其高计算效率和描述自然现象的关键动力学和统计特征的能力而受到青睐。以粘性Burgers方程为例，构建了卷积自编码器-储层计算-归一化流算法框架，其中卷积自编码器用于构造潜在空间表示，储层计算-归一化流框架用于表征演化潜在状态变量。这样，就构建了数据驱动的随机参数降阶模型来描述复杂系统及其动态行为。]]></description>
      <guid>https://arxiv.org/abs/2403.17032</guid>
      <pubDate>Wed, 27 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    </channel>
</rss>