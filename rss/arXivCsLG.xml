<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.LG 更新了 arXiv.org 电子打印档案。</description>
    <lastBuildDate>Mon, 12 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>EasyFS：通过特征的弹性变换实现高效的无模型特征选择框架</title>
      <link>https://arxiv.org/abs/2402.05954</link>
      <description><![CDATA[传统的无模型特征选择方法独立地处理每个特征，而忽略了特征之间的相互关系，这导致与模型感知方法相比性能相对较差。为了应对这一挑战，我们通过特征的弹性扩展和压缩提出了一种高效的无模型特征选择框架，即 EasyFS，以实现比最先进的模型感知方法更好的性能，同时共享效率和性能的特点。现有无模型方法的灵活性。特别是，EasyFS利用随机非线性投影网络扩展特征空间，实现原始特征的非线性组合，从而对特征之间的相互关系进行建模，发现最相关的特征。同时，提出了一种基于编码率变化的新颖冗余测量，以有效过滤冗余特征。对 21 个不同数据集的综合实验表明，EasyFS 在回归任务中优于最先进的方法高达 10.9%，在分类任务中优于最先进的方法高达 5.7%，同时节省超过 94% 的时间。]]></description>
      <guid>https://arxiv.org/abs/2402.05954</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>具有分裂可行性约束的可控帕累托前沿学习的超级变压器模型</title>
      <link>https://arxiv.org/abs/2402.05955</link>
      <description><![CDATA[可控帕累托前沿学习（CPFL）近似帕累托解集，然后针对给定的参考向量定位帕累托最优解。然而，在实践中，决策者的目标仅限于约束区域，因此我们只在约束区域上进行训练，而不是在整个决策空间上进行训练。具有分割可行性约束 (SFC) 的可控 Pareto 前沿学习是一种为满足特定约束的分割多目标优化问题找到最佳 Pareto 解决方案的方法。在之前的研究中，CPFL 使用了由多层感知器 (Hyper-MLP) 块组成的超网络模型。随着 Transformer 架构在深度学习方面的实质性进步，Transformer 在各种任务中都可以优于其他架构。因此，我们开发了带有 SFC 的 CPFL 超级变压器（Hyper-Trans）模型。我们使用序列到序列函数的通用逼近理论来表明，Hyper-Trans 模型在计算实验中使 MED 误差比 Hyper-MLP 模型更小。]]></description>
      <guid>https://arxiv.org/abs/2402.05955</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>Pathformer：具有用于时间序列预测的自适应路径的多尺度变压器</title>
      <link>https://arxiv.org/abs/2402.05956</link>
      <description><![CDATA[基于 Transformer 的模型在时间序列预测方面取得了一些成功。现有方法主要从有限或固定的尺度对时间序列进行建模，这使得捕获跨不同尺度的不同特征具有挑战性。在本文中，我们提出了具有自适应路径的多尺度变压器（Pathformer）。所提出的 Transformer 集成了时间分辨率和时间距离以进行多尺度建模。多尺度划分使用不同大小的块将时间序列划分为不同的时间分辨率。基于每个尺度的划分，对这些补丁执行双重关注，以捕获全局相关性和局部细节作为时间依赖性。我们进一步丰富了具有自适应路径的多尺度变压器，它根据输入时间序列中变化的时间动态自适应地调整多尺度建模过程，提高了 Pathformer 的预测精度和泛化能力。对 11 个真实世界数据集的大量实验表明，Pathformer 不仅超越了当前所有模型，实现了最先进的性能，而且在各种传输场景下表现出了更强的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2402.05956</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>\textit{SQT} -- \textit{std} $Q$-目标</title>
      <link>https://arxiv.org/abs/2402.05950</link>
      <description><![CDATA[\textit{Std} $Q$-target 是一个 \textit{conservative}、actor-critic、ensemble、基于 $Q$-learning 的算法，它基于单键 $Q$-formula：$Q$-网络标准差，这是一种“不确定性惩罚”，并且可以作为 \textit{overestimation} 偏差问题的简约解决方案。我们在 TD3/TD7 代码之上实现 \textit{SQT}，并在七个流行的 MuJoCo 和 Bullet 任务上针对最先进的 (SOTA) actor-critic 算法、DDPG、TD3 和 TD7 对其进行测试。我们的结果证明 \textit{SQT} 的 $Q$-target 公式优于 \textit{TD3} 的 $Q$-target 公式作为 RL 中高估偏差的 \textit{conservative} 解决方案，而 \textit{SQT在所有任务上，与 DDPG、TD3 和 TD7 相比，表现出明显的性能优势。]]></description>
      <guid>https://arxiv.org/abs/2402.05950</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>\textit{MinMaxMin} $Q$-学习</title>
      <link>https://arxiv.org/abs/2402.05951</link>
      <description><![CDATA[\textit{MinMaxMin} $Q$-learning 是一种新颖的 \textit{optimistic} Actor-Critic 算法，它解决了 \textit{overestimation} 偏差问题（$Q$-估计高估了真实的 $Q$-值）固有的问题在 \textit{保守} RL 算法中。其核心公式依赖于 $Q$-网络之间的分歧，其形式为最小批量 MaxMin $Q$-网络距离，该距离被添加到 $Q$-目标并用作优先体验重播采样规则。我们在 TD3 和 TD7 之上实现 \textit{MinMaxMin}，并在流行的 MuJoCo 和 Bullet 环境中针对最先进的连续空间算法（DDPG、TD3 和 TD7）对其进行严格的测试。结果表明，在所有测试任务中，\textit{MinMaxMin} 相对于 DDPG、TD3 和 TD7 都有一致的性能改进。]]></description>
      <guid>https://arxiv.org/abs/2402.05951</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型推进图表示学习：技术综合综述</title>
      <link>https://arxiv.org/abs/2402.05952</link>
      <description><![CDATA[大型语言模型 (LLM) 与图表示学习 (GRL) 的集成标志着复杂数据结构分析的重大发展。此次合作利用法学硕士复杂的语言能力来提高图模型的上下文理解和适应性，从而扩大 GRL 的范围和潜力。尽管越来越多的研究致力于将法学硕士整合到图领域，但深入分析这些模型中的核心组件和操作的全面审查却明显缺乏。我们的调查通过提出一种新颖的分类法来填补这一空白，该分类法从新颖的技术角度将这些模型分解为主要组件和操作技术。我们进一步将最近的文献剖析为两个主要组成部分，包括知识提取器和组织者，以及包括集成和训练策略在内的两种操作技术，阐明有效的模型设计和训练策略。此外，我们还确定并探索这个新兴但尚未充分探索的领域未来潜在的研究途径，并提出持续进展的路径。]]></description>
      <guid>https://arxiv.org/abs/2402.05952</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中可分离的多概念擦除</title>
      <link>https://arxiv.org/abs/2402.05947</link>
      <description><![CDATA[大规模扩散模型以其令人印象深刻的图像生成能力而闻名，引起了研究人员对社会影响的担忧，例如模仿受版权保护的艺术风格。作为回应，现有方法转向机器学习技术，以消除预训练模型中的不安全概念。然而，这些方法损害了生成性能，并忽略了多概念擦除之间的耦合以及概念恢复问题。为了解决这些问题，我们提出了一种可分离的多概念擦除器（SepME），它主要包括两部分：概念无关表示的生成和权重解耦。前者的目的是避免忘记与被遗忘的概念无关的大量信息。后者分离了可优化的模型权重，使得每个权重增量对应于特定的概念擦除，而不影响其他概念的生成性能。具体地，用于擦除指定概念的权重增量被公式化为基于其他已知的不需要的概念计算的解的线性组合。大量的实验表明我们的方法在消除概念、保持模型性能以及在擦除或恢复各种概念方面提供灵活性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.05947</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>DE$^3$-BERT：基于原型网络的 BERT 距离增强提前退出</title>
      <link>https://arxiv.org/abs/2402.05948</link>
      <description><![CDATA[早期退出已经证明了其通过动态调整执行层数来加速 BERT 等预训练语言模型推理的有效性。然而，大多数现有的早期现有方法仅考虑单个测试样本的局部信息来确定其现有指标，未能利用样本群体提供的全局信息。这会导致预测正确性的估计不理想，从而导致错误的现有决策。为了弥补这一差距，我们探讨了有效结合本地和全局信息的必要性，以确保推理过程中可靠的早期退出。我们有目的地利用原型网络来学习类原型，并设计样本和类原型之间的距离度量。这使我们能够利用全局信息来估计早期预测的正确性。在此基础上，我们提出了一种新颖的 BERT 距离增强早期退出框架（DE$^3$-BERT）。 DE$^3$-BERT 实现了一种混合退出策略，用基于距离的全局信息补充经典的基于熵的局部信息，以增强预测正确性的估计，从而获得更可靠的早期退出决策。 GLUE 基准上的大量实验表明，DE$^3$-BERT 在不同加速比下始终优于最先进的模型，且存储或计算开销最小，从而在模型性能和推理效率之间实现更好的权衡。此外，深入的分析进一步验证了我们方法的通用性和可解释性。]]></description>
      <guid>https://arxiv.org/abs/2402.05948</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>一种可解释的基于机器学习的方法，用于分析客户的在线数据以识别产品属性的重要性</title>
      <link>https://arxiv.org/abs/2402.05949</link>
      <description><![CDATA[在线客户数据为产品设计和营销研究提供了有价值的信息，因为它可以揭示客户的偏好。然而，由于潜在的隐藏模式，使用人工智能 (AI) 分析这些数据进行数据驱动设计是一项具有挑战性的任务。而且，在这些研究领域，大多数研究仅局限于寻找顾客的需求。在这项研究中，我们提出了一种博弈论机器学习（ML）方法，可以提取产品开发的综合设计含义。该方法首先使用遗传算法根据在线评级来选择、排名和组合可以最大限度提高客户满意度的产品功能。然后，我们使用 SHAP（SHapley Additive exPlanations），一种博弈论方法，根据每个特征对预测的贡献为其分配一个值，为评估每个特征对总满意度的重要性提供指导。我们将我们的方法应用于 Kaggle 的笔记本电脑的真实数据集，并根据结果得出设计含义。我们的方法解决了多标准决策领域的重大挑战，可以帮助产品设计师和营销人员以更少的数据和精力更好地了解客户偏好。所提出的方法在相关性能指标方面优于基准方法。]]></description>
      <guid>https://arxiv.org/abs/2402.05949</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>通过监督、分层概念学习消除硬概念瓶颈模型中的信息泄漏</title>
      <link>https://arxiv.org/abs/2402.05945</link>
      <description><![CDATA[概念瓶颈模型 (CBM) 旨在通过将特征和标签与人类可理解的概念联系起来，提供可解释和可干预的预测。虽然最近的 CBM 显示出有希望的潜力，但它们受到信息泄漏的影响，概念之外的意外信息（无论是用概率还是二进制状态表示概念时）都会泄漏到后续的标签预测中。因此，不同的类别通过难以区分的概念被错误地分类，破坏了 CBM 的解释和干预。
  本文通过在概念谓词中引入标签监督并构建层次概念集来缓解信息泄漏问题。因此，我们提出了一种新的 CBM 范式，即 SupCBM，它通过预测概念和精心设计的干预矩阵来实现标签预测。 SupCBM 关注与预测标签最相关的概念，并且仅在呈现不同概念时区分类别。我们的评估表明，SupCBM 在不同的数据集上优于 SOTA CBM。它还在不同的骨干模型之间表现出更好的通用性。通过对不同 CBM 中的信息泄漏进行适当量化，我们证明 SupCBM 显着减少了信息泄漏。]]></description>
      <guid>https://arxiv.org/abs/2402.05945</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>揭示潜在因果规则：异常事件解释的时点过程方法</title>
      <link>https://arxiv.org/abs/2402.05946</link>
      <description><![CDATA[在医疗保健等高风险系统中，了解异常事件（例如患者健康状况的突然变化）背后的因果关系至关重要。揭示因果关系有助于快速诊断和精确的治疗计划。在本文中，我们提出了一种自动化方法来揭示“如果-那么”逻辑规则来解释观察事件。我们引入时间点过程来对感兴趣的事件进行建模，并发现一组潜在规则来解释事件的发生。为了实现这一目标，我们采用期望最大化（EM）算法。在 E 步骤中，我们计算每个发现的规则解释每个事件的可能性。在 M 步骤中，我们更新规则集和模型参数以增强似然函数的下界。值得注意的是，我们以差异化的方式优化规则集。我们的方法在发现规则和识别根本原因方面展示了准确的性能。我们使用合成和真实的医疗数据集展示了其有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2402.05946</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>用于软件定义网络中实时异常检测的混合 IndRNNLSTM 方法</title>
      <link>https://arxiv.org/abs/2402.05943</link>
      <description><![CDATA[使用数据流预测进行 SDN 中的异常检测是一项艰巨的任务。该问题属于时间序列和回归问题的范畴。由于手动选择特征，机器学习方法在该领域具有挑战性。另一方面，由于特征的自动选择，深度学习方法具有重要的特征。同时，基于 RNN 的方法使用得最多。 LSTM 和 GRU 方法可以很好地学习依赖实体；另一方面，IndRNN 方法学习时间序列中的非依赖实体。所提出的方法尝试结合使用 IndRNN 和 LSTM 方法来学习相关和非相关特征。特征选择方法还为模型提供了合适的特征视图；为此，使用了四种特征选择模型：过滤器、包装器、嵌入式和自动编码器。所提出的IndRNNLSTM算法与Embedded相结合，能够在NSL-KDD数据上实现MAE=1.22和RMSE=9.92。]]></description>
      <guid>https://arxiv.org/abs/2402.05943</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>Todyformer：迈向具有结构感知标记化的整体动态图转换器</title>
      <link>https://arxiv.org/abs/2402.05944</link>
      <description><![CDATA[时间图神经网络因其对不断演变的结构和时间模式进行建模的能力而受到广泛关注，同时表现出令人印象深刻的性能。然而，众所周知，这些架构受到限制其性能的问题的困扰，例如过度挤压和过度平滑。与此同时，Transformers 展示了卓越的计算能力，可以有效解决与远程依赖相关的挑战。因此，我们引入了 Todyformer——一种为动态图量身定制的新型基于 Transformer 的神经网络。它将消息传递神经网络 (MPNN) 的本地编码能力与 Transformer 的全局编码结合起来，通过 i) 一种新颖的动态图修补范例来改善过度挤压，ii) 利用 MPNN 的结构感知参数标记化策略，iii ) 具有时间位置编码的 Transformer，用于捕获远程依赖性，以及 iv) 在局部和全局上下文之间交替的编码架构，减轻 MPNN 中的过度平滑。对公共基准数据集的实验评估表明，Todyformer 在下游任务方面始终优于最先进的方法。此外，我们还说明了所提出的模型在有效捕获动态图中广泛的时间依赖性方面的基本方面。]]></description>
      <guid>https://arxiv.org/abs/2402.05944</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>影响地下煤矿工作日损失的风险因素因果关系网络</title>
      <link>https://arxiv.org/abs/2402.05940</link>
      <description><![CDATA[本研究旨在利用新型因果人工智能（AI）方法建立导致地下煤矿工作日损失的各种因素之间的因果关系网络。该分析利用从美国国家职业安全与健康研究所 (NIOSH) 获得的数据。从 NIOSH 数据库中提取了 1990 年至 2020 年间 3,982 个独特地下煤矿的总共 101,010 条伤害记录。使用一种称为分组贪婪等价搜索（GGES）的新型因果人工智能方法对因果关系进行分析和可视化。通过干预微积分调整（IDA）分数评估每个变量对工作日损失的影响。使用10倍交叉验证技术进行模型训练和验证。使用性能指标来评估模型，包括邻接精度 (AP)、邻接召回率 (AR)、箭头精度 (AHP) 和箭头召回率 (AHR)。调查结果显示，2006年以后，导致采矿员工工作日损失的主要直接原因包括总采矿经验、平均办公室员工、平均井下员工、县和总采矿经验（年）。总采矿经验成为最有影响力的因素，而每个矿井的平均员工的影响力最小。分析强调了总采矿经验在确定工作日损失方面的重要作用。这些模型取得了最佳性能，AP、AR、AHP 和 AHR 值分别为 0.694、0.653、0.386 和 0.345。本研究证明了利用新的 GGES 方法通过分析就业人口统计数据和工伤记录并建立其因果关系网络来阐明工作日损失背后的因果因素的可行性。]]></description>
      <guid>https://arxiv.org/abs/2402.05940</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>合作知识蒸馏：一种与学习者无关的方法</title>
      <link>https://arxiv.org/abs/2402.05942</link>
      <description><![CDATA[知识蒸馏是一种在教师模型和学生模型之间迁移知识的简单但有效的方法。现有工作在转移方向和范围方面至少存在以下一项关键限制，限制了其使用：所有知识都从教师转移到学生，无论该知识是否有用，学生是唯一的学习者在这种交换中，通常蒸馏仅将知识从单个教师转移到单个学生。我们制定了一种新颖的知识蒸馏形式，其中许多模型可以充当学生和教师，我们称之为合作蒸馏。这些模型的协作方式如下：一个模型（学生）识别其性能中的具体缺陷，并搜索另一个模型（教师），该模型通过反事实实例生成将学到的知识编码到教学虚拟实例中。由于不同的模型可能有不同的优点和缺点，因此所有模型都可以在适当的时候充当学生或教师（合作），并且仅在其优势（重点）特定领域提取知识。由于反事实作为一种范式不依赖于任何特定的算法，因此我们可以使用这种方法在不同架构、算法甚至特征空间的学习者之间提取知识。我们证明，我们的方法不仅在多个数据集上优于迁移学习、自监督学习和多种知识蒸馏算法等基线，而且还可以在上述技术无法使用的环境中使用。]]></description>
      <guid>https://arxiv.org/abs/2402.05942</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:59 GMT</pubDate>
    </item>
    </channel>
</rss>