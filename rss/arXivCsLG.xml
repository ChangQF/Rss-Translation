<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 12 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>构建混合 B 样条和神经网络算子</title>
      <link>https://arxiv.org/abs/2406.06611</link>
      <description><![CDATA[arXiv:2406.06611v1 公告类型：新
摘要：控制系统对于确保汽车、飞机和导弹等各个领域的信息物理系统 (CPS) 的安全是必不可少的。保护 CPS 需要运行时方法，以持续监控安全关键条件并以可验证的安全方式做出响应。许多安全方法的一个基本方面涉及预测系统的未来行为。然而，实现这一点需要能够实时运行的精确模型。受 DeepONets 的启发，我们提出了一种新颖的策略，将 B 样条的归纳偏差与数据驱动的神经网络相结合，以促进对 CPS 行为的实时预测。我们引入了我们的混合 B 样条神经算子，确立了它作为通用近似器的能力，并对近似误差提供了严格的界限。这些发现适用于广泛的非线性自主系统，并通过在具有 12 维状态空间的受控 6 自由度 (DOF) 四旋翼飞行器上进行实验进行了验证。此外，我们对不同的网络架构（特别是全连接网络 (FCNN) 和循环神经网络 (RNN)）进行了比较分析，以阐明每种架构在现实场景中的实用性和权衡。]]></description>
      <guid>https://arxiv.org/abs/2406.06611</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>DualTime：用于时间序列表示的双适配器多模态语言模型</title>
      <link>https://arxiv.org/abs/2406.06620</link>
      <description><![CDATA[arXiv:2406.06620v1 公告类型：新
摘要：语言模型（LM）的近期快速发展引起了时间序列领域的关注，包括多模态时间序列建模。然而，我们注意到当前的时间序列多模态方法存在偏差，通常将主要角色分配给一种模态，而另一种模态则承担次要角色。他们忽视了不同模态的互利和互补。例如，在癫痫诊断中，仅依靠文本临床报告很难确定疾病的区域和类型，而单靠脑电图（EEG）如果不考虑症状则无法提供准确的诊断。在本研究中，基于时间序列多模态数据的互补信息挖掘，我们提出了 DualTime，这是一种用于时间序列表示的双适配器多模态语言模型，可同时实现时间主要和文本主要建模。通过注入轻量级自适应标记，双适配器共享的 LM 管道鼓励嵌入对齐并实现高效的微调。从经验上看，我们的方法在监督和无监督设置中都优于最先进的模型，凸显了不同模式的互补优势。此外，我们进行了少量标签转移实验，进一步验证了我们提出的 DualTime 的可转移性和表现力。]]></description>
      <guid>https://arxiv.org/abs/2406.06620</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>持续测试时间域自适应，在不断变化的操作条件下实现高效故障检测</title>
      <link>https://arxiv.org/abs/2406.06607</link>
      <description><![CDATA[arXiv:2406.06607v1 公告类型：新
摘要：故障检测在工业系统中至关重要，它通过区分异常和正常操作条件来防止故障和优化性能。随着来自复杂工业系统的状态监测数据量的增加，数据驱动方法在故障检测任务中越来越受欢迎。尽管取得了这些进展，但在现实场景中，早期故障检测仍然是一个挑战。操作条件和环境的高度可变性使得很难收集能够代表所有可能操作条件的综合训练数据集，特别是在系统运行的早期阶段。此外，这些变化往往会随着时间的推移而发展，可能会导致未来出现以前从未见过的全新数据分布。这些挑战阻碍了不同单元之间和随着时间的推移而进行的直接知识转移，导致训练数据和测试数据之间的分布差距，并导致这些方法在现实场景中的性能下降。为了克服这个问题，我们的工作引入了一种用于连续测试时间域自适应的新方法。这通过解决域转移和有限的数据代表性问题实现了早期稳健的异常检测。我们提出了一个测试时间域自适应异常检测 (TAAD) 框架，该框架将输入变量分为系统参数和测量值，采用两个域自适应模块来独立适应每个输入类别。此方法可以有效地适应不断变化的操作条件，尤其适用于数据稀缺的系统。我们的方法在现实世界的泵监测数据集上进行了测试，与现有的域自适应方法相比，在故障检测方面有显著的改进，表明准确性和可靠性得到了提高。]]></description>
      <guid>https://arxiv.org/abs/2406.06607</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>改善数据集压缩中的虚假相关性</title>
      <link>https://arxiv.org/abs/2406.06609</link>
      <description><![CDATA[arXiv:2406.06609v1 公告类型：新
摘要：数据集压缩是一种将大型数据集压缩为较小的合成数据集的技术，有助于下游训练任务。在本文中，我们研究了原始数据集内部的偏差对数据集压缩性能的影响。通过对具有颜色、损坏和背景偏差的典型数据集进行全面的实证评估，我们发现原始数据集中的颜色和背景偏差将通过压缩过程被放大，导致在压缩数据集上训练的模型性能显着下降，而损坏偏差则通过压缩过程得到抑制。
为了减少数据集压缩中的偏差放大，我们介绍了一种简单但非常有效的方法，该方法基于利用核密度估计的样本重新加权方案。在多个真实世界和合成数据集上的实证结果证明了该方法的有效性。
值得注意的是，在偏差冲突率为 5% 且 IPC 为 50 的 CMNIST 上，我们的方法实现了 91.5% 的测试准确率，而 vanilla DM 的测试准确率仅为 23.8%，性能提高了 67.7%，而在同一数据集上应用最先进的去偏差方法只能实现 53.7% 的准确率。
我们的研究结果强调了在数据集压缩过程中解决偏差的重要性，并为解决过程中的偏差放大问题提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2406.06609</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>基于行为的新能源汽车对城市生态影响建模</title>
      <link>https://arxiv.org/abs/2406.06602</link>
      <description><![CDATA[arXiv:2406.06602v1 公告类型：new 
摘要：节能减排、改善生态环境的迫切需要推动了新能源汽车需求的激增。通过对新能源汽车进行行为分析和使用模式挖掘，可以识别出特定的模式。例如，电池超载、电池电量不足、超速行驶都会对电池性能产生不利影响。为了评估这种驾驶行为对城市生态的影响，提出了一种环境计算建模方法来模拟新能源汽车与环境的相互作用。为了扩展汽车全生命周期的时间序列数据和模型序列数据中的生态环境，采用带有贝叶斯优化器的LSTM模型进行仿真。分析揭示了不良驾驶行为对环境的不利影响。]]></description>
      <guid>https://arxiv.org/abs/2406.06602</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>FPN-fusion：增强线性复杂度时间序列预测模型</title>
      <link>https://arxiv.org/abs/2406.06603</link>
      <description><![CDATA[arXiv:2406.06603v1 公告类型：新
摘要：本研究提出了一种新颖的时间序列预测模型 FPN-fusion，该模型具有线性计算复杂度，与 DLiner 相比，在不增加参数数量或计算需求的情况下表现出卓越的预测性能。我们的模型引入了两个关键创新：首先，采用特征金字塔网络 (FPN) 来有效捕获时间序列数据特征，绕过传统的趋势和季节性成分分解。其次，开发了多级融合结构，无缝集成深层和浅层特征。从经验上看，FPN-fusion 在八个开源数据集上的 32 个测试用例中的 31 个中表现优于 DLiner，均方误差 (MSE) 平均减少 16.8%，平均绝对误差 (MAE) 平均减少 11.8%。此外，与基于 Transformer 的 PatchTST 相比，FPN-fusion 在 32 个测试项目中仅使用了 PatchTST 总计算负载的 8%，就获得了 10 个最佳 MSE 和 15 个最佳 MAE 结果。]]></description>
      <guid>https://arxiv.org/abs/2406.06603</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>大规模可区分组合调度</title>
      <link>https://arxiv.org/abs/2406.06593</link>
      <description><![CDATA[arXiv:2406.06593v1 公告类型：新
摘要：本文讨论了资源受限调度的复杂问题，这是一个 NP 难题，涉及芯片设计和高性能计算等关键领域。传统的调度方法经常因可扩展性和适用性挑战而受阻。我们提出了一种使用可微分组合调度框架的新方法，利用 Gumbel-Softmax 可微分采样技术。这项新技术允许对基于线性规划 (LP) 的调度进行完全可微分的公式化，将其应用扩展到更广泛的 LP 公式化。为了对调度任务的不等式约束进行编码，我们引入了 \textit{constrained Gumbel Trick}，它可以熟练地对任意不等式约束进行编码。因此，我们的方法通过梯度下降促进了高效且可扩展的调度，而无需训练数据。对合成和真实基准的比较评估凸显了我们显著提高调度优化效率的能力，在大多数设计中超越了 CPLEX、Gurobi 和 CP-SAT 等商业和开源求解器提供的最先进的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.06593</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>使用图神经网络对网络数字孪生进行 5G 以上网络故障分类</title>
      <link>https://arxiv.org/abs/2406.06595</link>
      <description><![CDATA[arXiv:2406.06595v1 公告类型：新
摘要：网络数字孪生 (NDT) 中的第五代 (5G) 核心网络是一个具有众多组件的复杂系统，会产生大量数据。由于故障类型罕见，分析这些数据可能具有挑战性，导致多类分类中的类别不平衡。为了解决这个问题，我们提出了一种将图傅里叶变换 (GFT) 集成到为 NDT 设计的消息传递神经网络 (MPNN) 中的新方法。此方法使用 GFT 将数据转换为图以解决类别不平衡问题，而 MPNN 提取特征并模拟网络组件之间的依赖关系。这种组合方法可识别真实和模拟 NDT 环境中的故障​​类型，展示了其在 5G 及更高版本 (B5G) 网络中准确分类故障的潜力。此外，MPNN 擅长在端到端环境中学习邻居之间的复杂局部结构。大量实验表明，所提出的方法可以在真实网络和 NDT 环境中的多个故障点识别三个多类域数据集中的故障类型。结果表明，提出的 GFT-MPNN 可以准确地对 B5G 网络中的网络故障进行分类，尤其是在 NDT 中用于检测故障类型时。]]></description>
      <guid>https://arxiv.org/abs/2406.06595</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>HORAE：一种用于自动化多模式服务监管的领域无关建模语言</title>
      <link>https://arxiv.org/abs/2406.06600</link>
      <description><![CDATA[arXiv:2406.06600v1 公告类型：新
摘要：人工智能正在迅速侵入服务监管领域。这项工作介绍了 HORAE 背后的设计原则，HORAE 是一种统一的规范语言，用于对跨不同领域的多模式监管规则进行建模。我们展示了 HORAE 如何通过进一步利用名为 HORAE 的微调大型语言模型来促进智能服务监管流程，该模型可自动化 HORAE 建模过程，从而产生一个端到端的全自动智能服务监管框架。]]></description>
      <guid>https://arxiv.org/abs/2406.06600</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>神经网络训练的自适应多个最优学习因子</title>
      <link>https://arxiv.org/abs/2406.06583</link>
      <description><![CDATA[arXiv:2406.06583v1 公告类型：新
摘要：本论文提出了一种新的神经网络训练方法，解决了确定最佳学习因子数量的挑战。所提出的自适应多重最佳学习因子 (AMOLF) 算法根据每次乘法的误差变化动态调整学习因子的数量，从而提高训练效率和准确性。论文还介绍了基于目标函数曲率对权重进行分组的技术以及压缩大型 Hessian 矩阵的技术。实验结果表明，与 OWO-MOLF 和 Levenberg-Marquardt 等现有方法相比，AMOLF 具有更优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.06583</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>离散时间动力系统可解释模型的表达符号回归</title>
      <link>https://arxiv.org/abs/2406.06585</link>
      <description><![CDATA[arXiv:2406.06585v1 公告类型：新
摘要：定义离散时间动态系统（迭代映射）的可解释数学表达式可以模拟许多科学感兴趣的现象，从而更深入地理解系统行为。由于从第一原理制定控制表达式可能很困难，因此仅根据数据流识别迭代映射的表达式尤其令人感兴趣。在这项工作中，我们考虑为此任务使用经过修改的符号人工神经网络训练表达式 (SymANNTEx) 架构，该架构比文献中的其他架构更具表现力。我们对模型管道进行了修改以优化回归，然后描述调整后的模型在识别几个经典混沌映射中的行为。为了实现简约，我们实现了稀疏性诱导权重正则化和信息论信息简化。我们表明，我们修改后的 SymANNTEx 模型可以正确识别单状态图，并在近似双状态吸引子方面取得了一定的成功。这些表现为数据驱动的科学发现和解释提供了重要希望。]]></description>
      <guid>https://arxiv.org/abs/2406.06585</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>通过动态参数调整彻底改变大型语言模型训练</title>
      <link>https://arxiv.org/abs/2406.06564</link>
      <description><![CDATA[arXiv:2406.06564v1 公告类型：新
摘要：在大型语言模型时代，对高效利用计算资源的需求变得至关重要。尽管参数高效的微调技术已经取得了与完全微调相当的结果，但它们在预训练阶段的应用带来了重大挑战。具体而言，在预训练开始时采用参数高效的策略会严重影响效率，尤其是在较大的模型中。在本文中，我们基于微调方法 LoRA，引入了一种新颖的参数高效的训练技术，该技术频繁改变参数的可训练部分，从而促进有效的预训练。我们的方法不仅在预训练阶段实现了与当前最先进的参数高效算法相当的内存减少和计算开销，而且还保持了与完全预训练相当的准确度水平。我们提供理论分析和实证证据来证明我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.06564</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>DHA：通过自适应头部融合从 Transformer 检查点学习解耦头部注意力</title>
      <link>https://arxiv.org/abs/2406.06567</link>
      <description><![CDATA[arXiv:2406.06567v1 公告类型：新
摘要：具有数十亿个参数的大型语言模型（LLM）表现出令人印象深刻的性能。然而，LLM中广泛使用的多头注意力（MHA）在推理过程中会产生大量的计算和内存成本。虽然一些努力通过修剪头部或在头部之间共享参数来优化注意力机制，但这些方法往往会导致性能下降或需要大量的持续预训练成本来恢复性能。基于注意力冗余的分析，我们设计了一种解耦头部注意力（DHA）机制。DHA自适应地配置跨各个层的关键头和值头的组共享，从而实现性能和效率之间的更好平衡。受到对相似头部聚类观察的启发，我们提出通过逐步线性融合相似的头部参数，将MHA检查点逐步转换为DHA模型，同时保留MHA检查点的参数知识。我们通过给定目标头部预算来转换各种尺度的MHA检查点来构建DHA模型。实验表明，DHA 仅需原始模型预训练预算的 0.25% 即可实现 97.6% 的性能提升，同时节省了 75% 的 KV 缓存。与 Group-Query Attention (GQA) 相比，DHA 实现了 5 倍的训练加速，在 0.01% 的预训练预算下性能提升最高可达 13.93%，在 0.05% 的预训练预算下性能提升相对可达 4%。]]></description>
      <guid>https://arxiv.org/abs/2406.06567</guid>
      <pubDate>Wed, 12 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bert、Roberta 和 Xlnet 进行分子特性预测的集成模型</title>
      <link>https://arxiv.org/abs/2406.06553</link>
      <description><![CDATA[arXiv:2406.06553v1 公告类型：新
摘要：本文提出了一种无需大量预训练即可高精度预测分子特性的新方法。我们的方法采用集成学习和 BERT、RoBERTa 和 XLNet 的监督微调，与现有的高级模型相比，具有显著的有效性。至关重要的是，它解决了实验组面临的计算资源有限的问题，使他们能够准确预测分子特性。这项创新提供了一种经济高效且资源高效的解决方案，有可能推动分子领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2406.06553</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>Lean4 中的自动化形式化评估基准</title>
      <link>https://arxiv.org/abs/2406.06555</link>
      <description><![CDATA[arXiv:2406.06555v1 公告类型：新
摘要：大型语言模型 (LLM) 有可能彻底改变自动形式化。数学编程语言 Lean4 的引入为严格评估 LLM 的自动形式化能力提供了前所未有的机会。本文介绍了一种为 Lean4 设计的新型评估基准，并将其应用于测试最先进的 LLM 的能力，包括 GPT-3.5、GPT-4 和 Gemini Pro。我们的全面分析表明，尽管最近取得了进展，但这些 LLM 在自动形式化方面仍然存在局限性，特别是在更复杂的数学领域。这些发现强调了进一步开发 LLM 的必要性，以充分利用其在科学研究和开发中的潜力。这项研究不仅对当前的 LLM 能力进行了基准测试，而且为未来自动形式化的增强奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2406.06555</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    </channel>
</rss>