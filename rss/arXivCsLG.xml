<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>超越单价值指标：通过认知诊断评估和增强LLM学习的LLM</title>
      <link>https://arxiv.org/abs/2502.13996</link>
      <description><![CDATA[ARXIV：2502.13996V1公告类型：新 
摘要：由于LLM的广泛使用以及关键的道德和安全问题的增加，已开发出LLM学习方法来消除有害知识和不良能力。在这种情况下，评估主要基于单值指标，例如QA准确性。但是，这些指标通常无法捕获有害知识组成部分的细微差别，因此很难评估未学习的真正有效性。为了解决这个问题，我们提出了UNCD（通过认知诊断进行评估），这是一个新型框架，利用认知诊断建模来进行LLM的细粒度评估。我们专用的基准测试UNCD-Cyber​​提供了详细评估危险功能的删除。此外，我们介绍了UNCD代理，该代理通过诊断知识残留物并生成有针对性的学习数据来完善不学习。在八种未学习方法和两个基本模型上进行的广泛实验表明，UNCD不仅增强了评估，而且有效地促进了有害LLM的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.13996</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在现代Hopfield网络中纠正Lagrangian用于分布式检测</title>
      <link>https://arxiv.org/abs/2502.14003</link>
      <description><![CDATA[ARXIV：2502.14003V1公告类型：新 
摘要：现代Hopfield Networks（MHNS）最近在人工智能领域引起了极大的关注，因为它们可以存储和检索具有指数较大的内存能力的大量模式。 MHN通常是一个由记忆和特征神经元的拉格朗日定义的动态系统，其中与特征空间中的吸引子表示与分布（ID）样本相关的记忆。现有MHN的一个主要问题在于管理分布外（OOD）样本，因为最初假定所有样本都是ID样本。为了解决这个问题，我们提出了纠正的拉格朗日（Reglag），这是一种新的Lagrangian，用于记忆神经元，该神经元明确地将OOD样品的吸引子纳入MHNS的动力学系统中。 Reclag为任何相互作用矩阵创建一个微不足道的吸引子，从而通过识别落入该吸引子为OOD的样品来实现OOD检测。相互作用矩阵进行了优化，因此可以估计概率密度以识别ID/OOD。与基于能量的OOD检测方法相比，我们证明了基于RECLAG的MHN的有效性，包括在九个图像数据集中使用最先进的Hopfield Energies的MHN。]]></description>
      <guid>https://arxiv.org/abs/2502.14003</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>较小但更好：通过较小的大语言模型统一布局产生</title>
      <link>https://arxiv.org/abs/2502.14005</link>
      <description><![CDATA[ARXIV：2502.14005V1公告类型：新 
摘要：我们提出了LGGPT，这是一种针对统一布局生成的基于LLM的模型。首先，我们将任意布局指令（ALI）和通用布局响应（ULR）作为统一I/O模板。 ALI可以在多个布局域上容纳任意布局生成任务输入，从而使LGGPT能够统一任务生成和域的布局生成迄今未探索的生成。总体而言，Ali和Ulr拥有一种简洁的结构，它放弃了通常以HTML基于HTML的格式发现的多余令牌，从而促进了有效的教学调整并提高统一的生成性能。此外，我们提出了一个间隔量化编码（IQE）策略，该策略将ALI压缩为更凝结的结构。 IQE准确地保留了有效的布局线索，同时消除了较少信息的占位符，从而促进LGGPT在统一培训过程中捕获复杂而可变的布局生​​成条件。实验结果表明，与现有方法相比，LGGPT取得了优越或par性能。值得注意的是，LGGPT与紧凑的1.5B参数LLM之间的熟练程度和效率之间达到了显着的平衡，即使在最广泛，最具挑战性的统一场景中，它也比以前的7B或175B模型击败了先前的7B或175B模型。此外，我们强调了使用LLM进行统一布局生成的必要性，并建议1.5B可以通过比较不同尺度的LLM来成为最佳参数大小。代码可在https://github.com/niceringnode/lggpt上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.14005</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>哪个关注点对文化学习至关重要？</title>
      <link>https://arxiv.org/abs/2502.14010</link>
      <description><![CDATA[ARXIV：2502.14010V1公告类型：新 
摘要：大型语言模型（LLMS）具有令人印象深刻的内在学习能力（ICL）功能，使他们能够仅使用提示中的几个演示执行新任务。已经提出了两种不同的机制来解释ICL：查找和复制相关令牌的诱导头，以及功能向量（FV）头的激活计算ICL任务的潜在编码。为了更好地了解两种不同的机制中的哪种驱动ICL，我们研究和比较了12个语言模型中的归纳头和FV头。
  通过详细的消融，我们发现很少有ICL性能主要取决于FV头部，尤其是在较大的模型中。此外，我们发现FV和感应头连接在一起：许多FV头是在过渡到FV机制之前训练期间作为诱导头开始的。这使我们推测诱导有助于学习最终驱动ICL的更复杂的FV机制。]]></description>
      <guid>https://arxiv.org/abs/2502.14010</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DFDT：边缘设备上的物联网数据流挖掘的动态快速决策树</title>
      <link>https://arxiv.org/abs/2502.14011</link>
      <description><![CDATA[ARXIV：2502.14011V1公告类型：新 
摘要：物联网产生了大量的数据流，Edge Computing作为在线IoT应用程序和5G网络的关键推动器出现。边缘解决方案有助于实时机器学习推断，但也需要对概念漂移的持续适应。基于整体的解决方案提高了预测性能，但会产生更高的资源消耗，延迟和内存需求。本文介绍了DFDT：动态快速决策树，这是一种新型算法，旨在用于节能记忆约束的数据流挖掘。 DFDT通过动态调整宽限期，绑定阈值和基于传入数据的分裂评估来提高Hoeffding树的生长效率。它结合了更严格的评估规则（基于熵，信息增益和叶子实例计数），自适应膨胀模式以及叶片停用机制来管理记忆，从而可以在经常访问的节点上进行更多计算，同时在其他方面节省能量。实验表明，所提出的框架可以在内存约束和VFDT或SVFDT的运行时获得提高的预测性能（0.43 vs 0.29排名）。]]></description>
      <guid>https://arxiv.org/abs/2502.14011</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我想要全部（一次） - 超级群集层次结构</title>
      <link>https://arxiv.org/abs/2502.14018</link>
      <description><![CDATA[ARXIV：2502.14018V1公告类型：新 
摘要：分层聚类是探索性数据分析的强大工具，将数据组织到可以选择分区的聚类树中。本文通过证明，对于任何合理的层次结构，都可以最佳地解决基于中心的聚类目标（例如$ k $ -Means）来概括这些想法。此外，这些解决方案可以很快找到，并且本身必须是层次结构。因此，鉴于一个集群树，我们表明人们可以快速访问许多新的，同样有意义的层次结构。就像在标准层次结构聚类中一样，就可以从这些新层次结构中选择任何所需的分区。我们通过验证跨数据集，层次结构和分区方案的拟议技术的实用性来结束。]]></description>
      <guid>https://arxiv.org/abs/2502.14018</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过知识蒸馏的动态激活，用于节能尖峰NN合奏</title>
      <link>https://arxiv.org/abs/2502.14023</link>
      <description><![CDATA[ARXIV：2502.14023V1公告类型：新 
摘要：尽管Foundation AI模型在分类和决策等任务中表现出色，但它们的高能量消耗使它们不适合能源受限的应用。受大脑效率的启发，尖峰神经网络（SNN）由于事件驱动的性质和与神经形态芯片的兼容性而成为可行的替代方法。这项工作引入了一个新型系统，该系统结合了知识蒸馏和集合学习，以弥合人工神经网络（ANN）和SNN之间的性能差距。基金会AI模型充当教师网络，指导较小的学生SNN组成一个合奏，称为Spiking Neural Ensemble（SNE）。 SNE可以解散教师知识，使每个学生在处理相同的输入的同时专门预测其独特的方面。 SNE的核心创新是SNN模型的一个自适应激活，利用知识依据，并通过老师特征空间的知情分区（DISENTANGEMERT）增强。通过动态激活这些学生SNN的一部分，系统可以平衡准确性和能源效率，从而获得了可观的能源节省，而精度损失最小。此外，SNE比教师网络的效率要高得多，将计算要求降低了20倍，而CIFAR-10数据集的准确性仅下降了2％。与其他分区方案相比，这种分解程序的准确性提高了CIFAR-10数据集的准确性高达2.4％。最后，我们在嘈杂的条件下相对分析了SNE的性能，与ANN老师相比表明了鲁棒性的增强。总之，SNE为能源受限的应用提供了一个有希望的新方向。]]></description>
      <guid>https://arxiv.org/abs/2502.14023</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>寻求帮助可实现安全保证而无需牺牲效力</title>
      <link>https://arxiv.org/abs/2502.14043</link>
      <description><![CDATA[ARXIV：2502.14043V1公告类型：新 
摘要：大多数强化学习算法都以遗憾保证依赖一个关键假设：所有错误都是可恢复的。 Plaut等人的最新工作。丢弃了这一假设，并提出了算法，以避免通过寻求帮助来避免“灾难”（即无法弥补的错误）。但是，他们只提供了安全保证，并且不考虑奖励最大化。我们证明，在任何马尔可夫决策过程（MDP）中，任何避免灾难的算法也可以保证高奖励（即sublinear遗憾），包括带有不可逆转成本的MDP。这构成了通用MDP的第一个无重组保证。更广泛地说，我们的结果可能是第一个正式的证据，即代理商有可能获得高奖励，同时在未知，无限制和高风险环境中自给自足而不造成灾难或需要重置。]]></description>
      <guid>https://arxiv.org/abs/2502.14043</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>职位：长期序列中没有冠军预测</title>
      <link>https://arxiv.org/abs/2502.14045</link>
      <description><![CDATA[ARXIV：2502.14045V1公告类型：新 
摘要：长期时间序列预测的最新进展引入了许多复杂的预测模型，这些模型始终超过先前发表的体系结构。但是，这种快速的进步引起了人们对基准测试和报告实践不一致的担忧，这可能会破坏这些比较的可靠性。我们的立场强调需要将重点从追求不断增加的复杂模型转移到通过严格和标准化的评估方法来增强基准实践。为了支持我们的主张，我们首先通过培训14个数据集的3500多个网络对最受欢迎的基准测试的最佳模型进行广泛，透彻和可重复的评估。然后，通过全面的分析，我们发现对实验设置或当前评估指标的略有变化极大地改变了人们普遍的信念，即新发表的结果正在推动艺术的状态。我们的发现表明需要进行严格和标准化的评估方法，以实现更多的证实主张，包括可重复的超参数设置和统计测试。]]></description>
      <guid>https://arxiv.org/abs/2502.14045</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>走向表示形式的学习理论</title>
      <link>https://arxiv.org/abs/2502.14047</link>
      <description><![CDATA[ARXIV：2502.14047V1公告类型：新 
摘要：最近有人争辩说，随着其规模和性能的提高，AI模型的表示形式变得一致。经验分析旨在支持这一想法，并猜测不同表示形式可能与共享的现实统计模型的一致性。在本文中，我们提出了一种学习理论的观点来对齐。首先，我们根据度量，概率和光谱思想审查并连接不同的对齐方式。然后，我们将重点放在缝线上，这是一种在任务背景下理解不同表示之间相互作用的特殊方法。我们这里的主要贡献是将缝合的特性与基础表示的内核比对有关。我们的结果可以看作是施放表示形式作为学习理论问题的第一步。]]></description>
      <guid>https://arxiv.org/abs/2502.14047</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在低维矢量符号结构上进行矢量优化</title>
      <link>https://arxiv.org/abs/2502.14075</link>
      <description><![CDATA[ARXIV：2502.14075V1公告类型：新 
摘要：矢量符号体系结构（VSA）由于其效率而出现在机器学习中，但由于高度高度和准确性的问题而阻碍了它们。作为一种有希望的缓解，低维计算方法（LDC）方法通过采用基于梯度的优化来显着降低矢量维度约100倍，同时保持准确性。尽管具有潜力，但对VSA的最不发达国家优化仍未得到充实。我们对矢量更新的调查强调了稳定的自适应动态在最不发达国家培训中的重要性。我们还揭示了标准方法中批处理标准化（BN）和知识蒸馏（KD）的忽视而关键的作用。除了准确性提升外，BN在推断过程中不会增加计算开销，而KD显着提高了推理置信度。通过跨多个基准测试的广泛实验和消融研究，我们对我们的方法进行了彻底的评估，并扩展了类似于LDC的二元神经网络优化的可解释性，该优化类似于LDC，以前在BNN文献中未受解固。]]></description>
      <guid>https://arxiv.org/abs/2502.14075</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从最终用户数据中学习具有对内核密度的差异隐私</title>
      <link>https://arxiv.org/abs/2502.14087</link>
      <description><![CDATA[ARXIV：2502.14087V1公告类型：新 
摘要：我们研究了从最终用户分发的私人数据收集和学习的设置。在改组的差异隐私模型中，最终用户在共享数据之前部分保护其数据，并且他们的数据在收集过程中也被匿名化以增强隐私。该模型最近已成为Central DP的突出替代方法，该模型需要完全信任中央数据策展人和本地DP，在该DP上，完全本地数据保护对下游精度造成了巨大的损失。
  我们的主要技术结果是一个洗牌的DP协议，用于私下估计分布式数据集的内核密度函数，精度基本上与中央DP匹配。我们使用它通过学习每个类别的私人密度函数来私下从最终用户数据中学习分类器。此外，我们表明，尽管在没有任何未受保护的数据的情况下被学到了，但密度函数本身可以恢复其类的语义内容。我们的实验表明了我们方法的下游表现，并在实际的ML部署了改组的DP时突出了下游的关键注意事项和权衡。]]></description>
      <guid>https://arxiv.org/abs/2502.14087</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对齐的多目标优化</title>
      <link>https://arxiv.org/abs/2502.14096</link>
      <description><![CDATA[ARXIV：2502.14096V1公告类型：新 
摘要：迄今为止，多目标优化文献主要集中于相互矛盾的目标，研究帕累托阵线或要求用户平衡折衷方案。但是，在机器学习实践中，在许多情况下没有发生这种冲突。多任务学习，加强学习和LLMS培训的最新发现表明，各种相关的任务可以同时提高目标的绩效。尽管有这些证据，但尚未从优化的角度检查这种现象。这导致缺乏基于通用梯度的方法，这些方法可以扩展到具有大量相关目标的方案。为了解决这一差距，我们介绍了对齐的多目标优化框架，为此设置提出了新算法，并提供了与幼稚方法相比，其优越性能的理论保证。]]></description>
      <guid>https://arxiv.org/abs/2502.14096</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>零损失保证和明确的最小化器，用于通用过度兼容的深度学习网络</title>
      <link>https://arxiv.org/abs/2502.14114</link>
      <description><![CDATA[ARXIV：2502.14114V1公告类型：新 
摘要：我们确定了过多散射深度学习（DL）网络的足够条件，以确保在监督学习的背景下，零损失的可实现性，对于$ \ Mathcal {l}^2 $成本和{\ em emic}培训数据。我们提出了零损耗最小化器的明确结构，而无需调用梯度下降。另一方面，我们指出，使用梯度下降算法，深度的增加可以通过分析训练雅各布的等级损失条件来恶化成本最小化的效率。我们的结果阐明了二分法之间的关键方面，差距差损失范围与过多隔离的DL之间的二分法之间的关键方面。]]></description>
      <guid>https://arxiv.org/abs/2502.14114</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>追逐木跟踪：机器学习以揭示收获地点的陈述错误</title>
      <link>https://arxiv.org/abs/2502.14115</link>
      <description><![CDATA[ARXIV：2502.14115V1公告类型：新 
摘要：非法伐木对全球生物多样性，气候稳定构成了重大威胁，并降低了国际收获和负责任的森林产品贸易的国际价格，影响了全球的生计和社区。稳定的同位素比分析（SIRA）迅速成为确定交易，有机产品的收获位置的重要工具。稳定的同位素比值中的空间模式取决于大气和环境条件等因素，因此可以用于地理识别。我们在这里介绍了部署的机器学习管道的结果，我们利用同位素值和大气变量来确定木材收获位置。此外，管道还包含不确定性估计，以促进分析师收获位置确定的解释。我们介绍了来自其全球范围的橡木（Quercus spp。）样品的集合。我们的管道的表现优于可比较的最新模型，这些模型决定了商业交易的木制产品的地理收获起源，并且已被欧洲执法机构使用，以识别进入欧盟市场的非法俄罗斯和白俄罗斯木材。我们还确定了进一步发展我们的框架的机会，以及如何将其推广，以帮助确定整个供应链中错误标记的有机产品的起源。]]></description>
      <guid>https://arxiv.org/abs/2502.14115</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>