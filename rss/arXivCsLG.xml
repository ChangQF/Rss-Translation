<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>超越联邦：基于拓扑感知的联邦学习，可推广至未见过的客户端</title>
      <link>https://arxiv.org/abs/2407.04949</link>
      <description><![CDATA[arXiv:2407.04949v1 公告类型：新
摘要：联邦学习被广泛用于处理分布式敏感数据。现有方法主要侧重于解决联邦内数据异质性问题。然而，我们观察到，当应用于未见客户端进行联邦外 (OOF) 泛化时，它们的性能会显著下降。最近针对未见客户端的泛化尝试通常难以扩展到大规模分布式设置，因为通信或计算成本高昂。此外，扩展性好的方法通常表现出较差的泛化能力。为了以可扩展的方式实现 OOF 弹性，我们提出了拓扑感知联邦学习 (TFL)，它利用客户端拓扑（表示客户端关系的图）来有效地针对 OOF 数据训练稳健模型。我们为 TFL 制定了一个新颖的优化问题，该问题由两个关键模块组成：客户端拓扑学习，以隐私保护的方式推断客户端关系；客户端拓扑学习，利用学习到的拓扑识别有影响力的客户端并将此信息用于 FL 优化流程，以有效构建稳健模型。对各种真实数据集的实证评估验证了 TFL 卓越的 OOF 稳健性和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2407.04949</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>缩小差距：数据驱动报童问题的样本平均近似最优性</title>
      <link>https://arxiv.org/abs/2407.04900</link>
      <description><![CDATA[arXiv:2407.04900v1 公告类型：新
摘要：我们研究了样本平均近似 (SAA) 对于具有一般凸库存成本的数据驱动报童问题的遗憾性能。在文献中，SAA 的最优性在 \alpha-全局强凸性和 (\alpha,\beta)-局部强凸性（\alpha-在最优数量的 \beta-邻域内强凸）条件下尚未完全建立。本文弥补了这两种条件下遗憾上界和下界之间的差距。在 (\alpha,\beta)-局部强凸性条件下，我们证明了 SAA 的最优遗憾界限为 \Theta(\log T/\alpha + 1/ (\alpha\beta))。这个上限结果表明，从长远来看，SAA 的遗憾表现仅受 \alpha 的影响，而不受 \beta 的影响，这增强了我们对局部属性如何影响决策策略的长期遗憾表现的理解。在 \alpha-全局强凸性条件下，我们证明任何数据驱动方法的最坏情况遗憾的下界为 \Omega(\log T/\alpha)，这是第一个与参数 \alpha 和时间范围 T 的现有上限相匹配的下界结果。在此过程中，我们建议通过一种新的梯度近似技术以及一类新的平滑倒帽形难题实例来分析 SAA 遗憾，这些实例可能对更广泛的数据驱动问题的下界具有独立的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2407.04900</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:03 GMT</pubDate>
    </item>
    <item>
      <title>矢量量化中嵌入数量及其维数的平衡</title>
      <link>https://arxiv.org/abs/2407.04939</link>
      <description><![CDATA[arXiv:2407.04939v1 公告类型：新
摘要：嵌入的维数和可用嵌入的数量（也称为码本大小）是影响矢量量化（VQ）性能的关键因素，矢量量化（VQ）是一种离散化过程，用于许多模型，例如矢量量化变分自动编码器（VQ-VAE）架构。本研究考察了 VQ 中码本大小和嵌入维度之间的平衡，同时保持它们的乘积不变。传统上，这些超参数在训练期间是静态的；然而，我们的研究结果表明，增加码本大小同时减少嵌入维度可以显著提高 VQ-VAE 的有效性。因此，在保留离散码本空间容量的同时，战略性地选择码本大小和嵌入维度至关重要。为了解决这个问题，我们提出了一种新颖的自适应动态量化方法，该方法以 Gumbel-Softmax 机制为基础，允许模型自主确定每个数据实例的最佳码本配置。这种动态离散化器为 VQ-VAE 提供了非凡的灵活性。对多个基准数据集进行的全面实证评估验证了我们的方法所取得的显著性能提升，凸显了自适应动态量化在提高模型性能方面的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.04939</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:03 GMT</pubDate>
    </item>
    <item>
      <title>利用分层学习率改进迁移学习中的知识提炼</title>
      <link>https://arxiv.org/abs/2407.04871</link>
      <description><![CDATA[arXiv:2407.04871v1 公告类型：新
摘要：当学习任务的复杂性增加时，迁移学习方法的表现开始变差。这些方法中的大多数计算所有匹配特征的累积差异，然后使用它们在所有层中反向传播该损失。与这些方法相反，在这项工作中，我们提出了一种新颖的分层学习方案，该方案根据输出激活相对于网络参数的雅可比/注意/黑塞的差异来调整每层的学习参数。我们将这种新方案应用于基于注意力图和基于导数（一阶和二阶）的迁移学习方法。我们在各种数据集上获得了更好的学习性能和稳定性。从广泛的实验评估中，我们观察到，随着学习任务的难度增加，我们的方法实现的性能提升变得更加显著。]]></description>
      <guid>https://arxiv.org/abs/2407.04871</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:02 GMT</pubDate>
    </item>
    <item>
      <title>两层 ReLU 网络的差分隐私凸近似</title>
      <link>https://arxiv.org/abs/2407.04884</link>
      <description><![CDATA[arXiv:2407.04884v1 公告类型：新
摘要：我们表明，可以私下训练凸问题，使模型具有与使用差分隐私随机梯度下降 (DP-SGD) 训练的单隐层 ReLU 网络类似的隐私效用权衡。正如我们所展示的，这可以通过 ReLU 最小化问题的某种对偶公式实现。我们推导出对偶问题的随机近似，该近似导致强凸问题，这允许应用例如基于梯度的隐私优化器的迭代类型分析的隐私放大，特别是允许为具有固定不相交小批量的嘈杂循环小批量梯度下降提供准确的隐私界限。我们在 MNIST 和 FashionMNIST 问题上获得了嘈杂循环小批量梯度下降的第一个实证结果，这些结果显示了与应用于 ReLU 网络的 DP-SGD 类似的隐私效用权衡。我们概述了理论效用界限，以说明 ReLU 网络的私有凸近似的加速。]]></description>
      <guid>https://arxiv.org/abs/2407.04884</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:02 GMT</pubDate>
    </item>
    <item>
      <title>探索性模仿学习：一种适用于连续环境的路径签名方法</title>
      <link>https://arxiv.org/abs/2407.04856</link>
      <description><![CDATA[arXiv:2407.04856v1 公告类型：新
摘要：一些模仿学习方法将行为克隆与自我监督相结合，以从状态对中推断动作。然而，大多数方法都依赖于大量的专家轨迹来提高泛化能力，并依靠人工干预来捕捉问题的关键方面，例如领域约束。在本文中，我们提出了从观察中进行持续模仿学习 (CILO)，这是一种增强模仿学习的新方法，具有两个重要特征：(i) 探索，允许更多样化的状态转换，需要更少的专家轨迹并减少训练迭代；(ii) 路径签名，允许通过创建代理和专家轨迹的非参数表示来自动编码约束。我们在五种环境中将 CILO 与基线和两种领先的模仿学习方法进行了比较。它在所有环境中都具有所有方法中最好的整体性能，在其中两种环境中的表现优于专家。]]></description>
      <guid>https://arxiv.org/abs/2407.04856</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:01 GMT</pubDate>
    </item>
    <item>
      <title>增强贝叶斯策略搜索</title>
      <link>https://arxiv.org/abs/2407.04864</link>
      <description><![CDATA[arXiv:2407.04864v1 公告类型：新
摘要：在物理系统上实施时，确定性策略通常比随机策略更受青睐。它们可以防止不稳定和有害行为，同时更易于实施和解释。然而，在实践中，探索主要由随机策略执行。一阶贝叶斯优化 (BO) 方法提供了一种使用确定性策略进行探索的原则性方法。这是通过学习目标函数及其梯度的概率模型来完成的。尽管如此，这种方法将策略搜索视为黑箱问题，因此忽略了问题的强化学习性质。在这项工作中，我们利用性能差异引理为概率模型引入了一种新的均值函数。这导致使用动作值函数增强 BO 方法。因此，我们将我们的方法称为增强贝叶斯搜索~(ABS)。有趣的是，这种新的均值函数通过确定性策略梯度增强了后验梯度，有效地弥合了 BO 和策略梯度方法之间的差距。由此产生的算法将直接策略搜索的便利性与强化学习的可扩展性相结合。我们在高维运动问题上验证了 ABS，并展示了与现有直接策略搜索方案相比具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.04864</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:01 GMT</pubDate>
    </item>
    <item>
      <title>RPN：面向统一 PGM、核 SVM、MLP 和 KAN 的协调多项式网络</title>
      <link>https://arxiv.org/abs/2407.04819</link>
      <description><![CDATA[arXiv:2407.04819v1 公告类型：新
摘要：在本文中，我们将介绍一种用于深度函数学习的新型深度模型，即协调多项式网络 (RPN)。RPN 具有非常通用的架构，可用于构建具有各种复杂性、容量和完备程度的模型，这些都有助于这些模型的正确性。如副标题所示，RPN 还可以作为将不同基础模型统一为一个规范表示的主干。这包括非深度模型，如概率图模型 (PGM) - 例如贝叶斯网络和马尔可夫网络 - 和核支持向量机 (核 SVM)，以及深度模型，如经典的多层感知器 (MLP) 和最近的 Kolmogorov-Arnold 网络 (KAN)。
从技术上讲，RPN 建议将要推断的底层函数分解为数据扩展函数和参数协调函数的内积。 RPN 与余数函数一起，可以精确地逼近控制数据分布的底层函数。RPN 中的数据扩展函数将数据向量从输入空间投影到定义中的扩展函数指定的高维中间空间。同时，RPN 还引入了参数协调函数，将少量参数合成高阶参数矩阵，以解决数据扩展导致的“维数灾难”问题。此外，余数函数为 RPN 提供了额外的补充信息，以减少潜在的近似误差。我们对多种模态的大量基准数据集进行了广泛的实证实验，包括连续函数数据集、离散视觉和语言数据集以及经典表格数据集，以研究 RPN 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.04819</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>拥有许多优秀的模型就能创造奇迹</title>
      <link>https://arxiv.org/abs/2407.04846</link>
      <description><![CDATA[arXiv:2407.04846v1 公告类型：新
摘要：Leo Breiman 提出的“罗生门效应”描述了同一数据集存在许多同样好的预测模型的现象。这种现象发生在许多真实数据集中，当它发生时，它既会引发奇迹，也会引发惊愕，但主要是奇迹。鉴于罗生门效应，这篇观点文章提出重塑我们对机器学习的看法，特别是针对非确定性（嘈杂）环境中的表格数据问题。我们讨论了罗生门效应如何影响（1）简单而准确的模型的存在，（2）灵活地解决用户偏好，例如公平性和单调性，而不会损失性能，（3）预测、公平性和解释的不确定性，（4）可靠的变量重要性，（5）算法选择，具体而言，提供有关哪些算法可能适合给定问题的高级知识，以及（6）公共政策。我们还讨论了“罗生门效应”发生的时间和原因的理论。我们的目标是说明“罗生门效应”如何对使用机器学习解决社会复杂问题产生巨大影响。]]></description>
      <guid>https://arxiv.org/abs/2407.04846</guid>
      <pubDate>Tue, 09 Jul 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>公平子模块封面</title>
      <link>https://arxiv.org/abs/2407.04804</link>
      <description><![CDATA[arXiv:2407.04804v1 公告类型：新
摘要：子模优化是机器学习中许多应用的基本问题，通常涉及对具有敏感属性（例如性别或年龄）的数据集进行决策。在这种情况下，通常希望生成一个相对于这些属性公平分布的多样化解决方案集。受此启发，我们开始研究公平子模覆盖 (FSC)，其中给定一个基本集 $U$、一个单调子模函数 $f:2^U\to\mathbb{R}_{\ge 0}$、一个阈值 $\tau$，目标是找到一个具有最小基数的平衡子集 $S$，使得 $f(S)\ge\tau$。我们首先介绍实现双准则近似比 $(\frac{1}{\epsilon}, 1-O(\epsilon))$ 的 FSC 离散算法。然后，我们提出一种连续算法，该算法实现了 $(\ln\frac{1}{\epsilon}, 1-O(\epsilon))$-双准则近似比，该近似比与无公平性约束的子模覆盖的最佳近似保证相匹配。最后，我们通过一系列实证评估来补充我们的理论结果，这些评估证明了我们的算法在最大覆盖实例上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.04804</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>简化深度时间差分学习</title>
      <link>https://arxiv.org/abs/2407.04811</link>
      <description><![CDATA[arXiv:2407.04811v1 公告类型：新
摘要：Q 学习在强化学习 (RL) 领域发挥了基础性作用。然而，具有离策略数据的 TD 算法（例如 Q 学习）或非线性函数逼近（例如深度神经网络）需要一些额外的技巧来稳定训练，主要是重放缓冲区和目标网络。不幸的是，目标网络中冻结网络参数的延迟更新会损害样本效率，同样，重放缓冲区会引入内存和实现开销。在本文中，我们研究是否有可能在保持稳定性的同时加速和简化 TD 训练。我们的关键理论结果首次证明，正则化技术（例如 LayerNorm）可以产生可证明收敛的 TD 算法，而无需目标网络，即使使用离策略数据也是如此。从经验上讲，我们发现，由矢量化环境支持的在线并行采样可以稳定训练，而无需重放缓冲区。受这些发现的启发，我们提出了 PQN，这是我们简化的深度在线 Q 学习算法。令人惊讶的是，这种简单的算法可以与更复杂的方法相媲美，例如：Atari 中的 Rainbow、Hanabi 中的 R2D2、Smax 中的 QMix、Craftax 中的 PPO-RNN，并且比传统 DQN 快 50 倍，而不会牺牲样本效率。在 PPO 成为首选 RL 算法的时代，PQN 重新确立了 Q 学习作为可行替代方案的地位。我们的代码可在以下网址获取：https://github.com/mttga/purejaxql。]]></description>
      <guid>https://arxiv.org/abs/2407.04811</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>SPINEX：基于相似性的预测，利用可解释邻居探索进行异常和离群值检测</title>
      <link>https://arxiv.org/abs/2407.04760</link>
      <description><![CDATA[arXiv:2407.04760v1 公告类型：新
摘要：本文介绍了 SPINEX（基于相似性的可解释邻居探索预测）系列中的一种新型异常和离群值检测算法。该算法利用跨多个子空间的相似性和高阶交互的概念来识别离群值。进行了一组全面的实验来评估 SPINEX 的性能。该算法针对 21 种常用的异常检测算法进行了测试，即基于角度的异常值检测 (ABOD)、基于连通性的异常值因子 (COF)、基于 Copula 的异常值检测 (COPOD)、ECOD、椭圆包络 (EE)、带 KNN 的特征装袋、高斯混合模型 (GMM)、基于直方图的异常值得分 (HBOS)、孤立森林 (IF)、孤立神经网络集成 (INNE)、核密度估计 (KDE)、K 最近邻 (KNN)、轻量级在线异常检测器 (LODA)、基于线性模型偏差的检测器 (LMDD)、局部异常值因子 (LOF)、最小协方差行列式 (MCD)、一类 SVM (OCSVM)、二次 MCD (QMCD)、稳健协方差 (RC)、随机异常值选择 (SOS) 和子空间异常值检测（SOD），以及来自不同领域、具有各种维度和复杂度的 39 个合成和真实数据集。此外，还进行了复杂性分析以检查所提算法的复杂性。我们的结果表明，SPINEX 实现了卓越的性能，优于常用的异常检测算法，并且具有中等复杂度（例如，O（n log n d））。更具体地说，SPINEX 在合成数据集上排名第一，在真实数据集上排名第七。最后，展示了 SPINEX 的可解释性能力以及未来的研究需求。]]></description>
      <guid>https://arxiv.org/abs/2407.04760</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>量化和剪枝对深度强化学习模型的影响</title>
      <link>https://arxiv.org/abs/2407.04803</link>
      <description><![CDATA[arXiv:2407.04803v1 公告类型：新
摘要：深度强化学习 (DRL) 在各个领域都取得了显著的成功，例如视频游戏、机器人技术以及最近的大型语言模型。然而，DRL 模型的计算成本和内存要求通常会限制它们在资源受限环境中的部署。这一挑战凸显了探索神经网络压缩方法的迫切需要，以使 RDL 模型更加实用和广泛适用。我们的研究调查了两种突出的压缩方法、量化和修剪对 DRL 模型的影响。我们研究了这些技术如何影响四个性能因素：平均回报、内存、推理时间和各种 DRL 算法和环境中的电池利用率。尽管模型尺寸有所减小，但我们发现这些压缩技术通常不会提高 DRL 模型的能效，但模型尺寸会减小。我们深入了解了模型压缩和 DRL 性能之间的权衡，为在资源受限的环境中部署高效的 DRL 模型提供了指导。]]></description>
      <guid>https://arxiv.org/abs/2407.04803</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>可信联邦学习中隐私-效用权衡的统一学习扭曲数据框架</title>
      <link>https://arxiv.org/abs/2407.04751</link>
      <description><![CDATA[arXiv:2407.04751v1 公告类型：新
摘要：在本文中，我们首先基于贝叶斯隐私定义和总变分距离隐私定义介绍联邦学习中隐私效用平衡的理论基础。然后，我们提出了 \textit{Learn-to-Distort-Data} 框架，该框架通过明确将隐私保护机制引入的扭曲建模为可学习变量并与模型参数联合优化，提供了一种导航隐私效用平衡的原则性方法。我们展示了我们的框架对基于数据扭曲的各种隐私保护机制的适用性，并强调了它与对抗性训练、输入鲁棒性和不可学习示例等相关领域的联系。这些联系使得能够利用这些领域的技术在 \textit{Learn-to-Distort-Data} 框架下设计联邦学习中隐私效用平衡的有效算法。]]></description>
      <guid>https://arxiv.org/abs/2407.04751</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>SpikeLLM：通过基于显着性的脉冲将脉冲神经网络扩展到大型语言模型</title>
      <link>https://arxiv.org/abs/2407.04752</link>
      <description><![CDATA[arXiv:2407.04752v1 公告类型：新
摘要：具有数十亿个参数的大型语言模型 (LLM) 的最新进展显著提高了它们在各种实际应用中的性能。然而，这些模型的推理过程需要大量的能源和计算资源，带来了相当大的部署挑战。相比之下，人类大脑包含大约 860 亿个生物神经元，与具有相似数量参数的 LLM 相比，其能源效率明显更高。受此启发，我们使用生物可信的脉冲机制重新设计了 70 亿到 700 亿个参数的 LLM，模拟人脑的有效行为。我们提出了第一个脉冲大型语言模型，即最近的 LLM，称为 SpikeLLM。与所提出的模型相结合，引入了一种名为 Optimal Brain Spiking 的新型脉冲驱动量化框架，通过两种基本方法降低能量成本并加快推理速度：基于一阶（二阶）微分的显着通道检测，以及使用广义积分和激发神经元的每通道显着异常值扩展。我们提出的脉冲驱动量化可以插入量化训练方法的主流。在 OmniQuant 管道中，SpikeLLM 显着降低了 25.51% 的 WikiText2 困惑度，并在 LLAMA2-7B 4A4W 模型上将 6 个零样本数据集的平均准确率提高了 3.08%。在 GPTQ 管道中，SpikeLLM 实现了稀疏三元量化，在所有线性层中实现了加法。与具有类似操作的 PB-LLM 相比，SpikeLLM 也显着超越。我们将在 GitHub 上发布我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2407.04752</guid>
      <pubDate>Tue, 09 Jul 2024 06:20:57 GMT</pubDate>
    </item>
    </channel>
</rss>