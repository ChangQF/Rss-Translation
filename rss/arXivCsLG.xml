<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 机器学习 (cs.LG) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Mon, 04 Dec 2023 03:14:40 GMT</lastBuildDate>
    <item>
      <title>Elijah：通过分布转移消除扩散模型中注入的后门。 （arXiv：2312.00050v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00050</link>
      <description><![CDATA[扩散模型 (DM) 已成为最先进的生成模型，因为
他们有能力从噪声中生成高质量图像，而无需
对抗性训练。然而，它们很容易受到后门攻击，因为
最近的研究报道。当数据输入（例如，一些高斯噪声）
带有触发器的印记（例如，白色补丁），后门模型总是
生成目标图像（例如，不正确的照片）。然而，有效
减少 DM 后门的防御策略尚未得到充分探索。到桥
针对这一差距，我们提出了第一个后门检测和删除框架
私信。我们在 3 种类型的数百个 DM 上评估我们的框架 Elijah，包括
DDPM、NCSN 和 LDM，具有 13 个采样器，针对 3 个现有后门攻击。
大量实验表明我们的方法可以实现接近 100% 的检测
准确性并将后门效应降低到接近于零，而不会显着
牺牲模型效用。
]]></description>
      <guid>http://arxiv.org/abs/2312.00050</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:40 GMT</pubDate>
    </item>
    <item>
      <title>MIA-BAD：一种通过联邦学习增强成员推理攻击及其缓解方法。 （arXiv：2312.00051v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00051</link>
      <description><![CDATA[成员推理攻击（MIA）是一种流行的妥协范例
机器学习 (ML) 模型的隐私。 MIA 充分利用自然
机器学习模型过度拟合训练数据的倾向。 MIA 接受过培训
区分训练和测试预测置信度来推断
会员信息。联邦学习 (FL) 是一种保护隐私的 ML
范式使多个客户端能够训练统一的模型，而无需
泄露他们的私人数据。在本文中，我们建议加强会员资格
使用批量生成的攻击数据集进行推理攻击（MIA-BAD）
对 MIA 方法的修改。我们调查发现 MIA 更准确
当攻击数据集批量生成时。这在数量上减少了
攻击数据集，同时对其进行定性改进。我们展示了如何训练 ML
通过 FL 建立模型，具有一些明显的优势并研究威胁如何
所提出的 MIA-BAD 方法引入的问题可以通过 FL 来缓解
接近。最后，我们展示了所提出的定性效果
MIA-BAD 方法通过对各种目标进行广泛的实验
数据集、可变数量的联合客户端以及训练批量大小。
]]></description>
      <guid>http://arxiv.org/abs/2312.00051</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:40 GMT</pubDate>
    </item>
    <item>
      <title>使用卷积神经网络和本地二进制模式进行演示攻击检测。 （arXiv：2312.00041v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00041</link>
      <description><![CDATA[使用生物识别技术来验证用户身份并控制对安全的访问
近年来，生物识别访问变得非常流行
控制系统经常被政府和私人使用
公司。然而，这些系统在以下情况下可能会带来安全风险：
部署时未考虑生物特征识别攻击的可能性
（也称为欺骗）。演示攻击是一个严重的威胁，因为
他们不需要大量的时间、费用或技能来执行
对当今使用的许多生物识别系统仍然有效。这项研究
比较三种不同的基于软件的面部和虹膜方法
图像中的演示攻击检测。第一种方法使用 Inception-v3，
谷歌预训练的深度卷积神经网络（CNN）
ImageNet 挑战赛，针对这个问题进行了重新训练。第二个使用
基于改进的 Spoofnet 架构的浅层 CNN，经过训练
通常情况下。第三种是使用局部二进制模式的基于纹理的方法
（腰痛）。使用的数据集是ATVS-FIr数据集，包含真实和虚假
虹膜图像，以及 CASIA 人脸反欺骗数据集，其中包含真实的
图像以及变形照片、剪切照片和视频回放演示
攻击。我们还提出了第三组结果，基于裁剪版本
CASIA 图像。
]]></description>
      <guid>http://arxiv.org/abs/2312.00041</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>DeepTreeGANv2：点云的迭代池化。 （arXiv：2312.00042v1 [物理.数据-an]）</title>
      <link>http://arxiv.org/abs/2312.00042</link>
      <description><![CDATA[在高能物理中，详细且耗时的模拟用于
粒子与探测器的相互作用。要绕过这些模拟
生成模型，短时间内生成大点云
需要，而粒子之间的复杂依赖关系必须是
正确建模。粒子簇射本质上是基于树的过程，
每个粒子都是由粒子的衰变或探测器相互作用产生的
上一代。在这项工作中，我们提出了一个重要的扩展
DeepTreeGAN，具有评论家功能，能够聚合此类点云
以基于树的方式迭代。我们证明这个模型可以重现
复杂的分布，我们评估其在公共 JetNet 150 上的性能
数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.00042</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>通证化模型：区块链赋能的去中心化模型所有权验证平台。 （arXiv：2312.00048v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00048</link>
      <description><![CDATA[随着生成式人工智能等实用深度学习模型的发展，
他们的优异表现带来了巨大的经济价值。例如，
ChatGPT 在三个月内吸引了超过 1 亿用户。自从
模型训练需要大量的数据和计算能力，一个性能良好的模型
深度学习模型的背后是巨大的努力和成本。面对各种型号
来自网络的攻击、未经授权的使用和滥用，威胁到
除了考虑法律和其他方面之外，模型所有者的利益
行政措施，保护模型的权利同样重要
版权来自于技术手段。利用模型水印技术，
我们指出建立模型所有权统一平台的可能性
确认。回顾区块链在版权领域的应用历史
验证以及中心化​​第三方的弊端，本文
考虑将模型水印技术与区块链结合起来构建
统一模型版权保护平台。通过我们称为的新解决方案
代币化模型，通过可靠的所有权记录保护模型的版权
和验证机制。它还通过以下方式提升模型的财务价值：
构建模型的交易过程和贡献份额
模型。在典型案例研究中，我们还研究了在
通常的场景来验证这个平台的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.00048</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>声学网络安全：利用语音激活系统。 （arXiv：2312.00039v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00039</link>
      <description><![CDATA[在这项研究中，我们调查了听不见的声音的新威胁
针对数字语音助理的攻击，这是一个严重的问题，因为他们
预计到 2024 年患病率将超过全球人口。我们的研究
将这些攻击的可行性扩展到亚马逊等各种平台
Alexa、Android、iOS 和 Cortana，揭示了其中的重大漏洞
智能设备。已确定的 12 种攻击媒介包括成功的
操纵智能家居设备和汽车系统，潜在的违规行为
军事通信以及关键基础设施安全方面的挑战。
我们定量表明，攻击成功率徘徊在 60% 左右，其中
能够从 100 英尺以外远程激活设备。此外，
这些攻击威胁到关键基础设施，强调需要
结合声学屏蔽、先进信号的多方面防御策略
处理、机器学习和强大的用户身份验证来缓解这些问题
风险。
]]></description>
      <guid>http://arxiv.org/abs/2312.00039</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>使用小波变换和深度残差神经网络进行演示攻击检测。 （arXiv：2312.00040v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00040</link>
      <description><![CDATA[生物识别身份验证在安全方面变得越来越普遍
身份验证系统。然而，生物识别物质可能会被欺骗
冒名顶替者以多种方式。在其他冒名顶替者攻击中，打印攻击、
掩码攻击和重放攻击属于演示攻击类别。
生物识别图像，尤其是虹膜和面部，很容易受到
不同的呈现攻击。这项研究应用了深度学习方法
减轻生物识别访问控制系统中的演示攻击。我们的
本文的贡献有两个：首先，我们应用了小波变换
从生物识别图像中提取特征。其次，我们修改了深度
残差神经网络并将其应用于欺骗数据集，试图
检测演示攻击。这项研究应用了所提出的方法
生物识别欺骗数据集，即 ATVS、CASIA 二类和 CASIA 裁剪图像
套。本研究中使用的数据集包含捕获的图像
受控和非受控环境以及不同的分辨率
和尺寸。我们在 ATVS Iris 数据集上获得了 93% 的最佳准确率。为了
CASIA 两类和 CASIA 裁剪数据集，我们实现了 91% 的测试准确率
和82%，分别。
]]></description>
      <guid>http://arxiv.org/abs/2312.00040</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>通过个性化模型混淆进行隐私保护负载预测。 （arXiv：2312.00036v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00036</link>
      <description><![CDATA[智能电表的广泛采用提供了获取详细信息和
本地化负载消耗数据，适合训练楼宇级负载
预测模型。减轻模型引发的隐私问题
数据泄漏、联邦学习（FL）被提出。本文地址
训练有素的短期负荷预测模型的性能挑战
异构数据上的FL，强调通过模型保护隐私
混淆。我们提出的算法，隐私保护联邦学习
（PPFL），结合了每个地方的本地化培训的个性化层
智能电表。此外，我们采用差分隐私机制来
防止共享层的数据泄漏。 NREL 模拟
ComStock 数据集证实了我们方法的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.00036</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>用于稳健学习刚性化学动力学的物理约束 NeuralODE 方法。 （arXiv：2312.00038v1 [physical.comp-ph]）</title>
      <link>http://arxiv.org/abs/2312.00038</link>
      <description><![CDATA[与解决详细化学问题相关的高计算成本
对预测计算流体动力学 (CFD) 提出了重大挑战
湍流反应流的模拟。这些模型通常需要解决
耦合刚性常微分方程 (ODE) 系统。虽深
已经尝试了学习技术来开发更快的替代品
模型，它们通常无法与 CFD 求解器可靠地集成。这
不稳定性的出现是因为深度学习方法针对训练误差进行了优化
不确保与 ODE 求解器的兼容性，导致累积
随着时间的推移会出现错误。最近，基于 NeuralODE 的技术提供了一种有前景的方法
通过有效地模拟化学动力学来解决。在这项研究中，我们扩展
通过结合质量实现刚性化学动力学的 NeuralODE 框架
训练期间将守恒约束直接纳入损失函数。这
确保总质量和元素质量守恒，这是一个关键
与 CFD 求解器进行可靠的下游集成的要求。我们的成果
证明这种增强不仅提高了物理一致性
符合质量守恒标准，但也确保更好的鲁棒性
并使训练过程的计算效率更高。
]]></description>
      <guid>http://arxiv.org/abs/2312.00038</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>彻底改变法医工具标记分析：客观透明的比较算法。 （arXiv：2312.00032v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00032</link>
      <description><![CDATA[取证工具标记比较目前由人类主观执行，
这导致缺乏一致性和准确性。证据很少
检查员可以确定成对的标记是否是由同一工具制作的
或不同的工具。也没有什么证据表明他们可以做到这一点
在不同条件下进行标记时的分类，例如
不同的攻击角度或标记生成方向。我们生成
3D原始工具标记数据，从每个工具标记中提取信号，并训练
客观比较工具标记信号的算法。我们找到那个工具标记
信号按工具聚集，而不是按角度或方向聚集。那就是
无论角度/方向如何，工具内的变异性都小于
工具之间的可变性。已知匹配和已知不匹配的密度
即使考虑到，标记对的相似性也有很小的重叠
数据中的依赖性，使它们成为确定的有用工具
一对新标记是否是用同一工具制作的。我们提供一个可能性
比率方法作为将工具标记信号与度量进行比较的正式方法
的不确定性。这种经过经验训练的开源方法可以被使用
法医检查员能够客观地比较工具标记，从而提高
工具标记比较的可靠性。这反过来又可以减少流产
刑事司法系统中的正义。
]]></description>
      <guid>http://arxiv.org/abs/2312.00032</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>FBChain：基于区块链的高效、安全通信的联邦学习模型。 （arXiv：2312.00035v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00035</link>
      <description><![CDATA[联邦参数传输过程中的隐私和安全
学习是目前最突出的问题之一。然而，有
不受保护的通信方式导致的两个棘手问题：
“参数泄漏”和“低效通信”。本文提出
基于区块链的联邦学习 (FBChain) 联邦学习模型
参数通信克服了上述两个问题。首先，我们利用
区块链的不变性来存储全局模型和哈希值
本地模型参数以防通信过程中被篡改，
通过参数加密保护数据隐私，通过数据一致性验证
比较本地参数的哈希值，从而寻址
“参数泄漏”问题。二、加权链接速度证明（PoWLS）
共识算法综合选择链接权重较高的节点
速度聚合全局模型和包块，从而解决
“沟通效率低下”问题。实验结果表明
我们提出的 FBChain 模型的有效性及其改进模型的能力
联邦学习中的沟通效率。
]]></description>
      <guid>http://arxiv.org/abs/2312.00035</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以修补安全问题吗？ （arXiv：2312.00024v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00024</link>
      <description><![CDATA[大型语言模型 (LLM) 在代码方面表现出了令人印象深刻的熟练程度
一代。尽管如此，与人类开发人员类似，这些模型可能
生成包含安全漏洞和缺陷的代码。安全书写
代码仍然是一个巨大的挑战，因为在执行过程中经常会出现漏洞
程序与外部系统或服务之间的交互，例如
数据库和操作系统。在本文中，我们提出了一种新颖的方法，
反馈驱动解决方案综合（FDSS），旨在探索法学硕士的使用
从静态代码分析工具 Bandit 接收反馈，以及
然后法学硕士会生成潜在的解决方案来解决安全漏洞。
然后，每个解决方案以及易受攻击的代码都会被发送回法学硕士
代码细化。我们的方法比基线有了显着的改进
并优于现有方法。此外，我们引入了一个新的数据集，
PythonSecurityEval，从 Stack Overflow 上的真实场景中收集
评估法学硕士生成安全代码的能力。代码和数据可用
在 \url{https://github.com/Kamel773/LLM-code-refine}
]]></description>
      <guid>http://arxiv.org/abs/2312.00024</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>安全变压器推理。 （arXiv：2312.00025v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00025</link>
      <description><![CDATA[我们提出了一个三方协议，可以保护 Transformer
推理阶段的参数和用户数据。对于每个前馈
推理过程中，我们的协议仅引入了排列计算
用户端输入和输出数据。我们的协议，Secure Transformer
推理协议 (STIP) 可应用于 ChatGPT 等现实世界的服务。
]]></description>
      <guid>http://arxiv.org/abs/2312.00025</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>使用联合学习和乐观汇总的服务质量合规系统。 （arXiv：2312.00026v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00026</link>
      <description><![CDATA[边缘计算带来了一种新的范式，其中计算共享、
存储和带宽资源尽可能靠近移动设备或
传感器产生大量数据。一个平行的趋势是崛起
手机和平板电脑是许多人的主要计算设备。强者
这些设备上存在传感器，再加上它们是移动的，
意味着他们可以访问前所未有的多样化和私密性数据。
基于这些数据学习的模型有望通过以下方式大大提高可用性：
为更智能的应用程序提供动力，但数据的敏感性
意味着将其存储在集中存储中存在风险和责任
地点。解决这些设备中某些数据所需的数据隐私问题
我们建议使用联邦学习（FL），以便特定数据
客户端执行的服务不会离开源计算机。代替
共享数据，用户仅通过发送权重来协作训练模型
更新到服务器。然而，在这些场景中天真的使用 FL 暴露了它
在培训阶段存在腐败风险，无论是有意还是无意。
为了提高FL结构的安全性，我们提出了一种去中心化的
边缘计算场景中基于区块链的 FL。我们还应用区块链
在 FL 中创建奖励机制，以实现培训师的激励策略。
]]></description>
      <guid>http://arxiv.org/abs/2312.00026</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>基于物理信息的传输方程神经网络来预测建筑材料的屈服强度。 （arXiv：2312.00003v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00003</link>
      <description><![CDATA[在这项研究中，物理信息神经网络的应用
探索 (PINN) 模型来求解基于输运方程的偏微分
方程（偏微分方程）。主要目标是分析不同因素的影响
PINN 模型中结合的激活函数对其预测
性能，特别是评估均方误差 (MSE) 和平均值
绝对误差 (MAE)。研究中使用的数据集由一组不同的
输入与支柱直径、晶胞尺寸和
相应的屈服应力值。通过这次调查的目的是
了解PINN模型的有效性以及选择的意义
用于求解现实世界中复杂偏微分方程的适当激活函数
应用程序。结果表明激活函数的选择可能
对于这个特定的模型的预测准确性影响最小
问题。 PINN 模型展示了卓越的泛化能力，
表明其避免与所提供的数据集过度拟合的能力。这
研究强调了在绩效之间取得平衡的重要性
和计算效率，同时选择激活函数
具体的实际应用。这些有价值的发现有助于
促进对 PINN 作为有效工具的理解和潜在采用
用于解决不同科学和工程领域中具有挑战性的偏微分方程。
]]></description>
      <guid>http://arxiv.org/abs/2312.00003</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:34 GMT</pubDate>
    </item>
    </channel>
</rss>