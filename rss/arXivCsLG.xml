<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于深度学习的足球上下文冲刺分类</title>
      <link>https://arxiv.org/abs/2406.15659</link>
      <description><![CDATA[arXiv:2406.15659v1 公告类型：新
摘要：对足球中高强度跑步（或冲刺）的分析一直是体育科学研究人员和从业者感兴趣的话题。特别是，最近的研究建议根据战术目的对冲刺进行情境化，以更好地理解现代比赛的身体战术要求。然而，它们在可扩展性方面存在限制，因为人类专家必须为每场比赛手动分类数百次冲刺。为了应对这一挑战，本文提出了一个深度学习框架，用于自动将足球中的冲刺分为情境类别。通过部署 Set Transformers 和双向 GRU，所提出的模型涵盖了足球中多智能体轨迹的排列不变性和顺序性。我们使用通过人类注释者和基于规则的分类器的协作制作的类别标签来训练模型。实验结果表明，我们的模型将测试数据集中的冲刺分为 15 个类别，准确率为 77.65%，这意味着所提出的框架具有促进大规模足球冲刺综合分析的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.15659</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>将问题与解决方案匹配：解决机器学习问题的一种可解释的方法</title>
      <link>https://arxiv.org/abs/2406.15662</link>
      <description><![CDATA[arXiv:2406.15662v1 公告类型：新
摘要：各个领域的领域专家都被要求与数据科学家合作，探索使用 ML 技术来解决他们的问题。从领域问题/问题开始，基于 ML 的问题解决通常涉及三个步骤：(1) 将业务问题（问题域）表述为数据分析问题（解决方案域），(2) 根据领域要求和可用数据的属性，勾勒出基于 ML 的高级解决方案模式，以及 (3) 设计和改进解决方案模式的不同组件。必须有大量 ML 问题解决知识，ML 研究人员必须同意这些知识，并且 ML 从业者经常应用这些知识来解决最常见的问题。我们的工作是捕获这些知识，并将其体现在 ML 问题解决工作台中，以帮助非 ML 专家的领域专家探索 ML 解决方案空间。本文重点关注：1）领域问题、ML 问题和主要 ML 解决方案工件的表示，以及 2）启发式匹配函数，该函数有助于根据领域（专家）要求和训练数据的特征识别最适合当前领域问题的 ML 算法系列。我们回顾了相关工作并概述了验证工作台的策略]]></description>
      <guid>https://arxiv.org/abs/2406.15662</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>使用老虎机反馈测试线性规划的可行性</title>
      <link>https://arxiv.org/abs/2406.15648</link>
      <description><![CDATA[arXiv:2406.15648v1 公告类型：新
摘要：虽然最近的文献中出现了对受限老虎机问题的研究激增，但所有现有的方法都是从假设潜在问题的可行性开始的。我们发起了测试这种可行性假设的研究，特别是在线性老虎机设置中解决该问题，从而表征使用老虎机反馈对未知线性程序进行可行性测试的成本。具体来说，我们通过执行一系列动作 $x_t\in \mathbb{R}^d$ 并观察响应中的 $Ax_t + \mathrm{noise}$ 来测试对于未知的 $A \in \mathbb{R}^{m \times d}$，是否存在 $\exists x: Ax \ge 0$。通过将假设确定为确定极小极大博弈值的符号，我们基于低遗憾算法和非渐近对数定律构建了一种新型测试。我们证明该测试是可靠的，并且适应任何实例的“信号级别”$\Gamma,$，平均样本成本按 $\widetilde{O}(d^2/\Gamma^2)$ 缩放。我们通过可靠测试的样本成本的极小极大下限 $\Omega(d/\Gamma^2)$ 对此进行补充，通过捕获对 $d$ 的依赖性来控制先前的渐近下限，从而阐明现有文献中关于此类问题所缺失的基本见解。]]></description>
      <guid>https://arxiv.org/abs/2406.15648</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>用于估算飞机发动机剩余使用寿命 (RUL) 的物理信息机器学习 (PIML) 方法</title>
      <link>https://arxiv.org/abs/2406.15619</link>
      <description><![CDATA[arXiv:2406.15619v1 公告类型：新
摘要：本文旨在利用新兴的物理信息机器学习 (PIML) 领域来开发预测飞机发动机剩余使用寿命 (RUL) 的模型。我们将著名的基准 NASA 商用模块化航空推进系统模拟 (C-MAPSS) 数据作为本文的主要数据，该数据由各种不同操作模式下的传感器输出组成。C-MAPSS 是一个经过充分研究的数据集，文献中有许多现有研究使用经典和深度学习方法解决 RUL 预测问题。在没有已发表的支配 C-MAPSS 数据的经验物理定律的情况下，我们的方法首先使用随机方法从嘈杂的时间序列数据中估计支配物理模型。在我们的方法中，我们将各种传感器读数建模为受随机微分方程支配，并估计底层过程的相应过渡密度均值和方差函数。然后，我们在训练和推理过程中使用学习到的均值和方差函数增强 LSTM（长短期记忆）模型。我们基于 PIML 的方法不同于以前的方法，我们首先使用数据来学习物理。我们的结果表明，PIML 发现和解决方案方法非常适合这个问题，并且优于以前仅使用数据的深度学习方法，适用于此数据集和任务。此外，此处开发的框架非常灵活，可以适应其他情况（其他传感器模式或组合多物理环境），包括仅部分观察或了解底层物理的情况。]]></description>
      <guid>https://arxiv.org/abs/2406.15619</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>DataFreeShield：无需训练数据即可防御对抗性攻击</title>
      <link>https://arxiv.org/abs/2406.15635</link>
      <description><![CDATA[arXiv:2406.15635v1 公告类型：新
摘要：对抗性鲁棒性的最新进展依赖于丰富的训练数据集，其中使用外部或附加数据集已成为一种常见设置。然而，在现实生活中，出于安全和隐私问题，训练数据通常保持私密，而只有预训练的权重可供公众使用。在这种情况下，假设原始数据可访问的现有方法变得不适用。因此，我们研究了无数据对抗性鲁棒性的关键问题，我们尝试在不访问任何真实数据的情况下实现对抗性鲁棒性。通过初步研究，我们强调了问题的严重性，表明即使使用相似的域数据集，在没有原始数据集的情况下也很难实现鲁棒性。为了解决这个问题，我们提出了 DataFreeShield，它从两个角度解决问题：替代数据集生成和使用生成的数据进行对抗性训练。通过广泛的验证，我们表明 DataFreeShield 的表现优于基线，表明所提出的方法为对抗鲁棒性问题设置了第一个完全无数据的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.15635</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>MOUNTAINEER：用于比较局部解释的拓扑驱动可视化分析</title>
      <link>https://arxiv.org/abs/2406.15613</link>
      <description><![CDATA[arXiv:2406.15613v1 公告类型：新
摘要：随着黑盒机器学习 (ML) 技术在关键应用中的使用越来越多，对能够为模型预测提供透明度和可追溯性的方法的需求也日益增长。因此，大量针对黑盒模型的局部可解释性方法已经开发并普及。然而，由于其中一些方法的高维性、异构表示、不同尺度和随机性，机器学习解释仍然难以评估和比较。拓扑数据分析 (TDA) 可以成为该领域的一种有效方法，因为它可用于将归因转换为统一的图形表示，为不同解释方法之间的比较提供共同基础。
我们提出了一种新颖的拓扑驱动可视化分析工具 Mountaineer，它允许 ML 从业者通过将拓扑图链接回原始数据分布、模型预测和特征归因来交互式地分析和比较这些表示。 Mountaineer 有助于快速、迭代地探索 ML 解释，使专家能够更深入地了解解释技术，了解底层数据分布，从而得出关于模型行为的合理结论。此外，我们通过两个使用真实数据的研究案例展示了 Mountaineer 的实用性。在第一个案例中，我们展示了 Mountaineer 如何帮助我们比较黑盒 ML 解释，并辨别不同解释之间分歧的区域和原因。在第二个案例中，我们展示了如何使用该工具来比较和理解 ML 模型本身。最后，我们采访了三位行业专家，以帮助我们评估我们的工作。]]></description>
      <guid>https://arxiv.org/abs/2406.15613</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>BrowNNe：布朗非局部神经元和激活函数</title>
      <link>https://arxiv.org/abs/2406.15617</link>
      <description><![CDATA[arXiv:2406.15617v1 公告类型：新
摘要：人们普遍认为，在深度学习架构中使用随机激活函数可以产生具有卓越泛化能力的模型。然而，文献中缺乏对这种启发式方法的足够严格的陈述和理论证明。在本文中，我们在这方面为文献提供了几项新颖的贡献。定义非局部方向导数的新概念，分析其理论性质（存在性和收敛性）。其次，使用概率重新表述，我们证明非局部导数是 epsilon-sub 梯度，并推导出使用非局部导数的随机梯度下降类方法收敛的样本复杂度结果。最后，利用我们对 Holder 连续函数非局部梯度的分析，我们观察到布朗运动的样本路径允许非局部方向导数，并且布朗运动的非局部导数被视为具有可计算均值和标准差的高斯过程。利用非局部方向导数理论，我们解决了图像关节流形上参数估计的高度不可微和非凸模型问题。使用布朗运动注入的 ReLU 激活函数，在反向传播期间用非局部梯度代替通常的梯度，我们还对多个经过深入研究的深度学习架构进行了实验。我们的实验表明，布朗神经激活函数在低训练数据方案中具有出色的泛化能力，其中随机神经元的使用优于确定性 ReLU 对应物。]]></description>
      <guid>https://arxiv.org/abs/2406.15617</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>具有隐藏上下文的偏好的帕累托最优学习</title>
      <link>https://arxiv.org/abs/2406.15599</link>
      <description><![CDATA[arXiv:2406.15599v1 公告类型：新
摘要：确保 AI 模型与人类价值观保持一致对于其安全性和功能性至关重要。从人类反馈中强化学习 (RLHF) 使用人类偏好来实现这种一致性。然而，来自不同人群的偏好可能会导致人类价值观的点估计可能不是最优的或对特定群体不公平。我们提出了帕累托最优偏好学习 (POPL)，它将不同的群体偏好框定为具有潜在权衡的目标，旨在制定在偏好数据集上帕累托最优的策略。POPL 利用词汇表选择，这是一个选择多样化和帕累托最优解决方案的迭代过程。我们的实证评估表明，POPL 在学习奖励函数集方面超越了基线方法，有效地迎合了没有访问组号或成员标签的不同群体。此外，我们说明 POPL 可以作为优化特定群体公平概念的技术的基础，确保包容和公平的 AI 模型一致性。]]></description>
      <guid>https://arxiv.org/abs/2406.15599</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>基于极值理论的策略梯度灾难风险感知强化学习</title>
      <link>https://arxiv.org/abs/2406.15612</link>
      <description><![CDATA[arXiv:2406.15612v1 公告类型：新
摘要：本文解决了在顺序决策过程中减轻灾难性风险（频率非常低但严重程度非常高的风险）的问题。由于累积成本（负回报）分布的远尾观测值稀缺，这个问题尤其具有挑战性。开发了一种策略梯度算法，我们称之为 POTPG。它基于从极值理论得出的尾部风险近似值。数值实验强调了我们的方法优于常见基准，依赖于经验分布。介绍了一种应用于金融风险管理的应用，更准确地说是应用于金融期权的动态对冲。]]></description>
      <guid>https://arxiv.org/abs/2406.15612</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>从错误的人类反馈中进行稳健的强化学习</title>
      <link>https://arxiv.org/abs/2406.15568</link>
      <description><![CDATA[arXiv:2406.15568v1 公告类型：新
摘要：从人类反馈中进行强化学习 (RLHF) 为将 AI 系统与人类偏好数据对齐提供了一个原则框架。由于各种原因，例如个人偏见、上下文模糊性、缺乏培训等，人类注释者可能会给出不正确或不一致的偏好标签。为了应对这一挑战，我们提出了一种强大的 RLHF 方法——$R^3M$，它将潜在损坏的偏好标签建模为稀疏异常值。因此，我们将稳健的奖励学习表述为 $\ell_1$ 正则化的最大似然估计问题。在计算上，我们开发了一种高效的交替优化算法，与标准 RLHF 方法相比，它仅产生可忽略不计的计算开销。从理论上讲，我们证明，在适当的规律性条件下，$R^3M$ 可以持续学习底层奖励并识别异常值，前提是异常值标签的数量与偏好样本大小呈亚线性关系。此外，我们注意到 $R^3M$ 用途广泛，可以扩展到各种偏好优化方法，包括直接偏好优化 (DPO)。我们在机器人控制和使用大型语言模型 (LLM) 的自然语言生成方面的实验表明，$R^3M$ 提高了奖励对偏好数据多种类型扰动的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2406.15568</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>Sketch-GNN：具有亚线性训练复杂度的可扩展图神经网络</title>
      <link>https://arxiv.org/abs/2406.15575</link>
      <description><![CDATA[arXiv:2406.15575v1 公告类型：新
摘要：图神经网络 (GNN) 广泛应用于图学习问题，例如节点分类。当将 GNN 的底层图扩展到更大的尺寸时，我们被迫要么在完整的图上进行训练，并将完整的图邻接和节点嵌入保留在内存中（这通常是不可行的），要么对图进行小批量采样（这会导致计算复杂度随 GNN 层数呈指数增长）。提出了各种基于采样和基于历史嵌入的方法来避免这种复杂性的指数增长。然而，这些解决方案都不能消除对图大小的线性依赖。本文提出了一种基于草图的算法，通过在几个紧凑的图邻接和节点嵌入草图上训练 GNN，其训练时间和内存随图大小呈亚线性增长。我们的框架基于多项式张量草图 (PTS) 理论，提供了一种新颖的协议，用于在 GNN 中绘制非线性激活和图卷积矩阵，而不是在神经网络中绘制线性权重或梯度的现有方法。此外，我们还开发了一种局部敏感哈希 (LSH) 技术，可以对其进行训练以提高草图的质量。在大型图基准测试上的实验证明了我们的 Sketch-GNN 与全尺寸 GNN 相比具有可扩展性和竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2406.15575</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应采样对大型语言模型和文本到图像模型进行数据高效评估</title>
      <link>https://arxiv.org/abs/2406.15527</link>
      <description><![CDATA[arXiv:2406.15527v1 公告类型：新
摘要：评估 LLM 和文本到图像模型是一项经常被忽视的计算密集型任务。有效的评估对于理解这些模型的多样化功能以及在越来越多的新模型和基准之间进行比较至关重要。为了解决这个问题，我们引入了 SubLIME，这是一个数据高效的评估框架，它采用自适应采样技术（例如聚类和基于质量的方法）来创建基准的代表性子集。我们的方法确保与完整数据集相比，模型排名在统计上保持一致，这可以通过高 Pearson 相关系数来证明。对六个 NLP 基准的实证分析表明：（1）基于质量的采样始终与 10% 采样率的完整数据集（例如 Quality SE 和 Quality CPD）实现强相关性（0.85 到 0.95）（2）聚类方法在特定基准（如 MMLU）中表现出色（3）没有一种方法在所有指标上普遍优于其他方法。扩展此框架后，我们利用 HEIM 排行榜覆盖 17 个不同基准上的 25 个文本转图像模型。SubLIME 会动态选择每个基准的最佳技术，从而显著降低评估成本，同时保持排名完整性和分数分布。值得注意的是，对于 MMLU 等基准，1% 的最低采样率被证明是有效的。此外，我们证明，采用基于难度的采样来定位更具挑战性的基准片段可以增强模型差异化，并实现更广泛的分数分布。我们还结合了语义搜索、工具使用和 GPT-4 审查，以识别特定 LLM 类别（例如编码基准）内基准之间的冗余。这使我们能够进一步减少保持目标排名所需的样本数量。总体而言，SubLIME 为 LLM 和文本转图像模型的稳健评估提供了一种多功能且经济高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.15527</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>Geneverse：用于基因组和蛋白质组学研究的开源多模态大型语言模型集合</title>
      <link>https://arxiv.org/abs/2406.15534</link>
      <description><![CDATA[arXiv:2406.15534v1 公告类型：新
摘要：大型语言模型 (LLM) 在生物医学和医疗保健研究中的应用前景广阔。尽管有使用各种生物医学数据训练的开源 LLM，但目前关于 LLM 在基因组学和蛋白质组学中的应用的研究仍然有限。为了填补这一空白，我们提出了一组经过微调的 LLM 和多模态 LLM (MLLM)，称为 Geneverse，用于基因组学和蛋白质组学研究中的三个新任务。Geneverse 中的模型是基于领域特定数据集进行训练和评估的，我们使用先进的参数高效微调技术来实现模型适应任务，包括生成基因功能描述、从其结构推断蛋白质功能以及从空间转录组数据中选择标记基因。我们证明，经过调整的 LLM 和 MLLM 在这些任务上表现良好，并且根据我们对真实性和结构正确性的评估，其表现可能优于闭源大型模型。我们使用的所有训练策略和基础模型均可免费访问。]]></description>
      <guid>https://arxiv.org/abs/2406.15534</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>SAIL：自我改进的大型语言模型高效在线对齐</title>
      <link>https://arxiv.org/abs/2406.15567</link>
      <description><![CDATA[arXiv:2406.15567v1 公告类型：新
摘要：从人类反馈中强化学习 (RLHF) 是将大型语言模型 (LLM) 与人类偏好对齐的关键方法。然而，当前的离线对齐方法（如 DPO、IPO 和 SLiC）严重依赖固定偏好数据集，这可能导致性能不佳。另一方面，最近的文献专注于设计在线 RLHF 方法，但仍然缺乏统一的概念公式，并且存在分布偏移问题。为了解决这个问题，我们确定在线 LLM 对齐以双层优化为基础。通过将这个公式简化为有效的单级一阶方法（使用奖励策略等价性），我们的方法生成新样本并通过探索响应和调节偏好标签来迭代改进模型对齐。通过这样做，我们允许对齐方法以在线和自我改进的方式运行，并将先前的在线 RLHF 方法概括为特殊情况。与最先进的迭代 RLHF 方法相比，我们的方法以最小的计算开销显著提高了开源数据集上的对齐性能。]]></description>
      <guid>https://arxiv.org/abs/2406.15567</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>统一无监督图级异常检测和分布外检测：基准</title>
      <link>https://arxiv.org/abs/2406.15523</link>
      <description><![CDATA[arXiv:2406.15523v1 公告类型：新
摘要：为了构建安全可靠的图形机器学习系统，无监督图形级异常检测（GLAD）和无监督图形级分布外（OOD）检测（GLOD）近年来受到了广泛关注。虽然这两条研究路线确实有相同的目标，但由于不同的评估设置，它们在社区中被独立研究，从而造成了阻碍方法应用和评估的差距。为了弥合这一差距，在这项工作中，我们提出了一个无监督图级OOD和异常检测的统一基准（我们的方法），这是一个全面的评估框架，在广义图级OOD检测的概念下统一了GLAD和GLOD。我们的基准涵盖了4个实际异常和OOD检测场景的35个数据集，有助于比较16种代表性的GLAD / GLOD方法。我们进行多维度分析，探索现有方法的有效性、通用性、稳健性和效率，揭示其优势和局限性。此外，我们还提供了我们方法的开源代码库 (https://github.com/UB-GOLD/UB-GOLD)，以促进可重复的研究，并根据我们的见解概述未来研究的潜在方向。]]></description>
      <guid>https://arxiv.org/abs/2406.15523</guid>
      <pubDate>Tue, 25 Jun 2024 06:20:14 GMT</pubDate>
    </item>
    </channel>
</rss>