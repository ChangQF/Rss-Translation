<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 10 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CrowdTransfer：实现 AIoT 社区群体知识转移</title>
      <link>https://arxiv.org/abs/2407.06485</link>
      <description><![CDATA[arXiv:2407.06485v1 公告类型：新
摘要：物联网人工智能（AIoT）是基于物联网（IoT）和人工智能（AI）技术深度融合的新兴前沿。虽然先进的深度学习技术提高了复杂物联网数据的高效数据处理和智能分析能力，但在实际部署到AIoT应用中时，它们仍然面临着显著的挑战，例如资源受限和任务要求多样化。知识转移是一种有效的方法，可以避免与数据回忆和模型再训练相关的高昂成本，从而提高学习性能。值得注意的是，虽然已经有一些关于迁移学习的有价值和令人印象深刻的调查，但这些调查以相对孤立的方式介绍了方法，缺乏各种知识转移技术在AIoT领域的最新进展。本调查致力于引入一种新的知识转移概念，称为群体知识转移（CrowdTransfer），旨在转移从一群代理中学到的先验知识，以降低训练成本，并提高模型在现实世界复杂场景中的性能。具体来说，我们从群体智能的角度提出了四种转移模式，包括衍生、共享、演化和融合模式。在传统迁移学习方法的基础上，我们从三个角度进一步研究了适用于各种 AIoT 应用的高级群体知识转移模型。此外，我们还探索了 AIoT 领域的一些应用，例如人类活动识别、城市计算、多机器人系统和智能工厂。最后，我们讨论了尚未解决的问题，并概述了 AIoT 社区知识转移的未来研究方向。]]></description>
      <guid>https://arxiv.org/abs/2407.06485</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>如果你不理解，就不要使用它：利用层间过滤器消除木马</title>
      <link>https://arxiv.org/abs/2407.06411</link>
      <description><![CDATA[arXiv:2407.06411v1 公告类型：新
摘要：大型语言模型 (LLM) 有时会表现出危险的意外行为。查找和修复这些问题具有挑战性，因为攻击面非常大——无法详尽搜索可能引发此类行为的所有可能输入。一个具体且特别具有挑战性的案例是，如果数据中毒注入了木马，因为没有办法知道它们是什么来搜索它们。据我们所知，没有普遍适用的方法来忘记在预训练期间注入的未知木马。这项工作旨在提供一种通用配方（过滤器）和一种特定实现（LoRA）过滤器，这些过滤器在实践中适用于中小型模型。重点主要是经验性的，尽管一些令人困惑的行为为 LLM 如何存储和处理信息这一基本问题打开了大门。不出所料，我们发现我们的过滤器在残差流和最新层上效果最佳。]]></description>
      <guid>https://arxiv.org/abs/2407.06411</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>语言模型的可组合干预</title>
      <link>https://arxiv.org/abs/2407.06483</link>
      <description><![CDATA[arXiv:2407.06483v1 公告类型：新
摘要：语言模型的测试时干预可以提高事实准确性，减轻有害输出，并提高模型效率，而无需昂贵的再训练。但是，尽管新方法大量涌现，但不同类型的干预措施在很大程度上是独立发展的。在实践中，必须将多种干预措施按顺序应用于同一模型，但我们缺乏研究干预措施如何相互作用的标准化方法。我们通过引入可组合干预来填补这一空白，这是一个研究在同一语言模型上使用多种干预措施的影响的框架，具有新的指标和统一的代码库。使用我们的框架，我们进行了广泛的实验，并从三个新兴的干预类别（知识编辑、模型压缩和机器学习）中组合出流行的方法。我们从 310 种不同的组合中得出的结果揭示了有意义的相互作用：压缩阻碍了编辑和学习，编写干预措施取决于它们的应用顺序，而流行的通用指标不足以评估可组合性。综合起来，我们的研究结果显示出可组合性方面存在明显差距，表明需要新的多目标干预措施。我们所有的代码都是公开的：https://github.com/hartvigsen-group/composable-interventions。]]></description>
      <guid>https://arxiv.org/abs/2407.06483</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>浅层神经网络三阶有限差分加权本质无振动格式</title>
      <link>https://arxiv.org/abs/2407.06333</link>
      <description><![CDATA[arXiv:2407.06333v1 公告类型：新
摘要：本文介绍了基于双曲守恒定律神经网络的有限差分加权本质无振荡 (WENO) 方案。我们采用监督学习并设计两个损失函数，一个是均方误差，另一个是均方对数误差，其中 WENO3-JS 权重被计算为标签。每个损失函数由两个组件组成，其中第一个组件比较神经网络权重与 WENO3-JS 权重之间的差异，而第二个组件匹配神经网络的输出权重和线性权重。损失函数的前者强制神经网络遵循 WENO 属性，这意味着不需要后处理层。此外，后者可以在不连续性方面带来更好的性能。作为神经网络结构，我们选择浅层神经网络 (SNN) 以提高计算效率，其中 Delta 层由归一化未分割差异组成。与 WENO3-JS 和 WENO3-Z 的模拟相比，这些构建的 WENO3-SNN 方案在一维示例中表现出优异的结果，在二维示例中表现出改进的行为。]]></description>
      <guid>https://arxiv.org/abs/2407.06333</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:39 GMT</pubDate>
    </item>
    <item>
      <title>具有可扩展通信高效全局更新的高维分布式稀疏分类</title>
      <link>https://arxiv.org/abs/2407.06346</link>
      <description><![CDATA[arXiv:2407.06346v1 公告类型：新
摘要：随着统计学习中使用的数据集大小不断增长，模型的分布式训练引起了越来越多的关注。这些方法对数据进行分区并利用并行性来减少内存和运行时间，但随着数据大小或迭代次数的增加，通信成本越来越高。最近对线性模型的研究表明，可以局部优化替代似然，以高效通信的方式迭代改进初始解决方案。然而，随着数据量变得庞大，这些方法的现有版本存在多个缺点，包括发散更新和有效处理稀疏性。在这项工作中，我们开发了这些问题的解决方案，使我们能够学习通信高效的分布式逻辑回归模型，甚至超过数百万个特征。在我们的实验中，我们证明了与分布式算法相比，准确度有了很大的提高，只需要几个分布式更新步骤，并且运行时间相似或更快。我们的代码可在 \url{https://github.com/FutureComputing4AI/ProxCSL} 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.06346</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:39 GMT</pubDate>
    </item>
    <item>
      <title>非稳健特征在单类分类中并不总是有用的</title>
      <link>https://arxiv.org/abs/2407.06372</link>
      <description><![CDATA[arXiv:2407.06372v1 公告类型：新
摘要：对抗性示例的存在对机器学习模型的稳健性提出了质疑。我们研究了对抗性示例在需要轻量级模型进行一类分类的实际应用中的威胁。在 Ilyas 等人 (2019) 的基础上，我们研究了轻量级一类分类器对对抗性攻击的脆弱性及其可能的原因。我们的结果表明，轻量级一类分类器在较强的攻击下会学习不稳健的特征（例如纹理）。然而，与多类分类（Ilyas 等人，2019）不同，这些非稳健特征并不总是对一类任务有用，这表明学习这些不可预测和非稳健的特征是训练的不良后果。]]></description>
      <guid>https://arxiv.org/abs/2407.06372</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:39 GMT</pubDate>
    </item>
    <item>
      <title>CONGO：压缩在线梯度优化及其在微服务管理中的应用</title>
      <link>https://arxiv.org/abs/2407.06325</link>
      <description><![CDATA[arXiv:2407.06325v1 公告类型：新
摘要：我们解决了在线凸优化的挑战，其中目标函数的梯度表现出稀疏性，表明只有少数维度具有非零梯度。我们的目标是利用这种稀疏性来获得目标函数梯度的有用估计，即使唯一可用的信息是有限数量的函数样本。我们的动机源于分布式排队系统，如基于微服务的应用程序，其特点是请求-响应工作负载。在这里，每种请求类型都会通过一系列微服务来产生响应，并且控制整个微服务集合中的资源分配以平衡端到端延迟和资源成本。虽然微服务的数量很大，但延迟函数主要对少数资源变化做出反应，导致梯度稀疏。我们提出的方法 CONGO（压缩在线梯度优化）将同时扰动与压缩感知相结合以估计梯度。我们对每次迭代所需的压缩感知样本数量建立了分析界限，以保持梯度估计的有界偏差，从而确保亚线性遗憾。通过利用稀疏性，我们减少了每次迭代所需的样本，以匹配梯度的稀疏性，而不是问题的原始维度。数值实验和现实世界的微服务基准测试证明了 CONGO 优于多种随机梯度下降方法，因为它可以快速收敛到与使用工作负载感知进行预训练的策略相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.06325</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:38 GMT</pubDate>
    </item>
    <item>
      <title>通过坐标上升和动态规划解决多模型 MDP</title>
      <link>https://arxiv.org/abs/2407.06329</link>
      <description><![CDATA[arXiv:2407.06329v1 公告类型：新
摘要：多模型马尔可夫决策过程 (MMDP) 是一种有前途的框架，用于计算对 MDP 中的参数不确定性具有鲁棒性的策略。MMDP 旨在找到一种策略，使 MDP 模型分布的预期回报最大化。由于 MMDP 是 NP 难解的，大多数方法都采用近似值。在本文中，我们推导了 MMDP 的策略梯度并提出了 CADP，它结合了坐标上升法和动态规划算法来解决 MMDP。与早期算法相比，CADP 的主要创新之处在于采用坐标上升视角迭代调整模型权重，以保证单调策略改进到局部最大值。对 CADP 的理论分析证明，它的表现永远不会比 WSU 等以前的动态规划算法差。我们的数值结果表明，CADP 在几个基准问题上的表现大大优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2407.06329</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:38 GMT</pubDate>
    </item>
    <item>
      <title>MagMax：利用模型合并实现无缝持续学习</title>
      <link>https://arxiv.org/abs/2407.06322</link>
      <description><![CDATA[arXiv:2407.06322v1 公告类型：新
摘要：本文介绍了一种名为 MagMax 的持续学习方法，该方法利用模型合并使大型预训练模型能够不断从新数据中学习而不会忘记以前获得的知识。与旨在减少任务训练期间遗忘的传统持续学习方法不同，MagMax 将顺序微调与最大量级权重选择相结合，以实现跨任务的有效知识整合。我们最初的贡献是对模型合并技术的广泛研究，揭示了权重平均和随机权重选择等简单方法在各种持续学习环境中都表现出色。更重要的是，我们提出了 MagMax，一种新颖的模型合并策略，可以持续学习大型预训练模型以完成连续任务。我们的全面评估证明了 MagMax 在各种场景中的优势，包括类和域增量学习设置。]]></description>
      <guid>https://arxiv.org/abs/2407.06322</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>B'MOJO：具有逼真记忆和衰退记忆的基础模型的混合状态空间实现</title>
      <link>https://arxiv.org/abs/2407.06324</link>
      <description><![CDATA[arXiv:2407.06324v1 公告类型：新
摘要：我们描述了一种支持传导推理的架构系列，它允许记忆增长到有限但先验未知的界限，同时有效利用有限的资源进行推理。当前的架构使用此类资源在有限跨度（Transformers 中的“上下文”）上表示数据，或在无限跨度（状态空间模型或 SSM 中）上表示数据。最近的混合架构结合了记忆记忆和衰减记忆，但存在局限性，不允许设计者或学习过程无缝调节两者，也不能延长记忆记忆跨度。我们利用随机实现理论的思想来开发一类称为 B&#39;MOJO 的模型，以在一个基本的可组合模块中无缝结合记忆记忆和衰减记忆。整体架构可用于实现能够“在上下文中”访问短期意象记忆、“在权重中”访问永久结构记忆、“在状态中”访问衰减记忆和“在存储中”访问长期意象记忆的模型，方法是原生地结合从异步更新的内存中进行检索。我们表明，Transformers、现有的 SSM（如 Mamba）和混合架构（如 Jamba）是 B&#39;MOJO 的特殊情况，并描述了一种基本实现（即将开源），可以在硬件中高效堆叠和扩展。我们在传导推理任务（如联想回忆）上测试了 B&#39;MOJO，它的表现优于现有的 SSM 和混合模型；作为基准，我们测试了普通语言建模，其中 B&#39;MOJO 实现了与类似大小的 Transformers 和 SSM 相当的困惑度，最多 1.4B 参数，同时训练速度提高了 10%。最后，我们表明，B&#39;MOJO 调节图像记忆和衰退记忆的能力可以使其在长达 32K 个标记的长序列上进行更好的推理，这是训练期间看到的最长序列长度的四倍。]]></description>
      <guid>https://arxiv.org/abs/2407.06324</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>偏微分方程的自监督预训练</title>
      <link>https://arxiv.org/abs/2407.06209</link>
      <description><![CDATA[arXiv:2407.06209v1 公告类型：新
摘要：在这项工作中，我们描述了一种利用基于变压器的神经网络架构的最新进展来构建神经 PDE 求解器的新方法。我们的模型可以为不同值的 PDE 参数提供解决方案，而无需重新训练网络。训练以自监督的方式进行，类似于语言和视觉任务中应用的预训练方法。我们假设该模型实际上是在学习一组运算符（针对多个参数），将初始条件映射到未来任何时间步 t 的 PDE 解。我们将这种方法与傅里叶神经算子 (FNO) 进行了比较，并证明它可以在 PDE 参数空间上进行推广，尽管与 FNO 相比，单个参数值的预测误差更高。我们表明，通过使用非常少量的数据对模型进行微调，可以提高特定参数的性能。我们还证明模型可以随着数据和模型大小而扩展。]]></description>
      <guid>https://arxiv.org/abs/2407.06209</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的罕见事件分类中的偏差校正</title>
      <link>https://arxiv.org/abs/2407.06212</link>
      <description><![CDATA[arXiv:2407.06212v1 公告类型：新
摘要：可以使用网络抓取的文本来识别在线平台业务。这是一个结合了自然语言处理和罕见事件检测元素的分类问题。由于在线平台很少见，因此使用机器学习算法准确识别它们具有挑战性。在这里，我们描述了一种基于机器学习的文本分类方法的开发，该方法尽可能减少误报的数量。它大大减少了使用校准概率和集合获得的估计中的偏差。]]></description>
      <guid>https://arxiv.org/abs/2407.06212</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>不同神经网络架构中的拓扑结构表征</title>
      <link>https://arxiv.org/abs/2407.06286</link>
      <description><![CDATA[arXiv:2407.06286v1 公告类型：新
摘要：未来最重要的任务之一将是了解神经网络中正在发生的事情，因为它们将变得更加强大和广泛部署。这项工作旨在使用 TDA 方法分析神经表征。我们开发了分析不同架构表示的方法，并检查如何使用它们来获得有效结果。我们的研究结果表明，去除异常值对结果没有太大影响，我们应该比较具有相同数量元素的表示。我们将这些方法应用于 ResNet、VGG19 和 ViT 架构，发现存在显着差异以及一些相似之处。此外，我们确定具有相似架构的模型往往具有相似的表示拓扑，而具有更多层的模型可以更平滑地改变其拓扑。此外，我们发现预训练和微调模型的拓扑在中间层和最终层开始有所不同，而在初始层保持非常相似。这些发现证明了 TDA 在神经网络行为分析中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.06286</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>专家混合调查</title>
      <link>https://arxiv.org/abs/2407.06204</link>
      <description><![CDATA[arXiv:2407.06204v1 公告类型：新
摘要：大型语言模型 (LLM) 在从自然语言处理到计算机视觉等各个领域都取得了前所未有的进步。LLM 的强大之处在于其巨大的模型规模、广泛而多样的数据集以及训练过程中利用的巨大计算能力，所有这些都有助于 LLM 发挥小型模型所不具备的新兴能力（例如，上下文学习）。在这种背景下，专家混合 (MoE) 已成为一种有效的方法，可以以最小的计算开销大幅扩大模型容量，引起了学术界和工业界的极大关注。尽管 MoE 越来越流行，但缺乏对 MoE 文献的系统而全面的回顾。本调查旨在弥补这一差距，为深入研究 MoE 复杂性的研究人员提供重要资源。我们首先简要介绍 MoE 层的结构，然后提出一种新的 MoE 分类法。接下来，我们将概述各种 MoE 模型的核心设计，包括算法和系统方面，以及可用的开源实现、超参数配置和实证评估的集合。此外，我们描述了 MoE 在实践中的多方面应用，并概述了未来研究的一些潜在方向。为了促进持续更新和分享 MoE 研究的前沿发展，我们建立了一个资源库，网址为 https://github.com/withinmiaov/A-Survey-on-Mixture-of-Experts。]]></description>
      <guid>https://arxiv.org/abs/2407.06204</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>XAI 增强方法对稀缺数据二元分类的影响</title>
      <link>https://arxiv.org/abs/2407.06206</link>
      <description><![CDATA[arXiv:2407.06206v1 公告类型：新
摘要：即时超声 (POCUS) 是临床医生在患者床边进行和解释超声扫描的做法。然而，解释这些图像所需的专业知识相当丰富，而且在紧急情况下可能并不总是具备这些专业知识。这一现实使得机器学习分类器等算法对于增强人类决策极其有价值。POCUS 设备正以合理的价格在手机大小的范围内普及。将 POCUS 设备变成救生工具的挑战在于，解释超声图像需要专业培训和经验。不幸的是，难以获得积极的训练图像是构建高效和准确的分类器的一个重要障碍。因此，我们试图研究的问题是如何探索提高使用稀缺数据训练的分类器准确性的策略。我们假设使用少量数据实例进行训练可能不足以使分类器泛化，从而导致它们过度拟合。我们的方法使用可解释的人工智能增强方法来帮助算法从更少的知识中学习更多知识，并可能帮助分类器更好地概括。]]></description>
      <guid>https://arxiv.org/abs/2407.06206</guid>
      <pubDate>Wed, 10 Jul 2024 06:20:35 GMT</pubDate>
    </item>
    </channel>
</rss>