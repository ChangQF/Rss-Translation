<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CaLMFlow：使用因果语言模型进行 Volterra 流匹配</title>
      <link>https://arxiv.org/abs/2410.05292</link>
      <description><![CDATA[arXiv:2410.05292v1 公告类型：新
摘要：我们引入了 CaLMFlow（流匹配的因果语言模型），这是一种新颖的框架，它将流匹配转换为 Volterra 积分方程 (VIE)，利用大型语言模型 (LLM) 的强大功能进行连续数据生成。CaLMFlow 通过将流匹配制定为序列建模任务，连接离散语言建模和连续生成建模，使 LLM 能够直接应用来学习复杂流。我们的方法实现了跨空间和时间的标记化，从而解决了这些域上的 VIE。这种方法能够有效处理高维数据，并且优于依赖 ODE 求解器的方法，如条件流匹配 (CFM)。我们展示了 CaLMFlow 对合成和现实世界数据的有效性，包括单细胞扰动响应预测，展示了其结合文本上下文并推广到看不见的条件的能力。我们的研究结果强调了 LLM 驱动的流匹配作为生成建模中一个很有前途的范例，它提供了改进的可扩展性、灵活性和情境感知能力。]]></description>
      <guid>https://arxiv.org/abs/2410.05292</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型如何理解图形模式？图形模式理解的基准</title>
      <link>https://arxiv.org/abs/2410.05298</link>
      <description><![CDATA[arXiv:2410.05298v1 公告类型：新
摘要：对大型语言模型 (LLM) 在图相关任务中的能力和局限性进行基准测试正成为一个越来越受欢迎和至关重要的研究领域。最近的研究表明，LLM 表现出初步理解图结构和节点特征的能力。然而，LLM 在图模式挖掘中的潜力仍未得到充分开发。这是计算化学、生物学和社交网络分析等领域的关键组成部分。为了弥补这一差距，这项工作引入了一个全面的基准来评估 LLM 在图形模式任务中的能力。我们开发了一个基准，可以评估 LLM 是否可以根据术语或拓扑描述理解图形模式。此外，我们的基准测试了 LLM 从数据中自主发现图形模式的能力。基准测试涵盖合成和真实数据集以及各种模型，共有 11 个任务和 7 个模型。我们的实验框架旨在轻松扩展以适应新模型和数据集。我们的研究结果表明：（1）LLM 具有理解图形模式的初步能力，其中 O1-mini 在大多数任务中表现出色；（2）格式化输入数据以与预训练期间获得的知识保持一致可以提高性能；（3）LLM 采用的策略可能与传统算法中使用的策略不同。]]></description>
      <guid>https://arxiv.org/abs/2410.05298</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于VMD和IPSO-ELM的短期负荷预测模型研究</title>
      <link>https://arxiv.org/abs/2410.05300</link>
      <description><![CDATA[arXiv:2410.05300v1 公告类型：新 
摘要：为提高风电场电力负荷预测的准确性，本研究引入了一种先进的组合预测方法，该方法将变分模态分解 (VMD) 与改进的粒子群优化 (IPSO) 算法相结合以优化极限学习机 (ELM)。首先，采用 VMD 算法对原始电力负荷数据进行高精度模态分解，然后基于互信息熵理论将其分为高频和低频序列。随后，本研究通过结合 Tent 混沌映射、指数行进距离速率和精英反向学习机制对传统的多元宇宙优化器进行了深刻的修改，开发了 IPSO-ELM 预测模型。该模型独立预测高频和低频序列并重构数据以获得最终的预测结果。仿真结果表明，与传统ELM、PSO-ELM、PSO-ELM方法相比，所提方法显著提高了预测精度和收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2410.05300</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ConceptLens：从像素到理解</title>
      <link>https://arxiv.org/abs/2410.05311</link>
      <description><![CDATA[arXiv:2410.05311v1 公告类型：新
摘要：ConceptLens 是一种创新工具，旨在通过可视化隐藏的神经元激活来阐明深度神经网络 (DNN) 的复杂工作原理。通过将深度学习与符号方法相结合，ConceptLens 为用户提供了一种独特的方式来了解触发神经元激活的原因以及它们如何响应各种刺激。该工具使用误差幅度分析来深入了解神经元激活的置信度，从而增强 DNN 的可解释性。本文概述了 ConceptLens、其实现及其通过条形图实时可视化神经元激活和误差幅度的应用。]]></description>
      <guid>https://arxiv.org/abs/2410.05311</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PalmBench：移动平台上压缩大型语言模型的综合基准测试</title>
      <link>https://arxiv.org/abs/2410.05315</link>
      <description><![CDATA[arXiv:2410.05315v1 公告类型：新
摘要：在移动设备上本地部署大型语言模型 (LLM) 在由于隐私问题而无法将数据传输到远程云服务器或由于网络连接而不切实际的情况下具有优势。最近的进展 (MLC, 2023a; Gerganov, 2023) 促进了 LLM 的本地部署。然而，本地部署也带来了挑战，特别是在移动设备的硬件约束内平衡质量 (生成性能)、延迟和吞吐量。在本文中，我们介绍了我们的轻量级、一体化自动基准测试框架，允许用户在移动设备上评估 LLM。我们为具有不同量化配置 (权重和激活) 的各种流行 LLM 提供了全面的基准测试，这些 LLM 跨越具有不同硬件功能的多个移动平台。与评估高端 GPU 集群上的全尺寸模型的传统基准测试不同，我们专注于评估移动设备上压缩模型的资源效率 (内存和功耗) 和有害输出。我们的主要观察结果包括 i) 不同移动平台的能源效率和吞吐量的差异；ii) 量化对内存使用情况、GPU 执行时间和功耗的影响；iii) 与未量化模型相比，量化模型的准确性和性能下降；iv) 移动设备上压缩的 LLM 产生的幻觉和有毒内容的频率。]]></description>
      <guid>https://arxiv.org/abs/2410.05315</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于标记的特征缓存来加速扩散变压器</title>
      <link>https://arxiv.org/abs/2410.05317</link>
      <description><![CDATA[arXiv:2410.05317v1 公告类型：新
摘要：扩散变换器在图像和视频合成中都表现出显著的有效性，但计算成本巨大。为了解决这个问题，引入了特征缓存方法来加速扩散变换器，方法是缓存前一个时间步中的特征并在接下来的时间步中重用它们。然而，以前的缓存方法忽略了不同的 token 对特征缓存表现出不同的敏感度，并且与其他 token 相比，某些 token 上的特征缓存可能会导致整体生成质量降低 10$\times$ 倍。在本文中，我们引入了 token 级特征缓存，使我们能够自适应地选择最合适的 token 进行缓存，并进一步使我们能够将不同的缓存率应用于不同类型和深度的神经层。在 PixArt-$\alpha$、OpenSora 和 DiT 上进行的大量实验证明了我们在图像和视频生成中的有效性，并且不需要训练。例如，在 OpenSora 和 PixArt-$\alpha$ 上实现了 2.36$\times$ 和 1.93$\times$ 的加速，而生成质量几乎没有下降。]]></description>
      <guid>https://arxiv.org/abs/2410.05317</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过协作验证扩展推理计算来改进 LLM 推理</title>
      <link>https://arxiv.org/abs/2410.05318</link>
      <description><![CDATA[arXiv:2410.05318v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 的一般能力取得了重大进步，但它们仍然难以进行一致和准确的推理，尤其是在数学和代码推理等复杂任务中。一个关键的限制是 LLM 主要在正确的解决方案上进行训练，这降低了它们检测和从错误中学习的能力，从而妨碍了它们可靠地验证和排序输出的能力。为了解决这个问题，我们通过生成多个推理路径并使用验证器来评估和按正确性对生成的输出进行排序来扩大推理时间计算。为了促进这一点，我们引入了一个全面的数据集，该数据集由多个 LLM 生成的数学和代码任务的正确和不正确的解决方案组成。这组多样化的解决方案使验证者能够更有效地区分和排序正确答案和错误输出。构建验证器的训练方法是根据对现有方法的广泛比较而选择的。此外，为了充分利用不同推理策略的独特优势，我们提出了一种新颖的协作方法，将思维链 (CoT) 和思维程序 (PoT) 解决方案集成在一起进行验证。CoT 提供了一个清晰的、循序渐进的推理过程，增强了可解释性，而 PoT 是可执行的，提供了一种精确且对错误敏感的验证机制。通过结合两者的优势，我们的方法显著提高了推理验证的准确性和可靠性。我们的验证器 Math-Rev 和 Code-Rev 比现有的 LLM 具有显着的性能提升，在 GSM8k 和 MATH 等基准测试中取得了最先进的结果，甚至超过了使用 Qwen-72B-Instruct 作为推理器的 GPT-4o。]]></description>
      <guid>https://arxiv.org/abs/2410.05318</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从不完全粗粒度到完全细粒度：时空数据重建的两阶段框架</title>
      <link>https://arxiv.org/abs/2410.05323</link>
      <description><![CDATA[arXiv:2410.05323v1 公告类型：新
摘要：随着各种传感设备的快速发展，时空数据如今变得越来越重要。然而，由于传感成本和隐私问题，收集的数据通常不完整且粒度粗，限制了其在特定任务中的应用。为了解决这个问题，我们提出了一项名为时空数据重建的新任务，旨在从稀疏和粗粒度的观测中推断出完整且细粒度的数据。为了实现这一点，我们引入了一个两阶段数据推理框架 DiffRecon，它基于去噪扩散概率模型 (DDPM)。在第一阶段，我们提出了 Diffusion-C，这是一个由 ST-PointFormer 增强的扩散模型，ST-PointFormer 是一个强大的编码器，旨在利用稀疏数据点之间的空间相关性。接下来，第二阶段引入了 Diffusion-F，它结合了所提出的 T-PatternNet 来捕获序列数据中的时间模式。这两个阶段共同构成了一个端到端框架，能够从不完整和粗粒度的观察中推断出完整、细粒度的数据。我们在多个真实数据集上进行了实验，以证明我们方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2410.05323</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>早期循环内部阻抗可实现跨制造商的基于机器学习的电池循环寿命预测</title>
      <link>https://arxiv.org/abs/2410.05326</link>
      <description><![CDATA[arXiv:2410.05326v1 公告类型：新
摘要：由于电极材料、制造工艺、电池格式以及缺乏普遍可用的数据，预测不同制造商的锂离子电池的寿命终止 (EOL) 面临重大挑战。仅根据电压容量曲线数据构建特征的方法通常无法在电池化学中推广。本研究介绍了一种将传统电压容量特征与直流内阻 (DCIR) 测量相结合的方法，从而实现更准确和更通用的 EOL 预测。使用早期循环 DCIR 数据可以捕获与内阻增长相关的关键退化机制，从而增强模型的稳健性。结果表明，模型可以成功预测不同电极成分的未知制造商的 EOL 循环次数，平均绝对误差 (MAE) 为 150 次循环。这种跨制造商的通用性减少了大量新数据收集和再训练的需要，使制造商能够使用现有数据集优化新电池设计。此外，我们还发布了一种新型 DCIR 兼容数据集，作为丰富不断增长的循环数据生态系统和加速电池材料开发的持续努力的一部分。]]></description>
      <guid>https://arxiv.org/abs/2410.05326</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过关系偏好进行奖励学习</title>
      <link>https://arxiv.org/abs/2410.05328</link>
      <description><![CDATA[arXiv:2410.05328v1 公告类型：新
摘要：奖励学习在人类反馈强化学习 (RLHF) 中起着关键作用，确保语言模型的一致性。Bradley-Terry (BT) 模型是从包含选择和拒绝的响应对的数据集中捕获人类偏好的普遍选择。在偏好建模中，重点不是绝对值，而是选择和拒绝的响应之间的奖励差异，称为偏好强度。因此，在偏好建模中，偏好强度的精确评估至关重要。然而，一个容易被忽视的显著影响偏好强度测量的因素是，人类对两种反应的态度可能不仅仅表明对其中一种反应的偏好，而且平局也是常见的情况。为了解决这个问题，我们建议采用广义的 Bradley-Terry 模型——具有平局的 Bradley-Terry 模型 (BTT)——来适应平局偏好，从而利用额外的信息。我们证明，即使可以访问提示和响应的真实分布，忽略关系也会导致偏好强度测量出现明显偏差。综合实验进一步验证了在偏好建模中加入关系的优势。值得注意的是，在由最先进的开源 LLM 标记的带有关系的合成偏好数据集上，使用 BTT 进行微调的效果明显优于使用 BT 进行微调。]]></description>
      <guid>https://arxiv.org/abs/2410.05328</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VPI-Mlogs：一种用于岩石物理学应用的基于网络的机器学习解决方案</title>
      <link>https://arxiv.org/abs/2410.05332</link>
      <description><![CDATA[arXiv:2410.05332v1 公告类型：新
摘要：机器学习是数据科学领域的重要组成部分。在岩石物理学中，机器学习算法和应用已被广泛采用。在此背景下，越南石油研究所 (VPI) 研究并部署了几种有效的预测模型，即缺失日志预测、裂缝带和裂缝密度预测等。作为我们的解决方案之一，VPI-MLogs 是一个基于 Web 的部署平台，集成了数据预处理、探索性数据分析、可视化和模型执行。使用最流行的数据分析编程语言 Python，这种方法为用户提供了处理岩石物理日志部分的强大工具。该解决方案有助于缩小常识与岩石物理见解之间的差距。本文将重点介绍集成多种解决方案以掌握岩石物理数据的基于 Web 的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2410.05332</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>移动边缘和云端的分布式推理：基于早期退出的聚类方法</title>
      <link>https://arxiv.org/abs/2410.05338</link>
      <description><![CDATA[arXiv:2410.05338v1 公告类型：新
摘要：深度神经网络 (DNN) 的最新进展已在各个领域表现出色。然而，它们的庞大规模对于在资源受限的设备（如移动、边缘和物联网平台）上部署是一个挑战。为了克服这个问题，可以使用分布式推理设置，其中可以在移动设备上部署小型 DNN（初始几层），在边缘上部署更大的版本，在云端部署成熟的版本。然后可以在移动设备上推断复杂度低（简单）的样本，在边缘上推断复杂度中等（中等）的样本，在云端推断复杂度较高（困难）的样本。由于每个样本的复杂性都是未知的，因此在分布式推理中出现了以下问题：如何确定复杂性，以便由足够多的 DNN 层来处理它。我们开发了一种名为 DIMEE 的新方法，该方法利用了为最大限度地减少 DNN 中的推理延迟而开发的早期退出 (EE) 策略。 DIMEE 旨在提高准确率，同时考虑到从移动设备到边缘/云的卸载成本。在涵盖各种 NLP 任务的 GLUE 数据集上进行的实验验证表明，与所有推理都在云端进行的情况相比，我们的方法显著降低了推理成本 (&gt; 43%)，同时保持了准确率的最小下降 (&lt; 0.3%)。]]></description>
      <guid>https://arxiv.org/abs/2410.05338</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉语言模型生成 3D 设计的 CAD 代码</title>
      <link>https://arxiv.org/abs/2410.05340</link>
      <description><![CDATA[arXiv:2410.05340v1 公告类型：新
摘要：生成式人工智能通过提供高效且自动化的方法来生成和修改 3D 对象，改变了设计和制造领域。一种方法是使用大型语言模型 (LLM) 生成计算机辅助设计 (CAD) 脚本代码，然后可以执行该代码来渲染 3D 对象；但是，生成的 3D 对象可能不符合指定的要求。由于 3D 对象的复杂性和结构（例如形状、表面和尺寸）在代码中不可行，因此测试 CAD 生成的代码的正确性具有挑战性。在本文中，我们介绍了 CADCodeVerify，这是一种新颖的方法，可以迭代验证和改进从 CAD 代码生成的 3D 对象。我们的方法通过提示视觉语言模型 (VLM) 生成并回答一组验证问题来验证生成的对象并提示 VLM 纠正偏差，从而产生改善反馈。为了评估 CADCodeVerify，我们引入了 CADPrompt，这是 CAD 代码生成的第一个基准，它由 200 个自然语言提示与专家注释的 3D 对象脚本代码配对，以对进度进行基准测试。我们的研究结果表明，CADCodeVerify 通过提供视觉反馈、增强 3D 对象的结构以及提高编译程序的成功率来提高 VLM 性能。当应用于 GPT-4 时，与之前的工作相比，CADCodeVerify 将点云距离减少了 7.30%，成功率提高了 5.0%]]></description>
      <guid>https://arxiv.org/abs/2410.05340</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过训练的模型告诉我们如何在没有组注释的情况下使它们对虚假相关性具有鲁棒性</title>
      <link>https://arxiv.org/abs/2410.05345</link>
      <description><![CDATA[arXiv:2410.05345v1 公告类型：新
摘要：使用经验风险最小化 (ERM) 训练的分类器倾向于依赖与目标具有高度虚假相关性的属性。这可能会降低缺乏这些属性的代表性不足（或“少数”）群体的表现，对分布外泛化和公平性目标都构成重大挑战。许多研究旨在增强对虚假相关的鲁棒性，但它们有时依赖于组注释进行训练。此外，先前研究中的一个常见限制是依赖组注释的验证数据集进行模型选择。这限制了它们在虚假相关性的性质未知或某些虚假属性的组标签不可用的情况下的适用性。为了通过最少的组注释假设增强模型鲁棒性，我们提出了基于环境的验证和基于损失的抽样 (EVaLS)。它使用 ERM 训练模型的损失来构建一个由高损失和低损失样本组成的平衡数据集，从而缓解数据中的组不平衡。当配备简单的训练后最后一层再训练时，这可以显著增强对组偏移的稳健性。通过使用环境推理方法创建具有相关性偏移的多样化环境，EVaLS 可以潜在地消除验证数据中对组注释的需要。在这种情况下，最差环境准确度在整个再训练过程中充当可靠的替代品，用于调整超参数并找到在不同组偏移中表现良好的模型。EVaLS 有效地实现了组稳健性，表明即使对于验证也不需要组注释。这是一种快速、直接且有效的方法，无需组注释即可达到接近最佳的最差组准确度，标志着训练模型对抗虚假相关性的稳健性的新篇章。]]></description>
      <guid>https://arxiv.org/abs/2410.05345</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AnyAttack：面向视觉语言模型的大规模自监督目标对抗样本生成</title>
      <link>https://arxiv.org/abs/2410.05346</link>
      <description><![CDATA[arXiv:2410.05346v1 公告类型：新
摘要：由于其多模态能力，视觉语言模型 (VLM) 在现实世界场景中发现了许多有影响力的应用。然而，最近的研究表明，VLM 容易受到基于图像的对抗性攻击，特别是针对性对抗性图像，这些图像会操纵模型以生成对手指定的有害内容。当前的攻击方法依赖于预定义的目标标签来创建针对性对抗性攻击，这限制了它们的可扩展性和大规模鲁棒性评估的适用性。在本文中，我们提出了 AnyAttack，这是一个自监督框架，可在没有标签监督的情况下为 VLM 生成针对性对抗性图像，允许任何图像作为攻击的目标。为了解决现有需要标签监督的方法的局限性，我们引入了对比损失，在大型未标记图像数据集 LAION-400M 数据集上训练生成器，以生成针对性对抗性噪声。这种大规模预训练使我们的方法在各种 VLM 中具有强大的可迁移性。在三个多模态任务（图像文本检索、多模态分类和图像字幕）中对五种主流开源 VLM（CLIP、BLIP、BLIP2、InstructBLIP 和 MiniGPT-4）进行的大量实验证明了我们攻击的有效性。此外，我们成功地将 AnyAttack 转移到多个商业 VLM，包括 Google 的 Gemini、Claude 的 Sonnet 和 Microsoft 的 Copilot。这些结果揭示了 VLM 面临的前所未有的风险，凸显了采取有效对策的必要性。]]></description>
      <guid>https://arxiv.org/abs/2410.05346</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>