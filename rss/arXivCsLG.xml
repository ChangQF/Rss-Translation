<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 20 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>EVAL：基于特征向量的平均奖励学习</title>
      <link>https://arxiv.org/abs/2501.09770</link>
      <description><![CDATA[arXiv:2501.09770v1 公告类型：新
摘要：在强化学习中，文献中广泛开发了两个目标函数：折扣奖励和平均奖励。对熵正则化设置的推广提高了这两个目标的鲁棒性和探索性。最近，使用表格设置中的大偏差理论工具解决了熵正则化的平均奖励问题。该方法具有线性优势，可通过单个矩阵的属性访问最佳策略和平均奖励率。在本文中，我们通过开发基于神经网络函数逼近的方法将该框架扩展到更一般的设置。这种公式揭示了强化学习中使用的不同目标之间关系的新理论见解。此外，我们将我们的算法与后验策略迭代方案相结合，展示了我们的方法如何在没有熵正则化的情况下解决平均奖励强化学习问题。使用经典的控制基准，我们通过实验发现我们的方法在稳定性和收敛速度方面与其他算法相比具有优势。]]></description>
      <guid>https://arxiv.org/abs/2501.09770</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多头自关注神经 Tucker 分解</title>
      <link>https://arxiv.org/abs/2501.09776</link>
      <description><![CDATA[arXiv:2501.09776v1 公告类型：新
摘要：服务质量 (QoS) 数据表现出动态时间模式，这对于准确预测缺失值至关重要。这些模式源于用户和服务之间不断发展的交互，因此捕捉此类数据中固有的时间动态对于提高预测性能至关重要。随着 QoS 数据集的大小和复杂性的增加，现有模型难以提供准确的预测，这凸显了对更灵活和动态的方法来更好地捕获大规模 QoS 数据中的潜在模式的需求。为了解决这个问题，我们引入了一种基于神经网络的张量分解方法，专门用于学习高维和不完整 (HDI) 张量的时空表示，即多头自关注神经 Tucker 分解 (MSNTucF)。该模型经过精心设计，用于以双重思想对隐藏在现实世界数据中的复杂非线性时空特征交互模式进行建模。它首先采用神经网络结构来概括传统的 Tucker 分解框架，然后提出利用多头自关注模块来执行非线性潜在交互学习。在对来自实际应用的两个动态 QoS 数据集进行实证研究中，所提出的 MSNTucF 模型在估计缺失观测值方面表现出比最先进的基准模型更优的性能。这凸显了它学习 HDI 张量的非线性时空表示的能力。]]></description>
      <guid>https://arxiv.org/abs/2501.09776</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率风险下的旅行距离估计和路线推荐的图神经网络</title>
      <link>https://arxiv.org/abs/2501.09803</link>
      <description><![CDATA[arXiv:2501.09803v1 公告类型：新
摘要：估算城市或地区不同地点之间的最短旅行时间并提供路线推荐可以定量衡量极端事件期间或之后的交通网络状况。一种常见的方法是使用 Dijkstra 算法，该算法可以产生最短路径和最短距离。但是，当应用于大规模网络时，此选项的计算成本很高。本文提出了一种基于图神经网络 (GNN) 的新型快速框架，该框架近似位置对之间的单源最短距离，并随后预测单源最短路径。我们对不同大小的合成图进行了多次实验，以证明所提模型的可行性和计算效率。在现实世界的案例研究中，我们还应用了所提出的沿海城市地区洪水风险分析方法来计算飓风期间疏散到公共避难所的延迟。结果表明 GNN 模型的准确性和计算效率，以及其在应急规划和管理中有效实施的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.09803</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强较小模型的思维链推理的泛化能力</title>
      <link>https://arxiv.org/abs/2501.09804</link>
      <description><![CDATA[arXiv:2501.09804v1 公告类型：新 
摘要：较小语言模型中的思维链 (CoT) 推理是一个具有挑战性的自然语言处理问题，但在许多实际应用中非常受欢迎。现有的 CoT 知识蒸馏方法在较小的 LLM 中经常受到过于保守的记忆的影响，导致泛化信心低。由于无法完全保留教师模型的 CoT 能力，我们假设对抗性 CoT 微调对于开发具有强大 CoT 泛化的较小 LLM 至关重要。为此，我们提出了 \textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA)，这是一个集成不同 CoT 领域的原则性微调框架。具体而言，PRADA 在较小的 LLM 中率先进行了两项 CoT 改进：(1) 通过领域对抗性微调恢复通常在蒸馏过程中丢失的领域不变特征洞察； (2) 通过采用领域对抗方法增强 CoT 提示工程的领域适应性。我们从理论上证明了我们的方法的有效性，并通过经验表明它在各种任务中的表现都远远优于最先进的方法。此外，我们的实证研究结果表明，较小的 LLM 在利用 PRADA 时与领域知识紧密结合，从而提高了我们方法的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2501.09804</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BN-Pool：一种贝叶斯非参数图池化方法</title>
      <link>https://arxiv.org/abs/2501.09821</link>
      <description><![CDATA[arXiv:2501.09821v1 公告类型：新
摘要：我们引入了 BN-Pool，这是第一个基于聚类的图神经网络 (GNN) 池化方法，它可以自适应地确定粗化图中的超节点数量。通过利用贝叶斯非参数框架，BN-Pool 采用了一种生成模型，能够将图节点划分为无限数量的簇。在训练过程中，我们通过将下游任务的监督损失与无监督辅助项相结合来学习节点到簇的分配，这鼓励重建原始图拓扑，同时惩罚不必要的簇扩散。这种自适应策略允许 BN-Pool 自动发现最佳粗化级别，提供增强的灵活性，并且无需指定敏感的池化比率。我们表明 BN-Pool 在各种基准测试中都实现了卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.09821</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>pFedWN：具有异构数据的 D2D 无线网络的个性化联合学习框架</title>
      <link>https://arxiv.org/abs/2501.09822</link>
      <description><![CDATA[arXiv:2501.09822v1 公告类型：新
摘要：传统的联邦学习 (FL) 方法通常会遇到客户端间数据异质性问题，导致单个客户端的模型性能不佳。为了解决这个问题，个性化联邦学习 (PFL) 应运而生，以解决客户端间非独立同分布 (non-IID) 和不平衡数据带来的挑战。此外，在大多数现有的分散式机器学习工作中，都考虑了客户端和服务器之间模型参数传输的完美通信通道。然而，通过无线链路的分散式 PFL 带来了新的挑战，例如资源分配和干扰管理。为了克服这些挑战，我们制定了一个联合优化问题，将底层的设备到设备 (D2D) 无线信道条件纳入无服务器的 PFL 方法中。所提出的方法称为 pFedWN，可优化每个客户端的学习性能，同时考虑 D2D 无线信道的变化。为了解决公式化的问题，我们将其分为两个子问题：PFL 邻居选择和 PFL 权重分配。PFL 邻居选择是通过在未经许可的频谱带（例如 ISM 频段）内进行信道感知邻居选择来解决的。接下来，为了分配 PFL 权重，我们利用期望最大化 (EM) 方法来评估客户端数据之间的相似性，并在所选的 PFL 邻居之间获得最佳权重分布。实证结果表明，pFedWN 可在非 IID 和不平衡数据集中提供高效且个性化的学习性能。此外，它在学习效率和稳健性方面优于现有的 FL 和 PFL 方法，尤其是在动态和不可预测的无线信道条件下。]]></description>
      <guid>https://arxiv.org/abs/2501.09822</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>编码深度学习：框架与算法</title>
      <link>https://arxiv.org/abs/2501.09849</link>
      <description><![CDATA[arXiv:2501.09849v1 公告类型：新 
摘要：深度学习 (DL) 的成功通常是通过大型模型和训练和训练后推理过程中的高复杂性实现的，这阻碍了资源有限环境中的训练。为了缓解这些问题，本文介绍了一种称为“编码深度学习”（CDL）的新框架，它将信息论编码概念集成到 DL 的内部工作中，以显着压缩模型权重和激活，降低训练和训练后推理阶段的计算复杂度，并实现高效的模型/数据并行。具体而言，在 CDL 中，（i）我们首先提出了一种用于量化模型权重和激活的新型概率方法，以及它的软可微变体，它为训练期间的梯度计算提供了分析公式；（ii）训练期间的前向和后向传递都是在量化的权重和激活上执行的，从而消除了大多数浮点运算并降低了训练复杂度； (iii) 在训练期间，权重和激活都受到熵约束，因此它们在整个训练过程中在信息论意义上都是可压缩的，从而降低了模型/数据并行中的通信成本；(iv) CDL 中训练的模型默认采用量化格式，具有可压缩的量化权重，从而减少了训练后的推理和存储复杂性。此外，还提出了 CDL 的一种变体，即宽松 CDL (R-CDL)，以进一步改善验证准确率和压缩之间的权衡，尽管在训练中要求完全精确，但 CDL 的其他优势特性保持不变。大量的实证结果表明，CDL 和 R-CDL 优于文献中 DNN 压缩方面最先进的算法。]]></description>
      <guid>https://arxiv.org/abs/2501.09849</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习有边距的嘈杂半空间：Massart 并不比随机更难</title>
      <link>https://arxiv.org/abs/2501.09851</link>
      <description><![CDATA[arXiv:2501.09851v1 公告类型：新
摘要：我们研究了具有 Massart 噪声的 PAC 学习 $\gamma$-margin 半空间的问题。我们提出了一种简单的适当学习算法 Perspectron，其样本复杂度为 $\widetilde{O}((\epsilon\gamma)^{-2})$，分类错误率最多为 $\eta+\epsilon$，其中 $\eta$ 是 Massart 噪声率。先前的研究 [DGT19,CKMY20] 的样本复杂度保证更差（在 $\epsilon$ 和 $\gamma$ 中）或只能处理随机分类噪声 [DDK+23,KIT+23]——一个更温和的噪声假设。我们还表明，我们的结果可以扩展到更具挑战性的设置，即在 Massart 噪声下学习具有已知链接函数的广义线性模型，实现与半空间情况类似的样本复杂度。由于 [CKMY20] 引入了此模型，这显著提高了该环境下的先前最佳技术水平。]]></description>
      <guid>https://arxiv.org/abs/2501.09851</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从可解释性到可解释性：通过模型解释实现强化学习中的可解释策略</title>
      <link>https://arxiv.org/abs/2501.09858</link>
      <description><![CDATA[arXiv:2501.09858v1 公告类型：新
摘要：深度强化学习 (RL) 在复杂领域取得了显著的成功，然而，深度神经网络策略固有的黑箱性质对理解和信任决策过程提出了重大挑战。虽然现有的可解释 RL 方法提供了局部见解，但它们无法提供对模型的全局理解，特别是在高风险应用中。为了克服这一限制，我们提出了一种新颖的模型无关方法，通过利用 Shapley 值将复杂的深度 RL 策略转换为透明表示，弥合了可解释性和可解释性之间的差距。所提出的方法提供了两个关键贡献：一种使用 Shapley 值进行超越局部解释的策略解释的新方法，以及适用于离策略和在策略算法的通用框架。我们用三种现有的深度 RL 算法评估我们的方法，并在两个经典控制环境中验证其性能。结果表明，我们的方法不仅保留了原始模型的性能，而且还生成了更稳定的可解释策略。]]></description>
      <guid>https://arxiv.org/abs/2501.09858</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士指导的社交技能培训辅导系统</title>
      <link>https://arxiv.org/abs/2501.09870</link>
      <description><![CDATA[arXiv:2501.09870v1 公告类型：新
摘要：社交技能培训针对成功进行社交互动所必需的行为。然而，传统的课堂培训往往不足以教授有效的沟通——现实场景中的一对一互动比讲座式的信息传递更受欢迎。本文介绍了一个框架，允许教师与大型语言模型合作，动态设计学生交流的现实场景。我们的框架使用这些场景来让学生排练，提供即时反馈，并为学生和教师可视化表现。与传统的智能辅导系统不同，教师可以轻松地与大型语言模型共同创建场景，而无需技术技能。此外，当现有选项不适合学生的反应时，系统会实时生成新的场景分支。]]></description>
      <guid>https://arxiv.org/abs/2501.09870</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于知识追踪的稀疏二进制表示学习</title>
      <link>https://arxiv.org/abs/2501.09893</link>
      <description><![CDATA[arXiv:2501.09893v1 公告类型：新
摘要：知识追踪 (KT) 模型旨在根据学生的历史互动预测他们未来的表现。大多数现有的 KT 模型完全依赖于与练习相关的人类定义的知识概念 (KC)。因此，这些模型的有效性高度依赖于预定义 KC 的质量和完整性。标记中的人为错误以及覆盖所有潜在底层 KC 的成本可能会限制模型性能。
在本文中，我们提出了一个 KT 模型，即稀疏二进制表示 KT (SBRKT)，它生成新的 KC 标签，称为辅助 KC，它可以增强预定义的 KC，以解决仅依赖人类定义的 KC 的局限性。这些都是通过二进制向量表示来学习的，其中每个位表示辅助 KC 的存在（一）或不存在（零）。由此产生的离散表示允许这些辅助 KC 用于训练任何包含 KC 的 KT 模型。与预训练的密集嵌入（仅限于接受此类向量的模型）不同，我们的离散表示既兼容经典模型（例如贝叶斯知识追踪 (BKT)），也兼容现代深度学习方法。
为了生成这种离散表示，SBRKT 采用二值化方法，该方法学习稀疏表示，可通过随机梯度下降完全训练。此外，SBRKT 结合了循环神经网络 (RNN)，通过有效结合辅助和预定义 KC 来捕捉时间动态并预测未来学生的反应。实验结果表明，SBRKT 在多个数据集上的表现优于测试基线，并在其他数据集上实现了有竞争力的性能。此外，结合学习到的辅助 KC 可以持续提高 BKT 在所有测试数据集上的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.09893</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图神经网络的三维导体组合场积分方程快速求解器研究</title>
      <link>https://arxiv.org/abs/2501.09923</link>
      <description><![CDATA[arXiv:2501.09923v1 公告类型：新
摘要：本文提出了一种基于图神经网络 (GNN) 的快速求解器 (GraphSolver)，用于求解 3D 导体的组合场积分方程 (CFIE)。采用 Rao-Wilton-Glisson (RWG) 基函数离散准确地表示 3D 导体的几何形状。然后通过将每个 RWG 函数视为图中的节点来构建简洁且信息丰富的图形表示，从而实现节点之间的电流流动。利用转换后的图形，开发了 GraphSolver，以直接预测每个节点 (RWG 函数) 处表面电流密度 x、y 和 z 分量的实部和虚部。数值结果证明了 GraphSolver 在求解具有不同几何复杂程度的 3D 导体的 CFIE 方面的有效性，包括基本 3D 目标、导弹形目标和飞机形目标。]]></description>
      <guid>https://arxiv.org/abs/2501.09923</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用特征引导激活附加功能来控制大型语言模型</title>
      <link>https://arxiv.org/abs/2501.09929</link>
      <description><![CDATA[arXiv:2501.09929v1 公告类型：新
摘要：对大型语言模型 (LLM) 行为进行有效且可靠的控制是一项重大挑战。虽然激活转向方法（将转向向量添加到模型的隐藏状态）是一种很有前途的方法，但现有技术在影响模型输出的方式上往往缺乏精确性和可解释性。我们引入了特征引导激活添加 (FGAA)，这是一种新颖的激活转向方法，它利用了对比激活添加 (CAA) 和稀疏自动编码器目标转向 (SAE-TS) 的见解。通过在稀疏自动编码器 (SAE) 的潜在空间中操作并采用优化技术来选择所需的 SAE 特征，FGAA 构建了精确的转向向量，可提供更好的转向效果，同时保持转向模型输出的一致性。在这方面，对 Gemma-2-2B 和 Gemma-2-9B 模型在各种转向任务中的评估表明，FGAA 优于现有的 CAA、SAE 解码器转向和 SAE-TS 转向方法。我们的结果还强调了转向规模和一般模型能力之间的重要权衡，这些权衡在所有测试的转向方法中都是一致的。]]></description>
      <guid>https://arxiv.org/abs/2501.09929</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HEART：实现车边云一体化分层联邦学习的及时多模型训练</title>
      <link>https://arxiv.org/abs/2501.09934</link>
      <description><![CDATA[arXiv:2501.09934v1 公告类型：新 
摘要：支持 AI 的车联网 (IoV) 的快速发展需要高效的机器学习 (ML) 解决方案来处理高车辆移动性和分散数据。这促使了基于车辆边缘云架构的分层联邦学习 (VEC-HFL) 的出现。然而，在 VEC-HFL 文献中尚未充分探索的一个方面是，车辆通常需要同时执行多个 ML 任务，这种多模型训练环境带来了关键挑战。首先，不正确的聚合规则可能导致模型过时和训练时间延长。其次，车辆移动性可能会阻止车辆将其模型返回网络边缘，从而导致数据利用率低下。第三，实现不同任务之间的平衡资源分配变得至关重要，因为它主要影响协作训练的有效性。我们迈出了解决这些挑战的第一步，即提出一个动态 VEC-HFL 中的多模型训练框架，目标是最小化全局训练延迟，同时确保各个任务之间的平衡训练——这个问题最终被证明是 NP 难问题。为了促进及时的模型训练，我们引入了一种混合同步-异步聚合规则。在此基础上，我们提出了一种称为混合进化和贪婪分配 (HEART) 的新方法。该框架分两个阶段运行：首先，它通过结合改进的粒子群优化 (PSO) 和遗传算法 (GA) 的混合启发式方法实现平衡的任务调度；其次，它采用低复杂度的贪婪算法来确定分配给车辆的任务的训练优先级。在真实数据集上的实验证明了 HEART 优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2501.09934</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以客户端为中心的联邦自适应优化</title>
      <link>https://arxiv.org/abs/2501.09946</link>
      <description><![CDATA[arXiv:2501.09946v1 公告类型：新
摘要：联邦学习 (FL) 是一种分布式学习范式，其中客户端协作训练模型，同时保持自己的数据私密。随着客户端和模型规模的不断扩大，FL 面临两个关键挑战，由于高度的统计/系统异质性而导致的客户端漂移以及缺乏自适应性。然而，大多数现有的 FL 研究都是基于不切实际的假设，几乎忽略了系统异质性。在本文中，我们提出了以客户端为中心的联邦自适应优化，这是一类新颖的联邦自适应优化方法。我们在此框架中启用了几个功能，例如任意客户端参与、异步服务器聚合和异构本地计算，这些功能在现实世界的 FL 系统中无处不在，但在大多数现有工作中都被忽略了。我们对我们提出的框架进行了严格的收敛分析，以解决一般非凸目标，结果表明该框架以最佳已知速率收敛。大量实验表明，我们的方法在基准测试中始终大幅超越基线。]]></description>
      <guid>https://arxiv.org/abs/2501.09946</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>