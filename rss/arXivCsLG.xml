<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 24 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用交叉注意力机制改进对机械通气需求的预测</title>
      <link>https://arxiv.org/abs/2407.15885</link>
      <description><![CDATA[arXiv:2407.15885v1 公告类型：新
摘要：在重症监护室，预测机械通气 (MV) 需求的能力有助于更及时地进行干预以改善患者的预后。最近的研究表明，利用机器学习模型在这项任务中表现出色。本文探讨了具有多头注意力的深度学习模型 (FFNN-MHA) 的新应用，通过学习个别患者的个性化背景信息，做出更准确的 MV 预测并减少假阳性。利用公开的 MIMIC-IV 数据集，与前馈神经网络等基线模型相比，FFNN-MHA 的 AUC 提高了 0.0379，假阳性率降低了 17.8%。我们的结果突出了 FFNN-MHA 模型作为准确预测重症监护环境中机械通气需求的有效工具的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.15885</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>通过多源时空数据、深度学习、集成模型和迁移学习增强野火预报</title>
      <link>https://arxiv.org/abs/2407.15878</link>
      <description><![CDATA[arXiv:2407.15878v1 公告类型：新
摘要：本文通过整合多源时空数据（包括卫星数据）和应用深度学习技术，提出了一种预测野火的新方法。具体来说，我们利用基于迁移学习算法的集成模型来预测野火。重点是了解天气序列、人类活动和特定天气参数在野火预测中的重要性。这项研究在获取实时数据以训练网络方面遇到了挑战，尤其是在摩洛哥的荒野。未来的工作旨在开发一个能够处理多通道、多维和未格式化数据源的全局模型，以增强我们对地表瓷砖未来熵的理解。]]></description>
      <guid>https://arxiv.org/abs/2407.15878</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>Diff4VS：利用分类器引导扩散生成 HIV 抑制分子并进行虚拟筛选</title>
      <link>https://arxiv.org/abs/2407.15880</link>
      <description><![CDATA[arXiv:2407.15880v1 Announce Type: new 
摘要：艾滋病疫情已经夺走了4000万人的生命，造成了严重的全球性问题。发现新的HIV抑制分子对于抗击艾滋病疫情具有重要意义。这里，分类器引导扩散模型和基于配体的虚拟筛选策略相结合，首次发现了潜在的HIV抑制分子。我们称之为Diff4VS。使用HIV分子数据集训练一个额外的分类器，利用分类器的梯度引导扩散生成HIV抑制分子。实验表明，Diff4VS比其他方法能生成更多的HIV抑制候选分子。受基于配体的虚拟筛选的启发，提出了一种新的度量指标DrugIndex。DrugIndex是生成的分子中候选药物分子的比例与训练集中候选药物分子的比例之比。DrugIndex从制药的角度为分子生成模型的进化提供了一种新的评估方法。此外，我们报告了在使用分子生成模型进行虚拟筛选时观察到的一个新现象，即生成的分子与真实分子相比，与已知药物分子高度相似的比例较低，我们称之为分子生成中的降解。根据数据分析，降解可能是由于生成模型难以生成具有特定结构的分子所致。我们的研究从方法、度量和现象分析等方面促进了生成模型在药物设计中的应用。]]></description>
      <guid>https://arxiv.org/abs/2407.15880</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型对澳大利亚极端气候的评估：径流和洪水的预测</title>
      <link>https://arxiv.org/abs/2407.15882</link>
      <description><![CDATA[arXiv:2407.15882v1 公告类型：新
摘要：近年来，洪水等极端气候给澳大利亚带来了重大的环境和经济危害，对环境和经济造成了破坏，并造成了人员和动物的生命损失。一种有效的洪水预报方法对于限制这种损害至关重要。洪水预报技术目前基于水文和水动力学（基于物理）数值模型。包括深度学习在内的机器学习方法比传统的基于物理的方法具有某些优势，包括灵活性和准确性。深度学习方法有望在短时间内预测中小型气候极端事件；然而，大型洪水事件带来了严峻的挑战。我们提出了一种基于集成的机器学习方法，该方法使用由长短期记忆 (LSTM) 深度学习模型的极值理论启发的切换机制来解决大规模极端洪水挑战。我们使用多元和多步时间序列预测方法来预测澳大利亚主要集水区未来数天的流量。该集成框架还利用静态信息丰富时间序列信息，从而实现跨流域的区域建模。我们的结果表明，该模型对极端流量的预测能力得到增强，对选定的澳大利亚流域的大型洪水情景具有显著的效果。通过比较分析，我们的方法强调了深度学习模型有可能彻底改变不同地区的洪水预报。]]></description>
      <guid>https://arxiv.org/abs/2407.15882</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>语义原型：无需黑匣子即可增强透明度</title>
      <link>https://arxiv.org/abs/2407.15871</link>
      <description><![CDATA[arXiv:2407.15871v1 公告类型：新
摘要：随着机器学习 (ML) 模型和数据集的复杂性增加，对增强可解释性和可解释性的方法的需求变得至关重要。原型通过将基本特征封装在数据中，提供洞察力，从而实现战术决策并增强透明度。传统的原型方法通常依赖于亚符号原始数据和不透明的潜在空间，从而降低了可解释性并增加了误解的风险。本文提出了一个新颖的框架，该框架利用语义描述来定义原型并提供清晰的解释，有效地解决了传统方法的缺点。我们的方法利用基于概念的描述在语义层面上对数据进行聚类，确保原型不仅直观地表示底层属性，而且易于解释。我们的方法简化了解释过程，有效地弥合了复杂数据结构与人类认知过程之间的差距，从而提高了透明度并建立了信任。经过用户调查的验证，我们的方法在促进人类理解和信息量方面优于现有的广泛使用的原型方法。]]></description>
      <guid>https://arxiv.org/abs/2407.15871</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>一种用于自动化和加速 h/p 多重网格求解器的强化学习策略</title>
      <link>https://arxiv.org/abs/2407.15872</link>
      <description><![CDATA[arXiv:2407.15872v1 公告类型：新
摘要：我们探索了一种强化学习策略，以自动化和加速高阶求解器中的 h/p-多重网格方法。多重网格方法非常高效，但需要对数值参数进行微调，例如每级平滑扫描次数和校正分数（即从粗网格转移到细网格的校正解的比例）。本文的目的是使用近端策略优化算法自动调整多重网格参数，并通过这样做来提高 h/p-多重网格策略的稳定性和效率。
我们的研究结果表明，当使用高阶 h/p 方法在均匀和非均匀网格上离散化时，所提出的强化学习 h/p-多重网格方法显著加速并提高了一维对流扩散和非线性 Burgers 方程的稳态模拟的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2407.15872</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>CRMSP：一种利用类别重新平衡和合并语义伪标签进行关键信息提取的半监督方法</title>
      <link>https://arxiv.org/abs/2407.15873</link>
      <description><![CDATA[arXiv:2407.15873v1 公告类型：新 
摘要：在 KIE（关键信息提取）领域，应用半监督学习以节省人力和成本的需求日益增长，因为使用全监督方法训练文档数据需要劳动密集型的手动注释。在 KIE 中应用 SSL 的主要挑战是 (1) 低估长尾分布中尾部类别的置信度和 (2) 难以实现尾部特征的类内紧凑性和类间可分性。为了应对这些挑战，我们提出了一种新的 KIE 半监督方法，即类重新平衡和合并语义伪标签 (CRMSP)。首先，类重新平衡伪标签 (CRP) 模块引入了一个重新加权因子来重新平衡伪标签，增加了对尾部类别的关注。其次，我们提出了合并语义伪标签 (MSP) 模块，通过将样本分配给合并原型 (MP) 来聚类未标记数据的尾部特征。此外，我们专门为 MSP 设计了一种新的对比损失。在三个著名基准上进行的大量实验结果表明，CRMSP 实现了最先进的性能。值得注意的是，CRMSP 在 CORD 上实现了比最先进的 f1 分数提高 3.24% 的成绩。]]></description>
      <guid>https://arxiv.org/abs/2407.15873</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>用于神经网络压缩的 Shapley 剪枝</title>
      <link>https://arxiv.org/abs/2407.15875</link>
      <description><![CDATA[arXiv:2407.15875v1 公告类型：新
摘要：神经网络修剪是一个丰富的领域，具有多种方法。在这项工作中，我们建议将现有的修剪概念（例如留一法修剪和 Oracle 修剪）连接起来，并将它们发展为更通用的基于 Shapley 值的框架，该框架针对卷积神经网络的压缩。为了允许在实际应用中利用 Shapley 值，本研究提出了 Shapley 值近似值，并对神经网络压缩的成本效益效用进行了比较分析。根据基于 Oracle 集构建的新基准 Oracle 等级对所提出的等级进行了评估。广泛的实验表明，所提出的规范排名及其近似值显示出实际效果，获得了最先进的网络压缩。]]></description>
      <guid>https://arxiv.org/abs/2407.15875</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>具有张量输入的高斯过程模型及其在 3D 打印天线设计中的应用</title>
      <link>https://arxiv.org/abs/2407.15877</link>
      <description><![CDATA[arXiv:2407.15877v1 公告类型：新
摘要：在使用耗时的模拟器的基于模拟的工程设计中，高斯过程 (GP) 模型被广泛用作快速模拟器，以加快设计优化过程。在其最常用的形式中，GP 的输入是一个简单的设计参数列表。随着增材制造（也称为 3D 打印）的快速发展，具有 2D/3D 空间信息的设计输入在某些应用中变得普遍，例如，像素/体素之间的相邻关系和异质材料中的材料分布。这种空间信息对 3D 打印设计至关重要，很难融入现有的具有常用内核（如平方指数或 Mat\&#39;ern）的 GP 模型中。在这项工作中，我们建议将广义距离测量嵌入 GP 内核，提供一种新颖而方便的技术，将自由形式 3D 打印设计的空间信息纳入 GP 框架。所提出的方法允许 3D 打印对象的复杂设计问题利用 GP 代理模拟优化提供的大量工具，例如设计实验和基于 GP 的优化（包括贝叶斯优化）。我们研究了所提出方法的属性，并通过几个 3D 打印天线的数值示例说明了其性能。数据集可在以下网址公开获取：https://github.com/xichennn/GP_dataset。]]></description>
      <guid>https://arxiv.org/abs/2407.15877</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>一项关于农村社区可持续未来的人工智能微电网解决方案的调查</title>
      <link>https://arxiv.org/abs/2407.15865</link>
      <description><![CDATA[arXiv:2407.15865v1 公告类型：新
摘要：本文全面调查了旨在提高可持续能源获取的人工智能驱动的微电网解决方案。它强调了微电网的潜力，它可以独立运行或与国家电网协同运行，为偏远社区提供可靠且负担得起的电力。鉴于太阳能和风能等可再生能源固有的不可预测性，讨论了准确的能源预测和管理的必要性，强调了先进的人工智能技术在预测能源供需、优化电网运营和确保可持续能源分配方面的作用。本文回顾了各种预测模型，包括统计方法、机器学习算法和混合方法，评估了它们对短期和长期预测的有效性。此外，它还探索了用于模型实施和验证的公共数据集和工具，如 Prophet、NeuralProphet 和 N-BEATS。调查最后提出了未来研究的建议，解决了模型适应和优化在实际应用中的挑战。]]></description>
      <guid>https://arxiv.org/abs/2407.15865</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:36 GMT</pubDate>
    </item>
    <item>
      <title>SmartQuant：基于 CXL 的 AI 模型存储，支持运行时可配置权重量化</title>
      <link>https://arxiv.org/abs/2407.15866</link>
      <description><![CDATA[arXiv:2407.15866v1 公告类型：新 
摘要：最近的研究表明，在对 transformer 等生成式人工智能模型进行推理时，不同权重的重要性表现出显著的上下文相关变化。这自然体现出自适应配置权重量化以提高生成式人工智能推理效率的巨大潜力。虽然可配置权重量化可以轻松利用现代 GPU 和人工智能加速器中可变精度算法的硬件支持，但之前很少有研究研究如何利用可变权重量化来按比例提高人工智能模型内存访问速度和能源效率。在快速成熟的 CXL 生态系统的推动下，这项工作开发了一种基于 CXL 的设计解决方案来填补这一空白。关键是让 CXL 内存控制器在支持和利用运行时可配置权重量化方面发挥积极作用。以 transformer 为代表性的生成式人工智能模型，我们进行了实验，很好地证明了所提出的设计方案的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.15866</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:36 GMT</pubDate>
    </item>
    <item>
      <title>用于长期序列预测的长输入序列网络</title>
      <link>https://arxiv.org/abs/2407.15869</link>
      <description><![CDATA[arXiv:2407.15869v1 公告类型：新
摘要：短固定长度输入是深度学习方法在长时间序列预测任务中的主要瓶颈。延长输入长度会导致过度拟合，从而迅速降低准确性。我们的研究表明，过度拟合是时间序列中的多尺度模式耦合和当前模型的固定聚焦尺度的综合反应。首先，我们发现时间序列在不同尺度上表现出的模式反映了其多周期性质，其中每个尺度对应特定的周期长度。其次，我们发现标记大小主要决定模型行为，因为它决定了模型关注的尺度和它可以容纳的上下文大小。我们的想法是将时间序列的多尺度时间模式解耦，并使用其相应的周期长度作为标记大小对每个模式进行建模。我们引入了新颖的系列分解模块 (MPSD) 和多标记模式识别神经网络 (MTPR)，使模型能够处理 \textit{最多 $10\times$ 长的输入}。充足的上下文可提高性能（\textit{最大精度提高 38%}），而解耦方法可提供 \textit{低复杂度（$0.22\times$ 成本）} 和 \textit{高可解释性}。]]></description>
      <guid>https://arxiv.org/abs/2407.15869</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:36 GMT</pubDate>
    </item>
    <item>
      <title>BoRA：用于多任务大型语言模型的贝叶斯分层低秩自适应</title>
      <link>https://arxiv.org/abs/2407.15857</link>
      <description><![CDATA[arXiv:2407.15857v1 公告类型：新
摘要：本文介绍了贝叶斯分层低秩自适应 (BoRA)，这是一种用于微调多任务大型语言模型 (LLM) 的新方法。当前的微调方法，例如低秩自适应 (LoRA)，在减少训练参数和内存使用方面表现出色，但在应用于多个类似任务时会受到限制。从业者通常必须在为每个任务训练单独的模型或为所有任务训练一个模型之间做出选择，这两种方式在专业化和数据利用率方面都有所权衡。
BoRA 通过利用贝叶斯分层模型来解决这些权衡问题，该模型允许任务通过全局分层先验共享信息。这使数据有限的任务能够从来自相关任务的整体结构中受益，同时允许具有更多数据的任务进行专业化。我们的实验结果表明，BoRA 优于单独和统一模型方法，实现了更低的困惑度和更好的跨任务泛化。该方法为多任务 LLM 微调提供了一种可扩展且有效的解决方案，对各种应用具有重要的实际意义。]]></description>
      <guid>https://arxiv.org/abs/2407.15857</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:35 GMT</pubDate>
    </item>
    <item>
      <title>轻量级开源大型语言模型在儿科会诊中的表现评估：比较分析</title>
      <link>https://arxiv.org/abs/2407.15862</link>
      <description><![CDATA[arXiv:2407.15862v1 公告类型：新
摘要：大型语言模型 (LLM) 已在医学领域展现出潜在的应用，但数据隐私和计算负担限制了它们在医疗机构中的部署。开源和轻量级版本的 LLM 成为潜在的解决方案，但它们的性能，特别是在儿科环境中的性能仍未得到充分探索。在这项横断面研究中，从公共在线医疗论坛随机选择了 250 个患者咨询问题，每个问题来自 25 个儿科部门，时间跨度从 2022 年 12 月 1 日到 2023 年 10 月 30 日。两个轻量级开源 LLM ChatGLM3-6B 和 Vicuna-7B，以及更大规模的模型 Vicuna-13B 和广泛使用的专有 ChatGPT-3.5，在 2023 年 11 月 1 日至 2023 年 11 月 7 日期间独立用中文回答了这些问题。为了评估可重复性，每个询问都重复了一次。我们发现 ChatGLM3-6B 的准确性和完整性高于 Vicuna-13B 和 Vicuna-7B（P &lt; .001），但所有这些都比 ChatGPT-3.5 更胜一筹。 ChatGPT-3.5 在准确度方面获得了最高评分（65.2%），而 ChatGLM3-6B（41.2%）、Vicuna-13B（11.2%）和 Vicuna-7B（4.4%）则不然。同样，在完整性方面，ChatGPT-3.5 领先（78.4%），其次是 ChatGLM3-6B（76.0%）、Vicuna-13B（34.8%）和 Vicuna-7B（22.0%）。ChatGLM3-6B 在可读性方面与 ChatGPT-3.5 不相上下，均优于 Vicuna 模型（P &lt; .001）。在同理心方面，ChatGPT-3.5 优于轻量级 LLM（P &lt; .001）。在安全性方面，所有模型的表现都相当出色（P &gt; .05），超过 98.4% 的响应被评为安全。重复询问证实了这些发现。总之，轻量级 LLM 在儿科医疗保健领域具有广阔的应用前景。然而，轻量级和大型专有 LLM 之间的差距凸显了继续开发工作的必要性。]]></description>
      <guid>https://arxiv.org/abs/2407.15862</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:35 GMT</pubDate>
    </item>
    <item>
      <title>对比学习中的过度拟合？</title>
      <link>https://arxiv.org/abs/2407.15863</link>
      <description><![CDATA[arXiv:2407.15863v1 公告类型：新
摘要：过度拟合描述了一种机器学习现象，即模型与训练数据过于接近，导致泛化能力较差。虽然这种情况在许多形式的监督学习中都有详尽的记录，但在\underline{un}监督学习的背景下并没有得到很好的检验。在这项工作中，我们研究了无监督对比学习中过度拟合的性质。我们表明过度拟合确实可能发生，以及过度拟合背后的机制。]]></description>
      <guid>https://arxiv.org/abs/2407.15863</guid>
      <pubDate>Thu, 25 Jul 2024 03:16:35 GMT</pubDate>
    </item>
    </channel>
</rss>