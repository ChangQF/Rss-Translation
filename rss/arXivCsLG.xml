<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 20 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>WLAN 分布式信道接入的异构多智能体强化学习</title>
      <link>https://arxiv.org/abs/2412.14218</link>
      <description><![CDATA[arXiv:2412.14218v1 公告类型：新
摘要：本文研究了使用多智能体强化学习 (MARL) 解决无线局域网中的分布式信道访问问题。特别是，我们考虑了具有挑战性但更实际的情况，即代理异构地采用基于价值或基于策略的强化学习算法来训练模型。我们提出了一种异构 MARL 训练框架，名为 QPMIX，它采用集中式训练和分布式执行范例，使异构代理能够协作。此外，我们在理论上证明了使用线性值函数近似时所提出的异构 MARL 方法的收敛性。我们的方法最大化了网络吞吐量并确保了站点之间的公平性，从而提高了整体网络性能。仿真结果表明，与饱和流量场景下具有碰撞避免的传统载波侦听多路访问相比，所提出的 QPMIX 算法提高了吞吐量、平均延迟、延迟抖动和碰撞率。此外，QPMIX 在非饱和和延迟敏感的流量场景中表现出色，并促进异构代理之间的合作。]]></description>
      <guid>https://arxiv.org/abs/2412.14218</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合专家模型推理优化技术综述</title>
      <link>https://arxiv.org/abs/2412.14219</link>
      <description><![CDATA[arXiv:2412.14219v1 公告类型：新
摘要：大规模混合专家 (MoE) 模型的出现标志着人工智能的重大进步，通过条件计算提供了增强的模型容量和计算效率。然而，这些模型的部署和推理在计算资源、延迟和能源效率方面带来了巨大挑战。这项全面的调查系统地分析了整个系统堆栈中 MoE 模型的推理优化技术的当前状况。我们首先建立一个分类框架，将优化方法分为模型级、系统级和硬件级优化。在模型级别，我们研究架构创新，包括高效的专家设计、注意机制、各种压缩技术（如修剪、量化和知识提炼），以及算法改进（包括动态路由策略和专家合并方法）。在系统级别，我们研究分布式计算方法、负载平衡机制和实现可扩展部署的高效调度算法。此外，我们还深入研究了硬件特定的优化和共同设计策略，以最大限度地提高吞吐量和能源效率。这项调查不仅提供了现有解决方案的结构化概述，还确定了 MoE 推理优化中的关键挑战和有前途的研究方向。我们的全面分析为在资源受限的环境中大规模部署 MoE 模型的研究人员和从业者提供了宝贵的资源。为了促进持续更新和分享 MoE 推理优化研究的前沿进展，我们建立了一个存储库，网址为 \url{https://github.com/MoE-Inf/awesome-moe-inference/}。]]></description>
      <guid>https://arxiv.org/abs/2412.14219</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现 GNN 中的精确预测不确定性：使用拓扑分组策略细化 GNN</title>
      <link>https://arxiv.org/abs/2412.14223</link>
      <description><![CDATA[arXiv:2412.14223v1 公告类型：新
摘要：图神经网络 (GNN) 的最新进展凸显了校准模型预测的迫切需求，其中邻域预测相似性被认为是一个关键组成部分。现有研究表明，具有类似邻域预测相似性的节点通常表现出相似的校准特性。基于这一见解，最近的方法将邻域相似性纳入节点温度缩放技术中。然而，我们的分析表明，这一假设并不普遍成立。即使在具有可比邻域相似性的节点之间，校准误差也会有很大差异，这取决于它们的置信度。这需要重新评估现有的 GNN 校准方法，因为单一、统一的方法可能会导致次优校准。作为回应，我们引入了 **Simi-Mailbox**，这是一种新颖的方法，它根据邻域相似性和它们自己的置信度对节点进行分类，而不管接近度或连通性如何。我们的方法允许通过采用*特定于组*的温度缩放来实现细粒度校准，每个温度都经过量身定制，以解决关联节点的特定校准误差水平，而不是遵循基于邻域相似性的统一趋势。大量实验证明了我们的**Simi-Mailbox**在不同 GNN 架构上的不同数据集中的有效性，与未校准的 GNN 预测相比，误差降低了 13.79%。]]></description>
      <guid>https://arxiv.org/abs/2412.14223</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedSTaS：实现高效联邦学习的客户端分层和客户端级别采样</title>
      <link>https://arxiv.org/abs/2412.14226</link>
      <description><![CDATA[arXiv:2412.14226v1 公告类型：新
摘要：联邦学习 (FL) 是一种机器学习方法，涉及以隐私保护的方式在多个分散客户端之间协作训练全局模型。引入了几种 FL 方法来应对通信效率低下的问题，但没有解决如何有效地以隐私保护的方式对每轮参与的客户端进行采样。在本文中，我们提出了 \textit{FedSTaS}，这是一种受 \textit{FedSTS} 和 \textit{FedSampling} 启发的客户端和数据级采样方法。在每个联邦学习轮次中，\textit{FedSTaS} 根据客户端的压缩梯度对其进行分层，使用最佳 Neyman 分配重新分配要采样的客户端数量，并使用数据统一采样策略从每个参与客户端采样本地数据。在三个数据集上的实验表明，在固定数量的训练轮次内，\textit{FedSTaS} 可以获得比 \textit{FedSTS} 更高的准确率。]]></description>
      <guid>https://arxiv.org/abs/2412.14226</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念漂移下的分布稳健策略学习</title>
      <link>https://arxiv.org/abs/2412.14297</link>
      <description><![CDATA[arXiv:2412.14297v1 公告类型：新
摘要：分布稳健策略学习旨在找到一种在最坏情况分布偏移下表现良好的策略，但大多数现有的稳健策略学习方法都考虑了协变量和结果的最坏情况联合分布。当我们有更多关于分布偏移来源的信息时，联合建模策略可能会不必要地保守。本文研究了一个更细微的问题——概念漂移下的稳健策略学习，此时只有结果和协变量之间的条件关系会发生变化。为此，我们首先提供一个双稳健估计量，用于评估一组扰动条件分布下给定策略的最坏情况平均奖励。我们表明，即使以低于根 $n$ 的速率估计干扰参数，策略值估计量也具有渐近正态性。然后，我们提出了一种学习算法，该算法输出在给定策略类 $\Pi$ 内最大化估计策略值的策略，并表明所提算法的次优性差距为 $\kappa(\Pi)n^{-1/2}$ 阶，其中 $\kappa(\Pi)$ 是 Hamming 距离下 $\Pi$ 的熵积分，$n$ 是样本大小。提供了匹配的下限以显示速率的最优性。所提出的方法已在数值研究中实施和评估，与现有基准相比显示出显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2412.14297</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多重分类框架：通过问题转换、本体工程和模型集成优化多标签分类器</title>
      <link>https://arxiv.org/abs/2412.14299</link>
      <description><![CDATA[arXiv:2412.14299v1 公告类型：新
摘要：分类是机器学习中的一项基本任务。虽然传统方法（例如二分类、多类分类和多标签分类）对于较简单的问题很有效，但它们可能无法充分解决某些现实场景的复杂性。本文介绍了多重分类框架，这是一种通过集成问题转换、本体工程和模型集成来应对这些和类似挑战的新方法。该框架具有多种优势，包括适应任意数量的类别和逻辑约束、管理类别不平衡的创新方法、消除置信度阈值选择和模块化结构。进行了两个实验，以比较传统分类模型与多重方法的性能。我们的结果表明，多重方法可以显着提高分类性能（整体 F1 分数可提高 10%），特别是在具有大量类别和明显类别不平衡的分类问题中。然而，它也有局限性，因为它需要对问题领域有透彻的了解，并具有一定的本体工程经验，而且它涉及训练多个模型，这可能会使整个过程更加复杂。总的来说，这种方法为处理机器学习中复杂分类问题的研究人员和从业者提供了一个有价值的工具。]]></description>
      <guid>https://arxiv.org/abs/2412.14299</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>窃取免费午餐：揭露 Dyna 式强化学习的局限性</title>
      <link>https://arxiv.org/abs/2412.14312</link>
      <description><![CDATA[arXiv:2412.14312v1 公告类型：新
摘要：Dyna 风格的基于离线策略模型的强化学习 (DMBRL) 算法是一类用于生成合成状态转换数据并从而提高离线策略 RL 算法的采样效率的技术。本文确定并研究了在具有本体感受观察的不同基准环境中应用 DMBRL 算法时观察到的令人惊讶的性能差距。我们表明，虽然 DMBRL 算法在 OpenAI Gym 中表现良好，但它们的性能在 DeepMind Control Suite (DMC) 中可能会显着下降，即使这些设置提供了类似的任务和相同的物理后端。旨在解决这些设置中出现的几个关键问题的现代技术并不能在所有环境中提供一致的改进，总的来说，我们的结果表明，在训练过程中添加合成推出——Dyna 风格算法的骨干——会显着降低大多数 DMC 环境中的性能。我们的研究结果有助于更深入地理解基于模型的 RL 中的几个基本挑战，并表明，与许多优化领域一样，在评估 RL 中不同基准的性能时，没有免费的午餐。]]></description>
      <guid>https://arxiv.org/abs/2412.14312</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>免费协方差：利用预训练模型进行联邦学习的均值分布</title>
      <link>https://arxiv.org/abs/2412.14326</link>
      <description><![CDATA[arXiv:2412.14326v1 公告类型：新
摘要：使用预训练模型已被发现可以减少数据异质性的影响并加速联邦学习算法。最近的研究调查了使用一阶统计数据和二阶统计数据在服务器上聚合本地客户端数据分布并在没有任何训练的情况下实现非常高的性能。在这项工作中，我们提出了一种基于类协方差矩阵无偏估计量的无训练方法。我们的方法仅使用客户端与服务器通信的类均值形式的一阶统计数据，仅产生基于通信二阶统计数据的方法所需通信成本的一小部分。我们展示了如何使用这些估计的类协方差来初始化线性分类器，从而利用协方差而不实际共享它们。与同样只共享类均值的最先进的方法相比，我们的方法在完全相同的通信成本下将性能提高了 4-26% 左右。此外，我们的方法在显著减少通信开销的情况下，实现了与共享二阶统计量相当甚至更优的性能。最后，使用我们的方法初始化分类器，然后执行联合微调，可以实现更好、更快的收敛。代码可在 https://github.com/dipamgoswami/FedCOF 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.14326</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估生成模型的统一信息论视角</title>
      <link>https://arxiv.org/abs/2412.14340</link>
      <description><![CDATA[arXiv:2412.14340v1 公告类型：新
摘要：考虑到解释生成模型输出的难度，目前有大量研究集中于确定有意义的评估指标。最近的几种方法利用从分类领域借用的“精度”和“召回率”分别量化输出保真度（真实性）和输出多样性（真实数据变化的表示）。随着度量建议的增加，需要一个统一的视角，以便更容易比较和更清楚地解释它们的优点和缺点。为此，我们使用来自 kNN 密度估计的方法，在信息理论视角下统一了一类基于 kth-nearest-neighbors (kNN) 的度量。此外，我们提出了一个由精度交叉熵 (PCE)、召回交叉熵 (RCE) 和召回熵 (RE) 组成的三维度量，分别测量保真度和多样性的两个不同方面，即类间和类内。我们的领域无关度量源自信息论中熵和交叉熵的概念，可用于样本级和模式级分析。我们的详细实验结果证明了我们的度量组件对其各自质量的敏感性，并揭示了其他度量的不良行为。]]></description>
      <guid>https://arxiv.org/abs/2412.14340</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用交错异步推理实现大规模实时强化学习</title>
      <link>https://arxiv.org/abs/2412.14355</link>
      <description><![CDATA[arXiv:2412.14355v1 公告类型：新
摘要：即使代理执行动作推理和学习，实时环境也会发生变化，因此需要高交互频率才能有效地最大限度地减少遗憾。然而，机器学习的最新进展涉及更大的神经网络和更长的推理时间，这引发了人们对它们在反应时间至关重要的实时系统中的适用性的质疑。我们对实时强化学习 (RL) 环境中遗憾的下限进行了分析，以表明在典型的顺序交互和学习范式中，最大限度地减少长期遗憾通常是不可能的，但在有足够的异步计算时，通常会成为可能。我们提出了用于交错异步推理过程的新算法，以确保以一致的时间间隔采取行动，并证明使用具有高动作推理时间的模型仅受环境在推理范围内的有效随机性的限制，而不是动作频率的限制。我们的分析表明，所需的推理过程的数量随着推理时间的增加而线性增长，同时在从 Game Boy 游戏（例如 Pok&#39;emon 和 Tetris）的实时模拟中学习时，可以使用比现有方法大几个数量级的模型。]]></description>
      <guid>https://arxiv.org/abs/2412.14355</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ResQ：具有低秩残差的大型语言模型的混合精度量化</title>
      <link>https://arxiv.org/abs/2412.14363</link>
      <description><![CDATA[arXiv:2412.14363v1 公告类型：新
摘要：大型语言模型 (LLM) 的训练后量化 (PTQ) 有望降低推理时过高的计算成本。由于激活中的极端异常值导致的量化误差很大，因此将所有权重、激活和键值 (KV) 缓存张量量化为 4 位而不显著降低通用性是一项挑战。为了解决这个问题，我们提出了 ResQ，这是一种进一步推动最先进技术的 PTQ 方法。通过主成分分析 (PCA)，它识别激活方差最高的低秩子空间（实际上是隐藏维度的 1/8），并以高精度（例如 8 位）保持此子空间内的系数，同时将其余部分量化为 4 位。在每个子空间内，应用不变随机旋转以进一步抑制异常值。我们证明，这是一种可证明的最佳混合精度量化方案，可最大限度地减少误差。借助 Llama 系列模型，我们证明 ResQ 在各种基准测试中的表现均优于最近的均匀和混合精度 PTQ 方法，在 Wikitext 上的困惑度比下一个最佳方法 SpinQuant 低 33%，速度比 16 位基线快 2.4 倍。代码可在 https://github.com/utkarsh-dmx/project-resq 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.14363</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>I0T：嵌入标准化方法以实现零模态差距</title>
      <link>https://arxiv.org/abs/2412.14384</link>
      <description><![CDATA[arXiv:2412.14384v1 公告类型：新
摘要：对比语言-图像预训练 (CLIP) 可在图像文本检索和分类等下游任务中实现零样本推理。然而，最近扩展 CLIP 的工作受到模态差距问题的困扰，当图像和文本嵌入被投影到不同的流形时，就会出现这种问题，偏离图像文本对比学习的预期目标。我们发现这种现象与每个图像/文本编码器独立拥有的模态特定特征有关，并提出了两种方法来解决模态差距：(1) 事后嵌入标准化方法 $\text{I0T}_{\text{post}}$，可将模态差距缩小到接近零；(2) 一种可训练方法，$\text{I0T}_{\text{async}}$，通过为每个编码器添加两个规范化层来缓解模态差距问题。我们的 I0T 框架可以显著减少模态差距，同时保留已训练模型的原始嵌入表示及其锁定的参数。在实践中，$\text{I0T}_{\text{post}}$ 可以作为广泛使用的 CLIPScore (CLIP-S) 的另一种可解释的自动评估指标。]]></description>
      <guid>https://arxiv.org/abs/2412.14384</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DriveGPT：扩展驾驶自回归行为模型</title>
      <link>https://arxiv.org/abs/2412.14415</link>
      <description><![CDATA[arXiv:2412.14415v1 公告类型：新
摘要：我们提出了 DriveGPT，一种可扩展的自动驾驶行为模型。我们将驾驶建模为一个顺序决策任务，并学习一个转换器模型，以自回归方式将未来代理状态预测为标记。我们将模型参数和训练数据扩大了多个数量级，使我们能够探索数据集大小、模型参数和计算方面的扩展属性。我们通过定量指标和定性示例（包括复杂现实场景中的闭环驾驶）在规划任务中评估不同规模的 DriveGPT。在单独的预测任务中，DriveGPT 的表现优于最先进的基线，并通过在大规模数据集上进行预训练表现出更好的性能，进一步验证了数据扩展的好处。]]></description>
      <guid>https://arxiv.org/abs/2412.14415</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平衡梯度样本检索以增强基于代理的持续学习中的知识保留</title>
      <link>https://arxiv.org/abs/2412.14430</link>
      <description><![CDATA[arXiv:2412.14430v1 公告类型：新
摘要：深度神经网络中的持续学习经常遭受灾难性遗忘，即在后续训练中覆盖先前任务的表示。我们提出了一种从内存缓冲区中检索样本的新型策略，该策略利用梯度冲突和梯度对齐样本，在监督对比学习框架内有效地保留有关过去任务的知识。选择梯度冲突样本是因为它们有可能通过重新调整梯度来减少干扰，从而保留过去的任务知识。同时，梯度对齐样本被纳入以加强跨任务的稳定、共享表示。通过平衡冲突样本的梯度校正和对齐样本的对齐强化，我们的方法增加了检索到的实例之间的多样性，并在参数空间中实现了卓越的对齐，显着增强了知识保留并减轻了代理漂移。实证结果表明，使用两种样本类型优于仅依赖一种样本类型或随机检索的方法。在计算机视觉领域流行的持续学习基准上进行的实验验证了我们的方法在减轻遗忘方面的最佳性能，同时在新任务上保持具有竞争力的准确性。]]></description>
      <guid>https://arxiv.org/abs/2412.14430</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中的优选：如何选择数据集以使您的模型脱颖而出</title>
      <link>https://arxiv.org/abs/2412.14435</link>
      <description><![CDATA[arXiv:2412.14435v1 公告类型：新
摘要：时间序列预测的重要性推动了持续的研究和解决这一问题的新方法的开发。通常，这些方法是通过实证研究引入的，这些研究经常声称所提出的方法具有更高的准确性。然而，由于实验设置的局限性，人们对这些结果的可靠性和普遍性的担忧日益增加。本文解决了一个关键的限制：所用数据集的数量和代表性。我们研究了数据集选择偏差（特别是挑选数据集的做法）对预测方法性能评估的影响。通过对一组不同的基准数据集进行实证分析，我们的研究结果表明，挑选数据集会显著扭曲方法的感知性能，往往会夸大其有效性。此外，我们的结果表明，通过有选择地选择四个数据集（大多数研究报告），46% 的方法可以被视为同类最佳，77% 的方法可以排在前三名。此外，最近基于深度学习的方法对数据集选择表现出很高的敏感性，而传统方法则表现出更高的稳健性。最后，我们的结果表明，当在基准子集上对预测算法进行实证验证时，将测试的数据集数量从 3 个增加到 6 个可以将错误地将算法识别为最佳算法的风险降低约 40%。我们的研究强调了对更准确地反映现实世界场景的综合评估框架的迫切需求。采用这样的框架将确保开发出稳健可靠的预测方法。]]></description>
      <guid>https://arxiv.org/abs/2412.14435</guid>
      <pubDate>Fri, 20 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>