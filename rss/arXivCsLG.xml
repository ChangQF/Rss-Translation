<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 04 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>针对异构源的非联邦多任务分割学习</title>
      <link>https://arxiv.org/abs/2406.00150</link>
      <description><![CDATA[arXiv:2406.00150v1 公告类型：新
摘要：随着边缘网络和移动计算的发展，需要在网络边缘为异构数据源提供服务，这就要求设计新的分布式机器学习机制。作为一种流行的方法，联邦学习 (FL) 在客户端和服务器之间采用参数共享和梯度平均。尽管经典 FL 具有许多优点，例如收敛和数据隐私保证，但众所周知，它无法解决跨客户端的数据异构性和计算异构性的挑战。大多数旨在适应此类异构源的现有研究都停留在 FL 操作范式中，并进行了修改以克服异构数据的负面影响。在这项工作中，作为一种替代范式，我们提出了一个多任务分割学习 (MTSL) 框架，它将分割学习 (SL) 的优势与分布式网络架构的灵活性相结合。与 FL 对应物相比，在这个范式中，异构性不是需要克服的障碍，而是一个可以利用的有用属性。因此，这项工作旨在引入一种新的架构和方法，以有效地对异构数据源进行多任务学习，希望鼓励社区进一步探索我们所揭示的潜在优势。为了支持这一承诺，我们首先通过理论分析表明，MTSL 可以通过调整服务器和客户端的学习率来实现快速收敛。然后，我们在几个图像分类数据集上对 MTSL 与现有的多任务 FL 方法的性能进行了数值比较，以表明 MTSL 在训练速度、通信成本和对异构数据的鲁棒性方面优于 FL。]]></description>
      <guid>https://arxiv.org/abs/2406.00150</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>用于水管理的不确定性量化流量预测：一种约束推理和学习方法</title>
      <link>https://arxiv.org/abs/2406.00133</link>
      <description><![CDATA[arXiv:2406.00133v1 公告类型：新
摘要：预测流量的时空变化以及不确定性量化有助于为稀缺水资源的可持续管理做出决策。基于过程的水文模型（又名基于物理的模型）基于物理定律，但使用简化假设，这可能导致准确性较差。数据驱动的方法提供了一种强大的替代方案，但它们需要大量的训练数据，并且往往会产生与物理定律不一致的预测。本文研究了一种约束推理和学习 (CRL) 方法，其中以逻辑约束表示的物理定律被集成为深度神经网络中的一层。为了解决小数据设置问题，我们开发了一种理论化的训练方法来提高深度模型的泛化精度。对于不确定性量化，我们结合高斯过程 (GP) 和深度时间模型（即用于时间序列预测的深度模型）的协同优势，将学习到的潜在表示作为输入传递给基于标准距离的内核。在多个真实数据集上进行的实验证明了 CRL 和具有深度核方法的 GP 相对于强基线方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.00133</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>动态图中的异常检测：综合综述</title>
      <link>https://arxiv.org/abs/2406.00134</link>
      <description><![CDATA[arXiv:2406.00134v1 公告类型：新
摘要：本调查论文对使用动态图进行异常检测进行了全面和概念性的概述。我们专注于现有的基于图的异常检测 (AD) 技术及其在动态网络中的应用。本调查论文的贡献包括：i) 对现有异常检测调查的比较研究；ii) 基于动态图的异常检测 (DGAD) 审查框架，其中基于传统机器学习模型、矩阵变换、概率方法和深度学习方法对动态图中的异常检测方法进行分组；iii) 讨论以图形方式表示离散和动态网络；iv) 讨论基于图的技术在捕获动态图数据中的关系结构和复杂交互方面的优势。最后，这项工作确定了检测动态网络异常的潜在挑战和未来方向。这项 DGAD 调查方法旨在通过总结每种方法的优势和局限性、强调当前的研究趋势和确定开放的挑战，为研究人员和从业者提供宝贵的资源。这样，它可以指导未来的研究工作并促进动态图中异常检测的进步。
关键词：图、异常检测、动态网络、图神经网络 (GNN)、节点异常、图挖掘。]]></description>
      <guid>https://arxiv.org/abs/2406.00134</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>Query2CAD：使用自然语言查询生成 CAD 模型</title>
      <link>https://arxiv.org/abs/2406.00144</link>
      <description><![CDATA[arXiv:2406.00144v1 公告类型：新
摘要：计算机辅助设计 (CAD) 工程师通常不会一次性获得最佳原型。相反，他们会通过多次修改迭代和改进设计以获得最佳解决方案。这种传统方法虽然有效，但非常耗时，并且严重依赖熟练工程师的专业知识。为了应对这些挑战，我们引入了 Query2CAD，这是一种用于生成 CAD 设计的新框架。该框架使用大型语言模型来生成可执行的 CAD 宏。此外，Query2CAD 借助其自优化循环来优化 CAD 模型的生成。Query2CAD 无需监督数据或额外训练即可运行，使用 LLM 作为生成器和优化器。优化器利用 BLIP2 模型生成的反馈，为了解决误报问题，我们将人机反馈纳入我们的系统。此外，我们开发了一个包含 CAD 模型设计中使用的大多数操作的数据集，并使用该数据集评估了我们的框架。我们的研究结果表明，当我们使用 GPT-4 Turbo 作为语言模型时，该架构在第一次尝试时的成功率达到了 53.6%。随着后续的改进，成功率提高了 23.1%。特别是，在改进的第一次迭代中观察到了成功率的最显著提高。随着后续的改进，正确设计的准确性并没有显著提高。我们已经开源了我们的数据、模型和代码（github.com/akshay140601/Query2CAD）。]]></description>
      <guid>https://arxiv.org/abs/2406.00144</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>嘈杂和不确定环境中的深度强化学习奖励机器</title>
      <link>https://arxiv.org/abs/2406.00120</link>
      <description><![CDATA[arXiv:2406.00120v1 公告类型：新
摘要：奖励机器提供了一种自动机启发的结构，用于指定指令、安全约束和其他时间延长的奖励行为。通过公开复杂的奖励函数结构，它们可以实现反事实学习更新，从而带来令人印象深刻的样本效率提升。虽然奖励机器已在表格和深度 RL 设置中使用，但它们通常依赖于对构成奖励函数构建块的领域特定词汇的真实解释。这种真实解释在许多现实世界环境中可能难以捉摸，部分原因是部分可观测性或噪声感知。在本文中，我们探讨了在嘈杂和不确定的环境中将奖励机器用于深度 RL。我们将这个问题描述为 POMDP，并提出了一套 RL 算法，这些算法利用领域特定词汇的不确定解释下的任务结构。理论分析揭示了解决此问题的简单方法的缺陷，而实验结果表明，我们的算法成功利用任务结构来提高词汇解释嘈杂情况下的性能。我们的结果为在部分可观察环境中利用奖励机器提供了一个通用框架。]]></description>
      <guid>https://arxiv.org/abs/2406.00120</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>情境学习如何从非结构化数据训练中产生：共现、位置信息和噪声结构的作用</title>
      <link>https://arxiv.org/abs/2406.00131</link>
      <description><![CDATA[arXiv:2406.00131v1 公告类型：新 
摘要：像 transformer 这样的大型语言模型 (LLM) 具有令人印象深刻的上下文学习 (ICL) 能力；它们可以根据提示中的输入输出序列生成对新查询的预测，而无需更新参数。虽然许多理论试图解释 ICL，但它们通常侧重于类似于 ICL 任务的结构化训练数据，例如回归。然而，在实践中，这些模型是在非结构化文本数据上以无监督的方式训练的，这与 ICL 任务几乎没有相似之处。为此，我们研究了 ICL 是如何从非结构化数据的无监督训练中产生的。关键的观察是，ICL 可以简单地通过使用经典语言模型（如连续词袋 (CBOW)）对共现信息进行建模来产生，我们从理论上证明了这一点，并通过经验验证了这一点。此外，我们确定了位置信息和噪声结构的必要性，以将 ICL 推广到看不见的数据。最后，我们展示了 ICL 失败的实例并提供了理论解释；他们认为，LLM 识别某些任务的 ICL 能力可能对训练数据的结构很敏感。]]></description>
      <guid>https://arxiv.org/abs/2406.00131</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>QuanTA：利用量子信息张量自适应对 LLM 进行高效高秩微调</title>
      <link>https://arxiv.org/abs/2406.00132</link>
      <description><![CDATA[arXiv:2406.00132v1 公告类型：新
摘要：我们提出了量子信息张量自适应（QuanTA），这是一种新颖、易于实现的微调方法，对于大规模预训练语言模型没有推理开销。通过利用源自量子电路结构的量子启发方法，QuanTA 实现了高效的高秩微调，超越了低秩自适应（LoRA）的局限性——低秩近似可能会因复杂的下游任务而失败。我们的方法在理论上得到了普遍性定理和秩表示定理的支持，以实现高效的高秩自适应。实验表明，与传统方法相比，QuanTA 显着增强了常识推理、算术推理和可扩展性。此外，与其他方法相比，QuanTA 具有更少的可训练参数和更优异的性能，并且可以设计为与现有的微调算法相结合以进一步改进，为微调大型语言模型和推动自然语言处理的最新技术提供可扩展且高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.00132</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>具有后验的可扩展贝叶斯学习</title>
      <link>https://arxiv.org/abs/2406.00104</link>
      <description><![CDATA[arXiv:2406.00104v1 公告类型：新
摘要：尽管理论上很有说服力，但使用现代机器学习模型进行贝叶斯学习在计算上具有挑战性，因为它需要近似高维后验分布。在这项工作中，我们 (i) 引入了后验，这是一个易于扩展的 PyTorch 库，其中包含通用实现，使贝叶斯学习可以访问并扩展到大数据和参数机制；(ii) 提出了一种在后验中实现的随机梯度马尔可夫链蒙特卡罗的缓和框架，可以无缝过渡到优化，并揭示了对深度集成的微小修改，以确保它们对于贝叶斯后验是渐近无偏的，(iii) 通过实验展示和比较贝叶斯近似的效用，包括对冷后验效应的研究和与大型语言模型的应用。]]></description>
      <guid>https://arxiv.org/abs/2406.00104</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>ADEP：一种基于判别器增强型编码器-解码器架构的新方法，用于准确预测多重用药的不良反应</title>
      <link>https://arxiv.org/abs/2406.00118</link>
      <description><![CDATA[arXiv:2406.00118v1 公告类型：新
摘要：动机：未预料到的药物相互作用 (DDI) 对多重用药构成重大风险，强调了对预测方法的需求。计算技术的最新进展旨在应对这一挑战。
方法：我们引入了 ADEP，这是一种集成鉴别器和编码器-解码器模型的新方法，用于解决数据稀疏性并增强特征提取。ADEP 采用三部分模型，包括多种分类方法，来预测多重用药的不良反应。
结果：对基准数据集的评估表明，ADEP 优于 GGI-DDI、SSF-DDI、LSFC、DPSP、GNN-DDI、MSTE、MDF-SA-DDI、NNPS、DDIMDL、随机森林、K-最近邻、逻辑回归和决策树等知名方法。关键指标包括准确度、AUROC、AUPRC、F 分数、召回率、精确度、假阴性和假阳性。ADEP 可以更准确地预测多重用药的不良反应。使用真实数据进行的案例研究说明了 ADEP 在识别潜在 DDI 和预防不良反应方面的实际应用。
结论：ADEP 显著提高了多重用药不良反应的预测能力，提高了准确性和可靠性。其创新架构增强了从稀疏医疗数据中提取特征的能力，提高了用药安全性和患者治疗效果。
可用性：源代码和数据集可在 https://github.com/m0hssn/ADEP 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.00118</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>一种具有分位数交叉预防功能的高效多分位数回归网络</title>
      <link>https://arxiv.org/abs/2406.00080</link>
      <description><![CDATA[arXiv:2406.00080v1 公告类型：新
摘要：本文介绍了排序复合分位数回归神经网络 (SCQRNN)，这是一种先进的分位数回归模型，旨在防止分位数交叉并提高计算效率。SCQRNN 在训练中集成了临时排序，可确保分位数不相交，从而提高模型的可靠性和可解释性。我们证明 SCQRNN 不仅可以防止分位数交叉并降低计算复杂度，而且比传统模型实现了更快的收敛速度。这一进步满足了高性能计算对可持续、准确计算的要求。在有机计算中，SCQRNN 增强了具有预测不确定性的自我意识系统，丰富了金融、气象、气候科学和工程领域的应用。]]></description>
      <guid>https://arxiv.org/abs/2406.00080</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>从结构化到非结构化：计算机视觉和图形模型在解决基于网格的偏微分方程中的比较分析</title>
      <link>https://arxiv.org/abs/2406.00081</link>
      <description><![CDATA[arXiv:2406.00081v1 公告类型：新
摘要：本文研究了计算机视觉和基于图形的模型在高性能计算环境中解决基于网格的偏微分方程的应用。该研究重点关注结构化、分级结构化和非结构化网格，比较了三个数据集中三个基于计算机视觉的模型与三个基于图形的模型的性能和计算效率。该研究旨在确定最适合不同网格拓扑的模型，特别强调对分级网格的探索，这是一个研究较少的领域。结果表明，在三个网格拓扑中的两个（结构化和分级）中，基于计算机视觉的模型（尤其是 U-Net）在预测性能和效率方面优于图形模型。该研究还揭示了基于计算机视觉的模型在处理非结构化网格方面的意外有效性，这表明数据驱动的偏微分方程学习方法可能会发生转变。文章强调深度学习是一种可行且具有潜在可持续性的增强传统高性能计算方法的方法，提倡根据网格的地形进行明智的模型选择。]]></description>
      <guid>https://arxiv.org/abs/2406.00081</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>隐私保护机器学习稳定性技术新综述</title>
      <link>https://arxiv.org/abs/2406.00073</link>
      <description><![CDATA[arXiv:2406.00073v1 公告类型：新
摘要：机器学习模型的规模和受欢迎程度最近显著增加。然而，这种增长引发了人们对数据集隐私的担忧。为了防止数据泄露，各种隐私框架都保证机器学习模型的输出不会损害其训练数据。然而，这种私有化是有代价的，因为它会在训练过程中添加随机噪声，从而降低模型性能。通过使模型更能抵抗输入的微小变化，从而更加稳定，可以减少必要的噪声量，同时仍能保护隐私。本文研究了各种增强稳定性的技术，从而最大限度地减少机器学习中私有化的负面影响。]]></description>
      <guid>https://arxiv.org/abs/2406.00073</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>加法的任意长度推广</title>
      <link>https://arxiv.org/abs/2406.00075</link>
      <description><![CDATA[arXiv:2406.00075v1 公告类型：新
摘要：本文介绍了一种新颖的训练方法，该方法使小型 Transformer 模型能够将两位数的加法推广到位数未知的数字。所提出的方法采用自回归生成技术，从右到左进行处理，模仿常见的手动加法大数方法。据我所知，这种方法以前在文献中没有被探索过。所有结果都是可重现的，相应的 R 代码可在以下位置获得：\url{https://github.com/AGPatriota/ALGA-R/}。]]></description>
      <guid>https://arxiv.org/abs/2406.00075</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>决策曼巴：通过混合选择序列建模进行强化学习</title>
      <link>https://arxiv.org/abs/2406.00079</link>
      <description><![CDATA[arXiv:2406.00079v1 公告类型：新
摘要：最近的研究表明，Transformer 模型在强化学习 (RL) 中具有显著的优势，其中决策问题被表述为顺序生成。基于 Transformer 的代理可以通过提供任务上下文（例如多条轨迹）在在线环境中自我改进，这称为上下文 RL。然而，由于 Transformer 中注意力的二次计算复杂性，当前的上下文 RL 方法随着任务范围的增加而遭受巨大的计算成本。相比之下，Mamba 模型以其高效的处理长期依赖关系的能力而闻名，这为上下文 RL 提供了解决需要长期记忆的任务的机会。为此，我们首先通过替换决策 Transformer (DT) 的主干来实现决策 Mamba (DM)。然后，我们提出了一种决策 Mamba-Hybrid (DM-H)，它兼具 Transformer 和 Mamba 在高质量预测和长期记忆方面的优点。具体来说，DM-H 首先通过 Mamba 模型从长期记忆中生成高价值子目标。然后，我们使用子目标来提示 Transformer，建立高质量的预测。实验结果表明，DM-H 在长期和短期任务中达到了最佳水平，例如 D4RL、Grid World 和 Tmaze 基准。在效率方面，DM-H 在长期任务中的在线测试比基于 Transformer 的基线快 28$\times$ 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.00079</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>STAT：经过训练后 Transformer 体积缩小</title>
      <link>https://arxiv.org/abs/2406.00061</link>
      <description><![CDATA[arXiv:2406.00061v1 公告类型：新
摘要：我们提出 STAT：一种无需任何微调即可修剪 Transformer 模型的简单算法。STAT 从网络中消除了注意力头和神经元，同时通过计算对下一层的权重的校正来保持准确性。网络中的每个层块都使用一系列保留网络结构的原则性矩阵分解进行压缩。我们的整个算法需要几分钟才能压缩 BERT，使用单个 GPU 压缩具有 7B 参数的模型只需不到三个小时。仅使用数百个数据示例，STAT 即可保留网络的输出并改进现有的无梯度修剪方法。它甚至可以与包括大量微调的方法相媲美。我们使用 GLUE、Squad、WikiText2 等基准在编码器和解码器架构（包括 BERT、DistilBERT 和 Llama-2）上演示了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.00061</guid>
      <pubDate>Tue, 04 Jun 2024 06:19:52 GMT</pubDate>
    </item>
    </channel>
</rss>