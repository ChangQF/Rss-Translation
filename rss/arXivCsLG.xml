<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.lg arxiv.org上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.lg arxiv.org e-print档案中的更新。</description>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过API呼叫序列分析和概念漂移处理，深度学习驱动的恶意软件分类</title>
      <link>https://arxiv.org/abs/2502.08679</link>
      <description><![CDATA[ARXIV：2502.08679V1公告类型：新 
摘要：动态环境中的恶意软件分类提出了概念漂移引起的重大挑战，其中恶意软件数据的统计特性会随着时间的流逝而发展，从而使检测工作变得复杂。为了解决这个问题，我们提出了一个通过遗传算法增强的深度学习框架，以提高恶意软件分类的准确性和适应性。我们的方法在遗传算法中结合了突变操作和健身评分评估，以连续完善深度学习模型，从而确保鲁棒性防止不断发展的恶意软件威胁。实验结果表明，这种混合方法显着提高了分类性能和适应性，表现优于传统静态模型。我们提出的方法为实时恶意软件分类提供了一种有希望的解决方案，以不断变化的网络安全景观。]]></description>
      <guid>https://arxiv.org/abs/2502.08679</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的数学推理：评估广泛数值范围的逻辑和算术错误</title>
      <link>https://arxiv.org/abs/2502.08680</link>
      <description><![CDATA[ARXIV：2502.08680V1公告类型：新 
摘要：通常使用具有有限数值范围的基准评估大语言模型（LLMS）中的数学推理，无法反映出各种规模的现实世界问题。此外，大多数现有的评估方法仅将模型输出与地面真实答案进行比较，从而掩盖了对推理过程的见解。为了解决这些局限性，我们引入了GSM范围，这是一种来自GSM8K的数据集生成器，该数据集生成器有系统地将数值在数学问题中占据，以评估跨不同数值量表的模型鲁棒性。此外，我们提出了一种新颖的评分方法，该方法可以区分逻辑错误和非逻辑错误，从而对超出计算精度的推理过程进行了更精确的评估。我们使用各种模型的实验表明，逻辑错误率上升到14个百分点的显着提高 - 数值复杂性上升，表明与分布外数值的推理一般弱点。此外，尽管模型在独立算术任务上表现出很高的精度，但当计算嵌入单词问题中时，它们的性能会大大恶化。这些发现提供了对LLMS的数学推理能力的全面评估，并为未来的研究方向提供了改善语言模型中数值泛化的指导。]]></description>
      <guid>https://arxiv.org/abs/2502.08680</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于预训练的嵌入在二进制代码分析中的作用</title>
      <link>https://arxiv.org/abs/2502.08682</link>
      <description><![CDATA[ARXIV：2502.08682V1公告类型：新 
摘要：深度学习在二进制代码分析中取得了显着进步。特别是，训练的组装代码嵌入已成为解决分析任务的金标准，例如测量代码相似性或识别功能。这些嵌入能够从未标记的代码中学习向量表示。但是，与自然语言处理相反，在二进制代码分析中，许多任务的标签信息并不稀缺。例如，可以从编译器提供的调试信息中轻松地得出有关功能边界，优化级别和参数类型的标记培训数据。因此，嵌入的主要动机不会直接转移到二进制代码分析中。
  在本文中，我们从批判性的角度探讨了预训练的嵌入的作用。为此，我们使用Debian分布中的120万个功能的语料库系统地评估了在五个下游任务上的汇编代码的最新嵌入。我们观察到，当有足够的标记数据可用时，几个嵌入方式类似，并且在先前工作中报道的差异几乎不明显。令人惊讶的是，我们发现没有预训练的端到端学习平均表现最佳，这使人们质疑对专业嵌入的需求。通过改变标记数据的数量，我们最终得出了嵌入提供优势以及何时可用于二进制代码分析的端到端学习的准则。]]></description>
      <guid>https://arxiv.org/abs/2502.08682</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用尺寸降低和神经ODE的参数性和依赖性部分微分方程的深度学习方法</title>
      <link>https://arxiv.org/abs/2502.08683</link>
      <description><![CDATA[arxiv：2502.08683v1公告类型：新 
摘要：部分微分方程（PDE）是科学和工程的核心。由于解决它们的计算昂贵，因此已经通过传统和最近越来越深的学习（DL）技术付出了很多努力来近似其解决方案操作员。但是，在此类DL模型中，能够计算（连续）时间和参数依赖性的最终方法论仍然缺乏。在本文中，我们建议使用与经典数值求解器的类比提出一种自回归和数据驱动的方法，以进行时间依赖性，参数和（通常）非线性PDE。我们介绍如何降低维度（DR）与神经普通微分方程（节点）的结合，以学习任意PDES的解决方案操作员。我们工作的想法是，可以将高保真性（即高维）PDE解决方案空间映射到一个降低的（低维）空间中，后来表现出受（潜在）常见微分方程控制的动力学（颂）。在减少空间中解决此（更容易的）颂歌允许避免在高维解空间中求解PDE，从而减轻了计算负担以进行重复计算以进行重复计算，例如不确定性定量或设计优化目的。这项工作的主要结果是利用DR的重要性，而不是最近建造大型和复杂体系结构的趋势：我们表明，通过利用DR，我们不仅可以提供更准确的预测，而且可以比较更轻松，更快的DL模型。到现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.08683</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>工作店计划的自我评估</title>
      <link>https://arxiv.org/abs/2502.08684</link>
      <description><![CDATA[ARXIV：2502.08684V1公告类型：新 
摘要：组合优化问题，例如调度和路线规划，在各个行业至关重要，但由于其NP坚硬的性质，在计算上很棘手。神经组合优化方法利用机器学习来应对这些挑战，但通常取决于顺序的决策，这很容易积累，因为在整个过程中，小错误会传播。受大语言模型中的自我评估技术的启发，我们提出了一个新颖的框架，该框架生成和评估任务的子集，超越了传统的逐步方法。我们的方法应用于工作店调度问题，将异质图神经网络与变压器集成在一起，以构建策略模型和自我评估功能。对具有挑战性的，众所周知的基准的实验验证证明了我们方法的有效性，超过了最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.08684</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越模型！可解释的数据评估和指标适应</title>
      <link>https://arxiv.org/abs/2502.08685</link>
      <description><![CDATA[ARXIV：2502.08685V1公告类型：新 
摘要：用户行为记录是推荐系统的基础。虽然行为数据表现出易于获取的易用性，但质量通常会遭受不同的质量。当前方法采用数据评估来从低质量数据中辨别出高质量数据。但是，他们倾向于采用黑盒设计，缺乏透明度和解释性。此外，它们通常针对特定的评估指标量身定制，从而导致各种任务的一般性有限。为了克服这些问题，我们提出了一个可解释的通用框架DVR，可以提高根据模型架构和评估指标的任何要求量身定制的数据利用率的效率。对于可解释的数据估值，提出了数据估价符，以通过从游戏理论的角度计算其Shapley价值来评估数据质量，从而确保稳健的数学属性和可靠性。为了适应各种评估指标，包括可区分和非差异化指标，根据强化学习，设计了一个度量适配器，在该学习中，指标被视为指导模型优化的强化奖励。在各种基准上进行的广泛实验证明，我们的框架可以提高有关各种指标的当前建议算法的性能，包括排名准确性，多样性和公平性。具体而言，就代表性的NDCG指标而言，我们的框架比现有方法的改善最高为34.7％。该代码可在https://github.com/renqii/dvr上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.08685</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用深型自动编码器进行脑电图检测和校正</title>
      <link>https://arxiv.org/abs/2502.08686</link>
      <description><![CDATA[ARXIV：2502.08686V1公告类型：新 
摘要：EEG信号在健康和病理状况下传达了有关大脑活动的重要信息。但是，它们本质上是嘈杂的，这对准确的分析和解释构成了重大挑战。传统的脑电图删除方法虽然有效，但通常需要广泛的专家干预。这项研究提出了LSTEEG，这是一种基于LSTM的新型自动编码器，旨在检测和校正EEG信号中的伪影。利用深度学习，尤其是LSTM层，LSTEEG捕获了顺序EEG数据中的非线性依赖性。与其他最先进的卷积自动编码器相比，LSTEEG在伪影检测和校正任务中表现出卓越的性能。我们的方法可以增强自动编码器潜在空间的解释性和效用，从而在脑电图中的应用中删除数据驱动的自动伪像在下游任务中。这项研究促进了高效，准确的多渠道脑电图预处理的领域，并促进了自动脑电图分析管道对大脑健康应用的实施和使用。]]></description>
      <guid>https://arxiv.org/abs/2502.08686</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推进机器故障诊断：卷积神经网络的详细检查</title>
      <link>https://arxiv.org/abs/2502.08689</link>
      <description><![CDATA[ARXIV：2502.08689V1公告类型：新 
摘要：机械的复杂性日益增长以及对操作效率和安全性的不断增长促进了先进的故障诊断技术的发展。其中，卷积神经网络（CNN）已成为一种强大的工具，具有强大而准确的故障检测和分类功能。这项全面的评论深入研究了CNN在机器故障诊断中的应用，涵盖其理论基础，建筑变化和实际实现。在该域中分析了CNN的优势和局限性，讨论了它们在处理各种故障类型，数据复杂性和操作环境中的有效性。此外，我们探讨了基于CNN的故障诊断的不断发展的景观，研究了数据增强，转移学习和混合体系结构的最新进展。最后，我们强调了未来的研究方向和潜在的挑战，以进一步增强CNN在可靠和主动的机器故障诊断中的应用。]]></description>
      <guid>https://arxiv.org/abs/2502.08689</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SKRR：跳过并重复使用文本编码器，用于内存有效文本对图像生成</title>
      <link>https://arxiv.org/abs/2502.08690</link>
      <description><![CDATA[ARXIV：2502.08690V1公告类型：新 
摘要：文本到图像（T2I）扩散模型中的大规模文本编码在从文本提示中生成高质量的图像时表现出了出色的性能。与依赖多个迭代步骤的DeNORING模块不同，文本编码器仅需要单个正向通行证来产生文本嵌入。但是，尽管对总推断时间和浮点操作（FLOPS）的贡献很小，但文本编码的需求明显更高的内存使用情况，最多是降级模块的八倍。为了解决此效率低下，我们提出了跳过和重复使用层（SKRR），这是一种简单而有效的修剪策略，专为T2I扩散模型中的文本编码设计而设计。 SKRR通过针对T2I任务量身定制的方式选择性跳过或重复某些层来利用变压器块中固有的冗余性，从而在不损害性能的情况下减少内存消耗。广泛的实验表明，即使在高稀疏度下，SKRR也保持与原始模型相当的图像质量，表现优于现有的块状修剪方法。此外，SKRR可实现最新的记忆效率，同时在多个评估指标（包括FID，剪辑，DreamsIM和Geneval分数）中保持性能。]]></description>
      <guid>https://arxiv.org/abs/2502.08690</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的基于FPGA的Edge IoT设备的拆分学习LSTM模型</title>
      <link>https://arxiv.org/abs/2502.08692</link>
      <description><![CDATA[ARXIV：2502.08692V1公告类型：新 
摘要：拆分学习（SL）最近作为用于分布式机器学习（ML）的有效范式（适用于物联网（IoT） - 云系统）。但是，在资源受限的边缘物联网平台上部署SL在平衡模型性能与处理，内存和能源资源方面构成了重大挑战。在这项工作中，我们提出了一项实用研究，该研究对基于现实的现场可编程门阵列（FPGA）的边缘物联网平台部署SL框架。我们解决了应用于基于复发神经网络（RNN）的时间序列处理模型的SL框架。在河水质量监测和使用现实世界数据的背景下，我们在给定的边缘IoT FPGA平台上以不同的SL配置进行训练，优化和部署长期记忆（LSTM）模型。我们的结果表明，将设计选择与特定的应用程序要求保持一致，无论是最大化速度，最大化功率还是对资源约束进行优化。]]></description>
      <guid>https://arxiv.org/abs/2502.08692</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可扩展的离散扩散采样器：组合优化和统计物理</title>
      <link>https://arxiv.org/abs/2502.08696</link>
      <description><![CDATA[ARXIV：2502.08696V1公告类型：新 
摘要：学会从复杂的非平均分布中进行采样，而不是在统计物理学，变异推断和组合优化中应用的有前途的研究方向出现的离散域。最近的工作证明了在该域中扩散模型的潜力。但是，现有方法在内存缩放中面临局限性，因此可以通过整个生成过程进行反向传播，因此可达到的扩散步骤的数量。为了克服这些局限性，我们引入了两种新型的培训方法，用于离散扩散采样器，一种基于策略梯度定理，另一个基于一个利用自称的神经重要性采样（SN-nis）。这些方法产生了记忆有效的训练并实现最新的训练，从而实现了无监督的组合优化。许多科学应用还需要无偏抽样的能力。我们介绍了SN-NIS和神经马尔可夫链蒙特卡洛的适应性，这是首次将离散扩散模型应用于此问题。我们验证了关于ISING模型基准测试的方法，并发现它们表现优于流行的自动回归方法。我们的工作开辟了新的途径，用于将扩散模型应用于迄今仅限于精确可能模型的离散域中的广泛科学应用。]]></description>
      <guid>https://arxiv.org/abs/2502.08696</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用内部交易数据对股票价格预测的机器学习算法的比较研究</title>
      <link>https://arxiv.org/abs/2502.08728</link>
      <description><![CDATA[ARXIV：2502.08728V1公告类型：新 
摘要：研究论文通过经验研究了几种机器学习算法，以根据内幕交易信息来预测股票价格。内幕交易提供了有关市场情绪的特殊见解，指出了即将发生的股票价格变化。这项研究研究了使用特斯拉股票交易数据集，研究了决策树，随机森林，带有不同内核的支持向量机（SVM）等算法的有效性。该研究研究了2020年4月至2023年3月的过去数据，重点是这些算法如何确定趋势和预测股票价格波动。本文使用递归功能消除（RFE）和特征重要性分析来优化特征集，从而提高预测准确性。虽然它需要比其他模型要大得多的处理时间，但具有径向基函数（RBF）内核的SVM显示出最佳准确性。本文强调了机器学习模型中准确性和效率之间的权衡，并提出了汇总多个数据源以提高预测性能的可能性。本文的结果旨在帮助财务分析师和投资者选择强大的算法来优化投资策略。]]></description>
      <guid>https://arxiv.org/abs/2502.08728</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稀疏变分高斯过程的新界限</title>
      <link>https://arxiv.org/abs/2502.08730</link>
      <description><![CDATA[ARXIV：2502.08730V1公告类型：新 
摘要：稀疏变分高斯过程（GPS）构造了与GP模型的可拖动后近似值。这些方法的核心是假设训练函数的真实后验分布值$ {\ bf f} $和诱导变量$ {\ bf u} $近似于与条件GP先前$ p（ {\ bf f} |。虽然此假设被认为是基本的，但我们表明，对于模型培训，我们可以通过使用更通用的变分发行$ q（{\ bf f} | {\ bf u}）$放松它，该$取决于$ n $ extra参数，其中$ n $是培训示例的数量。在GP回归中，我们可以分析优化在额外参数上的下限证据，并表达比以前的界限更紧密的易变折叠结合。新的界限也适合随机优化，其实现需要对现有的稀疏GP代码进行微小修改。此外，我们还描述了非高斯可能性的扩展。在几个数据集上，我们证明我们的方法可以在学习超帕帕照明器时减少偏差，并可以提高预测性能。]]></description>
      <guid>https://arxiv.org/abs/2502.08730</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线域间高斯流程的经常记忆</title>
      <link>https://arxiv.org/abs/2502.08736</link>
      <description><![CDATA[ARXIV：2502.08736V1公告类型：新 
摘要：我们提出了一个新颖的在线高斯流程（GP）模型，该模型能够在在线回归环境中捕获连续数据中的长期记忆。我们的模型，在线河马稀疏变异高斯过程回归（OHSGPR），利用了河马（高阶多项式投影操作员）框架，该框架由于其远程存储器建模功能而在RNN域中普及。我们将河马时间变化的正交投影解释为具有时间依赖性正交多项式函数的诱导变量，这允许SGPR诱导点记住过程历史记录。我们表明，HIPPO框架自然符合域间GP框架，并证明了内核矩阵也可以基于河马的ODE演变以复发形式在线更新。我们在时间序列回归任务上评估我们的方法，表明它在预测性能和计算效率方面表现优于现有的在线GP方法]]></description>
      <guid>https://arxiv.org/abs/2502.08736</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过小型线性卷积神经网络学习不连续的Galerkin解决方案解决椭圆问题</title>
      <link>https://arxiv.org/abs/2502.08783</link>
      <description><![CDATA[ARXIV：2502.08783V1公告类型：新 
摘要：近年来，人们对使用深度学习和神经网络解决科学问题的兴趣越来越大，尤其是在解决部分微分方程（PDE）方面。但是，许多基于神经网络的方法，例如物理信息的神经网络，都取决于自动分化和搭配点的采样，这可能导致与传统的数值方法相比缺乏可解释性和较低的准确性。为了解决这个问题，我们提出了两种使用小型线性卷积神经网络学习不连续的Galerkin解决方案的方法。我们的第一种方法是监督的，并取决于标记的数据，而我们的第二种方法则是无监督的，并且不依赖任何培训数据。在这两种情况下，我们的方法都比基于数字的神经网络使用的参数少得多，同时也证明了与椭圆问题的真实和DG解决方案相当的精度。]]></description>
      <guid>https://arxiv.org/abs/2502.08783</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>