<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 07 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 支持的合成数据生成增强表格表示</title>
      <link>https://arxiv.org/abs/2411.03356</link>
      <description><![CDATA[arXiv:2411.03356v1 公告类型：新
摘要：在数据驱动决策的时代，准确的表格级表示和高效的表格推荐系统对于改进表格管理、发现和分析变得越来越重要。然而，现有的表格数据表示方法往往面临局限性，主要是因为它们专注于单元格级任务，并且缺乏高质量的训练数据。为了应对这些挑战，我们首先在数据驱动型企业内的数据转换活动的背景下制定表相似性的明确定义。这个定义是合成数据生成的基础，合成数据生成需要一个定义明确的数据生成过程。在此基础上，我们提出了一种新颖的合成数据生成管道，利用大型语言模型 (LLM) 的代码生成和数据操作功能来创建针对表级表示学习量身定制的大规模合成数据集。通过对表推荐任务的手动验证和性能比较，我们证明了我们的管道生成的合成数据符合我们提出的表相似性定义，并显着增强了表格表示，从而提高了推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2411.03356</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SPINEX_ 符号回归：基于相似性的符号回归与可解释邻居探索</title>
      <link>https://arxiv.org/abs/2411.03358</link>
      <description><![CDATA[arXiv:2411.03358v1 公告类型：新
摘要：本文介绍了一种基于 SPINEX（基于相似性的可解释邻居探索预测）系列的新型符号回归算法。这种新算法（SPINEX_SymbolicRegression）采用基于相似性的方法来识别满足准确性和结构相似性指标的高性能表达式。我们进行了广泛的基准测试，将 SPINEX_SymbolicRegression 与来自国际问题集的 180 多个数学基准测试函数进行比较，这些问题集涵盖随机生成的表达式和基于真实物理现象的表达式。然后，我们评估了所提算法在准确性、存在运算符和变量方面的表达式相似性（与实际表达式相比）、种群大小和收敛时的代数方面的性能。结果表明，SPINEX_SymbolicRegression 始终表现良好，在某些情况下可以胜过领先的算法。此外，通过深入的实验凸显了算法的可解释能力。]]></description>
      <guid>https://arxiv.org/abs/2411.03358</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用扩散卷积门控循环单元模型预测行人体积</title>
      <link>https://arxiv.org/abs/2411.03360</link>
      <description><![CDATA[arXiv:2411.03360v1 公告类型：新
摘要：有效的行人流量分析和预测模型对于确保行人和其他道路使用者的安全非常重要。这些工具在优化基础设施设计和几何形状以及支持互联社区的经济效用方面也发挥着关键作用。全市自动行人计数系统的实施为研究人员提供了宝贵的数据，使深度学习应用程序的开发和培训成为可能，从而可以更好地了解交通和人群流量。利用墨尔本市行人计数系统提供的真实数据，本研究提出了一种行人流量预测模型，作为具有动态时间扭曲的扩散卷积门控循环单元 (DCGRU) 的扩展，称为 DCGRU-DTW。该模型通过扩散过程捕获行人流的空间依赖性，并通过门控循环单元 (GRU) 捕获时间依赖性。通过大量的数值实验，我们证明所提出的模型在多个模型精度指标上优于经典向量自回归模型和原始 DCGRU。]]></description>
      <guid>https://arxiv.org/abs/2411.03360</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>能源价格建模：四代预测方法的比较评估</title>
      <link>https://arxiv.org/abs/2411.03372</link>
      <description><![CDATA[arXiv:2411.03372v1 公告类型：新
摘要：能源是现代经济体系的关键驱动力。准确的能源价格预测在支持各个层面的决策方面发挥着重要作用，从单个商业组织的运营采购决策到政策制定。大量文献研究了能源价格预测，研究了提高准确性和为这些关键决策提供信息的各种方法。鉴于预测技术的不断发展，文献缺乏对这些方法进行系统对比的彻底的实证比较。
本文深入回顾了预测建模框架的演变，从成熟的计量经济模型到机器学习方法、早期的序列学习器（如 LSTM）以及最近使用变压器网络进行的深度学习的进展，这些都代表了预测领域的前沿。我们对相关文献进行了详细的回顾，并将预测方法分为四个模型系列。我们还探讨了预训练和迁移学习等新兴概念，这些概念已经改变了非结构化数据的分析，并为时间序列预测带来了重大希望。我们通过对这四个模型系列进行全面的实证分析来解决文献中的空白，使用来自欧盟能源市场的数据，我们进行了一项大规模的实证研究，对比了不同方法的预测准确性，特别关注时间序列变压器的替代命题。]]></description>
      <guid>https://arxiv.org/abs/2411.03372</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用模拟内存计算的核近似</title>
      <link>https://arxiv.org/abs/2411.03375</link>
      <description><![CDATA[arXiv:2411.03375v1 公告类型：新
摘要：核函数是几种机器学习算法的重要组成部分，但通常会产生大量的内存和计算成本。我们介绍了一种适用于混合信号模拟内存计算 (AIMC) 架构的机器学习算法中的核近似方法。模拟内存核近似通过直接在内存中执行近似核方法中的大多数操作来解决传统基于核的方法的性能瓶颈。IBM HERMES 项目芯片是一种最先进的基于相变存储器的 AIMC 芯片，用于核近似的硬件演示。实验结果表明，我们的方法保持了高精度，在基于核的岭分类基准上下降不到 1%，在 Transformer 神经网络中核化注意力的 Long Range Arena 基准上的精度在 1% 以内。与传统的数字加速器相比，我们的方法估计可以提供更高的能源效率和更低的功耗。这些发现凸显了异构 AIMC 架构在提高机器学习应用的效率和可扩展性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.03375</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化治疗效果的随机不确定性：一种新颖的正交学习器</title>
      <link>https://arxiv.org/abs/2411.03387</link>
      <description><![CDATA[arXiv:2411.03387v1 公告类型：新
摘要：从观察数据中估计因果量对于理解医疗治疗的安全性和有效性至关重要。然而，为了做出可靠的推断，医疗从业者不仅需要估计平均因果量，例如条件平均治疗效果，还需要了解治疗效果作为随机变量的随机性。这种随机性被称为随机不确定性，对于理解治疗获益的概率或治疗效果的分位数是必要的。然而，治疗效果的随机不确定性在因果机器学习社区中却很少受到关注。为了填补这一空白，我们的目标是在协变量条件水平上量化治疗效果的随机不确定性，即治疗效果的条件分布 (CDTE)。与平均因果量不同，如果没有强有力的附加假设，CDTE 是无法点识别的。作为补救措施，我们采用部分识别来获得 CDTE 的明确界限，从而量化治疗效果的随机不确定性。然后，我们为 CDTE 的界限开发了一种新颖的正交学习器，我们称之为 AU-learner。我们进一步表明，我们的 AU-learner 具有几个优势，因为它满足 Neyman 正交性并且具有双重鲁棒性。最后，我们提出了一个完全参数化的 AU-learner 深度学习实例。]]></description>
      <guid>https://arxiv.org/abs/2411.03387</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用线性权重分类解决木马检测竞赛</title>
      <link>https://arxiv.org/abs/2411.03445</link>
      <description><![CDATA[arXiv:2411.03445v1 公告类型：新
摘要：神经网络可以隐藏恶意的特洛伊木马后门，这些后门允许触发器秘密改变模型行为。检测这些后门的迹象，特别是在无法访问任何触发数据的情况下，是正在进行的研究和公开挑战的主题。在问题的一个常见表述中，我们给出了一组干净和中毒的模型，需要预测给定的测试模型是干净的还是中毒的。在本文中，我们介绍了一种在许多现有数据集和领域中表现出色的检测器。它是通过在执行几个不同的预处理步骤（包括特征选择和标准化、参考模型权重减法和检测前的模型对齐）后，对大量模型权重进行二元分类器训练而获得的。我们在一组不同的特洛伊木马检测基准和领域上评估该算法，并检查该方法最有效和最无效的情况。]]></description>
      <guid>https://arxiv.org/abs/2411.03445</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于监督学习的变分量子电路的傅里叶分析</title>
      <link>https://arxiv.org/abs/2411.03450</link>
      <description><![CDATA[arXiv:2411.03450v1 公告类型：新
摘要：VQC 可以通过傅里叶分析的视角来理解。众所周知，任何电路架构所表示的函数空间都可以通过截断傅里叶和来描述。我们表明，该截断傅里叶和可用的频谱并非完全由电路的编码门决定，因为电路的变分部分可以将某些系数限制为零，从而有效地将该频率从频谱中移除。据我们所知，我们首次将傅里叶系数对变分参数的函数依赖性描述为三角多项式。这使我们能够提供一种算法，该算法可以计算任何给定电路的精确频谱和相应的傅里叶系数。最后，我们证明，通过将数据集的傅里叶变换与可用频谱进行比较，可以预测给定选择列表中的哪个 \gls{VQC} 能够最好地拟合数据。]]></description>
      <guid>https://arxiv.org/abs/2411.03450</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于癌症治疗的深度生成分子设计模型的通路引导优化</title>
      <link>https://arxiv.org/abs/2411.03460</link>
      <description><![CDATA[arXiv:2411.03460v1 公告类型：新 
摘要：数据驱动的药物设计问题可以表述为在巨大的高维和结构化分子空间上对潜在昂贵的黑盒目标函数进行优化的任务。连接树变分自动编码器 (JTVAE) 已被证明是一种有效的生成模型，可用于建议具有改进特性的合法新型类药物小分子。虽然生成分子设计 (GMD) 方案的性能在很大程度上取决于初始训练数据，但可以通过优化潜在空间来提高其采样效率，以建议具有增强特性的更好分子。在这项工作中，我们提出了如何使用机械模型（例如由微分方程描述的途径模型）对 JTVAE 和其他类似的 GMD 模型进行有效的潜在空间优化 (LSO)。为了证明我们提出的方法的潜力，我们展示了如何结合药效动力学模型，通过预测类药物小分子如何调节癌症途径来评估其治疗效果，以实现 GMD 数据驱动模型的有效 LSO。]]></description>
      <guid>https://arxiv.org/abs/2411.03460</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>激光：注意力指数变换</title>
      <link>https://arxiv.org/abs/2411.03493</link>
      <description><![CDATA[arXiv:2411.03493v1 公告类型：新 
摘要：Transformers 对几个序列相关任务产生了巨大影响，这主要是因为它们能够通过基于 softmax 的点积注意力从序列的任何部分进行检索。这种机制在 Transformer 的性能中起着至关重要的作用。我们分析了注意力机制中通过 softmax 操作反向传播的梯度，并观察到这些梯度通常很小。这种较差的梯度信号反向传播可能导致在注意力操作之前对参数的学习效率低下。为此，我们引入了一种称为 LASER 的新注意力机制，我们通过分析表明它可以接受更大的梯度信号。我们表明，可以通过对现有的注意力实现进行小幅修改来实现 LASER 注意力。我们对具有多达 22 亿个参数的自回归大型语言模型 (LLM) 进行了实验，结果显示下游评估中比标准注意力提高了 3.38%，平均提高了 ~1%。使用 LASER 可以在各种任务（视觉、文本和语音）中实现以下相对的泛化性能提升：Imagenet 上 Vision Transformer (ViT) 的准确率为 4.67%，Librispeech 语音转文本中 Conformer 的错误率为 2.25%，具有 22 亿个参数的 BERT 中错误预测率降低 0.93%。]]></description>
      <guid>https://arxiv.org/abs/2411.03493</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过高斯混合模型理解对比学习</title>
      <link>https://arxiv.org/abs/2411.03517</link>
      <description><![CDATA[arXiv:2411.03517v1 公告类型：新
摘要：对比学习试图从未标记的数据中学习表示；它通过一个损失函数来实现这一点，该损失函数鼓励一个点的嵌入接近其增强的嵌入，并远离随机其他点的嵌入。这个简单的想法表现得非常好，但从理论上讲，人们并没有准确地理解为什么会这样。在本文中，我们在自然环境中分析了对比学习（特别是 InfoNCE 损失）：高斯混合模型中的降维。至关重要的是，我们将数据点的增强定义为从同一底层混合成分中独立抽取的另一个数据点。我们表明，即使高斯分布不是各向同性的，vanilla InfoNCE 也能够找到最佳的低维子空间——这是 vanilla 谱技术无法做到的。我们进一步将我们的分析扩展到多模态对比学习算法（例如 CLIP）。在这种情况下，我们表明对比学习可以学习 Fisher 最优子空间的子集，从而有效地从学习到的表示中滤除所有噪音。]]></description>
      <guid>https://arxiv.org/abs/2411.03517</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PACE：起搏操作员学习复杂光子器件的精确光场模拟</title>
      <link>https://arxiv.org/abs/2411.03527</link>
      <description><![CDATA[arXiv:2411.03527v1 公告类型：新
摘要：电磁场模拟对于设计、优化和验证光子器件和电路至关重要。然而，与数值模拟相关的昂贵计算构成了重大瓶颈，阻碍了光子电路设计过程中的可扩展性和周转时间。神经算子提供了一种有前途的替代方案，但现有的 SOTA 方法 NeurOLight 难以预测现实世界复杂光子器件的高保真场，NeurOLight 中报告的最佳归一化平均绝对误差为 0.38。高度复杂的光物质相互作用（例如散射和共振）、对局部结构细节的敏感性、全域模拟的非均匀学习复杂性以及丰富的频率信息，导致现有神经 PDE 求解器失败。在这项工作中，我们通过由上述挑战驱动的新型算子设计将模拟复杂光子器件的预测保真度提高到前所未有的水平。我们提出了一种新颖的横轴分解 PACE 算子，它具有强大的长距离建模能力，可将全域复杂场模式与局部设备结构连接起来。受人类学习的启发，我们进一步将极其困难情况的模拟任务划分为两个逐渐简单的任务，第一阶段模型学习初始解决方案，由第二个模型细化。在各种复杂的光子设备基准测试中，我们证明，与最近的各种 PDE 求解器的 ML 相比，单一 PACE 模型能够将误差降低 73%，参数减少 50%。两阶段设置进一步推进了更复杂情况的高保真模拟。在运行时间方面，与使用 scipy 或高度优化的 pardiso 求解器的数值求解器相比，PACE 分别实现了 154-577 倍和 11.8-12 倍的模拟加速。我们开源了代码和数据集。]]></description>
      <guid>https://arxiv.org/abs/2411.03527</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自然界分子特性预测的两阶段预训练</title>
      <link>https://arxiv.org/abs/2411.03537</link>
      <description><![CDATA[arXiv:2411.03537v1 公告类型：新
摘要：准确的属性预测对于加速新分子的发现至关重要。尽管深度学习模型取得了显著的成功，但它们的性能往往依赖于大量标记数据，而这些数据的获取成本高昂且耗时。因此，人们越来越需要能够在有限的实验验证数据下表现良好的模型。在这项工作中，我们介绍了 MoleVers，这是一种多功能预训练模型，专为各种类型的野外分子属性预测而设计，即在实验验证的分子属性标签稀缺的情况下。MoleVers 采用两阶段预训练策略。在第一阶段，该模型通过掩蔽原子预测和动态去噪从大量未标记数据集中学习分子表示，这是一项由新分支编码器架构实现的新任务。在第二阶段，使用廉价计算方法获得的辅助标签对 MoleVers 进行进一步预训练，从而无需昂贵的实验数据即可实现监督学习。这种两阶段框架使 MoleVers 能够学习在各种下游数据集中有效推广的表示。我们在一个新基准上评估了 MoleVers，该基准包含 22 个具有各种属性的分子数据集，其中大多数数据集包含 50 个或更少的反映真实世界条件的训练标签。MoleVers 在 22 个数据集中的 20 个数据集上取得了最佳结果，并在其余两个数据集中排名第二，突显了它能够弥合数据密集型模型与实际有用的标签稀缺的现实条件之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2411.03537</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的长上下文 RAG 性能</title>
      <link>https://arxiv.org/abs/2411.03538</link>
      <description><![CDATA[arXiv:2411.03538v1 公告类型：新
摘要：检索增强生成 (RAG) 已成为通过整合外部信息来提高大型语言模型 (LLM) 准确性的关键技术。随着支持越来越长的上下文长度的 LLM 的出现，人们越来越有兴趣了解这些模型在 RAG 场景中的表现。这些新的长上下文模型可以提高 RAG 性能吗？本文对 20 种流行的开源和商业 LLM 中增加上下文长度对 RAG 性能的影响进行了全面研究。我们在三个特定领域的数据集上运行了 RAG 工作流，同时将总上下文长度从 2,000 个标记变为 128,000 个标记（如果可能的话为 200 万个标记），并报告了有关 RAG 应用中长上下文的优点和局限性的关键见解。我们的研究结果表明，虽然检索更多文档可以提高性能，但只有少数最新的 LLM 可以在 64k 以上标记的长上下文中保持一致的准确率。我们还确定了长上下文场景中的不同故障模式，并提出了未来研究的领域。]]></description>
      <guid>https://arxiv.org/abs/2411.03538</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>老鼠会理解吗？感觉皮层过度训练过程中隐藏的进展</title>
      <link>https://arxiv.org/abs/2411.03541</link>
      <description><![CDATA[arXiv:2411.03541v1 公告类型：新
摘要：当行为停止变化时，任务相关表征的学习是否会停止？受机器学习理论的最新进展以及人类专家在掌握后仍继续从实践中学习的直观观察的启发，我们假设特定于任务的表征学习可以继续，即使行为停滞不前。在对最近发表的神经数据进行新颖的重新分析后，我们发现小鼠后梨状皮质在行为达到接近上限的表现（“过度训练”）后继续进行任务训练后仍存在这种学习的证据。这种学习的标志是梨状神经群解码准确度的提高和保留泛化测试的表现的提高。我们证明皮质中的类别表征在过度训练期间继续分离，因此在过度训练开始时被错误分类的例子可以在以后突然被正确分类，尽管在此期间行为没有变化。我们假设这种隐藏但丰富的学习采取近似边际最大化的形式；我们在神经数据中验证了这一预测和其他预测，并构建和解释了一个概括这些现象的简单合成模型。最后，我们展示了这种后期特征学习模型如何解释动物学习中过度训练逆转的经验难题，其中特定于任务的表示对于特定任务的变化更具鲁棒性，因为学习到的特征可以重复使用。]]></description>
      <guid>https://arxiv.org/abs/2411.03541</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>