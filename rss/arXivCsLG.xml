<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.LG 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.LG</link>
    <description>cs.LG 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 06 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>PolarQuant：使用极坐标变换量化 KV 缓存</title>
      <link>https://arxiv.org/abs/2502.02617</link>
      <description><![CDATA[arXiv:2502.02617v1 公告类型：新
摘要：大型语言模型 (LLM) 需要大量内存来将键值 (KV) 嵌入存储在其 KV 缓存中，尤其是在处理长距离上下文时。量化这些 KV 嵌入是一种减少内存消耗的常用技术。这项工作介绍了 PolarQuant，一种采用随机预处理和极坐标变换的新型量化方法。我们的方法使用有效的递归算法将 KV 嵌入转换为极坐标，然后量化得到的角度。我们的关键见解是，经过随机预处理后，极坐标表示中的角度呈现出紧密有界且高度集中的分布，具有可分析计算的形式。这种良好的分布消除了显式归一化的需要，这是传统量化方法所需的步骤，它会带来大量内存开销，因为量化参数（例如零点和比例）必须以每个数据块的全精度存储。PolarQuant 绕过了这个归一化步骤，从而节省了大量的内存。长上下文评估表明，与最先进的方法相比，PolarQuant 将 KV 缓存压缩了 4.2 倍以上，同时获得了最佳质量分数。]]></description>
      <guid>https://arxiv.org/abs/2502.02617</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用子采样点到子空间距离进行偏差检测的样本复杂度</title>
      <link>https://arxiv.org/abs/2502.02623</link>
      <description><![CDATA[arXiv:2502.02623v1 公告类型：新
摘要：偏差估计的样本复杂度是任何偏差检测方法运行时间的下限。许多监管框架要求对所有子组进行偏差测试，子组的数量随着受保护属性的数量呈指数增长。除非希望以双指数运行时间运行偏差检测，否则应该希望对单个子组进行多项式复杂度的偏差检测。同时，参考数据可能基于调查，因此存在不平凡的不确定性。
在这里，我们将偏差检测重新表述为测度空间上的点到子空间问题，并表明对于上确界范数，可以有效地对其进行子采样。特别是，我们的概率近似正确 (PAC) 结果通过对众所周知的实例的测试得到了证实。]]></description>
      <guid>https://arxiv.org/abs/2502.02623</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分量子特征求解器中的贝叶斯参数移位规则</title>
      <link>https://arxiv.org/abs/2502.02625</link>
      <description><![CDATA[arXiv:2502.02625v1 公告类型：新
摘要：参数移位规则 (PSR) 是变分量子特征值求解器 (VQE) 中有效梯度估计的关键技术。在本文中，我们提出了它的贝叶斯变体，其中使用具有适当核的高斯过程来估计 VQE 目标的梯度。我们的贝叶斯 PSR 可以根据具有不确定性信息的任意位置的观测值提供灵活的梯度估计，并在特殊情况下简化为广义 PSR。在随机梯度下降 (SGD) 中，贝叶斯 PSR 的灵活性允许在前面的步骤中重复使用观测值，从而加速优化过程。此外，对后验不确定性的可访问性以及我们提出的梯度置信区域 (GradCoRe) 概念使我们能够在每个 SGD 步骤中最小化观察成本。我们的数值实验表明，基于贝叶斯 PSR 和 GradCoRe 的 VQE 优化显著加速了 SGD，并且优于包括顺序最小优化在内的最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.02625</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>e-SimFT：生成模型与模拟反馈的对齐，用于帕累托前沿设计探索</title>
      <link>https://arxiv.org/abs/2502.02628</link>
      <description><![CDATA[arXiv:2502.02628v1 公告类型：新
摘要：深度生成模型最近在解决复杂的工程设计问题方面取得了成功，其中模型预测的解决方案可以满足输入指定的设计要求。然而，在调整此类模型以进行有效的设计探索方面仍然存在挑战。对于许多设计问题，找到满足所有要求的解决方案是不可行的。在这种情况下，工程师更愿意获得一组符合这些要求的帕累托最优解，但生成模型的均匀采样可能无法产生有用的帕累托前沿。为了解决这一差距，我们引入了一个使用模拟微调生成模型进行帕累托前沿设计探索的新框架。首先，该框架采用为大型语言模型 (LLM) 开发的偏好对齐方法，并展示了在微调工程设计生成模型中的第一个应用。这里的重要区别是我们使用模拟器而不是人类来提供准确且可扩展的反馈。接下来，我们提出 epsilon 采样，灵感来自经典优化算法中用于生成 Pareto 前沿的 epsilon 约束方法，以使用微调模型构建高质量的 Pareto 前沿。我们的框架名为 e-SimFT，事实证明，它能生成比现有多目标对齐方法更高质量的 Pareto 前沿。]]></description>
      <guid>https://arxiv.org/abs/2502.02628</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ParetoQ：极低位 LLM 量化中的缩放定律</title>
      <link>https://arxiv.org/abs/2502.02631</link>
      <description><![CDATA[arXiv:2502.02631v1 公告类型：新
摘要：实现量化模型大小和准确度之间最佳平衡的最佳位宽一直是争论的话题。虽然有些人主张 4 位量化，但另一些人认为 1.58 位可以提供更好的结果。然而，由于缺乏针对不同位的统一框架，因此这样的结论相对脆弱。我们提出了 ParetoQ，这是第一个统一的框架，可促进 1 位、1.58 位、2 位、3 位和 4 位量化设置之间的严格比较。我们的研究结果揭示了 2 位和 3 位之间的显着学习转变：对于 3 位及以上，微调模型保持接近其原始预训练分布，而对于学习 2 位或以下网络，表示会发生巨大变化。通过优化训练方案和改进量化函数，ParetoQ 超越了所有以前针对特定位宽定制的方法。值得注意的是，我们的 ParetoQ 三元 600M 参数模型甚至在准确度上优于之前的 SoTA 三元 3B 参数模型，而参数数量仅为前者的五分之一。大量实验表明，三元、2 位和 3 位量化在大小-准确度权衡方面保持了相当的性能，并且通常优于 4 位和二进制量化。考虑到硬件限制，2 位量化在内存减少和加速方面具有巨大的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.02631</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于梯度的投影寻踪恢复不平衡聚类</title>
      <link>https://arxiv.org/abs/2502.02668</link>
      <description><![CDATA[arXiv:2502.02668v1 公告类型：新
摘要：投影追踪是一种经典的探索性技术，用于查找数据集的有趣投影。我们提出了一种使用基于梯度的技术来优化投影指数，以恢复包含不平衡簇或伯努利-拉德马赫分布的投影的方法。由于样本复杂性是投影追踪的主要限制因素，我们在植入向量设置中分析了我们算法的样本复杂性，我们可以观察到不平衡簇比平衡簇更容易恢复。此外，我们给出了适用于各种数据分布和投影指数的广义结果。我们将这些结果与低阶多项式框架中的计算下限进行比较。最后，我们使用 FashionMNIST 和人类活动识别数据集通过实验评估了我们的方法对现实世界数据的适用性，当只有少量样本可用时，我们的算法优于其他算法。]]></description>
      <guid>https://arxiv.org/abs/2502.02668</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型提炼中的教师黑客行为</title>
      <link>https://arxiv.org/abs/2502.02671</link>
      <description><![CDATA[arXiv:2502.02671v1 公告类型：新
摘要：语言模型 (LM) 的后训练越来越依赖于以下两个阶段：(i) 知识蒸馏，其中 LM 被训练来模仿更大的教师 LM，以及 (ii) 从人类反馈中强化学习 (RLHF)，其中 LM 通过优化奖励模型进行调整。在第二个 RLHF 阶段，一个众所周知的挑战是奖励黑客攻击，其中 LM 过度优化奖励模型。这种现象符合古德哈特定律，并可能导致真实目标的性能下降。在本文中，我们研究在知识蒸馏过程中是否会发生类似的现象，我们称之为教师黑客攻击。这可能是因为教师 LM 本身是真实分布的不完美近似。为了研究这一点，我们提出了一个受控的实验设置，其中包括：(i) 一个代表真实分布的 oracle 语言模型，(ii) 一个从 oracle 中提炼出来的教师语言模型，以及 (iii) 一个从教师中提炼出来的学生语言模型。我们的实验揭示了以下见解。当使用固定的离线数据集进行提炼时，会发生教师黑客攻击；此外，我们可以通过观察优化过程何时偏离多项式收敛定律来检测它。相比之下，采用在线数据生成技术可以有效地缓解教师黑客攻击。更准确地说，我们认为数据多样性是防止黑客攻击的关键因素。总的来说，我们的研究结果让我们更深入地了解了提炼在构建稳健高效的语言模型方面的优势和局限性。]]></description>
      <guid>https://arxiv.org/abs/2502.02671</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedRAX：胸部X光医学推理代理</title>
      <link>https://arxiv.org/abs/2502.02673</link>
      <description><![CDATA[arXiv:2502.02673v1 公告类型：新
摘要：胸部 X 光 (CXR) 在推动疾病管理和患者护理的关键决策方面发挥着不可或缺的作用。虽然最近的创新已经为各种 CXR 解释任务带来了专门的模型，但这些解决方案通常是孤立运行的，限制了它们在临床实践中的实际效用。我们提出了 MedRAX，这是第一个多功能 AI 代理，它将最先进的 CXR 分析工具和多模态大型语言模型无缝集成到一个统一的框架中。MedRAX 动态利用这些模型来解决复杂的医疗查询，而无需额外的培训。为了严格评估其能力，我们引入了 ChestAgentBench，这是一个全面的基准，包含 7 个不同类别的 2,500 个复杂医疗查询。我们的实验表明，与开源和专有模型相比，MedRAX 实现了最先进的性能，代表着向自动化 CXR 解释系统的实际部署迈出了重要一步。数据和代码已在 https://github.com/bowang-lab/MedRAX 上公开]]></description>
      <guid>https://arxiv.org/abs/2502.02673</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>伪物理信息神经算子：从有限数据中增强算子学习</title>
      <link>https://arxiv.org/abs/2502.02682</link>
      <description><![CDATA[arXiv:2502.02682v1 公告类型：新
摘要：神经算子在替代建模中显示出巨大的潜力。然而，训练一个表现良好的神经算子通常需要大量的数据，这在复杂的应用中可能是一个重大挑战。在这种情况下，详细的物理知识可能无法获得或难以获得，而收集大量数据的成本往往高得离谱。为了缓解这一挑战，我们提出了伪物理信息神经算子 (PPI-NO) 框架。PPI-NO 使用从简单、基本的物理原理（例如基本微分算子）中得出的偏微分方程 (PDE) 为目标系统构建替代物理系统。该替代系统与神经算子模型相结合，使用交替更新和学习过程来迭代增强模型的预测能力。虽然通过 PPI-NO 得出的物理学可能无法反映物理定律的真实情况（因此称为“伪物理学”），但这种方法显著提高了数据稀缺场景中标准操作员学习模型的准确性，这已通过对五个基准任务和一个疲劳建模应用程序的广泛评估得到证明。]]></description>
      <guid>https://arxiv.org/abs/2502.02682</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 ICESat-2 ATL03 数据进行可扩展的高分辨率极地海冰分类和干舷计算</title>
      <link>https://arxiv.org/abs/2502.02700</link>
      <description><![CDATA[arXiv:2502.02700v1 公告类型：新
摘要：美国宇航局的 ICESat-2 (IS2) 是一颗用于测量高分辨率表面海拔的地球观测卫星。IS2 的 ATL07 和 ATL10 海冰海拔和 10m-200m 段的干舷产品从原始 ATL03（地理定位光子）数据中聚合了 150 个信号光子。这些聚合产品可能会高估当地海面高度，从而低估干舷（海冰高出海面的高度）的计算。为了获得更高的海面高度和干舷信息分辨率，在这项工作中，我们使用 2m 窗口对 ATL03 数据进行重新采样。然后，我们使用深度学习方法（长短期记忆和多层感知器模型）将这些 2m 段分为厚海冰、薄冰和开阔水域。为了为我们的深度学习模型获取标记的训练数据，我们使用在空间和时间上与 IS2 轨迹重叠的分段 Sentinel-2 (S2) 多光谱影像来自动标记 IS2 数据，然后在不同冰/水类型或多云区域之间的过渡区域进行一些手动校正。我们采用并行工作流程进行这种自动标记，使用 PySpark 进行扩展，实现了 9 倍的数据加载和 16.25 倍的 map-reduce 加速。为了训练我们的模型，我们在 DGX A100 8 GPU 集群上采用基于 Horovod 的分布式深度学习工作流程，实现了 7.25 倍的加速。接下来，我们根据开阔水域段计算当地海面高度。最后，我们使用派生出的当地海平面扩展干舷计算，实现 8.54 倍的数据加载和 15.7 倍的 map-reduce 加速。与ATL07（当地海平面）和ATL10（干舷）数据产品相比，我们的结果显示出更高的分辨率和精度（96.56％）。]]></description>
      <guid>https://arxiv.org/abs/2502.02700</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果推断中实用有效的调整变量选择</title>
      <link>https://arxiv.org/abs/2502.02701</link>
      <description><![CDATA[arXiv:2502.02701v1 公告类型：新
摘要：在因果效应估计中，消除混杂因素影响的一种常用方法是调整满足后门标准的变量。然而，并不总是能够唯一地确定这些变量的集合。此外，现实世界的数据几乎总是有限的，这意味着它可能不足以进行统计估计。因此，我们提出了从候选调整变量列表中选择变量的标准，以及一种防止因果效应估计精度下降的算法。我们首先关注有向无环图 (DAG)，然后概述将此方法应用于完成的部分有向无环图 (CPDAG) 的具体步骤。我们还提出并证明了 CPDAG 中因果效应计算可能性的定理。最后，我们使用现有数据和人工数据证明了我们方法的实用性。]]></description>
      <guid>https://arxiv.org/abs/2502.02701</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对转向方法的统一理解和评估</title>
      <link>https://arxiv.org/abs/2502.02716</link>
      <description><![CDATA[arXiv:2502.02716v1 公告类型：新
摘要：通过将引导向量应用于中间激活，引导输出朝着期望的行为方向发展，同时避免重新训练，引导方法提供了一种控制大型语言模型的实用方法。尽管它们的重要性日益增加，但该领域缺乏对任务和数据集的统一理解和一致评估，阻碍了进展。本文介绍了一个用于分析和评估引导方法的统一框架，形式化了它们的核心原理并提供了关于其有效性的理论见解。通过对多项选择和开放式文本生成任务进行全面的实证评估，我们验证了这些见解，确定了影响性能的关键因素并展示了某些方法的优越性。我们的工作将理论和实践观点结合起来，为推进 LLM 中引导方法的设计、优化和部署提供了可行的指导。]]></description>
      <guid>https://arxiv.org/abs/2502.02716</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越拓扑自解释的 GNN：形式化可解释性视角</title>
      <link>https://arxiv.org/abs/2502.02719</link>
      <description><![CDATA[arXiv:2502.02719v1 公告类型：新
摘要：自解释图神经网络 (SE-GNN) 是流行的可解释设计 GNN，但其解释的属性和局限性尚不清楚。我们的第一个贡献填补了这一空白，通过形式化 SE-GNN 提取的解释（称为琐碎解释 (TE)），并将它们与既定的解释概念进行比较，即主要隐含项 (PI) 和忠实解释。我们的分析表明，对于一组受限但重要的任务，TE 与 PI 解释相匹配。然而，一般来说，它们的信息量可能不如 PI 解释，而且令人惊讶的是，它们与广泛接受的忠实概念不一致。虽然忠实和 PI 解释是有用的，但它们很难找到，我们表明它们可能非常大。受此启发，我们提出了双通道 GNN，它集成了白盒规则提取器和标准 SE-GNN，当任务有利时自适应地结合两个通道。我们的实验表明，即使是双通道 GNN 的简单实例也可以恢复简洁的规则，并且性能与广泛使用的 SE-GNN 相当甚至更好。我们的代码可以在补充材料中找到。]]></description>
      <guid>https://arxiv.org/abs/2502.02719</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Dobi-SVD：用于 LLM 压缩的可微分 SVD 和一些新观点</title>
      <link>https://arxiv.org/abs/2502.02723</link>
      <description><![CDATA[arXiv:2502.02723v1 公告类型：新
摘要：我们通过 SVD 提供了一种新的 LLM 压缩解决方案，为量化和修剪之外的 LLM 压缩开辟了新的可能性。我们指出，SVD 的最佳用途在于截断激活，而不仅仅是将激活用作优化距离。基于这一原则，我们解决了基于 SVD 的 LLM 压缩中的三个关键挑战：包括 (1) 如何确定 LLM 中每个权重矩阵的最佳激活截断位置？(2) 如何基于截断激活有效地重建权重矩阵？(3) 如何解决导致 SVD 信息丢失的固有“注入”性质？我们提出了 Dobi-SVD，它为基于 SVD 的 LLM 压缩建立了一种新的原则性方法。]]></description>
      <guid>https://arxiv.org/abs/2502.02723</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应优化联邦学习中的参数跟踪</title>
      <link>https://arxiv.org/abs/2502.02727</link>
      <description><![CDATA[arXiv:2502.02727v1 公告类型：新
摘要：在联邦学习 (FL) 中，模型训练性能受到客户端之间数据异质性的强烈影响。梯度跟踪 (GT) 最近作为一种解决方案出现，它通过在局部模型更新中引入校正项来缓解此问题。到目前为止，GT 仅在基于随机梯度下降 (SGD) 的模型训练下被考虑，而现代 FL 框架越来越多地采用自适应优化器来提高收敛性。在这项工作中，我们将 GT 框架推广到更灵活的参数跟踪 (PT) 范式，并提出了两种新的自适应优化算法，{\tt FAdamET} 和 {\tt FAdamGT}，将 PT 集成到基于 Adam 的 FL 中。我们在非凸设置下对这些算法进行了严格的收敛分析。我们的实验结果表明，在评估不同数据异质性水平的总通信成本和总计算成本时，两种提出的算法始终优于现有方法，显示了在联邦自适应优化中校正一阶信息的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.02727</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>