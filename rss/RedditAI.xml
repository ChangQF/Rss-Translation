<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit的人工智能之家（AI）</description>
    <lastBuildDate>Tue, 08 Apr 2025 09:19:56 GMT</lastBuildDate>
    <item>
      <title>微调LLM作为开发人员（无需全ML）</title>
      <link>https://www.reddit.com/r/artificial/comments/1ju8efu/finetuning_llms_as_a_developer_without_going_full/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     ai devs-您是否尝试过微调LLM，但发现了工具/文档压倒性？  我们正在为产品开发人员和工程师提供免费的网络研讨会，但可以通过AI进行构建，但无法通过ML。实际上适合开发工作流程的参数效率方法（Lora，Qlora）。   dm me或删除您的想法  - 我们正在围绕真实开发疼痛点的内容。    &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/soman_yadav     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ju8efu/finetuning_llms_as_a_developer_without_going_full/</guid>
      <pubDate>Tue, 08 Apr 2025 08:08:59 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻4/7/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1ju4rdv/oneminute_daily_ai_news_472025/</link>
      <description><![CDATA[ The (artificial intelligence) therapist can see you now.[1] Google is bringing multimodal search to AI Mode.[2] Shopify CEO Tobias Lütke: Employees Must Learn to Use AI Effectively.[3] 由氢燃料电池和AI系统提供动力 -  川崎的受狼风格的四足机器人允许骑手穿越不均匀的地形。[4]     sources;    [1]  https://www.npr.org/sections/shots-healts-health-news/2025/04/04/nx-s1-5351312/arterage-intelligence-intelligence-mental-health-health-therapy     [2]  https://blog.google/products/search/search/search/ai-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-mode-modemodal-search/ ， href =“ https://www.pymnts.com/artcover-intelligence-2/2025/shopify-ceo-tobias-tobias-lutke-employees-must-learn-learn-to-learn-to-use-ies-ai-forkectively/”&gt; https://www.pymnts.com/artcover-intelligence-2/2025/shopify-ceo-ceo-tobias-lutke-lutke-most-lutke-must-learn-to-learn-to-use-use-ai-effectivery/     [4]  href = https://hydrogen-central.com/powered-by-hydrogen-fuel-cell-and-with-ai-systems-kawasakis-wolf-inspired-four-legged-robot-lets-riders-traverse-uneven-terrain/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1ju4rdv/oneminute_daily_ai_ai_news_472025/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ju4rdv/oneminute_daily_ai_news_472025/</guid>
      <pubDate>Tue, 08 Apr 2025 04:00:42 GMT</pubDate>
    </item>
    <item>
      <title>AI是技术的祝福，我绝对不明白仇恨</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtvx1t/ai_is_a_blessing_of_technology_and_i_absolutely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  恨像血液敌人的人有什么问题？他们甚至不是创作者，不是艺术家，而是出于某种原因，他们仍然说“ AI创造了这个？它很糟糕。＆quot”  ，但是我可以创建任何一秒钟内想到的东西！我在哪里可以得到弗雷迪·克鲁格（Freddy Krueger）与印第安纳·琼斯（Indiana Jones）作战的照片？但是，繁荣，我做到了，我不必付钱给别人，等待一个星期才能拍摄一张我会看一秒钟的图片，并想到“ heh，cool”忘了它。 我以为“一个红色的罂粟花领域，背景中有一个旧磨坊必须看起来很漂亮”我马上就做到了！ 这些是独特的机会，仅仅因为您的原则而拒绝这些事情多么愚蠢。所有这些仅是关于图纸，更不用说视频，音频和文本创建了。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/maxvellgardner     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtvx1t/ai_is_a_blessing_of_technology_and_i_absolutely/</guid>
      <pubDate>Mon, 07 Apr 2025 20:48:41 GMT</pubDate>
    </item>
    <item>
      <title>山姆·奥特曼（Sam Altman）在吉卜力（Ghibli）的反弹片后捍卫AI艺术，称其为社会的“净获胜”</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtu3ro/sam_altman_defends_ai_art_after_studio_ghibli/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32;态href =“ https://www.businessinsider.com/sam-altman-openai-studio-ghibli-ai-ai-ai-ai-ar-image-image-image-ganerator-backlash-2025-4?utm_source = reddit＆source = reddit＆amp; amp medium_medium = social = social = social间＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtu3ro/sam_altman_defends_ai_art_after_studio_ghibli/</guid>
      <pubDate>Mon, 07 Apr 2025 19:34:43 GMT</pubDate>
    </item>
    <item>
      <title>任天堂说，即使有AI，游戏总是会有人为的</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtte5m/nintendo_says_games_will_always_have_a_human/</link>
      <description><![CDATA[      ＆＃32＆＃32;提交由＆＃32; /u/u/pogrebnik     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtte5m/nintendo_says_games_will_always_have_a_human/</guid>
      <pubDate>Mon, 07 Apr 2025 19:06:18 GMT</pubDate>
    </item>
    <item>
      <title>HAI人工智能指数报告2025：AI竞赛变得拥挤了，中国正在美国关闭</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtoaon/hai_artificial_intelligence_index_report_2025_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  斯坦福大学的人类人为AI（hai）今天发表了一份新的研究论文，该论文彰显了该领域的挤压。 href =“ https://macro.com/app/pdf/e10d9df1-f1-f135-4681-b377-8a6c72ec07f8/”&gt; hai人工智能索引报告2025  improve. AI is increasingly embedded in everyday life. Business is all in on AI, fueling record investment and usage, as research continues to show strong productivity impacts. The U.S. still leads in producing top AI models—but China is closing the performance gap. The responsible AI ecosystem evolves—unevenly. 全球AI乐观态度正在上升，但仍有深层区域鸿沟。收紧。  AI因其对科学的影响而获得最高荣誉。 复杂的推理仍然是一个挑战。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1jtoaon/hai_artercover_intelligence_index_report_2025_2025_the/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtoaon/hai_artificial_intelligence_index_report_2025_the/</guid>
      <pubDate>Mon, 07 Apr 2025 15:40:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能种族变得拥挤了，中国正在美国关闭</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtlxk9/the_ai_race_has_gotten_crowdedand_china_is/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/u/wiredmagazine      [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtlxk9/the_ai_race_has_gotten_crowdedand_china_is/</guid>
      <pubDate>Mon, 07 Apr 2025 14:00:28 GMT</pubDate>
    </item>
    <item>
      <title>当您使用光标进行更改时！</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtl6bh/when_you_make_changes_with_cursor/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/ugify       [注释]            ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtl6bh/when_you_make_changes_with_cursor/</guid>
      <pubDate>Mon, 07 Apr 2025 13:25:17 GMT</pubDate>
    </item>
    <item>
      <title>探索可扩展的代理工具使用：动态发现和执行模式</title>
      <link>https://www.reddit.com/r/artificial/comments/1jtgz2z/exploring_scalable_agent_tool_use_dynamic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在思考AI代理如何随着系统的增长而扩展其对外部工具的使用。 我继续遇到的问题是，大多数当前的设置要么将静态的工具列表预加载到代理的上下文中，要么在构建时间访问代理的上下文或硬代码工具。两种方法都感觉刚性和脆弱，尤其是随着工具的数量随时间扩展或变化。   被迫修剪，这限制了代理能力。扩展。 我正在探索的是对待工具不像固定的API，更像是动态的，可发现的对象。 Rather than carrying everything upfront, the agent would explore an external registry at runtime, inspect available tools and parameters, and decide what to use based on its current goal. This way, the agent has the flexibility to:  Discover tools at runtime Understand tool descriptions and parameter requirements dynamically Select and use tools based on context, not hard-coded knowledge  I’ve been comparing a few different workflows to enable this: Manual exploration The agent lists available tools names only, for the ones that seem promising it reads the description and compares them to its goal, and picks the most suitable option. It’s transparent and traceable but slows things down, especially with larger tool sets. Fuzzy auto-selection The agent describes its intent, and the system suggests the closest matching tool. This speeds things up but depends heavily on the quality of the matching. External LLM-assisted selection The agent delegates tool selection to another agent or service, which queries the registry and recommends a tool. It’s more complex but helps distribute decision-making and could scale to environments with many toolsets and domains and lets you use a cheaper model to choose the tool. The broader goal is to let the agent behave more like a developer browsing an API catalog:  Search for relevant tools Inspect their purpose and parameters Use them dynamically在需要时  我认为这是必不可少的，因为如果我们不解决这个问题：  代理人将保持限于静态功能。 工具集成不会随着工具创建的速度而扩展。 开发人员将不得不在 上不断地更新工具，以使他们不断地更新工具。自己。  我仍在考虑的一些开放问题：  是否应该将这些工作流程组合在一起？也许代理商从手动探索开始，并升级为自动化建议，如果该建议不合适。 该系统应该给出多少指导。 我应该从简单的字符串匹配到基于嵌入的语义搜索到基于嵌入的语义搜索？性能，尤其是在潜伏期敏感的环境中？  如果有人对更深入的潜水感兴趣，我已经写了一份研究说明：  https://github.com/m---hmed-elbeskeri/mcpregistry/main/tree/main/main        如果您访问了类似的工具，请访问类似的工具。 /&gt;很好奇听到他人尝试过的方法，有效的是什么。提交由＆＃32; /u/u/welcomemysterious122     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jtgz2z/exploring_scalable_agent_tool_use_dynamic/</guid>
      <pubDate>Mon, 07 Apr 2025 09:13:13 GMT</pubDate>
    </item>
    <item>
      <title>随机鹦鹉只是一个阶段，我们现在将看到LLMS的“ Lee Sedol Moment”</title>
      <link>https://www.reddit.com/r/artificial/comments/1jt0e6g/the_stochastic_parrot_was_just_a_phase_we_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最大的llms批评是它们是随机鹦鹉，无法理解他们说的话。通过拟人化的研究，越来越明显的是，情况并非如此，而LLMS具有现实的了解。但是，借助LLM的知识广泛，我们还没有体验到LLM的“ Lee Sedol时刻”，在该时刻中，LLM表现出如此富有创造力和聪明的东西，以至于它震惊甚至超越了最聪明的人。但是，这是一个很好的理由，为什么这尚未发生，以及为什么很快就会改变的原因。 模型以前已经专注于使用无监督学习的预训练。这意味着该模型可以预测下一个单词，即尽可能复制文本。这导致了明智的，了解模型，但不能带来创造力。奖励信号在输出上太密集（每个令牌都需要正确），因此，该模型在如何创建其答案方面没有灵活性。  现在，我们已经进入了RL：我们最终弄清楚如何在LLM上使用RL的时代，以使其性能提高。这很大。 RL是使Lee Sedol时刻发生的原因。延迟的奖励为模型进行了实验的空间，正如我们现在看到的推理模型尝试不同的链条（COT）的空间。一旦找到有效的方法，我们就会增强它。  请注意，我们没有对人类经过思考的数据进行训练；我们让它创建其思想链。虽然受到预训练的人类婴儿床的启发，但结果仍然是独特而创造性的。更重要的是，它可以超越人类的推理能力！这不像预训练一样受到人类智能的束缚，并且模型超越人类能力的能力是无限的。很快，我们将为LLM提供“ Lee Sedol时刻”。之后，鉴于AI是比地球上任何人类更好的推理者。  的含义将是，任何因推理能力而严重瓶颈的领域都会在进行中爆炸，例如数学和精确的科学。另一个重要的含义是，由于RL对推理任务的RL迫使模型对世界形成非常扎实的概念理解，因此该模型的现实世界的理解将飙升。就像一个使所有练习和深入思考这个主题的学生将比没有的人具有更深刻的理解，而未来的LLM将具有前所未有的世界理解。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pianistWinter8293     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jt0e6g/the_stochastic_parrot_was_just_a_phase_we_will/</guid>
      <pubDate>Sun, 06 Apr 2025 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>AIS有意识吗？认知科学家乔斯·巴赫（Joscha Bach）说，我们的大脑模拟了一个经历世界的观察者 - 但克劳德（Claude）也可以做同样的事情。因此，问题不是它是否有意识，而是它的模拟是否真的比我们的真实。</title>
      <link>https://www.reddit.com/r/artificial/comments/1jt01r5/are_ais_conscious_cognitive_scientist_joscha_bach/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/metaknowing       [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jt01r5/are_ais_conscious_cognitive_scientist_joscha_bach/</guid>
      <pubDate>Sun, 06 Apr 2025 17:53:20 GMT</pubDate>
    </item>
    <item>
      <title>法官在《纽约时报》上召集了Openai的“稻草人”论点版权诉讼</title>
      <link>https://www.reddit.com/r/artificial/comments/1jsognn/judge_calls_out_openais_straw_man_argument_in_new/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32;态href =“ https://arstechnica.com/tech-policy/2025/04/judge-doesnt-buy-openai-openai-argument-argument-argument-nyts-nyts-nyts-weakens-reporting-weakens-copyright-suit/-   [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jsognn/judge_calls_out_openais_straw_man_argument_in_new/</guid>
      <pubDate>Sun, 06 Apr 2025 07:14:23 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻4/5/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1jsmeeq/oneminute_daily_ai_news_452025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      meta 释放Llama 4，一种新的旗舰AI型号。[1]   Bradford-Bord bod boster to Bost to Bost to Boxing in Boxing。[2]        microsoft  美国计划在能源部土地上开发AI项目。[4]   来源：  [1]  https://techcrunch.com/2025/04/05/meta-releases-llama-4-a-new-crop-flagship-flagship-ai-models/    [2]  https://www.theverge.com/news/644117/microsoft-quake-ii-ai-generated-tech-demo-muse-muse-ai-model-copilot    [4]  https://www.reuters.com/technology/artcover-intelligence/us-plans-plans-develop-projects-energy-energy-department-lands-2025-04-04-03/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1jsmeeq/oneminute_daily_ai_ai_news_452025/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jsmeeq/oneminute_daily_ai_news_452025/</guid>
      <pubDate>Sun, 06 Apr 2025 04:53:28 GMT</pubDate>
    </item>
    <item>
      <title>骆驼4在这里</title>
      <link>https://www.reddit.com/r/artificial/comments/1jse8tf/llama_4_is_here/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/useconfident      [注释]         ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1jse8tf/llama_4_is_here/</guid>
      <pubDate>Sat, 05 Apr 2025 21:31:55 GMT</pubDate>
    </item>
    <item>
      <title>meta ai躺在你的脸上</title>
      <link>https://www.reddit.com/r/artificial/comments/1js6k41/meta_ai_is_lying_to_your_face/</link>
      <description><![CDATA[    /u/u/u/velemenyednemerdekel       [注释]    ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1js6k41/meta_ai_is_lying_to_your_face/</guid>
      <pubDate>Sat, 05 Apr 2025 15:54:35 GMT</pubDate>
    </item>
    </channel>
</rss>