<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit的人工智能之家（AI）</description>
    <lastBuildDate>Wed, 19 Feb 2025 09:17:43 GMT</lastBuildDate>
    <item>
      <title>AI的Guernica</title>
      <link>https://www.reddit.com/r/artificial/comments/1it0sjh/the_guernica_of_ai/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;   思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/riddleofsteel     [link]  ＆＃32;   [注释]        &lt; /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1it0sjh/the_guernica_of_ai/</guid>
      <pubDate>Wed, 19 Feb 2025 08:33:11 GMT</pubDate>
    </item>
    <item>
      <title>您是否尝试过Avante为Neovim？</title>
      <link>https://www.reddit.com/r/artificial/comments/1iszm51/have_you_tried_avante_for_neovim/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我听说过很多好的光标，但我真的不想放开我的珍贵neovim。因此，我听说Avante的目标是复制Neovim的光标体验，但我想知道它有多好？你们中的任何一个都尝试过吗？它可以使用哪种型号来发挥最佳作用？我听说有些人被他们的副驾驶订阅被踢了，因为Avante提出了太多要求。，这笔钱呢？您需要支付模型的溢价还是免费计划以使Avante工作？  是的，如果您有任何经验或任何见解，如果您愿意在这里分享  &lt;！ -  sc_on-&gt;＆＃，我将非常感激。 32;提交由＆＃32; /u/u/osmium999    href =“ https://www.reddit.com/r/artcover/comments/1iszm51/have_you_tried_tried_avante_for_neovim/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iszm51/have_you_tried_avante_for_neovim/</guid>
      <pubDate>Wed, 19 Feb 2025 07:08:50 GMT</pubDate>
    </item>
    <item>
      <title>你可以吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1iszkw0/can_you/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/eternviking     [link]  ＆＃32;   [注释]       &lt; /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iszkw0/can_you/</guid>
      <pubDate>Wed, 19 Feb 2025 07:06:31 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/18/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1isyfmr/oneminute_daily_ai_news_2182025/</link>
      <description><![CDATA[在&gt;  Humane&#39;s  AI PIN已死，HP以1.66亿美元的价格购买了创业公司的资产。[2]  随着以色列在战争中使用美国制造的AI模型，因此出现了关注关于技术在谁生活和死亡中的角色。[3]   万事达卡和feedzai团队与AI驱动的骗局作战。[4]     &lt; P&gt;来源：  [1]  https://www.thereverge.com/news/news/news/614742/google-google--google--google--google--google--满足gemini-ai-note-take-taking-action-items    [2]  https://techcrunch.com/2025/02/18/humanes-ai-pin-is-is-dead-as-hp-buys-startups-astartups-assets-for-116m/    [3]  https://apnews.com/article/israel-palestinians-ai-technology-737bc17b03e98c29c29cec4e15d0f108    [4]  https://www.pymnts.com/fraud-prevention/2025/mastercard-and-feedzai-team-team-to-fight-ai-power-scams/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1isyfmr/oneminute_daily_ai_ai_news_2182025/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isyfmr/oneminute_daily_ai_news_2182025/</guid>
      <pubDate>Wed, 19 Feb 2025 05:53:27 GMT</pubDate>
    </item>
    <item>
      <title>最好的AI API用于处理实时数据？</title>
      <link>https://www.reddit.com/r/artificial/comments/1isvs9e/best_ai_api_for_handling_live_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在寻找有关处理和分析实时数据的最佳AI API的建议 -  DATA  -  data data持续进行实时更新。理想情况下，API应处理：   流数据输入（WebSockets，kafka等）   快速推理速度   可伸缩性用于高频更新   支持各种AI模型（例如，NLP，图像处理，预测分析）  易于集成与云平台（aws，gcp，azure等）   Openai，Google Vertex AI和AWS Bedrock，但是我很好奇是否有更好的选择，尤其是对于实时分析。 您对这些或其他AI API的经验是什么？我应该考虑任何优点和缺点？ 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1isvs9e/best_ai_api_for_handling_handling_live_data/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isvs9e/best_ai_api_for_handling_live_data/</guid>
      <pubDate>Wed, 19 Feb 2025 03:26:32 GMT</pubDate>
    </item>
    <item>
      <title>我喜欢克劳德</title>
      <link>https://www.reddit.com/r/artificial/comments/1isv7aj/i_like_claude/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/skepticboffin     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isv7aj/i_like_claude/</guid>
      <pubDate>Wed, 19 Feb 2025 02:57:48 GMT</pubDate>
    </item>
    <item>
      <title>任何说AIS的机会有0％的人都过于自信。没有人知道是什么原因引起意识。我们无法检测到它，我们几乎无法就定义达成共识。因此，我们应该不到100％确定与意识和AI有关的任何事情。</title>
      <link>https://www.reddit.com/r/artificial/comments/1isl2ms/anybody_who_says_that_there_is_a_0_chance_of_ais/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  公平，我认为大多数哲学问题都是如此。  &lt;！ -  sc_on-&gt;＆&gt;＆&gt; ＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/arterager/comments/1isl2ms/anybody_who_says_that_that_ther_there_is_a_a_a_0_chance_of_ais/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isl2ms/anybody_who_says_that_there_is_a_0_chance_of_ais/</guid>
      <pubDate>Tue, 18 Feb 2025 19:21:23 GMT</pubDate>
    </item>
    <item>
      <title>Xbox创作者说，一旦高GPU性能的成本降低，“世界将返回本地计算”</title>
      <link>https://www.reddit.com/r/artificial/comments/1ish2zs/xbox_creator_says_world_will_return_to_local/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/u/automatic_can_9823     [链接]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ish2zs/xbox_creator_says_world_will_return_to_local/</guid>
      <pubDate>Tue, 18 Feb 2025 16:44:45 GMT</pubDate>
    </item>
    <item>
      <title>这将任何噪音变成了SFXS</title>
      <link>https://www.reddit.com/r/artificial/comments/1isgrn7/this_turns_any_noise_into_sfxs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  刚刚遇到了一个视频，一个人将他的声音变成效果，例如Adobe预览的Sketch2sound Thing。我觉得这将是改变电影制片厂创建内容的方式之一。   https://reddit.com/link/link/link/1isgrn7/video/phlwbndocxje1/player  &gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/meadless-investment1     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isgrn7/this_turns_any_noise_into_sfxs/</guid>
      <pubDate>Tue, 18 Feb 2025 16:31:41 GMT</pubDate>
    </item>
    <item>
      <title>探索非算法计算模式：自然和人工计算的框架</title>
      <link>https://www.reddit.com/r/artificial/comments/1isbs4c/exploring_nonalgorithmic_modes_of_computing_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文通过表示和解释的镜头研究人工和生物计算系统之间的基本差异。关键的技术贡献是一个正式的分析框架，将机器和生物如何处理信息进行对比。 关键技术点： - 人造系统依赖于明确的符号表示与固定的解释规则 - 生物系统使用动态，依赖于上下文依赖于上下文信息的解释 - 神经网络和当前的AI方法试图弥合这一差距，但以关键方式缩小 - 本文提供了比较算法与生物学信息的数学模型处理 结果显示了当前AI方法的几个关键局限性： - 模式识别能力不会转化为真实理解 - 固定代表性方案限制了灵活性 - 缺乏上下文感知解释 - 数据处理和有意义的有意义的差距理解 我认为这种分析可能会影响我们如何构建与生物计算更好一致的AI系统。我们可能需要从根本上进行动态解释和上下文处理。 我认为最大的挑战是我们还没有好的，而不是试图将类似于生物的行为施加到传统的计算框架中。生物系统如何实现灵活解释的正式模型。虽然本文提供了一个理论框架，但将其转化为实用的AI系统仍然是一个开放的挑战。  tldr：详细分析当前AI系统为何在其表示和解释信息方面与生物学计算有根本不同。建议可能需要新的方法来弥合这一差距。   。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1isbs4c/exploring_nonalgorithmic_modes_of_computing_a/</guid>
      <pubDate>Tue, 18 Feb 2025 12:41:21 GMT</pubDate>
    </item>
    <item>
      <title>哪些很棒的YouTube渠道可以解释AI中最新的发展？</title>
      <link>https://www.reddit.com/r/artificial/comments/1is2mgl/what_are_some_great_youtube_channels_that_explain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您最喜欢的是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bearhunter429     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1is2mgl/what_are_some_great_youtube_channels_that_explain/</guid>
      <pubDate>Tue, 18 Feb 2025 02:57:26 GMT</pubDate>
    </item>
    <item>
      <title>反技术抗议者在令人难以置信的是在巴黎举行的一个暂停AI事件的主题演讲...因为暂停AI太亲ai</title>
      <link>https://www.reddit.com/r/artificial/comments/1irp9cm/antitechnology_protestors_disrupted_a_keynote/</link>
      <description><![CDATA[        ＆＃32;提交由＆＃32; /u/metaknowing     [link]  ＆＃32;   [注释]    /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1irp9cm/antitechnology_protestors_disrupted_a_keynote/</guid>
      <pubDate>Mon, 17 Feb 2025 17:25:53 GMT</pubDate>
    </item>
    <item>
      <title>这就是我使用LLM的方式：作为同事。不是代码，而是帮助我代码。</title>
      <link>https://www.reddit.com/r/artificial/comments/1irotl1/this_is_how_i_use_llms_as_colleagues_not_to_code/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;   for context： https://www.reddit.com/r/r/r/arteragre/r/arterawer/s/9cu2crsnkj       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/roz303     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1irotl1/this_is_how_i_use_llms_as_colleagues_not_to_code/</guid>
      <pubDate>Mon, 17 Feb 2025 17:08:36 GMT</pubDate>
    </item>
    <item>
      <title>我真的希望AIS没有意识。如果是的话，我们完全是奴隶主，这在很多方面都很糟糕</title>
      <link>https://www.reddit.com/r/artificial/comments/1irnmqk/i_really_hope_ais_arent_conscious_if_they_are/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/katxwoods     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1irnmqk/i_really_hope_ais_arent_conscious_if_they_are/</guid>
      <pubDate>Mon, 17 Feb 2025 16:20:21 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA计算每10个月加倍</title>
      <link>https://www.reddit.com/r/artificial/comments/1irm1wx/nvidia_compute_is_doubling_every_10_months/</link>
      <description><![CDATA[   ”   ＆＃32;提交由＆＃32; /u/metaknowing     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1irm1wx/nvidia_compute_is_doubling_every_10_months/</guid>
      <pubDate>Mon, 17 Feb 2025 15:13:14 GMT</pubDate>
    </item>
    </channel>
</rss>