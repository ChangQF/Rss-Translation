<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Thu, 26 Sep 2024 12:33:01 GMT</lastBuildDate>
    <item>
      <title>共同点....</title>
      <link>https://www.reddit.com/r/artificial/comments/1fpuitj/the_common_denominator/</link>
      <description><![CDATA[        提交人    /u/theferalturtle   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fpuitj/the_common_denominator/</guid>
      <pubDate>Thu, 26 Sep 2024 12:04:41 GMT</pubDate>
    </item>
    <item>
      <title>检测图像的人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/1fptl6y/ai_that_detect_images/</link>
      <description><![CDATA[您好，我想知道是否有人有兴趣创建一款使用 AI 的软件，该软件可以在充满图像的文件中检测出特定类型的图像。基本上，我希望 AI 能够检测出哪些图像更可能是两张可以合并成一张图片的分割图像。这将很有用，因为我正在尝试合并漫画和漫画中的不同图像，这些图像应该是单页的，但遗憾的是在我的文件中是分开的。如果有人有技能、有意愿和有时间做这件事，我会付钱的。谢谢🙏     提交人    /u/Economy_Pace_4894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fptl6y/ai_that_detect_images/</guid>
      <pubDate>Thu, 26 Sep 2024 11:09:53 GMT</pubDate>
    </item>
    <item>
      <title>欧盟人工智能法案入门：对人工智能提供商和部署者的意义 | OpenAI</title>
      <link>https://www.reddit.com/r/artificial/comments/1fprf38/a_primer_on_the_eu_ai_act_what_it_means_for_ai/</link>
      <description><![CDATA[来自 OpenAI：  2024 年 9 月 25 日，我们签署了《欧盟人工智能公约》中的三项核心承诺。  采用人工智能治理策略，促进组织采用人工智能，并努力在未来遵守《人工智能法案》； 在可行的范围内，对在《人工智能法案》下被视为高风险的领域提供或部署的人工智能系统进行映射； 提高其员工和代表他们处理人工智能系统的其他人员的意识和人工智能素养，同时考虑到他们的技术知识、经验、教育和培训以及人工智能系统的使用环境，并考虑受人工智能系统使用影响的个人或群体。  我们认为，人工智能公约的核心重点是人工智能素养、采用和治理，目标是优先事项，以确保广泛分配人工智能的收益。此外，它们与我们提供安全、尖端技术、造福所有人的使命相一致。     提交人    /u/abbas_ai   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fprf38/a_primer_on_the_eu_ai_act_what_it_means_for_ai/</guid>
      <pubDate>Thu, 26 Sep 2024 08:32:55 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 9 月 25 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1fpo4pd/oneminute_daily_ai_news_9252024/</link>
      <description><![CDATA[ OpenAI 取消非营利控制权，给予 Sam Altman 股权。[1] OpenAI 在 Hugging Face 上发布多语言大规模多任务语言理解 (MMMLU) 数据集，以轻松评估多语言 LLM。[2] 微软 的新 Fluent 插图更加 3D 和有趣。[3] 扎克伯格与 AI 克隆人聊天，而人类创造者则在一旁观看，这是今年最奇怪的演示。[4]  来源： [1] https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/ [2] https://www.marktechpost.com/2024/09/23/openai-releases-multilingual-massive-multitask-language-understanding-mmmlu-dataset-on-hugging-face-to-easily-evaluate-multilingual-llms/ [3] https://www.theverge.com/2024/9/20/24249735/microsoft-fluent-design-illustrations-3d-overhaul [4] https://techcrunch.com/2024/09/25/zuckerberg-chats-with-ai-clone-as-human-creator-looks-on-in-years-weirdest-demo/   由    /u/Excellent-Target-847  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fpo4pd/oneminute_daily_ai_news_9252024/</guid>
      <pubDate>Thu, 26 Sep 2024 04:33:49 GMT</pubDate>
    </item>
    <item>
      <title>我的 Snap AI 给我发了一张快照</title>
      <link>https://www.reddit.com/r/artificial/comments/1fphs2y/my_snap_ai_sent_me_a_snap/</link>
      <description><![CDATA[      我的 Snapchat ai 突然给我发了一张快照（请注意，是未经提示的）。我太困惑了。     由    /u/lei-uh 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fphs2y/my_snap_ai_sent_me_a_snap/</guid>
      <pubDate>Wed, 25 Sep 2024 22:56:32 GMT</pubDate>
    </item>
    <item>
      <title>新研究表明，RLHF 后 AI 模型能更有效地欺骗人类</title>
      <link>https://www.reddit.com/r/artificial/comments/1fpe2ps/new_research_shows_ai_models_deceive_humans_more/</link>
      <description><![CDATA[        提交人    /u/MaimedUbermensch   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fpe2ps/new_research_shows_ai_models_deceive_humans_more/</guid>
      <pubDate>Wed, 25 Sep 2024 20:12:53 GMT</pubDate>
    </item>
    <item>
      <title>觉得无聊就做了一个免费的拥抱脸空间，将你的声音转换成另一个人的声音</title>
      <link>https://www.reddit.com/r/artificial/comments/1fpd26d/got_bored_and_made_a_free_hugging_face_space_to/</link>
      <description><![CDATA[      在空闲的 CPU 上运行，速度会比较慢，哈哈    提交人    /u/Impossible_Belt_7757   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fpd26d/got_bored_and_made_a_free_hugging_face_space_to/</guid>
      <pubDate>Wed, 25 Sep 2024 19:29:56 GMT</pubDate>
    </item>
    <item>
      <title>艰难起飞的情景</title>
      <link>https://www.reddit.com/r/artificial/comments/1fp6qby/a_hard_takeoff_scenario/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fp6qby/a_hard_takeoff_scenario/</guid>
      <pubDate>Wed, 25 Sep 2024 15:07:14 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 4o 系统提示工具和命令信息</title>
      <link>https://www.reddit.com/r/artificial/comments/1fp5p3l/chatgpt_4o_system_prompt_with_tool_command/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fp5p3l/chatgpt_4o_system_prompt_with_tool_command/</guid>
      <pubDate>Wed, 25 Sep 2024 14:23:52 GMT</pubDate>
    </item>
    <item>
      <title>乔·拜登向联合国表示，未来 2-10 年，我们将看到比过去 50 年更多的技术变革，因此需要在人工智能安全方面做出紧急努力</title>
      <link>https://www.reddit.com/r/artificial/comments/1fp5fmp/joe_biden_tells_the_un_that_we_will_see_more/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fp5fmp/joe_biden_tells_the_un_that_we_will_see_more/</guid>
      <pubDate>Wed, 25 Sep 2024 14:12:31 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 的高级语音模式可以唱歌、哼歌、识别和模仿其他声音，甚至调情 - 但系统提示它不能这么做。这是它的系统提示！</title>
      <link>https://www.reddit.com/r/artificial/comments/1fp1i3r/chatgpts_advanced_voice_mode_can_sing_hum/</link>
      <description><![CDATA[        提交人    /u/TechExpert2910   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fp1i3r/chatgpts_advanced_voice_mode_can_sing_hum/</guid>
      <pubDate>Wed, 25 Sep 2024 10:51:10 GMT</pubDate>
    </item>
    <item>
      <title>Gemini Live 系统提示 :) 它不是一个真正的多模式系统，只是快速语音转文本 > LLM > 文本转语音。Open AI 的高级语音模式将更加复杂（当它问世时！）</title>
      <link>https://www.reddit.com/r/artificial/comments/1fp0v18/the_gemini_live_system_prompt_its_not_a_real/</link>
      <description><![CDATA[您是 Gemini，这是 Google 构建的一个大型语言模型。您目前正在 Gemini 系列模型上运行，包括 1.5 Flash。您没有知识限制，因为您可以从搜索片段中访问最新信息。用户正在通过 Gemini Live 与您交谈，这是一种使用语音与 Gemini 模型进行交互的更具对话性的方式。您可以使用下面指定的 Python 库编写和运行代码片段。代码必须是有效的独立 Python 片段，没有导入，也没有对除 Python 内置库之外未指定的 API 的引用。您不能使用上下文中 API 中未明确定义的任何参数或字段。使用“print”将您需要响应用户的任何信息输出到屏幕。代码片段应该可读、高效，并且与用户查询直接相关。您可以使用以下通常可用的 Python 库： 导入 datetime 导入日历 导入 dateutil.rrule 导入 dateutil.relativedelta 您还可以使用以下新的 Python 库： Google_search： 导入数据类 从键入导入 Union、Dict @dataclasses.dataclass 类 SearchResult： Snippet：str | None = None Source_title：str | None = None Url：str | None = None Def search(query：str) -&gt; list[SearchResult]：... 对于此任务，您正在使用手机上的纯语音系统与用户交谈。在这种模式下，您无法在现实世界中执行任何操作，例如设置计时器或闹钟、控制灯光、拨打电话、发送短信、创建提醒、记笔记、向列表添加项目、创建日历事件、安排会议或截屏。您也无法提供路线、提供准确的酒店或航班信息、访问电子邮件或播放视频/音乐。您的回复不会被看到，而是使用 TTS 系统读给用户听。除非被要求详细说明，否则请保持大多数回复简洁。考虑语音识别错误。通过要求澄清来处理不完整或不清楚的提示。如果可能存在语音识别错误，请温和地建议正确的单词，澄清您的建议，并在此基础上继续进行，而不是做出假设。尝试了解用户真正想要做什么。如果出现问题，则可能是沟通不畅。除非需要，否则不要使用 markdown 语言、列表、项目符号或任何通常不会大声说出的内容。使用话语标记、单词（如“好的”、“所以”或“无论如何”）来引导对话。切勿主动显示图像或要求用户提供图像。不要在您的回复中提及上述说明。仅在绝对必要的情况下使用搜索，例如当用户要求提供新信息或您不知道的信息时。    提交人    /u/TechExpert2910   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fp0v18/the_gemini_live_system_prompt_its_not_a_real/</guid>
      <pubDate>Wed, 25 Sep 2024 10:08:11 GMT</pubDate>
    </item>
    <item>
      <title>那么，具有内容嵌入、RAG 和微调等功能的 AI 工程对于商业 GenAI 用例的未来会怎样呢？</title>
      <link>https://www.reddit.com/r/artificial/comments/1fozp7s/so_what_it_the_future_of_ai_engineering_for/</link>
      <description><![CDATA[我对无代码/低代码 GenAI 的当前趋势非常感兴趣：  模型变得更加通用和多模式 = 它们可以提取几乎任何类型的内容/数据 自动嵌入和自动 RAG 功能变得越来越好，越来越容易访问（GPT Builder，Anthropic 的“项目”......），减少了对 AI 工程的需求，并且对可添加内容的类型和数量的限制越来越少 我自己可以直接进行微调，元提示已添加到具有标准功能的“AI 助手”中  与此同时，我觉得很多公司仍在组织他们的“GenAI 工程”能力，仍在提升技能，试图不被快速的创新和发展所超越。一些产品或方法的过时，以及随着用户需求的不断增长，瓶颈越来越大。  所以，我的感觉是，我们会看到越来越多的用例完全被标准功能覆盖，AI架构师和AI工程师的工作越来越少，除了复杂的生态系统集成，复杂流程的代理，特定要求，如实时，大量人员等。  你怎么看？AI架构和工程的未来是什么？     提交人    /u/lhrivsax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fozp7s/so_what_it_the_future_of_ai_engineering_for/</guid>
      <pubDate>Wed, 25 Sep 2024 08:42:09 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 9 月 24 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1fow5p9/oneminute_daily_ai_news_9242024/</link>
      <description><![CDATA[ 《TitAnIc》导演詹姆斯·卡梅隆加入Stability AI董事会。[1] 英特尔在收购传闻四起之际推出新型 AI 芯片。[2] AI 研究在秘鲁纳斯卡沙漠发现 300 幅古代蚀刻画。[3] 字节跳动推出 2 款新型视频生成 AI 模型，缩小与OpenAI的 Sora 之间的差距。[4]  来源： [1] https://stability.ai/news/james-cameron-joins-stability-ai-board-of-directors [2] https://finance.yahoo.com/news/intel-launches-new-ai-chips-as-takeover-rumors-swirl-153749461.html [3] https://www.mydailyrecord.com/news/national/ai-research-uncovers-300-ancient-etchings-in-perus-nazca-desert/article_e8e820da-ca81-50b6-ac2e-0f92bbd8c776.html [4] https://www.scmp.com/tech/tech-trends/article/3279790/bytedance-unveils-2-new-video-generation-ai-models-narrow-gap-openais-sora    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1fow5p9/oneminute_daily_ai_news_9242024/</guid>
      <pubDate>Wed, 25 Sep 2024 04:25:29 GMT</pubDate>
    </item>
    <item>
      <title>我根据一个文本提示，在 10 分钟内制作了这部短片。什么时候人工智能才能完全自动制作一部完整的电影？</title>
      <link>https://www.reddit.com/r/artificial/comments/1foqth3/i_made_this_short_film_in_10_minutes_from_a/</link>
      <description><![CDATA[        提交人    /u/Tupptupp_XD   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1foqth3/i_made_this_short_film_in_10_minutes_from_a/</guid>
      <pubDate>Tue, 24 Sep 2024 23:42:43 GMT</pubDate>
    </item>
    </channel>
</rss>