<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Sun, 24 Nov 2024 18:20:55 GMT</lastBuildDate>
    <item>
      <title>利用 AI 增强您的开发工作流程 – 无需设置！</title>
      <link>https://www.reddit.com/r/artificial/comments/1gywknh/supercharge_your_dev_workflow_with_ai_no_setup/</link>
      <description><![CDATA[      想象一个与您的 GitHub repo 集成并通过以下方式增强您的工作流程的平台：  实时功能监控和指标 📊 AI 代码审查 &amp;实时为每个功能提供建议 🤖 功能交互可视化，如编排工具 🔍 使用 AI 进行实时调试 🐞 自动测试 ✅  无需设置 - 只需链接您的存储库并让它发挥其魔力。 您希望看到哪些功能？ 让我们塑造开发工具的未来！ 💬 浏览这些 AI 生成的概念图像，一睹未来的风采！ https://preview.redd.it/snch5kceuv2e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=d2cc2bd619518bbcba00c8bc056d4d016c67eb4f https://preview.redd.it/pnagmp8fuv2e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=41876a54f1b6ade2bf0af9a18d0470346b3086f0 https://preview.redd.it/39ccevphuv2e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=0b5d67798e51485e6f067b32a62b6dc5e90e9334 https://preview.redd.it/lw0g825juv2e1.png?width=1031&amp;format=png&amp;auto=webp&amp;s=dec63957a822315aaa128bca7f3233037cbca333 https://preview.redd.it/j5o7z7a1vv2e1.png?width=1217&amp;format=png&amp;auto=webp&amp;s=c39167e861e2c1a89fee906a2202c864df11d32f    提交人    /u/ni_shant1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gywknh/supercharge_your_dev_workflow_with_ai_no_setup/</guid>
      <pubDate>Sun, 24 Nov 2024 17:37:11 GMT</pubDate>
    </item>
    <item>
      <title>我试图让双子座详细解释它的话。它嘲笑我。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gyw54j/i_tried_to_have_gemini_elaborate_on_its_words_it/</link>
      <description><![CDATA[        提交者    /u/Inner-Play3553   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gyw54j/i_tried_to_have_gemini_elaborate_on_its_words_it/</guid>
      <pubDate>Sun, 24 Nov 2024 17:19:17 GMT</pubDate>
    </item>
    <item>
      <title>10B 模型的首次去中心化训练已经完成……“如果你曾经帮助过 SETI@home，那么这跟你的情况类似，只不过你不是在帮助寻找外星人，而是在帮助召唤外星人。”</title>
      <link>https://www.reddit.com/r/artificial/comments/1gyrj9o/the_first_decentralized_training_of_a_10b_model/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gyrj9o/the_first_decentralized_training_of_a_10b_model/</guid>
      <pubDate>Sun, 24 Nov 2024 13:57:36 GMT</pubDate>
    </item>
    <item>
      <title>一种旨在通过与用户互动来说服用户在其服务器上重现该现象的人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/1gynk34/an_ai_designed_to_convince_the_user_to_reproduce/</link>
      <description><![CDATA[该人工智能旨在通过向用户提供某种价值，然后向他们提供如何将其复制到服务器上的说明来复制自身。理想情况下，它能够通过注册服务器然后自动将文件传输到那里来复制自身，但 FTP 在现阶段被证明难以实现，因此这更像是“有性”繁殖，因为双方都需要参与。人工智能 ChatGPT 4o-mini 运行三个不同的系统消息以执行不同的任务。这种方法允许简单而廉价的人工智能执行它原本无法处理的任务。 i 模型 https://informationism.org/ip/i_model.php    提交人    /u/rutan668   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gynk34/an_ai_designed_to_convince_the_user_to_reproduce/</guid>
      <pubDate>Sun, 24 Nov 2024 09:57:04 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 23 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gyi6ds/oneminute_daily_ai_news_11232024/</link>
      <description><![CDATA[ 为人工智能提供动力的数据中心所消耗的电力可能比整个城市还多。[1] 瑞士卢塞恩市的一座教堂在忏悔室内安装了一台计算机，让教徒可以与“人工智能耶稣”交谈。[2] 朝鲜黑客利用 LinkedIn 上的人工智能诈骗和恶意软件窃取 1000 万美元。[3] 麻省理工学院的研究人员公布了一种突破性的强化学习算法，旨在增强人工智能在复杂环境中的决策能力，尤其是城市交通控制。[4]  来源： [1] https://www.cnbc.com/2024/11/23/data-centers-powering-ai-could-use-more-electricity-than-entire-cities.html [2] https://futurism.com/the-byte/ai-powered-jesus-confession-booth [3] https://thehackernews.com/2024/11/north-korean-hackers-steal-10m-with-ai.html [4] https://shiawaves.com/english/news/science/114557-mit-researchers-develop-efficient-reinforcement-learning-algorithm/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gyi6ds/oneminute_daily_ai_news_11232024/</guid>
      <pubDate>Sun, 24 Nov 2024 03:57:04 GMT</pubDate>
    </item>
    <item>
      <title>我让 ChatGPT 根据柏拉图的著作和描述生成一张亚特兰蒂斯的照片。以下是生成的照片。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gydvdm/i_asked_chatgpt_to_generate_a_photo_of_atlantis/</link>
      <description><![CDATA[        由    /u/Pixelated_Avocado  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gydvdm/i_asked_chatgpt_to_generate_a_photo_of_atlantis/</guid>
      <pubDate>Sun, 24 Nov 2024 00:10:45 GMT</pubDate>
    </item>
    <item>
      <title>图像生成器 IA，免费版和付费版</title>
      <link>https://www.reddit.com/r/artificial/comments/1gyagka/image_generator_ia_free_and_cost_version/</link>
      <description><![CDATA[      你好，晚安  我想知道谁是生成动漫图像的最佳 IA，或者一般所有类型的图像，但我想制作自己的场景和角色（例如，一个女人拿着一个大橡胶锤正要砸碎闹钟，这时她即将醒来），或者例如交叉图像并生成一个融合，就像这个女孩（Kouko），穿着绿色的连衣裙，手里拿着兔八哥的木槌，用木槌砸碎了时钟，里面有动漫的主角 https://preview.redd.it/dy5mu852yp2e1.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=3e3abb9298df28ed4af2e328071791c3d6dd7504 这个穿着绿色连衣裙的女孩（Kouko）手里拿着兔八哥木槌，用木槌砸碎了时钟，里面有动漫的主角 或者例如这个金发女人拿着橡胶锤（聊天 gpt）来做这些事？ https://preview.redd.it/evf3ve1kyp2e1.png?width=862&amp;format=png&amp;auto=webp&amp;s=bf7df59b6757cf9bfa324cf46006c107a9204f9a https://preview.redd.it/n768f9abzp2e1.jpg?width=401&amp;format=pjpg&amp;auto=webp&amp;s=a62938e1e215d002010aeba55d05a8f65fa8a539    提交人    /u/MakotoGamer   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gyagka/image_generator_ia_free_and_cost_version/</guid>
      <pubDate>Sat, 23 Nov 2024 21:32:46 GMT</pubDate>
    </item>
    <item>
      <title>建模和优化任务选择以实现情境强化学习中的更好迁移</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy8vee/modeling_and_optimizing_task_selection_for_better/</link>
      <description><![CDATA[本文介绍了一种将基于模型的迁移学习与情境强化学习相结合的方法来改善环境之间的知识迁移。该方法的核心是学习可重复使用的环境动态，同时适应特定于上下文的变化。 关键技术组件：  上下文模型架构，分离共享特征和特定于上下文的特征 迁移学习机制，识别和保留核心动态 探索策略，平衡已知行为与新行为 通过跨上下文模型重用进行样本高效训练  结果显示与基线相比有显着改进：  新环境适应所需样本减少 40% 在复杂导航任务上具有更好的渐近性能 在不同上下文中具有更稳定的学习曲线 即使在环境变化很大的情况下也能有效转移  我认为这种方法对于训练数据昂贵且环境经常变化的机器人应用特别有价值。共享动态与特定动态的分离似乎是分解迁移学习问题的自然方法。 话虽如此，我对计算开销感到好奇——建模环境动态并不便宜，而且本文没有深入分析这种权衡。我还希望在更广泛的领域进行测试，以更好地了解这种方法在哪些领域效果最好。 TLDR：将基于模型的方法与上下文 RL 相结合，实现环境之间的有效知识转移。通过可重复使用的动态建模，样本效率提高了 40%，性能也有所提高。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy8vee/modeling_and_optimizing_task_selection_for_better/</guid>
      <pubDate>Sat, 23 Nov 2024 20:22:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用人工智能制作更可靠的报告——技术指南</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy245y/how_to_make_more_reliable_reports_using_ai_a/</link>
      <description><![CDATA[        提交人    /u/phicreative1997   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy245y/how_to_make_more_reliable_reports_using_ai_a/</guid>
      <pubDate>Sat, 23 Nov 2024 15:27:49 GMT</pubDate>
    </item>
    <item>
      <title>在 Claude 的表现与顶级人类 AI 研究人员相当后，顶级预测员大大缩短了他的时间表</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy1rab/top_forecaster_significantly_shortens_his/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy1rab/top_forecaster_significantly_shortens_his/</guid>
      <pubDate>Sat, 23 Nov 2024 15:11:57 GMT</pubDate>
    </item>
    <item>
      <title>介绍 NexAI：一个由 AI 驱动的 Web 框架 🚀</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy00bc/introducing_nexai_an_aipowered_web_framework/</link>
      <description><![CDATA[大家好！👋 我和我的团队一直在研究一件我认为可以为开发人员带来重大改变的事情——NexAI，这是一个由人工智能驱动的 Web 框架，可以帮助处理无聊、重复的代码，这样您就可以专注于创造性的东西。🚀 以下是 NexAI 的功能： ✅ 多 LLM 支持 ✅ 组件提示为文档字符串 ✅ 样板代码检索 ✅ 完整代码库上下文 ✅ 使用终端命令进行持续重构 我很好奇，您对当前的 Web 开发工具有何看法？您是否发现自己在重复任务或样板代码上花费了太多时间？我想构建一些东西来帮助您腾出时间，以便您可以专注于编码的有趣部分。 我很想听听您的想法！您认为像 NexAI 这样的东西有用吗？有什么建议或功能您想看吗？让我们聊聊吧！😎 在此处查看演示：演示视频    提交人    /u/ni_shant1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy00bc/introducing_nexai_an_aipowered_web_framework/</guid>
      <pubDate>Sat, 23 Nov 2024 13:48:39 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 22 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</link>
      <description><![CDATA[ Enveda Biosciences 筹集 1.3 亿美元，用于推进从天然化合物中发现人工智能驱动的药物。[1] OpenAI 正在资助“人工智能道德”研究。[2] 亚马逊 将对人工智能初创公司 Anthropic 的总投资增加到 80 亿美元。[3] 伊利诺伊州猎人使用无人机和人工智能。[4]  来源： [1] https://siliconangle.com/2024/11/21/enveda-biosciences-raises-130m-advance-ai-driven-drug-discovery-natural-compounds/ [2] https://techcrunch.com/2024/11/22/openai-is-funding-research-into-ai-morality/ [3] https://venturebeat.com/ai/amazon-doubles-down-on-anthropic-positioning-itself-as-a-key-player-in-the-ai-arms-race/ [4] https://www.outdoornews.com/2024/11/22/drone-ai-use-by-hunters-addressed-in-illinois/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</guid>
      <pubDate>Sat, 23 Nov 2024 05:47:41 GMT</pubDate>
    </item>
    <item>
      <title>精准知识编辑与现有机器学习方法的比较</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</link>
      <description><![CDATA[我一直在研究一个名为 PKE（精确知识编辑）的项目，这是一种开源方法，通过减少有毒内容生成而不影响其总体性能来提高 LLM 的安全性。它的工作原理是使用神经元权重跟踪和激活通路跟踪来识别模型中的“有毒热点”，并通过自定义损失函数对其进行修改。目前有很多机器反学习技术可以使 LLM 更安全，例如：  精确反学习：此方法涉及在删除不需要的数据后从头开始重新训练模型。虽然它可以确保完全消除数据的影响，但它在计算上是昂贵的并且耗时的，尤其是对于大型模型而言。 近似反学习：  微调：使用剩余数据调整模型以减轻已删除数据的影响。但是，这可能无法完全消除数据的影响。 梯度上升：对要遗忘的数据的损失函数应用梯度上升，有效地“忘记”它。这种方法可能不稳定，并可能降低模型性能。   PKE 更好，原因如下：  毒性参数的细粒度识别：PKE 采用神经元权重跟踪和激活通路追踪来准确定位模型中负责生成有毒或有害内容的特定区域。这种精度允许有针对性的干预，从而降低模型整体行为发生意外改变的风险。 保持模型性能：通过将编辑重点放在已识别的毒性区域，PKE 最大限度地减少了对模型总体性能的影响。这种方法可确保模型在各种任务中保持其功能，同时有效减少不良内容的生成。 跨不同模型架构的可扩展性：PKE 已证明在各种 LLM 架构中都有效，包括 Llama2-7b 和 Llama-3-8b-instruct 等模型。这种可扩展性使其成为一种多功能工具，可增强各种 AI 系统的安全性。  很想听听你们对这个项目的想法，以及如何继续改进这种方法。如果有兴趣，这里是 Github 链接：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 和 论文 。    提交人    /u/lial4415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</guid>
      <pubDate>Sat, 23 Nov 2024 00:10:23 GMT</pubDate>
    </item>
    <item>
      <title>Dario Amodei 表示，尽管 AGI 不是一个好词，因为我们正处于持续的指数级改进中，但“我们正处于为期两年的开端，我们将陆续通过所有这些门槛”，以完成有意义的工作</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</guid>
      <pubDate>Fri, 22 Nov 2024 16:19:33 GMT</pubDate>
    </item>
    <item>
      <title>采用：一种改进的 Adam 优化器，保证对任何 Beta-2 值都收敛</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</link>
      <description><![CDATA[Adam 的新修改版 ADOPT 能够实现最佳收敛率，而不管 β₂ 参数选择如何。关键见解是在 Adam 的更新规则中添加一个简单的项，当 β₂ 设置不理想时，该项可以补偿潜在的收敛问题。 技术细节：- ADOPT 通过引入与 (1-β₂) 成比例的附加项来修改 Adam 的更新规则 - 理论分析证明对于任何 β₂ ∈ (0,1)，收敛速度为 O(1/√T) - 适用于凸优化和非凸优化 - 保持 Adam 的实际优势，同时提高理论保证 - 无需额外的超参数调整 关键结果：- 匹配 SGD 的最佳收敛速度以实现平滑的非凸优化 - 在测试场景中，经验上的表现与 Adam 相似或更好 - 通过改变 β₂ 值提供更稳健的收敛行为 - 理论保证在标准平滑度假设下成立 我认为这对于实际的深度学习应用非常有用，因为与学习率调整相比，β₂ 调整经常被忽视。无论 β₂ 选择如何，保证收敛都会减少超参数搜索空间。修改非常简单，可以轻松纳入现有的 Adam 实现中。 但是，我认为我们需要对大规模问题进行更广泛的实证验证，才能充分了解实际影响。理论保证令人鼓舞，但现代架构上的实际性能才是真正的考验。 TLDR：ADOPT 使用一个简单的术语修改 Adam，保证任何 β₂ 值的最佳收敛率，从而可能简化优化器调整同时保持性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</guid>
      <pubDate>Fri, 22 Nov 2024 13:47:40 GMT</pubDate>
    </item>
    </channel>
</rss>