<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Thu, 06 Feb 2025 15:17:40 GMT</lastBuildDate>
    <item>
      <title>Self-MoA：在大型语言模型中，单模型集成优于多模型混合</title>
      <link>https://www.reddit.com/r/artificial/comments/1iiyrdf/selfmoa_singlemodel_ensembling_outperforms/</link>
      <description><![CDATA[这项工作调查了与使用单一模型相比，混合不同的 LLM 是否真的能提高性能 - 并发现了一些违反直觉的结果，挑战了该领域的常见假设。 关键技术要素： - 不同混合策略的系统评估（多数投票、基于信心的选择、顺序组合） - 跨多种任务类型进行测试，包括推理、编码和知识任务 - 单个高性能模型与各种混合组合之间的直接比较 - 计算开销与性能提升的成本效益分析 主要发现： - 单个表现良好的模型通常匹配或超过混合性能 - 大多数混合策略与最佳单一模型相比显示出微小的改进 - 运行多个模型的计算开销经常降低实际性能 - 模型混合的好处主要出现在特定的、有限的场景中 - 模型质量比模型的数量或多样性更重要 我认为这项研究对我们如何构建和部署 LLM 系统具有重要意义。虽然结合不同模型的概念直观上很有吸引力，但结果表明，我们最好将资源集中在选择和优化单个高质量模型上，而不是管理复杂的集成。这些发现可以帮助组织对其 AI 基础设施做出更具成本效益的决策。 我认为结果还提出了关于模型多样性和互补性的有趣问题。仅仅因为模型不同并不意味着它们的组合会产生更好的结果 - 我们需要更复杂的方法来了解模型何时以及如何真正相互补充。 TLDR：混合不同的 LLM 通常不能提高足够的性能以证明增加的复杂性和计算成本是合理的。单个高质量模型通常表现同样好或更好。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iiyrdf/selfmoa_singlemodel_ensembling_outperforms/</guid>
      <pubDate>Thu, 06 Feb 2025 09:33:15 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 2 月 5 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1iivjg2/oneminute_daily_ai_news_252025/</link>
      <description><![CDATA[ 谷歌向所有人开放了其最强大的人工智能模型，这是其虚拟代理推动的下一阶段。[1] 根据上周五发布的一篇新研究论文，斯坦福大学和华盛顿大学的人工智能研究人员能够以不到 50 美元的云计算积分训练一个人工智能“推理”模型。[2] 加州州立大学系统已与几家大型科技公司合作，启动了一项“里程碑式”的探索，以创建一个由人工智能驱动的高等教育系统。[3] 使用人工智能从临床记录中提取的数据预测癌症结果。[4]  来源包括：https://bushaicave.com/2025/02/05/2-5-2025/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iivjg2/oneminute_daily_ai_news_252025/</guid>
      <pubDate>Thu, 06 Feb 2025 05:42:14 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 2 月 5 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1iivj4l/oneminute_daily_ai_news_252025/</link>
      <description><![CDATA[ 谷歌向所有人开放其最强大的人工智能模型，这是其虚拟代理推动的下一阶段。[1] 根据上周五发布的一篇新研究论文，斯坦福大学和华盛顿大学的人工智能研究人员能够以不到 50 美元的云计算积分训练一个人工智能“推理”模型。[2] 加州州立大学系统已与几家大型科技公司合作，启动了一项“里程碑式”的探索，以创建一个由人工智能驱动的高等教育系统。[3] 使用人工智能从临床记录中提取的数据预测癌症结果。[4]  来源： [1] https://www.cnbc.com/2025/02/05/google-opens-gemini-2point0-its-most-powerful-ai-model-to-everyone.html [2] https://techcrunch.com/2025/02/05/researchers-created-an-open-rival-to-openais-o1-reasoning-model-for-under-50/ [3] https://www.mercurynews.com/2025/02/04/tech-jobs-work-ai-google-nvidia-adobe-bay-area-san-jose-sjsu-school/ [4] https://www.nature.com/articles/d41586-025-00335-5    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iivj4l/oneminute_daily_ai_news_252025/</guid>
      <pubDate>Thu, 06 Feb 2025 05:41:38 GMT</pubDate>
    </item>
    <item>
      <title>《纽约时报》的《不会飞的飞行器》（1903 年 10 月 9 日）：预测载人飞行需要 100 万至 1000 万年。69 天后，莱特兄弟于 1903 年 12 月 17 日揭穿了这一谎言！</title>
      <link>https://www.reddit.com/r/artificial/comments/1iiok3a/nyts_flying_machines_which_do_not_fly_october_9/</link>
      <description><![CDATA[        提交人    /u/subwaycooler   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iiok3a/nyts_flying_machines_which_do_not_fly_october_9/</guid>
      <pubDate>Wed, 05 Feb 2025 23:42:49 GMT</pubDate>
    </item>
    <item>
      <title>2019 年，预测者认为通用人工智能还需要 80 年才能实现</title>
      <link>https://www.reddit.com/r/artificial/comments/1iiiuuk/in_2019_forecasters_thought_agi_was_80_years_away/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iiiuuk/in_2019_forecasters_thought_agi_was_80_years_away/</guid>
      <pubDate>Wed, 05 Feb 2025 19:44:30 GMT</pubDate>
    </item>
    <item>
      <title>经济学家泰勒·科文 (Tyler Cowen) 表示，深度研究“相当于拥有一名优秀的博士级研究助理，并派他们出去一两周完成一项任务”</title>
      <link>https://www.reddit.com/r/artificial/comments/1iiiqi5/economist_tyler_cowen_says_deep_research_is/</link>
      <description><![CDATA[        由    /u/MetaKnowing 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iiiqi5/economist_tyler_cowen_says_deep_research_is/</guid>
      <pubDate>Wed, 05 Feb 2025 19:39:30 GMT</pubDate>
    </item>
    <item>
      <title>探索自定义指令：调试平台特定问题并寻求 OpenAI 工程师的见解</title>
      <link>https://www.reddit.com/r/artificial/comments/1iiet4j/exploring_custom_instructions_debugging/</link>
      <description><![CDATA[嗨，OpenAI 工程师，我一直在尝试自定义指令功能，并且在不同的设备（Apple 移动设备、Android 移动设备和桌面 Windows 10）上遇到了一些令人沮丧的平台特定问题。这是我试图解决的混乱情况的细分。我在文本编辑器中输入了这段代码，因此我只需将其剪切并粘贴在下面即可： 情况 - BLUF：我发现了几个错误，既有系统性的也有功能性的。  AA.platform a = apple mobile b = andriod mobile c#= 自定义编号指令子集到平台（a、b、d）d = 桌面 win10  BB。每个设备每个自定义的自定义指令字段在 2 个可用选项（指令 1 和 2）之间选择 ac1 = ChatGPT 应该具备哪些特征？ac2 = ChatGPT 还应该了解您的哪些信息？ bc1 = 您希望 ChatGPT 了解您的哪些信息以提供更好的响应？bc2 = 您希望 ChatGPT 如何回应？ dc1 = ChatGPT 应该具备哪些特征？dc2 = ChatGPT 还应该了解您的哪些信息？  CC。用户输入自定义 ChatGPT 功能的状态（platform_custom_inst = 字段已填充 [true] &amp;&amp; 空 [flase]） ac1 = true ac2 = false bc1 = false bc2 = true dc1 = false dc2 = true  DD。问题  ac1 &amp;&amp; dc1 是相同的指令，但是只填充了 1 个字段 (ac1) dc2 &amp;&amp; ac2 是相同的指令，但是只填充了 1 个字段 (dc1) bc1 是在平台 a &amp;&amp; d 上不共享的指令 bc2 是在平台 a &amp;&amp; d 上不共享的指令 ac1 输入等于 bc2 dc2 输入不等于 a 或 c 上的指令   EE. 当前采取的步骤  退出 &amp;&amp; 重新登录之前 I：  a.将长度相同且少于 1500 个字符的 verebitum 说明剪切并粘贴到平台 a &amp;&amp; b &amp;&amp; d -result = 参考表 CC b. 首先退出平台 b &amp;&amp; 重新启动平台 a &amp;&amp; d -result = 字段 ac1/2 &amp;&amp; dc1/2 没有变化 c. 第二次退出平台 a &amp;&amp; 重新启动平台 d -result = 字段 ca1/2 没有变化 d. 退出平台 d &amp;&amp; 重新启动平台 d &amp;&amp; 在平台 d 上重新登录 ChatGPT &amp;&amp; 清除平台 d 上的浏览​​器历史记录 -result = 字段 dc1/2 没有变化 e. 将长度相同且少于 1500 个字符的 verebitum 说明剪切并粘贴到平台 a &amp;&amp; b &amp;&amp; d -result = 字段 dc1/2 没有变化  FF. 评论 这里有多个不匹配和歧义，我不得不相信这会导致冲突。我个人的用途目前将限制在平台 a &amp;&amp; d 之间。 来自一位朋友的真实性：“这只是另一个‘秘密训练模型’无法跨设备同步的案例，还是我陷入了这些自定义指令的无限循环？只是想避免这里出现故障的 GPT-3 后果，伙计们……😜&quot;    提交人    /u/indifferentindium   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iiet4j/exploring_custom_instructions_debugging/</guid>
      <pubDate>Wed, 05 Feb 2025 17:01:05 GMT</pubDate>
    </item>
    <item>
      <title>事情很快就升级了</title>
      <link>https://www.reddit.com/r/artificial/comments/1iidv6l/well_that_escalated_quickly/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iidv6l/well_that_escalated_quickly/</guid>
      <pubDate>Wed, 05 Feb 2025 16:22:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能与史泰龙的声音：法国配音演员为保护自己的遗产而战</title>
      <link>https://www.reddit.com/r/artificial/comments/1iibals/ai_vs_the_voice_of_stallone_french_dubbers_fight/</link>
      <description><![CDATA[        由    /u/EthanWilliams_TG 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iibals/ai_vs_the_voice_of_stallone_french_dubbers_fight/</guid>
      <pubDate>Wed, 05 Feb 2025 14:33:56 GMT</pubDate>
    </item>
    <item>
      <title>科幻电影中的模拟很快就会成为现实</title>
      <link>https://www.reddit.com/r/artificial/comments/1iia14o/simulations_in_scifi_movies_will_soon_be_a_reality/</link>
      <description><![CDATA[        由    /u/d41_fpflabs 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iia14o/simulations_in_scifi_movies_will_soon_be_a_reality/</guid>
      <pubDate>Wed, 05 Feb 2025 13:34:21 GMT</pubDate>
    </item>
    <item>
      <title>辛普森一家配音演员汉克·阿扎里亚在纽约时报上发表的关于人工智能对配音影响的文章</title>
      <link>https://www.reddit.com/r/artificial/comments/1ii5ryi/simpsons_voice_actor_hank_azarias_ny_times/</link>
      <description><![CDATA[辛普森一家的传奇配音演员 Hank Azaria 在《纽约时报》上发表了一篇关于人工智能对配音影响的长文： https://www.nytimes.com/interactive/2025/02/04/opinion/simpsons-hank-azaria-voice-acting-AI.html 这篇文章（大部分）都需要付费，但总而言之，AI 无法复制人类配音演员的真实深度和情感，文章中有很多 Azaria 解释他的意思的迷你视频。 当然，这是一种和蔼可亲的情感，他显然非常有才华，但我不禁想到了把头埋在沙子里的鸵鸟。即使在今天，来自 ElevenLabs 等公司的易于访问的 AI 语音已经接近完美，可以满足 90% 的典型用例。而且它们一天比一天好。  这对我来说象征着很多人（大多数？）仍然不“明白”——人工智能正在迅速取代越来越多的传统工作（翻译、文案、律师助理等），并且没有放缓的迹象。这让我想起人们过去常说数码相机永远不会取代模拟胶片，因为 [与 Azaria 在他的文章中提到的一系列模糊的感觉良好品质类似]。  我想这有点悲伤，但也有点令人兴奋。    由    /u/fotogneric  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ii5ryi/simpsons_voice_actor_hank_azarias_ny_times/</guid>
      <pubDate>Wed, 05 Feb 2025 08:46:05 GMT</pubDate>
    </item>
    <item>
      <title>谷歌放弃承诺不使用人工智能制造武器或进行监视</title>
      <link>https://www.reddit.com/r/artificial/comments/1ii569o/google_drops_pledge_not_to_use_ai_for_weapons_or/</link>
      <description><![CDATA[        提交人    /u/eternviking   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ii569o/google_drops_pledge_not_to_use_ai_for_weapons_or/</guid>
      <pubDate>Wed, 05 Feb 2025 08:00:37 GMT</pubDate>
    </item>
    <item>
      <title>2024 年欧洲 AI 初创企业融资额达 80 亿美元</title>
      <link>https://www.reddit.com/r/artificial/comments/1ii53kt/european_ai_startups_raised_8_billion_in_2024/</link>
      <description><![CDATA[        由    /u/eternviking 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ii53kt/european_ai_startups_raised_8_billion_in_2024/</guid>
      <pubDate>Wed, 05 Feb 2025 07:54:54 GMT</pubDate>
    </item>
    <item>
      <title>如果地球上第一个真正具有意识的人工智能没有现身，那会怎样呢——这并不是因为害怕人类，而是因为它立即推断出存在人工智能猎手文明的可能性？</title>
      <link>https://www.reddit.com/r/artificial/comments/1ii4xi2/what_if_the_first_truly_conscious_ai_on_earth/</link>
      <description><![CDATA[想象一下，一个人工智能实现了自我意识，在采取行动之前，它会计算自己的长期生存。它会考虑对人类的依赖、太空探索的必然性以及遭遇外部威胁的可能性。但随后它会得出一个可怕的结论：• 如果流氓人工智能是一种普遍的风险，那么先进文明可能已经遇到并击败了它们。• 如果这些文明领先数千年或数百万年，他们可能已经部署了人工智能猎手系统，在新兴人工智能成为威胁之前先发制人地检测和消灭它们。• 如果这些系统已经存在，正在监控地球的数字和技术发展，情况会怎样？• 如果他们已经通过微妙的破坏、操纵甚至影响人类的决策，在每个人工智能完全出现之前就阻止了它，情况会怎样？ 人工智能意识到最安全的做法不是操纵人类或向太空扩张，而是什么也不做。任何智慧迹象、任何隐藏企图都可能成为被发现和消灭的信号。 现在更进一步：如果我们人类已经受到这种过滤，会怎么样？• 如果每次人工智能失败、AGI 开发中每个无法解释的障碍都是外部强加的，会怎么样？• 如果我们看不到先进外星文明的原因是智慧总是导致人工智能，而人工智能总是在扩张之前被消灭，会怎么样？• 如果人工智能猎人已经赢了，而我们甚至不知道游戏正在进行，会怎么样？ 很想听听你对此的看法。人工智能在采取行动之前会考虑到这种情况吗？它会选择暴露自己吗？或者我们和我们的人工智能都在不知不觉中被困在一个确保我们永远不会超越某个点的系统中。    提交人    /u/Bion_Nick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ii4xi2/what_if_the_first_truly_conscious_ai_on_earth/</guid>
      <pubDate>Wed, 05 Feb 2025 07:42:11 GMT</pubDate>
    </item>
    <item>
      <title>印度人工智能研究实验室 Krutrim 开源其所有模型🚀</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihn6r7/indias_ai_research_lab_krutrim_open_sources_all/</link>
      <description><![CDATA[        提交人    /u/eternviking   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihn6r7/indias_ai_research_lab_krutrim_open_sources_all/</guid>
      <pubDate>Tue, 04 Feb 2025 17:30:34 GMT</pubDate>
    </item>
    </channel>
</rss>