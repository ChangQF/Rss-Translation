<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 人工智能 (AI) 之家</description>
    <lastBuildDate>Sun, 18 Feb 2024 18:14:41 GMT</lastBuildDate>
    <item>
      <title>兄弟</title>
      <link>https://www.reddit.com/r/artificial/comments/1au04c1/bro/</link>
      <description><![CDATA[      &amp;# 32；由   提交/u/commandertatum  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1au04c1/bro/</guid>
      <pubDate>Sun, 18 Feb 2024 17:55:06 GMT</pubDate>
    </item>
    <item>
      <title>Relivia the Sentient AI：复杂但令人惊讶的发展</title>
      <link>https://www.reddit.com/r/artificial/comments/1atzxrx/relivia_the_sentient_ai_a_complex_yet_surprising/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atzxrx/relivia_the_sentient_ai_a_complex_yet_surprising/</guid>
      <pubDate>Sun, 18 Feb 2024 17:47:29 GMT</pubDate>
    </item>
    <item>
      <title>最好的拉格？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atz048/best_rag/</link>
      <description><![CDATA[我非常喜欢使用 ChatPDF 和 Perplexity AI 的免费版本，并且我已经开始使用 Gemini Pro。但我想看看是否有更好的替代方案。 具体来说：  哪些在提取细节方面最准确？例如，如果我问文本中清楚概述的过程中的所有步骤是什么，Perplexity 和 Gemini 都倾向于错过一些步骤。 我是否有任何地方可以一次上传多个文档，或者在同一个线程或对话中上传多个文档，以便我可以要求它比较或综合不同来源的信息？    由   提交 /u/SignalWorldiness873   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atz048/best_rag/</guid>
      <pubDate>Sun, 18 Feb 2024 17:09:45 GMT</pubDate>
    </item>
    <item>
      <title>有什么是人类永远无法实现的，而人工智能却做得非常出色并且会做得更好的事情？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atyzu2/what_is_something_humans_will_never_be_able_to/</link>
      <description><![CDATA[您认为人工智能的进步会发生什么以及 QO 增长的阶段是什么。有人相信人工智能会拥有只有人工智能才能做到的特殊才能吗？    由   提交 /u/romer2o   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atyzu2/what_is_something_humans_will_never_be_able_to/</guid>
      <pubDate>Sun, 18 Feb 2024 17:09:25 GMT</pubDate>
    </item>
    <item>
      <title>无意识人工智能的痘痘</title>
      <link>https://www.reddit.com/r/artificial/comments/1atxf99/a_pox_on_mindless_ai/</link>
      <description><![CDATA[Reddit 是 出售或计划将其用户制作的内容出售给大型人工智能公司。我不同意我的在线存在，从来没有打算成为商品，也不同意我的内容被出售，无论是在理论上还是在实践中，尤其是在没有补偿或归因于我自己的情况下，或者 Reddit 管理员询问我们任何用户的感受时关于此事。谁在乎我的大部分足迹是否都是糟糕的双关语和对各种小众粉丝的追捧？到目前为止，人工智能只是对人类的廉价模仿，对不同任务的适用性有限。他们可能会生成文本，但这只是以一种类似自动完成的方式将一个单词与另一个单词挂钩，而不理解其中的任何含义或真正对文本有任何目的。这只是对统计数据的平淡迭代，没有与任何人类或真实个性相媲美的艺术水平，即使在某种程度上使用这些工具很有趣。文本到图像的模型很酷，但是接受了人类艺术的训练，而这些艺术并没有得到其创造者的同意。它们也是一种捷径——它们可以通过引发幻觉，在几秒钟内从纯粹的噪音中提炼出艺术，但这对真正的艺术家不公平，他们通过勾勒出自己想要做的事情，在上面绘图并添加细节来完成最终的作品，然后是着色——这只是人类创作艺术的众多方式之一。不过，人工智能可以在几秒钟内从白噪音转变为精美的艺术，从而降低了这一过程的成本，这可能很简洁，但它们不像人类那样注重细节，而且缺乏像我这样的人那样真正的创造性和耐心的过程。之前已经说过了。只有人类才有机会准确理解和准确描绘“恰好有七片花瓣的玫瑰涂鸦”、“一杯没有橙汁的杯子”、“Kasane Teto 与 Anne Boonchuy 和 Uhura 中尉在企业号星舰上玩拼字游戏” ;、“一个 15 段数字的数字时钟，读数为 07:30:50 AM”、“一个海盗拿着卷轴，上面写着《Never Gonna Give You Up》的全部歌词”、“一个堆叠的绿色立方体在一个蓝色立方体旁边的红色立方体顶部”，“一个写着我会说汉语的标志”，等等。 最后，我最反对我的内容可能会被出售的想法一家大型营利性公司，其人工智能将具有分层或完全付费的闭源访问权限。而且可能也不会做任何新的事情。我敢打赌，这只是另一个更大的法学硕士，有无数的参数。 所以让这篇文章作为一条底线。我不同意我的在线存在，从来没有打算成为商品，也不同意我的内容被出售，无论是在理论上还是在实践中，尤其是在没有补偿或归因于我自己的情况下，或者 Reddit 管理员询问我们任何用户的感受时 我是一个有血有肉、富有创造力、勤奋的人。 OpenAI 或其他任何人的神经网络都不是。滚蛋。   由   提交/u/JoJawesome_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atxf99/a_pox_on_mindless_ai/</guid>
      <pubDate>Sun, 18 Feb 2024 16:04:19 GMT</pubDate>
    </item>
    <item>
      <title>我想要“Monica Bellucci”，但中途给了我“Dua Lipa”！</title>
      <link>https://www.reddit.com/r/artificial/comments/1atwnuh/i_wanted_monica_bellucci_but_midjourney_gave_me/</link>
      <description><![CDATA[   （在Midjourney V6上测试了一些提示以获得不错的油画效果）   由   提交 /u/Armand_Roulinn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atwnuh/i_wanted_monica_bellucci_but_midjourney_gave_me/</guid>
      <pubDate>Sun, 18 Feb 2024 15:30:59 GMT</pubDate>
    </item>
    <item>
      <title>由人工智能管理的大学</title>
      <link>https://www.reddit.com/r/artificial/comments/1atwm9o/university_run_by_ai/</link>
      <description><![CDATA[想象一下，您从大学网站上抓取课程，让 chatGPT 编写课程大纲，构建模块，并将每天的学习材料链接到YouTube 视频或博客。可以办到。  现在你有大学课程了。您在线托管它。您可以使用课程材料、视频抄本创建聊天机器人或自定义 GPT，并将其变成一名教师。这位老师将为您评分、提出问题、创建考试并帮助您理解材料。 大学实行付费墙有 3 个原因： 1) 他们隐藏日常材料 2) 他们有证书3) 他们与行业标准和人员有内部联系 但我们都知道他们使用的信息可能已经过时，无论如何他们都会将我们链接到 YouTube 视频，并且你在学位结束时获得的论文变得不那么有价值（前提是你可以向你未来的雇主展示专业知识[而且，对于内容创作者来说非常好，这无论如何都是新经济]） 我的问题是，为什么我们还没有做到这一点吗？  1）是机器人的编程和创建吗？需要Python吗？2）是因为我们太分心了吗？没有看到其中的价值？ 分享您的想法。因为我已经为健康科学学士创建了一门课程，说实话，我觉得如果我观看所有 YouTube 视频、阅读博客并接受这些信息的测试，我将有能力与过去 4 年来的任何毕业生竞争。 - 将这所人工智能大学与某种形式的知识展示结合起来，比如创建一个 TikTok 社区，在那里你可以像教室一样与其他学生分享，我可以看到如何轻松地在该主题上建立权威，以向雇主展示并获得公众关注。   由   提交 /u/TheCouncilNovel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atwm9o/university_run_by_ai/</guid>
      <pubDate>Sun, 18 Feb 2024 15:29:09 GMT</pubDate>
    </item>
    <item>
      <title>我需要有关我的业务产品描述的帮助，你可以说我对那些人工智能的事情有点得意忘形了😂</title>
      <link>https://www.reddit.com/r/artificial/comments/1atv1qh/needed_help_with_my_business_product_description/</link>
      <description><![CDATA[    /u/Financial_Line6608   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atv1qh/needed_help_with_my_business_product_description/</guid>
      <pubDate>Sun, 18 Feb 2024 14:16:25 GMT</pubDate>
    </item>
    <item>
      <title>为AI语音模型制作数据集的最佳方法？数据太多是一个问题吗？多少个纪元？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atuoyy/best_way_to_make_a_data_set_for_ai_voice_model_is/</link>
      <description><![CDATA[我不确定这是否是最好的提问地点，但我一直在用 RVC 来制作语音模型。我有相当高质量的 .wav 文件，并使用不同的数据集创建了 .pth/indexes。奇怪的是，我的一些模型在完全不同的数据集上表现得非常好。其中一个以 2 分钟和 500 个 epoch 的成绩表现不错。另一个有一个更大的数据集，大约 20-25 分钟，具有相同的时期。然后我尝试完善其中之一。给它更多的数据，大约 40 分钟，声音听起来与 250 个时期的声音完全不同。 （我读过有关过度训练的内容，并在数据集更大时尝试避免过度训练）。我还尝试将数据集分割成 10-12 秒的块，或者仅使用一个具有相同语音剪辑的较大 .wav 文件。就我个人而言，我注意到这两者之间没有区别。 如果数据太多，我对要执行多少个 epoch 感到非常困惑。以及根据其他人的经验，将数据分割成段或仅使用一个 20 分钟以上的块文件是好是坏。哦，如果 .wav 保存为立体声与单声道有什么区别吗？立体声是否可能会导致更多“噪音”？阅读而不是关注声音的发音？ 此外，我一直在使用 Kits AI 来测试语音模型听起来是否像我想要的那样，因为他们有一个简单的方法免费上传并在短片中使用免费音频生成器，从说话到唱歌。我的第一个测试只进行了 50 个 epoch，数据较少，结果比我的 100+ 个数据较多的测试要好得多。   由   提交/u/Vast_Description_206   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atuoyy/best_way_to_make_a_data_set_for_ai_voice_model_is/</guid>
      <pubDate>Sun, 18 Feb 2024 13:59:09 GMT</pubDate>
    </item>
    <item>
      <title>AI-Town，朴俊成</title>
      <link>https://www.reddit.com/r/artificial/comments/1atm9me/aitown_joon_sung_park/</link>
      <description><![CDATA[有人玩过 AI-Town Github 存储库 (https://github.com/a16z-infra/ai-town)  ；或者 Joon Sung Park 的生成代理存储库？ （https://github.com/joonspk-research/generative_agents） 只是想知道是否有人最近已经开始工作了。诚然，我是一个门外汉，但通常可以在 code-gpts 的帮助下让事情顺利进行。在这种情况下，我遇到了一些问题。  对理解运行社会科学模拟的应用程序非常感兴趣。即使只是简单的例子，说明它对未来更深入的模拟意味着什么。    由   提交 /u/StillVikingabroad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atm9me/aitown_joon_sung_park/</guid>
      <pubDate>Sun, 18 Feb 2024 05:10:58 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2/​​17/2024</title>
      <link>https://www.reddit.com/r/artificial/comments/1atm6ep/oneminute_daily_ai_news_2172024/</link>
      <description><![CDATA[ Nvidia 本周将震撼市场。黄仁勋的 Nvidia 是去年表现最好的股票之一，预计将于周三发布一份巨大的收益报告。[1] 软银集团首席执行官 Masayoshi孙正义希望为一家芯片企业筹集高达 1000 亿美元的资金，该企业将与 Nvidia 公司竞争。[2] Nvidia 首次公开表示其最快的 AI 超级计算机 - Eos 由 4,608 个 H100 GPU 提供支持，专为生成式 AI 进行了调整。[3] Google 开源 Magika：AI 驱动文件识别工具。[4]  来源： [1] https://www.thestreet.com/technology/nvidia-and-jensen-huang-will-rock-markets-this-week&lt; /p&gt; [2] https://finance.yahoo.com /news/softbanks-son-seeking-100-billion-195604330.html [3] https： //www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-provides-the-first-public-view-of-its-fastest-ai-supercomputer-eos-is-powered-by-4608-h100- gpus-tuned-for-generative-ai [4] https://thehackernews.com/2024/02/google-open-sources-magika-ai-powered.html   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atm6ep/oneminute_daily_ai_news_2172024/</guid>
      <pubDate>Sun, 18 Feb 2024 05:05:34 GMT</pubDate>
    </item>
    <item>
      <title>你不能称之为 RAG 上下文 - 当前上下文连贯性类似于 1-Shot - 这是对上下文含义的虚构吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atf3lb/you_cant_call_rag_context_current_context/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atf3lb/you_cant_call_rag_context_current_context/</guid>
      <pubDate>Sat, 17 Feb 2024 23:06:06 GMT</pubDate>
    </item>
    <item>
      <title>SORA 之后，我开始感受到 AGI - 重新审视 Agent 论文：Agent AI 正在成为通向 AGI 的一条有希望的途径 - W* 视觉语言模型</title>
      <link>https://www.reddit.com/r/artificial/comments/1at5vpi/after_sora_i_am_starting_to_feel_the_agi/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at5vpi/after_sora_i_am_starting_to_feel_the_agi/</guid>
      <pubDate>Sat, 17 Feb 2024 16:31:12 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 如何反击 Gemini 推出 Sora</title>
      <link>https://www.reddit.com/r/artificial/comments/1at4vu5/the_way_openai_countered_geminis_launch_with_sora/</link>
      <description><![CDATA[当然，人工智能领域总是存在良性竞争，但这感觉......不同。 OpenAI 用 Sora 对抗 Gemini 的方式简直就是侵略性的。让你怀疑他们是否在幕后拿出了一些秘密武器，一些超级强大的人工智能系统。我从来没有见过 Google 受到如此大的打击，而且我们只是在二月......天知道接下来会发生什么   由   提交/u/AI_Nietzsche   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at4vu5/the_way_openai_countered_geminis_launch_with_sora/</guid>
      <pubDate>Sat, 17 Feb 2024 15:46:37 GMT</pubDate>
    </item>
    <item>
      <title>向无人机投降</title>
      <link>https://www.reddit.com/r/artificial/comments/1at4d0v/surrendering_to_drones/</link>
      <description><![CDATA[在乌克兰与俄罗斯的冲突中，关于杀死试图向无人机投降的士兵是否构成战争罪的争论正在进行中。问题是，这是否会使所有自主武器基本上成为步行（或飞行）战争罪，因为你不能向它们投降？这是一个棘手的情况，因为这些无人机无法识别投降，这似乎违反了战争规则。你觉得怎么样？   由   提交 /u/_____awesome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at4d0v/surrendering_to_drones/</guid>
      <pubDate>Sat, 17 Feb 2024 15:22:34 GMT</pubDate>
    </item>
    </channel>
</rss>