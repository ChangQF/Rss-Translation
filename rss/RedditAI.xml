<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Mon, 04 Nov 2024 09:19:41 GMT</lastBuildDate>
    <item>
      <title>人工智能不擅长编码，我受够了</title>
      <link>https://www.reddit.com/r/artificial/comments/1gj58j2/ai_is_not_good_in_coding_im_fed_up/</link>
      <description><![CDATA[在过去的 48 小时里，我一直在开发一个 wifi 项目，我以为它会成功，但是我真的尝试了 java、kotlin、android studio、react native、flutter、python。光标  现在什么都不起作用，甚至都不起作用，整个代码都很糟糕，有时候可能没有错误，但仍然什么都不起作用，有时候我直接得到 210 错误。 伙计们，如果有人可以制作这个应用程序，请像我想要一个具有美观用户界面的简单应用程序一样，但它甚至不起作用，我必须将这个项目提交给老师。 我以为人工智能会让我的工作变得轻松，另一方面，它真的浪费了我过去 3 天没睡觉的 48 个小时     提交人    /u/No_Bottle804   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gj58j2/ai_is_not_good_in_coding_im_fed_up/</guid>
      <pubDate>Mon, 04 Nov 2024 03:32:34 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 3 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gj4lmg/oneminute_daily_ai_news_1132024/</link>
      <description><![CDATA[ Meta 和 Google 使用用户评论或评价作为生成式 AI 对餐厅查询的响应或总结情绪的一部分，可能会带来新的诽谤风险。[1] Decart 的 AI 模拟了 Minecraft 的实时可玩版本。[2] AI 聊天机器人是新的牧师。[3]我永远不会向人工智能爸爸坦白。 这是根据堪萨斯大学寿命研究所的一项新研究得出的结论，该研究发现，寻求有关孩子健康信息的父母比人类医疗保健专业人员更倾向于使用人工智能。[4]  来源： [1] https://www.theguardian.com/technology/2024/nov/04/google-meta-efamation-ai-generated-responses-australia [2] https://techcrunch.com/2024/10/31/decarts-ai-simulates-a-real-time-playable-version-of-minecraft/ [3] https://www.businessinsider.com/rise-of-godgpt-religions-christians-using-chatbots-spiritual-formation-2024-11 [4] https://www.foxnews.com/health/parents-trust-ai-medical-advice-more-doctors-researchers-find    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gj4lmg/oneminute_daily_ai_news_1132024/</guid>
      <pubDate>Mon, 04 Nov 2024 02:57:40 GMT</pubDate>
    </item>
    <item>
      <title>这件事发生在今天。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gj3wtp/this_happened_today/</link>
      <description><![CDATA[我使用 Open AI 助手帮我寻找演示文稿的源材料。我以前做过这个，它通常会给我很好的材料来补充演示文稿。结果我得到了这个视频。我从来没有要求过它，对话也没有讽刺或喜剧性。真的很令人困惑。我知道这看起来像个笑话，但它确实发生了，具体来说是今天。     提交人    /u/mindatetheuniverse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gj3wtp/this_happened_today/</guid>
      <pubDate>Mon, 04 Nov 2024 02:20:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可能成为美国总统吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gj3tay/could_an_artificial_intelligence_become_president/</link>
      <description><![CDATA[人工智能超级智能能成为美国总统吗？    提交人    /u/Der_Ist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gj3tay/could_an_artificial_intelligence_become_president/</guid>
      <pubDate>Mon, 04 Nov 2024 02:14:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理的剖析</title>
      <link>https://www.reddit.com/r/artificial/comments/1gj2hn6/the_anatomy_of_an_ai_agent/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gj2hn6/the_anatomy_of_an_ai_agent/</guid>
      <pubDate>Mon, 04 Nov 2024 01:06:18 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻</title>
      <link>https://www.reddit.com/r/artificial/comments/1giz5r0/heres_what_is_making_news_in_the_ai_world/</link>
      <description><![CDATA[焦点 - 前 Twitter/X 挑战者 Pebble 的 CEO Gabor Cselle 刚刚加入 OpenAI！以下是我们所知道的（我为整个故事写了另一篇文章） - 微软商业软件部门前首席 AI 官 Sophia Velastegui 在接受 Tech Crunch 采访时认为 AI 发展得太快了 - 数据管理公司 DataStax 的 CEO 表示“没有数据就没有 AI，没有非结构化数据就没有 AI，没有大规模非结构化数据就没有 AI，” - Verge 发表了一篇关于最近 AI 搜索引擎出现 — — 并且越来越好的精彩文章    提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1giz5r0/heres_what_is_making_news_in_the_ai_world/</guid>
      <pubDate>Sun, 03 Nov 2024 22:29:40 GMT</pubDate>
    </item>
    <item>
      <title>以下是 AI 领域的新闻（前 Twitter/X Challenger Pebble 首席执行官 Gabor Cselle 刚刚加入 OpenAI！以下是我们所知道的消息）</title>
      <link>https://www.reddit.com/r/artificial/comments/1giz1vi/heres_what_is_making_news_in_the_ai_world_former/</link>
      <description><![CDATA[我刚看到一些有趣的消息，我想你们可能都想讨论一下。 看起来 Gabor Cselle（是的，Pebble/T2 的那个家伙）已经悄悄加入了 OpenAI！他昨天在 X 上透露了这一信息，对他在那里的工作内容讳莫如深。典型的技术保密，对吧？ 😅 给不认识他的人介绍一下他的背景： - 创立了 reMail（已出售给 Google） - 创立了 Namo Media（已出售给 Twitter） - 在马斯克时代之前曾担任 Twitter 的产品经理 - 最近创建了 Pebble（RIP），试图成为 Twitter 的替代品 - 根据他的 LinkedIn，他从 10 月开始就一直在 OpenAI 工作 有趣的是，在去年 Pebble 关闭后（现在它只是 Mastodon 的一个实例），他在 South Park Commons 研究一些 AI 的东西。他正在研究生成式 AI，包括一些受 HQ 琐事启发的东西。 哦，这里有一个有趣的巧合 - 当 OpenAI 得到 Cselle 时，他们的竞争对手 Anthropic 刚刚聘请 Alex Rodrigues（Embark 自动驾驶卡车司机）担任 AI 安全研究员。看来现在人工智能领域有很多人才流动。     提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1giz1vi/heres_what_is_making_news_in_the_ai_world_former/</guid>
      <pubDate>Sun, 03 Nov 2024 22:24:46 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI AGI Readiness 团队前负责人 Miles Brundage 表示，毫无疑问，人工智能的发展非常迅速，这一点很明显，因为许多没有炒作动机的人都在警告这一点</title>
      <link>https://www.reddit.com/r/artificial/comments/1givsjd/miles_brundage_exhead_of_openais_agi_readiness/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1givsjd/miles_brundage_exhead_of_openais_agi_readiness/</guid>
      <pubDate>Sun, 03 Nov 2024 20:02:43 GMT</pubDate>
    </item>
    <item>
      <title>尤瓦尔·诺亚·哈拉里说，人工智能可能会把我们困在一个充满幻想和妄想的世界中，我们会误以为它们是现实，而互联网的信息网络会把我们包裹起来，形成一个茧</title>
      <link>https://www.reddit.com/r/artificial/comments/1givn3w/yuval_noah_harari_says_ai_may_trap_us_in_a_world/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1givn3w/yuval_noah_harari_says_ai_may_trap_us_in_a_world/</guid>
      <pubDate>Sun, 03 Nov 2024 19:56:24 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 2 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1giazr9/oneminute_daily_ai_news_1122024/</link>
      <description><![CDATA[ Anthropic 推出 Claude 3.5 Sonnet，可对 100 页以下的图像、图表和图形进行可视化 PDF 分析。[1] Quantum Machines 和 Nvidia 使用机器学习来更接近纠错量子计算机。[2] Runway 为 Gen-3 Alpha Turbo 配备新的 AI 摄像头控制，实现 3D 化。[3] 科学家利用 AI 将 134 年前的照片变成失落的寺庙浮雕的 3D 模型。[4]  来源： [1] https://analyticsindiamag.com/ai-news-updates/anthropic-introduces-claude-3-5-sonnet-with-visual-pdf-analysis-for-images-charts-and-graphs-under-100-pages/ [2] https://techcrunch.com/2024/11/02/quantum-machines-and-nvidia-use-machine-learning-to-get-closer-to-an-error-corrected-quantum-computer/ [3] https://venturebeat.com/ai/runway-goes-3d-with-new-ai-video-camera-controls-for-gen-3-alpha-turbo/ [4] https://gizmodo.com/scientists-use-ai-to-turn-134-year-old-photo-into-3d-model-of-lost-temple-relief-2000519484    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1giazr9/oneminute_daily_ai_news_1122024/</guid>
      <pubDate>Sun, 03 Nov 2024 00:42:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是否帮助了 Shazam 音乐识别，以便我可以轻松哼唱一首歌曲？</title>
      <link>https://www.reddit.com/r/artificial/comments/1ghx7y9/has_ai_helped_shazam_music_identification_so_i/</link>
      <description><![CDATA[作为一个患有自闭症的孩子，我的脑海里总是回荡着旋律。交响乐、歌曲、节拍等等。但我永远搞不清楚自己是在歌曲中听到的，还是自己编的。但没有办法查找。 几十年后，Shazam 问世了，它可以听歌，但你不能哼唱。后来又出现了一种类似“对着麦克风唱歌”的功能，但几乎没有用。要么是因为我唱歌不好，要么是 Siri 的歌唱水平更差。 所以在这里，我想问：人工智能对此有帮助吗？想象一下 chatGPT 是一个总是知道那是什么歌的人。即使您几乎记不住歌词或旋律，也几乎不会唱歌。 这已经是事了吗？    提交人    /u/Aion2099   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ghx7y9/has_ai_helped_shazam_music_identification_so_i/</guid>
      <pubDate>Sat, 02 Nov 2024 14:06:45 GMT</pubDate>
    </item>
    <item>
      <title>一个可公开访问、用户可定制的推理模型，使用 GPT-4o mini 作为推理器。</title>
      <link>https://www.reddit.com/r/artificial/comments/1ghjcfh/a_publicly_accessible_user_customizable_reasoning/</link>
      <description><![CDATA[      可在 Sirius Model IIe 获得 好的，首先，我在我的网站上登录后得到了大量 AI 的自我提示，然后我将其与 Claude 和其他 AI 一起变成了一个推理模型。事实证明，Claude 是一个很棒的推理者，但以这种格式运行成本太高，所以我想我会只使用 GPT-4o mini 和三个步骤来公开演示一个残缺的推理模型。我担心这会造成太多流量，但实际上并没有，所以我取消了许多限制，并将其设置为最多六个推理步骤和用户可自定义的子提示。 它看起来像这样： Sirius IIe 模型 工作原理：它将带有“主”系统消息的用户提示发送到 GPT-4o mini 的事件。它从以插槽 1 开始的插槽之一中添加系统消息的第二部分，然后实例提供响应。在响应结束时，它可以调用另一个推理“槽”（通常是槽 2），从而它再次使用主系统消息和“槽 2”中的子系统消息提示 API 服务器，并且它还读取消息中的先前上下文，然后提供响应等等。直到它进行六个推理步骤或提供解决方案。 至少我认为它就是这样工作的。你可以让它以不同的方式工作。    提交人    /u/rutan668   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ghjcfh/a_publicly_accessible_user_customizable_reasoning/</guid>
      <pubDate>Fri, 01 Nov 2024 23:43:54 GMT</pubDate>
    </item>
    <item>
      <title>人类和人工智能推理之间的差异</title>
      <link>https://www.reddit.com/r/artificial/comments/1ghj2to/the_difference_between_human_and_ai_reasoning/</link>
      <description><![CDATA[较旧的 AI 模型显示出一定的泛化能力，但 O1 之前的模型并没有直接受到推理激励。这与人类有着根本的不同：​​我们的边缘系统可以选择其奖励功能，并奖励我们做出正确的推理步骤。关键区别在于，较旧的模型仅根据结果而不是推理过程本身获得 RLHF 奖励。 人类与 O1 模型之间的当前差距集中在灵活性上：AI 无法选择其奖励功能。这种限制会影响更高级别的能力，例如创造力和自主目标设定（例如最大化利润）。我们本质上是将这些模型变成推理引擎。 然而，人类和人工智能之间有显着的相似之处：  两者都使用“系统 1”思维：我们生成模式匹配的数据序列。在人类中，我们称之为想象力；在模型中，我们称之为输出。想象力本质上是预测的输出，它并不实际存在。这正是模型所做的事情，也是我们所做的事情（与千脑柱理论有关）。 两者都有可能在生成的数据上进行训练。模型可以使用它们的输出进行进一步的训练（尽管这可能需要评估函数）。人类在睡眠期间可能会做类似的事情。 两者都可以通过评估来改善系统 1 思维。借助评估函数，模型可以提高其生成性能以匹配其评估能力。这是有道理的，因为验证答案通常比最初生成一个好的答案更容易。人类也可以做到这一点。  这里的关键方面是，虽然模型正在成为更复杂的推理引擎，但它们仍然缺乏人类通过边缘系统拥有的灵活、自我导向的奖励系统。    提交人    /u/PianistWinter8293   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ghj2to/the_difference_between_human_and_ai_reasoning/</guid>
      <pubDate>Fri, 01 Nov 2024 23:31:40 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中的奖励函数：介于刚性与适应性之间</title>
      <link>https://www.reddit.com/r/artificial/comments/1ghil6v/reward_functions_in_ai_between_rigidity_and/</link>
      <description><![CDATA[人类和人工智能推理之间的关系揭示了奖励函数设计中一种有趣的张力。虽然人类大脑通过其边缘系统具有非常灵活的奖励系统，但当前的人工智能架构依赖于更严格的奖励结构 - 这可能并非完全是负面的。 考虑一下 O1 的推理方法：它因正确的推理步骤和实现正确的结果而获得奖励。这种严格的奖励结构有意将模型塑造为逐步的逻辑推理。这就像有一位严格但有效的老师，他坚持展示你的工作，而不仅仅是得到正确的答案。 一个真正适应性的奖励系统，类似于人类认知，将以不同的方式运作。它可以：  动态地将注意力集中在验证单个推理步骤上 在优先考虑逻辑严谨性和其他目标（优雅性、新颖性、清晰度）之间转换 根据上下文调整其成功标准 选择何时优先考虑推理而不是其他目标  但是，这种比较提出了一个重要的问题：完全的奖励函数适应性真的可取吗？对齐问题 - 确保人工智能系统与人类价值观和兴趣保持一致 - 表明允许模型修改自己的奖励函数可能会有风险。O1 对推理步骤的严格关注可能是一个特性，而不是一个错误。 人类边缘系统的灵活性既是优点也是弱点。虽然它使我们能够自适应地应对各种情况，但它也可能导致我们优先考虑即时满足而不是逻辑严谨性，或者优先考虑新颖性而不是准确性。相比之下，O1 的固定奖励结构始终关注合理推理。 也许理想情况介于两者之间。我们可能希望系统能够灵活地分配注意力并在精心划定的范围内调整其评估标准，同时与逻辑一致性和真实性等核心目标保持严格一致。这将把自适应评估的好处与约束优化的安全性结合起来。    提交人    /u/PianistWinter8293   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ghil6v/reward_functions_in_ai_between_rigidity_and/</guid>
      <pubDate>Fri, 01 Nov 2024 23:09:07 GMT</pubDate>
    </item>
    <item>
      <title>Oasis，第一个可玩的、实时的、开放世界的 AI 模型。</title>
      <link>https://www.reddit.com/r/artificial/comments/1ghc96f/oasis_the_first_playable_realtime_openworld_ai/</link>
      <description><![CDATA[      https://preview.redd.it/4w71epuw1cyd1.png?width=480&amp;format=png&amp;auto=webp&amp;s=79e970396f76e1871006ac7308e26a6e51731d22 https://oasis-model.github.io/ https://oasis.us.decart.ai/starting-point    由   提交  /u/Targed1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ghc96f/oasis_the_first_playable_realtime_openworld_ai/</guid>
      <pubDate>Fri, 01 Nov 2024 18:25:38 GMT</pubDate>
    </item>
    </channel>
</rss>