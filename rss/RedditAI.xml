<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Fri, 17 Jan 2025 18:21:12 GMT</lastBuildDate>
    <item>
      <title>ELIZA：全球首个人工智能聊天机器人 60 年后终于复活</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3kvrh/eliza_worlds_first_ai_chatbot_has_finally_been/</link>
      <description><![CDATA[        由    /u/mattsparkes  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3kvrh/eliza_worlds_first_ai_chatbot_has_finally_been/</guid>
      <pubDate>Fri, 17 Jan 2025 16:54:59 GMT</pubDate>
    </item>
    <item>
      <title>主动推理研究论文资源</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3ivbv/active_inference_research_paper_resources/</link>
      <description><![CDATA[此资源非常简洁，更具学术性，您可以在移动设备上点击进入每篇研究论文。 Karl Friston 对人工智能的自然/自然方法（自由能原理、主动推理、空间网络 hsml/hstp）可能会在下周的达沃斯 2025 上得到进一步扩展，预计即将到来的 atari 10k 挑战基准测试。 他的大部分工作都是学术性的，其中一些是在 Verses Ai 实验室完成的。关于贝叶斯模型的学术论文对我来说往往过于数学化，但却令人着迷。  更多研究论文链接： https://www.fil.ion.ucl.ac.uk/~karl/ https://arxiv.org/search/?query=Karl+friston&amp;searchtype=author&amp;source=header https://scholar.google.cl/citations?user=q_4u0aoAAAAJ&amp;hl=en https://www.nature.com/articles/nrn2787 https://arxiv.org/html/2410.10653v1 https://www.aimodels.fyi/papers/arxiv/from-pixels-to-planning-scale-free-active https://www.mdpi.com/1099-4300/24/3/361 https://arxiv.org/pdf/2212.01354.pdf https://activeinference.github.io/#resources    由   提交  /u/oroechimaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3ivbv/active_inference_research_paper_resources/</guid>
      <pubDate>Fri, 17 Jan 2025 15:29:04 GMT</pubDate>
    </item>
    <item>
      <title>AI提示和保护隐私</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3i2up/ai_prompts_and_protecting_privacy/</link>
      <description><![CDATA[在 AI 应用环境中保护隐私时，一个常见的问题出现了：如何在确保 AI 有效运行的同时保护敏感数据？一种潜在的解决方案是，在处理用户查询之前，先将查询匿名化，然后将原始详细信息重新引入响应中，然后再将其传递给用户。 该概念的工作原理如下：首先，分析查询以识别敏感信息，例如姓名、位置或其他个人数据。这些详细信息被替换为中性占位符，如“&lt;&lt;NAME&gt;&gt;”或“&lt;&lt;LOCATION&gt;&gt;”。同时，在本地创建一个映射表（仅临时存储），将这些占位符链接到原始数据。重要的是，这种映射永远不会离开本地系统，确保敏感信息的安全。 匿名化后，查询将发送给 AI 进行处理。 AI 照常处理请求，但无法访问任何个人或身份信息。AI 的输出也保持匿名。 处理后，系统使用本地映射表将原始详细信息重新插入 AI 的响应中。此步骤可确保用户收到完整且个性化的答案，同时在整个过程中保护他们的敏感数据。 这种方法有几个关键好处。首先，它可以保护用户隐私，因为敏感数据永远不会离开本地环境。其次，AI 可以在不依赖于特定数据结构的情况下运行，使其既灵活又高效。此外，该过程可以透明化，让用户准确了解他们的数据是如何处理的。 这种类型的系统在客户支持等领域特别有用，因为个人数据通常是查询的一部分，或者在医疗应用中，保护健康信息至关重要。它还可以应用于数据分析，以确保个人标识符保持安全。 总体而言，这个概念提供了一种平衡现代 AI 系统功能与强大隐私保护需求的方法。您觉得如何？这可能是在敏感领域使用人工智能的可行方法吗？    提交人    /u/No-End-6550   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3i2up/ai_prompts_and_protecting_privacy/</guid>
      <pubDate>Fri, 17 Jan 2025 14:53:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能应用程序开发的陷阱——以及如何构建未来</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3hp1u/the_pitfalls_of_ai_app_development_and_how_to/</link>
      <description><![CDATA[  由    /u/oivaizmir  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3hp1u/the_pitfalls_of_ai_app_development_and_how_to/</guid>
      <pubDate>Fri, 17 Jan 2025 14:35:56 GMT</pubDate>
    </item>
    <item>
      <title>解释：生成式人工智能对环境的影响</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3fxwh/explained_generative_ais_environmental_impact/</link>
      <description><![CDATA[        提交人    /u/F0urLeafCl0ver   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3fxwh/explained_generative_ais_environmental_impact/</guid>
      <pubDate>Fri, 17 Jan 2025 13:07:33 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 1 月 16 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1i3859u/oneminute_daily_ai_news_1162025/</link>
      <description><![CDATA[ 苹果在其测试版 iPhone 软件中禁用了新闻的 AI 通知。[1] MatterGen：一种利用生成式 AI 进行材料设计的新范式。[2] 谷歌希望在年底前拥有 5 亿 Gemini AI 用户。[3] 洛杉矶野火引发大量虚假图片[4]  来源： [1] https://www.cnbc.com/2025/01/16/apple-disables-ai-notifications-for-news-in-its-beta-iphone-software.html [2] https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/ [3] https://www.pymnts.com/news/artificial-intelligence/2025/google-wants-500-million-gemini-ai-users-year-end/ [4] https://www.npr.org/2025/01/16/nx-s1-5259629/la-wildfires-fake-images    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i3859u/oneminute_daily_ai_news_1162025/</guid>
      <pubDate>Fri, 17 Jan 2025 04:15:10 GMT</pubDate>
    </item>
    <item>
      <title>有没有可以在小空间内运行的人工智能？比如旧电脑上的旧浏览器？</title>
      <link>https://www.reddit.com/r/artificial/comments/1i362w6/are_there_an_ais_that_can_be_run_on_a_lite/</link>
      <description><![CDATA[为什么？我只是好奇，但我找不到。我试图在我启动的旧笔记本电脑上打开 ChatGPT。只是为了好玩。网站运行得不好。    提交人    /u/PM_ME_YOUR_FAV_HIKE   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i362w6/are_there_an_ais_that_can_be_run_on_a_lite/</guid>
      <pubDate>Fri, 17 Jan 2025 02:23:04 GMT</pubDate>
    </item>
    <item>
      <title>艾森豪威尔在告别演说中警告了军工联合体。拜登在告别演说中警告了科技工业联合体，并表示人工智能是我们这个时代最重要的技术，它可以治愈癌症，也可以对人类构成威胁。</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2y4ve/in_eisenhowers_farewell_address_he_warned_of_the/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2y4ve/in_eisenhowers_farewell_address_he_warned_of_the/</guid>
      <pubDate>Thu, 16 Jan 2025 20:13:15 GMT</pubDate>
    </item>
    <item>
      <title>英国在人工智能安全方面的大胆实验</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2vmzk/inside_the_uks_bold_experiment_in_ai_safety/</link>
      <description><![CDATA[       由    /u/F0urLeafCl0ver  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2vmzk/inside_the_uks_bold_experiment_in_ai_safety/</guid>
      <pubDate>Thu, 16 Jan 2025 18:27:39 GMT</pubDate>
    </item>
    <item>
      <title>X/Grok 在更多政治问题上撒谎！</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2vdfs/xgrok_is_lying_about_more_political_issues/</link>
      <description><![CDATA[        提交人    /u/MalachiDraven   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2vdfs/xgrok_is_lying_about_more_political_issues/</guid>
      <pubDate>Thu, 16 Jan 2025 18:16:33 GMT</pubDate>
    </item>
    <item>
      <title>Agentic AI 是否会成为下一个大趋势？</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2qekh/are_agentic_ai_the_next_big_trend_or_no/</link>
      <description><![CDATA[我们公司有一个人，他引用了 Forrester 公司的话，说 Agentic AI 将成为技术领域的下一个大趋势。我觉得现在这个领域变得越来越拥挤和嘈杂（只有我！！！）。此外，我认为由于自动化，这种噪音会迅速增长。但这确实值得研究和实施，他听起来像是肯定的。 你们怎么看？    提交人    /u/Brilliant-Gur9384   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2qekh/are_agentic_ai_the_next_big_trend_or_no/</guid>
      <pubDate>Thu, 16 Jan 2025 14:42:21 GMT</pubDate>
    </item>
    <item>
      <title>D-SEC：用于评估 LLM 防御自适应攻击的动态安全实用框架</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2q8jq/dsec_a_dynamic_securityutility_framework_for/</link>
      <description><![CDATA[本文介绍了一种用于 LLM 的自适应安全系统，该系统使用多阶段变压器架构，可根据交互模式和威胁评估动态调整其防御。关键创新是从基于规则的静态防御转向可以发展其安全态势的情境感知系统。 关键技术要点： - 使用基于变换器的模型进行实时提示分析 - 实现考虑历史模式、情境和行为标记的动态安全配置文件 - 采用红队技术主动识别漏洞 - 具有根据新威胁数据更新防御参数的持续适应机制 实验结果： - 与基线​​防御相比，成功攻击减少了 87% - 合法使用的模型功能保留了 92% - 新攻击模式的 24 小时适应窗口 - 与静态系统相比，计算开销减少了 43% - 证明了在多个 LLM 架构中的有效性 我认为这种方法可以重塑我们实施 AI 安全措施的方式。该系统的动态特性表明，我们可以在不显着损害实用性的情况下保持安全性，而不是依赖经常产生误报的严格规则集。虽然计算要求仍然很高，但与传统方法相比，计算量的减少是有希望的。 我特别感兴趣的是，这可能如何扩展到不同的部署环境。本文在受控测试中显示了良好的结果，但实际应用可能会带来更复杂的挑战。24 小时的适应窗口令人印象深刻，尽管我怀疑它对协同攻击的有效性。 TLDR：LLM 的新型自适应安全系统可根据交互模式动态调整防御，在保持模型功能的同时，在攻击预防方面显示出显着的改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2q8jq/dsec_a_dynamic_securityutility_framework_for/</guid>
      <pubDate>Thu, 16 Jan 2025 14:34:19 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2025 年 1 月 15 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2hyk4/oneminute_daily_ai_news_1152025/</link>
      <description><![CDATA[ 特朗普、马斯克与微软 CEO 讨论人工智能和网络安全。[1] 中国人工智能公司 MiniMax 发布新模型，声称可与业内最佳模型相媲美。[2] 尽管该技术存在缺陷，但越来越多的青少年报告使用 ChatGPT 完成学业。[3] 彭博社开始使用人工智能生成的新闻摘要。[4] 谷歌最近推出了名为“Titans”的新型神经长期记忆模块，以改善机器处理大量信息的方式。[5]  来源： [1] https://finance.yahoo.com/news/trump-musk-discuss-ai-cybersecurity-024947841.html [2] https://techcrunch.com/2025/01/15/chinese-ai-company-minimax-releases-new-models-it-claims-are-competitive-with-the-industrys-best/ [3] https://techcrunch.com/2025/01/15/more-teens-report-using-chatgpt-for-schoolwork-despite-the-techs-faults/ [4] https://talkingbiznews.com/media-news/bloomberg-starts-ai-generated-news-summaries/ [5] https://analyticsindiamag.com/ai-news-updates/googles-new-ai-architecture-titans-can-remember-long-term-data/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2hyk4/oneminute_daily_ai_news_1152025/</guid>
      <pubDate>Thu, 16 Jan 2025 05:30:52 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 研究人员表示，他们拥有一个可以在“牢不可破”的盒子中递归自我改进的人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/1i2bqqf/openai_researcher_indicates_they_have_an_ai/</link>
      <description><![CDATA[       由    /u/MetaKnowing  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i2bqqf/openai_researcher_indicates_they_have_an_ai/</guid>
      <pubDate>Thu, 16 Jan 2025 00:02:48 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 研究人员感到担忧</title>
      <link>https://www.reddit.com/r/artificial/comments/1i1zo0h/openai_researcher_is_worried/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1i1zo0h/openai_researcher_is_worried/</guid>
      <pubDate>Wed, 15 Jan 2025 15:18:26 GMT</pubDate>
    </item>
    </channel>
</rss>