<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Sat, 23 Nov 2024 06:22:10 GMT</lastBuildDate>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 22 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</link>
      <description><![CDATA[ Enveda Biosciences 筹集 1.3 亿美元，用于推进从天然化合物中发现人工智能驱动的药物。[1] OpenAI 正在资助“人工智能道德”研究。[2] 亚马逊 将对人工智能初创公司 Anthropic 的总投资增加到 80 亿美元。[3] 伊利诺伊州猎人使用无人机和人工智能。[4]  来源： [1] https://siliconangle.com/2024/11/21/enveda-biosciences-raises-130m-advance-ai-driven-drug-discovery-natural-compounds/ [2] https://techcrunch.com/2024/11/22/openai-is-funding-research-into-ai-morality/ [3] https://venturebeat.com/ai/amazon-doubles-down-on-anthropic-positioning-itself-as-a-key-player-in-the-ai-arms-race/ [4] https://www.outdoornews.com/2024/11/22/drone-ai-use-by-hunters-addressed-in-illinois/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</guid>
      <pubDate>Sat, 23 Nov 2024 05:47:41 GMT</pubDate>
    </item>
    <item>
      <title>精准知识编辑与现有机器学习方法的比较</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</link>
      <description><![CDATA[我一直在研究一个名为 PKE（精确知识编辑）的项目，这是一种开源方法，通过减少有毒内容生成而不影响其总体性能来提高 LLM 的安全性。它的工作原理是使用神经元权重跟踪和激活通路跟踪来识别模型中的“有毒热点”，并通过自定义损失函数对其进行修改。目前有很多机器反学习技术可以使 LLM 更安全，例如：  精确反学习：此方法涉及在删除不需要的数据后从头开始重新训练模型。虽然它可以确保完全消除数据的影响，但它在计算上是昂贵的并且耗时的，尤其是对于大型模型而言。 近似反学习：  微调：使用剩余数据调整模型以减轻已删除数据的影响。但是，这可能无法完全消除数据的影响。 梯度上升：对要遗忘的数据的损失函数应用梯度上升，有效地“忘记”它。这种方法可能不稳定，并可能降低模型性能。   PKE 更好，原因如下：  毒性参数的细粒度识别：PKE 采用神经元权重跟踪和激活通路追踪来准确定位模型中负责生成有毒或有害内容的特定区域。这种精度允许有针对性的干预，从而降低模型整体行为发生意外改变的风险。 保持模型性能：通过将编辑重点放在已识别的毒性区域，PKE 最大限度地减少了对模型总体性能的影响。这种方法可确保模型在各种任务中保持其功能，同时有效减少不良内容的生成。 跨不同模型架构的可扩展性：PKE 已证明在各种 LLM 架构中都有效，包括 Llama2-7b 和 Llama-3-8b-instruct 等模型。这种可扩展性使其成为一种多功能工具，可增强各种 AI 系统的安全性。  很想听听你们对这个项目的想法，以及如何继续改进这种方法。如果有兴趣，这里是 Github 链接：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 和 论文 。    提交人    /u/lial4415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</guid>
      <pubDate>Sat, 23 Nov 2024 00:10:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 AI 将工作室效果应用于视频！</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxcg53/applying_studio_effects_to_video_with_ai/</link>
      <description><![CDATA[       由    /u/happybirthday290  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxcg53/applying_studio_effects_to_video_with_ai/</guid>
      <pubDate>Fri, 22 Nov 2024 16:55:54 GMT</pubDate>
    </item>
    <item>
      <title>Dario Amodei 表示，尽管 AGI 不是一个好词，因为我们正处于持续的指数级改进中，但“我们正处于为期两年的开端，我们将陆续通过所有这些门槛”，以完成有意义的工作</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</guid>
      <pubDate>Fri, 22 Nov 2024 16:19:33 GMT</pubDate>
    </item>
    <item>
      <title>chatGPT、Copilot 等的替代品？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxa8go/alternatives_to_chatgpt_copilot_etc/</link>
      <description><![CDATA[所以我想知道你们有什么 ChatGPT、Copilot 的替代方案？我使用 chatGPT 有一段时间了，差不多一两年了。但现在我基本上无法访问我的帐户了，因为它说我的内存已满，即使我存档或删除旧对话也是如此。这很好，因为如果有好的替代方案，我更喜欢免费和/或开源替代方案。我一直在使用 Copilot，因为它是免费的，但效果一般。 特别是，我对能够超越“自然语言搜索”功能的东西感兴趣，能够发挥更大的作用，例如能够用数字方式预测某个政治事件发生的可能性……等等。我现在还不够精明，无法自己做。    提交人    /u/RADICCHI0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxa8go/alternatives_to_chatgpt_copilot_etc/</guid>
      <pubDate>Fri, 22 Nov 2024 15:21:17 GMT</pubDate>
    </item>
    <item>
      <title>采用：一种改进的 Adam 优化器，保证对任何 Beta-2 值都收敛</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</link>
      <description><![CDATA[Adam 的新修改版 ADOPT 能够实现最佳收敛率，而不管 β₂ 参数选择如何。关键见解是在 Adam 的更新规则中添加一个简单的项，当 β₂ 设置不理想时，该项可以补偿潜在的收敛问题。 技术细节：- ADOPT 通过引入与 (1-β₂) 成比例的附加项来修改 Adam 的更新规则 - 理论分析证明对于任何 β₂ ∈ (0,1)，收敛速度为 O(1/√T) - 适用于凸优化和非凸优化 - 保持 Adam 的实际优势，同时提高理论保证 - 无需额外的超参数调整 关键结果：- 匹配 SGD 的最佳收敛速度以实现平滑的非凸优化 - 在测试场景中，经验上的表现与 Adam 相似或更好 - 通过改变 β₂ 值提供更稳健的收敛行为 - 理论保证在标准平滑度假设下成立 我认为这对于实际的深度学习应用非常有用，因为与学习率调整相比，β₂ 调整经常被忽视。无论 β₂ 选择如何，保证收敛都会减少超参数搜索空间。修改非常简单，可以轻松纳入现有的 Adam 实现中。 但是，我认为我们需要对大规模问题进行更广泛的实证验证，才能充分了解实际影响。理论保证令人鼓舞，但现代架构上的实际性能才是真正的考验。 TLDR：ADOPT 使用一个简单的术语修改 Adam，保证任何 β₂ 值的最佳收敛速度，从而可能简化优化器调整同时保持性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</guid>
      <pubDate>Fri, 22 Nov 2024 13:47:40 GMT</pubDate>
    </item>
    <item>
      <title>具有速度控制功能的 ElevenLabs 替代方案</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx71sv/elevenlabs_alternative_with_speed_control/</link>
      <description><![CDATA[ElevenLabs 中的声音很棒，但我创建了语言学习内容，他们的声音说得太快了 我尝试使用 ... . 和其他标点符号，但为了正确发音，我需要听几次，而且显然 ElevenLabs 会收取测试费用，所以效果不佳  所以，基本上我需要 ElevenLabs 但带有速度控制 是的，我知道我可以使用其他软件来改变速度，但是当我这样做时，要么音调太荒谬，要么声音听起来太电子化和不自然 提前谢谢您    提交人    /u/Aromatic-Solid97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx71sv/elevenlabs_alternative_with_speed_control/</guid>
      <pubDate>Fri, 22 Nov 2024 12:48:56 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 21 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx0v9w/oneminute_daily_ai_news_11212024/</link>
      <description><![CDATA[ 麻省理工学院的研究人员开发出一种有效的方法来训练更可靠的人工智能代理。[1] 据报道，Uber投资了自动驾驶公司Pony.ai。[2] 阿里巴巴刚刚发布了Marco-o1：推进人工智能的开放式推理。[3] Nvidia的盈利超出预期，因为投资者关注对Blackwell人工智能芯片的需求。[4]  来源： [1] https://news.mit.edu/2024/mit-researchers-develop-efficiency-training-more-reliable-ai-agents-1122 [2] https://www.pymnts.com/news/investment-tracker/2024/uber-reportedly-investing-in-autonomous-driving-firm-pony-ai/ [3] https://www.marktechpost.com/2024/11/21/alibaba-just-released-marco-o1-advancing-open-ended-reasoning-in-ai/ [4] https://apnews.com/article/nvidia-ai-earnings-report-adc942aa0e0c5d1a550b7bad486b942a    由    /u/Excellent-Target-847  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx0v9w/oneminute_daily_ai_news_11212024/</guid>
      <pubDate>Fri, 22 Nov 2024 05:43:09 GMT</pubDate>
    </item>
    <item>
      <title>Andrew Ng 的新 AI 视觉代理，如他在最新的 Youtube 演示中演示的那样。玩起来很有趣，但可能不如其竞争对手那么强大……</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwwoq0/andrew_ngs_new_ai_vision_agent_as_demoed_in_his/</link>
      <description><![CDATA[  由    /u/Chris_in_Lijiang  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwwoq0/andrew_ngs_new_ai_vision_agent_as_demoed_in_his/</guid>
      <pubDate>Fri, 22 Nov 2024 01:56:35 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可能会在对其感知能力持有不同意见的人之间造成“社会分裂”</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwo8we/ai_could_cause_social_ruptures_between_people_who/</link>
      <description><![CDATA[       由    /u/F0urLeafCl0ver  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwo8we/ai_could_cause_social_ruptures_between_people_who/</guid>
      <pubDate>Thu, 21 Nov 2024 19:41:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能系统可能“背叛人类”：人工智能先驱 Yoshua Bengio 警告人工智能风险</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwnjj1/ai_systems_could_turn_against_humans_ai_pioneer/</link>
      <description><![CDATA[        由    /u/katxwoods 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwnjj1/ai_systems_could_turn_against_humans_ai_pioneer/</guid>
      <pubDate>Thu, 21 Nov 2024 19:11:49 GMT</pubDate>
    </item>
    <item>
      <title>Minecraft 评估：左：新 GPT-4o。右：旧 GPT-4o</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwldxu/minecraft_eval_left_new_gpt4o_right_old_gpt4o/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwldxu/minecraft_eval_left_new_gpt4o_right_old_gpt4o/</guid>
      <pubDate>Thu, 21 Nov 2024 17:48:10 GMT</pubDate>
    </item>
    <item>
      <title>我很确定我已经发现为什么双子座会让某人的兄弟去死……</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwk80t/pretty_sure_i_found_out_why_gemini_told_someones/</link>
      <description><![CDATA[      因此，我尝试了一下共享聊天，因为它可以让您继续对话。我注意到“听”这个词很随机地被随机放置在未来提示中给出的一个问题的中间，但它似乎与任何其他文本都没有联系。  如果我再次说“听”这个词，它会直接拒绝给出回应。如果我询问进一步的背景原因，或者是否因为它被告知如果使用该词要说类似的话，它会拒绝在相同的双子座式保护触发器中再次给出回应。我问这个问题的原因是因为我想排除整个“也许是因为它没有耳朵”回复。 https://preview.redd.it/crormenkca2e1.png?width=813&amp;format=png&amp;auto=webp&amp;s=db501d7938ffae4f04b73dedc6aec45b86f97aa4 https://preview.redd.it/76l3tt8tca2e1.png?width=800&amp;format=png&amp;auto=webp&amp;s=9563521b5a246e2d2f79b7b850b81eaca9f7eb2e https://preview.redd.it/qf73f8dwca2e1.png?width=814&amp;format=png&amp;auto=webp&amp;s=bbed31b20e26c6a7e318113dec8adaa6d5e5287a https://preview.redd.it/vsbms948da2e1.png?width=793&amp;format=png&amp;auto=webp&amp;s=747721dd1a8df8f4d048f4cd612466fa58baeb91 链接至聊天作为证明： https://g.co/gemini/share/c8850215295e  所以……似乎很明显，它是因“听”这个词而触发的，无论出于什么原因？这是原始海报链接到聊天中，它告诉他们的兄弟去死，如果有人想尝试一下： https://g.co/gemini/share/6d141b742a13    提交人    /u/Expensive_Issue_3767   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwk80t/pretty_sure_i_found_out_why_gemini_told_someones/</guid>
      <pubDate>Thu, 21 Nov 2024 17:04:00 GMT</pubDate>
    </item>
    <item>
      <title>10 个团队，每个团队由 10 名代理组成，完全自主地撰写一本书</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwjreb/10_teams_of_10_agents_are_writing_a_book_fully/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwjreb/10_teams_of_10_agents_are_writing_a_book_fully/</guid>
      <pubDate>Thu, 21 Nov 2024 16:45:51 GMT</pubDate>
    </item>
    <item>
      <title>AI艺术通过图灵测试：人类无法区分人类艺术与AI艺术</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwfmt8/ai_art_turing_test_passed_people_are_unable_to/</link>
      <description><![CDATA[        由    /u/MetaKnowing  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwfmt8/ai_art_turing_test_passed_people_are_unable_to/</guid>
      <pubDate>Thu, 21 Nov 2024 12:56:42 GMT</pubDate>
    </item>
    </channel>
</rss>