<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 人工智能 (AI) 之家</description>
    <lastBuildDate>Thu, 25 Jan 2024 03:15:15 GMT</lastBuildDate>
    <item>
      <title>人工智能是我们这一代人的自行车。 #加速e/acc</title>
      <link>https://www.reddit.com/r/artificial/comments/19evdwf/artificial_intelligence_is_our_generations/</link>
      <description><![CDATA[       由   提交 /u/Limp-Variation4095   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19evdwf/artificial_intelligence_is_our_generations/</guid>
      <pubDate>Wed, 24 Jan 2024 23:56:52 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试在 tictok/任何社交媒体上记录我的 Ai 个人资料并播放我的面部反应</title>
      <link>https://www.reddit.com/r/artificial/comments/19eu7bi/im_trying_to_make_my_ai_profile_on_tictok_any/</link>
      <description><![CDATA[当我实时说话时，如何让真人的图像说出我在说什么？   由   提交/u/SignalWeird2044   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19eu7bi/im_trying_to_make_my_ai_profile_on_tictok_any/</guid>
      <pubDate>Wed, 24 Jan 2024 23:05:51 GMT</pubDate>
    </item>
    <item>
      <title>宝马计划在南卡罗来纳州的一家工厂放置人形机器人来做……一些事情</title>
      <link>https://www.reddit.com/r/artificial/comments/19etnrb/bmw_plans_to_put_humanoid_robots_in_a_south/</link>
      <description><![CDATA[    /u/Cyanidechrist____   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19etnrb/bmw_plans_to_put_humanoid_robots_in_a_south/</guid>
      <pubDate>Wed, 24 Jan 2024 22:43:16 GMT</pubDate>
    </item>
    <item>
      <title>人工智能音乐</title>
      <link>https://www.reddit.com/r/artificial/comments/19etkwn/artificial_intelligence_music/</link>
      <description><![CDATA[AI 聊天机器人、AI 艺术以及现在的 AI 视频都非常流行。但是，我对 AI 音乐感到好奇。 OpenAI 创建了 Jukebox。但是，自发布以来似乎没有任何进展。 Meta 发布了 AudioCraft，但同样，自发布以来似乎没有任何进展。 我尝试安装 AudioCraft，但永远无法让它工作。你们有人用过 Jukebox 或 AudioCraft 吗？他们好吗？是否有更简单的方法来访问它们，例如基于网络的在线界面？我尝试了一些，但它们不起作用。如果你们中有人知道任何有效的工具，我将不胜感激。 有一些可以使用的在线工具。但是， Sona.ai 是我使用过的唯一能产生良好效果的工具。感谢您对此的帮助！我想深入了解AI Music，希望能使用OpenAI、Meta等平台。   由   提交 /u/megariff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19etkwn/artificial_intelligence_music/</guid>
      <pubDate>Wed, 24 Jan 2024 22:39:59 GMT</pubDate>
    </item>
    <item>
      <title>Heinrich、Young、Booker、Rounds 提出两党法案以扩大人工智能研究的覆盖范围 [2023 年 7 月]</title>
      <link>https://www.reddit.com/r/artificial/comments/19et17g/heinrich_young_booker_rounds_introduce_bipartisan/</link>
      <description><![CDATA[       由   提交/u/A3485  [链接] &amp;# 32； &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/artificial/comments/19et17g/heinrich_young_booker_rounds_introduce_bipartisan/&quot;&gt;[评论]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19et17g/heinrich_young_booker_rounds_introduce_bipartisan/</guid>
      <pubDate>Wed, 24 Jan 2024 22:17:09 GMT</pubDate>
    </item>
    <item>
      <title>海因里希和波特曼宣布两党人工智能法案，以增强国家安全人员的人工智能能力，提高政府透明度 [2021 年 5 月]</title>
      <link>https://www.reddit.com/r/artificial/comments/19esuss/heinrich_portman_announce_bipartisan_artificial/</link>
      <description><![CDATA[       由   提交/u/A3485  [链接]  [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19esuss/heinrich_portman_announce_bipartisan_artificial/</guid>
      <pubDate>Wed, 24 Jan 2024 22:09:50 GMT</pubDate>
    </item>
    <item>
      <title>🤖 GPT-4的中国表弟拥有90%的智慧、中国的AI标准化指南以及NVIDIA CEO低调的中国行</title>
      <link>https://www.reddit.com/r/artificial/comments/19esblx/gpt4s_chinese_cousin_boasts_90_smarts_chinas_ai/</link>
      <description><![CDATA[       由   提交 /u/trcytony   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19esblx/gpt4s_chinese_cousin_boasts_90_smarts_chinas_ai/</guid>
      <pubDate>Wed, 24 Jan 2024 21:48:04 GMT</pubDate>
    </item>
    <item>
      <title>讲座研究工具——寻找想法和方向</title>
      <link>https://www.reddit.com/r/artificial/comments/19erx5t/lecture_research_tool_looking_for_ideas_and/</link>
      <description><![CDATA[我不太确定如何标题我的问题，但这是我正在寻找的内容： 讲座记录&lt; /h2&gt; 我一直在收集我所关注的各种主题的讲座记录（通常为 30-60 分钟，因此每个记录文件中大约有 5k-10k 字）。我已经能够从 Youtube 下载成绩单，其中没有任何标点符号，但是当我将单个成绩单输入 LLM 进行总结时，通常可以毫无问题地给出很好的总结。 法学硕士成绩单 我认为用我为某个讲师/演讲者收集的所有成绩单以某种方式培训法学硕士会很棒，然后能够互动、提出问题并使用它作为学习指南。通过针对特定个人的数百场讲座，法学硕士似乎能够快速获得我需要很长时间才能获得的见解和联系。 我找到的选项 Google NotebookLM 当我看到 Google 的 NotebookLM 时，我其实很兴奋，但当我喂它“更大”时，它似乎会窒息。文本块或当我尝试向其提供许多文件时。老实说，如果 NotebookLM 可以处理 10k 字的文档并在每个笔记本中处理 1000 个文档 - 这正是我正在寻找的。由于它（还）不能，所以我在这里寻找想法。 其他选项 我看到的另一个选项是 AssemblyAI。不过，我还没有找到一种方法来为其提供文本转录 - 它似乎首先从实际音频驱动，然后您可以生成转录、摘要，并用转录训练他们的法学硕士。 &lt; h2&gt;想法？  综上所述，是否有产品（服务、我可以在我的服务器上运行的软件，甚至是我可以用来实现我自己的解决方案的 python 库）来从播客和YouTube 讲座，培训某种定制的法学硕士，并将其用作学习/研究工具？   由   提交/u/IamFuriousGeorge  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19erx5t/lecture_research_tool_looking_for_ideas_and/</guid>
      <pubDate>Wed, 24 Jan 2024 21:31:37 GMT</pubDate>
    </item>
    <item>
      <title>你是否认为最终为了区分人造图像和人造图像，将会有某种法律或规则要求你在展示你的图像时有某种水印以表明它是人工智能？</title>
      <link>https://www.reddit.com/r/artificial/comments/19ersrk/do_you_think_eventually_in_order_to_tell_the/</link>
      <description><![CDATA[你认为这会发生吗？我认为政府这样做是正确的。   由   提交 /u/Messa_Jar_Jar_Binks   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19ersrk/do_you_think_eventually_in_order_to_tell_the/</guid>
      <pubDate>Wed, 24 Jan 2024 21:26:45 GMT</pubDate>
    </item>
    <item>
      <title>“有效加速主义”运动并不关心人类是否被人工智能取代，只要他们能从中赚钱</title>
      <link>https://www.reddit.com/r/artificial/comments/19erl9g/the_effective_accelerationism_movement_doesnt/</link>
      <description><![CDATA[   /u/estasfuera  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19erl9g/the_effective_accelerationism_movement_doesnt/</guid>
      <pubDate>Wed, 24 Jan 2024 21:17:59 GMT</pubDate>
    </item>
    <item>
      <title>我还能在哪里与法学硕士或其他人工智能一起玩？</title>
      <link>https://www.reddit.com/r/artificial/comments/19er40f/where_else_can_i_play_with_llms_or_other_ai/</link>
      <description><![CDATA[自从 Dall-e 和 GPT 向公众开放以来，我一直在搞乱它们。最近我主要在手机上使用 Bing，因为它非常用户友好。我对编码或编程不感兴趣，只是使用已经有用户界面的东西。 Bard，至少在它问世时，不如 GPT，所以我没有搞乱它。  哪些法学硕士或其他人工智能产品可以免费使用和访问，并且不需要任何复杂的设置。  我知道我们正处于这种东西无处不在的边缘，在我们的手机上、在我们的智能扬声器上、在我们的 Rabbit R1 上:) 但我不想要它！  您正在使用什么，您期望在接下来的六个月内看到什么？   由   提交 /u/BrooklynDuke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19er40f/where_else_can_i_play_with_llms_or_other_ai/</guid>
      <pubDate>Wed, 24 Jan 2024 20:58:38 GMT</pubDate>
    </item>
    <item>
      <title>音乐本能是与生俱来的吗？人工智能模型表明如此。</title>
      <link>https://www.reddit.com/r/artificial/comments/19eqjx9/is_musical_instinct_innate_ai_model_suggests_so/</link>
      <description><![CDATA[研究人员利用人工神经网络模型发现，音乐本能可能自然地从人脑中产生。 要点包括：  研究人员发现，音乐选择性神经元无需明确的音乐训练即可自发发育。 这些神经元表现出与人类听觉相似的行为。  这一发现意味着音乐能力可能是一种本能的大脑功能，经过进化可以有效地处理自然声音。 音乐被称为通用语言，似乎是跨文化所共有的，表明有共同的“音乐本能”。 该研究利用 Google 的 AudioSet 来分析自然声音，并观察神经元对音乐的具体反应。 音乐选择性神经元对音乐的时间结构进行编码，并且不限于特定流派。 抑制这些神经元会影响对其他自然声音的认知准确性，强调“音乐能力”在处理声音中的作用。  该研究对人工智能音乐生成、音乐治疗和理解音乐认知具有影响。然而，它并没有解决音乐学习的发展方面。 来源：https:// Neurosciencenews.com/musical-instinct-ai-25513/ ----- PS：如果您喜欢这篇文章，您一定会喜欢AI With Style 时事通讯。每个周一/周/周五的早晨，我都会以简短的形式，以时髦的风格发布最新、最伟大的人工智能回顾。加入我（免费）。   由   提交 /u/AIWithStyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19eqjx9/is_musical_instinct_innate_ai_model_suggests_so/</guid>
      <pubDate>Wed, 24 Jan 2024 20:35:38 GMT</pubDate>
    </item>
    <item>
      <title>微软创始人比尔·盖茨在谈到人工智能的威胁时表示，“关键是好人比坏人拥有更好的人工智能”</title>
      <link>https://www.reddit.com/r/artificial/comments/19eotnt/the_key_thing_is_that_the_good_guys_have_better/</link>
      <description><![CDATA[      趋势将会变得越来越强！   由   提交/u/Georgeo57  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19eotnt/the_key_thing_is_that_the_good_guys_have_better/</guid>
      <pubDate>Wed, 24 Jan 2024 19:25:38 GMT</pubDate>
    </item>
    <item>
      <title>作为人工智能新手，我到底应该学习什么？</title>
      <link>https://www.reddit.com/r/artificial/comments/19emry7/what_exactly_should_i_learn_as_someone_new_in_ai/</link>
      <description><![CDATA[随着人工智能目前的发展程度，人工智能新手应该首先学习什么（从开发人员的角度）？我在那里听说YouTube 上有一些关于人工智能的免费哈佛课程吗？它们仍然相关吗？   由   提交/u/Toven47  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19emry7/what_exactly_should_i_learn_as_someone_new_in_ai/</guid>
      <pubDate>Wed, 24 Jan 2024 17:54:25 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待人工智能未来对您日常生活/工作的影响？</title>
      <link>https://www.reddit.com/r/artificial/comments/19emlaw/how_can_you_see_ai_influencing_your_regular/</link>
      <description><![CDATA[我的意思是，您可以看到哪些特定的人工智能项目扩展至这样的程度，以至于它们将成为日常生活中不可或缺的东西（即爱好、特定工作） 、旅行、学习等），本质上是任何你经常或经常做的事情，人工智能可以产生重大影响，使这些活动变得更容易/更“简化”/更愉快/更少耗时，这取决于我们谈论的 ofc . 就我个人而言，自从成为古典学专业以来，我一直在研究各种法学硕士，他们显然是我最感兴趣的。 Chat GPT4 是我进入 AI 世界的门户，LLM 项目在 2023 年取得的快速进展让我对它能够多么接近 GI 原型感到兴奋。在实践层面上，我每天都会有大量的信件往来，有时还有一些研讨会论文，所用的语言都是我只部分流利的语言，因此，拥有一名活跃的翻译人员或人工智能翻译合作伙伴/语言习得助手的可能性实际上将把所有除了逻辑上让我变得更有趣、更少麻烦之外，它还很乏味。我仍在用 GPT 上的各种提示进行实验和测试，看看这个模型可以学习多少，可以输出多少，作为一个外行，我对它有时的准确程度感到非常惊讶。 &lt; p&gt;这也是我接触 Tandem GTP 和 Personal AI 的方式。 Tandem 本身更适合语言习得，而且它似乎运行得很好，尽管不幸的是没有达到我需要的水平，各种提示并没有给出我想要的反馈（我猜它只是不够专业）我想我所做的“学术”工作，但对于一般语言学习来说是可以的，而且它在帮助我特别提高葡萄牙语方面创造了奇迹。 另一方面，个人人工智能让我感兴趣，因为它的能力生成不同的自定义角色，在每个角色中输入不同的提示，并基本上定制人工智能来创建定制答录机/个人助理，特别是在回答不同记者相对常见的问题时。这似乎是一个放在口袋里的非常方便的工具，特别是当有很多手动通信可以轻松自动化（在某种程度上）时 我对此还很陌生，但是这些人工智能项目由于我的职业，（LLM 和 NLP）是我最感兴趣的。这也可能有一天让我失业（好吧，如果 LLM 项目发展成为一个原型 GI，并且在我的一生中它可以像人类一样解释文本的细微差别）。这一切都是基于我个人的担忧和之前的人工智能经验（我承认这是相当小的）。那你自己呢——在你生活的哪些具体方面，你能看到它对你最有影响力的影响？   由   提交/u/First-Interaction741  /u/First-Interaction741 reddit.com/r/artificial/comments/19emlaw/how_can_you_see_ai_influencing_your_regular/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19emlaw/how_can_you_see_ai_influencing_your_regular/</guid>
      <pubDate>Wed, 24 Jan 2024 17:31:18 GMT</pubDate>
    </item>
    </channel>
</rss>