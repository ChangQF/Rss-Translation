<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Wed, 23 Oct 2024 21:15:41 GMT</lastBuildDate>
    <item>
      <title>OpenAI 的 AGI 准备负责人辞职并发出警告：“OpenAI 或任何其他前沿实验室都尚未做好准备，世界也尚未为 AGI 做好准备……政策制定者需要紧急采取行动”</title>
      <link>https://www.reddit.com/r/artificial/comments/1gakt50/openais_head_of_agi_readiness_quits_and_issues/</link>
      <description><![CDATA[    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gakt50/openais_head_of_agi_readiness_quits_and_issues/</guid>
      <pubDate>Wed, 23 Oct 2024 20:42:20 GMT</pubDate>
    </item>
    <item>
      <title>Google DeepMind 的 Tim Rocktäschel 表示，AGI 将很快引领 ASI，因为一旦你拥有了人类级别的系统，你就可以应用相同的方法进行自我改进，从而实现超人系统</title>
      <link>https://www.reddit.com/r/artificial/comments/1gaho0u/google_deepminds_tim_rocktäschel_says_that_agi/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gaho0u/google_deepminds_tim_rocktäschel_says_that_agi/</guid>
      <pubDate>Wed, 23 Oct 2024 18:25:16 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能安全时钟”推出</title>
      <link>https://www.reddit.com/r/artificial/comments/1gaet7o/ai_safety_clock_launches/</link>
      <description><![CDATA[“人工智能安全时钟”启动 事实  上个月，IMD商学院推出了人工智能安全时钟，其目标是“明确表示不受控制的AGI [通用人工智能]的危险是真实存在的”，其创始人IMD教授迈克尔·韦德 (Michael Wade) 表示。[1] 该时钟目前位于午夜零 29 分，声称可以监测三个关键因素——人工智能的复杂性、自主性和物理集成。这些都是通过来自 1K 多个网站和近 3.5K 个新闻提要的信息进行监控的。[2][3] IMD 表示，该时钟的“灵感”来自“末日时钟”，后者由《原子科学家公报》于 1947 年首次建立，旨在“传达对人类和地球的威胁”。&lt;/p&gt;自 2024 年 1 月起，末日时钟设置为午夜前 90 秒。[4][5] 韦德声称，虽然人工智能目前“基本上处于人类控制之下”，但它也“已经取得了进展”，包括自主军用无人机和社交媒体机器人。他呼吁采取“全球性人工智能监管方法”。[1] 今年早些时候，美国、英国和欧盟等签署了有史以来第一份具有法律约束力的国际人工智能条约。自 2023 年以来，其他人工智能承诺相继出台，包括《欧盟人工智能法案》、《布莱切利宣言》和七国集团 (G7) 人工智能协议。[6]     提交人    /u/DeepDreamerX   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gaet7o/ai_safety_clock_launches/</guid>
      <pubDate>Wed, 23 Oct 2024 16:28:55 GMT</pubDate>
    </item>
    <item>
      <title>人工智能无法推理。它应该驾驶汽车吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gadpq5/ai_cant_reason_should_it_drive_cars/</link>
      <description><![CDATA[        提交人    /u/yus456   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gadpq5/ai_cant_reason_should_it_drive_cars/</guid>
      <pubDate>Wed, 23 Oct 2024 15:44:08 GMT</pubDate>
    </item>
    <item>
      <title>甚至花旗集团也感受到了 AGI 的影响：2029 年是 AGI，之后不久就是 ASI</title>
      <link>https://www.reddit.com/r/artificial/comments/1gadbs1/even_citigroup_is_feeling_the_agi_agi_in_2029_asi/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gadbs1/even_citigroup_is_feeling_the_agi_agi_in_2029_asi/</guid>
      <pubDate>Wed, 23 Oct 2024 15:27:58 GMT</pubDate>
    </item>
    <item>
      <title>心理障碍（例如确认偏差）会减缓我们对人工智能的采用。应用魔鬼代言人等技巧可以帮助我们克服这些障碍。特别是在人工智能等创新领域，由于复杂性、冲突和时间压力大，偏见出现得更频繁，需要有效管理。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gacw9d/psychological_barriers_such_as_confirmation_bias/</link>
      <description><![CDATA[        提交人    /u/DarknStormyKnight   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gacw9d/psychological_barriers_such_as_confirmation_bias/</guid>
      <pubDate>Wed, 23 Oct 2024 15:09:56 GMT</pubDate>
    </item>
    <item>
      <title>一款迷幻游戏，讲述一个接受古代文明和哲学训练的人工智能。玩起来像怪异的 Halo 3</title>
      <link>https://www.reddit.com/r/artificial/comments/1gacgme/a_psychedelic_game_about_an_ai_trained_on_ancient/</link>
      <description><![CDATA[        提交者    /u/NuclearSnake   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gacgme/a_psychedelic_game_about_an_ai_trained_on_ancient/</guid>
      <pubDate>Wed, 23 Oct 2024 14:51:49 GMT</pubDate>
    </item>
    <item>
      <title>报名参加 CloudxLab 免费 AI/ML 课程的最后一天！</title>
      <link>https://www.reddit.com/r/artificial/comments/1ga79l8/last_day_to_sign_up_for_free_aiml_course_with/</link>
      <description><![CDATA[不要错过参加“免费提升 AI 技能”课程的机会！无论您是完全的初学者还是想要升级，这段为期 12 个月的旅程都会教会您从Python和数据结构到机器学习和生成式 AI的所有内容。全部免费！ 📅 现场会议：每个星期四和星期五，晚上 8 点至晚上 10 点（IST） 🎯 持续时间：12 个月 📺 地点：YouTube Live 准备好掌握 AI/ML 了吗？ 在此处注册：https://cloudxlab.com/events/175/master-data-science-and-ai-with-our-free-12-months-online-course/ 快点！这是我们上线前的最后一次机会！ #AIForAll #FreeCourse #AI #MachineLearning #DataScience #GenerativeAI #Upskill    提交人    /u/stupidgorilla7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ga79l8/last_day_to_sign_up_for_free_aiml_course_with/</guid>
      <pubDate>Wed, 23 Oct 2024 10:31:09 GMT</pubDate>
    </item>
    <item>
      <title>利用个人医疗数据训练人工智能？</title>
      <link>https://www.reddit.com/r/artificial/comments/1ga0dm8/training_ai_on_personal_medical_data/</link>
      <description><![CDATA[偶然看到了这篇文章，发现它随意使用了一个令人惊讶的短语：  在 300 万份医疗记录的语料库上训练自己的法学硕士  这合法吗？ :-o https://a16z.com/the-messy-inbox-problem-ai-apps-wedge-strategies/ 继续阅读，常见的投资者诱饵出现了，比如  用法学硕士 (LLM) 取代人力  还有一个有趣的图表值得一看，只是因为它很愚蠢，它应该可以说明人工智能的力量 - 通过在一个完全相同的流程图中将凌乱的波浪线与直线进行逐字交换。太搞笑了。为了节省您的点击次数，是的，这些波浪线来自人类。 经过深思熟虑，我发现这样的文章令人沮丧，因为其意图清楚地反映了这种现代形式的寡头资本主义 - 投资者阶级，而不是工人，控制着社会中的生产资料，尽可能地人性化（原谅这个双关语）取代劳动力，而不考虑后果。 我们已经在社交媒体中以更微妙的形式拥有了这种形式 - 寡头为自己的利益拥有并控制社交互动。任何出错的事情都是别人的错。例如，每年个人因使用这些平台的诈骗而损失数十亿美元 - 这些平台为所有者赚取数十亿美元，而他们却没有任何后果。请注意银行如何受到监管，至少试图解决此类事件，而这在支持它的平台上明显缺失。 同样，他们会尽可能地推动人工智能，因为“颠覆” - 这意味着要快速行动，走在监管的前面，因为钱就在那里，而后果则由你来承担。 我觉得，有了人工智能，经济和政治权力从工人手中转移到公司只会加速。监管将继续落后于技术数年，在此期间造成损害，而寡头们将转向下一个不受监管的资金渠道，政府/纳税人需要稍后清理。我不知道解决方案是什么，但问题似乎很明显。    提交人    /u/sweetnsourgrapes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ga0dm8/training_ai_on_personal_medical_data/</guid>
      <pubDate>Wed, 23 Oct 2024 02:53:38 GMT</pubDate>
    </item>
    <item>
      <title>人类学博客：“克劳德突然暂停了我们的编码演示，开始仔细查看黄石公园的照片”</title>
      <link>https://www.reddit.com/r/artificial/comments/1g9x7y4/anthropic_blog_claude_suddenly_took_a_break_from/</link>
      <description><![CDATA[    /u/MetaKnowing 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g9x7y4/anthropic_blog_claude_suddenly_took_a_break_from/</guid>
      <pubDate>Wed, 23 Oct 2024 00:13:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的工作转变</title>
      <link>https://www.reddit.com/r/artificial/comments/1g9wur4/changing_jobs_in_the_era_of_ai/</link>
      <description><![CDATA[我不会问哪些行业是安全的，因为关于这个话题已经有足够多的帖子了。我想我问的是，在尝试改变行业或追求教育时，应该警惕什么；即使是想法也会受到赞赏。 我讨厌我现在的工作类型，但我害怕回到学校，因为我学习的任何内容都可能在几年后被接管，使所有的培训都变得毫无意义。我刚刚看到一个关于整个 T1 服务台部门被解雇并被聊天机器人取代的帖子。谈到办公室工作正在减少（即使是所谓的安全 STEM 工作，但我并没有足够的智慧去做那些工作）。 经常预测工作结束甚至大规模裁员让我感到害怕；如果没有有意义的工作和外部结构，我会崩溃。 我想我正在寻找那些不一定否认人工智能发展方向的人的实用建议。     由    /u/littleborb 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g9wur4/changing_jobs_in_the_era_of_ai/</guid>
      <pubDate>Tue, 22 Oct 2024 23:56:21 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 10 月 22 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1g9vqjd/oneminute_daily_ai_news_10222024/</link>
      <description><![CDATA[ 亚马逊支持的 Anthropic 首次推出可以执行复杂任务的 AI 代理，与 OpenAI、微软和谷歌竞争。[1] 超过 11,000 名创意人员谴责未经授权使用内容进行 AI 开发。[2] Stability 声称其最新的稳定扩散模型可以生成更多“多样化”的图像。[3] 亚马逊One Medical：AI 工具将医疗保健管理任务减少了 40%。[4]  来源： [1] https://www.cnbc.com/2024/10/22/anthropic-announces-ai-agents-for-complex-tasks-racing-openai.html [2] https://www.nbcnews.com/tech/actors-artists-authors-open-letter-ai-copyright-rcna176681 [3] https://techcrunch.com/2024/10/22/stability-claims-its-newest-stable-diffusion-models-generate-more-diverse-images/ [4] https://www.pymnts.com/news/artificial-intelligence/2024/amazon-one-medical-ai-tools-reduce-healthcare-administrative-tasks-40percent/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g9vqjd/oneminute_daily_ai_news_10222024/</guid>
      <pubDate>Tue, 22 Oct 2024 23:03:08 GMT</pubDate>
    </item>
    <item>
      <title>当你思考技术进步时，“但是这从来没有发生过！”这不会让你走得太远。</title>
      <link>https://www.reddit.com/r/artificial/comments/1g9okkn/but_its_never_happened_before_isnt_going_to_get/</link>
      <description><![CDATA[       由    /u/katxwoods  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g9okkn/but_its_never_happened_before_isnt_going_to_get/</guid>
      <pubDate>Tue, 22 Oct 2024 18:00:02 GMT</pubDate>
    </item>
    <item>
      <title>首个完全由人工智能运营的广播电台在波兰成立</title>
      <link>https://www.reddit.com/r/artificial/comments/1g9g22x/the_first_radio_station_run_entirely_by_ai_has/</link>
      <description><![CDATA[      克拉科夫 OFF 电台即将开始一项创新实验，旨在探索人工智能 (AI) 对文化、媒体和新闻等社会各个方面的深远影响。该计划将于 10 月 22 日星期二上午 8:00 首次亮相。 这个开创性的项目旨在确定人工智能在媒体领域代表的是机遇还是威胁。该计划背后的团队强调通过 OFF Radio Kraków 及其文化频道的一系列广播直接应对人工智能时代的沟通挑战。该节目特别针对 Z 世代量身定制，解决了他们对人工智能如何塑造信息消费的兴趣和担忧。 https://preview.redd.it/pvj8cwyyqawd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=00142db997dbbb14f804708f38e4eaa99cc89d20    提交人    /u/greenapple92   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g9g22x/the_first_radio_station_run_entirely_by_ai_has/</guid>
      <pubDate>Tue, 22 Oct 2024 11:42:14 GMT</pubDate>
    </item>
    <item>
      <title>微软CEO称AI已开始递归改进自身：“我们正在利用AI构建AI工具，以构建更好的AI”</title>
      <link>https://www.reddit.com/r/artificial/comments/1g95tf8/microsoft_ceo_says_ai_has_begun_recursively/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1g95tf8/microsoft_ceo_says_ai_has_begun_recursively/</guid>
      <pubDate>Tue, 22 Oct 2024 00:52:19 GMT</pubDate>
    </item>
    </channel>
</rss>