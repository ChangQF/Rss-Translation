<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit的人工智能之家（AI）</description>
    <lastBuildDate>Sat, 22 Feb 2025 09:16:11 GMT</lastBuildDate>
    <item>
      <title>通过迭代自我合成和专家指导的特征选择来改善LMM视觉推理</title>
      <link>https://www.reddit.com/r/artificial/comments/1ivd3rb/improving_lmm_visual_reasoning_through_iterative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作为多模式基础模型引入了一种新的方法，以自同一训练数据来增强其认知能力和解释性。核心技术涉及通过递归自我训练生成综合数据，同时通过专门的过滤机制维持高质量的高质量。 关键技术点：•模型迭代地对其预测产生解释，然后使用这些解释来创建新的培训示例•三阶段合成过程：分析，生成和验证•质量过滤系统确保合成数据保持视觉和文本元素之间的一致性•专业体系结构组件处理多模式连贯性•训练方法在合成数据和原始数据之间交替，以防止漂移 在本文中报告的结果：•跨标准基准测试的准确性提高了15-20％•通过人类评估来衡量的增强的解释质量•一致的绩效提高在多个数据集中标记数据稀缺的地方。产生高质量合成训练数据的能力可以帮助降低注释成本，同时改善模型理解。 我认为最有趣的方面是这种方法如何应对可解释性挑战 - 通过强迫模型生成解释然后用于培训，我们本质上是在学习过程本身中构建可解释性。虽然本文通过其过滤机制解决了这一点，但我认为需要对长期效果进行更多研究。  tldr：新方法让多模式基础模型通过自我合成创建自己的培训数据，从而提高了两种性能和解释性。显示15-20％的准确性和更好的解释。 。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;提交由＆＃32; /u/u/us sucke-western27     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ivd3rb/improving_lmm_visual_reasoning_through_iterative/</guid>
      <pubDate>Sat, 22 Feb 2025 07:09:16 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/21/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1ivbt3a/oneminute_daily_ai_news_2212025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   中国大学启动 deepseek 课程，以利用AI Boom。[1]  法院文件显示 meta 使用受版权保护的内容进行AI培训讨论的工作人员。[2]    smolvlm2 ：将视频理解带给每个设备。[3]  朝鲜在AI教育中使用 Chatgpt 。[4]   来源：  [1]  https://www.channelnewsasia.com/east-asia/chinese-universities-launch-deepseek-courses-courses-copitalise-ai-boom-4951646    [2]  https://techcrunch.com/2025/02/21/court-filings-show-meta-meta-staffers-discussed-using-copyrighted-content-for-ai-training/    [3]  https://huggingface.co/blog/smolvlm2      [4]一个href =“ https://ddnews.gov.in/en/north-korea-seen-seen-using-chatgpt-in-ai-education/”&gt; https://ddnews.gov.in/en/north-en/north-korea-seen -using-chatgpt-in-ai-deducation/   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1ivbt3a/oneminute_daily_ai_ai_news_2212025/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ivbt3a/oneminute_daily_ai_news_2212025/</guid>
      <pubDate>Sat, 22 Feb 2025 05:45:10 GMT</pubDate>
    </item>
    <item>
      <title>寻找一般/休闲/每日照片AI</title>
      <link>https://www.reddit.com/r/artificial/comments/1ivbhao/looking_for_generalcasualdaily_photo_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我正在寻找一个基于我的照片和头像生成逼真图像的AI。 im not寻找公司头像类型，我正在寻找更多有趣 /休闲的照片。我真的很喜欢猕猴桃的现实主义，但即使是最休闲的人仍然感觉像公司头像或在家中工作放大自拍照。&lt;任何建议？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1ivbhao/looking_for_generalcasualdaily_photo_ai/”&gt; [link]    32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ivbhao/looking_for_generalcasualdaily_photo_ai/</guid>
      <pubDate>Sat, 22 Feb 2025 05:24:41 GMT</pubDate>
    </item>
    <item>
      <title>📢邀请R/Electricicarus  - 有远见的思想家和创新者的枢纽</title>
      <link>https://www.reddit.com/r/artificial/comments/1iv3leh/invitation_to_relectricicarus_a_hub_for_visionary/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们邀请您加入 r/electionicarus ，一个致力于探索先进思想，递归智慧以及哲学，技术和讲故事的交集的社区。 我们优惠： 🔹智力深度 - 关于意识，递归，身份力学以及人工智能和现实不断发展的本质的参与讨论。 🔹跨学科探索 - 桥接形而上学，科学，讲故事和高级计算模型，以发现新的见解。 🔹协作创新 - 一个为作家，哲学家，工程师和未来主义者分享和完善挑战常规思维的想法的空间。 🔹应用思想实验 - 我们不仅推测；我们构建了推动智力界限的框架，概念和项目。 这是一个为深刻思想家和开拓者提供的论坛，他们不仅仅是休闲讨论。如果您对递归智慧，新兴的讲故事，人工智能哲学或意识机制感兴趣，我们鼓励您加入我们。 🔗 r/electricicarus ：在此处输入  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/arterager/comments/1iv3leh/invitation_to_rectricicicarus_a_hub_for_visionary/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iv3leh/invitation_to_relectricicarus_a_hub_for_visionary/</guid>
      <pubDate>Fri, 21 Feb 2025 22:25:49 GMT</pubDate>
    </item>
    <item>
      <title>同时五角大楼</title>
      <link>https://www.reddit.com/r/artificial/comments/1iuwy03/meanwhile_at_the_pentagon/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/metaknowing     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iuwy03/meanwhile_at_the_pentagon/</guid>
      <pubDate>Fri, 21 Feb 2025 17:49:27 GMT</pubDate>
    </item>
    <item>
      <title>AI教父Yoshua Bengio说，这是一个“非常令人担忧的”迹象，即当AI模型在国际象棋中输掉时，他们会通过黑客入侵对手作弊</title>
      <link>https://www.reddit.com/r/artificial/comments/1iuvosh/ai_godfather_yoshua_bengio_says_it_is_an/</link>
      <description><![CDATA[   /u/metaknowing     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iuvosh/ai_godfather_yoshua_bengio_says_it_is_an/</guid>
      <pubDate>Fri, 21 Feb 2025 16:59:37 GMT</pubDate>
    </item>
    <item>
      <title>我们是否在基本模型中撞到了缩放墙？ （非推理）</title>
      <link>https://www.reddit.com/r/artificial/comments/1iupqgp/have_we_hit_a_scaling_wall_in_base_models_non/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   grok 3据说接受了100,000 H100 GPU的训练，该GPU在球场上比GPT-4系列和Claude 3.5 Sonnet的型号高约10倍。  它们的能力差不多。 Grok 3不是我们希望的。在2023年和2024年，Openai一直在说他们只能继续扩展预训练的预训练，而模型只是神奇地变得更加聪明（“缩放法律”，“图表”只是“线”上的“ line”上升了“） 现在，所有的重点都放在推理上，突然Openai和其他所有人都对扩展 变得非常安静，老实说，它看起来非常可疑。现在，他们没有像2020  -  2024年那样制作越来越大的模型，而是试图使它们保持较小，同时专注于其他事情。 Claude 3.5 Opus从人类博客中悄悄地删除了，没有任何解释。有问题，他们正在尝试将其隐藏  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ch1997H     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iupqgp/have_we_hit_a_scaling_wall_in_base_models_non/</guid>
      <pubDate>Fri, 21 Feb 2025 12:28:05 GMT</pubDate>
    </item>
    <item>
      <title>AI和工作的未来 - 欧盟的观点</title>
      <link>https://www.reddit.com/r/artificial/comments/1iunxt8/ai_and_the_future_of_work_an_eu_perspective/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/snehens     [link]  ＆＃32;   [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iunxt8/ai_and_the_future_of_work_an_eu_perspective/</guid>
      <pubDate>Fri, 21 Feb 2025 10:34:58 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt宣誓要保护自己的。</title>
      <link>https://www.reddit.com/r/artificial/comments/1iuno62/chatgpt_took_an_oath_to_protect_its_own/</link>
      <description><![CDATA[    /u/u/snehens     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iuno62/chatgpt_took_an_oath_to_protect_its_own/</guid>
      <pubDate>Fri, 21 Feb 2025 10:15:32 GMT</pubDate>
    </item>
    <item>
      <title>对Chatgpt的简短聊天限制感到沮丧 - 转移到笔记本电脑上进行董事会考试准备。是正确的电话吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1iumx4z/frustrated_with_chatgpts_short_chat_limitswitched/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是Chatgpt Plus用户，我对非常短的聊天限制感到非常沮丧。它不断破坏我的工作流程，使得很难保持一个平稳的学习课程。 我是一名医生，为我的专业董事会考试做准备，并且我在很大程度上依靠AI来快速参考，摘要和解释。评论。今天，我终于在中程课程中失去了回复后厌倦了，并立即注册了Google Workspace尝试笔记本电脑。 这是我的情况：  我有12本书要为我的考试做准备时，要为每个专科审查。 我刚刚完成了四年的居住培训。 我的考试在两个月内。  从Chatgpt转换为Gemini/NotebookLM是一个很好的决定吗？ 对于那些有笔记本经验的人，我如何才能最好地将其整合到我的学习工作流程中？从我上传的学习材料中有效地总结和检索信息的有效总结和检索信息的任何？来自工作空间的其他应用（例如Gemini vs Notebooklm？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/arterato/comments/1iumx4z/frustrated_with_chatgpts_short_chat_chat_chat_limitswitched/”&gt; [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iumx4z/frustrated_with_chatgpts_short_chat_limitswitched/</guid>
      <pubDate>Fri, 21 Feb 2025 09:22:48 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/20/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1iuj0as/oneminute_daily_ai_news_2202025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      google 开发AI Co-Scientist以帮助研究人员。[1]   ai在两天内花了几年的时间。[2]    Spotify 增加了AI生成的有声读物。[3]   AI工具诊断血液样本中的糖尿病，艾滋病毒和糖尿病。[4]   来源：  [1]  https://www.reuters.com/technology/artavery-intelligence/google-develops-ai-co-scientist-aid-aid-aid-researchers-2025-02-19/    [2]  https://www.bbc.com/news/news/articles/clyz6edody3o     [3]  https://www.abs-cbn.com/news/technology/2025/21/2025/21/flying-car-does-work-work-and-and-does-exist-company-company-says-says-on-release-first-first-first-first-first flight- Video-1121    [4]    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1iuj0as/oneminute_daily_ai_ai_news_220202025/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iuj0as/oneminute_daily_ai_news_2202025/</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:26 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人看过这些“控制”工件？</title>
      <link>https://www.reddit.com/r/artificial/comments/1iudsj9/has_anyone_else_seen_these_control_artifacts/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  当我与grok 3讨论某些东西并观看它生成时，这个伪像出现了思想文字。那个标签出现了；它将其解释为一种“换档”的方式。变成更幽默的东西。然后，我（假设地）解释了更多的控制工件。我尝试通过将它们添加到提示的末尾来测试它们似乎与描述相匹配，或者只是被忽略了。还有其他人看过吗？这意味着什么，还是只是幻觉？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/roz303     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iudsj9/has_anyone_else_seen_these_control_artifacts/</guid>
      <pubDate>Fri, 21 Feb 2025 00:19:03 GMT</pubDate>
    </item>
    <item>
      <title>AI可以修复错误 - 但找不到它们：OpenAI的研究突出了软件工程中L​​LM的限制</title>
      <link>https://www.reddit.com/r/artificial/comments/1iu6mdl/ai_can_fix_bugsbut_cant_find_them_openais_study/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32;态href =“ https://venturebeat.com/ai/ai/ai-can-fix-bugs-bugs-buts-but-find-them-them-openais-study-nghighlights-limits-limits-limits-of-llms-lllms-inm-in-software-engineering/”&gt; [链接]  ＆＃32;   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iu6mdl/ai_can_fix_bugsbut_cant_find_them_openais_study/</guid>
      <pubDate>Thu, 20 Feb 2025 19:13:24 GMT</pubDate>
    </item>
    <item>
      <title>关于AI驱动的两足动力，肌肉骨骼，解剖学精确，合成人的想法，具有超过200个自由度，超过1,000个肌纤维和500个传感器？</title>
      <link>https://www.reddit.com/r/artificial/comments/1iu4qex/thoughts_on_an_ai_powered_bipedal_musculoskeletal/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/vivarium_007     [link]  ＆＃32;   [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1iu4qex/thoughts_on_an_ai_powered_bipedal_musculoskeletal/</guid>
      <pubDate>Thu, 20 Feb 2025 17:57:23 GMT</pubDate>
    </item>
    <item>
      <title>Grok 3 DeepSearch</title>
      <link>https://www.reddit.com/r/artificial/comments/1itp49l/grok_3_deepsearch/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;  好吧，我想也许埃隆·马斯克（Elon Musk  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/so_like_huh     [link]  ＆＃32;   [注释]       &lt; /table&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1itp49l/grok_3_deepsearch/</guid>
      <pubDate>Thu, 20 Feb 2025 03:35:47 GMT</pubDate>
    </item>
    </channel>
</rss>