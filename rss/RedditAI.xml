<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Wed, 05 Feb 2025 01:15:00 GMT</lastBuildDate>
    <item>
      <title>Genius（Verses Ai 主动推理）在 Mastermind 基准测试中击败 Deepseek R1</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihvnvc/genius_verses_ai_active_inference_beats_deepseek/</link>
      <description><![CDATA[      “Genius 以象征性的成本解决了所有 100 场游戏，平均每场 3.1 秒，比 DeepSeek R1 快 245 倍，便宜 779 倍 DeepSeek R1 在 10 次猜测内仅解决了 45% 的游戏，平均每场游戏 5 分 34 秒 R1 的总计算时间为 26 小时，总成本为 38.94 美元，平均每场游戏成本为 0.39 美元” 公平地说，Deepseek 非常便宜，而且是法学硕士学位。 bayesia 主动推理在实时数据学习中表现出色。 尽管我认为 Genius Ai 的学习曲线会更陡峭，因为数据科学是新的，但在封闭测试版中可以通过 python 访问。    提交人    /u/oroechimaru   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihvnvc/genius_verses_ai_active_inference_beats_deepseek/</guid>
      <pubDate>Tue, 04 Feb 2025 23:19:26 GMT</pubDate>
    </item>
    <item>
      <title>谷歌解除了使用人工智能进行武器和监视的禁令</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihufgk/google_lifts_a_ban_on_using_its_ai_for_weapons/</link>
      <description><![CDATA[        由    /u/mattfromseattle  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihufgk/google_lifts_a_ban_on_using_its_ai_for_weapons/</guid>
      <pubDate>Tue, 04 Feb 2025 22:25:54 GMT</pubDate>
    </item>
    <item>
      <title>Deepseek au 回答 9.9 或 9.11 哪一个更大</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihqf68/deepseek_au_answer_to_99_or_911_which_one_is/</link>
      <description><![CDATA[        提交人    /u/ItsMangaSensei   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihqf68/deepseek_au_answer_to_99_or_911_which_one_is/</guid>
      <pubDate>Tue, 04 Feb 2025 19:41:42 GMT</pubDate>
    </item>
    <item>
      <title>霍利参议员提议对下载 DeepSeek 的人判处监禁</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihogfw/senator_hawley_proposes_jail_time_for_people_who/</link>
      <description><![CDATA[        由    /u/F0urLeafCl0ver 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihogfw/senator_hawley_proposes_jail_time_for_people_who/</guid>
      <pubDate>Tue, 04 Feb 2025 18:22:02 GMT</pubDate>
    </item>
    <item>
      <title>印度人工智能研究实验室 Krutrim 开源其所有模型🚀</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihn6r7/indias_ai_research_lab_krutrim_open_sources_all/</link>
      <description><![CDATA[        提交人    /u/eternviking   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihn6r7/indias_ai_research_lab_krutrim_open_sources_all/</guid>
      <pubDate>Tue, 04 Feb 2025 17:30:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么加速论者应该关心人工智能的安全性：批准切尔诺贝利设计的人并没有加速核能。AGI 似乎容易受到类似的强烈反对。</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihm7vz/why_accelerationists_should_care_about_ai_safety/</link>
      <description><![CDATA[        由    /u/MetaKnowing 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihm7vz/why_accelerationists_should_care_about_ai_safety/</guid>
      <pubDate>Tue, 04 Feb 2025 16:51:50 GMT</pubDate>
    </item>
    <item>
      <title>什么是OpenAI ChatGPT深度研究？</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihm0en/what_is_openai_chatgpt_deep_research/</link>
      <description><![CDATA[        提交人    /u/dasun0218   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihm0en/what_is_openai_chatgpt_deep_research/</guid>
      <pubDate>Tue, 04 Feb 2025 16:43:34 GMT</pubDate>
    </item>
    <item>
      <title>漫威影业似乎使用人工智能制作了《神奇四侠》海报</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihlyb6/it_looks_like_marvel_studios_used_ai_to_generate/</link>
      <description><![CDATA[       由    /u/S4v1r1enCh0r4k  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihlyb6/it_looks_like_marvel_studios_used_ai_to_generate/</guid>
      <pubDate>Tue, 04 Feb 2025 16:41:08 GMT</pubDate>
    </item>
    <item>
      <title>可以通过写入十六进制代码来绕过 DeepSeek IA 限制</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihlr9q/deepseek_ia_restrictions_can_be_bypassed_by/</link>
      <description><![CDATA[      https://preview.redd.it/r0zbdly5g5he1.png?width=642&amp;format=png&amp;auto=webp&amp;s=0d72569afe0e1dc4bcceb7b1c501bebc3c6c21f4 https://preview.redd.it/dxaxrp36g5he1.png?width=865&amp;format=png&amp;auto=webp&amp;s=5f131c2caffbb4fb573f77ea3f2d8c99fc7e5bc8 我不知道出于什么荒谬的原因这有效，但它确实有效 :) 我看到这篇文章，决定尝试一下。绕过仍然是可能的，但我不知道能持续多久。    提交人    /u/UzzInReddit   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihlr9q/deepseek_ia_restrictions_can_be_bypassed_by/</guid>
      <pubDate>Tue, 04 Feb 2025 16:33:08 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 要求求职者不要在求职过程中使用人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihhy4o/anthropic_asks_job_applicants_not_to_use_ai_in/</link>
      <description><![CDATA[        由    /u/F0urLeafCl0ver  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihhy4o/anthropic_asks_job_applicants_not_to_use_ai_in/</guid>
      <pubDate>Tue, 04 Feb 2025 13:44:22 GMT</pubDate>
    </item>
    <item>
      <title>欢迎 AI-Ludd，第一个被训练成卢德分子的人工智能代理。</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihhi1e/welcome_ailudd_the_first_ai_agent_trained_to_be_a/</link>
      <description><![CDATA[        提交人    /u/edapx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihhi1e/welcome_ailudd_the_first_ai_agent_trained_to_be_a/</guid>
      <pubDate>Tue, 04 Feb 2025 13:21:39 GMT</pubDate>
    </item>
    <item>
      <title>扩展推理时间计算可提高语言模型对对抗攻击的鲁棒性</title>
      <link>https://www.reddit.com/r/artificial/comments/1ihgddt/scaling_inferencetime_compute_improves_language/</link>
      <description><![CDATA[本文探讨了如何在推理时间内增加计算资源以提高模型对对抗性攻击的鲁棒性，而无需专门的训练或架构更改。 关键方法包括：- 使用不同的推理时间计算分配测试 OpenAI 的 o1-preview 和 o1-mini 模型- 衡量不同计算预算的攻击成功率- 开发针对基于推理的语言模型的新型攻击方法- 评估针对多种攻击类型的鲁棒性增益 主要技术发现：- 随着推理时间的增加，攻击成功率显着下降- 某些攻击类型在更高的计算水平下显示出接近于零的成功率- 无需对抗性训练即可自然获得好处- 尽管需要额外的计算，某些攻击媒介仍然有效- 改进可以随着计算资源的增加而可预测地扩展 我认为这项工作为在不进行复杂的架构更改的情况下改进模型安全性开辟了有趣的可能性。计算成本和安全效益之间的权衡对于无法始终进行重新训练的生产部署尤其重要。 我认为最有趣的方面是这与人类认知之间的联系 - 给予模型更多的“思考时间”自然会提高其避免欺骗的能力，类似于人类从花时间推理问题中受益。 持续漏洞的限制表明这不应该是唯一的防御机制，但它可能是更广泛安全策略的重要组成部分。 TLDR：更多的推理时间计算使模型自然地更能抵抗多种类型的攻击，而无需特殊训练。一些漏洞仍然存在，这表明这应该是更大安全方法的一部分。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ihgddt/scaling_inferencetime_compute_improves_language/</guid>
      <pubDate>Tue, 04 Feb 2025 12:19:28 GMT</pubDate>
    </item>
    <item>
      <title>来了</title>
      <link>https://www.reddit.com/r/artificial/comments/1ih0c98/here_it_comes/</link>
      <description><![CDATA[        提交人    /u/Hazzman   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ih0c98/here_it_comes/</guid>
      <pubDate>Mon, 03 Feb 2025 21:19:07 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI 创始人：“我们显然正处于智能起飞的场景中”</title>
      <link>https://www.reddit.com/r/artificial/comments/1igxm36/stability_ai_founder_we_are_clearly_in_an/</link>
      <description><![CDATA[    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1igxm36/stability_ai_founder_we_are_clearly_in_an/</guid>
      <pubDate>Mon, 03 Feb 2025 19:30:00 GMT</pubDate>
    </item>
    <item>
      <title>GeoSpy Al 现在仅需一张室内照片即可确定您的准确位置</title>
      <link>https://www.reddit.com/r/artificial/comments/1igrh2o/geospy_al_can_now_pinpoint_your_exact_location/</link>
      <description><![CDATA[        由    /u/Secure_Routine8650   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1igrh2o/geospy_al_can_now_pinpoint_your_exact_location/</guid>
      <pubDate>Mon, 03 Feb 2025 15:21:44 GMT</pubDate>
    </item>
    </channel>
</rss>