<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Thu, 04 Jul 2024 15:14:49 GMT</lastBuildDate>
    <item>
      <title>新的“道德”人工智能音乐生成器无法创作出一首像样的歌曲</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv8x5v/the_new_ethical_ai_music_generator_cant_write_a/</link>
      <description><![CDATA[歌曲生成器因涉嫌侵犯版权而陷入困境，但人工智能工具 Jen 是在获得许可的材料上进行训练的。    提交人    /u/wiredmagazine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv8x5v/the_new_ethical_ai_music_generator_cant_write_a/</guid>
      <pubDate>Thu, 04 Jul 2024 14:58:38 GMT</pubDate>
    </item>
    <item>
      <title>Apple Intelligence 的隐私保护能力与 Android 的“混合 AI”相比如何</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv8t6x/how_apple_intelligences_privacy_stacks_up_against/</link>
      <description><![CDATA[生成式人工智能正在渗透到手机核心，但这对隐私意味着什么？以下是苹果独特的人工智能架构与三星和谷歌采用的“混合”方法的比较。    提交人    /u/wiredmagazine   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv8t6x/how_apple_intelligences_privacy_stacks_up_against/</guid>
      <pubDate>Thu, 04 Jul 2024 14:53:32 GMT</pubDate>
    </item>
    <item>
      <title>上行：猴子看到了什么。下行：人工智能根据猴子的大脑记录重建的图像</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv86od/top_row_what_the_monkey_saw_bottom_row_images/</link>
      <description><![CDATA[        提交人    /u/Maxie445   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv86od/top_row_what_the_monkey_saw_bottom_row_images/</guid>
      <pubDate>Thu, 04 Jul 2024 14:25:41 GMT</pubDate>
    </item>
    <item>
      <title>温德尔·瓦拉赫的未来精神 - 机器伦理播客</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv5fop/an_ethos_for_the_future_with_wendell_wallach/</link>
      <description><![CDATA[        由    /u/benbyford  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv5fop/an_ethos_for_the_future_with_wendell_wallach/</guid>
      <pubDate>Thu, 04 Jul 2024 12:10:31 GMT</pubDate>
    </item>
    <item>
      <title>巴西禁止 Meta 使用 Instagram 帖子来训练人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv4zqa/brazil_suspends_meta_from_using_instagram_posts/</link>
      <description><![CDATA[        提交人    /u/dlaltom   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv4zqa/brazil_suspends_meta_from_using_instagram_posts/</guid>
      <pubDate>Thu, 04 Jul 2024 11:45:52 GMT</pubDate>
    </item>
    <item>
      <title>阅读应用程序通过人工智能重新唤醒已故好莱坞明星的声音</title>
      <link>https://www.reddit.com/r/artificial/comments/1dv4vtq/reading_app_revives_deceased_hollywood_stars/</link>
      <description><![CDATA[https://www.greenbot.com/reading-app-revives-voices/ 您对此有何看法？    提交人    /u/Aggressive_Thought27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dv4vtq/reading_app_revives_deceased_hollywood_stars/</guid>
      <pubDate>Thu, 04 Jul 2024 11:39:38 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 7/3/2024</title>
      <link>https://www.reddit.com/r/artificial/comments/1duykx7/oneminute_daily_ai_news_732024/</link>
      <description><![CDATA[ 加州大学伯克利分校和 Anyscale 的研究人员推出了 RouteLLM：一种经济高效的 LLM 路由开源框架。[1] Meta 的新技术可以在几分钟内根据文本提示创建 3D 资产。[2] Cloudflare 推出了一款对抗 AI 机器人的工具。[3] Altrove 使用 AI 模型和实验室自动化来创造新材料。[4]  来源： [1] https://www.marktechpost.com/2024/07/01/researchers-from-uc-berkeley-and-anyscale-introduce-routellm-an-open-source-framework-for-cost-effective-llm-routing/ [2] https://economictimes.indiatimes.com/tech/technology/metas-new-tech-can-create-3d-assets-from-text-prompts-within-minutes/articleshow/111463224.cms?from=mdr [3] https://techcrunch.com/2024/07/03/cloudflare-launches-a-tool-to-combat-ai-bots/ [4] https://techcrunch.com/2024/07/03/altrove-uses-ai-models-and-lab-automation-to-create-new-materials/    由   提交  /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1duykx7/oneminute_daily_ai_news_732024/</guid>
      <pubDate>Thu, 04 Jul 2024 04:54:24 GMT</pubDate>
    </item>
    <item>
      <title>哈佛大学的乔纳森·齐特林 (Jonathan Zittrain) 表示，人工智能代理应该有一个生存时间，以防止它们失控地扩散：“给它几个目标，让它有一个银行账户，让它花钱……谁知道它最终会去哪里？”</title>
      <link>https://www.reddit.com/r/artificial/comments/1duwepz/harvards_jonathan_zittrain_says_ai_agents_should/</link>
      <description><![CDATA[        提交人    /u/Maxie445   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1duwepz/harvards_jonathan_zittrain_says_ai_agents_should/</guid>
      <pubDate>Thu, 04 Jul 2024 02:51:50 GMT</pubDate>
    </item>
    <item>
      <title>[AI 与真实成本]：真实拍摄和合成需要花费多少钱？（详情见第一条评论）</title>
      <link>https://www.reddit.com/r/artificial/comments/1duqm42/ai_vs_real_cost_how_much_would_this_cost_to_shoot/</link>
      <description><![CDATA[    /u/Kulimar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1duqm42/ai_vs_real_cost_how_much_would_this_cost_to_shoot/</guid>
      <pubDate>Wed, 03 Jul 2024 22:03:57 GMT</pubDate>
    </item>
    <item>
      <title>是否有人研究过针对替代色彩空间的交叉注意编码？</title>
      <link>https://www.reddit.com/r/artificial/comments/1duhje0/has_anyone_worked_on_crossattention_encoding_for/</link>
      <description><![CDATA[据我所知，RGB 颜色是 VAE 编码和解码所使用的颜色，但是是否有人尝试过创建一个以 CMYK 甚至任意光谱遥测作为输入并可以解码为其他颜色空间的 VAE？ CMYK 可能不是一个很好的例子，因为我相信 CMYK 是 RGB 的真子集（尽管反之则不然）。但是，目前有很多种颜色空间被各种各样的过程使用，我认为能够对模型进行使用训练会很有帮助。 再说一次，CMYK 解码可能比尝试从潜在空间转换为 RGB 再转换为 CMYK（例如用于打印）更有用。 我在 Google 学术搜索和基本网络搜索上做了一些快速搜索，并没有看到任何东西，但这不是我的专业领域。    提交人    /u/Tyler_Zoro   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1duhje0/has_anyone_worked_on_crossattention_encoding_for/</guid>
      <pubDate>Wed, 03 Jul 2024 15:43:28 GMT</pubDate>
    </item>
    <item>
      <title>联想记忆的物理学</title>
      <link>https://www.reddit.com/r/artificial/comments/1dudydx/the_physics_of_associative_memory/</link>
      <description><![CDATA[        提交人    /u/DataPhreak   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dudydx/the_physics_of_associative_memory/</guid>
      <pubDate>Wed, 03 Jul 2024 13:08:51 GMT</pubDate>
    </item>
    <item>
      <title>您可以将草图变成 3D 环境</title>
      <link>https://www.reddit.com/r/artificial/comments/1dua6u0/you_can_turn_a_sketch_into_a_3d_environment/</link>
      <description><![CDATA[        由    /u/Dung3onlord  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dua6u0/you_can_turn_a_sketch_into_a_3d_environment/</guid>
      <pubDate>Wed, 03 Jul 2024 09:28:57 GMT</pubDate>
    </item>
    <item>
      <title>杰弗里·辛顿表示，人工智能已经通过了图灵测试。当人工智能能够解释一个笑话为什么好笑时，它就通过了图灵测试。</title>
      <link>https://www.reddit.com/r/artificial/comments/1du9bi6/geoffrey_hinton_says_ai_has_passed_the_turing/</link>
      <description><![CDATA[        提交人    /u/Maxie445   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1du9bi6/geoffrey_hinton_says_ai_has_passed_the_turing/</guid>
      <pubDate>Wed, 03 Jul 2024 08:26:45 GMT</pubDate>
    </item>
    <item>
      <title>谷歌搜索将人工智能垃圾新闻的排名置于新闻结果中的原始报道之上</title>
      <link>https://www.reddit.com/r/artificial/comments/1dtthjx/google_search_ranks_ai_spam_above_original/</link>
      <description><![CDATA[       提交者    /u/wiredmagazine   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dtthjx/google_search_ranks_ai_spam_above_original/</guid>
      <pubDate>Tue, 02 Jul 2024 18:49:28 GMT</pubDate>
    </item>
    <item>
      <title>最先进的 LLM 效率比人脑低 4 到 6 个数量级。要实现 AGI，需要更好的架构。</title>
      <link>https://www.reddit.com/r/artificial/comments/1dtkdr8/stateoftheart_llms_are_4_to_6_orders_of_magnitude/</link>
      <description><![CDATA[        由    /u/adeno_gothilla   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1dtkdr8/stateoftheart_llms_are_4_to_6_orders_of_magnitude/</guid>
      <pubDate>Tue, 02 Jul 2024 12:16:03 GMT</pubDate>
    </item>
    </channel>
</rss>