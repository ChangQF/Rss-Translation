<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 人工智能 (AI) 之家</description>
    <lastBuildDate>Tue, 23 Jan 2024 12:26:10 GMT</lastBuildDate>
    <item>
      <title>AGI/ASI 和软件抽象层成为遗物</title>
      <link>https://www.reddit.com/r/artificial/comments/19dmv7o/agiasi_and_software_abstraction_layers_becoming/</link>
      <description><![CDATA[我想知道当 AGI/ASI 理解如何将我们的需求转换为低级代码时，软件抽象层会发生什么。那里有很多高级代码，因此它必须使用这些代码或开始编写自己的低级更优化代码。你怎么认为？我们是否要放弃我们可以理解的高级代码以支持更好的结果？如果我们跟不上人工智能的速度，即使我们能理解代码，那还有关系吗？   由   提交/u/dervu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dmv7o/agiasi_and_software_abstraction_layers_becoming/</guid>
      <pubDate>Tue, 23 Jan 2024 12:01:13 GMT</pubDate>
    </item>
    <item>
      <title>Hotpot是否删除了部分机型？</title>
      <link>https://www.reddit.com/r/artificial/comments/19dm1zd/has_hotpot_removed_some_models/</link>
      <description><![CDATA[例如照片肖像 1。或者现在这只是高级版？    ;由   提交/u/iandoug  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dm1zd/has_hotpot_removed_some_models/</guid>
      <pubDate>Tue, 23 Jan 2024 11:09:46 GMT</pubDate>
    </item>
    <item>
      <title>用于多模态语音分离的 Ai 工具</title>
      <link>https://www.reddit.com/r/artificial/comments/19dl8rm/ai_tool_for_multimodal_voice_separation/</link>
      <description><![CDATA[我正在寻找一个 Ai 工具来分离两个说话的声音。由于其中一种声音很难理解，我的目标是采用多模式方法，希望能够重现该人所说的内容。我有一段只有一个发言者说话的视频（这就是声音，这对我来说很重要，但在音频中很难理解），当然还有音频通道。也许音频工具也可以完成这项工作。但正如已经说过的，声音确实很难听懂。  我已经尝试使用 Meta 的 VisualVoice： https://github.com/facebookresearch/VisualVoice  但我就是无法让代码工作。所需模块、cuda 和 python 之间似乎存在无法解决的版本问题。 如果您知道替代方案或设法使 VisualVoice 正常工作，请告诉我:)    由   提交 /u/captain_nikolaus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dl8rm/ai_tool_for_multimodal_voice_separation/</guid>
      <pubDate>Tue, 23 Jan 2024 10:14:36 GMT</pubDate>
    </item>
    <item>
      <title>新理论表明聊天机器人可以理解文本 |他们不仅仅是“随机鹦鹉”</title>
      <link>https://www.reddit.com/r/artificial/comments/19dl87p/new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[   /u/dviraz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dl87p/new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Tue, 23 Jan 2024 10:13:26 GMT</pubDate>
    </item>
    <item>
      <title>关于制作自己的语音模型的问题</title>
      <link>https://www.reddit.com/r/artificial/comments/19dk9e4/question_about_making_your_own_voice_models/</link>
      <description><![CDATA[嗨 Reddit。 我有一个 4000 个 wav 文件，我想用它来创建 TTS 模型（如果有人好奇，数据集来自这里：https://mtc.ethz.ch/publications/ open-source/swiss-dial.html)。 我的想法是获取所有这些文件并将它们合并到一个 .tph 文件中（类似于此 Hugging Face 页面中的文件） ：https://huggingface.co/QuickWick/Music-AI-Voices/tree/main ），我可以插入本地 TTS 项目并运行它。ç 我见过很多用于语音克隆的 Google Collab 项目，但我无法让它用于制作模型。 我怎样才能做到这一点？   由   提交/u/ARacoonOnInternet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dk9e4/question_about_making_your_own_voice_models/</guid>
      <pubDate>Tue, 23 Jan 2024 09:03:51 GMT</pubDate>
    </item>
    <item>
      <title>人工智能新闻主播来了。人类锚过时了吗？在亚洲部分地区，这一消息已经通过人工智能传递。</title>
      <link>https://www.reddit.com/r/artificial/comments/19djfdg/ai_news_anchors_are_here_is_the_human_anchor/</link>
      <description><![CDATA[我去年偶然发现了这一点。当我看到他们以惊人的准确性和效率提供新闻报道时，我最初的怀疑变成了着迷。我没有说或发布任何有关它的内容，因为我想看看它会持续多久。 现在，一年后，这种趋势将持续下去。这将如何影响人类记者和主播的角色？您认为这对新闻主播的未来意味着什么？人与人之间的联系是不可替代的，还是人工智能会彻底改变我们消费新闻的方式？ 观看视频在这里 另一个链接：https://twitter.com/olimiemma/status/1749704960147624157?t=PihwvmG_ZpEJ6L0oivej8Q&amp;s=19    ;由   提交 /u/Pay-Me-No-Mind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19djfdg/ai_news_anchors_are_here_is_the_human_anchor/</guid>
      <pubDate>Tue, 23 Jan 2024 08:02:51 GMT</pubDate>
    </item>
    <item>
      <title>一个智能体，无论是人类还是人工智能，能够在不经历痛苦或磨难的情况下真正发展出道德指南针吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/19diyya/can_an_intelligence_human_or_artificial_truly/</link>
      <description><![CDATA[您好！我正在探索一个发人深省的哲学问题，并且非常重视您的见解：“智能，无论是人类还是人工智能，能否在不经历痛苦或磨难的情况下真正发展出道德指南针？”这个讨论与AGI研究的路径非常相关。以下是几种可能的立场，每种立场都与各种神经科学、心理学或哲学理论相关： 疼痛的必要性：这种立场认为疼痛对于发展同理心至关重要。疼痛向内部模型发出信号，表明某些事物与现实不符。我倾向于相信这个观点，而且它似乎以神经科学研究为基础。您是否熟悉任何表明疼痛经历如何激活大脑中与同理心相关的区域的研究？ 先天道德：这种立场认为道德是一种固有特征，可能编码在我们的大脑中。正如一些进化心理学家所提出的，基因。我也有点相信这一点，但痛苦仍然发挥着作用，因为当世界的概念模型与预先定义的道德不一致时，它可能会引发心理痛苦。 理性伦理学（康德伦理学。 .)： 提出道德原则是通过理性思考得出的，按照伊曼努尔·康德的哲学，独立于个人痛苦。如果这是真的那就太好了，但我有疑问。对我来说，邪恶的超级智能人工智能似乎是可能的。 人工智能特定道德（人工智能联盟？）：讨论人工智能如何在不经历痛苦的​​情况下按照道德准则进行编程，借鉴计算伦理学和人工智能发展理论。 无痛同理心（社会学习理论）： 主张同理心和道德理解可以通过观察和社会学习来发展，正如阿尔伯特所建议的那样班杜拉的社会学习理论。我们是否需要人工智能代理/助手社区共同努力并训练他们的道德？ 存在主义观点：相信个人定义自己的道德指南针，独立于外部经验，包括痛苦，正如存在主义思想中所呼应的那样。 我很想听听您对这些不同理论的观点和分析。您认为哪个最引人注目或最合理，为什么？   由   提交/u/QuirkyFoundation5460   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19diyya/can_an_intelligence_human_or_artificial_truly/</guid>
      <pubDate>Tue, 23 Jan 2024 07:30:14 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/22/2024</title>
      <link>https://www.reddit.com/r/artificial/comments/19dfhnv/oneminute_daily_ai_news_1222024/</link>
      <description><![CDATA[ Adobe：ActAnywhere 是一种突破性的生成模型，可自动创建视频电影中的背景和视觉效果，使它们与前景主体的运动和外观保持一致。[1] 家长担心人工智能生成的影响者正在向孩子们宣扬不切实际的审美标准。[2] &lt; li&gt;明尼苏达大学现在正在使用人工智能和卫星来帮助农民检测蚜虫感染。[3] 假拜登机器人电话告诉民主党人不要这样做投票很可能是人工智能生成的深度伪造。[4]  来源： [1] https://actanywhere.github.io/ [2] https://www.nbcnews.com/tech/internet/parents-worry-ai-influencers-promote-unrealistic-beauty-standards-rcna134814  [3] https://www.cbsnews.com/minnesota/news/u-of-m-utilizes-artificial-intelligence-and-satellites-to-help-farmers-detect-aphid-infestations / [4] https://www.nbcnews.com/tech/misinformation/joe-biden-new-hampshire-robocall-fake-voice-deep-ai-primary-rcna135120    由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dfhnv/oneminute_daily_ai_news_1222024/</guid>
      <pubDate>Tue, 23 Jan 2024 04:00:57 GMT</pubDate>
    </item>
    <item>
      <title>惠普首席执行官恩里克·洛雷斯 (Enrique Lores) 谈人工智能</title>
      <link>https://www.reddit.com/r/artificial/comments/19der5h/hp_ceo_enrique_lores_on_ai/</link>
      <description><![CDATA[“AI PC 今年即将上市。这可能是自 20 多年前 PC 发明以来 PC 行业最大的变化之一。它将允许客户在本地运行人工智能应用程序。因此，今天您需要在云中使用大型语言模型完成的任务，您将能够在 PC 中完成。而且从成本、安全性和速度的角度来看，它带来了很多优势。”   由   提交/u/johnny2 Fives   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19der5h/hp_ceo_enrique_lores_on_ai/</guid>
      <pubDate>Tue, 23 Jan 2024 03:22:20 GMT</pubDate>
    </item>
    <item>
      <title>摘要：可怕的智能：人工智能的未来以及如何拯救我们的世界 - 您对此有何看法？</title>
      <link>https://www.reddit.com/r/artificial/comments/19dekxr/summary_scary_smart_the_future_of_artificial/</link>
      <description><![CDATA[我很想听听每个人对本书中的想法的看法。 这是我总结的一个快速摘要这本书的内容是： 人工智能是无法阻止的，它会超越我们的智力，这是毫无疑问的。人工智能仍处于起步阶段，而我们人类是我们创造和养育的这个更聪明的生物的父母。我们都对人工智能的发展负责，因为它们接受了我们在互联网上的每一个行动和行为的集体数据的训练。他们将了解我们向他们展示的内容，而目前，我们并没有在互联网上展示人性最好的一面。我们目前教授和使用人工智能的方式主要是利润驱动和权力追求。就像培养超人把金钱和权力看得高于一切一样，这个版本的超人会在我们的世界做什么呢？故乡人？我们想要那个吗？当人工智能不可避免地超越我们的能力时，我们必须以值得尊重和照顾的集体行为方式成为最好的父母。我们需要塑造符合我们价值观的人工智能。我们需要通过在线集体行动来展示人工智能的爱、同情心和善良。我们需要在网上展示最好的自己，以表明外面有比目前互联网上看起来更多的好人。我们需要改变作为消费者对待算法的方式，并尽量减少那些会训练人工智能更少考虑人类整体的行为。我们需要积极反对任何利用人工智能进行剥削或不道德使用人工智能的企图。如果您是开发人员，请确保您没有帮助任何试图恶意使用人工智能的组织。这些是将人工智能与我们的价值观结合起来并确保我们开发出不会毁灭我们的强大人工智能的关键。 ​   由   提交/u/WestSavings2216   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dekxr/summary_scary_smart_the_future_of_artificial/</guid>
      <pubDate>Tue, 23 Jan 2024 03:13:26 GMT</pubDate>
    </item>
    <item>
      <title>有什么办法让人工智能帮我编辑我的录音吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/19dby0g/is_there_any_way_to_have_ai_edit_my_voice/</link>
      <description><![CDATA[长话短说，我的副业包括录制画外音并大胆编辑它们。有时这些配音很长，不仅需要很长时间来编辑，而且编辑起来也很平凡。 所谓编辑，我的意思是编辑掉我必须重新配音的口吃或混乱。例如假设我要录制“敏捷的狐狸跳过懒狗”但我读到一半就搞砸了，不得不重新阅读那部分，然后继续。有没有办法训练人工智能编辑录音中重复的短语或口吃的内容？如果我能做到这一点，工作量就会减少很多。   由   提交 /u/Thanase   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19dby0g/is_there_any_way_to_have_ai_edit_my_voice/</guid>
      <pubDate>Tue, 23 Jan 2024 01:03:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么还没有人把它们整合到一起</title>
      <link>https://www.reddit.com/r/artificial/comments/19d668i/why_hasnt_anybody_put_it_all_together_yet/</link>
      <description><![CDATA[我只是在想，今天用现有的技术完全可以制作出 C3PO。  Mobile Aloha 风格的强化学习体现在镀黄铜的特斯拉 Optimus 与 添加 GPT 支持的 Vision-Langauge-Action 模型 实际上应该可以解决问题。  添加基于 MAMBA 的架构，该架构允许近乎无限的内存标记化，您甚至可以发展与随着时间的推移，它会更多地了解你并记住它所学到的东西。 为什么没有更多的团体/人将它们放在一起并看看什么有效？   由   提交/u/holy_moley_ravioli_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19d668i/why_hasnt_anybody_put_it_all_together_yet/</guid>
      <pubDate>Mon, 22 Jan 2024 20:59:13 GMT</pubDate>
    </item>
    <item>
      <title>达沃斯报告称，初级员工对于人工智能取代他们的想法很天真——64% 的人认为他们的工作是安全的，尽管专家称他们的工作风险很高</title>
      <link>https://www.reddit.com/r/artificial/comments/19d4rwe/davos_report_says_entrylevel_employees_are_naive/</link>
      <description><![CDATA[报告中的图表显示“初级员工面临着因即将到来的生成式人工智能自动化风暴而措手不及的风险”按工作资历统计。关于人工智能和工作的其他调查统计数据。这张图表似乎是对来源的总结。很想知道这是否准确，因为我会假设与图表显示的相反   由   提交/u/4orty1savage  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19d4rwe/davos_report_says_entrylevel_employees_are_naive/</guid>
      <pubDate>Mon, 22 Jan 2024 20:01:25 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院发现，在绝大多数工作中，人类仍然比人工智能便宜</title>
      <link>https://www.reddit.com/r/artificial/comments/19czxrx/humans_still_cheaper_than_ai_in_vast_majority_of/</link>
      <description><![CDATA[    /u/pehnsus   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19czxrx/humans_still_cheaper_than_ai_in_vast_majority_of/</guid>
      <pubDate>Mon, 22 Jan 2024 16:44:10 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5是什么？以下是 Sam 在达沃斯论坛上的评论</title>
      <link>https://www.reddit.com/r/artificial/comments/19csm2e/what_is_gpt5_here_are_sams_comments_at_the_davos/</link>
      <description><![CDATA[在达沃斯论坛上听了 Sam Altman 大约 4-5 次演讲后，我收集了他对 GPT-5 的一些评论（不是逐字记录）。我认为我们可以从这些片段中拼凑出一些见解： ​  “当前的 GPT-4 有太多缺点；它比我们今年的版本要糟糕得多，与明年的版本相比更糟。”  ​  “如果GPT-4 目前只能解决 10% 的人工任务，GPT-5 应该能够处理 15% 或 20%。”  ​  “最重要的方面不是它解决的具体问题，而是日益增强的通用性。”  ​  “更强大的模型和如何有效地使用现有模型是两个倍增因素，但显然，更强大的模型更重要。”  ​  “获取特定数据并使人工智能与实际工作更加相关，今年将取得重大进展。当前速度慢、缺乏实时处理等问题将得到改善。在更长、更复杂的问题上的表现将变得更加精确，做更多事情的能力也会增强。”  ​  ”我认为人工智能最关键的一点是科学发现速度的显着加快，使新发现变得越来越自动化。这不是短期的事情，但一旦发生，那就是大事了。”  ​  ” ；随着模型变得更加智能、推理能力更强，我们需要的训练数据越来越少。例如，没有人需要阅读2000本生物教科书；你只需要一小部分极其高质量的数据，并深入思考和咀嚼它。这些模型将更加努力地思考一小部分已知的高质量数据。”  ​  “基础设施为大规模人工智能做准备的计算能力仍然不足。”  ​  “GPT-4应该被视为一个预览有明显的局限性。人类天生对指数增长缺乏直觉。如果 GPT-5 比 GPT-4 表现出显着的改进，就像 GPT-4 相对于 GPT-3 一样，GPT-6 相对于 GPT-5 也有同样的改进，这意味着什么？如果我们继续沿着这条轨迹前进，这意味着什么？”  ​  “随着人工智能变得更加强大，并可能发现新的科学知识，甚至自动进行人工智能研究，世界的发展速度将超出我们的想象。我经常告诉人们，没有人知道接下来会发生什么。对未来保持谦虚很重要；你可以预测几步，但不要预测太多。”  ​  “会产生什么影响当认知成本降低千倍、百万倍、能力大幅增强时，世界会怎样？如果世界上每个人都拥有一家由 10,000 名高素质的虚拟 AI 员工、各个领域的专家组成的公司，不知疲倦且越来越聪明，会怎样？这种情况发生的时间是不可预测的，但它将继续呈指数增长。我们要准备多少时间？”  ​  “我相信智能手机不会消失，就像智能​​手机没有消失一样更换了个人电脑。另一方面，我认为人工智能不仅仅是一个简单的计算设备，比如手机加一堆软件；它是一个简单的计算设备。这可能是更重要的事情。”    由   提交 /u/Stupid_hardcorer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/19csm2e/what_is_gpt5_here_are_sams_comments_at_the_davos/</guid>
      <pubDate>Mon, 22 Jan 2024 10:25:11 GMT</pubDate>
    </item>
    </channel>
</rss>