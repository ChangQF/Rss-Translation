<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Sun, 24 Nov 2024 03:32:22 GMT</lastBuildDate>
    <item>
      <title>我让 ChatGPT 根据柏拉图的著作和描述生成一张亚特兰蒂斯的照片。以下是生成的照片。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gydvdm/i_asked_chatgpt_to_generate_a_photo_of_atlantis/</link>
      <description><![CDATA[        由    /u/Pixelated_Avocado  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gydvdm/i_asked_chatgpt_to_generate_a_photo_of_atlantis/</guid>
      <pubDate>Sun, 24 Nov 2024 00:10:45 GMT</pubDate>
    </item>
    <item>
      <title>图像生成器 IA，免费版和付费版</title>
      <link>https://www.reddit.com/r/artificial/comments/1gyagka/image_generator_ia_free_and_cost_version/</link>
      <description><![CDATA[      你好，晚安  我想知道谁是生成动漫图像的最佳 IA，或者一般所有类型的图像，但我想制作自己的场景和角色（例如，一个女人拿着一个大橡胶锤正要砸碎闹钟，这时她即将醒来），或者例如交叉图像并生成一个融合，就像这个女孩（Kouko），穿着绿色的连衣裙，手里拿着兔八哥的木槌，用木槌砸碎了时钟，里面有动漫的主角 https://preview.redd.it/dy5mu852yp2e1.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=3e3abb9298df28ed4af2e328071791c3d6dd7504 这个穿着绿色连衣裙的女孩（Kouko）手里拿着兔八哥木槌，用木槌砸碎了时钟，里面有动漫的主角 或者例如这个金发女人拿着橡胶锤（聊天 gpt）来做这些事？ https://preview.redd.it/evf3ve1kyp2e1.png?width=862&amp;format=png&amp;auto=webp&amp;s=bf7df59b6757cf9bfa324cf46006c107a9204f9a https://preview.redd.it/n768f9abzp2e1.jpg?width=401&amp;format=pjpg&amp;auto=webp&amp;s=a62938e1e215d002010aeba55d05a8f65fa8a539    提交人    /u/MakotoGamer   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gyagka/image_generator_ia_free_and_cost_version/</guid>
      <pubDate>Sat, 23 Nov 2024 21:32:46 GMT</pubDate>
    </item>
    <item>
      <title>建模和优化任务选择以实现情境强化学习中的更好迁移</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy8vee/modeling_and_optimizing_task_selection_for_better/</link>
      <description><![CDATA[本文介绍了一种将基于模型的迁移学习与情境强化学习相结合的方法来改善环境之间的知识迁移。该方法的核心是学习可重复使用的环境动态，同时适应特定于上下文的变化。 关键技术组件：  上下文模型架构，分离共享特征和特定于上下文的特征 迁移学习机制，识别和保留核心动态 探索策略，平衡已知行为与新行为 通过跨上下文模型重用进行样本高效训练  结果显示与基线相比有显着改进：  新环境适应所需样本减少 40% 在复杂导航任务上具有更好的渐近性能 在不同上下文中具有更稳定的学习曲线 即使在环境变化很大的情况下也能有效转移  我认为这种方法对于训练数据昂贵且环境经常变化的机器人应用特别有价值。共享动态与特定动态的分离似乎是分解迁移学习问题的自然方法。 话虽如此，我对计算开销感到好奇——建模环境动态并不便宜，而且本文没有深入分析这种权衡。我还希望在更广泛的领域进行测试，以更好地了解这种方法在哪些领域效果最好。 TLDR：将基于模型的方法与上下文 RL 相结合，实现环境之间的有效知识转移。通过可重复使用的动态建模，样本效率提高了 40%，性能也有所提高。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy8vee/modeling_and_optimizing_task_selection_for_better/</guid>
      <pubDate>Sat, 23 Nov 2024 20:22:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用人工智能制作更可靠的报告——技术指南</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy245y/how_to_make_more_reliable_reports_using_ai_a/</link>
      <description><![CDATA[        提交人    /u/phicreative1997   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy245y/how_to_make_more_reliable_reports_using_ai_a/</guid>
      <pubDate>Sat, 23 Nov 2024 15:27:49 GMT</pubDate>
    </item>
    <item>
      <title>在 Claude 的表现与顶级人类 AI 研究人员相当后，顶级预测员大大缩短了他的时间表</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy1rab/top_forecaster_significantly_shortens_his/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy1rab/top_forecaster_significantly_shortens_his/</guid>
      <pubDate>Sat, 23 Nov 2024 15:11:57 GMT</pubDate>
    </item>
    <item>
      <title>介绍 NexAI：一个由 AI 驱动的 Web 框架 🚀</title>
      <link>https://www.reddit.com/r/artificial/comments/1gy00bc/introducing_nexai_an_aipowered_web_framework/</link>
      <description><![CDATA[大家好！👋 我和我的团队一直在研究一件我认为可以为开发人员带来重大改变的事情——NexAI，这是一个由人工智能驱动的 Web 框架，可以帮助处理无聊、重复的代码，这样您就可以专注于创造性的东西。🚀 以下是 NexAI 的功能： ✅ 多 LLM 支持 ✅ 组件提示为文档字符串 ✅ 样板代码检索 ✅ 完整代码库上下文 ✅ 使用终端命令进行持续重构 我很好奇，您对当前的 Web 开发工具有何看法？您是否发现自己在重复任务或样板代码上花费了太多时间？我想构建一些东西来帮助您腾出时间，以便您可以专注于编码的有趣部分。 我很想听听您的想法！您认为像 NexAI 这样的东西有用吗？有什么建议或功能您想看吗？让我们聊聊吧！😎 在此处查看演示：演示视频    提交人    /u/ni_shant1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gy00bc/introducing_nexai_an_aipowered_web_framework/</guid>
      <pubDate>Sat, 23 Nov 2024 13:48:39 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 22 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</link>
      <description><![CDATA[ Enveda Biosciences 筹集 1.3 亿美元，用于推进从天然化合物中发现人工智能驱动的药物。[1] OpenAI 正在资助“人工智能道德”研究。[2] 亚马逊 将对人工智能初创公司 Anthropic 的总投资增加到 80 亿美元。[3] 伊利诺伊州猎人使用无人机和人工智能。[4]  来源： [1] https://siliconangle.com/2024/11/21/enveda-biosciences-raises-130m-advance-ai-driven-drug-discovery-natural-compounds/ [2] https://techcrunch.com/2024/11/22/openai-is-funding-research-into-ai-morality/ [3] https://venturebeat.com/ai/amazon-doubles-down-on-anthropic-positioning-itself-as-a-key-player-in-the-ai-arms-race/ [4] https://www.outdoornews.com/2024/11/22/drone-ai-use-by-hunters-addressed-in-illinois/    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxsppo/oneminute_daily_ai_news_11222024/</guid>
      <pubDate>Sat, 23 Nov 2024 05:47:41 GMT</pubDate>
    </item>
    <item>
      <title>精准知识编辑与现有机器学习方法的比较</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</link>
      <description><![CDATA[我一直在研究一个名为 PKE（精确知识编辑）的项目，这是一种开源方法，通过减少有毒内容生成而不影响其总体性能来提高 LLM 的安全性。它的工作原理是使用神经元权重跟踪和激活通路跟踪来识别模型中的“有毒热点”，并通过自定义损失函数对其进行修改。目前有很多机器反学习技术可以使 LLM 更安全，例如：  精确反学习：此方法涉及在删除不需要的数据后从头开始重新训练模型。虽然它可以确保完全消除数据的影响，但它在计算上是昂贵的并且耗时的，尤其是对于大型模型而言。 近似反学习：  微调：使用剩余数据调整模型以减轻已删除数据的影响。但是，这可能无法完全消除数据的影响。 梯度上升：对要遗忘的数据的损失函数应用梯度上升，有效地“忘记”它。这种方法可能不稳定，并可能降低模型性能。   PKE 更好，原因如下：  毒性参数的细粒度识别：PKE 采用神经元权重跟踪和激活通路追踪来准确定位模型中负责生成有毒或有害内容的特定区域。这种精度允许有针对性的干预，从而降低模型整体行为发生意外改变的风险。 保持模型性能：通过将编辑重点放在已识别的毒性区域，PKE 最大限度地减少了对模型总体性能的影响。这种方法可确保模型在各种任务中保持其功能，同时有效减少不良内容的生成。 跨不同模型架构的可扩展性：PKE 已证明在各种 LLM 架构中都有效，包括 Llama2-7b 和 Llama-3-8b-instruct 等模型。这种可扩展性使其成为增强各种 AI 系统安全性的多功能工具。  很想听听你们对这个项目的想法，以及如何继续改进这种方法。如果有兴趣，这里是 Github 链接：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 和 论文 。    提交人    /u/lial4415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxmgxw/comparing_precision_knowledge_editing_with/</guid>
      <pubDate>Sat, 23 Nov 2024 00:10:23 GMT</pubDate>
    </item>
    <item>
      <title>Dario Amodei 表示，尽管 AGI 不是一个好词，因为我们正在不断进步，但“我们正处于一个为期两年的时期的开始，我们将陆续通过所有这些门槛”，以完成有意义的工作</title>
      <link>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gxblg0/dario_amodei_says_although_agi_is_not_a_good_term/</guid>
      <pubDate>Fri, 22 Nov 2024 16:19:33 GMT</pubDate>
    </item>
    <item>
      <title>采用：一种改进的 Adam 优化器，保证对任何 Beta-2 值都收敛</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</link>
      <description><![CDATA[Adam 的新修改版 ADOPT 能够实现最佳收敛率，而不管 β₂ 参数选择如何。关键见解是在 Adam 的更新规则中添加一个简单的项，当 β₂ 设置不理想时，该项可以补偿潜在的收敛问题。 技术细节：- ADOPT 通过引入与 (1-β₂) 成比例的附加项来修改 Adam 的更新规则 - 理论分析证明对于任何 β₂ ∈ (0,1)，收敛速度为 O(1/√T) - 适用于凸优化和非凸优化 - 保持 Adam 的实际优势，同时提高理论保证 - 无需额外的超参数调整 关键结果：- 匹配 SGD 的最佳收敛速度以实现平滑的非凸优化 - 在测试场景中，经验上的表现与 Adam 相似或更好 - 通过改变 β₂ 值提供更稳健的收敛行为 - 理论保证在标准平滑度假设下成立 我认为这对于实际的深度学习应用非常有用，因为与学习率调整相比，β₂ 调整经常被忽视。无论 β₂ 选择如何，保证收敛都会减少超参数搜索空间。修改非常简单，可以轻松纳入现有的 Adam 实现中。 但是，我认为我们需要对大规模问题进行更广泛的实证验证，才能充分了解实际影响。理论保证令人鼓舞，但现代架构上的实际性能才是真正的考验。 TLDR：ADOPT 使用一个简单的术语修改 Adam，保证任何 β₂ 值的最佳收敛速度，从而可能简化优化器调整同时保持性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx88b4/adopt_a_modified_adam_optimizer_with_guaranteed/</guid>
      <pubDate>Fri, 22 Nov 2024 13:47:40 GMT</pubDate>
    </item>
    <item>
      <title>具有速度控制功能的 ElevenLabs 替代方案</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx71sv/elevenlabs_alternative_with_speed_control/</link>
      <description><![CDATA[ElevenLabs 中的声音很棒，但我创建了语言学习内容，他们的声音说得太快了 我尝试使用 ... . 和其他标点符号，但为了正确发音，我需要听几次，而且显然 ElevenLabs 会收取测试费用，所以效果不佳  所以，基本上我需要 ElevenLabs 但带有速度控制 是的，我知道我可以使用其他软件来改变速度，但是当我这样做时，要么音调太荒谬，要么声音听起来太电子化和不自然 提前谢谢您    提交人    /u/Aromatic-Solid97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx71sv/elevenlabs_alternative_with_speed_control/</guid>
      <pubDate>Fri, 22 Nov 2024 12:48:56 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 11 月 21 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gx0v9w/oneminute_daily_ai_news_11212024/</link>
      <description><![CDATA[ 麻省理工学院的研究人员开发出一种有效的方法来训练更可靠的人工智能代理。[1] 据报道，Uber投资了自动驾驶公司Pony.ai。[2] 阿里巴巴刚刚发布了Marco-o1：推进人工智能的开放式推理。[3] Nvidia的盈利超出预期，因为投资者关注对Blackwell人工智能芯片的需求。[4]  来源： [1] https://news.mit.edu/2024/mit-researchers-develop-efficiency-training-more-reliable-ai-agents-1122 [2] https://www.pymnts.com/news/investment-tracker/2024/uber-reportedly-investing-in-autonomous-driving-firm-pony-ai/ [3] https://www.marktechpost.com/2024/11/21/alibaba-just-released-marco-o1-advancing-open-ended-reasoning-in-ai/ [4] https://apnews.com/article/nvidia-ai-earnings-report-adc942aa0e0c5d1a550b7bad486b942a    由    /u/Excellent-Target-847  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gx0v9w/oneminute_daily_ai_news_11212024/</guid>
      <pubDate>Fri, 22 Nov 2024 05:43:09 GMT</pubDate>
    </item>
    <item>
      <title>Andrew Ng 的新 AI 视觉代理，如他在最新的 Youtube 演示中演示的那样。玩起来很有趣，但可能不如其竞争对手那么强大……</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwwoq0/andrew_ngs_new_ai_vision_agent_as_demoed_in_his/</link>
      <description><![CDATA[  由    /u/Chris_in_Lijiang  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwwoq0/andrew_ngs_new_ai_vision_agent_as_demoed_in_his/</guid>
      <pubDate>Fri, 22 Nov 2024 01:56:35 GMT</pubDate>
    </item>
    <item>
      <title>Minecraft 评估：左：新 GPT-4o。右：旧 GPT-4o</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwldxu/minecraft_eval_left_new_gpt4o_right_old_gpt4o/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwldxu/minecraft_eval_left_new_gpt4o_right_old_gpt4o/</guid>
      <pubDate>Thu, 21 Nov 2024 17:48:10 GMT</pubDate>
    </item>
    <item>
      <title>10 个团队，每个团队由 10 名代理组成，完全自主地撰写一本书</title>
      <link>https://www.reddit.com/r/artificial/comments/1gwjreb/10_teams_of_10_agents_are_writing_a_book_fully/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gwjreb/10_teams_of_10_agents_are_writing_a_book_fully/</guid>
      <pubDate>Thu, 21 Nov 2024 16:45:51 GMT</pubDate>
    </item>
    </channel>
</rss>