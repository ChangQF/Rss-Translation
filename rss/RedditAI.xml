<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 人工智能 (AI) 之家</description>
    <lastBuildDate>Mon, 19 Feb 2024 00:57:46 GMT</lastBuildDate>
    <item>
      <title>人工智能内容的强制版权怎么样？</title>
      <link>https://www.reddit.com/r/artificial/comments/1au853s/what_about_a_mandatory_copyright_for_ai_content/</link>
      <description><![CDATA[版权是现实，而且有效。人们对区分人工智能生成的内容和真实的人类内容的能力感到非常沮丧。这会是真的吗？如果我们能够对所有人工智能内容（视频、文本、音频等）拥有强制版权，那就太好了。 如果内容是由 Al 生成？   由   提交/u/Dramatic_Disaster837   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1au853s/what_about_a_mandatory_copyright_for_ai_content/</guid>
      <pubDate>Sun, 18 Feb 2024 23:19:25 GMT</pubDate>
    </item>
    <item>
      <title>最好的拉格？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atz048/best_rag/</link>
      <description><![CDATA[我非常喜欢使用 ChatPDF 和 Perplexity AI 的免费版本，并且我已经开始使用 Gemini Pro。但我想看看是否有更好的替代方案。 具体来说：  哪些在提取细节方面最准确？例如，如果我问文本中清楚概述的过程中的所有步骤是什么，Perplexity 和 Gemini 都倾向于错过一些步骤。 我是否有任何地方可以一次上传多个文档，或者在同一个线程或对话中上传多个文档，以便我可以要求它比较或综合不同来源的信息？    由   提交 /u/SignalWorldiness873   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atz048/best_rag/</guid>
      <pubDate>Sun, 18 Feb 2024 17:09:45 GMT</pubDate>
    </item>
    <item>
      <title>有什么是人类永远无法实现的，而人工智能却做得非常出色并且会做得更好的事情？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atyzu2/what_is_something_humans_will_never_be_able_to/</link>
      <description><![CDATA[您认为人工智能的进步会发生什么以及 QO 增长的阶段是什么。有人相信人工智能会拥有只有人工智能才能做到的特殊才能吗？    由   提交 /u/romer2o   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atyzu2/what_is_something_humans_will_never_be_able_to/</guid>
      <pubDate>Sun, 18 Feb 2024 17:09:25 GMT</pubDate>
    </item>
    <item>
      <title>我想要“Monica Bellucci”，但中途给了我“Dua Lipa”！</title>
      <link>https://www.reddit.com/r/artificial/comments/1atwnuh/i_wanted_monica_bellucci_but_midjourney_gave_me/</link>
      <description><![CDATA[   （在Midjourney V6上测试了一些提示以获得不错的油画效果）   由   提交 /u/Armand_Roulinn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atwnuh/i_wanted_monica_bellucci_but_midjourney_gave_me/</guid>
      <pubDate>Sun, 18 Feb 2024 15:30:59 GMT</pubDate>
    </item>
    <item>
      <title>由人工智能管理的大学</title>
      <link>https://www.reddit.com/r/artificial/comments/1atwm9o/university_run_by_ai/</link>
      <description><![CDATA[想象一下，您从大学网站上抓取课程，让 chatGPT 编写课程大纲，构建模块，并将每天的学习材料链接到YouTube 视频或博客。可以办到。  现在你有大学课程了。您在线托管它。您可以使用课程材料、视频抄本创建聊天机器人或自定义 GPT，并将其变成一名教师。这位老师将为您评分、提出问题、创建考试并帮助您理解材料。 大学实行付费墙有 3 个原因： 1) 他们隐藏日常材料 2) 他们有证书3) 他们与行业标准和人员有内部联系 但我们都知道他们使用的信息可能已经过时，无论如何他们都会将我们链接到 YouTube 视频，并且你在学位结束时获得的论文变得不那么有价值（前提是你可以向你未来的雇主展示专业知识[而且，对于内容创作者来说非常好，这无论如何都是新经济]） 我的问题是，为什么我们还没有做到这一点吗？  1）是机器人的编程和创建吗？需要Python吗？2）是因为我们太分心了吗？没有看到其中的价值？ 分享您的想法。因为我已经为健康科学学士创建了一门课程，说实话，我觉得如果我观看所有 YouTube 视频、阅读博客并接受这些信息的测试，我将有能力与过去 4 年来的任何毕业生竞争。 - 将这所人工智能大学与某种形式的知识展示结合起来，比如创建一个 TikTok 社区，在那里你可以像教室一样与其他学生分享，我可以看到如何轻松地在该主题上建立权威，以向雇主展示并获得公众关注。   由   提交 /u/TheCouncilNovel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atwm9o/university_run_by_ai/</guid>
      <pubDate>Sun, 18 Feb 2024 15:29:09 GMT</pubDate>
    </item>
    <item>
      <title>为AI语音模型制作数据集的最佳方法？数据太多是一个问题吗？多少个纪元？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atuoyy/best_way_to_make_a_data_set_for_ai_voice_model_is/</link>
      <description><![CDATA[我不确定这是否是最好的提问地点，但我一直在用 RVC 来制作语音模型。我有相当高质量的 .wav 文件，并使用不同的数据集创建了 .pth/indexes。奇怪的是，我的一些模型在完全不同的数据集上表现得非常好。其中一个以 2 分钟和 500 个 epoch 的成绩表现不错。另一个有一个更大的数据集，大约 20-25 分钟，具有相同的时期。然后我尝试完善其中之一。给它更多的数据，大约 40 分钟，声音听起来与 250 个时期的声音完全不同。 （我读过有关过度训练的内容，并在数据集更大时尝试避免过度训练）。我还尝试将数据集分割成 10-12 秒的块，或者仅使用一个具有相同语音剪辑的较大 .wav 文件。就我个人而言，我注意到这两者之间没有区别。 如果数据太多，我对要执行多少个 epoch 感到非常困惑。以及根据其他人的经验，将数据分割成段或仅使用一个 20 分钟以上的块文件是好是坏。哦，如果 .wav 保存为立体声与单声道有什么区别吗？立体声是否可能会导致更多“噪音”？阅读而不是关注声音的发音？ 此外，我一直在使用 Kits AI 来测试语音模型听起来是否像我想要的那样，因为他们有一个简单的方法免费上传并在短片中使用免费音频生成器，从说话到唱歌。我的第一个测试只进行了 50 个 epoch，数据较少，结果比我的 100+ 个数据较多的测试要好得多。   由   提交/u/Vast_Description_206   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atuoyy/best_way_to_make_a_data_set_for_ai_voice_model_is/</guid>
      <pubDate>Sun, 18 Feb 2024 13:59:09 GMT</pubDate>
    </item>
    <item>
      <title>AI-Town，朴俊成</title>
      <link>https://www.reddit.com/r/artificial/comments/1atm9me/aitown_joon_sung_park/</link>
      <description><![CDATA[有人玩过 AI-Town Github 存储库 (https://github.com/a16z-infra/ai-town)  ；或者 Joon Sung Park 的生成代理存储库？ （https://github.com/joonspk-research/generative_agents） 只是想知道是否有人最近已经开始工作了。诚然，我是一个门外汉，但通常可以在 code-gpts 的帮助下让事情顺利进行。在这种情况下，我遇到了一些问题。  对理解运行社会科学模拟的应用程序非常感兴趣。即使只是简单的例子，说明它对未来更深入的模拟意味着什么。    由   提交 /u/StillVikingabroad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atm9me/aitown_joon_sung_park/</guid>
      <pubDate>Sun, 18 Feb 2024 05:10:58 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2/​​17/2024</title>
      <link>https://www.reddit.com/r/artificial/comments/1atm6ep/oneminute_daily_ai_news_2172024/</link>
      <description><![CDATA[ Nvidia 本周将震撼市场。黄仁勋的 Nvidia 是去年表现最好的股票之一，预计将于周三发布一份巨大的收益报告。[1] 软银集团首席执行官 Masayoshi孙正义希望为一家芯片企业筹集高达 1000 亿美元的资金，该企业将与 Nvidia 公司竞争。[2] Nvidia 首次公开表示其最快的 AI 超级计算机 - Eos 由 4,608 个 H100 GPU 提供支持，专为生成式 AI 进行了调整。[3] Google 开源 Magika：AI 驱动文件识别工具。[4]  来源： [1] https://www.thestreet.com/technology/nvidia-and-jensen-huang-will-rock-markets-this-week&lt; /p&gt; [2] https://finance.yahoo.com /news/softbanks-son-seeking-100-billion-195604330.html [3] https： //www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-provides-the-first-public-view-of-its-fastest-ai-supercomputer-eos-is-powered-by-4608-h100- gpus-tuned-for-generative-ai [4] https://thehackernews.com/2024/02/google-open-sources-magika-ai-powered.html   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atm6ep/oneminute_daily_ai_news_2172024/</guid>
      <pubDate>Sun, 18 Feb 2024 05:05:34 GMT</pubDate>
    </item>
    <item>
      <title>你不能称之为 RAG 上下文 - 当前上下文连贯性类似于 1-Shot - 这是对上下文含义的虚构吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1atf3lb/you_cant_call_rag_context_current_context/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1atf3lb/you_cant_call_rag_context_current_context/</guid>
      <pubDate>Sat, 17 Feb 2024 23:06:06 GMT</pubDate>
    </item>
    <item>
      <title>SORA 之后，我开始感受到 AGI - 重新审视 Agent 论文：Agent AI 正在成为通向 AGI 的一条有希望的途径 - W* 视觉语言模型</title>
      <link>https://www.reddit.com/r/artificial/comments/1at5vpi/after_sora_i_am_starting_to_feel_the_agi/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at5vpi/after_sora_i_am_starting_to_feel_the_agi/</guid>
      <pubDate>Sat, 17 Feb 2024 16:31:12 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 如何反击 Gemini 推出 Sora</title>
      <link>https://www.reddit.com/r/artificial/comments/1at4vu5/the_way_openai_countered_geminis_launch_with_sora/</link>
      <description><![CDATA[当然，人工智能领域总是存在良性竞争，但这感觉......不同。 OpenAI 用 Sora 对抗 Gemini 的方式简直就是侵略性的。让你怀疑他们是否在幕后拿出了一些秘密武器，一些超级强大的人工智能系统。我从来没有见过 Google 受到如此大的打击，而且我们只是在二月......天知道接下来会发生什么   由   提交/u/AI_Nietzsche   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at4vu5/the_way_openai_countered_geminis_launch_with_sora/</guid>
      <pubDate>Sat, 17 Feb 2024 15:46:37 GMT</pubDate>
    </item>
    <item>
      <title>向无人机投降</title>
      <link>https://www.reddit.com/r/artificial/comments/1at4d0v/surrendering_to_drones/</link>
      <description><![CDATA[在乌克兰与俄罗斯的冲突中，关于杀死试图向无人机投降的士兵是否构成战争罪的争论正在进行中。问题是，这是否会使所有自主武器基本上成为步行（或飞行）战争罪，因为你不能向它们投降？这是一个棘手的情况，因为这些无人机无法识别投降，这似乎违反了战争规则。你觉得怎么样？   由   提交 /u/_____awesome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1at4d0v/surrendering_to_drones/</guid>
      <pubDate>Sat, 17 Feb 2024 15:22:34 GMT</pubDate>
    </item>
    <item>
      <title>加拿大航空被勒令向被航空公司聊天机器人误导的客户付款</title>
      <link>https://www.reddit.com/r/artificial/comments/1aswthf/air_canada_ordered_to_pay_customer_who_was_misled/</link>
      <description><![CDATA[      在法庭上，加拿大航空声称自己不承担责任聊天机器人所说的内容，因为聊天机器人是一个“独立的法人实体”。   由   提交/u/Parisian75009  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1aswthf/air_canada_ordered_to_pay_customer_who_was_misled/</guid>
      <pubDate>Sat, 17 Feb 2024 08:02:30 GMT</pubDate>
    </item>
    <item>
      <title>解释 OpenAI Sora 的技术，这是机器模拟我们的世界的重要下一步</title>
      <link>https://www.reddit.com/r/artificial/comments/1askfyz/explaining_openai_soras_technology_the_vital_next/</link>
      <description><![CDATA[      人工智能如何将静态图像转换为动态图像动态、逼真的视频？ OpenAI 的 Sora 通过时空补丁的创新使用引入了答案。 我对 Sora 的底层训练过程和补丁进行了解释https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b  &lt; a href=&quot;https://i.redd.it/e5yccw3io0jc1.gif&quot;&gt;图像切片过程 它能够理解和开发近乎完美的视觉模拟，包括像《我的世界》这样的数字世界，这将有所帮助它为未来的人工智能创建培训内容。为了让人工智能导航我们的世界，它需要数据和系统来帮助它更好地理解。 我们现在可以解锁虚拟现实 (VR) 的新高度，因为它改变了我们看待数字环境的方式，突破了VR 达到新高度。能够创建近乎完美的 3D 环境，我们现在可以将其与 Apple Vision Pro 或 Meta Quest 上按需的世界空间计算结合起来。   由   提交 /u/koconder   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1askfyz/explaining_openai_soras_technology_the_vital_next/</guid>
      <pubDate>Fri, 16 Feb 2024 21:40:33 GMT</pubDate>
    </item>
    <item>
      <title>事实上，SORA 不仅仅是生成视频，它还模拟物理现实并记录结果，这一事实似乎超出了人们对刚刚揭晓的内容规模的概括理解。</title>
      <link>https://www.reddit.com/r/artificial/comments/1ascmbm/the_fact_that_sora_is_not_just_generating_videos/</link>
      <description><![CDATA[   /u/holy_moley_ravioli_   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1ascmbm/the_fact_that_sora_is_not_just_generating_videos/</guid>
      <pubDate>Fri, 16 Feb 2024 16:21:57 GMT</pubDate>
    </item>
    </channel>
</rss>