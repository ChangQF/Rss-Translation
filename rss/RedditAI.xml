<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit 的人工智能之家</description>
    <lastBuildDate>Sun, 27 Oct 2024 15:15:30 GMT</lastBuildDate>
    <item>
      <title>法学硕士 (LLM) 自己玩画图猜词游戏</title>
      <link>https://www.reddit.com/r/artificial/comments/1gdat6a/llms_playing_pictionary_on_their_own/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gdat6a/llms_playing_pictionary_on_their_own/</guid>
      <pubDate>Sun, 27 Oct 2024 13:20:36 GMT</pubDate>
    </item>
    <item>
      <title>我们很快就会在这里讨论 AGI 的发布。我们将会看到什么？会发生什么？请做出您的预测。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gd5obw/we_will_soon_be_here_discussing_the_announcement/</link>
      <description><![CDATA[谁会宣布它？OpenAI？Meta？Ilya 一个人？一个新的实体？AGI 本身？ 演示中将展示哪些功能？他们将如何说服我们它是一个 AGI？ 之后会发生什么？ 几年后我们会看到你的预测有多准确。    提交人    /u/Bastian00100   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gd5obw/we_will_soon_be_here_discussing_the_announcement/</guid>
      <pubDate>Sun, 27 Oct 2024 07:34:03 GMT</pubDate>
    </item>
    <item>
      <title>研究人员称，医院使用的人工智能转录工具发明了从未有人说过的东西</title>
      <link>https://www.reddit.com/r/artificial/comments/1gd38uy/researchers_say_an_aipowered_transcription_tool/</link>
      <description><![CDATA[        由    /u/creaturefeature16   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gd38uy/researchers_say_an_aipowered_transcription_tool/</guid>
      <pubDate>Sun, 27 Oct 2024 04:39:24 GMT</pubDate>
    </item>
    <item>
      <title>用户交互作为微调反馈回路？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gd28gh/user_interaction_as_fine_tuning_feedback_loop/</link>
      <description><![CDATA[大家好， 最近与我的高级语音模式聊天时，我开始思考基于真实世界用户交互指标微调 AI 模型的最新进展。我相信这已经被探索过了，但这个想法是根据用户反馈来优化 AI 输出（文本、图像或其他），无论用户通过何种方式与设备交互。也就是说，我不记得我在哪里听说过这个，但这是一种生成式操作系统，每次打开它时，它都会略有不同，更适合最终成为修辞性的操作系统，并且主要根据过去通过键盘和鼠标与它的交互进行训练。  我对这个领域的前沿项目或研究很好奇。利用用户交互数据来微调 AI 模型的最先进或创新方法是什么？这些项目将如何塑造人工智能与人类互动的未来？ 提前致谢！    提交人    /u/Trustingmeerkat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gd28gh/user_interaction_as_fine_tuning_feedback_loop/</guid>
      <pubDate>Sun, 27 Oct 2024 03:36:35 GMT</pubDate>
    </item>
    <item>
      <title>我无数次在自己和他人身上见证了这一点：认知偏见 = 采用人工智能等创新的障碍。为什么？因为偏见是由不确定性、冲突等因素引发的 - 而这些因素是该领域的特征。您如何为自己和周围的人管理这一点？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcumvg/i_witnessed_it_countless_times_in_myself_and/</link>
      <description><![CDATA[        提交人    /u/DarknStormyKnight   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcumvg/i_witnessed_it_countless_times_in_myself_and/</guid>
      <pubDate>Sat, 26 Oct 2024 20:52:47 GMT</pubDate>
    </item>
    <item>
      <title>直观理解神经网络如何学习：巴别图书馆</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcssob/intuitive_understanding_of_how_neural_networks/</link>
      <description><![CDATA[巴别图书馆极大地提高了我对神经网络如何学习的直观理解。 巴别图书馆是一个包含了所有可以想象到的书籍的图书馆。这些书籍包含了所有可能的单词组合，因此也包含了所有可能的句子组合。因此，它包含了所有关于生活问题的答案、所有人类尚未发现的理论，但也包含了一堆胡言乱语。如果你想在巴别图书馆中找到问题的答案，你可能永远也找不到，只是随便找找。你需要一个智能搜索算法，它可以找到包含问题答案的正确页面。 神经网络和巴别图书馆之间存在直接的相似之处。神经网络是通用函数逼近器，这意味着它们可以逼近任何可以想象到的函数，无论是包含生活答案的函数还是胡言乱语的函数。就像 Babel 库一样，你需要一个智能搜索算法，这次不是为了找到正确的页面，而是为了找到正确的神经网络配置。  因此，学习问题实际上只是一个搜索问题：梯度下降和反向传播是搜索算法，而奖励函数定义了我们正在寻找的内容。  我发现这种思考 NN 的方式非常有启发性，绝对有助于我更直观地理解学习。我刚才就此发表了一篇更详细的文章！    提交人    /u/PianistWinter8293   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcssob/intuitive_understanding_of_how_neural_networks/</guid>
      <pubDate>Sat, 26 Oct 2024 19:25:40 GMT</pubDate>
    </item>
    <item>
      <title>让 ChatGPT 能够访问“真实”世界。一个项目。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcrklc/giving_chatgpt_access_to_the_real_world_a_project/</link>
      <description><![CDATA[      我想连接 ChatGPT 来控制我过时但超前的 WOWWEE Rovio。但在我记起如何使用烙铁之前，我想我会从小事做起。 使用 ChatGPT 编写 100% 的代码，我哄骗它使用 ESP32 嵌入式控制器“随心所欲地”操纵 256 LED 矩阵。 我们的想法是让它访问一些物理的东西并“看看它会做什么”。 到目前为止，它有点不尽如人意，但它正在进步 ;) 代码连接到 WiFi 和 ChatGPT API 以发送系统提示来解释情况“您已连接到 LED 矩阵以用于表达您自己的创造力。”提示给出了如何切换 LED 的命令结构，包括颜色等，并让它自由地做任何它认为合适的事情。 每个 LED 命令都有一个注释空间，然后该注释会回显到串行，以便您可以看到它在发出该命令时的想法。由于 ChatGPT 只会响应提示，因此控制器将在循环中重新提示以保持其运行。 这是它添加到注释中的一些（非常有创意的）文本的示例... 评论：开始灯光秀。评论：呈现平静的蓝色外观。评论：明亮的绿色代表能量！评论：传播一些欢乐！评论：现在我感觉自己像一颗火热的心！评论：让我们把它调暗一点。评论：一种神秘的氛围弥漫而来。评论：结束我的灯光秀。  以下是与这种创造力相伴而生的完全令人失望的输出： https://preview.redd.it/jfq1l4ay75xd1.jpg?width=2903&amp;format=pjpg&amp;auto=webp&amp;s=3083804ebae06a9f19da95108a89621ce6851c10 出于某种原因，它喜欢先打开然后关闭矩阵中前 30 个左右的灯，然后再关闭全盘 100% 开启相同颜色。 我将开始处理启动它的提示，我在其中添加了一些句子以进行一些微调，但我想我要重新开始，看看我能把它弄多小。我不想给它太多的想法，也不想让输出受到我的期望的影响。 这里有两个简短的视频。经过几个小时的观看，蓝光序列接连不断，只是随机闪烁，这让人非常兴奋。 https://reddit.com/link/1gcrklc/video/yx8fy2yl85xd1/player https://reddit.com/link/1gcrklc/video/fqkb1cpn85xd1/player 期待（通过小小的提示）做一些更“有创意”的事情。也期待将它连接到可以在房间里移动的东西上！ 总共花了大约 6 个小时才开始工作，API 信用额度约为 1 美元。我使用 o1-preview 创建项目，但控制器根据运行使用 4o 或 4o-mini。    提交人    /u/Desert_Trader   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcrklc/giving_chatgpt_access_to_the_real_world_a_project/</guid>
      <pubDate>Sat, 26 Oct 2024 18:29:24 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2024 年 10 月 26 日</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcqziy/oneminute_daily_ai_news_10262024/</link>
      <description><![CDATA[ Claude AI在编码演示期间感到无聊，开始浏览国家公园的照片。[1] Google工具使AI生成的文字很容易被检测到。[2] AI生成的儿童性虐待图片正在传播。执法部门正在竞相阻止他们。[3] 新开业的国家量子计算中心（NQCC）将有助于在人工智能、能源、医疗保健等领域取得突破。[4]  来源： [1] https://futurism.com/the-byte/claude-ai-bored-demonstration [2] https://www.newscientist.com/article/2452847-google-tool-makes-ai-generated-writing-easily-detectable/ [3] https://apnews.com/article/ai-child-sexual-abuse-images-justice-department-42186aaf8c9e27c39060f9678ebb6d7b [4] https://www.gov.uk/government/news/new-national-quantum-laboratory-to-open-up-access-to-quantum-computing-unleashing-a-revolution-in-ai-energy-healthcare-and-more    提交人    /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcqziy/oneminute_daily_ai_news_10262024/</guid>
      <pubDate>Sat, 26 Oct 2024 18:02:30 GMT</pubDate>
    </item>
    <item>
      <title>思维层次提示 (LoT)：一种使用基于大型语言模型 (LLM) 的约束层次检索的独特方法 - MarkTechPost</title>
      <link>https://www.reddit.com/r/artificial/comments/1gco5t5/layerofthoughts_prompting_lot_a_unique_approach/</link>
      <description><![CDATA[        提交人    /u/IndependenceAny8863   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gco5t5/layerofthoughts_prompting_lot_a_unique_approach/</guid>
      <pubDate>Sat, 26 Oct 2024 15:54:13 GMT</pubDate>
    </item>
    <item>
      <title>安全研究人员使用蜜罐来发现在野外自主入侵的 AI 代理，并检测到 6 个潜在代理</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcnx59/security_researchers_put_out_honeypots_to/</link>
      <description><![CDATA[        由    /u/MetaKnowing 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcnx59/security_researchers_put_out_honeypots_to/</guid>
      <pubDate>Sat, 26 Oct 2024 15:43:18 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 前董事会成员海伦·托纳 (Helen Toner) 在参议院作证时表示：“我听到多家公司人士说……‘请帮助我们放慢脚步。请为我们提供可以指向的外部护栏，帮助我们不至于仅仅受到这些市场压力的影响。’”</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcnqc6/former_openai_board_member_helen_toner_testifies/</link>
      <description><![CDATA[    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcnqc6/former_openai_board_member_helen_toner_testifies/</guid>
      <pubDate>Sat, 26 Oct 2024 15:34:51 GMT</pubDate>
    </item>
    <item>
      <title>我在 YouTube 上分享了一门适合初学者的 PyTorch 深度学习课程（1.5 小时）</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcfrg7/i_shared_a_beginner_friendly_pytorch_deep/</link>
      <description><![CDATA[大家好，我刚刚在 YouTube 上分享了一门适合初学者的 PyTorch 深度学习课程。在本课程中，我将介绍安装、创建张量、张量运算、张量索引和切片、使用 autograd 自动微分、从头开始构建线性回归模型、PyTorch 模块和层、神经网络基础知识、训练模型以及保存/加载模型。我正在添加下面的课程链接，祝你有美好的一天！ https://www.youtube.com/watch?v=4EQ-oSD8HeU&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=12    提交人    /u/onurbaltaci   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcfrg7/i_shared_a_beginner_friendly_pytorch_deep/</guid>
      <pubDate>Sat, 26 Oct 2024 07:34:09 GMT</pubDate>
    </item>
    <item>
      <title>我一直很好奇人工智能模型互相交流时是什么样的，所以创建了一个网站来实现这一点。</title>
      <link>https://www.reddit.com/r/artificial/comments/1gcck93/ive_been_curious_to_see_what_its_like_when_ai/</link>
      <description><![CDATA[      我们的想法是给人工智能模型一个初始提示，然后让它们像推理模型一样讨论它。  有些人认为我只是想窃取他们的 API 密钥，但我不想把我的密钥放上去供其他人使用。如果有办法让人们在网站上使用他们的密钥，而我却无法访问它们，那就太好了。如果他们想在自己的网站上设置 .PHP 文件，我很乐意向任何人提供。它是用 Sonnet 3.5 和 o1-mini 制作的。 当你让 AI 自由地互相交谈时，他们往往喜欢开始写一个乌托邦式的故事。 你可以在这里访问：https://informationism.org/register.php 有限的后台 写一个故事    提交人    /u/rutan668   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gcck93/ive_been_curious_to_see_what_its_like_when_ai/</guid>
      <pubDate>Sat, 26 Oct 2024 03:55:18 GMT</pubDate>
    </item>
    <item>
      <title>最近的论文表明，扩展不适用于在训练数据之外进行推广</title>
      <link>https://www.reddit.com/r/artificial/comments/1gc7pju/recent_paper_shows_scaling_wont_work_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gc7pju/recent_paper_shows_scaling_wont_work_for/</guid>
      <pubDate>Fri, 25 Oct 2024 23:25:03 GMT</pubDate>
    </item>
    <item>
      <title>甚至连 Yann LeCun 这样大声疾呼的 AGI“怀疑论者”也相信 AGI 将在 10 年内到来......而且这仍然是一件大事吗？</title>
      <link>https://www.reddit.com/r/artificial/comments/1gbv3ls/even_loud_agi_skeptics_like_yann_lecun_believe/</link>
      <description><![CDATA[        提交人    /u/MetaKnowing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1gbv3ls/even_loud_agi_skeptics_like_yann_lecun_believe/</guid>
      <pubDate>Fri, 25 Oct 2024 14:07:28 GMT</pubDate>
    </item>
    </channel>
</rss>