<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能（AI）</title>
    <link>https://www.reddit.com/r/artificial/</link>
    <description>Reddit的人工智能之家（AI）</description>
    <lastBuildDate>Thu, 06 Mar 2025 03:27:21 GMT</lastBuildDate>
    <item>
      <title>三个模型是否能够理解并改​​变自己的权重。真正AGI的关键？</title>
      <link>https://www.reddit.com/r/artificial/comments/1j4ih7k/three_models_on_if_they_could_understand_and/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j4ih7k/three_models_on_if_they_could_understand_and/</guid>
      <pubDate>Thu, 06 Mar 2025 00:19:23 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的新AI模式是我们知道的巨大飞跃</title>
      <link>https://www.reddit.com/r/artificial/comments/1j4f0r3/googles_new_ai_mode_is_a_huge_leap_away_from/</link>
      <description><![CDATA[    src =“ https://external-preview.redd.it/foinsrypmjpedhqlwjq5rzb94pppubzxxxm1f7ackpg1a.jpg？宽度= 640＆amp; crop = smart＆amp; auto = webp＆amp; s = 6916F2690EB7F25AC7DE370B70B7DFBEDA9CC2207EF“ title =“ Google的新AI模式是我们所知道的搜索范围的巨大飞跃”/&gt;   ＆＃32;提交由＆＃32;态href =“ https://www.businessinsider.com/google-ai-mode-search-search-gemini-results-chatgpt-chatgpt-overviews-2025-3?utm_source = ReDdit＆amp; amp.amm_medium = social = social = social＆amp；   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j4f0r3/googles_new_ai_mode_is_a_huge_leap_away_from/</guid>
      <pubDate>Wed, 05 Mar 2025 21:48:16 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.7 vs. Chatgpt 03 Mini</title>
      <link>https://www.reddit.com/r/artificial/comments/1j4anto/claude_37_vs_chatgpt_03_mini/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   claude 3.7 vs. chatgpt 03 Mini详细的比较，应用程序开发，一般推理和内容写作，我觉得Claude在比较Chatgpt的每个基准方面都更好。    https://youtu.be/f2ay_bt1ats     &lt;！ -  sc_on-提交由＆＃32; /u/u/annagreyxx     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j4anto/claude_37_vs_chatgpt_03_mini/</guid>
      <pubDate>Wed, 05 Mar 2025 18:53:08 GMT</pubDate>
    </item>
    <item>
      <title>哪个AI是最好的喜剧演员？</title>
      <link>https://www.reddit.com/r/artificial/comments/1j47vzl/which_ais_the_best_comedian/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;   大家好，我一直在探索不同的模型和他们开玩笑的能力，我很好奇：您认为哪个AI写了最好的笑话？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1j47vzl/which_ais_the_the_best_comedian/”&gt; [link]   ＆＃32;   [注释]           ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j47vzl/which_ais_the_best_comedian/</guid>
      <pubDate>Wed, 05 Mar 2025 17:03:07 GMT</pubDate>
    </item>
    <item>
      <title>具有动态数字信息图的模块化AI体系结构</title>
      <link>https://www.reddit.com/r/artificial/comments/1j47clu/modular_ai_architecture_with_dynamic_digital/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j47clu/modular_ai_architecture_with_dynamic_digital/</guid>
      <pubDate>Wed, 05 Mar 2025 16:41:04 GMT</pubDate>
    </item>
    <item>
      <title>代码创建统一的图形向量</title>
      <link>https://www.reddit.com/r/artificial/comments/1j47bwc/code_to_create_uniform_graph_vectors/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j47bwc/code_to_create_uniform_graph_vectors/</guid>
      <pubDate>Wed, 05 Mar 2025 16:40:13 GMT</pubDate>
    </item>
    <item>
      <title>对人类与AI推理的想法以及因果决策理论？</title>
      <link>https://www.reddit.com/r/artificial/comments/1j43wrm/thoughts_on_human_vs_ai_reasoning_with_causal/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/primordial_fupa    href =“ https://www.linkedin.com/posts/systems-paradigm-056686353_do-do-large-lange-models-range-models-rasonas-rason-causally-acusally-actactivity-730304791364 1762816-ea7_？utm_source = share＆amp; utm_medium = member_android＆amp; rcm = acoaafgy6mibt4xdfbzn3oiiwgmqr7gpu7gpu7gpu-wqmzkgg“ ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j43wrm/thoughts_on_human_vs_ai_reasoning_with_causal/</guid>
      <pubDate>Wed, 05 Mar 2025 14:09:54 GMT</pubDate>
    </item>
    <item>
      <title>我是一名艺术家，我正在寻找一些工具来帮助我</title>
      <link>https://www.reddit.com/r/artificial/comments/1j42z36/im_an_artist_and_im_looking_for_a_few_tools_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有两件事可以帮助我很多。如果这些易于找到，我深表歉意，但我似乎只使用Google找到任何东西。我主要使用提示找到AI-ART工具，我对此不感兴趣。 首先是从图纸上反向搜索的工具。例如，我绘制一个姿势，一个工具会找到我绘制的姿势的参考图片。  second将是增强现有艺术的东西。我是色盲的，可以极大地帮助黑白绘画的工具。另一个有趣的工具将是改善现有图形的东西，例如，以不同的样式重新绘制它。 任何帮助都将受到赞赏。谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/orion--     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j42z36/im_an_artist_and_im_looking_for_a_few_tools_to/</guid>
      <pubDate>Wed, 05 Mar 2025 13:24:16 GMT</pubDate>
    </item>
    <item>
      <title>单流使用LLM和解耦的语音令牌的单流文本到语音综合</title>
      <link>https://www.reddit.com/r/artificial/comments/1j41oxz/singlestream_texttospeech_synthesis_using_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚阅读了Spark-TTS论文，它引入了一种非常聪明的方法来进行文本到语音：一种具有解耦语音令牌的单流式体系结构，代表内容和声学特征，以统一的序列。 (Duration/Content/Condition) token format in a single stream instead of separate dual-streams * Achieves comparable quality to state-of-the-art models with just 1B parameters (vs competitors&#39; 7B) * 1.8x faster inference speed than previous approaches * Effectively handles both seen and unseen speaker adaptation * Maintains high speech quality while dramatically reducing computational costs The researchers conducted extensive评估表明，他们的模型在保持音频质量的同时，其模型在说话者的相似性和计算效率方面都优于诸如VALL-E之类的现有方法。他们使用矢量量化技术进行语音令牌和两阶段的训练方法（令牌训练，然后进行TTS模型培训）。 我认为这项工作代表了TTS的重要效率突破。他们没有简单地扩展模型尺寸，而是找到了一种更优雅的建筑解决方案，可以使高质量的语音合成在更适度的硬件上实用。具有脱钩令牌的单流方法似乎可能成为有效TTS系统的新标准体系结构。 特别令人印象深刻的是，他们设法在不牺牲质量的情况下减少了计算要求。这表明我们可以构建更容易访问的语音技术，而无需等待越来越多的模型或更强大的硬件。    tldr ：Spark-tts引入了一个单流式的架构，具有延迟的语音图表，具有更少的参数和较少的参数，比以前的型号    href =“ https://aimodels.fyi/papers/arxiv/spark-tts-felf--felcity-llm-基于基因 -  text-to”&gt;完整摘要在这里。 Paper 这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j41oxz/singlestream_texttospeech_synthesis_using_llms/</guid>
      <pubDate>Wed, 05 Mar 2025 12:14:05 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA首席执行官Jensen Huang赞扬DeepSeek的“奇妙”和“世界一流”开源推理模型</title>
      <link>https://www.reddit.com/r/artificial/comments/1j41dln/nvidia_ceo_jensen_huang_praises_deepseek_for/</link>
      <description><![CDATA[   班级”开源推理模型” src =“ https://external-preview.redd.it/h8ji602ojhnt0nhyhnhyhn00kwguglt5stao7tclugnfqy4.jpg？宽度= 640＆amp; crop = smart＆amp; auto = webp＆amp; s = ad2ee32560514DDC0705B18F788A930E330E3EE4B6CF“ title =“ NVIDIA首席执行官Jensen Huang赞美“奇妙的”和“世界级开源推理模型”，“/&gt;   ”提交由＆＃32; /u/u/u/tiny-indepent273    [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j41dln/nvidia_ceo_jensen_huang_praises_deepseek_for/</guid>
      <pubDate>Wed, 05 Mar 2025 11:55:25 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·巴托（Andrew Barto）和理查德·萨顿（Richard Sutton）赢得了上午。图灵（Turing）因发展强化学习的理论基础而奖，这是人工智能许多重大突破背后的关键方法</title>
      <link>https://www.reddit.com/r/artificial/comments/1j3zxba/andrew_barto_and_richard_sutton_have_won_the_am/</link>
      <description><![CDATA[   人工智能中许多重大突破的背后方法是“ src =” https://a.thumbs.redditmedia.com/q98evgok9u_blob-v6ikm1lozm1lozm1lozvjwhs1upxxsfxxsfexfexsfexsfexmmyq8.jpg&#39;人工智能中的重大突破”/&gt;   ＆＃32;提交由＆＃32; /u/u/nunki08       [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j3zxba/andrew_barto_and_richard_sutton_have_won_the_am/</guid>
      <pubDate>Wed, 05 Mar 2025 10:15:32 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻3/4/2025</title>
      <link>https://www.reddit.com/r/artificial/comments/1j3uyoy/oneminute_daily_ai_news_342025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     亚马逊的 aws构成了专注于代理AI的新小组。[1]  一个学生使用AI击败 Amazon的 残酷的技术访谈。他收到了一个要约，有人向大学奋斗。[2]  法官否认马斯克试图阻止 Openai 成为祖国实体。[3]      OpenAi 推出了5000万美元的赠款计划来帮助资助学术研究。 href =“ https://www.reuters.com/technology/artcover-intelligence/amazons-aws-forms-new-new----------------------- agentic-agentic-ai-2025-03-04/”&gt; https://www.reuters.com/technology/Artaver--intelligence/amazons-aws-forms-new--new-group-focused-focused-focused-2025-03-03-04/     [2]  https://gizmodo.com/a-student-used-duse-to-beat-amazons-brutal-technical-interview-he-got-an-got-an-got-an of-and-of-and-someOne-someOne-someone-to-his-University-to-his-University-20071562     [3]  https://www.cnbc.com/2025/03/04/judge-denies-musk-antempt-to-block-block-openai-from-becoming-for-profit-.html     [4] https://techcrunch.com/2025/03/04/openai-launches-50m-grant-program-to-help-fund-academic-research/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcover/comments/1j3uyoy/oneminute_daily_ai_ai_news_342025/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j3uyoy/oneminute_daily_ai_news_342025/</guid>
      <pubDate>Wed, 05 Mar 2025 04:31:48 GMT</pubDate>
    </item>
    <item>
      <title>研究人员惊讶地发现采用AI写作工具的受过教育程度较低的领域</title>
      <link>https://www.reddit.com/r/artificial/comments/1j3h1ue/researchers_surprised_to_find_lesseducated_areas/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32;态href =“ https://arstechnica.com/ai/2025/03/researchers-siverpreisht-to-find-edles-decated-ead-abecated-areas-adopting-ai-writing-tools-tools-faster/”&gt; [link]        [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j3h1ue/researchers_surprised_to_find_lesseducated_areas/</guid>
      <pubDate>Tue, 04 Mar 2025 18:01:25 GMT</pubDate>
    </item>
    <item>
      <title>Google释放了旨在识别野生动植物的AI模型的物种网络</title>
      <link>https://www.reddit.com/r/artificial/comments/1j3h0jq/google_releases_speciesnet_an_ai_model_designed/</link>
      <description><![CDATA[    src =“ https://external-preview.redd.it/epaqapemv-exhntgb1di6phfy9zyroxzcftohkm_3s4.jpg？宽度= 640＆amp; crop = smart＆amp; auto = webp＆amp; s = 5325FE547A56018CD4ABDC539E5C34D842264818“ title =“ Google释放了旨在识别野生动物的AI模型”/&gt;   ＆＃32;提交由＆＃32;态href =“ https://techcrunch.com/2025/03/03/google-releases-speciesnet-an-an-ai-model-designed-to-istionify-wildlife/&gt; [link]        [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j3h0jq/google_releases_speciesnet_an_ai_model_designed/</guid>
      <pubDate>Tue, 04 Mar 2025 18:00:11 GMT</pubDate>
    </item>
    <item>
      <title>升级的Unitree G1进行了720度圆形踢</title>
      <link>https://www.reddit.com/r/artificial/comments/1j3gce9/upgraded_unitree_g1_does_a_720_degree_roundhouse/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/metaknowing      [注释]]]></description>
      <guid>https://www.reddit.com/r/artificial/comments/1j3gce9/upgraded_unitree_g1_does_a_720_degree_roundhouse/</guid>
      <pubDate>Tue, 04 Mar 2025 17:33:11 GMT</pubDate>
    </item>
    </channel>
</rss>