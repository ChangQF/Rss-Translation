<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sat, 17 Aug 2024 09:14:11 GMT</lastBuildDate>
    <item>
      <title>需要学期项目的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eudefo/need_advice_for_semester_project/</link>
      <description><![CDATA[我必须为我的大学学期做一个项目，我正在考虑使用 VizDoom 和 OpenAI GYM 的强化学习制作一个玩 Doom (1993) 的 AI 代理。但我对此有几个问题： 我的设置： 笔记本电脑：i5 第 12 代，Iris Xe 显卡，8GB DDR4 PC：i5 第 10 代，RX 570 GPU，8GB DDR4 我可以使用笔记本电脑进行这个项目吗，还是需要使用 PC？ 我可以使用 Google Colab（免费版）进行这个项目吗？使用 Colab 进行这个项目有什么限制？ 我是一个对机器学习知之甚少的初学者，我才刚刚开始学习它。因此，请用简单的术语解释一下。 谢谢！    提交人    /u/TheGamerAz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eudefo/need_advice_for_semester_project/</guid>
      <pubDate>Sat, 17 Aug 2024 09:06:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何实现科学的“新”进步？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eucqv6/how_can_ai_make_new_advances_in_science/</link>
      <description><![CDATA[我的理解是，现在大多数人工智能都是通过强化学习、深度学习或两者兼而有之来完成的。从我在大学学到的知识来看，DNN 本质上只是执行曲线拟合。这使得它们非常适合发现难以发现的模式并应用它们。我明白，例如，这意味着它们可以学习如何通过去噪来“生成”某个物体特征之类的表示。但是当涉及到寻找新算法之类的东西时，我不明白问题是如何形成的。有了像 AlphaFold 这样的东西，我确信他们有一个模型可以生成符合某些规格的蛋白质模型或其他模型，但如果我们想用人工智能在科学上开辟新天地，那么我们需要做的不止这些，对吧？我很好奇它是如何工作的。例如，我知道 DeepMind 已经发现了新的算法，它是如何工作的？   由    /u/Hot_Barnacle_2672  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eucqv6/how_can_ai_make_new_advances_in_science/</guid>
      <pubDate>Sat, 17 Aug 2024 08:18:07 GMT</pubDate>
    </item>
    <item>
      <title>关于我的计划的问题和困惑</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1euc3at/questions_and_confusions_about_my_plan/</link>
      <description><![CDATA[您好， 我即将进入大学一年级。我对 ML 还比较陌生，在 PyTorch 方面有一些经验。我已经制定了一份很长的 ML 项目清单，我想完成这些项目，但我也想尝试一下理论，原因如下：(1) 我发现它很迷人，而且知道我从根本上理解概念（即 PCA、SVM、NN 等）让我感到很欣慰，(2) 理解理论可能会帮助我对项目产生洞察力，否则我就不会想到这些，(3) 它可能会在研究机会方面打开更多的大门。我首先是一个计算机科学的人（我喜欢算法问题和学习理论计算机科学，我喜欢编程），但我想在数学上有所成长。 然而，鉴于我的数学背景仅限于基本的向量微积分、线性代数和统计学，我正在努力制定一个可以轻松进行的计划。我天生是一个非常没有耐心的人，我想要开始一个项目，但事实上，获得更好的背景知识很可能需要一段时间，这让我对如何进行产生了矛盾的想法。 我学习数学的想法是学习 Andrew Ng 的 ML 和 DL 专业化，然后当我对某个数学/ML/DL 概念变得不熟悉时，我会回溯到我熟悉的最后一个先决条件，然后重新开始，心里想着这样我的学习会有动力和专注力。然后，我会继续做较小的项目，深入了解不同的技术和模型，然后攻克更宏伟的抱负。 但是，我担心自己没有扎实的数学基础，而且由于我对向量微积分和线性代数的理解很浅，这种回溯方法与仅仅学习这些科目没有什么不同。 另一个问题是，我列表中的 ML 项目非常多样化，需要他们自己的领域知识（优化问题、RL 和其他决策模型，如 MDP、体育预测、期货交易、图形和物理模拟、其他杂项）。 我担心如果我完全专注于理论，我就会偏离正轨，忘记完成我的项目，如果我过于专注于实践，我就会限制/欺骗自己探索模型背后所有有趣的理论。这场内心的争论真的浪费了我的时间，我想结束它，有人遇到过我的情况吗？我是不是有点力不从心了？    提交人    /u/Sweet-Stretch8243   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1euc3at/questions_and_confusions_about_my_plan/</guid>
      <pubDate>Sat, 17 Aug 2024 07:30:26 GMT</pubDate>
    </item>
    <item>
      <title>想要学习机器学习和深度学习所需的数学知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eubuc7/want_to_learn_math_for_ml_and_dl/</link>
      <description><![CDATA[我对数学中的概念有很好的理解，我以前上过很多数学课，所以我怀疑需要多少数学知识才能理解机器学习算法、深度学习算法的概念，事实上阅读论文也是如此。除了统计数据之外，我还应该学习线性代数中的哪些概念，我应该知道多少微积分。所以学习微积分 2 就够了吗？    提交人    /u/geralt_of_riviaRDR2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eubuc7/want_to_learn_math_for_ml_and_dl/</guid>
      <pubDate>Sat, 17 Aug 2024 07:13:03 GMT</pubDate>
    </item>
    <item>
      <title>Mamba 算法中的形状</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eub2sv/shapes_in_mamba_algorithm/</link>
      <description><![CDATA[      大家好 :) 这是 Mamba 论文中的 S6 算法（https://arxiv.org/pdf/2312.00752）： https://preview.redd.it/jusbz7c926jd1.png?width=890&amp;format=png&amp;auto=webp&amp;s=75cf754b3c1f7478e3c146b7ec7f373a8336cd3e 我不太理解输入相关的形状。以 C 为例。为什么它的形状是 (B,L,N)？直观地讲，由于它为序列中的每个输入标记提供了唯一的转换（选择），因此它的形状应该是 (B,L,D,N)，其中最后两个维度恰好是批次中相应标记的投影？ 如果不这样做，隐藏状态 h 将具有维度 (B,D,N)，从而可以像在 SSM 中那样更新隐藏状态和输出。这再次违反直觉，因为隐藏状态通常具有形状 (B,N)，即隐藏向量以压缩序列的过去信息。 所以我的问题是，为什么 B、C 和 Delta 的输入相关形状不是维度 (B,L,D,N) ？ 提前致谢！    提交人    /u/No_Individual_7831   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eub2sv/shapes_in_mamba_algorithm/</guid>
      <pubDate>Sat, 17 Aug 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>关于非线性数据的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eu9pwm/question_about_nonlinear_data/</link>
      <description><![CDATA[      嘿，我对这些东西还比较陌生，只是从 YouTube 和在线课程等东西上学习，我有一个问题。因此，这些数据能够仅使用直线进行分类（我只使用了线性层，没有非线性激活层。 https://preview.redd.it/0djt3346o5jd1.png?width=1580&amp;format=png&amp;auto=webp&amp;s=830fcdbbf2efeac64b757c7fb5d0fb0c456516a8 但我无法理解为什么不能使用类似的方法对此类数据进行分类（或者如果可以，我不知道该怎么做） https://preview.redd.it/cahyjz18o5jd1.png?width=559&amp;format=png&amp;auto=webp&amp;s=c7dafc4e8057c5f224d4a598498006931a931a90 https://preview.redd.it/c267x2t8o5jd1.png?width=974&amp;format=png&amp;auto=webp&amp;s=bcf8c1eab1e10dc9c59607a94f44538aab3fab3b 我正在考虑像这样使用直线将其分开，但无论我添加多少层或节点，我的模型似乎得到的最佳效果大约是 50%（只是猜测中间有一条直线）。模型似乎唯一能够学会在无需猜测的情况下对数据进行分类的方法是通过添加像 ReLU 这样的非线性函数。 https://preview.redd.it/37eueh7ao5jd1.png?width=1552&amp;format=png&amp;auto=webp&amp;s=75447791cdbdb7248e532db5a8a385da3c09ee82 https://preview.redd.it/6ebfw52bo5jd1.png?width=1454&amp;format=png&amp;auto=webp&amp;s=9f0c3b47a00d2725103c3e3ff0fb529b1a35b329 https://preview.redd.it/naz53qtbo5jd1.png?width=1964&amp;format=png&amp;auto=webp&amp;s=59a8288e3ec4851c0147199b8a5e336ceae4add9 我需要做什么才能仅使用线性函数来训练模型？如果不可能，有人可以解释为什么它不可能而另一个是可能的。此外，我应该阅读哪些概念才能完全理解它的工作原理   由    /u/foxxypants_  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eu9pwm/question_about_nonlinear_data/</guid>
      <pubDate>Sat, 17 Aug 2024 04:56:33 GMT</pubDate>
    </item>
    <item>
      <title>需要建议。可能会升职领导一个机器学习团队，最近毕业</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eu5q7e/advice_needed_might_get_promoted_to_lead_a_ml/</link>
      <description><![CDATA[大家好，希望大家一切顺利。我是一名应届毕业生，拥有计算机科学学士学位和人工智能硕士学位。大约一年前，我在一家中小型公司开始了第一份行业工作，担任软件工程师。在担任现职之前，我曾有 4 份实习经历（研究、软件工程和数据科学实习），这些经历为我在人工智能（尤其是深度学习）方面打下了坚实的基础。 在目前的工作中，我一直在开发可扩展且有弹性的微服务（主要是 C#），重点关注数据，而不是人工智能，我已经明确表示，这是我在某个时候要关注的目标。我觉得自己做得很好，因为很多东西对我来说都很新，在与我的经理谈加薪后，他们提到他们想在我们目前的团队中创建一个“创新/机器学习”子团队，让我领导这些计划。关于如何处理这个问题，你对我有什么建议？我在这个行业还很新，我想确保尽管没有多年的经验，但我能够以正确的方式抓住这个机会。    提交人    /u/vicson5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eu5q7e/advice_needed_might_get_promoted_to_lead_a_ml/</guid>
      <pubDate>Sat, 17 Aug 2024 01:23:13 GMT</pubDate>
    </item>
    <item>
      <title>从头开始构建 Gen Ai 模型：分享我的旅程并共同学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eu1oj3/building_gen_ai_models_from_scratch_sharing_my/</link>
      <description><![CDATA[      所以，我最近决定从头开始深入构建不同的生成式 AI 模型。我之前已经构建了一些，比如 VAE 和扩散模型，但那些大多是在教程的帮助下完成的。这次，我想尝试一些不同的东西，通过阅读论文和自己从头开始编写代码来学习。 但说实话，独自做这件事可能会有点困难，所以我想，为什么不分享我所学的东西呢？我可能会每周在 Reddit 上发布更新，并在 Twitter (X) 上更频繁地发布。如果你愿意，我们可以聊天、交换想法，并一起想办法构建一些很棒的高质量小模型。 以下是我刚刚训练的 VQ-VAE 的一些图片。我现在也在研究用于无条件生成的变压器模型。如果你好奇，请随时查看我的 GitHub（这里）或 Twitter（这里）并关注！ 😊    由   提交  /u/Full-Bell-4323   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eu1oj3/building_gen_ai_models_from_scratch_sharing_my/</guid>
      <pubDate>Fri, 16 Aug 2024 22:19:00 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用最少的代码更改来优化 PyTorch 以加速机器学习。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1etyeq2/try_out_pytorch_optimizations_with_minimal_code/</link>
      <description><![CDATA[       由    /u/nikita-1298  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1etyeq2/try_out_pytorch_optimizations_with_minimal_code/</guid>
      <pubDate>Fri, 16 Aug 2024 20:00:48 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1etycs5/time_series_analysis/</link>
      <description><![CDATA[大家好， 我有一个（我认为）相当简单的用例，但我缺乏 ML 知识，这阻碍了我。我希望这里的社区可以推动我朝着正确的方向前进。  我正在记录本质上是“事件”时间序列的内容（例如，网页访问者）。 我可以将这些数据“分组”到频率间隔中（例如，每小时、每 30 分钟等）。 然后我想使用过去的数据来确定最新数据是否符合预期或新颖性。例如，“我们在过去一小时内有 30 位访客，这在一天中的这个时间、一周中的这一天等是否很常见”。 我正在分析的时间序列是“季节性的”（例如，中午的访客多于午夜）。这种季节性促使我研究 ML 路线而不是更简单的统计分析。 我需要它是“无监督的”（即，我不会有正常与新颖的例子，只有一些历史数据）。  有人可以指出我如何最好地解决这个问题的正确方向吗？    提交人    /u/rbd2x   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1etycs5/time_series_analysis/</guid>
      <pubDate>Fri, 16 Aug 2024 19:58:37 GMT</pubDate>
    </item>
    <item>
      <title>[文章]：查看有关如何在英特尔 Tiber 开发者云上构建和实施深度学习工作负载的详细指南。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ety73p/article_check_out_the_detailed_guide_on_how_to/</link>
      <description><![CDATA[        由    /u/ramyaravi19 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ety73p/article_check_out_the_detailed_guide_on_how_to/</guid>
      <pubDate>Fri, 16 Aug 2024 19:51:49 GMT</pubDate>
    </item>
    <item>
      <title>什么是 QLoRA？：量化 LLM 高效微调的视觉指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ett9rm/what_is_qlora_a_visual_guide_to_efficient/</link>
      <description><![CDATA[TL;DR：QLoRA 是参数有效微调 (PEFT) 方法。由于 QLoRA 中引入了 NormalFloat4 (NF4) 格式，它使 LoRA（我们在之前的文章中介绍过）更加高效。 使用 NF4 4 位格式对 QLoRA 进行量化，其表现优于标准 16 位微调以及 16 位 LoRA。 本文介绍了一些细节，这些细节使 QLoRA 高效且性能与 16 位模型一样好，同时仅使用 4 位浮点表示，这要归功于最佳正态分布量化、块量化和分页优化器。 这使其在成本、时间、数据和 GPU 方面更加高效，而不会损失性能。 什么是 QLoRA？：视觉指南。 处理 img ba6j1n50t9id1...    由    /u/ml_a_day  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ett9rm/what_is_qlora_a_visual_guide_to_efficient/</guid>
      <pubDate>Fri, 16 Aug 2024 16:28:32 GMT</pubDate>
    </item>
    <item>
      <title>学习 ML 的 Kaggle 途径</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1etoqde/kaggle_pathway_for_learning_ml/</link>
      <description><![CDATA[嗨！我目前正在学习 ML，对其理论和工作原理有大致了解。但现在我希望通过应用程序来学习，因为数据并不总是干净的，而且我希望在处理未来的 ML 项目时学习实用技能。特别是，我希望专注于结构化数据的项目，因为我希望在研究中使用 ML。我知道学习基本算法的工作原理也很重要，但我还希望对神经网络有更深入的了解，这样我就不会只把它当作黑匣子。 我想知道从哪个 Kaggle 项目开始最好，如果有人可以创建一条我可以开始的途径（从基础到更高级别），我将不胜感激。就背景而言，我目前正在使用 Andrew Ng 的 ML 课程、Geron 的 Hands On Machine Learning 和 Strang 的 Linear Algebra 来研究理论。感谢任何能提供帮助的人！   由    /u/Gpenguin314  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1etoqde/kaggle_pathway_for_learning_ml/</guid>
      <pubDate>Fri, 16 Aug 2024 13:25:15 GMT</pubDate>
    </item>
    <item>
      <title>从头开始构建大型语言模型 | 新的 Youtube 播放列表</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1etknal/build_a_large_language_model_from_scratch_new/</link>
      <description><![CDATA[      我的一小段讲义 就像机器学习一样，只有真正理解大型语言模型 (LLM) 的具体工作原理，你才会成为一名严肃的 LLM 工程师。 很少有人了解 LLM 的具体工作原理。能够从头开始构建整个 LLM 的人就更少了。 从头开始构建自己的 LLM 不是很棒吗？ 这是我在 Youtube 上开始的一个很棒的新播放列表系列：从头开始构建你自己的 LLM。 一切都写在白板上。从头开始。  第一堂课现已上线：https://youtu.be/Xpr8D6LeAtw 我计划制作一个包含 65-70 堂课的大型播放列表。我将展示如何从头到尾构建 LLM。  希望您学到很多东西 :) 附注：附加的 GIF 显示了我为准备这个播放列表而做的一小段笔记。到目前为止，笔记已经接近一百页，我已经完成了 20% 的系列录制。     提交人    /u/OtherRaisin3426   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1etknal/build_a_large_language_model_from_scratch_new/</guid>
      <pubDate>Fri, 16 Aug 2024 09:47:07 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>