<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 05 Jul 2024 15:16:12 GMT</lastBuildDate>
    <item>
      <title>您能建议合并模型的资源吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvzk0h/can_you_suggest_resources_for_merging_models/</link>
      <description><![CDATA[我知道模型合并，也知道有一些工具可以做到这一点，但我想要一些好的资源来讨论这个概念。例如，它们展示了如何使用 Pytorch 合并 2 个小模型。任何这样的内容都应该足够了，即使是一篇研究论文也可以。我很感激你对此的看法。     提交人    /u/Ok_Cartographer5609   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvzk0h/can_you_suggest_resources_for_merging_models/</guid>
      <pubDate>Fri, 05 Jul 2024 14:40:00 GMT</pubDate>
    </item>
    <item>
      <title>我会向任何能帮我在 tensorflow 上设置 gpu 的人支付 50 美元。我会来 discord 和屏幕共享，只要告诉我该怎么做就行。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvykmq/ill_pay_anyone_50_that_helps_me_setup_my_gpu_on/</link>
      <description><![CDATA[  由    /u/IcyResponsibility312  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvykmq/ill_pay_anyone_50_that_helps_me_setup_my_gpu_on/</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:53 GMT</pubDate>
    </item>
    <item>
      <title>关于 YOLO 项目（计算机视觉）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvydyf/regarding_a_yolo_project_computer_vision/</link>
      <description><![CDATA[大家好，我是一名本科生，最近在做一个项目。这是一个水下物体检测项目。我使用了 Google Notebook 作为工具，使用了 YOLOv8 算法。为了处理图像，我使用了 Roboflow，这是一个允许您注释图像并提供 YOLO 格式数据集的网站。我已经训练了算法并做了一些预测。我希望有一点 YOLO 知识的人来回答这个问题。想象一下你正在接受面试，如果你在我的简历中看到那个项目，你会有什么感觉？如果您能提出任何建议来改进我的项目，使它在我的简历上看起来很棒，我将不胜感激。    提交人    /u/Ok-Association2722   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvydyf/regarding_a_yolo_project_computer_vision/</guid>
      <pubDate>Fri, 05 Jul 2024 13:46:17 GMT</pubDate>
    </item>
    <item>
      <title>小型图像数据集上的自监督预训练与 ImagNet 预训练</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvxygl/selfsupervised_pretraining_on_small_image/</link>
      <description><![CDATA[大家好 我正在研究一个包含大约 5k 张图像的医学图像分类数据集。我使用 15k 张相同类型的未标记图像进行自监督预训练。虽然使用 Dino 进行预训练会收敛并且损失会迅速减少，但迁移学习结果与仅使用 ImageNet 预训练权重类似或略差。 这是预料之中的，因为我只有 15k 张图像吗？在小数据集上进行 SSL 预训练的价值是否低于我的想象？我发现的大多数研究至少会略微提高结果。问题是我无法检索更多图像。 任何输入都值得赞赏，我知道这是一个模糊的问题。你在自监督预训练方面有什么经验？ 谢谢 !    提交人    /u/DerKaggler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvxygl/selfsupervised_pretraining_on_small_image/</guid>
      <pubDate>Fri, 05 Jul 2024 13:25:59 GMT</pubDate>
    </item>
    <item>
      <title>开始机器学习数学。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvx233/started_mathematics_for_machine_learning/</link>
      <description><![CDATA[我掌握了 Python，但我没有直接进入核心 ML 概念，而是考虑在线性代数、微积分和统计学方面打下基础，并在深入理解这些概念之前先深入理解它们。我正在 Udemy 上学习一门课程，同时还是一名计算机工程本科生，在我的 ML 旅程中，我需要采取哪些必要的步骤才能使我熟练掌握这些技能，我还听说大多数公司要求我具备 SWE 经验才能进入 ML 工作岗位，我也需要澄清这一点。     提交人    /u/Agitated_Plastic_157   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvx233/started_mathematics_for_machine_learning/</guid>
      <pubDate>Fri, 05 Jul 2024 12:41:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 Llama 创建 DPO 数据集：最佳实践？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvwio7/creating_a_dpo_dataset_using_llama_best_practices/</link>
      <description><![CDATA[大家好， 我目前正在使用 Llama 创建 DPO 数据集，我有一个关于创建数据集的最佳实践的问题。 这是方法 1： 假设我使用提示从 Llama 中抽取了 5 个响应，经过评估，样本 5 被认为是根据人工判断的最佳样本。数据集结构将如下所示： 接受拒绝样本 5 样本 1样本 5 样本 2样本 5 样本 3样本 5 样本 4 并对其他提示重复此操作 这是方法 2： 使用提示仅从 Llama 中抽取了 2 个响应。在这种情况下，结构将是： 接受 拒绝 样本 2 样本 1 并重复其他提示 我的问题是，哪种方法对于创建高质量的 DPO 数据集更有效？我应该坚持对多个响应进行抽样并将它们全部与最佳响应进行比较，还是最好只对每个提示抽样两个响应？ 任何基于您经验的见解或建议都将不胜感激！ 谢谢！    提交人    /u/AdKind316   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvwio7/creating_a_dpo_dataset_using_llama_best_practices/</guid>
      <pubDate>Fri, 05 Jul 2024 12:12:54 GMT</pubDate>
    </item>
    <item>
      <title>NER 任务</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvuu87/ner_task/</link>
      <description><![CDATA[我是一名应届毕业生，也是一家初创公司唯一的机器学习工程师。我被分配了一项任务，使用 NER 从提交的文档中提取关键信息。我的公司只提供了 20 份文档来训练我的模型。是否有可能仅使用 20 份文档样本来创建生产级模型？是否有可能并且可行伪造文档数据来训练我的模型？我试图要求提供更多数据，但我的公司无法提供。    提交人    /u/BoxFun9860   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvuu87/ner_task/</guid>
      <pubDate>Fri, 05 Jul 2024 10:30:31 GMT</pubDate>
    </item>
    <item>
      <title>将 PyTorch 视为理所当然</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvulup/taking_pytorch_for_granted/</link>
      <description><![CDATA[大家好，我仅使用 Rust 标准库实现了一个支持自动求导的张量库。 在此过程中，我学到了很多关于 PyTorch 内部工作原理的知识，因此我写了相关文章：https://nrehiew.github.io/blog/pytorch/ 我介绍了张量的实现方式、广播和反向传播  如果你们能看看就太好了！谢谢！    提交人    /u/nreHieS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvulup/taking_pytorch_for_granted/</guid>
      <pubDate>Fri, 05 Jul 2024 10:14:42 GMT</pubDate>
    </item>
    <item>
      <title>卷积自动编码器/变分自动编码器只能产生重复模式</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvt55w/convolutional_autoencodervariational_autoencoder/</link>
      <description><![CDATA[      我正在制作一个卷积自动编码器，我正在努力让模型真正重建输入。重建损失明显减少，但输出看起来完全不对。 我注意到自动编码器的输出始终是重复模式。它需要一些小序列并基本上重复它，直到达到所需的序列长度。它甚至无法重新创建非常简单的数据。 这是我的代码，这是构建 CNN 自动编码器的正确方法吗？我在编码器中使用 Conv1d/MaxPool/BatchNorm1d 层，在解码器中使用 ConvTranspose1d/Upsample 层作为相应的逆操作。输出中的重复模式是否与解码器中的上采样有关？我很感激任何建议或指点。 class CNNAE(torch.nn.Module): def __init__(self, latent_dim): super(CNNAE, self).__init__() self.latent_dim = latent_dim self.encoder_cnn = torch.nn.Sequential( # (1 x 1200) -&gt; (32 x 300) torch.nn.Conv1d( in_channels=1, out_channels=32, kernel_size=4, stride=4, padding=1, ), torch.nn.ReLU(), # (32 x 300) -&gt; (32 x 150) torch.nn.MaxPool1d( kernel_size=4, stride=2, padding=1, ), torch.nn.BatchNorm1d( num_features=32, ), # (32 x 150) -&gt; (32 x 38) torch.nn.Conv1d( in_channels=32, out_channels=32, kernel_size=4, stride=4, padding=1, ), torch.nn.ReLU(), # (32 x 38) -&gt; (32 x 19) torch.nn.MaxPool1d( kernel_size=4, stride=2, padding=1 ), torch.nn.BatchNorm1d( num_features=32, ), ) # (32 x 19) -&gt; (32 x 1) 挤压后 self.gap = torch.nn.AdaptiveAvgPool1d(1) # (32 x 1) -&gt; (latent_dim，) self.encoder_fc = torch.nn.Linear（in_features=32，out_features=latent_dim，）#（latent_dim，）-&gt;； （32，） self.decoder_fc = torch.nn.Linear（in_features = latent_dim，out_features = 32，）#从（32，）调整大小到（32 x 19）self.pool_reverse = torch.nn.Upsample（scale_factor = 19，mode =“nearest”）self.decoder_cnn = torch.nn.Sequential（#（32 x 19）到（32 x 38）torch.nn.Upsample（scale_factor = 2，mode =&#39;nearest&#39;），#（32 x 38）到（32 x 150）torch.nn.ConvTranspose1d（in_channels = 32，out_channels = 32，kernel_size = 4，stride = 4，padding = 1，），#（32 x 150）到（32 x 300） torch.nn.Upsample(scale_factor=2, mode=&#39;nearest&#39;), # (32 x 300) 到 (1 x 1200) torch.nn.ConvTranspose1d( in_channels=32, out_channels=1, kernel_size=4, stride=4, padding=1, output_padding=2 ), ) def encode(self, x): out = self.encoder_cnn(x) out = self.gap(out) out = out.squeeze(2) z = self.encoder_fc(out) return z def decrypt(self, z): out = self.decoder_fc(z) out = out.unsqueeze(2) out = self.pool_reverse(out) out = self.decoder_cnn(out) return out def forward(self, x): z = self.encode(x) out = self.decode(z) return out, z  样本损失曲线 简单数据重建失败 在更复杂的数据上重建失败    提交人    /u/coronary-service   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvt55w/convolutional_autoencodervariational_autoencoder/</guid>
      <pubDate>Fri, 05 Jul 2024 08:30:46 GMT</pubDate>
    </item>
    <item>
      <title>告诉我您不同意此列表中有关 LLM 能力的哪些内容？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvsh9m/tell_me_what_you_dont_agree_in_this_list_about/</link>
      <description><![CDATA[ LLM 给出的回答非常笼统。当被要求给出微妙的立场时，它们会一败涂地。 当你要求它给出一些不受欢迎的观点时，它会一败涂地，尤其是当这些观点在政治上不正确时。 它们不能从不同的角度撰写文本，尤其是从恶棍或坏人的角度。 它们擅长抄袭风格，但写的内容却很平庸。AI 研究人员对这种行为感到惊讶，我们认为抄袭风格对于 LLM 来说很难，但实际上，抄袭风格很容易，但模仿论证水平和逻辑流程对于这些系统来说要困难得多。 由于它没有信仰体系，它无法区分好的和坏的结论。 它不知道什么时候该停下来。 LLM 不会自我反省，只是表面上会而已。 在多目标问题上，他们表现得非常糟糕。 如果你问他们一个非常著名问题的不同版本，他们通常会给出错误的答案。例如第 n 次旋转问题或农民、山羊和草问题。 如果你问他们“你确定吗？”他们会改变答案。 他们可能不是统计鹦鹉，但他们没有我们想象的那么聪明。他们更像是一种风格（有时包括智能行为和过程）的复制机器，具有一些理解能力。 他们非常适合产生想法。在 LLM-Modulo 框架中可能工作得很好。 当我开始在训练数据的极端情况下进行操作时，他们真的很难适应。 它们非常适合重复的平凡任务。 它们可以很好地帮助查找某些内容并纠正给定文本中的语法错误。 当遇到难题时，他们不断重复相同的答案，尽管明确要求他们更改答案。感觉他们陷入了循环。     提交人    /u/Difficult-Race-1188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvsh9m/tell_me_what_you_dont_agree_in_this_list_about/</guid>
      <pubDate>Fri, 05 Jul 2024 07:44:29 GMT</pubDate>
    </item>
    <item>
      <title>如何顺利通过机器学习面试：我的个人剧本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvru3y/how_to_ace_machine_learning_interviews_my/</link>
      <description><![CDATA[嗨，ML 社区 准备机器学习面试可能会很艰巨。为了提供帮助，我整理了一些帮助我取得成功的策略和资源，包括： • ✨ ML 面试的关键要素和准备技巧 • 📚 一系列有价值的资源，包括在线课程、书籍和文章 • 🔍 了解我认为面试官一般会寻找什么 在这里阅读我的个人剧本：https://mlengineerinsights.substack.com/p/how-i-aced-machine-learning-interviews 希望这能帮助人们制定面试准备策略！    提交人    /u/tobeflyer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvru3y/how_to_ace_machine_learning_interviews_my/</guid>
      <pubDate>Fri, 05 Jul 2024 07:00:08 GMT</pubDate>
    </item>
    <item>
      <title>我在《权力的游戏》数据上实施了一个加权随机块模型来寻找角色组</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvkbhw/i_implemented_a_weighted_stochastic_block_model/</link>
      <description><![CDATA[      https://preview.redd.it/uy8u7djo6lad1.png?width=960&amp;format=png&amp;auto=webp&amp;s=fc2b66c0f0f638fe9e95eb3eb0ba9b704c4b043a https://preview.redd.it/os7cwxwp6lad1.png?width=755&amp;format=png&amp;auto=webp&amp;s=eb268c7ebf41f13fe355a8b08d010764c293d222 https://preview.redd.it/66xtu8pq6lad1.png?width=960&amp;format=png&amp;auto=webp&amp;s=89d6f97b8700b8e01c1c777bb5b454d4d8014740 https://preview.redd.it/yvvkpj2x6lad1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=0a80c85be861d59119cb5acb2fae2a9dfab7d583 本来应该是一个简单的 uni 项目，但是我在任何地方都找不到 WSBM 的函数，所以我自己制作了它们。  每个节点都是一个字符，每行都是一个连接。当两个角色出现在彼此 15 个字以内时，就会产生联系，节点越大，联系就越多。 所有分析和代码均位于 https://github.com/tcaio26/WSBM_ASOIAF（除书籍/第 1 季外，无剧透） 数据来自 https://networkofthrones.wordpress.com/    提交人    /u/ctheodore   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvkbhw/i_implemented_a_weighted_stochastic_block_model/</guid>
      <pubDate>Thu, 04 Jul 2024 23:30:40 GMT</pubDate>
    </item>
    <item>
      <title>数学本科生想辍学，请指点迷津</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvjdjt/math_undergrad_thinking_in_dropout_please_enlight/</link>
      <description><![CDATA[抱歉，因为我的英语不好，所以问的问题可能有点愚蠢。但我现在是数学本科一年级的中期，我真的很喜欢做数学，想获得博士学位，从事数学研究。问题是我将在 4 年内毕业，2 年获得硕士学位，4 年获得博士学位，所以从现在起总共 10 年后我才能达到我想要的水平，我爸爸跟我说我学习数学是在浪费时间，因为当我获得博士学位时，“人工智能”将在该领域取得所有进步，而我将被淘汰。我问过一位老师他是怎么想的，他说他不太了解人工智能，但如果人工智能达到这一点，那么该领域将发展得更快，我将无法赶上。我真的在浪费时间追求这个梦想吗？ 10 年后，数学家不会再做研究了？再次抱歉询问人工智能，我知道人们总是发布类似的东西，但最近我感到很沮丧    提交人    /u/mousse312   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvjdjt/math_undergrad_thinking_in_dropout_please_enlight/</guid>
      <pubDate>Thu, 04 Jul 2024 22:43:06 GMT</pubDate>
    </item>
    <item>
      <title>您认为初学者在开始学习机器学习时犯的最大错误是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dvhe9q/what_do_you_think_is_the_biggest_mistake/</link>
      <description><![CDATA[  由    /u/BEE_LLO  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dvhe9q/what_do_you_think_is_the_biggest_mistake/</guid>
      <pubDate>Thu, 04 Jul 2024 21:08:23 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>