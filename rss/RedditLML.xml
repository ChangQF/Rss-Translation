<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 26 Apr 2024 21:12:04 GMT</lastBuildDate>
    <item>
      <title>[求助]时空数据的生成建模</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdwir3/help_generative_modeling_of_spatiotemporal_data/</link>
      <description><![CDATA[TLDR：是否有任何资源/论文/代码可以生成 video2video ？ 我的数据集是视频中的帧。我现在的任务是针对每个帧，回顾窗口中的一些先前帧，对时空特征进行编码并学习分布，并从中进行采样以预测输入帧的同样可能的实现。我发现了很多用于下一帧生成或视频预测的资源，但用于同一帧预测的资源却很少。谁能给我指出这样的资源吗？   由   提交 /u/Adventurous-Duty-768   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdwir3/help_generative_modeling_of_spatiotemporal_data/</guid>
      <pubDate>Fri, 26 Apr 2024 21:02:32 GMT</pubDate>
    </item>
    <item>
      <title>Parler TTS 设置和演示</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cduofj/parler_tts_setup_and_demo/</link>
      <description><![CDATA[昨天我花了一些时间在 Colab Notebook 中设置 Parler-TTS 实例，并复习了该工具的一些基础知识。对于任何不知道的人来说，Parler TTS 是由 HuggingFace 直接推出的，是目前第一个完全开源的文本转语音工具。  如果您喜欢使用 MidJourney 进行即时工程，那么您一定会喜欢使用 Parler-TTS 进行即时工程。我会说关于该模型的最后一件事，您可以在下面看到我的完整演示和评论。您可以用自己的声音和大量数据“从技术上”对其进行微调。我没有这样做，因为我没有 11k 小时的带有标签的自己的录音，也没有 8 个 H100 GPU 可以直接运行 4 天来训练模型。不用说，您没有训练这个模型哈哈。 https://youtu.be/YMdS0gbfFUk    由   提交/u/Certain_End_5192   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cduofj/parler_tts_setup_and_demo/</guid>
      <pubDate>Fri, 26 Apr 2024 19:48:46 GMT</pubDate>
    </item>
    <item>
      <title>准备好使用 Pytorch Transformer 的示例数据集了吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdubiq/ready_to_use_sample_datasets_for_pytorch/</link>
      <description><![CDATA[我想要一些现成的示例数据集，我可以查看并使用它来试验 pytorch 变压器。  我正在专门研究这个实现。 （但是格式略有不同的变压器数据集是可以的，只要它们有明确的示例如何使用它们） https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch 它生成随机数对于它的数据集，但我想看看“真实”数据以及它如何变成“真实”输出。  ​ ​   由   提交/u/blaher123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdubiq/ready_to_use_sample_datasets_for_pytorch/</guid>
      <pubDate>Fri, 26 Apr 2024 19:33:29 GMT</pubDate>
    </item>
    <item>
      <title>寻求 Bishop 对 PRML 的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdualg/seeking_recommendations_for_prml_by_bishop/</link>
      <description><![CDATA[大家好！我最近对研究机器学习的理论基础非常感兴趣。我在大学学习了数学（因此拥有了良好的数学背景），并且听到了 Christopher Bishop 的很多关于模式识别和机器学习的好东西，我想对这本书进行彻底的研究。 鉴于我只对获得 ML 的核心基础感兴趣，以便能够理解当今 ML 应用程序中使用的更高级概念，例如深度学习和法学硕士，并且本书（2006 年起）中的一些技术很可能在当今机器学习的实际应用中已经过时了，我想从读过这本书并且在该主题上有经验的人那里知道我应该最强调本书的哪些部分/章节，从而哪些是最关键和最重要的对于我的目的来说是基础。 我提前感谢您的建议！   由   提交/u/Rob130301  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdualg/seeking_recommendations_for_prml_by_bishop/</guid>
      <pubDate>Fri, 26 Apr 2024 19:32:23 GMT</pubDate>
    </item>
    <item>
      <title>我的多变量回归模型在使用所谓的虚拟变量陷阱时表现更好。为什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdsqkx/my_multivariable_regression_model_performed/</link>
      <description><![CDATA[我的多变量回归模型在使用所谓的虚拟变量陷阱时比没有该额外变量时表现得更好。为什么？这应该发生吗？我使用 ols、ridge 和 lasso 估计系数，并且使用额外变量的结果总是更好。我在保留测试集上根据均方误差 (MSE) 和决定系数（R^2 分数）评估了模型。   由   提交 /u/sloth_on_adderall   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdsqkx/my_multivariable_regression_model_performed/</guid>
      <pubDate>Fri, 26 Apr 2024 18:28:13 GMT</pubDate>
    </item>
    <item>
      <title>UT 人工智能在线 MS</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdsdeh/online_ms_in_ai_at_ut/</link>
      <description><![CDATA[大家好。 UT Austin 今年年初开始接受在线人工智能硕士学位的学生，我想知道课程怎么样？负载是什么样的？我在网上找不到太多信息。谢谢。    由   提交 /u/According_Ice6515   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdsdeh/online_ms_in_ai_at_ut/</guid>
      <pubDate>Fri, 26 Apr 2024 18:13:28 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 值的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cds1h0/help_for_shap_values/</link>
      <description><![CDATA[您好，我正在尝试将 SHAP 添加到我的 Pytorch CNN，并且昨天能够生成一些值而没有错误。然而，每个测试输入的值几乎完全相同，并且我每次都得到相同的类别预测。  我的网络不是很好，但根据混淆矩阵有 80% 的准确率，没有比其他类更多地过度猜测任何类，所以错误不应该出在那里。我使用了官方 SHAP 文档中的 CNN 示例，但我想知道我的错误可能出在哪里。我对 SHAP 的理解仍然相当有限，我将非常感谢任何帮助。  ​ 代码： device = (&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) print(f&quot;使用 {device} 设备&quot;)  model = Network().to(device) model.load_state_dict(torch.load(&quot;CNNModel.pth&quot;))  model.eval()  def nhwc_to_nchw(x: torch.Tensor) -&gt; torch.Tensor: if x.dim() == 4: x = x if x.shape[1] == 1 else x.permute(0, 3, 1, 2) /&gt; elif x.dim() == 3: x = x if x.shape[0] == 1 else x.permute(2, 0, 1) return x  def nchw_to_nhwc(x: torch.Tensor) -&gt; torch.Tensor: if x.dim() == 4: x = x if x.shape[3] == 1 else x.permute(0, 2, 3, 1) /&gt; elif x.dim() == 3: x = x if x.shape[2] == 1 else x.permute(1, 2, 0) return x  testdata_path = &#39;./testdata/audio/&#39; data_path = &#39;../data_loader/archive (15)/Data/genres_original/&#39;genre_classes = [&#39;蓝调&#39;, &#39;古典&#39;, &#39;乡村&#39;、&#39;迪斯科&#39;、&#39;嘻哈&#39;、&#39;爵士&#39;、&#39;金属&#39;、&#39;流行&#39;、&#39;雷鬼&#39;、&#39;摇滚&#39;]  test_images, test_genres = get_features(testdata_path) 图像、流派 = get_features(data_path)  test_images = torch.tensor(test_images) X_train、X_test、y_train、y_test = train_test_split(图像、流派、test_size=0.2、random_state=42)  X_train = torch.tensor(X_train)  mean = torch.mean(X_train, dim=(0, 2, 3)) std = torch.std(X_train, dim =(0, 2, 3))  transform = [ torchvision.transforms.Lambda(nhwc_to_nchw), torchvision.transforms.Lambda(lambda x: x * (1 / 255)), torchvision.transforms.Normalize(mean=mean, std=std), torchvision.transforms.Lambda(nchw_to_nhwc),]  inv_transform = [ torchvision.transforms.Lambda(nhwc_to_nchw), torchvision.transforms.Normalize(mean=(-1 * np.array(mean) / np.array(std)).tolist (), std=(1 / np.array(std)).tolist(), ), torchvision.transforms.Lambda(nchw_to_nhwc), ]  transform = torchvision.transforms.Compose(transform) inv_transform = torchvision.transforms.Compose(inv_transform)  def Predict(img: np.ndarray) -&gt; torch.Tensor:img = nhwc_to_nchw(torch.Tensor(img))img = img.to(device)output = model(img)返回输出 def main(): # test Xtr = transform(torch.Tensor(X_train)) out = Predict(Xtr[1:3]) 类= torch.argmax(out, axis=1).cpu().numpy() print(f&quot;类: {classes}: {np.array(genre_classes)[classes]}&quot;)  # test masker_blur = shap.maskers.Image(&quot;blur(128, 128)&quot;, Xtr[0].shape)  explainer = shap.Explainer(predict 、 masker_blur、output_names=genre_classes) shap_values =explainer( Xtr[:1], max_evals=100,batch_size=50,outputs=shap.Explanation .argsort.flip[:10] )  outputs = Predict(Xtr[3:20])classes = torch.argmax(outputs, axis=1).cpu( ).numpy() print(f&quot;Classes: {classes}: {np.array(genre_classes)[classes]}&quot;) 为索引，在 enumerate(outputs[3:20] 中输出): print(f&quot;实际输出{y_train[index + 3]}&quot;)  if __name__ == &quot;__main__&quot;: main()    由   提交/u/Affectionate_Arm_922   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cds1h0/help_for_shap_values/</guid>
      <pubDate>Fri, 26 Apr 2024 18:00:08 GMT</pubDate>
    </item>
    <item>
      <title>如何减少过拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdpgwm/how_to_reduce_overfitting/</link>
      <description><![CDATA[我有这些选项可供选择以减少过度拟合，并想看看社区是否同意。 选项 A提高学习率  我说这不会减少过度拟合。 bc 这只会改变在无限长的时间内开始过度拟合的速度  选项 B 对训练图像应用随机变换（例如翻转、旋转）  我说这确实有助于减少过度拟合，因为您正在增加训练测试集。  选项 C 使用较小的网络&lt; /strong&gt;  我说这确实减少了过度拟合，因为它不是“记住”的。复杂的模式或任何东西  选项 d 使用更大的网络  我说这不会减少过度拟合，因为更大的网络，你开始记住不同的模式，对我来说，这就是过度拟合的定义。  选项 e 当验证损失趋于平稳时停止训练  对此不太确定。  有人可以帮助我了解如何减少过度拟合的逻辑吗？ ​ 所以我的最终答案是  B 和 C    由   提交 /u/Famous-Help-3572   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdpgwm/how_to_reduce_overfitting/</guid>
      <pubDate>Fri, 26 Apr 2024 16:15:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 Phi-3 构建 RAG 管道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdo3up/building_a_rag_pipeline_with_phi3/</link>
      <description><![CDATA[嘿， 刚刚发布了一个快速视频，使用 Phi-3 和 langchain&lt; 来设置 RAG 管道&lt; /strong&gt;。 我认为它对于那些想要运行一些测试的人来说可能很方便。 Phi-3？  新针对手机和小型设备优化的小语言模型，性能与 Llama3 具有竞争力 干杯！ https:// youtu.be/HCX210dyHhk ​ ​    ;由   提交/u/Mosh_98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdo3up/building_a_rag_pipeline_with_phi3/</guid>
      <pubDate>Fri, 26 Apr 2024 15:20:27 GMT</pubDate>
    </item>
    <item>
      <title>如何用较小的开源模型击败专有法学硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdn9pa/how_to_beat_proprietary_llms_with_smaller_open/</link>
      <description><![CDATA[       由   提交/u/aidantcooper  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdn9pa/how_to_beat_proprietary_llms_with_smaller_open/</guid>
      <pubDate>Fri, 26 Apr 2024 14:46:10 GMT</pubDate>
    </item>
    <item>
      <title>Ian Goodfellow 的深度学习书籍和 ML 数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdlujl/ian_goodfellows_deep_learning_book_and_ml/</link>
      <description><![CDATA[我开始阅读 Ian Goodfellow 的 Deep Laerning 书。但是，我意识到我在大学数学课程中几乎已经学完了书中的所有内容。当然，我并不了解机器学习数学的所有知识，而且我对大学数学也有点生疏了。但是，把所有的事情都记下来还是感觉很累很无聊。而且我似乎并没有纯粹从书本上学到很多东西。 而且我对 ML 的实际方面知之甚少，所以我浏览了 Andrej Karpathy、bycloud、Gary Explains 视频，他们帮助我很多。所以，现在，我正在考虑做更多的实践课程，学习如何实际使用 ML irl。我现在应该浏览一下伊恩的书吗？我觉得无论如何我都会忘记大部分这些东西，当我需要它时，我最好稍后再学习数学。    由   提交/u/open_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdlujl/ian_goodfellows_deep_learning_book_and_ml/</guid>
      <pubDate>Fri, 26 Apr 2024 13:46:48 GMT</pubDate>
    </item>
    <item>
      <title>如何处理多模态特征？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdlsar/how_to_handle_multi_modal_feature/</link>
      <description><![CDATA[      嗨！我有一个称为“财务损失”的功能。基本上描述了一个人在骗局中损失了多少。你如何预处理或处理这种特征？ log 或 sqrt 转换有帮助吗？    由   提交 /u/Vitoahshik   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdlsar/how_to_handle_multi_modal_feature/</guid>
      <pubDate>Fri, 26 Apr 2024 13:44:07 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 10 门数据科学数学免费课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdjeke/10_mathematics_for_data_science_free_courses_in/</link>
      <description><![CDATA[       由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdjeke/10_mathematics_for_data_science_free_courses_in/</guid>
      <pubDate>Fri, 26 Apr 2024 11:52:21 GMT</pubDate>
    </item>
    <item>
      <title>LLM：情境学习为何有效？从技术角度来看，具体发生了什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdif8m/llms_why_does_incontext_learning_work_what/</link>
      <description><![CDATA[无论我在哪里寻找这个问题的答案，得到的答案只不过是将模型拟人化而已。他们总是提出这样的主张：  如果没有示例，模型必须推断上下文并依靠其知识来推断出预期的结果。这可能会导致误解。 一次性提示通过提供具体示例来减轻这种认知负担，有助于锚定模型的解释并专注于具有更清晰期望的更狭窄的任务。  该示例充当模型的参考或提示，帮助其理解您正在寻求的响应类型并在训练期间触发对类似实例的记忆。&lt; /p&gt; 提供示例允许模型识别要复制的模式或结构。它为模型建立了一个对齐线索，减少了零样本场景中固有的猜测。  顺便说一句，这些是真实的摘录。 但这些模型不“理解”任何东西。他们不“推断”，或“解释”，或“聚焦”，或“记住训练”，或“猜测”，或有字面上的“认知负荷”。它们只是统计令牌生成器。因此，当寻求对上下文学习提高准确性的确切机制的具体理解时，像这样的流行科学解释是毫无意义的。 有人可以提供一个根据实际模型来解释事物的解释吗？架构/机制以及提供额外上下文如何带来更好的输出？我可以“说说而已”，所以请不遗余力地提供技术细节。 我可以做出有根据的猜测 - 在输入中包含示例，这些示例使用近似于您想要的输出类型的标记来引导注意力机制，并且最终的密集层对更高的令牌进行加权，这些令牌在某种程度上与这些示例相似，从而增加了在每个生成步骤中对这些所需令牌进行采样的几率；就像从根本上讲，我猜测相似性/距离的事情，其中​​明确举例说明我想要的输出会增加获得的输出与其相似的可能性 - 但我更愿意从对这些模型有深入了解的其他人那里听到它   由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdif8m/llms_why_does_incontext_learning_work_what/</guid>
      <pubDate>Fri, 26 Apr 2024 10:59:11 GMT</pubDate>
    </item>
    <item>
      <title>硕士生，却是个骗子。想要做对。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cdahde/masters_student_but_a_fraud_want_to_make_it_right/</link>
      <description><![CDATA[大家好，我想分享一些我非常没有安全感和羞耻的东西。但我觉得为了以后的改进，需要把它拿出来。我是美国一所非常普通的公立大学的计算机硕士学生，我也是从那里获得了学士学位。在我本科生期间，一开始我表现不错，但随着我进入第三年和第四年，课程变得越来越难，我在课堂上只做了最低限度的事情。这意味着没有副业，没有动力去做任何事情，没有实习，并且在我交作业或完成一个学期的那一刻就忘记了一切。我一直告诉自己，我会“稍后”阅读这个基本概念，但后来从未实现过，而且我对现在正在做的事情的基础非常薄弱。这意味着每当我遇到问题时，我都会严重依赖 ChatGPT，这让我感觉很糟糕和愚蠢，从而导致更多的不良行为。我从来没有完成过令我感到自豪的项目。在攻读硕士学位期间，我接触了 ML 并参加了 NLP 课程，我非常喜欢这门课程，主要是因为教授的帮助，我想在 2024 年秋季在这位教授的指导下进行研究，但我的编程技能，尤其是 Python 技能低于标准水平，而且我对 ML 的了解还不够。是不够的。我有 3.5 个月的时间来打下良好的基础，真正学习 ML 和 NLP，而不是在我不明白的时候就使用 chatGPT。我正在考虑首先学习 Andrew NG 的 ML 专业课程，并通过 Andrej Karpathy 在 YT 上的从零到英雄播放列表进行补充。有没有人有任何建议或建议，或者这是一个好的起点，以及完成这些课程后我应该做什么。我厌倦了无能，我想改变这一点。    由   提交/u/Funny_Professional85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cdahde/masters_student_but_a_fraud_want_to_make_it_right/</guid>
      <pubDate>Fri, 26 Apr 2024 02:48:01 GMT</pubDate>
    </item>
    </channel>
</rss>