<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 26 Jun 2024 06:21:45 GMT</lastBuildDate>
    <item>
      <title>将 LLM 映射到 GPU 实例以避免 OOM 错误</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dorpr4/mapping_of_llms_to_gpu_instances_to_avoid_oom/</link>
      <description><![CDATA[  由    /u/Possible_Minute_4299  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dorpr4/mapping_of_llms_to_gpu_instances_to_avoid_oom/</guid>
      <pubDate>Wed, 26 Jun 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和数据科学职位简历的注意事项</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1doqw89/resume_dos_and_donts_for_ai_and_data_science_jobs/</link>
      <description><![CDATA[在看过很多简历评论和与工作相关的帖子后，我介绍了一些简历技巧，可帮助您获得 ML 工程师、数据科学家或其他相关职位。AIQ 第 2 集通过回答一些重要问题讨论了如何为 AI 和 ML 工作准备简历（技巧和窍门），例如 1. 简历的重要部分。 2. 应届毕业生简历技巧 3. 认证与项目 4. 要避免的错误 5. 1 页简历是强制性的吗？ 6. 您是否应该包括过去的非技术经验？ 7. 免费 ATS 用于简历审查。 8. 可供选择哪些项目？ 9.我可以包括泰坦尼克号分类吗？......以及许多其他问题 在此处查看播客：https://youtu.be/vl0zNSE9Zws?si=IQwi9srpomnUmUE8    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1doqw89/resume_dos_and_donts_for_ai_and_data_science_jobs/</guid>
      <pubDate>Wed, 26 Jun 2024 05:23:57 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 的 Sora：文本转视频的人工智能的下一个飞跃——计算机视觉将扮演什么角色？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1doqdz1/openais_sora_the_next_leap_in_ai_with_texttovideo/</link>
      <description><![CDATA[大家好，我最近一直在研究人工智能的世界，尤其是计算机视觉，我偶然发现了一些关于 OpenAI 的新文本转视频工具 Sora 的有趣信息。它让我开始思考人工智能发展的更广泛影响，特别是视觉理解对于实现更先进的人工智能甚至 AGI 的重要性。 Sora 的简要介绍：  这是一款可以根据文本描述生成长达 60 秒的视频的人工智能工具 目前正在测试中，尚未向公众开放 使用“扩散变压器模型” （类似于 DALL-E 3 对图像的工作方式） 可以处理复杂的场景、相机移动，甚至在某种程度上模拟物理  有趣的是，与之前的文本到图像模型相比，Sora 似乎对物理世界和语言有更深入的理解。这让我想知道：计算机视觉对于 AI 的下一次重大飞跃有多重要？ 一些想法：  人类智能严重依赖视觉信息。想想一个 3 岁的孩子如何仅通过看一棵树就轻松识别一棵树。 当前的语言模型非常出色，但它们主要基于文本进行训练。我们是否因为没有整合强大的视觉理解而缺少了一个巨大的组件？ 可以为 LLM 提供自己的“一双眼睛”吗？ （即先进的计算机视觉功能）是迈向更通用智能的关键一步吗？ 纯语言模型是否会达到极限，从而使视觉理解成为进一步发展的必要条件？  我对此特别感兴趣，因为我正在工作中从事 CV 项目（尽管目前处于暂停状态）。该领域的职位空缺似乎比一般 ML 少，但我不禁觉得它将是未来的关键。 你们都觉得呢？像 Sora 这样的工具只是计算机视觉与 AI 系统更深入集成的开始吗？真正的 AGI 是否需要强大的视觉组件才能真正理解和与世界互动？ 让我们讨论一下！    提交人    /u/shivgupta5023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1doqdz1/openais_sora_the_next_leap_in_ai_with_texttovideo/</guid>
      <pubDate>Wed, 26 Jun 2024 04:53:00 GMT</pubDate>
    </item>
    <item>
      <title>正在寻找助手和共同学习者？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dooqo9/looking_for_helpers_and_colearners/</link>
      <description><![CDATA[嘿伙计们，正如你们所知，我之前创建了一个学习小组 discord 服务器，很多人都是从同一个子版块加入的。 现在我们正在寻找一些可以为服务器中的人们做出贡献或提供帮助的助手。 （请注意，这个服务器中有很多初学者） 所以如果你想为这个服务器做出贡献，请加入这个服务器：https://discord.com/invite/pKSvqwNv    提交人    /u/luffy_san2345   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dooqo9/looking_for_helpers_and_colearners/</guid>
      <pubDate>Wed, 26 Jun 2024 03:19:31 GMT</pubDate>
    </item>
    <item>
      <title>物理学家的机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dooq6m/machine_learning_for_a_physicist/</link>
      <description><![CDATA[我一直想学习物理，因为它作为一门科学让我着迷，但我知道我并不喜欢它作为职业选择，无论是成为一名学者和做研究还是只是教书。另一方面，我一直对人工智能和机器学习感兴趣，而且也有很好的职业选择。我没有获得 CSE 学士学位，因为我会后悔没有学习我非常喜欢的物理。但现在我即将完成我的物理学学士学位，最后一篇论文是关于神经网络的，随后是一个交通标志识别 ANN 的项目，我想知道物理学学士学位是否会让我比拥有计算机科学和工程学位的人处于劣势。我将在未来 2 年内完成一个优秀的数据科学硕士课程，重点是深度学习神经网络，但我对这些分支的市场运作方式并不十分了解。一方面，作为物理专业的学生，​​我的数学技能（无论是理论还是应用）都明显优于 CSE 专业的学生。另一方面，除了自学 Javascript SQL 和 Python 之外，我的学位只提供两门 C 和 C++ 编程课程，涵盖基础知识。这是否会限制我从事更多以研究为导向的工作？有哪些可能性和职位，以及我作为物理学家的身份对现实世界中想要招聘的公司有多重要？    提交人    /u/ThroawayAcc17   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dooq6m/machine_learning_for_a_physicist/</guid>
      <pubDate>Wed, 26 Jun 2024 03:18:45 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉对人工智能的发展有多重要</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1domqvu/how_important_will_computer_vision_be_to_the/</link>
      <description><![CDATA[我正在学习 ML，特别是计算机视觉，这个领域的工作机会少得多，但这是我的出路，因为我目前的工作是做一个 CV 项目（有点，由于市场原因，该项目暂停了，我已经从研发部门调到维持部门，但到目前为止已经做了足够多的工作来自学其余部分并将其写在简历上） 现在回到这篇文章的重点。对于人类智能来说，视觉似乎非常重要。如果你问一个三岁的孩子什么是树，他们很可能知道什么是树，或者至少可以识别一棵树。很多人都是视觉学习者，我明白人工智能在表面下或多或少只是数学，但我们可能会利用现有的 NLP 数据来消耗或过度训练当前的人工智能系统，而 LLM 可能会停滞不前。你们都认为真正的 AGI 需要一个 CV 组件来真正理解世界吗？我们在描述和标记事物方面取得的进展是否有限？当前的模型真的只有耳朵而没有眼睛，我们是否错过了自身智能的很大一部分？我知道有 CV 模型，但一切仍然归结为这些 LLM 中的嵌入式标签，构建天网的下一步是否会涉及为 LLM 提供一双自己的眼睛？有谁明白我想说什么，能比我解释得更好吗？    提交人    /u/LeopoldBStonks   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1domqvu/how_important_will_computer_vision_be_to_the/</guid>
      <pubDate>Wed, 26 Jun 2024 01:38:05 GMT</pubDate>
    </item>
    <item>
      <title>人脸识别模型需要训练吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dojxd9/is_it_necessary_to_train_face_recognition_model/</link>
      <description><![CDATA[比如，我可以只取平均嵌入，然后尝试使用具有阈值的新图像吗？（适用于 5-6 个类，每个类 10 张图像）    提交人    /u/uba-luba-dub-dub   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dojxd9/is_it_necessary_to_train_face_recognition_model/</guid>
      <pubDate>Tue, 25 Jun 2024 23:20:10 GMT</pubDate>
    </item>
    <item>
      <title>构建 AI 语音翻译器：保留任何语言的声音！（Python + Gradio 教程）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dohvsg/build_an_ai_voice_translator_keep_your_voice_in/</link>
      <description><![CDATA[上周，我开发了一个语音翻译器，只花了几个小时就使用了 3 种不同的 API。最近，AI API 所能做的事情令人惊叹。 🎤🌐 您可以录下自己说英语的声音，然后听自己的声音翻译成西班牙语、俄语、日语或任何其他语言！翻译后的音频保留了您独特的声音，让您感觉非常个性化和真实。🌟🗣️ 我录制了一个视频，记录了使用 Gradio（Python 语言）制作此应用的过程，大约只需 20 分钟。 我为此感到非常自豪，希望对您有所帮助！ https://youtu.be/ZduW0N31JuE   由    /u/turpyturp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dohvsg/build_an_ai_voice_translator_keep_your_voice_in/</guid>
      <pubDate>Tue, 25 Jun 2024 21:50:36 GMT</pubDate>
    </item>
    <item>
      <title>像专业人士一样构建知识图谱：传统 NER 与大型语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dof3ef/construct_knowledge_graphs_like_a_pro_traditional/</link>
      <description><![CDATA[您是否考虑使用 LLM 构建知识图谱以增强您的 RAG 系统？ 您知道实际上可以使用混合方法来结合两全其美吗？ 查看我们的最新视频：像专业人士一样构建知识图谱：传统 NER 与大型语言模型 知识图谱是现代数据驱动世界的支柱。它们帮助我们组织信息，发现隐藏的见解，并为语义搜索和智能问答等高级应用程序提供支持。但您如何真正构建有效的知识图谱？ 在我最新的 YouTube 视频中，我深入探讨了关键方法 - 传统的命名实体识别 (NER) 方法与尖端的大型语言模型 (LLM)。我比较了每种方法的优缺点，以便您可以选择最适合您的知识图谱项目的方案。 传统的 NER 技术（如基于规则的系统和机器学习模型）可提供精确度、透明度和计算效率。但它们在跨域可扩展性和适应性方面存在困难。另一方面，LLM 可带来令人印象深刻的上下文理解和快速设置，但它们资源密集且可解释性较差。 该视频探讨了如何通过结合两种方法的优点的混合方法最大限度地从非结构化数据源中提取见解。我分享了现实世界的例子、实用技巧以及选择知识图谱构建方法时需要考虑的关键因素。 看看吧： https://youtu.be/OsnM8YTFwk4?si=GGwJEyXNix5_erav    提交人    /u/linamagr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dof3ef/construct_knowledge_graphs_like_a_pro_traditional/</guid>
      <pubDate>Tue, 25 Jun 2024 19:54:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 TinyVGG 和 TrivialAugment 进行实验时的有趣观察</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dof1qu/interesting_observation_while_experimenting_with/</link>
      <description><![CDATA[      我正在从这个 YouTube 视频中学习使用 PyTorch 进行图像识别，视频中使用 TinyVGG 将图像分为披萨、牛排或寿司。所以我尝试自己做，调整了一些超参数，并对使用和不使用 TrivialAugment 的 TinyVGG 的性能进行了有趣的观察。 不使用 TrivialAugment 的损失和准确度曲线 .......并使用 TrivialAugment 视频中的讲师提到，TrivialAugment 应该是一种 SOTA 数据增强技术，并且与 ResNet50 配合得相当好。我很困惑为什么这个东西对 TinyVGG 来说不是一个好兆头。如您所见，使用 TrivialAugment 时损失曲线到处都是。我对计算机视觉模型和 ML 还不太熟悉，所以我不完全确定为什么会出现如此显著的差异。    提交人    /u/Ar010101   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dof1qu/interesting_observation_while_experimenting_with/</guid>
      <pubDate>Tue, 25 Jun 2024 19:52:18 GMT</pubDate>
    </item>
    <item>
      <title>从头开始训练 70B 模型：开源工具、评估数据集和经验教训</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dobgbs/training_a_70b_model_from_scratch_open_source/</link>
      <description><![CDATA[今年早些时候，Imbue 训练了一个针对推理和编码进行了优化的 70B 模型。尽管训练数据量少了 7 倍，但该模型的性能与 LLAMA 3 70B 大致相当。 今天，我们发布了一个工具包来帮助其他人做同样的事情，其中​​包括：  11 个经过清理和扩展的 NLP 推理基准，包括 ARC、GSM8K、HellaSwag 和 Social IQa 原创的以代码为中心的推理基准 包含 450,000 个关于 NLP 问题歧义性的人类判断的新数据集 用于将小型实验扩展到 70B 运行的超参数优化器 用于将集群从裸机转变为强大的高利用率训练的基础架构脚本  …还有更多！ 在此处阅读更多信息并访问工具包：https://imbue.com/research/70b-intro/ 除了我们的工具之外，我们还分享了三篇博客文章，其中包含我们从训练过程中获得的经验教训： I. 进行评估 我们发现，经过微调后，我们的模型和最好的开源模型在大多数多项选择基准测试中都优于 GPT-4o 零样本。 令人惊讶的是，当仅对明确的问题进行评估时，开放和封闭模型都达到了接近 100% 的准确率。我们清理了评估数据集，以将真正的推理失败与由于模棱两可或低质量问题导致的失败区分开来。 https://imbue.com/research/70b-evals/ II.设置基础设施 使用我们的集群进行高性能训练意味着每个组件（InfiniBand、以太网、GPU 和节点本身）都必须完美运行。如果超过 12,000 个连接中哪怕只有一个有点不稳定，也可能会减慢整个训练运行速度。 我们正在分享开源脚本和端到端基础设施设置指南，其中详细介绍了使一切完美运行并确保其保持这种状态的过程。 https://imbue.com/research/70b-infrastructure/ III。扩展实验 我们在第一次尝试时就成功地从 7B 运行扩展到 70B 运行，训练不稳定性最小，没有损失峰值。我们还根据更小模型的实验结果预测了 70B 模型的性能。 我们使用超参数优化器 CARBS 实现了这一目标。我们今天开源了 CARBS，以便其他尝试新模型架构的小团队可以进行小规模实验并信任大规模性能。 https://imbue.com/research/70b-carbs/ 这是我们正在开展的众多项目之一，旨在构建可以推理和编码的协作代理。其他领域包括 RL、数据生成和体验设计，以使这些强大的功能对用户来说易于访问和直观。 如果这引起了你的兴趣，我们正在招聘！    提交人    /u/thejashGI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dobgbs/training_a_70b_model_from_scratch_open_source/</guid>
      <pubDate>Tue, 25 Jun 2024 17:21:43 GMT</pubDate>
    </item>
    <item>
      <title>请禁止发布职业/简历帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dobbqq/please_ban_careerresume_posts/</link>
      <description><![CDATA[或者为他们创建另一个子版块或类似的东西。天呐。这个子版块充斥着无休止的&quot;评价我的简历&quot;或&quot;我需要 x 学位才能学机器学习吗&quot;帖子，而不是关于实际机器学习的内容    提交人    /u/Surmaaja   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dobbqq/please_ban_careerresume_posts/</guid>
      <pubDate>Tue, 25 Jun 2024 17:16:12 GMT</pubDate>
    </item>
    <item>
      <title>哪些模型最适合投资组合优化？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do9ork/what_models_are_best_for_portfolio_optimization/</link>
      <description><![CDATA[我使用随机森林模型，因为我知道它是最好的模型之一，具有最小的 MSE 和其他一般的东西，但我听说很多人使用神经网络。我使用随机森林来预测未来 5 年的回报，然后从中选择具有最佳回报的股票。    提交人    /u/patrickbateman53   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do9ork/what_models_are_best_for_portfolio_optimization/</guid>
      <pubDate>Tue, 25 Jun 2024 16:07:08 GMT</pubDate>
    </item>
    <item>
      <title>需要硕士或博士学位才​​能成为机器学习工程师。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do5w88/need_master_or_phd_for_become_machine_learning/</link>
      <description><![CDATA[问题很明确。成为 ML 工程师是否需要硕士学位和博士学位，或者像 coursea 这样的在线平台的优质证书是否足以获得良好的职业生涯？（我想在大公司工作）    提交人    /u/Necessary-Car-5080   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do5w88/need_master_or_phd_for_become_machine_learning/</guid>
      <pubDate>Tue, 25 Jun 2024 13:22:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do0dne/maths_for_ml/</link>
      <description><![CDATA[嗨，我刚刚开始学习机器学习。目前，我正在 Coursera 上学习 Andrew Ng 的 DeepAI“机器学习专业化”课程。为了进一步进步，我想学习一些数学。有人可以推荐一门关于机器学习中使用的数学的好课程吗？还有，有人可以建议在该领域前进的最有效途径是什么吗？我一直在练习和观看 Python、Numpy、Matplotlib 和 Pandas 的视频。我觉得还需要一些 Tensorflow 知识。除此之外，你们对我这个初学者有什么建议吗？    提交人    /u/NF_laidback   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do0dne/maths_for_ml/</guid>
      <pubDate>Tue, 25 Jun 2024 07:41:38 GMT</pubDate>
    </item>
    </channel>
</rss>