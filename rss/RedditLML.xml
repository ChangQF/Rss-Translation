<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 02 Apr 2024 15:12:57 GMT</lastBuildDate>
    <item>
      <title>我对 Kaggle 的预测只有在数据预处理非常少的情况下才会达到最大值，而且我不知道如何提高我的分数。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bu169a/my_predictions_on_kaggle_are_coming_at_a_maximum/</link>
      <description><![CDATA[我的数据集是一个金融预测数据集，有 9 个目标变量和大约 200 个预测变量，但我陷入了困境。当我的数据中有 np.inf 时，我不是用 nan 来估算它，然后使用 KNNImpute 或其他东西，而是用 float32 的最高可能值来估算它，我得到了更好的分数。我觉得如果我找到一种更好的方法来计算空值，我也会得到更好的分数。我的模型是 XGBoost，我注意到数据集中的一些缺失值似乎具有类似的模式，其中特定行中缺失相同的列值，但我无法确定到底该如何处理它并删除这些值rows 使我的 R^2 分数降低了很多。然而，事实证明，删除具有大量空值和中等数量空值且与目标数据高度相关的列非常有效。  &amp;# 32；由   提交/u/Electrical-Wafer4526  /u/Electrical-Wafer4526 reddit.com/r/learnmachinelearning/comments/1bu169a/my_predictions_on_kaggle_are_coming_at_a_maximum/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bu169a/my_predictions_on_kaggle_are_coming_at_a_maximum/</guid>
      <pubDate>Tue, 02 Apr 2024 15:11:56 GMT</pubDate>
    </item>
    <item>
      <title>我建立了一个免费的在线课程来教你如何实现检索增强生成</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bu0w9j/i_built_a_free_online_course_for_teaching_you_how/</link>
      <description><![CDATA[很好奇这里是否有人有兴趣查看它&amp;给我反馈。本课程完全在浏览器中完成，向您展示如何解析大型 PDF 文件、使用 OpenAI 的嵌入函数、使用矢量 DB 以及使用 LangChain 的 ConversationalRetrievalChain。 如果您有兴趣，请私信我!   由   提交 /u/D_D   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bu0w9j/i_built_a_free_online_course_for_teaching_you_how/</guid>
      <pubDate>Tue, 02 Apr 2024 15:00:57 GMT</pubDate>
    </item>
    <item>
      <title>如何使用计算机视觉将 3D 模型实时叠加到检测到的物体上？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bu0jv8/how_can_i_overlay_a_3d_model_onto_a_detected/</link>
      <description><![CDATA[我正在开发一个项目，需要使用计算机视觉将 3D 模型实时叠加到检测到的对象上。具体来说，我想检测摄像头输入中是否存在玻璃，并将玻璃的 3D 模型叠加到其上。此外，我想使用重叠的 3D 模型来识别真实玻璃中缺失的组件，例如把手。我探索过使用 YOLO 等技术进行对象检测，使用 Unity3D 渲染 3D 模型，但我不确定如何继续进行叠加和组件识别过程。有人可以提供如何实现这一目标的指导吗？具体来说，我正在寻找以下方面的建议：如何将 3D 模型实时准确地叠加到检测到的对象上。使用重叠 3D 模型识别真实对象中缺失组件的技术或算法。任何可以帮助实现此功能的库、框架或工具。任何帮助或建议将不胜感激。谢谢你！    由   提交/u/rootofpi227  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bu0jv8/how_can_i_overlay_a_3d_model_onto_a_detected/</guid>
      <pubDate>Tue, 02 Apr 2024 14:46:23 GMT</pubDate>
    </item>
    <item>
      <title>LilianWeng博客关于DDIM核心思想推导的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bu07ei/question_about_ddim_core_idea_derivation_from/</link>
      <description><![CDATA[      大家好，我在阅读DDIM核心思想的推导时遇到了麻烦，对从第一行跳到第二行感到困惑，如图。以下是博客链接：https:// /lilianweng.github.io/posts/2021-07-11-diffusion-models/#speed-up-diffusion-model-sampling 我可以使用 x_t-1 = a*x_0 + b 得到相同的结果*x_t + std*noise 等，所以基本上可以使用重新参数化技巧来替代和发挥作用，但这相当冗长。我感觉这里漏掉了什么，她能用什么技巧从第一行跳到第二行吗？非常感谢任何帮助，谢谢！ 图1   由   提交 /u/Puzzleheaded_Monk787   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bu07ei/question_about_ddim_core_idea_derivation_from/</guid>
      <pubDate>Tue, 02 Apr 2024 14:31:26 GMT</pubDate>
    </item>
    <item>
      <title>如果您已经在该领域，那么有不错的 ML Ops 课程吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btziyd/good_ml_ops_course_to_upscale_if_youre_already_in/</link>
      <description><![CDATA[我已经在 DS 领域工作了几年，非常习惯于建模，并将一些 ML 管道投入生产。我的大部分生产工作要么是使用 GUI（在我的例子中是 Rapidminer），要么是在 cron 上使用 hacky Python 脚本。因此，我觉得有必要提高一下我的技能。 如果我能接受任何对我这种情况的人有用的课程建议，我将不胜感激。对我来说，这意味着：  更多地关注 devops/生产部分（我已经掌握的 ML 基础知识） 尝试并关注平台较少的元素特定的依赖关系。  例如有些公司使用数据块，有些公司使用 Azure/AWS 堆栈，但应该有一些超越技术堆栈的元素。 同样，我认为容器和良好环境最佳实践等概念具有更广泛的实用性。  li&gt; 甚至，就像经常发生的情况一样，您的公司还没有技术堆栈 - 关于如何实现它的建议。  有重点关注什么更有可能超越趋势浪潮（因为如今生产工具来得快去得也快）  如此多的课程（甚至是“工程”）我发现似乎有 4/5 的重点放在 ML 基础知识上，我没有再稍微复习一下，但我确实在寻找类似上面的东西。   由   提交 /u/jshkk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btziyd/good_ml_ops_course_to_upscale_if_youre_already_in/</guid>
      <pubDate>Tue, 02 Apr 2024 14:02:36 GMT</pubDate>
    </item>
    <item>
      <title>是否有人工智能可以学习或预测小型在线游戏的机会类型事物？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btzi9x/is_there_a_ai_that_can_learn_or_predict_small/</link>
      <description><![CDATA[我对人工智能的研究还很陌生。最近在一些玩纸牌游戏的朋友的帮助下，我迷上了一款游戏。你在八个选择中的任何一个上下注硬币，如果你选择的卡被选中，你的硬币回报就会得到一个乘数。 玩了一段时间后，我开始思考是否会有一个人工智能我可以设置并观察模式并预测下一张牌的可能性。网上有类似的东西吗？   由   提交 /u/Th3DarkRavin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btzi9x/is_there_a_ai_that_can_learn_or_predict_small/</guid>
      <pubDate>Tue, 02 Apr 2024 14:01:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Img2Vec 和 UMAP 可视化高维数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btz5in/visualize_high_dimensional_data_with_img2vec_and/</link>
      <description><![CDATA[   /u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btz5in/visualize_high_dimensional_data_with_img2vec_and/</guid>
      <pubDate>Tue, 02 Apr 2024 13:46:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 Colab 进行实验或训练模型变得很糟糕</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btxkog/using_colab_for_experimenting_or_training_models/</link>
      <description><![CDATA[我不知道是不是只有我这么想，但最近尝试运行实验并跟上训练或实验时创建的文件已成为一种Colab 让人头疼。每次我都必须重新运行代码进行检查并再次返回，使单个错误再次返回。  你们在运行实验或训练模型时如何保持理智，你们是否经常保持可以使用的检查点？ 是否有任何关于此的博客文章或讨论以提高效率开发方法确实共享资源！I    由   提交 /u/Maniac_DT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btxkog/using_colab_for_experimenting_or_training_models/</guid>
      <pubDate>Tue, 02 Apr 2024 12:32:50 GMT</pubDate>
    </item>
    <item>
      <title>自我奖励模式可以成为LLM的未来吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btxcnd/can_selfreward_model_be_the_future_of_llm/</link>
      <description><![CDATA[让我们看看用于创建下一代 LLM 的自我奖励语言模型。 当前语言模型的瓶颈不仅在于标记的数量数据还取决于标记数据的质量。问题是 DPO 要求您拥有大量带标签的人类偏好数据才能训练模型。本文介绍的代理可以：充当指令跟踪模型，根据提示生成响应，生成并评估新的指令跟踪示例以添加到自己的训练集中。 全文： https://medium.com/aiguys/self-rewarding- language-model-4ee23ba67cf4 自我奖励语言模型 首先，我们从一组提示开始。然后，我们建立一个监督微调 (SFT) 模型，使其具有两种技能： - 生成响应 - 评估响应。 然后，我们使用 SFT 模型来生成数据提示和响应的形式以及排名的偏好对。每个提示都有多个潜在的完成，因此我们需要生成多个响应，然后使用相同的模型来排名哪个响应更好。他们使用巧妙的“LLM-as-a-Judge”提示来帮助生成并过滤添加回训练数据集中的数据，进而在正反馈循环中改进模型。 让模型遵循指令后的第二步是使模型与人类偏好保持一致。由于每个提示都有多个有效响应，因此了解我们更喜欢哪些响应会将语言模型从基本指令跟踪机器转变为更强大且一致的模型。 DPO 或 RLHF 等技术已被证明可以比简单的指令微调进一步改进语言模型。 此处需要注意的一些关键事项： 初始模型已经需要能够产生合理的响应，使其发挥作用奖励提示必须做好对输出进行评分的工作，以启动反馈循环如果我们不满足这两个条件，我们将产生垃圾，对垃圾进行排名，并将垃圾反馈到模型中。模型本身可以通过以下方式修改自己的训练集： - 生成一个新的提示，给出一些显示提示 - 生成 N给定每个提示的候选人响应 - 使用同一指令调整模型的法学硕士作为法官技能来评估每个候选人的响应，以评估其自己的响应 ​&lt; /p&gt;   由   提交 /u/Difficult-Race-1188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btxcnd/can_selfreward_model_be_the_future_of_llm/</guid>
      <pubDate>Tue, 02 Apr 2024 12:22:07 GMT</pubDate>
    </item>
    <item>
      <title>为文本到视频模型加载视频数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btx9hm/dataloading_video_data_for_text_to_video_model/</link>
      <description><![CDATA[嗨。我正在尝试构建文本到视频模型。我对人们通常如何存储大量数据并传输数据感到有点困惑。我的磁盘无法容纳太字节，但如果我尝试从 AWS 进行流式传输，则每个视频需要整整一分钟的时间，因为来自开源数据集的这些视频可能有很多帧。关于如何快速传输数据有什么建议吗？我查看了 Databricks 等服务，但不确定它们是否符合我的需求。他们看起来更有进取心。如果数据加载本身需要很长时间，就不可能训练这么多纪元......   由   提交/u/Only-Pen-1675   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btx9hm/dataloading_video_data_for_text_to_video_model/</guid>
      <pubDate>Tue, 02 Apr 2024 12:17:36 GMT</pubDate>
    </item>
    <item>
      <title>改进计算机视觉 ML 模型的技术</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btx8k5/techniques_for_improving_computer_vision_ml_model/</link>
      <description><![CDATA[大家好， 我一直在测试基于架构 vgg16 构建的机器学习模型，该模型接收图像作为输入并预测其标签。  现在，该图像是一件服装，并且具有不同的标签。标签如： - 类型（是衬衫、T 恤、正装衬衫、裤子、正装裤等。值范围为 0-9）， - 颜色， - 天气（0-9，每个数字对应一个温度）范围），- 性别（0-1，暂时简单一些），- 场合（0-9，不同的字符串对应不同的数字，正式为 0，休闲为 1 等） 现在的问题是我仅限于 3000 张图像的小数据集，无法执行增强（将图像旋转到不同角度以使数据集更大）。模型的性能很差，我希望它能够提高效率、准确性、精确度等。 当前的指标范围为不同标签的 30% 到 60%，性别的指标为 83%。  我可以应用哪些技术来使我的模型能够有效地进行预测。  非常感谢您，祝您学习愉快。    由   提交/u/khankhattak_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btx8k5/techniques_for_improving_computer_vision_ml_model/</guid>
      <pubDate>Tue, 02 Apr 2024 12:16:18 GMT</pubDate>
    </item>
    <item>
      <title>线性代数</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btv85f/linear_algebra/</link>
      <description><![CDATA[所提供的线性代数范围足以用于数据科学吗？我应该添加一些东西吗？我指的是开始数据科学所需的坚实的线性代数基础。这是一个很好的学习序列吗？  基本矩阵运算：  矩阵乘法 矩阵转置 &lt; li&gt;矩阵求逆 求解线性方程  线性方程：  求解线性方程  线性方程：  求解线性方程 li&gt; 求解线性方程组  向量空间和子空间 矩阵性质：&lt; /p&gt;  矩阵的特征值 矩阵的特征向量  矩阵分解：  LU 分解 QR 分解 奇异值分解 (SVD) 特征值分解  优化算法：  最小二乘法  主成分分析（PCA）    由   提交 /u/Acrobatic_Smoke_1873   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btv85f/linear_algebra/</guid>
      <pubDate>Tue, 02 Apr 2024 10:22:34 GMT</pubDate>
    </item>
    <item>
      <title>可变大小输入的随机森林</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bttq6h/random_forest_on_a_variablesize_input/</link>
      <description><![CDATA[        由   提交 /u/OhWaiiit   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bttq6h/random_forest_on_a_variablesize_input/</guid>
      <pubDate>Tue, 02 Apr 2024 08:43:15 GMT</pubDate>
    </item>
    <item>
      <title>但什么是 GPT？变形金刚视觉介绍 |深度学习，第 5 章</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btrlb1/but_what_is_a_gpt_visual_intro_to_transformers/</link>
      <description><![CDATA[       由   提交/u/limitless3172  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btrlb1/but_what_is_a_gpt_visual_intro_to_transformers/</guid>
      <pubDate>Tue, 02 Apr 2024 06:15:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么电弧放电不像升压那么受欢迎？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1btmn91/why_is_arcing_not_as_popular_as_boosting/</link>
      <description><![CDATA[Arcing 基于 DT 的 boosting 算法，大约是在同一时间开发的，但它在机器学习领域似乎并不流行。事实上，我只看到过一些 90 年代关于它的论文，当时 boosting 本身就被发现了。为什么这种特定的集成学习方法会随着时间的流逝而消失，而 bagging 和 boosting 仍然是流行的方法？   由   提交 /u/_HorseWithNoMane_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1btmn91/why_is_arcing_not_as_popular_as_boosting/</guid>
      <pubDate>Tue, 02 Apr 2024 01:51:38 GMT</pubDate>
    </item>
    </channel>
</rss>