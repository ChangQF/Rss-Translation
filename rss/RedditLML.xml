<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 29 Jul 2024 15:16:23 GMT</lastBuildDate>
    <item>
      <title>初级机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ef1x7x/beginner_ml/</link>
      <description><![CDATA[对于 ML 初学者来说，最好的资源是什么？请给出建议  谢谢    提交人    /u/Middle_Long_759   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ef1x7x/beginner_ml/</guid>
      <pubDate>Mon, 29 Jul 2024 15:08:38 GMT</pubDate>
    </item>
    <item>
      <title>如何处理准确率过高的过度自信模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eezq88/how_to_deal_with_an_overconfident_model_with_high/</link>
      <description><![CDATA[在作为硕士项目的一部分引入置信度阈值之前，我已经构建了一个具有良好准确度的机器学习模型（直方图梯度提升），并且该项目目标的准确度令人满意。问题是，我的模型在大多数情况下都会做出非常自信的预测，因此我的置信度阈值必须很高。我认为这是过度自信的问题。我该如何在不牺牲模型准确性性能的情况下解决这个问题？使用 Sklearn 的 CalibratedClassifierCV 进行的一些快速实验似乎表明，我的一个类的准确性在校准后会下降。    提交人    /u/centripetalstranger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eezq88/how_to_deal_with_an_overconfident_model_with_high/</guid>
      <pubDate>Mon, 29 Jul 2024 13:37:08 GMT</pubDate>
    </item>
    <item>
      <title>DCGAN 的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eezcwd/problems_with_dcgan/</link>
      <description><![CDATA[      大家好，我是 GAN 领域的新手，我想训练一个 DCGAN 来生成动漫人脸，但是出了问题。我进行了 100 个 epoch 的训练，但只产生了噪音： https://preview.redd.it/wfuz7rfwkgfd1.png?width=389&amp;format=png&amp;auto=webp&amp;s=a370773ccf8bb0d00c8f67fb3fa9eeeba713b82a 我进行了更多 epoch 的训练，但结果还是一样。 class Discriminator(nn.Module): def __init__(self): super(Discriminator，self).__init__() self.main = nn.Sequential( nn.Conv2d(3， 64， kernel_size=5， stride=4， padding=2， bias=False)， nn.BatchNorm2d(64)， nn.LeakyReLU(0.2， inplace=True)， nn.Conv2d(64， 64， kernel_size=5， stride=4， padding=2， bias=False)， nn.BatchNorm2d(64)， nn.LeakyReLU(0.2， inplace=True)， nn.Conv2d(64， 1， kernel_size=5， stride=4， padding=2， bias=False)， nn.Flatten()， nn.Sigmoid() ) def forward(self， x): return self.main(x) class Generator(nn.Module): def __init__(self): super(Generator， self).__init__() self.main = nn.Sequential( nn.ConvTranspose2d(128, 512, 内核大小=5, 步幅=2, 填充=1, 偏差=False), nn.ReLU(True), nn.BatchNorm2d(512), nn.ConvTranspose2d(512, 256, 内核大小=5, 步幅=2, 填充=1, 偏差=False), nn.ReLU(True), nn.BatchNorm2d(256), nn.ConvTranspose2d(256, 128, 内核大小=5, 步幅=2, 填充=1, 偏差=False), nn.ReLU(True), nn.BatchNorm2d(128), nn.ConvTranspose2d(128, 64, 内核大小=5, 步幅=2, 填充=1, 偏差=False), nn.ReLU(True), nn.BatchNorm2d(64), nn.ConvTranspose2d(64, 3, kernel_size=5, stride=2, padding=1, bias=False), nn.Tanh() ) def forward(self, x): return self.main(x) g_optimizer = optim.Adam(g_model.parameters(), lr=0.0002, betas=(0.5, 0.999)) d_optimizer = optim.Adam(d_model.parameters(), lr=0.0001, betas=(0.5, 0.999)) criterion = nn.BCELoss() num_epochs = 100 def train(): for epoch in range(num_epochs): for i, (real_images, _) in enumerate(dataset_loader): # 训练 d_model real_image = real_images.to(device) noice = torch.randn(real_image.size(0), latent_size, 1, 1, device=device) D_real = d_model(real_images) D_fake = d_model(g_model(noice)) real_label = torch.ones(D_real.size(0), 1) fake_label = torch.zeros(D_fake.size(0), 1) D_real_loss = criterion(D_real, real_label) D_fake_loss = criterion(D_fake, fake_label) D_loss = D_real_loss + D_fake_loss d_optimizer.zero_grad() D_loss.backward() d_optimizer.step() # 训练 g_model noice = torch.randn(real_image.size(0), latent_size, 1, 1, device=device) D_fake = d_model(g_model(noice).detach()) G_loss = criterion(D_fake, real_label) g_optimizer.zero_grad() G_loss.backward() g_optimizer.step() print(f&quot;Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataset_loader)}], D_loss: {D_loss.item():.4f}, G_loss: {G_loss.item():.4f}&quot;)     提交人    /u/Kepler-nn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eezcwd/problems_with_dcgan/</guid>
      <pubDate>Mon, 29 Jul 2024 13:20:40 GMT</pubDate>
    </item>
    <item>
      <title>帮我理解数学：关于 MNIST 训练的简单问题，但在任何地方都找不到令人满意的答案</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eez08i/help_me_understand_the_math_simple_question_about/</link>
      <description><![CDATA[为什么我不能训练网络直接预测图像标签，而是尝试猜测每个数字的概率？我能理解，有些地方不太对劲，但无法用语言清楚地表达出来。我对定义适当的损失函数的难度有一些想法，即 1 或 2 在形状上更远还是 1 和 7。 但是，如何解释为什么第一个方法有效，而第二个方法无效？损失函数模糊性是唯一的原因吗？ class Network(nn.Module): def __init__(self): super().__init__() # 定义层，128、64、每层 10 个单元 self.fc1 = nn.Linear(784, 128) self.fc2 = nn.Linear(128, 64) # 输出层，10 个单元 - 每个数字一个 self.fc3 = nn.Linear(64, 10) def forward(self, x): &#39;&#39;&#39; 前向传递通过网络，返回输出 logits &#39;&#39;&#39; x = self.fc1(x) x = F.relu(x) x = self.fc2(x) x = F.relu(x) x = self.fc3(x) x = F.log_softmax(x, dim=1) return x model = Network() criterion = lambda x, y: torch.mean(-x[range(len(y)), y]) #criterion = nn.NLLLoss() class Network(nn.Module): def __init__(self): super().__init__() # 定义层，128、64、每层 10 个单元 self.fc1 = nn.Linear(784, 128) self.fc2 = nn.Linear(128, 64) # 输出层，直接预测图像标签索引 self.fc3 = nn.Linear(64, 1) def forward(self, x): &#39;&#39;&#39; 前向通过网络，返回输出 logits &#39;&#39;&#39; x = self.fc1(x) x = F.relu(x) x = self.fc2(x) x = F.relu(x) x = self.fc3(x) return x model = Network() criterion = lambda x, y: torch.mean((y.view(x.shape) - x) ** 2) #criterion = nn.NLLLoss()     提交人    /u/SmallTimeCSGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eez08i/help_me_understand_the_math_simple_question_about/</guid>
      <pubDate>Mon, 29 Jul 2024 13:04:34 GMT</pubDate>
    </item>
    <item>
      <title>我正在制作一个关于 GPU 编程的系列文章 — — 现在推出了一个用纯 GPU 代码创建神经网络的新剧集！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eeyzu8/im_making_a_series_on_gpu_programming_a_new/</link>
      <description><![CDATA[https://youtu.be/Iyfuu64A0MM?si=EKJsglPm28NQwiHM    由   提交  /u/Fun-Department-7879   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eeyzu8/im_making_a_series_on_gpu_programming_a_new/</guid>
      <pubDate>Mon, 29 Jul 2024 13:04:06 GMT</pubDate>
    </item>
    <item>
      <title>配备 4060 和 4070 的笔记本电脑，性能有明显差异吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eexwf5/laptop_with_4060_vs_4070_noticeable_performance/</link>
      <description><![CDATA[我主要训练一些较小的模型，我想知道从 4060 到 4070 的价格跳跃是否值得。    提交人    /u/Lumpy-Permission-736   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eexwf5/laptop_with_4060_vs_4070_noticeable_performance/</guid>
      <pubDate>Mon, 29 Jul 2024 12:10:21 GMT</pubDate>
    </item>
    <item>
      <title>ML 基本查询</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eex483/ml_basic_query/</link>
      <description><![CDATA[假设我们已经有两个独立的测试集和训练集，请问一个简单的问题。在训练模型之后，在使用模型进行预测之前，我们是否还会更改测试集，例如应用 onehotencoding、特征缩放等    提交人    /u/Dapper_Leek1101   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eex483/ml_basic_query/</guid>
      <pubDate>Mon, 29 Jul 2024 11:28:36 GMT</pubDate>
    </item>
    <item>
      <title>为机器学习构建 PC</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eewovl/build_pc_for_ml/</link>
      <description><![CDATA[我计划构建一台主要用于运行狭窄、特定的机器学习任务的电脑，我想就我选择的组件获得一些反馈，以确保兼容性和充分性。以下是规格：  主板： Gigabyte B450M DS3H WiFi MicroATX 主板插槽 AM4 DDR4 CPU： AMD 5000 系列 Ryzen 5 5500 台式机处理器 6 核 12 线程 19 MB 缓存 3.6 GHz 最高 4.2 GHz 插槽 AM4 500 系列芯片组 GPU： GIGABYTE NVIDIA GeForce RTX 3060 WINDFORCE OC 12GB GDDR6 PCIe x16 显卡 RAM： Corsair Vengeance LPX 16GB (1x16GB) DDR4 3200MHz UDIMM C16 台式机 RAM 内存模块 存储： Crucial P3 500GB PCIe 3.0 3D NAND NVMe M.2 SSD，高达 3500MB/s PSU：Cooler Master MWE 550 Bronze V2 电源 - 非模块化 | 80 Plus Bronze 认证 | 120mm HDB 风扇 | DC-DC 电路设计 | ATX 2.52 版本 | 550 瓦 机箱：Ant Esports ICE-100 中塔式电脑机箱/游戏柜 - 黑色 | 支持 ATX、Micro-ATX、Mini-ITX | 预装 2 x 140mm 前置风扇和 1 x 140 mm 后置风扇     提交人    /u/scanatreddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eewovl/build_pc_for_ml/</guid>
      <pubDate>Mon, 29 Jul 2024 11:03:51 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习的实际实现/编码的最佳资源是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eevle5/what_are_the_best_resources_to_learn_practical/</link>
      <description><![CDATA[  由    /u/Successful-Energy-80  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eevle5/what_are_the_best_resources_to_learn_practical/</guid>
      <pubDate>Mon, 29 Jul 2024 09:54:52 GMT</pubDate>
    </item>
    <item>
      <title>转换型理学硕士课程是否值得您尝试进入该行业？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eevcn3/are_conversion_msc_programs_worth_it_for_trying/</link>
      <description><![CDATA[我是一名英语学士毕业生，有一点计算机科学和数学背景（在转专业之前读了一年理学学士学位，并用 Java 做过项目）。 看看世界的发展方向，我觉得看看我是否可以通过转换硕士学位重返该领域会很有趣，比如计算机科学硕士、人工智能和伦理学硕士或数字政治硕士。 对于具有语言学/哲学背景的人来说，进入转换硕士学位以进入该行业是否有可能？（并希望在此过程中赚到很多钱） 你们中有人与拥有 BA 或 BFA 学位并通过理学硕士转换为 STEM 的人一起工作吗？    提交人    /u/bhadrasub   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eevcn3/are_conversion_msc_programs_worth_it_for_trying/</guid>
      <pubDate>Mon, 29 Jul 2024 09:38:01 GMT</pubDate>
    </item>
    <item>
      <title>有哪些好的免费资源可以学习 NLP？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eeuf7b/what_are_some_good_free_resources_to_learn_nlp/</link>
      <description><![CDATA[  由    /u/xayushman  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eeuf7b/what_are_some_good_free_resources_to_learn_nlp/</guid>
      <pubDate>Mon, 29 Jul 2024 08:32:38 GMT</pubDate>
    </item>
    <item>
      <title>以下是 ICLR（'23、'24）、ICML（'23）、NeurIPS（'23）的所有论文列表</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eeueny/heres_a_list_of_all_papers_from_iclr_23_24_icml/</link>
      <description><![CDATA[Google 表格：链接 Excel 文件：链接  我编制了一份包含 ICLR、ICML 和 NeurIPS 会议所有论文的电子表格。它仅包含 2023 年的数据（ICLR 为 2024 年）。认为它对其他人也可能有用。 包含以下列（标题、作者、摘要和会议始终填写，其他不填写）：   标题 作者 摘要 会议 pdf 海报 幻灯片 OpenReview JMLR       提交人    /u/New-Path5262   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eeueny/heres_a_list_of_all_papers_from_iclr_23_24_icml/</guid>
      <pubDate>Mon, 29 Jul 2024 08:31:29 GMT</pubDate>
    </item>
    <item>
      <title>掌握机器和深度学习背后的数学需要多少微积分？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eendj5/how_much_calculus_is_needed_for_mastering_the/</link>
      <description><![CDATA[例如计算 1、2、3、4、5 或多变量、差异方程等，    提交人    /u/StellaarMonkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eendj5/how_much_calculus_is_needed_for_mastering_the/</guid>
      <pubDate>Mon, 29 Jul 2024 01:29:10 GMT</pubDate>
    </item>
    <item>
      <title>Julia 中的神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eed4nh/neural_nets_from_scratch_in_julia/</link>
      <description><![CDATA[我最近完成了一个名为Julia 中的 Scratch 神经网络的视频教程系列（受到 Andrej Karpathy、Sentdex 和 George 的类似 Python 项目的启发Hotz)。 我个人很喜欢这种学习方式，并发现从头开始构建某些东西是了解其工作原理的最佳方式。我希望本系列视频对喜欢这种方式学习的人来说既有用又有趣。该视频系列还附带一个我制作的 Julia 包——基本上视频展示了如何从头开始构建这个包。 如果您有兴趣，请查看！🙂    提交人    /u/mike20731   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eed4nh/neural_nets_from_scratch_in_julia/</guid>
      <pubDate>Sun, 28 Jul 2024 17:44:58 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>