<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 21 Jun 2024 21:15:05 GMT</lastBuildDate>
    <item>
      <title>Q*：利用深思熟虑的规划提高法学硕士的多步骤推理能力</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dldn8n/q_improving_multistep_reasoning_for_llms_with/</link>
      <description><![CDATA[  由    /u/marcelmarais  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dldn8n/q_improving_multistep_reasoning_for_llms_with/</guid>
      <pubDate>Fri, 21 Jun 2024 20:21:43 GMT</pubDate>
    </item>
    <item>
      <title>UNet 图像分割训练高阶时的 nan 损失</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlcxal/nan_loss_at_high_epochs_for_unet_image/</link>
      <description><![CDATA[      https://preview.redd.it/d3snu8s8bz7d1.png?width=1654&amp;format=png&amp;auto=webp&amp;s=51c56a411f78abc0080277e1f6324227c71934ac 你好， 我正在训练 UNet 进行图像分割，我听说进行“健全性检查”是有好处的仅在一个批次上进行训练以确保其过度拟合。 我这样做了，直到第 200 个时期，损失一直在持续减少。然后它开始上下波动，最后在第 229 个时期变为 nan 并保持这种状态。 这是一个问题吗？我不打算在整个数据集上训练模型超过 10-15 个时期，因为我有很多数据。如果这是一个问题，为什么，可能是什么问题？ 谢谢！    提交人    /u/Mysterious_Curve8635   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlcxal/nan_loss_at_high_epochs_for_unet_image/</guid>
      <pubDate>Fri, 21 Jun 2024 19:50:40 GMT</pubDate>
    </item>
    <item>
      <title>根本原因分析数据集 | 预测性维护 - 工业机械</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlct3c/dataset_for_root_cause_analysis_predictive/</link>
      <description><![CDATA[大家好，作为 SE 本科生最后一年的团队，我们计划开发一个工业机械的预测性维护系统。目前，我们在 Kaggle 上找到了一些数据集来训练故障预测模型（包含一些特定的故障类型），但对于另一个目标，即帮助利益相关者对系统预测的特定异常进行根本原因分析，我们没有足够的数据来训练模型。早期的数据集不包含任何与推进根本原因分析过程相关的内容。我在网上搜索，但找不到合适的数据集。 我目前看到的唯一选择是访问一家制造公司，并手动收集以前的故障数据以及维护记录及其根本原因详细信息，其中还包括每个故障的相关传感器数据。然后我必须创建自己的数据集，但这是一个非常困难和复杂的过程。 如果有人可以指导我从某个地方找到合适的数据集，或者如果您有任何联系人可以帮助我收集与特定机器过去维护相关的此类数据收集，我将不胜感激。 谢谢！    提交人    /u/Medium-Section-1075   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlct3c/dataset_for_root_cause_analysis_predictive/</guid>
      <pubDate>Fri, 21 Jun 2024 19:45:41 GMT</pubDate>
    </item>
    <item>
      <title>利用 NLP/预训练模型进行文档比较和偏差检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlbegh/leveraging_nlppretrained_models_for_document/</link>
      <description><![CDATA[我们如何利用 NLP 模型或生成式 AI 预训练模型（如 ChatGPT 或 Llama2）来比较两个文档（如法律合同或技术手册）并找出文档中的偏差。 请给我一些想法或方法来实现这一点，或者如果您有任何 Youtube/Github 链接可供参考。 谢谢    提交人    /u/DataaWolff   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlbegh/leveraging_nlppretrained_models_for_document/</guid>
      <pubDate>Fri, 21 Jun 2024 18:45:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kafka、Airflow 和 SageMaker 构建多模式数据处理管道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlanj4/building_a_multimodal_data_processing_pipeline/</link>
      <description><![CDATA[       由    /u/mixpeek  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlanj4/building_a_multimodal_data_processing_pipeline/</guid>
      <pubDate>Fri, 21 Jun 2024 18:14:12 GMT</pubDate>
    </item>
    <item>
      <title>寻找使用神经网络进行曲线拟合以近似宇宙积分的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dla91f/looking_for_resources_on_using_neural_networks/</link>
      <description><![CDATA[嗨， 我目前正在研究宇宙学中的一个问题，我需要解决一个没有解析解的积分。我不想使用数值方法，而是想训练一个神经网络来更快地逼近解。 我最初的想法是使用曲线拟合神经网络来完成这项任务。但是，我对这个领域还比较陌生，如果能推荐一些可以帮助我入门的资源，我将不胜感激。具体来说，我正在寻找：  YouTube 视频：解释如何使用神经网络进行曲线拟合和函数逼近的教程或讲座。 研究论文：讨论神经网络在物理学或宇宙学中的类似应用的研究或文章。 书籍：涵盖用于函数逼近的神经网络理论和实践方面的综合文本。  任何指导或建议都将不胜感激！ 提前感谢您的帮助！寻找有关使用神经网络进行曲线拟合以近似宇宙积分的资源    提交人    /u/Valery__Legasov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dla91f/looking_for_resources_on_using_neural_networks/</guid>
      <pubDate>Fri, 21 Jun 2024 17:58:04 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.5 Sonnet：速度、价格和多功能性无可比拟的终极 AI 创新</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dla7ex/claude_35_sonnet_the_ultimate_ai_innovation_for/</link>
      <description><![CDATA[    /u/Independent-Loan-854   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dla7ex/claude_35_sonnet_the_ultimate_ai_innovation_for/</guid>
      <pubDate>Fri, 21 Jun 2024 17:56:03 GMT</pubDate>
    </item>
    <item>
      <title>如何理解任何数学公式</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dl9pch/how_to_understand_any_math_formula/</link>
      <description><![CDATA[        提交人    /u/research_pie   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dl9pch/how_to_understand_any_math_formula/</guid>
      <pubDate>Fri, 21 Jun 2024 17:34:41 GMT</pubDate>
    </item>
    <item>
      <title>新 Python 书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dl9imd/new_python_book/</link>
      <description><![CDATA[你好 Reddit！ 我写了一本 Python 书，名为“精通 Python 之旅”。在我看来，我试图涵盖成为一名 Python 工程师所需的一切！你能看看并给我一些反馈吗？我将不胜感激！ 如果你觉得它有趣且有用，请点个星！ https://github.com/pro1code1hack/Your-Journey-To-Fluent-Python 非常感谢，期待您的评论！    提交人    /u/pro1code1hack   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dl9imd/new_python_book/</guid>
      <pubDate>Fri, 21 Jun 2024 17:26:39 GMT</pubDate>
    </item>
    <item>
      <title>什么是特征向量？：线性代数中基本概念之一的 5 分钟视觉指南。🧠</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dl8hq5/what_is_an_eigenvector_a_5minute_visual_guide_to/</link>
      <description><![CDATA[      TL;DR：矩阵 A 的特征向量 x 是与 A 相乘时方向不变的向量。 特征向量是机器学习和数据科学中许多先进技术的基石。特征向量是降维技术、数据转换和特征提取的核心。 它们在著名的页面排名算法中得到了应用，最初的 Google 搜索就是基于该算法。Netflix 的推荐系统也将其作为协同过滤和向用户推荐相关电影的核心。 什么是特征向量？：视觉指南。    提交人    /u/ml_a_day   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dl8hq5/what_is_an_eigenvector_a_5minute_visual_guide_to/</guid>
      <pubDate>Fri, 21 Jun 2024 16:43:26 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek Coder V2：在编码和数学方面可与 ChatGPT-4o 相媲美的开源模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dl3i9l/deepseek_coder_v2_an_opensource_model_rivaling/</link>
      <description><![CDATA[  由    /u/Independent-Loan-854  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dl3i9l/deepseek_coder_v2_an_opensource_model_rivaling/</guid>
      <pubDate>Fri, 21 Jun 2024 13:03:15 GMT</pubDate>
    </item>
    <item>
      <title>AIQ（人工智能商数）今日推出，旨在帮助解决一般的机器学习查询</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dl1tqv/aiq_artificial_intelligence_quotient_launched/</link>
      <description><![CDATA[大家好，我很高兴与大家分享，我今天推出了我的技术播客 AIQ（人工智能商数），我们将在其中讨论数据科学和人工智能领域的常见主题。第一集“数学是数据科学的障碍吗”现已推出，回答了我在社交媒体平台上收到的一些有关机器学习数学的问题。请在下面的 AIQ 中注释掉您希望我们涵盖的任何主题😊 https://youtu.be/Qj_hlIRZiJg?si=lQJ4O_XSXooRr75G    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dl1tqv/aiq_artificial_intelligence_quotient_launched/</guid>
      <pubDate>Fri, 21 Jun 2024 11:33:33 GMT</pubDate>
    </item>
    <item>
      <title>Bert 嵌入速度慢</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dky2ns/bert_embeddings_slow/</link>
      <description><![CDATA[      嗨，我正在尝试获取 Bert-embedding 中 df 的列（3963683 行），但估计需要 155 天。有人能帮帮我吗。我的代码有问题吗？我在 colab A100 GPU 40 GB 上尝试过，（我还使用了 %load_ext cudf.pandas）。[这只是我的完整数据集的一部分，实际数据集是 45 GB]。有什么建议如何处理它吗：）以及理想情况下需要多长时间谢谢！！    提交人    /u/Euphoric_Traffic2993   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dky2ns/bert_embeddings_slow/</guid>
      <pubDate>Fri, 21 Jun 2024 07:16:44 GMT</pubDate>
    </item>
    <item>
      <title>这取决于你如何看待资本主义，无论是积极的还是消极的</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dkwc2t/this_is_either_positive_or_negative_depending_on/</link>
      <description><![CDATA[        提交人    /u/blablablabling   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dkwc2t/this_is_either_positive_or_negative_depending_on/</guid>
      <pubDate>Fri, 21 Jun 2024 05:23:04 GMT</pubDate>
    </item>
    <item>
      <title>在 keras 中构建您的第一个自动编码器！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dkt5i8/build_your_first_autoencoder_in_keras/</link>
      <description><![CDATA[        提交人    /u/Just-Indication35   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dkt5i8/build_your_first_autoencoder_in_keras/</guid>
      <pubDate>Fri, 21 Jun 2024 02:22:47 GMT</pubDate>
    </item>
    </channel>
</rss>