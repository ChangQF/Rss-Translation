<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 26 Jul 2024 12:27:45 GMT</lastBuildDate>
    <item>
      <title>贝叶斯优化：为什么 AUC-ROC 会出现天花板效应而敏感度却不会？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecm3n8/bayesian_optimisation_why_does_aucroc_show_a/</link>
      <description><![CDATA[      我执行了贝叶斯优化来调整 XGBoost 分类模型的超参数。尽管进行了多次迭代（30、60、100、200），AUC-ROC 指标始终表现出天花板效应，如下图所示。 https://preview.redd.it/qf9l47hxpued1.png?width=794&amp;format=png&amp;auto=webp&amp;s=eb45974488818f7f1ea19d0bda7f9a498828aa3e 有人能解释一下为什么 AUC-ROC 指标显示天花板效应，而敏感度指标没有？    提交人    /u/Dobra_Vila   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecm3n8/bayesian_optimisation_why_does_aucroc_show_a/</guid>
      <pubDate>Fri, 26 Jul 2024 11:49:02 GMT</pubDate>
    </item>
    <item>
      <title>将句子与列表中的另一个句子进行匹配的模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecly6n/a_model_to_match_the_sentence_to_another_from_a/</link>
      <description><![CDATA[您好， 我需要创建一个模型，将一个文件中的句子与另一个文件中的句子进行匹配。例如，如果文件中的句子是“我们需要更换 2 楼的门”。则模型应该能够选择含义最接近的句子，例如“需要更换一扇门”。我需要什么样的模型来执行这样的任务？    提交人    /u/NefariousnessFar7176   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecly6n/a_model_to_match_the_sentence_to_another_from_a/</guid>
      <pubDate>Fri, 26 Jul 2024 11:40:40 GMT</pubDate>
    </item>
    <item>
      <title>[T5] [HuggingFace] 如何控制生成摘要的长度</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecll3g/t5_huggingface_how_to_control_the_lenth_of_the/</link>
      <description><![CDATA[大家好，在对 T5 模型进行微调后，我编写了一个用于推理的脚本： def generate_summary(text, max_length, creativity): input= tokenizer(text= text, return_tensors= &quot;pt&quot;, truncation= True, padding= True, max_length= 1024).to(parameters.device) output= model.generate( **inputs, max_length= max_length,temperature= creativity,num_beams= 4, no_repeat_ngram_size= 2, early_stopping= True, do_sample= True ) summary= tokenizer.decode(outputs[0], skip_special_tokens= True) return summary  在 generate_summary 方法中，我解析了三个参数：用于输入上下文的 text、用于确定性控制的temperature和用于输出长度控制。但是，我注意到，虽然温度运行良好，但 max_length 却不行，当达到最大长度时，它只会切断（截断）文本。 我在这里做错了什么吗？目标是告诉模型在预设长度内生成输出。 仅供参考，在微调过程中，我创建了一个自定义数据集方法： # 加载和处理数据集 class CustomDataset(Dataset): def __init__(self, data, context_max_length, summary_max_length): #self.data = data self.context_max_length= context_max_length self.summary_max_length= summary_max_length self.tokenizer= AutoTokenizer.from_pretrained(pretrained_model_name_or_path= parameters.model_name, cache_dir= parameters.model_cache_dir) self.data= [ item for item in data if len(self.tokenizer.encode(item[&quot;context&quot;]))&lt;= self.context_max_length and len(self.tokenizer.encode(item[&quot;summary&quot;]))&lt;= self.summary_max_length ] def __len__(self): return len(self.data) def __getitem__(self, idx): #context_token= self.tokenizer.encode(self.data[idx][&quot;context&quot;]) #summary_token= self.tokenizer.encode(self.data[idx][&quot;summary&quot;]) context_encodings= self.tokenizer( self.data[idx][&quot;context&quot;], max_length= self.context_max_length, padding= &quot;max_length&quot;, truncation= True, return_tensors= &quot;pt&quot; ) summary_encodings= self.tokenizer( self.data[idx][&quot;summary&quot;], max_length= self.summary_max_length, padding= &quot;max_length&quot;, truncation= True, return_tensors= &quot;pt&quot; ) return { &#39;input_ids&#39;: context_encodings[&quot;input_ids&quot;].squeeze(), &#39;labels&#39;: summary_encodings[&quot;input_ids&quot;].squeeze(), &quot;attention_mask&quot;: context_encodings[&quot;attention_mask&quot;].squeeze() } print(&quot;加载数据集&quot;) train_dataset= load_from_disk(f&quot;{parameters.datasets_cache_dir}/big_sum_dataset/train&quot;) validation_dataset= load_from_disk(f&quot;{parameters.datasets_cache_dir}/big_sum_dataset/validation&quot;) tokenized_train_dataset= CustomDataset(data= train_dataset, context_max_length= 1024, summary_max_length= 512) tokenized_validation_dataset= CustomDataset(data= validation_dataset, context_max_length= 1024, summary_max_length= 512)  这里我对数据集做了一些预处理：  我过滤掉了所有不满足预设长度的实例 我将输入上下文的长度填充为 1024，将输出摘要的长度填充为 512。  我不知道这个自定义数据集是否意​​味着模型不能生成可变长度的输出。 谢谢。    由    /u/Q_H_Chu 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecll3g/t5_huggingface_how_to_control_the_lenth_of_the/</guid>
      <pubDate>Fri, 26 Jul 2024 11:20:30 GMT</pubDate>
    </item>
    <item>
      <title>帮助本地设置 pytorch</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecklkn/help_in_setting_pytorch_locally/</link>
      <description><![CDATA[正如标题所说，我大部分工作都是在 colab 笔记本中完成的，因为我的笔记本电脑没有 GPU。最近，我购买了一台配备 Nvidia GeForce RTX 3050 GPU 的笔记本电脑。 因此，我尝试从预先训练的 hf 模型制作聊天机器人应用程序，然后我首先在 colab 上运行该模型，它运行良好👍。但现在我的下一步是在本地运行它。 经过一番研究，我首先下载了 cuda 12.1，然后下载了 cdn（12.x）并进行了复制粘贴。现在我设置了 conda 环境并安装了我的需求。  pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121 但运行后，我只从第一行收到错误，即 import torch 和错误，它说是操作系统错误 Window 126，错误 fbgemm.dll 或其依赖项丢失。所以我检查了路径文件，这个 dll 就在那里。 我该如何解决这个问题？    提交人    /u/ArugulaCrafty9236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecklkn/help_in_setting_pytorch_locally/</guid>
      <pubDate>Fri, 26 Jul 2024 10:19:29 GMT</pubDate>
    </item>
    <item>
      <title>“神经网络是通用函数逼近器”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eck5u8/neural_networks_are_universal_function/</link>
      <description><![CDATA[      当我们使用神经网络时，我们正在构建一个从输入映射到输出的函数。 神经网络的真正威力在于它们充当函数近似的能力。如果你能理解为什么，这意味着你对神经网络和激活函数的必要性了解很多。 通用近似定理指出，具有单个隐藏层和有限数量节点的前馈神经网络可以以任何精度近似任何连续函数。唯一的限制是，对于给定的神经网络权重和偏差，输入值的范围是固定的。 你如何真正理解通用近似定理？ 取一个连续非线性函数 f(x)=x^3-3x^2+2x+5 然后考虑 ReLU 激活函数。 ReLU(x)=max(0,x) 我们可以构造 5 种 ReLU 变体。当我们将 ReLU 或 x 乘以一个常数时，我们会缩放斜率。当我们将一个常数添加到 x 时（例如 ReLU(x+a)），我们会将 ReLU 的转换点移动 -a。  1) y1 =-5ReLU(x) 2) y2 = 5ReLU(x+1) 3) y3 = 5ReLU(x-2) 4) y4 = 15ReLU(x-3)  5) y5 = -20ReLU(-x-1) 现在，如果您将这 5 个函数相加并绘制出来，您将看到 f(x) ~ y1 + y2 + y3 + y4 + y5。 我们可以将这 5 个 ReLU 函数表示为只有一个输入节点和 1 个包含 5 个节点的隐藏层的神经网络。  https://preview.redd.it/lyp5kslt4ued1.png?width=1098&amp;format=png&amp;auto=webp&amp;s=172a9cd84a65ba5091be3181e8c09df62395647e 从输入到隐藏层的权重矩阵为 W1=[1,1,1,1,-1]  到隐藏层节点的偏置矩阵为B1=[0,1,-2,-3,-1] 从隐藏层到输出层的权重矩阵为 W2=[-5,5,5,15,-20] 从隐藏层到输出层的偏差矩阵为 B2=[0,0,0,0,0] 您可能已经注意到，如果我们将函数分为 100 个 ReLU 函数的总和，则隐藏层中将有 100 个节点，并且函数 f(x)=x^3-3x^2+2x+5 将可以通过 ReLU 很好地近似。  这不是通用近似定理的正式证明，而只是一个说明性演示。  我已经发表了一整篇关于此的讲座。我认为您会喜欢它，因为我们将向您展示如何构建这些 ReLU 函数并使用名为 Desmos 的工具绘制它们。在此处查看讲座：https://www.youtube.com/watch?v=SQeZ2FONQEw&amp;feature=youtu.be    提交人    /u/thesreedath   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eck5u8/neural_networks_are_universal_function/</guid>
      <pubDate>Fri, 26 Jul 2024 09:51:10 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的成本函数不是凸的？并且影响另一个</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eck3p6/cost_function_of_logistic_regression_isnt_convex/</link>
      <description><![CDATA[      为什么他们说逻辑回归是凸的，但似乎不是，它延伸到了其他部分，并相互影响，请参考所附的成本函数图 如果 y 为 1，则成本函数将为 -log(yhat) 如果 y 为 0，则成本函数将为 -log(1-yhat) 两者都会趋向于自己的最小值 一个成本的权重更新不会影响其他成本吗，例如，如果 y=1，它会尝试更新权重，使预测（yhat）接近 1 但是，如果调整权重以使 yhat 接近 1，那么其他成本函数（y=0）不会受到严重惩罚吗，因为它预计 yhat 会接近于零？ 您能解释一下逻辑回归的成本函数吗？ 为什么在那里使用 Sigmoid 函数？为什么他们说如果 Sigmoid 函数的输出 &gt;= 阈值 (0.5)，我们就会预测 1？ 提前致谢  图片来源 https://towardsdatascience.com/logistic-regression-and-decision-boundary-eab6e00c1e8    提交人    /u/ajihkrish   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eck3p6/cost_function_of_logistic_regression_isnt_convex/</guid>
      <pubDate>Fri, 26 Jul 2024 09:47:07 GMT</pubDate>
    </item>
    <item>
      <title>双编码器与交叉编码器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecisvl/biencoder_vs_crossencoder/</link>
      <description><![CDATA[大家好， 目前我正在学习编码器，我发现有两种常用类型：双编码器和交叉编码器（https://www.sbert.net/examples/applications/cross-encoder/README.html）。 我仍然有点难以理解。双编码器（基于 BERT）每次仅接收一个句子作为输入，然后计算相应的嵌入。另一方面，交叉编码器总是采用两个句子，然后计算一个公共嵌入，然后是分类层以生成 0 到 1 之间的值。 我读到过 BERT 只能进行自我注意，但我经常读到在交叉编码器设置中，两个输入句子被连接起来，然后使用交叉注意，但 BERT 中不存在交叉注意，因为它是一个仅编码器模型，对吗？ 那么，BERT 究竟如何处理这个问题？BERT 最多可以接受两个输入，然后看起来像这样“[CLS] 句子 1 [SEP] 句子 2”。在这种情况下，这已经被称为“交叉编码器”了吗？那么这后面是否只会跟着一个分类头？ 另一方面，在双编码器设置中，来自 BERT 的输入将如下所示：“[CLS] 句子 [SEP]”？然后将对这个句子应用自注意力多次，最后返回一个嵌入？ 一个输入和两个输入之间到底有什么区别？什么时候 BERT 是双编码器，什么时候是交叉编码器？当 BERT 仅接收一个输入（双编码器）时的行为与同时接收两个输入（交叉编码器）时的行为是否不同？BERT 交叉编码器只是普通的 BERT 模型 + 分类头吗？BERT 在给定两个输入时会执行交叉注意，而在仅给定一个输入时会执行正常的自注意力吗？我很困惑。 我希望你能理解我的问题，并提前非常感谢你！    提交人    /u/Ok-Bedroom2108   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecisvl/biencoder_vs_crossencoder/</guid>
      <pubDate>Fri, 26 Jul 2024 08:15:28 GMT</pubDate>
    </item>
    <item>
      <title>如果您即将购买任何月度订阅，那么有个好消息要告诉您。截止 2024 年 8 月 9 日，Coursera Plus 订阅可享受 50% 的折扣。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecin18/if_you_are_about_to_purchase_any_monthly/</link>
      <description><![CDATA[  由    /u/eham2017  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecin18/if_you_are_about_to_purchase_any_monthly/</guid>
      <pubDate>Fri, 26 Jul 2024 08:04:17 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习的绝佳资源！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eci5aw/great_resource_for_learning_ml/</link>
      <description><![CDATA[我偶然发现了微软为任何对机器学习感兴趣的人提供的免费课程。  描述机器学习的核心概念 识别不同类型的机器学习 描述训练和评估机器学习模型的注意事项 描述深度学习的核心概念 在 Azure 机器学习服务中使用自动化机器学习  它涵盖以下主题，并通过注释和示例详细讲授回归、分类和聚类 非常适合初学者 最后还提供了可共享的证书 在这里查看 https://learn.microsoft.com/training/modules/fundamentals-machine-learning/?wt.mc\_id=studentamb\_395038    由   提交  /u/Strange-Slide-5300   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eci5aw/great_resource_for_learning_ml/</guid>
      <pubDate>Fri, 26 Jul 2024 07:30:11 GMT</pubDate>
    </item>
    <item>
      <title>特征数量对选择更佳性能的模型的影响</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecgwiq/effect_of_number_of_features_on_the_choice_of/</link>
      <description><![CDATA[给定特征的数量（假设为 n），我无法理解哪种方法（灵活或不灵活）会提供更好的性能。  假设 n 很小，我应该使用线性回归（不灵活）还是随机森林、SVM（灵活）来实现更好的性能？     提交人    /u/tatv_047   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecgwiq/effect_of_number_of_features_on_the_choice_of/</guid>
      <pubDate>Fri, 26 Jul 2024 06:08:33 GMT</pubDate>
    </item>
    <item>
      <title>我可以成为一名拥有商业学位的数据分析师吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecf8t4/can_i_be_a_data_analyst_with_a_busines_degree/</link>
      <description><![CDATA[我很快就要上大学了。我计划攻读商业分析学士学位。我可以在获得学士学位后继续攻读数据科学或人工智能，或者攻读数据科学或人工智能硕士学位吗？\    提交人    /u/JuliusSeizure75   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecf8t4/can_i_be_a_data_analyst_with_a_busines_degree/</guid>
      <pubDate>Fri, 26 Jul 2024 04:27:13 GMT</pubDate>
    </item>
    <item>
      <title>有没有老师以与阿卜杜勒·巴里教授算法相同的方式教授机器学习概念？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ecdzqk/any_teacher_who_teaches_ml_concepts_in_the_same/</link>
      <description><![CDATA[  由    /u/-AnujMishra  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ecdzqk/any_teacher_who_teaches_ml_concepts_in_the_same/</guid>
      <pubDate>Fri, 26 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>寻求合适的模型和建议！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ec2fek/seeking_appropriate_model_and_advice/</link>
      <description><![CDATA[      您好！ 我对机器学习完全陌生，正在寻求指导。我一直在用 Python 开发一个基于 GUI 的应用程序，它可以接受用户输入并在 MRI 扫描中自动定义人脑区域。具体来说，手动测量的研究人员会坐在电脑前，拖动鼠标来测量 MRI 扫描的区域。虽然其中一些区域有自动化程序，但专家的手动测量仍然是该领域的黄金标准。到目前为止，我的应用程序已将时间/劳动力减少了约 90%，并且准确率通常超过 90%。我 9 个月前开始学习 Python，这是一个很棒的项目，我很满意！ 但是，现在我想进一步推动自动化方面。当我开始时，每次测量都是通过按住并拖动屏幕上所需区域的光标来手动完成的。现在我使用 Python 结合手动和半自动化工具，这些工具由用户的点击控制。这很好。我点击两次，看着鬼魂测量所需的区域。如果可能的话，我真的很想消除这些点击...... https://preview.redd.it/wb2dwx12mped1.jpg?width=712&amp;format=pjpg&amp;auto=webp&amp;s=f1cb1d95a538fbfe27ac53b2cf047bdcd2f47685 在这张图片中，我会点击四次，或者每侧点击两次，在同一张图像上渲染两个单独的测量值。用油漆编辑的库存图片，请原谅我的懒惰。 作为新手，我觉得我已经浏览了几个星期有关这个主题的视频和资源，但似乎找不到我想要的东西。我想我会对红色圆圈附近或内部的建议坐标对感到满意。我不会浏览所有的想法，而是直接问。我在寻找什么？什么类型的模型适合这项工作？这样的东西已经存在了吗？是否有可用的框架可能适用？ 感谢您的任何建议！    提交人    /u/Deeper_Sided   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ec2fek/seeking_appropriate_model_and_advice/</guid>
      <pubDate>Thu, 25 Jul 2024 18:39:43 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉工作表 - SOTA CNN p1</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ebt963/computer_vision_worksheets_sota_cnn_p1/</link>
      <description><![CDATA[        提交人    /u/basia25   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ebt963/computer_vision_worksheets_sota_cnn_p1/</guid>
      <pubDate>Thu, 25 Jul 2024 12:08:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>