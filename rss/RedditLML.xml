<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 28 Jun 2024 06:21:09 GMT</lastBuildDate>
    <item>
      <title>2024 年 10 门最佳高级机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqclj4/10_best_advanced_machine_learning_courses_in_2024/</link>
      <description><![CDATA[您是否在寻找最佳高级机器学习课程？ 如果是，那么本文适合您。 在本文中，您将找到10 个最佳高级机器学习课程。 祝你好运！    提交人    /u/Some-Patient-7191   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqclj4/10_best_advanced_machine_learning_courses_in_2024/</guid>
      <pubDate>Fri, 28 Jun 2024 05:58:39 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊 ML 2024 年夏季</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqceja/amazon_ml_summer_2024/</link>
      <description><![CDATA[有人收到选拔邮件了吗？     提交人    /u/Time_Max22   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqceja/amazon_ml_summer_2024/</guid>
      <pubDate>Fri, 28 Jun 2024 05:46:15 GMT</pubDate>
    </item>
    <item>
      <title>加速包中是否有一种方法可以将模型分布在多个 GPU 上，而无需将整个模型复制到每个 GPU？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqbycg/is_there_a_method_in_the_accelerate_package_for/</link>
      <description><![CDATA[我试图了解加速包。  https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db 这就是我所阅读的内容，但此代码实际上将整个模型加载到每个 GPU 上。 就我而言，我正在尝试执行 PPO，因此我想分发我的语言模型（例如 LLaMA 3）以及奖励模型，并使用多个 GPU 进行训练。该模型无法加载到单个 GPU 上。这种情况下我们需要用什么代码呢？ 我的模型加载（目前的代码）如下： model = AutoModelForCausalLMWithValueHead.from_pretrained( config.model_name, load_in_8bit=load_in_8bit, peft_config=peft_config, ) rw_model = RewardModel(sft_model = sft_model, base_model= base_model, lora=peft, peft_config=peft_config) state_dict = load_file(f&#39;{reward_model}/model.safetensors&#39;) rw_model.load_state_dict(state_dict, strict=False)  accelerate launch --config_file config/deepspeed_config/ds_config_ppo_v1.yaml train_ppo_revise_1823.py --config config/ppo_config/config_ppo.py  这种情况下，我该怎么办？  我使用的是 A100*8（40GB）。     submitted by    /u/cpaiml   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqbycg/is_there_a_method_in_the_accelerate_package_for/</guid>
      <pubDate>Fri, 28 Jun 2024 05:17:56 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的未来：2030 年和 2050 年的预测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqbip1/the_future_of_large_language_models_predictions/</link>
      <description><![CDATA[        由    /u/Redvelvet21xo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqbip1/the_future_of_large_language_models_predictions/</guid>
      <pubDate>Fri, 28 Jun 2024 04:51:38 GMT</pubDate>
    </item>
    <item>
      <title>还有其他与 Amazon ML Summer School 或 Tata CodeVita 类似的课程值得学生了解吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqbcob/are_there_any_other_programs_similar_to_amazon_ml/</link>
      <description><![CDATA[  由    /u/These-Cupcake-7984  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqbcob/are_there_any_other_programs_similar_to_amazon_ml/</guid>
      <pubDate>Fri, 28 Jun 2024 04:42:00 GMT</pubDate>
    </item>
    <item>
      <title>PINN 的泛化</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqav6e/generalising_a_pinn/</link>
      <description><![CDATA[我正在做一个关于物理学的神经网络的项目。我已经修改了损失函数以包含我正在建模的方程，并添加了一个实验损失，其中放入了从该方程的论文中获取的一组特定常数的几个数据点。该模型能够为特定的一组常数和相应的数据点生成精确的图表。我如何概括这一点，以便能够为任何一组常数生成该时间范围的图表？我不明白如何计算这种情况下的实验损失。谢谢。     提交人    /u/Machinations_Occur   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqav6e/generalising_a_pinn/</guid>
      <pubDate>Fri, 28 Jun 2024 04:13:37 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么作者在这里平铺/复制数据以增加训练集大小并减少训练周期数吗？我不明白这背后的直觉。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq9wn9/can_someone_explain_why_here_the_author_is/</link>
      <description><![CDATA[      Xt = np.tile(Xn,(1000,1)) Yt= np.tile(Y,(1000,1))  print(Xt.shape, Yt.shape)  此外，如果有人可以解释以下陈述： &quot; 为了进行下一次讨论，您将首先设置我们从之前的训练运行中保存的一些权重，而不是使用您立即获得的权重。这样，这个笔记本就可以随着时间的推移保持对 Tensorflow 变化的稳健性。不同的训练运行可能会产生略有不同的结果，并且当模型具有您将在下面加载的权重时，以下讨论适用。 &quot; 以及下图中的声明和图表： https://preview.redd.it/xq75ilcsd89d1.png?width=1238&amp;format=png&amp;auto=webp&amp;s=f39c10d6ae2838a21b7cfc4c63558b7a09f9b54a 附言：我正在 Coursera 上学习 Andrew NG 的课程。     由    /u/abxd_69 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq9wn9/can_someone_explain_why_here_the_author_is/</guid>
      <pubDate>Fri, 28 Jun 2024 03:22:02 GMT</pubDate>
    </item>
    <item>
      <title>有什么便宜、安全的方法可以在一次性 30 分钟的课程中运行大型 LLM（Nemotron-4-340B-Instruct 或 Command R Plus）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq9tth/whats_a_cheap_secure_way_to_run_huge_llms/</link>
      <description><![CDATA[我需要对一批长文本进行一次性摘要。安全性和准确性意味着一切，所以我正在寻找最大的开源模型。运行这个一次性会话的最便宜方法是什么？如果是 Colab，我应该选择什么计划？    提交人    /u/crosspostmodernist   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq9tth/whats_a_cheap_secure_way_to_run_huge_llms/</guid>
      <pubDate>Fri, 28 Jun 2024 03:17:54 GMT</pubDate>
    </item>
    <item>
      <title>两种情况的所有测试用例均通过。选择的机会？？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq87d3/all_test_cases_passed_for_both_cases_chance_of/</link>
      <description><![CDATA[两个问题的所有测试用例均通过。被选中的几率是多少？    提交人    /u/StreetShoulder5666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq87d3/all_test_cases_passed_for_both_cases_chance_of/</guid>
      <pubDate>Fri, 28 Jun 2024 01:53:01 GMT</pubDate>
    </item>
    <item>
      <title>TinyML —K最近邻（KNN分类器）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq7hu3/tinyml_knearest_neighbors_knnclassifier/</link>
      <description><![CDATA[阅读 Thommaskevin 在 Medium 上撰写的“TinyML —K-Nearest Neighbors (KNN-Classifier)”：https://medium.com/@thommaskevin/tinyml-k-nearest-neighbors-knn-classifier-6008f8e51189    提交人    /u/thommaskevin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq7hu3/tinyml_knearest_neighbors_knnclassifier/</guid>
      <pubDate>Fri, 28 Jun 2024 01:14:08 GMT</pubDate>
    </item>
    <item>
      <title>对数十万张街景图片进行人脸检测/分类（初学者）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq6yyz/face_detectionclassification_on_hundreds_of/</link>
      <description><![CDATA[      大家好！我已经在一个新的艺术项目上工作了一个星期，我来寻求建议，因为我现在正好处于涉及机器学习的部分。首先，解释和背景。该项目包括创建黎巴嫩公共场所中所有政治海报的档案/可视化。两个月前，黎巴嫩的 Google 街景已发布，我想使用这些全景图来检测此类海报的存在（这些海报在该国非常重要，因为它们证实了社区/城镇中宗教社区的存在）。 幸运的是，与行人不同，这些海报上的绝大多数肖像没有被 Google 模糊。我设法构建了项目的一部分，使我能够从任何给定区域恢复（等距矩形）全景图，并将它们拆分为可用的图像。首先，我将从贝鲁特的一个地区开始工作，以免有太多数据。我获得了市中心 30000 张全景图的数量，这对我来说似乎很合理。 现在，我想要一个程序，它可以检测所有这些图像中的人脸，看看海报上是否有人脸，以及是哪个人。这些海报大部分都是著名的政治人物，很少是不太重要的人物，例如士兵肖像。由于全景图包含 GPS 信息，我的目标是将某些肖像在街区、城市甚至整个国家范围内的位置可视化。 我没有任何编码知识，尽管我不得不用一点 Python 从谷歌下载这些图片。我应该从哪里开始？这可能吗？我说的是数十万张图片上的脸部检测和分类，因为每张全景图将被分解成 10 或 12 张图片。因此，例如，贝鲁特市中心的数据集（包含 40k 全景图）将是 40/480 000 张图片。 感谢阅读！我希望这张图片有助于理解  https://preview.redd.it/lhf3xm7bl79d1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=ef895531ddaeade89aa7e2909d3e8297573a0a3b    提交人    /u/laithhhhh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq6yyz/face_detectionclassification_on_hundreds_of/</guid>
      <pubDate>Fri, 28 Jun 2024 00:47:04 GMT</pubDate>
    </item>
    <item>
      <title>每次经历一个时期后，我的损失都会大幅下降。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</link>
      <description><![CDATA[      大家好， 我正在使用 IMDB 数据集对分类任务上的 DistilBERT 模型进行微调。然而，在每个 epoch 之后，我的损失会变得非常低，然后再次开始上升到一个值，并在整个 epoch 中保持这个值。这种行为会重复发生。 我创建了一个 Trainer 类，一个 epoch 的训练循环按以下方式处理： def _train_one_epoch(self, model, trainloader, testloader): &quot;&quot;&quot;训练一个 epoch 的模型。&quot;&quot;&quot; model.train() training_loss = 0.0accumulated_loss = 0.0 total_steps = len(trainloader) // self.gradient_accumulation_steps with tqdm(total=total_steps) as pbar: for i, data in enumerate(trainloader): # 将数据移动到设备 if isinstance(data, list): data = [item.to(self.device) for item in data] elif isinstance(data, dict): data = {key: value.to(self.device) for key, value in data.items()} else: data = data.to(self.device) # 使用 autocast(enabled=self.use_mixed_precision, dtype=torch.float16) 进行前向传递： output = model.train_step(data) loss = output[0] if isinstance(output, tuple) else output loss /= self.gradient_accumulation_steps # 后向传递 if self.use_mixed_precision: self.scaler.scale(loss).backward() else: loss.backward() accumulation_loss += loss.item() * self.gradient_accumulation_steps total_norm = 0.0 for param in model.parameters(): param_norm = param.grad.detach().data.norm(2) total_norm += param_norm.item() ** 2 total_norm = total_norm ** (1. / 2) self._log_metrics({&quot;Total Gradient Norm&quot;: total_norm}) # 更新权重 if (i + 1) % self.gradient_accumulation_steps == 0: if self.use_mixed_precision: self.scaler.unscale_(self.optimizer) if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.scaler.step(self.optimizer) self.scaler.update() else: if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.optimizer.step() self.optimizer.zero_grad() pbar.update(1) if self.scheduler: self.scheduler.step() if self.log: self._log_metrics({&quot;Training Loss&quot;: accumlidar_loss / (i + 1), &quot;Learning Rate&quot;: self.optimizer.param_groups[0][&#39;lr&#39;]}) pbar.set_postfix({&#39;Training Loss&#39;: accumlidar_loss / (i + 1)}) training_loss = accumlidar / len(trainloader) self.optimizer.zero_grad() return training_loss  这种行为每次都会发生，与学习率无关（我也使用调度）。它也发生在诸如问答或对不同数据集（例如 Hyperpartisan）进行分类等任务上。您还可以在 WikihopQA 上训练 QA 任务时看到损失行为。 https://preview.redd.it/zypdq1gzi59d1.png?width=2528&amp;format=png&amp;auto=webp&amp;s=a02d0d67cb4ae2321a364104537ecb981e92e910    提交人    /u/BossBigSword   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</guid>
      <pubDate>Thu, 27 Jun 2024 17:44:47 GMT</pubDate>
    </item>
    <item>
      <title>需要建议 - 两天时间准备 langchain 和 langgraph 的面试</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpwye4/need_advice_two_days_to_prepare_for_an_interview/</link>
      <description><![CDATA[有没有什么快速参考资料可以帮助有经验的人工智能专业人士准备 LangChain 和 LangGraph 的面试？ 非常感谢您的任何意见。谢谢。    提交人    /u/hidimbi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpwye4/need_advice_two_days_to_prepare_for_an_interview/</guid>
      <pubDate>Thu, 27 Jun 2024 17:28:58 GMT</pubDate>
    </item>
    <item>
      <title>从 32 开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</link>
      <description><![CDATA[大家好，我从事 IT 和网络安全工作已有几年了，似乎这个行业不再适合我了，我拥有网络安全理学学士学位，我想看看我是否能够转型。如果需要，我愿意回到学校通过 Coursera 获得硕士学位    提交人    /u/_Darth_Necro_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</guid>
      <pubDate>Thu, 27 Jun 2024 16:14:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>