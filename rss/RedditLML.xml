<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 16 May 2024 01:01:16 GMT</lastBuildDate>
    <item>
      <title>改进/构建一个倾向于一类的图像分类器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct07eu/improving_building_an_image_classifier_that_leans/</link>
      <description><![CDATA[我是一个初学者，并且过度简化了我正在处理的问题。我想建立一个图像分类器来检测狗。我创建了狗和非狗（主要是马）的数据集。该模型经过训练，并且在有效集上表现良好。 现在在野外，我给它说猫或斑马，它有时给出狗，有时给出非狗输出。这是有道理的，因为训练中不包括猫或斑马。然而，我真的很关心狗的反应。  那么，我可以以不同的方式训练模型吗？如果模型呈现的是它从未见过的图像类型，那么它不应该尝试称其为狗。它应该更好地知道狗看起来像什么，如果新的看不见的图像与狗一点都不像，那么就说不是狗。 今天，我正在为这项任务训练 ResNet 变体。感谢您教我。   由   提交 /u/punjipatti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct07eu/improving_building_an_image_classifier_that_leans/</guid>
      <pubDate>Thu, 16 May 2024 00:27:35 GMT</pubDate>
    </item>
    <item>
      <title>线性化大型语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cszun9/linearizing_large_language_models/</link>
      <description><![CDATA[arxiv: https://arxiv.org/abs/2405.06640  推文：https://x.com/sedrickkeh2/status/1790756596102074652  以可扩展的方式将 Mistral 转换为 RNN。以 &lt;10% 的数据击败 RWKV   由   提交 /u/Bubbly-Plankton-8947   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cszun9/linearizing_large_language_models/</guid>
      <pubDate>Thu, 16 May 2024 00:09:30 GMT</pubDate>
    </item>
    <item>
      <title>使用决策树时的连续值指数（基尼指数）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csyohj/continuesvalued_index_when_using_decision_trees/</link>
      <description><![CDATA[      您好，我有一个关于决策树的问题，特别是（CART）基尼指数。&lt; /p&gt; 我有一个小数据集，由 10 条记录、6 列（索引）组成，任务是使用决策树算法（基尼）来指定树规则。 我的问题是当我的目标是“持续重视”时在这种情况下我该怎么办？对于一个小数据集，我认为也许采用中位数并将其作为阈值（因为基尼系数应该是一个有“是”和“否”的二叉树）会很有用，但我认为这不是正确的方法。 除了目标索引之外，我什么时候应该尝试“二值化”？我的索引？例如，您将在照片中看到价格指数也是连续估值的。 我将为数据集留下一张照片。 提前致谢！ &gt; 数据集 &lt; /div&gt;  由   提交/u/its_showtime007   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csyohj/continuesvalued_index_when_using_decision_trees/</guid>
      <pubDate>Wed, 15 May 2024 23:13:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 HuggingFace 的变形金刚感觉就像作弊。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</link>
      <description><![CDATA[我一直在使用 Huggingface 任务演示作为许多令我兴奋的 NLP 项目的起点，甚至是我所求助的一些视觉任务Transformer 文档，有时是 pytorch 文档，用于根据我的用例自定义代码，并在遇到错误时进行调试，有时查看模型论文以了解超参数应该是什么样的以及要进行实验的范围是什么。  现在，我知道我感觉自己一直是一个糟糕的程序员，从来没有真正喜欢过其他语言和框架，但这对我来说非常有趣和令人兴奋。  &gt; 我能够使用像“TrainingArgs”这样的简单代码来微调很酷的模型。和“Trainer.train()”并让我的朋友们可以使用像“pipeline”这样简单易用的API这让我感到难以置信，并且引发了我的冒名顶替综合症。 所以我想我的问题是，仅使用变形金刚以及我的做法能走多远？是工业/生产标准还是研究标准？   由   提交/u/mhmdsd77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</guid>
      <pubDate>Wed, 15 May 2024 22:08:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能在医学成像（例如组织病理学）领域如此饱和？为什么人工智能在分子生物学（蛋白质折叠除外）方面的探索如此之少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</link>
      <description><![CDATA[我从事涉及生物医学研究人工智能的项目，令我震惊的是为什么有这么多涉及医学成像人工智能的论文/项目，尤其是计算病理学（或放射学）？是因为这个领域的需求（即医院对患者进行活检的组织病理学）吗？ 为什么我感到困惑的是，组织病理学，例如全切片图像分析，是一个资源密集型领域问题 - 典型的 WSI（整个幻灯片图像）需要大约 10GB 才能加载，因此训练模型可能需要几天甚至几周的时间。更不用说您必须将图像转换为更小的补丁，然后应用多实例学习等方法来聚合每个补丁的图像嵌入以获得最终预测。然后你必须看看哪些补丁对疾病很重要（通过注意力图之类的东西），然后你需要领域专家/专业知识来了解模型是否专注于图像的正确部分以进行预测。  然而，自 2020 年以来，该领域发表了如此多的论文，可能有数千篇，跨越 NeurIPS/ICLR/ICML、CVPR/ECCV/ICCV、MICCAI（专门针对我想知道这是否是因为很多来自计算机视觉领域的人想要解决一个更困难的问题（涉及非自然图像？） 然后我我还很困惑为什么分子生物学，尤其是 DNA/RNA/表观基因组学（不包括蛋白质结构/折叠）的 ML 工作少得多、少得多？对于分子生物学来说，几乎所有的焦点似乎都集中在新 AlphaFold 3 的蛋白质折叠/结构上，但除此之外，RNA/DNA/表观基因组学在很大程度上被忽略了？也就是说，在 2023 年底到 2024 年初，只有最近一波关于单细胞 RNA 测序基础模型（如 scGPT/Geneformer 等）的论文？是因为在分子生物学模式中进行良好的分析需要更多的领域知识，而拥有这些知识的人却很少吗？尽管分子生物学数据集（尤其是 RNA 测序）的计算强度通常比医学成像（如组织病理学）低得多？   由   提交/u/EcstaticAd162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</guid>
      <pubDate>Wed, 15 May 2024 21:09:03 GMT</pubDate>
    </item>
    <item>
      <title>自动纸张转视频通道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csuzho/automatic_paper_to_video_channel/</link>
      <description><![CDATA[https://youtu.be/8FPHwhNg_ns?si =aRmqPGlJytvGXlpk   由   提交 /u/This_is_crazy_bunch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csuzho/automatic_paper_to_video_channel/</guid>
      <pubDate>Wed, 15 May 2024 20:31:10 GMT</pubDate>
    </item>
    <item>
      <title>和我来自滑铁卢的朋友一起建造一辆主要的自动驾驶汽车，有人可以帮助确保我们走在正确的轨道上吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csud0q/building_a_primary_selfdriving_car_with_my_friend/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csud0q/building_a_primary_selfdriving_car_with_my_friend/</guid>
      <pubDate>Wed, 15 May 2024 20:05:14 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 合著者 Łukasz Kaiser (OpenAI) 在刚刚发表的这篇演讲中讨论了 GPT-4o 之外的法学硕士的未来。他说，使用较少/高效检索的强化学习数据进行训练是关键。一位前 Google Brain 同事随后展示了良好的检索与法学硕士是如何交织在一起的！想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cssewe/łukasz_kaiser_openai_transformer_coauthors/</link>
      <description><![CDATA[       由   提交/u/muditjps   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cssewe/łukasz_kaiser_openai_transformer_coauthors/</guid>
      <pubDate>Wed, 15 May 2024 18:44:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用不在其中心的 HuggingFace 模型将句子列表编码为嵌入？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1css2ix/how_do_i_encode_a_list_of_sentences_into/</link>
      <description><![CDATA[我正在尝试将句子列表编码为嵌入列表。当我使用 HuggingFace 中心中的模型时，它按预期工作。但是，当我使用不在中心中的模型时，在本例中是 Facebook 的 M2M100 模型，我没有得到预期的结果。 当在 SentenceTransformer( )，我的结果如下所示： from Sentence_transformers import SentenceTransformer dat = [&#39;陨石落在路上&#39;, &#39;我走错了方向&#39;] model_1 = SentenceTransformer( &#39;all-distilroberta-v1&#39;) embeddings_1 = model_1.encode(dat) embeddings_1.shape &gt; (2, 768)  但是，当我使用 M2M100 模型时，我的结果看起来根本不正确，具体来说，我期望有 2 行结果：  from Transformers import M2M100Tokenizer model_m2m = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) model_m2m.src_lang = &quot;en&quot;; embeddings_m2m = model_m2m.encode(dat, return_tensors=“pt”) embeddings_m2m.shape &gt; torch.Size([1, 4])  我应该如何格式化它，以便它返回一个 n 维嵌入列表，其中每行对应一个句子和列数等于嵌入的维度？ （请注意，最终我将对其他语言的句子执行此操作，这就是我使用多语言模型的原因。）   由   提交 /u/YourWelcomeOrMine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1css2ix/how_do_i_encode_a_list_of_sentences_into/</guid>
      <pubDate>Wed, 15 May 2024 18:30:47 GMT</pubDate>
    </item>
    <item>
      <title>你会把它训练到另一个时代吗？微调 LLM 以进行总结。损失高原很快进入第一个时期。性能还可以，但是这是典型的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</link>
      <description><![CDATA[    /u/grey-seagull   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</guid>
      <pubDate>Wed, 15 May 2024 18:15:48 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何LLM模型或方法可以通过从互联网获取最新信息来回答问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cspsc4/are_there_any_llm_model_or_approach_that_answers/</link>
      <description><![CDATA[标签：[讨论] 我正在构建一个使用自定义数据进行 RAG 的 LLM 模型。我想改进这一点。如果代理/模型无法根据信息回答，我希望它通过互联网查找并为我获取最新数据。 我已经使用 Mistral 和 BGE 通过 RAG 构建了基本模型。请分享您的想法   由   提交 /u/AltruisticPudding634   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cspsc4/are_there_any_llm_model_or_approach_that_answers/</guid>
      <pubDate>Wed, 15 May 2024 16:59:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 NLP 构建将职位名称与标准化角色相匹配的模型的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cspfbh/whats_the_best_approach_to_building_a_model_to/</link>
      <description><![CDATA[我工作的一小部分涉及获取客户的员工数据集，并根据角色的头衔将他们的职位映射到标准化头衔列表、在层次结构中假定的职位以及薪水。例如，“财务助理”之类的内容。将映射到我们的标准化角色“会计文员”或“服务台代理”可能会映射到我们的“客户服务代理”角色。  我有一个 CSV 文件，其中包含 280 个标准化标题以及每个标题的简要说明。虽然过去的数据不是那么准确，但我也有公司头衔到每个标准化角色的过去映射。  我目前正在探索完成这项任务的最佳方法。以前，有人建议我不要为此使用法学硕士，但后来我了解了检索增强生成（RAG），并想知道它是否适用于此。我正在考虑使用 BERT，但如果更高级的模型能够提供更好的准确性，我愿意接受建议。 以下是我想到和遇到的一些想法  使用 BERT（无壳或大型）进行语义理解，也许使用 GPT-3 嵌入更多的上下文理解（对于类似的角色可能会有所帮助，例如合规官与供应商等不同）连锁官）。目标是实现高精度的映射。 考虑使用某种 RAG（可能通过 Langchain）从描述中获取额外的上下文信息。  是否有其他模型或方法可能更适合这种语义和上下文匹配？期待反馈。   由   提交 /u/MountainBlock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cspfbh/whats_the_best_approach_to_building_a_model_to/</guid>
      <pubDate>Wed, 15 May 2024 16:44:20 GMT</pubDate>
    </item>
    <item>
      <title>了解分类评估及其指标：从偏差和普遍性到准确性、宏观 F1、MCC 等指标</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</link>
      <description><![CDATA[大家好！ 一个在我的工作中一次又一次出现的话题（当做自己的研究，阅读论文时，以及教学时）：选择哪种分类评估指标？或者：为什么论文使用度量 x 进行评估（而不是 y）？以及其他类似问题。  多年来我一直在做一些笔记，现在我已经完成了一篇文章。我想也许这对你们中的一些人来说很有趣，为什么不分享它： https://arxiv.org/abs/ 2404.16958 这是摘要：  分类系统在无数论文中进行了评估。然而，我们发现评估实践往往是模糊的。通常，指标的选择是没有争论的，模糊的术语会引起误解。例如，许多作品使用所谓的“宏观”指标对系统进行排名（例如“宏观 F1”），但没有明确说明他们对这种“宏观”指标的期望。这是有问题的，因为选择一个指标可能会影响论文发现以及共享任务排名，因此应该最大限度地提高过程中的清晰度。从偏见和普遍性的直观概念出发，我们考虑论文中表达的期望，对常见的评估指标进行分析。有了对指标的透彻理解，我们调查了自然语言处理最近共享任务中的指标选择。结果表明，指标选择通常没有令人信服的论据支持，这个问题可能使任何排名看起来很武断。这项工作旨在为更明智和透明的指标选择提供概述和指导，促进有意义的评估。   一些关键观察结果是：  通常，并不完全清楚为什么在案例中使用特定指标。&lt; /li&gt; 通常也不太清楚什么是“元度量”。属性由“宏观度量”中的“宏观”等术语隐含。然而，一个反复出现的愿望是指标应该引起某种“平衡”。  为了澄清这些问题，我们分析了一些流行的指标及其属性。一些见解是：  许多指标可以根据分类器偏差和类流行率来更简单地编写。 有两个指标称为宏 F1（！）。他们的衡量标准也截然不同。另一方面，Kappa 和 MCC（马修斯相关系数）有点相似。 Macro Recall 有一个直观的解释：这是一系列与公平的赔率。这是唯一一个对班级流行率变化完全不变的指标（以防万一我们希望如此）。  最后，如果只有一个结论绘制，那么我想这是没有整体完美的指标，并且应该始终在给定特定上下文的情况下明智地选择指标。希望我的工作能对此有所帮助。   由   提交/u/juopitz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</guid>
      <pubDate>Wed, 15 May 2024 13:56:40 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的随机深度解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</guid>
      <pubDate>Wed, 15 May 2024 13:17:52 GMT</pubDate>
    </item>
    <item>
      <title>2024/2025年学习基础NLP投资回报率低吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</link>
      <description><![CDATA[就上下文而言，我目前正在学习 MSCS，有一门 NLP 课程，但它不会像 PHD 级别那么深（显然），所以我我想知道 NLP 的原始教育还值得学习吗？我不认为我会成为一名“机器学习工程师”  我们学习了非常早期的情感分析方法，例如在没有库的情况下通过手动逻辑回归按频率分配权重。如今，ChatGpt 或 Gemini 使用的算法比这些算法聪明 1000 倍，我真的很怀疑我所学的东西在我毕业后是否有任何价值。我可以简单地调用 openai api 和一些 numpy 库来在几秒钟内完成我正在学习的所有内容。不要误会我的意思，我认为这些算法非常迷人且很酷，但我更想研究一些很酷、有用且投资回报率高的东西（例如网络）。 TLDR 关于如何进行基本学习的一些见解NLP 可以帮助技术领域的职业发展，本页的专家将非常感激 &lt;3 编辑：我感谢专家们的见解。真正有帮助的是了解学习传统方法不应该仅仅从表面上看，并且具有一定的可扩展性irl   由   提交/u/Flash77555  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</guid>
      <pubDate>Wed, 15 May 2024 04:24:41 GMT</pubDate>
    </item>
    </channel>
</rss>