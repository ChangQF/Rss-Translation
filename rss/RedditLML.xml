<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Mon, 24 Feb 2025 09:19:17 GMT</lastBuildDate>
    <item>
      <title>导入抹布时，我应该在文档中删除标头和页脚吗？如果我不这样做会有太多噪音吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwxumw/should_i_remove_header_and_footer_in_documents/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好。&lt; /p&gt; 由于市场情况，我决定采取越来越硬的机器学习项目。对现在，我正在尝试将我的大学的网站导入抹布，以作为知识库的聊天。 我必须说我对Genai并不那么了解，但是目前是蜜蜂的膝盖我真的需要一个工作。 我可以用请求和美丽的汤递归地刮擦链接。那里没问题。，但是那里有很多pdf和Word文档，自然而然地有徽标，标头，页脚和页码。&lt; /p&gt; 不幸的是，它并没有结束。文档因设计而有所不同，有些是从PowerPoint转换的，有些只是扫描的文档（糟糕）。 我一直在与LLMS讨论此问题，他们经常建议我应该指定一个高度和宽度值要删除标头的页脚和页码。 但是，如果没有OCR和删除标头，则不只是提取文本/使用Tesseract的问题，而不是一个问题。页脚。 像Openai这样的公司是如何做到的？我知道他们有整个团队，但他们仍然摄入了几乎全部互联网可用的知识。 他们是否使用过平衡平衡的一些特殊技术，因此标题和页脚没有重点的优先级？ ＆＃32;提交由＆＃32; /u/semperpistos     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwxumw/should_i_remove_header_and_footer_in_documents/</guid>
      <pubDate>Mon, 24 Feb 2025 09:05:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用这些约束执行电容聚类？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iww19u/how_to_perform_capacitated_clustering_with_these/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， 我需要电容聚类任务的帮助。我有400个位置（每次数字可能会有所不同），并且需要创建固定尺寸的簇（例如，每个群集40个位置）。群集不应重叠，每个集群的总面积应尽可能最小化。 要解决这个问题，我正在使用 Google路线优化API 。我创建一个请求，其中车辆数量等于群集的数量，然后将每个位置的负载需求设置为1。然后，我设置了每个车辆（例如40个位置）的负载限制，并尝试生成优化的路由。这种方法满足容量约束，但是产生的簇有时重叠（请参阅附件的图像）。 以解决重叠问题，我用来手动为每辆车手动分配 oute_distance_limit  ，改善了结果。但是，现在我需要自动化整个过程。 任何人都可以提出一种自动化的方法，同时确保群集不重叠（也许是通过对成本功能进行一些更改）。我也可以接受替代方法。 预先感谢！ 这是我要提出的请求，   request_json = { ＆quot“ oggrents”：[{{ “标签”：“：＆quot” }]，“ load_demands”：{pallet_count＆quot; cost_per_kilometer＆quot;：10.0，&#39;load_limits＆quot;：{ ＆quot&#39;pallet_count＆quot＆quot＆quot {max_load＆quot;：40}}，&#39;route_distance_limit月= 1，天= 7，小时= 7，分钟= 0，第二个= 0），＆quort; global_end_time;：datetime（年= 2025，月= 1，day = 7，hour = 23，minute = 0，sinume = 0，section = 0）}      &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iww19u/how_to_perform_capacite_clusterated_clustering_with_these/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iww19u/how_to_perform_capacited_clustering_with_with_these/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iww19u/how_to_perform_capacitated_clustering_with_these/</guid>
      <pubDate>Mon, 24 Feb 2025 06:57:33 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek Flashmla：DeepSeek OpenSource Week第1天</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4jc/deepseek_flashmla_deepseek_opensource_week_day_1/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/mehul_gupta1997       [links]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwv4jc/deepseek/deepseek_flashmla_flashmla_deepseek_opensource_opensource_week_week_week_day_1/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4jc/deepseek_flashmla_deepseek_opensource_week_day_1/</guid>
      <pubDate>Mon, 24 Feb 2025 05:57:45 GMT</pubDate>
    </item>
    <item>
      <title>Gemini vs OpenAI的功能/工具调用最佳是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_best_for_functiontool_calling_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  正如我所研究的那样，OpenAI GPT4-O模型和Gemini 2.0模型都可以函数/工具调用。从成本明智的角度来看，双子座模型比Openai便宜。但是从工具/函数调用角度来看，最佳模型是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/super_strawberry_555     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_the_best_for_functiontood_functiontool_calling_calling_from//]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_best_for_functiontool_calling_from/</guid>
      <pubDate>Mon, 24 Feb 2025 05:57:40 GMT</pubDate>
    </item>
    <item>
      <title>观看我关于机器学习的视频</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwslp1/watch_my_vid_about_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它使用pytorch教u基本的机器学习。将上传更多vids--  https://youtu.be/pipeym1klag？ &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/um/emotional-amount-520     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwslp1/watch_my_vid_about_machine_learning/</guid>
      <pubDate>Mon, 24 Feb 2025 03:29:59 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊作为访谈从2周开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iws2o5/amazon_as_interviews_starting_in_2_weeks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/mikespecterzane    href =“ https://www.reddit.com/r/leetcode/comments/1iwqwo6/amazon_as_interviews_starting_in_2_weeks/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iws2o5/amazon_as_interviews_starting_in_2_weeks/</guid>
      <pubDate>Mon, 24 Feb 2025 03:01:54 GMT</pubDate>
    </item>
    <item>
      <title>可以训练VAE还可以执行介绍 /降解吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_vae_be_trained_to_also_perform_inpainting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个相当小的数据集，可以最好地描述为随机掩盖的小补丁的图像（请注意，它们都在此中“损坏”方式，没有可以使用的“清洁图像”。 天真，我有两个模型。首先，我通过掩盖了一些没有掩盖的区域，以介绍一些没有掩盖的区域的损失（因此没有基本真相），从而训练了一个Denoising AutoCodoter，并通过掩盖了一些没有掩盖的区域。然后，我将使用该模型来注入我在训练的相同图像（填写那些蒙面的补丁）。其次，我想将增强图像压缩到有意义的潜在空间中，所以我会训练典型的VAE（或像VQ-VAE这样的变体）。 ，我不知道为什么这两个步骤无法使用单个模型来完成。我应该能够使用我描述的第一个目标来训练VAE，对吗？ 。但是无论出于何种原因，dae/vae通常被称为完全不同的概念，所以我只想确保我不会在这里错过任何东西。  &lt;！ -  sc_on-&gt;＆＃ 32;提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_a_vae_be_be_trained_to_also_also_also_also_also_perform_inpainting/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwqygq/can_a_a_a_a_vae_be_trained_to_to_also_also_also_perform_inpainting/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_vae_be_trained_to_also_perform_inpainting/</guid>
      <pubDate>Mon, 24 Feb 2025 02:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[help*]我的ML模型到底有什么问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwpiv6/help_what_is_exactly_wrong_with_my_ml_model/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    project  我和我的朋友正在建立一个深度学习模型，从我的班级收集天气数据，并旨在在我们学校周围的当地地区准确预测PV的生成。  问题 我们一年的小时光伏生成数据，一个卫星图像数据集和一个数字天气文件。最初，我们用3个月的数据进行了测试，达到了约12％的NMAE。验证损失（通过MSE衡量）在训练过程中平稳减少，没有尖峰或波动。 然后，我们将时间表从3个月扩大到全年...那时事情变得很奇怪。 NMAE提高到9％，这是该死的好，但是在训练中，验证损失或训练损失会随机飙升至 60 （通常，它保持不变左右 0.01 ）。当这种情况没有发生时，验证损失如地狱，但它仍然比训练损失低 ，这是没有意义的。.我们尝试了200多种不同的组合学习率和体重衰减...但是无助请帮助！ （这与我的数据有关...？）   -------第一个图：3个月的价值     ------然后，12个月（1年）数据             &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/necter_top_6988      [links]     ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwpiv6/help_what_is_exactly_wrong_with_my_ml_model/</guid>
      <pubDate>Mon, 24 Feb 2025 00:52:27 GMT</pubDate>
    </item>
    <item>
      <title>指导</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwmjpf/guidance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想了解深度学习和神经网络，我最终希望建立一个神经网络，该网络识别手写数字，就像许多人一样用作示例许多介绍该概念的视频。我需要帮助才能开始学习Python以及我对这个小项目的需求。谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/key-extension9475      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwmjpf/guidance/</guid>
      <pubDate>Sun, 23 Feb 2025 22:32:29 GMT</pubDate>
    </item>
    <item>
      <title>寻找一门好的课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwi6hh/looking_for_a_good_course/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找有关数据预处理和模型部署的好课程。有什么建议吗？最好是锻炼的实用性。谢谢🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/syedmayyan     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwi6hh/looking_for_a_good_course/</guid>
      <pubDate>Sun, 23 Feb 2025 19:25:47 GMT</pubDate>
    </item>
    <item>
      <title>全新的机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwhvma/entirely_new_to_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个同事帮助我构建一个自动编码器，以根据测量的形态特征对2种类型的修饰单元进行分类。  最初的结果很棒，但是在此方面，我们最终得到了一些数据泄漏，而没有进行5倍的交叉验证。  因此，我们修复了它，删除了一些我们认为没有用的数据，现在情况更糟。 现在我陷入了模型的性能减少，此外，我意识到少量的形态特征更依赖于样品中细胞的密度，而不是与细胞功能有关。从数据集中删除它们后，性能降低了。 此外，在5倍验证期间，一个折叠往往具有很高的重建损失。是否有关于尝试什么的一般建议，或者任何愿意查看我模型的培训部分并帮助故障排除的人？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/this-ae-nighte    href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwhvma/entirely_new_to_to_machine_learning/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwhvma/entirely_new_to_machine_learning/</guid>
      <pubDate>Sun, 23 Feb 2025 19:13:15 GMT</pubDate>
    </item>
    <item>
      <title>如果您想建造自己的抹布，吹牛是一个很好的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwf3sq/braglangchain_is_a_great_resource_if_you_want_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  它包括逐步的教程，一个很好的资源 突出显示： - 设置抹布应用程序的指南，从数据加载到向量存储 - 学习高级技术，例如多Query设置，更好索引准确的结果 - 实践示例以应用您所学的知识 在此处查看： https：// github。 com/bragai/brag-langchain    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielwetan     [link]  ＆＃32;   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwf3sq/braglangchain_is_a_great_resource_if_you_want_to/</guid>
      <pubDate>Sun, 23 Feb 2025 17:16:45 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwcbxq/dropout_explained/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我已经创建了一个视频在这里我谈论辍学的地方，这是一种强大的正则化技术。 我希望你们中的某些人可以使用它。反馈受到欢迎！ ：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/personal-trainer-541      [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwcbxq/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:16:17 GMT</pubDate>
    </item>
    <item>
      <title>但是，GPT实际上是如何工作的？ |逐步笔记本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivxhjl/but_how_does_gpt_actually_work_a_step_by_step/</link>
      <description><![CDATA[   /u/u/kevinpdev1     [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivxhjl/but_how_does_gpt_actually_work_a_step_by_step/</guid>
      <pubDate>Sun, 23 Feb 2025 00:32:22 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到此处   对于那些正在寻找简历评论的人，请发布在 imgur.com 首先，然后将链接作为评论，甚至在/r/sumumes 或首先，然后在这里交叉点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>