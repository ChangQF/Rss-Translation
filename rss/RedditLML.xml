<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Sun, 02 Mar 2025 15:16:46 GMT</lastBuildDate>
    <item>
      <title>TensorFlow或Pytorch</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1socd/tensorflow_or_pytorch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 也许有人已经问了这个问题，这可能是一个愚蠢的问题，但是我只是从学习ML开始。我已经完成了理论零件，并且即将开始从事小型项目。 看来，Tensorflow和Pytorch是人们使用的最常见工具，但我不确定哪个工具更广泛地使用或推荐。我宁愿坚持一个人，而不必在两者之间做事。 建议根据应用程序更改建议吗？  任何建议都将不胜感激！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/iwillnamemypugyoda     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1socd/tensorflow_or_pytorch/</guid>
      <pubDate>Sun, 02 Mar 2025 14:58:45 GMT</pubDate>
    </item>
    <item>
      <title>怎么知道什么时候放弃？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1ri81/how_to_know_when_to_give_up/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在过去一个月一直在开发模型，但它不会去任何地方。这是一种预期的预期，因为输入数据是非常随机的，但是我想问大家：您什么时候放弃？ 总是有更多的尝试，要尝试，功能工程，对建筑的摆弄等。 。 有些经验丰富的人可以分享他们的故事，他们何时知道任务是没有希望的？提交由＆＃32; /u/aiueka     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1ri81/how_to_know_when_to_give_up/</guid>
      <pubDate>Sun, 02 Mar 2025 14:02:23 GMT</pubDate>
    </item>
    <item>
      <title>亚历山大·阿米尼麻省理工学院播放列表的深度学习如何？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1rdr6/how_is_deep_learning_by_alexander_amini_mit/</link>
      <description><![CDATA[Need to study deep learning for btech minor project... i know basic ml theory not implementation (regression, svm etc) and since i need to submit project this sem i am thinking of directly learning dl... do suggest me resources... YT - Alexander Amini    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/norazzmatazz6097     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1rdr6/how_is_deep_learning_by_alexander_amini_mit/</guid>
      <pubDate>Sun, 02 Mar 2025 13:56:22 GMT</pubDate>
    </item>
    <item>
      <title>初学者的AI＆ML的资源和路线图。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1r7kz/resources_and_roadmap_for_ai_ml_in_2025_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， 您能为我提供成为AI或ML工程师的最佳资源。 请包含项目，以便我可以展示我的工作。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_ganache2414     [links]     &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1r7kz/resources_and_oadmap_for_for_ai_ml_ml_in_in_2025_for/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1r7kz/resources_and_roadmap_for_ai_ml_in_2025_for/</guid>
      <pubDate>Sun, 02 Mar 2025 13:47:32 GMT</pubDate>
    </item>
    <item>
      <title>哪个是学习ML的更好来源？ O'Reilly Hands ML Book还是Andrew Ng Coursera课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1qug5/which_is_the_better_source_for_learning_ml/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我个人更喜欢文档而不是视频，但想知道哪个是最好的来源。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/hamstermolester6969      [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1qug5/which_is_the_better_source_for_learning_ml/</guid>
      <pubDate>Sun, 02 Mar 2025 13:28:48 GMT</pubDate>
    </item>
    <item>
      <title>寻找学习伙伴 - 商业重点</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1qkaa/looking_for_study_partner_business_focus/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我正在寻找一个认真学习ML和AI并建造其承运人的学习伙伴。也愿意在未来的业务计划上合作，使用机器学习和人工智能解决现实世界中的问题。我居住在印度，更喜欢当地人，以便我们可以有效合作。我与Python处于中间水平，并完成了一些基本的ML课程，但希望更深入地研究高级主题。 DM如果您有兴趣或有任何疑问！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/vast-contribution938     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1qkaa/looking_for_study_partner_business_focus/</guid>
      <pubDate>Sun, 02 Mar 2025 13:13:36 GMT</pubDate>
    </item>
    <item>
      <title>缺失值对模型和预处理步骤的影响</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_of_missing_values_on_both_models_and/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/riteshbhadana     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_missing_values_values_on_both_models_models_and/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_of_missing_values_on_both_models_and/</guid>
      <pubDate>Sun, 02 Mar 2025 12:00:22 GMT</pubDate>
    </item>
    <item>
      <title>在线学习机器学习的最佳资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1p47h/best_resources_online_to_learn_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    从deeplearlearning.ai by Andrew ng ng ng   - 初学者    href =“ https://imp.i384100.net/dvzr5a”&gt; ibm机器学习专业证书A-Z™：动手Python＆amp; R UDEMY  数据科学的R r    深度学习专业化。深度学习  生产的机器学习工程（MLOPS）专业化来自Supervised Machine Learning: Regression and Classification, Coursera, Andrew Ng - Beginner Matrix Algebra for Engineers, Coursera, Jeffrey R. Chasnov 机器学习专业数学  - 初学者   Google Cloud上的机器学习href =“ https://www.pntra.com/t/tujgr0llr0jhskhgskhcr0zisk1n?website = 361357&amp;refurl=https%3A%3A%3A%2FFURL = HTTPS； -codecademy    python编程 -  udacity    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sreeravan   href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1p47h/1j1p47h/best_resources_online_to_to_to_learn_machine_learne_learning/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1p47h/best_resources_online_to_learn_machine_learning/</guid>
      <pubDate>Sun, 02 Mar 2025 11:47:15 GMT</pubDate>
    </item>
    <item>
      <title>Bentoml：初学者的MLOP</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1oss7/bentoml_mlops_for_beginners/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/kingabzpro      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1oss7/bentoml_mlops_for_beginners/</guid>
      <pubDate>Sun, 02 Mar 2025 11:25:30 GMT</pubDate>
    </item>
    <item>
      <title>Nesterov在极端学习机器中加速梯度下降，而高正规化</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1nu4c/nesterov_accelerated_gradient_descent_stalling/</link>
      <description><![CDATA[    我正在用一个隐藏层实现Nesterov加速梯度下降（NAG）。我的损耗函数是带有L2正则化的平均平方错误（MSE）。 梯度I计算是：   其中：  w2是参数矩阵，h是隐藏层激活矩阵（固定在榆树中），d是目标输出，λ是正规化参数。 如果我们选择一个固定的步骤，则依赖于convexity alpha的强度和函数的效果，而理论依赖于convexity alpha的强度，则该理论是在理论上的最佳降低。在Bubeck 2015的以下等式中显示：   其中k是函数的条件数。 问题： 如果我选择高lambda（等于或高于1），则该理论预测收敛速度更快，因为函数的条件数较低。这正是我从实验中观察到的。但是，尽管我的算法很快达到了不错的差距，但即使该理论预测单调减少，它也会失速。这是典型学习曲线的一个示例（在橙色的最坏情况差距中，蓝色算法）。   我的问题：如何调和这样的事实，即理论预测趋同的束缚，而我的算法由于较小的梯度而被卡住了？这个问题是高λ制度中L2正则化固有的，还是我的实施特定的？任何见解，数学解释或实用建议都将不胜感激！ 事先感谢您的帮助！ 注意：这与我选择的问题，隐藏的层大小和激活功能无关。     &lt;！ -  sc_on-&gt;＆&gt; 32;提交由＆＃32; /u/u/paulmil     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1nu4c/nesterov_accelerated_gradient_descent_stalling/</guid>
      <pubDate>Sun, 02 Mar 2025 10:20:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么要softmax引起注意？为什么只有一个标记对只有一个标量？ 2来自好奇初学者的问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1nq6r/why_softmax_for_attention_why_just_one_scalar_per/</link>
      <description><![CDATA[Hi, I just watched 3Blue1Brown’s transformer series, and I have a couple of questions that are bugging me and chatgpt couldn&#39;t help me :(  Why does attention use softmax instead of something like sigmoid? It seems like words should have their own independent importance rather than competing in a probability distribution. Wouldn&#39;t sigmoid allow for a更重要的是，更重要的是    为什么查询和钥匙只能计算出一个象征性对的单个标量，因为两个令牌并不是一个含义  [link]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1nq6r/1j1nq6r/why_softmax_for_terention_why_just_just_one_one_scalar_scalar_scalar_per/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1nq6r/why_softmax_for_attention_why_just_one_scalar_per/</guid>
      <pubDate>Sun, 02 Mar 2025 10:12:09 GMT</pubDate>
    </item>
    <item>
      <title>我还需要学习什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1m6tl/what_else_do_i_need_to_learn/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;  嗨，我想成为AI工程师，这是我的简历。这不是一个好的，但我需要您的帮助，对我可以学习或做什么。我知道这些项目是非常初学者的级别，但我才刚刚开始。请就我如何改进的建议提出建议？另外，如果您可以指导我有关我需要做的ETHE类型的项目，那也会有所帮助。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/iamnazzal      [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1m6tl/what_else_do_i_need_to_learn/</guid>
      <pubDate>Sun, 02 Mar 2025 08:21:15 GMT</pubDate>
    </item>
    <item>
      <title>我的数据集大小过于杀伤吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1jm7v/is_my_dataset_size_overkill/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试使用u-net对CT扫描数据进行医学图像分割。数据集约为400 CT扫描，切成2D图像并进一步增强。最后，我们获得了带有相应的斑点标签的400000 2D切片。这个尺寸的过度杀伤是训练U-NET的？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1jm7v/is_my_my_my_my_my_my_my_size_size_overkill/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1jm7v/is_my_dataset_size_overkill/</guid>
      <pubDate>Sun, 02 Mar 2025 05:27:48 GMT</pubDate>
    </item>
    <item>
      <title>[YouTube讲座摘要] Andrej Karpathy-深入研究LLM</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1g59r/youtube_lecture_summary_andrej_karpathy_deep_dive/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些没有时间观看讲座或想在钥匙外卖上加快速度的人，我已经为您概括了。   https://www.tidybook.app/392011cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-c320-4b61-8361-8383836-66,66888888888888.AN.6666666666.AP   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/igmyung     [links]   &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1g59r/youtube_lecture_lecture_summary_andrej_karpathy_karpathy_deep_deep_deep_dive/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1g59r/youtube_lecture_summary_andrej_karpathy_deep_dive/</guid>
      <pubDate>Sun, 02 Mar 2025 02:11:14 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到这里   对于那些正在寻找简历评论的人，请在 href =“ href =“ https://www.reddit.com/r/resumes”&gt;/r/简历或 r/EngineeringResumes 首先，然后在此处交叉crosspost。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>