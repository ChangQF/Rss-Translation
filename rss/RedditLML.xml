<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 14 Jun 2024 15:16:49 GMT</lastBuildDate>
    <item>
      <title>我拥有数据领域的硕士学位，但没有相关经验</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfsqdj/i_have_my_masters_in_data_field_but_i_dont_have/</link>
      <description><![CDATA[相反，我在本科期间做了两个月的运营实习生。从那时起，我就没有机会实习了，因为我们不被允许实习（很奇怪，但确实如此） 我如何在简历中展示这一点？我已将简历提交给多个简历审查网站。他们看到的只是我在运营实习生方面的技能……  尽管我在简历中提到了我的项目和技能    提交人    /u/BeyondAmbitious2039   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfsqdj/i_have_my_masters_in_data_field_but_i_dont_have/</guid>
      <pubDate>Fri, 14 Jun 2024 14:53:19 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch empty() 函数出错，我大概知道原因，但无法修复</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfseqv/pytorch_empty_function_erroring_out_i_have_some/</link>
      <description><![CDATA[我正在编写一个基于变分递归自动编码器的模型来预测股票收益，但就在实例化该模型之前，遇到了一个障碍。抛出的错误是：  empty()：参数“size”无法解压位置 2 处的对象，错误为“类型必须是 int 的元组，但得到了元组”  Encoder 模型构造函数是： def convert_to_dotdict(d): if isinstance(d, dict): return DotDict({k: convert_to_dotdict(v) for k, v in d.items()}) elif isinstance(d, list): return [convert_to_dotdict(i) for i in d] else: return d class Encoder(nn.Module): def __init__(self, params: DotDict): super(Encoder, self).__init__() self.params = params self.batch_size = self.params.batch_size self.num_stocks = int(self.params.num_stocks) self.num_factors = self.params.num_factors self.num_layers = self.params.num_layers self.hidden_​​size = self.params.hidden_​​size self.num_lags = self.params.num_lags self.dropout = self.params.dropout self.rnn = nn.LSTM( input_size=self.num_stocks, hidden_​​size=self.hidden_​​size, num_layers=self.num_layers, dropout=self.dropout, batch_first=True ) print(&quot;Hi&quot;) # 健全性检查 self.relu = nn.ReLU() = nn.Linear(self.hidden_​​size, self.num_factors) self.mu_activation = nn.ReLU() self.log_sigma = nn.Linear(self.hidden_​​size, self.num_factors) self.log_sigma_activation = nn.ReLU()self.mu  解码器模型构造函数非常相似，除了可能在这里或那里有一个完全连接的层或投影矩阵。 RVAE 模块是： class RVAE(nn.Module): def __init__(self,coder_params:dict,coder_params:dict): super(RVAE, self).__init__() self.encoder = Encoder(encoder_params) self.decoder = Decoder(decoder_params) self.weight_matrix = nn.Parameter(torch.randn(hyperparams.FACTOR_NETWORK.NUM_FACTORS, hyperparams.DATA.NUM_STOCKS), require_grad=True) = None self.logvar = None def sample(mu : list, logvar : list): assert len(mu) == len(logvar) std = torch.exp(0.5 * logvar) eps = torch.randn_like(std) return mu + eps * std def forward(self, x): mu, logvar = self.encoder(x) = mu self.logvar = logvar z = self.sample(mu, logvar) ft = self.decoder(z) return np.matmul(self.weight_matrix, ft)self.muself.mu  当我运行 model = RVAE(encoder_params,coder_params) 时，出现上述错误。请注意，DotDict 只是一个将字典转换为点可访问形式的实用程序类。 我尝试搜索有关 torch.empty() 的文档，并尝试对该函数进行各种输入组合以试图破坏它。有趣的是，`torch.empty(2, 2)`，`torch.empty((2, 2))`，`torch.empty([2, 2])` 似乎都可以工作，但 `torch.empty((2, (2, 2))` 给出了完全相同的错误，根据错误消息的内容，这是合理的。 此后，我尝试搜索 torch.empty() 的源代码，但找不到任何可靠的东西，而且我找到的任何内容都没有提到引发此错误。 但我的问题是，我已经非常明确地将 self.num_stocks 转换为 int()，但问题仍然存在。您的帮助对我很有帮助。谢谢！ 注意：`hyperparams` 是一个外部 JSON 文件，我正在读取它并将其转换为 DotDict。    由    /u/browbruh 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfseqv/pytorch_empty_function_erroring_out_i_have_some/</guid>
      <pubDate>Fri, 14 Jun 2024 14:39:09 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该先运行元优化来排除不成功的模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfqwux/should_i_run_metaoptimization_to_rule_out/</link>
      <description><![CDATA[我正在尝试在大型图像数据集（100000+ 张图像）上训练识别器。由于我是在个人电脑上执行此操作，因此需要花费大量时间，并且我想避免运行导致死胡同或不能很好地收敛的模型架构和参数的所有训练周期。因此，我正在寻找更快排除性能不佳的模型的方法。 我的一个想法是首先尝试一堆超参数集：批量大小、优化器和模型架构，但周期数较少。然后对性能最佳的模型运行完整的（200+ 个周期）训练。 我预见到的一个问题是我的模型通常不会快速收敛 - 损失仅在 60-70 个周期左右后才开始显着下降。这是使用较小的数据集和较少多样化图片的情况 - 我认为包含多样化图片的大型数据集将需要更多时间才能开始收敛。 我还能做些什么来减少训练时间？我也可以尝试较小的数据集，但重点是训练模型来识别可能看起来非常不同的图片，而且我不确定小数据集上的性能是否是较大数据集上性能的良好指标。 任何建议都值得赞赏！    提交人    /u/smthamazing   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfqwux/should_i_run_metaoptimization_to_rule_out/</guid>
      <pubDate>Fri, 14 Jun 2024 13:31:33 GMT</pubDate>
    </item>
    <item>
      <title>网络中的网络 | 使用 Pytorch 解释深度神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfqjni/network_in_network_deep_neural_network_explained/</link>
      <description><![CDATA[        提交人    /u/research_pie   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfqjni/network_in_network_deep_neural_network_explained/</guid>
      <pubDate>Fri, 14 Jun 2024 13:14:15 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 将十大 LMSYS 模型与通用 LLM API 库进行比较</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfpvdj/project_comparing_top_10_lmsys_models_with_a/</link>
      <description><![CDATA[      我们构建了一个开源 AI 网关，可让您访问和比较来自多个提供商的 200 多个 LLM。在基准问题上运行了前 10 个 LMSYS 排行榜模型： https://preview.redd.it/3f8nob1p8j6d1.png?width=549&amp;format=png&amp;auto=webp&amp;s=1e8cd9cdf96654ffe8e8ab0b208d556d38397ba4 结果？ GPT-4o 是唯一一个做对了的。 https://preview.redd.it/t0v1a7zp8j6d1.png?width=553&amp;format=png&amp;auto=webp&amp;s=7bf274357880c435bf7e9ba6e35926aca5c6505a 代码和演示：https://github.com/Portkey-AI/gateway/blob/main/cookbook/use-cases/LMSYS%20Series/comparing-top10-LMSYS-models-with-Portkey.ipynb 有什么想法吗？    提交人    /u/EscapedLaughter   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfpvdj/project_comparing_top_10_lmsys_models_with_a/</guid>
      <pubDate>Fri, 14 Jun 2024 12:40:56 GMT</pubDate>
    </item>
    <item>
      <title>[资源] 法语免费深度学习课程🇫🇷</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfpdxu/resources_free_deep_learning_course_in_french/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我一直在进行的一个个人项目：一系列涵盖深度学习基本方面的笔记本，从导数和梯度下降到 Transformer 架构。我的目标是让各个级别的学习者更容易理解这些概念。 🔗 GitHub 存储库：https://github.com/SimonThomine/CoursDeepLearning 🇫🇷 注意：课程材料目前为法语。 关于项目 该课程仍在进行中，我正在业余时间积极开发它。有些部分从著名的英语资源中汲取灵感，例如 Andrej Karpathy 的视频和 DeepLearning.ai 课程，以及法语资源。 您如何提供帮助  反馈：我很乐意听到您的想法和改进建议。 传播信息：与任何可能认为它有用的人分享该项目。 贡献：如果您有兴趣，请随时为该项目做出贡献。  无论您是刚刚开始深度学习之旅，还是希望加深理解，我都希望这些笔记本可以成为宝贵的资源。 期待您的反馈和建议！    提交人    /u/ElPoulpo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfpdxu/resources_free_deep_learning_course_in_french/</guid>
      <pubDate>Fri, 14 Jun 2024 12:14:34 GMT</pubDate>
    </item>
    <item>
      <title>我是唯一一个对人工智能/机器学习职业发展轨迹感到沮丧的人吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfls47/am_i_the_only_one_feeling_discouraged_at_the/</link>
      <description><![CDATA[大家好， 我很好奇其他人是否与此相关，如果是，你们中有人如何处理这个问题。  最近，我对担任 AI/ML 工程师感到非常沮丧、没有动力，也不太兴奋。这主要源于我的观察，这些观察表明，这类工程师的工作至少与整个 AI/ML 行业一样发生了变化。也就是说，变化很大，而且速度非常快。  我最喜欢的这个领域的一个方面是从头开始设计和开发个性化的定制模型。然而，除非我们从事严格的研究角色或学术工作（我主要指大学工作），否则我们似乎越来越无法利用这项技能谋生。  最近，似乎更重要的是如何使用模型，而不是创建模型，因为网上有太多开源模型可供获取并用于任何你想要的东西。我知道“如何使用它们一直很重要”，但说实话，与自己创建并自己或团队设计解决方案相比，整理已经为您预先打包的 Azure 模型感觉真的很无聊。不幸的是，预打包解决方案带来的易用性和部署速度才是最终赚钱的关键。 TL;DR：感到沮丧，因为我最喜欢的 AI/ML 东西开始感觉与行业无关，除非你只满足于严格的研究。还有谁能理解？    提交人    /u/1Motinator1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfls47/am_i_the_only_one_feeling_discouraged_at_the/</guid>
      <pubDate>Fri, 14 Jun 2024 08:13:44 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习最让你兴奋的是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dflf9r/dwhat_excites_you_most_about_machine_learning/</link>
      <description><![CDATA[      请在评论中回答 https://community.ai.ml/c/machine-learning-83a6c5/what-excites-you-most-about-ml    提交人    /u/Successful-Arm6595   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dflf9r/dwhat_excites_you_most_about_machine_learning/</guid>
      <pubDate>Fri, 14 Jun 2024 07:47:17 GMT</pubDate>
    </item>
    <item>
      <title>强化学习实现</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfldxs/reinforcement_learning_implementation/</link>
      <description><![CDATA[我正在为一个竞赛开发一款自动驾驶探测车，我计划为此实施强化学习，我需要帮助，我该如何做到这一点，我应该提供什么输入数据，我们正在使用什么算法，深度摄像头和激光雷达，以及建议我该怎么做    提交人    /u/SaNkAlPkAlOdE   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfldxs/reinforcement_learning_implementation/</guid>
      <pubDate>Fri, 14 Jun 2024 07:44:38 GMT</pubDate>
    </item>
    <item>
      <title>小语言模型作为评估者</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfh5gk/small_language_models_as_evaluators/</link>
      <description><![CDATA[GroundedAI 正在开创更小、更高效的语言模型，专门用于评估 LLM 应用程序。 （即幻觉、毒性等） 如果您对当前的 LLM 应用评估方法感到失望，请加入我们的 Discord 以了解我们的创新解决方案。 模型：https://huggingface.co/grounded-ai Discord：https://discord.gg/V5Jme28u    提交人    /u/Jl_btdipsbro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfh5gk/small_language_models_as_evaluators/</guid>
      <pubDate>Fri, 14 Jun 2024 03:13:16 GMT</pubDate>
    </item>
    <item>
      <title>Julia 中的神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfg7ig/neural_nets_from_scratch_in_julia/</link>
      <description><![CDATA[我最近创建了一个名为 SimpleGrad 的新 Julia 包。这里是文档站点和这里是 GitHub 存储库。 它是用于基本机器学习应用程序的梯度跟踪工具。但与其他 ML 包不同，SimpleGrad 的主要目标是教育性。其理念是，源代码应该足够易于阅读、理解和编辑/自定义，并且该包应该既可用于基本应用程序，也对学习 Julia 或 ML（或两者）的人有帮助。  文档还包括一个“引擎盖下”部分，解释了一切的工作原理，以便您可以根据需要从头开始重新创建它。我的目标是把它写成教科书章节，适合那些喜欢从第一原理了解事物工作原理的人。 此外，这是一个正在进行的项目，我会继续添加内容，所以如果有人有任何反馈、批评或功能请求，请告诉我！    提交人    /u/mike20731   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfg7ig/neural_nets_from_scratch_in_julia/</guid>
      <pubDate>Fri, 14 Jun 2024 02:21:30 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习和 PyTorch 进行植物疾病识别</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dfe312/plant_disease_recognition_using_deep_learning_and/</link>
      <description><![CDATA[      使用深度学习和 PyTorch 进行植物病害识别 https://debuggercafe.com/plant-disease-recognition-using-deep-learning-and-pytorch/ https://preview.redd.it/m0iucfo8mf6d1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=45d3e0cf36a59bde29aa71ac54d113d4b3c248ad    提交人    /u/sovit-123   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dfe312/plant_disease_recognition_using_deep_learning_and/</guid>
      <pubDate>Fri, 14 Jun 2024 00:29:01 GMT</pubDate>
    </item>
    <item>
      <title>Apple Silicon 会很快成为预算内 ML 的最佳选择吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1df7kxt/will_apple_silicon_be_the_best_choice_for_ml_on_a/</link>
      <description><![CDATA[我知道之前已经有人问过类似的问题，但随着 Apple 的 WWDC 公告，Mac 似乎可能成为机器学习领域 Nvidia 的真正强大替代品。Apple 正在使用 Apple Silicon 构建他们的计算云，我注意到现在有多少 Youtube 视频是关于在 Apple Silicon Mac 上本地运行 LLM 的。 无论如何，我真正的问题是，就投资具有足够内存的硬件以供非常大的 LLM 在本地运行和训练（而不是每个人都使用的 7B 参数小模型）而言，最明智的做法是什么...二手 Nvidia RTX 8000（48gb）还是几乎满配 RAM 的 Mac Studio？如果选择 RTX 8000，理想情况下我需要两个 96gb 的 Nvlinked，但它们不需要同时购买。  我知道 Nvidia 拥有更多的支持，但 Apple Silicon 似乎每天都在获得更多的支持，而且我认为这不会改变，尤其是在 Apple 完全进入 AI 领域的情况下。    提交人    /u/Serqetry7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1df7kxt/will_apple_silicon_be_the_best_choice_for_ml_on_a/</guid>
      <pubDate>Thu, 13 Jun 2024 19:34:23 GMT</pubDate>
    </item>
    <item>
      <title>未来哪些机器学习领域需求量最大？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1detfdf/which_ml_fields_will_the_in_most_demand_in_the/</link>
      <description><![CDATA[ML 似乎在几乎所有领域都已饱和。我目前处于起步阶段，我不想进入一个过度饱和的领域。哪些领域，现在很小众，未来会很抢手？如果这些领域是强化学习，那就更好了，因为那是我想要去的地方。AGI 会有单独的领域吗？如果有这样的领域，我肯定会想从事 AGI 的工作。    提交人    /u/JP_MW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1detfdf/which_ml_fields_will_the_in_most_demand_in_the/</guid>
      <pubDate>Thu, 13 Jun 2024 07:44:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>