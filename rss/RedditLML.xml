<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 08 Aug 2024 09:16:05 GMT</lastBuildDate>
    <item>
      <title>你记住了证明吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1en0r0l/do_you_memorise_proofs/</link>
      <description><![CDATA[这是我在为机器学习学习数学时的随机想法......我会记住某些我发现有用或有趣的定理、证明或推导，因为我可以快速回忆起它们，并立即知道如何解决问题或练习。对于任何好奇的人来说，不，我不是盲目地记住每个步骤。我理解证明如何以及为什么这样写的背后的要点或直觉。 但这让我思考这种方法的长期可持续性。所以......  这是正常的吗？因为我的教授总是说数学只需要练习而不是记忆，所以我通过记忆来学习数学是错误的吗？ 仅仅知道直觉或要点就足够了吗？  附言我使用 anki 来学习数学    提交人    /u/Confident_Ad_7734   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1en0r0l/do_you_memorise_proofs/</guid>
      <pubDate>Thu, 08 Aug 2024 08:35:04 GMT</pubDate>
    </item>
    <item>
      <title>word2vec 在 transformer 模型中还发挥作用吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1en0ny4/does_word2vec_still_play_a_role_in_transformer/</link>
      <description><![CDATA[随着 LLM 通过易于使用的库而广泛使用，我已经将学习更多关于 transformer 模型基础的知识作为我的项目。  到目前为止，我一直认为 word2vec 与 transformer 模型无关，而是将其视为过去的遗物，但最近我一直在问自己，至少在理论上，word2vec 是否仍然可以在 transformer 模型中发挥作用，即在创建初始静态嵌入时。据我所知，transformer 模型（甚至是前身 LSTM？）仍然依赖于静态词嵌入，然后根据上下文（注意力）进行“更改”？从这个逻辑来看，是否仍然可以将 word2vec 用作 transformer 的静态词嵌入模型，如果可以，在实践中有多普遍？ 谢谢！   由    /u/RDA92  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1en0ny4/does_word2vec_still_play_a_role_in_transformer/</guid>
      <pubDate>Thu, 08 Aug 2024 08:29:23 GMT</pubDate>
    </item>
    <item>
      <title>如何处理预测过程中缺失的特征？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emzgbt/how_to_handle_missing_features_during_prediction/</link>
      <description><![CDATA[我创建的模型包含 90 个特征，预计我们收集的新数据将缺少特征。换句话说，数据中将不存在 10 个或更多特征。如何在预测新数据结果的同时处理缺失的特征？    提交人    /u/mohitksharma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emzgbt/how_to_handle_missing_features_during_prediction/</guid>
      <pubDate>Thu, 08 Aug 2024 07:05:58 GMT</pubDate>
    </item>
    <item>
      <title>解决类别不平衡问题的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emzfb6/question_for_solving_class_imbalance_problem/</link>
      <description><![CDATA[您好， 我目前正在训练一个模型，对具有类别不平衡的数据集执行多标签分类任务。我已经使用非对称损失函数部分解决了正样本和负样本之间的差异。但是，正样本中严重的类别不平衡仍然是一个问题。下面列出的是我的按类别划分的正标签频率 `[3796, 2876, 661, 739, 6502, 2728, 109, 6389, 877, 1401, 149, 301, 1752, 422, 259, 1131, 2695, 1432, 357, 2099, 265, 282]` 作为一种潜在的解决方案，我尝试计算每个正样本的逆类频率并将其乘以最终的损失计算。 不幸的是，这并没有显示出太大的改善。 在这种情况下，我还可以尝试哪些其他方法？ 我将不胜感激任何建议。 谢谢。    提交人    /u/AdventurousPush1560   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emzfb6/question_for_solving_class_imbalance_problem/</guid>
      <pubDate>Thu, 08 Aug 2024 07:04:05 GMT</pubDate>
    </item>
    <item>
      <title>您如何解释这个 val_loss 模式？（更多细节见评论）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emz0e5/how_would_you_interpret_this_val_loss_pattern/</link>
      <description><![CDATA[        提交人    /u/Dykoine   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emz0e5/how_would_you_interpret_this_val_loss_pattern/</guid>
      <pubDate>Thu, 08 Aug 2024 06:37:17 GMT</pubDate>
    </item>
    <item>
      <title>帮助我使用知识图谱作为基于 RAG 的聊天机器人的训练数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emyyuf/help_me_with_using_a_knowledge_graph_as_a/</link>
      <description><![CDATA[我无法找到正确的方法将我在 neo4j aura db 中创建的图表连接为基于 RAG 的聊天机器人的数据源，其中我使用 META 3.1 作为 llm。     提交人    /u/eximious_astrophile   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emyyuf/help_me_with_using_a_knowledge_graph_as_a/</guid>
      <pubDate>Thu, 08 Aug 2024 06:34:30 GMT</pubDate>
    </item>
    <item>
      <title>“面向初学者的机器学习：100 分钟讲座”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emygrx/machine_learning_for_nervous_beginners_a/</link>
      <description><![CDATA[      2012 年，人们开始 ML 之旅很简单。当时只有几门课程。文献中没有充斥着论文。Kaggle 上也没有充斥着玩具项目。 今天，ML 已经成为一个家喻户晓的术语，数亿名来自机械工程、电气工程、计算机科学等各个领域的学生都渴望转向 ML。 2024 年，如果您作为完全的初学者想要转向 ML，您应该怎么做？我发布了一个 100 分钟的讲座，解释了我对这个问题的看法。这是链接： 我们涵盖以下几点： (1) 如何从任何工程领域过渡到 ML？ (2) ML 资源，助您开启旅程 (3) 如何开始做 ML 项目？ (4) 如何开始做 ML 研究并发表您的第一篇论文？ (5) 科学机器学习 (SciML) 领域简介 (6) 访问我们培育的 ML 社区：500 多名积极上进的学生。 我非常确定您将从本次讲座中受益。请随意查看：https://www.youtube.com/watch?v=06CBzP75rjU&amp;feature=youtu.be https://preview.redd.it/zdx8mt2rrdhd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=8930657ed41010aa6b934baa76f0570454c58e7e    提交人    /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emygrx/machine_learning_for_nervous_beginners_a/</guid>
      <pubDate>Thu, 08 Aug 2024 06:01:46 GMT</pubDate>
    </item>
    <item>
      <title>如何用学习率来匹配论文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emy04t/how_to_use_learning_rate_to_match_papers/</link>
      <description><![CDATA[你好！ 我正在复现一些论文，但我一直面临训练不稳定的问题，除非我降低论文中的学习率，因为在几篇论文中我发现我可能是错的。 假设我们有一篇论文，使用 M GPU 以批量大小 N（每个 GPU）训练网络，以学习率为 LR 进行训练。训练几乎总是使用 float16 和 adam/adamw。我正在使用 pytorch amp 进行混合精度训练。 大多数论文要求我正在训练（TTS 任务）在 16/32 gpu 上进行训练，但我不想进行分布式训练，我只使用更快的 GPU 进行 2 倍、4 倍或 8 倍训练，但使用梯度累积（G）。 不同的框架对如何在多 GPU 环境中指定学习率的定义不同。 我现在正在使用 Accelerate，它建议将学习率乘以使用的 GPU 数量，但不清楚如何处理梯度累积以及论文最初如何定义学习率。 我的选择是：  LR - 按原样使用 LR * M - 乘以论文中原始 GPU 的数量 LR * M / G - 乘以不使用梯度累积的实际 GPU 数量 LR * G - 乘以按梯度累积次数  现在我已经尝试了#3，但是梯度爆炸，我除以二，它通常是稳定的，但它与任何其他公式都不匹配。 另外，不清楚论文中使用了什么框架（论文主要来自 Meta 和微软），这可能会影响 LR 不匹配。    提交人    /u/stevekite   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emy04t/how_to_use_learning_rate_to_match_papers/</guid>
      <pubDate>Thu, 08 Aug 2024 05:32:41 GMT</pubDate>
    </item>
    <item>
      <title>MiniCPM：移动法学硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emu9y4/minicpm_mobile_llm/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emu9y4/minicpm_mobile_llm/</guid>
      <pubDate>Thu, 08 Aug 2024 02:12:28 GMT</pubDate>
    </item>
    <item>
      <title>提高 Transformers 和 LLM 的编码能力</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emu6cm/improving_coding_ability_in_transformers_llms/</link>
      <description><![CDATA[我是一名数学专业的学生，​​希望从事 transformers 和 LLM 方面的研究，更具体地说，从事一些具有理论倾向的研究工作，可以揭示 transformers 和注意力机制。我可以很容易地掌握数学部分，但我严重缺乏与 ML 相关的编码经验。我熟悉基本的 Python 和 OOP 编程，并做过简单的 ML 课程项目（填补一些 DL 算法的空白，运行一些 Jupyter Notebooks），但这似乎与研究所需的实际编码能力相去甚远，包括项目工程和实验内容。我想知道是否有任何资源可以用来提高我在这方面的能力。我打算看一看 Andrej 关于实施 GPT 的 YouTube 视频。我想知道我还能做些什么。    提交人    /u/mziycfh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emu6cm/improving_coding_ability_in_transformers_llms/</guid>
      <pubDate>Thu, 08 Aug 2024 02:07:42 GMT</pubDate>
    </item>
    <item>
      <title>评估 LlamaIndex+Azure RAG 管道的幻觉和正确性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emr1rf/evaluate_a_llamaindexazure_rag_pipeline_for/</link>
      <description><![CDATA[        由    /u/Federal-Air9781   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emr1rf/evaluate_a_llamaindexazure_rag_pipeline_for/</guid>
      <pubDate>Wed, 07 Aug 2024 23:40:28 GMT</pubDate>
    </item>
    <item>
      <title>未来 10 年，哪种 ML 专业化组合可能是最佳的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emknt8/what_combination_of_ml_specializations_is/</link>
      <description><![CDATA[嘿，我很快就要进入硕士课程了，我想对专业领域做出正确的决定。  当然，这是主观的，我内心想在自动驾驶汽车中做计算机视觉。 但为了讨论的目的，客观地思考，在未来 10 年里，哪种专业最适合薪水、工作选择和工作稳定性？  例如1. 自然语言处理（NLP） 2. 计算机视觉 3. 强化学习 4. 时间序列分析 5. 异常检测 6. 推荐系统 7. 语音识别和处理 8. 预测分析 9. 优化 10. 定量分析 11. 深度学习 12. 生物信息学 13. 计量经济学 14. 地理空间分析 15. 客户分析    提交人    /u/Capital_Might4441   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emknt8/what_combination_of_ml_specializations_is/</guid>
      <pubDate>Wed, 07 Aug 2024 19:16:41 GMT</pubDate>
    </item>
    <item>
      <title>微积分和线性代数对于机器学习有多重要？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emhu53/how_important_is_calculus_and_linear_algebra_for/</link>
      <description><![CDATA[我需要在多大程度上了解微积分和线性代数？ 了解基础知识和基本原理就足够了吗，还是我真的需要深入研究它们？    提交人    /u/rankme_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emhu53/how_important_is_calculus_and_linear_algebra_for/</guid>
      <pubDate>Wed, 07 Aug 2024 17:26:59 GMT</pubDate>
    </item>
    <item>
      <title>反向传播如何找到*全局*损失最小值？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1emfv3n/how_does_backpropagation_find_the_global_loss/</link>
      <description><![CDATA[据我所知，梯度下降/反向传播对权重和偏差的改变很小，就像球从山上慢慢滚下来一样。考虑到训练神经网络需要多少个时期，以及每个时期内有多少个训练数据批次，变化很小。 所以我不明白神经网络如何自动训练以“克服”局部最小值？只有当学习率定期足够大时，才能设定逃离局部最小值所需的变化阈值？ 为了用稍微好一点的数学来验证这一点，如果存在损失，但给定权重的损失梯度为零，则算法不会针对该权重进行更改。然而，这意味着，为了使网络保持局部最小值，每个权重和偏差本身都必须处于局部最小值，相对于该权重/偏差的损失导数？我无法确定这在统计上是否不可能，或者这是否与统计无关，而只找到局部最小值只是事物在较小的学习率下经常收敛的原因？我不得不承认，我很难想象对于每个训练批次，梯度在每个权重和偏差上都可能为零。我希望得到一个更正式但可以理解的解释。 我对数学的理解水平大约是本科一年级的水平，所以如果你能尝试用这个水平的术语来解释它，我将不胜感激    提交人    /u/140BPMMaster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1emfv3n/how_does_backpropagation_find_the_global_loss/</guid>
      <pubDate>Wed, 07 Aug 2024 16:10:24 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>