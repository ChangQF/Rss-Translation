<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 04 Dec 2024 15:19:25 GMT</lastBuildDate>
    <item>
      <title>一次性比较多个大型语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6eump/comparing_multiple_large_language_models_in_one/</link>
      <description><![CDATA[我写了一篇关于简化比较和选择大型语言模型 (LLM) 以完成各种任务的过程的文章： 一次性比较多个大型语言模型 希望这篇文章能帮助人们根据自己的用例选择最佳模型（这可能需要花费大量时间）。 我也期待讨论不同的技术和工具来自动化这个过程。 谢谢！    提交人    /u/grudev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6eump/comparing_multiple_large_language_models_in_one/</guid>
      <pubDate>Wed, 04 Dec 2024 12:29:56 GMT</pubDate>
    </item>
    <item>
      <title>处理手动解决 kNN 异常大表格的技巧和窍门？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6ei3m/tips_and_trick_to_deal_with_solving_knn_with_hand/</link>
      <description><![CDATA[      去年被问到的示例表，行中的数据（年龄、身高、体重、肥胖） 你好，这是我大学的最后一年，几天后我将参加一场机器学习考试。该表格来自去年考试的四个问题之一。问题要求使用 kNN 预测每个训练数据的肥胖程度，并且不允许使用具有功能的计算机或计算器。我们必须使用基本的计算器，据我所知，这种方式将花费很长时间（大约 50 个数学问题需要解决），而我没有。   由    /u/TheKaritha  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6ei3m/tips_and_trick_to_deal_with_solving_knn_with_hand/</guid>
      <pubDate>Wed, 04 Dec 2024 12:08:57 GMT</pubDate>
    </item>
    <item>
      <title>限时 24 小时免费赠送 Kindle 机器学习书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6e8dz/free_kindle_giveaway_of_machine_learning_book_for/</link>
      <description><![CDATA[我已经发布了我的机器学习书籍《可解释模型的特征工程与选择：数据科学家的第二门课程》的修订版 我正在免费赠送 Kindle 副本，今天是赠送活动的最后一天。立即获取您的 美国：https://www.amazon.com/dp/B0DP5DSFH4/ 加拿大：https://www.amazon.ca/dp/B0DP5DSFH4/ 印度：https://www.amazon.in/dp/B0DP5DSFH4/ 英国：https://www.amazon.co.uk/dp/B0DP5DSFH4/ 德国：https://www.amazon.de/dp/B0DP5DSFH4/ 澳大利亚：https://www.amazon.com.au/dp/B0DP5DSFH4/ 荷兰：https://www.amazon.nl/dp/B0DP5DSFH4/    提交人    /u/Enthusiast_new   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6e8dz/free_kindle_giveaway_of_machine_learning_book_for/</guid>
      <pubDate>Wed, 04 Dec 2024 11:52:22 GMT</pubDate>
    </item>
    <item>
      <title>A3T-GCN 模型：将嵌入从一个单元传递到另一个单元</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6cwfj/a3tgcn_model_passing_embeddings_from_cell_to_cell/</link>
      <description><![CDATA[大家好， 我目前正在使用 Pytorch Geometric Temporal 的 A3T-GCN 类，并发现了这个示例实现： https://www.kaggle.com/code/elmahy/a3t-gcn-for-traffic-forecasting 我遇到了一些理解问题。在我看来，此代码似乎显示了单个 A3T-GCN 单元，它输出具有指定时间戳的底层空间和时间依赖性的嵌入： h = self.tgnn(x, edge_index) # x [b, 207, 2, 12] 返回 h [b, 207, 12] h = F.relu(h) h = self.linear(h)  这里，x 和 edge_index 描述相应时间戳的图形数据。由此，计算嵌入 h，然后将其传递到完全连接的层以获得实际的单次预测，这意味着可以利用单个嵌入来预测未来的多个时间步骤。  此部分展示训练过程： forcoder_inputs, labels in train_loader: y_hat = model(encoder_inputs, static_edge_index) loss = loss_fn(y_hat, labels)  对于训练集中存在的每个时间戳，每次使用 A3T-GCN 单元计算嵌入。将每个时间戳产生的预测与基本事实进行比较，以执行反向传播并调整模型。  我的问题是，你们中有谁知道，前一个时间戳的嵌入是如何传递到当前时间戳的？这是 A3T-GCN 中的一个重要步骤，因为它基于门控循环单元。模型是否在后台执行嵌入传递？    提交人    /u/hertz2105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6cwfj/a3tgcn_model_passing_embeddings_from_cell_to_cell/</guid>
      <pubDate>Wed, 04 Dec 2024 10:21:19 GMT</pubDate>
    </item>
    <item>
      <title>需要指导才能继续深度学习或开始机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6cuzw/guidance_needed_to_continue_dl_or_start_ml/</link>
      <description><![CDATA[我最近看了这段视频https://www.youtube.com/watch?v=qNxrPri1V0I 它主要讲述了人们应该如何开始机器学习，它指出首先要进行数据科学，在数据科学方面做自己的项目，学习统计学，然后是微积分，学习 scikit，然后学习基本的 ML 算法，然后转到基于集成的算法，然后制作你的第一个项目 但是，我目前的情况是，我已经用 python 编码 2 年了，我了解它，然后我直接进入深度学习，我只需浏览一下并按照随机教程制作项目就知道事情是如何运作的，我在大学里学过统计学和微积分。 我现在应该做什么？我应该从头开始学习吗，因为我的数据不是那么强，而且我应该做 ML 吗，即使我对 nn、transformers 等 DL 有所了解？或者我应该跳过整个 ML 并通过学习注意力和新事物来提前学习 DL？    提交人    /u/ItsRealBeast   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6cuzw/guidance_needed_to_continue_dl_or_start_ml/</guid>
      <pubDate>Wed, 04 Dec 2024 10:18:30 GMT</pubDate>
    </item>
    <item>
      <title>这是一个非技术性的课程，描述了为什么在算法训练期间选择最重要的数据点而不是迭代所有数据点很重要。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6badx/a_nontechnical_lesson_to_describe_why_its/</link>
      <description><![CDATA[        提交人    /u/oscarleo0   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6badx/a_nontechnical_lesson_to_describe_why_its/</guid>
      <pubDate>Wed, 04 Dec 2024 08:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 线性回归，但以二进制作为输出，以实现大范围预测和更高的精度</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6b1yi/d_linear_regression_but_with_binary_as_the_output/</link>
      <description><![CDATA[神经网络往往很难预测输出中介于非常大和非常小的数字之间的数据。我的应用程序要求 NN 预测 -1000 到 1000 ∈ Z 之间的值。我可以通过将输出放大 1000 来实现这一点，从而使模型能够预测 -1 和 1 之间的值，但 L1Loss（最坏情况为 L2Loss）下的 2e-2（预测）和 3e-2（目标）之间的损失可以忽略不计（在这种情况下为 1e-2，最坏情况下为 1e-4）。模型必须非常精确地进行预测，当目标是 5e-2 时，它应该是这样的，甚至不能偏离 +-0.1e-2。当涉及到线性回归时，这种精度很难实现，所以我想到了一种更系统的方法来定义预测和标准。同样，我希望模型能够预测 -1000 到 1000 之间的值。这些数字至少可以使用 11 位（二进制）来表示，因此我重新设计了模型输出以包含 22 个神经元，排列为 ∈ R^11x2（11 个输出，两个类别），类别是 1 或 0 的二进制表示。这里可以使用 CrossEntropy 作为标准，但出于特定原因，我改用 multimarginloss。否则，另一种方法可能是使用 11 个神经元的 S 形输出来表示二进制数。你们对此有什么看法？这被认为是好的（如果不是更好的）做法吗？有没有类似的研究可以让我参考？    提交人    /u/Relevant-Twist520   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6b1yi/d_linear_regression_but_with_binary_as_the_output/</guid>
      <pubDate>Wed, 04 Dec 2024 08:00:55 GMT</pubDate>
    </item>
    <item>
      <title>一名 ML 学生，拥有“非 IT”本科学位，由于有一年的时间我学习 ML 并做了 2 个项目，我该怎么做才能立即找到工作？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h6az29/a_ml_student_did_a_nonit_undergraduate_degree/</link>
      <description><![CDATA[我知道这并不容易，但我必须开始尝试，因为我需要一份工作，而且我正试图通过非 IT 本科学位和机器学习课程在机器学习领域获得工作。从现在开始我应该走什么路才能快速找到工作或实习机会？    提交人    /u/Ok_Heron_6713   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h6az29/a_ml_student_did_a_nonit_undergraduate_degree/</guid>
      <pubDate>Wed, 04 Dec 2024 07:55:07 GMT</pubDate>
    </item>
    <item>
      <title>审查 Sutskever 发给 Carmack 的文件</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h62lyz/reviewing_the_papers_sutskever_sent_to_carmack/</link>
      <description><![CDATA[Tldr：我一直在写一组深度学习论文评论，一位朋友提到我应该在这里发布它。  https://open.substack.com/pub/theahura/p/ilyas-30-papers-to-carmack-table 希望它作为学习资源有用！ 更长的版本 -- 早在 2019 年左右，Ilya Sutskever（OpenAI 前首席科学家）就试图说服 John Carmack（杰出的计算机科学家）加入 OAI。他发送了一份约 30 篇论文的清单，让 John 尽快了解。我从事人工智能大约十年了，读过很多这样的文章，但时间已经过去很久了，我觉得从头到尾阅读这个系列对我来说是一个很好的复习。我开始发表论文评论，看到研究的线索以及不同论文随着时间的推移如何相互回应真的很酷。  我认为你不必非常熟悉人工智能，我试图让评论平易近人。我发表了大约 7 篇评论，还有大约 10 篇的草稿。如果这很有趣，我很乐意收到反馈/评论！    提交人    /u/theahura1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h62lyz/reviewing_the_papers_sutskever_sent_to_carmack/</guid>
      <pubDate>Wed, 04 Dec 2024 00:14:40 GMT</pubDate>
    </item>
    <item>
      <title>数据科学是否提供了创办初创企业的工具？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h62801/does_data_science_provide_the_tools_to_found_a/</link>
      <description><![CDATA[或者，如果这是目标，成为一名软件工程师会更好吗？ 我注意到大多数人工智能初创公司分为两类：  ChatGPT 包装器：围绕 ChatGPT 等 API 构建应用程序。这需要强大的软件工程技能来创建周围的软件。 自定义模型：训练自己的模型的初创公司（我说的不是 anthropic、openai……而是小型/“业余”的模型）。  问题： 1）对于后者，一般来说，他们主要使用回归/分类模型还是更复杂的模型？在这种情况下，数据科学家可以处理吗？还是需要 ML 工程师？ 2）那么，成为一名数据科学家是否是创建 AI 初创企业的良好基础？    提交人    /u/Filippo295   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h62801/does_data_science_provide_the_tools_to_found_a/</guid>
      <pubDate>Tue, 03 Dec 2024 23:57:51 GMT</pubDate>
    </item>
    <item>
      <title>请帮忙：有关深度学习的课程推荐</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h60gai/please_help_course_recommendation_about_deep/</link>
      <description><![CDATA[大家好， 我在寻求一些关于应该选修哪门深度学习课程的建议，而且这些课程也是使用 PyTorch 的。我列出了三个选项：  Fast.ai 的“使用 Fastai 和 Pytorch 进行程序员深度学习”最近我收到一些评论，尽管有一些好评，但人们在学习一段时间后仍然在编码方面遇到困难 Mike Cohen 的“使用 Pytorch 深入理解深度学习”  NPTEL 的“深度学习第 1 部分” – 最近在 Reddit 上发现了不错的评价，但我认为它并没有包含太多编码部分。  我真的很想掌握深度学习，所以如果需要的话我愿意结合两门课程。我的目标是拥有深入的理论知识以及大量的动手编码练习。我觉得在学习课程时参考一本详细的书也会有所帮助。 如果您能推荐哪门课程（或课程组合）最适合我，我将不胜感激。如果您已经参加过其中任何一门课程，能否分享一下您的诚实和详细的反馈体验？ 我正在寻找一些实用但不跳过基本理论的东西。请让我知道我应该如何处理这个问题。我有点急于做决定，所以您的指导对我来说意义重大！ 提前谢谢您！🙏    提交人    /u/Vampire-Willow1535   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h60gai/please_help_course_recommendation_about_deep/</guid>
      <pubDate>Tue, 03 Dec 2024 22:40:29 GMT</pubDate>
    </item>
    <item>
      <title>我讨厌面试 ML/DS 角色。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h5vlxp/i_hate_interviewing_for_mlds_roles/</link>
      <description><![CDATA[我只是想发泄一下。我最近在一家非常大的公司面试了一个 DS 职位。我花了好几天的时间准备，尤其是统计部分。说实话：很多统计的东西我自从研究生毕业后就没怎么接触过。并不是说很难，但有些细微差别我必须重新学习。我被一些回归问题难住了。根据我的经验，不同的学科对线性回归采用不同的方法，哪些有用，哪些没用。在面试过程中，我被困在线性回归的一个特定方面，我已经很久没有关注过这个方面了。我还被要求凭空想出不同事物的公式。记忆公式并不是我的强项，但在我近 10 年的 DS 工作中，我从来没有凭空想出过事情。这太令人沮丧了。我讨厌这些公司进行的面试本质上是对整个统计数据和机器学习的突击测验。这没有任何意义，也不是现实中发生的事情。无论如何，咆哮结束。     提交人    /u/The_Peter_Quill   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h5vlxp/i_hate_interviewing_for_mlds_roles/</guid>
      <pubDate>Tue, 03 Dec 2024 19:22:37 GMT</pubDate>
    </item>
    <item>
      <title>不擅长编码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h5rb14/not_getting_good_at_coding/</link>
      <description><![CDATA[嗨，我是一名正在学习机器学习的大学生。尽管我对 ML、DL 的理论有很好的掌握，但我在编码方面却很吃力。我尝试过多次学习 oops 或 pytorch，但当涉及到实时编程时，我有点卡住了，无法正确编码。我已经开始从那些 YouTube 视频中学习，在这些视频中，讲师一边教书一边编码，比如 karpathy 视频。我试着看一段时间视频，然后自己实现代码。这是一个好的策略吗，或者有人有更好的建议吗？    提交人    /u/Antique-Physics2378   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h5rb14/not_getting_good_at_coding/</guid>
      <pubDate>Tue, 03 Dec 2024 16:24:20 GMT</pubDate>
    </item>
    <item>
      <title>让我面对一个残酷的现实：成为一名完全自学成才的人工智能工程师</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h5hta4/give_me_the_harsh_reality_of_wanting_to_be_a/</link>
      <description><![CDATA[我今年 28 岁，想换个职业。 2015 年我学了一年计算机科学，后来因为愚蠢和一些坏习惯而退学。然后去游戏行业工作（目前是制作人）。我非常喜欢数学和编程。 我目前的计划是辞掉工作，在 1-2 年内成为一名全职自学入门级 ML 工程师，每天工作 7-8 小时（我住在泰国，所以有足够的积蓄，成本很低）。我想走自学路线的原因是： - 它更便宜 - 学士学位需要投入大量时间，而作为一个 28 岁的人，我觉得自己没有时间。 - 我觉得自学路线可以让我加速学习，专注于那些能立即给我带来现实世界实用价值的科目（也就是让我更快地被录用）。 - 我的执着天性让我能够自学，保持高效和快乐。我很难和别人一起坐在演讲厅里吸收内容 :/  我会遵循的 AI 路线图： https://cdn.prod.website-files.com/608338f07a8a726c265ad502/67245ae89ec6f0803f08b581_AI%20Roadmap_%20based%20on%20Stanford%20AI%20Graduate%20Certificate.pdf 我目前的学历：游戏开发学士学位（专业：游戏设计）。我知道没用。  我很高兴能继续攻读这个学位，但我很害怕，因为这会带来巨大的变化。我有一些朋友建议我回到大学，但我仍然认为这不是更快的就业方式。我知道我的作品集需要非常强大才能与新的计算机科学毕业生竞争。 注意：我可以想象自己在 2-3 年的工作经验后，攻读人工智能硕士学位。但我真的想先进入职场。 这个计划有多现实或不现实？    提交人    /u/OfficialCARD00R   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h5hta4/give_me_the_harsh_reality_of_wanting_to_be_a/</guid>
      <pubDate>Tue, 03 Dec 2024 07:09:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>