<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 06 Jan 2025 15:17:24 GMT</lastBuildDate>
    <item>
      <title>数据在哪里变成人工智能？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hv15tf/where_data_becomes_ai/</link>
      <description><![CDATA[在 AI 架构中，您如何区分原始数据和可以称为“人工智能”的东西？这全都与训练阶段有关，即学习模式的阶段？还是从更早的时候就开始了，比如在数据预处理或特征工程期间？ 我读过几篇论文，但我对那些积极从事 LLM 或其他高级模型工作的人们在现实世界中的实践和观点很好奇。您如何定义数据不再只是数据并开始变得“​​智能”的那一刻？    提交人    /u/Kelly-T90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hv15tf/where_data_becomes_ai/</guid>
      <pubDate>Mon, 06 Jan 2025 15:10:08 GMT</pubDate>
    </item>
    <item>
      <title>需要在机器学习领域提高薪水</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hv0q4r/need_to_increase_my_salary_in_ml_domain/</link>
      <description><![CDATA[嗨！我今年 24 岁，目前是一名机器学习工程师，CTC 为 8L。 在 MLE 之前是 SWE。 我的工作生活平衡得很好，团队成员也都很好。 但是我有一些财务需求，我的薪水不够。 我从 Krish naik 的 ml 课程和 youtube（campus x、3blue1brown、statquest、freecodecamp）学习了 ml 和 dl 中的所有主要算法 监督（ML）：1. 线性 reg 2. 对数 reg 3. Svm 4. Knn 5. 朴素贝叶斯 6. 决策树 7. 随机森林。 8. Xgboost 无监督（ML） 9. PCA 10. DBSCAN 11. K MEANS NLP 概念：1. BOW 2. TF IDF 3. WORD2VEC 深度学习架构：1. ANN 2. RNN 3. LSTM 4. 双向 rnn 5. 编码器，解码器 6. CNN（我对此有很好的直觉）7. Transformers（主要学习了注意力机制的工作原理）8. RAG 我花了一年多的时间慢慢学会了这些。 我擅长 SWE 和 python，对所有这些主题只有数学直觉。但是，如果可以为这些模型编写代码，我就缺乏对所有这些主题的实践经验。 害怕在这个就业市场中转换。我的公司不会给我加那么多工资。 我应该如何继续才能在这个领域获得最高的薪水？    提交人    /u/Sufficient_Web_309   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hv0q4r/need_to_increase_my_salary_in_ml_domain/</guid>
      <pubDate>Mon, 06 Jan 2025 14:51:00 GMT</pubDate>
    </item>
    <item>
      <title>ROCM RX6800 崩溃</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hv0kw3/rocm_rx6800_crashing/</link>
      <description><![CDATA[因此，我最近从 nvidia 切换到 amd，并尝试在 ubuntu 上的 pytorch 中设置 ROCM。一切似乎都正常，它可以检测到 gpu 并可以执行张量计算。但是，一旦我加载我的代码，我曾经用这个 amd gpu 在我的 1660 上训练模型，它就会使整个 ubuntu 操作系统崩溃。它打印出 cuda 可用开始训练，我看到 gpu 使用率增长，大约 5 分钟后它崩溃了。我甚至无法记录错误来查看为什么会发生这种情况。如果有人遇到类似的问题并知道如何解决它，我将不胜感激。    提交人    /u/XRoyageX   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hv0kw3/rocm_rx6800_crashing/</guid>
      <pubDate>Mon, 06 Jan 2025 14:44:22 GMT</pubDate>
    </item>
    <item>
      <title>计算大数据的 LOF</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hv05hi/calculating_lof_for_big_data/</link>
      <description><![CDATA[您好， 我有一个大数据集（数亿条记录，数十 GB），我想对异常检测问题执行 LOF（出于学术目的测试不同的方法）对该数据集进行训练，然后在较小的标记数据集上进行测试以检查方法的准确性。由于很难一次容纳所有数据，是否有任何实现允许我分批训练它？你会怎么做？    提交人    /u/Wikar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hv05hi/calculating_lof_for_big_data/</guid>
      <pubDate>Mon, 06 Jan 2025 14:24:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta 的 LCM（大型概念模型）：改进的 LLM，用于输出概念，而不是标记</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huyyny/metas_lcms_large_concept_models_improved_llms_for/</link>
      <description><![CDATA[因此，Meta 最近发表了一篇关于 LCM 的论文，该论文可以一次输出整个概念，而不仅仅是一个标记。这个想法非常有趣，可以支持任何语言、任何模态。请在此处查看更多详细信息：https://youtu.be/GY-UGAsRF2g    提交人    /u/mehul_gupta1997   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huyyny/metas_lcms_large_concept_models_improved_llms_for/</guid>
      <pubDate>Mon, 06 Jan 2025 13:27:29 GMT</pubDate>
    </item>
    <item>
      <title>优化衍生品</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huxnd4/optimized_derivatives/</link>
      <description><![CDATA[我自己计算了交叉熵损失、softmax 等的导数（或梯度），发现这些导数实际上是正确的。但是当我尝试编写所有代码时，我发现上述每个函数都有优化版本。例如：d cross entropy /d softmax = -1/softmax 但是当我尝试编写代码时，我得到了：d cross entropy /d softmax = y_true - y_predicted（或类似的东西） 我不太明白，如果有人能向我解释上述导数和其他导数是如何转换的，我将不胜感激。    提交人    /u/heinzen_leo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huxnd4/optimized_derivatives/</guid>
      <pubDate>Mon, 06 Jan 2025 12:14:00 GMT</pubDate>
    </item>
    <item>
      <title>𝗢𝗯𝗷𝗲𝗰𝘁 𝗗𝗲𝘁𝗲𝗰𝘁𝗶𝗼𝗻 𝘄𝗶𝘁𝗵 𝗢𝗿𝗶𝗲𝗻𝘁𝗲𝗱 𝗕𝗼𝘂𝗻𝗱𝗶𝗻𝗴 𝗕𝗼𝘅𝗲𝘀</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huxekw/𝗢𝗯𝗷𝗲𝗰𝘁_𝗗𝗲𝘁𝗲𝗰𝘁𝗶𝗼𝗻_𝘄𝗶𝘁𝗵_𝗢𝗿𝗶𝗲𝗻𝘁𝗲𝗱_𝗕𝗼𝘂𝗻𝗱𝗶𝗻𝗴_𝗕𝗼𝘅𝗲𝘀/</link>
      <description><![CDATA[      定向边界框 传统的物体检测通常依赖于矩形边界框来定位物体。虽然在许多情况下这些边界框很有效，但对于偏离矩形形状、具有较大纵横比或以一定角度定向的物体，这些边界框可能会变得效率低下。对于此类场景，矩形框往往会捕获过多的非对象数据，从而降低其精度和实用性。 为了应对这一挑战，𝗼𝗿𝗶𝗲𝗻𝘁𝗲𝗱 𝗯𝗼𝘂𝗻𝗱𝗶𝗻𝗴 𝗯𝗼𝘅𝗲𝘀 (𝗢𝗕𝗕𝘀) 提供了一种强大的替代方案。通过与对象的方向和形状对齐，OBB 最大限度地减少了不相关背景的包含，从而提高了检测系统的准确性和有效性。 在最近的一次实施中，我 (Pritam Kudale) 利用 OBB 来检测卡巴迪比赛中的数字板。考虑到这些板的角度定位和非矩形形状，OBB 被证明是比传统矩形框更合适的选择。 您对在这种特殊场景中使用 OBB 或分割等高级边界技术有何看法？我很想听听您的观点！ 我们的未来 我仍然面临一个问题，即定向边界框仍然无法解决所有问题，因为在检测地面时，它不是定向矩形。还可以使用什么其他方法？细分会不会太昂贵？    submitted by    /u/Ambitious-Fix-3376   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huxekw/𝗢𝗯𝗷𝗲𝗰𝘁_𝗗𝗲𝘁𝗲𝗰𝘁𝗶𝗼𝗻_𝘄𝗶𝘁𝗵_𝗢𝗿𝗶𝗲𝗻𝘁𝗲𝗱_𝗕𝗼𝘂𝗻𝗱𝗶𝗻𝗴_𝗕𝗼𝘅𝗲𝘀/</guid>
      <pubDate>Mon, 06 Jan 2025 11:59:19 GMT</pubDate>
    </item>
    <item>
      <title>Gemini LLM API 完整指南：从设置到高级功能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huwdb5/complete_guide_to_gemini_llm_api_from_setup_to/</link>
      <description><![CDATA[       由    /u/datageekrj  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huwdb5/complete_guide_to_gemini_llm_api_from_setup_to/</guid>
      <pubDate>Mon, 06 Jan 2025 10:49:53 GMT</pubDate>
    </item>
    <item>
      <title>OCR 如何工作以及如何将其应用于字体？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huw1bk/how_does_ocr_work_and_how_can_i_apply_it_to_fonts/</link>
      <description><![CDATA[在我的案例中具体来说是 PaddleOCR。对 ML 来说完全是新手。  您是在一致大小的数据上训练模型的，对吗？那么他们如何在一张图像中获取所有不同颜色的所有图像大小以及不同位置的多个文本？ 此外，如果数据图像每张图像只有 10 个字符，它如何检测多于或少于 10 个字符的文本行和边界框？ 尝试训练基于 Google 字体的字体检测模型，但不知道该怎么做。如何获取所有语言所有样式的所有字体的数据，以及它如何对从 OCR 中找到的文本起作用？尝试做 OCR -&gt;字体模型 这里的数字是什么意思：https://github.com/google/fonts/blob/main/tags/all/families.csv     提交人    /u/Relative-Pace-2923   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huw1bk/how_does_ocr_work_and_how_can_i_apply_it_to_fonts/</guid>
      <pubDate>Mon, 06 Jan 2025 10:26:28 GMT</pubDate>
    </item>
    <item>
      <title>在成为 ML 工程师之前，我是否需要先担任软件工程师？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huqs27/do_i_need_to_work_as_a_software_engineer_first/</link>
      <description><![CDATA[我正在攻读计算机科学学士学位，基本上我想问的是，在进入 ML 之前，我是否需要先建立传统的软件工程经验？ 然后，我再次看到具有商业或化学/机械/土木工程等背景的人学习机器学习，这怎么可能呢？我认为你至少应该拥有一些计算机相关课程的学士学位？ 无论如何，当谈到编程技能和数据结构和算法时，我是否需要达到 FAANG 有志者的水平，他们基本上是具有丰富数据结构和算法知识的 leetcode 猴子，才能成为一名机器学习工程师？ 我该如何在 DSA / leetcode monkey 方面变得如此强大，然后学习成为一名机器学习工程师？仅 DSA/leetcode FAANG 级别所需的时间和奉献精神就令人难以置信。    提交人    /u/Comfortable-Unit9880   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huqs27/do_i_need_to_work_as_a_software_engineer_first/</guid>
      <pubDate>Mon, 06 Jan 2025 04:28:13 GMT</pubDate>
    </item>
    <item>
      <title>集成模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huo0mk/ensemble_model/</link>
      <description><![CDATA[      嗨！我正在尝试使用经典 ML 为 CIFAR 10 数据集创建一个集成模型，作为我的课程项目。我使用 SVM、NKK、随机森林和梯度提升创建了一堆模型，使用数据集的 HOG 特征进行训练，采用不同的提取方法，应用 openCV 的 grabcut 算法并跳过结果中的全黑图像，然后提取其灰度、RGB 中的 HOG 特征并使用增强，总共为集成模型创建了 12 个模型。结果中最好的模型得分为 52%，平均值约为 46%，但集成模型的准确率为 36%。我使用混淆矩阵来计算每个类别的模型准确率，而不是采用每个模型的总体准确率，认为这会有所帮助。有人可以告诉我如何提高集成模型得分吗？    提交人    /u/MakinaDeFuego6942   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huo0mk/ensemble_model/</guid>
      <pubDate>Mon, 06 Jan 2025 02:05:52 GMT</pubDate>
    </item>
    <item>
      <title>Vertex AI Pipelines 迷你教程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1humyfh/vertex_ai_pipelines_mini_tutorial/</link>
      <description><![CDATA[大家好！ 请查看 4 课 Vertex AI 管道教程的第一个视频。 本教程将包含 4 个章节：  ML 基础知识。使用 scikit-learn 管道预处理特征，并训练 xgboost 模型 模型注册和版本控制。 Vertex AI 管道。 DSL、组件和仪表板。 Github Actions CI/CD 与 Vertex AI 管道。  https://youtu.be/9FXT8u44l5U?si=GSxQYQlVICiz91sA    提交人    /u/nepherhotep   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1humyfh/vertex_ai_pipelines_mini_tutorial/</guid>
      <pubDate>Mon, 06 Jan 2025 01:14:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 4gb GPU 可以进行 LLM 研究吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1huhmk4/is_it_possible_to_do_llm_research_with_a_4gb_gpu/</link>
      <description><![CDATA[大家好，社区！ 正如标题所示，使用 4GB RTX 3050 Ti、i7 处理器和 16GB RAM 进行 LLM 研究是否可行？ 我目前正在研究 transformer 的工作原理，并希望开始亲自动手进行实验。是否有任何非常轻量级的开源 LLM 可以在这些规格上运行？如果有，您会推荐哪种型号？ 我之所以问这个问题，是因为我想从我拥有的资源开始，并尽可能少地在云计算上花钱。    提交人    /u/angry_gingy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1huhmk4/is_it_possible_to_do_llm_research_with_a_4gb_gpu/</guid>
      <pubDate>Sun, 05 Jan 2025 21:19:31 GMT</pubDate>
    </item>
    <item>
      <title>掌握数学的 10 个 GitHub 存储库</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hu8iq3/10_github_repositories_to_master_math/</link>
      <description><![CDATA[        提交人    /u/kingabzpro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hu8iq3/10_github_repositories_to_master_math/</guid>
      <pubDate>Sun, 05 Jan 2025 14:45:56 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>