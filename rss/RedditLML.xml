<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 12 May 2024 06:18:23 GMT</lastBuildDate>
    <item>
      <title>无代码或低代码微调工具</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cq10m1/no_code_or_low_code_fine_tuning_tool/</link>
      <description><![CDATA[您好，我正在考虑对 Gemini 1.5 或 GPT4 进行微调。有哪些工具：  无代码或低代码 开源或低成本 与 M1 Macbook Air 兼容  谢谢   由   提交/u/Fr33-Thinker  /u/Fr33-Thinker  reddit.com/r/learnmachinelearning/comments/1cq10m1/no_code_or_low_code_fine_tuning_tool/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cq10m1/no_code_or_low_code_fine_tuning_tool/</guid>
      <pubDate>Sun, 12 May 2024 05:58:15 GMT</pubDate>
    </item>
    <item>
      <title>抱脸+Langchain+Upwork |如何解决现实世界的人工智能工作。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cq0nsb/hugging_face_langchain_upwork_how_to_solve_real/</link>
      <description><![CDATA[（1）抱脸+Langchain+Upwork |如何解决现实世界的人工智能工作。 - YouTube   由   提交 /u/Honest-Worth3677    reddit.com/r/learnmachinelearning/comments/1cq0nsb/hugging_face_langchain_upwork_how_to_solve_real/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cq0nsb/hugging_face_langchain_upwork_how_to_solve_real/</guid>
      <pubDate>Sun, 12 May 2024 05:34:11 GMT</pubDate>
    </item>
    <item>
      <title>对 NLP 中 Hugging Face 中的所有这些 Transformer 模型感到不知所措“[讨论]”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cq03dp/feeling_at_a_loss_with_all_these_transformer/</link>
      <description><![CDATA[“[讨论]” 最近开始做NLP项目，目前正在做这个kaggle竞赛“作文评分分类问题”。我正在查看其他代码，并决定使用三种技术 - 一种使用机器学习模型，一种使用 Huggingface Transformer，一种使用 Facebook 的 fasttext（听说他们擅长获取异常值或不常见的同义词）。 虽然 fasttext 的文档和代码源很少；相反，看到 Huggingface 中用于文本分类的所有这些 Transformer 预训练模型，我感到迷失！ 我应该选择哪个模型？起初，我的选择标准是基于这些变压器提供的自动标记化方法。但现在我一直在思考我应该考虑哪些其他参数（我暂时正在使用 NLTK 的基本标记化）。我的意思是让我们考虑计算机视觉。如果我想开发一个人脸识别系统，首先YOLO的版本将是典型的方法，如果我的图像样本很少，那么很少有镜头学习的机会。 但是文本呢？我有近 17000 个样本需要训练，总共大约有 3,55,00,000 个单词。我当时正在考虑实施 distilberta（拼写可能是错误的），然后它就出现在我的脑海中；好吧，我为什么要使用这个呢？我只是不知道！   由   提交/u/Bonito_Flakez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cq03dp/feeling_at_a_loss_with_all_these_transformer/</guid>
      <pubDate>Sun, 12 May 2024 04:57:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用pytorch计算矩阵和向量的部分积？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpznci/how_to_use_pytorch_to_compute_partial_products_of/</link>
      <description><![CDATA[我想实现一个速度快且 GPU 内存使用量较低的 MoE 模型，我遇到的问题可以通过以下方式抽象：  假设A[1:1024][1:1024]是一个矩阵，b[1:1024]是一个向量，c[1:1024]是一个稀疏向量，最多有100个非零元素。我需要计算由 d[i]=(A*b)[i] * c[i] 定义的 d[1:1024]。 对于固定的 A，我需要许多对 ( b,c)，计算 d。如何利用cuda的并行能力，在pytorch下计算d？ 取A的右行组成一个新的矩阵？这可能很快，但会使用大量不必要的 GPU 内存，并使最大可能的批量大小太小。 使用 for 循环在正确的索引上一一计算 d 的元素？这样可以节省gpu内存，但是速度太慢。 如何既节省内存又快？   由   提交/u/test_alpha0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpznci/how_to_use_pytorch_to_compute_partial_products_of/</guid>
      <pubDate>Sun, 12 May 2024 04:29:22 GMT</pubDate>
    </item>
    <item>
      <title>我的预测变成白色:(</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpx82e/my_predictions_fade_to_white/</link>
      <description><![CDATA[当前正在创建 ConvLSTM，并想知道为什么我的预测会变成白色？我的模型将帧序列作为输入，并将预测帧附加到输入序列上，删除旧帧作为下一个预测的输入。    由   提交/u/JoJoeNathan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpx82e/my_predictions_fade_to_white/</guid>
      <pubDate>Sun, 12 May 2024 02:08:42 GMT</pubDate>
    </item>
    <item>
      <title>寻找串行输入\串行输出实时自适应学习工具链</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpvqvn/looking_for_a_serial_inserial_out_realtime/</link>
      <description><![CDATA[我有一组 PID 系数，需要自动适应不断变化的条件。我有通过串行 UART 连接输出的错误值，并且我希望能够通过 UART 将调整后的系数值发送回，以使错误值最小化。我需要将其形成 Keras 或 Tensorflow DL 模型，以便在 STM32 上运行它。  是否有一个工具链可以像这样通过简单的实时串行 I\O 进行操作，从而生成我需要的深度学习模型？  &amp; #32；由   提交/u/WhoEvenThinksThat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpvqvn/looking_for_a_serial_inserial_out_realtime/</guid>
      <pubDate>Sun, 12 May 2024 00:47:54 GMT</pubDate>
    </item>
    <item>
      <title>需要建议：继续使用 HMM 进行语音二值化项目还是改用现代技术？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpqkcb/advice_needed_continue_speech_diarization_project/</link>
      <description><![CDATA[我最近在佐治亚理工学院完成了人工智能课程，我想将我所学到的知识应用到个人项目中。我最初的想法是使用隐马尔可夫模型（HMM）实现语音二值化模型。然而，在我的研究过程中，我发现一些资源表明现代语音识别已在很大程度上从 HMM 转向基于神经网络的方法（深度学习）。 鉴于此，我正处于十字路口，可以使用一些建议：  继续使用 HMM：学习和实现我自己的 HMM 可以让我对概率模型和序列分析有深入的了解。然而，我担心它可能会关注过时的技术。我的目标是将这种经验转化为实际产品的工作。  切换到神经网络：这意味着深入研究更现代和相关的技术，例如 CNN、RNN，甚至探索涉及 Transformer 和端到端模型的更新架构。这些都是我还没有正式了解的主题。学习曲线比较陡峭，但从长远来看，这可能对我的职业生涯更有利。  您认为什么对崭露头角的人工智能专业人士更有利？我应该坚持基础知识并建立对传统方法的深入理解，还是应该投入时间掌握更前沿的技术？反馈将非常有帮助。 感谢您的帮助！   由   提交/u/thrick77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpqkcb/advice_needed_continue_speech_diarization_project/</guid>
      <pubDate>Sat, 11 May 2024 20:34:48 GMT</pubDate>
    </item>
    <item>
      <title>不同语言的情感分析。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpqhap/sentiment_analysis_for_different_languages/</link>
      <description><![CDATA[我想创建一个模型来标记一些特定数据到他们的情绪：“中立”、“积极”和“积极”。或“阴性”。一个相当标准的练习。问题是我的数据是西班牙语，所以当我想要对我的输入进行标记时，huggingface.co (distilbert) 的标记生成器会将像“comer”这样的原子词拆分为“comer”。分成 2 个标记 [“come”, “##r”]。我的问题是，这种分裂是否会使模型不准确，或者是否无关紧要。或者是否有针对不同语言的分词器？   由   提交 /u/Equal-Magazine-9921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpqhap/sentiment_analysis_for_different_languages/</guid>
      <pubDate>Sat, 11 May 2024 20:30:52 GMT</pubDate>
    </item>
    <item>
      <title>在 NumpY 中从头开始的机器学习算法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpq45t/machine_learning_algorithms_from_scratch_in_numpy/</link>
      <description><![CDATA[我喜欢从头开始了解各种算法如何使用 NumPy 工作。 是否有实现某些（仅用 python 和 numpy 即可实现逻辑回归、线性、卷积、RNN 等）？   由   提交 /u/GuyTorbet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpq45t/machine_learning_algorithms_from_scratch_in_numpy/</guid>
      <pubDate>Sat, 11 May 2024 20:13:44 GMT</pubDate>
    </item>
    <item>
      <title>机器学习社区网站</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpmsfd/machine_learning_community_website/</link>
      <description><![CDATA[您好，有没有人对 ML 感兴趣并想展示自己的技能并与其他人分享 我是创建网站（针对感兴趣的人）我想要：  Web 开发人员 UX UI 设计师 营销专家（seo、sem） 网络安全专家  如果您相信自己有能力并且很兴奋，请随时联系 be 以获取有关该项目的更多信息   由   提交 /u/GingSkywalker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpmsfd/machine_learning_community_website/</guid>
      <pubDate>Sat, 11 May 2024 17:37:22 GMT</pubDate>
    </item>
    <item>
      <title>[ML] ML 理论方法与基于应用的方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpk9vl/ml_ml_theoretical_approach_vs_application_based/</link>
      <description><![CDATA[这是一个询问机器学习或强化学习科目的基于理论/数学的途径的问题： 您可以吗概述涵盖机器学习和强化学习的理论和数学基础的课程或课程路径？我正在寻找深入研究这些领域背后的理论基础、概率模型、优化技术和数学分析的主题，而不仅仅是关注应用算法或编码实现。目标是在转向更实际的应用之前建立强大的理论掌握。   由   提交/u/Background_Bowler236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpk9vl/ml_ml_theoretical_approach_vs_application_based/</guid>
      <pubDate>Sat, 11 May 2024 15:41:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 Riva 的 TTS 语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphgsj/language_model_for_tts_using_riva/</link>
      <description><![CDATA[您好，前段时间我创建了一个意大利语数据集来训练 tacotron2 模型。实验进行得不太顺利，我想再次尝试生成模型，这次使用 Nvidia Riva。然而，在阅读了文档并了解了自己之后，我仍然不太清楚应该如何继续。有做过类似事情的人有什么建议或者可以给我指点详细的指南吗？ 非常感谢！    ;由   提交/u/Il_Filosofo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphgsj/language_model_for_tts_using_riva/</guid>
      <pubDate>Sat, 11 May 2024 13:25:37 GMT</pubDate>
    </item>
    <item>
      <title>上下文窗口是 LLM 最终用户应该关心的方面之一。在类似于 ChatGPT 的应用程序中还有哪些其他方面需要注意？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphgl2/context_window_is_one_of_the_aspects_that_llm/</link>
      <description><![CDATA[我正在寻找使用该工具时容易了解的方面。例如，上下文窗口是我可以理解的一个特性，因为我尝试在 ChatGPT 上做很多事情并经历了该限制。 还有哪些其他限制或可以与上下文窗口一起分类的方面？ ？ 谢谢。   由   提交 /u/FreewillMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphgl2/context_window_is_one_of_the_aspects_that_llm/</guid>
      <pubDate>Sat, 11 May 2024 13:25:18 GMT</pubDate>
    </item>
    <item>
      <title>微软和清华大学的这篇 AI 论文介绍了 YOCO：一种用于语言模型的解码器-解码器架构</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpe7s3/this_ai_paper_by_microsoft_and_tsinghua/</link>
      <description><![CDATA[       由   提交/u/ashioyajotham   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpe7s3/this_ai_paper_by_microsoft_and_tsinghua/</guid>
      <pubDate>Sat, 11 May 2024 10:13:29 GMT</pubDate>
    </item>
    <item>
      <title>无法理解 Andrew ng 的 ML 简介课程 2 中发生的情况</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpds6t/cant_understand_whats_happening_in_andrew_ngs/</link>
      <description><![CDATA[我正在尝试一个名为“使用 Tensorflow 实现咖啡烘焙”的实验室，但我无法理解发生了什么。这是供您参考的实验 https://github.com/greyhatguy007/Machine-Learning-Specialization-Coursera/blob/main/C2%20-%20Advanced%20Learning%20Algorithms/week1/Optional-labs /C2_W1_Lab02_CoffeeRoasting_TF.ipynb 来源：greyhatguy007  我不明白这些函数是什么，它们在做什么，我们为什么调用它们，什么是纪元，为什么是模型摘要等。因为本课程尚未涵盖这些内容  有人可以建议我现在应该做什么吗？ （我已经达到了课程的这一点，不再进一步)   由   提交 /u/Weak_Display1131   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpds6t/cant_understand_whats_happening_in_andrew_ngs/</guid>
      <pubDate>Sat, 11 May 2024 09:42:45 GMT</pubDate>
    </item>
    </channel>
</rss>