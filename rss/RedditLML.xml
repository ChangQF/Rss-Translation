<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 02 Dec 2024 06:27:23 GMT</lastBuildDate>
    <item>
      <title>运行 10 种不同的 nerf/3dgs 方法会对我有帮助吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4oany/is_running_10_different_nerf3dgs_methods_gonna/</link>
      <description><![CDATA[我加入了大学的本科研究项目。我和我的 3 人团队必须收集大量具有不同光照条件等的物体视频，并对它们运行 nerf/3dgs。如你所知，研究人员在论文被接受后不会维护代码，因此，我必须运行 docker 来让它们运行。（顺便说一句，nerfstudio 根本不起作用）此外，还有太多错误，所以我必须自己阅读代码并修复错误。另外两个团队成员根本没有做出任何贡献。他们实际上什么都不做，所以我不得不自己做所有这些事情。现在我的教授要求我们通读代码并插入自定义相机位置以测试靠近地面真实图像的新型视图合成。这意味着我必须比自己更了解研究人员编写的糟糕代码......她要求我获得 PSNR/LPIPS 等，但那部分不会太难。 我问我的教授这是否会被发表，她告诉我这个项目缺乏新颖性，所以可能不会被发表。她告诉我这个项目是为了让她更好地理解这些模型，仅此而已。 我原本对 3d 重建和新颖的视图合成很感兴趣，但这个项目让我讨厌它。这只是一项苦差事，没有真正新颖的想法可以尝试，而且占用了我太多的时间。我最近和我真正想一起工作的教授谈过，他告诉我，如果我下学期在他的课上表现出色，他会让我进他的实验室，我担心这个项目，我不再有激情，会浪费我太多的时间，而这些时间最好花在好好上课上…… 你怎么看？我是否应该每周投入 20 多个小时以及整个寒假的时间来做这个项目，而这个项目只能增强教授的实践知识，而完全没有队友的帮助？ * 我的时间很紧，所以我没有足够的时间掌握模型的基础，只能多次浏览论文来理解代码    提交人    /u/gobears789123   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4oany/is_running_10_different_nerf3dgs_methods_gonna/</guid>
      <pubDate>Mon, 02 Dec 2024 05:59:48 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮忙改进这个代码吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4nmmy/can_someone_help_improve_this_code/</link>
      <description><![CDATA[from datasets import load_dataset from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments,Seq2SeqTrainingArguments # 1. 加载数据集 dataset = load_dataset(&quot;rahular/itihasa&quot;) # 示例：英语-德语翻译 train_data = dataset[&quot;train&quot;] val_data = dataset[&quot;validation&quot;] # 2. 加载预训练的标记器和模型 model_name = &quot;t5-small&quot; tokenizer = T5Tokenizer.from_pretrained(model_name) model = T5ForConditionalGeneration.from_pretrained(model_name) # 3. 预处理数据 def preprocess_data(examples): # 正确访问翻译数据 input = [f&quot;translate English to sanskrit: {example[&#39;en&#39;]}&quot;例如在示例[&quot;translation&quot;]]中 # 正确访问目标翻译，使用 ru 而不是 de target = [example[&#39;sn&#39;] 例如在示例[&quot;translation&quot;]]中 model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=&quot;max_length&quot;) labels = tokenizer(targets, max_length=128, truncation=True, padding=&quot;max_length&quot;) model_inputs[&quot;labels&quot;] = labels[&quot;input_ids&quot;] return model_inputs train_data = train_data.map(preprocess_data, batched=True) val_data = val_data.map(preprocess_data, batched=True) # 4. 训练设置 training_args = Seq2SeqTrainingArguments( output_dir=&quot;./results&quot;, evaluation_strategy=&quot;epoch&quot;, learning_rate=5e-5, per_device_train_batch_size=8, # 根据GPU内存增加 per_device_eval_batch_size=8, num_train_epochs=10, save_strategy=&quot;epoch&quot;, save_total_limit=3, logs_dir=&quot;./logs&quot;, predict_with_generate=True ) trainer = Trainer( model=model, args=training_args, train_dataset=train_data, eval_dataset=val_data, tokenizer=tokenizer ) # 5. 训练模型 trainer.train() # 6. 保存模型 model.save_pretrained(&quot;./translation_model&quot;) tokenizer.save_pretrained(&quot;./translation_model&quot;)  由于我有一个 Amd Radeon GPU，我正在使用 google collab，但遇到了很多运行时丢失错误。因此，如果您能以某种方式改进此代码以使其仍然正常工作。救命！    提交人    /u/Gurito_2902   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4nmmy/can_someone_help_improve_this_code/</guid>
      <pubDate>Mon, 02 Dec 2024 05:18:03 GMT</pubDate>
    </item>
    <item>
      <title>F5-TTS 在音频克隆方面被严重低估了！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4mzhq/f5tts_is_highly_underrated_for_audio_cloning/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4mzhq/f5tts_is_highly_underrated_for_audio_cloning/</guid>
      <pubDate>Mon, 02 Dec 2024 04:40:40 GMT</pubDate>
    </item>
    <item>
      <title>𝗣𝗼𝘄𝗲𝗿 𝗼𝗳 𝘃𝗲𝗰𝘁𝗼𝗿 𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴 𝗶𝗻 𝗮 𝗟𝗮𝗿𝗴𝗲 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗠𝗼𝗱𝗲𝗹</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4mu1i/𝗣𝗼𝘄𝗲𝗿_𝗼𝗳_𝘃𝗲𝗰𝘁𝗼𝗿_𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴_𝗶𝗻_𝗮_𝗟𝗮𝗿𝗴𝗲_𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲/</link>
      <description><![CDATA[      𝗣𝗼𝘄𝗲𝗿 𝗼𝗳 𝘃𝗲𝗰𝘁𝗼𝗿大型语言模型如何真正理解单词？这一切都归结于 𝘃𝗲𝗰𝘁𝗼𝗿 𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴𝘀——一种在多维空间中表示 𝘸𝘰𝘳𝘥𝘴 𝘢𝘴 𝘯𝘶𝘮𝘣𝘦𝘳𝘴 的强大方法。最初，这些向量以随机数开始，但通过深度神经网络训练，它们会演变为捕捉有意义的关系和上下文。 但要了解该向量是否真的以符合人类直觉的方式捕捉了编码的关系和语义。我们可以用一个简单的数学方程来证明这一点。  𝗞𝗶𝗻𝗴 - 𝗠𝗮𝗻 + 𝗪𝗼𝗺𝗮𝗻 = 𝗤𝘂𝗲𝗲𝗻。 这不仅仅是数学——它的意义被编码在数字中，使模型能够以令人难以置信的深度处理语言。 这就是向量嵌入的强大功能，连接数字和自然语言！ 对于任何深入研究 LLM 的人来说，理解嵌入都至关重要。我强烈推荐 Raj Dandekar 的这些富有洞察力的视频： 🔗 什么是 Token 嵌入？ https://youtu.be/ghCSGRgVB_o  🔗 位置嵌入的重要性 https://youtu.be/ufrPLpKnapU 从头开始学习 LLM：https://youtube.com/playlist?list=PLPTV0NXA_ZSgsLAr8YCgCwhPIJNNtexWu&amp;si=1S7ob8Xoxqy1UZ-r 成为 Vizuara 粉丝的不二之选！ --- 您可以在此处加入新闻通讯： https://9bfb8b39.sibforms.com/serve/MUIFAJFcOMHmiNnOggw1w5qD7tmpEtKMgA6BKj_WzggssRmgSDHoVWfB1OZOjVAB7uaJYCbWnvH-HG2NpolvOj6qHUOLkEJ5YA_cwnKeEIKulJ_h6NhvVaX9yGKM3ACtCZ5eITK80_zhvdz8uOdHfW46XkLnTiZsZzyX4nfyr6pzGMAumdmlv-UNZcYsNI5YipaBImsHcnpCeibg    提交人    /u/Ambitious-Fix-3376   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4mu1i/𝗣𝗼𝘄𝗲𝗿_𝗼𝗳_𝘃𝗲𝗰𝘁𝗼𝗿_𝗲𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴_𝗶𝗻_𝗮_𝗟𝗮𝗿𝗴𝗲_𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲/</guid>
      <pubDate>Mon, 02 Dec 2024 04:32:13 GMT</pubDate>
    </item>
    <item>
      <title>吐槽我女友的简历</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4k4xk/roast_my_gfs_resume/</link>
      <description><![CDATA[      她找工作很困难 https://preview.redd.it/k5madewwfc4e1.png?width=611&amp;format=png&amp;auto=webp&amp;s=e34890ac3081abfbc47a7f04ce8039b0f454024b    提交人    /u/Automatic_Rooster_26   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4k4xk/roast_my_gfs_resume/</guid>
      <pubDate>Mon, 02 Dec 2024 02:08:40 GMT</pubDate>
    </item>
    <item>
      <title>请嘲笑我。不要退缩。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4j96a/please_roast_me_dont_hold_back/</link>
      <description><![CDATA[        提交人    /u/AwrodHT   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4j96a/please_roast_me_dont_hold_back/</guid>
      <pubDate>Mon, 02 Dec 2024 01:24:13 GMT</pubDate>
    </item>
    <item>
      <title>寻求 LLM 超参数的学术资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4f6fo/seeking_academic_sources_for_llm_hyperparameters/</link>
      <description><![CDATA[互联网上充斥着博客和网站，它们解释了超参数（例如温度、频率惩罚、n-gram 惩罚、top-k、top-p 等）的作用和功能，但我发现自己找不到任何可靠的来源。如果您能帮助我，我将不胜感激，我已经搜索了几个小时    提交人    /u/PixelSavior   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4f6fo/seeking_academic_sources_for_llm_hyperparameters/</guid>
      <pubDate>Sun, 01 Dec 2024 22:15:49 GMT</pubDate>
    </item>
    <item>
      <title>获得人工智能认证是否值得花钱，还是自学更好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4ei32/is_getting_a_certification_in_ai_worth_the_money/</link>
      <description><![CDATA[获得 AI 认证是否物有所值，还是自学更好？我见过很多学校颁发的认证看起来很有意思，但我想知道它们是否物有所值，或者有更好的学习方法。我想为数据应用程序创建人工智能，也许可以为我的简历增添一些亮点。    提交人    /u/OrderofthePhoenix1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4ei32/is_getting_a_certification_in_ai_worth_the_money/</guid>
      <pubDate>Sun, 01 Dec 2024 21:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[要求] Arxiv 认可？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4dzed/request_arxiv_endorsement/</link>
      <description><![CDATA[大家好， 我来自慕尼黑大学，之前曾在 arXiv 的计算机视觉类别中发表过文章，现在只获得了 cs.CV 类别的认可。我的新论文“通过变形再训练增强深度学习模型的鲁棒性”更侧重于通用 AI，因此我想将其提交给 cs.AI 类别 :) 我需要获得认可才能继续。如果您符合条件，我将非常感谢您的帮助：https://arxiv.org/auth/endorse?x=ZKK9HC 如果您想联系，也可以在 LinkedIn 上找到我。提前谢谢您！    提交人    /u/AdSubstantial8986   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4dzed/request_arxiv_endorsement/</guid>
      <pubDate>Sun, 01 Dec 2024 21:24:55 GMT</pubDate>
    </item>
    <item>
      <title>古德菲洛还是毕晓普？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h46m3o/goodfellow_or_bishop/</link>
      <description><![CDATA[我最近在网站上免费找到了 goodfellows 这本书的 pdf。我通过频繁地借助其他材料完成了第一章的学习。我可以说，到目前为止，我对所教的概念已经掌握得很好了。 一位关系密切的学长建议我，如果我想快速学习，我应该选择 bishop 的书，因为它简单得多。我喜欢快速学习，但我也关心知识的强度和刚性，因为我不喜欢半生不熟的知识 那么，当我跟不上进度时，我应该继续学习并切换到 bishop 吗？或者，与 bishop 相比，学习我的 goodfellow 这本书有什么好处，是否值得付出额外的努力？ 附注：抱歉，我的英语不好，这不是我的母语    提交人    /u/Usenamenotfound404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h46m3o/goodfellow_or_bishop/</guid>
      <pubDate>Sun, 01 Dec 2024 16:10:11 GMT</pubDate>
    </item>
    <item>
      <title>需要气候数据处理方面的帮助（netCDF、Mosaic 数据集和 .CRF）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h4644f/need_help_with_climate_data_processing_netcdf/</link>
      <description><![CDATA[您好，前几天我发布了一篇关于通过 ArcGIS Pro 处理一段时间内许多气候变量的文章。我将它们下载为 .netCDF，将它们添加到 Mosaic 数据集中的项目中，然后使用聚合多维栅格工具将 MD 转换为 .CRF。这些转换似乎没有 100% 正常工作，我不明白为什么。 我完全困惑了。此外，我的项目顾问说他们不熟悉如何做到这一点，尽管他们鼓励我承担这个项目。我现在很紧张，因为这是我的论文，在这个关键的步骤上我感到完全迷失了方向。我的课程非常自学；这是一个远程研究生课程，这对我来说是最好的选择，因为我的伴侣的工作把我们带到了农村地区，所以不要给我关于学位或课程的废话。我的顾问很支持我，但这完全是从各个方面来讲的自学。 我需要的是一个可以和我一起屏幕共享这一切的人，他知道如何处理多维栅格数据并能帮助我。我对此很陌生。我的课程还没有教我如何使用 R 来检查这些文件。我花了几个月的时间学习如何使用这些工具，但我得到的输出没有意义，也不够。 由于最近的飓风以及它摧毁了我的社区，我不得不住在多个地方。我们的生活一团糟。这场风暴让我们损失了数万美元，我还因此失去了工作。 如果有人能帮助我走上正轨，我将不胜感激。非常感谢。    提交人    /u/arborealogue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h4644f/need_help_with_climate_data_processing_netcdf/</guid>
      <pubDate>Sun, 01 Dec 2024 15:47:52 GMT</pubDate>
    </item>
    <item>
      <title>适合初学者到高级人士的最佳机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h45y7o/best_machine_learning_courses_for_beginners_to/</link>
      <description><![CDATA[  由    /u/Sreeravan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h45y7o/best_machine_learning_courses_for_beginners_to/</guid>
      <pubDate>Sun, 01 Dec 2024 15:40:25 GMT</pubDate>
    </item>
    <item>
      <title>吐槽我的简历：为什么我没有入围？帮我解决这个问题！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h43522/roast_my_resume_why_am_i_not_getting_shortlisted/</link>
      <description><![CDATA[        提交人    /u/Altruistic-Cress-828   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h43522/roast_my_resume_why_am_i_not_getting_shortlisted/</guid>
      <pubDate>Sun, 01 Dec 2024 13:20:48 GMT</pubDate>
    </item>
    <item>
      <title>您需要的 Scikit 学习 ML 算法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h3gn3x/scikit_learn_ml_algorithms_u_need/</link>
      <description><![CDATA[        提交人    /u/sonofthegodd   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h3gn3x/scikit_learn_ml_algorithms_u_need/</guid>
      <pubDate>Sat, 30 Nov 2024 16:47:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>