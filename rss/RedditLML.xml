<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 12 Jul 2024 12:28:47 GMT</lastBuildDate>
    <item>
      <title>这个视频是真实的还是 AI 的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1g1i6/is_this_video_real_or_ai/</link>
      <description><![CDATA[        提交人    /u/29PiecesOfSilver   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1g1i6/is_this_video_real_or_ai/</guid>
      <pubDate>Fri, 12 Jul 2024 12:08:07 GMT</pubDate>
    </item>
    <item>
      <title>什么是 Flash Attention？解释一下</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1do1w/what_is_flash_attention_explained/</link>
      <description><![CDATA[本教程讲解了 Flash Attention，它是对标准 Attention 机制的改进，通过平铺和其他技术提高了空间和时间复杂度：https://youtu.be/znhk2mgplWY?si=ygXjaw3RWfghbKa-    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1do1w/what_is_flash_attention_explained/</guid>
      <pubDate>Fri, 12 Jul 2024 09:46:28 GMT</pubDate>
    </item>
    <item>
      <title>决策树的纯度和大小是什么意思？请解释一下这个选项🤔</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1cr00/what_do_you_mean_by_purity_and_size_for_a/</link>
      <description><![CDATA[Purity = 1.最小叶节点大小（min_samples_leaf）2.最小分割大小（min_samples_split）3.min_weight_fraction_leaf 4.min_impurity_decreass 5.其他：请指定 Size = 1.树的深度（max_depth）2.最小叶节点大小（min_samples_leaf）3.max_leaf_nodes 4.其他：请指定 参考库：https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html   由    /u/Psyd_ck  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1cr00/what_do_you_mean_by_purity_and_size_for_a/</guid>
      <pubDate>Fri, 12 Jul 2024 08:44:28 GMT</pubDate>
    </item>
    <item>
      <title>在混淆矩阵中对最常混淆的用户进行分组的方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1clk8/way_to_group_most_commonly_confused_users_in_a/</link>
      <description><![CDATA[对于我的学士论文，我正在研究一个 ML 项目来识别不同的 EV 驾驶员。我现在已经完成了这项工作，为了进一步分析，我想看看某些用户是否更容易相互混淆，并将他们分组在一起，以最能提高我的准确性，如果这种方法有效，这可能表明他们拥有同一辆车。有没有可以为我做到这一点的算法？    提交人    /u/Sarius2009   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1clk8/way_to_group_most_commonly_confused_users_in_a/</guid>
      <pubDate>Fri, 12 Jul 2024 08:34:02 GMT</pubDate>
    </item>
    <item>
      <title>我的新电脑适合 Amd 还是 Nvidia</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1bkk0/amd_or_nvidia_for_my_new_pc/</link>
      <description><![CDATA[我买了一台新电脑，AMD 显卡在我的预算范围内性能更出色，但如果我需要在本地运行某些东西，我不想后悔没有购买 nvidia 显卡。  我是这个领域的初学者，我不知道我是否需要在本地使用某些东西。我应该购买性能好的 AMD 显卡，还是应该购买对 DL 库和框架有更好支持的劣质 nvidia 显卡？     提交人    /u/DeliciousJello1717   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1bkk0/amd_or_nvidia_for_my_new_pc/</guid>
      <pubDate>Fri, 12 Jul 2024 07:23:55 GMT</pubDate>
    </item>
    <item>
      <title>我成为 FAANG ML 工程师时使用的免费教育 ML 资源列表</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1amzf/list_of_free_educational_ml_resources_i_used_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1amzf/list_of_free_educational_ml_resources_i_used_to/</guid>
      <pubDate>Fri, 12 Jul 2024 06:23:29 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊如何利用评论做到这一点？从评论和声明中查找与之匹配的术语？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e1acfy/how_is_amazon_doing_this_with_reviews_finding/</link>
      <description><![CDATA[我无法发布图片，因此它们在这里，https://imgur.com/a/edaiPF3 以方便您查看。 在图片中，可以看到 [&#39;质量&#39;、&#39;价值&#39;、&#39;口味&#39;、&#39;健康益处&#39;、&#39;新鲜度&#39;、&#39;成分&#39;、&#39;密封&#39;] 等术语。单击每个术语会显示所有标有该术语的评论，并且文本的相关部分会以粗体突出显示。我有几个问题：  第一张图片中的评论是关于牙膏的。诸如“对皮肤的影响”之类的术语不适用于牙膏，但与洗面奶之类的产品相关。我假设亚马逊可能会为每个产品类别维护一个固定的术语列表，并运行他们的模型来查找每个术语的匹配评论。但是，对于价格范围广泛的类别中的小众/奇特产品，某些标签适用于一种产品，但不适用于另一种产品。这表明，一个模型正在从评论本身中提取术语，而另一个模型则通过匹配的文本找到相关的声明。我可能是错的。请解释一下。我可以从哪些预先训练的模型开始（如果需要，可以进行微调）以从评论中找到这样的主题？据我所知，这也可以使用 Tf-Idf 或主题提取来完成，但提取的主题与产品相关。您如何确保相关性？ 我认为类似“facebook/bart-large-mnli”的东西被用于零样本分类来为某个术语找到匹配的评论。但是，该模型只提供蕴涵/中性/矛盾概率。我可以从哪些预先训练的模型开始（并在需要时进行微调）来标记评论并识别评论中表明存在同义词或与该术语相同的特定术语的部分？     提交人    /u/NoobLearner5475   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e1acfy/how_is_amazon_doing_this_with_reviews_finding/</guid>
      <pubDate>Fri, 12 Jul 2024 06:05:02 GMT</pubDate>
    </item>
    <item>
      <title>使用用户自定义结构化数据构建我的聊天机器人的方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e19t0g/approach_to_build_my_chatbot_using_users_custom/</link>
      <description><![CDATA[这是一个个人项目，聊天机器人的目的是回答有关用户业务的问题（例如产品、折扣、办公室）。 用户应该能够使用 mongoDB 为每个集合创建自定义字段（例如产品颜色、办公室编号浴室）。 然后聊天机器人可以回答以下问题：“产品 X 是什么颜色的？” - &quot;答案：这件 T 恤是红色的&quot; 我正在阅读有关 RAG 和矢量嵌入的文章，但我不确定如何实现它，因为我没有使用 PDF 或文本文档。 一种可能的方法是创建自定义字段的矢量嵌入并添加一些额外的上下文，因此如果用户创建了新产品，我会存储类似以下内容： { name: &quot;t-shirt&quot;, // 嵌入文本: &quot;产品名称 T 恤；说明 高品质&quot;, description: &quot;高品质&quot;, custom_fields: [ { color: &quot;red&quot;, // 嵌入文本: &quot;产品名称 T 恤；颜色 红色&quot; }, ], }  然后，我可以找到最合适的答案，例如：  &quot;这件 T 恤是什么颜色的？&quot; -&gt; &quot;产品名称 T 恤；颜色：红色 &quot;描述这件 T 恤&quot; -&gt; &quot;产品名称 T 恤；描述：高品质&quot;  最后，使用 LLM 根据正确的上下文创建更好的答案。 另一种方法可以使用知识图谱 (neo4j)。但是我注意到，此代码生成的嵌入仅嵌入了节点的属性（本例中为“name”），但没有嵌入节点的关系，因此我最终会嵌入类似“name: t-shirt”之类的内容，这不是太有用。 from langchain_community.vectorstores.neo4j_vector import Neo4jVector vector_index = Neo4jVector.from_existing_graph( embedding=embedding, url=url, username=username, password=password, index_name=index_name, node_label=&quot;Clothing&quot;, text_node_properties=[&#39;name&#39;], embedding_node_property=&#39;embedding&#39;, )  最后一种选择可能是使用 LLM 生成带有图形表示的 Cypher（或 mongoDB）查询或模式，但我宁愿使用 NLP 技术来降低成本和延迟。 我的第一种方法有意义吗？你会推荐什么？    提交人    /u/Not_a_Cake_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e19t0g/approach_to_build_my_chatbot_using_users_custom/</guid>
      <pubDate>Fri, 12 Jul 2024 05:32:06 GMT</pubDate>
    </item>
    <item>
      <title>那些已经学习过机器学习数学的人……</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e16l5k/those_who_have_learned_the_math_for_ml/</link>
      <description><![CDATA[你的步骤是什么？我学过 Lin alg 和 calc 2，现在除了很好地理解统计数据外，不知道该去哪里。     提交人    /u/Azemmol   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e16l5k/those_who_have_learned_the_math_for_ml/</guid>
      <pubDate>Fri, 12 Jul 2024 02:34:11 GMT</pubDate>
    </item>
    <item>
      <title>显然，机器学习论文很难阅读？！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e0zb0m/ml_papers_are_hard_to_read_obviously/</link>
      <description><![CDATA[我是一名本科计算机科学专业的学生，​​有时我会浏览一些论坛和机器学习社区的意见，我发现人们经常说阅读机器学习论文对他们来说很难，而他们的回答总是“机器学习论文不是为你写的”。我不明白为什么会出现这个问题，因为我确信在其他科学领域，当你还没有达到硕士或博士学位的水平时，阅读和理解论文是非常困难的。事实上，我发现与其他领域相比，阅读机器学习论文甚至更容易。 你们觉得呢？    提交人    /u/kom1323   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e0zb0m/ml_papers_are_hard_to_read_obviously/</guid>
      <pubDate>Thu, 11 Jul 2024 20:48:36 GMT</pubDate>
    </item>
    <item>
      <title>[Karpathy] 让我们重现 GPT-2（1.6B）：一个 8XH100 节点，24 小时，672 美元，在 llm.c · karpathy llm.c · 讨论 #677</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e0xozh/karpathy_lets_reproduce_gpt2_16b_one_8xh100_node/</link>
      <description><![CDATA[        提交人    /u/aifordevs   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e0xozh/karpathy_lets_reproduce_gpt2_16b_one_8xh100_node/</guid>
      <pubDate>Thu, 11 Jul 2024 19:41:53 GMT</pubDate>
    </item>
    <item>
      <title>机器学习学习伙伴</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e0t8xn/ml_study_partner/</link>
      <description><![CDATA[寻找一位认真的学习伙伴/导师，从头开始学习 ml。    提交人    /u/National-Math8836   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e0t8xn/ml_study_partner/</guid>
      <pubDate>Thu, 11 Jul 2024 16:33:54 GMT</pubDate>
    </item>
    <item>
      <title>研究人员如何确定其模型的架构和超参数？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e0t4uc/how_do_researchers_figure_out_the_architectures/</link>
      <description><![CDATA[我目前正在为我的毕业论文研究 GAN。 每篇论文/代码似乎都提供了自己的架构/超参数，但没有解释它们是如何得出的。他们只是强行计算各种可能性来找出最佳排列吗？ 如果我必须构建自己的 GAN 架构 + 选择超参数，我该怎么做？    提交人    /u/BadMeditator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e0t4uc/how_do_researchers_figure_out_the_architectures/</guid>
      <pubDate>Thu, 11 Jul 2024 16:29:03 GMT</pubDate>
    </item>
    <item>
      <title>AI/ML 的线性代数第 3 部分 – 构建图像搜索</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e0r4ma/linear_algebra_for_aiml_part_3_build_image_search/</link>
      <description><![CDATA[➡️ 文章链接：https://www.trybackprop.com/blog/linalg101/part_3_build_image_search AI/ML 系列的线性代数 101 第 3 部分。使用免费的 Google Colab 笔记本在浏览器中逐步了解如何构建图像搜索。无需进行开发设置。 在本文中，您将了解以下主题：  什么是 Google Colab？ 神经网络简介 CLIP – 对比语言-图像预训练 Imagenette – mini-ImageNet 矢量数据库 相似性搜索 余弦相似性  如果您错过了本系列的第 1 部分和第 2 部分，您可以在此处查看它们！    由   提交  /u/aifordevs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e0r4ma/linear_algebra_for_aiml_part_3_build_image_search/</guid>
      <pubDate>Thu, 11 Jul 2024 15:04:43 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>