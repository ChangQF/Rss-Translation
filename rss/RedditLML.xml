<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 17 Mar 2024 12:22:32 GMT</lastBuildDate>
    <item>
      <title>高中生学习人工智能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgvyvi/learning_ai_as_a_highschooler/</link>
      <description><![CDATA[你好！这是我第一次使用这个 Reddit 子版块，所以如果这是一个错误的 Reddit 子版块，我深表歉意（请随时将我重定向到更合适的子版块）。 这里有一些关于我的相关信息： i我目前是一名高中二年级学生，对学习人工智能/机器学习非常感兴趣。我想了解更多信息，但我不能 100% 确定我现在是否走在正确的道路上或从哪里开始。我明年将学习 calc 3 和线性代数，今年将学习概率+统计，所以我认为人工智能的数学部分对我来说非常扎实。我还计划在大学主修电气工程+计算机科学。我过去有一些编程/编码的经验（去年参加了Python课程，但忘记了大部分内容，学习了html、css和javascript的基础知识）夏天，了解 arduino + 熟悉树莓派，我的 jetson nano 几天后就会推出）。 现在，我正在读《利用 scikit-learn 和 tensorflow 进行机器学习》这本书;作者是geron aurelien，我正在学习由david malan 教授的Python 编程入门课程。我现在还应该做些什么，比如学习机器人技术？ （建造像机器人 ameca 这样的东西会非常酷：D 它对我来说非常有趣！）。我知道人工智能将成为未来的重要组成部分，所以我想尽早学习它并拥有很多相关知识，但我不确定我能够用我的知识构建哪些项目我正在学习 atm。非常感谢！   由   提交 /u/Spiritual_Swan5390   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgvyvi/learning_ai_as_a_highschooler/</guid>
      <pubDate>Sun, 17 Mar 2024 12:05:56 GMT</pubDate>
    </item>
    <item>
      <title>300 个 epoch 后使用视觉变换器模型获得 NAN。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgvr63/getting_nan_with_a_vision_transformer_model_after/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgvr63/getting_nan_with_a_vision_transformer_model_after/</guid>
      <pubDate>Sun, 17 Mar 2024 11:54:04 GMT</pubDate>
    </item>
    <item>
      <title>CNN 验证码解决“竞争”问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgvof1/cnn_captcha_solving_competition_questions/</link>
      <description><![CDATA[嗨，我是一名计算机科学学生，正在学习可选的机器学习课程。 我的老师很快将举办验证码破解马拉松。他的想法是提供一组包含 6 位数字的验证码图像及其相应的标签。我们有一周的时间来开发/训练我们自己的模型，这些模型将在比赛当天进行测试。  问题是，训练集中的每个图像的第一个数字都是 0，他强烈暗示在比赛中不会出现这种情况。我可以采取哪些策略来在训练期间缓解这种情况，以便我的模型可以检测到第一位置的其他数字？  也与位置相关，我调查后发现，我们必须使用的 CNN 应该能够提取验证码中的数字，而与位置无关。我计划在输出中使用完整的热编码，以便我有一个输出数组（位置，数字）（60 个值）。我不知道这种方法是否正确，所以也许这个方向的一些指示也可以有所帮助。  提前感谢您的回复！   由   提交 /u/RaskullQuake   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgvof1/cnn_captcha_solving_competition_questions/</guid>
      <pubDate>Sun, 17 Mar 2024 11:49:32 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习提高法学硕士的想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgvkha/an_idea_to_improve_llm_with_reinforcement_learning/</link>
      <description><![CDATA[将LLM视为环境和参与者，其中状态是问题和答案，动作是LLM生成的代币，奖励是是 log(tp)，其中 tp 是该标记的概率。使用ε-贪婪策略或其他方法探索生成令牌的策略，然后使用PPO算法更新LLM和批评家网络。使用PPO算法时，不需要更新旧的actor。 PPO算法可以保证LLM至少保持原策略的性能。因为 LLM 作为 actor 不需要折扣，所以 PPO 算法将最大化返回 log(t1p) + log(t2p) + … + log(tnp)，这相当于最大化概率 t1p*t2p … tnp 的乘积根据状态，从而改善 LLM 的答案。仅使用 LLM 生成的错误答案的问题作为初始状态。    由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgvkha/an_idea_to_improve_llm_with_reinforcement_learning/</guid>
      <pubDate>Sun, 17 Mar 2024 11:43:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 标题：考虑数据科学训练营：值得参加吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgvcva/r_title_considering_a_data_science_bootcamp_worth/</link>
      <description><![CDATA[ 由   提交 /u/Pristine_Term_7962   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgvcva/r_title_considering_a_data_science_bootcamp_worth/</guid>
      <pubDate>Sun, 17 Mar 2024 11:30:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习之旅</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgv8v9/machine_learning_journey/</link>
      <description><![CDATA[作为一名刚刚开始接触机器学习的初学者和未来的机器学习工程师。我必须尽早关注哪些事情才能帮助我做好工作准备？目前和未来几年机器学习的哪个领域需求更大？我还想知道如果我是Python编程爱好者，我可以采取哪些步骤，如何更有效地学习和理解概念？   由   提交 /u/ClassicDifferent8584   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgv8v9/machine_learning_journey/</guid>
      <pubDate>Sun, 17 Mar 2024 11:22:53 GMT</pubDate>
    </item>
    <item>
      <title>用于 AI 训练的 Nvidia 与 AMD GPU</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgv4k9/nvidia_vs_amd_gpus_for_ai_training/</link>
      <description><![CDATA[大家好，我是 reddit 和机器学习的新手。就在昨天，我完成了一场黑客马拉松，我和我的团队使用 MobileNetV2 制作了图像识别人工智能。我没有笔记本电脑，但我必须编写与人工智能相关的所有内容，并且我使用了其他笔记本电脑。我的家人已经存了钱，我的父母想为我 4 月 23 日参加的下一次编程活动买一台笔记本电脑（我想）。关键是，我想知道我是否应该购买一台 3050 或 4050（甚至 3060/4060）的笔记本电脑，或者只是使用 AnyDesk/TeamViewer 来访问我家里的计算机。 （r5 3600 和 6600 xt）我读了一些有关 TensorCores 和 Infinity Cache 的内容，但还没有得出结论。  我想，如果我要在家里远程使用 GPU，我可能不应该购买具有强大 GPU 的东西。  TLDR：我想买一台笔记本电脑，用它来编程 AI，我应该买一台 3050/4050 的笔记本电脑吗？这几代有什么区别。另外，6600 xt 对于我的用例来说是否足够强大，我是否应该购买任何笔记本电脑并远程访问我的家庭 PC？ 编辑：AMD 不太适合训练 AI，我对此有所了解。我的问题是你会使用哪一个，哪一个更适合训练 AI，桌面 6600 xt 还是移动 3050/4060/3060 或者 4060。  编辑 2：无论如何，我需要购买一台笔记本电脑，因为我不这样做我没有，但我需要一个来在学校编程、在活动/比赛中做项目等。对于我的预算，我可以买一台配备 3050、4050、3060 或 4060 的笔记本电脑。我的问题是，使用 4060（例如）进行 AI 训练是否值得，或者我应该购买一台更便宜的笔记本电脑并使用我的台式机6600 xt 远程。   由   提交 /u/NikolaAKolev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgv4k9/nvidia_vs_amd_gpus_for_ai_training/</guid>
      <pubDate>Sun, 17 Mar 2024 11:14:44 GMT</pubDate>
    </item>
    <item>
      <title>微控制器上的 ML 项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgtvb6/ml_projects_on_microcontrollers/</link>
      <description><![CDATA[是否可以使用微控制器完成任何像样的机器人/机器学习项目？微控制器的内存和计算能力较低，因此无法运行任何模型。那么，有没有办法用Arduino机器人来训练RL模型呢？或者您是否需要在研究实验室中使用超级昂贵的机器人来完成任何实际项目？   由   提交/u/open_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgtvb6/ml_projects_on_microcontrollers/</guid>
      <pubDate>Sun, 17 Mar 2024 09:49:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么在我设置 CUDA 环境后 torch.cuda.is_available() 不断返回 false（我有 Intel(R) UHD 显卡）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgtkpr/why_does_torchcudais_available_keep_returning/</link>
      <description><![CDATA[ 由   提交 /u/AshakUmesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgtkpr/why_does_torchcudais_available_keep_returning/</guid>
      <pubDate>Sun, 17 Mar 2024 09:28:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 标题：考虑数据科学训练营：值得参加吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgszq0/r_title_considering_a_data_science_bootcamp_worth/</link>
      <description><![CDATA[大家好，我目前正在考虑加入 Analytics Vidhya 的数据科学训练营，费用在 7 万到 8 万之间。我有武田制药数据分析工程师的背景，但不幸的是被解雇了。现在，我希望填补这一职业空白并提高我的技能。 任何人都可以分享他们关于 Analytics Vidhya 训练营的经验或见解吗？就训练营后的教育质量、支持和就业前景而言，是否值得进行投资？ 此外，我愿意接受其他数据科学训练营的建议，这些训练营被认为在准备方面有价值且有效从事数据科学职业。 期待听到您的想法和建议！   由   提交 /u/Pristine_Term_7962   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgszq0/r_title_considering_a_data_science_bootcamp_worth/</guid>
      <pubDate>Sun, 17 Mar 2024 08:46:53 GMT</pubDate>
    </item>
    <item>
      <title>作为本科生了解有关 ML 的更多信息</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgqgsi/learning_more_about_ml_as_an_undergrad/</link>
      <description><![CDATA[大家好， 我目前是一名大学本科生（大三），正在高年级之前尝试尽可能多的事情（还没弄清楚我想做什么）。然而，到目前为止，在我的本科阶段，我主要关注实验/湿实验室项目（我从事工程领域，因此进行了实际编程，并参加了一些数学课程，例如 Lin alg）。我还没有真正尝试过做任何计算项目。最近，我正在研究生物技术中的一些 ML/AI 应用，这看起来很酷，我确实想尝试从事 ML 相关项目，不是为了找工作，而是只是看看这是否是我想要的。  作为一个只想更多地了解 ML 并可能做一两个简单项目的人，您会推荐哪些资源？我一直在查看在线课程（例如 Coursera），但想知道是否有人对我可以从哪里开始有其他有用的资源或建议。我确实有使用 Python（numpy、matplotlib、pandas）和 R 的经验，但不知道 ML 技术背后的算法。谢谢！   由   提交 /u/chsalicia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgqgsi/learning_more_about_ml_as_an_undergrad/</guid>
      <pubDate>Sun, 17 Mar 2024 05:50:55 GMT</pubDate>
    </item>
    <item>
      <title>可视化潜在空间和动画路径的工具？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgpdde/tools_to_visualize_a_latent_space_and_animate_a/</link>
      <description><![CDATA[我找不到任何工具来为潜在空间中的路径设置动画。 GitHub 上有一些基本的可视化 https://github.com/gr-b/autoencoder-latent-space-可视化 但我觉得必须有人已经做到了   由   提交 /u/0xcedbeef   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgpdde/tools_to_visualize_a_latent_space_and_animate_a/</guid>
      <pubDate>Sun, 17 Mar 2024 04:44:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PyTorch 无法在数据中心 GPU 上实现理论最大 GEMM 速度？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgkckv/why_cant_pytorch_achieve_the_theoretical_maximum/</link>
      <description><![CDATA[我刚刚注意到一些奇怪的事情。当使用该代码在消费级 GPU（例如 2080ti、3090、4090）上进行 GEMM 测试时，它很容易达到 GEMM 操作的理论速度。然而，在数据中心 GPU（例如 V100、A100、H100）上，它只能达到理论速度的 60% 到 70% 左右，即使使用更大的矩阵也无法改善这种情况。为什么？？？ 我的理解是，对于计算量大的任务，PyTorch 会调用底层库（例如 CuBLAS、OpenMP），因此 GEMM 性能取决于这些库。鉴于数据中心 GPU 价格更高，并且可能提供更高的利润，您会期望制造商做出更多的优化工作。让我困惑的是为什么他们的性能下降。 代码： ```python import torch import time 确保使用 GPU（如果可用） device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) print(f&#39;使用设备: {device}&#39;)&lt; /p&gt; 定义矩阵的大小 n = 20000 # 矩阵的大小 (n x n) 创建随机矩阵 A = torch .rand(n, n, device=device, dtype=torch.float16) B = torch.rand(n, n, device=device, dtype=torch.float16) 预热（以确保公平时序，对于 GPU 尤其重要） for _ in range(10): _ = torch.mm(A, B) if torch.cuda.is_available(): torch .cuda.synchronize() # 等待所有内核完成（特定于 CUDA） 对矩阵乘法进行计时 start_time = time.time() C = torch.mm(A , B) if torch.cuda.is_available(): torch.cuda.synchronize() # 确保乘法完成 end_time = time.time() print(f&#39;size 矩阵乘法所用时间{n}x{n}: {end_time - start_time:.4f} 秒&#39;) print(f&quot;性能: {((2 * n3 - n2) / (end_time - start_time)) /1E12:.4f} TFLOPs”) ```   由   提交 /u/TinyStorage7916   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgkckv/why_cant_pytorch_achieve_the_theoretical_maximum/</guid>
      <pubDate>Sun, 17 Mar 2024 00:22:48 GMT</pubDate>
    </item>
    <item>
      <title>分子或分母布局在机器学习中更传统吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bgigoi/is_numerator_or_denominator_layout_more/</link>
      <description><![CDATA[（指矩阵演算分子或分母布局) 我的理解是，大多数数学和工程领域都使用分子布局，因为它更直观地映射到导数是线性运算符的想法。导数与 dx 的矩阵乘法与线性算子在 dx 上的应用相同。  分母布局的唯一优点是导数和梯度是相同的。您将节省最后一次转置操作。但现在你所有的衍生品都“倒退”了与我们期望在标量微积分中看到的相比 - 它们最终看起来像 dx f&#39;(x) 而不是 f&#39;(x) dx。  人们可以权衡文献中符号的普遍优势吗？  （FWIW 我问 Gemini 这个问题，它推荐了分母布局，然后我问了 ChatGPT，它推荐了分子布局，所以连法学硕士都不同意这一点）   由   提交 /u/dravacotron   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bgigoi/is_numerator_or_denominator_layout_more/</guid>
      <pubDate>Sat, 16 Mar 2024 22:53:39 GMT</pubDate>
    </item>
    <item>
      <title>我在 YouTube 上分享了 Python 数据科学训练营（7 个多小时、7 门课程和 3 个项目）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bg6z9e/i_shared_a_python_data_science_bootcamp_7_hours_7/</link>
      <description><![CDATA[您好，我在 YouTube 上分享了 Python 数据科学训练营。 Bootcamp 时长超过 7 个小时，共有 7 门课程、3 个项目。课程包括 Python、Pandas、Numpy、Matplotlib、Seaborn、Plotly 和 Scikit-learn。我将离开下面的链接，祝您有美好的一天！ https://www.youtube.com /watch?v=6gDLcTcePhM   由   提交/u/onurbaltaci   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bg6z9e/i_shared_a_python_data_science_bootcamp_7_hours_7/</guid>
      <pubDate>Sat, 16 Mar 2024 14:12:25 GMT</pubDate>
    </item>
    </channel>
</rss>