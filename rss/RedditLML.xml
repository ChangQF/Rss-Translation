<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 28 Nov 2023 06:18:01 GMT</lastBuildDate>
    <item>
      <title>从头开始建立法学硕士有多难？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185ormy/how_difficult_it_is_to_built_a_llm_from_scratch/</link>
      <description><![CDATA[除了计算/训练复杂性   由   提交/u/Samir925  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185ormy/how_difficult_it_is_to_built_a_llm_from_scratch/</guid>
      <pubDate>Tue, 28 Nov 2023 05:40:23 GMT</pubDate>
    </item>
    <item>
      <title>2024 年适合所有人的 12 门 Coursera 免费机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185ormf/12_best_coursera_free_courses_machine_learning/</link>
      <description><![CDATA[   /u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185ormf/12_best_coursera_free_courses_machine_learning/</guid>
      <pubDate>Tue, 28 Nov 2023 05:40:22 GMT</pubDate>
    </item>
    <item>
      <title>2024 年适合所有人的 12 门 Coursera 免费机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185orm7/12_best_coursera_free_courses_machine_learning/</link>
      <description><![CDATA[   /u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185orm7/12_best_coursera_free_courses_machine_learning/</guid>
      <pubDate>Tue, 28 Nov 2023 05:40:22 GMT</pubDate>
    </item>
    <item>
      <title>在 Transformer 模型上遇到梯度消失问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185jx2j/running_into_vanishing_gradient_on_transformer/</link>
      <description><![CDATA[大家好！抱歉，如果我在这里遗漏了一些完全明显的东西，但我在使用一个非常简单的变压器模型时遇到了一些问题，该模型正在对推文进行情感分类训练。我这样做只是作为变压器的最小可行示例，以便我可以更好地理解它们。我还使用 PyTorch 内置的 nn.Transformer。 通过阅读一些文献，我发现 Transformer 如此出色的部分原因是因为你可以使它们变得非常深，而不会遇到梯度消失的情况。然而，在我的模型中，如果我使编码器/解码器层的数量大于 1，我就会遇到梯度消失的情况（平均梯度幅度约为 1e-10 到 1e-12，并且损失根本不会减少）。当我只运行 1 层模型时，我倾向于看到平均只有 1e-8 梯度幅度，这是非常小的，但模型似乎仍在学习。 这导致我遇到第二个问题..模型确实学习了，但仅在一两个时期之后，训练和验证损失似乎出现了分歧，表明模型过度拟合。我的模型如此快地过度拟合，这似乎不太正确。 一些特别说明：我正在使用 AMP 优化。我尝试删除它，看看这是否会扰乱我的渐变。事实并非如此。 完全披露：这是一个学校项目，但我的模型的表现与我的成绩不相关。我问这个问题不是为了分数，而是因为我想了解这些东西是如何工作的以及我哪里出错了。 如果有人想查看更详细的细节，这里是代码（我会重点关注train_transformer.py、src/transformer.py和src/utils.py）https://github.com/NoahSchiro/cs448_final。有问题的数据集是 https://www.kaggle.com/code/paoloripamonti/twitter-sentiment -analysis/input 我的猜测是，变压器模型对于手头的任务来说太过强大，这就是为什么我看到非常快的收敛/梯度消失。任何帮助是极大的赞赏！    由   提交 /u/NoahSchiro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185jx2j/running_into_vanishing_gradient_on_transformer/</guid>
      <pubDate>Tue, 28 Nov 2023 01:27:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中实现软最近邻损失</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185jdzp/implementing_soft_nearest_neighbor_loss_in_pytorch/</link>
      <description><![CDATA[您好！我已经有一段时间没有写博客了。我写了两篇博客，内容如下： - 通过解缠改进 k 均值聚类： https://medium.com/@afagarap/improving-k-means-clustering-with-disentanglement-caf59a8c57bd - 在 PyTorch 中实现软最近邻损失：https://medium.com/@afagarap/implementing-soft-nearest-neighbor-loss-in-pytorch-b9ed2a371760 第一篇文章涵盖了我在 IJCNN 2020 中发表的论文，而第二篇文章是关于实现我们在参考论文中提出和扩展的损失函数的分步教程。 我希望您喜欢阅读它们。谢谢！   由   提交/u/afagarap  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185jdzp/implementing_soft_nearest_neighbor_loss_in_pytorch/</guid>
      <pubDate>Tue, 28 Nov 2023 01:02:45 GMT</pubDate>
    </item>
    <item>
      <title>关于多头LLM自我关注的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185ibbr/question_regarding_multi_head_llm_self_attention/</link>
      <description><![CDATA[ 当多头自注意力计算 Q、K 的点积并得到注意力分数时，同一个单词对齐的对角线没有有害影响，因为它是均匀分布的，但这不会与软最大尺度混淆，为什么每个单词都与自身进行比较？ （已编辑） 我们难道不想标准化相同单词计算之间的对角线吗，否则注意力分数会放大单词 -&gt;词，这会稀释注意力分数乘积？ GPT 说变压器依靠权重的差异来确定注意力模式，但它值得探索（我想特别是当变压器拾取这个值时）模式本身）？    由   提交/u/JakeN9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185ibbr/question_regarding_multi_head_llm_self_attention/</guid>
      <pubDate>Tue, 28 Nov 2023 00:14:23 GMT</pubDate>
    </item>
    <item>
      <title>2D 图像/网站/UI 中的模式识别/对象检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185hq9x/pattern_recognition_object_detection_in_2d_images/</link>
      <description><![CDATA[      我想编写一个程序，其中输入类似于网站的屏幕截图，输出是以下位置的坐标已识别的物体。例如按钮。 用例是自动化 UI 测试。 ​ https://preview.redd.it/yzj2cwnq7z2c1.png?width=2048&amp;format=png&amp;auto=webp&amp;s=e1e133a33f0c1e15b9f5eb205638d253fc 6fcdec 或者窗口按钮： ​ https://preview.redd.it/v9ypg29g9z2c1.png?width=300&amp;format=png&amp;auto=webp&amp;s=5a6fd21a4ded8c1f4bc031605922193f37b4ed08 我正在考虑使用YOLOv8，但我也认为这可能有点矫枉过正，而且旧的方法需要更少的资源并且运行推理更快。 我有什么选择？这些选项与 YOLOv8 相比如何？我认为 YOLOv8 更通用，更强大，更健壮，但资源更昂贵？ ​    ;由   提交 /u/GeniusPengiun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185hq9x/pattern_recognition_object_detection_in_2d_images/</guid>
      <pubDate>Mon, 27 Nov 2023 23:49:10 GMT</pubDate>
    </item>
    <item>
      <title>如果我有该主题的背景，我应该参加哪门 Udemy 数据科学/机器学习课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185fdac/which_udemy_data_scienceml_course_should_i_take/</link>
      <description><![CDATA[ 由   提交 /u/daymanAHAHahhhhhh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185fdac/which_udemy_data_scienceml_course_should_i_take/</guid>
      <pubDate>Mon, 27 Nov 2023 22:11:23 GMT</pubDate>
    </item>
    <item>
      <title>这个计算机视觉项目的最佳方法是什么</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185f2fo/what_would_be_the_best_approach_to_this_computer/</link>
      <description><![CDATA[构建可分析视频的非常小的细节的计算机模型的最佳方法是什么。诸如在视频中注意到小肿瘤或病变等细节。  是否可以进行实时或事后分析？什么算法最能在每一帧中有效地识别肿瘤？如果有任何帮助，我将不胜感激，谢谢   由   提交/u/the__mess1ah  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185f2fo/what_would_be_the_best_approach_to_this_computer/</guid>
      <pubDate>Mon, 27 Nov 2023 21:59:44 GMT</pubDate>
    </item>
    <item>
      <title>我可以在笔记本电脑上针对特定领域的任务微调 gpt 3.5 Turbo 模型吗？ (32GPU)</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185e9pg/can_i_finetune_gpt_35_turbo_model_for_a_domain/</link>
      <description><![CDATA[ 由   提交/u/Life_Ask2806   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185e9pg/can_i_finetune_gpt_35_turbo_model_for_a_domain/</guid>
      <pubDate>Mon, 27 Nov 2023 21:28:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性回归不能解决分类问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185cbk8/why_doesnt_linear_regression_work_on/</link>
      <description><![CDATA[你好。我是机器学习的初学者。我试图真正理解为什么线性回归不适用于分类问题。  我经常给出这样的答案：“它预测连续值”或“找到最佳拟合线”或类似的东西。  这对我来说很难直观地理解，并且我已经尝试弄清楚这一点已经超过三周了。  我正在研究泰坦尼克号数据集并尝试使用线性回归，但我什至不知道如何使其与线性回归一起工作。  我知道这不是 LR 的目的，但我只是想真正看到并理解为什么会这样。  如果可能的话，像个新手一样解释一下。没有复杂或隐性的语言   由   提交 /u/Ok_Tumbleweed8796   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185cbk8/why_doesnt_linear_regression_work_on/</guid>
      <pubDate>Mon, 27 Nov 2023 20:10:35 GMT</pubDate>
    </item>
    <item>
      <title>探索即将到来的人工智能格局</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185910n/navigating_the_ai_landscape_on_the_horizon/</link>
      <description><![CDATA[我想现在我们大多数人都听过这样一句话：“人工智能不会取代工作，懂得使用人工智能的人会取代那些会使用人工智能的人”  对于我们许多人来说，他们不是程序员或软件架构师，而是从事营销、会计、项目管理等工作的白领，我们到底应该开始学习什么？  我只能考虑了解一些基本概念（例如，什么是生成人工智能，什么是幻觉等），那里的大玩家及其关注点（例如，谁最擅长做文本）视频、图像生成等），也许还有一些关于提示优化的技巧，但仅此而已。  我没有看到差异化因素，因为所有这些都可以由任何人在一个下午学会，并且在网络上搜索“[我的职业]的人工智能最佳实践”就可以了。或者直接提示人工智能平台听起来也不太复杂。 这是全部还是我遗漏了什么？  &amp;# 32；由   提交 /u/YepYepisalifestyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185910n/navigating_the_ai_landscape_on_the_horizon/</guid>
      <pubDate>Mon, 27 Nov 2023 17:55:22 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle 比赛值得吗？ Kaggle大师的思考</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185412g/are_kaggle_competitions_worth_it_ponderings_of_a/</link>
      <description><![CDATA[ 由   提交/u/ledmmaster  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185412g/are_kaggle_competitions_worth_it_ponderings_of_a/</guid>
      <pubDate>Mon, 27 Nov 2023 14:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 GPT-4 Vision 和代理创建自动化 UI 控制器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1853i61/d_creating_an_automated_ui_controller_with_gpt4/</link>
      <description><![CDATA[嘿， 上周末，我成功地将 GPT-4 Vision 与另一个 GPT-4 和一个设备控制器合并起来工作作为使用 AutoGen 的 AutoGPT 等效项。好消息是，它不仅限于浏览器。它可以在任何 UI 窗口上运行。让我知道你们的想法以及可以做得更好的地方。 演示和方法可在以下位置获取：https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e 5e554f48a801728bfb68 我很快就会更新存储库 -&gt; https://github.com/gitlost-murali/grounded-gpt-agents &lt; /div&gt;  由   提交/u/Outlandish_MurMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1853i61/d_creating_an_automated_ui_controller_with_gpt4/</guid>
      <pubDate>Mon, 27 Nov 2023 13:56:01 GMT</pubDate>
    </item>
    <item>
      <title>🎉 机器学习爱好者的激动人心的消息！ 🚀</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/184qgua/exciting_news_for_machine_learning_enthusiasts/</link>
      <description><![CDATA[我们很高兴向社区通报 100 天代码 ML 挑战赛的最新情况。 &lt; strong&gt;我们是谁？ -我们是两名专门研究机器学习和人工智能的研究生，他们渴望深入研究各种机器学习主题和项目。 什么是 100 天编程挑战？ -承诺在 100 天内至少编写 1 小时的代码。但这不仅仅涉及编码，还涉及以创新方式学习、实验和应用机器学习。 您能期待什么？ -多样化主题：从基础算法到前沿技术。 -基于项目的学习：在现实场景中应用机器学习的实践项目。 -协作和网络：与志趣相投的人联系的机会。 我们希望您的意见！这段旅程不仅属于我们，也属于您。我们想知道： -感兴趣的主题： 您对哪些具体的 ML 主题最感兴趣？ -应用用途： &lt; p&gt;您认为 ML 是否可以对特定行业或问题产生重大影响？ 如何参与：只需按照您的意愿加入讨论即可。  &lt; li&gt;Twitter：@100daysml Reddit：r/100daysml Discord ： https://discord.com/invite/BVhwgeqy https://www.100daysofml.com  目前暂定发布日期为 2024 年 1 月 1 日。  让我们一起编码和学习！ 我们正在寻找少数人来帮助我们。如果您有兴趣，请联系ml_w0lf。  u/ml_w0lf u/vicethal    由   提交/u/ml_w0lf  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/184qgua/exciting_news_for_machine_learning_enthusiasts/</guid>
      <pubDate>Mon, 27 Nov 2023 01:05:38 GMT</pubDate>
    </item>
    </channel>
</rss>