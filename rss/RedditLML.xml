<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Sat, 08 Feb 2025 09:15:18 GMT</lastBuildDate>
    <item>
      <title>中断教练后如何发布GPU记忆？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikjahy/how_to_release_gpu_memory_after_interrupting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用 trainer 类培训一个模型Jupyter笔记本。有时，我需要使用键盘Interrupt 中断训练过程，以调整超参数，然后恢复培训。但是，我注意到当我中断培训时，GPU内存未正确发布。结果，我通常必须重新启动jupyter内核才能释放GPU内存，这很耗时，因为我需要重新加载模型并再次预处理数据集。 我已经尝试过  &gt; torch.cuda.ement_cache（）但没有帮助。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kir_aru     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikjahy/how_to_release_gpu_memory_after_interrupting/</guid>
      <pubDate>Sat, 08 Feb 2025 09:06:33 GMT</pubDate>
    </item>
    <item>
      <title>从自动编码器进行DIY对象检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikj7xp/making_an_diy_object_detection_from_an_autoencoder/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个自动编码器制作一个8x16x32滤波器地图，它在其中编码所有有关图像的东西，我如何从那里检测到实体？我正在考虑将Yolo头固定在Yolo头上，但是如何使用LSTM进行实体欺骗，但不确定  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/zazagaza213     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1ikj7xp/making_an_diy_objection_detection_from_an_autoencoder/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikj7xp/making_an_diy_object_detection_from_an_autoencoder/</guid>
      <pubDate>Sat, 08 Feb 2025 09:01:33 GMT</pubDate>
    </item>
    <item>
      <title>初学者的最佳机器学习书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikig9j/best_machine_learning_books_for_beginners_to/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/sreeravan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikig9j/best_machine_learning_books_for_beginners_to/</guid>
      <pubDate>Sat, 08 Feb 2025 08:07:46 GMT</pubDate>
    </item>
    <item>
      <title>紧急：西蒙·普林斯（Simon Prince）vs主教深度学习书，哪个是最好的选择？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikifxj/urgent_simon_prince_vs_bishop_deep_learning_book/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我目前正在参加ML/DL研究生课程，我们将Bishop的PRML用于简介主题。西蒙·普林斯（Simon Prince）的理解深度学习书籍和主教关于深度学习的最新书，哪一本最适合使用？我知道这两者都是免费的，但我需要专家意见，以节省时间不阅读两者。我的目标是建立强大的理论和实践基础，以便能够将DL应用于Pinns或Neural ODES或最新扩散模型等物理问题等物理问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/u/vegetableLatter3881     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikifxj/urgent_simon_prince_vs_bishop_deep_learning_book/</guid>
      <pubDate>Sat, 08 Feb 2025 08:07:07 GMT</pubDate>
    </item>
    <item>
      <title>Openai隐藏了O3米尼的实际思维令牌</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikh5kx/openai_is_hiding_the_actual_thinking_tokens_in/</link>
      <description><![CDATA[    -mini&quot; src=&quot;https://external-preview.redd.it/7p74lVWOq7GrqAnrRqOdU-BQFqsEnbk8XozOhsD2YQc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65833b846107b44ca5029ac644441d85516e7126&quot; title=&quot;OpenAI is hiding the actual thinking tokens在o3-mini“/&gt;   ＆＃32;提交由＆＃32; /u/u/u/kooky-somewhere-2883      link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikh5kx/openai_is_hiding_the_actual_thinking_tokens_in/</guid>
      <pubDate>Sat, 08 Feb 2025 06:38:14 GMT</pubDate>
    </item>
    <item>
      <title>对于强大的学术和实践基础，哪个是/是最好的机器学习资源？ ISLP或Andrew NG（2018- YouTube版本）还是其他一些资源？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikh58p/which_isare_the_best_machine_learning_resources/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我希望在机器学习中建立强大的学术和理论基础。我目前正在攻读硕士学位，因此一个强大的学术基础将帮助我获得更高级的课程，同时实用的基础也可以帮助我达到可以开始创建项目的水平。  我目前对Numpy，Pandas，Matplotlib和一些Scikit-Learn感到满意。我还早在2022年就做过Andrew Ng ML专业化，但是在此之后我对自己的ML技能并不十分自信。我还熟悉从Statquest指南到机器学习的机器学习概念。我最近也做过吉尔伯特·斯特朗（Gilbert Strang）的线性代数。  因此，我非常感谢有关标题中提到的资源或其他更好资源的一些指导。我问了有关Andrew Ng（2018 -YouTube版本），因为我看到它在数学上非常严格。 我不仅限制自己只有一个资源（无论如何，这都不是一个很好的心态） ，但是我对我应该首先选择什么感到非常困惑。 作为初学者和一个好奇的学生，我希望从这个潜艇那里得到一些有价值和扎实的建议，该潜艇充满了才华横溢和经验丰富的个人机器学习的领域。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/triend-sky-7368      link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikh58p/which_isare_the_best_machine_learning_resources/</guid>
      <pubDate>Sat, 08 Feb 2025 06:37:34 GMT</pubDate>
    </item>
    <item>
      <title>用“最小化我”探索张量流优化器。应用程序！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikh4sp/explore_tensorflow_optimizers_with_minimize_me_app/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对AI和深度学习的工作方式感到好奇吗？我刚刚推出了最小化我，这是探索优化的理想工具。观察像SGD和Adam这样的张量优化器，因为它们最小化复杂的数学函数。 使用超参数（如学习率）进行实验，并查看它们如何影响优化器的路径。借助交互式3D可视化，您将获得有关更改的即时反馈。 我很快就计划更多功能，包括自定义功能优化和其他算法。我很想听听您的想法，以帮助改进应用程序。如果您渴望潜入神经网络并优化，则最小化我是适合您的应用！我。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/foollat​​ter2597     [link]   ＆＃32;   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikh4sp/explore_tensorflow_optimizers_with_minimize_me_app/</guid>
      <pubDate>Sat, 08 Feb 2025 06:36:45 GMT</pubDate>
    </item>
    <item>
      <title>学习ML基础知识的最快方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikejl0/fastest_way_to_learn_ml_basics_to_get_a_job/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我目前是一名具有8年编码经验的技术人员（2010-2018）和另外7年的产品管理经验（2018年至今）。我有兴趣成为一名ML工程师，并试图了解一年中如何最好地做枢轴。请让我知道哪些课程是获得相关经验并在此空间中清除访谈的最佳方法  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/top-yard7329     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikejl0/fastest_way_to_learn_ml_basics_to_get_a_job/</guid>
      <pubDate>Sat, 08 Feb 2025 04:03:14 GMT</pubDate>
    </item>
    <item>
      <title>Sigmoids激活是否被认为是遗产？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikcu76/are_sigmoids_activations_considered_legacy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   relu及其许多变体使sigmoid呈现为遗产吗？可以说，它在许多书籍中的存在更多是出于历史和教育目的吗？ （对于神经网络）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tallesl     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikcu76/are_sigmoids_activations_considered_legacy/</guid>
      <pubDate>Sat, 08 Feb 2025 02:33:27 GMT</pubDate>
    </item>
    <item>
      <title>请帮助我的伴侣并评估她的简历-ML研究和数据科学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikctxy/please_help_my_partner_and_rate_her_resume_ml/</link>
      <description><![CDATA[     ＆＃32;提交由＆＃32; /u/thenewfroman     [link]  ＆＃32;   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikctxy/please_help_my_partner_and_rate_her_resume_ml/</guid>
      <pubDate>Sat, 08 Feb 2025 02:33:05 GMT</pubDate>
    </item>
    <item>
      <title>简单的抹布管道。完全停靠，完全开源。设计为分叉。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ikb63d/simple_rag_pipeline_fully_dockerized_completely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，刚刚建立了一个相当基本的抹布实现的V0。目的是拥有一个可靠的起始工作流程，可以从该工作流下进行分支并自定义您的特定任务。 如果您正在寻找稳固的生产级抹布实现的起点 - 希望您喜欢您要查看： https://github.com/emissary-tech/legit-rag     &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/newspapersea9851      [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ikb63d/simple_rag_pipeline_fully_dockerized_completely/</guid>
      <pubDate>Sat, 08 Feb 2025 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>支持DeepSeek R1的主要平台</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ik473w/major_platforms_supporting_deepseek_r1/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着deepseek r1的知名度，许多平台都采用了他们的平台来访问此模型，查看列表， https://aiagentslive.com/blogs/blogs/blogs/3b7i.deepseek-r1-gains-gains-wide-widespread -support-major-platforms-embrace-advanced-ai-remounting    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/logical_tonight8739      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ik473w/major_platforms_supporting_deepseek_r1/</guid>
      <pubDate>Fri, 07 Feb 2025 20:02:08 GMT</pubDate>
    </item>
    <item>
      <title>训练您自己的推理模型，例如R1-少80％的VRAM -GRPO（7GB VRAM最小）。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ik3ea8/train_your_own_reasoning_model_like_r1_80_less/</link>
      <description><![CDATA[        &lt;！ “ MD”&gt; 嘿，ML大家！这是我在这里的第一篇文章，我想宣布您现在可以复制DeepSeek-r1的“ aha”。在 unsploth （开放式芬特芬太尼项目）中，始终如一。您只需要 7GB VRAM 即可使用qwen2.5（1.5b）。  这是通过 grpo ，而且，我们已经增强了整个过程，以使其使用少80％的VRAM 。在 colab notebook  -grpo.ipynb ）对于Llama 3.1 8b！ 以前，实验证明您可以实现自己的“ aha” QWEN2.5（1.5B）的力矩 - 但最少需要4xA100 GPU（160GB VRAM）。现在，有了不完善，您可以实现相同的“ aha”。只使用单个7GB VRAM GPU  以前GRPO仅与FFT一起使用，但我们使其与Q​​lora和Lora一起使用。 使用15GB VRAM，您可以转换Phi-4（您可以转换Phi-4（ 14b），Llama 3.1（8b），Mistral（12b）或任何模型 最多15B参数   它如何在100个步骤（1小时）上看起来如何在PHI-4上接受培训：    https://preview.itd.it.it.itd.it/7pnpd8vztrhe1.png 819EF8C5A4F5C60C294C77F      高度建议您阅读我们真正有用的博客 +指南：    https：// unsloth。 ai/blog/r1-resounting          llama 3.1 8b colab链接 -grpo.ipynb）   phi-4 14b colab link  -grpo.ipynb） &gt;   -grpo.ipynb）                llama 8b需求〜13GB   phi-4 14b需求〜15GB   qwen 3b需要〜7gb       i绘制了特定运行的奖励曲线：   pip安装 - 升级 -  no-cache-dir -force-reinstall unsloth_zoo unsploth vllm   希望你们周末愉快！ ：d   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/yoracale     [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ik3ea8/train_your_own_reasoning_model_like_r1_80_less/</guid>
      <pubDate>Fri, 07 Feb 2025 19:28:39 GMT</pubDate>
    </item>
    <item>
      <title>与我一起学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ijrlqd/study_machine_learning_with_me/</link>
      <description><![CDATA[在并将其上传到YouTube。我经历了材料，解决问题。 如果您还学习ML或考虑参加本课程，请随时检查一下！也许我们可以一起学习。  https://www.youtube.com/@math_css9    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kitchen-paramedic474     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ijrlqd/study_machine_learning_with_me/</guid>
      <pubDate>Fri, 07 Feb 2025 09:59:32 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到此处   对于那些正在寻找简历评论的人，请发布在 imgur.com 首先，然后将链接发布为评论，甚至在/r/简历或 r/EngineeringResumes 首先，然后在这里交叉。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>