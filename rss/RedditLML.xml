<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 23 Jun 2024 09:15:39 GMT</lastBuildDate>
    <item>
      <title>使用 GPT-4o 训练小 2,000,000 倍的模型（可直接在设备上运行）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmi1s2/using_gpt4o_to_train_a_2000000x_smaller_model/</link>
      <description><![CDATA[    /u/thenarfer   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmi1s2/using_gpt4o_to_train_a_2000000x_smaller_model/</guid>
      <pubDate>Sun, 23 Jun 2024 09:03:41 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型反向传播</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmhb4g/custom_model_backprop/</link>
      <description><![CDATA[您好， 我正在研究一个小型语言模型，我用 C++ 为该模型实现了一个自定义推理脚本，它比 pytorch 版本快约 100 倍。 而且由于这显著提高了速度，我决定也用 C++ 实现训练代码。我的问题是我的代码中出现了错误的梯度。我大约完成了反向传播的一半，我的所有梯度都与 pytorch 代码完全相同，但现在后半部分不一样了，我不知道我做错了什么。 我不会要求人们查看杂乱的 2000 行 cpp 文件，但如果有人能帮我找出下面模型的反向传播函数（使用任何编码语言），那就太棒了！ “”” class RecurrentHead(nn.Module): &quot;&quot;&quot;一个自注意力的头脑“”“ def __init__(self, n_embd, head_size, dropout, device): super().__init__() self.key = nn.Linear(n_embd, head_size, bias=True, device=device) self.query = nn.Linear(1, head_size, bias=True, device=device) self.positions = torch.arange(0, n_embd).unsqueeze(dim=0).to(device) self.query_pos = nn.Embedding(n_embd, head_size, device=device) self.value = nn.Linear(n_embd, head_size, bias=False, device=device) self.proj = nn.Linear(head_size, 1, device=device) self.dropout = nn.Dropout(dropout) @profile def forward(self, x, tok_emb): # x 大小为 (batch, channels) # tok_emb 大小为 (batch, channels) # 大小为 (batch, head size) 的输出 k = self.key(tok_emb) # (B,1,hs) q = self.query(x) # (B,channels,hs) q2 = self.query_pos(self.positions) q = q + q2 # 将位置嵌入添加到查询 # 计算注意力分数（“亲和力”） wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, C, hs) @ (B, hs, 1) -&gt; (B, C, 1) wei = F.softmax(wei, dim=-2) # (B, C, 1) wei = self.dropout(wei) # 对值进行加权聚合 v = self.value(tok_emb) # (B,1,hs) out = wei @ v # (B, C, 1) @ (B, 1, hs) -&gt; (B, C, hs) out = self.proj(out).squeeze() # (B, C) return out  “”” P.S. 如果有帮助的话，我认为可以忽略 dropout，我总是将其设置为 0。    提交人    /u/dnsod_si666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmhb4g/custom_model_backprop/</guid>
      <pubDate>Sun, 23 Jun 2024 08:10:07 GMT</pubDate>
    </item>
    <item>
      <title>Ml 数学部分？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmh0g5/ml_maths_part/</link>
      <description><![CDATA[我的孩子现在上 7 年级，他知道所有普通 7 年级学生所知道的知识，但他想尝试 ml，我试图让他明白，如果他真的想做这件事，他就需要了解数学，尽管这很有野心，但他表示已经准备好付出努力，那么我应该如何学习数学部分呢？    提交人    /u/RougeReaper1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmh0g5/ml_maths_part/</guid>
      <pubDate>Sun, 23 Jun 2024 07:48:45 GMT</pubDate>
    </item>
    <item>
      <title>信息瓶颈方法的现状如何？是否值得使用这个“inf_T I(X;T) - beta I(T;Y)”进行训练以直接优化中间层的内容？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmgsfs/what_is_the_current_status_of_information/</link>
      <description><![CDATA[几年前，Naftali Tishby 的信息瓶颈方法被大肆炒作，但现在几乎没有什么动静了，尤其是作者不幸于 2021 年去世。 理论上，它允许直接优化隐藏/中间层 T 的内容 - 它不仅应该最大化关于输出 I(T;Y) 的相互信息，同时还应该最小化关于输入 I(X;T) 的信息 - 消除噪音，（有损）压缩/提取最有价值的信息。 在 Tishby 的演讲中，例如https://www.youtube.com/watch?v=utvIaZ6wYuw，他使用它进行评估，但似乎很想尝试直接用它来进行训练——优化中间层的内容。 我个人认为它很有前途，目前正在研究可以通过这种方式廉价训练的新 ANN（https://arxiv.org/abs/2405.05097），所以想问一下，提出讨论。 这个例如“inf_T I(X;T) - beta I(T;Y)”是否直接用于 NN 训练？应该是吗？也许一些更复杂的最小化-最大化会更好？ 一般来说：信息瓶颈方法的现状如何？    提交人    /u/jarekduda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmgsfs/what_is_the_current_status_of_information/</guid>
      <pubDate>Sun, 23 Jun 2024 07:32:34 GMT</pubDate>
    </item>
    <item>
      <title>注意力和变压器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmgqt9/attention_and_transformers/</link>
      <description><![CDATA[我一直在尝试理解注意力机制和 transformers 架构，但我无法理解，有没有好的文章或视频可以详细解释整个机制？谢谢！    提交人    /u/NoobPeen   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmgqt9/attention_and_transformers/</guid>
      <pubDate>Sun, 23 Jun 2024 07:29:24 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士评估数学的 ROUGE 分数指标（附示例）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmfo3k/rouge_score_metric_for_llm_evaluation_maths_with/</link>
      <description><![CDATA[ROUGE 分数是用于 LLM 和其他基于文本的应用程序的重要指标。它有许多变体，如 ROUGE-N、ROUGE-L、ROUGE-S、ROUGE-SU、ROUGE-W，这些变体在本帖中进行了解释：https://youtu.be/B9_teF7LaVk?si=6PdFy7JmWQ50k0nr    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmfo3k/rouge_score_metric_for_llm_evaluation_maths_with/</guid>
      <pubDate>Sun, 23 Jun 2024 06:14:46 GMT</pubDate>
    </item>
    <item>
      <title>Kolmogorov-Arnold网络不仅有一个训练概念。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmfk5d/kolmogorovarnold_network_has_not_only_one/</link>
      <description><![CDATA[http://openkan.org/ 展示了与 MIT 建模方法不同的方法。源代码可用。     由   提交  /u/Internal-Debate-4024   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmfk5d/kolmogorovarnold_network_has_not_only_one/</guid>
      <pubDate>Sun, 23 Jun 2024 06:07:15 GMT</pubDate>
    </item>
    <item>
      <title>对 Coursera 上的数学专业感到困惑</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmf4s9/confused_between_math_specializations_on_coursera/</link>
      <description><![CDATA[我不确定是选择帝国理工学院的“机器学习数学”还是 deeplearning.ai 的“机器学习数学”来学习机器学习所需的基本数学。这两个专业看起来都很有前途，而且很相似，一个关键的区别是前者是 PCA 课程，后者是概率和统计课程。我希望你能建议我应该追求哪个专业，因为同时学习这两个专业可能会很困难，而且很混乱。    提交人    /u/furyacer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmf4s9/confused_between_math_specializations_on_coursera/</guid>
      <pubDate>Sun, 23 Jun 2024 05:39:19 GMT</pubDate>
    </item>
    <item>
      <title>Parlay Bet ML 模型：使用哪种架构？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dmafp9/parlay_bet_ml_model_which_architecture_to_use/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dmafp9/parlay_bet_ml_model_which_architecture_to_use/</guid>
      <pubDate>Sun, 23 Jun 2024 01:04:17 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统——如何检索用户嵌入？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dm98qq/recommendation_systems_how_to_retrieve_user/</link>
      <description><![CDATA[我在一个相当大的数据集上对用户-项目交互进行了 KNN。该数据集基于用户提交的元数据（用户创建的内容）。这对于关联现有项目非常有效，但是，它们都指向同一用户提交的项目，我理想情况下想推荐其他用户提交的项目。最重要的是，最好有一种方法可以推荐训练集中未见过的项目（实时推荐）。我可能可以通过对后者进行一些批处理来解决问题。  现在，我不确定如何开始对用户进行分类。我认为推荐系统的最终结果是具有代表用户“喜好”的向量嵌入。然后，我们可以将批量项目（新项目）与用户向量进行余弦模拟以获得前 k 个推荐。不幸的是，我错过了有关如何实现此目的的详细信息。如果我能够将我拥有的 KNN 模型导出到 ONNX，我就能实现对新项目的矢量化，对吗？然而，这让我回到了我的第一个问题：我如何开始获取用户向量。 如果听起来令人困惑，抱歉，我是 ML 新手。    提交人    /u/ForeverDen   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dm98qq/recommendation_systems_how_to_retrieve_user/</guid>
      <pubDate>Sun, 23 Jun 2024 00:02:11 GMT</pubDate>
    </item>
    <item>
      <title>如何才能有效地找到距离特定向量最近的前 n 个向量？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dm4gk1/how_can_i_efficiently_find_the_first_n_closest/</link>
      <description><![CDATA[嗨 Reddit，不确定这是否是一个非常简单的问题，可能非常简单，但我试图弄清楚如何找到前 5 个向量，它们与 20 维空间中的特定向量最接近。任何指针都将不胜感激。谢谢！！    提交人    /u/Zestyclose_Ear4092   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dm4gk1/how_can_i_efficiently_find_the_first_n_closest/</guid>
      <pubDate>Sat, 22 Jun 2024 20:15:22 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该继续学习数学，还是直接跳到机器学习课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dm402f/do_i_keep_learning_math_or_just_jump_to_a_ml/</link>
      <description><![CDATA[我想学习 ML。所以我从数学开始。我已经很久没有复习过它了，我的知识有点生疏。我从大学代数开始，完成后我将同时从微积分和线性代数开始。我的问题是我应该继续这个路线图还是直接跳到学习 ML？    提交人    /u/Little-Peanut-765   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dm402f/do_i_keep_learning_math_or_just_jump_to_a_ml/</guid>
      <pubDate>Sat, 22 Jun 2024 19:54:30 GMT</pubDate>
    </item>
    <item>
      <title>你必须阅读的 5 本有关机器学习算法的免费书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlzoin/5_free_books_on_machine_learning_algorithms_you/</link>
      <description><![CDATA[        提交人    /u/kingabzpro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlzoin/5_free_books_on_machine_learning_algorithms_you/</guid>
      <pubDate>Sat, 22 Jun 2024 16:36:52 GMT</pubDate>
    </item>
    <item>
      <title>查找 NLP 书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlqgfx/nlp_book_find/</link>
      <description><![CDATA[      有人有这本书的电子版吗？    提交人    /u/Subject-Historian-12   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlqgfx/nlp_book_find/</guid>
      <pubDate>Sat, 22 Jun 2024 07:49:28 GMT</pubDate>
    </item>
    <item>
      <title>最好的 ML/AI 在线课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dlnx4o/best_mlai_online_program/</link>
      <description><![CDATA[嗨，我想了解有关 ML/AL 的更多信息，我在科技行业使用 C++ 和 Python 工作。但我的领域非常传统，没有什么新东西。你对参加哪些在线课程有什么建议吗？总时间大约为 0.5 到 1 年。    提交人    /u/First-Technician-609   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dlnx4o/best_mlai_online_program/</guid>
      <pubDate>Sat, 22 Jun 2024 04:59:39 GMT</pubDate>
    </item>
    </channel>
</rss>