<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 10 Jul 2024 06:21:14 GMT</lastBuildDate>
    <item>
      <title>DuckDB 教程：构建 AI 项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzo5bi/duckdb_tutorial_building_ai_projects/</link>
      <description><![CDATA[  由    /u/kingabzpro  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzo5bi/duckdb_tutorial_building_ai_projects/</guid>
      <pubDate>Wed, 10 Jul 2024 05:43:28 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士真的像我们想象的那么聪明吗？推理和规划的统计数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dznvz9/are_llms_really_as_smart_as_we_think_the_stats_on/</link>
      <description><![CDATA[大家好， 我发现了一些有关大型语言模型 (LLM) 的有趣统计数据，这让我开始思考它们的真正能力。 尽管大肆宣传，但事实证明只有 23% 的 LLM 能够成功解决复杂的推理任务。更令人惊讶的是，只有 15% 的人在规划方面表现出色！🤯  虽然这些模型在模仿人类反应方面非常出色，但在深入、深思熟虑的问题解决方面，它们还有很长的路要走。这确实让你想知道当前 AI 能力与真正的类人智能之间的差距。 你对此有何看法？你认为我们很快就会在这些领域看到显着的改进，还是我们高估了 LLM 的实际成就？  ai #machinelearning #techfacts #datascience #airesearch 期待听到您的见解！    提交人    /u/VoiceZealousideal466   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dznvz9/are_llms_really_as_smart_as_we_think_the_stats_on/</guid>
      <pubDate>Wed, 10 Jul 2024 05:26:52 GMT</pubDate>
    </item>
    <item>
      <title>单像素攻击</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dznsba/onepixel_attack/</link>
      <description><![CDATA[      想象一下，改变图像中一个像素的值，神经网络会将图像预测为马的概率为 99%青蛙。 这完全有可能，被称为“单像素攻击”。 单像素攻击是“对抗性攻击”或“对抗性示例”这一概念的一个子集，我们可以对图像进行人类无法检测到的小修改，并使神经网络错误分类。 在常规对抗性攻击中，我们可以用一个非常小的值修改任意数量的像素。 在单像素攻击中，我们只能根据需要修改图像的一个像素。 我们通过一种称为“差分进化”的算法找出导致错误分类的修改像素和 R、G、B 值修改的方法。 差分进化类似于遗传算法。随机选择几个像素作为父母。父母发生变异并产生“后代”像素。如果后代可以增加损失函数或降低预测置信度，那么它们就会生存下来（适者生存）。否则，它们将被丢弃（淘汰不适合的）。 进化是随机突变和非随机选择。我们可能会达到最优，但不能保证。 差分进化 (DE) 如此强大，因为与梯度下降不同，您不需要可微分函数。您可以在任何函数上应用 DE。 我已经制作了一个完整的单像素攻击讲座视频，其中介绍了以下内容。  回顾 Su 等人在 arXiv 上发表的开创性单像素攻击论文 教授单像素攻击背后的概念 回顾差异进化 在 Google colab 中实现单像素攻击（代码在视频描述中分享）  这是讲座的链接：https://youtu.be/_y1tIdnB__Y 本讲座是可解释人工智能 (XAI) 讲座系列的一部分。 https://i.redd.it/rab1kscylmbd1.gif    由   提交  /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dznsba/onepixel_attack/</guid>
      <pubDate>Wed, 10 Jul 2024 05:20:27 GMT</pubDate>
    </item>
    <item>
      <title>更好地理解超参数的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzmzb7/resources_for_better_understanding_hyperparameters/</link>
      <description><![CDATA[我正在寻找有关超参数的信息。目前我对 scikit 学习模型更感兴趣，但我也会学习深度学习，因为我接下来要开始探索它。我更喜欢一本书，但几乎什么都学。我的学位快要到一半了，我的大学课程涵盖了它们的概念，以及用于找到最佳超参数的网格搜索和随机搜索方法，但如果我坦率地说，我并不真正满足于这样的想法：调整模型的最佳方法是测试每种可能性或依赖随机机会。如果这是开始的基线，我没问题，但当涉及到微调时，必须有某种逻辑，对吧？我真的希望有人在某个地方制定了一套规则和指导方针。诸如“与分类相比，这个和那个对回归模型的影响更大”之类的事情或“如果您的特征主要是分类的，那么这个超参数比那个更重要”和“这个或那个应该会影响您在进行网格搜索时选择上限和下限的方式”。如果有人有任何可以提供帮助的东西，我将不胜感激任何建议。    提交人    /u/Pegarex   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzmzb7/resources_for_better_understanding_hyperparameters/</guid>
      <pubDate>Wed, 10 Jul 2024 04:32:24 GMT</pubDate>
    </item>
    <item>
      <title>作为初学者，如何进行/学习 NN 的稀疏化（修剪和量化）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzmwjp/how_to_go_aboutlearn_sparsificationpruning_and/</link>
      <description><![CDATA[您好， 我正在训练一个模型，使用 YOLOv8 在 Rpi5 上进行一些物体检测。到目前为止，我已经设法通过使用一个小图像（224 x 224）并将其转换为 NCNN 格式（根据 YOLO DOCS 的说法，该格式最适合 RPI）使其以大约 6 fps 的速度运行。 我正在寻找如何进一步提高速度（准确度目前对此并不那么重要，因为即使它检测到物体的时间只有一半，也应该没问题）。 我被引导到一些讨论修剪模型或使用权重量化的链接，但我不确定如何学习/执行任何这些操作。非常感谢任何指导/链接来做同样的事情。 我目前正在重新训练模型以适应 160x160 分辨率，我认为这应该会进一步提高速度，但我怀疑它是否会像我想要的那样快。我计划稍后用 C++ 重新编写代码（目前用 Python），但我想看看这在 Python 中的速度有多快，作为概念证明。 也非常感谢任何其他关于如何提高任何检测任务速度的建议。 谢谢。    提交人    /u/imaginedoinwideread   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzmwjp/how_to_go_aboutlearn_sparsificationpruning_and/</guid>
      <pubDate>Wed, 10 Jul 2024 04:27:59 GMT</pubDate>
    </item>
    <item>
      <title>目前哪些 AI 工具在创新性和可负担性方面引领市场？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzmjks/which_ai_tools_are_currently_leading_the_market/</link>
      <description><![CDATA[大家好，我正在寻找最好的 AI 桌面应用程序，以获取有关 AI 模型的最新更新并找到经济实惠的替代品。为了跟上 AI 的前沿，您关注哪些网站、博客或其他来源？ 与我分享您的常用网站，无论是一些富有洞察力的 YouTube 频道、活跃的 Twitter 帐户，还是持续提供最新 AI 工具信息的博客。我乐于聆听任何类型的资源 - 越多样化越好！ 非常感谢！    提交人    /u/XXai_DesktopTool   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzmjks/which_ai_tools_are_currently_leading_the_market/</guid>
      <pubDate>Wed, 10 Jul 2024 04:07:21 GMT</pubDate>
    </item>
    <item>
      <title>如何免费从头学习机器学习 ☁️ AWS SageMaker 🟠 亚马逊人工智能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzkt1r/how_to_learn_machine_learning_from_scratch_for/</link>
      <description><![CDATA[https://youtu.be/vf2aXzKf2Z8 在此视频中，我向您展示了如何免费从头开始学习机器学习☁️AWS SageMaker 🟠 亚马逊人工智能。亚马逊和人工智能。 https://studiolab.sagemaker.aws/ Amazon SageMaker 是一种完全托管的机器学习 (ML) 服务。借助 SageMaker，数据科学家和开发人员可以在可用于生产的托管环境中快速安全地创建、训练和部署机器学习模型。 Amazon SageMaker Studio Lab 是一个免费的机器学习 (ML) 开发环境，提供计算、存储（高达 15 GB）和安全性，因此任何人都可以免费学习和试验 ML。    提交人    /u/gabrielcodingok   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzkt1r/how_to_learn_machine_learning_from_scratch_for/</guid>
      <pubDate>Wed, 10 Jul 2024 02:35:58 GMT</pubDate>
    </item>
    <item>
      <title>22 唯一类别混淆矩阵。如何分解？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzkdjf/22_unique_class_confusion_matrix_how_to_break_down/</link>
      <description><![CDATA[我有 22 个唯一类。有一个 22x22 混淆矩阵。它几乎不可见，因为我需要一份硬拷贝。 有没有办法把它分解开？或者你能建议他们最好的做法是什么？    提交人    /u/FlaShH8t3eRs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzkdjf/22_unique_class_confusion_matrix_how_to_break_down/</guid>
      <pubDate>Wed, 10 Jul 2024 02:13:48 GMT</pubDate>
    </item>
    <item>
      <title>用于序列建模基准测试的小数据集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzk90o/small_data_sets_for_benchmarking_sequence/</link>
      <description><![CDATA[有哪些适合在消费级 GPU（例如 RTX 2060）上运行的知名数据集和顺序数据基准？例如，Long Range Arena 就是其中之一。    提交人    /u/chernivek   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzk90o/small_data_sets_for_benchmarking_sequence/</guid>
      <pubDate>Wed, 10 Jul 2024 02:07:23 GMT</pubDate>
    </item>
    <item>
      <title>向 KAN（Kolmogorov-Arnold 网络）作者提问</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dzet5s/ask_questions_for_kan_kolmogorovarnold_networks/</link>
      <description><![CDATA[我正在与 arXiv Labs 合作，为 arXiv 论文制作评论部分，目前位于 alphaxiv.org。本周 KAN 作者将回答有关其论文的问题：https://alphaxiv.org/abs/2404.19756v4。欢迎所有背景的人，所以如果您的问题不是特别“研究性”，也不用担心。 该网站正在积极开发中，所以如果你们想贡献或有功能请求，请随时给我发私信。    由   提交 /u/Vivid_Perception_143   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dzet5s/ask_questions_for_kan_kolmogorovarnold_networks/</guid>
      <pubDate>Tue, 09 Jul 2024 21:58:35 GMT</pubDate>
    </item>
    <item>
      <title>我已经创建了一个用于学习机器学习的路线图跟踪器应用程序</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dza85k/i_have_created_a_roadmap_tracker_app_for_learning/</link>
      <description><![CDATA[        由    /u/crackittodayupsc  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dza85k/i_have_created_a_roadmap_tracker_app_for_learning/</guid>
      <pubDate>Tue, 09 Jul 2024 18:49:46 GMT</pubDate>
    </item>
    <item>
      <title>参数到底是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dz7w1y/what_exactly_are_parameters/</link>
      <description><![CDATA[在 LLM 中，当人们说一个模型有 70 亿个参数或者你可以通过更改参数来微调 LLM 时，参数这个词经常被抛出。它们只是数据点还是其他东西？在这种情况下，如果你想微调 LLM，你是否需要一个包含数百万甚至数十亿个值的数据集？    提交人    /u/BookkeeperFast9908   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dz7w1y/what_exactly_are_parameters/</guid>
      <pubDate>Tue, 09 Jul 2024 17:14:01 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院机器学习博士毕业生 | 从头开始​​构建神经网络 | 无需 Tensorflow 或 PyTorch</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dyz9o0/mit_machine_learning_phd_graduate_building_neural/</link>
      <description><![CDATA[      我于 2022 年获得麻省理工学院机器学习博士学位。  然后发现了我对教授机器学习和神经网络的热情。 2 个月前，我开始了一个从头开始教授神经网络的项目，没有使用 PyTorch 或 TensorFlow。 目标是掌握构建模块，而不是盲目使用机器学习库。 结果是一个包含 26 个视频的项目，涵盖了有关神经网络的所有内容。我已经将所有视频上传到 Youtube。 这是播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSj6tNyn_UadmUeU3Q3oR-hu 很高兴收到反馈！ https://i.redd.it/4qg54z3g2hbd1.gif    提交人    /u/OtherRaisin3426   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dyz9o0/mit_machine_learning_phd_graduate_building_neural/</guid>
      <pubDate>Tue, 09 Jul 2024 10:42:12 GMT</pubDate>
    </item>
    <item>
      <title>我一直在努力理解稳定扩散的工作原理，所以我决定从头开始编写自己的程序，并附上数学解释 🤖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dyufu6/i_was_struggle_how_stable_diffusion_works_so_i/</link>
      <description><![CDATA[        提交人    /u/jurassimo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dyufu6/i_was_struggle_how_stable_diffusion_works_so_i/</guid>
      <pubDate>Tue, 09 Jul 2024 05:21:18 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>