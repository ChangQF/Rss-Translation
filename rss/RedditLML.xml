<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 28 Jul 2024 15:14:33 GMT</lastBuildDate>
    <item>
      <title>使用聚类算法进行图像压缩</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee9fvv/image_compression_using_clustering_algorithm/</link>
      <description><![CDATA[伙计们，我完成了 Andrew NG ML 课程。从那时起，我通过从 Kaggle 获取数据集制作了一些小项目以供实施。 现在我的理由是可以使用聚类算法压缩图像。所以在制作项目之前，我想知道一个可以阅读有关聚类算法理论的资源。    提交人    /u/SedTecH10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee9fvv/image_compression_using_clustering_algorithm/</guid>
      <pubDate>Sun, 28 Jul 2024 15:02:35 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 和生成式 AI 简介</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee7mi6/a_quick_introduction_to_chatgpt_and_generative_ai/</link>
      <description><![CDATA[      揭秘 ChatGPT、生成式 AI 以及您需要了解的其他相关概念。    提交人    /u/Thatshelbs   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee7mi6/a_quick_introduction_to_chatgpt_and_generative_ai/</guid>
      <pubDate>Sun, 28 Jul 2024 13:38:01 GMT</pubDate>
    </item>
    <item>
      <title>提高机器学习技能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee7iet/improve_machine_learning_skills/</link>
      <description><![CDATA[我是一名机器学习工程师。我于 2023 年毕业并获得学士学位（在英国），从那时起就一直从事机器学习职位（主要是计算机视觉），我将在一个月内转到一个生成式 AI 团队（作为同一家公司的一部分）。  我一直都很喜欢 AI 和 ML，甚至在整个 ChatGPT 热潮之前，当时 AI 在 CS 社区之外变得非常流行，所以我在大学学习期间一直专注于此，选择 ML/AI 相关课程并撰写有关神经网络、决策树和遗传算法的论文。 我现在不知道该怎么做才能提高我的 ML 技能。硕士学位太贵了，而且没有像 leetcode 这样的 ML 网站。我能想到的只有 2 个选项：  继续做个人项目，但很难想出很酷且可实现的项目想法，而且我也可以访问其数据。 在线课程（很难找到带有证书且价格不太贵的课程）。  我的目标是提高自己，这样我就可以找到更好的工作和/或在我的全职工作之外开始自由职业以增加我的收入。 对我来说，什么选项最适合我，还有我没有想到的其他选项吗？    提交人    /u/cipi1357   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee7iet/improve_machine_learning_skills/</guid>
      <pubDate>Sun, 28 Jul 2024 13:32:14 GMT</pubDate>
    </item>
    <item>
      <title>EDA：缺失值</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee79lc/eda_missing_values/</link>
      <description><![CDATA[嗨。 我有一个关于汽车保险的数据集，在这个数据集中，我有废止日期，其中有缺失值，确切地说是 151.021 中的 42.146。 这些缺失值很重要，因为它们表明该政策并未被废止。 我的问题是，我该如何处理它们？我应该保持原样还是应该创建一个二进制特征来指示该政策是否被废止？ 谢谢    提交人    /u/Hot_Variation_7150   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee79lc/eda_missing_values/</guid>
      <pubDate>Sun, 28 Jul 2024 13:19:51 GMT</pubDate>
    </item>
    <item>
      <title>音频预处理以适合模拟数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee6n0b/audio_preprocessing_to_fit_simulation_data/</link>
      <description><![CDATA[大家好，我们正在尝试预处理一些双耳音频，并将它们发送到基于一些 HRTF 的模拟数据集上预先训练的模型。但是，我们遇到了一些问题，即这种模型无法给出良好的预测结果，就像在训练或评估数据集（均由 HRTF 生成）上可以做什么一样。我也尝试过将两个通道和 HRTF 卷积，将它们的法线回原始 DBS；这也不起作用。这里有人有如何处理这个问题的经验吗？非常感谢。:)    提交人    /u/Few_Series8053   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee6n0b/audio_preprocessing_to_fit_simulation_data/</guid>
      <pubDate>Sun, 28 Jul 2024 12:46:05 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该从神经网络中删除具有较小 Shapley 值的特征？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee68wa/should_i_remove_features_with_small_shapley/</link>
      <description><![CDATA[如果我的神经网络有 13 个特征，其中几个特征（称为 X1、X2 和 X3）具有非常大的 Shapley 值（具体来说是 16、18、18），而我所有其他特征的 Shapley 值都在 3 左右。是否仍然值得将其他特征保留在模型中？这个比例是否足以让网络仍然从其他变量中获取信息，还是这被认为是一种不平衡，其中只有 X1、X2 和 X3 值得保留？这些事情有经验法则吗？    提交人    /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee68wa/should_i_remove_features_with_small_shapley/</guid>
      <pubDate>Sun, 28 Jul 2024 12:24:04 GMT</pubDate>
    </item>
    <item>
      <title>需要对Coursera的机器学习和深度学习课程中的一些代码提供帮助。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee689e/need_help_with_some_of_the_code_in_courseras/</link>
      <description><![CDATA[我已报名参加 ML 和深度学习专项课程。我拥有数学硕士学位，因此讲座内容对我来说轻而易举。但是，我最近才学习了 python、numpy 和 matplotlib，因此可选实验室中的一些代码很难理解。  有没有经历过同样的事情并相互依靠来学习这些东西的社区？ 附言：我已在深度学习门户网站上发布了一些查询，但没有得到问题的答案。    提交人    /u/No_Ostrich4811   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee689e/need_help_with_some_of_the_code_in_courseras/</guid>
      <pubDate>Sun, 28 Jul 2024 12:23:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 nnUNetResEncUNetPlans 进行 nnUNet 训练：面临批次大小问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee5o79/nnunet_training_with_nnunetresencunetplans_facing/</link>
      <description><![CDATA[大家好， 我正在一个非常强大的工作站设置上使用 nnUNetResEncUNetPlans 训练 nnUNet 模型：  512 GB RAM 128 个 CPU 核心 3x A100 80GB GPU  我正在使用以下 Docker 命令运行训练： docker run \ -it -d --rm \ --user 1002:1002 \ --gpus &#39;&quot;device=0,1,2&quot;&#39; \ --ipc=host \ --ulimit memlock=-1 \ --ulimit stack=67108864 \ -e nnUNet_compile=T \ -e nnUNet_n_proc_DA=32 \ -v /home/user/sessions/:/session/ \ ngc_torch:latest nnUNetv2_train 332 3d_fullres_resenc_bs4 all -num_gpus 3  基本图像是 nvidia ngc pytorch image。 但是，我只能在 3 个 GPU 上运行 4-6 的批量大小。根据 nnUNet 的文档，以及 nnUNetv2_plan_experiment -d 332 -pl nnUNetPlannerResEnc -gpu_memory_target 80，我应该能够在每个 GPU 上运行 20 的批次大小。 当我尝试将批次大小增加到 4-6 以上时，我的纪元时间从 &lt;50 秒飙升到 &gt;200 秒（批次大小为 45 时超过 550 秒） 3d_fullres 配置功能：  补丁大小： [128, 128, 128] 阶段数： 6 每个阶段的功能： [32, 64, 128, 256, 320, 320]  潜在问题：  Docker 配置： --ulimit 设置是否最佳？ nnUNet_n_proc_DA：通常的进程数是多少？ 工作站问题：是否设置了其他 RAM、GPU 或 CPU 限制？  如能提供任何想法或帮助，我们将不胜感激。 谢谢    提交人    /u/Pubec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee5o79/nnunet_training_with_nnunetresencunetplans_facing/</guid>
      <pubDate>Sun, 28 Jul 2024 11:50:27 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee2pu1/pytorch_course/</link>
      <description><![CDATA[伙计们，我需要有关 Pytorch 的帮助。因为我是初学者，从文档中学习有困难，请推荐一些最好的 PyTorch 课程或 Utube 资源     提交人    /u/zaynst   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee2pu1/pytorch_course/</guid>
      <pubDate>Sun, 28 Jul 2024 08:25:02 GMT</pubDate>
    </item>
    <item>
      <title>“特色”还是“专栏”？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee1im9/features_or_columns/</link>
      <description><![CDATA[我们何时使用哪个术语？我见过两个术语互换使用。提前致谢。    提交人    /u/apollonius_perga   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee1im9/features_or_columns/</guid>
      <pubDate>Sun, 28 Jul 2024 06:59:44 GMT</pubDate>
    </item>
    <item>
      <title>Llama 3.1 新手指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ee0rq1/llama_31_guide_for_beginners/</link>
      <description><![CDATA[Llama 3.1 于上周发布，是迄今为止最强大的开源 LLM。此播放列表涵盖有关 Llama 3.1 的以下内容 1. 如何使用 Llama 3.1？Python 代码 2. 在哪里可以免费与 Llama 3.1 聊天？ 3. Llama 3.1 使用 Groq 免费 API 密钥 4. Llama 3.1 使用 Ollama 离线 5. Llama 3.1 使用 LangChain 6. Llama 3.1 使用 Meta.ai 7. Llama 3.1 的 RAG 系统 播放列表：https://youtube.com/playlist?list=PLnH2pfPCPZsJXuC5Ah7Cq6npTKOrYDFbD&amp;si=QguVOvJL9rpgNkxO    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ee0rq1/llama_31_guide_for_beginners/</guid>
      <pubDate>Sun, 28 Jul 2024 06:08:34 GMT</pubDate>
    </item>
    <item>
      <title>我的 LSTM 模型要么过度拟合，要么没有改进……求助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1edzdvh/my_lstm_model_is_either_overfitting_or_not/</link>
      <description><![CDATA[      我目前正在为一个大学做实验室。 有 4 个选择。每个选项里面都有 4 个相关属性（圆圈），它们排列在 4x4 网格中。 （每列是一个选择，每行都有不同类型的道具）道具包括获胜数量、获胜概率、失败数量和延迟。有参与者进来用眼睛选择一个选项。最初，所有圆圈都与每个道具相关联（每个圆圈在道具值的一侧有数字，另一侧空白），人们看着某个道具将其翻转。一次只能翻转一个道具，因此一次只能显示一个值。人们可以花尽可能多的时间，可以查看任何选择的道具值。最后，他们根据所看到的内容做出选择。 我的数据（x）本质上由他们查看的不同图块的序列组成，（y）是选择的标签 我试图预测他们会选择什么标签，但我的代码过度拟合了。我之前已经改变了一些东西，但它根本不适合（保持在 25%，考虑到有 4 个选项，这并不好）。我的数据是否无法与 ml 模型相匹配？我有相当多的数据。 这是我当前的模型和时期： 模型： 来自 tensorflow.keras.optimizers 导入 Adam # 规范化数据 X_train = X_train / np.max(X_train) X_test= X_test / np.max(X_test) # 计算类权重 class_weights = compute_class_weight(&#39;balanced&#39;, classes=np.unique(y_train), y=y_train) class_weights = {i: class_weights[i] for i in range(len(class_weights)) input_layer =输入（形状=（X_train.shape[1]，X_train.shape[2]）） lstm = LSTM（128，return_sequences=True）（input_layer） dropout1 = Dropout（0.4）（lstm） lstm2 = LSTM（64，return_sequences=False）（dropout1） dropout2 = Dropout（0.4）（lstm2） dense1 = Dense（64，activation=&#39;relu&#39;）（dropout2） dropout3 = Dropout（0.4）（dense1） output_layer = Dense（4，activation=&#39;softmax&#39;）（dropout3） 模型 =模型（输入=输入层，输出=输出层） 优化器 = Adam（learning_rate=0.001） model.compile（优化器=优化器，损失=&#39;sparse_categorical_crossentropy&#39;，指标=[&#39;accuracy&#39;]） # 回调 early_stopping = EarlyStopping（monitor=&#39;val_loss&#39;，patience=10，restore_best_weights=True） reduce_lr = ReduceLROnPlateau（monitor=&#39;val_loss&#39;，factor=0.5，patience=5，min_lr=1e-6） model.summary() # 训练模型 history = model.fit( X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights, callbacks=[early_stopping, reduce_lr] ) 我的 epochs： https://preview.redd.it/cwpiqpu4v6fd1.png?width=1380&amp;format=png&amp;auto=webp&amp;s=1c02a77f9e262516da5f2f6b7935fa4caa5ac25b    提交人    /u/chickfilaman51   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1edzdvh/my_lstm_model_is_either_overfitting_or_not/</guid>
      <pubDate>Sun, 28 Jul 2024 04:40:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们说机器学习不需要数学或高中数学就足够了，但事实显然并非如此？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1edvtp7/why_do_people_say_you_dont_need_math_for_ml_or/</link>
      <description><![CDATA[我经常听到这种说法，最近我开始学习深度学习，我感到需要立即了解数学。我使用的很多函数只是与计算、统计或数值方法相关的直接数学函数。线性代数是深度学习的基础。 了解这些函数和架构的人与不了解的人之间存在巨大差异。 一个人在理解机器学习，而另一个人在记忆它。 有人知道“如果他将这个名为 sigmoid 的函数放在这个名为 BCE 的函数旁边，我就会得到这个变量”，与知道这些函数的作用以及为什么在这里使用它们来创建他们熟悉的变量及其用法的人有很大不同。学习系统的组件可以让你设计和开发更好的组件，而不仅仅是整个系统。 请不要再说你不需要数学了，因为你不仅需要数学才能成为一名优秀的 ML 工程师，而且它比技术和代码更重要，因为缺乏数学会严重阻碍你在这些方面的学习过程。    提交人    /u/tooMuchShitToDo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1edvtp7/why_do_people_say_you_dont_need_math_for_ml_or/</guid>
      <pubDate>Sun, 28 Jul 2024 01:17:19 GMT</pubDate>
    </item>
    <item>
      <title>在消费级硬件上微调 LLM（使用 PEFT）进行文本生成的可行性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1edv6fg/feasibility_of_finetuning_llms_using_peft_on/</link>
      <description><![CDATA[我有一个个人项目，可以从生成式 AI 中受益。当然，超大型 LLM 几乎无法用于消费级硬件，因此我很乐意将自己限制在小型 LLM 上。我很可能需要针对特定​​任务微调此模型。显然，微调整个模型的成本太高，因此我的计划是使用 PEFT 的某种变体进行微调。 话虽如此，如今所有研究都投入到 LLM 中，是否有任何“小型”模型在文本生成方面表现出令人印象深刻的能力，可以安装在单个消费级 GPU（可能是 2 个）上，并且可以使用 PEFT 的某种变体进行训练？    提交人    /u/carusGOAT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1edv6fg/feasibility_of_finetuning_llms_using_peft_on/</guid>
      <pubDate>Sun, 28 Jul 2024 00:42:06 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>