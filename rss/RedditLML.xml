<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 01 Nov 2024 18:22:11 GMT</lastBuildDate>
    <item>
      <title>获得 DS 或 AI 硕士学位是否值得？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghazl8/is_a_ms_in_ds_or_ai_worth_it/</link>
      <description><![CDATA[我拥有计算机工程学士学位，并在几家合作社工作过，对人工智能/数据科学硕士学位感兴趣。我有机会再读一年以获得硕士学位。我真的很喜欢机器学习和数据科学，即使没有经济利益，我也会考虑获得这个学位。 我想我的主要问题是：获得人工智能或数据科学硕士学位有什么好处？我和我目前合作社的团队负责人谈过，他说你可以在职业生涯的后期达到一个上限，而硕士学位可以帮助你解决这个问题。我希望硕士学位能让我成为 SWE 职位的更有竞争力的申请人，并让我有能力转换到更有利可图的人工智能工作。人们发现这是真的吗？ Ps。我也喜欢 SWE 和后端数据设计/算法。也许不值得转换，因为我已经喜欢我所做的事情了？我喜欢机器学习，但我不知道在公司环境中我是否会喜欢它？    提交人    /u/Jolly_Seat_4478   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghazl8/is_a_ms_in_ds_or_ai_worth_it/</guid>
      <pubDate>Fri, 01 Nov 2024 17:31:31 GMT</pubDate>
    </item>
    <item>
      <title>学习 Hopfield 网络，该模型荣获 2024 年物理学诺贝尔奖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gha40f/learn_hopfield_networks_the_model_that_won_the/</link>
      <description><![CDATA[        由    /u/Intelligent-Field-97  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gha40f/learn_hopfield_networks_the_model_that_won_the/</guid>
      <pubDate>Fri, 01 Nov 2024 16:54:01 GMT</pubDate>
    </item>
    <item>
      <title>适合初学者到高级人士的最佳机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh9f6e/best_machine_learning_courses_for_beginners_to/</link>
      <description><![CDATA[  由    /u/Sreeravan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh9f6e/best_machine_learning_courses_for_beginners_to/</guid>
      <pubDate>Fri, 01 Nov 2024 16:24:57 GMT</pubDate>
    </item>
    <item>
      <title>金融机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh8axo/machine_learning_for_finance/</link>
      <description><![CDATA[你们中有多少人在金融领域使用过 ML？在交易领域呢？这种体验是什么样的？对于已经使用 ML 进入该行业的人来说，需要具备哪些技能？    提交人    /u/Loose-Way-9183   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh8axo/machine_learning_for_finance/</guid>
      <pubDate>Fri, 01 Nov 2024 15:38:23 GMT</pubDate>
    </item>
    <item>
      <title>寻求 GNN 帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh7lde/looking_for_help_with_gnn/</link>
      <description><![CDATA[我是一名研究粒子探测器的物理专业学生。 探测器有单个传感器，当粒子飞过探测器时，具有给定位置的传感器会测量时间和电荷。根据这些特征，我们重建粒子的位置和角度。 我们面临的一个问题是强背景：在事件期间，额外的传感器将被激活并测量与我们感兴趣的粒子无关的东西。 为了解决这个问题，我想训练一个分类模型，该模型能够针对每个事件学习哪些传感器属于粒子，哪些传感器是背景。这在理论上应该是可行的，粒子具有与背景不同的特征（电荷/时间）。 此外，我们还有训练数据集，我们知道哪些传感器与监督学习相关。 到目前为止，我的想法是一个图神经网络，为每个传感器分配一个节点。然后，模型必须对哪些节点相关、哪些节点不相关进行分类。到目前为止，我还在努力让它发挥作用。 有 GNN 知识的人能帮我一下吗？    提交人    /u/St1gmata   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh7lde/looking_for_help_with_gnn/</guid>
      <pubDate>Fri, 01 Nov 2024 15:07:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习初学者：这份路线图完整吗？还是缺少什​​么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh6r2m/beginner_in_ml_is_this_roadmap_complete_or/</link>
      <description><![CDATA[        提交人    /u/Objective-Menu-7133   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh6r2m/beginner_in_ml_is_this_roadmap_complete_or/</guid>
      <pubDate>Fri, 01 Nov 2024 14:30:27 GMT</pubDate>
    </item>
    <item>
      <title>您会推荐数据科学硕士学位吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh4x1f/would_you_recommend_a_masters_degree_in_data/</link>
      <description><![CDATA[我目前从事数据质量工作，我想攻读数据科学和机器学习硕士学位。在这个领域获得硕士学位是否值得？如果不值得，你会推荐什么？我今年 24 岁，男，商学院毕业    提交人    /u/SilentAnalyst0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh4x1f/would_you_recommend_a_masters_degree_in_data/</guid>
      <pubDate>Fri, 01 Nov 2024 13:06:09 GMT</pubDate>
    </item>
    <item>
      <title>神经网络推理的最快方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh3hhn/quickest_method_of_neural_network_inference/</link>
      <description><![CDATA[我遇到的情况是需要多次从已加载的 NN 模型中进行预测。 请注意，我每次仅对小批量数据调用 .predict()。不确定这是否相关，但可能相关。 我本质上是在运行模拟（~10k 次迭代），每次迭代我都会调用网络进行预测。 我需要大幅加快速度。 就机器而言，我受到 CPU 限制（没有 GPU/TPU）。 我发现的当前最佳解决方案是将我的模型转换为 ONNX 模型，创建一个 InferenceSession 对象，并将此对象传递给我的各个工作器（以在我的 CPU 之间分配工作）。 ONNX 针对推理进行了优化，因此这已经足够好了。我已经修改了操作线程间/内属性等等。 我也尝试过量化我的模型，这有一点帮助，但作用不大。 有没有更好的方法？还有谁知道的其他技术吗？    提交人    /u/BasslineButty   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh3hhn/quickest_method_of_neural_network_inference/</guid>
      <pubDate>Fri, 01 Nov 2024 11:49:24 GMT</pubDate>
    </item>
    <item>
      <title>“是什么让 GPU 如此强大？矩阵乘法！”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggzx8t/what_makes_gpus_so_powerful_matrix_multiplication/</link>
      <description><![CDATA[      https://preview.redd.it/xm1m3w4as8yd1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=f7ddc7e1e90137325b0653d931a7f807f027c70e GPU 已成为当今最必不可少（且最昂贵）的硬件之一。在我发布在 Vizuara 的 YouTube 频道上的最新视频中，我探讨了 GPU 为何如此强大、它们有何不同，以及它们如何从提升游戏图形到改造 AI：https://www.youtube.com/watch?v=wYXARXhSoSs&amp;feature=youtu.be GPU 强大的背后是它们能够快速并行执行大量矩阵乘法。矩阵乘法是 3D 图形渲染和 AI 模型训练的核心。 在游戏中，每个 3D 对象都被分解为顶点和三角形，每次游戏场景刷新时，GPU 都必须使用矩阵数学快速重新计算位置、纹理和光照。高质量的游戏会渲染数百万个顶点和三角形。如果没有 GPU，我们所熟知的游戏根本无法实现。 2008 年，我记得我曾尝试在一台没有显卡的旧电脑上运行《侠盗猎车手：圣安地列斯》。我不得不降低分辨率才能让游戏可玩。与此同时，拥有专用显卡的朋友正在享受无缝的高分辨率游戏体验。那是我第一次真正接触到 GPU 的功能。 当时，NVIDIA 仍然主要专注于增强游戏视觉效果。但是，一旦深度学习出现，GPU 用于图形的矩阵乘法运算最终就非常适合 AI。 事实上，随着 AI 研究人员开始训练更大的神经网络，他们发现用于 3D 场景的相同类型的重复矩阵数学也适用于神经网络计算。NVIDIA 能够顺利地从专注于游戏过渡到走在 AI 硬件的最前沿。当我第一次听说 NVIDIA 在 AI 中的作用日益增强时，我不确定它是否真的会腾飞。现在，随着他们的股价飙升和人工智能需求达到历史最高水平，很明显他们在一个意想不到的市场中发现了金矿。 在当今的人工智能世界中，像谷歌和 OpenAI 这样的公司正在追逐人工智能的进步，就像淘金热中的矿工一样。然而，NVIDIA 提供了“铲子”——使这场人工智能革命成为可能的 GPU。 这些 GPU 的价格从 10,000 美元到高端型号的 40,000 美元不等，可执行大规模训练人工智能模型所需的矩阵乘法和并行计算。由于可用的芯片数量有限且需求不断增长，NVIDIA 已迅速成为科技界最有价值的公司之一。 对于那些想知道 GPU 对游戏和人工智能为何如此重要的人来说，我的视频对此进行了分解。我介绍了 GPU 处理的特定矩阵运算和转换，解释了为什么这些设备对于游戏爱好者和 AI 研究人员来说都物有所值。 GPU 从小众游戏硬件到 AI 强国的历程是一个鼓舞人心的创新、适应和令人惊讶的新应用的故事。如果您对这些突破背后的深层机制感兴趣，请查看我的视频中的完整分解：https://www.youtube.com/watch?v=wYXARXhSoSs&amp;feature=youtu.be    提交人    /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggzx8t/what_makes_gpus_so_powerful_matrix_multiplication/</guid>
      <pubDate>Fri, 01 Nov 2024 07:26:28 GMT</pubDate>
    </item>
    <item>
      <title>如果物体是矩形物体，从稍微倾斜的角度拍摄，可以给出顶部和侧面的一部分视图，则如何标记物体</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggzsqi/how_to_label_object_if_the_object_are_rectangular/</link>
      <description><![CDATA[      我是一名正在学习计算机视觉的学生，在我的课堂上，我被分配训练yolo-obb（定向物体检测）使用自定义数据集 当我尝试标记自己的数据集时，我意识到它不是完全平坦的，只能提供侧面的部分视图 我应该标记所有可见部分（图像 1）还是只标记顶部部分（例如图像 2）？ 如果我的英语不好，请原谅 图片 1 图片 2    提交人    /u/MeasurementChoice917   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggzsqi/how_to_label_object_if_the_object_are_rectangular/</guid>
      <pubDate>Fri, 01 Nov 2024 07:15:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该发布关于机器学习的笔记/博客吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</link>
      <description><![CDATA[大家好， 我是机器学习的硕士生（本科电气和计算机工程专业 + 3 年软件/网络开发经验）。现在，我是一名全日制学生，也是机器学习实验室的研究助理。 事情是这样的：我在机器学习方面完全是个菜鸟。比如，如果你认为使用 API 和人工智能工具意味着你“了解机器学习”，那么我要说这不算数。我对机器学习着迷了一段时间，并试图自学，但大多数课程都非常抽象。 事实证明，机器学习涉及大量数学。当然，有一些很酷的库，但如果你不懂数学，祝你好运改进你的模型。过去几个月，我一直在研究一些复杂的数学——高级线性代数、矩阵方法、信息论——同时在我的实验室从头开始构建一个 transformer 训练管道。这太让人不知所措了。说实话，我因为迷茫而崩溃了好几次。 但事情开始变得明朗起来。我最大的挣扎是不知道为什么以及如何使用我所学的东西。感觉我只是顺其自然，希望它最终会有意义，有时确实如此……但它花费的时间比它应该的要长得多。另外，我有没有提到数学？这不是高中数学；我们说的是研究生水平，甚至是博士水平的数学。而且大多数时候，你必须阅读最近的研究论文并解码这些符号以将它们应用于你的问题。 所以这是我的问题是：我挣扎了很多，也许其他人也一样？也许我只是反应慢。但我一路上都做了笔记，试图简化那些我希望有人能更好地解释的概念。我应该将它们作为博客/子堆栈/网站分享吗？我觉得知识最好是分享的，尤其是在一个想要一起学习的社区里。我很乐意与大家一起学习，一起探索这些很酷的东西。 关于从哪里开始或哪种格式可能最好的想法？    提交人    /u/ziggyboom30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</guid>
      <pubDate>Fri, 01 Nov 2024 04:33:48 GMT</pubDate>
    </item>
    <item>
      <title>迷路了！救命</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggxjgf/lost_help/</link>
      <description><![CDATA[所以，我刚刚开始学习机器学习，老实说，我不知道从哪里开始！如果有人有一些可靠的免费资源可以系统地列出所有内容，我将不胜感激。任何关于我应该如何开始的提示也都很棒。    提交人    /u/BowlInternational584   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggxjgf/lost_help/</guid>
      <pubDate>Fri, 01 Nov 2024 04:28:57 GMT</pubDate>
    </item>
    <item>
      <title>ML 工程师 techstack - 2024 年</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggx4yk/ml_engineer_techstack_2024/</link>
      <description><![CDATA[感谢大家的帮助。 对于任何计划从大数据/后端转向 MLE 作为工作角色的人，您会推荐哪种技术堆栈。我知道大多数基本原理保持不变，但肯定有一些偏好是大多数公司使用的工具？ 例如：在数据中，那就是 Spark 和 Airflow 对 MLE 有任何类似的想法吗？    提交人    /u/RobotsMakingDubstep   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggx4yk/ml_engineer_techstack_2024/</guid>
      <pubDate>Fri, 01 Nov 2024 04:03:53 GMT</pubDate>
    </item>
    <item>
      <title>VAE 中的后验、证据、先验和可能性是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggp3u5/what_is_the_posterior_evidence_prior_and/</link>
      <description><![CDATA[      嗨， 在变分自动编码器 (VAE) 中，我们尝试学习一些数据的分布。为此，我们有“两个”端到端训练的神经网络。第一个网络，即编码器，对分布 q(z|x) 进行建模，即给定 x 预测 z。第二个网络对后验 q(x|z) 和 p_theta(x|z) 进行近似建模，即，对给定潜在变量 z 的 x 采样分布进行建模。 https://preview.redd.it/ti93kfzsp5yd1.png?width=658&amp;format=png&amp;auto=webp&amp;s=cbe1ff00503ed8dfdd11145ef37fd030e07d0475 阅读文献似乎 VAE 的优化目标是最大化 ELBO。这意味着最大化 p_theta(x)。但是，我想知道 p_theta(x) 不是先验吗？它是证据吗？ 我的疑问只是关于行话。让我解释一下。对于具有两个随机变量 A 和 B 的给定条件概率，我们有： p(B|A) = p(A|B)*p(B)/P(A) - p(B|A) 是后验 - p(A|B) 是似然 - p(B) 是先验 - P(A) 是证据 好吧，对于 VAE，解码器将尝试近似后验 q(x|z)。在 VAE 中，似然是 q(z|x)，这意味着后验是 q(x|z)，证据是 q(z)，先验是 q(x)。好吧，如果 VAE 的目标是最大化 ELBO（证据下限），并且 p_theta(x|z) 是后验 q(x|z) 的近似值，那么鉴于 q(z) 是证据，证据应该是 p_theta(z)，对吗？这就是我不明白的，因为他们说 p_theta(x) 现在是证据……但那是 q 中的先验…… q 和 p_theta 分布是否不同，并且它们具有不同的似然、先验、证据和后验？q 和 p_theta 的似然、先验、证据和后验是什么？ 谢谢！    提交人    /u/CompSciAI   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggp3u5/what_is_the_posterior_evidence_prior_and/</guid>
      <pubDate>Thu, 31 Oct 2024 21:07:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>