<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sat, 02 Nov 2024 01:14:33 GMT</lastBuildDate>
    <item>
      <title>机器学习问题：训练时间</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghhzzm/ml_question_training_times/</link>
      <description><![CDATA[我一直在与 chatgpt 合作构建一个模型，该模型将为交易机器人提供趋势方向信息。我尝试使用相关性和图像识别来实现这一点。训练器开始了，但预计完成的时间范围非常大。我已经做了一些工作来优化它，但我正在分享我正在做的事情的细节，希望有人能告诉我这些训练时间是否太长或合适。根据批次/块比率，我很难找到最佳时间范围。有人能给我建议或者指明方向吗？ 项目概述：使用 TensorFlow 在市场数据上训练 CNN 数据集和结构  数据：50,000 张代表市场价格数据（蜡烛图）的图像。 输入：每个训练样本每个 UUID 包含 3 张图像，每个工具一张（黄金、白银、铜）。 图像规格：每张图像为 400x200 像素，预处理为 RGB 并规范化为 [0, 1]。  模型架构  模型：具有三个分支的 CNN（每个工具一个）。每个分支应用以下层： 数据增强：水平翻转、旋转、缩放 卷积层：两个 Conv2D 层，具有 128 个过滤器和批量规范化 池化：MaxPooling 后跟全局平均池化，以实现空间适应性  密集层：连接分支后，应用具有 L2 正则化的密集层（256 个单位），然后是用于正则化的 dropout，最后是 S 形输出。  硬件设置  系统规格： CPU：22 个 vCPU（Intel Xeon E5-2680 v4） RAM：148 GB GPU：3x NVIDIA V100（每个 16 GB，使用 TensorFlow MirroredStrategy 运行以进行多 GPU 训练）   训练参数  批次大小：18（用于平衡内存和计算使用情况） 块大小：100 个样本（用于在可管理的集合中处理） 时期：每个块最多 4 个，但启用早期停止以避免过度拟合。 时间限制：可调整的上限（例如 1 小时）以控制训练运行时间。  执行详细信息  具有时间限制的分块训练：为了处理内存和运行时限制，训练以块为单位执行，允许基于在时间限制内。每个块都经过约 20% 的数据集的验证和训练。 并行性：使用 TensorFlow 的 MirroredStrategy 进行 GPU 加速训练，同时在 CPU 核心上进行并行图像预处理。 调试选项：可调整的 debug_file_limit 以控制测试数据规模。  性能和效率  大约。运行时：批次大小为 18，样本块为 100 个，训练通常需要几个小时，具体取决于目标时期和时间限制。 挑战：管理数据输入大小与 GPU 内存，最大限度地减少文件加载延迟，并优化 GPU 利用率。  此设置可在控制内存使用量和训练时间的同时实现高效训练，利用 TensorFlow 的 GPU 功能和多处理在高性能 CPU 上进行预处理。    提交人    /u/whiskeyplz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghhzzm/ml_question_training_times/</guid>
      <pubDate>Fri, 01 Nov 2024 22:41:36 GMT</pubDate>
    </item>
    <item>
      <title>学习高等数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghfplr/studying_advanced_math/</link>
      <description><![CDATA[  由    /u/FuriousBugger  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghfplr/studying_advanced_math/</guid>
      <pubDate>Fri, 01 Nov 2024 20:57:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络学习-内层可视化</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghfcqo/neural_network_learning_inner_layer_visualization/</link>
      <description><![CDATA[        提交人    /u/SemperZero   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghfcqo/neural_network_learning_inner_layer_visualization/</guid>
      <pubDate>Fri, 01 Nov 2024 20:41:01 GMT</pubDate>
    </item>
    <item>
      <title>Andrew Ng 课程需要指导。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghf4h2/guidance_needed_for_andrew_ng_cource/</link>
      <description><![CDATA[大家好，AI 社区。我想从头开始学习 AI，所以我开始学习 Andrew 的课程。我已经完成了 1 周的课程，感觉很好。我发现的唯一问题是我是一名学生，只想学习这门课程，所以我正在旁听。因此，所有实验室和可选实验室都被锁定了。（所以我从一些 GitHub repo 下载了它们。）我认为我唯一缺少的是练习。现在，我已经学习了 1.5 周（特征缩放方法）。开始实践项目是否太早了？如果不是，请指导我。    提交人    /u/reyprince   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghf4h2/guidance_needed_for_andrew_ng_cource/</guid>
      <pubDate>Fri, 01 Nov 2024 20:30:43 GMT</pubDate>
    </item>
    <item>
      <title>本科生如何开始涉足机器学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gheygx/how_to_start_breaking_into_machine_learning_as_an/</link>
      <description><![CDATA[大家好， 我目前是一名大二学生，主修计算机工程和物理，希望进入机器学习领域，希望今年夏天能在该领域获得实习机会。但是，我感觉自己总体上有点落后。我最近在大一结束时将专业转到了计算机工程专业，所以我只有用 Python 编写代码的实际经验，但我对数据结构和算法没有太多经验，所以我现在正在尝试自学。我目前也在尝试学习 PyTorch，希望能为我加入的研究实验室做出一些贡献，但这需要一次性学习很多新信息。除此之外，许多实习生都希望招聘具有 C++ 知识的人，但我对这门语言知之甚少，也想学习它。很多人说要通过项目来学习，但我觉得每当我想做一个项目时，我都需要有人在整个编码过程中帮我，而不是自己建立一个项目。我也不完全理解 C++ 的语法。我认为我现在需要的是一些结构和建议，这样我就可以让自己走上正轨，在今年夏天获得实习机会。如果有人有有用的学习资源，那就太好了！任何东西都会受到赞赏，非常感谢！     提交人    /u/Relation-Different   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gheygx/how_to_start_breaking_into_machine_learning_as_an/</guid>
      <pubDate>Fri, 01 Nov 2024 20:23:07 GMT</pubDate>
    </item>
    <item>
      <title>在将 AI 部署到生产过程中，哪些监控方法和工具可以帮助您应对挑战？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghd8hn/what_monitoring_methods_and_tools_help_you_tackle/</link>
      <description><![CDATA[考虑到在现实环境中部署 AI 的复杂性，您如何处理幻觉、数据漂移和模型安全等问题？我很好奇哪些工具和方法可以保持模型的稳定和可靠。    提交人    /u/kgorobinska   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghd8hn/what_monitoring_methods_and_tools_help_you_tackle/</guid>
      <pubDate>Fri, 01 Nov 2024 19:07:41 GMT</pubDate>
    </item>
    <item>
      <title>我从 Coursera 上的 Andrew Ng 的机器学习课程开始学习？这是正确的步骤吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ghcgeq/im_starting_with_andrew_ngs_course_on_coursera/</link>
      <description><![CDATA[基本上，我是一名二年级工程专业的学生。我懂工程数学和数据结构、编程和一点统计学。    提交人    /u/Southern_Text2456   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ghcgeq/im_starting_with_andrew_ngs_course_on_coursera/</guid>
      <pubDate>Fri, 01 Nov 2024 18:33:44 GMT</pubDate>
    </item>
    <item>
      <title>学习 Hopfield 网络，该模型荣获 2024 年物理学诺贝尔奖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gha40f/learn_hopfield_networks_the_model_that_won_the/</link>
      <description><![CDATA[        由    /u/Intelligent-Field-97  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gha40f/learn_hopfield_networks_the_model_that_won_the/</guid>
      <pubDate>Fri, 01 Nov 2024 16:54:01 GMT</pubDate>
    </item>
    <item>
      <title>金融机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh8axo/machine_learning_for_finance/</link>
      <description><![CDATA[你们中有多少人在金融领域使用过 ML？在交易领域呢？这种体验是什么样的？对于已经使用 ML 进入该行业的人来说，需要具备哪些技能？    提交人    /u/Loose-Way-9183   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh8axo/machine_learning_for_finance/</guid>
      <pubDate>Fri, 01 Nov 2024 15:38:23 GMT</pubDate>
    </item>
    <item>
      <title>机器学习初学者：这份路线图完整吗？还是缺少什​​么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh6r2m/beginner_in_ml_is_this_roadmap_complete_or/</link>
      <description><![CDATA[        提交人    /u/Objective-Menu-7133   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh6r2m/beginner_in_ml_is_this_roadmap_complete_or/</guid>
      <pubDate>Fri, 01 Nov 2024 14:30:27 GMT</pubDate>
    </item>
    <item>
      <title>您会推荐数据科学硕士学位吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh4x1f/would_you_recommend_a_masters_degree_in_data/</link>
      <description><![CDATA[我目前从事数据质量工作，我想攻读数据科学和机器学习硕士学位。在这个领域获得硕士学位是否值得？如果不值得，你会推荐什么？我今年 24 岁，男，商学院毕业    提交人    /u/SilentAnalyst0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh4x1f/would_you_recommend_a_masters_degree_in_data/</guid>
      <pubDate>Fri, 01 Nov 2024 13:06:09 GMT</pubDate>
    </item>
    <item>
      <title>神经网络推理的最快方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gh3hhn/quickest_method_of_neural_network_inference/</link>
      <description><![CDATA[我遇到的情况是需要多次从已加载的 NN 模型中进行预测。 请注意，我每次仅对小批量数据调用 .predict()。不确定这是否相关，但可能相关。 我本质上是在运行模拟（~10k 次迭代），每次迭代我都会调用网络进行预测。 我需要大幅加快速度。 就机器而言，我受到 CPU 限制（没有 GPU/TPU）。 我发现的当前最佳解决方案是将我的模型转换为 ONNX 模型，创建一个 InferenceSession 对象，并将此对象传递给我的各个工作器（以在我的 CPU 之间分配工作）。 ONNX 针对推理进行了优化，因此这已经足够好了。我已经修改了操作线程间/内属性等等。 我也尝试过量化我的模型，这有一点帮助，但作用不大。 有没有更好的方法？还有谁知道的其他技术吗？    提交人    /u/BasslineButty   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gh3hhn/quickest_method_of_neural_network_inference/</guid>
      <pubDate>Fri, 01 Nov 2024 11:49:24 GMT</pubDate>
    </item>
    <item>
      <title>“是什么让 GPU 如此强大？矩阵乘法！”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggzx8t/what_makes_gpus_so_powerful_matrix_multiplication/</link>
      <description><![CDATA[      https://preview.redd.it/xm1m3w4as8yd1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=f7ddc7e1e90137325b0653d931a7f807f027c70e GPU 已成为当今最必不可少（且最昂贵）的硬件之一。在我发布在 Vizuara 的 YouTube 频道上的最新视频中，我探讨了 GPU 为何如此强大、它们有何不同，以及它们如何从提升游戏图形到改造 AI：https://www.youtube.com/watch?v=wYXARXhSoSs&amp;feature=youtu.be GPU 强大的背后是它们能够快速并行执行大量矩阵乘法。矩阵乘法是 3D 图形渲染和 AI 模型训练的核心。 在游戏中，每个 3D 对象都被分解为顶点和三角形，每次游戏场景刷新时，GPU 都必须使用矩阵数学快速重新计算位置、纹理和光照。高质量的游戏会渲染数百万个顶点和三角形。如果没有 GPU，我们所熟知的游戏根本无法实现。 2008 年，我记得我曾尝试在一台没有显卡的旧电脑上运行《侠盗猎车手：圣安地列斯》。我不得不降低分辨率才能让游戏可玩。与此同时，拥有专用显卡的朋友正在享受无缝的高分辨率游戏体验。那是我第一次真正接触到 GPU 的功能。 当时，NVIDIA 仍然主要专注于增强游戏视觉效果。但是，一旦深度学习出现，GPU 用于图形的矩阵乘法运算最终就非常适合 AI。 事实上，随着 AI 研究人员开始训练更大的神经网络，他们发现用于 3D 场景的相同类型的重复矩阵数学也适用于神经网络计算。NVIDIA 能够顺利地从专注于游戏过渡到走在 AI 硬件的最前沿。当我第一次听说 NVIDIA 在 AI 中的作用日益增强时，我不确定它是否真的会腾飞。现在，随着他们的股价飙升和人工智能需求达到历史最高水平，很明显他们在一个意想不到的市场中发现了金矿。 在当今的人工智能世界中，像谷歌和 OpenAI 这样的公司正在追逐人工智能的进步，就像淘金热中的矿工一样。然而，NVIDIA 提供了“铲子”——使这场人工智能革命成为可能的 GPU。 这些 GPU 的价格从 10,000 美元到高端型号的 40,000 美元不等，可执行大规模训练人工智能模型所需的矩阵乘法和并行计算。由于可用的芯片数量有限且需求不断增长，NVIDIA 已迅速成为科技界最有价值的公司之一。 对于那些想知道 GPU 对游戏和人工智能为何如此重要的人来说，我的视频对此进行了分解。我介绍了 GPU 处理的特定矩阵运算和转换，解释了为什么这些设备对于游戏爱好者和 AI 研究人员来说都物有所值。 GPU 从小众游戏硬件到 AI 强国的历程是一个鼓舞人心的创新、适应和令人惊讶的新应用的故事。如果您对这些突破背后的深层机制感兴趣，请查看我的视频中的完整分解：https://www.youtube.com/watch?v=wYXARXhSoSs&amp;feature=youtu.be    提交人    /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggzx8t/what_makes_gpus_so_powerful_matrix_multiplication/</guid>
      <pubDate>Fri, 01 Nov 2024 07:26:28 GMT</pubDate>
    </item>
    <item>
      <title>我应该发布关于机器学习的笔记/博客吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</link>
      <description><![CDATA[大家好， 我是机器学习的硕士生（本科电气和计算机工程专业 + 3 年软件/网络开发经验）。现在，我是一名全日制学生，也是机器学习实验室的研究助理。 事情是这样的：我在机器学习方面完全是个菜鸟。比如，如果你认为使用 API 和人工智能工具意味着你“了解机器学习”，那么我要说这不算数。我对机器学习着迷了一段时间，并试图自学，但大多数课程都非常抽象。 事实证明，机器学习涉及大量数学。当然，有一些很酷的库，但如果你不懂数学，祝你好运改进你的模型。过去几个月，我一直在研究一些复杂的数学——高级线性代数、矩阵方法、信息论——同时在我的实验室从头开始构建一个 transformer 训练管道。这太让人不知所措了。说实话，我因为迷茫而崩溃了好几次。 但事情开始变得明朗起来。我最大的挣扎是不知道为什么以及如何使用我所学的东西。感觉我只是顺其自然，希望它最终会有意义，有时确实如此……但它花费的时间比它应该的要长得多。另外，我有没有提到数学？这不是高中数学；我们说的是研究生水平，甚至是博士水平的数学。而且大多数时候，你必须阅读最近的研究论文并解码这些符号以将它们应用于你的问题。 所以这是我的问题是：我挣扎了很多，也许其他人也一样？也许我只是反应慢。但我一路上都做了笔记，试图简化那些我希望有人能更好地解释的概念。我应该将它们作为博客/子堆栈/网站分享吗？我觉得知识最好是分享的，尤其是在一个想要一起学习的社区里。我很乐意与大家一起学习，一起探索这些很酷的东西。 关于从哪里开始或哪种格式可能最好的想法？    提交人    /u/ziggyboom30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</guid>
      <pubDate>Fri, 01 Nov 2024 04:33:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>