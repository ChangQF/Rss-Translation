<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 12 Apr 2024 21:12:29 GMT</lastBuildDate>
    <item>
      <title>为什么选择 U-Net 而不是 Transformers？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2kbsx/why_unet_instead_of_transformers/</link>
      <description><![CDATA[最近，我开始阅读越来越多有关扩散模型的内容，以及它们的基本模型如何是 U-net，其组件根据用例而变化。我们需要一个保留其形状的模型。那么为什么不使用变压器而不是U-Net呢？扩散模型的威力是在U-Net中还是在它使用的过程中？如果权力在这个过程中，那么改变 U 形网所产生的差异应该不会那么明显。    由   提交 /u/SmartEvening   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2kbsx/why_unet_instead_of_transformers/</guid>
      <pubDate>Fri, 12 Apr 2024 21:07:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么概率推理中不使用事件并集？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2jy2n/why_are_unions_of_events_not_used_in/</link>
      <description><![CDATA[我注意到机器学习中概率推理的主要重点是与联合事件有关，因此大多数定律都是建立在这（边缘化、因式分解、贝叶斯定理等）。这是为什么？   由   提交/u/momma6969  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2jy2n/why_are_unions_of_events_not_used_in/</guid>
      <pubDate>Fri, 12 Apr 2024 20:51:24 GMT</pubDate>
    </item>
    <item>
      <title>Frechet 起始距离应该在什么之间计算？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2jr5c/between_what_should_the_frechet_inception/</link>
      <description><![CDATA[我了解 FID 的工作原理，因为它本质上比较 2 组图像。但我不确定我们要比较的两组应该是什么。 对于上下文，我正在尝试实现 Muse (https://arxiv.org/abs/2301.00704）。 Muse 的工作原理大致如下： - 编码器将图像编码为多个标记（例如 64），其中每个标记采用几个可能值之一（例如 8192） - 解码器根据标记重建图像 - 转换器接收文本标记并生成希望与文本标记匹配的图像标记 实际的图像生成如下所示：  - 将一段文本传递给转换器 - 转换器生成图像标记 - 解码器将这些图像标记解码为图像 - p&gt; 就计算 FID 而言，我看到有 2 个选项： - 从数据集中获取原始图像，将其传递给编码器，然后将生成的标记传递给解码器。计算原始图像和重建图像之间的 FID  - 获取图像标题（我的数据集有成对的图像 - 图像标题），将其传递给转换器，获取图像标记，对其进行解码以获得图像。计算原始图像和生成图像之间的FID 第二个对我来说似乎更合理，因为它正在测试整个模型。 还有训练集和训练集的问题测试集。我应该计算测试集上的 FID 吗？我看到一个 github 问题，有人提到在训练集上计算它，这对我来说似乎有点奇怪。在测试集和训练集之间计算它也是有意义的，尽管在这种情况下，我必须采用训练集的子集，因为它比测试集大。 如果有人能为我澄清这个问题，我将不胜感激。谢谢！   由   提交 /u/EltMenim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2jr5c/between_what_should_the_frechet_inception/</guid>
      <pubDate>Fri, 12 Apr 2024 20:43:31 GMT</pubDate>
    </item>
    <item>
      <title>如何处理系统提示的生成？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2jpoh/how_to_approach_system_prompt_generation/</link>
      <description><![CDATA[非常感谢您对我正在解决的问题的想法。 我正在构建一个基于 LLM 的聊天产品，并正在寻找进行赛马5-10系统提示选出获胜者。计划使用同一组用户输入测试所有提示，并比较输出以选择最佳系统提示。 （即，哪种提示会产生最相关、简洁和适当的反应，同时对幻觉和提示注射具有最大的弹性）。我知道随着获得更多数据，我需要不断完善，但我想为我的开始提示找到一些理由。  我的问题：如何有效地生成最初的 5-10 个提示，同时减少自己的偏见？我对在那里放什么有很强的想法，但我是一个创造力有限的人，我可能会错过一些机会。  你们如何看待提示生成/测试？你们有什么建议吗？我可以在哪些地方获取/生成提示？  谢谢！    由   提交/u/douglasadams420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2jpoh/how_to_approach_system_prompt_generation/</guid>
      <pubDate>Fri, 12 Apr 2024 20:41:49 GMT</pubDate>
    </item>
    <item>
      <title>我是一名非计算机科学毕业生，我缺少一些基础知识，您认为哪些基础知识对于从事 AL 和 ML 职业至关重要？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2ih35/im_a_non_cs_graduate_and_im_missing_some/</link>
      <description><![CDATA[   /u/Tough_Kale_1525   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2ih35/im_a_non_cs_graduate_and_im_missing_some/</guid>
      <pubDate>Fri, 12 Apr 2024 19:50:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Tensorflow 、 Tensor-Hub 和 Python 对地标进行分类？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2gdra/how_to_classify_landmarks_using_tensorflow/</link>
      <description><![CDATA[      https://preview.redd.it/v24zmpclc3uc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=860f659692fd52 b60a0e0cc07c91bd58feccad10 嗨， 这是一个 Tensorflow 教程，使您能够使用预先训练的 Tensor-Hub 平台对世界地标进行分类。 我们将如何安装相关的 Python 库，寻找正确的预训练模型，并学习如何使用它对欧洲的地标图像进行分类。 视频教程的链接位于：https://youtu.be/IJ5Z9Awzxr4 我还在视频说明中分享了 Python 代码的链接。 享受吧 Eran #Python #Cnn #TensorFlow #AI #Deeplearning #TensorFlow #ImageClassification #TransferLearning #Python #DeepLearning #ArtificialIntelligence #PretrainedModels #ImageRecognition #OpenCV #ComputerVision #Cnn   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2gdra/how_to_classify_landmarks_using_tensorflow/</guid>
      <pubDate>Fri, 12 Apr 2024 18:24:08 GMT</pubDate>
    </item>
    <item>
      <title>作为一名非计算机科学学生，我应该学习多深的理论？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2foo3/as_a_noncs_student_how_deep_should_i_learn_theory/</link>
      <description><![CDATA[我正在学习成为一名计算神经科学家。我需要学习 ML 才能学习 DL（抱歉，但我不太清楚我的目标，我想以后在 BCI 领域工作）。 我阅读了不同的课程（并且很多数学）但问题是我不知道我应该学习多少它的理论。每次我理解一部分时，我都必须学习另一堆数学才能学习下一部分，而且它们很难，所有这些纯数学让我更加困惑。 ​ 另外，我不知道我应该更多地关注理论还是编程（我知道编程，并且在金融科技行业编写了几年代码），但我对 python 不够好，一些消息来源说最好是 50/50编程和理论（没有讨论我应该关注理论的哪一部分），其他人说更多地关注理论。通过编程我的意思是1）我需要在Python中掌握多少数据结构，OOP等2）我应该在不同的框架上工作多少因为我知道如果你知道理论上你想做什么然后编码它不应该是这样很难处理文档等，但我不确定这是否适合机器学习软件。 ​ 抱歉我的基本问题，但我在这方面徘徊广阔的世界没有导师或帮助，所以我决定询问一些专家。还请原谅我的英语不好。   由   提交/u/madcraft256  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2foo3/as_a_noncs_student_how_deep_should_i_learn_theory/</guid>
      <pubDate>Fri, 12 Apr 2024 17:56:11 GMT</pubDate>
    </item>
    <item>
      <title>sdv：麻省理工学院创建了用于生成合成数据的 Python 库</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2fj56/sdv_mit_created_python_library_for_generating/</link>
      <description><![CDATA[麻省理工学院的数据到人工智能实验室创建了 sdv（合成数据库），以从现有数据集中生成真实的虚假数据。 这里是代码示例： from sdv.datasets import demo from sdv.single_table import GaussianCopulaSynthesizer 将 pandas 导入为 pd real_data,metadata = download_demo(&#39;single_table&#39;, &#39;adult&#39;) synthesizer = GaussianCopulaSynthesizer （元数据） synthesizer.fit(real_data) # 生成 1000 行合成数据 synthetic_data = Synthesizer.sample(1000) 链接到库：https://github.com/sdv-dev/SDV   由   提交 /u/semicausal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2fj56/sdv_mit_created_python_library_for_generating/</guid>
      <pubDate>Fri, 12 Apr 2024 17:49:51 GMT</pubDate>
    </item>
    <item>
      <title>多输入模型不断崩溃（内存不足）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2e4le/multiinput_model_keeps_crashing_out_of_memory/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2e4le/multiinput_model_keeps_crashing_out_of_memory/</guid>
      <pubDate>Fri, 12 Apr 2024 16:52:51 GMT</pubDate>
    </item>
    <item>
      <title>无法弄清楚为什么梯度下降在此数据集上不起作用</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2d4oo/cant_figure_out_why_gradient_descent_doesnt_work/</link>
      <description><![CDATA[      嗨，我是新来的我正在学习吴恩达 (Andrew Ng) 的机器学习专业课程。我正在尝试做一个简单的单变量线性回归数据集，并在为此数据集运行梯度下降批次时遇到问题 https://www.kaggle.com/datasets/umernaeem217/synthetic-house-prices-univariate 这是我的代码 def compute_gradient_descent_batch(X, y, w, b, alpha, num_iters): J_history = [] w_history = [] m = len(X) for i in range(num_iters): dj_dw, dj_db =compute_gradient(X, y, w, b ) w = w - alpha * dj_dw b = b - alpha * dj_db cost =compute_cost(X, y, w, b) J_history.append(cost) w_history.append(w) if i % math.ceil(num_iters/10) == 0: print(f&quot;迭代 {i:4}: 成本 {float(J_history[-1]):8.2f} &quot;) return w, b, J_history, w_history  数据集说明 按原样在数据集上运行梯度下降批次 因此，为了解决这个问题，我尝试将功能和目标缩小 1000，但这似乎并没有影响关系 缩小了 1000 当我尝试运行梯度下降批处理时现在它可以工作了，但是b截距项比通过 scikit 运行时应该低得多，并且不知道如何纠正它 https://preview.redd.it/ijsnl740p2uc1.png?width=1016&amp;format=png&amp;auto= webp&amp;s=7fabf02d31f25411dd82c302b388a02be384a410 https://preview.redd.it/aofzxb1ap2uc1.png?width=1006&amp;format=png&amp;auto=webp&amp;s=d3ba94f3b95d2348a39cba89e00d8f9008352e1c 如何解决此问题？   由   提交/u/FlavoredFrostedTits   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2d4oo/cant_figure_out_why_gradient_descent_doesnt_work/</guid>
      <pubDate>Fri, 12 Apr 2024 16:12:03 GMT</pubDate>
    </item>
    <item>
      <title>3D 场景中 2D 掩模/对象的实时长方体与圆柱体分类？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2cj4z/realtime_cuboid_vs_cylinder_classification_of_a/</link>
      <description><![CDATA[   /u/rockyearth   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2cj4z/realtime_cuboid_vs_cylinder_classification_of_a/</guid>
      <pubDate>Fri, 12 Apr 2024 15:48:20 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何行业标准流程可以让 AI CUDA 项目在 Apple 硬件上运行？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c2bvca/is_there_any_industry_standard_processes_to/</link>
      <description><![CDATA[大多数 AI 项目都是为 CUDA 构建的，以获得最佳的本地处理能力，这是有道理的。然而，即使速度缓慢，Apple 的硬件也是值得的（并且每年都在变得更好）。 那么，是否有任何现有流程/指南可以在最新的 Apple 硬件上运行这些项目？  &gt;   由   提交/u/Likeatr3b   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c2bvca/is_there_any_industry_standard_processes_to/</guid>
      <pubDate>Fri, 12 Apr 2024 15:21:49 GMT</pubDate>
    </item>
    <item>
      <title>检索增强语言建模 (REALM)</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c29ngj/retrievalaugmented_language_modeling_realm/</link>
      <description><![CDATA[我刚刚发现（我认为是）原始的 REALM 论文，“检索增强语言模型预训练”。非常有趣的想法，但是关于猎犬的角色，有一些关键细节我没有注意到。我希望这里有人能纠正我的观点：  首先也是最关键的是，检索增强仅与生成模型相关吗？你听说过很多关于RAG，但是就不能有像RAU这样的东西吗？就像为下游非生成任务 Y 编码某些文本 X 一样，编码器可以访问知识存储，从中识别、检索相关信息，然后将其包含在嵌入过程中以细化模型对原始文本的表示X？从概念上讲，这对我来说是有意义的，而且这似乎是 REALM 论文所做的（其中任务 Y 是 QA），但我在网上找不到此类事情的任何其他示例。检索增强似乎只适用于生成任务。那么，是的，情况总是如此，还是 RAU 也存在？ 如果语言模型是使用检索增强进行训练的，那就意味着检索器是模型架构，对吗？换句话说，在推理时间中，必须始终进行一些检索，这进一步意味着从中检索文档的知识存储也必须始终存在，对吗？或者检索部分周围的所有机制都只是训练的产物，可以在学习完成后丢弃？ REALM 的主要好处是它允许的较小的模型？ 这个问题背后的基本原理：如果没有检索步骤，模型的 100% 的潜在知识必须包含在注意力机制的权重内（我认为）。对于预计几乎了解一切的基础模型，这需要大量的权重。然而，如果模型可以通过某些其他机制（例如检索增强）将上下文注入到表示中，则检索后模型的其余部分（例如注意机制）要做的工作更少，并且可以更小/更简单。我理解这里的大思想了吗？    由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c29ngj/retrievalaugmented_language_modeling_realm/</guid>
      <pubDate>Fri, 12 Apr 2024 13:49:56 GMT</pubDate>
    </item>
    <item>
      <title>目前的机器学习研究生，您是否担心人工智能的指数级进步？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c23mpp/current_ml_grad_students_are_you_worried_about/</link>
      <description><![CDATA[对于目前正在攻读 ML/AI 研究生课程或计划攻读 ML/AI 研究生课程的人，您是否曾经担心 AI 可能会发展得足够远？当您毕业时，您正在寻找的工作/职位可能不再存在？   由   提交/u/coronary-service  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c23mpp/current_ml_grad_students_are_you_worried_about/</guid>
      <pubDate>Fri, 12 Apr 2024 08:05:07 GMT</pubDate>
    </item>
    <item>
      <title>训练曲线急剧下降</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1c1pr26/training_curve_going_down_steeply/</link>
      <description><![CDATA[     &lt; td&gt; 训练我的模型 300，我得到了这个图。曲线急剧下降，列车损失在最初的时期并没有减少太多。 （优化器 - AdamW，lr= 0.001）可能的问题是什么？    由   提交/u/Inknown_Complaint67   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1c1pr26/training_curve_going_down_steeply/</guid>
      <pubDate>Thu, 11 Apr 2024 20:44:06 GMT</pubDate>
    </item>
    </channel>
</rss>