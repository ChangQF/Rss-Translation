<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sat, 11 May 2024 15:13:00 GMT</lastBuildDate>
    <item>
      <title>我如何实施研究论文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpiy9a/how_can_i_implement_research_papers/</link>
      <description><![CDATA[我如何实现下面这样的论文？我只有Python的基础知识。 https://pubmed.ncbi.nlm.nih。 gov/31202397/ https://doi.org/10.1007/s00530 -021-00827-0 https://www.ijcai .org/Proceedings/09/Papers/168.pdf   由   提交 /u/iiillililiilililiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpiy9a/how_can_i_implement_research_papers/</guid>
      <pubDate>Sat, 11 May 2024 14:39:09 GMT</pubDate>
    </item>
    <item>
      <title>为 500.000 位用户打造 Julius AI、参与 YC、AI 资助、Twitter 接管恶作剧等等！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphroq/building_julius_ai_to_500000_users_getting_into/</link>
      <description><![CDATA[    /u/gordicaleksa   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphroq/building_julius_ai_to_500000_users_getting_into/</guid>
      <pubDate>Sat, 11 May 2024 13:41:34 GMT</pubDate>
    </item>
    <item>
      <title>如果我的目标是 LPA 季风降雨量，我应该使用什么类型的数据集，我应该获取每日、每月或每年的数据？ “[研究]”、“[R]”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphmpn/what_type_of_dataset_should_i_use_if_iam/</link>
      <description><![CDATA[如果我的目标是 LPA 季风降雨量，我应该使用什么类型的数据集，我应该采用每日、每月还是每年的数据？我正在使用数据集进行长期季风预报   由   提交 /u/Nice-Musician6346    reddit.com/r/learnmachinelearning/comments/1cphmpn/what_type_of_dataset_should_i_use_if_iam/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphmpn/what_type_of_dataset_should_i_use_if_iam/</guid>
      <pubDate>Sat, 11 May 2024 13:34:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 Riva 的 TTS 语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphgsj/language_model_for_tts_using_riva/</link>
      <description><![CDATA[您好，前段时间我创建了一个意大利语数据集来训练 tacotron2 模型。实验进行得不太顺利，我想再次尝试生成模型，这次使用 Nvidia Riva。然而，在阅读了文档并了解了自己之后，我仍然不太清楚应该如何继续。有做过类似事情的人有什么建议或者可以给我指点详细的指南吗？ 非常感谢！    ;由   提交/u/Il_Filosofo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphgsj/language_model_for_tts_using_riva/</guid>
      <pubDate>Sat, 11 May 2024 13:25:37 GMT</pubDate>
    </item>
    <item>
      <title>上下文窗口是 LLM 最终用户应该关心的方面之一。在类似于 ChatGPT 的应用程序中还有哪些其他方面需要注意？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cphgl2/context_window_is_one_of_the_aspects_that_llm/</link>
      <description><![CDATA[我正在寻找使用该工具时容易了解的方面。例如，上下文窗口是我可以理解的一个特性，因为我尝试在 ChatGPT 上做很多事情并经历了该限制。 还有哪些其他限制或可以与上下文窗口一起分类的方面？ ？ 谢谢。   由   提交 /u/FreewillMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cphgl2/context_window_is_one_of_the_aspects_that_llm/</guid>
      <pubDate>Sat, 11 May 2024 13:25:18 GMT</pubDate>
    </item>
    <item>
      <title>创建用于学习从多标签分类进行排名的数据集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cph3a5/creating_dataset_for_learning_to_rank_from/</link>
      <description><![CDATA[我遇到了一个表格多标签分类问题。标签总数为 8。我想知道是否有一种方法可以从这个多标签表格分类问题数据集创建学习排序数据集。这意味着对于每个样本，我想对这 8 个标签中的每一个进行排名。    由   提交 /u/ChaoticChaosConfused   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cph3a5/creating_dataset_for_learning_to_rank_from/</guid>
      <pubDate>Sat, 11 May 2024 13:05:48 GMT</pubDate>
    </item>
    <item>
      <title>catboost + optuna + 交叉验证 + 池（特征注释？）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpgu1d/catboost_optuna_crossvalidation_pool_feature/</link>
      <description><![CDATA[亲爱的*， 我正在寻找一些教程，展示如何将 catboost + optuna 与内部和外部 cv 一起使用（理想情况下） ）。但一个 CV 级别也足以开始。 一个不错的功能是使用 catboost 池功能来注释分类功能等。 干杯   由   提交/u/Overall-Ad-7227   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpgu1d/catboost_optuna_crossvalidation_pool_feature/</guid>
      <pubDate>Sat, 11 May 2024 12:52:01 GMT</pubDate>
    </item>
    <item>
      <title>微软Azure？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpgg77/microsoft_azure/</link>
      <description><![CDATA[嗨， 我要去参加暑期课程来学习机器学习。 （或者我想对其进行介绍） 在课程中他们有用于云计算的 Microsoft Azure。 我不太熟悉它。有什么好处吗？   由   提交/u/Environmental_Gap_65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpgg77/microsoft_azure/</guid>
      <pubDate>Sat, 11 May 2024 12:30:48 GMT</pubDate>
    </item>
    <item>
      <title>微软和清华大学的这篇 AI 论文介绍了 YOCO：一种用于语言模型的解码器-解码器架构</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpe7s3/this_ai_paper_by_microsoft_and_tsinghua/</link>
      <description><![CDATA[       由   提交/u/ashioyajotham   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpe7s3/this_ai_paper_by_microsoft_and_tsinghua/</guid>
      <pubDate>Sat, 11 May 2024 10:13:29 GMT</pubDate>
    </item>
    <item>
      <title>无法理解 Andrew ng 的 ML 简介课程 2 中发生的情况</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpds6t/cant_understand_whats_happening_in_andrew_ngs/</link>
      <description><![CDATA[我正在尝试一个名为“使用 Tensorflow 实现咖啡烘焙”的实验室，但我无法理解发生了什么。这是供您参考的实验 https://github.com/greyhatguy007/Machine-Learning-Specialization-Coursera/blob/main/C2%20-%20Advanced%20Learning%20Algorithms/week1/Optional-labs /C2_W1_Lab02_CoffeeRoasting_TF.ipynb 来源：greyhatguy007  我不明白这些函数是什么，它们在做什么，我们为什么调用它们，什么是纪元，为什么是模型摘要等。因为本课程尚未涵盖这些内容  有人可以建议我现在应该做什么吗？ （我已经达到了课程的这一点，不再进一步)   由   提交 /u/Weak_Display1131   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpds6t/cant_understand_whats_happening_in_andrew_ngs/</guid>
      <pubDate>Sat, 11 May 2024 09:42:45 GMT</pubDate>
    </item>
    <item>
      <title>109 个在线学习机器学习的最佳资源 - 2024</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cpd0yc/109_best_resources_to_learn_machine_learning/</link>
      <description><![CDATA[       由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cpd0yc/109_best_resources_to_learn_machine_learning/</guid>
      <pubDate>Sat, 11 May 2024 08:46:53 GMT</pubDate>
    </item>
    <item>
      <title>有人知道在哪里可以找到每种尺寸的 LLaMA2 详细模型规格吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cp7rqx/someone_know_where_can_i_find_llama2_detail_model/</link>
      <description><![CDATA[我正在研究bitNet1.58b。 在我的研究中，我发现fc的形状在权重量化时影响很大. 论文” 1bit llm时代”说他们从大 llama2 模型中得到了更好的结果 我想澄清一下这些模型之间的 fc 形状不同 并且想说这是它们准确性提高的原因，而不仅仅是模型的总尺寸。 那么我在哪里可以获得模型规格？   由   提交/u/Otherwise_Noise_5261   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cp7rqx/someone_know_where_can_i_find_llama2_detail_model/</guid>
      <pubDate>Sat, 11 May 2024 03:11:53 GMT</pubDate>
    </item>
    <item>
      <title>如果你不想付费 OpenAI 来做语音转文本，我写了一篇关于如何在你自己的机器上运行 OpenAI 的 Whisper 的文章</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cp5qol/if_you_dont_want_to_pay_openai_to_do_speech_to/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/jakecoolguy   [链接] &amp;# 32； &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/1cp5qol/if_you_dont_want_to_pay_openai_to_do_speech_to/&quot;&gt;[评论]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cp5qol/if_you_dont_want_to_pay_openai_to_do_speech_to/</guid>
      <pubDate>Sat, 11 May 2024 01:23:14 GMT</pubDate>
    </item>
    <item>
      <title>准备 ML 广度面试</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cox2gh/preparing_for_ml_breadth_interviews/</link>
      <description><![CDATA[FAANG+ 公司的机器学习面试通常包括机器学习广度轮。准备这些面试的最有效/高效的方法是什么？  就上下文而言，在我的 Amazon ML 面试中，我被问到的问题包括“讨论如何使用随机森林进行回归（而不是分类）”和“讨论如何使用随机森林进行回归（而不是分类）”等。 “为什么 ROPE 嵌入能够在 Transformer 中实现更大的上下文长度”。    由   提交/u/hamsterhooey  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cox2gh/preparing_for_ml_breadth_interviews/</guid>
      <pubDate>Fri, 10 May 2024 18:53:22 GMT</pubDate>
    </item>
    <item>
      <title>JSTOR 被发现缺乏</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</link>
      <description><![CDATA[       由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</guid>
      <pubDate>Thu, 09 May 2024 21:28:28 GMT</pubDate>
    </item>
    </channel>
</rss>