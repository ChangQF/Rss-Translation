<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 10 Nov 2024 06:20:57 GMT</lastBuildDate>
    <item>
      <title>一年只需 239 美元即可访问几乎所有 Coursera 课程。Coursera 为 Coursera Plus 提供 40% 折扣。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gntaa9/get_access_of_almost_all_coursera_courses_at_239/</link>
      <description><![CDATA[优惠详情：  优惠日期： 2024 年 11 月 7 日 — 2024 年 12 月 12 日（26 天） 优惠折扣：Coursera Plus 年度订阅 40% 折扣（优惠 160 美元） 限制：不包括印度、德国、讲西班牙语的拉丁美洲  从今天开始，Coursera 将为我们的 Coursera Plus 年度订阅提供 40% 的折扣。您可以无限制地访问 7,000 多门课程，包括来自 Google、Meta、Microsoft、IBM 等顶级行业领导者的专业证书 - 所有这些只需 239 美元（通常为 399 美元）即可享受 12 个月的优惠。 阅读全文。    由    /u/eham2017 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gntaa9/get_access_of_almost_all_coursera_courses_at_239/</guid>
      <pubDate>Sun, 10 Nov 2024 05:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[帮助] LSTM seq2seq 生成相同序列</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnq81z/help_lstm_seq2seq_generating_same_sequence/</link>
      <description><![CDATA[Kaggle Notebook 我正在尝试在 pytorch 中实现 seq2seq 模型来进行翻译。问题是模型生成相同的序列。我的目标是实现 seq2seq 的注意力，然后最终转向 transformers。有人可以看看我的代码吗（还附有 kaggle 笔记本）： class Encoder(nn.Module): def __init__(self,vocab_size,embedding_dim,hidden_​​dim,num_layers): super(Encoder,self).__init__() self.vocab_size = vocab_size self.embedding_dim = embedding_dim self.hidden_​​dim = hidden_​​dim self.num_layers = num_layers self.embedding = nn.Embedding(self.vocab_size,self.embedding_dim) self.lstm = nn.LSTM(self.embedding_dim,self.hidden_​​dim,self.num_layers,batch_first=True) def forward(self,x): x = self.embedding(x) output,(hidden_​​state,cell_state) = self.lstm(x) return输出，hidden_​​state，cell_state 类解码器（nn.Module）： def __init__（self，vocab_size，embedding_dim，hidden_​​dim，num_layers）： super（Decoder，self）。__init__（） self.vocab_size = vocab_size self.embedding_dim = embedding_dim self.hidden_​​dim = hidden_​​dim self.num_layers = num_layers self.embedding = nn.Embedding（self.vocab_size，self.embedding_dim） self.lstm = nn.LSTM（self.embedding_dim，self.hidden_​​dim，self.num_layers，batch_first=True） self.fc = nn.Linear（self.hidden_​​dim，self.vocab_size） def forward（self，x，h，c）： x = self.embedding（x）输出，（hidden_​​state，cell_state）= self.lstm（x）输出=self.fc（输出）返回输出，h，c class Seq2Seq（nn.Module）：def __init__（self，encoder，decoder）：super（Seq2Seq，self）。__init__（）self.encoder =编码器self.decoder =解码器def forward（self，X，Y）：输出，h，c =编码器（X）decoder_input = Y [：，0]。到（torch.int32）输出_tensor = torch.zeros（Y.shape[0]，Y.shape[1]，FR_VOCAB_SIZE）。到（device）#output_tensor [：，0] = Y [：，0]#设置相同的起始标记，即&lt;START&gt;&gt;对于范围内的 i（1，Y.shape [1]）： output_d，h，c = 解码器（decoder_input，h，c）# 输出形状：（b​​atch_size，fr_vocab_size）coder_input = torch.argmax（output_d，dim = 1）# 输出形状：（b​​atch_size，1）output_tensor [：，i] = output_d return output_tensor # 输出形状：（b​​atch_size，seq_length）class Seq2Seq2（nn.Module）：def __init__（self，encoder，decoder）：super（Seq2Seq2，self）。__init__（）self.encoder = 编码器self.decoder = 解码器def forward（self，X，Y）：output，h，c = 编码器（X）decoder_input = Y [：，：-1] 。到（torch.int32）output_tensor，h，c = self.decoder（decoder_input，h，c）返回output_tensor 编码器 = 编码器（ENG_VOCAB_SIZE，32,64,1）.to（设备） 解码器 = 解码器（FR_VOCAB_SIZE，32,64,1）.to（设备） 模型 = Seq2Seq2（编码器，解码器）.to（设备） lr = 0.001 优化器 = torch.optim.Adam（model.parameters（），lr=lr） loss_fn = nn.CrossEntropyLoss（ignore_index=0） epochs = 20 for epoch in range(epochs): running_loss = 0.0 progress_bar = tqdm（train_dataloader，desc=f“Epoch {epoch+1}”，leave=False） for X，Y in progress_bar： Y_pred = 模型（X，Y）# Y = Y[:,1:]# Y_pred = Y_pred[:,:-1,:] Y_pred = Y_pred.reshape(-1, Y_pred.size(-1)) # 展平为 (batch_size * seq_length, vocab_size) Y_true = Y[:,1:] Y_true = Y_true.reshape(-1) # 展平为 (batch_size * seq_length) loss = loss_fn(Y_pred, Y_true) optimizer.zero_grad() loss.backward() optimizer.step() # 更新运行损失并在 tqdm 中显示 running_loss += loss.item() progress_bar.set_postfix(loss=loss.item()) print(f&quot;Epoch {epoch+1}, Loss = {running_loss/len(train_dataloader)}&quot;)     submitted by    /u/Disastrous_Pie9783   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnq81z/help_lstm_seq2seq_generating_same_sequence/</guid>
      <pubDate>Sun, 10 Nov 2024 02:14:57 GMT</pubDate>
    </item>
    <item>
      <title>开始机器学习的最佳资源和建议？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnnjkh/best_resources_advice_for_getting_started_in/</link>
      <description><![CDATA[我打算学习机器学习，但我才刚刚开始攻读计算机科学学位，面对众多选择，我感到有些不知所措。我很想得到一些关于从哪里开始的指导，尤其是因为我想攻读机器学习硕士学位，并且想成为一名出色的申请人。 我有一些问题：  我应该先专注于学习数学，还是深入研究实用的机器学习并边学边学？ 您会推荐哪些在线课程或资源？ 我如何才能提高进入优秀机器学习硕士课程的机会。  提前感谢您的回答 :)    提交人    /u/Kerensky0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnnjkh/best_resources_advice_for_getting_started_in/</guid>
      <pubDate>Sat, 09 Nov 2024 23:55:41 GMT</pubDate>
    </item>
    <item>
      <title>跟踪噪声测量的算法建议？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnjobu/algorithm_suggestions_for_tracking_noisy/</link>
      <description><![CDATA[我正在跟踪一个带有噪声测量的时间值，并且有兴趣了解给定时刻的基础值的估计值，以及该值在每个时刻的估计误差。 （本质上，值加减误差，都是时间函数）。 例如，如果实际值随时间呈阶跃函数，则测量值在跳转到新值时会发生一些转变，并且在该转变期间，误差会激增。 我一直在尝试使用卡尔曼滤波器的贝叶斯线性动态系统。 （我可能错误地实现了这一点）但它似乎变得越来越确定，即使错误严重。对于这种类型的问题，有没有好的算法可以推荐？ 此外，测量噪声是高斯噪声，我知道它的分布是什么，如果这有帮助的话。    提交人    /u/tinySparkOf_Chaos   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnjobu/algorithm_suggestions_for_tracking_noisy/</guid>
      <pubDate>Sat, 09 Nov 2024 20:52:46 GMT</pubDate>
    </item>
    <item>
      <title>比较两个角色</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnj6ss/compare_two_roles/</link>
      <description><![CDATA[大家好，我收到了一家小型保险公司的录用通知，我是一名数据科学家，工作内容是预测客户行为并将其输入风险方程（包括部署和监控），但我认为这个职位缺乏工作与生活的平衡。我目前的职位是机器学习工程师，主要使用 GPT 等 genAI 进行研究和概念验证，这是一家工作与生活平衡性很好的大型保险公司。我收到的录用通知比我现在的职位高出约 10%，请分享一些建议，因为我正在努力做出明智的决定    提交人    /u/Putrid_Earth3846   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnj6ss/compare_two_roles/</guid>
      <pubDate>Sat, 09 Nov 2024 20:30:17 GMT</pubDate>
    </item>
    <item>
      <title>训练期间测试准确率不稳定意味着什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gniryc/what_does_a_volatile_test_accuracy_during/</link>
      <description><![CDATA[      在训练分类神经网络时，我一直得到非常不稳定/“跳跃”的测试准确率？这仍然是我对网络进行微调的早期阶段，但我很好奇这是否对模型有任何众所周知的影响？我怎样才能让它在更高的准确度下稳定下来？我很感激任何关于此的反馈或想法。     提交人    /u/learning_proover   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gniryc/what_does_a_volatile_test_accuracy_during/</guid>
      <pubDate>Sat, 09 Nov 2024 20:11:05 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型背后的数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnfb6o/math_behind_diffusion_models/</link>
      <description><![CDATA[有没有人有任何好的资源可以清楚地解释扩散模型背后的数学原理？    提交人    /u/amirdol7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnfb6o/math_behind_diffusion_models/</guid>
      <pubDate>Sat, 09 Nov 2024 17:34:57 GMT</pubDate>
    </item>
    <item>
      <title>SOTA 架构用于构建依赖于图片中显示的文本的图像分类器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnel4g/sota_architecture_to_build_image_classifiers/</link>
      <description><![CDATA[我目前正在尝试构建一个简单的多类图像分类器。我想使用预训练模型进行图像嵌入。但是，为了可靠地区分我的任务的类别，该模型还需要考虑图像中显示的文本/数字。每个要分类的图像的文本数量不是固定的。 大多数视觉编码器的输入大小都相当小，这使得模型可以理解文本，需要使用不同的方法提取所需的文本，例如使用 OCR 工具。 我的想法是运行检测 + 识别 OCR 工具，然后使用文本编码器嵌入识别的文本，然后根据图像中的边界框位置添加位置嵌入。 但是，给定“n”嵌入的文本 + 嵌入的图像，那么将它们组合起来并将它们输入分类头的最佳方法是什么？ 一般来说，我尝试采用的方法是否可行，或者除了一般的图像结构之外，还有其他方法可以确保将图像中的文本考虑在内？ 提前谢谢大家！    提交人    /u/Ok-Middle4477   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnel4g/sota_architecture_to_build_image_classifiers/</guid>
      <pubDate>Sat, 09 Nov 2024 17:02:32 GMT</pubDate>
    </item>
    <item>
      <title>新手询问如何为拥有 150 万数据的网站构建 LLM 或生成式 AI</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gnarbb/newbie_asking_how_to_build_an_llm_or_generative/</link>
      <description><![CDATA[我是一名开发人员，但对 AI 来说是新手，这是我发布的第一个关于它的问题。 我们的非营利网站托管着人物数据，例如传记。我正在寻找构建类似 chatgpt 的东西，它可以帮助用户搜索并理解这些数据。 例如，如果有人问“南卡罗来纳州有多少人死于新冠病毒并结婚”，它就能告诉你。 基本上是一个基于我们数据的 AI 驱动的搜索引擎。 我不知道从哪里开始查找或编码。不知何故，我知道我需要一个 llm 模型和数据集来训练 AI。但是我如何找到模型，然后如何安装它，以及我们使用什么 UI 来使用我们的数据训练 AI。我们的网站由 WordPress 提供支持。 基本上，我需要一个关于从哪里开始的指南。 提前致谢！    提交人    /u/tjthomas101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gnarbb/newbie_asking_how_to_build_an_llm_or_generative/</guid>
      <pubDate>Sat, 09 Nov 2024 14:02:43 GMT</pubDate>
    </item>
    <item>
      <title>Daniel Bourke 是倾斜的山羊</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gn9bmc/daniel_bourke_is_the_goat_for_leanin/</link>
      <description><![CDATA[就是这样，他很好地解释了实际概念，andrew ng 也不错，但主要是理论     提交人    /u/jinstronda   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gn9bmc/daniel_bourke_is_the_goat_for_leanin/</guid>
      <pubDate>Sat, 09 Nov 2024 12:45:07 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习打败恐龙游戏 - 详情见评论</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gn9a1p/beating_the_dinosaur_game_with_ml_details_in/</link>
      <description><![CDATA[        由    /u/Mbird1258  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gn9a1p/beating_the_dinosaur_game_with_ml_details_in/</guid>
      <pubDate>Sat, 09 Nov 2024 12:42:31 GMT</pubDate>
    </item>
    <item>
      <title>尽管 numpy 使用相同的数据 + 参数收敛，但 Pytorch 却出现了分歧</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gn80t9/pytorch_diverges_although_numpy_converges_with/</link>
      <description><![CDATA[      我首先在 numpy 中实现了线性回归的基本梯度下降，然后使用 pytorch。但是，在相同的数据、参数初始化和学习率的情况下，一个会收敛（numpy，左），而另一个会发散（pytorch，右） https://preview.redd.it/xz80dqlxzuzd1.png?width=1274&amp;format=png&amp;auto=webp&amp;s=808142943d9ecf323a4a7933fef95b2bb7532de7 以下是每个代码： Numpy： 导入数学 导入 matplotlib.pyplot 作为 plt 导入 numpy 作为 np n = 50 np.random.seed(1) x = np.linspace(0, 2*math.pi, n) y = np.sin(x) y += np.random.normal(scale=0.1, size=len(y)) alpha = 0.15 m = 0 b = 0loss = [] fig, axs = plt.subplots(2) while True: axs[0].plot(x, m*x+b) axs[0].scatter(x, y) axs[1].plot(losses) plt.draw() plt.waitforbuttonpress() for ax in axs: ax.clear() b -= alpha * 1/n * sum(b + m*x[i] - y[i] for i in range(n)) m -= alpha * 1/n * sum((b + m*x[i] - y[i]) * x[i] for i in range(n)) mse = sum((y - (m*x+b))**2)/n loss.append(mse)  Pytorch: import math import matplotlib.pyplot as plt import numpy as np import torch.nn n = 50 np.random.seed(1) x = np.linspace(0, 2*math.pi, n) y = np.sin(x) y += np.random.normal(scale=0.1, size=len(y)) x = torch.from_numpy(x) y = torch.from_numpy(y) x = x.reshape(-1, 1) y = y.reshape(-1, 1) alpha = 0.15 m = torch.zeros(1, require_grad=True) b = torch.zeros(1, require_grad=True) loss_fn = torch.nn.MSELoss() optimizer = torch.optim.SGD([m, b], lr=alpha) loss = [] fig, axs = plt.subplots(2) while True: y_est = m * x + b loss = loss_fn(y_est, y) loss.append(loss.item()) loss.backward() optimizer.step() optimizer.zero_grad() axs[0].plot(x, y_est.detach().numpy()) axs[0].scatter(x, y) axs[1].plot(losses) plt.draw() plt.waitforbuttonpress() for ax in axs: ax.clear()  即使我将 LR 降至 0.1，它们的行为仍然相同，因此我认为这不是一个小的舍入误差或类似错误。    提交人    /u/autorayn   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gn80t9/pytorch_diverges_although_numpy_converges_with/</guid>
      <pubDate>Sat, 09 Nov 2024 11:22:28 GMT</pubDate>
    </item>
    <item>
      <title>Fast.ai 有何帮助？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gn2skp/how_is_fastai_helpful/</link>
      <description><![CDATA[我曾多次尝试从中学习，也尝试过多个版本。我只是不明白为什么有些人在大型科技 AI 实验室工作时，会将他们的成功归功于 Fast.ai。我知道我的学习风格可能与目标受众不同，但我想知道从中受益的人。 首先，笔记本/书与视频关系不大。其次，有太多抽象，这有点加倍了你的工作量，因为你需要查找某些东西在 PyTorch 中是如何实际实现的。第三，一切都是笔记本，而我不喜欢笔记本。    提交人   /u/internet human016   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gn2skp/how_is_fastai_helpful/</guid>
      <pubDate>Sat, 09 Nov 2024 05:11:20 GMT</pubDate>
    </item>
    <item>
      <title>我很容易忘记学到的东西</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gmy36x/i_forget_what_ive_learnt_very_easily/</link>
      <description><![CDATA[您好， 我已经学习机器学习一段时间了，主要是通过视频、书籍和编码。然而，我很容易忘记事情是如何运作的，我只知道如何在代码中实现它们，因为有很多 ML 库。学习如何编码要容易得多，因为它不那么理论化？ 您有什么建议？从头开始编码，不使用任何库？ 编辑：感谢您的意见！我会尝试您推荐的所有方法，如果我找到最好的方法，我会报告（也许这可以帮助未来的某些人，尽管我们每个人的学习方式都不同）。    提交人    /u/Human-ID-0196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gmy36x/i_forget_what_ive_learnt_very_easily/</guid>
      <pubDate>Sat, 09 Nov 2024 00:54:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>