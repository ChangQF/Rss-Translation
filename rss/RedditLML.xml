<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 24 Dec 2023 12:22:42 GMT</lastBuildDate>
    <item>
      <title>JAX 中的多代理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ptmuk/multiagent_in_jax/</link>
      <description><![CDATA[     &lt; td&gt; 我们在 JAX 中发布了一个可扩展的多代理强化学习包。喜欢就加星吧！   由   提交 /u/misterpawan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ptmuk/multiagent_in_jax/</guid>
      <pubDate>Sun, 24 Dec 2023 11:39:16 GMT</pubDate>
    </item>
    <item>
      <title>强化学习基础知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pth3q/reinforcement_learning_basics/</link>
      <description><![CDATA[      强化学习教程系列！让我告诉我您还希望我介绍哪些内容！   由   提交 /u/MrSirLRD   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pth3q/reinforcement_learning_basics/</guid>
      <pubDate>Sun, 24 Dec 2023 11:27:23 GMT</pubDate>
    </item>
    <item>
      <title>请查看我的简历（任何数据科学人员）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pswlk/please_review_my_resume_any_data_science_guy/</link>
      <description><![CDATA[      &amp;# 32；由   提交 /u/Unkilninja   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pswlk/please_review_my_resume_any_data_science_guy/</guid>
      <pubDate>Sun, 24 Dec 2023 10:45:12 GMT</pubDate>
    </item>
    <item>
      <title>开始学习机器学习的最佳在线课程或 YouTube 播放列表是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18psvl9/what_is_the_best_online_course_or_youtube/</link>
      <description><![CDATA[大家好，我正计划开始学习机器学习。我应该从 Kaggle 课程开始吗？或者和吴恩达一起？或与其他课程一起？   由   提交/u/DeliciousHearing3693  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18psvl9/what_is_the_best_online_course_or_youtube/</guid>
      <pubDate>Sun, 24 Dec 2023 10:43:05 GMT</pubDate>
    </item>
    <item>
      <title>你对于 GAN 的损失有何感受？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pslzp/how_would_you_feel_about_this_gan_loss/</link>
      <description><![CDATA[      我正在研究具有相对论平均铰链损失的图像到图像转换模型。  生成器具有编码器-resnet-解码器风格的架构，可以通过纯 VGG-19 感知损失产生相当合理的结果。 对于纯对抗性损失，我发现鉴别器的损失是有时稳定，但随后会飙升至 2.0。生成器 (G) 似乎正在改进，尽管速度非常慢。 鉴别器 (D) 由三个分类器类型网络组成，每个网络以不同的规模接收输入。 D1 将接收全分辨率输入，D2 将接收 1/2 分辨率图像，D3 将接收 1/4 分辨率图像。每个网络都是自己的判别器，具有自己的预测逻辑，因为这应该可以提高稳定性并有助于防止模式崩溃。 我应该如何看待这个 GAN 图表？它健康吗？ 两个网络的学习率都是 5e-5，这已经相当低了。我观察到这种情况也发生在 7e-5 和 3e-5 上。 ​ 蓝色 = G，绿色 = (D1,D2,D3) &lt;!-- SC_ON - -&gt;  由   提交 /u/PlateRight7449   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pslzp/how_would_you_feel_about_this_gan_loss/</guid>
      <pubDate>Sun, 24 Dec 2023 10:23:17 GMT</pubDate>
    </item>
    <item>
      <title>专门的法学硕士真的需要 20 多个十亿个参数吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18psibb/do_specialized_llms_really_need_20_billion/</link>
      <description><![CDATA[如标题所示。我觉得目前LLM市场的趋势是让“人工智能终结所有人工智能”：它可以写诗，它可以写代码，它可以给你写一篇文章，它可以解释文本，它可以分析股票，它可以角色扮演等等 我的问题是，做 Mistral 团队和其他几个团队正在做的事情并引入许多较小的“专家”不是很明显吗？根据请求的性质激活以提高性能的模型？ 或者，是否有技术可以方便地“删除”模型？无需重新训练即可从现有模型中获取不必要的数据？例如，我不完全确定代码辅助模型需要知道 MBTI 的含义以及苏斯博士是谁。 这是否已经在大多数流行的模型中完成，而我刚刚退出循环？   由   提交 /u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18psibb/do_specialized_llms_really_need_20_billion/</guid>
      <pubDate>Sun, 24 Dec 2023 10:15:41 GMT</pubDate>
    </item>
    <item>
      <title>我有一个想法，需要输入</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18psc3l/i_have_an_idea_need_inputs/</link>
      <description><![CDATA[我是 AI/LLM 新手，正在思考一些事情，想知道如何将这个想法变为现实 所以我在小公司工作，我们有大量的融合/文档，我想知道我是否可以从中创建LLM并将聊天机器人与其集成？ 此外，我们还有几个我正在考虑的系统通过利用这些系统的 API 将它们集成到此模型中并进行相应的训练 如果有人有这方面的资源或任何关于如何实现的想法，请分享，提前致谢   由   提交/u/No_Management2161   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18psc3l/i_have_an_idea_need_inputs/</guid>
      <pubDate>Sun, 24 Dec 2023 10:02:26 GMT</pubDate>
    </item>
    <item>
      <title>易于实施研究论文</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18prdxb/easy_to_implementing_research_papers/</link>
      <description><![CDATA[嗨，有人能给我推荐一些关于计算机视觉或医疗保健人工智能的初学者水平论文吗？    由   提交/u/wandering_soul1103  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18prdxb/easy_to_implementing_research_papers/</guid>
      <pubDate>Sun, 24 Dec 2023 08:49:37 GMT</pubDate>
    </item>
    <item>
      <title>什么是机器学习？ - Scikit Learn 的创始人 Gael Varoquaux</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pqx0y/what_is_machine_learning_gael_varoquaux_creator/</link>
      <description><![CDATA[       由   提交/u/danipudani  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pqx0y/what_is_machine_learning_gael_varoquaux_creator/</guid>
      <pubDate>Sun, 24 Dec 2023 08:14:12 GMT</pubDate>
    </item>
    <item>
      <title>按什么顺序学习这些框架呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pqryw/what_order_to_learn_these_frameworks/</link>
      <description><![CDATA[Scikit learn • 张量流 • keras • pytorch   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pqryw/what_order_to_learn_these_frameworks/</guid>
      <pubDate>Sun, 24 Dec 2023 08:04:10 GMT</pubDate>
    </item>
    <item>
      <title>我可以相信神经网络会忽略不相关的特征吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pq4vt/can_i_trust_neural_networks_to_ignore_irrelevant/</link>
      <description><![CDATA[我正在研究用于二元分类的表格数据上的神经网络反向传播数学，但我很难看出哪里不相关/无关功能被忽略......我知道它发生只是不确定在哪里。那么我可以相信神经网络足够聪明，知道什么重要、什么不重要吗？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pq4vt/can_i_trust_neural_networks_to_ignore_irrelevant/</guid>
      <pubDate>Sun, 24 Dec 2023 07:19:38 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 与 Transformer 的低资源 seq2seq 翻译</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pp1tu/lstm_vs_transformer_for_lowresource_seq2seq/</link>
      <description><![CDATA[我正在开发一个 NMT 项目，该项目可翻译 4-50 个单词长的短语。英语句子不是问题，但我尝试仅使用 5000 个短语（最多 10 个单词左右）来训练模型。我的方法的一部分涉及使用多个 NMT 模型一起通信来构建正确的语法模式。我认为 LSTM 很好用，因为训练时间与相当小的数据集和短语的简短无关，但我开始怀疑 Transformer 模型是否会表现得更好。如果有人有建议或想法，请告诉我。    由   提交/u/Neat_Replacement_118   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pp1tu/lstm_vs_transformer_for_lowresource_seq2seq/</guid>
      <pubDate>Sun, 24 Dec 2023 06:06:40 GMT</pubDate>
    </item>
    <item>
      <title>如何从零开始学习机器学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18plun0/how_to_learn_machine_learning_from_scratch/</link>
      <description><![CDATA[嗨。所以我对机器学习有一定的了解，但这还不够。我对自己的知识不满意，并觉得自己缺少其中的关键方面。请建议一个涵盖大部分方面的机器学习学习路径，以便我足以解决kaggle问题？   由   提交/u/Suhurth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18plun0/how_to_learn_machine_learning_from_scratch/</guid>
      <pubDate>Sun, 24 Dec 2023 02:56:31 GMT</pubDate>
    </item>
    <item>
      <title>现在的LLM真的是“黑匣子”吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pl1wx/is_it_true_that_current_llms_are_actually_black/</link>
      <description><![CDATA[没有人真正理解 Chatgpt 4 是如何根据某些输入给出输出的。它们是黑匣子有多真实？ 因为我们似乎确实了解输出是如何产生的？    由   提交 /u/wouhf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pl1wx/is_it_true_that_current_llms_are_actually_black/</guid>
      <pubDate>Sun, 24 Dec 2023 02:11:09 GMT</pubDate>
    </item>
    <item>
      <title>建立直觉：决策树如何压缩图像</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pd0ks/build_intuition_how_decision_trees_compress_an/</link>
      <description><![CDATA[   我的三分钟视频概述了我所做的事情以及如何创建类似的内容这个你自己：https://youtu.be/pjmgdC6-lSo GIF 下方的详细说明：&lt; /p&gt; 在决策树模型中使用 RGB 与 HSV 颜色模型的并排比较的动画 gif。 您可以使用决策树来压缩图像。如果您的目标是压缩图像，则可以使用库，但我想看看决策树在查看图像时“看到”了什么。 想法如下：训练输入是每个像素的 x、y 位置和颜色通道（对于黑白，只有一个通道）。目标是该像素和通道的值。我没有进行测试/训练分割，因为我不想建立一个模型来预测任何东西，我想要压缩一些东西。 链接  &lt;强&gt;代码： https://jbwhit.github.io/vangoghviz/ YouTube 概述： https://youtu.be/pjmgdC6-lSo &lt; /ul&gt; 如果您有任何疑问，请告诉我！我希望提高此类事情的产出，因此欢迎提供任何反馈。   由   提交/u/Mr-Whitmore   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pd0ks/build_intuition_how_decision_trees_compress_an/</guid>
      <pubDate>Sat, 23 Dec 2023 19:28:29 GMT</pubDate>
    </item>
    </channel>
</rss>