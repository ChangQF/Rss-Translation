<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 24 Oct 2024 09:18:11 GMT</lastBuildDate>
    <item>
      <title>可以让我的生活更轻松的应用程序/网站/软件</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gay4ll/appwebsitesoftware_that_will_make_my_life_easier/</link>
      <description><![CDATA[我需要为我的数据集创建一个人类基准。我有一堆图像，我想问人类一个问题，然后我希望他们要么点击图像中的某些点，要么绘制一个边界框（尚未决定）。最好的方法是什么？我可以考虑构建一个类似小应用程序的东西（也许是 google colab+gradio），但我没有这方面的经验，我需要尽快得到它。    提交人    /u/__gp_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gay4ll/appwebsitesoftware_that_will_make_my_life_easier/</guid>
      <pubDate>Thu, 24 Oct 2024 08:58:39 GMT</pubDate>
    </item>
    <item>
      <title>如何为梯度提升和随机森林模型创建损失曲线？您能举个例子吗？我是否需要使用 n_estimators 来实现这一点，或者还有其他方法吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gaxw9j/how_can_i_create_a_loss_curve_for_gradient/</link>
      <description><![CDATA[这是我用于调整随机森林和 GBM 模型的代码  def tune_model(model, param_distributions, X_train, y_train, cluster_label, model_name, is_rf=False): &quot;&quot;&quot;应用 RandomizedSearchCV 进行超参数调整并绘制损失曲线。&quot;&quot;&quot; random_search = RandomizedSearchCV( estimator=model,  param_distributions=param_distributions,  n_iter=30, # 采样的参数设置数量 cv=5, # 5 倍交叉验证 verbose=2,  random_state=42,  n_jobs=-1 # 使用所有处理器 ) random_search.fit(X_train, y_train) # 最佳估计器和最佳超参数 best_model = random_search.best_estimator_ best_params = random_search.best_params_ return best_model, best_params 并应用 param_RF = &#39;n_estimators&#39;: randint(10, 1000), &#39;min_samples_leaf&#39;: [1,2,3,4,5,6,7, 8]  GBM param_grid_gb = { &#39;n_estimators&#39;: [100, 200, 300,400,500,600,700,800,900], &#39;learning_rate&#39;: [0.01, 0.03,0.05,0.06], &#39;min_samples_leaf&#39;: [1,2,3,4,5]     提交人    /u/Hopeful-SG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gaxw9j/how_can_i_create_a_loss_curve_for_gradient/</guid>
      <pubDate>Thu, 24 Oct 2024 08:40:03 GMT</pubDate>
    </item>
    <item>
      <title>OpenPerplex API：面向开发人员的高级人工智能搜索</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gaxtm9/openperplex_api_advanced_aipowered_search_for/</link>
      <description><![CDATA[嘿，开发人员！👋 我很高兴向您介绍 openperplex.com ，这是一个由人工智能驱动的搜索 API，旨在提高速度、准确性和灵活性。无论您需要实时搜索结果还是特定网站数据，我们都提供以下功能： 🚀 主要功能：  新闻搜索：快速准确地检索新闻文章。 引文和来源：回复包括完整的引文和参考文献，以确保透明度。 网页抓取和屏幕截图：从网站中提取文本、markdown 或整页屏幕截图。 多语言支持：支持 14 种语言，满足全球搜索需求。 基于位置的搜索：针对 40 多个国家/地区的结果。 基于 URL 的查询：从特定 URL 获取详细响应。 长格式响应：当您需要详细而全面的答案时。  💡 开发人员友好：  使用 pip install --upgrade openperplex 轻松设置 有据可查的 API 和自定义错误处理 灵活的响应类型：HTML、markdown 或文本  🆓 100 次免费请求：无需信用卡即可开始测试。 🔗 API 链接 🔗 文档 🔗 GitHub 🎉 加入我们的 Discord：有疑问或需要帮助？加入我们在 Discord 上不断壮大的开发者社区，获得实时支持并随时了解最新功能！    提交人    /u/EntertainmentSad2202   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gaxtm9/openperplex_api_advanced_aipowered_search_for/</guid>
      <pubDate>Thu, 24 Oct 2024 08:33:48 GMT</pubDate>
    </item>
    <item>
      <title>通过 Agentic AI 简化财务运营</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gaxkfi/streamlining_finance_operations_through_agentic_ai/</link>
      <description><![CDATA[        提交人    /u/diana_b_troutt   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gaxkfi/streamlining_finance_operations_through_agentic_ai/</guid>
      <pubDate>Thu, 24 Oct 2024 08:13:23 GMT</pubDate>
    </item>
    <item>
      <title>如果我将来想成为一名人工智能/机器学习工程师，我应该加入大学的研究实验室吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gax0y6/should_i_join_research_lab_at_my_university_if_i/</link>
      <description><![CDATA[我目前是一名大学生，将来想成为一名工程师。加入大学的研究实验室会对我的职业生涯有帮助吗？这样做有什么好处？或者研究实验室只适合那些想成为博士和研究人员的人？    提交人    /u/Alive-One8445   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gax0y6/should_i_join_research_lab_at_my_university_if_i/</guid>
      <pubDate>Thu, 24 Oct 2024 07:29:58 GMT</pubDate>
    </item>
    <item>
      <title>计算代码中 LLM 困惑度的正确方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gavxjn/what_is_the_correct_way_to_calculate_perplexity/</link>
      <description><![CDATA[我尝试使用两种方法确定 GPT-2 模型在 wikitext2 数据集上的困惑度：  huggingface 训练器（人次：262915.39172431716） 以下是固定长度模型的困惑度（人次：16.45）  据我了解，方法 2 可能更准确，如博客中所述，但是当我使用以下脚本获取困惑度时，我得到了一个非常高的值，如上所述。 ```python import torch from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments from datasets import load_dataset import math 加载预先训练的语言模型（例如，  model_name = &quot;gpt2&quot; # 您可以将其替换为另一个模型 model = AutoModelForCausalLM.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name) tokenizer.pad_token = tokenizer.eos_token 从 Hugging Face 加载 Wikitext-2 数据集 dataset = load_dataset(&quot;wikitext&quot;, &quot;wikitext-2-raw-v1&quot;) test_dataset = dataset[&quot;test&quot;] 对数据集进行标记 def tokenize_function(examples): return tokenizer(examples[&#39;text&#39;], return_attention_mask=False, truncation=True, padding=&quot;max_length&quot;, max_length=512) tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=[&quot;text&quot;]) 定义数据收集器 def data_collat​​or(features): batch = { &quot;input_ids&quot;: torch.stack([torch.tensor(f[&quot;input_ids&quot;]) for f in features]), &quot;labels&quot;: torch.stack([torch.tensor(f[&quot;input_ids&quot;]) for f in features]), } return batch 设置用于评估的训练参数 training_args = TrainingArguments( output_dir=&quot;./results&quot;, per_device_eval_batch_size=4, # 根据您的 GPU 内存进行调整 evaluation_strategy=&quot;no&quot;, logsing_dir=&#39;./logs&#39;, do_train=False, do_eval=True, report_to=&quot;none&quot;, ) 定义一个 Trainer trainer = Trainer( model=model, args=training_args, eval_dataset=tokenized_test_dataset, data_collat​​or=data_collat​​or, ) 评估模型并计算困惑度 eval_results = trainer.evaluate() 困惑度计算 log_loss = eval_results[&quot;eval_loss&quot;] perplexity = math.exp(log_loss) print(f&quot;Wikitext-2 数据集上的困惑度：{perplexity}&quot;) ``` 我在这里做什么？    由    /u/doctor-squidward  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gavxjn/what_is_the_correct_way_to_calculate_perplexity/</guid>
      <pubDate>Thu, 24 Oct 2024 06:08:07 GMT</pubDate>
    </item>
    <item>
      <title>您认为创建人工智能聊天机器人的最佳平台是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gau8jl/what_do_you_think_is_the_best_platform_for/</link>
      <description><![CDATA[我需要你的意见。    由   提交  /u/anarchicparson7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gau8jl/what_do_you_think_is_the_best_platform_for/</guid>
      <pubDate>Thu, 24 Oct 2024 04:18:36 GMT</pubDate>
    </item>
    <item>
      <title>攻读 AI/ML 博士学位时，本科阶段学习线性代数是否有必要？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gar5yw/is_taking_linear_algebra_in_undergrad_for_an_aiml/</link>
      <description><![CDATA[我是一名计算机科学专业的大四学生，在学年末完成了 2 项 ML 研究实习。我正试图通过在我的课程表中添加 CS 选修课来完成我的学位，但有人告诉我，没有选修线性代数会降低我进入课程的机会。下学期很难安排到我的课程表中。无论如何，没有选修线性代数对 ML 研究生院申请来说是成败攸关的吗？   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gar5yw/is_taking_linear_algebra_in_undergrad_for_an_aiml/</guid>
      <pubDate>Thu, 24 Oct 2024 01:33:16 GMT</pubDate>
    </item>
    <item>
      <title>快速工程第 1 部分</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gapiz4/prompt_engineering_part_1/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gapiz4/prompt_engineering_part_1/</guid>
      <pubDate>Thu, 24 Oct 2024 00:12:14 GMT</pubDate>
    </item>
    <item>
      <title>我应该关心算法背后的数学还是仅仅知道如何实现它们？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gammu3/should_i_care_about_the_math_behind_algorithms_or/</link>
      <description><![CDATA[我经常看到教程首先解释神经网络单元或层的每个步骤是如何工作的，老实说，我不知道这是一个有趣的事实还是我应该关注的事情     提交人    /u/SirLimonada   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gammu3/should_i_care_about_the_math_behind_algorithms_or/</guid>
      <pubDate>Wed, 23 Oct 2024 21:59:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该进入生物信息学吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gajqhz/should_i_get_into_bioinformatics/</link>
      <description><![CDATA[我是一名数据科学 BCs 学生，我的主要和唯一关注点是 AI，而且我在这方面确实取得了成功，但我小时候对生物学有点兴趣，我发现自己非常擅长生物学，并且拥有很好的一般知识，尽管我没有在高中教学大纲之外学习过它， 并且有一门关于生物信息学的很好的综合课程，如果我做得好的话，最终会进行暑期培训，但我不想远离 AI，你们认为作为一名对 AI 感兴趣的 DS 学生参加这门课程是个好主意吗？或者您认为这与我的主要兴趣相去甚远，请记住，同时建议我今年还有其他事情要做，所以我可能会专注于学习生物信息学    提交人    /u/TahaTheCaeser   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gajqhz/should_i_get_into_bioinformatics/</guid>
      <pubDate>Wed, 23 Oct 2024 19:57:23 GMT</pubDate>
    </item>
    <item>
      <title>如何将多元时间序列转换为单变量时间序列？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gah0ps/how_to_convert_multivariate_time_series_into/</link>
      <description><![CDATA[      我有多变量信息，大约有 9 个维度的时间序列，是从不同的传感器收集的。我想将这些信号组合或合并为一个信号时间序列来表示该事件。然后我将使用该单个时间序列进行异常检测。 除了 PCA 之外，还有哪些推荐的方法（数学或机器学习）可以将我的 9 维时间序列简化为 1 维？ 1 维单个时间序列应该能够有效地从所有传感器中捕捉该时间段的细微差别。然后可以使用一些分类或回归方法。 我想避免使用 PCA，并探索其他可用方法。是否有软件包可以从多元时间序列信号创建单一统一的时间序列模型？ https://preview.redd.it/lizypt2sojwd1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=dd9a53df8f6fdfb34b3b1d265651058002c0b27c    提交人    /u/camajuanivalley   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gah0ps/how_to_convert_multivariate_time_series_into/</guid>
      <pubDate>Wed, 23 Oct 2024 17:59:00 GMT</pubDate>
    </item>
    <item>
      <title>我们如何知道梯度下降在优化问题中真正提供了最优参数？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gagb2y/how_do_we_know_that_gradient_descent_truly/</link>
      <description><![CDATA[梯度下降似乎只是在神经网络之类的东西中寻找最佳权重的一种（非常好的）可能方法。但是，我们是否确定没有更好的解决方案（即，过度拟合更少的更优化的权重等）无法通​​过梯度下降找到？或者，梯度下降返回的解是否保证是理论上最好的解？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gagb2y/how_do_we_know_that_gradient_descent_truly/</guid>
      <pubDate>Wed, 23 Oct 2024 17:29:53 GMT</pubDate>
    </item>
    <item>
      <title>CUDA 安装难度如何？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gafwqa/how_difficult_is_cuda_to_install/</link>
      <description><![CDATA[我有一台 2060，我想在本地训练一些图像分类模型...从我所读的内容来看，安装所有 CUDA 东西以便 pytorch 可以正确利用 GPU 非常麻烦...是这种情况吗？我在 Windows 上。     提交人    /u/morecoffeemore   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gafwqa/how_difficult_is_cuda_to_install/</guid>
      <pubDate>Wed, 23 Oct 2024 17:13:11 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>