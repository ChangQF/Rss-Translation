<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 24 Sep 2024 03:22:02 GMT</lastBuildDate>
    <item>
      <title>是否存在 dropout 正则化弊大于利的情况？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo2ygy/any_cases_of_dropout_regularization_doing_more/</link>
      <description><![CDATA[我很好奇，是否有人有过使用 dropout 正则化对神经网络降低整体准确率而不是提高准确率的经历？是否存在已知的常见情况，或者 dropout 几乎总是能提高泛化和测试集上的性能？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo2ygy/any_cases_of_dropout_regularization_doing_more/</guid>
      <pubDate>Tue, 24 Sep 2024 03:12:06 GMT</pubDate>
    </item>
    <item>
      <title>你好，我有一个问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo2up1/hello_i_have_a_question/</link>
      <description><![CDATA[我想构建图形机器学习程序。我如何获取有关它的信息？我将使用 Python，我的知识水平非常基础。    提交人    /u/qwer1554   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo2up1/hello_i_have_a_question/</guid>
      <pubDate>Tue, 24 Sep 2024 03:06:30 GMT</pubDate>
    </item>
    <item>
      <title>不确定如何修复堆叠自动编码器实现</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo2luq/unsure_how_to_fix_stacked_auto_encoder/</link>
      <description><![CDATA[  由    /u/NonExstnt  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo2luq/unsure_how_to_fix_stacked_auto_encoder/</guid>
      <pubDate>Tue, 24 Sep 2024 02:53:26 GMT</pubDate>
    </item>
    <item>
      <title>如何改进拥抱脸部模型的文本生成？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo1kfc/how_to_improve_hugging_face_models_text_generation/</link>
      <description><![CDATA[前几天我在 stackoverflow 上发布了一个问题，觉得听听大家的想法会很好。 简而言之，我正在尝试使用 LLM 执行基本分类/摘要任务，否则这些任务很难编程。一个例子是找到一个段落的关键主题或找到与另一个词在语法上相似的单词。虽然使用 Poe 模型似乎工作得很好，提供的任务以连贯的方式得到回答。然而，出于某种原因，当我在本地使用类似的模型时，我得到了令人困惑的随机胡言乱语。 例如，我读到模型“EleutherAI/gpt-j-6b”在功能上与 chatGPT3 相似。我编写了代码来标记我的任务，在模型中运行并生成输出。 代码在这里 tokenizer = GPT2Tokenizer.from_pretrained(&quot;EleutherAI/gpt-j-6b&quot;) gpt_model = GPTNeoForCausalLM.from_pretrained(&quot;EleutherAI/gpt-j-6b&quot;) input_str = &quot;提供与短语“说 Nie 的骑士”相似的五个单词的列表&quot; input_ids = tokenizer.encode(input_str, return_tensors=&#39;pt&#39;)tention_mask = torch.ones(input_ids.shape, dtype=torch.long) pad_token_id = tokenizer.eos_token_id with torch.no_grad(): output = gpt_model.generate(input_ids, max_length=150,tention_mask=attention_mask, pad_token_id=pad_token_id, do_sample=True) generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True) print(generated_text)  输出 历史上一些最著名的国王的名字中都有聂氏的身影。另一位国王的名字是聂能，是由中国最著名的历史学家之一、历史学家唐三藏命名的。聂能一词的字面意思是“叔父之子”。这意味着聂能是聂能国王叔叔聂能唯一的儿子。有些国王从七岁起就开始使用皇家名字，并获得了“王子”的称号。小时候  这是 Poe 的输出，声称是 ChatGPT-3.5 Turbo 模型 1. 宣布“不”的战士 2. 大喊“不”的圣骑士 3. 发出“不”的守卫 4. 宣布“不”的防御者 5. 大喊“不”的哨兵  这是模型问题吗？我在编码过程中遗漏了什么吗？为什么输出彼此之间差异如此之大？我已在其他模型上尝试过此方法，结果大致相同，在本地我输出乱码，而在外部输出看起来很正常。这让我认为这是我这边的代码问题，但我无法查看我这边哪里导致了这种情况。    提交人    /u/Low-Information389   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo1kfc/how_to_improve_hugging_face_models_text_generation/</guid>
      <pubDate>Tue, 24 Sep 2024 01:59:32 GMT</pubDate>
    </item>
    <item>
      <title>报告称，2023 年 98% 的公司经历了机器学习项目失败</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo0fub/98_of_companies_experienced_ml_project_failures/</link>
      <description><![CDATA[  由    /u/Some-Technology4413  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo0fub/98_of_companies_experienced_ml_project_failures/</guid>
      <pubDate>Tue, 24 Sep 2024 01:01:25 GMT</pubDate>
    </item>
    <item>
      <title>如何学习 ML/DL</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fo04or/how_to_learn_mldl/</link>
      <description><![CDATA[如何以实用的方式学习 ml/dl？我需要为即将到来的项目工作学习这些。伙计们，如果您要重新开始学习 ml，您将如何开始？提前致谢！    提交人    /u/Asta-12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fo04or/how_to_learn_mldl/</guid>
      <pubDate>Tue, 24 Sep 2024 00:45:31 GMT</pubDate>
    </item>
    <item>
      <title>问题：1000 次试验，50 类 top-1 准确率</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnxcj0/question_1000_trial_50class_top1_accuracy/</link>
      <description><![CDATA[大家好，我是 ML 新手，我正在阅读一篇论文，其中他们将准确率描述为问题：1000 次试验 50 类 top-1 为 50%。但这项研究只包含 600 次试验和 50 个类别。 有人能帮我理解 1000 次试验 50 类 top-1 准确率到底指的是什么吗？ 谢谢。    提交人    /u/Physical-Carry-6474   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnxcj0/question_1000_trial_50class_top1_accuracy/</guid>
      <pubDate>Mon, 23 Sep 2024 22:31:03 GMT</pubDate>
    </item>
    <item>
      <title>我需要帮助来制作一致的角色人工智能（模型，LoRA）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnxbd1/i_need_help_to_do_a_consistent_character_ai_model/</link>
      <description><![CDATA[大家好，我是 AI 领域的新手。我曾多次使用 Image AI 制作壁纸或个人资料图片。但现在我想更进一步，制作一个虚拟角色。我一直在寻找有关模型和 LoRA 的信息。说实话，我感到很迷茫。所以，如果了解 Image AI 的人能帮助我，我将不胜感激。我想要实现什么？：我希望能够制作一个虚拟角色，并以不同的姿势、不同的面部表情（悲伤、愤怒、快乐、脸红）随意复制它。显然，我想保持相同的脸部和身体（胸部大小、体型、肤色），而我不知道如何实现这一切。我应该制作几个 LoRA，其中一个保存脸部，另一个保存体型吗？ （如果我必须制作一个保存体型的 lora，我该如何制作这种风格的 lora？因为我看到的大多数都专注于姿势或面部）还是最好使用预先训练过的模型来制作体型？有了姿势，制作 LoRA 或模型是否也更可取？感谢那些能帮助我的人。另外，如果有人不介意我问他们关于这个问题的问题，他们可以私下给我发他们的 discord。或者，如果您知道我可以问这些问题的 discord 服务器，请将其发送给我。非常感谢，并问候。    提交人    /u/Ikka_Sakai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnxbd1/i_need_help_to_do_a_consistent_character_ai_model/</guid>
      <pubDate>Mon, 23 Sep 2024 22:29:36 GMT</pubDate>
    </item>
    <item>
      <title>发现大词汇量的交叉熵损失的陷阱。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fntux8/discovering_a_pitfall_in_crossentropy_loss_for/</link>
      <description><![CDATA[在这篇简短的文章中，我发现了在具有大词汇量的模型中使用交叉熵损失的一个重大问题，这可能会导致微调的 LLM 的性能下降。我提供了理论见解和实证结果来支持这些发现。如果您正在处理大词汇量，这是必读内容：揭示大词汇量交叉熵损失的陷阱 | 作者 Oswaldo Ludwig | 2024 年 8 月 | Medium    提交人    /u/Gold-Plum-1436   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fntux8/discovering_a_pitfall_in_crossentropy_loss_for/</guid>
      <pubDate>Mon, 23 Sep 2024 20:00:30 GMT</pubDate>
    </item>
    <item>
      <title>我实现了许多经典的神经网络和训练方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnthws/i_implemented_a_number_of_classical_neural/</link>
      <description><![CDATA[大家好，最近我实现了一些经典的神经网络和训练方法。这些包括：  感知器 带有反向传播的前馈神经网络 梯度下降 共轭梯度下降 Adam 算法 用于训练前馈神经网络的 Levenberg-Marquardt 算法 贝叶斯正则化神经网络 使用正交最小二乘法训练第 1 层的径向基函数 (RBF) 网络，然后使用最小均方法训练第 2 层， 带有时间反向传播 (BPTT) 的循环神经网络 (RNN) 以及一些示例。   这是我的代码：https://github.com/dangmanhtruong1995/ClassicNeuralNetworks。如果有人可以对代码的编写方式进行评论，那就太好了。谢谢！    提交人    /u/CommunityOpposite645   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnthws/i_implemented_a_number_of_classical_neural/</guid>
      <pubDate>Mon, 23 Sep 2024 19:45:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 LSTM 预测的是一条水平直线？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnqk8w/why_does_my_lstm_predict_a_horizontal_straight/</link>
      <description><![CDATA[      # 缩放特征和目标 scaler = MinMaxScaler(feature_range=(0, 1)) scaled_train = scaler.fit_transform(train) scaled_test = scaler.transform(test) #重塑 X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1)) y_train = np.reshape(y_train, (y_train.shape[0],1)) print(&quot;X_train :&quot;,X_train.shape,&quot;y_train :&quot;,y_train.shape) # 将数据转换为numpy数组 X_test, y_test = np.array(X_test), np.array(y_test) #重塑 X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1)) y_test = np.reshape(y_test, (y_test.shape[0],1)) print(&quot;X_test :&quot;，X_test.shape，&quot;y_test :&quot;，y_test.shape）#X_train：（5849，150，1）y_train：（5849，1）#X_test：（370，150，1）y_test：（370，1）regressorLSTM = Sequential（）regressorLSTM.add（LSTM（200，return_sequences = True，input_shape =（X_train.shape [1]，1）））regressorLSTM.add（Dropout（0.3））regressorLSTM.add（LSTM（150，return_sequences = True））regressorLSTM.add（Dropout（0.3））regressorLSTM.add（LSTM（100，return_sequences = False）） regressorLSTM.add(Dropout(0.3)) regressorLSTM.add(Dense(50)) regressorLSTM.add(Dense(1)) regressorLSTM.compile(optimizer=RMSprop(learning_rate=0.0001), loss=Huber(), metrics=[&#39;mean_squared_error&#39;]) early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;,patient=10, restore_best_weights=True) regressorLSTM.fit(X_train, y_train, batch_size=4, epochs=200, validation_split=0.2,callbacks=[early_stopping])  https://preview.redd.it/7g2hwoxkilqd1.png?width=1365&amp;format=png&amp;auto=webp&amp;s=f3a7c1113859a5ec2a19b8a46a0cd44d7b0287d9 我在 reddit 和其他论坛上看到了旧帖子，人们说问题在于 epoch 数量太少，当人们将其增加到 500/1000 时它就会起作用。实际上我只使用了 20 个，但是现在我将其增加到 200 个 epoch，并且提前停止后它不会超过 40 个 epoch！    提交人    /u/Nihilus_666   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnqk8w/why_does_my_lstm_predict_a_horizontal_straight/</guid>
      <pubDate>Mon, 23 Sep 2024 17:45:21 GMT</pubDate>
    </item>
    <item>
      <title>开始使用 ML 建模的最佳方法是什么？AWS 用户在这里</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fno88u/whats_the_best_way_to_get_started_with_ml/</link>
      <description><![CDATA[大家好， 正如标题所示，开始学习 ML 的最佳方式是什么？我精通（虽然不是高级/熟练）Python 和 SQL。我的学术背景是经济学（大量 R、Stata、Excel、BI/分析工具），不一定是传统意义上的任何编程。我想探索 ML 建模以确定如何规划并预测客户行为，就用例而言，我认为这不是一个新概念。假设我对如何使用 ML 工具知之甚少，那么一个好的起点是什么？我最好熟悉 Sagemaker/AWS 套件，因为这些是我可以访问的工具。 我很高兴看到你们可能为我提供什么提示/反馈，同样也表示感谢！   由    /u/MrDylxtar  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fno88u/whats_the_best_way_to_get_started_with_ml/</guid>
      <pubDate>Mon, 23 Sep 2024 16:09:57 GMT</pubDate>
    </item>
    <item>
      <title>RepoViz：一种用于非结构化数据分析的开源工具</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnnup6/repoviz_an_opensource_tool_for_unstructured_data/</link>
      <description><![CDATA[      嗨r/learnmachinelearning， 我想分享一些我一直在研究的东西——一个开源工具 RepoViz。它有助于可视化和分析非结构化数据集，如图像、音频和文本数据。 我之所以构建这个工具，是因为我在一个涉及医学图像和时间序列数据的项目上遇到了困难。在处理繁琐的自定义脚本后，RepoViz 成为了我简化非结构化数据探索性数据分析 (EDA) 的解决方案。它与 D-Tale、SweetViz 和 YData Profiling 等 EDA 工具集成。 RepoViz 现已推出，并向社区开放。我计划添加自动特征提取选项，并希望大家能就人们希望看到哪些类型的特征提出建议。任何反馈都值得赞赏！ Repo：GitHub 教程：RepoViz 实际操作 https://preview.redd.it/dy2qy6k2zkqd1.png?width=1411&amp;format=png&amp;auto=webp&amp;s=7f6d8ab07d976b0c8d675bc458277b917ec5490e    提交人    /u/zndr27   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnnup6/repoviz_an_opensource_tool_for_unstructured_data/</guid>
      <pubDate>Mon, 23 Sep 2024 15:54:22 GMT</pubDate>
    </item>
    <item>
      <title>物理学家如何学习 ML/DL/AI 基础知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fnlv6s/how_to_learn_mldlai_fundamentals_as_a_physicist/</link>
      <description><![CDATA[大家好， 我想开始学习人工智能。我已经有使用 Python 的经验（主要是数据科学和光子学/光学的数值建模）并且对数学有扎实的掌握。我开始学习 Coursera 上的机器学习课程，但它对底层发生的事情的解释很少，而是直接开始编写一堆来自 Python 库的函数。我见过的其他 Coursera 课程都是从头开始，但开头讲得太多，只提供基本的数学介绍和 Python 编程。现在我更感兴趣的是了解与 AI、ML、NN 相关的概念……也许大学课程的教科书可能会有用，但资源太多了，我不知道从哪里开始……有什么推荐吗？    提交人    /u/nuvoldenovembre   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fnlv6s/how_to_learn_mldlai_fundamentals_as_a_physicist/</guid>
      <pubDate>Mon, 23 Sep 2024 14:31:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>