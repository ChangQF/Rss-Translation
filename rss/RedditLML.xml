<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Wed, 24 Jan 2024 06:18:36 GMT</lastBuildDate>
    <item>
      <title>使用 C++/CUDA 构建的相同模型收敛速度不如使用 Python/NumPy 构建的模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eagxe/identical_model_built_using_ccuda_doesnt_converge/</link>
      <description><![CDATA[我想学习神经网络背后的数学，因此我决定使用 numpy 从头开始​​构建一个 Python 模型来训练 MNIST 数据集。速度非常快，在调整超参数后，在 30 个 epoch 内测试数据集的准确率达到了 98%。作为一个简单的全连接网络，我没想到它会做得更好。所以我决定在 C++ 和 CUDA 中尝试同样的方法。该模型确实可以学习，但收敛速度不那么快。即使经过 1000 个 epoch，其准确性仍然非常可怕。模型架构相同，浮点精度、权重和偏差初始化、小批量大小以及所有超参数都相同。 GPU 在每次内核调用后也会同步。然而该模型的收敛速度似乎并没有那么快。我不知道该怎么做。有人知道可能是什么原因造成的吗？感谢您阅读所有内容。希望您有美好的一天。   由   提交 /u/Hey_DeadGuyHere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eagxe/identical_model_built_using_ccuda_doesnt_converge/</guid>
      <pubDate>Wed, 24 Jan 2024 06:16:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 为网站创建 AI 聊天机器人 - EmbedChain Dash</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/</link>
      <description><![CDATA[      大家好， 几天前，我创建了这个免费视频有关如何使用 Python 构建 AI 聊天机器人的教程。我使用 EmbedChain（构建在 LangChain 之上）和 Dash 库来展示如何训练机器人并与机器人交互。  https://youtu.be/tmOmTBEdNrE  https://preview.redd.it/c6r7guzfxbec1.png?width=1280&amp;format=png&amp; ;auto=webp&amp;s=e8fe1c145cb0d687a16a1ff87b8bad1c5ecfef4e   由   提交 /u/Adam-Schroeder   /u/Adam-Schroeder  reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/</guid>
      <pubDate>Wed, 24 Jan 2024 06:09:35 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 中处理名义多类分类目标变量的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ea3fe/what_is_the_best_way_to_deal_with_a_nomianal/</link>
      <description><![CDATA[我一直在互联网上寻找这个问题的答案，但似乎无法找到共识。 XGBoost具有“实验支持”对于分类变量，但如果某些实验被认为是最佳实践，我会感到惊讶，并且它必须将类别转换为“幕后”的某种数字表示形式。无论如何，以某种能力。 另一种选择是对目标进行标签编码，但这将创建一个隐含的序数变量，该变量应该表示名义变量。我不确定这是否会像预测变量那样对分类器中的目标变量产生影响。 理想情况下，我想对目标变量进行一次性编码，因为这似乎是名义多类分类变量的最正确的数字表示，这与其他类型的框架（例如 Keras）的运行方式一致。然而，XGBoost 似乎只能处理单个字段/一维数组作为目标。我遇到了一些可能允许其工作的包装函数，但我不确定如何在内部 XGBoost 模型上进行自动超参数调整。 编辑：标题应该说“标称”不是“标称”   由   提交/u/theromanempire1923   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ea3fe/what_is_the_best_way_to_deal_with_a_nomianal/</guid>
      <pubDate>Wed, 24 Jan 2024 05:53:55 GMT</pubDate>
    </item>
    <item>
      <title>机器如何学习？ （机器学习新手）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e9qo6/how_do_machines_learn_ml_newbie/</link>
      <description><![CDATA[我是机器学习世界的新手，我有兴趣了解它的工作原理。我听到“数据集”这个词“监督/非监督”可以是“监督/非监督”。学到了很多东西。 数据集是如何创建的以及它们存储在哪里？它只是一个包含数百万个对象的巨型数据库吗？ 了解如何创建人工智能模型的良好开端是什么？ “基础模型”？我已经尝试过 tenorflow，但现在有点卡住了？ 有什么建议或简单的方法来开始学习吗？   由   提交 /u/zerchoel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e9qo6/how_do_machines_learn_ml_newbie/</guid>
      <pubDate>Wed, 24 Jan 2024 05:32:44 GMT</pubDate>
    </item>
    <item>
      <title>奇异性与非奇异性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e9n3d/singularity_vs_nonsingularity/</link>
      <description><![CDATA[嗨，我正在 coursera 上学习线性代数，第一周他们强调了线性方程组中奇点与非奇点的概念。试图了解这与神经网络有何关系。是因为作为一般原则，您希望始终以神经网络的非奇点为目标吗？具有奇点的系统意味着它们是冗余的、矛盾的，或者可以有无限多个解决方案。这与神经网络有何关系？神经网络可以开始显示出奇点的迹象吗？那么我们的想法是消除这个吗？这怎么会发生呢？你会如何处理它？另外，神经网络也可以是非线性的吗？这意味着什么？我刚刚在加拿大攻读人工智能硕士课程，我正在尝试重新学习滑铁卢大学第一年的所有数学（艺术/经济专业），但我不记得很多数学；已经10多年了。之后我还将重新访问微积分，并且已经重新访问了统计与数据。现在概率是两倍。但我认为理解线性代数在神经网络/深度学习中极其重要。有人可以用简单的语言解释一下吗？这只是线性代数的第一周，所以我将在五月开课之前继续在线学习，但只是想要一些额外的见解。抱歉，我对这些概念非常非常陌生，我也在业余学习 Python。  谢谢   由   提交 /u/Can_swing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e9n3d/singularity_vs_nonsingularity/</guid>
      <pubDate>Wed, 24 Jan 2024 05:27:00 GMT</pubDate>
    </item>
    <item>
      <title>感知器可以循环处理线性可分离数据吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e925t/can_perceptron_cycle_on_linearly_separable_data/</link>
      <description><![CDATA[假设我们有由两个点 (x1, y1) = ((-1, -1) +1) 和 ( x2, y2) = ((1, 1) +1)。这些是线性可分的，正确吗？显然，任何不在这些点之间的线都会正确地将它们分类为相同的标签。 但是，如果我要在这些点上运行感知器算法，初始化 w_1 = (0,0) 并假设我们使用恒等特征映射，当 i 为奇数时，它将在 w_i = (0,0) 的权重向量之间循环，当 i 为偶数时，它会在 w_i = (-1,-1) 的权重向量之间循环，永不终止。这是为什么？除了线性可分性之外，还有其他属性也会影响感知器收敛吗？ 需要明确的是，这里的算法是，如果我们错误分类 (x_i, y_i)，如果 yi(w_t \dot x_i) &lt;= 0，则发生错误分类。   由   提交 /u/rhohodendron   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e925t/can_perceptron_cycle_on_linearly_separable_data/</guid>
      <pubDate>Wed, 24 Jan 2024 04:53:42 GMT</pubDate>
    </item>
    <item>
      <title>如何查询嵌入以进行语义搜索？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e614p/how_to_query_embeddings_for_semantic_search/</link>
      <description><![CDATA[如果这不是提问的地方，请道歉，并随时将我重定向到其他地方。我的问题如下：我对某些 SKU 商品有 1000 个描述，我想生成逆嵌入映射来进行语义搜索 例如，这是我所拥有的 item描述 item1 [word1, word2, word3, word4.........] item2 [word1, word2_2, word3_3, word4_4.......]  &lt; p&gt;如您所见，item1 和 item2 共享 word1，但 item1 和 item2 &gt; 有两个不同的上下文，通过生成嵌入，我们应该能够捕获每个单词的上下文 这是我生成嵌入的方法 my_description = [] with open (&#39;/content/gdrive/My Drive/my.csv&#39;, &#39;r&#39;) 作为数据： df = pd.read_csv(data,encoding = (&#39;utf-8&#39;),nrows=100) 为索引，df 中的行.iterrows(): my_str = row[&#39;description&#39;] my_description.append(my_str) 从变压器导入火炬导入 BertTokenizer, BertModel %matplotlib 内联 tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;) model = BertModel.from_pretrained( &#39;bert-base-uncased&#39;, output_hidden_​​states = True, # 模型是否返回所有隐藏状态。 ) model.eval() text2 = company_description[0] # 添加特殊标记。标记文本2 =“[CLS]” + 文本2 + &quot; [九月]” # 将句子分割成标记。 tokenized_text2 = tokenizer.tokenize(marked_text2) # 将标记字符串映射到其词汇表索引。 indexed_tokens2 = tokenizer.convert_tokens_to_ids（tokenized_text2）segment_ids2 = [1] * len（tokenized_text2）tokens_tensor2 = torch.tensor（[indexed_tokens2]）segments_tensors2 = torch.tensor（[segments_ids2]）与torch.no_grad（）：outputs2 = model（tokens_tensor2） ，segment_tensors2）hidden_​​states2=outputs2[2]token_embeddings2=torch.stack（hidden_​​states2，dim=0）token_embeddings2.size（）token_embeddings2=torch.squeeze（token_embeddings2，dim=1）token_embeddings2.size（）token_embeddings2=token_embeddings2.permute（1） ,0,2) token_embeddings2.size() token_vecs_cat2 = [] for token_embeddings2 中的 token: cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]) , dim=0) token_vecs_cat2.append(cat_vec) token_vecs_sum2 = [] import numpy as np x_token = np.empty((0, 768)) 对于 token_embeddings2 中的 token: sum_vec = torch.sum(token[-4:], dim =0) token_vecs_sum2.append(sum_vec) x_token = np.concatenate((x_token, sum_vec.numpy().reshape((1,-1))), axis=0)   x_token 将是一个描述中我所有单词/标记的嵌入例如，假设 item1 有 500 个标记，嵌入为 700，则 x_token 的形状将是 (500 x 700 ） 所以对于每个项目，我都会有这样的东西 项目令牌嵌入项目 1 令牌 1 [x1,x2,x3,.....] 项目 1标记 2 [x1,x2,x3,.....] .... 项目 2 标记 1_2 [x1,x2,x3,.....] 项目 2 标记 2_2 [x1,x2,x3,... ..] .... 项目 n 标记 1_n [x1,x2,x3,.....] 项目 n 标记 2_n [x1,x2,x3,.....]  &lt; p&gt;现在我的问题是如何执行搜索 如果我的搜索查询是一个句子 “word1 word2 word3.....wordn” 如果我为句子中的每个单词生成嵌入，并对每个标记的前 10 个最近邻执行 ANN 如果我的查询有 10 个标记，我将得到 100 个项目描述（每个标记 10 个）在这种情况下，我如何入围前 10 个项目描述？我应该使用哪个令牌？ query = [token1, token2.......tokenN] 前10个nearest_neighbor的项目，query_token1 -&gt; [itemx1_1、itemx1_2、itemx1_10] query_token2 -&gt; [itemx2_1, itemx2_2, itemx2_10]  我的语义搜索是否错误？   由   提交/u/Rough_Source_123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e614p/how_to_query_embeddings_for_semantic_search/</guid>
      <pubDate>Wed, 24 Jan 2024 02:18:30 GMT</pubDate>
    </item>
    <item>
      <title>这里发生了什么？这只是大规模的过度拟合吗？或者是其他东西？提前致谢。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e57wk/whats_going_on_here_is_this_just_massive/</link>
      <description><![CDATA[   /u/HoleNother  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e57wk/whats_going_on_here_is_this_just_massive/</guid>
      <pubDate>Wed, 24 Jan 2024 01:39:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用机器/深度学习来解释手语？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dxvm4/how_can_i_interpret_sign_language_using/</link>
      <description><![CDATA[使用什么模型或算法？我只能进行静态手势识别。但是对于视频输入呢？模型将解释该视频输入以获得含义或句子？连续的东西...   由   提交 /u/Funny_Shoe1772   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dxvm4/how_can_i_interpret_sign_language_using/</guid>
      <pubDate>Tue, 23 Jan 2024 20:19:45 GMT</pubDate>
    </item>
    <item>
      <title>构建个人人工智能助理需要指导！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dwvmf/guidance_needed_on_building_personal_ai_assistant/</link>
      <description><![CDATA[大家好！我是一名大学生，正在研究一个创建个性化人工智能助手的项目，其灵感来自于 BMO 和 Jarvis 等公司。我相信所有人工智能技术都可以使该项目成为可能。我当前的计划包括收集 Obsidian.md 文件中的个人数据，并对现有的大型语言模型（可能是 Dolphin Mixtral）进行微调，以基于这些数据来理解和交互。由于我对法学硕士、人工智能和 Python 比较陌生，因此我正在寻求类似项目的见解或参考，特别是关于个人数据与法学硕士的集成和微调技术。任何指导或资源将不胜感激！我只是想确保这个项目走在正确的轨道上。谢谢并告诉我！   由   提交/u/Lavanic  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dwvmf/guidance_needed_on_building_personal_ai_assistant/</guid>
      <pubDate>Tue, 23 Jan 2024 19:38:04 GMT</pubDate>
    </item>
    <item>
      <title>进入机器学习领域。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/</link>
      <description><![CDATA[大家好。 我是一名水工程师，今年想学习新东西，并决定采取一些步骤进入机器学习，获得一些见解。我的目标很简单，使用给定的数据集，应用机器学习模型，以便我可以用它来预测水质或优化问题，例如给定水质输入的最佳化学剂量。这与工作无关，只是我可以访问这些数据，这更像是一个个人项目，一个由于我的背景我可以理解的项目。 我有一些相当基本的 Python 知识（在学习期间介绍了 python 模块）以及有关数学建模、统计等的知识。 所以我的问题是：考虑到我的初始条件，这个目标是否现实？如果是，你会如何？去学习和构建这样的项目吗？ 感谢您的建议。   由   提交/u/Koa-3skie   reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/</guid>
      <pubDate>Tue, 23 Jan 2024 19:02:44 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何继续学习 ML？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19do5hg/how_should_i_continue_with_learning_ml/</link>
      <description><![CDATA[所以，基本上我已经完成并练习了 Andrew ng 的 3 门课程专业的课程和编码实验室练习。我还使用了 kaggle 数据集，例如泰坦尼克号、eda 房价预测以及测试一些模型（不是神经网络）。  我试图研究制作端到端的机器学习项目，但是当我寻找一些教程时，看起来我需要一些有关 html、css、javascript 和 Flask 或 fastapi 的知识 所以我有点困惑我是否应该学习这些并做一些端到端项目添加到我的简历 或者我是否应该学习神经网络（我确实有神经网络的非常基本的知识），NLP和其他主题，然后一旦我在几个月内很好地掌握了这些主题，然后尝试制作这些项目 PS。我正在攻读电气工程学位的第四个学期，正在 leetcode 上做 DSA，同时还辅以 AI/ML（我希望我的职业生涯是在科技领域）。我想尽快开始申请实习，因为我听说与其他开发领域相比，在 AI/ML 领域获得实习和实习要困难得多 我希望得到一些指导！    由   提交 /u/Hades_Kerbex22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19do5hg/how_should_i_continue_with_learning_ml/</guid>
      <pubDate>Tue, 23 Jan 2024 13:14:28 GMT</pubDate>
    </item>
    <item>
      <title>我应该训练自己的分类模型吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dlflm/should_i_train_my_own_classification_model/</link>
      <description><![CDATA[我应该训练自己的分类模型吗？ 我为 本网站的活动部分，其中有一个类别选择器。问题在于事件没有被正确分类。 我必须自己对事件进行分类，因为存在多种来源，它们应用不同的类别或根本不应用类别。 我&#39;我尝试应用零样本模型，因为显然没有针对我的类别训练的模型，总体来说结果很差。我也尝试过 OpenAI 函数调用，它做得更好，但我想避免调用 API，因为我没有从这样的网站获得任何利润（由于硬件限制，也无法在本地运行大型 LLM 模型）。  我从来没有这样做过所以我想知道我的方向是否正确。我即将深入训练 distillBERT（显然更容易？）模型来使用我自己的数据集对事件进行分类，因为我可以轻松获得数千个事件。 另一个问题是我将如何标记我自己也遇到过此类事件，我想通过结合手动标记、定义硬编码规则集，也许还可以调用 ChatGPT，我可以走得很远，我现在没有明确的策略。 这是个好主意吗？   由   提交 /u/iagovar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dlflm/should_i_train_my_own_classification_model/</guid>
      <pubDate>Tue, 23 Jan 2024 10:27:58 GMT</pubDate>
    </item>
    <item>
      <title>提高准确性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dlfat/improve_accuracy/</link>
      <description><![CDATA[大家好，我有一个项目，使用 CNN 将心电图图像分为 2 类。  我运行了几个 CNN 模型（diff 架构），但最高准确度是在我训练 CNN + VGG 时，但它严重过度拟合。  这里我想知道这个项目是没有未来还是什么？ CNN 无法区分细微的图形还是我的数据集图像有问题？  你能分享一下我下一步应该采取什么步骤吗？我真的迷路了。   由   提交/u/Mediocre_Bag7587   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dlfat/improve_accuracy/</guid>
      <pubDate>Tue, 23 Jan 2024 10:27:22 GMT</pubDate>
    </item>
    <item>
      <title>我可以通过制作项目来学习机器学习吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19diz76/can_i_learn_machine_learning_by_making_projects/</link>
      <description><![CDATA[我正在学习 andrew ng 的机器学习课程，但我更喜欢制作项目 ​ 是否可以通过项目来学习机器学习，因为其高度基于逻辑和方法？   由   提交/u/Bominator8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19diz76/can_i_learn_machine_learning_by_making_projects/</guid>
      <pubDate>Tue, 23 Jan 2024 07:30:42 GMT</pubDate>
    </item>
    </channel>
</rss>