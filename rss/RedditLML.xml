<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Mon, 08 Apr 2024 12:24:46 GMT</lastBuildDate>
    <item>
      <title>了解 Conv2dtranspose</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byw5lb/understanding_conv2dtranspose/</link>
      <description><![CDATA[大家好， 我目前正沉浸在我的论文工作中，发现自己需要一些关于 conv2dtranspose 函数的澄清在喀拉斯。具体来说，我想将此函数翻译成 C 语言，为此，我需要扎实掌握底层数学运算。 在我正在使用的卷积神经网络 (CNN) 中，我遇到从 8x8x1024 维度矩阵到 16x16x512 维度矩阵之一的转换。我设法理解将步幅参数设置为 2 负责 16x16 尺寸。然而，我很难理解滤波器的数量如何影响这个过程。 在我当前的示例中，有 512 个滤波器 (n_filters)，导致输出矩阵的最终维度为512.我正在寻求的是如何生成结果矩阵的每个元素的详细解释。 任何有关此事的见解或解释将不胜感激。提前谢谢您。   由   提交 /u/sepCIFic_account   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byw5lb/understanding_conv2dtranspose/</guid>
      <pubDate>Mon, 08 Apr 2024 12:04:33 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 10 门最佳深度强化学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byw12b/10_best_deep_reinforcement_learning_courses_in/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byw12b/10_best_deep_reinforcement_learning_courses_in/</guid>
      <pubDate>Mon, 08 Apr 2024 11:58:21 GMT</pubDate>
    </item>
    <item>
      <title>如何为机器学习模型生成的预测生成置信区间？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byu2fj/how_to_generate_confidence_intervals_for/</link>
      <description><![CDATA[我们有一个 CatboostRegressor 和一个 XGBoostRegressor 模型，它采用历史值（我有一个时间序列）和滞后特征来预测未来 6 个月的值。我可以访问训练和测试数据。 我被要求生成一个置信区间为 90% 的范围。我怎样才能在 python 中做到这一点？ 在网上找不到实际的答案。    由   提交/u/ds24carrer  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byu2fj/how_to_generate_confidence_intervals_for/</guid>
      <pubDate>Mon, 08 Apr 2024 10:01:23 GMT</pubDate>
    </item>
    <item>
      <title>选择什么来创建花粉识别模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bytvz9/what_to_choose_to_create_a_pollen_identification/</link>
      <description><![CDATA[      嘿！ 👋 我是机器学习新手，我必须创建一个用于花粉识别的检测/分类模型。下面是问题&amp;解决方案图像。基本上在拍照后（可以是实时的，可以在之后完成），模型应该预测可见的花粉类型。 （理想情况下，如果置信度较低，我希望它是交互式的并显示前 3 个预测）。 我认为我应该制作对象检测模型或分割模型。为此，我应该只使用 YOLO（v8？） 和自定义数据集吗？ 我有大约 250 张图像，其中包含多个样本。我假设我必须使用 Roboflow 之类的东西来绘制边界框并手动对它们进行分类并将其分割到训练/测试集中。 非常感谢任何提示和建议！ 🙌 注意：“BR”图像中的类是一个坏样本。它不会在训练中使用 https://preview.redd.it/v589wvx798tc1.jpg?width=3840&amp;format=pjpg&amp;auto=webp&amp;s=13e8e4bc6ed592872d764c878ead695f24311110   由   提交 /u/htkyy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bytvz9/what_to_choose_to_create_a_pollen_identification/</guid>
      <pubDate>Mon, 08 Apr 2024 09:49:51 GMT</pubDate>
    </item>
    <item>
      <title>图像中的脸部模糊</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bysn5m/blurring_faces_from_image/</link>
      <description><![CDATA[我一直在从事一个项目，需要使用 Python 对图像中的人脸进行模糊处理。到目前为止，我已经成功使用 cv2 和 Mediapipe 实现了面部模糊。然而，我发现了一个问题：当前的设置仅检测靠近相机的人脸，而忽略了背景中的人脸。 在寻求解决方案时，我偶然发现了 Tensorflow Tiny Faces，它看起来很有前途用于检测图像中较小的脸部。不幸的是，我找不到经过训练的 Tiny Faces 模型，并且不确定我的计算机能否处理它的训练。 这里有人使用过 Tensorflow Tiny Faces 吗？可以指导我在哪里可以找到经过训练的模型？此外，我愿意探索其他可以提高应用程序中的人脸检测范围的库或方法。 任何提示或建议将不胜感激！   由   提交/u/AnterosNL  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bysn5m/blurring_faces_from_image/</guid>
      <pubDate>Mon, 08 Apr 2024 08:24:44 GMT</pubDate>
    </item>
    <item>
      <title>适合初学者到高级的 Pluralsight 最佳 Tensorflow 课程 -</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byrsw6/best_tensorflow_courses_on_pluralsight_for/</link>
      <description><![CDATA[       由   提交 /u/Sreeravan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byrsw6/best_tensorflow_courses_on_pluralsight_for/</guid>
      <pubDate>Mon, 08 Apr 2024 07:25:30 GMT</pubDate>
    </item>
    <item>
      <title>好的日志，奇怪的日志？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byr3ri/good_logs_strange_logs/</link>
      <description><![CDATA[我们的服务器创建了大量日志文件。 我如何检测以前未出现过的奇怪日志行？ 我已经习惯了传统的软件开发，但 ML 对我来说是新的。 您能给我一些如何使用 ML 解决这个问题的建议吗？ &lt; !-- SC_ON --&gt;  由   提交 /u/guettli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byr3ri/good_logs_strange_logs/</guid>
      <pubDate>Mon, 08 Apr 2024 06:38:58 GMT</pubDate>
    </item>
    <item>
      <title>哪一篇与法学硕士相关的论文提到了“神圣干预”对某些发现或方法负责？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byqj0x/which_llmrelated_paper_mentioned_divine/</link>
      <description><![CDATA[我记得我遇到的一篇论文中的这句话，但不记得是哪一篇了。也许这是论文结尾处的一句幽默的话？ 这句话的主要概念是某种方法的发现/成功是由于神圣的干预（或类似的措辞）  p&gt; 有人知道我在谈论哪篇论文吗？我记得它与变形金刚/法学硕士有关。 谢谢   由   提交 /u/Madd0g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byqj0x/which_llmrelated_paper_mentioned_divine/</guid>
      <pubDate>Mon, 08 Apr 2024 06:01:27 GMT</pubDate>
    </item>
    <item>
      <title>对统计学习材料感到困惑。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byp3o4/confused_about_statistics_study_materials/</link>
      <description><![CDATA[我计划重新学习数据科学的数学部分。对于线性代数，我会去看 Gilbert Stang 的视频和书籍，但对于统计和概率，我很困惑。资源非常多，请推荐一些好的资料，比如视频和书籍。  提前谢谢您   由   提交/u/infinity_bit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byp3o4/confused_about_statistics_study_materials/</guid>
      <pubDate>Mon, 08 Apr 2024 04:36:23 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊的免费教材《MLU-Explain》以图文并茂的方式深入浅出地解释了AI机制和开发方法。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byo5nw/amazons_free_teaching_material_mluexplain/</link>
      <description><![CDATA[   /u/HairyEstate3016   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byo5nw/amazons_free_teaching_material_mluexplain/</guid>
      <pubDate>Mon, 08 Apr 2024 03:45:43 GMT</pubDate>
    </item>
    <item>
      <title>什么时候使用机器学习数学？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bylmx4/when_do_you_use_ml_math/</link>
      <description><![CDATA[我已经在我的大学完成了线性代数、概率、微积分等课程。我目前正在注册 ML 和 DL 课程，其中教授正在研究底层算法的数学。然而，我很好奇数学概念在专业领域的实际应用。 那么对于那些已经在 ML/DL 领域工作的人来说，您什么时候发现理解这些主题对您的工作直接有益？  ​ 谢谢！   由   提交/u/_El_Sicario_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bylmx4/when_do_you_use_ml_math/</guid>
      <pubDate>Mon, 08 Apr 2024 01:40:16 GMT</pubDate>
    </item>
    <item>
      <title>我制作了一个工具来查看反向传播的实际效果</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1byaloo/i_made_a_tool_to_see_backpropagation_in_action/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/shawnchang420  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1byaloo/i_made_a_tool_to_see_backpropagation_in_action/</guid>
      <pubDate>Sun, 07 Apr 2024 17:54:25 GMT</pubDate>
    </item>
    <item>
      <title>1/2怎么到了求和前面，把n=1变成了n=0？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1by9vv4/how_did_the_12_came_in_front_of_the_summation_and/</link>
      <description><![CDATA[    /u/Agitated-Bowl7487   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1by9vv4/how_did_the_12_came_in_front_of_the_summation_and/</guid>
      <pubDate>Sun, 07 Apr 2024 17:24:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何通过 AUTOMATIC1111 和 ComfyUI 使用 LangChain、DeepLake 和 ControlNet 创建艺术二维码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1by80mt/p_how_to_create_artistic_qr_codes_using_langchain/</link>
      <description><![CDATA[       由   提交/u/efenocchi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1by80mt/p_how_to_create_artistic_qr_codes_using_langchain/</guid>
      <pubDate>Sun, 07 Apr 2024 16:04:54 GMT</pubDate>
    </item>
    <item>
      <title>可视化注意力，变形金刚的心 |第 6 章，深度学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1by4to5/visualizing_attention_a_transformers_heart/</link>
      <description><![CDATA[       由   提交/u/Reszi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1by4to5/visualizing_attention_a_transformers_heart/</guid>
      <pubDate>Sun, 07 Apr 2024 13:43:25 GMT</pubDate>
    </item>
    </channel>
</rss>