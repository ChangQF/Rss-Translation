<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 04 Sep 2024 03:16:50 GMT</lastBuildDate>
    <item>
      <title>关于权重和偏差梯度的快速问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8hkwt/quick_question_about_weight_and_bias_gradients/</link>
      <description><![CDATA[有人告诉我，要关注 Welch Labs 在 yt 上的系列文章，以便从头开始创建神经网络。现在我陷入了困境，因为他的网络不使用偏差，而我正在尝试弄清楚如何计算我的神经网络的偏差梯度。 所以 dC/dB = dC/dA * dA/dZ * dZ/dB。假设我第一次在第一层执行梯度下降步骤，该层接受 3 个输入并给出 2 个输出。视频表示 dC/dA * dA/dZ 的方式是将两个矩阵逐个元素相乘。网络可以将多个输入作为一个矩阵，因此我决定使用 4 个输入，从而使矩阵有 4 行。这意味着梯度下降这一步的 dC/dA 和 dA/dZ 都是 4x2。由于是逐元素相乘，因此生成的矩阵仍为 4x2。现在到了乘以 dZ/dB 的部分，这也是我想弄清楚的。 在我的前馈中，z = XW + b，其中 X 是输入矩阵，W 是权重矩阵，b 是偏置向量（1d np 数组）。由于 XW 是 4x2，我本质上是将 b 的每个元素添加到 XW 中的每一列。由于 z 是 4x2，dZ/dB 将是一个只有 1 的 4x2 矩阵。如果我逐元素乘以 1 的矩阵和 dC/dA * dA/dZ，我会得到一个 4x2 矩阵，它不是 2 个元素的向量。我原本以为每列都必须相加或取平均值，但我不知道这在数学上是否合理。 我认为问题在于，当我添加偏差时，它可以被视为一个矩阵，其中每列具有相同的值，因此使其成为 4x2。但是，偏差的数量应与最后一层中的每个节点相对应，因此偏差“矩阵”中每列中的每个元素必须相同。 # 在层类的前馈期间 # i = 所取示例的数量，m = 输入节点的数量，n = 输出节点的数量 def forward(self, X): self.X = X # ixm self.z = np.matmul(X, self.W) + self.b # ixn self.a = self.activation.function(self.z) # ixn return self.a # ixn # 在网络类的梯度下降期间 def gradient_descent(self, X, y): yHat = self.feed_forward(X) output_layer = self.layers[-1] # dCdA * dAdZ == delta (dCdZ) delta = (y - yHat) * output_layer.activation.derivative(output_layer.z) # 输出层上下文中的 ixn dCdW = np.dot(output_layer.X.T, delta) # mxn就像输出层的权重矩阵一样 # dCdB = ??? 应该是类似 n 个元素的向量或 1xn 或 nx1 的东西，以匹配层中偏差向量的形状。     提交人    /u/LtBerry   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8hkwt/quick_question_about_weight_and_bias_gradients/</guid>
      <pubDate>Wed, 04 Sep 2024 01:54:28 GMT</pubDate>
    </item>
    <item>
      <title>作为一名自学 ML 的新手，没有足够的先决条件......</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8frrm/as_a_selfeducating_noob_to_ml_without_enough/</link>
      <description><![CDATA[        提交人    /u/Status-Shock-880   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8frrm/as_a_selfeducating_noob_to_ml_without_enough/</guid>
      <pubDate>Wed, 04 Sep 2024 00:29:04 GMT</pubDate>
    </item>
    <item>
      <title>何谓“融合”？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8fjek/what_is_convergence/</link>
      <description><![CDATA[对于 ML 模型来说，“收敛”到底意味着什么？我不断看到这个词在不同 ML 模型的上下文中使用。例如（在梯度下降的上下文中）：  当算法达到进一步迭代不会显著改变参数的点时，即实现收敛。  如果有人可以在 LR 和决策树的上下文中具体解释它，那就太好了。谢谢！    提交人    /u/NoResource56   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8fjek/what_is_convergence/</guid>
      <pubDate>Wed, 04 Sep 2024 00:18:36 GMT</pubDate>
    </item>
    <item>
      <title>曼城队对 SHAP 价值观的解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8ewad/shap_values_explained_with_manchester_city/</link>
      <description><![CDATA[我用曼城 2021 赛季解释了 SHAP 值  计算球员的 SHAP 值 解释其背后的数学 还在 Youtube 上分享了解释该帖子的视频 用纯 numpy 实现 KernelSHAP   http://mburaksayici.com/blog/2024/09/01/shap-v​​alues-explained.html    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8ewad/shap_values_explained_with_manchester_city/</guid>
      <pubDate>Tue, 03 Sep 2024 23:49:46 GMT</pubDate>
    </item>
    <item>
      <title>生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8dgxo/ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[      正如上一篇文章中所承诺的，我整理的一门课程将赠送 100% 的折扣券：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 使用 Docker 容器化您的应用程序并进行部署（稍后将介绍）  我已经在这门课程上工作了一段时间，我想得到您对我已经发布的视频（80％）的反馈。我不追求金钱价值 - 您的见解将帮助我在课程最终发布之前完善和改进内容。如果您喜欢本课程，请留下评分，我将非常感激。谢谢，祝您学习愉快！ 这是免费访问的优惠券代码：FREETOLEARNML。  https://preview.redd.it/dgyzwfhrdomd1.png?width=964&amp;format=png&amp;auto=webp&amp;s=4571bcc4c25ee14c7a9eb14b9de813d7d2e563a9    提交人    /u/5x12   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8dgxo/ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Tue, 03 Sep 2024 22:38:30 GMT</pubDate>
    </item>
    <item>
      <title>如何培养专家包？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8dgtu/how_to_you_train_bag_of_experts/</link>
      <description><![CDATA[所以我读过百万专家混合并理解了他们的 PEER 模型。我想尝试它的一个简化版本，为了简单起见，我们称之为专家包。 我不想要他们的查询网络、产品密钥和路由器分数，我只想在每次迭代中保留前 1 名专家，而不是前 k 名。但是我仍然保留他们的专家模型 eᵢ⁢(x):=σ⁢(uᵢT⁢x)⁢vᵢ，并根据激活值 σ⁢(uᵢT⁢x) 挑选出排名前 1 的专家。 我将专家的输出添加到输入中以保留维度和信息，而不是简单地用输出替换输入。我不需要层，而是简单地迭代，直到值落在某个区域内或达到终端专家。 （或者我可能可以为每一层设置一组特定的专家，但过一段时间后所有专家都会被考虑。） 所以基本上我有一袋单例神经元，我总是选择最活跃的神经元，我将它的输出添加到我的输入中，然后迭代直到满足某个条件：x&#39; = x + σ⁢(uᵢT⁢x)⁢vᵢ 其中 i = argmaxᵢ σ⁢(uᵢT⁢x) 我如何训练这样的构造，或者任何这些微小的专家模型？特别是当我想保持专家系数不变时，所以我只能创建一个新的专家或删除一个现有的专家。    提交人    /u/FrigoCoder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8dgtu/how_to_you_train_bag_of_experts/</guid>
      <pubDate>Tue, 03 Sep 2024 22:38:13 GMT</pubDate>
    </item>
    <item>
      <title>生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8df38/ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[正如上一篇文章中所承诺的，赠送我整理的一门课程的 100% 免费优惠券：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 使用 Docker 容器化您的应用程序并进行部署（稍后将介绍）  我已经在这门课程上工作了一段时间，我想得到您对我已经发布的视频（80％）的反馈。我不追求金钱价值 - 您的见解将帮助我在课程最终发布之前完善和改进内容。如果您喜欢本课程，请留下评分，我将不胜感激。谢谢，祝您学习愉快！  这是免费访问的优惠券代码：FREETOLEARNML。     提交人    /u/5x12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8df38/ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Tue, 03 Sep 2024 22:34:49 GMT</pubDate>
    </item>
    <item>
      <title>我查看了 Meta Llama 3.1 的标记器。为什么有这么多乱码？它出现在“词汇”和“合并”部分。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8d3tt/i_looked_inside_meta_llama_31s_tokenizer_why_is/</link>
      <description><![CDATA[        由    /u/Arkhos-Winter  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8d3tt/i_looked_inside_meta_llama_31s_tokenizer_why_is/</guid>
      <pubDate>Tue, 03 Sep 2024 22:19:28 GMT</pubDate>
    </item>
    <item>
      <title>对于之前没有学习过 LLM 或 NLP 相关课程的人，有没有什么好的（不太长）的课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8chep/any_good_not_very_long_courses_for_someone_who/</link>
      <description><![CDATA[另外，我应该先从 NLP 课程开始，还是直接跳过它直接跳到 LLM 课程。我不想成为大师或其他什么，我只是想在这一部分超越基础知识，并能够创建一个简单的 llm 助手，但总的来说，我对机器学习的其他部分更感兴趣    提交人    /u/youssef_naderr   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8chep/any_good_not_very_long_courses_for_someone_who/</guid>
      <pubDate>Tue, 03 Sep 2024 21:53:19 GMT</pubDate>
    </item>
    <item>
      <title>可以从数据工程师转为机器学习工程师吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8biow/is_it_possible_to_switch_from_data_engineer_to/</link>
      <description><![CDATA[我目前是一名初级 ETL 开发人员，主要使用 Python（主要用于 Airflow）和 PostgreSQL。今年 11 月将是我担任该职位的两周年。在此之前，我曾担任数据分析师一年，再之前，我曾担任生物信息学家。我目前对自己的薪水感到满意，但一年后，我计划要求晋升为中级开发人员职位。 为此做准备，我已经完成了为期 8 个月、每周 15 小时的数据科学课程和为期 4 个月、每周 15 小时的 SQL 课程。我还计划在要求晋升之前参加为期 6.5 个月、每周 15 小时的数据工程课程，然后参加为期 4 个月、每周 15 小时的算法课程。此外，我打算转到另一个项目以获得数据工程师的经验，或者，我将探索另一家公司的就业机会。 一旦我获得了数据工程师的职位，我计划学习一年的数学，然后攻读机器学习硕士课程。我的主要问题是，考虑到我将拥有 6 年的数据分析师、ETL 开发人员和数据工程师经验以及一系列学习项目，是否有可能跳过 ML 工程的初级职位（和相关薪酬）。这些角色的技能可以转移吗？ 我想转入 ML 工程的原因是，我发现创建预测和分析模型比简单地管理数据管道更有吸引力。另一方面，数据工程知识应该可以帮助我更快地获得更好的薪水，这将使我更容易资助硕士课程。我是否应该继续攻读硕士学位，还是 1 年的 ML 课程就足够了？ 我目前在俄罗斯，目前在国际上并不是特别受欢迎。然而，这里的就业市场到目前为止一直很稳定，不像美国，在那里我看到了很多关于 CS/IT 子版块的抱怨。    提交人    /u/IOvOI_owl   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8biow/is_it_possible_to_switch_from_data_engineer_to/</guid>
      <pubDate>Tue, 03 Sep 2024 21:13:21 GMT</pubDate>
    </item>
    <item>
      <title>帮助选择人工智能硕士学位：计算机科学还是科学技术人工智能？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f8804g/help_choosing_a_masters_degree_in_ai_computer/</link>
      <description><![CDATA[大家好， 我刚毕业，拥有计算机科学学士学位，目前正在决定攻读硕士学位。我对人工智能特别感兴趣，但我并不完全确定该领域的具体工作角色或所需的关键能力。 我已将选择范围缩小到两个项目：  计算机科学硕士：该项目提供广泛的课程，包括人工智能方面的几门课程，但也允许我探索其他领域，如软件工程或数据管理。 科学与技术人工智能硕士：该项目完全专注于人工智能并提供不同的专业化。它包括对整个 AI 过程的更全面研究，例如包括用于收集数据的传感器背后的物理原理。  这就是我遇到的问题：  计算机科学计划：看起来更容易，因为它不需要深入研究传感器的物理原理，这感觉非常专业（例如，航空或医疗设备中的传感器）。我可以更多地专注于 AI 模型，同时仍然可以灵活地研究计算机科学的其他关键领域。 科学和技术 AI：提供对 AI 的更深入研究，包括了解数据收集背后的物理过程。虽然这看起来更全面，但我担心它可能过于专业，而且我不确定在典型的 AI 工作中我实际上会用到多少知识。  我的问题：  与以 AI 为重点的更广泛的计算机科学学位相比，选择以 AI 为重点的学位是否会显着提高职业前景？ 在与 AI 相关的工作中，传感器物理和数据收集知识有多重要？公司是否普遍拥有这些领域的专家，还是 AI 专家应该知道的东西？ 考虑到我的兴趣和顾虑，哪个课程可以更好地为我从事 AI 职业做好准备？  提前感谢您的见解和建议！    提交人    /u/Budget-Price2037   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f8804g/help_choosing_a_masters_degree_in_ai_computer/</guid>
      <pubDate>Tue, 03 Sep 2024 18:53:04 GMT</pubDate>
    </item>
    <item>
      <title>软件工程师如何阅读深度学习论文</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f7ziwc/how_to_read_deep_learning_paper_as_a_software/</link>
      <description><![CDATA[        提交人    /u/research_pie   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f7ziwc/how_to_read_deep_learning_paper_as_a_software/</guid>
      <pubDate>Tue, 03 Sep 2024 13:09:41 GMT</pubDate>
    </item>
    <item>
      <title>在现实世界中有什么用途？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f7xhzy/what_is_used_in_the_real_world/</link>
      <description><![CDATA[嗨！ 请原谅我的无知，我是这个领域的新手，仍在学习。我一直在自学机器学习，并自己学习了标准的监督和无监督学习算法，以及一些 NLP。我从很多人那里听说，虽然这些都是本科阶段机器学习课程所涵盖的内容，但它们非常简单，绝对不是行业预测所用的内容。 有人可以告诉我行业中正在使用什么吗？是不同的算法，还是装袋/提升/堆叠技术，还是完全不同的东西？提前谢谢您！！    提交人    /u/darkGrayAdventurer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f7xhzy/what_is_used_in_the_real_world/</guid>
      <pubDate>Tue, 03 Sep 2024 11:27:32 GMT</pubDate>
    </item>
    <item>
      <title>我下一步该走哪条路才能成为一名机器学习工程师？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f7wpdo/what_path_should_i_take_next_to_become_an_ml/</link>
      <description><![CDATA[我是一名即将毕业的计算机科学本科生（印度人，仅用于地理背景）。我希望将来走机器学习的道路。因此，我参加了 Jose Portilla 的 Udemy 机器学习课程。我学习了基本模型、理论和它们背后的直觉，并做了一些简单的项目。我学到的主题主要是监督学习。 现在，当我寻找实习机会时，我意识到我的技能不足以获得一份正规的实习机会。因此，我很困惑下一步该怎么做。以下是我在观看了大量 Youtube 视频和路线图后找到的几条路径。  在 Coursera 上参加 Andrew ng 的机器学习和深度学习课程。虽然这项技术可能没有在行业中使用，但我想它会让我的基本概念清晰起来。 在 Udemy 上找到一些专门针对 NLP 的课程。  在 Udemy 上查找一些有关图像识别、处理和 OpenCV 的课程。 继续学习 Google 提供的 GenAI 和快速工程课程。虽然这可能会教很多实用的东西，但我担心自己从根本上很弱。  因此，如果您在这个领域有经验，我恳请您指导我应该走哪条路或任何其他路线图。    提交人    /u/VeganCannibal-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f7wpdo/what_path_should_i_take_next_to_become_an_ml/</guid>
      <pubDate>Tue, 03 Sep 2024 10:40:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>