<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 17 Sep 2024 09:17:01 GMT</lastBuildDate>
    <item>
      <title>是否可以将句子嵌入转换为张量以用于单词生成？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fiu2oo/is_it_possible_to_convert_a_sentence_embedding/</link>
      <description><![CDATA[我正在尝试找出一种基于新词在模型中的嵌入方式来查找新词的方法。我的目标是嵌入一个词，修改嵌入，然后返回一个接近新嵌入位置的新词。这个想法来自于图像，图像中国王 - 王后、男人 - 女人之间的距离相似。 阅读句子转换器和编码过程，编码是将单词嵌入到模型的 768 个维度中。然后可以通过余弦相似度计算将嵌入与其他嵌入进行比较。嵌入不具有任何转换回单词的方法。 需要的是一个句子生成器，它经过训练，可以根据所讨论的模型从嵌入中生成单词。环顾四周，我发现大多数都遵循输入标记样式的编码，其中一个输入文本，模型执行编码和标记生成。 我找不到关于嵌入和生成单词的讨论，所以我真的不知道这是否可能。  copilot 试图将一些代码作为我的问题的答案，copilot 似乎确信我所问的问题 100% 可能，无论代码多么不起作用 from sentence_transformers import SentenceTransformer from transformers import GPT2LMHeadModel model = SentenceTransformer(&#39;paraphrase-MiniLM-L6-v2&#39;) vector_1 = model.encode(&quot;hello&quot;) vector_2 = model.encode(&quot;world&quot;) t_vector = vector_1 - vector_2coded_tensor = torch.tensor(encoded_word).unsqueeze(0) gpt2_model = GPT2LMHeadModel.from_pretrained(&quot;GPT2&quot;) with torch.no_grad(): output = gpt2_model.generate(input_ids, max_length=50, num_return_sequences=1, do_sample=True,coder_outputs=encoded_tensor) generated_text = tokenizer.decode(outputs[0],skip_special_tokens=True)     提交人    /u/Low-Information389   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fiu2oo/is_it_possible_to_convert_a_sentence_embedding/</guid>
      <pubDate>Tue, 17 Sep 2024 08:50:23 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 会议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitscd/pytorch_conference/</link>
      <description><![CDATA[大家好， 我真的很想参加 Pytorch 大会，我想知道是否有人有他们没有使用的 PyTorch 大会门票。我试图在 pytorch 社区中发布此信息，但被骗了，所以我没有钱。但如果你愿意赠送一张，我将不胜感激！    提交人    /u/Regular_Egg4619   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitscd/pytorch_conference/</guid>
      <pubDate>Tue, 17 Sep 2024 08:31:06 GMT</pubDate>
    </item>
    <item>
      <title>扩散引导语言建模论文细目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitrqr/diffusion_guided_language_modelling_paper/</link>
      <description><![CDATA[        提交人    /u/RamboCambo15   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitrqr/diffusion_guided_language_modelling_paper/</guid>
      <pubDate>Tue, 17 Sep 2024 08:30:06 GMT</pubDate>
    </item>
    <item>
      <title>我如何为法学硕士 (LLM) 提供大量背景信息？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</link>
      <description><![CDATA[大家好！ 我的问题是如何向 LLM 提供超出提示的大量上下文信息。我想知道使用 RAG 是否可以做到这一点？目标是创建一个学习助手。LLM 需要大量有关学习内容（理想情况下是学习状态）的信息。理想的做法是提供完整聊天记录的上下文信息，而不是通过 RAG 为每个答案再次查询必要的信息并将其作为提示提供给 LLM。 除了在具有相应学习内容的数据集上训练 AI 或使用 RAG 查询信息之外，还有其他选择吗？    提交人    /u/Maleficent_Bus_994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</guid>
      <pubDate>Tue, 17 Sep 2024 08:24:01 GMT</pubDate>
    </item>
    <item>
      <title>大家好，</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitni4/hello_folks/</link>
      <description><![CDATA[大家好，我有一个疑问，我想训练一个语音模型作为助手，那么作为初学者，我应该关注哪些方面。您的信息对我应该很有帮助。     提交人    /u/newuserm01   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitni4/hello_folks/</guid>
      <pubDate>Tue, 17 Sep 2024 08:22:04 GMT</pubDate>
    </item>
    <item>
      <title>我不知道从哪里开始创建这个语音模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fita0f/i_dont_know_where_to_start_to_create_this_voice/</link>
      <description><![CDATA[我想创建一个模型，它可以听我的英语口音并给出最高 100% 的评分。我在 ML 方面有很好的基础知识，例如，我研究过神经网络、Transformer，使用过 PyTorch 和 Hugging Face，但我不知道如何开始这样的项目。我是否应该使用 PyTorch 从头开始​​构建模型？我是否应该对 Hugging Face 中的某些内容进行微调？您建议我怎么做？    提交人    /u/boringblobking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fita0f/i_dont_know_where_to_start_to_create_this_voice/</guid>
      <pubDate>Tue, 17 Sep 2024 07:57:11 GMT</pubDate>
    </item>
    <item>
      <title>好的图形数据库选项？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fit348/good_graph_database_options/</link>
      <description><![CDATA[我正在尝试构建一个 graphRAG 并使用其图形数据库，到目前为止，所有内容都指向 neo4j。我们还有其他更好、更适合生产的选项吗？    提交人    /u/Aromatic_Ad9700   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fit348/good_graph_database_options/</guid>
      <pubDate>Tue, 17 Sep 2024 07:43:40 GMT</pubDate>
    </item>
    <item>
      <title>寻求建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fit1ym/looking_for_advice/</link>
      <description><![CDATA[嘿！我目前正在学习 ML 基础知识。我需要做一个项目，为此我需要某种数据库或网页，以便我可以检查北极光（极光）是否在某个区域可见。如果有人知道类似的东西并且可以分享，我将不胜感激！谢谢    提交人    /u/Masterofstone777   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fit1ym/looking_for_advice/</guid>
      <pubDate>Tue, 17 Sep 2024 07:41:21 GMT</pubDate>
    </item>
    <item>
      <title>在家用电脑上运行 LLM：Llama 3.1 70B，压缩 6.4 倍，大小 22 GB</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</link>
      <description><![CDATA[大家好！想分享一些可能有助于您了解和试验 LLM 的内容。最近，我们使用 PV-Tuning 方法成功压缩了 Llama 3.1 70B 和 Llama 3.1 70B Instruct。 结果如下： - 压缩率：6.4 倍（从 141 GB 到 22 GB） - 质量保留：Llama 3.1-70B（MMLU 0.78 -&gt; 0.73），Llama 3.1-70B Instruct（MMLU 0.82 -&gt; 0.78） 我们实际上对 Llama 3.1 8B 模型做了同样的事情。根据[此](https://blacksamorez.substack.com/p/aqlm-executorch-android?r=49hqp1&amp;utm\_campaign=post&amp;utm\_medium=web&amp;triedRedirect=true) 工作证明，它现在可以在 RAM 少于 2.5 GB 的 Android 上运行。因此，您现在可以离线部署它，而无需共享您的数据。  您可以在此处找到结果并下载压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-AQLM-PV-2Bit-1x16-hf https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-Instruct-AQLM-PV-2Bit-1x16-hf    提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</guid>
      <pubDate>Tue, 17 Sep 2024 06:57:47 GMT</pubDate>
    </item>
    <item>
      <title>大家好。我想写一篇关于使用机器学习预测心脏病的硕士论文。这是一个好主题吗？我能提出什么新观点？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1firzyf/hello_everyone_i_want_to_write_a_masters_thesis/</link>
      <description><![CDATA[  由    /u/Spiritual_Food_2962  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1firzyf/hello_everyone_i_want_to_write_a_masters_thesis/</guid>
      <pubDate>Tue, 17 Sep 2024 06:32:17 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fipji6/need_help/</link>
      <description><![CDATA[我是一名大四学生。我们必须研究如何对视频进行索引，基本上是想提取信息，例如演员的讲话、场景、剪辑等。我找不到好的最新研究论文。请指导我如何找到一些。谢谢    提交人    /u/muhammadharoon021   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fipji6/need_help/</guid>
      <pubDate>Tue, 17 Sep 2024 04:09:33 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习的书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</link>
      <description><![CDATA[此帖是我对 reddit 不让我评论某人帖子的报复。他们想要学习机器学习的建议。他们是物理学毕业生。如果这对某些人不相关，我深表歉意 机器学习领域分为许多领域，但最突出的是深度学习、计算机视觉和自然语言处理。如果您想要深入研究某个特定领域，我或其他人肯定可以提供更具体的建议，话虽如此，已经有一些通用书籍出版，旨在涵盖AI（人工智能）的广度，其中最好的两本是-  深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书可从此处免费获取） 人工智能：一种现代方法（pearson.com）  这两本书试图涵盖人工智能领域的所有内容。虽然第一本书能让你真正理解和欣赏人工智能创新背后的启发式和直觉思维，但第二本书只会让你意识到人工智能思维的起源，可以追溯到亚里士多德。 现在，以上两本书都不会给你实践课程，我不推荐“实践”书籍。事实上，机器学习算法非常容易实现，只需几行 python/c++（一个算法可能需要 10 行到 100 行代码 - 无论如何都不是很多）。所以，一个好的策略是先学习 python（如果你还没有）-&gt;了解该领域并学习数学（并行），然后在学习 pytorch 的同时实现每个算法。既然你已经了解数学，我建议你阅读深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书免费这里）和/或我下面要提到的书籍。 下面的书都不是废话，只是数学和可视化书籍，作为物理学毕业生，你可能很容易理解。  计算智能：方法论介绍 | SpringerLink（我最喜欢的一本介绍神经网络、进化算法和模糊逻辑的书）。 （免费）模式识别和机器学习 (microsoft.com)（广受好评的“统计学习方法”书籍。 （免费）深入学习 — 深入学习 1.0.3 文档 (d2l.ai)（迄今为止学习深度学习的最佳书籍）。它有理论和代码）。  基于相关领域的其他书籍：  计算机视觉：算法和应用，第二版。 （szeliski.org） 计算机视觉：一种现代方法：Forsyth，David，Ponce，Jean：9780136085928：Amazon.com：图书  （注：CV（我认为通过视频课程学习计算机视觉效果更好）  统计自然语言处理基础（stanford.edu） 强化学习（mit.edu）     由   提交  /u/reacher1000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</guid>
      <pubDate>Tue, 17 Sep 2024 03:56:40 GMT</pubDate>
    </item>
    <item>
      <title>您推荐哪些机器学习工具来增强 AI 生成的内容？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fin7ua/what_machine_learning_tools_do_you_recommend_for/</link>
      <description><![CDATA[我很好奇哪些机器学习工具可以增强 AI 生成的内容。我听说过 Fleak，想知道以前是否使用过它，以及它与市场上的其他工具相比如何？    提交人    /u/Designer_Usual1786   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fin7ua/what_machine_learning_tools_do_you_recommend_for/</guid>
      <pubDate>Tue, 17 Sep 2024 02:16:42 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习时令我烦恼的事情。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fi1z5x/the_thing_that_bugs_me_about_learning_machine/</link>
      <description><![CDATA[学习机器学习有时会令人沮丧，因为它常常不像解决问题，而更像是“算法学习”。这意味着我正在学习别人对某个问题的思考方式。 例如，我正在学习小样本学习的概念。这个概念非常笼统：假设您只有来自训练集的几个示例，您如何训练分类器以成功识别新的测试图像。 如果我将这个问题交给对机器学习有最低限度了解的人，那个人可能会将这个问题定义为生成与这几个示例相关的高质量示例。我的意思是，如果您可以生成更多示例，那么示例数量就不再是问题。直观，对吧？ 但这种直观的方法并不是人们通常开始解释机器学习的方法。例如，在我看过的一个视频中，作者说了这样的话：“你需要另一个预先训练好的深度神经网络……”或“小样本学习的解决方案是孪生神经网络”（为什么？？）。这似乎不是解决这个问题最直观的方法。相反，这是那一年一些研究人员采取的方法，不知何故成为了问题本身的决定性解决方案。 在学习机器学习时，我多次遇到过这个问题。任何问题/任务似乎都有一些预定义的现成解决方案。并不总是最直观的，或最有效的，甚至没有意义（就某些假设而言）。但不知何故，这种方法成为整个问题的决定性解决方案。话虽如此，有些解决方案（例如用于聚类的 Kmeans/Knn）比其他解决方案更直观。 再举一个例子，我鼓励你查找元学习。视频总是以“元学习就是学习如何学习”开头然后接着说“我们就是这样解决的”。如果你退一步思考一下“学习如何学习”作为一个人（例如，学习如何学习一门新语言），你很快就会意识到你的解决方案与机器学习文献中采用的方法大不相同。 我想知道你在学习机器学习的过程中是否遇到过这个问题，以及你是如何思考或处理它的。    提交人    /u/TorontoEarthquake   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fi1z5x/the_thing_that_bugs_me_about_learning_machine/</guid>
      <pubDate>Mon, 16 Sep 2024 11:18:05 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>