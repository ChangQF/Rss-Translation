<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 23 Feb 2024 00:55:47 GMT</lastBuildDate>
    <item>
      <title>在推理管道中使用 PyTorch 可视化实用程序</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/</link>
      <description><![CDATA[      在推理管道中使用 PyTorch 可视化实用程序 https://debuggercafe.com/using-pytorch-visualization-utilities-in-inference-pipeline/ ​  https://preview.redd.it/y5rc0xj1e8kc1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=cb3d5a561b481102201f4702895847fa6c9a564f  &amp; #32；由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/</guid>
      <pubDate>Fri, 23 Feb 2024 00:39:35 GMT</pubDate>
    </item>
    <item>
      <title>论文的贡献和新颖性是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/</link>
      <description><![CDATA[我正在做我的论文。对于新闻文本分类，贡献是什么？我正在尝试使用数据集中的所有标签/类别，例如标题、文本、主题和日期。虽然大多数研究人员最多使用标题和文本。我知道主题和日期的贡献很小。但我仍然这么做了。这样就够了吗？   由   提交 /u/Kindly-Song5246    reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/</guid>
      <pubDate>Fri, 23 Feb 2024 00:08:06 GMT</pubDate>
    </item>
    <item>
      <title>Langchain 地图缩减</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axkz9u/langchain_map_reduce/</link>
      <description><![CDATA[我想知道 langchain 映射减少如何迭代地减少提示 例如，如果我们有一个 2k 的上下文大小和一个 8k 令牌提供输入 首先我们将 8k 映射到 4x2k 映射 然后假设这 4 个摘要导致 4x1k 输出时间摘要，我们如何为下一次迭代映射这些摘要 我们是否会将 2 个摘要放入一个摘要中，从而生成 2x2k 个令牌映射？ 或者我们是否会进一步总结每个 1k 输出，直到所有 4 个摘要组合起来小于 2k 上下文？  即第一次迭代后 2 个 llm 调用或 4 个 llm 调用？ 我真的找不到任何文档支持我清楚地回答任何一个问题   由   提交/u/proturtle46  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axkz9u/langchain_map_reduce/</guid>
      <pubDate>Thu, 22 Feb 2024 23:15:53 GMT</pubDate>
    </item>
    <item>
      <title>“ValueError：层“sequential_11”的输入 0 与该层不兼容：预期形状=（无，10，5），发现形状=（1,21,5）”您建议如何解决它？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axj9eq/valueerror_input_0_of_layer_sequential_11_is/</link>
      <description><![CDATA[很多时候我没有看到这一点，最近我看到了。但在这期间我没有添加和更改任何内容。 其中一个代码如下； - window_length = 10 - number_of_features = df.values.shape[1] - batch_size=5 - input_shape=(window_length, number_of_features)   由   提交/u/Ok_Orange_9086   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axj9eq/valueerror_input_0_of_layer_sequential_11_is/</guid>
      <pubDate>Thu, 22 Feb 2024 22:07:19 GMT</pubDate>
    </item>
    <item>
      <title>LLM 聊天机器人为何如此之快？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axi7do/how_are_llm_chatbots_so_fast/</link>
      <description><![CDATA[最近出现的很多聊天机器人都在使用 GPT，但我不明白它们的响应时间为何如此之短？每当我在项目中使用 GPT 3.5 或 4 Turbo 的 openAI 密钥时，响应时间通常都会超过 10 秒。我做错了什么？   由   提交/u/Dont_comment_much  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axi7do/how_are_llm_chatbots_so_fast/</guid>
      <pubDate>Thu, 22 Feb 2024 21:24:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MSE 被称为 L2 损失？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/</link>
      <description><![CDATA[它们不同。但是在这篇中等文章中：  损失是平均值输入图像与重建图像之间的平方误差，即L2损失。  在this 研究论文：  在 AE 中，每个数据点的目标函数由...给出，其中 || ·||表示任意距离函数。通常使用L2范数。  MSE是通常使用的损失，这让我相信论文表明它们是等价的。  ​ 为什么？   由   提交 /u/Exciting-Ordinary133    reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/</guid>
      <pubDate>Thu, 22 Feb 2024 20:35:25 GMT</pubDate>
    </item>
    <item>
      <title>这是否被认为是过度拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axgmrn/is_this_considered_as_overfitting/</link>
      <description><![CDATA[      对于糟糕的图像，我深表歉意，但我无法发布屏幕截图。这是否被认为是过度拟合？测试精度：0.97 验证精度：0.98   由   提交/u/Leading_Pspecial60   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axgmrn/is_this_considered_as_overfitting/</guid>
      <pubDate>Thu, 22 Feb 2024 20:22:50 GMT</pubDate>
    </item>
    <item>
      <title>2024 年业界最受 ML 工程师欢迎（也是最好）的技术堆栈是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/</link>
      <description><![CDATA[ 由   提交/u/Appropriate-Tip935   reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/</guid>
      <pubDate>Thu, 22 Feb 2024 19:50:03 GMT</pubDate>
    </item>
    <item>
      <title>地理数据聚类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axflbo/clustering_geographical_data/</link>
      <description><![CDATA[      所以我习惯在对坐标进行聚类时执行 K 均值之类的操作，但我得到了这个奇怪的结果。大多数数据（96%）位于右上方的“簇”中。 (0,0) 就是我放在那里的空值。如果我可以，K 意味着它将把大的部分分成簇，并将其中一些点放入同一个簇中（k = 8）。我想知道我是否应该相信我的 homeboi kmeans 或者推荐的方法是什么。 https://preview.redd.it/pxpoo2xrw6kc1.png?width=718&amp;format=png&amp;auto=webp&amp;s=b1334d0f97bd1a5d431c49e991 aa7696a958f3ff   由   提交 /u/Necessary-Echo-5241   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axflbo/clustering_geographical_data/</guid>
      <pubDate>Thu, 22 Feb 2024 19:43:31 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能创建一个结合定量数据和定性数据结果的模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axfhzk/is_it_possible_to_create_a_model_that_combines/</link>
      <description><![CDATA[我正在为我的学校创建一个项目，并希望创建一个模型，在考虑睡眠模式和社交媒体使用情况的情况下给出压力水平。 我找到了这些数据集 https://www. kaggle.com/datasets/laavanya/ human-stress-detection-in-and-through-sleep?resource=download（具有肢体运动、睡眠时间、快速眼动时间等功能） 和 &lt; a href=&quot;https://www.kaggle.com/datasets/monishakant/dataset-for-stress-analysis-in-social-media&quot;&gt;https://www.kaggle.com/datasets/monishakant/dataset-for -stress-analysis-in-social-media（有不同帖子的文本）我想知道是否可以创建这样的模型以及如何进行。   由   提交/u/xyratious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axfhzk/is_it_possible_to_create_a_model_that_combines/</guid>
      <pubDate>Thu, 22 Feb 2024 19:39:48 GMT</pubDate>
    </item>
    <item>
      <title>毫升数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axbdz1/mathematics_for_ml/</link>
      <description><![CDATA[你好，我想学习 ML 的数学知识，但在搜索之后我很困惑从哪里开始，我听到有人说使用可汗学院，但确实如此我只是学习线性代数、统计和微积分的全部内容？  或者我在这些科目中学习哪些主题？我将不胜感激您的建议。   由   提交/u/BEE_LLO   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axbdz1/mathematics_for_ml/</guid>
      <pubDate>Thu, 22 Feb 2024 16:58:26 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习进行动物行为识别</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axaabz/animal_behavior_recognition_using_machine_learning/</link>
      <description><![CDATA[我希望您能很好地找到这篇文章。 OpenCV 的文章 .ai 回顾了动物行为识别和动物姿势检测中的关键人工智能方法，展示了它们在神经生物学到兽医学等领域的应用。此外，它还强调了最近科学进步在理解和管理动物行为方面的重要性。 在本文中，您将了解：  深入理解行为识别学习 深度学习动物姿态识别方法 动物行为识别技术 基于深度学习的应用示例  完整文章为 这里。   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/learnmachinelearning/comments/1axaabz/animal_behavior_recognition_using_machine_learning/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axaabz/animal_behavior_recognition_using_machine_learning/</guid>
      <pubDate>Thu, 22 Feb 2024 16:16:02 GMT</pubDate>
    </item>
    <item>
      <title>快速提升 MLOps 掌握：您现在不可或缺的指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ax5l1x/quick_elevating_mlops_mastery_your_indispensable/</link>
      <description><![CDATA[      提升 MLOps 掌握  自动化重点：优先考虑构建中重复性任务的自动化，验证和部署机器学习模型，以提高工作效率并减少错误。 开源工具：采用广泛采用的开源 MLOps 工具，例如 Kubeflow、MLflow 和 TensorFlow Extended (TFX)，以加速您的 MLOps旅程并从充满活力的开发者社区中受益。 CI/CD 实施：将持续集成 (CI) 和持续部署 (CD) 原则集成到您的 MLOps 策略中，以加快迭代、最大程度地降低风险并提供高质量的服务。更快地开发高质量的机器学习产品。 协作重点：在整个机器学习生命周期中促进数据科学家、软件工程师和 DevOps 专业人员之间的密切合作，以促进高效的问题解决和无缝的团队合作。 &lt; li&gt;监控和优化：定期监控机器学习模型和 MLOps 基础设施的运行状况和性能，识别改进机会并实施策略以提高模型的准确性和稳定性。 持续学习：及时了解最新动态通过参加会议、阅读博客和文章以及参与在线社区，了解 MLOps 的最新趋势、技术和最佳实践，不断提高您在快速发展的机器学习操作领域的技能和知识。   关注更多：MLOps 快速提升精通：现在您不可或缺的指南 &lt; p&gt;Youtube：AITech.Studio 新闻  &amp;# 32；由   提交/u/AITech-Studio  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ax5l1x/quick_elevating_mlops_mastery_your_indispensable/</guid>
      <pubDate>Thu, 22 Feb 2024 12:46:22 GMT</pubDate>
    </item>
    <item>
      <title>Oxen.AI 明天的 Paper Club Zoom 电话会议将涵盖 Google 的文本到视频扩散模型 Lumiere（太平洋时间周五上午 10:00 - 10:45）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ax4hc4/oxenais_paper_club_zoom_call_tomorrow_will_cover/</link>
      <description><![CDATA[Oxen.AI 明天的 Paper Club Zoom 电话会议将涵盖 Lumiere , Google 的文本到视频传播模型Oxen 的首席执行官 Greg Schoeninger 非常聪明，而且善于直言不讳。他主持通话。 （嘿，格雷格，你在 reddit 上吗？） 在 45 分钟的会议结束时，我觉得我已经很好地理解了一篇论文，可以将其添加到我的瑞士军刀工具“可能的艺术”中;了解在正确的时刻进行部署。我非常高兴听到格雷格对卢米埃尔的看法，看看其他与会者怎么说，并询问谁在聊天中发疯。 下周五，3 月 1 日，美杜莎与嘉宾主持人丹尼尔·瓦罗里-瓦西列夫斯基 (Daniel Varoli-Vasilevskiy) 会面。  p&gt; 要注册 Zoom 通话（需要批准）： https:// www.oxen.ai/community?utm_source=paper_club_flyer 未正式为 Oxen 发布此内容。我的观点是我自己的。我很感激他们为我提供了一种有趣而简单的方法，让我在每个周五的午餐期间消化一篇人工智能基础论文。帮助聊天和问答的 Oxen 团队、Ben、Scott、Adam 和我的特别好友实习生团队 ;-) 也很棒。他们创造了一些特别的东西。我尊重并钦佩他们所做的事情以及他们是如何做到的。 此外，我还遇到了一些很棒的人，我正在通过他们的 Discord 与我在新项目上结对 https://discord.com/invite/s3tBEn7Ptg ​   由   提交 /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ax4hc4/oxenais_paper_club_zoom_call_tomorrow_will_cover/</guid>
      <pubDate>Thu, 22 Feb 2024 11:44:20 GMT</pubDate>
    </item>
    <item>
      <title>你们感觉到了吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ax3odj/do_you_guys_feel_it/</link>
      <description><![CDATA[       由   提交 /u/AdelSexy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ax3odj/do_you_guys_feel_it/</guid>
      <pubDate>Thu, 22 Feb 2024 10:54:13 GMT</pubDate>
    </item>
    </channel>
</rss>