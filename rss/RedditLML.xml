<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 11 Jan 2024 21:12:30 GMT</lastBuildDate>
    <item>
      <title>有人读完MML书吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194cda2/anyone_finished_mml_book/</link>
      <description><![CDATA[有用吗？是否存在误导学习的令人讨厌的拼写错误？   由   提交 /u/iiillililiilililiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194cda2/anyone_finished_mml_book/</guid>
      <pubDate>Thu, 11 Jan 2024 21:01:07 GMT</pubDate>
    </item>
    <item>
      <title>了解 LLM 模型如何在 Huggingface 上发挥作用</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194bmx1/understand_how_the_llm_models_work_on_huggingface/</link>
      <description><![CDATA[我知道您最近看到了很多新模型，甚至在 Infermatic.ai 或 Character.ai 这就是为什么我在这里向您解释这个模型是如何工作的 &lt; Hugging Face 等平台上的大型语言模型 (LLM) 通过使用先进的神经网络架构来处理和生成文本。以下是他们通常如何运作的简短说明：  培训：法学硕士接受大量文本数据的培训。在训练过程中，模型学习根据前面的单词预测句子中的下一个单词。此过程有助于模型理解语言模式、语法和上下文。 架构：这些模型通常使用 Transformer 架构的变体，该变体擅长处理文本等顺序数据。 Transformer 使用注意力等机制来权衡句子中不同单词的重要性，从而使模型能够生成更加连贯且与上下文相关的响应。 标记化：当您输入句子时，模型首先将其分解为标记（可以是单词或单词的一部分）。此过程称为标记化。 处理：然后将标记输入模型，模型使用其学习的模式对其进行处理并生成一系列输出标记。 解码：这些输出标记随后被转换回人类可读的文本，形成响应或生成的内容。 微调 ：在某些情况下，法学硕士针对特定任务或领域进行了微调，这意味着他们在较小的专业数据集上进行了进一步训练，以便在特定领域（如医学语言、法律文本等）表现良好。 &lt; li&gt;API 访问：在 Hugging Face 等平台上，这些模型通常可以通过 API 访问，从而允许开发人员将它们集成到各种应用程序中，以执行文本生成、翻译、摘要、问答等任务。     由   提交 /u/Horror_Echo6243   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194bmx1/understand_how_the_llm_models_work_on_huggingface/</guid>
      <pubDate>Thu, 11 Jan 2024 20:31:12 GMT</pubDate>
    </item>
    <item>
      <title>数学问题帮助：神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194atu2/math_problem_help_neural_networks/</link>
      <description><![CDATA[我正在解决 Bishop 1995 年关于神经网络的书中的这个问题： 在多层感知器中，隐藏单元有一个对于位于由 w^T x + w0 = const 给出的输入空间中的超平面上的输入向量的恒定激活，而对于径向基函数网络，隐藏单元在由 ||x 定义的超球面上具有恒定激活− µ||^2 = const.. 表明，对于参数的适当选择，如果输入向量归一化为单位长度，则这些表面会重合，因此 ||x|| = 1. 这个问题看起来很容易解决。然而，我陷入了开头本身，可能是因为用来表达问题的语言。球面和平面怎么可能重合？我缺少什么？对于此问题的任何帮助，我们将不胜感激。   由   提交 /u/shashvata   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194atu2/math_problem_help_neural_networks/</guid>
      <pubDate>Thu, 11 Jan 2024 19:58:09 GMT</pubDate>
    </item>
    <item>
      <title>注意帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1949pqa/attention_help/</link>
      <description><![CDATA[亲爱的 Reddit，  我已经失去了对注意力如何充分发挥作用的直觉，所以这一次，我试图明确写出我对查询、键和值矩阵代表什么的理解，但是，我不太确定我的理解是否正确，有人可以“校对”吗？我的理解？  “”“ 查询矩阵 W^Q (embedding_dim, d_k) = 矩阵，其中每个维度包含一行，其值等于“特征”的值。 （在下一段中讨论）要查找，即对于该特定维度而言，哪个维度最重要。 关键矩阵 W^K (embedding_dim, d_k) = 每个维度包含一行的矩阵它的“特征”对于这个特定的维度。注意：这些特征本身并不是实际的维度，我们不知道这些特征代表什么，但首先如果我们想象单词嵌入的每个维度都有一些含义，例如，某些维度代表语义相似性，意味着具有相似含义的单词在空间中很接近，其他维度可能是特定概念“人”、“颜色”、地点、时态等，其他维度可能是词性，例如名词、动词等，W^K 将它们转换为格式，一组可以与查询相匹配的“特征”，换句话说，在检索设置中，您可能会将其视为用于查找实际数据的元数据。  值矩阵 W^V (embedding_dim, d_v) = 每个维度包含一行的矩阵，其中包含在注意力机制中传递的 ACTUAL 维度的相关信息。 ”“  GPT4 似乎不同意我的观点： “”“”   查询矩阵 (W^Q)：该矩阵用于将输入嵌入转换为一组查询。每行并不完全包含指示特定维度的特征重要性的值。相反，它将输入嵌入转换为一个空间，其中每个维度代表不同的方面或“查询”。我们想要与键进行匹配。 键矩阵 (W^K)：与 W^Q 类似，W^K 将输入嵌入转换为键空间。键矩阵本身不包含特定维度的特征，而是将输入转换为一种表示形式，其中每个维度都可以被视为可以与查询进行匹配的不同特征或特征。 &lt;值矩阵（W^V）：该矩阵将输入嵌入转换为值空间。每行对应于输入嵌入的变换表示，其中每个维度都携带原始嵌入的一些信息。这些值用于注意力机制中的加权和计算。  “”“”  有人可以帮忙吗？  ​   由   提交/u/BenAhmed23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1949pqa/attention_help/</guid>
      <pubDate>Thu, 11 Jan 2024 19:11:25 GMT</pubDate>
    </item>
    <item>
      <title>128维高斯潜在空间之旅</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1947u06/a_trip_through_128_dimensional_gaussian_latent/</link>
      <description><![CDATA[    &lt; /a&gt;  我创建了一个工具，可以在我所构建的 VAE 的潜在空间内形成一系列随机线性插值。正在建设。然后，它显示最后一个 LERP 的结果和字符串，以从前一个 LERP 的端点开始，以创建平滑的（呃）过渡。 仍然缺少我想要捕获的更精细的图像细节，但我认为这个可视化结果看起来很酷。希望当我对更深入的模型进行调整时能看到更多的精美图像 https://github。 com/ddaeschler/vae-experiments 就像在疯狂的生成中快速行驶一样高速公路   由   提交/u/Spaghetti-Logic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1947u06/a_trip_through_128_dimensional_gaussian_latent/</guid>
      <pubDate>Thu, 11 Jan 2024 17:54:37 GMT</pubDate>
    </item>
    <item>
      <title>关于具有非常大输入向量的 FFNN 的直觉。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1947k0t/intuition_regarding_ffnns_with_very_large_input/</link>
      <description><![CDATA[我正在考虑解决我遇到的问题，其中之一需要使用具有可变输入大小的前馈神经网络。 （澄清一下，每个网络的输入大小是在创建时设置的，并且在其生命周期内不会改变，但不可能事先具体知道。在接近较大端的情​​况下，我可能有多达 160 个输入（尽管在特殊情况下，理论上可能更多），而最小情况为 7。（这是使用根据每个包含 x 值的数据样本计算出的统计数据的结果，具体来说 7x + 1_ {x &gt; 1} * (x^2 - x)  统计。我不能只使用长度为 x 的样本，因为我对数据的统计行为感兴趣我打算使用这些统计数据来预测单个通过/失败布尔值，使用简单的“基本”前馈层序列。我当前的计划是使用 3 个隐藏层层，随着我们在网络中的进展，层数会变得更小。假设单元的数量以某种有用的方式取决于输入大小，我认为这应该足够强大，足以接近 UFE。 但是，我缺乏将神经网络用于像这样的非常大的输入向量的经验，所以我想问是否有人发现我可能忽略的任何明显问题（性能除外）。任何其他想法也将受到欢迎。   由   提交 /u/Rhoderick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1947k0t/intuition_regarding_ffnns_with_very_large_input/</guid>
      <pubDate>Thu, 11 Jan 2024 17:43:25 GMT</pubDate>
    </item>
    <item>
      <title>有哪些项目可以在本地运行？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1946yh0/what_are_some_projects_that_can_run_locally/</link>
      <description><![CDATA[我发现的大多数是图像生成器。还有其他有趣的项目吗？ （例如视频或音频相关、文本聊天等）   由   提交/u/sdw23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1946yh0/what_are_some_projects_that_can_run_locally/</guid>
      <pubDate>Thu, 11 Jan 2024 17:19:57 GMT</pubDate>
    </item>
    <item>
      <title>您通常如何交付您的 OSS 应用程序以便其他人可以使用它们？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1944p2x/how_do_you_normally_ship_your_oss_apps_so_that/</link>
      <description><![CDATA[如果您正在开发具有多个移动组件的东西，您如何为最终用户打包和交付坑？    由   提交 /u/hopeirememberthisid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1944p2x/how_do_you_normally_ship_your_oss_apps_so_that/</guid>
      <pubDate>Thu, 11 Jan 2024 15:45:00 GMT</pubDate>
    </item>
    <item>
      <title>获得 RL、CV、NLP 博士学位后我可以在哪里工作？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19449vy/where_can_i_work_after_finish_a_phd_in_rl_vs_cv/</link>
      <description><![CDATA[ 由   提交 /u/Trevorego   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19449vy/where_can_i_work_after_finish_a_phd_in_rl_vs_cv/</guid>
      <pubDate>Thu, 11 Jan 2024 15:27:00 GMT</pubDate>
    </item>
    <item>
      <title>ML 应用程序中使用了多少高级 Python？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1943k7c/how_much_advanced_python_is_used_in_ml/</link>
      <description><![CDATA[机器学习对高级 Python 功能（例如多重继承、记忆、在 super() 内传递参数等）的重视程度如何？  我对基础中级（包括简单的 OOP 和函数式编程）Python 非常熟悉，但对上一段提到的更高级的概念不太熟悉。我还需要了解这些吗？   由   提交 /u/datashri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1943k7c/how_much_advanced_python_is_used_in_ml/</guid>
      <pubDate>Thu, 11 Jan 2024 14:55:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 VAE 过了一会儿就开始为每个输入生成一张图片？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1941qwj/why_does_my_vae_start_generating_one_pic_for/</link>
      <description><![CDATA[      在 3000 张猫脸图像上训练，7 层，编码器是 cnn，解码器是一个前馈（ik，它不是最优的，我只是还没有实现非池化层，而且它像这样工作得更好）这是 300 个 epoch 后的输出，但它与 100 个 epoch 中的输出没有那么不同..是这样的预期的？我可能在某个地方犯了错误吗？谢谢！ ​ https://preview.redd.it/dmvpk4gmbtbc1.jpg?width=64&amp;format=pjpg&amp;auto=webp&amp;s=1be8ad3a7dfd3e91236cb69ef7​​f7ea30d151befe   由   提交 /u/Mr__Weasels   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1941qwj/why_does_my_vae_start_generating_one_pic_for/</guid>
      <pubDate>Thu, 11 Jan 2024 13:30:19 GMT</pubDate>
    </item>
    <item>
      <title>多代理无人机仿真项目的专业知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1940w8a/expertise_for_multiagent_drone_simulation_project/</link>
      <description><![CDATA[您好， 我相信您会收到此消息。我目前正在从事一个涉及多代理无人机模拟的项目，我正在向这个受人尊敬的社区寻求指导和见解。 项目概述： 目标：开发一个分布式多代理无人机模拟展示跨设备的紧急群体行为（聚集、避障、寻求目标）。 寻求专业知识： 算法：针对稳健群体行为、避障的建议，以及目标寻求算法。 工具和目标搜索算法。框架：深入了解无人机模拟的首选工具或框架。 最佳实践：从类似项目经验丰富的人员那里获得行业最佳实践指南。 您的意见的意义： &gt; 我渴望与精通分布式系统、无人机模拟和人工智能工程的个人建立联系。 当我应对这个复杂的问题时，您的建议、建议或潜在的指导将是非常宝贵的。努力。 您可以如何贡献： 请通过评论或私信分享您的见解。 我愿意接受讨论，并感谢任何详细的经验或信息您可能提供的建议。 对于您提供的任何帮助，我表示衷心的感谢。让我们参与知识的协作交流，共同增强我们在这一领域的理解。感谢您的时间和考虑。   由   提交/u/Dry_Purple_3082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1940w8a/expertise_for_multiagent_drone_simulation_project/</guid>
      <pubDate>Thu, 11 Jan 2024 12:45:55 GMT</pubDate>
    </item>
    <item>
      <title>踏上人工智能之旅：寻求建议和见解</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/193zgju/embarking_on_an_ai_journey_seeking_advice_and/</link>
      <description><![CDATA[嘿 Reddit 社区👋 我将深入研究 AI 世界作为个人爱好，每天投入 2-3 小时。如果一切顺利，我的目标是最终启动一家科技初创公司。 NLP 和 Q Learning 引起了我的兴趣，我相信它们在人工智能的未来中发挥着关键作用（从神经科学中汲取灵感）。 计划投入十年来掌握这些领域，我很渴望针对潜在陷阱的清晰途径、估计和指导。在我看来，DeepMind 和 OpenAI 的工作强调了 NLP 和 Q Learning 在图像和音频处理等领域的重要性。 您有什么想法？您是否同意这个观点，或者您是否看到更好的替代方案？我愿意接受建设性的批评和对我可能偏离主题的见解。来！我们讨论一下！ 🚀   由   提交 /u/ImportantOwl2939   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/193zgju/embarking_on_an_ai_journey_seeking_advice_and/</guid>
      <pubDate>Thu, 11 Jan 2024 11:23:42 GMT</pubDate>
    </item>
    <item>
      <title>寻找将变压器应用于包含对象的地理空间地图的方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/193we90/finding_approaches_for_applying_a_transformer_to/</link>
      <description><![CDATA[我有一个多层地理空间地图（层数 x 高度 x 宽度），我想对其应用二维（或三维）维）位置编码并将其输入变压器。图层包含有关地图的信息以及有关地图上对象的详细信息。地图对象由需要从起点运输到终点的可移动对象和障碍物对象组成。我希望变压器能够在地图上构建最佳的移动轨迹。 我见过几种用于处理图像的变压器架构。不过，我想我还没有全部看过。您能推荐一下您认为最合适的架构吗？您能否建议一种合适的二维或三维位置编码方法？   由   提交/u/United-Sandwich-1965   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/193we90/finding_approaches_for_applying_a_transformer_to/</guid>
      <pubDate>Thu, 11 Jan 2024 07:56:14 GMT</pubDate>
    </item>
    <item>
      <title>这个损失曲线是否意味着我应该停止训练并优化我的数据集？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/193svt5/does_this_loss_curve_mean_i_should_stop_training/</link>
      <description><![CDATA[      我对创建自定义数据集相当陌生，并且已经看到大多数示例数据集的结果之前有一个很好的损失曲线。目前正在我的数据集上训练的这个模型看起来损失曲线并不乐观，但根据我所读到的内容，我不确定。 在所附的屏幕截图中，我目前位于Apple 的 CreateML 的迭代/纪元为 4951 次，共 12,000 次，损失为 40.417。我尝试训练的模型用于图像内的多对象检测。大约有 480 万张标记图像（真实数据和合成数据），因此这需要一段时间才能完成。此时已经运行超过 14 小时。就我而言，我发现损失随着时间的推移而减少，到最后一次迭代时可能会达到约 25%，但这可能不足以满足我的需求。 不过，我想要理解的是，当观察曲线时，什么是不值得继续训练的好例子？有哪些学习检查损失曲线的好资源？ ​ https://preview.redd.it/otfg9xw6rqbc1.png?width=1584&amp;format=png&amp;auto=webp&amp;s=dda4fcaf4818095d91 81666612a0ddd2e79b5bc4&lt; /p&gt;   由   提交/u/williammincy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/193svt5/does_this_loss_curve_mean_i_should_stop_training/</guid>
      <pubDate>Thu, 11 Jan 2024 04:25:10 GMT</pubDate>
    </item>
    </channel>
</rss>