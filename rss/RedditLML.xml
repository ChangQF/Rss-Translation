<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 28 Jan 2024 03:13:22 GMT</lastBuildDate>
    <item>
      <title>为什么反向传播不总是与 dropout 正则化一起教授。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acs9yx/why_isnt_backpropagation_always_taught_along_with/</link>
      <description><![CDATA[我最近了解了更多关于神经网络中 dropout 正则化的有效性，我不禁觉得 dropout 应该自然地与整个反向传播算法。有什么理由不这样吗？是否存在 dropout 正则化弊大于利的情况？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acs9yx/why_isnt_backpropagation_always_taught_along_with/</guid>
      <pubDate>Sun, 28 Jan 2024 02:46:54 GMT</pubDate>
    </item>
    <item>
      <title>了解 VAE 的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acqyiz/resources_to_understand_vaes/</link>
      <description><![CDATA[我“理解”VAE 是如何工作的，我已经阅读了很多关于它们的内容，但是当我尝试阅读原始论文时，我完全迷失了。我以为我有数学背景，但我很快意识到我没有。  您会推荐阅读哪些课程/书籍来理解该论文（以及其他生成模型论文，一般来说，我对生成模型论文有这个问题。）支撑它的数学超出了我的理解范围。    由   提交 /u/Ok_Seesaw5723   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acqyiz/resources_to_understand_vaes/</guid>
      <pubDate>Sun, 28 Jan 2024 01:39:23 GMT</pubDate>
    </item>
    <item>
      <title>如何抓住 AI 作弊：智胜机器人 - 2024 年版</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acov77/how_to_catch_aicheating_outsmart_the_bot_2024/</link>
      <description><![CDATA[&quot;如果您碰巧有任何不使用 ChatGPT 和其他人工智能 (AI) 作弊的学生，是时候了解情况了。根据民主与技术中心最近的一项调查，58% 的学生表示使用生成式人工智能来完成作业。随着人们对这项技术的认识不断提高，这个数字只会增加。与此同时，同一项研究报告称，教育工作者发现自己落后于技术曲线，只有 43% 的教师接受过生成人工智能方面的重要培训。  在本文中，我们将尝试为教育工作者提供所需的信息，以了解学生如何使用这项技术进行作弊以及教师如何检测和应对生成式人工智能。除了检测其使用之外，这项新技术还可能提供利用新的创新教育方式的机会。” https://ai-solutions.pro/tools-to-detect-ai-cheating/  &amp;# 32；由   提交/u/Science-man777  /u/Science-man777 reddit.com/r/learnmachinelearning/comments/1acov77/how_to_catch_aicheating_outsmart_the_bot_2024/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acov77/how_to_catch_aicheating_outsmart_the_bot_2024/</guid>
      <pubDate>Sat, 27 Jan 2024 23:58:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性回归模型的成本函数应用于逻辑回归时会给出非凸图或具有多个局部最小值的图？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acnyri/why_does_the_cost_function_of_a_linear_regression/</link>
      <description><![CDATA[ 由   提交/u/Professional_Path552   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acnyri/why_does_the_cost_function_of_a_linear_regression/</guid>
      <pubDate>Sat, 27 Jan 2024 23:18:01 GMT</pubDate>
    </item>
    <item>
      <title>机器学习工程师面临的最头疼和烦人的事情是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acmunb/what_are_the_biggest_headaches_and_annoying/</link>
      <description><![CDATA[我是一位非常新的机器学习工程师，我有兴趣了解更多有关机器学习工程师日常解决的问题以及一些问题的信息他们必须解决的最困难的问题，我很乐意听到与任何阶段相关的问题，例如构建模型、训练、部署等。 提前致谢！！ &lt; /div&gt;  由   提交/u/jaym-00   /u/jaym-00  reddit.com/r/learnmachinelearning/comments/1acmunb/what_are_the_biggest_headaches_and_annoying/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acmunb/what_are_the_biggest_headaches_and_annoying/</guid>
      <pubDate>Sat, 27 Jan 2024 22:29:14 GMT</pubDate>
    </item>
    <item>
      <title>关于 Huggingface 中的 GPT-1 的问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aclizm/questions_about_gpt1_in_huggingface/</link>
      <description><![CDATA[大家好，目前我正在学习法学硕士，我有几个菜鸟问题。 首先，让我们从GPT-1 论文：https://cdn.openai.com/research-covers/language- unsupervised/language_understand_paper.pdf 问题 1：嵌入步骤的输入到底是什么形状？ 让我们看一下表达式论文中的块（2）。 根据论文，模型的输入被命名为U。从我到目前为止收集到的信息来看，这些应该是第一个标记化步骤之后的 token_id。然而，我对这里的维度如何运作有点困惑。嵌入矩阵 W_e 应该是一个维度为 N x H 的矩阵，其中 N 是该分词器所有可能的分词 ID 的总数，H 是转换器块中隐藏层的维度。所以基本上 W_e 是一个查找表，其中每一行对应于该令牌 id 的嵌入。 W_e 应该工作的方式是，您采用令牌 id 的单热编码表示并将其相乘以选择适当的行。 所以我有点困惑论文中的乘法是如何运作的。我理解它计算矩阵 U 的方式应该包含每个 token_id 作为 one-hot 编码行。换句话说，矩阵应如下所示： 第一行 = U_{1,:} = [ 0 , 0 , ... 1 , 0 , 0 ...] 第二行 = U_{2,:} = [ 0 , 1 ,0 , .. 0 ] 等等。其中 1 的列索引对应于该令牌的令牌 id 的值。  这是正确的吗？然后我觉得论文中有点不清楚。他们只是写 U= (u1, u2, ...) 就这样了。如果我的理解是正确的，有人可以证实这一点吗？ 问题 2： 这一步发生在 HuggingFace 模型中的哪里？ &lt; p&gt;所以假设之前的解释是正确的，我尝试在 HuggingFace 中调用模型。考虑以下代码片段： from Transformers import OpenAIGPTTokenizer, OpenAIGPTModel import torch tokenizer = OpenAIGPTTokenizer.from_pretrained(“openai-gpt”) model = OpenAIGPTModel.from_pretrained(“openai-gpt”) input = tokenizer(&quot;你好，我的狗很可爱&quot;, return_tensors=&quot;pt&quot;) print(f&quot;输入：{输入}&quot;) 输出 =model(**输入) print(f&quot;输出：{输出}&quot; ;)  它返回： 输入：{&#39;input_ids&#39;：tensor([[3570, 240, 547, 2585, 544, 4957]] ), &#39;attention_mask&#39;: 张量([[1, 1, 1, 1, 1, 1]])} 输出: BaseModelOutput(last_hidden_​​state=tensor([[[ 0.4653, 0.0642, 0.5910, ..., 0.1177, -0.0021 , -1.2262], [-0.3697, -0.0957, 0.6613, ..., -0.0344, -0.2164, 0.1205], [ 0.1700, -0.3252, 0.0407, ..., 0.1589, -0.8057, -0.2830], [- 0.3669, -0.0448, 0.8061, ..., -0.0090, -0.0872, -0.5224], [-0.5047, 0.6522, 0.6932, ..., 0.0811, 0.6475, 0.3190], [-0.2972, 0.0591, 1.2 333、.. ., -0.7394, -0.2600, 0.0863]]], grad_fn=),hidden_​​states=None, Attentions=None)  因此，这里的实际输入似乎是model 只是 token id tensor([[3570, 240, 547, 2585, 544, 4957]]) 的单个张量，尚未采用适当的 one-hot 编码形式 U.任何人都可以确认这是否首先发生在模型内部，然后再乘以嵌入矩阵吗？ 问题 3： 该怎么办与这个“last_hidden_​​state”的输出？ 所以，按照我的理解，这里的输出实际上是最后一个变压器块“h_n”。它的维度为 (1, 6 , 768) - 所以基本上对于每个输入标记，我得到长度为 768 的隐藏最终状态。 那么如果我想用它做某事，现在如何使用这个结果？如果不训练单独的分类器，我对这个最终状态无能为力。 ​   由   提交/u/Invariant_apple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aclizm/questions_about_gpt1_in_huggingface/</guid>
      <pubDate>Sat, 27 Jan 2024 21:30:06 GMT</pubDate>
    </item>
    <item>
      <title>关于实验设计的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acli33/question_about_experimental_design/</link>
      <description><![CDATA[大家好， 在我的项目中，我评估了 4 个模型（xgboost、随机森林、svm 和 mlp）与 2 个模型源自同一数据集的特征工程数据集。我使用 AUC 指标进行超参数优化。  我想最终报告 4 个模型的平均 AUC 之间的统计显着性，以及模型组之间在所选特征数据集级别上的统计显着性。可能使用 t 检验或 F 检验。  现在由于问题与时间序列问题有关，因此我的测试集已修复，即最近 20% 的数据。因此，我不会通过交叉验证等方式生成分数样本来测试其显着性。我在参数优化期间确实使用交叉验证，但仅使用我的训练集。  我希望收到一些关于这种实验方法的反馈，以及我如何仍然可以测试显着性，而不是简单地报告测试集分数。我感到困惑的原因是我认为简单地报告测试集分数会忽略模型方差，并且我想解释这一点。  也许这是通过训练集上的交叉验证来解释的（？），但我不太确定。    ;由   提交 /u/JanBitesTheDust   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acli33/question_about_experimental_design/</guid>
      <pubDate>Sat, 27 Jan 2024 21:28:26 GMT</pubDate>
    </item>
    <item>
      <title>基本问题，但我对验证数据与测试数据感到困惑</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aclh12/basic_question_but_im_confused_by_validation_data/</link>
      <description><![CDATA[&quot;&quot;&quot; 接下来，拟合模型用于预测第二个数据集中观测值的响应，该数据集称为验证数据集。[3] 验证数据集提供对模型在训练数据集上的拟合度的公正评估，同时调整模型的超级参数)[5]（例如，神经网络中隐藏单元的数量（层数和层宽度）网络[4]）。 ... 最后，测试数据集是用于对训练数据集上的最终模型拟合度进行公正评估的数据集。 “” &quot; [来自维基百科] 首先，是一个过程，尝试许多不同的超参数，在同一训练集上训练所有这些变体，并选择验证准确度最高的模型在这种情况下，我很困惑为什么我们需要验证集和测试集，验证数据集不足以表明模型的性能吗？    由   提交/u/BenAhmed23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aclh12/basic_question_but_im_confused_by_validation_data/</guid>
      <pubDate>Sat, 27 Jan 2024 21:26:43 GMT</pubDate>
    </item>
    <item>
      <title>TorToiSe 的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acldyu/issue_with_tortoise/</link>
      <description><![CDATA[嗨！首先，如果这不是发布此内容的正确 subreddit，我想表示歉意。关于这个主题，我尝试使用 TorToiSe 进行逼真的 TTS，但是当听最终结果时，它们听起来与我给出的源剪辑完全不同。我尝试用我的设置复制用于导出 Tom 示例音频的音频的设置，但 AI 的结果似乎与源音频相去甚远。感谢您的阅读+感谢所有帮助！ https://preview.redd.it/2ap7igw1v1fc1.png?width=1637&amp;format=png&amp;auto=webp&amp;s=bee37c90d7b37c9935a4175f4c79f871fd618d13   由   提交 /u/BusyMushroom9975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acldyu/issue_with_tortoise/</guid>
      <pubDate>Sat, 27 Jan 2024 21:22:45 GMT</pubDate>
    </item>
    <item>
      <title>有人想结伴一起阅读 PRML 书吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ackdl1/anyone_wanna_form_a_pair_to_jointly_read_the_prml/</link>
      <description><![CDATA[我很久以前就计划阅读 PRML 这本书，但从未正确阅读过 -- 主要是因为我没有人讨论我读到的内容这本书。因此，我想在这里询问是否有人愿意结伴共同阅读这本书。 致管理员：我之前已经在这里发布过，但没有得到回复——只有反对票。我最后一次再试一次——如果没有得到任何答复，我就会停止。   由   提交 /u/pailkedv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ackdl1/anyone_wanna_form_a_pair_to_jointly_read_the_prml/</guid>
      <pubDate>Sat, 27 Jan 2024 20:38:30 GMT</pubDate>
    </item>
    <item>
      <title>深度学习小书（François Fleuret，2023 年 6 月 23 日，168 页）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acj92q/the_little_book_of_deep_learning_françois_fleuret/</link>
      <description><![CDATA[      PDF 链接：https://fleuret.org/public/lbdl.pdf 主页：https://fleuret.org/francois/lbdl.html “本书是为具有 STEM 背景的读者提供的关于深度学习的简短介绍，最初旨在在手机屏幕上阅读。它根据非商业知识共享许可证分发，八个月内下载了 500,000 次。 ＆quot; https://preview .redd.it/pspdw9ohe1fc1.jpg?width=1683&amp;format=pjpg&amp;auto=webp&amp;s=e06166fae2656bda007a160f775f7567ac9aaea4   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acj92q/the_little_book_of_deep_learning_françois_fleuret/</guid>
      <pubDate>Sat, 27 Jan 2024 19:49:40 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络中存在“特征稀释”吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acfyuy/is_feature_dilution_a_thing_in_deep_neural/</link>
      <description><![CDATA[我一直在努力应对与数据集成和多模式神经网络相关的挑战，我希望得到您的见解。场景如下：我有一个包含多种类型特征的特征矩阵，包括 0 到 1 范围内的 5 个连续变量。此外，我将一个 1024 维的嵌入向量连接到同一个特征矩阵中，其中嵌入值为也是连续的。 我担心的是高维嵌入特征的存在是否会削弱原始 5 个连续变量的效果或重要性。这是一种公认​​的现象吗？如果是，如何解决或对抗这种潜在的稀释效应？ 我很欣赏有关此主题的相关文献的任何指导或参考。预先感谢您的专业知识！   由   提交 /u/Primary-Wasabi292    reddit.com/r/learnmachinelearning/comments/1acfyuy/is_feature_dilution_a_thing_in_deep_neural/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acfyuy/is_feature_dilution_a_thing_in_deep_neural/</guid>
      <pubDate>Sat, 27 Jan 2024 17:27:01 GMT</pubDate>
    </item>
    <item>
      <title>免费数学重机器学习/人工智能课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1acaxty/free_math_heavy_machine_learningai_courses/</link>
      <description><![CDATA[我已完成 Andrew Ng 的机器学习“专业化”课程。共有三门独立的课程：  监督机器学习 高级学习算法 无监督机器学习  我对他在课程中介绍的数学感到非常惊讶（不同的回归、梯度下降、不同的激活函数、归一化、正则化、算法的变化等），对于那些不熟悉数学的人来说，其中的一部分也是可选的因为喜欢这个话题。完成本专业课程后，我渴望另一门类似的课程，它可能会涉及其他领域，或者相同的领域但更深入？ 如有任何建议，我们将不胜感激：D   由   提交/u/Guava-Java-  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1acaxty/free_math_heavy_machine_learningai_courses/</guid>
      <pubDate>Sat, 27 Jan 2024 13:33:59 GMT</pubDate>
    </item>
    <item>
      <title>试图让 GA 生成类似于数字 7 的 MNIST 图像，这个想法注定要失败吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aca14i/trying_to_get_a_ga_to_generate_mnist_like_images/</link>
      <description><![CDATA[大家好，我创建了一个适用于 28x28 二进制矩阵和 MNIST 数字分类器的遗传算法模型，我将 GA 适应度函数调整为依赖于MNIST 分类器给出的矩阵为 #7 的概率。我还没有看到人们在网上做类似的事情，并且由于训练时间很长并且摆弄超参数，算法没有收敛 - 这个想法可行吗？为什么/为什么不呢？  可以提供代码。 （还要注意的是，我应用了高斯模糊和 0-&gt;0、1-&gt;255 的映射来将二进制转换为灰度。）    ;由   提交 /u/Few-Fun3008    reddit.com/r/learnmachinelearning/comments/1aca14i/trying_to_get_a_ga_to_generate_mnist_like_images/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aca14i/trying_to_get_a_ga_to_generate_mnist_like_images/</guid>
      <pubDate>Sat, 27 Jan 2024 12:42:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工神经网络在训练时在验证数据上表现得更好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac0c6a/why_does_the_ann_perform_so_much_better_on_the/</link>
      <description><![CDATA[   /u/HoleNother  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac0c6a/why_does_the_ann_perform_so_much_better_on_the/</guid>
      <pubDate>Sat, 27 Jan 2024 02:41:41 GMT</pubDate>
    </item>
    </channel>
</rss>