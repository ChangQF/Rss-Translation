<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 15 Jul 2024 03:19:03 GMT</lastBuildDate>
    <item>
      <title>我该如何使用 NN 制作国际象棋引擎？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e3kdqz/how_would_i_go_about_making_a_chess_engine_using/</link>
      <description><![CDATA[我对神经网络和机器学习还很陌生，一般来说，我已经成功地从头开始制作了一个神经网络，可以教会代理找出通往食物的方向（它有点用）。然后，我想到了一个问题，即如何使用神经网络制作国际象棋引擎。我得到的一个意见是计算给定棋盘状态下所有可能的动作，并根据网络输出的等级模拟每场比赛。这听起来计算成本很高，我发现的另一种方法是以某种符号或格式输入许多现实世界的国际象棋游戏数据。这可能是一个特定的棋盘状态，然后是变化，神经网络可能会使用梯度下降之类的方法，根据许多国际象棋比赛中的许多棋盘状态来调整权重和偏差。这是我对制作国际象棋引擎的描述，我知道它可能是错的，所以（请纠正我），是的，我只是在探索这个领域，也是我喜欢问的一个问题..    提交人    /u/Alex6683   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e3kdqz/how_would_i_go_about_making_a_chess_engine_using/</guid>
      <pubDate>Mon, 15 Jul 2024 02:58:47 GMT</pubDate>
    </item>
    <item>
      <title>Pluralsight 上最好的机器学习课程（从初学者到高级）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e3i96j/best_machine_learning_courses_on_pluralsight/</link>
      <description><![CDATA[  由    /u/Sreeravan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e3i96j/best_machine_learning_courses_on_pluralsight/</guid>
      <pubDate>Mon, 15 Jul 2024 01:09:38 GMT</pubDate>
    </item>
    <item>
      <title>我是不是做错了什么，也许我只是个新手，但为什么我的损失一点也没有减少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e3ha0t/am_i_doing_something_wrong_maybe_im_just_a_noob/</link>
      <description><![CDATA[我是不是做错了什么，也许我只是个菜鸟，但为什么我的损失一点都没有减少呢？ https://colab.research.google.com/drive/1gKl1jetrdNoMU5Brwbz6DFh20BfW6udT?usp=sharing 它出现在我跟随的这个家伙的教程中 https://youtu.be/Z_ikDlimN6A?t=25600    提交人    /u/Standard_A1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e3ha0t/am_i_doing_something_wrong_maybe_im_just_a_noob/</guid>
      <pubDate>Mon, 15 Jul 2024 00:21:47 GMT</pubDate>
    </item>
    <item>
      <title>妈妈寻求建议。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e3e8ov/mom_looking_for_advice/</link>
      <description><![CDATA[我是一个 37 岁的寡妇，有一个 14 岁的儿子。我的丈夫 6 个月前因肝癌去世。他从量化交易员岗位上退休，放弃了在苏黎世联邦理工学院的数学博士学位，开始从事这个职业。我们目前住在纽约，但我的儿子和他已故的父亲都是瑞士公民。我的儿子希望去欧洲读大学，特别是去他表弟就读的奥地利，或者去他的祖国瑞士。 钱对我来说不是问题，我愿意给他他需要的一切。昨晚睡觉前，我儿子说妈妈，我没有人可以说话，你能跟我谈谈吗？我说怎么了。他说，妈妈，我希望爸爸在这里。没有人指导我。带你去哪里？当我问他需要什么具体指导时，他说他想学习机器学习，但没有人指导他，他非常希望爸爸在这里。 这些话让我整夜无法入睡，我在网上搜索指导，但没有找到任何可以帮助他的东西。 我的儿子有很强的数学天赋。非常喜欢数学。他的父亲从很小的时候就开始教他微积分、三角学和代数。我查看了他的 Coursera 帐户，发现他已经完成了 6 门 Python 课程。他让我在 Coursera 上购买神经网络和深度学习课程，我很快就买了。此外，他还完成了 Udemy 上的“从零到精通”Web 开发课程。 作为一个缺乏这些技术领域知识的母亲，我不知道如何正确地指导他。我相信他父亲的去世极大地影响了他的动力，他想做一些与医学尤其是癌症有关的事情。我寻求关于如何最好地支持他的建议和意见。我是个愚蠢的妈妈，只想支持我的儿子。 我们可能会搬到欧洲接受他的大学教育，因为他不满足于住在这里。    提交人    /u/Throwawaynn98637   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e3e8ov/mom_looking_for_advice/</guid>
      <pubDate>Sun, 14 Jul 2024 22:04:37 GMT</pubDate>
    </item>
    <item>
      <title>努力理解分类交叉熵</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e3c21l/struggling_to_understand_categorical_crossentropy/</link>
      <description><![CDATA[因此，我正在学习 Sentdex 编写的《从头开始的神经网络》，刚刚完成了第 7 部分关于交叉熵的内容。我一直在努力理解它在数学上是如何运作的。我理解损失函数是什么，在做了一些研究后，我对熵有了基本的了解（这个视频很有帮助），但使用交叉熵作为损失函数对我来说还没有触动。我想我可能需要退一步。  如果你们能提供任何资源或解释就太好了，谢谢     提交人    /u/remerdy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e3c21l/struggling_to_understand_categorical_crossentropy/</guid>
      <pubDate>Sun, 14 Jul 2024 20:32:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获得具有产品知识的法学硕士学位</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e37nz5/d_building_a_llm_with_product_knowledge/</link>
      <description><![CDATA[我有一个相对复杂的 SaaS，其中包含一些经典的最终用户文档和培训视频。 这两种形式的媒体都缺乏内容。  我很好奇是否有一种方法可以以交互方式（与其聊天）培训 LLM，我可以逐步向 LLM 教授有关此软件产品的所有知识，以便最终将其用作我的助手，例如： - 回答支持问题 - 构建用户指南 - 创建营销指南 - 等等  我是一名软件工程师，但对 AI 技术还不太熟悉。  我的平台在 Azure 中，因此最好利用 Azure 中的认知资源。  欢迎提供任何提示/想法。     提交人    /u/deplorablehuddy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e37nz5/d_building_a_llm_with_product_knowledge/</guid>
      <pubDate>Sun, 14 Jul 2024 17:18:46 GMT</pubDate>
    </item>
    <item>
      <title>深度学习的学习路径</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e377mv/learning_path_for_deep_learning/</link>
      <description><![CDATA[我几乎完成了 andrew ng 的机器学习专业化课程，并且已经为我的学习目的开发了一些简单的模型。完成本课程后，我应该继续学习 andrew ng 的深度学习专业化课程，还是应该参加深度学习的快速人工智能课程？    提交人    /u/Fun-Imagination8755   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e377mv/learning_path_for_deep_learning/</guid>
      <pubDate>Sun, 14 Jul 2024 17:00:24 GMT</pubDate>
    </item>
    <item>
      <title>10 倍交叉验证误差</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e371nm/10_fold_cross_validation_error/</link>
      <description><![CDATA[我正在尝试对数据集进行交叉验证，但是它显示以下错误，请帮我找出原因。 ValueError:  所有 10 次拟合均失败。 很可能是您的模型配置错误。 您可以尝试通过设置 error_score=&#39;raise&#39; 来调试错误。 以下是有关失败的更多详细信息：  9 次拟合失败，出现以下错误： 回溯（最近一次调用）： 文件“C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py”，第 895 行，位于 _fit_and_score estimator.fit(X_train, y_train, **fit_params) 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\base.py&quot;，第 1474 行，在包装器中 返回 fit_method(estimator, *args, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\svm\_base.py&quot;，第 190 行，在 fit 中 X, y = self._validate_data( ^^^^^^^^^^^^^^^^^^^^^^ 文件&quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\base.py&quot;，第 650 行，在 _validate_data 中 X, y = check_X_y(X, y, **check_params) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\validation.py&quot;，第 1263 行，在 check_X_y 中 X = check_array( ^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\validation.py&quot;，第997，在 check_array 中 array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\_array_api.py&quot;，第 521 行，在 _asarray_with_order 中 array = numpy.asarray(array, order=order, dtype=dtype) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\pandas\core\generic.py&quot;，第 2153 行，位于 __array__ arr = np.asarray(values, dtype=dtype) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ValueError: 无法将字符串转换为浮点数：&#39;MOTHER&#39;  1 次拟合失败，出现以下错误： 回溯（最近一次调用最后一次）： 文件&quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py&quot;，第 895 行，在 _fit_and_score 中 estimator.fit(X_train, y_train, **fit_params) 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\base.py&quot;，第 1474 行，在包装器中 return fit_method(estimator, *args, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件&quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\svm\_base.py&quot;，第 190 行，在 fit 中 X, y = self._validate_data( ^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\base.py&quot;，第 650 行，在 _validate_data 中 X, y = check_X_y(X, y, **check_params) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件&quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\validation.py&quot;，第 1263 行，在 check_X_y 中 X = check_array( ^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\validation.py&quot;，第 997 行，在 check_array 中 array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\sklearn\utils\_array_api.py&quot;，第 521 行，在 _asarray_with_order 中 array = numpy.asarray(array, order=order, dtype=dtype) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;C:\Users\megaa\anaconda3\Lib\site-packages\pandas\core\generic.py&quot;，第 2153 行，在 __array__ 中 arr = np.asarray(values, dtype=dtype) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ValueError：无法将字符串转换为浮点数：&#39;BROTHER&#39;    提交人    /u/Unfair-Actuator3088   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e371nm/10_fold_cross_validation_error/</guid>
      <pubDate>Sun, 14 Jul 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>训练渐进式 GAN 保持稳定，直到不再稳定</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e35f8g/training_progressive_gan_stable_until_its_not/</link>
      <description><![CDATA[嗨， 我正在训练 PGGAN，输出的图像很稳定，渐进式增长似乎进展顺利。也就是说，直到我到达第 4 层，在引入第四层后不久，生成器就开始输出 NaN 值，并且 NaN 出现在模型参数中。问题是 NaN 出现在之前训练的层中（NaN 出现的位置并不总是确定的）。 我有一些调试输出，但不知道为什么会发生这种情况。有人能给出建议吗？ （即使是关于应该看什么的一般建议也会有所帮助！） 迭代 628，第 4 层 - D 损失：94.89959217607975，梯度惩罚：7.816425678087398  梯度范数 - D：7.010403156280518，G：nan  迭代 628，第 4 层 - G 损失：242.10931265354156  剪辑后的梯度范数，G：nan  在生成器参数中检测到 NaN：input_layer.0.conv.bias 在生成器参数中检测到 NaN：input_layer.0.conv.weight_orig  在生成器参数中检测到 NaN： block_4x4.layers.0.conv.bias  在生成器参数中检测到 NaN：block_4x4.layers.0.conv.weight_orig 在生成器参数中检测到 NaN：block_4x4.layers.3.conv.bias 在生成器参数中检测到 NaN：block_4x4.layers.3.conv.weight_orig    提交人    /u/throwaway16362718383   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e35f8g/training_progressive_gan_stable_until_its_not/</guid>
      <pubDate>Sun, 14 Jul 2024 15:45:19 GMT</pubDate>
    </item>
    <item>
      <title>我想设计推荐系统。你推荐什么课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e311hz/i_want_to_design_recommender_systems_what_course/</link>
      <description><![CDATA[明尼苏达大学 Coursera 有一个推荐专家课程。该课程评分为 4.4（共 700 条评论）。你们有人上过这个课程吗？    提交人    /u/appman1138   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e311hz/i_want_to_design_recommender_systems_what_course/</guid>
      <pubDate>Sun, 14 Jul 2024 12:24:23 GMT</pubDate>
    </item>
    <item>
      <title>计算调整后的 r^2</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e30ozh/calculating_adjusted_r2/</link>
      <description><![CDATA[我有以下代码，我正在尝试计算调整后的 R^2。我可以计算 r^2，但不知道调整后的 r^2 的 n 和 p 值应该是多少。  p 是特征选择之前还是之后特征集中的列数，我如何获取它？ n 是训练数据还是测试数据中的行数？ 注意：我还没有确定调整后的 r^2 的 n 和 p，因为我不确定 这是我的代码： import numpy as np import pandas as pd from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split target_data = pd.read_csv(&#39;Cleaned data.csv&#39;, sep=&#39;,&#39;).head(1000)[&#39;Standard Value&#39;] features = pd.read_csv(&#39;features.csv&#39;, sep=&#39;,&#39;).head(1000) training_features, testing_features, training_target, testing_target = \ train_test_split(features, target_data, random_state=42) exports_pipeline = RandomForestRegressor(bootstrap=True, max_features=0.7500000000000001, min_samples_leaf=11, min_samples_split=9, n_estimators=100) exports_pipeline.fit(training_features, training_target) results = exports_pipeline.predict(testing_features) r2 = exports_pipeline.score(testing_features, testing_target) adj_R2 = 1- ((1-r2) * (n-1)/(n-p-1)) #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1) print(r2)     由   提交  /u/Legitimate_Trade_285   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e30ozh/calculating_adjusted_r2/</guid>
      <pubDate>Sun, 14 Jul 2024 12:05:00 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院机器学习研究生教授机器学习和深度学习（免费）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e2z1ap/mit_machine_learning_graduate_teaches_machine/</link>
      <description><![CDATA[      我相信任何人都可以转型到机器学习，只要他们决定这样做。 在过去的 3 个月里，我开始了一个教授机器学习和深度学习的项目。 我录制了 70 个机器学习和深度学习的视频。 每天，我都会编写脚本、录制和编辑 1 个视频，大约持续 6-7 个小时。结果是 2 个庞大的播放列表。 1️⃣ 机器学习边做边教播放列表： (a) 涵盖的主题：回归、分类、神经网络、卷积神经网络 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） (d) 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSi-nLQ4XV2Mds8Z7bihK68L 2️⃣ 从头开始​​的神经网络播放列表： (a) 涵盖的主题：神经网络架构、前向传递、后向传递、优化器。完全用 Python 从头开始​​编码。没有 Pytorch。没有 Tensorflow。只有 Numpy。 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSj6tNyn_UadmUeU3Q3oR-hu 附注：讲师背景：我毕业于麻省理工学院，获得机器学习博士学位。视频详细展示了我的笔记。 https://i.redd.it/tjxybbqyngcd1.gif    submitted by    /u/OtherRaisin3426   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e2z1ap/mit_machine_learning_graduate_teaches_machine/</guid>
      <pubDate>Sun, 14 Jul 2024 10:25:11 GMT</pubDate>
    </item>
    <item>
      <title>我计算输入层和隐藏层之间的权重的方式有什么错误？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e2xx7j/what_is_wrong_with_how_i_calculate_the_weights/</link>
      <description><![CDATA[我说这些权重有问题，因为当我注释掉更新这些权重的行时，NN 实现了约 80% 的准确率，但是当我保留它时，NN 会得到约 10% 的准确率，也就是随机的。  提前感谢任何帮助！ 这是代码： import numpy as np import pandas as pd class NeuralNetwork(): def __init__(self): self.trainData: np.array = np.array(pd.read_csv(&#39;mnist_train.csv&#39;)) self.testData: np.array = np.array(pd.read_csv(&#39;mnist_test.csv&#39;)) self.LR = 0.1 inputNeuronCount = 784 # 28 x 28 像素 hiddenNeuronCount = 64 outputNeuronCount = 10 # 0 -&gt; 9 # 权重和偏差用 -0.5 和 10 之间的随机值初始化0.5 self.weights：np.array = np.random.rand（inputNeuronCount，hiddenNeuronCount）-0.5 self.outputWeights：np.array = np.random.rand（hiddenNeuronCount，outputNeuronCount）-0.5 self.biases：list [np.array] = np.random.rand（hiddenNeuronCount）-0.5 self.outputBiases：list [np.array] = np.random.rand（outputNeuronCount）-0.5 def linearRegression（self，dataset）：lossValues = [] correctCount = 0 invalidCount = 0 for i，data in enumerate（dataset）：real：int = data [0] data：np.array = data [1：] / 255.0 prediction，outputLayer，activatedLayer，unactivatedLayer = self.forwardPass(data) if prediction == real: correctCount+=1 # print(f&quot;猜对了 ({prediction})，还不错！&quot;) else: invalidCount+=1 # print(f&quot;这东西肯定是坏的，pred 是 {prediction}，real 是 {real}，哈哈&quot;) loss, newWeights, newBiases, newOutputWeights, newOutputBiases = self.backPropagate(real, outputLayer, activatedLayer, unactivatedLayer, data) lossValues.append(loss) if i % 1000 == 0: print(f&quot;Loss 是 {loss}，accuracy 是 {round(correctCount/(correctCount+incorrectCount), 5)}&quot;) # self.weights = self.weights - (self.LR * newWeights.T) self.biases = self.biases - (self.LR * newBiases.T) self.outputWeights = self.outputWeights - (self.LR * newOutputWeights.T) self.outputBiases = self.outputBiases - (self.LR * newOutputBiases.T) def forwardPass(self, data): # print(f&quot;数据形状：{data.shape}\n权重形状：{self.weights.shape}&quot;) unactivated = data.dot(self.weights) #+ self.biases # 未激活的隐藏层 activated = self.ReLU(unactivated) # 激活的隐藏层 output = activated.dot(self.outputWeights) normalizedOutput = self.softmax(output) prediction = np.argmax(normalizedOutput) return prediction, normalizedOutput, activated, unactivated def ReLU(self, unactivatedLayer): return np.maximum(0, unactivatedLayer) def derivReLU(self, value): if value &gt;= 0: 返回 1 else: 返回 0 def getDerivReLUArray(self, layer): returnLayer = np.zeros_like(layer) for i, element in enumerate(layer): returnLayer[i] = element return returnLayer # 在 0 和 1 之间归一化的置信度值 def softmax(self, outputLayer): exp_values = np.exp(outputLayer - np.max(outputLayer)) # 防止溢出 return exp_values / np.sum(exp_values) def backPropagate(self, real, outputLayer, activatedLayer, unactivatedLayer, inputLayer): loss: int = self.getLoss(outputLayer[real]) oneHot: np.array = self.createOneHot(real) deltaOutput: np.array = outputLayer - oneHot activatedLayer = activatedLayer.reshape(1, -1) # 重塑为 (1, 64) newOutputWeights = deltaOutput.reshape(-1, 1) @ activatedLayer # 矩阵乘法，创建一个 (10, 64) 数组 newOutputBiases = deltaOutput derivReLUArray = self.getDerivReLUArray(unactivatedLayer) temp = newOutputWeights.T.dot(deltaOutput) deltaHidden = temp * derivReLUArray # 隐藏的误差项 inputLayer = inputLayer.reshape(1, -1) deltaHidden = deltaHidden.reshape(-1, 1) newWeights = deltaHidden @ inputLayer newBiases = deltaHidden return loss, newWeights, newBiases, newOutputWeights, newOutputBiases def createOneHot(self, real): oneHotList = np.zeros(10) oneHotList[real] = 1 return oneHotList def getLoss（self，realConfidenceValue）：如果 __name__ == &#39;__main__&#39;，则返回 -np.log（realConfidenceValue）：NN = NeuralNetwork（）NN.linearRegression（NN.trainData）    提交人    /u/SnazzySnail9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e2xx7j/what_is_wrong_with_how_i_calculate_the_weights/</guid>
      <pubDate>Sun, 14 Jul 2024 09:11:58 GMT</pubDate>
    </item>
    <item>
      <title>用于人工智能开发的 3D 联想思维网络提案</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e2tjge/proposal_for_a_3d_associative_mental_web_for_ai/</link>
      <description><![CDATA[      主题：用于 AI 开发的 3D 联想思维网络提案 我写这篇文章是为了分享一个可以显著增强 AI 开发和思维过程的概念。我的想法围绕着创建一个 3D 联想思维网络，通过以网络格式链接图像、想法和概念来模仿人类认知。 例如，在一个大的 3D 空间中，第一个图像将是链接到 3D 图元的 2D 几何图元。每个链接的图像都会有一个“让我想起”的关联，最终形成一个由 3D 对象、声音和可能的视频剪辑组成的庞大互连网络。 例如，球体可能会“让我想起”苹果，而苹果又会“让我想起”人类的大脑会从亚当的苹果开始，然后是亚当和夏娃的画作，然后是米开朗基罗这个词，接着是忍者神龟米开朗基罗的视频片段和其主题曲，最后是岩石上的乌龟的 3D 图像。节点会重叠，因为“苹果”可以有很多含义和联系。 人类以链接的图像思考，过渡到语音、声音和书面文字、字母和数字。在使用助记符时，我们会逆转这个过程，编码回 3D 图像或场景 - 将三个单词转换成首字母缩略词，将首字母缩略词转换成我们脑海中说出的短语，然后用代表首字母缩略词的符号可视化场景。 该模型可以改善人工智能处理信息的方式，从而推动各种应用的发展。我相信这个概念可以帮助开发一种更像人类思考和互动的人工智能。  潜在挑战：  实施复杂性：构建 3D 关联网络可能需要大量的计算资源和先进的算法。 数据输入需求：关联的准确映射将需要大量多样化的数据集进行训练。 类似人类的理解：确保人工智能以类似人类的方式浏览网络将需要持续的研究和改进。   Derek Van Derven    提交人    /u/ExpKey   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e2tjge/proposal_for_a_3d_associative_mental_web_for_ai/</guid>
      <pubDate>Sun, 14 Jul 2024 04:26:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>