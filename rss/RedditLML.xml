<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 29 Feb 2024 12:23:45 GMT</lastBuildDate>
    <item>
      <title>自然语言处理书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2z07k/nlp_books/</link>
      <description><![CDATA[有哪些值得深入研究的好书？我发现的一些评论较好的书似乎有点过时了。我最感兴趣的是使用 python 进行主题建模和文本摘要。提前致谢。   由   提交/u/_CaptainCooter_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2z07k/nlp_books/</guid>
      <pubDate>Thu, 29 Feb 2024 12:19:26 GMT</pubDate>
    </item>
    <item>
      <title>2024 年你必须知道的 8 门最佳金融机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2yxzx/8_best_machine_learning_courses_for_finance_you/</link>
      <description><![CDATA[   /u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2yxzx/8_best_machine_learning_courses_for_finance_you/</guid>
      <pubDate>Thu, 29 Feb 2024 12:15:58 GMT</pubDate>
    </item>
    <item>
      <title>文本分类 - 如何处理分组/分类数据？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2yomv/text_classification_how_do_i_deal_with/</link>
      <description><![CDATA[我有一个大型（约 170 万条记录）数据集，其中包含：  产品 ID - Int，大约 1200唯一值。 技术人员评论 - 4000 个字符的字段，通常包含 3-5 个短句子，描述项目的物理状况及其任何问题。每个产品 ID 中的问题描述往往是一致的（即，廉价扳手在扭矩作用下会弯曲，电钻会出现一种会发出灼烧痕迹的故障，等等）。针对每个特定产品，语言可能非常。 技术人员评分 - A、B、C、F，每个评分都有可能的 +/- 修饰符，总共 12 种可能得分值。  我的数据集中的产品 ID 分布不均匀。有几十个ID，约占总记录的一半。还有其他 ID 仅出现几次。 产品 ID 之上还有一个 2 层层次结构（认为工具 -&gt; 锤子 -&gt; 特定型号锤子），我可以将其包含在数据集中，但我已经在 1 级分组方面遇到了困难。 我希望能够“预测”基于他们撰写的评论的技术人员分数。 这似乎应该是一个非常简单的多类文本分类任务，但我什至不知道从什么开始搜索 用于处理产品 ID 方面。任何正确方向的指针将不胜感激。   由   提交/u/groovybrews  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2yomv/text_classification_how_do_i_deal_with/</guid>
      <pubDate>Thu, 29 Feb 2024 12:00:54 GMT</pubDate>
    </item>
    <item>
      <title>捕获时间戳数据之间的相互依赖性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2ynub/capturing_interdependencies_between_timestamps/</link>
      <description><![CDATA[嗨，我有一个巨大的数据集，其中有两个时间戳（基本上是某个事件的开始和结束）和发起事件的用户的用户 ID，这可能可以从某种意义上说，“一个事件经常发生在另一个事件之前、之后或同时发生”。我查了一下，有几个算法可以做到这一点，比如序列模式挖掘或隐藏马尔可夫模型。您能否向我推荐最好的一个，并提出一种“标准化”这些数据的方法？问题是时间序列不断增加（如何处理？），我需要捕获由不同或相同用户触发并且“可能互连”的事件   由   提交 /u/Jack_Hackerman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2ynub/capturing_interdependencies_between_timestamps/</guid>
      <pubDate>Thu, 29 Feb 2024 11:59:57 GMT</pubDate>
    </item>
    <item>
      <title>可以使用 TensorFlow 训练的模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2ye0z/the_models_that_can_be_trained_with_tensorflow/</link>
      <description><![CDATA[大家好，这是我的项目，大家可以使用tensorflow来训练这些模型。 模型可以在&lt; a href=&quot;https://github.com/NoteDance/Note/tree/Note-7.0/Note/neuralnetwork/tf&quot;&gt;https://github.com/NoteDance/Note/tree/Note-7.0/Note/neuralnetwork /tf 该教程可以在 https://github 找到.com/NoteDance/Note-documentation/tree/tf-7.0   由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2ye0z/the_models_that_can_be_trained_with_tensorflow/</guid>
      <pubDate>Thu, 29 Feb 2024 11:43:08 GMT</pubDate>
    </item>
    <item>
      <title>如何计算犯罪预测的预测准确性指数 (PAI)？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2xp4g/how_do_i_calculate_predictive_accuracy_index_pai/</link>
      <description><![CDATA[大家好， 我正在研究一个预测伦敦街道犯罪率的决策树。 Precision/Recall 和 ROC 效果不是很好，我听说对于犯罪预测，应该使用 Predictive Accuracy Index，并且该领域的论文也使用了 Predictive Accuracy Index。 任何人都可以给我一些指导吗？我如何将它用于我的决策树？ 当前 - 数据集是发生的年、月、街道、二元犯罪以及有关街道/社区的详细信息。如果一个月发生多起犯罪事件，该记录就会重复。阶级不平衡约为 9%，不利于犯罪。 感谢任何帮助。   由   提交/u/infinity123248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2xp4g/how_do_i_calculate_predictive_accuracy_index_pai/</guid>
      <pubDate>Thu, 29 Feb 2024 11:01:04 GMT</pubDate>
    </item>
    <item>
      <title>如何测试你的AI电话接待员？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2x3r6/how_to_test_your_ai_phone_receptionist/</link>
      <description><![CDATA[ 访问您的仪表板。 给您的 AI 接待员打电话&lt; /p&gt; 开始免费试用  恭喜！您已成功测试您的 AI 电话接待员。请随意探索仪表板中的更多功能并优化设置，以提高接待员的业务绩效。查看我的个人资料帖子了解详细信息。   由   提交/u/jaclynshelton   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2x3r6/how_to_test_your_ai_phone_receptionist/</guid>
      <pubDate>Thu, 29 Feb 2024 10:20:42 GMT</pubDate>
    </item>
    <item>
      <title>如何高效地将数百万文档添加到 ChromaDB</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2wmfk/how_to_add_millions_of_documents_to_chromadb/</link>
      <description><![CDATA[我有 200 万篇文章，正在使用 langchain 分成大约 1200 万个文档。我想对这些文档进行搜索，因此我希望将它们放入理想的一个色度数据库中。将数百万个文档插入色度数据库的最快方法是在创建数据库时插入所有文档或使用 db.add_documents()。现在我正在 db.add_documents() 中以 100,000 块为单位执行此操作，但每次调用 add_documents 的时间似乎变得越来越长。我是否应该在创建时尝试插入所有 1200 万个块，我有一个 GPU 和大量存储空间，过去每 100K 需要 30 分钟，但现在 add_document 100k 文档需要一个多小时。 &lt;代码&gt;从langchain.chains导入RetrievalQA从langchain.vectorstores导入Chroma从langchain.chat_models导入ChatOpenAI从langchain.document_loaders导入PyPDFLoader从langchain.embeddings.openai导入OpenAIEmbeddings从langchain.embeddings导入SentenceTransformerEmbeddings从sentence_transformers导入SentenceTransformer从langchain.text_splitter从 langchain.text_splitter 导入 RecursiveCharacterTextSplitter 导入 RecursiveCharacterTextSplitter model_path = “./multi-qa-MiniLM-L6-cos-v1/” model_kwargs = {“设备”：“cuda”}嵌入= SentenceTransformerEmbeddings（model_name =“./multi-qa-MiniLM-L6-cos-v1 /”，model_kwargs = model_kwargs）documents_array = 文档[0：100000] text_splitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=50, length_function=len, is_separator_regex=False, ) docs = text_splitter.create_documents(documents_array) persist_directory = &quot;chroma_db&quot;; vectordb = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=persist_directory ) vectordb.persist() docs = text_splitter.create_documents(documents[500000:600000]) def batch_process(documents_arr, batch_size, process_function): 对于范围内的 i （0，len（documents_arr），batch_size）：batch=documents_arr [i：i +batch_size] process_function（batch）def add_to_chroma_database（batch）：vectordb.add_documents（documents=batch）batch_size = 41000batch_process（docs，batch_size，add_to_chroma_database）    由   提交 /u/AggravatingSyrup8146   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2wmfk/how_to_add_millions_of_documents_to_chromadb/</guid>
      <pubDate>Thu, 29 Feb 2024 09:47:40 GMT</pubDate>
    </item>
    <item>
      <title>一个很好的期末预科机器学习/人工智能项目。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2wl77/a_good_machine_learning_ai_project_for_prefinal/</link>
      <description><![CDATA[给我一​​些可以给老师留下深刻印象的机器学习/人工智能项目想法， 恶意软件检测、文本到 SQL 法学硕士、深度造假检测、抑郁检测器等都被拒绝了。 请给我一些好主意，我们 3 人团队可以在 1.5 个月内实施 ​  div&gt;  由   提交 /u/nihlRen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2wl77/a_good_machine_learning_ai_project_for_prefinal/</guid>
      <pubDate>Thu, 29 Feb 2024 09:45:19 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv9架构细节，新SOTA物体检测王</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2vxw2/yolov9_architectural_details_new_sota_object/</link>
      <description><![CDATA[      YOLOv9 引入了两项新功能： 完整文章：https://medium.com/aiguys/yolov9-new-object-detection-king-6fc97b93dc9a GELAN 和 PGI - GELAN 结合了 CSPNet（以其轻量级设计和效率而闻名）和 ELAN（专注于梯度路径管理以实现有效的梯度路径管理）的优势学习）。 - 通过允许在网络中使用任何类型的计算块（而不仅仅是卷积层）来概括 ELAN 的概念。这为设计高效的网络架构提供了更大的灵活性。 PGI 基本上解决了两个主要问题： - 信息瓶颈 - 深度监督限制：深度监督向网络添加了额外的预测层以帮助训练。然而，它有时会导致网络过于关注特定特征或对象而忽略其他特征或对象。  为了解决深度监督问题，YOLOv9 提供了辅助可逆分支：该组件提供了另一种路径，以确保训练期间传播回来的梯度可靠且完整。 ​  https://preview.redd .it/g4ombvrqohlc1.png?width=828&amp;format=png&amp;auto=webp&amp;s=038924e0da6262afe8dd197c6813e9e86162c6fe ​   由   提交 /u/Difficult-Race-1188   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2vxw2/yolov9_architectural_details_new_sota_object/</guid>
      <pubDate>Thu, 29 Feb 2024 08:59:45 GMT</pubDate>
    </item>
    <item>
      <title>哈佛 CS50 的 Python 人工智能与机器学习专业化 作者：Andrew NG</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2uhgw/harvard_cs50s_artificial_intelligence_with_python/</link>
      <description><![CDATA[这些课程有什么区别   由   提交/u/Bominator8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2uhgw/harvard_cs50s_artificial_intelligence_with_python/</guid>
      <pubDate>Thu, 29 Feb 2024 07:19:47 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 icp 算法估计激光雷达传感器的轨迹？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2s35m/how_to_estimate_the_trajectory_of_a_lidar_sensor/</link>
      <description><![CDATA[我必须使用 ICP 配准来估计带有激光雷达的汽车的轨迹，并将其绘制在 xyz 图形上。我知道如何提取每一帧的变换矩阵，使用前一帧作为源，下一帧作为目标。但我不确定我应该如何专门跟踪汽车并用这个算法绘制他的轨迹。你们有什么想法吗？   由   提交/u/Independent-Key-4305   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2s35m/how_to_estimate_the_trajectory_of_a_lidar_sensor/</guid>
      <pubDate>Thu, 29 Feb 2024 05:00:27 GMT</pubDate>
    </item>
    <item>
      <title>需要学习很多不同的东西，感觉迷失了</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2mam6/so_many_different_things_to_learn_feeling_lost/</link>
      <description><![CDATA[在机器学习领域，有很多不同的工具可供使用，我感觉不知道该学习哪些工具。我认为我一生无法涵盖它们。 我指的不仅仅是基本的，例如监督/无监督/强化学习或编程。但是，还有几种不同的编程语言需要学习，数学需要学习，还有不同的模块、库和框架。我该如何掌握所有这些？许多工作要求列出了一大堆，所以我不能跳过其中一些。   由   提交/u/open_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2mam6/so_many_different_things_to_learn_feeling_lost/</guid>
      <pubDate>Thu, 29 Feb 2024 00:19:54 GMT</pubDate>
    </item>
    <item>
      <title>“群体计算”或分布式训练的人工智能是一种东西，甚至是可能的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2lrez/is_a_crowdcomputed_or_distributively_trained_ai_a/</link>
      <description><![CDATA[随机理论问题...但我在想 gpt 模型是如何昂贵的以及训练它们的服务器成本。那么是否有任何项目可以让人们贡献少量的处理能力来为更大的项目做出贡献呢？这种事情可能吗？   由   提交/u/Aeon001  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2lrez/is_a_crowdcomputed_or_distributively_trained_ai_a/</guid>
      <pubDate>Wed, 28 Feb 2024 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>视频中的活动发言者检测速度提高了 90%</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b2axms/active_speaker_detection_on_video_thats_90_faster/</link>
      <description><![CDATA[       由   提交/u/happybirthday290   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b2axms/active_speaker_detection_on_video_thats_90_faster/</guid>
      <pubDate>Wed, 28 Feb 2024 16:56:14 GMT</pubDate>
    </item>
    </channel>
</rss>