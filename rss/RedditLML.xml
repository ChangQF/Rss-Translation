<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 06 Dec 2024 15:18:28 GMT</lastBuildDate>
    <item>
      <title>付费课程推荐</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h83ekk/paid_course_recommendation/</link>
      <description><![CDATA[嗨。 我工作的公司将为我提供 ML 课程。我是一名拥有多个 YOE 的软件工程师，过去曾实现过一些基本的 CNN 模型。我们使用结构化数据（如相机图像），因此我考虑在 Udacity 攻读深度学习纳米学位。但是，我担心会把这些宝贵的时间浪费在太基础或太慢的事情上。 我想知道您的经验以及您的建议。我看过子版块的帖子，但许多回复都建议使用免费材料可以获得类似或更好的结果。由于我会在工作时间完成这项工作，因此我希望能够向我的公司展示结论证明，这就是为什么结构化课程比自学更受欢迎的原因。我也很愿意听取免费建议，只要它满足此要求。    提交人    /u/Longjumping-Map-8852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h83ekk/paid_course_recommendation/</guid>
      <pubDate>Fri, 06 Dec 2024 15:07:27 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我需要有关 Kaggle 的 TMDB 数据集项目的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h82sxc/guys_i_need_a_help_regarding_my_project_on_tmdb/</link>
      <description><![CDATA[      因此，我们正在 Kaggle 的 TMDB 数据集上开展 clge 项目 https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies 我们正在尝试进行回归。但问题是这些数据主要包含 0，我的意思是 75% 的列中有零值。 我需要你的帮助来执行这个模型，无论是回归还是分类。但是我们还没有学过 NLP，所以我们将致力于 ML（监督和无监督 - 聚类）。 数据类型 列 收入、预算、投票列中有超过 75 条记录为零 所以我需要你的帮助来完成这个项目。或者我遗漏了一些东西，我可以用 Mean 填充它们，但它不适合数据的上下文。我需要你的帮助。你也可以给我发私信 谢谢    提交人    /u/Bloodshot12_   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h82sxc/guys_i_need_a_help_regarding_my_project_on_tmdb/</guid>
      <pubDate>Fri, 06 Dec 2024 14:40:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 规范化流程应用</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h825fo/d_normalizing_flow_application/</link>
      <description><![CDATA[      我有一个后验近似值，它是图像形式的，其中 F、S 和 Q 是定义明确的实数值张量。  近似 我正在寻找一种对这种近似进行快速采样的方法（快速的意思是 t&lt;1 秒），我认为也许规范化流可能是一个好主意，因为对数后验的函数形式定义得很好。然而，在我尝试任何事情之前，我想听听实际使用规范化流的人的意见，看看是否值得花时间在这上面。正如我所说，我希望这个采样速度非常快（t&lt; 1 s），我的目标是 11 维参数空间。    提交人    /u/Specific-Result3696   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h825fo/d_normalizing_flow_application/</guid>
      <pubDate>Fri, 06 Dec 2024 14:08:44 GMT</pubDate>
    </item>
    <item>
      <title>约会推荐指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7zseb/dating_recommender_guidance/</link>
      <description><![CDATA[嗨， 我公司有一个约会项目。我负责创建一个基于用户行为和互动的推荐系统，根据用户的兴趣为他们提供建议。我需要指导，希望有人能帮助我。    提交人    /u/ImprovementAlive870   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7zseb/dating_recommender_guidance/</guid>
      <pubDate>Fri, 06 Dec 2024 12:00:29 GMT</pubDate>
    </item>
    <item>
      <title>ARR openreview 匿名预印本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7zdvr/arr_openreview_anonymous_preprint/</link>
      <description><![CDATA[我一直在做 CS NLP 方面的研究，第一次向 ARR Dec 周期提交论文，并勾选了获取匿名预印本的复选框。ARR 多久会给我匿名预印本的网址，还是我必须自己将其上传到 ARR 预印本服务器？    提交人    /u/Master_Ocelot8179   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7zdvr/arr_openreview_anonymous_preprint/</guid>
      <pubDate>Fri, 06 Dec 2024 11:34:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 研究论文：EGO-CH Gaze：探索文化遗址中的凝视驱动物体检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7ym0k/research_paper_egoch_gaze_exploring_gazedriven/</link>
      <description><![CDATA[大家好， 我想分享我们最近的研究成果，EGO-CH Gaze，这是一项使用自我中心视觉和凝视数据检测文化遗址中感兴趣物体的研究。这项研究解决了理解游客在参观博物馆期间的注意力这一挑战，旨在通过个性化推荐和更深入的参与来提升他们的体验。 要点：  数据集： 在博物馆环境中使用 HoloLens2 收集（Palazzo Bellomo，锡拉库萨）。 包括来自 7 位参与者的约 220,000 个带注释的 RGB 帧，重点关注 15 个感兴趣的物体。  问题： 使用 RGB 图像和注视信号检测关注的物体（并非场景中的所有物体）。 评估的方法：无监督、弱监督和全监督模型。  结果： 弱监督方法仅使用注视和最少的标记，在性能和注释工作量之间提供了良好的权衡。 我们引入了专门为这项任务量身定制的新算法，包括基于凝视的边界框回归器和受语义分割启发的方法。   如果您发现这项工作有帮助，请考虑引用我们的论文： {10.1145/3647999, author = {Mazzamuto*, Michele 和 Ragusa*, Francesco 和 Furnari*, Antonino 和 Farinella*, Giovanni Maria}, title = {学习使用凝视信号和弱对象监督检测文化场所中的注意对象}, year = {2024}, issue_date = {2024 年 9 月}, publisher = {计算机协会}, address = {美国纽约州纽约市}, volume = {17}, number = {3}, issn = {1556-4673}, url = {https://doi.org/10.1145/3647999}, doi = {10.1145/3647999}, articleno = {35}, numpages = {21}, keywords = {文化场所，可穿戴设备，凝视，物体检测} }  欢迎在此处查看数据集和完整研究：EGO-CH Gaze。我很乐意听到您的想法或回答任何问题！    提交人    /u/Mikess95   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7ym0k/research_paper_egoch_gaze_exploring_gazedriven/</guid>
      <pubDate>Fri, 06 Dec 2024 10:41:18 GMT</pubDate>
    </item>
    <item>
      <title>尝试创建一款可以预测并推荐使用哪种高尔夫球杆的应用程序</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7ydn6/trying_to_create_an_app_which_predicts_and/</link>
      <description><![CDATA[我编写了一个 Python 脚本，一旦您输入目标距离，它就会推荐高尔夫球杆。它会根据您输入的先前击球情况，使用您用球杆击球的距离以及您与球洞的距离来推荐球杆。但是我想让它更准确，涉及更多变量，并包含某种学习曲线，虽然我真的不确定要使用哪种模型，有人有什么建议吗？（我对此真的很陌生，如果这没有多大意义，请原谅）    提交人    /u/Analyst_Large   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7ydn6/trying_to_create_an_app_which_predicts_and/</guid>
      <pubDate>Fri, 06 Dec 2024 10:24:13 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习时感觉不知所措。有什么建议吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7wql2/feeling_overwhelmed_trying_to_learn_ml_any_tips/</link>
      <description><![CDATA[就某些方面而言，我一直觉得 ML 非常有趣，最近我想在空闲时间开始学习。我有编程背景，对 python、pandas、numpy 和 matplotlib 有一些经验。我还参加了线性代数课程以及微积分 1 和 2。 在数学、统计、数据和模型之间，我感到不知所措。有人对我应该从哪里开始学习以及学习什么有提示/指导吗？    提交人    /u/dhhdhdhddhegeb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7wql2/feeling_overwhelmed_trying_to_learn_ml_any_tips/</guid>
      <pubDate>Fri, 06 Dec 2024 08:20:33 GMT</pubDate>
    </item>
    <item>
      <title>人工智能图像识别模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7vllp/ai_image_recognition_model/</link>
      <description><![CDATA[我是这个领域的初学者，想创建一个人工智能图像识别模型。我该从哪里开始才能最快完成它。    提交人    /u/AlternativePure8552   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7vllp/ai_image_recognition_model/</guid>
      <pubDate>Fri, 06 Dec 2024 06:57:50 GMT</pubDate>
    </item>
    <item>
      <title>我如何在多台计算机上用 Pytorch 从头编写的基于 GPT 架构的 LLM 训练，其中 16 台设备中的每一台都有我想要使用的自己的 GPU？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7v7ks/how_can_i_train_an_llm_based_on_gpt_architecture/</link>
      <description><![CDATA[我编写了代码，使用数据集 wikipedia 英文版（从 hugging face 下载）从头开始训练，我学校实验室的 LLM 使用 python 和 pytorch。基本上在实验室里我有 16 台计算机，每台都有自己的 GPU，我想运行代码以确保我们一起使用所有 16 个 GPU，并使用大量参数训练 LLM。但是，我的 pytorch 代码仅适用于在单台 PC 上运行（并检查该 PC 上是否有 GPU，并使用 GPU，否则使用 CPU），但我现在想一起使用我拥有的所有 GPU，但每个 GPU 都在单独的 PC 上，而且作为学校实验室，我不能对硬件进行太多的移动。有一些方面需要考虑，例如所有 PC 都是固定的并且都使用 Windows 11。目前，我和数学老师设法使用 ssh 从一台主 PC 建立到另一台主 PC 的连接，但我不知道这是否有用。基本上，我想要做的是启动我的代码并确保我可以增加超参数，然后将计算分布在实验室中 16 台计算机的所有 GPU 上，而不必诉诸奇怪的东西。我该怎么做？最简单的方法是什么（简单很重要，因为它仍然是一个学校实验室）？如果你能帮忙，要知道每台计算机都有一个 NVIDIA GeForce RTX 3050 GPU。     提交人    /u/challenger_official   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7v7ks/how_can_i_train_an_llm_based_on_gpt_architecture/</guid>
      <pubDate>Fri, 06 Dec 2024 06:31:57 GMT</pubDate>
    </item>
    <item>
      <title>Google PaliGemma 2（视觉模型）发布，开源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7uc4t/google_paligemma_2_vision_models_released/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7uc4t/google_paligemma_2_vision_models_released/</guid>
      <pubDate>Fri, 06 Dec 2024 05:37:25 GMT</pubDate>
    </item>
    <item>
      <title>提出有趣的机器学习研究想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7trfx/coming_up_with_interesting_ml_research_ideas/</link>
      <description><![CDATA[嗨，我是一名从事 ML 研究的本科生，我意识到我真的需要提高我为潜在研究主题产生有趣想法的能力。现在，我能做的最好的事情就是做一些适合论文消融研究部分的事情，例如稍微改变模型的组成部分或改变评估设置，看看会发生什么。 关于如何提出更有创意的想法有什么建议吗？    提交人    /u/mltoohard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7trfx/coming_up_with_interesting_ml_research_ideas/</guid>
      <pubDate>Fri, 06 Dec 2024 05:03:52 GMT</pubDate>
    </item>
    <item>
      <title>我为国会开发了一个名为 Democrasee.io 的人工智能聊天机器人。我厌倦了听到政客们不回答问题。所以我开发了一个聊天机器人，让你可以与他们的立法记录、投票、财务、政治行动委员会捐款等进行聊天。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7mmui/i_built_an_aipowered_chatbot_for_congress_called/</link>
      <description><![CDATA[        提交人    /u/zerryhogan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7mmui/i_built_an_aipowered_chatbot_for_congress_called/</guid>
      <pubDate>Thu, 05 Dec 2024 23:05:54 GMT</pubDate>
    </item>
    <item>
      <title>我意识到这不是机场，而是由于所有的简历帖子而去和平的地方。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h7hiie/i_realize_its_not_the_airport_but_going_to_peace/</link>
      <description><![CDATA[标题。    由    /u/aqjo 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h7hiie/i_realize_its_not_the_airport_but_going_to_peace/</guid>
      <pubDate>Thu, 05 Dec 2024 19:29:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>