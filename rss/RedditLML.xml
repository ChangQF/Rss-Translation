<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 19 Aug 2024 15:16:29 GMT</lastBuildDate>
    <item>
      <title>使用 Encodec 构建 SFX 生成模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ew3xpr/building_an_sfx_generation_model_with_encodec/</link>
      <description><![CDATA[我正在尝试构建我的第一个 SFX 声音合成主要架构。我计划在 6 小时的电影 FX 数据集（脚步声、狗吠声等）上训练模型，并训练模型，以便它可以为输入的任何输入产生新的声音。 我原来的管道涉及： 训练：输入 —&gt; 频谱图 —&gt; VQVAE —&gt; PixelSNAIL 推理：训练过的 PixelSNAIL —&gt; VQVAE 解码器 —&gt; HiFiGAN —&gt; 输出 但是，现在我正在考虑使用 Meta 的 Encodec 的标记器来替换频谱图并将其输入到 VQVAE 中，因为 Encodec 似乎大量压缩音频数据，同时仍保留最重要的显着特征（比频谱图）。我只是想知道您对这个流程的看法，以及您是否使用 Encodec 进行过类似的项目，以及它是否为这些类型的任务提供了成功。    提交人    /u/corlioneeee   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ew3xpr/building_an_sfx_generation_model_with_encodec/</guid>
      <pubDate>Mon, 19 Aug 2024 14:57:55 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助找到正确的模型和数据集。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ew2f77/need_help_in_finding_the_right_model_and_dataset/</link>
      <description><![CDATA[我正在尝试为我的 Django Web 应用创建一个简单的酒店推荐系统。它将使用房价、酒店评分、房间类型作为特征并预测酒店名称。什么数据集最适合这项任务，我应该在什么模型上训练数据集。    提交人    /u/orcaguidance   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ew2f77/need_help_in_finding_the_right_model_and_dataset/</guid>
      <pubDate>Mon, 19 Aug 2024 13:54:58 GMT</pubDate>
    </item>
    <item>
      <title>机器学习系统设计面试技巧</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ew25hf/machine_learning_system_design_interview_tips/</link>
      <description><![CDATA[嘿，几周前我开通了一个 YouTube 频道，帮助现任和有抱负的 ML 工程师完成他们的整个职业生涯。  今天我发布了一个关于如何通过 ML 系统设计面试的新视频  https://youtu.be/XN2ymraj27g 很想听到来自这个社区的任何反馈！  谢谢！ PS：关于我 - 14 年技术经验 - 10 年 ML 经验 - Adob​​e、Twitter、Meta 的 ML 技术主管 - 目前是 B 轮 ML 平台负责人 - 0 年 YouTube 经验，这表明😂    提交人    /u/mftgdss   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ew25hf/machine_learning_system_design_interview_tips/</guid>
      <pubDate>Mon, 19 Aug 2024 13:43:41 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 在 Q 学习决斗网络中使用 V(s') 的平均值而不是 argmax Q(s',a) 进行引导</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ew0vr3/research_bootstrapping_in_qlearning_dueling/</link>
      <description><![CDATA[      https://preview.redd.it/q7qaxum3amjd1.png?width=665&amp;format=png&amp;auto=webp&amp;s=41eb112abc28cc80e18393eff05d6dcaa495c07c 我一直在进行一些实验，但结果并不理想。您能否就我的方法中可能存在的问题提供一些见解？ 我正在使用状态-动作-输入架构，为每个动作执行前向传递。网络为每个动作生成一个 Q 值估计。选择这种方法是因为在大动作空间下，状态输入架构不切实际。 这种方法背后的原理是有效地管理大动作空间。计算状态 S&#39; 中所有动作的 arg max 需要大量计算。我的方法涉及对可用动作子集执行前向传递，并直接使用决斗网络的 V 输出。为了估计 V(s&#39;)，我取该动作子集产生的 V(s&#39;) 值的平均值。 任何关于潜在缺陷或改进的反馈都将不胜感激。    提交人    /u/RjRdrG   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ew0vr3/research_bootstrapping_in_qlearning_dueling/</guid>
      <pubDate>Mon, 19 Aug 2024 12:47:21 GMT</pubDate>
    </item>
    <item>
      <title>rmsprop 为何有效？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ew09yy/why_rmsprop_works/</link>
      <description><![CDATA[从 Geoffrey 讲座中，他说这是选择一个全局学习率。1）这对不同权重具有不同尺度的事实有何影响。2）我总是直观地认为梯度的值有一些必需的信息，这有助于误差函数更快地收敛。    提交人    /u/ImpressionOwn5487   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ew09yy/why_rmsprop_works/</guid>
      <pubDate>Mon, 19 Aug 2024 12:18:09 GMT</pubDate>
    </item>
    <item>
      <title>有哪些疯狂或出色但很少在媒体上露面的机器学习应用？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evzenc/what_are_some_crazy_or_awesome_ml_applications/</link>
      <description><![CDATA[  由    /u/BEE_LLO  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evzenc/what_are_some_crazy_or_awesome_ml_applications/</guid>
      <pubDate>Mon, 19 Aug 2024 11:31:52 GMT</pubDate>
    </item>
    <item>
      <title>Cyber​​Scraper-2077 | 面向数据科学家/分析师的基于 OpenAI 的数据抓取工具:)</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evy6xp/cyberscraper2077_openai_based_data_scraper_for/</link>
      <description><![CDATA[      你好 Reddit！我使用 GPT-4o-mini 创建了一个有用的数据抓取工具，可以从互联网中提取信息。它对于从网络收集特定数据特别有用。 只需用简单的英语提供说明，该工具就会检索所需的信息。此外，您可以灵活地将数据保存为各种格式，例如 CSV、Excel、JSON 等。欢迎在 GitHub 上随意探索它： GitHub：https://github.com/itsOwen/Cyber​​Scraper-2077 如果你喜欢它，请给它一颗星 ❤️    由   提交  /u/SnooOranges3876   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evy6xp/cyberscraper2077_openai_based_data_scraper_for/</guid>
      <pubDate>Mon, 19 Aug 2024 10:17:00 GMT</pubDate>
    </item>
    <item>
      <title>“你听说过图卷积神经网络（Graph CNN）吗？”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evxsuz/have_you_heard_of_graph_convolutional_neural/</link>
      <description><![CDATA[      图像中的卷积运算不仅考虑单个像素的值，还考虑相邻像素的值，可帮助我们从图像中识别特征。使用图神经网络 (GNN) 中的卷积运算也可以从特征中提取含义。 想象一个代表研究论文的图神经网络 (GNN)。每篇论文都会在网络中引用其他几篇论文。 论文由节点表示，引用由边表示。各个论文可能基于几个不同的主题：机器学习、NLP、GenAI、计算机视觉等。 通常，当我们参考一篇论文时，我们非常有兴趣找到类似的论文。 是否可以使用 GNN 框架将论文分为几个不同的类别？这是完全可能的。 为了对论文（GNN 的节点）进行分类，我们考虑论文（节点）的特征以及相邻节点（引用论文的特征）的特征。我们可以使用称为图卷积网络 (GCN) 的概念来完成特征聚合和节点分类。 这里有一个讲授 GCNN 理论和应用的讲座。如果你是一个完全的初学者或者对 GNN 一无所知，我很确定这个讲座仍然会对你有所帮助。几个 GNN 操作 - 消息传递、特征聚合、转换和节点分类以非常简单的方式解释。请在此处查看讲座。你会喜欢它：https://www.youtube.com/watch?v=93FiLSxKr_U&amp;feature=youtu.be https://preview.redd.it/5o9wzxtseljd1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=153e868774b573895e62e7ca10ca24fd2694448b    提交人    /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evxsuz/have_you_heard_of_graph_convolutional_neural/</guid>
      <pubDate>Mon, 19 Aug 2024 09:51:41 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的 Kmeans 聚类 [从头开始编码]</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evwjql/kmeans_clustering_in_machine_learning_coded_from/</link>
      <description><![CDATA[很高兴分享我的机器学习系列的第七篇文章！ 您将学到什么：  Kmeans 背后的数学直觉 如何从头开始实现算法 Kmeans 闪耀的真实场景  链接：https://cckeh.hashnode.dev/a-step-by-step-guide-to-kmeans-clustering-in-machine-learning    提交人    /u/CC-KEH   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evwjql/kmeans_clustering_in_machine_learning_coded_from/</guid>
      <pubDate>Mon, 19 Aug 2024 08:22:40 GMT</pubDate>
    </item>
    <item>
      <title>“MindSearch：模仿人类思维进行更深入的人工智能搜索”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evwhdj/mindsearch_mimicking_human_mind_for_deeper_ai/</link>
      <description><![CDATA[      Google 的搜索引擎可以以网页链接的形式为您提供最佳搜索结果。但不能直接回答您的查询。如果将搜索引擎与 GPT4o 等强大的现代 LLM 相结合，您可以获得对复杂查询的非常准确的响应。 但是，即使是搜索引擎 + LLM 组合也有局限性。 1) 网页搜索结果包含太多信息和噪音。这很容易超过 LLM 的上下文长度。 2) 如果查询很复杂，搜索引擎无法有效地进行搜索 人类查找信息的过程非常不同。我们不会试图直接回答复杂的问题。我们将问题模块化为更小、更易于管理的块。 想象一下你想买一辆车。你不会直接试图回答你的问题“我希望买一辆预算在 120 万卢比以下的汽车用于日常使用。我想要 XYZ 功能、里程和 CC”。 相反，你会从不同角度看待这个问题。你的品牌偏好、功能列表、转售价值、座位数、预计总使用年限/公里数、最高预算等。然后你会找到一份汽车清单。其中一些会符合你的一些要求。你会权衡你的选择，然后打电话。这是一个相当反复的过程。 如何将这种复杂的迭代决策融入人工智能辅助互联网搜索中？ 这篇题为“MindSearch”的论文于 3 周前在 arXiv 上发表，有一个很有趣的想法。模块化搜索查询并将其表示为具有节点和边的图形神经网络。部署 LLM 代理以通过搜索引擎 API 规划网络搜索。进行并行搜索查询来回答查询的不同部分。这称为细粒度搜索。 图将是动态的。根据 LLM 代理的初始网络搜索结果，更新节点和边。图中的节点数取决于搜索查询的复杂性。  我发布了一个 30 分钟的讲座视频来回顾这篇论文，以便来自各种背景的观众都能理解这篇论文。观看视频：https://www.youtube.com/watch?v=DQH6CM5sj7o 根据论文作者进行的研究，MindSearch 毫无疑问击败了现有的开放式和封闭式问题的 AI 辅助搜索解决方案。他们的 GitHub repo 已经有 3.7k 个星：https://github.com/InternLM/MindSearch 这是论文的链接：https://arxiv.org/abs/2407.20183 LLM 搜索要取代传统的 Google 搜索还有很长的路要走。MindSearch 的商业用途将归结为成本、准确性、幻觉率、速度以及 LLM 代理响应的实际效用。 无论如何，我认为现在批判性地评论这篇论文还为时过早。我只是喜欢他们写它的方式。有影响力的研究，易于理解，完全开放。这正是科学应该有的样子。向作者致敬。 https://preview.redd.it/5aaqxon2ykjd1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=d91d41628640491671e1c6b0159f65c54b7bc236    提交人    /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evwhdj/mindsearch_mimicking_human_mind_for_deeper_ai/</guid>
      <pubDate>Mon, 19 Aug 2024 08:17:58 GMT</pubDate>
    </item>
    <item>
      <title>YOLO 边界框</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evw0rh/yolo_bounding_boxes/</link>
      <description><![CDATA[      嗨， 我想了解边界框在 YOLO 中为何以及如何工作。我读过一些帖子和解释，但我仍然不确定我是否真的理解了这个概念。 如何为大于网格的物体分配中心？我的意思是，如果网格看不到整个物体，它怎么能分辨出它是什么呢？  https://preview.redd.it/4zqgvdk8rkjd1.png?width=1446&amp;format=png&amp;auto=webp&amp;s=c2348485643f0b9ba3e95e9a12a71f32e988a601 这里的狗比 S x S 网格的每个单元格都大得多。例如，如果细胞只看到爪子，它怎么知道它检测到了狗？细胞是否以某种方式相互了解？我读到过，每个细胞（即其神经元）的接受域都大于其自身，但从架构上如何理解这一点？  https://preview.redd.it/sjjbnnnqrkjd1.png?width=2764&amp;format=png&amp;auto=webp&amp;s=7c1e8eac03b55b386387aba030ee6068010d97cf 我理解卷积不是在每个单元上独立运行的，但是如果最后的层都是 7 x 7，它们就比输入网格小得多，因此“分辨率”可能不允许我们制作准确的粘合框？  我不知道我是否很好地解释了我的观点，我真的很感激任何帮助:)谢谢！    提交人    /u/Advanced-Platform-97   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evw0rh/yolo_bounding_boxes/</guid>
      <pubDate>Mon, 19 Aug 2024 07:44:51 GMT</pubDate>
    </item>
    <item>
      <title>除了梯度下降之外，还有哪些其他拟合模型的方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evsev6/what_are_some_other_methods_of_fitting_a_model/</link>
      <description><![CDATA[我正在做一个简单的项目，从头开始实现各种机器学习模型，我想提供使用不同方法拟合模型的灵活性。 例如，我希望用户能够选择他们使用的模型（例如线性回归/ SVM / KNN），还可以选择他们想要如何拟合模型（例如梯度下降，随机梯度下降等） 我注意到很多教程和项目都使用梯度下降作为拟合许多回归模型的默认方法。我想知道其他模型是否使用其他方法。 我只想要一个我要实现的各种方法的列表。 此外，除了网格搜索之外，还有其他超参数调整方法吗？    提交人    /u/leemanjoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evsev6/what_are_some_other_methods_of_fitting_a_model/</guid>
      <pubDate>Mon, 19 Aug 2024 03:49:55 GMT</pubDate>
    </item>
    <item>
      <title>对法学硕士 (LLM) 工作原理的直观解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1evdab7/an_intuitive_explanation_of_how_llms_work/</link>
      <description><![CDATA[      博客文章中的一张图显示了 LLM 的示例输出。这些概率加起来为 1（或 100%） 嗨！ 我写了一篇博文文章，以非常直观的方式解释了 LLM 的工作原理。我们从高层次的抽象开始，其中 LLM 被视为个人助理，然后深入研究并涵盖标记化、采样和嵌入等概念。 我添加了一些图形以直观的方式说明一些概念。 我还解决了当前 LLM 的一些局限性，例如无法计算“strawberry”中的 R 以及反转字符串“copenhagen”。 我希望你觉得它有用！ 如果您有任何反馈或疑问，请告诉我。 https://amgadhasan.substack.com/p/explaining-how-llms-work-in-7-levels   由    /u/Amgadoz  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1evdab7/an_intuitive_explanation_of_how_llms_work/</guid>
      <pubDate>Sun, 18 Aug 2024 16:24:31 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用线性回归模型，在末尾和开头是否有垂直散点线</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ev81n2/i_am_using_a_linear_regression_model_are_are/</link>
      <description><![CDATA[        提交人    /u/Beyond_Birthday_13   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ev81n2/i_am_using_a_linear_regression_model_are_are/</guid>
      <pubDate>Sun, 18 Aug 2024 12:27:11 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>