<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Mon, 18 Mar 2024 12:23:34 GMT</lastBuildDate>
    <item>
      <title>有什么可以加入一起学习的 ML 项目或社区吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhoj7d/any_ml_program_or_community_to_join_for_learning/</link>
      <description><![CDATA[您好，正在寻找 ML 社区或项目，我可以加入其中进行学习、执行常规/每周任务、从导师那里获取反馈、讨论解决方案等？  正在寻找一个程序来让自己对自己负责并向他人学习。    由   提交/u/Ok_Guide_7500   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhoj7d/any_ml_program_or_community_to_join_for_learning/</guid>
      <pubDate>Mon, 18 Mar 2024 11:34:08 GMT</pubDate>
    </item>
    <item>
      <title>寻求见解：理论偏差会影响动物传播研究中的深度学习模型吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhohwd/seeking_insights_can_theoretical_bias_influence/</link>
      <description><![CDATA[大家好！ 我是一名专注于科学哲学和动物认知领域的研究员，对机器学习越来越感兴趣。最近，我遇到了通过强化学习过程探索动物交流的项目，但我发现自己有点停滞不前。在深入研究 ML 的基础知识时，很明显我只是触及了表面，这就是为什么我寻求您的指导。 诸如 CETI 项目 和地球物种项目引起了我的注意。他们在研究的不同方面使用各种人工智能工具，例如隔离鲸鱼的点击声或使用无监督模型来识别通信结构中的集群和模式。总体目标是处理、标记和分析科学家多年来积累的大量数据，并将新的有效数据纳入此基础。 我主要担心的是可能存在固有偏差数据中的权重源自初始选择过程中分配的预定权重，即使是在无监督训练中也是如此。实际上，我并不担心一般的偏见，例如人类中心主义偏见（那里有很多文献），而是担心潜在的语言或心灵理论隐含存在的可能性。然而，我有限的技术专业知识限制了我直接解决这个问题的能力。 我发现自己在思考几个问题，如果您能就其中一个问题提供任何见解，我们将不胜感激： &lt; p&gt;- 从技术角度来看，我的方法是否有些幼稚？ - 开发这些模型是否需要特定的语言理论？如果不是，在选择处理层期间如何分配给不同数据点的权重？如果是这样，您的理论如何转化为不同的分析点？ - 您将如何验证此类偏差的存在？您会从哪里开始寻找？ - 我愿意接受建议。虽然我观看了视频并阅读了基本材料，但更多专业资源将非常有益。 - 我应该了解 m-l 哪些知识才能正确谈论它？ 热烈欢迎您的批评和建议。   由   提交 /u/Plotino_Jr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhohwd/seeking_insights_can_theoretical_bias_influence/</guid>
      <pubDate>Mon, 18 Mar 2024 11:31:57 GMT</pubDate>
    </item>
    <item>
      <title>关于变压器的理论论文</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhogd4/theoretical_paper_about_transformers/</link>
      <description><![CDATA[我将成立一个专注于大型语言模型的研究小组。参与者是具有数学背景的计算机科学博士生。我想首先研究变压器（或注意力）的一些理论特性。可能有的同学还不太清楚Transformer具体是怎么公式化的，所以我也需要讨论一下。 您有什么关于Transformer理论分析的论文推荐（注意）吗？  最流行的注意力论文是“Attention is all you need”，但他们只介绍了架构并运行实验。  &amp; #32；由   提交/u/Massive_Horror9038   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhogd4/theoretical_paper_about_transformers/</guid>
      <pubDate>Mon, 18 Mar 2024 11:29:34 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 AMD RX6950XT 来训练我的模型吗？如果是这样怎么办？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bho329/can_i_use_an_amd_rx6950xt_to_train_my_models_if/</link>
      <description><![CDATA[ 由   提交/u/Obliviator77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bho329/can_i_use_an_amd_rx6950xt_to_train_my_models_if/</guid>
      <pubDate>Mon, 18 Mar 2024 11:06:59 GMT</pubDate>
    </item>
    <item>
      <title>作为新手运行大型项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhnwwl/running_big_projects_as_a_newbie/</link>
      <description><![CDATA[我是深度学习的新手，并且按照在线教程构建了小型项目。下一步我想复制大型项目。但问题是我不知道如何处理大小超过 3GB 左右的巨大数据集。基本上，我在GitHub上找到了一些代码库，想从复制和修改开始学习。我的选择是： 我有一台带有 CUDA GPU 的笔记本电脑。我的研究所有一个 GPU 集群，我可以使用，但我以前从未使用过 SLURM。谁能指导我开始探索大型项目的最佳方式。    由   提交 /u/thaaat_one   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhnwwl/running_big_projects_as_a_newbie/</guid>
      <pubDate>Mon, 18 Mar 2024 10:57:00 GMT</pubDate>
    </item>
    <item>
      <title>帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhngit/help/</link>
      <description><![CDATA[嘿伙计们，我想知道是否有任何网站或思维导图可用于了解我们应该根据数据类型进行哪些统计测试。例如，如果它是数值和数值，我们就会进行相关性......   由   提交/u/ted-96  /u/ted-96 reddit.com/r/learnmachinelearning/comments/1bhngit/help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhngit/help/</guid>
      <pubDate>Mon, 18 Mar 2024 10:27:51 GMT</pubDate>
    </item>
    <item>
      <title>标记图像并将其输入 ResNet50 (Keras)</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhnau6/labelling_images_and_feeding_it_into_resnet50/</link>
      <description><![CDATA[我有一个在 imagenet 上预训练的 resnet 模型，当前设置用于图像分类，并且它可以工作。然而，我最终需要模型来读取带有多个标记边界框的图像并对边界框中的对象进行分类。 我目前使用 Labelstudio 进行标记，并且可以选择将其导出到许多不同的格式（json、Yolo 格式等），但我只是不知道如何输入所有内容。 有如何执行此操作的示例吗？   由   提交 /u/777881840519R   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhnau6/labelling_images_and_feeding_it_into_resnet50/</guid>
      <pubDate>Mon, 18 Mar 2024 10:17:22 GMT</pubDate>
    </item>
    <item>
      <title>有什么方法可以使用 Llama2 通过 Neo4j 知识图进行 RAG 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhn9bu/any_way_to_do_rag_with_a_neo4j_knowledge_graph/</link>
      <description><![CDATA[基本上是标题。我见过很多使用 Neo4j 和 Langchain 进行知识图谱 RAG 的方法，问题是，它们需要 OpenAI 的付费 API 密钥才能工作。任何人都可以帮助在 Neo4j 知识图谱上使用 Llama2 等开源 LLM 和 MiniLM-L6-v2 等开源嵌入模型进行 RAG 吗？   由   提交/u/arinjay_11020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhn9bu/any_way_to_do_rag_with_a_neo4j_knowledge_graph/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:42 GMT</pubDate>
    </item>
    <item>
      <title>推出equiadapt python 库</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhmos2/launch_of_equiadapt_python_library/</link>
      <description><![CDATA[很高兴推出 EquiAdapt！ 🚀 用于神经网络等变适应的库，包括分段任意模型（SAM），使它们在不损失效率的情况下对转换具有鲁棒性：https://github.com/arnab39/equiadapt。  您还可以使用 PyPI 安装该库：pip install equalapt。 轻松将 equiadapt 合并到您的训练和/或推理脚本并将模型转换为“等变”模型： 1️⃣ 定义规范化网络2️⃣ 用 equiadapt 规范化器包装它&lt; br /&gt; 3️⃣ 在将输入传递给模型之前调用 canonicalize()。 我们设计了一些教程供您入门，并提供图像分类的详细示例和训练脚本，支持 lightning、wandb 和 Hydra 的实例分割、点云分类、零件分割和等变动力学预测，以便您可以轻松运行和扩展实验。  ⭐️ 如果您感谢我们为社区所做的努力，请通过分享和加注我们的 GitHub 存储库来帮助我们。 Twitter 帖子：https://twitter.com/sibasmarak/status/1769637864604643442   由   提交/u/Definitely_Dubious86   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhmos2/launch_of_equiadapt_python_library/</guid>
      <pubDate>Mon, 18 Mar 2024 09:36:41 GMT</pubDate>
    </item>
    <item>
      <title>nvidia 显卡与机器学习有什么关系？它是为了让视频游戏看起来更好而制作的GC吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhm4ip/how_is_an_nvidia_graphic_card_related_to_machine/</link>
      <description><![CDATA[我在这里缺少什么？我看到每个人都在谈论英伟达股票，以及它是如何飙升的，当我做了一些研究时，提到它是因为它提供了下一个级别的机器学习......我不明白的是，显卡项目如何与机器学习相关联？    由   提交 /u/Jumpy-Weekend-1223   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhm4ip/how_is_an_nvidia_graphic_card_related_to_machine/</guid>
      <pubDate>Mon, 18 Mar 2024 08:55:12 GMT</pubDate>
    </item>
    <item>
      <title>部署 Mistral 7B - 量化方法、托管选项等（针对 GPU 较差的情况）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhkvtx/deploying_mistral_7b_quantization_methods_hosting/</link>
      <description><![CDATA[我正在尝试为我正在构建的 RAG 应用程序部署 Mistral 7B api 端点。我感到困惑的一些主要事情 - 我的 GPU 很差:( 所以计划使用 AWS sagemaker 来部署模型 - 2 个月的免费计划每月有 125 小时的 m4.xlarge 或 m5.xlarge 实例用于推理- 这足以为量化的 Mistra 设置一个端点（我想是 5 位）吗？如果您自己没有 GPU 并且是一名破产的学生，那么模型托管的首选是什么？只需要它是我最后一年的项目，所以这不是一个长期的事情。此外，我对量化类型和方法感到困惑 - 首先是 AWQ、GGUF 和 GPTQ，因为它的效率，我倾向于 AWQ，但是我听说它的缺点是支持有限？如果我只是想部署 TheBloke 的 AWQ 模型，那应该不是特别困难的事情吧？另外，AWQ 的唯一缺点是它可能需要更多 RAM？还研究了部署方法本身 - openllama、vllama 等。我倾向于 vllama 因为效率 - 吞吐量是 Huggingface TGI 吞吐量的两倍，到目前为止我一直在使用 Huggingface TGI。但后来看到有人说它可能需要更多 VRAM？所以请提出建议 - 我的托管选项是什么，我应该使用什么量化方法，在这些有限的资源内，我有什么选择可以使这个模型尽可能快？ 注意：大多数情况下它不能得到帮助，我将不得不在模型速度上做出妥协，但我也想使用该模型来提取块的元数据，如果我向该模型提供 100 个块，我需要它不要慢到不切实际的地步哈哈。    由   提交/u/Aggravating-Floor-38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhkvtx/deploying_mistral_7b_quantization_methods_hosting/</guid>
      <pubDate>Mon, 18 Mar 2024 07:20:14 GMT</pubDate>
    </item>
    <item>
      <title>我在学习机器学习时陷入了选择兴趣领域的两难境地</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhkreo/i_am_in_a_dilemma_in_choosing_my_area_of_interest/</link>
      <description><![CDATA[问题是我对机器学习非常感兴趣，自从我开始学习概率和线性代数等基础知识以来已经有 4 天了从那时起一切都进展顺利，但问题是我怀疑自己，如果我将来想在这个领域进行研究，我没有稳定的财务来支持我的硕士。因此，每天我都在完全困惑中醒来，从职业角度来看这是否是正确的事情，然后浪费时间思考，直到出现一些动力，我想知道我是否应该选择以前学习成为后端开发人员的道路。有时我想，如果我同时学习 mL 和 Web，如果 mL 失败，则将 Web 作为备用计划，但这完全是胡说八道，你无法同时正确学习两者。所以上个月我注意到，当我做 Web 开发时，我的注意力开始转向 mL，因为我对此有点兴趣，但当我做 mL 时，我又想把它改回 Web 开发。我对毫升研究感兴趣，但我的财务状况困扰着我。我是一所糟糕大学的第一年第二学期，没有机会，所以没有好的同龄人。   由   提交 /u/Agitated-Bowl7487    reddit.com/r/learnmachinelearning/comments/1bhkreo/i_am_in_a_dilemma_in_choosing_my_area_of_interest/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhkreo/i_am_in_a_dilemma_in_choosing_my_area_of_interest/</guid>
      <pubDate>Mon, 18 Mar 2024 07:11:16 GMT</pubDate>
    </item>
    <item>
      <title>分词器如何塑造人工智能理解</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bhim9g/how_tokenizers_shape_ai_understanding/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/manishmanalath   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bhim9g/how_tokenizers_shape_ai_understanding/</guid>
      <pubDate>Mon, 18 Mar 2024 04:48:24 GMT</pubDate>
    </item>
    <item>
      <title>3D 对象移除数据集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bh7l87/3d_object_removal_dataset/</link>
      <description><![CDATA[       由   提交/u/Rojepi  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bh7l87/3d_object_removal_dataset/</guid>
      <pubDate>Sun, 17 Mar 2024 20:24:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我应该主修计算机科学而不是数学才能成为 DS？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bh0171/why_should_i_major_in_cs_over_math_to_become_a_ds/</link>
      <description><![CDATA[当人们询问数据科学教育时（研究生院基本上是强制性的），我觉得我看到本科生的计算机科学比本科生的数学更受推崇。掌握数据科学/机器学习背后的数学知识，并在 CS 或 DS 中兼修/辅修编程技能，不是比相反更好吗？ 我的目标是在数学中学习数学本科生，然后是统计学硕士，所以我觉得数学本科生对我来说会更好。   由   提交 /u/Background_Crazy2249   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bh0171/why_should_i_major_in_cs_over_math_to_become_a_ds/</guid>
      <pubDate>Sun, 17 Mar 2024 15:18:15 GMT</pubDate>
    </item>
    </channel>
</rss>