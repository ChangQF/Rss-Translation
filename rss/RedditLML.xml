<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 12 Jan 2024 03:15:34 GMT</lastBuildDate>
    <item>
      <title>研究生水平的项目构想</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194km4y/graduatelevel_project_idea/</link>
      <description><![CDATA[我是机器学习生成方法的新手。你们专家能给我一些关于使用表格数据进行机器学习生成方法的研究生水平项目的想法吗？   由   提交 /u/FollowingOdd2987   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194km4y/graduatelevel_project_idea/</guid>
      <pubDate>Fri, 12 Jan 2024 03:03:52 GMT</pubDate>
    </item>
    <item>
      <title>检查我对梯度下降的理解</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194hvnx/check_my_understanding_of_gradient_descent/</link>
      <description><![CDATA[我一直不太清楚为什么我们需要使用梯度下降来“推动”参数在减少损失的方向上，并在达到某个近似最小值之前猜测步长和步数。  为什么我们不求解损失函数来找到导致真正最小损失的实际参数，而不是通过这种方式迭代调整到近似最小值？  我假设它与执行此操作所需的计算量有关，但是有没有一种简单的方法可以解释这一点？是否需要将所有可能的参数值组合代入网络并计算每个可能组合的损失？我想如果您采用这种强力方法，组合的数量只会受到这些参数值的浮点表示的精度的限制？    由   提交/u/GrumpyMcGillicuddy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194hvnx/check_my_understanding_of_gradient_descent/</guid>
      <pubDate>Fri, 12 Jan 2024 00:53:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 和预训练的 Faster RCNN 模型进行交通标志检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194has8/traffic_sign_detection_using_pytorch_and/</link>
      <description><![CDATA[      使用 PyTorch 和预训练的 Faster RCNN 模型进行交通标志检测  https://debuggercafe.com/traffic-sign-detection-using -pytorch-and-pretrained-faster-rcnn-model/ ​ https://preview.redd.it/2zocxcfnlwbc1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=8e4 6c730ded0e9d1fa09d61bb0a3c385082782ae    由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/194has8/traffic_sign_detection_using_pytorch_and/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194has8/traffic_sign_detection_using_pytorch_and/</guid>
      <pubDate>Fri, 12 Jan 2024 00:27:48 GMT</pubDate>
    </item>
    <item>
      <title>烤我的简历。目标角色 DS/ML。谢谢大家:)</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194gg2n/roast_my_cv_targetted_roles_dsml_thanks_folks/</link>
      <description><![CDATA[       由   提交/u/Pale_Building4278  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194gg2n/roast_my_cv_targetted_roles_dsml_thanks_folks/</guid>
      <pubDate>Thu, 11 Jan 2024 23:49:39 GMT</pubDate>
    </item>
    <item>
      <title>有人读完MML书吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194cda2/anyone_finished_mml_book/</link>
      <description><![CDATA[有用吗？是否存在误导学习的令人讨厌的拼写错误？   由   提交 /u/iiillililiilililiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194cda2/anyone_finished_mml_book/</guid>
      <pubDate>Thu, 11 Jan 2024 21:01:07 GMT</pubDate>
    </item>
    <item>
      <title>数学问题帮助：神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/194atu2/math_problem_help_neural_networks/</link>
      <description><![CDATA[我正在解决 Bishop 1995 年关于神经网络的书中的这个问题： 在多层感知器中，隐藏单元有一个对于位于由 w^T x + w0 = const 给出的输入空间中的超平面上的输入向量的恒定激活，而对于径向基函数网络，隐藏单元在由 ||x 定义的超球面上具有恒定激活− µ||^2 = const.. 表明，对于参数的适当选择，如果输入向量归一化为单位长度，则这些表面会重合，因此 ||x|| = 1. 这个问题看起来很容易解决。然而，我陷入了开头本身，可能是因为用来表达问题的语言。球面和平面怎么可能重合？我缺少什么？对于此问题的任何帮助，我们将不胜感激。   由   提交/u/shashvata   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/194atu2/math_problem_help_neural_networks/</guid>
      <pubDate>Thu, 11 Jan 2024 19:58:09 GMT</pubDate>
    </item>
    <item>
      <title>注意帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1949pqa/attention_help/</link>
      <description><![CDATA[亲爱的 Reddit，  我已经失去了对注意力如何充分发挥作用的直觉，所以这一次，我试图明确写出我对查询、键和值矩阵代表什么的理解，但是，我不太确定我的理解是否正确，有人可以“校对”吗？我的理解？  “”“ 查询矩阵 W^Q (embedding_dim, d_k) = 矩阵，其中每个维度包含一行，其值等于“特征”的值。 （在下一段中讨论）要查找，即对于该特定维度而言，哪个维度最重要。 关键矩阵 W^K (embedding_dim, d_k) = 每个维度包含一行的矩阵它的“特征”对于这个特定的维度。注意：这些特征本身并不是实际的维度，我们不知道这些特征代表什么，但首先如果我们想象单词嵌入的每个维度都有一些含义，例如，某些维度代表语义相似性，意味着具有相似含义的单词在空间中很接近，其他维度可能是特定概念“人”、“颜色”、地点、时态等，其他维度可能是词性，例如名词、动词等，W^K 将它们转换为格式，一组可以与查询相匹配的“特征”，换句话说，在检索设置中，您可能会将其视为用于查找实际数据的元数据。  值矩阵 W^V (embedding_dim, d_v) = 每个维度包含一行的矩阵，其中包含在注意力机制中传递的 ACTUAL 维度的相关信息。 ”“  GPT4 似乎不同意我的观点： “”“”   查询矩阵 (W^Q)：该矩阵用于将输入嵌入转换为一组查询。每行并不完全包含指示特定维度的特征重要性的值。相反，它将输入嵌入转换为一个空间，其中每个维度代表不同的方面或“查询”。我们想要与键进行匹配。 键矩阵 (W^K)：与 W^Q 类似，W^K 将输入嵌入转换为键空间。键矩阵本身不包含特定维度的特征，而是将输入转换为一种表示形式，其中每个维度都可以被视为可以与查询进行匹配的不同特征或特征。 &lt;值矩阵（W^V）：该矩阵将输入嵌入转换为值空间。每行对应于输入嵌入的变换表示，其中每个维度都携带原始嵌入的一些信息。这些值用于注意力机制中的加权和计算。  “”“”  有人可以帮忙吗？  ​   由   提交/u/BenAhmed23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1949pqa/attention_help/</guid>
      <pubDate>Thu, 11 Jan 2024 19:11:25 GMT</pubDate>
    </item>
    <item>
      <title>128维高斯潜在空间之旅</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1947u06/a_trip_through_128_dimensional_gaussian_latent/</link>
      <description><![CDATA[    &lt; /a&gt;  我创建了一个工具，可以在我所构建的 VAE 的潜在空间内形成一系列随机线性插值。正在建设。然后，它显示最后一个 LERP 的结果和字符串，以从前一个 LERP 的端点开始，以创建平滑的（呃）过渡。 仍然缺少我想要捕获的更精细的图像细节，但我认为这个可视化结果看起来很酷。希望当我对更深入的模型进行调整时能看到更多的精美图像 https://github。 com/ddaeschler/vae-experiments 就像在疯狂的生成中快速行驶一样高速公路   由   提交/u/Spaghetti-Logic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1947u06/a_trip_through_128_dimensional_gaussian_latent/</guid>
      <pubDate>Thu, 11 Jan 2024 17:54:37 GMT</pubDate>
    </item>
    <item>
      <title>关于具有非常大输入向量的 FFNN 的直觉。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1947k0t/intuition_regarding_ffnns_with_very_large_input/</link>
      <description><![CDATA[我正在考虑解决我遇到的问题，其中之一需要使用具有可变输入大小的前馈神经网络。 （澄清一下，每个网络的输入大小是在创建时设置的，并且在其生命周期内不会改变，但不可能事先具体知道。在接近较大端的情​​况下，我可能有多达 160 个输入（尽管在特殊情况下，理论上可能更多），而最小情况为 7。（这是使用根据每个包含 x 值的数据样本计算出的统计数据的结果，具体来说 7x + 1_ {x &gt; 1} * (x^2 - x)  统计。我不能只使用长度为 x 的样本，因为我对数据的统计行为感兴趣我打算使用这些统计数据来预测单个通过/失败布尔值，使用简单的“基本”前馈层序列。我当前的计划是使用 3 个隐藏层层，随着我们在网络中的进展，层数会变得更小。假设单元的数量以某种有用的方式取决于输入大小，我认为这应该足够强大，足以接近 UFE。 但是，我缺乏将神经网络用于像这样的非常大的输入向量的经验，所以我想问是否有人发现我可能忽略的任何明显问题（性能除外）。任何其他想法也将受到欢迎。   由   提交 /u/Rhoderick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1947k0t/intuition_regarding_ffnns_with_very_large_input/</guid>
      <pubDate>Thu, 11 Jan 2024 17:43:25 GMT</pubDate>
    </item>
    <item>
      <title>有哪些项目可以在本地运行？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1946yh0/what_are_some_projects_that_can_run_locally/</link>
      <description><![CDATA[我发现的大多数是图像生成器。还有其他有趣的项目吗？ （例如视频或音频相关、文本聊天等）   由   提交/u/sdw23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1946yh0/what_are_some_projects_that_can_run_locally/</guid>
      <pubDate>Thu, 11 Jan 2024 17:19:57 GMT</pubDate>
    </item>
    <item>
      <title>您通常如何交付您的 OSS 应用程序以便其他人可以使用它们？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1944p2x/how_do_you_normally_ship_your_oss_apps_so_that/</link>
      <description><![CDATA[如果您正在开发具有多个移动组件的东西，您如何为最终用户打包和交付坑？    由   提交 /u/hopeirememberthisid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1944p2x/how_do_you_normally_ship_your_oss_apps_so_that/</guid>
      <pubDate>Thu, 11 Jan 2024 15:45:00 GMT</pubDate>
    </item>
    <item>
      <title>ML 应用程序中使用了多少高级 Python？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1943k7c/how_much_advanced_python_is_used_in_ml/</link>
      <description><![CDATA[机器学习对高级 Python 功能（如多重继承、记忆、在 super() 内传递参数等）的重视程度如何？  我对基础中级（包括简单的 OOP 和函数式编程）Python 非常熟悉，但对上一段提到的更高级的概念不太熟悉。我还需要了解这些吗？   由   提交 /u/datashri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1943k7c/how_much_advanced_python_is_used_in_ml/</guid>
      <pubDate>Thu, 11 Jan 2024 14:55:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 VAE 过了一会儿就开始为每个输入生成一张图片？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1941qwj/why_does_my_vae_start_generating_one_pic_for/</link>
      <description><![CDATA[      在 3000 张猫脸图像上训练，7 层，编码器是 cnn，解码器是一个前馈（ik，它不是最优的，我只是还没有实现非池化层，并且像这样工作得更好）这是 300 个 epoch 后的输出，但它与 100 个 epoch 中的输出没有那么不同......是这样的预期的？我可能在某个地方犯了错误吗？谢谢！ ​ https://preview.redd.it/dmvpk4gmbtbc1.jpg?width=64&amp;format=pjpg&amp;auto=webp&amp;s=1be8ad3a7dfd3e91236cb69ef7​​f7ea30d151befe   由   提交 /u/Mr__Weasels   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1941qwj/why_does_my_vae_start_generating_one_pic_for/</guid>
      <pubDate>Thu, 11 Jan 2024 13:30:19 GMT</pubDate>
    </item>
    <item>
      <title>多代理无人机仿真项目的专业知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1940w8a/expertise_for_multiagent_drone_simulation_project/</link>
      <description><![CDATA[您好， 我相信您会收到此消息。我目前正在从事一个涉及多代理无人机模拟的项目，我正在向这个受人尊敬的社区寻求指导和见解。 项目概述： 目标：开发一个分布式的多代理无人机模拟展示跨设备的紧急群体行为（聚集、避障、寻求目标）。 寻求专业知识： 算法：针对稳健群体行为、避障的建议，以及目标寻求算法。 工具和目标搜索算法。框架：深入了解无人机模拟的首选工具或框架。 最佳实践：从类似项目经验丰富的人员那里获得行业最佳实践指南。 您的意见的意义： &gt; 我渴望与精通分布式系统、无人机模拟和人工智能工程的个人建立联系。 当我应对这个复杂的问题时，您的建议、建议或潜在的指导将是非常宝贵的。努力。 您可以如何贡献： 请通过评论或私信分享您的见解。 我愿意接受讨论，并感谢任何详细的经验或信息您可能提供的建议。 对于您提供的任何帮助，我表示衷心的感谢。让我们参与知识的协作交流，共同增强我们在这一领域的理解。感谢您的时间和考虑。   由   提交/u/Dry_Purple_3082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1940w8a/expertise_for_multiagent_drone_simulation_project/</guid>
      <pubDate>Thu, 11 Jan 2024 12:45:55 GMT</pubDate>
    </item>
    <item>
      <title>这个损失曲线是否意味着我应该停止训练并优化我的数据集？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/193svt5/does_this_loss_curve_mean_i_should_stop_training/</link>
      <description><![CDATA[      我对创建自定义数据集相当陌生，并且已经看到大多数示例数据集的结果之前有一个很好的损失曲线。目前正在我的数据集上训练的这个模型看起来损失曲线并不乐观，但根据我所读到的内容，我不确定。 在所附的屏幕截图中，我目前位于Apple 的 CreateML 的迭代/纪元为 4951 次，共 12,000 次，损失为 40.417。我尝试训练的模型用于图像内的多对象检测。大约有 480 万张标记图像（真实数据和合成数据），因此这需要一段时间才能完成。此时已经运行超过 14 小时。就我而言，我发现损失随着时间的推移而减少，到最后一次迭代时可能会达到约 25%，但这可能不足以满足我的需求。 不过，我想要理解的是，当观察曲线时，什么是不值得继续训练的好例子？有哪些学习检查损失曲线的好资源？ ​ https://preview.redd.it/otfg9xw6rqbc1.png?width=1584&amp;format=png&amp;auto=webp&amp;s=dda4fcaf4818095d91 81666612a0ddd2e79b5bc4&lt; /p&gt;   由   提交/u/williammincy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/193svt5/does_this_loss_curve_mean_i_should_stop_training/</guid>
      <pubDate>Thu, 11 Jan 2024 04:25:10 GMT</pubDate>
    </item>
    </channel>
</rss>