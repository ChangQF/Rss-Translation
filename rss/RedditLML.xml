<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Mon, 24 Feb 2025 06:26:48 GMT</lastBuildDate>
    <item>
      <title>DeepSeek Flashmla：DeepSeek OpenSource Week第1天</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4jc/deepseek_flashmla_deepseek_opensource_week_day_1/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/mehul_gupta1997       [links]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwv4jc/deepseek/deepseek_flashmla_flashmla_deepseek_opensource_opensource_week_week_week_day_1/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4jc/deepseek_flashmla_deepseek_opensource_week_day_1/</guid>
      <pubDate>Mon, 24 Feb 2025 05:57:45 GMT</pubDate>
    </item>
    <item>
      <title>Gemini vs OpenAI的功能/工具调用最佳是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_best_for_functiontool_calling_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  正如我所研究的那样，OpenAI GPT4-O模型和Gemini 2.0模型都可以函数/工具调用。从成本明智的角度来看，双子座模型比Openai便宜。但是从工具/函数调用角度来看，最佳模型是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/super_strawberry_555     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_the_best_for_functiontood_functiontool_calling_calling_from//]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwv4i1/what_is_the_best_for_functiontool_calling_from/</guid>
      <pubDate>Mon, 24 Feb 2025 05:57:40 GMT</pubDate>
    </item>
    <item>
      <title>观看我关于机器学习的视频</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwslp1/watch_my_vid_about_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它使用pytorch教u基本的机器学习。将上传更多vids--  https://youtu.be/pipeym1klag？ &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/um/emotional-amount-520     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwslp1/watch_my_vid_about_machine_learning/</guid>
      <pubDate>Mon, 24 Feb 2025 03:29:59 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊作为访谈从2周开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iws2o5/amazon_as_interviews_starting_in_2_weeks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/mikespecterzane    href =“ https://www.reddit.com/r/leetcode/comments/1iwqwo6/amazon_as_interviews_starting_in_2_weeks/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iws2o5/amazon_as_interviews_starting_in_2_weeks/</guid>
      <pubDate>Mon, 24 Feb 2025 03:01:54 GMT</pubDate>
    </item>
    <item>
      <title>可以训练VAE还可以执行介绍 /降解吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_vae_be_trained_to_also_perform_inpainting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个相当小的数据集，可以最好地描述为随机掩盖的小补丁的图像（请注意，它们都在此中“损坏”方式，没有可以使用的“清洁图像”。 天真，我有两个模型。首先，我通过掩盖了一些没有掩盖的区域，以介绍一些没有掩盖的区域的损失（因此没有基本真相），从而训练了一个Denoising AutoCodoter，并通过掩盖了一些没有掩盖的区域。然后，我将使用该模型来注入我在训练的相同图像（填写那些蒙面的补丁）。其次，我想将增强图像压缩到有意义的潜在空间中，所以我会训练典型的VAE（或像VQ-VAE这样的变体）。 ，我不知道为什么这两个步骤无法使用单个模型来完成。我应该能够使用我描述的第一个目标来训练VAE，对吗？ 。但是无论出于何种原因，dae/vae通常被称为完全不同的概念，所以我只想确保我不会在这里错过任何东西。  &lt;！ -  sc_on-&gt;＆＃ 32;提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_a_vae_be_be_trained_to_also_also_also_also_also_perform_inpainting/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwqygq/can_a_a_a_a_vae_be_trained_to_to_also_also_also_perform_inpainting/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwqygq/can_a_vae_be_trained_to_also_perform_inpainting/</guid>
      <pubDate>Mon, 24 Feb 2025 02:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[help*]我的ML模型到底有什么问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwpiv6/help_what_is_exactly_wrong_with_my_ml_model/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    project  我和我的朋友正在建立一个深度学习模型，从我的班级收集天气数据，并旨在在我们学校周围的当地地区准确预测PV的生成。  问题 我们一年的小时光伏生成数据，一个卫星图像数据集和一个数字天气文件。最初，我们用3个月的数据进行了测试，达到了约12％的NMAE。验证损失（通过MSE衡量）在训练过程中平稳减少，没有尖峰或波动。 然后，我们将时间表从3个月扩大到全年...那时事情变得很奇怪。 NMAE提高到9％，这是该死的好，但是在训练中，验证损失或训练损失会随机飙升至 60 （通常，它保持不变左右 0.01 ）。当这种情况没有发生时，验证损失如地狱，但它仍然比训练损失低 ，这是没有意义的。.我们尝试了200多种不同的组合学习率和体重衰减...但是无助请帮助！ （这与我的数据有关...？）   -------第一个图：3个月的价值     ------然后，12个月（1年）数据             &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/necter_top_6988      [links]     ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwpiv6/help_what_is_exactly_wrong_with_my_ml_model/</guid>
      <pubDate>Mon, 24 Feb 2025 00:52:27 GMT</pubDate>
    </item>
    <item>
      <title>指导</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwmjpf/guidance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想了解深度学习和神经网络，我最终希望建立一个神经网络，该网络识别手写数字，就像许多人一样用作示例许多介绍该概念的视频。我需要帮助才能开始学习Python以及我对这个小项目的需求。谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/key-extension9475      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwmjpf/guidance/</guid>
      <pubDate>Sun, 23 Feb 2025 22:32:29 GMT</pubDate>
    </item>
    <item>
      <title>需要有关ML学习路径的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwm6wf/need_advice_on_ml_learning_path/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！ 我目前由Stanford Online和DeepLearning.ai入学。我不确定下一步该怎么做。完成此课程后，您建议您推荐哪个课程？我应该开始一个AI项目吗？还是两者？另外，我距离一所不那么伟大的大学获得了CS学位两个学期。您认为我应该获得硕士学位还是自学的AI发展？  事先感谢您的帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/newsir2760     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwm6wf/need_advice_on_ml_learning_path/</guid>
      <pubDate>Sun, 23 Feb 2025 22:16:46 GMT</pubDate>
    </item>
    <item>
      <title>寻找一门好的课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwi6hh/looking_for_a_good_course/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找有关数据预处理和模型部署的好课程。有什么建议吗？最好是锻炼的实用性。谢谢🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/syedmayyan     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwi6hh/looking_for_a_good_course/</guid>
      <pubDate>Sun, 23 Feb 2025 19:25:47 GMT</pubDate>
    </item>
    <item>
      <title>全新的机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwhvma/entirely_new_to_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个同事帮助我构建一个自动编码器，以根据测量的形态特征对2种类型的修饰单元进行分类。  最初的结果很棒，但是在此方面，我们最终得到了一些数据泄漏，而没有进行5倍的交叉验证。  因此，我们修复了它，删除了一些我们认为没有用的数据，现在情况更糟。 现在我陷入了模型的性能减少，此外，我意识到少量的形态特征更依赖于样品中细胞的密度，而不是与细胞功能有关。从数据集中删除它们后，性能降低了。 此外，在5倍验证期间，一个折叠往往具有很高的重建损失。是否有关于尝试什么的一般建议，或者任何愿意查看我模型的培训部分并帮助故障排除的人？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/this-ae-nighte    href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iwhvma/entirely_new_to_to_machine_learning/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwhvma/entirely_new_to_machine_learning/</guid>
      <pubDate>Sun, 23 Feb 2025 19:13:15 GMT</pubDate>
    </item>
    <item>
      <title>如果您想建造自己的抹布，吹牛是一个很好的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwf3sq/braglangchain_is_a_great_resource_if_you_want_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  它包括逐步的教程，一个很好的资源 突出显示： - 设置抹布应用程序的指南，从数据加载到向量存储 - 学习高级技术，例如多Query设置，更好索引准确的结果 - 实践示例以应用您所学的知识 在此处查看： https：// github。 com/bragai/brag-langchain    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielwetan     [link]  ＆＃32;   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwf3sq/braglangchain_is_a_great_resource_if_you_want_to/</guid>
      <pubDate>Sun, 23 Feb 2025 17:16:45 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iwcbxq/dropout_explained/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我已经创建了一个视频在这里我谈论辍学的地方，这是一种强大的正则化技术。 我希望你们中的某些人可以使用它。反馈受到欢迎！ ：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/personal-trainer-541      [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iwcbxq/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:16:17 GMT</pubDate>
    </item>
    <item>
      <title>零开放式推理器：AI培训效率的突破与DeepSeek相匹配，只有1/30个训练步骤 - 包括Kai-Fu Lee，Harry Shum和Xiangyu Zhang Zhang Zhang umeveil革命开放式开放式培训方法，包括AI的主要人物。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iw6jme/open_reasoner_zero_a_breakthrough_in_ai_training/</link>
      <description><![CDATA[   效率与DeepSeek相匹配，只有1/30的培训步骤 - 主要AI人物包括Kai-Fu Lee，Harry Shum和Xiangyu Zhang揭开革命开源培训方法” src =“ https://external-preview.redd.it/9bmchgsuf8urvewpa1jib4a2nzpho52vm4iv_psjonc.jpg？宽度= 640＆amp; crop = smart＆amp; auto = webp＆amp; s = ed0a17dd256c8c0395919191913113131575062D0F4742“ title =“开放推理零：AI培训效率的突破与DeepSeek相匹配，只有1/30的训练步骤 - 包括Kai-Fu Lee，Harry Shum和Xiangyu Zhang Zhang Zhang Zhang umeveil革命开放式开放式培训方法的主要AI人物。 /a&gt;  ＆＃32;提交由＆＃32; /u/u/xyz_labs     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iw6jme/open_reasoner_zero_a_breakthrough_in_ai_training/</guid>
      <pubDate>Sun, 23 Feb 2025 09:38:04 GMT</pubDate>
    </item>
    <item>
      <title>但是，GPT实际上是如何工作的？ |逐步笔记本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivxhjl/but_how_does_gpt_actually_work_a_step_by_step/</link>
      <description><![CDATA[   /u/u/kevinpdev1     [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivxhjl/but_how_does_gpt_actually_work_a_step_by_step/</guid>
      <pubDate>Sun, 23 Feb 2025 00:32:22 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到此处   对于那些正在寻找简历评论的人，请发布在 imgur.com 首先，然后将链接作为评论，甚至在/r/sumumes 或首先，然后在这里交叉点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>