<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 14 Nov 2024 06:24:36 GMT</lastBuildDate>
    <item>
      <title>深度学习小项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqx5qk/deep_learning_small_project/</link>
      <description><![CDATA[我想知道我应该尝试什么类型的深度学习项目来提升我的技能和知识。我是这方面的技术初学者，但我已经通过网络学习了深度学习的基础和原理。 我希望得到任何关于 CNN 算法项目的建议，任何可以提高我技能的小项目。    提交人    /u/YKnot__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqx5qk/deep_learning_small_project/</guid>
      <pubDate>Thu, 14 Nov 2024 04:50:14 GMT</pubDate>
    </item>
    <item>
      <title>答案是 D 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqwu9e/would_the_answer_be_d/</link>
      <description><![CDATA[      https://preview.redd.it/5w50cfdwos0e1.png?width=661&amp;format=png&amp;auto=webp&amp;s=2ad4d967236f6f3c1c658bfdc3b4ecce412e340d 我尝试回答这个问题，并得出答案为 D。有人可以确认它是否正确吗？如果不正确，哪一个是正确答案？ 提前谢谢您！    提交人    /u/NoResource56   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqwu9e/would_the_answer_be_d/</guid>
      <pubDate>Thu, 14 Nov 2024 04:31:43 GMT</pubDate>
    </item>
    <item>
      <title>如何处理非固定大小的输入？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqwg6n/how_to_handle_nonfixed_size_inputs/</link>
      <description><![CDATA[大家好，我是一名学生，目前遇到了一个问题！我想尝试音频分类，但是我拥有的数据大小差异很大，我想要一个固定的输出大小。如果这不可能，那么只要它可以处理可变的输入大小，那么可变的输出大小也可以。我知道我可以对其进行分块或类似操作，但我希望有另一种方法可以做到这一点！如果没有，您能否建议在不破坏数据的情况下对我的数据进行分块的最佳方法？非常感谢您的帮助。 我首选的机器学习框架是 PyTorch。 我目前就读高中。 非常感谢您的支持！    提交人    /u/LowPressureUsername   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqwg6n/how_to_handle_nonfixed_size_inputs/</guid>
      <pubDate>Thu, 14 Nov 2024 04:09:31 GMT</pubDate>
    </item>
    <item>
      <title>如何回答这个关于 NLP 的面试问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gquxul/how_to_answer_this_interview_question_on_nlp/</link>
      <description><![CDATA[我在一次采访中被问到这个问题。“对于分类任务，你会使用基于编码器还是基于解码器的模型，如果选择其中一种，背后的原因是什么？”我只是告诉他们我会使用编码器模型，因为它的注意力机制是双向的，但这仍然不是一个明显的区别。    提交人    /u/madara_x13   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gquxul/how_to_answer_this_interview_question_on_nlp/</guid>
      <pubDate>Thu, 14 Nov 2024 02:48:08 GMT</pubDate>
    </item>
    <item>
      <title>转发：为什么我的随机森林使用我的神经网络忽略的特征？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gquwgc/repost_why_does_my_random_forest_use_features/</link>
      <description><![CDATA[我的神经网络和随机森林在二元分类任务上的准确率大致相同（随机森林略好）。根据神经网络，某些特征的 shapley 值为零，但对于随机森林，其 shapley 值明显大于零。我的领域知识告诉我，这些特征非常有用，但即使在正则化之后也没有被神经网络拾取。怎么会这样？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gquwgc/repost_why_does_my_random_forest_use_features/</guid>
      <pubDate>Thu, 14 Nov 2024 02:46:09 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 CNN 模型来标记所有人脸特征点？照片中有 n 张人脸</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gquvo8/how_to_train_a_cnn_model_to_label_all_the_facial/</link>
      <description><![CDATA[因此，训练 CNN 模型来输出（x，y）一张脸的所有面部标志的位置非常容易，但对于照片中未知数量的脸部，我不知道该怎么做。     提交人    /u/GateCodeMark   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gquvo8/how_to_train_a_cnn_model_to_label_all_the_facial/</guid>
      <pubDate>Thu, 14 Nov 2024 02:45:07 GMT</pubDate>
    </item>
    <item>
      <title>对于基于 Twitter 的数据集，文本预处理步骤的顺序是否正确？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqtscz/is_the_order_of_text_preprocessing_steps_correct/</link>
      <description><![CDATA[顺序是否正确，或者是否有任何步骤需要按顺序更改？  仅保留相关列（文本）。 删除 URL。 删除提及和主题标签。 删除多余的空格。 缩写。 俚语。 将表情符号转换为文本。 删除标点符号。 替换领域特定术语（给定其上下文、机场名称等） 小写。 标记化。 拼写更正。 删除停用词。 删除罕见词 词形还原 命名实体识别（NER）。 词性 (POS) 标记。 文本矢量化。     提交人    /u/Creative_Collar_841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqtscz/is_the_order_of_text_preprocessing_steps_correct/</guid>
      <pubDate>Thu, 14 Nov 2024 01:49:40 GMT</pubDate>
    </item>
    <item>
      <title>我们对 AI 模型无损压缩研究的关键见解</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqtebn/key_insight_from_our_research_on_lossless/</link>
      <description><![CDATA[      📝 论文： https://arxiv.org/abs/2411.05239 💻 代码： https://github.com/zipnn/zipnn/  我们最近发表了一篇预印本，ZipNN：AI 模型的无损压缩，并希望与社区分享我们的一项重要发现。 神经网络参数可能看起来是随机的（例如，[0.1243, -1.2324, -0.3294...]），但它们在计算机中的表示实际上使压缩成为可能。 关键见解：浮点结构实现压缩 用于存储模型参数的浮点数是结构化的如：  符号位（正/负） 指数（范围） 尾数（精度）  有趣的是，虽然符号位和尾数位看起来是随机的，但指数并不覆盖其范围内的所有值，并且其分布是倾斜的。如图所示，该分布在四个不同的模型中都有说明 — — 我们在许多模型中都观察到了这种模式。 指数值直方图 为什么？这是由于模型的训练方式所致（有关详细信息，请参阅论文中的第 3 段）。 ZipNN 库：利用这一见解 这一见解构成了 ZipNN 的基础，这是我们的开源库无损压缩，与 ZSTD 等最先进的方法相比，它提供了更高的压缩比和更快的压缩/解压缩速度。 流行浮点格式的存储节省：  BF16 格式：节省 33% 的空间 FP32 格式：节省 17% 的空间  我们还开发了 Hugging Face 插件，可以快速下载和加载压缩模型。 示例模型：LLama-3.2-11B 使用 ZipNN，只需添加一行代码即可启用压缩。 🔗 GitHub 存储库   由    /u/Candid_Raccoon2102  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqtebn/key_insight_from_our_research_on_lossless/</guid>
      <pubDate>Thu, 14 Nov 2024 01:29:52 GMT</pubDate>
    </item>
    <item>
      <title>深度学习数学练习解决方案（De Gruyter）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqrcqj/exercise_solutions_for_the_mathematics_of_deep/</link>
      <description><![CDATA[大家好！我目前正在使用标题中提到的书籍（链接此处）学习深度学习的数学基础。我真的很喜欢它，但我注意到它似乎没有包含练习的解决方案 - 至少在我拥有的版本中没有。我试过在线搜索解决方案，但到目前为止还没有运气。  这里有人可以访问解决方案或知道我可以在哪里找到它们吗？提前感谢任何帮助！    提交人    /u/nerec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqrcqj/exercise_solutions_for_the_mathematics_of_deep/</guid>
      <pubDate>Wed, 13 Nov 2024 23:52:07 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能避免自己有时陷入“困境”？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqp0en/how_can_i_stop_myself_from_getting_stuck_at_times/</link>
      <description><![CDATA[有时在工作中我感觉自己陷入了困境，我不知道该怎么做，我开始感到不知所措，并逃避这种情况。我正在尽我所能培养能够帮助我避免“陷入困境”的技能。 我认为在深度学习中，我发现自己最常遇到这个问题，我认为这有时是因为我不知道下一步该如何处理一个项目。通常，它存在某种问题，我只是不知道如何处理。 我如何才能更好地处理诸如“我的模型不工作”之类的事情，“我的模型由于这个原因而无法工作”，“我的代码的这一部分是我的模型无法工作的原因”，“这是修复无法工作的代码部分的方法”。调试。出于某种原因，我对调试 Web 应用程序和游戏开发内容以及一般软件没有太大问题。但是，对于 ML/DL，调试和了解到底出了什么问题感觉要困难得多。什么输入没有作为正确的输出出现？诸如此类的事情。 我很感激任何见解！    提交人    /u/NightmareLogic420   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqp0en/how_can_i_stop_myself_from_getting_stuck_at_times/</guid>
      <pubDate>Wed, 13 Nov 2024 22:07:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT 就是这样处理提示的吗???拜托，我明天要考试...</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqn4cv/is_this_how_gpt_handles_the_prompt_please_i_have/</link>
      <description><![CDATA[大家好，这是我第一次在这里发帖，因为我最近才开始学习 ML。目前，我正在准备一个关于 transformer 的测试，不确定我是否理解得正确。所以我将写下我对提示处理和答案生成的理解，如果我错了，请纠正我。 在训练时，GPT 会同时生成所有输出标记，但在使用经过训练的 GPT 时，它会一次生成一个输出标记。 因此，当给出提示时，此提示将传递给与编码器基本相同的机制，以便在提示内部计算注意力。因此，提示被拆分成标记，然后将标记嵌入并传递到应用非掩码注意力的多个编码器层中。最后，我们剩下提示标记的上下文矩阵。 然后，当 GPT 开始生成时，为了生成第一个输出标记，它需要关注最后一个提示标记。这里，需要 Q、K、V 向量来继续执行解码器算法。因此，对于所有提示标记，我们使用上下文矩阵和解码器在训​​练期间学习的 Wq、Wk、Wv 矩阵来计算它们的 K 和 V 向量。因此，前一个提示标记只需要 K 和 V 向量，而最后一个提示标记还需要一个 Q 向量（因为我们专注于它）来生成第一个输出标记。 现在，解码器机制已应用，我们剩下一个维度为 vocabSize 的向量，其中包含所有词汇标记的概率分布，这些词汇标记将成为下一个生成的词汇标记。因此我们将概率最高的一个作为第一个生成的输出标记。 然后，我们通过将其嵌入向量乘以 Wq、Wk、Wv 矩阵来创建其 Q、K、V 向量，然后我们继续生成下一个输出标记，依此类推…… 所以这是我对其工作原理的理解，如果有任何错误，我将不胜感激任何评论和更正（即使只是一个小细节或命名约定，任何事情对我来说都意义重大）。我希望有人能回答我。 谢谢！    提交人    /u/Ok-Reputation5282   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqn4cv/is_this_how_gpt_handles_the_prompt_please_i_have/</guid>
      <pubDate>Wed, 13 Nov 2024 20:47:15 GMT</pubDate>
    </item>
    <item>
      <title>视频游戏人工智能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqmc9w/video_game_ai/</link>
      <description><![CDATA[是否有可能制作一个可以控制游戏输入的 AI 覆盖层，然后可以玩游戏并学习如何真正擅长该游戏？如果可以，我很乐意从哪里开始。    提交人    /u/Karatetiger7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqmc9w/video_game_ai/</guid>
      <pubDate>Wed, 13 Nov 2024 20:14:50 GMT</pubDate>
    </item>
    <item>
      <title>对自己在人工智能和数据科学领域的发展道路感到困惑——NLP/LLM 的研究经验真的足以获得机器学习工程实习机会吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqcfaw/confused_about_my_path_in_ai_data_scienceis/</link>
      <description><![CDATA[我最近看到一位名为The Data Janitor的 YouTuber 谈论 AI 和 ML 的职业道路，这让我对自己的方法产生了怀疑。他提到，ML 工程职位主要针对具有扎实数据背景的人，比如数据工程师和数据科学家。他甚至给出了这个等式：数据 + 建模 = ML 模型。 现在，这让我怀疑只专注于建模是否足够。我目前正在攻读 AI 和数据科学学位课程，我的目标是最终在 AI/ML 领域工作。但问题是：我不确定攀登典型的“数据”层级（比如从数据分析师做起）是否适合我。在我的国家，实际上没有入门级数据分析师的工作，远程工作看起来也没有什么前景，因为市场上充斥着愿意以低工资工作的人们。 现在，我正准备成为我所在大学教授的研究助理。我们的大部分工作将涉及 NLP/LLM 项目，例如针对特定应用微调现有模型，例如识别阿拉伯语手写，我们将在研究论文中发表这些发现。我的问题是：这种研究经验是否会增加我获得非学术职位的机会，尤其是实习机会？ 我的目标是在大一找到实习机会。我一直在研究机器学习入门级实习的要求，其中一些要求似乎太简单了。他们列出了“Python 基础知识”、“了解 ANN 架构”和“对 TensorFlow 有一定的了解”等内容，就足够了。这是真的吗？ 很想得到一些建议，关于以研究为重点的 LLM 和 NLP 经验是否能从长远来看帮助我，或者我是否最好转向不同的方法。提前感谢任何想法！    提交人    /u/R0b0_69   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqcfaw/confused_about_my_path_in_ai_data_scienceis/</guid>
      <pubDate>Wed, 13 Nov 2024 13:05:36 GMT</pubDate>
    </item>
    <item>
      <title>𝐁𝐮𝐢𝐥𝐝 𝐋𝐋𝐌𝐬 𝐟𝐫𝐨𝐦 𝐬𝐜𝐫𝐚𝐭𝐜𝐡</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gq6jsr/𝐁𝐮𝐢𝐥𝐝_𝐋𝐋𝐌𝐬_𝐟𝐫𝐨𝐦_𝐬𝐜𝐫𝐚𝐭𝐜𝐡/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gq6jsr/𝐁𝐮𝐢𝐥𝐝_𝐋𝐋𝐌𝐬_𝐟𝐫𝐨𝐦_𝐬𝐜𝐫𝐚𝐭𝐜𝐡/</guid>
      <pubDate>Wed, 13 Nov 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>