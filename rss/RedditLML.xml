<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 04 Feb 2024 18:17:24 GMT</lastBuildDate>
    <item>
      <title>学习路径</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aitc5n/learning_path/</link>
      <description><![CDATA[大家好。我有个问题。大约 6 个月前，我开始学习深度学习，首先我学习统计学、概率论和数学，通常需要这些作为先决条件。然后我学习了全连接层，直到 2015 年才取得进展。但后来我意识到要做的事情太多了。我真正理解并掌握了大部分概念。现在我想我应该专注于适度的（扩散、变压器等）。你怎么认为？了解旧技术也很重要还是坚持新技术就足够了？因为这个领域进步太快了。   由   提交 /u/vidaaannn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aitc5n/learning_path/</guid>
      <pubDate>Sun, 04 Feb 2024 17:33:08 GMT</pubDate>
    </item>
    <item>
      <title>我们不能在Jupiter Notebook中使用github的push、pull、committing吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aitbqt/cant_we_use_githubs_push_pull_committing_in/</link>
      <description><![CDATA[我刚刚通过这个视频学习了 github，她用的是 vscode ，她在本地电脑上创建的项目和github分支之间用remote连接，然后用add、commit、push，我们在jupiter中不也可以做同样的事情吗？ ​ 我也尝试在 jupiter 中打开终端来编写 git 命令，但我不能，jupiter 中有终端页面吗？    由   提交/u/Beyond_Birthday_13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aitbqt/cant_we_use_githubs_push_pull_committing_in/</guid>
      <pubDate>Sun, 04 Feb 2024 17:32:40 GMT</pubDate>
    </item>
    <item>
      <title>变形金刚如何结束神经网络中归纳偏差的传统（用动画解释！）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ait2rx/how_transformers_ended_the_tradition_of_inductive/</link>
      <description><![CDATA[       由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ait2rx/how_transformers_ended_the_tradition_of_inductive/</guid>
      <pubDate>Sun, 04 Feb 2024 17:22:05 GMT</pubDate>
    </item>
    <item>
      <title>为演示制作图片</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1airicu/making_pictures_for_a_presentation/</link>
      <description><![CDATA[嘿，我需要向大学教师委员会介绍一个有关 Transformer 模型的项目，其中一些教师不是人工智能领域的专家。我想以图形方式展示架构、字符串处理、标记化、嵌入数组等......以更好地解释模型的作用。我尝试过使用 Latex 和 powerpoint，但绘制图表/箭头非常困难且耗时。有没有更聪明的方法来做到这一点？是否有一个程序（如果免费的话更好）可以简化计算机科学图片创建过程？ ​   由   提交 /u/ThFormi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1airicu/making_pictures_for_a_presentation/</guid>
      <pubDate>Sun, 04 Feb 2024 16:16:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 建议我在解析超链接后微调 T5 模型以进行网页摘要是否是正确的选择？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aipepq/p_suggest_me_if_it_is_the_right_choice_to_fine/</link>
      <description><![CDATA[ 由   提交 /u/Ok_Freedom__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aipepq/p_suggest_me_if_it_is_the_right_choice_to_fine/</guid>
      <pubDate>Sun, 04 Feb 2024 14:44:17 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器还是变分自动编码器？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aiohuu/autoencoder_or_variational_auto_encoder/</link>
      <description><![CDATA[提前致谢。 假设，我有一些整数值向量。我想通过自动编码器或变分自动编码器对它们进行精确编码和重建。哪一个更适合这里？非常感谢有关架构大致应该是什么的简要想法。 注意：我特别没有庞大的数据集。不过，它们可以被合成，因为输入基本上是一堆整数向量。此类任务大约需要多少数据？   由   提交 /u/sadat-hossain   /u/sadat-hossain reddit.com/r/learnmachinelearning/comments/1aiohuu/autoencoder_or_variational_auto_encoder/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aiohuu/autoencoder_or_variational_auto_encoder/</guid>
      <pubDate>Sun, 04 Feb 2024 13:59:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习简介（L15，核密度估计）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ainjdx/introduction_to_machine_learning_l15_kernel/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ainjdx/introduction_to_machine_learning_l15_kernel/</guid>
      <pubDate>Sun, 04 Feb 2024 13:09:43 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的句子 Transformer 去噪自动编码器无监督预训练</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aimkjz/tranformerbased_denoising_autoencoder_for/</link>
      <description><![CDATA[ 由   提交/u/louisbrulenaudet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aimkjz/tranformerbased_denoising_autoencoder_for/</guid>
      <pubDate>Sun, 04 Feb 2024 12:12:54 GMT</pubDate>
    </item>
    <item>
      <title>嘿，我是机器学习新手，我目前是机器学习初学者中的初学者，所以，有必要……吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aim6d4/hey_i_am_new_to_ml_and_i_am_currently_a_beginner/</link>
      <description><![CDATA[...学会那些可视化代码了吗？我知道这可能听起来很愚蠢，但是，要创建箱线图或图表，是否有必要记住 matplot lib/seaborn 代码，或者不，我不应该过分强调它而应该专注于算法？ 请帮忙并指导一下！    由   提交/u/Leonopterxy10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aim6d4/hey_i_am_new_to_ml_and_i_am_currently_a_beginner/</guid>
      <pubDate>Sun, 04 Feb 2024 11:48:05 GMT</pubDate>
    </item>
    <item>
      <title>哪种小型开源法学硕士最适合对话？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aikudt/what_small_open_source_llm_is_best_for/</link>
      <description><![CDATA[哪种小型开源法学硕士对于社交媒体对话最有效？我尝试使用 Llama-2 7B-Q4 进行微调，但它在我的 GPU 上不起作用（出现错误 cuda 内存不足）。是否有更小、更适合听起来自然的对话的模型，可以用小数据集进行微调？我发现 Bard 响应感觉比 GPT-3.5 更自然。我怎样才能得到接近巴德的回应？   由   提交/u/Sea_Skill_3479   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aikudt/what_small_open_source_llm_is_best_for/</guid>
      <pubDate>Sun, 04 Feb 2024 10:19:14 GMT</pubDate>
    </item>
    <item>
      <title>当微调 Mistral 7B 时 - Colab GPU 放弃了我</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aikbct/while_fine_tuning_mistral_7b_colab_gpu_gave_up_on/</link>
      <description><![CDATA[作为每个尝试学习 ML 的人，我尝试理解 LLM 并对其进行微调。 按照本教程进行操作：https://www.datacamp.com/tutorial/mistral-7b-tutorial但最终选择了一个我猜太大的数据集：10K 行。教程有 1K 条记录 一切都很顺利，直到训练步骤并开始训练。 ETA 显示 4 小时。我以为它会成功，但 Colab 在 1 小时 16 分钟后将其关闭。我想免费套餐有局限性：P  无论如何，一路上学到了很多东西，比如 PEFT LoRA、QLoRA。另外关于使用 wandb 进行监控。   由   提交 /u/Paperplaneflyr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aikbct/while_fine_tuning_mistral_7b_colab_gpu_gave_up_on/</guid>
      <pubDate>Sun, 04 Feb 2024 09:43:51 GMT</pubDate>
    </item>
    <item>
      <title>强化学习（RL）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aid29c/reinforcement_learning_rl/</link>
      <description><![CDATA[     &lt; td&gt; 由   提交/u/Big_Equivalent9455  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aid29c/reinforcement_learning_rl/</guid>
      <pubDate>Sun, 04 Feb 2024 02:24:58 GMT</pubDate>
    </item>
    <item>
      <title>一直在申请 MLE/DS 职位，但几乎没有任何回复，我可以获得一些简历反馈吗？ 2 年生 + 博士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aib2bp/been_applying_for_mleds_jobs_with_almost_no/</link>
      <description><![CDATA[      大家好 - 感谢您的浏览！ 申请 MLE/DS 职位大约半年了，但几乎没有收到任何回复。确实收到了“fanng”对高级 MLE 职位的回复 - 进入了最后一轮，但没有得到录用通知（高级感觉有点牵强） ​ &lt; p&gt;我该怎么做才能让我的简历变得更好？我的简历中缺少哪些对 MLE 职位（接近）普遍有利的经历？  ​ ​  /u/Affectionate-Word-54   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aib2bp/been_applying_for_mleds_jobs_with_almost_no/</guid>
      <pubDate>Sun, 04 Feb 2024 00:44:41 GMT</pubDate>
    </item>
    <item>
      <title>我想训练一个自己的聊天机器人</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ai2o1u/i_want_to_train_a_chatbot_of_myself/</link>
      <description><![CDATA[我有大约 193k 条与我女朋友聊天的 Whatsapp 消息。我遇到过一个人，他针对他朋友在该子论坛中的不和谐消息对 GPT2 进行了微调。现在，我想微调一个模型来创建一个像我一样聊天的模型。我已经清理了数据并将其分成几天。我愿意接受任何有关如何进行的想法/建议。谢谢。   由   提交 /u/Lost-Season-4196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ai2o1u/i_want_to_train_a_chatbot_of_myself/</guid>
      <pubDate>Sat, 03 Feb 2024 18:28:40 GMT</pubDate>
    </item>
    <item>
      <title>我在 YouTube 上分享了 Python 数据科学训练营（7 个多小时、7 门课程和 3 个项目）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ai2iqp/i_shared_a_python_data_science_bootcamp_7_hours_7/</link>
      <description><![CDATA[您好，我刚刚在 YouTube 上分享了一个 Python 数据科学训练营。 Bootcamp 超过 7 个小时，有 7 门课程和 3 个项目。课程包括 Python、Pandas、Numpy、Matplotlib、Seaborn、Plotly 和 Scikit-learn。我将离开下面的链接，祝您有美好的一天！ https://www.youtube.com /watch?v=6gDLcTcePhM   由   提交/u/onurbaltaci  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ai2iqp/i_shared_a_python_data_science_bootcamp_7_hours_7/</guid>
      <pubDate>Sat, 03 Feb 2024 18:21:59 GMT</pubDate>
    </item>
    </channel>
</rss>