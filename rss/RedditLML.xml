<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 22 Dec 2024 09:15:23 GMT</lastBuildDate>
    <item>
      <title>如何从我的模型中连续输出流式数据？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjukyx/how_to_stream_output_continuously_from_my_model/</link>
      <description><![CDATA[假设我有一个 tensorflow 或 pytorch 模型，它返回一些句子作为输出。或者它返回一个嵌入，我需要对其进行解码。但问题是它一次性返回所有数据。但当我查看 Gemini 或 ChatGPT 时，它们似乎会生成输出并将输出流式传输到客户端。他们是如何做到的。我知道 websocket 是如何工作的。但我对从模型流式传输输出的那部分感到非常困惑。 它是如何工作的？你们能给我解释一下或者给我一些资源吗？ 非常感谢。    提交人    /u/maifee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjukyx/how_to_stream_output_continuously_from_my_model/</guid>
      <pubDate>Sun, 22 Dec 2024 08:35:15 GMT</pubDate>
    </item>
    <item>
      <title>无法获得任何采访。帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjtpt0/not_able_to_get_any_interviews_help/</link>
      <description><![CDATA[      我一直在申请机器学习的入门级和校园招聘职位，但仍然没有面试机会。我需要在 5 月毕业前找到一份全职工作。我应该做哪些改变来提高获得面试机会？    提交人    /u/HimanshuShekhar1434   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjtpt0/not_able_to_get_any_interviews_help/</guid>
      <pubDate>Sun, 22 Dec 2024 07:26:14 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Andrew Ng 课程学习机器学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjt4ov/how_to_learn_ml_from_andrew_ng_course/</link>
      <description><![CDATA[我应该如何完成这门课程。比如我无法自己实现 alogos。我无法理解可选实验室中的所有 Python。 似乎感觉不到我到目前为止已经做了一些实质性的事情。    提交人    /u/Dry-Acanthaceae2998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjt4ov/how_to_learn_ml_from_andrew_ng_course/</guid>
      <pubDate>Sun, 22 Dec 2024 06:42:13 GMT</pubDate>
    </item>
    <item>
      <title>在没有现有标记数据集的情况下创建机器学习模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjt247/creating_a_machine_learning_model_without_an/</link>
      <description><![CDATA[我正在为一家公司创建机器学习模型。问题是所涉及的变量特定于该公司，并且没有可用于这些变量的现有标记数据集。 我考虑生成一个模拟真实场景的合成数据集来训练模型。我计划确保数据涵盖各种可能的情况，同时忠实于公司环境中可能实际发生的情况。 这是现实世界 ML 工程中的常见方法吗？我如何确保数据真实且无偏见？您是否推荐更好的替代方案或工具？    提交人    /u/Slow-Philosophy7723   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjt247/creating_a_machine_learning_model_without_an/</guid>
      <pubDate>Sun, 22 Dec 2024 06:36:45 GMT</pubDate>
    </item>
    <item>
      <title>提示：避免在 Coursera 上进行 IBM 数据科学和机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjt0m2/tip_avoid_ibm_data_science_machine_learning_on/</link>
      <description><![CDATA[我一直在参加 IBM AI 工程认证，作为我硕士课程额外学分的一部分。作为参考，过去几年我在 Coursera 上学习过很多课程，包括 IBM 的一些课程。IBM 从来不是我的最爱，因为他们不擅长教授理论，只会考你记住他们那些非常具体的例子的能力，但这个“认证”系列毫无疑问是最好的。 太糟糕了。 视频很长，浪费时间，同时又很短（或很无聊），无法告诉你任何关于这个主题的信息。他们使用视频和实验室快速浏览非常具体的代码示例，而不是使用视频来帮助你理解“为什么”了解你所做的事情背后的原因。 在 30 分钟的讲座视频和 4x 45 分钟的实验室结束后，你会知道高斯模糊是某个库的一个功能，但你不知道如何真正使用它，也不知道对任何值进行更改会产生什么效果。你也不知道为什么要使用高斯模糊。 是的，这是一门“初学者”级别的课程，我明白。所以你想让你的“初学者”对 AI / ML 背后的理论一无所知，并且你希望他们不知道如何自给自足地完成 OpenCV、Pillow、TensorFlow、PyTorch 等文档？ 如果是这样，那么在约 3 个月的时间内你会教人们什么？ 我说这话是因为我有化学学士学位、半个计算机科学硕士学位，数学相当熟练（至少通过了微积分 III）。过去几年我所有课程的 GPA 均为 4.0。非常精通 Python，拥有数年专业经验。    提交人    /u/Lankeastor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjt0m2/tip_avoid_ibm_data_science_machine_learning_on/</guid>
      <pubDate>Sun, 22 Dec 2024 06:33:46 GMT</pubDate>
    </item>
    <item>
      <title>人工智能艺术的“塑料感”是怎么回事？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjsvbe/whats_with_the_plasticky_quality_to_ai_art/</link>
      <description><![CDATA[我知道很多新模型都产生了令人难以置信的令人印象深刻的结果，你无法区分真人的真实照片和不存在的人的 AI 照片，但一般来说，有这样一种趋势，你可以判断一件艺术品是 AI 生成的，因为它具有这种独特的品质，可以暴露它，我甚至不知道如何描述那是什么，我猜这就像有人在绘制一件艺术品时，作为分层过程的一部分，画了一层超高清塑料薄膜或类似的东西。这仍然没有多大意义或完美地描述它，但我想我们都知道我在说什么（只是在用语言表达方面做得很糟糕）。除了手和随机文物（如水印/艺术家签名的残留物等）之外，这就是我们仍然可以（或者直到最近）知道一件艺术品是人工智能生成的原因。 我想知道这种情况发生的原因，因为从算法的角度来看，扩散通常是合理的，所以它在复杂性和输出质量之间的交集方面在 SotA 上表现良好是有充分理由的（尽管后者显然在一定程度上是主观的，即使你可以逐​​像素地测量几个镜头输出与其源数据之间的相似性）。我想我不太了解这些大型多模式架构中使用方法，或者从软件堆栈的角度看它们是如何工作的，或者实际训练、稳定、维护和整合所有这些东西的后勤噩梦，我所知道的关于扩散的一切都是我大约两年前在大学课程中学到的，我不确定这些趋势会在如此多种多样的提示/目标片段中如何或为何出现。    提交人    /u/w-wg1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjsvbe/whats_with_the_plasticky_quality_to_ai_art/</guid>
      <pubDate>Sun, 22 Dec 2024 06:22:52 GMT</pubDate>
    </item>
    <item>
      <title>LLM 的进步是否归功于变压器本身，还是更多地归功于数据和计算的规模？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjse9z/are_advances_in_llms_due_to_transformers_per_se/</link>
      <description><![CDATA[（请原谅我的无知，因为我对深度学习还比较陌生） 我一直在阅读 LLM 的基础知识，不禁想知道：我们所看到的进步有多少是因为 Transformer 架构本身，而不是因为这些模型已经扩展到大规模计算和数据水平？ 例如，如果我们采用较旧的架构 - 比如 RNN、LSTM 或更简单的前馈网络 - 并尝试扩展到相同程度（例如，数万亿个参数，在庞大的数据集上进行训练），我们能否取得类似的结果？ 或者 Transformer 是否有根本优势（例如，自我注意、更好的并行化）使其特别适合处理这种规模？ 我也很好奇是否有任何研究尝试用更好的扩展方法重新审视这些较旧的架构，或者 Transformer 是否只是恰好在硬件和数据集可用时达到了可扩展性和性能的最佳点。 很想听听您的想法或参考相关论文！ 提前谢谢 :)    提交人    /u/Spirited_Ad4194   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjse9z/are_advances_in_llms_due_to_transformers_per_se/</guid>
      <pubDate>Sun, 22 Dec 2024 05:49:02 GMT</pubDate>
    </item>
    <item>
      <title>关于此解决方案的想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjsbd0/thoughts_on_this_solution/</link>
      <description><![CDATA[大家好，我正在尝试思考并推断人工智能如何解决逆运动学。我看过这个频道，它启发了我：https://youtu.be/tc4M8PrvYzQ?si=OAloNMkpVs_R6RDW 有没有人知道从哪里开始，什么样的数据集会有用？    提交人    /u/fikaslo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjsbd0/thoughts_on_this_solution/</guid>
      <pubDate>Sun, 22 Dec 2024 05:43:28 GMT</pubDate>
    </item>
    <item>
      <title>Genesis：使用 GenAI 生成 4D 机器人模拟</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjrqu4/genesis_generate_4d_robotic_simulations_using/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjrqu4/genesis_generate_4d_robotic_simulations_using/</guid>
      <pubDate>Sun, 22 Dec 2024 05:04:33 GMT</pubDate>
    </item>
    <item>
      <title>谷歌面试</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjrcxv/google_interview/</link>
      <description><![CDATA[对科技界如此陌生（过去从未在科技行业工作过）。过去主要从事与政府相关的工作。说实话，我从来没有参加过任何正式工作的公司面试。 申请了谷歌职位（高级，技术但非英语），并获得了面试机会。当然，我会仔细阅读他们给我的准备文件。看了一些 YouTube 视频。众包了一些想法和思路。已经从我的招聘人员那里得到了一些建议，并通过互联网进行了研究......但是其他人有他们推荐的谷歌面试资源吗？有什么必备的或要做的吗？    提交人    /u/abyssus2000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjrcxv/google_interview/</guid>
      <pubDate>Sun, 22 Dec 2024 04:40:26 GMT</pubDate>
    </item>
    <item>
      <title>如何批量清理txt文件</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjphlb/how_to_clean_up_txt_files_in_bulk/</link>
      <description><![CDATA[如果这不是该主题的正确 subreddit，请告诉我。 我有近十万个 .txt 文件，它们的格式如下：-我不想要的随机文本，但没有两个文件是相同的-讲述故事的连贯段落-有时更多垃圾 如何摆脱垃圾并保留实际故事，并批量完成？    提交人    /u/PublicQ   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjphlb/how_to_clean_up_txt_files_in_bulk/</guid>
      <pubDate>Sun, 22 Dec 2024 02:43:32 GMT</pubDate>
    </item>
    <item>
      <title>有没有文章或指南介绍如何从头开始构建一个简单的 GAN（没有库、没有 PyTorch、没有 TensorFlow，只有纯计算）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjo3mp/is_there_an_article_or_guideline_how_to_build_a/</link>
      <description><![CDATA[互联网上有很多文章介绍如何使用 Python 库在 5 分钟内构建 GAN（数字识别），但对我来说，它们的价值不大。我想更深入地了解它，并能够自己构建幕后的所有算法。我可以学习教科书，但这将花费很长时间……有没有一篇文章可以一步一步地解释和完成所有内容？    提交人    /u/Iaroslav-Baranov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjo3mp/is_there_an_article_or_guideline_how_to_build_a/</guid>
      <pubDate>Sun, 22 Dec 2024 01:21:14 GMT</pubDate>
    </item>
    <item>
      <title>您如何保持相关性？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hjgmhv/how_do_you_stay_relevant/</link>
      <description><![CDATA[我第一次因为从事机器学习而获得报酬是在 90 年代中期；我在本科期间参加了一个暑期研究实习，使用无监督学习来清理医生用于治疗癌症患者的嘈杂 CT 扫描。从那时起，我就一直从事软件工作，断断续续地从事 ML 工作。在我上一家公司，我从头开始组建了一个 ML 团队，然后离开公司去运营一个专注于为开发人员提供低级基础设施的软件团队。 那是 2017 年，就在 Transformer 推出的时候。我很想回到 ML 领域，很明显我已经过时了。当然，线性代数七年来没有改变，但现在有了基础模型、RAG 等等。 我很好奇其他人在做什么来保持相关性。我不可能成为这个位置上唯一的“老前辈”。    提交人    /u/PoolZealousideal8145   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hjgmhv/how_do_you_stay_relevant/</guid>
      <pubDate>Sat, 21 Dec 2024 19:02:14 GMT</pubDate>
    </item>
    <item>
      <title>您会给刚开始学习机器学习的人什么建议？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hj3y78/what_advice_would_you_give_to_someone_who_has/</link>
      <description><![CDATA[嗨 我已经开始学习 YouTube 上的 Andrew Ng 的 cs229 课程的机器学习，这似乎比他的 Coursera 讲座更详细。 我计划在 3 月前完成这门课程，然后探索我能学到什么。我的数学背景擅长微积分和代数，有什么建议吗？    提交人    /u/BlackberryOriginal63   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hj3y78/what_advice_would_you_give_to_someone_who_has/</guid>
      <pubDate>Sat, 21 Dec 2024 06:21:49 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>