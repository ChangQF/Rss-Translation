<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 24 Dec 2023 06:16:18 GMT</lastBuildDate>
    <item>
      <title>LSTM 与 Transformer 的低资源 seq2seq 翻译</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pp1tu/lstm_vs_transformer_for_lowresource_seq2seq/</link>
      <description><![CDATA[我正在开发一个 NMT 项目，该项目可翻译 4-50 个单词长的短语。英语句子不是问题，但我尝试仅使用 5000 个短语（最多 10 个单词左右）来训练模型。我的方法的一部分涉及使用多个 NMT 模型一起通信来构建正确的语法模式。我认为 LSTM 很好用，因为训练时间与相当小的数据集和短语的简短无关，但我开始怀疑 Transformer 模型是否会表现得更好。如果有人有建议或想法，请告诉我。    由   提交/u/Neat_Replacement_118   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pp1tu/lstm_vs_transformer_for_lowresource_seq2seq/</guid>
      <pubDate>Sun, 24 Dec 2023 06:06:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何开始学习状态空间模型来理解曼巴这样的模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pn5yh/how_should_i_start_learning_about_state_space/</link>
      <description><![CDATA[我学习深度学习大约一年了，刚刚完成了 Andrew ng 的深度学习专业课程。我正在研究曼巴模型，它看起来真的很有趣，但我对 ssms 真的一无所知，当我尝试进行一些谷歌搜索时，它似乎陷入了控制理论的兔子洞和我从未听说过的事情，所以有人可以让我知道在哪里吗？首先谢谢您！   由   提交/u/Commercial-Fee-6446   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pn5yh/how_should_i_start_learning_about_state_space/</guid>
      <pubDate>Sun, 24 Dec 2023 04:13:48 GMT</pubDate>
    </item>
    <item>
      <title>这些图表是否意味着我的模型过度拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pmtk7/do_these_graphs_mean_my_model_is_overfitting/</link>
      <description><![CDATA[      ​ https://preview.redd.it/fe6duyih068c1.png?width=1000&amp;format=png&amp; ;auto=webp&amp;s=2b9e1f15c245544de00f71514d9f41b648af85d7 https://preview.redd.it/37kovyih068c1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=1eb506cf34d3f18d546d6bc67d8c4a6e9335511 5 https://preview.redd.it/cvsvs1jh068c1.png?width=1000&amp;format =png&amp;auto=webp&amp;s=ea97f1f4913acb8d0a7dde1ab8f835253afa5de4 ​ 我正在训练 SegFromer 进行语义分割，50 个时期后我得到了这些图，我对机器学习仍然是新手，但无论我所知甚少，如果一个模型在训练集上表现良好（低训练损失）但在验证集上表现不佳（高验证损失），那么它就过度拟合了。  非常感谢你们的反馈，非常感谢！   由   提交/u/Hades8800  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pmtk7/do_these_graphs_mean_my_model_is_overfitting/</guid>
      <pubDate>Sun, 24 Dec 2023 03:53:43 GMT</pubDate>
    </item>
    <item>
      <title>如何从零开始学习机器学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18plun0/how_to_learn_machine_learning_from_scratch/</link>
      <description><![CDATA[嗨。所以我对机器学习有一定的了解，但这还不够。我对自己的知识不满意，并觉得自己缺少其中的关键方面。请建议一个涵盖大部分方面的机器学习学习路径，以便我足以解决kaggle问题？   由   提交/u/Suhurth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18plun0/how_to_learn_machine_learning_from_scratch/</guid>
      <pubDate>Sun, 24 Dec 2023 02:56:31 GMT</pubDate>
    </item>
    <item>
      <title>现在的LLM真的是“黑匣子”吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pl1wx/is_it_true_that_current_llms_are_actually_black/</link>
      <description><![CDATA[没有人真正理解 Chatgpt 4 是如何根据某些输入给出输出的。它们是黑匣子有多真实？ 因为我们似乎确实了解输出是如何产生的？    由   提交 /u/wouhf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pl1wx/is_it_true_that_current_llms_are_actually_black/</guid>
      <pubDate>Sun, 24 Dec 2023 02:11:09 GMT</pubDate>
    </item>
    <item>
      <title>IBM Machine Learning with Python 评论：学生的视角</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pjl31/ibm_machine_learning_with_python_review_students/</link>
      <description><![CDATA[ 由   提交/u/Sreeravan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pjl31/ibm_machine_learning_with_python_review_students/</guid>
      <pubDate>Sun, 24 Dec 2023 00:51:28 GMT</pubDate>
    </item>
    <item>
      <title>从哪里开始使用 Wavenet</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pesna/where_to_start_with_wavenet/</link>
      <description><![CDATA[大家好，我需要一些建议。所以我读了 Wavenet 论文，我认为它很有趣。我在最近的论文中看到了这项技术的使用，尤其是此处，它被用作吉他放大器建模的因果版本。 我真的很想实现这些东西，但我是一个完全的初学者。我可以从哪里开始？有没有 github 存储库可以帮助我完成大部分工作？   由   提交 /u/Oboungagungah   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pesna/where_to_start_with_wavenet/</guid>
      <pubDate>Sat, 23 Dec 2023 20:53:33 GMT</pubDate>
    </item>
    <item>
      <title>为医学生学习 AI/ML 的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pe1ne/advice_on_learning_aiml_for_a_medical_student/</link>
      <description><![CDATA[大家好，我是一名医学生。我最近参加了一些关于人工智能/医学的会议，我想我想了解更多。当然，我的主要兴趣是医疗保健系统中的人工智能。最主要的是我不想在不久的将来发现自己毫无准备，我希望能够在时机到来时拥抱新技术并有效地使用它。不幸的是，我没有任何特定的数学/IT 背景，目前我的大部分时间都花在医学上。我知道这听起来很愚蠢，但我是这样想象的：如果我生活在 80 年代，我不会想成为 90 年代的 IT 专家/程序员，但至少想成为一个习惯使用笔记本电脑的人。我应该从哪里开始？谢谢。   由   提交 /u/Evening-Armadillo325    reddit.com/r/learnmachinelearning/comments/18pe1ne/advice_on_learning_aiml_for_a_medical_student/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pe1ne/advice_on_learning_aiml_for_a_medical_student/</guid>
      <pubDate>Sat, 23 Dec 2023 20:17:27 GMT</pubDate>
    </item>
    <item>
      <title>建立直觉：决策树如何压缩图像</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18pd0ks/build_intuition_how_decision_trees_compress_an/</link>
      <description><![CDATA[   我的三分钟视频概述了我所做的事情以及如何创建类似的内容这个你自己：https://youtu.be/pjmgdC6-lSo GIF 下方的详细说明：&lt; /p&gt; 在决策树模型中使用 RGB 与 HSV 颜色模型的并排比较的动画 gif。 您可以使用决策树来压缩图像。如果您的目标是压缩图像，则可以使用库，但我想看看决策树在查看图像时“看到”了什么。 想法如下：训练输入是每个像素的 x、y 位置和颜色通道（对于黑白，只有一个通道）。目标是该像素和通道的值。我没有进行测试/训练分割，因为我不想建立一个模型来预测任何东西，我想要压缩一些东西。 链接  &lt;强&gt;代码： https://jbwhit.github.io/vangoghviz/ YouTube 概述： https://youtu.be/pjmgdC6-lSo &lt; /ul&gt; 如果您有任何疑问，请告诉我！我希望提高此类事情的产出，因此欢迎提供任何反馈。   由   提交/u/Mr-Whitmore   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18pd0ks/build_intuition_how_decision_trees_compress_an/</guid>
      <pubDate>Sat, 23 Dec 2023 19:28:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人用过 fairseq 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18paffj/d_does_anyone_have_used_fairseq/</link>
      <description><![CDATA[我正在寻找教程来了解 fairseq 堆栈以及如何修改或添加新的架构模型 l。有人可以帮助我吗？   由   提交/u/ahsaor8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18paffj/d_does_anyone_have_used_fairseq/</guid>
      <pubDate>Sat, 23 Dec 2023 17:24:52 GMT</pubDate>
    </item>
    <item>
      <title>通过稳定扩散背后的理论学习的最佳资源？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18padzf/best_resources_for_learning_through_theory_behind/</link>
      <description><![CDATA[大家好，在过去的一个月里，我一直在尝试一些稳定扩散模型，以更好地理解它们，这是我的主要爱好和激情就是艺术，它似乎对我作为一名艺术家构成了相当大的威胁，所以我真的很想从根本上理解这些模型。 我有 CS &amp;数学本科生，并在本科期间学习了 3 门 ML 课程，因此我了解感知器、随机森林等基础知识。（尽管老实说，快速简单的复习和林算法复习会很好地作为参考） 我听说吴恩达（Andrew Ng）的课程在这个子项目上受到强烈推荐，但这适用于我吗？或者对于零背景的人来说这更适合吗？ 我通过与理论相关的项目学得最好（我正在研究 Andrej Karpathy 的 Make More 系列以及《Attention is All You Need》论文，它对我有帮助更好地理解论文中概述的理论）因此，如果这些模型有任何类似的东西，我会洗耳恭听。 TLDR;书&amp;对于已经拥有 CS &amp; 基础知识的人来说，了解稳定扩散类型模型架构的课程建议数学本科生   由   提交 /u/Zaverose   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18padzf/best_resources_for_learning_through_theory_behind/</guid>
      <pubDate>Sat, 23 Dec 2023 17:22:46 GMT</pubDate>
    </item>
    <item>
      <title>刚刚开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18p7b8q/just_starting_out/</link>
      <description><![CDATA[[D] 刚刚开始 嘿，大家好，我有一个难得的机会来学习 AI/ML 的东西我公司即将进行的一个软件项目的工作。他们不想雇用新人，而是希望现有员工（我）填补该职位，学习相关知识并进入该职位。我太兴奋了！ TLDR：关于一些很棒的资源的建议，以便更好地理解和实现 ML，请提供，谢谢。 我最近购买了 udemy 课程（ZTM） TensorFlow Google 证书），我已经完成了大约 20%。所以我已经掌握了神经网络的基础知识，现在正在研究分类问题。 我的问题：这个社区是否已经发现或可能建议任何其他令人惊叹的资源？我不想成为黑客。我真的很感兴趣并且想在这方面做得很好。我仍在攻读软件工程学士学位，但它并不是专门针对 ML 的。   由   提交 /u/Bl4ckSt4ff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18p7b8q/just_starting_out/</guid>
      <pubDate>Sat, 23 Dec 2023 14:55:11 GMT</pubDate>
    </item>
    <item>
      <title>拉里·沃瑟曼 (Larry Wasserman) 撰写的《所有统计》学习小组书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18p6y2a/book_learning_group_on_all_of_statistics_by_larry/</link>
      <description><![CDATA[是否有人对专注于Larry Wasserman 的所有统计数据的图书小组感兴趣    由   提交/u/supervised-learning  /u/supervised-learning  reddit.com/r/learnmachinelearning/comments/18p6y2a/book_learning_group_on_all_of_statistics_by_larry/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18p6y2a/book_learning_group_on_all_of_statistics_by_larry/</guid>
      <pubDate>Sat, 23 Dec 2023 14:36:00 GMT</pubDate>
    </item>
    <item>
      <title>拓扑数据分析，第 1 部分，流形学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18p5f7y/topological_data_analysis_part_1_manifold_learning/</link>
      <description><![CDATA[   /u/fbeilstein  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18p5f7y/topological_data_analysis_part_1_manifold_learning/</guid>
      <pubDate>Sat, 23 Dec 2023 13:13:01 GMT</pubDate>
    </item>
    <item>
      <title>Daniel Bourke 在一天内学习 PyTorch 进行深度学习，有什么好处吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18p13wt/daniel_bourke_learn_pytorch_for_deep_learning_in/</link>
      <description><![CDATA[有没有人看过 Daniel Bourke 的 YouTube 视频 - “一天学习 PyTorch 进行深度学习。”字面意思。”？ 它是一年前发布的，有 100 万次浏览，所以我想这一定是对 PyTorch 的一个很好的介绍。我知道这个领域的发展绝对是疯狂的快，但是如果有人今天开始的话，一年前的 PyTorch 的一些东西仍然有效吗？或者是否有更好的替代方案可以提供更多最新的课程？  https://www.youtube.com/watch?v=Z_ikDlimN6A   由   提交 /u/DontKnowAGoodNames   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18p13wt/daniel_bourke_learn_pytorch_for_deep_learning_in/</guid>
      <pubDate>Sat, 23 Dec 2023 08:14:17 GMT</pubDate>
    </item>
    </channel>
</rss>