<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 10 Sep 2024 06:23:15 GMT</lastBuildDate>
    <item>
      <title>如何在 C++ 代码中打开 .onnx 文件</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fdb3l6/how_to_open_onnx_file_in_c_code/</link>
      <description><![CDATA[我想在我的 C++ 代码中读取 .onnx 文件。现在，我已经研究了 onnxruntime 库几个小时，似乎无法在我的 C++ 代码中将其用作标头。我正在使用 macOS。有人可以提供一些关于如何在 C++ 中读取和解析 onnx 文件的指南吗？ 我想将我的权重和偏差存储在 onnx 文件中，而不使用任何图形结构。我已经使用 python 完成了此操作。我现在想读取 C++ 文件中的值。    提交人    /u/BarNo8082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fdb3l6/how_to_open_onnx_file_in_c_code/</guid>
      <pubDate>Tue, 10 Sep 2024 06:09:46 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么高级pytorch的项目或者课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fdag73/are_there_any_projects_or_courses_for_advanced/</link>
      <description><![CDATA[现在我正在尝试了解分布式训练、融合内核、自定义自动求导函数和 torch.compile。但似乎没有整合的资源，而且我一直在阅读框架和 pytorch 文档的源代码。有人有这方面的资源吗？ 编辑：我的用例是出于个人兴趣，并可能改进开源训练框架。我真的很喜欢 unsloth、flash_attn 和 liger_kernel 的作品，尽管它们从根本上非常不同，一个是框架，两个是内核，但我喜欢它可以帮助用户降低 VRAM 和计算能力。    提交人    /u/Wheynelau   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fdag73/are_there_any_projects_or_courses_for_advanced/</guid>
      <pubDate>Tue, 10 Sep 2024 05:23:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 K 均值和低秩分解探索 LLM 参数压缩和加速</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd8pi6/exploring_llm_parameter_compression_and/</link>
      <description><![CDATA[考虑到预训练的LLM中全连接参数数量较多，我想知道是否可以在进行计算之前使用k-means对它们进行分组。具体做法如下：  使用k-means对参数进行分组。得到的聚类中心将保存为新的参数，无监督聚类结果将保存为索引。 原来的乘法可以替换为：WX = CX[index]  此外，对于误差项，可以在微调时添加一个可训练参数E，使得WX = CX[index] + E。 这类似于将W分解为低秩矩阵和误差项。 使用RPCA也可以探索类似的方法，将W分解为低秩矩阵和稀疏矩阵。 这种方法可以减少参数数量。您认为这个想法可行吗，或者已经有相关工作了？    submitted by    /u/SpecialImpressive608   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd8pi6/exploring_llm_parameter_compression_and/</guid>
      <pubDate>Tue, 10 Sep 2024 03:37:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么同一个 token 的位置编码不一致？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd8j0p/why_is_positional_encoding_for_the_same_token_not/</link>
      <description><![CDATA[我理解 transformer 中的注意力机制无法区分每个 token 的顺序，并且每个 token 具有不同的位置值是有道理的，但为什么 token 中的位置值不同（相同实例，因此位置相同）？向量内标量的较大差异会使位置更加明显，但在我看来，这会扭曲先前的嵌入值。神经网络可以学习位置值，但它也增加了复杂性，对吗？那么为什么我们不向向量添加标量呢？ https://datascience.stackexchange.com/questions/51065/what-is-the-positional-encoding-in-the-transformer-model 我也读过这个，但不太明白第一个答案的修正    提交人    /u/TFW_YT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd8j0p/why_is_positional_encoding_for_the_same_token_not/</guid>
      <pubDate>Tue, 10 Sep 2024 03:27:38 GMT</pubDate>
    </item>
    <item>
      <title>[PySpark/Optuna] Optuna 的并行化是否会干扰 PySpark？ 管理跨工作器的并行进程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd8297/pysparkoptuna_is_optunas_parallelization/</link>
      <description><![CDATA[大家好，我正在使用 Optuna 进行超参数优化和使用 PySpark 进行并行化训练，以训练产品级时间序列模型。我在 Optuna 中设置了 n_jobs &gt; 1，以启用优化过程的并行化。 在 PySpark 方面，我使用 sales_part.groupby([&#39;product_id&#39;]).applyInPandas(lambda df: running_optuna_optimization_forecasting(df, major_sales_events), schema=schema) 在各个工作器之间分配模型训练。 我的问题是：我是否应该担心这两个并行机制同时运行？具体来说，Optuna 的并行进程如何在 Spark 工作器之间分布？我有 4 个工作器，每个工作器有 8 个核心。系统将如何管理这些进程？希望得到一些见解！ 以下是代码： def running_optuna_optimization_forecasting(product_pd, Promotion): # 步骤 1：删除异常值 lower, upper = IQR_outliers_dectection(product_pd.y) product_pd_outliers_rmd = IQR_outliers_removal(lower, upper, product_pd) # 步骤 2：运行 Optuna 优化 study = optuna.create_study(direction=&quot;minimize&quot;) study.optimize(lambda trial: objective(trial, product_pd_outliers_rmd, Promotion), n_trials=25, n_jobs=4) # 从 n_jobs=1 开始以确保稳定性 尝试： best_param = study.best_params best_performance = study.best_trial.value model = Prophet( interval_width=0.95, holidays=promotion, growth=best_param[&#39;growth&#39;], yearly_seasonality=best_param[&#39;yearly_seasonality&#39;], changepoint_prior_scale=best_param[&#39;changepoint_prior_scale&#39;], holidays_prior_scale=best_param[&#39;holidays_prior_scale&#39;], seasonality_mode=best_param[&#39;seasonality_mode&#39;], seasonality_prior_scale=best_param[&#39;seasonality_prior_scale&#39;], changepoint_range=best_param[&#39;changepoint_range&#39;] ) except 例外情况如下： best_param = {}&gt; best_performance = 99999 model = Prophet( interval_width=0.95, holidays=promotion, yearly_seasonality = True) model.fit(product_pd_outliers_rmd) future_pd = model.make_future_dataframe( periods=12, freq=&#39;W-SAT&#39;, include_history=True ) forecast_pd = model.predict(future_pd) # 步骤 7：向预测添加元数据 (product_id、best_param、best_performance) forecast_pd[&quot;product_id&quot;] = product_pd_outliers_rmd[&#39;product_id&#39;].iloc[0] forecast_pd[&quot;best_param&quot;] = json.dumps(best_param) forecast_pd[&quot;best_performance&quot;] = best_performance # 步骤 8：连接原始数据 (ds, y) 进行比较 st_pd = product_pd[[&#39;ds&#39;, &#39;y&#39;]] forecast_pd = Forecast_pd.join(st_pd.set_index(&#39;ds&#39;), on=&#39;ds&#39;, how=&#39;left&#39;) return Forecast_pd[[&#39;product_id&#39;, &#39;ds&#39;, &#39;trend&#39;, &#39;trend_lower&#39;, &#39;trend_upper&#39;, &#39;additive_terms&#39;, &#39;additive_terms_lower&#39;, &#39;additive_terms_upper&#39;, &#39;april_VIB_sale&#39;, &#39;april_VIB_sale_lower&#39;, &#39;april_VIB_sale_upper&#39;, &#39;august_sale&#39;, &#39;august_sale_lower&#39;, &#39;august_sale_upper&#39;, &#39;christmas_sale&#39;, &#39;christmas_sale_lower&#39;, &#39;christmas_sale_upper&#39;, &#39;holidays&#39;, &#39;holidays_lower&#39;, &#39;holidays_upper&#39;， &#39;yearly&#39;，&#39;yearly_lower&#39;，&#39;yearly_upper&#39;， &#39;multiplicative_terms&#39;，&#39;multiplicative_terms_lower&#39;，&#39;multiplicative_terms_upper&#39;， &#39;y&#39;，&#39;yhat&#39;，&#39;yhat_upper&#39;，&#39;yhat_lower&#39;， &#39;best_param&#39;，&#39;best_performance&#39;]]    提交人    /u/AffectionatePut7138   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd8297/pysparkoptuna_is_optunas_parallelization/</guid>
      <pubDate>Tue, 10 Sep 2024 03:02:08 GMT</pubDate>
    </item>
    <item>
      <title>具有一个主导变量或仅 1 个变量的 ML 模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd81d1/ml_model_with_a_dominant_or_just_1_variable/</link>
      <description><![CDATA[您能否推荐一些资源，介绍使用具有主导变量的机器学习模型的效果，这些模型可以解释目标中的大部分方差，或者只用一个变量构建的模型？具体来说，我有兴趣了解这些方法的潜在缺点、偏见或局限性。    提交人    /u/ahmdvnrln   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd81d1/ml_model_with_a_dominant_or_just_1_variable/</guid>
      <pubDate>Tue, 10 Sep 2024 03:00:54 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么方法可以让决策树更好地检测和处理交互效应？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd6wcr/are_there_any_ways_to_make_decision_trees_detect/</link>
      <description><![CDATA[我相信神经网络在处理包含交互效应和非线性数据时表现更好。然而研究表明，树往往更适合表格数据。当怀疑表格数据具有交互效应并且可能存在大量非线性关系时，有什么方法可以使树表现更好？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd6wcr/are_there_any_ways_to_make_decision_trees_detect/</guid>
      <pubDate>Tue, 10 Sep 2024 02:02:15 GMT</pubDate>
    </item>
    <item>
      <title>是否值得“剔除”权重而不是修剪或提前停止</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd565c/is_it_worth_weeding_weights_instead_of_pruning_or/</link>
      <description><![CDATA[在 pytorch transformer 模型中使用 penn treebank 数据集进行下一个 token 预测： 经过几千个 epoch 后，有效损失不再变好，要么趋于平稳，要么逐渐恶化。 此时，我尝试循环遍历所有嵌入，并随机重置每个单词最弱或最没用的 30% 权重（“最弱”在这里表示最低梯度）。然后继续训练。 正如预期的那样，一开始情况变得更糟（损失更高），但随着有效损失再次开始下降，它最终变得比重置权重之前的水平更低，达到一个新的整体低点。然后，当它再次停止下降时，重复该过程以找到新的较低点。它似乎至少连续几次起作用，但毫无疑问，它可以被推到多远是有限制的。 这是一个有名字的众所周知的东西吗？我找不到任何关于它的信息，除了你可以称它为一种“正则化”，但我没有看到任何地方提到过这种特定的方法。在我的脑海里，我一直称它为“除草和重新播种”，因为与修剪不同，它不会减小模型的大小（因为修剪植物会减小植物的大小），但如果我们将权重集合视为花园，它会去除一些不受欢迎的元素，同时为更好的东西腾出空间来代替它们生长。    提交人    /u/StrategicHarmony   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd565c/is_it_worth_weeding_weights_instead_of_pruning_or/</guid>
      <pubDate>Tue, 10 Sep 2024 00:36:04 GMT</pubDate>
    </item>
    <item>
      <title>需要指导！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd4b5o/guidence_needed/</link>
      <description><![CDATA[所以在接下来的一个月里，我每天大约有 6 小时的学习时间！这样我就有大约 360 小时了。您认为我应该做什么/练习才能充分利用这段时间！如果您的建议需要更多时间，我愿意学习更多。背景 - 我今年 28 岁，男性（即将年满 29 岁），我刚回到学校攻读计算机硕士学位。在此之前，我在教书（我也创办了两家公司，但都没有成功）。我想充分利用这段时间，我愿意努力工作，我只是需要指导。    提交人    /u/Good-At-SQL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd4b5o/guidence_needed/</guid>
      <pubDate>Mon, 09 Sep 2024 23:54:16 GMT</pubDate>
    </item>
    <item>
      <title>解释反向传播的精彩视频</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd3d8q/great_vid_explaining_backpropogation/</link>
      <description><![CDATA[刚刚看完这个，虽然对某些人来说可能很基础，但我真的很喜欢他呈现它的方式！ https://youtu.be/SmZmBKc7Lrs?si=UPML4JC-qupa9V9J    提交人    /u/Status-Shock-880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd3d8q/great_vid_explaining_backpropogation/</guid>
      <pubDate>Mon, 09 Sep 2024 23:09:56 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的 dropout 正则化是否会意外地使不重要的特征看起来相关？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fd08jv/could_dropout_regularization_in_a_neural_network/</link>
      <description><![CDATA[纯粹是出于好奇而问（即我没有理由认为是这种情况，但想听听意见）。由于 dropout 往往会在学习过程中减少共同适应，它是否可能使网络发现非信息性特征似乎具有信息性，因为 dropout 似乎会使网络在前向传播过程中更难提取明确有用的“路径”？基本上，我在问，如果你让网络更难学习，它是否会开始尝试从任何可用的东西（即非信息性特征）中学习？    提交人    /u/learning_proover   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fd08jv/could_dropout_regularization_in_a_neural_network/</guid>
      <pubDate>Mon, 09 Sep 2024 20:55:00 GMT</pubDate>
    </item>
    <item>
      <title>我的模型是否过度拟合？？？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fcpkki/is_my_model_overfitting/</link>
      <description><![CDATA[      大家好，数据科学家！ 我希望得到有关我当前模型的反馈。我正在研究逻辑回归，并查看迄今为止使用的学习曲线和评估指标。我的数据集中有一个特征与目标变量具有非常高度相关性。  我应用了正则化（在逻辑回归中）来解决这个问题，它将性能从 23.3 降低到 9.3 左右（大概如此，这是一个很长的小数）。该特征在高度相关方面是有意义的，但根据学习曲线，该模型的性能仍然看起来不切实际的高。 现在，需要明确的是，我还没有完成 - 这只是在客户级别。我计划将客户模型的预测值用作基于交易的模型中的特征，以更深入地探索客户行为。 这是我的担忧：我担心该模型过度依赖这个单一特征。当我删除它时，性能会变得更糟。其他功能确实会影响模型，但这个似乎占主导地位。 我应该继续包含此功能吗？或者我应该更加谨慎地依赖它？任何建议或建议都会非常有帮助。 谢谢！    提交人    /u/SaraSavvy24   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fcpkki/is_my_model_overfitting/</guid>
      <pubDate>Mon, 09 Sep 2024 13:35:15 GMT</pubDate>
    </item>
    <item>
      <title>如何找到合适的 CNN 架构？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fcp4u5/how_do_you_find_a_suitable_cnn_architecture/</link>
      <description><![CDATA[大家好！ 我目前正在开展一个项目，对显微照片中的缺陷图像进行分类。不幸的是，我对机器学习几乎没有实际经验。我知道有不同的预训练网络，例如 ResNet、VGG、AlexNet 等，但这些架构中的每一个对数据（在输入层中）都有特定的要求。我的数据为 224x224x1（灰度）。显然，如果数据与训练数据的格式相同，则使用预训练网络是最有意义的。但是，我找不到 224x224x1 的网格。在这种情况下，您该怎么做？我知道您也可以从原则上调整架构并仅重新训练部分网络等，但感觉现在我可以尝试的方法不计其数。有没有什么好的资源可以介绍这一点，或者您有什么提示，如果您是我，您会怎么做？是否存在最先进的方法或最佳实践？ 我很感激任何建议！    提交人    /u/hungry_cowboy   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fcp4u5/how_do_you_find_a_suitable_cnn_architecture/</guid>
      <pubDate>Mon, 09 Sep 2024 13:13:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 检测脑肿瘤</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fcoy8b/brain_tumor_detection_using_cnn/</link>
      <description><![CDATA[大家好！我很高兴与大家分享我的深度学习项目，我开发了一个卷积神经网络 (CNN)，用于从 MRI 图像中检测脑肿瘤。该模型不仅可以识别肿瘤的存在，还可以对检测到的肿瘤类型进行分类。您可以在此处查看 GitHub 上的项目和代码：https://github.com/Mizab1/Brain-Tumor-Detection-using-CNN。  我很乐意听到您对项目的反馈和改进建议！让我知道您的想法。  如果您觉得它很有趣，请在 repo 上加一颗星 (⭐)，我们将不胜感激！    提交人    /u/Mizab1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fcoy8b/brain_tumor_detection_using_cnn/</guid>
      <pubDate>Mon, 09 Sep 2024 13:04:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>