<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 29 Mar 2024 21:12:39 GMT</lastBuildDate>
    <item>
      <title>可视化卷积神经网络真正学习的方式和内容</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqxndw/visualizing_how_and_what_convolutional_neural/</link>
      <description><![CDATA[   /u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqxndw/visualizing_how_and_what_convolutional_neural/</guid>
      <pubDate>Fri, 29 Mar 2024 19:34:58 GMT</pubDate>
    </item>
    <item>
      <title>了解 PyTorch 模型中的批处理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqxkfo/understanding_batching_in_pytorch_models/</link>
      <description><![CDATA[我有以下模型，它构成了我的整个模型管道中的步骤之一： import torch import torch. nn 作为 nn 类 NPB(nn.Module): def __init__(self, d, nhead, num_layers, dropout=0.1): super(NPB, self).__init__() self.te = nn.TransformerEncoder( nn.TransformerEncoderLayer(d_model) =d, nhead=nhead, dropout=dropout, batch_first=True), num_layers=num_layers, ) self.t_emb = nn.Parameter(torch.randn(1, d)) self.L = nn.Parameter(torch.randn( 1, d)) self.td = nn.TransformerDecoder( nn.TransformerDecoderLayer(d_model=d, nhead=nhead, dropout=dropout, batch_first=True), num_layers=num_layers, ) self.ffn = nn.Linear(d, 6 ) defforward(self, t_v, t_i): print(&quot;------------------------ t_v, t_i ----------------- ”) print(&#39;t_v: &#39;, tuple(t_v.shape)) print(&#39;t_i: &#39;, tuple(t_i.shape)) print(“---------------- t_v + t_i + t_emb -----------------&quot;) _x = t_v + t_i + self.t_emb print(tuple(_x.shape)) print(&quot;--- ------------ te ---------------&quot;) _x = self.te(_x) print(tuple(_x.shape)) print( “-------------- td ---------------”) _x = self.td(self.L, _x) print( tuple(_x.shape)) print(&quot;---------------- ffn ---------------&quot;) _x = self.ffn (_x) print(tuple(_x.shape)) return _x  这里 t_v 和 t_i 是来自早期编码器块的输入。我将它们作为 (4,256) 的形状传递，其中 256 是特征数量，4 是批量大小。 t_emb 是时间嵌入。 L 表示学习矩阵，表示查询的嵌入。我使用以下代码测试了此模块块： t_v = torch.randn((4,256)) t_i = torch.randn((4,256)) npb = NPB(d=256, nhead=8 , num_layers=2) npb(t_v, t_i)  输出： =============== NPB =============== -------------- t_v, t_i ---------------- - t_v: (4, 256) t_i: (4, 256) -------------- t_v + t_i + t_emb --------------- -- (4, 256) --------------- 特 --------------- (4, 256) -------- -------- td --------------- (1, 256) ------------------ ffn ----- ---------- (1, 6)  我期望输出的形状应为 (4,6)，6 个值对于大小为 6 的批次中的每个样本。但输出的大小为(1,6)。经过大量调整后，我尝试将 t_emb 和 L 形状从 (1,d) 更改为 (4,d)&lt; /code&gt;，因为我不希望所有采样共享这些变量（通过广播： self.t_emb = nn.Parameter(torch.randn(4, d)) # [n, d] = [4, 256] self.L = nn.Parameter(torch.randn(4, d))  这给出了所需的形状输出 (4,6: &lt;前&gt;&lt;代码&gt;--------------- t_v, t_i ----------------- t_v: (4, 256) t_i : (4, 256) --------------- t_v + t_i + t_emb ----------------- (4, 256) -- -------------- te --------------- (4, 256) -------------- td --------------- (4, 256) --------------- ffn -------------- - (4, 6)  我有以下疑问： Q1。到底为什么要更改 L 和从 (1,d) 到 (4,d) 的 t_emb 形状有效吗？为什么它不适用于 (1,d ） 通过广播？ Q2. 我是否以正确的方式进行批处理，或者输出是人为正确的，而在幕后它所做的事情与我预期的不同（预测 6 个值）对于大小为 4) 的批次中的每个样本？   由   提交 /u/Tiny-Entertainer-346   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqxkfo/understanding_batching_in_pytorch_models/</guid>
      <pubDate>Fri, 29 Mar 2024 19:30:24 GMT</pubDate>
    </item>
    <item>
      <title>谁能列出一些好的 udemy 机器学习课程。它应该包括有利于学习机器学习所需的数学或统计学的课程。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqwsjo/can_anyone_list_good_udemy_courses_for_machine/</link>
      <description><![CDATA[正如上面所说。谢谢你的帮助。    由   提交 /u/Confident-Ad4064    reddit.com/r/learnmachinelearning/comments/1bqwsjo/can_anyone_list_good_udemy_courses_for_machine/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqwsjo/can_anyone_list_good_udemy_courses_for_machine/</guid>
      <pubDate>Fri, 29 Mar 2024 18:43:00 GMT</pubDate>
    </item>
    <item>
      <title>无论输入分辨率如何，自定义稳定扩散实现始终输出 512*512 图像...</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqvxfd/custom_stable_diffusion_implementation_always/</link>
      <description><![CDATA[我正在做一个自定义修复应用程序，我几乎得到了所需的结果，除了管道对象输出 512*512 图像（无论什么分辨率）我进去了。我正在 CPU 上运行这个。  这是我认为相关的代码： class CustomDiffuser: def __init__(self,provider:Literal[&#39;CPUExecutionProvider&#39;, &#39;DmlExecutionProvider&#39;]=&#39;CPUExecutionProvider&#39;) ： self.pipe_text2image = 无 self.pipe_inpaint = 无 self.image = 无 self.sam = 无 self.provider = 提供商 def load_model_for_inpainting( self, 路径: str = &#39;../stable_diffusion_onnx_inpainting&#39;, safety_checker=None ): self.pipe_inpaint = OnnxStableDiffusionInpaintPipeline.from_pretrained(path,provider=self.provider,revision=&#39;onnx&#39;,safety_checker=safety_checker) def inpaint_with_prompt(self, image: cv2.typing.MatLike | Image.Image, mask: cv2.typing.MatLike | Image.图像，高度：int，宽度：int，提示：str = &#39;&#39;，负数：str = &#39;&#39;，步骤：int = 10，cfg：float = 7.5，噪音：float = 0.75 ）：pipe = self.pipe_inpaint image = image.resize（（宽度，高度）） mask = mask.resize（（宽度，高度））output_image = 管道（提示，图像，掩码，#strength =噪声，guiding_scale = cfg）返回output_image扩散器= CustomDiffuser（&#39;CPUExecutionProvider&#39; ) diffuser.load_model_for_inpainting(&#39;C:/path/to/repository/stable_diffusion_onnx_inpainting&#39;) 输出 = diffuser.inpaint_with_prompt( Image.open(image_path), Image.fromarray(headless_selfie_mask.astype(np.uint8)), 576, #高度优先384, &#39;一张穿着达斯维德服装的男人的照片，全身照，前视图，光剑&#39;, &#39;&#39; )  如果有帮助的话，我正在遵循本指南：  https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674   由   提交/u/cantbebothered67836   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqvxfd/custom_stable_diffusion_implementation_always/</guid>
      <pubDate>Fri, 29 Mar 2024 18:08:06 GMT</pubDate>
    </item>
    <item>
      <title>关于攻读计算机科学/机器学习/统计学硕士学位的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqtp47/advice_on_pursuing_a_masters_degree_in_csmlstats/</link>
      <description><![CDATA[就上下文而言，我将于 12 月毕业，获得计算机科学和数学学士学位，平均绩点很高，没有研究经验，课外活动也很一般。我在一家信誉良好的公司完成了两次夏季 SWE 实习，毕业后该公司为我提供了全职 SWE 职位。但是，我不想在 SWE 从事职业。该公司确实提供了 ML 方面的全职职位，我对此很感兴趣，但我需要申请。  最近，我被 ML/AI 职业所吸引，无论是机器学习工程师、数据科学家还是类似的职位。然而，关于攻读硕士学位是否对我的情况有利，我遇到了相互矛盾的意见，特别是因为某些职位可能不需要硕士学位，而其他职位则需要博士学位——我不想这样做 我应该攻读 CS/ML/Stats 硕士学位吗？如果是，您会推荐哪一所？有什么具体的项目/大学吗？另外，接受全日制 SWE/ML 录取并攻读在线硕士学位（例如佐治亚理工学院的 OMS）是否明智？ 您可以分享的任何想法或经验都会很棒。谢谢！   由   提交/u/TyIsOP   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqtp47/advice_on_pursuing_a_masters_degree_in_csmlstats/</guid>
      <pubDate>Fri, 29 Mar 2024 16:36:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SST-2 和 CoLA 常用数据集进行去偏？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqt85p/why_are_sst2_and_cola_commonly_used_datasets_for/</link>
      <description><![CDATA[为什么 SST-2、CoLA 和模型通常用于测量偏差和随后的去偏差？它与 GLUE 基准被广泛接受并用于研究目的相关吗？由于 SST-2 特别包含电影评论，消除此类数据的预期收益是什么？对具有更多固有偏差的数据集进行去偏是不是合理的（尽管我假设哪些数据集有偏差，一开始并不明显）？ 我目前的理解是，无论是否经过训练的模型和/或无论数据集是否存在偏差，去偏差都是争取更加公平的重要一步。因此，SST-2 和 CoLA 提供了具有广泛偏差和待研究接口的通用数据集。 有人基本上告诉我，SST-2 和 CoLA 对于去偏差没有意义，尽管它是在大量论文中使用，这让我产生了疑问......   由   提交/u/EducationalApple7076   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqt85p/why_are_sst2_and_cola_commonly_used_datasets_for/</guid>
      <pubDate>Fri, 29 Mar 2024 16:17:07 GMT</pubDate>
    </item>
    <item>
      <title>2024 年学习深度学习数学的最佳书籍？古德费罗的书还有意义吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqspec/best_book_to_learn_dl_math_in_2024_is_goodfellow/</link>
      <description><![CDATA[我想在接下来的几个月里自学深度学习。我将参加安德鲁·吴的课程（仅用于证书），但主要想从一本厚重的数学书中学习。古德费洛的书是一个不错的（不是过时的）选择吗？如果没有，那么我可以尝试什么？ 我的背景是 EE，并且我学过线性代数、统计、差分方程等课程。   由   提交 /u/BadMeditator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqspec/best_book_to_learn_dl_math_in_2024_is_goodfellow/</guid>
      <pubDate>Fri, 29 Mar 2024 15:55:14 GMT</pubDate>
    </item>
    <item>
      <title>我建立了一个网站来分享我的研究成果和一系列受两分钟论文启发的笔记本。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqrgjh/i_built_a_website_to_share_my_research_and_a/</link>
      <description><![CDATA[ 由   提交 /u/camp4climber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqrgjh/i_built_a_website_to_share_my_research_and_a/</guid>
      <pubDate>Fri, 29 Mar 2024 15:03:16 GMT</pubDate>
    </item>
    <item>
      <title>BART 模型解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqps4z/bart_model_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了BART模型的架构以及它是如何预训练的。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqps4z/bart_model_explained/</guid>
      <pubDate>Fri, 29 Mar 2024 13:50:51 GMT</pubDate>
    </item>
    <item>
      <title>关于云嵌入的从业者教程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqow5k/a_practitioners_tutorial_on_embeddings_on_cloud/</link>
      <description><![CDATA[大家好，由于最近嵌入研究的步伐，我刚刚更新了 我之前写过的关于词嵌入的博客系列：如何选择和评估预训练的嵌入、如何有效地部署它们、如何在 AWS 上选择用于 RAG 的 vectorDB案例……虽然技术性稍强并且涵盖了很大的领域，但它是为从业者/构建者设计的，因此希望可以访问。它附带一个存储库，我还在其中尝试了云上词嵌入的其他方面。希望这有帮助！   由   提交 /u/Daddouche   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqow5k/a_practitioners_tutorial_on_embeddings_on_cloud/</guid>
      <pubDate>Fri, 29 Mar 2024 13:09:19 GMT</pubDate>
    </item>
    <item>
      <title>房价预测高级回归笔记本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqog0x/notebook_on_house_price_prediction_advanced/</link>
      <description><![CDATA[https ://www.kaggle.com/code/souravhada/house-price-advanced-regression-techniques  这是我在 Kaggle 上的房价预测高级回归技术的笔记本，我的得分使用 GridsearchCV 后 Kaggle 没有改进，这使我的计算时间从 2 分钟增加到 43 分钟（使用 GPU）。关于如何改进这一点有什么建议吗？我应该从笔记本中删除 GridSearch 吗？另外，当您在那里时，如果您认为笔记本不错，请投票。   由   提交/u/WaveAdministrative36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqog0x/notebook_on_house_price_prediction_advanced/</guid>
      <pubDate>Fri, 29 Mar 2024 12:47:56 GMT</pubDate>
    </item>
    <item>
      <title>英国ML博士申请</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqmwf4/ml_phd_applications_in_the_uk/</link>
      <description><![CDATA[现在进入美国顶尖学校的 ML 博士项目非常困难，主要是因为你需要在大型会议上发表论文才能被考虑。但是像牛津、剑桥、伦敦大学学院或爱丁堡这样的地方呢？ 我本科读的是数学，所以我没有太多发表论文的机会。现在，我将从今年九月开始在牛津攻读计算机科学硕士学位。但问题是：会议论文的截止日期意味着我必须在有机会发表任何东西之前申请博士学位课程。我的硕士学位是为了在花大量现金申请博士学位之前先写出一些论文吗？攻读机器学习博士学位的数学毕业生或申请英国项目的人的任何建议或故事都很棒。   由   提交 /u/Trick_Hovercraft3466   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqmwf4/ml_phd_applications_in_the_uk/</guid>
      <pubDate>Fri, 29 Mar 2024 11:26:31 GMT</pubDate>
    </item>
    <item>
      <title>有什么理由不对每个 ML 项目使用 PyTorch（而不是 F.e Scikit）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</link>
      <description><![CDATA[由于神经网络的灵活性，是否有充分的理由在某种情况下不使用它们？您可以构建线性回归、逻辑回归和其他简单模型，以及集成模型。当然，决策树不会成为等式的一部分，但在我看来，无论如何，它们相比之下往往表现不佳。  虽然使用 PyTorch 设置神经网络可能需要多花 1 分钟，但灵活性是无与伦比的，无论如何，项目的未来可能会需要这种灵活性。当然，如果你只是创建一个回归图，那就有点矫枉过正了，但如果你正在构建一个实际的模型？ 我问这个问题的原因很简单，因为我已经开始获取神经网络解决方案每个新项目都会逐渐增加，因为它往往会产生更好的性能，并且可以灵活地进行正则化以避免过度拟合   由   提交/u/cajmorgans  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</guid>
      <pubDate>Fri, 29 Mar 2024 06:33:04 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 竞赛中使用 ChatGPT 编写代码是否合乎道德且可观？或者用它来微调模型。我不会复制任何人的笔记本或提交内容，只是使用人工智能为我编写函数和代码片段。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</link>
      <description><![CDATA[ 由   提交/u/WaveAdministrative36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</guid>
      <pubDate>Fri, 29 Mar 2024 06:10:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</link>
      <description><![CDATA[嗨，我是一名本科生，希望创建一个像样的项目来放入我的简历中，正在寻求任何想法/相关主题那些公司在寻找什么？我还想在 ML/AI/GenAI 领域获得实习机会，所以我很难找到一个令人印象深刻/展示我技能的项目。任何建议/帮助将不胜感激。  我在 Python 和 ML 方面相当不错，而且我一直在练习它，我只是在努力想出一个将所有内容联系在一起并适用于 ML 的当前趋势的好项目场地。    由   提交/u/Noodle___13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</guid>
      <pubDate>Fri, 29 Mar 2024 00:55:22 GMT</pubDate>
    </item>
    </channel>
</rss>