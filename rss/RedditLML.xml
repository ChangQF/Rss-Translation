<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 13 Aug 2024 06:22:58 GMT</lastBuildDate>
    <item>
      <title>我的 2012 Macbook Pro 是否兼容我开始学习 ML 所需的一切？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1er0ovn/is_my_2012_macbook_pro_going_to_be_compatible/</link>
      <description><![CDATA[我有一台 2012 年末的 13 英寸 MacBook Pro，运行 macOS Catalina。 这足以舒适地运行 Pytorch 以及学习 ML/AI 所需的一切吗？    提交人    /u/bhadrasub   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1er0ovn/is_my_2012_macbook_pro_going_to_be_compatible/</guid>
      <pubDate>Tue, 13 Aug 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>从基础到高级学习机器学习的最佳途径在哪里？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1er0eci/where_is_the_best_way_to_learn_machine_learning/</link>
      <description><![CDATA[你好！我想学习很多关于机器学习的知识，有没有网站或论文可以让我阅读来练习和学习机器学习？我更喜欢免费的，但如果需要付费并且最适合学习，那为什么不呢？无论如何，任何能帮助我开始学习机器学习之旅的东西我都会很感激！谢谢！！！    提交人    /u/Rocksaz_Angeles   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1er0eci/where_is_the_best_way_to_learn_machine_learning/</guid>
      <pubDate>Tue, 13 Aug 2024 05:57:24 GMT</pubDate>
    </item>
    <item>
      <title>帮助用 C++ 实现 LLM</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqzbhx/help_on_implementing_llms_in_c/</link>
      <description><![CDATA[  由    /u/AffectionateCat4482  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqzbhx/help_on_implementing_llms_in_c/</guid>
      <pubDate>Tue, 13 Aug 2024 04:49:08 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程参数调整</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqz3eh/gaussian_process_parameter_tuning/</link>
      <description><![CDATA[大家好， 我正在使用 GPflow 包为包含 150 个样本的数据集开发高斯过程 (GP) 回归模型。我需要使用重复的 k 倍交叉验证来评估此模型。这是我目前的方法：  初始分割：我将数据集分割为训练集 (80) 和测试集 (20)。 内核优化：我在训练集上使用 (gpflow.optimizers.Scipy) 来查找并保存优化的内核。 交叉验证：然后，我使用保存的优化内核对整个数据集运行重复的 k 倍交叉验证（splits= 5 和 repeats=3）。 最终模型：如果交叉验证的性能令人满意，我将使用优化的内核在完整数据集上训练最终模型，并保存此模型以供将来预测。  我是机器学习和高斯过程的新手，我正在尝试使用 k 倍将此 GP 模型与其他模型（如随机森林）的性能进行比较交叉验证。  这种方法是评估高斯过程回归模型的正确方法吗？ 我应该考虑哪些改进或最佳实践？ 如果我必须在 k 倍交叉验证的每一倍内执行优化，我应该如何为最终模型选择最佳超参数？我最初选择了训练测试分割以节省时间，但我愿意接受更有效的方法。  我很感激您能提供的任何建议！ 提前致谢！    提交人    /u/pika_ha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqz3eh/gaussian_process_parameter_tuning/</guid>
      <pubDate>Tue, 13 Aug 2024 04:35:52 GMT</pubDate>
    </item>
    <item>
      <title>格拉斯哥（苏格兰）语音助手项目故事</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqz2a3/glaswegianscottish_voice_assistant_project_story/</link>
      <description><![CDATA[在过去的 4 个月里，我和一位格拉斯哥本地人一直在创建一个数据集，其中包含带有该口音的人的音频，并将其转录，以便我们可以训练语音助手并可能改进 Siri 等助手。 数据集链接：https://huggingface.co/datasets/divakaivan/glaswegian_audio 我们设法收集并转录了 120 分钟的音频。听起来可能不多，但这是手动工作，因为语音识别软件不能很好地理解口音。 使用该数据集，我们创建了一个用于转录的 AI 模型。这是一个演示：https://huggingface.co/spaces/divakaivan/glaswegian-whisper 您可以给它任何音频/让它录制您的声音，它会将其转录。它可以用于 YouTube 视频字幕、会议转录，作为语音助手模型的一部分。 虽然我们制作了一个可以更好地将格拉斯哥语音翻译成文本的模型，但我们想尝试一下“格拉斯哥语音助手”。这是一个需要 openAI api 密钥的演示链接。 https://huggingface.co/spaces/divakaivan/glaswegian-assistant 不幸的是，我们俩都不擅长语音 AI，所以即使你不能尝试语音助手（它会接收你的音频并在几秒钟后返回音频），质量也不好。问题是我们无法训练 AI 模型来很好地将文本翻译成语音。 我们计划在 8 月结束这个项目的努力。所以我写这封信是为了：  分享我们（在我看来）成功创建 120 分钟转录格拉斯哥音频的数据集 分享给任何人使用，或与可以进一步改进我们工作的人分享。一切都是开源的，因此我们鼓励它保持这种状态  谢谢    提交人    /u/Bobsthejob   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqz2a3/glaswegianscottish_voice_assistant_project_story/</guid>
      <pubDate>Tue, 13 Aug 2024 04:34:06 GMT</pubDate>
    </item>
    <item>
      <title>什么类型的模型架构最适合生成音乐？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqyyhz/what_type_of_model_architecture_is_best_suited/</link>
      <description><![CDATA[在 $$$ 成为必需品并开始开发软件之前，我曾是一名音乐家。我弹吉他、钢琴、打鼓，对音乐理论有扎实的理解，并制作了一些自己的曲目。 这些对于构建我自己的生成音乐模型可能并不重要，但这绝对意味着我对此感兴趣 :) 有人可以推荐从哪里开始，特别是哪种类型的模型架构？GPT 建议使用 RNN、Transformers 或 VAE。有没有人尝试过各种模型并可以在架构选择 + 如何适当处理数据方面提供一些指导？    提交人    /u/redditTee123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqyyhz/what_type_of_model_architecture_is_best_suited/</guid>
      <pubDate>Tue, 13 Aug 2024 04:28:19 GMT</pubDate>
    </item>
    <item>
      <title>监督训练还是使用预先训练的模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqtn2d/supervised_training_or_use_pretrained_models/</link>
      <description><![CDATA[您好！我刚刚开始使用深度学习模型。我有一个手动标记的数据集，该数据集来自 2020 年的一大堆描述某人的文字（4000 个观测值）。基本上，我想在那一年训练一个模型，并从它从未见过的文本中推断出性别（2021 年...2024 年）。话虽如此，现在我正在熟悉 transformer 和预训练模型，我想知道我应该走哪条路？你有想法吗？我在看 BERT，但就像我说的，我对所有这些都很陌生。谢谢！（如果您有的话，我也愿意接受一些可以帮助我的资源/教程）。    提交人    /u/PietroViolo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqtn2d/supervised_training_or_use_pretrained_models/</guid>
      <pubDate>Tue, 13 Aug 2024 00:06:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的真正工作原理 - 开源大型语言模型简介</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqsamr/how_ai_really_works_intro_to_open_source_large/</link>
      <description><![CDATA[        提交人    /u/kushalgoenka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqsamr/how_ai_really_works_intro_to_open_source_large/</guid>
      <pubDate>Mon, 12 Aug 2024 23:07:48 GMT</pubDate>
    </item>
    <item>
      <title>百万专家的混合体</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqq9jb/mixture_of_a_million_experts/</link>
      <description><![CDATA[      https://preview.redd.it/n54s58xazaid1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=5424c1cbc036439083ec04365d7e47fe8a5b24d7 当你将 MoE 专家数量缩放定律推向极致时会发生什么？这是一个引用 Austin Powers 的好机会（但论文作者错过了）。 与许多其他方法一样，这种方法将依赖于 Nvidia 的硬件实现才能真正可行，但如果有效，这将是持续学习的巨大解锁。 在 YouTube 上查看我对该论文的深入分析！ YouTube：https://youtu.be/gI5qDjfb1Lg ArXiv：https://arxiv.org/abs/2407.04153 Bytez：https://bytez.com/docs/arxiv/2407.04153 askalphaxiv: https://alphaxiv.org/abs/2407.04153 P.S. 我不太喜欢 Redditor，所以如果这不属于这里，请随时告诉我    提交人    /u/EvinSTunador   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqq9jb/mixture_of_a_million_experts/</guid>
      <pubDate>Mon, 12 Aug 2024 21:43:16 GMT</pubDate>
    </item>
    <item>
      <title>L1 与 L2 正则化。哪个“更好”？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqp6bc/l1_vs_l2_regularization_which_is_better/</link>
      <description><![CDATA[      有人能用通俗易懂的英语解释一下哪些情况一种比另一种更好吗？我知道 L1 会引起稀疏性，这对于变量选择很有用，但 L2 也能做到这一点吗？我们如何确定在某些情况下使用哪一个，或者只是反复试验？    提交人    /u/Traditional_Soil5753   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqp6bc/l1_vs_l2_regularization_which_is_better/</guid>
      <pubDate>Mon, 12 Aug 2024 20:59:18 GMT</pubDate>
    </item>
    <item>
      <title>我应该选修什么科目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqkbp3/what_should_i_pick_for_elective_subjects/</link>
      <description><![CDATA[      所以现在是大学里我们要选修哪些科目的时候了，但我真的不知道该选什么或者选什么是最好的考虑到未来和行业中人工智能研究的进展。  谢谢。    提交人    /u/Infinite-Dragonfruit   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqkbp3/what_should_i_pick_for_elective_subjects/</guid>
      <pubDate>Mon, 12 Aug 2024 17:48:53 GMT</pubDate>
    </item>
    <item>
      <title>我的 RAG 聊天机器人占用 24GB RAM。这是正常的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqk8m1/my_rag_chatbot_takes_24gb_ram_is_this_normal/</link>
      <description><![CDATA[大家好， 我对聊天机器人的世界还比较陌生，大约 2 个月前开始使用 Langchain。我的目标是创建一个 RAG（检索增强生成）聊天机器人，它可以处理从整个网站抓取的非结构化数据。最初，我为此使用了 Langchain，但结果相当糟糕。 最近，我改用 Langroid 的 DocChatAgent，这显著提高了响应质量。但是，我注意到有时 RAM 使用量会飙升至 24GB，这对我来说似乎相当高。 以下是有关我的设置的一些详细信息：  用例：用于网站非结构化数据的 RAG 聊天机器人 当前工具：Langroid 的 DocChatAgent GPU RAM 使用量：偶尔飙升至 24GB  向社区提出几个问题：  RAG 聊天机器人消耗这么多 RAM 正常吗？ 考虑到高资源需求，公司通常如何商业化此类聊天机器人？ 我是否错误地使用了 RAG，或者是否有更有效的方法来处理此问题？  我了解 Langroid 的代理可能具有一些对于代理工作来说过度的功能，但是它目前为我提供了最好的结果。 任何见解或建议都将不胜感激！ 提前致谢！ 编辑： 应该提到我正在使用 API LLM 调用，因此 LLM 不可能是问题所在。但是，我正在使用 BAAI/bge-small 作为本地检索器。我认为问题在于 DocChatAgent 存储了之前消息的列表，以获得上下文感知的“聊天”功能。但这最终会导致 GPU 膨胀 - 即使在查询完成后，GPU 中的内存使用量也会非单调增加。    提交人    /u/Mountain_Guest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqk8m1/my_rag_chatbot_takes_24gb_ram_is_this_normal/</guid>
      <pubDate>Mon, 12 Aug 2024 17:45:37 GMT</pubDate>
    </item>
    <item>
      <title>迫切寻找项目创意</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqhdgf/desperately_looking_for_a_project_idea/</link>
      <description><![CDATA[我是一名最后一年的人工智能学生，我和我的团队正在努力想出一个独特的项目创意。我们探索了无数种可能性，但我们提出的一切都被教授拒绝了。我们非常热衷于做一些创新和突破常规的事情。现在，我正在探索使用神经架构搜索的零样本学习，但我们仍在寻找那个“哇”的想法。我们不想仅仅为了获得批准而满足于一些小众概念。 我们仔细研究了最新的研究论文，但似乎没有什么立竿见影的。您是否有任何公司目前正在寻找的具体想法，或者与 ml 或 dl 相关的最新行业趋势相符的想法？任何建议或灵感都将不胜感激！    提交人    /u/haha_shawarma28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqhdgf/desperately_looking_for_a_project_idea/</guid>
      <pubDate>Mon, 12 Aug 2024 15:54:52 GMT</pubDate>
    </item>
    <item>
      <title>我应该学什么才能做到这一点</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1eqck0b/what_all_should_i_learn_to_do_this/</link>
      <description><![CDATA[        提交人    /u/Training_Safe6155   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1eqck0b/what_all_should_i_learn_to_do_this/</guid>
      <pubDate>Mon, 12 Aug 2024 12:35:37 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>