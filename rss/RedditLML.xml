<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 20 Feb 2024 21:12:02 GMT</lastBuildDate>
    <item>
      <title>𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠: 𝐔𝐧𝐬𝐮𝐩𝐞𝐫𝐯𝐢𝐬𝐞𝐝 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐀𝐥𝐠𝐨𝐫𝐲𝐭𝐡𝐦𝐬 🌟</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avsnjj/𝐌𝐚𝐜𝐡𝐢𝐧𝐞_𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠_𝐔𝐧𝐬𝐮𝐩𝐞𝐫𝐯𝐢𝐬𝐞𝐝_𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠_𝐀𝐥𝐠𝐨𝐫𝐲𝐭𝐡𝐦𝐬/</link>
      <description><![CDATA[&lt;表&gt;     &lt; td&gt; 由   提交/u/victoriosus  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avsnjj/𝐌𝐚𝐜𝐡𝐢𝐧𝐞_𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠_𝐔𝐧𝐬𝐮𝐩𝐞𝐫𝐯𝐢𝐬𝐞𝐝_𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠_𝐀𝐥𝐠𝐨𝐫𝐲𝐭𝐡𝐦𝐬/</guid>
      <pubDate>Tue, 20 Feb 2024 20:58:01 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch如何“知道”基本函数的导数？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avsg5g/how_does_pytorch_know_the_derivative_of_basic/</link>
      <description><![CDATA[本文解释了计算图在查找梯度中的工作原理 https://pytorch.org/blog/overview-of-pytorch-autograd-engine/ 这里说  示例函数可以分解为 f 和 g，其中 f(x, y) = log(g(x, y)) 且 g(x, y) = xy。每次引擎在图中执行操作时，该操作的导数都会添加到图中，以便稍后在向后传递中执行。请注意，引擎知道基本函数的导数。  ​ ​ 那么到底是如何做到的呢？ Pytorch 知道 sin(x)、log(x) 等函数的导数吗？这些是从某处读出的吗？我的印象是，记录函数的导数是符号微分的发生方式，但我想不出如何计算不能进一步分解的函数的导数。    由   提交 /u/GrizzyLizz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avsg5g/how_does_pytorch_know_the_derivative_of_basic/</guid>
      <pubDate>Tue, 20 Feb 2024 20:49:57 GMT</pubDate>
    </item>
    <item>
      <title>有兴趣在不牺牲准确性的情况下加速 TensorFlow 模型的推理性能。查看文章。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avsb6z/interested_in_accelerating_the_inference/</link>
      <description><![CDATA[   /u/ramyaravi19  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avsb6z/interested_in_accelerating_the_inference/</guid>
      <pubDate>Tue, 20 Feb 2024 20:44:33 GMT</pubDate>
    </item>
    <item>
      <title>SARIMA 系数太大</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avrsqn/sarima_coeff_too_large/</link>
      <description><![CDATA[大家好， 我有一个时间序列数据来制作模型。转换时遇到一些问题，我从 boxcox 得到的 lambda 是 1.71，但是当模型拟合时，西格玛值为 2.21e+20。我可以使用这样的模型吗？有一个旧版本的模型，其 lambda 为 0.25，令人惊讶的是 coeff 值很好，但这个 lambda 值没有统计公式。我可以使用它吗？    由   提交/u/Esmasta97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avrsqn/sarima_coeff_too_large/</guid>
      <pubDate>Tue, 20 Feb 2024 20:24:55 GMT</pubDate>
    </item>
    <item>
      <title>有人用过EQ-BENCH基准来评估LLM吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avr9ii/has_anyone_yet_used_eqbench_benchmark_for_llm/</link>
      <description><![CDATA[如何设置config.cfg文件？   由   提交/u/MBU_NxtDoor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avr9ii/has_anyone_yet_used_eqbench_benchmark_for_llm/</guid>
      <pubDate>Tue, 20 Feb 2024 20:03:33 GMT</pubDate>
    </item>
    <item>
      <title>有人用过EQ-BENCH基准来评估LLM吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avr9i6/has_anyone_yet_used_eqbench_benchmark_for_llm/</link>
      <description><![CDATA[如何设置config.cfg文件？   由   提交/u/MBU_NxtDoor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avr9i6/has_anyone_yet_used_eqbench_benchmark_for_llm/</guid>
      <pubDate>Tue, 20 Feb 2024 20:03:32 GMT</pubDate>
    </item>
    <item>
      <title>谁能建议解决这个计算机视觉问题的一些步骤</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avr4h3/can_anyone_suggest_some_steps_for_this_computer/</link>
      <description><![CDATA[      我有大量扫描图像，类似于下面显示的图像，在这些图像中，我能够识别边界框并裁剪它[使用python中的轮廓方法]。而其余大部分图像相互重叠或移出画面，上述方法失败。我正在考虑使用机器学习来解决这个问题，但我不确定从哪里开始，任何正确方向的指导/步骤都会有所帮助，谢谢 https://preview.redd.it/pddg3mfmmsjc1.png?width=411&amp;format=png&amp;auto= webp&amp;s=92ab346b2fc6115f143dfb63247935e1c2aae39e   由   提交 /u/SalamanderBig6661   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avr4h3/can_anyone_suggest_some_steps_for_this_computer/</guid>
      <pubDate>Tue, 20 Feb 2024 19:58:15 GMT</pubDate>
    </item>
    <item>
      <title>学习 LSTM、Transformers 等的最佳在线课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avqkhw/best_online_courses_to_learn_lstms_transformers/</link>
      <description><![CDATA[嗨，我已经学习了一些 Tensorflow 和 NLP，并希望学习一些中级或高级 Keras。  我读到过 Datacamp 很糟糕，而 Dataquest 更好，但只有 Datacamp 有高级 Keras 课程。还有其他课程或书籍可以学习高级 Keras 吗？  谢谢   由   提交 /u/Cardzilla   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avqkhw/best_online_courses_to_learn_lstms_transformers/</guid>
      <pubDate>Tue, 20 Feb 2024 19:35:53 GMT</pubDate>
    </item>
    <item>
      <title>我的简历是否太啰嗦？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avnjd9/is_my_resume_too_wordy/</link>
      <description><![CDATA[      我希望转型为数据科学或机器学习工程师角色。我在面试中取得了一定的成功，但我觉得我的简历可能没有吸引力。  我如何才能比目前更简洁地有效地传达项目的范围、我所做的事情以及结果？  谢谢！    由   提交 /u/Proud-Mulberry9990   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avnjd9/is_my_resume_too_wordy/</guid>
      <pubDate>Tue, 20 Feb 2024 17:36:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习初学者，需要数学帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avneti/ml_beginner_need_help_with_maths/</link>
      <description><![CDATA[嘿，我是一名硕士生，正在开始我的 ML 之旅，但我本科时的数学水平还不足以让我理解大部分 ML 数学这是我的主题。 请向我推荐一些资源，以便我更好地掌握 ML 和 DS 的数学知识。 P.S.：寻找清晰的资源，但我愿意接受所有建议   由   提交 /u/whereartthoukehwa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avneti/ml_beginner_need_help_with_maths/</guid>
      <pubDate>Tue, 20 Feb 2024 17:31:19 GMT</pubDate>
    </item>
    <item>
      <title>需要关于选择模型和方法的指导，以用资源匮乏的印度语言构建 NLP 会话代理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avmjge/need_guidance_on_choosing_models_and_approaches/</link>
      <description><![CDATA[大家好， 这是我第一次在 Reddit 上发帖，所以请原谅任何错误。有人告诉我，Reddit 社区非常支持我，而我陷入了一个项目，需要帮助。  我正在致力于为印度地区语言开发对话代理，旨在提高 NLP 机器在低资源语言对话环境中的理解。主要障碍是确定支持我的目标语言并且也适用于创建聊天机器人的大型语言模型 (LLM)。虽然 GPT 似乎是一个显而易见的建议，但我的项目由于缺乏商业 GPT 模型的资金而受到限制，不幸的是，开源 GPT-2 模型的性能达不到我们的需求。 为了解决这些问题，我采用了基于翻译的方法。该方法利用熟练的翻译模型 Indic BART 将提示从目标语言准确翻译为英语。然后，对话模型处理这些提示以生成响应，随后将其翻译回原始语言。尽管增加了延迟和复杂性，但这种方法符合我们增强目标语言的语言理解的目标。 在此阶段，我正在考虑将 LLAMA 2.0 作为对话模型，尽管尚未设置此选择 我想知道是否有我忽略的替代方法或模型。此外，我们将非常感谢您推荐资源较少的模型作为 LLAMA 2.0 的替代品。 提前感谢您的宝贵时间和见解。 &lt;!-- SC_ON - -&gt;  由   提交/u/Venetia016   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avmjge/need_guidance_on_choosing_models_and_approaches/</guid>
      <pubDate>Tue, 20 Feb 2024 16:57:22 GMT</pubDate>
    </item>
    <item>
      <title>这个 ROC 分数看起来正确吗？这个模型合适吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avkyff/does_this_roc_score_seem_right_and_is_this_model/</link>
      <description><![CDATA[      ​ 这个 ROC 分数看起来正确吗？ ​ ; 我有一个非常不平衡的数据集，我在集成方法中使用 SciKit 的决策树。 当我使用第 1 类的预测概率时，总体 ROC 分数为 0.90。图片的阈值为 0.8，我通过将 0.8 以上的任何值更改为 1 整数来计算 ROC。  你们认为这个 ROC 分数正确吗？我的模型是否强大？ 我多年来一直在尝试网格搜索组合，这是更好的组合之一，但我我还是不确定。我知道它会根据上下文/主题而有所不同，但我可以使用一些建议/对我的结果进行第二手审查。 那么你们觉得怎么样？   由   提交/u/infinity123248   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avkyff/does_this_roc_score_seem_right_and_is_this_model/</guid>
      <pubDate>Tue, 20 Feb 2024 15:54:37 GMT</pubDate>
    </item>
    <item>
      <title>Udemy 初学者、高级的最佳机器学习课程 -</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avku91/best_machine_learning_courses_on_udemy_beginners/</link>
      <description><![CDATA[   /u/Sreeravan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avku91/best_machine_learning_courses_on_udemy_beginners/</guid>
      <pubDate>Tue, 20 Feb 2024 15:49:53 GMT</pubDate>
    </item>
    <item>
      <title>GPU 与 TPU：哪一个更好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avj5ed/gpu_vs_tpu_which_one_is_better/</link>
      <description><![CDATA[您好，我想了解哪种选项更适合部署相同的 LLM（可能是 LLAMA 或其他）。 &lt; p&gt;此比较涉及将其部署在 AWS、Google Cloud 和本地设置（Mac 或 NVidia RTX 4090）上。 需要考虑的因素包括：  LLM 模型之间的互操作性 效率 成本 其他  你能帮我吗？谢谢！   由   提交 /u/Which_Pin_6386   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avj5ed/gpu_vs_tpu_which_one_is_better/</guid>
      <pubDate>Tue, 20 Feb 2024 14:38:13 GMT</pubDate>
    </item>
    <item>
      <title>如何创建具有可扩展输入参数或 n 输入参数的神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avi90v/how_to_create_a_neural_network_with_a_scalable/</link>
      <description><![CDATA[所以我正在创建一个图像识别软件来识别交通灯、汽车、人、桥梁等。假设我不知道图像分辨率如何创建可扩展的输入参数？我的一种方法是将输入参数设置得非常大，如果给定图像的分辨率小于设置的输入数，我可以编码它的其余输入不会被触发，但这会弄乱重量，有偏差和神经元在训练和使用它时。另一个想法是将图像缩放到输入值，但这会非常糟糕，因为缩放图像意味着丢失数据和我不想要的东西？还有其他建议吗？   由   提交 /u/GateCodeMark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avi90v/how_to_create_a_neural_network_with_a_scalable/</guid>
      <pubDate>Tue, 20 Feb 2024 13:57:52 GMT</pubDate>
    </item>
    </channel>
</rss>