<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 16 May 2024 03:17:32 GMT</lastBuildDate>
    <item>
      <title>掌握 ChatGPT-4：释放 AI 全部潜力的分步指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct2qvi/mastering_chatgpt4_stepbystep_guide_to_unlock_ais/</link>
      <description><![CDATA[ 由   提交/u/amplifyabhi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct2qvi/mastering_chatgpt4_stepbystep_guide_to_unlock_ais/</guid>
      <pubDate>Thu, 16 May 2024 02:38:24 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到残疾人数据集？仅全身或面部识别</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct1v0l/where_can_i_find_a_dataset_of_disabled_people/</link>
      <description><![CDATA[标题   由   提交/u/Annual-Ad-416   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct1v0l/where_can_i_find_a_dataset_of_disabled_people/</guid>
      <pubDate>Thu, 16 May 2024 01:52:43 GMT</pubDate>
    </item>
    <item>
      <title>LLM 的代理服务器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct1s5q/proxy_server_for_llms/</link>
      <description><![CDATA[这个简短的教程介绍了如何使用 LiteLLM 轻松创建代理服务器来托管本地或基于 API 的 LLM：https://youtu.be/YqgpGUGBHrU?si=8EWOzzmDv5DvSiJY   由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct1s5q/proxy_server_for_llms/</guid>
      <pubDate>Thu, 16 May 2024 01:48:45 GMT</pubDate>
    </item>
    <item>
      <title>书籍推荐</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct1hg7/book_recommendations/</link>
      <description><![CDATA[有人知道一本教授决策、理论、制作模型的最佳实践等的书，等等机器学习和机器学习。深度学习    由   提交 /u/Compliance-Bet652   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct1hg7/book_recommendations/</guid>
      <pubDate>Thu, 16 May 2024 01:33:52 GMT</pubDate>
    </item>
    <item>
      <title>主题提取模型建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct1h4n/topic_extraction_model_advice/</link>
      <description><![CDATA[嗨，我想训练一个可以从头条新闻中提取主题的模型，例如标题“Wayne Brown SLAMS 奥克兰市议会关于奥克兰中央商务区停车问题” ；，主题可能是[“韦恩·布朗”、“奥克兰议会”、“奥克兰中央商务区”、“停车”]。过去（对于大学），我实现了非常简单的模型，例如决策树和朴素贝叶斯。我只是对一般指导或任何人可能有的建议感兴趣。我开始收集标题并识别特征，比如这个词是否是一个城市或名称，第一个字母是否大写，诸如此类的事情，只是不知道从这里到哪里。   由   提交 /u/JudenBar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct1h4n/topic_extraction_model_advice/</guid>
      <pubDate>Thu, 16 May 2024 01:33:23 GMT</pubDate>
    </item>
    <item>
      <title>寻求论文建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct11ry/seeking_advice_for_dissertation/</link>
      <description><![CDATA[你好！我目前正在攻读大数据技术硕士学位，并拥有大约 2 年的数据工程师工作经验。当我正在为我的论文项目选择主题时，我发现自己面临着一些疑虑和不确定性。 我从课程作业中获得了一些使用 Python 进行情感分析的背景，并拥有对机器学习概念的基本了解。我正在考虑为我的论文做一些其他的事情，我的一个想法是将大型语言模型（LLM）微调为用于情感分析的专用语言模型（SLM）。然而，除了电影、客户分析之外，我正在努力寻找这个想法的应用。 一个主要问题是我缺乏微调技术方面的知识。我想知道是否有可能采用生成式人工智能模型并进行一些在线研究来弥补这一知识差距并有效地实施微调过程。 我非常感谢任何见解、建议或指导关于将 LLM 微调为 SLM 以进行情感分析或其他任务的潜在应用、大数据项目想法、学习微调技术的资源以及大数据技术论文项目的一般建议。 提前感谢您的帮助，如果这不是此类查询的理想平台，我们深表歉意。当我完成这篇论文选题过程时，您的专业知识和支持将非常有价值！    由   提交/u/i-wuv-boobies   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct11ry/seeking_advice_for_dissertation/</guid>
      <pubDate>Thu, 16 May 2024 01:11:14 GMT</pubDate>
    </item>
    <item>
      <title>改进/构建一个倾向于一类的图像分类器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct07eu/improving_building_an_image_classifier_that_leans/</link>
      <description><![CDATA[我是一个初学者，并且过度简化了我正在处理的问题。我想建立一个图像分类器来检测狗。我创建了狗和非狗（主要是马）的数据集。该模型经过训练，并且在有效集上表现良好。 现在在野外，我给它说猫或斑马，它有时给出狗，有时给出非狗输出。这是有道理的，因为训练中不包括猫或斑马。然而，我真的很关心狗的反应。  那么，我可以以不同的方式训练模型吗？如果模型呈现的是它从未见过的图像类型，那么它不应该尝试称其为狗。它应该更好地知道狗看起来像什么，如果新的看不见的图像与狗一点都不像，那么就说不是狗。 今天，我正在为这项任务训练 ResNet 变体。感谢您教我。   由   提交 /u/punjipatti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct07eu/improving_building_an_image_classifier_that_leans/</guid>
      <pubDate>Thu, 16 May 2024 00:27:35 GMT</pubDate>
    </item>
    <item>
      <title>线性化大型语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cszun9/linearizing_large_language_models/</link>
      <description><![CDATA[arxiv: https://arxiv.org/abs/2405.06640  推文：https://x.com/sedrickkeh2/status/1790756596102074652  以可扩展的方式将 Mistral 转换为 RNN。以 &lt;10% 的数据击败 RWKV   由   提交 /u/Bubbly-Plankton-8947   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cszun9/linearizing_large_language_models/</guid>
      <pubDate>Thu, 16 May 2024 00:09:30 GMT</pubDate>
    </item>
    <item>
      <title>使用决策树时的连续值指数（基尼指数）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csyohj/continuesvalued_index_when_using_decision_trees/</link>
      <description><![CDATA[      您好，我有一个关于决策树的问题，特别是（CART）基尼指数。&lt; /p&gt; 我有一个小数据集，由 10 条记录、6 列（索引）组成，任务是使用决策树算法（基尼）来指定树规则。 我的问题是当我的目标是“持续重视”时在这种情况下我该怎么办？对于一个小数据集，我认为也许采用中位数并将其作为阈值（因为基尼系数应该是一个有“是”和“否”的二叉树）会很有用，但我认为这不是正确的方法。 除了目标索引之外，我什么时候应该尝试“二值化”？我的索引？例如，您将在照片中看到价格指数也是连续估值的。 我将为数据集留下一张照片。 提前致谢！ &gt; 数据集 &lt; /div&gt;  由   提交/u/its_showtime007   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csyohj/continuesvalued_index_when_using_decision_trees/</guid>
      <pubDate>Wed, 15 May 2024 23:13:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 HuggingFace 的变形金刚感觉就像作弊。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</link>
      <description><![CDATA[我一直在使用 Huggingface 任务演示作为许多令我兴奋的 NLP 项目的起点，甚至是我所求助的一些视觉任务Transformer 文档，有时是 pytorch 文档，用于根据我的用例自定义代码，并在遇到错误时进行调试，有时查看模型论文以了解超参数应该是什么样的以及要进行实验的范围是什么。  现在，我知道我感觉自己一直是一个糟糕的程序员，从来没有真正喜欢过其他语言和框架，但这对我来说非常有趣和令人兴奋。  &gt; 我能够使用像“TrainingArgs”这样的简单代码来微调很酷的模型。和“Trainer.train()”并让我的朋友们可以使用像“pipeline”这样简单易用的API这让我感到难以置信，并且引发了我的冒名顶替综合症。 所以我想我的问题是，仅使用变形金刚以及我的做法能走多远？是工业/生产标准还是研究标准？   由   提交/u/mhmdsd77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</guid>
      <pubDate>Wed, 15 May 2024 22:08:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能在医学成像（例如组织病理学）领域如此饱和？为什么人工智能在分子生物学（蛋白质折叠除外）方面的探索如此之少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</link>
      <description><![CDATA[我从事涉及生物医学研究人工智能的项目，令我震惊的是为什么有这么多涉及医学成像人工智能的论文/项目，尤其是计算病理学（或放射学）？是因为这个领域的需求（即医院对患者进行活检的组织病理学）吗？ 为什么我感到困惑的是，组织病理学，例如全切片图像分析，是一个资源密集型领域问题 - 典型的 WSI（整个幻灯片图像）需要大约 10GB 才能加载，因此训练模型可能需要几天甚至几周的时间。更不用说您必须将图像转换为更小的补丁，然后应用多实例学习等方法来聚合每个补丁的图像嵌入以获得最终预测。然后你必须看看哪些补丁对疾病很重要（通过注意力图之类的东西），然后你需要领域专家/专业知识来了解模型是否专注于图像的正确部分以进行预测。  然而，自 2020 年以来，该领域发表了如此多的论文，可能有数千篇，跨越 NeurIPS/ICLR/ICML、CVPR/ECCV/ICCV、MICCAI（专门针对我想知道这是否是因为很多来自计算机视觉领域的人想要解决一个更困难的问题（涉及非自然图像？） 然后我我还很困惑为什么分子生物学，尤其是 DNA/RNA/表观基因组学（不包括蛋白质结构/折叠）的 ML 工作少得多、少得多？对于分子生物学来说，几乎所有的焦点似乎都集中在新 AlphaFold 3 的蛋白质折叠/结构上，但除此之外，RNA/DNA/表观基因组学在很大程度上被忽略了？也就是说，在 2023 年底到 2024 年初，只有最近一波关于单细胞 RNA 测序基础模型（如 scGPT/Geneformer 等）的论文？是因为在分子生物学模式中进行良好的分析需要更多的领域知识，而拥有这些知识的人却很少吗？尽管分子生物学数据集（尤其是 RNA 测序）的计算强度通常比医学成像（如组织病理学）低得多？   由   提交/u/EcstaticAd162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</guid>
      <pubDate>Wed, 15 May 2024 21:09:03 GMT</pubDate>
    </item>
    <item>
      <title>你会把它训练到另一个时代吗？微调 LLM 以进行总结。损失高原很快进入第一个时期。性能还可以，但是这是典型的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</link>
      <description><![CDATA[    /u/grey-seagull   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</guid>
      <pubDate>Wed, 15 May 2024 18:15:48 GMT</pubDate>
    </item>
    <item>
      <title>了解分类评估及其指标：从偏差和普遍性到准确性、宏观 F1、MCC 等指标</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</link>
      <description><![CDATA[大家好！ 一个在我的工作中一次又一次出现的话题（当做自己的研究，阅读论文时，以及教学时）：选择哪种分类评估指标？或者：为什么论文使用度量 x 进行评估（而不是 y）？以及其他类似问题。  多年来我一直在做一些笔记，现在我已经完成了一篇文章。我想也许这对你们中的一些人来说很有趣，为什么不分享它： https://arxiv.org/abs/ 2404.16958 这是摘要：  分类系统在无数论文中进行了评估。然而，我们发现评估实践往往是模糊的。通常，指标的选择是没有争论的，模糊的术语会引起误解。例如，许多作品使用所谓的“宏观”指标对系统进行排名（例如“宏观 F1”），但没有明确说明他们对这种“宏观”指标的期望。这是有问题的，因为选择一个指标可能会影响论文发现以及共享任务排名，因此应该最大限度地提高过程中的清晰度。从偏见和普遍性的直观概念出发，我们考虑论文中表达的期望，对常见的评估指标进行分析。有了对指标的透彻理解，我们调查了自然语言处理最近共享任务中的指标选择。结果表明，指标选择通常没有令人信服的论据支持，这个问题可能使任何排名看起来很武断。这项工作旨在为更明智和透明的指标选择提供概述和指导，促进有意义的评估。   一些关键观察结果是：  通常，并不完全清楚为什么在案例中使用特定指标。&lt; /li&gt; 通常也不太清楚什么是“元度量”。属性由“宏观度量”中的“宏观”等术语隐含。然而，一个反复出现的愿望是指标应该引起某种“平衡”。  为了澄清这些问题，我们分析了一些流行的指标及其属性。一些见解是：  许多指标可以根据分类器偏差和类流行率来更简单地编写。 有两个指标称为宏 F1（！）。他们的衡量标准也截然不同。另一方面，Kappa 和 MCC（马修斯相关系数）有点相似。 Macro Recall 有一个直观的解释：这是一系列与公平的赔率。这是唯一一个对班级流行率变化完全不变的指标（以防万一我们希望如此）。  最后，如果只有一个结论绘制，那么我想这是没有整体完美的指标，并且应该始终在给定特定上下文的情况下明智地选择指标。希望我的工作能对此有所帮助。   由   提交/u/juopitz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</guid>
      <pubDate>Wed, 15 May 2024 13:56:40 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的随机深度解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</guid>
      <pubDate>Wed, 15 May 2024 13:17:52 GMT</pubDate>
    </item>
    <item>
      <title>2024/2025年学习基础NLP投资回报率低吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</link>
      <description><![CDATA[就上下文而言，我目前正在学习 MSCS，有一门 NLP 课程，但它不会像 PHD 级别那么深（显然），所以我我想知道 NLP 的原始教育还值得学习吗？我不认为我会成为一名“机器学习工程师”  我们学习了非常早期的情感分析方法，例如在没有库的情况下通过手动逻辑回归按频率分配权重。如今，ChatGpt 或 Gemini 使用的算法比这些算法聪明 1000 倍，我真的很怀疑我所学的东西在我毕业后是否有任何价值。我可以简单地调用 openai api 和一些 numpy 库来在几秒钟内完成我正在学习的所有内容。不要误会我的意思，我认为这些算法非常迷人且很酷，但我更想研究一些很酷、有用且投资回报率高的东西（例如网络）。 TLDR 关于如何进行基本学习的一些见解NLP 可以帮助技术领域的职业发展，本页的专家将非常感激 &lt;3 编辑：我感谢专家们的见解。真正有帮助的是了解学习传统方法不应该仅仅从表面上看，并且具有一定的可扩展性irl   由   提交/u/Flash77555  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</guid>
      <pubDate>Wed, 15 May 2024 04:24:41 GMT</pubDate>
    </item>
    </channel>
</rss>