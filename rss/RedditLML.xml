<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sat, 27 Jan 2024 06:15:11 GMT</lastBuildDate>
    <item>
      <title>机器学习项目路线图？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac45mv/machine_learning_project_roadmap/</link>
      <description><![CDATA[我正在尝试学习机器学习，我创建了一个 iphone 价格猜测器和我的第一个项目，然后我使用流光创建了一个图像识别器作为我的第二个项目 ​ 我想要一个我可以学习的项目列表，我搜索了一些，但我不确定它们是否适合入门级 我想慢慢来，这样我才能正确理解东西   由   提交/u/Bominator8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac45mv/machine_learning_project_roadmap/</guid>
      <pubDate>Sat, 27 Jan 2024 06:09:45 GMT</pubDate>
    </item>
    <item>
      <title>条件概率与贝叶斯公式</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac3w6u/conditional_probability_vs_bayes_formula/</link>
      <description><![CDATA[贝叶斯概率公式有什么好处P(A∣B)=P(B∣A)P(A)/P(B )规定通常的条件概率公式不能P(A∣B)=P(A∩B)/P(B)？ 什么是使用贝叶斯而不是其他的场景？   由   提交 /u/DressProfessional974   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac3w6u/conditional_probability_vs_bayes_formula/</guid>
      <pubDate>Sat, 27 Jan 2024 05:54:20 GMT</pubDate>
    </item>
    <item>
      <title>R 与 Python 中的随机森林分类器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac3rxb/randomforest_classifier_in_r_vs_python/</link>
      <description><![CDATA[我正在尝试用 Python 实现 R 的 randomForest 分类器的等效项。有人可以帮忙吗？ 谢谢！ a.rf = randomForest(y=a.y, x=a.x, ntree=1000, importantity=T, strata=a.y, sampsize=c(89,89), do.trace=10, approximation=T)    由   提交 /u/tinkerpal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac3rxb/randomforest_classifier_in_r_vs_python/</guid>
      <pubDate>Sat, 27 Jan 2024 05:47:00 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 easyocr / pytesseract 神经网络的准确性？尝试使用 pytesseract 来识别这些数字，但它不能正确识别它们。也尝试过easyocr，但这也不起作用。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac2vqq/how_do_i_improve_the_accuracy_of_easyocr/</link>
      <description><![CDATA[   /u/Physical_Map_9647   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac2vqq/how_do_i_improve_the_accuracy_of_easyocr/</guid>
      <pubDate>Sat, 27 Jan 2024 04:56:55 GMT</pubDate>
    </item>
    <item>
      <title>尝试创建任何简单的神经网络，学习将输入文本数据压缩为较小的文件大小以获取乐趣......无法弄清楚如何训练它输出比输入更小的文件大小</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac23n3/trying_to_create_any_simple_neural_network_that/</link>
      <description><![CDATA[我正在尝试构建一个玩具神经网络来压缩 enwik9，这是 xml 文本格式的维基百科的第一个 1gb 内容。但我正在努力想出一个简单的神经网络，它可以执行以下操作：  获取输入文本并将其矢量化 将其通过神经网络 &gt; 训练网络将其压缩为比输入更小的文件大小表示 同时确保该过程在相同权重下是可逆的（这样我可以稍后解压缩压缩的输入）。 &gt;  这只是一个有趣的项目，因为我最近听说了大文本压缩基准 。如果有任何提示，我将不胜感激！   由   提交 /u/i_stole_your_swole   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac23n3/trying_to_create_any_simple_neural_network_that/</guid>
      <pubDate>Sat, 27 Jan 2024 04:13:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在低资源边缘设备上部署 TensorFlow Lite 模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac0ep5/how_to_deploy_a_tensorflow_lite_model_on_a_low/</link>
      <description><![CDATA[ 由   提交/u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac0ep5/how_to_deploy_a_tensorflow_lite_model_on_a_low/</guid>
      <pubDate>Sat, 27 Jan 2024 02:45:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工神经网络在训练时在验证数据上表现得更好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ac0c6a/why_does_the_ann_perform_so_much_better_on_the/</link>
      <description><![CDATA[   /u/HoleNother  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ac0c6a/why_does_the_ann_perform_so_much_better_on_the/</guid>
      <pubDate>Sat, 27 Jan 2024 02:41:41 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮助我理解 PatchTST 论文中提到的“通道独立”的概念吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abz88g/could_someone_help_me_understand_the_concept_of/</link>
      <description><![CDATA[我正在阅读论文并在线查看视频，但我仍然不太明白多元时间背景下的通道独立性意味着什么系列预测。 https://arxiv.org/pdf/2211.14730.pdf   由   提交/u/Xander2299  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abz88g/could_someone_help_me_understand_the_concept_of/</guid>
      <pubDate>Sat, 27 Jan 2024 01:45:53 GMT</pubDate>
    </item>
    <item>
      <title>关于 SelectKBest 和 GridSearchCV 的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abw2m0/question_about_selectkbest_and_gridsearchcv/</link>
      <description><![CDATA[在我的模型评估中，我有几个需要评估的假设类，即 XGBoost、Randomforest、SVM、MLP。我选择网格搜索而不是参数网格，但也想基于 Sklearn 的 SelectKBest 选择特征。这里选择k有什么好的方法呢？对于每个模型类别，执行 k 个最佳选择似乎会忽略最佳超参数，对吗？也许更好的想法是反其道而行之，首先应用网格搜索，而不通过 k best 进行特征选择，一旦找到超参数，就通过交叉验证应用 k best。但后来我想知道如果选择不同的功能，网格搜索的结果是否会有所不同。 我对如何设计我的评估感到困惑，并希望收到一些反馈。   由   提交 /u/JanBitesTheDust   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abw2m0/question_about_selectkbest_and_gridsearchcv/</guid>
      <pubDate>Fri, 26 Jan 2024 23:19:18 GMT</pubDate>
    </item>
    <item>
      <title>从头开始实施 K 均值聚类（ML 系列）！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abu9ze/implement_kmeans_clustering_from_scratch_ml_series/</link>
      <description><![CDATA[   /u/Tubbyball   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abu9ze/implement_kmeans_clustering_from_scratch_ml_series/</guid>
      <pubDate>Fri, 26 Jan 2024 22:02:46 GMT</pubDate>
    </item>
    <item>
      <title>seq-2-seq 表示/带有标记的损失计算？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abtri6/seq2seq_representation_loss_computation_with/</link>
      <description><![CDATA[你好， （免责声明：我很笨，不知道我在做什么）。因此，我想训练一个小模型，该模型获取固定长度的输入标记，例如一个样本将是 [0, 1, 2]，然后尝试再次预测它们。这些代表玩具示例中已标记化的哈希标签。 我想使用 BCE 损失，并且输出应该可以再次转换为标记。我应该做哪些改变？ 我的猜测是我应该让最后一个线性层输出output_dim * vocab_size？我想保留令牌表示（没有人热）以供我处理。最终，我计划学习如何使用 RNN 和 1D CNN 来实现这一点。我知道这个应用程序可能看起来很愚蠢。 ​ import pytorch_lightning as pl import torch import torch.nn as nn from pytorch_lightning import Trainer from torch.utils。数据导入DataLoader，TensorDataset类SimpleNN（pl.LightningModule）：def __init__（self，input_dim，hidden_​​dim，output_dim）：super（SimpleNN，self）.__init__（）self.input_dim = input_dim self.hidden_​​dim = hide_dim self.output_dim = output_dim self.step1 = nn.Linear（input_dim，hidden_​​dim） self.step2 = nn.ReLU（） self.step3 = nn.Linear（hidden_​​dim，output_dim） defforward（self，x）：x = self.step1（x）x = self.step2(x) x = self.step3(x) # 我应该在这里使用 sigmoid / softmax 吗？返回 x def 损失(self, y_hat, y): # ??? return nn.function.binary_cross_entropy(y_hat, y) def Training_step(self, batch, batch_idx): x, y = 批次 y_hat = self.forward(x) loss = self.loss(y_hat, y) self.log(&#39;train_loss &#39;, loss) return loss def configure_optimizers(self): return torch.optim.Adam(self.parameters(), lr=1e-3) if __name__ == &#39;__main__&#39;: input_shape = 3 hide_dim = 12 # 只是一个数据点 x = torch.Tensor([0, 1, 2]).view(-1, 3) train_loader = DataLoader(TensorDataset(x, x), batch_size=1) simple_model = SimpleNN(input_shape, hide_dim, input_shape) trainer = Trainer(max_epochs=100) trainer.fit(simple_model, train_loader) print(simple_model(x))  ​ 当前打印： 第 99 纪元：100%|██████████| 1/1 [00:00&lt;00:00, 45.62it/s, v_num=135] 张量([[-0.7901, 0.3822, 0.7713]], grad_fn=) 因为它应该能够在这里过度拟合，所以我很确定有些东西不对... ​ ​   由   提交 /u/compbio_guy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abtri6/seq2seq_representation_loss_computation_with/</guid>
      <pubDate>Fri, 26 Jan 2024 21:41:20 GMT</pubDate>
    </item>
    <item>
      <title>正则化会增加还是降低你在损失景观中的高度？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abrqk7/does_regularization_increase_or_decrease_your/</link>
      <description><![CDATA[当您对神经网络实施正则化时。这会提高还是降低你在损失景观中的高度？换句话说，正则化会让你更接近还是更接近损失情况的全局最小值？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abrqk7/does_regularization_increase_or_decrease_your/</guid>
      <pubDate>Fri, 26 Jan 2024 20:15:38 GMT</pubDate>
    </item>
    <item>
      <title>我确实有一些 DSA 经验，但是 ML 和 DL 需要达到什么水平？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ablrqv/i_definitely_have_some_experience_with_dsa_but_to/</link>
      <description><![CDATA[   /u/GenerallySome  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ablrqv/i_definitely_have_some_experience_with_dsa_but_to/</guid>
      <pubDate>Fri, 26 Jan 2024 16:05:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abkfjm/bayesian_network/</link>
      <description><![CDATA[      有人能给我解决这个问题的步骤吗？和解释 #bayesiannetwork   由   提交/u/Suspicious_Permit463  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abkfjm/bayesian_network/</guid>
      <pubDate>Fri, 26 Jan 2024 15:06:45 GMT</pubDate>
    </item>
    <item>
      <title>[D]ML 中有哪些对初学者最友好的项目？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1abiczt/dwhat_are_some_of_the_best_beginner_friendly/</link>
      <description><![CDATA[ 由   提交/u/hecker_007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1abiczt/dwhat_are_some_of_the_best_beginner_friendly/</guid>
      <pubDate>Fri, 26 Jan 2024 13:29:18 GMT</pubDate>
    </item>
    </channel>
</rss>