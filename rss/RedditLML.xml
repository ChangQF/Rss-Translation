<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Mon, 12 Feb 2024 15:13:58 GMT</lastBuildDate>
    <item>
      <title>您可以从另一台计算机下载 pickle 文件并在您的计算机上运行吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap21ts/can_you_download_a_pickle_file_from_another/</link>
      <description><![CDATA[我的计算机不是很强大，我决定在一个更强大的同事计算机上运行我的程序。当我下载 sav pickle 文件并尝试将其用作预测模型时，spyder 告诉我出现错误“ModuleNotFoundError：没有名为 &#39;keras.src&#39; 的模块”。 ​ ; 我做错了什么？   由   提交 /u/GlassWalkerKinfolk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap21ts/can_you_download_a_pickle_file_from_another/</guid>
      <pubDate>Mon, 12 Feb 2024 15:05:20 GMT</pubDate>
    </item>
    <item>
      <title>LangChain 播放列表，包含 60 个教程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap1uy7/langchain_playlist_with_60_tutorials/</link>
      <description><![CDATA[大家好，看看这个 LangChain（生成式 AI 框架）播放列表，其中包含 60 个从头开始解释一切的教程 https://youtube.com/playlist?list=PLnH2pfPCPZsKJnAIPimrZaKwStQrLSNIQ&amp;si=8bXhqED-NiVITZK9   由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap1uy7/langchain_playlist_with_60_tutorials/</guid>
      <pubDate>Mon, 12 Feb 2024 14:56:59 GMT</pubDate>
    </item>
    <item>
      <title>商业数据科学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap0ymc/data_science_for_business/</link>
      <description><![CDATA[我正在参加商业数据科学考试，它更侧重于使用 R 进行机器学习，主题包括基于树的方法和移动等超越线性。讲座没有提供任何示例考试问题，但他坚持将分为 1. 多个问题 2. 开放式问题 3. 代码问题 如果您有任何示例问题或网站，我可以用来测试我的考试技能，我会欣赏。   由   提交/u/Warm_Bell23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap0ymc/data_science_for_business/</guid>
      <pubDate>Mon, 12 Feb 2024 14:15:12 GMT</pubDate>
    </item>
    <item>
      <title>对应用于 ANN 回归的 K-Fold 交叉验证的疑问</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap0m86/doubt_regarding_kfold_cross_validation_applied_to/</link>
      <description><![CDATA[您好。 我对机器学习还很陌生，鉴于此，有很多事情我仍然不明白我没有计算机科学背景，但仍然必须在我的研究项目中使用 AI/ML。 其中之一是 K-Fold 交叉验证实际上是如何工作的？ &gt; 我有一个由 120 个值组成的数据集，我用它来构建 ANN 回归模型（根据项目要求）。我还使用 K-fold CV 来评估模型性能。我的疑问是： 与仅使用训练测试分割相比，使用 K 折是否可以改进模型？  折叠结果是否真正彼此独立，或者折叠之间存在一些“泄漏”，例如，第三次折叠受到第二次折叠结果的影响？  我设计了一种方法来交叉检查使用 k-fold cv 获得的结果，这表明折叠以某种方式受到影响并且并不是真正独立的..这是否意味着我的代码是错误还是这是常见现象？  作为参考，这是我的代码： ​ # 构建 ANN 模型 model = Sequential()  model.add（Dense（200，input_dim = 13，activation=&#39;relu&#39;））#（特征，） model.add（Dense（50，activation=&#39;relu&#39;） &#39;)) model.add(Dense(25,activation=&#39;relu&#39;)) model.add(Dense(1,activation=&#39;linear&#39;)) # 输出节点 model.summary() # 看看你的模型是什么样的 # 编译模型 model.compile(optimizer=&#39;adam&#39;, loss=&#39; mse&#39;,metrics=[&#39;mae&#39;,&#39;mse&#39;]) ​ # 提前停止回调 es = EarlyStopping(monitor= &#39;loss&#39;， mode=&#39;min&#39;， patience=60， restore_best_weights = True) ​  # 执行 k 折交叉验证 ( k=17) k = 17 kf = KFold(n_splits = k, shuffle = False) k = 17 kf = KFold(n_splits = k, shuffle = False) p&gt; ​ mse_scores = [] mae_scores = [] fold_results = [] &amp; #x200b; 对于 kf.split(X_train) 中的 train_index、val_index： X_tr, X_val = X_train[train_index], X_train[val_index] y_tr , y_val = y_train[train_index], y_train[val_index] # 创建并编译 ANN 模型 # 训练模型 history = model.fit(X_tr, y_tr, epochs = 150, batch_size = 7, verbose =1) # 对验证集进行预测 ​ y_pred = model.predict(X_val) # 计算并存储均方误差 mse = Mean_squared_error(y_val , y_pred) mse_scores.append(mse) ​ # 将折叠结果存储在 DataFrame 中 fold_result_df = pd.DataFrame({&#39;True&#39;: y_val, &#39;预测&#39;: y_pred.flatten()}) fold_results.append(fold_result_df) ​&lt; /p&gt; # 计算MSE分数的均值和标准差 mean_mse = np.mean(mse_scores) std_mse = np.std(mse_scores) &gt; ​ print(f“平均 MSE: {mean_mse}”) print(f“MSE 标准差: {std_mse}”)  ​ # 将所有折叠结果保存为单个 CSV 文件 all_fold_results_df = pd.concat(fold_results,ignore_index=True) &gt; all_fold_results_df.to_csv(&#39;validation_set_results_run1.csv&#39;, index=True) ​ preds_on_test_set = model.predict(X_test) 预测 ​ ---------------------------- ---------------------------- 请向我解释一下这个东西是如何工作的？   由   提交 /u/ShazzieSlays08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap0m86/doubt_regarding_kfold_cross_validation_applied_to/</guid>
      <pubDate>Mon, 12 Feb 2024 13:58:52 GMT</pubDate>
    </item>
    <item>
      <title>NLP API 可以从文件中找到相关文本片段并将其发送给翻译人员吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap0l13/nlp_apis_that_can_find_segments_of_relevant_text/</link>
      <description><![CDATA[寻找一个 API，可以从文本文件中提取有意义且相关的片段（大约 1-4 个句子）发送给翻译人员。 如果它也能处理转录就更好了。 我看到 OpenAI 说它在其文档中的分段级别创建时间戳，但没有说明这些分段是如何确定的。我将开始摆弄它，看看会发生什么，但同时会喜欢一些其他建议。   由   提交/u/gn-04  /u/gn-04  reddit.com/r/learnmachinelearning/comments/1ap0l13/nlp_apis_that_can_find_segments_of_relevant_text/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap0l13/nlp_apis_that_can_find_segments_of_relevant_text/</guid>
      <pubDate>Mon, 12 Feb 2024 13:57:10 GMT</pubDate>
    </item>
    <item>
      <title>饱和度准确度</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap0h74/saturation_in_accuracy/</link>
      <description><![CDATA[大家好， 我正在阅读一篇关于残差网络的论文，该论文解决了 CNN 模型遇到的梯度消失问题。论文中指出：  &quot;当更深的网络能够开始收敛时，就会暴露出退化问题：随着网络深度的增加，精度会饱和（这可能并不令人惊讶），然后迅速降级”[1]。  据我了解，消失梯度是指经过一些迭代后精度没有增加的情况，所以我会想问一下饱和精度是否与梯度消失问题有关，或者在这种情况下饱和度到底意味着什么？ 另一个问题是，当目标函数面临急剧最小值时，是否会发生梯度爆炸问题？ 我将不胜感激您可以就此事提供任何见解或澄清。谢谢！ [1] 用于图像识别的深度残差学习 - 作者：何凯明、张翔宇、任少卿，孙健。   由   提交 /u/PlacingABid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap0h74/saturation_in_accuracy/</guid>
      <pubDate>Mon, 12 Feb 2024 13:51:44 GMT</pubDate>
    </item>
    <item>
      <title>要过渡到机器学习职业领域，我应该关注什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ap0eil/what_should_i_focus_on_to_transition_into_a/</link>
      <description><![CDATA[我正在寻求一些帮助，概述可能是“非传统”路线。我已经拥有历史学硕士学位，所以花 4 年以上的时间学习传统的计算机科学课程对我来说没有吸引力。我已经在中学教书四年了，我决定薪水对我和我的家人来说真的不会减少。我的最终目标：我很想追求每年 15 万美元以上的人工智能开发或数据科学工作。  我现在可以利用的资产 - 1. 对 Python 非常基本的工作理解，我完全打算在空闲时间自学 Python，而不用花大学钱。 2. SQL 相当流利，几年前我在一家保险公司短暂担任过业务分析师。 3. 历史学硕士，9/11 退伍军人法案还剩 18 个月，这意味着我可以免费上大学 18 个月。历史硕士在技术上没有相关性，但将为我进入任何其他研究生课程打开大门，而无需摆弄选修课和其他本科学士学位。 4.退伍军人法案是根据时间而不是金钱计算的。在 18 个月的付费时间内，我几乎可以完成任何我想要的课程，除了极少数例外。示例：我在一年内获得了历史学硕士学位，通过 1.5 倍的课程负担，并在暑假和寒假期间上课，所有费用都是付费的。它还支付住房补贴，所以没有工作并在大学加班是一个可行的选择。 我缺乏的是：任何 IT 证书，实际上任何 SQL 之外的“真正”编程经验。&lt; /p&gt; 没有数学背景 - 我对统计学没问题，从技术上讲我从未上过大学课程，但我有足够的自学能力，我可以轻松完成一门课程。我对微积分 1、2 或 3 毫无了解。 我看到各个大学都在宣传这些为期 6 个月的在线训练营，这对我来说是一条好路线吗？首先？结束于？  我即将完成高中教师的学年，然后将寻求从今年夏天五月或今年秋天开始全日制学习证书和大学课程，具体取决于哪一个最有意义。  所以说实话，归根结底，如果我想在人工智能领域找到一份高薪工作，那么如何最有效地利用我 18 个月的免费大学时光，以及在开始学习之前我应该​​自学什么？开始使用那个？预先感谢您的时间和考虑！   由   提交 /u/TangerineMalk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ap0eil/what_should_i_focus_on_to_transition_into_a/</guid>
      <pubDate>Mon, 12 Feb 2024 13:48:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 来创建 AI NPC？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aoz87b/using_llms_to_create_ai_npcs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aoz87b/using_llms_to_create_ai_npcs/</guid>
      <pubDate>Mon, 12 Feb 2024 12:46:52 GMT</pubDate>
    </item>
    <item>
      <title>【研究】《Attention is All You Need》中的多头自注意力公式是否存在误解？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aoz7hj/research_is_there_a_misunderstanding_in_the/</link>
      <description><![CDATA[   大家好， 希望你们一切顺利。我一直在研究 Transformer 架构，并且在开创性论文“Attention is All You Need”中提出的多头自注意力 (MHSA) 公式方面遇到了障碍。  ​ https:// /preview.redd.it/9ap9c5ieh5ic1.png?width=715&amp;format=png&amp;auto=webp&amp;s=2569326828c63eda509def99f0b5eb08c8ec159e 论文中指出，每个注意力头，表示为head(i) 是使用 QW^Q_i、KW^K_i 和 VW^V_i 计算的。我对 QW^Q_i 一词感到困惑。如果我们已经将 Q 定义为输入嵌入 X 和权重矩阵 W^Q 的乘积（即 Q = XW^Q），那么 QW^Q_i 代表什么？这是符号的简化，还是意味着在我们获得 Q、K 和 V 向量之后、执行注意力计算之前还有额外的可学习参数发挥作用？我们将非常感谢您就此事提供的任何见解或澄清。谢谢！   由   提交/u/amt_42  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aoz7hj/research_is_there_a_misunderstanding_in_the/</guid>
      <pubDate>Mon, 12 Feb 2024 12:45:49 GMT</pubDate>
    </item>
    <item>
      <title>适合初学者进行 ML/Ai 学习的最低 RAM 和 CPU 规格</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aoxq89/minimum_ram_and_cpu_spec_for_mlai_learning_for/</link>
      <description><![CDATA[ 由   提交 /u/kalbeyoki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aoxq89/minimum_ram_and_cpu_spec_for_mlai_learning_for/</guid>
      <pubDate>Mon, 12 Feb 2024 11:17:58 GMT</pubDate>
    </item>
    <item>
      <title>先进的 RAG 技术</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aovlnl/advanced_rag_techniques/</link>
      <description><![CDATA[大家好， 这里尝试总结不同的 RAG 技术以改进检索。 视频经过 ​  长上下文重新排序， 从小到大  &lt; p&gt;还有许多其他... https://youtu.be/YpcENPDn9u4?si=UMfXQ_P9J- l92jBR   由   提交/u/Mosh_98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aovlnl/advanced_rag_techniques/</guid>
      <pubDate>Mon, 12 Feb 2024 08:48:06 GMT</pubDate>
    </item>
    <item>
      <title>Udacity 生成式 AI 纳米学位回顾 - 最新 2024 年</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aoucf1/udacity_generative_ai_nanodegree_review_latest/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aoucf1/udacity_generative_ai_nanodegree_review_latest/</guid>
      <pubDate>Mon, 12 Feb 2024 07:19:10 GMT</pubDate>
    </item>
    <item>
      <title>一般知识/推理数据集的嵌入模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aots4o/embedding_models_for_general_knowledgereasoning/</link>
      <description><![CDATA[当用于对像 ARC 这样的常识 kr 推理数据集进行微调时，建议使用哪些嵌入模型...建议的损失函数是什么（对比或重新排序） )?   由   提交/u/MBU_NxtDoor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aots4o/embedding_models_for_general_knowledgereasoning/</guid>
      <pubDate>Mon, 12 Feb 2024 06:42:08 GMT</pubDate>
    </item>
    <item>
      <title>模型过拟合？到底是怎么回事？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aopr04/overfitting_model_what_is_going_on/</link>
      <description><![CDATA[       由   提交 /u/CuteKittenMittens   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aopr04/overfitting_model_what_is_going_on/</guid>
      <pubDate>Mon, 12 Feb 2024 02:51:57 GMT</pubDate>
    </item>
    <item>
      <title>总结了 VQVAE。如果其他人很难掌握它，希望它能对其有所帮助。如果您认为其中缺少任何内容，请告诉我，请参考原始张量流实现。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aooquz/summarized_vqvae_hopefully_it_helps_someone_else/</link>
      <description><![CDATA[    /u/I_will_delete_myself   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aooquz/summarized_vqvae_hopefully_it_helps_someone_else/</guid>
      <pubDate>Mon, 12 Feb 2024 01:58:19 GMT</pubDate>
    </item>
    </channel>
</rss>