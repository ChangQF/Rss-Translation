<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 07 Jun 2024 06:21:27 GMT</lastBuildDate>
    <item>
      <title>橙色数据挖掘</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9zgld/orange_data_minimg/</link>
      <description><![CDATA[嗨，我正在尝试使用 Orange 数据挖掘将酒店评论分为 3 个不同的类别，例如 1 星、2 星和 3 星。我想我可能哪里做错了，但我似乎无法将数据集（文本格式）中的评论列设置为目标变量。我是初学者。有人能帮帮我吗？     提交人    /u/Intelligent_Mix291   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9zgld/orange_data_minimg/</guid>
      <pubDate>Fri, 07 Jun 2024 02:01:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 从头构建 ResNet</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9xk76/building_resnets_from_scratch_using_pytorch/</link>
      <description><![CDATA[      使用 PyTorch 从头开始​​构建 ResNets https://debuggercafe.com/building-resnets-from-scratch-using-pytorch/ https://preview.redd.it/oxv8yt7vm15d1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=5e4e57211b9582d8e6bd3ae2045c0cb8c4506f37    提交人    /u/sovit-123   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9xk76/building_resnets_from_scratch_using_pytorch/</guid>
      <pubDate>Fri, 07 Jun 2024 00:23:30 GMT</pubDate>
    </item>
    <item>
      <title>帮助解决简单 MLP 模型的过度拟合问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9x9te/help_with_overfitting_on_simple_mlp_model/</link>
      <description><![CDATA[大家好，我正在使用 tensorflow 和只有两个隐藏层的顺序模型编写一个简单的神经网络。我的数据集是 quickdraw 图像。我通过 PCA 对其进行处理，因此模型的参数较少。拟合模型时，准确率 &gt;90%，但验证准确率不超过 50%。我尝试了分层抽样，因此训练和验证数据集具有相同的类别比例 - 一切仍然相同。数据集有 10 个类，每个类有 1000 个示例，因此我认为数据示例没有问题。有什么帮助或提示吗？提前谢谢您。    提交人    /u/Aromatic_Fly4830   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9x9te/help_with_overfitting_on_simple_mlp_model/</guid>
      <pubDate>Fri, 07 Jun 2024 00:09:22 GMT</pubDate>
    </item>
    <item>
      <title>输出层之前的层和批归一化会毁掉卷积余弦预测模型。LSTM 和 Dense 不会发生这种情况</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9wszk/layer_and_batch_normalization_before_output_layer/</link>
      <description><![CDATA[这是一个简单的模型 Conv1d（leaky relu 或 tanh）或 LSTM 或 Dense（leaky relu） 批量或层规范化 Dense（tanh） 适用于每种组合，除了使用批量规范化的卷积层，这会显着降低预测效果，也没有使用层规范化来破坏它们，因此它总是在每一步中输出相同的数字。    提交人    /u/indexator69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9wszk/layer_and_batch_normalization_before_output_layer/</guid>
      <pubDate>Thu, 06 Jun 2024 23:47:23 GMT</pubDate>
    </item>
    <item>
      <title>在 6 月 22 日至 23 日举行的加州大学伯克利分校人工智能黑客马拉松上了解最新的人工智能/机器学习技术和创新。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9vzog/learn_about_the_latest_aiml_technologies_and/</link>
      <description><![CDATA[        由    /u/nikita-1298  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9vzog/learn_about_the_latest_aiml_technologies_and/</guid>
      <pubDate>Thu, 06 Jun 2024 23:09:32 GMT</pubDate>
    </item>
    <item>
      <title>训练误差持续下降，但测试误差却没有下降，即使测试数据集是训练数据集的子集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9u3ff/train_error_decreases_consistently_but_test_error/</link>
      <description><![CDATA[我的数据包含来自传感器的 6 个特征。我正在用这些数据训练一个 LSTM 网络来预测三个值。在训练期间，我的训练损失随着每个时期而持续减少，但测试损失在几个时期后并没有减少多少。这是训练和测试数据之间没有重叠的情况。所以我尝试使用训练数据的子集作为测试数据。但是，仍然是同样的行为，测试损失仍然没有减少。 以下是 LSTM 模型和训练器的代码。  class LSTMModel(nn.Module): def __init__(self, in_dim=6, hidden_​​size=200, num_layers=1, output_size=3): super(LSTMModel, self).__init__() self.lstm_1 = nn.LSTM(in_dim, hidden_​​size, num_layers, batch_first=True) self.lstm_2 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True) self.lstm_3 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True) self.lstm_4 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True) self.fc = nn.Linear(hidden_​​size, output_size) def forward(self, x): x, _ = self.lstm_1(x) x, _ = self.lstm_2(x) x, _ = self.lstm_3(x) x, _ = self.lstm_4(x) output = self.fc(x[:, -1, :]) 返回输出类 SimpleModelTrainer：def __init__(self，model，train_dataset，test_dataset，batch_size=1024，epochs=100，lr=0.005）：# window_size=200，do_windowing=True，patience=5，pad_testing_data = False self.model = model self.optimizer = AdamW(params=self.model.parameters()，lr=lr) self.lr = lr self.epochs = epochs self.batch_size = batch_size self.loss_fn = nn.L1Loss() self.train_data = train_dataset self.test_data = test_dataset def train(self): self.train_dataloader = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device=device)) self.test_dataloader = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device=device)) total_samples = 0 for epoch in tqdm(range(self.epochs), desc=&quot;epoch&quot;): self.model.train() total_loss = 0 for train_data in tqdm(self.train_dataloader, desc=&quot;train&quot;): X = train_data[0] Y = train_data[1] if X.shape[0] != self.batch_size: continue # 避免 RuntimeError: shape &#39;[16, 1, 256]&#39; 对于大小为 3328 的输入无效 total_samples += self.batch_size y_hat = self.model(X) loss = self.loss_fn(y_hat, Y) self.optimizer.zero_grad() loss.backward() self.optimizer.step() total_loss += loss.item() av​​g_train_loss = total_loss / total_samples val_loss = self.test(self.test_dataloader) print(f&quot;Epoch {epoch} - Train loss:{avg_train_loss:.10f}, Val loss:{val_loss:.10f}&quot;) def test(self, dataloader): self.model.eval() with torch.no_grad(): total_loss = 0 total_samples = 0 for test_data in tqdm(dataloader, desc=&quot;test&quot;): X = test_data[0] Y = test_data[1] if X.shape[0] != self.batch_size: continue # 避免 RuntimeError: 对于大小为 Z 的输入，形状 &#39;[Y, 200, 6]&#39; 无效 total_samples += self.batch_size y_hat = self.model(X) loss = self.loss_fn(y_hat, Y) total_loss += loss.item() val_loss = total_loss/total_samples return val_loss  我用随机生成的虚拟数据集尝试了这个。它给出了与上面完全相同的行为！您可以在这个 colab 笔记本中查看它。 正如您在笔记本中看到的，自第一个时期以来，验证损失一直停留在 0.00048。但是训练损失随着每个时期持续减少，从第 28 个时期的 0.00048 减少到 0.000016。（我写这个问题的时候它还在训练。）测试数据集是训练数据集的子集： train_dataset = CustomDataset(windowed_input_data, windowed_target_data) test_dataset = CustomDataset(windowed_input_data[:20000], windowed_target_data[:20000])  因此，我相信验证损失应该得到类似的行为，验证损失也应该达到约 0.00001。我想我在代码中犯了一些愚蠢的错误（错误的 pytorch API 调用？）而且我的眼睛根本无法帮助我。有人可以帮帮我吗？我是否遗漏了概念上的什么？    提交人    /u/Tiny-Entertainer-346   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9u3ff/train_error_decreases_consistently_but_test_error/</guid>
      <pubDate>Thu, 06 Jun 2024 21:45:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT 模型检测故意混淆的文本中的毒性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9ss2q/using_bert_models_to_detect_toxicity_in_texts/</link>
      <description><![CDATA[大家好， 我一直在使用 BERT 模型来检测文本中的毒性，我遇到了一个有趣的困境，我想与大家讨论一下。 困境：当用户故意以掩盖其真实意图的方式书写时，例如使用 leet 说话（l33t sp34k）或故意拼写错误，准确检测有毒内容就变得具有挑战性。这种文本操纵可能涉及：  Leet talk：用数字或符号替换字母（例如，用“h3ll0”替换“hello”）。 过多的元音或辅音：故意重复字母（例如，“heeeeeey”或“byeeee”）。 拼写错误或语音拼写：故意拼错单词（例如，用“toxxic”代替“toxic”）。  我的方法：为了解决这个问题，我建议使用双模型系统：  混淆检测模型：该模型首先识别文本是否包含任何形式的故意混淆，例如 leet talk 或其他类型的操作，并尝试规范化文本。 规范化和毒性检测模型：检测到混淆后，该模型将尝试将混淆的文本转换为标准语言。 规范化后，文本将通过传统的毒性检测模型。  但最近一位同事向我提出了一个选择，那就是只训练一个 BERT 模型，使用所有毒性示例，并通过以编程方式将我的毒性数据集转换为 leet 语言或其他混淆来进行数据增强。 使用侮辱数据集，并将毒性数据集中存在的侮辱转换为 leet 语言和其他技术。 对我来说这似乎也是一种有效的方法。 哪种选择似乎最有意义？ 还有其他方法可以与这些方法竞争吗？   由    /u/GiRLaZo  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9ss2q/using_bert_models_to_detect_toxicity_in_texts/</guid>
      <pubDate>Thu, 06 Jun 2024 20:51:55 GMT</pubDate>
    </item>
    <item>
      <title>有关 EasyOCR 模型的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9slj3/help_with_easyocr_models/</link>
      <description><![CDATA[您好， 我正在训练一个自定义模型，但由于一些限制，我不能让它训练很长时间。有没有办法用不同的（较小的）数据集多次训练它，然后最后将它们组合在一起？    提交人    /u/Good-Intention751   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9slj3/help_with_easyocr_models/</guid>
      <pubDate>Thu, 06 Jun 2024 20:44:39 GMT</pubDate>
    </item>
    <item>
      <title>我对现在应该学什么感到很困惑</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9r85k/i_am_too_confused_on_what_should_i_learn_now/</link>
      <description><![CDATA[看到很多数据角色要求使用 R 和 sas......但我还必须涵盖 DL 和 NLP 🥲    提交人    /u/Assalamwhileicum   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9r85k/i_am_too_confused_on_what_should_i_learn_now/</guid>
      <pubDate>Thu, 06 Jun 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>3090 与 7900xt</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9qdk3/3090_vs_7900xt/</link>
      <description><![CDATA[两台都是二手的，价格为 500 英镑，状况良好。  我希望能够在家中使用一台进行机器学习。 Nvidia 似乎是阻力最小的路径，但我犹豫不决，因为 7900xt 较新且游戏性能略好？    由   提交  /u/Mart_Fisher   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9qdk3/3090_vs_7900xt/</guid>
      <pubDate>Thu, 06 Jun 2024 19:14:45 GMT</pubDate>
    </item>
    <item>
      <title>抱歉，如果这太初级了，但是</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9pbo5/sorry_if_this_is_too_beginner_but/</link>
      <description><![CDATA[我对向量和张量感到困惑，有人能给我解释一下吗，我好迷茫    提交人    /u/Fluid_Structure_1506   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9pbo5/sorry_if_this_is_too_beginner_but/</guid>
      <pubDate>Thu, 06 Jun 2024 18:31:25 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用什么书？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9ja9y/what_book_can_i_use/</link>
      <description><![CDATA[大家好，你们推荐哪些书籍来进入机器学习的世界。我是一名工程本科生，所以我有微积分线性代数和统计学方面的经验。我在网上找到了 Bishop 模式识别和机器学习，但我还想有一个在 Python 上实现代码的实用指南。    提交人    /u/AshamedRecover1786   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9ja9y/what_book_can_i_use/</guid>
      <pubDate>Thu, 06 Jun 2024 14:17:47 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的 1x1 卷积是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9hu4t/what_are_1x1_convolutions_in_deep_learning/</link>
      <description><![CDATA[        提交人    /u/research_pie   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9hu4t/what_are_1x1_convolutions_in_deep_learning/</guid>
      <pubDate>Thu, 06 Jun 2024 13:12:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 CPU 上的 LLM 嵌入进行闪电般的文本分类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d9gozo/lightningfast_text_classification_with_llm/</link>
      <description><![CDATA[      https://preview.redd.it/br9q3raj0y4d1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=bf803ff40788e515488c2dc8aa8b07c11fe16e19 我很高兴介绍fastc，这是一个不起眼的 Python 库，旨在使文本分类高效而直接，尤其是在 CPU 环境中。无论您从事的是情绪分析、垃圾邮件检测还是其他文本分类任务，fastc 都面向小型模型，避免了微调，非常适合资源受限的环境。尽管方法简单，但性能却相当不错。 主要特点  专注于 CPU 执行：使用 deepset/tinyroberta-6l-768d 等高效模型生成嵌入。 余弦相似度分类：无需微调，而是使用类嵌入质心和文本嵌入之间的余弦相似度对文本进行分类。 高效的多分类器执行：在使用同一模型进行嵌入时，无需额外开销即可运行多个分类器。 使用 HuggingFace 轻松导出和加载：可以轻松地将模型导出到 HuggingFace 并从中加载。与微调不同，只需要在内存中加载一个嵌入模型即可为任意数量的分类器提供服务。  https://github.com/EveripediaNetwork/fastc    提交人    /u/brunneis   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d9gozo/lightningfast_text_classification_with_llm/</guid>
      <pubDate>Thu, 06 Jun 2024 12:12:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>