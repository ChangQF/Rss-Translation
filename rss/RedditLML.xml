<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 20 Dec 2024 15:16:57 GMT</lastBuildDate>
    <item>
      <title>使用 Geron 的 HOML 进行自我学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hilqxu/self_learning_ml_with_gerons_homl/</link>
      <description><![CDATA[嗨，我真的很喜欢构建 AI 应用程序和学习 AI 和机器学习。我已经参加了一些关于 ML 的课程和训练营，现在正在阅读《使用 keras scikit learn 和 Tensorflow 进行机器学习》。问题是我目前读到第 12 章，事情变得非常困难。我一直在寻求聊天 gpt 的帮助，使概念对我来说更容易，但现在事情变得无法控制。请指导我该怎么做以及如何保持动力并学习这些枯燥的概念？    提交人    /u/mr_pewterschmidtt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hilqxu/self_learning_ml_with_gerons_homl/</guid>
      <pubDate>Fri, 20 Dec 2024 15:06:14 GMT</pubDate>
    </item>
    <item>
      <title>90 天人工智能学习挑战</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hila5u/90_days_ai_learning_challenge/</link>
      <description><![CDATA[现在是假期，我开始了 90 天的 AI 学习挑战，以创建可用于生产的应用程序。有人有兴趣加入吗？#90daysAIChallenge https://youtube.com/shorts/YKtz77MwOgg?si=uqWZoNbJyfnbbqZX    提交人    /u/Capital_Coyote_2971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hila5u/90_days_ai_learning_challenge/</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:12 GMT</pubDate>
    </item>
    <item>
      <title>成为梯度下降忍者：动量</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hik4sh/become_a_gradient_descent_ninja_momentum/</link>
      <description><![CDATA[        提交人    /u/Ok-District-4701   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hik4sh/become_a_gradient_descent_ninja_momentum/</guid>
      <pubDate>Fri, 20 Dec 2024 13:47:29 GMT</pubDate>
    </item>
    <item>
      <title>云服务列表：我觉得协作最差，帮我改变主意（不难）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hihbw6/cloud_services_list_i_feel_collab_is_the_worse/</link>
      <description><![CDATA[大家好；我是 Riccardo，一名机械工程师，我正在自学所有的机器学习理论等。我想实现一个模型来直观地研究机械元素（缺陷=0 好=1）； 现在我的笔记本电脑很烂，烂到疯狂的程度，我试图在肿瘤脑数据库上训练 yolo，结果简直是地狱，然后我尝试使用 collab，但也很痛苦，至少速度更快，但是我遇到了很多问题；由于某种原因，我甚至无法下载我的 .pt 的 15mb 训练集。 我将分享一些代码；现在我正在自己处理数学、代数统计概率，虽然很痛苦，但我喜欢它：但是，我很快就会遇到瓶颈，因为我的电脑出现了大问题；我尝试对一些扁平图像矩阵进行 pca 和 SVD 分析，并研究一些人脸的相似性或均值，但这非常糟糕，学习时电脑崩溃是一个严重的问题，而且浪费了太多时间，特别是对于不习惯它的人。 事情是这样的，我尝试了 collab，但效果并不好，我还必须切换到 utf-8（不好，我正在使用最后一个 ubuntu，因此必须在 collab 中对其进行自定义很奇怪）； 所以我在寻找一种在线服务，一种可靠的东西，如果我必须链接我的电脑或只是下载上传文件，它不会要求我浪费太多时间；感觉像第二个 ubuntu 或类似的东西：如果可能的话也是免费的，我没有钱，我真的很穷。你有什么建议？ 出于某些原因，我对 collab 有一种不好的感觉 我也可以花一些欧元，我买不起 100 欧元，但我可能会买得起一些可以通过代币使用的东西，比如 gpt，它可能会更贵？我不知道，我会相信你的意见 带着爱，谢谢和所有&lt;3 # 安装 YOLO 的 Ultralytics 库 #!pip install ultralytics #Yolo train tumor.py from ultralytics import YOLO from google.colab import files &quot;&quot;&quot;Salva pesi in runs/detect/train/weights/best.pt &quot;&quot;&quot; import locale import matplotlib.pyplot as plt import cv2 locale.getpreferredencoding = lambda: &quot;UTF-8&quot; # 从您的 PC 下载文件 #uploaded = files.upload(&quot;PAth&quot;) # 加载模型 model = YOLO(&quot;yolo11n.pt&quot;) # 加载预训练模型（推荐用于训练） # 训练模型 ## 开始示例 # results = model.train(data=&quot;brain-tumor.yaml&quot;, epochs=100, imgsz=640) results = model.train(data=&quot;brain-tumor.yaml&quot;, epochs=100, imgsz=600) # 加载模型 #model = YOLO(&quot;path/to/best.pt&quot;) # 加载脑肿瘤微调模型 #在图像上推断模型（第二种自动保存日志的方法//image-seg） inference=model.predict(&quot;https://ultralytics.com/assets/brain-tumor-sample.jpg&quot;) annotated_img = inference[0].plot() plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)) plt.axis(&quot;off&quot;) plt.show()# 安装 Ultralytics 库用于 YOLO #!pip install ultralytics #Yolo train tumor.py from ultralytics import YOLO from google.colab import files &quot;&quot;&quot;保存在 runs/detect/train/weights/best.pt &quot;&quot;&quot; import locale import matplotlib.pyplot as plt import cv2 locale.getpreferredencoding = lambda: &quot;UTF-8&quot; # 从您的 PC 下载文件 #uploaded = files.upload(&quot;PAth&quot;) # 加载模型 model = YOLO(&quot;yolo11n.pt&quot;) # 加载预训练模型（推荐用于训练） # 训练模型 ## 开始示例 # results = model.train(data=&quot;brain-tumor.yaml&quot;, epochs=100, imgsz=640) results = model.train(data=&quot;brain-tumor.yaml&quot;, epochs=100, imgsz=600) # 加载模型 #model = YOLO(&quot;path/to/best.pt&quot;) # 加载脑肿瘤微调模型 #在图像上推断模型（第二种自动保存日志的方法//image-seg） inference=model.predict(&quot;https://ultralytics.com/assets/brain-tumor-sample.jpg&quot;) annotated_img = inference[0].plot() plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)) plt.axis(&quot;off&quot;) plt.show()     提交人    /u/Proper_Fig_832   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hihbw6/cloud_services_list_i_feel_collab_is_the_worse/</guid>
      <pubDate>Fri, 20 Dec 2024 10:53:39 GMT</pubDate>
    </item>
    <item>
      <title>制作了一个直观解释检索增强生成的视频。我希望你们喜欢它，就像我喜欢制作这个视频一样。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hihbp4/made_a_video_that_intuitively_explains_retrieval/</link>
      <description><![CDATA[        提交人    /u/faizalHoonBC   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hihbp4/made_a_video_that_intuitively_explains_retrieval/</guid>
      <pubDate>Fri, 20 Dec 2024 10:53:13 GMT</pubDate>
    </item>
    <item>
      <title>在线举办精细化的法学硕士课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hih6zw/hosting_a_finetuned_llm_online/</link>
      <description><![CDATA[我没有运行任何类型的 LLM 的经验，但现在我正在这里微调 LLama 3 8B https://colab.research.google.com/drive/1efOx_rwZeF3i0YsirhM1xhYLtGNX6Fv3?usp=sharing 一旦我根据自己的喜好对其进行了微调，下一步该怎么做才能将其上线？另外，一旦上线，是否可以为其添加语音？    提交人    /u/WorldImmediate8853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hih6zw/hosting_a_finetuned_llm_online/</guid>
      <pubDate>Fri, 20 Dec 2024 10:43:53 GMT</pubDate>
    </item>
    <item>
      <title>在线举办精细化的法学硕士课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hih6zp/hosting_a_finetuned_llm_online/</link>
      <description><![CDATA[我没有运行任何类型的 LLM 的经验，但现在我正在这里微调 LLama 3 8B https://colab.research.google.com/drive/1efOx_rwZeF3i0YsirhM1xhYLtGNX6Fv3?usp=sharing 一旦我根据自己的喜好对其进行了微调，下一步该怎么做才能将其上线？另外，一旦上线，是否可以为其添加语音？    提交人    /u/WorldImmediate8853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hih6zp/hosting_a_finetuned_llm_online/</guid>
      <pubDate>Fri, 20 Dec 2024 10:43:53 GMT</pubDate>
    </item>
    <item>
      <title>大多数 LLM 是否使用与 BERT 类似的词邻近度/频率/上下文向量嵌入模型？我理解他们通过上下文“学习”隐式规则和定义，但基于意义（定义）的向量（包括 POS）是否被低估了？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1higt6s/do_the_majority_of_llms_utilise_word/</link>
      <description><![CDATA[        提交人    /u/clippeh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1higt6s/do_the_majority_of_llms_utilise_word/</guid>
      <pubDate>Fri, 20 Dec 2024 10:15:21 GMT</pubDate>
    </item>
    <item>
      <title>什么使优秀的数据科学家 + MLE 与众不同？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hifs8v/what_sets_great_data_scientists_mles_apart/</link>
      <description><![CDATA[那么这些技能如何学习呢？    提交人    /u/darkGrayAdventurer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hifs8v/what_sets_great_data_scientists_mles_apart/</guid>
      <pubDate>Fri, 20 Dec 2024 08:57:25 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的推理LLM，Gemini2 Flash思维看起来不错</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hieg1c/googles_reasoning_llm_gemini2_flash_thinking/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hieg1c/googles_reasoning_llm_gemini2_flash_thinking/</guid>
      <pubDate>Fri, 20 Dec 2024 07:14:08 GMT</pubDate>
    </item>
    <item>
      <title>ModernBERT：更快、更好的 BERT 变体发布</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hidc9w/modernbert_faster_better_bert_variant_released/</link>
      <description><![CDATA[ModernBERT 最近发布，支持 8192 个序列长度（编码器通常为 512 个），准确度更高，效率更高（比下一个最佳 BERT 变体快 2-3 倍）。该模型发布 2 个变体，基本版和大型版。查看如何使用 Transformers 库使用它：https://youtu.be/d1ubgL6YkzE?si=rCeoxVHSja4mwdeW    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hidc9w/modernbert_faster_better_bert_variant_released/</guid>
      <pubDate>Fri, 20 Dec 2024 06:00:01 GMT</pubDate>
    </item>
    <item>
      <title>没有计算机科学学位，成为一名开发人员的可行性有多大？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hi6tv0/how_feasible_is_working_as_a_developer_without_a/</link>
      <description><![CDATA[我今年将以金融专业和 BTM 辅修专业毕业。  我一直都很喜欢编程，而且我在这方面也有不错的背景。我喜欢学习它，并且可以花无数的时间研究和弄清楚一些事情以完成一个项目。  很多人告诉我，你不需要计算机科学学位就可以找到一份开发人员的工作。然而也有相反的观点。  我现在的问题是，如果我能够拥有我需要的所有技术技能。没有计算机科学学位，有可能成为一名开发人员吗？你对我有什么建议？    提交人    /u/SpinxLogic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hi6tv0/how_feasible_is_working_as_a_developer_without_a/</guid>
      <pubDate>Thu, 19 Dec 2024 23:58:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么要堆叠 LSTM 层</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hhz5s2/why_stacked_lstm_layers/</link>
      <description><![CDATA[堆叠 LSTM 层背后的直觉是什么？我没有看到任何关于为什么使用堆叠 LSTM 层的讨论，例如为什么使用。  1) 50 输入 &gt; 256 LSTM &gt; 256 LSTM &gt; 10 输出 2) 50 输入 &gt; 256 LSTM &gt; 256 Dense &gt; 256 LSTM &gt; 10 输出 3) 50 输入 &gt; 512 LSTM &gt; 10 输出 我想我可以明白为什么人们会选择 1 而不是 3（深度网络比浅层但宽的网络更擅长泛化），但为什么人们通常使用 1 而不是 2？为什么使用堆叠的 LSTM，而不是与普通 Dense 交织的 LSTM？    提交人    /u/ZazaGaza213   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hhz5s2/why_stacked_lstm_layers/</guid>
      <pubDate>Thu, 19 Dec 2024 18:13:18 GMT</pubDate>
    </item>
    <item>
      <title>基于 SAM 2 的强大球跟踪功能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hhybde/robust_ball_tracking_built_on_top_of_sam_2/</link>
      <description><![CDATA[        由    /u/happybirthday290  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hhybde/robust_ball_tracking_built_on_top_of_sam_2/</guid>
      <pubDate>Thu, 19 Dec 2024 17:37:41 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>