<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 28 Nov 2024 12:35:17 GMT</lastBuildDate>
    <item>
      <title>我怎样才能真正建立一个真正的项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1uswb/how_can_i_really_build_a_real_project/</link>
      <description><![CDATA[最近，我一直在研究 ML 和 DL 背后的理论，但老实说，我花了几乎 0 分钟来编码。 接下来，我想开始使用 PyTorch 构建一些真实的东西，我可以把它放在我的简历上。同时试图弄清楚我应该学习哪些其他工具 - 比如 Cloud、Hugging Face、Git、Docker、API 等。 问题是，我找到的所有课程要么不断地谈论房价预测，要么只是展示一些随机的 PyTorch 代码而没有做任何实际的事情。 有人能帮我吗？专注于构建实际项目的课程、书籍或资源？    提交人    /u/Shams--IsAfraid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1uswb/how_can_i_really_build_a_real_project/</guid>
      <pubDate>Thu, 28 Nov 2024 12:23:10 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity AI PRO - 1 年计划优惠 - 75% 折扣</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1usft/perplexity_ai_pro_1_year_plan_offer_75_off/</link>
      <description><![CDATA[      正如标题：我们提供一年计划的 Perplexity AI PRO 优惠券代码。  订购：CHEAPGPT.STORE 接受的付款：  PayPal。 （100% 买家保护） Revolut。  反馈：反馈帖子    提交人    /u/Verza-   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1usft/perplexity_ai_pro_1_year_plan_offer_75_off/</guid>
      <pubDate>Thu, 28 Nov 2024 12:22:25 GMT</pubDate>
    </item>
    <item>
      <title>有人可以推荐一些关于 opencv、边界框生成和分类的好资源或书籍吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1ug8k/can_someone_suggest_some_good_resources_or_books/</link>
      <description><![CDATA[需要撰写一篇基于一些视觉模型的研究论文：边界框生成和分类。    提交人    /u/Monkeydluffy8400   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1ug8k/can_someone_suggest_some_good_resources_or_books/</guid>
      <pubDate>Thu, 28 Nov 2024 12:01:14 GMT</pubDate>
    </item>
    <item>
      <title>人工智能模型评估中配对 t 检验的最佳实践：是否固定超参数？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1u5y3/best_practice_for_paired_ttest_in_ai_model/</link>
      <description><![CDATA[您好， 我是一名学生，我们正在评估同一 AI 模型的两个版本，用于 NLP 任务，具体来说是一个单任务学习版本和一个多任务学习版本。我们计划使用配对 t 检验来比较其性能（精度、召回率、f1 分数）。我理解需要多次训练和测试模型（例如 10 次运行）以考虑可变性。我们使用分层的训练-验证-测试分割而不是 k 倍，所以我们一次又一次地重新运行模型。 但是，我对一个方面不确定：  我是否应该在所有运行中保持超参数（例如学习率、批量大小等）固定，而只改变随机种子？ 或者最好在每次运行中稍微调整超参数以捕获更多变化？     提交人    /u/Paizahn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1u5y3/best_practice_for_paired_ttest_in_ai_model/</guid>
      <pubDate>Thu, 28 Nov 2024 11:41:52 GMT</pubDate>
    </item>
    <item>
      <title>您如何解释 BLEU 增加而 ChrF 减少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1tzgm/how_do_you_explain_increase_in_bleu_but_decrease/</link>
      <description><![CDATA[  由    /u/SalamanderThick1390  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1tzgm/how_do_you_explain_increase_in_bleu_but_decrease/</guid>
      <pubDate>Thu, 28 Nov 2024 11:29:29 GMT</pubDate>
    </item>
    <item>
      <title>机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1tsjr/machine_learning_course/</link>
      <description><![CDATA[寻找班加罗尔附近的机器学习课程。最好找一些真正优秀的、能亲自动手教学的培训师。任何帮助都值得感激。    提交人    /u/raghavdarkseid   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1tsjr/machine_learning_course/</guid>
      <pubDate>Thu, 28 Nov 2024 11:16:19 GMT</pubDate>
    </item>
    <item>
      <title>我找不到将实际结果与预期结果进行比较并将其标记为正面或负面的数据集（产品质量控制）。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1tkgj/i_cant_find_a_data_set_that_compares_actual/</link>
      <description><![CDATA[您好， 我想参与这个项目，但找不到数据集。有人能帮我吗？在这种情况下我该怎么办？或者有人有这样的数据集的链接吗？提前谢谢了    提交人    /u/Salakhosh   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1tkgj/i_cant_find_a_data_set_that_compares_actual/</guid>
      <pubDate>Thu, 28 Nov 2024 11:00:46 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity Pro 1 年代金券（查看反馈）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1t07u/perplexity_pro_1_year_vouchers_check_feedback/</link>
      <description><![CDATA[我的服务提供商提供的 1 年 Perplexity Pro 代金券，价格为 29 美元（通常为 200 美元） 这包括访问以下高级模型：  Claude 3.5 Sonnet、Claude 3.5 Haiku（Opus Removed）、Grok-2 GPT-4o、o1 Mini 用于推理和Llama 3.1 图像生成器：Flux.1、DALL-E 3、Playground v3 Stable Diffusion XL  全球适用，为保护买家权益，接受通过 PayPal 付款。 工作原理：  开始聊天 或 Discord 通过 PayPal 或加密货币付款 促销确认链接已兑换..  买家担保，反馈 2、反馈 3、反馈 4、反馈 5    提交人    /u/AICentralZA   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1t07u/perplexity_pro_1_year_vouchers_check_feedback/</guid>
      <pubDate>Thu, 28 Nov 2024 10:21:27 GMT</pubDate>
    </item>
    <item>
      <title>需要面部检测方面的帮助：面部重叠和数据不平衡的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1shus/need_help_with_face_detection_issues_with/</link>
      <description><![CDATA[大家好， 我目前正在进行一个人脸检测项目，我的代码在人脸检测方面做得不错，但我面临几个问题：  重叠人脸：有时，人脸会重叠或被错误检测，这会影响准确性。 数据不平衡：我的数据集不平衡，有些人的代表性不足，导致这些人脸的检测不正确或很差。  我正在寻找有关如何解决这些问题的建议。具体来说，我需要有关以下方面的建议：  为某人收集更多照片：有任何提示或工具可以为数据集中代表性不足的个人收集更多图像吗？ 图像增强：有任何特定的图像增强方法可以帮助平衡数据并提高模型的稳健性吗？ 其他方法：如果我应该探索任何其他方法或技巧，我愿意接受建议。  提前感谢您的帮助！    提交人    /u/Spidey_qbz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1shus/need_help_with_face_detection_issues_with/</guid>
      <pubDate>Thu, 28 Nov 2024 09:44:44 GMT</pubDate>
    </item>
    <item>
      <title>DS/ML 和应用科学面试怎么会比 SWE 面试难这么多呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1rsjw/how_can_dsml_and_applied_science_interviews_be/</link>
      <description><![CDATA[我与亚马逊进行了最后 5 轮应用科学面试。 每轮面试内容如下：（每轮 1 小时，单日面试）  ML 广度（所有经典 ML 和 DL，所有内容都将进行一定深度测试，+ 数学推导） ML 深度（深入研究您的一般研究领域/或切线，激烈的质问） 编码（ML Algos 编码 + Leetcode 媒介） 科学应用：ML 系统设计，解决一些广泛的问题 行为：Bar Raiser 就领导原则进行 1.5 小时质问  您需要对 ML 中无限数量的概念有广泛而深入的知识，并且能够回忆和准确地重现它们，包括数学。 这么多本身基本上是不可能实现的（特别是对于像我这样记忆力和回忆能力较差的人来说）。 即使在您的研究领域（这本身就是一个巨大的领域），也可能有大量问题或整个领域您一无所知。 + 您需要与 SWE 2 相同级别的编码。 ______ 而这正是包括亚马逊在内的几乎所有公司中的 SWE 所需要的： - Leetcode 练习。 - 如果是高级，则进行系统设计。 我很擅长 Leetcode - 它是临时思考和解决问题的。即使没有练习，我在编码测试中也做得很好，通过练习，你基本上可以看到大多数问题和模式。 我根本不擅长记住软边缘支持向量机的晦涩理论细节，然后突然跳到为什么 RLHF 有问题，将 LLM 与人类偏好相结合，然后被告知从头开始在 PyTorch 中编写稀疏注意力 ______ 最糟糕的是，在掌握了这么多知识并付出了这么多努力之后，得到的报酬是一样的。即使是工作也要困难 100 倍，因为你可能需要做的事情种类繁多。 与此相反，你通常会作为 SWE 拥有一套专业知识，在某个领域建立明确的能力，并且总是可以毫无问题地跳到任何只需要这些而不需要其他任何东西的工作中。    提交人    /u/anotheraccount97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1rsjw/how_can_dsml_and_applied_science_interviews_be/</guid>
      <pubDate>Thu, 28 Nov 2024 08:51:21 GMT</pubDate>
    </item>
    <item>
      <title>最新的 MacBook Pro/MacBook Air 适用于深度学习吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1prl0/latest_macbook_pro_macbook_air_for_deep_learning/</link>
      <description><![CDATA[我有特定要求。我选择 MacBook（而不是基于 Windows 的机器）是因为电池寿命（对我来说非常重要），而且我一生都是 Linux/Mac 用户。但是我对选择哪款 MacBook 感到困惑，是选择最好的还是只选择基本款以节省一些钱。 我的技术栈/主要工作：我主要从事计算机视觉工作，但有时也从事 LLM 工作。做研究。尝试实现论文（主要基于 Linux，有时库/构建至少在我的 Intel Mac 上不起作用，只能在 Linux 上工作）。我也做视频编辑工作（这就是选择 Mac 的原因） MacBook Pro：如果我要使用它，我会选择带有 M4 Pro（14 核 CPU，20 核 GPU）的 MBP。它有 24 GB 的总 RAM。现在，我认为我不会在这台机器上进行直接训练。但我认为最好有这样的计算来进行推理，或者构建/编译项目，或者更好地创建数据（图像、视频）。但我仍然需要 SSH/云 GPU 来训练我的模型（这就是我目前的做法）。 MacBook Air：我会省下所有的钱，只需将这台机器连接到 SSH/云 GPU，然后用省下的钱购买云代币。但我想知道无风扇机器能否维持工作负载，尤其是长时间每天 10-12 小时。另外，本地没有推理（我怀疑）。所以在这种情况下我会完全依赖云。另外，这对于视频编辑来说不是很好（但我没问题，因为我偶尔会这样做）。 我应该选哪一个？你觉得这些机器怎么样？ PS：我知道有一款带风扇和 M4 的基准 MacBook Pro，但我宁愿跳过它，购买具有更快 SSD 和更多 RAM 的基准 M4 pro。     由    /u/DramaticCloud1498 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1prl0/latest_macbook_pro_macbook_air_for_deep_learning/</guid>
      <pubDate>Thu, 28 Nov 2024 06:28:33 GMT</pubDate>
    </item>
    <item>
      <title>新推理 LLM：QwQ 在多个基准测试中击败 OpenAI-o1</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1nkck/new_reasoning_llm_qwq_beats_openaio1_on_multiple/</link>
      <description><![CDATA[阿里巴巴最新的推理模型 QwQ 在许多基准测试中击败了 o1-mini、o1-preview、GPT-4o 和 Claude 3.5 Sonnet。该模型只有 32b，并且完全开源。查看如何使用它：https://youtu.be/yy6cLPZrE9k?si=wKAPXuhKibSsC810    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1nkck/new_reasoning_llm_qwq_beats_openaio1_on_multiple/</guid>
      <pubDate>Thu, 28 Nov 2024 04:13:23 GMT</pubDate>
    </item>
    <item>
      <title>𝗨𝗻𝗱𝗲𝗿𝘀𝘁𝗮𝗻𝗱𝗶𝗻𝗴 𝗧𝗼𝗸𝗲𝗻𝗶𝘇𝗮𝘁𝗶𝗼𝗻 𝗶𝗻 𝗟𝗮𝗿𝗴𝗲 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗠𝗼𝗱𝗲𝗹𝘀: 𝗪𝗼𝗿𝗱, 𝗖𝗵𝗮𝗿𝗮𝗰𝘁𝗲𝗿, 𝗮𝗻𝗱 𝗕𝘆𝘁𝗲 𝗣𝗮𝗶𝗿 𝗘𝗻𝗰𝗼𝗱𝗶𝗻𝗴</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1n1dn/𝗨𝗻𝗱𝗲𝗿𝘀𝘁𝗮𝗻𝗱𝗶𝗻𝗴_𝗧𝗼𝗸𝗲𝗻𝗶𝘇𝗮𝘁𝗶𝗼𝗻_𝗶𝗻_𝗟𝗮𝗿𝗴𝗲_𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲/</link>
      <description><![CDATA[      Tokenizer 自然语言处理是自然语言处理的基石（NLP），多年来，已经开发出各种方法来优化它。其中最值得注意的方法是基于字、基于字符和字节对编码 (BPE)。 𝗪𝗼𝗿𝗱-𝗯𝗮𝘀𝗲𝗱：虽然直观，但它需要维护庞大的词汇量——高达 𝟭𝟳𝟬,𝟬𝟬𝟬 𝗰𝘂𝗿𝗿𝗲𝗻𝘁 𝘄𝗼𝗿𝗱𝘀（牛津词典）和 47,000 个过时的单词。尽管如此，它仍在努力应对未知单词标记。 𝗖𝗵𝗮𝗿𝗮𝗰𝘁𝗲𝗿-𝗯𝗮𝘀𝗲𝗱：通过将词汇量减少到英语中仅有 𝟮𝟱𝟲 𝗰𝗵𝗮𝗿𝗮𝗰𝘁𝗲𝗿𝘀，它解决了未知标记问题。但是，它无法有效地保留单词的语义。 𝗕𝘆𝘁𝗲 𝗣𝗮𝗶𝗿 𝗘𝗻𝗰𝗼𝗱𝗶𝗻𝗴 (𝗕𝗣𝗘)：字节对编码 (BPE) 是一种基于子词的标记器。它的工作原理是将最常见的相邻字符对迭代合并为一个单元，直到达到所需的词汇量。它通过将单词分解为子单词、有效处理未知标记以及与基于单词的编码相比保持词汇量易于管理，达到了完美的平衡。 这种在保持语义连贯性的同时处理看不见的单词的能力使得 BPE 标记器成为大多数 𝗺𝗼𝗱𝗲𝗿𝗻 𝗹𝗮𝗿𝗴𝗲 𝗹𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗺𝗼𝗱𝗲𝗹𝘀 的标准。 标记化创新是我们今天在 NLP 中看到的进步的关键推动因素！  要深入了解 tokenizer，我强烈建议您观看以下视频： • 使用 Python 从 Scratch 编写 LLM Tokenizer：https://youtu.be/rsy5Ragmso8 • GPT Tokenizer：字节对编码：https://youtu.be/fKd8s29e-l4 作者：Raj Abhijit Dandekar 𝘍𝘰𝘳 𝘴𝘪𝘮𝘪𝘭𝘢𝘳谢谢大家的支持：Pritam Kudale 我们的未来之路谢谢你Vizuara！ --- 您可以在此处加入新闻通讯： https://9bfb8b39.sibforms.com/serve/MUIFAJFcOMHmiNnOggw1w5qD7tmpEtKMgA6BKj_WzggssRmgSDHoVWfB1OZOjVAB7uaJYCbWnvH-HG2NpolvOj6qHUOLkEJ5YA_cwnKeEIKulJ_h6NhvVaX9yGKM3ACtCZ5eITK80_zhvdz8uOdHfW46XkLnTiZsZzyX4nfyr6pzGMAumdmlv-UNZcYsNI5YipaBImsHcnpCeibg    提交人    /u/Ambitious-Fix-3376   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1n1dn/𝗨𝗻𝗱𝗲𝗿𝘀𝘁𝗮𝗻𝗱𝗶𝗻𝗴_𝗧𝗼𝗸𝗲𝗻𝗶𝘇𝗮𝘁𝗶𝗼𝗻_𝗶𝗻_𝗟𝗮𝗿𝗴𝗲_𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲/</guid>
      <pubDate>Thu, 28 Nov 2024 03:43:17 GMT</pubDate>
    </item>
    <item>
      <title>我快要疯了。我向 MLE 职位投递了 200 份简历，但只有 10 次面试。我做错了什么？我应该补充什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h126tg/im_slowly_losing_my_mind_200_resumes_sent_for_mle/</link>
      <description><![CDATA[        提交人    /u/Bitter-Surprise-7508   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h126tg/im_slowly_losing_my_mind_200_resumes_sent_for_mle/</guid>
      <pubDate>Wed, 27 Nov 2024 11:28:31 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>