<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Wed, 05 Mar 2025 06:27:19 GMT</lastBuildDate>
    <item>
      <title>在开发RNN网络方面需要帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3vz5y/need_help_with_developing_rnn_network/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3vz5y/need_help_with_developing_rnn_network/</guid>
      <pubDate>Wed, 05 Mar 2025 05:30:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么在多类分类中使用SoftMax层？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3v6g6/why_use_softmax_layer_in_multiclass_classification/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   softmax之前，我们得到了logits，从-inf到 +inf。在SoftMax之后，我们获得了从0到1的概率。在此之后，我们确实以最大的概率获得了班级。 如果我们在逻辑本身上确实进行了argmax，则完全跳过了软磁性层，我们仍然获得与输出相同的类，因为SoftMax之后的最大logit以来，Softmax之后的最大logit是最大的概率。 sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unewer_ordinary2051     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j3v6g6/why_use_softmax_layer_in_mlyer_in_multiclass_classification/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3v6g6/why_use_softmax_layer_in_multiclass_classification/</guid>
      <pubDate>Wed, 05 Mar 2025 04:44:12 GMT</pubDate>
    </item>
    <item>
      <title>笔记本电脑建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3uce7/laptop_recommendation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在市场上，主要用于数据科学任务（主要用于ML/DL），我非常感谢一些建议。我将在几个月内上一所大学，我的预算可以达到120000印度卢比或1400美元。我知道大多数云工作都将是在线服务，例如Google Collacn，拥有一个不错的GPU/SPECS？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/comments/1j3uce7/laptop_recommendation/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3uce7/laptop_recommendation/</guid>
      <pubDate>Wed, 05 Mar 2025 03:57:14 GMT</pubDate>
    </item>
    <item>
      <title>努力跟上压倒性的研究洪水？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3turs/struggling_to_keep_up_with_the_overwhelming_flood/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感谢所有查看我以前关于Arxiv论文摘要工具的文章的人！ 我已经收到了大量的积极反馈，令人鼓舞的是，令人鼓舞的是，很高兴看到有多少工作人员和学生在每天的范围内添加了一个强大的𝐍𝐞𝐰𝐍𝐞𝐰：   - 𝐁𝐚𝐭𝐜𝐡𝐁𝐚𝐭𝐜𝐡：您现在可以根据特定关键字和日期范围从arxiv获取并总结所有论文**。使用此工具，您可以自动汇总所有这些工具（并查看每个关键字存在多少纸），而无需打开任何文章。现在，您可以毫不费力地跟踪您领域中不断发展的研究趋势！ 🔗查看更新的 github repo 。。您认为接下来应该添加什么？ 🤔 𝐒𝐨𝐦𝐞𝐒𝐨𝐦𝐞𝐢𝐝𝐞𝐚𝐬𝐦𝐭𝐡𝐢𝐧𝐤𝐢𝐧𝐠：   - 𝐀𝐮𝐭𝐨𝐦𝐚𝐭𝐢𝐜𝐀𝐮𝐭𝐨​​𝐦𝐚𝐭𝐢𝐜𝐋𝐢𝐭𝐞𝐫𝐚𝐭𝐮𝐫𝐞𝐑𝐞𝐯𝐢𝐞𝐰：想象一下，请自动从成千上万的摘要论文中生成全面的文献综述。    - 𝐏𝐚𝐭𝐭𝐞𝐫𝐧＆amp; 𝐓𝐫𝐞𝐧𝐝𝐓𝐫𝐞𝐧𝐝：如果该工具可以自动检测到跨论文的模式并突出显示新兴趋势或新的研究领域？   - 𝐑𝐞𝐬𝐞𝐚𝐫𝐜𝐡𝐑𝐞𝐬𝐞𝐚𝐫𝐜𝐡𝐆𝐚𝐩：我们能否创建一个自动系统，以确定基于分析的论文的研究差距？ 我对我的建议和协作使该工具变得更好。让我们共同努力，建立一个开源资源，该资源可以向前迈进，并帮助研究人员保持领先地位！ 如果您觉得此工具很有用，请考虑主演回购！我将在接下来的几个月中完成博士学位，并寻找工作，因此您的支持肯定会有所帮助。预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j3turs/struggling_to_keep_kep_ep_ep_ep_with_with_the_the_overwhellming_flood/”&gt; [link]     [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3turs/struggling_to_keep_up_with_the_overwhelming_flood/</guid>
      <pubDate>Wed, 05 Mar 2025 03:30:03 GMT</pubDate>
    </item>
    <item>
      <title>动手：公司将如何建立协作代理AI工作流程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3tawq/handson_how_companies_will_build_collaborative/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3tawq/handson_how_companies_will_build_collaborative/</guid>
      <pubDate>Wed, 05 Mar 2025 03:01:19 GMT</pubDate>
    </item>
    <item>
      <title>AI生成的Nefertiti的DBSCAN聚类 - 一种机器学习方法。与K-均值不同，DBSCAN适应复杂的形状，而无需预定簇。工具：Python，OpenCV，Matplotlib。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3scg5/dbscan_clustering_of_aigenerated_nefertiti_a/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/aiwithashwin      &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j3scg5/dbscan_clustering_aigenerated_nefertiti_a/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3scg5/dbscan_clustering_of_aigenerated_nefertiti_a/</guid>
      <pubDate>Wed, 05 Mar 2025 02:12:55 GMT</pubDate>
    </item>
    <item>
      <title>有人在数据科学领域具有背景/职业是否足以让我知道他们对此课程的想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3qi2e/is_anyone_with_a_backgroundcareer_in_data_science/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3qi2e/is_anyone_with_a_backgroundcareer_in_data_science/</guid>
      <pubDate>Wed, 05 Mar 2025 00:42:43 GMT</pubDate>
    </item>
    <item>
      <title>ML路线图 -  Andrew NG ML专业化与CS229</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3p30s/ml_roadmap_andrew_ng_ml_specialization_vs_cs229/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，我是计算机工程学的大学生，我最近拿起了机器学习。我在Andrew Ng在Coursera上的ML专业化中的一半，但是我遇到了CS229，我听说这非常深入且基于理论（我很好）。我想知道我是否应该还要完成当前的Coursera课程，并在此之后观看CS229，因为我计划在整个夏季进行大型ML项目。在夏天开始之前，我正在尝试在ML和深度学习中学习尽可能多的知识（在这里和那里进行小型项目）。  当我已经进入Coursera课程的一半时，还是应该在此过程中学习时，值得花CS229吗？我的下一个计划是做一个小型项目，并潜入学习深度学习。任何其他建议都将不胜感激，因为我想理想地开始在6月左右开始该项目，并且我有学校的工作要平衡和东西直到夏天：   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3p30s/ml_roadmap_andrew_ng_ml_specialization_vs_cs229/</guid>
      <pubDate>Tue, 04 Mar 2025 23:36:20 GMT</pubDate>
    </item>
    <item>
      <title>该DBSCAN动画动态簇指向，从而发现没有预定义组的隐藏结构。与K-均值不同，DBSCAN适应复杂的形状 - 创建AI驱动的生成模式。想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3m9g6/this_dbscan_animation_dynamically_clusters_points/</link>
      <description><![CDATA[   &lt;img alt=&quot;This DBSCAN animation dynamically clusters points, uncovering hidden structures without predefined groups. Unlike K-Means, DBSCAN适应复杂的形状 - 创造AI驱动的生成模式？” src =“ https://external-preview.redd.it/ym91cndocgpycw1lmvb-37ihhiyhyhyhyhyhyhyhyhy0xeqvm7ygzywh306qicnm4gluiof 29mh.png？width = 640＆amp; crop = smart＆amp; auto = webp＆amp; s = 44AFF6466832DE4DBC6D2FD721D8007F933AFF17A“ title =“此DBSCAN动画动态簇指向，揭示了没有预定义组的隐藏结构。与K-均值不同，DBSCAN适应复杂的形状 - 创建AI-DREAD的生成模式。想法？” /&gt;   ＆＃32;提交由＆＃32; /u/u/aiwithashwin       [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3m9g6/this_dbscan_animation_dynamically_clusters_points/</guid>
      <pubDate>Tue, 04 Mar 2025 21:35:21 GMT</pubDate>
    </item>
    <item>
      <title>使用LLM进行时间序列分类和聚类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3jzkp/using_an_llm_for_timeseries_classification_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对使用LLM的新手很新，所以这也许不是那么有趣的“发现”，但我仍然认为这很酷。我能够使用Gemini 2.0在时间序列数据上同时执行分类和聚类。我在这里有一个简短的笔记本：  https://github.com/BlankAdventure/snippets/blob/main/Python/llm/demo.ipynb I was pretty surprised it actually worked!现在让我感到好奇，这有很大的学术兴趣吗？我知道内部的学习一直是在变压器体系结构和解释性上进行探索的积极研究领域。 （作为旁注，我熟悉ML技术，所以是的，我意识到使用LLM为此非常愚蠢，但我认为从理论角度来看）。提交由＆＃32; /u/quasievil     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3jzkp/using_an_llm_for_timeseries_classification_and/</guid>
      <pubDate>Tue, 04 Mar 2025 20:00:35 GMT</pubDate>
    </item>
    <item>
      <title>Google免费在COLAB中发布数据科学代理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3hxzq/google_released_data_science_agent_in_colab_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Google启动了集成在COLAB中的数据科学代理，您只需要上传文件并询问诸如构建分类管道，显示洞察力等任何问题，显示了洞察力等。测试了该代理，看上去很体面，但有错误，并且无法在某些EV数据上训练一个回归模型。在这里了解更多信息： https://youtu.be/94hbbp-4n8o        &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/mehul_gupta1997       [link]       [注释]    ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3hxzq/google_released_data_science_agent_in_colab_for/</guid>
      <pubDate>Tue, 04 Mar 2025 18:37:20 GMT</pubDate>
    </item>
    <item>
      <title>我创建了一种SoftMax算法，但从未给我确切的值。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j3fxvi/i_created_a_softmax_algorithm_but_never_give_me/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我仅出于学习目的而创建了一些有关SoftMax算法的代码。我达到的矢量总和是0,99998这是一个真正的问题？为什么？这如何影响我的预测的精度？ 编辑1：该值将用作Logistc回归的激活器。 编辑2：我将float d_type变量和向量切换到更精确的d_type，在这种情况下为长期双倍。现在，我已经需要精确度，总和达到1.00   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/smooth_atmosphere_24      &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j3fxvi/i_created_a_softmax_algorithm_but_but_but_never_never_never_give_give_me/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j3fxvi/i_created_a_softmax_algorithm_but_never_give_me/</guid>
      <pubDate>Tue, 04 Mar 2025 17:17:08 GMT</pubDate>
    </item>
    <item>
      <title>终于掌握了6名玩家的Deep CFR无限制扑克！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j39moo/finally_mastered_deep_cfr_in_6_player_no_limit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  经过数月尝试开发能干的扑克模型，并在此过程中面临许多失败之后，我终于创建了一个AI，它不仅可以击败我，而且不仅可以击败我，而且每个人都认识的每个人，包括在桌子上播放的一些专业扑克玩家，他们在桌子上播放了他们的榜首。  https://github.com/dberweger.com/dberweger2017/deepcffr-texas-texas-no-texas-no-limit-holdem-holdem-6-players fornection fornect解释完整的架构，我的发展旅程和结果： https://medium.com/@davide_95694/mastering-poker-poker-with-with-deep-cfr-building-an-ai-for-6-player-no-limit-texas-holdem-759d3ed8e600     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j39moo/finally_mastered_deep_deep_deep_cfr_cfr_in_6_player_no_no_limit/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/lealelnmachinelearning/comments/1j39moo/finally_mastered_deep_cfr_in_6_6_player_no_no_no_no_no_no_limit/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j39moo/finally_mastered_deep_cfr_in_6_player_no_limit/</guid>
      <pubDate>Tue, 04 Mar 2025 12:27:00 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace“ LLM推理”免费认证课程是现场的</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j30i33/huggingface_llm_reasoning_free_certification/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;   huggingface已在＆quoting上推出了新的免费课程。用于解释如何构建诸如DeepSeek-R1之类的模型。该课程特别关注加强学习。链接： https://huggingface.co/reasoning-course     &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mehul_gupta1997       [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j30i33/huggingface_llm_reasoning_free_certification/</guid>
      <pubDate>Tue, 04 Mar 2025 02:34:38 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到这里   对于那些正在寻找简历评论的人，请在 href =“ href =“ https://www.reddit.com/r/resumes”&gt;/r/简历或 r/EngineeringResumes 首先，然后在此处交叉crosspost。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>