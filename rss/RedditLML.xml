<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 22 Dec 2023 00:59:22 GMT</lastBuildDate>
    <item>
      <title>使用在医学 MNIST 数据集上预训练的 PyTorch 模型对气胸进行二元分类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o2fwi/pneumothorax_binary_classification_using_pytorch/</link>
      <description><![CDATA[      使用在医学 MNIST 数据集上预训练的 PyTorch 模型进行气胸二元分类 https://debuggercafe.com/气胸二元分类使用-pytorch-model-pretrained-on-medical-mnist-dataset/ ​ https://preview.redd.it/7wo9y17rvq7c1.png?width=1000&amp;format= png&amp;auto=webp&amp;s=2637f8425662dd3ef1d6c5bbb0e91d7952da34ae   由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/18o2fwi/pneumothorax_binary_classification_using_pytorch/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o2fwi/pneumothorax_binary_classification_using_pytorch/</guid>
      <pubDate>Fri, 22 Dec 2023 00:57:10 GMT</pubDate>
    </item>
    <item>
      <title>目前人体语义分割的SotA是多少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o2c6j/what_is_the_current_sota_in_human_body_semantic/</link>
      <description><![CDATA[我一直在谷歌搜索，但我似乎找不到人体语义分割的当前最先进的实现。我正在尝试找到一个高效的预训练 pyTorch 模型。 ​ 有人有任何指导吗？   由   提交/u/I-cant_even  /u/I-cant_even  reddit.com/r/learnmachinelearning/comments/18o2c6j/what_is_the_current_sota_in_ human_body_semantic/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o2c6j/what_is_the_current_sota_in_human_body_semantic/</guid>
      <pubDate>Fri, 22 Dec 2023 00:52:06 GMT</pubDate>
    </item>
    <item>
      <title>如何跳过 AWS Glue 中不存在的 S3 对象加载？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o1zo6/how_to_skip_non_existent_s3_objects_loading_in/</link>
      <description><![CDATA[ 由   提交/u/atticusfinch975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o1zo6/how_to_skip_non_existent_s3_objects_loading_in/</guid>
      <pubDate>Fri, 22 Dec 2023 00:35:30 GMT</pubDate>
    </item>
    <item>
      <title>我在 RL 和 CV 之间左右为难，哪一种更适合在大公司找到研究职位？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o1kix/im_torn_between_rl_and_cv_which_one_is_better_for/</link>
      <description><![CDATA[我正在学习 ML/DL，现在我需要选择一条要遵循和专注的道路。我喜欢 RL 和 DL。简历，幸运的是我有机会与我的教授一起研究这两个学科。然而，我只是不知道该学习哪一个，或者也许我应该说先学习，因为很可能我也会学习并且将来需要与另一个一起工作，但现在我无法决定。它们看起来都很有趣，都看起来很有挑战性，都看起来很有趣。因此，现在我考虑哪一个是在 OpenAI、Google 等大公司寻找研究职位的更好选择。我愿意接受任何建议，并且确实需要一个建议。   由   提交 /u/Trevorego   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o1kix/im_torn_between_rl_and_cv_which_one_is_better_for/</guid>
      <pubDate>Fri, 22 Dec 2023 00:15:37 GMT</pubDate>
    </item>
    <item>
      <title>解释基于文本的法学硕士如何查看和生成新图像（Dall-E、Deepmind Gemini）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o10yp/explaining_how_textbased_llms_view_and_generate/</link>
      <description><![CDATA[       由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o10yp/explaining_how_textbased_llms_view_and_generate/</guid>
      <pubDate>Thu, 21 Dec 2023 23:50:19 GMT</pubDate>
    </item>
    <item>
      <title>用于存储 ML 模型数据的 NAS 或服务器</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18o0rox/nas_or_server_for_storing_data_for_ml_models/</link>
      <description><![CDATA[免责声明：在 ML 方面，我非常业余。 我目前正在致力于构建基于 CNN 的分类模型（python/pytorch）使用大型成像文件（准确地说是数字化组织学幻灯片）。每个文件至少有 1 GB，我正在数千个文件上训练模型（目前总计约 4 TB）。我目前正在使用我的台式电脑（Windows 11、128 RAM、intel i9-12900K CPU、NVIDIA 3090ti GPU、驱动器之间的总存储量为 14 TB）。 我计划大幅增加训练量我将要处理的数据，因此我需要扩展我的存储能力并确保数据安全和备份。将来我可能想添加更多 GPU 来训练更大的模型（我不知道这将如何与 NAS 和服务器配合使用）。 您认为实现这一目标的最佳方法是什么？我与一位同事交谈过，他使用 Synology NAS 来实现非常相似的目的，因此我正在考虑使用 Synology NAS（可能是 DS423+ 或 DS923+）。 如有任何帮助，我们将不胜感激。 &lt; !-- SC_ON --&gt;  由   提交/u/V--------   &lt; a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/18o0rox/nas_or_server_for_storing_data_for_ml_models/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18o0rox/nas_or_server_for_storing_data_for_ml_models/</guid>
      <pubDate>Thu, 21 Dec 2023 23:38:39 GMT</pubDate>
    </item>
    <item>
      <title>用 Java 从头开始​​学习神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nzli9/neural_network_from_scratch_in_java/</link>
      <description><![CDATA[       由   提交/u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nzli9/neural_network_from_scratch_in_java/</guid>
      <pubDate>Thu, 21 Dec 2023 22:46:53 GMT</pubDate>
    </item>
    <item>
      <title>有抱负的数据科学家竞赛：Citadel x Correlation One 女子数据马拉松 2024</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nyovk/competition_for_aspiring_data_scientists_citadel/</link>
      <description><![CDATA[您好！我是 Calais，在 Correlation One 的业务团队工作。我们是一家总部位于纽约的初创公司，为顶尖大学的 STEM 学生举办数据科学和工程竞赛。 今年 2 月 9 日至 11 日，我们将与 Citadel 和 Citadel 合作举办一场现场女性数据马拉松证券。 此处查看！这是一项数据科学竞赛，向所有正在攻读 STEM 学位的女性本科生开放。此次活动的重点是营造一种氛围，让 STEM 领域的女性能够相互联系并建立一个专业社区，同时获得数据科学实践经验。 受邀学生将全程飞往迈阿密。 -为期两天的活动的付费旅行！ 鉴于此页面的重点是机器学习，我认为你们中的一些人可能会感兴趣。如需了解完整详情并进行申请，您可以使用以下链接。我们还有一系列区域性春季活动，将向所有本科生和研究生开放，在这里找到。如果您有任何问题，请给我发私信！   由   提交 /u/Correlation_One   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nyovk/competition_for_aspiring_data_scientists_citadel/</guid>
      <pubDate>Thu, 21 Dec 2023 22:06:09 GMT</pubDate>
    </item>
    <item>
      <title>理解“稳定扩散”AI模型构建的学习路径</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nu3co/learning_path_for_understanding_the_construction/</link>
      <description><![CDATA[我最近通过学习 CNN 和 RNN 课程开始了深度学习之旅（AndrewNG 的深度学习专业化） 。我特别有兴趣了解“稳定扩散”是如何产生的。人工智能模型已构建及其内部工作原理。 考虑到我目前的知识，您能否为我提供路线图或建议资源以加深我的理解？接下来我应该深入研究哪些主题来弥合差距并理解稳定的基于扩散的模型的复杂性？ 任何建议、推荐课程或学习路径将不胜感激！预先感谢您的见解。这项技术的发展速度让我感到不知所措。我目前是一名计算机科学本科生，希望攻读计算机科学硕士学位。如果您能提供任何建议，我也将不胜感激。   由   提交/u/Ok_Science_867   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nu3co/learning_path_for_understanding_the_construction/</guid>
      <pubDate>Thu, 21 Dec 2023 18:46:38 GMT</pubDate>
    </item>
    <item>
      <title>Langchain、LlamaIndex 与 OpenAI GPT：您应该使用哪一个？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ntbp9/langchain_vs_llamaindex_vs_openai_gpts_which_one/</link>
      <description><![CDATA[    /u/OnlyProggingForFun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ntbp9/langchain_vs_llamaindex_vs_openai_gpts_which_one/</guid>
      <pubDate>Thu, 21 Dec 2023 18:13:30 GMT</pubDate>
    </item>
    <item>
      <title>打乱标签训练的意义</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nqh7s/significance_of_training_with_shuffled_labels/</link>
      <description><![CDATA[我刚刚观看了 3Blue1Brown 的这段视频，其中他提到了 Lisha Li 的研究，她使用随机排列的数据集标签来训练网络。他说，这是为了识别“最小化成本函数是否对应于图像中的任何结构，或者只是记忆”。 （即，正如 Lisha 所说，“记住正确分类的整个数据集”） https://youtu.be/IHZwWFHWa-w?si=aDGIG1zVMHtFlYk7&amp;t=1064 我的问题是如何通过随机打乱标签来解决这个问题？也就是说，仅仅因为汽车被贴上狗的标签而狗被贴上拖拉机的标签，这有什么区别呢？在我对标签的实际含义的理解中，我是否缺少一些隐含的知识？我的假设是，标签一旦打乱，在训练期间就保持不变。   由   提交 /u/OhDearAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nqh7s/significance_of_training_with_shuffled_labels/</guid>
      <pubDate>Thu, 21 Dec 2023 16:08:22 GMT</pubDate>
    </item>
    <item>
      <title>使用神经渲染在 iPhone 上进行光线追踪（评论中的演示）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18npcjc/raytracing_on_iphone_using_neural_rendering_demo/</link>
      <description><![CDATA[       由   提交/u/immortal_ray  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18npcjc/raytracing_on_iphone_using_neural_rendering_demo/</guid>
      <pubDate>Thu, 21 Dec 2023 15:17:58 GMT</pubDate>
    </item>
    <item>
      <title>数据科学访谈中的 ROC 曲线和 AUR</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nnpw6/roc_curve_and_aur_in_data_science_interviews/</link>
      <description><![CDATA[在初级数据科学回合中，许多面试官询问 ROC 和 AUC 曲线。深入理解这些概念不仅可以简化理解，还有助于掌握相关概念。 以下是面试中提出的一些问题： 1.您能解释一下真阳性、真阴性、假阳性和假阴性的值吗？ 2. 混淆矩阵代表什么？ 3. 您能详细说明一下ROC曲线吗？ 4. 为什么需要ROC曲线？ 5. 哪个阈值最适合我们的模型？ 6. 曲线下面积（AUC）的定义是什么？它代表什么？ 7. 如何使用 ROC 曲线比较两个模型？  在此处阅读正确的解释：https:// arshad-kazi.com/roc-curve-and-aur-from-scratch/   由   提交 /u/Amazing_Life_221   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nnpw6/roc_curve_and_aur_in_data_science_interviews/</guid>
      <pubDate>Thu, 21 Dec 2023 14:01:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从顶级排行榜 LLM 中删除了 50% 的权重，而不会对评估产生负面影响</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nn8tr/d_removed_50_of_the_weights_from_a_top/</link>
      <description><![CDATA[      我从顶级排行榜 LLM 中删除了 50% 的权重，而没有对评估产生负面影响。  使用 SparseML，我能够将 50% 的 SOLAR-10.7B-Instruct-v1.0 权重归零。  然后我将剩余的权重量化为 INT8。  结果令人惊奇！  ​ https://preview.redd.it/mvoae2noin7c1.png?width=927&amp;format=png&amp;auto=webp&amp;s=4a614bc9b8b3131727465804c813ec4e1efbb103 即使在修剪和量化之后模型到 50% 我仍然得到了出色的零样本评估结果。  ​ 尝试模型： ​ https://preview.redd.it/sa9d4lbpin7c1.png?width=1999&amp;format=png&amp;auto= webp&amp;s=b893faac3b88ff94350b6a2cac962dfc06955dfb 有趣的是，模型是一次性修剪和量化的。这意味着不进行再培训。  该过程的工作原理是使用校准数据集对模型进行分块修剪，同时调整其余权重以确保模型的准确性不受影响。  这里使用的算法是SparseGPT。  SparseGPT是一种训练后剪枝方法，用于高效、准确地压缩GPT3、Solar等大型语言模型。该模型可以一次性修剪法学硕士，同时将准确性损失降至最低。  由于 LLM 通常过度参数化，因此您可以删除大部分权重，从而改善推理过程中的延迟和吞吐量。  查看此处一次性修剪的 SOLAR-10.7B-Instruct-v1.0 模型： https://huggingface.co/neuralmagic/SOLAR-10.7B-Instruct-v1.0-pruned50-quant-ds  了解如何一次性优化模型：https ://github.com/neuralmagic/sparseml/tree/main/src/sparseml/transformers/sparsification/obcq 了解有关 SparseGPT 的更多信息：https://neuralmagic.com/blog/sparsegpt-remove-100-billion-parameters-for-free/&lt; /p&gt;   由   提交 /u/mwitiderrick   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nn8tr/d_removed_50_of_the_weights_from_a_top/</guid>
      <pubDate>Thu, 21 Dec 2023 13:38:49 GMT</pubDate>
    </item>
    <item>
      <title>适合初学者的机器学习博客</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18nf3zw/machine_learning_blogs_for_beginners/</link>
      <description><![CDATA[对于机器学习初学者来说，有哪些好的博客值得阅读？我了解 ML 的一些基础知识。  我知道大多数人会建议通过视频/Coursera 等学习，我已经做了一些，但我更喜欢阅读和学习。 欢迎任何好的教科书推荐以及。 （有关机器学习相关概念以及用于 ML 的数学的书籍）   由   提交/u/techhgal  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18nf3zw/machine_learning_blogs_for_beginners/</guid>
      <pubDate>Thu, 21 Dec 2023 05:12:40 GMT</pubDate>
    </item>
    </channel>
</rss>