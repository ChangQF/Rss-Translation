<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 08 Sep 2024 06:20:33 GMT</lastBuildDate>
    <item>
      <title>如何可视化 Python 图表？使用 Loom</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbr5jn/how_to_visualize_python_graphs_using_loom/</link>
      <description><![CDATA[我刚刚导出了 loom，这是一个 Python 库，可以为您的图表和图形添加动画效果，使其更加引人注目。在此处查看演示：https://youtu.be/5eZqREtMW_Y?si=hJCJbt7sXdWAnCdQ    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbr5jn/how_to_visualize_python_graphs_using_loom/</guid>
      <pubDate>Sun, 08 Sep 2024 06:12:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么 VAE 的方差会收敛到零（可能过度拟合）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbr4c2/why_does_the_variance_of_vae_converge_to_zero/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbr4c2/why_does_the_variance_of_vae_converge_to_zero/</guid>
      <pubDate>Sun, 08 Sep 2024 06:10:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 FastAI 进行基本 GAF 时间序列分类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbqt8j/basic_gaf_time_series_classification_using_fastai/</link>
      <description><![CDATA[我找不到使用 Gramian Angular Fields 和 FastAI 快速构建使用迁移学习的时间序列模型的简单示例，因此我在这里发布了一个：https://github.com/mkwatson/fastai-dl-playground/blob/main/GAF.ipynb 希望它对某些人有用！    提交人    /u/mkw5053   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbqt8j/basic_gaf_time_series_classification_using_fastai/</guid>
      <pubDate>Sun, 08 Sep 2024 05:49:25 GMT</pubDate>
    </item>
    <item>
      <title>[数学] 给初学者的一些概率论笔记</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbpxqa/math_some_probability_theory_notes_for_beginners/</link>
      <description><![CDATA[看到这个子版块总是会问需要多少数学知识，所以我迁移了关于概率论的杂乱笔记（这是第一门课程，所以对于本科生来说相当“基础”，没有测度论的废话）。第一门课程的大部分章节都在下面，我认为它为在阅读困难的教科书时打下了良好的基础，可能会有错误，欢迎 PR 以进一步做出贡献（只需向 https://github.com/gao-hongnan/omniverse 发起 PR - 如果你喜欢它，请给它一颗星）。 注意：它有一定的严谨性，所以如果你是数学符号的完全初学者，我建议你慢慢来。我试图使符号尽可能一致，但这很难！ 目录  数学预备知识 概率 离散随机变量 连续随机变量 联合分布 样本统计 估计理论  第 1 章：数学预备知识  排列与组合 微积分 等高线图  第 2 章：概率  概率空间 概率公理 条件概率 独立性 贝叶斯定理和全概率定律  第 3 章：离散随机变量  随机变量 离散随机变量 概率质量函数 累积分布函数 期望 矩和方差 离散均匀分布：概念、应用 伯努利分布：概念、应用 独立和相同分布 (IID) 二项分布：概念、实现、现实世界示例 几何分布：概念 泊松分布：概念、实现  第 4 章：连续随机变量  从离散到连续 连续随机变量 概率密度函数 期望 矩和方差 累积分布函数 均值、中位数和众数 连续均匀分布 指数分布 高斯分布 偏度和峰度 随机变量的卷积和求和 随机变量的函数  第 5 章：联合分布  从单变量到联合分布 联合 PMF 和 PDF 联合期望和相关性 条件PMF 和 PDF 条件期望和方差 随机变量之和 随机向量 多元高斯分布  第 6 章：样本统计  矩生成和特征函数 概率不等式 大数定律  第 8 章：估计理论  最大似然估计     提交人    /u/hyperverse-1992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbpxqa/math_some_probability_theory_notes_for_beginners/</guid>
      <pubDate>Sun, 08 Sep 2024 04:51:06 GMT</pubDate>
    </item>
    <item>
      <title>学习线性代数的最佳方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fborzx/best_way_to_learn_linear_algebra/</link>
      <description><![CDATA[嗨！我目前正在通过一些书籍学习机器学习，并参加 Kaggle 竞赛，我想问一下学习线性代数的最佳方法是什么。  我试着阅读 Gilbert Straang 的书，但我发现很难理解或看到我在 ML 中所做的事情的应用。那么，以更符合 ML 的方式学习线性代数的最佳方法是什么？谢谢！    提交人    /u/Gpenguin314   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fborzx/best_way_to_learn_linear_algebra/</guid>
      <pubDate>Sun, 08 Sep 2024 03:39:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：Ml 是什么意思？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbm78z/machine_learning_what_does_ml_mean/</link>
      <description><![CDATA[        提交人    /u/kuzgunnew   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbm78z/machine_learning_what_does_ml_mean/</guid>
      <pubDate>Sun, 08 Sep 2024 01:11:23 GMT</pubDate>
    </item>
    <item>
      <title>f1_score 低，但精度和召回率高</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbi6jx/low_f1_score_but_high_precision_and_recall/</link>
      <description><![CDATA[我正在 Keras 中训练神经网络，并使用精度、召回率和 f1_score 作为指标。但我得到的 f1_score 很低，但精度和召回率很高。由于 f1_score 是通过准确率和召回率计算得出的，那么 f1_score 是否也应该很高？ Epoch 1/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 22s 375ms/step - f1_score: 0.4756 - loss: 0.5549 - precision_3: 0.9111 - recall_3: 0.9111 Epoch 2/10 19/19 ━━━━━━━━━━━━━━━━━━━━━ 6s 330ms/step - f1_score: 0.4932 - loss: 0.1223 - precision_3: 0.9731 - recall_3: 0.9731 Epoch 3/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 7s 353ms/step - f1_score: 0.4946 - loss: 0.0836 - precision_3: 0.9788 - recall_3：0.9788 纪元 4/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 7 秒 358 毫秒/步 - f1_score：0.4910 - 损失：0.1209 - precision_3：0.9645 - recall_3：0.9645 纪元 5/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6 秒328ms/步 - f1_score：0.4893 - 损失：0.1384 - precision_3：0.9583 - recall_3：0.9583 纪元 6/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6s 331ms/步 - f1_score：0.4933 - 损失：0.0819 - precision_3：0.9736 - recall_3：0.9736 纪元 7/10 19/19 ━━━━━━━━━━━━━━━━━━━━━ 6s 334ms/step - f1_score: 0.4914 - loss: 0.0954 - precision_3: 0.9663 - recall_3: 0.9663 纪元 8/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 7s 344ms/step - f1_score: 0.4943 - loss: 0.0857 - precision_3: 0.9774 - recall_3：0.9774 纪元 9/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 7 秒 356 毫秒/步 - f1_score：0.4944 - 损失：0.0650 - precision_3：0.9778 - recall_3：0.9778 纪元 10/10 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 10s 356ms/step - f1_score：0.4902 - loss：0.1048 - precision_3：0.9616 - recall_3：0.9616    提交人    /u/Jeterion85   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbi6jx/low_f1_score_but_high_precision_and_recall/</guid>
      <pubDate>Sat, 07 Sep 2024 21:51:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该选择 CS 而不是 Stats 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbhfkk/should_i_have_gone_cs_instead_of_stats/</link>
      <description><![CDATA[我的统计本科只涉及监督式机器学习，整个学期的代码几乎都一样（唯一不同的是使用的模型及其超参数）。这门课更侧重于 KNN、SVM、决策树等背后的理论。 目前正在攻读应用统计硕士学位，可以选择数据科学方向，该方向有更多机器学习课程（NN、无监督、深度）。不过，我觉得我缺乏现实世界应用的计算机科学基础知识（数据结构知识），所以我目前只坚持统计学而不是 DS 路线。 我的教授开玩笑说，大多数时候他和其他博士会坐在圆桌旁，这样每个人都可以争论假设和准备工作，而编码则交给硕士持有者。  我在编程方面是否落后太多而无法真正发挥作用？    提交人    /u/Bruhhhhhhhhhhhhs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbhfkk/should_i_have_gone_cs_instead_of_stats/</guid>
      <pubDate>Sat, 07 Sep 2024 21:16:45 GMT</pubDate>
    </item>
    <item>
      <title>我尝试编写自己的 YOLO 模型来检测足球运动员</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbc6sk/i_tried_to_code_my_own_yolo_model_to_detect/</link>
      <description><![CDATA[        提交人    /u/AvvYaa   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbc6sk/i_tried_to_code_my_own_yolo_model_to_detect/</guid>
      <pubDate>Sat, 07 Sep 2024 17:22:45 GMT</pubDate>
    </item>
    <item>
      <title>深度学习项目？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbb6g4/projects_for_deep_learning/</link>
      <description><![CDATA[今年夏天我需要一份实习工作，但一直被拒绝。我想学习深度学习/机器学习，因为人工智能是未来，但我不知道该学什么。我知道这篇文章已经出现了一百万次，但我仍然需要一些建议。我不想制作一个使用线性回归的分类模型，因为我觉得它太基础了，我觉得任何类型的 NLP 模型或聊天机器人都是不可能的，因为 chatgpt 已经可以做到了，而且它并不突出。任何想法和资源都会有所帮助。     提交人    /u/Either-Clothes7212   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbb6g4/projects_for_deep_learning/</guid>
      <pubDate>Sat, 07 Sep 2024 16:38:51 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据的超参数调整 LSTM 网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fbav2b/hyper_parameter_tuning_lstm_network_on_time/</link>
      <description><![CDATA[      我正在尝试在时间序列数据上训练 LSTM 模型（包含四个 LSTM 层（每层 500 个单元）和三个 droupouts 以及一个用于进行回归的完全连接的输出层）。首先，我尝试在微小数据（几千条记录，每条窗口 200）上对模型进行过度拟合（训练数据 = 测试数据）。当我从微小的基本学习率（0.00005）开始时，我能够过度拟合数据（下图中的棕色运行）。（我在另一个问题中详细讨论了这一点）。 现在，我正在尝试在更大的数据集（几乎多出 300 倍的记录）上训练此模型。我观察到以下情况：  我逐步降低学习率 [0.00005, 0.000005, 0.0000005, 0.00000005]。 （我知道这是个奇怪的小学习率。但是，嘿，我只是尝试一下。我也尝试过拟合较小的数据，而且效果最好。如果我从 0.005 开始，我会得到非常非常糟糕的预测。）另外，只有当连续 7 个时期验证损失没有改善时，我才会降低 LR。如您在粉红色运行中所见，我降低了三次（lr_group_0 图表）。但我的验证损失仍然没有减少。并且它在非常高的损失处保持稳定（与 val_loss 图表中过拟合的棕色线相比）。 当 25 个时期后验证损失没有改善时，我提前停止了训练。您可以在 train_loss 图表中看到粉红色的线，它在高训练损失时达到稳定状态。  https://preview.redd.it/6zmqip0byend1.png?width=1179&amp;format=png&amp;auto=webp&amp;s=b62431010190f1d25e5e5126ef02c9e145984cb6 我有以下猜测：  我是否需要从较小的 LR 开始（0.000005）在对较大数据进行训练时比对较小数据进行过度拟合时（0.00005）更容易获得一致的验证和训练损失？ 我是否需要大幅增加退出概率？对于过度拟合，它是 0.1。我应该尝试 0.25 之类的值吗？ 我是否需要增加模型复杂度，比如六个 LSTM 层来改善训练损失？  我上面说的对吗？此外，还可以做些什么来提高模型性能？    提交人    /u/Tiny-Entertainer-346   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fbav2b/hyper_parameter_tuning_lstm_network_on_time/</guid>
      <pubDate>Sat, 07 Sep 2024 16:25:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么我需要很小的学习率来过度拟合模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fb9i7u/why_i_am_requiring_tiny_learning_rate_to_overfit/</link>
      <description><![CDATA[      我正在尝试在包含 160 万条记录的时间序列数据上训练 LSTM 模型。我已将窗口大小设为 200。 最初，我尝试在小型数据集（几千条记录）上过度拟合模型（训练数据 = 测试数据）。我观察到，如果我将基准 LR 设为 &gt; 0.00005（例如 0.005 或 0.0005），损失会迅速下降，但即使我逐步降低损失，损失也会在较高损失时趋于稳定。只有当我从基准 LR 0.00005 开始时，我才能很好地过度拟合。我认为这背后的原因是我的传感器读数范围很小。这里有三条记录: 0.23760258454545455,-0.22289974636363638,0.0001035681818190329,-0.04648843152272728,0.050574934999999994,0.07726843131818183 0.22356182786363635,-0.3411078932272727,-0.20997647727272656,0.10069696159090907,0.000854025636363637,0.020162423527272724 0.28690914204545453,-0.1688149386363636,0.21814179090909178,0.11453165154545455,0.11816517982272727,-0.011788583654545453  上面最小的幅度值为 0.0001035681818190329，最大的幅度值为 0.11816517982272727。 下面的屏幕截图显示了三次运行的训练和验证损失以及相应的学习率。从屏幕截图中可以看出，绿色和棕色运行从 LR 0.005 开始，逐步降低到 0.0005 和 0.00005。但是它们都以比使用恒定 LR 0.00005 的灰色运行更高的训练和验证损失达到稳定状态。此外，当我可视化输出预测时，它们对于灰色运行非常准确，而对于绿色和棕色，它们与基本事实相差甚远。当我进一步将 LR 逐步降低到 0.000005 和 0.0000005 时，我得到了更好的结果。 （仅当当前 LR 在 7 个 epoch 内没有改善测试损失时，我才会降低学习率。） https://preview.redd.it/mei48lp5nend1.png?width=1179&amp;format=png&amp;auto=webp&amp;s=13cfa3e57486bea88a3ee51f50e6468b13bcd644 问：我猜要过度拟合由如此小的值定义的空间，我可能需要微小的学习率 0.000005，以及更高的学习率对于由如此小的值定义的空间不起作用。我的理解正确吗？ PS：我尝试标准化这些值，但对于相同的训练配置，它确实给出了非常糟糕的预测。如果有人告诉我为什么会发生这种情况，我将不胜感激。我相信原始传感器值比缩放值提供了更有意义/更现实/更真实的数据，这就是为什么标准化不能提供更好的结果？    提交人    /u/Tiny-Entertainer-346   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fb9i7u/why_i_am_requiring_tiny_learning_rate_to_overfit/</guid>
      <pubDate>Sat, 07 Sep 2024 15:27:26 GMT</pubDate>
    </item>
    <item>
      <title>你是如何学会在生产环境中为 ML 系统编写干净的代码的？有什么建议或资源吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fb58z7/how_did_you_learn_to_write_clean_code_for_ml/</link>
      <description><![CDATA[我想知道您是如何学习为端到端 ML 生产生命周期编写干净的代码的。您可以分享您的经验和知识吗？我也在寻找好的资源。 谢谢    提交人    /u/Few-Imagination4433   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fb58z7/how_did_you_learn_to_write_clean_code_for_ml/</guid>
      <pubDate>Sat, 07 Sep 2024 11:58:48 GMT</pubDate>
    </item>
    <item>
      <title>[资源请求] 我可以利用空闲时间在手机上阅读/观看什么内容（以提高深度学习技能）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fb2zx1/resource_request_what_can_i_readwatch_to_upskill/</link>
      <description><![CDATA[当我不能使用笔记本电脑或代码时，我通常会发现自己有空闲时间。我总是随身带着手机。我一直试图利用这些时间阅读博客或观看视频。 我真的很好奇你们在空闲时间在手机上阅读或观看什么（在机器学习或深度学习的背景下）？ 我相信阅读一些博客会很好，但不知道是哪些。非常感谢您的建议。    提交人    /u/inclinedadarsh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fb2zx1/resource_request_what_can_i_readwatch_to_upskill/</guid>
      <pubDate>Sat, 07 Sep 2024 09:24:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>