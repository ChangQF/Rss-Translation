<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å­¦ä¹ æœºå™¨å­¦ä¹ </title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>è‡´åŠ›äºå­¦ä¹ æœºå™¨å­¦ä¹ çš„ Reddit å­ç‰ˆå—</description>
    <lastBuildDate>Fri, 05 Jan 2024 18:16:40 GMT</lastBuildDate>
    <item>
      <title>ä¸º Aiã€Mlã€Dl å¯»æ‰¾ä¸€å°åˆé€‚çš„ç¬”è®°æœ¬ç”µè„‘</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zd6d4/find_a_decent_laptop_for_ai_ml_dl_for_uni/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œæˆ‘ç¡®å®æœ‰å‡ ä¸ªé—®é¢˜ é¦–å…ˆæ˜¯ 4gb vram å¥½ä¸å¥½ï¼Œè‡³å°‘åœ¨æœªæ¥å‡ å¹´å†…å®ƒæ˜¯å¦èƒ½å®Œæˆè¿™é¡¹å·¥ä½œï¼Œå› ä¸ºæˆ‘æˆ‘ä¸è®¤ä¸ºæˆ‘å°†æ¥èƒ½å¤Ÿè´­ä¹°å¦ä¸€å°ï¼Œç¬¬äºŒæ˜¯æˆ´å°” Precision 5540 å¥½ä¸å¥½ï¼Œå®ƒæœ‰ Quadro t1000 4 GB VRAM å’Œè‹±ç‰¹å°” i7 9 ä»£ï¼Œå®ƒä¸æ˜¯æˆ‘çš„é¦–é€‰ï¼Œå› ä¸ºæˆ‘ä¸ä½¿ç”¨ 4k æ˜¾ç¤ºå±çœŸçš„ä¸éœ€è¦è€Œä¸”æ²¡æœ‰ä»¥å¤ªç½‘ç«¯å£ï¼Œè¿™å¯¹æˆ‘æ¥è¯´å¾ˆé‡è¦ï¼Œå› ä¸ºæˆ‘å¤§å­¦çš„ wifi ä¸å¤ªå¥½ ç¬¬ä¸‰æˆ‘åº”è¯¥ä¹°æ¸¸æˆç¬”è®°æœ¬ç”µè„‘è¿˜æ˜¯å·¥ä½œç«™   ç”±   æäº¤ /u/Nadoo_Alaa   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zd6d4/find_a_decent_laptop_for_ai_ml_dl_for_uni/</guid>
      <pubDate>Fri, 05 Jan 2024 18:03:06 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰äººåœ¨ä»–ä»¬çš„æ¨¡å‹ä¸­å®é™…ä½¿ç”¨ float16 æ··åˆç²¾åº¦å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zccyh/anyone_actually_using_float16_mixed_precision_in/</link>
      <description><![CDATA[æ ‡é¢˜å‡ ä¹è¯´æ˜äº†ä¸€åˆ‡ã€‚æˆ‘æœ€è¿‘å°è¯•åœ¨æ¨¡å‹ä¸­ä½¿ç”¨ float16 æƒé‡ï¼Œè¿™è®©æˆ‘æƒ³ï¼Œæˆ‘ä»æœªè§è¿‡æœ‰äººè¯´ä»–ä»¬ä½¿ç”¨æ··åˆç²¾åº¦ã€‚è¿™æ˜¯ä¸æ˜¯ç»å¸¸ä½¿ç”¨ï¼Œè¿˜æ˜¯æˆ‘åªæ˜¯ç¼ºå°‘ä½¿ç”¨å®ƒçš„é¡¹ç›®ï¼Ÿ æ­¤å¤–ï¼Œæ‚¨ä»€ä¹ˆæ—¶å€™ä¼šè€ƒè™‘ä½¿ç”¨æ··åˆç²¾åº¦è€Œä¸æ˜¯æ ‡å‡†å•ç²¾åº¦ï¼Ÿ   ç”±   æäº¤/u/Rajivrocks  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zccyh/anyone_actually_using_float16_mixed_precision_in/</guid>
      <pubDate>Fri, 05 Jan 2024 17:29:31 GMT</pubDate>
    </item>
    <item>
      <title>ML æˆ– Web å¼€å‘</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zcayw/ml_or_web_dev/</link>
      <description><![CDATA[æˆ‘çš„ Python æ°´å¹³å¤„äºä¸­çº§æ°´å¹³ï¼Œå¸Œæœ›åœ¨æœºå™¨å­¦ä¹  (ML) é¢†åŸŸä»äº‹èŒä¸šç”Ÿæ¶¯ã€‚ç„¶è€Œï¼Œæˆ‘çš„ä¸€ä½ç²¾é€š Web å¼€å‘çš„æœ‹å‹å»ºè®®æˆ‘ä¸è¦åšæŒä½¿ç”¨ Pythonã€‚ç›¸åï¼Œä»–ä»¬å»ºè®®å­¦ä¹ å…¶ä»–è¯­è¨€ï¼Œå¦‚ Java æˆ– C++ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æä¾›å¯¹å†…å­˜ç®¡ç†çš„æ›´æ·±å…¥çš„ç†è§£ã€‚æ­¤å¤–ï¼Œä»–ä»¬å»ºè®®æˆ‘è€ƒè™‘è½¬å‘ç½‘ç»œå¼€å‘ï¼Œå¹¶ä¸ºåˆå­¦è€…æä¾›äº†æ›´å¤šçš„èŒƒå›´å’Œæœºä¼šã€‚è¯·æä¾›æŒ‡å¯¼   ç”±   æäº¤/u/Lazy_Explanation_239   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zcayw/ml_or_web_dev/</guid>
      <pubDate>Fri, 05 Jan 2024 17:27:08 GMT</pubDate>
    </item>
    <item>
      <title>æ— æ³•ä½¿ç”¨ PANDAS groupby</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zbdkn/cant_use_pandas_groupby/</link>
      <description><![CDATA[       ä»»ä½•äººéƒ½å¯ä»¥è§£é‡Šä¸ºä»€ä¹ˆæˆ‘ä¼šæ”¶åˆ°æ­¤é”™è¯¯å¹¶ä¸”æ— æ³•åƒæˆ‘çš„è®²å¸ˆé‚£æ ·ä½¿ç”¨ grouby å‡½æ•° https://preview.redd.it/ypkyd8afinac1.png?width=866&amp;format=png&amp;auto=webp&amp; s=a65e600975814bf7d2b6bf0da0ac9d49f67d6294   ç”±   æäº¤/u/law_1821  [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zbdkn/cant_use_pandas_groupby/</guid>
      <pubDate>Fri, 05 Jan 2024 16:48:51 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰çš„å¥½åœ°æ–¹æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zb9b2/whats_a_good_place_to_learn_image_processing_and/</link>
      <description><![CDATA[æœ‰äººå‘æˆ‘æ¨èäº† Gonzalez çš„ä¹¦ï¼Œæˆ‘å°†å­¦ä¹ è¿™æœ¬ä¹¦ã€‚ä½†æˆ‘éœ€è¦ä¸€ä¸ªå…³äºå›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰çš„å®ç”¨å’Œæœºå™¨å­¦ä¹ æ–¹é¢çš„å¥½æ•™ç¨‹ã€‚æˆ‘å·²ç»é€šè¿‡å¤šæ¬¡è°·æ­Œæœç´¢ã€‚éœ€è¦æ›´å¤šæŠ•ç¥¨ï¼Œå‘µå‘µ   ç”±   æäº¤/u/SnooAdvice1157  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zb9b2/whats_a_good_place_to_learn_image_processing_and/</guid>
      <pubDate>Fri, 05 Jan 2024 16:43:58 GMT</pubDate>
    </item>
    <item>
      <title>soft-max åˆ›å»ºçš„æ¦‚ç‡æ˜¯å¦ä»£è¡¨æ¨¡å‹æ„Ÿå—åˆ°çš„æ¦‚ç‡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18zar0j/do_the_probabilities_created_by_softmax_represent/</link>
      <description><![CDATA[æˆ‘ä¸å¤ªç¡®å®šå¦‚ä½•è¡¨è¾¾è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯ softmax çš„è¾“å‡ºæ˜¯å¦ç»™å‡ºäº†æ¨¡å‹ç›¸ä¿¡çš„æ¦‚ç‡ï¼Ÿ  ä»æŠ€æœ¯ä¸Šè®²ï¼Œè¾“å‡ºæ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œä½†è¿™å¹¶ä¸ä¸€å®šæ„å‘³ç€å®ƒæ˜¯æ¨¡å‹â€œç›¸ä¿¡â€çš„æ¦‚ç‡ã€‚  å°±åƒå¦‚æœæˆ‘ä»¬æœ‰çŒ«æˆ–éçŒ«åˆ†ç±»å™¨ï¼Œå¹¶ä¸” softmax ä¹‹åçš„è¾“å‡ºæ˜¯ 0.7ã€0.3ï¼Œé‚£ä¹ˆå¯ä»¥å‡†ç¡®åœ°è¯´æ¨¡å‹è®¤ä¸ºå›¾åƒæœ‰ 70% çš„æœºä¼šæ˜¯ä¸€åªçŒ«ï¼Ÿæˆ–è€…è¯´softmaxä»…åœ¨å…³è”å¤§å°æ—¶æœ‰ç”¨ï¼Œå³åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªèƒ½è¯´æ¨¡å‹æ›´æœ‰ä¿¡å¿ƒå›¾åƒæ˜¯çŒ«è€Œä¸æ˜¯ä¸æ˜¯çŒ«ã€‚  æˆ‘æ˜¯å¦å¯¹æ¨¡å‹è¿›è¡Œäº†å¤ªå¤šçš„æ‹ŸäººåŒ–ï¼Ÿ   ç”±   æäº¤/u/Rit2Strong  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18zar0j/do_the_probabilities_created_by_softmax_represent/</guid>
      <pubDate>Fri, 05 Jan 2024 16:22:22 GMT</pubDate>
    </item>
    <item>
      <title>é¢„æµ‹æœªæ¥çš„æœ€ä½³æ¨¡å‹æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z9jzx/which_are_the_best_models_to_predict_the_future/</link>
      <description><![CDATA[æˆ‘è¯•å›¾é¢„æµ‹èƒ½æºæ¶ˆè€—ï¼Œç›®æ ‡æ˜¯é¢„æµ‹ 1 åˆ° 3 å¤©ã€‚æˆ‘æœ‰ä¸€ä¸ª 1.5 å¹´çš„æ¯æ—¥æ¶ˆè´¹æ•°æ®é›†ï¼Œå¤§çº¦æœ‰ 100 ä¸ªå®¢æˆ·ã€‚æˆ‘æƒ³çŸ¥é“å“ªç§æ¨¡å‹æœ€é€‚åˆè¿™ç§æƒ…å†µï¼Œå½“ç„¶æˆ‘ä¼šå°è¯•ä¸åŒçš„æ¨¡å‹ï¼Œä¾‹å¦‚ LSTMã€GRUã€XGboostï¼Œä½†ä¹Ÿè®¸å¯¹äºè¿™ç§æƒ…å†µæœ‰æ›´å¥½çš„æ¨¡å‹ã€‚ æå‰è°¢è°¢æ‚¨ã€‚   ç”±   æäº¤ /u/Matnaranjo   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z9jzx/which_are_the_best_models_to_predict_the_future/</guid>
      <pubDate>Fri, 05 Jan 2024 15:31:50 GMT</pubDate>
    </item>
    <item>
      <title>æœ¬å‘¨äººå·¥æ™ºèƒ½ä¸»è¦è¿›å±•ç®€è¿°ï¼ˆ2023 å¹´ 12 æœˆç¬¬ 4 å‘¨ + 2024 å¹´ 1 æœˆç¬¬ 1 å‘¨ï¼‰</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/</guid>
      <pubDate>Fri, 05 Jan 2024 15:14:07 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆè¿™ä¸ªæ„ŸçŸ¥å™¨ä¸å­¦ä¹ ï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z92te/why_doesnt_this_perceptron_learn/</link>
      <description><![CDATA[import pandas as pd import numpy as np train_set = np.array(pd.read_csv(&#39;/kaggle/input/mnist-in- csv/mnist_train.csv&#39;))[:1000] test_set = np.array(pd.read_csv(&#39;/kaggle/input/mnist-in-csv/mnist_test.csv&#39;))[2000:3000] train_labels = train_set[: , 0].T test_labels = test_set[:, 0].T X_train = train_set[:, 1:].T X_test = test_set[:, 1:].T print(&quot;X_train å½¢çŠ¶ï¼š&quot;, X_train.shape ) print(&quot;X_label shape: &quot;, train_labels.shape) print(&quot;è®­ç»ƒæ ‡ç­¾ shape: &quot;, train_labels.shape) print(&quot;æµ‹è¯•æ ‡ç­¾ shape: &quot;, test_labels.shape) # åˆå§‹åŒ–å‚æ•° def init_params (): w1 = np.random.rand(784, 10) b1 = np.random.rand(10, 1) w2 = np.random.rand(10, 10) b2 = np.random.rand(10, 1 ) return w1, b1, w2, b2 # åœ¨æ­¤å®šä¹‰æ¿€æ´»å‡½æ•° def ReLU(x): return np.maximum(0, x) def Softmax(x): exp_x = np.exp(x - np.max(x)) return exp_x / exp_x.sum() # å®šä¹‰æ‰€ç”¨æ¿€æ´»çš„å¯¼æ•° def der_ReLU(x): return np.where(x &lt;= 0, 0, 1) def der_Softmax(z): exps = np.exp(z ) sum_exps = np.sum(exps, axis=1, keepdims=True) softmax = exps / sum_exps return softmax * (1 - softmax) def one_hot_encode(Y): return np.eye(10)[Y].reshape(- 1, 1) print(one_hot_encode(5)) # å®šä¹‰æŸå¤±å‡½æ•° # æ ‡ç­¾å¿…é¡»æ˜¯ä¸€ä¸ªçƒ­ç¼–ç  def cost(output, label): epsilon = 1e-10 # å°å¸¸æ•°ä»¥é¿å… log(0) return -np .sum(label * np.log(output + epsilon)) / label.shape[1] def cost_derivative(output, label): return 2 * (output - label) # å‰å‘ä¼ é€’ def front(x, w1, b1, w2) , b2): Z1 = w1.T.dot(x) + b1 A1 = ReLU(Z1) Z2 = w2.dot(A1) + b2 A2 = Softmax(Z2) return Z1, A1, Z2, A2 # å‘åä¼ é€’ defå‘åï¼ˆXï¼ŒZ2ï¼ŒA2ï¼ŒA1ï¼ŒZ1ï¼ŒW2ï¼Œæ ‡ç­¾ï¼‰ï¼šdz2 = Z2 - æ ‡ç­¾ dw2 = dz2.dotï¼ˆA1.Tï¼‰ db2 = np.sumï¼ˆdz2ï¼Œaxis = 1ï¼Œkeepdims = Trueï¼‰# z1 çš„å¯¼æ•° dz1 = W2.T.dot(dz2) * der_ReLU(A1) dw1 = dz1.dot(X.T) db1 = np.sum(dz1, axis=1, keepdims=True) è¿”å› dw1, db1, dw2, db2 # æ›´æ–°å‚æ•° def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha): w1 = w1 - (alpha * dw1.T) w2 = w2 - (alpha * dw2) b1 = b1 - ( alpha * db1) b2 = b2 - (alpha * db2) return w1, b1, w2, b2 defgradient_descent(X, Y, num_epochs, alpha): &quot;&quot;&quot;åœ¨æŒ‡å®šçš„çºªå…ƒæ•°å†…æ‰§è¡Œéšæœºæ¢¯åº¦ä¸‹é™ã€‚ â€â€œâ€ w1, b1, w2, b2 = init_params() for epoch in range(num_epochs): loss = 0.0 for i in range(X.shape[1]): # è¿­ä»£æ ·æœ¬sample_X = X[:, i].reshape( -1, 1) # é‡å¡‘ä¸ºåˆ—å‘é‡sample_Y = Y[i] sample_Y = one_hot_encode(sample_Y) # å¯¹æ­¤æ ·æœ¬æ‰§è¡Œå‰å‘ä¼ é€’ã€åå‘ä¼ é€’å’Œæ›´æ–° Z1, A1, Z2, A2 =forward(sample_X, w1, b1) ã€w2ã€b2) dw1ã€db1ã€dw2ã€db2 = å‘å(sample_Xã€Z2ã€A2ã€A1ã€Z1ã€w2ã€sample_Y) w1ã€b1ã€w2ã€b2 = update_params(w1ã€b1ã€w2ã€b2ã€dw1ã€db1 , dw2, db2, alpha) loss += cost(A2, Sample_Y) # å®šæœŸæ‰“å°æŸå¤± if epoch % 50 == 0: # æ¯ 50 ä¸ªæ ·æœ¬æ‰“å°æŸå¤± print(&quot;Epoch:&quot;, epoch, &quot;Loss:&quot; ;, loss) return w1, b1, w2, b2 w1, b1, w2, b2 =gradient_descent(X_train, train_labels, 500, 0.01)  ä»¥ä¸Šæ˜¯æˆ‘çš„ä»£ç ã€‚æŸå¤±åŸºæœ¬ä¿æŒä¸å˜ã€‚æˆ‘ä¸è®¤ä¸ºè¿™æ˜¯å­¦ä¹ ç‡é—®é¢˜ã€‚å¾ˆå¯èƒ½æ˜¯æˆ‘é€ æˆäº†ä¸€äº›ç»“æ„æ··ä¹±ã€‚  ä»»ä½•å¸®åŠ©å°†ä¸èƒœæ„Ÿæ¿€ï¼   ç”±   æäº¤ /u/GraphicsMonster   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z92te/why_doesnt_this_perceptron_learn/</guid>
      <pubDate>Fri, 05 Jan 2024 15:10:41 GMT</pubDate>
    </item>
    <item>
      <title>æ•°å­¦å¸®åŠ©</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z90i1/math_help/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚è¯·å»ºè®®ä¸€äº› ML æ•°å­¦å…ˆå†³æ¡ä»¶ã€‚æˆ‘æ˜¯ä¸€åè®¡ç®—æœºç§‘å­¦æ¯•ä¸šç”Ÿï¼Œæ‰€ä»¥æˆ‘å¯¹ç¼–ç¨‹æœ‰å¾ˆå¥½çš„äº†è§£ï¼Œä½†æˆ‘åœ¨æ•°å­¦æ–¹é¢å¾ˆå¼±ã€‚æ‚¨èƒ½ç»™æˆ‘æ¨èä¸€äº›æœ‰å…³çº¿æ€§ä»£æ•°ã€ç»Ÿè®¡ä»¥åŠ MLops æ‰€éœ€çš„æ‰€æœ‰æ•°å­¦æ¦‚å¿µçš„èµ„æºå—ï¼Ÿ   ç”±   æäº¤/u/KryPyThon  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z90i1/math_help/</guid>
      <pubDate>Fri, 05 Jan 2024 15:07:43 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•é€šè¿‡å†·ç”µå­é‚®ä»¶è·å¾—ä¼˜ç§€æ•™æˆçš„ç ”ç©¶å®ä¹ æœºä¼šï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z40z6/how_to_get_research_internships_under_great_profs/</link>
      <description><![CDATA[æˆ‘æ˜¯ä¸€åæ•°æ®ç§‘å­¦ä¸“ä¸šçš„æœ¬ç§‘ç”Ÿï¼Œå¯¹ MLã€DL å’Œ Python æœ‰ç›¸å½“çš„äº†è§£ã€‚ æˆ‘ä¸€ç›´å¸Œæœ›åœ¨ä¸€äº›ç‹¬ç‰¹ä¸”æœ‰åˆ›æ„çš„ä¸œè¥¿ä¸Šåšå¤§é‡çš„å·¥ä½œã€‚ä½†æˆ‘å¾—åˆ°çš„å¤§å¤šæ•°æƒ³æ³•éƒ½æœ‰æ•™ç¨‹ã€‚æˆ‘æ„è¯†åˆ°ï¼Œé€šè¿‡åˆ†æ­¥æ•™ç¨‹åšä¸€äº›äº‹æƒ…ä¸ä¼šç»™æˆ‘çš„ä¸ªäººèµ„æ–™å¢åŠ ä»»ä½•ä»·å€¼ã€‚ ä¸»è¦é—®é¢˜æ˜¯æˆ‘æ²¡æœ‰ä¸€ä¸ªé—ªäº®çš„ä½œå“é›†ï¼Œå…¶ä¸­æœ‰è®¸å¤šæˆå°±ç­‰ï¼Œæœ‰äººä¼šç«‹å³é›‡ç”¨å®ƒæˆ‘å°±åƒå®ä¹ ç”Ÿä¸€æ ·ã€‚æˆ‘åªæœ‰ä¸€ä¸ªå…³äºç®€å• ML çš„å°é¡¹ç›®å’Œä¸€ä¸ªéå¸¸æ ‡å‡†çš„ç¥ç»é£æ ¼è¿ç§»é¡¹ç›®ï¼Œå°½ç®¡æˆ‘å¯èƒ½æ‹¥æœ‰æ¯”è¿™äº›é¡¹ç›®æ‰€å±•ç¤ºçš„æ›´å¤šçš„ ML/DL çŸ¥è¯†ã€‚æˆ‘ä¹Ÿè¯»è¿‡ä¸€äº›è®ºæ–‡å’Œåšå®¢ã€‚ æˆ‘çš„å¤§å­¦æ²¡æœ‰åœ¨è¿™ä¸ªé¢†åŸŸå·¥ä½œçš„ä¼˜ç§€æ•™æˆï¼Œæ‰€ä»¥æˆ‘æƒ³åœ¨ CMU ç­‰å¤§å­¦çš„æ•™æˆï¼ˆæ’åå‰ 100 çš„å¤§å­¦ï¼‰çš„æ•™æˆæŒ‡å¯¼ä¸‹å·¥ä½œcrankings AIï¼‰ã€‚ æˆ‘å¦‚ä½•å—è˜ä¸ºä¸€åæœ¬ç§‘ç”Ÿç ”ç©¶å®ä¹ ç”Ÿå¹¶ä¸ä¼˜ç§€æ•™æˆä¸€èµ·æ’°å†™ç ”ç©¶è®ºæ–‡ï¼Œè€Œä¸”æˆ‘å¦‚ä½•æ‰¾åˆ°æ„¿æ„æ¥å—æˆ‘çš„äººï¼Ÿ    ;ç”±   æäº¤/u/clever-machine  /u/clever-machine  reddit.com/r/learnmachinelearning/comments/18z40z6/how_to_get_research_internships_under_great_profs/&quot;&gt;[é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z40z6/how_to_get_research_internships_under_great_profs/</guid>
      <pubDate>Fri, 05 Jan 2024 10:42:57 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚æœæˆ‘ä¸æƒ³ä»äº‹NLPå·¥ä½œï¼Œæˆ‘è¿˜éœ€è¦å­¦ä¹ NLPå—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18z2hvy/do_i_need_to_learn_nlp_if_i_dont_want_to_work/</link>
      <description><![CDATA[æˆ‘æœ€è¿‘åˆšåˆšæ‰¾åˆ°ç¬¬ä¸€ä»½å·¥ä½œï¼Œæ‹…ä»» CV é¡¹ç›®çš„ ML å·¥ç¨‹å¸ˆã€‚ç„¶è€Œï¼Œå½“æˆ‘æ¥å—é‡‡è®¿æ—¶ï¼Œæœ‰ä¸€äº›å…³äºNLPçš„é—®é¢˜ã€‚æˆ‘å–œæ¬¢è®¡ç®—æœºè§†è§‰é—®é¢˜ï¼Œæˆ‘ç¡®å®å–œæ¬¢ä¼ æ„Ÿå™¨èåˆå’Œè¡¨æ ¼æ•°æ®ï¼Œä½†æˆ‘å°±æ˜¯æ— æ³•å¿å—å¤„ç†æ–‡æœ¬æ•°æ®ã€‚æ‰€ä»¥æˆ‘çš„é—®é¢˜æ˜¯æˆ‘éœ€è¦ç»§ç»­å­¦ä¹ NLPå’Œæˆ‘æ„Ÿå…´è¶£çš„ä¸œè¥¿å—ï¼Ÿå³ä½¿å®é™…é¡¹ç›®ä¸éœ€è¦ï¼Œä¹Ÿä¼šä¸€ç›´æœ‰å…³äºNLPï¼ˆåˆçº§ã€ä¸­çº§ã€é«˜çº§â€¦â€¦ï¼‰çš„é—®é¢˜å—ï¼Ÿ   ç”±   æäº¤/u/tepes_creature_8888   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18z2hvy/do_i_need_to_learn_nlp_if_i_dont_want_to_work/</guid>
      <pubDate>Fri, 05 Jan 2024 09:00:05 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ æœºå™¨å­¦ä¹ çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18yzvek/what_is_the_best_way_to_learn_machine_learning/</link>
      <description><![CDATA[æˆ‘æƒ³å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ ã€‚ä½†æˆ‘çœ‹åˆ°å¾ˆå¤šäººè¯´äº†å¾ˆå¤šä¸œè¥¿...æœ‰äººè¯´æœ€å¥½è´­ä¹°è¯¾ç¨‹ï¼Œæœ‰äººè¯´æœ€å¥½é€šè¿‡åšé¡¹ç›®å¼€å§‹å­¦ä¹ ... æˆ‘æœ‰ä¸€ç‚¹ç¼–ç¨‹èƒŒæ™¯ã€‚ â€¦â€¦æˆ‘çš„ç›®æ ‡æ˜¯ä»äº‹æ•°æ®ç§‘å­¦/æœºå™¨å­¦ä¹ é¢†åŸŸçš„èŒä¸šã€‚ä½†æˆ‘ä¸çŸ¥é“å¦‚ä½•å¼€å§‹ã€‚å› ä¸ºæˆ‘å–œæ¬¢ä»¥ç»“æ„åŒ–çš„æ–¹å¼å’Œç±»ä¼¼äºå­¦æœ¯çš„ç¯å¢ƒå­¦ä¹ ï¼Œæ‰€ä»¥æˆ‘æƒ³æˆ‘ä¼šä» mit ocw è¯¾ç¨‹å¼€å§‹å­¦ä¹ ã€‚ä½†æ˜¯ä½ çœ‹ï¼Œæœ‰äº›äººçœŸçš„åªæ˜¯å…ˆå¼€å§‹å­¦ä¹ åº“ï¼ˆæ¯”å¦‚ pandasã€numpy ç­‰ï¼‰ã€‚  æˆ‘æƒ³å°†æœºå™¨å­¦ä¹ å­¦ä¹ åˆ°å®Œå…¨æŒæ¡åŸºç¡€çŸ¥è¯†çš„æ°´å¹³ã€‚ é‚£ä¹ˆï¼Œä½ ä»¬è®¤ä¸ºå¼€å§‹å­¦ä¹  ML çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆä»¥åŠéœ€è¦å¤šé•¿æ—¶é—´ä½ ä»¬è®¤ä¸ºæˆ‘éœ€è¦æŒæ¡åŸºç¡€çŸ¥è¯†ã€‚ æå‰æ„Ÿè°¢æ‚¨çš„å®è´µæ—¶é—´..ğŸ˜   ç”±   æäº¤ /u/juspassingby___-_-   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18yzvek/what_is_the_best_way_to_learn_machine_learning/</guid>
      <pubDate>Fri, 05 Jan 2024 06:11:47 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œä½¿ç”¨ä¸å†³ç­–æ ‘ä¸åŒçš„å˜é‡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18yyvnf/why_does_neural_network_use_different_variables/</link>
      <description><![CDATA[æˆ‘ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ•°æ®é›†æ„å»ºäº†ä¸€ä¸ªç¥ç»ç½‘ç»œå’Œä¸€ä¸ªå†³ç­–æ ‘ã€‚æˆ‘çš„ç¥ç»ç½‘ç»œä¸­å…·æœ‰æœ€é«˜ shapley å€¼çš„å˜é‡ä¸æˆ‘çš„å†³ç­–æ ‘ä¸­çš„é¡¶éƒ¨èŠ‚ç‚¹å˜é‡å®Œå…¨ä¸åŒã€‚ä¸ºä»€ä¹ˆè¿™ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹è®¤ä¸ºä¸åŒçš„å˜é‡é›†å¾ˆé‡è¦ï¼Ÿ   ç”±   æäº¤ /u/Traditional_Soil5753   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18yyvnf/why_does_neural_network_use_different_variables/</guid>
      <pubDate>Fri, 05 Jan 2024 05:17:46 GMT</pubDate>
    </item>
    <item>
      <title>è‡ªç„¶è¯­è¨€å¤„ç† (NLP) å­¦ä¹ è·¯å¾„ - æ·±å…¥</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/</guid>
      <pubDate>Thu, 04 Jan 2024 21:15:12 GMT</pubDate>
    </item>
    </channel>
</rss>