<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 17 May 2024 18:19:04 GMT</lastBuildDate>
    <item>
      <title>K-Means 聚类算法的可视化指南。👥</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cua97t/a_visual_guide_to_the_kmeans_clustering_algorithm/</link>
      <description><![CDATA[      TL;DR：K-Means 聚类根据相似性将数据点分组为聚类，这使其适用于客户细分、图像分割和文档聚类等应用。 K-Means 聚类可视化指南  https://preview.redd.it/92n1nckko01d1.png?width=936&amp;format=png&amp;auto=webp&amp;s=ae4bfeb8fa4ee1399afc03447cbf5bc95563d464    提交人    /u/ml_a_day   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cua97t/a_visual_guide_to_the_kmeans_clustering_algorithm/</guid>
      <pubDate>Fri, 17 May 2024 16:54:48 GMT</pubDate>
    </item>
    <item>
      <title>与最新法学硕士的文本相似度</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu7voj/text_similarity_with_latest_llms/</link>
      <description><![CDATA[假设您有两个文本，您想要定量测量它们传达相同含义的程度，并且您关心微妙的细节，例如内在逻辑是否有意义等这样粗略的旧的和更小的 BERT 模型就不行了。  任何人都可以向我指出最近使用最新的法学硕士（例如 Llama3）进行此类操作的参考文献吗？    由   提交/u/Invariant_apple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu7voj/text_similarity_with_latest_llms/</guid>
      <pubDate>Fri, 17 May 2024 15:18:47 GMT</pubDate>
    </item>
    <item>
      <title>在视频（或文本）上训练人工智能以使用人工智能创建新视频的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu7mcz/what_would_be_the_best_way_to_train_ai_on_videos/</link>
      <description><![CDATA[例如： 假设您有一个电视节目已经结束，并且您想使用 AI 来创建新一季。是否有可能根据过去的季节来训练人工智能来制作新剧集？ 另外，有没有办法通过同人小说写作来做到这一点？ 会怎样？最简单的方法？   由   提交 /u/number001   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu7mcz/what_would_be_the_best_way_to_train_ai_on_videos/</guid>
      <pubDate>Fri, 17 May 2024 15:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] LoRA 基础知识和低阶微调</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu7h66/d_fundamentals_of_lora_and_lowrank_finetuning/</link>
      <description><![CDATA[  由    /u/Patrick-239  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu7h66/d_fundamentals_of_lora_and_lowrank_finetuning/</guid>
      <pubDate>Fri, 17 May 2024 15:02:45 GMT</pubDate>
    </item>
    <item>
      <title>如何评价降维算法的好坏？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu7d7l/how_do_you_evaluate_how_good_a_dimensionality/</link>
      <description><![CDATA[我一直在尝试寻找人们如何选择要减少的维度的方法，但到目前为止我还没有任何运气。我基本上找不到关于这个主题的任何内容，尽管这似乎是一个非常明显的问题。人们是否只是选择任意数量的维度，然后继续使用它？ 对于 PCA，有解释方差，而且您可以将逆变换应用于减少的数据，然后计算重建误差。但是，一旦您不使用像 PCA 这样的线性东西（因此没有解释的方差）并且使用没有明确/容易获得的逆变换的东西（例如自动编码器和 PCA）。例如，如果您使用 t-SNE、UMAP、isomaps、稀疏/内核/增量 PCA、ICA 等，您将如何评估/理解是否有足够的维度来完全捕获数据集？ 这如何推广到更高级的方法，如嵌入或流形学习？   由   提交 /u/Amun-Aion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu7d7l/how_do_you_evaluate_how_good_a_dimensionality/</guid>
      <pubDate>Fri, 17 May 2024 14:58:42 GMT</pubDate>
    </item>
    <item>
      <title>在我的无限注意力实现中需要 NaN 的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu702s/need_help_with_nans_in_my_infiniattention/</link>
      <description><![CDATA[大家好， 我目前正在致力于实现来自 本文，但我一直遇到一个问题，即我的实现不断产生 NaN。在循环的第一次迭代中，_update_memory 的 memory 和 norm_term 输出非常大，到下一次迭代时，一切都变成了NaN。我不确定我的代码中是否存在错误，或者 Infini-Attention 本质上不稳定。 这是我当前的实现： class Attention(nn.Module) : def __init__( self: &quot;Attention&quot;, causal: bool = True, Heads: int = 8, infini: bool = True, segment_len: int = 1024, ) -&gt;无： super().__init__() 断言不是 version.parse(torch.__version__) &lt; version.parse(“2.0.0”),“sdpa 需要 torch&gt;=2.0.0” self.causal = 因果 self.infini = 无限 self.segment_len = segment_len # sdpa 配置 self.cpu_config = _config(True, True, True) if infini: self.gate = nn.Parameter(torch.full((1, 头, 1, 1), -100.0)) 如果不是 torch.cuda.is_available(): return device_properties = torch.cuda.get_device_properties(torch.device(&quot;cuda&quot;)) 如果 device_properties.major == 8 并且 device_properties.minor = = 0: self.cuda_config = _config(True, False, False) else: self.cuda_config = _config(False, True, True) defforward_sdpa( self: “注意力”, q: torch.Tensor, k: torch.Tensor , v: torch.Tensor, ) -&gt; torch.Tensor: is_cuda, dtype = v.is_cuda, v.dtype config = self.cuda_config if is_cuda else self.cpu_config 与 torch.backends.cuda.sdp_kernel(**config._asdict()): q = q.half( ) k = k.half() v = v.half() q, k, v = (t.contigious() for t in (q, k, v)) 比例 = q.shape[-1] ** - 0.5 q = q * 横向扩展 = F.scaled_dot_product_attention( q, k, v, is_causal=self.causal, ) return out.to(dtype) def _retrieve_from_memory( self: &quot;Attention&quot;, q: torch.Tensor, memory:可选[torch.Tensor] = None，norm_term：可选[torch.Tensor] = None，）-&gt; torch.Tensor：如果内存为None或norm_term为None：返回torch.zeros_like（q）q = F.elu（q）+ 1.0内存= torch.matmul（q，内存）norm_term = torch.matmul（q，rearrange（ norm_term, &quot;b 1 1 d -&gt; b 1 d 1&quot;), ) 返回内存 /norm_term def _update_memory( self: &quot;Attention&quot;, k: torch.Tensor, v: torch.Tensor, memory: 可选[torch .Tensor] = None，norm_term：可选[torch.Tensor] = None，）-&gt; torch.Tensor: k = F.elu(k) + 1.0 如果内存不是 None: 内存 = 内存 + torch.matmul(rearrange(k, &quot;b h n d -&gt; b h d n&quot;), v) 否则: 内存 = torch .matmul(rearrange(k, &quot;b h n d -&gt; b h d n&quot;), v) ifnorm_term 不是 None: # noqa: SIM108norm_term =norm_term + k.sum(dim=-2, keepdim=True) else:norm_term = k.sum(dim=-2, keepdim=True) 返回内存，norm_term def front_infini( self: &quot;Attention&quot;, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, ) -&gt; torch.Tensor: n_segments = q.shape[-2] // self.segment_len # 假设序列长度可以被段长度整除 q, k, v = (rearrange(t, &quot;b h (s n) d -&gt; b h s n d&quot; ;, s=n_segments) for t in (q, k, v)) 输出 = [] 内存 = Nonenorm_term = None for idx in range(n_segments): q_segment = q[:, :, idx, :, :] k_segment = k[:, :, idx, :, :] v_segment = v[:, :, idx, :, :] 内存输出 = self._retrieve_from_memory(q_segment, 内存,norm_term) update_memory, Updated_norm_term = self._update_memory( k_segment, v_segment ，内存，norm_term，）内存= Updated_memory.detach（）norm_term = Updated_norm_term.detach（） attn = self.forward_sdpa（q_segment，k_segment，v_segment）combined_output =（F.sigmoid（self.gate）* memory_output）+（1 - F.sigmoid(self.gate)) * attn ports.append(combined_output) out = torch.cat(outputs, dim=-2) return out defforward( self: &quot;Attention&quot;, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, ) -&gt; torch.Tensor: if self.infini: return self.forward_infini(q, k, v) return self.forward_sdpa(q, k, v)  这里有人成功实现了无限注意力吗并让它发挥作用？任何帮助将不胜感激！ 其他上下文：我的数据是一维（某种）时间序列。   由   提交 /u/TheDisturbedBooty   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu702s/need_help_with_nans_in_my_infiniattention/</guid>
      <pubDate>Fri, 17 May 2024 14:44:11 GMT</pubDate>
    </item>
    <item>
      <title>您使用什么软件与本地大语言模型交互？为什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu6dso/what_software_do_you_use_to_interact_with_local/</link>
      <description><![CDATA[您使用 deepchecks、KoboldCpp、LM Studio、PrivateGPT、GPT4All 等吗？ 您喜欢您的解决方案的哪些方面？您使用多个吗？你做RAG吗？您正在做其他人可能认为独特或新颖的事情吗？   由   提交 /u/UpvoteBeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu6dso/what_software_do_you_use_to_interact_with_local/</guid>
      <pubDate>Fri, 17 May 2024 14:18:49 GMT</pubDate>
    </item>
    <item>
      <title>自动数据分析Python包要知道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu4t3o/auto_data_analysis_python_packages_to_know/</link>
      <description><![CDATA[查看此视频教程，探索不同的 AutoEDA python 软件包，如 pandas-profiling、sweetviz、dataprep 等，这些软件包可以在几分钟内轻松实现自动数据分析: https://youtu.be/Z7RgmM4cI2I?si=8GGM50qqlN0lGzry   由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu4t3o/auto_data_analysis_python_packages_to_know/</guid>
      <pubDate>Fri, 17 May 2024 13:11:50 GMT</pubDate>
    </item>
    <item>
      <title>10 门最佳高级机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu3r1p/10_best_advanced_machine_learning_courses/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu3r1p/10_best_advanced_machine_learning_courses/</guid>
      <pubDate>Fri, 17 May 2024 12:20:36 GMT</pubDate>
    </item>
    <item>
      <title>有助于可视化神经网络的新平台</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cu20j0/a_new_platform_that_helps_visualising_neural/</link>
      <description><![CDATA[在过去的一年里，我开始从事这个项目，以帮助简化神经网络的设计和开发。我想在这里分享它，以尽可能帮助新人了解深度学习。您基本上可以直观地设计、构建、训练和部署人工智能网络等等。非常感谢您的反馈和支持！我会让您看一下。 产品搜寻启动：https://www.producthunt.com /posts/neuralhub-beta 网站：https://neuralhub.ai/   由   提交/u/s_n_dev  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cu20j0/a_new_platform_that_helps_visualising_neural/</guid>
      <pubDate>Fri, 17 May 2024 10:38:55 GMT</pubDate>
    </item>
    <item>
      <title>无法清除 2 岁的数据科学 OA 需要您的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctvyrp/unable_to_clear_data_science_oa_for_2_yoe_need/</link>
      <description><![CDATA[嗨，在过去的两个月里，我为三家公司提供了 OA，连一家都无法清除。 询问的主题 UBS 1 DSA ,1 探索性数据分析案例研究 ZS 统计、NLP、DSA（做不到） IBM DSA（做不到）、SQL  我擅长处理 sql 类型的问题、基本的 DSA，但不擅长处理硬 DSA 问题和统计或 EDA。 你们如何为此类主题准备任何建议、您关注的资源。我想重新开始我的学习，包括DSA。说实话💔申请了很多职位后都得到了上述公司的回复，但连OA都无法通关😔。   由   提交/u/Left_Tip_7300   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctvyrp/unable_to_clear_data_science_oa_for_2_yoe_need/</guid>
      <pubDate>Fri, 17 May 2024 03:45:01 GMT</pubDate>
    </item>
    <item>
      <title>有没有涵盖这些主题的书籍或课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctuqdo/is_there_any_book_or_courses_that_covers_these/</link>
      <description><![CDATA[       由   提交 /u/itsmekalisyn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctuqdo/is_there_any_book_or_courses_that_covers_these/</guid>
      <pubDate>Fri, 17 May 2024 02:37:49 GMT</pubDate>
    </item>
    <item>
      <title>coursera 上的机器学习专业化证书值得吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cttyuz/is_the_machine_learning_specialization_cert_on/</link>
      <description><![CDATA[作为对此感兴趣的大学一年级学生，值得吗？它与 Andrew Ng 的在线 YouTube 播放列表有什么不同吗？另外，证书在简历上好看吗？谢谢。   由   提交/u/Big_Dance_408   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cttyuz/is_the_machine_learning_specialization_cert_on/</guid>
      <pubDate>Fri, 17 May 2024 01:56:59 GMT</pubDate>
    </item>
    <item>
      <title>我很失落</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cttt4s/im_so_lost/</link>
      <description><![CDATA[您好，我目前是一所排名相当高的大学的数学 C 专业三年级学生，辅修数据科学。尽管我的专业如此，但我觉得我目前没有适销对路的技能，并且越来越担心我可能永远找不到工作。我最近通过目前正在学习的入门课程对机器学习产生了热情，并一直在学习 Aurélien Géron 的关于机器学习和温习线性代数技能的书。我将来想成为一名机器学习工程师或研究员，但老实说，我真的不知道自己应该关注什么。我有相当先进的统计背景，觉得我很容易学习新东西，但我很好奇我是否会犯一个错误，因为我真的不知道还能做什么。任何关于任何事情的建议将不胜感激，我现在​​只是感到没有方向。    由   提交/u/yeezyboy1254  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cttt4s/im_so_lost/</guid>
      <pubDate>Fri, 17 May 2024 01:48:45 GMT</pubDate>
    </item>
    <item>
      <title>作为高级软件工程师，我应该学习机器学习吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctgg0t/should_i_learn_machine_learning_as_already_senior/</link>
      <description><![CDATA[大家好， 我是一名拥有丰富经验的软件工程师，主要专注于后端开发，具有 DevOps 知识和强大的开发能力建筑背景。我主要使用 Java 和 Kotlin 工作，但也使用其他语言。 在您看来，为了跟上行业的发展而学习什么才有意义？您认为学习机器学习这个完全不同的领域值得付出努力吗？或者也许专注于利用第三方人工智能服务来增强我们的项目会更好？ 我的目标是学习一些有趣的东西，同时不会退出市场并冒着难以找到的风险如果需要的话，可以找一份新工作。 请考虑一下我没有太多的人工智能知识。我只使用了几次 OpenAI API 来实现一些简单的功能。 我最近发现了哈佛 CS50AI 或赫尔辛基大学的 Elements of AI，但我不确定我是否会进入一个太复杂的领域离我很远，如果我不转向机器学习工程，这是否值得付出努力。或者也许我错了，这对我的日常工作也可能有帮助。 你能帮我吗？正如你所看到的，我很困惑:) 非常感谢！   由   提交/u/sP0re90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctgg0t/should_i_learn_machine_learning_as_already_senior/</guid>
      <pubDate>Thu, 16 May 2024 16:04:05 GMT</pubDate>
    </item>
    </channel>
</rss>