<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 14 Mar 2024 06:17:24 GMT</lastBuildDate>
    <item>
      <title>1 位法学硕士时代 - 论文解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1beeiqn/the_era_of_1bit_llms_paper_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频这里我通过分析论文“The Era of 1-bit LLMs: All Large”来谈谈我们如何构建权重可以用1.58位表示的LLM以及这样做的优点是什么语言模型采用 1.58 位”。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1beeiqn/the_era_of_1bit_llms_paper_explained/</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:12 GMT</pubDate>
    </item>
    <item>
      <title>用于 ML 的 eGPU 或台式机，价格不超过 3200 美元</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bedvos/egpu_or_desktop_for_3200_or_less_for_ml/</link>
      <description><![CDATA[我的教授说他有 3200 美元的预算来购买用于研究的设备。  我们应该购买外部 GPU 还是台式机？ 您能告诉我：  使用 eGPU 会显着降低性能吗？ （我的笔记本电脑有 3050ti 和 AMDR5800） 买哪一个更好，eGPU 还是台式机？ 它与 Colab 相比如何？    由   提交 /u/state9981   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bedvos/egpu_or_desktop_for_3200_or_less_for_ml/</guid>
      <pubDate>Thu, 14 Mar 2024 05:34:08 GMT</pubDate>
    </item>
    <item>
      <title>作为 ML 工程师，我需要在我的作品集中添加哪些项目？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bedp98/what_projects_do_i_add_in_my_portfolio_for_a_job/</link>
      <description><![CDATA[大家好..我是一名即将毕业的学生，​​我想在ML领域继续我的职业生涯。我是CS出身的。我还在攻读人工智能和机器学习学位。  我想知道我应该在简历中添加哪些项目才能找到工作 就我目前的技能而言，我对 python 和机器学习有不错的了解，并且深入学习算法。  另外，如果有人可以帮助我解决我是否应该在简历中添加小型 python 项目的问题 谢谢    由   提交 /u/Designer-Mirror-8823   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bedp98/what_projects_do_i_add_in_my_portfolio_for_a_job/</guid>
      <pubDate>Thu, 14 Mar 2024 05:23:24 GMT</pubDate>
    </item>
    <item>
      <title>关于“否”的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bedas9/question_on_ddim/</link>
      <description><![CDATA[我对 DDIM 论文有疑问 (https:// arxiv.org/abs/2010.02502):  在我看来，中心思想是通过构造一个非马尔可夫推理过程 q( x_{t-1}|x_{t}, x_0)  ，仅使用部分模型生成图像即可提高采样效率（相对于DDPM）。但是，我不确定为什么不能直接在 DDPM 上完成相同的过程，我的意思是，前向过程是易于处理的，因此我们可以使用马尔可夫结构在 DDPM 中定义类似的推理轨迹？具体来说，DDPM推理模型如下 q(x_1:T|x_0) = q(x_1|x_0) * q(x_2|x_1) * q(x_3|x_2)...  为什么我们不能定义一个跳过某些 x_t 的生成轨迹？我没有看到无法做到这一点的架构级别原因，所以我猜测这是因为性能问题？   由   提交 /u/Eastern-Mongoose-618   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bedas9/question_on_ddim/</guid>
      <pubDate>Thu, 14 Mar 2024 04:59:29 GMT</pubDate>
    </item>
    <item>
      <title>不稳定、依赖种子的训练，具有约 4 种不同的模式</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bed1jz/unstable_seeddependent_training_with_4_distinct/</link>
      <description><![CDATA[您好！我正在尝试复制一篇论文，但我在不稳定的训练中遇到了麻烦。更准确地说，重新运行代码会产生截然不同的结果。不过，我认为有 4 个主要模式。 模型和训练如下所示（完整代码位于 https://www.kaggle.com/code/adelphene/dagmm): ```python 类 DAGMM(nn.Module): def init (self, inputdim=118, Latent_dim=1, n_gmm=4): super().init_()  self.encoder = nn.Sequential( nn.Linear(input_dim, 60), nn.Tanh(), nn.Linear(60, 30), nn.Tanh(), nn.Linear(30, 10), nn.Tanh(), nn.Linear(10, Latent_dim), ) self.decoder = nn.Sequential( nn.Linear(latent_dim, 10), nn.Tanh(), nn.Linear(10, 30), nn. tanh(), nn.Linear(30, 60), nn.Tanh(), nn.Linear(60, input_dim), ) self.estimator = nn.Sequential( nn.Linear(latent_dim + 2, 10), nn. tanh(), nn.Dropout(), nn.Linear(10, n_gmm), nn.Softmax(dim=1) ) defforward(self, x): l = self.encoder(x) r = self.decoder( l) re = (x - r).norm(p=2, dim=1) / x.norm(p=2, dim=1) cs = F.cosine_similarity(x, r, dim=1) z = 火炬.cat((l, re.unsqueeze(-1), cs.unsqueeze(-1)), dim=1) g = self.estimator(z) return r, z, g  &lt; h1&gt;------------------------------------------------ ------ torch.autograd.set_detect_anomaly(False) epochs = 200 lr = 1e-4 loss_fn = Loss() 批次 = len(train_dataloader) model = DAGMM(n_gmm=4).to(device) optimizationr = torch.optim.Adam(model.parameters(), lr=lr) for epoch in range(epochs):对于批量，枚举（train_dataloader）中的（x，_）：r，z，g = model.train（）（x）损失，_ = loss_fn（x，r，z，g）loss.backward（）optimizer.step () optimizer.zero_grad()  if batch % 400 == 0: r, z, g = model.eval()(val_dataset.x) val_loss, e = loss_fn(val_dataset.x , r, z, g) 阈值 = np.percentile(e.detach().cpu(), 80) y_pred = (e &gt;阈值) * 1 y_true = val_dataset.y 报告 = 分类_报告(y_true.cpu(), y_pred.cpu(), output_dict=True) a = round(report[&quot;accuracy&quot;], 2) p = round(report[&quot; ;宏平均值”][“精度”], 2) r = round(report[“宏平均值”][“召回率”], 2) print(f&quot;loss: {round(loss.item(), 3)}，准确率：{a}，精度：{p}，召回率：{r} [{batch+1}/{batches}] [{epoch+1}/{epochs}]&quot;)   ``` 需要明确的是，纪元数、优化器和学习率直接取自论文。 我得到的结果如下： 1. 损失下降到 0.5/0.6/0.7，准确率约为 0.88，精确率和召回率均约为 0.82 2. 损失停留在约 2.0，准确率约为 0.6，精确率和召回率约为 0.44 3.损失在 ~1.5 和 ~0.8 之间，准确度在 ~0.75 和 ~0.85 之间，精确度和召回率在 ~0.65 和 ~0.75 之间 4.（最佳）损失下降到 ~1.2/~0.8，准确度上升到 ~0.94，精确度和回想一下 ~0.92 我尝试过的一些事情包括 Pytorch 中可用的许多不同的初始化方法以及 BatchNorm1d。 我不太确定应该如何做接近这个。感谢任何指导！ PS：我相信我比其他模式更频繁地观察模式 2。   由   提交 /u/UhuhNotMe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bed1jz/unstable_seeddependent_training_with_4_distinct/</guid>
      <pubDate>Thu, 14 Mar 2024 04:44:56 GMT</pubDate>
    </item>
    <item>
      <title>您使用哪种 RAG 堆栈？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1becsah/what_kind_of_rag_stack_do_you_use/</link>
      <description><![CDATA[大家好，我终于找到了一些空闲时间来对开源 HF LLMS、RAG 和 vectorDB 堆栈进行一些自学。我一直在尝试构建一个简单的 QA 代理，它可以使用在一些电影脚本中找到的上下文信息（这是我的玩具数据集）。 我一直在使用 Google flan-t5-base （我有糟糕的GPU 🥲）作为分词器/模型。我正在使用 Chromadb 并加载使用 paraphrase-miniLM-L6-v2 生成的嵌入。结果看起来相当不错，尽管我对较小的上下文大小 (512) 不太满意。 只是想知道在数据集上使用 LLM-RAG 的一些经过尝试和测试的组合是什么？  （由于成本和可访问性问题，目前对使用 OpenAI 等 SaaS 不感兴趣）   由   提交 /u/appleciderv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1becsah/what_kind_of_rag_stack_do_you_use/</guid>
      <pubDate>Thu, 14 Mar 2024 04:30:52 GMT</pubDate>
    </item>
    <item>
      <title>利用 Cohere 的新 AI 模型实现 RAG 的生产规模</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1becnv4/rag_at_production_scale_with_coheres_new_ai_model/</link>
      <description><![CDATA[      Cohere 刚刚推出了 Command-R，这是一种针对长上下文任务（例如作为 RAG 并使用外部 API 和工具。  它的目标是效率和准确性之间的最佳平衡点，以实现从原型到全面生产环境的平稳过渡。 ​ https://preview.redd.it/m2s7foy988oc1.png?width=2376&amp; format=png&amp;auto=webp&amp;s=1fea9b2fa85e2c764bbb0826c2d64abc2e771579 为什么 Command-R 在 RAG 中脱颖而出？ 1. 海量上下文窗口：使用高达 128k 的令牌进行深入讨论上下文窗口，确保不留下任何细节。  速度和速度效率：Command-R 专为企业设计，承诺低延迟和高吞吐量，使从原型扩展到生产变得轻而易举。 精度与生产力的结合：与 Cohere 的 Embed 相结合和重新排序模型，Command-R 增强检索和理解，提高准确性，同时保持信息的相关性和可信度。 全球覆盖范围：讲世界语言，支持 10 种主​​要全球语言， Cohere 的模型覆盖 100 多种语言，可实现无缝、准确的对话。 基准测试的出色表现：Command-R 在 3-shot 多跳 REACT 和“Needles in”等基准测试中表现出色干草堆，”与 Cohere 模型配合使用时证明了其准确性的优越性。   想了解最新的人工智能发展和突破。加入我的时事通讯，每天与成千上万的读者一起放松 - https://unwindai.substack.com   由   提交/u/gptwhisperer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1becnv4/rag_at_production_scale_with_coheres_new_ai_model/</guid>
      <pubDate>Thu, 14 Mar 2024 04:24:16 GMT</pubDate>
    </item>
    <item>
      <title>一直很喜欢Keras！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1becb8u/always_have_loved_keras/</link>
      <description><![CDATA[   /u/cosm_zest  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1becb8u/always_have_loved_keras/</guid>
      <pubDate>Thu, 14 Mar 2024 04:05:45 GMT</pubDate>
    </item>
    <item>
      <title>关于如何学习数据分析的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bebx6w/advice_of_how_to_learn_data_analysis/</link>
      <description><![CDATA[我的一个朋友一直在思考学习数据分析的最佳方法。他已经在该领域拥有丰富的知识，并且拥有编程语言、Excel、Tableau 等方面的经验。您认为，是否有任何课程或认证对于数据分析职位来说具有足够的课程分量值得认真对待？ &lt; /div&gt;  由   提交/u/nooob_Master_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bebx6w/advice_of_how_to_learn_data_analysis/</guid>
      <pubDate>Thu, 14 Mar 2024 03:45:49 GMT</pubDate>
    </item>
    <item>
      <title>我需要对所有描述符应用降维吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bebrz2/do_i_need_to_apply_dimension_reduction_to_all_my/</link>
      <description><![CDATA[我是全新的，所以如果这真的很基本，请原谅我！ 我有一个包含一些字符串值的数据集，但是主要是数字描述符。我想对可能使用 PCA 的数据集进行降维。 尽管 PCA 仅适用于连续值，但对数据集使用 PCA 真的是不好的做法吗？不一致的应用让我感到紧张。我考虑过一种热门编码，但这也让我犹豫不决，因为据我所知，PCA 并不是为二进制值设计的。 （另外，如果你们中有人涉足过 KNIME，有谁知道如何以可以解释描述符贡献的格式提取经过训练的模型？） 谢谢！   由   提交 /u/Tenth_planet4757   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bebrz2/do_i_need_to_apply_dimension_reduction_to_all_my/</guid>
      <pubDate>Thu, 14 Mar 2024 03:38:45 GMT</pubDate>
    </item>
    <item>
      <title>数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1beb33x/math/</link>
      <description><![CDATA[我不太擅长数学。线性代数、微积分和概率。我正在学习 ML 课程。得分非常少。提高数学和理解概念的建议。直觉很难形成。如有任何建议，我们将不胜感激   由   提交 /u/Infinite_Blood8484   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1beb33x/math/</guid>
      <pubDate>Thu, 14 Mar 2024 03:04:29 GMT</pubDate>
    </item>
    <item>
      <title>良好的 Python 资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1beaboh/good_python_resources/</link>
      <description><![CDATA[所以我对 ML 非常感兴趣有一段时间了，并决定为什么不尝试一下。因此，为了入门，我想问一下有哪些学习 Python 的好课程/资源，以及一旦我很好地理解了 Python，我应该做什么。  对于一些背景信息，我在 JS 和 Java 编程方面拥有丰富的知识。   由   提交 /u/SurfinShibe7669   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1beaboh/good_python_resources/</guid>
      <pubDate>Thu, 14 Mar 2024 02:27:26 GMT</pubDate>
    </item>
    <item>
      <title>寻求对斯坦福AI Professional Program课程的意见和建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1be8jxm/looking_for_opinions_on_stanfords_ai_professional/</link>
      <description><![CDATA[    /u/Bobsthejob   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1be8jxm/looking_for_opinions_on_stanfords_ai_professional/</guid>
      <pubDate>Thu, 14 Mar 2024 01:03:58 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 在严重不平衡数据的测试集上表现非常好（不平衡比为 0.03）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bdrkkv/xgboost_does_really_well_on_test_set_on_heavily/</link>
      <description><![CDATA[数据集大小为 120 万。我有两个类，3%的数据是负样本。 XGBoost 甚至无需调整类别权重就表现得非常好！添加的数据越多，效果就越好。这是真的还是某个地方有错误？   由   提交 /u/Exciting-Ordinary133    reddit.com/r/learnmachinelearning/comments/1bdrkkv/xgboost_does_really_well_on_test_set_on_heavily/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bdrkkv/xgboost_does_really_well_on_test_set_on_heavily/</guid>
      <pubDate>Wed, 13 Mar 2024 13:33:43 GMT</pubDate>
    </item>
    <item>
      <title>我不明白 Andrew ng 的斯坦福 229</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bdmpm5/i_dont_understand_stanford_229_by_andrew_ng/</link>
      <description><![CDATA[好吧，我是一名 Python 开发人员，自从我开始工作以来已经一年了？但自从我学数学已经有两年了 现在我正在学习这门课程，我正在听第三堂课 我还很早，但我不明白任何事情，就像我不知道如何做一样学习这些算法 即使我不明白为什么我们还要学习这些算法，我是否应该练习理解它们？ 这也是因为在过去的一年里我只专注于编码和不是理论，所以我很难集中注意力 我想优先考虑编码和实际工作，而不是立即理解它 是否有任何课程，他们编码和解释而不是完整的理论 &gt; ​ 或者我应该坚持这门课程并专注于数学。在这门课程之后理解练习并进行实践 &lt;!-- SC_ON - -&gt;  由   提交/u/Bominator8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bdmpm5/i_dont_understand_stanford_229_by_andrew_ng/</guid>
      <pubDate>Wed, 13 Mar 2024 08:52:52 GMT</pubDate>
    </item>
    </channel>
</rss>