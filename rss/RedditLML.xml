<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Wed, 24 Jan 2024 12:26:48 GMT</lastBuildDate>
    <item>
      <title>是否可以使用图像识别从轮辋图像估计车轮规格？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19efgnv/is_it_possible_to_use_image_recognition_to/</link>
      <description><![CDATA[如标题所示。我正在研究构建一个应用程序的可能性，用户可以在其中拍摄汽车轮辋的照片，模型会估计许多变量，包括：PCD、螺母/螺栓长度等。这似乎是一个技术上非常具有挑战性的项目，但我会想知道这是否真的可能。 提前致谢！   由   提交/u/Better_Pollution_114   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19efgnv/is_it_possible_to_use_image_recognition_to/</guid>
      <pubDate>Wed, 24 Jan 2024 11:58:57 GMT</pubDate>
    </item>
    <item>
      <title>Chomsky vs Shannon 的 NLP 和 AI 方法 - Chris Manning 斯坦福大学 OpenNLP 创建者</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ef7ql/chomsky_vs_shannon_approaches_to_nlp_and_ai_chris/</link>
      <description><![CDATA[       由   提交 /u/fancypigollo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ef7ql/chomsky_vs_shannon_approaches_to_nlp_and_ai_chris/</guid>
      <pubDate>Wed, 24 Jan 2024 11:43:54 GMT</pubDate>
    </item>
    <item>
      <title>从 ML 论文中学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eel4f/learning_from_ml_papers/</link>
      <description><![CDATA[我一直在努力从机器学习论文中学习并在实践中实施这些概念 有任何具体资源吗？ &gt;   由   提交 /u/sigma_ks   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eel4f/learning_from_ml_papers/</guid>
      <pubDate>Wed, 24 Jan 2024 11:03:38 GMT</pubDate>
    </item>
    <item>
      <title>汉明距离问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ee7qw/hamming_distance_problem/</link>
      <description><![CDATA[      ​ A. 4、B. 否，最多 7。 我的看法   由   提交/u/Victor_Paul_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ee7qw/hamming_distance_problem/</guid>
      <pubDate>Wed, 24 Jan 2024 10:39:28 GMT</pubDate>
    </item>
    <item>
      <title>关于 LSTM 的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ee4h2/questions_about_lstms/</link>
      <description><![CDATA[所以我观看了 Andrew Ng 的视频并阅读了一些有关 RNN 的 pdf 文件，这样我就掌握了基础知识，但在使用它们时我有一些关于它们的问题在 PyTorch 上。我正在尝试实现自己的自定义 LSTM，所以我只是好奇它是如何在 PyTorch 上实现的。 首先，LSTM 如何批量训练。观察 LSTM 的内部，我发现有一个专门用于输入权重的矩阵（我假设它结合了遗忘门、输入门、控制门和输出门的所有权重）。然而，同样有趣的是，隐藏状态也有一个类似的权重矩阵，但大小与批量大小相关。根据我的推断，这意味着隐藏状态会批量相乘，但隐藏状态并不依赖于它们之前的输入，那么这将如何工作。总的来说，考虑到矩阵大小，我很困惑谁会批量训练 LSTM。  其次，我的输入是二维的，因为它包含序列长度的特征数量，这意味着它需要 n 天的数据作为输入（我的 LSTM 用于时间预测）。我感到困惑的是 LSTM 如何获取这些数据。它会把它压平吗？除了权重矩阵之外，它是否会乘以第二个矩阵，使其变平？我只是不知道。 第三，如何从 PyTorch 中的数据加载器类访问成员？基本上，我尝试制作的 LSTM 试图回忆以前的内存值和输入，但是当我尝试仅使用传统数组表示法访问数据加载器类中的成员时，我不断收到错误。那么还有哪些其他方法呢？    由   提交/u/Successful-Fee4220   reddit.com/r/learnmachinelearning/comments/19ee4h2/questions_about_lstms/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ee4h2/questions_about_lstms/</guid>
      <pubDate>Wed, 24 Jan 2024 10:33:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] BELT（较长文本的 BERT）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ee1fb/project_belt_bert_for_longer_texts/</link>
      <description><![CDATA[我们创建了 BELT（BERT For Longer Texts）——一个 Python 包，允许对长度超过 512 个 token 的文本使用类似 BERT 的模型。该方法是 Jacob Devlin 提出的想法的实现，Jacob Devlin 是 评论。您可以在 Medium 上我刚刚发表的两篇文章中阅读有关它的更多详细信息： 第一部分是应用 BERT 分类器的概述： 第 1 部分 第二部分深入介绍我们训练 BELT 模型的方法。 第 2 部分 该存储库以开源方式提供： Repo 我知道你在想什么：“等等，bucko，这不是什么新鲜事。每个人都知道有像 BigBird 或 Longformer 这样的模型可以处理更长的文本”。对此我的回答是：“我知道，伙计，但是 BigBird 和 Longformers 不是修改过的 BERT。它们是具有不同架构的模型。因此，它们需要从头开始预训练或下载。 BELT修改模型微调。这带来了 BELT 方法的主要优点 - 它使用任何预先训练的 BERT 或 RoBERTa 模型。快速查看 HuggingFace Hub 可以确认，BERT 的资源比 Longformer 多大约 100 倍。找到适合特定任务或语言的可能会更容易。”享受吧！   由   提交/u/MBrzozowskiML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ee1fb/project_belt_bert_for_longer_texts/</guid>
      <pubDate>Wed, 24 Jan 2024 10:27:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用准确率而不是二元交叉熵来进行超参数调整？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ebwo7/why_do_we_use_accuracy_instead_of_binary_cross/</link>
      <description><![CDATA[在许多产生结果概率的模型（决策树、随机森林、概率神经网络等）中，我认为准确性是超级的选择指标参数调整（即准确度与历元、准确度与树深度、准确度与minimum_leaf_size等）。二元交叉熵对于这些评估来说也是一个足够的指标吗？我的直觉告诉我确实如此，只是我想多了。大家可以发表一下自己的意见吗？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ebwo7/why_do_we_use_accuracy_instead_of_binary_cross/</guid>
      <pubDate>Wed, 24 Jan 2024 07:51:11 GMT</pubDate>
    </item>
    <item>
      <title>[R][紧急] 这个项目需要帮助！即使是一种方法也能有所帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eavds/rurgent_need_help_with_this_project_even_an/</link>
      <description><![CDATA[我正在开展一个项目，该项目要求我开发一种症状到医生的特殊性映射，稍后将其合并到搜索栏中。对于患者搜索的每种症状，模型应该能够提供与该症状相关的 3 个最相关的医生专业知识，并且结果应该按照与该症状的相关性排序。该数据集包含针对医生专业知识的症状列表。请对此紧急指导！我可以使用什么模型以及如何实现相关顺序？如果您见过任何类似的项目，请也提及！太紧急了   由   提交/u/Effective_Form165   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eavds/rurgent_need_help_with_this_project_even_an/</guid>
      <pubDate>Wed, 24 Jan 2024 06:41:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 C++/CUDA 构建的相同模型收敛速度不如使用 Python/NumPy 构建的模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eagxe/identical_model_built_using_ccuda_doesnt_converge/</link>
      <description><![CDATA[我想学习神经网络背后的数学，所以我决定使用 numpy 从头开始​​构建一个 Python 模型来训练 MNIST 数据集。速度非常快，在调整超参数后，在 30 个 epoch 内测试数据集的准确率达到了 98%。作为一个简单的全连接网络，我没想到它会做得更好。所以我决定在 C++ 和 CUDA 中尝试同样的方法。该模型确实可以学习，但收敛速度不那么快。即使经过 1000 个 epoch，其准确性仍然非常可怕。模型架构相同，浮点精度、权重和偏差初始化、小批量大小以及所有超参数都相同。 GPU 在每次内核调用后也会同步。然而该模型的收敛速度似乎并没有那么快。我不知道该怎么做。有人知道可能是什么原因造成的吗？感谢您阅读所有内容。希望您有美好的一天。   由   提交 /u/Hey_DeadGuyHere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eagxe/identical_model_built_using_ccuda_doesnt_converge/</guid>
      <pubDate>Wed, 24 Jan 2024 06:16:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 为网站创建 AI 聊天机器人 - EmbedChain Dash</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/</link>
      <description><![CDATA[      大家好， 几天前，我创建了这个免费视频有关如何使用 Python 构建 AI 聊天机器人的教程。我使用 EmbedChain（构建在 LangChain 之上）和 Dash 库来展示如何训练机器人并与机器人交互。  https://youtu.be/tmOmTBEdNrE  https://preview.redd.it/c6r7guzfxbec1.png?width=1280&amp;format=png&amp; ;auto=webp&amp;s=e8fe1c145cb0d687a16a1ff87b8bad1c5ecfef4e   由   提交 /u/Adam-Schroeder   /u/Adam-Schroeder  reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19eacx0/create_ai_chatbots_for_websites_in_python/</guid>
      <pubDate>Wed, 24 Jan 2024 06:09:35 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 中处理名义多类分类目标变量的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19ea3fe/what_is_the_best_way_to_deal_with_a_nomianal/</link>
      <description><![CDATA[我一直在互联网上寻找这个问题的答案，但似乎无法找到共识。 XGBoost具有“实验支持”对于分类变量，但如果某些实验被认为是最佳实践，我会感到惊讶，并且它必须将类别转换为“幕后”的某种数字表示形式。无论如何，以某种能力。 另一种选择是对目标进行标签编码，但这将创建一个隐含的序数变量，该变量应该表示名义变量。我不确定这是否会像预测变量那样对分类器中的目标变量产生影响。 理想情况下，我想对目标变量进行一次性编码，因为这似乎是名义多类分类变量的最正确的数字表示，这与其他类型的框架（例如 Keras）的运行方式一致。然而，XGBoost 似乎只能处理单个字段/一维数组作为目标。我遇到了一些可能允许其工作的包装函数，但我不确定如何在内部 XGBoost 模型上进行自动超参数调整。 编辑：标题应该说“标称”不是“标称”   由   提交/u/theromanempire1923   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19ea3fe/what_is_the_best_way_to_deal_with_a_nomianal/</guid>
      <pubDate>Wed, 24 Jan 2024 05:53:55 GMT</pubDate>
    </item>
    <item>
      <title>奇异性与非奇异性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e9n3d/singularity_vs_nonsingularity/</link>
      <description><![CDATA[嗨，我正在 coursera 上学习线性代数，第一周他们强调了线性方程组中奇点与非奇点的概念。试图了解这与神经网络有何关系。是因为作为一般原则，您希望始终以神经网络的非奇点为目标吗？具有奇点的系统意味着它们是冗余的、矛盾的，或者可以有无限多个解决方案。这与神经网络有何关系？神经网络可以开始显示出奇点的迹象吗？那么我们的想法是消除这个吗？这怎么会发生呢？你会如何处理它？另外，神经网络也可以是非线性的吗？这意味着什么？我刚刚在加拿大攻读人工智能硕士课程，我正在尝试重新学习滑铁卢大学第一年的所有数学（艺术/经济专业），但我不记得很多数学；已经10多年了。之后我还将重新访问微积分，并且已经重新访问了统计与数据。现在概率是两倍。但我认为理解线性代数在神经网络/深度学习中极其重要。有人可以用简单的语言解释一下吗？这只是线性代数的第一周，所以我将在五月开课之前继续在线学习，但只是想要一些额外的见解。抱歉，我对这些概念非常非常陌生，我也在业余学习 Python。  谢谢   由   提交 /u/Can_swing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e9n3d/singularity_vs_nonsingularity/</guid>
      <pubDate>Wed, 24 Jan 2024 05:27:00 GMT</pubDate>
    </item>
    <item>
      <title>感知器可以循环处理线性可分离数据吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e925t/can_perceptron_cycle_on_linearly_separable_data/</link>
      <description><![CDATA[假设我们有由两个点 (x1, y1) = ((-1, -1) +1) 和 ( x2, y2) = ((1, 1) +1)。这些是线性可分的，正确吗？显然，任何不在这些点之间的线都会正确地将它们分类为相同的标签。 但是，如果我要在这些点上运行感知器算法，初始化 w_1 = (0,0) 并假设我们使用恒等特征映射，当 i 为奇数时，它将在 w_i = (0,0) 的权重向量之间循环，当 i 为偶数时，它会在 w_i = (-1,-1) 的权重向量之间循环，永不终止。这是为什么？除了线性可分性之外，还有其他属性也会影响感知器收敛吗？ 需要明确的是，这里的算法是，如果我们错误分类 (x_i, y_i)，如果 yi(w_t \dot x_i) &lt;= 0，则发生错误分类。   由   提交 /u/rhohodendron   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e925t/can_perceptron_cycle_on_linearly_separable_data/</guid>
      <pubDate>Wed, 24 Jan 2024 04:53:42 GMT</pubDate>
    </item>
    <item>
      <title>这里发生了什么？这只是大规模的过度拟合吗？或者是其他东西？提前致谢。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19e57wk/whats_going_on_here_is_this_just_massive/</link>
      <description><![CDATA[   /u/HoleNother  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19e57wk/whats_going_on_here_is_this_just_massive/</guid>
      <pubDate>Wed, 24 Jan 2024 01:39:25 GMT</pubDate>
    </item>
    <item>
      <title>进入机器学习领域。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/</link>
      <description><![CDATA[大家好。 我是一名水工程师，今年想学习新东西，并决定采取一些步骤进入机器学习，获得一些见解。我的目标很简单，使用给定的数据集，应用机器学习模型，以便我可以用它来预测水质或优化问题，例如给定水质输入的最佳化学剂量。这与工作无关，只是我可以访问这些数据，这更像是一个个人项目，一个由于我的背景我可以理解的项目。 我有一些相当基本的 Python 知识（在学习期间介绍了 python 模块）以及有关数学建模、统计等的知识。 所以我的问题是：考虑到我的初始条件，这个目标是否现实？如果是，你会如何？去学习和构建这样的项目吗？ 感谢您的建议。   由   提交/u/Koa-3skie   reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19dw0ho/getting_into_ml/</guid>
      <pubDate>Tue, 23 Jan 2024 19:02:44 GMT</pubDate>
    </item>
    </channel>
</rss>