<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 16 May 2024 15:14:21 GMT</lastBuildDate>
    <item>
      <title>功能之间的距离</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctf6b3/distance_between_functions/</link>
      <description><![CDATA[       我正在研究一些不公开的笔记。 对于域为 ℝ^(M)（特征空间）的两个函数，我们定义距离 &lt; a href=&quot;https://preview.redd.it/zbzpevt61t0d1.png?width=415&amp;format=png&amp;auto=webp&amp;s=445489334a784f73feb0f0cf3a6ce94449dca86c&quot;&gt;https://preview.redd.it/zbzpevt61t0d1.png?width =415&amp;format=png&amp;auto=webp&amp;s=445489334a784f73feb0f0cf3a6ce94449dca86c 其中B是单位球，V_(B)是单位球的体积。 当我们从离散情况转向连续情况时，我看到这是平均欧几里德距离。但我不太明白为什么我们要在单位球上进行积分。就不进一步解释了。我不是一名数学学生，也没有使用过函数空间。要么通过在有界集合上积分来定义范数，要么假设首先对特征进行归一化？如果后者是真的，我们不能只用不定积分来定义距离吗？   由   提交 /u/DiedeutscheEiche   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctf6b3/distance_between_functions/</guid>
      <pubDate>Thu, 16 May 2024 15:09:01 GMT</pubDate>
    </item>
    <item>
      <title>您可以微调以生成简短的数字“分数”输出吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctevr2/can_you_fine_tune_to_generate_a_short_numerical/</link>
      <description><![CDATA[我正在训练集上对 Llama3 8B（指令）进行微调，该训练集包含可能成为市场报告一部分的可能句子的编号列表。我要求法学硕士选择它认为与读者最相关的三个故事。输出只是选择的三个故事（训练集包含此类示例）。 我已经能够使用 LORA 获得不错的（但不够）结果，但是这样做没有 LORA 的全面训练实际上已经倒退，并且似乎部分地重新创建了上下文窗口。我想知道问题的一部分是否可能是试图从大量的书面上下文中获得如此小的数字输出。  我必须想象人们试图获得“情绪分数”或类似输出的东西，但我还没有遇到任何人谈论这是否会给微调带来问题。有人对这是否可能有任何假设吗？   由   提交/u/AggressiveMirror579   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctevr2/can_you_fine_tune_to_generate_a_short_numerical/</guid>
      <pubDate>Thu, 16 May 2024 14:56:32 GMT</pubDate>
    </item>
    <item>
      <title>这个模型有什么问题吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctecuf/whats_wrong_with_this_model/</link>
      <description><![CDATA[尝试找出模型的问题;) PS：这不是为了调试，只是一个有趣的练习&lt; /p&gt; .utils.register_keras_serialized(package=&#39;Custom&#39;, name=&#39;ConvMNISTClassifier&#39;) class ConvMNISTClassifier(keras.Model): def __init__(self, **kwargs): super().__init__( **kwargs) self.image_norm = ImageNorm(name=&#39;image_norm&#39;) self.conv1 = keras.layers.Conv2D(32, 3, 激活=&#39;relu&#39;, name=&#39;conv1&#39;) self.conv2 = keras.layers. Conv2D(64, 3, 激活=&#39;relu&#39;, name=&#39;conv2&#39;) self.batch_norm = keras.layers.BatchNormalization(name=&#39;batch_norm&#39;) self.pool = keras.layers.MaxPooling2D(name=&#39;max_pool&#39;) self.flatten = keras.layers.Flatten(name=&#39;flatten&#39;) self.dense1 = keras.layers.Dense(128, name=&#39;dense1&#39;) self.dropout = keras.layers.Dropout(rate=0.2, name= &#39;dropout&#39;) self.relu = keras.layers.ReLU(name=&#39;relu&#39;) self.dense2 = Linear(10, name=&#39;dense2&#39;) self.softmax = keras.layers.Softmax(name=&#39;softmax&#39;) self.argmax = ArgMax(name=&#39;argmax&#39;) def call(self,inputs,training=False): x = self.image_norm(inputs) x = self.conv1(x) x = self.conv2(x) x = self.batch_norm(x, 训练=训练) x = self.pool(x) x = self.flatten(x) x = self.dense1(x) x = self.dropout(x, 训练=训练) x = self. relu(x) logits = self.dense2(x) return logits def Predict(self, input): logits = self(inputs) probs = self.softmax(logits) return self.argmax(probs) defcompute_loss(self, x, y，y_pred =无，sample_weight =无）：如果y_pred为无：y_pred = self（x，training = True）print（self.dense2.losses）loss = super（ConvMNISTClassifier，self）.compute_loss（x，y，y_pred ) 返回损失类 Linear(keras.Layer): def __init__(self,units=32, **kwargs): super(Linear, self).__init__(**kwargs) self.units = 单位 self.kernel = None self.偏差=无 def build(self, input_shape): self.kernel = self.add_weight(name=&#39;kernel&#39;, shape=(input_shape[-1], self.units),initializer=&#39;uniform&#39;, trainable=True) self .bias = self.add_weight（name=&#39;bias&#39;，shape=（self.units，），initializer=&#39;uniform&#39;，trainable=True） def call（self，inputs）：self.add_loss（tf.reduce_sum（inputs） ) return tf.matmul(inputs, self.kernel) + self.bias  这是输出： Epoch 1/2 [&lt;tf .张量 &#39;conv\_mnist\_classifier\_39\_1/dense2\_1/Sum:0&#39; shape=() dtype=float32&gt;] [] 1875/1875 ──────────────────────────────── 8s 3ms/步 -损失：10.4156 - 稀疏分类准确度：0.1045 Epoch 2/2 1875/1875 ────────────────────────────── 5s 3ms/步 - 损失：2.3053 -稀疏分类精度：0.1124 问题在于自定义线性层及其对 add_loss 方法的使用。它添加了一个损失值，该损失值是输入的总和，从而爆炸了总体损失值。  这就是我个人不喜欢 add_loss 方法的原因，因为它使 debuggin 成为一场绝对的噩梦。大多数人只会简单地查看compute_loss方法，并发现它没有任何问题，而不知道某些自定义层正在注入此类垃圾损失值。    由   提交/u/dunno_about_this   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctecuf/whats_wrong_with_this_model/</guid>
      <pubDate>Thu, 16 May 2024 14:33:10 GMT</pubDate>
    </item>
    <item>
      <title>我可以将 FastChat 存储库与 llava-v1.6-vicuna-13b 等视觉模型一起使用吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cte620/can_i_use_fastchat_the_repo_with_a_vision_model/</link>
      <description><![CDATA[我之前在普通模型中使用过 FastChat，但是它可以与视觉模型一起使用吗？如果可以的话是否需要大量配置，并且有已经做好了，网上有资源吗？   由   提交/u/Party_Industry3080   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cte620/can_i_use_fastchat_the_repo_with_a_vision_model/</guid>
      <pubDate>Thu, 16 May 2024 14:24:43 GMT</pubDate>
    </item>
    <item>
      <title>拥有 10 年经验的交易员正在由 Andrew Ng 进行 ML 专业化，接下来做什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctdpu8/trader_with_10y_exp_doing_ml_specialization_by/</link>
      <description><![CDATA[嗨， 我是一名拥有 10 年经验的金融交易员。该领域的竞争每年都变得更加激烈，因此我计划通过深入研究机器学习来提高自己的技能，以协助研究和识别新的交易策略。 我有一些 Python 基础知识，足以完成Andrew Ng 的 ML 课程，但我没有在其他地方广泛练习过 Python。过去，我曾与研究人员合作，他们使用刻度数据（数百万行，文件大小为数百 GB）来探索我感兴趣的想法，但我不再有权访问它们，现在正在独立工作。&lt; /p&gt; 我希望能够使用刻度数据进行自己的研究，但我还不熟悉数据处理和清理。我应该在完成 ML 专业化后开始深入研究项目，还是应该首先专注于学习更多内容？ 我听说 快.ai 非常实用——也许这就是我下一步应该去的地方？然后我应该从 Kaggle 开始，还是直接进入我的项目？ 提前非常感谢！   由   提交 /u/ttpr0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctdpu8/trader_with_10y_exp_doing_ml_specialization_by/</guid>
      <pubDate>Thu, 16 May 2024 14:04:56 GMT</pubDate>
    </item>
    <item>
      <title>新手机器学习工程师需要建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctd9ix/novice_machine_learning_engineer_needs_advice/</link>
      <description><![CDATA[嗨，我在编码方面是个新手，但我想成为一名机器学习工程师，我目前已经注册了一年的数据科学证书与我的商业学位相结合，我对整个事情有耐心，因为我知道我不是最理想的候选人，但我想要一些关于我可以遵循的路径的提示，以确保我成为机器学习者尽管我有商业教育背景，但我还是一名工程师，而且是一名出色的工程师   由   提交 /u/diamantedaddy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctd9ix/novice_machine_learning_engineer_needs_advice/</guid>
      <pubDate>Thu, 16 May 2024 13:45:13 GMT</pubDate>
    </item>
    <item>
      <title>Coursera 上 12 门最佳深度学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctb6u8/12_best_deep_learning_courses_on_coursera/</link>
      <description><![CDATA[       由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctb6u8/12_best_deep_learning_courses_on_coursera/</guid>
      <pubDate>Thu, 16 May 2024 11:59:11 GMT</pubDate>
    </item>
    <item>
      <title>生成阿拉伯语文本转语音的过程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctazy6/process_for_generating_arabic_text_to_speech/</link>
      <description><![CDATA[我是 AI 新手，正在尝试学习 tts。我有乌龟，但我只能说英语。有谁知道我需要做什么才能发出像样的阿拉伯语演讲？   由   提交/u/slydawggy69420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctazy6/process_for_generating_arabic_text_to_speech/</guid>
      <pubDate>Thu, 16 May 2024 11:47:49 GMT</pubDate>
    </item>
    <item>
      <title>从 deeplearning.ai 学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctahkc/learning_ml_from_deeplearningai/</link>
      <description><![CDATA[所以，我正在从 deeplearning.ai 学习 ML 专业化。所以我的问题是，对于那些已经完成了课程的人来说，这门课程真的能提供实践机会吗？如果你知道任何可以参考以提高我的实践学习的材料，我将不胜感激。提前致谢。   由   提交 /u/Slayerma   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctahkc/learning_ml_from_deeplearningai/</guid>
      <pubDate>Thu, 16 May 2024 11:17:15 GMT</pubDate>
    </item>
    <item>
      <title>我应该从哪里开始学习 ML？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ctafys/where_should_i_start_learning_ml/</link>
      <description><![CDATA[我是一名计算机科学专业的学生，​​已经涵盖了数学、概率、Python 和 pytorch 等基础知识。但是，我渴望将我的技能提升到一个新的水平并深入研究该领域。我正在向社区寻求指导，了解下一步的重点以及如何有效地继续我的学习之旅。我可以获得任何建议、提示或推荐吗？   由   提交 /u/Excellent_Ad9603   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ctafys/where_should_i_start_learning_ml/</guid>
      <pubDate>Thu, 16 May 2024 11:14:27 GMT</pubDate>
    </item>
    <item>
      <title>将 google colab 链接到 index.js</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct8yt6/linking_google_colab_to_indexjs/</link>
      <description><![CDATA[您好，我手头有一个项目，我需要从 MERN 堆栈中创建的前端获取一些用户输入，然后将其传输到LLM。由于我无法在本地运行 llm，因此建议我使用 google colab。我是一个完全的初学者，我不知道如何从前端向 google colab 发送和接收数据。以前，在我可以在本地运行的其他机器学习项目中，我会使用系统参数或管道。如有任何帮助，我们将不胜感激，谢谢。   由   提交/u/_sasiii11_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct8yt6/linking_google_colab_to_indexjs/</guid>
      <pubDate>Thu, 16 May 2024 09:31:49 GMT</pubDate>
    </item>
    <item>
      <title>StyleGan2 在一批中生成几乎相同的图像？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct60qx/stylegan2_generates_nearly_identical_images/</link>
      <description><![CDATA[      我正在使用此 site 但我认为原始代码来自此 repo 到目前为止我尝试过的： - 更改批量大小。 - 将学习率更改为 1e5（之前为 1e3） - 更改损失（用正常 wgan 替换梯度惩罚） - 更改判别器。使用来自 Projected Gan 代码库的判别器。到目前为止，问题依然存在。有什么建议么？谢谢 sm！   由   提交/u/basil_0408  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct60qx/stylegan2_generates_nearly_identical_images/</guid>
      <pubDate>Thu, 16 May 2024 05:53:36 GMT</pubDate>
    </item>
    <item>
      <title>深入探讨：我如何从高级软件工程师转向机器学习/深度学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ct4f1o/diving_in_how_do_i_go_from_senior_software/</link>
      <description><![CDATA[如果这个问题被问得令人作呕，请原谅我。  我正在研究 Jef Prosise 的应用机器学习和人工智能工程师课程，到目前为止它很有趣。我有数学背景：辅修数学并获得理学士学位。计算机科学学士学位和软件工程硕士学位。 （虽然我的数学能力有点生疏，但我可以很好地理解它。） 是什么让这种情况更加独特：我的退伍军人法案还剩下大约一年的免费教育。问题是我现在住在海外，所以必须远程完成，所以它必须在线。但是鉴于我不需要继续接受正规教育，您会选择什么途径？ 我在卫生部门工作，所以一旦我开始涉足，我知道我的老板会喜欢我们尝试做一些研究并在可能的情况下发表。出版会对我有所帮助，因为最终我想攻读博士学位。 我的问题： 知道我在哪里，我要走什么路才能从这里到达那里？什么在线课程最好？我应该自学并继续学习 O&#39;Reilly 的书籍（这些年来一直帮助我提高水平？），还是更正式的课程（例如麻省理工学院或斯坦福大学或其他地方的专业证书）会更好？ 我想去哪里？ 一些研究想法涉及使用医学分类器模型（BERT）进行文本分类，但我想通过其他一些研究从稍微不同的角度来看待它我们已经完成了。我们有一些产品也可能受益于我想开始探索的不同类型的更简单的机器学习方法（不完全是法学硕士）。这是项目一开始的目标，但工具并不容易获得，几年前我也没有经验。 非常感谢您的帮助。   由   提交/u/Global-Comedian-8331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ct4f1o/diving_in_how_do_i_go_from_senior_software/</guid>
      <pubDate>Thu, 16 May 2024 04:11:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 HuggingFace 的变形金刚感觉就像作弊。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</link>
      <description><![CDATA[我一直在使用 Huggingface 任务演示作为许多令我兴奋的 NLP 项目的起点，甚至是我所求助的一些视觉任务Transformer 文档，有时是 pytorch 文档，用于根据我的用例自定义代码，并在遇到错误时进行调试，有时查看模型论文以了解超参数应该是什么样的以及要进行实验的范围是什么。  现在，我知道我感觉自己一直是一个糟糕的程序员，从来没有真正喜欢过其他语言和框架，但这对我来说非常有趣和令人兴奋。  &gt; 我能够使用像“TrainingArgs”这样的简单代码来微调很酷的模型。和“Trainer.train()”并让我的朋友可以使用像“pipeline”这样简单易用的API这让我感到难以置信，并且引发了我的冒名顶替综合症。 所以我想我的问题是，仅使用变形金刚以及我的做法能走多远？是工业/生产标准还是研究标准？   由   提交/u/mhmdsd77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csx8zh/using_huggingfaces_transformers_feels_like/</guid>
      <pubDate>Wed, 15 May 2024 22:08:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能在医学成像（例如组织病理学）领域如此饱和？为什么人工智能在分子生物学（蛋白质折叠除外）方面的探索如此之少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</link>
      <description><![CDATA[我从事涉及生物医学研究人工智能的项目，令我震惊的是为什么有这么多涉及医学成像人工智能的论文/项目，尤其是计算病理学（或放射学）？是因为这个领域的需求（即医院对患者进行活检的组织病理学）吗？ 为什么我感到困惑的是，组织病理学，例如全切片图像分析，是一个资源密集型领域问题 - 典型的 WSI（整个幻灯片图像）需要大约 10GB 才能加载，因此训练模型可能需要几天甚至几周的时间。更不用说您必须将图像转换为更小的补丁，然后应用多实例学习等方法来聚合每个补丁的图像嵌入以获得最终预测。然后你必须看看哪些补丁对疾病很重要（通过注意力图之类的东西），然后你需要领域专家/专业知识来了解模型是否专注于图像的正确部分以进行预测。  然而，自 2020 年以来，该领域发表了如此多的论文，可能有数千篇，跨越 NeurIPS/ICLR/ICML、CVPR/ECCV/ICCV、MICCAI（专门针对我想知道这是否是因为很多来自计算机视觉领域的人想要解决一个更困难的问题（涉及非自然图像？） 然后我我还很困惑为什么分子生物学，尤其是 DNA/RNA/表观基因组学（不包括蛋白质结构/折叠）的 ML 工作少得多、少得多？对于分子生物学来说，几乎所有的焦点似乎都集中在新 AlphaFold 3 的蛋白质折叠/结构上，但除此之外，RNA/DNA/表观基因组学在很大程度上被忽略了？也就是说，在 2023 年底到 2024 年初，只有最近一波关于单细胞 RNA 测序基础模型（如 scGPT/Geneformer 等）的论文？是因为在分子生物学模式中进行良好的分析需要更多的领域知识，而拥有这些知识的人却很少吗？尽管分子生物学数据集（尤其是 RNA 测序）的计算强度通常比医学成像（如组织病理学）低得多？   由   提交/u/EcstaticAd162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</guid>
      <pubDate>Wed, 15 May 2024 21:09:03 GMT</pubDate>
    </item>
    </channel>
</rss>