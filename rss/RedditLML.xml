<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 16 Dec 2024 01:24:48 GMT</lastBuildDate>
    <item>
      <title>我如何在这个就业市场找到工作？我如何脱颖而出？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf6svo/how_do_i_get_a_job_in_this_job_market_how_do_i/</link>
      <description><![CDATA[关于我 - 我是一名国际研究生，将于 2025 年春季毕业。我从 2024 年 9 月开始申请工作和实习，到目前为止，我甚至还没有获得一次面试机会。 我并不是这个领域的绝对初学者。在进入研究生院之前，我在一家初创公司担任 AI 软件工程师超过一年。我有 2 篇出版物，一篇在 WACV 研讨会上，另一篇在 ACM TALLIP 上。我在计算机视觉和自然语言处理方面拥有丰富的经验，专注于多模态学习和现实世界的 AI 应用。我的学术项目包括构建视觉语言模型、医学成像的分割算法以及开发具有人类注意力注释的数据集。我还参与过一些具有挑战性的行业项目，比如自动化 AI 管道和部署实时分类器。  我怎样才能在这个竞争激烈的就业市场中提高自己的机会？ 是否有针对国际学生申请美国科技职位的具体策略？ 我怎样才能脱颖而出，尤其是在与来自顶尖学校且经验更丰富的候选人竞争时？     提交人    /u/__proximity__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf6svo/how_do_i_get_a_job_in_this_job_market_how_do_i/</guid>
      <pubDate>Mon, 16 Dec 2024 00:35:33 GMT</pubDate>
    </item>
    <item>
      <title>阿尔茨海默病数据集分析</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf5n44/alzheimer_disease_dataset_analysis/</link>
      <description><![CDATA[  由    /u/Ok_Parsley_8002  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf5n44/alzheimer_disease_dataset_analysis/</guid>
      <pubDate>Sun, 15 Dec 2024 23:38:44 GMT</pubDate>
    </item>
    <item>
      <title>在小环境中训练模型，为更大的环境做好准备？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf5j9e/train_model_in_small_context_to_prepare_it_for_a/</link>
      <description><![CDATA[抱歉，如果这没有意义，我只是个初学者 比如说，假设我想训练我的模型，一个足球运动员，让他进球。但是，我也希望他将球传给他的队友。我可以制作一个较小的场景来改善他的传球吗？我只需进行不必要的观察 0，并在更大的环境（实际比赛）中使用这个模型，这样他就可以利用他目前在传球训练中学到的东西来获得进球奖励？     提交人    /u/usuarioabencoado   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf5j9e/train_model_in_small_context_to_prepare_it_for_a/</guid>
      <pubDate>Sun, 15 Dec 2024 23:33:19 GMT</pubDate>
    </item>
    <item>
      <title>希望学习如何训练模型，根据我自己的镜头创建 AI 克隆头像</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf3j93/looking_to_learn_how_to_train_a_model_to_create/</link>
      <description><![CDATA[大家好， 最近，我对 Heygen 和 Synthesia 的可能性感到震惊。但那些相当昂贵。 我想知道我是否可以通过视频模型训练系统创建类似的东西，例如我使用 Flux（使用 fal.ai）所做的那样，以获得令人难以置信的照片效果。 感谢您的帮助！    提交人    /u/oscaro99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf3j93/looking_to_learn_how_to_train_a_model_to_create/</guid>
      <pubDate>Sun, 15 Dec 2024 21:58:43 GMT</pubDate>
    </item>
    <item>
      <title>精彩的 LLM 书籍：大型语言模型书籍精选</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf2w5p/awesome_llm_books_curated_list_of_books_on_large/</link>
      <description><![CDATA[        由    /u/jasonb  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf2w5p/awesome_llm_books_curated_list_of_books_on_large/</guid>
      <pubDate>Sun, 15 Dec 2024 21:29:39 GMT</pubDate>
    </item>
    <item>
      <title>我该如何从众多超参数中选择出合适的超参数呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf27om/how_do_i_choose_hyperparameter_from_so_many/</link>
      <description><![CDATA[我最近研究了超参数优化。鉴于许多模型中的超参数数量庞大（例如，CatBoost 拥有超过 90 个，尽管开发人员可能只选择 7 个关键参数），确定哪些参数最相关是一项重大挑战。我们如何在不同模型中可用的众多选项中有效地识别关键超参数？    提交人    /u/im_pulsive   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf27om/how_do_i_choose_hyperparameter_from_so_many/</guid>
      <pubDate>Sun, 15 Dec 2024 20:59:03 GMT</pubDate>
    </item>
    <item>
      <title>高斯 copula 在模拟表格数据时有哪些缺点</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hf1z7v/what_are_downsides_of_gaussian_copulas_for/</link>
      <description><![CDATA[我有混合数据，包括数值和分类数据。关于数据生成有什么建议吗？    提交人    /u/Friendly-Rub-2047   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hf1z7v/what_are_downsides_of_gaussian_copulas_for/</guid>
      <pubDate>Sun, 15 Dec 2024 20:48:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型在蒸馏过程中没有学到任何东西？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1heyvj3/why_does_my_model_not_learn_anything_during/</link>
      <description><![CDATA[我一直在尝试在 pytorch 中对 Imagenet1k 上的网络进行蒸馏，但损失在各个 epoch 之间几乎没有变化，并且在下降时上升和下降时一样多，徘徊在同一值附近。 def train_defensive_distillation(teacher, student, train_loader, epochs, learning_rate, T, device, teacher_func): optimizer = optim.Adam(student.parameters(), lr=learning_rate) teacher.eval() # 教师设置为评估模式 student.train() # 学生设置为训练模式 teacher_func = teacherlogitfunc(teacher_func) for epoch in range(epochs): running_loss = 0.0 for input, labels in train_loader: input, labels = input.to(device), labels.to(device) optimizer.zero_grad() # 使用教师模型进行前向传递 - 在这里不保存梯度，因为我们不会更改使用 torch.no_grad() 计算教师权重： teacher_logits = teacher(inputs) # 使用学生模型进行前向传递 student_logits = student(inputs) # 先应用 softmax，再应用 log() 软化学生 logits soft_targets = teacher_func(teacher_logits, T) soft_prob = nn. functional.log_softmax(student_logits / T, dim=-1) # 计算软目标损失。按照论文“在神经网络中提炼知识”的作者建议的方式，按 T**2 缩放loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2) loss.backward() optimizer.step() running_loss += loss.item() print(f&quot;Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}&quot;)  当学生模型具有 resnet 架构时，我训练了 120 个 epoch，初始 lr 为 0.1，每 50 个 epoch 将 lr 减少 10 倍。 使用 alexnet 架构作为学生的训练类似，只有初始 lr 为 0.01。    提交人    /u/GreeedyGrooot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1heyvj3/why_does_my_model_not_learn_anything_during/</guid>
      <pubDate>Sun, 15 Dec 2024 18:29:03 GMT</pubDate>
    </item>
    <item>
      <title>需要深度学习练习题方面的帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hexo9f/need_help_with_deep_learning_practice_problems/</link>
      <description><![CDATA[您好，我是一名正在学习深度学习课程的学生，我一直在解决一些练习问题。但是，有一些问题我很难解决。由于练习问题没有答案，我发现很难验证我的解决方案。如果有人能帮助提供正确的答案和解释，我将不胜感激。非常感谢！    提交人    /u/Few_History8647   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hexo9f/need_help_with_deep_learning_practice_problems/</guid>
      <pubDate>Sun, 15 Dec 2024 17:35:03 GMT</pubDate>
    </item>
    <item>
      <title>帮助将成绩单 PDF 中的数据提取到预定义表中</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hevn6k/help_with_extracting_data_from_transcript_pdfs/</link>
      <description><![CDATA[大家好， 我正在做一个项目，需要读取成绩单 PDF 并将其数据填充到预定义表中。挑战在于这些成绩单有各种格式，无论布局如何，程序都需要可靠地识别和提取学生姓名、课程名称、成绩等字段。 我遇到的一个大问题是，在将 PDF 转换为文本时，输出不一致。例如，即使 MATH 101 和 3.0 在 PDF 中位于同一行，文本输出也可能将它们相隔几行，中间有不相关的文本。 我很乐意听取您关于如何解决这个问题的建议或意见！具体来说：  您推荐任何工具或库来更好地解析 PDF 或保留布局？ 处理不一致的文本提取以准确匹配字段的策略？ 如果您从事过类似工作，有什么见解或提示吗？  提前感谢您的帮助！    提交人    /u/HoneyChilliPotato7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hevn6k/help_with_extracting_data_from_transcript_pdfs/</guid>
      <pubDate>Sun, 15 Dec 2024 16:04:07 GMT</pubDate>
    </item>
    <item>
      <title>我的 LR 是不是太高了？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1heulh0/is_my_lr_too_high/</link>
      <description><![CDATA[      https://preview.redd.it/s3cipze2417e1.png?width=1800&amp;format=png&amp;auto=webp&amp;s=325297902c05d35b5225e1930d2d1f60c35a7083 训练有效批量大小为 32 的 Transformer 解码器（4 个 GPU，每个 GPU 的 bs 为 8使用 DDP 策略）。预热 5k 步后，最大 LR 为 1e-4，余弦衰减至 1e-6。我还将梯度范数剪裁为 1.0。但我想知道，损失中的这些急剧尖峰，是否看起来是 LR 太高的情况？    提交人    /u/leoholt   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1heulh0/is_my_lr_too_high/</guid>
      <pubDate>Sun, 15 Dec 2024 15:15:05 GMT</pubDate>
    </item>
    <item>
      <title>制作 AI 内容检测器时对 BERT 模型的结果进行增强</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hetir5/result_enhancement_for_bert_model_while_making_ai/</link>
      <description><![CDATA[      大家好！ 我正在尝试制作内容写作行业中最好的 AI 检测器。因此，对于最小版本，我已从 hugging face 获取数据集，并在此基础上训练 Roberta 模型，准确率达到 94.00%。现在我想提高模型的性能，也想获得这些结果的概率，例如“90% 更有可能由 AI 编写”或类似内容。 我应该使用 softmax 函数吗？请为我提供宝贵的见解，告诉我现在该如何继续。我是 AI 的初学者，我正在自学一切。您的小小帮助在这个过程中对我非常有帮助。请向我提供宝贵的反馈意见，以提高我的模型准确性。 Roberta 模型性能报告    提交人    /u/immodestmunda   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hetir5/result_enhancement_for_bert_model_while_making_ai/</guid>
      <pubDate>Sun, 15 Dec 2024 14:20:48 GMT</pubDate>
    </item>
    <item>
      <title>SWE 至 MLE 建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hepn4v/swe_to_mle_advice/</link>
      <description><![CDATA[我的目标是成为 ML 领域的 MLE 或 SWE  哪些课程对我这样的背景的人最有帮助。  过去 3 - 4 年来，我一直是一名 SWE（全栈），希望成长为 MLE 类型的角色，或者只是部署 ML 模型的 SWE。  寻求资源、建议或路线图。  这里有其他人经历过类似的转变吗？     提交人    /u/CornSpark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hepn4v/swe_to_mle_advice/</guid>
      <pubDate>Sun, 15 Dec 2024 10:08:21 GMT</pubDate>
    </item>
    <item>
      <title>Ilya Sutskever 谈论预训练和数据的未来。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1he8ir4/ilya_sutskever_on_the_future_of_pretraining_and/</link>
      <description><![CDATA[        提交人    /u/bulgakovML   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1he8ir4/ilya_sutskever_on_the_future_of_pretraining_and/</guid>
      <pubDate>Sat, 14 Dec 2024 18:02:31 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>