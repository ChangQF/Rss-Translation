<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 07 Aug 2024 12:29:38 GMT</lastBuildDate>
    <item>
      <title>对于任何想要了解更多有关多模式 LLM 的人来说，这张评估图表帮助我了解每种型号的价格和性能。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ema8de/for_anyone_looking_to_learn_more_about_multimodal/</link>
      <description><![CDATA[  由    /u/Confident-Honeydew66  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ema8de/for_anyone_looking_to_learn_more_about_multimodal/</guid>
      <pubDate>Wed, 07 Aug 2024 12:15:32 GMT</pubDate>
    </item>
    <item>
      <title>“实际”值错误</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em9qea/error_in_actual_values/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em9qea/error_in_actual_values/</guid>
      <pubDate>Wed, 07 Aug 2024 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>训练推理性能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em9aas/training_inference_performance/</link>
      <description><![CDATA[大家好。 我已经创建了一个使用网格搜索优化超参数的 CNN 模型，并且由于项目具体情况，使用 NSE 作为性能指标。 我的训练 NSE 为 0.8，但是当我运行推理时，预测结果很糟糕。该模型非常简单，超参数低，并且与训练数据拟合得很好。每当我调整它时，它的性能就会下降。 我该如何应对这种疑似过度拟合？    提交人    /u/Jinsteh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em9aas/training_inference_performance/</guid>
      <pubDate>Wed, 07 Aug 2024 11:25:47 GMT</pubDate>
    </item>
    <item>
      <title>熊猫图书馆</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em7kuo/pandas_library/</link>
      <description><![CDATA[此 Github Pandas 练习 中的练习是否足以帮助您在应用模型之前清理数据。 我在清理部分遇到了困难，因此开始练习 pandas、numpy 库。 在实施 ML 模型之前，我还应该关注什么？    提交人    /u/MediumMix707   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em7kuo/pandas_library/</guid>
      <pubDate>Wed, 07 Aug 2024 09:40:29 GMT</pubDate>
    </item>
    <item>
      <title>揭示高度依赖特征的关系并保留特征相对排名的想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em7b35/ideas_for_uncovering_the_relationships_highly/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em7b35/ideas_for_uncovering_the_relationships_highly/</guid>
      <pubDate>Wed, 07 Aug 2024 09:21:42 GMT</pubDate>
    </item>
    <item>
      <title>免费 LLM API</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em61mr/free_llm_apis/</link>
      <description><![CDATA[为了使用 LLM 构建生成式 AI 应用程序，许多公司都提供免费的 LLM API。本教程介绍如何利用 Gemini (由 Google 提供)、Groq 和 Hugging face 的免费 API：https://youtu.be/iw6xozGZH3g?si=WZJ-y9wQybfS17aA    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em61mr/free_llm_apis/</guid>
      <pubDate>Wed, 07 Aug 2024 07:55:18 GMT</pubDate>
    </item>
    <item>
      <title>GitHub - OCEANOFANYTHINGOFFICIAL/AI-Blog-Article-Generator：AI 博客文章生成器是一款基于 Python 的工具。此工具可帮助您根据指定主题创建引人入胜、独特且人性化的内容。它可以以 HTML 和 Markdown 格式输出内容。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em5irs/github/</link>
      <description><![CDATA[        提交人    /u/OCEANOFANYTHING   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em5irs/github/</guid>
      <pubDate>Wed, 07 Aug 2024 07:19:10 GMT</pubDate>
    </item>
    <item>
      <title>像 CrossValidated 这样的 Subreddit，我可以在其中提出一些不那么初级的问题并获得深入的答案？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em4ckx/subreddit_like_crossvalidated_where_i_can_ask_not/</link>
      <description><![CDATA[我知道我可以在这里问，但通常人们会假设我是一个完全的初学者，这意味着人们会在类比上付出额外的努力，这一点非常值得赞赏，但我想要更深入的见解或观点，我可能甚至没有想过？    提交人    /u/MysticalDragoneer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em4ckx/subreddit_like_crossvalidated_where_i_can_ask_not/</guid>
      <pubDate>Wed, 07 Aug 2024 06:02:02 GMT</pubDate>
    </item>
    <item>
      <title>Coursera 生成式人工智能课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em42le/coursera_generative_ai_courses/</link>
      <description><![CDATA[伙计们， 您在寻找 Coursera 生成式 AI 课程吗？... 如果是，那么本博客适合您。在此博客中，我将与您分享最佳 Coursera 生成式 AI 课程。 希望这些课程对您有所帮助。 学习愉快！    提交人    /u/Some-Patient-7191   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em42le/coursera_generative_ai_courses/</guid>
      <pubDate>Wed, 07 Aug 2024 05:44:37 GMT</pubDate>
    </item>
    <item>
      <title>每个特征的有效时间步长数量可变的 LSTM。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1em246z/lstm_with_variable_number_of_valid_timesteps_for/</link>
      <description><![CDATA[嗨， 我正在尝试确定是否可以使用 TensorFlow 构建多变量、多时间步长、多步骤 LSTM，其中每个特征不一定具有相同的长度，即具有不同的时间步长。例如，假设 X 的形状为 (n, 4, 3)，但最后一个特征仅在前两个时间步中具有有效值，例如 X[0] 为：   a b c    d e f   g h .   i j .   I尝试了 Masking 层，但根据 doco，掩码决定了要使用哪些时间步长，但我想使用上面的所有四个时间步长，但忽略第三个特征中的最后两个值。 我猜一个解决方案就是在这些位置放 0。但我实际上想以某种方式告诉 LSTM 模型不应该使用这些值。实际上，我有很多长度不同的特征。 这可能吗？谢谢您的帮助！    提交人    /u/ebararist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1em246z/lstm_with_variable_number_of_valid_timesteps_for/</guid>
      <pubDate>Wed, 07 Aug 2024 03:51:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在预测过程中正确地进行模型基准测试</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1elzrw1/how_to_properly_do_model_benchmark_during/</link>
      <description><![CDATA[您好， 我目前正在开发一个项目，该项目将使用 Keras 机器学习 CNN 模型进行图像分类。此模型将部署在非常有限的硬件上，受到 CPU、功率和内存的限制。在有效地对其进行原型设计之前，我想知道是否有一种好的方法可以在预测过程中对模型进行基准测试。 对于训练，我在租用的机器上使用 Python Keras。我尝试到处搜索，但找不到解决此问题的项目。我找到的是 Python 库，例如 psutil 和 memory_profiler。 有人知道这些库是否会让我对这些参数进行良好的估计，在这种情况下，或者是否有更好的方法在实际原型设计之前预测这些参数？ 任何帮助都将不胜感激！    提交人    /u/Repulsive_Apple9286   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1elzrw1/how_to_properly_do_model_benchmark_during/</guid>
      <pubDate>Wed, 07 Aug 2024 01:54:04 GMT</pubDate>
    </item>
    <item>
      <title>如何改进图像编码器-解码器模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1elzdsp/how_can_i_improve_an_image_encoderdecoder_model/</link>
      <description><![CDATA[大家好！ 首先，我对人工智能完全是个新手。我喜欢阅读，这只是我的一个爱好。 我有一个小模型（部分基于 Stable Diffusion 的 AutoencoderKL，但没有注意力，潜在值为 3x64x64 而不是 4x64x64）用于接收 3x1024x1024 图像并在 3x64x64 空间中对其进行编码，然后将其解码回来。它使用纯 Conv2d，带有 BatchNorm 和 Tanh &amp; LeakyReLU 层。我用视频中的图像对它进行了训练，使用了不同的优化器和超参数（优化器为 SGD、Adam、AdamW；L1、MSE 和一些我似乎记不清的其他损失；以及这些优化器和损失函数的所有排列）。 问题是，与 AutoencoderKL 相比，它似乎没有什么用。它编码然后解码的图像具有所有一般特征，但细节和锐利边缘仍然缺失。 我的问题是，我该如何改进它？这是 Conv2d 的限制吗？使用注意力真的能解决问题吗？还是我需要（就像 AlexNet 的情况一样）增加层数？ 我读了一些关于残差网络和跳过连接的文章，但我认为我不应该使用它们。我想将图像编码到潜在空间中，以便在其他模型中使用。 任何帮助，即使不能直接回答问题，也非常感谢。提前致谢！    提交人    /u/busypoof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1elzdsp/how_can_i_improve_an_image_encoderdecoder_model/</guid>
      <pubDate>Wed, 07 Aug 2024 01:35:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习入门的热门资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1elqmqt/top_resources_to_get_started_in_ml/</link>
      <description><![CDATA[大家好，ML 社区 分享一些我喜欢的顶级资源，以便开始/刷新我在 ML 中的概念。 如需更多资源和见解，请访问我的时事通讯上的最新文章，网址为ML Engineer Insights。如果您喜欢，请考虑订阅，它是免费的！ 课程：  Coursera 上的机器学习专业化简介，由 Andrew Ng 讲授 Coursera 上的深度学习专业化  书籍：  百页机器学习书籍，作者：Andriy Burkov 使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习，作者：Aurélien Géron  实用的 NLP 资源：  开始使用NLP，我强烈推荐 Hugging Face 的 Practical NLP Introduction。 要开始学习 LLM，请访问 GitHub 上的 Introduction to LLM。  你喜欢什么资源？在评论中分享！    提交人    /u/tobeflyer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1elqmqt/top_resources_to_get_started_in_ml/</guid>
      <pubDate>Tue, 06 Aug 2024 19:22:06 GMT</pubDate>
    </item>
    <item>
      <title>重现麻省理工学院的机器学习讲座</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1elede1/recreating_the_machine_learning_lectures_taught/</link>
      <description><![CDATA[我的手写讲义 - 视频 我在麻省理工学院上的机器学习课程改变了我的生活。我从机械工程转到机器学习，并获得了机器学习博士学位。 我想创建像我在麻省理工学院学到的讲座那样的机器学习视频：  深入  -直觉驱动  不假设任何事情，展示一切的细节  在过去的 3 个月里，我开始了一个教授机器学习和深度学习的项目，就像我在麻省理工学院学到的那样。 我录制了 70 个机器学习和深度学习视频。 每天，我都会编写脚本、录制和编辑 1 个视频，大约 6-7 个小时。结果是 2 个庞大的播放列表。 1️⃣ 机器学习边做边教播放列表： (a) 涵盖的主题：回归、分类、神经网络、卷积神经网络 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） (d) 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSi-nLQ4XV2Mds8Z7bihK68L 2️⃣ 从头开始​​的神经网络播放列表： (a) 涵盖的主题：神经网络架构、前向传递、后向传递、优化器。完全用 Python 从头开始​​编码。没有 Pytorch。没有 Tensorflow。只有 Numpy。 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSj6tNyn_UadmUeU3Q3oR-hu P.S：讲师背景：我毕业于麻省理工学院，获得机器学习博士学位。视频详细展示了我的笔记。   由    /u/OtherRaisin3426  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1elede1/recreating_the_machine_learning_lectures_taught/</guid>
      <pubDate>Tue, 06 Aug 2024 10:34:03 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>