<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 01 Nov 2024 06:25:45 GMT</lastBuildDate>
    <item>
      <title>寻找包含以下内容的书籍/课程：训练 VAE、主要机器/深度学习模型概述，最好是在 pytorch 中</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggyct5/looking_for_bookcourses_that_includes_training/</link>
      <description><![CDATA[我目前正在阅读《傻瓜机器学习》，原本计划阅读《傻瓜深度学习》。但这本书太糟糕了。是的，它涵盖了基础知识。但描述和代码在完全不同的章节中。当你读到代码时，你已经忘记了描述。此外，他们几乎没有解释代码。 所以，我正在寻找一本替代书籍/课程来涵盖所有基本的机器/深度学习模型。理想情况下使用 pytorch，因为我计划在未来的项目中使用原生 pytorch FSDP（而不是像加速之类的东西）。并且理想情况下深入介绍训练 VAE，因为这是我真正感兴趣的当前主题。 http://neuralnetworksanddeeplearning.com 看起来有点基础。通过阅读《理解深度学习》的几章，我熟悉了其中的大部分概念。 d2l.ai 看起来不错，但我在大纲中没有看到任何关于 VAE 的内容。 背景：我是一名业余爱好者，计划以后微调 LLM 和文本到图像模型以供工作使用。学习的数学：线性代数、微积分、基础统计/概率。目前正在阅读《学生贝叶斯统计指南》。可以用 Python 编写一些基本的东西。比如，我编写了一个带有扩散器和加速 FSDP 的多 GPU sdxl 微调脚本，带有自定义数据集类和验证函数以及其他自定义内容。目前正在将其移植到 sd3.5 介质，并进行 CLIP 微调（我不喜欢通过 UNET 训练 CLIP 的想法）。 提前致谢！    提交人    /u/Aware_Photograph_585   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggyct5/looking_for_bookcourses_that_includes_training/</guid>
      <pubDate>Fri, 01 Nov 2024 05:24:11 GMT</pubDate>
    </item>
    <item>
      <title>我应该发布关于机器学习的笔记/博客吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</link>
      <description><![CDATA[大家好， 我是机器学习的硕士生（本科电气和计算机工程专业 + 3 年软件/网络开发经验）。现在，我是一名全日制学生，也是机器学习实验室的研究助理。 事情是这样的：我在机器学习方面完全是个菜鸟。比如，如果你认为使用 API 和人工智能工具意味着你“了解机器学习”，那么我要说这不算数。我对机器学习着迷了一段时间，并试图自学，但大多数课程都非常抽象。 事实证明，机器学习涉及大量数学。当然，有一些很酷的库，但如果你不懂数学，祝你好运改进你的模型。过去几个月，我一直在研究一些复杂的数学——高级线性代数、矩阵方法、信息论——同时在我的实验室从头开始构建一个 transformer 训练管道。这太让人不知所措了。说实话，我因为迷茫而崩溃了好几次。 但事情开始变得明朗起来。我最大的挣扎是不知道为什么以及如何使用我所学的东西。感觉我只是顺其自然，希望它最终会有意义，有时确实如此……但它花费的时间比它应该的要长得多。另外，我有没有提到数学？这不是高中数学；我们说的是研究生水平，甚至是博士水平的数学。而且大多数时候，你必须阅读最近的研究论文并解码这些符号以将它们应用于你的问题。 所以这是我的问题是：我挣扎了很多，也许其他人也一样？也许我只是反应慢。但我一路上都做了笔记，试图简化那些我希望有人能更好地解释的概念。我应该将它们作为博客/子堆栈/网站分享吗？我觉得知识最好是分享的，尤其是在一个想要一起学习的社区里。我很乐意与大家一起学习，一起探索这些很酷的东西。 关于从哪里开始或哪种格式可能最好的想法？    提交人    /u/ziggyboom30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggxm3q/should_i_post_my_notes_blog_on_machine_learning/</guid>
      <pubDate>Fri, 01 Nov 2024 04:33:48 GMT</pubDate>
    </item>
    <item>
      <title>迷路了！救命</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggxjgf/lost_help/</link>
      <description><![CDATA[所以，我刚刚开始学习机器学习，老实说，我不知道从哪里开始！如果有人有一些可靠的免费资源可以系统地列出所有内容，我将不胜感激。任何关于我应该如何开始的提示也都很棒。    提交人    /u/BowlInternational584   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggxjgf/lost_help/</guid>
      <pubDate>Fri, 01 Nov 2024 04:28:57 GMT</pubDate>
    </item>
    <item>
      <title>ML 工程师 techstack - 2024 年</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggx4yk/ml_engineer_techstack_2024/</link>
      <description><![CDATA[感谢大家的帮助。 对于任何计划从大数据/后端转向 MLE 作为工作角色的人，您会推荐哪种技术堆栈。我知道大多数基本原理保持不变，但肯定有一些偏好是大多数公司使用的工具？ 例如：在数据中，那就是 Spark 和 Airflow 对 MLE 有任何类似的想法吗？    提交人    /u/RobotsMakingDubstep   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggx4yk/ml_engineer_techstack_2024/</guid>
      <pubDate>Fri, 01 Nov 2024 04:03:53 GMT</pubDate>
    </item>
    <item>
      <title>超越原始文本分类？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggu83s/beyond_vanilla_text_classification/</link>
      <description><![CDATA[我经常使用 HuggingFace Transformer 的框架来微调类似 BERT 的文本分类模型。在我的任务上，性能通常相当不错，而且我尝试扩展完全原始的管道来改进它。具体来说，我尝试过堆叠模型、用合成样本扩充我的训练数据集，以及训练自定义 QA 模型以在分类之前从每个文档中分割重要文本。 这一切都有帮助，但仍有改进的空间，而且我的想法已经用完了。对于那些在这个范式中训练文本分类器的人，你们使用了哪些创造性的方法来提高性能，超越了原始的&amp;32; 微调变压器模型&amp;32;？    提交人    /u/empirical-sadboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggu83s/beyond_vanilla_text_classification/</guid>
      <pubDate>Fri, 01 Nov 2024 01:17:46 GMT</pubDate>
    </item>
    <item>
      <title>首次微调模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggtn3n/first_time_fine_tuning_model/</link>
      <description><![CDATA[我如何微调像 Llama 3 这样的模型以从给定的描述中提取重要信息？另外，我必须手动完成这个过程吗？我希望它提取非常具体的数据并以特殊的方式组织它，所以我想我必须提示它，告诉它输出是否正确，并继续生成我自己的数据。有没有办法自动生成数据，这样我就不必总是手动操作了？ 这是我第一次这样做，所以任何提示和指导都很好。谢谢！    提交人    /u/Droski_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggtn3n/first_time_fine_tuning_model/</guid>
      <pubDate>Fri, 01 Nov 2024 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>在自定义数据集上训练 PyTorch DeepLabV3</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggtefu/train_pytorch_deeplabv3_on_custom_dataset/</link>
      <description><![CDATA[      在自定义数据集上训练 PyTorch DeepLabV3 https://debuggercafe.com/train-pytorch-deeplabv3-on-custom-dataset/ 语义分割与深度学习结合可以增加巨大的价值。语义分割在医学成像、环境成像和卫星图像领域有多种应用。涉足这些领域中的任何一个并开展项目都可以提供大量知识。在本文中，我们将从单类语义分割开始。我们将在自定义数据集上训练 PyTorch DeepLabV3 模型。该数据集由水体的卫星图像组成。 https://preview.redd.it/46hc1rwxq6yd1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=0633f6446953c86193b1a03e453ea21657370541    提交人    /u/sovit-123   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggtefu/train_pytorch_deeplabv3_on_custom_dataset/</guid>
      <pubDate>Fri, 01 Nov 2024 00:35:01 GMT</pubDate>
    </item>
    <item>
      <title>时期的数量是否会影响创建或绘制 pkl 模型的时间？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggte4u/does_the_amount_of_epochs_affect_the_amount_of/</link>
      <description><![CDATA[我正在使用 ipynb 和 anaconda 运行一段代码，该代码可以在 Visual Studio Code 中创建 pkl 格式的 cnn 模型。它在大多数情况下都有效，直到到达代码的这一部分：  learn = vision_learner(dls, resnet50, metrics=error_rate) learn.fine_tune(4)  从开始运行这部分代码已经过去了将近 2 个小时，感觉它让我的整个笔记本电脑都严重滞后。我知道这更像是一个编程问题，但这就是为什么我一直很好奇 epoch 数量（如您在“fine_tune”上看到的是 4）是否影响了完成其部分所需的时间。我用于该模型的数据集非常大，有超过 15 个类别。所以我不确定是否应该增加或减少 epoch 的数量。     提交人    /u/LuisCruz13   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggte4u/does_the_amount_of_epochs_affect_the_amount_of/</guid>
      <pubDate>Fri, 01 Nov 2024 00:34:35 GMT</pubDate>
    </item>
    <item>
      <title>2024 - 2025 年的新产品是 MLX 和 Transofermers，因此让我们比较一下 Apple Silicon 上的 MLX 与 PyTorch 上的 iOS 自定义深度学习模型 - 第 2 天 - INGOAMPT</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggt3mx/new_on_2024_2025_are_mlx_and_transofermers_so/</link>
      <description><![CDATA[  由    /u/Potential_Arrival326  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggt3mx/new_on_2024_2025_are_mlx_and_transofermers_so/</guid>
      <pubDate>Fri, 01 Nov 2024 00:19:29 GMT</pubDate>
    </item>
    <item>
      <title>适合非计算机科学背景的 DS/ML/NLP 硕士课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggs7z3/dsmlnlp_masters_programs_for_noncs_background/</link>
      <description><![CDATA[大家好， 我是一名国际学生，目前正在攻读计算语言学学士学位，并考虑在美国学校攻读计算语言学/语言技术硕士学位。目前，我的（非常乐观的）职业计划是获得硕士学位，在此期间和之后，我将寻找可以在 STEM OPT 期间赞助工作签证的美国工作。我知道这非常狭窄，但是我确实有备用计划。 无论如何，由于我的背景更多地以语言学为导向，而我的计算机科学和数学训练相对较少，因此我主要关注也注重语言学的硕士课程，例如 UW Comp Ling MS、Brandeis Comp Ling MS 等。 但我的顾问也建议我研究更“纯粹”的具有与 NLP/语言学接口的 CS/DS 程序，例如 NYU MS DS 和 UMD MS DS。 所以我想问：你们对美国这样的 MS 课程有什么建议吗，这些课程也不严格要求计算机科学学士学位？    提交人    /u/TerminallyWell   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggs7z3/dsmlnlp_masters_programs_for_noncs_background/</guid>
      <pubDate>Thu, 31 Oct 2024 23:35:54 GMT</pubDate>
    </item>
    <item>
      <title>我正在开展一个使用元学习器的项目，但我没有机器学习背景（但精通计算机科学）有人可以推荐一些好的材料并快速提升吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggrjst/im_working_on_a_project_on_using_meta_learners/</link>
      <description><![CDATA[  由    /u/DoubleRadiant4331  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggrjst/im_working_on_a_project_on_using_meta_learners/</guid>
      <pubDate>Thu, 31 Oct 2024 23:02:29 GMT</pubDate>
    </item>
    <item>
      <title>VAE 中的后验、证据、先验和可能性是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ggp3u5/what_is_the_posterior_evidence_prior_and/</link>
      <description><![CDATA[      嗨， 在变分自动编码器 (VAE) 中，我们尝试学习一些数据的分布。为此，我们有“两个”端到端训练的神经网络。第一个网络，即编码器，对分布 q(z|x) 进行建模，即给定 x 预测 z。第二个网络对后验 q(x|z) 和 p_theta(x|z) 进行近似建模，即，对给定潜在变量 z 的 x 采样分布进行建模。 https://preview.redd.it/ti93kfzsp5yd1.png?width=658&amp;format=png&amp;auto=webp&amp;s=cbe1ff00503ed8dfdd11145ef37fd030e07d0475 阅读文献似乎 VAE 的优化目标是最大化 ELBO。这意味着最大化 p_theta(x)。但是，我想知道 p_theta(x) 不是先验吗？它是证据吗？ 我的疑问只是关于行话。让我解释一下。对于具有两个随机变量 A 和 B 的给定条件概率，我们有： p(B|A) = p(A|B)*p(B)/P(A) - p(B|A) 是后验 - p(A|B) 是似然 - p(B) 是先验 - P(A) 是证据 好吧，对于 VAE，解码器将尝试近似后验 q(x|z)。在 VAE 中，似然是 q(z|x)，这意味着后验是 q(x|z)，证据是 q(z)，先验是 q(x)。好吧，如果 VAE 的目标是最大化 ELBO（证据下限），并且 p_theta(x|z) 是后验 q(x|z) 的近似值，那么鉴于 q(z) 是证据，证据应该是 p_theta(z)，对吗？这就是我不明白的，因为他们说 p_theta(x) 现在是证据……但那是 q 中的先验…… q 和 p_theta 分布是否不同，并且它们具有不同的似然、先验、证据和后验？q 和 p_theta 的似然、先验、证据和后验是什么？ 谢谢！    提交人    /u/CompSciAI   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ggp3u5/what_is_the_posterior_evidence_prior_and/</guid>
      <pubDate>Thu, 31 Oct 2024 21:07:10 GMT</pubDate>
    </item>
    <item>
      <title>KNN算法可以处理多少个特征</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gglhi6/how_many_features_can_the_knn_algorithm_handle/</link>
      <description><![CDATA[KNN 算法应该能够处理多少个缩放（0 到 1 之间）的特征。我知道增加 KNN 的维度会导致问题，所以我很好奇要增加多少维度才会真正出现问题？我目前正在处理 40 个特征，想知道这对于 KNN 在数据中找到有意义的模式来说是否太多了？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gglhi6/how_many_features_can_the_knn_algorithm_handle/</guid>
      <pubDate>Thu, 31 Oct 2024 18:30:20 GMT</pubDate>
    </item>
    <item>
      <title>重新审视机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gghau0/revisiting_ml/</link>
      <description><![CDATA[我之前于 2013 年在布里斯托尔获得了机器学习硕士学位，但最终从事金融软件工作，因为当时该领域非博士生的工作机会并不多。 显然，深度学习从那时起就一路飙升。 有没有人对我们这些已经离开十年左右的人有什么建议？    提交人    /u/NotSoEnlightenedOne   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gghau0/revisiting_ml/</guid>
      <pubDate>Thu, 31 Oct 2024 15:30:31 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>