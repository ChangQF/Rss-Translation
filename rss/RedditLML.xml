<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 13 Feb 2024 21:12:12 GMT</lastBuildDate>
    <item>
      <title>解码后的预测输出始终是标记列表中的空字符串，但预测看起来不错。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aq2dya/predicted_output_after_decoding_is_always_empty/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aq2dya/predicted_output_after_decoding_is_always_empty/</guid>
      <pubDate>Tue, 13 Feb 2024 19:38:44 GMT</pubDate>
    </item>
    <item>
      <title>完成所有 Kaggle Learn 课程需要多长时间？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aq282o/how_long_does_it_take_to_finish_all_kaggle_learn/</link>
      <description><![CDATA[5 天，每天 5 小时够吗？   由   提交 /u/Icy_Broccoli_4162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aq282o/how_long_does_it_take_to_finish_all_kaggle_learn/</guid>
      <pubDate>Tue, 13 Feb 2024 19:31:55 GMT</pubDate>
    </item>
    <item>
      <title>常见问题解答聊天机器人</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aq1zsr/faq_chatbot/</link>
      <description><![CDATA[我有常见问题解答和答案。当用户提出与常见问题解答相关的问题时，机器人应该给出响应。常见问题解答的大小非常大。我是新手ML.iam 考虑使用前馈神经网络实现分类模型。我将为常见问题解答创建一些示例问题，并为每个问题创建一个类。当数据很大时，这个模型是否可行？请建议是否有合适的模型。   由   提交 /u/Intelligent_Usual392   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aq1zsr/faq_chatbot/</guid>
      <pubDate>Tue, 13 Feb 2024 19:22:35 GMT</pubDate>
    </item>
    <item>
      <title>从同一域下载多个 JSON 文件的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aq0vyo/what_is_the_best_way_to_download_multiple_json/</link>
      <description><![CDATA[ 由   提交/u/alenathomasfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aq0vyo/what_is_the_best_way_to_download_multiple_json/</guid>
      <pubDate>Tue, 13 Feb 2024 18:39:17 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的线性代数书籍？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apzpon/books_on_linear_algebra_for_machine_learning/</link>
      <description><![CDATA[我正在做一个项目，涉及从头开始创建一个神经网络。有很多资源可以告诉我如何做到这一点，但我一直在努力寻找任何深入了解机器学习和神经网络背后的线性代数的资源。是否有任何论文、书籍或其他资源可以指导我提供对 ML 背后数学的严格理解？   由   提交/u/Endeavor09  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apzpon/books_on_linear_algebra_for_machine_learning/</guid>
      <pubDate>Tue, 13 Feb 2024 17:52:39 GMT</pubDate>
    </item>
    <item>
      <title>释放 AI 的力量：ChatGPT 和大型语言模型的热门免费课程|深度学习人工智能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apyyrd/unlock_ais_power_top_free_courses_on_chatgpt/</link>
      <description><![CDATA[       由   提交/u/UseCreative4765   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apyyrd/unlock_ais_power_top_free_courses_on_chatgpt/</guid>
      <pubDate>Tue, 13 Feb 2024 17:23:06 GMT</pubDate>
    </item>
    <item>
      <title>在文本行+转录图像上训练 Tesseract？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apyvgp/training_tesseract_on_images_of_text_lines/</link>
      <description><![CDATA[你好， 我对如何仅使用图像 + txt 来训练 Tesseract 进行 OCR 感到非常困惑。它应该可以工作，但我无法让它工作。 这里有人有这方面的经验吗？可以为我提供一些帮助/如何正确使用它的示例吗？我知道 GitHub 存储库上有一些东西，但是（正如我所说）我对如何实际使用它感到非常困惑。 非常感谢任何帮助！    由   提交 /u/SirVampyr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apyvgp/training_tesseract_on_images_of_text_lines/</guid>
      <pubDate>Tue, 13 Feb 2024 17:19:30 GMT</pubDate>
    </item>
    <item>
      <title>变压器中的多头</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apy9uf/multihead_in_transformers/</link>
      <description><![CDATA[我是变形金刚的新手，对多头使用有疑问。我从各种博客中了解到，它有助于捕捉不同上下文中单词的重要性。例如，如果有 2 个头，令牌大小为 516，则嵌入会分成两个部分，分别进行处理。如果像“国王”这样的词在不同的维度上代表性别和皇室，那么将它们分成不同的两半可以让模型学习这两个方面。然而，如果性别和皇室在同一半，模型仍然可以单独辨别它们的重要性，还是仅限于一次只关注一个方面？   由   提交/u/thestorytellerixvii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apy9uf/multihead_in_transformers/</guid>
      <pubDate>Tue, 13 Feb 2024 16:55:47 GMT</pubDate>
    </item>
    <item>
      <title>哪个模型从超参数调整中受益最多？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apxv7d/which_model_benefited_the_most_from/</link>
      <description><![CDATA[      是否可以看出哪个模型从超参数调整中获益最多？我认为我们可以说它不是随机森林分类器，因为它的结果非常好且均匀。 https://preview.redd.it/y1c8q252sdic1.png?width=1766&amp;format=png&amp;auto=webp&amp;s=4c681106c16a537fc54eec 5d63e42c3784d1aa45   由   提交/u/nipaldi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apxv7d/which_model_benefited_the_most_from/</guid>
      <pubDate>Tue, 13 Feb 2024 16:39:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 vLLM 在 AWS EC2 上部署 Mixtral 8x7B、LLaMA 2 和 Mistral</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apxjn6/deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</link>
      <description><![CDATA[大家好， 2023 年，许多复杂的开源 LLM 已经推出。然而，将这些人工智能模型集成到生产环境中仍然是一项复杂的任务。我撰写了一篇文章，将指导您在 AWS EC2 上部署一些顶级 LLM，即 LLaMA 2 70B、Mistral 7B 和 Mixtral 8x7B。我采用了一个能够批量处理和分布式推理的推理引擎：vLLM。 vLLM 将极大地帮助 LLaMA 2 和 Mixtral 的实现，因为它允许我们使用配备多个较小 GPU 的 AWS EC2 实例（例如例如 NVIDIA A10），而不是依赖单个大型 GPU（例如 NVIDIA A100 或 H100）。 请参阅此处的详细操作方法：https://nlpcloud.com/deploy-llama -2-mistral-and-mixtral-on-aws-ec2-with-vllm.html 在本教程中，我使用了 AWS EC2，但当然我也可以使用其他供应商。主要挑战是 GPU 的成本及其可用性。 请随时分享有关本文的反馈，我们将非常感激！ Julien   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apxjn6/deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</guid>
      <pubDate>Tue, 13 Feb 2024 16:26:39 GMT</pubDate>
    </item>
    <item>
      <title>我很困惑我应该做什么</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apvhbe/i_am_confused_about_what_i_should_do/</link>
      <description><![CDATA[我学习了基本的分类和回归模型（例如：SVR、决策树、随机森林等）。下一步我应该做什么？？？ ​   由   提交/u/Personal-Novel-7171   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apvhbe/i_am_confused_about_what_i_should_do/</guid>
      <pubDate>Tue, 13 Feb 2024 15:01:42 GMT</pubDate>
    </item>
    <item>
      <title>我的代码运行没有错误，但生成的模型错误地分类了苹果叶病</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1apve3o/my_code_run_without_error_but_the_resulted_model/</link>
      <description><![CDATA[大家好。我还是个初学者。我想问我的代码有什么问题，结果模型没有正确分类苹果叶病？当我运行代码时，代码运行没有错误，但疾病分类是错误的。我在 7k 图像苹果叶病数据集上进行了训练，包含 4 个类别，每个类别大约有 1.8k 个图像。每个类的总图像不相等，这是否影响模型分类？还是我下面的代码有问题？ ```python from google.colab importdrivedrive.mount(&#39;/content/gdrive&#39;)import zipfile zip_ref = zipfile .ZipFile(&#39;/content/gdrive/MyDrive/dataset/data9k.zip&#39;, &#39;r&#39;) zip_ref.extractall(&quot;/content/dataset&quot;) zip_ref.close() 导入tensorflow为tf从tensorflow.keras.applications.imagenet_utils导入preprocess_input导入matplotlib.pyplot作为plt train_dataset = tf.keras.utils.image_dataset_from_directory(&#39;/content/dataset/datasets/train&#39;,batch_size=10,image_size= (224, 224), labels=&#39;inferred&#39;, label_mode=&#39;categorical&#39; ) validation_dataset = tf.keras.utils.image_dataset_from_directory( &#39;/content/dataset/datasets/test&#39;, batch_size=10, image_size=(224, 224), labels=&#39;推断&#39;, label_mode=&#39;分类&#39; ) val_batches = tf.data.experimental.cardinality(validation_dataset) test_dataset =validation_dataset.take(val_batches // 5) valid_dataset = valid_dataset.skip(val_batches // 5) AUTOTUNE = tf.data.AUTOTUNE train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE) validation_dataset = valid_dataset.prefetch(buffer_size=AUTOTUNE) test_dataset = test_dataset.prefetch (buffer_size=AUTOTUNE) data_augmentation = tf.keras.Sequential( [tf.keras.layers.RandomFlip(&#39;horizo​​ntal&#39;), tf.keras.layers.RandomRotation(0.2)] )  模型 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0( include_top=False, Weights=None, input_tensor=None, input_shape=(224, 224, 3), pooling=&#39;avg&#39;, include_preprocessing=True ) model.trainable=False prediction_layer = tf.keras.layers.Dense(4,activation=&#39;softmax&#39;) inputs = tf.keras.Input(shape =(224, 224, 3)) x = data_augmentation(inputs) x = preprocess_input(x) x = model(x) x = tf.keras.layers.Dropout （0.2）（x）输出=预测层（x）模型= tf.keras.Model（输入，输出） model.compile（optimizer=tf.keras.optimizers.Adam（learning_rate=1e-4） ），loss=tf.keras.losses.CategoricalCrossentropy（），metrics=[&#39;accuracy&#39;]） model.fit（train_dataset，validation_data=validation_dataset，epochs=10） 从tensorflow.keras.preprocessing导入numpy作为np导入图像 img_path = &#39;gdrive/MyDrive/dataset/rust.jpg&#39; img = image.load_img(img_path, target_size=(224, 224)) img_array = image.img_to_array(img) img_array = np.expand_dims(img_array, axis=0) 预测 = model.predict(img_array) class_names = [&#39;apple_scab&#39;, &#39;black_rot&#39; , &#39;cedar_apple_rust&#39;, &#39;healthy&#39;] predicted_index = np.argmax(predictions[0]) label = class_names[predicted_index] print(&quot;预测标签：&quot;, label) ``` 如果我的英语语法不好，我很抱歉。   由   提交 /u/Mammoth-Baker5144   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1apve3o/my_code_run_without_error_but_the_resulted_model/</guid>
      <pubDate>Tue, 13 Feb 2024 14:57:55 GMT</pubDate>
    </item>
    <item>
      <title>简化的变形金刚？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1appqes/simplified_transformers/</link>
      <description><![CDATA[我了解 Transformer 架构有多么革命性。然而，在研究它的过程中，这个东西包含了如此之多的细节，这让每个人都难以理解/增强。 我的问题是，是否有人尝试过构建简化的 Transformer 架构？类似于 GRU 是 LSTM 的简化版本。  如果您能给我指出任何试图实现这一目标的论文，或者在 2017 年原始论文中找到任何不必要/不太必要的元素，我将不胜感激。 &lt; !-- SC_ON --&gt;  由   提交 /u/Salloum-A   /u/Salloum-A  reddit.com/r/learnmachinelearning/comments/1appqes/simplified_transformers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1appqes/simplified_transformers/</guid>
      <pubDate>Tue, 13 Feb 2024 09:43:38 GMT</pubDate>
    </item>
    <item>
      <title>我的公司给了我 500 美元的教育预算。寻找推荐</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aplhu5/my_company_gave_me_a_500dollar_education_budget/</link>
      <description><![CDATA[有什么值得付费的课程、书籍或其他材料的推荐吗？ TIA。   由   提交 /u/myotheraccount7071   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aplhu5/my_company_gave_me_a_500dollar_education_budget/</guid>
      <pubDate>Tue, 13 Feb 2024 05:05:59 GMT</pubDate>
    </item>
    <item>
      <title>宣布 ML 的小型编码问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aphj8p/announcing_bitesized_coding_problems_for_ml/</link>
      <description><![CDATA[大家好，  u/NeetCode 和我很高兴地宣布 AI/ML 的编码问题，您可以在浏览器中解决这些问题并针对测试用例运行。他们假设没有人工智能/机器学习方面的背景知识。他们从头开始从线性回归到编码和训练 GPT 聊天模型！ 对于每个问题，我还创建了一个 5-10 分钟的背景视频，涵盖解决问题所需的概念（或测验、包含多项选择测验的主题）以及解决方案视频。 所有问题视频，以及每周 2 次关于不同 ML 主题的概念概述（欢迎提出建议！）可以在我的频道上找到：https://www.youtube.com/@GPTandChill The问题列表可以在 NeetCode 网站上找到 https://neetcode.io/practice?subpage =practice&amp;tab=coreSkills&amp;topic=Machine%20Learning 或在我的网站上 https://www.gptandchill .ai/leetcode-for-ml 以下是 Navi 的帖子，提供一些其他背景信息： https://x.com/neetcode1/status/1756997643556041191?s=20 https://www.linkedin.com/posts/activity-7162822685037674496-i0Yo?utm_source=share&amp;utm_medium=member_desktop&lt; /p&gt; 如果您喜欢此类教育内容或有任何反馈，请告诉我们！   由   提交 /u/GPTandChill   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aphj8p/announcing_bitesized_coding_problems_for_ml/</guid>
      <pubDate>Tue, 13 Feb 2024 01:49:20 GMT</pubDate>
    </item>
    </channel>
</rss>