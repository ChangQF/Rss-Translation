<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Sun, 02 Mar 2025 12:30:08 GMT</lastBuildDate>
    <item>
      <title>缺失值对模型和预处理步骤的影响</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_of_missing_values_on_both_models_and/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/riteshbhadana     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_missing_values_values_on_both_models_models_and/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1pbc3/impact_of_missing_values_on_both_models_and/</guid>
      <pubDate>Sun, 02 Mar 2025 12:00:22 GMT</pubDate>
    </item>
    <item>
      <title>在线学习机器学习的最佳资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1p47h/best_resources_online_to_learn_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    从deeplearlearning.ai by Andrew ng ng ng   - 初学者    href =“ https://imp.i384100.net/dvzr5a”&gt; ibm机器学习专业证书A-Z™：动手Python＆amp; R UDEMY  数据科学的R r    深度学习专业化。深度学习  生产的机器学习工程（MLOPS）专业化来自Supervised Machine Learning: Regression and Classification, Coursera, Andrew Ng - Beginner Matrix Algebra for Engineers, Coursera, Jeffrey R. Chasnov 机器学习专业数学  - 初学者   Google Cloud上的机器学习href =“ https://www.pntra.com/t/tujgr0llr0jhskhgskhcr0zisk1n?website = 361357&amp;refurl=https%3A%3A%3A%2FFURL = HTTPS； -codecademy    python编程 -  udacity    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sreeravan   href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1p47h/1j1p47h/best_resources_online_to_to_to_learn_machine_learne_learning/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1p47h/best_resources_online_to_learn_machine_learning/</guid>
      <pubDate>Sun, 02 Mar 2025 11:47:15 GMT</pubDate>
    </item>
    <item>
      <title>Bentoml：初学者的MLOP</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1oss7/bentoml_mlops_for_beginners/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/kingabzpro      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1oss7/bentoml_mlops_for_beginners/</guid>
      <pubDate>Sun, 02 Mar 2025 11:25:30 GMT</pubDate>
    </item>
    <item>
      <title>剥夺利用的漏洞？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1ny1w/denoising_vulnerabilities_to_exploit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨！我是一名计算机科学本科生，目前正在研究我的最后一篇论文。 因此，关于我的研究，在过去的一年中，我一直在看到针对生成模型的扰动工具，旨在损坏这些模型输出（文本到图像）的图像。我正在基于它们的研究。 由于它们的流行，我决定专门针对扩散模型。目前，我正在尝试了解扩散模型的工作原理以及它们如何生成图像，因为我试图寻找弱点和脆弱性来利用我的自定义对抗性工具。我正在阅读DDPM的原始论文，但老实说，它的技术程度使我不知所措。老实说，我不知道在哪里寻找帮助，也不相信要求AI帮助我完成我需要毕业的最后一件事。这里有人可以帮助我并将我指向正确的方向吗？有人知道我可以在DeNoising阶段利用哪些特定漏洞？预先感谢您，这真的很大程度上会帮助我完成我的最后一个学期。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lahrens28     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1ny1w/denoising_vulnerabilities_to_exploit/</guid>
      <pubDate>Sun, 02 Mar 2025 10:27:33 GMT</pubDate>
    </item>
    <item>
      <title>Nesterov在极端学习机器中加速梯度下降，而高正规化</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1nu4c/nesterov_accelerated_gradient_descent_stalling/</link>
      <description><![CDATA[    我正在用一个隐藏层实现Nesterov加速梯度下降（NAG）。我的损耗函数是带有L2正则化的平均平方错误（MSE）。 梯度I计算是：   其中：  w2是参数矩阵，h是隐藏层激活矩阵（固定在榆树中），d是目标输出，λ是正规化参数。 如果我们选择一个固定的步骤，则依赖于convexity alpha的强度和函数的效果，而理论依赖于convexity alpha的强度，则该理论是在理论上的最佳降低。在Bubeck 2015的以下等式中显示：   其中k是函数的条件数。 问题： 如果我选择高lambda（等于或高于1），则该理论预测收敛速度更快，因为函数的条件数较低。这正是我从实验中观察到的。但是，尽管我的算法很快达到了不错的差距，但即使该理论预测单调减少，它也会失速。这是典型学习曲线的一个示例（在橙色的最坏情况差距中，蓝色算法）。   我的问题：如何调和这样的事实，即理论预测趋同的束缚，而我的算法由于较小的梯度而被卡住了？这个问题是高λ制度中L2正则化固有的，还是我的实施特定的？任何见解，数学解释或实用建议都将不胜感激！ 事先感谢您的帮助！ 注意：这与我选择的问题，隐藏的层大小和激活功能无关。     &lt;！ -  sc_on-&gt;＆&gt; 32;提交由＆＃32; /u/u/paulmil     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1nu4c/nesterov_accelerated_gradient_descent_stalling/</guid>
      <pubDate>Sun, 02 Mar 2025 10:20:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么要softmax引起注意？为什么只有一个标记对只有一个标量？ 2来自好奇初学者的问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1nq6r/why_softmax_for_attention_why_just_one_scalar_per/</link>
      <description><![CDATA[Hi, I just watched 3Blue1Brown’s transformer series, and I have a couple of questions that are bugging me and chatgpt couldn&#39;t help me :(  Why does attention use softmax instead of something like sigmoid? It seems like words should have their own independent importance rather than competing in a probability distribution. Wouldn&#39;t sigmoid allow for a更重要的是，更重要的是    为什么查询和钥匙只能计算出一个象征性对的单个标量，因为两个令牌并不是一个含义  [link]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1nq6r/1j1nq6r/why_softmax_for_terention_why_just_just_one_one_scalar_scalar_scalar_per/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1nq6r/why_softmax_for_attention_why_just_one_scalar_per/</guid>
      <pubDate>Sun, 02 Mar 2025 10:12:09 GMT</pubDate>
    </item>
    <item>
      <title>实验reddit +小LLM</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1n6jj/experiment_reddit_small_llm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想测试是否可以可靠地使用小型模型过滤内容。这个想法是要多次阅读文本，一次过滤几件事。 要测试它，我制作了一个reddit帐户 u/osoconfesoso007 ，该 efters of atory the the the the per per pp&gt;有趣的故事。我想测试过滤器是否可靠，因此请随时戳它。 它是开源的： github        &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/raul3820     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1n6jj/experiment_reddit_small_llm/</guid>
      <pubDate>Sun, 02 Mar 2025 09:33:21 GMT</pubDate>
    </item>
    <item>
      <title>我还需要学习什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1m6tl/what_else_do_i_need_to_learn/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;  嗨，我想成为AI工程师，这是我的简历。这不是一个好的，但我需要您的帮助，对我可以学习或做什么。我知道这些项目是非常初学者的级别，但我才刚刚开始。请就我如何改进的建议提出建议？另外，如果您可以指导我有关我需要做的ETHE类型的项目，那也会有所帮助。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/iamnazzal      [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1m6tl/what_else_do_i_need_to_learn/</guid>
      <pubDate>Sun, 02 Mar 2025 08:21:15 GMT</pubDate>
    </item>
    <item>
      <title>AI工程师路线图2025！ （没人告诉你！）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1lcn2/ai_engineer_roadmap_2025_what_no_one_is_telling/</link>
      <description><![CDATA[       &lt;！&lt;！ -  sc_off-&gt;  大多数AI路线图都错了。他们假设他们知道您要走的AI路径。但是我在这里告诉你，有多种方法可以做到。我分析了一些最受欢迎的AI路线图，并提出了一个3路径框架，以帮助您立即开始！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kevinwoodrobotics      &lt;a href =“ https://www.reddit.com/r/lealelnmachinelearning/comments/1j1lcn2/ai_engineer_engineer_ovedmap_2025_what_no_no_no_one_ise_is_telling/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1lcn2/ai_engineer_roadmap_2025_what_no_one_is_telling/</guid>
      <pubDate>Sun, 02 Mar 2025 07:22:11 GMT</pubDate>
    </item>
    <item>
      <title>我的数据集大小过于杀伤吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1jm7v/is_my_dataset_size_overkill/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试使用u-net对CT扫描数据进行医学图像分割。数据集约为400 CT扫描，切成2D图像并进一步增强。最后，我们获得了带有相应的斑点标签的400000 2D切片。这个尺寸的过度杀伤是训练U-NET的？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1jm7v/is_my_my_my_my_my_my_my_size_size_overkill/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1jm7v/is_my_dataset_size_overkill/</guid>
      <pubDate>Sun, 02 Mar 2025 05:27:48 GMT</pubDate>
    </item>
    <item>
      <title>ML数学概念视频的反馈</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1jeqg/feedback_for_ml_math_concept_videos/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我开始制作YouTube视频，在此解释机器学习的数学基础！我这样做是因为我喜欢教学，并且想帮助其他人了解一开始似乎很难进入的数学概念。  我仍然是初学者，所以这就是为什么我会感谢视频的任何建设性反馈！ 这是信息和熵的一个：   https://youtu.be/cq8twnlzwbk?si = 2oiai = 2oai = 2oai = 2oaiwi3v0dcox9jr roferition函数：   https://youtu.be/youtu.be/fecke5dyhgs？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tozlow4u     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1jeqg/feedback_for_ml_math_concept_videos/</guid>
      <pubDate>Sun, 02 Mar 2025 05:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[YouTube讲座摘要] Andrej Karpathy-深入研究LLM</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1g59r/youtube_lecture_summary_andrej_karpathy_deep_dive/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于那些没有时间观看讲座或想在钥匙外卖上加快速度的人，我已经为您概括了。   https://www.tidybook.app/392011cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-cd-c320-4b61-8361-8383836-66,66888888888888.AN.6666666666.AP   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/igmyung     [links]   &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j1g59r/youtube_lecture_lecture_summary_andrej_karpathy_karpathy_deep_deep_deep_dive/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1g59r/youtube_lecture_summary_andrej_karpathy_deep_dive/</guid>
      <pubDate>Sun, 02 Mar 2025 02:11:14 GMT</pubDate>
    </item>
    <item>
      <title>我敢打赌，这份工作不存在3年前。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j0rj20/i_bet_this_job_didnt_exist_3_years_ago/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/wordybug     &lt;a href =“ https://www.reddit.com/r/lealelnmachinelearning/comments/1j0rj20/i_bet_this_this_job_job_job_job_didnt_exist_exist_3_years_ago/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j0rj20/i_bet_this_job_didnt_exist_3_years_ago/</guid>
      <pubDate>Sat, 01 Mar 2025 04:45:11 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·恩（Andrew Ng）的深度学习很无聊</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j0pxse/deep_learning_by_andrew_ng_got_boring/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在做DL专业化，但我有点无聊的IDK为什么，实验室很无聊，即使讲座很好，我也不喜欢这样做。我决定观看Andrej Karpathy的视频，然后 fast.ai  如果您有任何建议，请lmk。提交由＆＃32; /u/u/u/willly_reppect9259     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j0pxse/deep_learning_by_andrew_ng_got_boring/</guid>
      <pubDate>Sat, 01 Mar 2025 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到这里   对于那些正在寻找简历评论的人，请在 href =“ href =“ https://www.reddit.com/r/resumes”&gt;/r/简历或 r/EngineeringResumes 首先，然后在此处交叉crosspost。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>