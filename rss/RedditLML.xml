<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 10 May 2024 09:15:00 GMT</lastBuildDate>
    <item>
      <title>具有分层随机森林的分层 K-Fold CV</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cokjtb/stratified_kfold_cv_with_stratified_random_forest/</link>
      <description><![CDATA[大家好，我现在正在使用 R 处理一个不平衡的数据集，其中大多数类占 75%。我计划使用分层 10 倍 CV，并为每个折叠运行分层随机森林。  1）我的方法有意义吗？2）我是否只为分层随机森林设置strata=df$Response？我需要调整 sampsize 参数吗？  谢谢！    由   提交 /u/CardiographerLiving51   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cokjtb/stratified_kfold_cv_with_stratified_random_forest/</guid>
      <pubDate>Fri, 10 May 2024 08:25:30 GMT</pubDate>
    </item>
    <item>
      <title>其他人永远无法真正理解图像生成吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cokegt/anyone_else_can_never_truly_understand_image/</link>
      <description><![CDATA[我从未见过像生成式人工智能这样令人难以置信的科学概念。 就像我理解（大量）它背后的数学一样，但是视觉结果太引人注目了。    提交人    /u/blablablabling   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cokegt/anyone_else_can_never_truly_understand_image/</guid>
      <pubDate>Fri, 10 May 2024 08:14:42 GMT</pubDate>
    </item>
    <item>
      <title>通过行车记录仪驾驶时进行困倦检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1coj842/sleepy_detection_while_driving_via_dashcam/</link>
      <description><![CDATA[我需要有关此项目想法的帮助。我对此很陌生，任何类型的信息都会有帮助，我想开发一个模型，通过行车记录仪实时反馈检测驾驶员是否昏昏欲睡。 我该如何解决这个问题，我应该如何接近它，是否有更好和最差的方法来做到或避免。任何类型的信息都会非常有帮助。谢谢:)   由   提交/u/ahar_AIM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1coj842/sleepy_detection_while_driving_via_dashcam/</guid>
      <pubDate>Fri, 10 May 2024 06:51:02 GMT</pubDate>
    </item>
    <item>
      <title>曼巴玩具示例</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1coig9j/mamba_toy_examples/</link>
      <description><![CDATA[我现在已经尝试使用（非预训练的）Mamba 模型一段时间了，但似乎无法让它工作。代码运行后，损失（MSE；由 ASGD 优化）在训练数据上下降到我想要的水平（是的，过度拟合，但目前还好），但它似乎从未学习过实际任务。 例如，我尝试生成各种分布中的输入，在所有情况下正确的标签都是 1.0。应该是一项简单的任务，因为它可以通过具有 1 个参数的“模型”来完成。并且，如上所述，我得到了非常好的低损失值，但运行实际张量得到的值根本不接近 1.0 任何关于潜在修复的想法或可行的玩具示例都将不胜感激。   由    /u/Rhoderick  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1coig9j/mamba_toy_examples/</guid>
      <pubDate>Fri, 10 May 2024 05:58:28 GMT</pubDate>
    </item>
    <item>
      <title>YOLO v8 中的帧检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cohi0z/frame_detection_in_yolo_v8/</link>
      <description><![CDATA[1) 我正在运行 YOLOv8 模型 2) 该模型用于对象检测，我的代码使用了其中 2 个：一个通用版本用于检测车辆，另一个专门经过预训练以检测车牌 3) 我遇到的问题是关于帧号的输出似乎会永远持续下去，如果我对其设置上限，它还不能准确检测到车牌，它应该将输出保存在按帧号序列化的 csv 文件中，但它没有这样做 4) 我不确定整个帧速率以及这是否是问题所在    提交人    /u/varun-saha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cohi0z/frame_detection_in_yolo_v8/</guid>
      <pubDate>Fri, 10 May 2024 04:57:03 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，预测时必须满足“无多重共线性”假设？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1coh5u0/in_linear_regression_no_multicollinearity/</link>
      <description><![CDATA[我在某处了解到，当我们进行预测时，假设没有任何意义，但对于推理来说，它很重要......就像当 chatgpt 时我感到困惑一样和其他消息来源说不同...    由   提交 /u/Assalamwhileicum   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1coh5u0/in_linear_regression_no_multicollinearity/</guid>
      <pubDate>Fri, 10 May 2024 04:36:14 GMT</pubDate>
    </item>
    <item>
      <title>您如何找到适合您的研究论文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cogs39/how_do_you_find_the_research_papers_right_for_you/</link>
      <description><![CDATA[所以我是机器学习的初学者，我观察到很多人在阅读研究论文。他们为什么这么做？他们如何找到适合他们的论文（从某种意义上说，有很多论文适合他们）？读完论文后会发生什么？ ~凯   由   提交 /u/Weak_Display1131   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cogs39/how_do_you_find_the_research_papers_right_for_you/</guid>
      <pubDate>Fri, 10 May 2024 04:13:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 的混合网络简介</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/</link>
      <description><![CDATA[使用 PyTorch 的混合网络简介 https://debuggercafe.com/introduction-to-hybridnets-using-pytorch/   由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/</guid>
      <pubDate>Fri, 10 May 2024 00:37:36 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士/自然语言处理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/</link>
      <description><![CDATA[大家好，  我正在尝试为我的工作学习 nlp/llm 技术。我在不同的领域（物理学），想学习使用 NLP/LLM 模型来实现这些目标。我不太清楚如何去学习这些。当我查阅传统的 NLP 课程时，大多数都是处理词袋、vec2vec 等。但是 Transformer 的引入是否让这些传统方法变得过时了呢？我该如何学习这些？谁能为我提供学习此内容所需遵循的路径指南？归根结底，我想构建一个类似 BERT 的模型来用于预测。如果问题听起来含糊不清，我深表歉意。    由   提交/u/No-Mud4063  /u/No-Mud4063 reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/</guid>
      <pubDate>Fri, 10 May 2024 00:26:40 GMT</pubDate>
    </item>
    <item>
      <title>未毕业指南：柯尔莫哥洛夫-阿诺德网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co9xha/didnt_graduate_guide_to_kolmogorovarnold_networks/</link>
      <description><![CDATA[       由   提交 /u/import_torch-nn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co9xha/didnt_graduate_guide_to_kolmogorovarnold_networks/</guid>
      <pubDate>Thu, 09 May 2024 22:28:27 GMT</pubDate>
    </item>
    <item>
      <title>JSTOR 被发现缺乏</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</link>
      <description><![CDATA[       由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</guid>
      <pubDate>Thu, 09 May 2024 21:28:28 GMT</pubDate>
    </item>
    <item>
      <title>了解变形金刚中的注意力机制：5 分钟的视觉指南。 🧠</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co37tn/understanding_the_attention_mechanism_in/</link>
      <description><![CDATA[      TL;DR：注意力是“可以学习的” ”，键值存储或字典的“模糊”版本。由于主要针对 NLP 和 LLM 改进了序列建模，Transformers 使用注意力并接管了以前的架构 (RNN)。 什么是注意力以及为什么它接管了法学硕士和机器学习：视觉指南   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co37tn/understanding_the_attention_mechanism_in/</guid>
      <pubDate>Thu, 09 May 2024 17:46:47 GMT</pubDate>
    </item>
    <item>
      <title>最大的小丑奖颁发给：</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cntx3p/the_biggest_clown_award_goes_to/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/yphase  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cntx3p/the_biggest_clown_award_goes_to/</guid>
      <pubDate>Thu, 09 May 2024 10:26:36 GMT</pubDate>
    </item>
    <item>
      <title>我觉得这需要出现在机器学习教科书的封面上</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cnp4vj/i_feel_like_this_needs_to_be_on_the_cover_of_an/</link>
      <description><![CDATA[       由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cnp4vj/i_feel_like_this_needs_to_be_on_the_cover_of_an/</guid>
      <pubDate>Thu, 09 May 2024 04:57:01 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人对人工智能中所有不同类型的数学感到不知所措吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cn97az/does_anyone_else_get_overwhelmed_by_all_the/</link>
      <description><![CDATA[      由于如此多的数学分支融合在一起，似乎没有人能够真正掌握人工智能。即使是数学家也几乎不可能掌握这个主题。我曾与一些人交谈过，他们不知道我在说什么。此外，该领域的发展速度极快 混合线性代数和随机微分方程是魔鬼的工作。    提交人    /u/blablablabling   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cn97az/does_anyone_else_get_overwhelmed_by_all_the/</guid>
      <pubDate>Wed, 08 May 2024 16:43:51 GMT</pubDate>
    </item>
    </channel>
</rss>