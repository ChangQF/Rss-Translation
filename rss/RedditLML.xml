<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 28 Jun 2024 09:15:39 GMT</lastBuildDate>
    <item>
      <title>时间序列预测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqf289/time_series_forecasting/</link>
      <description><![CDATA[大家好，我是一名 dotnet 开发人员，刚刚开始使用 Python 进行机器学习。 我正在尝试一些天气预报的东西，想知道是否可以使用不同的数据集来训练模型（不同位置）。我不太清楚，例如均值和方差的变化是否会对优化模型不利，或者这是数据规范化/预处理发挥作用的地方？ 另一个问题是，我是否应该将特征列表（风速、压力……）保持在较小水平，还是特征越多越好？我明白，如果添加更多特征，还应该添加更多数据来训练模型，所以这就是我的第一个问题，我是否可以添加来自不同位置的数据。 提前致谢！    提交人    /u/MundaneCoach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqf289/time_series_forecasting/</guid>
      <pubDate>Fri, 28 Jun 2024 08:51:27 GMT</pubDate>
    </item>
    <item>
      <title>关于知识提炼的几个问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqedrt/a_couple_questions_about_knowledge_distillation/</link>
      <description><![CDATA[您能否为我提供任何见解，说明为什么这种技术如此有效/有哪些论文讨论过这个问题？我认为这与原始模型中的梯度景观更加危险和粗糙有关，但随后较新的较小模型可以走捷径，本质上是从较大模型的错误中学习（更像是绕过）。 关于提炼的大小限制是否有经验法则？显然它不会无限期地起作用，即您（大概）不能将 70B 模型提炼成 1B（并期望获得良好的结果），但与此相关的实际数字/比率是多少？如果您尝试提炼成不合理的小模型会发生什么？输出会发生什么？ 这主要针对 LLM 提炼，但如果有任何应用，我也不介意听听除此之外的应用。   由    /u/OblivionPhase  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqedrt/a_couple_questions_about_knowledge_distillation/</guid>
      <pubDate>Fri, 28 Jun 2024 08:01:15 GMT</pubDate>
    </item>
    <item>
      <title>我们是如何在 ARC-AGI 挑战赛中从 34% 突然提高到 50% 的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqe9wl/how_did_we_suddenly_reached_from_34_to_50_on/</link>
      <description><![CDATA[用于解决 ARC 的 GPT-4o 这个解决方案背后的主要思想非常简单。 使用 GPT-4o 生成大约 8,000 个尝试实现转换的 Python 程序，选择一个对所有示例都正确的程序（通常有 3 个示例），然后提交此函数应用于其他测试输入时产生的输出。将问题显示为图像和各种 ASCII 表示形式。 这种方法在精神上类似于 AlphaCode 中应用的方法，其中模型生成数百万个完成以尝试解决编程问题，然后对它们进行聚合以确定要提交的内容。  全文： https://medium.com/aiguys/llm-based-agi-50-on-the-arc-agi-273014247cf2  让我们看看 ARC-AGI细节。  向 GPT-4o 提供 ARC-AGI 问题，同时为问题中的每个网格提供图像表示和各种文本表示。文本表示包括显示哪些单元格被不同颜色的连接组件占据，并显示输入和输出之间的差异（在网格形状相同的情况下）。只将原始图像提供给 GPT-4o 根本行不通。 指导 GPT-4o 推理什么是转换，推理如何将转换实现为代码，然后最终在代码中实际实现转换。 使用几个精心手写的分步推理示例的少量提示，让 GPT-4o 能够有效地进行这种推理。生成的提示通常大约有 30k 个 token（包括图像）。   使用一对小样本提示：一个提示用于网格大小发生变化时（在任何示例中），另一个提示用于网格大小不变时。   从 GPT-4o 中抽取大量完成（每个问题约 5,000 个）。 为每个问题选取最有希望的 12 个完成，然后尝试通过向 GPT-4o 展示该程序在示例上的实际输出来修复每个问题，然后要求 GPT-4o 修改代码以使其正确。  他们在 12 个起始实现中总共抽样了约 3,000 个尝试修复每个问题的完成。  使用小样本提示进行逐步推理的修订。 显示实际输出和预期输出之间差异的文本表示。   最后，根据对正确示例的程序的多数投票，选择 3 个提交。 （如果我们没有 3 个不同的正确示例的程序提交，我们会应用一些启发式方法来选择提交）。   AIGuys 月度新闻简报： https://medium.com/aiguys/newsletter     提交人    /u/Difficult-Race-1188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqe9wl/how_did_we_suddenly_reached_from_34_to_50_on/</guid>
      <pubDate>Fri, 28 Jun 2024 07:53:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 SOTA 模型的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqe8x4/what_is_the_the_best_approach_to_use_sota_models/</link>
      <description><![CDATA[我正在构建一个计算机视觉多类分类模型，试图在 food101 数据集上获得最佳准确率。 我发现了一篇 Google 的研究文章，该文章在数据集上的准确率为 96%，我想在我的 jupyter 笔记本中实现他们的算法。在本文中，他们提出了一个优化器，可以改善学习过程和模型的泛化能力。 他们在 Github 上发布的代码不包含“food101”的训练配置，所以我需要对其进行修改，而要做到这一点，我需要了解他们如何在代码中加载数据集（ImageNet、Cifar、SVHN……）。 但是： 这是尝试使用 SOTA 模型时的正确方法吗？浏览发布者的源代码并根据自己的需要进行定制？ 或者： 我应该了解他们开发的优化器的概念，然后在我的笔记本中自己实现优化器吗？ 附注：在他们发布的源代码中，他们使用“tfds”下载数据集，而我无法使用它，因为我没有稳定的互联网连接。因此，我认为定制他们的源代码需要修改大量源代码，并添加更多代码以使用他们的方法加载“food101”。  无论如何，我对任何方法都没有问题。但我想知道专业的方法，以及当我在简历中提到该项目时听起来更好的方法。 谢谢。    提交人    /u/Esmaeel_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqe8x4/what_is_the_the_best_approach_to_use_sota_models/</guid>
      <pubDate>Fri, 28 Jun 2024 07:51:29 GMT</pubDate>
    </item>
    <item>
      <title>对话式人工智能的主导地位之争——用户排名</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqe587/the_race_to_dominate_conversational_ai_user/</link>
      <description><![CDATA[       由    /u/Top_Communication238  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqe587/the_race_to_dominate_conversational_ai_user/</guid>
      <pubDate>Fri, 28 Jun 2024 07:44:23 GMT</pubDate>
    </item>
    <item>
      <title>[播客] 机器学习和概率模型自动优化 Postgres 性能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqe54d/podcast_machine_learning_and_probabilistic_models/</link>
      <description><![CDATA[在本周的节目中，我有机会与 DBtune 的 Luigi Nardi 讨论如何将机器学习和概率模型应用于 PostgreSQL 配置。了解到最小信号足以对如何更改 Postgres 配置（一点一点）以优化性能做出有根据的猜测，这非常有趣。 我要感谢 Luigi 做客这个节目，也感谢它对其他人的帮助和兴趣。 https://youtu.be/lkquofjg9zo    提交人    /u/noctarius2k   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqe54d/podcast_machine_learning_and_probabilistic_models/</guid>
      <pubDate>Fri, 28 Jun 2024 07:44:10 GMT</pubDate>
    </item>
    <item>
      <title>解释人工智能和数据科学行业中的不同工作角色</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqdzt8/different_job_roles_in_ai_and_data_science/</link>
      <description><![CDATA[AIQ 第 3 集解释了数据科学和人工智能行业中的不同工作角色，回答了以下问题： 1. 人工智能工作行业中有哪些不同角色？ 2. 它们彼此有何不同？ 3. 新手应该在人工智能行业选择哪些角色？ 4. 相对容易的工作角色 5. 你可以从一个工作角色切换到另一个工作角色吗？ ... 以及许多其他疑问 https://youtu.be/WAIkJrOE8GE?si=Gd3tb1HGHT8SNZzv    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqdzt8/different_job_roles_in_ai_and_data_science/</guid>
      <pubDate>Fri, 28 Jun 2024 07:33:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习失败</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqd0te/failing_machine_learning/</link>
      <description><![CDATA[所以我在大学里第二次没通过机器学习考试。我通过看所有的讲座、理解它们并为所有主题做笔记来准备考试。 在我的大学里，我们有大约 27 个问题，每个主题大约有 1-2 个问题。所以我花时间试图理解每个主题，但我仍然不断失败。似乎我的方法很糟糕，因为每当我做题时，我都不知道答案。 我们的问题涉及诸如 PCA、决策树、过度拟合 - 交叉验证、性能评估、贝叶斯和朴素贝叶斯、关联挖掘等主题。 我确实有所有主题的笔记。 我能做些什么来准备这次考试呢？这都是手工的，但我们也可以用代码来计算一些练习。    提交人    /u/Virtual_Turn1728   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqd0te/failing_machine_learning/</guid>
      <pubDate>Fri, 28 Jun 2024 06:25:59 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 10 门最佳高级机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqclj4/10_best_advanced_machine_learning_courses_in_2024/</link>
      <description><![CDATA[您是否在寻找最佳高级机器学习课程？ 如果是，那么本文适合您。 在本文中，您将找到10 个最佳高级机器学习课程。 祝你好运！    提交人    /u/Some-Patient-7191   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqclj4/10_best_advanced_machine_learning_courses_in_2024/</guid>
      <pubDate>Fri, 28 Jun 2024 05:58:39 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊 ML 2024 年夏季</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqceja/amazon_ml_summer_2024/</link>
      <description><![CDATA[有人收到选拔邮件了吗？     提交人    /u/Time_Max22   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqceja/amazon_ml_summer_2024/</guid>
      <pubDate>Fri, 28 Jun 2024 05:46:15 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的未来：2030 年和 2050 年的预测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dqbip1/the_future_of_large_language_models_predictions/</link>
      <description><![CDATA[        由    /u/Redvelvet21xo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dqbip1/the_future_of_large_language_models_predictions/</guid>
      <pubDate>Fri, 28 Jun 2024 04:51:38 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么作者在这里平铺/复制数据以增加训练集大小并减少训练周期数吗？我不明白这背后的直觉。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dq9wn9/can_someone_explain_why_here_the_author_is/</link>
      <description><![CDATA[      Xt = np.tile(Xn,(1000,1)) Yt= np.tile(Y,(1000,1))  print(Xt.shape, Yt.shape)  此外，如果有人可以解释以下陈述： &quot; 为了进行下一次讨论，您将首先设置我们从之前的训练运行中保存的一些权重，而不是使用您立即获得的权重。这样，这个笔记本就可以随着时间的推移保持对 Tensorflow 变化的稳健性。不同的训练运行可能会产生略有不同的结果，并且当模型具有您将在下面加载的权重时，以下讨论适用。 &quot; 以及下图中的声明和图表： https://preview.redd.it/xq75ilcsd89d1.png?width=1238&amp;format=png&amp;auto=webp&amp;s=f39c10d6ae2838a21b7cfc4c63558b7a09f9b54a 附言：我正在 Coursera 上学习 Andrew NG 的课程。     由    /u/abxd_69 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dq9wn9/can_someone_explain_why_here_the_author_is/</guid>
      <pubDate>Fri, 28 Jun 2024 03:22:02 GMT</pubDate>
    </item>
    <item>
      <title>每次经历一个时期后，我的损失都会大幅下降。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</link>
      <description><![CDATA[      大家好， 我正在使用 IMDB 数据集对分类任务上的 DistilBERT 模型进行微调。然而，在每个 epoch 之后，我的损失会变得非常低，然后再次开始上升到一个值，并在整个 epoch 中保持这个值。这种行为会重复发生。 我创建了一个 Trainer 类，一个 epoch 的训练循环按以下方式处理： def _train_one_epoch(self, model, trainloader, testloader): &quot;&quot;&quot;训练一个 epoch 的模型。&quot;&quot;&quot; model.train() training_loss = 0.0accumulated_loss = 0.0 total_steps = len(trainloader) // self.gradient_accumulation_steps with tqdm(total=total_steps) as pbar: for i, data in enumerate(trainloader): # 将数据移动到设备 if isinstance(data, list): data = [item.to(self.device) for item in data] elif isinstance(data, dict): data = {key: value.to(self.device) for key, value in data.items()} else: data = data.to(self.device) # 使用 autocast(enabled=self.use_mixed_precision, dtype=torch.float16) 进行前向传递： output = model.train_step(data) loss = output[0] if isinstance(output, tuple) else output loss /= self.gradient_accumulation_steps # 后向传递 if self.use_mixed_precision: self.scaler.scale(loss).backward() else: loss.backward() accumulation_loss += loss.item() * self.gradient_accumulation_steps total_norm = 0.0 for param in model.parameters(): param_norm = param.grad.detach().data.norm(2) total_norm += param_norm.item() ** 2 total_norm = total_norm ** (1. / 2) self._log_metrics({&quot;Total Gradient Norm&quot;: total_norm}) # 更新权重 if (i + 1) % self.gradient_accumulation_steps == 0: if self.use_mixed_precision: self.scaler.unscale_(self.optimizer) if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.scaler.step(self.optimizer) self.scaler.update() else: if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.optimizer.step() self.optimizer.zero_grad() pbar.update(1) if self.scheduler: self.scheduler.step() if self.log: self._log_metrics({&quot;Training Loss&quot;: accumlidar_loss / (i + 1), &quot;Learning Rate&quot;: self.optimizer.param_groups[0][&#39;lr&#39;]}) pbar.set_postfix({&#39;Training Loss&#39;: accumlidar_loss / (i + 1)}) training_loss = accumlidar / len(trainloader) self.optimizer.zero_grad() return training_loss  这种行为每次都会发生，与学习率无关（我也使用调度）。它也发生在诸如问答或对不同数据集（例如 Hyperpartisan）进行分类等任务上。您还可以在 WikihopQA 上训练 QA 任务时看到损失行为。 https://preview.redd.it/zypdq1gzi59d1.png?width=2528&amp;format=png&amp;auto=webp&amp;s=a02d0d67cb4ae2321a364104537ecb981e92e910    提交人    /u/BossBigSword   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</guid>
      <pubDate>Thu, 27 Jun 2024 17:44:47 GMT</pubDate>
    </item>
    <item>
      <title>从 32 开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</link>
      <description><![CDATA[大家好，我从事 IT 和网络安全工作已有几年了，似乎这个行业不再适合我了，我拥有网络安全理学学士学位，我想看看我是否能够转型。如果需要，我愿意回到学校通过 Coursera 获得硕士学位    提交人    /u/_Darth_Necro_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</guid>
      <pubDate>Thu, 27 Jun 2024 16:14:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>