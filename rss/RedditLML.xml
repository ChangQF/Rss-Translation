<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 25 Aug 2024 06:20:19 GMT</lastBuildDate>
    <item>
      <title>人工智能硕士学位，最好是NLP</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0pg20/master_degree_in_ai_preferably_nlp/</link>
      <description><![CDATA[我将于 2025 年完成我的学士学位，如果您能告诉我在德国、意大利或任何欧盟国家应该选择哪些课程，我将不胜感激，我来自埃及。    提交人    /u/antagonist78   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0pg20/master_degree_in_ai_preferably_nlp/</guid>
      <pubDate>Sun, 25 Aug 2024 05:48:50 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 如何处理大于上下文大小的大型文档？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0nr82/how_does_chatgpt_handle_big_documents_larger_than/</link>
      <description><![CDATA[您好， 与大多数 LLM 一样，GPT4/4o 的上下文大小有限。 然而，ChatGPT 可以读取和分析 PDF 等大型文档，并且仍然返回有用的信息。 这在后台是如何处理的？ 它是以块的形式总结的吗？ 我很想用 API 做同样的事情，但它似乎没有那个功能。 谢谢！    提交人    /u/citra-ceth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0nr82/how_does_chatgpt_handle_big_documents_larger_than/</guid>
      <pubDate>Sun, 25 Aug 2024 04:01:49 GMT</pubDate>
    </item>
    <item>
      <title>将模型从单 GPU 扩展到多 GPU？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0kq21/scaling_models_from_single_to_multigpu/</link>
      <description><![CDATA[我正在 Replicate 上玩一些模型，它在 A100 GPU 上运行。如果我在具有 4xA100 GPU 的 EC2 上的 AWS 上部署这些模型，性能是否会提高 4 倍？ 或者，在扩大 GPU 资源以进行模型推理时，是否存在收益递减点？    提交人    /u/allyman13   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0kq21/scaling_models_from_single_to_multigpu/</guid>
      <pubDate>Sun, 25 Aug 2024 01:13:12 GMT</pubDate>
    </item>
    <item>
      <title>5 分钟内掌握 LangChain | 初学者快速指南</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0ig9h/langchain_in_under_5_min_a_quick_guide_for/</link>
      <description><![CDATA[       由    /u/bravehub  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0ig9h/langchain_in_under_5_min_a_quick_guide_for/</guid>
      <pubDate>Sat, 24 Aug 2024 23:17:54 GMT</pubDate>
    </item>
    <item>
      <title>有没有能够很好地描述实验室化学的法学硕士？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0gmbk/are_there_any_llms_who_are_decent_at_describing/</link>
      <description><![CDATA[我最近发现 Microsoft Copilot 和 ChatGPT-4o 在描述涉及实验室化学的程序时非常糟糕。即使给出了替代反应的完整化学方程式（例如），它们也非常糟糕。我可以继续写几段长篇大论来描述它们有多糟糕，但请读者暂时相信我。  有没有专门接受过无机化学实验室程序培训的法学硕士？  谢谢。    提交人    /u/moschles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0gmbk/are_there_any_llms_who_are_decent_at_describing/</guid>
      <pubDate>Sat, 24 Aug 2024 21:51:59 GMT</pubDate>
    </item>
    <item>
      <title>需要有关使用 NLP 和 GenAI 实现客户服务自动化的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0ghfu/advice_needed_on_automating_customer_service_with/</link>
      <description><![CDATA[我目前正在开展一个项目，旨在使用 NLP 和生成式 AI 实现客户服务响应的自动化。我有一个数据集，其中记录了客户查询及其相应的人工答案。我的目标是开发一个可以处理这些查询并提供自动响应的聊天机器人。 我面临的挑战是客户查询具有高度动态性。例如，客户可能会在问题中包含他们的帐号，而聊天机器人需要根据帐户状态进行理解和响应。目前，人工代理提供答案，我需要通过自动化复制此功能。 我正在考虑使用 Rasa 之类的框架，但我知道它们需要手动提取槽、意图和其他参数。有没有一种有效的方法来识别常见的一般问题和答案，或者训练一个可以处理此类动态查询的模型？我愿意使用任何合适的 NLP 技术或生成式 AI 方法。 您能否提供指导或建议有助于有效自动化此过程的方法或工具？ 如能得到任何指导或建议，我们将不胜感激！    提交人    /u/SeekingRealAnswers   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0ghfu/advice_needed_on_automating_customer_service_with/</guid>
      <pubDate>Sat, 24 Aug 2024 21:45:49 GMT</pubDate>
    </item>
    <item>
      <title>生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0f9gg/ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[      我很高兴与大家分享我整理的一门课程：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 容器化您的应用程序并使用 Docker 进行部署  我很乐意收到您对本课程的反馈。这是免费访问的优惠券代码：FREETOLEARN。您的见解将帮助我改进和完善内容。如果您喜欢这门课程，我将不胜感激您留下评分，以便其他人也可以找到这门课程。谢谢，学习愉快！ https://preview.redd.it/535v63z1dokd1.png?width=1430&amp;format=png&amp;auto=webp&amp;s=92281855b42da6001d16fd2810a885a288617494    提交人    /u/5x12   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0f9gg/ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Sat, 24 Aug 2024 20:49:43 GMT</pubDate>
    </item>
    <item>
      <title>自定义损失函数帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0e0j3/custom_loss_function_help/</link>
      <description><![CDATA[我想要微调一个 llm (llama3.1)，它只返回基于给定文本的数字（想想情绪分析），并且想要定义我自己的自定义损失函数以在微调过程中使用。我担心默认损失函数会导致 llm 有偏差，返回训练数据集中提供的输出的平均值，我想知道自定义损失函数是否可以更好地惩罚 llm 返回远离训练示例的数值。这是可以做到的/会带来更好的最终结果吗？如果是这样，有没有关于我应该如何去做的建议？    提交人    /u/HardcoreFrog848   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0e0j3/custom_loss_function_help/</guid>
      <pubDate>Sat, 24 Aug 2024 19:53:32 GMT</pubDate>
    </item>
    <item>
      <title>如何让附近的孤独猫咪通过 Facetime 进行互动（开源）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0bzfl/how_to_get_facetimed_by_lonely_cats_in_your_area/</link>
      <description><![CDATA[        由    /u/DareFail 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0bzfl/how_to_get_facetimed_by_lonely_cats_in_your_area/</guid>
      <pubDate>Sat, 24 Aug 2024 18:23:14 GMT</pubDate>
    </item>
    <item>
      <title>一年的时间里可以学习多少 ML 和 DL？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f0arup/how_much_can_one_learn_ml_and_dl_in_a_span_of_a/</link>
      <description><![CDATA[  由    /u/BEE_LLO  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f0arup/how_much_can_one_learn_ml_and_dl_in_a_span_of_a/</guid>
      <pubDate>Sat, 24 Aug 2024 17:30:44 GMT</pubDate>
    </item>
    <item>
      <title>来自 Reddit 上的 learnmachinelearning 社区：从头开始构建 Gen Ai 模型：分享我的旅程并共同学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f06vws/from_the_learnmachinelearning_community_on_reddit/</link>
      <description><![CDATA[      基于上周的帖子 (这里），以下是我本周所做的事情： -&gt; 我构建了一个 Transformer 模型，并使用 VQ-VAE 中的 token 对其进行训练。下面的前 3 幅图像显示了初始生成，而接下来的 3 幅图像显示了较新的结果。-&gt; 我花了太多时间调整我的旧扩散模型（这里），以使用更少的参数对其进行优化。最后 3 幅图像是来自一些训练中的实验模型的样本-&gt; 我还实现了 CLIP、VQ-GAN 和 ESRGAN，但我还没有机会训练它们中的任何一个。 本周充满了学习和实验。例如，我注意到，当我减少 Transformer 模型的 top-k 采样参数时，图像的多样性会降低（事后看来，这是有道理的）。我还发现，从特定标记开始会产生具有某些特征的图像（例如粉红色头发）。哦，还有注意力机制？它们对扩散模型产生了巨大的影响。 下周，我计划使用从 Danbooru 抓取的数据来训练我的 CLIP 模型。我还希望完成我的条件和非条件扩散模型的训练，然后使用训练后的 CLIP 模型来调节我的 VQ-VAE 的扩散模型和 Transformer 模型。 如果您有兴趣跟随我的旅程并像我一样学习，您可以在 X 上关注我（这里），我会在那里分享我正在做的事情或实时体验。或者，如果您愿意，您可以定期检查我的 GitHub 以查看我的项目。     提交人    /u/Full-Bell-4323   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f06vws/from_the_learnmachinelearning_community_on_reddit/</guid>
      <pubDate>Sat, 24 Aug 2024 14:42:28 GMT</pubDate>
    </item>
    <item>
      <title>训练“在线” .py 训练文件的最佳方法。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f06jqw/best_way_to_train_online_py_training_files/</link>
      <description><![CDATA[大家好，这是第一篇帖子。 我最近开始训练 (PyTorch) 神经网络进行手势识别。我开始后一切都运行良好，但在某个时候我注意到我的笔记本电脑（虽然它并不坏）可能不是进一步调整网络的最佳/最快方式。 所以现在我想知道从现在开始该怎么做。我知道 kaggle 和 google co-labs 提供免费（但有限）的 CPU 资源。然而，我想知道这对我来说是否是一种可行的方法，因为我的所有代码都是用纯“.py”文件编写的，据我所知，kaggle 和 co-labs 大多使用 Jupyter 笔记本。 所以这里基本上是我的问题，例如，这是否正常？将我的文件上传到 kaggle，然后从笔记本中调用 train.py？（例如：!python3 &lt;path_to_file&gt;/train.py） 你们是怎么做到的？ 此致敬意 :)    提交人    /u/Strange-Detective-67   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f06jqw/best_way_to_train_online_py_training_files/</guid>
      <pubDate>Sat, 24 Aug 2024 14:27:20 GMT</pubDate>
    </item>
    <item>
      <title>从晶体管到 CPU - 计算机在硬件层面如何工作</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f056vu/from_transistor_to_cpu_how_computers_work_at_ha/</link>
      <description><![CDATA[      从晶体管到 CPU – 计算机的真正工作原理 在此播放列表中，您可以找到有关 CPU 工作原理的解释。CPU 是一个相当复杂和精密的组件，因此最好描述 CPU 的简单版本。在这里，我们分析了 Scott 的 CPU，它非常适合教育目的。我们将一步一步地一起构建一个 CPU。 https://youtube.com/playlist?list=PLnAxReCloSeTJc8ZGogzjtCtXl_eE6yzA 在这里您可以找到 Andrej Karpathy 对本系列的评论 https://x.com/karpathy/status/1818897688571920514    提交人    /u/SimplyExplained2022   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f056vu/from_transistor_to_cpu_how_computers_work_at_ha/</guid>
      <pubDate>Sat, 24 Aug 2024 13:23:43 GMT</pubDate>
    </item>
    <item>
      <title>如果 Python 这么慢，为什么它却是机器学习最广泛使用的语言？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1f03vqa/why_is_python_the_most_widely_used_language_for/</link>
      <description><![CDATA[考虑到训练机器学习模型需要大量时间和资源，为什么像 C++ 这样更快的编程语言在训练 ML 模型方面不那么受欢迎呢？    提交人    /u/Lastrevio   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1f03vqa/why_is_python_the_most_widely_used_language_for/</guid>
      <pubDate>Sat, 24 Aug 2024 12:16:39 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>