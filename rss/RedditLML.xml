<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 18 Oct 2024 12:32:06 GMT</lastBuildDate>
    <item>
      <title>人工智能和计算机视觉中的伦理问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6gwgt/ethics_in_artificial_intelligence_and_computer/</link>
      <description><![CDATA[  由    /u/Computer_Vision4883  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6gwgt/ethics_in_artificial_intelligence_and_computer/</guid>
      <pubDate>Fri, 18 Oct 2024 12:30:51 GMT</pubDate>
    </item>
    <item>
      <title>`tf.keras.metrics.R2Score()`: ValueError: 对于 dtype 为 float32 的 Tensor，Tensor 转换请求 dtype int32：<tf.Tensor: shape=(), dtype=float32, numpy=0.0></title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6g28w/tfkerasmetricsr2score_valueerror_tensor/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6g28w/tfkerasmetricsr2score_valueerror_tensor/</guid>
      <pubDate>Fri, 18 Oct 2024 11:44:46 GMT</pubDate>
    </item>
    <item>
      <title>决策树的计算复杂性⌛：了解决策树在输入大小增加时的表现。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6fwdz/computational_complexity_of_decision_trees_learn/</link>
      <description><![CDATA[      https://preview.redd.it/i8l2fibx3ivd1.png?width=900&amp;format=png&amp;auto=webp&amp;s=bcde0246193635a2bd8990abbcd3f0704bd73595    提交人    /u/Amitchejara   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6fwdz/computational_complexity_of_decision_trees_learn/</guid>
      <pubDate>Fri, 18 Oct 2024 11:35:18 GMT</pubDate>
    </item>
    <item>
      <title>衡量自信心和缓解法学硕士幻觉的技巧</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6fhxe/tips_to_measure_confidence_and_mitigate_llm/</link>
      <description><![CDATA[我需要更多地了解我正在构建的工具的幻觉。因此，我在此过程中写了一些笔记 -  https://nanonets.com/blog/how-to-tell-if-your-llm-is-hallucinating/ TL;DR:  要测量幻觉，请尝试这些 -   在简单情况下使用 ROGUE、BLEU 将生成与基本事实进行比较 从相同（略有不同）的问题生成多个答案并检查一致性 在生成的实体之间创建关系并验证关系是否正确 尽可能使用自然语言蕴涵 使用 SAR 指标（将注意力转移到相关性上） 使用辅助 LLM 评估答案  要减少大型语言模型 (LLM) 中的幻觉，请尝试以下方法 -   向 LLM 提供可能的选项以减少幻觉 为 LLM 输出创建置信度分数以识别潜在幻觉 要求 LLM 提供归因、推理步骤和可能的选项以鼓励基于事实的回应 利用检索增强生成 (RAG) 系统来提高上下文准确性  训练技巧 -   过度的教师强迫会增加幻觉 训练期间较少的 T 将减少幻觉 微调特殊的 I-KNOW 代币     由    /u/CoffeeSmoker 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6fhxe/tips_to_measure_confidence_and_mitigate_llm/</guid>
      <pubDate>Fri, 18 Oct 2024 11:11:00 GMT</pubDate>
    </item>
    <item>
      <title>SciML 博士学位：无需正式背景即可掌握物理学——帮助我填补空白！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6f8ql/phd_in_sciml_mastering_physics_without_a_formal/</link>
      <description><![CDATA[大家好， 我最近获得了科学机器学习博士学位，我将使用机器学习技术解决 PDE（偏微分方程）。我的背景是应用数学（硕士学位）和统计学（学士学位），所以我在数学方面很扎实（PDE、ML 模型等）。 问题是什么？我在学习期间从未上过正规的物理课程。虽然我对数学基础很有信心，但我常常觉得自己缺乏扎实的物理背景所提供的直觉。 我想以最有效的方式自学我需要的物理学。我应该专注于物理学的哪些领域，您会推荐哪些资源（书籍、课程、视频）来快速建立我攻读博士学位所需的直觉？ 谢谢你的帮助！    提交人    /u/Niccricket   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6f8ql/phd_in_sciml_mastering_physics_without_a_formal/</guid>
      <pubDate>Fri, 18 Oct 2024 10:55:21 GMT</pubDate>
    </item>
    <item>
      <title>微软发布适用于 1 位 LLM 的 BitNet.cpp</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6evbc/microsoft_bitnetcpp_for_1_bit_llms_released/</link>
      <description><![CDATA[BitNet.cpp 是运行和加载论文“1 位 LLM 时代”中的 1 位 LLM 的官方框架，即使在 CPU 中也能运行巨大的 LLM。该框架目前支持 3 种模型。您可以在此处查看其他详细信息：https://youtu.be/ojTGcjD5x58?si=K3MVtxhdIgZHHmP7    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6evbc/microsoft_bitnetcpp_for_1_bit_llms_released/</guid>
      <pubDate>Fri, 18 Oct 2024 10:30:05 GMT</pubDate>
    </item>
    <item>
      <title>STS 激活函数</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6elz9/activation_function_for_sts/</link>
      <description><![CDATA[假设我处理句子，每个初始句子向量都是通过将句子传递给变换器模型获得的，并获得一个平均池化向量，随后该平均池化向量通过一个简单的神经网络（1 层 +1 激活函数）进行相似性标签训练。那么我会问的问题是：  什么度量（例如余弦相似度）最适合用于分配相似性标签； 哪种激活函数最适合此目的。  我是否理解正确，在训练之后，句子的嵌入将是隐藏层的值（或权重），然后传递给激活函数？    提交人    /u/RDA92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6elz9/activation_function_for_sts/</guid>
      <pubDate>Fri, 18 Oct 2024 10:11:54 GMT</pubDate>
    </item>
    <item>
      <title>从事机器学习工作真的需要硕士学位吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6duvh/does_working_in_ml_really_need_master_degree/</link>
      <description><![CDATA[  由    /u/gggsss119  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6duvh/does_working_in_ml_really_need_master_degree/</guid>
      <pubDate>Fri, 18 Oct 2024 09:15:53 GMT</pubDate>
    </item>
    <item>
      <title>8 到 12 个月内成为 AI 工程师的路线图（从零开始）。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6d4cz/roadmap_to_becoming_an_ai_engineer_in_8_to_12/</link>
      <description><![CDATA[大家好！ 我刚刚开始攻读电子与通信工程 (ECE) 的机械工程/技术硕士学位，我的目标是在未来 8 到 12 个月内转型为人工智能工程师。我从零开始，但每天可以投入 6 到 8 个小时来学习和构建项目。我正在寻找一份详细的路线图，以及在此过程中要构建的项目想法、任何相关的黑客马拉松、实习和其他可以帮助我实现这一目标的机会。 如果有人经历过这段旅程或目前正在走类似的道路，我很想听听你对以下方面的见解：  学习路线图——我应该每个月关注什么？ 项目——我可以构建哪些现实世界的 AI 项目来提高我的技能？ 黑客马拉松——我在哪里可以找到专注于 AI/ML 的黑客马拉松？ 实习/机会——关于在哪里寻找与 AI 相关的实习或兼职机会的任何建议？  非常感谢任何资源、建议或经验分享。提前谢谢！😊   由    /u/Massive-Medium-4174  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6d4cz/roadmap_to_becoming_an_ai_engineer_in_8_to_12/</guid>
      <pubDate>Fri, 18 Oct 2024 08:18:01 GMT</pubDate>
    </item>
    <item>
      <title>我尝试在 JAX 中创建一个深度学习框架，将神经网络保留为纯函数（正在进行中）：</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6cggc/i_tried_to_make_a_deep_learning_framework_in_jax/</link>
      <description><![CDATA[链接：在评论中 我真的很喜欢 jax，因为它很纯粹。但是，使用框架（现有的 jax 框架、tf、pytorch 等）会使神经网络变得不纯粹，或者变成某种特殊的东西，您必须对其进行初始化或转换。对于大多数事情来说，这都没问题，但是当您需要做非常低级的细粒度的事情时，它就会变得很痛苦（这就是为什么他们通常称之为“模型手术”——在我看来，使用这个新库很容易，如果您习惯使用低级 jax 和函数思考，这甚至几乎是微不足道的） 这个库不会重新发明任何东西。您始终处于最低级别（jax 级别），但它确实消除了停留在 jax 级别的痛苦点：参数构建！参数构建通常非常繁琐，所以我制作了这个库来处理这个问题。之后，真的没有什么可以阻止你直接使用 jax 了。  免责声明：这仍处于非常早期的阶段：   它演示了要点/功能，但缺少一些东西（例如转换网络） 它具有稀疏网络模块（到目前为止是 mlp、attention、layer_norm），因为我专注于核心功能  现在您可以立即 pip 安装 alpha 版本并尝试它！  很高兴听到您的想法和建议（无论是在这里还是在 github 上的问题上）。如果您有兴趣帮助将其开发到第一个可发布状态，我们非常欢迎您这样做。    提交人    /u/Pristine-Staff-5250   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6cggc/i_tried_to_make_a_deep_learning_framework_in_jax/</guid>
      <pubDate>Fri, 18 Oct 2024 07:25:13 GMT</pubDate>
    </item>
    <item>
      <title>我究竟如何个性化我的 ChatGPT 应用程序，以便它记住我的一些事情并在讨论事情时回忆起它？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6c9qf/how_exactly_do_i_personalize_my_chatgpt_app_so_it/</link>
      <description><![CDATA[  由    /u/Hey_u_23_skidoo  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6c9qf/how_exactly_do_i_personalize_my_chatgpt_app_so_it/</guid>
      <pubDate>Fri, 18 Oct 2024 07:10:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能写故事这么差？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6afmz/why_are_ais_so_bad_at_writing_stories/</link>
      <description><![CDATA[我注意到 AI LLM 似乎每次都以同样的方式开始。 感觉很僵硬，做工不太好。但是我们有图像生成器可以制作一些非常令人印象深刻的东西。奇怪的是，AI 似乎真的不能制作令人印象深刻的故事。    提交人    /u/ryan7251   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6afmz/why_are_ais_so_bad_at_writing_stories/</guid>
      <pubDate>Fri, 18 Oct 2024 04:59:10 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Nemotron-70B 不是最好的法学硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g6a23j/nvidia_nemotron70b_isnt_the_best_llm/</link>
      <description><![CDATA[虽然这个模型很好，但我认为它有点被夸大了，因为它仅在三个基准测试中就击败了 Claude3.5 和 GPT4o。我相信这个想法还有其他一些原因，我在这里分享了这些原因：https://youtu.be/a8LsDjAcy60?si=JHAj7VOS1YHp8FMV    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g6a23j/nvidia_nemotron70b_isnt_the_best_llm/</guid>
      <pubDate>Fri, 18 Oct 2024 04:34:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的泰坦尼克号模型返回的结果带有小数而不是只有 0 和 1？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g685vt/why_is_my_titanic_model_returning_results_with/</link>
      <description><![CDATA[将 pandas 导入为 pd 从 sklearn.metrics 导入 mean_absolute_error 从 sklearn.tree 导入 DecisionTreeRegressor 数据集 = pd.read_csv(&#39;train.csv&#39;) train_y = dataset.Survived 特征 = [&#39;Pclass&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;] train_X = dataset[features] titanic_model = DecisionTreeRegressor(random_state=1) titanic_model.fit(train_X, train_y) test_dataset = pd.read_csv(&#39;test.csv&#39;) test_X = test_dataset[features] test_pred = titanic_model.predict(test_X) 结果 = pd.DataFrame({ &#39;PassengerId&#39;:test_dataset[&#39;PassengerId&#39;], &#39;Survived&#39;: test_pred }) results.to_csv(&#39;results.csv&#39;, index=False)     提交人    /u/mschlindwein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g685vt/why_is_my_titanic_model_returning_results_with/</guid>
      <pubDate>Fri, 18 Oct 2024 02:42:40 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>