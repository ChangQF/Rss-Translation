<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sat, 05 Oct 2024 21:15:43 GMT</lastBuildDate>
    <item>
      <title>Transformer 中的位置编码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fx01zm/positional_encoding_in_a_transformer/</link>
      <description><![CDATA[如果两个单词在句子中靠得很近，并且具有相似的位置编码，这是否会导致自注意力机制赋予它们比应有的更多的权重，即使它们在语义上没有关联？模型如何确保注意力机制优先考虑单词之间的有意义的关系，而不是仅仅关注位置接近性？ 此外，自注意力如何知道两个单词彼此接近？例如，如果一个单词与另一个处于较远位置的单词之间的总体得分与该单词与其附近单词之间的得分相同，那么编码器如何区分在句子上下文中哪个词实际上离它更近？    submitted by    /u/ardesai1907   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fx01zm/positional_encoding_in_a_transformer/</guid>
      <pubDate>Sat, 05 Oct 2024 20:51:29 GMT</pubDate>
    </item>
    <item>
      <title>合成数据的清理方式是否应与真实数据不同</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwz74r/should_synthetic_data_be_sanitized_differently/</link>
      <description><![CDATA[抱歉，这里不适合讨论这个问题。总之，我对这些都很陌生，正在与学校的一些教授合作，使用合成数据进行分析项目。数据集是提供的，无法重新生成，并且存在来自多个来源的不一致的编码变量（谁知道我们还会在其中发现什么……）我的问题是： 是否有任何研究规定了在处理合成数据而不是真实数据时首选/更有效的清理技术？ 我的直觉告诉我它应该像任何数据集一样处理，但我对此了解不够多，无法对此有任何真正的直觉。TIA    提交人    /u/joefromCLE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwz74r/should_synthetic_data_be_sanitized_differently/</guid>
      <pubDate>Sat, 05 Oct 2024 20:11:33 GMT</pubDate>
    </item>
    <item>
      <title>机器学习——尝试制作合成数据集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwyeld/machine_learning_trying_to_make_synthetic_dataset/</link>
      <description><![CDATA[我正在尝试在 Gujlish 数据集（古吉拉特语 + 英语）上训练 LLM 模型，但由于缺乏数据集，我在训练任何模型时都遇到了麻烦。 因此，我想到了一种生成数据集的方法，该数据集也可以帮助其他人训练 gujlish 语言的模型。  我将使用 Llama-3.1（最好是 70B 令牌）来生成一个数据集，该数据集由两个用户用 gujlish 语言聊天讨论某个话题组成。 然后，将手动查看对话，以消除任何错误的语法和其他内容（我知道这是一个非常漫长的过程！）。 之后，我想我可以在该对话上训练模型。  这种方法的问题：  至少需要 70B 令牌的 Llama-3.1 40G 的 GPU，而 Kaggle 最多只提供 30G。 即使我能够以某种方式加载模型并训练它，我需要多少数据集来训练模型（将使用预训练模型）。  有人可以建议解决这个问题的其他方法吗？    提交人    /u/plutonium12348   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwyeld/machine_learning_trying_to_make_synthetic_dataset/</guid>
      <pubDate>Sat, 05 Oct 2024 19:35:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么协变量转移是机器学习中的一个问题？（从理论角度）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwxxes/why_is_covariate_shift_a_problem_in_machine/</link>
      <description><![CDATA[  由    /u/amirdol7  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwxxes/why_is_covariate_shift_a_problem_in_machine/</guid>
      <pubDate>Sat, 05 Oct 2024 19:14:18 GMT</pubDate>
    </item>
    <item>
      <title>有人推荐做 MiniTorch 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwxa0w/does_anyone_recommend_doing_minitorch/</link>
      <description><![CDATA[&quot;MiniTorch 是一个 DIY 教学库，适用于希望了解深度学习系统内部概念的机器学习工程师。它是 Torch API 的纯 Python 重新实现，旨在简单、易读、经过测试和增量。&quot; 链接：https://minitorch.github.io/    提交人    /u/_stracci   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwxa0w/does_anyone_recommend_doing_minitorch/</guid>
      <pubDate>Sat, 05 Oct 2024 18:44:37 GMT</pubDate>
    </item>
    <item>
      <title>✅DSA 第 4 天与开发（AI、ML、DS）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwwt08/day_4_of_dsa_with_development_aimlds/</link>
      <description><![CDATA[      1.学习一些排序算法以及例子。2. 机器学习领域，学习了线性回归模型。就这些！ DSA #Machinelearning #Datascience #Ai #coding #linearregression #sorting    提交人    /u/Rikin_29_11   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwwt08/day_4_of_dsa_with_development_aimlds/</guid>
      <pubDate>Sat, 05 Oct 2024 18:22:54 GMT</pubDate>
    </item>
    <item>
      <title>如何开始学习机器学习？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwwhvm/how_to_start_learning_ml/</link>
      <description><![CDATA[有人可以指导如何开始学习 ML 吗？    提交人    /u/Beautiful_Plate_8996   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwwhvm/how_to_start_learning_ml/</guid>
      <pubDate>Sat, 05 Oct 2024 18:08:36 GMT</pubDate>
    </item>
    <item>
      <title>EVINGCA：一种基于视觉直觉的聚类算法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwvgb5/evingca_a_visual_intuitionbased_clustering/</link>
      <description><![CDATA[      经过大约一个月的工作，我很高兴与大家分享我的聚类算法 EVINGCA（不断发展的直观神经图构造算法）的第一个版本。EVINGCA 是一种基于密度的算法，类似于 DBSCAN，但具有更高的适应性和与人类直觉的一致性。它大量利用图论来形成聚类，这反映在其名称中。 “神经”方面来自其更高的复杂性 - 目前，它使用 5 个可调权重/参数和 3 个类似于激活函数的复杂函数。虽然这些都不需要修改，但可以对它们进行调整以用于探索目的，而不会显着或不可预测地降低模型的性能。 在下面的视频中，您将看到 EVINGCA 在一些示例数据集上的表现。对于每个数据集（第一个数据集除外），我将首先展示一个 2D 表示，然后展示一个 3D 表示，其中集群按照数据集沿 y 轴的定义进行分隔。3D 版本已经描绘出了每个集群，但我将在它们上运行我的算法，以展示其在 2D 和 3D 数据中的功能和一致性。 虽然该算法并不完美，并且并不总是完全按照每个数据集的意图进行聚类，但我很高兴它与人类直觉的匹配程度很高，并且有效地排除了异常值 - 就像 DBSCAN 一样。 由于这仍在开发中，因此欢迎所有想法、评论和问题。    提交人    /u/Significant-Agent854   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwvgb5/evingca_a_visual_intuitionbased_clustering/</guid>
      <pubDate>Sat, 05 Oct 2024 17:20:51 GMT</pubDate>
    </item>
    <item>
      <title>你更喜欢哪一个</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwv7ij/which_one_do_you_prefer/</link>
      <description><![CDATA[要学习 EDA 和数据预处理，你会推荐哪一个： 1. Krish naik 2. Satyajit Pattnaik 3. Coursera 上的 EDA 课程  如果你有比上述更好的，请提及。提前致谢！    提交人    /u/Asta-12   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwv7ij/which_one_do_you_prefer/</guid>
      <pubDate>Sat, 05 Oct 2024 17:09:53 GMT</pubDate>
    </item>
    <item>
      <title>10 月 4 日进展 - 冬季专题：机器学习与健康</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwopsh/oct_4_progress_winter_arc_machine_learning_health/</link>
      <description><![CDATA[10 月 4 日进度 由于在大学里花了更多时间，所以进展不大🥲。花了 2-3 个小时为 Hactoberfest 进行公开贡献。 目前进度：- 特征工程 计划在周日之前完成 Python、概率和特征工程。这样我就可以重新开始机器学习了。 也在健身房呆了 1 个小时。我本来想逃掉，但不知怎么的我做到了。 与往常一样，我愿意接受任何建议、提示或学习资源。同学们，欢迎加入我的旅程！ 机器学习 #AI #冬季目标 #自我提升    提交人    /u/ActuarySecret6564   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwopsh/oct_4_progress_winter_arc_machine_learning_health/</guid>
      <pubDate>Sat, 05 Oct 2024 11:57:28 GMT</pubDate>
    </item>
    <item>
      <title>您更喜欢哪一个进行 eda 和预处理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwoio6/which_one_do_you_prefer_for_eda_and_prepocessing/</link>
      <description><![CDATA[要学习 EDA 和数据预处理，您会推荐哪一个： 1. Krish naik 2. Satyajit Pattnaik 3. Coursera 上的 EDA 课程  如果您有比上述更好的其他课程，请提及。提前致谢！    提交人    /u/Asta-12   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwoio6/which_one_do_you_prefer_for_eda_and_prepocessing/</guid>
      <pubDate>Sat, 05 Oct 2024 11:45:12 GMT</pubDate>
    </item>
    <item>
      <title>是否需要 cuda 编程来编写高效的推理管道？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwo9p8/is_cuda_programming_required_to_write_efficient/</link>
      <description><![CDATA[据我所知，在生产级机器学习应用中，每个人都希望尽可能降低推理成本并节省资金。但与使用 pytorch 等高级 python 库的推理管道相比，部署 c/cuda 编写的管道真的有益吗？是否有显着的性能改进和资源使用量的减少？    提交人    /u/Content-Ad7867   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwo9p8/is_cuda_programming_required_to_write_efficient/</guid>
      <pubDate>Sat, 05 Oct 2024 11:29:15 GMT</pubDate>
    </item>
    <item>
      <title>你会使用哪种算法来对矩阵中最相关的列进行聚类</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwjpmp/which_algorithm_would_you_use_to_cluster_the_most/</link>
      <description><![CDATA[您将使用哪种算法来“分组”或“聚类”一组列向量，以便最相关的被分组在一起，而不同的组之间相关性最小？我假设这就是 k 均值聚类的用途？有人可以证实吗？我很感激任何建议。     提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwjpmp/which_algorithm_would_you_use_to_cluster_the_most/</guid>
      <pubDate>Sat, 05 Oct 2024 05:56:19 GMT</pubDate>
    </item>
    <item>
      <title>评估机器学习模型：平衡欠拟合、过拟合和鲁棒性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fwieep/evaluating_machine_learning_models_balancing/</link>
      <description><![CDATA[      来源：LinkedIn 在构建机器学习模型时，最终目标是开发能够很好地推广到看不见的数据的模型。但我们如何才能可靠地衡量这一点呢？ 在这篇文章中，我想分享一些重要的模型评估技巧，帮助你避免常见的陷阱，并确保你的模型在实际应用中表现出色。 📊 训练、验证和测试集评估模型的第一步是将数据分成三组： →训练集：用于训练模型。  →验证集：用于调整模型超参数。  →测试集：用于部署模型前的最终评估。为什么是三组？  使用验证集调整模型时，信息可能会泄露到模型中。随着时间的推移，模​​型可能会过度拟合验证集 - 这意味着它在验证数据上表现很好，但无法推广到新的、看不见的数据。测试集是评估模型真实泛化能力和检查其是否具有稳健拟合的保障。 🔄一些交叉验证  方法1. 保留验证：一种简单的方法，您可以保留一部分数据进行验证和测试。但是，如果数据有限，验证/测试集可能不具代表性，导致结果差异很大。  K 倍交叉验证：将数据分成 K 个相等的部分。每个折叠都用作验证数据，而剩余的折叠用于训练。此方法非常适合检测过度拟合或欠拟合。它提供了更可靠的评估，并有助于确保您的模型既不太简单（欠拟合），也不太复杂（过拟合）。 迭代 K 折验证：为了获得更高的精度，请多次重复 K 折交叉验证，每次都对数据进行混洗。当您的数据有限时，这很有用，可确保进行稳健的评估，但计算成本可能很高。  🎯 欠拟合、过拟合和稳健拟合  → 当您的模型过于简单而无法捕捉数据中的模式时，就会发生欠拟合，导致训练和验证集的性能不佳。  → 当您的模型过于复杂并捕获训练数据中的噪声时，就会发生过度拟合，在训练集上表现良好，但在看不见的数据（验证/测试集）上表现不佳。如果仅根据验证表现反复调整模型，则可能会意外出现过度拟合。  → 稳健拟合是最佳点 — 您的模型可以很好地推广到新数据。 这是通过仔细调整模型的超参数、使用适当的评估技术（例如 K 折验证）以及确保在调整过程中不会将验证集中的信息泄露到模型中来实现的。    提交人    /u/Excellent_Attempt353   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fwieep/evaluating_machine_learning_models_balancing/</guid>
      <pubDate>Sat, 05 Oct 2024 04:30:13 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>