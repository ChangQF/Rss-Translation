<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Wed, 22 May 2024 09:16:13 GMT</lastBuildDate>
    <item>
      <title>在 C 中实现 Keras 的 Conv2DTranspose 层：填充问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxvf28/implementing_conv2dtranspose_layer_from_keras_in/</link>
      <description><![CDATA[      我想在 c 中实现 keras 的 conv2dtranspose 层。我想要的确切层是这个 x =layers.Conv2DTranspose(n_filters, 3, strides=2, padding=&#39;same&#39;)(x) 我发现Conv2DTranspose 的算法，如下图所示。在我的 CNN 中，输入大小为 32x32xn_filters，输出大小为 64x64xn_filters/2。填充计算让我很困惑。在第二张图片中，有一个计算输出大小的方程。当我替换除 p（填充）之外的所有数据时，p 最终为 0.5。但是，由于填充必须是整数，因此该值是不可能的。 64 = (32-1)*2 + 3 -2p =&gt; 2p =65-64 =&gt; p = 0.5 我应该采取什么方法来处理填充计算以确保CNN的准确性？ https://preview.redd.it/me5tpbduxx1d1.png?width=1083&amp;format=png&amp;auto=webp&amp;s=f783 c0ee25e66d45ed231cd924f1a1006af2bed3  https:// /preview.redd.it/242wzbduxx1d1.png?width=269&amp;format=png&amp;auto=webp&amp;s=3b688e5c1c029ff56217e58e8293d9e377fecbe5   由   提交 /u/sepCIFic_account   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxvf28/implementing_conv2dtranspose_layer_from_keras_in/</guid>
      <pubDate>Wed, 22 May 2024 08:37:34 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络中的逻辑计算</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxveem/logical_computation_in_anns/</link>
      <description><![CDATA[      https://preview.redd .it/grb62hblux1d1.png?width=1279&amp;format=png&amp;auto=webp&amp;s=e795299636b3f95359db6b35e1437ad1bdfecc23 这是来自 Keras Scikit-Learn 机器学习实践的图像，以及 Aurelion Geron 所著的 TensorFlow 书籍。 此处，我们假设神经元在至少两个输入连接处于活动状态时被激活。 在此图像下方的文本中，对于在最右边的网络中，他提到“仅当神经元 A 处于活动状态且神经元 B 处于关闭状态时，神经元 C 才会被激活。” 我不确定如果神经元 A 处于活动状态并且神经元 B 也处于活动状态，为什么神经元 C 不能处于活动状态，因为在这种情况下，神经元 B 的信号将变为关闭，但即使如此 A 也是活动的，我们有 2活动信号是我们需要的最少信号。  有人可以澄清一下吗？谢谢。   由   提交/u/headmaster_007  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxveem/logical_computation_in_anns/</guid>
      <pubDate>Wed, 22 May 2024 08:36:12 GMT</pubDate>
    </item>
    <item>
      <title>嘿！我想学习机器学习和人工智能开发，但我在编码方面完全是新手。如何开始？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxvbvu/hey_i_want_to_learn_machine_learning_and_ai/</link>
      <description><![CDATA[我是一名PCB（第11标准选择生物）学生。我对 11 12 数学一无所知，而且我总是害怕数学。我对编码也一无所知。我不想学习网络开发或任何其他东西，只想直接进入人工智能学习。不想以此为职业，只想学习新东西。 这可能吗？如果是，我该如何开始？   由   提交 /u/inklusivemediaco   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxvbvu/hey_i_want_to_learn_machine_learning_and_ai/</guid>
      <pubDate>Wed, 22 May 2024 08:30:41 GMT</pubDate>
    </item>
    <item>
      <title>关于使用 INT8 量化从 TF（张量流）到 TFLite 的问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxui7v/questions_about_tf_tensorflow_to_tflite_with_int8/</link>
      <description><![CDATA[      我尝试按照 https://medium.com/analytics-vidhya/noise-suppression-using-deep-learning-6ead8c8a1839 这是一个完整的Conv1D SEGAN模型。感谢作者分享。然后我完成训练并得到 H5 模型。 然后我尝试转换为具有 Full Integer INT8 量化的 TFLite 模型。 model = load_model(&#39;NS_SEGAN_localTrained.h5 &#39;) model.summary() score = model.evaluate(test_dataset) tflite_model = tf.lite.TFLiteConverter.from_keras_model(model) tflite_model.optimizations = [tf.lite.Optimize.DEFAULT]  tflite_model.representative_dataset =representative_data_gen tflite_model.target_spec.supported_ops = [  tf.lite.OpsSet.TFLITE_BUILTINS, # 启用 TensorFlow Lite 操作。 tf.lite.OpsSet.SELECT_TF_OPS, # 启用 TensorFlow 操作。 tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # 同时使用选择操作和内置函数  tflite_model.inference_input_type = tf.int8 tflite_model.inference_output_type = tf.int8 tflite_model_quant_INT8 = tflite_model.convert()&lt; /code&gt; with open(&#39;NS_SEGAN_localTrained_quant_2.tflite&#39;, &#39;wb&#39;) as f: f.write(tflite_model_quant_INT8)&lt; /code&gt; H5 型号 TFLite 模型 然后有人专家告诉我，除了第一个之外，TransposeConv 似乎异常，这意味着其他 TransposeConv 的输出维度不正确。请看底部的数字。 我不知道为什么会出现错误的输出维度，因为 TFLiteConverter 已经完成且没有任何错误，而且这是官方的tensorflow API，对吗？虽然它看起来也很不正常，因为第一个 TransposeConv 具有正常的输出暗淡。 不幸的是专家没有分享更多，我仍然不知道根本原因以及如何修复它或如何检查 \防止其他型号。在网络上搜索，找不到准确的知识。 如果有人知道或遇到过麻烦，请分享并指导我。  谢谢。 第一个 TransposeConv 似乎是正确的。 其他 TransposeConv 输出 [1,1,1,1] 似乎尺寸错误   由   提交/u/Ok_Box_6059   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxui7v/questions_about_tf_tensorflow_to_tflite_with_int8/</guid>
      <pubDate>Wed, 22 May 2024 07:28:01 GMT</pubDate>
    </item>
    <item>
      <title>如何向面试官展示我的项目？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxty3g/how_do_i_showcase_my_projects_to_interviewers/</link>
      <description><![CDATA[当然，不用说我的项目也必须非常好。但是，我只是想知道外面的趋势是什么，或者作为面试官，是什么吸引你看到一个人的作品集，以一种奇特的方式描绘我们的个人资料是否重要？提前致谢！    由   提交/u/NewRogg  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxty3g/how_do_i_showcase_my_projects_to_interviewers/</guid>
      <pubDate>Wed, 22 May 2024 06:49:44 GMT</pubDate>
    </item>
    <item>
      <title>请教如何融合特征向量</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxtham/ask_about_how_to_fuse_feature_vector/</link>
      <description><![CDATA[目前，我正在处理图像分类问题。我使用 2 种提取方法：HOG 和面部地标。我的想法是使用 HOG 来查找图像的梯度大小和方向，并使用面部标志来查找面部关键点。我想我可以融合两种方法来制作更好的功能。但新特征比 HOG 差，比面部特征点好（评估相同模型）。我有一些问题： 1.我想知道如何融合这两种方法，其中 HOG 归一化之前和面部标志返回 68x2 对点整数。 2.如果可以，我应该在熔断之前进行归一化或其他处理吗？我可以尝试融合哪种方法（连接、加法、乘法……）？   由   提交/u/Civil_Statement_9331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxtham/ask_about_how_to_fuse_feature_vector/</guid>
      <pubDate>Wed, 22 May 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>如何开始微调法学硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxtfv0/how_to_begin_at_fine_tuning_llms/</link>
      <description><![CDATA[大家好。这是我的第一篇 Reddit 帖子，如果我使用了错误的格式，请原谅。 我想了解微调 LLM，例如 LLama-2、Gemma 模型、Llama-3。我读了很多Medium文章，接触了很多新的话题，比如LoRA、QLoRA、PEFT等，我已经尽力去理解它们。但是，在按照媒体文章实现代码时，我有时会遇到许多在没有解释的情况下初始化的参数，这有时令人难以承受。我也接触过Unsloth。我想知道我可以从哪里开始。我应该首先了解如何使用 PyTorch 和 Transformers 库微调 BERT、T5 等小型模型吗？如果您想提供一些路线图，那将会非常有帮助。感谢您抽出时间。 我附上了我难以理解的代码示例。如何知道哪些参数应该使用，哪些参数不应该使用？ model_name = &quot;NousResearch/Llama-2-7b-chat-hf&quot; dataset_name = “mlabonne/guanaco-llama2-1k” new_model =“Llama-2-7b-chat-finetune” # QLoRA 参数 lora_r = 64 lora_alpha = 16 lora_dropout = 0.1 #bitsandbytes 参数 #激活 4 位精度基础模型加载 use_4​​bit = True #计算 4 位基础模型的 dtype bnb_4bit_compute_dtype = &quot;float16&quot; #量化类型 fp4 或 nf4 bnb_4bit_quant_type = &quot;nf4&quot; #激活4位基础模型的嵌套量化 use_nested_quant = False #训练参数 #output dir output_dir = &quot;./results&quot; ＃不。训练周期数 num_train_epochs = 1 fp16 = False bf16 = False per_device_train_batch_size = 4 per_device_eval_batch_size = 4gradient_accumulation_steps = 1gradient_checkpointing = True max_grad_norm = 0.3learning_rate = 2e-4weight_decay = 0.001optim =“paged_adamw_32bit” ” lr_scheduler_type =“余弦” max_steps = -1 Warmup_ratio = 0.03 group_by_length = True save_steps = 0logging_steps = 25 # SFT 参数 # 使用的最大序列长度 max_seq_length = None # 在同一输入序列中打包多个短示例以提高效率 Packing = False # 加载整个模型GPU 0 device_map = {“”: 0} # 加载数据集（您可以在此处处理） dataset = load_dataset(dataset_name, split=“train”) # 使用 QLoRA 配置加载分词器和模型compute_dtype = getattr(torch, bnb_4bit_compute_dtype) bnb_config = BitsAndBytesConfig( load_in_4bit=use_4​​bit, bnb_4bit_quant_type=bnb_4bit_quant_type, bnb_4bit_compute_dtype=compute_dtype, bnb_4bit_use_double_quant=use_nested_quant, ) # 检查 GPU 与 bfloat16 的兼容性 ifcompute_dtype == torch.float 16、use_4​​bit：主要，_ = torch.cuda.get_device_capability() if Major &gt;= 8: print(&quot;==&quot; * 80) print(&quot;您的 GPU 支持 bfloat16: 使用 bf16=True 加速训练&quot;) print(&quot;==&quot; * 80) # 加载基础模型 model = AutoModelForCausalLM.from_pretrained( model_name, quantization_config=bnb_config, device_map=device_map ) model.config.use_cache = False model.config.pretraining_tp = 1 # 加载LLaMA tokenizer tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True) tokenizer.pad_token = tokenizer. eos_token tokenizer.padding_side = “右”; # 修复 fp16 训练中奇怪的溢出问题 # 加载 LoRA 配置 peft_config = LoraConfig( lora_alpha=lora_alpha, lora_dropout=lora_dropout, r=lora_r,bias=“none”, task_type=“CAUSAL_LM”, ) # 设置训练参数training_arguments = TrainingArguments （output_dir=output_dir、num_train_epochs=num_train_epochs、per_device_train_batch_size=per_device_train_batch_size、gradient_accumulation_steps=gradient_accumulation_steps、optim=optim、save_steps=save_steps、logging_steps=logging_steps、learning_rate=learning_rate、weight_decay=weight_decay、fp16=fp16、b f16=bf16，max_grad_norm=max_grad_norm，max_steps =max_steps, Warmup_ratio=warmup_ratio, group_by_length=group_by_length, lr_scheduler_type=lr_scheduler_type, report_to=“tensorboard” ) # 设置监督微调参数 trainer = SFTTrainer( model=model, train_dataset=dataset, peft_config=peft_config, dataset_text_field=“text” ;, max_seq_length=max_seq_length, tokenizer=tokenizer, args=training_arguments, Packing=packing, ) # 训练模型 trainer.train()     ;由   提交/u/Straight-Ad-6389   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxtfv0/how_to_begin_at_fine_tuning_llms/</guid>
      <pubDate>Wed, 22 May 2024 06:14:37 GMT</pubDate>
    </item>
    <item>
      <title>数据科学需要多少统计数据？免费资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxsqjw/how_much_statistics_is_needed_for_data_science/</link>
      <description><![CDATA[   /u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxsqjw/how_much_statistics_is_needed_for_data_science/</guid>
      <pubDate>Wed, 22 May 2024 05:28:11 GMT</pubDate>
    </item>
    <item>
      <title>学习DuckDB和sql来替代pandas</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxrjv4/learn_duckdb_and_sql_to_replace_pandas/</link>
      <description><![CDATA[大家好。我是一个普通的 python 用户。我将 pandas 与 numpy 和 scipy 一起用于日常任务。我打算学习大数据来代替 pandas。请告诉我学习DuckDB和sql是否是一个不错的选择。还有其他值得考虑的事情吗？   由   提交/u/According_Cut_9497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxrjv4/learn_duckdb_and_sql_to_replace_pandas/</guid>
      <pubDate>Wed, 22 May 2024 04:15:15 GMT</pubDate>
    </item>
    <item>
      <title>在我大学的大数据和人工智能实验室获得了研究助理职位</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxrgon/got_a_research_assisstant_position_at_my_unis_big/</link>
      <description><![CDATA[您好， 我从未发表过论文，我是一名刚开始的硕士生，而且我从未（在今天之前）访问过或者知道研究实验室里发生了什么。面试的主题是学习、参与任何即将进行的项目。我将成为我实验室的第一个也是唯一一个硕士（其他都是未毕业的人，因为它是一个新部门）所以我想象会得到很多帮助和一起学习。但除此之外，您对新手研究员还有什么建议吗？  谢谢。   由   提交 /u/Bobsthejob   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxrgon/got_a_research_assisstant_position_at_my_unis_big/</guid>
      <pubDate>Wed, 22 May 2024 04:10:03 GMT</pubDate>
    </item>
    <item>
      <title>你有扑克</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxpsv1/ai_poker/</link>
      <description><![CDATA[我最近对人工智能玩游戏的想法非常感兴趣。最终目标是让大型人工智能模型能够玩像《我的世界》这样复杂的游戏。对于中期目标，我的目标是让人工智能玩《星露谷物语》。短期内，我想从AI打牌游戏开始。 我没有系统地学习过深度学习，但我对Python和PyTorch有一些经验。 这是我的到目前为止的计划。如果您有更好的建议，请告诉我。 卡牌游戏我选择了热门游戏“斗地主”。 （中国扑克）我朋友玩的。基本规则是 2 vs 1，第一个完成卡片的团队获胜。 对于输入信息，我正在考虑使用流行的 YOLO 对象检测。我不确定训练过程会有多复杂。 对于决策模型，也许是强化学习？我觉得纸牌游戏的强化学习可能会很慢。 对于输出，我正在考虑使用 PyAutoGUI 之类的东西来模拟点击。   由   提交 /u/p1aintiff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxpsv1/ai_poker/</guid>
      <pubDate>Wed, 22 May 2024 02:38:28 GMT</pubDate>
    </item>
    <item>
      <title>Autogen Studio：无需代码即可构建多代理编排用例</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxps8f/autogen_studio_building_multiagent_orchestration/</link>
      <description><![CDATA[Autogen studio 为 Autogen 框架启用 UI，如果您不喜欢编程，它看起来是一个很酷的选择。本教程介绍了 studio 版本的不同组件，以及如何通过一个简短的运行示例来设置它们，以及如何使用 LiteLLM 为 Ollama 的tinllama 模型创建代理服务器 https://youtu.be/rPCdtbA3aLw?si=c4zxYRbv6AGmPX2y   由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxps8f/autogen_studio_building_multiagent_orchestration/</guid>
      <pubDate>Wed, 22 May 2024 02:37:31 GMT</pubDate>
    </item>
    <item>
      <title>多少数学就够了</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxp70m/how_much_maths_should_be_enough/</link>
      <description><![CDATA[我将进入 cs 中 clg 的最后一年，我不喜欢数学，所以我从来没有太关注，但我对概念有基本的工作理解就像矩阵向量微积分，我在统计系也很好，我想知道我应该在什么水平上学习机器学习，应该深入研究还是仅仅了解这些概念的基础知识就足够了    由   提交/u/AiZ3N_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxp70m/how_much_maths_should_be_enough/</guid>
      <pubDate>Wed, 22 May 2024 02:06:39 GMT</pubDate>
    </item>
    <item>
      <title>暑假期间可以做的机器学习事情</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxjbq2/machine_learning_stuff_to_do_over_the_summer/</link>
      <description><![CDATA[我即将高中毕业，所以在接下来的 3 个月左右的时间里我有很多空闲时间。我的目标职业道路是机器学习工程师或机器学习研究员，虽然我知道这将是一条漫长的道路，但我想在今年夏天朝着这个方向努力（也是为了我自己对机器学习的兴趣）。 数学知识方面，我了解AP微积分AB​​，并阅读过https://www.deeplearningbook.org/ 到目前为止。对于编码，我对 Python、C++ 和 Java 非常熟悉，并且我在 Kaggle.com 上参加过一些 ML 竞赛，尽管大多数竞赛只是游乐场比赛（至少到目前为止，我对继续进行 Kaggle 不太感兴趣，因为在我看来，它更注重数据，而且我更喜欢低水平的数学知识）。 有人告诉我如果我想进入 ML（和 ML 研究）的技术方面，我应该考虑阅读 ML 研究论文并用 C++ 实现它们。我很可能会从更简单的模型（例如线性回归）开始，然后逐步发展到更先进和现代的模型。我知道计算、线性代数和统计学的基础很重要，但我更喜欢直接跳到论文和实施中，并在此过程中学习我需要了解的任何数学知识。 这会是一个很好的选择吗？主意？如果是这样，有什么建议可以增加我成功的机会吗？如果没有，你建议我做什么？   由   提交/u/Minimum-Tea-1942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxjbq2/machine_learning_stuff_to_do_over_the_summer/</guid>
      <pubDate>Tue, 21 May 2024 21:27:54 GMT</pubDate>
    </item>
    <item>
      <title>是什么让你找到好工作？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cxdgma/what_make_you_land_good_job/</link>
      <description><![CDATA[我最近获得了人工智能和机器人学硕士学位。我在学术领域（例如教学和研究）有六年的经验。我的问题是：我需要哪些技能、证书或项目才能找到一份好工作？任何建议都会有帮助   由   提交 /u/heyitm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cxdgma/what_make_you_land_good_job/</guid>
      <pubDate>Tue, 21 May 2024 17:27:07 GMT</pubDate>
    </item>
    </channel>
</rss>