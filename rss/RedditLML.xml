<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 09 Jan 2024 03:14:52 GMT</lastBuildDate>
    <item>
      <title>但为什么神经网络偏向于平滑函数呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1923kde/but_why_are_neural_networks_biased_towards_smooth/</link>
      <description><![CDATA[是否有任何扎实的数学文献可以开始解释为什么神经网络偏向于平滑函数并且不太倾向于学习急剧/陡峭的变化或转变特征空间？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1923kde/but_why_are_neural_networks_biased_towards_smooth/</guid>
      <pubDate>Tue, 09 Jan 2024 02:29:18 GMT</pubDate>
    </item>
    <item>
      <title>寻找具有“双豆”结构的二元分类数据集（2000 个条目）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1923fzb/looking_for_a_binary_classification_dataset_with/</link>
      <description><![CDATA[      我目前正在开发一个二元分类项目，需要一个能够展示独特的“两豆”结构。具体来说，我正在寻找 2000 个数据条目，其特征表示为 (x1, x2) 和相应的类标签 (+1/-1)。数据应类似于以下格式： x1 x2 class 8.0919 -1.7303 1 我丢失了文件的数据，现在在网络上找不到它。有谁知道我在哪里可以找到这样的数据集？ ​ https://preview.redd.it/p79ts0qjrbbc1.png?width=260&amp;format=png&amp;auto=webp&amp;s=7736670a4dd73b86b 7a4a0fba09de113a346469d   由   提交 /u/Radiant-Cockroach-33   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1923fzb/looking_for_a_binary_classification_dataset_with/</guid>
      <pubDate>Tue, 09 Jan 2024 02:23:27 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用分段掩码而不是边界框在数据集上训练 YOLO v8 吗？如果是这样怎么办？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/192198y/can_i_train_yolo_v8_on_a_dataset_using/</link>
      <description><![CDATA[我确信有一种方法可以做到这一点，但我似乎无法在任何地方找到有关如何执行此操作的任何说明。需要明确的是，我已经有了分割掩码，并且我想在数据集中使用它们而不是边界框，我不需要 YOLO 为我创建分割掩码。   由   提交 /u/salvosalvosalvo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/192198y/can_i_train_yolo_v8_on_a_dataset_using/</guid>
      <pubDate>Tue, 09 Jan 2024 00:42:20 GMT</pubDate>
    </item>
    <item>
      <title>新颖研究项目的最佳资源/模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191zlob/best_resourcesmodel_for_novel_research_project/</link>
      <description><![CDATA[大家好， 我即将作为大学研究员开始一个新的研究项目，使用机器学习来优化设备需要周期性的驱动波形。  我的目标是随着时间的推移监控该设备并生成任意波形，然后将生成的波形与测量的性能（可以是矢量、数字或其他东西！这是我们正在研究的问题）=&gt; ;生成新波形进行测试 =&gt;形成优化循环。  我在做简单的回归任务、神经网络和树模型方面有很多经验，但我不知道这里到底要使用什么模型，而且我对闭环机器学习优化框架也没有太多经验。我与一位前项目合作伙伴进行了交谈，他建议使用 cVAE 或 cGAN 模型来避免与单个性能向量相关的小潜在空间的潜在问题。这些看起来合理吗？如果是这样，关于这些模型或此类优化机器学习框架，有什么好的资源/代码库/论文可供查看吗？  任何帮助或建议都很棒！ 谢谢你， 迪伦 ​  div&gt;  由   提交 /u/redditdylanj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191zlob/best_resourcesmodel_for_novel_research_project/</guid>
      <pubDate>Mon, 08 Jan 2024 23:30:29 GMT</pubDate>
    </item>
    <item>
      <title>本地 AI 的 P40 与 P100</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191yctt/p40_vs_p100_for_local_ai/</link>
      <description><![CDATA[我计划构建一个专注于机器学习、推理和 LLM 聊天机器人实验的服务器。 Tesla P40 和 P100 都在我的 Prince 范围内。 P40 提供稍多的 VRAM（24GB 与 16GB），但 P100 中的 GDDR5 与 HBM2 相比，这意味着它的带宽要低得多，我认为这对于推理很重要。 P100 的 FP16 和 FP64 性能也比 P40 高得多。 P40 在 FP32 上实现了 11.7 Tflops，但在 FP16 上仅实现了 183 Gflops，在 FP64 上实现了 367 Gflops，而 P100 在 FP32 上实现了 9.5 Tflops，在 FP16 上实现了 19 Tflops，在 FP64 上实现了 4.7 Tflops。考虑到这些因素，以及我打算在本地运行 LLM 的推理用途，什么是最佳设置：两个 P40、两个 P100，还是一个 P40 和一个 P100？   由   提交 /u/PaperboyNZ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191yctt/p40_vs_p100_for_local_ai/</guid>
      <pubDate>Mon, 08 Jan 2024 22:39:10 GMT</pubDate>
    </item>
    <item>
      <title>您多久发现 VIF 和相关性分数有助于提高模型的性能？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191xyvq/how_often_do_you_find_vif_and_correlation_scores/</link>
      <description><![CDATA[我知道如果您使用线性回归模型并且数据集中存在大量多重共线性，它肯定会有所帮助，但我发现使用神经网络时，去掉减少多重共线性的特征不会对我的 ANN 模型的性能产生太大影响。 您的经验是什么？   由   提交/u/fouried96  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191xyvq/how_often_do_you_find_vif_and_correlation_scores/</guid>
      <pubDate>Mon, 08 Jan 2024 22:23:05 GMT</pubDate>
    </item>
    <item>
      <title>机器学习工程项目理念</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191xt1h/machine_learning_engineering_project_idea/</link>
      <description><![CDATA[ 由   提交/u/snoopsprouts43  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191xt1h/machine_learning_engineering_project_idea/</guid>
      <pubDate>Mon, 08 Jan 2024 22:16:27 GMT</pubDate>
    </item>
    <item>
      <title>一点团队合作</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191xiag/a_little_teamwork/</link>
      <description><![CDATA[最近我看到了很多 ML/AI/DL/DS 的路线图/指南。如果我们共同创建或找到好的存储库并将它们固定在 Reddit 子版块和规则中，这对许多人都有帮助，这不是很好吗 我们可以按类别和子类别进行操作。类似的类别包括 CV、NLP、语音、部署，以及 CNN、LSTM、Transformers、Data2Vec 等子类别。显然，它将包含一个自述文件，让用户决定选择所有给定（子）类别的原因和路径。 很少有版主检查高质量内容和冗余   由   提交 /u/mrpkeya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191xiag/a_little_teamwork/</guid>
      <pubDate>Mon, 08 Jan 2024 22:04:14 GMT</pubDate>
    </item>
    <item>
      <title>增加纪元是否会提高准确性。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191vm0t/does_increasing_epochs_improve_accuracy/</link>
      <description><![CDATA[我的数据集有 15 个特征和大约 4,000 个观测值/行。我觉得这可能不足以让神经网络真正捕获所有交互并通过特征空间形成最优函数。如果我大幅增加神经网络训练过程中经过的纪元数，这会提高准确性还是毫无用处？换句话说，更多的纪元是否可以让我更接近损失函数的全局最小值？ 编辑 :: 还有一个纪元传递整个数据集还是仅传递预定的批量大小？ &lt; /div&gt;  由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191vm0t/does_increasing_epochs_improve_accuracy/</guid>
      <pubDate>Mon, 08 Jan 2024 20:49:27 GMT</pubDate>
    </item>
    <item>
      <title>寻求有关简单 CNN 模型的反馈。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191uoye/asking_for_feedback_on_a_simple_cnn_model/</link>
      <description><![CDATA[class ConvNet(nn.Module): def __init__(self, input_size=28, num_channels=1, num_classes=10, dropout_prob=0.5 ): super().__init__() self.num_channels=num_channels self.input_size=input_size self.num_classes=num_classes ###卷积部分 self.conv1=nn.Sequential( nn.Conv2d(in_channels=self.num_channels, out_channels=48 , kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(48), nn.MaxPool2d(kernel_size=(2, 2)) ) self.conv2=nn.Sequential( nn.Dropout(p= dropout_prob), nn.Conv2d(in_channels=48, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(128), nn.MaxPool2d(kernel_size=(2, 2)), ) self.conv3=nn.Sequential( nn.Dropout(p=dropout_prob), nn.Conv2d(in_channels=128, out_channels=192, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(192 ), nn.Dropout(p=dropout_prob), nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(192), nn.Dropout(p =dropout_prob), nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(128), nn.MaxPool2d(kernel_size=(2, 2)) ) self.flatten = nn.Flatten() self.dense_input_size=self.calculate_fc_input_size() self.dense_intermediate_size=self.dense_input_size ###密集部分 self.dense=nn.Sequential( nn.Dropout(p=dropout_prob), nn.线性（self.dense_input_size，self.dense_intermediate_size），nn.ReLU（），nn.BatchNorm1d（self.dense_intermediate_size），nn.Dropout（p = dropout_prob），nn.Linear（self.dense_intermediate_size，self.dense_intermediate_size），nn。 ReLU(), nn.BatchNorm1d(self.dense_intermediate_size), nn.Linear(self.dense_intermediate_size, self.num_classes) ) defforward(self, x: torch.Tensor) -&gt; torch.Tensor: x = self.conv1(x) x= self.conv2(x) x= self.conv3(x) x = self.flatten(x) x = self.dense(x) return x defcalculate_fc_input_size(self ): # 定义一个具有所需最小维度的虚拟输入张量 x = torch.zeros(1, self.num_channels, self.input_size, self.input_size, dtype=torch.float32) x = self.conv1(x) x= self .conv2(x) x=self.conv3(x) x = self.flatten(x) return x.size(1)  这就是我正在使用的松散启发的模型由 AlexNet 开发。 我正在 CIFAR100 上使用它。在运行 Optuna 几十次试验后，我发现像 Adam 优化器这样的 lr=0.001 和 bs=64 效果最好。 我已经尝试过不同的 dropout 值和位置，也尝试过使用批量归一化层。我在 CIFAR100 上获得的最佳值是 50%。 如果模型有任何非常明显的弱点，有任何反馈吗？   由   提交/u/Educational_Roll_868   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191uoye/asking_for_feedback_on_a_simple_cnn_model/</guid>
      <pubDate>Mon, 08 Jan 2024 20:12:43 GMT</pubDate>
    </item>
    <item>
      <title>课程推荐和路线图帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191tbu3/course_recommendations_and_roadmap_assistance/</link>
      <description><![CDATA[大家好！ 我是一名应届毕业生，渴望开始我的机器学习职业生涯。我一直在 Udemy 上学习课程并观看 Andrew Ng 的视频来学习基础知识。然而，我发现自己在吴恩达讲座中的推导中遇到了困难，这让我怀疑自己是否走在正确的道路上。我很感激其他免费和付费课程的推荐，这些课程为机器学习基础知识提供了坚实的基础。此外，我非常感谢有关机器学习之旅路线图的指导。 谢谢 ​   由   提交/u/Maverick-1810  /u/Maverick-1810 reddit.com/r/learnmachinelearning/comments/191tbu3/course_recommendations_and_roadmap_assistance/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191tbu3/course_recommendations_and_roadmap_assistance/</guid>
      <pubDate>Mon, 08 Jan 2024 19:18:35 GMT</pubDate>
    </item>
    <item>
      <title>寻求有关为数据库驱动的问答应用程序有效提取相关表和列的指导</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191qy6o/seeking_guidance_on_efficient_extraction_of/</link>
      <description><![CDATA[我正在开发一个应用程序，旨在回答用户对包含数百个表和数千个列的数据库的查询。每个表和列都有很好的描述（如每个表和列的作用都有清晰的描述）。首先，我想根据用户查询提取前 n 个最相关的表和列，以便我可以将那些相关的表和列作为架构/上下文发送到 LLM，以构建一个 SQL 表达式，我可以进一步使用该表达式回答用户的问题。 我在有效提取相关表和列方面面临挑战。我当前使用语义搜索的方法对于这个问题没有产生令人满意的结果。 有人可以建议替代方法或技术来从大型数据库中提取相关表和列，以便在问答场景中获得更好的结果吗？我们将非常感谢您的见解和经验！   由   提交/u/impl66  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191qy6o/seeking_guidance_on_efficient_extraction_of/</guid>
      <pubDate>Mon, 08 Jan 2024 17:43:43 GMT</pubDate>
    </item>
    <item>
      <title>Andrew NG ML 专业化 Coursera 后的 ML 路线图？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191mh1f/ml_roadmap_after_andrew_ng_ml_specialization/</link>
      <description><![CDATA[伙计们，我已经完成了 Coursera 上 Andrew NG 的 ML 专业化课程和 deeplearning.ai 的机器学习数学专业化课程。  你认为我接下来应该做什么？  我对此 Reddit 子版块进行了深入搜索，但我对各种建议感到困惑，其中包括 YouTube 上的 CS229 以及课程中深入探讨的作业/问题集。&lt; /li&gt; Fast.ai 深度学习课程。  统计学习简介和统计学习要素。 斯坦福大学的 CS231N。  deeplearning.ai 的深度学习专业化。   我想坚持一条学习路径，确保我没有学习差距并为我的工作做好准备。 我知道所需的数学先决条件，因为我在机械工程学士学位期间学习了 3 门工程数学和应用数值技术课程。    由   提交 /u/Straight-Sky-7368   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191mh1f/ml_roadmap_after_andrew_ng_ml_specialization/</guid>
      <pubDate>Mon, 08 Jan 2024 14:29:56 GMT</pubDate>
    </item>
    <item>
      <title>烤我的简历</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/191gijf/roast_my_cv/</link>
      <description><![CDATA[       由   提交 /u/zero_redditer   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/191gijf/roast_my_cv/</guid>
      <pubDate>Mon, 08 Jan 2024 08:30:31 GMT</pubDate>
    </item>
    <item>
      <title>您认为决策树在表格数据上优于神经网络的原因是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1917mti/what_do_you_believe_is_the_reason_decision_trees/</link>
      <description><![CDATA[我只是想听听关于为什么会出现这种情况的不同推理和信念？   由   提交 /u/Traditional_Soil5753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1917mti/what_do_you_believe_is_the_reason_decision_trees/</guid>
      <pubDate>Mon, 08 Jan 2024 00:35:48 GMT</pubDate>
    </item>
    </channel>
</rss>