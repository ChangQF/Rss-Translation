<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 15 Feb 2024 18:17:17 GMT</lastBuildDate>
    <item>
      <title>使用 NLP 模型对社交媒体进行情感分析</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arl8jq/using_nlp_models_for_sentient_analysis_for_social/</link>
      <description><![CDATA[大家好， 我正在寻找使用 NLP 模型来自动分析社交媒体帖子。我对金融领域感兴趣，似乎 finBERT 或 finVADER 是最好的选择，但我想知道是否有任何模型/配置可以更好地工作。   由   提交 /u/URNotReal6969   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arl8jq/using_nlp_models_for_sentient_analysis_for_social/</guid>
      <pubDate>Thu, 15 Feb 2024 17:42:47 GMT</pubDate>
    </item>
    <item>
      <title>只是想知道，执行二元分类的一些常见技术是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arkpjk/just_wondering_what_are_some_of_the_common/</link>
      <description><![CDATA[ 由   提交 /u/Curious_keyboard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arkpjk/just_wondering_what_are_some_of_the_common/</guid>
      <pubDate>Thu, 15 Feb 2024 17:21:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 LSTM/GRU 自动编码器对时间序列数据进行异常检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arkbdo/anomaly_detection_in_time_seiries_data_using/</link>
      <description><![CDATA[我有具有 3 个特征（acc_x、acc_y 和 acc_z）的加速度计数据。我应该使用包含正常条件下加速度的数据集来训练模型。训练模型后，我向模型提供了异常数据，该数据应该会产生较高的 MAE 损失，但实际上并不是我所期望的。这是代码，如果我在这里做错了，请告诉我，我是初学者 ``` split_index = int(0.85 * len(df)) train = df .iloc[:split_index] test = df.iloc[split_index:]scaler=StandardScaler()scaler=scaler.fit(train[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39; acc_z&#39;]]) train[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39;acc_z&#39;]] = scaler.transform(train[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39;acc_z&#39;]]) test[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39;acc_z&#39;]] = scaler.transform(test[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39;acc_z&#39;]])  seq_size=7&lt; br /&gt; def to_sequences(x, seq_size=1): x_values = [] y_values = [] for i in range(len(x)-seq_size): x_values.append(x.iloc[i:(i+seq_size)].values) return np.array(x_values) trainX, trainY = to_sequences(train[[&#39;acc_x&#39;, &#39;acc_y&#39; , &#39;acc_z&#39;]], seq_size) testX, testY = to_sequences(test[[&#39;acc_x&#39;, &#39;acc_y&#39;, &#39;acc_z&#39;]], seq_size)  model = Sequential()  model.add(GRU(128, input_shape=(trainX.shape[1], trainX.shape[2]))) model.add(Dropout(rate=0.2)) model.add(RepeatVector(trainX.shape[1])) model.add(GRU(128, return_sequences=True)) model.add(Dropout(rate=0.2)) model.add(TimeDistributed(Dense(trainX.shape[2]))) model.compile(optimizer=&#39;adam&#39;, loss=&#39;mae&#39;) model.summary()  历史记录 = model.fit(trainX, trainX, epochs=40, batch_size=32,validation_split=0.1,shuffle=False, 回调=[keras.callbacks.EarlyStopping(monitor=“val_loss”, Patient=5, mode) =“min”)],verbose=1) trainPredict = model.predict(trainX) trainMAE = np.mean(np.abs(trainPredict - trainX), axis=1)  plt.hist(trainMAE,bins=40)  testPredict = model.predict(testX) testMAE = np.mean(np.abs(testPredict - testX), axis= 1) plt.hist(testMAE, bins=30)  data = np.array([ [19.61,-2.11,-6.31], [19.61 ,1.44,0.77], [19.61,6.11,-1.83] 等等。 }  nscaler = StandardScaler() nscaler = nscaler .fit(data) data = nscaler.transform(data) new= to_sequences(scaled_df, seq_size) newPredict = model.predict(new) newMAE = np.mean(np.abs(newPredict - new), axis=1) 异常 = newMAE &gt; 0.4 print(&quot;异常样本数量：&quot;, np.sum(anomalies)) print(&quot;异常样本索引：&quot;, np.where(anomalies)) ``` 此外，我想看看模型如何重建新数据，但无法做到这一点，因为我在将其重塑回原始绘图形式时遇到问题。   由   提交/u/saugatn3  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arkbdo/anomaly_detection_in_time_seiries_data_using/</guid>
      <pubDate>Thu, 15 Feb 2024 17:05:04 GMT</pubDate>
    </item>
    <item>
      <title>适合所有人的人工智能：DataCamp 的免费大师班课程 | ML、DL、LLM 等</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arj8eu/ai_for_everyone_free_masterclass_courses_with/</link>
      <description><![CDATA[       由   提交/u/UseCreative4765   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arj8eu/ai_for_everyone_free_masterclass_courses_with/</guid>
      <pubDate>Thu, 15 Feb 2024 16:20:21 GMT</pubDate>
    </item>
    <item>
      <title>Precision Recall Auc 中的坏分是多少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ariqtd/what_is_a_bad_score_in_precision_recall_auc/</link>
      <description><![CDATA[我是机器学习和编程新手，所以请耐心等待。我一直在研究具有类别不平衡（15% 的标签为正）的分类模型，以及精确回忆曲线 AUC（曲线下面积）作为用于评估模型质量的指标。使用始终预测 1 的模型，我获得了 0.51 的分数。使用随机森林分类器模型，我获得了 0.25 PR AUC 的低分。 坏分是否接近 0.5 或更接近 PR AUC 的随机预测 (0.15)？是否可以应用任何预测后技术来提高分数？谢谢您的建议。   由   提交/u/giordafrancis10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ariqtd/what_is_a_bad_score_in_precision_recall_auc/</guid>
      <pubDate>Thu, 15 Feb 2024 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>低延迟对话式AI模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ari1ud/lowlatency_conversational_ai_model/</link>
      <description><![CDATA[大家好， 对菜鸟问题表示歉意，我是这个主题的新手。 我想创建产生对话（语音）的人工智能模型。它很可能会围绕一个特定主题。我需要的是这个模型非常快，我们谈论毫秒，我想要非常小的延迟。这可以实现吗？ 如果是的话，那么我想我需要从零开始，或者采用一些大型模型并在此基础上训练新模型，这样我就可以只保留我需要保留的较小尺寸并保持快速？另外一个重要的问题是，由一个人完成是否现实？ 我是一名工程师，但我的领域是后端、云和网络..所以这不完全是我的专业领域。 &gt; 大约需要多少钱（仅用于培训） 谢谢！   由   提交 /u/Dubinko   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ari1ud/lowlatency_conversational_ai_model/</guid>
      <pubDate>Thu, 15 Feb 2024 15:30:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么这段代码在第一个分层 kfold 的第 3 折叠时耗尽了 RAM (12GB) ？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arhboq/why_does_this_code_run_out_of_ram_12gb_by_fold_3/</link>
      <description><![CDATA[代码链接：https://pastebin.com/afpLEREX&lt; /a&gt; #分层 K 折叠分类器 = [ MultinomialNB(), SVC(kernel=&#39;线性&#39;), DecisionTreeClassifier(), RandomForestClassifier(), MLPClassifier(hidden_​​layer_sizes=(5,)) ] classifier_names = [ &#39;多项式朴素贝叶斯&#39;、&#39;支持向量&#39;、&#39;决策树&#39;、&#39;随机森林&#39;、&#39;多人感知器&#39;] 数据集 = [Ling_spam、Enron、pu1、pu2、pu3、pua、[[Spamassassin.text , Spamassassin.target]]] Dataset_names = [&#39;Ling Spam&#39;, &#39;Enron&#39;, &#39;PU1&#39;, &#39;PU2&#39;, &#39;PU3&#39;, &#39;PUA&#39;, &#39;SpamAssassin&#39;] k_values=[3,4,5] # 外部循环获取不同的 k 值 for k in k_values: print(f&quot;分层 K 重交叉验证 k={k}&quot;) for classifier, classifier_name in zip(classifiers, classifier_names): print(f&quot;\nClassifier: { classifier_name}&quot;) classifier_accuracies = [] # 不同数据集的内循环 for dataset, dataset_name in zip(Datasets, Dataset_names): print(f&quot;\nDataset: {dataset_name}&quot;) [[emails_part,categories_part]] = dataset #分层 K 折交叉验证 skf = StratifiedKFold(n_splits=k, shuffle=True) Fold_accuracies=[] for train_index, test_index in skf.split(emails_part,categories_part): X_train_part, X_test_part = np.array(emails_part)[train_index] , np.array(emails_part)[test_index] y_train_part, y_test_part = np.array(categories_part)[train_index], np.array(categories_part)[test_index] count_vectorizer = CountVectorizer(stop_words=&#39;english&#39;) tf = count_vectorizer.fit_transform(X_train_part ) tfidf_vectorizer = TfidfVectorizer(stop_words=&#39;english&#39;) X_train_part = tfidf_vectorizer.fit_transform(X_train_part) X_test_part = tfidf_vectorizer.transform(X_test_part) classifier.fit(X_train_part, y_train_part) y_pred_pa​​rt = classifier.predict(X_test_part) 准确度 = precision_score( y_测试_部分、y_预测_部分) Fold_accuracies.append(accuracy) print(f&#39;Accuracy for Fold {len(fold_accuracies)}: {accuracy}&#39;) # 迭代之间清除内存 del X_train_part, X_test_part, y_train_part, y_test_part, count_vectorizer, tfidf_vectorizer, tf gc.collect() classifier_accuracies.append(np.mean(fold_accuracies)) print(f&#39;{dataset_name} 的准确度:{np.mean(fold_accuracies)}&#39;) print(f&quot;{classifier_name} 的平均准确度: {np.mean(classifier_accuracies)} \n&quot;)  ​   由   提交/u/lazypotato1729  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arhboq/why_does_this_code_run_out_of_ram_12gb_by_fold_3/</guid>
      <pubDate>Thu, 15 Feb 2024 14:59:32 GMT</pubDate>
    </item>
    <item>
      <title>Jeremy Howard -answer.ai，筹集 1000 万美元，他们如何招聘，为什么学术界的激励措施混乱</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1argi7n/jeremy_howard_answerai_raising_10m_how_they_hire/</link>
      <description><![CDATA[       由   提交/u/gordicaleksa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1argi7n/jeremy_howard_answerai_raising_10m_how_they_hire/</guid>
      <pubDate>Thu, 15 Feb 2024 14:21:35 GMT</pubDate>
    </item>
    <item>
      <title>Savant 0.2.7 已发布：针对 NVIDIA 优化的计算机视觉框架</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arge63/savant_027_is_out_computer_vision_framework/</link>
      <description><![CDATA[Savant 是一个先进的计算机视觉框架基于 NVIDIA DeepStream 和 TensorRT - NVIDIA 硬件上数据中心和边缘计算机视觉的一流技术。 在 0.2.7 中，Savant 收到了 4 个新演示，其中包括 26 个演示，涵盖检测、分类、分割、关键点、对象跟踪和 GAN。 0.2.7 中的新演示是：  RT-DETR 使用示例； 基于 CuPy 的 YOLOV8-Seg GPU 内后处理； 在 Savant 管道中提供 PyTorch CUDA 推理服务； 定向边界框检测和跟踪。  &lt; p&gt;0.2.7 中的新功能：  Grafana/Prometheus 集成。除了 OpenTelemetry 跟踪之外，您还可以使用 Grafana 和 Prometheus 来调查管道的运行方式。开发人员还可以导出他们的自定义指标。 缓冲区适配器。一种特殊的中间适配器，可以承受流量激增和管道减速的情况。它实现了一种机制，允许通过慢速管道元素延迟视频处理。该适配器具有 Prometheus/Grafana 集成，因此您始终知道有多少元素等待处理。它基于RocksDB。 仅编译模式。当管道首次启动时，它会在 TensorRT 引擎中编译模型。这很容易需要几分钟的时间。以前，开发人员无法将编译和评估分开。现在他们可以了。 关闭 PyFunc 中的处理程序。这个新的 API 允许正确处理管道关闭操作，以释放资源并通知第 3 方系统有关终止的信息。 入口和出口的消息过滤。这项高级功能允许开发人员通过简单的回调修改原始编码流及其元数据。例如，您可以仅选择关键帧进行处理，并丢弃其余帧或删除未检测到对象的视频片段。 在 GPU 上进行模型后处理。借助一项新功能，开发人员可以可以指示框架直接从 GPU 内存访问模型输出张量，而无需将其下载到 CPU 内存。 GPU 内存表示函数。在该版本中，我们提供了 OpenCV GpuMat、PyTorch GPU 张量和 CuPy 张量之间转换内存缓冲区的函数。 高级对象属性修改操作。在该版本中，我们实现了一组新操作，使开发人员能够以更方便的方式修改对象属性。 PyFunc 的队列利用 API。 Savant 允许在 PyFunc 之间添加队列以实现并行处理和流量突发管理。在该版本中，我们实现了一个新的 API，允许开发人员访问部署在管道中的队列以请求其使用。  完整版本 注释。 别忘了加入我们的Discord，我们为用户提供帮助。要了解有关 Savant 的更多信息，请阅读我们的文章：在计算机视觉项目中考虑 Savant 的十大理由。   由   提交 /u/ivan_kudryavtsev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arge63/savant_027_is_out_computer_vision_framework/</guid>
      <pubDate>Thu, 15 Feb 2024 14:16:23 GMT</pubDate>
    </item>
    <item>
      <title>适用于 ML 的 Anki Decks</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arfz7i/anki_decks_for_ml/</link>
      <description><![CDATA[大家好，有人可以分享您正在使用或发现更好的 Anki Decks 吗？不知道安琪吗？请阅读此处：https://augmentingcognition.com/ltm.html &lt;!-- SC_ON - -&gt;  由   提交 /u/sAI_Rama_Krishna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arfz7i/anki_decks_for_ml/</guid>
      <pubDate>Thu, 15 Feb 2024 13:57:11 GMT</pubDate>
    </item>
    <item>
      <title>需要指导！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arbbz5/guidance_needed/</link>
      <description><![CDATA[我是一个专注于应用科学的研究中心的博士后。在我的实验室和团队中，我是唯一做 ML/DL/CV 的人。  当我开始时（2016 年），我从前辈那里得到了一些指导，但他们很快就离开了团队。有人给了我一套课程（Andrew NG、Jose Portilla 等），帮助我在当时建立了强大的能力。因此，我的角色得到了升级，并攻读了博士学位，这是 CV 方法（图像分类、对象检测和语义分割）在极其复杂的现实生活环境中的实际应用的概念证明。 由于这个事件的过程，事实上我是各个项目的项目经理，我正在写资助等等，而且我没有得到团队中任何人的任何真正的指导，也没有任何需要解决的复杂问题，我在 ML 方面落后了。 我从未接触过 NLP（超出了基础知识，即 Jose Portilla 在 Udemy 上的课程），这让我觉得我对 ML 最热门的主题（法学硕士）一无所知。值得庆幸的是，简历已经达到了稳定水平。  我以前使用 Tensorflow，但现在我发现大多数人都使用 Pytorch，尤其是生产环境，而我对此没有经验。  现在，我不喜欢自己的处境，我想通过提高自己的技能来改变现状，以便离开学术界进入工业界。我想学习与 LLM 相关的任何内容（使用基础模型，微调并将其限制为自定义知识、RAG、部署等），以及 SQL、云服务（可能是 AWS），以及一般而言的任何内容大多数公司都想要。 你们能帮我列出所需的知识和相应的课程吗？我觉得我需要指导才能跟上，否则我会迷失在周围过多的信息中。提前致谢！    由   提交 /u/Mediocre_aanagn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arbbz5/guidance_needed/</guid>
      <pubDate>Thu, 15 Feb 2024 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地GPU上执行DL模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arbbgm/how_to_execute_dl_model_on_local_gpu/</link>
      <description><![CDATA[我的设备中有 rtx 3060 ti GPU，并尝试在 Jupiter 笔记本中执行多个深度学习和机器学习模型。 但我检查了任务管理器以及执行时间。看起来它没有利用 GPU 内存等本地资源。 您能帮我提供所需的代码片段或文章，让我可以在 GPU 上执行我的模型吗？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arbbgm/how_to_execute_dl_model_on_local_gpu/</guid>
      <pubDate>Thu, 15 Feb 2024 09:02:10 GMT</pubDate>
    </item>
    <item>
      <title>微调模型时遇到哪些问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ar9j3x/what_are_some_of_the_problems_faced_while/</link>
      <description><![CDATA[最近在微调稳定的扩散模型时，我缺乏针对我的用例微调模型所需的具体数据，也缺乏计算资源，而且我没有太多预算，我不断切换 google colab 帐户以使用免费 GPU。  我想知道人们在微调模型时通常会遇到哪些其他问题。   由   提交/u/Medium_Alternative50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ar9j3x/what_are_some_of_the_problems_faced_while/</guid>
      <pubDate>Thu, 15 Feb 2024 06:55:12 GMT</pubDate>
    </item>
    <item>
      <title>完整的机器学习工程师路线图</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ar2kmg/comprehensive_machine_learning_engineer_roadmap/</link>
      <description><![CDATA[社区您好，我是计算机科学专业一年级第二学期的学生，对成为一名机器学习工程师有着浓厚的兴趣。我正在寻求收集见解和建议，为我的学术和技能发展制定全面的路线图。如果您可以分享您的任何经验、推荐的课程或任何书籍。   由   提交/u/Flimsy-Ad-1236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ar2kmg/comprehensive_machine_learning_engineer_roadmap/</guid>
      <pubDate>Thu, 15 Feb 2024 00:32:20 GMT</pubDate>
    </item>
    <item>
      <title>有可能成为一名盲人机器学习程序员吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aqrpdw/is_it_possible_to_be_a_blind_ml_programmer/</link>
      <description><![CDATA[大家好，我还没有失明，但是我的病情恶化了，我担心它会毁掉我的梦想。我知道这会非常困难，但是您认为这可能以某种方式实现吗？   由   提交/u/A13xxnd3r   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aqrpdw/is_it_possible_to_be_a_blind_ml_programmer/</guid>
      <pubDate>Wed, 14 Feb 2024 16:58:02 GMT</pubDate>
    </item>
    </channel>
</rss>