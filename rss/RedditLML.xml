<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 28 Nov 2024 18:23:39 GMT</lastBuildDate>
    <item>
      <title>软件开发人员想要学习机器学习，哪些证书值得？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h21yco/software_dev_wanting_to_learning_machine_learning/</link>
      <description><![CDATA[我是一名软件开发人员，前端和全栈开发人员。我大约 7 年前在训练营学习编程。在此之前，我主修英语，做过一段时间的作家。我正在考虑下一步的职业发展，不确定是否想继续构建前端应用程序。我一直对机器学习很好奇，已经上过几门关于人工智能治理的课程，并考虑过重返学校学习。我有能力这样做，而且说实话，我很想念上课。我没有数学背景，所以我想上很多数学课程。 问题，你推荐什么课程？我在多伦多，看过 Chang School 的实用数据科学和机器学习课程。我应该先上一门数学课，看看我是否能做到吗？比如线性代数或微积分？ 编辑：只是想添加上下文。从小到大，我的数学一直不太好，这对我来说一直是一个自我意识问题。我的高中辅导员告诉我“坚持学习艺术”（现在回想起来，我意识到这是个非常糟糕的建议）。作为一名 30 多岁的女性，我对自己有了更多的自我意识和信心。我还成功转行从事编码工作，并在一家大型科技公司工作了 5.5 年。学习数学课程来学习机器学习对我来说似乎很可怕，但我不知道我是否会让自己感到惊讶。    提交人    /u/dsub11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h21yco/software_dev_wanting_to_learning_machine_learning/</guid>
      <pubDate>Thu, 28 Nov 2024 18:07:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在 ML 项目中从笔记本更改为脚本？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h21ly6/how_to_change_from_notebooks_to_scripts_in_a_ml/</link>
      <description><![CDATA[嗨，使用笔记本进行模型的实验和首次训练是正常的，但是当你必须将模型投入生产时，最好使用脚本来实现功能。你如何构建这些脚本？只为模型创建类？对超参数使用类似 args.parse 的东西？想知道人们是怎么做到的。  感谢评论😉    提交人    /u/Antthoss   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h21ly6/how_to_change_from_notebooks_to_scripts_in_a_ml/</guid>
      <pubDate>Thu, 28 Nov 2024 17:52:18 GMT</pubDate>
    </item>
    <item>
      <title>哪里可以找到好的学习资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h21hm8/where_find_good_source_for_learning/</link>
      <description><![CDATA[大家好，我正在按照免费课程营的教程学习如何做人工智能，但是我遇到了一个问题，代码是用 jupyter notebook 编写的，所以很不干净，很难理解，有人有更好的源代码吗？编辑免费资源     提交人    /u/FewVEVOkuruta   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h21hm8/where_find_good_source_for_learning/</guid>
      <pubDate>Thu, 28 Nov 2024 17:46:53 GMT</pubDate>
    </item>
    <item>
      <title>继 Andrew Ng 的机器学习专业化之后的步骤。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h20wwi/steps_after_andrew_ngs_machine_learning/</link>
      <description><![CDATA[我目前正在攻读 Andrew Ng 的机器学习专业课程（已完成第一门课程，目前正在学习第二门课程）。我想更深入地研究机器学习和数据科学。我对 Python 及其库（如 numpy）有点熟悉。除此之外，我了解不多。完成本课程后，我应该从哪里开始以及应该学习什么？    提交人    /u/Critical-Mix-1116   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h20wwi/steps_after_andrew_ngs_machine_learning/</guid>
      <pubDate>Thu, 28 Nov 2024 17:21:21 GMT</pubDate>
    </item>
    <item>
      <title>人们说“0 训练错误”是什么意思</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h20dwu/what_do_people_mean_when_they_say_0_training_error/</link>
      <description><![CDATA[在广为人知的论文理解深度学习需要重新思考泛化中，你可以找到这样的引述：  更准确地说，当对真实数据的完全随机标签进行训练时，神经网络可以实现 0 训练误差。  在众所周知的双重下降论文中：  我们证明，在与上述类似的设置中，当模型训练时间刚好达到 ≈ 0 训练误差时，测试性能会达到相应的峰值  当他们谈论训练误差时，他们是指训练数据的准确性还是其他指标？因为我无法想象它们意味着 0 训练损失，因为我从未见过任何训练接近 0。我还认为，使用通常的 softmax-crossentropy 或 MSE 损失，应该不可能实现 0 损失，因为即使数据集中只有一个实例，模型也只近似于标签，永远不会是“1”，只有 0.9999。    提交人    /u/G_fucking_G   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h20dwu/what_do_people_mean_when_they_say_0_training_error/</guid>
      <pubDate>Thu, 28 Nov 2024 16:58:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释GPU的内存使用情况？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h207uy/how_to_explain_the_memory_usage_of_gpu/</link>
      <description><![CDATA[嗨，我目前很难解释我的实验中出现的奇怪趋势。 我正在使用我提出的 2 个 PEFT 方法 A 和 B（抱歉，我不能分享方法名称）在 GLUE Benchmark 上微调基于 Roberta 的模型，并报告这些方法的内存使用情况（GPU）。 在大多数情况下，方法 B 消耗的内存比方法 A 多，大约是 1.2 到 1.5 倍。然而，在 CoLA 数据集上，当方法 B 的内存消耗是方法 A 的 2.2 倍时，会出现一个奇怪的模式。 我需要在报告中解释这一点，但没能找出原因。希望你们能给我一些有效调试问题的方法。这是我第一次探索 NLP 以及高效 GPU 的概念。  以下是我尝试过的方法： - 首先，2 种方法的数据预处理相同，并且所有数据集都具有相同的 batch_size 和 max_seq_length。 - 我能够找到方法 B 中导致内存增加的行，因为在方法 B 中我使用“torch.bmm”替换方法 A 中的“F.linear”。但是，我无法解释为什么每个数据集的内存使用情况不同。我做了一些研究，很多人说 torch.bmm 仍然是内存高效的。 谢谢大家阅读！    提交人    /u/ma-d-ghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h207uy/how_to_explain_the_memory_usage_of_gpu/</guid>
      <pubDate>Thu, 28 Nov 2024 16:51:14 GMT</pubDate>
    </item>
    <item>
      <title>寻求建议：我可以训练机器学习模型来预测代币价格趋势吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1z6jd/seeking_advice_can_i_train_an_ml_model_to_predict/</link>
      <description><![CDATA[大家好！ 我是一名开发人员，但从未研究过 ML，但我一直在集思广益一个项目想法，并希望从社区获得一些关于其可行性的反馈。以下是概念： • 使用部署在特定 DEX（或多个）上的代币的所有链上交易和价格行为训练机器学习模型（可能类似于 TensorFlow？）。 • 为其提供新推出的代币上周交易的数据，并要求其预测其价格是否有可能升值。 • 输出将是基于显示类似趋势的先前代币，代币价格上涨或下跌的百分比可能性。 它不需要完美 - 只要足够准确，就可以作为交易者做出明智决策的附加工具。 问题：  这个想法可行吗？  您认为结果的准确度如何？ 训练这样的模型会不会非常昂贵？ 构建起来有多复杂，需要多长时间？ 模型训练完成后，处理新标记的预测需要多长时间？  提前致谢！    提交人    /u/bco3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1z6jd/seeking_advice_can_i_train_an_ml_model_to_predict/</guid>
      <pubDate>Thu, 28 Nov 2024 16:04:53 GMT</pubDate>
    </item>
    <item>
      <title>在 GenAI 应用程序中使用内存图形数据库进行 GraphRAG</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1yt2j/using_an_inmemory_graph_database_for_graphrag_in/</link>
      <description><![CDATA[大家好！我注意到这里有很多关于处理小众数据集以构建智能系统（如 GenAI 应用）的帖子。无论是法律文档、医疗数据集还是专有代码库，挑战始终是相同的：如何在不超负荷 LLM 或花费大量资金进行微调的情况下实现有意义的知识发现？ 我在 Memgraph 工作（完全披露），几个月来我们一直在研究检索增强生成 (RAG) 系统。RAG 将 LLM 与知识图谱配对以动态检索相关上下文，因此模型只处理重要内容。它速度更快、可扩展且能适应实时数据变化。 例如：  Cedars-Sinai 使用 Memgraph 进行医疗保健风险预测。 Precina Health 利用 GraphRAG 彻底改变糖尿病护理。  Memgraph 与 LangChain 和 LlamaIndex 等工具集成，甚至提供向量搜索、深度路径遍历和流数据提取等功能。它位于内存中，因此速度非常快。 想知道其他人如何将他们的数据与 GenAI 应用程序集成。您将 LLM 与结构化和非结构化数据相结合的方法是什么？有关 Memgraph 的 GraphRAG 生态系统的更多详细信息，请参见此处。    提交人    /u/l7feathers   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1yt2j/using_an_inmemory_graph_database_for_graphrag_in/</guid>
      <pubDate>Thu, 28 Nov 2024 15:47:54 GMT</pubDate>
    </item>
    <item>
      <title>如何处理任务</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1ymtz/how_to_approach_task/</link>
      <description><![CDATA[我有少量高质量数据 标签是 1-5 的整数 数据点有 100 多个 我有许多特征（100 多个），并非所有特征都一定相关，而且许多特征通常为零 我的目标是使用这些特征或其中的子集来预测标签 关于如何在如此少的数据上训练有效模型，您有什么想法吗？ 我不确定使用连续可微运算符（如软加或 tanh 激活函数）并尝试预测精确的连续值（即只有一个输出是标量）是否更容易 或者我是否应该输出一个大小为 5 的向量，其概率分布在最可能的得分上 也许使用一些更传统的 ml 方法对此更好 - 即 svm  任何建议都有帮助     由    /u/proturtle46 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1ymtz/how_to_approach_task/</guid>
      <pubDate>Thu, 28 Nov 2024 15:39:48 GMT</pubDate>
    </item>
    <item>
      <title>我应该研究哪些主题才能在软件开发工作中为人工智能项目做出贡献？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1xise/what_kind_of_topics_should_i_study_to_contribute/</link>
      <description><![CDATA[我是一名软件工程师，负责开发配置和编程稳压器 IC 的应用程序。公司内部有一项计划，将 AI 整合到我们的软件中，以提高客户的利益。特别是，我们可以访问来自所有不同客户配置的数据，以便将他们期望的行为编程到我们的 IC 中。我的老板让我探索创建 AI 功能的想法，以添加到我们的软件中，特别是通过利用来自这些配置的数据。了解客户如何配置这些 IC 可能有助于我们更好地设计 IC 以及我们编写的用于编程的软件。 我有一些在线 AI 课程的经验，但我想开始多学习一点，重点是能够从这些配置中获取数据并获得有用的见解。您建议学习哪些类型的主题来培养制作类似产品所需的技能？特别是，如果您推荐任何课程或书籍，我们将不胜感激。    提交人    /u/Occupy_Mars   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1xise/what_kind_of_topics_should_i_study_to_contribute/</guid>
      <pubDate>Thu, 28 Nov 2024 14:47:58 GMT</pubDate>
    </item>
    <item>
      <title>机器学习和 Microsoft Fabric</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1wugc/ml_microsoft_ffabric/</link>
      <description><![CDATA[你们当中有人用过 Microsoft Fabric 进行机器学习吗？它有什么缺点/优势？    提交人    /u/vtimevlessv   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1wugc/ml_microsoft_ffabric/</guid>
      <pubDate>Thu, 28 Nov 2024 14:14:36 GMT</pubDate>
    </item>
    <item>
      <title>寻找学习 kubernetes 的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1wegu/looking_for_resources_to_learn_kubernetes/</link>
      <description><![CDATA[大家好，我正在寻找学习机器学习 kubernetes 基础知识的资源。我的最终目标是运行 kubeflow 管道     提交人    /u/Relative_Rope4234   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1wegu/looking_for_resources_to_learn_kubernetes/</guid>
      <pubDate>Thu, 28 Nov 2024 13:52:14 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能真正建立一个真正的项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1uswb/how_can_i_really_build_a_real_project/</link>
      <description><![CDATA[最近，我一直在研究 ML 和 DL 背后的理论，但老实说，我花了几乎 0 分钟来编码。 接下来，我想开始使用 PyTorch 构建一些真实的东西，我可以把它放在我的简历上。同时试图弄清楚我应该学习哪些其他工具 - 比如 Cloud、Hugging Face、Git、Docker、API 等。 问题是，我找到的所有课程要么不断地谈论房价预测，要么只是展示一些随机的 PyTorch 代码而没有做任何实际的事情。 有人能帮我吗？专注于构建实际项目的课程、书籍或资源？    提交人    /u/Shams--IsAfraid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1uswb/how_can_i_really_build_a_real_project/</guid>
      <pubDate>Thu, 28 Nov 2024 12:23:10 GMT</pubDate>
    </item>
    <item>
      <title>DS/ML 和应用科学面试怎么会比 SWE 面试难这么多呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1h1rsjw/how_can_dsml_and_applied_science_interviews_be/</link>
      <description><![CDATA[我与亚马逊进行了最后 5 轮应用科学面试。 每轮面试内容如下：（每轮 1 小时，单日面试）  ML 广度（所有经典 ML 和 DL，所有内容都将进行一定深度测试，+ 数学推导） ML 深度（深入研究您的一般研究领域/或切线，激烈的质问） 编码（ML Algos 编码 + Leetcode 媒介） 科学应用：ML 系统设计，解决一些广泛的问题 行为：Bar Raiser 就领导原则进行 1.5 小时质问  您需要对 ML 中无限数量的概念有广泛而深入的知识，并且能够回忆和准确地重现它们，包括数学。 这么多本身基本上是不可能实现的（特别是对于像我这样记忆力和回忆能力较差的人来说）。 即使在您的研究领域（这本身就是一个巨大的领域），也可能有大量问题或整个领域您一无所知。 + 您需要与 SWE 2 相同级别的编码。 ______ 而这正是包括亚马逊在内的几乎所有公司中的 SWE 所需要的： - Leetcode 练习。 - 如果是高级，则进行系统设计。 我很擅长 Leetcode - 它是临时思考和解决问题的。即使没有练习，我在编码测试中也做得很好，通过练习，你基本上可以看到大多数问题和模式。 我根本不擅长记住软边缘支持向量机的晦涩理论细节，然后突然跳到为什么 RLHF 有问题，将 LLM 与人类偏好相结合，然后被告知从头开始在 PyTorch 中编写稀疏注意力 ______ 最糟糕的是，在掌握了这么多知识并付出了这么多努力之后，得到的报酬是一样的。即使是工作也要困难 100 倍，因为你可能需要做的事情种类繁多。 与此相反，你通常会作为 SWE 拥有一套专业知识，在某个领域建立明确的能力，并且总是可以毫无问题地跳到任何只需要这些而不需要其他任何东西的工作中。    提交人    /u/anotheraccount97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1h1rsjw/how_can_dsml_and_applied_science_interviews_be/</guid>
      <pubDate>Thu, 28 Nov 2024 08:51:21 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>