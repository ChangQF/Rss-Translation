<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 17 Sep 2024 12:31:14 GMT</lastBuildDate>
    <item>
      <title>我想开始学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fixw0y/i_want_to_start_learning_machine_learning/</link>
      <description><![CDATA[大家好，我刚从 IT 毕业，最近对非技术性的东西感兴趣，但现在，我对学习机器学习更感兴趣，我希望在 AI 领域建立一些东西，可能将其打造为一家初创公司的产品。但我对编码技能知之甚少，即 C 和 C++。请问您对我应该从哪里开始学习有什么建议，也许可以给我一些指导或建议。    提交人    /u/sophisticated0x   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fixw0y/i_want_to_start_learning_machine_learning/</guid>
      <pubDate>Tue, 17 Sep 2024 12:28:21 GMT</pubDate>
    </item>
    <item>
      <title>适合机器学习的优质音频资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fixuhz/good_audio_resources_for_ml/</link>
      <description><![CDATA[大家好，我已经尝试学习 ML 一段时间了，尽管我还是个初学者。我想知道你们能否推荐一些好的音频资源，用于学习或只是更好地了解这个领域。我必须经常旅行，而且大部分旅程需要 8-9 个小时。我想利用这段时间听一些可以增加我知识的东西。 谢谢     提交人    /u/NF_laidback   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fixuhz/good_audio_resources_for_ml/</guid>
      <pubDate>Tue, 17 Sep 2024 12:26:17 GMT</pubDate>
    </item>
    <item>
      <title>3Blue 1Brown 制作的精彩视频解释了神经网络。对我这样的业余爱好者很有帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fiw5qa/amazing_video_by_3blue_1brown_explaining_neural/</link>
      <description><![CDATA[https://youtu.be/aircAruvnKk?feature=shared    由   提交  /u/Needy_Panda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fiw5qa/amazing_video_by_3blue_1brown_explaining_neural/</guid>
      <pubDate>Tue, 17 Sep 2024 11:00:46 GMT</pubDate>
    </item>
    <item>
      <title>微调dinov2</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fivld0/finetune_dinov2/</link>
      <description><![CDATA[有人用过 dinov2 嵌入吗？我正在尝试为我的数据集生成可靠的嵌入，以进行图像相似性搜索。Dinov2 在 90 个案例中有 3 个不起作用。我的数据集是绘画图像。所以我想对它进行微调。有没有办法在不标记数据和不对其进行分类的情况下微调模型。我不需要分类器头，我只希望模型学习我的图像并给我更好的嵌入。这可能吗？我写了一个脚本，但它不起作用，所以我想知道我是否应该继续进行下去。    提交人    /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fivld0/finetune_dinov2/</guid>
      <pubDate>Tue, 17 Sep 2024 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>获得机器学习相关实习机会的路线图</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fivbsg/roadmap_to_land_a_ml_related_internship/</link>
      <description><![CDATA[大家好。我是一名机器人和人工智能专业的学生，​​即将开始大学二年级的学习。我迫切地想找到暑期实习机会，我想提高自己的技能和履历。我该从哪里开始呢？哪些项目能让我脱颖而出？请帮帮我    提交人    /u/Only-Way-8840   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fivbsg/roadmap_to_land_a_ml_related_internship/</guid>
      <pubDate>Tue, 17 Sep 2024 10:12:07 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将句子嵌入转换为张量以用于单词生成？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fiu2oo/is_it_possible_to_convert_a_sentence_embedding/</link>
      <description><![CDATA[我正在尝试找出一种基于新词在模型中的嵌入方式来查找新词的方法。我的目标是嵌入一个词，修改嵌入，然后返回一个接近新嵌入位置的新词。这个想法来自于图像，图像中国王 - 王后、男人 - 女人之间的距离相似。 阅读句子转换器和编码过程，编码是将单词嵌入到模型的 768 个维度中。然后可以通过余弦相似度计算将嵌入与其他嵌入进行比较。嵌入不具有任何转换回单词的方法。 需要的是一个句子生成器，它经过训练，可以根据所讨论的模型从嵌入中生成单词。环顾四周，我发现大多数都遵循输入标记样式的编码，其中一个输入文本，模型执行编码和标记生成。 我找不到关于嵌入和生成单词的讨论，所以我真的不知道这是否可能。  copilot 试图将一些代码作为我的问题的答案，copilot 似乎确信我所问的问题 100% 可能，无论代码多么不起作用 from sentence_transformers import SentenceTransformer from transformers import GPT2LMHeadModel model = SentenceTransformer(&#39;paraphrase-MiniLM-L6-v2&#39;) vector_1 = model.encode(&quot;hello&quot;) vector_2 = model.encode(&quot;world&quot;) t_vector = vector_1 - vector_2coded_tensor = torch.tensor(encoded_word).unsqueeze(0) gpt2_model = GPT2LMHeadModel.from_pretrained(&quot;GPT2&quot;) with torch.no_grad(): output = gpt2_model.generate(input_ids, max_length=50, num_return_sequences=1, do_sample=True,coder_outputs=encoded_tensor) generated_text = tokenizer.decode(outputs[0],skip_special_tokens=True)     提交人    /u/Low-Information389   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fiu2oo/is_it_possible_to_convert_a_sentence_embedding/</guid>
      <pubDate>Tue, 17 Sep 2024 08:50:23 GMT</pubDate>
    </item>
    <item>
      <title>扩散引导语言建模论文细目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitrqr/diffusion_guided_language_modelling_paper/</link>
      <description><![CDATA[        提交人    /u/RamboCambo15   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitrqr/diffusion_guided_language_modelling_paper/</guid>
      <pubDate>Tue, 17 Sep 2024 08:30:06 GMT</pubDate>
    </item>
    <item>
      <title>我如何为法学硕士 (LLM) 提供大量背景信息？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</link>
      <description><![CDATA[大家好！ 我的问题是如何向 LLM 提供超出提示的大量上下文信息。我想知道使用 RAG 是否可以做到这一点？目标是创建一个学习助手。LLM 需要大量有关学习内容（理想情况下是学习状态）的信息。理想的做法是提供完整聊天记录的上下文信息，而不是通过 RAG 为每个答案再次查询必要的信息并将其作为提示提供给 LLM。 除了在具有相应学习内容的数据集上训练 AI 或使用 RAG 查询信息之外，还有其他选择吗？    提交人    /u/Maleficent_Bus_994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</guid>
      <pubDate>Tue, 17 Sep 2024 08:24:01 GMT</pubDate>
    </item>
    <item>
      <title>好的图形数据库选项？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fit348/good_graph_database_options/</link>
      <description><![CDATA[我正在尝试构建一个 graphRAG 并使用其图形数据库，到目前为止，所有内容都指向 neo4j。我们还有其他更好、更适合生产的选项吗？    提交人    /u/Aromatic_Ad9700   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fit348/good_graph_database_options/</guid>
      <pubDate>Tue, 17 Sep 2024 07:43:40 GMT</pubDate>
    </item>
    <item>
      <title>在家用电脑上运行 LLM：Llama 3.1 70B，压缩 6.4 倍，大小 22 GB</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</link>
      <description><![CDATA[大家好！想分享一些可能有助于您了解和试验 LLM 的内容。最近，我们使用 PV-Tuning 方法成功压缩了 Llama 3.1 70B 和 Llama 3.1 70B Instruct。 结果如下： - 压缩率：6.4 倍（从 141 GB 到 22 GB） - 质量保留：Llama 3.1-70B（MMLU 0.78 -&gt; 0.73），Llama 3.1-70B Instruct（MMLU 0.82 -&gt; 0.78） 我们实际上对 Llama 3.1 8B 模型做了同样的事情。根据[此](https://blacksamorez.substack.com/p/aqlm-executorch-android?r=49hqp1&amp;utm\_campaign=post&amp;utm\_medium=web&amp;triedRedirect=true) 工作证明，它现在可以在 RAM 少于 2.5 GB 的 Android 上运行。因此，您现在可以离线部署它，而无需共享您的数据。  您可以在此处找到结果并下载压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-AQLM-PV-2Bit-1x16-hf https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-Instruct-AQLM-PV-2Bit-1x16-hf    提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</guid>
      <pubDate>Tue, 17 Sep 2024 06:57:47 GMT</pubDate>
    </item>
    <item>
      <title>大家好。我想写一篇关于使用机器学习预测心脏病的硕士论文。这是一个好主题吗？我能提出什么新观点？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1firzyf/hello_everyone_i_want_to_write_a_masters_thesis/</link>
      <description><![CDATA[  由    /u/Spiritual_Food_2962  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1firzyf/hello_everyone_i_want_to_write_a_masters_thesis/</guid>
      <pubDate>Tue, 17 Sep 2024 06:32:17 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习的书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</link>
      <description><![CDATA[此帖是我对 reddit 不让我评论某人帖子的报复。他们想要学习机器学习的建议。他们是物理学毕业生。如果这对某些人不相关，我深表歉意 机器学习领域分为许多领域，但最突出的是深度学习、计算机视觉和自然语言处理。如果您想要深入研究某个特定领域，我或其他人肯定可以提供更具体的建议，话虽如此，已经有一些通用书籍出版，旨在涵盖AI（人工智能）的广度，其中最好的两本是-  深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书可从此处免费获取） 人工智能：一种现代方法（pearson.com）  这两本书试图涵盖人工智能领域的所有内容。虽然第一本书能让你真正理解和欣赏人工智能创新背后的启发式和直觉思维，但第二本书只会让你意识到人工智能思维的起源，可以追溯到亚里士多德。 现在，以上两本书都不会给你实践课程，我不推荐“实践”书籍。事实上，机器学习算法非常容易实现，只需几行 python/c++（一个算法可能需要 10 行到 100 行代码 - 无论如何都不是很多）。所以，一个好的策略是先学习 python（如果你还没有）-&gt;了解该领域并学习数学（并行），然后在学习 pytorch 的同时实现每个算法。既然你已经了解数学，我建议你阅读深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书免费这里）和/或我下面要提到的书籍。 下面的书都不是废话，只是数学和可视化书籍，作为物理学毕业生，你可能很容易理解。  计算智能：方法论介绍 | SpringerLink（我最喜欢的一本介绍神经网络、进化算法和模糊逻辑的书）。 （免费）模式识别和机器学习 (microsoft.com)（广受好评的“统计学习方法”书籍。 （免费）深入学习 — 深入学习 1.0.3 文档 (d2l.ai)（迄今为止学习深度学习的最佳书籍）。它有理论和代码）。  基于相关领域的其他书籍：  计算机视觉：算法和应用，第二版。 （szeliski.org） 计算机视觉：一种现代方法：Forsyth，David，Ponce，Jean：9780136085928：Amazon.com：图书  （注：CV（我认为通过视频课程学习计算机视觉效果更好）  统计自然语言处理基础（stanford.edu） 强化学习（mit.edu）     由   提交  /u/reacher1000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</guid>
      <pubDate>Tue, 17 Sep 2024 03:56:40 GMT</pubDate>
    </item>
    <item>
      <title>您推荐哪些机器学习工具来增强 AI 生成的内容？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fin7ua/what_machine_learning_tools_do_you_recommend_for/</link>
      <description><![CDATA[我很好奇哪些机器学习工具可以增强 AI 生成的内容。我听说过 Fleak，想知道以前是否使用过它，以及它与市场上的其他工具相比如何？    提交人    /u/Designer_Usual1786   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fin7ua/what_machine_learning_tools_do_you_recommend_for/</guid>
      <pubDate>Tue, 17 Sep 2024 02:16:42 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习时令我烦恼的事情。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fi1z5x/the_thing_that_bugs_me_about_learning_machine/</link>
      <description><![CDATA[学习机器学习有时会令人沮丧，因为它常常不像解决问题，而更像是“算法学习”。这意味着我正在学习别人对某个问题的思考方式。 例如，我正在学习小样本学习的概念。这个概念非常笼统：假设您只有来自训练集的几个示例，您如何训练分类器以成功识别新的测试图像。 如果我将这个问题交给对机器学习有最低限度了解的人，那个人可能会将这个问题定义为生成与这几个示例相关的高质量示例。我的意思是，如果您可以生成更多示例，那么示例数量就不再是问题。直观，对吧？ 但这种直观的方法并不是人们通常开始解释机器学习的方法。例如，在我看过的一个视频中，作者说了这样的话：“你需要另一个预先训练好的深度神经网络……”或“小样本学习的解决方案是孪生神经网络”（为什么？？）。这似乎不是解决这个问题最直观的方法。相反，这是那一年一些研究人员采取的方法，不知何故成为了问题本身的决定性解决方案。 在学习机器学习时，我多次遇到过这个问题。任何问题/任务似乎都有一些预定义的现成解决方案。并不总是最直观的，或最有效的，甚至没有意义（就某些假设而言）。但不知何故，这种方法成为整个问题的决定性解决方案。话虽如此，有些解决方案（例如用于聚类的 Kmeans/Knn）比其他解决方案更直观。 再举一个例子，我鼓励你查找元学习。视频总是以“元学习就是学习如何学习”开头然后接着说“我们就是这样解决的”。如果你退一步思考一下“学习如何学习”作为一个人（例如，学习如何学习一门新语言），你很快就会意识到你的解决方案与机器学习文献中采用的方法大不相同。 我想知道你在学习机器学习的过程中是否遇到过这个问题，以及你是如何思考或处理它的。    提交人    /u/TorontoEarthquake   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fi1z5x/the_thing_that_bugs_me_about_learning_machine/</guid>
      <pubDate>Mon, 16 Sep 2024 11:18:05 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>