<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 28 Nov 2023 09:13:57 GMT</lastBuildDate>
    <item>
      <title>NLP 和 CV 哪个先</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185rfbj/which_one_first_nlp_or_cv/</link>
      <description><![CDATA[我已完成 nlp 和 cv 所需的机器学习。我还学习了一些文本预处理技术，还学习了 ANN 和 CNN。我喜欢 NLP 和 CV，并且我想两者都做。有很多问题我都需要。但我必须从一开始。那么，各位能告诉我先从哪一个开始吗？我会学习两者，但我必须从一个开始。 而且我不懂任何 SQL。 所以，任何人都可以知道哪一个最适合初学者。请记住，我的目标是学习两者。   由   提交 /u/CodingWithSatyam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185rfbj/which_one_first_nlp_or_cv/</guid>
      <pubDate>Tue, 28 Nov 2023 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>从哪儿开始？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185qksg/where_to_start/</link>
      <description><![CDATA[我在完全不同的领域拥有 2 年的 IT 经验，对机器学习感兴趣，有什么建议我可以从哪里开始，因为我擅长数学和 Python好吧   由   提交 /u/Rangaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185qksg/where_to_start/</guid>
      <pubDate>Tue, 28 Nov 2023 07:39:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 simplet5 并调用“model.train”方法时出现“AttributeError：'LightningDataModule'对象没有属性'_has_setup_TrainerFn.FITTING”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185pv50/getting_attributeerror_lightningdatamodule_object/</link>
      <description><![CDATA[``` GPU 可用：False，已用：False TPU 可用：False，使用：0 个 TPU 内核 IPU 可用：False，使用：0 个 IPU&lt; /p&gt;  AttributeError Traceback (最近一次调用最后一次) Cell In[11], line 2 1 # train ----&gt; 2 model.train(train_df=train_df, # 2 列的 pandas 数据框: source_text &amp; target_text 3 eval_df=eval_df, # 2 列的 pandas 数据框: source_text &amp; target_text 4 source_max_token_len = 512, 5 target_max_token_len = 128, 6 batch_size = 8 , 7 max_epochs = 3, 8 use_gpu = False, 9 ) 文件 ~/projects/nlprocessing/env/lib/python3.11/site-packages/simplet5/simplet5.py:395，在 SimpleT5 中。火车（自我，train_df，eval_df，source_max_token_len，target_max_token_len，batch_size，max_epochs，use_gpu，outputdir，early_stopping_patience_epochs，精度，记录器，dataloader_num_workers，save_only_last_epoch）385训练器= pl.Trainer（386记录器=记录器，387回调=回调，（ .. .) 391 log_every_n_steps=1, 392 ) 394 # 健身教练 --&gt;第395章 训练师.fit（self.T5Model，self.data_module） Trainer.fit(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path) 735rank_zero_deprecation( 736 &quot;trainer.fit(train_dataloader) 在 v1.4 中已弃用，并将在 v1 中删除。 6.”737”使用trainer.fit(train_dataloaders)代替。提示：添加了“s””738) 739 train_dataloaders = train_dataloader --&gt;第740章 741、第741章 741、第741章/trainer.py:685，在 Trainer._call_and_handle_interrupt(self, trainer_fn, args, *kwargs) 675 r&quot;&quot;&quot;第676章 错误处理，仅用于主训练器函数入口点（拟合、验证、测试、预测） 第677章 因为所有错误都应该通过它们（...）第683章 683第684章 试试：--&gt;第685章 686、第686章nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:777，在 Trainer._fit_impl(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path) 775 # TODO: ckpt_path 仅在 v1 中。第7776章 ckpt_path = ckpt_path或self.resume_from_checkpoint --&gt;第777章 779 断言 self.state.stopped 780 self.training = False pytorch_lightning/trainer/trainer.py:1138，在 Trainer._run(self, model, ckpt_path) 1136 self.call_hook(“on_before_accelerator_backend_setup”) 1137 self.accelerator.setup_environment() -&gt;第1138章 self._call_setup_hook() # 允许用户在加速器环境中设置lightning_module 第1140章 检查是否应该延迟恢复检查点直到稍后 1141 if not self.training_type_plugin.restore_checkpoint_after_pre_dispatch: File ~/projects/nlprocessing/env /lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1438，在 Trainer._call_setup_hook(self) 1435 self.training_type_plugin.barrier(“pre_setup”) 1437 如果 self.datamodule 不是 None：- &gt;第1438章 1439章 1441章 1441章/env/lib/python3.11/site-packages/pytorchlightning/core/datamodule.py:461，在 LightningDataModule._track_data_hook_calls..wrapped_fn(args, *kwargs ) 459 else: 460 attr = f&quot;_has{name}_{stage}&quot; --&gt; 461 has_run = getattr(obj, attr) 462 setattr(obj, attr, True) 464 elif name == &quot;prepare_data&quot;: AttributeError: &#39;LightningDataModule&#39; 对象没有属性 &#39;_has_setup_TrainerFn.FITTING`` `   由   提交 /u/Downtown-Rice-7560   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185pv50/getting_attributeerror_lightningdatamodule_object/</guid>
      <pubDate>Tue, 28 Nov 2023 06:50:39 GMT</pubDate>
    </item>
    <item>
      <title>用于评估计算机科学学习资源的数据集</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185pqym/dataset_for_evaluating_computer_science_learning/</link>
      <description><![CDATA[嘿社区， 我正在开展一个项目来评估计算机科学学习资源的质量，但我努力寻找标记数据集（已在 Kaggle 和 UCI ML 存储库上搜索）。关于在哪里可以找到一个或如何有效地创建它有什么建议吗？接受建议。非常感谢您的见解！   由   提交/u/sudo_ManasT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185pqym/dataset_for_evaluating_computer_science_learning/</guid>
      <pubDate>Tue, 28 Nov 2023 06:42:53 GMT</pubDate>
    </item>
    <item>
      <title>我是否犯了 GPU 错误？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185peoj/am_i_making_a_gpu_mistake/</link>
      <description><![CDATA[对于看到此内容的任何人，我们将不胜感激。 ​ I&#39;我正在尝试为生成式 AI 项目制作一个装备，重点是视觉效果（还不确定我要使用什么 LLM），而 Radeon M100 卡似乎非常适合我的构建。它们使用时很便宜，所以我可以用假设更好的单显卡的价格购买其中的两个，而且它们的 32GB VRAM 似乎是一个坚实的卖点。但是，由于某种我看不到的原因购买这种 GPU 会不会是一个错误？  ​ 就上下文而言，如果有帮助的话，我的目标是使用新的 Ryzen 7000 系列 CPU 和与之匹配的主板。 PCIe 5.0 是对于 MI100 来说有点大材小用，但我读到两个 PCIe 5.0 x8 插槽将模仿两个 PCIe4.0 x16 插槽的性能（这超出了这些 GPU 的规格）。   由   提交 /u/Gamer-C   /u/Gamer-C  reddit.com/r/learnmachinelearning/comments/185peoj/am_i_making_a_gpu_mistake/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185peoj/am_i_making_a_gpu_mistake/</guid>
      <pubDate>Tue, 28 Nov 2023 06:21:03 GMT</pubDate>
    </item>
    <item>
      <title>2024 年适合所有人的 12 门 Coursera 免费机器学习课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185orm7/12_best_coursera_free_courses_machine_learning/</link>
      <description><![CDATA[   /u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185orm7/12_best_coursera_free_courses_machine_learning/</guid>
      <pubDate>Tue, 28 Nov 2023 05:40:22 GMT</pubDate>
    </item>
    <item>
      <title>在 Transformer 模型上遇到梯度消失问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185jx2j/running_into_vanishing_gradient_on_transformer/</link>
      <description><![CDATA[大家好！抱歉，如果我在这里遗漏了一些完全明显的东西，但我在使用一个非常简单的变压器模型时遇到了一些问题，该模型正在对推文进行情感分类训练。我这样做只是作为变压器的最小可行示例，以便我可以更好地理解它们。我还使用 PyTorch 内置的 nn.Transformer。 通过阅读一些文献，我发现 Transformer 如此出色的部分原因是因为你可以使它们变得非常深，而不会遇到梯度消失的情况。然而，在我的模型中，如果我使编码器/解码器层的数量大于 1，我就会遇到梯度消失的情况（平均梯度幅度约为 1e-10 到 1e-12，并且损失根本不会减少）。当我只运行 1 层模型时，我倾向于看到平均只有 1e-8 梯度幅度，这是非常小的，但模型似乎仍在学习。 这导致我遇到第二个问题..模型确实学习了，但仅在一两个时期之后，训练和验证损失似乎出现了分歧，表明模型过度拟合。我的模型如此快地过度拟合，这似乎不太正确。 一些特别说明：我正在使用 AMP 优化。我尝试删除它，看看这是否会扰乱我的渐变。事实并非如此。 完全披露：这是一个学校项目，但我的模型的表现与我的成绩不相关。我问这个问题不是为了分数，而是因为我想了解这些东西是如何工作的以及我哪里出错了。 如果有人想查看更详细的细节，这里是代码（我会重点关注train_transformer.py、src/transformer.py和src/utils.py）https://github.com/NoahSchiro/cs448_final。有问题的数据集是 https://www.kaggle.com/code/paoloripamonti/twitter-sentiment -analysis/input 我的猜测是，变压器模型对于手头的任务来说太过强大，这就是为什么我看到非常快的收敛/梯度消失。任何帮助是极大的赞赏！    由   提交 /u/NoahSchiro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185jx2j/running_into_vanishing_gradient_on_transformer/</guid>
      <pubDate>Tue, 28 Nov 2023 01:27:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中实现软最近邻损失</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185jdzp/implementing_soft_nearest_neighbor_loss_in_pytorch/</link>
      <description><![CDATA[您好！我已经有一段时间没有写博客了。我写了两篇博客，内容如下： - 通过解缠改进 k 均值聚类：https://medium.com/@afagarap/improving-k-means-clustering-with-disentanglement-caf59a8c57bd - 在 PyTorch 中实现软最近邻损失：https://medium.com/@afagarap/implementing-soft-nearest-neighbor-loss-in-pytorch-b9ed2a371760 第一篇文章涵盖了我在 IJCNN 2020 中发表的论文，而第二篇文章是关于实现我们在参考论文中提出和扩展的损失函数的分步教程。 我希望您喜欢阅读它们。谢谢！   由   提交/u/afagarap  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185jdzp/implementing_soft_nearest_neighbor_loss_in_pytorch/</guid>
      <pubDate>Tue, 28 Nov 2023 01:02:45 GMT</pubDate>
    </item>
    <item>
      <title>关于多头LLM自我关注的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185ibbr/question_regarding_multi_head_llm_self_attention/</link>
      <description><![CDATA[嗨，我刚刚开始学习 Transformer 架构，有一个问题：  当多头时自注意力计算 Q、K 的点积，你会得到一个注意力分数，同一个单词对齐的对角线没有有害影响，因为它是均匀分布的，但这不会与软最大尺度混淆，为什么每个单词都与本身？ （已编辑） 我们难道不想标准化相同单词计算之间的对角线吗，否则注意力分数会放大单词 -&gt;词，这会稀释注意力分数乘积？ GPT 说变压器依靠权重的差异来确定注意力模式，但它值得探索（我想特别是当变压器拾取这个值时）模式本身）？    由   提交 /u/JakeN9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185ibbr/question_regarding_multi_head_llm_self_attention/</guid>
      <pubDate>Tue, 28 Nov 2023 00:14:23 GMT</pubDate>
    </item>
    <item>
      <title>2D 图像/网站/UI 中的模式识别/对象检测</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185hq9x/pattern_recognition_object_detection_in_2d_images/</link>
      <description><![CDATA[      我想编写一个程序，其中输入类似于网站的屏幕截图，输出是以下位置的坐标已识别的物体。例如按钮。 用例是自动化 UI 测试。 ​ https://preview.redd.it/yzj2cwnq7z2c1.png?width=2048&amp;format=png&amp;auto=webp&amp;s=e1e133a33f0c1e15b9f5eb205638d253fc 6fcdec 或者窗口按钮： ​ https://preview.redd.it/v9ypg29g9z2c1.png?width=300&amp;format=png&amp;auto=webp&amp;s=5a6fd21a4ded8c1f4bc031605922193f37b4ed08 我正在考虑使用YOLOv8，但我也认为这可能有点矫枉过正，而且旧的方法需要更少的资源并且运行推理更快。 我有什么选择？这些选项与 YOLOv8 相比如何？我认为 YOLOv8 更通用，更强大，更健壮，但资源更昂贵？ ​    ;由   提交 /u/GeniusPengiun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185hq9x/pattern_recognition_object_detection_in_2d_images/</guid>
      <pubDate>Mon, 27 Nov 2023 23:49:10 GMT</pubDate>
    </item>
    <item>
      <title>如果我有该主题的背景，我应该参加哪门 Udemy 数据科学/机器学习课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185fdac/which_udemy_data_scienceml_course_should_i_take/</link>
      <description><![CDATA[ 由   提交 /u/daymanAHAHahhhhhh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185fdac/which_udemy_data_scienceml_course_should_i_take/</guid>
      <pubDate>Mon, 27 Nov 2023 22:11:23 GMT</pubDate>
    </item>
    <item>
      <title>这个计算机视觉项目的最佳方法是什么</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185f2fo/what_would_be_the_best_approach_to_this_computer/</link>
      <description><![CDATA[构建可分析视频的非常小的细节的计算机模型的最佳方法是什么。诸如在视频中注意到小肿瘤或病变等细节。  是否可以进行实时或事后分析？什么算法最能在每一帧中有效地识别肿瘤？如果有任何帮助，我将不胜感激，谢谢   由   提交/u/the__mess1ah  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185f2fo/what_would_be_the_best_approach_to_this_computer/</guid>
      <pubDate>Mon, 27 Nov 2023 21:59:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性回归不能解决分类问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185cbk8/why_doesnt_linear_regression_work_on/</link>
      <description><![CDATA[你好。我是机器学习的初学者。我试图真正理解为什么线性回归不适用于分类问题。  我经常给出这样的答案：“它预测连续值”或“找到最佳拟合线”或类似的东西。  这对我来说很难直观地理解，并且我已经尝试弄清楚这一点已经超过三周了。  我正在研究泰坦尼克号数据集并尝试使用线性回归，但我什至不知道如何使其与线性回归一起工作。  我知道这不是 LR 的目的，但我只是想真正看到并理解为什么会这样。  如果可能的话，像个新手一样解释一下。没有复杂或隐性的语言   由   提交 /u/Ok_Tumbleweed8796   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185cbk8/why_doesnt_linear_regression_work_on/</guid>
      <pubDate>Mon, 27 Nov 2023 20:10:35 GMT</pubDate>
    </item>
    <item>
      <title>探索即将到来的人工智能格局</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185910n/navigating_the_ai_landscape_on_the_horizon/</link>
      <description><![CDATA[我想现在我们大多数人都听过这样一句话：“人工智能不会取代工作，知道如何使用人工智能的人会取代那些会使用人工智能的人”  对于我们许多人来说，他们不是程序员或软件架构师，而是从事营销、会计、项目管理等工作的白领，我们到底应该开始学习什么？  我只能考虑了解一些基本概念（例如，什么是生成人工智能，什么是幻觉等），那里的大玩家及其关注点（例如，谁最擅长做文本）视频、图像生成等），也许还有一些关于提示优化的技巧，但仅此而已。  我没有看到差异化因素，因为所有这些都可以由任何人在一个下午学会，并且在网络上搜索“[我的职业]的人工智能最佳实践”就可以了。或者直接提示人工智能平台听起来也不太复杂。 这是全部还是我遗漏了什么？  &amp;# 32；由   提交 /u/YepYepisalifestyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185910n/navigating_the_ai_landscape_on_the_horizon/</guid>
      <pubDate>Mon, 27 Nov 2023 17:55:22 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle 比赛值得吗？ Kaggle大师的思考</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/185412g/are_kaggle_competitions_worth_it_ponderings_of_a/</link>
      <description><![CDATA[ 由   提交/u/ledmmaster  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/185412g/are_kaggle_competitions_worth_it_ponderings_of_a/</guid>
      <pubDate>Mon, 27 Nov 2023 14:20:34 GMT</pubDate>
    </item>
    </channel>
</rss>