<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 30 May 2024 01:02:43 GMT</lastBuildDate>
    <item>
      <title>没有资源来训练神经网络。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3qs2l/dont_have_the_resources_to_train_a_neural_network/</link>
      <description><![CDATA[我有一个包含 131 种不同水果的数据集，训练数据包含 65,000+ 100x100 图像。当我尝试训练我的 CNN 时，Google Collab 在我完成一个 epoch 之前就超时了。购买计算积分和使用高级 GPU 都无济于事。我没有办法在本地合理地训练这个模型，我该怎么办？ 我目前的计划是逐渐缩小我的训练数据，但无法训练整个数据集真是太糟糕了。我已经在 1-5 种水果的训练数据上测试了该模型，它运行良好。    提交人    /u/Background_Crazy2249   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3qs2l/dont_have_the_resources_to_train_a_neural_network/</guid>
      <pubDate>Thu, 30 May 2024 00:11:34 GMT</pubDate>
    </item>
    <item>
      <title>对翻译任务的 LLM 进行微调而不是微调专用模型是否有意义？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3pxpn/does_it_make_sense_to_finetune_an_llm_for/</link>
      <description><![CDATA[如果我对 llam3-8b-instruct 等 llm 进行微调，我可以通过两种方式进行推理：  使用采样和温度 使用束搜索  采样是 llm 通常使用的方式，例如适用于讲故事，但每次结果都不同，所以似乎不太适合翻译任务。   但问题是，如果我无论如何都要使用波束搜索，那么微调专用模型（如 madlad400）不是更好吗？   另外，我不知道如何使用 trl 的 SFTTrainer 进行自动评估，所以我不知道何时停止训练，所以这似乎是 seq2seq 模型的另一个优点，因为我可以轻松地使用 Seq2SeqTrainer 进行评估。    提交人    /u/Sadeghi85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3pxpn/does_it_make_sense_to_finetune_an_llm_for/</guid>
      <pubDate>Wed, 29 May 2024 23:31:14 GMT</pubDate>
    </item>
    <item>
      <title>用于多个二进制时间序列和非常长的预测的 Transformer</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3nq1h/transformer_for_multiple_binary_time_series_and/</link>
      <description><![CDATA[我得到了一个数据集，其中包含数千个二进制时间序列，每个序列都有一百个时间点。下面是该数据的一个示例： ID t1 t2 t3 t4 ... t100 A 1 0 0 0 1 B 1 0 1 0 0 C 1 1 0 0 0 D 1 1 1 1 0 E 1 0 1 1 1 ... 目标是针对每个 ID 预测接下来的 100、200 和 300 个时间点。 限制在于只能使用基于 Transformer 的时间序列模型。 鉴于这个目标和限制，我认为基于自回归 Transformer 的模型是提供如此长预测范围的预测的唯一方法（给定 100 个时间点的有限输入）。 哪种基于 Transformer 的时间序列模型架构最适合这个问题？哪种实现？ 感谢您对此的任何意见！    提交人    /u/_majom_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3nq1h/transformer_for_multiple_binary_time_series_and/</guid>
      <pubDate>Wed, 29 May 2024 21:51:53 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在分析财务报告方面已经比人类做得更好</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3l7ka/ai_is_already_better_at_analyzing_financial/</link>
      <description><![CDATA[  由    /u/Used-Bat3441  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3l7ka/ai_is_already_better_at_analyzing_financial/</guid>
      <pubDate>Wed, 29 May 2024 19:55:14 GMT</pubDate>
    </item>
    <item>
      <title>你建议对 ML 感兴趣的大学学生如何</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3kue0/how_would_you_recommend_going_through_college/</link>
      <description><![CDATA[来自好奇心的其他可选问题： 实习比研究机会更重要吗？学位的选择会显著影响你的职业道路吗？优先考虑机器学习的理论和数学密集型方面，而不是实际项目，还是反之亦然？在考虑你的未来时，你应该倾向于研究还是工程道路？最后，如果你想成功，最健康的心态是什么？    提交人    /u/ReasonableNectarine4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3kue0/how_would_you_recommend_going_through_college/</guid>
      <pubDate>Wed, 29 May 2024 19:39:18 GMT</pubDate>
    </item>
    <item>
      <title>训练文本转图像模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3hfzg/training_a_texttoimage_model/</link>
      <description><![CDATA[嗨，我是机器学习的新手，想知道在 RTX 4070 上使用数据集从头开始训练文本到图像的扩散模型是否可行，以及需要多长时间    提交人    /u/Consistent_Newt_1661   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3hfzg/training_a_texttoimage_model/</guid>
      <pubDate>Wed, 29 May 2024 17:15:02 GMT</pubDate>
    </item>
    <item>
      <title>关于扩散模型背后的数学问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3h0lb/questions_about_math_behind_diffusion_model/</link>
      <description><![CDATA[我理解我们在这里为变分下限添加了 KL 散度项，但有些地方我不太明白。 https://preview.redd.it/fvm4qvgyae3d1.png?width=1079&amp;format=png&amp;auto=webp&amp;s=68ed306891a19958b8e1e116e1468f8177d4cbda  这里`p_theta(x_1:T | x_0)` 为什么当 p 是逆过程并且它不知道 x_0 时我们要考虑 x_0？ 这些正确吗？ q(x_1:T | x_0) = q(x_1 | x_0)q(x_2 | x_1)q(x_3 | x_2) … q(x_T | x_T-1)  p_theta(x_1:T | x_0) = p_theta(x_1 | x_2)p_theta(x_2 | x_3) … p_theta(x_T-1 | x_T)  在阅读有关扩散模型的其他文档时，我发现方程式说  https://preview.redd.it/ameieq9qbe3d1.png?width=359&amp;format=png&amp;auto=webp&amp;s=2d2d70215b68e5d63cea687becaba5ae90e75058 我不明白这一点。 由于逆过程是 p_theta(x_t-1 | x_t)，我认为 p_theta(x_0:T) 应该是 p_theta(x_-1 | x_0)p_theta(x_0 | x_1)p_theta(x_1 | x_2) … p_theta(x_T-1 | x_T)。但为什么不是这样呢？为什么术语 p_theta(x_t) 没有任何条件？ 感谢您阅读长问题。    提交人    /u/Witty_Ad2022   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3h0lb/questions_about_math_behind_diffusion_model/</guid>
      <pubDate>Wed, 29 May 2024 16:57:02 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3f4xt/can_somebody_explain_this/</link>
      <description><![CDATA[      这是用于将电子邮件分类为垃圾邮件的多项事件模型。  这是 Andrew Ng 讲授的斯坦福 CS229 讲座 5。 不幸的是，讲座和笔记都没有帮助到我。 有人可以解释一下吗： i）数据的可能性以及这意味着什么？ ii）拉普拉斯平滑在这里究竟是如何工作的？ https://preview.redd.it/eh2gzzcexd3d1.png?width=607&amp;format=png&amp;auto=webp&amp;s=3c9964b79c9b76bd4a1b2306a0a63e15186e05c3 https://preview.redd.it/d9lub64dxd3d1.png?width=621&amp;format=png&amp;auto=webp&amp;s=9939cd9e915510eca65206c357358e5fb5d5d04d 谢谢！    提交人    /u/AccountRare   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3f4xt/can_somebody_explain_this/</guid>
      <pubDate>Wed, 29 May 2024 15:36:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要除以 n-1 而不是 n 来估计方差？贝塞尔校正的直观解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3clie/why_do_we_divide_by_n1_instead_of_n_to_estimate/</link>
      <description><![CDATA[    /u/Intelligent-Field-97   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3clie/why_do_we_divide_by_n1_instead_of_n_to_estimate/</guid>
      <pubDate>Wed, 29 May 2024 13:46:16 GMT</pubDate>
    </item>
    <item>
      <title>您发现哪些资源（书籍、课程、网站）对学习 ML 最有帮助？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d3a3ym/what_resources_books_courses_websites_have_you/</link>
      <description><![CDATA[这些信息对于初学者和希望扩展 ML 知识的有经验的人来说都非常有用。此外，它可以帮助我们找到最好的学习工具和策略。所以，让我们分享我们的经验吧。    提交人    /u/CodefinityCom   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d3a3ym/what_resources_books_courses_websites_have_you/</guid>
      <pubDate>Wed, 29 May 2024 11:40:46 GMT</pubDate>
    </item>
    <item>
      <title>理解 Transformer</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d392hr/understanding_transformers/</link>
      <description><![CDATA[      了解 Transformers https://medium.com/advanced-deep-learning/understanding-transformers-5291b0b75b2e?sk=8ce30daa88b1586092c31972542e37ef 我认为这有一些很好的可视化效果！     提交人    /u/Junior_Syllabub_3037   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d392hr/understanding_transformers/</guid>
      <pubDate>Wed, 29 May 2024 10:37:34 GMT</pubDate>
    </item>
    <item>
      <title>人工智能认证浪费时间</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d359cf/ai_certifications_are_a_waste_of_time/</link>
      <description><![CDATA[问题不在于认证是否会帮助您找到工作，而在于它是否具有市场信誉。 大多数工作不需要认证。 我向担任招聘经理的朋友问了同样的问题。 以下是他们的说法 → - 专业级认证通常缺乏实践专业知识。 - 通过认证考试通常会测试理论知识。 - 我们不仅关注候选人是否拥有认证。 认证在 MLOps 等专业领域更为重要 - 认证将具有价值，因为它告诉公司您了解特定的云平台，例如 GCP、AWS 或 Azure。 - 服务型公司通常会向客户展示云认证，以展示他们在云平台上的专业知识。 它将为他们带来业务。 AI 产品管理 [领导职位] - 没有人可以教您如何领导成功的 AI产品。 - 认证无助于解决现实世界的 AI 混乱。 - 85％的 AI 开发由于各种原因而失败。 我相信， 如果你有认证但在面试中没有回答问题，那么该认证就无关紧要。 如果您没有认证但在面试中回答了问题，那么认证再次无关紧要。    提交人    /u/hemansnation   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d359cf/ai_certifications_are_a_waste_of_time/</guid>
      <pubDate>Wed, 29 May 2024 06:07:44 GMT</pubDate>
    </item>
    <item>
      <title>前 OpenAI 董事会成员分享 Sam Altman 被解雇的详细信息</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d316j8/exopenai_board_member_shares_details_on_sam/</link>
      <description><![CDATA[      TED AI 节目的完整采访：http://link.chtbl.com/TEDAI    由    /u/imaginfinity 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d316j8/exopenai_board_member_shares_details_on_sam/</guid>
      <pubDate>Wed, 29 May 2024 02:08:32 GMT</pubDate>
    </item>
    <item>
      <title>嗯……看来 Elon 不知道 Yann LeCun 是谁。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d2to9d/umit_seems_elon_doesnt_know_who_yann_lecun_is/</link>
      <description><![CDATA[        提交人    /u/blablablabling   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d2to9d/umit_seems_elon_doesnt_know_who_yann_lecun_is/</guid>
      <pubDate>Tue, 28 May 2024 20:29:36 GMT</pubDate>
    </item>
    <item>
      <title>那么我们都同意埃隆马斯克是个骗子吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/</link>
      <description><![CDATA[        提交人    /u/blablablabling   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d2qd35/so_we_can_all_agree_that_elon_musk_is_a_fraud/</guid>
      <pubDate>Tue, 28 May 2024 18:20:06 GMT</pubDate>
    </item>
    </channel>
</rss>