<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Sun, 13 Oct 2024 15:16:29 GMT</lastBuildDate>
    <item>
      <title>为什么在这种情况下我需要使用 GloVe？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2rne8/why_do_i_need_using_glove_in_this_scenario/</link>
      <description><![CDATA[初学者警报  我正在构建情绪分析模型并对数据进行预处理，这是标记和填充后数据的样子： [[ 1, 2, 3, ..., 0, 0, 0], [ 51, 197, 198, ..., 0, 0, 0], [ 142, 281, 22, ..., 0, 0, 0],  这是模型代码： class BiRNN(nn.Module): def __init__(self, vocab_size, embed_size, num_hidden, num_layers): super (BiRNN, self).__init__() self.embedding = nn.Embedding(vocab_size, embed_size) # 包含 0 到 vocab_size - 1 之间数字的 len seq 向量 self.encoder = nn.LSTM(embed_size, num_hidden, num_layers, bidirectional = True) self.decoder = nn.Linear( 4*num_hidden, 2) def forward(self, input): embedding = self.embedding(input) output, h = self.encoder(embedding) encoding = torch.cat((outputs[:, 0, :], output[:, -1, :]), dim=1) # 连接最后和第一个隐藏状态 output = self.decoder(encoding) return output  现在我正在遵循的教程是使用 GloVe 模型来嵌入单词并将它们从 500 长度向量转换为 100 长度向量  我不明白如果我已经标记了我拥有的单词并且模型将具有自己的嵌入，为什么还需要嵌入模型     提交人    /u/Emotional-Rhubarb725   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2rne8/why_do_i_need_using_glove_in_this_scenario/</guid>
      <pubDate>Sun, 13 Oct 2024 15:04:11 GMT</pubDate>
    </item>
    <item>
      <title>机器学习认证</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2ra0n/ml_certifications/</link>
      <description><![CDATA[你对 Google Cloud 机器学习工程师证书有什么看法...    提交人    /u/Lazy_Humor2000   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2ra0n/ml_certifications/</guid>
      <pubDate>Sun, 13 Oct 2024 14:47:14 GMT</pubDate>
    </item>
    <item>
      <title>如果我关注一个模型，它现在是一个变形金刚吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2qx9d/if_i_add_attention_to_a_model_is_it_now_a/</link>
      <description><![CDATA[有人告诉我，没有愚蠢的问题……    由   提交  /u/InternationalMany6   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2qx9d/if_i_add_attention_to_a_model_is_it_now_a/</guid>
      <pubDate>Sun, 13 Oct 2024 14:30:38 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助修改代码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2q3ek/need_help_with_modification_of_code/</link>
      <description><![CDATA[大家好。如果有人能帮助我，我将不胜感激。 我必须使用此处给出的代码 (https://snntorch.readthedocs.io/en/latest/tutorials/tutorial\_7.html) 来编写一个神经网络，并且必须对其进行一些修改。我应该从数据集中随机选取 10 个批次的数据，并将其输入到代码中，以便每次都提供一个新的神经网络。有人能帮我吗？我非常迷茫。    提交人    /u/warmcookiedev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2q3ek/need_help_with_modification_of_code/</guid>
      <pubDate>Sun, 13 Oct 2024 13:51:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PCA 对列进行分组？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2pz9a/how_would_you_use_pca_to_group_columns/</link>
      <description><![CDATA[我想要对彼此“相似”的列进行分组（但实际上并不减少数据集的维度）。我认为 PCA 是一种合理的方法，但有人能解释一下我如何简单地对特征进行分组而不是减少整个维度，因为这是 PCA 通常所做的吗？    提交人    /u/learning_proover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2pz9a/how_would_you_use_pca_to_group_columns/</guid>
      <pubDate>Sun, 13 Oct 2024 13:45:50 GMT</pubDate>
    </item>
    <item>
      <title>训练 MLP 并需要创建它的精确副本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2p9aa/training_an_mlp_and_need_to_create_an_exact_copy/</link>
      <description><![CDATA[我已经在计算机上使用真实数据（使用 chatgpt）训练了一个 MLP，需要在 FPGA 上创建它的精确副本。我已经提取了神经网络的权重和偏差，但我不知道如何复制数据预处理部分。输入的数据格式有 6 个字段，每个字段有 60 个值，所以总共有 360 个输入，但可能缺少数据点，因此使用填充。我正在尝试在另一个代码中创建完全相同的数据预处理，但缩放器函数似乎存在问题，并且 chatgpt 告诉我用经过训练的缩放器替换缩放器。 # 使用来自训练的相同缩放器缩放输入（用经过训练的缩放器对象替换缩放器）scaled_input = scaler.transform([padded_input]) 我猜测缩放器是在原始模型中创建的，并且依赖于它训练的数据？有没有什么关于如何解决这个问题的建议。 模型中数据预处理的代码片段： # 加载并预处理数据集 file_path = &#39;data/combined_my_data.csv&#39; df = pd.read_csv(file_path, converters={&#39;ax&#39;: literal_eval, &#39;ay&#39;: literal_eval, &#39;az&#39;: literal_eval, &#39;gx&#39;: literal_eval, &#39;gy&#39;: literal_eval, &#39;gz&#39;: literal_eval}) # 将 ax、ay、az、gx、gy、gz 列组合成一个特征列表 X_combined = [ax + ay + az + gx + gy + gz for ax, ay, az, gx, gy, gz in zip(df[&#39;ax&#39;], df[&#39;ay&#39;], df[&#39;az&#39;], df[&#39;gx&#39;], df[&#39;gy&#39;], df[&#39;gz&#39;])] # 将序列填充到最大长度 max_length = max(len(sequence) for serial in X_combined) X_padded = np.array([np.pad(sequence, (0, max_length - len(sequence)), &#39;constant&#39;) for serial in X_combined]) # 重塑以适合模型的输入要求 X_padded = X_padded.reshape((X_padded.shape[0], -1)) # 编码手势标签gesture_encoder = LabelEncoder()gestures_encoded =gesture_encoder.fit_transform(df[&#39;gesture&#39;]) y = torch.tensor(gestures_encoded, dtype=torch.long) # 缩放特征 scaler = StandardScaler() X_scaled = scaler.fit_transform(X_padded) X_scaled = torch.tensor(X_scaled, dtype=torch.float32)     提交人    /u/AntiMurlock   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2p9aa/training_an_mlp_and_need_to_create_an_exact_copy/</guid>
      <pubDate>Sun, 13 Oct 2024 13:07:33 GMT</pubDate>
    </item>
    <item>
      <title>从这本书《PFA 目录》开始学习数学。它是一本不错的教材吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2mmts/started_learning_maths_from_this_book_pfa_table/</link>
      <description><![CDATA[        提交人    /u/Nocturnal_Atavistic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2mmts/started_learning_maths_from_this_book_pfa_table/</guid>
      <pubDate>Sun, 13 Oct 2024 10:23:47 GMT</pubDate>
    </item>
    <item>
      <title>如何探索机器学习的数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2mjt4/how_to_explore_the_math_of_ml/</link>
      <description><![CDATA[我是一名计算机工程专业二年级学生，我开始探索机器学习，我参加了一些关于机器学习的在线课程，这些课程确实告诉了我成本函数和梯度下降等内容背后的数学公式，但现在在做一些项目时，我只使用 Scikit-learn 和 Tensorflow 等库，所以我实际上不需要处理数学。我确实掌握了线性代数、基本微积分和概率，尽管有点生疏了。我想知道我是否做错了什么，我是否应该开始根据机器学习所需的概念来解决数学问题，或者还有其他方法可以解决这个问题。     提交人    /u/Rektplayer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2mjt4/how_to_explore_the_math_of_ml/</guid>
      <pubDate>Sun, 13 Oct 2024 10:18:00 GMT</pubDate>
    </item>
    <item>
      <title>成本函数：线性和逻辑回归</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2ls1f/cost_function_linear_and_logistic_regression/</link>
      <description><![CDATA[      你好， 我曾在Coursera上学习过Andrew Ng的课程，我认为关于线性和逻辑回归中的成本函数有些不清楚。 我想更好地理解为什么在线性回归中老师建议将成本分为使用 2m（数据集大小/行数的两倍），而在逻辑回归中他只使用 1m 线性成本函数 注意总和除以 2m 逻辑成本函数 注意仅除以 1m    提交人    /u/aster94   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2ls1f/cost_function_linear_and_logistic_regression/</guid>
      <pubDate>Sun, 13 Oct 2024 09:19:09 GMT</pubDate>
    </item>
    <item>
      <title>产品开发到机器学习：入门的最佳资源？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2k2ti/product_dev_to_ml_best_resources_to_get_started/</link>
      <description><![CDATA[我是一名具有产品开发（前端）背景的软件开发人员，最近对机器学习产生了兴趣。我涉猎过 Python、NumPy、Pandas、Matplotlib，因此我有一些基础知识，但深入研究机器学习/深度学习感觉让人不知所措，因为外面有无穷无尽的资源。😵‍💫 我想从扎实、结构化的资源（课程、书籍、实践项目）开始，进入机器学习，然后再进入深度学习。 有人可以推荐对他们有用的必试资源吗？如果其中包含实际项目，则可获得加分！ 提前致谢！🙏   由    /u/-_ROy  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2k2ti/product_dev_to_ml_best_resources_to_get_started/</guid>
      <pubDate>Sun, 13 Oct 2024 07:10:09 GMT</pubDate>
    </item>
    <item>
      <title>一篇论文的结果与另一篇论文不同</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2iq7i/result_of_one_paper_is_different_from_paper_to/</link>
      <description><![CDATA[我是一名一年级博士生，我正在尝试了解研究人员如何撰写论文和重现现有工作。 我注意到的一件事是，例如，论文 X 展示了数据集 D 的结果。但是，使用相同数据集 D 的另外两篇论文 Y 和 Z 引用了论文 X 并将其结果与其进行比较。有趣的是，论文 Y 和 Z 报告的论文 X 结果的数字与论文 X 中的原始结果略有不同，甚至彼此之间也存在差异。 发生这种情况是因为论文 Y 和 Z 的作者重现了论文 X 的结果并将其用于比较吗？如果论文 X 的重现结果低于已发表的结果，会发生什么？ 在比较论文 Y 和 Z 的作者重现的论文 X 结果时，我们如何信任它们？会不会是他们使用了略有不同的数据预处理技术，降低了论文 X 的结果，但提高了他们自己的结果？    提交人    /u/JicamaNormal927   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2iq7i/result_of_one_paper_is_different_from_paper_to/</guid>
      <pubDate>Sun, 13 Oct 2024 05:30:27 GMT</pubDate>
    </item>
    <item>
      <title>通道如何为 CNN 增添内容？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2dqq2/how_do_channels_add_anything_to_cnns/</link>
      <description><![CDATA[我正在尝试理解卷积神经网络，所以这是一个非常基本的问题，但是一个由 3 个大小相同的卷积组成的层与一个由 3 个通道组成的卷积层有什么不同？我一直在从数学的角度寻找它们实际上有什么区别的解释，但似乎每个通道都是独立卷积的，而这个概念的存在只是为了帮助更好地描述后面的操作，比如“然后为每个条目选择通道之间的平均值”或“然后我们在通道之间进行池化” 但如果我有一个简单的单层 CNN，那就是 (3x3x3) 卷积，它与三个独立的 (3x3x1) 卷积有什么不同？    提交人    /u/60hzcherryMXram   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2dqq2/how_do_channels_add_anything_to_cnns/</guid>
      <pubDate>Sun, 13 Oct 2024 00:26:57 GMT</pubDate>
    </item>
    <item>
      <title>资深机器学习人员，您是如何进行数据清理的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g2a9dg/senior_ml_people_how_have_you_made_peace_with/</link>
      <description><![CDATA[它让你感到沮丧吗？它让你感到兴奋吗？你觉得它有治疗作用吗？你觉得它无聊吗？你是否有一套固定的方法来处理它？还是根据具体情况来决定？你多久在 Python 和 Excel 或任何其他你偏爱的工具之间切换一次？你认为你花在它上面的时间占了多少百分比？用这个作为发泄或传授智慧的一般途径。    提交人    /u/sharmasagar94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g2a9dg/senior_ml_people_how_have_you_made_peace_with/</guid>
      <pubDate>Sat, 12 Oct 2024 21:25:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么现在一篇机器学习论文需要几十个人的参与？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g23o6m/why_does_a_single_machine_learning_paper_need/</link>
      <description><![CDATA[而且我不仅仅是在谈论调查。 早在 2000 年代初期到后期，我的导师就独自发表了几篇论文，这些论文的长度和技术深度与如今数十名 ML 研究人员共同完成的一篇论文完全相同。后来，他总是与另一个人合作，或者接手一名学生，使作者总数达到 3 人。 我的导师总是告诉我，在学术界，大量作者撰写的论文被视为“极其廉价”，因为可能论文上大多数人的名字甚至都无法告诉你论文的内容。在他参加的招聘委员会中，他们总是对在大型团队中合作完成大量工作的候选人持怀疑态度。 那么为什么这种做法在 2020 年代的机器学习中被视为可以接受的甚至是好的呢？ 我相信那些有几十位作者的论文可以精简到 1 或 2 位作者，内容不会有任何重大变化。    提交人    /u/RandomProjections   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g23o6m/why_does_a_single_machine_learning_paper_need/</guid>
      <pubDate>Sat, 12 Oct 2024 16:17:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>