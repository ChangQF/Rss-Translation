<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 02 Jan 2025 15:16:46 GMT</lastBuildDate>
    <item>
      <title>寻求针对特定领域法学硕士 (LLM) 的自动数据混合加权建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrupvb/seeking_advice_on_automated_data_mixture/</link>
      <description><![CDATA[大家好，机器学习的朋友们！ 我目前正在通过指令微调和 DPO 来研究训练后领域特定的 LLM，使用领域内的各种数据集（10+）。但是，我遇到了一点障碍。当我天真地合并这些数据集并使用均匀采样时，与基于直觉手动调整权重（例如，对具有大量数据的简单任务进行下采样）相比，性能往往表现不佳。虽然这种手动方法在一定程度上有效，但我怀疑它远非最佳。 我想看看这里是否有人有经验或见解，了解用于确定数据混合权重的自动化算法方法。我知道 DoReMi，但就我而言，它的性能改进相当有限。您是否发现其他更有效的技巧或策略？ 如果您能分享任何建议、资源或个人经验，我们将不胜感激。提前致谢！    提交人    /u/purified_piranha   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrupvb/seeking_advice_on_automated_data_mixture/</guid>
      <pubDate>Thu, 02 Jan 2025 14:19:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理学习资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrtz8g/resources_to_learn_on_ai_agents/</link>
      <description><![CDATA[背景 担任机器学习工程师，具有 LLM、RAG、MLOps 等方面的经验。非常精通 Python、数据工程和 ML 框架（从 tensorflow 到 Zen ML 等）。 问题 但不知何故，我的老板了解了 AI 代理的流行趋势，现在我必须做一些与代理有关的事情。公平地说，这不是我以前使用/研究过的东西，猜想应该不会那么难学吧？但网上的材料似乎很少。 那么，寻找资源，可以从头开始在实际问题上解释一下？你遇到的任何东西（最好是免费的，显然）- 书籍、博客或其他任何东西..     提交人    /u/CheetahGloomy4700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrtz8g/resources_to_learn_on_ai_agents/</guid>
      <pubDate>Thu, 02 Jan 2025 13:43:51 GMT</pubDate>
    </item>
    <item>
      <title>变形金刚变得如此简单，你的祖母现在就可以编码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrqz41/transformers_made_so_simple_your_grandma_can_code/</link>
      <description><![CDATA[      嘿 Reddit！！在过去的几周里，我花了很多时间尝试制作一份全面的、直观的变形金刚指南。 解释每个组件背后的直觉，并向其中添加代码。 因为我使用的所有教程都有代码解释或变形金刚背后的想法，所以我从未遇到过将它们结合在一起的东西。 链接：https://goyalpramod.github.io/blogs/Transformers_laid_out/  很想听听你的想法 :) https://preview.redd.it/k91ykm687kae1.png?width=1170&amp;format=png&amp;auto=webp&amp;s=c02eb210be37441c5c54efeb1ee898e6929598d7    提交人    /u/Pale-Gear-1966   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrqz41/transformers_made_so_simple_your_grandma_can_code/</guid>
      <pubDate>Thu, 02 Jan 2025 10:39:24 GMT</pubDate>
    </item>
    <item>
      <title>帮助自适应共形推理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrp7e3/help_with_adaptive_conformal_inference/</link>
      <description><![CDATA[我目前被 TS 的这个硬件难住了。如果有人有兴趣帮忙，我们可以私下聊聊，并发送必要的 pdf 文件。提前谢谢您    提交人    /u/IbraKing9   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrp7e3/help_with_adaptive_conformal_inference/</guid>
      <pubDate>Thu, 02 Jan 2025 08:26:22 GMT</pubDate>
    </item>
    <item>
      <title>寻求基于 AI/ML 的半导体项目的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrnq08/seeking_advice_for_an_aimlbased_semiconductor/</link>
      <description><![CDATA[大家好， 我正在深入研究一个雄心勃勃的项目，该项目位于 AI/ML 和 半导体 的交叉领域，我很乐意从在这些领域有经验的人那里获得一些反馈和建议。 项目概述： 我们的想法是开发可以优化半导体行业各个方面的 AI/ML 模型，从硬件设计（专注于用于 AI 工作负载的芯片）到制造过程优化甚至供应链管理。目标是应用人工智能驱动的解决方案，这些解决方案可以在以下领域提供价值：  增强芯片设计以加速人工智能工作负载 优化制造流程以提高产量并减少缺陷 预测和管理半导体行业的供应链，该行业最近由于全球短缺而承受着巨大压力  我已经做了一些初步研究，但我仍处于早期阶段，还有很多东西需要学习。我希望与其他可能对如何处理这个项目有见解或建议的人建立联系。 寻找：  AI / ML 方面的技术专家，尤其是在硬件设计或制造优化方面有经验的 半导体行业专业人士，他们可以提供对现实世界挑战的见解 任何有关资源、工具或最佳实践的一般建议，都可以帮助我推进这个项目  如果您曾经从事过类似的事情或对如何开始有想法，我很乐意听到您的声音！ 期待收到大家的来信并从您的经验中学习！    提交人    /u/rickgrimes3338   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrnq08/seeking_advice_for_an_aimlbased_semiconductor/</guid>
      <pubDate>Thu, 02 Jan 2025 06:40:30 GMT</pubDate>
    </item>
    <item>
      <title>我们是否需要知道如何证明 ML/AI</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrjcph/do_we_need_to_know_how_to_proof_of_mlai/</link>
      <description><![CDATA[我正在学习人工智能，我们必须学习的课程之一是人工智能数学，它涵盖了复数、矩阵、微积分和证明等主题。现在，除了证明之外，我对这些都不在行。 我就是无法理解它……因为我不知道如何证明，而且我发现很难学习如何证明，我不确定我是否做错了什么，或者证明是否客观上比数学更难。二，我不明白为什么我需要证明一些东西来学习人工智能。 那么，学习如何证明人工智能真的有必要吗？或者这只是老派教授决定我们必须学习的一些大学胡言乱语，因为在你的人工智能职业生涯中，可能有 0.5% 的机会你需要证明一些东西？ 编辑：如何证明* n 标题    提交人    /u/Philanthrax   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrjcph/do_we_need_to_know_how_to_proof_of_mlai/</guid>
      <pubDate>Thu, 02 Jan 2025 02:28:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 AI/ML 领域建立有意义的联系？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrh0gf/how_can_i_build_meaningful_connections_in_the/</link>
      <description><![CDATA[大家好， 我是一名计算机科学专业二年级学生，对 AI/ML 充满热情。我积极开展项目，参加黑客马拉松，最近开始探索研究论文以加深我的理解。随着我在这个领域的成长，我逐渐意识到与做出重大贡献的人建立联系的重要性——博士生、研究人员和行业专业人士。 我的目标不仅是在 LinkedIn 等平台上建立联系，而且要建立促进学习、协作和共同成长的真诚关系。 我很乐意听取您的建议： 寻找和接触志同道合的人的最佳平台、社区或活动。 如何以尊重和有意义的方式接近专业人士和研究人员。 随着时间的推移，维持和培养这些联系的有效方法。 如果您自己走过这条路或指导过他人，我将非常感激您能分享的任何提示、个人经历或资源。 如果您愿意分享见解或开始对话，我也很乐意与您联系。感谢您的时间和指导！    提交人    /u/PixelPioneer-1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrh0gf/how_can_i_build_meaningful_connections_in_the/</guid>
      <pubDate>Thu, 02 Jan 2025 00:32:06 GMT</pubDate>
    </item>
    <item>
      <title>理论上是否可以沿着头部维度分割多头注意力计算？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hrblj2/is_it_theoretically_possible_to_split_multihead/</link>
      <description><![CDATA[我不确定这个问题是否适合这里，如果不适合 - 请删除它，我提前道歉。 这里使用 Python 作为示例，这个问题主要是关于推理，而不是训练。 如果我们有一个像这样的注意力函数： deftention(q, k, v, heads, sm_scale=None): ...  其中 q 的形状可能是 batch, seqlen, dim_head 并且我们会将头部维度计算为 dim_head // heads。 理论上是否可以拆分注意力计算并运行它，例如，dim_head 的前半部分，然后是后半部分，然后将结果组合成至少近似于正确结果的东西？简单的实现（实际上不能正常工作，但奇怪的是也没有完全破坏结果）可能看起来像： def dumb_attention(q, k, v, heads): b, _, dim_head = q.shape hdh = dim_head // 2 # Half head dim r1 =tention(q[..., :hdh], k[..., :hdh], v[..., :hdh], heads, sm_scale=None) r2 =tention(q[..., hdh:], k[..., hdh:], v[..., hdh:], heads, sm_scale=None) return torch.cat((r1, r2), dim=-1)  我无法访问注意力函数的内部细节，但我可以覆盖 softmax 尺度（sm_scale），默认情况下为 (dim_head // heads) **如果未指定，则为 -0.5。  我试图弄清楚这一点的最初动机是因为我想使用优化的注意力实现（SageAttention），它仅支持最大 128 的 head_dim。像这样拆分它很有可能比跳过不支持 head_dim 的注意力的 SageAttention 更慢（Stable Diffusion 1.5 中有一些 head_dim 为 160）。我仍然想弄清楚是否有可能满足我的好奇心，即使没有任何实际价值！    提交人    /u/alwaysbeblepping   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hrblj2/is_it_theoretically_possible_to_split_multihead/</guid>
      <pubDate>Wed, 01 Jan 2025 20:24:09 GMT</pubDate>
    </item>
    <item>
      <title>了解模型内部工作原理的资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hraeax/resources_to_learn_how_models_work_under_the_hood/</link>
      <description><![CDATA[嗨。 我对机器学习还很陌生，刚刚开始探索它。我目前是一名计算机科学本科生，我发现大学水平的数学一点也不难。我在微积分、线性代数和概率与统计课程中取得了优异的成绩。 我最近开始了我的机器学习之旅，学习了传统的 Andrew Ng 的“监督机器学习”课程，这是一个很棒的学习体验。它帮助我深入了解了线性回归和逻辑回归模型在数学（理论）和代码（实践）方面的工作原理。我很惊讶地发现，我在概率和统计课程中学习的概念是逻辑回归模型的一部分。 我列出了在进入深度学习之前要学习的模型列表。  决策树 随机森林 朴素贝叶斯 KNN K-Means Ridge/Lasso  （如果我应该将任何其他模型添加到此列表，请告诉我） 现在，我有开发背景，并且对 Python 有很好的掌握。我一直在研究编码部分，EDA 的过程令人愉快。然而，就模型而言，我发现只需从库中导入并应用它们就很简单了。 from sklearn.ensemble import RandomForestClassifier 我可以轻松地在实践中应用这些模型并获得良好的评估分数，但不明白它们背后的工作原理。数学、可视化和训练过程是我想要了解的。 我不知道我参加的 Andrew Ng 的课程是否让我对学习体验抱有如此高的期望。但如果有任何学习资源在模型工作原理的理论方面提供了类似的学习体验，请告诉我。 谢谢。    提交人    /u/Still_Dealer_3908   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hraeax/resources_to_learn_how_models_work_under_the_hood/</guid>
      <pubDate>Wed, 01 Jan 2025 19:30:36 GMT</pubDate>
    </item>
    <item>
      <title>我还有希望成为一名研究员吗？还是我应该放弃？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hr3tx3/is_there_any_hope_for_me_to_become_a_researcher/</link>
      <description><![CDATA[我不想听起来太情绪化，只是实际上我觉得我的道路已经走到了尽头。但我仍在努力争取最后一点。 我的故事并不罕见，下面是：  我本科毕业于一所不知名的大学，来自一个贫穷的国家。 我在 ML 领域有一份工作，大约有 4 年的经验，但这没有任何意义，因为我所在的行业不允许我（或者说不要求我有任何研究背景），尽管这也可能是因为地区（国家）。 我发表过一些论文，但那些都太初级了（因此我把它们发布在 arxiv 上，而不是一些随机的会议上）。 我对数学有很好的掌握，很想以此为生，但我也觉得自己是个冒名顶替者，因为一切都是自学的。而且我甚至不知道我是否有能力进行任何好的研究（而且还靠我自己）。 由于经济和个人原因，我无法获得博士学位（另外，我已经被我所在国家的教育体系淘汰了）。 我尝试自己实现论文或做一些研究，很多时候也与其他研究人员联系过，但每次我都碰壁然后失去希望，因为没有方向，没有人指导我，也没有相同兴趣的人讨论任何想法。 我知道这个领域的竞争非常激烈，我认为我没有任何机会，但我仍然不想直接放弃。  那么我有什么办法可以自己做吗？如果可以，怎么做？在这种激烈的竞争中，是否有希望成为自力更生的人工智能研究人员，还是我应该放弃？    提交人    /u/DramaticCloud1498   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hr3tx3/is_there_any_hope_for_me_to_become_a_researcher/</guid>
      <pubDate>Wed, 01 Jan 2025 14:21:59 GMT</pubDate>
    </item>
    <item>
      <title>LLM 对于从网页中提取实体来说是否过度了？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hr3gbm/are_llms_overkill_for_entity_extraction_from/</link>
      <description><![CDATA[我收集了数千个公司的网页。我想自动提取他们的技术和产品。gpt4o 可以很好地完成这项任务，但价格昂贵。我已经对 4o-mini 进行了微调，使其工作得几乎与 4o 一样好，而且我也在研究 llama。 但有人对我说，这是对计算的巨大浪费，因为 BERT 或 Spacy 可以做同样的事情。他们是对的吗？    提交人    /u/vegatx40   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hr3gbm/are_llms_overkill_for_entity_extraction_from/</guid>
      <pubDate>Wed, 01 Jan 2025 14:00:21 GMT</pubDate>
    </item>
    <item>
      <title>终于拿到了我的 NVIDIA Jetson Orin Nano 超级计算机（NVIDIA 赞助）。我应该在上面尝试哪些 ML 特定的东西？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hr1uve/finally_got_my_nvidia_jetson_orin_nano/</link>
      <description><![CDATA[        由    /u/mehul_gupta1997   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hr1uve/finally_got_my_nvidia_jetson_orin_nano/</guid>
      <pubDate>Wed, 01 Jan 2025 12:16:10 GMT</pubDate>
    </item>
    <item>
      <title>我从 2024 年 1 月 2 日开始，对 AI 知识 0，写了 365 天的博客，学习了 AI。下面是总结。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hr0qsk/i_started_with_0_ai_knowledge_on_the_2nd_of_jan/</link>
      <description><![CDATA[      完整博文和更多信息在第一条评论中 :) 编辑标题：365 天*（和拼写） 由于我有会计和数据分析背景，我对人工智能知之甚少。在此之前，我的理解仅限于线性回归、R 平方、微积分中的幂律以及使用 Python 和 SQL 进行数据处理的工作经验。我学习了免费的在线讲座、课程，阅读了书籍。 *花在理论和实践上的时间* 最后发现我在理论和实践上花费的时间几乎相同。在回顾我的一年时，我发现在接下来的几天里从课程 / 讲座中学习到一些东西后，我会立即应用它 - 无论是通过练习、制作 Kaggle 笔记本还是通过开展项目。 *2024 年学习之旅主题细分* 我学到的一件事是*基础*很重要。我发现任何人都可以制作模型，但制作能够增加商业价值的模型很重要。此外，为了正确理解模型的内部工作原理，我想对统计数据和概率以及 AI 背后的数学进行适当的介绍。我还深入研究了“传统”ML（线性模型、树）以及深度学习（NLP、CV、语音、图表），这很棒。值得注意的是，我并不是从统计数据和概率开始的数学，我引导自己，从传统和一些 GenAI 开始，但不久之后，我开始问很多“为什么事情会这样”，这促使我更多地研究统计和数学。很快，我也意识到 *数据为王*，所以我深入研究了数据工程及其涵盖的所有实践和想法。除了数据工程，我还对 MLOps 感兴趣。我想知道在测试集上评估模型后会发生什么——事实证明，这背后有一个完整的领域，我立刻就迷上了。制作模型不仅仅是从 Kaggle 获取数据并进行训练/测试评估，我们需要从商业案例开始，提出一个适当的案例来增加商业价值，然后它是一个完整的开发、测试、维护和监控生命周期。 *词云* 在删除一些通用重复的词后，我从我的 365 篇博客文章中最常用的作品中创建了这个工作云。最热门的词是：- 模型和数据 - 这并不奇怪，因为它们齐头并进- 价值 - 因为模型需要传递价值- 特性（工程） - 模型开发中的关键步骤- 系统 - 这主要是因为我对数据工程和 MLOps 的兴趣 我希望你觉得我的总结和博客很有趣。 https://preview.redd.it/pxohznpy4dae1.png?width=2134&amp;format=png&amp;auto=webp&amp;s=03c16bb3535d75d1f009b44ee5164cc3e6483ac4 https://preview.redd.it/0y47rrpy4dae1.png?width=1040&amp;format=png&amp;auto=webp&amp;s=f1fdf7764c7151ff0a05ae92777c5bb7d52f4359 https://preview.redd.it/e59inppy4dae1.png?width=1566&amp;format=png&amp;auto=webp&amp;s=2566033777a90410277350947617d3ce8406be15    提交人    /u/Bobsthejob   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hr0qsk/i_started_with_0_ai_knowledge_on_the_2nd_of_jan/</guid>
      <pubDate>Wed, 01 Jan 2025 10:54:11 GMT</pubDate>
    </item>
    <item>
      <title>43 堂讲座的大型 LLM 资源 | 热门 YouTube 播放列表</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hqwwf3/mega_llm_resource_of_43_lectures_popular_youtube/</link>
      <description><![CDATA[      https://i.redd.it/mo5d2g93obae1.gif 就像机器学习一样，只有真正了解大型语言模型 (LLM) 的具体工作原理，您才会成为一名严肃的 LLM 工程师。 很少有人了解 LLM 究竟是如何运作的。能从头开始建立整个 LLM 的人就更少了。 如果能从头开始建立自己的 LLM，那不是很棒吗？ 这里有一个很棒的 Youtube 播放列表系列：从头开始构建你自己的 LLM。 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSgsLAr8YCgCwhPIJNNtexWu 它在 Youtube 上已经非常流行。 一切都写在白板上。从头开始。  43 场讲座发布。 本系列讲座灵感来自 Sebastian Raschka 的书“从头开始构建 LLM” 希望您学到很多东西 :) 附注：附加的 GIF 显示了此播放列表附带的一小段笔记。    提交人    /u/OtherRaisin3426   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hqwwf3/mega_llm_resource_of_43_lectures_popular_youtube/</guid>
      <pubDate>Wed, 01 Jan 2025 05:57:34 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>