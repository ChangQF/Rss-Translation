<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 30 Jan 2024 00:57:03 GMT</lastBuildDate>
    <item>
      <title>神经网络实现</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aeadsl/neural_network_implementation/</link>
      <description><![CDATA[我尝试在 XOR 上进行测试，损失稳定在 0.25 左右。我创建了一个具有自动微分功能的张量类，其中递归计算梯度。 ​ https://colab.research.google.com/drive/1mIo2v8tA8xULFtfSp25gxIfFvbMaHzDg?usp=sharing  &amp;# 32；由   提交 /u/LeTrollDud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aeadsl/neural_network_implementation/</guid>
      <pubDate>Tue, 30 Jan 2024 00:02:40 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机。特征点积</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aea3lh/svm_feature_dot_product/</link>
      <description><![CDATA[大家好！ 我现在正在学习 SVM 的工作原理，但我无法理解其中的一件事。我看了 Andrew Ng 的讲义，也看了 MIT 的讲义，但是没看懂。 所以，在 SVM 中我们需要最小化 1/2 * (norm(W)) 我们可以假设 W 是我们的特征的线性组合。所以W = sum [Y_i * alpha_i * X_i]然后norm(W) = W_T * W现在我无法得到。 /&gt; 我们这样做norm(W) = Transpose(sum [Y_i * alpha_i * X_i]) * sum [Y_j * alpha_j * X_j]  我们更改索引，添加新索引 j 。但为什么我们要这样做？ 假设我们有向量 a = (1,2) 那么 a_T * a = 1*1 + 2*2 我们将数字与相同的索引 为什么我们使用新索引 J ？还是我弄错了什么？   由   提交 /u/Top-Permission-1526   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aea3lh/svm_feature_dot_product/</guid>
      <pubDate>Mon, 29 Jan 2024 23:50:06 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae9kn2/cosine_similarity/</link>
      <description><![CDATA[我试图弄清楚每个特征的标准化（减去平均值并除以标准差）是否会改变 kNN 在使用时所做的预测余弦相似度作为距离的度量（就像使用欧几里得时一样）。我认为不应该，因为我们只是测量角度，每个特征都被相同的值改变，但我不确定。是否有证据表明它不会受到影响，或者有反例表明不受影响？   由   提交 /u/Rich-Professional-54   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae9kn2/cosine_similarity/</guid>
      <pubDate>Mon, 29 Jan 2024 23:26:46 GMT</pubDate>
    </item>
    <item>
      <title>[视频系列]Word2Vec 的故事</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae8u4c/video_series_the_story_of_word2vec/</link>
      <description><![CDATA[    &lt; /a&gt;  庆祝最美模型之一 Word2Vec 十岁生日最近赢得了“时间考验”奖 - 我决定去冒险！ 描绘嵌入聚类的动画随着时间的推移。 首先，我讲述 Word2Vec 的故事，它最初是一个语言模型，但后来演变成简单但功能强大的东西：https://youtube.com/watch?v=XG1GjWZKCvM ​ 输入单词与相邻单词之间的相似度得分. 事实证明，吸引相似的单词并排斥随机单词（一种称为对比学习的方法）是获得嵌入的好方法。 新视角：从语言建模到词对分类。&lt; /a&gt; 我将 CLIP 等最新模型联系起来，它执行类似的舞蹈来协调语言和图像。 CLIP 是对比学习的另一个例子。  Word2Vec 的影响是巨大的。首先，它是理解什么是模型以及什么是词嵌入的一个很好的例子。 Word2Vec 开启了在没有标签的大型数据集上进行自监督学习的时代，它将我们今天的法学硕士。 大像 Llama 2 这样的语言模型是在没有任何标签的情况下进行预训练的！ 在第二个视频中，我探索了 Word2Vec 的梯度：https://youtube.com/watch?v=X4mIrD4dTRk  它的形式非常简单，适合类比：粒子吸引和排斥。语言的物理学是如此美丽。 祝贺作者赢得了时间的考验，也感谢作者：Word2Vec 是多年前我机器学习之旅的开始模型。  我在制作这个过程中获得了很多乐趣，希望你们都觉得这很有价值！   由   提交 /u/LearnAIwithAndy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae8u4c/video_series_the_story_of_word2vec/</guid>
      <pubDate>Mon, 29 Jan 2024 22:54:38 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散也适用于条形图！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae8l13/stable_diffusion_works_on_bar_charts_too/</link>
      <description><![CDATA[    /u/tylersuard   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae8l13/stable_diffusion_works_on_bar_charts_too/</guid>
      <pubDate>Mon, 29 Jan 2024 22:43:41 GMT</pubDate>
    </item>
    <item>
      <title>如何处理顺序数据</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae5rpy/how_to_deal_with_sequential_data/</link>
      <description><![CDATA[大家好， 我刚刚开始使用 ML，我不知道我的问题是否可以解决. 本质上，我想做一些日志处理。每个日志条目都包含一行或多行，其中包含持续时间和功率级别：   Step 持续时间 (S) 能量级别 (0-255)     1 10 100   2 5 150   3 12 80   4 10 110   连续条目包含基本相同的数据，但时间发生了变化。即 12 秒的转变可能如下所示： ​   Step 持续时间 (S) 功率级别 (0-255)    1 3 150   2 12 80   3 td&gt; 10 110   4  5   20     5  40 30   有一些变化，一些是预期的/良性的，一些是不好：  预期/良性 时间变化（如上所示） 最后的额外步骤 额外的中介功率级别较高的步数（即 10s @ 100 =&gt; 8s @ 100 + 2s @ 200）  坏  丢弃的步数（除了第一个时隙（如果它被“逐步淘汰”）如上所示 额外的中间步骤/具有较低功率水平的更改步骤（即 10s @ 100 =&gt; 10s @ 80） 持续时间非常短的步骤（&lt; 1s）&lt; /li&gt;   这还不是全部，有些值永远不应该出现，有最大的变化率，早期的步骤不太可能改变，...但这些都是在一篇已经很长的文章中很难定义。  我听说*可以*用 RNN 来完成，但我什至不知道从哪里开始。 如果有人有任何指示、方法、技巧，或策略，类似的项目，...我将不胜感激！ ​ 版主：我以前尝试过发布此内容，但不知何故搞砸了。抱歉    由   提交 /u/TryingToLearnML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae5rpy/how_to_deal_with_sequential_data/</guid>
      <pubDate>Mon, 29 Jan 2024 20:47:54 GMT</pubDate>
    </item>
    <item>
      <title>在计算集群指标之前是否应该删除标记为噪声的数据？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae5o30/should_data_labeled_as_noise_be_removed_before/</link>
      <description><![CDATA[我正在使用 OPTICS 进行聚类，并且正在迭代一些参数、计算指标并存储它们以进行评估。我正在收集聚类数量、标记为噪声的百分比、Calinski-Harabasz 指数、轮廓得分和 Davies-Bouldin 指数。 我是否应该排除标记为噪声的数据（-1 标签） ）在收集分数之前？它会扭曲结果，但我想确保簇结构良好、正确分离，并且具有相似的大小和簇内方差。评分框架 IIRC 关注这些方面。 好主意还是坏主意？   由   提交 /u/WadeEffingWilson   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae5o30/should_data_labeled_as_noise_be_removed_before/</guid>
      <pubDate>Mon, 29 Jan 2024 20:43:46 GMT</pubDate>
    </item>
    <item>
      <title>GPU 转换和 CPU 转换的值不同，可以吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae54q3/different_values_from_gpu_transformation_and_cpu/</link>
      <description><![CDATA[      image_size = 224 变换 = T.Compose([ T.ToPILImage() ，T.Resize（（image_size，image_size）），T.RandomResizedCrop（image_size），T.RandomHorizo​​ntalFlip（），T.Grayscale（），T.ToTensor（）]）gpu_available = torch.cuda.is_available（）transform_gpu = torch .nn.Sequential( # T.ToPILImage(), T.Resize((image_size, image_size)), T.RandomResizedCrop(image_size), T.RandomHorizo​​ntalFlip(), T.Grayscale(), # T.ToTensor() T. ConvertImageDtype(torch.float), ) # 测试 Transformer - CPU my_image = read_image(X_train[0]) print(&quot;CPU 图像输入 - &quot;, my_image.shape, my_image.dtype) returned_image = transform(my_image) print( &quot;CPU 图像输出 - &quot;, Transformed_image) print(&quot;CPU 图像输出 - &quot;,transformed_image.shape,transformed_image.dtype) # pyplot.imshow(transformed_image.squeeze(), cmap=&quot;gray&quot;) # 测试Transformer - GPU my_image_gpu = read_image(X_train[0]) print(&quot;GPU 图像输入 - &quot;, my_image_gpu.shape, my_image_gpu.dtype) my_image_gpu = my_image.to(device) my_image_gpu = my_image_gpu.type(torch.float32) Transformed_image_gpu = transform_gpu(my_image_gpu) # # # 显示变换后的图像 gpu_cpu_img = Transformed_image_gpu.squeeze().cpu().numpy() pyplot.imshow(gpu_cpu_img, cmap=“gray”) print(“GPU 图像输出 - ” ;,transformed_image_gpu) print(&quot;GPU 图像输出 - &quot;,transformed_image_gpu.shape,transformed_image_gpu.dtype)  ​ https://preview.redd.it/rjhztjh4vffc1.png?width=1074&amp;format =png&amp;auto=webp&amp;s=27af8a2f0ff3140568b90c4f870e98436ee11fc6 CPU 图像输出为每个值提供 0-1 范围，GPU 转换在哪里给出 1-255，是否符合预期？ 显示时的图像 \`pyplot.imshow(gpu\_cpu\_img, cmap=“gray”)\` 看起来很相似。   由   提交 /u/ContributionLow6546   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae54q3/different_values_from_gpu_transformation_and_cpu/</guid>
      <pubDate>Mon, 29 Jan 2024 20:21:21 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae521b/multiple_linear_regression_help/</link>
      <description><![CDATA[您好，我需要一些有关使用 sklearn 在 python 上运行的模型的帮助。我正在尝试将基金回报率与 2 个指数进行回归。我的 r2 值非常差，所以现在我正在尝试优化模型，但我不确定如何去做。返回数据已经干净，所有数据集都采用 % 格式。我还需要标准化吗？我可以使用哪些技术来帮助提高 r2 值？   由   提交/u/LdnCrypto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae521b/multiple_linear_regression_help/</guid>
      <pubDate>Mon, 29 Jan 2024 20:18:24 GMT</pubDate>
    </item>
    <item>
      <title>开始学习 DS 机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae4sxf/started_learning_ml_for_ds/</link>
      <description><![CDATA[最近，我开始使用 scikit learn 和 keras 学习机器学习实践，并在 Jupyter Notebook 上进行练习。今天，我看到了 roadmap.sh 的 AI 和 DS 路线图，我觉得很酷。我想知道该路线图的质量（或者如果有其他路线图，请提出建议）   由   提交/u/ValiantThor07  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae4sxf/started_learning_ml_for_ds/</guid>
      <pubDate>Mon, 29 Jan 2024 20:08:03 GMT</pubDate>
    </item>
    <item>
      <title>书籍推荐</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae1bbh/book_recommendations/</link>
      <description><![CDATA[我要出差一个月（不带笔记本电脑💻⛔️），谁能推荐一些关于机器学习、大数据、统计和机器学习的好书吗？等等。谢谢🙏🏼   由   提交/u/ad3li  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae1bbh/book_recommendations/</guid>
      <pubDate>Mon, 29 Jan 2024 17:47:37 GMT</pubDate>
    </item>
    <item>
      <title>电子邮件营销/筹款背景对于获得 IBM 机器学习证书有什么好处吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae11hp/would_a_background_in_email_marketingfundraising/</link>
      <description><![CDATA[我只是在评估这对我来说是否是一条好的职业道路。我在数字筹款领域工作了大约 8 年，这本身就是一种营销形式。主要是，我的工作主要是通过电子邮件进行，这需要最少的 HTML 编码，但需要大量审查各种统计数据，以告知如何修改正在进行的活动（并知道何时停止并尝试新的东西）。 我实际上很擅长我所做的事情，但因为这是一个令人难以置信的利基领域，所以确实没有很多工作可以做。我在失业中度过了两年的大部分时间，虽然我确实找到了另一份目前正在做的工作，但我想积极主动地涉足其他职业道路。 我想是因为尽管有如此多的炒作，人们很难不对当今人们利用人工智能/机器学习所做的事情印象深刻。我在 Coursera 上开设了一门有关 IBM 证书的课程，但发现它将涉及比我预期更多的数学内容。 当涉及到我理解的数字时&lt; /em&gt;，我对这些数字很满意。但总的来说，我的数学从来都不是很好。我开始只是在 YouTube 上观看课程，试图提高我的数学技能，我想说，我的技能有多差，这实际上是令人尴尬的。 好吧，考虑到人工智能的很多好处正在消失要消除带薪职位，这让我想知道这是否真的是一个值得追求的好领域，或者我是否已经远远落后于曲线，不值得？我不仅是从头开始，而且我想我的学习速度会比许多同龄人慢得多，因为即使我拥有的编码知识也大多是通过渗透来学习的。 通过营销经验是通常“难以证明”的东西在简历中（这并不是说你可以透露你为以前的客户赚了多少钱），我想确保我不会遇到机器学习的类似问题，这几乎是不可能的几年后找到工作？   由   提交/u/Jcorb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae11hp/would_a_background_in_email_marketingfundraising/</guid>
      <pubDate>Mon, 29 Jan 2024 17:36:26 GMT</pubDate>
    </item>
    <item>
      <title>寻求帮助以查找有关面部图像生成和特征控制的旧视频</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ae0uzs/seeking_help_to_find_an_old_video_on_face_image/</link>
      <description><![CDATA[我需要帮助来查找几年前观看的视频。该视频重点介绍了一个人工智能项目，可能涉及神经网络或深度学习，用于生成或识别面部图像。 视频中最有趣的部分是一个控制面板，可以调整各种功能图像参数，例如背景颜色、头发长度等。这些特征似乎是网络在训练过程中自动识别的。 这是了解经过训练的神经网络如何自主识别特定特征的绝佳资源。图像特征，例如区分长发和短发。 有人记得看过这样的视频或者可以帮我找到它吗？任何线索或建议将不胜感激。   由   提交 /u/Bimbonesto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ae0uzs/seeking_help_to_find_an_old_video_on_face_image/</guid>
      <pubDate>Mon, 29 Jan 2024 17:29:19 GMT</pubDate>
    </item>
    <item>
      <title>对于已经在该领域工作的人们来说，这个路线图好吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1adtzqr/question_for_folks_already_working_in_the_field/</link>
      <description><![CDATA[我找到了这个路线图：https://roadmap。 sh/ai-数据科学家。我应该照原样遵循吗？好吗？  要成为机器学习工程师，我还应该遵循 https://roadmap.sh/devops 吗？  谢谢:) ​   由   提交/u/thepeppesilletti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1adtzqr/question_for_folks_already_working_in_the_field/</guid>
      <pubDate>Mon, 29 Jan 2024 12:18:30 GMT</pubDate>
    </item>
    <item>
      <title>什么专业最适合成为 ML/AI 工程师？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1adhe7f/what_major_would_be_best_to_become_a_mlai_engineer/</link>
      <description><![CDATA[目前是高中高年级学生，我计划在秋季就读公立学校。我打算主修软件工程，但主修计算机科学或数据科学会更好吗？软件工程学位包含更多的工程课程，如微分方程、物理、化学以及与软件相关的课程，并实际做软件工程师的工作。 CS专业更偏重理论。 DS专业有更多的统计课程与CS理论混合在一起。如果我只想成为一名机器学习或人工智能工程师，哪个专业是理想的？   由   提交 /u/MainBreadfruit167   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1adhe7f/what_major_would_be_best_to_become_a_mlai_engineer/</guid>
      <pubDate>Mon, 29 Jan 2024 00:08:46 GMT</pubDate>
    </item>
    </channel>
</rss>