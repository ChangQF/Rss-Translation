<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 29 Mar 2024 12:25:03 GMT</lastBuildDate>
    <item>
      <title>Grook 模型编写“你想建一首雪人音歌曲吗？你想投票吗？”</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqn259/grook_model_writing_do_you_wanna_build_a_snowman/</link>
      <description><![CDATA[它是由 Grook 唱歌生成的，你想投票吗  （第 1 节）你想投票吗？  一篇让你微笑的帖子？  评论太聪明了， 它会持续一段时间。 （合唱） 让我们传播橙色光芒，&lt; /p&gt; 表达一点爱。  你想投票吗， 并让数字增长？ （第2节） 一个让你咯咯笑的模因，  深刻见解， 只需轻轻一点，即可找到好内容！ （合唱）  p&gt; 让我们传播橙色光芒， 表达一点爱。  你想投票吗， 并让人数增长？ （结尾） 所以不要成为潜伏者，决不！  今天让您的声音被听到！  投票！   由   提交 /u/tsamt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqn259/grook_model_writing_do_you_wanna_build_a_snowman/</guid>
      <pubDate>Fri, 29 Mar 2024 11:35:28 GMT</pubDate>
    </item>
    <item>
      <title>英国ML博士申请</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqmwf4/ml_phd_applications_in_the_uk/</link>
      <description><![CDATA[现在进入美国顶尖学校的 ML 博士项目非常困难，主要是因为你需要在大型会议上发表论文才能被考虑。但是像牛津、剑桥、伦敦大学学院或爱丁堡这样的地方呢？ 我本科读的是数学，所以我没有太多发表论文的机会。现在，我将从今年九月开始在牛津攻读计算机科学硕士学位。但问题是：会议论文的截止日期意味着我必须在有机会发表任何东西之前申请博士学位课程。我的硕士学位是为了在花大量现金申请博士学位之前先写出一些论文吗？攻读机器学习博士学位的数学毕业生或申请英国项目的人的任何建议或故事都很棒。   由   提交 /u/Trick_Hovercraft3466   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqmwf4/ml_phd_applications_in_the_uk/</guid>
      <pubDate>Fri, 29 Mar 2024 11:26:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 CrewAI (GenerativeAI) 创建人工智能技术团队</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqmurv/creating_ai_tech_team_using_crewai_generativeai/</link>
      <description><![CDATA[大家好，请查看本教程，了解如何创建 AI 技术团队（编码员、产品经理、技术主管等），然后看看他们如何解决问题本演示中使用 CrewAI 执行任务：https://youtu.be/QPUUclaNI5o?si=HQZMbn-KOInQ02o1    由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqmurv/creating_ai_tech_team_using_crewai_generativeai/</guid>
      <pubDate>Fri, 29 Mar 2024 11:23:53 GMT</pubDate>
    </item>
    <item>
      <title>如何评估文本到图像模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqm4cy/how_to_evaluate_texttoimage_model/</link>
      <description><![CDATA[在文本到图像生成问题中，单个文本描述可以转换为不同的图像。例如，给定描述“这只鸟是白色的，有黄色的翅膀”，生成的图像都将具有一只带有黄色翅膀的白色鸟，但可能在姿势、背景等方面有所不同，从而使每个图像根据描述。然而，在验证数据集中，每个文本描述都对应一个实际图像。 那么，如何评估模型的性能呢？具体来说，如何将多个正确生成的图像与单个真实图像进行比较？是否可以应用 Inception Score 和 FID 等指标？如果可以，它们是如何工作的？谢谢   由   提交 /u/Equivalent-Funny3396    reddit.com/r/learnmachinelearning/comments/1bqm4cy/how_to_evaluate_texttoimage_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqm4cy/how_to_evaluate_texttoimage_model/</guid>
      <pubDate>Fri, 29 Mar 2024 10:40:07 GMT</pubDate>
    </item>
    <item>
      <title>从0到机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqlftw/from_0_to_machine_learning/</link>
      <description><![CDATA[你好亲爱的，希望一切顺利 我刚从大学毕业，已经从事业务开发工作了 5 年几个月，因为我需要钱。但我想从事机器学习和人工智能领域的工作。您可以推荐什么课程吗？或者如果您愿意，我可以成为您的助手来帮助您提高我的技能:) 非常感谢    由   提交/u/OccasionLow5310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqlftw/from_0_to_machine_learning/</guid>
      <pubDate>Fri, 29 Mar 2024 09:57:05 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器不是重构输入</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bql8p2/variational_autoencoder_is_not_reconstructing/</link>
      <description><![CDATA[我创建了一个不同频率的正弦曲线的人工数据集，并构建了一个 LSTM-VAE 来重建数据，看看该模型是否可以在潜在空间。 从我所看到的来看，我的实现非常照章办事：编码器采用单变量时间序列，而我采用 hidden[-1, :, : ] 来自其输出，其长度为 hidden_​​dim。它被分别传递到 2 个 FC 层以生成均值和对数变量，两者的长度均为 latent_dim。我使用重新参数化技巧来获取 z，它通过另一个 FC 层返回到 hidden_​​dim。该向量重复 seq_len 次，为解码 lstm 层提供输入，从而生成重建。 我相信我也正确计算了损失（重建 + beta* KL 损失）。超过 100 个 epoch，重建损失（1.1-&gt;0.99）仍然停滞不前。 KL 散度的大小要小得多，并且通常会随着训练过程而减小。在潜在空间中，我实际上看到 3 个不同的频率被分成了潜在空间的 3 个不同部分，这很酷。 不幸的是，重建的输入只是一条平线。 我尝试了不同的隐藏/潜在大小，不同的 beta 值（甚至是 0，完全消除 KL 散度）和不同的学习率并且没有成功，这让我相信我的实现在某个地方是不正确的。不幸的是，我没有运气调试它。 有人对可能出现的问题有任何想法吗？ class Encoder(torch.nn.Module): def __init__（self，input_dim，hidden_​​dim，latent_dim，num_layers）：super（编码器，self）.__init__（）self.lstm = torch.nn.LSTM（input_dim，hidden_​​dim，num_layers，batch_first = True，双向= False，）def向前(self, x): x, (hidden, cell) = self.lstm(x) return x, (hidden, cell) class Sampler(torch.nn.Module): def __init__(self): super(Sampler, self) .__init__() defforward(self, z_mean, z_logvar): epsilon = torch.randn_like(z_mean) z = z_mean + torch.exp(0.5 * z_logvar) * epsilon 返回 z 类解码器(torch.nn.Module): def __init__ （self，input_dim，hidden_​​dim，output_dim，batch_size，seq_len，num_layers）：super（解码器，self）.__init__（） self.seq_len = seq_len self.fc = torch.nn.Linear（in_features = input_dim，out_features = hide_dim，） self.lstm = torch.nn.LSTM（hidden_​​dim，output_dim，num_layers，batch_first = True，双向= False，）def转发（self，x，隐藏）：x = self.fc（x）x = x.unsqueeze（1 ).repeat(1, self.seq_len, 1) x, (hidden, cell) = self.lstm(x) return x, (hidden, cell) class VAE(torch.nn.Module): def __init__(self, input_dim) ,hidden_​​dim,latent_dim,batch_size,seq_len,num_encoder_layers,num_decoder_layers): super(VAE,self).__init__() self.encoder = 编码器( input_dim=input_dim,hidden_​​dim=hidden_​​dim,latent_dim=latent_dim,num_layers=num_encoder_layers, ) self.fc_mean = torch.nn.Linear( in_features=hidden_​​dim, out_features=latent_dim, ) self.fc_logvar = torch.nn.Linear( in_features=hidden_​​dim, out_features=latent_dim, ) self.sampler = Sampler() self.decoder = 解码器( input_dim= Latent_dim、hidden_​​dim=hidden_​​dim、output_dim=input_dim、batch_size=batch_size、seq_len=seq_len、num_layers=num_decoder_layers, ) defforward(self, x): x, (hidden, cell) = self.encoder(x) z_mean = self.fc_mean (hidden[-1, :, :]) z_logvar = self.fc_logvar(hidden[-1, :, :]) 如果 self.training: z = self.sampler(z_mean, z_logvar) else: z = z_mean 重建, (隐藏，细胞）= self.decoder（z，隐藏）返回重建，z_mean，z_logvar类VAELoss（torch.nn.Module）：def __init__（self，beta）：super（VAELoss，self）.__init__（）self.beta = beta self.reconstruction_loss = torch.nn.MSELoss() defforward(self, x, 重建, z_mean, z_logvar):reconstruction_loss = self.reconstruction_loss(重建, x) kl_loss = -0.5 * torch.mean(1 + z_logvar - torch.pow（z_mean，2） - torch.exp（z_logvar））total_loss =重构_loss + self.beta * kl_loss返回total_loss，重构_loss，kl_loss  ​   由   提交/u/coronary-service  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bql8p2/variational_autoencoder_is_not_reconstructing/</guid>
      <pubDate>Fri, 29 Mar 2024 09:43:46 GMT</pubDate>
    </item>
    <item>
      <title>努力使用经过训练的机器学习模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqkgdv/struggling_at_using_a_trained_ml_model/</link>
      <description><![CDATA[一点背景信息：我是一名 Web 开发人员，因此对机器学习知之甚少。  最近，我开始了这个项目，即在平台上构建虚拟试用。 我在 GitHub 上找到了一个适合我的需求的开源 ML 模型，并尝试将它集成到我的应用程序中。 问题：有大量的 python 命令，我不知道它们的含义（尽管我了解 python）。对于没有机器学习背景的人来说，设置它似乎已经很困难了。 我如何“使用”某人构建的机器学习模型？我至少需要学习/了解什么？我猜我不必为了使用模型而学习 ML 中的所有内容？ 这是存储库：https ://github.com/rlawjdghek/StableVITON   由   提交 /u/Flavius_Auvadancer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqkgdv/struggling_at_using_a_trained_ml_model/</guid>
      <pubDate>Fri, 29 Mar 2024 08:51:13 GMT</pubDate>
    </item>
    <item>
      <title>测试准确性学习曲线看起来很奇怪</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqk7o1/test_accuracy_learning_curve_looks_weird/</link>
      <description><![CDATA[我正在 200.000 行的数据集上训练一个广泛而深入的模型，大约有 30 个用于二元分类（搅动）的参数。 &lt; p&gt;当我使用数据集的子集时，我的学习曲线看起来很正常，随着训练和测试精度在历元内不断增加，但当我在完整数据集上训练时，测试精度在 1 个历元后已经上升到 0.97。我做错了什么吗？查看图表。   由   提交 /u/__room101__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqk7o1/test_accuracy_learning_curve_looks_weird/</guid>
      <pubDate>Fri, 29 Mar 2024 08:34:47 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何聊天室（discord、messenger 等）可供人们讨论 ML？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqk2ug/are_there_any_chatrooms_discord_messenger_etc/</link>
      <description><![CDATA[ 由   提交 /u/chjammy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqk2ug/are_there_any_chatrooms_discord_messenger_etc/</guid>
      <pubDate>Fri, 29 Mar 2024 08:25:23 GMT</pubDate>
    </item>
    <item>
      <title>在没有 GPU 的情况下训练 RVC 模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqiyez/train_rvc_model_with_no_gpu/</link>
      <description><![CDATA[我一直在使用 Replicate 在线训练 RVC 模型，但由于某种原因它无法训练超过 100 个 epoch。我看到 Google Colabs 希望我们付费访问或使查找数据集文件夹位置变得过于复杂。如何在 Windows 11 上训练没有 GPU 的 RVC 模型？    由   提交 /u/digitaldisgust   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqiyez/train_rvc_model_with_no_gpu/</guid>
      <pubDate>Fri, 29 Mar 2024 07:05:52 GMT</pubDate>
    </item>
    <item>
      <title>有什么理由不对每个 ML 项目使用 PyTorch（而不是 Scikit）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</link>
      <description><![CDATA[由于神经网络的灵活性，是否有充分的理由在某种情况下不使用它们？您可以构建线性回归、逻辑回归和其他简单模型，以及集成模型。当然，决策树不会成为等式的一部分，但在我看来，无论如何，它们相比之下往往表现不佳。  虽然使用 PyTorch 设置神经网络可能需要多花 1 分钟，但灵活性是无与伦比的，无论如何，项目的未来可能会需要这种灵活性。当然，如果你只是创建一个回归图，那就有点矫枉过正了，但如果你正在构建一个实际的模型？ 我问的原因只是因为我已经开始获取神经网络解决方案每个新项目都会逐渐增加，因为它往往会产生更好的性能，并且可以灵活地进行正则化以避免过度拟合   由   提交/u/cajmorgans  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</guid>
      <pubDate>Fri, 29 Mar 2024 06:33:04 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 竞赛中使用 ChatGPT 编写代码是否合乎道德且可观？或者用它来微调模型。我不会复制任何人的笔记本或提交内容，只是使用人工智能为我编写函数和代码片段。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</link>
      <description><![CDATA[ 由   提交/u/WaveAdministrative36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</guid>
      <pubDate>Fri, 29 Mar 2024 06:10:54 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 3 月 28 日发表的法学硕士相关顶级研究论文摘要</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqhcbg/summary_of_top_llmsrelated_research_papers/</link>
      <description><![CDATA[ 由   提交/u/dippatel21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqhcbg/summary_of_top_llmsrelated_research_papers/</guid>
      <pubDate>Fri, 29 Mar 2024 05:20:04 GMT</pubDate>
    </item>
    <item>
      <title>数据分析师是机器学习的好起点吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqcrx5/is_data_analyst_a_good_place_to_start_in_machine/</link>
      <description><![CDATA[提供一些背景信息： 我拥有 IT 学士学位，并且已经担任软件工程师 2 年了. 我真的很想成为一名机器学习工程师，但找不到像全职工作那样多的时间来处理项目。我正在考虑担任数据分析师或数据工程师的职位，以获得更多处理数据的技能，因为我听说从数据角色过渡到机器学习要容易得多。  任何有行业经验的人都可以确认，与其他路径相比，来自数据背景的人更受追捧，或者至少更容易考虑担任 ML 职位吗？ 我不想得到如果有更好的机器学习方法，就可以找到一份数据工作。    由   提交 /u/Notatrace280   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqcrx5/is_data_analyst_a_good_place_to_start_in_machine/</guid>
      <pubDate>Fri, 29 Mar 2024 01:27:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</link>
      <description><![CDATA[嗨，我是一名本科生，希望创建一个像样的项目来放入我的简历中，正在寻求任何想法/相关主题那些公司在寻找什么？我还想在 ML/AI/GenAI 领域获得实习机会，所以我很难找到一个令人印象深刻/展示我技能的项目。任何建议/帮助将不胜感激。  我在 Python 和 ML 方面相当不错，而且我一直在练习它，我只是在努力想出一个将所有内容联系在一起并适用于 ML 的当前趋势的好项目场地。    由   提交/u/Noodle___13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</guid>
      <pubDate>Fri, 29 Mar 2024 00:55:22 GMT</pubDate>
    </item>
    </channel>
</rss>