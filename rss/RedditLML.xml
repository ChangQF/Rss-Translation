<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 18 Jan 2024 15:14:30 GMT</lastBuildDate>
    <item>
      <title>需要有关我的 AI 模型的输入</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199rqxl/need_input_on_my_ai_model/</link>
      <description><![CDATA[嗨！ 我正在创建一个 AI 模型，以预测何时是向不同的人发送通知的最佳时间。作为特征，我使用了每个人过去与我过去发送的消息的互动情况，并作为他们阅读我的最后一条消息（确切时间）时使用的目标。然后，我使用随机森林来训练模型。我不认为使用他们阅读我最后一条消息的时间作为目标是最佳的。  您能给我一些关于可以用作目标/标签的建议吗？   由   提交 /u/LostStudent7974   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199rqxl/need_input_on_my_ai_model/</guid>
      <pubDate>Thu, 18 Jan 2024 14:45:47 GMT</pubDate>
    </item>
    <item>
      <title>项目：使用 RAG 和 VectorDB 对任何 PDF 文档进行质量检查</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199rq4b/project_qa_on_any_pdf_document_using_rag_and/</link>
      <description><![CDATA[      智能 PDF 阅读器是一个综合项目，利用检索增强的功能基于 Langchain 的大型语言模型 (LLM) 的生成 (RAG) 模型。此外，它还利用 Pinecone 矢量数据库来有效地存储和检索与 PDF 文档相关的矢量。这种方法可以从 PDF 文件中提取基本信息，而无需在问答数据集上训练模型。 查找 GitHub 存储库：此处   由   提交/u/Amazing_Life_221   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199rq4b/project_qa_on_any_pdf_document_using_rag_and/</guid>
      <pubDate>Thu, 18 Jan 2024 14:44:44 GMT</pubDate>
    </item>
    <item>
      <title>专业机器学习工程师简介的项目构想</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199rnhu/project_ideas_for_a_professional_ml_engineer/</link>
      <description><![CDATA[我正在寻找项目创意来创建能够展示 mlops 技能的项目。如有任何建议，我们将不胜感激。   由   提交/u/Desperate_Ad1405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199rnhu/project_ideas_for_a_professional_ml_engineer/</guid>
      <pubDate>Thu, 18 Jan 2024 14:41:21 GMT</pubDate>
    </item>
    <item>
      <title>Azure 机器学习设计器中的拆分数据组件在哪里？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199q8t0/where_is_the_split_data_component_in_azure/</link>
      <description><![CDATA[我正在尝试按照本教程进行操作 并且无法找到他在机器学习工作室设计器中搜索的大部分内容。我不知道这是因为该组件已停用，还是我需要以某种方式启用它。 通常，我无法弄清楚如何使用 Azure 机器学习工具。我在谷歌上搜索了“azure机器学习设计器教程”看看如何从 0 到 1 构建一个项目，但我得到的只是无用的微软文档的链接。   由   提交 /u/Radiant-Message9493    reddit.com/r/learnmachinelearning/comments/199q8t0/where_is_the_split_data_component_in_azure/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199q8t0/where_is_the_split_data_component_in_azure/</guid>
      <pubDate>Thu, 18 Jan 2024 13:33:25 GMT</pubDate>
    </item>
    <item>
      <title>用于主题识别的最佳 NLP 模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199q61s/best_nlp_model_for_topic_identification/</link>
      <description><![CDATA[我正在尝试查找或构建一个脚本，该脚本将文本块作为输入，并识别正在讨论的不同主题。  例如它应该采用这样的文字：“我目前的新闻来源太有偏见了。我有一个正在改变他们报道的新闻类型。我也更喜欢更中立且根据我的喜好量身定制的不同类型的来源。”  并确定这里有 4 个主题：  我当前的新闻来源太有偏见。  我有1正在改变他们报道的新闻类型。 还喜欢更中立的不同类型的来源 并根据我的喜好量身定制。   我不需要总结主题。我只需要知道有 4 个不同的主题，并将每个主题拉入一个字符串数组中。 我想这是 NLP 世界中的一条常见路径。到目前为止，我已经尝试过 NLTK 和 LDA，但运气不佳。 有人有建议或首选库吗？   由   提交 /u/reallymemorable   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199q61s/best_nlp_model_for_topic_identification/</guid>
      <pubDate>Thu, 18 Jan 2024 13:29:50 GMT</pubDate>
    </item>
    <item>
      <title>学习从头开始创建神经网络。我从哪说起呢？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199ptwp/learning_to_create_a_neural_network_from_scratch/</link>
      <description><![CDATA[我想为编程课上的最后一个高中项目训练一个神经网络，但不知道从哪里开始。 Reddit 上有数百个两年或更长时间前的帖子，但几乎没有最近的帖子。我对 Java 和 Python 相当了解，并且非常愿意学习另一种语言。我真正想要的只是一个好的教程，我知道有些人有很好的经验。提前谢谢   由   提交 /u/Crosgaard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199ptwp/learning_to_create_a_neural_network_from_scratch/</guid>
      <pubDate>Thu, 18 Jan 2024 13:11:41 GMT</pubDate>
    </item>
    <item>
      <title>我有一些关于决策树（修剪和过度拟合）的问题，可以回答是或否。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199ol7i/i_have_some_questions_about_decision_trees/</link>
      <description><![CDATA[根据 https://www.youtube .com/watch?v=uwuMhT7t4hY.  修剪是删除低重要性分支的过程，从而提高决策树的性能。   在sklearn中，有ma​​x_深度超参数。给它一个较低的值意味着较小的树，较小的树意味着删除分支。 这是修剪的示例（是/否）吗？我倾向于是，但另有说法&lt; /a&gt;. 从数据集中删除某个特征也会导致树变小并删除分支。 这是修剪的示例（是/否）吗？我也倾向于是。 给定一个完美的数据集，是否有可能不过度拟合决策树分类器（二元分类）？  我有一个数据集可以做到这一点，我什至尝试过仅对 10% 进行训练并在 90% 上进行测试，但仍然提供高于 95% 的准确度，进行了 K 倍验证，仍然是一样的，我在想也许只是鉴于该数据集，也许我做错了什么，这就是为什么我要问是否 是否可以不过度拟合决策树分类器（是/否）。 然而，当我尝试另一个数据集（回归）时，我发现它过度拟合。     由   提交/u/Gullible-Tart-8629   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199ol7i/i_have_some_questions_about_decision_trees/</guid>
      <pubDate>Thu, 18 Jan 2024 12:01:33 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模块化模型（nn.ModuleList）始终比直接实现差</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199nppz/pytorch_modular_model_consistently_nnmodulelist/</link>
      <description><![CDATA[大家好，我的第一篇文章，因为我不知道还能去哪里。我正在写我的论文，我正在尝试创建 nn.Module 类，该类将结构作为输入，并使用相应的层数、输入/输出大小等实例化模型。此类使用 nn.ModuleList() 。我们将此模型称为 A。 我将模型 A 与另一个模型（例如模型 B）进行了比较，后者执行完全相同的操作，但不使用 nn.ModuleList，并且使用标准中的确切参数进行定义方式（例如 class NN(nn.Module):...）就像标准 pytorch 教程中一样。  问题是两个模型都应该做同样的事情，但模型 B 在相同的数据上比模型 A 获得了更好的准确性。 我不确定这是否会发生，也许我在代码中做错了什么，但我的主要问题是：额外的结构是否可能会扰乱 autograd 图，使其变慢，甚至无法像模型 B 那样学习？ 我可以附加如果人们有兴趣，请查看代码。 模型 A structural = {&#39;f&#39;: [[0,100]], &#39;s&#39;: [100, 101]} ConvLayers(nn.Module) 类：  def __init__(self, in_d, kernel_volving, kernel_pool, convolution_stride, pool_stride, hide_channels = [4,4] ): super().__init__() dim = [1] + hide_channels self.conv_layers = nn.ModuleList([nn.Conv1d(dim[i-1], dim[i], = kernel_volving, stride = volving_stride) for i in range(1, len(dim))]) self.pool = nn.MaxPool1d(kernel_pool, pool_stride).to(device) defcalculate_output_length(length_in, kernel_size, stride=1, padding=0, dilation=1): return (length_in + 2 * 填充 - 膨胀 * (kernel_size - 1) - 1) // 步幅 + 1 L_in = in_d for _ in range(1, len(dim)): L_out = 计算输出长度(L_in, kernel_volve, volution_stride) L_out = calculate_output_length(L_out, kernel_pool, pool_stride) L_in = L_out self.out_d = L_in *hidden_​​channels[-1] defforward(self, t): for i in range(len(self.conv_layers)): t = self.pool(F .relu(self.conv_layers[i](t))) return t  类 CNN(nn.Module): def __init__(self,结构体，kernel_volve = 8，kernel_pool = 4，volve_stride = 1，pool_stride = 2，conv_hidden_​​channels = [4,4]，fc_hidden = [24, 24]，device = None）：super().__init__() self.struct =结构体 self.f_in_d = [f[1] - f[0] for f in 结构体[&#39;f&#39;]] self.s_in_d = 结构体[&#39;s&#39;][1] - 结构体[&#39;s&#39;][0] self. device = device self.conv_layers = nn.ModuleList([ConvLayers(in_d, conv_hidden_​​channels, kernel_convolution, kernel_pool, volv_stride, pool_stride) for in_d in self.f_in_d]).to(device) self.out_d_values = [layer.out_d for layer in self.conv_layers] fc_in_d = sum(self.out_d_values) + self.scalar_in_d self.fc_layers = FeedForward(fc_in_d, fc_hidden, dropout = dropout, model_version = “simple”).to(device) defforward(self, x): f_i = [x[:, f[0] : f[1]].unsqueeze(1).to(self.device) for f in self.struct[&#39;f&#39;]] s_i = x[:, self.struct [&#39;s&#39;][0] : self.struct[&#39;s&#39;][1]].reshape(-1, self.scalar_in_d).to(self.device) 结果 = [] 层，input_data in zip(self .conv_layers, f_i): 输出 = 层(input_data) result.append(输出) conv_output = torch.hstack([torch.flatten(torch.hstack(result), 1), s_i]) return(self.fc_layers(conv_output) )  模型 B CNN 类(nn.Module): def __init__(self ，设备）： super().__init__() self.device = 设备 self.conv1 = nn.Conv1d(in_channels = 1, out_channels = 4, kernel_size = 8, stride = 1).to(device) self.pool = nn .MaxPool1d(kernel_size = 4, stride = 2).to(设备) self.conv2 = nn.Conv1d(in_channels = 4, out_channels = 4, kernel_size = 8).to(设备) self.fc1 = nn.Linear(73 , 24).to(设备) self.fc2 = nn.Linear(24, 24).to(设备) self.fc3 = nn.Linear(24, 1).to(设备) defforward(self, x): f, s = x[:,:100].unsqueeze(1).to(self.device), x[:,100].unsqueeze(1).to(self.device) 卷积 = self.pool(F. relu(self.conv2(self.pool(F.relu(self.conv1(func)))))) full = torch.hstack([torch.flatten(卷积, 1), scal]) # 展平除批量之外的所有维度返回 self.fc3(F.relu(self.fc2(F.relu(self.fc1(full)))))     ;由   提交 /u/Altruistic_Desk1464   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199nppz/pytorch_modular_model_consistently_nnmodulelist/</guid>
      <pubDate>Thu, 18 Jan 2024 11:07:15 GMT</pubDate>
    </item>
    <item>
      <title>空气.ai |销售 NLP 机器人</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199nic5/airai_sales_nlp_bot/</link>
      <description><![CDATA[你们知道air.ai吗，他们制造模仿人类的语音驱动销售机器人，我不知道他们是否已经建立了自己的基础模型或使用其他模型，但是他们肯定已经对其进行了微调。 您知道他们用于微调的数据类型吗？   由   提交/u/AdministrativeSea688  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199nic5/airai_sales_nlp_bot/</guid>
      <pubDate>Thu, 18 Jan 2024 10:54:11 GMT</pubDate>
    </item>
    <item>
      <title>有什么好的AI研究和自学助手吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199ldpc/any_good_ai_assistants_for_research_and_selfstudy/</link>
      <description><![CDATA[有没有好的AI助手可以帮我搜索论文、总结论文、解读论文等？理想情况下，它还应该拥有许多学术主题（不仅仅是机器学习！）的广泛知识库。我不介意付一点钱。 我一直在尝试 ChatGPT 的免费版本，但效果非常糟糕。它无法阅读 PDF，通常缺乏知识，并且总是给出令人难以置信的冗长和不明确的答案。   由   提交 /u/HumanSpinach2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199ldpc/any_good_ai_assistants_for_research_and_selfstudy/</guid>
      <pubDate>Thu, 18 Jan 2024 08:24:51 GMT</pubDate>
    </item>
    <item>
      <title>碰壁了，不知道该何去何从</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199ju3q/hit_a_wall_and_dont_know_where_to_go_from_here/</link>
      <description><![CDATA[我已经完成了几门基础 AI 和 ML 课程。我已经掌握了基础知识，自己制作了一些基本模型等。但是，现在我不知道从这里该去哪里，该专攻哪里。我不知道哪个人工智能领域适合我。我对机器人技术感兴趣，也对法学硕士感兴趣，但我想我会更快选择机器人技术。但是，即使是机器人技术也是一个广泛的领域，所以我不知道该专注于它的哪一部分。   由   提交/u/open_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199ju3q/hit_a_wall_and_dont_know_where_to_go_from_here/</guid>
      <pubDate>Thu, 18 Jan 2024 06:40:45 GMT</pubDate>
    </item>
    <item>
      <title>fastai 书，作为 Jupyter Notebooks 出版</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199j24r/the_fastai_book_published_as_jupyter_notebooks/</link>
      <description><![CDATA[    /u/lovestacoo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199j24r/the_fastai_book_published_as_jupyter_notebooks/</guid>
      <pubDate>Thu, 18 Jan 2024 05:53:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型突然变得非常好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199iw44/why_is_my_model_suddenly_extremely_good/</link>
      <description><![CDATA[二元分类数据集。 随机森林 ~ 60% 准确度 神经网络 ~ 62% 准确度 随机森林输出用作神经网络中的新功能 ~ 92% 准确度。 我在某个地方犯了错误吗？这还可能吗？合奏可以这样执行吗？ 编辑 ::: 抱歉，这称为堆叠而不是合奏。我使用了错误的术语。 更新 ::: 我正在重新进行分析，并密切关注是否有任何数据泄漏，因为我不认为我的模型应该显着改进这一点。稍后将更新详细信息和调查结果。谢谢大家的意见。    由   提交/u/lambo_engine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199iw44/why_is_my_model_suddenly_extremely_good/</guid>
      <pubDate>Thu, 18 Jan 2024 05:44:13 GMT</pubDate>
    </item>
    <item>
      <title>井字游戏中强化学习的结果</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199b01v/results_from_reinforcement_learning_in_tictactoe/</link>
      <description><![CDATA[我做了几个月前的一篇文章，想要进行更新。 ​ 我的程序包含 5 个不同的模式：人类、简单、中级、不可能和人工智能。 ​ 我制作了一些图表，其中每个点代表 50,000 次训练中的 200 场比赛片段游戏。 x 轴代表模拟了多少场比赛，而 y 轴代表玩家 1 在该分段中获胜的比赛数量。 ​ 这是我运行的第一个模拟。在前 50,000 场游戏中，它与随机机器人对战，70% 的时间使用 Q 值，30% 的时间随机进行。请注意最后的一个尖峰：这是我关闭随机性的地方，100% 的移动都是从 Q 表中获取的。 ​ 但是，它当面对不可能的极小极大机器人时，仍然表现不佳。所以我用它来训练人工智能。  ​ 这是出来的图表。唯一的区别是每个点代表每个分段的平局次数，而不是玩家 1 获胜。 我还做了一些更改。探索与利用现在成为一个考虑因素，利用的机会从一开始的 0% 到 50,000 场游戏时的 100%（因此更加线性的趋势）。请注意，过去几千场比赛都是平局，得出的结论是机器人现在已经被训练得无与伦比。  ​ 这个结论很快就被驳回了，因为我仍然能够通过玩不规则和不寻常的动作来击败它，而这是它在对抗极小极大游戏时从未遇到过的（就像国际象棋棋手将对手从已知的理论中剔除，因此他们被迫自己思考）。 ​ 我的想法是充分利用两个都。训练的第一部分将针对随机机器人，以涵盖几乎所有可能的场景。然后，让它面对极小极大。 这里是结果（AI 是玩家二）。 前 35,000 场比赛是与简单的比赛进行的机器人；此后的所有比赛都是对抗极小极大。与第二张图类似，剥削率在整个训练过程中缓慢增加，并在第 50,000 场比赛中达到 100%。不幸的是，虽然仍然比以前的版本好得多，但当我偶然发现它尚未探索的位置时，我仍然能够击败它一两次。但在大多数情况下，它保持得很好！  ​ 对于下一部分，我可能会考虑尝试神经网络的实现，或者可能会研究 ML 的不同领域，例如监督/无监督学习。我今年 16 岁，这只是一个学校项目，所以我真的不想花所有时间试图让这个人工智能绝对无敌，因为我还有其他科目要学习...... 如果有人想查看代码，那么我也很乐意上传。谢谢。   由   提交/u/ZenyatasBalls96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199b01v/results_from_reinforcement_learning_in_tictactoe/</guid>
      <pubDate>Wed, 17 Jan 2024 23:19:57 GMT</pubDate>
    </item>
    <item>
      <title>根据这张图，是否过度拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/198ws2x/according_to_this_graph_is_it_overfitting/</link>
      <description><![CDATA[      我的数据不平衡，因此我尝试通过随机过采样对少数数据进行过采样。分数太高了，而且我是机器学习新手，所以我无法理解这个模型是否过度拟合。曲线有问题吗？   由   提交 /u/Felurian_dry   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/198ws2x/according_to_this_graph_is_it_overfitting/</guid>
      <pubDate>Wed, 17 Jan 2024 13:40:23 GMT</pubDate>
    </item>
    </channel>
</rss>