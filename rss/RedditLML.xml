<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 29 Mar 2024 09:12:56 GMT</lastBuildDate>
    <item>
      <title>努力使用经过训练的机器学习模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqkgdv/struggling_at_using_a_trained_ml_model/</link>
      <description><![CDATA[一点背景信息：我是一名 Web 开发人员，因此对机器学习知之甚少。  最近，我开始了这个项目，即在平台上构建虚拟试用。 我在 GitHub 上找到了一个适合我的需求的开源 ML 模型，并尝试将它集成到我的应用程序中。 问题：有大量的 python 命令，我不知道它们的含义（尽管我了解 python）。对于没有机器学习背景的人来说，设置它似乎已经很困难了。 我如何“使用”某人构建的机器学习模型？我至少需要学习/了解什么？我猜我不必为了使用模型而学习 ML 中的所有内容？ 这是存储库：https ://github.com/rlawjdghek/StableVITON   由   提交 /u/Flavius_Auvadancer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqkgdv/struggling_at_using_a_trained_ml_model/</guid>
      <pubDate>Fri, 29 Mar 2024 08:51:13 GMT</pubDate>
    </item>
    <item>
      <title>测试准确性学习曲线看起来很奇怪</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqk7o1/test_accuracy_learning_curve_looks_weird/</link>
      <description><![CDATA[我正在 200.000 行的数据集上训练一个广泛而深入的模型，大约有 30 个用于二元分类（搅动）的参数。 &lt; p&gt;当我使用数据集的子集时，我的学习曲线看起来很正常，随着训练和测试精度在历元内不断增加，但当我在完整数据集上训练时，测试精度在 1 个历元后已经上升到 0.97。我做错了什么吗？查看图表。   由   提交 /u/__room101__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqk7o1/test_accuracy_learning_curve_looks_weird/</guid>
      <pubDate>Fri, 29 Mar 2024 08:34:47 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何聊天室（discord、messenger 等）可供人们讨论 ML？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqk2ug/are_there_any_chatrooms_discord_messenger_etc/</link>
      <description><![CDATA[ 由   提交 /u/chjammy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqk2ug/are_there_any_chatrooms_discord_messenger_etc/</guid>
      <pubDate>Fri, 29 Mar 2024 08:25:23 GMT</pubDate>
    </item>
    <item>
      <title>在没有 GPU 的情况下训练 RVC 模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqiyez/train_rvc_model_with_no_gpu/</link>
      <description><![CDATA[我一直在使用 Replicate 在线训练 RVC 模型，但由于某种原因它无法训练超过 100 个 epoch。我看到 Google Colabs 希望我们付费访问或使查找数据集文件夹位置变得过于复杂。如何在 Windows 11 上训练没有 GPU 的 RVC 模型？    由   提交 /u/digitaldisgust   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqiyez/train_rvc_model_with_no_gpu/</guid>
      <pubDate>Fri, 29 Mar 2024 07:05:52 GMT</pubDate>
    </item>
    <item>
      <title>批评我在集合预测平均中调整多重共线性的新方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqiv79/critique_my_novel_approach_to_adjust_for/</link>
      <description><![CDATA[大家好，我是一名刚高中毕业的学生，​​对机器学习/统计非常感兴趣，很快就会开始我的数据科学学位。&lt; /p&gt; 最近我一直在阅读有关集成建模和平均预测的方法，然后思考高度相关的特征/预测的问题。 我一直在考虑一种新颖的方法来地址相关功能，我想寻求您对此的反馈，以了解我是否只是愚蠢或遗漏了一些重要的东西。 ​ 场景  考虑 N 个因素，每个因素都用于生成目标变量 Y(t+1) 的简单线性预测。 因此在任何时间 t， Y 在 t+1 处有 N 个预测。 通过取每个预测的平均值来计算最终的组合预测。  多重共线性问题  对这些预测进行平均假定每个因素具有同等重要性，因为它为所有因素分配相同的权重 (w=1/N)。 但是，此方法不准确地强调了彼此高度相关的因素。  我调整相关特征的方法  为了缓解这种情况，如果您根据每个要素与其他要素之间的绝对相关性对每个要素或预测应用了加权方法，如下所示： 要素 X 的相关性调整权重 = (1 - 绝对相关性的平均值所有其他特征） 其中每个特征的最终有效权重只是其相关性调整权重除以所有特征相关性调整权重的总和。 我的原因使用一个特征与其他特征的绝对相关性的平均值是指，无论一个特征与另一个特征的相关性是1还是-1，无论哪种方式，该特征都不会增加新的价值或信息（除非我错了？）。  基本原理  每个特征权重应根据其与其他特征的相关性进行向下调整，因为这种相关性量化了信息的重复。&lt; /li&gt;  简化 示例 想象 3 个因数 X1、X2、X3，其中  X1 与 X2 和 X3 的相关性为 0， X2 和 X3 的相关性为 1。  平均预测意味着每个因素的权重为 1 /N（在本例中为 1/3）。 但是，如果 X2 和 X3 几乎相同，则意味着 X2 和 X3 几乎相同，并且对 X1、X2 的预测进行平均，X3，导致错误地超重 X2 和 X3 (w=2/3)，并低估 X1 (w = 1/3)。 因此，使用我的方法来调整每个因素的权重，我们得到：&lt; /p&gt;  调整后的 X2 权重= 1 - (1+0)/2 = 0.5 调整后的 X3 权重 = 1 - (1+0)/2 = 0.5 调整后的 X3 权重 = 1 - (1+0)/2 = 0.5 调整后的 X3 权重 = 1 - (1+0)/2 = 0.5 li&gt; X1 的调整权重 = 1 - (0+0)/2 = 1 调整权重之和 = 0.5 + 0.5 + 1 = 2  如果我们将每个因素调整权重与调整权重之和的比率，我们得到  有效调整权重X2 = 0.5 / 2 = 0.25 有效X3 的调整权重 = 0.5 / 2 = 0.25 X1 的有效调整权重 = 1 / 2 = 0.5  因此，如您所见，调整已调整为X2和X3完美相关，因为  X2和X3的有效调整权重之和为1/2 X1的有效调整权重现在为1 /2  ​ _____________________ ​ 我的问题 strong&gt;  您对这种方法有何看法？ 它在逻辑上有意义吗？ 是否有类似的模型/方法？ 是否有类似的模型/方法？ li&gt; 有什么关键缺陷吗？ .....即我是不是一个完全业余的白痴，忽略了一些关键或明显的东西？  谢谢！   由   提交 /u/YourGoodFriend44   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqiv79/critique_my_novel_approach_to_adjust_for/</guid>
      <pubDate>Fri, 29 Mar 2024 07:00:11 GMT</pubDate>
    </item>
    <item>
      <title>有什么理由不对每个 ML 项目使用 PyTorch（而不是 Scikit）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</link>
      <description><![CDATA[由于神经网络的灵活性，是否有充分的理由在某种情况下不使用它们？您可以构建线性回归、逻辑回归和其他简单模型，以及集成模型。当然，决策树不会成为等式的一部分，但在我看来，无论如何，它们相比之下往往表现不佳。  虽然使用 PyTorch 设置神经网络可能需要多花 1 分钟，但灵活性是无与伦比的，无论如何，项目的未来可能会需要这种灵活性。当然，如果你只是创建一个回归图，那就有点矫枉过正了，但如果你正在构建一个实际的模型？ 我问的原因只是因为我已经开始获取神经网络解决方案每个新项目都会逐渐增加，因为它往往会产生更好的性能，并且可以灵活地进行正则化以避免过度拟合   由   提交/u/cajmorgans  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqigwy/any_reason_to_not_use_pytorch_for_every_ml/</guid>
      <pubDate>Fri, 29 Mar 2024 06:33:04 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 竞赛中使用 ChatGPT 编写代码是否合乎道德且可观？或者用它来微调模型。我不会复制任何人的笔记本或提交内容，只是使用人工智能为我编写函数和代码片段。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</link>
      <description><![CDATA[ 由   提交/u/WaveAdministrative36   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqi4q0/is_it_ethical_and_considerable_to_use_chatgpt_to/</guid>
      <pubDate>Fri, 29 Mar 2024 06:10:54 GMT</pubDate>
    </item>
    <item>
      <title>我的本科机器学习课程项目学习主题建模的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqhx28/what_would_be_the_optimal_approach_for_learning/</link>
      <description><![CDATA[我选择使用 Bangla Wikipedia 开展主题建模项目，因为对此主题的研究有限且准确度分数较高。我的课程涵盖了常见的机器学习和一些带有实验室实现的深度学习算法。目前，我正在学习LDA和LDA2Vec算法并打算实现它们。我还打算将这个项目扩展为将来可能发表的论文。任何有关此努力的最佳学习路径的建议将不胜感激。   由   提交 /u/SkirtSea5456   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqhx28/what_would_be_the_optimal_approach_for_learning/</guid>
      <pubDate>Fri, 29 Mar 2024 05:56:58 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 3 月 28 日发表的法学硕士相关顶级研究论文摘要</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqhcbg/summary_of_top_llmsrelated_research_papers/</link>
      <description><![CDATA[ 由   提交/u/dippatel21  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqhcbg/summary_of_top_llmsrelated_research_papers/</guid>
      <pubDate>Fri, 29 Mar 2024 05:20:04 GMT</pubDate>
    </item>
    <item>
      <title>在扩散概率模型论文中努力求导</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqemz5/struggling_with_a_derivation_in_the_diffusion/</link>
      <description><![CDATA[我正在努力解决 Sohl-Dickstein 等人论文中的推导问题。 al，“使用非平衡热力学的深度无监督学习” （2015）：https://arxiv.org/pdf/1503.03585.pdf  我有在下面的链接中发布了我关于 AI 堆栈交换的问题： https://ai.stackexchange.com/questions/45272/trying-to-understand-some-derivation-in-the-paper-deep-unsupervised-learning-us 请帮我解决这个问题。提前致谢。    由   提交 /u/possiblemonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqemz5/struggling_with_a_derivation_in_the_diffusion/</guid>
      <pubDate>Fri, 29 Mar 2024 02:56:08 GMT</pubDate>
    </item>
    <item>
      <title>您将如何对流程进行后缀预测？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqdl81/how_would_you_do_the_suffix_prediction_for_a/</link>
      <description><![CDATA[此上下文中的进程是一组按顺序发生的事件。想象一下正在经历各个阶段处理的贷款申请。一个流程可以有 1 到大约 200 个任意数量的事件。 任务是根据前 x 个事件，我必须预测流程中的其余事件。假设我得到了一个大小为 3 的前缀，其中包含事件 A、B 和 C，并且我必须预测其余事件，直到该过程结束（即后缀）。现在显然每个进程没有有限/固定数量的事件，因此基本上任务是预测将要发生的事件数量以及实际事件本身。 我真的陷入困境关于如何做到这一点。我完全不知道你会使用什么型号。我越想就越困惑。 有人可以指导我正确的方法吗？我非常感谢该领域一些有经验的人的帮助。   由   提交/u/Leading_Ad_4884   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqdl81/how_would_you_do_the_suffix_prediction_for_a/</guid>
      <pubDate>Fri, 29 Mar 2024 02:05:39 GMT</pubDate>
    </item>
    <item>
      <title>数据分析师是机器学习的好起点吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqcrx5/is_data_analyst_a_good_place_to_start_in_machine/</link>
      <description><![CDATA[提供一些背景信息： 我拥有 IT 学士学位，并且已经担任软件工程师 2 年了. 我真的很想成为一名机器学习工程师，但找不到像全职工作那样多的时间来处理项目。我正在考虑担任数据分析师或数据工程师的职位，以获得更多处理数据的技能，因为我听说从数据角色过渡到机器学习要容易得多。  任何有行业经验的人都可以确认，与其他路径相比，来自数据背景的人更受追捧，或者至少更容易考虑担任 ML 职位吗？ 我不想得到如果有更好的机器学习方法，就可以找到一份数据工作。    由   提交 /u/Notatrace280   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqcrx5/is_data_analyst_a_good_place_to_start_in_machine/</guid>
      <pubDate>Fri, 29 Mar 2024 01:27:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</link>
      <description><![CDATA[嗨，我是一名本科生，希望创建一个像样的项目来放入我的简历中，正在寻求任何想法/相关主题那些公司在寻找什么？我还想在 ML/AI/GenAI 领域获得实习机会，所以我很难找到一个令人印象深刻/展示我技能的项目。任何建议/帮助将不胜感激。  我在 Python 和 ML 方面相当不错，而且我一直在练习它，我只是在努力想出一个将所有内容联系在一起并适用于 ML 的当前趋势的好项目场地。    由   提交/u/Noodle___13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bqc3dw/ml_project_ideas/</guid>
      <pubDate>Fri, 29 Mar 2024 00:55:22 GMT</pubDate>
    </item>
    <item>
      <title>DeepMLeet 简介：一个基于挑战的新机器学习和深度学习平台</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bpx7h7/introducing_deepmleet_a_new_challengebased/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享一个我一直热衷于从事的项目：DeepMLeet。受到 LeetCode 等基于挑战的平台格式的启发，DeepMLeet 带来了独特的变化——它专门致力于机器学习 (ML) 和深度学习 (DL) 挑战。我创建这个网站的目标是帮助我自己和其他人提高技能，深入研究有趣的问题，并在同行社区中交流见解。 截至目前，该项目仍在开发中。我最近完成了一个关于线性代数问题的重要部分，为机器学习和深度学习中关键的数学概念奠定了基础。下一阶段涉及围绕机器学习策划和构建挑战，随后，我将重点关注深度学习部分。 DeepMLeet 是一个开源事业，如果您有兴趣添加问题或有任何建议，我希望您通过 GitHub 上的拉取请求做出贡献 moe18/DeepMLeet。 我渴望听到您的反馈！让我知道您对 DeepMLeet 的看法、您希望看到的任何功能，或者它如何更好地服务您的学习之旅。您的意见对于将 DeepMLeet 打造成真正有益于机器学习和深度学习社区的资源而言非常宝贵。 期待您的想法和贡献！   由   提交/u/mosef18  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bpx7h7/introducing_deepmleet_a_new_challengebased/</guid>
      <pubDate>Thu, 28 Mar 2024 14:39:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么是梯度下降？为什么不求解 dy/dx = 0</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1bpou7i/why_gradient_descent_and_why_not_solve_for_dydx_0/</link>
      <description><![CDATA[在 ML 和 DL 中，我们的主要重点是优化，我们使用梯度下降来实现这一点。 因为，我们有确定的已经针对不同情况定义了成本函数，为什么我们不采用成本函数的导数并求解 dy/dx =0，然后求解最大或最小点 ​ ​ p&gt; 我知道，我们在获取这些极值点时可能会遇到一些问题，但是 GD 优化也有很多复杂性。   由   提交 /u/naniramd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1bpou7i/why_gradient_descent_and_why_not_solve_for_dydx_0/</guid>
      <pubDate>Thu, 28 Mar 2024 06:34:29 GMT</pubDate>
    </item>
    </channel>
</rss>