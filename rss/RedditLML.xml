<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 18 Jul 2024 21:13:59 GMT</lastBuildDate>
    <item>
      <title>对数学“失去兴趣”？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6lw2a/disattracted_from_the_math/</link>
      <description><![CDATA[我自学了 CS229，但已经很难不深入其中而完全理解数学。这里只需提一下：我的背景是电气工程。已经找到工作，并利用业余时间做这件事。 我的问题是，我总是倾向于在数学上花费比一般概念更多的时间。不是因为我太挣扎，而是因为我想尽我所能地理解它，并且有一种 FOMO。还有其他人有这种经历吗？它确实耗费了太多时间，我觉得我在 ML 本身上只取得了很小的进展。    提交人    /u/GefallenesObst   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6lw2a/disattracted_from_the_math/</guid>
      <pubDate>Thu, 18 Jul 2024 20:54:03 GMT</pubDate>
    </item>
    <item>
      <title>ML 面试准备指导和资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6le6g/ml_interview_preparation_guidance_and_resources/</link>
      <description><![CDATA[大家好！ 我刚刚开始寻找机器学习/数据工程或相关实习。过去 2 年，我一直从事 ML 和 DL 工作，项目涉及 LLM 和扩散模型。虽然我很久以前就学习了基础知识，但我知道大多数面试都强调这些基础知识。是否有专门的资源可以帮助复习 ML 基础知识？ 我对面试的另一个疑问，特别是在数据领域的面试，是强调 DSA（数据结构和算法）。虽然我知道 DSA 是基础，任何 CS 工作都需要这方面的知识，相对于 ML 工作，DSA 需要多少？与从事与 ML 相关的工作相比，我发现做 LeetCode 问题无休止地累人。我觉得专注于获得 DSA 所需的实力以通过面向数据的工作的筛选轮次会很有帮助。我应该如何处理？ SDE 申请者可以借助多个平台准备面试。 有没有什么平台可以帮助 MLE 或 DE 申请者？ 除了这些和研究论文之外，在准备面试时我还应该注意什么？ 提前谢谢！ 干杯！    提交人    /u/Administrative_Scar4   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6le6g/ml_interview_preparation_guidance_and_resources/</guid>
      <pubDate>Thu, 18 Jul 2024 20:33:37 GMT</pubDate>
    </item>
    <item>
      <title>保存 Facebook 先知模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6l6pr/saving_facebook_prophet_model/</link>
      <description><![CDATA[如果我在大量数据上拟合预言模型，保存拟合模型是否有意义？我习惯使用 Scikit Learn 模型，这非常标准。 一位团队成员声称保存拟合的预言模型没有意义。    提交人    /u/GongtingLover   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6l6pr/saving_facebook_prophet_model/</guid>
      <pubDate>Thu, 18 Jul 2024 20:24:44 GMT</pubDate>
    </item>
    <item>
      <title>有人能帮我使用 Cloud TPU 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6l4mn/can_someone_help_me_with_cloud_tpus/</link>
      <description><![CDATA[嘿！ 花了几个小时阅读 Cloud TPU 文档后，我有点困惑。我想使用现货/可抢占的 Cloud TPU 来代替足够的 GPU（我现在很遗憾缺少 GPU），但我有点迷失在实际需要支付的费用、是否需要不断配置 VM 实例、是否需要将训练数据上传到 Cloud Datastore、2024 年 Torch 支持有多好（或多坏）等等... 有人知道最近的好解释或视频吗？或者使用云 TPU 并有一些意见？✨ [ps。不要再给我发垃圾私人消息了。我希望了解社区的想法，而不是为 LLM 吐出的东西付钱给“legitimatetutor9999”]   由    /u/parametricRegression  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6l4mn/can_someone_help_me_with_cloud_tpus/</guid>
      <pubDate>Thu, 18 Jul 2024 20:22:20 GMT</pubDate>
    </item>
    <item>
      <title>流行算法的 Scratch 实现</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6kh5t/scratch_implementations_of_popular_algorithms/</link>
      <description><![CDATA[嗨，我对学习 LLM 及其实际工作原理很感兴趣。我遇到的一个存储库是 llama-3-from-scratch。这是作者做的一个非常有趣的练习。我想知道是否还有其他存储库可以从头开始教授这些概念。我还发现了 Andrej Karpathy 的精彩讲座，以及哈佛大学的 transformers 的入门实现。谢谢！！    提交人    /u/ChaoticChaosConfused   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6kh5t/scratch_implementations_of_popular_algorithms/</guid>
      <pubDate>Thu, 18 Jul 2024 19:55:43 GMT</pubDate>
    </item>
    <item>
      <title>异质性图学习手册：基准、模型、理论分析、应用和挑战</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6jvfd/the_heterophilic_graph_learning_handbook/</link>
      <description><![CDATA[      很高兴与大家分享我们最近的作品《异质图学习手册》 https://arxiv.org/pdf/2407.09618v1。作为图的最基本属性之一，异质性对几乎所有与图相关的应用程序和基于消息传递的模型（包括 transformer 和图 transformer）都具有强大的影响。我们的论文是一个友好的教程，也是一本全面的参考书，可帮助您研究异质性图学习。欢迎提出建议和意见！ https://preview.redd.it/j4viv78hxbdd1.png?width=817&amp;format=png&amp;auto=webp&amp;s=562a1ac195880d41eee5217ea8b15c395bd9f5cd    提交人    /u/Ok_Confidence6681   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6jvfd/the_heterophilic_graph_learning_handbook/</guid>
      <pubDate>Thu, 18 Jul 2024 19:30:19 GMT</pubDate>
    </item>
    <item>
      <title>对于那些有兴趣了解如何在英特尔 Tiber 开发者云上构建和实施 ML 工作负载的人，请查看文章。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6iqw3/for_those_who_are_interested_in_learning_how_to/</link>
      <description><![CDATA[        提交人    /u/ramyaravi19   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6iqw3/for_those_who_are_interested_in_learning_how_to/</guid>
      <pubDate>Thu, 18 Jul 2024 18:44:23 GMT</pubDate>
    </item>
    <item>
      <title>DeepLearning.ai 高级算法课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6hhd9/deeplearningai_advanced_algorithms_course/</link>
      <description><![CDATA[      在观看 Andrew ng 的机器学习专业第二门课程中的前向传播视频时，我注意到如图所示的权重每个单元的权重都是按列计算的 W[:,j]，而不是按行计算的。我真的觉得这不仅从编程的角度而且从理论上来说都与正常的行权重向量相悖。有人能告诉我他为什么这样做吗？我一点也不为此辩护，但我真的想知道为什么，因为我确实认为当我自己实现神经网络时我会犯错。    提交人    /u/Extension-Group2131   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6hhd9/deeplearningai_advanced_algorithms_course/</guid>
      <pubDate>Thu, 18 Jul 2024 17:46:59 GMT</pubDate>
    </item>
    <item>
      <title>ML 系统设计：450 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6h0k0/ml_system_design_450_case_studies_to_learn_from/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 450 个 ML 用例的数据库链接，这些用例详细介绍了 ML 和 LLM 系统设计。您可以按行业或 ML 用例进行筛选。 如果这里有人着手设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design  免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6h0k0/ml_system_design_450_case_studies_to_learn_from/</guid>
      <pubDate>Thu, 18 Jul 2024 17:27:18 GMT</pubDate>
    </item>
    <item>
      <title>对人工智能炒作的共识？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6gouc/consensus_on_ai_hype/</link>
      <description><![CDATA[您的看法是什么？我在参加 GPT 之前就对 AI 很感兴趣，但无法深入了解数学或要求。但我最近从这个小组和其他 AI 小组看到，AI 被炒作了。尽管如此，它还是很有用的。由于对数据感兴趣，我仍在学习它，但您认为 5 年后 AI 会成为一种实用工具吗？我正在尝试过渡到它。但我想知道您的答案，因为我知道 AI 炒作会逐渐消退，全球对它的兴趣也会逐渐消退。顺便说一下，我有金融背景。     提交人    /u/bliss22_23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6gouc/consensus_on_ai_hype/</guid>
      <pubDate>Thu, 18 Jul 2024 17:13:52 GMT</pubDate>
    </item>
    <item>
      <title>你们是如何学习 LLms 基本知识的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e6c27t/how_have_you_guys_learnt_llms_genai_n_stuffs/</link>
      <description><![CDATA[我只是太困惑了，我是否应该正确地构建基础知识或直接进入高级主题......  任何经历过数据科学面试的人，他们是否会深入询问你迄今为止学到的所有内容，例如 nlp，dl 等？因为根据我的经验，他们到目前为止从未真正深入询问过 ML......     提交人    /u/prettyvanza   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e6c27t/how_have_you_guys_learnt_llms_genai_n_stuffs/</guid>
      <pubDate>Thu, 18 Jul 2024 13:56:03 GMT</pubDate>
    </item>
    <item>
      <title>你们在进入机器学习之前喜欢数学吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e68syz/did_you_guys_enjoy_maths_before_getting_into_ml/</link>
      <description><![CDATA[我已经好几年没学过数学了，所以我一直在努力复习线性代数、统计学等。其实我真的很喜欢。我认为看到我所学知识的实际意义让事情变得更有趣了。并不是说我以前讨厌数学，但我绝对没有想过自己会在空闲时间做数学。 我注意到很多从事机器学习的人已经对数学产生了兴趣。无论是数学或统计学学位，还是数据科学学位等。只是希望听到一些程序员变成数学家的成功故事，而不是数学家变成程序员的故事。    提交人    /u/remerdy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e68syz/did_you_guys_enjoy_maths_before_getting_into_ml/</guid>
      <pubDate>Thu, 18 Jul 2024 11:11:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络“战斗”以求胜利：生成对抗网络（GAN）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e66fhc/neural_networks_fight_to_win_generative/</link>
      <description><![CDATA[      假设您有一个神经网络 (NN1)，其任务是初始输出随机噪声 32x32 矩阵（噪声图像）。 现在假设有第二个神经网络 (NN2)。NN1 的输出作为 NN2 的输入。 NN2 经过训练，可以预测输入的 32x32 图像为“猫”这一特定图像的概率 (p)。 由于初始输入图像是噪声，概率“p”将是一个较低的数字。假设 p = 0.001。 现在我们可以为 NN1 和 NN2 定义损失函数。 如果预测输出“p”接近于零，则 NN1 的损失非常低。 ‘p’ 的值越高，损失越大。 如果预测输出 ‘p’ 接近 1，NN2 的损失就非常低。你明白这意味着什么吗？这意味着 NN1 输出的图像看起来非常像 NN2 所指的猫图像。 基本上，如果 ‘p’ 接近 1，那么 NN1 会生成一个与原始猫一模一样的‘假’猫图像。 那么我们如何尝试使输出 ‘p’ 尽可能接近 1？我们让 NN1 对抗 NN2。 NN1 有一个独特的使命。让 ‘p’ 接近 1。 NN2 有一个独特的使命。使“p”接近于 0。 如果我们根据相应的损失训练 NN1 和 NN2 的权重和偏差，我们会得到一个非常好的“生成器”，它可以创建一个非常好看的“假”猫图像。 这个简单的任务是 GAN 的基本原理：生成对抗网络。 NN1 称为生成器。 NN2 称为鉴别器。 他们是对手。 听说过 Deepfake 吗？你可能看过特朗普说话和奥巴马一模一样的视频/GIF。GAN 可以实现这一点。 GAN 与当前生成式 AI 图像模型中使用的扩散模型有很大不同。但 GAN 更简单，更适合非常明确的任务。 这是一个如此令人惊叹的概念，但又如此简单，你会想你怎么可能想不出这个？我想这就是任何美好事物的魅力所在。 我创建了一整篇关于 GAN 的讲座：https://youtu.be/AKfPXbdLdO8  我将介绍以下内容。 1) 什么是 GAN？ 2) GAN 的应用 3) 回顾 Goodfellow 等人的开创性 GAN 论文 4) 在 Google Colab 上实现 GAN。视频说明中提供了 Colab 笔记本的链接。 祝您实现 GAN 愉快。  https://i.redd.it/7cgwfxvin8dd1.gif    由   提交  /u/thesreedath   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e66fhc/neural_networks_fight_to_win_generative/</guid>
      <pubDate>Thu, 18 Jul 2024 08:32:40 GMT</pubDate>
    </item>
    <item>
      <title>阅读《机器为何学习》。数学问题。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1e5s8hh/reading_why_machines_learn_math_question/</link>
      <description><![CDATA[      如果权重向量初始化为0，结果不是一直都是0吗？     由    /u/Tyron_Slothrop  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1e5s8hh/reading_why_machines_learn_math_question/</guid>
      <pubDate>Wed, 17 Jul 2024 20:18:49 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>