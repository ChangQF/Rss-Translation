<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Mon, 21 Oct 2024 09:19:00 GMT</lastBuildDate>
    <item>
      <title>需要有关学习机器学习的建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8lbs4/need_suggestions_on_learning_ml/</link>
      <description><![CDATA[嗨，我大约在 9 月份开始了我的数据科学 ML 之旅，在此之前我参加了一些 Python 和基础数据分析可视化课程，现在我正在学习 SQL，同时也在学习 ML 基础知识。我正在学习 Coursera 的 Andrew NG 专业课程，已经完成了一半。所以我想也许我应该开始做一些机器学习方面的项目。但我不知道如何以及从哪里开始。当我看其他人的项目时，似乎我和他们之间存在很大的知识差距，我觉得我什么都没学到。     提交人    /u/yours_moonly   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8lbs4/need_suggestions_on_learning_ml/</guid>
      <pubDate>Mon, 21 Oct 2024 09:09:01 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity Pro 年度优惠券现价为 30 美元或 27 欧元</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8l439/perplexity_pro_yearly_coupon_available_for_30_or/</link>
      <description><![CDATA[我有 1 年 Perplexity Pro 代金券，可为您提供 100% 折扣 – 仅需 30 美元（28 欧元）！这包括访问以下高级模型： Claude 3.5 Sonnet、Claude 3 Opus* GPT-4o、OpenAI o1 Llama 3.1  图像生成器：Flux 1、DALL-E 3、Stable Diffusion XL 和 Playground v3  可在全球范围内使用，并且使用 PayPal 付款是安全的。我也接受加密 工作原理：  在这里或在WhatsApp上给我发私信：点击此处。 通过 PayPal 或您喜欢的方式付款。 我会直接将优惠券激活到您的电子邮箱。  我还有6 个月的 LinkedIn Business Premium 查看我以前买家的优惠券：查看反馈 反馈 2, 反馈 3, 反馈 4、反馈 5、反馈 6）。    提交人    /u/TheeOracle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8l439/perplexity_pro_yearly_coupon_available_for_30_or/</guid>
      <pubDate>Mon, 21 Oct 2024 08:52:36 GMT</pubDate>
    </item>
    <item>
      <title>7 分钟解释人工智能与机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8l3sf/ai_vs_machine_learning_explained_in_7_minutes/</link>
      <description><![CDATA[        提交人    /u/SoftwareDream   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8l3sf/ai_vs_machine_learning_explained_in_7_minutes/</guid>
      <pubDate>Mon, 21 Oct 2024 08:51:56 GMT</pubDate>
    </item>
    <item>
      <title>有人能帮我做一些长镜头微调吗</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8krt1/can_someone_help_me_with_few_shot_longformer/</link>
      <description><![CDATA[我正在尝试微调长模型，以便在仅 2 个类别上进行文本分类。我正在使用 DAIC-WOZ 数据集进行抑郁症检测。问题是存在类别不平衡（我通过同义词替换解决了这个问题），并且每个类别的样本数量非常少（每个类别约 120 个）。  该模型似乎并没有减少其训练和验证损失。我得到的最佳准确率约为 50%，最佳 F1 分数约为 67%。  我想研究一些样本学习方法或任何可以在我的小数据集上微调这个大模型的方法。谢谢！    提交人    /u/vollhard-natta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8krt1/can_someone_help_me_with_few_shot_longformer/</guid>
      <pubDate>Mon, 21 Oct 2024 08:25:25 GMT</pubDate>
    </item>
    <item>
      <title>我可以在非图像分类中使用 NN 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8k205/can_i_use_nn_on_nonimage_classification/</link>
      <description><![CDATA[我有一个关于机器学习的学校项目，想知道神经网络是否可以用于图像以外的分类任务。  数据集是带有分类变量的表格，尝试实现神经网络是否可行，或者我们最好使用决策树和逻辑回归？    提交人    /u/Wonderful_Chemist266   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8k205/can_i_use_nn_on_nonimage_classification/</guid>
      <pubDate>Mon, 21 Oct 2024 07:27:51 GMT</pubDate>
    </item>
    <item>
      <title>硬负挖掘和嵌入增强</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8jzmb/hard_negative_mining_and_embedding_enhancement/</link>
      <description><![CDATA[我有一个用于法律文档检索的嵌入任务，需要提高相关检索文档的 MRR 分数。我的数据集包含大约 200k 对 {query: str,legal_doc: str}。所以我有几个问题   我已经推断出 BAAI/bge-large-en，结果非常令人印象深刻，但该模型在长查询上下文中仍然表现不佳。有没有表现良好的 &lt;1B 模型？ 为了在重新排名期间获得更高的准确性和召回率，我需要在将数据提供给模型之前进行硬负挖掘，但我已经搜索过并且没有找到与此工作流程相关的任何管道，如何挖掘硬负，是否有挖掘硬负的限制？   提前致谢    提交人    /u/Disastrous-Sand8882   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8jzmb/hard_negative_mining_and_embedding_enhancement/</guid>
      <pubDate>Mon, 21 Oct 2024 07:22:39 GMT</pubDate>
    </item>
    <item>
      <title>提示报告：提示技巧调查</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8im6k/the_prompt_report_prompting_techniques_survey/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8im6k/the_prompt_report_prompting_techniques_survey/</guid>
      <pubDate>Mon, 21 Oct 2024 05:40:04 GMT</pubDate>
    </item>
    <item>
      <title>如何做笔记？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8d2h5/how_to_take_notes/</link>
      <description><![CDATA[那些自己教机器学习的人，你们是如何记笔记的，以及你们后来是如何复习的？有什么特别的笔记方法或推荐的应用程序吗？    提交人    /u/binarySolo0h1   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8d2h5/how_to_take_notes/</guid>
      <pubDate>Mon, 21 Oct 2024 00:16:22 GMT</pubDate>
    </item>
    <item>
      <title>最近开始学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8clmu/started_ml_recently/</link>
      <description><![CDATA[您好，我是后端/数据工程方面的高级软件工程师，最近开始学习机器学习。我们进入这个领域是不是太晚了？与已经了解该领域的人相比，我看到的招聘信息非常少。此外，像我一样学习的人的数量每天都在增加。如果 AIML 行业的人能帮助我了解这种情况，那就太好了。     提交人    /u/smithabs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8clmu/started_ml_recently/</guid>
      <pubDate>Sun, 20 Oct 2024 23:52:25 GMT</pubDate>
    </item>
    <item>
      <title>从自学机器学习转向数据工程：寻求建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g8an1v/switching_from_selfstudied_machine_learning_to/</link>
      <description><![CDATA[我毕业于印度一所三级公立大学，对机器学习一直充满热情。毕业后，我花了一年时间致力于学习传统机器学习以及云和 MLOps 背后的数学、统计学和技术。我没有选择找工作或攻读 ME，而是选择自学。然而，由于目前的就业市场严重偏爱有经验的求职者，而实习机会大多提供给在校学生，因此这很有挑战性。此外，机器学习职位现在通常需要深度学习和生成式人工智能方面的技能，而我没有足够的时间在家学习这些技能。所以，我决定转向数据工程职位。任何建议或意见都将不胜感激！    提交人    /u/Big-Breakfast5031   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g8an1v/switching_from_selfstudied_machine_learning_to/</guid>
      <pubDate>Sun, 20 Oct 2024 22:16:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么 DDPM 实现的正弦位置编码与 transformer 不同？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g876j8/why_do_ddpms_implement_a_different_sinusoidal/</link>
      <description><![CDATA[      嗨， 我正在尝试为 DDPM 实现正弦位置编码。我发现了两种解决方案，它们以相同的嵌入维度为相同的位置/时间步长计算不同的嵌入。我想知道其中一个是错的还是两个都是正确的。DDPM 官方源代码不使用 transformers 论文中使用的原始正弦位置编码……为什么？ 1) 来自“Attention is all you need”的原始正弦位置编码纸。 原始正弦 https://preview.redd.it/a6atl1v0rzvd1.png?width=1494&amp;format=png&amp;auto=webp&amp;s=fdad3639837b88f5dc266105e0645c37043302a4 2）DDPM论文官方代码中使用的正弦位置编码 DDPM 中使用的正弦位置编码 https://preview.redd.it/aps58hwvqzvd1.png?width=1478&amp;format=png&amp;auto=webp&amp;s=c9f0c15547615727479ee2a270fa3684712dd88b 为什么 DDPM 的官方代码使用的编码（选项 2）与 transformer 论文中使用的原始正弦位置编码不同？对于 DDPM 来说，第二种选择是否更好？ 我注意到官方 DDPM 代码实现中使用的正弦位置编码是从 tensor2tensor 借用的。实现上的差异甚至在对官方 tensor2tensor 实现的 PR 提交中突出显示。为什么 DDPM 的作者使用这种实现（选项 2）而不是来自 transformers 的原始实现（选项 1）？ ps：如果您想检查代码，请访问这里 https://stackoverflow.com/questions/79103455/should-i-interleave-sin-and-cosine-in-sinusoidal-positional-encoding    提交人    /u/CompSciAI   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g876j8/why_do_ddpms_implement_a_different_sinusoidal/</guid>
      <pubDate>Sun, 20 Oct 2024 19:43:10 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 OpenCV 或计算机视觉来执行哪些过程来增强捕获的手写笔记并使其更清晰？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g82gyh/what_process_can_i_do_using_opencv_or_computer/</link>
      <description><![CDATA[      像这样。 使背景更白并增加笔迹的厚度或对比度的东西......    提交人    /u/AppropriateWork4011   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g82gyh/what_process_can_i_do_using_opencv_or_computer/</guid>
      <pubDate>Sun, 20 Oct 2024 16:21:03 GMT</pubDate>
    </item>
    <item>
      <title>ML初学者</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g80riz/ml_beginner/</link>
      <description><![CDATA[大家好，ml 社区，我是 ml 和 dl 之旅的新手，我属于 IIT，因此我的数学很好，但是自从我开始 ml 以来，我感到非常失望和孤独，我正在取得非常小的进步，我觉得想放弃它，但是当我看到编码时，它似乎也很难。我缺乏什么，或者这种怀旧的感觉在开始时很常见。 请帮帮我.. 对我来说意义重大     提交人    /u/Longjumping-Cheek101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g80riz/ml_beginner/</guid>
      <pubDate>Sun, 20 Oct 2024 15:05:31 GMT</pubDate>
    </item>
    <item>
      <title>我的 Loss 和 F1 怎么会相关呢？不是反相关的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1g7v9sh/how_can_my_loss_and_f1_be_correlated_not/</link>
      <description><![CDATA[      https://preview.redd.it/1yd04eepvvvd1.png?width=1034&amp;format=png&amp;auto=webp&amp;s=cbd95cbec821e7a7168c198307928fee6eb4f54d 上图是我关于学习率调整的数据，你可以看到，虽然 f1 的差异很小，但是val loss 很大，但是最好的 f1 是 1e-5，但 val loss 最差；而 1e-6 的 f1 最差，但 val loss 最好。在我的另一个数据上可以看到类似的模式，使用 RoBERTa 代替 XLNet。 https://preview.redd.it/zo4vxhhyvvvd1.png?width=1040&amp;format=png&amp;auto=webp&amp;s=c631bf51c4ca2e5602440a9a997bb13c2e239f7e 为了便于理解，这里使用的损失函数是交叉熵，经过 10 次训练，并使用 AdamW 优化器。如果这很重要的话，这是一个具有多类数据而不是多标签的情绪分类任务（我从 GoEmotions 中删除了多标签行，因此数据非常不平衡）。 由于整个过程是我的超参数调整的一部分，我不知道应该使用哪个学习率，应该关注损失还是 f1？ 我的代码中可能存在一些问题导致此问题，或者可能只是方法错误，我对机器学习还很陌生，所以这可能只是我的错误。    提交人    /u/BlehBlah_   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1g7v9sh/how_can_my_loss_and_f1_be_correlated_not/</guid>
      <pubDate>Sun, 20 Oct 2024 09:57:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>