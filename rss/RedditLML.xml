<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 20 Feb 2024 15:12:34 GMT</lastBuildDate>
    <item>
      <title>GPU 与 TPU：哪一个更好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avj5ed/gpu_vs_tpu_which_one_is_better/</link>
      <description><![CDATA[您好，我想了解哪种选项更适合部署相同的 LLM（可能是 LLAMA 或其他）。 &lt; p&gt;此比较涉及将其部署在 AWS、Google Cloud 和本地设置（Mac 或 NVidia RTX 4090）上。 需要考虑的因素包括：  LLM 模型之间的互操作性 效率 成本 其他  你能帮我吗？谢谢！   由   提交 /u/Which_Pin_6386   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avj5ed/gpu_vs_tpu_which_one_is_better/</guid>
      <pubDate>Tue, 20 Feb 2024 14:38:13 GMT</pubDate>
    </item>
    <item>
      <title>如何创建具有可扩展输入参数或 n 输入参数的神经网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avi90v/how_to_create_a_neural_network_with_a_scalable/</link>
      <description><![CDATA[所以我正在创建一个图像识别软件来识别交通灯、汽车、人、桥梁等。假设我不知道图像分辨率如何创建可扩展的输入参数？我的一种方法是将输入参数设置得非常大，如果给定图像的分辨率小于设置的输入数，我可以编码它的其余输入不会被触发，但这会弄乱重量，有偏差和神经元在训练和使用它时。另一个想法是将图像缩放到输入值，但这会非常糟糕，因为缩放图像意味着丢失数据和我不想要的东西？还有其他建议吗？   由   提交 /u/GateCodeMark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avi90v/how_to_create_a_neural_network_with_a_scalable/</guid>
      <pubDate>Tue, 20 Feb 2024 13:57:52 GMT</pubDate>
    </item>
    <item>
      <title>机器学习简介，FINALE（L16，流形学习）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avhpw8/introduction_to_machine_learning_finale_l16/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avhpw8/introduction_to_machine_learning_finale_l16/</guid>
      <pubDate>Tue, 20 Feb 2024 13:32:21 GMT</pubDate>
    </item>
    <item>
      <title>关于ccix协议的问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avhlfw/question_regarding_the_ccix_protocol/</link>
      <description><![CDATA[因此，根据我的理解，ccix 是一个缓存共享协议，与 nvidias NvLINK 非常相似，但与 nvlink 不同的是，该协议似乎完全适用于整个单元。 ccix 有很多合作伙伴，但这里要补充的另一件有趣的事情是，如果您的 CPU 上有 igpu，它基本上也会利用您的 igpu。 Ccix 与包括 AMD 在内的很多人合作，并且是在 PCIE 协议的基础上构建的，在某种意义上是第 2 层。所以我的问题是，英特尔 GPU 对于 ML 变得更加可行（特别是配备 32GB vram 和 256 总线的高端 Battleimage），那么多卡在消费者层面上不是更可行吗？ &lt; !-- SC_ON --&gt;  由   提交/u/metaldad2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avhlfw/question_regarding_the_ccix_protocol/</guid>
      <pubDate>Tue, 20 Feb 2024 13:26:26 GMT</pubDate>
    </item>
    <item>
      <title>空用笔和纸简单说明</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avflle/sora_explained_simply_with_pen_and_paper/</link>
      <description><![CDATA[   /u/techie_ray  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avflle/sora_explained_simply_with_pen_and_paper/</guid>
      <pubDate>Tue, 20 Feb 2024 11:36:41 GMT</pubDate>
    </item>
    <item>
      <title>矢量数据库和相似性搜索解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avfk5u/vector_databases_similarity_search_explained/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交 /u/True_Hedgehog6990   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avfk5u/vector_databases_similarity_search_explained/</guid>
      <pubDate>Tue, 20 Feb 2024 11:34:20 GMT</pubDate>
    </item>
    <item>
      <title>使用带有 kmeans 的句子嵌入模型逐渐增加 CPU 负载</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avcidb/gradually_increasing_cpu_load_on_using_sentence/</link>
      <description><![CDATA[我有一个基于 ML 的生产应用程序，使用 Flask，使用 Gunicorn Workers 部署在 GCP 服务器上。在每个传入请求中，都会收到一个文本句子。 它使用句子转换器（All-MiniLM-L6-v2 模型），该模型会全局加载一次，以创建嵌入传入文本，然后使用预先训练的 kmeans（也全局加载）来预测/将其映射到意图集群。基本上，目标是找到句子的意图。 我有足够的资源，请求的数量也恒定，文本也相似，但每天CPU负载都在逐渐增加。第一天的平均响应时间约为 200 毫秒，10 天后现在为 400 毫秒。 我尝试在代码本身中使用“del”命令删除嵌入变量，同时还强制 python 垃圾收集器在主进程执行完成后执行的线程中使用“gc.collect()”，但问题仍然出现。 我注意到的一件事是，如果我不使用 del 和 gc。收集（）后，RAM开始逐渐下降。对于这两种情况，RAM 是恒定的，但现在 CPU 使用率每天都在逐渐增加，因此负载和响应时间也随之增加。 我花了数周的时间在这个问题上尝试调试它，但没有找到解决方案，如有任何帮助，我们将不胜感激。   由   提交/u/Devinco001  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avcidb/gradually_increasing_cpu_load_on_using_sentence/</guid>
      <pubDate>Tue, 20 Feb 2024 08:09:54 GMT</pubDate>
    </item>
    <item>
      <title>在事先不知道 K 数的情况下对文本进行聚类的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avccwk/what_are_the_best_ways_to_do_clustering_on_text/</link>
      <description><![CDATA[我正在尝试对已转换为嵌入并存储在松果中的笔记进行分类。我想将笔记分类为簇，但没有事先明确设置簇数或 K。 据我所知，有 Kmeans 与肘部方法或使用另一种聚类方法，如 HDBSCAN . 我用 sillhoutte 尝试过肘法，但结果很差。 你们都知道有什么方法可以自动选择 K 吗？或者不选择 K 的情况下进行聚类的不同方法？   由   提交/u/oozak9  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avccwk/what_are_the_best_ways_to_do_clustering_on_text/</guid>
      <pubDate>Tue, 20 Feb 2024 08:00:03 GMT</pubDate>
    </item>
    <item>
      <title>帮助解决有关扩散模型中的后向过程的这些问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avc5ty/help_with_these_questions_about_backward_process/</link>
      <description><![CDATA[      首先，我认为我已经理解了方程后向过程，以 x_t 为条件 x_{t-1}： ​ https://preview.redd.it/sljzh0a8xkjc1.png?width=1407&amp;format=png&amp;auto=webp&amp;s=b9235fa993e9 a246de6637d567955746ebacbcd3&lt; /a&gt; 其中 mu 是均值和 sigma de 协方差。有了这些信息，马尔可夫链上一步的数据就可以用以下等式定义： ​ https://preview.redd.it/r3s6ssaoxkjc1.png?width=1470&amp;format=png&amp;auto=网页p&amp; ;s=8281d07a8c8a06e81d5b73e262b0b27397f8f0bc 但是，几天前我在做个人项目时，我注意到 diffusers 库，这是我没想到的。它位于step函数的这些行中。  看一下原始文章（改进的去噪扩散实用性模型（Nichol, A. &amp; Dhariwal, P） .))我在第2.1节中发现了一些我无法理解的事情： ​ https://preview.redd.it/k06ftef2zkjc1.png?width=1691&amp;format=png&amp;auto=webp&amp;放大器;s=f854477328aa88ab588c4c157881bafcca8e1b02 我知道这是在原始去噪中的方程6和7中提出的扩散概率模型（Jonathan, H.、Jain, A. 和 Abbeel, P.）文章。但我完全没有抓住要点；对我来说理解这意味着什么是相当复杂的。 ​ https://preview.redd.it/j9jp0xqqsljc1.png?width=1896&amp;format=png&amp;auto=webp&amp;s=03df39f98e44d 93726afd9bca3430b04171d9aa2&lt; /p&gt; 公式 10 和公式 11 中定义的 beta 和 mu 的新定义是什么？为什么方程 12 重新定义 p(x_{t-1}|x_t) 逆过程的定义，其中 q 后验以 x_t 和 x_0 为条件？这种不同的方法有哪些优点？   由   提交 /u/SrPinko   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avc5ty/help_with_these_questions_about_backward_process/</guid>
      <pubDate>Tue, 20 Feb 2024 07:46:31 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的算法和深度学习算法有什么不同吗？如果有的话有什么区别</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avbkib/are_neural_networks_algorithm_different_than_deep/</link>
      <description><![CDATA[神经网络使用权重、偏置和反向传播（梯度下降）来训练和处理数据，深度学习也使用这种类似的系统吗？要添加其他算法吗？   由   提交 /u/GateCodeMark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avbkib/are_neural_networks_algorithm_different_than_deep/</guid>
      <pubDate>Tue, 20 Feb 2024 07:09:13 GMT</pubDate>
    </item>
    <item>
      <title>我在哪里可以找到它们？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avbhly/where_can_i_find_them/</link>
      <description><![CDATA[大家好，有没有一个代理可以自动化我的工作申请流程，例如填写所有表格并单击“否”，您是联邦雇员吗？    由   提交 /u/Unlikely-Ad3950    reddit.com/r/learnmachinelearning/comments/1avbhly/where_can_i_find_them/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avbhly/where_can_i_find_them/</guid>
      <pubDate>Tue, 20 Feb 2024 07:03:58 GMT</pubDate>
    </item>
    <item>
      <title>这是二元分类还是完全是别的什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avbf25/is_this_binary_classification_or_something_else/</link>
      <description><![CDATA[我的任务是解决这个问题 - 有 2 条由 2d 组点形成的同心正弦曲线（不等幅）。 “将每个映射到 1d，使得较大的曲线以 +1 为中心，较小的曲线以 -1 为中心”。 如果我正确地解释了这一点，这是否意味着该模型将预测是否有新的输入点属于+1或-1（即，如果它是较大曲线或较小曲线的一部分）？那么这本质上是二元分类吗？ 我在解释这个问题时遇到了困难 - 抱歉，如果这非常微不足道，我还是个新人。 TIA    由   提交/u/MyMindisUptoNoGood  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avbf25/is_this_binary_classification_or_something_else/</guid>
      <pubDate>Tue, 20 Feb 2024 06:59:51 GMT</pubDate>
    </item>
    <item>
      <title>最佳深伪机器人</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avbapy/best_deepfake_bot/</link>
      <description><![CDATA[https:// www.deepfakeaibot.com/bot/t/dfm/?start=6353841066 仅适用于电报    ;由   提交 /u/StrangerSpare3770   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avbapy/best_deepfake_bot/</guid>
      <pubDate>Tue, 20 Feb 2024 06:51:56 GMT</pubDate>
    </item>
    <item>
      <title>作业帮助：基本 ML 任务</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1avanqi/homework_help_basic_ml_task/</link>
      <description><![CDATA[大家好，我有一份关于使用模型进行图像处理的报告，其中的任务是比较 8 个预训练模型的性能，其中 2 个模型我的模型和使用 Scikit Image 的基线模型。我需要帮助来解释结果，因为我的主管拒绝与我会面并讨论我实习的最终结果。我有很多足够简单的精确召回曲线。我将撰写报告的大部分内容，只需要您的专业知识即可从图表中得出结论。我的报告截止日期是2月28日，我终于可以从硕士毕业了。任何帮助表示赞赏！    由   提交 /u/swallalalala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1avanqi/homework_help_basic_ml_task/</guid>
      <pubDate>Tue, 20 Feb 2024 06:13:24 GMT</pubDate>
    </item>
    <item>
      <title>我想要 ML 项目的想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1av60zm/i_want_ml_projects_ideas/</link>
      <description><![CDATA[我想要它，这样我就可以训练自己，这样我就可以把它放在我的简历中。我想要一些新的、有创意的东西   由   提交 /u/Budget-Tap-4473   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1av60zm/i_want_ml_projects_ideas/</guid>
      <pubDate>Tue, 20 Feb 2024 02:12:20 GMT</pubDate>
    </item>
    </channel>
</rss>