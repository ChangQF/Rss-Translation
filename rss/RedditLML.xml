<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 19 Jan 2024 03:15:55 GMT</lastBuildDate>
    <item>
      <title>为她 - 自然未成年人</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a6jud/for_her_natural_minor/</link>
      <description><![CDATA[       由   提交 /u/Zealousideal-Ad-1095   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a6jud/for_her_natural_minor/</guid>
      <pubDate>Fri, 19 Jan 2024 01:11:08 GMT</pubDate>
    </item>
    <item>
      <title>使用任何 Torchvision 预训练模型作为 PyTorch Faster RCNN 的骨干</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a5uv8/using_any_torchvision_pretrained_model_as/</link>
      <description><![CDATA[      使用任何 Torchvision 预训练模型作为 PyTorch Faster RCNN 的骨干 https://debuggercafe.com/ using-any-torchvision-pretrained-model-as-backbone-for-pytorch-faster-rcnn/ ​ https://preview.redd.it/gwswitfyladc1.png?width=1000&amp;format= png&amp;auto=webp&amp;s=19406c9f83e032c2b76dfff38a4add8241f9d147   由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/19a5uv8/using_any_torchvision_pretrained_model_as/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a5uv8/using_any_torchvision_pretrained_model_as/</guid>
      <pubDate>Fri, 19 Jan 2024 00:38:35 GMT</pubDate>
    </item>
    <item>
      <title>Udemy 初学者、高级的最佳机器学习课程 -</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a5r2v/best_machine_learning_courses_on_udemy_beginners/</link>
      <description><![CDATA[    /u/Sreeravan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a5r2v/best_machine_learning_courses_on_udemy_beginners/</guid>
      <pubDate>Fri, 19 Jan 2024 00:33:36 GMT</pubDate>
    </item>
    <item>
      <title>美国 MLOps 职业生涯</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a5joz/career_in_mlops_in_the_us/</link>
      <description><![CDATA[我来自孟加拉国，在一家美国跨国公司担任 2 级机器学习工程师，该公司在超过 13 个国家/地区设有分支机构。我完成了机械工程学士学位，在一家财富 500 强公司的无关职位工作了 1.5 年之后，我转向了机器学习。在我目前的表格业务数据工作中，我主要从事传统的机器学习工作，但最近我更多地参与了 MLOps 方面的开发模型的部署，因为我们这里没有单独的 MLOps 工程师。主要使用 Github CI/CD、Argo 工作流程等。 我在之前的工作和研究小组中确实有计算机视觉、NLP 和语音转文本方面的经验，但目前还没有任何经验重要出版物（在 arxiv 上有一篇论文被 5 次引用哈哈）。但由于我在目前的工作中从事表格数据的传统机器学习工作已经有 1.5 年了，所以接触深度学习的时间不长，几乎忘记了很多东西。 我的计划是离开到美国定居并在未来瞄准大型科技公司。由于我已经有一段时间没有接触 SOTA 深度学习的东西了，我觉得 MLOps 对我来说非常适合，因为无论使用什么 ML/DL 算法，这都有点通用化。&lt; /p&gt; 所以，首先，我想获得硕士学位，以便通过学生签证进入美国（我根本没有时间和精力去攻读博士学位，因为我已经 28 岁以上了）而且我不想长期做一个失业的学生）。我需要建议，根据我的经验，我应该攻读什么样的硕士学位？另外，请建议特定大学的任何适合我的目标和经验的相关课程（最好是资助课程，因为我没有很多储蓄 ATM） （对我来说最好的事情是获得一个直接在美国工作并持有工作许可证，但从孟加拉国，这更具挑战性，所以我选择了大师赛）   由   提交 /u/TheAIBeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a5joz/career_in_mlops_in_the_us/</guid>
      <pubDate>Fri, 19 Jan 2024 00:24:14 GMT</pubDate>
    </item>
    <item>
      <title>“线性代数做得好”应该是第二门课程的内容——第一门课程是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a1kos/linear_algebra_done_right_is_supposed_to_be_for_a/</link>
      <description><![CDATA[标题。我对微积分、向量微积分和常微分方程有非常深入的了解，并对偏微分方程有大致的了解。我在线性代数方面做过一些工作，但从来没有上过课程或进行过广泛的个人研究。 .net/ 这表示本书是线性代数的第二门课程。我应该学习什么书作为入门？我正在努力为这学期的大学学习快速准备一本书/课程。 ​   由   提交 /u/dittospin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a1kos/linear_algebra_done_right_is_supposed_to_be_for_a/</guid>
      <pubDate>Thu, 18 Jan 2024 21:35:25 GMT</pubDate>
    </item>
    <item>
      <title>不要在 Ai Core 上浪费钱</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a1g4m/dont_waste_money_on_ai_core/</link>
      <description><![CDATA[这是一个骗局 13,000英镑的视频和孩子们的教学。如果他们经验丰富，我不会介意，他们不是我一生中最大的金钱浪费   由   提交 /u/Background_Perfect   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a1g4m/dont_waste_money_on_ai_core/</guid>
      <pubDate>Thu, 18 Jan 2024 21:30:10 GMT</pubDate>
    </item>
    <item>
      <title>为您的模型训练客户数据的合法性？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/19a12bw/legality_of_training_client_data_for_your_model/</link>
      <description><![CDATA[您好， 在工作中，我被要求根据客户数据微调模型。这是一个相当简单的带有 BERT 模型的情感分析器，我要做的就是客户每天提交的关于他们工作整体经验的培训笔记。本质上，它将根据一个客户的数据进行微调，然后我们将针对每个客户的数据使用该模型（假设所有客户都会提供类似的响应）。我问我的老板我们是否需要征求客户的许可来根据他们的数据微调模型，她说我们不需要，因为在我们的合同中我们可以用他们的数据做我们想做的事情。然而，这是很多年前写的，我觉得人工智能有点具有合法性和权限的全新世界。我是否想得太多了，还是这肯定需要进一步追求？只是不想根据他们的数据微调模型，并且由于没有获得许可而遇到了一些法律问题。   由   提交 /u/DontKnowAGoodNames   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/19a12bw/legality_of_training_client_data_for_your_model/</guid>
      <pubDate>Thu, 18 Jan 2024 21:14:45 GMT</pubDate>
    </item>
    <item>
      <title>学习 CNN 和 CV 哪个系列讲座比较好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199zosk/which_lectures_series_is_better_for_learning_cnn/</link>
      <description><![CDATA[有斯坦福的cs231n (2017) 和密歇根大学的讲座 (2020)。两门课程看起来很相似，而且他们的教练也是同一个人。您知道哪一个更好吗？   由   提交 /u/Trevorego   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199zosk/which_lectures_series_is_better_for_learning_cnn/</guid>
      <pubDate>Thu, 18 Jan 2024 20:19:26 GMT</pubDate>
    </item>
    <item>
      <title>关于调试机器学习项目的系统方法的博客</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199xw40/blog_on_systematic_approach_to_debugging_machine/</link>
      <description><![CDATA[嗨， 我写了一篇关于调试 ML 项目的系统方法的文章。请让我知道你的想法。任何需要改进的东西或更多的调试技巧都非常感谢。 &quot;&gt;https://medium.com/@gitlostmurali/debugging-your-machine-learning-project-8d1897676050?sk=5d30bfe483b97eb0dc4275565234ccad  &amp;# 32；由   提交/u/Outlandish_MurMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199xw40/blog_on_systematic_approach_to_debugging_machine/</guid>
      <pubDate>Thu, 18 Jan 2024 19:05:46 GMT</pubDate>
    </item>
    <item>
      <title>根据搜索的关键词，搜索不同版本技术文档的特定部分的摘要</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199xeqh/searching_for_summary_of_specific_part_of/</link>
      <description><![CDATA[您好， 我正在查找有关某个字段的信息。我有几个不同软件的技术文档，存在多个版本，具体取决于文档随时间的演变。  我们的想法是，根据指定的关键字/文本，我们可以从与正确软件相对应的文档中提取与所引用的关键字/文本相对应的部分的摘要。 输出将是一个摘要，其中考虑了不同版本文档中相应部分的演变。  示例：如果用户在 V1 文档中搜索“软件 X 的错误”，则说明存在错误 22 和错误 24。在 V2 上解释了错误 22 已得到纠正。 然后输出解释了错误 22 已得到纠正，但 X 软件的错误 24 没有得到纠正。 关于出版物、模型预制的任何想法是否受过培训，我可以参考吗？ 谢谢。   由   提交 /u/Thamelia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199xeqh/searching_for_summary_of_specific_part_of/</guid>
      <pubDate>Thu, 18 Jan 2024 18:46:24 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 多头注意力实现</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199vyfe/transformer_multihead_attention_implementation/</link>
      <description><![CDATA[我一直在关注带注释的 Transformer&lt; /a&gt; 实现变压器架构。在多头注意力类的forward()方法中，Query、Key &amp;值与相应的投影矩阵相乘； W_q、W_k、W_v。   query, key, value = [ lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for lin, x in zip (self.linears, (query, key, value)) ]  这里，lin(x) 被重塑为 (nbatches, -1 , self.h, self.d_k) 和维度 1 &amp; 2 正在被转置，这使得维度 (nbatches, self.h, -1, self.d_k)。  我无法理解为什么他们不直接这样做lin(x).view(nbatches, self.h, -1, self.d_k) ?   由   提交 /u/Melodic_Stomach_2704   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199vyfe/transformer_multihead_attention_implementation/</guid>
      <pubDate>Thu, 18 Jan 2024 17:46:55 GMT</pubDate>
    </item>
    <item>
      <title>对于数学家来说最好的机器学习资源是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199tvz7/whats_the_best_machine_learning_resource_for_a/</link>
      <description><![CDATA[（抱歉，我知道我连续发帖两次。不过我有两个问题！） 嗨！具体来说，我有数学背景，了解统计学，并在行业中构建机器学习模型、梯度增强决策树。 但那是几年前的事了，这个领域发展很快，我感觉很好落后，所以我想从头开始来弥补我的差距。 ​ 什么是好的机器学习资源，可以通过理论教授现代技术已经可以做数学的人吗？  提前致谢！   由   提交/u/mcarlin2  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199tvz7/whats_the_best_machine_learning_resource_for_a/</guid>
      <pubDate>Thu, 18 Jan 2024 16:21:05 GMT</pubDate>
    </item>
    <item>
      <title>项目：使用 RAG 和 VectorDB 对任何 PDF 文档进行质量检查</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199rq4b/project_qa_on_any_pdf_document_using_rag_and/</link>
      <description><![CDATA[      智能 PDF 阅读器是一个综合项目，利用检索增强的功能基于 Langchain 的大型语言模型 (LLM) 的生成 (RAG) 模型。此外，它还利用 Pinecone 矢量数据库来有效地存储和检索与 PDF 文档相关的矢量。这种方法可以从 PDF 文件中提取基本信息，而无需在问答数据集上训练模型。 查找 GitHub 存储库：此处   由   提交/u/Amazing_Life_221   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199rq4b/project_qa_on_any_pdf_document_using_rag_and/</guid>
      <pubDate>Thu, 18 Jan 2024 14:44:44 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模块化模型（nn.ModuleList）始终比直接实现差</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199nppz/pytorch_modular_model_consistently_nnmodulelist/</link>
      <description><![CDATA[大家好，我的第一篇文章，因为我不知道还能去哪里。我正在写我的论文，我正在尝试创建 nn.Module 类，该类将结构作为输入，并使用相应的层数、输入/输出大小等实例化模型。此类使用 nn.ModuleList() 。我们将此模型称为 A。 我将模型 A 与另一个模型（例如模型 B）进行了比较，后者执行完全相同的操作，但不使用 nn.ModuleList，并且使用标准中的确切参数进行定义方式（例如 class NN(nn.Module):...）就像标准 pytorch 教程中一样。  问题是两个模型都应该做同样的事情，但模型 B 在相同的数据上比模型 A 获得了更好的准确性。 我不确定这是否会发生，也许我在代码中做错了什么，但我的主要问题是：额外的结构是否可能会扰乱 autograd 图，使其变慢，甚至无法像模型 B 那样学习？ 我可以附加如果人们有兴趣，请查看代码。 模型 A structural = {&#39;f&#39;: [[0,100]], &#39;s&#39;: [100, 101]} ConvLayers(nn.Module) 类：  def __init__(self, in_d, kernel_volving, kernel_pool, convolution_stride, pool_stride, hide_channels = [4,4] ): super().__init__() dim = [1] + hide_channels self.conv_layers = nn.ModuleList([nn.Conv1d(dim[i-1], dim[i], = kernel_volving, stride = volving_stride) for i in range(1, len(dim))]) self.pool = nn.MaxPool1d(kernel_pool, pool_stride).to(device) defcalculate_output_length(length_in, kernel_size, stride=1, padding=0, dilation=1): return (length_in + 2 * 填充 - 膨胀 * (kernel_size - 1) - 1) // 步幅 + 1 L_in = in_d for _ in range(1, len(dim)): L_out = 计算输出长度(L_in, kernel_volve, volution_stride) L_out = calculate_output_length(L_out, kernel_pool, pool_stride) L_in = L_out self.out_d = L_in *hidden_​​channels[-1] defforward(self, t): for i in range(len(self.conv_layers)): t = self.pool(F .relu(self.conv_layers[i](t))) return t  类 CNN(nn.Module): def __init__(self,结构体，kernel_volve = 8，kernel_pool = 4，volve_stride = 1，pool_stride = 2，conv_hidden_​​channels = [4,4]，fc_hidden = [24, 24]，device = None）：super().__init__() self.struct =结构体 self.f_in_d = [f[1] - f[0] for f in 结构体[&#39;f&#39;]] self.s_in_d = 结构体[&#39;s&#39;][1] - 结构体[&#39;s&#39;][0] self. device = device self.conv_layers = nn.ModuleList([ConvLayers(in_d, conv_hidden_​​channels, kernel_convolution, kernel_pool, volv_stride, pool_stride) for in_d in self.f_in_d]).to(device) self.out_d_values = [layer.out_d for layer in self.conv_layers] fc_in_d = sum(self.out_d_values) + self.scalar_in_d self.fc_layers = FeedForward(fc_in_d, fc_hidden, dropout = dropout, model_version = “simple”).to(device) defforward(self, x): f_i = [x[:, f[0] : f[1]].unsqueeze(1).to(self.device) for f in self.struct[&#39;f&#39;]] s_i = x[:, self.struct [&#39;s&#39;][0] : self.struct[&#39;s&#39;][1]].reshape(-1, self.scalar_in_d).to(self.device) 结果 = [] 层，input_data in zip(self .conv_layers, f_i): 输出 = 层(input_data) result.append(输出) conv_output = torch.hstack([torch.flatten(torch.hstack(result), 1), s_i]) return(self.fc_layers(conv_output) )  模型 B CNN 类(nn.Module): def __init__(self ，设备）： super().__init__() self.device = 设备 self.conv1 = nn.Conv1d(in_channels = 1, out_channels = 4, kernel_size = 8, stride = 1).to(device) self.pool = nn .MaxPool1d(kernel_size = 4, stride = 2).to(设备) self.conv2 = nn.Conv1d(in_channels = 4, out_channels = 4, kernel_size = 8).to(设备) self.fc1 = nn.Linear(73 , 24).to(设备) self.fc2 = nn.Linear(24, 24).to(设备) self.fc3 = nn.Linear(24, 1).to(设备) defforward(self, x): f, s = x[:,:100].unsqueeze(1).to(self.device), x[:,100].unsqueeze(1).to(self.device) 卷积 = self.pool(F. relu(self.conv2(self.pool(F.relu(self.conv1(func)))))) full = torch.hstack([torch.flatten(卷积, 1), scal]) # 展平除批量之外的所有维度返回 self.fc3(F.relu(self.fc2(F.relu(self.fc1(full)))))     ;由   提交 /u/Altruistic_Desk1464   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199nppz/pytorch_modular_model_consistently_nnmodulelist/</guid>
      <pubDate>Thu, 18 Jan 2024 11:07:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型突然变得非常好？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/199iw44/why_is_my_model_suddenly_extremely_good/</link>
      <description><![CDATA[二元分类数据集。 随机森林 ~ 60% 准确度 神经网络 ~ 62% 准确度 随机森林输出用作神经网络中的新功能 ~ 92% 准确度。 我在某个地方犯了错误吗？这还可能吗？合奏可以这样执行吗？ 编辑 ::: 抱歉，这称为堆叠而不是合奏。我使用了错误的术语。 更新 ::: 我正在重新进行分析，并密切关注是否有任何数据泄漏，因为我不认为我的模型应该显着改进这一点。稍后将更新详细信息和调查结果。谢谢大家的意见。    由   提交/u/lambo_engine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/199iw44/why_is_my_model_suddenly_extremely_good/</guid>
      <pubDate>Thu, 18 Jan 2024 05:44:13 GMT</pubDate>
    </item>
    </channel>
</rss>