<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Sun, 31 Dec 2023 09:12:20 GMT</lastBuildDate>
    <item>
      <title>愿新年的黎明带来创新、发现和无限可能的挂毯！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18v3vcy/may_the_dawn_of_the_new_year_bring_forth_a/</link>
      <description><![CDATA[这一年充满了技术奇迹、突破性进步，以及共同迈向未来的旅程，激发奇迹并激励我们所有人。明日世界的探索者们，新年快乐！   由   提交 /u/Sttuardbe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18v3vcy/may_the_dawn_of_the_new_year_bring_forth_a/</guid>
      <pubDate>Sun, 31 Dec 2023 09:04:40 GMT</pubDate>
    </item>
    <item>
      <title>[问] MXNet 替代方案</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18v3og7/q_mxnet_alternatives/</link>
      <description><![CDATA[我两年前使用过 MXNet ...现在，我注意到 MXNet 已被弃用（不幸的是）。如今有哪些替代方案 - 张量流、pytorch ...？当我两年前尝试 Tensorflow 2 时，它令人失望（不稳定、缓慢......）...   由   提交 /u/og__x   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18v3og7/q_mxnet_alternatives/</guid>
      <pubDate>Sun, 31 Dec 2023 08:51:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于强化学习已经做了很多很多的工作。然而，影响小于预期——例如与自我监督学习相比。看来Lecun的预测是正确的。你认为 RL 正在消亡还是会变得强大并产生 AGI？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18v2rgf/d_there_has_been_lots_and_lots_of_work_on/</link>
      <description><![CDATA[ 由   提交/u/Ok_Can2425   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18v2rgf/d_there_has_been_lots_and_lots_of_work_on/</guid>
      <pubDate>Sun, 31 Dec 2023 07:50:09 GMT</pubDate>
    </item>
    <item>
      <title>从数学角度探讨机器学习的论文主题思想</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uyr0v/essay_topic_ideas_about_machine_learning_from_a/</link>
      <description><![CDATA[ 由   提交/u/zen_bud  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uyr0v/essay_topic_ideas_about_machine_learning_from_a/</guid>
      <pubDate>Sun, 31 Dec 2023 03:59:16 GMT</pubDate>
    </item>
    <item>
      <title>开始时需要帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uxs49/help_needed_in_starting_off/</link>
      <description><![CDATA[我是一名学生，我对网络安全和机器学习感兴趣。我想在这些领域努力。我想进入研究领域，我想在这两个领域建立一些扎实的项目。目前我只是通过 youtube、博客和其他东西来学习它们。 我想得到一些关于这方面的建议以及我现在应该关注什么。 我想学尽可能多的东西可能，但我被困在我应该开始的地方。 （英语不是我的母语，对语法感到抱歉）  &amp;# 32；由   提交/u/meme_hunter2612   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uxs49/help_needed_in_starting_off/</guid>
      <pubDate>Sun, 31 Dec 2023 03:08:58 GMT</pubDate>
    </item>
    <item>
      <title>Python 中从头开始的反向传播</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ux6yw/backpropagation_from_scratch_in_python/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ux6yw/backpropagation_from_scratch_in_python/</guid>
      <pubDate>Sun, 31 Dec 2023 02:39:57 GMT</pubDate>
    </item>
    <item>
      <title>如何提高小型复杂数据的模型性能？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uvs6b/how_to_improve_model_performance_for_small_and/</link>
      <description><![CDATA[我有一个小数据集（30-40 行），它是一个多变量和多目标回归问题。数据有 10-15 个特征和 5 个输出，我想准确地预测它们。然而，我当前的模型（神经网络）给出的 R2 分数非常低，有时甚至是负数。我尝试过不同的模型（线性、树等）和预处理技术（缩放、特征选择等），但似乎都效果不佳。 有哪些建议可以改进我的模型如此小而复杂的数据集的模型性能如何？是否有任何特定的算法、超参数或数据增强方法可以提供帮助？我很感激任何建议或资源。谢谢。   由   提交 /u/Double_Ticket935   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uvs6b/how_to_improve_model_performance_for_small_and/</guid>
      <pubDate>Sun, 31 Dec 2023 01:31:16 GMT</pubDate>
    </item>
    <item>
      <title>作为非数据科学家，评估我在数据集中查找“最重要”列的方法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ut66f/as_a_nondatascientist_assess_my_approach_for/</link>
      <description><![CDATA[我正在为英雄联盟视频游戏构建一款产品，它将为玩家提供 3-6 个不同的游戏关注点，这将增加他们获胜的机会。 就我的技术背景而言，我以为我想成为一名数据科学家，但后来转向了数据工程，所以我对机器学习概念有非常基本的掌握。这就是为什么我希望你们所有非常聪明的人就我如何计算这些“重要”的问题提供意见。列。 我知道可解释性的世界仍然不确定，但这是我的方法：  我得到了单个玩家的比赛数据集，其中每个玩家行表示比赛结束时该球员的统计数据。删除其中包含任何 NULL 的列后，大约有 100 列（例如击杀、助攻、造成的伤害等）。  有一个二进制 WIN 列，显示玩家是否赢得了比赛。这是我们最感兴趣的专栏  我在此数据上训练一个简单的基于树的模型，并获得“特征重要性”列表使用 sklearn 的 permutation_importance() 函数。  出于某种原因（也许有人可以解释），有大量列在计算后返回零特征重要性。  这是我的做法不同：我使用相同的数据集重新训练模型，但没有在最后一次“运行”时返回 0 重要性的列 我基本上重复此过程，直到特征重要性列表不再出现为止。 t 包含零。  最终结果是通常还剩下 3-20 列（取决于型号）。  我取了前 N 列（还没有尚未决定）列和“给予”让用户在下一场游戏中重点关注  理论上，如果“功能重要性”确实名副其实，结局模型应该只有“最重要”的内容。试图取得胜利时的列。 我尝试过使用 SHAP/LIME，但它们比使用直接特征重要性更复杂。 就像我提到的，我不这样做接受过机器学习或统计学方面的经典培训，所以所有这些都是我曾经尝试自学的东西。我很感激任何关于这种方法是否有意义/有效的有用建议。 最大的问题是：这种方法是否存在任何问题，以及生成的列集是否确实是“最重要的？” ;   由   提交 /u/NFeruch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ut66f/as_a_nondatascientist_assess_my_approach_for/</guid>
      <pubDate>Sat, 30 Dec 2023 23:33:27 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解死亡神经元并解释激活函数的作用？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18us1sn/help_understanding_dead_neurons_and_interpreting/</link>
      <description><![CDATA[激活函数对我来说一直感觉有点模糊。我最初理解它只是因为应用连续的线性变换可以表示为单个线性变换，因此我们引入非线性以便让网络有更多的自由度。然而，当我研究死亡神经元的想法时，似乎有一些不太数学的解释来解释为什么我们需要这样做。 除了纯粹的数学作用之外，这样说是否正确？ ，激活函数赋予模型使特定神经元处理特定类型数据的能力？例如，当数据位于 tanh 的尾部或 ReLU 的负数部分时，它会将梯度归零，并使特定神经元无法从此类数据中学习。因此，我将非线性解释为赋予网络将某些类型的数据划分为特定神经元的能力是否正确？   由   提交/u/Opening-Education-88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18us1sn/help_understanding_dead_neurons_and_interpreting/</guid>
      <pubDate>Sat, 30 Dec 2023 22:45:04 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下 Conv 在 Mamba 中做什么吗？我认为它是重复出现的，但这是否意味着它需要在推理时间内访问整个输入序列？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uque7/can_someone_explain_what_that_conv_is_doing_in/</link>
      <description><![CDATA[   /u/hazard02  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uque7/can_someone_explain_what_that_conv_is_doing_in/</guid>
      <pubDate>Sat, 30 Dec 2023 21:54:05 GMT</pubDate>
    </item>
    <item>
      <title>拓扑数据分析，第 2 部分，持久同调</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18umm15/topological_data_analysis_part_2_persistent/</link>
      <description><![CDATA[   /u/fbeilstein  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18umm15/topological_data_analysis_part_2_persistent/</guid>
      <pubDate>Sat, 30 Dec 2023 18:50:33 GMT</pubDate>
    </item>
    <item>
      <title>我在玩《超级马里奥兄弟世界 1-1》时，在 matplotlib 中对 CNN 进行了可视化布局。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uji6v/i_made_a_visual_layout_of_my_cnn_in_matplotlib/</link>
      <description><![CDATA[   /u/cookie2004  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uji6v/i_made_a_visual_layout_of_my_cnn_in_matplotlib/</guid>
      <pubDate>Sat, 30 Dec 2023 16:34:54 GMT</pubDate>
    </item>
    <item>
      <title>尝试进行二元分类，但我的测试准确率太低:(</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18uhsrn/trying_to_do_binary_classification_and_my_test/</link>
      <description><![CDATA[     &lt; /td&gt; ​ 结果 如图所示，训练精度还不错（ 0.87），但是验证和测试精度太低。有什么方法可以解决这个问题吗？ 我有一个包含 2 个类和 1400 个图像的数据集。所有图像只是一个对象。    提交者    /u/iv_damke   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18uhsrn/trying_to_do_binary_classification_and_my_test/</guid>
      <pubDate>Sat, 30 Dec 2023 15:16:05 GMT</pubDate>
    </item>
    <item>
      <title>我免费提供 2024 年机器学习路线图辅导：梅赛德斯-奔驰数据科学家回馈 learnmachinelearning 社区</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ug7uc/i_offer_free_machine_learning_roadmap_for_2024/</link>
      <description><![CDATA[嘿， 在 2023 年即将结束之际，我一直在反思自己的旅程——不断发展的领域。自 2018 年以来，我一直潜伏在这个 Reddit 子版块中，与你们一起学习、讨论和成长。每隔两年，我似乎习惯性地发布有关学习 ML 的路线图，这通常会引起一些关注： （4 年前）：https://www.reddit.com/r/learnmachinelearning/comments/cxrpjz/a_clear_roadmap_for_mldl/ （2年前）： https://www.reddit.com/r/learnmachinelearning/comments/qlpcl8/a_clear_roadmap_to_complete_learning_aiml_by_the/ 今天，经过 5 年的努力工作和可能数千个小时的学习，我成为了一名数据与技术人员。梅赛德斯-奔驰的人工智能专家，受邀在行业活动中发表演讲，例如 2024 年 GenAI 汽车会议，我将在会上发表有关自动驾驶的 GenAI 的演讲。但关于我已经足够了。  我来这里是为了回馈社区，这在我的成长中发挥了重要作用。从 2024 年初开始，我将举办 5 场免费机器学习路线图辅导课程。这是我表达谢意并帮助他人开启新的一年的方式 - 将其视为您潜在的新年决心。 交易如下： 五次会议，零成本：我正在进行五次小组会议，每周一次，每次持续 60-90 分钟（取决于小组规模）。它完全免费 - 无任何附加费用，无隐藏费用。  直言不讳，真功夫：期待一种严肃的方法。不会有任何废话，真正的行业见解，我们将为每个参与者制定个人学习路线图。 谁应该申请：我正在寻找承诺。仅当您准备好投入工作、参加会议并参与讨论时才可以申请。  这将是高度互动的，我这边没有或只有几张预先制作的幻灯片。我们将讨论您的个人情况，制定让您取得进步的最佳策略，并且我将在此过程中分享我的见解。 有兴趣吗？填写此 Google 表单：https://forms.gle/SvU8b7WMHPd4LQJh7。该表格将帮助我了解您的背景以及您希望实现的目标。 让我们让 2024 年成为您在 ML 之旅中实现巨大飞跃的一年。期待在会议中见到你们中的一些人！ 最好， Marcel P.S.：我想让小组保持相当小的规模。所以名额有限，先到先得，所以不要磨磨蹭蹭！    由   提交 /u/MarcelDeSutter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ug7uc/i_offer_free_machine_learning_roadmap_for_2024/</guid>
      <pubDate>Sat, 30 Dec 2023 13:58:29 GMT</pubDate>
    </item>
    <item>
      <title>您学习机器学习的动机是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18udkn1/what_is_your_motivation_to_learn_machine_learning/</link>
      <description><![CDATA[基本上是标题。就我个人而言，我开始对机器学习感兴趣，因为我对自己的心理学本科生感到有点失望，并且从广义上讲，我想转向人工智能。所以我回到大学学习一些计算机科学和计算机科学。数学，学习了大量在线课程，成为一名数据科学家，并完成了理学硕士。认知科学领域，研究自然（心理）和人工（人工智能）认知，严重倾向于机器学习相关课程。我热爱这个领域，但我学得越多，我就越无法理解我研究 AGI 的最初动机哈哈 对我来说，它是一波又一波的：首先，它将人工智能视为一种心理/神经科学挑战，然后是关于我的理学硕士中机器学习的数学之美。 （核方法、贝叶斯形式主义等），目前的重点是让这些概率系统在行业环境中发挥作用。 我想知道您学习 ML 的动机或故事是什么？   div&gt;  由   提交 /u/MarcelDeSutter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18udkn1/what_is_your_motivation_to_learn_machine_learning/</guid>
      <pubDate>Sat, 30 Dec 2023 11:22:00 GMT</pubDate>
    </item>
    </channel>
</rss>