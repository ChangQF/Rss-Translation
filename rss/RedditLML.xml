<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Wed, 26 Jun 2024 09:17:22 GMT</lastBuildDate>
    <item>
      <title>TextGrad：通过文本控制 LLM 行为</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dosy6h/textgrad_controlling_llm_behavior_via_text/</link>
      <description><![CDATA[什么是 TextGrad？ 自动梯度引擎 — 用于文本梯度！ TextGrad 是一个功能强大的框架，可通过文本构建自动微分。TextGrad 通过 LLM 提供的文本反馈实现反向传播，这在很大程度上建立在梯度隐喻的基础上 TextGrad 提供了一个简单直观的 API，让我们可以定义自己的损失函数并使用文本反馈对其进行优化。此 API 类似于 Pytorch API，因此很容易适应我们的用例。 即时优化 在即时优化下，有两个主要想法。 首先，DSPy 率先提出了将复杂的基于 LLM 的系统视为可能具有许多层的程序的想法，并提出了以编程方式构建和优化它们的方法。  其次，基于文本梯度的提示优化（ProTeGi）在提示优化的背景下定义了文本梯度，其中梯度是 LLM 对任务期间所犯错误的自然语言反馈。  全文： https://medium.com/aiguys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10  ProteGei 如何工作？ 自然语言梯度：像数值梯度一样工作，但在语义空间中，根据当前提示指出缺陷它在给定一批数据上的表现。通过反馈循环生成，其中 LLM 通过识别和描述其缺点来批评当前提示。 提示编辑：通过解决自然语言梯度突出显示的问题来调整提示。使用另一组 LLM 指令来修改提示，使其在语义上与梯度描述的问题相反。 波束搜索和强盗选择：通过评估多个候选提示并选择最有希望的提示，帮助浏览潜在提示改进的空间。  扩展步骤：根据当前提示评估生成新的提示候选。 选择步骤：采用 UCB Bandits 和连续拒绝等策略，以最小的计算成本识别最有效的新提示。  这种系统的局限性是大量的 API 调用。 提示修改 修改提示以“语义上”与梯度描述的问题相反的概念是 ProTeGi 方法的一个关键方面，该方法旨在提高大型语言模型 (LLM) 的性能通过提示优化。这个过程模仿数值梯度下降，但现在应用于语义或基于语言的上下文中。 理解与梯度相反的语义运动 识别缺点：第一步涉及识别当前提示性能中的具体缺点或错误。这是通过根据一组标准或预期输出评估 LLM 的响应来完成的，从而产生所谓的“自然语言梯度”。这些梯度本质上是详细的、人类可读的反馈，描述了当前提示失败的原因和方式。但这一切都取决于 LLM 的聪明才智！ 语义方向：在数值梯度下降中，梯度指向损失函数最陡峭的增长方向；因此，逆着梯度移动会导致损失的局部最小值。在文本领域，向渐变“语义相反”的方向移动意味着以解决和纠正所指出的缺陷的方式调整提示。例如，如果渐变表明提示太模糊，则使其更具体将是朝相反方向移动。  AIGuys 时事通讯： https://medium.com/aiguys/newsletter     提交人    /u/Difficult-Race-1188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dosy6h/textgrad_controlling_llm_behavior_via_text/</guid>
      <pubDate>Wed, 26 Jun 2024 07:42:17 GMT</pubDate>
    </item>
    <item>
      <title>如何参与项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dosmd1/how_to_get_in_working_with_projects/</link>
      <description><![CDATA[大家好，我来告诉你们我的处境。现在，我熟悉机器学习算法的理论，比如监督学习和无监督学习。同时，我也研究了深度学习方面，比如使用 TensorFlow 的 ANN。最近，我使用 OpenCV 和 MediaPipe 做了一些非常基本的项目，比如手势音量控制和使用手势在屏幕上绘画。我似乎喜欢使用 OpenCV 做所有这些事情。我还没有真正使用 CSV 类型的数据集做过任何关于 ML 算法的项目，因为我发现这真的很无聊——绘制可视化和数据清理（只是表格）。  你对我应该走哪条路有什么建议吗？对我来说，这一切都非常令人不知所措；有太多东西要学。    提交人    /u/Otherwise_Ask4290   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dosmd1/how_to_get_in_working_with_projects/</guid>
      <pubDate>Wed, 26 Jun 2024 07:18:41 GMT</pubDate>
    </item>
    <item>
      <title>将 LLM 映射到 GPU 实例以避免 OOM 错误</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dorpr4/mapping_of_llms_to_gpu_instances_to_avoid_oom/</link>
      <description><![CDATA[  由    /u/Possible_Minute_4299  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dorpr4/mapping_of_llms_to_gpu_instances_to_avoid_oom/</guid>
      <pubDate>Wed, 26 Jun 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和数据科学职位简历的注意事项</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1doqw89/resume_dos_and_donts_for_ai_and_data_science_jobs/</link>
      <description><![CDATA[在看过很多简历评论和与工作相关的帖子后，我介绍了一些简历技巧，可帮助您获得 ML 工程师、数据科学家或其他相关职位。AIQ 第 2 集通过回答一些重要问题讨论了如何为 AI 和 ML 工作准备简历（技巧和窍门），例如 1. 简历的重要部分。 2. 应届毕业生简历技巧 3. 认证与项目 4. 要避免的错误 5. 1 页简历是强制性的吗？ 6. 您是否应该包括过去的非技术经验？ 7. 免费 ATS 用于简历审查。 8. 可供选择哪些项目？ 9.我可以包括泰坦尼克号分类吗？......以及许多其他问题 在此处查看播客：https://youtu.be/vl0zNSE9Zws?si=IQwi9srpomnUmUE8    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1doqw89/resume_dos_and_donts_for_ai_and_data_science_jobs/</guid>
      <pubDate>Wed, 26 Jun 2024 05:23:57 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 的 Sora：文本转视频的人工智能的下一个飞跃——计算机视觉将发挥什么作用？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1doqdz1/openais_sora_the_next_leap_in_ai_with_texttovideo/</link>
      <description><![CDATA[大家好，我最近一直在研究人工智能的世界，尤其是计算机视觉，我偶然发现了一些关于 OpenAI 的新文本转视频工具 Sora 的有趣信息。它让我开始思考人工智能发展的更广泛影响，特别是视觉理解对于实现更先进的人工智能甚至 AGI 的重要性。 Sora 的简要介绍：  这是一款可以根据文本描述生成长达 60 秒的视频的人工智能工具 目前正在测试中，尚未向公众开放 使用“扩散变压器模型” （类似于 DALL-E 3 对图像的工作方式） 可以处理复杂的场景、相机移动，甚至在某种程度上模拟物理  有趣的是，与之前的文本到图像模型相比，Sora 似乎对物理世界和语言有更深入的理解。这让我想知道：计算机视觉对于 AI 的下一次重大飞跃有多重要？ 一些想法：  人类智能严重依赖视觉信息。想想一个 3 岁的孩子如何仅通过看一棵树就轻松识别一棵树。 当前的语言模型非常出色，但它们主要基于文本进行训练。我们是否因为没有整合强大的视觉理解而缺少了一个巨大的组件？ 可以为 LLM 提供自己的“一双眼睛”吗？ （即先进的计算机视觉功能）是迈向更通用智能的关键一步吗？ 纯语言模型是否会达到极限，从而使视觉理解成为进一步发展的必要条件？  我对此特别感兴趣，因为我正在工作中从事 CV 项目（尽管目前处于暂停状态）。该领域的职位空缺似乎比一般 ML 少，但我不禁觉得它将是未来的关键。 你们都觉得呢？像 Sora 这样的工具只是计算机视觉与 AI 系统更深入集成的开始吗？真正的 AGI 是否需要强大的视觉组件才能真正理解和与世界互动？ 让我们讨论一下！    提交人    /u/shivgupta5023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1doqdz1/openais_sora_the_next_leap_in_ai_with_texttovideo/</guid>
      <pubDate>Wed, 26 Jun 2024 04:53:00 GMT</pubDate>
    </item>
    <item>
      <title>正在寻找助手和共同学习者？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dooqo9/looking_for_helpers_and_colearners/</link>
      <description><![CDATA[嘿伙计们，正如你们所知，我之前创建了一个学习小组 discord 服务器，很多人都是从同一个子版块加入的。 现在我们正在寻找一些可以为服务器中的人们做出贡献或提供帮助的助手。 （请注意，这个服务器中有很多初学者） 所以如果你想为这个服务器做出贡献，请加入这个服务器：https://discord.com/invite/pKSvqwNv    提交人    /u/luffy_san2345   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dooqo9/looking_for_helpers_and_colearners/</guid>
      <pubDate>Wed, 26 Jun 2024 03:19:31 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉对人工智能的发展有多重要</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1domqvu/how_important_will_computer_vision_be_to_the/</link>
      <description><![CDATA[我正在学习 ML，特别是计算机视觉，这个领域的工作机会少得多，但这是我的出路，因为我目前的工作是做一个 CV 项目（有点，由于市场原因，该项目暂停了，我已经从研发部门调到维持部门，但到目前为止已经做了足够多的工作来自学其余部分并将其写在简历上） 现在回到这篇文章的重点。对于人类智能来说，视觉似乎非常重要。如果你问一个三岁的孩子什么是树，他们很可能知道什么是树，或者至少可以识别一棵树。很多人都是视觉学习者，我明白人工智能在表面下或多或少只是数学，但我们可能会利用现有的 NLP 数据来消耗或过度训练当前的人工智能系统，而 LLM 可能会停滞不前。你们都认为真正的 AGI 需要一个 CV 组件来真正理解世界吗？我们在描述和标记事物方面取得的进展是否有限？当前的模型真的只有耳朵而没有眼睛，我们是否错过了自身智能的很大一部分？我知道有 CV 模型，但一切仍然归结为这些 LLM 中的嵌入式标签，构建天网的下一步是否会涉及为 LLM 提供一双自己的眼睛？有谁明白我想说什么，能比我解释得更好吗？    提交人    /u/LeopoldBStonks   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1domqvu/how_important_will_computer_vision_be_to_the/</guid>
      <pubDate>Wed, 26 Jun 2024 01:38:05 GMT</pubDate>
    </item>
    <item>
      <title>构建 AI 语音翻译器：保留任何语言的声音！（Python + Gradio 教程）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dohvsg/build_an_ai_voice_translator_keep_your_voice_in/</link>
      <description><![CDATA[上周，我开发了一个语音翻译器，只花了几个小时就使用了 3 种不同的 API。最近，AI API 所能做的事情令人惊叹。 🎤🌐 您可以录下自己说英语的声音，然后听自己的声音翻译成西班牙语、俄语、日语或任何其他语言！翻译后的音频保留了您独特的声音，让您感觉非常个性化和真实。🌟🗣️ 我录制了一个视频，记录了使用 Gradio（Python 语言）制作此应用的过程，大约只需 20 分钟。 我为此感到非常自豪，希望对您有所帮助！ https://youtu.be/ZduW0N31JuE   由    /u/turpyturp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dohvsg/build_an_ai_voice_translator_keep_your_voice_in/</guid>
      <pubDate>Tue, 25 Jun 2024 21:50:36 GMT</pubDate>
    </item>
    <item>
      <title>像专业人士一样构建知识图谱：传统 NER 与大型语言模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dof3ef/construct_knowledge_graphs_like_a_pro_traditional/</link>
      <description><![CDATA[您是否考虑使用 LLM 构建知识图谱以增强您的 RAG 系统？ 您知道实际上可以使用混合方法来结合两全其美吗？ 查看我们的最新视频：像专业人士一样构建知识图谱：传统 NER 与大型语言模型 知识图谱是现代数据驱动世界的支柱。它们帮助我们组织信息，发现隐藏的见解，并为语义搜索和智能问答等高级应用程序提供支持。但您如何真正构建有效的知识图谱？ 在我最新的 YouTube 视频中，我深入探讨了关键方法 - 传统的命名实体识别 (NER) 方法与尖端的大型语言模型 (LLM)。我比较了每种方法的优缺点，以便您可以选择最适合您的知识图谱项目的方案。 传统的 NER 技术（如基于规则的系统和机器学习模型）可提供精确度、透明度和计算效率。但它们在跨域可扩展性和适应性方面存在困难。另一方面，LLM 可带来令人印象深刻的上下文理解和快速设置，但它们资源密集且可解释性较差。 该视频探讨了如何通过结合两种方法的优点的混合方法最大限度地从非结构化数据源中提取见解。我分享了现实世界的例子、实用技巧以及选择知识图谱构建方法时需要考虑的关键因素。 看看吧： https://youtu.be/OsnM8YTFwk4?si=GGwJEyXNix5_erav    提交人    /u/linamagr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dof3ef/construct_knowledge_graphs_like_a_pro_traditional/</guid>
      <pubDate>Tue, 25 Jun 2024 19:54:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 TinyVGG 和 TrivialAugment 进行实验时的有趣观察</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dof1qu/interesting_observation_while_experimenting_with/</link>
      <description><![CDATA[      我正在从这个 YouTube 视频中学习使用 PyTorch 进行图像识别，视频中使用 TinyVGG 将图像分为披萨、牛排或寿司。所以我尝试自己做，调整了一些超参数，并对使用和不使用 TrivialAugment 的 TinyVGG 的性能进行了有趣的观察。 不使用 TrivialAugment 的损失和准确度曲线 .......并使用 TrivialAugment 视频中的讲师提到，TrivialAugment 应该是一种 SOTA 数据增强技术，并且与 ResNet50 配合得相当好。我很困惑为什么这个东西对 TinyVGG 来说不是一个好兆头。如您所见，使用 TrivialAugment 时损失曲线到处都是。我对计算机视觉模型和 ML 还不太熟悉，所以我不完全确定为什么会出现如此显著的差异。    提交人    /u/Ar010101   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dof1qu/interesting_observation_while_experimenting_with/</guid>
      <pubDate>Tue, 25 Jun 2024 19:52:18 GMT</pubDate>
    </item>
    <item>
      <title>从头开始训练 70B 模型：开源工具、评估数据集和经验</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dobgbs/training_a_70b_model_from_scratch_open_source/</link>
      <description><![CDATA[今年早些时候，Imbue 训练了一个针对推理和编码进行了优化的 70B 模型。尽管训练数据量少了 7 倍，但该模型的性能与 LLAMA 3 70B 大致相当。 今天，我们发布了一个工具包来帮助其他人做同样的事情，其中​​包括：  11 个经过清理和扩展的 NLP 推理基准，包括 ARC、GSM8K、HellaSwag 和 Social IQa 原创的以代码为中心的推理基准 包含 450,000 个关于 NLP 问题歧义性的人类判断的新数据集 用于将小型实验扩展到 70B 运行的超参数优化器 用于将集群从裸机转变为强大的高利用率训练的基础架构脚本  …还有更多！ 在此处阅读更多信息并访问工具包：https://imbue.com/research/70b-intro/ 除了我们的工具之外，我们还分享了三篇博客文章，其中包含我们从训练过程中获得的经验教训： I. 进行评估 我们发现，经过微调后，我们的模型和最好的开源模型在大多数多项选择基准测试中都优于 GPT-4o 零样本。 令人惊讶的是，当仅对明确的问题进行评估时，开放和封闭模型都达到了接近 100% 的准确率。我们清理了评估数据集，以将真正的推理失败与由于模棱两可或低质量问题导致的失败区分开来。 https://imbue.com/research/70b-evals/ II.设置基础设施 使用我们的集群进行高性能训练意味着每个组件（InfiniBand、以太网、GPU 和节点本身）都必须完美运行。如果超过 12,000 个连接中哪怕只有一个连接有点不稳定，也可能会减慢整个训练运行速度。 我们正在分享开源脚本和端到端基础设施设置指南，其中详细介绍了使一切完美运行并确保其保持这种状态的过程。 https://imbue.com/research/70b-infrastructure/ III。扩展实验 我们在第一次尝试时就成功地从 7B 运行扩展到 70B 运行，训练不稳定性最小，没有损失峰值。我们还根据更小模型的实验结果预测了 70B 模型的性能。 我们使用超参数优化器 CARBS 实现了这一目标。我们今天开源了 CARBS，以便其他尝试新模型架构的小团队可以进行小规模实验并信任大规模性能。 https://imbue.com/research/70b-carbs/ 这是我们正在开展的众多项目之一，旨在构建可以推理和编码的协作代理。其他领域包括 RL、数据生成和体验设计，以使这些强大的功能对用户来说易于访问和直观。 如果这引起了你的兴趣，我们正在招聘！    提交人    /u/thejashGI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dobgbs/training_a_70b_model_from_scratch_open_source/</guid>
      <pubDate>Tue, 25 Jun 2024 17:21:43 GMT</pubDate>
    </item>
    <item>
      <title>请禁止发布职业/简历帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dobbqq/please_ban_careerresume_posts/</link>
      <description><![CDATA[或者为他们创建另一个子版块或类似的东西。天呐。这个子版块充斥着无休止的&quot;评价我的简历&quot;或&quot;我需要 x 学位才能学机器学习吗&quot;帖子，而不是关于实际机器学习的内容    提交人    /u/Surmaaja   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dobbqq/please_ban_careerresume_posts/</guid>
      <pubDate>Tue, 25 Jun 2024 17:16:12 GMT</pubDate>
    </item>
    <item>
      <title>哪些模型最适合投资组合优化？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do9ork/what_models_are_best_for_portfolio_optimization/</link>
      <description><![CDATA[我使用随机森林模型，因为我知道它是最好的模型之一，具有最小的 MSE 和其他一般的东西，但我听说很多人使用神经网络。我使用随机森林来预测未来 5 年的回报，然后从中选择具有最佳回报的股票。    提交人    /u/patrickbateman53   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do9ork/what_models_are_best_for_portfolio_optimization/</guid>
      <pubDate>Tue, 25 Jun 2024 16:07:08 GMT</pubDate>
    </item>
    <item>
      <title>需要硕士或博士学位才​​能成为机器学习工程师。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do5w88/need_master_or_phd_for_become_machine_learning/</link>
      <description><![CDATA[问题很明确。成为 ML 工程师是否需要硕士学位和博士学位，或者像 coursea 这样的在线平台的优质证书是否足以获得良好的职业生涯？（我想在大公司工作）    提交人    /u/Necessary-Car-5080   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do5w88/need_master_or_phd_for_become_machine_learning/</guid>
      <pubDate>Tue, 25 Jun 2024 13:22:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1do0dne/maths_for_ml/</link>
      <description><![CDATA[嗨，我刚刚开始学习机器学习。目前，我正在 Coursera 上学习 Andrew Ng 的 DeepAI“机器学习专业化”课程。为了进一步进步，我想学习一些数学。有人可以推荐一门关于机器学习中使用的数学的好课程吗？还有，有人可以建议在该领域前进的最有效途径是什么吗？我一直在练习和观看 Python、Numpy、Matplotlib 和 Pandas 的视频。我觉得还需要一些 Tensorflow 知识。除此之外，你们对我这个初学者有什么建议吗？    提交人    /u/NF_laidback   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1do0dne/maths_for_ml/</guid>
      <pubDate>Tue, 25 Jun 2024 07:41:38 GMT</pubDate>
    </item>
    </channel>
</rss>