<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Mon, 03 Mar 2025 21:18:12 GMT</lastBuildDate>
    <item>
      <title>为什么推理模型（例如O1，O3和R1）不支持函数本质上调用？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2t6ii/why_do_reasoning_models_eg_o1_o3_and_r1_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为什么您认为最佳推理模型（例如OpenAI O1，O3和DeepSeek R1）不支持呼叫的功能，这是“这是“对固定模型”的额外成本，以及策划的额外额外的额外效果，以及在策划的额外范围内，该案例的额外成本，以及在策划+工具数据上的额外范围，这是“这是“合理+工具”分析的额外成本，这是否是合理的，这是一个案例的案例，以及确切的效率，安全性分析，安全性分析，并具有确定性，安全性分析的额外范围，并且是策划的，并且是策划的。用于工具和推理“或我们尚未解决的技术挑战？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cluelessperson3     &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j2t6ii/why_do_reasoning_models_eg_o1_o1_o3_o3_and_and_r1_not/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2t6ii/why_do_reasoning_models_eg_o1_o3_and_r1_not/</guid>
      <pubDate>Mon, 03 Mar 2025 20:55:27 GMT</pubDate>
    </item>
    <item>
      <title>Stanford CS229A：机器学习课程，Andrew NG？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2sqg1/stanford_cs229a_machine_learning_course_andrew_ng/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是好奇，是否有斯坦福CS229A的YouTube链接：机器学习课程，Andrew Ng。在那里吗？我想看Andrew Ng的应用ML类。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/usestigndistrict376     [link]  &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j2sqg1/stanford_cs229a_machine_machine_learning_course_course_andrewrew_andrew_andrew_ng/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2sqg1/stanford_cs229a_machine_learning_course_andrew_ng/</guid>
      <pubDate>Mon, 03 Mar 2025 20:36:36 GMT</pubDate>
    </item>
    <item>
      <title>免费A100 GPU访问 - 寻找学生产品测试人员 -  $ 250礼品卡</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2s38l/free_a100_gpu_access_looking_for_student_product/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  问候： 我正在寻找目前正在beta的新的无服务器GPU产品的10个产品测试人员。 这是规则：   - 必须在美国大学中注册的老师或学生。 You cannot use the service without a .edu address. - You must be proficient in English (it can be a second language) so that we can ask questions during the debrief. - You must have intermediate Python skills (you have Python on your local machine, you can install virtual environments, you can clone github repos, you know how to use pip).您可以使用Windows，Mac或Linux机器。   - 您必须在5天的时间内从我们的AI/ML示例目录中运行三个Python实验。每个人都需要5-10分钟才能运行。如果需要的话，您也可以运行自己的Python代码。   - 测试完成后，您必须对30个视频汇报进行投入，您将分享您的反馈，并告诉我们您喜欢的产品和不喜欢该产品的内容。   - 然后，您将通过电子邮件获得选择的礼品卡（Amazon等）。 Limit one per person. If you are interested, please email [beta@positronnetworks.com](mailto:beta@positronnetworks.com) Please email from your .edu地址。 注意：如果您从非.edu电子邮件地址给我发送电子邮件，您将被忽略，并且您没有资格。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/curttel     &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j2s38l/free_a100_gpu_access_for_for_for_student_product/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2s38l/free_a100_gpu_access_looking_for_student_product/</guid>
      <pubDate>Mon, 03 Mar 2025 20:09:46 GMT</pubDate>
    </item>
    <item>
      <title>在没有单词限制的情况下免费进行语音文本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2r5dg/made_a_free_ai_text_to_speech_with_no_word_limit/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/u/cool-hornet-8191      &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j2r5dg/made_a_a_free_ai_ai_ai_ai_e_text_to_speect_to_speech_with_with_with_no_no_no_no_no_no_no_word/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2r5dg/made_a_free_ai_text_to_speech_with_no_word_limit/</guid>
      <pubDate>Mon, 03 Mar 2025 19:31:02 GMT</pubDate>
    </item>
    <item>
      <title>如果我的输入功能具有无法使用插补的NA值，我应该使用哪种机器学习模型。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2qrmv/what_machine_learning_model_should_i_use_if_my/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的输入是数字矩阵。（即每行培训/测试数据只是一个矩阵）。我有两个问题。 1）这些单独的矩阵都有不同的尺寸。 2）每个矩阵在无法使用插补的不同位置具有多个NA值。如何在此数据上训练模型（最好是随机森林）？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j2qrmv/what_machine_learning_model_model_should_should_i_is_if_my/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2qrmv/what_machine_learning_model_should_i_use_if_my/</guid>
      <pubDate>Mon, 03 Mar 2025 19:15:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么令牌只关注以前的令牌？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2qokz/why_do_tokens_only_pay_attention_to_previous/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  更具体地说，我的意思是。 想象一下，数据是“约翰买了冰淇淋”。他感到很高兴。＆quot＆quot  我们通过在每个点截断了（自我？）监督学习的标签数据。我们训练该模型预测“购买” “约翰”之后“冰” “约翰买”之后，等等。 （显然，我应该谈论代币，而不是单词，但这是无害的，广泛的简化）。 ，所以现在我们有6个标记的数据。  在我们给型号“约翰购买冰淇淋”的情况下。我们对其进行训练以预测下一个单词（旁注：我们不训练它以预测接下来的两个，计算对此的损失等。如果有人想告诉我为什么我想要那个，但是我的假设是没有好处，所以没有意义：做出最好的国际象棋动作是两次最好的举动？ Happy尚未产生，也没有作为输入提供！这很明显。买的确实去了约翰。但是，为什么买不买奶油呢？作为输入的一部分，已提供乳霜。  我目前的最佳猜测是：如果我们并行化并想一次对所有这6个样本进行训练，那么我们可以重复使用计算？那是原因吗？  我敢肯定我曾经理解过答案，但是现在它逃脱了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j2qokz/why_do_do_do_tokens_only_pay_pay_attention_to_previous/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2qokz/why_do_tokens_only_pay_attention_to_previous/</guid>
      <pubDate>Mon, 03 Mar 2025 19:12:20 GMT</pubDate>
    </item>
    <item>
      <title>本周在AI中：（ 2025年2月24日至3月2日）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2qk53/this_week_in_ai_february_24th_march_2nd_2025/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/glum_significance140      [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2qk53/this_week_in_ai_february_24th_march_2nd_2025/</guid>
      <pubDate>Mon, 03 Mar 2025 19:07:10 GMT</pubDate>
    </item>
    <item>
      <title>我应该将哪种强化学习方法与LLM一起用于扑克AI？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2q40d/what_reinforcement_learning_method_should_i_use/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我正在研究一个扑克AI项目，在那里我正在培训大型语言模型（LLM），以预测给定游戏状态的扑克动作（检查，呼叫，下注，下注，加薪等）。我的最终目标是创建一个模型，该模型主要是通过自我播放和对手建模来高水平发挥扑克的作用。但是，我遇到了一些挑战，希望您能帮助我！ 这是情况：  培训方法：我正在使用“真正的扑克手动历史数据”上使用监督的微调（SFT）来最初教LLM如何预测游戏国家的扑克动作。这意味着该模型从过去的游戏的示例中学习，预测玩家在各种情况下采取的行动。 自我播放设置：我计划最终转向自我玩法，在这里LLM将与自己（或我创建的其他类型的模型来模拟不同的游戏样式）。我将使用这些自我播放会话来改善模型。这给我带来了训练的相当多种对手行为。连续的动作空间。这使得应用传统的RL方法有些棘手。  我的问题： 鉴于我无法访问动作概率，我应该采取什么RL方法或策略来改善模型？具体来说，我正在寻找一种方法：  将自我播放与基于奖励的学习结合在一起。 不需要连续的概率来完善模型，而不需要连续的概率。 确保模型确保过度适应其先前的行为，而是在播放和利用不同的策略，但我                   监督微调或使用更简单的RL技术（例如Monte Carlo更新），但我不确定哪种方法最适合我拥有的LLM设置。我还考虑了Q学习或深度Q学习。 鉴于我的情况，我应该采取的任何建议或建议将不胜感激！ 是的，是的，我用AI使用AI来编写此Queston。但它捕获了我想说的一切，我很努力写作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/godlover123451     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2q40d/what_reinforcement_learning_method_should_i_use/</guid>
      <pubDate>Mon, 03 Mar 2025 18:49:26 GMT</pubDate>
    </item>
    <item>
      <title>BS+MS工业工程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2pn95/bsms_in_industrial_engineering/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的单身汉在工业工程中，我的MS也在工业工程中，但我的MS大学（UIUC）允许我参加所有ML，DL和统计课程，所以我没有参加任何ML，DL，dl，i i i i i i i i i i i i i，在我的履历中，因此发生了很多过滤/拒绝。提交由＆＃32;态href =“ https://www.reddit.com/r/learnmachinelearning/comments/1j2pn95/bsms_in_industrial_engineering/”&gt; [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2pn95/bsms_in_industrial_engineering/</guid>
      <pubDate>Mon, 03 Mar 2025 18:31:10 GMT</pubDate>
    </item>
    <item>
      <title>视觉说明“反向传播：差异化规则[第3部分]</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2o5as/visual_explanation_of_backpropagation/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/madiyar       [注释]            ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2o5as/visual_explanation_of_backpropagation/</guid>
      <pubDate>Mon, 03 Mar 2025 17:30:27 GMT</pubDate>
    </item>
    <item>
      <title>深入研究卷积层！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2mrwp/a_deep_dive_into_convolutional_layers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我一直在深入研究卷积操作。我在此处发表了一篇文章 https://ym2132.github.io/from_scratch_convolate_convolutional_layers 。我的目的是在此过程中以很多很酷的想法从头开始建立卷积。 我希望您觉得它有用，并且对任何反馈都非常感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/throwaway16362718383      [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2mrwp/a_deep_dive_into_convolutional_layers/</guid>
      <pubDate>Mon, 03 Mar 2025 16:34:33 GMT</pubDate>
    </item>
    <item>
      <title>进入ML/AI</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2j9dj/getting_into_mlai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨。 我正在寻求有关AI/ML行业中的课程和工作类型的建议，并想知道是否有人可以提供帮助。我目前正在与Udemy在线一起参加课程，觉得这不是一门好课程。代码学院是一个好的学习平台吗？我目前正在学习Python，并希望Whatelse考虑学习一些建议。同样，在不久的将来，任何有工作类型的建议都将不胜感激。 我有电气/电子背景，但要对其他领域开放，因为我想要的是AI，ML，DevOps等。提交由＆＃32; /u/u/bednew8044     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2j9dj/getting_into_mlai/</guid>
      <pubDate>Mon, 03 Mar 2025 13:59:49 GMT</pubDate>
    </item>
    <item>
      <title>我可以实施哪些非琐碎的NLP论文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j2ccwm/what_are_some_non_trivial_nlp_papers_i_can/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/dark_matter22     [links]   &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1j2ccwm/what_are_are_are_non_non_non_trivial_trivial_nlp_papers_papers_i_i_i_can/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j2ccwm/what_are_some_non_trivial_nlp_papers_i_can/</guid>
      <pubDate>Mon, 03 Mar 2025 06:22:01 GMT</pubDate>
    </item>
    <item>
      <title>哪个是学习ML的更好来源？ O'Reilly Hands ML Book还是Andrew Ng Coursera课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1j1qug5/which_is_the_better_source_for_learning_ml/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我个人更喜欢文档而不是视频，但想知道哪个是最好的来源。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/hamstermolester6969      [注释]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1j1qug5/which_is_the_better_source_for_learning_ml/</guid>
      <pubDate>Sun, 02 Mar 2025 13:28:48 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到这里   对于那些正在寻找简历评论的人，请在 href =“ href =“ https://www.reddit.com/r/resumes”&gt;/r/简历或 r/EngineeringResumes 首先，然后在此处交叉crosspost。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>