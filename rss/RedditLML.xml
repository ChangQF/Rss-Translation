<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 14 Nov 2024 09:18:06 GMT</lastBuildDate>
    <item>
      <title>请推荐遵循基于项目的学习方法的机器学习书籍/资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gr0y82/please_recommend_machine_learning_booksresources/</link>
      <description><![CDATA[我正在寻找教授机器学习但使用基于项目的方法的书籍。我说书籍的原因是因为我更容易理解书籍，但是任何其他基于项目的学习资源也将受到赞赏。     提交人    /u/Suspicious_Row_5195   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gr0y82/please_recommend_machine_learning_booksresources/</guid>
      <pubDate>Thu, 14 Nov 2024 09:17:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 主题建模+新闻文章情绪</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gr00l6/d_topic_modellingsentiment_on_news_articles/</link>
      <description><![CDATA[我正在开展一个项目，使用主题建模，然后对大量新闻文章（至少 100k）进行情感分析。对于每一篇文章，我的目标是对主要主题进行分类，并将情绪确定为消极、中性或积极。 我很想听听您在以下方面的实践经验，包括哪些方法对您有用以及您遇到了哪些挑战：  主题建模 + 情绪分析管道：有没有有效结合这些任务的流行管道示例，例如 LDA、NMF、KeyBERT、BERTopic 等？ 嵌入模型：有关在不同块大小下表现良好的嵌入模型的建议。 块的粒度：有关有效主题建模的块大小的见解 - 我见过同时使用字数（例如 50 个字）和标记数（例如 50 个标记）的方法。 评估方法：评估各种架构和超参数，包括困惑度和连贯性等指标。  提前谢谢大家！项目完成后，我很乐意在这里分享我的经验。    提交人    /u/alex7885   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gr00l6/d_topic_modellingsentiment_on_news_articles/</guid>
      <pubDate>Thu, 14 Nov 2024 08:03:56 GMT</pubDate>
    </item>
    <item>
      <title>在 Conformer 模型中位置编码是必要的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqzunn/is_positional_encoding_necessary_in_the_conformer/</link>
      <description><![CDATA[我已阅读 Pytorch 中 Conformer 模型的实现 (https://pytorch.org/audio/main/_modules/torchaudio/models/conformer.html#Conformer)。据我所见，那里没有位置编码 (PE) 层。 有人知道为什么 Pytorch 在这里没有使用 PE 吗？因为原始的 Conformer 论文声称他们确实使用了 PE     提交人    /u/khanh14ph   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqzunn/is_positional_encoding_necessary_in_the_conformer/</guid>
      <pubDate>Thu, 14 Nov 2024 07:51:19 GMT</pubDate>
    </item>
    <item>
      <title>有实际讲师指导的 Python/NLP/数据科学最佳在线直播课程吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqzsbi/best_live_online_courses_for_pythonnlpdata/</link>
      <description><![CDATA[我正在通过 Python 路径从目前的教学职业转向 NLP 职业，虽然我已经自学了大约三个月，但我发现进度有点慢，想看看是否有一个好的课程（标题中描述）真的值得投入金钱和时间，并且可以让我这样的人更容易上手？ 一个重要的要求是（为此）我对纯自学课程不感兴趣，在这些课程中你应该自己观看视频或阅读文本，而无需与任何人实时见面。    提交人    /u/Surpr1Ze   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqzsbi/best_live_online_courses_for_pythonnlpdata/</guid>
      <pubDate>Thu, 14 Nov 2024 07:46:16 GMT</pubDate>
    </item>
    <item>
      <title>如何检查我的包名称是否在 PYPI 上可用？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqze9v/how_to_check_if_my_package_name_is_available_on/</link>
      <description><![CDATA[  由    /u/No-Consequence-3216  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqze9v/how_to_check_if_my_package_name_is_available_on/</guid>
      <pubDate>Thu, 14 Nov 2024 07:16:22 GMT</pubDate>
    </item>
    <item>
      <title>如何安装pytorch、cuda</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqz9jm/how_to_install_pytorch_cuda/</link>
      <description><![CDATA[当我放 conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia  它最终得到 https://preview.redd.it/wfld1f0i6t0e1.png?width=1743&amp;format=png&amp;auto=webp&amp;s=1d1959ca8cae0e5e562dff576fc22a72a913b61c    提交人    /u/IAMGODSS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqz9jm/how_to_install_pytorch_cuda/</guid>
      <pubDate>Thu, 14 Nov 2024 07:06:28 GMT</pubDate>
    </item>
    <item>
      <title>非 Web 开发人员，您是如何学习 Web 抓取的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqyxzc/nonweb_developers_how_did_you_learn_web_scraping/</link>
      <description><![CDATA[你花了多长时间才学会它？任何在线资源链接都会非常有用。  PS：我知道有很多 YouTube 资源可以帮助我，但我的非开发人员背景使我无法理解这些课程中教授的所有内容。假设我有 3-4 个月的时间来学习 Web 抓取，你会向我推荐哪些资源/课程？  谢谢！     提交人    /u/NoResource56   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqyxzc/nonweb_developers_how_did_you_learn_web_scraping/</guid>
      <pubDate>Thu, 14 Nov 2024 06:43:42 GMT</pubDate>
    </item>
    <item>
      <title>深度学习小项目</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqx5qk/deep_learning_small_project/</link>
      <description><![CDATA[我想知道我应该尝试什么类型的深度学习项目来提升我的技能和知识。我是这方面的技术初学者，但我已经通过网络学习了深度学习的基础和原理。 我希望得到任何关于 CNN 算法项目的建议，任何可以提高我技能的小项目。    提交人    /u/YKnot__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqx5qk/deep_learning_small_project/</guid>
      <pubDate>Thu, 14 Nov 2024 04:50:14 GMT</pubDate>
    </item>
    <item>
      <title>答案是 D 吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqwu9e/would_the_answer_be_d/</link>
      <description><![CDATA[      https://preview.redd.it/5w50cfdwos0e1.png?width=661&amp;format=png&amp;auto=webp&amp;s=2ad4d967236f6f3c1c658bfdc3b4ecce412e340d 我尝试回答这个问题，并得出答案为 D。有人可以确认它是否正确吗？如果不正确，哪一个是正确答案？ 提前谢谢您！    提交人    /u/NoResource56   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqwu9e/would_the_answer_be_d/</guid>
      <pubDate>Thu, 14 Nov 2024 04:31:43 GMT</pubDate>
    </item>
    <item>
      <title>我们对 AI 模型无损压缩研究的关键见解</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqtebn/key_insight_from_our_research_on_lossless/</link>
      <description><![CDATA[      📝 论文： https://arxiv.org/abs/2411.05239 💻 代码： https://github.com/zipnn/zipnn/  我们最近发表了一篇预印本，ZipNN：AI 模型的无损压缩，并希望与社区分享我们的一项重要发现。 神经网络参数可能看起来是随机的（例如，[0.1243, -1.2324, -0.3294...]），但它们在计算机中的表示实际上使压缩成为可能。 关键见解：浮点结构实现压缩 用于存储模型参数的浮点数是结构化的如：  符号位（正/负） 指数（范围） 尾数（精度）  有趣的是，虽然符号位和尾数位看起来是随机的，但指数并不覆盖其范围内的所有值，并且其分布是倾斜的。如图所示，该分布在四个不同的模型中都有说明 — — 我们在许多模型中都观察到了这种模式。 指数值直方图 为什么？这是由于模型的训练方式所致（有关详细信息，请参阅论文中的第 3 段）。 ZipNN 库：利用这一见解 这一见解构成了 ZipNN 的基础，这是我们的开源库无损压缩，与 ZSTD 等最先进的方法相比，它提供了更高的压缩比和更快的压缩/解压缩速度。 流行浮点格式的存储节省：  BF16 格式：节省 33% 的空间 FP32 格式：节省 17% 的空间  我们还开发了 Hugging Face 插件，可以快速下载和加载压缩模型。 示例模型：LLama-3.2-11B 使用 ZipNN，只需添加一行代码即可启用压缩。 🔗 GitHub 存储库   由    /u/Candid_Raccoon2102  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqtebn/key_insight_from_our_research_on_lossless/</guid>
      <pubDate>Thu, 14 Nov 2024 01:29:52 GMT</pubDate>
    </item>
    <item>
      <title>深度学习数学练习解决方案（De Gruyter）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqrcqj/exercise_solutions_for_the_mathematics_of_deep/</link>
      <description><![CDATA[大家好！我目前正在使用标题中提到的书籍（链接此处）学习深度学习的数学基础。我真的很喜欢它，但我注意到它似乎没有包含练习的解决方案 - 至少在我拥有的版本中没有。我试过在线搜索解决方案，但到目前为止还没有运气。  这里有人可以访问解决方案或知道我可以在哪里找到它们吗？提前感谢任何帮助！    提交人    /u/nerec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqrcqj/exercise_solutions_for_the_mathematics_of_deep/</guid>
      <pubDate>Wed, 13 Nov 2024 23:52:07 GMT</pubDate>
    </item>
    <item>
      <title>GPT 就是这样处理提示的吗???拜托，我明天要考试...</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqn4cv/is_this_how_gpt_handles_the_prompt_please_i_have/</link>
      <description><![CDATA[大家好，这是我第一次在这里发帖，因为我最近才开始学习 ML。目前，我正在准备一个关于 transformer 的测试，不确定我是否理解得正确。所以我将写下我对提示处理和答案生成的理解，如果我错了，请纠正我。 在训练时，GPT 会同时生成所有输出标记，但在使用经过训练的 GPT 时，它会一次生成一个输出标记。 因此，当给出提示时，此提示将传递给与编码器基本相同的机制，以便在提示内部计算注意力。因此，提示被拆分成标记，然后将标记嵌入并传递到应用非掩码注意力的多个编码器层中。最后，我们剩下提示标记的上下文矩阵。 然后，当 GPT 开始生成时，为了生成第一个输出标记，它需要关注最后一个提示标记。这里，需要 Q、K、V 向量来继续执行解码器算法。因此，对于所有提示标记，我们使用上下文矩阵和解码器在训​​练期间学习的 Wq、Wk、Wv 矩阵来计算它们的 K 和 V 向量。因此，前一个提示标记只需要 K 和 V 向量，而最后一个提示标记还需要一个 Q 向量（因为我们专注于它）来生成第一个输出标记。 现在，解码器机制已应用，我们剩下一个维度为 vocabSize 的向量，其中包含所有词汇标记的概率分布，这些词汇标记将成为下一个生成的词汇标记。因此我们将概率最高的一个作为第一个生成的输出标记。 然后，我们通过将其嵌入向量乘以 Wq、Wk、Wv 矩阵来创建其 Q、K、V 向量，然后我们继续生成下一个输出标记，依此类推…… 所以这是我对其工作原理的理解，如果有任何错误，我将不胜感激任何评论和更正（即使只是一个小细节或命名约定，任何事情对我来说都意义重大）。我希望有人能回答我。 谢谢！    提交人    /u/Ok-Reputation5282   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqn4cv/is_this_how_gpt_handles_the_prompt_please_i_have/</guid>
      <pubDate>Wed, 13 Nov 2024 20:47:15 GMT</pubDate>
    </item>
    <item>
      <title>对自己在人工智能和数据科学领域的发展道路感到困惑——NLP/LLM 的研究经验真的足以获得机器学习工程实习机会吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gqcfaw/confused_about_my_path_in_ai_data_scienceis/</link>
      <description><![CDATA[我最近看到一位名为The Data Janitor的 YouTuber 谈论 AI 和 ML 的职业道路，这让我对自己的方法产生了怀疑。他提到，ML 工程职位主要针对具有扎实数据背景的人，比如数据工程师和数据科学家。他甚至给出了这个等式：数据 + 建模 = ML 模型。 现在，这让我怀疑只专注于建模是否足够。我目前正在攻读 AI 和数据科学学位课程，我的目标是最终在 AI/ML 领域工作。但问题是：我不确定攀登典型的“数据”层级（比如从数据分析师做起）是否适合我。在我的国家，实际上没有入门级数据分析师的工作，远程工作看起来也没有什么前景，因为市场上充斥着愿意以低工资工作的人们。 现在，我正准备成为我所在大学教授的研究助理。我们的大部分工作将涉及 NLP/LLM 项目，例如针对特定应用微调现有模型，例如识别阿拉伯语手写，我们将在研究论文中发表这些发现。我的问题是：这种研究经验是否会增加我获得非学术职位的机会，尤其是实习机会？ 我的目标是在大一找到实习机会。我一直在研究机器学习入门级实习的要求，其中一些要求似乎太简单了。他们列出了“Python 基础知识”、“了解 ANN 架构”和“对 TensorFlow 有一定的了解”等内容，就足够了。这是真的吗？ 很想得到一些建议，关于以研究为重点的 LLM 和 NLP 经验是否能从长远来看帮助我，或者我是否最好转向不同的方法。提前感谢任何想法！    提交人    /u/R0b0_69   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gqcfaw/confused_about_my_path_in_ai_data_scienceis/</guid>
      <pubDate>Wed, 13 Nov 2024 13:05:36 GMT</pubDate>
    </item>
    <item>
      <title>𝐁𝐮𝐢𝐥𝐝 𝐋𝐋𝐌𝐬 𝐟𝐫𝐨𝐦 𝐬𝐜𝐫𝐚𝐭𝐜𝐡</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1gq6jsr/𝐁𝐮𝐢𝐥𝐝_𝐋𝐋𝐌𝐬_𝐟𝐫𝐨𝐦_𝐬𝐜𝐫𝐚𝐭𝐜𝐡/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1gq6jsr/𝐁𝐮𝐢𝐥𝐝_𝐋𝐋𝐌𝐬_𝐟𝐫𝐨𝐦_𝐬𝐜𝐫𝐚𝐭𝐜𝐡/</guid>
      <pubDate>Wed, 13 Nov 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>