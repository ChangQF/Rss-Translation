<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 10 May 2024 01:00:35 GMT</lastBuildDate>
    <item>
      <title>使用 PyTorch 的混合网络简介</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/</link>
      <description><![CDATA[使用 PyTorch 的混合网络简介 https://debuggercafe.com/introduction-to-hybridnets-using-pytorch/   由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cocpjb/introduction_to_hybridnets_using_pytorch/</guid>
      <pubDate>Fri, 10 May 2024 00:37:36 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士/自然语言处理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/</link>
      <description><![CDATA[大家好，  我正在尝试为我的工作学习 nlp/llm 技术。我在不同的领域（物理学），想学习使用 NLP/LLM 模型来实现这些目标。我不太清楚如何去学习这些。当我查阅传统的 NLP 课程时，大多数都是处理词袋、vec2vec 等。但是 Transformer 的引入是否让这些传统方法变得过时了呢？我该如何学习这些？谁能为我提供学习此内容所需遵循的路径指南？归根结底，我想构建一个类似 BERT 的模型来用于预测。如果问题听起来含糊不清，我深表歉意。    由   提交/u/No-Mud4063  /u/No-Mud4063 reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cochi1/llmnlp/</guid>
      <pubDate>Fri, 10 May 2024 00:26:40 GMT</pubDate>
    </item>
    <item>
      <title>数据科学和机器学习从基础到高级 |免费 Udemy 课程，报名人数有限</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1coaipi/data_science_and_machine_learning_basic_to/</link>
      <description><![CDATA[       由   提交 /u/Ordinary_Craft   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1coaipi/data_science_and_machine_learning_basic_to/</guid>
      <pubDate>Thu, 09 May 2024 22:54:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么文字、音频、视频的生成同时进步很快？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1coa7wz/why_has_text_audio_video_generation_all/</link>
      <description><![CDATA[根据我对这个主题的虚拟理解 文本生成是通过依赖于首先编写的转换器的 LLM 完成的关于“注意”就是您所需要的。  图像是通过扩散模型完成的，这与LLM完全不同。  那么，为什么它们似乎同时呈指数级增长，而几年前这对于普通人来说几乎是不可想象的。还有很多其他的例子，比如蛋白质等。  我应该添加逻辑告诉我有一个组件（我认为是注意力机制？）可以用于一切，所以它占据了整个领域向前 ？  我想这是一个完全不同的问题，但是扩散模型可以用来生成文本吗？我再次假设您会生成错误的输出，但是在粒度级别上，您如何告诉模型您想要输出的格式？  对这篇糟糕的帖子表示歉意，但我认为这对像我这样的很多傻瓜来说是一个障碍，无法更好地理解这些东西。    由   提交/u/bigmad99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1coa7wz/why_has_text_audio_video_generation_all/</guid>
      <pubDate>Thu, 09 May 2024 22:41:15 GMT</pubDate>
    </item>
    <item>
      <title>未毕业指南：柯尔莫哥洛夫-阿诺德网络</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co9xha/didnt_graduate_guide_to_kolmogorovarnold_networks/</link>
      <description><![CDATA[       由   提交 /u/import_torch-nn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co9xha/didnt_graduate_guide_to_kolmogorovarnold_networks/</guid>
      <pubDate>Thu, 09 May 2024 22:28:27 GMT</pubDate>
    </item>
    <item>
      <title>使用大数据集训练大型模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co8v48/training_a_large_model_with_large_dataset/</link>
      <description><![CDATA[我正在用一个非常大的数据集（大约 100M 数据点）进行 Kaggle 竞赛。我已经完成了对少量数据的研究，并创建/缩小了 30 个特征。我计划训练 keras 模型，但我不知道它应该有多大（层数和层大小）。我还想知道应该如何尽快训练这个模型。我有一个旧的 AMD gpu，所以我必须使用 colab 之类的。我需要一些帮助来了解如何选择模型的大小以及如何尽可能快速、尽可能便宜地使用如此多的数据进行训练。   由   提交/u/古生物学家-Over   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co8v48/training_a_large_model_with_large_dataset/</guid>
      <pubDate>Thu, 09 May 2024 21:42:16 GMT</pubDate>
    </item>
    <item>
      <title>JSTOR 被发现缺乏</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</link>
      <description><![CDATA[       由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co8jn0/jstor_got_caught_lacking/</guid>
      <pubDate>Thu, 09 May 2024 21:28:28 GMT</pubDate>
    </item>
    <item>
      <title>网页抓取 AI 代理（带 Python 代码）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co87a1/web_scraping_ai_agent_with_python_code/</link>
      <description><![CDATA[       由   提交/u/dulldata  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co87a1/web_scraping_ai_agent_with_python_code/</guid>
      <pubDate>Thu, 09 May 2024 21:13:50 GMT</pubDate>
    </item>
    <item>
      <title>了解变形金刚中的注意力机制：5 分钟的视觉指南。 🧠</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co37tn/understanding_the_attention_mechanism_in/</link>
      <description><![CDATA[      TL;DR：注意力是“可以学习的” ”，键值存储或字典的“模糊”版本。由于主要针对 NLP 和 LLM 改进了序列建模，Transformers 使用注意力并接管了以前的架构 (RNN)。 什么是注意力以及为什么它接管了法学硕士和机器学习：视觉指南   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co37tn/understanding_the_attention_mechanism_in/</guid>
      <pubDate>Thu, 09 May 2024 17:46:47 GMT</pubDate>
    </item>
    <item>
      <title>分享一篇关于一些初创公司如何在其业务中使用人工智能工具和平台的文章</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co37sy/sharing_an_article_on_how_some_startups_used_ai/</link>
      <description><![CDATA[   /u/sonya-ai   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co37sy/sharing_an_article_on_how_some_startups_used_ai/</guid>
      <pubDate>Thu, 09 May 2024 17:46:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习路线图。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co2qt2/roadmap_for_machine_learning/</link>
      <description><![CDATA[嗨。学习机器学习以及在该领域找到工作或实习的理想路线图是什么？我了解 python，我们有一门机器学习课程，但它只有数学方面的内容（我知道 SVM、回归、朴素贝叶斯、随机森林等概念）。该课程几乎没有这些概念的代码实现。有没有这方面完整的在线课程？请帮忙。   由   提交 /u/sukhoititan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co2qt2/roadmap_for_machine_learning/</guid>
      <pubDate>Thu, 09 May 2024 17:26:07 GMT</pubDate>
    </item>
    <item>
      <title>学习 ML 数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1co2bpw/learning_math_for_ml/</link>
      <description><![CDATA[我在代数 II 和三角学方面有扎实的基础，对于开始学习微积分、线性代数和统计学是否足够？我应该按什么顺序学习？   由   提交/u/Vegetable_Creme_6949   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1co2bpw/learning_math_for_ml/</guid>
      <pubDate>Thu, 09 May 2024 17:07:57 GMT</pubDate>
    </item>
    <item>
      <title>最大的小丑奖颁发给：</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cntx3p/the_biggest_clown_award_goes_to/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/yphase  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cntx3p/the_biggest_clown_award_goes_to/</guid>
      <pubDate>Thu, 09 May 2024 10:26:36 GMT</pubDate>
    </item>
    <item>
      <title>我觉得这需要出现在机器学习教科书的封面上</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cnp4vj/i_feel_like_this_needs_to_be_on_the_cover_of_an/</link>
      <description><![CDATA[       由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cnp4vj/i_feel_like_this_needs_to_be_on_the_cover_of_an/</guid>
      <pubDate>Thu, 09 May 2024 04:57:01 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人对人工智能中所有不同类型的数学感到不知所措吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cn97az/does_anyone_else_get_overwhelmed_by_all_the/</link>
      <description><![CDATA[   如此多的数学分支融合在一起，似乎没有人能真正掌握人工智能。即使是数学家也几乎不可能掌握这门学科。我和一些人交谈过，他们不知道我在说什么。此外，该领域的发展速度非常快 混合线性代数和随机微分方程是魔鬼的工作。   由   提交 /u/blablablabling   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cn97az/does_anyone_else_get_overwhelmed_by_all_the/</guid>
      <pubDate>Wed, 08 May 2024 16:43:51 GMT</pubDate>
    </item>
    </channel>
</rss>