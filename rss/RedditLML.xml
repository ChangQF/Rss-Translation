<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 16 Feb 2024 00:56:55 GMT</lastBuildDate>
    <item>
      <title>PyTorch 可视化实用程序简介</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aruymm/an_introduction_to_pytorch_visualization_utilities/</link>
      <description><![CDATA[      PyTorch 可视化实用程序简介 https://debuggercafe.com/an-introduction-to-pytorch-visualization-utilities/ &amp;# x200b; https://preview .redd.it/780ypmy3duic1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=c81bc8e1ec99821ba28695322c025a9d178ee151   由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/1aruymm/an_introduction_to_pytorch_visualization_utilities/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aruymm/an_introduction_to_pytorch_visualization_utilities/</guid>
      <pubDate>Fri, 16 Feb 2024 00:25:17 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 代码帮助</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arqnj2/help_with_xgboost_code/</link>
      <description><![CDATA[你好，我正在尝试运行一个小型 XGboost 模型来适应超参数，并提前停止和评估集，但不幸的是它似乎与 GridSearchCV 一起爆炸。有人可以帮忙吗？我的代码已通过人工智能进行错误检查，但没有任何帮助。代码如下，谢谢！  # 将数据拆分为训练集和测试集 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) ​ # 定义预处理步骤 scaling = StandardScaler() ​ # 定义 XGBoost具有早期停止和评​​估集的模型 xgb_model = XGBRegressor(n_estimators=5000,learning_rate=0.05, max_depth=7) ​ #指定评估集 eval_set = [(X_test, y_test)] ​ # 通过提前停止来拟合模型 xgb_model.fit(X_train, y_train, eval_metric=“rmse”, eval_set=eval_set, Early_stopping_rounds=10, verbose=True) ​ # 找到最佳参数 print(&quot;最佳参数：&quot;, xgb_model.get_params()) ​ # 最佳交叉验证分数 print(&quot;最佳交叉验证分数 (R^2):&quot;, xgb_model.best_score_) ​   由   提交 /u/ThisIsDrSmith   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arqnj2/help_with_xgboost_code/</guid>
      <pubDate>Thu, 15 Feb 2024 21:24:04 GMT</pubDate>
    </item>
    <item>
      <title>Sora AI 文本转视频生成器示例（合集）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arpz3j/sora_ai_text_to_video_generator_examples/</link>
      <description><![CDATA[       由   提交/u/iamfaijan  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arpz3j/sora_ai_text_to_video_generator_examples/</guid>
      <pubDate>Thu, 15 Feb 2024 20:56:28 GMT</pubDate>
    </item>
    <item>
      <title>MLE 数学博士或 ML 硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arojv5/phd_in_math_or_msc_in_ml_for_mle/</link>
      <description><![CDATA[我目前是数学和计算机科学双专业的大三学生，我的职业目标是成为一名机器学习工程师或从事人工智能工作，所以毕业学校是书本上的，但我在数学博士学位和计算机科学或机器学习/人工智能硕士学位之间左右为难。起初，选择专注于 ML/AI 似乎是显而易见的事情，但我见过并听说过很多拥有数学博士学位的 MLE。我喜欢数学并且非常擅长数学，总体来说我在编程和软件工程方面也很出色，但不如数学好，但是我想追求最适合我成为机器学习工程师的东西。我也有同时攻读研究生的想法。任何建议都会有所帮助，谢谢。   由   提交/u/Ok_Holiday_9926   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arojv5/phd_in_math_or_msc_in_ml_for_mle/</guid>
      <pubDate>Thu, 15 Feb 2024 19:58:51 GMT</pubDate>
    </item>
    <item>
      <title>我应该学习什么云平台？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aro78n/what_cloud_platform_should_i_learn/</link>
      <description><![CDATA[大家好，我要开始学习云了，但是主要有三个选择：Azure、AWS和GCP，我想成为一名机器学习工程师和我想阅读您的建议，了解我应该学习这三个云平台中的哪一个，或者哪个是机器学习工程师最喜欢的或该领域最需要的，谢谢您的回答。    由   提交 /u/Sea_Presence3131   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aro78n/what_cloud_platform_should_i_learn/</guid>
      <pubDate>Thu, 15 Feb 2024 19:44:18 GMT</pubDate>
    </item>
    <item>
      <title>在 Python 中理解和实现线性回归的批量梯度下降</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1aro1ir/understanding_and_implementing_batch_gradient/</link>
      <description><![CDATA[机器学习算法通常涉及优化模型以适应给定的数据。其中一种优化技术是梯度下降，这是一种用于最小化成本函数的基本算法。在本教程中，我们将探索使用 Python 和 NumPy 来解决简单线性回归问题的批量梯度下降的实现。 简介 线性回归是机器学习中的常见方法。对因变量和一个或多个自变量之间的关系进行建模。目标是找到最小化预测值和实际值之间差异的最佳拟合线。梯度下降是一种迭代优化算法，用于最小化成本函数，它衡量预测值和实际值之间的差异。 先决条件 在我们深入实施之前，请确保您已经了解安装以下内容：  Python NumPy  您可以使用以下命令安装 NumPy： 实现 pip install numpy  实现批量梯度下降 让我们从实现批量梯度下降算法开始。打开您最喜欢的 Python 环境并按照说明进行操作。 在此处阅读完整的实现 ​   由   提交 /u/HoomanBasic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1aro1ir/understanding_and_implementing_batch_gradient/</guid>
      <pubDate>Thu, 15 Feb 2024 19:37:50 GMT</pubDate>
    </item>
    <item>
      <title>AI Startup 的 NLP 暑期研究或 ML 工程师暑期实习生</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arnwoy/nlp_summer_research_or_ml_engineer_summer_intern/</link>
      <description><![CDATA[我是一名计算机科学专业大四学生，明年将攻读计算机科学硕士学位，主修机器学习。我的最终目标是成为一名机器学习工程师。今年夏天，我有机会在一家小型人工智能初创公司担任机器学习工程师实习生。今年夏天我也可能有机会和一位教授一起进行 NLP 研究。我以前从未做过研究。这里有正确答案吗？什么对开启机器学习职业生涯更有帮助？先感谢您。非常感谢任何建议。 查看民意调查   由   提交 /u/Material_Yam_598   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arnwoy/nlp_summer_research_or_ml_engineer_summer_intern/</guid>
      <pubDate>Thu, 15 Feb 2024 19:32:23 GMT</pubDate>
    </item>
    <item>
      <title>在 git 日志上训练 LLM ??</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arnr51/training_llm_on_git_logs/</link>
      <description><![CDATA[大家好， 我在阅读《通过游戏数据的词嵌入揭示游戏动态》时想到了一个想法由 Rabii 和 Cook（2021）撰写，他们使用游戏数据的词嵌入来探索游戏动态。这让我开始思考将类似的机器学习 (ML) 技术应用于不同类型的数据的潜力：Git 日志。 Git 日志是结构化数据的宝库，通过以下方式记录软件开发的历史：提交消息、时间戳、作者身份和代码更改。我突然意识到，对编码助理来说，对此类数据进行 LLM 培训是疯狂的。 但我没有找到任何提到这一点的内容。 有什么想法吗？   由   提交 /u/Elegant-Catch-9648   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arnr51/training_llm_on_git_logs/</guid>
      <pubDate>Thu, 15 Feb 2024 19:26:02 GMT</pubDate>
    </item>
    <item>
      <title>引领未来：了解人工智能法案对产品公司的要求</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1armyvl/navigating_the_future_understanding_the_ai_act/</link>
      <description><![CDATA[这个博客文章是关于《人工智能法案》要求的，专门为基于产品的企业设计。它介绍了应对人工智能监管环境的基本背景、可能的障碍和战略建议，帮助 OpenCV.ai 读者做好适应这些发展的准备。 在本文中，您将发现：   什么是《人工智能法案》？   主要目标  人工智能法案禁止什么？   行业影响 挑战 机遇  实现新的人工智能监管合规性  合规性步骤 最佳实践   完整文章ia 此处   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/learnmachinelearning/comments/1armyvl/navigating_the_future_understanding_the_ai_act/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1armyvl/navigating_the_future_understanding_the_ai_act/</guid>
      <pubDate>Thu, 15 Feb 2024 18:53:15 GMT</pubDate>
    </item>
    <item>
      <title>如何充分利用吴恩达的课程？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1armq8d/how_to_get_the_most_out_of_andrew_ngs_course/</link>
      <description><![CDATA[大家好， 我正在考虑学习 2 到 3 个月的 Coursera，并学习 Andrew Ng 的 ML 课程（不是DL 专业）。由于这很昂贵，而且我已经有一段时间在强制遵守纪律的教室里上课了，所以想在这里询问如何充分利用这门课程。有几个问题： ​  很多人说他们推荐这门课程高于其他任何课程，到底为什么呢？大多数人都是人云亦云地为了证明价格的合理性，是他的教学风格，还是实际内容，他教给你什么是其他课程没有教给你的？ 只是为了确定，这是一个吗？ ？ https://www.coursera.org/specializations/machine-learning-introduction ..或其他一，因为这里提到了另外 3 名老师。 假设我每周可以投入 6-10 个小时，主要是周末，这需要多长时间？ 您使用什么学习？笔和纸、数字笔记本、Python 笔记本、Colab，你做笔记、绘制图表吗？ 机器学习与数学、代数、统计等基础知识之间的平衡是什么？  li&gt; 您是仅通过本课程学习基本要点，还是除了本课程之外还结合其他课程、书籍等学习？ 随课程阅读的书籍推荐？ &lt; li&gt;那些即将完成或已经完成的人，你觉得你理解并且能够自己做简单的ML吗？更重要的是，当您开始编码时，您知道您需要什么以及它是如何工作的吗？ 您对此有任何其他想法，请随时分享。可能是随机的，也可能是罕见的，但我倾向于在别人认为无意义的事情中找到有价值的金块。  一点背景知识，我从 Google ML 速成课程开始，非常喜欢其中的视频他们用白板上的图画进行解释，但第一个最好的代码部分在我的 Colab 中被破坏了。不知道这意味着什么，也不知道如何解决它，所以我可以继续观看视频和阅读文字，但可能无法进行实际练习。 我还从头到尾开始使用 Udemy ML，但正如老师所说，“...我想为你制作一个非常实用的模板，供你在未来的项目中使用”。 公平地说，我是 Python 新手同样，如果我了解 Python，他们使用的代码可能是小菜一碟，但我仍然觉得我缺少有关为什么使用该特定函数及其工作原理的信息。 好吧，谢谢您的到来听我的 Ted 演讲：D 谢谢。   由   提交 /u/SquidsAndMartians   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1armq8d/how_to_get_the_most_out_of_andrew_ngs_course/</guid>
      <pubDate>Thu, 15 Feb 2024 18:43:14 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类器 oob 错误</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1armkqk/random_forest_classifier_oob_error/</link>
      <description><![CDATA[      谁能帮我解释一下这个情节吗？这是什么意思？ ​ https://preview.redd.it/u6stxmn2nsic1.png?width=602&amp;format=png&amp;auto=webp&amp;s=253287f6a7c70e240bd82d7d188d0 ecb754b0989    由   提交 /u/tinkerpal   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1armkqk/random_forest_classifier_oob_error/</guid>
      <pubDate>Thu, 15 Feb 2024 18:36:49 GMT</pubDate>
    </item>
    <item>
      <title>低延迟对话式AI模型</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ari1ud/lowlatency_conversational_ai_model/</link>
      <description><![CDATA[大家好， 对菜鸟问题表示歉意，我是这个主题的新手。 我想创建产生对话（语音）的人工智能模型。它很可能会围绕一个特定主题。我需要的是这个模型非常快，我们谈论毫秒，我想要非常小的延迟。这可以实现吗？ 如果是的话，那么我想我需要从零开始，或者采用一些大型模型并在此基础上训练新模型，这样我就可以只保留我需要保留的较小尺寸并保持快速？另外一个重要的问题是，由一个人完成是否现实？ 我是一名工程师，但我的领域是后端、云和网络..所以这不完全是我的专业领域。 &gt; 大约需要多少钱（仅用于培训） 谢谢！   由   提交 /u/Dubinko   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ari1ud/lowlatency_conversational_ai_model/</guid>
      <pubDate>Thu, 15 Feb 2024 15:30:38 GMT</pubDate>
    </item>
    <item>
      <title>Jeremy Howard -answer.ai，筹集 1000 万美元，他们如何招聘，为什么学术界的激励措施混乱</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1argi7n/jeremy_howard_answerai_raising_10m_how_they_hire/</link>
      <description><![CDATA[       由   提交/u/gordicaleksa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1argi7n/jeremy_howard_answerai_raising_10m_how_they_hire/</guid>
      <pubDate>Thu, 15 Feb 2024 14:21:35 GMT</pubDate>
    </item>
    <item>
      <title>Savant 0.2.7 已发布：针对 NVIDIA 优化的计算机视觉框架</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1arge63/savant_027_is_out_computer_vision_framework/</link>
      <description><![CDATA[Savant 是一个先进的计算机视觉框架基于 NVIDIA DeepStream 和 TensorRT - NVIDIA 硬件上数据中心和边缘计算机视觉的一流技术。 在 0.2.7 中，Savant 收到了 4 个新演示，其中包括 26 个演示，涵盖检测、分类、分割、关键点、对象跟踪和 GAN。 0.2.7 中的新演示是：  RT-DETR 使用示例； 基于 CuPy 的 YOLOV8-Seg GPU 内后处理； 在 Savant 管道中提供 PyTorch CUDA 推理服务； 定向边界框检测和跟踪。  &lt; p&gt;0.2.7 中的新功能：  Grafana/Prometheus 集成。除了 OpenTelemetry 跟踪之外，您还可以使用 Grafana 和 Prometheus 来调查管道的运行方式。开发人员还可以导出他们的自定义指标。 缓冲区适配器。一种特殊的中间适配器，可以承受流量激增和管道减速的情况。它实现了一种机制，允许通过慢速管道元素延迟视频处理。该适配器具有 Prometheus/Grafana 集成，因此您始终知道有多少元素等待处理。它基于RocksDB。 仅编译模式。当管道首次启动时，它会在 TensorRT 引擎中编译模型。这很容易需要几分钟的时间。以前，开发人员无法将编译和评估分开。现在他们可以了。 关闭 PyFunc 中的处理程序。这个新的 API 允许正确处理管道关闭操作，以释放资源并通知第 3 方系统有关终止的信息。 入口和出口的消息过滤。这项高级功能允许开发人员通过简单的回调修改原始编码流及其元数据。例如，您可以仅选择关键帧进行处理，并丢弃其余帧或删除未检测到对象的视频片段。 在 GPU 上进行模型后处理。借助一项新功能，开发人员可以可以指示框架直接从 GPU 内存访问模型输出张量，而无需将其下载到 CPU 内存。 GPU 内存表示函数。在该版本中，我们提供了 OpenCV GpuMat、PyTorch GPU 张量和 CuPy 张量之间转换内存缓冲区的函数。 高级对象属性修改操作。在该版本中，我们实现了一组新操作，使开发人员能够以更方便的方式修改对象属性。 PyFunc 的队列利用 API。 Savant 允许在 PyFunc 之间添加队列以实现并行处理和流量突发管理。在该版本中，我们实现了一个新的 API，允许开发人员访问部署在管道中的队列以请求其使用。  完整版本 注释。 别忘了加入我们的Discord，我们为用户提供帮助。要了解有关 Savant 的更多信息，请阅读我们的文章：在计算机视觉项目中考虑 Savant 的十大理由。   由   提交 /u/ivan_kudryavtsev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1arge63/savant_027_is_out_computer_vision_framework/</guid>
      <pubDate>Thu, 15 Feb 2024 14:16:23 GMT</pubDate>
    </item>
    <item>
      <title>微调模型时遇到哪些问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ar9j3x/what_are_some_of_the_problems_faced_while/</link>
      <description><![CDATA[最近在微调稳定的扩散模型时，我缺乏针对我的用例微调模型所需的具体数据，也缺乏计算资源，而且我没有太多预算，我不断切换 google colab 帐户以使用免费 GPU。  我想知道人们在微调模型时通常会遇到哪些其他问题。   由   提交/u/Medium_Alternative50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ar9j3x/what_are_some_of_the_problems_faced_while/</guid>
      <pubDate>Thu, 15 Feb 2024 06:55:12 GMT</pubDate>
    </item>
    </channel>
</rss>