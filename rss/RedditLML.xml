<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Thu, 02 May 2024 06:18:58 GMT</lastBuildDate>
    <item>
      <title>2024 年你必须知道的学习计算机视觉的最佳资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci8dl9/best_resources_to_learn_computer_vision_you_must/</link>
      <description><![CDATA[       由   提交/u/Aqsa81  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci8dl9/best_resources_to_learn_computer_vision_you_must/</guid>
      <pubDate>Thu, 02 May 2024 06:05:17 GMT</pubDate>
    </item>
    <item>
      <title>我是法学硕士的新手，对此有疑问</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci7s40/i_am_new_to_using_llms_and_had_a_question_on_it/</link>
      <description><![CDATA[嘿，我有一个简单的问题 - 我正在尝试使用 google 的 palm api 来分析大量文本文件，但我一直超出其限制。 有没有更好的方法可以处理信息，因为我需要浏览整个文本文件    提交人    /u/EnvironmentBasic6030   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci7s40/i_am_new_to_using_llms_and_had_a_question_on_it/</guid>
      <pubDate>Thu, 02 May 2024 05:28:40 GMT</pubDate>
    </item>
    <item>
      <title>如何撰写研究论文并发表？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci7d8t/how_does_one_write_a_research_paper_and_publish_it/</link>
      <description><![CDATA[ 由   提交 /u/Constant-Sandwich904    reddit.com/r/learnmachinelearning/comments/1ci7d8t/how_does_one_write_a_research_paper_and_publish_it/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci7d8t/how_does_one_write_a_research_paper_and_publish_it/</guid>
      <pubDate>Thu, 02 May 2024 05:03:30 GMT</pubDate>
    </item>
    <item>
      <title>Llama 3 正在产生随机输出</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci7apx/llama_3_is_producing_random_outputs/</link>
      <description><![CDATA[您好， 我正在开发一个项目，该项目将使用法学硕士生成电子邮件营销活动。我认为最近发布的 Llama 3 开源 LLM 将对此很有用（因为该模型在评估基准中与 GPT-4 相当）。我决定使用 together.ai 网站上托管的 Llama 3 模型。令我惊讶的是，该模型的行为太奇怪了。以下是我注意到该模型的一些问题：  该模型不遵守提示中提供的说明。例如即使明确说明只生成特定文本的一个示例，它也会生成多个示例。 它在简单的摘要任务/文本生成任务上惨败。很多时候，它会生成部分提示作为输出。大多数时候，输出根本无法使用。  我遵循类似于GPT模型的提示风格。我有什么遗漏的吗？是否有任何提示 Llama 模型的指南？ Llama 3 模型适合此类任务吗？ 非常感谢任何有关此问题的帮助！！   由   提交 /u/peaceful_creature   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci7apx/llama_3_is_producing_random_outputs/</guid>
      <pubDate>Thu, 02 May 2024 04:59:56 GMT</pubDate>
    </item>
    <item>
      <title>免费的 Google Gemini API 密钥</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci6wlo/google_gemini_api_key_for_free/</link>
      <description><![CDATA[ 由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci6wlo/google_gemini_api_key_for_free/</guid>
      <pubDate>Thu, 02 May 2024 04:37:26 GMT</pubDate>
    </item>
    <item>
      <title>机器学习大数据问题！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci5ty9/ml_big_datproblem/</link>
      <description><![CDATA[我参加了一个数据科学家职位的测试，我必须预测一家大公司的库存需求，我认为自己非常擅长编程，从数学上讲，我对概念的理解非常好，甚至可以创建自己的改进模型来适应每种情况，但是我在测试中遇到了一个大问题，有超过 1 亿条记录，而我不知道如何使用它，它简直让人不知所措，我甚至没有使用 Pandas 库，我只使用了 Numpy 来加速处理，但我的 PC 不够用，无论是由于 RAM 还是处理器，我来这里寻求最有经验的人的建议，如何在不诉诸虚拟机或云服务的情况下管理这个问题？你知道这方面的例子吗？我应该关注什么？    提交人    /u/Chrissaker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci5ty9/ml_big_datproblem/</guid>
      <pubDate>Thu, 02 May 2024 03:37:10 GMT</pubDate>
    </item>
    <item>
      <title>有什么办法可以用手机摄像头来区分肤色吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci5tj5/any_way_to_classify_skin_type_with_phone_camera/</link>
      <description><![CDATA[我读到过，如果我们拍摄热图像，我们可以对皮肤类型进行分类，并且根据热量我们可以识别皮肤类型。 但是我们的手机摄像头无法拍摄热图像，所以我想知道是否有其他方法可以比这更有效 不要求准确率超过 90%，即使准确率超过 70% 也可以 如何处理这个问题？    提交人    /u/ifeelanime   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci5tj5/any_way_to_classify_skin_type_with_phone_camera/</guid>
      <pubDate>Thu, 02 May 2024 03:36:35 GMT</pubDate>
    </item>
    <item>
      <title>如何快速复制 Colab 笔记本中的所有代码单元？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci5goo/how_can_i_quickly_copy_all_the_code_cells_from_a/</link>
      <description><![CDATA[我经常将整个代码复制并粘贴到 ChatGPT 中，但我必须逐个单元格手动执行此操作。有什么办法可以复制整个内容吗？我读到我可以选择多个单元格并复制它们，但它不会将它们复制为我可以粘贴的文本   由   提交/u/zuccoff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci5goo/how_can_i_quickly_copy_all_the_code_cells_from_a/</guid>
      <pubDate>Thu, 02 May 2024 03:17:37 GMT</pubDate>
    </item>
    <item>
      <title>机器翻译任务中出现错误：形状“[12672]”对于大小 12800 的输入无效</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci56b5/getting_error_in_machine_translation_task_shape/</link>
      <description><![CDATA[我正在使用带有 Bahdanau 注意力机制的 seq2seq 训练机器翻译模型。当我运行训练循环时，我收到此错误消息：形状 &#39;[12672]&#39; 对于大小为 12800 的输入无效。在出现此错误之前，我遇到了许多与形状相关的错误。因此，我开始注释掉所需的形状，最后，我得到了所有所需的形状，但仍然收到此错误。当我计算 trg 的形状时，我得到了这个形状：12672。所以，这个形状是正确的，但仍然收到错误。 这是代码：https://www.kaggle.com/code/apibrains/machine-translation   由    /u/CodingWithSatyam  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci56b5/getting_error_in_machine_translation_task_shape/</guid>
      <pubDate>Thu, 02 May 2024 03:02:14 GMT</pubDate>
    </item>
    <item>
      <title>如何根据各种指标比较不同的对象检测模型（如果我以不同的方式训练它们）？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci3g09/how_do_i_compare_different_object_detection/</link>
      <description><![CDATA[抱歉这个菜鸟问题 但我已经使用相同的数据集训练了 YOLOv5 模型和 Faster R-CNN。然而，对于 YOLOv5，我使用 Ultralytics，而对于 Faster R-CNN，我使用 Detectron2。我不知道如何正确比较两者。  我选择了骨干网络，其中我将 YOLOv5s 用于没有预训练权重的 YOLOv5 模型，并在 Faster R-CNN 上使用 Resnet 50 FPN3x 作为骨干网和预训练权重。我为两者设置了各种超参数。  我注意到在 YOLOv5 训练中它有纪元，而在 Faster R-CNN 中它使用迭代。两者用于训练的代码不同。此外，他们在训练时显示不同的指标。  我的问题是，既然我有了最终模型（YOLO 为 .pt，FR-CNN 为 .pth），我如何公平或平等地评估两者？我想根据精度、召回率、MAP、推理、IOU 等指标进行评估。我很困惑，因为我已经有了模型文件，但不知道如何处理它们。我不确定要使用什么包或模块以及如何进行评估，因为它们是在不同的环境中使用不同的超参数进行训练的。    由   提交/u/Upset_Business_4591   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci3g09/how_do_i_compare_different_object_detection/</guid>
      <pubDate>Thu, 02 May 2024 01:35:34 GMT</pubDate>
    </item>
    <item>
      <title>选择正确的硕士学位地点</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ci29ef/choosing_the_right_place_for_a_masters_degree/</link>
      <description><![CDATA[我是一名来自哥伦比亚的数学家，寻求出国攻读硕士学位，特别是数据科学或人工智能领域的硕士学位。然而，我热衷于寻找在整个课程中强调数学的课程。您能否就提供针对此重点的奖学金的大学提供建议或指导？谢谢！   由   提交/u/Amazing-Floor801  /u/Amazing-Floor801 reddit.com/r/learnmachinelearning/comments/1ci29ef/choosing_the_right_place_for_a_masters_ Degree/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ci29ef/choosing_the_right_place_for_a_masters_degree/</guid>
      <pubDate>Thu, 02 May 2024 00:38:54 GMT</pubDate>
    </item>
    <item>
      <title>有人学完抱脸课程吗？如果是，您对此有何看法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1chy54x/has_anyone_finished_any_courses_from_hugging_face/</link>
      <description><![CDATA[我正在从抱脸开始NLP课程，只是想知道你对课程的看法。有小费吗 ？如果您还有其他资源，欢迎分享。谢谢！   由   提交 /u/AcanthisittaWarm2927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1chy54x/has_anyone_finished_any_courses_from_hugging_face/</guid>
      <pubDate>Wed, 01 May 2024 21:41:57 GMT</pubDate>
    </item>
    <item>
      <title>最好的开源本地托管 OCR 模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1chu4lq/best_open_sourced_locally_hosted_ocr_model/</link>
      <description><![CDATA[大家好，这个问题以前以稍微不同的形式提出过，但由于这个领域的情况变化非常快，我认为这是值得问的再次。 我正在寻找一个开源光学字符识别 (OCR) 模型，我可以在自己的服务器上本地托管该模型。我熟悉流行的 OCR（tesseract、Paddle、EasyOCR），但说实话，我对它们的工作方式感到非常失望。当文件只是清晰键入的 PDF 时，它们是准确的，但对于任何具有模糊文本或手写内容的图像，它们对于我的用例而言表现太差。我已经演示了 microsoft Azure 和 Google Visions OCR，它们运行得非常好，所以我知道这些模型的 SOTA 是什么样的，但出于安全目的，我仅限于本地托管的模型。我无法将我的任何数据发送给第三方。我知道可以在本地部署 Microsoft 和 Google 的 OCR，但我现在想避免这种情况，因为我的基础设施位于 AWS 上。我也知道 AWS 有自己的 OCR 工具，但它非常糟糕。 有人成功构建了自己的模型吗？ OCR 是 AI/ML 的基本组成部分，因此我对缺乏可靠的开源模型感到惊讶。我觉得我错过了一些东西。 感谢所有建议，谢谢！   由   提交 /u/mickeypiekarski   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1chu4lq/best_open_sourced_locally_hosted_ocr_model/</guid>
      <pubDate>Wed, 01 May 2024 18:57:42 GMT</pubDate>
    </item>
    <item>
      <title>探索 LLM 模型中的模型漂移（随着时间的推移，ChatGPT 实际上会变得更愚蠢吗？）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1chsmze/exploring_model_drift_in_llm_models_does_chatgpt/</link>
      <description><![CDATA[模型漂移是一个自预测 AI 模型诞生以来就一直困扰其的问题。当前形式的法学硕士模型是人工智能家族的一个非常新的成员（当前形式是数十亿甚至数万亿参数的庞然大物）。  模型漂移发生在参数较小的模型中。在较大的参数模型中，它或多或少可能发生？经常出现的很多关于“X 模型现在与发布时相比很糟糕”的言论实际上有其优点吗？如果这一切都是编造出来的，那为什么还会发生这样的事呢？  对我来说，这总体上是一个有趣的现象。它提出了很多有趣的问题，而法学硕士模型似乎也不能幸免。我认为有很多企业都在忽视这个问题并假装它不可能存在，这就是为什么我认为这个问题没有得到更多讨论。  我在此视频中更深入地探讨了这个主题：https://youtu.be/q7to83yK2nk    由   提交/u/Certain_End_5192   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1chsmze/exploring_model_drift_in_llm_models_does_chatgpt/</guid>
      <pubDate>Wed, 01 May 2024 17:59:01 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性背后的完整故事</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1chiiw6/the_full_story_behind_multicollinearity/</link>
      <description><![CDATA[      有一段时间，我对我读到的大多数有关多重共线性的书籍（或询问法学硕士）给出的一般答案不满意：多重共线性导致模型对参数做出不准确的估计。有一段时间，这是我大脑中的一个错误，我最终决定坐下来深入探讨当存在多重共线性时*实际*会发生什么。 https://preview.redd.it/3n7qkzm7isxc1.png?width=1351&amp;format=png &amp; auto=webp&amp;s=f98323f9cee484dea7b068cdbdf70a192643c3e4 https://preview.redd.it/c7rvick7isxc1.png?width=1351&amp;format=png&amp;auto=webp&amp;s=4188ae35a2886355f2a53713d3ef8eae4197dcd5  https://preview.redd.it/cvfblck7isxc1.png?width=1351&amp;format= png&amp;auto=webp&amp;s=e16568f73776955ca322684adc59c0608b80de1a https://preview.redd.it/q5zo37k7isxc1.png?width=1351&amp;format=png&amp;auto=webp&amp;s=7e71ad5754dba048d474bb714fb669169 96f7611 注意！我写的可能不是100%正确，我已经仔细检查过，但这只是我和互联网作为我的帮助，所以如果你发现一些不准确或不完整的地方，请告诉我。   由   提交 /u/Bobsthejob   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1chiiw6/the_full_story_behind_multicollinearity/</guid>
      <pubDate>Wed, 01 May 2024 10:12:39 GMT</pubDate>
    </item>
    </channel>
</rss>