<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到 r/learnmachinelearning - 一个由对机器学习充满热情的学习者和教育者组成的社区！在这里您可以提出问题、分享资源，并共同了解机器学习概念 - 从基本原理到高级技术。无论您是编写第一个神经网络还是深入研究 transformer，您都可以在这里找到支持您的同伴。对于机器学习研究，/r/machinelearning 对于简历审查，/r/engineeringresumes 对于机器学习工程师，/r/mlengineering</description>
    <lastBuildDate>Tue, 28 Jan 2025 01:13:34 GMT</lastBuildDate>
    <item>
      <title>为什么 [RAVDESS 情感语音音频] 数据集在 Kaggle 上的文件编号与原始源不同？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibp2i5/why_are_the_file_numbers_in_the_ravdess_emotional/</link>
      <description><![CDATA[同志们，有人能告诉我为什么 当我在 colalab 笔记本上更新时，[RAVDESS 情感语音音频] 数据集中的文件数量会有所不同吗？  首先……  原始 DS 每个类别有 192 个文件，但 Kaggel 上的文件数量为 384 个，除了两个类别（中性和平静）大约有 2544 个文件。 有人知道为什么会发生这种情况吗？这可能是由于上传者的修改造成的，还是有造成这种差异的特定原因？    提交人    /u/lama_777a   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibp2i5/why_are_the_file_numbers_in_the_ravdess_emotional/</guid>
      <pubDate>Tue, 28 Jan 2025 00:40:02 GMT</pubDate>
    </item>
    <item>
      <title>在 NumPy 上实现 GPT1</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibozfm/implement_gpt1_on_numpy/</link>
      <description><![CDATA[这是我关于在 Numpy 上实现 GPT1 的博客文章： https://mburaksayici.com/blog/2025/01/27/GPT1-Implemented-NumPy-only.html 我很高兴收到批评/反馈。    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibozfm/implement_gpt1_on_numpy/</guid>
      <pubDate>Tue, 28 Jan 2025 00:36:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么语言模型不是随时间不变的？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibnz6a/why_exactly_are_language_models_not_time_invarient/</link>
      <description><![CDATA[假设 x[n] 表示训练数据中所有标记的离散信号 现在，本质上每个语言模型所做的就是将这个信号向右侧移动一步，对吗？因此，如果语言模型是函数 T，则它将接受整个 x[n] 并输出 x[n+1]，因此 T(x[n]) = x[n+] 但是从时间不变性系统的定义来看，即，如果 T(x[n])= y[n]，则 T(x[n+a])= y[n+a] 这里 y[n]=x[n+1]，因此 T(x[n+a])=x[n+a+1]=y[n+a]，因此 T 满足时间不变性的定义 我这里遗漏了什么？    提交人    /u/tensorsgo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibnz6a/why_exactly_are_language_models_not_time_invarient/</guid>
      <pubDate>Mon, 27 Jan 2025 23:49:41 GMT</pubDate>
    </item>
    <item>
      <title>图解 DeepSeek-R1</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibnw39/the_illustrated_deepseekr1/</link>
      <description><![CDATA[        提交人    /u/jayalammar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibnw39/the_illustrated_deepseekr1/</guid>
      <pubDate>Mon, 27 Jan 2025 23:45:36 GMT</pubDate>
    </item>
    <item>
      <title>受到 Andrej Karpathy 的 Micrograd 启发</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibkw5u/inspired_by_andrej_karpathys_micrograd/</link>
      <description><![CDATA[受到 Andrej Karpathy 的 Micrograd 的启发，为了练习我在学校学习的 C 语言，我建立了一个迷你库，用 C 语言重现了一些 PyTorch 功能并用它实现了一个神经网络。 https://github.com/karam-koujan/mini-pytorch    提交人    /u/kaku53   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibkw5u/inspired_by_andrej_karpathys_micrograd/</guid>
      <pubDate>Mon, 27 Jan 2025 21:38:45 GMT</pubDate>
    </item>
    <item>
      <title>有抱负的人工智能工程师寻求深度学习和法学硕士黑客马拉松和活动</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibhpjl/aspiring_ai_engineer_seeking_hackathons_and/</link>
      <description><![CDATA[大家好！ 我是一名有抱负的人工智能工程师，对深度学习 (DL) 和大型语言模型 (LLM) 有着浓厚的兴趣。目前，我正在开发 DL 模型来对阿尔茨海默病的阶段进行分类，我也在致力于构建股票市场预测器。我的主要工具是 Python 和 PyTorch。 我想加深我在这些领域的理论知识和实践技能。您是否知道我应该关注哪些黑客马拉松、活动或网站，以便及时了解最新情况并积极参与社区活动？如果您能分享一些建议或链接，我将不胜感激！ 提前感谢您的帮助！ 您希望我列出一些特定的资源或网站供您参考吗？    提交人    /u/Arjeinn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibhpjl/aspiring_ai_engineer_seeking_hackathons_and/</guid>
      <pubDate>Mon, 27 Jan 2025 19:29:11 GMT</pubDate>
    </item>
    <item>
      <title>如何学习训练模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibec2q/how_to_learn_to_train_models/</link>
      <description><![CDATA[我遇到了一个有趣的问题：我了解深度学习理论，知道优化器的工作原理等等，但在实践中，我无法成功训练模型。 我尝试过训练 VGG16、ResNet 和 SSD，但每次模型都会达到一定的错误水平，并且永远不会再改善（错误率一直很高）。 我的问题是：如何有效地训练 AI 模型？如何选择具有适当超参数的正确优化器？更重要的是，应该做些什么才能真正减少错误？ 如何正确训练模型，应该采取哪些步骤才能获得更好的结果？    提交人    /u/Away_Material5725   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibec2q/how_to_learn_to_train_models/</guid>
      <pubDate>Mon, 27 Jan 2025 17:15:14 GMT</pubDate>
    </item>
    <item>
      <title>llms 如何知道何时停止输出新标记？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibe27u/how_do_llms_know_when_to_stop_outputting_new/</link>
      <description><![CDATA[我记得早期的模型，我想是 GPT-3，有时会疯狂输出，生成新的标记，直到达到极限。 我知道我可以使用 max_tokens 参数限制输出的总长度，但大多数情况下，LLM 响应似乎自然结束。 据我所知，对话模型是在大量对话数据上训练的。他们怎么知道每次互动都应该只包含一个 Assistant 回应？为什么不继续对话，生成（预测）“用户输入”和 LLMS 输出？ 我也知道有特殊的“序列结束”标记，但我不明白为什么它们会让模型停止。它是硬编码到模型中吗？就像如果 output.endsWith(&lt;|EOS|&gt;&quot;) 然后 break else go on？ 现在有了&quot;推理&quot;模型。他们怎么知道什么时候停止，当他们应该生成更多的代币时，理论上&quot;思考&quot; 几个小时甚至几天，然后退出？ 现代模型怎么知道何时停止？    提交人    /u/demureboy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibe27u/how_do_llms_know_when_to_stop_outputting_new/</guid>
      <pubDate>Mon, 27 Jan 2025 17:04:18 GMT</pubDate>
    </item>
    <item>
      <title>了解更多有关（实用）法学硕士 (LLM) 的优质资源</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibdqf2/good_resources_for_learning_more_about_practical/</link>
      <description><![CDATA[我是一名软件工程师，对 LLM 有基本的（最低限度的）了解。但是我想提高我的技能，例如，我想知道： - 具有 x 参数的模型 X 需要多少 RAM - 我注意到，当我提示 deepSeek 时，它首先开始输出它的思考过程，为什么以及它是如何工作的？ 您如何在 ML 和 LLM 中获得更多理论和实践经验？我很感激对您有帮助的资源。 目前，我正在使用 Ollama 和 LM studio，我更喜欢 LM studio，因为它也有使用 MLX 的 LLM。    提交人    /u/BukHunt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibdqf2/good_resources_for_learning_more_about_practical/</guid>
      <pubDate>Mon, 27 Jan 2025 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能 (AI) 和机器学习 (ML) 有什么区别？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibct8h/what_is_the_difference_between_ai_and_ml/</link>
      <description><![CDATA[  由    /u/Careful_Fig8482  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibct8h/what_is_the_difference_between_ai_and_ml/</guid>
      <pubDate>Mon, 27 Jan 2025 16:14:05 GMT</pubDate>
    </item>
    <item>
      <title>脑电图上的 STFT 输出</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ibag5b/output_of_stft_on_eeg/</link>
      <description><![CDATA[      在对癫痫发作患者的 EEG 文件应用 Bandpass+STFT 进行预处理后，我得到了此输出。我很困惑它是否正确。有人可以帮忙吗？    提交人    /u/Plane_Reputation5646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ibag5b/output_of_stft_on_eeg/</guid>
      <pubDate>Mon, 27 Jan 2025 14:34:10 GMT</pubDate>
    </item>
    <item>
      <title>用通俗易懂的语言理解机器学习的线性代数</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ib4w4a/understanding_linear_algebra_for_ml_in_plain/</link>
      <description><![CDATA[      向量在机器学习中无处不在，但一开始可能会让人感到害怕。我创建了这个简单的分类来解释： 1. 什么是向量？ （指向空间的箭头！） 想象一下你正在玩一辆玩具车。如果你推汽车，它会朝某个方向移动，对吧？矢量就像这种推力 - 它告诉你汽车朝哪个方向行驶以及你推它的力度。  箭头的方向告诉你汽车要去哪里（左、右、上、下，甚至是斜着走）。 箭头的长度告诉你推的力度。长箭头表示推的力度大，短箭头表示推的力度小。  所以，矢量就是显示方向和力度的箭头。很酷，对吧？ 2. 如何添加矢量（合并它们的方向） 现在，假设你有两辆玩具车，你同时推它们。一次推力向右，另一次推力向上。会发生什么？汽车会朝新的方向移动，有点像两种推力的混合！ 添加向量就像是将它们的推力组合在一起：  取第一个箭头（向量）并绘制它。 然后，取第二个箭头，并从第一个箭头的尖端开始。 从第一个箭头的起点到第二个箭头的尖端的新箭头是两个向量的和。  就像连接点一样！新箭头显示了两个推力的组合方向和强度。 3. 什么是标量乘法？（拉伸或收缩箭头） 好的，现在让我们讨论如何使箭头变大或变小。想象一下，您有一根可以拉伸或收缩箭头的魔杖。这就是标量乘法的作用！  如果将矢量乘以一个数字（例如 2），箭头会变长。这就像说，“将这个推力加倍！” 如果将矢量乘以一个小数字（例如 0.5），箭头会变短。这就像说，“将这个推力减半。”  但最酷的是：箭头的方向保持不变！只有长度会改变。因此，标量乘法就像放大或缩小箭头一样。  什么是向量（想想指向空间的箭头）。 如何添加它们（组合它们的方向）。 标量乘法的含义（拉伸/收缩）。  以下是我的指南的 PDF： 我正在 LinkedIn 上分享适合初学者的 ML 数学，因此如果您有兴趣，这里是完整的细分：LinkedIn 请告诉我这是否有帮助或者您有疑问！ https://preview.redd.it/8henuj89fife1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=104522492b1d2ce5e29589a7a2093ea96e06fd68    提交人    /u/glow-rishi   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ib4w4a/understanding_linear_algebra_for_ml_in_plain/</guid>
      <pubDate>Mon, 27 Jan 2025 09:59:06 GMT</pubDate>
    </item>
    <item>
      <title>AI/ML研究伙伴</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iaxqb3/aiml_study_partner/</link>
      <description><![CDATA[我目前是一名软件工程师，正在寻找一个学习伙伴，从基础开始学习 AI/ML，然后有兴趣深入研究，组队学习会很棒。定期讨论、集思广益，甚至一起解决小项目都可以使学习过程更有效、更有吸引力。 如果这听起来像你感兴趣的事情，请告诉我，我们可以想办法让它发挥作用。 期待联系！    提交人    /u/Ornery_Change1015   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iaxqb3/aiml_study_partner/</guid>
      <pubDate>Mon, 27 Jan 2025 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>我正在做一个项目，该项目将过滤鼠标输入中的手部颤抖，我想整合机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iawzmj/working_on_project_that_will_filter_hand_tremors/</link>
      <description><![CDATA[        由    /u/_Ariel23   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iawzmj/working_on_project_that_will_filter_hand_tremors/</guid>
      <pubDate>Mon, 27 Jan 2025 02:05:19 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>