<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Mon, 26 Feb 2024 00:57:44 GMT</lastBuildDate>
    <item>
      <title>值得作为 SWE 加入 ML 组织中机器学习最少的团队吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b04bj4/worth_joining_the_leastml_team_within_an_ml_org/</link>
      <description><![CDATA[我作为一名 SWE 在大型科技公司工作，我已经 4 年了。 只有传统的 SWE 背景，没有机器学习工作经验。 我想对 ML 相关的团队开玩笑，但我知道我没有资格从事 100% ML 工作，因为这些工作是为博士研究人员保留的。但我仍然想成为一名 SWE，能够帮助构建和完善 ML 生态系统，从而使产品变得更好（几乎 SWE 在 ML 生态系统和生产化方面拥有丰富的知识）。 我收到录用通知的团队是我公司最热门的组织，但该团队本身更像是一个支持性团队，不需要太多 ML 知识。看来我仍将与组织内的许多团队合作进行机器学习并了解大局，但我不太确定。 是否仍然值得采取这一行动？权衡是 当前团队/新团队 良好的WLB /较差的WLB 我在团队中拥有良好的声誉/需要重建并重新获得信任 无聊的话题/热门话题 ​ 有什么想法吗？谢谢！ ​ ​ ​   由   提交 /u/czechrepublic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b04bj4/worth_joining_the_leastml_team_within_an_ml_org/</guid>
      <pubDate>Mon, 26 Feb 2024 00:48:51 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 内生性问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b00gkh/lstm_endogeneity_issues/</link>
      <description><![CDATA[我正在训练一个 LSTM 来预测 NBA 球员在下一场比赛中会得到多少分。该模型做出的预测与分布的平均值（对于所有玩家）过于中心。它在预测尾巴方面非常糟糕。该模型拒绝预测低于某个特定值，这对我来说是有意义的，因为它的预测下限仍然相当接近 0。然而，它拒绝预测更高的值令人沮丧。就上下文而言，玩家总是得分超过 30 分，而模型从未预测到这一点。  我附上了两张图。比较真实值和预测值的分布。另一个是残差图。  我该如何解决这个问题？   由   提交 /u/NewDawn729   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b00gkh/lstm_endogeneity_issues/</guid>
      <pubDate>Sun, 25 Feb 2024 22:06:37 GMT</pubDate>
    </item>
    <item>
      <title>可解释的金融人工智能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1b00ee9/explainable_ai_for_finance/</link>
      <description><![CDATA[我认为，随着人工智能的不断进步，创造这项技术的人们甚至无法解释它在做什么，这很疯狂。计算的复杂性超出了图表。讽刺的是，他们称之为“可解释性”。人工智能的本质，也就是说，创造人工智能的人能否真正解释为什么它会产生特定的反应？ 我认为这是一篇关于如何使人工智能变得清晰易懂的好文章金融领域： “人工智能的挑战之一是，随着它的进步，其输出的来源变得越来越复杂。例如，如果你问人工智能什么时候是投资房地产市场的最佳时机，它给了你一个复杂的答案，你将如何证明和证明这个观点的合理性？这正是我们在财务中使用“可解释的人工智能”这个术语时的意思。 思考这个问题的另一种方式是问自己，如果你是一名使用人工智能的财务经理，你会如何向你的老板解释你的人工智能程序是如何得出数据的？您认为它使用了技术分析吗？您是否会相信它正在使用自己的逻辑或人类行为知识？也许人工智能正在利用它的历史知识。  如何了解底层算法变得越来越难。在这篇文章中，我将讨论如何在金融领域实现这一点。 ＆quot; https://ai-solutions.pro/explainable-ai-finance/   由   提交/u/Science-man777  /u/Science-man777 reddit.com/r/learnmachinelearning/comments/1b00ee9/explainable_ai_for_finance/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1b00ee9/explainable_ai_for_finance/</guid>
      <pubDate>Sun, 25 Feb 2024 22:04:18 GMT</pubDate>
    </item>
    <item>
      <title>卷积网络编码</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azyqfc/convolutional_network_coding/</link>
      <description><![CDATA[我正在修读与 Coursera 上 Andrew Ng 的卷积神经网络课程类似的课程，我需要一些可以帮助我的 YouTube 视频教程深入理解使用 PyTorch 的编码概念。有人有什么建议吗？   由   提交/u/La-lunaa  /u/La-lunaa reddit.com/r/learnmachinelearning/comments/1azyqfc/convolutional_network_coding/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azyqfc/convolutional_network_coding/</guid>
      <pubDate>Sun, 25 Feb 2024 20:58:08 GMT</pubDate>
    </item>
    <item>
      <title>这可行吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azy0dg/is_this_feasible/</link>
      <description><![CDATA[您好！我对机器人和机器学习非常陌生，最近，我们的任务是对创新项目进行论文研究。我的想法是使用 Arduino Uno、LED 屏幕和电线制作一个湿度测量设备。请问这个可以做吗？如果是这样，怎么办？   由   提交/u/Fickle_Desk_4680   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azy0dg/is_this_feasible/</guid>
      <pubDate>Sun, 25 Feb 2024 20:29:17 GMT</pubDate>
    </item>
    <item>
      <title>推理速度差异异常大</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azwu8n/unusually_large_difference_in_inference_speed/</link>
      <description><![CDATA[我正在训练用于对象检测的 yolov5 模型。我使用稀疏 ml 对其进行修剪和量化，然后将其导出为 onnx 格式。 （图像大小 640，批量大小 16） 在使用 CPU（和 ryzen 5 5600、16GB RAM）的笔记本电脑上推断时，每个图像速度大约需要 20 毫秒。 现在什么时候我在树莓派 5（A76，8gb 内存）中推断同样的事情，每个图像的推理速度仅为 220 毫秒 为什么推理速度有如此大的差异。我知道 Pi 模块的 cpu 可能较慢，但相差 10 倍??? 我在它们两个中安装了相同的库。是否需要在树莓派中手动配置onnx运行时以提高推理速度？   由   提交 /u/Melodic_Draw6781   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azwu8n/unusually_large_difference_in_inference_speed/</guid>
      <pubDate>Sun, 25 Feb 2024 19:42:30 GMT</pubDate>
    </item>
    <item>
      <title>优秀的 ML/DL 项目可以在简历中脱颖而出</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azw3ep/good_mldl_projects_for_standing_out_in_resume/</link>
      <description><![CDATA[有什么好的 ML/tensorflow 项目创意可以让我的简历在今天的环境中脱颖而出吗？ PS-我也知道它要求很高，但如果项目不太困难或者有在线资源可以了解该项目，我会很感激   由   提交 /u/PandeyyJi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azw3ep/good_mldl_projects_for_standing_out_in_resume/</guid>
      <pubDate>Sun, 25 Feb 2024 19:12:39 GMT</pubDate>
    </item>
    <item>
      <title>训练基于大型语言模型的应用程序来生成 SQL</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azvz51/training_a_large_language_model_based_application/</link>
      <description><![CDATA[        由   提交/u/phicreative1997   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azvz51/training_a_large_language_model_based_application/</guid>
      <pubDate>Sun, 25 Feb 2024 19:07:59 GMT</pubDate>
    </item>
    <item>
      <title>DS 至 MLE 切换</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azvg7q/ds_to_mle_switch/</link>
      <description><![CDATA[嗨，简单介绍一下我自己，我已经获得了电子学学士学位。拥有 3 年 DS 经验和半年 SWE 经验。现在，计划过渡到 MLE 角色。关于我应该培养的特定技能、认证或者我应该攻读硕士学位有什么建议吗？    由   提交/u/big_birdiee  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azvg7q/ds_to_mle_switch/</guid>
      <pubDate>Sun, 25 Feb 2024 18:47:22 GMT</pubDate>
    </item>
    <item>
      <title>互联网上的聪明人大家好</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azuh5k/hello_smart_people_of_the_internet/</link>
      <description><![CDATA[伙计们，我参加了实习，但问题是我是生物学专业的。我除了Python入门之外，一无所知。因此，任何编写有意义的代码对我来说都是不可能的，更不用说深度学习、机器学习了。我现在该怎么办？我开始了 fastai 课程，但我不知道它需要一些代码知识和经验。问题是我没有太多时间，因为我不能继续拖延教授的项目。我必须学习，而且学得快。请帮助我    由   提交 /u/Subject_Lab_6013   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azuh5k/hello_smart_people_of_the_internet/</guid>
      <pubDate>Sun, 25 Feb 2024 18:08:52 GMT</pubDate>
    </item>
    <item>
      <title>需要一些很酷的项目想法</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azrxaz/need_some_cool_project_ideas/</link>
      <description><![CDATA[大家好， 我需要为我的大学课程做一个人工智能项目。我需要一些创造性的想法才能让它真正变得非凡。项目时间约为 10 周，我想确保它脱颖而出。 ​ 这是独家新闻：  它应该利用人工智能作为核心组件，增强应用程序的功能。 理想情况下，这个想法应该是独特和创新的，而不是基本的机器学习模型或可以快速完成的东西（比如 4 或 6 秒）一个人的时间）。  ​ 举个例子，我一直在考虑的一个想法是使用人工智能来解释图像，例如解决由相机捕获的数独谜题，校正图像中的任何倾斜，提取数字，解决谜题，然后将解决方案覆盖回图像上。 ​ &lt; p&gt;所以，如果您脑子里闪过任何绝妙的想法，或者偶然发现了一些非常酷的人工智能应用程序，请不要犹豫！在下面分享它们，让我们一起创造一些奇迹。 考虑到这是一个初学者课程，所以没有先验人工智能知识。现在我们只知道编程。 ​ 提前感谢您的贡献！  &amp;# 32；由   提交 /u/Be1a1_A   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azrxaz/need_some_cool_project_ideas/</guid>
      <pubDate>Sun, 25 Feb 2024 16:26:20 GMT</pubDate>
    </item>
    <item>
      <title>导出问题...啊...问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azroz9/exporting_questions_ah_question/</link>
      <description><![CDATA[这是愚蠢的问题线程吗？  只需阅读 Johannes Naylor 关于从头到尾构建葡萄酒推荐聊天机器人的精彩分步指南。明白了。好吧..这是一个愚蠢的问题：如果 sql 产品数据库有 100 万行，我们是否必须导出 100 万行问题才能嵌入到模型中？ 我们要做的就是用会话式自然语言搜索和响应。 我可能会因为问这样一个可笑的愚蠢问题而被跺脚...抱歉...  &amp; #32；由   提交/u/Knowa-com  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azroz9/exporting_questions_ah_question/</guid>
      <pubDate>Sun, 25 Feb 2024 16:16:44 GMT</pubDate>
    </item>
    <item>
      <title>通过 VAE 的仅解码器部分来近似已知分布（达到归一化因子）。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azq3cu/approximating_known_distributions_up_to_a/</link>
      <description><![CDATA[大家好， 我正在阅读一堆关于如何使用神经网络学习和采样分布的论文，并且有一些问题。下面描述的所有内容都是我读过的几篇论文的摘要，其中人们试图做这件事，但我想让这篇文章保持独立。 --------- -------------------------------------------------- -------------------------------------------------- ----------------- 简介：我有以下问题。想象一下你有一个分布P(x)=F(x)/N，我们知道F(x)并且可以随意评估它，但我们不知道知道归一化因子N。问题是——我们如何学习生成分布P(x)的样本，其中x是某个高维空间的元素？一种选择是进行马尔可夫链蒙特卡罗，但我对另一个方向感兴趣。您将立即认识到变分推理和 VAE 的相似之处，但请耐心等待。 设置：我们可以做的是提出一个解码器网络，但没有编码器 我们将尝试用它来优化模型分布M_v(x)。我们开始从 M(z) 中采样 z，其中 M(z) 是已知的，例如是一个简单的高斯函数。接下来，z 是神经网络 NN(z)=v 的输入，该网络生成模型分布的参数。这里需要注意的是，解码器网络不会产生实际的元素x，而是产生模型分布的权重。例如，如果 M_v(x) 是 x 分量中的高斯混合，参数 v 则为必要的均值、方差和混合权重。 目标：学习网络中适当的权重，以便图形模型：“ M_v(x) =sample M(z) -&gt; 获取参数 v -&gt; 样本  &gt;x from M_v(x) &quot; 近似采样我们想要学习的分布 P(x)。  &gt;方法：我们首先将两个分布之间的 KL 散度写为 KL(M_v(x)| F(x)/N)= E_{M_v} [ log (M_v(x)) - log ( F(x) ) ] + log(N)。 为了优化我们的解码器网络，我们本质上在 log(N) 上放置了一个变分不等式，如下所示： log(N) &lt; E_{M_v} [ log(M_v(x)) - log ( F(x) ) ] （表达式 1） 我们设置中唯一可调的参数是神经网络的权重产生 NN(z)=v ，因此目标是以 RHS 最小化的方式调整权重。 问题： 1) 这看起来与变分推理非常相似，但主要区别在于，现在我们实际上知道目标分布 F(x) (直到归一化）并尝试学习它的变分近似。然而在大多数关于变分推理的教程和解释中，您不知道分布F(x)，但有一些根据它分布的数据{x}，因此您还需要一个编码器网络。因此，第一个问题是：这个“仅解码器”是否可以实现？用于近似已知目标分布的 VAE 有一个名称吗？ 2) 所以我了解设置和理论，但我不确定如何实际评估  的 RHS &gt;表达式1。 假设M_v(x)是高斯混合。在这种情况下，不可能分析计算这两项中的至少一项。那么在这种情况下，如何在 PyTorch 中实际进行反向传播呢？您实际上是否必须对分布M_v(x)进行真实采样，生成一些样本{x}，然后使用生成的样本来近似E_{M_v} [ log(M_v(x)) - log ( F(x) ) ] ?   由   提交/u/Invariant_apple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azq3cu/approximating_known_distributions_up_to_a/</guid>
      <pubDate>Sun, 25 Feb 2024 15:09:39 GMT</pubDate>
    </item>
    <item>
      <title>LSTM预测问题</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azowky/lstm_forecasting_issue/</link>
      <description><![CDATA[      ​ https://preview.redd.it/nvhgmo2toqkc1.png?width=1233&amp;format=png&amp;auto=webp&amp;s=741146185fac14fffef32f6cfea0f319dc2b5f5e 大家好，我是机器新手学习并刚刚尝试运行单变量时间序列 LSTM 模型进行预测。这种问题有具体的名称吗？另外，您能推荐一些书籍或资源来帮助我了解有关时间序列 LSTM 预测的更多信息吗？提前致谢！    由   提交 /u/Dry-Individual-5802   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azowky/lstm_forecasting_issue/</guid>
      <pubDate>Sun, 25 Feb 2024 14:15:25 GMT</pubDate>
    </item>
    <item>
      <title>制作了模型，很满意，然后怎么办？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1azm5k8/made_the_model_happy_with_it_and_now_what/</link>
      <description><![CDATA[      嗨， 我正在努力学习和理解ML 是其中一部分的高级视图。我制作了一个线性回归模型，对其进行了训练和测试，对分数和结果感到满意。 ​ https://preview.redd.it/fe9cbu​​mdypkc1.png?width=970&amp;format=png&amp;auto=webp&amp;s =65ad7fab88c1e26c7f1ef0ddeba8c836807f8fbc 但是现在怎么办？如何充分利用这个模型？当新数据进来时，我如何“使用”这个模型？我见过的每个教程、课程和博客都集中在训练和测试部分，这仍然是一个实验。他们都没有解释接下来的步骤... 如何“保存”此模型以便可以重复使用？ 我在哪里“放置”模型？ 模型在数据集上进行训练和测试，但如何获取新数据？我需要在代码中更改哪些内容才能从预测开始？ 希望有人理解我的意思并尝试询问。 谢谢。    由   提交 /u/SquidsAndMartians   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1azm5k8/made_the_model_happy_with_it_and_now_what/</guid>
      <pubDate>Sun, 25 Feb 2024 11:51:42 GMT</pubDate>
    </item>
    </channel>
</rss>