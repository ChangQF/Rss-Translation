<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Fri, 20 Dec 2024 21:14:38 GMT</lastBuildDate>
    <item>
      <title>如果我的笔记本电脑配置很低，学习机器学习会很难吗？（基本上就是土豆）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1his7ac/will_it_be_hard_to_learn_ml_if_my_laptop_has_very/</link>
      <description><![CDATA[标题。我已经开始学习 Python 并想进入 ML，但据我所知，您需要一台非常强大的带有 GPU 的 PC 才能运行它。我有一台带有集成显卡（Vega 3）的 Ryzen 3 芯片笔记本电脑。在那上面学习 ML 会不可能吗？（我现在买不起新的）    提交者    /u/Key_Apartment1576   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1his7ac/will_it_be_hard_to_learn_ml_if_my_laptop_has_very/</guid>
      <pubDate>Fri, 20 Dec 2024 19:55:33 GMT</pubDate>
    </item>
    <item>
      <title>评价我的简历，我还是个学生，愿意把它发给实习和入门级工作</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hirzgf/rate_my_resume_i_am_still_a_student_and_willing/</link>
      <description><![CDATA[        提交人    /u/Beyond_Birthday_13   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hirzgf/rate_my_resume_i_am_still_a_student_and_willing/</guid>
      <pubDate>Fri, 20 Dec 2024 19:45:39 GMT</pubDate>
    </item>
    <item>
      <title>增加数据的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hirpq4/what_is_the_best_way_to_increase_data/</link>
      <description><![CDATA[我正在研究一个二分类项目，其训练数据集有 5,000 行，但非常不平衡（0 多于 1）。我进行了欠采样，结果只有 2K 行。我尝试了所有 SDV 合成器，其中最好的是 TVAESynthesizer。 在训练数据上，情况看起来不错：几乎所有模型的准确率和召回率都达到 80%（我同时进行了这两项操作：欠采样 + TVAESynthesizer）。但是当我在测试数据集上测试模型时，召回率保持在 80%，而所有模型的准确率都下降到 33%。 （我知道这是一个过度拟合的问题，我尝试了分层 K 折，但没有好的结果） 关于如何解决这个问题并提高测试数据的精度，有什么想法吗？    提交人    /u/Successful-Life8510   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hirpq4/what_is_the_best_way_to_increase_data/</guid>
      <pubDate>Fri, 20 Dec 2024 19:33:17 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI o3 和 o3-mini 细节总结</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hirjn3/openai_o3_and_o3mini_details_summarized/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hirjn3/openai_o3_and_o3mini_details_summarized/</guid>
      <pubDate>Fri, 20 Dec 2024 19:25:32 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能的秘诀</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hinmcw/tips_for_generative_ai/</link>
      <description><![CDATA[ 我进入数据科学和机器学习阶段已经有一段时间了。我在从 pytorch 或 tensorflow 创建神经网络架构时遇到了问题，因为我总是对如何处理感到困惑。由于我学习的时间很短，而且我已经对它有了基本的了解，所以我想要一些资源，以便以最佳方式实现它，同时为面试做准备     提交人    /u/heisenberg-1210   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hinmcw/tips_for_generative_ai/</guid>
      <pubDate>Fri, 20 Dec 2024 16:32:18 GMT</pubDate>
    </item>
    <item>
      <title>更快的推理：torch.compile 与 TensorRT</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1himnoj/faster_inference_torchcompile_vs_tensorrt/</link>
      <description><![CDATA[  由    /u/lubosz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1himnoj/faster_inference_torchcompile_vs_tensorrt/</guid>
      <pubDate>Fri, 20 Dec 2024 15:48:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 Geron 的 HOML 进行自我学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hilqxu/self_learning_ml_with_gerons_homl/</link>
      <description><![CDATA[嗨，我真的很喜欢构建 AI 应用程序和学习 AI 和机器学习。我已经参加了一些关于 ML 的课程和训练营，现在正在阅读使用 keras scikit learn 和 Tensorflow 进行机器学习。问题是我目前读到第 12 章，事情变得非常困难。我一直在寻求聊天 gpt 的帮助，使概念对我来说更容易，但现在事情变得无法控制。请指导我该怎么做以及如何保持动力并学习这些枯燥的概念？    提交人    /u/mr_pewterschmidtt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hilqxu/self_learning_ml_with_gerons_homl/</guid>
      <pubDate>Fri, 20 Dec 2024 15:06:14 GMT</pubDate>
    </item>
    <item>
      <title>90 天人工智能学习挑战</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hila5u/90_days_ai_learning_challenge/</link>
      <description><![CDATA[现在是假期，我开始了 90 天的 AI 学习挑战，以创建可用于生产的应用程序。有人有兴趣加入吗？#90daysAIChallenge https://youtube.com/shorts/YKtz77MwOgg?si=uqWZoNbJyfnbbqZX    提交人    /u/Capital_Coyote_2971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hila5u/90_days_ai_learning_challenge/</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:12 GMT</pubDate>
    </item>
    <item>
      <title>制作了一个直观解释检索增强生成的视频。我希望你们喜欢它，就像我喜欢制作这个视频一样。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hihbp4/made_a_video_that_intuitively_explains_retrieval/</link>
      <description><![CDATA[        提交人    /u/faizalHoonBC   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hihbp4/made_a_video_that_intuitively_explains_retrieval/</guid>
      <pubDate>Fri, 20 Dec 2024 10:53:13 GMT</pubDate>
    </item>
    <item>
      <title>大多数 LLM 是否使用与 BERT 类似的词邻近度/频率/上下文向量嵌入模型？我理解他们通过上下文“学习”隐式规则和定义，但基于意义（定义）的向量（包括 POS）是否被低估了？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1higt6s/do_the_majority_of_llms_utilise_word/</link>
      <description><![CDATA[        提交人    /u/clippeh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1higt6s/do_the_majority_of_llms_utilise_word/</guid>
      <pubDate>Fri, 20 Dec 2024 10:15:21 GMT</pubDate>
    </item>
    <item>
      <title>什么使优秀的数据科学家 + MLE 与众不同？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hifs8v/what_sets_great_data_scientists_mles_apart/</link>
      <description><![CDATA[那么这些技能如何学习呢？    提交人    /u/darkGrayAdventurer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hifs8v/what_sets_great_data_scientists_mles_apart/</guid>
      <pubDate>Fri, 20 Dec 2024 08:57:25 GMT</pubDate>
    </item>
    <item>
      <title>没有计算机科学学位，成为一名开发人员的可行性有多大？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hi6tv0/how_feasible_is_working_as_a_developer_without_a/</link>
      <description><![CDATA[我今年将以金融专业和 BTM 辅修专业毕业。  我一直都很喜欢编程，而且我在这方面也有不错的背景。我喜欢学习它，并且可以花无数的时间研究和弄清楚一些事情以完成一个项目。  很多人告诉我，你不需要计算机科学学位就可以找到一份开发人员的工作。然而也有相反的观点。  我现在的问题是，如果我能够拥有我需要的所有技术技能。没有计算机科学学位，有可能成为一名开发人员吗？你对我有什么建议？    提交人    /u/SpinxLogic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hi6tv0/how_feasible_is_working_as_a_developer_without_a/</guid>
      <pubDate>Thu, 19 Dec 2024 23:58:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么要堆叠 LSTM 层</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hhz5s2/why_stacked_lstm_layers/</link>
      <description><![CDATA[堆叠 LSTM 层背后的直觉是什么？我没有看到任何关于为什么使用堆叠 LSTM 层的讨论，例如为什么使用。  1) 50 输入 &gt; 256 LSTM &gt; 256 LSTM &gt; 10 输出 2) 50 输入 &gt; 256 LSTM &gt; 256 Dense &gt; 256 LSTM &gt; 10 输出 3) 50 输入 &gt; 512 LSTM &gt; 10 输出 我想我可以明白为什么人们会选择 1 而不是 3（深度网络比浅层但宽的网络更擅长泛化），但为什么人们通常使用 1 而不是 2？为什么使用堆叠的 LSTM，而不是与普通 Dense 交织的 LSTM？    提交人    /u/ZazaGaza213   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hhz5s2/why_stacked_lstm_layers/</guid>
      <pubDate>Thu, 19 Dec 2024 18:13:18 GMT</pubDate>
    </item>
    <item>
      <title>基于 SAM 2 的强大球跟踪功能</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1hhybde/robust_ball_tracking_built_on_top_of_sam_2/</link>
      <description><![CDATA[        由    /u/happybirthday290  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1hhybde/robust_ball_tracking_built_on_top_of_sam_2/</guid>
      <pubDate>Thu, 19 Dec 2024 17:37:41 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>