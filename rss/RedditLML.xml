<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Tue, 12 Dec 2023 12:26:09 GMT</lastBuildDate>
    <item>
      <title>您使用哪些工具来帮助您更快地学习人工智能？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gkpfo/what_tools_are_you_using_to_help_you_learn_ai/</link>
      <description><![CDATA[我最近开始使用 Docker 进行机器学习开发和个人教育。我使用带有 CUDA GPU 的专用 Windows 桌面已有几年了。我对 Docker 能够让 Jupyter 示例和相关代码快速运行感到兴奋。它有助于通过使用 WSL2 避免不兼容库的问题。过去，我遇到过如果没有解决方法就无法完成教程的情况。与 Colab 等云解决方案相比，专用桌面为我提供了更大的灵活性，后者对于许多场景仍然非常有用。我希望将来为 AI+ML 运行 Linux 桌面，但现在这最适合我。 由于 Docker 非常适合我的用例，因此我创建了一份详细的指南。我希望它对您有用。 使用 Windows 设置带有 GPU 加速的 TensorFlow 、Docker 和 WSL2 对我来说，使用正确的工具节省的时间意味着有更多时间完成工作和学习。您使用哪些工具让您的 AI 学习更加顺利？   由   提交/u/dreoporto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gkpfo/what_tools_are_you_using_to_help_you_learn_ai/</guid>
      <pubDate>Tue, 12 Dec 2023 12:23:50 GMT</pubDate>
    </item>
    <item>
      <title>如何以比平常更快的速度阅读研究论文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gjvhv/how_to_read_research_paper_at_a_faster_pace_than/</link>
      <description><![CDATA[我可以轻松地以每周 1 篇（最多 2 篇）的速度阅读 ML 研究论文，但是，我是按顺序阅读的。我在网上找到了一些文章、视频，建议你把数学部分留到最后，也尝试过，但速度没有提高多少。 如何更快地完成这项工作?   由   提交/u/arinjay_11020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gjvhv/how_to_read_research_paper_at_a_faster_pace_than/</guid>
      <pubDate>Tue, 12 Dec 2023 11:32:01 GMT</pubDate>
    </item>
    <item>
      <title>适合父亲的数学书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gju48/mathfocused_book_for_father/</link>
      <description><![CDATA[嗨r/learnmachinelearning， 有什么好的、以数学为重点的机器学习介绍/概述书籍吗？ 我爸爸是一名精算师/机械工程师（他喜欢数学），我最近一直在人工智能聊天让他大吃一惊。  有什么好书介绍现代机器学习中使用的数学吗？ 谢谢！  &amp;# 32；由   提交 /u/SufficientBowler2722   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gju48/mathfocused_book_for_father/</guid>
      <pubDate>Tue, 12 Dec 2023 11:29:47 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]如何从新手走向搭建LLM代理进行生产？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gj1jv/discussion_how_do_i_go_from_being_a_novice_to/</link>
      <description><![CDATA[我拥有数据科学硕士学位，并且对传统机器学习模型有一些经验。 但是，我感到不知所措关于法学硕士和人工智能领域发生的一切的大量知识。我感到迷失，我想跟上最新的技术。  如何从初学者过渡到能够理解和构建 LLM 申请？  任何帮助或见解表示赞赏。谢谢！   由   提交 /u/reborn_tonight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gj1jv/discussion_how_do_i_go_from_being_a_novice_to/</guid>
      <pubDate>Tue, 12 Dec 2023 10:36:54 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱格式的可视化文本摘要的最佳方法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gihkg/best_approach_for_visual_text_summarization_in/</link>
      <description><![CDATA[ 由   提交 /u/Responsible-Dig7538    reddit.com/r/LanguageTechnology/comments/18gi6qf/best_approach_for_visual_text_summarization_in/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gihkg/best_approach_for_visual_text_summarization_in/</guid>
      <pubDate>Tue, 12 Dec 2023 09:58:52 GMT</pubDate>
    </item>
    <item>
      <title>同一个模型可以训练两次吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gigx1/is_it_possible_to_train_the_same_model_twice/</link>
      <description><![CDATA[如果是，概念的名称是什么？ 我有一个包含 50000000 行的数据集，需要 3 小时才能完成运行 相反，我想单独训练每个 1000000 行，然后在第二个 1000000 行上重新训练模型 这个想法存在吗？ 谢谢   由   提交 /u/qhelspil   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gigx1/is_it_possible_to_train_the_same_model_twice/</guid>
      <pubDate>Tue, 12 Dec 2023 09:57:31 GMT</pubDate>
    </item>
    <item>
      <title>将 GridSearch 与 OneVsRestClassifier 结合使用用于 SVM（Jupyter Notebook、Sklearn）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gi0g9/using_gridsearch_with_onevsrestclassifier_for/</link>
      <description><![CDATA[大家好，这里是机器学习菜鸟。 我目前正在尝试使用 gridsearch 为我的 svm 分类器找到最佳的超参数。我有 10 个标签，所以我使用 OneVsRest 分类器来处理多个类。 我仍然不确定我的方法是否错误，我不想浪费数小时的训练时间，所以这是我的代码： -------------------------------------------- # 导入数据集 X_train, y_train = mnist_reader.load_mnist(&#39;数据/时尚&#39;, kind=&#39;train&#39;) X_test, y_test = mnist_reader.load_mnist(&#39;数据/时尚&#39;, kind= &#39;t10k&#39;) ​ # 缩放测试和训练数据 scaler = StandardScaler() X_train_scaled = scaler .fit_transform(X_train) X_test_scaled = scaler.transform(X_test) ​ # 创建网格搜索模型 svm_model = svm.SVC() ​ # 设置网格搜索参数 grid_params = [ {&#39;内核&#39;: [&#39;线性&#39;], &#39;C&#39;: [0.1, 1, 10, 100, 1000]}, {&#39;内核&#39;: [&#39;rbf&#39;], &#39;伽玛&#39;: [1E -3, 1E-2, 1E-1, 1E0, 1E1], &#39;C&#39;: [0.1, 1, 10, 100]} ] ​&lt; /p&gt; # 使用上述参数进行网格搜索 grid_search = GridSearchCV(OneVsRestClassifier(svm_model), grid_params, cv=5) grid_search.fit(X_train_scaled, y_train)  ​ # 获取最佳参数 best_params = grid_search.best_params_ print(&quot;最佳参数：&quot;; , best_params) ​ # 使用最佳参数进行实际训练 best_svm_classifier = OneVsRestClassifier(svm.SVC(**best_params)) best_svm_classifier.fit(X_train_scaled, y_train) ​ # 保存完成的模型 model_filename = &#39;svm_model.pkl&#39; joblib.dump(best_svm_classifier, model_filename) print(f“模型保存为 {model_filename}”) ------------ --------------------------------- 你认为这会起作用吗？有什么改进的建议或建议吗？我是否必须在 GridSearch 期间使用 OneVsRest 分类器，还是仅在使用最佳参数的实际训练中使用 OneVsRest 分类器？ MNIST Zalando 数据集  &amp; #32；由   提交/u/hertz2105  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gi0g9/using_gridsearch_with_onevsrestclassifier_for/</guid>
      <pubDate>Tue, 12 Dec 2023 09:23:37 GMT</pubDate>
    </item>
    <item>
      <title>我需要针对 Hugging Face 上的特定任务评估不同的法学硕士</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18ghqr3/i_need_to_evaluate_different_llms_for_a_specific/</link>
      <description><![CDATA[您好，我需要在数学领域的 Hugging Face 上评估不同的法学硕士（mistral、falcon、llama..）？我该如何继续？ Hugging Face 是免费的吗？有人可以帮忙提供示例代码或教程吗？非常感谢！   由   提交/u/Life_Ask2806   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18ghqr3/i_need_to_evaluate_different_llms_for_a_specific/</guid>
      <pubDate>Tue, 12 Dec 2023 09:03:00 GMT</pubDate>
    </item>
    <item>
      <title>决策树中节点的顺序重要吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gfjpc/does_the_order_of_the_nodes_in_a_decision_tree/</link>
      <description><![CDATA[节点顺序对准确性重要吗？   由   提交 /u/limitless_raindrop   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gfjpc/does_the_order_of_the_nodes_in_a_decision_tree/</guid>
      <pubDate>Tue, 12 Dec 2023 06:25:42 GMT</pubDate>
    </item>
    <item>
      <title>微调 BERT</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gey3m/finetuning_bert/</link>
      <description><![CDATA[BERT 发布时是 NLP 领域最有用的模型之一。其双向架构有助于它比其他模型更好地理解文本上下文。了解更多。 存储库：https： //github.com/spmallick/learnopencv/tree/master/Fine-Tuning-BERT-using-Hugging-Face-Transformers 了解更多：https://learnopencv.com/fine-tuning-bert/   由   提交 /u/spmallick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gey3m/finetuning_bert/</guid>
      <pubDate>Tue, 12 Dec 2023 05:48:31 GMT</pubDate>
    </item>
    <item>
      <title>与仅传递“hist”相比，传递“gpu_hist”时的处理时间增加了一倍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gdvha/process_times_are_doubled_when_passing_gpu_hist/</link>
      <description><![CDATA[我正在学习本教程 在数据阵营中，他们提到的一个主题是利用 GPU 来加快处理时间。他们甚至说它“速度极快”。 然而，我看到了相反的结果。对于下面的代码块，最大数量的提升（已注释掉早期停止），我看到“hist”约为 30 秒。传递我的参数与使用“gpu_hist”只需要一分多钟的时间使用我的参数传递。 我正在尝试在 jupyter 笔记本中的 VSCode 中运行它。 - 我已经安装了 CUDA 工具包和 cuDNN  - 我已检查它们是否已添加到路径中  - 我已确保安装了正确版本的 xgboost 来利用 GPU。 - 数据集为 53k 行，其中 10列（与上面的链接相同） 我问过chatgpt，在网上搜索过，甚至问过我正在学习的课程中的导师，但无法诊断为什么花了这么长时间“gpu_hist”。 我在这里缺少什么？ params = {“objective”: “reg:squarederror”, “tree_method”: “ gpu_hist&quot;, &quot;subsample&quot;: 0.8, # 示例值，根据需要调整 &quot;colsample_bytree&quot;: 0.8} evals = [(dtrain_reg, &quot;train&quot;),(dtest_reg, &quot;validation&quot;)] n = 10000 model = xgb.train( params=params, dtrain=dtrain_reg, num_boost_round=n, evals=evals, verbose_eval=50, 激活提前停止 Early_stopping_rounds=50 )  ​   由   提交/u/secondattempt416  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gdvha/process_times_are_doubled_when_passing_gpu_hist/</guid>
      <pubDate>Tue, 12 Dec 2023 04:46:34 GMT</pubDate>
    </item>
    <item>
      <title>用 PyTorch 解释量化 - 对称和非对称量化、训练后量化、量化感知训练</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18gb4x2/quantization_explained_with_pytorch_symmetric_and/</link>
      <description><![CDATA[   /u/hkproj_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18gb4x2/quantization_explained_with_pytorch_symmetric_and/</guid>
      <pubDate>Tue, 12 Dec 2023 02:20:45 GMT</pubDate>
    </item>
    <item>
      <title>神经科学家的人工智能职位？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18g6x86/ai_positions_for_a_neuroscientist/</link>
      <description><![CDATA[大家好， 我是一名神经科学家，在细胞神经科学方面做了很多研究和一篇博士论文（大量的基准工作）和分子生物学）并且想过渡到计算机科学已经有一段时间了，因为生物技术的成本和限制非常高，而且我喜欢编程和构建东西，这在生物技术中不可能达到令人满意的水平。 我学习了几种编程语言，用 C++ 和 Python numpy 从头开始​​编写 MLP，学习了 Pytorch 并探索了 MLP、CNN 和 LSTM 模型（目前正在研究 Transformer）。 这可能不相关，但我也在coursera上获得了一些证书（例如微积分、深度学习和版本控制）。 我还学习了很多多变量微积分，以便能够了解幕后发生的事情。我对算法和复杂性有一些了解，尽管到目前为止我只做了 25-30 个简单的 Leetcode 问题。 在接下来的几个月里，我想进一步提高我特别感兴趣的 pytorch 技能在带有 pytorch 几何的 GNN 中，因为在制药中，它们似乎对分子结构建模很有用。 此外，大型科技公司似乎对医疗保健和生物信息学越来越感兴趣（例如 Google、NVIDIA、Meta 在这些领域开展项目）  我最近还看到了一些人工智能明星讨论神经科学在人工智能中的重要性的视频，并暗暗希望我的生物直觉可以帮助构建新的人工智能算法。 &lt; p&gt;根据我目前的知识，作为一名神经科学家，成为一名快乐的机器学习工程师的机会有多大？还有机会吗？我应该主要关注/改进哪里？   由   提交/u/balaena7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18g6x86/ai_positions_for_a_neuroscientist/</guid>
      <pubDate>Mon, 11 Dec 2023 22:58:05 GMT</pubDate>
    </item>
    <item>
      <title>构建神经网络架构时有什么经验法则吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18fv2yv/are_there_any_rules_of_thumb_when_making_the/</link>
      <description><![CDATA[我如何知道何时需要更多隐藏层？我如何知道何时必须使已有的图层变大？使每一层逐渐变小有哪些好处/成本？都是反复试验吗？   由   提交/u/TimeConsideration336   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18fv2yv/are_there_any_rules_of_thumb_when_making_the/</guid>
      <pubDate>Mon, 11 Dec 2023 13:55:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么就业市场如此糟糕？它会变得更好吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/18fsg0q/why_is_the_job_market_so_bad_will_it_ever_get/</link>
      <description><![CDATA[我在 Reddit 子版块上看到了很多很多帖子，谈论现在的就业市场有多么糟糕。 目前，我因为我还在读高中，所以还没有进入就业市场。我想进入这个行业，但我实际上对人们所说的就业市场有多糟糕感到震惊。为什么情况这么糟糕？5-6年后会变得更好还是会变得更糟？   由   提交/u/LabOpposite3248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/18fsg0q/why_is_the_job_market_so_bad_will_it_ever_get/</guid>
      <pubDate>Mon, 11 Dec 2023 11:28:00 GMT</pubDate>
    </item>
    </channel>
</rss>