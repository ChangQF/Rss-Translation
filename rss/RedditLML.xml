<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Thu, 27 Jun 2024 18:17:44 GMT</lastBuildDate>
    <item>
      <title>有没有办法通过 AoT 编译 AI 模型以在 CPU 或 GPU 上运行？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpxrhn/is_there_a_way_to_aot_compile_an_ai_model_to_run/</link>
      <description><![CDATA[从我初步的研究来看，AoT 编译是过去一两年来讨论的热门话题。随着模型越来越大，按需提供服务和预编译的成本也越来越高，关于 AoT 编译优于 JIT 编译的讨论也越来越普遍。但是，我还没有看到任何针对 GPU 的明确解决方案？同样，也没有看到针对 CPU 的现状解决方案。 Tensorflow XLA 支持 AoT 编译，但据我所知，它仅适用于 x86 CPU：https://openxla.org/xla/tf2xla/tfcompile PyTorch Glow 和内置的 PyTorch `aot_compile` 似乎也没有针对 GPU 的 AoT。它也是实验性的。 TVM 具有 AoT 编译，但 (1) 它目前已损坏，并且 (2) 是为针对微控制器（例如 x86、ARM、RISC-V）的 MicroTVM 构建的。 所以我的问题很简单。如果我想执行以下操作：  将 LLM 之类的神经网络模型作为二进制文件分发到多个主机上进行推理 让该二进制文件在运行推理时使用 GPU 或 CPU（编译时的选择）  ...我有什么选择？现在人们用什么来做这个？ 此外，有人知道任何基准测试吗：JIT 与 AoT 与 CPU 上的无编译以及一般的 GPU？    提交人    /u/jiMalinka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpxrhn/is_there_a_way_to_aot_compile_an_ai_model_to_run/</guid>
      <pubDate>Thu, 27 Jun 2024 18:02:13 GMT</pubDate>
    </item>
    <item>
      <title>推荐阅读学习机器学习基础知识？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpxfvw/recommended_reading_for_l_learning_fundamentals/</link>
      <description><![CDATA[想知道是否有人推荐一些关于机器学习的书籍或文章，可以让我对其有扎实的基础理解？历史、主题、基本原理。不需要技术性——甚至可能不喜欢。 机器学习越来越成为我工作的一部分，虽然我不是工程师或数据科学家，但我希望能够更流利地谈论它，并了解机器学习世界中的可能性。    提交人    /u/johnnyhighschool   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpxfvw/recommended_reading_for_l_learning_fundamentals/</guid>
      <pubDate>Thu, 27 Jun 2024 17:48:54 GMT</pubDate>
    </item>
    <item>
      <title>每次经历一个时期后，我的损失都会大幅下降。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</link>
      <description><![CDATA[      大家好， 我正在使用 IMDB 数据集对分类任务上的 DistilBERT 模型进行微调。然而，在每个 epoch 之后，我的损失会变得非常低，然后再次开始上升到一个值，并在整个 epoch 中保持这个值。这种行为会重复发生。 我创建了一个 Trainer 类，一个 epoch 的训练循环按以下方式处理： def _train_one_epoch(self, model, trainloader, testloader): &quot;&quot;&quot;训练一个 epoch 的模型。&quot;&quot;&quot; model.train() training_loss = 0.0accumulated_loss = 0.0 total_steps = len(trainloader) // self.gradient_accumulation_steps with tqdm(total=total_steps) as pbar: for i, data in enumerate(trainloader): # 将数据移动到设备 if isinstance(data, list): data = [item.to(self.device) for item in data] elif isinstance(data, dict): data = {key: value.to(self.device) for key, value in data.items()} else: data = data.to(self.device) # 使用 autocast(enabled=self.use_mixed_precision, dtype=torch.float16) 进行前向传递： output = model.train_step(data) loss = output[0] if isinstance(output, tuple) else output loss /= self.gradient_accumulation_steps # 后向传递 if self.use_mixed_precision: self.scaler.scale(loss).backward() else: loss.backward() accumulation_loss += loss.item() * self.gradient_accumulation_steps total_norm = 0.0 for param in model.parameters(): param_norm = param.grad.detach().data.norm(2) total_norm += param_norm.item() ** 2 total_norm = total_norm ** (1. / 2) self._log_metrics({&quot;Total Gradient Norm&quot;: total_norm}) # 更新权重 if (i + 1) % self.gradient_accumulation_steps == 0: if self.use_mixed_precision: self.scaler.unscale_(self.optimizer) if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.scaler.step(self.optimizer) self.scaler.update() else: if self.max_grad_norm is not None: nn_utils.clip_grad_norm_(model.parameters(), self.max_grad_norm) self.optimizer.step() self.optimizer.zero_grad() pbar.update(1) if self.scheduler: self.scheduler.step() if self.log: self._log_metrics({&quot;Training Loss&quot;: accumlidar_loss / (i + 1), &quot;Learning Rate&quot;: self.optimizer.param_groups[0][&#39;lr&#39;]}) pbar.set_postfix({&#39;Training Loss&#39;: accumlidar_loss / (i + 1)}) training_loss = accumlidar / len(trainloader) self.optimizer.zero_grad() return training_loss  这种行为每次都会发生，与学习率无关（我也使用调度）。它也发生在诸如问答或对不同数据集（例如 Hyperpartisan）进行分类等任务上。您还可以在 WikihopQA 上训练 QA 任务时看到损失行为。 https://preview.redd.it/zypdq1gzi59d1.png?width=2528&amp;format=png&amp;auto=webp&amp;s=a02d0d67cb4ae2321a364104537ecb981e92e910    提交人    /u/BossBigSword   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpxc6p/my_loss_gets_a_big_spike_downward_after_every/</guid>
      <pubDate>Thu, 27 Jun 2024 17:44:47 GMT</pubDate>
    </item>
    <item>
      <title>由于高 epoch 数导致 DL 过度拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpx7g6/dl_overfitting_due_to_high_epoch_count/</link>
      <description><![CDATA[有一件事我不确定我是否理解，那就是如果我们试图将梯度降到 0，那么较高的 epoch 数为什么会很糟糕。它不是应该收敛吗？ 我认为它有问题的唯一方式是，如果它最终超过最小值，那么梯度就不为 0，但你会认为在这种情况下模型会欠拟合而不是过拟合。 如果有人能提供一些见解，我将不胜感激。    提交人    /u/RNRuben   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpx7g6/dl_overfitting_due_to_high_epoch_count/</guid>
      <pubDate>Thu, 27 Jun 2024 17:39:15 GMT</pubDate>
    </item>
    <item>
      <title>需要建议 - 两天时间准备 langchain 和 langgraph 的面试</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpwye4/need_advice_two_days_to_prepare_for_an_interview/</link>
      <description><![CDATA[有没有什么快速参考资料可以帮助有经验的人工智能专业人士准备 LangChain 和 LangGraph 的面试？ 非常感谢您的任何意见。谢谢。    提交人    /u/hidimbi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpwye4/need_advice_two_days_to_prepare_for_an_interview/</guid>
      <pubDate>Thu, 27 Jun 2024 17:28:58 GMT</pubDate>
    </item>
    <item>
      <title>从 32 开始</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</link>
      <description><![CDATA[大家好，我从事 IT 和网络安全工作已有几年了，似乎这个行业不再适合我了，我拥有网络安全理学学士学位，我想看看我是否能够转型。如果需要，我愿意回到学校通过 Coursera 获得硕士学位    提交人    /u/_Darth_Necro_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpv55h/starting_at_32/</guid>
      <pubDate>Thu, 27 Jun 2024 16:14:32 GMT</pubDate>
    </item>
    <item>
      <title>如何开始学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dptwi4/how_to_start_learning_ml/</link>
      <description><![CDATA[嗨，我是一名高中生，对学习计算机科学特别是机器学习领域感兴趣。但是我不想学习如何创建 chatGPT 包装器，而是想学习机器学习背后的理论和数学。我已经学习了微积分 2，并且了解矩阵的基础知识。 我看过 3blue1brown 关于机器学习和多层感知器的系列节目，并且在编程和 Python、Java 等语言方面拥有丰富的经验。 我想知道是否有路线图、研究论文、在线大学课程、视频系列或任何资源可以帮助我学习更多并开始一些实际项目？ 附加问题：有什么项目适合我的理解水平吗？    提交人    /u/Axion48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dptwi4/how_to_start_learning_ml/</guid>
      <pubDate>Thu, 27 Jun 2024 15:21:57 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dps7tw/deep_reinforcement_learning/</link>
      <description><![CDATA[发表于 ICML 2024 论文：https://huggingface.co/papers/2406.16979    由   提交  /u/ml_dnn   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dps7tw/deep_reinforcement_learning/</guid>
      <pubDate>Thu, 27 Jun 2024 14:10:24 GMT</pubDate>
    </item>
    <item>
      <title>帮助使用 C++ ML 框架</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dprj8h/help_with_c_ml_framework/</link>
      <description><![CDATA[嗨，我正在用 C++ 创建一个用于传统机器学习的框架，我遇到了一点麻烦，我需要一点帮助来创建一个用于求逆的函数/解决 Ax = B 以获得权​​重估计。到目前为止，我只是找到了矩阵的 Cholesky 因子，然后使用 LU 分解来求解方程，但后来我发现这并不适用于每个矩阵。如果你们有任何理论/方法可以发给我，那就太好了。    提交人    /u/yesimacavsfan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dprj8h/help_with_c_ml_framework/</guid>
      <pubDate>Thu, 27 Jun 2024 13:39:35 GMT</pubDate>
    </item>
    <item>
      <title>了解机器学习的基础知识</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpqwkm/learn_the_fundamentals_of_machine_learning/</link>
      <description><![CDATA[我刚刚完成了 A-level 考试，接下来大约有两个半月的时间我没什么事可做。我有不错的数学背景，正在学习 A-level 数学和高等数学。我想知道哪些书籍或在线资源最适合学习机器学习的基础知识和内部工作原理。我希望找到一些东西来鼓励我应用新获得的知识。    提交人    /u/Different_Wonder1842   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpqwkm/learn_the_fundamentals_of_machine_learning/</guid>
      <pubDate>Thu, 27 Jun 2024 13:09:57 GMT</pubDate>
    </item>
    <item>
      <title>我应该首先瞄准什么角色？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dpim1h/what_role_should_i_aim_first/</link>
      <description><![CDATA[说实话，我迷路了。我现在是计算机系统工程专业的第三年，我真的很想找到一份 ML 工程师的工作。但是，我被很多互联网观点轰炸了（我的错）。有些人说没有 ML 工程师入门级工作，所以我应该先瞄准数据科学角色，但是，也有人认为你应该瞄准数据分析师的角色。我应该先学习这些角色还是直接学习 ML？是的，我想成为一名 ML 工程师，但我也想找到一份入门级工作，不一定是我梦想中的工作，但对积累经验很有用。    提交人    /u/Dystrom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dpim1h/what_role_should_i_aim_first/</guid>
      <pubDate>Thu, 27 Jun 2024 04:24:28 GMT</pubDate>
    </item>
    <item>
      <title>我的模型是否过度拟合？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dp88sv/is_my_model_overfitting/</link>
      <description><![CDATA[      我正在使用 lstm 网络来预测股票价格，结果如下。 测试集指标： MAE：3.3516 MSE：19.5701 R2：0.9712 MAPE：0.0192 3 倍平均指标： MAE：1.7284 MSE：6.9064 R2：0.9962 我不确定我的模型是否过度拟合。我还附上了未来 30 天预测价格的图表。    提交人    /u/Electronic-Hotel7116   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dp88sv/is_my_model_overfitting/</guid>
      <pubDate>Wed, 26 Jun 2024 20:10:32 GMT</pubDate>
    </item>
    <item>
      <title>你们的 ML 工程师或 ML 研究人员拥有什么学位？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dp6or7/what_degree_do_you_ml_engineers_or_ml_researchers/</link>
      <description><![CDATA[考虑我的未来时，我非常好奇，我拥有数学学士学位，但还没有工作。  您可以放弃您所拥有的学位（学士、硕士、博士，计算机科学/数据科学/其他），以及您所担任的职位（机器学习工程师、研究员、学术界）吗？    提交人    /u/fyre87   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dp6or7/what_degree_do_you_ml_engineers_or_ml_researchers/</guid>
      <pubDate>Wed, 26 Jun 2024 19:06:30 GMT</pubDate>
    </item>
    <item>
      <title>我学习机器学习是不是在浪费时间？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1dp3n7s/am_i_wasting_time_learning_ml/</link>
      <description><![CDATA[我是计算机科学专业二年级学生。我从 14 岁起就开始编程。我曾担任后端 Web 开发人员一年，现在学习 ML 已有 2 年左右了。 这些是我的一些最新项目： https://github.com/Null-byte-00/Catfusion https://github.com/Null-byte-00/SmilingFace_DCGAN 但大多数 ML 工作至少需要硕士学位，大多数研究工作需要博士学位。我至少需要 5 到 6 年才能获得 ML 的入门级工作。而且很多人都涌入 ML，所以竞争太激烈了，我们无法预测那时的就业市场会是什么样子。即使我设法在 ML 领域找到一份工作，大多数入门级工作也只是部署现有模型并围绕它们构建应用程序，而不是实际设计模型。 自从大约 6 年前开始编码以来，我经历了许多不同的阶段。首先，我对网络安全非常感兴趣，当时我把所有时间都花在了 CTF 挑战上。然后我开始从事 Web 开发，在那里我得到了第一份（也是唯一一份）工作。我也有一个游戏开发阶段（像任何其他程序员一样）。现在大约 2 年来我一直在学习 ML。但我真的很困惑我要继续哪一个。你认为我应该怎么做？    提交人    /u/Soroush_ra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1dp3n7s/am_i_wasting_time_learning_ml/</guid>
      <pubDate>Wed, 26 Jun 2024 17:00:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>