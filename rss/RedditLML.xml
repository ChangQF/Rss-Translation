<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Fri, 23 Feb 2024 09:12:45 GMT</lastBuildDate>
    <item>
      <title>关于 ML 但 NLP-LM 专业化的 YouTube 频道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axw407/youtube_channel_about_ml_but_nlplm_specialization/</link>
      <description><![CDATA[大家好，我正在考虑开设一个有关 NLP 和 LLM 的 YouTube 频道。我正在考虑选择一个主题，解释其背后的理论，然后实施它。此外，创建端到端项目并将其部署在云上。我想创建 NLP 专业化以找到 NLP 工程师的工作。 有什么想法吗？   由   提交/u/Learning_DL  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axw407/youtube_channel_about_ml_but_nlplm_specialization/</guid>
      <pubDate>Fri, 23 Feb 2024 09:05:05 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习或微调</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axtl44/transfer_learning_or_fine_tuning/</link>
      <description><![CDATA[迁移学习和微调之间有什么区别以及何时使用什么？   由   提交/u/Professional_Skin432   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axtl44/transfer_learning_or_fine_tuning/</guid>
      <pubDate>Fri, 23 Feb 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用自定义语料库来使用/创建/扩展巨大的上下文？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axtheu/could_it_be_possible_to_usecreateextend_a_huge/</link>
      <description><![CDATA[嗨，超级新手。 我想知道我是否可以做这样的事情...... &lt;我有一个巨大的语料库。比如说，小说很少。我想将所有这些小说中的信息添加到模型中，最好是 LoRa 或 QLoRa 以某种方式，这样我就可以使用它作为上下文来提出问题。比如，这些小说中有多少角色是女性？并且它会吐出所有女性角色的名字？ 我能找到的所有资源都是基于数据集的训练。我显然必须提供背景和答案。但是我如何只将上下文输入到模型中，以便在后期进行推理？ 是否可以将上下文构建到模型中或像这样的 LoRa？ 我可以使用小型提示上下文执行类似的操作，但我的上下文需要类似于 1M+ 令牌。 提前致谢  &amp; #32；由   提交/u/TheHawkEy3  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axtheu/could_it_be_possible_to_usecreateextend_a_huge/</guid>
      <pubDate>Fri, 23 Feb 2024 06:12:56 GMT</pubDate>
    </item>
    <item>
      <title>一种新的时间序列问题（至少对我来说）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axseq5/a_new_kind_of_time_series_problem_atleast_for_me/</link>
      <description><![CDATA[我正在解决一个问题，我们有时间戳和事件数据（分类）。时间戳不统一，格式为 Fri 10th Jan 00:00:00 GMT 2010，并且存在不同类型事件的记录，其中时间戳甚至可以重复。  问题陈述是预测事件时间戳？！自从过去几周以来，这一直让我大吃一惊，理解这个问题真是令人费解。 任何指示或建议都会有很大帮助。   由   提交 /u/outsideofthefoot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axseq5/a_new_kind_of_time_series_problem_atleast_for_me/</guid>
      <pubDate>Fri, 23 Feb 2024 05:11:48 GMT</pubDate>
    </item>
    <item>
      <title>神经网络和替代方案的局限性</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axrgzl/limitations_of_neural_nets_and_alternatives/</link>
      <description><![CDATA[我们知道神经网络可以逼近任何连续函数。然而，下面的函数不是连续的：f(x) = 表示 x 所需的英语单词数。例如f(1.3)＝4，因为1.3是“十分之一又三”。我可以设计数据以使数字量成为一个特征，但我对可能更适合此问题的替代模型感兴趣。   由   提交 /u/chilltutor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axrgzl/limitations_of_neural_nets_and_alternatives/</guid>
      <pubDate>Fri, 23 Feb 2024 04:20:40 GMT</pubDate>
    </item>
    <item>
      <title>用于语法检查的 HMM，潜在问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axq6mf/hmm_for_grammar_checking_potential_issue/</link>
      <description><![CDATA[我想尝试从头开始制作一个用于词性标记的 HMM，我会将其扩展到语法检查。我知道语法检查器有更好的方法，但这只是一种学习体验和乐趣。我对 HMM 也不太了解，我可能说的东西可能不正确，或者这可能是一个愚蠢的问题。 我的想法是根据 POS 标签的序列进行基于规则的语法检查。我将通过 HMM 生成 POS 标签，然后强制执行具体的语法规则。例如，我会将 POS 标签分配给一个句子，然后执行以下检查（在许多检查中）：如果形容词位于名词后面，中间是否有连接动词？如果不存在，则该句子很可能包含错误。 但是，我知道 HMM 寻求最大化根据前一个标签的 POS 分配 POS 标签的概率。我主要担心的是，如果我只引入具有正确语法的句子，从而引入正确的 POS 标签序列，那么我的模型不会分配不正确的 POS 标签，并且我的基于规则的检查永远不会工作，因为每个 POS 标签都是有效的序列? 例如，取完整句子的这一部分：“他想要手表...”。这里的问题很明显，应该是“他想看……”。我想象的问题是，如果我的模型仅获取具有正确 VB-&gt;VB 转换的句子的数据，即第二个动词位于“ing”中，则第二个动词位于“ing”中。形式，或者第二个动词是不定式，等等...那么不正确的 VB-&gt;VB 转换（例如“他想要手表”）的概率不会是被解析为“NN VB NN”因为这种不正确的动词到动词的转换的概率为 0，因为它在数据中从未见过。在这种情况下，我假设该模型自“watch”开始以来采用 VB-&gt;NN 转换。也是一个名词，VB-&gt;NN 的概率非零 我不确定我是否想得太多，或者这是否有效。有任何修复吗？我想象平滑可以解决这个问题，因为它确保没有任何事情是 0 概率，而且我还考虑故意将语法不正确的句子引入数据集。是否可以坚持仅使用 HMM 并为语法检查器强制执行具体规则，或者我必须通过依赖项解析器之类的东西来运行它？   &amp; #32；由   提交/u/sean_kim0327  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axq6mf/hmm_for_grammar_checking_potential_issue/</guid>
      <pubDate>Fri, 23 Feb 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>在推理管道中使用 PyTorch 可视化实用程序</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/</link>
      <description><![CDATA[      在推理管道中使用 PyTorch 可视化实用程序 https://debuggercafe.com/using-pytorch-visualization-utilities-in-inference-pipeline/ ​  https://preview.redd.it/y5rc0xj1e8kc1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=cb3d5a561b481102201f4702895847fa6c9a564f  &amp; #32；由   提交/u/sovit-123  /u/sovit-123  reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axmy82/using_pytorch_visualization_utilities_in/</guid>
      <pubDate>Fri, 23 Feb 2024 00:39:35 GMT</pubDate>
    </item>
    <item>
      <title>论文的贡献和新颖性是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/</link>
      <description><![CDATA[我正在做我的论文。对于新闻文本分类，贡献是什么？我正在尝试使用数据集中的所有标签/类别，例如标题、文本、主题和日期。虽然大多数研究人员最多使用标题和文本。我知道主题和日期的贡献很小。但我仍然这么做了。这样就够了吗？   由   提交 /u/Kindly-Song5246    reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axm88z/what_could_be_contribution_and_novelty_in_thesis/</guid>
      <pubDate>Fri, 23 Feb 2024 00:08:06 GMT</pubDate>
    </item>
    <item>
      <title>Langchain 地图缩减</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axkz9u/langchain_map_reduce/</link>
      <description><![CDATA[我想知道 langchain 映射减少如何迭代地减少提示 例如，如果我们有一个 2k 的上下文大小和一个 8k 令牌提供输入 首先我们将 8k 映射到 4x2k 映射 然后假设这 4 个摘要导致 4x1k 输出时间摘要，我们如何为下一次迭代映射这些摘要 我们是否会将 2 个摘要放入一个摘要中，从而生成 2x2k 个令牌映射？ 或者我们是否会进一步总结每个 1k 输出，直到所有 4 个摘要组合起来小于 2k 上下文？  即第一次迭代后 2 个 llm 调用或 4 个 llm 调用？ 我真的找不到任何文档支持我清楚地回答任何一个问题   由   提交/u/proturtle46  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axkz9u/langchain_map_reduce/</guid>
      <pubDate>Thu, 22 Feb 2024 23:15:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MSE 被称为 L2 损失？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/</link>
      <description><![CDATA[它们不同。但是在这篇中等文章中：  损失是平均值输入图像与重建图像之间的平方误差，即L2损失。  在this 研究论文：  在 AE 中，每个数据点的目标函数由...给出，其中 || ·||表示任意距离函数。通常使用L2范数。  MSE是通常使用的损失，这让我相信论文表明它们是等价的。  ​ 为什么？   由   提交 /u/Exciting-Ordinary133    reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axgyle/why_is_mse_referred_to_as_l2_loss/</guid>
      <pubDate>Thu, 22 Feb 2024 20:35:25 GMT</pubDate>
    </item>
    <item>
      <title>2024 年业界最受 ML 工程师欢迎（也是最好）的技术堆栈是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/</link>
      <description><![CDATA[ 由   提交/u/Appropriate-Tip935   reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axfrb7/whats_the_most_popularand_the_best_tech_stack_for/</guid>
      <pubDate>Thu, 22 Feb 2024 19:50:03 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能创建一个结合定量数据和定性数据结果的模型？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axfhzk/is_it_possible_to_create_a_model_that_combines/</link>
      <description><![CDATA[我正在为我的学校创建一个项目，并希望创建一个模型，在考虑睡眠模式和社交媒体使用情况的情况下给出压力水平。 我找到了这些数据集 https://www. kaggle.com/datasets/laavanya/ human-stress-detection-in-and-through-sleep?resource=download（具有肢体运动、睡眠时间、快速眼动时间等功能） 和 &lt; a href=&quot;https://www.kaggle.com/datasets/monishakant/dataset-for-stress-analysis-in-social-media&quot;&gt;https://www.kaggle.com/datasets/monishakant/dataset-for -stress-analysis-in-social-media（有不同帖子的文本）我想知道是否可以创建这样的模型以及如何进行。   由   提交/u/xyratious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axfhzk/is_it_possible_to_create_a_model_that_combines/</guid>
      <pubDate>Thu, 22 Feb 2024 19:39:48 GMT</pubDate>
    </item>
    <item>
      <title>毫升数学</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1axbdz1/mathematics_for_ml/</link>
      <description><![CDATA[你好，我想学习 ML 的数学知识，但在搜索之后我很困惑从哪里开始，我听到有人说使用可汗学院，但确实如此我只是学习线性代数、统计和微积分的全部内容？  或者我在这些科目中学习哪些主题？我将不胜感激您的建议。   由   提交/u/BEE_LLO   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1axbdz1/mathematics_for_ml/</guid>
      <pubDate>Thu, 22 Feb 2024 16:58:26 GMT</pubDate>
    </item>
    <item>
      <title>Oxen.AI 明天的 Paper Club Zoom 电话会议将涵盖 Google 的文本到视频扩散模型 Lumiere（太平洋时间周五上午 10:00 - 10:45）</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ax4hc4/oxenais_paper_club_zoom_call_tomorrow_will_cover/</link>
      <description><![CDATA[Oxen.AI 明天的 Paper Club Zoom 电话会议将涵盖 Lumiere , Google 的文本到视频传播模型Oxen 的首席执行官 Greg Schoeninger 非常聪明，而且善于直言不讳。他主持通话。 （嘿，格雷格，你在 reddit 上吗？） 在 45 分钟的会议结束时，我觉得我已经很好地理解了一篇论文，可以将其添加到我的瑞士军刀工具“可能的艺术”中;了解在正确的时刻进行部署。我非常高兴听到格雷格对卢米埃尔的看法，看看其他与会者怎么说，并询问谁在聊天中发疯。 下周五，3 月 1 日，美杜莎与嘉宾主持人丹尼尔·瓦罗里-瓦西列夫斯基 (Daniel Varoli-Vasilevskiy) 会面。  p&gt; 要注册 Zoom 通话（需要批准）： https:// www.oxen.ai/community?utm_source=paper_club_flyer 未正式为 Oxen 发布此内容。我的观点是我自己的。我很感激他们为我提供了一种有趣而简单的方法，让我在每个周五的午餐期间消化一篇人工智能基础论文。帮助聊天和问答的 Oxen 团队、Ben、Scott、Adam 和我的好友团队实习生;-) 也很棒。他们创造了一些特别的东西。我尊重并钦佩他们所做的事情以及他们是如何做到的。 此外，我还遇到了一些很棒的人，我正在通过他们的 Discord 与我在新项目上结对 https://discord.com/invite/s3tBEn7Ptg ​   由   提交 /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ax4hc4/oxenais_paper_club_zoom_call_tomorrow_will_cover/</guid>
      <pubDate>Thu, 22 Feb 2024 11:44:20 GMT</pubDate>
    </item>
    <item>
      <title>你们感觉到了吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ax3odj/do_you_guys_feel_it/</link>
      <description><![CDATA[       由   提交 /u/AdelSexy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ax3odj/do_you_guys_feel_it/</guid>
      <pubDate>Thu, 22 Feb 2024 10:54:13 GMT</pubDate>
    </item>
    </channel>
</rss>