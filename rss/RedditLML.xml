<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>一个致力于学习机器学习的 subreddit</description>
    <lastBuildDate>Tue, 17 Sep 2024 21:15:13 GMT</lastBuildDate>
    <item>
      <title>机器学习学习之路！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fjaozm/machine_learning_study_path/</link>
      <description><![CDATA[大家好，我现在是一名 G12 学生，我即将完成我的申请，这意味着我每天都会有大量的空闲时间。我对机器学习很感兴趣，我想自学。我的目标是真正进入这个领域，也许在暑假找一份实习或项目。（我也认为这是我未来的职业）有人可以推荐我学习路径吗？我知道有很多，但它们大多差别很大。所以，根据我的基础（G12）和我的目标，有人可以推荐我一条学习路径吗（我更喜欢教科书而不是视频）    提交人    /u/Sure-Pain-8577   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fjaozm/machine_learning_study_path/</guid>
      <pubDate>Tue, 17 Sep 2024 20:59:06 GMT</pubDate>
    </item>
    <item>
      <title>了解 DvC 但寻找替代方案</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fja6kf/learning_about_dvc_but_looking_for_alternatives/</link>
      <description><![CDATA[我最近学习了一个关于 DVC 的精彩教程 (https://dvc.org/)。我真的很喜欢它的管道功能，其中每个阶段都由 yaml 文件和相关配置参数定义，并且它会根据生成的图表中的变化自动知道要运行什么。 但是由于各种原因，我不想要与 git 紧密耦合的东西。所以基本上，寻找具有类似功能但不需要 git 的工具。我隐约知道有各种 ML 管道工具，所以我假设这是可能的。谢谢！    提交人    /u/QuasiEvil   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fja6kf/learning_about_dvc_but_looking_for_alternatives/</guid>
      <pubDate>Tue, 17 Sep 2024 20:39:08 GMT</pubDate>
    </item>
    <item>
      <title>预测梦幻联赛的胜率</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj8wfm/predicting_winning_rate_in_a_fantasy_league/</link>
      <description><![CDATA[      我已经在一个网站上玩梦幻体育很长一段时间了，最​​近我意识到通过从网站收集相关数据，我可能能够预测哪些球队获胜的几率最高。我的目标是每天预测前 150 名球队，并从中找出最有可能赢得联赛冠军的球队。 挑战在于每天都会提供新数据，有 5,000 到 50,000 个球队，我需要每天进行预测和挑选球队。数据中的每一行代表一个不同的球队，我想专注于预测“实际”列，使用所有其他列作为特征。我有很多天的数据，但每一行都是一个不同的球队（我只学会了对房屋特征及其价格等数据集进行预测） 我对机器学习还比较陌生，虽然我很高兴将其作为一个学习项目来解决，但我正在努力寻找一种有效的方法来解决这个问题。我相信从事这项工作将帮助我培养技能并实现目标。 https://preview.redd.it/q6c0qppxbfpd1.png?width=1391&amp;format=png&amp;auto=webp&amp;s=0a3ca2336f0526cceeaca702affb20e094f0dd35    提交人    /u/ASHTaG0001   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj8wfm/predicting_winning_rate_in_a_fantasy_league/</guid>
      <pubDate>Tue, 17 Sep 2024 19:49:41 GMT</pubDate>
    </item>
    <item>
      <title>健全性检查句子-BERT</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj8d1m/sanity_check_sentencebert/</link>
      <description><![CDATA[大家好！ 我使用 Sentence-BERT 来查找句子相似度，方法是遍历句子并根据它们与另一篇文档中的句子的接近程度分配数字分数。这会产生一组相似度分数以及每个查询对应的最相似句子。最终目标是找出句子的“新颖性”。这一切都非常简单，现在对我来说效果很好。 问题出现在将论文与存储库进行比较时。在原始论文（Reimers, N., &amp; Gurevych, I. (2019, 11). Sentence-bert: 使用暹罗 bert 网络的句子嵌入。在 2019 年自然语言处理经验方法会议论文集。计算语言学协会。取自 https://arxiv.org/abs/1908.10084 ）中，我发现了以下描述（第 3984 页）： 处理 img rvl6a31q0fpd1... 使用 Python 实现和相应的存储库（https://www.sbert.net/examples/applications/cross-encoder/README.html) 我发现了这个例子： 处理 img 9iu2wngc1fpd1... 该 repo 还指出了以下内容：  &quot;Bi-Encoders 为给定的句子生成一个句子嵌入。我们将句子 A 和 B 分别传递给 BERT，从而得到句子嵌入 u 和 v。然后可以使用余弦相似度比较这些句子嵌入&quot;  这对我来说很清楚，但它也表明：  &quot;相反，对于 Cross-Encoder，我们将两个句子同时传递给 Transformer 网络。然后它产生一个介于 0 和 1 之间的输出值，表示输入句子对的相似性：Cross-Encoder 不会产生句子嵌入。此外，我们无法将单个句子传递给 Cross-Encoder。&quot;  这对我来说是违反直觉的。我以为我们正在像论文图 1 中那样传递句子。对我来说，论文写得很清楚，两种变体都会产生句子嵌入，但 Cross-Encoder 会采用元素差异，然后使用 softmax 来训练权重，以找到句子相似的概率。然后我在实现中使用这些预先训练的权重。Cross-Encoder 不会输出两个句子嵌入，但实际上，它使用句子嵌入在嵌入空间中产生距离度量。 下一个令人困惑的部分是，repo 的右图表明该过程的输出是二进制的。我第一次看到这个时，以为它想说 {0,1}，但事实并非如此。我想要的和我使用它时得到的都是 [0,1] 之间的数字。 我忽略了什么吗？！任何帮助我都会非常感谢。也许我没有理解一些重要的事情，我对此感到不舒服。    提交人    /u/Lazy_Price3593   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj8d1m/sanity_check_sentencebert/</guid>
      <pubDate>Tue, 17 Sep 2024 19:28:33 GMT</pubDate>
    </item>
    <item>
      <title>这样的学习曲线可能有什么解释吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj7fp3/possible_explanations_for_a_learning_curve_like/</link>
      <description><![CDATA[        提交人    /u/nvs93   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj7fp3/possible_explanations_for_a_learning_curve_like/</guid>
      <pubDate>Tue, 17 Sep 2024 18:53:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中在所有时间序列上滑动窗口？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj6paf/how_to_slide_a_window_on_all_timeserie_in_pytorch/</link>
      <description><![CDATA[嗨， 我目前正在尝试了解如何使用 Pytorch 使用 LSTM 进行时间序列预测。我基本上有 50 个长度为 100 的时间序列，每个时间序列都有 10 个输入，我想将它们用于学习。我还想使用长度为 5 的序列，以便使用最后 5 个值来预测下一个值。现在，我基本上以以下方式重塑我的输入张量：  包含所有形状为 (50, 100, 10) 的时间序列的 Numpy 数组 (时间序列、时间步长、输入)-&gt;形状为 (1000, 5, 10) 的张量 (batch_size、sequence_length、input_size)  这种方法似乎可以粗略地工作，但从技术上讲，它仅使用可用数据的一小部分，因为我将时间序列拆分为较小的窗口而不重叠。当使用神经网络评估新的时间序列时，这也会出现问题，因为缺乏重叠会导致预测不连续。 我该如何解决这个问题？我原本想在时间序列上滑动窗口而不是重塑，但我不知道如何进行…… 编辑：拼写错误    提交人    /u/Heimdell_Irsei   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj6paf/how_to_slide_a_window_on_all_timeserie_in_pytorch/</guid>
      <pubDate>Tue, 17 Sep 2024 18:24:28 GMT</pubDate>
    </item>
    <item>
      <title>适用于加载深度学习模型并运行推理的 Python 应用程序的廉价但性能不错的云托管平台？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj5q7d/cheap_but_decent_performance_cloud_hosting/</link>
      <description><![CDATA[我是一名大二学生，目前正在从事一个由 AI 驱动的移动应用程序项目。  我的计划是使用 Flutter 或 Kotlin（我最熟悉的两种语言）创建一个前端，然后使用 FastAPI 创建一个 Python 应用程序后端，并将其部署在云托管平台上，以便随时调用。 因此，这个 Python 应用程序加载了一个图像识别模型（大约 200mb）并使用 Google Vision API 进行 OCR（我为该服务付费）。 您建议在哪个云部署平台上部署我的 Python 应用程序，该平台以合理的价格提供不错的性能和速度？ 此外，如果您对我的架构提出建议或意见，我们将不胜感激。谢谢！    提交人    /u/AppropriateWork4011   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj5q7d/cheap_but_decent_performance_cloud_hosting/</guid>
      <pubDate>Tue, 17 Sep 2024 17:45:37 GMT</pubDate>
    </item>
    <item>
      <title>需要研究建议</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj4yrp/need_suggestions_on_research/</link>
      <description><![CDATA[大家好，我正在研究一个课题，其中我有不同的模型，这些模型具有相同的架构，但在不同的用户数据（序列数据）上进行训练，但我想对这些模型进行聚类。 我怎样才能做到这一点？ 我尝试使用模型参数，但它不起作用。 我的模型架构是 Transformer Autoencoder，它具有编码器和解码器，并提供重建错误作为输出。 任何建议都会有所帮助。 谢谢     提交人    /u/Potential_Plant_160   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj4yrp/need_suggestions_on_research/</guid>
      <pubDate>Tue, 17 Sep 2024 17:16:52 GMT</pubDate>
    </item>
    <item>
      <title>解释随机森林和xgboost</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fj0azj/explain_random_forest_and_xgboost/</link>
      <description><![CDATA[我知道这些模型被称为 bagging 模型，本质上是将数据分成子集并在这些子集上进行训练。我更想知道它背后的统计数据和现实世界的应用。 听起来你想用不同的参数和不同的子集构建许多这样的模型（例如 100 个），然后多次运行它们（再次运行 100 次），然后对结果进行概率分析。 这听起来对吗，还是我错了？    提交人    /u/Legal-Yam-235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fj0azj/explain_random_forest_and_xgboost/</guid>
      <pubDate>Tue, 17 Sep 2024 14:12:19 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的微积分变体</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fizh6k/calculus_variation_for_ml/</link>
      <description><![CDATA[      大家好！我正在学习 Bishop 的《深度学习和基础概念》中的机器学习。我看到了这个页面 (51)，其中解释了使用变化计算函数最大熵的示例。不幸的是，尽管我阅读了引用的附录 B，但我还是无法理解。有人能帮助我吗？非常感谢！    提交人    /u/ArlingtonBeech343   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fizh6k/calculus_variation_for_ml/</guid>
      <pubDate>Tue, 17 Sep 2024 13:37:24 GMT</pubDate>
    </item>
    <item>
      <title>我想开始学习机器学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fixw0y/i_want_to_start_learning_machine_learning/</link>
      <description><![CDATA[大家好，我刚从 IT 毕业，最近对非技术性的东西感兴趣，但现在，我对学习机器学习更感兴趣，我希望在 AI 领域建立一些东西，可能将其打造为一家初创公司的产品。但我对编码技能知之甚少，即 C 和 C++。请问您对我应该从哪里开始学习有什么建议，也许可以给我一些指导或建议。    提交人    /u/sophisticated0x   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fixw0y/i_want_to_start_learning_machine_learning/</guid>
      <pubDate>Tue, 17 Sep 2024 12:28:21 GMT</pubDate>
    </item>
    <item>
      <title>我如何为法学硕士 (LLM) 提供大量背景信息？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</link>
      <description><![CDATA[大家好！ 我的问题是如何向 LLM 提供超出提示的大量上下文信息。我想知道使用 RAG 是否可以做到这一点？目标是创建一个学习助手。LLM 需要大量有关学习内容（理想情况下是学习状态）的信息。理想的做法是提供完整聊天记录的上下文信息，而不是通过 RAG 为每个答案再次查询必要的信息并将其作为提示提供给 LLM。 除了在具有相应学习内容的数据集上训练 AI 或使用 RAG 查询信息之外，还有其他选择吗？    提交人    /u/Maleficent_Bus_994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fitoin/how_can_i_provide_a_large_amount_of_context_to_an/</guid>
      <pubDate>Tue, 17 Sep 2024 08:24:01 GMT</pubDate>
    </item>
    <item>
      <title>在家用电脑上运行 LLM：Llama 3.1 70B，压缩 6.4 倍，大小 22 GB</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</link>
      <description><![CDATA[大家好！想分享一些可能有助于您了解和试验 LLM 的内容。最近，我们使用 PV-Tuning 方法成功压缩了 Llama 3.1 70B 和 Llama 3.1 70B Instruct。 结果如下： - 压缩率：6.4 倍（从 141 GB 到 22 GB） - 质量保留：Llama 3.1-70B（MMLU 0.78 -&gt; 0.73），Llama 3.1-70B Instruct（MMLU 0.82 -&gt; 0.78） 我们实际上对 Llama 3.1 8B 模型做了同样的事情。根据[此](https://blacksamorez.substack.com/p/aqlm-executorch-android?r=49hqp1&amp;utm\_campaign=post&amp;utm\_medium=web&amp;triedRedirect=true) 工作证明，它现在可以在 RAM 少于 2.5 GB 的 Android 上运行。因此，您现在可以离线部署它，而无需共享您的数据。  您可以在此处找到结果并下载压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-AQLM-PV-2Bit-1x16-hf https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-8B-Instruct-AQLM-PV-2Bit-1x16-hf    提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fisec0/run_an_llm_on_your_home_pc_llama_31_70b/</guid>
      <pubDate>Tue, 17 Sep 2024 06:57:47 GMT</pubDate>
    </item>
    <item>
      <title>学习机器学习的书籍</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</link>
      <description><![CDATA[这篇帖子是我对 reddit 不让我评论某人帖子的报复。他们是一名想要学习机器学习的物理学毕业生。因此，这些建议适用于已经拥有扎实数学基础（熟悉并能解决线性代数和概率论问题）的人。 机器学习领域分为许多领域，但最突出的是深度学习、计算机视觉和自然语言处理。如果您想要深入研究某个特定领域，我或其他人肯定可以提供更具体的建议，话虽如此，已经有一些通用书籍出版，旨在涵盖AI（人工智能）的广度，其中最好的两本是-  深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书可从此处免费获取） 人工智能：一种现代方法（pearson.com）  这两本书试图涵盖人工智能领域的所有内容。虽然第一本书能让你真正理解和欣赏人工智能创新背后的启发式和直觉思维，但第二本书只会让你意识到人工智能思维的起源，可以追溯到亚里士多德。 现在，以上两本书都不会给你实践课程，我不推荐“实践”书籍。事实上，机器学习算法非常容易实现，只需几行 python/c++（一个算法可能需要 10 行到 100 行代码 - 无论如何都不是很多）。所以，一个好的策略是先学习 python（如果你还没有）-&gt;了解该领域并学习数学（并行），然后在学习 pytorch 的同时实现每个算法。既然你已经了解数学，我建议你阅读深度学习（自适应计算和机器学习系列）：Goodfellow，Ian，Bengio，Yoshua，Courville，Aaron：9780262035613：Amazon.com：图书。 （电子书免费这里）和/或我下面要提到的书籍。 下面的书都不是废话，只是数学和可视化书籍，作为物理学毕业生，你可能很容易理解。  计算智能：方法论介绍 | SpringerLink（我最喜欢的一本介绍神经网络、进化算法和模糊逻辑的书）。 （免费）模式识别和机器学习 (microsoft.com)（广受好评的“统计学习方法”书籍。 （免费）深入学习 — 深入学习 1.0.3 文档 (d2l.ai)（迄今为止学习深度学习的最佳书籍）。它有理论和代码）。  基于相关领域的其他书籍：  计算机视觉：算法和应用，第二版。 （szeliski.org） 计算机视觉：一种现代方法：Forsyth，David，Ponce，Jean：9780136085928：Amazon.com：图书  （注：CV（我认为通过视频课程学习计算机视觉效果更好）  统计自然语言处理基础（stanford.edu） 强化学习（mit.edu）     由   提交  /u/reacher1000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1fipadd/books_to_learn_machine_learning/</guid>
      <pubDate>Tue, 17 Sep 2024 03:56:40 GMT</pubDate>
    </item>
    <item>
      <title>机器学习相关的简历审查帖</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[请礼貌地将任何关于简历审查的帖子重定向到这里 对于那些正在寻找简历审查的人，请先在 imgur.com 上发布它们，然后将链接作为评论发布，或者甚至先在 /r/resumes 或 r/EngineeringResumes 上发布，然后在此处交叉发布。     提交人    /u/techrat_reddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>