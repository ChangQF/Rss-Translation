<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>致力于学习机器学习的 Reddit 子版块</description>
    <lastBuildDate>Wed, 15 May 2024 21:14:51 GMT</lastBuildDate>
    <item>
      <title>为什么人工智能在医学成像（例如组织病理学）领域如此饱和？为什么人工智能在分子生物学（蛋白质折叠除外）方面的探索如此之少？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</link>
      <description><![CDATA[我从事涉及生物医学研究人工智能的项目，令我震惊的是为什么有这么多涉及医学成像人工智能的论文/项目，尤其是计算病理学（或放射学）？是因为这个领域的需求（即医院对患者进行活检的组织病理学）吗？ 为什么我感到困惑的是，组织病理学，例如全切片图像分析，是一个资源密集型领域问题 - 典型的 WSI（整个幻灯片图像）需要大约 10GB 才能加载，因此训练模型可能需要几天甚至几周的时间。更不用说您必须将图像转换为更小的补丁，然后应用多实例学习等方法来聚合每个补丁的图像嵌入以获得最终预测。然后你必须看看哪些补丁对疾病很重要（通过注意力图之类的东西），然后你需要领域专家/专业知识来了解模型是否专注于图像的正确部分以进行预测。  然而，自 2020 年以来，该领域发表了如此多的论文，可能有数千篇，跨越 NeurIPS/ICLR/ICML、CVPR/ECCV/ICCV、MICCAI（专门针对我想知道这是否是因为很多来自计算机视觉领域的人想要解决一个更困难的问题（涉及非自然图像？） 然后我我还很困惑为什么分子生物学，尤其是 DNA/RNA/表观基因组学（不包括蛋白质结构/折叠）的 ML 工作少得多、少得多？对于分子生物学来说，几乎所有的焦点似乎都集中在新 AlphaFold 3 的蛋白质折叠/结构上，但除此之外，RNA/DNA/表观基因组学在很大程度上被忽略了？也就是说，在 2023 年底到 2024 年初，只有最近一波关于单细胞 RNA 测序基础模型（如 scGPT/Geneformer 等）的论文？是因为在分子生物学模式中进行良好的分析需要更多的领域知识，而拥有这些知识的人却很少吗？尽管分子生物学数据集（尤其是 RNA 测序）的计算强度通常比医学成像（如组织病理学）低得多？   由   提交/u/EcstaticAd162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/</guid>
      <pubDate>Wed, 15 May 2024 21:09:03 GMT</pubDate>
    </item>
    <item>
      <title>自动纸张转视频通道</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csuzho/automatic_paper_to_video_channel/</link>
      <description><![CDATA[https://youtu.be/8FPHwhNg_ns?si =aRmqPGlJytvGXlpk   由   提交 /u/This_is_crazy_bunch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csuzho/automatic_paper_to_video_channel/</guid>
      <pubDate>Wed, 15 May 2024 20:31:10 GMT</pubDate>
    </item>
    <item>
      <title>和我来自滑铁卢的朋友一起建造一辆主要的自动驾驶汽车，有人可以帮助确保我们走在正确的轨道上吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csud0q/building_a_primary_selfdriving_car_with_my_friend/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csud0q/building_a_primary_selfdriving_car_with_my_friend/</guid>
      <pubDate>Wed, 15 May 2024 20:05:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要人工智能作为财务顾问？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csu4ne/why_do_we_need_ai_as_a_financial_advisor/</link>
      <description><![CDATA[强调以下好处：这是我的个人案例研究，但您可能不同意我的观点！ 预算规划：人工智能比您自己更深入地分析您的消费习惯。这会带来您无法手动发现的定制建议和见解。此外，它可以在几秒钟内处理大量的财务数据，例如预算计划、支出分析和储蓄建议。  另外，我想提一下对抗冲动购买的斗争。人工智能消除了通常与人类预算相关的情感支出触发因素。它坚持数据，促进财务纪律。  这是您可以使用的提示： “创建预算”适合我的收入和消费习惯的模板。我想要一些可以轻松跟踪和修改的东西。”  会计和税务合规性：现代平台实时跟踪税务规则和立法的变化，提醒您可能影响您生活和工作的更新。这降低了不合规和潜在处罚的风险。如果你智能地设置你的助手，在某些情况下你甚至可以防止出现问题。  而且，与真正的财务顾问不同，人工智能平台明显更便宜并且每天 24 小时可用，每周 7 天。  这是您可以使用的提示： “解释关键财务比率以及如何计算它们。提供如何使用它们来评估我的业务健康状况的示例。”  投资管理：人工智能在交易中变得越来越重要，因为金融家使用算法进行交易。如果最好的专家都在使用它，我们为什么不应该呢？人工智能平台经过大量数据的训练，使我们能够识别人类可能错过的模式。这有助于确保财务数据的完整性并减少代价高昂的错误。  此外，一些平台可以评估风险承受能力、财务目标和市场状况，以生成定制的投资组合管理建议。  这是您可以使用的提示： “总结当前的经济形势。突出显示关键指标（例如通货膨胀、利率、GDP）及其对我的投资组合的潜在影响。”  这些观点得出了一个关于一个基本优势的共同结论：数据驱动的自动化。人工智能可以快速处理日常和耗时的任务，使我们能够做出更明智的决定或腾出时间进行更愉快的活动。   由   提交/u/AI_technologies  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csu4ne/why_do_we_need_ai_as_a_financial_advisor/</guid>
      <pubDate>Wed, 15 May 2024 19:55:53 GMT</pubDate>
    </item>
    <item>
      <title>使用我自己的数据集的 CNN 模型。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cstle8/cnn_model_using_my_own_dataset/</link>
      <description><![CDATA[      我使用 python 中的tensorflow 和 keras 库创建了一个 CNN 模型。我创建了自己的数据集。该数据集由 4 种生物信号变体组成。每个都是一个单独的动作。例如，1 个文件夹包含 92 个单个操作实例。然后我编写了一些代码将所有这些编译成数据集以插入 cnn 模型。我对 ML 及其所需的所有各种输入非常不熟悉，但我需要在接下来的几天内运行它以查看某种准确性的输出等。我将在下面提供我的代码。同样，使用的数据是 MFCC。对每个信号进行 MFCC 特征提取，形成一种“图像”，供 cnn 模型进行训练。 第一张图片是代码迭代每个单独的文件夹并创建一些数据集。第二个是模型本身（这是相当不确定的，因为我对其中的大部分都不熟悉）。最后是进口。我知道它看起来像Python不接受2个导入，但在尝试了一堆东西并谷歌搜索之后，我发现它是张量流本身的一个问题，即使它说它没有找到等，它也应该可以正常工作。 我会很感激任何提示，因为我的时间很短，我希望在接下来的几天内完成这项工作。我对机器学习非常陌生，这是我第一次编码这样的东西，所以我努力尝试调试并获得任何形式的输出！提前致谢：3 https： //preview.redd.it/gg6lede67n0d1.png?width=803&amp;format=png&amp;auto=webp&amp;s=85966b5df859042aa9547d4d31c4c156d89e3f14 https://preview.redd.it/jj7x9zs67n0d1.png?width=580&amp;format=png&amp;auto=网页&amp; s=2cc556f377574091f3e4ac4a2f9993e7a3bb989d  https://preview.redd.it/e2z9s4777n0d1.png?width=784&amp;format=png&amp;auto=webp&amp;s=4cc73d85eeb256d37e60c7c8a3da84ee41e057d9  &amp; #32；由   提交 /u/Alive_Local_2000   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cstle8/cnn_model_using_my_own_dataset/</guid>
      <pubDate>Wed, 15 May 2024 19:33:42 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 合著者 Łukasz Kaiser (OpenAI) 在刚刚发表的这篇演讲中讨论了 GPT-4o 之外的法学硕士的未来。他说，使用较少/高效检索的强化学习数据进行训练是关键。一位前 Google Brain 同事随后展示了良好的检索与法学硕士是如何交织在一起的！想法？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cssewe/łukasz_kaiser_openai_transformer_coauthors/</link>
      <description><![CDATA[       由   提交/u/muditjps   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cssewe/łukasz_kaiser_openai_transformer_coauthors/</guid>
      <pubDate>Wed, 15 May 2024 18:44:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用不在其中心的 HuggingFace 模型将句子列表编码为嵌入？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1css2ix/how_do_i_encode_a_list_of_sentences_into/</link>
      <description><![CDATA[我正在尝试将句子列表编码为嵌入列表。当我使用 HuggingFace 中心中的模型时，它按预期工作。但是，当我使用不在中心中的模型时，在本例中是 Facebook 的 M2M100 模型，我没有得到预期的结果。 当在 SentenceTransformer( )，我的结果如下所示： from Sentence_transformers import SentenceTransformer dat = [&#39;陨石落在路上&#39;, &#39;我走错了方向&#39;] model_1 = SentenceTransformer( &#39;all-distilroberta-v1&#39;) embeddings_1 = model_1.encode(dat) embeddings_1.shape &gt; (2, 768)  但是，当我使用 M2M100 模型时，我的结果看起来根本不正确，具体来说，我期望有 2 行结果：  from Transformers import M2M100Tokenizer model_m2m = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) model_m2m.src_lang = &quot;en&quot;; embeddings_m2m = model_m2m.encode(dat, return_tensors=“pt”) embeddings_m2m.shape &gt; torch.Size([1, 4])  我应该如何格式化它，以便它返回一个 n 维嵌入列表，其中每行对应一个句子和列数等于嵌入的维数？ （请注意，最终我将对其他语言的句子执行此操作，这就是我使用多语言模型的原因。）   由   提交 /u/YourWelcomeOrMine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1css2ix/how_do_i_encode_a_list_of_sentences_into/</guid>
      <pubDate>Wed, 15 May 2024 18:30:47 GMT</pubDate>
    </item>
    <item>
      <title>你会把它训练到另一个时代吗？微调 LLM 以进行总结。损失高原很快进入第一个时期。性能还可以，但是这是典型的吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</link>
      <description><![CDATA[        由    /u/grey-seagull   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csrnog/would_you_train_it_for_another_epoch_finetuning/</guid>
      <pubDate>Wed, 15 May 2024 18:15:48 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何LLM模型或方法可以通过从互联网获取最新信息来回答问题？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cspsc4/are_there_any_llm_model_or_approach_that_answers/</link>
      <description><![CDATA[标签：[讨论] 我正在构建一个使用自定义数据进行 RAG 的 LLM 模型。我想改进这一点。如果代理/模型无法根据信息回答，我希望它通过互联网查找并为我获取最新数据。 我已经使用 Mistral 和 BGE 通过 RAG 构建了基本模型。请分享您的想法   由   提交 /u/AltruisticPudding634   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cspsc4/are_there_any_llm_model_or_approach_that_answers/</guid>
      <pubDate>Wed, 15 May 2024 16:59:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 NLP 构建将职位名称与标准化角色相匹配的模型的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cspfbh/whats_the_best_approach_to_building_a_model_to/</link>
      <description><![CDATA[我工作的一小部分涉及获取客户的员工数据集，并根据角色的头衔将他们的职位映射到标准化头衔列表、在层次结构中假定的位置以及薪水。例如，“财务助理”之类的内容。将映射到我们的标准化角色“会计文员”或“服务台代理”可能会映射到我们的“客户服务代理”角色。  我有一个 CSV 文件，其中包含 280 个标准化标题以及每个标题的简要说明。虽然过去的数据不是那么准确，但我也有公司头衔到每个标准化角色的过去映射。  我目前正在探索完成这项任务的最佳方法。以前，有人建议我不要为此使用法学硕士，但后来我了解了检索增强生成（RAG），并想知道它是否适用于此。我正在考虑使用 BERT，但如果更高级的模型能够提供更好的准确性，我愿意接受建议。 以下是我想到和遇到的一些想法  使用 BERT（无壳或大型）进行语义理解，也许使用 GPT-3 嵌入更多的上下文理解（对于类似的角色可能会有所帮助，例如合规官与供应商等不同）连锁官）。目标是实现高精度的映射。 考虑使用某种 RAG（可能通过 Langchain）从描述中获取额外的上下文信息。  是否有其他模型或方法可能更适合这种语义和上下文匹配？期待反馈。   由   提交 /u/MountainBlock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cspfbh/whats_the_best_approach_to_building_a_model_to/</guid>
      <pubDate>Wed, 15 May 2024 16:44:20 GMT</pubDate>
    </item>
    <item>
      <title>Swiftui 和 Tensorflow Lite</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csnquz/swiftui_and_tensorflow_lite/</link>
      <description><![CDATA[为什么我找不到有关如何在 swift 和 SwiftUI 中使用 Tensor Flow lite 的教程？我想要一个有用的应用程序，我发现的唯一的东西是 4 年前用于对象检测的，但实际上没有用！我想了解如何在 swift 和代码上使用 tensorflow lite，以便在 iOS 上实际使用机器学习！    由   提交 /u/Still-Expression-203   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csnquz/swiftui_and_tensorflow_lite/</guid>
      <pubDate>Wed, 15 May 2024 15:33:54 GMT</pubDate>
    </item>
    <item>
      <title>了解分类评估及其指标：从偏差和普遍性到准确性、宏观 F1、MCC 等指标</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</link>
      <description><![CDATA[大家好！ 一个在我的工作中一次又一次出现的话题（当做自己的研究，阅读论文时，以及教学时）：选择哪种分类评估指标？或者：为什么论文使用度量 x 进行评估（而不是 y）？以及其他类似问题。  多年来我一直在做一些笔记，现在我已经完成了一篇文章。我想也许这对你们中的一些人来说很有趣，为什么不分享它： https://arxiv.org/abs/ 2404.16958 这是摘要：  分类系统在无数论文中进行了评估。然而，我们发现评估实践往往是模糊的。通常，指标的选择是没有争论的，模糊的术语会引起误解。例如，许多作品使用所谓的“宏观”指标对系统进行排名（例如“宏观 F1”），但没有明确说明他们对这种“宏观”指标的期望。这是有问题的，因为选择一个指标可能会影响论文发现以及共享任务排名，因此应该最大限度地提高过程中的清晰度。从偏见和普遍性的直观概念出发，我们考虑论文中表达的期望，对常见的评估指标进行分析。有了对指标的透彻理解，我们调查了自然语言处理最近共享任务中的指标选择。结果表明，指标选择通常没有令人信服的论据支持，这个问题可能使任何排名看起来很武断。这项工作旨在为更明智和透明的指标选择提供概述和指导，促进有意义的评估。   一些关键观察结果是：  通常，并不完全清楚为什么在案例中使用特定指标。&lt; /li&gt; 通常也不太清楚什么是“元度量”。属性由“宏观度量”中的“宏观”等术语隐含。然而，一个反复出现的愿望是指标应该引起某种“平衡”。  为了澄清这些问题，我们分析了一些流行的指标及其属性。一些见解是：  许多指标可以用分类器偏差和类流行率来更简单地编写。 有两个指标称为宏 F1（！）。他们的衡量标准也截然不同。另一方面，Kappa 和 MCC（马修斯相关系数）有点相似。 Macro Recall 有一个直观的解释：这是一系列与公平的赔率。这是唯一一个对班级流行率变化完全不变的指标（以防万一我们希望如此）。  最后，如果只有一个结论绘制，那么我想这是没有整体完美的指标，并且应该始终在给定特定上下文的情况下明智地选择指标。希望我的工作能对此有所帮助。   由   提交/u/juopitz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cslfus/understanding_classification_evaluation_and_its/</guid>
      <pubDate>Wed, 15 May 2024 13:56:40 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的随机深度解释</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/research_pie  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csklcz/stochastic_depth_for_neural_networks_explained/</guid>
      <pubDate>Wed, 15 May 2024 13:17:52 GMT</pubDate>
    </item>
    <item>
      <title>2024/2025年学习基础NLP投资回报率低吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</link>
      <description><![CDATA[就上下文而言，我目前正在学习 MSCS，有一门 NLP 课程，但它不会像 PHD 级别那么深（显然），所以我我想知道 NLP 的原始教育还值得学习吗？我不认为我会成为一名“机器学习工程师”  我们学习了非常早期的情感分析方法，例如在没有库的情况下通过手动逻辑回归按频率分配权重。如今，ChatGpt 或 Gemini 使用的算法比这些算法聪明 1000 倍，我真的很怀疑我所学的东西在我毕业后是否有任何价值。我可以简单地调用 openai api 和一些 numpy 库来在几秒钟内完成我正在学习的所有内容。不要误会我的意思，我认为这些算法非常迷人且很酷，但我更想研究一些很酷、有用且投资回报率高的东西（例如网络）。 TLDR 关于如何进行基本学习的一些见解NLP 可以帮助技术领域的职业发展，本页的专家将非常感激 &lt;3 编辑：我感谢专家们的见解。真正有帮助的是了解学习传统方法不应该仅仅从表面上看，并且具有一定的可扩展性irl   由   提交/u/Flash77555  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1cscauk/is_learning_basic_nlp_in_20242025_low_roi/</guid>
      <pubDate>Wed, 15 May 2024 04:24:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLaVA 将图像转为文本</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1csbrpe/image_to_text_using_llava/</link>
      <description><![CDATA[      我第一次尝试使用大型语言和视觉助手 (LLaVA) 生成图像描述。     提交人    /u/justwantstoknowguy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1csbrpe/image_to_text_using_llava/</guid>
      <pubDate>Wed, 15 May 2024 03:54:10 GMT</pubDate>
    </item>
    </channel>
</rss>