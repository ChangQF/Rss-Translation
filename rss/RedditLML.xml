<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>学习机器学习</title>
    <link>https://www.reddit.com/r/learnmachinelearning/</link>
    <description>欢迎来到R/LearnMachineLearning-一个学习者和教育工作者对机器学习充满热情的社区！这是您提出问题，共享资源并共同发展的空间，从理解ML概念到从基本原理到高级技术。无论您是写第一个神经网络还是潜入变压器，都可以在这里找到支持者。用于ML研究， /R /MachineLearning用于简历审查， /R /工程介绍ML工程师， /r /mlengineering</description>
    <lastBuildDate>Sat, 22 Feb 2025 09:16:39 GMT</lastBuildDate>
    <item>
      <title>嗨，很高兴认识你</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivegdw/hi_its_nice_to_meet_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是MEC的第一学期学生，我可以在这里了解MLS，AI以及可能的数据科学，以了解Robotics Field的未来机会。我想加入这个社区，以便在分享我的疑问并以某种方式帮助他人之后，我可以在社区中建立宝贵的联系。我真的没有使用Reddit，通常是从社交媒体上脱离电网的，因为某些人似乎是一个缺点，但是从我的角度来看，感觉就像是更多的时间来投入生产时间。有时候我可能会很多，但我保证要保持很小的东西。我有一个复杂的过去，但我不让它定义我选择的路径。在我的生命结束时，我希望改变世界，我想通过使用技术和科学来对人们的生活进行良好的改变。会有跌宕起伏，我知道我会失败很多，但是我会从错误中成长出来，成为一个更好的人。我还没有在生活中进行任何Reddit社区的介绍，因此请原谅我，如果我犯了任何错误，下次我会努力。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/advertisingVisible70     [link]      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivegdw/hi_its_nice_to_meet_you/</guid>
      <pubDate>Sat, 22 Feb 2025 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>担心在ML或AI中找到工作。</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivds76/worried_about_getting_job_in_ml_or_gen_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是来自南亚的上一年度CS学生（不是印度），这里大约没有ML角色可用的工作（在大多数人中我在一些跨国公司中看到了1或2个角色，这些公司还需要3-5个YOE的大量研究获得主人的计划在明年的欧洲。并至少开始典型的软件工程（我有个人财务危机）。现在，我的区域中的开口更少]    &lt;！ -  sc_on-&gt;＆＃32; /www.reddit.com/user/ok_group_1771“&gt;/u/ok_group_1771     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivds76/worried_about_getting_job_in_ml_or_gen_ai/</guid>
      <pubDate>Sat, 22 Feb 2025 07:57:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同的电子商务网站上准确匹配被刮擦的产品？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivdnwl/how_to_accurately_match_scraped_products_across/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用一个从各种电子商务网站上刮下产品的价格比较平台。目的是将相同的产品（包括它们的变体）匹配不同站点，以帮助客户比较价格。 我首先研究了字符串相似性方法，例如Levenshtein Dance，Jaccard，Jaccard和Sørensen-dice。他们有点工作，但并不总是会在产品名称上遇到细微的差异。然后，我偶然发现了Bert和类似的模型，以获得语义相似性。这听起来很有希望，但我不确定这是否是适合工作的工具，或者在我的情况下如何使其最有效。刮擦的数据看起来像   {title;：＆quot示例产品标题&#39; -16C1733A057A; ＆quot“ mrp”：130，“价格”：118}]，“ url”：; }   所以我想知道伯特非常适合匹配产品名称和变体吗？如果是这样，我该如何优化我的用例？  ps：我真的没有深度的AI背景（我主要是后端工程师），所以任何动手的建议或解决此问题的实用方法将很有帮助。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/say-ad-8018     [link]  &lt;a href =“ https://www.reddit.com/r/lealenmachinelearning/comments/1ivdnwl/1ivdnwl/how_to_accuratery_match_scraped_products_across/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivdnwl/how_to_accurately_match_scraped_products_across/</guid>
      <pubDate>Sat, 22 Feb 2025 07:48:41 GMT</pubDate>
    </item>
    <item>
      <title>我在哪里可以学习深度学习</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivayrv/where_can_i_learn_deep_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道一些基本的ML算法，想深入学习。您能否分享您用来学习深度学习的资源（理论和实用），谢谢！..   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1ivayrv/where_can_i_ileln_deep_learning/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivayrv/where_can_i_learn_deep_learning/</guid>
      <pubDate>Sat, 22 Feb 2025 04:54:01 GMT</pubDate>
    </item>
    <item>
      <title>LLDMS：LLMS的扩散</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1ivaxe0/lldms_diffusion_for_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  提出了一种用于LLM培训的新体系结构，称为LLDMS，它使用扩散（主要用于图像生成模型）进行文本生成。第一个模型LLADA 8B看起来不错，并且与Llama 8b和Qwen2.5 8b相当。在这里了解更多信息： https://youtu.be/ednvmx1fria?si = xau = xau2zya1iebdmasd  ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mehul_gupta1997       [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1ivaxe0/lldms_diffusion_for_llms/</guid>
      <pubDate>Sat, 22 Feb 2025 04:51:51 GMT</pubDate>
    </item>
    <item>
      <title>天气应用程序具有州管理的长期运行对话，使用AI代理</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iv8fez/weather_app_with_state_management_for_long/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  构建一个具有高级状态管理的天气应用程序，用于无缝长期互动  全文    https://i.redd.it/yo8f4ogoqlke1.gif  P&gt;我构建了一个使用Langgraph和Groq API的天气应用程序来创建一个天气助手，以记住您以前的问题。该应用程序演示了如何为AI助理实施状态管理，从而允许自然对话在多个交互之间维护上下文。该代码显示了如何构建基于图的代理，该代理可以使用搜索工具并在数据库中坚持对话历史记录。  简介 当聊天机器人忘记刚才谈论的内容时，您是否曾经感到沮丧？我建立了解决该问题的解决方案。这位天气助理记得您的整个对话，让您自然地提出后续问题。如果您问“纽约的天气是什么？”然后“明天怎么样？”，它知道您仍在谈论纽约。   这篇文章是什么？ 本文逐步通过使用现代工具和技术来建立一个状态的AI助手。我创建了一个简化的Web应用程序，用户可以在其中询问有关世界任何地方天气的问题。使这个助手与众不同的是它在整个对话中保持上下文的能力。 幕后，我正在使用langgraph创建一个灵活的代理体系结构：  记住使用SQLite存储的对话历史记录 使用Tavyily搜索API查找实时天气信息 用Groq的Llama-3.3-70B模型为自然语言的理解提供支持 通过简化的UI提供了一个干净的UI   应用程序通过每次交互时传递一个唯一的对话ID，从而使其可以从数据库中检索过去的消息。即使用户关闭浏览器并稍后返回。 为什么要阅读它？  AI正在改变企业与客户的互动方式。根据行业报告，到2025年，AI将处理95％的客户互动。本文展示了我们虚构的“天气应用程序”是如何的。可以实施现代对话型AI：  提供更自然的人类互动 通过保持上下文来减少用户的挫败感 秤来处理许多同时处理许多同时对话 为更复杂的AI助手创造基础支持，以及上下文对话改善用户体验的任何应用程序。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aniketwork     [link]        [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iv8fez/weather_app_with_state_management_for_long/</guid>
      <pubDate>Sat, 22 Feb 2025 02:32:46 GMT</pubDate>
    </item>
    <item>
      <title>我想在COLAB上导入Metatrader5，但不能，我可以导入任何网站并训练我的模型吗？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iv8c0d/i_want_to_import_metatrader5_on_colab_but_cantare/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/badboyhalo1801      ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iv8c0d/i_want_to_import_metatrader5_on_colab_but_cantare/</guid>
      <pubDate>Sat, 22 Feb 2025 02:27:49 GMT</pubDate>
    </item>
    <item>
      <title>现在，您可以仅使用5GB VRAM在本地培训自己的推理模型！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iv6ljc/you_can_now_train_your_own_reasoning_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！非常感谢2周前我们的GRPO版本的支持！今天，我们很高兴地宣布，您现在只需5GB VRAM即可训练自己的推理模型，qwen2.5（1.5b） - 从上一不舒服释放！ GRPO是DeepSeek-r1背后的算法及其训练的方式。  GRPO的最佳部分与较大的型号相比，训练小型型号与更快的速度相比无关紧要与较大模型相比，训练时间将非常相似！您也可以在执行其他操作的同时将GRPO培训在PC的背景中运行！  这要归功于我们新派生的高效GRPO算法，该算法可启用  10x更长的上下文 长度时，使用 少90％的VRAM  与所有其他GRPO Lora/Qlora实现，甚至是利用那些Flash注意力2（FA2）。 使用TRL + FA2，Llama 3.1（8b）训练在20K上下文长度上需要510.8GB的VRAM。但是，Unsploth的90％VRAM减少将要求降至同一设置中的54.3GB。 我们利用我们的梯度检查点我们前一段时间发布的算法。它可以巧妙地将中间激活卸载到系统RAM异步，同时仅慢1％。  这将刮去372GB VRAM  ，因为我们需要num_generations = 8。我们可以通过中间梯度积累进一步减少此内存使用。 尝试我们的免费GRPO笔记本带有10倍更长的上下文：COLAB上的Llama 3.1（8b）  博客有关该算法的更多详细信息，数学在GRPO的背后，我们发现的问题等等： https://unsloth.ai/blog/grpo     grpo VRAM分解：      metric   n&gt; unsploth   trl + fa2         训练内存成本（GB）  42GB   414GB  在/tr&gt;  推理成本（gb）  0gb   16GB     to 20k上下文的推理kv缓存（gb）   2.5gb &lt; /td&gt;  2.5GB    总存储器用法   54.3GB（减少90％）    510.8GB      &lt; /tbody&gt;   现在我们还为所有奖励功能提供完整的记录详细信息！以前我们只显示了总汇总函数本身。 您现在可以运行并使用我们的 4-bit动态量子直接在vllm中。 我们也花了很多时间在GRPO +奖励功能/验证器上的所有内容上，所以强烈建议你们阅读它： docs.unsloth.ai/basics/reasoning       &lt; &lt; P&gt;再次感谢大家的所有支持，对我们来说确实意味着很多！我们还将在接下来的几周内发布一个重大版本，我知道你们一直在等待 - 我们也为此感到兴奋。 🦥  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/yoracale     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iv6ljc/you_can_now_train_your_own_reasoning_model/</guid>
      <pubDate>Sat, 22 Feb 2025 00:43:02 GMT</pubDate>
    </item>
    <item>
      <title>DataQuest：我应该如何在个人资料上组织项目？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iv6kj7/dataquest_how_should_i_organize_my_projects_on_my/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  标题校正：我应该如何在我的投资组合中组织项目（在我的个人资料上不是“）”  大家好，  不确定这是否是正确提出此问题的正确子，或者是否有一个更合适的子，因此，如果它不合适，我深表歉意。 我是一个Java开发人员，我一直在学习机器学习和数据科学，只是为了在DataQuest上的娱乐。我发现自己真的很喜欢它，我正在考虑转变职业。 我一直在做所有项目（数据科学轨道），并且想知道：炫耀这些的最佳方法是什么项目，并且潜在的雇主甚至看他们吗？ 一开始，我将它们全部分为一个github存储库，称为“ dataquest_projects＆quots”，每个项目都在其自己的文件夹中，每个项目都在项目是其自己的git分支，后来我在完成该分支机构时将我合并到主分支中。 ，但现在我想知道这是否是正确的方法。我应该将未来的项目分为自己的存储库吗？ 最重要的是，这甚至值得吗？没有其他使用DataQuest的人完成这些相同的项目？ 谢谢您的所有答案  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/abject_seesaw_1877      &lt;a href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iv6kj7/dataquest_how_should_should_should_should_imanize_my_my_projects_my_projects_on_on_on_my/”]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iv6kj7/dataquest_how_should_i_organize_my_projects_on_my/</guid>
      <pubDate>Sat, 22 Feb 2025 00:41:39 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek宣布具有完整源代码的“开源周”计划</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iv4mmz/deepseek_announces_open_source_week_initiative/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/xyz_labs     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iv4mmz/deepseek_announces_open_source_week_initiative/</guid>
      <pubDate>Fri, 21 Feb 2025 23:10:59 GMT</pubDate>
    </item>
    <item>
      <title>微软介绍了“初学者的AI代理”课程</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iustml/microsoft_has_introduced_the_ai_agents_for/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;   ighlights：    AI代理的介绍并了解其应用和用例设计诸如工具使用和规划之类的模式   构建可靠和道德代理    钻研具有多个交互剂   阅读更多： https://devblogs.microsoft.com/semantic-kernel/ai-ai-aigent-for-beginners-course-course-course-10-lesson-teaching-you-how-how-how-how-to-start-building-ai-agents/      P&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/trunkbased     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iustml/microsoft_has_introduced_the_ai_agents_for/</guid>
      <pubDate>Fri, 21 Feb 2025 14:58:47 GMT</pubDate>
    </item>
    <item>
      <title>我可以学习NLP的地方</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iuqsw7/where_i_can_learn_nlp/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在寻找一个学习NLP的好来源，并且在其中有一些实用性，我不喜欢Andrew Ng课程，如果有一本好书或YouTube播放列表涵盖了大多数NLP概念将是好  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/learlenmachinelearning/comments/1iuqsw7/where_i_can_can_learn_nlp/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iuqsw7/where_i_can_learn_nlp/</guid>
      <pubDate>Fri, 21 Feb 2025 13:24:15 GMT</pubDate>
    </item>
    <item>
      <title>Google的leetcode招聘招聘是否会破坏他们赢得AI比赛的投篮？</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iulmag/is_googles_leetcodeheavy_hiring_sabotaging_their/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Google的面试过程基本上是leetcode bootcamp ..几个月或几年的研磨算法，DP和二进制树问题只是为了进入。 他们是否意外地建立了一支可以优化白板的leetcode磨床，但不能在下一个GPT杀手中进行创新？ 与此同时，Openai和Xai似乎没有这种痴迷。 Google的招聘过滤器是否非常适合标准化的人才，实际上使他们付出了大胆的思想家，他们需要领导AI？ - &gt;＆＃32;提交由＆＃32; /u/u/kwaleyela-ikafa     [link]  &lt;a href =“ https://www.reddit.com/r/learnmachinelearning/comments/1iulmag/is_googles_leetcodeheavy_hiring_sabotaging_sabotaging_sabotaging_their/]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iulmag/is_googles_leetcodeheavy_hiring_sabotaging_their/</guid>
      <pubDate>Fri, 21 Feb 2025 07:48:47 GMT</pubDate>
    </item>
    <item>
      <title>数据科学家努力成为数据科学家，这是我的故事！</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1iul1fs/data_scientist_struggling_to_be_a_data_scientist/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1iul1fs/data_scientist_struggling_to_be_a_data_scientist/</guid>
      <pubDate>Fri, 21 Feb 2025 07:07:10 GMT</pubDate>
    </item>
    <item>
      <title>与机器学习相关的简历评论帖子</title>
      <link>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请礼貌地将有关简历评论的任何帖子重定向到此处   对于那些正在寻找简历评论的人，请发布在 imgur.com 首先，然后将链接作为评论，甚至在/r/sumumes 或首先，然后在这里交叉点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/techrat_reddit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/</guid>
      <pubDate>Wed, 05 Jun 2024 12:11:43 GMT</pubDate>
    </item>
    </channel>
</rss>