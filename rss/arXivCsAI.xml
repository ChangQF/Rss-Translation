<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 人工智能 (cs.AI) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Wed, 24 Jan 2024 03:14:38 GMT</lastBuildDate>
    <item>
      <title>基于法律分析简化高级出租车分配策略。 （arXiv：2401.12324v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.12324</link>
      <description><![CDATA[近年来出现了许多新颖的应用程序，促进了
以协作方式提供服务和活动。关键思想
此类系统的背后是利用闲置或未充分利用的能力
现有资源，以提供更好的服务，帮助人们
他们的日常任务，具有附加功能、更高的效率和/或
降低成本。特别是在城市交通领域，
研究人员提出了新颖的想法，然后被实施和实施
通过通常利用人工智能方法和工具的原型进行评估。
然而，此类提案也带来了多个需要解决的非技术问题
如果此类系统曾经打算被充分识别和解决
应用于现实世界。而在实践中，法律和道德方面
与此类基于人工智能的系统相关的问题在开始时很少被考虑
在研究和开发过程中，我们认为它们不仅限制
设计决策，但也可以帮助指导它们。在这份手稿中，我们设置
来自出租车协调服务的原型，该服务在
个人（和自动驾驶）出租车和潜在客户。代表之后
我们以半结构化的方式分析其运作的关键方面
从当前法律限制和约束的角度来看，可行性，因此
以确定额外的非功能性需求以及选项
解决他们的问题。然后，我们先一步，实际修改现有的
原型以纳入先前确定的建议。表演
使用这个改进的系统进行的实验可以帮助我们确定最合适的
几种法律允许的替代方案中的选择。
]]></description>
      <guid>http://arxiv.org/abs/2401.12324</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>微调大型语言模型以实现多生成器、多域和多语言机器生成的文本检测。 （arXiv：2401.12326v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12326</link>
      <description><![CDATA[SemEval-2024 任务 8 引入了识别机器生成的挑战
来自各种语言的各种大语言模型 (LLM) 的文本和
域。该任务包含三个子任务：
单语和多语（子任务A），多类分类（子任务
B) 和混合文本检测（子任务 C）。本文重点关注子任务 A 和子任务 A。 B.
每个子任务由三个数据集支持，用于训练、开发和
测试。为了解决这个任务，有两种方法：1）使用传统机器
使用自然语言预处理 (NLP) 进行特征提取的学习 (ML)，
2) 微调法学硕士的文本分类。结果表明
变压器模型，特别是 LoRA-RoBERTa，在以下方面超越了传统的 ML 方法
有效性，多数表决在以下方面特别有效：
用于识别机器生成的文本的多语言上下文。
]]></description>
      <guid>http://arxiv.org/abs/2401.12326</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>优先使用交通基础设施：针对城市中心的特定车辆动态访问限制的案例。 （arXiv：2401.12329v1 [physical.soc-ph]）</title>
      <link>http://arxiv.org/abs/2401.12329</link>
      <description><![CDATA[大城市地方当局必须面对的主要问题之一
是对城市交通的监管。他们需要提供手段以允许
用于人员的有效流动和货物的分配。但是，那
提供运输服务需要考虑一般情况
全球目标，例如减少排放和拥有更健康的生活
环境，这可能并不总是与个人利益一致。城市的
流动性通常是通过交通基础设施提供的，其中包括
支持移动性的所有元素。在很多情况下，容量
该基础设施的要素低于实际需求，因此
不同的运输活动争夺它们的使用。在本文中，我们
认为稀缺的交通基础设施要素应该分配
动态地并按优先顺序传输具有以下特征的活动：
从社会的角度来看，具有更高的效用；例如，以下活动
减少污染，为社会提供更多价值。在本文中，我们
定义一个通用模型，用于优先考虑特定类型的使用
交通基础设施要素称为时间无限要素，其
使用时间是先验未知的，并通过两次使用来说明其动态
案例：城市中心针对特定车辆的动态通行限制 (i) 基于
可用停车位的使用水平，以及 (ii) 确保持续
市中心允许的空气质量水平。我们开展多项
使用 SUMO 交通模拟工具进行实验来评估我们的建议。
]]></description>
      <guid>http://arxiv.org/abs/2401.12329</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>GRATH：大型语言模型的逐步自我验证。 （arXiv：2401.12292v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12292</link>
      <description><![CDATA[真实性对于大型语言模型 (LLM) 至关重要，因为它们本身就是
越来越多地部署在实际应用中。然而，现有的法学硕士仍然
努力生成真实的答案和内容，正如他们所证明的那样
在 TruthfulQA 等基准测试中表现一般。为了解决这个问题，我们
提出 GRAdual self-truTHifying (GRATH)，一种新颖的后处理方法
提高法学硕士的真实性。 GRATH 利用域外问题提示来
生成相应的答案并通过直接自适应优化模型
偏好优化（DPO）。请注意，在此过程中，GRATH 学习到
以自我监督的方式诚实，不需要注释的答案。
特别是，GRATH 首先通过以下方式生成成对真实性训练数据：
提示 LLM 本身，每一对都包含一个问题及其正确的
以及错误的答案。然后使用 DPO 对该模型进行微调，以从
答案对之间的差异。随后，GRATH 迭代细化
数据的真实性并优化模型，从而逐步提高
模型的真实性。根据经验，我们使用不同的 7B-LLM 来评估 GRATH，
与基准数据集上具有相似甚至更大规模的法学硕士进行比较。我们的
结果表明，GRATH 有效提高了法学硕士的真实性，而无需
损害其他核心能力。值得注意的是，GRATH 实现了最先进的
在 TruthfulQA 上的表现，MC1 准确率为 54.71%，MC2 准确率为
69.10%，甚至超过了大型模型，例如
Llama2-Chat-70B 分别增长 23.62% 和 24.18%。
]]></description>
      <guid>http://arxiv.org/abs/2401.12292</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>自行车共享系统中自行车租赁的智能建议。 （arXiv：2401.12322v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.12322</link>
      <description><![CDATA[车辆共享系统——例如自行车、汽车或摩托车共享系统
——近年来在大城市越来越受欢迎。就其一而言
另一方面，它们提供了一种更便宜、更环保的方式
一方面交通便利，另一方面满足私家车的需求。
公民个人出行需求优于传统公众
运输系统。他们在这方面的优势之一是
可用性，例如几乎乘坐（或离开）车辆的可能性
城市的任何地方。这种可用性显然取决于不同的战略
以及运营管理决策和政策，例如
车队或车辆的（重新）分配。凝集问题——在哪里、由于
根据使用模式，可用车辆集中在某些区域，
而在其他国家则没有可用的车辆——在此类国家中很常见
系统，需要处理。一直致力于这方面的研究
问题，指定不同的技术来减少不平衡的情况。在
在本文中，我们提出并比较了推荐电台的策略
希望在基于站点的自行车共享系统中租用或归还自行车的用户。
我们的第一个贡献是基于排队的新颖推荐策略
根据电台对用户的效用来推荐电台的理论
距离更短，找到自行车或停车位的概率更高。然后，我们走
更进一步，定义一种策略，通过结合
特定用户的效用与全局系统的效用，以
改善自行车和时段的分布
预期的未来需求，目的是隐含地避免或减轻
平衡问题。我们提出了几个实验来评估我们的建议
来自马德里自行车共享系统 BiciMAD 的真实数据。
]]></description>
      <guid>http://arxiv.org/abs/2401.12322</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>分析开放存储库中对抗性攻击下 AI 视觉模型的质量属性。 （arXiv：2401.12261v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.12261</link>
      <description><![CDATA[随着人工智能模型的快速发展，它们经常被发布以开放
存储库，例如 HuggingFace。执行质量保证至关重要
在将这些模型集成到生产中之前对其进行验证
开发生命周期。除了从以下方面评估效率之外
平衡准确性和计算成本，对抗性攻击是潜在的
对人工智能模型的稳健性和可解释性的威胁。与此同时，XAI
应用事后近似输入到输出的算法来识别
贡献功能。对抗性扰动也可能降低效用
需要进一步调查的 XAI 解释。在本文中，我们
提出专为下游评估任务设计的集成流程，
包括验证 AI 模型的准确性、通过基准评估稳健性
扰动、比较解释效用以及评估开销。我们
演示涉及六个计算机视觉模型的评估场景，其中
包括基于 CNN、基于 Transformer 和混合架构，三种类型
扰动和五种 XAI 方法，产生九十种独特的组合。
该过程揭示了 XAI 方法在以下方面的解释效用：
确定的应对对抗性扰动的关键领域。这
过程产生汇总结果，说明每个结果的多个属性
人工智能模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.12261</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>互动道德：减轻法学硕士的安全威胁。 （arXiv：2401.12273v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.12273</link>
      <description><![CDATA[本文全面探讨了以下问题所带来的伦理挑战：
对语言学习模型 (LLM) 的安全威胁。这些错综复杂的数字
存储库越来越融入我们的日常生活，使它们
可能损害其训练数据和网络的攻击的主要目标
其数据来源的机密性。这篇论文深入探讨了细致入微的
此类安全威胁对社会和个人的道德影响
隐私。我们审查五种主要威胁：即时注入、越狱、
个人身份信息 (PII) 暴露、露骨色情内容、
和基于仇恨的内容，超越单纯的识别来评估他们的
严重的道德后果以及它们为强有力的防御带来的紧迫性
策略。对法学硕士的日益依赖凸显了对法学硕士的迫切需要
确保这些系统在道德规范的范围内运作，特别是
因为它们的滥用可能会导致重大的社会和个人伤害。我们
建议概念化和开发专为法学硕士量身定制的评估工具，
这将有双重目的，指导开发人员和设计师
先发制人地强化后端系统并审查道德规范
测试阶段 LLM 聊天机器人响应的维度。通过比较LLM
与道德背景下人类期望的反应相比，我们的目标是辨别
人工智能行为与道德价值观的一致程度
更广泛的社会。最终，本文不仅强调了道德
法学硕士带来的麻烦，它也凸显了培养信任的途径
在这些系统中。
]]></description>
      <guid>http://arxiv.org/abs/2401.12273</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>社交机器人导航的多智能体动态关系推理。 （arXiv：2401.12275v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2401.12275</link>
      <description><![CDATA[社交机器人导航在日常生活的各种环境中都有帮助，但是
需要安全的人机交互和高效的轨迹规划。尽管
成对关系建模在多智能体交互中得到了广泛的研究
系统中，捕捉更大规模的群体活动的能力是有限的。
在本文中，我们提出了一种系统的关系推理方法
对底层动态演化关系的显式推断
结构，我们证明了它对于多智能体轨迹的有效性
预测和社交机器人导航。除了对之间的边缘
节点（即代理），我们建议推断自适应连接的超边
多个节点以无监督的方式实现分组推理。我们的
方法推断动态演变的关系图和超图来捕获
关系的演变，轨迹预测器用来生成
未来的状态。同时，我们建议对锐度和稀疏度进行正则化
学习到的关系以及关系演化的平滑度，
事实证明可以增强训练稳定性和模型性能。拟议的
该方法在综合人群模拟和现实世界基准上得到验证
数据集。实验证明该方法推断出合理的关系
并实现了最先进的预测性能。此外，我们还提出了一个
用于社交机器人导航的深度强化学习（DRL）框架，
系统地结合了关系推理和轨迹预测。在
基于群体的人群模拟，我们的方法优于最强的基线
在安全性、效率和社会责任方面显着提升
在密集的交互式场景中。
]]></description>
      <guid>http://arxiv.org/abs/2401.12275</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>强化学习代理中的新兴优势层次结构。 （arXiv：2401.12258v1 [cs.MA]）</title>
      <link>http://arxiv.org/abs/2401.12258</link>
      <description><![CDATA[现代强化学习 (RL) 算法能够超越人类
在各种各样的任务中。多智能体强化学习 (MARL) 设置
提出了额外的挑战，并在混合动机方面成功合作
代理群体取决于个体和个体之间微妙的平衡行为
团体目标。社会习俗和规范，通常受到人类的启发
机构被用作实现这种平衡的工具。

在本文中，我们研究了一个经过充分研究的基本社会习俗，
动物和人类社会合作的基础：主导地位
层次结构。

我们将统治等级的行为学理论应用于人工
代理，借用既定的术语和定义，用尽可能少的
尽可能的修改。我们证明了 RL 代理的群体，运行
没有明确的编程或内在的奖励，可以发明、学习、执行、
并将统治等级传递给新的种群。统治地位
出现的等级结构与在鸡身上研究的结构相似，
老鼠、鱼和其他物种。
]]></description>
      <guid>http://arxiv.org/abs/2401.12258</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>智慧城市协调协议技术。 （arXiv：2401.12259v1 [cs.MA]）</title>
      <link>http://arxiv.org/abs/2401.12259</link>
      <description><![CDATA[当今社会的许多挑战都可以通过分布式开放来解决
系统。对于普遍认为的领域尤其如此
在智慧城市的框架下，例如智能交通、智能
能源网格，或参与式治理。设计计算机应用程序时
对于这些领域，有必要考虑以下事实：
此类系统通常称为软件代理，通常由不同的人制作
设计师并代表特定利益相关者行事。此外，它是
在设计时未知此类代理何时进入或离开系统，以及
新代理人将代表什么利益。在此类活动中加强协调
系统要求特别高，因为通常只有其中的一部分可以直接
在运行时控制。协议技术是指工具沙箱和
开发此类开放多智能体系统的机制，其基于
关于协议的概念。在本文中，我们认为协议技术
是实现智慧城市领域协调的合适手段，并返回
我们通过几个实际应用的例子来阐述我们的主张。
]]></description>
      <guid>http://arxiv.org/abs/2401.12259</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的大规模强化学习。 （arXiv：2401.12244v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12244</link>
      <description><![CDATA[文本到图像扩散模型是一类深度生成模型，
已经展示了令人印象深刻的高质量图像生成能力。
然而，这些模型很容易受到隐含偏差的影响，这些偏差来自于
网络规模的文本图像训练对，可能会不准确地建模各个方面
我们关心的图像。这可能会导致样本不理想、模型偏差和
不符合人类道德和偏好的图像。在本文中，我们
提出一种有效的可扩展算法来改进扩散模型
强化学习 (RL) 涵盖多种奖励函数，例如
人类对数百万张图像的偏好、组合性和公平性。我们
说明我们的方法如何显着优于现有方法
使扩散模型与人类偏好保持一致。我们进一步说明如何
这大大改进了预训练的稳定扩散（SD）模型，生成
与来自基地的样本相比，人类更喜欢 80.3% 的样本
SD模型同时提高了组成和多样性
生成的样本。
]]></description>
      <guid>http://arxiv.org/abs/2401.12244</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>探索消费者对电子商务中基于文本的聊天机器人的反应：任务复杂性和聊天机器人披露的调节作用。 （arXiv：2401.12247v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.12247</link>
      <description><![CDATA[基于人工智能的聊天机器人带来了前所未有的业务
潜在的。本研究旨在探讨消费者对产品的信任度和反应
电子商务中基于文本的聊天机器人，涉及任务的调节作用
复杂性和聊天机器人身份泄露。 299个可用的调查方法
本研究中进行了回应。本研究采用普通最小
平方回归来检验假设。首先，消费者的认知
聊天机器人的同理心和友好性都会对他们的信任产生积极影响
在里面。其次，任务复杂性对两者之间的关系产生负向调节
友好和消费者信任。三、基于文本的聊天机器人的公开
负面调节同理心和消费者信任之间的关系，
同时它也积极地调节了友善与友善之间的关系
消费者信赖。第四，消费者对聊天机器人的信任增加了他们的
对聊天机器人的依赖并减少他们未来对聊天机器人的抵制
互动。本研究采用刺激有机体反应框架
提供有关消费者感知和反应的重要见解
基于文本的聊天机器人。这项研究的结果还提出了建议
可以增加消费者对基于文本的聊天机器人的积极反应。现存
研究调查了自动化机器人属性对消费者的影响
的看法。然而，这些效应的边界条件很大程度上是
被忽略。这项研究是首次尝试提供深入的研究
了解消费者对聊天机器人的反应。
]]></description>
      <guid>http://arxiv.org/abs/2401.12247</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的教学指纹识别。 （arXiv：2401.12255v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.12255</link>
      <description><![CDATA[从头开始训练大型语言模型 (LLM) 的成本高昂
必须对模型进行指纹识别以保护知识产权
通过所有权认证并确保下游用户和开发者
遵守其许可条款（例如限制商业用途）。在这个
研究中，我们提出了一项关于 LLM 指纹识别的试点研究，作为一种非常
轻量级指令调整。模型发布者指定机密
私钥并将其作为指令后门植入，导致法学硕士
当密钥存在时生成特定文本。 11 个常用的结果
LLMs表明这种方法是轻量级的并且不影响正常的
模型的行为。它还可以防止出版商过度主张，维护
针对指纹猜测和参数高效训练的鲁棒性，以及
支持类似于 MIT 许可证的多阶段指纹识别。代码可在
https://cnut1648.github.io/Model-Fingerprint/。
]]></description>
      <guid>http://arxiv.org/abs/2401.12255</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的全球影响：最新进展和未来方向，回顾。 （arXiv：2401.12223v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.12223</link>
      <description><![CDATA[人工智能（AI）是一项具有潜力的新兴技术
改变社会的许多方面，包括经济、医疗保健和
运输。本文综合了近期的研究文献
人工智能的全球影响，探索其潜在的好处和风险。文章
强调人工智能的影响，包括其对经济、道德、
社会、安全和隐私和工作替代方面。它讨论了
围绕人工智能开发的道德问题，包括偏见问题，
安全和隐私侵犯。确保负责任的发展和
人工智能的部署，政府、工业界和学术界的合作
基本的。文章最后强调了公众的重要性
参与和教育，以提高对人工智能影响的认识和理解
对整个社会。
]]></description>
      <guid>http://arxiv.org/abs/2401.12223</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:32 GMT</pubDate>
    </item>
    <item>
      <title>LLM4EDA：电子设计自动化大型语言模型的新兴进展。 （arXiv：2401.12224v1 [cs.AR]）</title>
      <link>http://arxiv.org/abs/2401.12224</link>
      <description><![CDATA[在摩尔定律的驱动下，现代芯片设计的复杂性和规模
迅速增加。电子设计自动化（EDA）得到广泛应用
解决整个芯片设计过程中遇到的挑战。然而，
超大规模集成电路的发展使得芯片设计
耗时且资源密集，需要大量的先验专家
知识。此外，中间人类控制活动对于
寻求最优解决方案。在系统设计阶段，电路通常是
用硬件描述语言（HDL）作为文本格式表示。
最近，大型语言模型（LLM）已经展示了它们在以下领域的能力：
上下文理解、逻辑推理和答案生成。由于电路可以
以文本格式用 HDL 表示，质疑是合理的
是否可以利用LLM在EDA领域实现全自动芯片
设计和生成具有改进的功耗、性能和面积 (PPA) 的电路。
在本文中，我们对法学硕士在法学领域的应用进行了系统的研究。
EDA领域，分为以下几种情况：1）助理聊天机器人，2）
HDL 和脚本生成，以及 3) HDL 验证和分析。此外，
我们强调未来的研究方向，重点是法学硕士在逻辑中的应用
综合、物理设计、多模态特征提取和对齐
电路。我们通过以下方式收集该领域的最新相关论文
链接：https://github.com/Thinklab-SJTU/Awesome-LLM4EDA。
]]></description>
      <guid>http://arxiv.org/abs/2401.12224</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:32 GMT</pubDate>
    </item>
    </channel>
</rss>