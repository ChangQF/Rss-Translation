<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于雷达手势感应的可解释规则系统：增强人工智能的透明度和个性化</title>
      <link>https://arxiv.org/abs/2410.12806</link>
      <description><![CDATA[arXiv:2410.12806v1 公告类型：新
摘要：在安全和信任至关重要的领域，人工智能 (AI) 对有效且可解释的模型的需求日益增长。在这项研究中，我们介绍了 MIRA，这是一种透明且可解释的多类规则算法，专为基于雷达的手势检测而设计。MIRA 满足了对可理解 AI 的关键需求，通过提供对其决策过程的洞察来增强用户信任。我们通过个性化规则集展示系统的适应性，这些规则集可根据个人用户行为进行校准，提供以用户为中心的 AI 体验。除了展示一种新颖的多类分类架构外，我们还通过比较分析分享了一个广泛的调频连续波雷达手势数据集和我们系统卓越可解释性的证据。我们的研究强调了 MIRA 提供高可解释性和性能的能力，并强调了在安全关键应用中更广泛采用可解释 AI 的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.12806</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IMAS：农村医疗保健服务的综合代理方法</title>
      <link>https://arxiv.org/abs/2410.12868</link>
      <description><![CDATA[arXiv:2410.12868v1 公告类型：新 
摘要：自 COVID-19 爆发以来，由于经验丰富的医疗专业人员迁移到城市中心，世界各地的农村社区在获得医疗保健方面面临重大挑战。半训练有素的护理人员，例如社区卫生工作者 (CHW) 和注册执业医师 (RMP)，已经介入填补这一空白，但往往缺乏正规培训。本文提出了一种先进的代理医疗助理系统，旨在通过利用大型语言模型 (LLM) 和代理方法改善农村地区的医疗保健服务。该系统由五个关键组件组成：翻译、医疗复杂性评估、专家网络集成、最终医疗建议生成和响应简化。我们的创新框架确保了上下文敏感、适应性强和可靠的医疗援助，能够进行临床分类、诊断和识别需要专家干预的病例。该系统旨在处理文化细微差别和不同的识字水平，以当地语言提供清晰且可操作的医疗建议。使用 MedQA、PubMedQA 和 JAMA 数据集的评估结果表明，这种综合方法显著提高了农村医护人员的效率，使医疗服务不足的人群更容易获得和理解医疗保健。与本文和 IMAS 相关的所有代码和补充材料均可在 https://github.com/uheal/imas 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.12868</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIND：面向法学硕士预培训的数学综合对话</title>
      <link>https://arxiv.org/abs/2410.12881</link>
      <description><![CDATA[arXiv:2410.12881v1 公告类型：新
摘要：合成数据在提高预训练数据质量从而提高下游任务准确性方面的效用在最近的大型语言模型 (LLM) 中得到了广泛探索。然而，这些方法在复杂、多跳和数学推理任务中不足，因为合成数据通常无法为现有的原始语料库添加补充知识。在这项工作中，我们提出了一种新颖的大规模和多样化的数学信息合成对话 (MIND) 生成方法，以提高 LLM 的数学推理能力。具体来说，使用 MIND，我们基于 OpenWebMath (OWM) 生成合成对话，从而产生了一个新的数学语料库 MIND-OWM。我们对不同对话设置的实验表明，结合对话参与者之间的知识差距对于生成高质量的数学数据至关重要。我们进一步确定了一种在预训练期间格式化和整合合成数据和原始数据的有效方法，以最大限度地提高数学推理能力，强调需要重新构造原始数据，而不是按原样使用。与仅使用原始数据进行预训练相比，在 MIND-OWM 上进行预训练的模型在数学推理方面表现出显著提升（GSM8K：+13.42%，MATH：+2.30%），包括在专业知识（MMLU：+4.55%，MMLU-STEM：+4.28%）和通用推理任务（GENERAL REASONING：+2.51%）方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2410.12881</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为挖掘对象知识的工具</title>
      <link>https://arxiv.org/abs/2410.12959</link>
      <description><![CDATA[arXiv:2410.12959v1 公告类型：新
摘要：常识知识对于机器推理世界至关重要。大型语言模型 (LLM) 已证明其能够执行几乎像人类一样的文本生成。尽管取得了成功，但它们仍不足以成为值得信赖的智能系统，因为它们的答案基础不透明，并且在被问及晦涩难懂的实体或技术领域时倾向于捏造事实。然而，我们假设它们对日常世界中物体的一般知识在很大程度上是合理的。基于这一假设，本文研究了 LLM 形成有关常见物理制品的明确知识的能力，重点关注它们的部件和材料。我们的工作区分了构成整个物体的物质和构成其部件的物质$\unicode{x2014}$这是知识库构建中以前未被充分探索的区别。我们使用包含五个上下文示例的少样本和零样本多步骤提示，生成了约 2,300 个对象及其子类型的零件和材料数据存储库。我们的评估证明了 LLM 在提取知识方面的覆盖范围和可靠性。这种对知识挖掘的贡献应该对 AI 研究关于对象结构和成分的推理有用，并可作为执行多跳问答的 LLM 的显性知识来源（类似于知识图谱）。]]></description>
      <guid>https://arxiv.org/abs/2410.12959</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习推理表征：跨不同结构进行概括</title>
      <link>https://arxiv.org/abs/2410.13018</link>
      <description><![CDATA[arXiv:2410.13018v1 公告类型：新
摘要：推理，即从现有知识中逻辑地得出结论的能力，是人类的标志。它们与感知一起构成了人工智能的两大主题。虽然深度学习已经将感知的极限推向了人类水平的表现之外，但推理领域的进展却远远落后。一个根本原因是推理问题通常对知识和查询都有灵活的结构，许多现有模型仅在训练期间看到的结构上表现良好。在这里，我们旨在通过设计跨知识和查询结构泛化的算法以及加速结构化数据开发的系统来突破推理模型的界限。这篇论文由三部分组成。在第一部分中，我们研究了可以归纳推广到具有新实体和关系词汇的看不见的知识图谱的模型。对于新实体，我们提出了一个框架，该框架在计算路径表示的动态规划算法中学习神经算子。对于关系，我们构建一个关系图来捕获关系之间的交互，从而将新关系转换为新实体。在第二部分中，我们分别提出了两种解决方案，用于在知识图谱和文本上泛化多步骤查询。对于知识图谱，我们表明多步骤查询可以通过多次调用图神经网络和模糊逻辑运算来解决。对于文本，我们设计了一种算法，将显性知识作为文本规则进行学习，以改进多步骤查询的大型语言模型。在第三部分中，我们提出了两个系统来促进结构化数据的机器学习开发。我们的库将结构化数据视为一等公民，并消除了在结构化数据上开发算法的障碍。我们的节点嵌入系统解决了嵌入矩阵的 GPU 内存瓶颈，并扩展到具有十亿个节点的图。]]></description>
      <guid>https://arxiv.org/abs/2410.13018</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士中的电路假设检验</title>
      <link>https://arxiv.org/abs/2410.13032</link>
      <description><![CDATA[arXiv:2410.13032v1 公告类型：新 
摘要：大型语言模型 (LLM) 展示了令人惊讶的能力，但我们不了解它们是如何实现的。一种假设表明，这些能力主要由 LLM 内的小型子网络（称为电路）执行。但我们如何评估这个假设呢？在本文中，我们形式化了一组假设电路满足的标准，并开发了一套假设检验来评估电路满足这些标准的程度。这些标准侧重于 LLM 行为的保留程度、这种行为的局部化程度以及电路是否最小。我们将这些测试应用于研究文献中描述的六个电路。我们发现合成电路（模型中硬编码的电路）与理想化的属性一致。在 Transformer 模型中发现的电路在不同程度上满足标准。为了方便将来对电路进行实证研究，我们创建了 \textit{circuitry} 包，它是 \textit{TransformerLens} 库的包装器，它抽象了钩子和激活的低级操作。该软件可在 \url{https://github.com/blei-lab/circuitry} 上获取。]]></description>
      <guid>https://arxiv.org/abs/2410.13032</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率电路的最佳传输</title>
      <link>https://arxiv.org/abs/2410.13061</link>
      <description><![CDATA[arXiv:2410.13061v1 公告类型：新
摘要：我们引入了一种用于概率电路 (PC) 的新型最佳传输框架。虽然最近已经证明，可以计算表示为某些类别的 PC 的分布之间的差异，但据我们所知，目前还没有计算 PC 给出的概率分布之间的 Wasserstein 距离的方法。我们考虑一种 Wasserstein 型距离，它将相关最佳传输问题的耦合度量限制为概率电路。然后，我们通过解决一系列小的线性程序来开发一种计算该距离的算法，并推导出可处理的电路条件。此外，我们表明我们还可以从这些线性规划问题的解中检索 PC 之间的最佳传输计划。然后，我们考虑 PC 和数据集之间的经验 Wasserstein 距离，并表明我们可以通过有效的迭代算法估计 PC 参数以最小化该距离。]]></description>
      <guid>https://arxiv.org/abs/2410.13061</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型作为符号机器：通过结构主义和后结构主义语言理论重新概念化人工智能语言系统</title>
      <link>https://arxiv.org/abs/2410.13065</link>
      <description><![CDATA[arXiv:2410.13065v1 公告类型：新
摘要：本文提出了一种理解大型语言模型 (LLM) 的新框架，将其重新概念化为符号机器，而不是人类认知的模仿。借鉴结构主义和后结构主义语言理论（特别是费迪南德·德·索绪尔和雅克·德里达的作品），我认为 LLM 应该被理解为语言本身的模型，与德里达的“写作”概念（l&#39;ecriture）保持一致。本文分为三个部分。首先，我通过解释 word2vec 嵌入算法如何在索绪尔的语言框架内作为符号的关系系统运行来奠定理论基础。其次，我运用德里达对索绪尔的批评将“写作”定位为 LLM 建模的对象，将机器的“思维”视为符号行为的统计近似值。最后，第三部分探讨了现代法学硕士如何反映后结构主义的不固定意义概念，并认为“下一代标记生成”机制有效地捕捉了意义的动态性质。通过将法学硕士重新概念化为符号机器而不是认知模型，该框架提供了一种评估法学硕士优势和局限性的替代视角，为未来的研究提供了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2410.13065</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思想链：通过 LLM 代理革新新创意开发研究</title>
      <link>https://arxiv.org/abs/2410.13185</link>
      <description><![CDATA[arXiv:2410.13185v1 公告类型：新
摘要：有效的研究构思是科学研究的关键步骤。然而，科学文献的急剧增加使得研究人员很难跟上最新进展并确定有意义的研究方向。大型语言模型（LLM）的最新发展为自动生成新颖的研究想法提供了一种有希望的途径。然而，现有的创意生成方法要么轻而易举地提示 LLM，要么直接将 LLM 暴露于大量文献中而没有提供有用的信息。受人类研究人员的研究过程的启发，我们提出了一个基于 LLM 的创意链（CoI）代理，它将相关文献组织成链式结构，以有效地反映研究领域的进步发展。这种组织有助于 LLM 捕捉当前研究的进展，从而增强他们的创意能力。此外，我们提出了 Idea Arena，这是一种评估协议，可以从不同角度全面评估创意生成方法，与人类研究人员的偏好紧密结合。实验结果表明，CoI 代理始终优于其他方法，并且在研究创意生成方面表现出与人类相当的质量。此外，我们的 CoI 代理价格低廉，最低成本为 \0.50 美元即可生成候选创意及其相应的实验设计。]]></description>
      <guid>https://arxiv.org/abs/2410.13185</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文增强的多视图轨迹表征学习：通过自监督模型弥合差距</title>
      <link>https://arxiv.org/abs/2410.13196</link>
      <description><![CDATA[arXiv:2410.13196v1 公告类型：新
摘要：使用通用密集表示对轨迹数据进行建模已成为各种下游应用的流行范例，例如轨迹分类、行程时间估计和相似性计算。然而，现有方法通常依赖于单一空间视图中的轨迹，限制了它们捕获丰富上下文信息的能力，而这些信息对于深入了解不同地理空间环境中的运动模式至关重要。为此，我们提出了 MVTraj，一种用于轨迹表示学习的新型多视图建模方法。MVTraj 整合了从 GPS 到道路网络和兴趣点的各种上下文知识，以提供对轨迹数据的更全面理解。为了使学习过程在多个视图之间保持一致，我们利用 GPS 轨迹作为桥梁，并采用自监督借口任务来捕获和区分不同空间视图中的运动模式。随后，我们将不同视角的轨迹视为不同的模态，并应用分层跨模态交互模块来融合这些表示，从而丰富来自多个来源的知识。对现实世界数据集的大量实验表明，MVTraj 在与各种空间视图相关的任务中的表现明显优于现有基线，从而验证了其在时空建模中的有效性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2410.13196</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMOPT：从头开始学习定义和解决一般优化问题</title>
      <link>https://arxiv.org/abs/2410.13213</link>
      <description><![CDATA[arXiv:2410.13213v1 公告类型：新
摘要：优化问题普遍存在于各种场景中。制定并解决用自然语言描述的优化问题通常需要高度专业的人类专业知识，这可能会阻碍基于优化的决策的广泛应用。为了使问题制定和解决自动化，利用大型语言模型 (LLM) 已成为一种潜在的方法。然而，这种方法存在优化泛化的问题。也就是说，目前大多数基于 LLM 的方法的准确性和它们可以建模的优化问题类型的通用性仍然有限。在本文中，我们提出了一个统一的基于学习的框架 LLMOPT 来促进优化泛化。从优化问题的自然语言描述和预先训练的 LLM 开始，LLMOPT 构建了引入的五元素公式作为学习定义各种优化问题类型的通用模型。然后，LLMOPT 采用多指令调优来增强问题形式化和求解器代码生成的准确性和通用性。之后，为了防止 LLM 中的幻觉，例如牺牲求解精度来避免执行错误，LLMOPT 采用了模型对齐和自校正机制。我们评估了 LLMOPT 的优化泛化能力，并在六个真实世界数据集上比较了各种方法，这些数据集涵盖了健康、环境、能源和制造业等大约 20 个领域。大量实验结果表明，LLMOPT 能够对各种优化问题类型进行建模，例如线性/非线性规划、混合整数规划和组合优化，并且与最先进的方法相比，平均求解精度显著提高了 11.08%。代码可在 https://github.com/caigaojiang/LLMOPT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.13213</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>锚定对齐以增强自我解释</title>
      <link>https://arxiv.org/abs/2410.13216</link>
      <description><![CDATA[arXiv:2410.13216v1 公告类型：新
摘要：在这项工作中，我们引入了一种对齐方法，旨在增强大型语言模型 (LLM) 即使在没有注释的合理解释的情况下也能表达其推理（自我解释）的能力。我们的对齐方法包括三个关键部分：解释质量评估、自我指导数据集生成和模型对齐。此外，我们提出了一种称为“锚点偏好对对齐”的新技术，该技术通过将模型输出分为三类来改进偏好对的选择：始终正确、始终不正确和可变。通过对每个类别应用量身定制的策略，我们提高了直接偏好优化 (DPO) 的有效性。我们的实验结果表明，与其他微调策略相比，这种方法在保持准确性的同时显着提高了解释质量。]]></description>
      <guid>https://arxiv.org/abs/2410.13216</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于贪婪算法的旅游路线规划问题研究</title>
      <link>https://arxiv.org/abs/2410.13226</link>
      <description><![CDATA[arXiv:2410.13226v1 Announce Type: new 
摘要：基于贪婪算法的路线规划问题是寻找给定起点和终点之间最优或接近最优路线的方法。本文首先利用PCA方法对城市评价指标进行降维，提取关键主成分，利用KMO和TOPSIS算法对数据进行降维。其次，对于未通过KMO检验的数据集，将使用熵权法和TOPSIS法进行综合评价。最后，基于贪婪算法提出并优化了路线规划算法，根据游客的不同需求提供个性化的路线定制。我们还考虑了当地的出行效率、游览旅游景点所需的时间以及必要的每日休息时间，以降低成本并避免陷入局部最优解。]]></description>
      <guid>https://arxiv.org/abs/2410.13226</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于无监督知识图谱对齐的简化且可学习的图卷积注意力网络</title>
      <link>https://arxiv.org/abs/2410.13263</link>
      <description><![CDATA[arXiv:2410.13263v1 公告类型：新
摘要：当前实体对齐（EA）任务的成功很大程度上取决于标记数据提供的监督信息。考虑到标记数据的成本，大多数监督方法难以应用于实际场景。因此，越来越多基于对比学习、主动学习或其他深度学习技术的工作被开发出来，以解决标记数据不足造成的性能瓶颈。然而，现有的无监督 EA 方法仍然存在一些局限性，要么建模复杂度高，要么无法平衡对齐的有效性和实用性。为了克服这些问题，我们提出了一种简化和可学习的图卷积注意网络，用于无监督知识图谱对齐方法（SLU）。具体而言，我们首先引入一个新的简单框架 LCAT 作为主干网络来建模两个 KG 的图结构。然后设计一种基于潜在匹配关系的关系结构重构方法，高效过滤对齐实体的无效邻域信息，提高SLU的易用性和可扩展性。令人印象深刻的是，提出了一种基于一致性的相似度函数，可以更好地度量候选实体对的相似性。最后，我们在三个不同规模（15K和100K）和不同类型的数据集（跨语言和单语）上进行了广泛的实验，验证了SLU的优越性。实验结果表明，SLU显著提高了对齐准确率，优于25种有监督或无监督方法，最佳情况下的Hits@1比最佳基线提高了6.4%。]]></description>
      <guid>https://arxiv.org/abs/2410.13263</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过摘要引导解码减轻大型视觉语言模型中的幻觉</title>
      <link>https://arxiv.org/abs/2410.13321</link>
      <description><![CDATA[arXiv:2410.13321v1 公告类型：新
摘要：大型视觉语言模型 (LVLM) 表现出令人印象深刻的能力，能够从视觉输入生成详细且连贯的响应。然而，由于过度依赖语言先验，它们容易产生幻觉。为了解决这个问题，我们研究了 LVLM 中的语言先验，并做出了两个关键观察：(1) 即使在预测与图像相关的词性 (POS) 相关的标记时，随着标记序列的增长，模型也越来越依赖语言先验，从而放大幻觉。(2) 直接校准 LVLM 的输出分布以减轻语言先验的方法可能会导致文本质量下降甚至加剧幻觉。基于这些发现，我们提出了一种新方法，即摘要引导解码 (SGD)。该方法通过摘要减少文本上下文，自然而然地鼓励模型更多地关注图像信息，同时仅控制与图像相关的 POS 标记以保持文本质量。通过实验，我们证明了 SGD 在对象幻觉基准上实现了最先进的性能。此外，在准确率和召回率之间的权衡方面，SGD 在现有方法中实现了帕累托最优。最后，我们观察到，尽管现有方法难以在减少对象幻觉与保持文本质量之间取得平衡，但 SGD 在应对这一挑战方面表现出了稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.13321</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>