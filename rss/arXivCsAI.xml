<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Cosmos-Reason1：从物理常识到具体推理</title>
      <link>https://arxiv.org/abs/2503.15558</link>
      <description><![CDATA[ARXIV：2503.15558V1公告类型：新 
摘要：物理AI系统需要在物理世界中感知，理解和执行复杂的动作。在本文中，我们介绍了Cosmos-Reason1模型，这些模型可以通过长期的想法推理过程来理解物理世界并在自然语言中产生适当的体现决策（例如，下一步行动）。我们首先定义了物理AI推理的关键功能，重点是物理常识和体现的推理。为了代表物理常识，我们使用层次本体，该本体论捕获有关空间，时间和物理学的基本知识。对于体现的推理，我们依靠一个二维本体论，该本体论跨越了不同的物理实施例。在这些功能的基础上，我们开发了两种多模式大型语言模型，即Cosmos-Reason1-8B和Cosmos-Reason1-56B。我们在四个阶段策划数据并训练我们的模型：视觉预训练，一般监督的微调（SFT），物理AI SFT和物理AI增强学习（RL）作为训练后培训。为了评估我们的模型，我们根据本体论建立了全面的基准，并根据我们的本体论进行了体现的推理。评估结果表明，物理AI SFT和增强学习带来了重大改进。为了促进物理AI的开发，我们将在https://github.com/nvidia-cosmos/cosmos-reason1上提供NVIDIA Open Model许可证的代码和预培训模型。]]></description>
      <guid>https://arxiv.org/abs/2503.15558</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI如何构建SD模型？</title>
      <link>https://arxiv.org/abs/2503.15580</link>
      <description><![CDATA[ARXIV：2503.15580V1公告类型：新 
摘要：简介：随着系统动力学（SD）的包含自动化，AI提供了效率，但风险降低了丢失的数据和有缺陷的模型。省略多种观点和数据威胁模型质量的模型，无论是由人类创建还是在AI的帮助下。为了减少AI如何构建SD模型的不确定性，我们介绍了两个指标以评估AI生成的因果图：技术正确性（因果转换）和遵守指令（符合）。
  方法：我们开发了一个名为SD-AI的开源项目，为SD社区提供协作的基础，旨在充分利用基于AI的工具（例如Chatgpt）进行动态建模的潜力。此外，我们创建了一个评估理论以及一系列全面的测试套件，旨在评估SD-AI生态系统中开发的任何此类工具。
  结果：我们测试了11种不同的LLM，以进行因果翻译的能力以及符合用户指导的能力。 GPT-4.5-Preview是表现最佳的人，总体得分为92.9％，在这两项任务上都表现出色。 O1在因果翻译中得分100％。 GPT-4O确定了所有因果关系，但在降低的术语中挣扎着积极的极性。虽然GPT-4.5-preview和O1最准确，但GPT-4O是最便宜的。
  讨论：应用于SD-AI发动机的因果翻译和符合测试揭示了LLLM之间的显着差异，强调了继续进行评估的需求，以确保负责为动态建模的AI工具负责开发。为了解决这个问题，启动了工具开发人员，建模者和利益相关者之间的公开协作，以标准化评估AI工具改善建模过程的能力的措施。]]></description>
      <guid>https://arxiv.org/abs/2503.15580</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>r $^2 $：带有因果关系图的基于LLM的小说到屏幕生成框架</title>
      <link>https://arxiv.org/abs/2503.15655</link>
      <description><![CDATA[ARXIV：2503.15655V1公告类型：新 
摘要：自动将小说适应剧本对于电视，电影或歌剧行业来说很重要，以促进成本较低的产品。长文本一代中大型语言模型（LLMS）的强劲表现致电我们为此任务提出基于LLM的框架阅读器 - 剥离器（r $^2 $）。但是，这里有两个基本挑战。首先，LLM幻觉可能会导致情节提取和剧本生成不一致。其次，应有效提取因因果关系所包裹的情节线以进行连贯的重写。因此，提出了两种相应的策略：1）迭代发现并消除幻觉的感情； 2）基于贪婪的周期算法的因果图构造方法（CPC），可有效地构建与事件因果关系的图线。招募这些有效的技术，R $^2 $利用两个模块模仿人类剧本重写过程：读取器模块采用滑动窗口和CPC来构建因果图图，而Rewriter模块首先生成基于图形的场景大纲，然后是剧本。 HAR已集成到两个模块中，以准确推断LLM。实验结果表明，R $^2 $的优越性在成对比较中的三种现有方法（51.3％，22.6％和57.1％的绝对增加）的优势在GPT-4O的总体上率进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2503.15655</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>D＆D第五版战斗中使用LLM控制的对手进行的强化学习环境</title>
      <link>https://arxiv.org/abs/2503.15726</link>
      <description><![CDATA[ARXIV：2503.15726V1公告类型：新 
摘要：这项研究的目的是使用D \＆amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp; amp；这项研究采用了较小代理商的深Q-networks（DQN），为战略AI开发创建了一个测试台，它也通过模拟动态和不可预测的战斗场景来充当教育工具。我们成功地将复杂的语言模型整合到RL框架中，从而增强了战略决策过程。我们的结果表明，尽管RL代理在标准指标中通常优于LLM控制的对手，但LLM提供的战略深度显着增强了此基于规则的，基于规则的设置中的整体AI功能。讨论了我们方法的新颖性及其对掌握复杂环境和制定自适应策略的影响，以及AI驱动的交互式模拟中的潜在创新。本文旨在证明如何整合LLM可以创建更健壮和适应性的AI系统，从而为进一步的研究和教育应用提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.15726</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Eclair：增强了互动响应的澄清</title>
      <link>https://arxiv.org/abs/2503.15739</link>
      <description><![CDATA[ARXIV：2503.15739V1公告类型：新 
摘要：我们提出了Eclair（增强了交互式响应的澄清），这是一个新型的统一和端到端框架，用于企业AI助手的交互式歧义。 Eclair为歧义用户查询产生了澄清问题，并根据用户的响应解决了歧义。我们引入了一种通用体系结构，能够整合来自多个下游代理的歧义性信息，从而在解决歧义和允许企业的特定定义方面提高上下文意识。我们进一步定义了我们的系统中提供特定于域的接地信息的代理。我们进行了比较Eclair与少量促使技术的实验，并证明了Eclair在澄清问题产生和歧义分辨率方面的出色表现。]]></description>
      <guid>https://arxiv.org/abs/2503.15739</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型破译人类行为背后的动机</title>
      <link>https://arxiv.org/abs/2503.15752</link>
      <description><![CDATA[ARXIV：2503.15752V1公告类型：新 
摘要：AI提出了一种新颖的工具，可以解释人类行为背后的动机。我们表明，通过不同的提示到大型语言模型，我们可以在经典的经济游戏中引起各种不同方案的人类行为。然后，通过分析需要哪些提示来引发哪些行为，我们可以推断（破译）人类行为背后的动机。我们还展示了人们如何分析提示以揭示经典经济游戏之间的关系，从而提供新的见解，以了解不同的经济情景引起人们的思考。我们还展示了如何使用这种解密过程来理解不同人群的行为趋势的差异。]]></description>
      <guid>https://arxiv.org/abs/2503.15752</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>儿童机器人互动中的对话学习：一种个性化教育内容的混合方法</title>
      <link>https://arxiv.org/abs/2503.15762</link>
      <description><![CDATA[ARXIV：2503.15762V1公告类型：新 
摘要：对话学习通过有目的和结构化的对话来促进动机和更深入的教育理解。基础模型为儿童机器人互动提供了变革性的潜力，从而实现了个性化，引人入胜和可扩展的相互作用的设计。但是，它们整合到教育环境中，在确保适合年龄和安全的内容以及与教学目标的一致性方面提出了挑战。我们介绍了一种混合方法，以设计儿童机器人互动中的个性化教育对话。通过将基于规则的系统与LLM相结合以进行选择性离线内容产生和人类验证，该框架确保了教育质量和发展适当性。我们通过一个旨在增强阅读动机的项目来说明这种方法，在该项目中，机器人促进了与书籍相关的对话。]]></description>
      <guid>https://arxiv.org/abs/2503.15762</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Video-VOT-R1：有效的视频推理模型集成图像包装和AOE架构</title>
      <link>https://arxiv.org/abs/2503.15807</link>
      <description><![CDATA[ARXIV：2503.15807V1公告类型：新 
摘要：在视频预读的领域，现有模型在推理效率和多模式数据处理方面面临许多挑战。本文提出了基于长期图像编码器的Kunlunbaize-vot-R1视频推理模型以及其培训和应用方法。通过集成图像包装技术，专家的自主性（AOE）体系结构，并结合思想视频（fot），一种大型语言模型（LLM），该模型（LLM）接受了大规模增强学习的培训以及多​​种培训技术，该模型在视频推理任务中的效率和准确性得到了有效的改进。实验表明，该模型在多个测试中表现出色，为视频语言理解提供了一种新的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.15807</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意修剪：通过替代模拟退火对语言模型的自动公平修复</title>
      <link>https://arxiv.org/abs/2503.15815</link>
      <description><![CDATA[ARXIV：2503.15815V1公告类型：新 
摘要：本文探讨了将注意力头部作为大型语言模型（LLMS）的后处理偏置缓解方法。 LLM等现代AI系统正在扩展为敏感的社会环境，在这种情况下，公平关注变得特别关键。由于LLM通过对人类生成内容的大规模数据集进行培训来发展决策模式，因此它们自然地编码并永久存在社会偏见。在修改培训数据集和算法时很昂贵，需要大量资源；后处理技术，例如在预训练的LLMS-CAN中有选择地停用神经元和注意力头，为提高公平性提供了可行有效的方法。但是，识别参数的最佳子集以修剪参数提出了LLMS巨大参数空间内的组合挑战，这需要有效平衡模型公平和实用性边界的竞争目标的解决方案。
  为了应对计算挑战，我们通过随机模拟退火探索基于搜索的程序维修方法。鉴于数十亿参数LLM的评估成本过高，我们开发了替代深层神经网络，这些神经网络有效地建模了注意力头状态（主动/无效）之间的关系及其相应的公平/实用性指标。这使我们能够对替代模型进行优化，并有效地识别注意力头的最佳子集以进行选择性修剪，而不是直接通过LLM参数空间进行搜索。本文介绍了注意修剪，这是一种公平感知的替代模拟退火方法，用于修剪LLMS中的修剪注意力，这会导致偏见，同时最小化整体模型效用。我们的实验表明，修剪的注意力可达到高达$ 40 \％$的性别偏见，并表现优于最先进的偏见缓解策略。]]></description>
      <guid>https://arxiv.org/abs/2503.15815</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对反事实的解释进行排名</title>
      <link>https://arxiv.org/abs/2503.15817</link>
      <description><![CDATA[ARXIV：2503.15817V1公告类型：新 
摘要：AI驱动的结果对于最终用户了解可能是具有挑战性的。解释可以解决两个关键问题：“为什么这个结果？” （事实）和“为什么不另一个？” （反事实）。尽管已经做出了大量努力来形式化事实解释，但仍缺乏对反事实解释的精确而全面的研究。本文提出了对反事实解释的形式定义，证明了他们所满足的某些特性，并通过事实解释来研究这种关系。鉴于通常在特定情况下通常存在多种反事实解释，因此我们还引入了一种严格的方法来对这些反事实解释进行排名，超越了简单的最小条件，并确定了最佳的解释。我们对12个现实世界数据集进行的实验强调了，在大多数情况下，出现了一个最佳的反事实解释。我们还通过三个指标证明，所选的最佳解释具有更高的代表性，并且可以与随机最小的反事实相比，可以解释更广泛的元素。该结果突出了我们方法在确定更强大和全面的反事实解释方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.15817</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越本地选择：全球剪切选择用于增强的混合组件编程</title>
      <link>https://arxiv.org/abs/2503.15847</link>
      <description><![CDATA[ARXIV：2503.15847V1公告类型：新 
摘要：在混合式编程（MIP）求解器中，切割平面对于分支和切割（B＆amp; c）算法至关重要，因为它们会减少搜索空间并加速求解过程。传统方法依靠硬编码的启发式方法来选择平面，但无法利用特定问题的结构特征。最近的机器学习方法使用神经网络进行切割选择，但狭义地关注B＆amp; c算法中单个节点的效率，而无需考虑更广泛的上下文信息。为了解决这个问题，我们提出了全球剪切选择（GCS），该选择使用二分图来表示搜索树，并将图形神经网络与增强学习结合在一起以制定切割选择策略。与先前的方法不同，GCS在所有节点上都采用切割平面，并包含更丰富的上下文信息。实验表明，与传统和基于学习的方法相比，GCS显着提高了合成和大规模现实世界MIP的解决效率。]]></description>
      <guid>https://arxiv.org/abs/2503.15847</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于熵的探索传导多步推理</title>
      <link>https://arxiv.org/abs/2503.15848</link>
      <description><![CDATA[ARXIV：2503.15848V1公告类型：新 
摘要：在大语言模型（LLM）推理中，多步骤过程已被证明可有效解决复杂的任务。但是，探索的深度会严重影响推理性能。自动决定深度的现有方法通常会带来高昂的成本和缺乏灵活性，从而破坏了模型的推理准确性。为了解决这些问题，我们提出了基于熵的探索深度传导（Entro-Duction），这是一种新颖的方法，该方法通过监视LLM的输出熵和方差熵在多步推理过程中动态调节探索深度。我们采用这两个指标来捕获该模型的当前不确定性以及连续推理步骤的不确定性的波动。根据观察到的变化，LLM选择是否根据概率加深，扩展或停止探索。通过这种方式，我们平衡了推理的准确性和勘探效率。四个基准数据集的实验结果证明了ENTRO诱导的功效。我们进一步对Entro duction的组成部分进行实验和分析，以讨论其对推理性能的贡献。]]></description>
      <guid>https://arxiv.org/abs/2503.15848</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Deeppsy-Ancent：一种舞台意识和深刻思维的情感支持代理系统</title>
      <link>https://arxiv.org/abs/2503.15876</link>
      <description><![CDATA[ARXIV：2503.15876V1公告类型：新 
摘要：本文介绍了Deeppsy-Ancent，这是一种创新的心理支持系统，将心理学中的三阶段帮助理论与深度学习技术结合在一起。该系统由两个核心组成部分组成：（1）多阶段响应能力的对话模型（\ textIt {deeppsy-chat}），该模型通过阶段意识和深入思考的分析来增强推理能力，以产生高质量的响应； （2）一个实时阶段过渡检测模型，该模型识别上下文转移，以指导对话到更有效的干预阶段。根据30,000次真实的心理热线对话，我们采用了AI模拟的对话和专家重新注册策略来构建高质量的多转向对话数据集。实验结果表明，Deeppsy代理在关键指标（例如问题暴露完整性，认知重组成功率和采用率）中的通用大型语言模型（LLM）优于通用大型语言模型（LLM）。消融研究进一步验证了阶段意识和深入思考模块的有效性，表明阶段信息贡献了42.3 \％的性能，而深刻思维的模块将根本原因识别增加了58.3 \％，并将无效的建议降低了72.1 \％。该系统通过动态的对话管理和深入的推理来解决基于AI的心理支持的关键挑战，从而推进了智能心理健康服务。]]></description>
      <guid>https://arxiv.org/abs/2503.15876</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推进移动GUI代理：验证者驱动的实际部署方法</title>
      <link>https://arxiv.org/abs/2503.15937</link>
      <description><![CDATA[ARXIV：2503.15937V1公告类型：新 
摘要：我们提出了一种移动GUI任务自动化代理V-Droid。与以前利用大型语言模型（LLM）作为发电机直接生成操作的移动代理不同，V-Droid在做出最终决策之前使用LLMS作为验证者来评估候选行动。为了实现这种新颖的范式，我们介绍了一个综合框架，用于构建验证者驱动的移动剂：离散的动作空间构建，再加上仅预填充的工作流程，以加速验证过程，配对进度偏好培训，以显着增强了验证能力，可衡量的验证能力，并有效地缩放了可伸缩的人类代理，以有效地收集量表。 V-Droid在几个公共移动任务自动化基准中设定了新的最新任务成功率：AndroidWorld的59.5％，AndroidLab的38.3％，MobileaGentBench的49％，超过现有代理，分别超过9.5％，2.1％，2.1％和9％。此外，V-Droid每步达到0.7秒的低潜伏期，使其成为第一个能够提供近实时，有效的决策能力的移动代理。]]></description>
      <guid>https://arxiv.org/abs/2503.15937</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>虚幻图：基于非现实引擎的多代理增强学习的通用平台</title>
      <link>https://arxiv.org/abs/2503.15947</link>
      <description><![CDATA[ARXIV：2503.15947V1公告类型：新 
摘要：在本文中，我们提出了一个基于虚幻引擎（UE）的MARL通用平台（UNEL-MAP）。虚幻映射允许用户使用UE社区中可用的大量视觉和物理资源自由创建多代理任务，并在其中部署最新的MARL算法。在部署，修改和可视化方面，虚幻映射对用户友好，其所有组件都是开源的。我们还开发了一个兼容的实验框架，与第三方框架提供的算法从基于规则的算法到基于学习的算法。最后，我们在通过虚幻映射开发的示例任务中部署了几种SOTA算法，并进行相应的实验分析。我们认为，通过将现有算法与用户定制的任务紧密相结合，从而推进MARL领域，这可以通过将现有算法紧密整合到MARL领域中发挥重要作用。]]></description>
      <guid>https://arxiv.org/abs/2503.15947</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>