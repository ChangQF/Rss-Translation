<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 11 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用星系演化作为生成模型基于物理的地面实况来源</title>
      <link>https://arxiv.org/abs/2407.07229</link>
      <description><![CDATA[arXiv:2407.07229v1 公告类型：交叉 
摘要：生成图像的生成模型具有巨大的潜力，可以推动各个科学领域的发现，并且需要能够量化高维输出的指标。我们提出，天体物理数据（例如星系图像）除了人类判断之外，还可以使用额外的物理驱动的基本事实来测试生成模型。例如，宇宙中的星系在数十亿年内形成和变化，遵循物理定律和关系，这些定律和关系既易于表征又难以在生成模型中编码。我们建立了一个条件去噪扩散概率模型 (DDPM) 和一个条件变分自动编码器 (CVAE)，并测试它们根据其红移（星系年龄）生成真实星系的能力。这是首批使用物理驱动指标来探究这些生成模型的研究之一。我们发现，根据人工评估，这两种模型都能生成类似的真实星系，但我们基于物理的指标能够更好地辨别生成模型的优势和劣势。总体而言，DDPM 模型在大多数基于物理的指标上的表现都优于 CVAE。最终，如果我们能够证明生成模型可以学习星系演化的物理原理，那么它们就有可能开启新的天体物理发现。]]></description>
      <guid>https://arxiv.org/abs/2407.07229</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>探索自动驾驶感知的摄像头编码器设计</title>
      <link>https://arxiv.org/abs/2407.07276</link>
      <description><![CDATA[arXiv:2407.07276v1 公告类型：交叉 
摘要：自动驾驶汽车 (AV) 的基石是坚实的感知系统，其中摄像头编码器起着至关重要的作用。现有工作通常利用预先训练的卷积神经网络 (CNN) 或视觉变换器 (ViT)，用于一般视觉任务，例如图像分类、分割和 2D 检测。尽管这些众所周知的架构已经在 AV 相关任务（例如 3D 对象检测）中实现了最先进的精度，但由于工业级 AV 数据集的细微复杂性，网络设计仍有很大改进潜力。此外，现有的公共 AV 基准通常包含的数据不足，这可能导致对这些架构的评估不准确。为了揭示特定于 AV 的模型见解，我们从标准通用编码器 ConvNeXt 开始，并逐步改造设计。我们调整了不同的设计参数，包括模型的宽度和深度、阶段计算比率、注意机制和输入分辨率，并对每个修改进行了系统分析。这种定制产生了针对 AV 摄像头编码器优化的架构，与基线相比，mAP 提高了 8.79%。我们相信我们的努力可以成为 AV 图像编码器的甜蜜秘诀，并为下一级驱动系统铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2407.07276</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>适应性持续学习的神经模拟可塑性</title>
      <link>https://arxiv.org/abs/2407.07133</link>
      <description><![CDATA[arXiv:2407.07133v1 公告类型：交叉 
摘要：基于深度神经网络 (DNN) 模型的传统智能系统由于灾难性遗忘而难以实现类似人类的持续学习。在这里，我们提出了一种受人类工作记忆启发的元可塑性模型，使 DNN 能够在没有任何预处理或后处理的情况下进行无灾难性遗忘的持续学习。我们方法的一个关键方面涉及实现从稳定到灵活的不同类型的突触，并随机混合它们以训练具有不同灵活性的突触连接。这种策略使网络能够成功学习连续的信息流，即使在输入长度发生意外变化的情况下也是如此。该模型在不需要额外训练或结构修改的情况下实现了内存容量和性能之间的平衡，动态分配内存资源以保留新旧信息。此外，该模型通过选择性地过滤掉错误记忆，利用 Hebb 重复效应来加强对重要数据的保留，表现出对数据中毒攻击的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2407.07133</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>结合现有的事后分析方法改进分布外检测</title>
      <link>https://arxiv.org/abs/2407.07135</link>
      <description><![CDATA[arXiv:2407.07135v1 公告类型：交叉 
摘要：自 Hendrycks 等人的开创性论文 arXiv:1610.02136 以来，事后深度分布外 (OOD) 检测迅速扩展。因此，从事安全关键应用并寻求提高神经网络鲁棒性的从业者现在有大量方法可供选择。但是，没有一种方法在每个数据集 arXiv:2210.07242 上都优于其他方法，因此当前的最佳做法是在手头的数据集上测试所有方法。本文将重点从开发新方法转移到有效地结合现有方法以增强 OOD 检测。我们提出并比较了四种不同的策略，用于将多个检测分数集成到统一的 OOD 检测器中，这些策略基于多数投票、基于经验和 copulas 的累积分布函数建模以及基于最佳传输的多元分位数等技术。我们将常见的 OOD 评估指标（如固定 TPR 速率下的 AUROC 和 FPR）扩展到这些多维 OOD 检测器，使我们能够对它们进行评估，并在广泛的基准上将它们与单个方法进行比较。此外，我们提出了一系列指导方针，以选择在更现实的设置中组合哪些 OOD 检测器，即在没有已知 OOD 数据的情况下，依靠来自 Outlier Exposure arXiv:1812.04606 的原则。代码可在 https://github.com/paulnovello/multi-ood 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.07135</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散模型的视频编辑：综述</title>
      <link>https://arxiv.org/abs/2407.07111</link>
      <description><![CDATA[arXiv:2407.07111v1 公告类型：交叉 
摘要：扩散模型 (DM) 的快速发展极大地推动了图像和视频应用的发展，使“所见即所得”成为现实。其中，视频编辑引起了广泛关注，研究活动迅速增加，因此有必要对现有文献进行全面而系统的回顾。本文回顾了基于扩散模型的视频编辑技术，包括理论基础和实际应用。我们首先概述数学公式和图像领域的关键方法。随后，我们根据核心技术的内在联系对视频编辑方法进行分类，描绘出进化轨迹。本文还深入探讨了新颖的应用，包括基于点的编辑和姿势引导的人体视频编辑。此外，我们使用我们新推出的 V2VBench 进行了全面的比较。基于迄今为止取得的进展，本文最后总结了持续的挑战和未来研究的潜在方向。]]></description>
      <guid>https://arxiv.org/abs/2407.07111</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>FedClust：通过权重驱动的客户端聚类解决联邦学习中的数据异质性问题</title>
      <link>https://arxiv.org/abs/2407.07124</link>
      <description><![CDATA[arXiv:2407.07124v1 公告类型：交叉 
摘要：联邦学习 (FL) 是一种新兴的分布式机器学习范式，它能够在分散设备上协作训练机器学习模型，而无需暴露其本地数据。FL 的主要挑战之一是客户端设备之间的数据分布不均匀，这违反了传统机器学习中众所周知的独立同分布 (IID) 训练样本假设。为了解决由这种数据异质性引起的性能下降问题，集群联邦学习 (CFL) 通过根据客户端本地数据分布的相似性将其分组为单独的学习集群来展现其前景。然而，最先进的 CFL 方法需要大量的通信轮次来学习训练过程中的分布相似性，直到集群的形成稳定下来。此外，其中一些算法严重依赖于预定义的集群数量，从而限制了它们的灵活性和适应性。在本文中，我们提出了一种新的 CFL 方法 FedClust，该方法利用了本地模型权重与客户端数据分布之间的相关性。FedClust 根据本地训练模型的策略性选择的部分权重来测量客户端之间的相似度，从而一次性将客户端分组到群集中。我们在具有不同非 IID 数据设置的四个基准数据集上进行了广泛的实验。实验结果表明，与最先进的同类产品相比，FedClust 实现了高达 $\sim$45\% 的更高模型准确率以及更快的收敛速度，并且通信成本显著降低了 2.7$\times$。]]></description>
      <guid>https://arxiv.org/abs/2407.07124</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>使用基于网格的游戏竞赛评估大型语言模型：可扩展的 LLM 基准和排行榜</title>
      <link>https://arxiv.org/abs/2407.07796</link>
      <description><![CDATA[arXiv:2407.07796v2 公告类型：新
摘要：我们通过基于网格的游戏（例如井字棋、四子棋和五子棋）为大型语言模型 (LLM) 引入了一种新颖且可扩展的基准。开源游戏模拟代码可在 GitHub 上获取，它允许 LLM 进行竞争并生成 JSON、CSV、TXT 和 PNG 格式的详细数据文件，用于排行榜排名和进一步分析。我们展示了领先 LLM 之间的游戏结果，包括 Anthropic 的 Claude 3.5 Sonnet 和 Claude 3 Sonnet、谷歌的 Gemini 1.5 Pro 和 Gemini 1.5 Flash、OpenAI 的 GPT-4 Turbo 和 GPT-4o 以及 Meta 的 Llama3-70B。我们也鼓励提交其他 LLM 的结果。总共，我们模拟了 2,310 场比赛（7 名 LLM 和一名随机玩家每对 5 场比赛），涉及三种类型的游戏，使用三种不同的提示类型：列表、插图和图像。结果显示，LLM 在不同游戏和提示类型中的表现存在显著差异，分析涵盖了获胜和取消资格率、错失机会分析和无效动作分析。排行榜和结果矩阵数据的详细信息可作为 GitHub 上的开放访问数据获得。这项研究增强了我们对 LLM 在玩未经专门训练的游戏时的能力的理解，有助于评估他们的规则理解和战略思维。在通用人工智能 (AGI) 的道路上，这项研究为未来探索它们在复杂决策场景中的效用奠定了基础，阐明了它们的战略思维能力，并为进一步探究基于游戏的框架内 LLM 的局限性提供了方向。]]></description>
      <guid>https://arxiv.org/abs/2407.07796</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>Nash CoT：具有偏好均衡的多路径推理</title>
      <link>https://arxiv.org/abs/2407.07099</link>
      <description><![CDATA[arXiv:2407.07099v1 公告类型：交叉 
摘要：思路链 (CoT) 提示已成为一种强大的技术，可增强大型语言模型 (LLM) 在复杂问题上的推理能力。在与 CoT 相关的研究中，自我一致性（通过投票进行答案过滤的多路径推理）涉及使用 CoT 框架生成多条推理路径，然后选择最常产生的输出，这是一种简洁而有竞争力的方法。虽然自我一致性确实导致了 LLM 推理的改进，但使用多路径推理也会增加部署成本。因此，在降低推理成本的同时保持从多路径推理继承的自我一致性的性能优势具有重要价值。在这项研究中，我们将语言解码概念化为偏好共识游戏，在每个本地路径内构建一个双人游戏系统，并引入纳什思路链 (Nash CoT)。具体来说，对于给定的问题，我们利用 LLM 自主选择上下文相关的模板并生成由该模板引导的输出，旨在达到纳什均衡，同时在每条路径上实现正常生成。这种方法使我们能够在各种推理任务（包括阿拉伯语推理、常识性问答和符号推理）上使用更少的推理路径，同时实现与自洽性相当或更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.07099</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>心电图基础模型</title>
      <link>https://arxiv.org/abs/2407.07110</link>
      <description><![CDATA[arXiv:2407.07110v1 公告类型：交叉 
摘要：通过自监督学习 (SSL) 技术增强的基础模型代表了生物医学信号分析的前沿，特别是对于心电图 (ECG)，这对于心脏健康监测和诊断至关重要。本研究通过采用和改进创新的 SSL 方法（即生成和对比学习）对超过 110 万个 ECG 样本的庞大数据集对 ECG 的基础模型进行了全面分析。通过定制这些方法以适应 ECG 信号的复杂特征，我们的研究成功开发了基础模型，显着提高了心脏诊断的精度和可靠性。这些模型擅长表示 ECG 数据的复杂、微妙的细微差别，从而显着增强了诊断能力。结果强调了 SSL 增强的基础模型在临床环境中的巨大潜力，并为未来在更广泛的医疗诊断领域对其可扩展应用的广泛研究铺平了道路。这项工作为心电图领域树立了标杆，展示了定制的数据驱动模型训练对医疗诊断的功效和准确性的深远影响。]]></description>
      <guid>https://arxiv.org/abs/2407.07110</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>利用潜在图扩散实现二级结构引导的新型蛋白质序列生成</title>
      <link>https://arxiv.org/abs/2407.07443</link>
      <description><![CDATA[arXiv:2407.07443v1 公告类型：新
摘要：深度学习的出现为从头蛋白质序列设计引入了有效的方法，与计算或实验方法相比，成功率显著提高，开发成本降低。然而，现有方法在生成具有不同长度和形状的蛋白质同时保持关键结构特征方面面临挑战。为了应对这些挑战，我们引入了 CPDiffusion-SS，这是一种基于粗粒度二级结构信息生成蛋白质序列的潜在图扩散模型。CPDiffusion-SS 在保留整体结构约束的同时，在生成各种新型氨基酸序列方面提供了更大的灵活性，从而提高了生成蛋白质的可靠性和多样性。实验分析证明了所提出的方法在生成多样化和新颖序列方面的显著优势，CPDiffusion-SS 在各种定量测量的开放基准上超越了流行的基线方法。此外，我们提供了一系列案例研究，以强调所提出方法的生成性能的生物学意义。源代码可在 https://github.com/riacd/CPDiffusion-SS 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2407.07443</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要实现道德决策的自动化？</title>
      <link>https://arxiv.org/abs/2407.07671</link>
      <description><![CDATA[arXiv:2407.07671v1 公告类型：新
摘要：虽然人们普遍相信人工智能能够在生活的各个方面做出决定，但当人工智能参与具有重大道德影响的决策时，人们就会担心。道德推理缺乏精确的数学框架，这加剧了这些担忧，因为伦理学往往不符合简单的数学模型。与逻辑推理、不确定性推理和战略决策等领域不同，道德推理缺乏一个被广泛接受的框架，这些领域有明确的数学框架。这种缺失引发了人们对我们对人工智能道德决策能力的信心的质疑。
如今，人工智能系统通常接受训练的环境似乎不够丰富，不足以让这样的系统从头开始学习伦理，即使我们有合适的环境，我们也不清楚我们如何实现这种学习。另一种方法是让人工智能从人类的道德决策中学习。这个学习过程可以包括在特定领域汇总精心策划的人类判断或演示，或者利用一个由广泛数据提供的基础模型。然而，鉴于人类道德决策的不完善，人们的担忧依然存在。
鉴于此，我们为什么要自动化道德决策——将所有道德决策都留给人类不是更好吗？本文列举了我们应该期望人工智能系统参与具有道德成分的决策的若干原因，并简要讨论了相关风险。]]></description>
      <guid>https://arxiv.org/abs/2407.07671</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:50 GMT</pubDate>
    </item>
    <item>
      <title>融合、推理和验证：利用图表解析子句解决几何问题</title>
      <link>https://arxiv.org/abs/2407.07327</link>
      <description><![CDATA[arXiv:2407.07327v1 公告类型：新
摘要：几何问题求解（GPS）需要多模态理解、多跳推理和定理知识应用的能力。本文提出了一种用于平面几何问题求解的神经符号模型（PGPS），名为PGPSNet-v2，其关键步骤包括三个：模态融合、推理过程和知识验证。在模态融合中，我们利用文本子句来表达几何图的细粒度结构和语义内容，并通过结构语义预训练将图表与文本问题有效地融合。对于推理，我们设计了一个可解释的解程序来描述几何推理过程，并使用自限解码器自回归地生成解程序。为了减少解的错误，提出了一个多级定理验证器来消除与几何原理不符的解，从而减轻神经模型的幻觉。我们还构建了一个名为 PGPS9K 的大规模几何问题数据集，其中包含文本子句、解决方案和所涉及知识元组的细粒度注释。在 Geometry3K 和 PGPS9K 数据集上进行的大量实验表明，我们的 PGPSNet 求解器在 GPS 性能方面优于现有的符号和神经求解器，同时保持了良好的可解释性和可靠性，并且求解器组件（融合、推理、验证）均被证明是有效的。]]></description>
      <guid>https://arxiv.org/abs/2407.07327</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:49 GMT</pubDate>
    </item>
    <item>
      <title>稳定权重更新：利用深度学习实现可靠 PDE 解决方案的关键</title>
      <link>https://arxiv.org/abs/2407.07375</link>
      <description><![CDATA[arXiv:2407.07375v1 公告类型：新
摘要：背景：深度学习技术，特别是神经网络，已经彻底改变了计算物理学，为解决复杂的偏微分方程 (PDE) 提供了强大的工具。然而，确保稳定性和效率仍然是一个挑战，特别是在涉及非线性和时间相关方程的场景中。方法：本文介绍了新的基于残差的架构，即简单高速公路网络和平方残差网络，旨在提高物理信息神经网络 (PINN) 的稳定性和准确性。这些架构通过合并残差连接来增强传统神经网络，这有助于更平滑地更新权重并提高反向传播效率。结果：通过对包括线性和非线性、时间相关和独立 PDE 在内的各种示例进行广泛的数值实验，我们证明了所提出的架构的有效性。特别是平方残差网络表现出稳健的性能，与传统神经网络相比，实现了更高的稳定性和准确性。这些发现强调了基于残差的架构在推动 PDE 和计算物理应用的深度学习方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.07375</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:49 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习进行结构设计</title>
      <link>https://arxiv.org/abs/2407.07288</link>
      <description><![CDATA[arXiv:2407.07288v1 公告类型：新
摘要：本文介绍了结构优化健身房 (SOgym)，这是一种新颖的开源强化学习环境，旨在推动机器学习在拓扑优化中的应用。SOgym 旨在通过将 TO 的物理原理直接集成到奖励函数中，让 RL 代理学习生成物理上可行且结构稳健的设计。为了增强可扩展性，SOgym 利用特征映射方法作为环境和代理之间的网格独立接口，无论网格分辨率如何，都可以与设计变量进行有效交互。使用无模型近端策略优化代理和基于模型的 DreamerV3 代理呈现基线结果。测试了三种观察空间配置。TopOpt 游戏启发配置是一种交互式教育工具，可提高学生在设计结构以最大限度地降低体积约束下的合规性方面的直觉，在性能和样本效率方面表现最佳。 DreamerV3 的 100M 参数版本产生的结构与传统优化方法实现的基线顺应性相差 54%，断开率达到 0%，这比经常难以处理断开负载路径的监督学习方法有所改进。将智能体的学习率与 TopOpt 游戏实验中的工程专业学生的学习率进行比较时，DreamerV3-100M 模型的学习率大约低了四个数量级，对于通过反复试验从头开始训练的策略来说，这是一个令人印象深刻的成就。这些结果表明 RL 具有解决连续 TO 问题的潜力，以及探索和学习各种设计解决方案的能力。SOgym 提供了一个用于开发 RL 智能体的平台，用于应对复杂的结构设计挑战，并且可公开使用以支持该领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2407.07288</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:48 GMT</pubDate>
    </item>
    <item>
      <title>CPU 上大型语言模型的推理性能优化</title>
      <link>https://arxiv.org/abs/2407.07304</link>
      <description><![CDATA[arXiv:2407.07304v1 公告类型：新
摘要：大型语言模型（LLM）在各种任务中表现出色，潜力巨大。然而，在低资源环境中部署高性能的LLM已引起业界的极大关注。当GPU硬件资源有限时，我们可以在CPU上探索替代方案。为了减轻财务负担并缓解硬件资源的限制，优化推理性能是必要的。在本文中，我们介绍了一种易于部署的推理性能优化解决方案，旨在加速CPU上的LLM。在这个解决方案中，我们实现了一种有效的方法来减少KV缓存的大小，同时确保精度。我们提出了一种分布式推理优化方法，并基于oneAPI Collective Communications Library实现它。此外，我们提出了CPU上LLM的优化方法，并针对最常用的模型进行了量身定制的优化。代码在https://github.com/intel/xFasterTransformer开源。]]></description>
      <guid>https://arxiv.org/abs/2407.07304</guid>
      <pubDate>Fri, 12 Jul 2024 03:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>