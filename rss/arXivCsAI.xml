<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>KnowWhereGraph 本体</title>
      <link>https://arxiv.org/abs/2410.13948</link>
      <description><![CDATA[arXiv:2410.13948v1 公告类型：新
摘要：KnowWhereGraph 是最大的完全公开可用的地理空间知识图谱之一。它包括 30 个层级的数据，涉及自然灾害（例如飓风、野火）、气候变量（例如气温、降水）、土壤特性、作物和土地覆盖类型、人口统计和人类健康、各种地点和地区标识符等主题。各种应用程序通过图表利用这些数据来应对粮食安全和农业供应链中的挑战；与土壤保护实践和农场劳动力相关的可持续性；以及灾难发生后提供紧急人道主义援助。在本文中，我们介绍了作为 KnowWhereGraph 模式的本体。这个广泛的概述提供了对图表及其模式的要求和设计规范的深入了解，包括开发方法（模块化本体建模）和用于实现、实现和部署 KnowWhereGraph 及其最终用户界面和公共查询 SPARQL 端点的资源。]]></description>
      <guid>https://arxiv.org/abs/2410.13948</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从开放式对话中推断目标</title>
      <link>https://arxiv.org/abs/2410.13957</link>
      <description><![CDATA[arXiv:2410.13957v1 公告类型：新
摘要：我们提出了一种在线方法，让具身代理学习并实现不同的用户目标。虽然像 RLHF 这样的离线方法可以表示各种目标，但需要大量数据集，但我们的方法实现了类似的灵活性和在线效率。我们从与大型语言模型 (LLM) 的对话中提取自然语言目标表示。我们提示 LLM 扮演具有不同目标的人类，并使用相应的可能性对潜在目标进行贝叶斯推理。因此，我们的方法可以根据不受限制的对话来表示复杂目标的不确定性。我们分别使用基于文本的界面和 AI2Thor 模拟在杂货店购物和家用机器人辅助领域评估我们的方法。结果表明，我们的方法优于缺乏明确目标表示或概率推理的消融基线。]]></description>
      <guid>https://arxiv.org/abs/2410.13957</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CausalChat：使用大型语言模型进行交互式因果模型开发和改进</title>
      <link>https://arxiv.org/abs/2410.14146</link>
      <description><![CDATA[arXiv:2410.14146v1 公告类型：新
摘要：因果网络在许多领域被广泛用于建模变量之间的复杂关系。最近的一种方法试图通过人类的集体参与，利用群体智慧来构建因果网络。虽然这可以产生能够很好地模拟潜在现象的详细因果网络，但它需要大量具有领域理解能力的个体。我们采用了一种不同的方法：利用大型语言模型（例如 OpenAI 的 GPT-4）通过吸收大量文献学到的因果知识。在一个名为 CausalChat 的专用可视化分析界面中，用户可以递归地探索单个变量或变量对以识别因果关系、潜在变量、混杂因素和中介因素，通过对话构建详细的因果网络。每个探测交互都被转换成定制的 GPT-4 提示，并通过与生成的文本链接的视觉表示来传达响应以进行解释。我们展示了 CausalChat 在不同数据环境中的功能，并开展了涉及领域专家和外行人员的用户研究。]]></description>
      <guid>https://arxiv.org/abs/2410.14146</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行事件解构，以增强基于多模态方面的情绪分析</title>
      <link>https://arxiv.org/abs/2410.14150</link>
      <description><![CDATA[arXiv:2410.14150v1 Announce Type: new 
摘要：随着互联网的快速发展，用户生成内容的丰富度不断提升，多模态方面情感分析（MABSA）成为研究热点。现有研究在MABSA方面取得了一定的成果，但并未有效解决多实体和多情感共存场景下的分析挑战。本文创新性地引入大型语言模型（LLM）进行事件分解，提出了一种基于强化学习的多模态方面情感分析（MABSA-RL）框架。该框架利用LLM将原文分解为事件集，降低分析复杂度，引入强化学习优化模型参数。实验结果表明，MABSA-RL在两个基准数据集上优于现有的先进方法。本文为多模态方面情感分析提供了一种新的研究视角和方法。]]></description>
      <guid>https://arxiv.org/abs/2410.14150</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能的正式解释</title>
      <link>https://arxiv.org/abs/2410.14219</link>
      <description><![CDATA[arXiv:2410.14219v1 公告类型：新
摘要：尽管人工智能 (AI) 在实践中取得了成功，但当前的神经 AI 算法面临两个重大问题。首先，神经架构做出的决策往往容易产生偏见和脆弱性。其次，当需要一系列推理时，神经系统通常表现不佳。神经符号人工智能是一种很有前途的方法，它通过结合神经感知和符号推理的力量来解决这些（和其他）弱点。同时，人工智能的成功使得理解其行为变得至关重要，从而导致了可解释人工智能 (XAI) 的发展。虽然神经符号 AI 系统比纯神经 AI 具有重要优势，但我们仍然需要解释它们的行为，而这些行为被神经和符号成分的相互作用所掩盖。为了解决这个问题，本文提出了一种解释神经符号系统决策的形式化方法。该方法取决于使用正式的溯因解释和分层解决神经符号可解释性问题。也就是说，它首先计算系统的符号组件的形式解释，用于识别需要解释的神经信息各个部分的子集。然后，仅解释那些彼此独立的单个神经输入，这有助于简化分层形式解释，并有助于提高该方法的整体性能。一些复杂推理任务的实验结果表明，与纯神经系统相比，从解释大小、解释时间、训练时间、模型大小和报告的解释质量来看，所提出的方法具有实际效率。]]></description>
      <guid>https://arxiv.org/abs/2410.14219</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多智能体模拟合成法学硕士 (LLM) 的训练后数据</title>
      <link>https://arxiv.org/abs/2410.14251</link>
      <description><![CDATA[arXiv:2410.14251v1 公告类型：新
摘要：后期训练对于使大型语言模型 (LLM) 遵循人类指令至关重要。受到最近使用 LLM 模拟人类社会的成功启发，我们利用多智能体模拟自动生成各种基于文本的场景，捕捉广泛的现实世界人类需求。我们提出了 MATRIX，这是一个可以创建逼真且可扩展场景的多智能体模拟器。利用这些输出，我们引入了一种新颖的场景驱动指令生成器 MATRIX-Gen，用于可控且高度逼真的数据合成。大量实验表明，我们的框架可以有效地生成通用数据和特定领域的数据。值得注意的是，在 AlpacaEval 2 和 Arena-Hard 基准测试中，使用 MATRIX-Gen 合成的数据集（仅 20K 个指令-响应对）进行后训练的 Llama-3-8B-Base 表现优于使用超过 1000 万个指令-响应对进行训练的 Meta 的 Llama-3-8B-Instruct 模型；请参阅我们的项目 https://github.com/ShuoTang123/MATRIX-Gen。]]></description>
      <guid>https://arxiv.org/abs/2410.14251</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Nova：一种迭代规划和搜索方法，用于增强 LLM 生成想法的新颖性和多样性</title>
      <link>https://arxiv.org/abs/2410.14255</link>
      <description><![CDATA[arXiv:2410.14255v1 公告类型：新
摘要：科学创新对人类至关重要，利用大型语言模型 (LLM) 来产生研究想法可以改变发现。然而，现有的 LLM 通常会产生过于简单和重复的建议，因为它们在获取创新外部知识方面的能力有限。为了解决这个问题，我们引入了一种增强的规划和搜索方法，旨在提高基于 LLM 的系统的创造潜力。我们的方法涉及一个迭代过程，有目的地规划外部知识的检索，逐步丰富想法的生成，提供更广泛和更深入的见解。通过自动和人工评估的验证表明，我们的框架大大提高了生成想法的质量，特别是在新颖性和多样性方面。我们的框架产生的独特新颖想法的数量是没有它的 3.4 倍。此外，我们的方法优于目前最先进的方法，在瑞士锦标赛评估中，基于 170 篇种子论​​文产生的顶级想法至少多 2.5 倍。]]></description>
      <guid>https://arxiv.org/abs/2410.14255</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoMAL：用于混合自主交通的协作多智能体大型语言模型</title>
      <link>https://arxiv.org/abs/2410.14368</link>
      <description><![CDATA[arXiv:2410.14368v1 公告类型：新
摘要：自动驾驶汽车融入城市交通，通过减少拥堵和系统地优化交通流量，具有提高效率的巨大潜力。在本文中，我们介绍了 CoMAL（协作多智能体 LLM），这是一个旨在通过自动驾驶汽车之间的协作来优化交通流量，解决混合自动驾驶交通问题的框架。CoMAL 建立在大型语言模型之上，在交互式交通模拟环境中运行。它利用感知模块来观察周围的智能体，利用记忆模块来存储每个智能体的策略。整体工作流程包括一个协作模块，鼓励自动驾驶汽车讨论有效策略并分配角色，一个推理引擎，根据分配的角色确定最佳行为，以及一个执行模块，使用结合基于规则的模型的混合方法控制车辆动作。实验结果表明，CoMAL 在 Flow 基准上取得了优异的表现。此外，我们评估了不同语言模型的影响，并将我们的框架与强化学习方法进行了比较。它突出了 LLM 代理的强大协作能力，并提出了一种有希望的混合自治交通挑战解决方案。代码可在 https://github.com/Hyan-Yao/CoMAL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.14368</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的端到端神经符号强化学习代理</title>
      <link>https://arxiv.org/abs/2410.14371</link>
      <description><![CDATA[arXiv:2410.14371v1 公告类型：新
摘要：深度强化学习 (RL) 代理依赖于捷径学习，这阻止了它们推广到略有不同的环境。为了解决这个问题，已经开发了使用以对象为中心的状态的符号方法。但是，将这些方法与深度代理进行比较并不公平，因为后者是从原始像素状态开始操作的。在这项工作中，我们实例化了符号 SCoBots 框架。SCoBots 将 RL 任务分解为中间的、可解释的表示，最终基于一组可理解的以对象为中心的关系概念做出行动决策。这种架构有助于揭开代理决策的神秘面纱。通过明确学习从原始状态、以对象为中心的 RL 和通过规则提取的策略提炼中提取以对象为中心的表示，这项工作将自己置于神经符号 AI 范式中，将神经网络的优势与符号 AI 相结合。我们展示了端到端训练的 SCoBot 的第一个实现，并在不同的 Atari 游戏中分别评估其组件。结果证明了该框架创建可解释和执行的 RL 系统的潜力，并为未来获得端到端可解释的 RL 代理的研究方向铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14371</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当 LLM 遵循指示时，他们内心是否“知道”？</title>
      <link>https://arxiv.org/abs/2410.14516</link>
      <description><![CDATA[arXiv:2410.14516v1 公告类型：新
摘要：指令遵循对于使用大型语言模型 (LLM) 构建 AI 代理至关重要，因为这些模型必须严格遵守用户提供的约束和指南。然而，LLM 往往无法遵循简单而明确的指令。为了改善指令遵循行为并防止不良输出，需要更深入地了解 LLM 的内部状态与这些结果的关系。我们对 LLM 内部状态的分析揭示了输入嵌入空间中与成功遵循指令相关的维度。我们证明，与随机更改相比，沿此维度修改表示可以提高指令遵循的成功率，而不会影响响应质量。进一步的调查显示，这个维度与提示的措辞更密切相关，而不是任务或指令的固有难度。这一发现还解释了为什么 LLM 有时无法遵循明确的指令，以及为什么即使内容基本保持不变，提示工程也往往有效。这项工作深入了解了法学硕士 (LLM) 遵循指令的内部运作，为可靠的法学硕士 (LLM) 代理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14516</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LTLf 中责任归因和预期的计算基础</title>
      <link>https://arxiv.org/abs/2410.14544</link>
      <description><![CDATA[arXiv:2410.14544v1 公告类型：新
摘要：责任是机器伦理和自主系统领域的关键概念之一。它是一个多方面的概念，涉及对行动和策略的反事实推理。在本文中，我们基于 LTLf 研究战略环境中的不同责任变体。我们展示了与反应合成中的概念的联系，包括获胜、主导和尽力而为策略的综合。这种联系为责任的计算基础提供了基础，包括复杂性特征以及用于归因和预测责任的合理、完整和最佳算法。]]></description>
      <guid>https://arxiv.org/abs/2410.14544</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransBox: EL++封闭的本体嵌入</title>
      <link>https://arxiv.org/abs/2410.14571</link>
      <description><![CDATA[arXiv:2410.14571v1 公告类型：新
摘要：OWL（Web 本体语言）本体能够将关系和类型事实表示为标准知识图谱，将复杂领域知识表示为描述逻辑（DL）公理，广泛应用于医疗保健和生物信息学等领域。受知识图谱嵌入成功的启发，嵌入 OWL 本体近年来引起了广泛关注。当前的方法主要侧重于学习原子概念和角色的嵌入，通过专门设计的评分函数实现基于规范化公理的评估。然而，它们往往忽略了复杂概念的嵌入，使得用更复杂的公理进行推断变得困难。这种限制降低了它们在高级推理任务（如本体学习和本体介导的查询回答）中的有效性。在本文中，我们提出了 EL++ 封闭本体嵌入，它能够通过组合在 DL 中表示任何逻辑表达式。此外，我们开发了 TransBox，这是一种有效的 EL++ 封闭本体嵌入方法，可以处理多对一、一对多和多对多关系。我们大量的实验表明，TransBox 通常在各种现实世界数据集中实现最佳性能，用于预测复杂的公理。]]></description>
      <guid>https://arxiv.org/abs/2410.14571</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能很好地估计指令遵循中的不确定性吗？</title>
      <link>https://arxiv.org/abs/2410.14582</link>
      <description><![CDATA[arXiv:2410.14582v1 公告类型：新
摘要：大型语言模型 (LLM) 可以成为各个领域的有价值的个人 AI 代理，前提是它们能够精确地遵循用户指令。然而，最近的研究表明 LLM 的指令遵循能力存在很大局限性，这引发了人们对其在高风险应用中的可靠性的担忧。准确评估 LLM 在遵守指令方面的不确定性对于降低部署风险至关重要。据我们所知，我们首次系统地评估了 LLM 在指令遵循方面的不确定性估计能力。我们的研究确定了现有指令遵循基准的主要挑战，其中多种因素与来自指令遵循的不确定性纠缠在一起，使方法和模型之间的隔离和比较变得复杂。为了解决这些问题，我们引入了一个受控评估设置，其中包含两个基准版本的数据，从而能够全面比较各种条件下的不确定性估计方法。我们的研究结果表明，现有的不确定性方法很难，尤其是当模型在指令遵循中出现细微错误时。虽然内部模型状态提供了一些改进，但它们在更复杂的场景中仍然不足。我们从受控评估设置中获得的见解为理解 LLM 的局限性和在指令跟随任务中不确定性估计的潜力提供了关键的理解，为更值得信赖的 AI 代理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.14582</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MCSFF：用于实体对齐的多模态一致性和特异性融合框架</title>
      <link>https://arxiv.org/abs/2410.14584</link>
      <description><![CDATA[arXiv:2410.14584v1 公告类型：新
摘要：多模态实体对齐 (MMEA) 对于增强知识图谱和改进信息检索和问答系统至关重要。现有方法通常侧重于通过模态的互补性来整合模态，但忽略了每种模态的特殊性，这可能会掩盖关键特征并降低对齐准确性。为了解决这个问题，我们提出了多模态一致性和特异性融合框架 (MCSFF)，它创新地整合了模态的互补性和特异性方面。我们利用 Scale Computing 的超融合基础设施来优化大规模数据处理中的 IT 管理和资源分配。我们的框架首先使用模态嵌入计算每种模态的相似度矩阵以保留其独特特征。然后，迭代更新方法对模态特征进行去噪和增强，以充分表达关键信息。最后，我们整合来自所有模态的更新信息，以创建丰富而精确的实体表示。实验表明，我们的方法在 MMKG 数据集上的表现优于当前最先进的 MMEA 基线，证明了其有效性和实用潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.14584</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联想记忆和死亡神经元</title>
      <link>https://arxiv.org/abs/2410.13866</link>
      <description><![CDATA[arXiv:2410.13866v1 公告类型：交叉 
摘要：在“神经生物学和机器学习中的大型联想记忆问题”中，Dmitry Krotov 和 John Hopfield 介绍了一种系统构建具有非增加能量或 Lyapunov 函数的神经常微分方程的通用技术。我们研究了这种能量函数，并发现它容易受到神经元死亡问题的影响。神经元死亡的状态空间中的每个点都包含在具有恒定能量的非紧凑区域中。在这些平坦区域中，能量函数本身并不能完全确定所有自由度，因此不能用于分析稳定性或找到稳定状态或吸引盆地。我们对动态系统进行直接分析，并展示如何解决由对应于死神经元的平坦方向引起的问题：（i）可以从能量和 Hessian 矩阵（拉格朗日函数）中提取有关固定点处状态向量的所有信息，（ii）在 Hessian 矩阵范围内分析稳定性就足够了，（iii）如果接触平坦区域的稳定状态是稳定的，则整个平坦区域就是吸引盆。对于实际架构，Hessian 矩阵的分析可能很复杂，因此我们表明，对于略微改变的动态系统（具有相同的稳定状态结构），可以推导出没有对应于死神经元的平坦区域的多样化 Lyapunov 函数系列。此外，这些能量函数允许将拉格朗日函数与不一定是正定的 Hessian 矩阵一起使用，甚至可以考虑具有非对称前馈和反馈连接的架构。]]></description>
      <guid>https://arxiv.org/abs/2410.13866</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>