<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 04 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于地标的任务分解的 LLM 增强符号强化学习</title>
      <link>https://arxiv.org/abs/2410.01929</link>
      <description><![CDATA[arXiv:2410.01929v1 公告类型：新
摘要：强化学习 (RL) 的基本挑战之一是将复杂的任务分解为更易于 RL 代理学习的子任务。在本文中，我们报告了我们的工作，该工作将通过使用一些给定的正向和负向轨迹来解决复杂任务来识别子任务。我们假设状态由一阶谓词逻辑表示，我们利用该逻辑设计了一种新算法来识别子任务。然后，我们使用大型语言模型 (LLM) 来生成用于实现每个子任务的一阶逻辑规则模板。然后，通过基于归纳逻辑编程 (ILP) 的 RL 代理将这些规则进一步微调为基于规则的策略。通过实验，我们验证了我们的算法在检测子任务方面的准确性，该算法成功地正确检测了所有子任务。我们还调查了语言模型为实现子任务而生成的常识性规则的质量。我们的实验表明，我们的 LLM 指导规则模板生成可以生成解决子任务所需的规则，从而可以用更少的关于环境预定义的一阶逻辑谓词的假设来解决复杂任务。]]></description>
      <guid>https://arxiv.org/abs/2410.01929</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>距离迷失：上下文接近度对图形任务中 LLM 性能的影响</title>
      <link>https://arxiv.org/abs/2410.01985</link>
      <description><![CDATA[arXiv:2410.01985v1 公告类型：新
摘要：尽管取得了重大进展，但大型语言模型 (LLM) 仍存在盲点，削弱了它们检索和有效处理相关上下文数据的能力。我们证明，LLM 在图形任务中的表现超出了“大海捞针”的场景——解决问题需要跨多个子问题进行交叉引用和推理——受到上下文中相关信息的接近度的影响，我们称这种现象为“距离丢失”。我们研究了两个基本的图形任务：识别两个节点之间的共同连接和评估三个节点之间的相似性，并表明模型在这些任务中的性能显著取决于公共边的相对定位。我们使用各种图形编码技术评估了三个公开可用的 LLM - Llama-3-8B、Llama-3-70B 和 GPT-4，这些技术代表了 LLM 输入的图形结构。我们提出了一种用于描述“距离迷失”现象的公式，并证明“距离迷失”和“中间迷失”现象是独立发生的。结果表明，随着节点连接距离的增加，模型准确率可能会下降高达 6 倍，与图编码和模型大小无关。]]></description>
      <guid>https://arxiv.org/abs/2410.01985</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zodiac：用于多智能体诊断的心脏病专家级 LLM 框架</title>
      <link>https://arxiv.org/abs/2410.02026</link>
      <description><![CDATA[arXiv:2410.02026v1 公告类型：新
摘要：大型语言模型 (LLM) 在医疗保健领域取得了显著进展。然而，LLM 在特定领域临床实践中的专业性仍然存在很大差距，限制了它们在现实世界诊断中的应用。在这项工作中，我们介绍了 ZODIAC，这是一个由 LLM 驱动的框架，具有心脏病专家级别的专业性，旨在让 LLM 参与心脏病诊断。ZODIAC 通过从患者数据中提取临床相关特征、检测显著的心律失常以及生成初步报告供心脏病专家审查和改进来协助心脏病专家。为了实现心脏病专家级别的专业性，ZODIAC 建立在多智能体协作框架上，能够跨多种模式处理患者数据。每个 LLM 代理都使用心脏病专家裁定的真实患者数据进行微调，从而增强了模型的专业性。 ZODIAC 经过独立心脏病专家的严格临床验证，通过八项指标进行评估，以衡量临床有效性并解决安全问题。结果表明，ZODIAC 的表现优于行业领先的模型，包括 OpenAI 的 GPT-4o、Meta 的 Llama-3.1-405B 和 Google 的 Gemini-pro，以及 Microsoft 的 BioGPT 等医学专家 LLM。ZODIAC 通过提供满足医疗实践严格要求的领域特定解决方案，展示了专业 LLM 在医疗保健领域的变革潜力。值得注意的是，ZODIAC 已成功集成到心电图 (ECG) 设备中，体现了将 LLM 嵌入软件即医疗设备 (SaMD) 的日益增长的趋势。]]></description>
      <guid>https://arxiv.org/abs/2410.02026</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跟踪外观以相位同步变化的物体</title>
      <link>https://arxiv.org/abs/2410.02094</link>
      <description><![CDATA[arXiv:2410.02094v1 公告类型：新
摘要：我们遇到的物体在与它们互动时经常会改变外观。照明（阴影）、物体姿势或非刚性物体的移动的变化会极大地改变可用的图像特征。生物视觉系统如何跟踪变化中的物体？它可能涉及特定的注意力机制，用于独立于物体外观推断物体的位置——一种著名的神经科学理论与通过神经同步进行计算相关的能力。我们通过计算测试了以下假设：通过神经同步实现视觉注意力是生物视觉系统跟踪外观随时间变化的物体的能力的基础。我们首先介绍一种新颖的深度学习电路，它可以通过神经同步学习精确控制对特征的注意力，而不受其在世界上的位置的影响：复值循环神经网络 (CV-RNN)。接下来，我们使用 FeatureTracker 比较人类、CV-RNN 和其他深度神经网络 (DNN) 中的物体跟踪：这是一项大规模挑战，要求观察者在物体的位置和外观以精确控制的方式发生变化时跟踪它们。虽然人类毫不费力地解决了 FeatureTracker，但最先进的 DNN 却没有。相比之下，我们的 CV-RNN 在挑战中的表现与人类相似，为相位同步作为跟踪移动时外观变化的物体的神经基础的作用提供了计算概念验证。]]></description>
      <guid>https://arxiv.org/abs/2410.02094</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能否可靠地模拟人类学习者的行为？开放式学习环境的模拟创作框架</title>
      <link>https://arxiv.org/abs/2410.02110</link>
      <description><![CDATA[arXiv:2410.02110v1 公告类型：新
摘要：模拟学习者的行为有助于在部署之前对开放式交互式学习环境进行压力测试和原型设计。虽然最近的研究表明使用大型语言模型 (LLM) 模拟人类行为很有前景，但由于关键限制，这种方法尚未超越基本的概念验证阶段。首先，LLM 对微小的提示变化高度敏感，这让人怀疑它们在没有大量提示工程的情况下能否推广到新的场景。此外，看似成功的结果往往是不可靠的，要么是因为领域专家无意中引导 LLM 产生预期结果，导致自我实现的预言；要么是因为 LLM 在其训练数据中遇到了高度相似的场景，这意味着模型可能不是在模拟行为，而是在复述记忆的内容。为了应对这些挑战，我们提出了 Hyp-Mix，这是一个模拟创作框架，允许专家通过结合关于学习者行为的可测试假设来开发和评估模拟。在物理学习环境中测试该框架后，我们发现即使底层学习者模型发生变化，GPT-4 Turbo 也能保持校准的行为，这首次证明 LLM 可用于在开放式交互式学习环境中模拟现实行为，这是实现有用的 LLM 行为模拟的必要先决条件。]]></description>
      <guid>https://arxiv.org/abs/2410.02110</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从像素到标记：量化视觉模态的字节对编码</title>
      <link>https://arxiv.org/abs/2410.02155</link>
      <description><![CDATA[arXiv:2410.02155v1 公告类型：新
摘要：多模态大型语言模型在整合视觉和文本信息方面取得了重大进展，但它们往往难以有效地协调这些模态。我们引入了一种新颖的图像标记器，通过将字节对编码 (BPE) 的原理应用于视觉数据来弥补这一差距。与依赖单独视觉编码器的传统方法不同，我们的方法直接将结构先验信息合并到图像标记中，反映了纯文本大型语言模型中使用的成功标记策略。这种创新方法使 Transformer 模型能够更有效地跨模态学习和推理。通过理论分析和大量实验，我们证明我们的 BPE 图像标记器显着增强了 MLLM 的多模态理解能力，即使在训练数据有限的情况下也是如此。我们的方法不仅提高了各种基准的性能，而且还显示出良好的可扩展性，有可能为更高效、更强大的多模态基础模型铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2410.02155</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>草莓园规划：评估和改进 LRM o1 的规划和调度能力</title>
      <link>https://arxiv.org/abs/2410.02162</link>
      <description><![CDATA[arXiv:2410.02162v1 公告类型：新 
摘要：规划实现期望状态的行动方案的能力长期以来一直被认为是智能代理的核心能力，并且自诞生以来一直是人工智能研究不可或缺的一部分。随着大型语言模型 (LLM) 的出现，人们对它们是否具有这种规划能力产生了浓厚的兴趣，但是——尽管自 GPT3 以来出现了大量新的私有和开源 LLM——但进展仍然缓慢。OpenAI 声称他们最近的 o1（Strawberry）模型是专门构建和训练的，以摆脱自回归 LLM 的正常限制——使其成为一种新型模型：大型推理模型 (LRM)。在本文中，我们在规划和调度基准上评估了两个 LRM（o1-preview 和 o1-mini）的规划能力。我们发现，虽然 o1 似乎确实比自回归 LLM 有显著的改进，但这是以高昂的推理成本为代价的，而且仍然无法对其生成的内容提供任何保证。我们还表明，将 o1 模型与外部验证器相结合（在所谓的 LRM-Modulo 系统中）可以保证组合系统输出的正确性，同时进一步提高性能。]]></description>
      <guid>https://arxiv.org/abs/2410.02162</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有人类水平指南优化的 LLM 驱动自动评分框架</title>
      <link>https://arxiv.org/abs/2410.02165</link>
      <description><![CDATA[arXiv:2410.02165v1 公告类型：新
摘要：开放式简答题 (SAG) 已被广泛认为是在学习分析 (LA) 背景下深入了解学习者反应的有力工具。然而，由于评分工作量大以及对评估不一致的担忧，SAG 在实践中经常带来挑战。随着自然语言处理 (NLP) 的最新进展，自动简答评分 (ASAG) 为这些挑战提供了一个有希望的解决方案。尽管如此，当前的 ASAG 算法通常在通用性方面受到限制，并且倾向于针对特定问题进行量身定制。在本文中，我们提出了一个统一的多智能体 ASAG 框架 GradeOpt，它利用大型语言模型 (LLM) 作为 SAG 的评分器。更重要的是，GradeOpt 将两个额外的基于 LLM 的代理 - 反射器和精炼器 - 合并到多智能体系统中。这使 GradeOpt 能够通过对其错误进行自我反思来自动优化原始评分指南。通过对一项具有挑战性的 ASAG 任务（即对教学内容知识 (PCK) 和内容知识 (CK) 问题进行评分）进行实验，GradeOpt 在评分准确性和与人类评分员的行为一致性方面表现出优于代表性基线的性能。最后，全面的消融研究证实了 GradeOpt 中设计的各个组件的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.02165</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体系统中面向智能体的规划</title>
      <link>https://arxiv.org/abs/2410.02189</link>
      <description><![CDATA[arXiv:2410.02189v1 公告类型：新
摘要：通过拥有不同专业知识和工具的多个代理的协作，多代理系统在解决实际问题方面取得了令人瞩目的进展。给定用户查询，作为这些系统中的大脑的元代理需要将查询分解为多个子任务，这些子任务可以分配给能够解决它们的合适代理，即所谓的面向代理的规划。在本研究中，我们确定了面向代理的规划的三个关键设计原则，包括可解性、完整性和非冗余性，以确保每个子任务都得到有效解决，从而对原始查询做出令人满意的响应。这些原则进一步启发我们提出一种用于多代理系统中面向代理的规划的新框架，利用快速的任务分解和分配过程，然后通过奖励模型进行有效和高效的评估。在规划过程中，元代理还负责评估专家代理的表现，及时调整子任务并根据需要进行安排。此外，我们将反馈回路集成到所提出的框架中，以进一步增强此类问题解决过程的有效性和稳健性。大量实验表明，与单智能体系统和现有的多智能体系统规划策略相比，所提出的框架在解决实际问题方面具有进步性。]]></description>
      <guid>https://arxiv.org/abs/2410.02189</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于对齐语言模型的具有偏好表示的一般偏好建模</title>
      <link>https://arxiv.org/abs/2410.02197</link>
      <description><![CDATA[arXiv:2410.02197v1 公告类型：新
摘要：对人类偏好进行建模对于将基础模型与人类价值观相结合至关重要。传统的奖励建模方法，例如 Bradley-Terry (BT) 奖励模型，在表达能力方面存在不足，特别是在解决不及物偏好方面。虽然监督配对偏好模型 (PairPM) 可以表达一般偏好，但它们的实现是高度临时的，不能保证比较配对的偏好概率一致。此外，由于它们在比较多个响应时具有二次查询复杂度，因此计算成本很高。在本文中，我们引入了偏好表示学习，这是一种将响应嵌入潜在空间以有效捕获复杂偏好结构的方法，可实现线性查询复杂度。此外，我们提出了基于偏好分数的一般偏好优化 (GPO)，它从人类反馈中推广了基于奖励的强化学习。实验结果表明，我们的一般偏好表示模型 (GPM) 在 RewardBench 基准上的表现优于 BT 奖励模型，幅度高达 5.6%，并且有效地模拟了周期性偏好，而任何 BT 奖励模型的行为都像随机猜测一样。此外，在使用 GPO 和我们的一般偏好模型对语言模型进行后期训练后，对 AlpacaEval2.0 和 MT-Bench 等下游任务进行评估，结果显示性能显著提升，幅度高达 9.3%。这些发现表明，我们的方法可以增强基础模型与细微的人类价值观的一致性。代码可在 https://github.com/general-preference/general-preference-model 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.02197</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphIC：基于图的多步推理上下文示例检索模型</title>
      <link>https://arxiv.org/abs/2410.02203</link>
      <description><![CDATA[arXiv:2410.02203v1 公告类型：新
摘要：上下文学习 (ICL) 使大型语言模型 (LLM) 能够通过在输入中直接合并一些上下文示例 (ICE) 来推广到新任务，而无需更新参数。然而，ICL 的有效性在很大程度上依赖于 ICE 的选择，而传统的基于文本的嵌入方法通常不足以完成需要多步推理的任务，例如数学和逻辑问题解决。这是由于浅层语义相似性引入的偏差无法捕捉这些任务所需的更深层的推理结构。我们提出了 GraphIC，这是一种利用基于图的推理过程表示的新方法，结合贝叶斯网络 (BN) 来选择 ICE。图结构本质上会过滤掉浅层语义，同时保留核心推理结构。重要的是，BN 可以捕获节点属性对其父节点的依赖性，这与人类认知的层次性非常相似，即每个想法都由前面的想法塑造而成。这使得 BN 特别适合多步骤推理任务，使该过程更接近人类推理。对三种推理任务（数学推理、代码生成和逻辑推理）进行的大量实验表明，GraphIC 在选择 ICE 方面优于无训练和基于训练的模型，在有效性和效率方面均表现出色。我们表明，GraphIC 增强了 ICL 的性能和互操作性，显著提高了多步骤推理任务的 ICE 选择。]]></description>
      <guid>https://arxiv.org/abs/2410.02203</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CodePMP：用于大型语言模型推理的可扩展偏好模型预训练</title>
      <link>https://arxiv.org/abs/2410.02229</link>
      <description><![CDATA[arXiv:2410.02229v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言理解和生成方面取得了重大进展，这得益于可扩展的预训练和高级微调。然而，由于高质量偏好数据的稀缺，增强 LLM 的推理能力，特别是通过从人类反馈中强化学习 (RLHF)，仍然具有挑战性，而这些数据的注释需要大量劳动力，对奖励模型 (RM) 微调至关重要。为了缓解这个问题，我们引入了 CodePMP，这是一种可扩展的偏好模型预训练 (PMP) 管道，它利用来自公开可用的高质量源代码的大量合成代码偏好对语料库。CodePMP 通过在大规模合成代码偏好对上预训练偏好模型来提高 RM 微调效率。我们在数学推理任务（GSM8K、MATH）和逻辑推理任务（ReClor、LogiQA2.0）上对 CodePMP 进行了评估，结果一致显示 LLM 的推理性能有显著提升，并强调了可扩展偏好模型预训练对于有效奖励建模的重要性。]]></description>
      <guid>https://arxiv.org/abs/2410.02229</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEAL：通过语言模型进行语义增强模仿学习</title>
      <link>https://arxiv.org/abs/2410.02231</link>
      <description><![CDATA[arXiv:2410.02231v1 公告类型：新
摘要：分层模仿学习 (HIL) 是一种有前途的方法，可用于解决长期决策任务。然而，由于缺乏详细的子目标学习监督标签，并且依赖数百到数千个专家演示，因此这是一项具有挑战性的任务。在这项工作中，我们引入了 SEAL，这是一个新颖的框架，它利用大型语言模型 (LLM) 强大的语义和世界知识来指定子目标空间和预标记状态，以表示语义上有意义的子目标，而无需事先了解任务层次结构。SEAL 采用双编码器结构，将监督的 LLM 引导子目标学习与无监督的矢量量化 (VQ) 相结合，以获得更稳健的子目标表示。此外，SEAL 还结合了转换增强的低级规划器，以提高对子目标转换的适应性。我们的实验表明，SEAL 的表现优于最先进的 HIL 方法和基于 LLM 的规划方法，特别是在专家数据集较小和复杂的长期任务环境中。]]></description>
      <guid>https://arxiv.org/abs/2410.02231</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用强化学习实现高交互交通场景中的端到端驾驶</title>
      <link>https://arxiv.org/abs/2410.02253</link>
      <description><![CDATA[arXiv:2410.02253v1 公告类型：新
摘要：动态和交互式交通场景对自动驾驶系统提出了重大挑战。强化学习 (RL) 提供了一种有前途的方法，它能够探索超出预先收集的数据集和预定义条件限制的驾驶策略，尤其是在复杂环境中。然而，一个关键的挑战在于有效地从高维、多模态观测序列中提取空间和时间特征，同时最大限度地减少误差随时间的积累。此外，有效地引导大规模 RL 模型在训练过程中收敛到最佳驾驶策略而不频繁失败仍然很棘手。
我们提出了一种基于端到端模型的 RL 算法 Ramble 来解决这些问题。Ramble 将多视图 RGB 图像和 LiDAR 点云处理成低维潜在特征，以捕捉每个时间步骤的交通场景背景。然后采用基于 Transformer 的架构来建模时间依赖性并预测未来状态。通过学习环境的动态模型，Ramble 可以预测即将发生的交通事件并做出更明智的战略决策。我们的实施表明，特征提取和决策方面的先前经验在加速 RL 模型向最佳驾驶策略的收敛方面起着关键作用。Ramble 在 CARLA Leaderboard 2.0 上的路线完成率和驾驶得分方面取得了最先进的表现，展示了其在管理复杂和动态交通状况方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.02253</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IoT-LLM：利用大型语言模型增强现实世界的物联网任务推理</title>
      <link>https://arxiv.org/abs/2410.02429</link>
      <description><![CDATA[arXiv:2410.02429v1 公告类型：新
摘要：大型语言模型 (LLM) 在文本和视觉领域表现出卓越的能力，但经常产生违反物理定律的输出，揭示了它们对物理世界的理解存在差距。受人类认知的启发，感知是推理的基础，我们探索使用物联网 (IoT) 传感器数据和相关知识增强 LLM 的感知能力，以便在物理世界中进行物联网任务推理。在这项工作中，我们系统地研究了 LLM 通过增强其感知和知识库来处理现实世界物联网任务的能力，然后提出了一个统一的框架 IoT-LLM 来增强这种能力。在 IoT-LLM 中，我们为 LLM 定制了三个步骤：将物联网数据预处理为适合 LLM 的格式，通过思路提示和专门的角色定义激活他们的常识性知识，并通过基于上下文学习的面向物联网的检索增强生成来扩展他们的理解。为了评估性能，我们设计了一个新的基准，其中包含五个具有不同数据类型和推理难度的真实物联网任务，并提供了六个开源和闭源 LLM 的基准测试结果。实验结果表明，现有 LLM 的局限性在于，它们使用简单的文本输入，无法有效地执行这些任务。我们表明，IoT-LLM 显著提高了 LLM（如 GPT-4）的物联网任务推理性能，与以前的方法相比，在各种任务中平均提高了 65%。结果还展示了 LLM 通过提供推理过程来理解物联网数据和数据背后的物理定律的能力。我们工作的局限性旨在激发这个新时代的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2410.02429</guid>
      <pubDate>Fri, 04 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>