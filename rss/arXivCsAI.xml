<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 26 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>人机协作中没有免费午餐定理</title>
      <link>https://arxiv.org/abs/2411.15230</link>
      <description><![CDATA[arXiv:2411.15230v1 公告类型：新
摘要：人机协作的黄金标准是互补性——当综合表现超过人类和算法本身时。我们在二元分类设置中研究这一挑战，目标是最大化 0-1 准确度。给定两个或多个可以做出校准概率预测的代理，我们展示了一个“没有免费午餐”式的结果。任何确定性协作策略（将校准概率映射到二元分类的函数）本质上并不总是服从同一个代理，有时会比最不准确的代理表现更差。换句话说，互补性不能“免费”实现。结果确实提出了一种有保证的协作模型，其中一个代理识别另一个代理的“明显”错误。我们还利用结果来了解使其他协作技术成功的必要条件，为人机协作提供指导。]]></description>
      <guid>https://arxiv.org/abs/2411.15230</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>监管机构-制造商 AI 代理建模：数学反馈驱动的多代理 LLM 框架</title>
      <link>https://arxiv.org/abs/2411.15356</link>
      <description><![CDATA[arXiv:2411.15356v1 公告类型：新
摘要：全球监管机构监管更新的复杂性日益增加，这对医疗器械制造商提出了重大挑战，需要制定敏捷战略来维持合规性和保持市场准入。同时，监管机构必须有效监控制造商的反应并制定战略监控计划。本研究采用多智能体建模方法，并辅以大型语言模型 (LLM)，以模拟监管动态并检查主要参与者（包括监管机构、制造商和竞争对手）的适应性行为。这些智能体在受监管流理论支配的模拟环境中运行，捕捉监管变化对合规决策、市场适应和创新战略的影响。我们的研究结果阐明了监管变化对行业行为的影响，并确定了改善监管实践、优化合规性和促进创新的战略机会。通过利用多智能体系统和 LLM 的集成，本研究提供了一个新颖的视角，并为驾驭医疗器械行业不断变化的监管格局的利益相关者提供了可行的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.15356</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在有备选工艺方案的情况下设计单元制造系统</title>
      <link>https://arxiv.org/abs/2411.15361</link>
      <description><![CDATA[arXiv:2411.15361v1 公告类型：新
摘要：在单元制造系统 (CMS) 的设计中，必须在设计和操作阶段做出许多技术和管理决策。设计 CMS 的第一步是分组零件和机器。本文提出了四个整数规划公式，用于在设计和操作层面对 CMS 中的零件和机器进行分组，以解决广义分组问题，其中每个零件都有多个工艺计划，并且工艺计划的每个操作都可以在多台机器上执行。通过将零件类型的最大可能连续操作数分别分配给同一单元和同一台机器，可以实现单元间和单元内移动的最小化。讨论了将最小化单元间和单元内移动作为目标的适用性，与其他目标（例如最小化机器投资成本、运营成本等）相比。包括数值示例以说明公式的工作原理。]]></description>
      <guid>https://arxiv.org/abs/2411.15361</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在道德推理语言模型中引入类似人类的偏见</title>
      <link>https://arxiv.org/abs/2411.15386</link>
      <description><![CDATA[arXiv:2411.15386v1 公告类型：新 
摘要：在这项工作中，我们研究了针对道德推理进行微调的大型语言模型 (LLM) 在执行相同任务的人类的行为数据和/或大脑数据上的对齐 (BrainScore)。我们还探索了在执行道德推理的人类的 fMRI 数据上微调几个 LLM 是否可以提高 BrainScore。我们根据来自 ETHICS 基准 [Hendrycks et al., 2020] 的道德推理行为数据、来自 Koster-Hale et al. [2013] 的道德推理 fMRI 数据或两者对几个 LLM (BERT、RoBERTa、DeBERTa) 进行了微调。我们研究了 ETHICS 基准的准确性以及模型激活和 fMRI 数据之间的 BrainScores。虽然较大的模型通常在两个指标上都表现更好，但 BrainScores 经过微调后并没有显着改善。]]></description>
      <guid>https://arxiv.org/abs/2411.15386</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 是否同意对替代用途的创造力评估？</title>
      <link>https://arxiv.org/abs/2411.15560</link>
      <description><![CDATA[arXiv:2411.15560v2 公告类型：新
摘要：本文研究大型语言模型 (LLM) 在评估替代用途测试 (AUT) 的创造力方面是否表现出一致性。虽然 LLM 越来越多地用于评估创造性内容，但以前的研究主要集中在评估由同一模型或人类生成的响应的单一模型上。本文探讨 LLM 是否能够公正准确地评估由自身和其他模型生成的输出中的创造力。使用一组按创造力水平（普通、创造性和高度创造性）分类的 AUT 响应的 oracle 基准集，我们尝试使用四个最先进的 LLM 来评估这些输出。我们测试了评分和排名方法，并采用两种评估设置（综合和分段）来检查 LLM 是否同意替代用途的创造力评估。结果显示模型间一致性很高，Spearman 相关性在各个模型间平均高于 0.7，与 oracle 相比达到 0.77 以上，表明一致性很高，并验证了 LLM 在替代用途创造力评估中的可靠性。值得注意的是，模型并不偏向自己的反应，而是为其他模型生成的替代用途提供类似的创造力评估分数或排名。这些发现表明 LLM 在创造力评估中表现出公正性和高度一致性，为其在自动化创造力评估中的应用提供了有希望的意义。]]></description>
      <guid>https://arxiv.org/abs/2411.15560</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协调人类与机器之间的泛化</title>
      <link>https://arxiv.org/abs/2411.15626</link>
      <description><![CDATA[arXiv:2411.15626v1 公告类型：新
摘要：人工智能的最新进展（包括生成方法）已经产生了可以支持人类进行科学发现和决策支持的技术，但也可能破坏民主制度并针对个人。负责任地使用人工智能越来越表明需要人机合作，需要人机之间进行有效的交互。这些交互中一个至关重要但经常被忽视的方面是人机泛化的不同方式。在认知科学中，人类泛化通常涉及抽象和概念学习。相比之下，人工智能泛化包括机器学习中的域外泛化、符号人工智能中的基于规则的推理和神经符号人工智能中的抽象。在这篇观点论文中，我们结合人工智能和认知科学的见解，从三个维度确定关键的共性和差异：泛化概念、泛化方法和泛化评估。我们沿着这三个维度映射人工智能和认知科学中泛化的不同概念，并考虑它们在人机合作中的作用。这导致了人工智能和认知科学之间的跨学科挑战，必须解决这些挑战才能为人机合作场景中有效且认知支持的协调奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2411.15626</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TableTime：通过大型语言模型将时间序列分类重新表述为零样本表理解</title>
      <link>https://arxiv.org/abs/2411.15737</link>
      <description><![CDATA[arXiv:2411.15737v1 公告类型：新
摘要：大型语言模型 (LLM) 已证明其在多变量时间序列分类 (MTSC) 中的有效性。有效适应 MTSC 的 LLM 需要信息丰富的数据表示。现有的基于 LLM 的方法直接从头开始对 LLM 潜在空间中的时间序列嵌入进行编码，以与 LLM 的语义空间对齐。尽管这些方法很有效，但我们发现它们隐藏了三个固有的瓶颈：(1) 它们难以以无损方式编码时间和通道特定信息，这两者都是多变量时间序列的关键组成部分；(2) 很难将学习到的表示空间与 LLM 的语义空间对齐；(3) 它们需要针对特定​​任务的再训练，这既耗费计算资源又耗费人力。为了弥补这些差距，我们提出了 TableTime，它将 MTSC 重新表述为表格理解任务。具体来说，TableTime 引入了以下策略：（1）将多变量时间序列转换为表格形式，从而最大程度地减少信息损失；（2）以文本格式表示表格时间序列，以实现与 LLM 语义空间的自然对齐；（3）设计一个集成上下文文本信息、邻域辅助、多路径推理和问题分解的推理框架，以增强 LLM 的推理能力并实现零样本分类。在 UEA 档案中的 10 个公开代表性数据集上进行的大量实验验证了 TableTime 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2411.15737</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解读城市工业复杂性：通过 IndustryScopeGPT 增强知识驱动的洞察力</title>
      <link>https://arxiv.org/abs/2411.15758</link>
      <description><![CDATA[arXiv:2411.15758v1 公告类型：新
摘要：工业园区对城市经济增长至关重要。然而，它们的发展经常遇到源于工业需求和城市服务之间不平衡的挑战，这凸显了战略规划和运营的必要性。本文介绍了 IndustryScopeKG，这是一种开创性的大规模多模式、多层次工业园区知识图谱，它整合了包括街景、企业、社会经济和地理空间信息在内的各种城市数据，捕捉了工业园区内复杂的关系和语义。除此之外，我们还提出了 IndustryScopeGPT 框架，该框架利用大型语言模型 (LLM) 和蒙特卡洛树搜索来增强工业园区规划和运营 (IPPO) 中的工具增强推理和决策。我们的工作显着改善了站点推荐和功能规划，展示了将 LLM 与结构化数据集相结合以推进工业园区管理的潜力。这种方法为智能 IPPO 研究树立了新的标杆，并为推进城市工业发展奠定了坚实的基础。数据集和相关代码可在https://github.com/Tongji-KGLLM/IndustryScope获取。]]></description>
      <guid>https://arxiv.org/abs/2411.15758</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>创建可扩展的AGI：开放式通用智能框架</title>
      <link>https://arxiv.org/abs/2411.15832</link>
      <description><![CDATA[arXiv:2411.15832v1 公告类型：新
摘要：本文介绍了一种新型通用人工智能系统架构，该架构提供了通用灵活性并解决了当前困扰该领域的可扩展性问题。该架构 OGI（开放式通用智能）利用动态处理系统来控制和委托专门的人工智能模块。它旨在用作智能系统的参考设计，为各种实际应用中的通用人工智能提供类似人类的认知灵活性。]]></description>
      <guid>https://arxiv.org/abs/2411.15832</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PIANIST：利用法学硕士 (LLM) 学习部分可观察的世界模型，实现多智能体决策</title>
      <link>https://arxiv.org/abs/2411.15998</link>
      <description><![CDATA[arXiv:2411.15998v1 公告类型：新
摘要：有效提取 LLM 中的世界知识以用于复杂的决策任务仍然是一个挑战。我们提出了一个框架 PIANIST，用于将世界模型分解为七个直观的组件，有利于零样本 LLM 生成。仅给定游戏的自然语言描述以及输入观察的格式，我们的方法就可以生成一个有效的世界模型，以进行快速高效的 MCTS 模拟。我们表明，我们的方法在两种不同的游戏中效果很好，这些游戏挑战了代理在基于语言和非语言的行动方面的规划和决策技能，而无需对特定领域的训练数据或明确定义的世界模型进行任何训练。]]></description>
      <guid>https://arxiv.org/abs/2411.15998</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>智能体为何做出该决定：使用视觉蒙版解释深度强化学习</title>
      <link>https://arxiv.org/abs/2411.16120</link>
      <description><![CDATA[arXiv:2411.16120v1 公告类型：新
摘要：由于深度神经网络本身缺乏透明度，深度强化学习 (DRL) 代理很难获得用户的信任和接受，尤其是在医疗诊断和军事行动等安全关键应用中。现有的解释代理决策的方法要么需要使用支持解释生成的模型重新训练代理，要么依靠基于扰动的技术来揭示不同输入特征在决策过程中的重要性。然而，重新训练代理可能会损害其完整性和性能，而基于扰动的方法性能有限，缺乏知识积累或学习能力。此外，由于每个扰动都是独立执行的，因此扰动输入的联合状态可能没有物理意义。为了应对这些挑战，我们引入了 $\textbf{VisionMask}$，这是一个独立的解释模型，经过端到端训练，可以识别代理视觉输入中可以解释其行为的最关键区域。 VisionMask 以自监督的方式进行训练，不依赖于人工生成的标签。重要的是，它的训练不会改变代理模型，因此可以保留代理的性能和完整性。我们在超级马里奥兄弟 (SMB) 和三款 Atari 游戏上评估了 VisionMask。与现有方法相比，VisionMask 在根据所选视觉解释重现原始动作时实现了 14.9% 更高的插入准确率和 30.08% 更高的 F1 分数。我们还提供了示例来说明如何使用 VisionMask 进行反事实分析。]]></description>
      <guid>https://arxiv.org/abs/2411.16120</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过条件模仿共同学习实现自动驾驶汽车的端到端转向</title>
      <link>https://arxiv.org/abs/2411.16131</link>
      <description><![CDATA[arXiv:2411.16131v1 公告类型：新
摘要：自动驾驶涉及复杂的任务，例如数据融合、物体和车道检测、行为预测和路径规划。与将各个子系统专用于处理每个任务的模块化方法相反，端到端方法使用深度神经网络将问题视为单个可学习的任务，从而降低系统复杂性并最大限度地减少对启发式方法的依赖。条件模仿学习 (CIL) 训练端到端模型以模仿人类专家考虑引导车辆到达目的地的导航命令，CIL 采用专门用于学习每个导航命令的驾驶任务的专家网络分支。然而，当部署到看不见的环境时，CIL 模型缺乏泛化。这项工作引入了条件模仿共同学习 (CIC) 方法来解决这个问题，通过使模型能够通过由门控双曲正切单元 (GTU) 生成的共同学习矩阵来学习 CIL 专家分支之间的关系。此外，我们建议将转向回归问题作为分类问题，使用分类-回归混合损失来弥合回归和分类之间的差距，我们还建议使用共存概率来考虑转向类别之间的空间趋势。与 CIL 方法相比，我们的模型在看不见的环境中平均将自动驾驶成功率提高了 62%。]]></description>
      <guid>https://arxiv.org/abs/2411.16131</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过第三方 LLM 集成增强多智能体共识：分析大型语言模型中的不确定性并减轻幻觉</title>
      <link>https://arxiv.org/abs/2411.16189</link>
      <description><![CDATA[arXiv:2411.16189v1 Announce Type: new 
摘要：大型语言模型（LLM）在处理复杂推理任务时仍面临挑战，经常导致幻觉现象，限制了LLM的实际应用。为了缓解这一问题，本文提出了一种新方法，通过整合不同的LLM来扩展知识边界，减少对单一模型的依赖，并促进代理之间的深入讨论。主要贡献包括：1）引入第三方LLM通过不确定性估计和置信度分析来调整代理的注意力权重，优化多代理系统中的共识形成；2）在算术数据集上的实验验证了该方法的有效性，超越了传统的多代理基线。这项研究为大型模型在处理复杂任务时缓解幻觉现象提供了一个新的视角。]]></description>
      <guid>https://arxiv.org/abs/2411.16189</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索机器意识</title>
      <link>https://arxiv.org/abs/2411.16262</link>
      <description><![CDATA[arXiv:2411.16262v1 公告类型：新
摘要：本研究探索了人工智能体发展核心意识的潜力，正如安东尼奥·达马西奥的意识理论所提出的。根据达马西奥的说法，核心意识的出现依赖于由情绪和感觉的表征形成的自我模型和世界模型的整合。我们假设，通过虚拟环境中的强化学习 (RL) 训练的人工智能体可以在其主要任务的副产品中开发出这些模型的初步形式。代理的主要目标是学习玩电子游戏和探索环境。为了评估世界和自我模型的出现，我们使用了探测前馈分类器，它使用训练有素的代理神经网络的激活来预测代理本身的空间位置。我们的结果表明，代理可以形成基本的世界和自我模型，这为发展机器意识提供了一条途径。这项研究为人工智能体在反映人类意识方面的能力提供了基础见解，对未来人工智能的发展具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2411.16262</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CATP-LLM：为成本感知工具规划提供大型语言模型支持</title>
      <link>https://arxiv.org/abs/2411.16313</link>
      <description><![CDATA[arXiv:2411.16313v1 公告类型：新 
摘要：利用大型语言模型 (LLM) 进行工具规划已成为开发通用 AI 系统的一种有前途的途径，其中 LLM 会自动安排外部工具（例如视觉模型）根据任务描述处理复杂任务。为了将这种范式推向实际应用，LLM 必须考虑工具执行成本（例如执行时间）以进行工具规划。不幸的是，先前的研究忽视了工具执行成本，导致生成昂贵的计划，其成本超过了任务性能。为了填补这一空白，我们提出了使用 LLM 的成本感知工具规划 (CATP-LLM) 框架，该框架首次提供了一个连贯的设计，使 LLM 能够进行成本感知的工具规划。具体而言，CATP-LLM 结合了一种工具规划语言来增强 LLM 生成多个分支的非连续计划的能力，从而实现高效的并发工具执行并降低成本。此外，它还设计了一种成本感知的离线强化学习算法来微调 LLM，以优化工具规划中的性能成本权衡。在缺乏公共成本相关数据集的情况下，我们进一步提出了第一个成本感知规划评估平台 OpenCATP。在 OpenCATP 上的实验表明，即使在使用 Llama2-7B 作为骨干时，CATP-LLM 的表现也优于 GPT-4，即使在具有挑战性的规划任务上，规划性能平均提高了 28.2%-30.2%，成本降低了 24.7%-45.8%。CATP-LLM 和 OpenCATP 的代码将公开提供。]]></description>
      <guid>https://arxiv.org/abs/2411.16313</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>