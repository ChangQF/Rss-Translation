<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 08 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>保护社交空间：利用深度学习消除网络欺凌</title>
      <link>https://arxiv.org/abs/2404.03686</link>
      <description><![CDATA[arXiv:2404.03686v1 公告类型：交叉
摘要：在当今的数字世界中，网络欺凌是一个严重的问题，可能会损害社交媒体用户的身心健康。本文解释了网络欺凌的严重程度以及它如何真正影响遭受网络欺凌的个人。它还强调了找到更好的方法来检测网络欺凌以使在线空间更加安全的重要性。另外，它还讨论了如何制作更准确的工具来发现网络欺凌在未来会真正有帮助。我们的论文介绍了一种基于深度学习的方法，主要采用 BERT 和 BiLSTM 架构来有效解决网络欺凌问题。这种方法旨在分析大量帖子并预测在线空间中潜在的网络欺凌事件。我们的结果证明了 hatBERT 模型（专注于仇恨语音检测的 BERT 扩展）在五个模型中的优越性，准确率达到 89.16%。这项研究对“社会转型的计算智能”做出了重大贡献，有望打造一个更安全、更具包容性的数字环境。]]></description>
      <guid>https://arxiv.org/abs/2404.03686</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:19 GMT</pubDate>
    </item>
    <item>
      <title>通过标签修订和数据选择改进知识提炼</title>
      <link>https://arxiv.org/abs/2404.03693</link>
      <description><![CDATA[arXiv:2404.03693v1 公告类型：交叉
摘要：知识蒸馏（KD）已成为模型压缩领域广泛使用的技术，其目的是将知识从大型教师模型转移到轻量级学生模型以实现高效的网络开发。除了对groundtruth的监督之外，vanilla KD方法还将教师的预测视为软标签来监督学生模型的训练。基于普通 KD，人们开发了各种方法来进一步提高学生模型的性能。然而，以前的方法很少考虑教师模型监督的可靠性。错误预测的监督可能会误导学生模型的训练。因此，本文建议从两个方面来解决这个问题：标签修订以纠正错误的监督和数据选择以选择合适的样本进行蒸馏以减少错误监督的影响。在前者中，我们建议使用事实来纠正老师不准确的预测。在后者中，我们引入了数据选择技术来选择合适的训练样本来接受教师的监督，从而在一定程度上减少了错误预测的影响。实验结果证明了我们提出的方法的有效性，并表明我们的方法可以与其他蒸馏方法相结合，提高其性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03693</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:19 GMT</pubDate>
    </item>
    <item>
      <title>用于时空预测的个性化联合学习：基于双重语义对齐的对比方法</title>
      <link>https://arxiv.org/abs/2404.03702</link>
      <description><![CDATA[arXiv:2404.03702v1 公告类型：交叉
摘要：现有的时空预测联邦学习（FL）方法无法捕捉固有的时空异质性，这就需要个性化 FL（PFL）方法来建模时空变异模式。虽然对比学习方法在解决时空异质性方面很有前景，但现有方法在确定负对方面无效，并且很难应用于 PFL 范式。为了解决这个限制，我们提出了一种新的 PFL 方法，称为基于联合双重语义对齐的对比学习（FUELS），它可以根据语义相似性自适应地对齐正负对，从而将精确的时空异质性注入到潜在表示空间中通过辅助对比任务。从时间角度来看，引入硬负过滤模块来动态对齐异构时间表示，以补充客户端内对比任务。从空间角度来看，我们设计了轻量级但高效的原型作为客户端级语义表示，基于该原型，服务器评估空间相似性并为补充的客户端间对比任务生成客户端定制的全局原型。大量实验表明，FUELS 的性能优于最先进的方法，通信成本降低了约 94%。]]></description>
      <guid>https://arxiv.org/abs/2404.03702</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:19 GMT</pubDate>
    </item>
    <item>
      <title>通过风格转移减轻 fMRI 结果的分析变异性</title>
      <link>https://arxiv.org/abs/2404.03703</link>
      <description><![CDATA[arXiv:2404.03703v1 公告类型：交叉
摘要：我们提出了一种新方法，通过转换不同功能 MRI 管道的统计图来提高神经影像结果的可重复性。我们假设管道可以被视为数据的一种样式组件，并建议使用不同的生成模型，其中扩散模型（DM）在管道之间转换数据。我们设计了一种新的基于 DM 的无监督多域图像到图像转换框架，并使用辅助分类器的潜在空间来约束 3D fMRI 统计图的生成，该辅助分类器区分来自不同管道的统计图。我们扩展了 DM 中使用的传统采样技术来提高转换性能。我们的实验证明我们提出的方法是成功的：管道确实可以转移，为未来的医学研究提供了数据增强的重要来源。]]></description>
      <guid>https://arxiv.org/abs/2404.03703</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:19 GMT</pubDate>
    </item>
    <item>
      <title>节能和容错云计算的串行并行可靠性冗余分配优化</title>
      <link>https://arxiv.org/abs/2404.03665</link>
      <description><![CDATA[arXiv:2404.03665v1 公告类型：交叉
摘要：串并行冗余是确保云计算中服务和系统可用的可靠方法。该方法涉及复制同一系统或程序，并且只有一个保持活动状态。当发生错误时，非活动副本可以立即作为备份介入，这提供了连续的性能和不间断的操作。这种方法称为并行冗余，也称为主动-主动冗余，在策略方面具有特殊性。它创建同时运行的系统或服务的副本。通过这样做，容错能力会提高，因为如果一个副本发生故障，工作负载可以分布在任何正常运行的副本上。可靠性分配取决于系统的功能以及您希望从中获得的可用性和容错能力。可以应用串行冗余或并行冗余来提高系统和服务的可靠性。为了证明这个概念的效果如何，我们研究了固定的串行并行可靠性冗余分配问题，然后使用创新的混合优化技术来找到峰值可靠性的最佳可能分配。然后我们将我们的发现与其他研究进行比较。]]></description>
      <guid>https://arxiv.org/abs/2404.03665</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>一致性模型的强化学习：更快的奖励引导文本到图像生成</title>
      <link>https://arxiv.org/abs/2404.03673</link>
      <description><![CDATA[arXiv:2404.03673v1 公告类型：交叉
摘要：强化学习（RL）通过直接优化捕捉图像质量、美观和指令遵循能力的奖励，改进了扩散模型的引导图像生成。然而，由此产生的生成策略继承了导致生成缓慢的扩散模型的相同迭代采样过程。为了克服这一限制，一致性模型提出学习一类新的生成模型，将噪声直接映射到数据，从而产生一个可以在短短一次采样迭代中生成图像的模型。在这项工作中，为了优化特定任务奖励的文本到图像生成模型并实现快速训练和推理，我们提出了一个通过 RL 微调一致性模型的框架。我们的框架称为一致性模型强化学习 (RLCM)，将一致性模型的迭代推理过程构建为 RL 过程。 RLCM 在文本到图像生成功能上改进了 RL 微调扩散模型，并在推理时间内以计算量换取样本质量。通过实验，我们表明 RLCM 可以使文本到图像的一致性模型适应难以通过提示表达的目标，例如图像可压缩性，以及源自人类反馈的目标，例如美学质量。与 RL 微调扩散模型相比，RLCM 训练速度明显更快，提高了奖励目标下测量的生成质量，并通过仅需两个推理步骤生成高质量图像来加快推理过程。我们的代码可在 https://rlcm.owenoertell.com 获取]]></description>
      <guid>https://arxiv.org/abs/2404.03673</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>搜索流（SoS）：学习用语言搜索</title>
      <link>https://arxiv.org/abs/2404.03683</link>
      <description><![CDATA[arXiv:2404.03683v1 公告类型：交叉
摘要：语言模型在训练时很少出现富有成果的错误。然后，他们努力去超越下一个标记，遭受滚雪球般的错误的困扰，并努力预测他们的行为的后果。在本文中，我们展示了如何通过将语言中的搜索过程表示为扁平化字符串——搜索流（SoS）来训练语言模型进行搜索。我们提出了一种统一的搜索语言，它捕获了一系列不同的符号搜索策略。我们使用简单但困难的倒计时游戏演示了我们的方法，其目标是将输入数字与算术运算相结合以达到目标数字。我们在启发式求解器生成的搜索流数据集上从头开始预训练基于变压器的语言模型。我们发现，与仅预测最佳搜索轨迹的模型相比，SoS 预训练的搜索精度提高了 25%。我们通过两种策略改进方法进一步微调该模型：优势诱导策略调整（APA）和自学推理器（STaR）。经过微调的 SoS 模型解决了 36% 以前未解决的问题，包括任何启发式求解器都无法解决的问题。我们的结果表明，语言模型可以学习通过搜索解决问题，自我改进以灵活使用不同的搜索策略，并有可能发现新的策略。]]></description>
      <guid>https://arxiv.org/abs/2404.03683</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>合作进化压力和收益递减可能解释费米悖论：关于超级人工智能是什么样子</title>
      <link>https://arxiv.org/abs/2404.03685</link>
      <description><![CDATA[arXiv:2404.03685v1 公告类型：交叉
摘要：通过进化的方法，道德的基础可以解释为对合作问题的适应。从广义上理解“进化”，满足进化适用条件的进化人工智能将受到与生物实体相同的合作进化压力。这里讨论了随着物质安全和财富增加而加强合作的适应性——对于人类、其他社会和人工智能来说。增加物质资源获取带来的有益回报减少也表明，总体而言，没有动力去殖民整个星系，从而为费米悖论提供了一种可能的解释，即想知道每个人都在哪里。有人进一步认为，旧社会可能会产生超级人工智能，并让位于超级人工智能，因为超级人工智能很可能是可行的，而且更适合。结束语是对道德和目标影响生活和社会的有效方式的旁白，强调环境、文化和法律，并以如何饮食为例。
  附加的是快速殖民（例如星系）的算法​​、收益递减下合作和公平的演化模型以及用于模拟信号发展的软件。还值得注意的是，由于数学原因，不可能存在指数殖民或繁殖，因为每个实体都占用一定的空间。]]></description>
      <guid>https://arxiv.org/abs/2404.03685</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为预言机，用于使用特定领域的知识实例化本体</title>
      <link>https://arxiv.org/abs/2404.04108</link>
      <description><![CDATA[arXiv:2404.04108v1 公告类型：新
摘要：背景。为智能系统赋予语义数据通常需要使用特定领域的知识来设计和实例化本体。特别是在早期阶段，这些活动通常由人类专家手动执行，可能会利用他们自己的经验。因此，最终的过程非常耗时、容易出错，并且常常受到本体设计者个人背景的影响。客观的。为了缓解这个问题，我们提出了一种新颖的独立于领域的方法，通过利用大型语言模型（LLM）作为预言机，自动实例化具有特定领域知识的本体。方法。从（i）由相互关联的类和属性组成的初始模式和（ii）一组查询模板开始，我们的方法多次查询LLM，并从其回复中生成类和属性的实例。因此，本体会自动填充特定领域的知识，符合初始模式。结果，本体快速、自动地丰富了多种实例，专家可以根据自己的需要和专业知识考虑保留、调整、丢弃或补充这些实例。贡献。我们以一般方式形式化我们的方法，并在各种法学硕士以及具体案例研究中实例化它。我们报告植根于营养领域的实验，其中食品膳食及其成分的本体论是从膳食及其关系的分类开始从头开始半自动实例化的。在那里，我们分析生成的本体的质量，并比较通过利用不同的法学硕士获得的本体。最后，我们对所提出的方法进行了 SWOT 分析。]]></description>
      <guid>https://arxiv.org/abs/2404.04108</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:17 GMT</pubDate>
    </item>
    <item>
      <title>TableLlama：迈向开放大型通用表模型</title>
      <link>https://arxiv.org/abs/2311.09206</link>
      <description><![CDATA[arXiv:2311.09206v3 公告类型：交叉
摘要：半结构化表无处不在。有多种旨在自动解释、扩充和查询表的任务。当前的方法通常需要对表进行预训练或特殊的模型架构设计，仅限于特定的表类型，或者对表和任务有简化的假设。本文朝着开发开源大型语言模型（LLM）作为各种基于表格的任务的通才迈出了第一步。为此，我们构建了 TableInstruct，这是一个包含各种实际表格和任务的新数据集，用于指令调整和评估 LLM。我们通过使用 LongLoRA 微调 Llama 2 (7B) 来进一步开发第一个开源通用表模型 TableLlama，以解决长上下文挑战。我们在域内设置和域外设置下进行实验。在 8 个域内任务中的 7 个中，TableLlama 的每个任务都实现了与 SOTA 相当或更好的性能，尽管后者通常具有特定于任务的设计。在 6 个域外数据集上，与基础模型相比，它实现了 5-44 的绝对点增益，表明 TableInstruct 上的训练增强了模型的泛化性。我们开源我们的数据集和训练模型，以促进未来开发开放通用表模型的工作。]]></description>
      <guid>https://arxiv.org/abs/2311.09206</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:17 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士进行云事件管理的 X-lifecycle 学习</title>
      <link>https://arxiv.org/abs/2404.03662</link>
      <description><![CDATA[arXiv:2404.03662v1 公告类型：交叉
摘要：大型云服务的事件管理是一个复杂而乏味的过程，需要值班工程师 (OCE) 进行大量的手动工作。 OCE 通常利用来自软件开发生命周期 [SDLC] 不同阶段的数据（例如代码、配置、监控数据、服务属性、服务依赖性、故障排除文档等）来生成用于检测、根本原因和缓解的见解。事件。大型语言模型 [LLM]（例如 ChatGPT、GPT-4、Gemini）的最新进展为自动向 OCE 生成上下文建议创造了机会，帮助他们快速识别和缓解关键问题。然而，现有的研究通常采用孤立的观点，通过利用 SDLC 单个阶段的数据来解决事件管理中的特定任务。在本文中，我们证明了增加来自 SDLC 不同阶段的额外上下文数据可以提高两项极其重要且具有实际挑战性的任务的性能：(1) 自动生成依赖失败相关事件的根本原因建议，以及 (2) 识别服务本体用于自动检测事件的监视器。通过利用 Microsoft 的 353 个事件和 260 个监控数据集，我们证明了增强 SDLC 不同阶段的上下文信息可以提高最先进方法的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03662</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:17 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士是差异化测试的核心：医疗规则引擎的案例研究</title>
      <link>https://arxiv.org/abs/2404.03664</link>
      <description><![CDATA[arXiv:2404.03664v1 公告类型：交叉
摘要：挪威癌症登记处（CRN）使用自动化癌症登记支持系统（CaReSS）来支持核心癌症登记活动，即数据采集、数据管理以及为各个利益相关者生成数据产品和统计数据。 GURI 是 CaReSS 的核心组件，负责根据医疗规则验证传入数据。这些医疗规则是由医疗专家根据医疗标准、法规和研究手动实施的。由于大型语言模型 (LLM) 已经接受了大量公共信息（包括这些文档）的训练，因此可以使用它们来生成 GURI 的测试。因此，我们提出了一种基于 LLM 的测试生成和差异测试方法 (LLMeDiff) 来测试 GURI。我们尝试了四种不同的 LLM、两种医疗规则引擎实现和 58 条真实的医疗规则，以调查 LLM 生成测试的幻觉、成功、时间效率和鲁棒性，以及这些测试发现 GURI 中潜在问题的能力。我们的结果表明，GPT-3.5 产生的幻觉最少，是最成功的，并且通常是最稳健的；然而，它的时间效率最差。我们的差异测试揭示了 22 条医疗规则，其中发现了实施不一致的情况（例如，关于处理规则版本）。最后，我们根据结果为从业者和研究人员提供见解。]]></description>
      <guid>https://arxiv.org/abs/2404.03664</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:17 GMT</pubDate>
    </item>
    <item>
      <title>KGExplainer：探索知识图补全的连通子图解释</title>
      <link>https://arxiv.org/abs/2404.03893</link>
      <description><![CDATA[arXiv:2404.03893v1 公告类型：新
摘要：知识图补全（KGC）旨在减轻知识图（KG）固有的不完整性，这对于各种应用程序（例如网络推荐）来说是一项关键任务。尽管知识图嵌入（KGE）模型在 KGC 任务上表现出了卓越的预测性能，但这些模型以黑盒方式推断缺失的链接，缺乏透明度和问责制，阻碍了研究人员开发负责任的模型。现有的基于 KGE 的解释方法侧重于探索关键路径或孤立边缘作为解释，这对于推理目标预测来说信息较少。此外，缺失的基本事实导致这些解释方法在定量评估探索的解释方面无效。为了克服这些限制，我们提出了 KGExplainer，这是一种与模型无关的方法，可以识别连接的子图解释并提取评估器来定量评估它们。 KGExplainer 采用基于扰动的贪婪搜索算法来查找关键连接子图作为目标预测局部结构内的解释。为了评估所探索的解释的质量，KGExplainer 从目标 KGE 模型中提取了一个评估器。通过将解释转发给评估者，我们的方法可以检查它们的保真度。对基准数据集的大量实验表明，KGExplainer 取得了可喜的改进，并在人类评估中实现了 83.3% 的最佳比率。]]></description>
      <guid>https://arxiv.org/abs/2404.03893</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:16 GMT</pubDate>
    </item>
    <item>
      <title>随机排列集合论中的随机游走</title>
      <link>https://arxiv.org/abs/2404.03978</link>
      <description><![CDATA[arXiv:2404.03978v1 公告类型：新
摘要：随机游走是一种在分子水平上模拟自然过程的可解释方法。随机排列集理论 (RPST) 作为不确定性推理的框架，扩展了 Dempster-Shafer 理论的适用性。最近的探索表明 RPST 和随机游走之间存在着良好的联系。在本研究中，我们根据 RPST 的特性进行分析并构建随机游走模型，并对这种随机游走进行蒙特卡罗模拟。我们的研究结果表明，通过 RPST 生成的随机游走表现出与高斯随机游走类似的特征，并且可以通过特定的限制缩放程序转换为维纳过程。这项研究在 RPST 和随机游走理论之间建立了一种新颖的联系，从而不仅扩展了 RPST 的适用性，而且展示了结合两种方法的优势来提高解决问题能力的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.03978</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:16 GMT</pubDate>
    </item>
    <item>
      <title>用于在线随机排队网络优化的干预辅助策略梯度方法：技术报告</title>
      <link>https://arxiv.org/abs/2404.04106</link>
      <description><![CDATA[arXiv:2404.04106v1 公告类型：新
摘要：深度强化学习（DRL）提供了一种强大的方法来训练随机排队网络（SQN）的神经网络控制策略。然而，传统的 DRL 方法依赖于离线模拟或静态数据集，限制了它们在 SQN 控制中的实际应用。这项工作提出了基于在线深度强化学习的控制（ODRLC）作为替代方案，其中智能代理直接与真实环境交互，并从这些在线交互中学习最优控制策略。由于网络中队列的无界性质导致无界状态空间，SQN 给 ODRLC 带来了挑战。无界状态空间对于神经网络策略来说尤其具有挑战性，因为神经网络在推断未知状态方面非常糟糕。为了应对这一挑战，我们提出了一个干预辅助框架，该框架利用已知稳定政策的战略干预来确保队列大小保持有限。该框架将神经网络的学习能力与 SQN 经典控制策略的稳定性保证相结合。我们引入了一种设计这些干预辅助策略的方法，以确保网络的强大稳定性。此外，我们扩展了干预辅助政策的基本 DRL 定理，并专门针对 SQN 的 ODRLC 开发了两种实用算法。最后，我们通过实验证明我们提出的算法优于经典控制方法和先前的 ODRLC 算法。]]></description>
      <guid>https://arxiv.org/abs/2404.04106</guid>
      <pubDate>Mon, 08 Apr 2024 15:12:16 GMT</pubDate>
    </item>
    </channel>
</rss>