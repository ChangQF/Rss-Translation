<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 29 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>神经网络中维度抽象的关系归纳偏差</title>
      <link>https://arxiv.org/abs/2402.18426</link>
      <description><![CDATA[arXiv:2402.18426v1 公告类型：新
摘要：人类认知系统表现出显着的灵活性和泛化能力，部分原因在于它能够形成环境的低维组合表征。相比之下，标准神经网络架构通常难以处理抽象推理任务、过度拟合以及需要大量数据进行训练。本文研究了关系瓶颈（一种将处理重点放在输入之间的关系上的机制）对有利于组合编码的分解表示学习以及随之而来的处理灵活性的影响。我们证明，这样的瓶颈不仅提高了泛化和学习效率，而且使网络性能与类人行为偏差保持一致。经过关系瓶颈训练的网络开发了数据集中潜在特征维度的正交表示，反映了人类认知灵活性背后的因式分解结构。此外，关系网络模仿了人类对规律性的偏见，而没有预先指定的符号原语，这表明瓶颈促进了抽象表示的出现，赋予了类似于符号的灵活性。]]></description>
      <guid>https://arxiv.org/abs/2402.18426</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>语言模型代表自我和他人的信念</title>
      <link>https://arxiv.org/abs/2402.18496</link>
      <description><![CDATA[arXiv:2402.18496v1 公告类型：新
摘要：理解和归因心理状态，称为心理理论（ToM），是人类社会推理的基本能力。虽然大型语言模型 (LLM) 似乎拥有某些 ToM 功能，但这些功能背后的机制仍然难以捉摸。在这项研究中，我们发现可以通过语言模型的神经激活从不同主体的角度线性解码信念状态，表明自我和他人信念的内部表征的存在。通过操纵这些表示，我们观察到模型 ToM 性能的巨大变化，强调了它们在社会推理过程中的关键作用。此外，我们的研究结果扩展到涉及不同因果推理模式的各种社会推理任务，表明这些表示的潜在普遍性。]]></description>
      <guid>https://arxiv.org/abs/2402.18496</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>如果在众包数据注释管道中，GPT-4</title>
      <link>https://arxiv.org/abs/2402.16795</link>
      <description><![CDATA[arXiv:2402.16795v1 公告类型：交叉
摘要：最近的研究表明，GPT-4 在数据标记准确性方面优于在线众包工作人员，尤其是来自 Amazon Mechanical Turk (MTurk) 的工作人员。然而，这些研究因偏离标准众包实践并强调个体工作者在整个数据注释过程中的表现而受到批评。本文比较了 GPT-4 和道德且执行良好的 MTurk 管道，其中 415 名工作人员使用 CODA-19 方案标记了 200 篇学术文章中的 3,177 个句子片段。两个工作接口产生了 127,080 个标签，然后通过八个标签聚合算法推断最终标签。我们的评估表明，尽管有最佳实践，MTurk 管道的最高准确度为 81.5%，而 GPT-4 达到了 83.6%。有趣的是，当将 GPT-4 的标签与通过高级工作人员界面收集的人群标签相结合进行聚合时，8 种算法中的 2 种实现了更高的准确度（87.5%、87.0%）。进一步的分析表明，当人群和 GPT-4 的标记优势互补时，将它们聚合可以提高标记准确性。]]></description>
      <guid>https://arxiv.org/abs/2402.16795</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>作为进化策略的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.18381</link>
      <description><![CDATA[arXiv:2402.18381v1 公告类型：新
摘要：大型 Transformer 模型能够实现大量所谓的上下文学习算法。这些包括梯度下降、分类、序列完成、转换和改进。在这项工作中，我们研究了从未明确遇到黑盒优化任务的大型语言模型（LLM）原则上是否能够实现进化优化算法。虽然之前的工作只关注基于语言的任务规范，但我们继续前进并专注于法学硕士在黑盒优化中的零样本应用。我们引入了一种新颖的提示策略，包括对离散总体成员进行从最小到最大的排序，并查询 LLM 以提出对均值统计的改进，即执行一种黑盒重组操作。根据经验，我们发现我们的设置允许用户获得基于 LLM 的进化策略，我们称之为“EvoLLM”，该策略在合成 BBOB 函数以及小型神经进化任务上远远优于随机搜索和高斯爬山等基线算法。因此，LLM 可以充当上下文重组运算符的“插件”。我们提供了一些关于法学硕士模型规模、提示策略和背景构建的比较研究。最后，我们表明，通过对先前收集的教师优化轨迹进行指令微调来提供教师算法信息，可以灵活地提高 EvoLLM 的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.18381</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>通过变形测试评估自动驾驶的决策最优性</title>
      <link>https://arxiv.org/abs/2402.18393</link>
      <description><![CDATA[arXiv:2402.18393v1 公告类型：新
摘要：自动驾驶系统（ADS）测试在 ADS 开发中至关重要，目前的主要关注点是安全性。然而，非安全关键性能的评估，特别是ADS为自动驾驶汽车（AV）做出最佳决策和生成最佳路径的能力，对于确保自动驾驶汽车的智能性和降低风险同样重要。目前，由于缺乏相应的预言机以及难以生成非最优决策的场景，专门评估 ADS 最优决策性能的工作很少。在本文中，我们重点评估 ADS 的决策质量，并提出第一种检测非最优决策场景（NoDS）的方法，其中 ADS 不计算 AV 的最佳路径。首先，为了解决预言机问题，我们提出了一种新颖的变质关系（MR），旨在揭露对最优决策的违反。 MR 确定了当最佳路径不受非侵入性变化影响时 ADS 应保留最佳决策的属性。随后，我们开发了一个新框架 Decictor，旨在高效生成 NoDS。 Decictor 包含三个主要组件：非侵入性突变、MR 检查和反馈。非侵入性变异保证变异场景下原有的最优路径不受影响，而MR Check则负责判断是否做出非最优决策。为了提高识别 NoDS 的有效性，我们设计了一种反馈指标，结合了 AV 运动的空间和时间方面。我们在百度 Apollo（一种开源生产级 ADS）上评估 Decictor。实验结果验证了Decictor在检测ADS非最优决策方面的有效性。我们的工作为评估 ADS 的非安全关键性能提供了宝贵且独到的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.18393</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>大视觉语言模型图像推理与描述的认知评估基准</title>
      <link>https://arxiv.org/abs/2402.18409</link>
      <description><![CDATA[arXiv:2402.18409v1 公告类型：新
摘要：大视觉语言模型（LVLM）尽管最近取得了成功，但其认知能力却很难得到全面测试。受人类认知测试中普遍使用的“Cookie Theft”任务的启发，我们提出了一种新颖的评估基准，使用具有丰富语义的图像来评估 LVLM 的高级认知能力。它定义了八种推理能力，由图像描述任务和视觉问答任务组成。我们对著名的 LVLM 的评估表明，LVLM 与人类的认知能力仍然存在很大差距。]]></description>
      <guid>https://arxiv.org/abs/2402.18409</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>随机硅采样：使用基于群体级人口统计信息的大型语言模型模拟人类子群体的意见</title>
      <link>https://arxiv.org/abs/2402.18144</link>
      <description><![CDATA[arXiv:2402.18144v1 公告类型：新
摘要：大型语言模型表现出与人口统计信息相关的社会偏见，包括种族、性别等。赋予此类语言模型基于人口统计数据的个性，可以生成与人类一致的观点。基于这个想法，我们提出了“随机硅采样”，这是一种模仿人群子群体意见的方法。我们的研究分析了 1) 一种语言模型，该模型仅根据人口统计分布生成与人类群体相对应的调查答复；2) 我们的方法在各种人口统计亚组和主题问题中的适用性。通过随机硅抽样并仅使用群体级别的人口统计信息，我们发现语言模型可以生成与实际的美国民意调查非常相似的响应分布。此外，我们发现语言模型的可复制性根据人口群体和问题主题的不同而变化，这可以归因于模型中固有的社会偏见。我们的研究结果证明了仅使用人口统计分布来反映群体意见的可行性，并阐明了语言模型中的社会偏见对此类模拟的影响。]]></description>
      <guid>https://arxiv.org/abs/2402.18144</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>从总结到行动：使用开放世界 API 增强复杂任务的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.18157</link>
      <description><![CDATA[arXiv:2402.18157v1 公告类型：新
摘要：人类与动物的区别在于人类使用和创造工具的独特能力。工具使人类能够克服生理限制，促进伟大文明的创造。同样，启用具有学习外部工具使用能力的大型语言模型（LLM）等基础模型可能是实现通用人工智能的关键一步。该领域之前的研究主要采用两种不同的方法来增强法学硕士的工具调用能力。第一种方法强调构建用于模型微调的相关数据集。相比之下，第二种方法旨在通过情境学习策略充分利用法学硕士固有的推理能力。在这项工作中，我们引入了一种新颖的工具调用管道，旨在控制大量现实世界的 API。该管道反映了人工任务解决过程，解决了现实生活中复杂的用户查询。在每一步中，我们都会指导法学硕士总结所取得的成果并确定下一步的行动方针。我们将这个管道称为“从摘要到行动”，简称 Sum2Act。我们在 ToolBench 基准上对 Sum2Act 管道进行的实证评估显示出显着的性能改进，优于 ReAct 和 DFSDT 等既定方法。这凸显了 Sum2Act 在增强法学硕士应对复杂现实任务方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.18157</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是否反映认知语言处理？</title>
      <link>https://arxiv.org/abs/2402.18023</link>
      <description><![CDATA[arXiv:2402.18023v1 公告类型：新
摘要：大语言模型（LLM）在文本理解和逻辑推理方面表现出了卓越的能力，在许多认知任务中达到甚至超越了人类水平。由于法学硕士是根据人类语言认知的大量文本输出进行训练的，因此很自然地会问法学硕士是否反映了认知语言处理。或者法学硕士在何种程度上类似于认知语言处理？在本文中，我们提出了一种连接 LLM 表示和人类认知信号的新方法，以评估 LLM 模拟认知语言处理的有效性。我们采用表征相似性分析 (RSA) 来测量 16 个主流 LLM 与大脑 fMRI 信号之间的一致性。我们凭经验研究了各种因素（例如模型缩放、对齐训练、指令附加）对这种 LLM-大脑对齐的影响。实验结果表明，模型缩放与LLM-大脑相似度呈正相关，对齐训练可以显着提高LLM-大脑相似度。此外，各种 LLM 评估（例如 MMLU、Chatbot Arena）的表现与 LLM 大脑相似性高度相关。]]></description>
      <guid>https://arxiv.org/abs/2402.18023</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>通过深度学习自动发现积分</title>
      <link>https://arxiv.org/abs/2402.18040</link>
      <description><![CDATA[arXiv:2402.18040v1 公告类型：新
摘要：深度学习领域的最新进展，特别是大型语言模型（LLM）的开发，已经证明了人工智能处理复杂数学问题或解决编程挑战的能力。然而，基于大量训练数据解决明确问题的能力与做出科学发现的微妙过程有很大不同。当今复杂的法学硕士接受了几乎所有人类可用知识的培训，基本上学会了预测标记序列。他们以类似于写论文的方式生成数学推导和编写代码，并且不具备以人类科学家的方式开拓科学发现的能力。
  在这项研究中，我们深入研究了使用深度学习重新发现基本数学概念：积分的潜力。通过将积分定义为曲线下的面积，我们说明了 AI 如何推导给定函数的积分，例如推断 $\int_{0}^{x} t^2 dt = \frac{x^3}{3} $ 和 $\int_{0}^{x} ae^{bt} dt = \frac{a}{b} e^{bx} - \frac{a}{b}$。我们的实验表明，深度学习模型可以通过序列到序列模型（类似于语言翻译）或通过揭示积分的基本原理来完成推断积分的任务，例如 $\int_{0}^{x} t^n dt = \frac{x^{n+1}}{n+1}$。]]></description>
      <guid>https://arxiv.org/abs/2402.18040</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>令人惊讶的失败？多模式法学硕士和 NLVR 挑战</title>
      <link>https://arxiv.org/abs/2402.17793</link>
      <description><![CDATA[arXiv:2402.17793v1 公告类型：新
摘要：本研究在组合自然语言视觉推理任务 NLVR 上评估了三种最先进的 MLLM（GPT-4V、Gemini Pro 和开源模型 IDEFICS）。给定一个与合成图像配对的人类书写的句子，该任务要求模型确定该句子相对于图像的真值。尽管这些模型表现出了强大的性能，但我们观察到它们在 NLVR 上表现不佳，NLVR 的构建需要组合和空间推理，并且对语义和系统偏差具有鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2402.17793</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>通过合作语言引导逆向规划实现实用指令跟踪和目标协助</title>
      <link>https://arxiv.org/abs/2402.17930</link>
      <description><![CDATA[arXiv:2402.17930v1 公告类型：新
摘要：人们经常在没有进一步上下文的情况下发出含义不明确的指令，期望他们的行为或目标能够消除他们的意图的歧义。我们如何构建以灵活、上下文敏感的方式遵循此类指令的辅助代理？本文介绍了协作语言引导逆向计划搜索（CLIPS），这是一种用于语用指令跟踪和目标辅助的贝叶斯代理架构。我们的智能体通过将人类建模为合作规划者来协助人类，该规划者将联合计划传达给助手，然后根据行为和语言对人类的目标进行多模态贝叶斯推理，使用大型语言模型 (LLM) 来评估给定指令的可能性。假设的计划。考虑到这个后验，我们的助手会采取行动，尽量减少预期目标实现成本，使其能够务实地遵循模糊的指令，即使在目标不确定的情况下也能提供有效的帮助。我们在两个合作规划领域（Doors、Keys &amp; Gems 和 VirtualHome）中评估了这些功能，发现 CLIPS 在准确性和有用性方面显着优于 GPT-4V、基于 LLM 的文字指令跟踪和单峰逆向规划，同时与推论和帮助紧密匹配。由人类评估者提供的辅助判断。]]></description>
      <guid>https://arxiv.org/abs/2402.17930</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>具有动态感知奖励的样本高效、基于偏好的强化学习</title>
      <link>https://arxiv.org/abs/2402.17975</link>
      <description><![CDATA[arXiv:2402.17975v1 公告类型：新
摘要：基于偏好的强化学习（PbRL）通过从代理行为的二元反馈中学习到的奖励函数，使机器人行为与人类偏好保持一致。我们表明，动态感知奖励函数将 PbRL 的样本效率提高了一个数量级。在我们的实验中，我们迭代：（1）通过自我监督的时间一致性任务学习动态感知的状态动作表示（z^{sa}），以及（2）从（z^）引导基于偏好的奖励函数{sa}），这会导致更快的策略学习和更好的最终策略性能。例如，在四足行走、步行者行走和猎豹奔跑上，使用 50 个偏好标签，我们实现了与使用 500 个偏好标签的现有方法相同的性能，并且我们恢复了 83% 和 66% 的地面真实奖励策略性能而只有 38% 和 21%。性能提升证明了显式学习动态感知奖励模型的好处。仓库：\texttt{https://github.com/apple/ml-reed}。]]></description>
      <guid>https://arxiv.org/abs/2402.17975</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的逐步自洽数学推理</title>
      <link>https://arxiv.org/abs/2402.17786</link>
      <description><![CDATA[arXiv:2402.17786v1 公告类型：新
摘要：使用大型语言模型进行复杂的数学推理很困难，这主要是由于多步骤推理的复杂性。该过程的主要挑战包括（1）选择关键的中间结果来推进该过程，以及（2）对潜在解决方案的探索有限。为了解决这些问题，我们引入了一种新颖的算法，即逐步自洽思想链（SSC-CoT）。 SSC-CoT 采用基于各种推理链的交集选择中间步骤的策略。此外，SSC-CoT 使模型能够通过查询包含相关领域知识的知识图来发现关键的中间步骤。为了验证 SSC-CoT，我们提出了一个新的数据集 TriMaster100，专为复杂的三角学问题而定制。该数据集包含 100 个问题，每个解决方案都分为评分的中间步骤，有助于对数学推理过程进行全面评估。在 TriMaster100 上，SSC-CoT 使最先进方法的有效性提高了三倍。此外，我们在广泛认可的复杂数学问题数据集 MATH level 5 上对 SSC-CoT 进行了基准测试，它的准确率超过了第二好的方法 7.2%。代码和TriMaster100数据集可以在：https://github.com/zhao-zilong/ssc-cot找到。]]></description>
      <guid>https://arxiv.org/abs/2402.17786</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>用于知识图上节点重要性估计的标签知情对比预训练</title>
      <link>https://arxiv.org/abs/2402.17791</link>
      <description><![CDATA[arXiv:2402.17791v1 公告类型：新
摘要：节点重要性估计（NIE）是推断图中节点重要性得分的任务。由于可以获得更丰富的数据和知识，NIE 最近的研究兴趣一直致力于知识图谱来预测未来或缺失的节点重要性分数。现有最先进的 NIE 方法通过可用标签来训练模型，并且在训练之前平等地考虑每个感兴趣的节点。然而，在现实场景中，重要性较高的节点通常需要或受到更多关注，例如，人们可能更关心重要性较高的电影或网页。为此，我们将标签知情对比预训练（LICAP）引入 NIE 问题，以便更好地了解具有高重要性分数的节点。具体来说，LICAP 是一种新型的对比学习框架，旨在充分利用连续标签来生成用于预训练嵌入的对比样本。考虑到NIE问题，LICAP采用了一种新颖的采样策略，称为顶级节点优先分层采样，首先根据节点重要性得分将所有感兴趣的节点分为顶级仓和非顶级仓，然后将顶级仓内的节点划分为更细的节点。垃圾箱也基于分数。从这些箱中生成对比样本，然后通过新提出的谓词感知图注意网络（PreGAT）用于预训练知识图的节点嵌入，以便更好地将顶部节点与非顶部节点分开，并区分通过保持更精细的箱之间的相对顺序来确定顶部箱内的顶部节点。大量实验表明，LICAP 预训练嵌入可以进一步提高现有 NIE 方法的性能，并在回归和排名指标方面实现新的最先进性能。可重复性的源代码位于 https://github.com/zhangtia16/LICAP]]></description>
      <guid>https://arxiv.org/abs/2402.17791</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    </channel>
</rss>