<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Mon, 30 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>检测人工智能生成的自我展示中的国籍、种族和民族偏见及其后果</title>
      <link>https://arxiv.org/abs/2412.18647</link>
      <description><![CDATA[arXiv:2412.18647v1 公告类型：新
摘要：本研究以人感知和人类人工智能交互 (HAII) 理论为基础，研究内容和来源线索（特别是种族、民族和国籍）如何影响对高风险自我展示环境中人工智能生成内容的判断：大学申请。一项具有全国代表性的美国样本（N = 644）的预注册实验的结果表明，内容启发式方法（例如语言风格）在人工智能检测中起主导作用。国籍等源启发式方法也是一个重要因素，国际学生更有可能被视为使用人工智能，尤其是当他们的陈述包含听起来像人工智能的特征时。有趣的是，当被标记为国内学生时，亚裔和西班牙裔申请者更有可能被判定为人工智能用户，这表明种族刻板印象和人工智能检测之间存在相互作用。人工智能归因导致对个人陈述质量和真实性的认知降低，以及对申请人的能力、社交能力、道德和未来成功的负面评价。]]></description>
      <guid>https://arxiv.org/abs/2412.18647</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高神经机器翻译的可解释性：注意力和对齐一致性的分析指标</title>
      <link>https://arxiv.org/abs/2412.18669</link>
      <description><![CDATA[arXiv:2412.18669v1 公告类型：新
摘要：神经机器翻译 (NMT) 模型表现出色，但其决策过程仍然很大程度上不透明。这些模型的可解释性，尤其是它们的内部注意力机制，对于建立信任和验证这些系统是否按预期运行至关重要。在这项工作中，我们引入了一个系统框架，通过将 NMT 模型注意力模式与统计对齐进行比较并将其与标准机器翻译质量指标相关联，定量评估 NMT 模型注意力模式的可解释性。我们提出了一组指标注意力熵和对齐一致性，并使用预先训练的 mT5 模型在 WMT14 的英语-德语测试子集上对其进行验证。我们的结果表明，更清晰的注意力分布与更好的可解释性相关，但并不总能保证更好的翻译质量。这些发现加深了我们对 NMT 可解释性的理解，并指导未来努力构建更透明、更可靠的机器翻译系统。]]></description>
      <guid>https://arxiv.org/abs/2412.18669</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>欧盟人工智能法案背景下 ISMS 与 AIMS 的相互作用</title>
      <link>https://arxiv.org/abs/2412.18670</link>
      <description><![CDATA[arXiv:2412.18670v1 公告类型：新 
摘要：欧盟人工智能法案 (AIA) 要求为高风险人工智能系统实施风险管理系统 (RMS) 和质量管理体系 (QMS)。ISO/IEC 42001 标准为满足这些要求提供了基础，但并未涵盖所有欧盟特定的监管规定。为了加强德国 AIA 的实施，联邦信息安全局 (BSI) 可以引入国家标准 BSI 200-5，该标准规定了 AIA 要求并整合了现有的 ISMS 标准，例如 ISO/IEC 27001。本文研究了信息安全管理系统 (ISMS) 和人工智能管理系统 (AIMS) 之间的接口，表明将现有的 ISMS 控制与特定的 AI 扩展相结合是遵守 AIA 第 15 条的有效策略。引入了四个新的 AI 模块，提议将其纳入 BSI IT Grundschutz 框架，以全面确保人工智能系统的安全。此外，本文还概述了调整 BSI 资格和认证系统的方法，以确保不断发展安全 AI 处理方面的专业知识。最后，本文讨论了 BSI 如何通过 ISO/IEC 42001 的国家化来衔接国际标准和 AIA 的具体要求，从而产生协同效应并增强德国 AI 领域的竞争力。]]></description>
      <guid>https://arxiv.org/abs/2412.18670</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Map2Text：从低维可视化中生成新内容</title>
      <link>https://arxiv.org/abs/2412.18673</link>
      <description><![CDATA[arXiv:2412.18673v1 公告类型：新
摘要：低维可视化或数据集的“投影图”广泛应用于科学研究和创意产业，是解释大规模复杂信息的有效工具。这些可视化不仅支持理解现有的知识空间，而且经常被隐式地用于指导对未知领域的探索。虽然像 TSNE 或 UMAP 这样的强大方法可以创建这样的可视化地图，但目前还没有系统的方法来利用它们来生成新内容。为了弥补这一差距，我们引入了 Map2Text，这是一项新颖的任务，它将低维可视化中的空间坐标转换为新的、连贯的、准确对齐的文本内容。这允许用户以交互和直观的方式探索和导航嵌入在这些空间布局中的未发现的信息。为了评估 Map2Text 方法的性能，我们提出了 Atometric，这是一种评估指标，可以对生成的文本中原子语句的逻辑连贯性和对齐性进行细粒度评估。在各种数据集上进行的实验表明，Map2Text 在生成科学研究假设、制作合成角色和制定测试大型语言模型的策略方面具有多功能性。我们的研究结果强调了 Map2Text 有潜力开辟与大型文本数据集交互和导航的新途径，为空间引导的内容生成和发现提供新颖的框架。]]></description>
      <guid>https://arxiv.org/abs/2412.18673</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法庭上的特工：基于大型语言模型的可信数字司法多代理框架</title>
      <link>https://arxiv.org/abs/2412.18697</link>
      <description><![CDATA[arXiv:2412.18697v1 公告类型：新
摘要：司法系统越来越多地采用人工智能技术来提高效率，但在提高决策质量方面仍然存在局限性，特别是在维护公众对法律人工智能的信任所需的透明度和可解释性方面。为了应对这些挑战，我们提出了一个基于大型语言模型的多智能体框架，名为 AgentsBench，旨在同时提高司法决策的效率和质量。我们的方法利用多个 LLM 驱动的智能体来模拟司法法庭的协作审议和决策过程。我们对法律判决预测任务进行了实验，结果表明，我们的框架在性能和决策质量方面优于现有的基于 LLM 的方法。通过结合这些要素，我们的框架更紧密地反映了现实世界的司法程序，提高了准确性、公平性和社会考虑。AgentsBench 提供了一种更细致入微、更现实的可信人工智能决策方法，在各种案件类型和法律场景中具有强大的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.18697</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CAG：Google Chrome 内置 Gemini Nano 的分块增强生成</title>
      <link>https://arxiv.org/abs/2412.18708</link>
      <description><![CDATA[arXiv:2412.18708v1 公告类型：新
摘要：我们提出了分块增强生成 (CAG)，这是一种专门为克服 Google Chrome 内置 Gemini Nano 模型的上下文窗口限制而设计的架构。虽然 Chrome 对 Gemini Nano 的集成代表了将 AI 功能直接引入浏览器的重大进步，但其受限的上下文窗口对处理大量输入提出了挑战。CAG 通过智能输入分块和处理策略解决了这一限制，能够高效处理大量内容，同时在浏览器限制内保持模型的性能。我们的实现在直接在 Chrome 中处理大型文档和数据集方面表现出特别的功效，使复杂的 AI 功能可以通过浏览器访问，而无需外部 API 依赖。立即开始使用 https://github.com/vivekVells/cag-js。]]></description>
      <guid>https://arxiv.org/abs/2412.18708</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结合协同过滤和大型语言模型的增强推荐</title>
      <link>https://arxiv.org/abs/2412.18713</link>
      <description><![CDATA[arXiv:2412.18713v1 Announce Type: new 
摘要：随着信息爆炸时代的到来，推荐系统在各类应用中的重要性日益凸显。传统的协同过滤算法因其能有效捕捉用户行为模式而被广泛应用，但在处理冷启动问题和数据稀疏性时受到限制。大型语言模型（LLM）以其强大的自然语言理解和生成能力为推荐系统提供了新的突破。本研究提出一种结合协同过滤和LLM的增强推荐方法，旨在发挥协同过滤在建模用户偏好方面的优势，同时通过LLM增强对用户和物品文本信息的理解，提高推荐的准确性和多样性。本文首先介绍了协同过滤和LLM的基本理论，然后设计了一个融合两者的推荐系统架构，并通过实验验证了系统的有效性。结果表明，基于协同过滤和LLM的混合模型显著提高了准确率、召回率和用户满意度，在复杂的推荐场景中展现出潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.18713</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中协同过滤算法的优化和可扩展性</title>
      <link>https://arxiv.org/abs/2412.18715</link>
      <description><![CDATA[arXiv:2412.18715v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的快速发展和对个性化内容的需求不断增长，推荐系统已成为提升用户体验和推动参与的关键。协同过滤算法是许多推荐系统的核心，因其效率和可解释性而备受关注。然而，传统的协同过滤方法在集成到基于 LLM 的大型系统中时面临许多挑战，包括高计算成本、严重的数据稀疏性、冷启动问题和缺乏可扩展性。本文研究了大型语言模型中协同过滤算法的优化和可扩展性，并通过高级优化策略解决了这些限制。首先，我们分析了协同过滤算法的基本原理及其在基于 LLM 的环境中应用的局限性。接下来，提出了几种优化技术，如矩阵分解、近似最近邻搜索和并行计算，以提高计算效率和模型准确性。此外，还探索了分布式架构和模型压缩等策略，以促进数据密集型环境中的动态更新和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2412.18715</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据聚类：数据科学中的一项基本技术</title>
      <link>https://arxiv.org/abs/2412.18760</link>
      <description><![CDATA[arXiv:2412.18760v1 公告类型：新
摘要：本文对数据聚类进行了全面探讨，强调了其在不同领域的方法和应用。本文讨论了传统技术（包括分区和层次聚类）以及数据流、子空间和网络聚类等其他方法，强调了它们在处理复杂、高维数据集中的作用。本文还回顾了聚类的基本原理，介绍了常用工具和方法，并研究了其在数据科学中的各种应用。最后，讨论以对未来方向的见解结束，强调了聚类在推动创新和实现数据驱动决策方面的核心作用。]]></description>
      <guid>https://arxiv.org/abs/2412.18760</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士辅助向量相似性搜索</title>
      <link>https://arxiv.org/abs/2412.18819</link>
      <description><![CDATA[arXiv:2412.18819v2 公告类型：新
摘要：随着数据检索需求变得越来越复杂，传统的搜索方法往往无法解决细微差别和概念性查询。向量相似性搜索已成为一种有效查找语义相似信息的有前途的技术。然而，在处理具有上下文细微差别的复杂查询时，其有效性会降低。本文探讨了一种将向量相似性搜索与大型语言模型 (LLM) 相结合的混合方法，以提高搜索准确性和相关性。提出的两步解决方案首先使用向量相似性搜索来筛选潜在匹配项，然后使用 LLM 对结果进行上下文感知排名。在结构化数据集上的实验表明，虽然单独的向量相似性搜索对于简单查询表现良好，但 LLM 辅助方法在处理涉及约束、否定或概念要求的复杂查询方面表现出色。通过利用 LLM 的自然语言理解能力，该方法可以在不牺牲效率的情况下提高复杂任务的搜索结果的准确性。我们还讨论了现实世界的应用，并提出了未来研究的方向，以改进和扩展该技术以适应不同的数据集和用例。
原文：https://engineering.grab.com/llm-assisted-vector-similarity-search]]></description>
      <guid>https://arxiv.org/abs/2412.18819</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoEvo：利用大型语言模型不断演化符号解决方案</title>
      <link>https://arxiv.org/abs/2412.18890</link>
      <description><![CDATA[arXiv:2412.18890v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为人工智能的变革性工具，能够处理和理解广泛的人类知识，以增强各个领域的问题解决能力。本文探讨了 LLM 在推动科学和工程学科中发现符号解决方案的潜力，这些解决方案对于推进理论和实际应用至关重要。我们提出了一个新颖的框架，该框架在进化搜索方法中利用 LLM，并通过动态知识库进行增强，该动态知识库以 \textit{开放式方式} 集成和细化见解。这种方法旨在应对有效导航复杂符号表示空间和利用现有和新生成的知识促进开放式创新的双重挑战。通过使 LLM 能够与知识库交互并对其进行扩展，我们促进了以语言、代码和数学表达式等多种形式不断生成新颖的解决方案。我们的实验结果表明，该方法不仅提高了寻找符号解决方案的效率，而且还支持持续的发现过程，类似于人类的科学探索。这项研究首次将寻找符号解决方案概念化为一个终身、反复的过程，标志着利用人工智能不断追求科学和工程突破的重要一步。我们已经开源了我们的代码和数据，请访问 \url{https://github.com/pgg3/CoEvo} 了解更多信息。]]></description>
      <guid>https://arxiv.org/abs/2412.18890</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GAI：创新生成代理</title>
      <link>https://arxiv.org/abs/2412.18899</link>
      <description><![CDATA[arXiv:2412.18899v1 公告类型：新
摘要：本研究考察了生成代理之间的集体推理是否能够促进导致创新的新颖和连贯的思维。为了实现这一目标，它提出了 GAI，这是一个新的 LLM 授权框架，旨在让多个生成代理之间的反思和交互复制创新过程。GAI 框架的核心在于动态处理代理内部状态的架构和专门为促进类比驱动的创新而定制的对话方案。使用戴森发明的无叶风扇作为案例研究来评估该框架的功能，评估创新的核心思想可以通过一组虚构的技术文档复制的程度。实验结果表明，具有内部状态的模型明显优于没有内部状态的模型，获得了更高的平均分数和更低的方差。值得注意的是，具有五个配备内部状态的异构代理的模型成功复制了戴森发明背后的关键思想。这表明内部状态使代理能够完善他们的想法，从而构建和共享更加连贯和全面的概念。]]></description>
      <guid>https://arxiv.org/abs/2412.18899</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EC-Diffuser：通过以实体为中心的行为生成实现多对象操作</title>
      <link>https://arxiv.org/abs/2412.18907</link>
      <description><![CDATA[arXiv:2412.18907v1 公告类型：新
摘要：对象操作是日常任务的常见组成部分，但学习从高维观察中操纵对象带来了重大挑战。由于状态空间以及所需行为的组合复杂性，这些挑战在多对象环境中更加突出。虽然最近的方法已经利用大规模离线数据从像素观察中训练模型，通过缩放实现性能提升，但这些方法在网络和数据集大小受限的看不见的对象配置中难以进行组合泛化。为了解决这些问题，我们提出了一种新颖的行为克隆 (BC) 方法，该方法利用以对象为中心的表示和以实体为中心的 Transformer 以及基于扩散的优化，从而能够从离线图像数据中高效学习。我们的方法首先将观察分解为以对象为中心的表示，然后由以实体为中心的 Transformer 处理，以计算对象级别的注意力，同时预测对象动态和代理的动作。结合扩散模型捕捉多模态行为分布的能力，这可显著提高多对象任务的性能，更重要的是，可实现组合泛化。我们提出了能够对具有新颖的对象和目标组合的任务进行零样本泛化的 BC 代理，包括比训练期间看到的更多的对象。我们在网页上提供了视频演示：https://sites.google.com/view/ec-diffuser。]]></description>
      <guid>https://arxiv.org/abs/2412.18907</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AdaEAGLE：通过自适应草案结构的显式建模优化推测解码</title>
      <link>https://arxiv.org/abs/2412.18910</link>
      <description><![CDATA[arXiv:2412.18910v1 公告类型：新
摘要：推测解码 (SD) 是一种流行的无损技术，用于加速大型语言模型 (LLM) 的推理。我们表明，通过结合上下文感知的自适应草稿结构，可以显着提高具有静态草稿结构的 SD 框架的解码速度。然而，目前对自适应草稿结构的研究受到其性能、建模方法和适用性的限制。在本文中，我们介绍了 AdaEAGLE，这是第一个明确建模自适应草稿结构的 SD 框架。AdaEAGLE 利用轻量级草稿长度预测器 (LDLP) 模块在推理过程中明确预测最佳草稿标记数以指导草稿模型。它无需手动阈值即可实现可比的加速结果，并允许进行更深入、更专业的优化。此外，结合基于阈值的策略，AdaEAGLE 比普通 AR 解码实现了 $1.62\times$ 的加速，并且在保持输出质量的同时优于固定长度的 SotA 基线。]]></description>
      <guid>https://arxiv.org/abs/2412.18910</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用短上下文 LLM 的远程任务：使用结构化记忆进行增量推理</title>
      <link>https://arxiv.org/abs/2412.18914</link>
      <description><![CDATA[arXiv:2412.18914v1 公告类型：新
摘要：长距离任务需要对长输入进行推理。现有的解决方案要么需要大量的计算预算、训练数据、访问模型权重，要么使用复杂的、特定于任务的方法。我们提出了 PRISM，它通过将信息处理为块流来缓解这些问题，维护由类型层次结构模式指定的结构化上下文内存。这种方法在不同任务上表现出优于基线的性能，同时使用的上下文至少比长上下文模型小 4 倍。此外，PRISM 具有标记效率。通过生成短输出并有效利用键值 (KV) 缓存，与其他短上下文方法相比，它实现了高达 54% 的成本降低。该方法还可以缩小到微小的信息块（例如 500 个标记），而不会增加编码的标记数量或牺牲质量。此外，我们表明，可以生成模式，以最小的努力将我们的方法推广到新任务。]]></description>
      <guid>https://arxiv.org/abs/2412.18914</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>