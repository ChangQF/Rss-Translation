<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 06 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型对从文本中提取程序性知识图谱进行人工评估</title>
      <link>https://arxiv.org/abs/2412.03589</link>
      <description><![CDATA[arXiv:2412.03589v1 公告类型：新
摘要：程序知识是以执行某些任务所需的步骤序列形式表达的专业知识。程序通常通过自然语言文本描述，例如食谱或维护手册，可能分布在不同的文档和系统中，并且它们的解释和后续执行通常留给读者。在知识图谱 (KG) 中表示此类程序可以作为构建数字工具的基础，以支持那些需要应用或执行它们的用户。在本文中，我们利用大型语言模型 (LLM) 功能并提出一种快速工程方法，从文本程序中提取步骤、操作、对象、设备和时间信息，以便根据预定义的本体填充程序 KG。我们通过用户研究评估 KG 提取结果，以便定性和定量评估 LLM 提取的程序知识的感知质量和有用性。我们表明，LLM 可以产生可接受质量的输出，并且我们评估人类评估者对 AI 的主观感知。]]></description>
      <guid>https://arxiv.org/abs/2412.03589</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在军事情报中的应用：分析过程中附加值的实验调查</title>
      <link>https://arxiv.org/abs/2412.03610</link>
      <description><![CDATA[arXiv:2412.03610v1 公告类型：新
摘要：毫无疑问，人工智能 (AI) 在军事情报方面的潜在好处是巨大的。然而，人工智能究竟如何增强军事数据分析仍不确定。本研究的目的是解决这个问题。为此，与初创公司 Aleph Alpha 合作开发了人工智能演示器 deepCOM。
人工智能功能包括文本搜索、自动文本摘要和命名实体识别 (NER)。这些功能在军事分析中的附加价值得到了评估。结果表明，在时间压力下，使用人工智能功能获得的评估结果明显优于对照组。尽管如此，尽管实验组的分析结果明显优于对照组，但研究人员并没有观察到他们对自身分析准确性的信心增加。最后，本文指出了在军事情报中使用人工智能的局限性，特别是在分析模糊和矛盾信息的背景下。]]></description>
      <guid>https://arxiv.org/abs/2412.03610</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在基于语言的代理系统上正确进行语义反向传播</title>
      <link>https://arxiv.org/abs/2412.03624</link>
      <description><![CDATA[arXiv:2412.03624v1 公告类型：新
摘要：基于语言的代理系统近年来显示出巨大的前景，从解决小规模研究问题过渡到部署到具有挑战性的现实任务中。然而，优化这些系统通常需要大量的人工。最近的研究表明，这些系统可以表示为计算图，从而实现自动优化。尽管取得了这些进展，但目前基于图的代理系统优化 (GASO) 的大多数努力都未能在系统输出反馈的情况下正确地将反馈分配给系统组件。为了应对这一挑战，我们用语义梯度形式化了语义反向传播的概念——这是一种通过利用具有共同后继的节点之间的关系来协调几种关键优化技术的概括，包括反向模式自动微分和最新​​的 TextGrad。这是一种计算方向信息的方法，用于说明代理系统每个组件的更改如何改善系统的输出。为了使用这些梯度，我们提出了一种称为语义梯度下降的方法，它使我们能够有效地解决 GASO。我们在 BIG-Bench Hard 和 GSM8K 上的结果表明，我们的方法优于现有的解决 GASO 问题的最先进的方法。对 LIAR 数据集的详细消融研究表明了我们方法的简约性。我们的实现的完整副本可在 https://github.com/HishamAlyahya/semantic_backprop 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2412.03624</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索人工智能聊天机器人对患有自闭症或社交焦虑症的青少年和年轻人的作用</title>
      <link>https://arxiv.org/abs/2412.03740</link>
      <description><![CDATA[arXiv:2412.03740v1 公告类型：新
摘要：世界可能是一个复杂而难以驾驭的地方。患有高功能自闭症谱系障碍以及一般社交无能的人经常面临其他人群根本不会遇到的导航挑战。当该特定群体的青少年时期和成年早期（这是大学生的通常年龄范围）时，这种情况会变得更加明显。当他们处于如此脆弱的年龄时，他们更容易陷入难以适应和满足于社交互动以及建立牢固关系（直系亲属之外）的困境。关于这一点，人工智能聊天机器人的迅速出现导致其中许多被用于造福不同年龄和人口统计数据的人，并使其易于访问。因此，如果高功能自闭症谱系障碍和社交无能的人在自我提升指导方面有什么想要的，那么易于访问肯定是其中之一。使用 Mindstudio 人工智能聊天机器人为患有上述疾病的青少年和年轻人提供心理健康支持有哪些潜在的好处和局限性？可以使用这样的工具做些什么来帮助这些人在不同的社会环境中应对道德困境，以缓解现有的社会紧张局势？本文解答了这些问题，并提供了见解，为未来关于该主题的讨论提供参考。]]></description>
      <guid>https://arxiv.org/abs/2412.03740</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越局部清晰度：用于联邦学习的通信高效全局清晰度感知最小化</title>
      <link>https://arxiv.org/abs/2412.03752</link>
      <description><![CDATA[arXiv:2412.03752v1 公告类型：新
摘要：联邦学习 (FL) 支持在保护隐私的情况下进行协作模型训练。边缘设备（客户端）之间的数据异质性可能导致模型收敛到尖锐的最小值，从而对泛化和鲁棒性产生负面影响。最近的方法使用客户端锐度感知最小化 (SAM) 来鼓励更平坦的最小值，但局部和全局损失景观之间的差异往往会削弱它们的有效性，因为优化局部锐度并不能确保全局平坦度。这项工作引入了 FedGloSS（联邦全局服务器端锐度），这是一种新颖的 FL 方法，它使用 SAM 优先优化服务器上​​的全局锐度。为了减少通信开销，FedGloSS 巧妙地使用之前的全局梯度来近似锐度，从而无需额外的客户端通信。我们广泛的评估表明，与各种联邦视觉基准中最先进的 FL 方法相比，FedGloSS 始终达到更平坦的最小值和更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.03752</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当代概述：移动设备上大型语言模型的趋势和应用</title>
      <link>https://arxiv.org/abs/2412.03772</link>
      <description><![CDATA[arXiv:2412.03772v1 Announce Type: new 
摘要：随着大型语言模型（LLM）的快速发展，LLM 具备强大的自然语言处理和生成能力，能够提供更加自然和个性化的用户体验，其在移动设备上的部署正逐渐成为智能设备领域的一大趋势，在语音助手、实时翻译、智能推荐等应用中展现出巨大的潜力。硬件技术（如神经网络加速器）和网络基础设施（如 5G）的进步使得移动设备能够实现高效的本地推理和低延迟的智能响应，从而减少对云计算的依赖，同时增强数据隐私和安全性。开发者可以通过开放的 API 和 SDK 轻松集成 LLM 功能，从而创建更多创新的智能应用。LLM 的广泛使用不仅增强了移动设备的智能化，还促进了增强现实（AR）和物联网（IoT）等领域的集成创新，这一趋势有望推动下一代移动智能应用的发展。]]></description>
      <guid>https://arxiv.org/abs/2412.03772</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对精神疾病进行自动多标签注释</title>
      <link>https://arxiv.org/abs/2412.03796</link>
      <description><![CDATA[arXiv:2412.03796v1 公告类型：新
摘要：精神健康障碍的日益流行和复杂性对准确诊断和治疗提出了重大挑战，特别是在了解并发疾病之间的相互作用方面。抑郁症和焦虑症等精神健康障碍经常同时发生，但目前来自社交媒体帖子的数据集通常侧重于单一疾病标签，限制了它们在综合诊断分析中的效用。本文通过提出一种清理、采样、标记和组合数据以创建多功能多标签数据集的新方法来解决这一关键差距。我们的方法引入了一种合成标记技术，将单标签数据集转换为多标签注释，捕捉重叠精神健康状况的复杂性。为此，首先将两个单标签数据集合并为一个基础多标签数据集，从而实现对并发诊断的真实分析。然后，我们设计并评估大型语言模型 (LLM) 的各种提示策略，从单标签预测到能够检测任何现有疾病的不受限制的提示。在严格评估多个 LLM 和提示配置后，确定最佳组合并将其应用于标记来自 RMHD 的另外六个单疾病数据集。结果是 SPAADE-DR，这是一个强大的多标签数据集，涵盖了各种心理健康状况。这项研究展示了 LLM 驱动的合成标记在从社交媒体数据推进心理健康诊断方面的变革潜力，为更细致入微、数据驱动的心理健康护理洞察铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2412.03796</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向前沿人工智能模型的数据治理</title>
      <link>https://arxiv.org/abs/2412.03824</link>
      <description><![CDATA[arXiv:2412.03824v1 公告类型：新
摘要：数据对于训练和微调当今前沿人工智能 (AI) 模型以及开发未来模型至关重要。迄今为止，学术、法律和监管工作主要解决数据如何直接损害消费者和创造者的问题，例如通过侵犯隐私、侵犯版权以及偏见和歧视。相反，我们的工作重点是相对被忽视的问题，即数据如何为前沿 AI 模型提供新的治理能力。这种“前沿数据治理”方法为监控和减轻先进 AI 模型的风险开辟了新途径，特别是当它们扩展并获得特定的危险能力时。尽管如此，前沿数据治理仍面临着源于数据本身基本属性的挑战：数据是非竞争性的、通常不可排除的、易于复制的，并且越来越可合成。尽管存在这些固有的困难，我们还是提出了一套针对数据供应链上关键参与者的政策机制，包括数据生产者、聚合者、模型开发者和数据供应商。我们简要概述了 15 种治理机制，并集中介绍了其中五项尚未得到充分探索的政策建议。这些建议包括为生产者开发金丝雀令牌以检测未经授权的使用；（自动）数据过滤以删除训练前和训练后数据集的恶意内容；对开发人员和供应商强制要求数据集报告；提高数据集和数据生成算法的安全性；以及对供应商的了解客户要求。通过将数据不仅视为潜在危害的来源，而且视为关键的治理杠杆，这项工作旨在为政策制定者提供一种新的工具来管理和监管前沿人工智能模型。]]></description>
      <guid>https://arxiv.org/abs/2412.03824</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Movie Gen：Meta 生成 AI 基础模型的 SWOT 分析，旨在改变媒体生成、广告和娱乐行业</title>
      <link>https://arxiv.org/abs/2412.03837</link>
      <description><![CDATA[arXiv:2412.03837v1 公告类型：新
摘要：生成式人工智能正在重塑媒体格局，在视频创作、个性化和可扩展性方面具有前所未有的能力。本文对 Metas Movie Gen 进行了全面的 SWOT 分析，Metas Movie Gen 是一种尖端的生成式人工智能基础模型，旨在通过简单的文本提示生成带有同步音频的 1080p 高清视频。我们探索了它的优势，包括高分辨率视频生成、精确编辑和无缝音频集成，这使其成为电影制作、广告和教育等行业的变革工具。然而，该分析还解决了局限性，例如视频长度的限制和生成内容中的潜在偏见，这对更广泛地采用构成了挑战。此外，我们还研究了围绕生成式人工智能不断发展的监管和道德考量，重点关注内容真实性、文化代表性和负责任的使用等问题。通过与 DALL-E 和 Google Imagen 等领先模型进行比较，本文重点介绍了 Movie Gens 的独特功能，例如视频个性化和多模态合成，同时确定了创新机会和需要进一步研究的领域。我们的研究结果为利益相关者提供了切实可行的见解，强调了在媒体制作中部署生成式人工智能的机遇和挑战。这项工作旨在指导生成式人工智能的未来发展，确保这一快速发展的领域的可扩展性、质量和道德诚信。]]></description>
      <guid>https://arxiv.org/abs/2412.03837</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedMetaMed：分布式医疗系统中个性化医疗的联合元学习</title>
      <link>https://arxiv.org/abs/2412.03851</link>
      <description><![CDATA[arXiv:2412.03851v1 公告类型：新
摘要：个性化医疗旨在根据患者的个人特征量身定制医疗保健。然而，不同医疗保健系统中患者数据的异质性对实现准确有效的个性化治疗提出了重大挑战。道德问题进一步使来自不同机构的大量数据的聚合变得复杂。联邦学习 (FL) 通过交换客户端模型而不是原始数据来实现协作模型训练，从而保护隐私，提供了一种有前途的分散式解决方案。然而，现有的 FL 方法在服务器聚合过程中经常遭受倒退，导致模型在现实世界的医疗 FL 环境中的性能下降。为了解决分布式医疗保健系统中的数据多变性，我们引入了个性化医疗的联邦元学习 (FedMetaMed)，它结合了联邦学习和元学习，以创建适应医疗保健系统中不同患者数据的模型。FedMetaMed 框架旨在通过解决这些限制为个人客户制作卓越的个性化模型。具体来说，我们在服务器上引入了累积傅里叶聚合 (CFA)，以提高全局知识聚合的稳定性和有效性。CFA 通过从低频到高频逐步集成客户端模型来实现这一点。在客户端级别，我们实施了协作传输优化 (CTO) 策略，该策略包含三个步骤 - 检索、交互和优化 - 通过无缝的全局知识传输来增强个性化的本地模型。在现实世界的医学成像数据集上进行的实验表明，FedMetaMed 的表现优于最先进的 FL 方法，即使在分布外的队列中也表现出卓越的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2412.03851</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在电子学习环境中使用知识图谱提供自适应指导的效果如何？</title>
      <link>https://arxiv.org/abs/2412.03856</link>
      <description><![CDATA[arXiv:2412.03856v1 公告类型：新 
摘要：电子学习环境越来越多地利用 GPT-3.5 和 GPT-4 等大型语言模型 (LLM) 来提供量身定制的教育支持。这项研究介绍了一种将动态知识图与 LLM 相结合的方法，以提供细致入微的学生帮助。通过评估过去和正在进行的学生互动，系统可以识别并将最突出的学习背景附加到针对 LLM 的提示中。这种方法的核心是知识图在评估学生对主题先决条件的理解方面的作用。根据分类的理解（好、一般或差），LLM 会调整其指导，分别提供高级帮助、基础评论或深入的先决条件解释。初步调查结果表明，学生可以从这种分层支持中受益，从而提高理解力并改善任务结果。然而，发现了几个与 LLM 可能产生的错误有关的问题，这可能会误导学生。这凸显了需要人工干预来减轻这些风险。这项研究旨在推进人工智能驱动的个性化学习，同时承认其局限性和潜在缺陷，从而指导未来技术和数据驱动教育的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.03856</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电动汽车用户评论的细粒度情感分析：一种捕捉中文文本情感强度的双向 LSTM 方法</title>
      <link>https://arxiv.org/abs/2412.03873</link>
      <description><![CDATA[arXiv:2412.03873v1 公告类型：新
摘要：电动汽车 (EV) 行业的快速扩张凸显了用户反馈在改进产品设计和充电基础设施方面的重要性。传统的情绪分析方法往往过于简单化用户情绪的复杂性，限制了它们在捕捉细微情绪和情绪强度方面的有效性。本研究提出了一种基于双向长短期记忆 (Bi-LSTM) 网络的情绪评分模型来分析用户对电动汽车充电基础设施的评论。通过分配从 0 到 5 的情绪分数，该模型提供了对情绪表达的细粒度理解。该研究利用来自 PC Auto 的 43,678 条评论数据集，采用严格的数据清理和预处理，包括标记和停用词删除，以优化深度学习的输入。Bi-LSTM 模型在关键评估指标方面比 SnowNLP 等传统方法有显着改进，包括均方误差 (MSE)、平均绝对误差 (MAE) 和解释方差分数 (EVS)。这些结果凸显了该模型捕捉细微情绪动态的卓越能力，为电动汽车生态系统中针对性的产品和服务增强提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.03873</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于评估可解释人工智能方法在实际应用中的有效性和提高透明度的统一框架</title>
      <link>https://arxiv.org/abs/2412.03884</link>
      <description><![CDATA[arXiv:2412.03884v1 公告类型：新
摘要：深度学习的快速发展导致了人工智能驱动应用的重大进步；然而，这些模型的“黑匣子”特性经常限制它们的可解释性、透明度和可靠性。可解释人工智能 (XAI) 旨在阐明人工智能决策过程，保证解释忠实地代表模型的原理并与人类的理解相符。尽管对 XAI 进行了全面的研究，但在评估 XAI 技术在许多实际应用中的有效性和透明度的标准化程序方面仍然存在很大差距。本研究提出了一个统一的 XAI 评估框架，该框架结合了广泛的定量和定性标准，以系统地评估人工智能模型生成的解释的正确性、可解释性、稳健性、公平性和完整性。该框架优先考虑以用户为中心和特定领域的适应性，从而提高人工智能模型在关键领域的可用性和可靠性。为了解决现有评估流程中的不足，我们建议定义基准和系统评估流程，包括数据加载、解释开发和全面的方法评估。医疗保健、金融、农业和自主系统中的案例研究证明了建议框架的相关性和多样性。这些为公平和可靠的 XAI 方法评估提供了坚实的基础。该范式通过提供系统、灵活和务实的方法来增强 XAI 研究，以确保在许多现实世界环境中 AI 系统的透明度和问责制。]]></description>
      <guid>https://arxiv.org/abs/2412.03884</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SlowFast 网络对行车记录仪视频中的险情事件进行分析</title>
      <link>https://arxiv.org/abs/2412.03903</link>
      <description><![CDATA[arXiv:2412.03903v1 公告类型：新
摘要：本文使用 SlowFast 深度神经网络对近距离交通视频进行分类，该网络模仿人类大脑 M（大细胞）和 P（小细胞）细胞的两种不同流处理的慢速和快速视觉信息的特征。该方法显著提高了交通近距离视频分析的准确性，并提供了对交通场景中人类视觉感知的洞察。此外，它有助于提高交通安全，并为交通事故中潜在的认知错误提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2412.03903</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MISR：测量前沿模型中的工具性自我推理</title>
      <link>https://arxiv.org/abs/2412.03904</link>
      <description><![CDATA[arXiv:2412.03904v1 公告类型：新
摘要：我们提出了一套任务来评估大型语言模型 (LLM) 代理的工具性自我推理能力。工具性自我推理能力可以提高适应性并实现自我修改，但也可能带来重大风险，例如实现欺骗性对齐。先前的工作仅在非代理设置或有限领域中评估了自我推理。在本文中，我们提出了在广泛场景中的代理任务中评估工具性自我推理能力，包括自我修改、知识寻求和不透明的自我推理。我们评估使用最先进的 LLM 构建的代理，包括商业和开源系统。我们发现工具性自我推理能力仅在最强大的前沿模型中出现，并且它高度依赖于上下文。没有一个模型能够通过我们最困难的评估版本，因此我们的评估可用于衡量未来模型中工具性自我推理能力的提高。我们在 https://github.com/kaifronsdal/Self-Reasoning-Evals 上开源了我们的评估。]]></description>
      <guid>https://arxiv.org/abs/2412.03904</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>