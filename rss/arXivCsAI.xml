<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>立场：情景记忆是长期法学硕士代理所缺少的一块拼图</title>
      <link>https://arxiv.org/abs/2502.06975</link>
      <description><![CDATA[arXiv:2502.06975v1 公告类型：新
摘要：随着大型语言模型 (LLM) 从文本完成工具演变为在动态环境中运行的成熟代理，它们必须应对不断学习和保留长期知识的挑战。许多生物系统使用情景记忆来解决这些挑战，情景记忆支持对特定于实例的上下文进行单次学习。受此启发，我们为 LLM 代理提出了一个情景记忆框架，该框架围绕情景记忆的五个关键属性为中心，这些属性是自适应和上下文敏感行为的基础。由于各种研究工作已经部分涵盖了这些属性，本立场文件认为，现在是明确、综合地关注情景记忆以催化长期代理发展的最佳时机。为此，我们概述了一个路线图，将几个研究方向统一在支持情景记忆的所有五个属性的目标下，以实现更高效的长期 LLM 代理。]]></description>
      <guid>https://arxiv.org/abs/2502.06975</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自主深度代理</title>
      <link>https://arxiv.org/abs/2502.07056</link>
      <description><![CDATA[arXiv:2502.07056v1 公告类型：新
摘要：本技术简介介绍了 Deep Agent，这是一种先进的自主 AI 系统，旨在通过新颖的分层任务管理架构管理复杂的多阶段任务。该系统的基础建立在我们的分层任务 DAG (HTDAG) 框架之上，该框架将高级目标动态分解为可管理的子任务，同时严格保持依赖关系和执行一致性。Deep Agent 通过三项关键创新超越了传统的代理系统：首先，它实现了递归的两阶段规划器-执行器架构，可以随着情况的变化不断改进和调整任务。其次，它具有自主 API 和工具创建 (AATC) 系统，可自动从 UI 交互中生成可重用的组件，从而大大降低了类似任务的运营成本。第三，它结合了 Prompt Tweaking Engine 和自主 Prompt Feedback Learning 组件，可针对特定场景优化大型语言模型提示，从而提高推理准确性和操作稳定性。这些组件集成在一起，形成一个服务基础架构，用于管理用户上下文、处理复杂的任务依赖关系以及协调端到端代理工作流执行。通过这种复杂的架构，Deep Agent 在自治 AI 系统中建立了一种新范式，展示了独立处理复杂、多步骤任务的强大能力，同时通过持续的自我优化保持一致的效率和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2502.07056</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与 LLM 代理进行交互式数据协调</title>
      <link>https://arxiv.org/abs/2502.07132</link>
      <description><![CDATA[arXiv:2502.07132v1 公告类型：新
摘要：数据协调是一项基本任务，需要整合来自不同来源的数据集。尽管该领域进行了多年的研究，但由于模式不匹配、术语不同以及数据收集方法的差异，它仍然是一项耗时且具有挑战性的任务。本文介绍了代理数据协调的案例，它既可以帮助专家协调数据，又可以简化流程。我们介绍了 Harmonia，这是一个结合了基于 LLM 的推理、交互式用户界面和数据协调原语库的系统，用于自动合成数据协调管道。我们在临床数据协调场景中演示了 Harmonia，它有助于以交互方式创建可重用的管道，将数据集映射到标准格式。最后，我们讨论了挑战和未解决的问题，并提出了推进我们愿景的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2502.07132</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解法学硕士的流体智力缺陷：ARC 任务分析</title>
      <link>https://arxiv.org/abs/2502.07190</link>
      <description><![CDATA[arXiv:2502.07190v1 公告类型：新
摘要：虽然 LLM 在各种 NLP 任务上表现出色，但值得注意的是，这些任务中的大多数依赖于利用 LLM 参数中编码的大量知识，而不是在没有先验知识的情况下解决新问题。在认知研究中，后一种能力被称为流体智力，这被认为是评估人类智力的关键。最近对流体智力评估的研究强调了 LLM 能力的重大缺陷。在本文中，我们以最具代表性的 ARC 任务为例，分析了 LLM 在通过受控实验展示流体智力方面面临的挑战。我们的研究揭示了现有 LLM 的三个主要局限性：技能组合能力有限、不熟悉抽象输入格式以及从左到右解码的内在缺陷。我们的数据和代码可以在 https://wujunjie1998.github.io/araoc-benchmark.github.io/ 中找到。]]></description>
      <guid>https://arxiv.org/abs/2502.07190</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 推理的推理时间计算技巧</title>
      <link>https://arxiv.org/abs/2502.07191</link>
      <description><![CDATA[arXiv:2502.07191v2 公告类型：新
摘要：随着大型语言模型 (LLM) 的进步，解决复杂的推理任务越来越受到关注。推理时间计算方法（例如 Best-of-N、集束搜索等）特别有价值，因为它们可以在不修改模型参数或需要额外训练的情况下提高推理性能。然而，这些技术面临着实施挑战，大多数现有方法仍处于概念验证阶段，由于其计算复杂性和不同任务之间的不同有效性，实际采用有限。在本文中，我们研究并评估了不同复杂度的推理任务中的各种推理时间计算策略。由于大多数当前方法依赖于提议者-验证者管道，该管道首先生成候选解决方案（例如，推理解决方案），然后根据奖励信号（例如，RLHF 奖励、过程奖励）选择最佳解决方案，因此我们的研究重点是优化候选解决方案生成（例如，指导提示、温度和 top-p 等超参数）和奖励机制（例如，自我评估、奖励类型）。通过对各种规模的各种模型（例如，Llama、Qwen 和 Mistral 系列）进行大量实验（超过 20,000 个 A100-80G GPU 小时，超过 1,000 次实验），我们的消融研究表明，以前被忽视的策略可以显着提高性能（例如，调整温度可以将推理任务性能提高多达 5%）。此外，我们通过系统地评估八个推理任务中的六种代表性方法，为推理时间计算建立了标准化基准。这些发现为未来的研究奠定了更坚实的基础。代码可以在 https://github.com/usail-hkust/benchmark_inference_time_computation_LL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.07191</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>系统 2 规划的蒙特卡洛树扩散</title>
      <link>https://arxiv.org/abs/2502.07202</link>
      <description><![CDATA[arXiv:2502.07202v1 公告类型：新
摘要：扩散模型最近已成为规划的强大工具。然而，与蒙特卡洛树搜索 (MCTS) 不同 - 其性能会随着额外的测试时间计算 (TTC) 而自然提高，而基于扩散的标准规划器仅为 TTC 可扩展性提供有限的途径。在本文中，我们介绍了蒙特卡洛树扩散 (MCTD)，这是一种新颖的框架，它将扩散模型的生成强度与 MCTS 的自适应搜索功能相结合。我们的方法将去噪重新概念化为一个树结构过程，允许对部分去噪的计划进行迭代评估、修剪和细化。通过有选择地扩展有希望的轨迹，同时保留重新访问和改进次优分支的灵活性，MCTD 实现了 MCTS 的好处，例如在扩散框架内控制探索-利用权衡。在具有挑战性的长期任务上的经验结果表明，MCTD 的表现优于扩散基线，随着 TTC 的增加可以产生更高质量的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.07202</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多即是少：理解法学硕士中的思路链长度</title>
      <link>https://arxiv.org/abs/2502.07266</link>
      <description><![CDATA[arXiv:2502.07266v1 公告类型：新
摘要：思路链 (CoT) 推理通过将复杂任务分解为更小、更易于管理的子任务来增强大型语言模型 (LLM) 的多步骤推理能力。研究人员一直在探索引导模型生成更复杂的 CoT 过程以提高 LLM 推理能力的方法，例如长 CoT 和测试时间缩放定律。然而，对于大多数模型和任务，增加 CoT 长度是否会持续提高推理准确性？在本文中，我们观察到一种微妙的关系：随着推理步骤数量的增加，性能最初会提高，但最终会下降。为了理解这种现象，我们提供了一个证据，即较长的推理过程越来越容易受到噪声的影响。我们从理论上证明了最佳 CoT 长度的存在，并根据模型能力和任务难度推导出该最佳长度的缩放定律。受我们理论的启发，我们在合成数据集和现实世界数据集上进行了实验，并提出了长度过滤投票来缓解过长或过短的 CoT 的影响。我们的研究结果强调了校准 CoT 长度以适应模型能力和任务需求的迫切需要，为优化 LLM 中的多步推理提供了一个原则框架。]]></description>
      <guid>https://arxiv.org/abs/2502.07266</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>粗集理论：粗俗伦理的数学基础</title>
      <link>https://arxiv.org/abs/2502.07347</link>
      <description><![CDATA[arXiv:2502.07347v1 公告类型：新
摘要：在道德决策中，个人的评估通常基于广义评估，而不是精确的个人表现。这个被称为粗略伦理 (CE) 的概念主要在自然语言中讨论，没有正式的数学基础。本文引入了粗集理论 (CST) 来建立 CE 的数学框架。我们使用完全有序集定义粗集，并提出描述元素及其分组之间层次关系的公理。此外，我们引入了粗粒度集，它根据预定义的标准将底层集合划分为等价类。我们通过定义粗映射来扩展这个框架，将详细的个人数据转换为更粗的表示，同时保持基本的结构属性。为了衡量信息丢失，我们采用 Kullback-Leibler (KL) 散度，展示不同的粗分区如何影响信息的保存。我们通过理论公式和实证分析来说明 CST 如何应用于现实世界的评分系统。这项研究为 CE 提供了严谨的基础，使人们能够更系统地探索公平性、可解释性和决策权衡。]]></description>
      <guid>https://arxiv.org/abs/2502.07347</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KABB：用于多智能体系统中动态专家协调的知识感知贝叶斯赌博机</title>
      <link>https://arxiv.org/abs/2502.07350</link>
      <description><![CDATA[arXiv:2502.07350v1 公告类型：新
摘要：由于扩展大型语言模型面临高昂的成本，多智能体系统成为一种有前途的替代方案，尽管受到静态知识假设和协调效率低下的挑战。我们引入了知识感知贝叶斯老虎机 (KABB)，这是一种通过语义理解和动态适应增强多智能体系统协调的新框架。该框架具有三个关键创新：用于深度语义理解的三维知识距离模型、用于持续专家优化的双重适应机制以及用于有效专家选择的知识感知汤普森采样策略。广泛的评估表明，KABB 实现了最佳的性价比平衡，在多智能体协调中保持高性能的同时保持相对较低的计算需求。]]></description>
      <guid>https://arxiv.org/abs/2502.07350</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以轻松地从演示结构中学习推理，而不是内容，这才是最重要的！</title>
      <link>https://arxiv.org/abs/2502.07374</link>
      <description><![CDATA[arXiv:2502.07374v1 公告类型：新
摘要：大型推理模型 (LRM) 通过遵循包含反思、回溯和自我验证的长链思维 (Long CoT) 来解决复杂的推理问题。然而，引出长 CoT 的训练技术和数据要求仍然不太清楚。在这项工作中，我们发现大型语言模型 (LLM) 可以通过数据高效的监督微调 (SFT) 和参数高效的低秩自适应 (LoRA) 有效地学习长 CoT 推理。仅使用 17k 个长 CoT 训练样本，Qwen2.5-32B-Instruct 模型就在广泛的数学和编码基准测试中取得了显著的进步，包括 AIME 2024 上的 56.7% (+40.0%) 和 LiveCodeBench 上的 57.0% (+8.1%)，与专有 o1-preview 模型的 44.6% 和 59.1% 的得分相媲美。更重要的是，我们发现长 CoT 的结构对学习过程至关重要，而各个推理步骤的内容影响甚微。影响内容的扰动（例如使用不正确的样本进行训练或删除推理关键字）对性能影响不大。相反，破坏长 CoT 逻辑一致性的结构修改（例如改组或删除推理步骤）会显著降低准确性。例如，使用具有错误答案的长 CoT 样本训练的模型与使用完全正确的样本进行训练相比，准确率仍仅低 3.2%。这些见解加深了我们对如何在 LLM 中引出推理能力的理解，并强调了有效训练下一代推理模型的关键考虑因素。这是我们之前发布的 Sky-T1-32B-Preview 模型的学术论文。代码可在 https://github.com/NovaSky-AI/SkyThought 上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.07374</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过计算内在动机走向能力需求的形式理论</title>
      <link>https://arxiv.org/abs/2502.07423</link>
      <description><![CDATA[arXiv:2502.07423v1 公告类型：新
摘要：计算模型为形式化心理学理论提供了强大的工具，使其在数字环境中既可测试又可应用。然而，它们在心理学动机研究中仍然很少使用。我们专注于“能力需求”，它被假定为自我决定理论 (SDT) 中的一项关键基本人类需求——可以说是研究内在动机 (IM) 最具影响力的心理学框架。能力需求在 SDT 文本中被视为单一结构。然而，最近的研究已经确定了 SDT 中能力的多个定义模糊的方面。我们提出，这些不一致之处可以通过借鉴人工智能领域的计算模型来缓解，特别是强化学习 (RL) 领域的计算模型。通过将上述能力的各个方面（效果、技能使用、任务绩效和能力增长）与现有的 RL 形式主义相结合，我们为更广泛地推进 SDT 和动机心理学中的能力相关理论奠定了基础。这些形式主义揭示了 SDT 未能明确说明的潜在先决条件，展示了计算模型如何改善我们对 IM 的理解。此外，我们的工作可以通过启发新的计算模型来支持理论发展的周期，这些模型形式化了理论的各个方面，然后可以通过实证测试来完善理论。虽然我们的研究奠定了良好的基础，但仍需要对这些模型在人类和机器中进行实证研究，从而吸引跨学科合作。]]></description>
      <guid>https://arxiv.org/abs/2502.07423</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 增强型递归推理器和多智能体超级博弈来近似人类战略推理</title>
      <link>https://arxiv.org/abs/2502.07443</link>
      <description><![CDATA[arXiv:2502.07443v1 公告类型：新
摘要：LLM 驱动的多智能体模拟在博弈论和社会模拟中的应用越来越受到关注。虽然大多数实现都试图利用或评估 LLM 智能体推理，但它们通常使用较弱的代理概念和简化的架构来实现。我们实施了一个基于角色的多智能体战略交互框架，该框架针对复杂的递归推理器量身定制，为系统深入开发和评估战略推理提供了手段。我们的游戏环境由负责促进游戏的裁判管理，从配对到移动验证再到环境管理。玩家将最先进的 LLM 融入他们的决策机制中，依赖于基于正式超游戏的分层信念模型。我们使用一次性、2 人选美比赛来评估最新 LLM 的递归推理能力，并与经济学中已建立的基线模型和来自人类实验的数据进行比较。此外，我们为 k 级理论引入了另一种语义推理度量的基础。我们的实验表明，人工智能推理机在接近人类行为和达到最优解方面的表现都优于基线模型。]]></description>
      <guid>https://arxiv.org/abs/2502.07443</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在渐进式论证中引出合理的初始权重</title>
      <link>https://arxiv.org/abs/2502.07452</link>
      <description><![CDATA[arXiv:2502.07452v1 公告类型：新
摘要：许多加权论证框架的语义假设每个论证都与一个初始权重相关联。然而，引出这些初始权重带来了挑战：（1）准确提供特定数值通常很困难，（2）在存在其他论证的情况下，个人经常将初始权重与可接受度混淆。为了解决这些问题，我们提出了一个引出管道，允许人们为每个论证指定可接受度区间。通过使用渐进语义，我们可以在合理时细化这些区间，在不合理时恢复合理性，并最终确定每个论证的可能初始权重。]]></description>
      <guid>https://arxiv.org/abs/2502.07452</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URECA：语义代码搜索适应转变背后存在两个最小集覆盖问题链</title>
      <link>https://arxiv.org/abs/2502.07494</link>
      <description><![CDATA[arXiv:2502.07494v1 公告类型：新
摘要：自适应是让模型学习从训练分布中偏移的模式。一般来说，这种自适应被表述为最小熵问题。然而，最小熵问题具有固有的局限性——偏移初始化级联现象。我们通过勒贝格积分扩展了最小熵问题和最小集覆盖问题之间的关系。这种扩展揭示了最小熵问题的内部机制忽略了解缠结表示之间的关系，从而导致了偏移初始化级联。通过分析，我们引入了一种新的聚类算法，基于联合查找的递归聚类算法~(URECA)。URECA 是一种有效的聚类算法，用于利用解缠结表示之间的关系。URECA 的更新规则依赖于阈值可更新平稳假设对动态的发布版本平稳假设。这一假设有助于 URECA 基于解缠结表示之间的关系无错误地传输解缠结表示。URECA 还利用模拟技巧有效地对解缠结表示进行聚类。广泛的评估表明，URECA 在对不同类型的移位进行少量适应时实现了一致的性能提升，并在查询移位场景中在 CoSQA 中提升到了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.07494</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用递归推理缩放来驾驭语言的分形几何</title>
      <link>https://arxiv.org/abs/2502.07503</link>
      <description><![CDATA[arXiv:2502.07503v1 公告类型：新
摘要：语言建模方面的最新研究揭示了两种扩展效应：众所周知的来自增加训练计算的改进，以及鲜为人知的来自应用更复杂或计算密集型推理方法的提升。受最近关于语言分形几何的发现的启发，我们引入了递归推理扩展 ​​(RINS) 作为扩展推理时间的补充插件配方。对于给定的固定模型架构和训练计算预算，RINS 可显着提高语言建模性能。它还可以推广到纯语言任务之外，在多模态系统中带来收益，包括 SigLIP-B/16 的 0-shot ImageNet 准确率提高 +2%。此外，通过推导数据缩放定律，我们表明 RINS 可以改善渐近性能极限和缩放指数。即使与最先进的递归技术（如 Mobile LLM 中的“全部重复”（RAO）策略）相比，这些优势仍然保持不变。最后，随机 RINS 不仅可以进一步提高性能，而且还提供了灵活性，可以选择在测试时放弃增加的推理计算，同时将性能下降降至最低。]]></description>
      <guid>https://arxiv.org/abs/2502.07503</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>