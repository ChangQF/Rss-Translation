<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 26 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>强化条件作用下的文本扩散</title>
      <link>https://arxiv.org/abs/2402.14843</link>
      <description><![CDATA[arXiv:2402.14843v1 公告类型：交叉
摘要：扩散模型在生成高质量图像、视频和音频方面表现出了卓越的能力。由于它们在迭代细化方面的适应性，它们为实现更好的非自回归序列生成提供了强大的潜力。然而，由于处理语言离散性方面的挑战，现有的文本扩散模型在性能上仍然存在不足。本文彻底分析了文本传播模型，并揭示了两个显着的局限性：训练过程中自我调节的退化以及训练和采样之间的错位。受我们研究结果的启发，我们提出了一种名为 TREC 的新型文本扩散模型，该模型可以通过强化条件调节来减轻退化，并通过时间感知方差缩放来减轻错位。我们广泛的实验证明了 TREC 相对于自回归、非自回归和扩散基线的竞争力。此外，定性分析显示其在精炼样品中充分利用扩散过程的先进能力。]]></description>
      <guid>https://arxiv.org/abs/2402.14843</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>RFBES 在 SemEval-2024 任务 8：研究句法和语义特征以区分人工智能生成的文本和人类编写的文本</title>
      <link>https://arxiv.org/abs/2402.14838</link>
      <description><![CDATA[arXiv:2402.14838v1 公告类型：交叉
摘要：如今，大型语言模型（LLM）的使用有所增加，LLM 已被用于生成不同语言和不同任务的文本。此外，由于谷歌和OpenAI等知名公司的参与，法学硕士现在更容易获得，人们可以轻松使用它们。然而，一个重要的问题是我们如何从人类编写的文本中检测人工智能生成的文本。在本文中，我们从语义和语法两个不同的方面研究了人工智能生成的文本检测问题。最后，我们提出了一个人工智能模型，可以使用 M4 数据集在多语言和单语言任务上高精度地区分人工智能生成的文本和人类编写的文本。根据我们的结果，使用语义方法对检测更有帮助。然而，句法方法还有很大的改进空间，这将是未来工作的一个很好的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.14838</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>RJUA-MedDQA：医疗文档问答和临床推理的多模式基准</title>
      <link>https://arxiv.org/abs/2402.14840</link>
      <description><![CDATA[arXiv:2402.14840v1 公告类型：交叉
摘要：大型语言模型（LLM）和大型多模态模型（LMM）的最新进展在智能医疗诊断等各种医疗应用中显示出了潜力。尽管取得了令人印象深刻的结果，但我们发现现有的基准并不能反映真实医疗报告的复杂性和专门的深度推理能力。在这项工作中，我们引入了 RJUA-MedDQA，这是医学专业领域的综合基准，它提出了几个挑战：在各种具有挑战性的布局中全面解释图像内容，拥有识别异常指标的数字推理能力，并展示提供陈述的临床推理能力基于医疗背景的疾病诊断、状态和建议。我们精心设计了数据生成流程，并提出了高效结构恢复注释（ESRA）方法，旨在恢复医疗报告图像中的文本和表格内容。该方法极大地提高了标注效率，使每个标注者的生产力提高了一倍，并且准确率提高了 26.8%。我们进行了广泛的评估，包括对 5 个能够解决中国医学 QA 任务的 LMM 进行小样本评估。为了进一步研究当前 LMM 的局限性和潜力，我们使用 ESRA 方法生成的图像文本对一组强 LMM 进行了比较实验。我们报告了基线的性能并提供了一些观察结果：（1）现有 LMM 的整体性能仍然有限；然而，与 LLM 相比，LMM 对低质量和多样化结构的图像更稳健。 (3) 跨上下文和图像内容的推理提出了重大挑战。我们希望这个基准能够帮助社区在多模式医疗文档理解方面的这些具有挑战性的任务上取得进展，并促进其在医疗保健中的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.14840</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型提示技术的实证分类：从业者指南</title>
      <link>https://arxiv.org/abs/2402.14837</link>
      <description><![CDATA[arXiv:2402.14837v1 公告类型：交叉
摘要：由于大型语言模型（LLM）开发的快速进步，使用提示对这些模型进行编程最近引起了极大的关注。然而，可用的即时工程技术的绝对数量为希望利用这些工具的从业者创造了压倒性的前景。为了最有效地利用法学硕士，编制一份全面的提示技术清单并建立标准化的跨学科分类框架非常重要。在这项调查中，我们从学术和实践的角度研究了一些最著名的提示技巧，并将它们分为七个不同的类别。我们对每个类别进行概述，旨在阐明它们的独特贡献并展示它们在现实世界示例中的实际应用，以便为其他从业者提供一个结构化框架，用于理解和分类适合其特定领域的提示技术。我们相信，这种方法将有助于简化即时工程的复杂情况，并能够在各种应用中更有效地利用法学硕士。通过为从业者提供系统的提示分类方法，我们的目标是帮助经过对话预训练的法学硕士了解有效提示设计的复杂性，并在各自领域激发新的可能性。]]></description>
      <guid>https://arxiv.org/abs/2402.14837</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>MIKE：细粒度多模态实体知识编辑的新基准</title>
      <link>https://arxiv.org/abs/2402.14835</link>
      <description><![CDATA[arXiv:2402.14835v1 公告类型：交叉
摘要：多模态知识编辑代表了增强多模态大语言模型（MLLM）能力的关键进步。尽管具有潜力，但当前的基准主要关注粗粒度知识，而细粒度（FG）多模态实体知识的复杂性在很大程度上尚未得到探索。这一差距提出了一个显着的挑战，因为 FG 实体识别对于 MLLM 在各种现实场景中的实际部署和有效性至关重要。为了弥补这一差距，我们引入了 MIKE，这是一个专门为 FG 多模态实体知识编辑设计的综合基准和数据集。 MIKE 包含一套专为评估不同观点而定制的任务，包括普通名称应答、实体级标题和复杂场景识别。此外，还引入了一种新的知识编辑形式——多步编辑来评估编辑效率。通过我们的广泛评估，我们证明当前最先进的方法在处理我们提出的基准方面面临着重大挑战，强调了 MLLM 中 FG 知识编辑的复杂性。我们的研究结果凸显了该领域对新方法的迫切需求，为社区内未来的研究和开发工作制定了明确的议程。]]></description>
      <guid>https://arxiv.org/abs/2402.14835</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>基于大语言模型的推荐的隐秘攻击</title>
      <link>https://arxiv.org/abs/2402.14836</link>
      <description><![CDATA[arXiv:2402.14836v1 公告类型：交叉
摘要：最近，强大的大语言模型（LLM）在推动推荐系统（RS）的进步方面发挥了重要作用。然而，尽管这些系统蓬勃发展，但它们对安全威胁的敏感性却在很大程度上被忽视了。在这项工作中，我们揭示了将法学硕士引入推荐模型会带来新的安全漏洞，因为它们强调项目的文本内容。我们证明，攻击者只需在测试阶段更改项目的文本内容即可显着提高项目的曝光率，而无需直接干扰模型的训练过程。此外，这种攻击非常隐蔽，因为它不会影响整体推荐性能，而且对文本的修改很微妙，使得用户和平台很难检测到。我们对四种主流的基于 LLM 的推荐模型进行了全面的实验，证明了我们方法的卓越功效和隐蔽性。我们的工作揭示了基于法学硕士的推荐系统中存在的重大安全漏洞，并为未来保护这些系统的研究铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2402.14836</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>MSynFD：多跳语法感知假新闻检测</title>
      <link>https://arxiv.org/abs/2402.14834</link>
      <description><![CDATA[arXiv:2402.14834v1 公告类型：交叉
摘要：社交媒体平台的激增助长了假新闻的快速传播，对我们的现实社会构成了威胁。现有方法使用多模态数据或上下文信息，通过分析新闻内容和/或其社会背景来增强对假新闻的检测。然而，这些方法常常忽视重要的文本新闻内容（文章），并严重依赖顺序建模和全局注意力来提取语义信息。这些现有的方法无法处理新闻文章中复杂、微妙的扭曲，例如语法语义不匹配和先验偏差，当模式或社会背景缺失时，会导致性能下降和潜在的失败。为了弥补这些重大差距，我们提出了一种新颖的多跳语法感知假新闻检测（MSynFD）方法，该方法结合了补充语法信息来处理假新闻中的微妙变化。具体来说，我们引入了语法依赖图并设计了多跳子图聚合机制来捕获多跳语法。它扩展了单词感知的效果，从而实现有效的噪声过滤和相邻关系增强。随后，设计了一个顺序相对位置感知 Transformer 来捕获顺序信息，以及一个精心设计的关键字去偏差模块来减轻先验偏差。在两个公共基准数据集上的广泛实验结果验证了我们提出的 MSynFD 相对于最先进的检测模型的有效性和优越性能。]]></description>
      <guid>https://arxiv.org/abs/2402.14834</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>Orca-Math：释放 SLM 在小学数学中的潜力</title>
      <link>https://arxiv.org/abs/2402.14830</link>
      <description><![CDATA[arXiv:2402.14830v1 公告类型：交叉
摘要：长期以来，数学应用问题解决一直被认为是小语言模型（SLM）的一项复杂任务。最近的一项研究假设，在 GSM8K 基准上实现超过 80% 的准确度所需的最小模型大小为 340 亿个参数。为了使用较小的模型达到这种性能水平，研究人员经常训练 SLM 来生成 Python 代码或使用工具来帮助避免计算错误。此外，他们还采用集成，将多达 100 个模型运行的输出组合起来，以获得更准确的结果。结果选择是使用共识、多数投票或与 SLM 结合使用的单独验证者模型来完成的。集成极大地提高了准确性，但由于多次调用模型，成本显着增加（例如，Phi-GSM 使用 top-48 将性能从 68.2 提高到 81.5）。
  在这项工作中，我们提出了 Orca-Math，一种基于 Mistral-7B 的 70 亿参数 SLM，它在 GSM8k 上实现了 86.81%，无需多个模型调用或使用验证器、代码执行或任何其他外部工具。我们的方法具有以下关键要素：(1) 使用多代理设置创建的 20 万个数学问题的高质量综合数据集，其中代理协作创建数据，(2) 迭代学习技术，使 SLM 能够练习解决问题，接收有关其解决方案的反馈，并从结合了 SLM 解决方案和反馈的偏好对中学习。当单独使用监督微调进行训练时，Orca-Math 在 GSM8k pass@1 指标上达到了 81.50%。通过迭代偏好学习，Orca-Math 达到了 86.81% pass@1。 Orca-Math 的性能超越了较大模型的性能，例如 LLAMA-2-70B、WizardMath-70B、Gemini-Pro、ChatGPT-3.5。在使用更小的数据（数十万与数百万问题）时，它的性能也显着优于其他较小的模型。]]></description>
      <guid>https://arxiv.org/abs/2402.14830</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>CliqueParcel：一种联合优化效率和忠诚度的 LLM 提示批处理方法</title>
      <link>https://arxiv.org/abs/2402.14833</link>
      <description><![CDATA[arXiv:2402.14833v1 公告类型：交叉
摘要：大型语言模型（LLM）在最近的研究中已变得至关重要。然而，在推理过程中，法学硕士仍然需要大量资源。在本文中，我们提出了 CliqueParcel，一种旨在通过即时批处理提高 LLM 效率的方法。现有的优化推理效率的策略通常会损害输出质量，从而导致输出折扣问题。此问题可能会导致准确性降低或输出不太详细。 CliqueParcel 是我们应对这一挑战的答案。在确保准确性并最大限度地减少与原始输出的偏差（即忠实度）的同时，我们的方法显着提高了推理过程中的效率。
  为了奠定基础，我们首先重新定义效率测量，排除由于较短的长度而导致的运行时间的减少。然后，我们提供效率和忠诚度之间的全面权衡，以阐明“贴现产出”问题的本质。在 CliqueParcel 框架内，我们建议使用多种批处理子方法，并讨论它们可以应用的具体场景。在评估过程中，CliqueParcel 在八个广泛认可的数据集上进行了测试，这些数据集可分为三种类型：阅读理解、开源问答和推理。我们的实验探索了 CliqueParcel 的性能，包括效率、忠实度以及它们之间的权衡。这项工作为推理效率提供了新颖的见解，并展示了有前途的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.14833</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>AgentOhana：设计统一数据和训练管道以实现有效的代理学习</title>
      <link>https://arxiv.org/abs/2402.15506</link>
      <description><![CDATA[arXiv:2402.15506v1 公告类型：新
摘要：由大语言模型（LLM）支持的自主代理已经引起了广泛的研究关注。然而，由于具有多轮轨迹的不同数据源的异构性，充分利用法学硕士的潜力来完成基于代理的任务会带来固有的挑战。在本文中，我们引入 \textbf{AgentOhana} 作为应对这些挑战的综合解决方案。 \textit{AgentOhana} 聚合来自不同环境的代理轨迹，涵盖各种场景。它将这些轨迹精心标准化并统一为一致的格式，简化了针对代理培训优化的通用数据加载器的创建。利用数据统一，我们的训练管道在不同数据源之间保持平衡，并在数据集分区和模型训练期间保持跨设备的独立随机性。此外，我们还推出了 \textbf{xLAM-v0.1}，这是一个为 AI 代理量身定制的大型动作模型，它在各种基准测试中表现出了卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.15506</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>通过窗口选择和节点优化优化妊娠和临产时的子宫同步分析</title>
      <link>https://arxiv.org/abs/2402.14827</link>
      <description><![CDATA[arXiv:2402.14827v1 公告类型：交叉
摘要：早产（PL）已成为全球 5 岁以下儿童死亡的主要原因。为了解决这个问题，本文将通过分析分娩和怀孕期间母亲腹部记录的 EHG 信号来提供一种新方法。 EHG 信号反映了引起子宫肌层机械收缩的电活动。由于已知 EHG 是非平稳信号，并且由于我们预计连接在收缩期间会发生变化，因此我们对真实信号应用加窗方法，以帮助我们识别具有用于分类的最重要数据的最佳窗口和最佳节点。建议的流程包括 i) 将孕妇腹部记录的 16 个 EHG 信号划分为 N 个窗口； ii) 在每个窗口上应用连接矩阵； iii) 对每个窗口上的连接矩阵应用基于图论的测量； iv) 在每个窗口上应用共识矩阵，以检索最佳窗口和最佳节点。接下来，根据不同的输入参数（单独的连接方法、连接方法加图形参数、最佳节点、所有节点、最佳节点），将几种神经网络和机器学习方法应用于最佳窗口和最佳节点，以对妊娠和分娩宫缩进行分类。窗口，所有窗口）。结果显示，最好的节点是节点8、9、10、11和12；最佳窗口为2、4、5。仅使用这些最佳节点得到的分类结果比使用整个节点时得到的分类结果更好。无论选择什么节点，使用全突发时结果总是更好。因此，加窗方法被证明是一种创新技术，可以改善分娩和妊娠 EHG 信号之间的差异。]]></description>
      <guid>https://arxiv.org/abs/2402.14827</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>释放不平衡模态信息的力量，完成多模态知识图谱</title>
      <link>https://arxiv.org/abs/2402.15444</link>
      <description><![CDATA[arXiv:2402.15444v1 公告类型：新
摘要：多模态知识图补全（MMKGC）旨在通过将实体的结构、视觉和文本信息纳入判别模型来预测多模态知识图中缺失的三元组。来自不同方式的信息将共同衡量三重似真性。现有的MMKGC方法忽视了实体间模态信息不平衡的问题，导致模态融合不充分，原始模态信息利用效率低下。为了解决上述问题，我们提出了自适应多模态融合和模态对抗训练（AdaMF-MAT），以释放 MMKGC 不平衡模态信息的力量。 AdaMF-MAT通过自适应模态权重实现多模态融合，并进一步通过模态对抗训练生成对抗样本，以增强不平衡的模态信息。我们的方法是 MMKGC 模型和训练策略的共同设计，它可以超越最近的 19 种 MMKGC 方法，并在三个公共 MMKGC 基准上取得新的最先进的结果。我们的代码和数据已发布在https://github.com/zjukg/AdaMF-MAT。]]></description>
      <guid>https://arxiv.org/abs/2402.15444</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>我们会忘记我们是如何学习的吗？迭代信念修正中的信念冗余</title>
      <link>https://arxiv.org/abs/2402.15445</link>
      <description><![CDATA[arXiv:2402.15445v1 公告类型：新
摘要：如何获取信息可能变得无关紧要。一个明显的例子是某件事被多次确认。就迭代信念修正而言，特定的修正可能在其他人存在的情况下变得无关紧要。简单的重复就是一个例子，但并不是发生这种情况的唯一情况。有时，即使没有同等版本，甚至没有其他暗示，修订也会变得多余。给出了字典序修订序列中第一个的冗余的充分必要条件。即使只有两个命题修订，该问题也是 coNP 完全的。 Horn 案例中的复杂性是相同的，但仅具有无限数量的修订：它变成具有两次修订的多项式。词典编纂修订不仅本身相关，而且还因为它们的序列是用于表示迭代修订过程的状态的最紧凑的常见机制。缩短词典编纂修订序列正在缩短迭代信念修订状态的最紧凑表示。]]></description>
      <guid>https://arxiv.org/abs/2402.15445</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>在混合贝叶斯网络模型中堆叠因式分解分区表达式</title>
      <link>https://arxiv.org/abs/2402.15075</link>
      <description><![CDATA[arXiv:2402.15075v1 公告类型：新
摘要：混合贝叶斯网络（HBN）包含复杂的条件概率分布（CPD），指定为离散和连续变量的分区表达式。当使用离散推理时，这些 CPD 的大小随着父节点的数量呈指数增长，导致效率显着低下。通常，减小 CPD 大小的有效方法是使用二元分解 (BF) 算法，通过将连接的父节点的数量分解为大小为 2 的集合来分解 CPD 中的统计或算术函数。然而，BF 算法并不是为处理分区表达式而设计的。因此，我们提出了一种称为堆叠分解（SF）的新算法来分解分区表达式。 SF 算法创建中间节点来增量重建原始分区表达式中的密度，允许不超过两个连续父节点连接到生成的 HBN 中的每个子节点。 SF可以单独使用，也可以与BF算法结合使用。我们表明，SF+BF 算法显着减小了 CPD 大小，有助于降低模型的树宽，从而提高效率。]]></description>
      <guid>https://arxiv.org/abs/2402.15075</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>超关系知识图中消息传递的关系交互方法</title>
      <link>https://arxiv.org/abs/2402.15140</link>
      <description><![CDATA[arXiv:2402.15140v1 公告类型：新
摘要：超关系知识图（KG）包含额外的键值对，提供有关关系的更多信息。在许多场景中，相同的关系可以具有不同的键值对，使得原始三元组事实更加可识别和具体。先前对超关系知识图谱的研究已经为超关系图编码建立了可靠的标准方法。在这项工作中，我们提出了一种具有全局关系结构感知能力的基于消息传递的图编码器，我们称之为ReSaE。与现有最先进的方法相比，ReSaE 强调消息传递过程中关系的交互，并优化了链路预测任务的读出结构。总体而言，ReSaE 为超关系 KG 提供了编码解决方案，并确保在下游链路预测任务上具有更强的性能。我们的实验表明，ReSaE 在多个链路预测基准上实现了最先进的性能。此外，我们还分析了不同模型结构对模型性能的影响。]]></description>
      <guid>https://arxiv.org/abs/2402.15140</guid>
      <pubDate>Mon, 26 Feb 2024 06:17:46 GMT</pubDate>
    </item>
    </channel>
</rss>