<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>思考更聪明，而不是思考更困难：具有推理感知优化的自适应推理</title>
      <link>https://arxiv.org/abs/2501.17974</link>
      <description><![CDATA[arXiv:2501.17974v1 公告类型：新
摘要：解决数学问题一直是大型语言模型的一项有趣功能，人们已经做出许多努力通过延长推理长度来改进推理，例如通过自我纠正和广泛的长链思维。虽然先进的长推理链模型在解决问题方面很有前景，但它表现出不受欢迎的单模态行为，其中琐碎的问题需要不必要的冗长的长链思维。在这项工作中，我们提出了一种方法，让模型能够意识到推理预算，方法是将其表述为关于推理预算约束的效用最大化，因此将我们的算法命名为推理预算约束策略优化 (IBPO)。简而言之，通过 IBPO 微调的模型学会“理解”查询的难度并将推理预算分配给更难的查询。使用不同的推理预算，我们的最佳模型在 MATH500 上分别使用 $2.16$x 和 $4.32$x 推理预算，相对于 LLaMA3.1 8B Instruct，能够获得 $4.14$\% 和 $5.74$\% 的绝对改进（$8.08$\% 和 $11.2$\% 的相对改进）。这些改进大约是相同预算下自洽性的 $2$x。]]></description>
      <guid>https://arxiv.org/abs/2501.17974</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>研究蒙特卡罗树搜索方法解决车间作业调度问题</title>
      <link>https://arxiv.org/abs/2501.17991</link>
      <description><![CDATA[arXiv:2501.17991v1 公告类型：新
摘要：车间作业调度问题 (JSSP) 是制造业中一个众所周知的优化问题，其目标是确定不同机器间作业的最佳顺序，以最小化给定目标。在这项工作中，我们专注于最小化作业完成时间的加权总和。我们探索蒙特卡洛树搜索 (MCTS)（一种基于启发式的强化学习技术）解决大规模 JSSP（尤其是具有再循环的 JSSP）的潜力。我们提出了几种马尔可夫决策过程 (MDP) 公式来为 MCTS 算法建模 JSSP。此外，我们引入了一个从实际制造数据中得出的新合成基准，它可以捕捉实践中经常遇到的大型非矩形实例的复杂性。我们的实验结果表明，MCTS 可以有效地为大规模 JSSP 实例生成高质量的解决方案，优于我们的约束编程方法。]]></description>
      <guid>https://arxiv.org/abs/2501.17991</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型思考太快，无法有效探索</title>
      <link>https://arxiv.org/abs/2501.18009</link>
      <description><![CDATA[arXiv:2501.18009v1 公告类型：新
摘要：大型语言模型已经出现了许多智力能力。虽然有许多基准测试评估了它们的智力，但人们对它们的探索能力关注有限，而探索能力是发现新信息和适应自然和人工系统中新环境的基本能力。LLM 能够有效探索的程度，特别是在开放式任务中，仍不清楚。这项研究调查了 LLM 是否可以在开放式任务的探索中超越人类，使用 Little Alchemy 2 作为范例，其中代理将元素组合起来以发现新元素。结果表明，除了 o1 模型外，大多数 LLM 的表现都不如人类，这些传统的 LLM 主要依赖于不确定性驱动的策略，而不像人类那样平衡不确定性和赋权。使用稀疏自动编码器对模型的表征分析表明，不确定性和选择在较早的转换器块中表示，而赋权值在较晚的处理中，导致 LLM 思考得太快并做出过早的决定，阻碍了有效的探索。这些发现揭示了 LLM 探索的局限性并提出了提高其适应性的方向。]]></description>
      <guid>https://arxiv.org/abs/2501.18009</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有日常道德困境的大型语言模型的规范评估</title>
      <link>https://arxiv.org/abs/2501.18081</link>
      <description><![CDATA[arXiv:2501.18081v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速采用促使人们对其编码的道德规范和决策过程进行广泛研究。这些研究的大部分内容都依赖于用调查式问题提示 LLM，以评估模型与某些人口群体、道德信仰或政治意识形态的契合程度。虽然这些方法很有启发性，但它们对相对肤浅的构造的坚持往往会过度简化日常道德困境背后的复杂性和细微差别。我们认为，沿着更详细的人类互动轴线审核 LLM 至关重要，以便更好地评估它们可能对人类信仰和行为产生的影响程度。为此，我们评估了 LLM 在复杂的日常道德困境上的表现，这些困境来自 Reddit 上的“我是混蛋吗”(AITA) 社区，用户在该社区寻求其他社区成员对日常冲突的道德判断。我们促使七位法学硕士 (LLM) 为 10,000 多个 AITA 道德困境归咎并给出解释。然后，我们将法学硕士的判断和解释与 Reddit 用户以及彼此的判断和解释进行比较，旨在发现他们道德推理中的模式。我们的结果表明，大型语言模型表现出不同的道德判断模式，与 AITA 子版块上的人类评估有很大不同。法学硕士表现出中等到高度的自洽性，但模型间一致性较低。对模型解释的进一步分析揭示了模型如何调用各种道德原则的不同模式。这些发现强调了在人工系统中实施一致道德推理的复杂性，以及仔细评估不同模型如何处理道德判断的必要性。由于法学硕士继续用于需要道德决策的角色（例如治疗师和陪护人员），因此仔细评估对于减轻潜在的偏见和局限性至关重要。]]></description>
      <guid>https://arxiv.org/abs/2501.18081</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习以法官思维进行评估计划和推理</title>
      <link>https://arxiv.org/abs/2501.18099</link>
      <description><![CDATA[arXiv:2501.18099v1 公告类型：新
摘要：LLM-as-a-Judge 模型生成思路链 (CoT) 序列，旨在捕捉最终评估响应所依据的逐步推理过程。然而，由于缺乏人工注释的 CoT 用于评估，有效推理轨迹所需的组件和结构仍未得到充分研究。因此，以前的方法通常 (1) 将推理轨迹限制为手工设计的组件，例如标准列表、参考答案或验证问题，以及 (2) 将它们结构化，使规划与评估推理交织在一起。在这项工作中，我们提出了 EvalPlanner，这是一种用于 Thinking-LLM-as-a-Judge 的偏好优化算法，它首先生成不受约束的评估计划，然后执行，然后做出最终判断。在自我训练循环中，EvalPlanner 会迭代优化综合构建的评估计划和执行，从而得出更好的最终判决。尽管我们的方法在较少数量且综合生成的偏好对上进行训练，但它在 RewardBench 上的生成奖励模型中取得了新的最佳表现（得分为 93.9）。在 RM-Bench、JudgeBench 和 FollowBenchEval 等其他基准上进行的额外实验进一步凸显了规划和推理对于构建强大的 LLM-as-a-Judge 推理模型的实用性。]]></description>
      <guid>https://arxiv.org/abs/2501.18099</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>专业化下的经济理性：人工智能代理决策偏见的证据</title>
      <link>https://arxiv.org/abs/2501.18190</link>
      <description><![CDATA[arXiv:2501.18190v1 Announce Type: new 
摘要：在Chen et al. (2023) [01]的研究中，大型语言模型GPT在预算分配、风险偏好等任务上表现出了与人类平均水平相当甚至超过人类平均水平的经济理性。在此基础上，本文进一步引入生物技术专家、经济学家等专业化智能体进行横向比较，探讨专业化能否在类似决策场景下增强或维持与GPT相当的经济理性。结果表明，当智能体在专业领域投入更多精力时，其决策行为更容易发生“理性转移”，具体表现为GARP（显示偏好广义公理）违反行为增多、CCEI（关键成本效率指数）下降，高风险条件下决策偏差更显著。相比之下，GPT和更广义化的基础智能体在多个任务中保持了更稳定、一致的理性水平。该研究揭示了专业化与经济理性之间的内在冲突，为构建在不同场景下平衡专业化与泛化的人工智能决策系统提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2501.18190</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于神经算子的强化学习，用于控制具有空间变化状态延迟的一阶偏微分方程</title>
      <link>https://arxiv.org/abs/2501.18201</link>
      <description><![CDATA[arXiv:2501.18201v1 公告类型：新
摘要：受延迟影响的分布式参数系统的控制是一项具有挑战性的任务，特别是当延迟取决于空间变量时。将分析控制理论与基于学习的控制相结合形成统一控制方案的想法正变得越来越有前景和优势。在本文中，我们通过结合 PDE 反步控制策略和深度强化学习 (RL) 来解决控制具有空间变化延迟的不稳定一阶双曲 PDE 的问题。为了消除反步设计所需的延迟函数假设，我们提出了一种软演员-评论家 (SAC) 架构，该架构结合了 DeepONet 来近似反步控制器。DeepONet 从反步控制器中提取特征并将它们输入到策略网络中。在模拟中，我们的算法优于没有先验反步知识和分析控制器的基线 SAC。]]></description>
      <guid>https://arxiv.org/abs/2501.18201</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过引导逻辑推理扩展神经符号编程</title>
      <link>https://arxiv.org/abs/2501.18202</link>
      <description><![CDATA[arXiv:2501.18202v1 公告类型：新 
摘要：概率神经符号学习寻求将神经网络与符号编程相结合。许多最先进的系统依赖于概率加权模型计数问题 (PWMC) 的简化，这需要计算一个称为逻辑起源的布尔公式。然而，PWMC 是 \\#P-hard，并且逻辑起源公式中的子句数量可能会呈指数增长，从而造成一个主要瓶颈，严重限制了 PNL 解决方案在实践中的适用性。我们提出了一种以精确算法 DPNL 为中心的新方法，该方法可以绕过逻辑起源的计算。DPNL 方法依赖于 oracle 和递归 DPLL 类分解的原理来指导和加速逻辑推理。此外，我们表明这种方法可以适用于具有 $\epsilon$ 或 $(\epsilon, \delta)$ 保证的近似推理，称为 ApproxDPNL。实验表明性能显着提升。DPNL 可以进一步扩展精确推理，从而产生更准确的模型。此外，ApproxDPNL 显示出潜力通过进一步结合近似值来提高神经符号编程的可扩展性，同时确保推理过程的保证。]]></description>
      <guid>https://arxiv.org/abs/2501.18202</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CueTip：一款可交互、可解释的物理感知台球助手</title>
      <link>https://arxiv.org/abs/2501.18291</link>
      <description><![CDATA[arXiv:2501.18291v1 公告类型：新
摘要：我们为台球/桌球变体提供了一种交互式且可解释的自动教练助手，名为 CueTip。CueTip 的新颖之处在于它结合了三个功能：自然语言界面、执行上下文、物理感知推理的能力，以及它的解释植根于领域专家开发的一组预定指南。我们安装了一个物理模拟器，以便它在传统状态跟踪的同时生成自然语言中的事件跟踪。事件跟踪适合语言模型进行解释，语言模型充当我们助手的界面。我们设计并训练了一个神经适配器，将 CueTip 做出的战术选择与其交互性和可解释性分离，从而允许它重新配置以模仿任何台球游戏代理。我们的实验表明，CueTip 能够提供基于上下文查询的帮助和解释，同时保持代理在胜率方面的实力（在某些情况下会提高）。 CueTip 生成的解释具有物理意识并且以专家规则为基础，因此更加可靠。]]></description>
      <guid>https://arxiv.org/abs/2501.18291</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩展本体化实践的设计空间：以bCLEARer为例</title>
      <link>https://arxiv.org/abs/2501.18296</link>
      <description><![CDATA[arXiv:2501.18296v1 公告类型：新
摘要：本文旨在概述本体化过程的设计空间如何比当前实践所建议的更丰富。我们指出，工程流程和产品都需要设计 - 并确定设计的一些组成部分。我们研究了设计一系列全新实践的可能性，并使用异常方法 bCLEARer 提供了我们过去三十年工作中新实践的示例。我们还建议，为本体化设置一个进化背景有助于人们更好地理解这些新实践的性质，并提供塑造富有成效的过程的概念支架。这种进化视角将数字化（计算技术的进化出现）定位为信息转换漫长进化轨迹中的最新一步。这将本体化重新定义为利用数字化提供的新兴机会的战略工具。]]></description>
      <guid>https://arxiv.org/abs/2501.18296</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无模型 RL 代理展示类似系统 1 的意向性</title>
      <link>https://arxiv.org/abs/2501.18299</link>
      <description><![CDATA[arXiv:2501.18299v1 公告类型：新
摘要：本文认为，无模型强化学习 (RL) 代理虽然缺乏明确的规划机制，但表现出的行为可以类比人类认知中的系统 1（“快速思考”）过程。与基于模型的 RL 代理不同，后者通过利用内部表示进行规划，类似于系统 2（“慢速思考”）推理，而无模型代理则对环境刺激做出反应而无需预期建模。我们提出了一个新颖的框架，将系统 1 和系统 2 的二分法与无模型和基于模型的 RL 之间的区别联系起来。这种框架挑战了普遍的假设，即意向性和有目的的行为需要规划，而是表明意向性可以体现在无模型代理的结构化、反应性行为中。通过借鉴认知心理学、法律理论和实验法学的跨学科见解，我们探讨了这种观点对归咎责任和确保人工智能安全的影响。这些见解主张对强化学习系统中的意向性进行更广泛、更具情境性的解释，并对其道德部署和监管产生影响。]]></description>
      <guid>https://arxiv.org/abs/2501.18299</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 代理对 SASP 问题进行自动优化建模：基于 Graph-RAG 的方法</title>
      <link>https://arxiv.org/abs/2501.18320</link>
      <description><![CDATA[arXiv:2501.18320v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的快速发展，自动优化建模 (AOM) 引起了人们的极大兴趣。现有方法主要依赖于提示工程，利用精心设计的专家响应链或结构化指导。然而，由于缺乏特定领域的知识，基于提示的技术在传感器阵列信号处理 (SASP) 领域表现不佳。为了解决这个问题，我们提出了一种基于检索增强生成 (RAG) 技术的自动建模方法，该方法由两个主要组件组成：多代理 (MA) 结构和基于图的 RAG (Graph-RAG) 过程。MA 结构是为架构 AOM 过程量身定制的，每个代理都是根据人类建模过程的原理设计的。Graph-RAG 过程用于将用户查询与特定的 SASP 建模知识相匹配，从而增强建模结果。十个经典信号处理问题的结果表明，所提出的方法（称为 MAG-RAG）优于多个 AOM 基准。]]></description>
      <guid>https://arxiv.org/abs/2501.18320</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedXpertQA：对专家级医学推理和理解进行基准测试</title>
      <link>https://arxiv.org/abs/2501.18362</link>
      <description><![CDATA[arXiv:2501.18362v1 公告类型：新
摘要：我们引入了 MedXpertQA，这是一个极具挑战性和综合性的基准，用于评估专家级医学知识和高级推理。MedXpertQA 包括 4,460 个问题，涵盖 17 个专业和 11 个身体系统。它包括两个子集，用于文本评估的 Text 和用于多模态评估的 MM。值得注意的是，MM 引入了具有多样化图像和丰富临床信息的专家级考试问题，包括患者记录和检查结果，使其有别于传统的医学多模态基准，这些基准仅通过从图像标题生成简单的 QA 对。MedXpertQA 应用严格的过滤和增强来解决 MedQA 等现有基准的难度不足问题，并结合专业委员会问题以提高临床相关性和全面性。我们进行数据合成以降低数据泄露风险，并进行多轮专家评审以确保准确性和可靠性。我们在 MedXpertQA 上评估了 16 种领先模型。此外，医学与现实世界的决策密切相关，为评估数学和代码以外的推理能力提供了丰富且具有代表性的环境。为此，我们开发了一个以推理为导向的子集，以促进对 o1 类模型的评估。]]></description>
      <guid>https://arxiv.org/abs/2501.18362</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Gravity-Bench-v1：代理引力物理发现基准</title>
      <link>https://arxiv.org/abs/2501.18411</link>
      <description><![CDATA[arXiv:2501.18411v1 公告类型：新
摘要：现代科学源于对反复观察的行星运动的推理。我们提出了 Gravity-Bench-v1，这是一个基于环境的基准，它挑战 AI 代理在与这一历史发展并行的任务上的表现。Gravity-Bench-v1 使用严格的重力动力学模拟来评估代理在动态环境中发现隐藏的物理学的能力。Gravity-Bench 包括分布外的情况，即偏离现实世界的物理学，以评估真正的科学泛化能力。代理必须计划在实验预算内收集数据，并且必须执行动态形式的数据分析和推理才能有效地解决任务。我们的基准测试允许开放的解决方案空间。每个任务都提供了博士级解决方案，以根据人类专业知识校准 AI 性能。从技术上讲，在本科高年级水平上，我们的基准测试对基线 AI 代理具有挑战性。 Gravity-Bench-v1 和计划中的扩展应该有助于规划 AI 在科学发现能力方面的进展。]]></description>
      <guid>https://arxiv.org/abs/2501.18411</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GBFRS：通过粒球计算实现的稳健模糊粗糙集</title>
      <link>https://arxiv.org/abs/2501.18413</link>
      <description><![CDATA[arXiv:2501.18413v1 Announce Type: new 
摘要：模糊粗糙集理论是一种处理复杂属性数据集的有效方法，具有坚实的数学基础，与机器学习中的核方法紧密相关。基于模糊粗糙集理论的属性约简算法和分类器在高维多元复杂数据的分析中表现出良好的性能。然而，现有的大多数模型都以最细的粒度运行，效率低下且对噪声敏感，尤其是对于高维大数据。因此，增强模糊粗糙集模型的鲁棒性对于有效的特征选择至关重要。多粒度粒球计算是近年来发展起来的，它使用不同大小的粒球自适应地表示和覆盖样本空间，并基于这些粒球进行学习。本文提出将多粒度粒球计算融入模糊粗糙集理论，用粒球代替样本点。颗粒球的粗粒度特性使得模型更加鲁棒。此外，我们提出了一种新的颗粒球生成方法，可扩展到基于颗粒球计算的整个监督方法。采用前向搜索算法通过依赖函数定义特征与类别之间的相关性来选择特征序列。实验证明了所提模型的有效性和优于基准方法。]]></description>
      <guid>https://arxiv.org/abs/2501.18413</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>