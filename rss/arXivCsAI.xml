<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 15 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>FGeo-DRL：通过深度强化学习对几何问题进行演绎推理</title>
      <link>https://arxiv.org/abs/2402.09051</link>
      <description><![CDATA[arXiv:2402.09051v1 公告类型：新
摘要： 类人自动演绎推理一直是数学与人工智能交叉学科中最具挑战性的开放问题之一。本文是我们系列作品中的第三篇。我们构建了一个名为 FGeoDRL 的神经符号系统，可以自动执行类似人类的几何演绎推理。神经部分是基于强化学习的人工智能代理，能够从形式化环境的反馈中自主学习解决问题的方法，而不需要人类监督。它利用预先训练的自然语言模型来建立用于定理选择的策略网络，并采用蒙特卡洛树搜索进行启发式探索。符号部分是基于几何形式化理论和 FormalGeo\cite{FormalGeo} 的强化学习环境，它将 GPS 建模为马尔可夫决策过程\cite{MDP}。在这个形式符号系统中，问题的已知条件和目标形成状态空间，而定理集形成动作空间。利用 FGeoDRL，我们已经实现了几何问题的可读且可验证的自动化解决方案。在formalgeo7k数据集上进行的实验取得了86.40\%的问题解决成功率。该项目位于 https://github.com/PersonNoName/FGeoDRL。]]></description>
      <guid>https://arxiv.org/abs/2402.09051</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>L3GO：具有 3D 思想链的语言代理，用于生成非常规对象</title>
      <link>https://arxiv.org/abs/2402.09052</link>
      <description><![CDATA[arXiv:2402.09052v1 公告类型：新
摘要：基于扩散的图像生成模型（例如 DALL-E 3 和 Stable Diffusion-XL）在生成具有真实且独特构图的图像方面表现出了卓越的能力。然而，这些模型在精确推理物体的物理和空间配置方面并不稳健，特别是当接受非常规的、不符合分布的描述时，例如“一把五条腿的椅子”。在本文中，我们提出了一种具有 3D 思想链 (L3GO) 的语言代理，这是一种推理时间方法，可以推理当前数据驱动扩散模型难以解决的非常规对象的基于部分的 3D 网格生成。更具体地说，我们使用大型语言模型作为代理，在 3D 模拟环境中通过反复试验来组成所需的对象。为了便于我们的调查，我们开发了一个新的基准，非常规可行对象 (UFO)，以及 SimpleBlenv，这是一个构建在 Blender 之上的包装器环境，语言代理可以在其中通过 API 调用构建和组合原子构建块。人工和自动 GPT-4V 评估表明，我们的方法超越了标准 GPT-4 和其他语言代理（例如 ReAct 和 Reflexion），用于在 ShapeNet 上生成 3D 网格。此外，在我们的 UFO 基准测试中，我们的方法优于其他基于人类评估的最先进的文本到 2D 图像和文本到 3D 模型。]]></description>
      <guid>https://arxiv.org/abs/2402.09052</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>FGeo-TP：语言模型增强的几何问题求解器</title>
      <link>https://arxiv.org/abs/2402.09047</link>
      <description><![CDATA[arXiv:2402.09047v1 公告类型：新
摘要： 应用当代人工智能技术解决几何问题和自动演绎证明一直是数学与人工智能交叉学科领域面临的巨大挑战。这是我们系列工作中的第四篇文章，在我们之前的工作中，我们建立了一个称为 FormalGeo 的几何形式化系统。此外，我们注释了大约 7000 个几何问题，形成了 FormalGeo7k 数据集。尽管FGPS（形式几何问题求解器）可以实现可解释的代数方程求解和类似人类的演绎推理，但由于搜索策略的复杂性，它经常遇到超时。在本文中，我们介绍了FGeo-TP（定理预测器），它利用语言模型来预测解决几何问题的定理序列。我们比较了各种 Transformer 架构（例如 BART 或 T5）在定理预测中的有效性，在 FGPS 的搜索过程中实现剪枝，从而提高其解决几何问题的性能。我们的结果表明，语言模型增强的 FGeo-TP 在 FormalGeo7k 数据集上的问题解决率显着提高，从 39.7% 上升到 80.86%。此外，FGeo-TP 显着减少了不同难度级别问题的解决时间和搜索步骤。]]></description>
      <guid>https://arxiv.org/abs/2402.09047</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>GroundDial：人类规范接地安全对话响应生成</title>
      <link>https://arxiv.org/abs/2402.08968</link>
      <description><![CDATA[arXiv:2402.08968v1 公告类型：新
摘要：众所周知，当前基于大语言模型（LLM）的对话人工智能系统会生成不安全的响应，同意攻击性的用户输入或包含有毒内容。之前的研究旨在通过手动注释的安全对话历史微调 LLM 来减轻毒性。然而，对额外调整的依赖需要大量成本。为了消除这种依赖性，我们提出了 GrounDial，其中响应安全是通过将响应基于常识性社会规则来实现的，而不需要进行微调。 GrounDial 的情境学习和人类规范引导解码的混合方法使响应在定量和定性上更加安全，即使无需额外的数据或调整。]]></description>
      <guid>https://arxiv.org/abs/2402.08968</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>抽象推理对推理和学习的统一描述</title>
      <link>https://arxiv.org/abs/2402.09046</link>
      <description><![CDATA[arXiv:2402.09046v1 公告类型：新
摘要：受神经科学中脑功能贝叶斯方法的启发，我们给出了一种简单的概率推理理论，用于统一解释推理和学习。我们简单地根据数据在形式逻辑中的可满足性来模拟数据如何产生符号知识。其基本思想是，推理是通过抽象（即选择性无知）从数据中导出符号知识的过程。讨论了逻辑结果关系的基于证明的理论正确性。讨论了 MNIST 数据集基于实验的经验正确性。]]></description>
      <guid>https://arxiv.org/abs/2402.09046</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>芥末：掌握定理和证明数据的统一综合</title>
      <link>https://arxiv.org/abs/2402.08957</link>
      <description><![CDATA[arXiv:2402.08957v1 公告类型：新
摘要：最近的大型语言模型（LLM）在各种任务上取得了显着的进步，包括数学推理和定理证明。由于这两项任务需要严格且正式的多步骤推理，因此它们是探索法学硕士推理能力的有吸引力的领域，但仍然面临着重要的挑战。先前的研究，例如思想链（CoT），已经揭示了中间步骤指导的有效性。然而，这种逐步注释需要大量的劳动，导致当前基准的训练步骤不足。为了填补这一空白，这项工作引入了 MUSTARD，一种数据生成框架，它掌握了高质量和多样性的定理和证明数据的统一合成。 MUSTARD 分三个阶段合成数据：（1）它采样一些数学概念种子作为问题类别。 (2)然后，它利用采样的概念生成生成语言模型，以获得问题及其逐步的形式化解决方案。 (3)最后，框架利用证明助手（例如Lean Prover）来过滤有效证明。通过提出的 MUSTARD，我们提出了一个具有 5,866 个有效数据点的定理和证明基准 MUSTARDSAUCE。每个数据点都包含一个非正式的陈述、一个非正式的证明和一个通过证明者验证的翻译后的正式证明。我们进行广泛的分析并证明 MUSTARD 生成经过验证的高质量分步数据。我们进一步应用 MUSTARDSAUCE 来微调较小的语言模型。经过微调的 Llama 2-7B 在自动定理证明中实现了 15.41% 的平均相对性能增益，在数学应用题中实现了 8.18% 的平均相对性能增益。代码和数据可在 https://github.com/Eleanor-H/MUSTARD 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.08957</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>HyCubE：高效知识超图 3D 圆形卷积嵌入</title>
      <link>https://arxiv.org/abs/2402.08961</link>
      <description><![CDATA[arXiv:2402.08961v1 公告类型：新
摘要：现有的知识超图嵌入方法主要侧重于提高模型性能，但其模型结构变得更加复杂和冗余。此外，由于固有的复杂语义知识，知识超图嵌入模型的计算往往非常昂贵，导致效率低下。在本文中，我们提出了一种特征交互和提取增强的3D循环卷积嵌入模型HyCubE，该模型设计了一种新颖的3D循环卷积神经网络并引入了交替掩码堆栈策略来实现高效的n元知识超图嵌入。 HyCubE通过自适应调整3D循环卷积核大小并统一嵌入实体位置信息，以更少的参数提高了模型性能，在模型性能和效率之间达到了更好的平衡。此外，我们使用基于实体掩码机制的1-N多线性评分来进一步加速模型训练效率。最后，所有数据集上的大量实验结果表明，HyCubE 始终优于最先进的基线，所有指标的平均改进为 4.08%-10.77%，最大改进为 21.16%。值得称赞的是，与最新的最先进基准相比，HyCubE 的速度平均提高了 7.55 倍，内存使用量平均减少了 77.02%。]]></description>
      <guid>https://arxiv.org/abs/2402.08961</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型推理中的前提顺序很重要</title>
      <link>https://arxiv.org/abs/2402.08939</link>
      <description><![CDATA[arXiv:2402.08939v1 公告类型：新
摘要：大型语言模型（LLM）在各个领域都取得了显着的推理性能。然而，在推理任务领域，我们发现了一个弱点：法学硕士对于前提的排序非常脆弱，尽管事实上这种排序不会改变底层任务。特别是，我们观察到，当前提顺序与中间推理步骤所需的上下文一致时，法学硕士可以获得最佳性能。例如，在演绎推理任务中，以与提示中的真实事实证明相同的顺序呈现前提（而不是随机排序）可以大大提高模型的准确性。我们首先检查了各种 LLM 中前提顺序对演绎推理的影响，我们的评估表明，置换前提顺序可能会导致性能下降超过 30%。此外，我们发布了基于 GSM8K 的基准 R-GSM，以检查数学问题解决的排序效应，我们再次观察到相对于原始 GSM8K 基准，精度显着下降。]]></description>
      <guid>https://arxiv.org/abs/2402.08939</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用反事实任务评估大型语言模型中类比推理的通用性</title>
      <link>https://arxiv.org/abs/2402.08955</link>
      <description><![CDATA[arXiv:2402.08955v1 公告类型：新
摘要：大型语言模型（LLM）在多个推理基准上表现良好，包括测试类比推理能力的基准。然而，人们一直在争论它们是否实际上是在执行类似人类的抽象推理，还是采用依赖于与训练数据中所见相似性的不太通用的过程。在这里，我们研究了之前声称的法学硕士的类比能力的普遍性（Webb、Holyoak 和 Lu，2023）。我们采用一组类比问题来评估 LLM，并创建一组“反事实”变体版本，用于测试相同的抽象推理能力，但可能与任何预训练数据不同。我们在原始问题和反事实问题上测试了人类和三个 GPT 模型，结果表明，虽然人类在所有问题上的表现仍然很高，但 GPT 模型在反事实集上的表现却急剧下降。这项工作提供的证据表明，尽管之前报道过法学硕士在类比推理方面取得了成功，但这些模型缺乏人类类比的稳健性和普遍性。]]></description>
      <guid>https://arxiv.org/abs/2402.08955</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>ScamSpot：打击 Instagram 评论中的金融欺诈</title>
      <link>https://arxiv.org/abs/2402.08869</link>
      <description><![CDATA[arXiv:2402.08869v1 公告类型：新
摘要：金融领域 Instagram 页面评论部分长期存在的垃圾邮件和欺诈信息问题每天都会有新的受害者。 Instagram 目前的垃圾邮件过滤器被证明是不够的，现有的研究方法主要局限于理论概念。缺少评估结果的实际实施。为了解决这个问题，我们提出了 ScamSpot，这是一个综合系统，包括浏览器扩展、微调的 BERT 模型和 REST API。这种方法确保使用 Chrome 浏览器的 Instagram 用户可以公开访问我们的结果。此外，我们进行了数据注释研究，阐明问题的原因和原因，并通过用户反馈和与现有模型的比较来评估系统。 ScamSpot 是一个开源项目，可在 https://scamspot.github.io/ 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2402.08869</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>结合多个大型语言模型的见解可提高诊断准确性</title>
      <link>https://arxiv.org/abs/2402.08806</link>
      <description><![CDATA[arXiv:2402.08806v1 公告类型：新
摘要：背景：诸如 OpenAI 的 GPT-4 或 Google 的 PaLM 2 等大型语言模型 (LLM) 被提议作为可行的诊断支持工具，甚至被认为是“路边咨询”的替代品。然而，即使是受过医学主题专门培训的法学硕士也可能缺乏现实生活应用的足够诊断准确性。
  方法：使用集体智慧方法和 200 个现实案例的临床片段数据集，我们评估并比较了通过询问各个商业法学硕士（OpenAI GPT-4、Google PaLM 2、Cohere Command、Meta Llama 2）获得的鉴别诊断的准确性）与通过聚合相同法学硕士组合的反应而合成的鉴别诊断的准确性进行比较。
  结果：我们发现，与单个法学硕士产生的鉴别诊断（单个法学硕士的平均准确度： $59.0\%\pm 6.1pp$)。
  讨论：使用集体智慧方法结合不同法学硕士的反应来综合鉴别诊断，实现了推进法学硕士作为诊断支持工具的接受的两个必要步骤：（1）展示高诊断准确性和（2）消除对法学硕士的依赖。单一商业供应商。]]></description>
      <guid>https://arxiv.org/abs/2402.08806</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>具有图卷积推荐功能的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.08859</link>
      <description><![CDATA[arXiv:2402.08859v1 公告类型：新
摘要：近年来，人们努力使用文本信息来更好地进行用户分析和推荐中的项目表征。然而，文本信息有时质量较低，阻碍了其在实际应用中的有效性。凭借大型语言模型 (LLM) 中包含的知识和推理能力，利用 LLM 成为改进描述​​的一种有前景的方法。然而，现有的用原始文本提示法学硕士的方法忽略了用户-项目交互的结构化知识，这可能会导致描述生成不一致等幻觉问题。为此，我们提出了一种图感知卷积 LLM 方法来引发 LLM 捕获用户-项目图中的高阶关系。为了使基于文本的法学硕士与结构化图相适应，我们使用法学硕士作为图处理中的聚合器，使其能够逐步理解基于图的信息。具体来说，LLM需要通过逐层探索多跳邻居来增强描述，从而在图中逐步传播信息。为了使 LLM 能够捕获大规模图形信息，我们将描述任务分解为更小的部分，这大大减少了每个步骤的标记输入的上下文长度。对三个现实世界数据集的广泛实验表明，我们的方法始终优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.08859</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>使用具有优先级和时间约束的基于冲突的搜索来优化任务分配和路径规划</title>
      <link>https://arxiv.org/abs/2402.08772</link>
      <description><![CDATA[arXiv:2402.08772v1 公告类型：新
摘要：多智能体路径查找（MAPF）问题需要为一组智能体找到无碰撞路径，引导它们从起始位置到目标位置。然而，MAPF 没有考虑一些与实际任务相关的约束。例如，代理可能需要在特定执行时间的目标位置执行操作，遵守预定的顺序和时间范围。此外，可能没有为代理预定义目标分配，并且优化目标可能缺乏明确的定义。为了将任务分配、路径规划和用户定义的目标合并到一个连贯的框架中，本文研究了具有优先级和时间约束的任务分配和路径查找 (TAPF-PTC) 问题。我们增强了基于冲突的搜索（CBS），以同时生成遵守优先级和时间约束的任务分配和无碰撞路径，从而最大化强化学习（RL）中用户定义的奖励函数的回报所量化的目标。通过实验，我们证明了我们的算法 CBS-TA-PTC 相对于 MARL 和适应的目标分配和路径查找 (TAPF) 方法，可以有效地解决具有优先级和时间约束的高度挑战性的炸弹拆除任务。]]></description>
      <guid>https://arxiv.org/abs/2402.08772</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>2D 自动驾驶汽车的增强型深度 Q 学习：在自定义赛道环境上的实施和评估</title>
      <link>https://arxiv.org/abs/2402.08780</link>
      <description><![CDATA[arXiv:2402.08780v1 公告类型：新
摘要：该研究项目介绍了在二维 (2D) 自定义赛道上自动驾驶汽车的深度 Q 学习网络 (DQN) 的实现，目的是提高 DQN 网络的性能。它包括在孟菲斯大学地图周围的赛道上使用 Pygame 开发自定义驾驶环境，以及 DQN 模型的设计和实现。该算法利用安装在汽车上的 7 个传感器的数据，这些传感器测量汽车与轨道之间的距离。这些传感器位于车辆前方，间隔 20 度，使它们能够感知前方的广阔区域。我们成功实现了 DQN 以及具有基于优先级的动作选择机制的 DQN 的修改版本，我们将其称为修改的 DQN。该模型经过 1000 多次训练，发现智能体收到的平均奖励约为 40，比原始 DQN 高出约 60%，比普通神经网络高出约 50%。]]></description>
      <guid>https://arxiv.org/abs/2402.08780</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士驱动的亚理性行为模仿：幻觉还是现实？</title>
      <link>https://arxiv.org/abs/2402.08755</link>
      <description><![CDATA[arXiv:2402.08755v1 公告类型：新
摘要：由于难以校准强化学习模型或收集涉及人类受试者的数据，对人类或经济家庭等亚理性主体进行建模本质上具有挑战性。现有的工作强调了大型语言模型（LLM）解决复杂推理任务和模仿人类交流的能力，而使用 LLM 作为代理的模拟显示了新兴的社会行为，有可能提高我们对人类行为的理解。在本文中，我们建议研究使用 LLM 来生成合成人类演示，然后用于通过模仿学习来学习亚理性代理策略。我们假设法学硕士可以用作人类的隐式计算模型，并提出一个框架，使用从法学硕士衍生的综合演示来模拟人类特征的亚理性行为（例如，近视行为或风险规避偏好）。我们通过四个简单的场景（包括经过充分研究的最后通牒游戏和棉花糖实验）来实验评估我们的框架模拟次理性的能力。为了获得对我们的框架的信心，我们能够复制先前与上述场景相关的人类研究中已得到证实的发现。最后，我们讨论了我们框架的潜在好处、挑战和局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.08755</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    </channel>
</rss>