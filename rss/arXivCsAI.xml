<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 17 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>知识图谱上的神经符号推理：从查询角度进行的综述</title>
      <link>https://arxiv.org/abs/2412.10390</link>
      <description><![CDATA[arXiv:2412.10390v1 公告类型：新
摘要：知识图谱推理在数据挖掘、人工智能、网络和社会科学等各个领域都至关重要。这些知识图谱充当人类知识的综合存储库，有助于推断新信息。传统的符号推理尽管有其优势，但仍难以应对这些图中不完整和嘈杂的数据所带来的挑战。相比之下，神经符号人工智能的兴起标志着一项重大进步，将深度学习的稳健性与符号推理的精确性相结合。这种整合旨在开发不仅具有高度可解释性和可解释性而且用途广泛的人工智能系统，有效地弥合符号和神经方法之间的差距。此外，大型语言模型 (LLM) 的出现开辟了知识图谱推理的新领域，使以前所未有的方式提取和综合知识成为可能。本调查对知识图谱推理进行了全面回顾，重点关注各种查询类型和神经符号推理的分类。此外，它还探讨了知识图谱推理与大型语言模型的创新集成，突出了突破性进步的潜力。这份全面的概述旨在通过详细了解知识图谱推理的当前状况和未来方向，为数据挖掘、人工智能、网络和社会科学等多个领域的研究人员和从业者提供支持。]]></description>
      <guid>https://arxiv.org/abs/2412.10390</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TANGO：无需训练的具身化 AI 代理，用于执行开放世界任务</title>
      <link>https://arxiv.org/abs/2412.10402</link>
      <description><![CDATA[arXiv:2412.10402v1 公告类型：新
摘要：大型语言模型 (LLM) 已展示出将各种模块组合在一起以创建可对图像执行复杂推理任务的程序的出色能力。在本文中，我们提出了 TANGO，这是一种通过已在图像中观察到的 LLM 扩展程序组合的方法，旨在将这些功能集成到能够观察和行动的具身代理中。具体来说，通过采用简单的 PointGoal 导航模型结合基于记忆的探索策略作为引导代理穿越世界的基础原语，我们展示了单个模型如何在没有额外训练的情况下解决各种任务。我们要求 LLM 组合提供的原语来解决特定任务，仅使用提示中的几个上下文示例。我们在三个关键的具身人工智能任务上评估了我们的方法：开放集对象目标导航、多模态终身导航和开放具身问答，在具有挑战性的零样本场景中无需任何特定的微调即可实现最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2412.10402</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GROOT-2：弱监督多模态指令跟随代理</title>
      <link>https://arxiv.org/abs/2412.10410</link>
      <description><![CDATA[arXiv:2412.10410v1 公告类型：新
摘要：开发能够遵循多模态指令的代理仍然是机器人技术和人工智能领域的一项基本挑战。尽管对未标记数据集（无语言指令）进行大规模预训练使代理能够学习各种行为，但这些代理在遵循指令方面往往遇到困难。虽然使用指令标签扩充数据集可以缓解此问题，但大规模获取如此高质量的注释是不切实际的。为了解决这个问题，我们将问题定义为半监督学习任务，并引入 GROOT-2，这是一种多模态可指导代理，使用一种将弱监督与潜在变量模型相结合的新方法进行训练。我们的方法由两个关键部分组成：受限的自我模仿，它利用大量未标记的演示使策略能够学习不同的行为，以及人类意图对齐，它使用一组较小的标记演示来确保潜在空间反映人类意图。 GROOT-2 的有效性在四种不同的环境中得到验证，从视频游戏到机器人操作，证明了其强大的多模式指令遵循能力。]]></description>
      <guid>https://arxiv.org/abs/2412.10410</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>游戏动作中的隐写术</title>
      <link>https://arxiv.org/abs/2412.10442</link>
      <description><![CDATA[arXiv:2412.10442v1 公告类型：新
摘要：潜意识交流问题已在各种形式的隐写术中得到解决，主要依赖于视觉、听觉和语言媒体。然而，该领域面临着一个根本性的悖论：随着隐藏艺术的进步，启示科学也在进步，从而导致持续的进化相互作用。这项研究旨在扩展被认为是可行的隐写媒介的边界。我们探索了一种隐写范式，其中隐藏的信息通过多个代理与环境交互的事件进行传达。每个代理都充当编码器，学习一种策略来掩盖隐藏信息的存在，而这些隐藏信息似乎针对的是无辜的目标。同时，观察者充当解码器，学习将行为模式与各自的代理联系起来，尽管它们具有动态性质，从而揭示隐藏的信息。代理之间的交互受多代理强化学习框架的支配，并由观察者的反馈塑造。这个框架概括了一个博弈论困境，其中代理面临着选择合作以创建可区分的行为模式还是背叛以追求个体最优但可能重叠的偶发性行动之间的决定。作为概念证明，我们通过迷宫游戏举例说明了动作隐写术，迷宫游戏是一项导航任务，其中潜意识交流隐藏在驶向目的地的动作中。该隐写系统已通过实验评估得到系统验证，评估了其失真和容量以及在面对模拟被动和主动对手时的保密性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.10442</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在因果学习中是否存在偏见？</title>
      <link>https://arxiv.org/abs/2412.10509</link>
      <description><![CDATA[arXiv:2412.10509v1 公告类型：新
摘要：因果学习是一种认知过程，即根据可用信息发展做出因果推理的能力，通常由规范原则指导。这个过程容易出现错误和偏见，例如因果错觉，即人们认为两个变量之间存在因果关系，尽管缺乏支持证据。这种认知偏见被认为是许多社会问题的根源，包括社会偏见、刻板印象形成、错误信息和迷信思想。在这项研究中，我们调查大型语言模型 (LLM) 是否会产生因果错觉，无论是在现实世界中还是在受控的实验室环境中进行因果学习和推理。为此，我们建立了一个超过 2K 个样本的数据集，其中包括纯相关情况、零偶然性情况以及时间信息通过将潜在影响置于原因之前来排除因果关系可能性的情况。然后，我们提示模型做出陈述或回答因果问题，以评估它们在这些结构化环境中错误推断因果关系的倾向。我们的研究结果表明，法学硕士中存在强烈的因果错觉偏见。具体来说，在涉及虚假相关性的开放式生成任务中，模型表现出的偏见水平与对人类受试者的类似研究中观察到的偏见水平相当，甚至更低。然而，当面对零偶然性情景或否定因果关系的时间线索时，需要以 0-100 的量表做出反应，模型表现出明显更高的偏见。这些发现表明，模型并没有统一、一致或可靠地内化准确因果学习所必需的规范原则。]]></description>
      <guid>https://arxiv.org/abs/2412.10509</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从黑盒二元分类器中提取 PAC 决策树：基于 BERT 的语言模型上的性别偏见研究案例</title>
      <link>https://arxiv.org/abs/2412.10513</link>
      <description><![CDATA[arXiv:2412.10513v1 公告类型：新
摘要：决策树是一种流行的机器学习方法，以其固有的可解释性而闻名。在可解释的人工智能中，决策树可以用作复杂黑盒人工智能模型的替代模型，也可以用作此类模型的部分近似值。这种方法的一个关键挑战是确定提取的决策树对原始模型的准确度，以及在多大程度上可以将其作为其行为的近似值。在这项工作中，我们研究了使用可能近似正确 (PAC) 框架为从人工智能模型中提取的决策树提供保真度的理论保证。基于 PAC 框架的理论结果，我们调整了决策树算法以确保在某些条件下的 PAC 保证。我们专注于二元分类并进行实验，从基于 BERT 的语言模型中提取具有 PAC 保证的决策树。我们的结果表明这些模型存在职业性别偏见。]]></description>
      <guid>https://arxiv.org/abs/2412.10513</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://arxiv.org/abs/2412.10673</link>
      <description><![CDATA[arXiv:2412.10673v1 公告类型：新
摘要：数学奥林匹克是一项享有盛誉的竞赛，提出和解决问题的能力备受推崇。构建提出和解决奥林匹克问题的人工智能对自动定理发现和证明提出了一个尚未解决的挑战，尤其是在几何学中，因为它结合了数值和空间元素。我们介绍了 TongGeometry，这是一个支持基于树搜索的引导式问题提出和解决的欧几里得几何系统。这个高效的几何系统建立了迄今为止最广泛的几何定理库：在与现有技术相同的计算预算内，TongGeometry 发现了 67 亿条需要辅助构造的几何定理，其中 41 亿条表现出几何对称性。其中，10 个定理被提交给地区数学奥林匹克竞赛，TongGeometry 的 3 个提案在实际竞赛中入选，获得了国家队资格考试或中国和美国顶级民间奥林匹克竞赛的参赛资格。在经过微调的大型语言模型的指导下，TongGeometry 解决了 IMO-AG-30 的所有国际数学奥林匹克几何问题，首次超越金牌获得者。它还在更广泛的奥林匹克级问题上超越了现有的最先进水平。该系统的全部功能可以在消费级机器上使用，使模型更容易获得并促进其使用的广泛民主化。打个比方，与仅仅像学生一样解决问题的现有系统不同，TongGeometry 就像一个几何教练，发现、提出和证明定理。]]></description>
      <guid>https://arxiv.org/abs/2412.10673</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AuctionNet：大型游戏决策的新基准</title>
      <link>https://arxiv.org/abs/2412.10798</link>
      <description><![CDATA[arXiv:2412.10798v1 公告类型：新 
摘要：大型游戏中的决策是人工智能 (AI) 中的一个重要研究领域，对现实世界具有重大影响。然而，对现实大型游戏环境的有限访问阻碍了该领域的研究进展。在本文中，我们提出了 \textbf{AuctionNet}，这是源自现实世界在线广告平台的大型广告拍卖出价决策的基准。AuctionNet 由三部分组成：广告拍卖环境、基于环境的预生成数据集以及几种基线出价决策算法的性能评估。更具体地说，该环境通过多个模块的交互有效地复制了现实世界广告拍卖的完整性和复杂性：广告机会生成模块采用深度生成模型来弥合模拟数据和现实世界数据之间的差距，同时降低敏感数据泄露的风险；竞价模块实现了使用不同决策算法训练的各种自动竞价代理；拍卖模块以经典的广义第二价格 (GSP) 拍卖为基础，但也允许根据需要定制拍卖机制。为了方便研究并提供对游戏环境的洞察，我们还根据环境预先生成了一个相当大的数据集。该数据集包含 48 个不同代理相互竞争的轨迹，总计超过 5 亿条记录，占用 80GB 的存储空间。作为 AuctionNet 的一部分，还介绍了线性规划、强化学习和出价决策生成模型等基线算法的性能评估。我们注意到 AuctionNet 不仅适用于广告拍卖中的出价决策算法研究，也适用于大型游戏中的一般决策领域。]]></description>
      <guid>https://arxiv.org/abs/2412.10798</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在医生的推理任务中表现出超人的表现</title>
      <link>https://arxiv.org/abs/2412.10849</link>
      <description><![CDATA[arXiv:2412.10849v1 公告类型：新
摘要：大型语言模型 (LLM) 在医疗任务上的表现传统上是使用多项选择题基准来评估的。然而，这样的基准受到高度限制，充斥着 LLM 的反复令人印象深刻的表现，并且与实际临床场景中的表现关系不明确。临床推理是医生运用批判性思维收集和综合临床数据以诊断和管理医疗问题的过程，仍然是模型性能的一个有吸引力的基准。先前的 LLM 在常规和复杂的诊断场景中表现出超越临床医生的潜力。我们试图评估 OpenAI 的 o1-preview 模型，该模型旨在通过生成响应之前的思维链过程来增加运行时间。我们通过五个实验来描述 o1-preview 的性能，包括鉴别诊断生成、诊断推理显示、分类鉴别诊断、概率推理和管理推理，由经过验证的心理测量的医生专家进行裁决。我们的主要结果是将 o1-preview 的输出与具有历史人类控制和先前 LLM 基准的相同先前实验进行比较。在鉴别诊断生成和诊断和管理推理的质量方面观察到了显著的改善。在概率推理或分类鉴别诊断方面没有观察到任何改善。这项研究强调了 o1-preview 在需要复杂批判性思维的任务（例如诊断和管理）上表现出色，而其在概率推理任务上的表现与过去的模型相似。需要新的稳健基准和与人类医生相比的 LLM 能力的可扩展评估，以及在真实临床环境中评估 AI 的试验。]]></description>
      <guid>https://arxiv.org/abs/2412.10849</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>递归聚合作为答案集编程中的内涵函数：语义和强等价性</title>
      <link>https://arxiv.org/abs/2412.10975</link>
      <description><![CDATA[arXiv:2412.10975v1 公告类型：新
摘要：本文表明，由求解器 clingo 和 dlv 实现的带有聚合的程序的语义可以表征为 Here-and-There 逻辑中具有内涵函数的扩展一阶公式。此外，这种表征可用于研究任一语义下带有聚合的程序的强等价性。我们还提出了一种转换，将检查强等价性的任务简化为经典一阶逻辑中的推理，这为自动化此过程奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2412.10975</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedG-KRP：医学图谱知识表示探索</title>
      <link>https://arxiv.org/abs/2412.10982</link>
      <description><![CDATA[arXiv:2412.10982v2 公告类型：新
摘要：大型语言模型 (LLM) 最近成为强大的工具，并在许多医学领域得到应用。LLM 能够从许多来源整合大量信息以生成响应（类似于人类专家的过程），这使得许多人看到了将 LLM 部署用于临床的潜力。然而，医学是一个准确推理至关重要的领域。许多研究人员质疑经常用于测试 LLM 的多项选择题回答 (MCQA) 基准的有效性。研究人员和临床医生都必须对 LLM 的能力充满信心，才能将它们部署到医疗环境中。为了满足这种理解需求，我们引入了一种基于知识图 (KG) 的方法来评估 LLM 的生物医学推理能力。本质上，我们绘制了 LLM 如何链接医学概念，以便更好地理解它们的推理方式。我们测试了 GPT-4、Llama3-70b 和 PalmyraMed-70b（一种专门的医学模型）。我们邀请了一组医学生来审查总共 60 个 LLM 生成的图表，并将这些图表与大型生物医学知识图谱 BIOS 进行比较。我们观察到 GPT-4 在人工审查中表现最佳，但在基本事实比较中表现最差；医学模型 PalmyraMed 则相反。我们的工作提供了一种可视化 LLM 医学推理路径的方法，以便可以安全有效地在临床环境中实施它们。]]></description>
      <guid>https://arxiv.org/abs/2412.10982</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型概率推理中的双重特征</title>
      <link>https://arxiv.org/abs/2412.11009</link>
      <description><![CDATA[arXiv:2412.11009v1 公告类型：新
摘要：我们进行了三项实验来研究大型语言模型 (LLM) 如何评估后验概率。我们的研究结果揭示了在最先进的模型中后验判断中两种模式的共存：一种遵循贝叶斯规则的规范模式，以及一种依赖于相似性的基于代表性的模式——与人类的系统 1 和系统 2 思维相似。此外，我们观察到 LLM 很难从记忆中回忆起基准率信息，而制定及时的工程策略来减轻基于代表性的判断可能具有挑战性。我们进一步推测，双重判断模式可能是强化学习中采用对比损失函数的结果，这些损失函数来自人类反馈。我们的研究结果强调了减少 LLM 中认知偏差的潜在方向以及在关键领域谨慎部署 LLM 的必要性。]]></description>
      <guid>https://arxiv.org/abs/2412.11009</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法律：托管和基金服务合同的法律代理工作流程</title>
      <link>https://arxiv.org/abs/2412.11063</link>
      <description><![CDATA[arXiv:2412.11063v1 公告类型：新
摘要：托管和基金服务领域的法律合同管理着关键方面，例如关键提供商责任、费用表和赔偿权利。然而，由于冗长的非结构化文本流、有限的 LLM 上下文窗口和复杂的法律术语，现成的大型语言模型 (LLM) 很难吸收这些合同。为了应对这些挑战，我们引入了 LAW（托管和基金服务合同的法律代理工作流程）。LAW 采用模块化设计，通过协调一套特定于领域的工具和文本代理来响应用户查询。我们的实验表明，通过集成多个专门的代理和工具，LAW 的表现明显优于基线。LAW 在计算合同终止日期等复杂任务方面尤其出色，超过基线 92.9%。此外，LAW 通过利用可重复使用的、特定领域的工具，为传统的精细法律 LLM 提供了一种经济高效的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.11063</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>既见森林又见树木：使用大型多模态模型解决基于可视图形和树的数据结构问题</title>
      <link>https://arxiv.org/abs/2412.11088</link>
      <description><![CDATA[arXiv:2412.11088v1 公告类型：新
摘要：生成式人工智能系统的最新进展引起了教育工作者对学术诚信的担忧。除了擅长解决编程问题和基于文本的多项选择题之外，最近的研究还发现，大型多模态模型 (LMM) 可以仅基于图像解决帕森斯问题。然而，这类问题本质上仍然是基于文本的，依赖于模型将代码块的图像转换为其对应文本的能力。在本文中，我们进一步研究了 LMM 仅基于图像解决图形和树数据结构问题的能力。为了实现这一点，我们通过计算构建和评估一个新的基准数据集，该数据集包含 9,072 个不同的图形和树数据结构任务样本，以评估 GPT-4o、GPT-4v、Gemini 1.5 Pro、Gemini 1.5 Flash、Gemini 1.0 Pro Vision 和 Claude 3 模型系列的性能。 GPT-4o 和 Gemini 1.5 Flash 分别在树和图上表现最佳。GPT-4o 在树样本上的准确率达到 87.6%，而 Gemini 1.5 Flash 在图样本上的准确率达到 56.2%。我们的研究结果强调了结构和视觉变化对模型性能的影响。这项研究不仅引入了 LMM 基准以促进复制和进一步探索，而且还强调了 LMM 在解决复杂计算问题方面的潜力，对教学和评估实践具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2412.11088</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型打造活跃商人非玩家角色</title>
      <link>https://arxiv.org/abs/2412.11189</link>
      <description><![CDATA[arXiv:2412.11189v1 公告类型：新
摘要：我们强调了导致当前商人非玩家角色 (NPC) 被动的两个重要问题：定价和沟通。虽然沉浸式互动一直是焦点，但商人 NPC 和玩家之间就商品价格进行的谈判尚未得到足够的重视。首先，我们将被动定价定义为商家修改预定义商品价格的有限能力。其次，被动沟通意味着商家只能以脚本方式与玩家互动。为了解决这些问题并创建一个活跃的商家 NPC，我们提出了一个基于大型语言模型 (LLM) 的商家框架，称为 MART，它由评估模块和谈判模块组成。我们进行了两个实验，通过比较不同的训练方法和 LLM 大小来指导游戏开发者选择合适的实现。我们的研究结果表明，微调方法（例如监督微调 (SFT) 和知识蒸馏 (KD)）在使用较小的 LLM 实现主动商家 NPC 时是有效的。此外，我们发现 LLM 的响应中出现了三起不正常的情况。我们希望我们的发现能够指导开发人员使用 LLM 开发活跃的商家 NPC。]]></description>
      <guid>https://arxiv.org/abs/2412.11189</guid>
      <pubDate>Tue, 17 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>