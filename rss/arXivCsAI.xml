<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 17 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>从多文档科学摘要的多个候选排序中解开指导性信息</title>
      <link>https://arxiv.org/abs/2404.10416</link>
      <description><![CDATA[arXiv:2404.10416v1 公告类型：新
摘要：自动将多篇主题相关的科学论文压缩成简洁的摘要，称为多文档科学摘要（MDSS）。目前，虽然常用的抽象MDSS方法可以生成灵活且连贯的摘要，但处理全局信息的困难以及解码过程中缺乏指导仍然使得生成更好的摘要具有挑战性。为了缓解这两个缺点，本文将摘要候选引入 MDSS，利用文档集的全局信息和摘要候选的附加指导来指导解码过程。我们的见解是双重的：首先，摘要候选者可以从积极和消极的角度提供指导性信息，其次，从多个选项中选择更高质量的候选者有助于生成更好的摘要。根据这些见解，我们提出了一个摘要候选人融合框架——从 MDSS 排名候选人 (DIR) 中解开指导信息。具体来说，DIR 首先对多个候选者使用专门的成对比较方法来挑选出质量较高的候选者。然后，DIR 使用条件变分自动编码器将摘要候选的指导信息分解为正潜变量和负潜变量。这些变量被进一步合并到解码器中以指导生成。我们使用三种不同类型的基于 Transformer 的模型和三种不同类型的候选模型来评估我们的方法，并根据自动和人工评估持续观察到明显的性能改进。更多分析进一步证明了我们的模型在处理全局信息和增强解码可控性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.10416</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>MEEL：多模态事件演化学习</title>
      <link>https://arxiv.org/abs/2404.10429</link>
      <description><![CDATA[arXiv:2404.10429v1 公告类型：新
摘要：多模态事件推理（MMER）致力于赋予机器理解跨不同数据模态的复杂事件关系的能力。 MMER 是基础，是广泛应用的基础。尽管进行了大量的指令微调，当前的多模态大语言模型在这种能力上仍然存在不足。这种差异源于现有模型不足以捕捉各种场景下事件演化的基本原则。在本文中，我们引入多模态事件演化学习（MEEL），使模型能够掌握事件演化机制，从而产生先进的 MMER 能力。具体来说，我们从事件多样化的设计入手，从丰富的场景中收集种子事件。随后，我们使用 ChatGPT 为这些种子事件生成演化图。我们提出了一种指令封装过程，将不断演变的图表制定为指令调整数据，使事件推理的理解与人类保持一致。最后，我们观察到以这种方式训练的模型仍然难以完全理解事件演化。在这种情况下，我们提出了指导性判别策略，通过训练模型来判别不正确的进化方向。我们为 MMER 收集并策划了基准 M-EV2。 M-EV2 上的大量实验验证了我们方法的有效性，展示了开源多模式法学硕士的竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10429</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型实现复杂的本体对齐</title>
      <link>https://arxiv.org/abs/2404.10329</link>
      <description><![CDATA[arXiv:2404.10329v1 公告类型：新
摘要：本体对齐是语义网中用于检测不同本体之间关系的关键过程，传统上侧重于通过类标签和属性比较来识别所谓的“简单”一对一关系。对更复杂的对齐的更实际有用的探索仍然是自动化的难题，因此在很大程度上尚未得到充分探索，即在应用实践中，它通常由本体和领域专家手动完成。最近，在大型语言模型（LLM）进步的推动下，自然语言处理（NLP）能力的激增，为增强本体工程实践（包括本体对齐任务）提供了新的机会。本文研究了法学硕士技术的应用，以应对复杂的本体对齐挑战。利用基于提示的方法并集成丰富的本体内容（所谓的模块），我们的工作构成了复杂对准任务自动化的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2404.10329</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中位置编码的有趣特性</title>
      <link>https://arxiv.org/abs/2404.10337</link>
      <description><![CDATA[arXiv:2404.10337v1 公告类型：新
摘要：基于变压器的方法在时间序列预测（TSF）方面取得了重大进展。它们主要处理两种类型的标记，即包含相同时间戳的所有变量的时间标记，以及包含特定变量的所有输入时间点的变量标记。基于 Transformer 的方法依靠位置编码（PE）来标记标记的位置，便于模型感知标记之间的相关性。然而，在TSF中，对PE的研究仍然不够。为了解决这一差距，我们进行了实验并揭示了 TSF 中现有 PE 的有趣特性：（i）PE 注入的位置信息随着网络深度的增加而减少； (ii)增强深度网络中的位置信息有利于提高模型性能； (iii)基于token之间相似性的PE可以提高模型的性能。受这些发现的启发，我们引入了两种新的 PE：用于时间标记的时间位置编码（T-PE）和用于变量标记的可变位置编码（V-PE）。 T-PE和V-PE都结合了基于标记位置的几何PE和基于标记之间相似性的语义PE，但使用不同的计算。为了利用这两个 PE，我们设计了一个基于 Transformer 的双分支框架，名为 T2B-PE。它首先分别计算时间标记的相关性和变量标记的相关性，然后通过门控单元融合双分支特征。大量实验证明了 T2B-PE 卓越的稳健性和有效性。该代码位于：\href{https://github.com/jlu-phyComputer/T2B-PE}{https://github.com/jlu-phyComputer/T2B-PE}。]]></description>
      <guid>https://arxiv.org/abs/2404.10337</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>基于 CNN 的解释集成，用于数据集、表示和解释评估</title>
      <link>https://arxiv.org/abs/2404.10387</link>
      <description><![CDATA[arXiv:2404.10387v1 公告类型：新
摘要：由于复杂的深度学习模型在医学、金融和自动驾驶汽车等高风险领域的广泛使用，可解释的人工智能受到了极大的关注。然而，不同的解释通常呈现模型行为的不同方面。在这份研究手稿中，我们探索了使用卷积模型的深度分类模型生成的集成解释的潜力。通过实验和分析，我们的目标是研究组合解释的含义，以揭示模型行为的更连贯和可靠的模式，从而使评估模型学习的表示成为可能。通过我们的方法，我们可以发现特定类别中图像代表性不足的问题。此外，我们还讨论了其他好处，例如通过用解释替换原始图像来减少特征，从而删除一些敏感信息。通过使用 Quantus 库中精心挑选的评估指标，与单独的解释相比，我们证明了该方法在本地化和可信度方面的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10387</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>基于稀疏注意力回归网络的 Ummaso 土壤肥力预测</title>
      <link>https://arxiv.org/abs/2404.10274</link>
      <description><![CDATA[arXiv:2404.10274v1 公告类型：新
摘要：土壤养分数据集不平衡的挑战严重阻碍了土壤肥力的准确预测。为了解决这个问题，本研究提出了一种新方法，将统一流形逼近和投影（UMAP）与最小绝对收缩和选择算子（LASSO）相结合。主要目的是应对数据分布不均匀的影响，提高土壤肥力模型的预测精度。引入的模型使用稀疏注意力回归，有效地结合了不平衡数据集中的相关特征。 UMAP 最初用于降低数据复杂性，揭示隐藏结构和重要模式。随后，应用 LASSO 来细化特征并增强模型的可解释性。实验结果凸显了 UMAP 和 LASSO 混合方法的有效性。所提出的模型实现了出色的性能指标，预测精度达到 98%，展示了其准确预测土壤肥力的能力。此外，它的精确度高达 91.25%，表明它能够准确识别肥沃的土壤实例。召回率指标为 90.90%，强调了模型有效捕获真实阳性案例的能力。]]></description>
      <guid>https://arxiv.org/abs/2404.10274</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>LLMs4OM：将本体与大型语言模型相匹配</title>
      <link>https://arxiv.org/abs/2404.10317</link>
      <description><![CDATA[arXiv:2404.10317v1 公告类型：新
摘要：本体匹配（OM）是知识集成中的一项关键任务，其中对齐异构本体有助于数据互操作和知识共享。传统的 OM 系统通常依赖于专家知识或预测模型，对大型语言模型 (LLM) 潜力的探索有限。我们提出了 LLMs4OM 框架，这是一种评估 LLM 在 OM 任务中有效性的新方法。该框架分别利用两个模块进行检索和匹配，并通过跨三个本体表示（概念、概念父代和概念子代）的零样本提示来增强。通过使用来自不同领域的20个OM数据集进行综合评估，我们证明LLMs4OM框架下的LLM可以匹配甚至超越传统OM系统的性能，特别是在复杂的匹配场景中。我们的结果凸显了法学硕士对 OM 领域做出重大贡献的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.10317</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>DB-GPT演示：大语言模型赋能的下一代数据交互系统</title>
      <link>https://arxiv.org/abs/2404.10209</link>
      <description><![CDATA[arXiv:2404.10209v1 公告类型：新
摘要：大型语言模型（LLM）的最新突破有望改变软件的许多领域。数据交互技术尤其与法学硕士有着重要的联系，因为高效、直观的数据交互至关重要。在本文中，我们介绍了 DB-GPT，这是一个革命性的、产品就绪的 Python 库，它将 LLM 集成到传统的数据交互任务中，以增强用户体验和可访问性。 DB-GPT 旨在理解自然语言描述的数据交互任务，并提供由法学硕士支持的上下文感知响应，使其成为从新手到专家的用户不可或缺的工具。其系统设计支持跨本地、分布式和云环境的部署。除了使用法学硕士处理文本到 SQL 等基本数据交互任务之外，它还可以通过多代理框架和代理工作流表达式语言 (AWEL) 处理生成数据分析等复杂任务。面向服务的多模型管理框架 (SMMF) 确保数据隐私和安全，使用户能够将 DB-GPT 与私人法学硕士一起使用。此外，DB-GPT 还提供一系列产品就绪功能，旨在使用户能够轻松地将 DB-GPT 集成到其产品环境中。 DB-GPT的代码可以在Github（https://github.com/eosphoros-ai/DB-GPT）上找到，该代码已经拥有超过10,7k star。]]></description>
      <guid>https://arxiv.org/abs/2404.10209</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>找出差距：视觉问答的知识库推理</title>
      <link>https://arxiv.org/abs/2404.10226</link>
      <description><![CDATA[arXiv:2404.10226v1 公告类型：新
摘要：我们分析了基于知识的视觉问答，对于给定的问题，模型需要将其融入视觉模态并从给定的大型知识库（KB）中检索相关知识才能回答。我们的分析有两个方面，一个基于设计神经架构并从头开始训练它们，另一个基于大型预训练语言模型（LLM）。我们的研究问题是：1）我们能否通过显式监督检索相关知识库信息来有效地增强模型来解决知识库-VQA 问题？ 2）特定任务和基于法学硕士的模型在视觉和外部知识的集成以及对两种信息源的多跳推理方面表现如何？ 3）LLM的隐性知识足以用于KB-VQA吗？它在多大程度上可以替代显性知识库？我们的结果证明了通过受监督的外部和视觉知识检索模型增强特定任务和法学硕士模型的积极影响。我们的研究结果表明，尽管法学硕士在 1 跳推理中更强，但与我们微调的 NN 模型相比，即使模型可以获得两种模态的相关信息，它们在 2 跳推理中也会受到影响。此外，我们观察到 LLM 模型在知识库相关问题上优于 NN 模型，这证实了法学硕士中隐性知识的有效性，但是它们并没有减轻对外部知识库的需求。]]></description>
      <guid>https://arxiv.org/abs/2404.10226</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>可压缩、可搜索：具有学习图像压缩功能的 AI 原生多模态检索系统</title>
      <link>https://arxiv.org/abs/2404.10234</link>
      <description><![CDATA[arXiv:2404.10234v1 公告类型：新
摘要：各种形式的数字内容数量不断增长，需要高效的存储和检索方法。传统方法难以应对多媒体数据不断增加的复杂性和规模。在本文中，我们提出的框架通过将人工智能原生多模态搜索功能与神经图像压缩相融合来解决这一挑战。首先，我们分析可压缩性和可搜索性之间的复杂关系，认识到两者在存储和检索系统的效率中发挥的关键作用。通过使用简单的适配器来桥接学习图像压缩（LIC）和对比语言图像预训练（CLIP）的功能，同时保留语义保真度和多模态数据的检索。对柯达数据集的实验评估证明了我们方法的有效性，与现有方法相比，显示了压缩效率和搜索准确性的显着增强。我们的工作标志着大数据时代可扩展且高效的多模式搜索系统的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2404.10234</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>Chinchilla Scaling：一次复制尝试</title>
      <link>https://arxiv.org/abs/2404.10102</link>
      <description><![CDATA[arXiv:2404.10102v1 公告类型：新
摘要：霍夫曼等人。 (2022) 提出了三种估计计算最佳缩放定律的方法。我们尝试复制他们的第三个估计过程，其中涉及将参数损失函数拟合到从他们的图中重建的数据。我们发现报告的估计与他们的前两种估计方法不一致，无法拟合提取的数据，并且报告的置信区间窄得令人难以置信——如此狭窄的区间需要超过 600,000 次实验，而他们可能只运行了不到 500 次。相比之下，我们使用第三种方法重新推导缩放定律，得到的结果与 Hoffmann 等人描述的前两个估计程序的结果一致。]]></description>
      <guid>https://arxiv.org/abs/2404.10102</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>欺骗以启迪：引导法学硕士进行自我反思，以增强偏见检测和缓解</title>
      <link>https://arxiv.org/abs/2404.10160</link>
      <description><![CDATA[arXiv:2404.10160v1 公告类型：新
摘要：大型语言模型（LLM）嵌入了复杂的偏见和刻板印象，可能导致有害的用户体验和社会后果，而模型本身通常没有意识到。本文强调了为法学硕士配备更好的自我反思和偏见识别机制的重要性。我们的实验表明，通过告知法学硕士他们生成的内容并不代表他们自己的观点并质疑他们的偏见，他们识别和解决偏见的能力得到了提高。这种增强归因于法学硕士的内部注意力机制和潜在的内部敏感性政策。基于这些发现，我们提出了一种减少法学硕士输出偏差的新方法。这涉及让法学硕士参与多角色场景，扮演不同的角色，负责暴露偏见，并在每个辩论循环结束时扮演公正裁判的角色。采用排名评分机制来量化偏差水平，从而实现更精细的反射和卓越的输出质量。比较实验结果证实，我们的方法在减少偏见方面优于现有方法，这使其为实现更道德的人工智能系统做出了宝贵的贡献。]]></description>
      <guid>https://arxiv.org/abs/2404.10160</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>TEL'M：语言模型的测试和评估</title>
      <link>https://arxiv.org/abs/2404.10200</link>
      <description><![CDATA[arXiv:2404.10200v1 公告类型：新
摘要：语言模型在某些任务上表现出了卓越的能力，但在其他任务上却表现得很糟糕。这种情况引起了人们对理解和比较各种语言模型 (LM) 功能的极大兴趣，但这些努力很大程度上是临时性的，其结果往往只是轶事。这与医疗保健、雷达信号处理和其他国防领域使用的测试和评估流程形成鲜明对比。在本文中，我们将语言模型测试和评估 (TEL&#39;M) 描述为一种原则方法，用于评估当前和未来专注于高价值商业、政府和国家安全应用的语言模型的价值。我们相信，这种方法可以应用于其他人工智能（AI）技术，作为人工智能“工业化”这一更大目标的一部分。]]></description>
      <guid>https://arxiv.org/abs/2404.10200</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>ClimODE：利用基于物理的神经常微分方程进行气候和天气预报</title>
      <link>https://arxiv.org/abs/2404.10024</link>
      <description><![CDATA[arXiv:2404.10024v1 公告类型：新
摘要：气候和天气预报传统上依赖于大气物理的复杂数值模拟。深度学习方法（例如 Transformer）最近通过复杂的网络预测挑战了模拟范式。然而，它们通常充当数据驱动的黑盒模型，忽略了底层物理原理并且缺乏不确定性量化。我们用 ClimODE 解决了这些限制，这是一种时空连续时间过程，它实现了统计力学中平流的关键原理，即由于时间量的空间运动而导致的天气变化。 ClimODE 通过价值守恒动力学对精确的天气演化进行建模，将全球天气传输作为神经流进行学习，这也能够估计预测中的不确定性。我们的方法在全球和区域预测中优于现有的数据驱动方法，参数化程度要小一个数量级，建立了新的最先进技术。]]></description>
      <guid>https://arxiv.org/abs/2404.10024</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:40 GMT</pubDate>
    </item>
    <item>
      <title>LegalPro-BERT：通过微调 BERT 大语言模型对法律条款进行分类</title>
      <link>https://arxiv.org/abs/2404.10097</link>
      <description><![CDATA[arXiv:2404.10097v1 公告类型：新
【摘要】：合同是组织中常用的一种法律文件。合同审查是一个完整且重复的过程，以避免商业风险和责任。合同分析需要对协议中的关键条款和段落进行识别和分类。合同条款的识别和验证可能是一项耗时且具有挑战性的任务，需要训练有素且费用昂贵的律师、律师助理或其他法律助理的服务。由于模型训练需要领域专业的法律语言以及法律领域缺乏足够的标记数据，利用人工智能和自然语言处理对合同中的法律条款进行分类是复杂的。在这种情况下，使用通用模型并不有效，因为合同中使用了通用模型可能无法识别的专门法律词汇。为了解决这个问题，我们建议使用预先训练的大型语言模型，随后根据法律分类进​​行校准。我们提出了 LegalPro-BERT，这是一种 BERT 变压器架构模型，我们对其进行微调以有效处理法律条款的分类任务。我们进行了实验来测量指标并将其与当前基准结果进行比较。我们发现 LegalPro-BERT 优于本研究中用于比较的先前基准。]]></description>
      <guid>https://arxiv.org/abs/2404.10097</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>