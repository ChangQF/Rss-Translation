<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 22 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于深度强化学习策略的分层控制器综合</title>
      <link>https://arxiv.org/abs/2402.13785</link>
      <description><![CDATA[arXiv:2402.13785v1 公告类型：新
摘要：我们提出了一种针对马尔可夫决策过程（MDP）建模环境的控制器设计问题的新方法。具体来说，我们将分层 MDP 视为一个图，其中每个顶点都由称为“房间”的 MDP 填充。我们首先应用深度强化学习（DRL）来获取每个房间的低级策略，扩展到结构未知的大房间。然后，我们应用反应式综合来获得一个高级规划器，该规划器选择在每个房间中执行哪个低级策略。综合规划器的主要挑战是对建模室的需求。我们通过开发 DRL 程序来训练简洁的“潜在”策略以及 PAC 对其性能的保证来应对这一挑战。与以前的方法不同，我们的方法绕过了模型蒸馏步骤。我们的方法解决了 DRL 中奖励稀疏的问题，并实现了低级策略的可重用性。我们通过涉及移动障碍物中代理导航的案例研究证明了可行性。]]></description>
      <guid>https://arxiv.org/abs/2402.13785</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>对问题进行解释而不是证明</title>
      <link>https://arxiv.org/abs/2402.13914</link>
      <description><![CDATA[arXiv:2402.13914v1 公告类型：新
摘要：可解释人工智能（XAI）是一个年轻但非常有前途的研究领域。不幸的是，目前该领域的进展因目标分歧和不相容而放缓。在本文中，我们将 XAI 领域内纠缠在一起的各种线索分为两种互补的文化：以人类/价值为导向的解释（BLUE XAI）和以模型/验证为导向的解释（RED XAI）。我们还认为，RED XAI 领域目前尚未得到充分探索，并且隐藏着确保人工智能系统安全所需的重要研究的巨大机遇和潜力。我们通过提出该领域有希望的挑战来结束本文。]]></description>
      <guid>https://arxiv.org/abs/2402.13914</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>妄想对冲算法作为人类从不同意见中学习的模型</title>
      <link>https://arxiv.org/abs/2402.13927</link>
      <description><![CDATA[arXiv:2402.13927v1 公告类型：新
摘要：虽然学习的认知模型通常假设对事件特征以及真实标签或结果的直接体验，但许多日常学习来自于听取他人的意见，而不是直接获取经验或真实结果。我们考虑人们如何通过扩展对冲算法来了解在这种情况下应该信任哪些观点：从不同信息源学习的经典解决方案。我们首先引入一种半监督变体，我们称之为妄想对冲，能够从监督和无监督的经验中学习。在两个实验中，我们检查了标准对冲、妄想对冲和启发式基线模型的人类判断和预测之间的一致性。结果表明，人类以与妄想对冲算法一致的方式有效地整合了标记和未标记信息，这表明人类学习者不仅衡量信息来源的准确性，而且衡量信息来源与其他可靠来源的一致性。这些发现增进了我们对人类从不同观点中学习的理解，对开发更好地捕捉人们如何学习权衡相互冲突的信息源的算法具有影响。]]></description>
      <guid>https://arxiv.org/abs/2402.13927</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>将连词谬误作为事实进行分析</title>
      <link>https://arxiv.org/abs/2402.13615</link>
      <description><![CDATA[arXiv:2402.13615v1 公告类型：新
摘要：自从特沃斯基和卡尼曼发表开创性论文以来，合取谬误一直是多种争论的主题，并成为决策认知理论的根本挑战。在这篇文章中，我们对这种现象采取了一种相当不寻常的视角。我们不是试图解释合取谬误的性质或原因（内涵定义），而是分析其事实可能性的范围（外延定义）。我们发现，根据我们审查的涵盖 1983 年至 2016 年文献的实验样本，大多数关于合取谬误的研究都集中在先验事实可能性的一小部分，这意味着对合取谬误的解释从根本上来说是有偏见的。通过探索的可能性的范围很短。考虑到合取谬误的本质是由外延考虑所激发的，后者是合取谬误研究演变中一个相当奇怪的方面。]]></description>
      <guid>https://arxiv.org/abs/2402.13615</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>用于概率和神经符号逻辑编程的半环</title>
      <link>https://arxiv.org/abs/2402.13782</link>
      <description><![CDATA[arXiv:2402.13782v1 公告类型：新
摘要：概率逻辑编程（PLP）领域专注于将概率模型集成到基于逻辑的编程语言中。在过去的 30 年里，已经开发了许多用于概率逻辑程序建模、推理和学习的语言和框架。虽然最初的 PLP 专注于离散概率，但最近的方法已经结合了连续分布和神经网络，有效地产生了神经符号方法。我们提供了关于 PLP 的统一代数视角，表明 PLP 的许多（如果不是大部分）扩展都可以在通用代数逻辑编程框架内进行转换，其中事实用半环元素标记，析取和合取被加法和合取取代。乘法。这不仅适用于 PLP 变体本身，也适用于基于（代数）模型计数的底层执行机制。]]></description>
      <guid>https://arxiv.org/abs/2402.13782</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>定量因果关系、因果关系引导的科学发现和因果机器学习</title>
      <link>https://arxiv.org/abs/2402.13427</link>
      <description><![CDATA[arXiv:2402.13427v1 公告类型：新
摘要：有人说，因果关系分析应该为可解释的深度学习和泛化铺平一条有希望的道路。然而，将因果关系纳入人工智能（AI）算法却面临着模糊性、非定量性、计算效率低下等挑战。在过去的18年里，这些挑战已经基本得到解决，建立了严格的因果关系形式主义分析最初源于大气的可预测性。这不仅开辟了大气-海洋科学的一个新领域，即信息流，而且通过各种应用，带动了其他学科的科学发现，如量子力学、神经科学、金融经济学等。本文简要回顾了十年来的努力，包括主要理论成果列表、因果深度学习框架的草图，以及与该期刊相关的一些在地球科学中具有代表性的实际应用，例如关于人类起源的应用全球变暖的原因、厄尔尼诺Modoki的十年预测、中国极端干旱的预测等等。]]></description>
      <guid>https://arxiv.org/abs/2402.13427</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>用于可解释性和概率决策的多智能体强化学习的神经符号方法</title>
      <link>https://arxiv.org/abs/2402.13440</link>
      <description><![CDATA[arXiv:2402.13440v1 公告类型：新
摘要：多智能体强化学习（MARL）非常适合运行时决策，以优化多个智能体共存并竞争共享资源的系统的性能。然而，将常见的基于深度学习的 MARL 解决方案应用于现实世界的问题会遇到可解释性、样本效率、部分可观察性等问题。为了解决这些挑战，我们提出了一种事件驱动的公式，其中决策由分布式处理使用神经符号方法的合作 MARL 代理。最近引入的神经符号逻辑神经网络 (LNN) 框架充当强化学习的函数逼近器，用于训练基于规则的策略，该策略既符合逻辑又可通过构造进行解释。为了在不确定性和部分可观察性下做出决策，我们开发了一种新颖的概率神经符号框架，即概率逻辑神经网络（PLNN），它将逻辑推理与概率图形模型的功能结合起来。在 PLNN 中，继承自 LNN 的向上/向下推理策略通过将与每个神经网络节点关联的逻辑运算符的激活函数设置为 Fr&#39;echet 不等式的概率推广，与置信边界相结合。这些 PLNN 节点形成了结合概率逻辑和贝叶斯网络的统一元素，允许对具有未观察到的状态的变量进行推断。我们通过解决片上系统应用中功率共享的关键 MARL 挑战来展示我们的贡献。]]></description>
      <guid>https://arxiv.org/abs/2402.13440</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>通过深度强化学习和行为调节掌握关蛋游戏</title>
      <link>https://arxiv.org/abs/2402.13582</link>
      <description><![CDATA[arXiv:2402.13582v1 公告类型：新
摘要：游戏是现实的简化模型，通常是人工智能（AI）研究的首选平台。许多研究都与游戏代理及其决策过程有关。关蛋游戏（字面意思是“扔鸡蛋”）是一种具有挑战性的游戏，即使是职业玩家有时也很难做出正确的决定。在本文中，我们提出了一个名为guanZero的框架，供人工智能代理使用蒙特卡罗方法和深度神经网络来掌握这个游戏。本文的主要贡献是通过精心设计的神经网络编码方案来调节代理的行为。然后，我们通过与最先进的方法进行比较来证明所提出的框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.13582</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>通过马尔可夫博弈中的贝叶斯规则归纳来学习和维持共享规范系统</title>
      <link>https://arxiv.org/abs/2402.13399</link>
      <description><![CDATA[arXiv:2402.13399v1 公告类型：新
摘要：人类社会的一个普遍特征是采用为合作目的服务的规则和规范体系。我们如何构建具有相同功能的学习代理，以便它们可以灵活地与它们所处的人类机构合作？我们假设，代理人可以通过假设存在一套大多数其他人在追求个人愿望时遵守的共同规范来实现这一目标，即使他们不知道这些规范的确切内容。通过假设共享规范，新引入的代理可以从对遵守和违规行为的观察中推断出现有群体的规范。此外，代理群体可以收敛到一套共享的规范，即使他们最初对规范的信念存在分歧。这反过来又保证了规范系统的稳定性：由于代理可以引导规范的常识，这导致规范被广泛遵守，使新进入者能够快速学习这些规范。我们在马尔可夫博弈的背景下形式化了这个框架，并通过强制性和禁止性规范的近似贝叶斯规则归纳来证明其在多智能体环境中的运行。使用我们的方法，代理人能够快速学习和维持各种合作制度，包括资源管理规范和亲社会劳动补偿，促进集体福利，同时仍然允许代理人按照自己的利益行事。]]></description>
      <guid>https://arxiv.org/abs/2402.13399</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>基于模型的规划代理行为保证的奖励约束</title>
      <link>https://arxiv.org/abs/2402.13419</link>
      <description><![CDATA[arXiv:2402.13419v1 公告类型：新
摘要：近年来，人们对基于机器学习的代理的可信度产生了浓厚的兴趣，特别是在机器人领域，以为行业提供安全保证。为这些代理人获得行为保证仍然是一个重要问题。在这项工作中，我们专注于保证基于模型的规划代理在特定的未来时间步内达到目标状态。我们证明，目标状态下的奖励存在一个下限，如果所述奖励低于该下限，则不可能获得这样的保证。通过扩展，我们展示了如何强制执行对多个目标的偏好。]]></description>
      <guid>https://arxiv.org/abs/2402.13419</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>人类和机器的操作集体智能</title>
      <link>https://arxiv.org/abs/2402.13273</link>
      <description><![CDATA[arXiv:2402.13273v1 公告类型：新
摘要：我们探索使用聚合众包预测（ACF）作为一种机制来帮助实施人机团队的“集体智慧”以进行协调行动。我们采用集体智慧的定义为：“数据-信息-知识、软件-硬件和个人（具有新见解和公认权威的人）之间的协同作用产生的群体属性，能够实现及时集体智慧源于连接人类和人工智能的新方式，以实现决策优势，部分是通过创建和利用其他可能不包含的信息源来实现。聚合众包预测 (ACF) 是集体智能的最新关键进展，其中预测（Y 发生的 X\% 概率）和基本原理（为什么我相信 X 发生的概率）是从不同人群中独立得出的，聚合，然后用于为高层决策提供信息。本研究询问 ACF 作为实现作战集体智能的关键方式，是否可以应用于作战场景（即具有定义的代理、组件和交互的事件序列）和决策，并考虑这种能力是否具有可以提供新颖的运营能力，以实现新形式的决策优势。]]></description>
      <guid>https://arxiv.org/abs/2402.13273</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和认知科学视角的基础</title>
      <link>https://arxiv.org/abs/2402.13290</link>
      <description><![CDATA[arXiv:2402.13290v1 公告类型：新
摘要：接地是一个具有挑战性的问题，需要正式的定义和不同的抽象级别。本文从认知科学和机器学习的角度探讨了基础知识。它确定了接地的微妙之处、其对协作代理的重要性以及两个社区接地方法的异同。本文探讨了针对接地任务量身定制的神经符号方法的潜力，展示了它们如何更全面地解决接地问题。最后，我们讨论了接地方面进一步探索和发展的领域。]]></description>
      <guid>https://arxiv.org/abs/2402.13290</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>走向 Transformers：用 Transformers 彻底改变混合整数程序的解决方案</title>
      <link>https://arxiv.org/abs/2402.13380</link>
      <description><![CDATA[arXiv:2402.13380v1 公告类型：新
摘要：在这项研究中，我们介绍了一种创新的深度学习框架，该框架采用变压器模型来解决混合整数程序的挑战，特别关注容量调整问题（CLSP）。据我们所知，我们的方法是第一个利用变压器来预测混合整数规划（MIP）问题的二进制变量的方法。具体来说，我们的方法利用编码器解码器变压器处理顺序数据的能力，使其非常适合预测指示 CLSP 每个时期的生产设置决策的二进制变量。这个问题本质上是动态的，我们需要在约束下处理顺序决策。我们提出了一种有效的算法，其中通过变压器神经网络学习 CLSP 解决方案。在测试的 240K 基准 CLSP 实例中，所提出的后处理 Transformer 算法在求解时间、最佳间隙和不可行性百分比方面超越了最先进的求解器、CPLEX 和长短期记忆 (LSTM)。训练 ML 模型后，对模型进行推理（包括后处理），将 MIP 简化为线性程序 (LP)。这将基于 ML 的算法与 LP 求解器相结合，转变为多项式时间近似算法，以解决众所周知的 NP-Hard 问题，并具有近乎完美的解质量。]]></description>
      <guid>https://arxiv.org/abs/2402.13380</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>KGroot：通过知识图和图卷积神经网络增强根本原因分析</title>
      <link>https://arxiv.org/abs/2402.13264</link>
      <description><![CDATA[arXiv:2402.13264v1 公告类型：新
摘要：由于监控数据量、类型、事件的多样性以及服务和组件之间复杂的相互依赖关系，在线微服务中的故障定位具有挑战性。服务中的故障事件具有传播性，可以在短时间内触发级联警报。在业界，故障定位通常由经验丰富的人员手动进行。这种对经验的依赖是不可靠的并且缺乏自动化。不同模块在手动定位时存在信息障碍，紧急​​故障时难以快速对准。这种低效率滞后于稳定性保证，无法最大限度地减少故障检测和修复时间。尽管可行的方法旨在实现过程自动化，但准确性和效率却不尽如人意。故障定位结果的精度至关重要，因为它巩固了工程师对诊断结论的信任，而诊断结论是从多个角度得出并提供全面的见解。因此，需要一种更可靠的方法来自动识别故障事件与传播路径之间的关联关系。为了实现这一目标，KGroot 通过集成知识图谱和 RCA 的 GCN，利用事件知识和事件之间的相关性来执行根本原因推理。 FEKG基于历史数据构建，当故障事件发生时实时构建在线图，并使用GCN比较每个知识图与在线图之间的相似度，通过排序策略来查明故障类型。综合实验表明，KGroot 能够定位根本原因，对于二级潜在原因的前 3 个潜在原因的准确率达到 93.5%。该性能与工业环境中的实时故障诊断水平相匹配，并且在有效性和效率方面显着超越 RCA 的最先进基准。]]></description>
      <guid>https://arxiv.org/abs/2402.13264</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的自发心理理论</title>
      <link>https://arxiv.org/abs/2402.13272</link>
      <description><![CDATA[arXiv:2402.13272v1 公告类型：新
摘要：人工智能（AI）中现有的心智理论（ToM）方法过分强调提示或基于线索的 ToM，这可能会限制我们开发人工智能社会智能（ASI）的集体能力。根据计算机科学、认知科学和相关学科的研究，我们将提示性思维理论与我们所说的自发思维理论进行了对比——对他人基于无意识、可能无法控制的认知功能的心理状态进行推理。我们主张采用一种有原则的方法来研究和开发 AI ToM，并建议强大的或通用的 ASI 将响应提示\textit{并}自发地参与社会推理。]]></description>
      <guid>https://arxiv.org/abs/2402.13272</guid>
      <pubDate>Thu, 22 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    </channel>
</rss>