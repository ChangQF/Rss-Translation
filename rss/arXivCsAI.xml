<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 16 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于移动边缘计算系统中定制 VR 服务的基于联合提示的决策转换器</title>
      <link>https://arxiv.org/abs/2402.09729</link>
      <description><![CDATA[arXiv:2402.09729v1 公告类型：新
摘要：本文研究了移动边缘计算（MEC）系统中的资源分配，以便为异构用户提供定制的虚拟现实（VR）服务。我们首先引入体验质量（QoE）指标来衡量用户体验，该指标考虑了 MEC 系统的延迟、用户注意力水平和首选分辨率。然后，制定 QoE 最大化问题来进行资源分配，以确保尽可能高的用户体验，这被视为强化学习问题，旨在学习适用于所有 MEC 服务器的跨不同用户环境的通用策略。为了学习广义策略，我们提出了一个框架，该框架采用联邦学习（FL）和基于提示的序列建模来预训练跨 MEC 服务器的通用决策模型，该模型名为 FedPromptDT。使用FL解决了本地MEC数据不足的问题，同时保护了离线训练时用户的隐私。结合用户环境提示和用户偏好分配的提示设计提高了模型在线执行时对各种用户环境的适应性。]]></description>
      <guid>https://arxiv.org/abs/2402.09729</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>特工不需要知道他们的目的</title>
      <link>https://arxiv.org/abs/2402.09734</link>
      <description><![CDATA[arXiv:2402.09734v1 公告类型：新
摘要：确保人工智能的行为方式与人类价值观保持一致通常被称为一致性挑战。先前的研究表明，理性主体在以最大化效用函数的方式行事时，将不可避免地以不符合人类价值观的方式行事，特别是当他们的智力水平提高时。先前的工作还表明，不存在“一个真正的效用函数”；解决方案必须包括更全面的协调方法。本文描述了不经意的代理：代理的架构方式使得它们的有效效用函数是已知和隐藏子函数的聚合。要最大化的隐藏组件在内部实现为黑匣子，以防止代理检查它。要最小化的已知分量是隐藏子函数的知识。架构约束进一步影响代理行为如何发展其内部环境模型。我们表明，一个不经意的代理人，行为理性，构建了设计者意图的内部近似（即推断对齐），并且由于其架构和有效的效用函数，其行为方式最大化对齐；即最大化近似意图函数。我们证明，矛盾的是，无论使用什么效用函数作为隐藏组件，它都会这样做，并且与现有技术相比，随着智能体智能的增长，对齐的机会实际上会增加。]]></description>
      <guid>https://arxiv.org/abs/2402.09734</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>模型编辑的蝴蝶效应：很少的编辑就能引发大型语言模型的崩溃</title>
      <link>https://arxiv.org/abs/2402.09656</link>
      <description><![CDATA[arXiv:2402.09656v1 公告类型：新
摘要：虽然模型编辑在修改大型语言模型（LLM）知识方面显示出了希望，但它对 LLM 固有能力的影响常常被忽视。在这项工作中，我们揭示了一个关键现象：即使是单个编辑也可能触发模型崩溃，表现为各种基准任务中的性能显着下降。然而，每次编辑后对法学硕士进行基准测试虽然是防止此类崩溃所必需的，但实际上非常耗时且耗费资源。为了缓解这一问题，我们建议使用困惑度作为替代指标，并通过大量实验进行验证，证明其与下游任务绩效的强相关性。我们进一步对顺序编辑（现实世界场景的实际设置）进行了深入研究，涉及各种编辑方法和法学硕士，重点关注我们之前的单一编辑研究中的困难案例。结果表明，几乎所有检查的编辑方法仅在几次编辑后就会导致模型崩溃。为了促进进一步的研究，我们利用 ChatGPT 基于这些困难案例开发了一个新的数据集 HardCF。该数据集旨在为可靠模型编辑和编辑引起的模型崩溃的机制奠定基础。我们希望这项工作能够引起社区对模型编辑实践中固有的潜在风险的关注。]]></description>
      <guid>https://arxiv.org/abs/2402.09656</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>用户建模和用户分析：综合调查</title>
      <link>https://arxiv.org/abs/2402.09660</link>
      <description><![CDATA[arXiv:2402.09660v1 公告类型：新
摘要：人工智能（AI）融入日常生活，特别是通过信息检索和推荐系统，需要先进的用户建模和分析技术来提供个性化体验。这些技术旨在基于与这些系统交互生成的大量数据来构建准确的用户表示。本文对用户建模和分析研究的现状、演变和未来方向进行了全面的调查。我们提供历史概述，追溯从早期刻板印象模型到最新深度学习技术的发展，并提出一种新颖的分类法，涵盖该研究领域的所有活跃主题，包括最新趋势。我们的调查强调了范式转向更复杂的用户分析方法，强调隐式数据收集、多行为建模和图数据结构的集成。我们还解决了对隐私保护技术的迫切需求，以及推动用户建模方法的可解释性和公平性。通过检查核心术语的定义，我们旨在通过提出主要术语的两个新颖的百科全书式定义来澄清歧义并促进对该领域的更清晰的理解。此外，我们还探索用户建模在假新闻检测、网络安全和个性化教育等各个领域的应用。这项调查为研究人员和从业者提供了综合资源，提供了对用户建模和分析的演变的见解，并指导开发更加个性化、道德和有效的人工智能系统。]]></description>
      <guid>https://arxiv.org/abs/2402.09660</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:38 GMT</pubDate>
    </item>
    <item>
      <title>LLM 增强的用户-项目交互：利用边缘信息来优化推荐</title>
      <link>https://arxiv.org/abs/2402.09617</link>
      <description><![CDATA[arXiv:2402.09617v1 公告类型：新
摘要：大型语言模型的非凡性能不仅重塑了 NLP 领域的研究格局，而且还展示了其在各个领域的非凡应用潜力。然而，这些模型在从图数据中挖掘关系方面的潜力仍未得到充分探索。图神经网络作为近年来的热门研究领域，关于关系挖掘的研究众多。然而，当前图神经网络的前沿研究尚未与大型语言模型有效集成，导致图关系挖掘任务的效率和能力有限。主要挑战是法学硕士无法深入利用图中的边缘信息，这对于理解复杂的节点关系至关重要。这一差距限制了法学硕士从图结构中提取有意义的见解的潜力，限制了它们在更复杂的基于图的分析中的适用性。我们专注于如何利用现有的法学硕士来挖掘和理解图数据中的关系，并将这些技术应用于推荐任务。我们提出了一种创新框架，将 LLM 强大的上下文表示能力与 GNN 的关系提取和分析功能相结合，用于挖掘图数据中的关系。具体来说，我们设计了一个新的提示构建框架，将图数据的关系信息集成到自然语言表达中，帮助法学硕士更直观地掌握图数据中的连接信息。此外，我们将图关系理解和分析功能引入法学硕士，以增强他们对图数据中连接信息的关注。我们对现实世界数据集的评估证明了该框架理解图形数据中的连接信息的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.09617</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 在基于 USMLE 的案例研究中对其性能的评估</title>
      <link>https://arxiv.org/abs/2402.09654</link>
      <description><![CDATA[arXiv:2402.09654v1 公告类型：新
摘要：本研究调查了 GPT-4 在医疗保健应用中对其性能的评估。使用一种简单的提示技术来提示法学硕士从美国医学执照考试（USMLE）问卷中提取的问题，并要求其在提出问题之前和提出问题之后评估其置信度得分。问卷分为两组：有反馈的问题（WF）和问题后无反馈的问题（NF）。该模型被要求在每个问题之前和之后提供绝对和相对置信度分数。使用统计工具对实验结果进行分析，以研究 WF 和 NF 组的置信度变异性。此外，还进行了序贯分析以观察 WF 组和 NF 组的表现差异。结果表明，反馈会影响相对信心，但不会持续增加或减少它。了解法学硕士的表现对于探索其在医疗保健等敏感领域的效用至关重要。这项研究为医疗保健领域人工智能（尤其是 GPT-4 等法学硕士）可靠性的持续讨论做出了贡献，提供了有关如何优化反馈机制以增强人工智能辅助医疗教育和决策支持的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.09654</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:37 GMT</pubDate>
    </item>
    <item>
      <title>使用大语言语言模型进行药物分子和适应症之间翻译的新机会</title>
      <link>https://arxiv.org/abs/2402.09588</link>
      <description><![CDATA[arXiv:2402.09588v1 公告类型：新
摘要：药物分子是改变生物体精神或身体状态的物质。每种批准的药物都有一个适应症，这是指该药物用于治疗特定疾病的治疗用途。虽然大语言模型（LLM）是一种生成人工智能（AI）技术，最近证明了在分子及其文本描述之间翻译的有效性，但在其在促进药物分子和适应症之间的翻译方面的应用仍然存在研究空白，反之亦然，这可以极大地有利于药物发现过程。根据给定适应症生成药物的能力将有助于发现针对特定疾病或目标的药物，并最终为患者提供更好的治疗。在本文中，我们首先提出一个新任务，即药物分子和相应适应症之间的翻译，然后在这个新任务上测试现有的法学硕士。具体来说，我们考虑了 T5 LLM 的九种变体，并在从 ChEMBL 和 DrugBank 获得的两个公共数据集上对其进行评估。我们的实验展示了使用法学硕士完成这项任务的早期结果，并提供了对最新技术的看法。我们还强调当前的局限性，并讨论未来有可能提高这项任务性能的工作。根据适应症创建分子，反之亦然，将能够更有效地靶向疾病，并显着降低药物发现的成本，有可能在生成人工智能时代彻底改变药物发现领域。]]></description>
      <guid>https://arxiv.org/abs/2402.09588</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>一种基于网络的工具，用于复杂医疗调查研究（包括社交网络分析）的自动数据收集、管理和可视化</title>
      <link>https://arxiv.org/abs/2402.09592</link>
      <description><![CDATA[arXiv:2402.09592v1 公告类型：新
【摘要】：当今社会,尤其是年轻人中,饮酒和吸毒问题引起了人们的高度关注。通过使用 AUDIT、FAS、KIDSCREEN 等问卷调查来分析这些青少年所处的社会环境，以及确定酗酒风险或个人情况和认知的一系列措施，可以深入了解青少年的酗酒情况。特定个人有关其消费行为的当前状况。但为了实现这种分析，需要使用能够简化调查问卷创建、数据收集、管理和表示以及随后向用户进行分析和可视化的过程的工具。这项研究提出了一个基于网络的平台的设计和构建，该平台能够通过将不同阶段集成到一个带有图形用户界面的直观系统中来促进每个提到的过程，该系统隐藏了每个调查问卷和所使用的技术背后的复杂性，并呈现了以灵活、可视化的方式产生结果，避免在此过程中手动处理数据。展示了这种方法的优点，并与以前的情况进行了比较，在以前的情况下，一些任务是通过耗时且容易出错的数据操作来完成的。]]></description>
      <guid>https://arxiv.org/abs/2402.09592</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>图骨架：~1% 的节点足以表示十亿级图</title>
      <link>https://arxiv.org/abs/2402.09565</link>
      <description><![CDATA[arXiv:2402.09565v1 公告类型：新
摘要：由于网络上图数据的普遍存在，网络图挖掘已成为研究热点。尽管如此，大规模网络图在实际应用中的盛行对存储、计算能力和图模型设计提出了重大挑战。尽管有大量研究来增强图模型的可扩展性，但学术研究和实际的网络图挖掘应用程序之间仍然存在明显的差距。一个主要原因是，在大多数工业场景中，实际上只需要分析Web图中的一小部分节点，我们将这些节点称为目标节点，而其他节点称为背景节点。在本文中，我们认为从海量网络图数据中正确获取和压缩背景节点可能是从根本上解决障碍的更经济的捷径。为此，我们首次尝试研究海量背景节点压缩用于目标节点分类的问题。通过大量的实验，我们揭示了背景节点在目标节点分类中发挥的两个关键作用：增强目标节点之间的结构连接性以及与目标节点的特征相关性。随后，我们提出了一种新颖的 Graph-Skeleton1 模型，该模型可以正确获取背景节点，并进一步将背景节点的语义和拓扑信息压缩到相似的目标-背景局部结构中。对各种网络图数据集的广泛实验证明了所提出方法的有效性和效率。特别是，对于具有 2.4 亿个节点的 MAG240M 数据集，我们生成的骨架图实现了高度可比的性能，同时仅包含原始图的 1.8% 节点。]]></description>
      <guid>https://arxiv.org/abs/2402.09565</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>建筑能源系统中基于大语言模型的可解释机器学习控制</title>
      <link>https://arxiv.org/abs/2402.09584</link>
      <description><![CDATA[arXiv:2402.09584v1 公告类型：新
摘要：机器学习控制（MLC）在 HVAC 系统中的潜力因其不透明的性质和推理机制而受到阻碍，这对用户和建模者来说很难完全理解，最终导致对基于 MLC 的决策缺乏信任。为了应对这一挑战，本文研究和探索了可解释机器学习 (IML)，它是机器学习 (ML) 的一个分支，可增强模型及其推论的透明度和理解，以提高 MLC 及其在 HVAC 系统中的工业应用的可信度。具体来说，我们开发了一个创新框架，结合了 Shapley 值的原则和大型语言模型 (LLM) 的上下文学习功能。虽然 Shapley 值有助于剖析 ML 模型中各种特征的贡献，但 LLM 提供了对 MLC 中基于规则的部分的深入理解；将它们结合起来，法学硕士进一步将这些见解打包成一个连贯的、人类可以理解的叙述。本文提出了一个案例研究，证明了所开发的 IML 框架在虚拟测试台中需求响应事件下基于模型预测控制的预冷的可行性。结果表明，所开发的框架根据基于规则的原理生成并解释控制信号。]]></description>
      <guid>https://arxiv.org/abs/2402.09584</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:35 GMT</pubDate>
    </item>
    <item>
      <title>用于预测火灾和其他紧急事件的统计和机器学习模型</title>
      <link>https://arxiv.org/abs/2402.09553</link>
      <description><![CDATA[arXiv:2402.09553v1 公告类型：新
【摘要】：城市突发事件给个人、家庭和社区造成巨大的经济损失。准确及时的事件预测可以帮助应急消防和救援部门做好准备并减轻紧急事件的后果。在本文中，我们提出了加拿大埃德蒙顿市各种类型紧急事件的预测模型的系统开发。我们提出了（i）数据收集和数据集开发的方法； (ii) 对每种事件类型及其在不同时空层面的特征进行描述性分析； (iii)基于相关系数分析和特征重要性分析的特征分析和选择； (iv) 开发不同时间和空间分辨率下每种事件类型发生可能性的预测模型。我们分析事件类型与社区层面的社会经济和人口统计数据的关联，为每种事件类型确定一组预测变量，并开发具有负二项式回归的预测模型。我们在社区和消防站服务区级别进行评估。我们的结果表明，这些模型对于大多数事件类型都表现良好，每周和每月的预测误差都可以接受。评估表明，预测精度在消防站层面上是一致的，因此预测结果可以用于消防救援部门的管理，规划这些时间段的资源分配。我们还研究了 COVID-19 大流行对事件发生和事件预测模型准确性的影响。我们的研究结果表明，COVID-19 对事件预测模型的性能有重大影响。]]></description>
      <guid>https://arxiv.org/abs/2402.09553</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>用于改进时间序列表示学习的双向生成预训练</title>
      <link>https://arxiv.org/abs/2402.09558</link>
      <description><![CDATA[arXiv:2402.09558v1 公告类型：新
摘要：学习判别任务的时间序列表示一直是一个长期存在的挑战。当前的预训练方法仅限于单向下一个令牌预测或随机屏蔽令牌预测。我们提出了一种称为双向及时生成预训练变压器（BiTimelyGPT）的新颖架构，它通过交替变压器层中的下一个令牌和上一个令牌预测来对时间序列数据进行预训练。此预训练任务保留了时间序列的原始分布和数据形状。此外，全秩前向和后向注意力矩阵表现出更具表现力的表示能力。使用生物信号数据，BiTimelyGPT 在预测神经功能、疾病诊断和生理体征方面表现出卓越的性能。通过可视化注意力热图，我们观察到预训练的 BiTimelyGPT 可以从时间序列中识别出有区别的片段，在对任务进行微调后更是如此。]]></description>
      <guid>https://arxiv.org/abs/2402.09558</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:34 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习技术检测预防产后尿失禁最有影响力的变量</title>
      <link>https://arxiv.org/abs/2402.09498</link>
      <description><![CDATA[arXiv:2402.09498v1 公告类型：新
【摘要】：背景:产后尿失禁(PUI)是产后女性的常见问题。先前的研究确定了潜在的相关变量，但缺乏对怀孕期间某些内在和外在患者变量的分析。
  目的：本研究旨在利用机器学习评估 PUI 中最有影响力的变量，重点关注内在、外在和组合变量组。
  方法：使用机器学习和过采样技术分析 93 名孕妇的数据。预测了四个关键变量：尿失禁的发生率、频率、强度和压力性尿失禁。
  结果：使用外部变量的模型最准确，尿失禁的准确率为 70%，频率的准确率为 77%，强度的准确率为 71%，压力性尿失禁的准确率为 93%。
  结论：该研究强调外在变量是 PUI 问题的重要预测因素。这表明 PUI 的预防可能可以通过怀孕期间的健康习惯来实现，尽管还需要进一步的研究来证实。]]></description>
      <guid>https://arxiv.org/abs/2402.09498</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>关于智能机器的形式上不可判定的特征</title>
      <link>https://arxiv.org/abs/2402.09500</link>
      <description><![CDATA[arXiv:2402.09500v1 公告类型：新
摘要：以 Alfonseca 等人的工作为基础。 （2021），我们研究了逻辑上可能证明任意人工智能机器将表现出某些行为的必要条件。为此，我们开发了一种形式主义，类似于形式语言及其属性的理论，但在数学上有所不同。我们的形式主义提供了一种精确的手段，不仅可以谈论我们所期望的机器特征（例如它们具有智能性、包容性、道德性等），而且还可以详细说明从逻辑上可能决定机器是否具备的必要条件。给定任意机器是否具有这样的特征。与 Alfonseca 等人（2021）的结果相反，我们发现可计算性理论中的莱斯定理一般不能用于确定任意机器是否具有给定的特征。因此，判断任意机器是否智能、包容、道德等在逻辑上并不一定是不可能的。]]></description>
      <guid>https://arxiv.org/abs/2402.09500</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>数学解释</title>
      <link>https://arxiv.org/abs/2402.09413</link>
      <description><![CDATA[arXiv:2402.09413v1 公告类型：新
摘要：给出了什么才算是数学陈述的解释以及何时一种解释比另一种解释更好的定义。由于所有数学事实在所有因果模型中都必须是真实的，因此被代理所知，因此数学事实不能成为解释的一部分（在解释的标准概念下）。这个问题是用不可能的可能世界来解决的。]]></description>
      <guid>https://arxiv.org/abs/2402.09413</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:32 GMT</pubDate>
    </item>
    </channel>
</rss>