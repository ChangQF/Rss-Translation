<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 人工智能 (cs.AI) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Thu, 30 Nov 2023 03:13:59 GMT</lastBuildDate>
    <item>
      <title>知识驱动的 AutoML 架构。 （arXiv：2311.17124v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.17124</link>
      <description><![CDATA[本文提出了一种知识驱动的 AutoML 架构，用于管道和
深度特征合成。主要目标是渲染 AutoML 流程
可解释并利用领域知识来合成管道和
特征。该架构探索了几个新颖的想法：首先，
管道和深层特征的构建以统一的方式进行。
接下来，综合由共享知识系统驱动，交互式查询
至于要使用哪些管道操作或要计算的功能。最后，
综合过程在运行时使用部分解决方案做出决策，
他们在数据上的应用结果。进行了两个实验
演示所提议的简单实现的功能
架构并讨论其优势、权衡以及未来
AutoML 的潜力。
]]></description>
      <guid>http://arxiv.org/abs/2311.17124</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:59 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的光学字符识别对抗性攻击的脆弱性分析。 （arXiv：2311.17128v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17128</link>
      <description><![CDATA[光学字符识别 (OCR) 的最新进展已得到推动
通过基于变压器的模型。 OCR 系统在许多高风险领域至关重要
域，但它们对对抗性攻击的脆弱性仍然很大
未知领域，引发对安全和合规性的担忧
新兴的人工智能法规。在这项工作中，我们提出了一个新颖的框架来评估
基于 Transformer 的 OCR (TrOCR) 模型的弹性。我们开发和评估
针对目标和非目标攻击的算法。对于非目标情况，
我们测量字符错误率 (CER)，而对于目标情况，我们使用
成功率。我们发现 TrOCR 非常容易受到非目标攻击的影响
攻击，并且不太容易受到针对性攻击。在基准上
手写数据集，无针对性的攻击可以导致CER超过1而无需
肉眼可见。具有相似的扰动大小，有针对性的攻击
可以导致大约 $25\%$ 的成功率——这里我们攻击单个代币，
要求 TrOCR 从大量词汇中输出第十个最可能的标记。
]]></description>
      <guid>http://arxiv.org/abs/2311.17128</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:59 GMT</pubDate>
    </item>
    <item>
      <title>ClimateX：法学硕士能否准确评估人类专家对气候声明的信心？ （arXiv：2311.17107v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.17107</link>
      <description><![CDATA[评估大型语言模型 (LLM) 生成的输出的准确性
在气候科学和政策领域尤其重要。我们介绍
气候声明专家信心 (ClimateX) 数据集，一个新颖的、
精心策划、专家标记的数据集，包含收集的 8094 份气候声明
根据最新的政府间气候变化专门委员会（IPCC）报告，
标有相关的置信水平。使用这个数据集，我们展示了
最近的法学硕士可以对人类专家对气候相关的信心进行分类
陈述，特别是在几次学习的环境中，但有限（最多
47%）准确度。总体而言，模型表现出一致且显着的
对低度和中等置信度声明过度自信。我们强调
我们的结果对气候传播、法学硕士评估的影响
策略，以及法学硕士在信息检索系统中的使用。
]]></description>
      <guid>http://arxiv.org/abs/2311.17107</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:58 GMT</pubDate>
    </item>
    <item>
      <title>XAI 利用图像突出显示方法进行时间序列分类。 （arXiv：2311.17110v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.17110</link>
      <description><![CDATA[尽管在计算机视觉的可解释性方面已经做了很多工作，
自然语言处理（NLP）领域，还有很多工作要做
解释应用于时间序列的方法，因为时间序列本质上是不可能的
第一眼就明白了。在本文中，我们提出了一个深度神经网络
（DNN）在师生架构（蒸馏模型）中提供
时间序列分类任务中的可解释性。我们的可解释性
该方法基于将时间序列转换为二维图并应用
图像突出显示方法（例如 LIME 和 GradCam），进行预测
可解释的。同时，所提出的方法提供了增加
准确性与基线模型竞争，但需要权衡增加
训练时间。
]]></description>
      <guid>http://arxiv.org/abs/2311.17110</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:58 GMT</pubDate>
    </item>
    <item>
      <title>ConTex-Human：通过纹理一致的合成从单个图像中自由观看人体渲染。 （arXiv：2311.17123v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17123</link>
      <description><![CDATA[在这项工作中，我们提出了一种方法来解决渲染 3D 的挑战
以自由观看的方式从单个图像中识别人类。一些现有的方法可以
通过使用可概括的像素对齐隐式字段来实现这一点
重建人体的纹理网格或通过采用 2D 扩散模型作为
使用分数蒸馏采样 (SDS) 方法进行指导，以提升 2D
图像进入 3D 空间。然而，可概括的隐式字段通常会导致
过度平滑的纹理场，而 SDS 方法往往会导致
与输入图像纹理不一致的新颖视图。在本文中，我们
引入纹理一致的后视图合成模块，可以传输
通过深度和文本引导将参考图像内容传递到后视图
注意注射。此外，为了减轻出现的颜色失真
在侧面区域，我们提出了可见性感知的补丁一致性正则化
用于与合成后视图相结合的纹理映射和细化
质地。通过以上技术，我们可以实现高保真度和
从单个图像进行纹理一致的人体渲染。进行的实验
真实数据和合成数据都证明了我们方法的有效性
表明我们的方法优于以前的基线方法。
]]></description>
      <guid>http://arxiv.org/abs/2311.17123</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:58 GMT</pubDate>
    </item>
    <item>
      <title>通过未知数量簇的群落检测进行单细胞多视图聚类。 （arXiv：2311.17103v1 [q-bio.GN]）</title>
      <link>http://arxiv.org/abs/2311.17103</link>
      <description><![CDATA[单细胞多视图聚类使细胞探索成为可能
从不同角度看同一细胞内的异质性。尽管
几种多视图聚类方法的开发，两个主要挑战
坚持。首先，大多数现有方法都会处理来自两者的信息
单细胞 RNA (scRNA) 和转座酶单细胞检测
染色质 (scATAC) 认为同样重要，忽略了实质性
两种观点之间数据丰富程度的差异。这种疏忽经常发生
导致整体性能下降。此外，大多数
聚类方法需要手动指定聚类数量
由用户。然而，对于处理细胞数据的生物学家来说，精确确定
不同细胞类型的数量构成了巨大的挑战。为此，我们
引入 scUNC，这是一种专为以下领域量身定制的创新多视图聚类方法
单细胞数据，无缝集成来自不同视图的信息
不需要预定义数量的簇。 scUNC 方法
包括几个步骤：首先，它采用跨视图融合网络
创建有效的嵌入，然后用于生成初始
通过社区检测进行聚类。随后，簇会自动
合并和优化，直到无法合并更多集群为止。我们进行了一次
使用三个不同的单细胞数据集对 scUNC 进行综合评估。
结果强调 scUNC 优于其他基线方法。
]]></description>
      <guid>http://arxiv.org/abs/2311.17103</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:57 GMT</pubDate>
    </item>
    <item>
      <title>通过双图对齐进行单细胞聚类。 （arXiv：2311.17104v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.17104</link>
      <description><![CDATA[近年来，单细胞RNA测序领域出现了激增
聚类方法的发展。这些方法可以识别
细胞亚群，从而促进对肿瘤的理解
微环境。尽管它们很实用，但大多数现有的聚类算法
主要关注单元矩阵或
细胞之间的网络结构，往往忽略了基因之间的网络。
这种疏忽可能会导致信息和聚类结果的丢失
缺乏临床意义。为了解决这个限制，我们开发了一种先进的
结合双图对齐的单细胞聚类模型，
将基因网络信息整合到基于聚类的过程中
自监督和无监督优化。具体来说，我们设计了一个
通过注意力机制增强的基于图的自动编码器可以有效地
捕获细胞之间的关系。此外，我们执行了node2vec方法
基于蛋白质-蛋白质相互作用（PPI）网络推导基因网络
结构并在整个聚类过程中保持该结构。我们的
通过实验证明所提出的方法是有效的
结果，展示了其优化聚类结果的能力，同时
保留细胞和基因之间的原始关联。这项研究
有助于获得准确的细胞亚群并生成聚类
结果更接近真实世界的生物场景。它提供
更好地了解病变细胞的特征和分布，
最终为疾病的早期诊断和治疗奠定基础。
]]></description>
      <guid>http://arxiv.org/abs/2311.17104</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:57 GMT</pubDate>
    </item>
    <item>
      <title>使用基于贝叶斯网络模型的推理分析进行 5G 中的匿名干扰检测。 （arXiv：2311.17097v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2311.17097</link>
      <description><![CDATA[干扰和入侵检测在 5G 研究中至关重要，旨在
保持可靠性，防止用户体验下降，并避免
基础设施故障。本文介绍一种匿名干扰检测
基于协议栈信号参数的 5G 模型。系统
使用监督和无监督学习来实现实时、高精度
检测干扰，包括未知类型。监督模型达到 AUC
相比之下，AUC 为 0.923 比 1 的 LSTM 模型为 0.964 比 1。然而，
对数据注释的需求限制了监督方法。为了解决这个问题，一个
基于无监督自动编码器的异常检测的 AUC 为
0.987。该方法可以抵抗对抗性训练样本。为了
透明度和领域知识注入，基于贝叶斯网络的因果关系
进行了分析介绍。
]]></description>
      <guid>http://arxiv.org/abs/2311.17097</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>DyRA：用于规模稳健的物体检测的动态分辨率调整。 （arXiv：2311.17098v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17098</link>
      <description><![CDATA[在物体检测中，由于
物体大小的可变性。该问题的一种可能的解决方案是
优化输入分辨率，称为多分辨率策略。以前的
优化分辨率的方法通常基于预定义的分辨率
或动态神经网络，但缺乏对运行时的研究
现有架构的分辨率优化。在本文中，我们提出了一个
称为 DyRA 的自适应分辨率缩放网络，由卷积组成
和变压器编码器块，用于现有检测器。我们的 DyRA 返回
输入图像的比例因子，可实现特定于实例的缩放。这
网络与具有专门设计损失的检测器联合训练
函数，即 ParetoScaleLoss 和 BalanceLoss。 ParetoScaleLoss 产生
图像的自适应比例因子，而 BalanceLoss 则优化
根据数据集的定位能力的比例因子。损失函数
旨在最大限度地减少小型对比物镜的精度下降
和大型物体。我们在 COCO、RetinaNet、Faster-RCNN、FCOS 和
Mask-RCNN 的准确率比之前的模型提高了 1.3%、1.1%、1.3% 和 0.8%。
仅进行分辨率调整的多分辨率基线。代码是
可在 https://github.com/DaEunFullGrace/DyRA.git 获取。
]]></description>
      <guid>http://arxiv.org/abs/2311.17098</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>StreamFlow：视频序列的简化多帧光流估计。 （arXiv：2311.17099v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17099</link>
      <description><![CDATA[连续帧之间的遮挡长期以来一直是一个重大挑战
在光流估计中。遮挡带来的固有歧义
直接违反了亮度恒定性约束并极大地阻碍了
像素到像素的匹配。为了解决这个问题，多帧光流
方法利用相邻帧来减轻局部歧义。尽管如此，
现有的多帧方法主要采用递归流量估计，
导致相当大的计算重叠。相比之下，我们提出一个
简化的批处理框架，消除了大量冗余的需要
递归计算，同时开发有效的时空
批量估计约束下的建模方法。具体来说，我们
提出针对视频量身定制的简化批处理多帧 (SIM) 管道
输入，达到与两帧网络相似的时间效率水平。
此外，我们引入了一种有效的综合时空相干性
(ISC) 有效时空建模的建模方法
编码阶段，不会引入额外的参数开销。
此外，我们设计了一个全局时间回归器（GTR），它可以有效地
探索解码过程中的时间关系。受益于高效的 SIM 卡
StreamFlow 不仅在管道和有效的模块方面表现出色
在具有挑战性的 KITTI 和 Sintel 数据集上的性能，特别是
遮挡区域有所改善，但也达到了显着的 $63.82\%$
与以前的多帧方法相比，速度有所提高。该代码将
即将在 https://github.com/littlespray/StreamFlow 上提供。
]]></description>
      <guid>http://arxiv.org/abs/2311.17099</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>对抗人工智能艺术中的“同质性”：对交互式人工智能装置《击剑幻觉》的思考。 （arXiv：2311.17080v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17080</link>
      <description><![CDATA[文章总结了人工中的三类“相同性”问题
智能（AI）艺术，每一种都发生在人工智能发展的不同阶段
图像创建工具。通过击剑幻觉项目，文章
反思AI艺术制作的设计在缓解
均匀性，保持人工智能图像合成器图像的唯一性，
并增强艺术品与观众之间的联系。这张纸
致力于通过讲述独特的人工智能艺术来激发创作
来自击剑幻觉项目的努力和见解，所有
致力于解决“同一性”问题。
]]></description>
      <guid>http://arxiv.org/abs/2311.17080</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>即插即用、无密集标签地从视觉语言模型中提取开放词汇语义分割。 （arXiv：2311.17095v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17095</link>
      <description><![CDATA[从大量的图像-文本对中，大规模的视觉-语言
模型（VLM）学习隐式地将图像区域与单词相关联，即
对于图像字幕和视觉问答等任务至关重要。
然而，利用这种预先训练的模型来实现开放词汇语义
细分仍然是一个挑战。在本文中，我们提出了一个简单但
极其有效、无需培训的技术、即插即用的开放词汇
用于此任务的语义分割 (PnP-OVSS)。 PnP-OVSS 利用 VLM
直接文本到图像交叉注意力和图像文本匹配损失产生
语义分割。然而，单独的交叉注意力往往会过度细分，
而交叉注意力加上 GradCAM 往往会出现分割不足的情况。为了缓解这种情况
问题，我们引入Salience Dropout；通过迭代地删除补丁
模型是我们最关注的，我们能够更好地解决整个范围
分割掩码。与现有技术相比，所提出的方法
不需要任何神经网络训练并执行超参数调整
不需要任何分段注释，甚至对于验证集也是如此。
PnP-OVSS 与可比较的基线相比有了显着的改进
（Pascal VOC 上 +29.4% MIoU，Pascal 上下文上 +13.2% MIoU，MS 上 +14.0% MIoU
COCO，+2.4% mIoU on COCO Stuff），甚至优于大多数基线
在预训练的 VLM 之上进行额外的网络训练。
]]></description>
      <guid>http://arxiv.org/abs/2311.17095</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>SOFA 评分在预测脓毒症死亡率中的聚类轨迹。 (arXiv:2311.17066v1 [q-bio.QM])</title>
      <link>http://arxiv.org/abs/2311.17066</link>
      <description><![CDATA[目标：败血症是一种危及生命的疾病。继发性器官衰竭
评估（SOFA）评分通常用于评估器官功能障碍和
预测 ICU 死亡率，但它被视为静态测量，无法预测
捕捉动态变化。本研究旨在探讨两者之间的关系
入住 ICU 前 72 小时内 SOFA 评分的动态变化
和患者的结果。

设计、设置和参与者：医疗信息中的 3,253 名患者
符合脓毒症 3 标准并被诊断为重症监护 IV 数据库的 Mart
从急诊科入院且入住 ICU 至少 72 小时
并分析了完全主动复苏状态。基于组的轨迹
使用动态时间扭曲和 k 均值聚类进行建模，识别出不同的
动态 SOFA 分数中的轨迹模式。随后对他们进行了比较
使用Python。

主要结果指标：结果包括医院和 ICU 死亡率、持续时间
住院和 ICU 住院率以及住院期间再次入院率分别为
集。从 ICU 到病房的出院时间以及 7 天和 14 天的截止时间
被带走了。

结果：确定了四个聚类：A（持续较低的 SOFA 分数）、B
（SOFA 分数快速增加，随后下降），C（较高基线
分数逐渐提高）和 D（分数持续升高）。簇
D 的 ICU 和住院时间最长，ICU 和医院死亡率最高。
A 组和 B 组的 ICU 出院率相似，而 C 组的出院率相似
最初的比率相当，但过渡到病房的速度较慢。

结论：监控 SOFA 分数的动态变化对于以下方面很有价值
评估脓毒症的严重程度和治疗反应。
]]></description>
      <guid>http://arxiv.org/abs/2311.17066</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:54 GMT</pubDate>
    </item>
    <item>
      <title>IG Captioner：信息增益字幕器是强大的零样本分类器。 （arXiv：2311.17072v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17072</link>
      <description><![CDATA[生成训练已被证明对于构建非常强大
视觉语言模型。然而，在零样本判别基准上，有
使用生成和训练模型训练的模型之间仍然存在性能差距
歧视性目标。在本文中，我们的目标是通过以下方式缩小这一差距：
提高分类任务生成训练的效率，无需
任何微调过程或附加模块。

具体来说，我们专注于缩小生成字幕之间的差距
和 CLIP 分类器。我们首先分析
标题生成器和分类器，并观察标题生成继承了
使用纯文本模态训练的语言模型的分布偏差，
使其不太依赖于视觉信号。为了解决这个问题，我们
重新设计字幕员的评分目标，以减轻
分布偏差并专注于衡量所带来的信息增益
视觉输入。我们进一步设计一个生成训练目标来匹配
评价目标。我们将训练和评估的模型命名为
作为信息增益（IG）字幕器的新颖程序。我们对模型进行预训练
公共 Laion-5B 数据集并执行一系列判别性评估。
对于 ImageNet 上的零样本分类，IG Captioner 实现了 $&gt; 18\%$
对标准字幕机的改进，实现可比的性能
与 CLIP 分类器。 IG Captioner 也展现了强劲的表现
MSCOCO 和 Flickr30K 上的零样本图像文本检索任务。我们希望这个
论文激发了进一步研究统一生成性和判别性
视觉语言模型的训练程序。
]]></description>
      <guid>http://arxiv.org/abs/2311.17072</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:54 GMT</pubDate>
    </item>
    <item>
      <title>大型多模态模型的组合思想链提示。 （arXiv：2311.17076v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2311.17076</link>
      <description><![CDATA[强大的视觉支柱和大型语言模型（LLM）的结合
推理导致大型多模态模型（LMM）成为当前的
适用于各种视觉和语言 (VL) 任务的标准。然而，最近
研究表明，即使是最先进的 LMM 仍然难以捕获
组合视觉推理的各个方面，例如属性和关系
物体之间。一种解决方案是利用场景图（SG）——一种形式化
对象及其关系和属性，已被广泛用作
视觉和文本领域之间的桥梁。然而，场景图数据需要
场景图注释，收集起来很昂贵，因此不容易
可扩展。此外，基于 SG 数据微调 LMM 可能会导致灾难性的结果
忘记预训练目标。为了克服这个问题，受到启发
思想链方法，我们提出组合思想链（CCoT），
利用SG的新型零样本思想链提示方法
表示以便从 LMM 中提取组合知识。
具体来说，我们首先使用 LMM 生成 SG，然后在中使用该 SG
产生响应的提示。通过大量的实验，我们发现
所提出的 CCoT 方法不仅提高了多个视觉上的 LMM 性能
和语言 VL 组合基准，而且还提高了性能
通用多模式基准上的几个流行的 LMM，无需
微调或带注释的真实 SG。
]]></description>
      <guid>http://arxiv.org/abs/2311.17076</guid>
      <pubDate>Thu, 30 Nov 2023 03:13:54 GMT</pubDate>
    </item>
    </channel>
</rss>