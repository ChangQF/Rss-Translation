<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 12 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>量化布尔贝叶斯网络：逻辑图形模型的理论和实验</title>
      <link>https://arxiv.org/abs/2402.06557</link>
      <description><![CDATA[本文介绍了量化布尔贝叶斯网络（QBBN），它提供了逻辑和概率推理的统一视图。 QBBN 旨在解决大型语言模型 (LLM) 的一个核心问题，该模型在信息检索中非常流行，即 LLM 的幻觉。从结构上看，贝叶斯网络不会产生幻觉，因为它只能返回它可以解释的答案。我们展示了如何配置无限数量布尔变量上的贝叶斯网络来表示人类语言背后的逻辑推理。我们通过创建一阶微积分的键值版本来做到这一点，我们可以证明它的一致性和完整性。我们表明，该模型是在完全观察到的数据上进行的简单训练，但推理并非简单。贝叶斯网络中的精确推理很棘手（即 $\Omega(2^N)$ 对于 $N$ 变量）。为了进行推理，我们研究了循环置信传播（LBP）的使用，它不能保证收敛，但在实践中已被证明经常收敛。我们的实验表明，LBP确实非常可靠地收敛，并且我们的分析表明，一轮LBP需要时间$O(N2^n)$，其中$N$限制了考虑的变量的数量，$n$限制了考虑的变量的数量。任何因素的传入连接，并且可能有进一步的改进。我们的网络专门设计用于在布尔代数中的“与”门和“或”门之间交替，这与逻辑推理联系更紧密，允许为我们网络的扩展版本提供完整性证明，并且还允许推理遵循特定但充分的路径，从而将出去要快。]]></description>
      <guid>https://arxiv.org/abs/2402.06557</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>ACTER：用于解释和诊断 RL 策略的多样化且可操作的反事实序列</title>
      <link>https://arxiv.org/abs/2402.06503</link>
      <description><![CDATA[了解强化学习 (RL) 中的故障如何发生以及如何预防故障对于启用调试、维护用户信任和制定个性化策略是必要的。反事实推理经常被用来通过寻找避免失败的最接近的可能世界来分配责任和理解失败。然而，当前强化学习中的反事实状态解释只能使用当前状态特征来解释结果，并且无法就如何预防负面结果提供可行的资源。在这项工作中，我们提出了 ACTER（用于解释强化学习结果的可操作反事实序列），这是一种生成反事实序列的算法，为如何避免失败提供了可操作的建议。 ACTER 调查导致失败的操作，并使用进化算法 NSGA-II 生成反事实的操作序列，即使在随机环境中，也能以最小的变化和高确定性防止失败。此外，ACTER 生成一组多个不同的反事实序列，使用户能够以最适合他们偏好的方式纠正失败。我们还介绍了三个可用于评估反事实序列多样性的多样性指标。我们在两种 RL 环境中评估 ACTER，包括离散和连续动作，并表明它可以生成可操作且多样化的反事实序列。我们进行了一项用户研究，探索 ACTER 生成的解释如何帮助用户识别和纠正失败。]]></description>
      <guid>https://arxiv.org/abs/2402.06503</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>内省规划：指导支持语言的智能体完善自己的不确定性</title>
      <link>https://arxiv.org/abs/2402.06529</link>
      <description><![CDATA[大型语言模型 (LLM) 展现出先进的推理技能，使机器人能够理解自然语言指令，并通过适当的基础来战略性地规划高级行动。然而，LLM 幻觉可能会导致机器人自信地执行与用户目标不一致的计划，或者在极端情况下是不安全的。此外，自然语言指令中固有的歧义可能会导致任务的不确定性，特别是在存在多个有效选项的情况下。为了解决这个问题，法学硕士必须识别这种不确定性并主动寻求澄清。本文探讨了内省计划的概念，作为一种系统方法，用于指导法学硕士形成机器人任务执行的不确定性感知计划，而无需进行微调。我们研究了任务级机器人规划中的不确定性量化，并证明与最先进的基于 LLM 的规划方法相比，内省显着提高了成功率和安全性。此外，我们评估了内省规划与保形预测相结合的有效性，表明这种组合产生更严格的置信界限，从而通过更少的多余用户澄清查询来维持统计成功保证。]]></description>
      <guid>https://arxiv.org/abs/2402.06529</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>从观察到的数据即时检测根本原因并将其应用于 IT 系统</title>
      <link>https://arxiv.org/abs/2402.06500</link>
      <description><![CDATA[本文介绍了一种专为表示基于阈值的 IT 系统而定制的新结构因果模型，并提出了一种旨在快速检测此类系统中异常的根本原因的新算法。当根本原因不存在因果关系时，该方法被证明是正确的；而基于代理人的干预提出了扩展以放宽这一假设。我们的算法及其基于代理的扩展利用离线数据的因果发现，并在遇到在线数据中的新异常时进行子图遍历。我们的大量实验证明了我们的方法的卓越性能，即使应用于从替代结构因果模型或真实 IT 监控数据生成的数据。]]></description>
      <guid>https://arxiv.org/abs/2402.06500</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>基于人类审美偏好的大型文本到图像模型个性化：以康定斯基一代为例</title>
      <link>https://arxiv.org/abs/2402.06389</link>
      <description><![CDATA[随着神经生成能力的进步，艺术界积极采用 GenAI（生成人工智能）来创作绘画内容。大型文本到图像模型可以快速生成美观的结果。然而，这个过程可能是不确定的，并且经常涉及繁琐的试错，因为用户很难制定有效的提示来实现他们想要的结果。本文介绍了一种无提示生成方法，使用户能够自动生成个性化的绘画内容，将他们的审美偏好融入定制的艺术风格中。这种方法涉及利用“语义注入”来定制特定艺术风格的艺术家模型，并进一步利用遗传算法通过实时迭代的人类反馈来优化提示生成过程。通过仅仅依靠用户的审美评价和对艺术家模型生成的图像的偏好，这种方法为用户创建了包含他们的审美偏好和定制的艺术风格的个性化模型。]]></description>
      <guid>https://arxiv.org/abs/2402.06389</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>朱斯蒂齐亚的婚礼。人工智能、法律、逻辑、语言和计算之间的相互作用以及交通法规和医疗保健的一些案例研究</title>
      <link>https://arxiv.org/abs/2402.06487</link>
      <description><![CDATA[本文的一个重要目的是向使用人工智能的法律界传达数理逻辑的一些基础知识。在分析了人工智能是什么之后，我们决定将自己界定为基于规则的人工智能，而将神经网络和机器学习放在一边。基于规则的人工智能允许以基本形式描述的形式方法。然后我们将看到数理逻辑如何与基于法律规则的人工智能实践相互作用。我们将看到数理逻辑如何给人工智能应用带来限制和复杂性。我们将数理逻辑和法律人工智能之间的局限性和相互作用分为三类：逻辑、计算和数学。展示交互作用的示例主要来自欧洲交通法规。论文最后对人工智能的使用方式和地点以及塑造社会的基本机制进行了一些思考。]]></description>
      <guid>https://arxiv.org/abs/2402.06487</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>快速学习时间交互图</title>
      <link>https://arxiv.org/abs/2402.06326</link>
      <description><![CDATA[时间交互图（TIG）被广泛用于表示现实世界的系统。为了促进 TIG 的表征学习，研究人员提出了一系列 TIG 模型。然而，这些模型在“预训练，预测”训练范式中仍然面临着预训练和下游预测之间的两个巨大差距。首先，预训练和推理数据之间的时间差异严重损害了模型在动态演变数据的遥远未来预测中的适用性。其次，借口和下游任务之间的语义分歧阻碍了它们的实际应用，因为它们很难在跨应用场景中保持学习和预测能力。
  最近，“预训练、提示”范式已经成为模型泛化的轻量级机制。应用这种范式是解决上述挑战的潜在解决方案。然而，将此范例应用于 TIG 并不简单。由于缺乏对时间敏感动态的考虑和表达能力的缺乏，静态图上下文中的提示应用在时间设置上存在不足。为了解决这个问题，我们引入了时间交互图提示（TIGPrompt），这是一个与 TIG 模型无缝集成的多功能框架，弥合了时间和语义差距。详细地说，我们提出了一个时间提示生成器，为不同的任务提供时间感知的提示。这些提示因其简约的设计而脱颖而出，仅依靠提示生成器的调整而很少有监督数据。为了满足不同的计算资源需求，我们提出了一种扩展的“预训练、基于提示的微调”范例，提供了更大的灵活性。通过大量的实验，TIGPrompt 展示了 SOTA 性能和显着的效率优势。]]></description>
      <guid>https://arxiv.org/abs/2402.06326</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>为人工智能推理建模人类价值观</title>
      <link>https://arxiv.org/abs/2402.06359</link>
      <description><![CDATA[当今最重大的社会挑战之一是构建人工智能系统，其行为或它在交互代理（人类和人工）社区内实现的行为符合人类价值观。为了应对这一挑战，我们详细介绍了人类价值观的正式模型，以实现其明确的计算表示。据我们所知，目前还没有尝试过这种做法，考虑到人工智能中整合价值的研究数量不断增加，这一点令人惊讶。以过去几十年来从社会心理学研究人类价值观本质的大量研究为出发点，我们着手提供这样一个正式的模型。我们展示了该模型如何为基于人工智能的值推理提供基础工具，并证明其在实际用例中的适用性。我们说明了我们的模型如何捕捉社会心理学研究的关键思想，并为未来人工智能中人类价值的综合、跨学科研究提出了路线图。自动推理价值观的能力不仅有助于解决价值观一致问题，而且有助于人工智能系统的设计，支持个人和社区做出更明智、价值观一致的决策。越来越多的个人和组织有动力更明确地理解他们的价值观，并探索他们的行为和态度是否正确反映了这些价值观。我们在人类价值观建模方面的工作将使人工智能系统的设计和部署能够满足这一不断增长的需求。]]></description>
      <guid>https://arxiv.org/abs/2402.06359</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>DeAL：大型语言模型的解码时间对齐</title>
      <link>https://arxiv.org/abs/2402.06147</link>
      <description><![CDATA[如今，大型语言模型（LLM）有望生成符合人类偏好的内容。目前的工作重点是通过人类反馈强化学习（RLHF）等技术在模型训练时进行对齐。然而，尚不清楚此类方法是否是向模型教授对齐目标的有效选择。首先，无法整合多种自定义奖励以及依赖模型开发人员对通用和静态原则的看法是主要限制。其次，模型训练中的剩余差距和此类方法的可靠性也值得怀疑（例如，即使在安全训练之后也容易越狱）。为了解决这些问题，我们提出了 DeAL，这是一个允许用户自定义奖励函数并启用 LLM 解码时间对齐 (DeAL) 的框架。从本质上讲，我们将解码视为启发式引导的搜索过程，并促进使用各种对齐目标。我们对关键字和长度约束等程序性约束（在LLM之前时代广泛研究）和无害性和有用性（在后LLM时代提出）等抽象目标的实验表明，我们可以通过细粒度的权衡来进行DeAL ，提高对调整目标的遵守，并解决法学硕士的剩余差距。最后，虽然 DeAL 可以有效地与 RLHF 和提示技术配合使用，但它的通用性使得解码速度变慢，这是我们留给未来工作的优化。]]></description>
      <guid>https://arxiv.org/abs/2402.06147</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>LLaVA-Docent：利用多模态大语言模型进行指令调整以支持艺术欣赏教育</title>
      <link>https://arxiv.org/abs/2402.06264</link>
      <description><![CDATA[艺术欣赏对于培养学习者的批判性思维和情商至关重要。然而，传统的艺术欣赏教育往往受到艺术资源有限的阻碍，尤其是对于弱势学生而言，以及主流教育对STEM科目的重视不平衡。为了应对这些挑战，最近的技术进步为创新解决方案铺平了道路。本研究探讨了多模态大语言模型 (MLLM) 在艺术欣赏教育中的应用，重点开发 LLaVA-Docent，这是一个利用这些进步的模型。我们的方法涉及全面的文献综述以及与该领域专家的咨询，从而开发出强大的数据框架。利用这个框架，我们生成了 GPT-4 使用的虚拟对话数据集。该数据集在训练 MLLM（名为 LLaVA-Docent）方面发挥了重要作用。六名研究人员对 LLaVA-Docent 进行了定量和定性评估，以评估其有效性，并在几次设置中将其与 GPT-4 模型进行基准测试。评估过程揭示了 LLaVA-Docent 模型的明显优点和缺点。我们的研究结果强调了 LLaVA-Docent 在提高艺术欣赏教育的可及性和参与度方面的功效。通过利用 MLLM 的潜力，这项研究为艺术教育领域做出了重大贡献，提出了一种新颖的方法，重新构想了艺术欣赏的教学和体验方式。]]></description>
      <guid>https://arxiv.org/abs/2402.06264</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>TWIG：通过模拟 KGE 模型实现事前超参数优化和跨图泛化</title>
      <link>https://arxiv.org/abs/2402.06097</link>
      <description><![CDATA[在本文中，我们介绍了 TWIG（拓扑加权智能生成），这是一种新颖的无嵌入范例，用于使用一小部分参数来模拟 KGE 的输出。 TWIG 从由图数据的拓扑特征组成的输入中学习权重，无需对实体或边的潜在表示进行编码。我们在 UMLS 数据集上的实验表明，单个 TWIG 神经网络可以在所有超参数配置上几乎准确地预测最先进的 ComplEx-N3 KGE 模型的结果。为此，它总共使用了 2590 个可学习参数，但可以准确预测 1215 个不同超参数组合的结果，总成本为 29,322,000 个参数。基于这些结果，我们提出两个主张：1）KGE 不学习潜在语义，而只学习结构模式的潜在表示； 2) KGE 中的超参数选择是 KGE 模型和图结构的确定性函数。我们进一步假设，由于 TWIG 可以在没有嵌入的情况下模拟 KGE，因此不需要学习节点和边嵌入来准确预测 KG 中的新事实。最后，我们在“结构泛化假设”的框架下阐述了我们的所有发现，该假设表明“twiggy”无嵌入/基于数据结构的学习方法可以允许单个神经网络模拟 KGE 性能，并且也许可以解决来自不同领域和具有不同语义的许多知识图谱的链接预测任务。]]></description>
      <guid>https://arxiv.org/abs/2402.06097</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>Veni、Vidi、Vici：解决知识图学习之前的无数挑战</title>
      <link>https://arxiv.org/abs/2402.06098</link>
      <description><![CDATA[知识图（KG）在表示大规模链接数据方面变得越来越普遍。然而，它们的巨大规模需要图学习系统来帮助人类进行分析、解释和模式检测。虽然通过各种知识图谱学习系统为研究人员和临床医生赋权已经取得了有希望的结果，但我们发现了最先进的图形学习中的四个关键缺陷，这些缺陷同时限制了知识图谱学习性能并削弱了人类交互的能力通过这些学习系统达到最佳效果。这些缺陷是：1）缺乏专家知识整合；2）知识图谱中节点度极值不稳定；3）学习时缺乏对不确定性和相关性的考虑；4）缺乏可解释性。此外，我们描述了解决每个问题的最先进的尝试，并注意到每个尝试在很大程度上都与解决其他问题的尝试隔离。通过对这些问题的形式化以及对解决这些问题的文献的回顾，我们采取的立场是，这四个关键领域的缺陷不仅阻碍了人类知识图谱的赋权，而且解决这些问题的分而治之的方法也阻碍了人类知识图谱的赋权。作为个体单位而不是整体是人类和 KG 学习系统之间接口的重大障碍。我们认为，只有通过综合、整体的解决方案来解决知识学习系统的局限性，才能有效地影响人类和知识学习的共同赋权。最后，我们提出了“Veni、Vidi、Vici”框架，该框架为在知识图谱学习和更广泛的机器学习领域有效且高效地转向整体共同赋权模型制定了路线图。]]></description>
      <guid>https://arxiv.org/abs/2402.06098</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>用自然语言和概率推理进行实验和修改规则</title>
      <link>https://arxiv.org/abs/2402.06025</link>
      <description><![CDATA[我们建立了一个人类如何通过实验主动推断隐藏规则的计算模型。该模型背后的基本原理是，即使规则是确定性的，学习器也会考虑更广泛的模糊概率规则空间（用自然语言表示），并在每次实验后根据近似贝叶斯原理在线更新其假设。在同一框架中，我们还根据信息论标准对实验设计进行建模。我们发现，明确假设、概率规则和在线更新这三个原则的结合可以解释人类在 Zendo 风格任务中的表现，并且删除任何这些组件都会使模型无法解释数据。]]></description>
      <guid>https://arxiv.org/abs/2402.06025</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>OpenToM：评估大型语言模型心智推理能力的综合基准</title>
      <link>https://arxiv.org/abs/2402.06044</link>
      <description><![CDATA[神经心理理论 (N-ToM) 是机器理解和跟踪他人心理状态的能力，对于开发社交智能体至关重要。然而，流行的 N-ToM 基准有几个缺点，包括存在模糊和人为的叙述、缺乏人格特征和偏好、缺乏针对人物心理状态的问题以及所提出问题的多样性有限。针对这些问题，我们构建了 OpenToM，一个评估 N-ToM 的新基准，具有（1）更长且更清晰的叙事故事，（2）具有明确个性特征的角色，（3）由角色意图触发的动作，以及（ 4) 旨在挑战法学硕士模拟人物生理和心理世界心理状态的能力的问题。使用 OpenToM，我们发现最先进的法学硕士在模拟物理世界中心理状态的某些方面方面表现出色，但在跟踪心理世界中角色的心理状态时却表现不佳。]]></description>
      <guid>https://arxiv.org/abs/2402.06044</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在人类辩论中的局限性</title>
      <link>https://arxiv.org/abs/2402.06049</link>
      <description><![CDATA[大型语言模型 (LLM) 在与人类熟练交互的能力方面表现出了非凡的前景。随后，它们在涉及对话的社会学实验中作为人工同盟者和代理人的潜在用途是一个令人兴奋的前景。但这个想法的可行性如何？本文试图通过一项预先注册的研究来测试当前法学硕士的局限性，该研究将真实的人和充当人的法学硕士代理人结合起来。该研究重点关注三种环境中基于辩论的意见共识形成：仅人类、代理人与人类、以及仅代理人。我们的目标是了解 LLM 代理人如何影响人类，以及他们像人类一样进行辩论的能力如何。我们发现法学硕士可以融入并促进人类生产力，但在辩论中缺乏说服力，他们的行为最终偏离了人类的行为。我们阐明了这些主要缺陷，并预计法学硕士必须进一步发展才能成为可行的辩论者。]]></description>
      <guid>https://arxiv.org/abs/2402.06049</guid>
      <pubDate>Mon, 12 Feb 2024 06:16:43 GMT</pubDate>
    </item>
    </channel>
</rss>