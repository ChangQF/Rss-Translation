<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 19 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>HyperAgent：适用于复杂环境的简单、可扩展、高效且可证明的强化学习框架</title>
      <link>https://arxiv.org/abs/2402.10228</link>
      <description><![CDATA[arXiv:2402.10228v1 公告类型：交叉
摘要：为了解决资源限制下的复杂任务，强化学习（RL）代理需要简单、高效且可扩展，具有（1）大的状态空间和（2）不断积累的交互数据。我们提出了 HyperAgent，这是一种具有超模型、索引采样方案和增量更新机制的 RL 框架，能够在超越共轭的一般值函数近似下实现计算高效的顺序后验逼近和数据高效的动作选择。 \HyperAgent 的实现很简单，只在 DDQN 的基础上添加了一个模块和一行代码。实际上，HyperAgent 在大规模深度 RL 基准测试中展示了其强大的性能，并在数据和计算方面显着提高了效率。理论上，在实际可扩展的算法中，HyperAgent 是第一个在表格强化学习下实现可证明可扩展的每步计算复杂度以及亚线性遗憾的方法。我们理论分析的核心是序贯后验近似论证，它是通过序贯随机投影的第一个分析工具（约翰逊-林登斯特劳斯引理的非平凡鞅扩展）而成为可能的。这项工作弥合了 RL 的理论和实践领域，为 RL 算法设计建立了新的基准。]]></description>
      <guid>https://arxiv.org/abs/2402.10228</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>使用多样性搜索发现元胞自动机中的感觉运动机构</title>
      <link>https://arxiv.org/abs/2402.10236</link>
      <description><![CDATA[arXiv:2402.10236v1 公告类型：交叉
摘要：人工生命研究领域研究诸如自创生、代理或自我调节等类生命现象如何在计算机模拟中自组织。在元胞自动机（CA）中，一个关键的悬而未决的问题是是否有可能找到环境规则，从初始状态自组织鲁棒的“个体”，而无需事先存在“身体”、“大脑”、 “感知”或“行动”。在本文中，我们利用机器学习的最新进展，结合多样性搜索、课程学习和梯度下降的算法，自动搜索此类“个体”，即能够以一致的方式移动的局部结构外部障碍并保持其完整性，因此是感觉运动机构的原始形式。我们表明，这种方法能够系统地发现 CA 中的环境条件，从而导致这种基本形式的代理的自组织。通过多次实验，我们表明，所发现的智能体具有令人惊讶的强大能力，可以移动、保持身体完整性以及在各种障碍物中导航。它们还表现出强大的泛化能力，对规模变化、随机更新或训练期间未见的环境扰动具有鲁棒性。我们讨论这种方法如何为人工智能和合成生物工程开辟新的视角。]]></description>
      <guid>https://arxiv.org/abs/2402.10236</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么问题的动态观点</title>
      <link>https://arxiv.org/abs/2402.10240</link>
      <description><![CDATA[arXiv:2402.10240v1 公告类型：交叉
摘要：我们解决随机过程生成的多元时间序列数据中的因果推理。现有的方法很大程度上局限于静态设置，忽略了随时间变化的连续性和发射。相反，我们提出了一种学习范式，可以直接建立时间过程中事件之间的因果关系。我们提出了两个关键引理来计算因果贡献并将其构建为强化学习问题。我们的方法提供了形式和计算工具，用于揭示和量化扩散过程中的因果关系，包含各种重要设置，例如离散时间马尔可夫决策过程。最后，在相当复杂的实验中，通过纯粹的学习，我们的框架揭示并量化了因果联系，否则这些联系似乎难以解释。]]></description>
      <guid>https://arxiv.org/abs/2402.10240</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>通过深度强化学习的自动驾驶车辆巡逻：学习沟通与合作</title>
      <link>https://arxiv.org/abs/2402.10222</link>
      <description><![CDATA[arXiv:2402.10222v1 公告类型：交叉
摘要：自动驾驶车辆适用于连续区域巡逻问题。由于未知的环境因素（例如风或景观），寻找最佳的巡逻策略可能具有挑战性；或自动驾驶汽车的限制，例如有限的电池寿命或硬件故障。重要的是，大面积巡逻通常需要多个特工共同协调行动。然而，由于巡逻环境的复杂性，手动定义最佳协调策略通常并不容易。在本文中，我们考虑了具有环境因素、代理限制和三个典型合作问题——避免碰撞、避免拥塞和巡逻目标协商的巡逻问题。我们提出了一种基于强化智能体间学习（RIAL）方法的多智能体强化学习解决方案。通过这种方法，代理经过培训，可以开发自己的通信协议，以便在可能且确实发生故障的巡逻过程中进行合作。该方案通过仿真实验进行了验证，并从不同角度与几种最先进的巡逻解决方案进行了比较，包括整体巡逻性能、防撞性能、电池充电策略效率和整体容错能力。]]></description>
      <guid>https://arxiv.org/abs/2402.10222</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>具有波纹下降规则的以人为中心的目标推理</title>
      <link>https://arxiv.org/abs/2402.10224</link>
      <description><![CDATA[arXiv:2402.10224v1 公告类型：交叉
摘要：ActorSim 是海军研究实验室开发的目标推理框架。最初，所有目标推理规则都是手工制定的。这项工作扩展了 ActorSim 的通过演示学习的能力，也就是说，当人类训练者不同意系统做出的决定时，训练者可以接管并向系统展示正确的决定。学习组件使用 Ripple-Down Rules (RDR) 来构建新的决策规则，以便将来正确处理类似情况。该系统使用 RoboCup 救援代理模拟进行演示，该模拟模拟全市范围的灾难，需要将包括消防、救护车和警察在内的紧急服务派遣到不同地点，将平民从危险情况中疏散。 RDR 使用脚本语言 FrameScript 实现，该语言用于在 ActorSim 和代理模拟器之间进行协调。使用 Ripple-Down 规则，ActorSim 可以比之前的版本扩大一个数量级的目标。]]></description>
      <guid>https://arxiv.org/abs/2402.10224</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型的可解释性：从数据适应性到用户感知</title>
      <link>https://arxiv.org/abs/2402.10888</link>
      <description><![CDATA[arXiv:2402.10888v1 公告类型：新
摘要：本文探讨了为已部署的机器学习模型生成局部解释，旨在考虑数据和用户需求，确定产生有意义的解释的最佳条件。主要目标是开发为任何模型生成解释的方法，同时确保这些解释忠实于底层模型并且可供用户理解。
  论文分为两部分。第一个增强了广泛使用的基于规则的解释方法。然后介绍了一种新方法来评估线性解释对近似模型的适用性。此外，它还对两种反事实解释方法进行了比较实验，以分析一种方法相对于另一种方法的优势。第二部分侧重于用户实验，以评估三种解释方法和两种不同表示的影响。这些实验根据解释和表示来衡量用户如何在理解和信任方面感知他们与模型的交互。这项研究有助于生成更好的解释，对提高已部署的人工智能系统的透明度、可信度和可用性具有潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2402.10888</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>WiMANS：基于 WiFi 的多用户活动传感的基准数据集</title>
      <link>https://arxiv.org/abs/2402.09430</link>
      <description><![CDATA[arXiv:2402.09430v1 公告类型：交叉
摘要：基于 WiFi 的人体感应在以非侵入式和无设备的方式分析用户行为方面表现出了巨大的潜力，使智能家居和医疗保健等多种应用受益。然而，之前的大多数工作都集中在单用户感知上，在涉及多用户的场景中实用性有限。尽管最近的研究已经开始研究基于 WiFi 的多用户活动传感，但仍然缺乏基准数据集来促进可重复和可比较的研究。为了弥补这一差距，据我们所知，我们推出了 WiMANS，这是第一个基于 WiFi 的多用户活动传感数据集。 WiMANS 包含超过 9.4 小时的 WiFi 信道状态信息 (CSI)，监控多个用户在各种环境中同时执行的活动。与现有数据集相比，WiMANS不仅收集双WiFi频段的CSI，还包括同步视频。我们利用 WiMANS 对最先进的基于 WiFi 的人体传感模型和基于视频的模型的性能进行基准测试，为基于 WiFi 的多用户识别、定位和活动识别带来新的挑战和机遇。我们相信 WiMANS 可以突破当前基于 WiFi 的人体传感的界限，并促进多用户活动分析的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.09430</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>使用展开网络对归纳偏差进行聚类</title>
      <link>https://arxiv.org/abs/2402.10213</link>
      <description><![CDATA[arXiv:2402.10213v1 公告类型：交叉
摘要：经典的稀疏编码（SC）模型将视觉刺激表示为一些学习基函数的线性组合，这些基函数在自然图像数据上训练时类似于 Gabor。然而，通过经典稀疏编码学习的类 Gabor 滤波器远远高估了经验观察到的经过良好调整的简单细胞感受野轮廓。虽然神经元放电稀疏，但神经元群体也根据其对某些特征的敏感性在物理空间中进行组织。在 V1 中，该组织是沿着皮质片的方向的平滑进展。许多后续模型要么完全放弃了稀疏字典学习框架，要么其更新尚未利用展开的神经字典学习架构的激增。这些更新缺少的一个关键主题是\emph{结构化稀疏}的更强概念。我们提出了一种自动编码器架构（WLSC），其潜在表示通过二部图的拉普拉斯二次形式隐式地局部组织用于谱聚类，它生成一组多样化的人工感受野，与 V1 中的灵长类数据一样忠实地匹配最近的对比框架像局部低维，或 LLD \citep{lld} 丢弃稀疏字典学习。通过我们的自动编码器统一早期视觉皮层模型中的稀疏和平滑编码，我们还表明我们的正则化可以解释为感受野对某些类别刺激的早期专门化；也就是说，我们对皮层的后期阶段引入了弱聚类偏差，其中已知会发生功能和空间隔离（即地形）。结果表明，感受野和发射率的 \emph{空间正则化} 必须开始描述 V1 及更高版本中的特征解缠结。]]></description>
      <guid>https://arxiv.org/abs/2402.10213</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>从状态跟踪中学习规划行动模型</title>
      <link>https://arxiv.org/abs/2402.10726</link>
      <description><![CDATA[arXiv:2402.10726v1 公告类型：新
摘要：以前从状态跟踪中学习的 STRIPS 域模型获取方法从要学习的动作的名称和参数开始。因此，他们唯一的任务是推断给定行动的前提和效果。在这项工作中，我们探索在未提供学习动作参数的情况下的学习。我们根据提供的信息定义了两个级别的跟踪质量，并为每个级别提供了一种算法。在一级（L1）中，轨迹中的状态标有动作名称，因此我们可以推断出动作的数量和名称，但我们仍然需要计算出参数的数量和类型。在另一个级别（L2）中，状态还用构成相应扎根动作参数的对象进行标记。这里我们仍然需要推断学习到的动作中的参数类型。我们通过实验评估所提出的算法，并在大量 IPC 基准测试中将其与最先进的学习工具 FAMA 进行比较。评估表明，我们的新算法速度更快，可以处理更大的输入，并在学习动作模型与参考模型更相似方面提供更好的结果。]]></description>
      <guid>https://arxiv.org/abs/2402.10726</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>关于解释不公平：概述</title>
      <link>https://arxiv.org/abs/2402.10762</link>
      <description><![CDATA[arXiv:2402.10762v1 公告类型：新
摘要：算法公平性和可解释性是实现负责任的人工智能的基本要素。在本文中，我们重点关注它们的相互作用，这是一个最近受到越来越多关注的研究领域。为此，我们首先提出两个综合分类法，每个分类法代表两个互补的研究领域之一：公平性和解释。然后，我们将公平性的解释分为三类：（a）增强公平性指标的解释，（b）帮助我们理解（不）公平的原因的解释，以及（c）帮助我们设计减轻不公平性的方法的解释。最后，基于我们的公平性和解释分类法，我们提出了未被发现的文献路径，揭示了可以为未来研究提供有价值见解的差距。]]></description>
      <guid>https://arxiv.org/abs/2402.10762</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>鲁棒代理学习因果世界模型</title>
      <link>https://arxiv.org/abs/2402.10877</link>
      <description><![CDATA[arXiv:2402.10877v1 公告类型：新
摘要：长期以来，人们一直认为因果推理在稳健和通用智能中发挥着基础作用。然而，尚不清楚智能体是否必须学习因果模型才能推广到新领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布变化下满足后悔界限的智能体都必须学习数据生成过程的近似因果模型，该模型收敛到最佳智能体的真实因果模型。我们讨论了这一结果对包括迁移学习和因果推理在内的几个研究领域的影响。]]></description>
      <guid>https://arxiv.org/abs/2402.10877</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>关于贝叶斯心理理论信仰的基础语言</title>
      <link>https://arxiv.org/abs/2402.10416</link>
      <description><![CDATA[arXiv:2402.10416v1 公告类型：新
摘要：尽管信念是无法直接观察到的心理状态，但人类经常谈论彼此的信念，经常使用丰富的组合语言来描述他人的想法和知识。如何解释这种解释其他心灵隐藏的认知内容的能力？在本文中，我们通过将信念陈述的语义建立在贝叶斯心理理论的基础上，朝着答案迈出了一步：通过建模人类如何共同推断解释代理行为的连贯目标、信念和计划集，然后评估通过认知逻辑对主体信念的陈述与这些推论进行比较，我们的框架为信念提供了概念角色语义，解释了人类信念归因的分级性和组合性，以及它们与目标和计划的密切联系。我们通过研究人类如何归因目标和信念来评估这个框架，同时观察智能体解决需要对隐藏对象进行工具推理的门和钥匙网格世界难题。与纯粹的逻辑演绎、非心智化基线和忽略工具计划作用的心智化相比，我们的模型更适合人类目标和信念归因，证明了心智理论对于信念语义的重要性。]]></description>
      <guid>https://arxiv.org/abs/2402.10416</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>AutoSAT：通过大型语言模型自动优化 SAT 求解器</title>
      <link>https://arxiv.org/abs/2402.10705</link>
      <description><![CDATA[arXiv:2402.10705v1 公告类型：新
摘要：启发式算法在 SAT 求解器中至关重要，但没有任何启发式规则适用于所有问题实例。因此，通常需要针对特定​​问题实例改进特定的求解器。在这种背景下，我们提出了 AutoSAT，一种用于自动优化 SAT 求解器中启发式算法的新颖框架。 AutoSAT 基于大型模型 (LLM)，能够自动生成代码、进行评估，然后利用反馈进一步优化启发式方法，从而减少人为干预并增强求解器能力。 AutoSAT 在即插即用的基础上运行，无需进行大量的初步设置和模型训练，并培育具有容错能力的思想链协作流程，确保稳健的启发式优化。对冲突驱动子句学习 (CDCL) 求解器的大量实验证明了 AutoSAT 的整体优越性能，特别是在解决一些特定 SAT 问题实例方面。]]></description>
      <guid>https://arxiv.org/abs/2402.10705</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>云厨房：使用基于规划的复合人工智能来优化食品配送流程</title>
      <link>https://arxiv.org/abs/2402.10725</link>
      <description><![CDATA[arXiv:2402.10725v1 公告类型：新
摘要：全球食品配送市场为基于人工智能的服务提供了许多机会，可以提高世界粮食供应的效率。本文将云厨房平台作为提供送餐服务的餐厅的决策工具和评估决策影响的模拟器。该平台由技术专用桥 (TSB) 组成，提供与餐厅或模拟器进行通信的接口。 TSB 使用 PDDL 模型来表示嵌入在统一规划框架 (UPF) 中的决策。决策涉及将客户的订单分配给车辆以及决定为客户提供服务的顺序（针对每辆车），这是通过带有时间窗的车辆路由问题 (VRPTW) 完成的，VRPTW 是解决此问题的有效工具。我们证明，我们的平台做出的决策可以通过使用真实世界的历史数据集减少延迟交货的数量来提高客户满意度。]]></description>
      <guid>https://arxiv.org/abs/2402.10725</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络结构化数据编码实验</title>
      <link>https://arxiv.org/abs/2402.10290</link>
      <description><![CDATA[arXiv:2402.10290v1 公告类型：新
摘要：该项目的目标是创建一个能够在称为“Battlespace”的游戏域中选择良好动作的人工智能代理。像战场空间这样的顺序域是规划问题的重要测试平台，因此，国防部使用此类域进行兵棋推演。我们开发的代理结合了蒙特卡罗树搜索 (MCTS) 和深度 Q 网络 (DQN) 技术，旨在导航游戏环境、避开障碍物、与对手交互并夺取旗帜。本文将重点介绍我们探索的编码技术，以呈现存储在 Python 类中的复杂结构化数据，这是代理的必要先驱。]]></description>
      <guid>https://arxiv.org/abs/2402.10290</guid>
      <pubDate>Mon, 19 Feb 2024 06:17:42 GMT</pubDate>
    </item>
    </channel>
</rss>