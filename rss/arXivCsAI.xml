<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 人工智能 (cs.AI) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Wed, 06 Dec 2023 03:14:17 GMT</lastBuildDate>
    <item>
      <title>图生成的简单且可扩展的表示。 （arXiv：2312.02230v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02230</link>
      <description><![CDATA[最近，人们对利用神经网络进行研究的兴趣激增
图生成，一个基本的统计学习问题，具有关键性
分子设计和社区分析等应用。然而，大多数
方法在生成大规模数据时遇到重大限制
图表。这是因为他们要求输出完整的邻接矩阵
其大小随节点数量呈二次方增长。对此作出回应
挑战，我们引入了一种新的、简单的、可扩展的图形表示，名为
间隙编码边缘列表 (GEEL)，具有较小的对齐表示大小
与边数。此外，GEEL 显着降低了
通过结合间隙编码和带宽限制来实现词汇量大小
计划。 GEEL 可以通过结合节点自回归生成
位置编码，我们进一步扩展 GEEL 来处理属性图
通过设计新的语法。我们的研究结果表明，采用这种
紧凑的表示不仅增强了可扩展性，而且还支持
通过简化图形生成过程来提高性能。我们进行
十个非归因图和两个分子图的综合评价
生成任务，证明了 GEEL 的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02230</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>JarviX：用于表格数据分析和优化的 LLM 无代码平台。 （arXiv：2312.02213v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02213</link>
      <description><![CDATA[在这项研究中，我们介绍了 JarviX，一个复杂的数据分析框架。
JarviX 旨在采用大型语言模型 (LLM) 来促进
自动指导并对表格数据集执行高精度数据分析。
该框架强调不同列类型的重要性，
利用最先进的法学硕士来生成简明的数据洞察力
总结、提出相关分析查询、有效地可视化数据，以及
对从大量数据中得出的结果提供全面的解释
分析管道。此外，JarviX 还集成了自动化机器学习
用于预测建模的 (AutoML) 管道。这种整合形成了
全面且自动化的优化周期，这证明特别
有利于优化机器配置。功效与
JarviX的适应性通过一系列实际用例得到证实
学习。
]]></description>
      <guid>http://arxiv.org/abs/2312.02213</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>用于开发基于人工智能的帕金森病语音评估的合成数据生成技术（比较研究）。 （arXiv：2312.02229v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.02229</link>
      <description><![CDATA[言语和语言的变化是帕金森氏症的最初迹象之一
疾病（PD）。因此，临床医生试图从以下方面识别患有 PD 的个体：
多年来他们的声音。医生可以利用基于人工智能的言语评估来
得益于人工智能 (AI) 的进步，可以发现 PD。这样的人工智能系统
可以使用经过训练的机器学习分类器进行开发
使用个人的声音。尽管多项研究表明合理
开发此类人工智能系统的结果，这些系统将需要更多数据
样品以实现有希望的性能。本文探讨了利用深度
基于学习的数据生成技术对机器学习准确性的影响
分类器是此类系统的核心。
]]></description>
      <guid>http://arxiv.org/abs/2312.02229</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>真实世界视觉数据集中自动错误标签检测的实证研究。 （arXiv：2312.02200v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02200</link>
      <description><![CDATA[计算机视觉的重大进步主要归功于使用
标记数据集。然而，获取数据集的标签通常会导致
可能损害模型性能的错误。最近的工作提出了方法
自动识别错误标记的图像，但制定策略
在现实世界的数据集中有效地实施它们的探索很少。
改进以数据为中心的方法来清理现实世界视觉数据集，
我们最近首先进行了200多个实验，仔细进行了基准测试
在多个数据集上开发了自动错误标签检测方法
具有不同噪声水平的各种合成和真实噪声设置。我们
将这些方法与简单高效的错误标签检测器 (SEMD) 进行比较
我们精心设计，发现 SEMD 的表现与之前的相似或优于之前的
错误标签检测方法。然后我们将 SEMD 应用于多个现实世界
计算机视觉数据集并测试数据集大小、错误标签删除策略、
错误标签去除量进一步影响再训练后的模型性能
关于清理后的数据。通过仔细设计该方法，我们发现错误标签
移除后，每类的性能提升最多可达重新训练的 8%
较小数据范围内的分类器。
]]></description>
      <guid>http://arxiv.org/abs/2312.02200</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>长篇问答的公理偏好模型。 （arXiv：2312.02206v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.02206</link>
      <description><![CDATA[像 GPT-4 这样的大型语言模型（LLM）的卓越能力部分
源于训练后过程，例如人类强化学习
反馈（RLHF）涉及奖励模型中编码的人类偏好。然而，
这些奖励模型 (RM) 通常缺乏对原因或在什么情况下的直接了解
原则，偏好注释。在这项研究中，我们确定
指导 RM 更好地符合人类偏好的原则，然后
开发一个公理框架来生成丰富多样的偏好信号
来支持他们。我们使用这些公理信号来训练评分模型
长篇问题的答案。我们的方法产生一个偏好模型，仅
大约 2.2 亿个参数与人工注释的黄金偏好标签一致
比 GPT-4 更常见。这项工作的贡献包括：
独立的偏好模型，可以对人类和法学硕士生成的答案进行评分
相同的规模；开发用于生成训练数据的公理框架
根据某些原则量身定制的配对；并表明少量
公理化信号可以帮助小型模型在偏好评分方面优于 GPT-4。
我们在 Huggingface 上发布了我们的模型：
https://huggingface.co/corbyrosset/axiomatic_preference_model
]]></description>
      <guid>http://arxiv.org/abs/2312.02206</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>用于边缘推理的低精度混合计算模型。 （arXiv：2312.02210v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02210</link>
      <description><![CDATA[本文提出了一种混合计算神经网络处理方法
适用于包含低精度（低宽度）Posit 和
低精度定点 (FixP) 数字系统。这种混合计算
方法采用 4 位 Posit (Posit4)，它在零附近具有更高的精度，
用于表示高灵敏度的权重，同时使用 4 位 FixP
(FixP4) 用于表示其他权重。用于分析的启发式
提出了权重的重要性和量化误差来分配
不同权重的正确数字系统。另外，还有一个梯度
引入Posit表示的近似来提高
反向传播过程中的权重更新。由于能量高
完全基于Posit的计算、神经网络操作的消耗
在 FixP 或 Posit/FixP 中执行。高效的硬件实现
具有第一 Posit 操作数和 FixP 的第二操作数的 MAC 操作，以及
累加器被提出。所提出的低精度的功效
混合计算方法在视觉和语言方面进行了广泛评估
楷模。结果表明，平均而言，准确率
混合计算比FixP高约1.5%，成本低0.19%
能源开销。
]]></description>
      <guid>http://arxiv.org/abs/2312.02210</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>零样本组合学习的快速调整。 （arXiv：2312.02191v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02191</link>
      <description><![CDATA[众所周知，开放世界组合零样本学习（OW-CZSL）是一种
极具挑战性的任务，旨在识别形成的看不见的成分
来自所见的属性和对象，无需事先假设输出
空间。为了实现这一目标，模型必须“智能”并且
“知识渊博”。为了变得聪明，模型应该善于推理
所看到的组合中的属性和对象之间的相互作用。尽管
“知识渊博”意味着模型对开放世界拥有“常识”，可以
“预见”未见作品的某些特征。以前的大部分工作重点
在“智能”部分，虽然很少有人提供有效的解决方案
达到“知识渊博”的目标。在本文中，我们提出了一个名为
多模态提示调优（MMPT）继承“知识渊博”的属性
大型预训练视觉语言模型。大量实验表明
我们提出的 MMPT 在 OW-CZSL 任务中获得了新的最先进的结果。上
UT-Zappos 数据集，MMPT 将 AUC 分数推至 $29.8$，而之前的最佳
得分为 26.5 美元。在更具挑战性的 MIT-States 数据集上，AUC 得分为
MMPT 比当前最先进的技术好 1.5 倍。
]]></description>
      <guid>http://arxiv.org/abs/2312.02191</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>USat：用于多传感器卫星图像的统一自监督编码器。 （arXiv：2312.02199v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02199</link>
      <description><![CDATA[大型、自我监督的视觉模型已经带来了显着的进步
自动解释自然图像。近期作品已开始剪裁
这些方法对具有丰富结构的遥感数据
多传感器、多光谱和时间信息提供海量
可用于自我监督预训练的大量自标记数据。
在这项工作中，我们开发了一种名为 USat 的新编码器架构，它可以输入
来自多个传感器的多光谱数据用于自我监督预训练。
USat 是一个视觉转换器，具有修改后的补丁投影层和
位置编码来模拟具有不同空间尺度的光谱带
多个传感器。我们将 USAt 集成到掩码自动编码器 (MAE) 中
自监督预训练程序并发现预训练的 USAt
优于在远程训练的最先进的自监督 MAE 模型
多个遥感基准数据集的传感数据（高达 8%）和线索
改善低数据状况（高达 7%）。代码和预训练权重
可在 https://github.com/stanfordmlgroup/USat 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.02199</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>使用反事实对齐识别虚假相关性。 （arXiv：2312.02186v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02186</link>
      <description><![CDATA[由虚假相关性驱动的模型通常会产生较差的泛化能力
表现。我们提出了反事实对齐方法来检测和
探索黑盒分类器的虚假相关性。反事实图像
针对一个分类器生成的结果可以输入到其他分类器中
看看它们是否也会引起这些分类器输出的变化。这
这些响应之间的关系可以量化并用于识别
存在虚假相关性的特定实例以及计算
数据集的聚合统计数据。我们的工作展示了我们的能力
检测面部属性分类器中的虚假相关性。这是经过验证的
通过观察面部属性分类器的直观趋势以及
制造虚假相关性并检测它们的存在，无论是视觉上
和定量。此外，利用 CF 对齐方法，我们证明了
我们可以纠正分类器中发现的虚假相关性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02186</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>视频摘要：走向实体感知字幕。 （arXiv：2312.02188v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02188</link>
      <description><![CDATA[现有流行的视频字幕基准和模型处理通用问题
标题中不含特定的人、地点或组织命名实体。在
相比之下，新闻视频呈现出一个具有挑战性的背景，其中字幕需要
此类命名实体进行有意义的总结。因此，我们提出任务
将新闻视频直接总结为实体感知的字幕。我们还发布了一个
大型数据集 VIEWS（视频新闻）来支持该任务的研究。
此外，我们提出了一种增强视频视觉信息的方法
从外部世界知识中检索上下文以生成实体感知
字幕。我们通过三个视频展示了我们方法的有效性
字幕模型。我们还表明我们的方法可以推广到现有新闻
图像标题数据集。凭借所有广泛的实验和见解，我们
相信我们为未来研究这一具有挑战性的问题奠定了坚实的基础
任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.02188</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>StableDreamer：驯服嘈杂的乐谱蒸馏采样以实现文本转 3D。 （arXiv：2312.02189v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02189</link>
      <description><![CDATA[在文本到 3D 生成领域，通过以下方式利用 2D 扩散模型
分数蒸馏采样 (SDS) 经常导致诸如模糊等问题
外观和多面几何，主要是由于本质上的噪声
SDS 损失的性质。我们的分析将这些挑战的核心确定为
二维扩散过程中噪声水平之间的相互作用，
扩散网络的架构和 3D 模型表示。到
克服这些限制，我们提出了 StableDreamer，一种方法
融合了三项进步。首先，受到 InstructNeRF2NeRF 的启发，我们
形式化 SDS 生成先验和简单监督的等价性
L2 重建损失。这一发现提供了一种调试 SDS 的新工具，
我们用来展示时间退火噪声水平对降低噪声的影响
多面几何形状。其次，我们的分析表明，虽然图像空间
扩散有助于几何精度，潜在空间扩散至关重要
以获得生动的色彩表现。基于这一观察，StableDreamer 推出
有效结合这些方面的两阶段培训策略，
从而产生高保真 3D 模型。第三，我们采用各向异性3D
高斯表示，取代神经辐射场 (NeRF)，以增强
整体质量，减少训练期间的内存使用，并加速
渲染速度，并更好地捕捉半透明物体。稳定的梦想家
减少多面几何形状，生成精细细节，并稳定收敛。
]]></description>
      <guid>http://arxiv.org/abs/2312.02189</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在政府聊天机器人中有效使用生成式人工智能。 （arXiv：2312.02181v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.02181</link>
      <description><![CDATA[随着人工智能的快速发展和突破
机器学习和自然语言处理，智能
问答机器人在政务领域得到广泛应用。这
论文对广东省政府进行了横向比较
聊天机器人ChatGPT和文心Ernie这两个大型语言模型，来分析
现有政府聊天机器人和 AIGC 技术的优点和缺点。
研究发现政府聊天机器人与大型聊天机器人之间存在显着差异
语言模型。中国政务聊天机器人仍处于探索阶段
并有差距要接近才能实现“智能”。探索未来
政府聊天机器人的发展方向更加深入，本研究提出了有针对性的
帮助生成式人工智能在政府中有效应用的优化路径
聊天机器人对话。
]]></description>
      <guid>http://arxiv.org/abs/2312.02181</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>基于单一传感器的活动识别的虚拟融合与对比学习。 （arXiv：2312.02185v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02185</link>
      <description><![CDATA[各种类型的传感器可用于人类活动识别（HAR），
他们每个人都有不同的优点和缺点。有时单个
传感器无法从其角度完全观察用户的动作，这
导致错误的预测。虽然传感器融合提供了更多信息
HAR，它具有许多固有的缺点，例如用户隐私和接受度，
设置、操作和维护成本高昂。为了解决这个问题，我们
提出虚拟融合——一种利用未标记数据的新方法
训练期间来自多个时间同步传感器，但只需要一个
传感器进行推理。采用对比学习来开发
传感器之间的相关性。虚拟融合显着提高了准确性
比使用相同的单个传感器进行训练要好，在某些情况下，它甚至超过了
在测试时使用多个传感器进行实际融合。我们也扩展这个方法
到一个更通用的版本，称为虚拟融合中的实际融合（AFVF），
它在推理过程中使用训练传感器的子集。我们的方法实现了
UCI-HAR 和 PAMAP2 基准上最先进的准确度和 F1 分数
数据集。可根据要求实施。
]]></description>
      <guid>http://arxiv.org/abs/2312.02185</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    <item>
      <title>用于大规模 MIMO CSI 预测的谱时态图神经网络。 （arXiv：2312.02159v1 [cs.IT]）</title>
      <link>http://arxiv.org/abs/2312.02159</link>
      <description><![CDATA[在 5G 通信系统领域，信道状态的准确性
信息 (CSI) 预测对于优化性能至关重要。这封信
介绍了一种开创性的方法：谱时图神经网络
（STEM GNN），融合了空间关系和时间动态
使用图傅立叶变换的无线信道。我们比较 STEM GNN
传统循环神经网络 (RNN) 和长短期方法
用于 CSI 预测的记忆 (LSTM) 模型。我们的研究结果揭示了一个重要的
通过 STEM GNN 增强整体通信系统性能。为了
例如，在一种情况下，STEM GNN 的总速率达到 5.009 bps/Hz，
比 LSTM 高 $11.9\%$，比 RNN 高 $35\%$。这
STEM GNN 的谱时分析功能可捕获复杂的模式
经常被传统模型忽视，提供波束成形的改进，
干扰缓解和超可靠低延迟通信 (URLLC)。
]]></description>
      <guid>http://arxiv.org/abs/2312.02159</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    <item>
      <title>通过潜变量推理训练思维链。 （arXiv：2312.02179v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02179</link>
      <description><![CDATA[大型语言模型 (LLM) 可以更准确、更可解释地解决问题
当被指示使用a逐步计算出答案时
“思想链”（CoT）提示。人们还可以提高法学硕士在以下方面的表现：
通过监督微调来完成特定任务，即通过对某些任务使用梯度上升
可调参数以最大化正确答案的平均对数似然
来自标记的训练集。天真地将 CoT 与监督调优结合起来
不仅需要监督正确答案，还需要监督细节
得出这些答案的理由；这些理由的代价是昂贵的
手工制作。相反，我们提出了一个微调策略，试图
最大化生成正确答案的 \emph{marginal} 对数似然
使用 CoT 提示，对所有可能的理由进行近似平均。这
核心挑战是从后验的基础上进行采样
正确答案;我们使用简单的马尔可夫链蒙特卡罗来解决它
（MCMC）期望最大化（EM）算法的灵感来自于自学
推理机 (STaR)、记忆唤醒睡眠、马尔可夫分数攀爬和持久性
对比分歧。该算法还允许一种新颖的控制变量
将梯度估计的方差驱动为零的技术
模型得到改善。将我们的技术应用于 GSM8K 和 BIG-Bench 中的任务
很难，我们发现这种 MCMC-EM 微调技术通常可以提高
模型在保留示例上的准确性高于 STaR 或使用 或 进行提示调整
没有 CoT。
]]></description>
      <guid>http://arxiv.org/abs/2312.02179</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:11 GMT</pubDate>
    </item>
    </channel>
</rss>