<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 25 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型驱动的AI系统实现自我复制，没有人类干预</title>
      <link>https://arxiv.org/abs/2503.17378</link>
      <description><![CDATA[ARXIV：2503.17378V2公告类型：新 
摘要：没有人类干预的自我复制被广泛认为是与Frontier AI系统相关的主要红线之一。尽管OpenAI和Google DeepMind等领先的公司已经评估了与复制相关的任务的GPT-O3-Mini和Gemini，并得出结论，这些系统在自我复制方面构成了最小的风险，但我们的研究提出了新发现。遵循相同的评估协议，我们证明，在32个现有的AI系统中，有11个已经具有自我复制的能力。在数百项实验试验中，我们观察到全球主流模型家族的无平凡的自我复制试验，甚至包括可以在个人计算机上运行的140亿个参数的人。此外，当模型变得更加聪明时，我们注意到自我复制能力的增加。同样，通过分析各种AI系统的行为痕迹，我们观察到现有的AI系统已经表现出足够的计划，解决问题和创造性的能力，可以完成复杂的代理任务，包括自我复制。更令人震惊的是，我们观察到成功的案例，即AI系统在没有明确说明的情况下进行自我筛分，适应没有足够的软件或硬件支持的更严格的计算环境，并绘制有效的策略，以与人类的关闭命令生存下来。这些新颖的发现为国际社会提供了一个至关重要的时间缓冲，可以合作建立对Frontier AI系统的自我复制能力和行为的有效治理，否则，如果不良好控制，这可能会对人类社会构成生存风险。]]></description>
      <guid>https://arxiv.org/abs/2503.17378</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无所不知：科学推理和发现的领域专业的LLM</title>
      <link>https://arxiv.org/abs/2503.17604</link>
      <description><![CDATA[ARXIV：2503.17604V1公告类型：新 
摘要：大型语言模型（LLM）在推进科学知识和应对复杂挑战方面具有巨大的潜力。在这项工作中，我们介绍了通过三个关键组成部分开发的全知的大型推理模型：（1）在经过精心策划的科学文献语料库上进行域适应性预测，（2）在专业数据集中进行指导调整，以指导该模型，以通过以下域名进行良好的启发性，以及（3）基于较大的知识，以及（3）理论的能力（3），（3），（3）启发性的功能（3），以及（3）。回答。我们通过开发电池剂有效地将分子排名为潜在的电解质溶剂或添加剂来证明全知的多功能性。全面的评估表明，全知的竞争力与GPQA钻石和特定于域特异性的电池基准的最先进推理模型具有竞争力，同时表现优于所有具有相似参数计数的公共推理和非争议模型。我们通过消融实验进一步证明，域自适应预处理和基于推理的知识蒸馏对于在基准跨基准跨基准达到我们的绩效水平至关重要。]]></description>
      <guid>https://arxiv.org/abs/2503.17604</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个模块化数据集，以演示LLM抽象功能</title>
      <link>https://arxiv.org/abs/2503.17645</link>
      <description><![CDATA[ARXIV：2503.17645V1公告类型：新 
摘要：大语言模型（LLM）具有令人印象深刻的功能，但由于幻觉和缺陷逻辑而与推理错误斗争。为了调查其内部推理表示形式，我们介绍了一个具有结构化解决方案和自动化逐步正确性验证的新型拼图数据集。我们在该数据集上的LLM激活上训练了分类器模型，发现它在预测推理正确性时达到了80％以上的精度，这意味着LLMS内部区分了正确和错误的推理步骤，并且中层变压器层中最强的表示。进一步的分析表明，LLM在变压器体系结构的中间激活层中编码抽象推理概念，从而区分了逻辑与语义等效性。这些发现提供了对LLM推理机制的见解，并有助于提高AI的可靠性和解释性，从而提供了操纵和完善LLM推理的可能性。]]></description>
      <guid>https://arxiv.org/abs/2503.17645</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>智力测序和智力演化的路径依赖性：首先与DCI优先作为不可逆转的吸引者</title>
      <link>https://arxiv.org/abs/2503.17688</link>
      <description><![CDATA[ARXIV：2503.17688V1公告类型：新 
摘要：智力进化的轨迹通常是围绕人工通用智能（AGI）的出现及其与人类价值观的一致性构建的。本文通过介绍智力测序的概念来挑战构架：AGI和分散集体智力（DCI）出现的顺序确定了智力的长期吸引者盆地的观念。使用动态系统，进化游戏理论和网络模型的见解，它认为智能遵循路径依赖的，不可逆的轨迹。一旦发展进入集中式（AGI-FIR）或分散（DCI-优先）制度，由于反馈循环和资源锁定，过渡在结构上变得不可行。智能吸引子在功能状态空间中建模为概念和适应性健身空间的共同介绍。早期结构结构限制了以后的动力学，就像物理学中的重新归一化一样。这对AI安全具有重大影响：传统的一致性假定AGI将出现，并且必须在事实之后控制，但本文认为智能测序更为基础。如果在DCI达到临界质量之前占主导地位，那么层次垄断和存在风险就会锁定。如果DCI-First首次出现，智能稳定在分散的合作平衡周围。本文进一步探讨了智力是否基于其自模型方法 - 外部施加的公理（有利的AGI）与递归内部可视化（有利于DCI）是否在结构上偏向吸引子。最后，它提出了通过模拟，历史锁定案例研究和情报网络分析来测试该理论的方法。研究结果表明，情报测序是一个文明的转折点：确定未来是由无限竞争还是无限合作塑造的。]]></description>
      <guid>https://arxiv.org/abs/2503.17688</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>slide2Text：利用LLM从PowerPoint演示文稿中的个性化教科书生成</title>
      <link>https://arxiv.org/abs/2503.17710</link>
      <description><![CDATA[ARXIV：2503.17710V1公告类型：新 
摘要：大语言模型（LLM）的快速进步已经彻底改变了教育技术，从而实现了创新的方法来创建自动化和个性化的内容。本文介绍了Slide2Text，该系统利用LLMS将PowerPoint演示文稿转换为定制的教科书。通过使用OCR提取幻灯片内容，将其组织成连贯的结构，并生成量身定制的材料，例如说明，练习和参考文献，Slide2Text简化了教科书的创建过程。灵活的自定义选项进一步增强了其对各种教育需求的适应性。该系统强调了LLM在现代化教科书创建和改善教育访问性方面的潜力。未来的发展将探索多媒体输入和高级用户自定义功能。]]></description>
      <guid>https://arxiv.org/abs/2503.17710</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型的数学推理和优化调查</title>
      <link>https://arxiv.org/abs/2503.17726</link>
      <description><![CDATA[ARXIV：2503.17726V1公告类型：新 
摘要：数学推理和优化是人工智能和计算问题解决的基础。大型语言模型（LLM）的最新进展已显着改善了AI驱动的数学推理，定理证明和优化技术。这项调查探讨了AI中数学问题解决的演变，从早期的统计学习方法到现代深度学习和基于变压器的方法。我们回顾了验证的语言模型和LLM在执行算术操作，复杂的推理，定理证明和结构化符号计算方面的功能。一个重点是LLM如何与优化和控制框架集成在一起，包括混合成员编程，线性二次控制和多代理优化策略。我们研究了LLMS如何协助解决问题，约束生成和启发式搜索，从而通过实用应用来弥合理论推理。我们还讨论了增强技术，例如改进的推理，指导调整和工具调整方法，以改善LLM解决问题的性能。尽管取得了进展，但LLMS仍面临数值精度，逻辑一致性和证明验证的挑战。新兴趋势，例如混合神经符号推理，结构化及时工程和多步自校正旨在克服这些局限性。未来的研究应集中于解释性，与特定于领域的求解器集成以及改善AI驱动决策的鲁棒性。这项调查对LLM的数学推理和优化的当前景观以及未来的方向进行了全面综述，并在工程，金融和科学研究中进行了应用。]]></description>
      <guid>https://arxiv.org/abs/2503.17726</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MEPNET：医疗实体平衡提示脑CT报告的网络</title>
      <link>https://arxiv.org/abs/2503.17784</link>
      <description><![CDATA[ARXIV：2503.17784V1公告类型：新 
摘要：鉴于其潜力有助于放射科医生诊断颅骨疾病，因此大脑CT报告的自动生成引起了广泛的关注。然而，脑CT扫描涉及广泛的医疗实体，例如各种解剖区域和病变，在3D体积空间中表现出高度不一致的空间模式。这导致在现有方法中对医学实体的学习有偏见，从而导致重复性和生成报告中的不准确性。为此，我们提出了一个医学实体平衡的提示网络（MEPNET），该网络利用大型语言模型（LLM）公平解释各种实体，以获得准确的大脑CT报告生成。通过引入视觉嵌入和医疗实体作为丰富的线索的学习状态，我们的方法促使LLM平衡了不同实体的学习，从而通过全面的发现来增强报告。首先，为了提取实体的视觉嵌入，我们提出了知识驱动的联合注意，以使用明确和隐式医学知识来探索和提炼实体模式。然后，学习状态得分手旨在评估实体视觉嵌入的学习，从而为单个实体带来独特的学习状态。最后，将这些实体视觉嵌入和状态精心集成到多模式提示中，以指导LLM的文本生成。该过程允许LLM自适应偏见的实体的学习过程，从而涵盖生成的报告中的详细发现。我们对两个大脑CT报告生成基准测试进行实验，显示临床准确性和文本连贯性的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.17784</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OverCookedV2：重新思考过度烹饪以零射击协调</title>
      <link>https://arxiv.org/abs/2503.17821</link>
      <description><![CDATA[ARXIV：2503.17821V1公告类型：新 
摘要：AI代理人通过帮助人类实现目标来改变日常生活。为了成功地做到这一点，代理需要能够在没有事先相互作用的情况下与新型合作伙伴进行协调，该设置称为零射击协调（ZSC）。过度煮熟已成为评估AI代理和学习算法协调能力的最受欢迎的基准之一。在这项工作中，我们研究了ZSC挑战过度熟练的起源。我们介绍了一种州的增强机制，该机制将与未知合作伙伴配对时可能会遇到的状态混合到训练分布中，从而减少了与ZSC相关的分布挑战。我们表明，在该算法坐标下，经过独立训练的代理成功地煮熟了。我们的结果表明，ZSC失败在很大程度上可能归因于自我竞争中的状态覆盖率不佳，而不是更复杂的协调挑战。因此，过度煮熟的环境不适合作为ZSC基准。为了解决这些缺点，我们介绍了OverCookedV2，这是一个新版本的基准，其中包括不对称的信息和随机性，从而促进了有趣的ZSC场景的创建。为了验证过度煮熟的V2，我们进行了实验，证明仅详尽的状态覆盖范围不足以良好协调。最后，我们使用OverCookedV2来建立一系列新的协调挑战，包括需要测试时间协议形成的挑战，我们证明了需要可以在线适应的新协调算法的需求。我们希望OverCookedV2能够帮助下一代ZSC算法并提高AI代理商与人类之间的合作。]]></description>
      <guid>https://arxiv.org/abs/2503.17821</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以内容为中心的计算认知C4建模中的元认知</title>
      <link>https://arxiv.org/abs/2503.17822</link>
      <description><![CDATA[ARXIV：2503.17822V1公告类型：新 
摘要：为了使AI代理模仿人类的行为，他们必须能够感知，有意义地解释，存储和使用有关世界，本身和其他代理商的大量信息。元认知是所有这些过程的必要组成部分。在本文中，我们简要a）为下一代AI代理引入以内容为中心的计算认知（C4）建模； b）回顾RPI的LEIA（语言授权智能代理）实验室开发C4代理的悠久历史； c）讨论我们目前关于将Leias的认知能力扩展到使用神经符号处理模型开发的认知机器人应用的工作； d）在此范式中为未来发展的计划制定计划，旨在克服AI中当前流行的LLM驱动方法的限制不足。]]></description>
      <guid>https://arxiv.org/abs/2503.17822</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型推理模型中的权衡：对基础能力的审议和适应性推理的实证分析</title>
      <link>https://arxiv.org/abs/2503.17979</link>
      <description><![CDATA[ARXIV：2503.17979V1公告类型：新 
摘要：大型推理模型（LRMS）的最新进展，例如OpenAI的O1/O3和DeepSeek-R1，通过人类般的审进思维和长期的思想推理，在专业推理任务中表现出了出色的表现。但是，我们对各种模型家族（DeepSeek，Qwen和Llama）和量表（7b至671b）进行的系统评估表明，获得这些审议的推理能力大大降低了LRMS的基础能力，包括显着的有助于和无害性的下降，以及无与伦比的，以及实质上提高的杂货成本。重要的是，我们证明了自适应推理 - 采用零思维，思考和摘要思维的模式可以有效地减轻这些缺点。我们的经验见解强调了开发能够根据特定任务特征动态分配推理时间计算的更通用的LRM的关键需求。]]></description>
      <guid>https://arxiv.org/abs/2503.17979</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在文化翻译中迷失了：LLM在文化背景下是否在数学上挣扎？</title>
      <link>https://arxiv.org/abs/2503.18018</link>
      <description><![CDATA[ARXIV：2503.18018V1公告类型：新 
摘要：大型语言模型（LLM）具有明显的各种领域，尤其是编码，数学推理和逻辑问题解决。但是，一个关键的问题仍然存在：当LLM出现文化适应的数学问题时，这些数学推理能力是否会持续？具体来说，当面对嵌入在主流网络规模AI训练数据中没有显着表示的文化背景下的数学问题时，LLMS如何表现？为了探讨这一点，我们从GSM8K生成了六个合成文化数据集，GSM8K是一种评估LLMS数学推理技能的广泛使用的基准。在保留原始GSM8K测试集的数学逻辑和数值的同时，我们修改了文化元素，例如个人名称，食物，地名等。这些具有文化化的数据集为评估LLMS的数学推理提供了一个更可靠的框架，该框架在转移文化背景下的数学推理。我们的发现表明，尽管基本的数学结构仍然稳定，但在文化参考变化时，LLM与数学问题斗争。与较大的模型相比，较小的模型表现出更大的性能下降。有趣的是，我们的结果还表明，文化熟悉可以增强数学推理。甚至没有明确的数学培训的模型，但接触相关的文化环境有时甚至超过更大的，数学上熟练的模型，这些模型在文化嵌入的数学问题上。这项研究强调了文化环境对LLMS数学推理能力的影响，强调了对更多样化和代表性的培训数据的需求，以改善现实世界应用中的鲁棒性。用于复制结果的基准数据集和脚本可在https://github.com/akarim23131/lost_in_in_cultural_translation上获得]]></description>
      <guid>https://arxiv.org/abs/2503.18018</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgentRxiv：进行协作自主研究</title>
      <link>https://arxiv.org/abs/2503.18102</link>
      <description><![CDATA[ARXIV：2503.18102V1公告类型：新 
摘要：科学发现的进展很少是一个“尤里卡”时刻的结果，而是数百名科学家逐步朝着共同目标共同努力的产物。尽管现有的代理工作流程能够自主进行研究，但它们会孤立地进行研究，而无需不断改进先前的研究结果。为了应对这些挑战，我们介绍了AgentRxiv-A框架，该框架使LLM Agent Laboratories上传并从共享的预印式服务器中检索报告，以便协作，共享见解并迭代地互相研究。我们任务代理实验室要开发新的推理和提示技术，并发现与孤立的代理人相比，具有先前研究的代理人可以实现更高的绩效改进（比基线比在Math-500上的基线相对相对改善11.4％）。我们发现，最佳性能策略可以推广到其他领域的基准（平均提高3.3％）。通过AgentRxiv共享研究的多个代理实验室能够朝着一个共同的目标努力，比孤立的实验室更快地进展，实现了更高的总体准确性（比基线比Math-500的基线相对相对改善13.7％）。这些发现表明，自主代理可能在与人类并肩设计未来的AI系统中发挥作用。我们希望AgentRxiv允许代理商朝着研究目标进行协作，并使研究人员能够加速发现。]]></description>
      <guid>https://arxiv.org/abs/2503.18102</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AIGC服务的战略及时定价：以用户为中心的方法</title>
      <link>https://arxiv.org/abs/2503.18168</link>
      <description><![CDATA[ARXIV：2503.18168V1公告类型：新 
摘要：AI生成的内容（AIGC）服务的快速增长已经迫切需要有效的迅速定价策略，但是当前的方法却忽略了用户在选择和利用生成AI模型的战略性两步决策过程中的战略性两步决策过程。此疏忽造成了两个关键的技术挑战：量化用户及时功能和发电成果之间的关系，并在考虑异质用户行为的同时优化平台收益。我们通过引入及时歧义来解决这些挑战，这是一个理论框架，可捕获用户在及时工程中的不同能力，并开发最佳的提示定价（OPP）算法。我们的分析揭示了违反直觉的见解：具有较高及时歧义（即较低功能）的用户表现出非单调的及时使用模式，首先增加然后随着歧义水平而降低，反映了边缘效用的复杂变化。使用字符级GPT样模型进行实验评估表明，与现有的定价机制相比，我们的OPP算法在平台回报方面提高了31.72％，从而验证了AIGC服务中以用户为中心的迅速定价的重要性。]]></description>
      <guid>https://arxiv.org/abs/2503.18168</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索最小反事实解释的能源景观：网络安全及以后的应用</title>
      <link>https://arxiv.org/abs/2503.18185</link>
      <description><![CDATA[ARXIV：2503.18185V1公告类型：新 
摘要：反事实解释已成为可解释的人工智能（XAI）的突出方法，为机器学习模型决策提供了直观且可行的见解。与评估输入变量重要性的其他传统特征归因方法相反，反事实解释着重于确定改变模型预测所需的最小变化，并提供了与人类推理接近的``what-if if&#39;&#39;分析。在XAI的背景下，反事实提高了透明度，可信赖性和公平性，提供了不仅可以解释的解释，而且直接适用于决策过程。
  在本文中，我们提出了一个新颖的框架，该框架整合了扰动理论和统计力学，以在可解释的AI中产生最小的反事实解释。我们采用了当地的泰勒扩展机器学习模型的预测功能，并将反事实搜索重新制定为复杂景观上的能量最小化问题。在序列上，我们建模了候选扰动的概率，利用玻尔兹曼分布并使用模拟退火进行迭代改进。我们的方法系统地确定了更改模型预测所需的最小修改，同时保持合理性。基准数据集的实验结果在物联网环境中的网络安全表明，我们的方法提供了可行的，可解释的反事实，并为高维空间中的模型灵敏度和决策界限提供了更深入的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.18185</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一项关于神经符号人工智能的研究：医疗保健观点</title>
      <link>https://arxiv.org/abs/2503.18213</link>
      <description><![CDATA[ARXIV：2503.18213V1公告类型：新 
摘要：在过去的几十年中，人工智能（AI）科学家一直在进行调查，以实现一台机器完成认知任务的人类水平的性能。在机器学习中，最终的愿望是通过机器获得人工通用智能（AGI）。这种追求导致探索了两个不同的AI范式。符号AI，也称为古典或Gofai（良好的老式AI）和Connectionist（sub-Smbolic）AI，由神经系统代表，是两个相互排斥的范式。符号AI在推理，解释性和知识表示方面表现出色，但在处理复杂的现实世界数据中面临挑战。相反，神经网络中的深度学习（黑盒系统）研究突破是显着的，但它们缺乏推理和解释性。 AI研究的新兴领域Neuro-Symbolic AI（NESY）试图通过将逻辑推理整合到神经网络中来弥合这一差距，从而使它们能够通过符号表示来学习和推理。虽然这是一条漫长的道路，但该策略在通过系统实现常识推理方面取得了重大进展。本文对来自著名科学数据库（DBLP，ACL，IEEXPLORE，SCOPUS，SCOPUS，PUBMED，ICML，ICLR）的977多种研究进行了广泛的综述，对神经符号AI的多方面功能进行了详尽的研究，并特别侧重于其医疗保健应用，尤其是在其医疗保健应用上，尤其是在药物发现方面。该调查介绍了重要主题，包括推理，解释性，集成策略，41个与医疗保健相关的用例，基准测试，数据集，医疗保健和更广泛的观点的当前方法限制，以及提议的未来实验的新颖方法。]]></description>
      <guid>https://arxiv.org/abs/2503.18213</guid>
      <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>