<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 人工智能 (cs.AI) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Fri, 08 Dec 2023 03:14:20 GMT</lastBuildDate>
    <item>
      <title>认知失调：为什么语言模型的输出与真实性的内部表征不一致？ （arXiv：2312.03729v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03729</link>
      <description><![CDATA[神经语言模型 (LM) 可用于评估事实的真实性
以两种方式查询语句：可以查询它们的语句概率，
或探究真实性的内部表征。过去的工作发现
这两个程序有时会不一致，并且探测往往更
比 LM 输出更准确。这使得一些研究人员得出结论，LM
“撒谎”或以其他方式编码非合作的交流意图。这是一个
当今 LM 的准确描述，或者查询-探测分歧是否会出现在
其他方法？我们确定了三类不同的分歧，我们称之为
虚构、欺骗和异质性。在很多情况下，它的优越性
探针只是归因于对不确定答案的更好校准，而不是
比正确、高置信度答案的比例更大。在某些情况下，
查询和探测在不同的输入子集和准确性上表现更好
可以通过将两者结合起来进一步改进。代码可在
github.com/lingo-mit/lm-truthativity。
]]></description>
      <guid>http://arxiv.org/abs/2312.03729</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>基于内容本地化的系统，用于分析资源匮乏的方言阿拉伯语中的情绪和仇恨行为：英语到黎凡特和海湾。 （arXiv：2312.03727v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03727</link>
      <description><![CDATA[尽管在线社交运动可以迅速在社交媒体上传播开来，
语言可能成为及时监控和分析底层的障碍
在线社交行为（OSB）。对于资源匮乏的地区尤其如此
社交媒体上的语言，如方言阿拉伯语；使用的主要语言
社交媒体上的阿拉伯人。因此，提供解决方案至关重要
有效地利用资源丰富的语言的资源来解决
资源贫乏语言中依赖于语言的 OSB 分析。这张纸
建议将资源丰富的语言的资源内容本地化为
资源贫乏的阿拉伯方言。内容本地化超越内容
将文本从一种语言转换为另一种语言的翻译；内容
本地化适应文化、语言的细微差别和地区偏好
语言到特定语言/方言。自动理解
不同地区自然而熟悉的日常表达方式，是关键
对 OSB 进行更广泛的分析，特别是对于智慧城市。在本文中，我们
利用基于内容本地化的神经机器翻译来开发
两种资源匮乏的阿拉伯方言的情绪和仇恨分类器：黎凡特
和海湾。不仅如此，我们还利用无监督学习来
通过推断隐藏的信息来促进情绪和仇恨预测的分析
来自相应数据的主题并提供连贯的解释
这些主题用他们的母语/方言。实验评价
和基于真实数据的概念验证 COVID-19 案例研究验证了
我们提出的系统在精确区分情绪和
准确识别黎凡特和海湾阿拉伯方言中的仇恨内容。
我们的研究结果揭示了考虑其独特性的重要性
同一语言中的方言并忽略方言方面会导致
误导性分析。
]]></description>
      <guid>http://arxiv.org/abs/2312.03727</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>真正的定制还是只是营销：聊天 GPT 的定制版本有用吗？ （arXiv：2312.03728v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03728</link>
      <description><![CDATA[大型语言模型 (LLM)，例如 OpenAI ChatGPT-4 Turbo，是
彻底改变包括高等教育在内的多个行业。在这个
在此背景下，法学硕士可以通过微调过程进行个性化以满足
学生对每个特定科目的要求，例如统计学。近日，OpenAI
推出了用自然语言微调模型的可能性
Web 界面，可以创建定制的 GPT 版本
刻意调整以满足特定任务的要求。目标
这项研究的目的是评估定制 GPT 的潜力
最近由 OpenAI 推出。开发业务统计后
虚拟教授 (BSVP)，为教皇大学的学生量身定制
Comillas 对其行为进行了评估，并与 ChatGPT-4 Turbo 的行为进行了比较。
结果得出几个结论。首先，大幅修改
观察沟通方式。按照说明进行操作是
经过培训，BSVP 以更加相关和友好的语气提供了答复，
甚至还夹杂了一些小笑话。其次，这是一个问题
相关性，当明确询问诸如“我想练习
类似于 R 实践 4 中的编程练习，”BSVP 能够
提供更优越的响应：可以访问上下文文档，
它可以满足该请求，这超出了 ChatGPT-4 Turbo 的能力。
不利的一面是，响应时间通常较长。最后，关于
整体表现、质量、深度以及与具体内容的一致性
过程中，没有观察到统计上显着的差异
BSVP 和 ChatGPT-4 Turbo 之间的响应。看来是定制的
经过提示培训的助理具有作为虚拟辅助工具的优势
学生，但与 ChatGPT-4 相比，它们并未构成实质性改进
涡轮。
]]></description>
      <guid>http://arxiv.org/abs/2312.03728</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>SCStory：自我监督和持续的在线故事发现。 （arXiv：2312.03725v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03725</link>
      <description><![CDATA[我们提出了一个用于在线故事发现的框架 SCStory，可以帮助人们
无需人工实时消化快速发布的新闻文章流
注释。将新闻文章流组织成故事，现有方法
直接对文章进行编码并根据表示进行聚类
相似。然而，这些方法会产生嘈杂且不准确的故事发现
结果是因为通用文章嵌入不能有效地反映
文章中的故事指示语义，无法快速适应
不断发展的新闻文章流。 SCStory 采用自我监督和持续的
以新闻故事指示自适应建模的新颖理念进行学习
文章流。使用轻量级分层嵌入模块，首先
学习句子表示，然后学习文章表示，SCStory
识别新闻文章中与故事相关的信息并使用它们
发现故事。嵌入模块不断更新以适应
不断发展的新闻流具有对比性的学习目标，并有两个支持
独特的技术、信心感知记忆重放和优先增强，
用于解决标签缺失和数据稀缺问题。彻底的实验
真实且最新的新闻数据集表明 SCStory 表现优于
用于无监督在线故事发现的现有最先进算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.03725</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>解释模型：通过推理隐含的道德判断来为句子建立社会基础。 （arXiv：2312.03726v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03726</link>
      <description><![CDATA[人类交流的社会性和隐性本质影响着读者的
对书面句子的理解。单一黄金标准解释
很少存在，挑战自然语言中的传统假设
加工。这项工作介绍了解释建模（IM）任务
涉及对句子的底层语义的几种解释进行建模
挖掘隐含意义的层次。为了获得这些，IM 的指导是
社会关系和共同点的多重注释——在这项工作中
大致取决于读者对作者的态度和理解
道德判断巧妙地嵌入到句子中。我们提出了一些
依赖一对一和一对多生成方法的建模策略
其灵感来自解释的哲学研究。 A
首创的 IM 数据集旨在支持实验和分析。
建模结果加上对数据集的审查，强调了
IM 面临的挑战是社会上相互冲突且复杂的解释
似是而非的。这种不同阅读的相互作用得到了自动化和
对生成的解释进行人类评估。最后进行毒性分析
生成的解释证明了 IM 对于精炼的重要性
内容过滤并协助内容管理员维护安全
在网上的讨论中。
]]></description>
      <guid>http://arxiv.org/abs/2312.03726</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在总结成像深度学习技术演变中的应用：一项定性研究。 （arXiv：2312.03723v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03723</link>
      <description><![CDATA[对文章或文本摘要的追求已经引起了人们的注意
自然语言处理（NLP）从业者，将自己呈现为
巨大的挑战。 ChatGPT 3.5展现了压缩内容的能力
在单个页面中最多可包含 3000 个令牌，旨在保留关键信息
来自跨不同主题的给定文本。在进行的定性研究中
为了努力，我们选择了七篇科学文章并聘请了公众
可用 ChatGPT 服务来生成这些文章的摘要。
随后，我们聘请了六位文章的合著者进行了一项调查，提出了
与实际情况相比，评估摘要质量的五个问题
原创内容。调查结果显示，ChatGPT 生成的摘要
有效地概括了文章中存在的关键信息，
保留每份手稿的主要信息。尽管如此，还是有一个
与摘要的技术深度相比略有减少
原创文章。因此，我们的结论强调了 ChatGPT 的文本
总结能力作为提取基本见解的有效工具
一种比纯粹的科学话语更符合报道的方式。
]]></description>
      <guid>http://arxiv.org/abs/2312.03723</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>DP-OPT：让大型语言模型成为您的隐私保护提示工程师。 （arXiv：2312.03724v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03724</link>
      <description><![CDATA[大型语言模型 (LLM) 已成为各种领域的主导工具
任务，特别是通过及时调整针对特定目标进行定制时。
尽管如此，围绕数据隐私的担忧仍然存在障碍，因为
调整提示对敏感私人信息的依赖。一个实用的
解决方案是托管本地法学硕士并使用私下优化软提示
数据。然而，当模型所有权被剥夺时，托管本地模型就会出现问题
受保护。替代方法，例如将数据发送给模型提供者
培训，加剧了不受信任的提供商面临的这些隐私问题。在这个
论文中，我们提出了一种新颖的解决方案，称为“差异私有异地提示”
调整（DP-OPT）来应对这一挑战。我们的方法包括调整
客户端离散提示，然后应用到所需的云
楷模。我们证明，法学硕士自己建议的提示可以
在不显着影响性能的情况下进行转移。为了确保
提示不要泄露隐私信息，我们先介绍一下隐私提示
生成机制，通过上下文中的差分私有（DP）集成
通过私人演示学习。通过 DP-OPT，生成
Vicuna-7b 的隐私保护提示可以产生具有竞争力的性能
与 GPT3.5 或本地私人提示上的非私人情境学习相比
调整。代码可在 https://github.com/VITA-Group/DP-OPT 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.03724</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>探索模型分级评估的稳健性和自动解释性。 （arXiv：2312.03721v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03721</link>
      <description><![CDATA[人们对评估语言模型的兴趣越来越浓厚
各种风险和特征。基于自然语言的评估
对评分的理解通常可以通过使用其他方法来大规模执行
语言模型。我们测试这些模型分级评估的稳健性
对不同数据集的注入，包括新的欺骗评估。这些
注入类似于测试者和评估者之间的直接沟通
更改他们的评分。我们推断未来更智能的模型
可能会操纵或配合他们的评估模型。我们发现显着
在所有最先进的商业模型中对这些注射的敏感性
检查评价。此外，类似的注射可用于自动化
可解释性框架产生误导性的模型编写解释。
研究结果对未来的工作有启发，并应警惕对
评估和自动解释性。
]]></description>
      <guid>http://arxiv.org/abs/2312.03721</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能衍生的数据进行碳核算：从替代来源提取信息。 （arXiv：2312.03722v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03722</link>
      <description><![CDATA[碳核算是我们全球道路上的一个基本组成部分
减排脱碳，但实现目标仍面临诸多挑战
可靠且值得信赖的碳核算措施。我们激发碳
会计不仅需要更多的数据驱动，还需要更多的数据驱动
方法论上合理。我们讨论对替代性、更多样化数据的需求
在我们走向可信碳的道路上可以发挥重要作用的来源
会计程序，不仅详细说明原因，而且详细说明如何
一般智能 (AI) 和自然语言处理 (NLP)
特别是可以合理地访问替代数据宝库
根据该领域的最新进展，更好地实现
在此过程中利用非结构化数据。我们提出了一个案例研究
通过 NLP 支持的分析来了解现实世界数据的最新发展
OpenAI 针对金融和航运数据的 GPT API。我们以
讨论如何将这些方法和途径整合到更广泛的领域中
基于人工智能的综合碳核算框架。
]]></description>
      <guid>http://arxiv.org/abs/2312.03722</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>评估人工智能聊天机器人在综合标准化测试准备中的表现； GRE 案例研究。 （arXiv：2312.03719v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03719</link>
      <description><![CDATA[这篇研究论文对
三个人工智能 10 智能聊天机器人：Bing、ChatGPT 和 GPT-4
解决标准化测试问题。研究生入学考试，称为
GRE 作为本文的案例研究，涵盖定量
推理和语言能力。共有137道定量推理题，
具有不同的风格和 157 个口头问题，分为不同的类别
难度级别（简单、中等和困难）用于评估
聊天机器人的功能。本文提供了详细的检查
结果及其对人工智能应用的影响
通过展示每个聊天机器人的性能来进行标准化测试准备
涵盖考试中测试的各种技能和风格。另外，本文
探讨人工智能在处理基于图像的问题上的熟练程度
问题并说明每个聊天机器人的不确定性水平。结果
揭示了聊天机器人不同程度的成功，展示了
模型复杂度和训练数据的影响。 GPT-4 成为最
精通，尤其是复杂的语言理解任务，突出
人工智能在语言理解方面的演变及其
以高分通过考试的能力。
]]></description>
      <guid>http://arxiv.org/abs/2312.03719</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>与 LLMS 谈判：提示黑客、技能差距和推理缺陷。 （arXiv：2312.03720v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03720</link>
      <description><![CDATA[诸如 ChatGPT 之类的大型语言模型 LLM 已达到 100 Mio 用户大关
在创纪录的时间内，可能会越来越多地进入我们生活的各个领域，从而导致
这些人工智能模型和
人类。虽然许多研究讨论了治理和监管
从一阶原理演绎，很少有研究提供归纳，
基于观察人类和法学硕士之间对话的数据驱动镜头
尤其是当涉及到非合作、竞争的情况时
可能对人们构成严重威胁。在这项工作中，我们进行了
用户研究涉及各个年龄段的 40 多个人的价格
与法学硕士谈判。我们探索人们如何与法学硕士互动，
研究谈判结果和策略的差异。此外，
我们强调法学硕士在推理能力方面的缺点
反过来，也容易引发旨在操纵网络的黑客攻击
LLM 可以制定违反其指示或超出任何规定的协议
理性。我们还表明，人类设法实现的协商价格
跨越广泛的范围，这表明在有效互动方面存在读写能力差距
与法学硕士。
]]></description>
      <guid>http://arxiv.org/abs/2312.03720</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>多意图口语理解的共同指导。 （arXiv：2312.03716v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03716</link>
      <description><![CDATA[最近基于图的多意图 SLU 模型已经取得了良好的前景
通过建模指导从意图预测到结果
时隙填充的解码。然而，现有方法（1）仅对
从意图到槽位的单向引导，同时也有双向引导
意图和槽位之间的相互关系； (2)采用齐次图
对槽语义节点和意图标签节点之间的交互进行建模，
这限制了性能。在本文中，我们提出了一种新颖的模型，称为
Co-guiding Net，它实现了一个两阶段框架，实现了相互的
两项任务之间的指导。第一阶段，初步估计
生成两个任务的标签，然后在第二个任务中利用它们
阶段建立相互指导模型。具体来说，我们提出了两种异构
图注意力网络致力于提出的两种异构语义
标签图，有效表示语义之间的关系
节点和标签节点。此外，我们进一步提出Co-guiding-SCL Net，
利用单任务和双任务语义对比关系。为了
第一阶段，我们提出单任务监督对比学习，并且
第二阶段，我们提出共同指导监督对比学习，其中
考虑对比学习中两个任务的相互指导
程序。多意图 SLU 的实验结果表明，我们的模型
大幅优于现有模型，获得相对改进
总体准确度比 MixATIS 数据集上之前的最佳模型提高了 21.3%。
我们还在零样本跨语言场景和
结果表明我们的模型可以相对改进state-of-the-art模型
9 种语言的总体准确率平均提高了 33.5%。
]]></description>
      <guid>http://arxiv.org/abs/2312.03716</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>法律中的大型语言模型：调查。 （arXiv：2312.03718v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03718</link>
      <description><![CDATA[人工智能 (AI) 的出现极大地影响了
传统司法行业。而且，近来，随着
人工智能生成内容（AIGC）、人工智能和法律已在各个领域得到应用
领域，包括图像识别、自动文本生成和
互动聊天。随着大型企业的迅速崛起和普及
模型中，显然人工智能将推动传统行业的转型
司法行业。然而，合法的大语言模型的应用
（法学硕士）仍处于起步阶段。需要解决几个挑战。
在本文中，我们的目标是对法律法学硕士进行全面的调查。我们不
不仅对法学硕士进行了广泛的调查，而且还公开了他们在
司法系统。我们首先概述一下人工智能技术
法律领域并展示法学硕士的最新研究。然后，我们讨论
法律法学硕士提出的实际实施，例如提供法律
在审判期间向用户提供建议并协助法官。此外，我们还探索
法律法学硕士的局限性，包括数据、算法和司法实践。
最后，我们总结了切实可行的建议并提出了未来的发展建议
应对这些挑战的方向。
]]></description>
      <guid>http://arxiv.org/abs/2312.03718</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:14 GMT</pubDate>
    </item>
    <item>
      <title>通过范例进行抽象？ BERT 中词汇类别推断的代表性案例研究。 （arXiv：2312.03708v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03708</link>
      <description><![CDATA[基于示例的帐户通常被认为与
纯粹语言抽象解释语言学习者的能力
推广到新颖的表达方式。然而，最近神经网络的成功
语言敏感任务的语言模型表明也许
抽象可以通过范例的编码产生。我们提供经验
通过调整现有的实验来证明这一说法，该实验研究了如何
LM (BERT) 概括了属于词汇的新颖标记的使用
名词/动词/形容词/副词等类别仅接触到一个
它们的用法实例。我们分析小说的代表性行为
这些实验中的标记，并发现 BERT 的泛化能力
涉及使用这些新颖标记的看不见的表达构成了
新的标记表示向已知类别的区域移动
二维空间中的范例。我们的结果表明学习者的编码
样本的数量确实可以产生类似抽象的行为。
]]></description>
      <guid>http://arxiv.org/abs/2312.03708</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:13 GMT</pubDate>
    </item>
    <item>
      <title>用于讽刺检测的最先进大型语言模型的评估。 （arXiv：2312.03706v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.03706</link>
      <description><![CDATA[根据韦氏词典的定义，讽刺是指某人使用以下词语：
意思与他想说的相反。在感情领域
分析自然语言处理，正确识别的能力
为了了解人们的真实想法，讽刺是必要的。因为使用
讽刺的表达通常是基于语境的，之前的研究已经使用了语言
表示模型，例如支持向量机 (SVM) 和长期短期
记忆（LSTM），通过基于上下文的信息识别讽刺。最近的
NLP 的创新为检测讽刺提供了更多可能性。在
BERT：语言深度双向变压器的预训练
理解，雅各布·德夫林等人。 (2018) 引入了一种新语言
表示模型并表现出更高的解释精度
语境化的语言。正如 Hazarika 等人提出的。 （2018），CASCADE 是
上下文驱动的模型可以为检测讽刺产生良好的结果。这
研究使用这两种最先进的模型来分析 Reddit 语料库
根据基线模型评估其性能，以找到理想的方法
讽刺检测。
]]></description>
      <guid>http://arxiv.org/abs/2312.03706</guid>
      <pubDate>Fri, 08 Dec 2023 03:14:12 GMT</pubDate>
    </item>
    </channel>
</rss>