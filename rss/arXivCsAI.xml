<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 30 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用视觉语言模型解决零样本机器人问题</title>
      <link>https://arxiv.org/abs/2407.19094</link>
      <description><![CDATA[arXiv:2407.19094v1 公告类型：新
摘要：我们介绍了 Wonderful Team，这是一个多智能体视觉 LLM (VLLM) 框架，用于解决零样本机制中的机器人问题。零样本的意思是，对于一个新环境，我们向 VLLM 提供机器人环境的图像和任务描述，并让 VLLM 输出机器人完成任务所需的动作序列。之前关于机器人 VLLM 的工作主要集中在管道某些部分经过微调的设置上，例如根据机器人数据调整 LLM 或训练单独的视觉编码器以进行感知和动作生成。令人惊讶的是，由于 VLLM 功能的最新进展，这种类型的微调对于许多任务可能不再是必要的。在这项工作中，我们展示了通过精心设计，我们可以促使单个现成的 VLLM 处理机器人任务的所有方面，从高级规划到低级位置提取和动作执行。Wonderful Team 以多智能体 LLM 的最新进展为基础，在智能体层次结构中划分任务，使其具有自我纠正能力，能够有效地划分和解决甚至长期任务。在 VIMABench 和现实世界机器人环境中进行的大量实验证明了该系统能够以零样本方式处理各种机器人任务，包括操纵、视觉目标实现和视觉推理。这些结果强调了一个关键点：视觉语言模型在过去一年中取得了迅速发展，应该被强烈视为未来机器人问题的支柱。]]></description>
      <guid>https://arxiv.org/abs/2407.19094</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>GPT 解读美联储言论：量化鹰派和鸽派之间的分歧</title>
      <link>https://arxiv.org/abs/2407.19110</link>
      <description><![CDATA[arXiv:2407.19110v1 公告类型：新
摘要：全球市场和政策制定者都关注联邦公开市场委员会 (FOMC) 做出的重大货币政策决定。他们会议的公开文本文件可以深入了解成员对经济的态度。我们使用 GPT-4 来量化成员在通货膨胀问题上的分歧。我们发现，会议记录和会议纪要反映了成员对宏观经济前景的多样化看法，而这种看法在公开声明中被忽略或省略了。事实上，揭示委员会“真实”态度的不同意见几乎完全被从最终声明中省略了。因此，我们认为，仅根据声明来预测 FOMC 情绪不足以反映鹰派和鸽派之间的分歧。]]></description>
      <guid>https://arxiv.org/abs/2407.19110</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为医学研究中因果推理的辅助引导</title>
      <link>https://arxiv.org/abs/2407.19118</link>
      <description><![CDATA[arXiv:2407.19118v1 公告类型：新
摘要：基于真实世界临床数据的医学研究（例如观察性研究）的有效性取决于得出有关医疗干预的因果结论所必需的关键假设。许多已发表的研究存在缺陷，因为它们违反了这些假设，并存在诸如残留混杂、选择偏差以及治疗和测量时间不一致等偏差。尽管研究人员意识到了这些陷阱，但它们仍然存在，因为如果没有一支拥有丰富专业知识的大型、通常笨拙的跨学科团队，在特定研究的背景下预测和解决这些问题可能具有挑战性。为了解决这一专业知识差距，我们探索使用大型语言模型 (LLM) 作为副驾驶工具，以帮助研究人员识别破坏因果推理有效性的研究设计缺陷。我们提出了一个概念框架，将 LLM 作为因果副驾驶，对各个领域的领域知识进行编码，与研究人员进行自然语言交互，以在研究设计中提供情境化帮助。我们提供了 LLM 如何充当因果副驾驶的说明性示例，提出了一个以现有因果推理框架为基础的结构化框架，并强调了将 LLM 调整为可靠地用于流行病学研究的独特挑战和机遇。]]></description>
      <guid>https://arxiv.org/abs/2407.19118</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>贪婪输出近似：无需再训练即可实现 LLM 的高效结构化剪枝</title>
      <link>https://arxiv.org/abs/2407.19126</link>
      <description><![CDATA[arXiv:2407.19126v1 公告类型：新
摘要：为了在不产生大量计算成本的情况下删除大型语言模型 (LLM) 的冗余组件，这项工作专注于无需再训练阶段的单次修剪。我们通过识别独立运行的深度 2 修剪结构来简化基于 Transformer 的 LLM 的修剪过程。此外，我们提出了两个从输出近似的优化角度得出的推理感知修剪标准，其性能优于梯度和 Hessian 等传统的训练感知指标。我们还引入了一种两步重建技术来减轻修剪错误而无需模型再训练。实验结果表明，我们的方法显着降低了计算成本和硬件要求，同时在各种数据集和模型中保持了卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.19126</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>分级向量空间上的人工神经网络</title>
      <link>https://arxiv.org/abs/2407.19031</link>
      <description><![CDATA[arXiv:2407.19031v1 公告类型：新
摘要：我们开发了新的分级向量空间人工神经网络模型，适用于数据中不同特征具有不同重要性（权重）的情况。这是首次以数学方式设计此类模型，预计它们的表现将优于通常向量空间上的神经网络，而通常向量空间是分级均为 1 的特殊情况。]]></description>
      <guid>https://arxiv.org/abs/2407.19031</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>采用长短期记忆 (LSTM) 的水电站涡轮导向轴承故障预测系统</title>
      <link>https://arxiv.org/abs/2407.19040</link>
      <description><![CDATA[arXiv:2407.19040v1 公告类型：新
摘要：水力发电是一种可再生能源，可满足全球的电力需求。因此，水电站 (HPP) 一直是研究的焦点。快速的技术进步使我们能够开发出最先进的发电机。这不仅提高了涡轮机效率，而且还增加了这些系统的复杂性。因此，这种复杂发电系统的有效运行和维护 (O&amp;M) 已成为一项更具挑战性的任务。因此，在维护 HPP 方面，已经从传统的被动方法转向更智能的预测方法。因此，该研究的目标是为 HPP 的涡轮机轴承开发一种人工智能故障预测系统。所提出的方法利用长短期记忆 (LSTM) 算法来开发模型。最初，使用来自测试台的轴承振动数据对模型进行训练和测试。随后，该模型通过监控和数据采集 (SCADA) 系统使用从巴基斯坦水力发电厂获得的真实轴承振动数据进行进一步训练和测试。该模型对轴承振动值的预测非常有效，实现了非常低的 RMSE。]]></description>
      <guid>https://arxiv.org/abs/2407.19040</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型优化法律领域的数值估算和运算效率</title>
      <link>https://arxiv.org/abs/2407.19041</link>
      <description><![CDATA[arXiv:2407.19041v1 公告类型：新
摘要：法律领域涵盖了广泛的诉讼类型，律师面临着及时和准确地向客户提供信息的挑战，特别是在关键方面，如潜在的监禁期限或财务影响。由于法律专家的稀缺，迫切需要提高传统法律工作流程的效率。深度学习的最新进展，尤其是大型语言模型 (LLM)，为这一挑战提供了有希望的解决方案。利用 LLM 的数学推理能力，我们提出了一种新颖的方法，将基于 LLM 的方法与专门设计的提示相结合，以满足法律人工智能 (LegalAI) 应用程序中的精度要求。这项提议的工作旨在弥合传统法律实践与现代技术进步之间的差距，为更易于访问、更高效和更公平的法律体系铺平道路。为了验证这种方法，我们引入了一个针对精度导向的 LegalAI 任务量身定制的精选数据集，作为评估基于 LLM 的方法的基准。大量实验证实了我们的方法在法律领域生成准确数值估计的有效性，强调了法学硕士在简化法律流程和满足 LegalAI 不断变化的需求方面的作用。]]></description>
      <guid>https://arxiv.org/abs/2407.19041</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 实现工业资产管理解决方案配方的自动化生成</title>
      <link>https://arxiv.org/abs/2407.18992</link>
      <description><![CDATA[arXiv:2407.18992v1 公告类型：新
摘要：本研究通过将基于条件的管理 (CBM) 原则与大型语言模型 (LLM) 的最新进展相结合，引入了一种工业资产管理 (IAM) 的新方法。我们的研究引入了一种自动化的模型构建过程，传统上依赖于数据科学家和领域专家之间的密切协作。我们提出了两项​​主要创新：分类法引导的提示生成，有助于自动创建 AI 解决方案配方，以及一组 LLM 管道，旨在生成包含一组由文档、样本数据和 IAM 模型组成的工件的解决方案配方。这些管道以标准化原则为指导，无需直接人工输入即可为异构资产类别生成初始解决方案模板，从而减少对广泛领域知识的依赖并增强自动化。我们通过评估十种资产类别的资产健康和可持续性来评估我们的方法。我们的研究结果表明，法学硕士 (LLM) 和基于分类法的法学硕士 (LLM) 具有推动资产管理转型的潜力，并为后续研究和开发计划整合到快速客户解决方案中提供了蓝图。]]></description>
      <guid>https://arxiv.org/abs/2407.18992</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>根据需求进行在线测试合成：利用博弈论增强强化学习</title>
      <link>https://arxiv.org/abs/2407.18994</link>
      <description><![CDATA[arXiv:2407.18994v1 公告类型：新
摘要：我们考虑从指定为自动机的功能需求中自动在线合成黑盒测试用例，用于反应式实现。测试人员的目标是达到某个给定状态，以满足覆盖标准，同时监控对需求的违反情况。我们开发了一种基于蒙特卡洛树搜索的方法，这是强化学习中用于有效选择有希望的输入的经典技术。将自动机需求视为实现和测试人员之间的游戏，我们通过将搜索偏向于游戏中有希望的输入来开发启发式方法。我们通过实验表明，我们的启发式方法加速了蒙特卡洛树搜索算法的收敛，从而提高了测试性能。]]></description>
      <guid>https://arxiv.org/abs/2407.18994</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>数据驱动维护的成熟度框架</title>
      <link>https://arxiv.org/abs/2407.18996</link>
      <description><![CDATA[arXiv:2407.18996v1 公告类型：新
摘要：维护决策范围从简单的故障检测到最终预测未来故障并解决问题。这些传统的人类决策如今越来越多地得到数据的支持，最终目标是使它们自主化。本文探讨了数据驱动维护中遇到的挑战，并建议在成熟度框架中考虑四个方面：数据/决策成熟度、从现实世界到数据的转换、决策的可计算性（使用模型）以及获得的关系中的因果关系。在讨论了所涉及的理论概念之后，继续探索实际的故障检测和识别问题。从成熟度框架的四个方面比较和讨论了两种方法，即基于经验和基于模型的方法。观察到两种方法得出相同的决策，但在因果关系的分配上仍然存在差异。这证实了成熟度评估不仅涉及决策类型，还应包括其他提出的方面。]]></description>
      <guid>https://arxiv.org/abs/2407.18996</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>迈向网络信息本体</title>
      <link>https://arxiv.org/abs/2407.18998</link>
      <description><![CDATA[arXiv:2407.18998v1 公告类型：新
摘要：本文介绍了一组术语，旨在充当网络本体（如文件系统本体或数据融合本体）与顶级和中级本体（特别是基本形式本体和通用核心本体）之间的接口。这些术语围绕网络信息管理的独特之处：大量复制信息项的行为、由这些行为产生的副本集合以及代表所有其他成员的这些集合的忠实成员。]]></description>
      <guid>https://arxiv.org/abs/2407.18998</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>MMAU：跨不同领域的代理能力整体基准</title>
      <link>https://arxiv.org/abs/2407.18961</link>
      <description><![CDATA[arXiv:2407.18961v2 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展增加了对全面基准测试的需求，以评估它们作为类人代理的能力。现有的基准测试虽然有用，但通常侧重于特定的应用场景，强调任务完成，但未能剖析推动这些结果的底层技能。这种缺乏粒度使得很难深入辨别失败的根源。此外，设置这些环境需要付出相当大的努力，有时还会出现不可靠性和可重复性的问题，尤其是在交互式任务中。为了解决这些限制，我们引入了大规模多任务代理理解 (MMAU) 基准测试，该基准测试具有全面的离线任务，无需复杂的环境设置。它评估五个领域的模型，包括工具使用、有向无环图 (DAG) 问答、数据科学和机器学习编码、竞赛级编程和数学，并涵盖五种基本能力：理解、推理、规划、解决问题和自我纠正。MMAU 共有 20 个精心设计的任务，涵盖 3000 多个不同的提示，为评估 LLM 代理的优势和局限性提供了一个全面的框架。通过在 MMAU 上测试 18 个代表性模型，我们提供了深入而有见地的分析。最终，MMAU 不仅揭示了 LLM 代理的能力和局限性，而且还增强了其性能的可解释性。MMAU 的数据集和评估脚本发布在 https://github.com/apple/axlearn/tree/main/docs/research/mmau。]]></description>
      <guid>https://arxiv.org/abs/2407.18961</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:20 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能增强归纳形式验证</title>
      <link>https://arxiv.org/abs/2407.18965</link>
      <description><![CDATA[arXiv:2407.18965v1 公告类型：新
摘要：生成人工智能 (GenAI) 已在当今世界展示了其显著减少人类工作量的能力。它利用深度学习技术在文本、图像、代码、音乐和视频方面创建原创和逼真的内容。研究人员还展示了 GenAI 模型使用的现代大型语言模型 (LLM) 的功能，可用于辅助硬件开发。形式验证是一种基于数学的证明方法，用于详尽验证设计的正确性。在本文中，我们展示了如何在基于归纳的形式验证中使用 GenAI 来提高验证吞吐量。]]></description>
      <guid>https://arxiv.org/abs/2407.18965</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:20 GMT</pubDate>
    </item>
    <item>
      <title>语言模型智能分析</title>
      <link>https://arxiv.org/abs/2407.18968</link>
      <description><![CDATA[arXiv:2407.18968v1 公告类型：新
摘要：在这个项目中，我们在抽象和推理语料库 (ARC) 数据集上测试大型语言模型 (LLM) 的有效性。该数据集是测试抽象推理能力的代表性基准，需要对对象识别、基本计数和基本几何原理等关键概念有基本的了解。来自此数据集的任务被转换为基于提示的格式以进行评估。最初，我们通过零样本方法评估模型的潜力。随后，我们研究了思维链 (CoT) 技术的应用，旨在确定其在提高模型性能方面的作用。我们的结果表明，尽管人们对当代 LLM 寄予厚望，但这些模型在非语言领域仍然举步维艰，即使在处理 ARC 数据集的较简单子集时也是如此。我们的研究是第一个专注于这种背景下开源模型能力的研究。支持该项目研究成果的代码、数据集和提示可以在我们的 GitHub 存储库中找到，网址为：https://github.com/Lianga2000/LLMsOnARC。]]></description>
      <guid>https://arxiv.org/abs/2407.18968</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:20 GMT</pubDate>
    </item>
    <item>
      <title>康德视角下的人工智能判断的不可解释性</title>
      <link>https://arxiv.org/abs/2407.18950</link>
      <description><![CDATA[arXiv:2407.18950v1 Announce Type: new 
摘要：康德的《纯粹理性批判》是认识论史的一大贡献，它提出了一个范畴表来阐明人类判断的先验原理的结构。基于功能主义的人工智能（AI）技术声称模拟或复制人类的判断。要评估这一说法，有必要研究AI判断是否具有人类判断的特征。本文认为，AI判断表现出一种不能按照康德的人类判断特征来理解的形式。由于判断的特征重叠，我们可以称之为AI的不确定性。然后，我指出，没有物理直觉的概念在通过视觉展示其功能时不易解释。最后，我说明即使AI通过自然语言中的主语和谓语（判断的组成部分）造句，也很难确定AI是否将概念理解到人类可以接受的水平。这表明通过自然语言的解释是否可靠是值得怀疑的。]]></description>
      <guid>https://arxiv.org/abs/2407.18950</guid>
      <pubDate>Wed, 31 Jul 2024 03:16:19 GMT</pubDate>
    </item>
    </channel>
</rss>