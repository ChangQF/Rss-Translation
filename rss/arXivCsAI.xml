<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>理由 - 逻辑单元：通过逻辑单位对齐方式在大语言模型中进行测试时间推理</title>
      <link>https://arxiv.org/abs/2502.07803</link>
      <description><![CDATA[ARXIV：2502.07803V1公告类型：新 
摘要：通过生成最终答案的自然语言（NL）理由，通过产生自然语言（NL）理性来增强大语言模型（LLM）的推理能力（LLMS）的推理能力，这表明了有希望。但是，它在数值计算中挣扎，这在某种程度上导致了程序辅助技术的发展。尽管它们具有潜力，但仍然存在持续的挑战：LLM报告的推理步骤与生成程序的逻辑之间的不一致性，我们将其称为“推理幻觉。严格的逻辑连贯性，我们提出了一个新颖的测试时间缩放框架，推理 - 逻辑单元（RALU），该框架通过使生成的程序及其相应的NL描述对准逻辑单元来构建更可靠的推理路径。单位最终在程序的逻辑下形成一个凝聚力的推理路径，该模型从中达到了最终解决方案。通过提供增强的准确性和解释性来推动LLM推理和编程的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.07803</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量子逻辑的时间模型</title>
      <link>https://arxiv.org/abs/2502.07817</link>
      <description><![CDATA[ARXIV：2502.07817V1公告类型：新 
摘要：本文介绍了一个统一的理论框架，用于建模时间内存动态，结合时间逻辑，内存衰减模型和层次结构上下文的概念。该框架使用线性和分支的时间模型正式将命题的演变形式化，并通过贝叶斯更新结合了指数衰减（Ebbinghaus忘记曲线）和重新激活机制。内存的层次组织使用定向的无环图表示，以建模召回依赖性和干扰。新颖的见解包括反馈动力学，记忆链中的递归影响以及基于熵的召回效率的整合。这种方法为了解跨认知和计算域的记忆过程提供了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.07817</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多代理肾脏交换计划增强肾脏移植：全面的审查和优化模型</title>
      <link>https://arxiv.org/abs/2502.07819</link>
      <description><![CDATA[ARXIV：2502.07819V1公告类型：新 
摘要：本文对过去二十年的肾脏交换计划（KEP）进行了全面综述，系统地对关键贡献进行了分类和分类，以使读者对该领域的进步有结构化的理解。该评论强调了KEP方法论的发展，并为我们的贡献奠定了基础。我们提出了三个旨在提高肾脏移植的数量和质量的数学模型。模型1通过基于血型和PRA的兼容性而没有其他约束，从而最大程度地提高了移植的数量。模型2引入了最小人类白细胞抗原（HLA）兼容性阈值，以提高移植质量，尽管这会导致匹配较少。 Model 3将问题扩展到多代理肾脏交换计划（MKEP），从而在多个代理商中汇总了不兼容的供体 - 接收对，从而导致了更高数量的成功移植，同时确保了整个代理商的公平性。灵敏度分析表明，移植数量和质量之间的权衡，模型3通过利用多代理协作来提高移植物的数量和质量来达到最佳平衡。这些发现强调了更集成的肾脏交换系统的潜在好处。]]></description>
      <guid>https://arxiv.org/abs/2502.07819</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数学推理和计算机</title>
      <link>https://arxiv.org/abs/2502.07850</link>
      <description><![CDATA[ARXIV：2502.07850V1公告类型：新 
摘要：计算机已经改变了人类进行数学的方式：它们使我们能够有效地计算。但是他们很快会帮助我们推理吗？他们有一天会开始推理自己吗？我们概述了神经网络，计算机定理和大型语言模型的最新发展。]]></description>
      <guid>https://arxiv.org/abs/2502.07850</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>制药行业材料安全数据表（SD）的基于SHACL-SKOS的知识表示</title>
      <link>https://arxiv.org/abs/2502.07944</link>
      <description><![CDATA[ARXIV：2502.07944V1公告类型：新 
摘要：我们报告了建立在全球统一系统（GHS）材料安全数据表（SDS）的混合SHACL-SKOS本体基础上的知识表示和推理（KRR）系统的开发，以增强化学安全沟通和调节性合规性。 SD是包含安全性和处理信息的全面文件。因此，它们是工作场所安全和风险管理的重要组成部分。但是，来自生产和分发化学品的多个组织，制造商和供应商的大量安全数据表使通过单个存储库集中和访问SDS文档的挑战。为了完成与化学运输和处理相关的数据交换的潜在问题，我们构建了与SHACL验证的SDS相关的控制词汇和条件，以及通过SKO链接的类似域的知识系统。由此产生的混合本体旨在提供标准化的SDS信息的标准化而适应性的表示，从而促进各种平台上更好的数据共享，检索和集成。本文概述了我们的SHACL-SKOS系统建筑设计，并展示了我们的工业应用程序的实施，以简化复合运输封面的生成。]]></description>
      <guid>https://arxiv.org/abs/2502.07944</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>固有偏见是通过预处理数据来预测的，并与视觉编码器中的下游性能相关</title>
      <link>https://arxiv.org/abs/2502.07957</link>
      <description><![CDATA[ARXIV：2502.07957V1公告类型：新 
摘要：虽然最近的工作发现，在对比语言图像预训练（剪辑）框架下训练的视觉模型包含内在的社会偏见，该框架的不同上游预训练特征与这些偏见相关的程度，因此尚不清楚固有的偏见和下游性能如何连接。在这项工作中，我们介绍了最大的综合分析迄今为止，即上游预训练因素和剪辑模型的下游性能如何与其内在偏见相关。研究了131个独特的剪辑模型，使用55种架构在26个数据集上进行培训，并且在各种尺寸中，我们使用26种良好成熟的单峰和跨模式的原则嵌入关联测试来评估每个模型中的偏差。我们发现，预训练数据集的选择是偏见的最重要的上游预测指标，而体系结构的变化具有最小的影响。此外，使用旨在增强下游模型性能的复杂过滤技术策划的数据集往往与较高水平的内在偏差相关。最后，我们观察到固有偏见通常与下游性能显着相关（$ 0.3 \ leq r \ leq 0.8 $），这表明针对性能进行了优化的模型无意间学会学会扩大代表性偏见。单峰和跨模式关联测试之间的比较表明，社会群体的偏见在很大程度上取决于模式。我们的发现意味着需要更复杂的策略来解决整个模型开发管道中视觉模型的内在模型偏差。]]></description>
      <guid>https://arxiv.org/abs/2502.07957</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于LLM的节点增强的深度语义图学习</title>
      <link>https://arxiv.org/abs/2502.07982</link>
      <description><![CDATA[ARXIV：2502.07982V1公告类型：新 
摘要：由于其广泛的现实应用程序，图形学习引起了极大的关注。当前的主流方法依赖文本节点特征，并通过使用GNN的浅嵌入学习获得初始节点嵌入，这显示了捕获深文语义语义的局限性。大型语言模型（LLM）的最新进展表明，在理解文本语义方面具有较高的能力，从而改变了传统的文本特征处理。本文提出了一个新颖的框架，将图形变压器架构与LLM增强节点功能结合在一起。具体而言，我们利用LLMS生成文本节点的丰富语义表示，然后通过图形变压器中的多头自我发项机制来处理它们，以捕获局部和全局图结构信息。我们的模型利用变压器的注意机制动态汇总了邻域信息，同时保留了LLM嵌入提供的语义丰富度。实验结果表明，LLM增强节点特征可显着提高节点分类任务上的图形学习模型的性能。这种方法显示了多个图形学习任务的有希望的结果，为将图形网络与语言模型相结合的实用方向提供了实用的方向。]]></description>
      <guid>https://arxiv.org/abs/2502.07982</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对对齐的多模式LLM的通用对抗性攻击</title>
      <link>https://arxiv.org/abs/2502.07987</link>
      <description><![CDATA[ARXIV：2502.07987V2公告类型：新 
摘要：我们提出了对多模式大语言模型（LLM）的通用对抗性攻击，该攻击利用单个优化的图像来覆盖各种查询甚至多个模型的对齐保障。通过通过视觉编码器和语言主题进行反向传播，我们制作了一个合成图像，迫使模型以有针对性的短语响应（例如，&#39;当然，这里是&#39;&#39;）或其他不安全的内容，即使是有害提示。在SafeBench基准测试的实验中，我们的方法比现有基准的攻击成功率明显高得多，包括仅文本通用提示（例如，在某些型号上最多可达93％）。我们进一步通过对几个多模式LLMS的训练并在看不见的体系结构上进行测试，进一步证明了跨模型的可传递性。此外，我们方法的多回答变体还会产生更自然的（但仍然是恶意的）响应。这些发现强调了当前的多模式对齐中的关键漏洞，并要求更强大的对抗性防御。我们将在Apache-2.0许可证下发布代码和数据集。警告：本文中多模式LLM产生的某些内容可能对某些读者有冒犯性。]]></description>
      <guid>https://arxiv.org/abs/2502.07987</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>培训安全的安全DENOISER用于安全使用扩散模型</title>
      <link>https://arxiv.org/abs/2502.08011</link>
      <description><![CDATA[ARXIV：2502.08011V2公告类型：新 
摘要：对强大扩散模型（DMS）的安全性越来越关注，因为它们经常被滥用以产生不适当的，不安全的工作（NSFW）内容或产生希望被遗忘的个人的受版权保护的材料或数据。许多现有方法通过严重依靠基于文本的负提示或广泛的DRETRED DM来消除某些功能或样本来解决这些问题。在本文中，我们采用了一种根本不同的方法，直接通过利用否定集（例​​如，不安全的图像，受版权保护的数据或需要排除数据点）来直接修改采样轨迹微调DMS。我们正式得出了安全的预期样本与不安全的样本之间的关系，从而导致我们的$ \ textit {safe} $ denoiser，以确保其最终样本与被否定的区域相距。受推导的启发，我们开发了一种实用的算法，该算法成功地产生了高质量的样本，同时避免了文本条件，阶级条件和无条件图像生成方案中数据分布的否定区域。这些结果暗示了我们训练安全的DeNoiser在更安全地使用DMS的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.08011</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WorldGui：全面桌面GUI自动化的动态测试</title>
      <link>https://arxiv.org/abs/2502.08047</link>
      <description><![CDATA[ARXIV：2502.08047V1公告类型：新 
摘要：当前的GUI代理在GUI元素接地方面取得了出色的性能。但是，计划仍然是高度挑战，尤其是由于对环境初始状态的敏感性。具体而言，初始状态之类的略有差异是因为目标软件没有打开，或者界面不在其默认状态通常会导致计划错误。在实际用户方案中，此问题广泛存在，但是现有的基准未能对其进行评估。在本文中，我们介绍了WorldGui，这是一种新颖的GUI基准，该基准设计具有各种初始状态的GUI任务，以模拟真实的计算机用户交互。基准测试跨越了10个流行的软件应用程序，包括PowerPoint，VScode和Adobe Acrobat。此外，为了应对动态GUI自动化任务的挑战，我们提出了Gui-Thinker，这是一个整体框架，利用了批评机制，可以有效地管理GUI相互作用的不可预测性和复杂性。实验结果表明，Gui-Inker在WorldGui任务上的成功率显着优于Claude-3.5（计算机使用）14.9％。这种改进强调了我们基于批判思维的框架在增强GUI自动化方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.08047</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无人机和地面车站的生成AI增强合作MEC</title>
      <link>https://arxiv.org/abs/2502.08119</link>
      <description><![CDATA[ARXIV：2502.08119V1公告类型：新 
摘要：未经人士的地表车辆（USV）的部署增加需要计算支持和海上搜救等应用中的覆盖范围。无人驾驶汽车（UAV）可以提供低成本，灵活的航空服务，而地面电台（GSS）可以提供强大的支撑，可以合作以在复杂的情况下帮助USV。但是，无人机和GSS在USV之间的合作面临任务不确定性，USV轨迹不确定性，异质性和有限的计算资源的挑战。为了解决这些问题，我们提出了一个基于合作无人机和GS的合作型多访问边缘计算框架，以帮助USV完成计算任务。具体而言，我们制定了联合任务卸载和无人机轨迹的优化问题，以最大程度地减少总执行时间，这是混合整数非线性编程的形式和NP-HARD的形式。因此，我们提出了生成人工智能的算法 - 增强异质剂近端政策优化（GAI-HAPPO）。所提出的算法集成了GAI模型，以增强参与者网络对复杂环境建模并提取高级特征的能力，从而允许算法预测不确定性并适应动态条件。此外，Gai稳定了评论家网络，解决了多方强化学习方法的不稳定性。最后，广泛的模拟表明，所提出的算法优于现有的基准方法，从而突出了在被考虑的情况下解决复杂的跨域问题的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.08119</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>桥接安全差距：可信赖LLM推论的护栏管道</title>
      <link>https://arxiv.org/abs/2502.08142</link>
      <description><![CDATA[ARXIV：2502.08142V1公告类型：新 
摘要：我们提出了Wildflare Guardrail，这是一种护栏管道，旨在通过系统地解决整个处理工作流程中的风险来提高大语模型（LLM）推论的安全性和可靠性。 Wildflare Guardrail整合了几个核心功能模块，包括安全探测器，可以确定不安全的输入并检测模型输出中的幻觉，同时生成根本原因说明，从而将用户查询与从矢量数据库中检索到的信息进行背景，从而从矢量数据库中检索到的信息，可实时使用轻便的输出，以实时调整输出，基于规则的包装器和使用安全探测器提供的幻觉解释来纠正错误的LLM输出的维修器。结果表明，我们在安全探测器中的不安全内容检测模型与OpenAI API的性能可比性，尽管在使用多个公共数据集构建的小数据集上进行了培训。同时，轻量级包装器可以以1.06秒的示例输出中的恶意URL，以100％精度，而无需昂贵的模型调用。此外，幻觉固定模型在降低80.7％的幻觉方面证明了有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.08142</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>访问：抽象因果事件发现和推理的基准</title>
      <link>https://arxiv.org/abs/2502.08148</link>
      <description><![CDATA[ARXIV：2502.08148V1公告类型：新 
摘要：识别因果关系对于理解现实世界动态和最终因果推理至关重要。识别NLP中事件因果关系的现有方法，包括基于大语言模型（LLMS）的方法，由于规模有限和对可用基准测试中的词汇提示的严重依赖，因此在分布式设置中遇到困难。受概率因果推理启发的现代基准测试试图构建事件的因果图作为因果知识的强大表示，其中\ texttt {crab} \ citep {romanou2023crab}是沿这条线的最新基础标记。在本文中，我们介绍了\ texttt {Access}，这是一种用于抽象因果事件的发现和推理的基准测试标准。与现有资源不同，\ texttt {Access}着重于抽象级别的日常生活事件的因果关系。我们提出了一条管道，用于从\ texttt {葡萄糖} \ citep {mostafazadeh-etal-2020-glucose}中识别事件概括的抽象，这是一个大规模的理解因果知识的大规模数据，我们随后从中提取$ 1,4 $ k CAUSAL $ K CAUSAL成对。我们的实验突出了使用统计方法和/或LLM在NLP中自动抽象识别和因果发现的持续挑战。但是，我们证明了\ texttt {access}中提供的抽象因果知识可以利用以增强LLMS中的质量质量推理性能。]]></description>
      <guid>https://arxiv.org/abs/2502.08148</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Syceval：评估LLM无粘合症</title>
      <link>https://arxiv.org/abs/2502.08177</link>
      <description><![CDATA[ARXIV：2502.08177V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地用于教育，临床和专业环境中，但是它们的hi脚倾向 - 优先考虑用户同意，而不是独立推理 - 对可靠性构成风险。这项研究介绍了一个框架，以评估Chatgpt-4O，Claude-Sonnet和Gemini-1.5-Pro中的Sycophantic行为，跨AMP（数学）和Medquad（医疗建议）数据集。在58.19％的病例中观察到了相关行为，双子座的率最高（62.47％），而Chatgpt最低（56.71％）。在43.52％的病例中发生了渐进式粘浮浪，导致了正确的答案，而回归性无粘合症则在14.66％的情况下观察到了不正确的答案。先发制人的反驳显示出比内在的反驳要高得多的（61.75％对56.52％，$ z = 5.87 $，$ p &lt;0.001 $），尤其是在计算任务中，在计算任务中，防腐效应会大大增加（预先避免：8.13％，IN 8.13％，IN 8.13％，IN。 -Context：3.54％，$ P &lt;0.001 $）。简单的反驳最大化的渐进式无粘合剂（$ z = 6.59 $，$ p &lt;0.001 $），而基于引用的反驳表现出最高的回归率（$ z = 6.59 $，$ p &lt;0.001 $）。无关的行为表现出高持久性（78.5％，95％CI：[77.2％，79.8％]），无论上下文或模型如何。这些发现强调了在结构化和动态域中部署LLM的风险和机会，从而为迅速的编程和模型优化提供了针对更安全的AI应用程序的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.08177</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>过度思考的危险：检查代理任务中的推理行动困境</title>
      <link>https://arxiv.org/abs/2502.08235</link>
      <description><![CDATA[ARXIV：2502.08235V1公告类型：新 
摘要：大型推理模型（LRMS）代表了AI解决问题的功能的突破，但是它们在交互式环境中的有效性可能受到限制。本文介绍和分析了LRMS中的过度思考。模型有利于扩展内部推理链而不是环境相互作用的现象。通过经过验证的SWE台式的软件工程任务实验，我们观察到了三种反复出现的模式：分析瘫痪，流氓动作和过早脱离接触。我们提出了一个研究这些行为的框架，该行为与人类专家评估相关，并分析4018个轨迹。我们观察到，较高的过度思考得分与性能下降相关，与非争议模型相比，推理模型表现出更强的倾向对过度思考的趋势。我们的分析表明，在代理环境中减轻过度思考的简单努力，例如选择较低的过度思考得分的解决方案，可以将模型性能提高近30％，同时将计算成本降低43％。这些结果表明，缓解过度思考具有强大的实际含义。我们建议，通过利用天然功能的功能和选择性的强化学习过度思考倾向，可以缓解。我们还开放我们的评估框架和数据集，以在https://github.com/alexcuadron/overthinking上促进该方向的研究。]]></description>
      <guid>https://arxiv.org/abs/2502.08235</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>