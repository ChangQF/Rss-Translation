<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>紧急医疗服务实时多模态认知助手</title>
      <link>https://arxiv.org/abs/2403.06734</link>
      <description><![CDATA[arXiv:2403.06734v1 公告类型：新
摘要：紧急医疗服务 (EMS) 响应人员通常在时间敏感的条件下工作，面临认知超载和固有风险，需要批判性思维和快速决策的基本技能。本文介绍了 CognitiveEMS，这是一种端到端可穿戴认知辅助系统，可以充当协作虚拟伙伴，实时采集和分析紧急情况现场的多模态数据，并通过增强现实 (AR) 与 EMS 响应人员进行交互智能眼镜。 CognitiveEMS 实时处理连续的数据流，并利用边缘计算为 EMS 协议选择和干预识别提供帮助。我们通过引入三个新颖的组件来解决实时认知辅助中的关键技术挑战：(i) 语音识别模型，该模型使用模拟 EMS 音频记录针对现实世界的医疗紧急对话进行微调，并通过大语言生成的合成数据进行增强模型（法学硕士）； (ii) EMS 协议预测模型，使用基于图的注意力机制将最先进的 (SOTA) 微小语言模型与 EMS 领域知识相结合； (iii) EMS 动作识别模块，利用多模态音频和视频数据以及协议预测来推断响应人员在事件现场采取的干预/治疗行动。我们的结果表明，对于语音识别，我们在对话数据上实现了优于 SOTA 的性能（WER 分别为 0.290 和 0.618）。我们的协议预测组件的性能也显着优于 SOTA（top-3 准确度分别为 0.800 与 0.200），动作识别的准确度达到 0.727，同时边缘协议预测的端到端延迟为 3.78 秒，协议预测为 0.31 秒在服务器上。]]></description>
      <guid>https://arxiv.org/abs/2403.06734</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>开发一种在产房为新生儿科医生提供支持的教育工具</title>
      <link>https://arxiv.org/abs/2403.06843</link>
      <description><![CDATA[arXiv:2403.06843v1 公告类型：新
摘要：如今，有证据表明，有几个因素可能会增加婴儿出生时需要稳定或复苏操作的风险。然而，这种风险因素尚不完全清楚，并且还没有普遍适用的模型来预测高风险情况。考虑到这些限制以及出生时需要复苏的情况很少见，因此必须对产房中负责新生儿护理的医护人员进行定期培训。
  在本文中，我们提出了一种机器学习方法，用于从真实数据中识别风险因素及其对出生事件的影响，人员可以使用该方法逐步增加和更新他们的知识。我们的最终目标是设计一款用户友好的移动应用程序，能够提高识别率并规划对高危患者的适当干预措施。]]></description>
      <guid>https://arxiv.org/abs/2403.06843</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>ArgMed-Agents：通过论证方案使用大型语言模型进行可解释的临床决策推理</title>
      <link>https://arxiv.org/abs/2403.06294</link>
      <description><![CDATA[arXiv:2403.06294v1 公告类型：新
摘要：在临床推理中使用大语言模型（LLM）有两个主要障碍。首先，虽然法学硕士在自然语言处理（NLP）任务中表现出巨大的前景，但他们在复杂推理和规划方面的表现却低于预期。其次，法学硕士使用无法解释的方法来做出与临床医生的认知过程根本不同的临床决策。这会导致用户的不信任。在本文中，我们提出了一个名为 ArgMed-Agents 的多智能体框架，旨在使基于 LLM 的智能体能够通过交互做出可解释的临床决策推理。 ArgMed-Agents 通过临床决策论证方案（临床推理中认知过程建模的推理机制）进行自我论证迭代，然后将论证过程构建为表示冲突关系的有向图。最终，Reasoner（符号求解器）识别出一系列理性且连贯的论据来支持决策。 ArgMed-Agents 使法学硕士能够通过以自我导向的方式生成推理解释来模仿临床论证推理的过程。设置实验表明，与其他提示方法相比，ArgMed-Agents 不仅提高了复杂临床决策推理问题的准确性，更重要的是，它为用户提供了决策解释，增加了他们的信心。]]></description>
      <guid>https://arxiv.org/abs/2403.06294</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>置换质量函数的否定</title>
      <link>https://arxiv.org/abs/2403.06483</link>
      <description><![CDATA[arXiv:2403.06483v1 公告类型：新
摘要：否定是知识表示的一个重要视角。现有的否定方法主要应用于概率论、证据论和复杂证据论。作为证据论的推广，随机排列集理论可以更精确地表示信息。然而，如何将否定的概念应用到随机排列集理论中还没有研究。本文提出了置换质量函数的否定。此外，在否定过程中，验证了所提出的否定方法的收敛性。研究每次否定操作后的不确定性和相异性的趋势。数值例子证明了该方法的合理性。]]></description>
      <guid>https://arxiv.org/abs/2403.06483</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>通过随时性能分析更好地理解和配置 MaxSAT 本地搜索求解器</title>
      <link>https://arxiv.org/abs/2403.06568</link>
      <description><![CDATA[arXiv:2403.06568v1 公告类型：新
摘要：虽然针对 MaxSAT 问题提出了许多求解器，并且 MaxSAT 评估等基准环境为比较最先进的求解器提供了平台，但现有的评估通常是根据质量进行评估的，例如，适应度，在给定的运行时间预算内获得的最佳解决方案。然而，仅关注最终获得的特定时间预算的解决方案可能会限制我们理解求解器在收敛过程中的行为。本文证明，经验累积分布函数可用于比较 MaxSAT 局部搜索求解器在多个问题实例和各种时间预算中的任意时间性能。该评估揭示了求解器性能的差异，并表明求解器的（缺点）优势会随着不同的运行时间而调整。这项工作还表明，随时性能的定量和高方差评估可以指导机器（即自动配置器）寻找更好的参数设置。我们的实验结果表明，与使用最佳找到的解决方案的适应度相比，超参数优化工具（即 SMAC）在使用随时性能作为成本函数时通常可以实现更好的局部搜索参数设置。]]></description>
      <guid>https://arxiv.org/abs/2403.06568</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>迈向可推广和可解释的运动预测：深度变分贝叶斯方法</title>
      <link>https://arxiv.org/abs/2403.06086</link>
      <description><![CDATA[arXiv:2403.06086v1 公告类型：新
摘要：估计周围人类驾驶车辆的潜在行为对于混合交通流中自动驾驶车辆的安全至关重要。最近最先进的技术使用深度神经网络实现了准确的预测。然而，这些端到端模型通常是黑匣子，可解释性和泛化性较弱。本文提出了基于目标的神经变分代理（GNeVA），这是一种可解释的运动预测生成模型，对分布外情况具有鲁棒的泛化性。为了可解释性，该模型通过使用高斯变分混合估计长期目的地的空间分布来实现目标驱动的运动预测。我们识别地图和代理历史之间的因果结构，并推导变分后验以增强普遍性。运动预测数据集上的实验验证了拟合模型是可解释和可推广的，并且可以实现与最先进结果相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.06086</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>TRAD：通过逐步思想检索和一致决策来增强法学硕士代理人的能力</title>
      <link>https://arxiv.org/abs/2403.06221</link>
      <description><![CDATA[arXiv:2403.06221v1 公告类型：新
摘要：由于 LLM 广泛的知识和文本理解能力，已经为网络导航和在线购物等不同任务构建了许多大型语言模型（LLM）代理。在这些工作中，许多人利用上下文示例来实现泛化而不需要微调，而很少有人考虑如何选择和有效利用这些示例的问题。最近，人们提出了基于任务元数据轨迹级检索并使用轨迹作为上下文示例的方法，以提高智能体在某些顺序决策任务中的整体性能。然而，这些方法可能存在问题，因为在没有特定于任务的状态转换动态的情况下检索到看似合理的示例，并且输入带有大量不相关的上下文。在本文中，我们提出了一个新颖的框架（TRAD）来解决这些问题。 TRAD首先进行思维检索，通过思维匹配实现阶梯级演示选择，从而获得更多有用的演示并减少不相关的输入噪音。然后，TRAD 引入了对齐决策，将检索到的演示步骤与其之前或后续步骤进行补充，从而能够容忍不完美的想法，并提供在更多背景和更少噪音之间实现平衡的选择。 ALFWorld 和 Mind2Web 基准测试的大量实验表明，TRAD 不仅优于最先进的模型，而且还有效地帮助减少噪音和促进泛化。此外，TRAD已部署在一家全球商业保险公司的实际场景中，提高了机器人流程自动化的成功率。]]></description>
      <guid>https://arxiv.org/abs/2403.06221</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>通过奖励塑造技术增强多跳知识图推理</title>
      <link>https://arxiv.org/abs/2403.05801</link>
      <description><![CDATA[arXiv:2403.05801v1 公告类型：新
摘要：在计算知识表示领域，知识图推理（KG-R）处于促进跨多个领域的复杂推理能力的最前沿。这项研究的精髓阐明了强化学习 (RL) 策略（特别是 REINFORCE 算法）的使用，以解决多跳 KG-R 中固有的复杂性。这项研究批判性地解决了知识图（KG）固有的不完整性带来的普遍挑战，这经常导致错误的推理结果，表现为假阴性和误导性阳性。通过将统一医学语言系统 (UMLS) 基准数据集划分为丰富和稀疏的子集，我们研究了预训练的 BERT 嵌入和提示学习方法的有效性，以完善奖励塑造过程。这种方法不仅提高了多跳KG-R的精度，而且为该领域的未来研究开创了新的先例，旨在提高复杂KG框架内知识推理的鲁棒性和准确性。我们的工作为知识图谱推理的讨论提供了一种新颖的视角，提供了与《自然》杂志的学术严谨性和学术抱负相一致的方法论进步，有望推动计算知识表示领域的进一步进步。]]></description>
      <guid>https://arxiv.org/abs/2403.05801</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>OntoChat：使用语言模型的对话本体工程框架</title>
      <link>https://arxiv.org/abs/2403.05921</link>
      <description><![CDATA[arXiv:2403.05921v1 公告类型：新
摘要：大型项目中的本体工程（OE）提出了许多挑战，这些挑战源于各个利益相关者、领域专家的异构背景以及他们与本体设计者的复杂交互。这种多方交互往往会在本体需求的引出中产生系统性的模糊性和偏差，这直接影响设计、评估，并可能危及目标的重用。同时，当前的 OE 方法强烈依赖于手动活动（例如访谈、讨论页面）。在收集了最关键的 OE 活动的证据后，我们引入了 OntoChat，这是一个支持需求获取、分析和测试的会话本体工程框架。通过与对话代理交互，用户可以引导用户故事的创建和能力问题的提取，同时获得计算支持来分析总体需求并测试所得本体的早期版本。我们通过复制音乐元本体的工程来评估 OntoChat，并从用户那里收集有关每个组件有效性的初步指标。我们在 https://github.com/King-s-Knowledge-Graph-Lab/OntoChat 发布了所有代码。]]></description>
      <guid>https://arxiv.org/abs/2403.05921</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>使用基于分解的决策重点学习进行高效的公共卫生干预规划</title>
      <link>https://arxiv.org/abs/2403.05683</link>
      <description><![CDATA[arXiv:2403.05683v1 公告类型：新
摘要：随着时间的推移，受益人的参与度不断下降是公共卫生计划的一个关键问题。提高保留率的一个流行策略是让卫生工作者对有退出风险的受益人进行“干预”。然而，这些卫生工作者的资源和时间都是有限的。因此，人们进行了一系列利用 Restless Multi-Armed Bandits (RMAB) 来优化这些有限干预资源的研究。在实践中使用该框架的关键技术障碍在于需要根据历史数据估计受益人的 RMAB 参数。最近的研究表明，以决策为中心的学习（DFL）侧重于最大化受益人的依从性而不是预测准确性，可以提高使用 RMAB 进行干预的效果。不幸的是，由于需要在每个 DFL 训练步骤中求解和评估 RMAB，因此这些收益的计算成本很高。在本文中，我们提供了一种利用 RMAB 结构的原则性方法，通过巧妙地解耦不同受益人的规划来加快干预规划。我们使用来自印度非政府组织 ARMMAN 的真实数据来表明，我们的方法比最先进的方法快两个数量级，同时还产生了卓越的模型性能。这将使该非政府组织能够扩大使用 DFL 的部署，覆盖数百万潜在的母亲，最终推动 UNSDG 3.1 的进展。]]></description>
      <guid>https://arxiv.org/abs/2403.05683</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>保守 DDPG——无集成的悲观强化学习</title>
      <link>https://arxiv.org/abs/2403.05732</link>
      <description><![CDATA[arXiv:2403.05732v1 公告类型：新
摘要：DDPG 受到高估偏差问题的阻碍，其 $Q$ 估计值往往会高估实际的 $Q$ 值。针对这种偏差的传统解决方案涉及基于集成的方法，该方法需要大量的计算资源，或者复杂的基于日志策略的方法，这些方法难以理解和实现。相比之下，我们提出了一个简单的解决方案，使用 $Q$ 目标并结合行为克隆 (BC) 损失惩罚。该解决方案充当不确定性度量，可以使用最少的代码轻松实现，并且无需集成。我们的实证研究结果强烈支持保守 DDPG 在各种 MuJoCo 和 Bullet 任务中优于 DDPG。我们始终观察到，与 TD3 和 TD7 相比，所有评估的任务都有更好的性能，甚至具有竞争性或优越的性能，所有这些都是在显着降低计算要求的情况下实现的。]]></description>
      <guid>https://arxiv.org/abs/2403.05732</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>一种适用于感知和抽象推理的基于特征的泛化预测模型</title>
      <link>https://arxiv.org/abs/2403.05641</link>
      <description><![CDATA[arXiv:2403.05641v1 公告类型：新
摘要：人类智能的一个标志是能够从有限的经验中推断出抽象规则并将这些规则应用于不熟悉的情况。使用乌鸦渐进矩阵在视觉领域广泛研究了这种能力。深度学习的最新进展使得多种人工神经网络模型能够匹配甚至超越人类的表现。然而，虽然人类可以在几乎没有暴露的情况下识别和表达这些任务背后的规则，但当代神经网络通常依赖于大量基于模式的训练，并且无法表达或推断从任务中推断出的规则。此外，大多数用于神经网络训练的 Raven 渐进矩阵或类 Raven 任务都使用符号表示，而人类可以在符号表示和连续感知表示之间灵活切换。在这项工作中，我们提出了一种使用特征检测、仿射变换估计和搜索来进行规则检测和应用的算法方法。我们将我们的模型应用于简化的 Raven 渐进矩阵任务，该任务之前是为人类行为测试和神经成像而设计的。该模型展示了一次性学习，并在简化任务的符号推理条件下实现了接近人类水平的性能。此外，该模型可以表达发现的关系并根据底层规则生成多步骤预测。最后，该模型可以使用连续模式进行推理。我们讨论了我们的结果及其与研究人类抽象推理的相关性，以及它们对改进智能机器的影响。]]></description>
      <guid>https://arxiv.org/abs/2403.05641</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 分解基于视觉的 LLM 预测以进行自动评估</title>
      <link>https://arxiv.org/abs/2403.05680</link>
      <description><![CDATA[arXiv:2403.05680v1 公告类型：新
摘要：世界范围内进行的 CT 检查数量每年都在增加，这导致了放射科医生的倦怠。大型语言模型 (LLM) 有可能减轻他们的负担，但它们在临床中的采用取决于放射科医生的信任以及对生成内容的轻松评估。目前，许多自动化方法可用于评估胸片生成的报告，但这种方法目前不适用于 CT。在本文中，我们提出了一种新颖的评估框架来判断视觉语言法学硕士生成基于 CT 异常的准确摘要的能力。将包含异常（例如病变）的 CT 切片输入到基于视觉的 LLM（GPT-4V、LLaVA-Med 和 RadFM），并生成异常预测特征的自由文本摘要。接下来，GPT-4 模型将摘要分解为特定方面（身体部位、位置、类型和属性），根据真实情况自动评估特征，并根据每个方面的临床相关性和事实准确性生成分数。然后将这些分数与临床医生获得的分数进行对比，观察到高度相关性 (85%，p &lt; .001)。尽管GPT-4V在我们的评估中优于其他模型，但它仍然需要整体改进。我们的评估方法为最需要增强的特定领域提供了宝贵的见解，指导该领域的未来发展。]]></description>
      <guid>https://arxiv.org/abs/2403.05680</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能玩游戏吗？自我对弈方法的案例研究</title>
      <link>https://arxiv.org/abs/2403.05632</link>
      <description><![CDATA[arXiv:2403.05632v1 公告类型：新
摘要：大型语言模型（LLM）利用来自互联网的大量数据，存储广泛的先验知识。虽然法学硕士已被证明有助于决策辅助，但其可靠性受到推理限制、幻觉现象等因素的阻碍。另一方面，蒙特卡洛树搜索（MCTS）是一种启发式搜索算法，可通过递归推出和自博弈来提供可靠的决策解决方案。然而，MCTS 的有效性在很大程度上依赖于启发式剪枝和外部价值函数，特别是在复杂的决策场景中。这项工作引入了一种创新方法，通过 MCTS 自对弈来支持法学硕士，以有效解决确定性回合制零和游戏 (DTZG)，例如国际象棋和围棋，而无需额外培训。具体来说，我们利用 LLM 作为动作修剪器和价值函数的代理，而不需要额外的培训。我们从理论上证明，我们提出的方法中估计值的次优性与 $\tilde{\mathcal O}\Bigl(\frac{|\tilde {\mathcal A}|}{\sqrt{N}} + \epsilon_ \mathrm{pruner} + \epsilon_\mathrm{critic}\Bigr)$，其中 \(N\) 是模拟次数，$|\tilde {\mathcal A}|$ 是修剪后的动作空间的基数LLM、$\epsilon_\mathrm{pruner}$ 和 $\epsilon_\mathrm{critic}$ 分别量化采用 LLM 作为动作空间剪枝器和价值函数代理所产生的误差。我们在国际象棋和围棋方面的实验证明了我们的方法能够解决 MCTS 范围之外的挑战，并提高直接应用法学硕士的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.05632</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>LLM 部署的无调整负责任干预——一种元认知方法</title>
      <link>https://arxiv.org/abs/2403.05636</link>
      <description><![CDATA[arXiv:2403.05636v1 公告类型：新
摘要：大型语言模型（LLM）通过少样本或零样本提示，绕过了参数调整的需要，催化了一系列自然语言处理任务的变革性进步。虽然方便，但这种做法加剧了“幻觉”担忧，特别是考虑到其巨大模型尺寸背后神秘的“黑匣子”本质。在高风险应用（例如医疗保健）中，这种担忧会加剧，其中不负责任的决策错误可能会导致灾难性后果。相比之下，人类的决策依赖于微妙的认知过程，例如通过概念理解来感知和自适应纠正错误判断的能力。受人类认知的启发，我们提出了一种创新的 \textit{metacognitive} 方法，称为 \textbf{CLEAR}，为法学硕士配备自我意识错误识别和纠正的能力。我们的框架有助于构建特定概念的稀疏子网络，阐明透明的决策路径。这为部署后的模型 \textit{intervention} 提供了一个新颖的界面。我们的干预提供了引人注目的优势：(\textit{i})~在部署或推理时，我们的元认知 LLM 可以在最少的人类参与下有意识地识别潜在的错误预测，(\textit{ii})~模型有能力自我识别-有效地纠正错误，无需额外调整，并且(\textit{iii})~纠正过程不仅是不言自明的，而且是用户友好的，增强了模型的可解释性和可访问性。通过整合这些元认知特征，我们的方法开创了一条新的道路，在法学硕士的部署中产生更大的可信度和责任感。]]></description>
      <guid>https://arxiv.org/abs/2403.05636</guid>
      <pubDate>Tue, 12 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>