<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Wed, 13 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>测试时间训练对抽象推理的惊人效果</title>
      <link>https://arxiv.org/abs/2411.07279</link>
      <description><![CDATA[arXiv:2411.07279v1 公告类型：新
摘要：语言模型在其训练分布内的任务上表现出色，但经常难以解决需要复杂推理的新问题。我们研究了测试时训练（TTT）的有效性——在推理过程中使用从输入数据中得出的损失临时更新模型参数——作为改进模型推理能力的机制，使用抽象和推理语料库（ARC）作为基准。通过系统实验，我们确定了成功 TTT 的三个关键组成部分：（1）对类似任务的初始微调（2）辅助任务格式和增强（3）每个实例的训练。TTT 显着提高了 ARC 任务的性能，与基础微调模型相比，准确率提高了 6 倍；将 TTT 应用于 8B 参数语言模型，我们在 ARC 的公共验证集上实现了 53% 的准确率，将公共和纯神经方法的最新水平提高了近 25%。通过将我们的方法与最近的程序生成方法相结合，我们获得了 61.9% 的 SoTA 公开验证准确率，与人类平均得分相当。我们的研究结果表明，显式符号搜索并不是神经语言模型中改进抽象推理的唯一途径；在少数样本上继续训练时应用额外的测试时间也非常有效。]]></description>
      <guid>https://arxiv.org/abs/2411.07279</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自动化自主教学的人工智能生态系统</title>
      <link>https://arxiv.org/abs/2411.07300</link>
      <description><![CDATA[arXiv:2411.07300v1 公告类型：新
摘要：本研究介绍了一种创新的人工智能驱动教育理念，旨在通过个性化的课程交付和自动化的教学辅助来优化自主学习。该系统利用经过微调的人工智能模型来创建一个自适应学习环境，该环境包含定制的路线图、自动演示生成和复杂概念可视化的三维建模。通过集成实时虚拟帮助来解决疑问，该平台满足了学习者的即时教育需求，同时促进了自主学习实践。本研究探讨了自主学习的心理优势，并展示了人工智能自动化如何通过个性化的内容传递和交互式支持机制来增强教育成果。该研究通过提出一个综合框架，将自动内容生成、视觉学习辅助和智能辅导结合起来，为现代教育需求创建一种高效、可扩展的解决方案，为不断发展的教育技术领域做出了贡献。初步研究结果表明，这种方法不仅适应不同的学习风格，而且还通过强调自定进度、独立的学习方法来加强学生的参与度和知识保留。]]></description>
      <guid>https://arxiv.org/abs/2411.07300</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>中国医疗器械软件领域人工智能的数据驱动分析：基于监管数据的深度学习和人工智能总体趋势</title>
      <link>https://arxiv.org/abs/2411.07378</link>
      <description><![CDATA[arXiv:2411.07378v1 公告类型：新
摘要：医疗器械软件（MDSW）中的人工智能（AI）代表了一种变革性的临床技术，引起了医学界和监管机构越来越多的关注。在这项研究中，我们利用数据驱动的方法从国家药品管理局（NMPA）监管数据库中自动提取和分析支持人工智能的医疗器械（AIMD）。公开监管数据的持续增加需要可扩展的分析方法。监管信息筛选的自动化对于创建可重复的见解至关重要，这些见解可以在不断变化的医疗器械领域快速更新。评估了超过 400 万个条目，确定了 2,174 个 MDSW 注册，包括 531 个独立应用程序和 1,643 个集成在医疗器械中的注册，其中 43 个支持人工智能。结果表明，使用 AIMD 的主要医学专业包括呼吸科（20.5%）、眼科/内分泌科（12.8%）和骨科（10.3%）。这种方法大大提高了数据提取的速度，提供了更强的比较和对比能力。这项研究首次对中国 AIMD 进行了广泛的数据驱动探索，展示了自动化监管数据分析在理解和推进医疗技术领域人工智能发展方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.07378</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以数据为中心的学习框架，用于荧光寿命成像引导手术中瞄准光束的实时检测</title>
      <link>https://arxiv.org/abs/2411.07395</link>
      <description><![CDATA[arXiv:2411.07395v1 公告类型：新
摘要：本研究介绍了一种新颖的以数据为中心的方法，使用基于光纤的荧光寿命成像 (FLIm) 来改善实时手术指导。该方法的一个关键方面是瞄准光束的准确检测，这对于定位用于将 FLIm 测量映射到手术区域内的组织区域的点至关重要。主要挑战来自于手术环境中遇到的复杂多变的条件，特别是在经口机器人手术 (TORS) 中。手术区域中的不均匀照明会引起反射、降低对比度并导致颜色表示不一致，从而进一步使瞄准光束检测复杂化。为了克服这些挑战，使用以数据为中心的训练策略开发了一个实例分割模型，该模型通过最小化标签噪声和增强检测稳健性来提高准确性。该模型在包含 40 个体内手术视频的数据集上进行了评估，显示中位检测率为 85%。当模型集成到临床系统中时，这种性能得以保持，在对患者进行的 TORS 手术中实现了 85% 的类似检测率。该系统的计算效率约为每秒 24 帧 (FPS)，足以进行实时手术指导。这项研究提高了基于 FLIm 的瞄准光束检测在复杂手术环境中的可靠性，提高了实时图像引导干预以提高手术精度的可行性]]></description>
      <guid>https://arxiv.org/abs/2411.07395</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估检测阈值：假阳性和假阴性对超分辨率超声定位显微镜的影响</title>
      <link>https://arxiv.org/abs/2411.07426</link>
      <description><![CDATA[arXiv:2411.07426v1 公告类型：新
摘要：使用超声定位显微镜 (ULM) 的超分辨率超声成像提供了微血管结构的高分辨率视图。然而，ULM 图像质量严重依赖于精确的微泡 (MB) 检测。尽管定位算法起着至关重要的作用，但人们对 MB 检测任务中的实际缺陷（例如设置检测阈值）的关注有限。本研究通过系统地向模拟数据添加受控检测误差来检查假阳性 (FP) 和假阴性 (FN) 如何影响 ULM 图像质量。结果表明，虽然 FP 和 FN 速率对峰值信噪比 (PSNR) 的影响相似，但将 FP 速率从 0\% 增加到 20\% 会使结构相似性指数 (SSIM) 降低 7\%，而相同的 FN 速率会导致更大的下降，约为 45\%。此外，密集的 MB 区域对检测误差具有更强的弹性，而稀疏区域表现出高灵敏度，这表明需要强大的 MB 检测框架来增强超分辨率成像。]]></description>
      <guid>https://arxiv.org/abs/2411.07426</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种基于时间谱的攻击流量识别方法</title>
      <link>https://arxiv.org/abs/2411.07510</link>
      <description><![CDATA[arXiv:2411.07510v1 Announce Type: new 
摘要：针对现有网络攻击检测与识别模型鲁棒性不足、特征不稳定、数据噪声干扰等问题，本文提出一种基于时间谱的攻击流量检测与识别方法。首先，通过滑动窗口对流量数据进行切分，构建网络流量的特征序列和对应的标签序列。然后，利用提出的谱标签生成方法SSPE和COAP将标签序列转化为谱标签，将特征序列转化为时间特征。利用谱标签和时间特征对攻击行为模式进行捕获和表示。最后，利用构建的时间特征和谱标签对模型进行训练，实现对网络攻击行为的检测和识别。实验结果表明，与传统方法相比，利用SSPE或COAP方法训练的模型识别准确率提高了10%，并且表现出较强的鲁棒性，尤其是在噪声环境下。]]></description>
      <guid>https://arxiv.org/abs/2411.07510</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 申请抢注和克隆</title>
      <link>https://arxiv.org/abs/2411.07518</link>
      <description><![CDATA[arXiv:2411.07518v1 公告类型：新
摘要：应用程序抢注和应用程序克隆等冒充策略一直是移动应用商店面临的长期挑战，恶意行为者利用热门应用程序的名称和声誉来欺骗用户。随着 GPT Store 和 FlowGPT 等大型语言模型 (LLM) 商店的快速发展，这些问题也同样浮出水面，威胁着 LLM 应用生态系统的完整性。在本研究中，我们使用我们定制的工具 LLMappCrazy 首次对 LLM 应用程序抢注和克隆进行了大规模分析。LLMappCrazy 涵盖了 14 种抢注生成技术，并集成了 Levenshtein 距离和基于 BERT 的语义分析，通过分析应用程序功能相似性来检测克隆。使用此工具，我们生成了前 1000 个应用程序名称的变体，并在数据集中发现了 5,000 多个抢注应用程序。此外，我们在六大平台上观察到 3,509 个抢注应用程序和 9,575 个克隆案例。经过抽样，我们发现 18.7% 的抢注应用程序和 4.9% 的克隆应用程序表现出恶意行为，包括网络钓鱼、恶意软件分发、虚假内容传播和积极广告注入。]]></description>
      <guid>https://arxiv.org/abs/2411.07518</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过使用大型语言模型进行上下文知识检索来改进字素到音素的转换</title>
      <link>https://arxiv.org/abs/2411.07563</link>
      <description><![CDATA[arXiv:2411.07563v1 公告类型：新
摘要：字素到音素 (G2P) 转换是文本到语音 (TTS) 系统中的关键步骤，负责将字素映射到相应的语音表示。然而，它面临着歧义问题，即同一个字素可以根据上下文表示多个音素，这对 G2P 转换提出了挑战。受大型语言模型 (LLM) 在处理上下文感知场景方面取得的显著成功的启发，提出了具有 LLM 上下文知识检索 (ICKR) 功能的上下文 G2P 转换系统来提高消歧能力。在 Librig2p 数据集上充分展示了将 ICKR 纳入 G2P 转换系统的有效性。特别是，使用 ICKR 的最佳上下文 G2P 转换系统优于基线，加权平均音素错误率 (PER) 降低了 2.0% 绝对值（相对值 28.9%）。在 ICKR 系统中使用 GPT-4 可以使 Librig2p 数据集的绝对值增加 3.5%（相对值增加 3.8%）。]]></description>
      <guid>https://arxiv.org/abs/2411.07563</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能驱动的自动程序修复和代码生成方面的进步和技术的全面调查</title>
      <link>https://arxiv.org/abs/2411.07586</link>
      <description><![CDATA[arXiv:2411.07586v1 公告类型：新
摘要：多年来，错误修复和代码生成一直是软件开发的核心研究主题。大型语言模型的近期爆炸式增长彻底改变了这些领域，为这两个领域带来了极其强大的工具。在本次调查中，审查了 27 篇最近的论文，并将其分为两组：一组致力于自动程序修复 (APR) 和 LLM 集成，另一组致力于使用 LLM 生成代码。第一组包括用于错误检测和修复的新方法，其中包括定位语义错误、安全漏洞和运行时故障错误。这项工作强调了 LLM 在减少手动调试工作方面的作用，APR 致力于上下文感知修复，其创新提高了自动调试的准确性和效率。第二组着重于代码生成，概述了针对编程和特定任务模型进行微调的通用 LLM。它还介绍了改进代码生成的方法，例如标识符感知训练、指令级微调和合并语义代码结构。这项调查工作对比了 APR 和代码生成中的方法，以确定使用 LLM、反馈循环以实现迭代代码改进和开源模型等趋势。它还讨论了实现功能正确性和安全性的挑战，并概述了基于 LLM 的软件开发研究的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2411.07586</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用稀疏特征级约束的直接偏好优化</title>
      <link>https://arxiv.org/abs/2411.07618</link>
      <description><![CDATA[arXiv:2411.07618v1 公告类型：新
摘要：大型语言模型 (LLM) 与人类偏好的对齐仍然是一个关键挑战。虽然诸如人类反馈强化学习 (RLHF) 和直​​接偏好优化 (DPO) 等训练后技术取得了显着的成功，但它们往往会引入计算效率低下和训练不稳定。在本文中，我们提出了特征级约束偏好优化 (FPO)，这是一种旨在简化对齐过程同时确保稳定性的新方法。FPO 利用预先训练的稀疏自动编码器 (SAE) 并引入特征级约束，从而实现高效的稀疏强制对齐。我们的方法通过使用在训练有素的稀疏自动编码器中激活的稀疏特征来提高效率，并通过使用特征级离线参考来提高顺序 KL 散度的质量。基准数据集上的实验结果表明，与最先进的基线相比，FPO 的胜率绝对提高了 5.08%，而且计算成本更低，这使其成为高效、可控的 LLM 比对的有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.07618</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多智能体强化学习以实现无关并行机器调度</title>
      <link>https://arxiv.org/abs/2411.07634</link>
      <description><![CDATA[arXiv:2411.07634v1 公告类型：新
摘要：调度问题对资源、行业和运营管理提出了重大挑战。本文使用多智能体强化学习 (MARL) 方法解决了具有设置时间和资源的无关并行机器调度问题 (UPMS)。该研究介绍了强化学习环境并进行了实证分析，将 MARL 与单智能体算法进行了比较。实验采用了各种深度神经网络策略来处理单智能体和多智能体方法。结果证明了近端策略优化 (PPO) 算法的可屏蔽扩展在单智能体场景中的有效性以及多智能体 PPO 算法在多智能体设置中的有效性。虽然单智能体算法在简化场景中表现良好，但多智能体方法在合作学习方面面临挑战，但具有可扩展的能力。这项研究为将 MARL 技术应用于调度优化提供了见解，强调了智能调度解决方案需要在算法复杂性与可扩展性之间取得平衡。]]></description>
      <guid>https://arxiv.org/abs/2411.07634</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>世界模型：安全视角</title>
      <link>https://arxiv.org/abs/2411.07690</link>
      <description><![CDATA[arXiv:2411.07690v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的普及，世界模型 (WM) 的概念最近在 AI 研究界引起了极大关注，尤其是在 AI 代理的背景下。可以说，它正在发展成为构建 AI 代理系统的重要基础。WM 旨在帮助代理预测环境状态的未来演变或帮助代理填写缺失信息，以便它可以计划其行动并安全地行事。WM 的安全属性在其在关键应用中的有效使用中起着关键作用。在这项工作中，我们从可信度和安全性的角度回顾和分析了当前最先进的 WM 技术的影响，该研究基于全面的调查和设想的应用领域。我们对最先进的 WM 进行了深入分析，并得出了技术研究挑战及其影响，以呼吁研究界合作提高 WM 的安全性和可信度。]]></description>
      <guid>https://arxiv.org/abs/2411.07690</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预训练模型的新兴安全与隐私：综述与展望</title>
      <link>https://arxiv.org/abs/2411.07691</link>
      <description><![CDATA[arXiv:2411.07691v1 公告类型：新
摘要：得益于数据的爆炸式增长和计算资源的发展，可以构建预训练模型，这些模型可以在各种任务上取得出色的性能，例如神经语言处理、计算机视觉等。尽管预训练模型功能强大，但它们也引发了人们对与其实际应用相关的新兴安全挑战的关注。泄露隐私信息和产生有害响应等安全和隐私问题严​​重削弱了用户对这些强大模型的信心。随着模型性能的大幅提高，人们的担忧也日益加剧。研究人员渴望探索出现的独特安全和隐私问题、它们的区分因素以及如何防御它们。然而，目前的文献缺乏对预训练模型的新兴攻击和防御的明确分类，这阻碍了对这些问题的高层次和全面的理解。为了填补这一空白，我们对预训练模型的安全风险进行了系统调查，并根据预训练模型的输入和权重在各种安全测试场景中的可访问性提出了攻击和防御方法的分类。该分类将攻击和防御分为无变化、输入变化和模型变化方法。通过分类分析，我们捕捉到了预训练模型独特的安全和隐私问题，并根据其特点对现有的安全问题进行了分类和总结。此外，我们还对每个类别的优势和局限性进行了及时而全面的回顾。我们的调查最后强调了预训练模型的安全和隐私方面潜在的新研究机会。]]></description>
      <guid>https://arxiv.org/abs/2411.07691</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的训练数据</title>
      <link>https://arxiv.org/abs/2411.07715</link>
      <description><![CDATA[arXiv:2411.07715v1 Announce Type: new 
摘要：2022年，随着ChatGPT的发布，大规模语言模型得到了广泛关注。ChatGPT不仅在参数和预训练语料规模方面超越了之前的模型，而且通过对大量高质量的人工注释数据进行微调，实现了革命性的性能提升。这一进步使企业和研究机构认识到，构建更智能、更强大的模型依赖于丰富而高质量的数据集。因此，数据集的构建和优化已成为人工智能领域的一个关键重点。本文总结了用于训练大规模语言模型的预训练和微调数据的现状，涵盖了数据规模、收集方法、数据类型和特征、处理流程等方面，并概述了可用的开源数据集。]]></description>
      <guid>https://arxiv.org/abs/2411.07715</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>认知与感知一致吗？评估和缓解文档理解中的多模态知识冲突</title>
      <link>https://arxiv.org/abs/2411.07722</link>
      <description><![CDATA[arXiv:2411.07722v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 在文档理解方面表现出了令人印象深刻的能力，文档理解是近年来工业需求巨大的快速发展的研究领域。作为一项多模态任务，文档理解需要模型同时具备感知和认知能力。然而，当前的 MLLM 经常面临感知和认知之间的冲突。以文档 VQA 任务（认知）为例，MLLM 可能会生成与其 OCR（感知）识别的相应视觉内容不匹配的答案。这种冲突表明 MLLM 可能难以在它“看到”的信息和它“理解”的信息之间建立内在联系。这种冲突挑战了认知与感知一致的直观观念，阻碍了 MLLM 的性能和可解释性。在本文中，我们将认知和感知之间的冲突定义为认知和感知 (C&amp;P) 知识冲突，这是一种多模态知识冲突，并系统地评估它们，重点是文档理解。我们的分析表明，即使是领先的 MLLM GPT-4o，也只实现了 68.6% 的 C&amp;P 一致性。为了缓解 C&amp;P 知识冲突，我们提出了一种称为多模态知识一致性微调的新方法。该方法首先确保特定于任务的一致性，然后将认知和感知知识联系起来。我们的方法显着减少了所有测试的 MLLM 中的 C&amp;P 知识冲突，并在大多数情况下提高了它们在认知和感知任务中的表现。]]></description>
      <guid>https://arxiv.org/abs/2411.07722</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>