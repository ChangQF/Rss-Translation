<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>将可靠性验证限制嵌入一代扩展计划中</title>
      <link>https://arxiv.org/abs/2504.07131</link>
      <description><![CDATA[ARXIV：2504.07131V1公告类型：新 
摘要：生成计划方法在管理可靠性评估和发电计划的优化模型之间管理不兼容的数学结构方面面临挑战，这阻碍了可靠性约束的整合。这项研究提出了一种通过利用加权倾斜决策树（WODT）技术将可靠性验证约束嵌入到生成扩展计划中的方法。在每个计划年度中，都会生成带有可靠性评估模拟的一代混合数据集。使用此数据集对WODT模型进行了训练。可靠性可行的区域是通过深度优先搜索技术提取的，并作为析取约束。然后，使用凸形船体建模技术将这些约束转换为混合成员线性形式，并嵌入到单位承诺集成的生成扩展计划模型中。提出的方法通过为德克萨斯州电力可靠性委员会（ERCOT）地区的长期生成计划案例研究进行了验证，并证明了其在实现可靠和最佳计划解决方案方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.07131</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能指数报告2025</title>
      <link>https://arxiv.org/abs/2504.07139</link>
      <description><![CDATA[ARXIV：2504.07139V1公告类型：新 
摘要：欢迎进入AI索引报告的第八版。 2025年的指数是我们迄今为止最全面的，并且随着人工智能在社会，经济和全球治理的影响继续增强。今年报告中的新内容是对AI硬件不断发展的景观的深入分析，对推理成本的新颖估计以及对AI出版物和专利趋势的新分析。我们还介绍了有关公司采用负责人AI实践的新数据，以及对AI在科学和医学中不断增长的作用的扩大覆盖范围。自2017年成立作为一百年人工智能研究的分支以来，AI指数一直致力于为决策者，记者，高管，研究人员和公众提供准确，严格验证和全球供应的数据。我们的使命一直是帮助这些利益相关者就AI的发展和部署做出更明智的决定。在这个世界各地讨论AI的世界中 - 从董事会到厨房桌 - 此任务从未如此重要。 AI指数继续导致跟踪和解释塑造该领域的最关键趋势 - 从不断变化的地缘政治格局以及基础技术的快速发展，到AI在商业，决策和公共生活中的不断扩展的作用。纵向跟踪仍然是我们任务的核心。在以惊人的速度前进的域中，该索引提供了基本的背景 - 帮助我们了解AI今天的位置，它如何到达这里以及接下来的位置。 AI指数在全球范围内被认为是人工智能上最有权威的资源之一，在《纽约时报》，彭博社和监护人等主要媒体中引用了AI指数。在数百本学术论文中引用；并由世界各地的政策制定者和政府机构使用。]]></description>
      <guid>https://arxiv.org/abs/2504.07139</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种新的心理健康文本分类培训方法：statentgloss</title>
      <link>https://arxiv.org/abs/2504.07245</link>
      <description><![CDATA[ARXIV：2504.07245V1公告类型：新 
摘要：本研究通过利用传统的机器学习算法，深度学习体系结构和基于变压器的模型来提出一种多阶段的心理健康分类方法。从常规分类器开始并通过神经网络前进开始，策划了一个新颖的数据集并用来评估各种方法的性能。为了扩大建筑范围，还评估了诸如LSTM和GRU之类的复发神经网络（RNN），以探索它们在数据中建模顺序模式中的有效性。随后，对变压器模型（例如BERT）进行了微调，以评估该域中上下文嵌入的影响。除了这些基线评估之外，这项研究的核心贡献在于一种新型的培训策略，该培训涉及由教师和学生网络组成的双模型架构。与标准蒸馏技术不同，此方法不依赖于软标签传输。相反，它通过修改损失函数来促进信息流入教师模型的输出及其潜在表示。实验结果突出了每个建模阶段的有效性，并表明拟议的损失功能和教师互动可显着提高模型在心理健康预测任务中的学习能力。]]></description>
      <guid>https://arxiv.org/abs/2504.07245</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过正确的因果世界模型更好的决定</title>
      <link>https://arxiv.org/abs/2504.07257</link>
      <description><![CDATA[ARXIV：2504.07257V1公告类型：新 
摘要：增强学习（RL）代理在各种环境中表现出了出色的性能，在那里他们可以直接从感觉输入中发现有效的策略。但是，这些试剂通常会利用训练数据中的虚假相关性，从而导致脆弱的行为未能推广到新的或略微修改的环境中。为了解决这个问题，我们介绍了以因果对象为中心的模型提取工具（彗星），这是一种新型算法，旨在学习确切的可解释的因果世界模型（CWMS）。彗星首先从观测值中提取以对象为中心的状态描述，并标识与所描绘对象属性相关的环境内部状态。使用符号回归，IT对以对象为中心的过渡进行建模并得出有关对象动态的因果关系。彗星进一步结合了用于语义推理的大型语言模型（LLM），并注释因果变量以增强可解释性。
  通过利用这些功能，彗星构建了与环境的真正因果结构保持一致的CWM，从而使代理能够专注于任务相关的功能。提取的CWMS减轻了快捷方式的危险，从而开发了能够在动态场景中更好地计划和决策的RL系统。我们的结果在Atari环境（例如Pong and Freeway）中进行了验证，证明了彗星的准确性和鲁棒性，强调了其在增强学习中以对象推理和因果推断之间弥合差距的潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.07257</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>路由正确的专业知识：基于教学的图像编辑的值得信赖的法官</title>
      <link>https://arxiv.org/abs/2504.07424</link>
      <description><![CDATA[ARXIV：2504.07424V1公告类型：新 
摘要：由于多模式大型语言模型（MLLM）和扩散模型的进展，基于指令的图像编辑（IIE）模型已经显着改善，这些模型可以理解和理解复杂的编辑指令。除了推进当前的IIE模型外，准确评估其产出已经变得越来越重要和具有挑战性。当前的IIE评估方法及其评估程序通常与人类判断力不符，并且常常缺乏解释性。为了解决这些限制，我们通过专业知识（JURE）提出判断。 JURE中的每个专家都是一个预先选择的模型，该模型假定配备了原子专业知识，可以为判断输出提供有用的反馈，并且路由器动态地将给定指令及其输出的评估任务汇总到适当的专家，将反馈汇总到最终的法官中。吉尔在两个方面都值得信赖。首先，它可以通过检查路由专家及其反馈来轻松地提供有关法官的解释。其次，实验结果表明，通过与人类判断的优越对准，JUR是可靠的，为自动IIE评估树立了新的标准。此外，Jure的灵活设计是防前的 - 模块化专家可以无缝替换或扩展以适应IIE的进步，从而保持始终如一的高评估质量。我们的评估数据和结果可从https://github.com/cyyyyyrus/jure.git获得。]]></description>
      <guid>https://arxiv.org/abs/2504.07424</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用两层DRL和基于LLM的代理系统来增强玩家的享受</title>
      <link>https://arxiv.org/abs/2504.07425</link>
      <description><![CDATA[ARXIV：2504.07425V1公告类型：新 
摘要：深入强化学习（DRL）有效地增强了各种游戏类型的游戏体验和游戏设计。但是，很少有关于格斗游戏特工的研究明确地集中在增强玩家享受上，这是开发人员和玩家的关键因素。为了解决这一差距并建立了设计以享受性为中心的代理商的实用基准，我们提出了一个两层代理（TTA）系统，并在经典的格斗游戏《街头霸王II》中进行了实验。 TTA的第一层采用了以任务为导向的网络架构，模块化的奖励功能和混合培训来生产多样化和熟练的DRL代理。在TTA的第二层中，一种大型语言模型超级试剂，利用玩家的播放数据和反馈，动态选择了合适的DRL对手。此外，我们研究并模拟了影响对手享受性的几个关键因素。该实验表明，在基线方法上执行高级技能的执行中，有64％的36％提高到156。训练有素的代理商还表现出独特的游戏风格。此外，我们进行了一项小规模的用户研究，并且在玩家的反馈中的整体享受验证了我们TTA系统的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.07425</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于知识的AI和生成性AI来增强基于技能的学习的提问</title>
      <link>https://arxiv.org/abs/2504.07463</link>
      <description><![CDATA[ARXIV：2504.07463V1公告类型：新 
摘要：支持学习者对在线环境中教授技能的理解是一个长期以来的挑战。虽然练习和基于聊天的代理可以在有限的情况下评估理解，但当学习者寻求解释来研究程序知识（事情的完成方式）和推理（为什么会发生事情）时，这一挑战就会放大。我们假设智能代理人能够使用基于知识的AI框架的TMK（Task-Method-nowledge）模型来理解和解释学习者对技能的问题的能力。我们介绍了Ivy，这是一种利用LLM和迭代精致技术的智能代理，以生成构成目的论，因果和作曲原理的解释。我们的初步评估表明，这种方法超出了代理商访问非结构化文本的典型浅层响应，从而实质上改善了反馈的深度和相关性。这可以确保学习者对在线环境中有效解决问题的有效解决问题的技能有全面的了解。]]></description>
      <guid>https://arxiv.org/abs/2504.07463</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过约束放松的资源约束项目调度中的瓶颈标识</title>
      <link>https://arxiv.org/abs/2504.07495</link>
      <description><![CDATA[ARXIV：2504.07495V1公告类型：新 
摘要：在现实的生产场景中，高级计划和调度（APS）工具通常需要制作计划者手动干预，因为该系统可处理不完整的信息，从而产生了次优的时间表。通常，仅仅因为过于限制的约束来指定优化问题，而不是时间表中代表瓶颈，因此无法找到优选的解决方案。为了为决策提供计算机辅助的支持，我们的目标是在给定的时间表中自动识别瓶颈，同时将其链接到要放松的特定约束。在这项工作中，我们通过放松与已确定的瓶颈相关的约束来解决在资源约束项目调度问题中获得的时间表中降低特定项目的迟到的问题。为此，我们开发了两种方法。第一种方法调整了车间文献的现有方法，并将其用于所谓的非目标放松。第二种方法确定了问题的放松版本的潜在改善，并提出了目标放松。令人惊讶的是，不靶向的放松导致与目标放松相当的改进。]]></description>
      <guid>https://arxiv.org/abs/2504.07495</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们的感觉：通过多模式大语言模型在情感推理中打破界限</title>
      <link>https://arxiv.org/abs/2504.07521</link>
      <description><![CDATA[ARXIV：2504.07521V1公告类型：新 
摘要：大多数现有的情绪分析强调了出现的情绪（例如，快乐，悲伤，愤怒），但忽略了原因。我们提出情感解释（EI），重点是因果因素 - 无论是明确的（例如，可观察的对象，人际交互）或隐式（例如，文化背景，屏幕外事件） - 这会推动情感反应。与传统的情感识别不同，EI任务需要有关触发器的推理，而不是仅仅标记。为了促进EI研究，我们提出了EIBENCH，这是一个涵盖1,615个基本EI样品和50个具有多方面情绪的复杂EI样品的大规模基准。每个实例都需要基于基本原理的解释，而不是直接的分类。我们进一步提出了一条粗到1的自我掩盖（CFSA）注释管道，该管道通过迭代的问题解答弹引导视觉模型（VLLMS），以在大规模产生高质量的标签。在四个实验设置下对开源和专有大语模型进行的广泛评估揭示了稳定的性能差距 - 尤其是对于更复杂的场景 - 符合EI的潜力，可以丰富富有善解人意的，上下文感知的AI应用程序。我们的基准和方法可公开可用：https：//github.com/lum1104/eibench，为高级多模式因果分析和下一代情感计算提供基础。]]></description>
      <guid>https://arxiv.org/abs/2504.07521</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在AI的背景下，认知不公的分类法和生成诠释学的案例</title>
      <link>https://arxiv.org/abs/2504.07531</link>
      <description><![CDATA[ARXIV：2504.07531V1公告类型：新 
摘要：是否与机器学习模型的认知性不透明度，算法分类系统的证明偏见的歧视性自动化，通过生成AI的“幻觉”对人类信念的扭曲，全球南方的“幻觉”，全球AI纳入全球AI政府的纳入，或通过官僚主义的官僚主义对官僚主义的侵略性的执行，而与官僚主义的执行相关，则与官僚主义的行为相关。人工智能越来越关注。基于拟议的认知不公的一般分类法，本文依靠技术，政治哲学和社会认识论的哲学领域的工作，对AI的认知不公正类型的分类法进行了素描。其次，在AI的背景下，关于认知不公的另一种观点：生成的诠释学擦除。我认为，通过应用大语言模型（LLM）可能会产生这种不公正现象，并认为，当生成性AI在其西方概念空间之外部署在概念擦除之外时，尤其是在认知域中，尤其是在认知域中，然后是由AI系统和概念框架中的构造构架造成的概念颠覆形式。 AI系统的“从无处可去的观点”从认识论上降低了非西方认识论，从而有助于侵蚀其认识论的细节，逐渐促进了诠释学的擦除。这项工作的相关性在于提议分类法，该分类法允许在AI领域映射认知不公正，并提出了一种与AI相关的认知不公正形式的新形式。]]></description>
      <guid>https://arxiv.org/abs/2504.07531</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过启发式奖励观察空间进化来增强通用LLM奖励设计</title>
      <link>https://arxiv.org/abs/2504.07596</link>
      <description><![CDATA[ARXIV：2504.07596V1公告类型：新 
摘要：大型语言模型（LLM）正在成为自动增强学习（RL）奖励设计的有前途的工具，这是由于它们在常识性推理和代码生成中的强大功能。通过与RL代理进行对话，LLMS通过选择相关环境状态并定义其内部操作来构建奖励观察空间（ROS）。但是，现有的框架并未有效利用历史探索数据或手动任务描述来迭代地发展该空间。在本文中，我们提出了一个新颖的启发式框架，通过通过基于桌子的探索缓存机制和文本代码对帐策略来发展ROS，从而增强了LLM驱动的奖励设计。我们的框架介绍了一个州执行表，该表跟踪环境状态的历史用法和成功率，克服了通常在LLM对话中发现的马尔可夫约束，并促进了更有效的探索。此外，我们使用结构化提示将用户提供的任务描述与专家定义的成功标准调和，从而确保奖励设计目标保持一致。对基准RL任务的全面评估证明了所提出的框架的有效性和稳定性。代码和视频演示可在jingjjjjjie.github.io/llm2reward上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.07596</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用合成认知跳动变压器</title>
      <link>https://arxiv.org/abs/2504.07619</link>
      <description><![CDATA[ARXIV：2504.07619V1公告类型：新 
摘要：通往人工智能的道路通过了情节性反应性行为的产生，在这种行为中，变压器结构已被证明是最新的。但是，他们仍然无法发展推理。最近，已经提出并实施了一种新型的认知结构方法，称为合成认知，以发展瞬时反应性行为。在这项研究中，我们旨在探索合成认知来发展情节反应性行为的使用。我们提出了一种处理合成认知最近实施的序列的机制，并在DNA序列分类任务中对DNA基础模型进行测试。在我们的实验中，我们的建议显然优于DNA基础模型，比替代方案获得了比替代方案更高的分数。因此，我们实现了两个目标：扩展合成认知以处理序列，并击败变压器体系结构进行序列分类。]]></description>
      <guid>https://arxiv.org/abs/2504.07619</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>物联网计算的生成人工智能：系统调查</title>
      <link>https://arxiv.org/abs/2504.07635</link>
      <description><![CDATA[ARXIV：2504.07635V1公告类型：新 
摘要：生成人工智能（Genai）在物联网（IoT）中的整合引起了极大的兴趣。这种日益增长的关注源于它们的持续发展和广泛采用，它们都单独地采用，足以自发地重塑许多部门，包括医疗保健，制造业和智能城市。因此，他们日益普及的人促进了进一步的广泛研究，以了解二人组的潜力，它们如何相互作用以及在他们的各个场景中可以创新他们的最新技术。但是，尽管Genai在物联网计算中的突出性越来越高，但现有的许多研究仍集中在特定的，狭窄的应用上。这种分散的方法强调了对Genai整合在更广泛的物联网生态系统中的潜在，挑战和含义的更全面分析的必要性。这项调查旨在通过提供这些主流范式融合引起的机遇，问题和考虑的整体概述来解决这一差距。通过Prisma方法论，通过系统的文献综述来实现我们的贡献。提出了一个比较框架，并概述了定义明确的研究问题，以全面探索Genai集成与物联网计算的过去，现在和将来的方向，为专家和新移民提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.07635</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过神经符号整合和本体论推理来增强大型语言模型</title>
      <link>https://arxiv.org/abs/2504.07640</link>
      <description><![CDATA[ARXIV：2504.07640V1公告类型：新 
摘要：大语言模型（LLMS）在自然语言处理中表现出令人印象深刻的能力，但遭受了不准确和逻辑上的矛盾，称为幻觉。这损害了它们的可靠性，尤其是在需要事实准确性的领域。我们提出了一种整合符号本体论推理和机器学习方法的神经符号方法，以增强LLM输出的一致性和可靠性。我们的工作流利用猫头鹰本体，符号推理器（例如隐士）进行一致性检查以及轻巧的机器学习模型（逻辑回归），以将自然语言语句映射到与本体学兼容的逻辑形式中。当检测到LLM输出与本体学之间的不一致时，系统会生成解释性反馈，以指导LLM在迭代的完善循环中引导校正后的，逻辑上一致的响应。我们提出了一个工作的Python原型，展示了该管道。定义域中的实验结果表明，LLM输出的语义连贯性和事实准确性的显着提高，展示了将LLM流利度与正式语义的严格性相结合的潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.07640</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与基于LLM的专家和学生代理人合成高质量的编程任务</title>
      <link>https://arxiv.org/abs/2504.07655</link>
      <description><![CDATA[ARXIV：2504.07655V1公告类型：新 
摘要：生成的AI通过实现自动生成个性化内容和反馈来改变计算教育。我们研究了其在为学生提供高质量编程任务的能力。尽管任务产生有希望的进步，但在AI生成和专家创建的任务之间仍然存在质量差距。 AI生成的任务可能与目标编程概念不符，学生无法理解，或者可能包含关键问题，例如不正确的测试。现有作品通常需要人类教师的干预措施进行验证。我们通过引入Pytasksyn（一种新颖的合成技术）来解决这些挑战，该技术首先生成编程任务，然后决定它是否符合某些质量标准，以给学生。关键的想法是将这个过程分为由使用强生成模型模拟的专家和学生代理人执行的多个阶段。通过广泛的评估，我们表明，与基线技术相比，Pytasksyn显着提高了任务质量，并展示了我们验证管道中每种专业代理类型的重要性。此外，我们使用公开可用的Web应用程序进行了用户研究，并表明Pytasksyn可以提供与专家设计的高质量编程任务，同时减少工作量和成本，并且比在线资源中可用的编程任务更具吸引力。]]></description>
      <guid>https://arxiv.org/abs/2504.07655</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>