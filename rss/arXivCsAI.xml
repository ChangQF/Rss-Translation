<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 08 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>将知识图嵌入简并 Clifford 代数中</title>
      <link>https://arxiv.org/abs/2402.04870</link>
      <description><![CDATA[克利福德代数是实数、复数和四元数的自然推广。到目前为止，在知识图嵌入的背景下，仅研究了 $Cl_{p,q}$ 形式的 Clifford 代数（即没有幂零基向量的代数）。我们建议考虑幂零指数为 2 的幂零基向量。在这些空间中，表示为 $Cl_{p,q,r}$，允许泛化基于对偶数的方法（无法使用 $Cl_{p,q}$ 建模）并捕获由于缺乏更高的值而产生的模式。实体嵌入的真实部分和复杂部分之间的交互顺序。我们设计了两个新模型来发现参数 $p$、$q$ 和 $r$。第一个模型使用贪婪搜索来优化 $p$、$q$ 和 $r$。第二个基于使用神经网络计算的输入知识图的嵌入来预测 $(p, q,r)$。我们对七个基准数据集的评估结果表明，幂零向量可以帮助更好地捕获嵌入。我们与现有技术的比较表明，我们的方法在所有数据集上比其他方法具有更好的泛化能力。它在验证数据上实现的 MRR。我们还表明，贪婪搜索足以发现接近最优的 $p$、$q$ 和 $r$ 值。]]></description>
      <guid>https://arxiv.org/abs/2402.04870</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>选择具有图神经网络的经典规划器</title>
      <link>https://arxiv.org/abs/2402.04874</link>
      <description><![CDATA[在线规划器选择是针对给定的规划问题从预定义的集合中选择求解器的任务。由于规划的计算难度很大，求解器在规划问题上的性能差异很大。因此，预测他们在给定问题上的表现的能力非常重要。虽然已经采用了多种学习方法，但对于经典的成本最优规划，流行的方法使用图神经网络（GNN）。在这项工作中，我们继续使用 GNN 进行在线规划器选择的工作。我们对所选 GNN 模型、图表示和节点特征以及预测任务的影响进行了彻底调查。更进一步，我们建议使用 GNN 获得的图表示作为极限梯度提升 (XGBoost) 模型的输入，从而产生更资源高效且更准确的方法。我们展示了各种基于 GNN 的在线规划器选择方法的有效性，为在线规划器选择的研究开辟了新的令人兴奋的途径。]]></description>
      <guid>https://arxiv.org/abs/2402.04874</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>通过加权模型集成对人工智能系统进行概率验证的统一框架</title>
      <link>https://arxiv.org/abs/2402.04892</link>
      <description><![CDATA[人工智能系统的概率形式验证（PFV）尚处于起步阶段。到目前为止，方法仅限于针对特定类别的模型和/或属性的临时算法。
  我们提出了一个基于加权模型集成（WMI）的人工智能系统 PFV 的统一框架，它允许以非常笼统的术语来描述问题。
  至关重要的是，这种减少能够在广泛的机器学习模型中验证许多感兴趣的属性，例如公平性、鲁棒性或单调性，而无需做出强分布假设。
  我们通过使用单个现成的 WMI 求解器解决多个验证任务来支持该方法的通用性，然后讨论与这个有前景的框架相关的可扩展性挑战和研究方向。]]></description>
      <guid>https://arxiv.org/abs/2402.04892</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>结构化 d-DNNF 在否定下不封闭</title>
      <link>https://arxiv.org/abs/2402.04832</link>
      <description><![CDATA[结构化 d-DNNF 和 SDD 都比 OBDD 更加简洁。此外，SDD 本质上与 OBDD 一样易于处理。但这留下了两个重要的悬而未决的问题。首先，OBDD 是否支持比结构化 d-DNNF 更容易处理的转换？其次，结构化 d-DNNF 是否比 SDD 更简洁？在本文中，我们对这两个问题的回答都是肯定的。对于第一个问题，我们表明，与 OBDD 不同，结构化 d-DNNF 不支持多时间否定、析取或存在量化操作。作为推论，我们推断出存在具有等效多项式大小的结构化 d-DNNF 的函数，但没有像 SDD 这样的表示，从而回答了第二个问题。我们还将第二个结果提升到算术电路 (AC)，以显示 PSDD 和单调 AC 模拟到结构化 d-DNNF 之间的简洁性差距。]]></description>
      <guid>https://arxiv.org/abs/2402.04832</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>用反事实轨迹解释学习奖励函数</title>
      <link>https://arxiv.org/abs/2402.04856</link>
      <description><![CDATA[从人类行为或反馈中学习奖励是将人工智能系统与人类价值观结合起来的一种很有前途的方法，但无法始终如一地提取正确的奖励函数。可解释性工具可以使用户理解和评估学习奖励函数中可能存在的缺陷。我们提出反事实轨迹解释（CTE），通过将原始轨迹与反事实部分轨迹以及它们各自获得的奖励进行对比来解释强化学习中的奖励函数。我们得出了 CTE 的六个质量标准，并提出了一种基于蒙特卡罗的新颖算法来生成 CTE，以优化这些质量标准。最后，我们通过在 CTE 上进行训练来衡量生成的解释对于代理人类模型的信息量。 CTE 对于代理人类模型来说显然提供了丰富的信息，增加了其预测与未见轨迹上的奖励函数之间的相似性。此外，它学会准确判断轨迹之间奖励的差异，并将其推广到分布外的示例。尽管 CTE 并不能带来对奖励的完美理解，但我们的方法，以及更普遍的 XAI 方法的改编，被认为是解释学习奖励函数的富有成效的方法。]]></description>
      <guid>https://arxiv.org/abs/2402.04856</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>CodeIt：通过优先的事后重播来自我改进语言模型</title>
      <link>https://arxiv.org/abs/2402.04858</link>
      <description><![CDATA[大型语言模型越来越多地解决人们普遍认为需要人类推理能力的任务。然而，这些模型在抽象与推理语料库（ARC）等通用智能基准上的表现仍然很差。在本文中，我们将 ARC 作为示例编程问题来处理，并介绍了一种新颖且可扩展的语言模型自我改进方法，称为代码迭代 (CodeIt)。我们的方法在 1）程序采样和事后重新标记以及 2）从优先经验重放中学习之间进行迭代。通过将一个片段的目标（即给定输入的目标程序输出）重新标记为采样程序产生的实现输出，我们的方法有效地处理了程序合成中奖励的极端稀疏性。将 CodeIt 应用于 ARC 数据集，我们证明了优先的事后重放以及预训练和数据增强可以成功实现任务间泛化。 CodeIt 是第一个可扩展到完整 ARC 评估数据集的神经符号方法。我们的方法解决了 15% 的 ARC 评估任务，实现了最先进的性能，并超越了现有的神经和符号基线。]]></description>
      <guid>https://arxiv.org/abs/2402.04858</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>SPARQL 生成：针对生命科学知识图问答的 OpenLLaMA 微调分析</title>
      <link>https://arxiv.org/abs/2402.04627</link>
      <description><![CDATA[最近，大型语言模型 (LLM) 在各种自然语言处理应用中取得的成功，为利用 LLM 的知识图谱新型问答系统开辟了道路。然而，阻碍其实现的主要障碍之一是缺乏将问题转换为相应 SPARQL 查询的训练数据，特别是在特定于领域的 KG 的情况下。为了克服这一挑战，在本研究中，我们评估了几种微调 OpenLlama LLM 以回答生命科学知识图问题的策略。特别是，我们提出了一种端到端数据增强方法，用于将给定知识图上的一组现有查询扩展到语义丰富的问题​​到 SPARQL 查询对的更大数据集，甚至可以对这些数据集进行微调对是稀缺的。在这种情况下，我们还研究了查询中语义“线索”的作用，例如有意义的变量名称和内联注释。最后，我们在现实世界的 Bgee 基因表达知识图谱上评估了我们的方法，结果表明，与具有随机变量名称且不包含注释的基线相比，语义线索可以将模型性能提高高达 33%。]]></description>
      <guid>https://arxiv.org/abs/2402.04627</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>根据在线人工智能反馈直接语言模型对齐</title>
      <link>https://arxiv.org/abs/2402.04792</link>
      <description><![CDATA[偏好直接调整 (DAP) 方法（例如 DPO）最近已成为人类反馈强化学习 (RLHF) 的有效替代方案，不需要单独的奖励模型。然而，DAP 方法中使用的偏好数据集通常是在训练之前收集的，并且从未更新，因此反馈纯粹是离线的。此外，这些数据集中的响应通常是从与正在对齐的语言模型不同的语言模型中采样的，并且由于模型在训练过程中不断发展，因此对齐阶段不可避免地会偏离策略。在这项研究中，我们认为在线反馈是关键并改进了 DAP 方法。我们的方法，在线人工智能反馈（OAIF），使用 LLM 作为注释器：在每次训练迭代中，我们从当前模型中采样两个响应，并提示 LLM 注释器选择首选哪一个，从而提供在线反馈。尽管它很简单，但我们通过在多项任务中的人工评估证明 OAIF 优于离线 DAP 和 RLHF 方法。我们进一步表明，通过 LLM 注释器的指令提示，OAIF 中利用的反馈很容易控制。]]></description>
      <guid>https://arxiv.org/abs/2402.04792</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型代理可以模拟人类信任行为吗？</title>
      <link>https://arxiv.org/abs/2402.04559</link>
      <description><![CDATA[大型语言模型 (LLM) 代理已越来越多地被用作模拟工具，在社会科学等应用中对人类进行建模。然而，一个基本问题仍然存在：LLM 代理真的可以模拟人类行为吗？在本文中，我们关注人类互动中最关键的行为之一——信任，并旨在研究LLM代理是否可以模拟人类信任行为。我们首先发现LLM代理人在行为经济学广泛认可的信任博弈框架下普遍表现出信任行为，称为代理人信任。然后，我们发现LLM代理可以在信任行为方面与人类具有高度的行为一致性，这表明用LLM代理模拟人类信任行为的可行性。此外，我们还探讨了代理信任的偏差以及代理对代理和人类的信任的差异。我们还探索了在高级推理策略和外部操作等条件下代理信任的内在属性。我们进一步为信任至关重要的各种场景提供了重要的启示。我们的研究代表了理解法学硕士代理人的行为和法学硕士与人类类比的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2402.04559</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>S-Agents：开放环境中的自组织代理</title>
      <link>https://arxiv.org/abs/2402.04578</link>
      <description><![CDATA[利用大型语言模型 (LLM)，自主代理得到了显着改进，获得了处理各种任务的能力。在开放式环境中，优化协作以提高效率和效果需要灵活的调整。尽管如此，当前的研究主要强调固定的、以任务为导向的工作流程，而忽视了以代理为中心的组织结构。从人类组织行为中汲取灵感，我们引入了一种自组织代理系统（S-Agents），该系统具有用于动态工作流程的“代理树”结构、用于平衡信息优先级的“沙漏代理架构”以及“无阻碍协作” “方法允许代理之间异步执行任务。这种结构可以自主协调一组智能体，无需人工干预即可有效应对开放动态环境的挑战。我们的实验表明，S-Agents 在 Minecraft 环境中熟练地执行协作构建任务和资源收集，验证了其有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.04578</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>解决软件产品线中优先级成对测试数据生成问题的CMSA算法</title>
      <link>https://arxiv.org/abs/2402.04597</link>
      <description><![CDATA[在软件产品线 (SPL) 中，由于可能存在大量有效的功能组合，因此测试该系列的所有产品可能很困难甚至不可能。因此，我们希望找到产品系列的最小子集，使我们能够测试所有这些可能的组合（成对）。此外，当测试单个产品需要付出很大的努力时，最好首先测试由一组优先功能组成的产品。该问题称为优先化成对测试数据生成问题。
  针对此问题的基于整数线性规划的最先进算法对于中小型实例来说足够快。然而，由于候选解的数量呈指数增长，存在一些太大的实际实例，无法在合理的时间内用这些算法进行计算。此外，这些启发法并不总能引导我们找到最佳解决方案。在这项工作中，我们提出了一种基于混合元启发式算法的新方法，称为“构造、合并、求解和适应”。我们将此数学方法与四种算法进行比较：基于整数线性规划 (HILP) 的混合算法、基于整数非线性规划 (HINLP) 的混合算法、并行优先级遗传求解器 (PPGS) 以及称为优先级-ICPL 的贪婪算法分析表明，在大多数情况下和大多数加权覆盖级别下，CMSA 会产生统计上显着更高质量的解决方案，尽管它需要更多的执行时间。]]></description>
      <guid>https://arxiv.org/abs/2402.04597</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>行人过街决策可以通过嘈杂视觉感知下的有界最优决策来解释</title>
      <link>https://arxiv.org/abs/2402.04370</link>
      <description><![CDATA[本文提出了一种基于计算理性理论的行人过路决策模型。假设交叉决策是有界最优的，最优性的界限源于人类认知的局限性。虽然以前的行人行为模型要么是“黑匣子”机器学习模型，要么是对认知因素有明确假设的机械模型，但我们将这两种方法结合起来。具体来说，我们对人类视觉感知的机械噪声进行建模，并假定交叉时的奖励，但我们使用强化学习来学习有界最优行为策略。该模型比以前的模型重现了更多的已知经验现象，特别是：（1）接近车辆的到达时间对行人是否接受间隙的影响，车辆速度对两者的影响（2）间隙接受度和（3）行人在让行车辆前面过马路的时间，以及（4）让行车辆的停车距离对过马路时间的影响。值得注意的是，我们的研究结果表明，以前被视为决策“偏见”的行为，例如速度相关的间隙接受，可能是对视觉感知限制的理性适应的产物。我们的方法还允许拟合每个人的认知约束和奖励参数，以更好地解释个体差异。总而言之，通过利用强化学习和机械建模，我们的模型提供了有关行人行为的新颖见解，并可能为更准确和可扩展的行人模型提供有用的基础。]]></description>
      <guid>https://arxiv.org/abs/2402.04370</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>通过答案集编程进行反事实生成</title>
      <link>https://arxiv.org/abs/2402.04382</link>
      <description><![CDATA[自动化决策的机器学习模型越来越多地应用于贷款审批、审前保释批准、招聘等领域。不幸的是，大多数这些模型都是黑匣子，即它们无法揭示它们是如何做出这些预测决策的。透明度的需要需要为此类预测提供理由。受影响的个人可能还需要解释以了解做出决定的原因。道德和法律方面的考虑可能还需要告知个人输入属性的变化，这些变化可以产生期望的结果。本文重点讨论后一个自动生成反事实解释的问题。我们提出了一个 Counterfactual Generation with s(CASP) (CFGS) 框架，该框架利用答案集编程 (ASP) 和 s(CASP) 目标导向 ASP 系统，根据基于规则的机器学习 (RBML) 生成的规则自动生成反事实解释算法。在我们的框架中，我们展示了如何通过想象一些或所有事实假设被改变/改变的世界来计算和证明反事实解释。更重要的是，我们展示了如何在这些世界之间导航，即从我们获得不期望结果的原始世界/场景到我们获得期望/有利结果的想象世界/场景。]]></description>
      <guid>https://arxiv.org/abs/2402.04382</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>我们必须解决的人工智能十大难题</title>
      <link>https://arxiv.org/abs/2402.04464</link>
      <description><![CDATA[我们探讨了阻碍人工智能前景并导致人工智能风险的AI2050“难题”：（1）开发系统的通用能力； (2) 确保人工智能系统及其训练过程的性​​能； (3) 使系统目标与人类目标保持一致； （4）让人工智能在现实生活中得到很好的应用； (5) 解决经济混乱问题； （六）保证全民参与； (7) 同时确保对社会负责的部署； (8) 解决人工智能造成的任何地缘政治混乱； (9) 促进技术的健全治理； (10) 应对人工智能时代人类的哲学颠覆。对于每个问题，我们都会概述该领域，确定近期的重要工作，并提出前进的方向。 [注：本文回顾了截至 2023 年 1 月的文献。]]]></description>
      <guid>https://arxiv.org/abs/2402.04464</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>解决物联网中身份识别问题的逻辑识别方法</title>
      <link>https://arxiv.org/abs/2402.04338</link>
      <description><![CDATA[最近出现的逻辑代数方法和值逻辑方法的一个新应用领域是识别各种对象和现象、医学或技术诊断、构建现代机器、检查测试问题等问题。可以简化为构造逻辑函数到整个特征空间的最佳扩展。例如，在逻辑识别系统中，使用基于离散分析的逻辑方法和基于它的命题演算来构建自己的识别算法。在一般情况下，逻辑识别方法的使用提供了由 k 值函数在整个特征空间上的最优连续表示的逻辑连接的存在，其中变量是被识别的对象或现象的逻辑特征。认可。这项工作的目标是开发一种用于对象识别的逻辑方法，该方法由具有逻辑特征的参考表和不相交对象的类组成，这些对象被指定为来自给定特征空间的向量。该方法包括将参考表视为并非处处定义的逻辑函数，并构造逻辑函数到整个特征空间的最优延拓，这决定了类到整个空间的扩展。]]></description>
      <guid>https://arxiv.org/abs/2402.04338</guid>
      <pubDate>Thu, 08 Feb 2024 06:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>