<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ai更新在arxiv.org上</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.ai在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过信息内容扩展来检查两个HOP推理</title>
      <link>https://arxiv.org/abs/2502.03490</link>
      <description><![CDATA[ARXIV：2502.03490V1公告类型：新 
摘要：先前的工作发现，变形金刚具有学习回答潜在两跳的问题的能力不一致 - 形式的问题是“谁是鲍勃的母亲的老板？”我们通过研究变形金刚如何学习两跳问题和答案数据集的能力（两跳质量质量质量质量质量）的能力，这是这种情况，这是这种情况，这是由于先前在变压器知识能力上进行简单事实记忆的工作的动机。我们发现能力缩放和概括都支持了以下假设：潜在的两跳质量质量质量质量质量质量质量质量质量质量质量质量质量质量质量标准质量质量器需要两次学习每个事实，而具有思想链的两跳质量质量质量质量质量却没有。我们还表明，借助适当的数据集参数，可以在制度中“捕获”非常小的模型，在该制度中，他们可以独立地记住对两跳跃问题的答案，即使他们可以通过函数组成来回答它们，他们的表现会更好。我们的发现表明，容量缩放的测量可以补充现有的可解释性方法，尽管用于此目的存在挑战。]]></description>
      <guid>https://arxiv.org/abs/2502.03490</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Yinyang-Align：基准矛盾的目标并提出基于多目标优化的DPO，用于文本对象对齐</title>
      <link>https://arxiv.org/abs/2502.03512</link>
      <description><![CDATA[ARXIV：2502.03512V1公告类型：新 
摘要：文本到图像（T2i）系统中的精确对齐对于确保生成的视觉效果不仅准确地封装用户意图，而且还符合严格的道德和美学基准，至关重要。像Google Gemini惨败这样的事件，未对准的产出引发了重大的公众反弹，强调了对强大比对机制的关键需求。相反，大型语言模型（LLM）在对齐方面取得了显着的成功。在这些进步的基础上，研究人员渴望将类似的对齐技术（例如直接偏好优化（DPO））应用于T2I系统，以增强图像产生的保真度和可靠性。
  我们提出了Yinyangalign，这是一个高级基准测试框架，系统地量化了T2I系统的一致性保真度，解决了六个基本且固有的矛盾设计目标。每对都代表图像生成的基本紧张局势，例如平衡遵守用户提示与创造性修改或保持视觉连贯性的多样性。 YinyAngalign包括具有人类提示，对齐（选择）响应，未对准（被拒绝的）AI生成的输出的详细公理数据集以及对基本矛盾的解释。]]></description>
      <guid>https://arxiv.org/abs/2502.03512</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用字母测定法解决奥林匹克几何形状时的金医师表演2</title>
      <link>https://arxiv.org/abs/2502.03544</link>
      <description><![CDATA[ARXIV：2502.03544V1公告类型：新 
摘要：我们介绍了AlphageMetry2，这是Trinh等人中引入的字母计量法的显着改进的版本。 （2024），现在已经超过了解决奥林匹克几何问题的平均金牌得主。为了实现这一目标，我们首先将原始的字母计量学语言扩展到解决涉及对象运动的更严重问题，以及包含角度，比率和距离的线性方程的问题。这与其他增加一起显着提高了国际数学奥林匹克运动会（IMO）2000-2024几何问题的覆盖率从66％到88％。通过使用Gemini架构来更好地建模，并且通过使用Gemini架构以及一种结合了多个搜索树的新型知识共享机制，可以极大地改善Alphageometry2的搜索过程。加上对符号发动机和合成数据生成的进一步增强，我们在过去25年中的$ \ textit {ast textit {All} $几何问题的总体解决速率显着提高到84％，而先前的54％。 Alphageometry2也是在IMO 2024 https://dpmd.ai/imo-silver上实现银色标准的系统的一部分。最后但并非最不重要的一点是，我们报告了使用Alphageometry2作为完全自动化系统的一部分，该系统直接从自然语言输入中可靠地解决了几何问题。]]></description>
      <guid>https://arxiv.org/abs/2502.03544</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多代理抹布系统通过异质资源集成来提高在线学习效率</title>
      <link>https://arxiv.org/abs/2502.03948</link>
      <description><![CDATA[ARXIV：2502.03948V1公告类型：新 
摘要：有效的在线学习需要无缝访问各种资源，例如视频，代码存储库，文档和一般的Web内容。这份海报论文介绍了有关多代理检索生成（RAG）系统的早期工作，旨在通过整合这些异质资源来提高学习效率。使用针对特定资源类型量身定制的专用代理（例如，YouTube教程，GitHub存储库，文档网站和搜索引擎），该系统可自动检索和合成相关信息。通过简化查找和结合知识的过程，这种方法可以减少手动努力并增强学习经验。一项初步的用户研究证实了该系统的强大可用性和中等高级的实用性，证明了其提高知识获取效率的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.03948</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>好的，我会自己合并：自动模型合并的多保真框架</title>
      <link>https://arxiv.org/abs/2502.04030</link>
      <description><![CDATA[ARXIV：2502.04030V1公告类型：新 
摘要：推理能力代表了大型语言模型（LLMS）的关键边界，但是开发它们需要广泛的专有数据集和计算资源。通过模型合并有效地补充功能的一种方法，它通过在不重新培训的情况下组合多个模型来提供有希望的替代方案。但是，当前的合并方法依赖于手动设计的策略来合并超参数，限制了潜在模型组合的探索并需要大量的人类努力。我们提出了一个自动化模型合并框架，该框架能够对合并策略进行精细的探索，同时通过多余性近似来降低成本。我们支持单目标优化和多目标优化，并引入了两个新颖的搜索空间：layerwise Fusion（LFS）和深度整合（DIS）。通过在许多基准测试中评估搜索自主发现的1）合并以进一步提高单目标性能的合并，即使在任务上，该模型已经被填写了，并且2）合并在跨任务中优化多目标边界的合并。发现有效合并有限的计算，例如在不到500个搜索步骤中。]]></description>
      <guid>https://arxiv.org/abs/2502.04030</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>战略学习和本地解释作为反馈</title>
      <link>https://arxiv.org/abs/2502.04058</link>
      <description><![CDATA[ARXIV：2502.04058V1公告类型：新 
摘要：我们调查了算法决策问题，代理可以对决策者（DM）模型进行战略性响应。 DMS到（潜在战略性）代理商对明确和可行的解释的需求继续增加。尽管先前的工作通常将解释视为完整模型披露，但实践中的解释可能只传达部分信息，这可能导致误解和有害的回应。当对预测模型的完全披露既不是可行的也不是可取的时，一个关键的开放问题是，DMS如何使用解释来最大化其实用性，而无需损害代理的福利。在这项工作中，我们探讨了众所周知的本地和全球解释方法，并建立了必要的条件，以防止误导代理人进入自我伤害行动。此外，通过有条件的同质性，我们确定了行动建议（AR）的解释足以进行无害的响应，类似于信息设计的启示原则。为了实现基于AR的解释，我们提出了一种简单的算法，以共同优化预测模型和AR策略，以平衡DM结果与代理福利。我们的经验结果证明了这种方法的好处是在算法决策中对安全有效的部分模型披露的更精致的策略。]]></description>
      <guid>https://arxiv.org/abs/2502.04058</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自由能源风险的全身安全AI：守门多代理研究</title>
      <link>https://arxiv.org/abs/2502.04249</link>
      <description><![CDATA[ARXIV：2502.04249V1公告类型：新 
摘要：我们研究自由能原理是衡量代理和多代理系统风险的基础。从这些原则中，我们引入了一个累积的风险暴露度量，该指标在不同的环境和需求中灵活。我们将其与其他流行的AI理论进行对比，该理论取决于大量数据或描述任意复杂的世界模型。在我们的框架中，利益相关者只需要指定他们对系统结果的偏好，从而为风险治理和缓解措施提供直接且透明的决策规则。该框架自然说明了世界模型和偏好模型中的不确定性，从而可以在认识论和公理上谦虚，简约和未来的决策。我们在简化的自动驾驶汽车环境中展示了这种新颖的方法，其驾驶政策是由守门人介导的，这些驾驶政策是由网上方式评估其附近集体安全风险的，并在适当的情况下介入了每辆车的政策。我们表明，即使在较低的渗透率下，也可以在系统安全性提高方面引入守门人，即使在低渗透率下也可以产生显着的积极外部性。]]></description>
      <guid>https://arxiv.org/abs/2502.04249</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在答案集编程中具有强大的等效性和约束</title>
      <link>https://arxiv.org/abs/2502.04302</link>
      <description><![CDATA[ARXIV：2502.04302V1公告类型：新 
摘要：我们调查了在答案集编程的扩展框架内具有约束的概念。如果非正式地说，在任何情况下它们具有相同的含义，则认为两组规则是强烈的等效物。我们证明，在某些假设下，在此扩展设置中规则集之间的强大等价性可以精确地以它们在此处的逻辑中的等效性为特征。此外，我们提出了几个基于克林戈的答案集求解器的语言的翻译，这些求解器将约束限制到这里的语言以及受到约束。这种翻译使我们能够利用这里和在这些求解器中有强大等价的理由的逻辑。我们还探讨了在这种情况下确定强相等性的计算复杂性。]]></description>
      <guid>https://arxiv.org/abs/2502.04302</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI保证可能会出错的地方：关键系统工程的初始课程</title>
      <link>https://arxiv.org/abs/2502.03467</link>
      <description><![CDATA[ARXIV：2502.03467V1公告类型：交叉 
摘要：我们借鉴了在系统和软件保证和对社会重要的系统评估方面工作的经验，以总结在传统关键系统（例如飞机飞行控制）中如何执行安全工程的经验。我们分析了这种关键系统观点如何支持AI安全框架的开发和实施。我们介绍了以下方面的分析：系统工程，安全和风险分析以及决策分析和支持。
  我们考虑四个关键问题：系统是什么？它必须有多好？批判性对系统开发的影响是什么？我们应该信任多少？我们确定值得进一步讨论的话题。特别是，我们担心系统界限不够广泛，风险的宽容性和性质不够充分阐述，并且保证方法缺乏可以充分保证行为的理论。
  我们主张使用基于Assurance 2.0的保证案例来支持决策的决策以及评估系统的关键性的决策。我们指出，关键系统而不是日常系统所需的信心的幅度差异以及日常技术如何不进行严格规模。
  最后，我们将发现的发现详细介绍给FAISC组织者提出的两个问题，我们注意到关键系统的工程通过开放和多样化的讨论而发展。我们希望这里确定的主题将支持FAIS后对话。]]></description>
      <guid>https://arxiv.org/abs/2502.03467</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI伦理的能力方法</title>
      <link>https://arxiv.org/abs/2502.03469</link>
      <description><![CDATA[ARXIV：2502.03469V1公告类型：交叉 
摘要：我们通过能力方法提出了AI伦理的概念化和实施。我们的目的是表明，通过能力方法概念化AI伦理学对AI伦理作为纪律具有两个主要优势。首先，它有助于阐明AI工具的道德维度。其次，它为在AI工具的设计中实施道德考虑提供了指导。我们通过展示了基于伦理学的医学工具在医学上的AI工具的背景下说明这些优势，从而可以从我们基于能力的方法中受益匪浅。]]></description>
      <guid>https://arxiv.org/abs/2502.03469</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>域专家可以适当依靠AI吗？关于AI辅助前列腺癌MRI诊断的案例研究</title>
      <link>https://arxiv.org/abs/2502.03482</link>
      <description><![CDATA[ARXIV：2502.03482V1公告类型：交叉 
摘要：尽管对人类AI决策的兴趣日益增加，但与领域专家的实验研究仍然很少见，这在很大程度上是由于与域专家合作的复杂性以及在建立现实实验方面所面临的挑战。在这项工作中，我们根据MRI图像与前列腺癌诊断中的放射科医生进行了深入的合作。在现有的教学前列腺癌诊断工具的基础上，我们开发了一个接口，并进行了两个实验，以研究AI援助和性能反馈如何塑造领域专家的决策。在研究1中，要求临床医生提供初始诊断（人类），然后查看AI的预测，然后最终确定其决定（人类AI团队）。在研究2（记忆力消除期之后）中，相同的参与者首先从研究1获得了汇总的绩效统计数据，特别是他们自己的表现，AI的表现和他们的人类AI团队绩效，然后直接直接查看了AI的预测进行诊断（即没有独立的初始诊断）。这两个工作流代表了现实的方式，即在实践中可以使用临床AI工具，第二项研究模拟了医生可以根据先前的绩效反馈来调整其对AI的依赖和信任的情况。我们的发现表明，尽管人类团队始终单独超过人类，但由于不足的依赖，他们仍然表现不佳，类似于与人群工人的先前研究。为临床医生提供绩效反馈并没有显着改善人类团队的性能，尽管事先显示了AI的决定使人们更多地跟随AI。同时，我们观察到，人类团队的合奏可以胜过AI，这暗示了人类合作的有希望的指示。]]></description>
      <guid>https://arxiv.org/abs/2502.03482</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和法律分析：对法律教育和专业的影响</title>
      <link>https://arxiv.org/abs/2502.03487</link>
      <description><![CDATA[ARXIV：2502.03487V1公告类型：交叉 
摘要：本文报告了一项研究的结果，研究了法律和非法律大语言模型使用问题规则 - 申请解决框架进行法律分析的能力。对LLM进行了针对涉及规则分析和类比推理的法律推理任务的测试。结果表明，LLM可以进行基本的IRAC分析，但受到缺乏细节的简短答复的限制，无法提交答案，虚假的信心和幻觉。该研究比较了法律和非法律学士学位，确定了缺点，并探讨了可能会阻碍他们像律师一样思考的特征。它还讨论了对法律教育和实践的影响，强调了未来律师中批判性思维技能的需求以及对人工智能AI过度依赖的潜在陷阱，从而导致逻辑，推理和批判性思维技能的丧失。]]></description>
      <guid>https://arxiv.org/abs/2502.03487</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教语言模型通过加强学习来批评</title>
      <link>https://arxiv.org/abs/2502.03492</link>
      <description><![CDATA[ARXIV：2502.03492V1公告类型：交叉 
摘要：教导大语模型（LLMS）批评和完善其产出对于可以迭代改进的建筑系统至关重要，但是它在根本上受到提供准确的判断和可行建议的能力的限制。在这项工作中，我们研究了代码生成的LLM评论家，并提出$ \ texttt {ctrl} $，$ \ texttt {c} $ ritic $ \ texttt {t} $通过$ \ texttt {r texttt {r} \ texttt {l} $ ginning，该奖励模型生成反馈，该反馈最大程度地提高了固定发电机模型的校正性能，而无需人工监督。我们的结果表明，经过$ \ texttt {ctrl} $培训的评论家显着提高了通过率，并减轻基本和更强的发电机模型的复合错误。此外，我们表明这些评论家模型充当准确的生成奖励模型，并通过迭代批判性革命进行测试时间扩展，从而在挑战性的代码生成基准中实现了高达106.1％的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2502.03492</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Omni-DNA：统一的跨模式和多任务学习的基因组基础模型</title>
      <link>https://arxiv.org/abs/2502.03499</link>
      <description><![CDATA[ARXIV：2502.03499V1公告类型：交叉 
摘要：大型语言模型（LLMS）在各种任务中表现出显着的普遍性，但是基因组基础模型（GFMS）仍然需要为每个下游应用程序单独进行填充，随着模型尺寸的增长而产生了重要的开销。此外，现有的GFM受刚性输出格式的限制，从而将其适用性限制在各种基因组任务中。在这项工作中，我们重新访问了基于变压器的自动回归模型，并引入了Omni-DNA，Omni-DNA是一个跨模式多任务模型，范围从2000万到10亿个参数。我们的方法由两个阶段组成：（i）对DNA序列进行预处理，并具有下一个令牌预测目标，以及（ii）为多个下游任务的多模式特定任务特异性令牌和填充扩展。当对核苷酸变压器和GB基准测试进行评估时，Omni-DNA可以在26个任务中的18个任务中实现最先进的性能。通过多任务登录，Omni-DNA立即解决10个乙酰化和甲基化任务，超过了对每个任务进行训练的模型。最后，我们设计了两个复杂的基因组任务，即DNA2功能和针中的DNA，它们分别将DNA序列映射到文本功能描述和图像，表明Omni-DNA的跨模式功能以扩大基因组应用的范围。所有模型均可通过https://huggingface.co/collections/zehui127获得]]></description>
      <guid>https://arxiv.org/abs/2502.03499</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在一致性流匹配有效恢复图像恢复</title>
      <link>https://arxiv.org/abs/2502.03500</link>
      <description><![CDATA[ARXIV：2502.03500V1公告类型：交叉 
摘要：生成图像恢复（IR）的最新进展已显示出令人印象深刻的结果。但是，这些方法的大小和计算需求受到阻碍，使它们不适合在边缘设备上部署。这项工作引入了Elir，这是一种有效的潜在图像恢复方法。 ELIR首先预测最小均方误差（MMSE）估计器的潜在表示，然后使用潜在的一致性基于基于流量的模型将此估算传输到高质量的图像。因此，与最先进的扩散和基于流动的方法相比，ELIR的速度快4倍以上。此外，Elir也小于4倍以上，非常适合在资源受限的边缘设备上部署。对各种图像恢复任务的全面评估表明，ELIR取得了竞争成果，有效地平衡了失真和感知质量指标，同时在记忆和计算方面提供了提高的效率。]]></description>
      <guid>https://arxiv.org/abs/2502.03500</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>