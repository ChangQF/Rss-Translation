<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 28 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>reBandit：基于随机效应的在线强化学习算法，用于减少大麻使用</title>
      <link>https://arxiv.org/abs/2402.17739</link>
      <description><![CDATA[arXiv:2402.17739v1 公告类型：新
摘要：大麻使用率的不断上升以及相关的大麻使用障碍（CUD）对全球公共卫生构成了重大挑战。由于治疗差距明显较大，特别是在新兴成年人（EA；18-25 岁）中，解决大麻使用和 CUD 问题仍然是 2030 年联合国可持续发展目标议程 (SDG) 中的一个关键目标。在这项工作中，我们开发了一种名为 reBandit 的在线强化学习 (RL) 算法，该算法将在移动健康研究中使用，以提供个性化的移动健康干预措施，旨在减少 EA 中的大麻使用。 reBandit 利用随机效应和信息丰富的贝叶斯先验，在嘈杂的移动健康环境中快速有效地学习。此外，reBandit采用经验贝叶斯和优化技术来在线自主更新其超参数。为了评估我们算法的性能，我们使用先前研究的数据构建了一个模拟测试台，并与移动健康研究中常用的算法进行比较。我们表明，reBandit 的性能与所有基线算法相同或更好，并且随着模拟环境中群体异质性的增加，性能差距扩大，证明了其适应不同研究参与者群体的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.17739</guid>
      <pubDate>Wed, 28 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>Agent-Pro：通过策略级反思和优化学习进化</title>
      <link>https://arxiv.org/abs/2402.17574</link>
      <description><![CDATA[arXiv:2402.17574v1 公告类型：新
摘要：大型语言模型表现出针对不同任务的强大的问题解决能力。然而，大多数基于 LLM 的代理被设计为具有复杂提示工程的特定任务解决器，而不是能够通过交互学习和进化的代理。这些任务解决器需要手动制作提示来告知任务规则并规范 LLM 行为，本质上无法解决复杂的动态场景，例如大型互动游戏。有鉴于此，我们提出了 Agent-Pro：一种基于 LLM 的 Agent，具有策略级反射和优化功能，可以从交互体验中学习丰富的专业知识，并逐步提升其行为策略。具体来说，它涉及政策演变的动态信念生成和反思过程。 Agent-Pro 不是进行行动层面的反思，而是迭代地反思过去的轨迹和信念，微调其非理性信念以获得更好的政策。此外，采用深度优先搜索进行策略优化，确保策略收益不断增强。 Agent-Pro 在两种游戏中进行了评估：二十一点和德州扑克，其表现优于普通 LLM 和专业模型。我们的结果表明 Agent-Pro 可以在复杂和动态的场景中学习和发展，这也有利于众多基于 LLM 的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2402.17574</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>基于案例或基于规则：Transformers 如何进行数学运算？</title>
      <link>https://arxiv.org/abs/2402.17709</link>
      <description><![CDATA[arXiv:2402.17709v1 公告类型：新
摘要：尽管现代大型语言模型（LLM）在各种复杂任务中表现出色，但在处理一些对人类来说简单直观的数学问题（例如加法）时仍然遇到困难。虽然我们可以轻松学习加法的基本规则并将其应用于任何长度的新问题，但法学硕士却很难做到这一点。相反，他们可能会依靠训练语料库中看到的类似“案例”来寻求帮助。我们将这两种不同的推理机制定义为“基于规则的推理”和“基于案例的推理”。由于基于规则的推理对于获得系统泛化能力至关重要，因此我们的目标是准确探索 Transformer 是否使用基于规则的推理或基于案例的推理来解决数学问题。通过对五个数学任务精心设计的干预实验，我们确认 Transformer 正在执行基于案例的推理，无论是否使用暂存器，这与之前的观察一致，即 Transformer 使用子图匹配/快捷学习进行推理。为了缓解此类问题，我们提出了一种规则遵循微调（RFFT）技术来教导 Transformer 执行基于规则的推理。具体来说，我们在输入中提供明确的规则，然后指导 Transformer 逐步背诵并遵循规则。通过 RFFT，我们成功地使法学硕士能够在 1-5 位加法上进行微调，以推广到 12 位加法，准确率超过 95%，比暂存器高出 40% 以上。这一显着改进表明，教导法学硕士明确使用规则有助于他们学习基于规则的推理并在长度上更好地概括。]]></description>
      <guid>https://arxiv.org/abs/2402.17709</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>KANDY 基准：增量神经符号学习和康定斯基模式推理</title>
      <link>https://arxiv.org/abs/2402.17431</link>
      <description><![CDATA[arXiv:2402.17431v1 公告类型：新
摘要：人工智能不断寻求新的挑战和基准，以有效衡量性能并推进最先进的技术。在本文中，我们介绍了 KANDY，这是一个基准测试框架，可用于生成受康定斯基模式启发的各种学习和推理任务。通过创建复杂性不断增加且监督稀疏的二元分类任务课程，KANDY 可用于实现持续和半监督学习的基准，特别关注符号组合性。基本事实中还提供了分类规则，以便能够分析可解释的解决方案。与基准生成流程一起，我们发布了两门课程，一个更简单，一个更难，我们建议将其作为研究界的新挑战。通过彻底的实验评估，我们展示了最先进的神经模型和纯粹的符号方法如何努力解决大多数任务，因此需要应用随着时间的推移训练的先进神经符号方法。]]></description>
      <guid>https://arxiv.org/abs/2402.17431</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>COCOA：基于 CBT 的对话咨询代理，使用专门从事认知扭曲和动态提示的记忆</title>
      <link>https://arxiv.org/abs/2402.17546</link>
      <description><![CDATA[arXiv:2402.17546v1 公告类型：新
摘要：对提供心理健康护理的会话代理的需求不断增加。在这项工作中，我们开发了一种心理咨询代理，称为 CoCoA，它应用认知行为疗法 (CBT) 技术来识别和解决客户陈述中固有的认知扭曲。具体来说，我们构建了一个记忆系统，以有效管理咨询所需的信息，同时从客户的话语中提取有关客户的高级见解。此外，为了确保咨询代理产生适当的反应，我们引入动态提示来灵活应用CBT技术并促进适当的信息检索。我们在 CoCoA 和 Character.ai 的角色之间进行对话，创建用于评估的数据集。然后，我们要求 GPT 评估构建的咨询数据集，我们的模型与其他模型表现出统计上的显着差异。]]></description>
      <guid>https://arxiv.org/abs/2402.17546</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>OmniACT：为桌面和 Web 启用多模式通才自治代理的数据集和基准</title>
      <link>https://arxiv.org/abs/2402.17553</link>
      <description><![CDATA[arXiv:2402.17553v1 公告类型：新
摘要：几十年来，人机交互基本上都是手动的。即使在今天，几乎所有在计算机上完成的生产性工作都需要人工在每一步进行输入。自主虚拟代理代表了许多这些琐碎任务自动化的令人兴奋的一步。虚拟代理将使技术能力有限的用户能够充分利用计算机系统的可能性。它们还可以有效地简化大量计算机任务，从日历管理到复杂的旅行预订，而无需人工干预。在本文中，我们介绍了 OmniACT，这是第一个用于评估代理生成可执行程序以完成计算机任务的能力的数据集和基准。我们的范围超出了传统的网络自动化，涵盖了各种桌面应用程序。该数据集包含“播放下一首歌曲”等基本任务，以及“向 John Doe 发送电子邮件，提及见面的时间和地点”等长期任务。具体来说，给定一对屏幕图像和一个基于视觉的自然语言任务，目标是生成能够完全执行该任务的脚本。我们在基准测试中运行了几个强大的基线语言模型代理。最强的基线 GPT-4 在我们的基准测试中表现最好，但是，在生成能够完成任务的可执行脚本方面，其性能水平仍然仅达到人类熟练程度的 15%，这表明我们的任务对传统 Web 代理的挑战。我们的基准测试提供了一个平台来衡量和评估语言模型代理在自动化计算机任务方面的进展，并激励未来的工作构建连接大型语言模型和计算机屏幕视觉基础的多模态模型。]]></description>
      <guid>https://arxiv.org/abs/2402.17553</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>数据科学代理基准测试</title>
      <link>https://arxiv.org/abs/2402.17168</link>
      <description><![CDATA[arXiv:2402.17168v1 公告类型：新
摘要：在数据驱动决策的时代，数据分析的复杂性需要先进的数据科学专业知识和工具，这对专家来说也提出了巨大的挑战。大型语言模型 (LLM) 已成为数据科学代理的有前途的辅助工具，可帮助人类进行数据分析和处理。然而，它们的实际功效仍然受到现实应用的不同需求和复杂的分析过程的限制。在本文中，我们介绍了 DSEval——一种新颖的评估范式，以及一系列为评估这些代理在整个数据科学生命周期中的性能而定制的创新基准。结合一种新颖的引导注释方法，我们简化了数据集准备，提高了评估覆盖率，并扩展了基准测试的全面性。我们的研究结果揭示了普遍存在的障碍，并为该领域未来的进步提供了重要的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.17168</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>多智能体、人类智能体及其他：社会困境中的合作调查</title>
      <link>https://arxiv.org/abs/2402.17270</link>
      <description><![CDATA[arXiv:2402.17270v1 公告类型：新
摘要：社会困境中的合作研究长期以来一直是包括计算机科学和社会科学在内的各个学科的基本主题。人工智能 (AI) 的最新进展极大地重塑了这一领域，为理解和加强合作提供了新的见解。这项调查研究了人工智能与社会困境中的合作交叉点的三个关键领域。首先，我们关注多智能体合作，回顾了支持理性智能体之间合作的内在和外在动机，以及针对不同对手制定有效策略的方法。其次，研究人类与智能体的合作，我们讨论了当前与人类合作的人工智能算法以及人类对人工智能体的偏见。第三，我们回顾了利用人工智能代理加强人类之间合作的新兴领域。最后，我们讨论了未来的研究途径，例如使用大型语言模型、建立统一的理论框架、重新审视现有的人类合作理论以及探索多种现实世界的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.17270</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士辅助决策的决定因素</title>
      <link>https://arxiv.org/abs/2402.17385</link>
      <description><![CDATA[arXiv:2402.17385v1 公告类型：新
【摘要】：决策能力是日常生活中一项基本能力。大型语言模型 (LLM) 为增强人类决策过程提供多方面的支持。然而，了解LLM辅助决策的影响因素对于使个人能够利用LLM提供的优势并最大程度地减少相关风险以做出更明智和更好的决策至关重要。本研究呈现了综合文献分析的结果，在法学硕士的支持下，对影响决策的决定因素进行了结构概述和详细分析。我们特别探讨了法学硕士技术方面的影响，包括透明度和及时工程、情绪和决策风格等心理因素，以及任务难度和责任等具体决策决定因素。此外，还通过多个应用场景说明了决定因素对决策过程的影响。根据我们的分析，我们开发了一个依赖框架，该框架根据这些决定因素之间的相互依赖关系将可能的相互作用系统化。我们的研究表明，由于与各种决定因素的多方面相互作用，对法学硕士的信任或依赖、用户的心理模型以及信息处理的特征等因素被认为是影响法学硕士辅助决策过程的重要方面。我们的研究结果对于提高人类与人工智能协作的决策质量、增强用户和组织的能力以及设计更有效的法学硕士界面至关重要。此外，我们的工作为未来对法学硕士协助的决策决定因素进行实证研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2402.17385</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>通过突出潜在错误并提出纠正建议，成功地指导人类执行不完美的指令</title>
      <link>https://arxiv.org/abs/2402.16973</link>
      <description><![CDATA[arXiv:2402.16973v1 公告类型：新
摘要：本文解决了在接地导航任务的背景下利用不完美的语言模型来指导人类决策的挑战。我们证明，不完美的指令生成模型可以通过有效的沟通机制来补充，以更成功地指导人类。我们构建的通信机制包括可以检测指令中潜在幻觉并提出实用替代方案的模型，以及向用户呈现该信息的直观界面。我们的研究表明，这种方法可将人类导航误差降低高达 29%，且不会带来额外的认知负担。这一结果强调了将多种通信渠道整合到人工智能系统中的潜力，以弥补其缺陷并增强其对人类的效用。]]></description>
      <guid>https://arxiv.org/abs/2402.16973</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>REFACTOR：学习从证明中提取定理</title>
      <link>https://arxiv.org/abs/2402.17032</link>
      <description><![CDATA[arXiv:2402.17032v1 公告类型：新
摘要：人类数学家通常擅长识别模块化和可重用的定理，这些定理使复杂的数学结果触手可及。在本文中，我们提出了一种称为定理提取器（REFACTOR）的新方法，用于训练神经网络以模仿形式数学定理证明中的这种能力。我们在一组未见过的证明上展示，REFACTOR 能够提取人类用来编写证明的 19.6% 的定理。当将该模型应用于现有的 Metamath 库时，REFACTOR 提取了 16 个新定理。通过新提取的定理，我们表明可以重构 MetaMath 数据库中的现有证明。新定理重构后使用频率很高，平均使用次数为733.5次，有助于缩短证明长度。最后，我们证明了在新定理重构数据集上训练的证明者通过频繁利用一组不同的新提取的定理来证明更多的测试定理并超越最先进的基线。代码可以在 https://github.com/jinpz/refactor 找到。]]></description>
      <guid>https://arxiv.org/abs/2402.17032</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>参与式城市规划的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.17161</link>
      <description><![CDATA[arXiv:2402.17161v1 公告类型：新
摘要： 参与式城市规划是现代城市规划的主流，它涉及居民的积极参与。然而，传统的参与范式需要经验丰富的规划专家，而且往往耗时且成本高昂。幸运的是，新兴的大型语言模型（LLM）已经显示出相当大的模拟类人代理的能力，可以用来轻松模拟参与过程。在这项工作中，我们引入了一种基于法学硕士的参与式城市规划多主体协作框架，该框架可以考虑居民的多样化需求，为城市地区制定土地利用规划。具体来说，我们构建了 LLM 代理来模拟规划者和数千名具有不同背景和背景的居民。我们首先要求规划师进行初步的土地利用规划。针对居民不同的设施需求，我们在各个社区发起了居民讨论，居民根据自己的情况提出反馈。此外，为了提高讨论效率，我们采用鱼缸讨论机制，每轮由部分居民进行讨论，其余居民作为倾听者。最后，我们让规划师根据居民的反馈修改方案。我们将我们的方法部署在北京的两个现实世界区域。实验表明，我们的方法在居民满意度和包容性指标方面实现了最先进的性能，并且在服务可及性和生态指标方面也优于人类专家。]]></description>
      <guid>https://arxiv.org/abs/2402.17161</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>EvoGPT-f：用于对形式数学语言进行基准测试的进化 GPT 框架</title>
      <link>https://arxiv.org/abs/2402.16878</link>
      <description><![CDATA[arXiv:2402.16878v1 公告类型：新
摘要：形式数学是将数学转化为编程语言的学科，其中任何语句都可以由计算机明确地检查。数学家和计算机科学家花费了数十年的艰苦形式化努力来开发 Coq、HOL 和 Lean 等语言。机器学习研究已经集中在这些正式的数学语料库上，并产生了各种方法来帮助交互式和自动化的定理证明。然而，这些论文主要关注一种方法、一种语言、一种证明任务。本文介绍了 EvoGPT-f：一种新颖的进化框架，用于使用四种标记化方法（字符、单词）对五个正式数学语料库（Lean 3、Lean 4、Coq、HOL 4、HOL Light）的差异机器学习性进行首次系统定量分析-level、字节对编码和 StarCoder 分词器）。本文并没有解决“最好”或“最容易”学习的语言的问题。相反，这个框架和初步研究结果开始阐明这些语言的不同机器学习能力，为跨社区建立更系统的定量和定性比较研究提供了基础。]]></description>
      <guid>https://arxiv.org/abs/2402.16878</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>通过反应合成对生成代理行为实施时间约束</title>
      <link>https://arxiv.org/abs/2402.16905</link>
      <description><![CDATA[arXiv:2402.16905v1 公告类型：新
摘要：大型语言模型（LLM）的普及为创建交互式代理的新方法打开了大门。然而，在交互过程中管理此类代理的时间行为仍然具有挑战性。连贯代理行为所需的有状态、长期视野和定量推理并不适合法学硕士范式。我们提出将基于形式逻辑的程序合成和法学硕士内容生成相结合，以创建遵守时间约束的生成代理。我们的方法使用时间流逻辑（TSL）来生成一个自动机，该自动机在代理上强制执行时间结构，并将每个动作的细节及时留给 LLM。通过使用 TSL，我们能够增强生成代理，使用户对行为有更高级别的保证、更好的系统可解释性以及更多以模块化方式构建代理的能力。我们评估了我们在创建专门针对各种应用程序领域的连贯交互式代理所涉及的不同任务上的方法。我们发现，在所有任务中，我们使用 TSL 的方法实现了至少 96% 的遵守率，而纯粹基于 LLM 的方法的遵守率低至 14.67%。]]></description>
      <guid>https://arxiv.org/abs/2402.16905</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>信息破碎方面的理论统一</title>
      <link>https://arxiv.org/abs/2402.16924</link>
      <description><![CDATA[arXiv:2402.16924v1 公告类型：新
摘要：本文的主要目标是识别与不必要的方法论假设相关的信息研究中的基本认识论障碍，以及在信息方面的基本划分中揭开流行信仰的神秘面纱，这些基本划分可以理解为认识论障碍的巴什拉德破裂。在这些一般性考虑之前，概述了信息研究的动机以及信息概念在智力、复杂性和意识概念化中的作用，证明了在信息研究中需要一个足够普遍的视角，并且是随后在文章末尾简要阐述了在发展统一信息理论中可能应用的一个例子，而没有不必要的分歧和现有方法论偏好的优越性。加斯顿·巴什拉（Gaston Bachelard）及其关于认识论障碍和认识论断裂的思想似乎非常适合反思信息研究的发展，特别是在信息语义缺失、忽视信息结构分析、分离等障碍的背景下。其数字和模拟形式，以及数学的误导性使用。]]></description>
      <guid>https://arxiv.org/abs/2402.16924</guid>
      <pubDate>Wed, 28 Feb 2024 06:16:55 GMT</pubDate>
    </item>
    </channel>
</rss>