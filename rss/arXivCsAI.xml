<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Thu, 06 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过 CHARCHA 实现安全且个性化的音乐视频生成</title>
      <link>https://arxiv.org/abs/2502.02610</link>
      <description><![CDATA[arXiv:2502.02610v1 公告类型：新
摘要：音乐是一种非常个人化的体验，我们的目标是通过完全自动化的个性化音乐视频生成流程来增强这种体验。我们的工作允许听众不仅是消费者，而且是音乐视频生成过程中的共同创作者，通过根据歌词、节奏和音乐中的情感创建个性化、一致和情境驱动的视觉效果。该流程结合了多模态翻译和生成技术，并利用听众图像的低秩适应来创建既能反映音乐又能反映个人的沉浸式音乐视频。为了确保用户身份的合乎道德的使用，我们还引入了 CHARCHA（正在申请专利），这是一种面部身份验证协议，可保护人们免遭未经授权使用其面部，同时从用户那里收集授权图像以个性化他们的视频。因此，本文为创建深度个性化的音乐视频提供了一个安全且创新的框架。]]></description>
      <guid>https://arxiv.org/abs/2502.02610</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不应开发完全自主的人工智能代理</title>
      <link>https://arxiv.org/abs/2502.02649</link>
      <description><![CDATA[arXiv:2502.02649v1 公告类型：新
摘要：本文认为不应开发完全自主的人工智能代理。为了支持这一立场，我们根据先前的科学文献和当前的产品营销来描述不同的人工智能代理级别，并详细说明每个级别中发挥作用的道德价值观，记录潜在利益和风险的权衡。我们的分析表明，系统自主性越高，对人的风险就越大：用户对人工智能代理的控制越多，对人的风险就越大。特别令人担忧的是安全风险，它会影响人类生命并影响进一步的价值。]]></description>
      <guid>https://arxiv.org/abs/2502.02649</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效且有成本地实现全局基数约束</title>
      <link>https://arxiv.org/abs/2502.02688</link>
      <description><![CDATA[arXiv:2502.02688v1 公告类型：新
摘要：约束编程的成功部分依赖于全局约束和相关过滤算法的实现。最近，出现了一些新的想法来改进这些实现，特别是关于所有不同的约束。在本文中，我们考虑了有成本的基数约束。基数约束是所有不同约束的泛化，它指定了解决方案中给定变量集必须取每个值的次数。有成本的版本引入了分配成本并限制了分配成本的总和。这种约束的弧一致性过滤算法在实践中很难使用，因为它系统地搜索许多最短路径。我们提出了一种基于地标的最短路径上限的新方法。这种方法可以看作是一种预处理。它速度很快，并且在实践中避免了大量最短路径的显式计算。]]></description>
      <guid>https://arxiv.org/abs/2502.02688</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用可供性进行规划：整合学习到的可供性模型和符号规划</title>
      <link>https://arxiv.org/abs/2502.02768</link>
      <description><![CDATA[arXiv:2502.02768v1 公告类型：新
摘要：在现实环境中工作的智能代理必须能够了解环境及其功能，这使它们能够采取行动改变世界状态，从而在逼真的环境中完成复杂的多步骤任务。了解环境对于执行各种多步骤任务尤其重要，而无需为不同的任务或环境设置重新定义代理的操作集。在我们的工作中，我们通过学习到的世界中对象的可供性模型来增强现有的任务和运动规划框架，以便使用学习到的模型规划和执行多步骤任务。每个任务都可以看作是将世界的当前状态更改为给定的目标状态。可供性模型为我们提供了可能的操作以及如何在任何给定状态下执行这些操作。符号规划算法使用此信息以及起始状态和目标状态来创建可行的计划，以达到完成给定任务所需的目标状态。我们在虚拟 3D 逼真环境 AI2-Thor 中展示了我们的方法，并在现实世界任务中对其进行了评估。我们的结果表明，我们的代理可以快速学习如何与环境交互，并做好充分准备来执行诸如“移开物体以到达所需位置”之类的任务。]]></description>
      <guid>https://arxiv.org/abs/2502.02768</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>行动质量评估十年：趋势、挑战和未来方向的最大系统调查</title>
      <link>https://arxiv.org/abs/2502.02817</link>
      <description><![CDATA[arXiv:2502.02817v1 公告类型：新
摘要：动作质量评估 (AQA)——量化人体运动、动作或技能水平并提供反馈的能力——在低成本物理治疗、体育训练和劳动力发展等领域具有深远的影响。因此，在过去十年中，它已成为计算机视觉和视频理解的关键领域。AQA 方法、数据集和应用程序取得了重大进展，但迫切需要对这个快速发展的领域进行全面综合。在本文中，我们对 AQA 领域进行了全面调查，使用系统评价和荟萃分析 (PRISMA) 框架的首选报告项目系统地审查了 200 多篇研究论文。我们首先介绍基础概念和定义，然后转到一般框架和性能指标，最后讨论方法和数据集的最新进展。这项调查提供了对研究趋势、性能比较、挑战和未来方向的详细分析。通过这项工作，我们旨在为新手和经验丰富的研究人员提供宝贵的资源，促进 AQA 的进一步探索和进步。数据可在 https://haoyin116.github.io/Survey_of_AQA/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.02817</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SensorChat：在长期多模式传感器交互过程中回答定性和定量问题</title>
      <link>https://arxiv.org/abs/2502.02883</link>
      <description><![CDATA[arXiv:2502.02883v1 公告类型：新
摘要：自然语言与传感系统的交互对于使所有用户能够理解传感器数据及其对日常生活的影响至关重要。然而，现有的系统通常以问答 (QA) 的方式运行，在它们能够处理的传感器数据的持续时间和复杂性方面受到很大限制。在这项工作中，我们介绍了 SensorChat，这是第一个端到端 QA 系统，旨在使用包括时间序列在内的多模态和高维数据进行长期传感器监控。SensorChat 有效地回答了现实场景中的定性（需要高级推理）和定量（需要从传感器数据中得出的准确响应）问题。为了实现这一点，SensorChat 使用了创新的三阶段管道，包括问题分解、传感器数据查询和答案组装。第一阶段和第三阶段利用大型语言模型 (LLM) 进行直观的人机交互并指导传感器数据查询过程。与现有的多模态 LLM 不同，SensorChat 包含一个显式查询阶段，可从长时间传感器数据中精确提取事实信息。我们实现了 SensorChat，并展示了其在云服务器上进行实时交互的能力，同时还能够在量化后完全在边缘平台上运行。全面的 QA 评估表明，SensorChat 在定量问题上的回答准确率比最先进的系统高出 26%。此外，一项有八名志愿者参与的用户研究强调了 SensorChat 在处理定性和开放式问题方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.02883</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于不一致性测量的（神经符号）机器学习</title>
      <link>https://arxiv.org/abs/2502.02963</link>
      <description><![CDATA[arXiv:2502.02963v1 公告类型：新
摘要：我们提出了基于机器学习的方法来确定命题逻辑知识库的不一致度（数值）。具体来说，我们提出了基于回归和神经的模型，这些模型可以学习预测不一致度量 $\incmi$ 和 $\incat$ 将分配给命题逻辑知识库的值。我们的主要动机是，传统上计算这些值在复杂性方面可能很困难。作为一个重要的补充，我们使用底层不一致度量的特定假设（即属性）来推断符号规则，并将其与基于学习的模型以约束的形式结合起来。我们进行了各种实验，并表明 a) 在许多情况下预测度值是可行的，并且 b) 包括从合理性假设推导出的符号约束可以提高预测质量。]]></description>
      <guid>https://arxiv.org/abs/2502.02963</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedMobileAgent：使用来自不同用户的分散自源数据训练移动代理</title>
      <link>https://arxiv.org/abs/2502.02982</link>
      <description><![CDATA[arXiv:2502.02982v1 公告类型：新
摘要：移动代理的进步为移动设备上的自动化任务开辟了新的机会。训练这些代理需要大量高质量的数据，而这需要大量的人力。鉴于全球手机用户数量庞大，如果能够自动收集这些数据，那么由此产生的数据量和随后训练的移动代理将达到前所未有的水平。然而，出现了两个主要挑战：（1）在不涉及人工的情况下提取高级和低级用户指令；（2）在保护隐私的同时利用来自不同用户的分布式数据。
为了应对这些挑战，我们提出了 FedMobileAgent，这是一个协作框架，它使用来自不同用户的自源数据来训练移动代理。具体来说，它包括两种技术。首先，我们提出了自动注释，它能够以最低的成本在用户日常使用手机期间自动收集高质量的数据集。其次，我们引入了自适应聚合，通过结合情节和步骤级分布来改进移动代理在非 IID 用户数据上的联合训练。在分布式设置中，FedMobileAgent 以不到 0.02% 的成本实现了与集中式人工注释模型相当的性能，凸显了其在实际应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.02982</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>智能蛋糕以及谁来烘焙它：人工智能类比及其对参与的影响</title>
      <link>https://arxiv.org/abs/2502.03038</link>
      <description><![CDATA[arXiv:2502.03038v1 公告类型：新
摘要：图灵奖获得者 Yann LeCun 曾将机器智能比作蛋糕，无监督学习是基础，监督学习是锦上添花，强化学习则是锦上添花。我们将这个“智能蛋糕”类比从简单的结构隐喻扩展到人工智能系统的整个生命周期，包括原料采购（数据）、食谱构思（说明）、烘焙过程（培训）以及蛋糕的品尝和销售（评估和分发）。利用我们的重新概念化，我们描述了每个步骤所涉及的社会影响以及它们如何受到机器学习中统计假设的限制。尽管这些技术基础和社会影响紧密交织在一起，但它们往往被孤立地研究，从而造成了限制有意义参与的障碍。我们的重新概念化为弥合这一差距铺平了道路，通过映射技术基础与社会成果之间的相互作用，突出跨学科对话的机会。最后，我们在隐喻性的人工智能蛋糕生命周期的每个阶段都提出了可行的建议，增强了未来的人工智能从业者、用户和研究人员的意识和参与更广泛的人工智能讨论的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.03038</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CORTEX：一种成本敏感的规则和树提取方法</title>
      <link>https://arxiv.org/abs/2502.03200</link>
      <description><![CDATA[arXiv:2502.03200v1 公告类型：新
摘要：基于树和基于规则的机器学习模型在可解释人工智能 (XAI) 中发挥着关键作用，因为它们具有以树或规则集的形式提供易于理解和解释的解释的独特能力，这使得它们对于需要信任模型决策的应用程序至关重要。这些透明模型通常用于代理建模，这是一种事后 XAI 方法，用于解释黑盒模型的逻辑，使用户能够理解和信任复杂的预测系统，同时保持竞争性能。本研究提出了成本敏感规则和树提取 (CORTEX) 方法，这是一种基于多类成本敏感决策树 (CSDT) 方法的新型基于规则的 XAI 算法。通过引入 n 维类相关成本矩阵的概念，将 CSDT 的原始版本扩展到具有两个以上类别的分类问题。将 CORTEX 作为规则提取器 XAI 方法的性能与其他事后树和规则提取方法在具有不同数量类别的多个数据集上进行了比较。采用了几种定量评估指标来评估生成的规则集的可解释性。我们的研究结果表明，CORTEX 与其他基于树的方法相比具有竞争力，并且可以在不同数据集上优于其他基于规则的方法。提取的规则集表明，使用 CORTEX 方法优于其他方法，因为它可以在具有不同数量类别的数据集中生成较小的规则集，平均规则较短。总体而言，结果强调了 CORTEX 作为强大的 XAI 工具的潜力，适用于需要生成清晰、人类可理解的规则同时保持良好预测性能的场景。]]></description>
      <guid>https://arxiv.org/abs/2502.03200</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种可扩展的概率神经符号验证方法</title>
      <link>https://arxiv.org/abs/2502.03274</link>
      <description><![CDATA[arXiv:2502.03274v1 公告类型：新 
摘要：神经符号人工智能 (NeSy AI) 已成为将神经学习与符号推理相结合的一个有前途的方向。在这种系统的概率变体中，神经网络首先从子符号输入中提取一组符号，然后符号组件使用这些符号以概率方式推理以回答查询。在这项工作中，我们解决了正式验证此类 NeSy 概率推理系统的鲁棒性的问题，从而为它们在关键领域的安全部署铺平了道路。我们准确分析了解决这个问题的复杂性，并表明它是 $\mathrm{NP}^{\# \mathrm{P}}$ 难的。为了解决这个问题，我们提出了第一种基于松弛的概率 NeSy 系统近似验证方法。我们通过实验证明，所提出的方法比基于求解器的解决方案具有指数级的优势，并将我们的技术应用于现实世界的自动驾驶数据集，在该数据集中验证了大输入维度和网络规模下的安全属性。]]></description>
      <guid>https://arxiv.org/abs/2502.03274</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SymAgent：一种用于知识图谱复杂推理的神经符号自学习代理框架</title>
      <link>https://arxiv.org/abs/2502.03283</link>
      <description><![CDATA[arXiv:2502.03283v1 公告类型：新 
摘要：最近的进展表明，大型语言模型 (LLM) 在解决复杂推理问题时容易产生幻觉，从而导致错误的结果。为了解决这个问题，研究人员结合知识图谱 (KG) 来提高 LLM 的推理能力。然而，现有的方法面临两个限制：1) 它们通常假设所有问题的答案都包含在 KG 中，而忽略了 KG 的不完整性问题；2) 它们将 KG 视为静态存储库，而忽略了 KG 固有的隐式逻辑推理结构。在本文中，我们介绍了 SymAgent，这是一种创新的神经符号代理框架，可实现 KG 和 LLM 之间的协作增强。我们将 KG 概念化为动态环境，并将复杂的推理任务转化为多步骤的交互过程，使 KG 能够深入参与推理过程。 SymAgent 由两个模块组成：Agent-Planner 和 Agent-Executor。Agent-Planner 利用 LLM 的归纳推理能力从 KG 中提取符号规则，指导高效的问题分解。Agent-Executor 自主调用预定义的操作工具来整合来自 KG 和外部文档的信息，解决 KG 不完整的问题。此外，我们设计了一个自学习框架，包括在线探索和离线迭代策略更新阶段，使代理能够自动合成推理轨迹并提高性能。实验结果表明，与各种强基线相比，具有弱 LLM 主干（即 7B 系列）的 SymAgent 具有更好或相当的性能。进一步的分析表明，我们的代理可以识别缺失的三元组，从而促进自动 KG 更新。]]></description>
      <guid>https://arxiv.org/abs/2502.03283</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PalimpChat：声明性和交互式人工智能分析</title>
      <link>https://arxiv.org/abs/2502.03368</link>
      <description><![CDATA[arXiv:2502.03368v1 公告类型：新
摘要：得益于生成架构和大型语言模型的进步，数据科学家现在可以编写机器学习操作的管道来处理大量非结构化数据。最近的进展见证了声明式 AI 框架（例如 Palimpzest、Lotus 和 DocETL）的兴起，这些框架用于构建优化且日益复杂的管道，但这些系统通常只有专家程序员才能访问。在此演示中，我们展示了 PalimpChat，这是一个基于聊天的 Palimpzest 界面，它通过让用户仅通过自然语言创建和运行复杂的 AI 管道来弥补这一差距。通过集成基于 ReAct 的推理代理 Archytas 以及 Palimpzest 的关系和基于 LLM 的运算符套件，PalimpChat 提供了一个实际的例子，说明聊天界面如何让非专家真正访问声明式 AI 框架。
我们的演示系统可在线公开。在 SIGMOD&#39;25 上，参与者可以探索三个真实场景——科学发现、法律发现和房地产搜索——或者将 PalimpChat 应用于他们自己的数据集。在本文中，我们重点介绍 Palimpzest 优化器支持的 PalimpChat 如何简化复杂的 AI 工作流程，例如提取和分析生物医学数据。]]></description>
      <guid>https://arxiv.org/abs/2502.03368</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过代理价值传播从积极的人类参与中学习</title>
      <link>https://arxiv.org/abs/2502.03369</link>
      <description><![CDATA[arXiv:2502.03369v1 公告类型：新
摘要：从积极的人类参与中学习使人类主体能够在训练期间主动干预并向 AI 代理展示。来自人类的互动和纠正反馈为学习过程带来了安全性和 AI 一致性。在这项工作中，我们提出了一种新的无奖励主动人类参与方法，称为代理值传播，用于策略优化。我们的关键见解是可以设计一个代理值函数来表达人类的意图，其中人类演示中的状态-动作对被标记为高值，而那些被干预的代理的动作则获得低值。通过 TD 学习框架，已演示的状态-动作对的标记值进一步传播到代理探索生成的其他未标记数据。因此，代理值函数诱导出一种忠实模拟人类行为的策略。人在环实验证明了我们方法的通用性和效率。只需对现有的强化学习算法进行最少的修改，我们的方法就可以学习使用各种人工控制设备解决连续和离散控制任务，包括《侠盗猎车手 V》中的驾驶挑战性任务。演示视频和代码可在以下位置获得：https://metadriverse.github.io/pvp]]></description>
      <guid>https://arxiv.org/abs/2502.03369</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BFS-Prover：基于 LLM 的自动定理证明的可扩展最佳优先树搜索</title>
      <link>https://arxiv.org/abs/2502.03438</link>
      <description><![CDATA[arXiv:2502.03438v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展激发了人们对使用 Lean4 自动定理证明的兴趣，其中有效的树搜索方法对于导航证明搜索空间至关重要。虽然现有方法主要依赖于值函数和蒙特卡洛树搜索 (MCTS)，但最佳优先搜索 (BFS) 等更简单方法的潜力仍未得到充分开发。本文研究了 BFS 是否能在大规模定理证明任务中实现具有竞争力的性能。我们提出了 \texttt{BFS-Prover}，这是一个可扩展的专家迭代框架，具有三个关键创新。首先，我们在每一轮专家迭代中实施战略数据过滤，排除可通过波束搜索节点扩展解决的问题，以专注于更难的情况。其次，我们通过对自动标注有编译器错误反馈的状态-策略对应用直接偏好优化 (DPO) 来提高 BFS 的采样效率，从而改进 LLM 的策略以优先考虑生产性扩展。第三，我们在 BFS 中采用长度规范化来鼓励探索更深层次的证明路径。\texttt{BFS-Prover} 在 MiniF2F 测试集上获得了 $71.31$ 的分数，因此挑战了复杂树搜索方法的必要性，表明 BFS 在适当扩展时可以实现具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.03438</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>