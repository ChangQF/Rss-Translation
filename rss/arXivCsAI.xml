<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.AI 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.AI</link>
    <description>cs.AI 对 arXiv.org 电子印刷档案进行更新。</description>
    <lastBuildDate>Tue, 19 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>体贴是实现代理人工智能多元化协调的途径</title>
      <link>https://arxiv.org/abs/2411.10613</link>
      <description><![CDATA[arXiv:2411.10613v1 公告类型：新
摘要：多元一致性涉及确保人工智能系统的目标和行为与人类价值观和观点的多样性相协调。在本文中，我们研究了代理人工智能背景下的多元一致性概念，特别是在代理试图以一种考虑到环境中其他人的价值观和观点的方式学习策略的背景下。为此，我们展示了如何考虑其他（人类）代理的未来福祉和代理可以促进一种多元一致性。]]></description>
      <guid>https://arxiv.org/abs/2411.10613</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移，多元联盟</title>
      <link>https://arxiv.org/abs/2411.10654</link>
      <description><![CDATA[arXiv:2411.10654v1 公告类型：新
摘要：如果人工智能系统会随着时间的推移做出决策，我们应该如何评估它与一组利益相关者（他们可能有相互冲突的价值观和偏好）的一致性？在这篇立场文件中，我们主张考虑时间方面，包括利益相关者不断变化的满意度水平及其可能在时间上延长的偏好。我们建议如何将最近评估公平性的方法应用于一种新的多元化一致性形式：时间多元化，其中人工智能系统在不同时间反映不同利益相关者的价值观。]]></description>
      <guid>https://arxiv.org/abs/2411.10654</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强化多智能体竞争机制，以应对“玩久了的傻瓜”游戏</title>
      <link>https://arxiv.org/abs/2411.11057</link>
      <description><![CDATA[arXiv:2411.11057v1 公告类型：新
摘要：本文研究了经典深度强化学习 (DRL) 算法 DQN、DDQN 和 Dueling DQN 在战略游戏 So Long Sucker (SLS) 中的使用情况，SLS 是一款以联盟建设和战略背叛为定义的外交驱动游戏。SLS 因其合作和对抗动态的融合而带来独特的挑战，使其成为研究多智能体学习和博弈论的理想平台。该研究的主要目标是使用经典 DRL 方法向自主智能体传授游戏规则和策略。为了支持这项工作，作者开发了一种新颖的、公开可用的 SLS 实现，具有图形用户界面 (GUI) 和 DRL 算法的基准测试工具。实验结果表明，虽然 DQN、DDQN 和 Dueling DQN 智能体按照现代 DRL 标准被认为是基本的，但它们实现了最大可能游戏奖励的大约 50%。这表明对游戏机制有基本的了解，代理更倾向于合法动作而不是非法动作。然而，一个重大的限制是，与在几轮内掌握游戏的人类玩家相比，代理需要进行大量训练（大约 2000 场游戏）才能达到最佳表现。即使经过长时间的训练，代理偶尔也会做出非法动作，这凸显了这些经典 DRL 方法在半复杂、社交驱动的游戏中既有潜力又有局限性。这些发现为在 SLS 和类似的基于谈判的环境中训练代理建立了基础基准，同时强调了需要采用高级或混合 DRL 方法来提高学习效率和适应性。未来的研究可以结合博弈论策略来增强动态多代理环境中的代理决策能力。]]></description>
      <guid>https://arxiv.org/abs/2411.11057</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教学大纲：强化学习代理的便携式课程</title>
      <link>https://arxiv.org/abs/2411.11318</link>
      <description><![CDATA[arXiv:2411.11318v1 公告类型：新
摘要：课程学习一直是强化学习许多引人注目的成功中的一个安静而关键的组成部分。尽管如此，主要的强化学习库都没有直接支持课程学习或包括课程学习实现。这些方法可以提高 RL 代理的能力和稳健性，但通常需要对代理训练代码进行重大而复杂的更改。我们引入了 Syllabus，一个用于使用课程学习训练 RL 代理的库，作为解决此问题的解决方案。Syllabus 为课程学习算法、流行课程学习方法的实现以及可轻松将它们与几乎任何 RL 库中编写的分布式训练代码集成的基础设施提供了通用 API。Syllabus 为课程学习的每个核心组件提供了最小的 API，大大简化了设计新算法和将现有算法应用于新环境的过程。我们证明相同的 Syllabus 代码可用于训练在多个领域中用多个不同的 RL 库编写的代理。在此过程中，我们展示了 NetHack 和 Neural MMO 中课程学习的第一个示例，这两个分别是单智能体和多智能体 RL 的主要挑战，与最先进的基线相比取得了强劲的成果。]]></description>
      <guid>https://arxiv.org/abs/2411.11318</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健马尔可夫决策过程：人工智能与形式化方法的交汇之地</title>
      <link>https://arxiv.org/abs/2411.11451</link>
      <description><![CDATA[arXiv:2411.11451v1 公告类型：新
摘要：马尔可夫决策过程 (MDP) 是顺序决策问题的标准模型，广泛应用于许多科学领域，包括形式化方法和人工智能 (AI)。然而，MDP 确实带有一个限制性假设，即转移概率需要精确知道。鲁棒 MDP (RMDP) 通过将转移概率定义为属于某些不确定集来克服这一假设。我们对 RMDP 进行了温和的调查，提供了涵盖其基础知识的教程。特别是，我们讨论了 RMDP 语义以及如何通过扩展标准 MDP 方法（例如值迭代和策略迭代）来解决它们。我们还讨论了 RMDP 与其他模型的关系以及它们如何在多种情况下使用，包括强化学习和抽象技术。最后，我们提出了 RMDP 未来工作的一些挑战。]]></description>
      <guid>https://arxiv.org/abs/2411.11451</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>外星人重组：探索视觉艺术中超越人类认知可用性的概念融合</title>
      <link>https://arxiv.org/abs/2411.11494</link>
      <description><![CDATA[arXiv:2411.11494v1 公告类型：新
摘要：虽然人工智能模型在游戏策略等受限领域表现出非凡的能力，但它们在艺术等开放领域发挥真正创造力的潜力仍存在争议。我们通过研究人工智能如何超越人类在视觉艺术创作中的认知限制来探索这个问题。我们的研究假设视觉艺术包含一个广阔的未开发的概念组合空间，这些组合不是受固有的不兼容性限制，而是受艺术家的文化、时间、地理和社会背景所施加的认知限制的限制。
为了检验这一假设，我们提出了外来重组方法，这是一种利用微调的大型语言模型来识别和生成超出人类认知可用性的概念组合的新方法。该系统建模并有意抵消人类可用性偏见，即依赖可立即访问的示例的倾向，以发现新颖的艺术组合。
该系统不仅可以在我们的数据集中生成以前从未尝试过的组合，还可以识别和生成该领域所有艺术家在认知上不可用的组合。此外，我们将这些组合转化为视觉表现，从而探索对新颖性的主观感知。我们的研究结果表明，认知不可用性是优化艺术新颖性的一个有前途的指标，其效果优于没有额外评估标准的情况下的单纯温度缩放。这种方法使用生成模型来连接以前不相关的想法，为将人工智能驱动的创造力构建为组合问题的潜力提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.11494</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>搜索、验证和反馈：通过验证器工程迈向下一代基础模型后训练范式</title>
      <link>https://arxiv.org/abs/2411.11504</link>
      <description><![CDATA[arXiv:2411.11504v1 公告类型：新
摘要：机器学习的发展越来越重视开发强大的模型和更具可扩展性的监督信号。然而，基础模型的出现对提供进一步增强其能力所需的有效监督信号提出了重大挑战。因此，迫切需要探索新的监督信号和技术方法。在本文中，我们提出了验证器工程，这是一种专为基础模型时代设计的新型后训练范式。验证器工程的核心涉及利用一套自动验证器来执行验证任务并向基础模型提供有意义的反馈。我们系统地将验证器工程过程分为三个基本阶段：搜索、验证和反馈，并全面回顾每个阶段的最新研究进展。我们相信验证器工程是实现通用人工智能的基本途径。]]></description>
      <guid>https://arxiv.org/abs/2411.11504</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图的预训练模型，用于教育文档的自适应排序</title>
      <link>https://arxiv.org/abs/2411.11520</link>
      <description><![CDATA[arXiv:2411.11520v1 公告类型：新 
摘要：大规模开放在线课程 (MOOC) 为使教育更加普及做出了巨大贡献。然而，许多 MOOC 都保持着僵化的、一刀切的结构，无法满足个人学习者的不同需求和背景。学习路径个性化旨在通过定制教育内容序列来优化个人学生的学习成果，从而解决这一限制。然而，现有的方法通常需要大量的学生互动数据或大量的专家注释，从而限制了它们的广泛应用。在本研究中，我们引入了一种新颖的数据高效学习路径个性化框架，该框架无需专家注释即可运行。我们的方法采用了一个灵活的推荐系统，该系统在原始课程材料数据集上通过强化学习进行了预训练。通过对半合成数据的实验，我们表明，这个预训练阶段大大提高了一系列以新教育材料为特色的自适应学习场景的数据效率。这为自适应学习基础模型的设计开辟了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2411.11520</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能科学发现</title>
      <link>https://arxiv.org/abs/2411.11672</link>
      <description><![CDATA[arXiv:2411.11672v1 公告类型：新
摘要：本论文扎根于过去十年深度学习的爆炸式增长，从 AlphaGo 到 ChatGPT，以实证研究实现人工智能科学家愿景所需的基本概念：一种能够自主生成原创研究并为扩展人类知识做出贡献的机器。调查从 {\sc Olivaw} 开始，这是一个类似 AlphaGo Zero 的代理，它从头开始发现奥赛罗知识，但无法传达。这一认识导致了解释性学习 (EL) 框架的发展，这是科学家在试图向同行解释新现象时面临的问题的形式化。有效的 EL 处方使我们能够破解 Zendo，这是一款模拟科学努力的棋盘游戏。这一成功源于一个基本见解：人工智能科学家必须发展自己对用于解释其发现的语言的解释。这种观点让我们将现代多模态模型视为解释器，并设计出一种构建可解释且经济高效的 CLIP 类模型的新方法：通过使用少量多模态数据且无需进一步训练来耦合两个单模态模型。最后，我们讨论了 ChatGPT 及其同类模型在成为人工智能科学家方面还缺少什么，并介绍了 Odeen，这是一个解释解释的基准，它认为 LLM 只能是随机的，而完全由人类解决。]]></description>
      <guid>https://arxiv.org/abs/2411.11672</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PSPO*：一种有效的过程监督推理对齐策略优化</title>
      <link>https://arxiv.org/abs/2411.11681</link>
      <description><![CDATA[arXiv:2411.11681v1 公告类型：新
摘要：过程监督通过在思路链推理的每个步骤提供反馈来提高大型语言模型在推理任务中的表现。然而，由于缺乏有效的过程监督方法，即使是先进的大型语言模型也容易出现逻辑错误和冗余推理。我们认为过程监督的有效性在很大程度上取决于推理链的准确性和长度。此外，我们发现这些因素与推理过程的整体奖励分数呈现非线性关系。受这些见解的启发，我们提出了一种新颖的过程监督范式 PSPO*，它系统地概述了从奖励模型训练到策略优化的工作流程，并强调了非线性奖励在过程监督中的重要性。基于 PSPO*，我们开发了 PSPO-WRS，它在确定奖励分数时考虑了推理步骤的数量，并利用调整后的威布尔分布进行非线性奖励塑造。在六个数学推理数据集上的实验结果表明，PSPO-WRS 的表现始终优于当前主流模型。]]></description>
      <guid>https://arxiv.org/abs/2411.11681</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无需归一化的提升模型构建：利用因子图中对称性的矢量化方法</title>
      <link>https://arxiv.org/abs/2411.11730</link>
      <description><![CDATA[arXiv:2411.11730v1 公告类型：新
摘要：提升概率推理利用概率模型中的对称性，允许对逻辑变量的域大小进行可处理的概率推理。我们发现，当前最先进的以参数因子图形式构建提升表示的算法会忽略可交换但缩放不同的因子之间的对称性，从而导致表示不太紧凑。在本文中，我们提出了高级颜色传递 (ACP) 算法的泛化，这是构建参数因子图的最新技术。我们提出的算法允许因子的潜力任意缩放，并且比原始 ACP 算法更有效地检测出更多的对称性。通过比 ACP 严格检测更多的对称性，我们的算法在应用结果模型时显著减少了概率推理的在线查询时间，我们也在实验中证实了这一点。]]></description>
      <guid>https://arxiv.org/abs/2411.11730</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Goetterfunke：《机器之心》中的创造力。关于以文本转图像为重点的生成式人工智能的质变</title>
      <link>https://arxiv.org/abs/2411.10448</link>
      <description><![CDATA[arXiv:2411.10448v1 公告类型：交叉 
摘要：2022 年标志着技术的分水岭，可以说是人类历史上的分水岭，强大的生成式人工智能的发布能够令人信服地执行创造性任务。借助这些系统，任何人都可以创造出以前被认为是非凡艺术作品的东西。在人机协作中，计算机似乎已不仅仅是一种工具。许多第一次接触当前生成式人工智能的人将它们视为“创造力机器”，而对其他人来说，“机器创造力”一词仍然是一个矛盾的说法。本文是关于当前机器学习范式中计算机创造力（的可能性）。它概述了促成这种质变的技术背后的一些关键概念和创新，重点是文本到图像系统。讨论了人工智能的本质，以及这对艺术意味着什么。人工智能可能会成为艺术创作过程中负责任的合作者，并具有独立机器创作的元素。]]></description>
      <guid>https://arxiv.org/abs/2411.10448</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>爱在行动：将公共摄像机游戏化以促进现实世界中的社会关系</title>
      <link>https://arxiv.org/abs/2411.10449</link>
      <description><![CDATA[arXiv:2411.10449v1 公告类型：交叉
摘要：在本文中，我们创建了“爱在行动”（LIA），这是一款基于肢体语言的社交游戏，利用安装在公共场所的摄像机来增强现实世界中的社交关系。在游戏中，参与者扮演双重角色，即发出社交请求的请求者，以及通过执行指定的肢体语言来响应社交请求的表演者。为了调解参与者之间的交流，我们构建了一个人工智能增强视频分析系统，该系统结合了多个视觉分析模块，如人物检测、属性识别和动作识别，以评估表演者的肢体语言质量。一项为期两周的实地研究涉及 27 名参与者，根据自我报告的问卷调查显示，他们的社交友谊显着改善。此外，还调查了用户体验，以突出公共摄像机作为公共场所社交的新型通信媒介的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.10449</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据集细化以提高 EEG 解码模型的泛化能力</title>
      <link>https://arxiv.org/abs/2411.10450</link>
      <description><![CDATA[arXiv:2411.10450v1 公告类型：交叉 
摘要：脑电图 (EEG) 是一种在脑机接口中广泛使用的神经成像方法，因为它具有非侵入性和便利性，使其成为理解人类意图的有效工具。因此，最近的研究集中于利用深度学习方法从 EEG 信号中解码人类意图。然而，由于 EEG 信号在采集过程中极易受到噪声的影响，因此数据集中存在噪声数据的可能性很高。虽然先驱研究通常假设数据集是经过精心策划的，但 EEG 数据集并不总是满足这一假设。在本文中，我们通过设计一种数据集细化算法来解决这个问题，该算法可以根据评估训练过程中数据影响的指标来消除噪声数据。我们将提出的算法应用于两个运动想象 EEG 公共数据集和三个不同的模型来执行数据集细化。结果表明，与使用原始数据集相比，使用细化后的数据集重新训练模型始终可以获得更好的泛化性能。因此，我们证明，仅从训练数据集中去除噪声数据就可以有效提高深度学习模型在 EEG 领域的泛化性能。]]></description>
      <guid>https://arxiv.org/abs/2411.10450</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>约束满足问题（和 NP 中的其他问题）之间的几何保持约简</title>
      <link>https://arxiv.org/abs/2411.10453</link>
      <description><![CDATA[arXiv:2411.10453v1 公告类型：交叉 
摘要：受组合优化问题中的相变启发，我们在约束满足问题和其他 NP 搜索问题之间定义了两种保持几何形状的归约。我们为这些归约给出了几个例子和反例。]]></description>
      <guid>https://arxiv.org/abs/2411.10453</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>