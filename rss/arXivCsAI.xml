<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 06 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>PuzzleBench：法学硕士可以解决具有挑战性的一阶组合推理问题吗？</title>
      <link>https://arxiv.org/abs/2402.02611</link>
      <description><![CDATA[最近的工作探索了使用法学硕士进行推理任务，重点关注相对简单的问题，例如逻辑问题回答。在我们的工作中，我们希望解决更复杂的问题，显着扩展这些模型的功能。特别是，我们探索法学硕士是否可以解决具有挑战性的一阶组合推理问题，一个例子是流行的数独谜题。这些问题具有由自然语言的一般描述描述的底层一阶结构，并且可以实例化为不同大小的实例。此外，这些问题的计算量很大，需要多个推理步骤才能得出解决方案。我们向 PuzzleBench 提供了包含 31 个此类挑战性谜题的数据集。我们观察到，法学硕士即使在符号求解器的帮助下，在我们的基准测试中表现也相当差。作为回应，我们提出了一种新方法，即 Puzzle-LM，它将法学硕士与符号求解器和程序解释器相结合，使他们能够推理此类具有挑战性的问题。我们还展示了较小的已解决实例的反馈如何帮助提高这种推理能力。]]></description>
      <guid>https://arxiv.org/abs/2402.02611</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>通过验证器解决多步骤问题：模型引发的过程监督的实证分析</title>
      <link>https://arxiv.org/abs/2402.02658</link>
      <description><![CDATA[过程监督，使用训练有素的验证器来评估推理器生成的中间步骤，已经证明了多步骤问题解决的显着改进。在本文中，为了避免对验证者训练数据进行昂贵的人工注释工作，我们引入了模型诱导过程监督（MiPS），这是一种自动数据管理的新方法。 MiPS 通过推理模型对该解决方案的完成进行采样，并获得定义为正确完成的比例的准确度来注释中间步骤。推理器中的错误会导致 MiPS 低估中间步骤的准确性，因此，我们建议并根据经验表明，应优先考虑验证者的高预测分数的验证，而不是低预测分数的验证，这与之前的工作相反。我们的方法显着提高了 PaLM 2 在数学和编码任务上的性能（与输出监督训练的验证者相比，GSM8K 上的准确度 +0.67%，MATH 上的准确度 +4.16%，MBPP 上的准确度 +0.92%）。此外，我们的研究表明验证者在不同的推理模型中表现出很强的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2402.02658</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>了解LLM代理的规划：一项调查</title>
      <link>https://arxiv.org/abs/2402.02716</link>
      <description><![CDATA[随着大型语言模型（LLM）显示出显着的智能，利用 LLM 作为自主代理的规划模块的进展引起了更多关注。这项调查提供了基于法学硕士的代理人规划的第一个系统视图，涵盖了旨在提高规划能力的最新工作。我们提供了 LLM-Agent 规划现有工作的分类，可分为任务分解、计划选择、外部模块、反思和记忆。对每个方向进行了综合分析，并讨论了研究领域的进一步挑战。]]></description>
      <guid>https://arxiv.org/abs/2402.02716</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:45 GMT</pubDate>
    </item>
    <item>
      <title>DeLLMa：大型语言模型不确定性下的决策框架</title>
      <link>https://arxiv.org/abs/2402.02392</link>
      <description><![CDATA[大型语言模型 (LLM) 在整个社会中越来越多地使用，包括商业、工程和医学等领域。这些领域经常需要在不确定的情况下做出决策，这是一项关键但具有挑战性的任务。在本文中，我们表明，直接促使法学硕士解决这些类型的决策问题会产生较差的结果，特别是当问题复杂性增加时。为了克服这个限制，我们提出了DeLLMa（决策大型语言模型助手），一个旨在提高不确定环境下决策准确性的框架。 DeLLMa 涉及多步骤脚手架程序，借鉴决策理论和效用理论的原理，提供最佳且可人工审计的决策过程。我们在涉及真实农业和金融数据的决策环境中验证了我们的框架。我们的结果表明，DeLLMa 可以显着提高 LLM 决策性能，与竞争方法相比，准确率提高了 40%。]]></description>
      <guid>https://arxiv.org/abs/2402.02392</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:44 GMT</pubDate>
    </item>
    <item>
      <title>通过情境感知探索实现快速同伴适应</title>
      <link>https://arxiv.org/abs/2402.02468</link>
      <description><![CDATA[快速适应具有不同策略的未知同伴（合作伙伴或对手）是多智能体博弈中的关键挑战。为此，智能体有效地探测和识别同伴的策略至关重要，因为这是在适应中执行最佳响应的先决条件。然而，探索未知同行的策略是很困难的，特别是当博弈是部分可观察的并且具有很长的视野时。在本文中，我们提出了一种同伴识别奖励，它根据学习代理在历史背景下识别同伴行为模式的能力（例如对多个事件的观察）来奖励学习代理。这种奖励激励代理学习上下文感知策略，以进行有效探索和快速适应，即在不确定其策略时积极寻求和收集来自同伴的信息反馈，并在有信心时利用上下文执行最佳响应。我们在涉及竞争性（Kuhn Poker）、合作性（PO-Overcooked）或与同伴代理的混合（Predator-Prey-W）游戏的不同测试平台上评估我们的方法。我们证明，我们的方法会引发更积极的探索行为，比现有方法实现更快的适应和更好的结果。]]></description>
      <guid>https://arxiv.org/abs/2402.02468</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:44 GMT</pubDate>
    </item>
    <item>
      <title>将认知任务集成到大型模型的通用人工智能测试中</title>
      <link>https://arxiv.org/abs/2402.02547</link>
      <description><![CDATA[在大型模型的演化过程中，需要对中间模型进行性能评估，以评估其能力，对训练有素的模型进行性能评估，以确保实际应用前的安全性。然而，当前的模型评估主要依赖于特定任务和数据集，缺乏评估大型模型多维智能的统一框架。从这个角度来看，我们主张建立一个全面的通用人工智能（AGI）测试框架，旨在满足具有增强功能的大型语言模型和多模态大型模型的测试需求。 AGI 测试框架将认知科学和自然语言处理联系起来，涵盖了所有的智力方面，包括结晶智力（结晶智力），它是积累的知识和经验的反映；流体智力，以解决问题和适应性推理为特征；社交智能，意味着多方面的社交场景中的理解和适应；体现智能，表示与其物理环境互动的能力。为了评估大型模型的多维智能，AGI测试由一系列精心设计的认知测试组成，这些认知测试借鉴了人类智能测试，然后自然地封装到沉浸式虚拟社区中。我们建议 AGI 测试任务的复杂性应该随着大型模型的进步而相应增加。我们强调解释测试结果以避免假阴性和假阳性的必要性。我们相信，基于认知科学的AGI测试将有效指导大模型在特定智能维度上的针对性改进，加速大模型融入人类社会。]]></description>
      <guid>https://arxiv.org/abs/2402.02547</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:44 GMT</pubDate>
    </item>
    <item>
      <title>TSIS：用于基于片段的分子表示的 t-SMILES 的补充算法</title>
      <link>https://arxiv.org/abs/2402.02164</link>
      <description><![CDATA[基于字符串的分子表示，例如 SMILES，是线性表示分子信息的事实上的标准。然而，必须配对的符号和解析算法导致了较长的语法依赖性，使得即使是最先进的深度学习模型也难以准确理解语法和语义。尽管 DeepSMILES 和 SELFIES 解决了某些限制，但它们仍然难以应对高级语法，这使得某些字符串难以阅读。本研究向 t-SMILES 系列引入了一种补充算法 TSIS（TSID Simplified）。 TSIS 和另一种基于片段的线性解决方案 SAFE 之间的比较实验表明，SAFE 在管理语法中的长期依赖性方面提出了挑战。 TSIS 继续使用 t-SMILES 中定义的树作为其基础数据结构，这使其与 SAFE 模型不同。 TSIS模型的性能超过了SAFE模型，表明t-SMILES族的树结构提供了一定的优势。]]></description>
      <guid>https://arxiv.org/abs/2402.02164</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:43 GMT</pubDate>
    </item>
    <item>
      <title>增强游戏狼人中大型语言模型的推理</title>
      <link>https://arxiv.org/abs/2402.02330</link>
      <description><![CDATA[本文提出了一种创新框架，将大型语言模型 (LLM) 与外部 Thinker 模块集成，以增强基于 LLM 的代理的推理能力。与通过即时工程增强法学硕士不同，Thinker 直接利用数据库中的知识并采用各种优化技术。该框架形成了一个推理层次结构，其中 LLM 处理直观的 System-1 任务，例如自然语言处理，而 Thinker 则专注于需要复杂逻辑分析和特定领域知识的认知 System-2 任务。我们的框架是使用需要双系统推理的 9 人狼人游戏来呈现的。我们引入了 LLM 和 Thinker 之间的通信协议，并使用 18800 次人类会话和强化学习的数据来训练 Thinker。实验证明了该框架在演绎推理、语音生成和在线游戏评估方面的有效性。此外，我们对 6B LLM 进行了微调，使其在与 Thinker 集成时超越 GPT4。这篇论文还贡献了迄今为止最大的社交推理游戏数据集。]]></description>
      <guid>https://arxiv.org/abs/2402.02330</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:43 GMT</pubDate>
    </item>
    <item>
      <title>CEC 2024多方多目标优化竞赛基准</title>
      <link>https://arxiv.org/abs/2402.02033</link>
      <description><![CDATA[竞赛的重点是多方多目标优化问题 (MPMOP)，其中多个决策者的目标相互冲突，如无人机路径规划等应用中所示。尽管 MPMOP 很重要，但与传统的多目标优化相比，其研究仍然不足。该竞赛旨在通过鼓励研究人员探索量身定制的建模方法来弥补这一差距。该测试套件包括两部分：常见帕累托最优解的问题和未知解的双方多目标无人机路径规划（BPMO-UAVPP）问题。第一部分的优化算法使用多方倒代距离 (MPIGD) 进行评估，第二部分的优化算法使用多方超卷 (MPHV) 指标进行评估。所有问题的平均算法排名作为性能基准。]]></description>
      <guid>https://arxiv.org/abs/2402.02033</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:42 GMT</pubDate>
    </item>
    <item>
      <title>经济实惠的生成剂</title>
      <link>https://arxiv.org/abs/2402.02053</link>
      <description><![CDATA[大型语言模型（LLM）的出现极大地推进了可信交互代理的模拟。然而，维持长时间代理交互的巨大成本对部署可信的基于 LLM 的代理提出了挑战。因此，在本文中，我们开发了可负担的生成代理（AGA），这是一个框架，用于在代理环境和代理间级别上生成可信且低成本的交互。具体来说，对于主体与环境的交互，我们用学习的策略替代重复的 LLM 推论；而对于代理间交互，我们对代理之间的社会关系进行建模并压缩辅助对话信息。对多种环境的大量实验表明了我们提出的框架的有效性和效率。此外，我们深入研究了 LLM 智能体中紧急可信行为的机制，证明智能体只能在固定环境中生成有限行为，基于此，我们了解促进紧急交互行为的方法。我们的代码公开于：\url{https://github.com/AffordableGenerativeAgents/Affordable-Generative-Agents}。]]></description>
      <guid>https://arxiv.org/abs/2402.02053</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:42 GMT</pubDate>
    </item>
    <item>
      <title>应急计算：一种基于分层强化学习的自适应协同推理方法</title>
      <link>https://arxiv.org/abs/2402.02146</link>
      <description><![CDATA[为了实现有效的应急响应，环境信息的及时获取、指挥数据的无缝传输和及时决策至关重要。这就需要建立一个有弹性的应急通信专用网络，即使在缺乏基础设施的情况下也能够提供通信和传感服务。在本文中，我们提出了一种具有传感、通信、计算、缓存和智能功能的应急网络（E-SC3I）。该框架融合了应急计算、缓存、集成通信和传感以及情报赋能等机制。 E-SC3I确保快速接入庞大的用户群，在不稳定的链路上可靠地传输数据，并在变化的环境中实现动态的网络部署。然而，这些优势是以大量计算开销为代价的。因此，我们特别关注紧急计算，并提出了一种基于分层强化学习的自适应协作推理方法（ACIM）。实验结果证明我们的方法能够在计算和通信资源有限的情况下实现人工智能模型的快速推理。]]></description>
      <guid>https://arxiv.org/abs/2402.02146</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:42 GMT</pubDate>
    </item>
    <item>
      <title>COA-GPT：用于加速军事行动中行动方案开发的生成式预训练 Transformer</title>
      <link>https://arxiv.org/abs/2402.01786</link>
      <description><![CDATA[军事行动中行动方针（COA）的制定传统上是一个耗时且复杂的过程。为了解决这一挑战，本研究引入了 COA-GPT，这是一种采用大型语言模型 (LLM) 快速高效生成有效 COA 的新颖算法。 COA-GPT 通过情境学习将军事学说和领域专业知识融入法学硕士，允许指挥官以文本和图像格式输入任务信息，并接收战略一致的 COA 进行审查和批准。独特的是，COA-GPT 不仅加速 COA 开发，在几秒钟内生成初始 COA，而且还有助于根据指挥官反馈进行实时改进。这项工作在军事版《星际争霸 II》游戏的军事相关场景中评估 COA-GPT，将其性能与最先进的强化学习算法进行比较。我们的结果表明，COA-GPT 在更迅速地生成战略上合理的 COA 方面具有优势，并具有增强适应性和与指挥官意图保持一致的额外优势。 COA-GPT 在任务期间快速调整和更新 COA 的能力为军事规划带来了变革潜力，特别是在解决规划差异和利用紧急机会窗口方面。]]></description>
      <guid>https://arxiv.org/abs/2402.01786</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:41 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士无法规划，但可以帮助在法学硕士模数框架中进行规划</title>
      <link>https://arxiv.org/abs/2402.01817</link>
      <description><![CDATA[人们对大型语言模型 (LLM) 在规划和推理任务中的作用存在相当大的困惑。一方面是过于乐观的说法，即法学硕士确实可以通过正确的提示或自我验证策略来完成这些任务。另一方面，也许有些过于悲观的说法，即法学硕士在计划/推理任务中的所有优势都只是将问题规范从一种句法格式转换为另一种句法格式，并将问题传递给外部符号求解器。在本立场文件中，我们认为这两种极端观点都是错误的。我们认为，自回归法学硕士本身无法进行规划或自我验证（这毕竟是推理的一种形式），并阐明了文献中误解的原因。我们还将认为，法学硕士应该被视为通用的近似知识源，除了简单的前端/后端格式翻译器之外，它们在规划/推理任务中可以发挥更有意义的作用。我们提出了 {\bf LLM-Modulo Frameworks} 的愿景，它将 LLM 的优势与基于外部模型的验证器结合在更紧密的双向交互机制中。我们将展示如何在法学硕士的帮助下获得驱动外部验证器本身的模型。我们还将认为，这种 LLM-Modulo 框架不是简单地流水线化 LLM 和符号组件，而是提供了一种更好的神经符号方法，可以在 LLM 和符号组件之间提供更紧密的集成，并允许将基于模型的规划/推理机制的范围扩展到更灵活的知识、问题和偏好规范。]]></description>
      <guid>https://arxiv.org/abs/2402.01817</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:41 GMT</pubDate>
    </item>
    <item>
      <title>基础模型在神经符号学习和推理中的作用</title>
      <link>https://arxiv.org/abs/2402.01889</link>
      <description><![CDATA[神经符号人工智能（NeSy）有望确保人工智能系统的安全部署，因为可解释的符号技术提供了正式的行为保证。挑战在于如何有效地集成神经计算和符号计算，以便能够从原始数据中进行学习和推理。按顺序训练神经和符号组件的现有管道需要大量标签，而由于符号接地问题中的组合爆炸，端到端方法在可扩展性方面受到限制。在本文中，我们利用基础模型中的隐式知识来提高 NeSy 任务的性能，同时减少数据标记和手动工程的数量。我们引入了一种名为 NeSyGPT 的新架构，它对视觉语言基础模型进行微调，以从原始数据中提取符号特征，然后再学习高度表达的答案集程序来解决下游任务。我们的综合评估表明，NeSyGPT 比各种基线都具有更高的准确性，并且可以扩展到复杂的 NeSy 任务。最后，我们强调有效使用大型语言模型来生成神经组件和符号组件之间的编程接口，从而显着减少所需的手动工程量。]]></description>
      <guid>https://arxiv.org/abs/2402.01889</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:41 GMT</pubDate>
    </item>
    <item>
      <title>通过合并外延知识和内涵知识嵌入本体</title>
      <link>https://arxiv.org/abs/2402.01677</link>
      <description><![CDATA[本体包含丰富的领域知识，可分为外延知识和内涵知识两类。外延知识提供属于本体中特定概念的具体实例的信息，而内涵知识则详细描述概念之间的固有属性、特征和语义关联。然而，现有的本体嵌入方法未能同时充分考虑外延知识和内涵知识。在本文中，我们提出了一种新颖的本体嵌入方法，称为 EIKE（外延和内涵知识嵌入），通过在两个空间（称为外延空间和内涵空间）中表示本体。 EIKE提出了一个统一的框架，用于将实例、概念及其关系嵌入到本体中，应用基于几何的方法来建模外延知识，并应用预训练的语言模型来建模内涵知识，它可以捕获结构信息和文本信息。实验结果表明，EIKE 在三元组分类和链接预测的三个数据集中显着优于最先进的方法，表明 EIKE 提供了更全面和更具代表性的领域视角。]]></description>
      <guid>https://arxiv.org/abs/2402.01677</guid>
      <pubDate>Tue, 06 Feb 2024 21:11:40 GMT</pubDate>
    </item>
    </channel>
</rss>