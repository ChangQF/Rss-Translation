<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.AI 更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>cs.AI 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 01 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>针对土耳其语言理解任务微调基于 Transformer 的编码器</title>
      <link>https://arxiv.org/abs/2401.17396</link>
      <description><![CDATA[过去几年，基于深度学习和最近基于 Transformer 的语言模型一直主导着自然语言处理的研究。由于其准确和快速的微调特性，它们的性能优于传统的基于机器学习的方法，并在许多具有挑战性的自然语言理解（NLU）问题上取得了最先进的结果。最近的研究表明，基于 Transformer 的模型（例如 BERT（Transformers 的双向编码器表示））在许多任务上取得了令人印象深刻的成就。此外，由于它们的迁移学习能力，这些架构允许我们迁移预构建的模型并将其微调到特定的 NLU 任务，例如回答问题。在这项研究中，我们提供了一个基于 Transformer 的模型和土耳其语言的基线基准。我们成功地对土耳其 BERT 模型（即 BERTurk）进行了微调，该模型使用基础设置进行训练，适用于许多下游任务，并使用土耳其基准数据集进行评估。我们表明，我们的研究在土耳其语命名实体识别、情感分析、问答和文本分类方面明显优于其他现有的基线方法。我们公开发布了这四个经过微调的模型和资源，以确保可重复性，并支持其他土耳其研究人员和应用程序。]]></description>
      <guid>https://arxiv.org/abs/2401.17396</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:40 GMT</pubDate>
    </item>
    <item>
      <title>持续学习的步长优化</title>
      <link>https://arxiv.org/abs/2401.17401</link>
      <description><![CDATA[在持续学习中，学习者必须在一生中不断从数据中学习。一个关键问题是决定保留哪些知识以及放弃哪些知识。在神经网络中，这可以通过使用步长向量来缩放梯度样本改变网络权重的程度来实现。 RMSProp 和 Adam 等常见算法使用启发法（特别是归一化）来适应此步长向量。在本文中，我们表明这些启发式方法忽略了它们的适应对整体目标函数的影响，例如通过将步长向量移离更好的步长向量。另一方面，随机元梯度下降算法，如 IDBD (Sutton, 1992)，显式优化相对于整体目标函数的步长向量。在简单问题上，我们证明 IDBD 能够持续改进步长向量，而 RMSProp 和 Adam 则不能。我们解释了两种方法之间的差异及其各自的局限性。我们的结论是，结合这两种方法可能是提高神经网络在持续学习中的性能的一个有前途的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2401.17401</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:40 GMT</pubDate>
    </item>
    <item>
      <title>阿拉伯语推文行为：用于对 Twitter 上的阿拉伯语语音行为进行分类的加权集成预训练 Transformer 模型</title>
      <link>https://arxiv.org/abs/2401.17373</link>
      <description><![CDATA[言语行为是说话者在对话中执行话语时的行为，例如询问、推荐、问候或感谢某人，表达想法或提出建议。理解言语行为有助于解释说话者或作者话语背后的意图和行为。本文提出了一种基于 Transformer 深度学习神经网络的 Twitter 方言阿拉伯语言语行为分类方法。 Twitter 和社交媒体越来越融入日常生活。因此，它们已发展成为代表用户观点和态度的重要信息来源。我们提出了一种基于 BERT 的加权集成学习方法，以整合各种 BERT 模型在阿拉伯语方言语音行为分类中的优势。我们将所提出的模型与阿拉伯语 BERT 模型和基于序列的模型的几种变体进行了比较。我们通过基于六个言语行为类别注释现有大型阿拉伯语情感分析数据集 (ASAD) 的子集，开发了阿拉伯语方言推文行为数据集。我们还在之前开发的阿拉伯推文法案数据集 (ArSAS) 上评估了模型。为了克服言语行为问题中常见的类别不平衡问题，实现了基于变压器的数据增强模型来生成相等比例的言语行为类别。结果表明，最好的 BERT 模型是 araBERTv2-Twitter 模型，其宏观平均 F1 分数、准确度分别为 0.73 和 0.84。使用基于 BERT 的集成方法提高了性能，在我们的数据集上平均 F1 分数和准确度分别为 0.74 和 0.85。]]></description>
      <guid>https://arxiv.org/abs/2401.17373</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:39 GMT</pubDate>
    </item>
    <item>
      <title>Infini-gram：将无界 n-gram 语言模型扩展到万亿代币</title>
      <link>https://arxiv.org/abs/2401.17377</link>
      <description><![CDATA[n-gram 语言模型在这个神经大语言模型 (LLM) 时代仍然相关吗？我们的答案是肯定的，我们在文本分析和改进神经法学硕士方面展示了它们的价值。然而，这需要在两个方面对 n-gram 模型进行现代化改造。首先，我们以与神经 LLM 相同的数据规模（1.4 万亿个令牌）训练它们。这是有史以来最大的 n-gram 模型。其次，现有的n-gram模型使用较小的n，这阻碍了它们的性能；相反，我们通过引入带有退避功能的新 $\infty$-gram LM 来允许 n 任意大。我们开发了一个名为 infini-gram 的引擎（由后缀数组提供支持），而不是预先计算 n-gram 计数表（这会非常昂贵），它可以计算 $\infty$-gram （以及 n-gram）具有任意 n) 概率和毫秒级延迟。 $\infty$-gram 框架和 infini-gram 引擎使我们能够对人类编写的和机器生成的文本进行许多新颖且有趣的分析：我们发现 $\infty$-gram LM 对于下一个-令牌预测（47%），并且可以补充神经法学硕士，大大减少其语言建模的复杂性。在分析机器生成的文本时，我们还观察到机器-$\infty$-gram 在后缀长度方面的一致性水平存在不规则性，这表明神经 LLM 预训练和 Transformer 的位置嵌入存在缺陷。我们开源无限语法引擎，希望能够就如何最好地利用从大型文本语料库中检索到的逐字信息进行更多研究。]]></description>
      <guid>https://arxiv.org/abs/2401.17377</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:39 GMT</pubDate>
    </item>
    <item>
      <title>通过对比情境学习定制语言模型响应</title>
      <link>https://arxiv.org/abs/2401.17390</link>
      <description><![CDATA[大型语言模型 (LLM) 对于机器学习应用程序变得越来越重要。然而，让法学硕士与我们的意图保持一致可能具有挑战性，特别是当我们想要生成比其他内容更好的内容时，或者当我们希望法学硕士以某种难以描述的风格或语气做出回应时。为了应对这一挑战，我们提出了一种使用对比示例来更好地描述我们的意图的方法。这包括提供说明真实意图的正面例子，以及显示我们希望法学硕士避免哪些特征的负面例子。负面例子可以从人类编写的标记数据中检索，也可以由法学硕士本身生成。在生成答案之前，我们要求模型分析示例，以教会自己应该避免什么。此推理步骤为模型提供了用户需求的适当表达，并指导其生成更好的答案。我们在合成数据集和真实数据集（包括 StackExchange 和 Reddit）上测试了我们的方法，发现与标准的几次提示相比，它显着提高了性能]]></description>
      <guid>https://arxiv.org/abs/2401.17390</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:39 GMT</pubDate>
    </item>
    <item>
      <title>去中心化联合学习：安全和隐私调查</title>
      <link>https://arxiv.org/abs/2401.17319</link>
      <description><![CDATA[近年来，联邦学习由于其隐私保护功能等优点而迅速发展并受到欢迎。然而，该架构中模型更新和梯度的交换为网络的恶意用户提供了新的攻击面，这可能会危及模型性能以及用户和数据隐私。因此，去中心化联邦学习的主要动机之一是通过将服务器从网络中移除并通过区块链等技术进行补偿来消除与服务器相关的威胁。然而，这种优势是以新的隐私威胁挑战系统为代价的。因此，有必要在这种新范式中进行彻底的安全分析。这项调查研究了去中心化联合学习中威胁和对手的可能变化，并概述了潜在的防御机制。本研究还考虑了去中心化联邦学习的可信性和可验证性。]]></description>
      <guid>https://arxiv.org/abs/2401.17319</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>用于增强地球观测数据预测置信度的潜在空间度量</title>
      <link>https://arxiv.org/abs/2401.17342</link>
      <description><![CDATA[这项研究提出了一种估计机器学习模型预测置信度的新方法，特别是在利用地球观测（EO）数据的回归任务中，特别关注蚊子丰度（MA）估计。我们利用变分自动编码器架构，通过 EO 数据集的潜在空间表示导出置信度度量。该方法对于建立潜在表示中的欧几里得距离与单个 MA 预测中的绝对误差 (AE) 之间的相关性至关重要。我们的研究重点是意大利威尼托地区和德国莱茵河上游河谷的 EO 数据集，目标是受蚊子种群影响严重的地区。一个重要发现是 MA 预测的 AE 与所提出的置信度指标之间存在 0.46 的显着相关性。这种相关性意味着一种强大的新指标，可以在 EO 数据分析和蚊子丰度研究的背景下量化人工智能模型的预测可靠性并增强其可信度。]]></description>
      <guid>https://arxiv.org/abs/2401.17342</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>YTCommentQA：教学视频中的视频问题解答</title>
      <link>https://arxiv.org/abs/2401.17343</link>
      <description><![CDATA[教学视频提供了各种任务的详细操作指南，观看者经常提出有关内容的问题。解决这些问题对于理解内容至关重要，但立即得到答案却很困难。虽然已经为视频问答（视频 QA）任务开发了许多计算模型，但它们主要针对基于视频内容生成的问题进行训练，旨在从内容中生成答案。然而，在现实世界中，用户可能会提出超出视频信息边界的问题，这凸显了确定视频是否可以提供答案的必要性。由于视频具有多模态性质，视觉和口头信息相互交织，因此判断视频内容是否可以回答问题具有挑战性。为了弥补这一差距，我们提出了 YTCommentQA 数据集，其中包含来自 YouTube 的自然生成的问题，按其可回答性和所需的回答方式（视觉、脚本或两者）进行分类。可回答性分类任务的实验证明了 YTCommentQA 的复杂性，并强调需要理解视频推理中视觉和脚本信息的组合作用。该数据集可在 https://github.com/lgresearch/YTCommentQA 获取。]]></description>
      <guid>https://arxiv.org/abs/2401.17343</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>通过 Deep Black Litterman 模型优化时序供应商分配风险</title>
      <link>https://arxiv.org/abs/2401.17350</link>
      <description><![CDATA[我们引入 BL 模型和透视矩阵来优化供应商选择和订单分配，重点关注时间和空间动态。我们使用时空图神经网络开发供应商关系网络，增强了对复杂供应商相互依赖性的理解。此外，我们通过屏蔽排名机制解决零阶场景下的可信度问题，提高供应商排名效率。与传统模型相比，我们的模型在两个数据集上表现出了更好的结果。我们使用真实数据集进行的评估凸显了 DBLM 在提供准确预测和精确置信区间方面的优势，特别是在高分辨率场景中。]]></description>
      <guid>https://arxiv.org/abs/2401.17350</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>室内设计中的审美偏好预测：模糊方法</title>
      <link>https://arxiv.org/abs/2401.17710</link>
      <description><![CDATA[室内设计就是创造外观和感觉良好的空间。然而，审美偏好的主观性质在定义和量化室内设计视觉吸引力方面提出了重大挑战。本文通过引入一种量化和预测室内设计中的审美偏好的新颖方法来解决这一差距。我们的研究将模糊逻辑与图像处理技术相结合。我们从社交媒体平台收集了室内设计图像的数据集，重点关注基本的视觉属性，例如色彩和谐、亮度和复杂性。我们使用加权平均来整合这些特征来计算一般的审美分数。我们的方法在计算整体审美偏好时考虑了个人的颜色偏好。我们最初收集用户对红色、棕色等原色的评分，以了解他们的偏好。然后，我们使用图像中前五种主色的像素数来获得配色方案偏好。然后，将配色方案偏好和审美得分作为输入传递给模糊推理系统，以计算总体偏好得分。该分数代表了用户对特定室内设计的偏好的综合衡量，考虑了他们的颜色选择和总体审美吸引力。我们使用 2AFC（两种选择强制选择）方法来验证我们的方法，达到了 0.7 的显着命中率。这项研究可以帮助设计师和专业人士更好地了解和满足人们的室内设计偏好，特别是在一个严重依赖数字媒体的世界中。]]></description>
      <guid>https://arxiv.org/abs/2401.17710</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:37 GMT</pubDate>
    </item>
    <item>
      <title>SwarmBrain：通过大型语言模型实现实时战略游戏《星际争霸 II》的具体代理</title>
      <link>https://arxiv.org/abs/2401.17749</link>
      <description><![CDATA[大型语言模型（LLM）最近在各种探索性任务中取得了重大成就，甚至超越了历史上主导基于代理领域的基于强化学习的传统方法的性能。本文的目的是研究法学硕士在星际争霸 II 游戏环境中执行实时战略战争任务的有效性。在本文中，我们介绍了 SwarmBrain，这是一种利用 LLM 在《星际争霸 II》游戏环境中实现实时策略的具体代理。 SwarmBrain 包含两个关键组件：1）由最先进的法学硕士提供支持的主宰智能矩阵，旨在从高层角度协调宏观战略。这个矩阵模拟了虫族智能大脑的总体意识，综合了战略远见，旨在分配资源、指导扩张和协调多管齐下的攻击。 2）Swarm ReflexNet，它是与主宰智能矩阵的计算深思熟虑相对应的敏捷对应物。由于 LLM 推理中固有的延迟，Swarm ReflexNet 采用条件响应状态机框架，能够对基本的 Zerg 单位机动进行快速战术响应。在实验设置中，SwarmBrain 控制着虫族种族，与计算机控制的人族对手对抗。实验结果显示了SwarmBrain进行经济增强、领土扩张和战术制定的能力，并且表明SwarmBrain能够在不同难度级别的计算机玩家中取得胜利。]]></description>
      <guid>https://arxiv.org/abs/2401.17749</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:37 GMT</pubDate>
    </item>
    <item>
      <title>SDRDPy：以图形方式可视化通过监督描述规则算法获得的知识的应用程序</title>
      <link>https://arxiv.org/abs/2401.17783</link>
      <description><![CDATA[SDRDPy 是一个桌面应用程序，允许专家直观地以图形和表格形式表示由任何有监督的描述性规则发现算法提取的知识。该应用程序能够提供数据分析，显示数据集的相关信息以及规则、数据和与每个规则关联的质量度量之间的关系，而不管执行算法的工具如何。所有信息都显示在用户友好的应用程序中，以便于专家分析以及以不同格式导出报告。]]></description>
      <guid>https://arxiv.org/abs/2401.17783</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:37 GMT</pubDate>
    </item>
    <item>
      <title>移动益智游戏中的难度建模：结合玩家分析和模拟数据的不同方法的实证研究</title>
      <link>https://arxiv.org/abs/2401.17436</link>
      <description><![CDATA[难度是玩家参与度的关键驱动因素之一，也是设计师为优化玩家体验而调整最多的方面之一；因此，对其进行操作是游戏开发工作室的一项关键任务。常见的做法包括根据玩家与内容交互收集的数据创建指标；然而，这只能在内容发布后进行估算，并没有考虑未来潜在玩家的特征。
  在本文中，我们提出了在这种情况下估计难度的一些潜在解决方案，并展示了一项比较研究的结果，旨在了解哪种方法和哪种类型的数据在不同场景中表现更好。
  结果表明，结合队列统计数据和模拟数据训练的模型可以在所有场景中产生最准确的难度估计。此外，在这些模型中，人工神经网络显示出最一致的结果。]]></description>
      <guid>https://arxiv.org/abs/2401.17436</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>用语言传达面向患者的风险预测模型中的不确定性</title>
      <link>https://arxiv.org/abs/2401.17511</link>
      <description><![CDATA[本文解决了人工智能模型应用于医疗保健中面向患者的环境时与不确定性量化相关的独特挑战。与为模型开发人员或领域专家量身定制的传统可解释人工智能（XAI）方法不同，需要额外考虑自然语言的交流、其呈现和评估可理解性。我们在风险预测的背景下使用自然语言确定通信模型性能、置信度、推理和未知知识方面的挑战。我们提出了一种旨在解决这些挑战的设计，重点关注体外受精结果预测的具体应用。]]></description>
      <guid>https://arxiv.org/abs/2401.17511</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>学习停止割代以实现高效的混合整数线性规划</title>
      <link>https://arxiv.org/abs/2401.17527</link>
      <description><![CDATA[割平面（割）在求解混合整数线性规划 (MILP) 中发挥着重要作用，因为它们显着收紧了对偶界限并提高了求解性能。割断的一个关键问题是何时停止割断生成，这对于求解 MILP 的效率非常重要。然而，许多现代 MILP 求解器采用硬编码启发式方法来解决这个问题，这往往会忽略某些应用程序中 MILP 之间的潜在模式。为了应对这一挑战，我们将削减生成停止问题表述为强化学习问题，并提出了一种新颖的混合图表示模型（HYGRO）来学习有效的停止策略。 HYGRO 的一个吸引人的特点是它可以有效地捕获 MILP 的动态和静态特征，从而实现停止策略的动态决策。据我们所知，HYGRO 是第一个解决削减发电停止问题的数据驱动方法。通过将我们的方法与现代求解器相结合，实验表明，与竞争基准相比，HYGRO 显着提高了求解 MILP 的效率，提高了高达 31%。]]></description>
      <guid>https://arxiv.org/abs/2401.17527</guid>
      <pubDate>Thu, 01 Feb 2024 15:12:36 GMT</pubDate>
    </item>
    </channel>
</rss>