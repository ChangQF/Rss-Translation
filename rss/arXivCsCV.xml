<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Wed, 24 Jan 2024 03:15:03 GMT</lastBuildDate>
    <item>
      <title>一种由虚拟试穿模型的蒸馏知识监督的新型服装传输方法。 （arXiv：2401.12433v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12433</link>
      <description><![CDATA[当购物者在线选择服装时，服装转移技术会穿戴
将服装从模特图像转移到购物者的图像上，使购物者能够
决定这件衣服是否适合他们。作为服装转移杠杆
狂野廉价的人物形象作为服装条件，吸引了巨大的关注
社会关注度高，具有巨大的商业潜力。然而，自从
服装转移的基本事实在现实中几乎不可用，以前
研究将服装转移视为姿势转移或服装姿势
解开，并在自我监督学习中训练服装转移，但
不要完全涵盖服装转移意图。因此，训练
监督服装转移是一个棘手的问题。值得注意的是，虚拟试穿
技术通过自我监督学习表现出了卓越的性能。
我们通过知识蒸馏来监督服装转移培训
虚拟试穿。具体来说，我们首先训练转移解析推理
多阶段模型为下游任务提供形状指导。这
转移解析推理模型学习响应和特征知识
尝试解析推理模型并吸收硬知识
基本事实。通过利用虚拟试穿中的变形知识，我们
通过学习形状来估计渐进流以精确地使服装变形
以及内容对应。为了增强转移现实性，我们提出了
精心设计的手臂再生任务来推断暴露的皮肤像素内容。
实验表明我们的方法在以下方面具有最先进的性能
与其他虚拟试穿相比，在人与人之间转移服装
服装转移方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.12433</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>用于诊断 COVID-19 的安全联合学习方法。 (arXiv:2401.12438v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.12438</link>
      <description><![CDATA[最近的大流行凸显了准确诊断的重要性
医院环境中的 COVID-19。这方面的一个主要挑战是
根据胸部症状区分 COVID-19 和其他呼吸道疾病
X 射线，加上 HIPAA 合规性的限制，限制了
患者 X 光片的比较。本文介绍了一种符合 HIPAA 的模型
利用联邦学习帮助诊断 COVID-19。联邦
学习是一种分布式机器学习方法，允许算法
使用本地数据样本跨多个分散设备进行训练，
无需数据共享。我们的模型推进了之前在胸部方面的努力
X射线诊断模型。我们研究了成熟的领先模型
参加该领域的竞赛并开发了我们自己的模型
对具体医院数据有效。考虑模型的运行
在联邦学习背景下，我们探讨了有偏见的数据的潜在影响
模型性能的更新。加强医院对本病的认识
模型的决策过程并验证模型不关注
不相关的特征，我们采用了可视化技术来突出显示关键
胸部 X 光检查的特征表明 COVID-19 诊断呈阳性。
]]></description>
      <guid>http://arxiv.org/abs/2401.12438</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>MAST：使用混合注意连体变压器进行视频息肉分割。 （arXiv：2401.12439v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12439</link>
      <description><![CDATA[从结肠镜检查视频中准确分割息肉非常重要
对息肉治疗和结直肠癌早期预防具有重要意义。
然而，由于建模困难，这具有挑战性
结肠镜检查视频中的远程时空关系。在这个
论文中，我们用一种新颖的混合注意力暹罗来解决这个具有挑战性的任务
Transformer (MAST)，它明确地模拟了远程时空
与准确息肉的混合注意机制的关系
分割。具体来说，我们首先构建一个连体变压器
联合编码配对视频帧的特征的架构
交涉。然后我们设计一个混合注意力模块来利用
帧内和帧间相关性，增强了丰富的特征
时空关系。最后，增强的特征被馈送到两个
用于预测分割图的并行解码器。尽我们最大的努力
据了解，我们的 MAST 是第一个专用于视频息肉的 Transformer 模型
分割。在大规模 SUN-SEG 基准上进行了大量实验
与 MAST 相比，证明了 MAST 的优越性能
最前沿的竞争对手。我们的代码公开于
https://github.com/Junqing-Yang/MAST。
]]></description>
      <guid>http://arxiv.org/abs/2401.12439</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>AdaEmbed：嵌入空间中的半监督域适应。 （arXiv：2401.12421v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12421</link>
      <description><![CDATA[半监督域适应（SSDA）提出了一个关键障碍
计算机视觉，特别是考虑到标记数据经常缺乏
现实世界的设置。这种稀缺性通常会导致基础模型的训练
广泛的数据集，在应用于新领域时表现不佳。阿达嵌入，我们的
新提出的 SSDA 方法为这些问题提供了一个有前景的解决方案
挑战。利用未标记数据的潜力，AdaEmbed 有助于
将知识从标记的源域转移到未标记的目标
通过学习共享嵌入空间来定义域。通过生成准确且统一的
基于已建立的嵌入空间的伪标签，该模型克服了
克服了传统 SSDA 的局限性，从而显着提高了性能。我们的
通过对基准的大量实验验证了方法的有效性
数据集，例如 DomainNet、Office-Home 和 VisDA-C，其中 AdaEmbed
始终优于所有基线，为
固态硬盘协会。凭借其简单的实施和高数据效率，
AdaEmbed 是现实世界中强大而务实的解决方案
标签数据稀缺的场景。为了促进进一步的研究和
在这个领域的应用程序，我们正在共享我们统一框架的代码库
用于半监督域适应。
]]></description>
      <guid>http://arxiv.org/abs/2401.12421</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>InverseMatrixVT3D：一种基于投影矩阵的高效 3D 占用预测方法。 （arXiv：2401.12422v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12422</link>
      <description><![CDATA[本文介绍了 InverseMatrixVT3D，一种高效的变换方法
将多视图图像特征转化为 3D 特征体积以实现 3D 语义占用
预言。构建 3D 体积的现有方法通常依赖于深度
估计、特定于设备的运算符或变压器查询，这阻碍了
3D 占用模型的广泛采用。相比之下，我们的方法
利用两个投影矩阵来存储静态映射关系
矩阵乘法可有效生成全局鸟瞰图 (BEV)
特征和局部 3D 特征体积。具体来说，我们通过以下方式实现这一目标
在多视图图像特征图和两个图像之间执行矩阵乘法
稀疏投影矩阵。我们引入稀疏矩阵处理技术
投影矩阵以优化 GPU 内存使用。此外，全球-本地
提出了注意力融合模块，将全局 BEV 特征与
局部 3D 特征体积以获得最终的 3D 体积。我们还聘请了
多尺度监管机制进一步提升绩效。综合的
nuScenes 数据集上的实验证明了简单性和
我们方法的有效性。该代码将可用
位于：https://github.com/DanielMing123/InverseMatrixVT3D
]]></description>
      <guid>http://arxiv.org/abs/2401.12422</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型被忽视的尾巴。 （arXiv：2401.12425v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12425</link>
      <description><![CDATA[视觉语言模型 (VLM) 在零样本识别方面表现出色，但表现出
视觉概念之间的表现严重不平衡。例如，剪辑、
尽管 ImageNet 上的平均零样本准确率令人印象深刻（72.7%），但
十个概念（例如陀螺仪和夜蛇）的价格低于 10%，大概是因为
这些概念在 VLM 不平衡的预训练数据中代表性不足。然而，
评估这种不平衡具有挑战性，因为计算
VLM 大规模预训练数据中特定概念的出现频率。我们的
工作首次尝试通过分析来测量概念频率
预训练文本。我们使用现成的语言模型来帮助计算相关的
包含给定概念的同义词并解决语言问题的文本
歧义。我们确认像 LAION 这样的流行 VLM 数据集确实表现出了
长尾概念分布，与每个类别密切相关
准确性。此外，当代多模式系统，例如视觉聊天机器人和
文本到图像生成器，也与由
我们的方法。为了缓解 VLM 在零样本识别中的不平衡性能，
我们提出 REtrieval-Augmented Learning REAL。首先，不提示VLM
使用原始类名，REAL 使用最常见的同义词
VLM 的预训练文本。这已经超越了人类工程和
LLM 在九个基准数据集上生成提示，可能是因为 VLM 具有
看到更多与常用同义词相关的图像。二、真实
使用所有概念同义词来检索一个小的、类平衡的集合
预训练数据来训练鲁棒的分类器。 REAL 超越近期
检索增强解决方案 REACT，使用的存储空间减少 400 倍，存储空间减少 10,000 倍
训练时间！
]]></description>
      <guid>http://arxiv.org/abs/2401.12425</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>用于采样自主的冰月表面模拟和立体深度估计。 （arXiv：2401.12414v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12414</link>
      <description><![CDATA[冰冷月球着陆器任务的自主采样需要了解
采样地形的地形和光度特性。不可用
高分辨率视觉数据集（鸟瞰图或视角）
着陆器）是选择、验证或开发的障碍
感知系统。我们尝试通过以下方式缓解这个问题：1）提出
冰月表面模拟图形实用程序 (GUISS) 框架，用于
多功能立体数据集生成，涵盖批量光度测定的范围
属性，2）专注于基于立体的视觉感知系统和
评估传统算法和基于深度学习的深度算法
立体匹配估计。冰月表面反射特性
地形（土卫二和欧罗巴）是从多光谱数据集推断出来的
以前的任务。具有程序地形生成和物理有效
照明源，我们的框架可以适应广泛的假设
尊重冰冷月球地形的视觉表现。接下来是
不同视觉下立体匹配算法的性能研究
假设。最后，我们强调需要解决的长期挑战
模拟土卫二和木卫二等冰冷卫星的感知数据资产。
我们的代码可以在这里找到：https://github.com/nasa-jpl/guiss。
]]></description>
      <guid>http://arxiv.org/abs/2401.12414</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>通过专业标记的视频进行多模式新闻理解 (ReutersViLNews)。 （arXiv：2401.12419v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12419</link>
      <description><![CDATA[虽然视频语言理解领域取得了进展，
当前最先进的算法的能力仍然有限
理解高抽象层次的视频，例如新闻视频。
或者，人类可以轻松地将视频和语言中的信息合并为
推断超出像素中视觉可观察到的信息。一个例子
其中之一是观看新闻报道，其中事件的背景可以作为
在将故事理解为事件本身方面发挥着重要作用。迈向一个
为了在算法中设计这种能力，我们提出了一个大规模的解决方案
对路透社收集的内部数据集进行分析，称为
路透社视频语言新闻 (ReutersViLNews) 数据集，重点关注
高级视频语言理解，重点是长篇新闻。这
ReutersViLNews 数据集由收集和标记的长篇新闻视频组成
多年来由新闻行业专业人士评选，包含重要新闻
来自世界各地的报道。每个视频都涉及一个故事
包含实际事件的动作镜头、对相关人员的采访
事件、附近地区的镜头等等。 ReutersViLNews 数据集
包含七个主题类别的视频：灾难、金融、
娱乐、健康、政治、体育和其他带注释的内容
从高级到低级，标题说明，视觉视频描述，
高级故事描述、关键词和地点。我们首先提出一个
与之前相比，ReutersViLNews 的数据集统计分析
数据集。然后我们对四种不同的最先进方法进行基准测试
视频语言任务。结果表明，以新闻为导向的视频是
当前视频语言理解算法面临巨大挑战
最后，我们提供了设计解决问题的方法的未来方向
路透社ViLNews 数据集。
]]></description>
      <guid>http://arxiv.org/abs/2401.12419</guid>
      <pubDate>Wed, 24 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>用于目标注释的对比学习和基于循环一致性的转导迁移学习。 （arXiv：2401.12340v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12340</link>
      <description><![CDATA[注释自动目标识别（ATR）是一项极具挑战性的任务，
主要是由于目标域中标记数据不可用。
因此，有必要通过以下方式构建最佳目标域分类器：
利用源域图像的标记信息。转导式
迁移学习 (TTL) 方法，结合了基于 CycleGAN 的不配对
领域翻译网络之前已在文献中提出过
有效的ATR注释。尽管该方法显示出巨大的潜力
ATR，它严重受到注释性能较低、Fr\&#39;echet 较高的影响
起始距离 (FID) 分数，以及视觉伪影的存在
合成图像。为了解决这些问题，我们提出了一种混合对比
学习基础不配对域翻译（H-CUT）网络，实现
显着降低 FID 分数。它结合了注意力和熵
强调特定领域的区域，生成一个噪声特征混合模块
高变分合成负片和调制噪声对比
估计（MoNCE）损失使用最优重新加权所有负补丁
运输以获得更好的性能。我们提出的对比学习和
基于周期一致性的 TTL (C3TTL) 框架由两个 H-CUT 网络组成
和两个分类器。它同时优化循环一致性、MoNCE 和
身份损失。在 C3TTL 中，通过一个网络使用了两个 H-CUT 网络
双射映射将重建的源域图像输入
预训练分类器来指导最佳目标域分类器。广泛的
对三个 ATR 数据集进行的实验分析表明
提出的 C3TTL 方法在注释民用和军用方面是有效的
车辆以及船舶目标。
]]></description>
      <guid>http://arxiv.org/abs/2401.12340</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>OCT-SelfNet：具有多模态数据集的自我监督框架，用于广义和稳健的视网膜疾病检测。 （arXiv：2401.12344v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12344</link>
      <description><![CDATA[尽管人工智能产生了革命性的影响，并且本地培训的发展
算法，从多模态数据中实现广泛的广义学习
医疗人工智能仍然是一个重大挑战。这种差距阻碍了实际操作
部署可扩展的医疗人工智能解决方案。应对这一挑战，我们的
研究贡献了一个自我监督的稳健机器学习框架，
OCT-SelfNet，用于使用光学相干断层扫描检测眼部疾病
（OCT）图像。在这项工作中，来自不同机构的各种数据集
结合起来可以实现更全面的代表性。我们的方法
使用两阶段培训方法解决该问题，该方法结合了
使用掩模自动编码器进行自监督预训练和监督微调
基于 SwinV2 主干，为现实世界的临床提供解决方案
部署。使用不同编码器对三个数据集进行大量实验
主干网、低数据设置、看不见的数据设置以及影响
增强表明我们的方法优于基线模型 Resnet-50
在所有测试中始终保持超过 77% 的 AUC-ROC 性能，
而基线模型超过 54%。此外，就 AUC-PR 而言
指标，我们提出的方法超过了 42%，显示出显着的增长
与基线相比，性能至少提高了 10%，而基线仅超过了 33%。
这有助于我们了解我们的方法的潜力和
强调其在临床环境中的有用性。
]]></description>
      <guid>http://arxiv.org/abs/2401.12344</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>扩大量化感知神经架构搜索，以实现边缘的高效深度学习。 （arXiv：2401.12350v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12350</link>
      <description><![CDATA[神经架构搜索 (NAS) 已成为事实上的方法
为边缘设备设计准确高效的网络。由于模型是
通常针对边缘部署进行量化，最近的工作进行了调查
量化感知 NAS (QA-NAS)，用于搜索高度准确且高效的
量化模型。然而，现有的 QA-NAS 方法，特别是少数位
混合精度（FB-MP）方法不能扩展到更大的任务。最后，
QA-NAS 主要局限于小规模任务和小型网络。在这个
工作中，我们提出了一种大规模启用 QA-NAS（INT8 和 FB-MP）的方法
通过利用 block-wise NAS 引入的 block-wise 公式来完成任务。我们
在城市景观上展示语义分割任务的强劲结果
数据集，发现 FB-MP 模型比该模型小 33%，INT8 模型比该模型快 17.6%
DeepLabV3 (INT8) 不会影响任务性能。
]]></description>
      <guid>http://arxiv.org/abs/2401.12350</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>数字图书馆中学习资源类别的自动识别。 （arXiv：2401.12220v1 [cs.DL]）</title>
      <link>http://arxiv.org/abs/2401.12220</link>
      <description><![CDATA[数字图书馆经常面临处理大量数据的挑战
多样化的文档类型。元数据的手动收集和标记可以是
耗时且容易出错的任务。为了解决这个问题，我们的目标是开发一个
数字图书馆的自动元数据提取器。在这项工作中，我们介绍
专为文档图像设计的异构学习资源（HLR）数据集
分类。该方法涉及分解个人学习资源
成组成文档图像（纸张）。然后对这些图像进行处理
通过 OCR 工具提取文本表示。最先进的
分类器用于对文档图像及其文本进行分类
内容。随后，组成文档图像的标签是
用于预测整个文档的标签。
]]></description>
      <guid>http://arxiv.org/abs/2401.12220</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>通过对象检测和过滤器集成进行多模式数据管理。 （arXiv：2401.12225v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12225</link>
      <description><![CDATA[我们提出了一种管理多模态数据的方法，我们将其用于我们的
进入 2023 年 DataComp 竞赛过滤赛道。我们的技术结合了
对象检测和基于弱监督的集成。在两个中的第一个中
在我们的方法步骤中，我们采用开箱即用的零样本目标检测
模型来提取粒度信息并生成各种滤波器设计。
第二步，我们采用弱监督来集成过滤规则。
与之前的方法相比，此方法的性能提高了 4%
表现最佳的基线，在小规模中排名第一
撰写本文时的轨迹。此外，在中型赛道上，我们
通过简单的集成，在基线上实现了 4.2% 的显着改进
现有基线监管薄弱。
]]></description>
      <guid>http://arxiv.org/abs/2401.12225</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的大规模强化学习。 （arXiv：2401.12244v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.12244</link>
      <description><![CDATA[文本到图像扩散模型是一类深度生成模型，
已经展示了令人印象深刻的高质量图像生成能力。
然而，这些模型很容易受到隐含偏差的影响，这些偏差来自于
网络规模的文本图像训练对，可能会不准确地建模各个方面
我们关心的图像。这可能会导致样本不理想、模型偏差和
不符合人类道德和偏好的图像。在本文中，我们
提出一种有效的可扩展算法来改进扩散模型
强化学习 (RL) 涵盖多种奖励函数，例如
人类对数百万张图像的偏好、组合性和公平性。我们
说明我们的方法如何显着优于现有方法
使扩散模型与人类偏好保持一致。我们进一步说明如何
这大大改进了预训练的稳定扩散（SD）模型，生成
与来自基地的样本相比，人类更喜欢 80.3% 的样本
SD模型同时提高了组成和多样性
生成的样本。
]]></description>
      <guid>http://arxiv.org/abs/2401.12244</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>社交机器人导航的多智能体动态关系推理。 （arXiv：2401.12275v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2401.12275</link>
      <description><![CDATA[社交机器人导航在日常生活的各种环境中都有帮助，但是
需要安全的人机交互和高效的轨迹规划。尽管
成对关系建模在多智能体交互中得到了广泛的研究
系统中，捕捉更大规模的群体活动的能力是有限的。
在本文中，我们提出了一种系统的关系推理方法
对底层动态演化关系的显式推断
结构，我们证明了它对于多智能体轨迹的有效性
预测和社交机器人导航。除了对之间的边缘
节点（即代理），我们建议推断自适应连接的超边
多个节点以无监督的方式实现分组推理。我们的
方法推断动态演变的关系图和超图来捕获
关系的演变，轨迹预测器用来生成
未来的状态。同时，我们建议对锐度和稀疏度进行正则化
学习到的关系以及关系演化的平滑度，
事实证明可以增强训练稳定性和模型性能。拟议的
该方法在综合人群模拟和现实世界基准上得到验证
数据集。实验证明该方法推断出合理的关系
并实现了最先进的预测性能。此外，我们还提出了一个
用于社交机器人导航的深度强化学习（DRL）框架，
系统地结合了关系推理和轨迹预测。在
基于群体的人群模拟，我们的方法优于最强的基线
在安全性、效率和社会责任方面显着提升
在密集的交互式场景中。
]]></description>
      <guid>http://arxiv.org/abs/2401.12275</guid>
      <pubDate>Wed, 24 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    </channel>
</rss>