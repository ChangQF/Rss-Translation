<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 22 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MindTuner：具有视觉指纹和语义校正的跨主题视觉解码</title>
      <link>https://arxiv.org/abs/2404.12630</link>
      <description><![CDATA[arXiv:2404.12630v1 公告类型：新
摘要：从大脑活动解码自然视觉场景已经蓬勃发展，单主题任务的研究广泛，但跨主题任务的研究较少。由于受试者之间存在巨大的个体差异以及数据注释的稀缺，在跨受试者任务中重建高质量图像是一个具有挑战性的问题。在这项工作中，我们提出了用于跨主题视觉解码的 MindTuner，受益于人类视觉系统中视觉指纹的现象和一种新颖的 fMRI-to，仅使用 1 小时的 fMRI 训练数据即可实现高质量和丰富语义的重建。 -文本对齐范例。首先，我们在 7 个受试者中预训练一个多受试者模型，并利用新受试者的稀缺数据对其进行微调，其中使用带有 Skip-LoRA 的 LoRA 来学习视觉指纹。然后，我们以图像模态作为中间枢轴模态来实现 fMRI 到文本的对齐，从而实现了令人印象深刻的 fMRI 到文本的检索性能，并通过微调语义纠正 fMRI 到图像的重建。定性和定量分析的结果表明，无论使用 1 小时还是 40 小时的训练数据，MindTuner 都超越了自然场景数据集 (NSD) 上最先进的跨主题视觉解码模型。]]></description>
      <guid>https://arxiv.org/abs/2404.12630</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>ELEV-VISION-SAM：用于自动估计建筑物最低楼层标高的集成视觉语言和基础模型</title>
      <link>https://arxiv.org/abs/2404.12606</link>
      <description><![CDATA[arXiv:2404.12606v1 公告类型：新
摘要：借助图像质量和可访问性的进步，街景图像已成为城市分析研究的宝贵资源。最近的研究探索了其估算最低楼层标高 (LFE) 的潜力，为传统现场测量提供了可扩展的替代方案，这对于评估房产的洪水风险和损坏程度至关重要。虽然现有方法依赖于对象检测，但图像分割的引入扩大了街景图像在 LFE 估计中的实用性，尽管分割质量和区分前门与其他门的能力仍然存在挑战。为了解决 LFE 估计中的这些挑战，本研究将分割基础模型 Segment Anything 模型与视觉语言模型集成，对街景图像进行文本提示图像分割以进行 LFE 估计。通过评估各种视觉语言模型、集成方法和文本提示，我们确定了最适合街景图像分析和 LFE 估计任务的模型，从而将当前基于图像分割的 LFE 估计模型的可用性从 33% 提高到 56%的属性。值得注意的是，我们提出的方法显着增强了 LFE 估计对几乎所有在街景图像中可见前门的房产的可用性。研究结果还提出了基于街景图像的 LFE 估计的各种视觉模型的第一个基线和比较。该模型和研究结果不仅有助于推进城市分析的街景图像分割，而且还为其他土木工程和基础设施分析任务的图像分割任务提供了一种新颖的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.12606</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>重新思考换衣人员重识别：冲突、综合与优化</title>
      <link>https://arxiv.org/abs/2404.12611</link>
      <description><![CDATA[arXiv:2404.12611v1 公告类型：新
摘要：换衣者重新识别（CC-ReID）旨在检索同一个人穿着不同服装的图像。主流研究侧重于设计先进的模型结构和策略来捕获独立于服装的身份信息。然而，CC-ReID 中作为标准 ReID 学习目标的同衣歧视在之前的研究中一直被忽视。在本研究中，我们深入探讨了标准学习目标和换衣学习目标之间的关系，并将这两个目标之间的内在冲突凸显出来。我们尝试通过补充由我们提出的衣服变化扩散模型产生的高保真衣服变化合成来放大 CC 训练对的比例。通过将合成图像合并到 CC-ReID 模型训练中，我们观察到 CC 协议下的显着改进。然而，由于标准与CC之间的内在冲突，这种改进牺牲了标准协议下的性能。为了缓解冲突，我们将这些目标解耦，并将 CC-ReID 学习重新表述为多目标优化 (MOO) 问题。通过有效地规范多个目标的梯度曲率并引入偏好限制，我们的 MOO 解决方案超越了单任务训练范例。我们的框架与模型无关，并且在 CC 和标准 ReID 协议下表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.12611</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>SkelFormer：使用骨骼变压器进行无标记 3D 姿势和形状估计</title>
      <link>https://arxiv.org/abs/2404.12625</link>
      <description><![CDATA[arXiv:2404.12625v1 公告类型：新
摘要：我们介绍了 SkelFormer，这是一种用于多视图人体姿势和形状估计的新型无标记运动捕捉管道。我们的方法首先使用现成的 2D 关键点估计器，在大规模野外数据上进行预训练，以获得 3D 关节位置。接下来，我们设计一个基于回归的逆运动骨骼变换器，将关节位置映射到来自严重噪声观测的姿势和形状表示。该模块集成了有关姿势空间的先验知识，并在运行时推断完整的姿势状态。将 3D 关键点检测和逆运动学问题分开，以及我们的骨架变换器学习到的表达表示，增强了我们的方法对看不见的噪声数据的泛化。我们使用三个数据集在分布内和分布外设置的三个公共数据集上评估我们的方法，并观察到相对于先前工作的强劲性能。此外，消融实验证明了我们架构中每个模块的影响。最后，我们研究了我们的方法在处理噪声和严重遮挡方面的性能，并发现相对于其他解决方案具有相当大的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2404.12625</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>跨模态适配器：视觉语言模型的参数高效迁移学习方法</title>
      <link>https://arxiv.org/abs/2404.12588</link>
      <description><![CDATA[arXiv:2404.12588v1 公告类型：新
摘要：基于适配器的参数高效迁移学习在视觉语言模型中取得了令人兴奋的结果。传统的适配器方法通常需要训练或微调，面临样本不足或资源限制等挑战。虽然一些方法通过利用图像模态缓存和检索来克服训练的需要，但它们忽略了文本模态的重要性以及跨模态线索对于视觉语言模型中参数的有效适应。这项工作引入了一种名为 XMAdapter 的跨模式参数高效方法。 XMAdapter 为文本和图像模式建立缓存模型。然后，它利用视觉语言双模信息检索来收集推理线索。通过动态调整亲和度比率，实现跨模态融合，解耦不同模态的相似性以评估其各自的贡献。此外，它还根据跨模态亲和力的差异探索硬样本，并通过样本学习强度的自适应调整来增强模型性能。基准数据集上的大量实验结果表明，XMAdapter 在准确性、泛化性和效率方面显着优于以前的基于适配器的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.12588</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>CNN网络中数据域变化的可视化方法及分类任务中选择阈值的优化方法</title>
      <link>https://arxiv.org/abs/2404.12602</link>
      <description><![CDATA[arXiv:2404.12602v1 公告类型：新
摘要：近年来，人脸反欺骗（FAS）在维护人脸识别技术的安全方面发挥了至关重要的作用。随着假冒人脸生成技术的兴起，数字编辑的人脸反欺骗所带来的挑战正在不断升级。现有的 FAS 技术主要侧重于拦截物理伪造的人脸，缺乏针对跨域 FAS 挑战的强大解决方案。此外，确定适当的阈值以实现最佳部署结果仍然是域内 FAS 的一个问题。为了解决这些问题，我们提出了一种可视化方法，通过可视化数据集上的预测结果来直观地反映模型的训练结果。此外，我们证明采用数据增强技术（例如下采样和高斯模糊）可以有效提高跨域任务的性能。基于我们的数据可视化方法，我们还引入了一种根据训练数据集的分布设置阈值的方法。最终，我们的方法在统一物理数字人脸攻击检测竞赛和快照光谱成像人脸反欺​​骗竞赛中获得了第二名。训练代码可在 https://github.com/SeaRecluse/CVPRW2024 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.12602</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>GenVideo：使用 T2I 扩散模型进行一次性目标图像和形状感知视频编辑</title>
      <link>https://arxiv.org/abs/2404.12541</link>
      <description><![CDATA[arXiv:2404.12541v1 公告类型：新
摘要：基于扩散模型的视频编辑方法仅依靠文本提示进行编辑，但由于文本提示的表达能力有限而受到阻碍。因此，为了精确控制编辑，合并参考目标图像作为视觉引导变得令人期望。此外，当目标图像中的对象的形状和大小与源对象不同时，大多数现有方法都难以准确地编辑视频。为了应对这些挑战，我们提出了“GenVideo”，用于利用目标图像感知 T2I 模型来编辑视频。我们的方法处理具有不同形状和大小的目标对象的编辑，同时使用我们新颖的目标和形状感知 InvEdit 蒙版保持编辑的时间一致性。此外，我们在推理过程中提出了一种新颖的目标图像感知潜在噪声校正策略，以提高编辑的时间一致性。实验分析表明，GenVideo 可以有效地处理不同形状对象的编辑，而现有方法则无法做到这一点。]]></description>
      <guid>https://arxiv.org/abs/2404.12541</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>Gaussian Splatting 是否需要 SFM 初始化？</title>
      <link>https://arxiv.org/abs/2404.12547</link>
      <description><![CDATA[arXiv:2404.12547v1 公告类型：新
摘要：由于其高质量的结果以及与硬件光栅化的兼容性，3D 高斯分布最近被认为是场景重建和新颖视图合成的通用且有效的方法。尽管高斯溅射有其优点，但它对运动结构 (SFM) 算法的高质量点云初始化的依赖是一个需要克服的重大限制。为此，我们研究了高斯分布的各种初始化策略，并深入研究了如何利用神经辐射场 (NeRF) 的体积重建来绕过对 SFM 数据的依赖。我们的研究结果表明，如果精心设计，随机初始化可以表现得更好，并且通过采用改进的初始化策略和低成本 NeRF 模型的结构蒸馏相结合，可以获得相同的结果，有时甚至优于所获得的结果从 SFM 初始化。]]></description>
      <guid>https://arxiv.org/abs/2404.12547</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>DoughNet：可变形物体拓扑操纵的视觉预测模型</title>
      <link>https://arxiv.org/abs/2404.12524</link>
      <description><![CDATA[arXiv:2404.12524v1 公告类型：新
摘要：像面团这样的弹塑性物体的操纵通常涉及拓扑变化，例如分裂和合并。准确预测特定动作可能引起的拓扑变化的能力对于规划与弹塑性物体的相互作用至关重要。我们提出了 DoughNet，一种基于 Transformer 的架构，用于应对这些挑战，由两个组件组成。首先，去噪自动编码器将不同拓扑的可变形对象表示为潜在代码集。其次，视觉预测模型执行自回归集预测，以确定纯粹潜在空间中的长视界几何变形和拓扑变化。给定部分初始状态和所需的操作轨迹，它会推断出每一步的所有结果对象几何形状和拓扑。因此，DoughNet 允许规划机器人操作；选择合适的工具、其姿势和开口宽度来重建机器人或人造目标。我们在模拟和真实环境中的实验表明，DoughNet 能够显着优于仅将变形视为几何变化的相关方法。]]></description>
      <guid>https://arxiv.org/abs/2404.12524</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>TrACT：用于长尾轨迹预测的训练动态感知对比学习框架</title>
      <link>https://arxiv.org/abs/2404.12538</link>
      <description><![CDATA[arXiv:2404.12538v1 公告类型：新
摘要：作为一项安全关键任务，自动驾驶需要准确预测道路使用者的未来轨迹以进行安全运动规划，特别是在具有挑战性的条件下。然而，许多最近的深度学习方法在具有挑战性的场景中表现不佳，主要是因为这些场景在训练数据中出现的频率较低。为了解决这样的长尾问题，现有的方法在训练过程中迫使具有挑战性的场景在特征空间中更加紧密地结合在一起，以触发它们之间的信息共享，从而实现更强大的学习。然而，这些方法主要依靠运动模式来表征场景，忽略了更多信息丰富的上下文信息，例如交互和场景布局。我们认为，利用此类信息不仅可以提高预测准确性，还可以提高生成轨迹的场景合规性。在本文中，我们建议将更丰富的训练动态信息纳入原型对比学习框架中。更具体地说，我们提出了一个两阶段的过程。首先，我们使用基线编码器-解码器框架生成丰富的上下文特征。使用训练动态信息，根据模型的输出误差将这些特征分成簇，并在每个簇内计算原型。其次，我们在对比学习框架中使用原型重新训练模型。我们使用两个大规模自然数据集对我们的方法进行了实证评估，并表明我们的方法通过提高长尾样本的准确性和场景合规性来实现最先进的性能。此外，我们对集群的子集进行实验，以强调我们的方法在减少训练偏差方面的额外好处。]]></description>
      <guid>https://arxiv.org/abs/2404.12538</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>SPIdepth：用于自监督单目深度估计的强化姿势信息</title>
      <link>https://arxiv.org/abs/2404.12501</link>
      <description><![CDATA[arXiv:2404.12501v1 公告类型：新
摘要：自监督单目深度估计因其在自动驾驶和机器人技术中的应用而受到广泛关注。虽然最近的方法在利用自查询层 (SQL) 等技术来推断运动深度方面取得了长足的进步，但它们常常忽视了增强姿势信息的潜力。在本文中，我们介绍了 SPIdepth，这是一种优先增强姿势网络以改进深度估计的新颖方法。 SPI深度建立在 SQL 奠定的基础上，强调姿势信息在捕获细粒度场景结构中的重要性。通过增强姿态网络的功能，SPI深度在场景理解和深度估计方面取得了显着的进步。在 KITTI 和 Cityscapes 等基准数据集上的实验结果展示了 SPIdepth 的最先进性能，大幅超越了之前的方法。值得注意的是，SPIdepth 的性能超过了无监督模型，并且在对度量数据进行微调后，性能优于所有现有方法。值得注意的是，SPIdepth 仅使用单个图像进行推理就实现了这些结果，甚至超越了利用视频序列进行推理的方法，从而证明了其在实际应用中的功效和效率。我们的方法代表了自监督单目深度估计的重大飞跃，强调了加强姿势信息对于推进现实世界应用中的场景理解的重要性。]]></description>
      <guid>https://arxiv.org/abs/2404.12501</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:08 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习中的多模态转换器</title>
      <link>https://arxiv.org/abs/2404.12467</link>
      <description><![CDATA[arXiv:2404.12467v1 公告类型：新
摘要：多模态变压器标志着不同领域的重大进展，但孤立的高质量数据阻碍了其进一步改进。为了解决这个问题，联邦学习（FL）已成为一种有前途的隐私保护范例，用于训练模型，而无需直接访问不同客户端持有的原始数据。尽管具有潜力，但关于 FL 中不成对的单模态客户端和变压器架构的大量研究方向仍未得到探索。为了填补这一空白，本文探索了视觉语言领域内的迁移多模态联邦学习（MFL）场景，其中客户拥有分布在不同数据集中的各种模态的数据。我们系统地评估了使用变压器架构时现有方法的性能，并通过解决客户端之间的模内和跨模态差距，引入了一种称为联邦模态补充和协作（FedCola）的新颖框架。通过在各种 FL 设置上进行的广泛实验，FedCola 展示了优于以前方法的性能，为未来多模态 Transformer 的联合训练提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2404.12467</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>推进卫星摄影测量的应用：使用立体/多视图卫星图像衍生的 3D 数据进行建成区建模和自然环境监测的新方法</title>
      <link>https://arxiv.org/abs/2404.12487</link>
      <description><![CDATA[arXiv:2404.12487v1 公告类型：新
摘要：随着近几十年来遥感技术的发展，具有亚米级和米级空间分辨率的星载传感器（Worldview 和 PlanetScope）已经获得了相当高的图像质量，可以通过立体匹配管道生成 3D 地理空间数据。这些成就显着提高了 3D 数据的可访问性，因此需要调整这些 3D 地理空间数据来分析人类和自然环境。本论文探索了几种基于立体和多视图卫星图像衍生的 3D 地理空间数据的新方法，以处理建成区建模和自然环境监测的遥感应用问题，包括建筑模型 3D 重建、冰川动态跟踪和湖泊藻类监测。具体来说，本文介绍了处理卫星 3D 数据的空间和时间挑战的新方法的四个部分。第一项研究通过采用模型驱动工作流程的新颖方法，利用卫星衍生的正射影像和 DSM 推进 LoD-2 建筑建模，生成建筑矩形 3D 几何模型。其次，我们进一步增强了针对密集城市地区和非矩形目的的建筑重建框架，我们实施了单元级分割的深度学习，并针对圆形建筑引入了基于梯度的圆形重建，开发了用于高级建筑 LoD2 重建的多边形合成技术。我们的第三项研究利用高时空分辨率的 PlanetScope 卫星图像在中纬度地区进行 3D 水平的冰川跟踪。最后，我们提出了“藻类行为函数”这一术语，以细化水质监测中卫星图像叶绿素a浓度的量化，解决藻类波动以及卫星观测和现场测量之间的时间差异，从而提高水下藻类体积的精度估计。总体而言，本论文展示了卫星摄影测量应用在解决城市和环境挑战方面的广泛潜力。它进一步展示了创新的分析方法，增强了适应立体和多视图超高分辨率卫星衍生 3D 数据的适用性。 （参见文档中的完整摘要）]]></description>
      <guid>https://arxiv.org/abs/2404.12487</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>TV100：预训练的CLIP没见过的电视剧数据集</title>
      <link>https://arxiv.org/abs/2404.12407</link>
      <description><![CDATA[arXiv:2404.12407v1 公告类型：新
摘要：预训练模型时代为机器学习社区带来了大量新见解。在出现的无数问题中，最重要的一个是：“预训练的模型是否拥有全面的知识？”本文旨在解决这一关键问题。根据我们的目标，我们公开了一个新颖的数据集，其中包含 2021 年后发布的电视剧的图像。该数据集在各个研究领域具有巨大的应用潜力，包括增量学习的评估、新类发现和长尾学习等。项目页面：https://tv-100.github.io/]]></description>
      <guid>https://arxiv.org/abs/2404.12407</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:06 GMT</pubDate>
    </item>
    <item>
      <title>增强人工智能诊断：通过半监督深度学习自主病变掩蔽</title>
      <link>https://arxiv.org/abs/2404.12450</link>
      <description><![CDATA[arXiv:2404.12450v1 公告类型：新
摘要：本研究提出了一种无监督域适应方法，旨在自动生成概述感兴趣区域（ROI）的图像掩模，以区分乳腺超声（US）成像中的乳腺病变。我们的半监督学习方法利用在具有真实注释的小型公共乳房美国数据集上训练的原始模型。然后，针对域适应任务，对该模型进行迭代细化，为我们私有的、未注释的乳房美国数据集生成伪掩模。该数据集的大小是公共数据集的两倍，在图像采集视角和人口统计代表性方面表现出相当大的变化，带来了领域转移的挑战。与典型的领域对抗训练不同，我们采用下游分类结果作为基准来指导后续迭代中伪掩模的更新。我们发现分类精度与生成的 ROI 的完整性高度相关，这提高了深度学习分类模型的可解释性。初步研究结果证明了该方法在简化 ROI 注释过程方面的有效性和可靠性，从而增强了乳腺病变的分类和定位，从而实现更精确和可解释的诊断。]]></description>
      <guid>https://arxiv.org/abs/2404.12450</guid>
      <pubDate>Mon, 22 Apr 2024 06:18:06 GMT</pubDate>
    </item>
    </channel>
</rss>