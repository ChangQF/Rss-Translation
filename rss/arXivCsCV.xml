<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>STAT：迈向可推广的时间动作本地化</title>
      <link>https://arxiv.org/abs/2404.13311</link>
      <description><![CDATA[arXiv:2404.13311v1 公告类型：新
摘要：弱监督时间动作定位（WTAL）旨在仅使用视频级标签来识别和定位动作实例。尽管取得了重大进展，但现有方法在转移到不同发行版时性能会严重下降，因此可能很难适应现实场景。为了解决这个问题，我们提出了可泛化时间动作定位任务（GTAL），其重点是提高动作定位方法的泛化性。我们观察到，性能下降主要归因于缺乏对不同行动规模的概括性。为了解决这个问题，我们提出了 STAT（自监督时间自适应教师），它利用师生结构进行迭代细化。我们的 STAT 具有细化模块和对齐模块。前者通过利用上下文信息迭代地细化模型的输出，并帮助适应目标规模。后者通过促进学生和教师模型之间的共识来改进细化过程。我们在 THUMOS14、ActivityNet1.2 和 HACS 三个数据集上进行了广泛的实验，结果表明，我们的方法在跨分布评估设置下显着改进了 Baseline 方法，甚至接近同分布评估性能。]]></description>
      <guid>https://arxiv.org/abs/2404.13311</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>像素是一个障碍：扩散模型比我们想象的更具有对抗性</title>
      <link>https://arxiv.org/abs/2404.13320</link>
      <description><![CDATA[arXiv:2404.13320v1 公告类型：新
摘要：扩散模型的对抗性例子被广泛用作安全问题的解决方案。通过向个人图像添加对抗性扰动，攻击者无法轻松编辑或模仿它们。然而，值得注意的是，所有这些保护都是针对潜在扩散模型（LDM）的，像素空间（PDM）中扩散模型的对抗性例子在很大程度上被忽视了。这可能会误导我们，认为扩散模型像大多数深度模型一样容易受到对抗性攻击。在本文中，我们展示了新的发现：尽管基于梯度的白盒攻击可用于攻击 LDM，但它们无法攻击 PDM。这一发现得到了对具有不同模型结构的各种 PDM 和 LDM 上几乎多种攻击方法的广泛实验的支持，这意味着扩散模型确实对对抗性攻击更加鲁棒。我们还发现，PDM 可以用作现成的净化器，有效去除 LDM 上生成的对抗模式以保护图像，这意味着当今的大多数保护方法在某种程度上无法保护我们的图像免受恶意攻击攻击。我们希望我们的见解能够激励社区重新思考扩散模型的对抗样本作为保护方法，并迈向更有效的保护。代码可在 https://github.com/xavihart/PDM-Pure 中找到。]]></description>
      <guid>https://arxiv.org/abs/2404.13320</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>PCQA：基于即时条件的 AIGC 质量评估的强大基线</title>
      <link>https://arxiv.org/abs/2404.13299</link>
      <description><![CDATA[arXiv:2404.13299v1 公告类型：新
摘要：大型语言模型（LLM）和扩散模型的发展带来了人工智能生成内容（AIGC）的繁荣。有必要建立一个有效的质量评估框架，以基于 AIGC 技术对不同图像或视频提供可量化的评估。 AIGC 方法生成的内容由精心设计的提示驱动。因此，直观上提示也可以作为AIGC质量评估的基础。本研究提出了一个有效的 AIGC 质量评估 (QA) 框架。首先，我们提出了一种基于双源CLIP（对比语言-图像预训练）文本编码器的混合提示编码方法，以理解并响应提示条件。其次，我们提出了一种基于集成的特征混合器模块，以有效地混合适应的提示和视觉特征。实证研究在两个数据集AIGIQA-20K（AI生成的图像质量评估数据库）和T2VQA-DB（文本到视频质量评估数据库）中实践，验证了我们提出的方法的有效性：即时条件质量评估（PCQA） ）。我们提出的简单可行的框架可以促进多模式生成领域的研究发展。]]></description>
      <guid>https://arxiv.org/abs/2404.13299</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>FakeBench：利用大型多模态模型揭开假图像的致命弱点</title>
      <link>https://arxiv.org/abs/2404.13306</link>
      <description><![CDATA[arXiv:2404.13306v1 公告类型：新
摘要：最近，人工智能（AI）模型生成的虚假图像已变得与真实图像难以区分，这给虚假图像检测模型带来了新的挑战。从这个意义上来说，由于缺乏人类可以理解的解释，简单的真假二元判断似乎缺乏说服力和可信度。幸运的是，大型多模态模型（LMM）为实现判断过程带来了可能性，同时其性能仍不确定。因此，我们提出了 FakeBench，这是第一个透明防伪基准，由伪造图像和伪造标志上的人类语言描述组成。 FakeBench 探索了 LMM 的两个悬而未决的问题：（1）LMM 能否区分 AI 生成的假图像，以及（2）LMM 如何区分假图像？具体来说，我们用 6k 个不同来源的假图像和真实图像构建了 FakeClass 数据集，每个图像都配备了一个关于图像真实性的问答对，用于对检测能力进行基准测试。为了检验 LMM 的推理和解释能力，我们提出了 FakeClue 数据集，该数据集由 15k 条关于揭示虚假图像伪造的线索的描述组成。此外，我们构建了 FakeQA 来衡量 LMM 在细粒度真实性相关方面的开放式问题回答能力。我们的实验结果发现，当前的 LMM 具有中等的识别能力、初步解释和推理能力以及图像篡改的开放式问答能力。 FakeBench 将很快公开。]]></description>
      <guid>https://arxiv.org/abs/2404.13306</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>StrideNET：用于地形识别和动态粗糙度提取的 Swin Transformer</title>
      <link>https://arxiv.org/abs/2404.13270</link>
      <description><![CDATA[arXiv:2404.13270v1 公告类型：新
摘要：深度学习的进步正在彻底改变遥感图像的分类。基于 Transformer 的架构利用自注意力机制，已成为传统卷积方法的替代方案，能够捕获图像中的远程依赖关系以及全局关系。受这些进步的推动，本文提出了 StrideNET，这是一种专为地形识别和隐式属性估计而设计的新型双分支架构。地形识别分支利用 Swin Transformer，利用其分层表示和低计算成本来有效捕获局部和全局特征。地形属性分支侧重于使用统计纹理分析方法提取表面属性，例如粗糙度和光滑度。通过计算表面地形特性，可以获得增强的环境感知。 StrideNET 模型在包含四个目标地形类别的数据集上进行训练：Grassy、Marshy、Sandy 和 Rocky。与当代方法相比，StrideNET 获得了具有竞争力的性能。这项工作的影响延伸到各种应用，包括环境监测、土地利用和土地覆盖 (LULC) 分类、灾害响应、精准农业等等。]]></description>
      <guid>https://arxiv.org/abs/2404.13270</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉掩模恢复进行无监督异常检测的多特征重建网络</title>
      <link>https://arxiv.org/abs/2404.13273</link>
      <description><![CDATA[arXiv:2404.13273v1 公告类型：新
摘要： 仅使用正常样本的无监督异常检测对于工业制造中的质量检测具有重要意义。尽管现有的基于重建的方法取得了可喜的结果，但它们仍然面临两个问题：图像重建中的可区分信息较差以及模型过度泛化能力导致的异常再生。为了克服上述问题，我们将图像重建转换为并行特征恢复的组合，并在本文中提出了一种使用交叉掩模恢复的多特征重建网络MFRNet。具体来说，首先开发多尺度特征聚合器，以从预训练模型生成输入图像的更具辨别力的分层表示。随后，采用交叉掩模生成器随机覆盖提取的特征图，然后采用基于变压器结构的恢复网络对缺失区域进行高质量修复。最后，配备混合损失来指导模型训练和异常估计，同时考虑像素和结构相似性。大量实验表明，我们的方法在四个公共可用数据集和一个自制数据集上与其他最先进的方法相比具有很强的竞争力或显着优于其他最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.13273</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>Wills Aligner：强大的多主体大脑表征学习器</title>
      <link>https://arxiv.org/abs/2404.13282</link>
      <description><![CDATA[arXiv:2404.13282v1 公告类型：新
摘要：从人脑活动中解码视觉信息在最近的研究中取得了显着的进展。然而，由于不同受试者的皮质分区和认知模式存在显着差异，当前的方法为每个受试者提供个性化的深度模型，限制了该技术在现实世界中的实用性。为了应对这些挑战，我们引入了 Wills Aligner，一个强大的多主题大脑表征学习器。我们的遗嘱对齐器最初在解剖层面上对齐不同受试者的大脑。随后，它结合了大脑专家的混合物来学习个人的认知模式。此外，它将多学科学习任务解耦为两阶段训练，推动深度模型及其插件网络分别学习学科间共性知识和各种认知模式。 Wills Aligner 使我们能够克服解剖学差异，并有效利用单一模型进行多主体大脑表征学习。我们仔细评估了我们的方法在粗粒度和细粒度视觉解码任务中的性能。实验结果表明，我们的 Wills Aligner 实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.13282</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>FilterPrompt：指导扩散模型中的图像传输</title>
      <link>https://arxiv.org/abs/2404.13263</link>
      <description><![CDATA[arXiv:2404.13263v1 公告类型：新
摘要：在可控生成任务中，根据单个输入图像线索灵活地操纵生成的图像以获得所需的外观或结构仍然是一个关键且长期存在的挑战。要实现这一目标，需要对输入图像数据中的关键属性进行有效解耦，以准确地获得表示。先前的研究主要集中在特征空间内解开图像属性。然而，现实世界数据中存在的复杂分布通常使得将此类解耦算法应用于其他数据集具有挑战性。此外，对特征编码的控制粒度经常无法满足特定的任务要求。通过仔细研究各种生成模型的特征，我们发现扩散模型的输入敏感性和动态演化特性可以与像素空间中的显式分解操作有效地融合。这种集成使得能够针对输入图像的特定特征分布在像素空间中执行图像处理操作，并且可以在生成的结果中达到期望的控制效果。因此，我们提出了FilterPrompt，一种增强模型控制效果的方法。它可以普遍应用于任何扩散模型，允许用户根据任务需求调整特定图像特征的表示，从而有利于更精确、可控的生成结果。特别是，我们设计的实验表明，FilterPrompt 优化了特征相关性，减轻了生成过程中的内容冲突，并增强了模型的控制能力。]]></description>
      <guid>https://arxiv.org/abs/2404.13263</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>表结构和字符识别的多单元解码器和相互学习</title>
      <link>https://arxiv.org/abs/2404.13268</link>
      <description><![CDATA[arXiv:2404.13268v1 公告类型：新
摘要：从科学论文、财务报告等文档中提取表格内容并将其转换为大型语言模型可以处理的格式是知识信息处理中的一项重要任务。端到端方法不仅可以识别表格结构，还可以识别单元格内容，其性能可与使用外部字符识别系统的最先进模型相媲美，并且具有进一步改进的潜力。此外，这些模型现在可以通过引入局部注意力来识别具有数百个单元格的长表。然而，这些模型从页眉到页脚的一个方向识别表格结构，并且单元格内容识别是针对每个单元格独立执行的，因此没有机会从相邻单元格检索有用的信息。在本文中，我们提出了一种多单元内容解码器和双向相互学习机制来改进端到端方法。其有效性在两个大型数据集上得到了证明，实验结果表明，即使对于具有大量单元格的长表，其性能也可与最先进的模型相媲美。]]></description>
      <guid>https://arxiv.org/abs/2404.13268</guid>
      <pubDate>Tue, 23 Apr 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>用于高光谱图像分类的 3D 卷积引导光谱空间变换器</title>
      <link>https://arxiv.org/abs/2404.13252</link>
      <description><![CDATA[arXiv:2404.13252v1 公告类型：新
摘要：近年来，视觉变换器（ViTs）由于其自注意力机制，在卷积神经网络（CNN）上表现出了良好的分类性能。许多研究人员已将 ViT 纳入高光谱图像 (HSI) 分类。 HSI 的特点是窄连续光谱带，可提供丰富的光谱数据。尽管 ViT 擅长处理顺序数据，但它们无法像 CNN 那样提取光谱空间信息。此外，为了具有高分类性能，HSI 令牌和类别（CLS）令牌之间应该有很强的交互作用。为了解决这些问题，我们提出了一种用于 HSI 分类的 3D 卷积引导频谱空间变换器 (3D-ConvSST)，它利用编码器之间的 3D 卷积引导残差模块 (CGRM) 来“融合”局部空间和频谱信息并增强特征传播。此外，我们放弃了类标记，而是应用全局平均池化，它有效地编码了更具辨别力和相关性的高级分类特征。在三个公共 HSI 数据集上进行了大量实验，以证明所提出的模型相对于最先进的传统模型、卷积模型和 Transformer 模型的优越性。代码可在 https://github.com/ShyamVarahagiri/3D-ConvSST 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.13252</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>PAFedFV：用于指静脉识别的个性化异步联合学习</title>
      <link>https://arxiv.org/abs/2404.13237</link>
      <description><![CDATA[arXiv:2404.13237v1 公告类型：新
摘要：随着人们对用户隐私保护的日益重视，基于联邦学习的生物特征识别成为最新的研究热点。然而，由于数据的异构性和开放集验证，传统的联邦学习方法无法直接应用于指静脉识别。因此，仅提出了少数应用案例。这些方法仍然有两个缺点。 (1) 统一模型导致部分客户端性能较差，因为指静脉数据高度异构且非独立同分布（non-IID）。 (2)在个别客户端上，大量时间没有得到充分利用，例如等待服务器返回模型的时间。为了解决这些问题，本文提出了一种用于指静脉识别的个性化异步联邦学习（PAFedFV）框架。 PAFedFV设计了个性化模型聚合方法来解决非IID数据之间的异构性。同时，它采用了异步培训模块，供客户利用等待时间。最后，对六个手指静脉数据集进行了广泛的实验。基于这些实验结果，分析了非独立同分布指静脉数据对联邦学习性能的影响，证明了PAFedFV在准确性和鲁棒性方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.13237</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>超越医学图像分割的逐像素监督：从传统模型到基础模型</title>
      <link>https://arxiv.org/abs/2404.13239</link>
      <description><![CDATA[arXiv:2404.13239v1 公告类型：新
摘要：医学图像分割在许多图像引导的临床方法中发挥着重要作用。然而，现有的分割算法大多依赖于具有逐像素注释的完全注释图像来进行训练，这可能既费力又需要专业知识，特别是在只有专家才能提供可靠且准确的注释的医学成像领域。为了缓解这一挑战，人们越来越关注开发能够训练具有弱注释的深度模型的分割方法，例如图像级、边界框、涂鸦和点。视觉基础模型的出现，特别是分段任意模型（SAM），为分割任务引入了创新功能，使用弱注释通过大规模预训练实现快速分割。采用基础模型与传统学习方法相结合最近越来越引起研究界的兴趣，并显示出实际应用的潜力。在本文中，我们全面调查了在基础模型时代之前和之后利用弱注释进行医学图像分割的注释高效学习的最新进展。此外，我们分析和讨论了现有方法的几个挑战，我们相信这将为塑造基础模型的轨迹提供有价值的指导，以进一步推进医学图像分割领域。]]></description>
      <guid>https://arxiv.org/abs/2404.13239</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>使用基于混合经典量子 CNN 的方法对水下图像进行机载分类</title>
      <link>https://arxiv.org/abs/2404.13130</link>
      <description><![CDATA[arXiv:2404.13130v1 公告类型：新
摘要：自主水下航行器（AUV）拍摄的水下图像通常存在低光、高浊度、对比度差、运动模糊和过度光散射的问题，因此需要图像增强技术来进行目标识别。在这种不利条件下，机器学习方法越来越多地用于物体识别。这些从 AUV 拍摄的图像的增强对象识别方法在水下管道和光纤监视、海底资源提取、海底测绘、水下物种探索等方面具有潜在的应用。虽然经典的机器学习方法在准确性方面非常有效，它们需要大量数据集和大量计算时间来进行图像分类。在目前的工作中，我们首次使用量子经典混合机器学习方法在 AUV 上进行实时水下物体识别。我们使用从内部内置的 AUV 机载摄像头拍摄的实时运动模糊和低光图像，并应用现有的混合机器学习方法进行对象识别。我们的混合方法包括使用量子电路对经典图像进行量子编码和扁平化，并将其发送到经典神经网络进行图像分类。将使用 GPU 上基于 Pennylane 的量子模拟器以及板载 NVIDIA GPU 芯片组上的预训练模型执行的混合方法的结果与相应的经典机器学习方法的结果进行比较。我们观察到，与经典机器学习方法相比，混合量子机器学习方法的效率提高了 65% 以上，运行时间减少了三分之一，并且训练模型所需的数据集大小减少了 50%。我们希望我们的工作为自动驾驶汽车中的量子增强实时计算机视觉开辟更多可能性。]]></description>
      <guid>https://arxiv.org/abs/2404.13130</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>BACS：背景感知持续语义分割</title>
      <link>https://arxiv.org/abs/2404.13148</link>
      <description><![CDATA[arXiv:2404.13148v1 公告类型：新
摘要：语义分割在实现机器人系统的全面场景理解方面发挥着至关重要的作用。然而，生成注释具有挑战性，需要为图像中的每个像素添加标签。在自动驾驶等场景中，随着部署的代理的操作环境变得更加复杂，需要逐步合并新的类。为了提高注释效率，理想情况下，仅注释属于新类的像素。这种方法称为连续语义分割（CSS）。除了持续学习环境中经典的灾难性遗忘的常见问题之外，CSS 还受到背景固有的模糊性的影响，我们将这种现象称为“背景偏移”，因为标记为背景的像素可能对应于未来的类别（前向背景）因此，持续学习方法往往会失败，本文提出了一种后向背景偏移检测器（BACS）来根据它们在潜在空间中与前景质心的距离来检测先前观察到的类别。此外，我们提出了交叉熵损失函数的修改版本，结合了 BACS 检测器来减轻与先前观察到的类别相关的背景像素的权重，为了对抗灾难性遗忘，我们采用了屏蔽特征蒸馏和黑暗经验重放。此外，我们的方法包括一个转换器解码器，能够调整到新的类别，而无需额外的分类头。我们在标准 CSS 基准测试上验证了 BACS 相对于现有最先进方法的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2404.13148</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>自监督高光谱图像修复的等变成像</title>
      <link>https://arxiv.org/abs/2404.13159</link>
      <description><![CDATA[arXiv:2404.13159v1 公告类型：新
摘要：高光谱成像（HSI）是地球观测、监视、医学成像和诊​​断、天文学和太空探索的关键技术。遥感应用中 HSI 的传统技术基于推扫扫描方法，其中相机一次记录场景条纹的光谱图像，而图像是通过随时间推移的测量聚合而生成的。在现实世界的机载和星载 HSI 仪器中，某些位置会出现一些空条纹，因为平台并不总是保持恒定的编程姿态，或者无法访问精确的数字高程图 (DEM)，并且行进轨迹不一定对齐始终使用高光谱相机。这使得增强从不完整或损坏的观测中获取的 HS 图像成为一项重要任务。我们在这里介绍一种新颖的 HSI 修复算法，称为高光谱等变成像 (Hyper-EI)。 Hyper-EI 是一种基于自我监督学习的方法，不需要对大量数据集进行训练或访问预先训练的模型。实验结果表明，与现有方法相比，所提出的方法实现了最先进的修复性能。]]></description>
      <guid>https://arxiv.org/abs/2404.13159</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:56 GMT</pubDate>
    </item>
    </channel>
</rss>