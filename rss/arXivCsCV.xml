<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Wed, 06 Dec 2023 03:14:39 GMT</lastBuildDate>
    <item>
      <title>真实世界视觉数据集中自动错误标签检测的实证研究。 （arXiv：2312.02200v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02200</link>
      <description><![CDATA[计算机视觉的重大进步主要归功于使用
标记数据集。然而，获取数据集的标签通常会导致
可能损害模型性能的错误。最近的工作提出了方法
自动识别错误标记的图像，但制定策略
在现实世界的数据集中有效地实施它们的探索很少。
改进以数据为中心的方法来清理现实世界视觉数据集，
我们最近首先进行了200多个实验，仔细进行了基准测试
在多个数据集上开发了自动错误标签检测方法
具有不同噪声水平的各种合成和真实噪声设置。我们
将这些方法与简单高效的错误标签检测器 (SEMD) 进行比较
我们精心设计，发现 SEMD 的表现与之前的相似或优于之前的
错误标签检测方法。然后我们将 SEMD 应用于多个现实世界
计算机视觉数据集并测试数据集大小、错误标签删除策略、
错误标签去除量进一步影响再训练后的模型性能
关于清理后的数据。通过仔细设计该方法，我们发现错误标签
移除后，每类的性能提升最多可达重新训练的 8%
较小数据范围内的分类器。
]]></description>
      <guid>http://arxiv.org/abs/2312.02200</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:39 GMT</pubDate>
    </item>
    <item>
      <title>动态惯性姿势 (DynaIP)：基于部分的运动动力学学习，通过稀疏惯性传感器增强人体姿势估计。 （arXiv：2312.02196v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02196</link>
      <description><![CDATA[本文介绍了一种使用稀疏的新颖的人体姿态估计方法
惯性传感器，解决了以前依赖于惯性传感器的方法的缺点
合成数据。它利用了各种真实的惯性运动捕捉
来自不同骨架格式的数据，以提高运动多样性和模型
概括。该方法具有两个创新组成部分：
惯性动态运动捕捉的伪速度回归模型
传感器，以及基于部件的模型，将身体和传感器数据分为三部分
地区，每个地区都侧重于其独特的特征。该方法
在五个方面展示了优于最先进模型的性能
公共数据集，特别是在 DIP-IMU 数据集上将姿态误差减少了 19%，
因此代表了基于惯性传感器的人体姿势的显着改进
估计。我们将向公众提供我们模型的实施
使用。
]]></description>
      <guid>http://arxiv.org/abs/2312.02196</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>利用扩散先验进行一体化图像恢复。 （arXiv：2312.02197v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02197</link>
      <description><![CDATA[All-in-one 旨在在一个单一的任务中解决图像恢复的各种任务
模型。为此，我们提出了一种利用图像先验的可行方法
由预训练的扩散模型捕获，通过解决两个
挑战，即退化建模和扩散指导。前者的目标
模拟干净图像因某些退化而退化的过程，
后者旨在指导扩散模型生成
相应的干净图像。有了动机，我们提出了零样本
一体式图像恢复框架，称为 ZeroAIR，或者
执行测试时退化建模 (TDM) 和三阶段扩散
反向采样的每个时间步长的指导（TDG）。具体来说，TDM
利用扩散先验从给定的情况中学习退化模型
退化图像，TDG 将时间步分为三个阶段以充分利用
不同扩散先验的优势。由于它们的退化不可知论
属性，可以以零镜头的方式实现一体化图像恢复
由 ZeroAIR 提供。通过大量的实验，我们表明我们的 ZeroAIR 实现了
与那些特定于任务的方法相比，性能甚至更好。代码
将在 Github 上提供。
]]></description>
      <guid>http://arxiv.org/abs/2312.02197</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>USat：用于多传感器卫星图像的统一自监督编码器。 （arXiv：2312.02199v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02199</link>
      <description><![CDATA[大型、自我监督的视觉模型已经带来了显着的进步
自动解释自然图像。近期作品已开始剪裁
这些方法对具有丰富结构的遥感数据
多传感器、多光谱和时间信息提供海量
可用于自我监督预训练的大量自标记数据。
在这项工作中，我们开发了一种名为 USat 的新编码器架构，它可以输入
来自多个传感器的多光谱数据用于自我监督预训练。
USat 是一个视觉转换器，具有修改后的补丁投影层和
位置编码来模拟具有不同空间尺度的光谱带
多个传感器。我们将 USAt 集成到掩码自动编码器 (MAE) 中
自监督预训练程序并发现预训练的 USAt
优于在远程训练的最先进的自监督 MAE 模型
多个遥感基准数据集的传感数据（高达 8%）和线索
改善低数据状况（高达 7%）。代码和预训练权重
可在 https://github.com/stanfordmlgroup/USat 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.02199</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>零样本组合学习的快速调整。 （arXiv：2312.02191v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02191</link>
      <description><![CDATA[众所周知，开放世界组合零样本学习（OW-CZSL）是一种
极具挑战性的任务，旨在识别形成的看不见的成分
来自所见的属性和对象，无需事先假设输出
空间。为了实现这一目标，模型必须“智能”并且
“知识渊博”。为了变得聪明，模型应该善于推理
所看到的组合中的属性和对象之间的相互作用。尽管
“知识渊博”意味着模型对开放世界拥有“常识”，可以
“预见”未见作品的某些特征。以前的大部分工作重点
在“智能”部分，虽然很少有人提供有效的解决方案
达到“知识渊博”的目标。在本文中，我们提出了一个名为
多模态提示调优（MMPT）继承“知识渊博”的属性
大型预训练视觉语言模型。大量实验表明
我们提出的 MMPT 在 OW-CZSL 任务中获得了新的最先进的结果。上
UT-Zappos 数据集，MMPT 将 AUC 分数推至 $29.8$，而之前的最佳
得分为 26.5 美元。在更具挑战性的 MIT-States 数据集上，AUC 得分为
MMPT 比当前最先进的技术好 1.5 倍。
]]></description>
      <guid>http://arxiv.org/abs/2312.02191</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>DiverseDream：具有增强文本嵌入的多样化文本到 3D 合成。 （arXiv：2312.02192v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02192</link>
      <description><![CDATA[文本到 3D 合成最近已成为一种新的 3D 采样方法
通过采用预训练的文本到图像模型作为指导视觉先验来构建模型。一个
现有文本转 3D 方法的一个有趣但尚未充分探索的问题是
从优化采样过程中获得的 3D 模型往往具有
模式崩溃，因此结果的多样性较差。在本文中，我们
提供分析并确定这种有限多样性的潜在原因，
然后设计一种新方法，考虑不同的联合生成
来自同一文本提示的 3D 模型，我们建议使用增强文本
通过参考图像的文本反转进行提示以使关节多样化
一代。我们证明我们的方法可以提高文本转 3D 的多样性
定性和定量合成。
]]></description>
      <guid>http://arxiv.org/abs/2312.02192</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>局部遮蔽与渐进式冻结的结合：为自我监督学习打造高效的视觉转换器。 （arXiv：2312.02194v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02194</link>
      <description><![CDATA[在本文中，我们提出了一种自我监督学习的创新方法
对于 Vision Transformers (ViTs)，将局部掩模图像建模与
渐进层冻结。该方法侧重于提高效率和
ViT 中初始层训练的速度。通过系统地冷冻特定
在训练期间的战略点上进行分层，我们减少了计算需求
同时保持或提高学习能力。我们的方法采用了
新颖的多尺度重建过程，促进高效学习
初始层并增强跨尺度的语义理解。结果
证明训练时间大幅减少 (~12.5\%)
对模型精度的影响（top-1 精度降低 0.6%）。我们的方法
分别达到 82.6% 和 96.2% 的 top-1 和 top-5 准确率，
强调了它在计算资源和时间有限的场景中的潜力
很关键。这项工作标志着自我监督领域的进步
学习计算机视觉。我们的方法的实施是可用的
在我们项目的 GitHub 存储库：github.com/utkutpcgl/ViTFreeze。
]]></description>
      <guid>http://arxiv.org/abs/2312.02194</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>使用反事实对齐识别虚假相关性。 （arXiv：2312.02186v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02186</link>
      <description><![CDATA[由虚假相关性驱动的模型通常会产生较差的泛化能力
表现。我们提出了反事实对齐方法来检测和
探索黑盒分类器的虚假相关性。反事实图像
针对一个分类器生成的结果可以输入到其他分类器中
看看它们是否也会引起这些分类器输出的变化。这
这些响应之间的关系可以量化并用于识别
存在虚假相关性的特定实例以及计算
数据集的聚合统计数据。我们的工作展示了我们的能力
检测面部属性分类器中的虚假相关性。这是经过验证的
通过观察面部属性分类器的直观趋势以及
制造虚假相关性并检测它们的存在，无论是视觉上
和定量。此外，利用 CF 对齐方法，我们证明了
我们可以纠正分类器中发现的虚假相关性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02186</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>视频摘要：走向实体感知字幕。 （arXiv：2312.02188v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02188</link>
      <description><![CDATA[现有流行的视频字幕基准和模型处理通用问题
标题中不含特定的人、地点或组织命名实体。在
相比之下，新闻视频呈现出一个具有挑战性的背景，其中字幕需要
此类命名实体进行有意义的总结。因此，我们提出任务
将新闻视频直接总结为实体感知的字幕。我们还发布了一个
大型数据集 VIEWS（视频新闻）来支持该任务的研究。
此外，我们提出了一种增强视频视觉信息的方法
从外部世界知识中检索上下文以生成实体感知
字幕。我们通过三个视频展示了我们方法的有效性
字幕模型。我们还表明我们的方法可以推广到现有新闻
图像标题数据集。凭借所有广泛的实验和见解，我们
相信我们为未来研究这一具有挑战性的问题奠定了坚实的基础
任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.02188</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>StableDreamer：驯服嘈杂的乐谱蒸馏采样以实现文本转 3D。 （arXiv：2312.02189v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02189</link>
      <description><![CDATA[在文本到 3D 生成领域，通过以下方式利用 2D 扩散模型
分数蒸馏采样 (SDS) 经常导致诸如模糊等问题
外观和多面几何，主要是由于本质上的噪声
SDS 损失的性质。我们的分析将这些挑战的核心确定为
二维扩散过程中噪声水平之间的相互作用，
扩散网络的架构和 3D 模型表示。到
克服这些限制，我们提出了 StableDreamer，一种方法
融合了三项进步。首先，受到 InstructNeRF2NeRF 的启发，我们
形式化 SDS 生成先验和简单监督的等价性
L2 重建损失。这一发现提供了一种调试 SDS 的新工具，
我们用来展示时间退火噪声水平对降低噪声的影响
多面几何形状。其次，我们的分析表明，虽然图像空间
扩散有助于几何精度，潜在空间扩散至关重要
以获得生动的色彩表现。基于这一观察，StableDreamer 推出
有效结合这些方面的两阶段培训策略，
从而产生高保真 3D 模型。第三，我们采用各向异性3D
高斯表示，取代神经辐射场 (NeRF)，以增强
整体质量，减少训练期间的内存使用，并加速
渲染速度，并更好地捕捉半透明物体。稳定的梦想家
减少多面几何形状，生成精细细节，并稳定收敛。
]]></description>
      <guid>http://arxiv.org/abs/2312.02189</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>扩散手柄：通过将激活提升到 3D 来启用扩散模型的 3D 编辑。 （arXiv：2312.02190v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02190</link>
      <description><![CDATA[扩散手柄是一种在 3D 对象上进行 3D 对象编辑的新颖方法
扩散图像。我们使用现有的预训练完成这些编辑
扩散模型和 2D 图像深度估计，无需任何微调或 3D
对象检索。编辑后的结果仍然可信、真实并保留
对象身份。扩散手柄解决了一个严重缺失的方面
基于生成图像的创意设计，并显着推进
最先进的生成图像编辑。我们的主要见解是提升
使用代理深度将对象的扩散激活转换为 3D，将对象进行 3D 变换
深度和相关的激活，并将它们投影回图像空间。这
扩散过程应用于具有身份控制的操纵激活，
生成合理的编辑图像，显示复杂的 3D 遮挡和照明
影响。我们评估扩散手柄：在大型合成物上进行定量评估
数据基准；并通过用户研究定性地表明我们的输出是
在 3D 编辑和身份方面比现有技术更合理、更好
控制。
]]></description>
      <guid>http://arxiv.org/abs/2312.02190</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>TailorMe：解剖学约束体积人体形状模型的自我监督学习。 （arXiv：2312.02173v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02173</link>
      <description><![CDATA[人体形状空间已被广泛研究，因为它们是核心元素
人体形状和姿势推理任务。创造人类的经典方法
形状模型将表面模板网格注册到 3D 扫描数据库并使用
降维技术，例如主成分分析，
学习紧凑的表示。虽然这些形状模型可以实现全局形状
通过将人体测量结果与所学知识相关联进行修改
子空间，它们仅提供有限的局部形状控制。我们反而
注册一个体积解剖模板，包括骨骼和
软组织、CAESAR 数据库的表面扫描。我们进一步扩大
我们的训练数据为所有骨骼和所有软体的完整笛卡尔积
使用物理上合理的体积变形转移的组织。这个数据
然后用于学习解剖学约束的体积人体形状模型
以自我监督的方式。由此产生的 TailorMe 模型可实现形状
采样、局部形状操作以及给定表面的快速推理
扫描。
]]></description>
      <guid>http://arxiv.org/abs/2312.02173</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>基于单一传感器的活动识别的虚拟融合与对比学习。 （arXiv：2312.02185v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02185</link>
      <description><![CDATA[各种类型的传感器可用于人类活动识别（HAR），
他们每个人都有不同的优点和缺点。有时单个
传感器无法从其角度完全观察用户的动作，这
导致错误的预测。虽然传感器融合提供了更多信息
HAR，它具有许多固有的缺点，例如用户隐私和接受度，
设置、操作和维护成本高昂。为了解决这个问题，我们
提出虚拟融合——一种利用未标记数据的新方法
训练期间来自多个时间同步传感器，但只需要一个
传感器进行推理。采用对比学习来开发
传感器之间的相关性。虚拟融合显着提高了准确性
比使用相同的单个传感器进行训练要好，在某些情况下，它甚至超过了
在测试时使用多个传感器进行实际融合。我们也扩展这个方法
到一个更通用的版本，称为虚拟融合中的实际融合（AFVF），
它在推理过程中使用训练传感器的子集。我们的方法实现了
UCI-HAR 和 PAMAP2 基准上最先进的准确度和 F1 分数
数据集。可根据要求实施。
]]></description>
      <guid>http://arxiv.org/abs/2312.02185</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的分割中的不确定性量化：MRI 中左心室容量估计的事后方法。 （arXiv：2312.02167v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02167</link>
      <description><![CDATA[最近的研究证实心血管疾病仍然是导致
非传染性疾病中死亡人数最高。准确的左心室
(LV) 体积估计对于有效诊断和管理至关重要
各种心血管疾病，但由于以下原因构成了重大挑战
与磁性分割算法相关的固有不确定性
磁共振成像（MRI）。最近的机器学习进展，特别是
类似 U-Net 的卷积网络，促进了自动分割
医学图像，但在某些病理和/或不同的情况下挣扎
扫描仪供应商和成像协议。这项研究提出了一种新颖的方法
使用 It\^{o} 进行 LV 体积预测的事后不确定性估计
随机微分方程 (SDE) 来模拟路径行为
预测错误。该模型描述了左心室沿
心脏的长轴。该方法与底层分割无关
算法，方便其与各种现有和未来的分割一起使用
技术。所提出的方法提供了一种量化机制
不确定性，使医疗专业人员能够干预不可靠的情况
预测。这在关键应用中至关重要，例如
医疗诊断，预测的准确性和可靠性可以直接
影响患者的治疗结果。该方法对于数据集变化也具有鲁棒性，使得
适用于访问标记数据有限的医疗中心的应用程序。我们的
研究结果凸显了所提出的不确定性估计方法的潜力
增强自动分割的鲁棒性和通用性，为
在临床环境中更可靠、更准确地估计 LV 容量的方法
以及为生物医学图像中的不确定性量化开辟新途径
细分，为未来的研究提供了有前景的方向。
]]></description>
      <guid>http://arxiv.org/abs/2312.02167</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>由于分布不匹配，SVHN 数据集对于概率生成模型具有欺骗性。 （arXiv：2312.02168v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02168</link>
      <description><![CDATA[街景门牌号 (SVHN) 数据集是一个流行的基准数据集
在深度学习中。 SVHN 最初是为数字分类任务而设计的
数据集已被广泛用作各种其他任务的基准，包括
生成建模。然而，通过这项工作，我们的目的是警告社区
关于 SVHN 数据集作为生成建模基准的问题
任务：我们发现官方分为训练集和测试集
SVHN 数据集不是从同一分布中得出的。我们凭经验表明
这种分布不匹配对分类任务影响很小
（这可以解释为什么之前没有检测到这个问题），但它
严重影响概率生成模型的评估，例如
变分自动编码器和扩散模型。作为解决方法，我们建议
当SVHN用于任务时混合并重新分割官方训练和测试集
除了分类之外。我们发布了新的分割和我们以前使用的指数
在 https://jzenn.github.io/svhn-remix/ 创建它。
]]></description>
      <guid>http://arxiv.org/abs/2312.02168</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:34 GMT</pubDate>
    </item>
    </channel>
</rss>