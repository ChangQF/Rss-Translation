<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过对比 CutMix 增强来增强长尾识别</title>
      <link>https://arxiv.org/abs/2407.04911</link>
      <description><![CDATA[arXiv:2407.04911v1 公告类型：新 
摘要：现实世界的数据通常遵循长尾分布，其中少数头类占据了大部分数据，而大量尾类仅包含非常有限的样本。在实践中，由于分布不平衡，深度模型在尾类上通常表现出较差的泛化性能。为了解决这个问题，数据增强通过为尾类合成新样本已成为一种有效的方法。其中，一种流行的方法是使用 CutMix，它明确地将尾类和其他类的图像混合在一起，同时根据从两幅图像中裁剪的面积比构建标签。然而，基于区域的标签完全忽略了增强样本的固有语义信息，常常导致误导性的训练信号。为了解决这个问题，我们提出了一种对比 CutMix (ConCutMix)，它构建具有语义一致标签的增强样本，以提高长尾识别的性能。具体来说，我们计算通过对比学习学到的语义空间中样本之间的相似性，并使用它们来纠正基于区域的标签。实验表明，我们的 ConCutMix 显著提高了尾部类别的准确率以及整体性能。例如，基于 ResNeXt-50，我们将 ImageNet-LT 的整体准确率提高了 3.0%，这要归功于尾部类别的 3.3% 的显著提升。我们强调，这种改进也能很好地推广到其他基准和模型。我们的代码和预训练模型可在 https://github.com/PanHaulin/ConCutMix 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.04911</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:23 GMT</pubDate>
    </item>
    <item>
      <title>完成多模态 MRI 分析的特征解缠学习</title>
      <link>https://arxiv.org/abs/2407.04916</link>
      <description><![CDATA[arXiv:2407.04916v1 公告类型：新
摘要：多模态 MRI 在临床诊断和治疗中起着至关重要的作用。基于特征解缠 (FD) 的方法旨在学习用于多模态数据分析的卓越特征表示，已在多模态学习 (MML) 中取得了重大成功。通常，现有的基于 FD 的方法将多模态数据分为模态共享特征和模态特定特征，并使用连接或注意机制来整合这些特征。然而，我们的初步实验表明，当输入包含两种以上的模态时，这些方法可能会导致模态子集之间共享信息的丢失，而这些信息对于预测准确性至关重要。此外，这些方法不能充分解释融合阶段解耦特征之间的关系。为了解决这些限制，我们提出了一种新颖的完全特征解缠 (CFD) 策略，可在特征解耦过程中恢复丢失的信息。具体而言，CFD 策略不仅可以识别模态共享特征和模态特定特征，还可以解耦多模态输入子集之间的共享特征，称为模态部分共享特征。我们进一步引入了一个新的动态混合专家融合 (DMF) 模块，通过明确学习特征之间的局部全局关系，动态集成这些解耦的特征。通过对三个多模态 MRI 数据集的分类任务验证了我们方法的有效性。大量实验结果表明，我们的方法以明显的优势优于其他最先进的 MML 方法，展示了其卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.04916</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:23 GMT</pubDate>
    </item>
    <item>
      <title>可解释的度量学习，用于消除数据偏差</title>
      <link>https://arxiv.org/abs/2407.04866</link>
      <description><![CDATA[arXiv:2407.04866v1 公告类型：新
摘要：图像分类是计算机视觉的重要组成部分，它根据给定标准内的相似性评估将给定的输入图像分配到特定类别。虽然可以通过深度学习模型获得有前途的分类器，但这些方法缺乏可解释性，分类结果很难以人类可理解的方式进行解释。在本文中，我们提出了一个可解释的度量学习框架，该框架构建了图像语义片段的层次结构，以提高可解释性。关键方法涉及自下而上的学习策略，首先训练各个片段的局部度量学习模型，然后将片段组合起来以组成树中的综合度量。具体而言，我们的方法能够基于其中的语义片段对两个图像之间的相似性进行更人性化地测量，这可用于生成新样本以减少训练数据集中的偏差。广泛的实验评估表明，与最先进的方法相比，所提出的方法可以显着提高模型准确性。]]></description>
      <guid>https://arxiv.org/abs/2407.04866</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:22 GMT</pubDate>
    </item>
    <item>
      <title>SID：恶劣条件下自动驾驶的立体图像数据集</title>
      <link>https://arxiv.org/abs/2407.04908</link>
      <description><![CDATA[arXiv:2407.04908v1 公告类型：新
摘要：稳健的感知对于自动驾驶至关重要，尤其是在现实环境中常见的恶劣天气和光照条件下。在本文中，我们介绍了立体图像数据集 (SID)，这是一个大规模立体图像数据集，可捕捉各种具有挑战性的现实环境场景。SID 使用安装在车辆上的 ZED 立体摄像机以 20 Hz 的速率记录，由 27 个序列组成，总计超过 178k 个立体图像对，展示了从晴朗的天空到大雪的条件，在白天、黄昏和夜晚拍摄。该数据集包括天气条件、一天中的时间、位置和道路状况的详细序列级注释，以及相机镜头弄脏的情况，真实地反映了自动导航中的挑战。我们的工作旨在通过呈现开发和测试高级感知算法所必需的高保真立体图像来解决自动驾驶系统研究中的显着差距。这些算法支持在各种天气和光照条件下实现一致、可靠的操作，即使在处理镜头脏污等棘手情况时也是如此。SID 可公开访问：https://doi.org/10.7302/esz6-nv83。]]></description>
      <guid>https://arxiv.org/abs/2407.04908</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:22 GMT</pubDate>
    </item>
    <item>
      <title>神经变量：量化点云几何形状的聚合表示</title>
      <link>https://arxiv.org/abs/2407.04844</link>
      <description><![CDATA[arXiv:2407.04844v1 公告类型：新
摘要：点云是现实生活中物体的流行 3D 表示（例如 LiDAR 和 Kinect），因为它们具有基于表面的几何形状的详细而紧凑的表示。最近的方法通过将基于深度学习的技术与几何保真度指标（例如最佳运输成本（例如，倒角和 Wasserstein 指标））结合在一起来表征点云的几何形状。在本文中，我们提出了一种该领域内的新表面几何表征，即点云的神经可变表示。在这里，表面表示为点云的点位置和切线空间的度量/分布。可变表示不仅通过基于流形的判别量化点云的表面几何形状，而且还量化由于组合乘积空间而导致的表面上微妙的几何一致性。本研究提出了神经可变算法，使用点云上的神经网络及其神经切线核表示来计算两个点云之间的可变范数。所提出的神经可变模型在三个不同的热门任务上进行了评估——形状匹配、少量形状分类和形状重建。详细评估和与最先进方法的比较表明，所提出的多功能神经可变模型在形状匹配和少量形状分类方面表现优异，并且在形状重建方面具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2407.04844</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:21 GMT</pubDate>
    </item>
    <item>
      <title>混合原始草图：结合类比、定性表征和计算机视觉进行场景理解</title>
      <link>https://arxiv.org/abs/2407.04859</link>
      <description><![CDATA[arXiv:2407.04859v1 公告类型：新
摘要：感知的目的之一是在传感器和概念理解之间架起桥梁。Marr 的 Primal Sketch 将初始边缘查找与多个下游过程相结合，以捕捉视觉感知的各个方面，例如分组和立体视觉。鉴于此后人工智能多个领域取得的进展，我们开发了一个受 Marr 的工作启发的新框架，即 Hybrid Primal Sketch，它将计算机视觉组件组合成一个整体，以生成类似草图的实体，然后由我们的高级人类视觉模型 CogSketch 进一步处理，以生成更详细的形状表示和场景表示，可用于通过类比泛化进行数据高效学习。本文介绍了我们的理论框架，总结了之前的几个实验，并概述了正在进行的图表理解新实验。]]></description>
      <guid>https://arxiv.org/abs/2407.04859</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:21 GMT</pubDate>
    </item>
    <item>
      <title>NSD-DIL：使用深度身份学习进行空镜头去模糊</title>
      <link>https://arxiv.org/abs/2407.04815</link>
      <description><![CDATA[arXiv:2407.04815v1 公告类型：新
摘要：在本文中，我们建议重新制定盲图像去模糊任务，以使用深度线性网络直接学习退化模型的逆。我们引入了深度身份学习 (DIL)，这是一种新颖的学习策略，其中包括基于线性系统属性的专用正则化项，以利用退化和逆退化模型之间的身份关系。我们提出的框架的突出之处在于它既不依赖于去模糊数据集，也不依赖于单个输入模糊图像（如自监督方法 Polyblur）。由于它完全独立于图像数据，我们将我们的模型称为使用深度身份学习 (NSD-DIL) 的 Null-Shot 去模糊。我们还以矩阵形式提供了学习到的深度线性网络的显式表示，称为用于去模糊任务的深度恢复核 (DRK)。借助我们的随机核图库 (RKG) 数据集，所提出的框架绕过了大多数现有盲去模糊解决方案中涉及的典型退化核估计步骤。在这项工作中，我们专注于恢复由轻微失焦、镜头模糊或轻微相机运动产生的轻度模糊图像，这些模糊图像经常出现在真实图像中。我们的实验表明，所提出的方法优于传统和基于深度学习的去模糊方法，计算资源至少减少了 100 个数量级。所提出的 NSD-DIL 方法可以毫不费力地扩展到图像超分辨率 (ISR) 任务，以恢复具有精细细节的低分辨率图像。NSD-DIL 模型及其核形式表示 (DRK) 轻量级但稳健，可在几分之一秒内恢复轻度模糊输入。因此，更适合广泛的实时应用。]]></description>
      <guid>https://arxiv.org/abs/2407.04815</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:20 GMT</pubDate>
    </item>
    <item>
      <title>用于域不变点云识别的 3D 自适应结构卷积网络</title>
      <link>https://arxiv.org/abs/2407.04833</link>
      <description><![CDATA[arXiv:2407.04833v1 公告类型：新
摘要：由于数据集和传感器技术的多变性，自动驾驶汽车中点云数据识别的深度学习网络面临挑战，强调需要自适应技术来保持不同条件下的准确性。在本文中，我们介绍了 3D 自适应结构卷积网络 (3D-ASCN)，这是一种用于 3D 点云识别的前沿框架。它结合了 3D 卷积核、结构化树结构和自适应邻域采样，可有效提取几何特征。该方法获得了域不变特征，并在各种点云数据集上表现出稳健、适应性强的性能，确保了跨不同传感器配置的兼容性，而无需调整参数。这凸显了其显着提高自动驾驶汽车技术可靠性和效率的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.04833</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:20 GMT</pubDate>
    </item>
    <item>
      <title>MJ-Bench：你的多模式奖励模型真的可以很好地判断文本到图像的生成吗？</title>
      <link>https://arxiv.org/abs/2407.04842</link>
      <description><![CDATA[arXiv:2407.04842v1 公告类型：新
摘要：虽然 DALLE-3 和 Stable Diffusion 等文本到图像模型正在迅速普及，但它们经常遇到诸如幻觉、偏见以及产生不安全、低质量输出等挑战。为了有效解决这些问题，根据多模态评判者的反馈将这些模型与期望的行为保持一致至关重要。尽管它们很重要，但当前的多模态评判者经常对其能力和局限性进行不充分的评估，这可能会导致错位和不安全的微调结果。为了解决这个问题，我们引入了 MJ-Bench，这是一种新颖的基准，它结合了全面的偏好数据集来评估多模态评判者在四个关键角度为图像生成模型提供反馈的能力：对齐、安全性、图像质量和偏见。具体来说，我们在偏好数据集的每个分解子类别上评估了大量不同的多模态评判器，包括小型基于 CLIP 的评分模型、开源 VLM（例如 LLaVA 系列）和闭源 VLM（例如 GPT-4o、Claude 3）。实验表明，闭源 VLM 通常提供更好的反馈，其中 GPT-4o 的平均表现优于其他评判器。与开源 VLM 相比，小型评分模型可以在文本-图像对齐和图像质量方面提供更好的反馈，而 VLM 由于其更强的推理能力而在安全性和生成偏差方面提供更准确的反馈。进一步对反馈量表的研究表明，VLM 评判器通常可以以自然语言（李克特量表）提供比数值量表更准确和稳定的反馈。值得注意的是，使用这些多模态评判器的单独反馈对端到端微调模型进行的人工评估也得出了类似的结论，进一步证实了 MJ-Bench 的有效性。所有数据、代码、模型均可在 https://huggingface.co/MJ-Bench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.04842</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:20 GMT</pubDate>
    </item>
    <item>
      <title>揭示神经网络中学习子空间的利用等级</title>
      <link>https://arxiv.org/abs/2407.04797</link>
      <description><![CDATA[arXiv:2407.04797v1 公告类型：新
摘要：在这项工作中，我们研究了神经网络学习到的权重如何很好地利用可用的空间。这个概念与容量有关，但还结合了网络架构与数据集的交互。大多数学习到的权重似乎是满秩的，因此不适合低秩分解。这误导性地暗示权重正在利用可用的整个空间。我们提出了一种简单的数据驱动转换，将权重投影到数据和权重交互的子空间上。这保留了层的功能映射并揭示了其低秩结构。在我们的研究结果中，我们得出结论，大多数模型只利用了可用空间的一小部分。例如，对于在 ImageNet 上训练的 ViTB-16 和 ViTL-16，平均层利用率分别为 35% 和 20%。我们的转换将参数分别减少到 50% 和 25%，同时在微调后准确率下降不到 0.2%。我们还表明，自监督预训练将这一利用率提高到 70%，证明了其适用于下游任务。]]></description>
      <guid>https://arxiv.org/abs/2407.04797</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:19 GMT</pubDate>
    </item>
    <item>
      <title>文本到图像扩散模型的无分割指导</title>
      <link>https://arxiv.org/abs/2407.04800</link>
      <description><![CDATA[arXiv:2407.04800v1 公告类型：新
摘要：我们引入了无分割指导，这是一种专为文本到图像扩散模型（如稳定扩散）设计的新方法。我们的方法不需要重新训练扩散模型。无需额外的计算成本，它使用扩散模型本身作为隐含的分割网络，因此称为无分割指导，根据补丁与提示中概念的相关性动态调整生成图像每个补丁的负面提示。我们使用 FID、CLIP、IS 和 PickScore 客观地评估无分割指导，并通过人工评估者主观地评估。对于主观评价，我们还提出了一种在 MS COCO-30K 等数据集中对提示进行子采样的方法，以保持人工评估的数量可控，同时确保所选子集在内容方面具有代表性，在模型性能方面公平。结果证明了我们的无分割指导优于广泛使用的无分类器方法。人类评估者对无分割指导的偏好度为 60%，而对无分类器的偏好度为 19%，其中 18% 的情况表现出强烈的偏好。此外，最近提出的模仿人类偏好的指标 PickScore 胜率也表明，我们的方法比无分类器方法更受青睐。]]></description>
      <guid>https://arxiv.org/abs/2407.04800</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:19 GMT</pubDate>
    </item>
    <item>
      <title>视觉评估人工智能：基于概念的解释和证据权重的假设驱动工具</title>
      <link>https://arxiv.org/abs/2407.04710</link>
      <description><![CDATA[arXiv:2407.04710v1 公告类型：新
摘要：本文介绍了视觉评估人工智能，这是一种决策辅助工具，它从图像数据中为给定的假设提供正面和负面证据。此工具在图像中查找高级人类概念，并在决策过程中为每个假设生成证据权重 (WoE)。我们通过构建一个基于 Web 的应用程序在皮肤癌领域应用和评估此工具，该应用程序允许用户上传皮肤镜图像、选择假设并通过评估提供的证据来分析他们的决策。此外，我们展示了视觉评估人工智能在不同基于概念的解释方法上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.04710</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>MetaFruit 与基础模型的结合：利用综合多水果数据集推进农业基础模型</title>
      <link>https://arxiv.org/abs/2407.04711</link>
      <description><![CDATA[arXiv:2407.04711v1 公告类型：新
摘要：水果采摘给该行业带来了巨大的劳动力和财务负担，凸显了机器人采摘解决方案的进步的迫切需求。基于机器视觉的水果检测已被认为是指导机器人操作的稳健水果识别的重要组成部分。尽管在利用深度学习和机器学习技术进行水果检测方面取得了长足的进步，但一个常见的不足是无法迅速将开发的模型扩展到不同的果园和/或各种水果品种。此外，相关数据的有限可用性进一步加剧了这些挑战。在这项工作中，我们介绍了 MetaFruit，这是最大的公开可用的多类水果数据集，包含 4,248 张图像和 248,015 个手动标记的实例，来自美国不同的果园。此外，本研究提出了一种创新的开放式水果检测系统，利用先进的视觉基础模型 (VFM) 进行水果检测，可以在不同的果园条件下熟练地识别各种水果类型。该系统不仅通过少量学习展示了从极少量数据中学习的出色适应性，还展示了解读人类指令以执行细微检测任务的能力。使用多种指标全面评估了开发的基础模型的性能，其性能优于我们 MetaFruit 数据集和其他开源水果数据集中现有的最先进算法，从而为农业技术和机器人采摘领域树立了新的标杆。MetaFruit 数据集和检测框架是开源的，旨在促进未来基于视觉的水果采摘研究，标志着朝着解决农业部门的迫切需求迈出了重要一步。]]></description>
      <guid>https://arxiv.org/abs/2407.04711</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>自闭症情绪识别的传感技术和机器学习方法：系统评价</title>
      <link>https://arxiv.org/abs/2407.04712</link>
      <description><![CDATA[arXiv:2407.04712v1 公告类型：新
摘要：背景：人类情绪识别 (HER) 是过去几年的热门研究领域。尽管迄今为止取得了巨大进展，但人们对 HER 在自闭症中的应用关注相对较少。众所周知，自闭症患者在日常社交沟通和对情绪反应的原型解释方面面临问题，这些反应最常通过面部表情表现出来。这对常规 HER 系统的应用提出了重大的实际挑战，这些系统通常是为神经正常人开发的。目的：本研究回顾了关于 HER 系统在自闭症中的应用的文献，特别是在传感技术和机器学习方法方面，以确定现有的障碍和可能的未来方向。方法：我们根据 2020 年 PRISMA 指南对 2011 年 1 月至 2023 年 6 月期间发表的文章进行了系统回顾。通过搜索 Web of Science 和 Scopus 数据库来识别手稿。纳入的论文涉及情绪识别、使用传感器和机器学习技术，以及涉及自闭症儿童、青少年或成年人。结果：搜索到 346 篇文章。共有 65 篇出版物符合资格标准并被纳入审查。结论：研究主要使用面部表情技术作为情绪识别方法。因此，摄像机是各项研究中使用最广泛的设备，尽管最近观察到生理传感器的使用呈增长趋势。最常提到的是快乐、悲伤、愤怒、恐惧、厌恶和惊讶。主要使用经典的监督机器学习技术，而牺牲了无监督方法或较新的深度学习模型。]]></description>
      <guid>https://arxiv.org/abs/2407.04712</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>QMViT：一朵蘑菇值 16x16 个单词</title>
      <link>https://arxiv.org/abs/2407.04708</link>
      <description><![CDATA[arXiv:2407.04708v1 公告类型：新
摘要：食用有毒蘑菇会对健康造成严重后果，甚至导致死亡，准确区分可食用和有毒蘑菇品种仍然是确保食品安全的重大挑战。因此，在现有物种中区分可食用和有毒蘑菇至​​关重要。这一点至关重要，因为人们的日常饮食对蘑菇的需求很大，而且它们对医学科学有潜在贡献。这项工作提出了一种新颖的量子视觉变换器架构，利用量子计算来增强蘑菇分类性能。通过使用变分量子电路实现专门的量子自注意机制，所提出的架构分别根据其类别和可食用性实现了 92.33% 和 99.24% 的准确率。这表明所提出的架构在减少有毒蘑菇的假阴性方面取得了成功，从而确保了食品安全。我们的研究强调了 QMViT 在整体上改善蘑菇分类方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.04708</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:17 GMT</pubDate>
    </item>
    </channel>
</rss>