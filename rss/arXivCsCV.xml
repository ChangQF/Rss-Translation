<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 30 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过数据增强对比调节减轻物体幻觉</title>
      <link>https://arxiv.org/abs/2405.18654</link>
      <description><![CDATA[arXiv:2405.18654v1 公告类型：新
摘要：尽管取得了显著进展，但多模态大型语言模型 (MLLM) 往往会产生幻觉，产生事实上不准确的信息。在这项工作中，我们解决了 MLLM 中的对象幻觉问题，其中提供了有关模型输入中不存在的对象的信息。我们引入了一种对比调整方法，可以应用于预先训练的现成 MLLM，以减轻幻觉，同时保留其一般的视觉语言能力。对于给定的事实标记，我们通过选择性地改变基本事实信息，通过生成数据增强来创建幻觉标记。所提出的对比调整应用于标记级别，以提高事实标记与幻觉标记相比的相对可能性。我们的全面评估证实了对比调整在减轻幻觉方面的有效性。此外，所提出的对比调整简单、快速，并且只需要最少的训练，并且在推理时没有额外的开销。]]></description>
      <guid>https://arxiv.org/abs/2405.18654</guid>
      <pubDate>Thu, 30 May 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>三维多视角多目标跟踪的轨迹初始化与重新识别</title>
      <link>https://arxiv.org/abs/2405.18606</link>
      <description><![CDATA[arXiv:2405.18606v1 公告类型：新
摘要：我们提出了一种 3D 多目标跟踪 (MOT) 解决方案，该解决方案仅使用单目摄像机的 2D 检测，可自动启动/终止轨迹以及解决轨迹出现-重现和遮挡问题。此外，这种方法在重新配置摄像机时不需要重新训练检测器，而只需更新重新配置的摄像机的摄像机矩阵。我们的方法基于贝叶斯多目标公式，将轨迹启动/终止、重新识别、遮挡处理和数据关联集成到单个贝叶斯过滤递归中。然而，由于（多对象）过滤密度中的项数呈指数增长，利用所有这些功能的精确过滤器在数值上是难以处理的，而现有的近似值会牺牲其中一些功能来换取速度。为此，我们通过将物体特征和运动学纳入测量模型，开发出一种更适合在线 MOT 的高效近似方法，从而改善数据关联并减少术语数量。具体而言，我们利用来自多个摄像机的 2D 检测和提取特征来提供多物体滤波密度的更好近似，以实现轨迹启动/终止和重新识别功能。此外，结合基于 3D 物体在摄像机平面上的 2D 投影的易处理几何遮挡模型，实现了滤波器的遮挡处理功能。与现有的多视图 MOT 解决方案相比，在具有挑战性的数据集上对所提出的解决方案的评估表明，当摄像机配置动态更改时，该解决方案具有显着的改进和稳健性。源代码可在 https://github.com/linh-gist/mv-glmb-ab 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.18606</guid>
      <pubDate>Thu, 30 May 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>基于小波的视觉变换器图像标记器</title>
      <link>https://arxiv.org/abs/2405.18616</link>
      <description><![CDATA[arXiv:2405.18616v1 公告类型：新
摘要：非重叠的逐块卷积是所有最先进的视觉变换器 (ViT) 模型的默认图像标记器。尽管已经提出了许多 ViT 变体来提高其效率和准确性，但文献中很少有关于改进图像标记器本身的研究。在本文中，我们提出了一种基于小波变换的新型图像标记器。我们表明，使用新标记器的 ViT 模型在 ImageNet 验证集上实现了更高的训练吞吐量和更好的 top-1 精度。我们对所提出的标记器为何在不改变 ViT 模型架构的情况下提高训练吞吐量进行了理论分析。我们的分析表明，新的标记器可以有效处理高分辨率图像，并且天然具有抵抗对抗攻击的能力。此外，所提出的图像标记器为基于 ViT 的模型设计的重要新研究方向提供了新的视角，例如用于图像理解的非均匀网格上的图像标记。]]></description>
      <guid>https://arxiv.org/abs/2405.18616</guid>
      <pubDate>Thu, 30 May 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>基于势场的深度度量学习</title>
      <link>https://arxiv.org/abs/2405.18560</link>
      <description><![CDATA[arXiv:2405.18560v1 公告类型：新
摘要：深度度量学习 (DML) 涉及训练网络以学习语义上有意义的表示空间。许多当前方法挖掘 n 元组示例并模拟每个元组中的交互。我们提出了一种新颖的组合 DML 模型，该模型受到物理学中静电场的启发，它不是以元组的形式，而是用连续势场表示每个示例 (嵌入) 的影响，并将这些场叠加以获得它们的组合全局势场。我们使用吸引/排斥势场来表示来自相同/不同类别图像的嵌入之间的相互作用。与典型的学习方法相反，样本的相互影响与它们的距离成正比，我们强制减少这种影响与距离成正比，从而导致场衰减。我们表明，这种衰减有助于提高具有大量类内变化和标签噪声的真实世界数据集的性能。与其他基于代理的方法一样，我们也使用代理来简洁地表示示例的子群体。我们在三个标准 DML 基准（Cars-196、CUB-200-2011 和 SOP 数据集）上评估了我们的方法，其表现优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2405.18560</guid>
      <pubDate>Thu, 30 May 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>这不是模态差距：描述和解决对比差距</title>
      <link>https://arxiv.org/abs/2405.18570</link>
      <description><![CDATA[arXiv:2405.18570v1 公告类型：新
摘要：多模态对比模型（如 CLIP）通过将输入图像和文本嵌入联合表征空间，在零样本分类中实现了最先进的性能。最近，据报道，在 CLIP 等双编码器对比模型中存在模态差距，这意味着图像和文本嵌入位于潜在空间的不相交区域。先前的研究表明，这种差距的存在是由于 1) 锥体效应、2) 数据集中的不匹配对和 3) 训练不足。我们表明，即使考虑到所有这些因素，即使使用相同的模态，对比损失实际上也会在训练期间产生差距。因此，我们提出模态差距是双编码器对比损失所固有的，并将其重命名为对比差距。我们提出的证据表明，这种对比差距是由于 CLIP 空间的低均匀性造成的，导致嵌入仅占据潜在空间的一小部分。为了缩小差距，我们将单峰对比损失的均匀性和对齐属性调整到多模态设置，并表明只需将这些项添加到 CLIP 损失中，就可以在表示空间中更均匀地分布嵌入，从而缩小差距。在我们的实验中，我们表明修改后的表示空间在下游任务（例如零样本图像分类和多模态算法）中实现了比默认 CLIP 损失更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.18570</guid>
      <pubDate>Thu, 30 May 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>通过保形预测实现逆问题中任务驱动的不确定性量化</title>
      <link>https://arxiv.org/abs/2405.18527</link>
      <description><![CDATA[arXiv:2405.18527v1 公告类型：新
摘要：在成像逆问题中，人们试图从缺失/损坏的测量中恢复图像。由于此类问题属于不适定问题，因此人们强烈希望量化测量和恢复过程中引起的不确定性。受恢复图像用于下游任务（例如软输出分类）的应用的启发，我们提出了一种以任务为中心的不确定性量化方法。具体而言，我们使用共形预测来构建一个区间，该区间保证包含来自真实图像的任务输出，最高可达用户指定的概率，并且我们使用该区间的宽度来量化测量和恢复带来的不确定性。对于基于后验采样的图像恢复，我们构建局部自适应预测区间。此外，我们建议在多轮中收集测量值，一旦任务不确定性降至可接受水平以下，就停止。我们在加速磁共振成像 (MRI) 上展示了我们的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.18527</guid>
      <pubDate>Thu, 30 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型的低秩小样本自适应</title>
      <link>https://arxiv.org/abs/2405.18541</link>
      <description><![CDATA[arXiv:2405.18541v1 公告类型：新
摘要：视觉语言模型 (VLM) 的少样本适应性的最新进展进一步推动了其泛化能力，而代价是目标下游任务中仅有少量标记样本。然而，这些有前途的、已经相当丰富的少样本文献主要集中在提示学习上，在较小程度上集中在适配器上，忽视了参数高效微调 (PEFT) 的最新进展。此外，现有的 VLM 少样本学习方法通​​常依赖于繁重的训练程序和/或精心选择的、特定于任务的超参数，这可能会妨碍它们的适用性。作为回应，我们在 VLM 的少样本学习中引入了低秩适应 (LoRA)，并在 11 个数据集上展示了它的潜力，与当前最先进的基于提示和适配器的方法相比。令人惊讶的是，我们的简单 CLIP-LoRA 方法表现出了显著的改进，同时减少了训练时间，并在所有目标任务（即所有数据集和镜头数量）中保持相同的超参数。当然，我们令人惊讶的结果并没有否定即时学习和基于适配器的研究的潜力。然而，我们相信我们强大的基线可用于评估这些新兴主题在少镜头 VLM 中的进展。]]></description>
      <guid>https://arxiv.org/abs/2405.18541</guid>
      <pubDate>Thu, 30 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>紧凑空间中的对齐：异构架构之间的对比知识提炼</title>
      <link>https://arxiv.org/abs/2405.18524</link>
      <description><![CDATA[arXiv:2405.18524v1 公告类型：新
摘要：知识蒸馏通常用于压缩神经网络，降低推理成本和内存占用。在同质架构的场景中，基于特征的方法已被广泛验证其有效性。然而，在教师和学生模型属于异构架构的情况下，特征表示的固有差异会显著降低这些方法的性能。最近的研究表明，低频成分构成了图像特征的大部分。受此启发，我们提出了一种基于低频成分的对比知识蒸馏 (LFCC) 框架，可显著提高异构架构之间基于特征的蒸馏性能。具体而言，我们设计了一组多尺度低通滤波器来从教师和学生模型中提取中间特征的低频成分，并将它们对齐在紧凑的空间中以克服架构差异。此外，利用师生框架的内在配对特性，我们设计了一个创新的样本级对比学习框架，巧妙地将样本内特征相似性和样本间特征差异的约束重构为对比学习任务。这种策略使学生模型能够利用样本内特征一致性，同时增强不同样本之间特征的区分度。因此，我们的 LFCC 框架准确地捕捉了异构架构中特征表示的共性。对三种架构（CNN、Transformers 和 MLP）的广泛评估和实证分析表明，LFCC 在 ImageNet-1K 和 CIFAR-100 的具有挑战性的基准上取得了优异的表现。所有代码都将公开。]]></description>
      <guid>https://arxiv.org/abs/2405.18524</guid>
      <pubDate>Thu, 30 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>REPARO：具有可区分 3D 布局对齐的组合 3D 资源生成</title>
      <link>https://arxiv.org/abs/2405.18525</link>
      <description><![CDATA[arXiv:2405.18525v1 公告类型：新
摘要：由于偏差和遮挡复杂性，传统的图像到 3D 模型通常难以处理包含多个对象的场景。为了应对这一挑战，我们提出了 REPARO，这是一种从单个图像生成组合 3D 资产的新方法。REPARO 采用两步流程：首先，它从场景中提取单个对象并使用现成的图像到 3D 模型重建它们的 3D 网格；然后，它通过可微分渲染技术优化这些网格的布局，确保场景构图连贯。通过在可微分渲染中集成最佳基于传输的长距离外观损失项和高级语义损失项，REPARO 可以有效恢复 3D 资产的布局。所提出的方法可以显著增强对象独立性、细节准确性和整体场景连贯性。对多对象场景的广泛评估表明，我们的 REPARO 提供了一种全面的方法来应对从单个图像生成多对象 3D 场景的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2405.18525</guid>
      <pubDate>Thu, 30 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>从具有不同脑部疾病和分割方式的 MRI 数据库进行联合学习的可行性和优势</title>
      <link>https://arxiv.org/abs/2405.18511</link>
      <description><![CDATA[arXiv:2405.18511v1 公告类型：新
摘要：多模态 MRI 中脑病变分割的模型通常使用具有预定义 MRI 模态集的单个数据库针对特定病理进行训练，该预定义 MRI 模态集由特定疾病的协议确定。这项工作探讨了以下未解决的问题：使用包含不同脑病理的不同 MRI 模态集和注释的多个数据库来训练模型是否可行？这种联合学习是否会有益于训练期间可用的模态和病理集的表现？它是否能够分析具有不同模态和病理集的新数据库？我们开发和比较了不同的方法，并表明通过对模型和训练框架进行适当、简单和实用的修改，可以获得有希望的结果。我们用 7 个数据库进行了实验，这些数据库包含 5 种类型的脑病理和不同的 MRI 模态集。结果首次证明，对具有不同脑病理和模态集的多模态 MRI 数据库进行联合训练是可行的，并具有实际好处。它使单个模型能够对在各种模态中训练期间遇到的病理进行分割，同时通过后续微调等方式促进对新类型病理的分割。本研究对这一范式的潜力和局限性提供的见解应该有助于指导未来在该方向上的进步。代码和预训练模型：https://github.com/WenTXuL/MultiUnet]]></description>
      <guid>https://arxiv.org/abs/2405.18511</guid>
      <pubDate>Thu, 30 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>TripletMix：用于 3D 理解的三重数据增强</title>
      <link>https://arxiv.org/abs/2405.18523</link>
      <description><![CDATA[arXiv:2405.18523v1 公告类型：新
摘要：数据增强已被证明是增强深度学习模型泛化能力的重要工具，尤其是在传统数据集通常有限的 3D 视觉环境中。尽管之前取得了一些进展，但现有方法主要适用于单模态数据场景，在集成文本、图像和点云的多模态三元组数据的增强方面留下了空白。同时增强所有三种模态可增强多样性并改善跨模态的一致性，从而产生更全面、更强大的 3D 表示。为了解决这一差距，我们提出了 TripletMix，这是一种新颖的方法，用于解决 3D 理解中以前未探索过的多模态数据增强问题。TripletMix 创新地将基于混合的增强原理应用于多模态三元组数据，从而可以保留和优化跨模态连接。我们提出的 TripletMix 结合了特征级和输入级增强，实现了原始数据和潜在特征之间的双重增强，通过确保特征一致性并提供多样化和真实的训练样本，显著提高了模型的跨模态理解和泛化能力。我们证明 TripletMix 不仅可以提高模型在各种学习场景（包括零样本和线性探测分类）中的基线性能，还可以显著提高模型的泛化能力。值得注意的是，我们将 ScanObjectNN 上的零样本分类准确率从 51.3% 提高到 61.9%，将 Objaverse-LVIS 上的零样本分类准确率从 46.8% 提高到 51.4%。我们的研究结果凸显了多模态数据增强在显著推进 3D 物体识别和理解方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.18523</guid>
      <pubDate>Thu, 30 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>面向开放域文本驱动的多人动作合成</title>
      <link>https://arxiv.org/abs/2405.18483</link>
      <description><![CDATA[arXiv:2405.18483v1 公告类型：新
摘要：这项工作旨在从文本描述中生成多个人的自然和多样化的群体运动。虽然单人文本到运动的生成得到了广泛的研究，但从野外提示中合成一个或两个以上主体的运动仍然具有挑战性，这主要是由于缺乏可用的数据集。在这项工作中，我们通过从大规模图像和视频数据集中估计姿势信息来整理人体姿势和运动数据集。我们的模型使用基于变换器的扩散框架，该框架可容纳具有任意数量主体或帧的多个数据集。实验探索了多人静态姿势的生成和多人运动序列的生成。据我们所知，我们的方法是第一个从大量文本提示中生成具有高多样性和保真度的多主体运动序列的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.18483</guid>
      <pubDate>Thu, 30 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>卫星图像中火山骚乱的异常检测</title>
      <link>https://arxiv.org/abs/2405.18487</link>
      <description><![CDATA[arXiv:2405.18487v1 公告类型：新
摘要：卫星图像有可能在火山爆发前探测到火山变形，但尽管大量图像是常规获取的，但只有一小部分包含火山变形事件。人工检查可能会错过这些异常，而使用监督学习建模的自动系统需要适当标记的数据集。为了解决这些问题，本文探讨了在卫星数据上使用无监督深度学习来识别火山变形异常。我们的检测器基于斑块分布建模 (PaDiM)，通过加权距离增强了检测性能，为更深层的特征分配了更大的重要性。此外，我们提出了一种预处理方法来处理嘈杂和不完整的数据点。最终框架在五座具有不同变形特征的火山上进行了测试，并将其性能与用于火山变形检测的监督学习方法进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2405.18487</guid>
      <pubDate>Thu, 30 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>传导式零样本和少样本 CLIP</title>
      <link>https://arxiv.org/abs/2405.18437</link>
      <description><![CDATA[arXiv:2405.18437v1 公告类型：新
摘要：传导推理在小样本图像分类中得到了广泛的研究，但在最近快速发展的关于采用 CLIP 等视觉语言模型的文献中却被完全忽视了。本文解决了传导零样本和小样本 CLIP 分类挑战，其中推理是在一小批未标记的查询样本上联合执行的，而不是单独处理每个实例。我们最初构建了信息丰富的视觉文本概率特征，从而导致单位单纯形集上的分类问题。受期望最大化 (EM) 的启发，我们基于优化的分类目标使用狄利克雷定律为每个类建模数据概率分布。然后使用一种新颖的块 Majorization-Minimization 算法来解决最小化问题，该算法同时估计分布参数和类分配。在 11 个数据集上进行的大量数值实验凸显了我们的批量推理方法的优势和有效性。在包含 75 个样本的零样本测试批次的零样本任务中，我们的方法使 ImageNet 准确率比 CLIP 的零样本性能提高了近 20%。此外，我们在少量样本设置中的表现优于最先进的方法。代码可在以下网址获取：https://github.com/SegoleneMartin/transductive-CLIP。]]></description>
      <guid>https://arxiv.org/abs/2405.18437</guid>
      <pubDate>Thu, 30 May 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>GHOST：基于开放词汇场景和文本上下文的人体运动生成</title>
      <link>https://arxiv.org/abs/2405.18438</link>
      <description><![CDATA[arXiv:2405.18438v1 公告类型：新
摘要：我们的 3D 周围环境与描述它们的描述性语言之间的联系非常适合在上下文中定位和生成人体运动，但有一个问题。多种模态引入的复杂性使得使用一组固定的描述符来捕获这种联系具有挑战性。具体来说，封闭词汇场景编码器需要从头开始学习文本场景关联，这在文献中受到青睐，但通常会导致不准确的运动基础。在本文中，我们提出了一种将开放词汇场景编码器集成到架构中的方法，在文本和场景之间建立稳健的联系。我们的两步方法首先通过从现有的开放词汇语义图像分割模型中进行知识提炼来对场景编码器进行预训练，确保共享的文本场景特征空间。随后，对场景编码器进行微调以生成条件运动，结合两个新的正则化损失，以回归目标对象的类别和大小。与 HUMANISE 数据集上之前最先进的基线模型相比，我们的方法将目标物体距离度量降低了 30%。通过使用我们框架的三种实现和一项感知研究进行的评估，证明了这一改进。此外，我们的方法旨在无缝适应未来的 2D 分割方法，这些方法可提供用于提炼的逐像素文本对齐特征。]]></description>
      <guid>https://arxiv.org/abs/2405.18438</guid>
      <pubDate>Thu, 30 May 2024 06:19:44 GMT</pubDate>
    </item>
    </channel>
</rss>