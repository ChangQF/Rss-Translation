<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Tue, 02 Jan 2024 15:14:44 GMT</lastBuildDate>
    <item>
      <title>使用 MRI 和包含数据的机器学习算法量化胶质母细胞瘤的肿瘤内遗传异质性，以实现精准医疗。 （arXiv：2401.00128v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.00128</link>
      <description><![CDATA[胶质母细胞瘤 (GBM) 是最具侵袭性和致命性的人类癌症之一。
肿瘤内遗传异质性对肿瘤治疗提出了重大挑战
治疗。活检是侵入性的，这促进了非侵入性的发展，
基于 MRI 的机器学习 (ML) 模型可量化肿瘤内遗传
每个患者的异质性。这种能力有很大的前景
实现更好的治疗选择以改善患者的治疗结果。我们提议
一种新颖的弱监督序数支持向量机（WSO-SVM）来预测
使用 MRI 检查每个 GBM 肿瘤内的区域遗传改变状态。 WSO-SVM 是
应用于包含 318 个图像局部活检的独特数据集
来自 74 名 GBM 患者的匹配多参数 MRI。该模型被训练为
预测三个 GBM 驱动基因（EGFR、
PDGFRA和PTEN）基于从相应区域提取的特征
五幅 MRI 对比图像。为了进行比较，各种现有的 ML 算法
也被应用。比较各基因的分类准确率
不同算法之间。 SHapley 加法解释 (SHAP)
方法进一步应用于计算不同对比度的贡献分数
图片。最后，使用训练好的WSO-SVM生成预测图
在每位患者的肿瘤区域内，以帮助可视化肿瘤内
遗传异质性。这项研究证明了使用 MRI 和
WSO-SVM 可实现肿瘤内区域遗传的无创预测
每个 GBM 患者的改变，可以为未来的适应性治疗提供信息
个体化肿瘤学。
]]></description>
      <guid>http://arxiv.org/abs/2401.00128</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:44 GMT</pubDate>
    </item>
    <item>
      <title>突破界限：利用大型多模态模型探索零样本对象分类。 （arXiv：2401.00127v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00127</link>
      <description><![CDATA[$$语言和视觉模型的协同作用催生了大语言
和视觉助手模型（LLVA），旨在让用户参与丰富的活动
对话体验与基于图像的查询交织在一起。这些
全面的多模态模型将视觉编码器与大型
语言模型 (LLM)，扩展其在通用领域的应用
语言和视觉理解。大型多模式模型 (LMM) 的出现
预示着人工智能 (AI) 援助的新时代，扩展了
人工智能应用的视野。本文对 LMM 采取了独特的视角，
探索它们在执行图像分类任务中的功效
为特定数据集设计的定制提示。我们还调查了 LLVA
零样本学习能力。我们的研究包括基准分析
跨越四个不同的数据集：MNIST、Cats Vs。狗、膜翅目（蚂蚁与蜜蜂）、
以及包含 Pox Vs 的非常规数据集。非痘皮肤图像。这
我们的实验结果证明了该模型的卓越性能，
实现了 85\%、100\%、77\% 和 79\% 的分类准确率
各自的数据集，无需任何微调。为了支持我们的分析，我们评估
模型的性能针对特定任务进行微调。在一个例子中，
对包含儿童面部图像的数据集进行微调
有和没有自闭症。在微调之前，模型演示了测试
准确率达到 55\%，微调后显着提高到 83\%。这些
结果，加上我们之前的发现，强调了变革性的
LLVA 的潜力及其在现实场景中的多功能应用。
]]></description>
      <guid>http://arxiv.org/abs/2401.00127</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:43 GMT</pubDate>
    </item>
    <item>
      <title>生成增强的负例以训练基于语言的物体检测器。 （arXiv：2401.00094v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00094</link>
      <description><![CDATA[基于语言的开放词汇对象检测的最新进展可以
很大程度上归因于找到利用大规模数据的更好方法
自由格式的文本注释。用判别性训练这样的模型
目标函数已被证明是成功的，但需要良好的积极和
负样本。然而，自由形式的性质和开放词汇
对象描述使否定的空间变得非常大。之前的作品
随机采样负片或使用基于规则的技术来构建它们。在
相比之下，我们建议利用现代中内置的大量知识
生成模型自动构建与以下内容更相关的负片
原始数据。具体来说，我们使用大型语言模型来生成
负文本描述以及文本到图像的扩散模型也可以生成
相应的负像。我们的实验分析证实了相关性
生成的负数据及其在基于语言的检测器中的使用
提高了两个复杂基准测试的性能。
]]></description>
      <guid>http://arxiv.org/abs/2401.00094</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:42 GMT</pubDate>
    </item>
    <item>
      <title>具有感知损失的扩散模型。 （arXiv：2401.00110v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00110</link>
      <description><![CDATA[用均方误差损失训练的扩散模型往往会生成
不切实际的样本。当前最先进的模型依赖于无分类器
提高样本质量的指导，但其令人惊讶的有效性却并非如此
完全明白了。在本文中，我们证明了
无分类器指导部分源于它是一种隐式形式
感性引导。因此，我们可以直接将感知损失纳入
进行扩散训练以提高样本质量。由于比分匹配
扩散训练中使用的目标与去噪非常相似
用于感知网络无监督训练的自动编码器目标，
扩散模型本身是一个感知网络，可以用来生成
有意义的知觉损失。我们提出了一个新颖的自我感知目标
结果是扩散模型能够生成更真实的样本。为了
条件生成，我们的方法只提高了样本质量，而没有
与条件输入纠缠，因此不会牺牲样本
多样性。我们的方法还可以提高无条件样本的质量
生成，这在以前的无分类器指导下是不可能的。
]]></description>
      <guid>http://arxiv.org/abs/2401.00110</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:42 GMT</pubDate>
    </item>
    <item>
      <title>LLM-Assist：通过基于语言的推理增强闭环规划。 （arXiv：2401.00125v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.00125</link>
      <description><![CDATA[虽然规划是自动驾驶堆栈的重要组成部分，
研究人员尚未开发出能够
安全地处理各种可能的驾驶场景。学习为本
规划者遭受过度拟合和长尾性能不佳的困扰。在另一
另一方面，基于规则的规划器概括得很好，但可能无法处理场景
需要复杂的驾驶操作。为了解决这些限制，我们
研究利用常识推理的可能性
GPT4 和 Llama2 等大型语言模型 (LLM) 的功能
制定自动驾驶车辆计划。我们特别开发了一部小说
结合利用传统的基于规则的规划器的混合规划器
与基于法学硕士的规划师。以法学硕士常识推理能力为指导，
我们的方法可以应对现有规划者难以应对的复杂场景，
产生合理的输出，同时通过工作保持脚踏实地
与基于规则的方法一起。通过对 nuPlan 的广泛评估
基准，我们实现了最先进的性能，超越了所有现有的
涵盖大多数指标的纯粹基于学习和规则的方法。我们的代码将是
可以在 https://llmassist.github.io 上找到。
]]></description>
      <guid>http://arxiv.org/abs/2401.00125</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:42 GMT</pubDate>
    </item>
    <item>
      <title>适用于任意感兴趣区域的基于粒子的形状建模。 （arXiv：2401.00067v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00067</link>
      <description><![CDATA[统计形状模型（SSM）是一种定量分析方法
解剖结构的形态变化。这些分析常常
需要在感兴趣的目标解剖区域建立模型以集中注意力
关于具体的形态特征。我们提出了基于粒子的扩展
形状建模 (PSM) 是一种广泛使用的 SSM 框架，允许形状建模
任意感兴趣区域。定义感兴趣区域的现有方法
计算成本昂贵并且具有拓扑限制。讲话
针对这些缺点，我们使用网格场来定义自由形式约束，这
允许在形状表面上划定任意感兴趣区域。
此外，我们在模型优化中添加了二次惩罚方法
能够以计算效率执行任意组合
切割平面和自由形式约束。我们证明了以下方法的有效性
该方法在一个具有挑战性的合成数据集和两个医学数据集上进行。
]]></description>
      <guid>http://arxiv.org/abs/2401.00067</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:41 GMT</pubDate>
    </item>
    <item>
      <title>体育场景下的大规模重识别分析：到达临界点的背叛。 （arXiv：2401.00080v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00080</link>
      <description><![CDATA[重新识别超长跑比赛的参与者可以
由于距离遥远和不断变化的地形而令人畏惧。到
克服这些挑战，计算机视觉技术已经发展到
分析跑步者的面孔、号码布上的号码和服装。然而，我们的研究
提出了一种新颖的基于步态的跑步者重新识别（re-ID）方法
利用各种预先训练的人类动作识别（HAR）模型和损失
功能。我们的结果表明，这种方法为以下方面提供了有希望的结果：
重新识别超长跑比赛中的跑步者。此外，我们
研究运动员在运动时不同人体动作的重要性
接近其耐力极限及其对 re-ID 的潜在影响
准确性。我们的研究调查了跑步者步态的识别如何受到影响
比赛的临界点（CP），定义为严重疲劳的时刻
距离终点线仅几公里的地方
从这个位置。我们的目标是确定这个 CP 如何提高准确度
运动员重新识别。我们的实验结果表明步态识别可以
随着运动员接近，显着增强（mAP 增加高达 9%）
这点。这凸显了利用步态识别的潜力
现实场景，例如超距离比赛或长时间比赛
监视任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.00080</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:41 GMT</pubDate>
    </item>
    <item>
      <title>对比世界模型的泛化属性。 （arXiv：2401.00057v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.00057</link>
      <description><![CDATA[最近关于以对象为中心的世界模型的工作旨在分解表示
就完全无监督或自我监督的方式的对象而言。
假设这样的世界模型是解决问题的关键组成部分
泛化问题。虽然自我监督的表现有所改善
然而，OOD 泛化尚未经过系统和明确的测试。
在本文中，我们对泛化性质进行了广泛的研究
对比世界模型。我们在多种条件下系统地测试该模型
不同的 OOD 泛化场景，例如外推到新对象
属性，引入新的连词或新的属性。我们的实验
表明对比世界模型无法在不同的情况下进行推广
OOD 测试和性能下降取决于
样品是 OOD。当可视化过渡更新和卷积时
特征映射中，我们观察到对象属性的任何变化（例如
以前未见过的颜色、形状或颜色和形状的结合）中断
降低对象表示的因式分解。总体而言，我们的工作亮点
以对象为中心的表示对于泛化和当前的重要性
模型学习所需表示的能力有限
人类层面的概括。
]]></description>
      <guid>http://arxiv.org/abs/2401.00057</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:40 GMT</pubDate>
    </item>
    <item>
      <title>加速新型金属合金 3D 打印工艺开发。 (arXiv:2401.00065v1 [cond-mat.mtrl-sci])</title>
      <link>http://arxiv.org/abs/2401.00065</link>
      <description><![CDATA[解决 3D 打印质量的不确定性和可变性
金属可以进一步促进这项技术的广泛使用。流程图
新合金对于确定最佳工艺参数至关重要
始终如一地产生可接受的印刷质量。流程图通常是
通过常规方法进行并用于实验设计和
打印部件的异位表征。另一方面，在原地
方法是有限的，因为它们可观察到的特征是有限的，而且它们
需要复杂的高成本设置来获得温度测量值以提高
准确性。我们的方法通过结合时间来放松这些限制
使用视频了解激光-金属相互作用期间熔融金属动力学的特征
视觉变压器和高速成像。我们的方法可以用于
现有的商用机器，并可以提供现场流程图，以实现高效
缺陷和变异性量化。该方法的普适性是
通过对不同合金的跨数据集评估来证明
成分和固有热流体特性。
]]></description>
      <guid>http://arxiv.org/abs/2401.00065</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:40 GMT</pubDate>
    </item>
    <item>
      <title>6D-Diff：6D 物体姿态估计的关键点扩散框架。 （arXiv：2401.00029v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00029</link>
      <description><![CDATA[从单个 RGB 图像估计 6D 物体姿态通常会涉及噪声
以及由于遮挡和杂乱等挑战而导致的不确定性
背景。与此同时，扩散模型在以下方面表现出了吸引人的表现：
从具有高度不确定性的随机噪声生成高质量图像
通过逐步去噪。受到其去噪能力的启发，我们
提出一种新颖的基于扩散的框架（6D-Diff）来处理噪声和
物体姿态估计的不确定性以获得更好的性能。在我们的
框架，为了建立准确的 2D-3D 对应关系，我们制定 2D
关键点检测作为反向扩散（去噪）过程。为了方便
这样的去噪过程，我们设计了基于 Mixture-of-Cauchy 的前向扩散
处理并条件化对象特征的逆过程。广泛的
LM-O 和 YCB-V 数据集上的实验证明了我们的有效性
框架。
]]></description>
      <guid>http://arxiv.org/abs/2401.00029</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:39 GMT</pubDate>
    </item>
    <item>
      <title>离散配电网络。 （arXiv：2401.00036v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00036</link>
      <description><![CDATA[我们引入了一种新颖的生成模型，即离散分销网络
（DDN），使用分层离散来近似数据分布
分布。我们假设，由于网络中的特征本质上
包含分布信息，将网络从单一输出中解放出来
同时生成多个样本被证明是非常有效的。
因此，DDN 通过以下方式拟合目标分布，包括连续分布：
生成多个离散样本点。为了捕捉更精细的细节
目标数据，DDN选择最接近Ground Truth（GT）的输出
来自第一层生成的粗略结果。这个选定的输出是
然后反馈到网络作为第二层的条件，从而
生成与 GT 更相似的新输出。随着DDN层数
增加，输出的表示空间呈指数扩展，并且
生成的样本变得越来越类似于 GT。这种分层的
离散分布的输出模式赋予 DDN 两个有趣的特性
属性：高度压缩的表示和更通用的零样本
有条件的生成。我们展示了 DDN 的功效和这些有趣的
通过在 CIFAR-10 和 FFHQ 上进行实验来确定其特性。
]]></description>
      <guid>http://arxiv.org/abs/2401.00036</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:39 GMT</pubDate>
    </item>
    <item>
      <title>具有可学习离散小波变换的高效多尺度网络，用于盲运动去模糊。 （arXiv：2401.00027v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00027</link>
      <description><![CDATA[从粗到精的方案广泛应用于传统的单图像运动
去模糊；然而，在深度学习的背景下，现有的多尺度
算法不仅需要使用复杂的模块来进行特征融合
低尺度RGB图像和深层语义，也可以手动生成
没有足够置信度的低分辨率图像对。在这个
工作中，我们提出了一个基于单输入的多尺度网络
用于运动去模糊的多输出（SIMO）。这简化了复杂性
基于从粗到细方案的算法。减轻修复体缺陷
影响使用多尺度架构带来的详细信息，
我们将现实世界模糊轨迹的特征与
可学习的小波变换模块专注于方向连续性和
模糊图像之间逐步过渡的频率特征
清晰的图像。总之，我们提出了一个具有可学习的多尺度网络
离散小波变换（MLWNet），展示了最先进的
在多个真实世界的去模糊数据集上的性能
主观和客观质量以及计算效率。
]]></description>
      <guid>http://arxiv.org/abs/2401.00027</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:38 GMT</pubDate>
    </item>
    <item>
      <title>OCR 缩放定律的实证研究。 （arXiv：2401.00028v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.00028</link>
      <description><![CDATA[模型大小、数据量、计算量和模型性能的规律
自然语言处理（NLP）领域得到了广泛的研究。
然而，光学字符识别 (OCR) 中的缩放法则尚未制定
被调查。为了解决这个问题，我们进行了全面的研究
涉及检查性能和模型规模之间的相关性，
文本识别领域的数据量和计算。综上所述，
研究证明了性能和模型大小之间的平滑幂律，如
当其他影响因素保持不变时，以及训练数据量。
此外，我们还构建了一个名为 REBU-Syn 的大规模数据集，该数据集
包括 600 万个真实样本和 1800 万个合成样本。基于我们的
缩放定律和新数据集，我们已经成功训练了场景文本
识别模型，在 6 个常见测试基准上达到新的最先进水平
top-1 平均准确率为 97.42%。
]]></description>
      <guid>http://arxiv.org/abs/2401.00028</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:38 GMT</pubDate>
    </item>
    <item>
      <title>资源有限的乳腺癌 Ki67 指数自动估计。 (arXiv:2401.00014v1 [q-bio.QM])</title>
      <link>http://arxiv.org/abs/2401.00014</link>
      <description><![CDATA[肿瘤进展和化疗反应的预测已被证实
最近解决了利用肿瘤浸润淋巴细胞（TIL）和
核蛋白Ki67作为预后因素。最近，深度神经网络
（DNN）已被证明在估计 Ki67 表达和
同时测定乳腺癌细胞的瘤内 TIL 评分。
然而，在过去的十年里，深度学习所带来的非凡进步
模型的激增至少与其资源需求一样多。过高的
查询（在某些情况下还存储）深度数据所需的计算成本
模型在资源有限的环境中表现出强烈的局限性，例如
基于物联网的应用程序为医护人员提供支持。为此，我们建议
用于有效估计百分比的资源消耗感知 DNN
Ki67 阳性细胞在乳腺癌筛查中的应用我们的方法减少到
内存和磁盘空间使用率分别为 75% 和 89%，高达 1.5 倍
能源消耗，并保持或提高了整体精度
最先进的解决方案基准。受到这些积极成果的鼓舞，我们
开发并构建了所采用的框架，以使其总体
目的使用，以及支持其使用的公共软件存储库。
]]></description>
      <guid>http://arxiv.org/abs/2401.00014</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:37 GMT</pubDate>
    </item>
    <item>
      <title>用于政策学习的任意点轨迹建模。 （arXiv：2401.00025v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2401.00025</link>
      <description><![CDATA[从演示中学习是教授机器人新知识的有效方法
技能和更多的示范数据通常可以改善政策学习。然而，
收集示范数据的高昂成本是一个重大瓶颈。
视频作为丰富的数据源，包含行为、物理和
语义，但从中提取特定于控制的信息具有挑战性
由于缺乏动作标签。在这项工作中，我们引入了一个新颖的框架，
任意点轨迹建模 (ATM)，利用视频演示
预训练轨迹模型来预测任意物体的未来轨迹
视频帧内的点。经过训练后，这些轨迹会提供详细的
控制指导，使学习强大的视觉运动策略成为可能
最少的动作标记数据。我们的方法的有效性得到了证明
130 个模拟任务，重点是语言条件操作任务。
可视化和代码可在以下位置获取：
\url{https://xingyu-lin.github.io/atm}。
]]></description>
      <guid>http://arxiv.org/abs/2401.00025</guid>
      <pubDate>Tue, 02 Jan 2024 15:14:37 GMT</pubDate>
    </item>
    </channel>
</rss>