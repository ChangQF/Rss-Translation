<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 01 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>ViewFusion：通过插值去噪实现多视图一致性</title>
      <link>https://arxiv.org/abs/2402.18842</link>
      <description><![CDATA[arXiv:2402.18842v1 公告类型：新
摘要：通过扩散模型的新视图合成已显示出生成多样化和高质量图像的巨大潜力。然而，这些流行方法中图像生成的独立过程给维持多视图一致性带来了挑战。为了解决这个问题，我们引入了 ViewFusion，这是一种新颖的免训练算法，可以无缝集成到现有的预训练扩散模型中。我们的方法采用自回归方法，隐式地利用先前生成的视图作为下一个视图生成的上下文，确保新颖视图生成过程中强大的多视图一致性。通过通过插值去噪融合已知视图信息的扩散过程，我们的框架成功地将单视图条件模型扩展为在多视图条件设置中工作，而无需任何额外的微调。大量的实验结果证明了 ViewFusion 在生成一致且详细的新颖视图方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.18842</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>用于 3D 人体姿势估计和网格恢复的深度学习：一项调查</title>
      <link>https://arxiv.org/abs/2402.18844</link>
      <description><![CDATA[arXiv:2402.18844v1 公告类型：新
摘要：3D 人体姿态估计和网格恢复引起了计算机视觉、自动驾驶和机器人等许多领域的广泛研究兴趣。 3D 人体姿势估计和网格恢复的深度学习最近蓬勃发展，提出了许多方法来解决该领域的不同问题。在本文中，为了激发未来的研究，我们通过深入研究 200 多篇参考文献，全面回顾了过去五年该领域深度学习方法的最新进展。据我们所知，这项调查可以说是第一个全面涵盖 3D 人体姿态估计深度学习方法的调查，包括单人和多人方法，以及人体网格恢复，包括基于显式模型和隐式表示。我们还提供了几个公开数据集的比较结果，以及富有洞察力的观察和启发未来的研究方向。定期更新的项目页面可以在 https://github.com/liuyangme/SOTA-3DHPE-HMR 找到。]]></description>
      <guid>https://arxiv.org/abs/2402.18844</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>跨域人脸反欺骗的梯度对齐</title>
      <link>https://arxiv.org/abs/2402.18817</link>
      <description><![CDATA[arXiv:2402.18817v1 公告类型：新
摘要：人脸反欺骗（FAS）领域泛化（DG）的最新进展引起了广泛关注。传统方法侧重于设计学习目标和附加模块来隔离特定于领域的特征，同时在其表示中保留领域不变的特征。然而，此类方法通常缺乏对域不变特征的一致维护或域特定特征的完全删除的保证。此外，FAS 的 DG 的大多数先前工作并不能确保收敛到局部平坦最小值，这已被证明对 DG 是有利的。在本文中，我们介绍了 GAC-FAS，这是一种新颖的学习目标，它鼓励模型收敛到最佳平坦最小值，而无需额外的学习模块。与传统的锐度感知最小化器不同，GAC-FAS 识别每个域的上升点，并调节这些点的泛化梯度更新，以与经验风险最小化 (ERM) 梯度更新保持一致。这种独特的方法专门指导模型对域转移具有鲁棒性。我们通过对具有挑战性的跨域 FAS 数据集进行严格测试来证明 GAC-FAS 的功效，并在其中建立了最先进的性能。该代码可从 https://github.com/leminhbinh0209/CVPR24-FAS 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.18817</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>去偏见的小说类别发现和本地化</title>
      <link>https://arxiv.org/abs/2402.18821</link>
      <description><![CDATA[arXiv:2402.18821v1 公告类型：新
摘要：近年来，深度学习中的目标检测得到了快速发展。然而，大多数现有的目标检测模型仅在封闭集数据集上表现良好，忽略了训练集中未定义类别的大量潜在目标。这些物体通常被检测器识别为背景或错误地分类为预定义类别。在本文中，我们关注新类别发现和定位（NCDL）这一具有挑战性的问题，旨在训练能够检测训练数据中存在的类别的检测器，同时还主动发现、定位和聚类新类别。我们分析了现有的 NCDL 方法并确定了核心问题：目标检测器往往偏向于可见的目标，这导致忽略不可见的目标。为了解决这个问题，我们首先提出了一种去偏区域挖掘（DRM）方法，该方法以互补的方式结合了类无关区域提议网络（RPN）和类感知 RPN。此外，我们建议通过利用未标记数据的半监督对比学习来改进表示网络。最后，我们采用简单高效的小批量 K 均值聚类方法进行新类发现。我们对 NCDL 基准进行了广泛的实验，结果表明所提出的 DRM 方法显着优于以前的方法，建立了新的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2402.18821</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>基于文本转3D的分数蒸馏采样的定量评估</title>
      <link>https://arxiv.org/abs/2402.18780</link>
      <description><![CDATA[arXiv:2402.18780v1 公告类型：新
摘要：由于在用于图像生成的预训练扩散模型上使用了分数蒸馏采样 (SDS) 方法，从文本提示创建 3D 内容的生成模型的发展取得了长足的进步。然而，SDS 方法也是一些伪影的根源，例如 Janus 问题、文本提示与生成的 3D 模型之间的错位以及 3D 模型不准确。虽然现有方法严重依赖于通过对有限样本集进行目视检查来对这些工件进行定性评估，但在这项工作中，我们提出了更客观的定量评估指标，我们通过人工评级进行交叉验证，并显示对失败案例的分析SDS 技术。我们通过设计一种新颖的计算高效的基线模型来证明这种分析的有效性，该模型在解决所有上述工件的同时，在所提出的指标上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2402.18780</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>OpticalDR：用于隐私保护抑郁症识别的深度光学成像模型</title>
      <link>https://arxiv.org/abs/2402.18786</link>
      <description><![CDATA[arXiv:2402.18786v1 公告类型：新
摘要：抑郁症识别（DR）提出了相当大的挑战，特别是在人们日益关注隐私的背景下。传统的DR技术自动诊断需要使用人脸图像，无疑暴露了患者的身份特征并带来隐私风险。为了减轻与不当披露患者面部图像相关的潜在风险，我们设计了一种新的成像系统，可以擦除捕获的面部图像的身份信息，同时保留与疾病相关的特征。身份信息恢复是不可逆的，同时保留准确 DR 所需的基本疾病相关特征。更具体地说，我们尝试通过可学习的镜头记录去识别的面部图像（尽可能擦除可识别的特征），该镜头结合以下DR任务以及一系列人脸分析相关的辅助任务进行了优化端到端的方式。这些上述策略构成了我们最终的光学深度抑郁识别网络（OpticalDR）。在 CelebA、AVEC 2013 和 AVEC 2014 数据集上的实验表明，我们的 OpticalDR 已经实现了最先进的隐私保护性能，在流行的面部识别模型上平均 AUC 为 0.51，DR 的 MAE/RMSE 为 7.53 的竞争结果AVEC 2013 上的 /8.48 和 AVEC 2014 上的 7.89/8.82 分别。]]></description>
      <guid>https://arxiv.org/abs/2402.18786</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>BFRFormer：基于 Transformer 的现实世界盲脸恢复生成器</title>
      <link>https://arxiv.org/abs/2402.18811</link>
      <description><![CDATA[arXiv:2402.18811v1 公告类型：新
摘要：由于未知且复杂的退化，盲人脸恢复是一项具有挑战性的任务。尽管基于人脸先验的方法和基于参考的方法最近已经证明了高质量的结果，但恢复的图像往往包含过度平滑的结果，并且当退化严重时会丢失身份保留的细节。据观察，这归因于短程依赖性，即卷积神经网络的内在限制。为了对远程依赖性进行建模，我们提出了一种基于 Transformer 的盲脸恢复方法，名为 BFRFormer，以端到端的方式重建具有更多身份保留细节的图像。在 BFRFormer 中，为了消除块效应，开发了小波鉴别器和聚合注意力模块，并自适应地应用谱归一化和平衡一致性调节来分别解决训练不稳定和过拟合问题。大量的实验表明，我们的方法在合成数据集和四个真实数据集上优于最先进的方法。源代码、Casia-Test 数据集和预训练模型发布于 https://github.com/s8Znk/BFRFormer。]]></description>
      <guid>https://arxiv.org/abs/2402.18811</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入翻译进行模型配对，用于开放集分类任务的后门攻击检测</title>
      <link>https://arxiv.org/abs/2402.18718</link>
      <description><![CDATA[arXiv:2402.18718v1 公告类型：新
摘要：后门攻击允许攻击者在机器学习算法中嵌入特定漏洞，当攻击者选择的模式出现时，该漏洞就会被激活，从而导致特定的错误预测。由于需要识别生物识别场景中的后门，我们提出了一种具有不同权衡的新技术。在本文中，我们建议在开放集分类任务中使用模型对来检测后门。使用简单的线性运算将嵌入从探测模型的嵌入空间投影到参考模型的嵌入空间，我们可以比较两个嵌入并计算相似度得分。我们表明，尽管模型具有不同的架构，并在不同的数据集上进行了独立训练，但该分数可以作为后门存在的指标。此外，我们还表明，即使两个模型都存在后门，也可以检测到后门。提供源代码是为了重现性目的。]]></description>
      <guid>https://arxiv.org/abs/2402.18718</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>比较用于减轻类别不平衡影响的基于重要性采样的方法</title>
      <link>https://arxiv.org/abs/2402.18742</link>
      <description><![CDATA[arXiv:2402.18742v1 公告类型：新
摘要：大多数最先进的计算机视觉模型严重依赖于数据。然而，许多数据集表现出极端的类别不平衡，这已被证明会对模型性能产生负面影响。在已探索的训练时间和数据生成解决方案中，利用现有数据的一个子集是重要性采样。这项工作的大量内容主要集中在 CIFAR-10 和 CIFAR-100 数据集上，这些数据集无法代表当前最先进数据集的规模、组成和复杂性。在这项工作中，我们探索并比较了源自重要性采样的三种技术：损失重新加权、欠采样和过采样。具体来说，我们比较了这些技术对两个编码器在一个有影响力的卫星图像数据集（Planet 的亚马逊雨林数据集）上的性能的影响，为另一项工作做准备。此外，我们对场景分类数据集 ADE20K 进行补充实验，以在对比域上进行测试并阐明我们的结果。在这两种类型的编码器中，我们发现增加损失权重和欠采样对代表性不足的类的性能影响可以忽略不计。此外，我们的结果表明，过采样通常可以提高相同代表性不足类别的性能。有趣的是，我们的发现还表明 Planet 数据集中的数据可能存在一些冗余。我们的工作旨在为 Planet 数据集和类似的特定领域数据集的进一步工作提供基础。我们在 https://github.com/RichardZhu123/514-class-imbalance 上开源了我们的代码，以便将来在其他卫星图像数据集上开展工作。]]></description>
      <guid>https://arxiv.org/abs/2402.18742</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>NARUTO：从不确定目标观察中进行神经主动重建</title>
      <link>https://arxiv.org/abs/2402.18771</link>
      <description><![CDATA[arXiv:2402.18771v1 公告类型：新
摘要：我们提出了 NARUTO，一种神经主动重建系统，它将混合神经表示与不确定性学习相结合，实现高保真表面重建。我们的方法利用多分辨率哈希网格作为映射主干，选择它是因为其卓越的收敛速度和捕获高频局部特征的能力。我们工作的核心是结合不确定性学习模块，该模块动态量化重建不确定性，同时积极开展环境改造。通过利用学习到的不确定性，我们提出了一种新颖的不确定性聚合策略，用于目标搜索和有效的路径规划。我们的系统通过针对不确定的观测进行自主探索，并以卓越的完整性和保真度重建环境。我们还通过主动射线采样策略增强 SOTA 神经 SLAM 系统，展示了这种不确定性感知方法的实用性。使用室内场景模拟器对 NARUTO 在各种环境中进行的广泛评估证实了其在主动重建方面的卓越性能和最先进的状态，其在 Replica 和 MP3D 等基准数据集上令人印象深刻的结果就证明了这一点。]]></description>
      <guid>https://arxiv.org/abs/2402.18771</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>人类注意力建模的趋势、应用和挑战</title>
      <link>https://arxiv.org/abs/2402.18673</link>
      <description><![CDATA[arXiv:2402.18673v1 公告类型：新
摘要：近年来，人类注意力模型已被证明不仅对于理解视觉探索背后的认知过程特别有用，而且还可以为旨在解决包括图像和视频处理在内的各个领域的问题的人工智能模型提供支持。 、视觉和语言应用以及语言建模。这项调查对最近将人类注意力机制整合到当代深度学习模型中的努力进行了合理的概述，并讨论了未来的研究方向和挑战。有关正在进行的研究的全面概述，请参阅我们的专用存储库：https://github.com/aimagelab/awesome- human-visual-attention。]]></description>
      <guid>https://arxiv.org/abs/2402.18673</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>视觉实体识别的基础语言模型</title>
      <link>https://arxiv.org/abs/2402.18695</link>
      <description><![CDATA[arXiv:2402.18695v1 公告类型：新
摘要：我们介绍 AutoVER，一种用于视觉实体识别的自回归模型。我们的模型通过采用检索增强约束生成来扩展自回归多模态大语言模型。它可以缓解域外实体的低性能问题，同时在需要视觉情境推理的查询中表现出色。我们的方法通过在没有外部检索器的情况下与序列到序列目标并行地对硬负对进行对比训练来学习区分巨大标签空间中的相似实体。在推理过程中，检索到的候选答案列表通过删除无效的解码路径来明确指导语言生成。所提出的方法在最近提出的 Oven-Wiki 基准测试中跨不同数据集分割实现了显着改进。实体分割的准确率从 32.7% 上升到 61.5%。它还在未见的和查询拆分方面表现出卓越的性能，显着提高了两位数的优势。]]></description>
      <guid>https://arxiv.org/abs/2402.18695</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>用于显着和伪装物体检测及其他的空间相干性损失</title>
      <link>https://arxiv.org/abs/2402.18698</link>
      <description><![CDATA[arXiv:2402.18698v1 公告类型：新
摘要：通用对象检测是一项独立于类别的任务，依赖于对象性的准确建模。大多数相关的基于 CNN 的对象性模型都利用损失函数（例如二元交叉熵），这些函数专注于单一响应，即单个像素的损失响应。受人类视觉系统的启发，人类视觉系统在深入研究语义之前首先识别模糊区域（即硬区域）的边界，我们提出了一种新颖的损失函数，空间相干损失（SCLoss），它使用相邻像素之间的相互响应抑制或强调像素的单一响应。我们证明了所提出的 SCLoss 可以通过检测和强调硬区域的边界来逐渐学习硬区域。通过综合实验，我们证明用 SCLoss 替换流行的损失函数可以提高当前最先进（SOTA）显着或伪装目标检测（SOD 或 COD）模型的性能。我们还证明，将 SCLoss 与其他损失函数相结合可以进一步提高性能，并为不同的应用带来 SOTA 结果。最后，作为其他相关任务的潜在用途的演示示例，我们展示了 SCLloss 在语义分割中的应用。]]></description>
      <guid>https://arxiv.org/abs/2402.18698</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>用于高效蒙版视频建模的运动引导令牌压缩</title>
      <link>https://arxiv.org/abs/2402.18577</link>
      <description><![CDATA[arXiv:2402.18577v1 公告类型：新
摘要：变形金刚的最新发展在增强视频理解方面取得了显着的进步。尽管如此，在处理高维视频时，与注意力机制相关的 O($N^2$) 计算复杂度带来了巨大的计算障碍。当努力提高每秒帧数 (FPS) 以增强动作捕捉能力时，这一挑战变得尤为明显。这种追求可能会引入冗余并加剧现有的计算限制。在本文中，我们首先展示通过提高 FPS 速率所实现的增强性能。此外，我们提出了一种新颖的方法，即运动引导令牌压缩（MGTC），使 Transformer 模型能够利用更小但更具代表性的令牌集来进行全面的视频表示。因此，这会大幅减少计算负担，并保持无缝适应增加的 FPS 速率。具体来说，我们从视频压缩算法中汲取灵感，并仔细检查时间维度上连续视频帧中的补丁之间的差异。然后，表现出低于预定阈值的差异的标记被屏蔽。值得注意的是，这种屏蔽策略有效地解决了视频冗余问题，同时保留了重要信息。我们的实验在经过广泛检查的视频识别数据集 Kinetics-400、UCF101 和 HMDB51 上进行，结果表明，提高 FPS 速率可将 top-1 准确度得分显着提高超过 1.6、1.6 和 4.0。通过实施掩蔽率为 25% 的 MGTC，我们将 Kinetics-400 上的精度进一步提高了 0.1，同时将计算成本降低了 31% 以上。即使在固定的计算预算内，与较低的 FPS 设置相比，较高的 FPS 速率与 MGTC 相结合也能维持性能增益。]]></description>
      <guid>https://arxiv.org/abs/2402.18577</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>用于 SAR 图像中船舶检测的 Wilcoxon 非参数 CFAR 方案</title>
      <link>https://arxiv.org/abs/2402.18579</link>
      <description><![CDATA[arXiv:2402.18579v1 公告类型：新
摘要: 基于各种统计分布的参数恒虚警率（CFAR）检测算法，如高斯分布、伽玛分布、威布尔分布、对数正态分布、G0分布、α稳定分布等，被广泛应用于检测目前SAR图像中的船舶目标。然而SAR图像中的杂波背景复杂多变。当实际杂波背景偏离假设的统计分布时，参数CFAR检测器的性能将会恶化。除了参数CFAR方案之外，还有另一类非参数CFAR检测器，它可以在不假设已知杂波分布的情况下保持目标检测恒定的误报率。在这项工作中，提出并分析了用于SAR图像中船舶检测的Wilcoxon非参数CFAR方案，并提出了用于Wilcoxon非参数检测器确定决策阈值的误报率的闭合形式。通过与Radarsat-2、ICEYE-X6和高分三号SAR图像上的几种典型参数CFAR方案进行比较，揭示了Wilcoxon非参数检测器在不同检测背景下保持良好虚警性能的鲁棒性，并针对波涛汹涌的海面中船舶的脆弱性得到一定程度的改善。此外，Wilcoxon非参数检测器可以在一定程度上抑制旁瓣引起的虚警，且检测速度较快。]]></description>
      <guid>https://arxiv.org/abs/2402.18579</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:37 GMT</pubDate>
    </item>
    </channel>
</rss>