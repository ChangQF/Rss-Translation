<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Mon, 01 Jan 2024 03:15:14 GMT</lastBuildDate>
    <item>
      <title>STanHop：用于记忆增强时间序列预测的稀疏串联 Hopfield 模型。 （arXiv：2312.17346v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.17346</link>
      <description><![CDATA[我们提出了多变量时间的 STanHop-Net（稀疏串联 Hopfield 网络）
具有记忆增强功能的系列预测。在我们的核心
方法是 STanHop，一种新颖的基于 Hopfield 的神经网络模块，
稀疏地学习时间和跨序列表示并将其存储在
依赖数据的时尚。本质上，STanHop 顺序学习时间
使用两个串联稀疏 Hopfield 表示和跨系列表示
层。此外，StanHop 还集成了两个额外的外部存储器
模块：即插即用模块和调谐即用模块，用于无火车和
分别是任务感知记忆增强。它们使 StanHop-Net 能够迅速
对某些突发事件做出反应。在方法论上，我们构造
StanHop-Net 通过以分层方式堆叠 STanHop 块，使得
具有特定于分辨率的稀疏性的多分辨率特征提取。
理论上，我们引入现代 Hopfield 模型的稀疏扩展
（广义稀疏现代霍普菲尔德模型）并表明它赋予了更紧密的
与密集对应物相比，内存检索错误不受影响
内存容量。根据经验，我们验证了我们的框架在以下方面的有效性
合成和现实世界的设置。
]]></description>
      <guid>http://arxiv.org/abs/2312.17346</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>通过消除文本表示中的退化来改善图像恢复。 （arXiv：2312.17334v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17334</link>
      <description><![CDATA[在本文中，我们介绍了改进图像恢复的新视角
通过消除给定降级文本表示中的降级
图像。直观上，文本模态的恢复比图像模态的恢复容易得多。
例如，可以通过删除与退化相关的单词来轻松进行
同时保留内容感知的词语。因此，我们结合了以下优点
详细描述的图像和要执行的降级去除中的文本
恢复。为了解决跨模式援助问题，我们建议绘制
将图像降级为文本表示以消除降级，以及
然后将恢复的文本表示转换为指导图像
协助图像修复。特别是，我们巧妙地嵌入了
图像到文本映射器和文本恢复模块到配备 CLIP 的
文本到图像模型来生成指导。那么我们采用一个简单的
从粗到细的方法动态注入多尺度信息
图像恢复网络指南。进行了大量的实验
各种图像恢复任务，包括去模糊、去雾、去雨等
去噪和一体化图像恢复。结果表明我们的
该方法在所有这些任务中都优于最先进的方法。代码和
模型可在 \url{https://github.com/mrluin/TextualDegRemoval} 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.17334</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>3VL：使用树来教授视觉和语言模型组合概念。 （arXiv：2312.17345v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17345</link>
      <description><![CDATA[事实证明，视觉语言模型 (VLM) 在对齐图像和
文本表示，在传输到时产生卓越的零样本结果
许多下游任务。然而，这些表述受到了一些关键问题的影响
组合语言概念（CLC）理解方面的缺陷，例如
识别对象的属性、状态以及不同对象之间的关系
对象。此外，VLM 通常具有较差的可解释性，使其
调试和减轻构图理解失败具有挑战性。在这个
工作中，我们引入了树增强视觉语言（3VL）模型架构
和训练技术以及我们提出的 Anchor 推理方法和
差异相关性 (DiRe) 可解释性工具。通过扩展文本
使用语言将任意图像-文本对转换为分层树结构
分析工具，3VL 允许将这种结构引入视觉中
模型学习到的表示，增强其可解释性和
组合推理。此外，我们还展示了 Anchor（一种简单的技术）如何
对于文本统一，可以用来过滤干扰因素，同时
提高 CLC 理解性能，例如基本 VL-Checklist
基准。我们还展示了 DiRe 如何执行差异比较
VLM 相关性图之间，使我们能够生成引人注目的可视化
模型成功或失败的原因。
]]></description>
      <guid>http://arxiv.org/abs/2312.17345</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:13 GMT</pubDate>
    </item>
    <item>
      <title>将卷积神经网络与长短时记忆层相结合来预测帕金森病的进展。 (arXiv:2312.17290v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.17290</link>
      <description><![CDATA[帕金森病是一种神经系统疾病，近 1% 的人患有帕金森病
世界人口。该疾病表现为多巴胺下降
生产中，症状是认知和行为的，包括广泛的
性格改变、抑郁症、记忆问题和情绪问题
随着疾病的进展，可能会出现调节失调。早期诊断和
准确的疾病分期对于应用适当的治疗方法至关重要
减缓认知和运动能力下降的治疗方法。

目前，还没有单一的血液测试或生物标志物可用于
诊断帕金森病。磁共振成像已被用于
过去三十年诊断和区分PD和其他疾病
神经系统疾病。然而，近年来出现了新的可能性
出现：已经开发了几种人工智能算法来提高精度和
PD 早期鉴别诊断的准确性。

据我们所知，目前还没有设计出任何人工智能工具来识别所处的阶段
进展。本文旨在填补这一空白。使用“帕金森病
Progression Markers Initiative”数据集，报告患者的 MRI 和
疾病阶段的指示，我们开发了一个模型来识别疾病的水平
进展。图像和相关分数用于训练和
评估不同的深度学习模型。我们的分析区分了四种
基于标准量表的不同疾病进展水平（Hoehn 和 Yah
规模）。最终架构由 3DCNN 网络的级联组成，
采用减少和提取RMI的空间特征
对连续 LSTM 层进行有效训练，旨在对
数据之间的时间依赖性。

我们的结果表明，所提出的 3DCNN + LSTM 模型实现了
通过将 91.90\% 的元素分类为宏，获得最先进的结果
四个类别的平均 OVR AUC
]]></description>
      <guid>http://arxiv.org/abs/2312.17290</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>计算你想要的：野外人类行为的样本识别和小样本计数。 （arXiv：2312.17330v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17330</link>
      <description><![CDATA[本文解决了使用以下方法计算感兴趣的人类行为的任务
来自可穿戴设备的传感器数据。我们提出了一种新颖的基于范例的框架，
允许用户提供他们想要计数的操作示例
发出预定义的声音“一”、“二”和“三”。首先我们的方法
定位音频序列中这些话语的时间位置。这些
立场是识别代表行动的范例的基础
兴趣类别。然后计算样本之间的相似度图
整个传感器数据序列，进一步输入密度估计
模块生成一系列估计密度值。总结这些
密度值提供最终计数。为了开发和评估我们的方法，
我们引入了一个多样化且真实的数据集，其中包含来自真实世界的数据
37 个主题和 50 个动作类别，包含传感器和音频数据。
该数据集上的实验证明了所提出的方法的可行性
计算新类别和主题的动作实例的方法
不是训练数据的一部分。平均而言，两者之间的差异
预测计数与真实值是 7.47，显着低于
基于频率和基于变压器的方法的误差。我们的项目，
代码和数据集可以在 https://github.com/cvlab-stonybrook/ExRAC 找到。
]]></description>
      <guid>http://arxiv.org/abs/2312.17330</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:12 GMT</pubDate>
    </item>
    <item>
      <title>RefineNet：通过分层转换器和渐进式细化，以高分辨率和细节精度增强文本到图像的转换。 （arXiv：2312.17274v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17274</link>
      <description><![CDATA[在这项研究中，我们介绍了RefineNet，这是一种新颖的架构，旨在
解决文本到图像转换系统中的分辨率限制。我们探索
从文本描述生成高分辨率图像的挑战，
专注于细节准确性和计算之间的权衡
效率。 RefineNet 利用分层 Transformer 并结合
渐进式和条件式细化技术，优于现有技术
生成详细和高质量图像的模型。通过广泛
通过对不同数据集的实验，我们证明了RefineNet在以下方面的优越性：
清晰度和分辨率，特别是在动物等复杂图像类别中，
植物、人脸。我们的工作不仅推动了图像到文本领域的发展
转换，而且还为高保真图像生成开辟了新途径
各种应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2312.17274</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>智能解析：从电子商务创意中提取设计语义的自动解析框架。 （arXiv：2312.17283v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17283</link>
      <description><![CDATA[在工业电子商务领域，横幅和广告等创意设计
海报无处不在。从中提取结构化语义信息
创意电商设计素材（设计师手稿）
获取设计语义是智能领域的核心挑战
设计。在本文中，我们提出了一个全面的自动化框架
智能解析创意材料。该框架包括材料
识别、预处理、智能名称和标签层。材质识别
层整合了各种检测和识别接口，涵盖
业务方面包括检测创意内的辅助区域
材料和层级检测以及标签识别。
从算法上来说，它涵盖了各种从粗到精的方法，例如
级联RCNN、GFL等模型。预处理层涉及过滤
创意图层和分级创意材料。 smartname层实现
创意素材智能命名，标签层覆盖
创意素材的多级标签，可以在不同的位置进行标签
等级层次。智能解析构成完整解析
显着帮助下游流程的框架，例如智能
创作、创意优化、素材库建设。内
在苏宁的实际业务应用，显着提升了曝光度，
创意材料的流通量和点击率，加快
创意素材闭环生产，效益丰厚。
]]></description>
      <guid>http://arxiv.org/abs/2312.17283</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>在没有监督的情况下理解深度神经网络中概念的分布式表示。 （arXiv：2312.17285v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17285</link>
      <description><![CDATA[理解深度学习概念的中间表示
学习分类器对于解释一般模型行为是必不可少的。
现有的揭示学到的概念的方法通常依赖于人类的监督，
例如预定义的概念集或细分过程。在本文中，我们
提出一种新的无监督方法来发现分布式表示
通过选择神经元的主要子集来理解概念。我们的实证结果
证明具有相似神经元激活状态的实例倾向于共享
连贯的概念。根据观察结果，所提出的方法选择
构建可解释区域的主要神经元，即松弛区域
决策区域（RDR），包含具有连贯概念的实例
特征空间。它可用于识别数据中未标记的子类
并找出错误分类的原因。此外，适用性
我们跨各个层的方法揭示了不同的分布式
层上的表示，这提供了对层的更深入的了解
深度学习模型的内部机制。
]]></description>
      <guid>http://arxiv.org/abs/2312.17285</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>$\mu$-Net：用于宇宙 μ 子断层扫描的基于 ConvNext 的 U-Net。 （arXiv：2312.17265v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17265</link>
      <description><![CDATA[μ子散射断层扫描利用μ子，通常源自宇宙
光线对密集物体的内部进行成像。但由于通量低
海平面的宇宙射线μ子以及μ子之间高度复杂的相互作用
穿过物质时显示，现有的重建算法
经常遭受低分辨率和高噪声的困扰。在这项工作中，我们开发了一个
新颖的两阶段深度学习算法 $\mu$-Net，由 MLP 组成
预测 μ 子轨迹并使用基于 ConvNeXt 的 U-Net 将
将点分散到体素中。 $\mu$-Net 达到了最先进的水平
1024μ子剂量下PSNR性能为17.14，优于
传统的重建算法，例如最接近点
算法以及最大似然和期望最大化算法。
此外，我们发现我们的方法对各种损坏具有鲁棒性，例如
μ子动量不准确或探测器分辨率有限。我们也
生成并公开发布第一个映射μ介子的大规模数据集
对体素的检测。我们希望我们的研究能够进一步激发
调查深度学习彻底改变该领域的潜力。
]]></description>
      <guid>http://arxiv.org/abs/2312.17265</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>机器人辅助椎板切除手术中基于人工智能的自动椎板切除切割平面规划(arXiv:2312.17266v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.17266</link>
      <description><![CDATA[目的：本研究旨在利用人工智能来实现
椎板切除术的自动规划，并验证该方法。方法：我们提出了一种
自动椎板切除术切割平面规划的两阶段方法。首先
阶段是关键点的识别。 7个关键点手动标注
在每张 CT 图像上。空间金字塔上采样网络（SPU-Net）算法
利用我们研发的精准定位7个关键点。在第二
阶段，基于关键点识别，个性化坐标
为每个椎骨生成系统。最后，横向和
在坐标下生成椎板切除术的纵向切割平面
系统。对规划的总体效果进行了评价。结果：第一名
阶段，SPU-Net 算法在七个阶段的平均定位误差
关键点为0.65mm。第二阶段共进行320次横向切割
该算法规划了 640 个纵向剖切面。之中
其中，A、B、C级水平面规划效果数分别为
分别为 318 个（99.38%）、1 个（0.31%）和 1 个（0.31%）。纵向规划
A、B、C 级的效果分别为 622（97.18%）、1（0.16%）、17（2.66%），
分别。结论：在本研究中，我们提出了一种自动
基于关键点定位的椎板切除手术路径规划
在 CT 图像中。结果表明该方法取得了满意的结果。
需要更多的研究来证实这种方法的可靠性
未来。
]]></description>
      <guid>http://arxiv.org/abs/2312.17266</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>X 模态辅助 RGBT 对象跟踪。 （arXiv：2312.17273v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17273</link>
      <description><![CDATA[学习鲁棒的多模态特征表示对于提升至关重要
跟踪性能。为此，我们提出了一种新颖的 X 模态辅助
网络（X-Net）通过以下方式阐明融合范式的影响
将视觉对象跟踪解耦为三个不同的级别，促进
后续处理。首先，解决特征学习障碍
从 RGB 和热模态之间的显着差异来看，
提出了即插即用像素级生成模块（PGM）
自知蒸馏学习，有效生成 X 模态
弥合双图案之间的间隙，同时减少噪声干扰。
随后，进一步实现最优的样本特征表示和
促进跨模式交互，我们提出了特征级交互
模块（FIM），包含一个混合功能交互变压器和一个
空间维度特征翻译策略。最终随机瞄准
由于缺少实例功能而漂移，我们提出了灵活的在线
称为决策级细化模块（DRM）的优化策略，
包含光流和细化机制。实验进行于
三个基准来验证所提出的 X-Net 是否优于最先进的技术
追踪器。
]]></description>
      <guid>http://arxiv.org/abs/2312.17273</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>TimePillars：时间循环 3D LiDAR 物体检测。 （arXiv：2312.17260v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17260</link>
      <description><![CDATA[应用于 LiDAR 点云的对象检测是一项相关任务
机器人技术，特别是自动驾驶领域。单帧方法，
在该领域占主导地位，利用来自单个传感器扫描的信息。
最近的方法以相对较短的推理时间实现了良好的性能。
然而，鉴于 LiDAR 数据固有的高度稀疏性，这些方法
在我们认为至关重要的长距离检测（例如 200m）方面遇到困难
实现安全自动化。聚合多个扫描不仅会导致
更密集的点云表示，但它也带来了时间意识
系统，并提供有关环境如何变化的信息。
然而，此类解决方案通常是针对特定问题的，需要
仔细的数据处理，往往无法满足运行时要求。在这个
我们提出了 TimePillars，一种时间循环对象检测
利用跨时间激光雷达数据的支柱表示的管道，
尊重硬件集成效率限制，并利用
新颖的 Zenseact 开放数据集 (ZOD) 的多样性和远程信息。
通过实验，我们证明了循环的好处，并展示了
基本构建模块如何足以实现稳健且高效的结果。
]]></description>
      <guid>http://arxiv.org/abs/2312.17260</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>具有解耦数据关联和平滑功能的基于变压器的多对象平滑。 （arXiv：2312.17261v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17261</link>
      <description><![CDATA[多目标跟踪（MOT）是估计状态轨迹的任务
特定时间窗口内未知且随时间变化的对象数量。
已经提出了几种算法来解决多对象平滑问题
任务，其中对象检测可以以所有测量值为条件
时间窗口。然而，性能最好的方法也存在一些棘手的问题
计算复杂性并且需要近似值，在以下方面表现不佳
复杂的设置。基于深度学习的算法是一个可能的场所
解决这个问题，但尚未广泛应用于以下环境
可以获得准确的多目标模型并且可以进行测量
低维。我们提出了一种新颖的深度学习架构，专门针对
此设置将数据关联任务与平滑任务分离。
我们将所提出的平滑器的性能与最先进的技术进行了比较
不同难度的不同任务，并尽我们所能提供
知识，传统贝叶斯跟踪器和深度学习的第一次比较
平滑问题设置中的跟踪器。
]]></description>
      <guid>http://arxiv.org/abs/2312.17261</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>下贝氏体钢和回火马氏体钢的 SEM 图像的语义分割。 （arXiv：2312.17251v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17251</link>
      <description><![CDATA[这项研究采用深度学习技术来分割扫描电子
显微镜图像，能够对碳化物沉淀物进行定量分析
具有相当强度的下贝氏体钢和回火马氏体钢。
分割后，研究碳化物及其体积百分比，
在图像数据集中探测尺寸分布和方向。我们的
研究结果表明，下贝氏体和回火马氏体具有可比性
碳化物的体积百分比，尽管分布更均匀
回火马氏体中的碳化物。下贝氏体中的碳化物表现出
比回火马氏体有更好的排列倾向，与
其他研究人员的观察。然而，两种微观结构都显示出
碳化物方向分散，没有任何可辨别的图案。比较
下贝氏体和回火中碳化物的长径比和尺寸分析
马氏体揭示了惊人的相似之处。深度学习模型实现了
碳化物/铁基体分类的像素精度高达 98.0%
单个像素级别。深度语义分割
学习将其适用性扩展到第二阶段的分析
各种材料，提供省时、多功能的人工智能驱动的工作流程
定量微观结构分析。
]]></description>
      <guid>http://arxiv.org/abs/2312.17251</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>Flying By ML——CNN 仿射变换反转。 （arXiv：2312.17258v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.17258</link>
      <description><![CDATA[本文描述了一种自动读取驾驶舱的机器学习方法
仪表，使用 CNN 进行仿射变换逆变换并推断飞机状态
从仪器图像。使用转弯和银行的合成图像进行验证
指标，本研究介绍了从数据集生成数据集等方法
单图像，最佳无噪声训练的“清洁训练原则”，
以及 CNN 插值，用于根据分类数据进行连续值预测。
它还提供了对超参数优化和机器学习系统软件的见解
工程。
]]></description>
      <guid>http://arxiv.org/abs/2312.17258</guid>
      <pubDate>Mon, 01 Jan 2024 03:15:08 GMT</pubDate>
    </item>
    </channel>
</rss>