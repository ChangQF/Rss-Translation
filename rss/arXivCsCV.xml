<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 13 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>物体级场景去遮挡</title>
      <link>https://arxiv.org/abs/2406.07706</link>
      <description><![CDATA[arXiv:2406.07706v1 公告类型：新
摘要：在场景中去除物体的隐藏部分是一项艰巨的任务，尤其是在处理真实场景时。在本文中，我们提出了一种新的自监督并行可见到完全扩散框架，称为 PACO，这是物体级场景去遮挡的基础模型。利用预先训练模型的丰富先验，我们首先设计并行变分自动编码器，它生成一个同时编码多个完整对象的全视图特征图，以及可见到完全潜在生成器，它学习从输入图像中不完整对象提取的部分视图特征图和文本提示中隐式预测全视图特征图。为了训练 PACO，我们创建了一个包含 500k 个样本的大规模数据集，以实现自监督学习，避免对非模态掩码和遮挡区域进行繁琐的注释。在推理阶段，我们设计了一种逐层去遮挡策略，以提高效率，同时保持去遮挡质量。在 COCOA 和各种真实场景上进行的大量实验表明，PACO 具有出色的场景去遮挡能力，远远超过了现有技术水平。我们的方法还可以扩展到训练集未涵盖的跨域场景和新类别。此外，我们展示了 PACO 在单视图 3D 场景重建和对象重构中的去遮挡适用性。]]></description>
      <guid>https://arxiv.org/abs/2406.07706</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:19 GMT</pubDate>
    </item>
    <item>
      <title>PRISMA 驱动的公开数据集系统评价，用于工业缺陷检测的基准和模型开发</title>
      <link>https://arxiv.org/abs/2406.07694</link>
      <description><![CDATA[arXiv:2406.07694v1 公告类型：新
摘要：各行各业质量控制的最新进展越来越多地利用摄像机和图像处理的集成来有效检测缺陷。阻碍进步的一个关键障碍是缺乏具有注释缺陷的综合数据集，而这些数据集对于开发和改进自动缺陷检测模型至关重要。这项系统性审查涵盖 2015 年至 2023 年，确定了 15 个公开可用的数据集，并对其进行了严格审查，以评估其对基准测试和模型开发的有效性和适用性。我们的研究结果揭示了数据集的多样性，例如 NEU-CLS、NEU-DET、DAGM、KolektorSDD、PCB 缺陷数据集和空心圆柱形缺陷检测数据集，每个数据集在图像质量、缺陷类型表示和实际适用性方面都有独特的优势和局限性。本系统性审查的目标是将这些数据集整合到一个位置，为寻求此类公开资源的研究人员提供全面的参考。]]></description>
      <guid>https://arxiv.org/abs/2406.07694</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>CUPID：基于提示条件的图像分布的上下文理解</title>
      <link>https://arxiv.org/abs/2406.07699</link>
      <description><![CDATA[arXiv:2406.07699v1 公告类型：新
摘要：我们提出 CUPID：一种用于上下文理解提示条件图像分布的可视化方法。CUPID 的目标是对现代文本到图像生成模型产生的分布进行视觉分析，其中用户可以通过自然语言指定场景，模型生成一组图像，每个图像都旨在满足用户的描述。CUPID 旨在帮助理解最终的分布，使用上下文线索来促进分析：提示中提到的对象、未明确提及的新颖的合成对象及其潜在关系。CUPID 的核心是一种可视化高维分布的新方法，其中对象的上下文嵌入（在图像中找到的嵌入）通过基于密度的嵌入映射到低维空间。我们展示了这种嵌入如何允许人们发现分布中对象的显着样式，以及识别异常或罕见的对象样式。此外，我们引入了条件密度嵌入，通过对给定对象的条件化，可以比较分布中的对象依赖性。我们使用 CUPID 分析由大规模扩散模型生成的图像分布，我们的实验结果提供了关于此类模型的语言误解和对象构成偏差的见解，同时还提供了发现典型或罕见合成场景的界面。]]></description>
      <guid>https://arxiv.org/abs/2406.07699</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>基于显著性的模型解释的图形感知</title>
      <link>https://arxiv.org/abs/2406.07702</link>
      <description><![CDATA[arXiv:2406.07702v1 公告类型：新
摘要：近年来，人们投入了大量精力来解释基于深度学习的预测模型，以及如何评估解释。一类重要的评估方法是以人为本的方法，通常需要通过可视化来传达解释。虽然可视化在感知和理解模型解释方面起着关键作用，但可视化设计如何影响人类对解释的感知仍然知之甚少。在这项工作中，我们研究模型解释的图形感知，特别是基于显着性的视觉识别模型解释。我们提出了一个实验设计来研究可视化设计如何影响人类感知，其中我们研究对齐评估任务，或者显着图是否与图像中的对象对齐。我们的研究结果表明，与可视化设计决策、对齐类型和显着图质量相关的因素都在人类如何感知基于显着性的视觉解释方面发挥着重要作用。]]></description>
      <guid>https://arxiv.org/abs/2406.07702</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:18 GMT</pubDate>
    </item>
    <item>
      <title>AV-DiT：用于联合音频和视频生成的高效音频视频扩散变换器</title>
      <link>https://arxiv.org/abs/2406.07686</link>
      <description><![CDATA[arXiv:2406.07686v1 公告类型：新
摘要：最近的扩散变换器 (DiT) 在生成高质量单模态内容（包括图像、视频和音频）方面表现出了令人印象深刻的能力。然而，基于变换器的扩散器是否能够有效地去除高斯噪声以实现出色的多模态内容创建仍未得到充分探索。为了弥补这一差距，我们引入了 AV-DiT，这是一种新颖而高效的视听扩散变换器，旨在生成具有视觉和音频轨道的高质量逼真的视频。为了最大限度地降低模型复杂性和计算成本，AV-DiT 使用在纯图像数据上预先训练的共享 DiT 主干，只有轻量级、新插入的适配器才可训练。这个共享主干有助于音频和视频的生成。具体而言，视频分支将可训练的时间注意层合并到冻结的预训练 DiT 块中以实现时间一致性。此外，少量可训练参数使基于图像的 DiT 块适应音频生成。额外的共享 DiT 块配备了轻量级参数，有助于音频和视觉模态之间的特征交互，从而确保对齐。在 AIST++ 和 Landscape 数据集上进行的大量实验表明，AV-DiT 在联合视听生成中实现了最先进的性能，并且可调参数明显减少。此外，我们的结果强调，具有模态特定适应性的单个共享图像生成主干足以构建联合视听生成器。我们的源代码和预训练模型即将发布。]]></description>
      <guid>https://arxiv.org/abs/2406.07686</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>AI 放射科医生：利用卷积神经网络和临床医生友好的 GUI 彻底改变肝组织分割</title>
      <link>https://arxiv.org/abs/2406.07688</link>
      <description><![CDATA[arXiv:2406.07688v1 公告类型：新
摘要：人工智能 (AI) 是一个普遍的研究课题，渗透到各个领域和应用中。在这项研究中，我们利用人工智能的力量，特别是卷积神经网络 (ConvNets)，来分割肝脏组织。它还专注于开发一个用户友好的图形用户界面 (GUI) 工具“AI 放射科医生”，使临床医生能够有效地描绘不同的肝脏组织（实质、肿瘤和血管），从而挽救生命。这一努力弥合了学术研究与实际工业应用之间的差距。GUI 是一个单页应用程序，使用 PyQt5 Python 框架设计。离线可用的 AI 放射科医生采用三个经过训练的 ConvNet 模型来分割所有肝脏组织。就 Dice 指标而言，最佳肝脏 ConvNet 得分为 98.16%，最佳肿瘤 ConvNet 得分为 65.95%，最佳血管 ConvNet 得分为 51.94%。它输出肝脏、肿瘤和血管的 2D 切片以及 .obj 和 .mtl 格式的 3D 插值，可以使用任何兼容 3D 的软件进行可视化/打印。因此，AI 放射科医生为临床医生提供了一种方便的工具，可以使用最先进的组织分割模型进行肝脏组织分割和 3D 插值。凭借提供的选择体积和预训练模型的能力，临床医生可以将其余的工作留给 AI 放射科医生。]]></description>
      <guid>https://arxiv.org/abs/2406.07688</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:17 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习自动检测和分类路面裂缝</title>
      <link>https://arxiv.org/abs/2406.07674</link>
      <description><![CDATA[arXiv:2406.07674v1 公告类型：新 
摘要：监测资产状况是建立高效运输资产管理的关键因素。由于图像处理的重大进步，传统的手动分类已被半自动/自动技术大量取代。因此，需要自动资产检测和分类技术。本文提出了一种使用著名的 You Only Look Once (YOLO) 第五版 (YOLOv5) 和第八版 (YOLOv8) 算法检测和分类道路路面裂缝的方法。实验结果表明，在不同照明条件和图像大小下，路面裂缝检测的精度高达 67.3%。本研究的结果可以帮助公路机构准确检测和分类不同照明条件下的资产状况。这将减少与人工检查相关的成本和时间，从而大大降低公路资产维护的成本。]]></description>
      <guid>https://arxiv.org/abs/2406.07674</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:16 GMT</pubDate>
    </item>
    <item>
      <title>从上方观察群体动态：无人机视频中高级对象跟踪的框架</title>
      <link>https://arxiv.org/abs/2406.07680</link>
      <description><![CDATA[arXiv:2406.07680v1 公告类型：新
摘要：易于获取的传感器，如带有各种机载传感器的无人机，极大地扩展了对自然环境中动物行为的研究。然而，分析大量未标记的视频数据（通常持续数小时）仍然是机器学习的挑战，尤其是在计算机视觉领域。现有方法通常只分析几帧。我们的重点是长期动物行为分析。为了应对这一挑战，我们利用经典的概率方法进行状态估计，例如粒子滤波。通过结合语义对象分割方面的最新进展，即使在数据可用性有限的场景中，我们也能够持续跟踪快速演变的对象形成。粒子过滤器提供了一种可证明的最佳算法结构，用于递归添加新的传入信息。我们提出了一种从无人机视频中跟踪公海鱼群的新方法。我们的框架不仅在 2D 中执行经典的对象跟踪，而且还通过融合视频数据和无人机的机载传感器信息（GPS 和 IMU）来跟踪鱼群在世界坐标中的位置和空间扩展。该框架首次允许研究人员以非侵入性和可扩展的方式研究鱼群在自然社会和环境背景下的集体行为。]]></description>
      <guid>https://arxiv.org/abs/2406.07680</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:16 GMT</pubDate>
    </item>
    <item>
      <title>M-LRM：多视图大型重建模型</title>
      <link>https://arxiv.org/abs/2406.07648</link>
      <description><![CDATA[arXiv:2406.07648v1 公告类型：新
摘要：尽管大型重建模型 (LRM) 的最新进展取得了令人印象深刻的成果，但当将其输入从单幅图像扩展到多幅图像时，它表现出效率低下、几何和纹理质量不佳以及收敛速度比预期慢。
原因在于，LRM 将 3D 重建公式化为一个简单的图像到 3D 的转换问题，忽略了输入图像之间的强 3D 连贯性。在本文中，我们提出了一种多视图大型重建模型 (M-LRM)，旨在以 3D 感知的方式从多视图高效重建高质量 3D 形状。具体而言，我们引入了一种多视图一致的交叉注意方案，使 M-LRM 能够准确地从输入图像中查询信息。此外，我们使用输入多视图图像的 3D 先验来初始化三平面标记。与 LRM 相比，所提出的 M-LRM 可以生成具有 $128 \times 128$ 分辨率的三平面 NeRF，并生成高保真度的 3D 形状。实验研究表明，我们的模型比 LRM 实现了显着的性能提升和更快的训练收敛。项目页面：https://murphylmf.github.io/M-LRM/]]></description>
      <guid>https://arxiv.org/abs/2406.07648</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:15 GMT</pubDate>
    </item>
    <item>
      <title>ROADWork 数据集：学习识别、观察、分析和穿越工作区</title>
      <link>https://arxiv.org/abs/2406.07661</link>
      <description><![CDATA[arXiv:2406.07661v1 公告类型：新
摘要：即使在自动驾驶研究方面取得了重大进展，感知和穿越工作区仍然具有挑战性且尚未得到充分探索。一个重要原因是缺乏开放数据集来开发新算法来解决这种长尾场景。我们提出了 ROADWork 数据集来学习如何识别、观察、分析和穿越工作区。我们发现最先进的基础模型在工作区上表现不佳。利用我们的数据集，我们在检测工作区物体方面有所改进 (+26.2 AP)，同时以更高的发现率 (12.8 倍) 以更高的精度 (+32.5%) 发现工作区，显著提高检测 (+23.9 AP) 和阅读 (+14.2% 1-NED) 工作区标志和描述工作区 (+36.7 SPICE)。我们还根据工作区导航视频计算可驾驶路径，并表明可以预测导航目标和路径，其中 53.6% 的目标具有角度误差 (AE) &lt; 0.5 度 (+9.9 %)，75.3% 的路径具有 AE &lt; 0.5 度 (+8.1 %)。]]></description>
      <guid>https://arxiv.org/abs/2406.07661</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:15 GMT</pubDate>
    </item>
    <item>
      <title>PLT-D3：用于立体深度和场景流的高保真动态驾驶模拟数据集</title>
      <link>https://arxiv.org/abs/2406.07667</link>
      <description><![CDATA[arXiv:2406.07667v1 公告类型：新
摘要：自动驾驶取得了显著进展，这得益于计算硬件和复杂的深度学习方法的创新。这些进步的基础在于数据集的可用性和质量，这对于开发和改进可靠且多功能的自动驾驶算法至关重要。虽然已经开发了大量数据集来支持自动驾驶感知技术的发展，但很少有数据集能够提供在各种天气条件下彻底测试和增强系统稳健性所需的多样性。许多公共数据集缺乏对具有挑战性的天气场景的全面覆盖和详细的高分辨率数据，而这些数据对于训练和验证先进的自动驾驶感知模型至关重要。在本文中，我们介绍了 PLT-D3；一种动态天气驾驶数据集，专门用于增强自动驾驶系统对各种天气条件的适应性。 PLT-D3 提供使用虚幻引擎 5 生成的高保真立体深度和场景流地面实况数据。具体来说，该数据集包括同步高分辨率立体图像序列，可复制各种动态天气场景，包括雨、雪、雾和各种光照条件，在基于模拟的测试中提供前所未有的真实感。PLT-D3 的主要目的是解决能够模拟真实天气变化的综合训练和测试资源的稀缺问题。已经使用 PLT-D3 为几项关键的自动驾驶任务建立了基准，例如深度估计、光流和场景流，以衡量和提高最先进模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.07667</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:15 GMT</pubDate>
    </item>
    <item>
      <title>BrainChat：使用视觉语言预训练模型从 fMRI 解码语义信息</title>
      <link>https://arxiv.org/abs/2406.07584</link>
      <description><![CDATA[arXiv:2406.07584v1 公告类型：新
摘要：语义信息对于人类交互至关重要，从大脑活动中解码语义信息可以实现非侵入性临床增强和替代交流。虽然在重建视觉图像方面取得了重大进展，但很少有研究关注语言方面。为了解决这一差距，利用基于解码器的视觉语言预训练模型 CoCa 的强大功能，本文提出了 BrainChat，这是一个简单而有效的生成框架，旨在快速完成从大脑活动中解码语义信息的任务，包括 fMRI 问答和 fMRI 字幕。BrainChat 采用 Masked Brain Modeling 的自监督方法对稀疏 fMRI 数据进行编码，从而在潜在空间中获得更紧凑的嵌入表示。随后，BrainChat 通过应用对比损失来弥合模态之间的差距，从而产生 fMRI、图像和文本嵌入的对齐表示。此外，fMRI 嵌入通过交叉注意层映射到生成式大脑解码器，在那里它们通过最小化字幕损失以回归方式指导有关 fMRI 的文本内容的生成。从经验上看，BrainChat 在 fMRI 字幕任务中的表现超过了现有的最先进方法，并首次实现了 fMRI 问答。此外，BrainChat 非常灵活，无需图像数据即可实现高性能，使其更适合数据有限的现实场景。]]></description>
      <guid>https://arxiv.org/abs/2406.07584</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:14 GMT</pubDate>
    </item>
    <item>
      <title>SSNVC：具有隐式时间信息的单流神经视频压缩</title>
      <link>https://arxiv.org/abs/2406.07645</link>
      <description><![CDATA[arXiv:2406.07645v1 公告类型：新 
摘要：最近，神经视频压缩（NVC）技术取得了显著的性能，甚至超越了最好的传统有损视频编解码器。然而，现有的大多数NVC方法严重依赖传输运动矢量（MV）来生成准确的上下文特征，这有以下缺点。（1）压缩和传输MV需要专门的MV编码器和解码器，这使得模块冗余。（2）由于MV编码器-解码器的存在，训练策略很复杂。在本文中，我们提出了一种新颖的单流NVC框架（SSNVC），它消除了复杂的MV编码器-解码器结构并采用了单阶段训练策略。SSNVC通过将先前的熵模型特征添加到当前熵模型并使用前两帧在解码器端生成预测运动信息来隐式使用时间信息。此外，我们增强了帧生成器以生成更高质量的重建帧。实验表明，SSNVC 可以在多个基准测试中取得最佳性能，并且可以大大简化压缩过程和训练过程。]]></description>
      <guid>https://arxiv.org/abs/2406.07645</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:14 GMT</pubDate>
    </item>
    <item>
      <title>地球观测卫星图像中的运动物体检测</title>
      <link>https://arxiv.org/abs/2406.07566</link>
      <description><![CDATA[arXiv:2406.07566v1 公告类型：新
摘要：移动物体在使用推扫式扫描的地球观测卫星制作的多光谱图像中具有特征特征。虽然一般概念适用于所有此类卫星，但每种卫星设计都有自己独特的成像系统，需要独特的方法来分析特征特征。我们评估了在 Planet Labs Corporation 使用其 SuperDove 卫星群制作的一个特定卫星图像档案中检测移动物体并测量其速度的可行性。Planet Labs 数据提出了一个特殊的挑战，因为档案中的图像是单独曝光的马赛克，因此没有唯一的时间戳。我们解释了如何间接恢复时间信息。我们的结果表明，可以检测和测量常见交通工具、飞机、汽车和船只的运动。]]></description>
      <guid>https://arxiv.org/abs/2406.07566</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>基于混合机器学习算法的水稻种子纯度鉴定新方法</title>
      <link>https://arxiv.org/abs/2406.07581</link>
      <description><![CDATA[arXiv:2406.07581v1 公告类型：新
摘要：在粮食行业中，种子纯度的鉴定是一项至关重要的任务，因为它是评估种子质量的重要因素。对于水稻种子，这一特性可以减少其他品种对水稻产量、营养成分和价格的意外影响。然而，在实践中，它们经常与其他品种的种子混合。本研究提出了一种基于混合机器学习算法自动识别某一水稻品种水稻种子纯度的新方法。主要思想是使用深度学习架构从原始数据中提取重要特征，然后使用机器学习算法进行分类。在实际实施后进行了几次实验，以评估所提模型的性能。结果表明，新方法显著提高了现有方法的性能。因此，它可以应用于设计有效的水稻种子纯度识别系统。]]></description>
      <guid>https://arxiv.org/abs/2406.07581</guid>
      <pubDate>Fri, 14 Jun 2024 03:16:13 GMT</pubDate>
    </item>
    </channel>
</rss>