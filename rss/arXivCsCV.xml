<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 05 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于深度学习和神经架构搜索的水果分类系统</title>
      <link>https://arxiv.org/abs/2406.01869</link>
      <description><![CDATA[arXiv:2406.01869v1 公告类型：新
摘要：水果识别过程涉及根据视觉特征对不同类型的水果进行分析和分类。可以使用多种方法来实现此活动，包括手动检查、传统计算机视觉方法以及采用机器学习和深度学习的更复杂的方法。我们的研究确定了总共 15 种不同的水果类别，包括鳄梨、香蕉、樱桃、苹果 Braeburn、苹果金 1、杏、葡萄、猕猴桃、芒果、橙子、木瓜、桃子、菠萝、石榴和草莓。神经架构搜索 (NAS) 是深度学习和人工智能领域的一项技术进步，用于自动概念化和细化神经网络拓扑。NAS 旨在识别非常适合诸如水果检测等任务的神经网络结构。我们建议的模型具有 99.98% 的 mAP，提高了使用水果数据集的先前研究的检测性能。此外，研究完成后，还进行了比较分析，以结合与该主题相关的另一项研究的结果来评估研究结果。与早期研究的结果相比，所提出的检测器在准确性和精确度方面都表现出更高的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.01869</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:21 GMT</pubDate>
    </item>
    <item>
      <title>基于排序的无参考人脸交换质量评估</title>
      <link>https://arxiv.org/abs/2406.01884</link>
      <description><![CDATA[arXiv:2406.01884v1 公告类型：新
摘要：由于技术的快速进步，人脸交换已成为计算机视觉和图像处理中一个突出的研究领域。大多数人脸交换方法中衡量质量的指标依赖于被处理图像与源图像或目标图像之间的几个距离，即存在合适的已知参考人脸图像。因此，在无参考场景中准确评估人脸交换的质量仍然存在差距。在本研究中，我们提出了一种专门为人脸交换设计的新型无参考图像质量评估 (NR-IQA) 方法，通过构建一个全面的大规模数据集、实现一种基于多种面部属性对图像质量进行排名的方法以及结合基于可解释定性比较的暹罗网络来解决此问题。我们的模型展示了交换人脸质量评估的最新性能，提供了粗粒度和细粒度。通过这个指标的增强，改进的人脸交换模型在表情和姿势方面达到了更先进的水平。大量实验证实了我们的方法优于现有的一般无参考图像质量评估指标和最新的面部图像质量评估指标，非常适合在现实场景中评估人脸交换图像。]]></description>
      <guid>https://arxiv.org/abs/2406.01884</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:21 GMT</pubDate>
    </item>
    <item>
      <title>L-MAGIC：语言模型辅助生成具有连贯性的图像</title>
      <link>https://arxiv.org/abs/2406.01843</link>
      <description><![CDATA[arXiv:2406.01843v1 公告类型：新
摘要：在当前生成式 AI 突破的时代，从单个输入图像生成全景场景仍然是一项关键挑战。大多数现有方法使用基于扩散的迭代或同时多视图修复。然而，缺乏全局场景布局先验会导致输出具有重复对象的低质量（例如，卧室中的多张床）或需要为每个视图输入耗时的人工文本。我们提出了 L-MAGIC，这是一种利用大型语言模型进行指导的新方法，同时扩散 360 度全景场景的多个连贯视图。L-MAGIC 利用预先训练的扩散和语言模型而无需微调，确保零样本性能。超分辨率和多视图融合技术进一步提高了输出质量。大量实验表明，与相关作品相比，生成的全景场景具有更好的场景布局和透视图渲染质量，在人工评估中的偏好度超过 70%。结合条件扩散模型，L-MAGIC 可以接受各种输入模式，包括但不限于文本、深度图、草图和彩色脚本。应用深度估计可以进一步实现 3D 点云生成和具有流畅相机运动的动态场景探索。代码可在 https://github.com/IntelLabs/MMPano 上找到。视频演示可在 https://youtu.be/XDMNEzH4-Ec?list=PLG9Zyvu7iBa0-a7ccNLO8LjcVRAoMn57s 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.01843</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:20 GMT</pubDate>
    </item>
    <item>
      <title>MoLA：通过对抗训练增强潜在扩散的运动生成和编辑</title>
      <link>https://arxiv.org/abs/2406.01867</link>
      <description><![CDATA[arXiv:2406.01867v1 公告类型：新
摘要：在运动生成中，可控性以及生成质量和速度变得越来越重要。有各种各样的运动编辑任务，例如中间编辑、上身编辑和路径跟踪，但现有方法使用数据空间扩散模型执行运动编辑，与潜在扩散模型相比，该模型的推理速度较慢。在本文中，我们提出了 MoLA，它提供快速和高质量的运动生成，还可以在单​​个框架中处理多个编辑任务。为了实现高质量和快速的生成，我们采用了变分自动编码器和潜在扩散模型，并通过对抗训练提高了性能。此外，我们应用了无需训练的引导生成框架来实现具有运动控制输入的各种编辑任务。我们定量展示了对抗学习在文本到运动生成中的有效性，并证明了我们的编辑框架对运动领域中多种编辑任务的适用性。]]></description>
      <guid>https://arxiv.org/abs/2406.01867</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:20 GMT</pubDate>
    </item>
    <item>
      <title>通过数据驱动的光谱预见修剪在视觉模型中寻找彩票</title>
      <link>https://arxiv.org/abs/2406.01820</link>
      <description><![CDATA[arXiv:2406.01820v1 公告类型：新
摘要：神经网络修剪的最新进展表明，在训练之前降低深度学习模型的计算成本和内存需求是可能的。我们专注于这个框架，并提出了一种新的初始化修剪算法，该算法利用神经切线核 (NTK) 理论将稀疏网络的训练动态与密集网络的训练动态对齐。具体来说，我们展示了如何通过为将神经网络分解为单个路径获得的 NTK 轨迹提供分析上限来考虑 NTK 频谱中通常被忽略的数据相关成分。这导致了我们的路径排除 (PX)，这是一种前瞻性修剪方法，旨在保留主要影响 NTK 轨迹的参数。即使在高稀疏度水平下，PX 也能够找到彩票（即好的路径），并且大大减少了额外训练的需要。当应用于预训练模型时，它会提取可直接用于多个下游任务的子网络，从而实现与密集对应网络相当的性能，但成本和计算节省却大幅​​减少。代码可从以下网址获取：https://github.com/iurada/px-ntk-pruning]]></description>
      <guid>https://arxiv.org/abs/2406.01820</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:19 GMT</pubDate>
    </item>
    <item>
      <title>利用传导增强视觉语言模型</title>
      <link>https://arxiv.org/abs/2406.01837</link>
      <description><![CDATA[arXiv:2406.01837v1 公告类型：新
摘要：传导是一种强大的范例，它利用未标记数据的结构来提高预测准确性。我们提出了 TransCLIP，这是一种专为视觉语言模型 (VLM) 设计的新颖且计算效率高的传导方法。TransCLIP 可用作流行的归纳零样本和少样本模型之上的即插即用模块，可不断提高其性能。我们的新目标函数可以看作是正则化的最大似然估计，受 KL 散度惩罚的约束，该惩罚整合了文本编码器知识并指导传导学习过程。我们进一步推导出一个迭代块主要化-最小化 (BMM) 程序来优化我们的目标，保证收敛和解耦样本分配更新，从而为大规模数据集提供计算效率高的传导。我们报告了全面的评估、比较和消融研究，结果表明：（i）传导可以极大地增强归纳预训练零次和少样本 VLM 的泛化能力；（ii）TransCLIP 的表现大大优于仅依赖视觉特征的标准传导少样本学习方法，尤其是由于基于 KL 的语言约束。]]></description>
      <guid>https://arxiv.org/abs/2406.01837</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:19 GMT</pubDate>
    </item>
    <item>
      <title>遗忘和迁移对连续视觉里程计的实证影响</title>
      <link>https://arxiv.org/abs/2406.01797</link>
      <description><![CDATA[arXiv:2406.01797v1 公告类型：新
摘要：随着机器人技术的不断发展，对自适应和持续学习的具身代理的需求也在增加，特别是在辅助机器人领域。快速适应和长期信息保留对于在人类日常生活中典型的动态环境中运行至关重要。因此需要终身学习模式，但目前的机器人文献很少涉及它。本研究通过实证研究了灾难性遗忘的影响以及在具身环境中持续训练的神经网络中知识转移的有效性。我们专注于视觉里程计的任务，这对于具身代理实现其自我定位至关重要。我们在室内位置之间离散转换的简单连续场景中进行实验，类似于机器人在不同公寓中导航。在这种情况下，我们观察到初始令人满意的性能，在环境之间具有很高的可转移性，然后是专业化阶段，其中模型优先考虑当前特定于环境的知识，而牺牲了泛化。传统的正则化策略和增加的模型容量在缓解这种现象方面被证明是无效的。排练反而有一点好处，但会增加大量的记忆成本。像在具身环境中常见的那样，加入动作信息有助于更快地收敛，但会加剧专业化，使模型过度依赖于其运动预期，而不太擅长正确解释视觉线索。这些发现强调了在终身机器人中平衡适应性和记忆保留的开放挑战，并为终身范式在具身代理中的应用提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2406.01797</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>用于无监督细胞分割的深度非对称混合模型</title>
      <link>https://arxiv.org/abs/2406.01815</link>
      <description><![CDATA[arXiv:2406.01815v1 公告类型：新
摘要：由于手动描绘过于费力且主观，自动细胞分割对于疾病诊断和药物发现变得越来越重要。为了解决手动注释有限的问题，研究人员开发了半/无监督分割方法。在这些方法中，深度高斯混合模型因其促进复杂数据分布的能力而发挥着至关重要的作用。然而，这些模型假设数据遵循对称正态分布，这不适用于非对称分布的数据。这些模型还存在泛化能力弱的障碍，并且对异常值敏感。为了解决这些问题，本文提出了一种用于无监督细胞分割的新型非对称混合模型。该非对称混合模型是通过将某些多元高斯混合模型与对数似然和基于自监督的优化函数聚合而构建的。所提出的非对称混合模型在细胞分割（包括分割任何内容）方面的表现优于现有的最先进的无监督模型（骰子系数提高了近 2-30％，p&lt;0.05）。]]></description>
      <guid>https://arxiv.org/abs/2406.01815</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>针对鲁棒 Transformer 跟踪器的对抗性攻击的可重复性研究</title>
      <link>https://arxiv.org/abs/2406.01765</link>
      <description><![CDATA[arXiv:2406.01765v1 公告类型：新
摘要：新的变压器网络已集成到对象跟踪管道中，并在最新基准测试中表现出色。本文重点介绍变压器跟踪器在对抗性攻击下的行为，以及随着参数的变化，不同攻击对跟踪数据集的表现。我们进行了一系列实验，以评估现有对抗性攻击对具有变压器和非变压器主干的对象跟踪器的有效性。我们在 7 种不同的跟踪器上进行了实验，其中 3 种基于变压器，4 种利用其他架构。这些跟踪器针对 4 种最近的攻击方法进行了测试，以评估它们在 VOT2022ST、UAV123 和 GOT10k 数据集上的性能和鲁棒性。我们的实证研究重点是评估基于边界框与二进制掩码预测的对象跟踪器的对抗性鲁棒性，以及不同扰动程度的攻击方法。有趣的是，我们的研究发现，改变扰动水平可能不会显着影响攻击后的整体对象跟踪结果。类似地，攻击扰动的稀疏性和不可察觉性可能在扰动水平变化的情况下保持稳定。通过对所有 Transformer 跟踪器应用特定攻击，我们表明具有更强交叉注意力模型的新 Transformer 跟踪器在跟踪数据集（例如 VOT2022ST 和 GOT10k）上实现了更高的对抗鲁棒性。我们的结果还表明，需要新的攻击方法来有效应对最新类型的 Transformer 跟踪器。重现这项研究所需的代码可在 https://github.com/fatemehN/ReproducibilityStudy 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.01765</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:17 GMT</pubDate>
    </item>
    <item>
      <title>跨多域标签的混合学习视频时刻检索</title>
      <link>https://arxiv.org/abs/2406.01791</link>
      <description><![CDATA[arXiv:2406.01791v1 公告类型：新
摘要：视频时刻检索（VMR）是通过给定的文本查询描述（句子）在未修剪的原始视频中搜索视觉时间时刻。现有的研究要么从收集目标时刻时间边界上的详尽帧注释开始（全监督），要么仅使用视频级视频文本配对标签进行学习（弱监督）。前者由于数据集规模受限和注释成本高昂的多样性，对未知概念和/或新场景的泛化能力较差；后者容易受到不完整标签的视觉文本错误相关性的影响。在这项工作中，我们引入了一种称为混合学习视频时刻检索的新方法，通过将从全监督源域学习的视频文本匹配关系调整到弱标记目标域（当它们不共享公共标签空间时），通过知识转移来解决问题。我们的目标是探索两个领域之间共享的通用知识，以改进弱标记目标域中的模型学习。具体来说，我们引入了一个多分支视频文本对齐模型 (EVA)，该模型执行跨模态 (视觉-文本) 匹配信息共享和多模态特征对齐，以优化域不变的视觉和文本特征以及每个任务的判别性联合视频文本表示。实验表明，EVA 在探索源域中的时间片段注释方面非常有效，有助于在目标域中学习没有时间标签的视频时刻检索。]]></description>
      <guid>https://arxiv.org/abs/2406.01791</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:17 GMT</pubDate>
    </item>
    <item>
      <title>基于近似值的方法与人工智能方法在腹主动脉瘤 CT 图像研究中的比较</title>
      <link>https://arxiv.org/abs/2406.01764</link>
      <description><![CDATA[arXiv:2406.01764v1 公告类型：新
摘要：本研究评估了两种应用于腹主动脉瘤患者计算机断层扫描 (CT) 图像的方法：一种是基于近似理论工具的确定性方法，另一种是基于人工智能的方法。两者都旨在分割基础 CT 图像以提取主动脉血管的开放区域，以提出一种用于诊断这种病理的肾毒性造影剂的替代方案。虽然确定性方法采用采样 Kantorovich 算子及其背后的理论，利用这些算子应用于图像的重建和增强功能，但基于人工智能的方法依赖于 U-net 神经网络。对两种方法的测试结果进行了数值和视觉比较，以评估它们的性能，表明两种模型都能产生准确的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.01764</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:16 GMT</pubDate>
    </item>
    <item>
      <title>用于无源域自适应的代理去噪</title>
      <link>https://arxiv.org/abs/2406.01658</link>
      <description><![CDATA[arXiv:2406.01658v1 公告类型：新
摘要：无源域自适应 (SFDA) 旨在将预训练的源模型适应未标记的目标域，而无需访问源数据。受预训练的大型视觉语言 (ViL) 模型在许多其他应用中取得成功的启发，最新的 SFDA 方法也通过利用其预测作为伪监督来验证了 ViL 模型的优势。然而，我们观察到 ViL 的预测可能以未知的速率嘈杂且不准确，可能会在适应过程中引入额外的负面影响。为了解决这个迄今为止被忽视的挑战，在本文中，我们引入了一种新颖的代理去噪 (ProDe) 方法。具体而言，我们利用 ViL 模型作为代理来促进向潜在域不变空间的适应过程。至关重要的是，我们设计了一种代理去噪机制来纠正 ViL 的预测。这是基于一种新颖的代理置信度理论，通过优雅地建模代理对领域不变空间的发散的领域适应效应。为了利用修正后的代理，我们进一步推导出一个相互知识提取正则化。大量实验表明，我们的 ProDe 在传统的闭集设置和更具挑战性的开放集、部分集和广义 SFDA 设置下都明显优于当前最先进的替代方案。代码将很快发布。]]></description>
      <guid>https://arxiv.org/abs/2406.01658</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:15 GMT</pubDate>
    </item>
    <item>
      <title>日常生活互动活动的少样本分类（InteractADL）</title>
      <link>https://arxiv.org/abs/2406.01662</link>
      <description><![CDATA[arXiv:2406.01662v1 公告类型：新
摘要：了解日常生活活动 (ADL) 是辅助机器人、智能家居和医疗保健等不同应用的关键步骤。然而，到目前为止，很少有基准和方法关注复杂的 ADL，尤其是那些涉及家庭环境中多人互动的 ADL。在本文中，我们提出了一个新的数据集和基准 InteractADL，用于理解涉及人（和物体）之间交互的复杂 ADL。此外，由于多人互动的罕见性，家庭环境中发生的复杂 ADL 包含具有挑战性的长尾分布，并且由于语义和视觉上相似的类的存在，提出了细粒度的视觉识别任务。为了解决这些问题，我们提出了一种新的细粒度少镜头视频分类方法，称为名称调整，通过学习最佳类名向量实现更大的语义可分离性。我们展示了 Name Tuning 可以与现有的提示调整策略相结合，以学习整个输入文本（而不是仅学习提示或类名），并在 InteractADL 和其他 4 个细粒度视觉分类基准上展示了小样本分类的改进性能。为了实现透明度和可重复性，我们在 https://github.com/zanedurante/vlm_benchmark 上发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2406.01662</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:15 GMT</pubDate>
    </item>
    <item>
      <title>端到端率失真优化的三维高斯表示</title>
      <link>https://arxiv.org/abs/2406.01597</link>
      <description><![CDATA[arXiv:2406.01597v1 公告类型：新
摘要：3D 高斯分层（3DGS）已成为一种新兴技术，在 3D 表示和图像渲染方面具有巨大潜力。然而，3DGS 的大量存储开销严重阻碍了其实际应用。在这项工作中，我们将紧凑的 3D 高斯学习公式化为端到端速率失真优化（RDO）问题，并提出了可以实现灵活和连续速率控制的 RDO-Gaussian。RDO-Gaussian 解决了当前方案中存在的两个主要问题：1）与在固定失真下最小化速率的先前努力不同，我们引入了动态修剪和熵约束矢量量化（ECVQ），可同时优化速率和失真。2）以前的工作平等对待每个高斯的颜色，而我们用可学习的参数数量对不同区域和材料的颜色进行建模。我们在真实场景和合成场景中验证了我们的方法，结果表明 RDO-Gaussian 将 3D Gaussian 的尺寸大大减少了 40 倍以上，并且在率失真性能方面超越了现有方法。]]></description>
      <guid>https://arxiv.org/abs/2406.01597</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:14 GMT</pubDate>
    </item>
    <item>
      <title>D2E——涉及驾驶员状态和人类评估的自主决策数据集</title>
      <link>https://arxiv.org/abs/2406.01598</link>
      <description><![CDATA[arXiv:2406.01598v1 Announce Type: new 
摘要：随着深度学习技术的进步，数据驱动的方法越来越多地应用于自动驾驶决策，数据集的质量极大地影响了模型的性能。尽管目前的数据集在车辆和环境数据的收集方面取得了重大进展，但对包括驾驶员状态和人类评价在内的人端数据的重视程度不够。此外，现有的数据集多为跟车等简单场景，交互程度较低。本文引入了驾驶员评估数据集（D2E），这是一个自主决策数据集，包含驾驶员状态、车辆状态、环境情况和人类评审员的评估分数，涵盖了车辆决策的全面过程。除了常规代理和周围环境信息外，我们不仅收集驾驶员因素数据，包括第一人称视角视频、生理信号和眼部注意力数据，还提供来自40名人类志愿者的主观评分。数据集混合了驾驶模拟器场景和真实道路场景。设计和过滤高交互情况以确保行为多样性。 D2E通过数据组织、分析和预处理，囊括了1100余段从人为因素到评价结果的交互式驾驶案例数据，支持数据驱动决策相关算法的开发。]]></description>
      <guid>https://arxiv.org/abs/2406.01598</guid>
      <pubDate>Thu, 06 Jun 2024 03:17:14 GMT</pubDate>
    </item>
    </channel>
</rss>