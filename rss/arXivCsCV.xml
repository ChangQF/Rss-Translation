<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 09 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>混合查询转换器：统一的图像分割架构</title>
      <link>https://arxiv.org/abs/2404.04469</link>
      <description><![CDATA[arXiv:2404.04469v1 公告类型：新
摘要：现有的统一图像分割模型要么采用跨多个任务的统一架构，但使用针对每个数据集定制的单独权重，要么将一组权重应用于多个数据集，但仅限于单个任务。在本文中，我们介绍了混合查询转换器（MQ-Former），这是一种使用一组权重进行多任务和多数据集图像分割的统一架构。为了实现这一点，我们提出了一种混合查询策略，它可以有效、动态地适应不同类型的对象，而无需启发式设计。此外，统一的架构允许我们使用合成掩模和标题的数据增强来进一步提高模型的泛化能力。实验表明，与具有竞争性能的专业最先进模型相比，MQ-Former 不仅可以有效处理多个分割数据集和任务，而且可以更好地泛化到开放集分割任务，性能比其他模型高出 7 个百分点以上。开放词汇 SeginW 基准的现有技术。]]></description>
      <guid>https://arxiv.org/abs/2404.04469</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>JRDB-Social：用于理解社会群体内人类互动的背景和动态的多方面机器人数据集</title>
      <link>https://arxiv.org/abs/2404.04458</link>
      <description><![CDATA[arXiv:2404.04458v1 公告类型：新
摘要：理解人类社会行为对于计算机视觉和机器人技术至关重要。像个人行为这样的微观层面的观察是不够的，需要一种综合的方法来考虑个人行为、群体内动态和社会群体水平，以进行彻底的理解。为了解决数据集限制，本文引入了 JRDB-Social，它是 JRDB 的扩展。 JRDB-Social 旨在填补人类在不同的室内和室外社交环境中的理解空白，提供三个级别的注释：个人属性、群体内互动和社会群体环境。该数据集旨在增强我们对机器人应用的人类社会动态的掌握。利用最新的尖端多模态大语言模型，我们评估了我们的基准，以探索它们破译人类社会行为的能力。]]></description>
      <guid>https://arxiv.org/abs/2404.04458</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>结肠镜检查图像中的自动息肉分割</title>
      <link>https://arxiv.org/abs/2404.04461</link>
      <description><![CDATA[arXiv:2404.04461v1 公告类型：新
摘要：在医学诊断过程中找到人体系统中有助于预防癌症的息肉非常重要。这项研究讨论了使用扩张卷积模块和基于交叉注意力的网络来从结肠内窥镜图像中分割息肉。为了更有效地收集图像中所有像素的上下文信息，交叉注意力模块发挥了至关重要的作用。为了从数据集中提取最大的信息，在数据集中采用了数据增强技术。旋转、翻转、缩放和对比度以及不同的学习率被实施以创建更好的模型。全局平均池化应用于 ResNet50，有助于存储编码器的重要细节。在我们的实验中，所提出的架构的性能与 U-Net、DeepLabV3、PraNet 等现有模型进行了比较。该架构在具有不规则息肉形状的数据集子集上优于其他模型。人们发现扩张卷积模块、RCCA 和全局平均池化的组合对于不规则形状是有效的。我们的架构展示了一种增强，与现有模型相比，所有指标平均提高了 3.75%。]]></description>
      <guid>https://arxiv.org/abs/2404.04461</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>通过优化人类效用来调整扩散模型</title>
      <link>https://arxiv.org/abs/2404.04465</link>
      <description><![CDATA[arXiv:2404.04465v1 公告类型：新
摘要：我们提出了 Diffusion-KTO，这是一种通过将对齐目标制定为预期人类效用的最大化来对齐文本到图像扩散模型的新方法。由于该目标独立适用于每一代，因此 Diffusion-KTO 不需要收集昂贵的成对偏好数据，也不需要训练复杂的奖励模型。相反，我们的目标需要简单的每图像二进制反馈信号，例如喜欢或不喜欢，这是很容易获得的。在使用 Diffusion-KTO 进行微调后，文本到图像的扩散模型在人类判断和自动评估指标（例如 PickScore 和 ImageReward）方面均表现出优于现有技术（包括监督微调和 Diffusion-DPO）的性能。总体而言，Diffusion-KTO 释放了利用现成的每图像二进制信号的潜力，并扩大了将文本到图像扩散模型与人类偏好对齐的适用性。]]></description>
      <guid>https://arxiv.org/abs/2404.04465</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>具有基于焦点多样性的剪枝的鲁棒少样本集成学习</title>
      <link>https://arxiv.org/abs/2404.04434</link>
      <description><![CDATA[arXiv:2404.04434v1 公告类型：新
摘要：本文提出了 FusionShot，一种焦点多样性优化的少样本集成学习方法，用于提高预训练少样本模型的鲁棒性和泛化性能。该论文做出了三项原创贡献。首先，我们通过创建三个替代融合通道来探索少样本学习的独特特征，以集成多个少样本（FS）模型。其次，我们引入焦点误差多样性的概念来学习最有效的集成组合策略，而不是假设大量基本模型的集成将优于那些较小尺寸的子集成。我们开发了一种焦点多样性集成修剪方法，可以有效地修剪出具有低集成误差多样性的候选集成，并推荐具有最高焦点误差多样性的 top-$K$ FS 集成。最后，我们通过设计学习组合算法来捕获集成少样本预测的复杂非线性模式，该算法可以学习不同的权重分配，以实现不同成员模型上的鲁棒集成融合。对代表性少样本基准的大量实验表明，FusionShot 推荐的 top-K 集成可以在新任务（不同分布和训练时未知）上优于代表性 SOTA 少样本模型，并且可以在以下两个方面优于现有的少样本学习器：跨域设置和对抗性设置。出于可重复性的目的，FusionShot 训练的模型、结果和代码可在 https://github.com/sftekin/fusionshot 上获取]]></description>
      <guid>https://arxiv.org/abs/2404.04434</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>领域适应和泛化中的视觉转换器：鲁棒性研究</title>
      <link>https://arxiv.org/abs/2404.04452</link>
      <description><![CDATA[arXiv:2404.04452v1 公告类型：新
摘要：深度学习模型通常在数据分布与训练和验证阶段使用的数据分布不同的场景中进行评估。这种差异给准确预测部署在目标分布上的模型的性能带来了挑战。领域适应和泛化被广泛认为是解决此类转变的有效策略，从而确保可靠的性能。最近在计算机视觉任务中应用视觉变压器的有希望的结果，加上自注意力机制的进步，已经证明了它们在处理分布变化方面的鲁棒性和泛化性的巨大潜力。在研究界日益增长的兴趣的推动下，我们的论文研究了视觉变换器在领域适应和领域泛化场景中的部署。对于领域适应方法，我们将研究分为特征级、实例级、模型级适应和混合方法，以及关于增强领域适应的不同策略的其他分类。同样，对于领域泛化，我们将研究分为多领域学习、元学习、正则化技术和数据增强策略。我们进一步对研究中的不同策略进行分类，强调研究人员通过集成视觉变换器来解决分布变化所采取的各种方法。包含总结这些类别的综合表格是我们工作的一个显着特征，为研究人员提供了宝贵的见解。这些发现凸显了视觉转换器在管理配电变化方面的多功能性，这对于现实世界的应用至关重要，尤其是在关键的安全和决策场景中。]]></description>
      <guid>https://arxiv.org/abs/2404.04452</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>超越已知：新颖性检测中的对抗性自动编码器</title>
      <link>https://arxiv.org/abs/2404.04456</link>
      <description><![CDATA[arXiv:2404.04456v1 公告类型：新
摘要：在新颖性检测中，目标是在给定主要捕获内点分布的训练数据集的情况下，决定新数据点是否应归类为内点或离群点。最近的方法通常使用深度编码器和解码器网络框架来导出重建误差，并利用该误差来确定新颖性分数，或作为一类分类器的基础。在本研究中，我们使用类似的框架，但具有轻量级深度网络，并采用具有重建误差的概率评分。我们的方法计算样本是否来自内点分布的概率。这项工作做出了两个关键贡献。首先，我们通过线性化包含内点分布结构的流形来计算新颖性概率。这使我们能够解释概率是如何分布的，并且可以根据流形切空间的局部坐标来确定。第二个贡献是我们改进了网络的训练协议。我们的结果表明，我们的方法在学习目标类方面是有效的，并且在几个基准数据集上优于最新的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2404.04456</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>使用具有行为特征的无监督远程光电容积描记法分析参与者在在线会议期间的参与度</title>
      <link>https://arxiv.org/abs/2404.04394</link>
      <description><![CDATA[arXiv:2404.04394v1 公告类型：新
摘要：参与度测量在医疗保健、教育、广告和服务中都有应用。使用生理和行为特征是可行的，但由于需要接触传感器，传统生理测量变得不切实际。我们证明了无监督远程光电体积描记法 (rPPG) 作为接触传感器的替代方案的可行性，可获取心率变异性 (HRV) 特征，然后将这些特征与行为特征融合以衡量在线小组会议的参与度。首先，通过细粒度的参与标签收集社会工作者之间在线互动的独特参与数据集，提供对虚拟会议动态的洞察。其次，定制预训练的rPPG模型，以无监督的方式重建来自视频会议的准确rPPG信号，从而能够计算HRV特征。第三，证明了使用短观察窗根据 HRV 特征估计参与度的可行性，当使用两到四分钟的较长观察窗时，其效果显着增强。第四，评估行为线索的有效性并将其与生理数据融合，这进一步提高了参与度评估性能。仅使用 HRV 功能时，准确度可达 94%，无需接触传感器或地面实况信号。行为线索的结合将准确率提高到 96%。面部视频分析提供精确的参与度测量，有利于未来的应用。]]></description>
      <guid>https://arxiv.org/abs/2404.04394</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>PhysPT：物理感知预训练 Transformer，用于从单目视频估计人体动力学</title>
      <link>https://arxiv.org/abs/2404.04430</link>
      <description><![CDATA[arXiv:2404.04430v1 公告类型：新
摘要：虽然当前的方法在从单目视频估计 3D 人体运动方面取得了有希望的进展，但它们的运动估计通常在物理上不切实际，因为它们主要考虑运动学。在本文中，我们介绍了物理感知预训练变压器（PhysPT），它改进了基于运动学的运动估计并推断运动力。 PhysPT 利用 Transformer 编码器-解码器主干以自我监督的方式有效地学习人类动力学。此外，它还结合了控制人体运动的物理原理。具体来说，我们构建了基于物理的身体表示和接触力模型。我们利用它们施加新颖的物理启发训练损失（即力损失、接触损失和欧拉-拉格朗日损失），使 PhysPT 能够捕获人体的物理特性及其所经历的力。实验表明，经过训练后，PhysPT 可以直接应用于基于运动学的估计，以显着增强其物理合理性并产生有利的运动力。此外，我们还表明，这些具有物理意义的量可以转化为重要下游任务（人类行为识别）准确性的提高。]]></description>
      <guid>https://arxiv.org/abs/2404.04430</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>Koala：关键帧调节长视频-LLM</title>
      <link>https://arxiv.org/abs/2404.04346</link>
      <description><![CDATA[arXiv:2404.04346v1 公告类型：新
摘要：长视频问答是一项具有挑战性的任务，涉及识别短期活动并推理它们的细粒度关系。最先进的视频大语言模型（vLLM）因其在新任务上展示的新兴能力而有望成为可行的解决方案。然而，尽管 vLLM 接受了数百万个长达数秒的短视频的训练，但仍无法理解长达数分钟的视频并准确回答有关它们的问题。为了解决这个限制，我们提出了一种轻量级的自监督方法，即关键帧调节的长视频 LLM (Koala)，它引入了可学习的时空查询来调整预训练的 vLLM 以推广到更长的视频。我们的方法引入了两个新的标记器，它们以从稀疏视频关键帧计算出的视觉标记为条件，以理解短视频时刻和长视频时刻。我们在 HowTo100M 上训练我们提出的方法，并在零样本长视频理解基准上展示其有效性，在所有任务中，它的绝对准确度比最先进的大型模型高 3 - 6%。令人惊讶的是，我们还凭经验表明，我们的方法不仅有助于预训练的 vLLM 理解长视频，而且还提高了其短期动作识别的准确性。]]></description>
      <guid>https://arxiv.org/abs/2404.04346</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>Idea-2-3D：协作式 LMM 代理支持从交错多模态输入生成 3D 模型</title>
      <link>https://arxiv.org/abs/2404.04363</link>
      <description><![CDATA[arXiv:2404.04363v1 公告类型：新
摘要：在本文中，我们追求一种新颖的 3D AIGC 设置：从 IDEA 生成 3D 内容。 IDEA 的定义是多模态输入的组合，包括文本、图像和 3D 模型。据我们所知，这种具有挑战性和吸引力的 3D AIGC 设置以前从未被研究过。我们提出了名为 Idea-2-3D 的新颖框架来实现这一目标，该框架由基于大型多模型模型 (LMM) 的三个代理以及供它们调用的几个现有算法工具组成。具体来说，这三个基于 LMM 的智能体被提示完成提示生成、模型选择和反馈反映的工作。他们的工作循环既涉及相互合作又涉及批评。请注意，此循环是以全自动方式完成的，无需任何人为干预。然后，该框架输出一个文本提示，以生成与输入 IDEA 非常一致的 3D 模型。我们展示了令人印象深刻的 3D AIGC 结果，这是以前任何方法都无法达到的。为了进行定量比较，我们使用一大堆最先进的 3D AIGC 模型构建基于字幕的基线，并证明 Idea-2-3D 的表现显着优于。 Idea-2-3D在94.2%的情况下满足用户需求，IDEA与3D模型的匹配度是基线的2.3倍。此外，在 93.5% 的情况下，用户同意 Idea-2-3D 优于基线。代码、数据和模型将公开。]]></description>
      <guid>https://arxiv.org/abs/2404.04363</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>ClickDiffusion：利用法学硕士进行交互式精确图像编辑</title>
      <link>https://arxiv.org/abs/2404.04376</link>
      <description><![CDATA[arXiv:2404.04376v1 公告类型：新
摘要：最近，研究人员提出了使用自然语言指令生成和操作图像的强大系统。然而，仅用文本很难精确地指定许多常见的图像变换类别。例如，用户可能希望改变具有几只相似狗的图像中特定狗的位置和品种。仅使用自然语言来完成这项任务相当困难，并且需要用户编写费力复杂的提示，既要消除目标狗的歧义，又要描述目的地。我们提出了 ClickDiffusion，这是一种用于精确图像操作和生成的系统，它将自然语言指令与用户通过直接操作界面提供的视觉反馈相结合。我们证明，通过将图像和多模态指令序列化为文本表示，可以利用 LLM 来执行图像布局和外观的精确转换。代码可在 https://github.com/poloclub/ClickDiffusion 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.04376</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>基于翻译的视频到视频合成</title>
      <link>https://arxiv.org/abs/2404.04283</link>
      <description><![CDATA[arXiv:2404.04283v1 公告类型：新
摘要：基于翻译的视频合成（TVS）已成为计算机视觉中的一个重要研究领域，旨在促进不同领域之间的视频转换，同时保留时间连续性和底层内容特征。通过将传统图像到图像转换的功能扩展到时域，该技术得到了广泛的应用，包括视频超分辨率、着色、分割等。 TVS 面临的主要挑战之一是在合成过程中引入闪烁伪像和帧之间不一致的固有风险。由于必须确保视频帧之间平滑且连贯的过渡，这尤其具有挑战性。为了应对这一挑战，人们创建了多种策略和算法，旨在减轻这些不良后果。这篇全面的综述广泛研究了 TVS 领域的最新进展。它彻底研究了新兴方法，阐明了用于熟练视频合成的基本概念和机制。这项调查还阐明了它们的固有优势、局限性、适当的应用以及未来发展的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2404.04283</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>通过偏振快速融合调谐实现稳健的深度增强</title>
      <link>https://arxiv.org/abs/2404.04318</link>
      <description><![CDATA[arXiv:2404.04318v1 公告类型：新
摘要：现有的深度传感器并不完善，在具有挑战性的场景中（例如存在透明或反射物体的情况下）可能会提供不准确的深度值。在这项工作中，我们提出了一个利用偏振成像来改善各种深度传感器不准确的深度测量的通用框架。以前的基于偏振的深度增强方法侧重于利用单个传感器的纯物理公式。相比之下，我们的方法首先采用基于学习的策略，其中训练神经网络根据偏振数据和来自不同传感器的传感器深度图估计密集且完整的深度图。为了进一步提高性能，我们提出了一种偏振提示融合调整（PPFT）策略，以有效地利用在大规模数据集上预训练的基于 RGB 的模型，因为偏振数据集的大小受到限制，无法从头开始训练强大的模型。我们在公共数据集上进行了广泛的实验，结果表明，与现有的深度增强基线相比，所提出的方法表现良好。代码和演示可在 https://lastbasket.github.io/PPFT/ 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.04318</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>SpatialTracker：跟踪 3D 空间中的任何 2D 像素</title>
      <link>https://arxiv.org/abs/2404.04319</link>
      <description><![CDATA[arXiv:2404.04319v1 公告类型：新
摘要：恢复视频中密集且长距离的像素运动是一个具有挑战性的问题。部分困难源于 3D 到 2D 的投影过程，导致 2D 运动域中的遮挡和不连续性。虽然 2D 运动可能很复杂，但我们认为底层的 3D 运动通常可以是简单且低维的。在这项工作中，我们建议估计 3D 空间中的点轨迹，以减轻图像投影引起的问题。我们的方法名为 SpatialTracker，使用单目深度估计器将 2D 像素提升为 3D，使用三平面表示有效地表示每个帧的 3D 内容，并使用转换器执行迭代更新以估计 3D 轨迹。 3D 跟踪使我们能够利用尽可能刚性 (ARAP) 约束，同时学习将像素聚集到不同刚性部分的刚性嵌入。广泛的评估表明，我们的方法在定性和定量上都实现了最先进的跟踪性能，特别是在平面外旋转等具有挑战性的场景中。]]></description>
      <guid>https://arxiv.org/abs/2404.04319</guid>
      <pubDate>Tue, 09 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    </channel>
</rss>