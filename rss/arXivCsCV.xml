<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Mon, 22 Jan 2024 03:15:35 GMT</lastBuildDate>
    <item>
      <title>M3BUNet：CT 扫描上胰腺分割的移动平均最大 UNet。 (arXiv:2401.10419v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.10419</link>
      <description><![CDATA[CT扫描图像中的器官分割是多个器官的必要过程
下游医学图像分析任务。目前，手动CT扫描分割
放射科医生的这种做法很普遍，特别是对于像胰腺这样的器官来说，
需要高水平的领域专业知识才能进行可靠的细分，因为
诸如器官尺寸小、闭塞和形状不同等因素。当求助于
自动胰腺分割，这些因素转化为有限的可靠
标记数据来训练有效的分割模型。因此，
当代胰腺分割模型的性能仍不达标
可接受的范围。为了改进这一点，我们提出了 M3BUNet，它是 MobileNet 的融合
和 U-Net 神经网络，配备了新颖的平均最大（MM）注意力，
分两个阶段操作，逐步将胰腺 CT 图像从粗略分割到
很好的用于物体检测的掩模引导。这种方法使
网络超越类似网络实现的分割性能
架构并实现与复杂的最先进技术相当的结果
方法，同时保持较低的参数数量。此外，我们
引入外部轮廓分割作为粗略的预处理步骤
阶段通过图像标准化协助分割过程。为了
在精细分割阶段，我们发现应用小波分解
创建多输入图像的过滤器增强了胰腺分割性能。
我们在众所周知的 NIH 胰腺数据集上广泛评估了我们的方法
和 MSD 胰腺数据集。我们的方法展示了相当可观的性能
改进，实现平均 Dice 相似系数 (DSC) 值高达
NIH 的 Intersection Over Union (IOU) 分数高达 81.16
胰腺数据集，MSD 胰腺数据集的 DSC 为 88.60%，IOU 为 79.90%。
]]></description>
      <guid>http://arxiv.org/abs/2401.10419</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>扩散膨胀：文本到视频超分辨率的有效时间适应。 （arXiv：2401.10404v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10404</link>
      <description><![CDATA[我们提出了一种高效的基于扩散的文本到视频超分辨率（SR）
利用像素级容易学习的能力的调整方法
图像扩散模型捕获空间信息以生成视频。到
为了实现这个目标，我们通过膨胀来设计一个高效的架构
文本到图像 SR 模型在我们的视频生成框架中的权重。
此外，我们还采用了时间适配器来确保时间一致性
跨视频帧。我们根据我们的研究不同的调整方法
夸大的架构并报告计算成本和
超分辨率质量。实证评估，包括定量和
在 Shutterstock 视频数据集上的定性表明我们的方法
能够以良好的视觉质量执行文本到视频的 SR 生成，并且
时间一致性。为了评估时间相干性，我们还提出
视频格式的可视化
https://drive.google.com/drive/folders/1YVc-KMSJqOrEUdQWVaI-Yfu8Vsfu_1aO?usp=sharing 。
]]></description>
      <guid>http://arxiv.org/abs/2401.10404</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>DataViz3D：一种利用在线全息建模进行广泛数据集预处理和可视化的新方法。 （arXiv：2401.10416v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10416</link>
      <description><![CDATA[DataViz3D 是一款创新的在线软件，可转换复杂的数据集
使用全息技术构建交互式 3D 空间模型。这个工具
使用户能够在 3D 空间内生成散点图，并准确映射到
数据集的XYZ坐标，提供生动直观的
了解数据中固有的空间关系。 DataViz3D 的
用户友好的界面使得先进的 3D 建模和全息
广泛的用户可以访问可视化，创造新的机会
跨学科的合作研究和教育。
]]></description>
      <guid>http://arxiv.org/abs/2401.10416</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>农业物体检测与你只看一次（YOLO）算法：文献计量和系统文献综述。 （arXiv：2401.10379v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10379</link>
      <description><![CDATA[视觉是多种数字技术和工具的主要组成部分
农业。物体检测器 You Look Only Once (YOLO) 已获得
由于其在相对较短的时间内在农业中普及
最先进的性能。 YOLO 提供实时检测，具有良好的
准确性并应用于各种农业任务，包括
监测、监视、传感、自动化和机器人技术。该研究和
YOLO在农业的应用加速但碎片化
和多学科。此外，性能特征（即
物体检测器的精度、速度、计算）会影响
农业技术的实施和采用。因此，该研究旨在
收集大量文献来记录和批判性地评估进展
以及YOLO在农业物体识别中的应用。首先，我们
对 257 篇文章进行了文献计量审查，以了解学术观点
YOLO在农业领域的景观。其次，我们进行了系统的
审查 30 篇文章，以确定当前的知识、差距和修改
YOLO 用于特定农业任务。该研究批判性地评估并
总结了YOLO端到端学习方法的信息，包括
数据采集​​、处理、网络修改、集成和
部署。我们还讨论了特定于任务的 YOLO 算法修改和
整合以满足农业目标或环境特定的挑战。
总的来说，YOLO 集成的数字工具和技术显示出潜力
用于实时、自动监控、监视和对象处理
减少劳动力、生产成本和环境影响，同时最大限度地提高
资源效率。该研究提供了详细的文档和
显着提高了 YOLO 在农业中应用的现有知识，
这可以使科学界受益匪浅。
]]></description>
      <guid>http://arxiv.org/abs/2401.10379</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>分析和减轻弱势群体的偏见：实现数据集中的平衡表示。 （arXiv：2401.10397v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10397</link>
      <description><![CDATA[自动驾驶感知系统的准确性和公平性
至关重要，特别是对于弱势道路使用者而言。主流研究已经看到
改进分类准确性的性能指标。然而，
人工智能模型中偏见继承的隐藏特征、类别不平衡和
数据集中的差异常常被忽视。在此背景下，我们的研究
通过关注阶级来检查弱势道路使用者的阶级不平衡
分布分析、绩效评估和偏差影响评估。我们
确定对阶级代表性不平衡的担忧，从而导致
检测准确性的潜在偏差。利用流行的 CNN 模型和 Vision
Transformers (ViTs) 与 nuScenes 数据集，我们的性能评估
揭示了代表性不足的类别的检测差异。我们提出一个
模型优化和偏差缓解的方法，其中包括数据
增强、重采样和特定度量的学习。使用建议的
缓解方法中，我们看到 IoU(%) 和 NDS(%) 指标有所改善
对于 CNN 模型，分别为 71.3 到 75.6 和 80.6 到 83.7。同样，对于
ViT，我们观察到 IoU 和 NDS 指标从 74.9 提高到 79.2 和 83.8
分别为87.1。这项研究有助于开发更可靠的
模型和数据集，增强少数群体的包容性。
]]></description>
      <guid>http://arxiv.org/abs/2401.10397</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>重建不可见：通过连体掩码条件变分自动编码器恢复视频帧。 （arXiv：2401.10402v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10402</link>
      <description><![CDATA[在计算机视觉领域，修复缺失信息
视频帧是一个严峻的挑战，特别是在诸如
自动驾驶和监控系统。本文介绍的是暹罗
掩码条件变分自动编码器 (SiamMCVAE)，利用暹罗
基于视觉变压器的双编码器架构。这种创新的
设计通过捕获来增强模型理解丢失内容的能力
配对帧之间的内在相似性。熟练掌握 SiamMCVAE
重建屏蔽帧中缺失的元素，有效解决问题
通过变分推理由相机故障引起。实验性的
结果有力地证明了该模型在恢复缺失方面的有效性
信息，从而增强计算机视觉系统的弹性。这
在 SiamMCVAE 中纳入 Siamese Vision Transformer (SiamViT) 编码器
体现了解决现实世界挑战的巨大潜力
计算机视觉，增强自治系统在动态中的适应性
环境。
]]></description>
      <guid>http://arxiv.org/abs/2401.10402</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>ELRT：紧凑卷积神经网络的高效低阶训练。 （arXiv：2401.10341v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10341</link>
      <description><![CDATA[低阶压缩，一种流行的模型压缩技术，可产生
具有低秩的紧凑卷积神经网络（CNN）已被
在文献中得到了很好的研究。另一方面，低阶训练，作为
从头开始训练低阶 CNN 的替代方法，目前很少被利用
然而。与低秩压缩不同，低秩训练不需要预训练
全秩模型，并且整个训练阶段始终在
低阶结构，为实际应用带来诱人的好处。
然而，现有的低秩训练方案仍然面临着一些问题
挑战，例如准确度大幅下降和/或仍需要更新
训练期间使用全尺寸模型。在本文中，我们进行了系统的
对低阶 CNN 训练的调查。通过识别适当的低等级
格式和绩效改进策略，我们提出 ELRT，一种高效的
高精度、高紧凑性、低秩 CNN 的低秩训练解决方案
楷模。我们在不同的环境下训练各种 CNN 的广泛评估结果
数据集证明了 ELRT 的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2401.10341</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:32 GMT</pubDate>
    </item>
    <item>
      <title>协调空间和光谱学习，实现稳健和广义的医学图像分割。 (arXiv:2401.10373v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.10373</link>
      <description><![CDATA[深度学习在医学图像领域展现出显著成果
分割。然而，流行的深度学习模型与较差的
由于（i）类内变化而产生的泛化，其中出现相同的类
不同样本中的情况不同，以及（ii）类间独立性，从而产生
难以捕捉不同物体之间的复杂关系，
导致更高的假阴性病例。本文提出了一种新颖的方法
协同空间和光谱表示以增强
领域广义医学图像分割。我们推出创新的
谱相关系数目标提高模型的能力
捕获中序特征和上下文远程依赖性。这
目标通过纳入有价值的内容来补充传统的空间目标
光谱信息。大量实验表明，优化此
与 UNet 和 TransUNet 等现有架构的目标显着
增强泛化性、可解释性和噪声鲁棒性，产生更多
自信的预测。例如，在心脏分割中，我们观察到 0.81
DSC 比 UNet 提高了 pp 和 1.63 pp（pp = 百分点）
分别是 TransUNet。我们的可解释性研究表明，在大多数情况下
通过引入 UNet 优化的任务、目标甚至优于 TransUNet
全局上下文信息以及本地详细信息。这些发现
强调我们提出的方法的多功能性和有效性
不同的成像方式和医学领域。
]]></description>
      <guid>http://arxiv.org/abs/2401.10373</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:32 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的零空间特性及其在图像隐写术中的应用。 （arXiv：2401.10262v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10262</link>
      <description><![CDATA[本文探讨了神经网络的零空间特性。我们延长
从线性映射到非线性映射的零空间定义并讨论
神经网络中存在零空间。给定神经元的零空间
网络可以告诉我们输入数据中没有贡献的部分
最终的预测，以便我们可以用它来欺骗神经网络。这
揭示了神经网络中可被利用的固有弱点。一
这里描述的应用导致了一种图像隐写术的方法。通过
在 MNIST 等图像数据集上进行的实验表明，我们可以使用零空间
强制神经网络选择选定的隐藏图像类的组件，
即使整体图像看起来完全不同
图像。我们通过比较人类观众的观看结果来得出结论
看，神经网络实际使用的图像部分
做出预测，从而表明神经网络“看到”的是
与我们的预期完全不同。
]]></description>
      <guid>http://arxiv.org/abs/2401.10262</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>用于联合域泛化的多源协作梯度差异最小化。 （arXiv：2401.10272v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10272</link>
      <description><![CDATA[联合域泛化旨在从中学习域不变模型
多个分散的源域，用于部署在看不见的目标域上。
出于隐私考虑，保留不同源域的数据
孤立，这给弥合领域差距带来了挑战。为了解决这个问题
问题，我们提出了多源协作梯度差异
用于联合域泛化的最小化（MCGDM）方法。具体来说，
我们提出原始图像和
增强图像以避免过度拟合其中的特定领域信息
隔离域。此外，我们提出域间梯度匹配
其他领域的协作，可以进一步减少领域转移
跨去中心化的领域。结合域内和域间梯度
匹配，我们的方法使学习的模型能够很好地概括未知的
域。此外，我们的方法可以扩展到联邦域
通过在伪标记目标上微调目标模型来适应任务
领域。关于联邦域泛化和的广泛实验
适应表明我们的方法优于最先进的方法
显著地。
]]></description>
      <guid>http://arxiv.org/abs/2401.10272</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>尝试从生成流的潜在空间生成新的桥梁类型。 （arXiv：2401.10299v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.10299</link>
      <description><![CDATA[通过例子之间的坐标和概率变换
不同分布，介绍归一化流的基本原理
以简单明了的方式。从分布来看
随机变量函数，概率变换的本质是
解释了，以及比例因子雅可比概率行列式
引入了转换。将数据集视为来自
人口，获得归一化流量本质上是通过抽样调查
统计推断总体的数字特征，然后
采用最大似然估计方法建立损失函数。
本文介绍归一化流如何巧妙地解决两大问题
高维矩阵行列式计算的应用挑战和
神经网络可逆变换。使用对称结构图像
三跨梁桥、拱桥、斜拉桥数据集
悬索桥，基于 Glow 的标准化流程构建和训练
TensorFlow 概率库中的 API。该模型可以平滑地转变
将桥梁数据集的复杂分布转换为标准正态分布，
并根据获得的潜在空间采样，可以生成新的桥梁类型
与训练数据集不同。
]]></description>
      <guid>http://arxiv.org/abs/2401.10299</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>一种基于双PCS的视频SAR持续成像波束分割极坐标格式算法。 （arXiv：2401.10252v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10252</link>
      <description><![CDATA[视频合成孔径雷达（SAR）近年来受到越来越多的关注
凭借其高分辨率、高帧率的能力和优势，多年来
在不断的观察中。一般来说，极坐标格式算法（PFA）是一种
聚光模式视频 SAR 的高效算法。然而，在这个过程中
PFA，波前曲率误差（WCE）限制了成像场景尺寸和
二维插值会影响效​​率。为了解决上述问题，
基于线性调频缩放 (PCS) 原理的光束分段 PFA，称为
BS-PCS-PFA，是针对视频SAR成像而提出的，具有以下能力：
不同载波频率视频SAR的持续成像。首先，一个
建议采用适用于视频 SAR PFA 的改进 PCS 来取代 2-D
地面输出坐标系中的插值和粗略图像
获得（GOCS）。至于粗画中存在的畸变或散焦
image，一种基于光束分段快速滤波的新型子块成像方法
提出将图像分割成多个子光束数据，其畸变
当子块等效尺寸较小时，可以忽略离焦
比畸变可忽略不计的区域。通过对子光束数据的处理
对重新聚焦的子图像进行镶嵌，GOCS 中的完整图像无失真
并获得散焦。此外，还应用了三步MoCo方法
适应实际不规则轨迹的算法。这
所提出的方法可以显着扩大PFA的有效场景尺寸，并且
更好的运行效率使其更适合视频SAR成像。
通过实验数据验证了算法的可行性。
]]></description>
      <guid>http://arxiv.org/abs/2401.10252</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:30 GMT</pubDate>
    </item>
    <item>
      <title>Beyond the Frame：具有用户定义长度的单个和多个视频摘要方法。 （arXiv：2401.10254v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10254</link>
      <description><![CDATA[视频精简是减少视频时长的重要方法，
减少观看/回顾长视频所花费的时间。这个方法已经成为
更重要的是，发布的视频数量每天都在增加。 A
单个或多个视频可以总结为一个相对较短的视频，使用
从多模态视听技术到自然技术的各种技术
语言处理方法。视听技术可用于识别
重要的视觉事件并选择最重要的部分，而 NLP
技术可用于评估音频转录并提取主要内容
原始视频中的句子（时间戳）和相应的视频帧。
另一种方法是利用两个领域的优点。这意味着我们可以使用
视听线索以及视频文字记录来提取和总结
视频。在本文中，我们结合了多种 NLP 技术（提取和
基于内容的摘要器）与视频处理技术来转换长
视频成一个相对较短的视频。我们设计这个收费站的方式是
用户可以指定摘要视频的相对长度。我们还有
探索了将多个视频汇总并连接成一个视频的方法
简短的视频将有助于了解同一主题中最重要的概念
单个短视频中的主题。我们的方法表明视频摘要是一种
困难但重要的工作，具有进一步研究的巨大潜力
和发展，这要归功于NLP模型的发展。
]]></description>
      <guid>http://arxiv.org/abs/2401.10254</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:30 GMT</pubDate>
    </item>
    <item>
      <title>主动头枕与基于深度摄像头的耳朵定位系统相结合。 （arXiv：2401.10256v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10256</link>
      <description><![CDATA[主动式头枕可以根据主动式头枕减少耳朵周围的低频噪音
噪声控制（ANC）系统。两者的控制系统均采用固定控制滤波器
基于远程麦克风的自适应控制系统提供良好的噪音
当头部处于原始位置时的减少性能。然而，他们的
当头部运动时，性能会显着下降。在本文中，一个
引入基于深度相机的人耳定位系统来解决
这个问题。系统使用RTMpose模型来估计二维
(2D) 耳朵在色框中的位置，然后导出
深度框架中对应的三维（3D）坐标
深度相机。实验结果表明，该耳朵定位系统可以
有效追踪耳朵运动，宽带降噪
主动头枕与系统相结合的性能显着提高
当人类头部平移或旋转时得到改善。
]]></description>
      <guid>http://arxiv.org/abs/2401.10256</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:30 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的分辨率色谱。 （arXiv：2401.10247v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10247</link>
      <description><![CDATA[扩散模型通过迭代随机生成高分辨率图像
流程。尤其是去噪方法是最流行的方法之一
预测样本中的噪声并每次对其进行去噪的方法
步。人们普遍观察到，生成样本的分辨率
随着时间的推移而变化，开始变得模糊和粗糙，然后变得更加清晰和
更精细。在本文中，我们介绍了“解析色谱”，它表明
每个分辨率的信号生成率，这是非常有用的概念
从数学上解释生成过程中从粗到细的行为，
了解噪声调度的作用，并设计与时间相关的调制。
使用分辨率色谱法，我们确定哪个分辨率级别成为
在特定时间步长占主导地位，并通过实验验证我们的理论
文本到图像的扩散模型。我们还提出了一些直接应用
利用这个概念：将预先训练的模型升级到更高分辨率
与时间相关的提示作曲。我们的理论不仅能够实现更好的
了解许多现有的图像处理技术
的产生，但也表明了设计更好的噪声的潜力
时间表。
]]></description>
      <guid>http://arxiv.org/abs/2401.10247</guid>
      <pubDate>Mon, 22 Jan 2024 03:15:29 GMT</pubDate>
    </item>
    </channel>
</rss>