<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Thu, 07 Dec 2023 03:14:52 GMT</lastBuildDate>
    <item>
      <title>Uni3DL：3D 和语言理解的统一模型。 （arXiv：2312.03026v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03026</link>
      <description><![CDATA[在这项工作中，我们提出了 Uni3DL，一个 3D 和语言的统一模型
理解。与现有的 3D 统一视觉语言模型不同
其任务种类有限并且主要取决于预计的
多视图图像，Uni3DL 直接在点云上运行。这种方法
显着扩展了 3D 支持的任务范围，包括
3D 视觉和视觉语言任务。 Uni3DL 的核心是查询
Transformer 旨在学习与任务无关的语义并通过以下方式屏蔽输出
关注 3D 视觉特征，并采用任务路由器来选择性地
生成不同任务所需的特定于任务的输出。具有统一的
体系结构，我们的 Uni3DL 模型享有无缝的任务分解和
跨任务共享大量参数。 Uni3DL经过严格的
在不同的 3D 视觉语言理解任务中进行评估，包括
语义分割、对象检测、实例分割、视觉
基础、3D 字幕和文本 3D 跨模式检索。它展示了
性能与特定任务的最先进 (SOTA) 相当或超过
楷模。我们希望我们的基准测试和 Uni3DL 模型能够成为实现这一目标的坚实一步。
简化 3D 和语言领域统一模型的未来研究
理解。项目页面：https://uni3dl.github.io。
]]></description>
      <guid>http://arxiv.org/abs/2312.03026</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散暴露：从提示到图像的性别偏见。 （arXiv：2312.03027v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03027</link>
      <description><![CDATA[最近的研究强调了生成模型中的偏差，揭示了这一点
她们倾向于基于性别的陈规定型观念和不平衡。这
论文通过引入评估为这一不断增长的研究做出了贡献
旨在自动分析性别指标对人的影响的协议
稳定的扩散图像。利用之前工作的见解，我们探索如何
性别指标不仅影响性别呈现，还影响
生成图像中对象和布局的表示。我们的发现
包括对物体的描绘存在差异，例如
为特定性别量身定制的乐器以及整体布局的变化。我们
还表明中性提示往往会产生更符合以下内容的图像
男性的提示多于女性的提示，提供了宝贵的见解
稳定扩散中固有的微妙的性别偏见。
]]></description>
      <guid>http://arxiv.org/abs/2312.03027</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>DreamVideo：具有图像保留和文本引导的高保真图像到视频生成。 （arXiv：2312.03018v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03018</link>
      <description><![CDATA[图像到视频生成，旨在从
给出的参考图像，引起了极大的关注。现有方法尝试
将预先训练的文本引导图像扩散模型扩展到图像引导视频
一代模型。然而，这些方法通常会导致要么低
由于浅层图像的限制，保真度或随着时间的推移而闪烁
指导和时间一致性差。为了解决这些问题，我们提出了一个
通过设计帧保留的高保真图像到视频生成方法
基于预先训练的视频扩散模型的分支，名为 DreamVideo。
而不是将参考图像集成到扩散过程中
语义层面，我们的DreamVideo通过卷积感知参考图像
层并将特征与噪声潜在特征连接起来作为模型输入。经过
这意味着，可以最大程度地保留参考图像的细节
程度。此外，通过结合双条件无分类器
指导，单个图像可以通过以下方式定向到不同动作的视频
提供不同的提示文本。这对于
可控视频生成，具有广阔的应用前景。我们进行
对公共数据集进行全面的实验，包括定量和
定性结果表明我们的方法优于最先进的方法
方法。特别是在保真度方面，我们的模型具有强大的图像保留能力
与其他图像到视频模型相比，UCF101 具有较高的 FVD。还，
通过给出不同的文字提示，可以实现精确的控制。更远
我们模型的细节和综合结果将在
https://anonymous0769.github.io/DreamVideo/。
]]></description>
      <guid>http://arxiv.org/abs/2312.03018</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 MobileNetV2 增强乳腺癌肿瘤分类：对图像强度、错误缓解和 Streamlit 驱动的实时部署的详细探索。 （arXiv：2312.03020v1 [eess.IV]）</title>
      <link>http://arxiv.org/abs/2312.03020</link>
      <description><![CDATA[这项研究引入了一种基于
Google的MobileNetV2用于将乳腺癌肿瘤分类为正常、
良性和恶性类别，利用 1576 个超声图像的数据集
（265 例正常，891 例良性，420 例恶性）。该模型的准确率达到
0.82，精度为 0.83，召回率为 0.81，ROC-AUC 为 0.94，PR-AUC 为 0.88，以及
MCC 为 0.74。它检查图像强度分布和错误分类
错误，为未来的应用程序提供改进。寻址数据集
不平衡，该研究确保了一个可推广的模型。这项工作，使用数据集
来自埃及开罗巴赫亚医院，由 Walid Al-Dhabyani 等人编制，
强调MobileNetV2在医学成像方面的潜力，旨在提高
肿瘤学的诊断精度。此外，本文还探讨了
基于 Streamlit 的实时肿瘤分类部署，展示了
MobileNetV2 在医学成像中的适用性并为
肿瘤学诊断的未来研究。
]]></description>
      <guid>http://arxiv.org/abs/2312.03020</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>在多模态关系提取中，合成数据训练胜过真实数据。 （arXiv：2312.03025v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.03025</link>
      <description><![CDATA[多模态关系提取任务引起了重大研究
关注，但进展因缺乏可用培训而受到限制
数据。一种自然的想法是通过跨模式扩展现有数据集
生成模型。在本文中，我们考虑一个新颖的问题设置，其中
训练期间仅提供单峰数据（文本或图像）。我们的目标是
从合成数据中训练在真实情况下表现良好的多模态分类器
多模态测试数据。然而，使用合成数据进行训练有两个问题
障碍：缺乏数据多样性和标签信息丢失。为了缓解
问题，我们提出了相互信息感知的多模态迭代关系数据
GEeration (MI2RAGE)，将链式跨模态生成 (CCG) 应用于
促进生成数据的多样性并利用教师网络
选择具有高互信息的有价值的训练样本
地面实况标签。将我们的方法与合成数据的直接训练进行比较，
我们观察到合成文本的 F1 显着提高了 24.06%
合成图像的 F1 为 26.42%。值得注意的是，我们最好的模型完全训练
合成图像优于之前在真实图像上训练的最先进模型
F1 中的多模态数据领先 3.76%。我们的代码库将可供使用
接受后。
]]></description>
      <guid>http://arxiv.org/abs/2312.03025</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 LangChain 生成乳房超声报告。 (arXiv:2312.03013v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.03013</link>
      <description><![CDATA[乳房超声 (BUS) 是乳腺领域的重要诊断工具
成像，有助于早期检测和表征乳房
异常。解释乳房超声图像通常涉及创建
全面的医疗报告，包含重要信息以供及时评估
病人的情况。然而，超声成像系统需要
捕获各个部分的多个图像以编制一份报告，
提出了一项耗时的挑战。为了解决这个问题，我们建议
使用 Large 通过 LangChain 集成多个图像分析工具
语言模型（LLM），进入乳房报告过程。通过组合
通过LangChain指定的工具和文本生成，我们的方法可以
从超声图像中准确提取相关特征，并在其中解释它们
临床背景，并生成全面且标准化的报告。这
该方法不仅减轻了放射科医生和医疗保健人员的负担
专业人士的同时还提高了报告的一致性和质量。这
大量的实验表明，所提出的方法中涉及的每个工具都可以
提供定性和定量的显着结果。此外，
对生成的报告的临床评估表明，拟议的
方法可以以有临床意义的方式做出报告。
]]></description>
      <guid>http://arxiv.org/abs/2312.03013</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>天气和气候数据理解的基础模型：综合调查。 （arXiv：2312.03014v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03014</link>
      <description><![CDATA[随着人工智能 (AI) 的不断快速发展，
地球和大气科学越来越多地采用数据驱动的模型，
由深度学习 (DL) 的进步发展提供动力。具体来说，DL
技术被广泛用于解码混沌和非线性方面
地球系统，并通过了解天气来应对气候挑战
和气候数据。在较窄的范围内完成特定任务的尖端性能
最近通过深度学习实现了时空尺度。大的崛起
模型，特别是大型语言模型（LLM），已经启用了微调
在各种下游任务中产生显着成果的流程，
从而推动通用人工智能的进步。然而，我们仍然
探索针对天气和气候打造通用人工智能的初始阶段。
在本次调查中，我们对最先进的人工智能进行了详尽、及时的概述
专门为天气和气候数据设计的方法，具有
特别关注时间序列和文本数据。我们的主要覆盖范围包括
四个关键方面：天气和气候数据的类型、主要模型
架构、模型范围和应用程序以及天气和数据数据集
气候。此外，关于基金会的创建和应用
天气和气候数据理解模型，我们深入研究该领域
普遍存在的挑战，提供重要的见解，并提出详细的途径
未来的研究。这种综合方法使从业者能够
在此领域取得实质性进展所需的知识。我们的调查
概括了大型数据驱动研究的最新突破
天气和气候数据理解模型，强调稳健
基础、当前进展、实际应用、关键资源、
和前瞻性研究机会。
]]></description>
      <guid>http://arxiv.org/abs/2312.03014</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>PartSLIP++：通过多视图实例分割和最大似然估计增强低镜头 3D 零件分割。 （arXiv：2312.03015v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03015</link>
      <description><![CDATA[开放世界 3D 零件分割在多种应用中至关重要，例如
机器人技术和 AR/VR。传统的监督方法常常面临有限的问题
3D 数据可用性和难以推广到看不见的对象类别。
PartSLIP 是一项最新进展，在零和
少镜头 3D 零件分割。这是通过利用以下能力来实现的
2D 开放词汇检测模块 GLIP 的介绍，并引入启发式
将多视图 2D 边界框预测转换并提升为
3D 分割掩模。在本文中，我们介绍了 PartSLIP++，一种增强的
旨在克服其前身的局限性的版本。我们的方法
包含两项主要改进。首先，我们利用预先训练的 2D
分割模型 SAM，用于生成像素级 2D 分割，从而产生更多
与 PartSLIP 中使用的 2D 边界框相比，注释更加精确。
其次，PartSLIP++ 将启发式 3D 转换过程替换为
创新的改进的期望最大化算法。这个算法
将 3D 实例分割概念化为未观察到的潜在变量，并且
然后通过 2D-3D 匹配的交替过程迭代地细化它们
和梯度下降优化。通过广泛的评估，我们表明
PartSLIP++ 在低射中表现出比 PartSLIP 更好的性能
3D 语义和基于实例的对象部分分割任务。代码发布于
https://github.com/zyc00/PartSLIP2。
]]></description>
      <guid>http://arxiv.org/abs/2312.03015</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>具有对抗性损失的少样本异常检测，用于鲁棒的特征表示。 （arXiv：2312.03005v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.03005</link>
      <description><![CDATA[异常检测是一项关键且具有挑战性的任务，旨在识别
数据集中偏离正态模式和分布的数据点。
已经使用一类一模型方法提出了各种方法，但是
这些技术经常面临实际问题，例如内存效率低下和
训练时需要足够的数据。特别是少拍
异常检测给工业应用带来了重大挑战，
批量生产前可用的样品有限。在本文中，我们
提出一种集成对抗性的少样本异常检测方法
训练损失以获得更鲁棒和更通用的特征表示。我们
利用先前在域适应中使用的对抗性损失来对齐
源域和目标域之间的特征分布，以增强特征
少样本异常检测任务中的鲁棒性和泛化性。我们
假设对抗性损失在应用于以下特征时是有效的
应该具有相似的特征，例如来自同一层的特征
连体网络的并行分支或输入输出对
基于重建的方法。实验结果表明
所提出的方法通常在利用时获得更好的性能
对抗性损失。
]]></description>
      <guid>http://arxiv.org/abs/2312.03005</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>I-PHYRE：交互式物理推理。 （arXiv：2312.03009v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.03009</link>
      <description><![CDATA[当前的评估协议主要评估物理推理
固定场景，在评估智能体交互能力方面造成差距
与动态事件。虽然现代方法允许代理人修改初始
场景配置和观察后果，他们缺乏能力
与事件实时互动。为了解决这个问题，我们推出了 I-PHYRE，
挑战代理同时展示直观物理的框架
推理、多步骤规划和现场干预。在这里，直观
物理推理是指对物理学的快速、近似的理解
解决复杂的问题；多步骤表示需要广泛的序列
在 I-PHYRE 中进行规划，考虑到每次干预都会显着改变
后续选择；就地意味着及时对象的必要性
场景内的操作，微小的时间偏差可能会导致任务失败
失败。我们制定了四个游戏分组来审查代理的学习和
交互式物理推理基本原理的概括，
通过与代表性场景的互动来促进学习。我们的
探索涉及三个规划策略并检查几个受监督的
以及强化代理在 I-PHYRE 上的零样本泛化能力。这
结果凸显了现有学习算法与人类之间的显着差距
性能，强调需要进行更多研究以增强代理
具有交互式物理推理能力。环境和基线
将被公开。
]]></description>
      <guid>http://arxiv.org/abs/2312.03009</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>InstructBooth：遵循指令的个性化文本到图像生成。 （arXiv：2312.03011v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.03011</link>
      <description><![CDATA[使用有限的图像集个性化文本到图像模型
在特定主题图像生成中探索了特定对象。
然而，现有方法在与文本对齐方面经常遇到挑战
由于对有限的训练图像过度拟合而出现提示。在这项工作中，我们
介绍 InstructBooth，一种旨在增强图像文本的新颖方法
个性化文本到图像模型中的对齐。我们的方法首先是个性化
使用少量特定于主题的图像的文本到图像模型
唯一标识符。个性化后，我们对个性化进行微调
使用强化学习的文本到图像模型来最大化奖励
量化图像文本对齐。此外，我们建议补充
增加这两个过程之间的协同作用的技术。我们的方法
与基线相比，展示了卓越的图像文本对齐，同时
保持个性化能力。在人工评估中，InstructBooth
考虑到所有综合因素，其表现优于 DreamBooth。
]]></description>
      <guid>http://arxiv.org/abs/2312.03011</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>FocalPose++：通过渲染和比较进行焦距和物体姿势估计。 （arXiv：2312.02985v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02985</link>
      <description><![CDATA[我们引入了 FocalPose++，一种神经渲染和比较方法，用于联合
在给定单个 RGB 的情况下估计相机对象 6D 位姿和相机焦距
描绘已知物体的输入图像。这项工作的贡献是
三重。首先，我们推导出焦距更新规则，该规则扩展了现有的
最先进的渲染和比较 6D 姿态估计器来解决关节问题
估计任务。其次，我们研究了几种不同的损失函数
联合估计物体位姿和焦距。我们发现一个组合
直接焦距回归与重投影损失解开
平移、旋转和焦距的贡献导致改进
结果。第三，我们探讨了不同的合成训练数据对
我们方法的性能。具体来说，我们调查了不同
用于采样物体 6D 姿态和相机焦距的分布
渲染合成图像，并显示参数分布拟合
真实的训练数据效果最好。我们展示了三个具有挑战性的结果
在不受控制的设置中描述已知 3D 模型的基准数据集。我们
证明我们的焦距和 6D 姿态估计的误差低于
现有的最先进的方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.02985</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>用于驱动面部模拟的高效增量电位接触。 （arXiv：2312.02999v1 [cs.GR]）</title>
      <link>http://arxiv.org/abs/2312.02999</link>
      <description><![CDATA[我们提出了一种用于人脸动画的准静态有限元模拟器。
我们将面部建模为驱动的软体，可以有效地模拟
使用射影动力学（PD）。我们采用增量电位接触（IPC）来
处理自相交。然而，直接将IPC集成到仿真中
会阻碍 PD 求解器的高效率，因为刚度矩阵
全局步长不再是常数并且不能被预先分解。我们
请注意，受碰撞影响的实际顶点数只是
整个模型的一小部分，通过利用这一事实，我们有效地
减小要求解的线性系统的规模。随着提议的
碰撞优化方法，我们实现了高视觉保真度
性能开销相对较低。
]]></description>
      <guid>http://arxiv.org/abs/2312.02999</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉通过识别神经外科手术室中的仪器来提高手术效率：概念验证研究。 (arXiv:2312.03001v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.03001</link>
      <description><![CDATA[目标计算机视觉（CV）是人工智能的一个领域，
使机器能够解释和理解图像和视频。简历有
可能有助于手术室 (OR) 跟踪手术情况
仪器。我们建立了一个 CV 算法来识别手术器械
神经外科手术室作为外科手术的潜在解决方案
器械跟踪和管理，以减少手术浪费和开放
不必要的工具。方法 我们收集了 27 个常用图像的 1660 张图像
神经外科器械。使用 VGG 图像注释器对图像进行标记
并分成 80% 的训练集和 20% 的测试集以训练 U-Net
使用 5 折交叉验证的卷积神经网络。结果我们的U-Net
区分25个时工具识别准确率达到80-100%
仪器类别，其中 19/25 类别的准确度超过 90%。该模型
性能不足以对 Adson、Gerald 和 Debakey 进行细分
镊子，其准确度为 60-80%。结论 我们证明了
使用机器学习准确识别手术的可行性
仪器。器械识别有助于优化手术托盘
包装，减少工具使用和浪费，减少仪器发生率
误置事件，并协助安排日常仪器维护的时间。
需要更多的训练数据来提高所有手术的准确性
神经外科手术室中出现的仪器。这样的
技术有潜力被用作一种方法来证明什么
每种类型的手术都确实需要工具，使外科医生能够跨越不同的领域
世界以更少的资源做更多的事情。
]]></description>
      <guid>http://arxiv.org/abs/2312.03001</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>Diff-GO：以扩散目标为导向的通信，以实现超高频谱效率。 （arXiv：2312.02984v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.02984</link>
      <description><![CDATA[人工智能 (AI) 的最新进展呈现出许多
前所未有的机会，可以大大节省带宽
通讯。与专注于分组的传统通信系统不同
运输、丰富的数据集和人工智能使得高效传输成为可能
对消息接收者的目标最关键的信息。中的一个
生成式人工智能中最令人兴奋的进步被称为扩散模型，它提出了
设计超高速通信系统的独特机会
基于语言的消息。这项工作呈现了一种超高效的沟通方式
利用基于扩散模型的生成人工智能作为特定的设计
一般目标导向的沟通框架的示例。为了更好的控制
接收器输出处的再生消息，我们的扩散系统设计
包括具有有限维潜在噪声的局部再生模块。这
噪声潜伏控制和共享的重要意义在于我们
Diff-GO是引入“局部生成反馈”概念的能力
（Local-GF），使发射机能够监控质量并测量
语义系统接收器处的消息恢复的质量或准确性。到
为此，我们提出了一个新的低维噪声空间来训练
扩散模型，显着降低了通信开销
达到满意的消息恢复性能。我们的实验结果
证明所提出的噪声空间和​​基于扩散的生成
模型实现超高频谱效率和精确恢复
传输图像信号。通过权衡计算来换取带宽效率
（C4BE），这个新框架提供了实现卓越的重要途径
计算带宽权衡。
]]></description>
      <guid>http://arxiv.org/abs/2312.02984</guid>
      <pubDate>Thu, 07 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    </channel>
</rss>