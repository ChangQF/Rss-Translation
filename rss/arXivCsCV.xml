<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Wed, 31 Jan 2024 03:14:11 GMT</lastBuildDate>
    <item>
      <title>VR-GS：虚拟现实中的物理动力学感知交互式高斯溅射系统。 （arXiv：2401.16663v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.16663</link>
      <description><![CDATA[随着消费者虚拟现实 (VR) 和混合现实 (MR) 技术的发展
势头，人们越来越关注 3D 交互的发展
虚拟内容。不幸的是，传统的内容创建技术，
这些虚拟空间中的编辑和交互充满了
困难。它们往往不仅是工程密集型的，而且还需要
广泛的专业知识，这增加了虚拟现实中的挫败感和低效率
对象操纵。我们提出的 VR-GS 系统代表了一个飞跃
以人为本的 3D 内容交互，为用户提供无缝且直观的体验
经验。通过开发物理动力学感知的交互式高斯
在虚拟现实环境中泼溅，构建高效
两级嵌入策略以及变形体模拟，VR-GS
确保实时执行和高度逼真的动态响应。这
我们的虚拟现实系统的组件旨在实现高效率和
有效性，从详细的场景重建和对象开始
分割，通过多视图图像修复推进，并扩展到
基于物理的交互式编辑。该系统还集成了实时
变形嵌入和动态阴影投射，确保全面和
引人入胜的虚拟体验。我们的项目页面位于：
https://yingjian96.github.io/VR-GS/。
]]></description>
      <guid>http://arxiv.org/abs/2401.16663</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>使用模板匹配和 CNN 通过连接和终端检测来表征磁性迷宫结构。 （arXiv：2401.16688v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16688</link>
      <description><![CDATA[在材料科学中，表征周期性结构中的故障至关重要
用于了解材料特性。表征磁迷宫
模式，需要准确识别路口和终端，通常
每张图像都有超过一千个紧密排列的缺陷。这项研究
引入了一种称为 TM-CNN（模板匹配 - 卷积
神经网络）旨在检测图像中的大量小物体，例如
作为磁性迷宫图案中的缺陷。 TM-CNN 用于识别这些
444张实验图像中的结构，并对结果进行探索以加深
对磁性材料的认识。它采用两级检测
方法将初始检测中使用的模板匹配与
卷积神经网络，用于消除错误识别。到
训练一个CNN分类器，需要创建大量的训练
图片。这一困难阻碍了 CNN 在许多实际应用中的使用。
TM-CNN 显着减少了创建训练图像的手动工作量
自动进行大部分注释并只留下少量
对人类审阅者的更正。在测试中，TM-CNN 取得了令人印象深刻的 F1
得分为 0.988，远远优于传统模板匹配和基于 CNN 的
物体检测算法。
]]></description>
      <guid>http://arxiv.org/abs/2401.16688</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:10 GMT</pubDate>
    </item>
    <item>
      <title>超越图像-文本匹配：使用引导掩码的多模态转换器中的动词理解。 （arXiv：2401.16575v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.16575</link>
      <description><![CDATA[主要探测方法依赖于零样本性能
图像-文本匹配任务，以获得更细粒度的理解
最近的多模态图像语言转换器模型学习到的表示。
评估是在精心策划的数据集上进行的，重点关注
计数、关系、属性等。这项工作介绍了一个
另一种探测策略称为引导掩蔽。提议的方法
使用掩蔽消除不同的模式并评估模型的能力
高精度地预测屏蔽词。我们专注于研究多式联运
考虑对象获得的感兴趣区域 (ROI) 特征的模型
检测器作为输入令牌。我们使用引导探究对动词的理解
对 ViLBERT、LXMERT、UNTER 和 VisualBERT 进行掩蔽，并表明这些模型
可以高精度地预测正确的动词。这与之前的对比
从图像文本匹配探测技术中得出的结论经常
在需要动词理解的情况下失败。所有实验的代码
将公开 https://github.com/ivana-13/guided_masking。
]]></description>
      <guid>http://arxiv.org/abs/2401.16575</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>深入医学图像中的任何内容：比较研究。 （arXiv：2401.16600v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16600</link>
      <description><![CDATA[单目深度估计 (MDE) 是许多医学的重要组成部分
跟踪和映射算法，特别是内窥镜或腹腔镜的算法
视频。然而，由于地面实况深度图无法从真实的数据中获取
患者数据，监督学习不是预测深度的可行方法
医疗场景地图。尽管最近 MDE 的自监督学习
引起了人们的关注，但输出很难可靠地评估，并且每个 MDE 的
对其他患者和解剖结构的普遍适用性有限。这部作品
评估新发布的Depth Anything Model的零样本性能
医疗内窥镜和腹腔镜场景。我们比较准确度和
Depth Anything 与其他受一般训练的 MDE 模型的推理速度
场景以及基于内窥镜数据训练的域内模型。我们的发现
表明虽然 Depth Anything 的零样本能力相当
令人印象深刻的是，无论是速度还是速度，它都不一定比其他型号更好
表现。我们希望这项研究能够激发进一步的研究
医疗场景中 MDE 的基础模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.16600</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么、何时以及如何在大数据驱动的 3D 对象检测中使用主动学习来实现安全自动驾驶：实证探索。 （arXiv：2401.16634v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16634</link>
      <description><![CDATA[自动驾驶中 3D 物体检测的主动学习策略
数据集可能有助于解决数据不平衡、冗余和
高维数据。我们证明了熵查询的有效性
选择信息丰富的样本，旨在降低标注成本并改进模型
表现。我们尝试使用 BEVFusion 模型进行 3D 对象检测
nuScenes 数据集，将主动学习与随机采样进行比较
证明熵查询在大多数情况下都表现出色。方法是
在缩小大多数人与其他人之间的绩效差距方面特别有效
少数民族班级。特定于类别的分析揭示了
有限数据预算的注释资源，强调了
选择多样化且信息丰富的数据进行模型训练。我们的研究结果表明
熵查询是一种很有前途的选择数据的策略，可以增强
资源受限环境中的模型学习。
]]></description>
      <guid>http://arxiv.org/abs/2401.16634</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:09 GMT</pubDate>
    </item>
    <item>
      <title>使可动画面部头像的创建民主化。 （arXiv：2401.16534v1 [cs.GR]）</title>
      <link>http://arxiv.org/abs/2401.16534</link>
      <description><![CDATA[在高端视觉效果管道中，定制（且昂贵）的灯光
舞台系统（通常）用于扫描演员以获得两者
各种表达的几何和纹理。以民主化为目标，
我们提出了一种新颖的管道来获取几何和纹理以及
足够的表情信息来构建定制的特定人物动画
无需使用灯光舞台或任何其他高端硬件（或手动
清理）。一个关键的新颖想法包括扭曲现实世界的图像以使其与
模板头像的几何形状并随后投影扭曲的图像
进入模板头像的纹理；重要的是，这使我们能够利用
烘焙真实世界的照明/纹理信息以创建替代项
出于几何考虑，面部特征（并弥合域间隙）
重建。我们的方法不仅可以用来获得中性表达
几何和去光纹理，但它也可以用来改善头像
它们已被导入到动画系统中（请注意，此类导入倾向于
有损，同时还会产生各种特征的幻觉）。既然默认了
动画装备将包含不正确的模板表达式
对应于特定个体的那些，我们使用西蒙说的方法
捕捉各种表情并构建特定于人的动画装备（
像他们一样移动）。我们前面提到的扭曲/投影方法具有很高的
足够的功效来重建与每个表达式对应的几何形状。
]]></description>
      <guid>http://arxiv.org/abs/2401.16534</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:08 GMT</pubDate>
    </item>
    <item>
      <title>多标签学习的深度学习：综合调查。 （arXiv：2401.16549v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.16549</link>
      <description><![CDATA[多标签学习是一个快速发展的研究领域，旨在预测
来自单个输入数据点的多个标签。大数据时代，任务
涉及多标签分类 (MLC) 或排名呈现显着且
错综复杂的挑战，引起了不同领域的广泛关注。
MLC 固有的困难包括处理高维数据、
解决标签相关性，并处理部分标签，为此
传统方法被证明是无效的。近年来出现了引人注目的
越来越多地采用深度学习 (DL) 技术来应对这些挑战
在 MLC 中更有效。值得注意的是，人们正在迅速努力利用
深度学习的强大学习能力可改进标签依赖性建模
以及 MLC 中的其他挑战。但值得注意的是，综合
专门针对多标签学习的深度学习的研究很有限。
因此，本次调查旨在彻底回顾深度学习的最新进展
多标签学习，以及 MLC 中开放研究问题的总结。
该审查整合了 MLC DL 的现有研究工作，包括深度学习
神经网络、变压器、自动编码器以及卷积和循环
架构。最后，本研究进行了比较分析
现有方法提供富有洞察力的观察并激发未来
该领域的研究方向。
]]></description>
      <guid>http://arxiv.org/abs/2401.16549</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:08 GMT</pubDate>
    </item>
    <item>
      <title>IEEE BigData 2023 击键验证挑战赛 (KVC)。 （arXiv：2401.16559v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16559</link>
      <description><![CDATA[本文描述了 IEEE BigData 2023 击键结果
验证挑战（KVC），考虑生物识别验证
击键动力学 (KD) 的性能，捕获为长推文序列
来自超过 185,000 个受试者的可变转录文本。数据来自
迄今为止最大的两个 KD 公共数据库：Aalto Desktop 和
移动击键数据库，保证每个主题的数据量最少，
年龄和性别注释，没有损坏的数据，并避免过度
就所考虑的人口统计而言，主题分布不平衡
属性。参与者提出了几种神经架构，
导致全球等错误率 (EER) 低至 3.33%，并达到 3.61%
分别由桌面端和移动端场景的最佳团队打造，表现优于
KD 目前最先进的生物识别验证性能。主办
在 CodaLab 上，KVC 将持续成为一个有用的工具
研究团体在同一实验下比较不同的方法
条件，加深对该领域的了解。
]]></description>
      <guid>http://arxiv.org/abs/2401.16559</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:08 GMT</pubDate>
    </item>
    <item>
      <title>用新的基元扩展快速运动的运动学理论。 （arXiv：2401.16519v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16519</link>
      <description><![CDATA[快速运动的运动学理论及其相关的西格玛对数正态分布，
二维时空轨迹模型。它主要被构建为一个时间
虚拟目标点之间的曲线重叠。具体来说，它使用圆弧
和对数正态作为轨迹表示的原语和
速度，分别。本文建议开发这个模型，我们
称为运动学理论变换，它建立了一个数学框架
允许使用更多原语。主要是，我们评估欧拉曲线
连接虚拟目标点和高斯、Beta、Gamma、双界对数正态、
和广义极值函数来模拟钟形速度
轮廓。使用这些原语，我们报告重建结果
人类、动物和人类所执行的时空轨迹
拟人化机器人。
]]></description>
      <guid>http://arxiv.org/abs/2401.16519</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:07 GMT</pubDate>
    </item>
    <item>
      <title>MT-HCCAR：具有分层分类和基于注意力的回归的多任务深度学习，用于云属性检索。 （arXiv：2401.16520v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.16520</link>
      <description><![CDATA[在地球科学领域，有效的云属性检索，
包括云掩蔽、云相分类和云光学
厚度（COT）预测仍然至关重要。传统方法论
由于每个传感器仪器的独特性，因此需要不同的模型
光谱特性。地球科学研究的最新进展
采用机器学习和深度学习技术来提取特征
卫星数据集的光谱观测。然而，主流方法缺乏
考虑检索之间层次关系的新颖架构
任务。此外，考虑到现有传感器之间的光谱多样性，
开发具有强大泛化能力的模型
传感器数据集势在必行。令人惊讶的是，缺乏方法论
解决针对不同数据集选择最佳模型的问题。作为回应，
本文介绍了MT-HCCAR，一种端到端深度学习模型，采用
多任务学习同时解决云掩蔽、云相
检索（分类任务）和 COT 预测（回归任务）。这
MT-HCCAR 集成了分层分类网络 (HC) 和
分类辅助基于注意力的回归网络（CAR），增强
云标记和 COT 预测的精度和鲁棒性。另外，一个
植根于 K 折交叉验证的综合模型选择方法，一种
标准错误规则，并提出了两个引入的性能分数
在三个模拟卫星数据集 OCI、VIIRS 上选择最佳模型，
和阿比。 MT-HCCAR 与基线方法比较的实验，消融
研究和模型选择肯定了其优越性和泛化性
MT-HCCAR 的功能。
]]></description>
      <guid>http://arxiv.org/abs/2401.16520</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:07 GMT</pubDate>
    </item>
    <item>
      <title>用于 HSI 场景上波段选择的 Dropout 具体自动编码器。 （arXiv：2401.16522v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16522</link>
      <description><![CDATA[基于深度学习的高光谱信息波段选择方法
图像（HSI）最近受到了强烈关注，以消除光谱
相关性和冗余。然而，现有的基于深度学习的方法
要么需要额外的后处理策略来选择描述性
由于无法参数化，因此可以间接优化模型
用于选择过程的离散变量。为了克服这些
局限性，这项工作提出了一种新颖的端到端网络信息频带
选择。所提出的网络的灵感来自混凝土的进步
自动编码器（CAE）和 dropout 特征排序策略。不同于
基于传统深度学习的方法，对所提出的网络进行训练
直接给出所需的频段子集，无需进一步
后期处理。四个 HSI 场景的实验结果表明，所提出的方法
辍学者 CAE 取得了实质性且有效的绩效水平
竞争方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.16522</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:07 GMT</pubDate>
    </item>
    <item>
      <title>DressCode：根据文本指导自动缝纫和生成服装。 （arXiv：2401.16465v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16465</link>
      <description><![CDATA[服装在人类外表中的重要作用凸显了其重要性
服装数字化，用于数字人类创作。 3D 的最新进展
内容创作对于数字人类创作至关重要。尽管如此，服装
从文本指导生成仍处于萌芽阶段。我们引入了文本驱动的 3D
服装生成框架 DressCode，旨在使设计民主化
新手在时装设计、虚拟试穿和
数字人类创作。对于我们的框架，我们首先引入 SewingGPT，一个
基于 GPT 的架构将交叉注意力与文本调节相结合
嵌入以生成带有文本指导的缝纫图案。我们还定制了一个
预训练的稳定扩散，用于高质量、基于图块的 PBR 纹理
一代。通过利用大型语言模型，我们的框架生成
通过自然语言交互制作适合 CG 的服装。我们的方法也
促进图案完成和纹理编辑，简化了流程
设计师通过用户友好的交互。通过综合评价和
与其他最先进的方法相比，我们的方法展示了最好的
质量以及与输入提示的一致性。用户研究进一步验证了我们的
高质量的渲染效果，凸显其实用性和
生产环境中的潜力。
]]></description>
      <guid>http://arxiv.org/abs/2401.16465</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:06 GMT</pubDate>
    </item>
    <item>
      <title>按照人类指令进行高质量图像恢复。 （arXiv：2401.16468v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16468</link>
      <description><![CDATA[图像恢复是一个基本问题，涉及恢复
从其退化的观察中获得高质量的清晰图像。多合一图像
恢复模型可以有效恢复各种类型和级别的图像
使用退化特定信息作为提示来指导退化
恢复模型。在这项工作中，我们提出了第一种方法，该方法使用
人工编写的指令来指导图像恢复模型。赋予自然
语言提示，我们的模型可以从退化的图像中恢复高质量的图像
对应的，考虑多种降解类型。我们的方法，InstructIR，
在包括图像在内的多项恢复任务上取得了最先进的结果
去噪、去雨、去模糊、去雾和（低光）图像增强。
InstructIR 比以前的一体化恢复方法提高了 +1dB。
此外，我们的数据集和结果代表了新研究的新基准
文本引导图像恢复和增强。我们的代码、数据集和模型
位于：https://github.com/mv-lab/InstructIR
]]></description>
      <guid>http://arxiv.org/abs/2401.16468</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:06 GMT</pubDate>
    </item>
    <item>
      <title>SHViT：具有内存高效宏设计的单头视觉变压器。 （arXiv：2401.16456v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16456</link>
      <description><![CDATA[最近，高效的 Vision Transformer 在低功耗的情况下表现出了出色的性能
资源受限设备上的延迟。按照惯例，他们使用 4x4 补丁
宏观层面的嵌入和 4 级结构，同时利用
微观层面上多头配置的复杂关注。这
论文旨在解决所有设计级别的计算冗余问题
内存高效的方式。我们发现使用较大步幅的 patchify 茎不会
不仅降低了内存访问成本，还通过以下方式实现了有竞争力的性能
利用令牌表示来减少早期的空间冗余
阶段。此外，我们的初步分析表明，注意力层
早期阶段可以用卷积代替，并且需要注意一些
后面阶段的磁头在计算上是多余的。为了处理这个问题，我们
引入一个单头注意力模块，本质上可以防止头
冗余并同时通过并行组合全局来提高准确性
和当地信息。基于我们的解决方案，我们推出了 SHViT，
获得最先进速度精度的单头视觉变压器
权衡。例如，在 ImageNet-1k 上，我们的 SHViT-S4 是 3.3x、8.1x 和 2.4x
在 GPU、CPU 和 iPhone12 移动设备上比 MobileViTv2 x1.0 更快，
分别提高了 1.3% 的准确率。用于对象检测和实例
使用 Mask-RCNN 头对 MS COCO 进行分割，我们的模型实现了性能
与 FastViT-SA12 相当，同时主干线降低 3.8 倍和 2.0 倍
分别是 GPU 和移动设备上的延迟。
]]></description>
      <guid>http://arxiv.org/abs/2401.16456</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:05 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散先验桥接生成模型和判别模型，实现统一视觉感知。 （arXiv：2401.16459v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.16459</link>
      <description><![CDATA[扩散模型在图像生成方面的卓越能力刺激了
努力将其应用扩展到生成任务之外。然而，一个
缺乏统一的扩散方法是持续存在的挑战
具有不同语义粒度的视觉感知任务模型
要求。我们的目的是建立统一的视觉感知
框架，利用生成性和生成性之间的潜在协同作用
判别模型。在本文中，我们推荐苦艾酒，一种简单但
包含预训练稳定扩散（SD）模型的有效框架
包含丰富的生成先验，一个统一的头（U-head）能够
整合层次表示，并提供适应的专家
歧视性先验。全面调查揭示潜力
苦艾酒的特征，例如不同的感知粒度
隐藏在不同时间步长和不同 U 网阶段的潜在变量中。
我们强调，没有必要纳入重量级或
复杂的解码器将扩散模型转换为有效的表示
学习者。针对定制歧视进行广泛的比较评估
模型展示了我们的方法对基于零样本草图的图像的有效性
检索 (ZS-SBIR)、少样本分类和开放词汇语义
分割任务。有希望的结果证明了潜力
扩散模型作为强大的学习者，确立了它们在
提供信息丰富且强大的视觉表示。
]]></description>
      <guid>http://arxiv.org/abs/2401.16459</guid>
      <pubDate>Wed, 31 Jan 2024 03:14:05 GMT</pubDate>
    </item>
    </channel>
</rss>