<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 08 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>BirdNeRF：从航空图像中快速神经重建大规模场景</title>
      <link>https://arxiv.org/abs/2402.04554</link>
      <description><![CDATA[在这项研究中，我们介绍了 BirdNeRF，它是神经辐射场 (NeRF) 的一种改进，专为使用航空图像重建大规模场景而设计。与之前专注于小规模和以对象为中心的 NeRF 重建的研究不同，我们的方法解决了多个挑战，包括（1）解决与大型模型相关的缓慢训练和渲染的问题。 (2) 满足大量图像建模所需的计算需求，需要大量资源，例如高性能 GPU。 （3）克服由于模型容量有限而在大规模重建任务中常见的明显伪影和低视觉保真度。具体来说，我们提出了一种新颖的基于鸟瞰姿势的空间分解算法，该算法将大型航空图像集分解为多个具有适当大小重叠的小集，使我们能够训练子场景的单独 NeRF。这种分解方法不仅将渲染时间与场景大小解耦，而且使渲染能够无缝缩放到任意大的环境。此外，它允许对环境进行逐块更新，增强了重建过程的灵活性和适应性。此外，我们提出了一种投影引导的新颖视图重新渲染策略，有助于有效利用独立训练的子场景来生成出色的渲染结果。我们在现有数据集以及我们自己的无人机镜头上评估了我们的方法，在具有相似渲染质量的单个 GPU 上，将重建速度比经典摄影测量软件提高了 10 倍，比最先进的大规模 NeRF 解决方案提高了 50 倍。]]></description>
      <guid>https://arxiv.org/abs/2402.04554</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:24 GMT</pubDate>
    </item>
    <item>
      <title>FM-Fusion：视觉语言基础模型推动的实例感知语义映射</title>
      <link>https://arxiv.org/abs/2402.04555</link>
      <description><![CDATA[基于监督对象检测器的语义映射对图像分布敏感。在现实环境中，对象检测和分割性能可能会导致大幅下降，从而阻碍了语义映射在更广泛的领域中的使用。另一方面，视觉语言基础模型的开发展示了跨数据分布的强大的零样本可迁移性。它提供了构建可概括的实例感知语义图的机会。因此，这项工作探讨了如何通过基础模型生成的对象检测来增强实例感知语义映射。我们提出了一种概率标签融合方法来从开放集标签测量中预测封闭集语义类。实例细化模块合并由于分割不一致而导致的过度分割实例。我们将所有模块集成到一个统一的语义映射系统中。读取 RGB-D 输入序列，我们的工作逐步重建实例感知语义图。我们评估了我们的方法在 ScanNet 和 SceneNN 数据集中的零样本性能。我们的方法在 ScanNet 语义实例分割任务上实现了 40.3 的平均精度 (mAP)。它显着优于传统的语义映射方法。]]></description>
      <guid>https://arxiv.org/abs/2402.04555</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:24 GMT</pubDate>
    </item>
    <item>
      <title>BioDrone：基于仿生无人机的单目标跟踪基准，用于鲁棒视觉</title>
      <link>https://arxiv.org/abs/2402.04519</link>
      <description><![CDATA[单目标跟踪（SOT）是计算机视觉中的一个基本问题，具有广泛的应用，包括自动驾驶、增强现实和机器人导航。 SOT 的鲁棒性面临两个主要挑战：微小目标和快速运动。这些挑战在无人机 (UAV) 拍摄的视频中尤其明显，其中目标通常距离摄像机很远，并且通常相对于摄像机有显着的运动。为了评估 SOT 方法的稳健性，我们提出了 BioDrone——第一个基于仿生无人机的 SOT 视觉基准。与现有的无人机数据集不同，BioDrone 具有从扑翼无人机系统捕获的视频，由于其空气动力学特性，相机抖动较大。因此，BioDrone 强调跟踪连续帧之间发生剧烈变化的微小目标，为 SOT 提供新的稳健视觉基准。迄今为止，BioDrone 提供了最大的基于无人机的 SOT 基准，具有高质量的细粒度手动注释，并自动生成帧级标签，专为稳健的视觉分析而设计。利用我们提出的 BioDrone，我们对现有 SOT 方法进行了系统评估，比较了 20 个代表性模型的性能，并研究了优化 SOTA 方法（KeepTrack KeepTrack）以实现稳健 SOT 的新方法。我们的评估为稳健的 SOT 提供了新的基线和见解。展望未来，我们希望 BioDrone 不仅能够成为稳健 SOT 的高质量基准，而且还能引发未来对稳健计算机视觉的研究。数据库、工具包、评估服务器和基线结果可在 http://biodrone.aitestunion.com 上获取。]]></description>
      <guid>https://arxiv.org/abs/2402.04519</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:23 GMT</pubDate>
    </item>
    <item>
      <title>BRI3L：用于识别和定位幻觉感知区域的亮度幻觉图像数据集</title>
      <link>https://arxiv.org/abs/2402.04541</link>
      <description><![CDATA[视觉错觉在理解视觉感知方面发挥着重要作用。目前理解和评估视错觉的方法大多是基于确定性过滤的方法，它们对少数视错觉进行评估，因此得出的结论并不通用。为此，我们生成了包含五种亮度错觉的 22,366 张图像的大型数据集（BRI3L：用于识别和定位错觉感知的亮度错觉图像数据集），并使用基于数据驱动的神经网络的方法对数据集进行基准测试。数据集包含标签信息 - (1) 特定图像是否是虚幻的/非虚幻的，(2) 图像虚幻区域的分割掩模。因此，可以使用该数据集来评估分类和分割任务。我们遵循涉及人类受试者的标准心理物理学实验来验证数据集。据我们所知，这是首次尝试使用数据驱动的方法来开发视觉错觉数据集和基准来进行错觉分类和定位。我们考虑五种经过充分研究的亮度错觉类型：1) 赫尔曼网格，2) 同步亮度对比度，3) 白色错觉，4) 网格错觉，以及 5) 诱导光栅错觉。对数据集进行基准测试，错觉识别准确率达到 99.56%，错觉定位像素准确率达到 84.37%。研究表明，深度学习模型的应用也概括了看不见的亮度错觉，例如亮度同化到对比度过渡。我们还测试了最先进的扩散模型产生亮度错觉的能力。我们在 github 存储库中提供了所有代码、数据集、说明等：https://github.com/aniket004/BRI3L]]></description>
      <guid>https://arxiv.org/abs/2402.04541</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:23 GMT</pubDate>
    </item>
    <item>
      <title>ColorSwap：用于多模式评估的颜色和词序数据集</title>
      <link>https://arxiv.org/abs/2402.04492</link>
      <description><![CDATA[本文介绍了 ColorSwap 数据集，旨在评估和提高多模态模型将对象与其颜色匹配的熟练程度。该数据集由 2,000 个独特的图像标题对组成，分为 1,000 个示例。每个示例都包含一个标题-图像对，以及一个“颜色交换”对。我们遵循 Winoground 模式：示例中的两个标题具有相同的单词，但颜色单词已重新排列以修改不同的对象。该数据集是通过自动字幕和图像生成与人类参与循环的新颖结合而创建的。我们评估了图像文本匹配（ITM）和视觉语言模型（VLM），发现即使是最新的模型在这项任务上仍然不够稳健。 GPT-4V 和 LLaVA 在我们的主要 VLM 指标上得分为 72% 和 42%，尽管它们可能会通过更先进的提示技术而有所改善。在主要 ITM 指标上，CLIP 和 SigLIP 等对比模型的表现接近机会（分别为 12% 和 30%），尽管非对比 BLIP ITM 模型更强（87%）。我们还发现，对少于 2,000 个示例进行微调可以在这种非分布词序理解任务中带来显着的性能提升。数据集位于：https://github.com/Top34051/colorswap。]]></description>
      <guid>https://arxiv.org/abs/2402.04492</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:22 GMT</pubDate>
    </item>
    <item>
      <title>Text2Street：街景的可控文本到图像生成</title>
      <link>https://arxiv.org/abs/2402.04504</link>
      <description><![CDATA[随着扩散模型的出现，文本到图像的生成取得了显着的进步。然而，基于文本生成街景图像仍然是一项艰巨的任务，主要是因为街景的道路拓扑复杂，交通状况多样，天气条件多样，​​这使得传统的文本到图像模型很难对付。为了应对这些挑战，我们提出了一种新颖的可控文本到图像框架，名为 \textbf{Text2Street}。在该框架中，我们首先引入了车道感知的道路拓扑生成器，它通过配备计数适配器的准确的道路结构和车道线实现文本到地图的生成，实现可控的道路拓扑生成。然后，提出基于位置的对象布局生成器，通过对象级边界框扩散策略获得文本到布局的生成，实现可控交通对象布局生成。最后，设计了多控制图像生成器，集成道路拓扑、物体布局和天气描述，实现可控街景图像生成。大量实验表明，所提出的方法实现了可控街景文本到图像的生成，并验证了 Text2Street 街景框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.04504</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:22 GMT</pubDate>
    </item>
    <item>
      <title>数字像素传感器综述</title>
      <link>https://arxiv.org/abs/2402.04507</link>
      <description><![CDATA[数字像素传感器 (DPS) 已发展成为现代成像系统的关键组件，具有彻底改变医学成像、天文学、监控、物联网设备等各个领域的潜力。与模拟像素传感器相比，DPS 提供高速和良好的图像质量。然而，每个像素内引入的固有复杂性（主要归因于 ADC 电路的调节）导致像素间距大幅增加。不幸的是，像素间距的显着增加极大地破坏了实现高密度集成的可行性，这是显着缩小潜在应用领域的障碍。尽管如此，设计紧凑的转换电路以及 3D 架构范例的战略集成可能是解决当前情况的潜在补救措施。这篇评论文章全面概述了 DPS 技术的广阔领域。分析了不同类型DPS电路的工作原理、优点和挑战。我们根据 ADC 操作将方案分为几类。还展示了基于不同性能指标的比较研究，以实现全面的理解。]]></description>
      <guid>https://arxiv.org/abs/2402.04507</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:22 GMT</pubDate>
    </item>
    <item>
      <title>Web 导航的双视图视觉情境化</title>
      <link>https://arxiv.org/abs/2402.04476</link>
      <description><![CDATA[自动网络导航旨在构建一个网络代理，可以按照语言指令在现实网站上执行复杂多样的任务。现有的工作主要以 HTML 文档作为输入，定义网页的内容和操作空间（即可操作元素和操作）。然而，HTML 文档可能无法为每个元素提供清晰的任务相关上下文，因此很难选择正确的操作（序列）。在本文中，我们建议通过网页屏幕截图中的“双视图”将 HTML 元素置于上下文中：每个 HTML 元素在屏幕截图中都有其相应的边界框和视觉内容。我们基于这样的见解——Web 开发人员倾向于在网页上附近排列与任务相关的元素，以增强用户体验——并建议使用文本和视觉功能将每个元素与其相邻元素置于上下文中。 HTML 元素的结果表示可以为代理采取行动提供更多信息。我们在最近发布的 Mind2Web 数据集上验证了我们的方法，该数据集在现实网站上具有不同的导航域和任务。我们的方法在所有场景中始终优于基准，包括跨任务、跨网站和跨域。]]></description>
      <guid>https://arxiv.org/abs/2402.04476</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:21 GMT</pubDate>
    </item>
    <item>
      <title>BEBLID：提升高效的二进制局部图像描述符</title>
      <link>https://arxiv.org/abs/2402.04482</link>
      <description><![CDATA[局部图像特征的有效匹配是许多计算机视觉应用中的一项基本任务。然而，由于硬件的简单性和有限的能源供应，顶级匹配算法的实时性能在计算能力有限的设备（例如手机或无人机）中受到影响。在本文中，我们介绍了 BEBLID，一种高效的学习二值图像描述符。它改进了我们之前的实值描述符 BELID，使其匹配更高效、更准确。为此，我们使用 AdaBoost 和改进的弱学习器训练方案，以产生更好的局部描述。此外，我们通过强制所有弱学习器在强学习器组合中具有相同的权重来对描述符进行二值化，并在不平衡的数据集中对其进行训练，以解决匹配和​​检索任务中出现的不对称问题。在我们的实验中，BEBLID 实现了接近 SIFT 的精度，并且比文献中最快的算法 ORB 更好的计算效率。]]></description>
      <guid>https://arxiv.org/abs/2402.04482</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:21 GMT</pubDate>
    </item>
    <item>
      <title>用于口腔罕见疾病牙齿检测、分割和编号的检测变压器：关注数据增强和修复技术</title>
      <link>https://arxiv.org/abs/2402.04408</link>
      <description><![CDATA[在这项工作中，我们专注于口腔罕见疾病背景下的深度学习图像处理，由于数据可用性有限，这带来了挑战。关键的一步涉及全景X光照片中的牙齿检测、分割和编号。为此，我们使用了一个数据集，该数据集由 156 张患有罕见口腔疾病的个体的全景 X 光照片组成，并由专家标记。我们训练了用于牙齿检测、分割和对 52 个牙齿类别进行编号的检测变压器 (DETR) 神经网络。此外，我们还使用了数据增强技术，包括几何变换。最后，我们通过从全景放射照片中移除牙齿并将牙齿整合到其中，使用具有稳定扩散的修复技术生成新的全景图像。结果显示，在没有数据增强的情况下，DETR 的 mAP 超过 0.69。当使用数据增强技术时，mAP 提高到 0.82。此外，我们在使用通过修复技术生成的新全景射线照片时观察到了有希望的性能，mAP 为 0.76。]]></description>
      <guid>https://arxiv.org/abs/2402.04408</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:20 GMT</pubDate>
    </item>
    <item>
      <title>通过从网络规模多模态数据检索实现无监督域泛化的以数据为中心的方法</title>
      <link>https://arxiv.org/abs/2402.04416</link>
      <description><![CDATA[域泛化（DG）是一个重要问题，它学习一种模型，该模型可以在共享标签空间的假设下利用一个或多个源域泛化到看不见的测试域。然而，大多数 DG 方法都假设可以访问目标标签空间中的丰富源数据，事实证明，这一要求对于众多现实世界的应用来说过于严格，在这些应用中，获取与目标任务相同的标签空间的成本过高。对于此设置，我们解决无监督域泛化 (UDG) 问题的多模式版本，该问题在微调期间使用大型与任务无关的未标记源数据集，例如 LAION-2B。我们的框架没有明确假设源数据集和目标任务之间的任何关系。相反，它仅依赖于可以在联合视觉语言空间中有效搜索源数据集的前提。对于这种多模式 UDG 设置，我们提出了一种新颖的方法，通过三个简单的步骤构建源数据的小型（$&lt;$100K）子集：（1）使用标签名称作为查询进行多样化检索，（2）排名伪标签， (3)聚类寻找代表性样本。为了证明研究多模态 UDG 问题的价值，我们将我们的结果与最先进的无源 DG 和零样本 (ZS) 方法在各自的基准上进行了比较，并显示在 20 上精度提高了 10%多样化的目标数据集。此外，我们的多阶段数据集构建方法比最近邻检索平均提高了 3%。代码可用：https://github.com/Chris210634/mudg]]></description>
      <guid>https://arxiv.org/abs/2402.04416</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:20 GMT</pubDate>
    </item>
    <item>
      <title>BAdaCost：带有成本的多类别提升</title>
      <link>https://arxiv.org/abs/2402.04465</link>
      <description><![CDATA[我们提出了 BAdaCost，一种多类成本敏感的分类算法。它结合了一组成本敏感的多类弱学习器，在Boosting框架内获得强分类规则。为了推导该算法，我们引入了 CMEL，一种成本敏感的多类指数损失，它概括了在各种分类算法（例如 AdaBoost、SAMME、成本敏感的 AdaBoost 和 PIBoost）中优化的损失。因此将它们统一在一个共同的理论框架下。在进行的实验中，我们证明与以前的多类成本敏感方法相比，BAdaCost 在性能方面取得了显着的进步。所提出的算法在非对称多类分类中的优势也在实际的多视图人脸和汽车检测问题中得到了评估。]]></description>
      <guid>https://arxiv.org/abs/2402.04465</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:20 GMT</pubDate>
    </item>
    <item>
      <title>路面缺陷检测——从基于图像到非图像：一项调查</title>
      <link>https://arxiv.org/abs/2402.04297</link>
      <description><![CDATA[确保交通安全至关重要，这就需要对路面缺陷进行检测和预防。因此，人们对该主题的文献越来越感兴趣，从而导致了各种路面缺陷检测方法的发展。根据输入数据类型或训练方法，检测道路缺陷的方法可以以多种方式分类。主要方法涉及基于图像的方法，该方法分析像素强度和表面纹理以识别缺陷。尽管基于图像的方法很受欢迎，但它具有明显的局限性，即容易受到天气和光照变化的影响。为了解决这个问题，研究人员探索了使用额外的传感器，例如激光扫描仪或激光雷达，提供明确的深度信息，从而能够检测尺寸和体积的缺陷。然而，对图像之外的数据的探索尚未得到充分研究。在这篇调查论文中，我们对路面缺陷检测研究进行了全面的回顾，并根据输入数据类型和使用的方法对它们进行了分类。此外，我们回顾了最近提出的非基于图像的方法，并讨论了与这些技术相关的几个挑战和开放问题。]]></description>
      <guid>https://arxiv.org/abs/2402.04297</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:19 GMT</pubDate>
    </item>
    <item>
      <title>ConsistI2V：增强图像到视频生成的视觉一致性</title>
      <link>https://arxiv.org/abs/2402.04324</link>
      <description><![CDATA[图像到视频 (I2V) 生成旨在使用初始帧（连同文本提示）创建视频序列。 I2V 生成的一个巨大挑战是保持整个视频的视觉一致性：现有方法通常很难从第一帧开始保持主题、背景和风格的完整性，并确保视频叙事中的流畅和逻辑进展。为了缓解这些问题，我们提出了 ConsistI2V，这是一种基于扩散的方法，用于增强 I2V 生成的视觉一致性。具体来说，我们引入（1）对第一帧的时空注意力以保持空间和运动一致性，（2）从第一帧的低频带进行噪声初始化以增强布局一致性。这两种方法使 ConsistI2V 能够生成高度一致的视频。我们还扩展了所提出的方法，以展示其提高自回归长视频生成和相机运动控制一致性的潜力。为了验证我们方法的有效性，我们提出了 I2V-Bench，一个 I2V 生成的综合评估基准。我们的自动和人工评估结果证明了 ConsistI2V 相对于现有方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.04324</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:19 GMT</pubDate>
    </item>
    <item>
      <title>打破数据孤岛：来自独立私人来源的多智能体感知的跨域学习</title>
      <link>https://arxiv.org/abs/2402.04273</link>
      <description><![CDATA[多智能体感知系统中的不同智能体可能来自不同的公司。每个公司都可能使用相同的基于经典神经网络架构的编码器来进行特征提取。然而，训练各个智能体的数据源在每个公司都是独立和私有的，导致多智能体感知系统中用于训练不同智能体的不同私有数据的分布差距。上述分布差距造成的数据孤岛可能会导致多智能体感知性能显着下降。在本文中，我们彻底研究了分配差距对现有多智能体感知系统的影响。为了打破数据孤岛，我们引入了用于跨域学习的特征分布感知聚合（FDA）框架，以缓解多智能体感知中的上述分布差距。 FDA 包含两个关键组件：可学习特征补偿模块和分布感知统计一致性模块，两者都旨在增强中间特征以最小化多代理特征之间的分布差距。对公共 OPV2V 和 V2XSet 数据集的密集实验强调了 FDA 在基于点云的 3D 对象检测方面的有效性，将其视为对现有多智能体感知系统的宝贵增强。]]></description>
      <guid>https://arxiv.org/abs/2402.04273</guid>
      <pubDate>Thu, 08 Feb 2024 18:16:18 GMT</pubDate>
    </item>
    </channel>
</rss>