<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Thu, 04 Jan 2024 03:15:00 GMT</lastBuildDate>
    <item>
      <title>土地利用土地覆盖的深度自回归建模。 （arXiv：2401.01395v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01395</link>
      <description><![CDATA[由于长距离，土地利用/土地覆盖 (LULC) 建模是一项具有挑战性的任务
地理特征和相关的不同空间模式之间的依赖性
地形、生态和人类发展。我们确定了密切的联系
土地利用空间模式建模与图像任务之间
从计算机视觉进行修复并对修改后的 PixelCNN 进行研究
具有约 1900 万个用于 LULC 建模的参数的架构。在
与基准空间统计模型比较，我们发现前者
能够捕获更丰富的空间相关模式，例如道路
和水体，但不会产生校准的预测分布，
表明需要进行额外的调整。我们找到了预测的证据
重要的生态相关土地利用的分散不足
诸如补丁数和邻接性之类的统计数据可以改进为一些
通过操纵抽样变异性来确定程度。
]]></description>
      <guid>http://arxiv.org/abs/2401.01395</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>SwapTransformer：通过 OSHA 数据集上的模仿学习的高速公路超车战术规划器模型。 （arXiv：2401.01425v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.01425</link>
      <description><![CDATA[本文研究了高速公路的高层决策问题
有关变道和超越其他速度较慢的车辆的场景。在
特别是，本文旨在改进自动驾驶的旅行辅助功能
高速公路上的超车和变道。约 900 万个样本，包括泳道
在模拟中收集图像和其他动态对象。该数据；
发布模拟高速公路超车 (OSHA) 数据集来解决此问题
挑战。为了解决这个问题，一个名为 SwapTransformer 的架构是
作为 OSHA 数据集上的模仿学习方法进行设计和实施。
而且，未来点、车距网络等辅助任务
提出预测是为了帮助模型更好地理解
周边环境。所提出解决方案的性能比较
具有多层感知器（MLP）和多头自注意力网络
模拟环境中的基线。我们还展示了
有和没有辅助任务的模型。所有模型的评估基于
不同的指标，例如完成每圈的时间、超车次数，以及
与速度限制的速度差。评估表明，
SwapTransformer模型在不同流量密度下优于其他模型
在推理阶段。
]]></description>
      <guid>http://arxiv.org/abs/2401.01425</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>基于越野 LiDAR 强度的语义分割。 （arXiv：2401.01439v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01439</link>
      <description><![CDATA[LiDAR用于自动驾驶，提供3D空间信息和
在越野环境中实现准确感知，帮助克服障碍
检测、绘图和路径规划。基于学习的激光雷达语义
分割利用机器学习技术自动分类
LiDAR 点云中的对象和区域。基于学习的模型陷入困境
由于存在不同物体的越野环境
颜色、纹理和未定义的边界，这可能会导致困难
使用传统的基于几何的方法准确地分类和分割对象
特征。在本文中，我们通过利用激光雷达来解决这个问题
强度参数以增强越野环境中的对象分割。
我们的方法在 RELLIS-3D 数据集中进行了评估，并取得了有希望的结果
结果是对“水坑”类进行改进的 MIoU 的初步分析，
与更复杂的基于深度学习的基准相比，“草”。这
评估了 Velodyne 和 Ouster 之间方法的兼容性
激光雷达系统，保证其跨平台适用性。本次分析
主张将校准强度作为补充
输入，旨在提高基于语义学习的预测精度
细分框架。
https://github.com/MOONLABIISERB/lidar-intensity-predictor/tree/main
]]></description>
      <guid>http://arxiv.org/abs/2401.01439</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>DiffAugment：基于扩散的长尾视觉关系识别。 （arXiv：2401.01387v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01387</link>
      <description><![CDATA[视觉关系识别（VRR）的任务旨在识别
图像中两个相互作用的对象之间的关系，特别是
由于广泛分布且分布高度不平衡，具有挑战性
&lt;主语、关系、客体&gt;三胞胎。为了克服由此产生的性能
针对现有 VRR 方法的偏差，我们引入了 DiffAugment——一种方法
首先通过利用
WordNet，然后利用扩散模型的生成能力进行扩展
少数群体的视觉空间。我们提出了一种新颖的硬度感知
扩散中的成分基于每个&lt;S、R、O&gt;的硬度。三联体
并证明硬度感知扩散在生成中的有效性
尾部类的视觉嵌入。我们还提出了一个新颖的主题
基于对象的扩散采样播种策​​略，提高了
生成的视觉嵌入的辨别能力。广泛的
GQA-LT 数据集上的实验显示了在
使用扩散的主题/对象和关系平均每类准确度
增强样本。
]]></description>
      <guid>http://arxiv.org/abs/2401.01387</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>用于远距离穿墙人体活动识别的定向天线系统。 （arXiv：2401.01388v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01388</link>
      <description><![CDATA[基于 WiFi 信道状态信息 (CSI) 的人类活动识别 (HAR)
在空间受限的环境中实现非接触式远距离传感
同时保护视觉隐私。然而，尽管有众多的存在
我们周围支持 WiFi 的设备很少会将 CSI 暴露给用户，从而导致缺乏
传感硬件选项。 Espressif ESP32 的变体已出现：
基于 WiFi CSI 的 HAR 的潜在低成本且易于部署的解决方案。在这个
工作中，评估了四个基于 ESP32-S3 的 2.4GHz 定向天线系统
他们能够促进远程穿墙 HAR。两个有前途的系统
被提出，其中之一将 ESP32-S3 与定向双二阶相结合
天线。据我们所知，这种组合代表了第一个
在基于 WiFi 的 HAR 中演示了此类系统。第二个系统依赖于
ESP32-S3 内置印刷倒F天线（PIFA）并实现
通过平面反射器的方向性。在综合评价中
两个系统的视距 (LOS) 和非视距 (NLOS) HAR 性能
部署在跨距18米的办公环境中
五个房间。在此实验设置中，Wallhack1.8k 数据集包括
1806 收集并制作人类活动的CSI振幅谱图
公开可用。基于Wallhack1.8k，我们训练活动识别模型
使用 EfficientNetV2 架构评估 LOS 中的系统性能
非视距场景。对于核心 NLOS 活动识别问题，双二阶
天线和基于 PIFA 的系统达到 92.0$\pm$3.5 的精度
分别为86.8$\pm$4.7，论证了远程的可行性
穿墙 HAR 与建议的系统。
]]></description>
      <guid>http://arxiv.org/abs/2401.01388</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>关于使用配备位置编码的 MLP 学习 SDF 的最佳采样。 （arXiv：2401.01391v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01391</link>
      <description><![CDATA[神经隐式场，例如神经符号距离场 (SDF)
形状，已成为许多应用的有力代表，例如
对 3D 形状进行编码并执行碰撞检测。通常，隐式
字段由具有位置编码的多层感知器 (MLP) 进行编码
(PE) 捕捉高频几何细节。然而，值得注意的一面
这种配备 PE 的 MLP 的影响是学习中存在的噪声伪影
隐式字段。虽然提高采样率通常可以减轻
这些伪影，在本文中我们旨在解释这种不良现象
通过傅里叶分析的镜头。我们设计了一个工具来确定
用于学习准确的神经隐式场的适当采样率
无不良副作用。具体来说，我们提出了一个简单但
估计给定网络固有频率的有效方法
基于网络响应的傅立叶分析的随机权重。它
据观察，配备 PE 的 MLP 的固有频率远高于
PE层中的最高频率分量。对此进行抽样
遵循奈奎斯特-桑农采样定理的固有频率使我们能够
确定适当的训练采样率。我们凭经验表明
SDF 拟合的设置，建议的采样率足以
确保准确的拟合结果，同时进一步提高采样率
不会进一步显着减少拟合误差。训练体育装备
MLP 只需采用我们的采样策略即可获得优于
现有的方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.01391</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>探索音乐驱动的舞蹈生成中的多模态控制。 （arXiv：2401.01382v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.01382</link>
      <description><![CDATA[现有的音乐驱动的3D舞蹈生成方法主要集中在
高质量的舞蹈一代，但在创作过程中缺乏足够的控制力
生成过程。为了解决这些问题，我们提出了一个统一的框架
能够生成高质量的舞蹈动作并支持多模态
控制，包括类型控制、语义控制和空间控制。第一的，
我们将舞蹈生成网络与舞蹈控制网络解耦，
从而避免添加额外的舞蹈质量时的下降
控制信息。其次，我们设计了具体的控制策略
不同的控制信息并将它们集成到统一的框架中。
实验结果表明，所提出的舞蹈生成框架
在运动质量和
可控性。
]]></description>
      <guid>http://arxiv.org/abs/2401.01382</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>使用稀缺数据通过联合多轨迹 GNN 预测婴儿大脑连接。 （arXiv：2401.01383v1 [q-bio.NC]）</title>
      <link>http://arxiv.org/abs/2401.01383</link>
      <description><![CDATA[对婴儿大脑网络复杂进化的理解
出生后第一年对于识别早期大脑的动态至关重要
互联互通发展。现有的深度学习解决方案存在三个问题
主要限制。首先，它们不能推广到多轨迹预测
任务，其中每个图形轨迹对应于特定的成像模式
或连接类型（例如，T1-w MRI）。其次，现有模型要求
广泛的训练数据集以获得令人满意的性能，这通常是
获得具有挑战性。第三，他们没有有效地利用不完整的时间
系列数据。为了解决这些限制，我们引入了 FedGmTE-Net++，
基于联合图的多轨迹进化网络。使用的力量
联合会，我们汇总了有限的不同医院之间的当地经验
数据集。因此，我们提高了每家医院当地的绩效
生成模型，同时保护数据隐私。三大关键创新
FedGmTE-Net++ 是：(i) 提出第一个联邦学习框架
专为大脑多轨迹进化预测而设计
数据稀缺环境，（ii）在
局部目标函数利用所有纵向大脑连接
在进化轨迹内并最大化数据利用率，（iii）
引入两步插补过程，包括基于 KNN 的初步插补
预完成，然后是使用回归器的插补细化步骤
提高相似性分数并细化插补。我们的综合
实验结果表明 FedGmTE-Net++ 在大脑中的表现优于
与单个基线图的多轨迹预测相比
基准方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.01383</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>使用整个幻灯片图像进行自动诊断的组织伪影分割和严重性分析。 (arXiv:2401.01386v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.01386</link>
      <description><![CDATA[传统上，病理分析和诊断是通过人工进行的
专家在显微镜下观察载玻片标本。整体
载玻片图像是由载玻片产生的数字样本。整张幻灯片
图像使标本能够在计算机屏幕上观察并导致
计算机视觉和人工智能所在的计算病理学
用于自动分析和诊断。以目前的计算
进步，整个幻灯片图像可以自主分析，无需
人类监督。然而，分析可能会失败或导致错误的诊断
如果整个幻灯片图像受到组织伪影的影响，例如组织折叠或
气泡取决于严重程度。现有的伪影检测方法依赖于
专家进行严重性评估，以消除受伪影影响的区域
分析。这个过程既费时又费力，并且破坏了
自动分析或删除工件而不评估它们的目标
严重性，这可能会导致诊断上重要的数据丢失。
因此，有必要检测工件并评估其严重性
自动地。在本文中，我们提出了一个包含严重性的系统
利用卷积神经网络进行伪影检测评估。这
所提出的系统使用 DoubleUNet 来分割工件和一个集成网络
六个微调卷积神经网络模型来确定严重程度。这
该方法的准确度比当前最先进的技术高出 9%
伪影分割并实现了 97% 的强相关性
病理学家评估严重程度。的稳健性
使用我们提出的异构数据集和实用的数据集演示了系统
通过将其与自动分析系统集成来确保可用性。
]]></description>
      <guid>http://arxiv.org/abs/2401.01386</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>用于自动驾驶应用中低复杂度物体检测的快速量子卷积神经网络。 （arXiv：2401.01370v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01370</link>
      <description><![CDATA[在深度学习领域不断进步和创新的推动下，object
检测应用已经变得普遍，特别是在自主领域
利用各种视觉数据进行驾驶。作为卷积神经网络
（CNN）正在优化，对象的性能和计算速度
自动驾驶的检测得到显着改善。然而，由于
所使用的数据的复杂性和规模呈指数级快速增长
物体检测，在计算速度方面存在限制，而
仅使用经典计算进行物体检测。受此激励，
基于量子卷积的目标检测（QCOD）被提出采用量子
计算以高速执行物体检测。 QCOD 利用我们的
提出了上传输入通道信息的快速量子卷积
重建输出通道以降低计算复杂度
从而提高性能。最后，与 KITTI 进行的广泛实验
自动驾驶目标检测数据集验证了所提出的快速
量子卷积和QCOD在真实物体检测中成功运行
应用程序。
]]></description>
      <guid>http://arxiv.org/abs/2401.01370</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用张量卷积神经网络促进制造中的缺陷检测。 （arXiv：2401.01373v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01373</link>
      <description><![CDATA[缺陷检测是当今最重要但最具挑战性的任务之一
制造部门的质量控制阶段。在这项工作中，我们介绍了一个
张量卷积神经网络 (T-CNN) 并检查其在
超声波元件之一的真实缺陷检测应用
罗伯特博世制造工厂生产的传感器。我们的量子启发
T-CNN 在减少的模型参数空间上运行，以显着提高
不牺牲同等 CNN 模型的训练速度和性能
准确性。更具体地说，我们演示了 T-CNN 如何能够达到
通过质量指标衡量，性能与经典 CNN 相同，最高可达
参数减少 15 倍，训练时间加快 4% 到 19%。我们的成果
证明 T-CNN 大大优于传统人类的结果
目视检查，在当前的实际应用中提供价值
制造业。
]]></description>
      <guid>http://arxiv.org/abs/2401.01373</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>利用高分辨率多光谱无人机图像和机器学习绘制核桃水分胁迫图。 （arXiv：2401.01375v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01375</link>
      <description><![CDATA[有效监测整个核桃水分状况和胁迫水平
果园是实现精准灌溉管理的重要一步
核桃，加州的重要农作物。这项研究提出了一种机器
使用随机森林 (RF) 模型来绘制茎水势的学习方法
（SWP）通过集成高分辨率多光谱遥感图像
带有天气数据的无人机 (UAV) 飞行。从2017年到2018年，
配备七波段多光谱相机的无人机进行了五次飞行
在商业核桃园进行，并与并行地面配对
核桃植株样本的测量。 RF 回归模型，利用
来自正射无人机图像和天气数据的植被指数，
有效估计了地面测量的 SWP，实现了 0.63 的 $R^2$ 和
平均绝对误差 (MAE) 为 0.80 条。气象数据的整合
对于整合不同航班日期的数据尤其重要。
SWP 估算的重要变量包括风速和植被
NDVI、NDRE 和 PSRI 等指数。排除红边的简化 RF 模型
NDRE 和 PSRI 指数的准确性略有降低 ($R^2$ =
0.54）。此外，RF 分类模型预测了水分胁迫水平
核桃树的准确率达到 85%，超过了简化模型的 80% 准确率
分类模型。结果证实了基于无人机的功效
多光谱成像与机器学习相结合，结合热
核桃水分胁迫中的数据、NDVI、红边指数和天气数据
估计和评估。该方法提供了一种可扩展、经济高效的方法
用于对单个植物进行数据驱动的精确灌溉管理的工具
核桃园的水平。
]]></description>
      <guid>http://arxiv.org/abs/2401.01375</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>从图像中生成增材制造粗糙度表面的合成模态。 （arXiv：2401.01345v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01345</link>
      <description><![CDATA[一种从以下位置推断和综合推断粗糙度场的方法
使用电子显微镜扫描增材制造的表面
Rogallo 合成湍流方法的改编 [R. S.罗加洛，美国宇航局
技术备忘录 81315, 1981] 提出了基于傅里叶模式的技术备忘录。这
生成的合成粗糙度场是平滑的并且与网格兼容
计算流体动力学或其他数值模拟中的发生器。
与机器学习方法不同，机器学习方法可能需要对表面进行二十多次扫描
训练的粗糙度，基于傅里叶模式的方法可以推断
使用单次物理粗糙度扫描均匀合成粗糙度场
到任何所需的尺寸和范围。五种类型的合成粗糙度场是
使用文献中的电子显微镜粗糙度图像生成。 A
其光谱能量和两点相关光谱的比较表明
合成场非常接近粗糙度结构和光谱
扫描能量。
]]></description>
      <guid>http://arxiv.org/abs/2401.01345</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>优化卷积神经网络架构。 （arXiv：2401.01361v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01361</link>
      <description><![CDATA[卷积神经网络（CNN）被广泛用于应对具有挑战性的任务
例如语音识别、自然语言处理或计算机视觉。正如美国有线电视新闻网
架构变得更大、更复杂，它们的计算要求
增加，产生巨大的能源成本并挑战他们
在资源受限的设备上部署。在本文中，我们提出优化
卷积神经网络架构 (OCNNA)，一种新颖的 CNN 优化和
基于剪枝和知识蒸馏的构建方法旨在
确定卷积层的重要性。该提案已
通过全面的实证研究（包括最著名的数据集）进行评估
（CIFAR-10、CIFAR-100 和 Imagenet）和 CNN 架构（VGG-16、ResNet-50、
DenseNet-40 和 MobileNet），设置准确度下降和剩余参数
比率作为客观指标来比较 OCNNA 与
其他最先进的方法。我们的方法已与 20 多种方法进行了比较
卷积神经网络简化算法取得优异成绩
结果。因此，OCNNA 是一种有竞争力的 CNN 构建方法，
可以简化神经网络在物联网或资源有限的环境中的部署
设备。
]]></description>
      <guid>http://arxiv.org/abs/2401.01361</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>使用带有声音反馈的物体检测来帮助盲人。 （arXiv：2401.01362v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.01362</link>
      <description><![CDATA[对于视障人士来说，独立自主是非常困难的
在室内和室外环境中移动并安全移动。此外，
这些身体和视觉上的挑战阻碍了他们的日常生活
活动。同样，他们在感知周围物体时也有问题
可能对他们构成风险的环境。拟议的方法建议
使用网络摄像头检测实时视频中的对象，以获取对象
识别, 过程.使用 You Look Only Once (YOLO) 模型，即
基于CNN的实时目标检测技术。此外，OpenCV
Python 库用于实现软件程序以及深度学习
执行学习过程。图像识别结果传输至
通过 Google 文本转语音以可听形式呈现视障用户
库并确定对象相对于其在屏幕中的位置的位置。
使用平均精度（mAP）评估获得的结果，
结果发现，所提出的方法在以下情况下取得了优异的结果：
与以前的方法相比。
]]></description>
      <guid>http://arxiv.org/abs/2401.01362</guid>
      <pubDate>Thu, 04 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    </channel>
</rss>