<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Thu, 25 Jan 2024 03:14:57 GMT</lastBuildDate>
    <item>
      <title>语义分割的边界和关系蒸馏。 （arXiv：2401.13174v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13174</link>
      <description><![CDATA[最近，有消息称小型语义分割（SS）模型
在维持边界区域完整性方面表现出犯错误的倾向
尽管进行了有效的分割，但仍保持目标区域的连通性
主要对象区域。为了解决这些错误，我们提出了有针对性的
使用知识蒸馏的边界和关系蒸馏（BRD）策略
从大型教师模型到小型学生模型。具体来说，边界
蒸馏从层次特征中提取明确的对象边界
主干网络的地图，随后增强学生模型的掩模
边界区域的质量。同时，关系蒸馏转移
使用从教师模型到学生模型的隐式关系
像素级的自我关系作为桥梁，确保学生的掩模具有
强大的目标区域连通性。拟议的 BRD 是专门为
SS的特点是简单、高效。通过实验
对多个 SS 数据集的评估，包括 Pascal VOC 2012、Cityscapes、
ADE20K 和 COCO-Stuff 10K，我们证明 BRD 显着超越
当前的方法在不增加推理成本的情况下，生成清晰的
区域边界和平滑连接区域对于小型企业来说具有挑战性
楷模。
]]></description>
      <guid>http://arxiv.org/abs/2401.13174</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>使用扩散模型的合成数据进行多域人脸标志检测。 （arXiv：2401.13191v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13191</link>
      <description><![CDATA[最近，基于深度学习的野外面部特征点检测
取得了显着的进步。然而，仍存在挑战
其他领域（例如卡通、漫画等）中的人脸标志检测。这
这是由于缺乏广泛注释的训练数据。为了解决这个问题
关心，我们设计了一个两阶段的培训方法，有效地利用
有限的数据集和预先训练的扩散模型以获得对齐的对
多个领域的地标和面孔。在第一阶段，我们训练一个
基于真实人脸的大型数据集的地标条件人脸生成模型。在
第二阶段，我们在一个小数据集上微调上述模型
图像地标与用于控制域的文本提示配对。我们新的
设计使我们的方法能够生成高质量的合成配对数据集
来自多个域，同时保留地标和
面部特征。最后，我们微调了预训练的人脸标志检测
在合成数据集上建立模型以实现多域人脸特征点检测。
我们的定性和定量结果表明我们的方法
在多域人脸特征点检测方面优于现有方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.13191</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>一种通用的多尺度基于束的高光谱稀疏解混算法。 （arXiv：2401.13161v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13161</link>
      <description><![CDATA[在高光谱稀疏分解中，成功的方法采用光谱
束来解决空间域中端元的可变性。
然而，通常采用的正规化处罚总计相当大
计算复杂性，并且解决方案对噪声非常敏感。我们
推广多尺度空间正则化方法来解决分解问题
通过合并导致群体稀疏的混合规范来解决问题。那么，我们建议
一种利用束结构来处理噪声的鲁棒方法
具有端元变异性，同时确保类间和类内稀疏性
具有合理计算成本的丰度估计。我们还提出了一个
选择\emph{最具代表性}丰度估计的一般启发式
经过多次运行分离过程，产生稳健的解决方案
且可重复性高。实验证明了鲁棒性和一致性
与相关方法相比的结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.13161</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>ADMap：用于重建在线矢量化高精地图的抗干扰框架。 （arXiv：2401.13172v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13172</link>
      <description><![CDATA[自动驾驶领域，在线高清（HD）地图
重建对于规划任务至关重要。最近的研究已经发展
几种高性能的高清地图重建模型可以满足这种需要。
然而，实例向量内的点序列可能会抖动或
由于预测偏差而出现锯齿状，这可能会影响后续任务。所以，
本文提出了抗干扰地图重建框架（ADMap）。
为了减轻点阶抖动，该框架由三个模块组成：
多尺度感知颈、实例交互式注意力（IIA）和向量
方向差损耗 (VDDL)。通过探索点序关系
在实例之间和实例内以级联方式，模型可以监控
更有效地进行点序预测过程。 ADMap实现
nuScenes 和 Argoverse2 数据集上的最先进性能。广泛的
结果证明其能够在中生成稳定可靠的地图元素
复杂且多变的驾驶场景。代码和更多演示可在
https://github.com/hht1996ok/ADMap。
]]></description>
      <guid>http://arxiv.org/abs/2401.13172</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 3D 卷积自动编码器对经胸超声心动图图像进行深度时空杂波过滤。 (arXiv:2401.13147v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.13147</link>
      <description><![CDATA[这项研究提出了一种用于过滤的深度卷积自动编码器网络
经胸超声心动图 (TTE) 图像的混响伪影
序列。考虑到这些伪影的时空性质，过滤
使用 3D 卷积层构建网络来抑制杂波
整个心动周期的模式。该网络的设计采用
优点：i）主要关注杂乱区域的注意力机制
ii）残差学习以保留图像帧的精细结构。到
训练深度网络，模拟了一组不同的工件模式
模拟图案叠加到无伪影的超现实图案上
六个超声供应商的合成 TTE 序列，以生成
过滤网络。无伪影序列作为基本事实。
使用看不见的合成物来评估过滤网络的性能
以及体内人工序列。使用该方法获得了令人满意的结果
后一个数据集证实了所提出的良好泛化性能
使用合成序列和模拟工件训练的网络
模式。杂波过滤后的序列是否适合进一步处理
通过计算它们的分段应变曲线来评估。结果显示
由计算得出的应变分布之间存在很大差异
杂乱片段及其在无杂乱图像中的对应片段
使用建议的过滤序列后显着减少
网络。经过训练的深度网络可以处理人为的 TTE 序列
不到一秒，可用于实时杂波过滤。
此外，它还可以提高临床指标的精确度。
根据 TTE 序列计算。所提出方法的源代码是
可以在：
https://github.com/MahdiTabassian/Deep-Clutter-Filtering/tree/main。
]]></description>
      <guid>http://arxiv.org/abs/2401.13147</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>场景识别中的数字鸿沟：揭示深度学习系统中的社会经济偏见。 （arXiv：2401.13097v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13097</link>
      <description><![CDATA[基于计算机的场景理解已经影响了从城市到城市的各个领域
计划自动驾驶汽车的性能，但对其效果知之甚少
这些技术跨越社会差异发挥作用。我们调查的偏见
场景分类中的深度卷积神经网络（dCNN），使用
来自全球和美国的近百万张图像，包括用户提交的
家庭照片和 Airbnb 房源。我们应用统计模型来量化
家庭收入、人类发展等社会经济指标的影响
指数 (HDI) 以及来自公共数据源（中央情报局和美国）的人口因素
Census）对 dCNN 性能的影响。我们的分析揭示了重要的社会经济
偏差，预训练的 dCNN 表现出较低的分类精度、较低的
分类置信度，以及分配标签的更高倾向
用于房屋时会带有攻击性（例如“废墟”、“贫民窟”），尤其是在图像中
来自社会经济地位 (SES) 较低的家庭。这个趋势是一致的
跨越两个国际图像数据集以及不同的经济和
美国的种族景观。这项研究有助于
了解计算机视觉中的偏见，强调需要更多
具有包容性和代表性的训练数据集。通过减少偏见
计算机视觉管道，我们可以确保更公平、更公平的结果
应用计算机视觉，包括房屋估价和智能家居安全
系统。解决这些偏见刻不容缓，这可能会显着
影响城市发展和资源分配的关键决策。我们的
研究结果还推动了人工智能系统的开发，以更好地理解和
服务多元化社区，迈向公平受益的技术
社会各界。
]]></description>
      <guid>http://arxiv.org/abs/2401.13097</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>用于心脏 SPECT 同步去噪、有限视图重建和衰减校正的双域粗到精渐进估计网络。 (arXiv:2401.13140v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.13140</link>
      <description><![CDATA[单光子发射计算机断层扫描（SPECT）广泛应用于
冠状动脉疾病的诊断。低剂量 (LD) SPECT 旨在最大限度地减少
辐射暴露但会导致图像噪声增加。有限视野 (LV) SPECT，
例如最新的 GE MyoSPECT ES 系统，可实现加速扫描和
减少了硬件费用，但降低了重建精度。此外，
计算机断层扫描 (CT) 通常用于得出衰减图
($\mu$-maps) 用于心脏 SPECT 的衰减校正 (AC)，但它会
引入额外的辐射暴露和 SPECT-CT 错位。虽然
人们已经开发出各种方法来专注于 LD 去噪、LV
重建，或 SPECT 中的无 CT AC，同时解决
解决这些任务仍然具有挑战性且尚未得到充分探索。此外，它
对于探索融合跨领域和跨模式的潜力至关重要
这些相互关联的任务的信息，以进一步提高
每个任务。因此，我们提出了一种双域粗到细渐进网络
（DuDoCFNet），一种同时LD去噪、LV的多任务学习方法
重建，以及心脏 SPECT 的无 CT $\mu$-图生成。配对
DuDoCFNet 中的双域网络使用多层融合进行级联
跨领域和跨模态特征融合的机制。两级
渐进式学习策略应用于投影和图像
域以实现 SPECT 投影的粗略到精细估计
CT 衍生的 $\mu$ 地图。我们的实验证明了 DuDoCFNet 的优越性
估计投影、生成 $\mu$ 地图和 AC 的准确性
与现有的单任务或多任务学习方法相比的重建，
在各种迭代和 LD 级别下。本作品的源代码为
可以在 https://github.com/XiongchaoChen/DuDoCFNet-MultiTask 获取。
]]></description>
      <guid>http://arxiv.org/abs/2401.13140</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:54 GMT</pubDate>
    </item>
    <item>
      <title>放射学中的自由形式医学视觉问答。 （arXiv：2401.13081v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13081</link>
      <description><![CDATA[医疗领域的视觉问答（VQA）呈现出独特的、
跨学科挑战，结合计算机视觉、自然等领域
语言处理和知识表示。尽管它很重要，
医学 VQA 方面的研究还很少，自 2018 年以来才开始出现势头。
为了解决这一差距，我们的研究深入探讨了
放射学图像和多模态表示的联合学习，
超越现有方法。我们创新地扩充了 SLAKE 数据集，
使我们的模型能够回答更多样的问题，但不限于此
放射学或病理学图像的直接内容。我们的模型实现了
top-1 准确度为 79.55\%，架构不太复杂，证明
性能可与当前最先进的型号相媲美。这项研究不
不仅促进了医学 VQA 的发展，而且还为实际应用开辟了途径
诊断设置。
]]></description>
      <guid>http://arxiv.org/abs/2401.13081</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>PlaceFormer：使用多尺度补丁选择和融合的基于 Transformer 的视觉位置识别。 （arXiv：2401.13082v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13082</link>
      <description><![CDATA[视觉地点识别是计算机领域一项具有挑战性的任务
视觉、自主机器人和车辆，旨在识别位置
或来自视觉输入的地方。视觉地点识别的现代方法
采用卷积神经网络并利用图像中的每个区域
用于地点识别任务。然而，动态和
图像中分散注意力的元素可能会影响该场所的有效性
识别过程。因此，关注与任务相关的内容是有意义的
图像区域以提高识别能力。在本文中，我们提出
PlaceFormer，一种基于变压器的新型视觉地点识别方法。
PlaceFormer 使用转换器中的补丁标记来创建全局图像
描述符，然后用于图像检索。对检索到的重新排序
图像，PlaceFormer 合并来自转换器的补丁标记以形成
多尺度补丁。利用变压器的自注意力机制，
选择与图像中任务相关区域相对应的补丁。这些
选定的补丁进行几何验证，生成相似性分数
跨越不同的补丁大小。随后，每个补丁大小的空间分数
融合以产生最终的相似度得分。然后这个分数被用来
使用全局图像描述符对最初检索的图像进行重新排序。
对基准数据集的大量实验表明 PlaceFormer
在准确性和准确性方面优于多种最先进的方法
计算效率高，需要更少的时间和内存。
]]></description>
      <guid>http://arxiv.org/abs/2401.13082</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>街景图像的开源数据管道：COVID-19 大流行期间社区流动性的案例研究。 （arXiv：2401.13087v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13087</link>
      <description><![CDATA[街景图像 (SVI) 是有价值数据的常见来源
研究人员。研究人员使用 SVI 数据来估算行人流量，
人口监测，并更好地了解建筑和自然
城市景观中的环境。然而，最常见的公开来源
可用的SVI数据是Google街景。谷歌街景图像是
收集频率较低，使得时间分析具有挑战性，尤其是在低
人口密度地区。我们的主要贡献是开发了
用于处理从 360 度视频录制的开源数据管道
车载摄像头。视频数据用于生成 SVI，然后可以将其
用作时间分析的输入。我们演示了管道的使用
通过对华盛顿州西雅图进行为期 38 个月的纵向调查收集 SVI 数据集，
COVID-19 大流行期间的美国。我们管道的输出经过验证
通过对图像中的行人流量进行统计分析。我们确认
文献中已知的结果并为户外提供新的见解
行人交通模式。本研究论证了可行性和价值
收集和使用 SVI 进行超出可能范围的研究目的
当前可用的 SVI 数据。数据的局限性和未来的改进
还讨论了管道和案例研究。
]]></description>
      <guid>http://arxiv.org/abs/2401.13087</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:53 GMT</pubDate>
    </item>
    <item>
      <title>PA-SAM：用于高质量图像分割的快速适配器 SAM。 （arXiv：2401.13051v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13051</link>
      <description><![CDATA[分段任意模型（SAM）在
各种图像分割任务。尽管接受了超过十亿的训练
掩模，SAM 在多种场景下面临掩模预测质量的挑战，
尤其是在现实世界中。在本文中，我们介绍了一部小说
将提示驱动适配器转化为SAM，即Prompt Adapter Segment Anything Model
（PA-SAM），旨在增强原始SAM的分割掩模质量。
通过专门训练提示适配器，PA-SAM 提取详细的
来自图像的信息并优化稀疏的掩模解码器特征
和密集的提示级别，提高了 SAM 的分割性能
生产高品质口罩。实验结果表明我们的 PA-SAM
在高质量、零样本和开放集方面优于其他基于 SAM 的方法
分割。我们将在以下位置提供源代码和模型：
https://github.com/xzz2/pa-sam。
]]></description>
      <guid>http://arxiv.org/abs/2401.13051</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>用于改进高光谱图像中气体羽流识别的局部背景估计。 （arXiv：2401.13068v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13068</link>
      <description><![CDATA[深度学习识别模型已显示出识别气体的前景
城市场景的长波红外高光谱图像中的羽状物，特别是当
正在考虑建立大型气体库。因为许多气体都有相似的
光谱特征，正确估计来自光谱特征的信号非常重要
检测到羽流。通常，场景的全局平均谱和协方差矩阵
估计会使羽流信号变白，从而消除背景的
来自气体签名的签名。然而，城市场景可以有许多不同的
空间和光谱异质的背景材料。这个可以
当全局背景估计为
不代表特定的当地背景材料。我们使用图像
分割以及迭代背景估计算法
为驻留的各种背景材料创建本地估计
在气体羽流下方。我们的方法优于全局背景估计
一组模拟和真实的气体羽流。这种方法有望提高
深度学习识别信心十足，同时简单且易于调整
当考虑不同的羽流时。
]]></description>
      <guid>http://arxiv.org/abs/2401.13068</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>SemanticSLAM：基于学习的语义地图构建和鲁棒相机定位。 （arXiv：2401.13076v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2401.13076</link>
      <description><![CDATA[视觉同步定位与建图 (VSLAM) 的当前技术
通过比较连续场景的图像特征来估计相机位移。
这些算法依赖于场景连续性，因此需要频繁的摄像
输入。然而，频繁处理图像可能会导致大量内存占用
使用和计算开销。在本研究中，我们引入了 SemanticSLAM，
利用语义特征的端到端视觉惯性里程计系统
从 RGB-D 传感器中提取。这种方法可以创建一个
环境的语义地图并确保可靠的相机定位。
SemanticSLAM 与场景无关，这意味着它不需要重新训练
不同的环境。即使在室内环境中，它也能有效运行
不频繁的相机输入，没有先验知识。语义SLAM的优势
在于它能够逐步细化语义图并改善姿态
估计。这是通过卷积长短期记忆来实现的
(ConvLSTM) 网络，经过训练可以纠正地图构建过程中的错误。比较的
与现有的 VSLAM 算法相比，SemanticSLAM 将姿态估计提高了 17%。这
生成的语义图提供有关环境的可解释信息
并且可以轻松应用于各种下游任务，例如路径规划，
避障和机器人导航。该代码将公开
在 https://github.com/Leomingyangli/SemanticSLAM
]]></description>
      <guid>http://arxiv.org/abs/2401.13076</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>CCA：图像编辑的协作竞争代理。 （arXiv：2401.13011v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.13011</link>
      <description><![CDATA[本文提出了一种新颖的生成模型：协作竞争
代理（CCA），利用多种大语言的功能
基于模型（LLM）的代理来执行复杂的任务。从中汲取灵感
生成对抗网络（GAN），CCA 系统采用两个同等地位的网络
生成器代理和鉴别器代理。发电机独立
处理用户指令并生成结果，而判别器
评估输出，并为生成器代理提供反馈
进一步体现和提高发电成果。与之前不同的是
生成模型，我们的系统可以获得生成的中间步骤。
这允许每个生成器代理从其他成功执行中学习
提高其透明度，从而实现协作竞争，从而增强
系统结果的质量和稳健性。本研究的主要焦点
是图像编辑，展示了 CCA 处理复杂的能力
强有力的指示。本文的主要贡献包括引言
具有可控中间步骤的基于多智能体的生成模型
和迭代优化，详细检查代理关系，以及
图像编辑综合实验。代码可在
\href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}。
]]></description>
      <guid>http://arxiv.org/abs/2401.13011</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>CIS-UNet：通过上下文感知移动窗口自注意力对计算机断层扫描血管造影中的主动脉进行多类分割。 (arXiv:2401.13049v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2401.13049</link>
      <description><![CDATA[医学成像和血管内移植技术的进步促进了
主动脉疾病的微创治疗。精确的 3D 分割
主动脉及其分支对于干预至关重要，因为不准确
分割可能导致错误的手术计划和内移植物
建造。以前的方法将主动脉分割简化为二值图像
分割问题，忽视了区分的必要性
个别主动脉分支。在本文中，我们介绍了上下文注入
Swin-UNet（CIS-UNet），专为多类别设计的深度学习模型
主动脉和十三个主动脉分支的分割。强强联手
CIS-UNet 采用卷积神经网络 (CNN) 和 Swin 变压器
分层编码器-解码器结构，包括 CNN 编码器、对称
解码器、跳过连接和新颖的上下文感知移位窗口
自注意力（CSW-SA）作为瓶颈块。值得注意的是，CSW-SA 引入了
补丁合并层的独特利用，与传统的 Swin 不同
变压器。它有效地压缩了特征图，提供了全局特征图
空间上下文并在瓶颈层应用时增强性能，
相比之下，提供卓越的计算效率和分割精度
到 Swin 变压器。我们在计算机断层扫描 (CT) 上训练我们的模型
对 44 名患者进行扫描，并对 15 名患者进行测试。 CIS-UNet 的表现优于
最先进的 SwinUNetR 分割模型，完全基于 Swin
变压器，通过实现 0.713 的卓越平均 Dice 系数
平均表面距离为 0.697，平均表面距离为 2.78 毫米，而平均表面距离为 3.39 毫米。
CIS-UNet 卓越的 3D 主动脉分割提供更高的精度和
优化血管内治疗计划。我们的数据集和代码将是
公开可用。
]]></description>
      <guid>http://arxiv.org/abs/2401.13049</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:51 GMT</pubDate>
    </item>
    </channel>
</rss>