<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>盲图像超分辨率空间变异核细化与扩散模型的自适应多模态融合</title>
      <link>https://arxiv.org/abs/2403.05808</link>
      <description><![CDATA[arXiv:2403.05808v1 公告类型：新
摘要：用于图像生成的预训练扩散模型封装了与复杂纹理相关的大量先验知识。在图像超分辨率的背景下利用先验知识的潜力提供了一条引人注目的途径。尽管如此，目前流行的基于扩散的方法忽视了退化信息对扩散过程施加的限制。此外，这些方法未能考虑估计的模糊内核中固有的空间变化，这种空间变化源于开放环境场景中的运动抖动和失焦元素等因素。这种疏忽导致图像超分辨率效果与基本现实存在显着偏差。为了解决这些问题，我们引入了一种称为自适应多模态融合的框架，该框架是\textbf{S}patially Variant Kernel Refinement与盲图像\textbf{S}uper-\textbf{R}解散模型的自适应多模态融合（SSR）。在SSR框架内，我们提出了一个空间变异核细化（SVKR）模块。 SVKR 估计深度信息核，它考虑了深度信息并且是空间变化的。此外，SVKR 提高了从 LR 图像获取的深度信息的准确性，允许深度图和模糊核估计之间的相互增强。最后，我们引入自适应多模态融合（AMF）模块来对齐来自三种模态的信息：低分辨率图像、深度图和模糊内核。这种对齐可以限制扩散模型以生成更真实的 SR 结果。定量和定性实验证实了我们方法的优越性，而消融实验则证实了我们提出的模块的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.05808</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>通过知识蒸馏和多尺度 Sigmoid 推理进行弱监督变化检测</title>
      <link>https://arxiv.org/abs/2403.05796</link>
      <description><![CDATA[arXiv:2403.05796v1 公告类型：新
摘要：变化检测旨在检测一对多时相图像由于自然或人为原因引起的空间变化，已广泛应用于遥感、灾害管理、城市管理等领域。然而，它们受到全面监督，并且需要劳动密集型的像素级标签。为了解决这个问题，我们通过利用图像级标签的知识蒸馏和多尺度 Sigmoid 推理 (KD-MSI) 开发了一种新颖的弱监督变化检测技术。在我们的方法中，类激活图（CAM）不仅用于导出变化概率图，而且还用作知识蒸馏过程的基础。这是通过教师和学生网络的联合训练策略来完成的，使学生网络能够比基于图像级标签的教师网络更准确地突出潜在的变化区域。此外，我们设计了一个多尺度 Sigmoid 推理 (MSI) 模块作为后处理步骤，以进一步细化训练后的学生网络的变化概率图。三个公共数据集（即 WHU-CD、DSIFN-CD 和 LEVIR-CD）的实证结果表明，我们提出的技术及其集成训练策略明显优于最先进的技术。]]></description>
      <guid>https://arxiv.org/abs/2403.05796</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>用于图像水印去除的自监督 CNN</title>
      <link>https://arxiv.org/abs/2403.05807</link>
      <description><![CDATA[arXiv:2403.05807v1 公告类型：新
摘要：流行的卷积神经网络主要以监督方式使用成对图像来去除图像水印。然而，水印图像没有现实世界中的参考图像，这导致图像水印去除技术的鲁棒性较差。在本文中，我们提出了一种用于图像水印去除（SWCNN）的自监督卷积神经网络（CNN）。 SWCNN 根据水印分布，使用自监督方式构建参考水印图像，而不是给定配对训练样本。异构 U-Net 架构用于通过简单的组件提取更多互补的结构信息以进行图像水印去除。考虑纹理信息，利用混合损失来改善图像水印去除的视觉效果。此外，还进行了水印数据集。实验结果表明，所提出的 SWCNN 在图像水印去除方面优于流行的 CNN。]]></description>
      <guid>https://arxiv.org/abs/2403.05807</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>使用航空激光雷达图像分割揭开古代玛雅定居点的面纱</title>
      <link>https://arxiv.org/abs/2403.05773</link>
      <description><![CDATA[arXiv:2403.05773v1 公告类型：新
摘要：手动识别激光雷达图像中的考古特征是劳动密集型的、成本高昂的，并且需要考古专业知识。本文展示了深度学习 (DL) 的最新进展如何提供有效的解决方案，使用 YOLOv8 神经网络准确分割航空 LiDAR 图像中的考古结构。所提出的方法使用原始 LiDAR 数据的新颖预处理和数据集增强方法来生成训练有素的 YOLOv8 网络，以提高两种重要 Maya 结构类型（环形结构和平台）分割的准确性、精确度和召回率。结果显示，平台的 IoU 性能为 0.842，环形结构的 IoU 性能为 0.809，优于现有方法。此外，领域专家的分析考虑了分段区域的拓扑一致性以及性能与区域的关系，提供了重要的见解。该方法可自动执行耗时的激光雷达图像标记，从而显着加快对历史景观的准确分析。]]></description>
      <guid>https://arxiv.org/abs/2403.05773</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>uniGradICON：医学图像配准的基础模型</title>
      <link>https://arxiv.org/abs/2403.05780</link>
      <description><![CDATA[arXiv:2403.05780v1 公告类型：新
摘要：传统的医学图像配准方法直接优化变换模型的参数。这些方法非常成功，通常用于不同解剖区域的配准。最近的深度注册网络非常快速和准确，但仅针对特定任务进行训练。因此，它们不再是通用注册方法。因此，我们提出 uniGradICON，这是迈向配准基础模型的第一步，它提供了 1）跨多个数据集的出色性能，这对于当前基于学习的配准方法来说是不可行的，2）适用于新配准任务的零样本功能与训练数据集相比，不同的采集、解剖区域和模式，以及 3) 对分布外配准任务进行微调的强大初始化。 UniGradICON 将基于学习的配准算法的速度和准确性优势与传统非深度学习方法的通用适用性结合起来。我们在 12 个不同的公共数据集上对 uniGradICON 进行了广泛的训练和评估。我们的代码和 uniGradICON 模型可在 https://github.com/uncbiag/uniGradICON 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.05780</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过实时感知实现导管插入实验室自动化</title>
      <link>https://arxiv.org/abs/2403.05758</link>
      <description><![CDATA[arXiv:2403.05758v1 公告类型：新
摘要：几十年来，三维C形臂锥形束计算机断层扫描（CBCT）成像系统一直是复杂血管和非血管介入手术的关键组成部分。虽然它可以显着改善多平面软组织成像并提供治疗前目标病变路线图和指导，但传统的工作流程可能既繁琐又耗时，特别是对于经验不足的用户而言。为了简化这一过程并提高整体程序效率，我们提出了一种视觉感知系统，即 AutoCBCT，与血管造影套件无缝集成。该系统实时动态地模拟患者的身体和手术环境。 AutoCBCT 实现了一种新颖的工作流程，具有自动定位、导航和模拟测试运行，无需手动操作和交互。所提出的系统已在实验室和临床环境中成功部署和研究，表明工作流程效率显着提高。]]></description>
      <guid>https://arxiv.org/abs/2403.05758</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>语义特征引导下的深度对比多视图聚类</title>
      <link>https://arxiv.org/abs/2403.05768</link>
      <description><![CDATA[arXiv:2403.05768v1 公告类型：新
摘要：对比学习最近在多视图聚类领域取得了令人鼓舞的性能。然而，忽略语义一致性的正负样本构建机制会导致假负对，限制了现有算法性能的进一步提高。为了解决这个问题，我们提出了一种名为语义特征引导下的深度对比多视图聚类（DCMCS）的多视图聚类框架，以减轻假阴性对的影响。具体地，首先从原始特征中提取特定于视图的特征，并根据视图重要性进行融合以获得融合视图特征。为了减轻视图私有信息的干扰，通过集群级对比学习来学习特定视图和融合视图语义特征，并将其连接起来以测量实例的语义相似性。通过最小化由语义相似性加权的实例级对比损失，DCMCS 自适应地削弱了假阴性对之间的对比倾向。几个公共数据集的实验结果表明，所提出的框架优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.05768</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>通过扰动感知对比学习实现偏差鲁棒智能体导航</title>
      <link>https://arxiv.org/abs/2403.05770</link>
      <description><![CDATA[arXiv:2403.05770v1 公告类型：新
摘要：视觉和语言导航（VLN）要求智能体遵循给定的语言指令在真实的 3D 环境中进行导航。尽管取得了显着的进步，但传统的 VLN 智能体通常是在无干扰的环境下进行训练的，并且在现实场景中很容易失败，因为它们不知道如何处理各种可能的干扰，例如广泛存在的突然障碍或人为干扰。通常可能会导致意外的路线偏差。在本文中，我们提出了一种与模型无关的训练范例，称为渐进式扰动感知对比学习（PROPER），通过要求现有 VLN 智能体学习偏差鲁棒导航来增强现有 VLN 智能体的泛化能力。具体来说，引入了一种简单而有效的路径扰动方案来实现路线偏差，要求代理仍然能够按照原始指令成功导航。由于直接强制智能体学习扰动轨迹可能会导致训练效率低下，因此设计了一种渐进式扰动轨迹增强策略，其中智能体可以自适应地学习在扰动下导航，并提高每个特定轨迹的导航性能。为了鼓励智能体更好地捕捉扰动带来的差异，通过对比无扰动轨迹编码和基于扰动的轨迹编码，进一步开发了扰动感知对比学习机制。 R2R 上的大量实验表明，PROPER 可以在无扰动场景中使多个 VLN 基线受益。我们进一步收集扰动路径数据以构建基于 R2R 的内省子集，称为路径扰动 R2R (PP-R2R)。 PP-R2R 上的结果表明流行的 VLN 代理的鲁棒性不令人满意，而 PROPER 在提高导航鲁棒性方面的能力。]]></description>
      <guid>https://arxiv.org/abs/2403.05770</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>使用硬件受限设备和计算机视觉检测光伏电池中的微裂纹</title>
      <link>https://arxiv.org/abs/2403.05694</link>
      <description><![CDATA[arXiv:2403.05694v1 公告类型：新
摘要：太阳能正迅速成为传统有限资源（例如化石燃料）的强大可再生能源。它是使用互连的光伏电池板收集的，通常由晶体硅电池制成，即可以有效地将太阳辐射转化为电能的半导体材料。然而，晶体硅很脆弱，随着时间的推移或在预测性维护任务中容易破裂，这可能导致太阳能电池部分电隔离甚至失效，从而影响电池板性能并减少发电量。这项工作旨在开发一种用于检测太阳能电池板电池裂纹的系统，以通过使用计算机视觉技术来预测和警告光伏系统的潜在故障。定义了这些技术将带来价值的三种场景。在场景 A 中，图像是手动拍摄的，检测太阳能电池故障的系统不受任何计算限制。在场景 B 中，边缘设备放置在太阳能发电厂附近，能够进行推断。最后，在场景 C 中，小型微控制器被放置在一架飞越太阳能发电厂的无人机中，并对太阳能电池的状态进行推断。三种不同的架构被发现是最合适的解决方案，每种场景一种，即 InceptionV3 模型、收缩为全整数量化的 EfficientNetB0 模型以及使用 VGG16 块构建的定制 CNN 架构。]]></description>
      <guid>https://arxiv.org/abs/2403.05694</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>不仅仅是鸟类和汽车：专业视觉识别的通用、可扩展和可解释模型</title>
      <link>https://arxiv.org/abs/2403.05703</link>
      <description><![CDATA[arXiv:2403.05703v1 公告类型：新
摘要：一些视觉识别任务比一般任务更具挑战性，因为它们需要专业类别的图像。之前的工作，例如细粒度视觉分类，主要引入了针对特定任务定制的模型，例如识别鸟类物种或汽车品牌，但可扩展性和通用性有限。本文旨在设计一个可扩展且可解释的模型，以从通用的角度解决专业视觉识别任务。我们引入了一种名为 Pro-NeXt 的受生物学启发的结构，并揭示了 Pro-NeXt 在时尚、医学和艺术领域等以前被认为是不同的专业领域中表现出实质性的普遍性。我们的基本尺寸 Pro-NeXt-B 在 5 个不同领域的 12 个不同数据集上超越了所有先前的特定任务模型。此外，我们发现其良好的缩放特性，随着 GFlops 的增加而扩大 Pro-NeXt 的深度和宽度可以持续提高其准确性。除了可扩展性和适应性之外，Pro-NeXt 的中间功能无需额外训练即可实现可靠的目标检测和分割性能，凸显了其可靠的可解释性。我们将发布代码以促进该领域的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2403.05703</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>场景图辅助放射学报告生成</title>
      <link>https://arxiv.org/abs/2403.05687</link>
      <description><![CDATA[arXiv:2403.05687v1 公告类型：新
摘要：放射学报告生成（RRG）方法通常缺乏足够的医学知识来生成临床准确的报告。场景图包含描述图像中对象的丰富信息。我们探索通过场景图丰富 RRG 的医学知识，这在当前的 RRG 文献中尚未完成。为此，我们提出了场景图辅助RRG（SGRRG）网络，这是一个生成区域级视觉特征、预测解剖属性并利用自动生成的场景图的框架，从而实现端到端的医学知识蒸馏方式。 SGRRG 由负责转换场景图的专用场景图编码器和利用补丁级和区域级视觉信息的场景图辅助解码器组成。设计了一种细粒度的句子级注意力方法来更好地提取场景图信息。大量实验表明，SGRG 在报告生成方面优于以前最先进的方法，并且可以更好地捕获异常发现。]]></description>
      <guid>https://arxiv.org/abs/2403.05687</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>用于通用无监督跨域检索的语义特征学习</title>
      <link>https://arxiv.org/abs/2403.05690</link>
      <description><![CDATA[arXiv:2403.05690v1 公告类型：新
摘要：跨域检索（CDR）作为众多技术的重要工具，正在得到越来越广泛的应用。然而，现有的努力面临几个重大问题，其中最关键的是需要准确的监管，这往往需要昂贵的资源和努力。前沿研究的重点是实现无监督的 CDR，但通常假设跨领域的类别空间是相同的，这种假设在现实场景中通常是不切实际的。这是因为只有通过专门、全面的分析才能确认不同领域的类别空间相同，这与无监督场景的前提相矛盾。因此，在这项工作中，我们首次引入了通用无监督跨域检索（U^2CDR）问题，并设计了一个两阶段语义特征学习框架来解决它。第一阶段，在实例原型混合对比损失和语义增强损失的指导下建立跨领域统一原型结构，以抵消类别空间差异。在第二阶段，通过改进的对抗训练机制，我们确保在域对齐过程中对已建立的原型结构进行最小的改变，从而实现更准确的最近邻搜索。跨多个数据集和场景（包括壁橱、部分和开放集 CDR）的广泛实验表明，我们的方法在解决 U^2CDR 挑战方面明显优于现有最先进的 CDR 工作以及其他主题的一些潜在有效的研究。]]></description>
      <guid>https://arxiv.org/abs/2403.05690</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>特征 CAM：图像分类中的可解释人工智能</title>
      <link>https://arxiv.org/abs/2403.05658</link>
      <description><![CDATA[arXiv:2403.05658v1 公告类型：新
摘要：深度神经网络由于其内层结构复杂、深层且不透明，通常被称为黑匣子。人们对在安全、金融、健康和制造业等关键和高精度领域使用人工智能缺乏信任。为了提供可解释的模型，人们做了很多有针对性的工作，旨在为神经网络的思想和行为提供有意义的见解。在我们的研究中，我们比较了基于激活的方法 (ABM) 中用于解释 CNN 模型预测的最先进方法，特别是在图像分类的应用中。然后，我们将其扩展到八种基于 CNN 的架构，以比较可视化和可解释性的差异。我们引入了一种新技术Feature CAM，它属于扰动-激活组合，用于创建细粒度、类别区分的可视化。事实证明，我们的实验得出的显着性图的人类可解释性比 ABM 中最先进的图要好 3-4 倍。同时它保留了机器可解释性，即分类的平均置信度分数。]]></description>
      <guid>https://arxiv.org/abs/2403.05658</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>音频同步视觉动画</title>
      <link>https://arxiv.org/abs/2403.05659</link>
      <description><![CDATA[arXiv:2403.05659v1 公告类型：新
摘要：当前的视觉生成方法可以生成由文本引导的高质量视频。然而，有效控制物体动力学仍然是一个挑战。这项工作探索音频作为生成时间同步图像动画的提示。我们引入了音频同步视觉动画（ASVA），这是一项对静态图像进行动画处理以演示运动动态的任务，由跨多个类的音频剪辑进行临时引导。为此，我们推出了 AVSync15，这是一个由 VGGSound 策划的数据集，其中包含跨 15 个类别的同步视听事件的视频。我们还提出了一种扩散模型 AVSyncD，能够生成由音频引导的动态动画。广泛的评估验证了 AVSync15 作为同步生成的可靠基准，并展示了我们模型的卓越性能。我们进一步探索 AVSyncD 在各种音频同步生成任务中的潜力，从生成没有基础图像的完整视频到用各种声音控制对象运动。我们希望我们建立的基准能够为可控视觉生成开辟新途径。更多视频请参见项目网页 https://lzhangbj.github.io/projects/asva/asva.html。]]></description>
      <guid>https://arxiv.org/abs/2403.05659</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>通过循环网络解耦退化，实现屏下摄像头的视频恢复</title>
      <link>https://arxiv.org/abs/2403.05660</link>
      <description><![CDATA[arXiv:2403.05660v1 公告类型：新
摘要：屏下摄像头（UDC）系统是全屏显示设备的基础，其中镜头安装在显示屏下方。用于显示器的发光二极管的像素阵列会衍射和衰减入射光，随着光强度的变化而导致各种性能下降。与通过同等对待不同退化因素来恢复视频的一般视频恢复不同，UDC 系统的视频恢复更具挑战性，涉及随着时间的推移消除各种退化，同时保持时间一致性。在本文中，我们介绍了一种新颖的视频恢复网络，称为 D$^2$RNet，专为 UDC 系统设计。它采用了一组解耦注意力模块（DAM），可以有效地分离各种视频质量下降因素。更具体地说，提出了一种软掩模生成函数，根据不同强度的入射光产生的衍射将每一帧表示为耀斑和雾霾，然后提出了利用长期和短期特征学习来消除耀斑和雾霾的组件。处理相应的降级。这种设计提供了有针对性的有效解决方案，以消除 UDC 系统中各种类型的退化。我们进一步将设计扩展到多尺度，以克服长距离视频中经常出现的尺度变化退化问题。为了证明 D$^2$RNet 的优越性，我们通过收集 HDR 视频并使用商业 UDC 系统测量的点扩散函数生成真实降级的视频，提出了大规模 UDC 视频基准。广泛的定量和定性评估证明了 D$^2$RNet 与其他最先进的视频恢复和 UDC 图像恢复方法相比的优越性。代码可在 https://github.com/ChengxuLiu/DDRNet.git 获取]]></description>
      <guid>https://arxiv.org/abs/2403.05660</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    </channel>
</rss>