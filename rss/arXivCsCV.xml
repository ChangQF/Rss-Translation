<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 15 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过变化估计的有效梯度样本大小，以加速锐度感知最小化</title>
      <link>https://arxiv.org/abs/2403.08821</link>
      <description><![CDATA[arXiv:2403.08821v1 公告类型：新
摘要：最近提出了锐度感知最小化（SAM）来提高模型泛化能力。然而，SAM 在每个优化步骤中计算梯度两次，因此与随机梯度下降 (SGD) 相比，计算成本增加了一倍。在本文中，我们提出了一种简单而有效的采样方法来显着加速 SAM。具体来说，我们发现 SAM 的梯度是 SGD 的梯度和二阶梯度矩阵到一阶梯度（PSF）的投影的组合。 PSF 在训练过程中表现出逐渐增加的变化频率。为了利用这一观察结果，我们提出了一种基于 PSF 变化的自适应采样方法，并将采样的 PSF 重新用于非采样迭代。大量的实证结果表明，所提出的方法在不同的网络架构上实现了与 SAM 相当的最先进的精度。]]></description>
      <guid>https://arxiv.org/abs/2403.08821</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>TINA：零样本视觉语言导航的思考、交互和行动框架</title>
      <link>https://arxiv.org/abs/2403.08833</link>
      <description><![CDATA[arXiv:2403.08833v1 公告类型：新
摘要：零样本导航是视觉语言导航（VLN）任务中的一个关键挑战，适应不熟悉的指令并在未知环境中采取行动的能力至关重要。现有的基于监督学习的模型，通过强化学习使用带注释的数据进行训练，在泛化能力方面表现出局限性。大型语言模型（LLM）凭借其广泛的知识和新兴的推理能力，为实现零样本导航提供了潜在的途径。本文提出了一种基于 LLM 的 VLN 代理，探索零样本导航问题的方法。为了弥补法学硕士在环境感知方面的不足，我们提出了思考、互动和行动（TINA）框架。 TINA 使智能体能够仔细检查感知信息，并通过引入的问答模块自主查询环境中的关键线索，从而将指令与特定的感知数据对齐。 TINA框架增强了导航代理的感知能力，而明确的思维和查询过程也提高了导航过程的可解释性和透明度。我们评估了我们的方法在 Room-to-Room 数据集上的性能。实验结果表明，我们的方法提高了基于 LLM 的代理的导航性能。我们的方法还优于一些基于监督学习的方法，突出了其在零样本导航中的功效。]]></description>
      <guid>https://arxiv.org/abs/2403.08833</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>NoiseDiffusion：使用超越球面线性插值的扩散模型校正图像插值的噪声</title>
      <link>https://arxiv.org/abs/2403.08840</link>
      <description><![CDATA[arXiv:2403.08840v1 公告类型：新
摘要：基于扩散模型的图像插值在创建新鲜有趣的图像方面很有前景。先进的插值方法主要集中于球面线性插值，将图像编码到噪声空间中，然后进行插值以对图像进行去噪。然而，现有方法在有效插值自然图像（不是由扩散模型生成）方面面临挑战，从而限制了它们的实际适用性。我们的实验研究表明，这些挑战源于编码噪声的无效性，编码噪声可能不再服从预期的噪声分布，例如正态分布。为了应对这些挑战，我们提出了一种纠正图像插值噪声的新方法，即 NoiseDiffusion。具体来说，NoiseDiffusion 通过引入细微的高斯噪声，并引入抑制极值噪声的约束，将无效噪声逼近预期分布。在这种情况下，提高噪声有效性有助于减轻图像伪影，但约束和引入的外源噪声通常会导致信噪比降低，即原始图像信息的丢失。因此，NoiseDiffusion 在噪声图像空间内执行插值，并将原始图像注入这些噪声对应图像中，以解决信息丢失的挑战。因此，NoiseDiffusion 使我们能够对自然图像进行插值，而不会造成伪影或信息丢失，从而获得最佳插值结果。]]></description>
      <guid>https://arxiv.org/abs/2403.08840</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>大规模图像分类器卷积神经网络的神经损失函数演化</title>
      <link>https://arxiv.org/abs/2403.08793</link>
      <description><![CDATA[arXiv:2403.08793v1 公告类型：新
摘要：对于分类，神经网络通常通过最小化交叉熵来学习，但使用准确性进行评估和比较。这种差异表明神经损失函数搜索（NLFS），即为神经网络寻找交叉熵的直接替代损失函数。我们将 NLFS 应用于图像分类器卷积神经网络。我们提出了一个新的 NLFS 搜索空间，鼓励探索更多样化的损失函数，以及准确转移到大规模卷积神经网络的代理函数。我们使用正则化进化（一种仅突变的老化遗传算法）来搜索空间。经过进化和提出的损失函数消除协议后，我们将最终的损失函数跨多个架构、数据集和图像增强技术进行转移，以评估泛化能力。最后，我们发现了三个新的损失函数，称为 NeuroLoss1、NeuroLoss2 和 NeuroLoss3，在大多数实验中，作为简单的插入式替换损失函数，它们能够在更高的平均测试精度方面优于交叉熵。]]></description>
      <guid>https://arxiv.org/abs/2403.08793</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>CoBra：用于鲁棒弱监督语义分割的补充分支融合类和语义知识</title>
      <link>https://arxiv.org/abs/2403.08801</link>
      <description><![CDATA[arXiv:2403.08801v1 公告类型：新
摘要：利用从图像级类知识派生的语义精确伪掩模进行分割，即图像级弱监督语义分割（WSSS），仍然具有挑战性。虽然使用 CNN 的类激活图 (CAM) 一直在为 WSSS 的成功做出贡献，但生成的激活图通常狭隘地关注特定于类的部分（例如，仅人脸）。另一方面，最近基于视觉变换器（ViT）的工作已经显示出基于其自注意力机制来捕获语义部分的有希望的结果，但未能捕获完整的特定于类的细节（例如，人类的整个身体部位，但也有附近有一只狗）。在这项工作中，我们提出了互补分支（CoBra），这是一种新颖的双分支框架，由两种不同的架构组成，为每个分支提供有价值的类（来自 CNN）和语义（来自 ViT）的互补知识。特别是，我们学习 CNN 分支的类感知投影（CAP）和 ViT 分支的语义感知投影（SAP），以明确融合它们的互补知识，并促进新型额外补丁级监督。我们的模型通过 CoBra 融合 CNN 和 ViT 的互补输出，创建强大的伪掩模，有效地集成类和语义信息。大量实验定性和定量研究了 CNN 和 ViT 如何在 PASCAL VOC 2012 数据集上相互补充，显示了最先进的 WSSS 结果。这不仅包括我们的模型生成的掩模，还包括利用这些掩模作为伪标签而得出的分割结果。]]></description>
      <guid>https://arxiv.org/abs/2403.08801</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>通过对抗性特征相似性学习进行对抗性鲁棒 Deepfake 检测</title>
      <link>https://arxiv.org/abs/2403.08806</link>
      <description><![CDATA[arXiv:2403.08806v1 公告类型：新
摘要：Deepfake 技术引起了人们对数字内容真实性的担忧，需要开发有效的检测方法。然而，深度造假的广泛存在带来了对抗性攻击形式的新挑战。对手可以通过微小的、难以察觉的扰动来操纵深度伪造视频，这些扰动可以欺骗检测模型产生错误的输出。为了解决这个关键问题，我们引入了对抗性特征相似性学习（AFSL），它集成了三种基本的深度特征学习范例。通过优化样本和权重向量之间的相似性，我们的方法旨在区分真实和虚假的实例。此外，我们的目标是最大化对抗性扰动示例和未扰动示例之间的相似性，无论其真实或虚假性质。此外，我们引入了一种正则化技术，可以最大化真实样本和假样本之间的差异，确保这两个类别之间的清晰分离。通过对流行的 Deepfake 数据集（包括 FaceForensics++、FaceShifter 和 DeeperForensics）进行大量实验，所提出的方法显着优于其他基于标准对抗训练的防御方法。这进一步证明了我们保护 Deepfake 探测器免受对抗性攻击的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.08806</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>物体检测验证——IBP IoU</title>
      <link>https://arxiv.org/abs/2403.08788</link>
      <description><![CDATA[arXiv:2403.08788v1 公告类型：新
摘要：我们引入了一种新颖的区间界限传播（IBP）方法，用于对象检测模型的形式验证，特别针对交并集（IoU）指标。该方法已在名为 IBP IoU 的开源代码中实现，与流行的基于抽象解释的验证工具兼容。由此产生的验证器在着陆进近跑道检测和手写数字识别案例研究中进行评估。与基线（Vanilla IBP IoU）的比较突显了 IBP IoU 在确保准确性和稳定性方面的卓越性能，有助于实现更安全、更稳健的机器学习应用。]]></description>
      <guid>https://arxiv.org/abs/2403.08788</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>连接人类概念和计算机视觉以进行可解释的面部验证</title>
      <link>https://arxiv.org/abs/2403.08789</link>
      <description><![CDATA[arXiv:2403.08789v1 公告类型：新
摘要：随着人工智能（AI）影响人脸验证等敏感应用的决策过程，确保决策的透明度、公平性和问责制至关重要。尽管可解释人工智能 (XAI) 技术的存在可以阐明人工智能决策，但为人类提供这些决策的可解释性也同样重要。在本文中，我们提出了一种结合计算机和人类视觉的方法，以提高人脸验证算法的解释的可解释性。特别是，我们受到人类感知过程的启发，了解机器在面部比较任务中如何感知面部的人类语义区域。我们使用 Mediapipe，它提供了一种分割技术，可以识别不同的人类语义面部区域，从而实现机器的感知分析。此外，我们采用了两种与模型无关的算法，为决策过程提供人类可解释的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.08789</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>实时面部表情识别：神经形态硬件与边缘人工智能加速器</title>
      <link>https://arxiv.org/abs/2403.08792</link>
      <description><![CDATA[arXiv:2403.08792v1 公告类型：新
摘要：本文重点关注实时面部表情识别（FER）系统作为社交机器人等各种现实应用中的重要组成部分。我们研究了在边缘部署 FER 机器学习 (ML) 模型的两种硬件选项：神经形态硬件与边缘 AI 加速器。我们的研究包括详尽的实验，提供英特尔 Loihi 神经拟态处理器和四种不同边缘平台之间的比较分析：Raspberry Pi-4、英特尔神经计算棒 (NSC)、Jetson Nano 和 Coral TPU。获得的结果表明，与功耗和能耗最低的边缘人工智能加速器 Coral TPU 相比，Loihi 可以实现大约两个数量级的功耗降低和一个数量级的节能。在实现功率和能量的降低的同时，神经形态解决方案保持了与边缘加速器相当的精度水平，所有这些都在实时延迟要求之内。]]></description>
      <guid>https://arxiv.org/abs/2403.08792</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>带有风格转换的程序地形生成</title>
      <link>https://arxiv.org/abs/2403.08782</link>
      <description><![CDATA[arXiv:2403.08782v1 公告类型：新
摘要：在这项研究中，我们引入了一种生成地形图的新技术，利用程序生成和神经风格迁移的组合。我们认为我们的方法是竞争生成模型的可行替代方案，我们的技术实现了更大的多功能性、更低的硬件要求以及设计师和开发人员创意过程中的更大集成。我们的方法涉及使用多层平滑高斯噪声或 Perlin 算法生成程序噪声图。然后，我们采用增强的神经风格转移技术，从真实世界的高度图绘制风格。算法生成和神经处理的融合有可能产生不仅多样化而且与现实世界景观的形态特征紧密结合的地形，我们的过程以低计算成本产生一致的地形结构，并提供创建的能力定制地图。数值评估进一步验证了我们的模型精确复制地形形态的增强能力，超越了传统的程序方法。]]></description>
      <guid>https://arxiv.org/abs/2403.08782</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用合成多模态错误信息进行图像文本脱离上下文检测</title>
      <link>https://arxiv.org/abs/2403.08783</link>
      <description><![CDATA[arXiv:2403.08783v1 公告类型：新
摘要：错误信息已成为数字信息不断增加的时代的主要挑战，需要开发有效的检测方法。我们研究了一种使用合成数据生成的脱离上下文检测 (OOCD) 的新方法。我们创建了一个专门为 OOCD 设计的数据集，并开发了一个用于准确分类的高效检测器。我们的实验结果验证了合成数据生成的使用，并证明了其在解决与 OOCD 相关的数据限制方面的功效。数据集和检测器应成为未来研究和开发强大的错误信息检测系统的宝贵资源。]]></description>
      <guid>https://arxiv.org/abs/2403.08783</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>通过自适应共识图过滤器的多视图子空间聚类</title>
      <link>https://arxiv.org/abs/2403.08787</link>
      <description><![CDATA[arXiv:2403.08787v1 公告类型：新
摘要：近年来，多视图子空间聚类（MVSC）引起了越来越多的关注。大多数现有的 MVSC 方法首先从不同视图收集互补信息，从而导出一致的重建系数矩阵来指示多视图数据集的子空间结构。在本文中，我们最初假设存在共识重建系数矩阵，然后使用它来构建共识图滤波器。在每个视图中，滤波器用于平滑数据并为重建系数矩阵设计正则化器。最后，使用从不同角度获得的重建系数矩阵来创建一致重建系数矩阵的约束。因此，在所提出的方法中，一致重建系数矩阵、一致图滤波器和来自不同视图的重建系数矩阵是相互依赖的。我们提供了一种优化算法来获得它们的最佳值。对不同多视图数据集的广泛实验表明，我们的方法优于一些最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.08787</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>Veagle：多模态表示学习的进展</title>
      <link>https://arxiv.org/abs/2403.08773</link>
      <description><![CDATA[arXiv:2403.08773v1 公告类型：新
摘要：最近，人工智能研究人员对语言和视觉如何结合非常感兴趣，从而促进了旨在无缝集成文本和视觉信息的多模态模型的发展。多模态模型是大型语言模型 (LLM) 的扩展，在解决从图像字幕和视觉问答 (VQA) 到视觉基础等各种任务方面表现出了卓越的能力。虽然这些模型展示了显着的进步，但准确解释图像和回答问题仍然存在挑战，这在现实场景中很常见。本文介绍了一种增强现有模型多模态能力的新方法。为了应对当前视觉语言模型 (VLM) 和多模态大语言模型 (MLLM) 中观察到的局限性，我们提出的模型 Veagle 结合了受先前工作的成功和见解启发的独特机制。 Veagle 利用动态机制将编码的视觉信息直接投射到语言模型中。这种动态方法可以更细致地理解视觉环境中存在的复杂细节。为了验证 Veagle 的有效性，我们对基准数据集进行了全面的实验，重点关注视觉问答和图像理解等任务。我们的结果表明，Veagle 的性能提高了 5-6%，明显优于现有模型。结果强调了该模型超越传统基准的多功能性和适用性。]]></description>
      <guid>https://arxiv.org/abs/2403.08773</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>利用基于聊天的大视觉语言模型进行多模式脱离上下文检测</title>
      <link>https://arxiv.org/abs/2403.08776</link>
      <description><![CDATA[arXiv:2403.08776v1 公告类型：新
摘要：脱离上下文（OOC）检测是一项具有挑战性的任务，涉及识别与其呈现的上下文无关的图像和文本。大型视觉语言模型 (LVLM) 在各种任务中都很有效，包括图像分类和文本生成。然而，他们在多模式 OOC 检测任务中的熟练程度尚不清楚。在本文中，我们研究了 LVLM 检测多模态 OOC 的能力，并表明这些模型在不进行微调的情况下无法在 OOC 检测任务上实现高精度。然而，我们证明了在多模态 OOC 数据集上微调 LVLM 可以进一步提高其 OOC 检测精度。为了评估 LVLM 在 OOC 检测任务上的性能，我们在 NewsCLIPpings 数据集（一个多模式 OOC 的大型数据集）上微调 MiniGPT-4。我们的结果表明，在 NewsCLIPpings 数据集上微调 MiniGPT-4 显着提高了该数据集中的 OOC 检测准确性。这表明微调可以显着提高 LVLM 在 OOC 检测任务上的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.08776</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>更快的投影 GAN：迈向更快的少样本图像生成</title>
      <link>https://arxiv.org/abs/2403.08778</link>
      <description><![CDATA[arXiv:2403.08778v1 公告类型：新
摘要： 为了解决 GAN 网络在图像生成中训练时间长、计算资源消耗大、参数量大的问题，在 Projected GAN 的基础上，提出一种改进的 GAN 网络模型，称为 Faster Projected GAN。所提出的网络主要集中在 Projected GAN 生成器的改进上。通过引入深度可分离卷积（DSC），减少了Projected GAN的参数数量，加快了训练速度，并且节省了内存。实验结果表明，在ffhq-1k、art-painting、Landscape等少样本图像数据集上，实现了20%的速度提升和15%的内存节省。同时FID损失较少或无损失，模型参数量得到更好的控制。同时，在公共数据集较少的地震场景等特殊场景的小样本图像生成任务中，取得了显着的训练速度提升。]]></description>
      <guid>https://arxiv.org/abs/2403.08778</guid>
      <pubDate>Fri, 15 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    </channel>
</rss>