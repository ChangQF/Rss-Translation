<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Fri, 15 Dec 2023 03:14:53 GMT</lastBuildDate>
    <item>
      <title>ConFormer：深度学习模型的新集合，可帮助心脏病专家评估心脏功能。 (arXiv:2312.08567v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.08567</link>
      <description><![CDATA[心血管疾病，特别是心力衰竭，是导致心血管疾病的主要原因
全球死亡。通过常规检查早期发现心力衰竭
超声心动图筛查往往因成本高且劳动密集而受到阻碍
这些程序的性质，可能意味着生命之间的差异的障碍
和死亡。本文提出了 ConFormer，一种新颖的深度学习模型，旨在
自动估计射血分数 (EF) 和左心室壁
超声心动图的厚度。 ConFormer 的实现有
通过实现具有成本效益的、增强预防性心脏病学的潜力，
方便且全面的心脏健康监测，从而节省了无数
生活。源代码可在 https://github.com/Aether111/ConFormer 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.08567</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>NViST：使用 Transformer 从单个图像进行野外新视图合成。 （arXiv：2312.08568v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08568</link>
      <description><![CDATA[我们提出了 NViST，一种基于变压器的模型，用于从
单个图像，在大规模野外图像数据集上进行训练
复杂的背景。 NViST 将图像输入直接转换为辐射亮度
领域，采用可扩展的基于变压器的架构。在实践中，NViST
利用由掩码自动编码器（MAE）学习的自监督特征，并且
学习一种新颖的解码器，通过以下方式将特征转换为 3D 标记：
交叉注意力和自适应层归一化。我们的模型的效率是
推理，因为只需要一次前向传播来预测 3D
表示，与需要测试时优化或采样的方法不同
例如 3D 感知扩散模型。我们解决当前的进一步限制
新视图综合模型。首先，与大多数生成模型不同
以特定类别的方式进行训练，通常在合成数据集或屏蔽数据集上进行训练
输入，我们的模型在 MVImgNet 上进行训练，MVImgNet 是一个真实世界的大规模数据集，
随意拍摄的视频，包含数百个不同类别的对象
背景。其次，我们的模型不需要规范化
训练数据 - 即用正面视图对齐所有对象 - 只需要
训练时的相对姿势，消除了训练时的实质性障碍
用于随意捕获的数据集。我们展示了看不见的物体的结果
MVImgNet 上的类别，甚至是随意的手机捕获。我们进行定性
对 MVImgNet 和 ShapeNet 的定量评估表明我们的模型
代表着朝着实现真正的野外小说视角迈出了一步
从单个图像合成。
]]></description>
      <guid>http://arxiv.org/abs/2312.08568</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>G-MEMP：驾驶中的注视增强多模态自我运动预测。 （arXiv：2312.08558v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08558</link>
      <description><![CDATA[了解司机的决策过程是关键之一
确保道路安全。虽然驾驶员意图和由此产生的自我运动
轨迹对于开发驾驶辅助系统、现有的
方法主要关注其他车辆的运动。相比之下，我们关注的是
使用驾驶员的视线数据推断其车辆的自我轨迹。为了
为此，我们首先收集一个新的数据集 GEM，其中包含高保真度
自我运动视频与驾驶员的眼球追踪数据和 GPS 坐标相结合。
接下来，我们开发了 G-MEMP，一种新型的多模态自我轨迹预测网络
它将 GPS 和视频输入与注视数据相结合。我们还提出了一个新的指标
称为路径复杂度指数（PCI）来衡量轨迹复杂度。我们
在 GEM 和 DR(eye)VE 上对所提出的方法进行广泛的评估，
现有的基准数据集。结果表明，G-MEMP显着
在两个基准测试中都优于最先进的方法。此外，消融
研究表明，使用凝视可将平均位移提高 20% 以上
数据，特别是在具有高 PCI 的挑战性驾驶场景中。数据，
代码和模型可以在 https://eth-ait.github.io/g-memp/ 找到。
]]></description>
      <guid>http://arxiv.org/abs/2312.08558</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>Efficient-NeRF2NeRF：通过多视图对应增强扩散模型简化文本驱动的 3D 编辑。 （arXiv：2312.08563v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08563</link>
      <description><![CDATA[文本驱动的 3D 内容编辑的进步得到了
二维生成扩散模型的进展。然而，一个主要障碍
阻碍 3D 内容编辑广泛采用的一个因素是其耗时
加工。这一挑战来自迭代和细化步骤
从基于 2D 图像的生成中获得一致的 3D 输出所需
楷模。最近最先进的方法通常需要优化时间
使用单个 3D 场景编辑 3D 场景的时间从几十分钟到几个小时不等
图形处理器。在这项工作中，我们建议通过合并信件
正则化为扩散模型，3D编辑的过程可以是
显着加速。这种方法的灵感来自于这样一个概念：
扩散过程中估计的样本应该是多视图一致的
扩散生成过程。通过利用这种多视图一致性，我们可以
以更快的速度编辑 3D 内容。在大多数情况下，我们建议的
与基线方法相比，该技术带来了 10$\times$ 的加速
在 2 分钟内完成 3D 场景的编辑，质量相当。
]]></description>
      <guid>http://arxiv.org/abs/2312.08563</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:51 GMT</pubDate>
    </item>
    <item>
      <title>EVP：使用逆多注意力特征细化和正则化图像文本对齐增强视觉感知。 （arXiv：2312.08548v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08548</link>
      <description><![CDATA[这项工作提出了网络架构 EVP（增强视觉感知）。
EVP 建立在之前的工作 VPD 之上，为使用 Stable 铺平了道路
用于计算机视觉任务的扩散网络。我们提出两项主要改进。
首先，我们开发逆多注意力特征细化（IMAFR）模块
通过聚合空间信息来增强特征学习能力
来自更高的金字塔级别。其次，我们提出了一种新颖的图像文本对齐方式
用于改进稳定扩散主干的特征提取的模块。这
由此产生的架构适用于各种任务，我们
展示其在单图像深度估计中的性能
使用基于分类的箱和引用的专用解码器
使用现成的解码器进行分段。进行了综合实验
在已建立的数据集上的研究表明，EVP 在以下方面取得了最先进的结果：
室内单图像深度估计（NYU Depth v2，11.8% RMSE 改进
over VPD）和室外（KITTI）环境，以及引用细分
（RefCOCO，比 ReLA 的 IoU 提高了 2.53）。代码和预训练模型是
可在 https://github.com/Lavreniuk/EVP 公开获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.08548</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>KDAS3：通过注意力监督进行知识蒸馏，以及用于息肉分割的对称结构指导。 (arXiv:2312.08555v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.08555</link>
      <description><![CDATA[息肉分割是医学成像中一个有争议的问题，已经出现了许多
提出的方法旨在提高分段掩模的质量。现在，
最先进的技术产生了令人印象深刻的结果。然而，庞大的规模
这些模型对实际工业应用提出了挑战。到
为了解决这个问题，我们提出了一个知识蒸馏框架，其中包含
注意监督和对称引导法。这个框架是
旨在促进知识从教师模式向更多人的转移
参数较少的紧凑学生模型。我们的实验评估
框架评估其在使学生模型获得能力方面的有效性
有效地从老师那里获得知识。此外，我们的方法还可以
防止学生模型合并可能导致的冗余特征
到不准确的预测。因此，我们的方法拥有大约 5
万个参数，达​​到了与
最先进的方法。实现可以在以下位置找到：
https://github.com/huyquoctrinh/KDAS3
]]></description>
      <guid>http://arxiv.org/abs/2312.08555</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>M3T：用于视频对象分割和跟踪的多尺度内存匹配。 （arXiv：2312.08514v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08514</link>
      <description><![CDATA[视频对象分割 (VOS) 变得越来越重要
更大的数据集和更复杂、更现实的设置的可用性，
涉及具有全局运动的长视频（例如，在以自我为中心的设置中），描绘
经历刚性和非刚性（包括状态）的小物体
变形。虽然最近已经为此探索了许多方法
任务中，这些数据特征仍然存在挑战。在这项工作中我们
提出了一种新颖的 DETR 式编码器-解码器架构，其重点是
系统地分析和解决上述挑战。
具体来说，我们的模型可以对长视频进行在线推理
窗口时尚，通过将视频分解为剪辑并传播上下文
其中使用时间编码存储器。我们说明短剪辑长度和
具有学习时间编码的更长记忆是重要的设计选择
实现最先进的 (SoTA) 性能。此外，我们提出多尺度
匹配和解码以确保小物体的灵敏度和准确性。
最后，我们提出了一种新颖的训练策略，将学习重点放在部分上
视频中物体发生显着变形——一种形式
“软”硬负挖掘，以损失重新加权的形式实施。总的来说，
这些技术贡献使我们的模型能够实现 SoTA 性能
两个复杂的数据集——VISOR 和 VOST。一系列详细的消融验证
我们的设计选择以及对参数重要性的见解
选择及其对绩效的影响。
]]></description>
      <guid>http://arxiv.org/abs/2312.08514</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>一种有趣的压缩 HDR 视频质量评估方法。 (arXiv:2312.08524v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.08524</link>
      <description><![CDATA[近年来，其受欢迎程度和可用性稳步增长
高动态范围 (HDR) 内容，特别是视频，通过流式传输
互联网。因此，评估 HDR 视频的主观质量，
通常受到压缩，因此变得越来越重要。在
特别是，我们的目标是全参考质量评估的任务
压缩的 HDR 视频。最先进的 (SOTA) 方法 HDRMAX 涉及
增强现成的视频质量模型，例如 VMAF，具有以下功能
在非线性变换的视频帧上计算。然而，HDRMAX 增加了
VMAF 等模型的计算复杂性。在这里，我们展示了一个
名为 FUNQUE+ 的高效视频质量预测模型实现了 SOTA
准确性。这表明 FUNQUE+ 模型是 VMAF 的灵活替代方案
以较低的成本实现更高的 HDR 视频质量预测精度
计算成本。
]]></description>
      <guid>http://arxiv.org/abs/2312.08524</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉变压器的深度学习用于子宫内膜癌的组织学分类。 （arXiv：2312.08479v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08479</link>
      <description><![CDATA[子宫内膜癌是全球女性第六大常见癌症，
表现为一个异质群体，某些类型容易复发。
子宫内膜癌的精确组织学评估对于有效治疗至关重要
患者管理并确定最佳治疗方式。这项研究
推出 EndoNet，一种基于 Transformer 的组织学深度学习方法
子宫内膜癌的分类。 EndoNet 使用卷积神经网络
用于提取组织学特征的网络和视觉转换器
聚合这些特征并根据幻灯片的视觉效果对其进行分类
特征。该模型在 929 数字化苏木精上进行了训练
子宫切除病例中子宫内膜癌的伊红染色全玻片图像
在达特茅斯健康中心。它将这些幻灯片分类为低级（子宫内膜
1级和2级）和高级别（子宫内膜癌FIGO 3级，子宫
浆液性癌、癌肉瘤）类别。 EndoNet 的评估基于
218 张幻灯片的内部测试集和 100 张随机幻灯片的外部测试集
来自公共 TCGA 数据库。该模型取得了加权平均 F1 分数
为 0.92（95% CI：0.87-0.95），AUC 为 0.93（95% CI：0.88-0.96）
内部测试，F1 分数为 0.86（95% CI：0.80-0.94），F1 分数为 0.86（95% CI：
0.75-0.93) 外部测试的 AUC。等待进一步验证，EndoNet
有潜力协助病理学家对具有挑战性的妇科疾病进行分类
病理肿瘤和加强患者护理。
]]></description>
      <guid>http://arxiv.org/abs/2312.08479</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>用于二维姿态估计的 PnP。 （arXiv：2312.08488v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2312.08488</link>
      <description><![CDATA[我们提出了一种适用于二维相机的 PnP 算法
运动（例如，适用于许多轮式机器人平台）。
利用这一假设可以提高 3D PnP 的性能
由于搜索空间维数的减少而导致的算法。它还减少了
模糊姿态估计的发生率（在大多数情况下，虚假的
解决方案落在运动平面之外）。我们的算法找到了一个
使用几何标准近似解并细化其预测
迭代地。我们将该算法与现有的 3D PnP 算法进行比较
一般和共面点配置的情况。
]]></description>
      <guid>http://arxiv.org/abs/2312.08488</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>草地监测中的可解释人工智能：增强模型性能和领域适应性。 （arXiv：2312.08408v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.08408</link>
      <description><![CDATA[草原以其高度的生物多样性和提供
多种生态系统服务。自动识别的挑战
指示植物是大规模草原监测的主要障碍。这些
挑战源于广泛数据集的稀缺、分布式
通用数据集和草原特定数据集之间的转换以及固有的
深度学习模型的不透明性。本文深入探讨了后两者
挑战，特别关注迁移学习和可解释
草原监测的人工智能（XAI）方法，强调
XAI 在这个领域的新颖性。我们分析各种迁移学习方法
弥合通用和草原特定之间的分配差距
数据集。此外，我们还展示了可解释的人工智能技术如何揭示
模型的领域适应能力，采用定量评估
评估模型准确居中相关输入的能力
感兴趣的对象周围的特征。这项研究贡献了宝贵的
通过迁移学习和增强模型性能的见解
通过可解释的人工智能测量领域适应性，显示出巨大的前景
以便在农业界得到更广泛的应用。
]]></description>
      <guid>http://arxiv.org/abs/2312.08408</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>FaceTalk：神经参数头部模型的音频驱动运动扩散。 （arXiv：2312.08459v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08459</link>
      <description><![CDATA[我们介绍 FaceTalk，一种专为合成而设计的新颖生成方法
输入音频中说话的人头的高保真 3D 运动序列
信号。捕捉人类头部富有表现力的细节，包括
头发、耳朵和更精细的眼球运动，我们建议耦合语音信号
利用神经参数头部模型的潜在空间来创建高保真度，
时间相干的运动序列。我们提出了一种新的潜在扩散模型
对于此任务，在神经参数头的表达空间中进行操作
模型，以合成音频驱动的逼真头部序列。在缺少...之下
具有与音频对应的 NPHM 表达式的数据集，我们针对这些进行优化
生成时间优化的 NPHM 表达式数据集的对应关系
适合人们谈话的音频视频记录。据我们所知，
这是第一个提出现实和现实的生成方法的作品
立体人体头部的高质量运动合成，代表
音频驱动的 3D 动画领域取得了重大进展。值得注意的是，我们的
该方法的突出之处在于它能够生成合理的运动序列，
可以产生与 NPHM 形状空间相结合的高保真头部动画。我们的
实验结果一致证实了 FaceTalk 的有效性
实现卓越且视觉上自然的运动，涵盖多样化的面部
表达方式和风格，在感知上优于现有方法 75%
用户研究评估。
]]></description>
      <guid>http://arxiv.org/abs/2312.08459</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>全局优化的SAR图像分割模型可以很容易地转化为通用的ROF去噪模型。 （arXiv：2312.08376v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08376</link>
      <description><![CDATA[在本文中，我们提出了一种新颖的局部统计活动轮廓模型
(LACM) 基于 Aubert-Aujol (AA) 去噪模型和变分水平集
方法，可用于SAR图像强度分割
不均匀性。然后我们将所提出的模型转化为全局优化
使用凸松弛技术建立模型。首先，我们应用Split Bregman
将全局优化模型转化为两个交替的技术
Shrink算子和Laplace算子的优化过程，称为
SB_LACM 模型。此外，我们提出了两种快速模型来解决全局问题
优化模型 ，比 SB_LACM 模型更高效。首先
模型是：我们添加近端函数来改造全局优化
模型到一般的ROF模型[29]，可以通过快速去噪来解决
R.-Q.Jia和H.Zhao提出的算法；这样我们就得到了快速分割
具有全局优化求解器的算法，不涉及部分
微分方程或差分方程，只需简单差分
计算。第二个模型是：我们使用与
一种将全局优化模型转换为可微项的模型
和一个通用的 ROF 模型项，可以通过与
第一个模型。使用一些具有挑战性的合成图像和 Envisat 进行实验
SAR 图像证明了我们提出的模型在以下方面的优越性：
最先进的模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.08376</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>用于完全测试时适应的奇异值惩罚和语义数据增强。 （arXiv：2312.08378v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2312.08378</link>
      <description><![CDATA[完全测试时适应 (FTTA) 适应在源上训练的模型
在测试阶段将域转换为目标域，其中两个域
遵循不同的分布并且源数据在期间不可用
训练阶段。现有方法通常采用熵最小化来减少
目标预测结果的不确定性，提高FTTA性能
因此。然而，他们无法确保目标预测的多样性
结果。最近的领域适应研究表明，最大化
预测结果的奇异值可以同时增强其
信心（可辨别性）和多样性。然而在训练过程中
阶段，较大的奇异值通常在损失中占据主导地位
最大化。这导致模型更倾向于增强
易于区分的类别的可区分性，以及改进
多样性不够有效。此外，适应和
FTTA 中的预测仅使用当前批次的数据，这可能会导致
过度拟合的风险。针对上述问题，我们建议
最大化奇异值的总和，同时最小化其方差。这
使模型能够专注于较小的奇异值，从而增强
更具挑战性的类别之间的区分度并有效提高
预测结果的多样性。此外，我们还整合了来自
前一个批次实现当前批次的语义数据增强，
降低过度拟合的风险。对基准数据集进行广泛的实验
表明我们提出的方法优于一些最先进的 FTTA
方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.08378</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>更进一步：利用伪标签在标签稀缺的小农地区进行田野划分。 （arXiv：2312.08384v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.08384</link>
      <description><![CDATA[迁移学习可以实现资源高效的地理迁移
预先训练的场地描绘模型。然而，缺乏标记数据
复杂且充满活力的小农景观，特别是在撒哈拉以南非洲地区，
仍然是大面积场地圈定的主要瓶颈。这项研究
探索使用稀疏字段描绘伪标签的机会
跨地域和传感器特性微调模型。我们建立在
FracTAL ResUNet 在印度接受了作物田地划定培训（中位田地大小
0.24 公顷）并使用此预训练模型生成伪标签
莫桑比克（土地面积中位数为 0.06 公顷）。我们设计了多个伪标签
选择策略并比较数量、面积特性、季节
伪标签的分布和空间一致性
人工注释的训练标签（n = 1,512）。然后我们使用人工注释的
用于模型微调和比较预测的标签和伪标签
针对人类现场注释（n = 2,199）。我们的结果表明 i) 良好
预训练模型在场地描绘和区域划分方面的基线性能
区域大小估计，以及 ii) 区域微调的附加值
几乎所有实验的性能都有所提高。此外，我们发现iii)
仅使用伪标签时，性能会显着提高（高达 77%）
通过人类标签获得的 IoU 增加和 RMSE 减少 68%），以及
iv) 当补充人工注释时，额外的性能会提高
伪标签。伪标签可以大规模有效地生成，因此
促进标签稀缺环境中的域适应。提出的工作流程
这是克服持续存在的数据差距的基石
撒哈拉以南非洲的异质小农农业，标签是
普遍稀缺。
]]></description>
      <guid>http://arxiv.org/abs/2312.08384</guid>
      <pubDate>Fri, 15 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    </channel>
</rss>