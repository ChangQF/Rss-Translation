<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 06 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>BSDP：用于在线开放世界对象检测的受大脑启发的流式双级扰动</title>
      <link>https://arxiv.org/abs/2403.02637</link>
      <description><![CDATA[arXiv:2403.02637v1 公告类型：新
摘要：人类可以轻松区分已知和未知类别，并且通过学习一次就可以识别未知对象，而不是重复多次而不会忘记所学的对象。因此，我们的目标是让深度学习模型模拟人们的学习方式。我们将这种学习方式称为在线开放世界对象检测（OLOWOD）。现有的OWOD方法更注重未知类别的识别，而增量学习部分也非常重要。此外，一些神经科学研究表明，特定的噪音可以让大脑形成新的连接和神经通路，从而提高学习速度和效率。在本文中，我们将旧样本的双级信息作为对新样本的扰动，使模型善于学习新知识而不忘记旧知识。因此，我们提出了一种简单的即插即用方法，称为脑启发流双级扰动（BSDP），来解决 OLOWOD 问题。具体来说，（1）我们首先计算之前类别的原型，并使用样本与原型之间的距离作为样本选择策略，选择旧样本进行重放； （2）然后将原型作为新样本的流式特征级扰动，通过重温旧知识来提高模型的可塑性； （3）并且还利用旧类别样本的特征分布以流的形式生成对抗性数据作为数据级扰动，以增强模型对新类别的鲁棒性。我们在 PASCAL VOC 和 MS-COCO 上对 BSDP 进行了实证评估，优异的结果证明了我们提出的方法和学习方式的良好性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02637</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>建模协作者：通过 LLM 工具使用以最少的人力实现主观视觉分类</title>
      <link>https://arxiv.org/abs/2403.02626</link>
      <description><![CDATA[arXiv:2403.02626v1 公告类型：新
摘要：从内容审核到野生动物保护，需要模型识别细微差别或主观视觉概念的应用程序数量正在不断增加。传统上，为此类概念开发分类器需要大量的手动工作（以小时、天甚至月为单位）来识别和注释训练所需的数据。即使使用最近提出的敏捷建模技术，可以快速引导图像分类器，用户仍然需要花费 30 分钟或更长时间的单调、重复的数据标记来训练单个分类器。借鉴 Fiske 的认知守财奴理论，我们提出了一个新的框架，通过用自然语言交互代替人类标记来减轻人工工作量，从而将定义概念所需的总工作量减少一个数量级：从标记 2,000 张图像到仅标记 100 张加上一些自然图像语言互动。我们的框架利用基础模型（大型语言模型和视觉语言模型）的最新进展，通过对话和自动标记训练数据点来开拓概念空间。最重要的是，我们的框架消除了对众包注释的需要。此外，我们的框架最终产生可部署在成本敏感场景中的轻量级分类模型。在 15 个主观概念和 2 个公共图像分类数据集中，我们训练的模型优于传统的敏捷建模以及最先进的零样本分类模型（如 ALIGN、CLIP、CuPL）和大型视觉问答模型（如 PaLI） -X。]]></description>
      <guid>https://arxiv.org/abs/2403.02626</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>交互式持续学习：快思考和慢思考</title>
      <link>https://arxiv.org/abs/2403.02628</link>
      <description><![CDATA[arXiv:2403.02628v1 公告类型：新
摘要：高级生命形式由神经认知机制的协同相互作用维持，在其一生中不断获取和转移知识。相比之下，当代机器学习范式在模拟持续学习（CL）方面表现出局限性。尽管如此，大型语言模型 (LLM) 的出现为通过与这些模型的交互来实现 CL 提供了有希望的途径。本文借鉴互补学习系统理论，提出了一种新颖的交互式持续学习（ICL）框架，该框架通过各种规模的模型之间的协作交互来实现。具体来说，我们将 ViT 模型指定为 System1，将多模态 LLM 指定为 System2。为了使记忆模块能够从类信息中推断任务并增强 Set2Set 检索，我们提出了类知识任务多头注意力（CKT-MHA）。此外，为了通过增强几何表示来改进 System1 中的内存检索，我们引入了基于 von Mises-Fisher (vMF) 分布的 CL-vMF 机制。同时，我们引入了 von Mises-Fisher 离群点检测和交互（vMF-ODI）策略来识别困难示例，从而增强 System1 和 System2 之间的协作以实现复杂的推理。对我们提出的 ICL 的综合评估表明，相对于现有方法，具有显着的抗遗忘能力和优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02628</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>我们从反演 CLIP 模型中学到了什么？</title>
      <link>https://arxiv.org/abs/2403.02580</link>
      <description><![CDATA[arXiv:2403.02580v1 公告类型：新
摘要：我们采用基于反演的方法来检查 CLIP 模型。我们的研究表明，反转 CLIP 模型会生成与指定目标提示语义一致的图像。我们利用这些倒置图像来深入了解 CLIP 模型的各个方面，例如它们融合概念和包容性别偏见的能力。我们在模型反演过程中特别观察到 NSFW（工作不安全）图像的实例。即使对于语义上无害的提示（例如“美丽的风景”）以及涉及名人姓名的提示，也会发生这种现象。]]></description>
      <guid>https://arxiv.org/abs/2403.02580</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>VEglue：通过对象对齐联合擦除测试视觉蕴涵系统</title>
      <link>https://arxiv.org/abs/2403.02581</link>
      <description><![CDATA[arXiv:2403.02581v1 公告类型：新
摘要：视觉蕴涵（VE）是一种由图像-句子对组成的多模态推理任务，其中由图像定义承诺，由句子描述假设。目标是预测图像在语义上是否包含句子。 VE系统已广泛应用于许多下游任务中。变形测试是 AI 算法最常见的技术，但它对 VE 测试提出了重大挑战。他们要么只考虑单一模态的扰动，这会由于图文对关系的破坏而导致测试无效，要么只是对输入进行浅层扰动，很难检测到VE系统做出的决策错误。由于图像中的对象是推理的基本元素，我们提出了 VEglue，一种用于 VE 系统测试的对象对齐联合擦除方法。它首先对齐前提中的对象区域和假设中的对象描述，以识别链接和未链接的对象。然后，根据对齐信息，设计三个变形关系来共同擦除两种模态的对象。我们在涉及两个公共数据集的四个广泛使用的 VE 系统上评估 VEglue。结果显示，VEglue 平均可以检测到 11,609 个问题，比基线多 194%-2,846%。此外，VEglue 平均问题发现率 (IFR) 可达 52.5%，明显优于基线 17.1%-38.2%。此外，我们利用 VEglue 生成的测试来重新训练 VE 系统，这大大提高了新生成的测试的模型性能（准确率提高了 50.8%），而无需牺牲原始测试集的准确率。]]></description>
      <guid>https://arxiv.org/abs/2403.02581</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>具有多金字塔变压器和对比学习的显微镜散焦去模糊统一框架</title>
      <link>https://arxiv.org/abs/2403.02611</link>
      <description><![CDATA[arXiv:2403.02611v1 公告类型：新
摘要：散焦模糊是显微镜成像中长期存在的问题，对细胞显微镜和显微镜手术的病理解释和医疗干预造成损害。为了解决这个问题，提出了一个包括多金字塔变换器（MPT）和扩展频率对比正则化（EFCR）的统一框架，以解决显微镜去模糊中的两个突出挑战：更长的注意力广度和特征缺陷。 MPT在每个网络阶段采用显式金字塔结构，集成跨尺度窗口注意力（CSWA）、内尺度通道注意力（ISCA）和特征增强前馈网络（FEFN）来捕获长程跨尺度空间互动和全球渠道环境。 EFCR 通过探索来自不同频段的潜在去模糊信号来解决特征缺陷问题。它还支持去模糊知识转移，以从额外数据中学习跨域信息，从而提高标记和未标记数据的去模糊性能。广泛的实验和下游任务验证表明该框架在多个数据集上实现了最先进的性能。项目页面：https://github.com/PieceZhang/MPT-CataBlur。]]></description>
      <guid>https://arxiv.org/abs/2403.02611</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>使用纹理进行语义人体网格重建</title>
      <link>https://arxiv.org/abs/2403.02561</link>
      <description><![CDATA[arXiv:2403.02561v1 公告类型：新
摘要：近年来，3D 详细人体网格重建领域取得了重大进展。然而，由于结果不稳定、网格质量低以及缺乏 UV 展开和蒙皮权重，当前方法在工业应用中仍然面临挑战。在本文中，我们提出了 SHERT，这是一种新颖的管道，可以利用纹理和高精度细节重建语义人体网格。 SHERT 在详细表面（例如网格和 SDF）与相应的 SMPL-X 模型之间应用基于语义和法线的采样，以获得部分采样的语义网格，然后通过我们专门设计的自监督完成和细化生成完整的语义网格网络。以完整的语义网格为基础，我们采用纹理扩散模型来创建由图像和文本驱动的人体纹理。我们重建的网格具有稳定的 UV 展开、高质量的三角形网格和一致的语义信息。给定的 SMPL-X 模型提供了语义信息和形状先验，使得 SHERT 即使在输入不正确和不完整的情况下也能表现良好。语义信息还可以轻松地替换和动画不同的身体部位，例如面部、身体和手。定量和定性实验表明，SHERT 能够生成高保真且稳健的语义网格，其性能优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.02561</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>手语人工智能研究中的系统性偏见：聋人主导的重新评估研究议程的呼吁</title>
      <link>https://arxiv.org/abs/2403.02563</link>
      <description><![CDATA[arXiv:2403.02563v1 公告类型：新
摘要：随着人工智能手语识别、生成和翻译研究的不断发展，人们呼吁此类技术的道德发展。虽然这些工作对于帮助个体研究人员做得更好至关重要，但明显缺乏对系统偏见的讨论或对影响该领域研究问题和方法的修辞分析，特别是因为该领域仍然由听力非签名研究人员主导。因此，我们对手语人工智能领域的 101 篇最新论文进行了系统回顾。我们的分析发现了手语人工智能研究现状中的重大偏见，包括过度关注解决感知到的沟通障碍、缺乏代表性数据集的使用、使用缺乏语言基础的注释以及开发基于有缺陷的模型的方法。我们的立场是，该领域缺乏聋人利益相关者的有意义的投入，而是由对听力研究人员来说最方便或认为重要的决策来驱动。最后，我们呼吁采取行动：该领域必须为聋人研究人员腾出空间，以引导手语人工智能的对话。]]></description>
      <guid>https://arxiv.org/abs/2403.02563</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络什么时候停止学习？</title>
      <link>https://arxiv.org/abs/2403.02473</link>
      <description><![CDATA[arXiv:2403.02473v1 公告类型：新
摘要：卷积神经网络（CNN）在图像分类、检测、分割和医学图像分析等计算机视觉任务中表现出了出色的性能。一般来说，使用任意数量的纪元来训练此类神经网络。在一个时期内，整个训练数据（除以批量大小）都会被输入到网络中。在实践中，带有训练损失的验证误差用于估计神经网络的泛化能力，这表明网络的最佳学习能力。目前的做法是当训练损失减少并且训练和验证误差之间的差距增大（即泛化差距）时停止训练，以避免过度拟合。然而，这是一种基于试错的方法，提出了一个关键问题：是否可以根据训练数据来估计神经网络何时停止学习？这项研究工作引入了一个假设，该假设分析 CNN 变体所有层的数据变化，以预测其接近最佳的学习能力。在训练阶段，我们使用我们的假设来预测 CNN 变体的接近最优的学习能力，而不使用任何验证数据。我们的假设可以作为即插即用的方式部署到任何现有的 CNN 变体，而无需向网络引入额外的可训练参数。我们在六种不同的 CNN 变体和三个不同的通用图像数据集（CIFAR10、CIFAR100 和 SVHN）上测试我们的假设。基于这些 CNN 变体和数据集的结果表明，我们的假设在训练中节省了 58.49% 的计算时间（平均）。我们进一步对十个医学图像数据集进行假设，并与 MedMNIST-V2 基准进行比较。根据我们的实验结果，我们节省了 $\approx$ 44.1\% 的计算时间，同时又不损失与 MedMNIST-V2 基准相比的准确性。]]></description>
      <guid>https://arxiv.org/abs/2403.02473</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>通过图像字幕进行差分私人表示学习</title>
      <link>https://arxiv.org/abs/2403.02506</link>
      <description><![CDATA[arXiv:2403.02506v1 公告类型：新
摘要：差分隐私（DP）机器学习被认为是从敏感数据训练模型同时仍然保护隐私的黄金标准解决方案。然而，实现这一理想的一个主要障碍是其次优的隐私准确性权衡，这在 DP 表示学习中尤其明显。具体来说，事实证明，在适度的隐私预算下，大多数模型学习的表示并不比手工制作的特征好得多。在这项工作中，我们证明了可以通过图像字幕和扩展到互联网规模的多模态数据集来完成有效的 DP 表示学习。通过一系列的工程技巧，我们使用合理的计算量从头开始在 LAION-2B 的 233M 子集上成功训练了 DP 图像字幕器（DP-Cap），并获得了前所未有的高质量图像特征，可用于各种下游视觉和视觉语言任务。例如，在隐私预算为 $\varepsilon=8$ 的情况下，基于学习的 DP-Cap 特征训练的线性分类器在 ImageNet-1K 上达到了 65.8% 的准确率，大大提高了之前 56.5% 的 SOTA。我们的工作挑战了普遍的观点，即高实用性的 DP 表示学习无法通过从头开始训练来实现。]]></description>
      <guid>https://arxiv.org/abs/2403.02506</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>超过一千次电池计算机断层扫描的数据集</title>
      <link>https://arxiv.org/abs/2403.02527</link>
      <description><![CDATA[arXiv:2403.02527v1 公告类型：新
摘要：电池技术对于全球电气化工作越来越重要。然而，电池对微小的制造变化非常敏感，这可能会引发可靠性或安全问题。电池质量控制的一项重要技术是计算机断层扫描 (CT) 扫描，该技术广泛用于各种临床和工业应用中的无损 3D 检查。然而，从历史上看，CT 扫描在大批量制造中的实用性一直受到其低吞吐量以及处理大文件大小的困难的限制。在这项工作中，我们提供了超过一千张商用电池 CT 扫描数据集。该数据集涵盖各种化学成分（锂离子和钠离子）以及各种电池形状因素（圆柱形、袋装和棱柱形）。我们总共评估了七种不同的电池类型。通过该数据集可以观察制造的可变性和电池缺陷的存在。研究电池技术、计算机视觉或两者的科学家和工程师可能会对这个数据集感兴趣。]]></description>
      <guid>https://arxiv.org/abs/2403.02527</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>优化双曝光 HDR 成像中的光源估计</title>
      <link>https://arxiv.org/abs/2403.02449</link>
      <description><![CDATA[arXiv:2403.02449v1 公告类型：新
摘要：高动态范围（HDR）成像涉及捕获同一场景的一系列帧，每个帧具有不同的曝光设置，以拓宽光的动态范围。这可以通过连拍或使用交错的 HDR 传感器来实现，这些传感器在相机图像信号处理器 (ISP) 中同时捕获长曝光和短曝光。在相机 ISP 管道中，光源估计是关键的一步，旨在估计场景中全局光源的颜色。该估计用于相机 ISP 白平衡模块，以消除最终图像中不需要的色偏。尽管 HDR 管道中捕获了多个帧，但传统的光源估计方法通常仅依赖于场景的单个帧。在本文中，我们探索利用不同曝光时间捕获的帧中的信息。具体来说，我们引入了从双重曝光图像中提取的一个简单特征来指导光源估计器，称为双重曝光特征（DEF）。为了验证 DEF 的效率，我们使用了所提出的 DEF 的两个光源估计器：1）多层感知器网络（MLP），称为基于曝光的 MLP（EMLP），以及 2）卷积颜色恒常性的修改版本（ CCC）来集成我们的 DEF，我们称之为 ECCC。 EMLP 和 ECCC 都取得了可喜的结果，在某些情况下超越了先前需要数十万或数百万参数的方法，而 EMLP 只需要几百个参数，ECCC 只需要几千个参数。]]></description>
      <guid>https://arxiv.org/abs/2403.02449</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>用于医疗报告生成和视觉问答的视觉语言模型：综述</title>
      <link>https://arxiv.org/abs/2403.02469</link>
      <description><![CDATA[arXiv:2403.02469v1 公告类型：新
摘要：医学视觉语言模型（VLM）结合计算机视觉和自然语言处理来分析视觉和文本医学数据。我们的论文回顾了开发专门用于医疗保健的 VLM 的最新进展，重点关注为医疗报告生成和视觉问答而设计的模型。我们提供自然语言处理和计算机视觉的背景知识，解释如何将这两个领域的技术集成到 VLM 中以实现从多模式数据中学习。我们讨论的关键领域包括医学视觉语言数据集的探索，对最近值得注意的医学VLM中采用的架构和预训练策略的深入分析，以及对评估VLM在医学报告生成和视觉问题方面的性能的评估指标的全面讨论回答。我们还强调当前的挑战并提出未来的方向，包括提高临床有效性和解决患者隐私问题。总的来说，我们的综述总结了开发 VLM 以利用多模式医疗数据改进医疗保健应用的最新进展。]]></description>
      <guid>https://arxiv.org/abs/2403.02469</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>NiNformer：具有令牌混合生成门控功能的网络变压器中的网络</title>
      <link>https://arxiv.org/abs/2403.02411</link>
      <description><![CDATA[arXiv:2403.02411v1 公告类型：新
摘要：注意力机制是 Transformer 架构的主要组成部分，自推出以来，它在跨越多个领域和多个任务的深度学习领域取得了重大进展。注意力机制在计算机视觉中被用作视觉变压器ViT，其用途已扩展到视觉领域的许多任务，例如分类、分割、对象检测和图像生成。虽然这种机制非常具有表现力和能力，但它的缺点是计算量大，并且需要相当大的数据集才能有效优化。为了解决这些缺点，文献中提出了许多设计来减少计算负担并减轻数据大小要求。视觉领域中此类尝试的例子有 MLP-Mixer、Conv-Mixer、Perciver-IO 等等。本文介绍了一种新的计算块作为标准 ViT 块的替代品，通过用网络结构中的网络替换普通的注意力层来减少计算负担，该网络结构通过学习元素的动态系统增强了 MLP 混合器的静态方法。通过令牌混合过程实现明智的门控功能。大量实验表明，所提出的设计在视觉领域图像分类任务中应用的多个数据集上提供了比基线架构更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.02411</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>胎儿大脑的解剖学约束纤维束成像</title>
      <link>https://arxiv.org/abs/2403.02444</link>
      <description><![CDATA[arXiv:2403.02444v1 公告类型：新
摘要：弥散加权磁共振成像（dMRI）越来越多地用于研究子宫内胎儿的大脑。 dMRI 实现的一项重要计算是流线纤维束成像，它具有独特的应用，例如大脑白质的纤维束特异性分析和结构连接评估。然而，由于胎儿 dMRI 数据质量低以及纤维束成像的挑战性，现有方法往往会产生高度不准确的结果。它们产生许多错误的流线，同时无法重建构成主要白质束的流线。在本文中，我们主张基于直接在 dMRI 空间中准确分割胎儿脑组织的解剖学约束纤维束成像。我们开发了一种深度学习方法来自动计算分割。独立测试数据的实验表明，该方法可以准确分割胎儿脑组织并极大地改善纤维束成像结果。它能够重建高度弯曲的束，例如视辐射。重要的是，我们的方法从适合 dMRI 数据的扩散张量推断出组织分割和流线型传播方向，使其适用于常规胎儿 dMRI 扫描。所提出的方法可以显着提高 dMRI 胎儿大脑定量评估的准确性和可重复性。]]></description>
      <guid>https://arxiv.org/abs/2403.02444</guid>
      <pubDate>Wed, 06 Mar 2024 06:18:24 GMT</pubDate>
    </item>
    </channel>
</rss>