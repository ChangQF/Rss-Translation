<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Tue, 05 Dec 2023 03:15:08 GMT</lastBuildDate>
    <item>
      <title>VMC：使用时间注意力适应文本到视频扩散模型的视频运动定制。 （arXiv：2312.00845v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00845</link>
      <description><![CDATA[文本到视频的扩散模型显着提高了视频生成的速度。
但是，自定义这些模型以生成具有定制动作的视频
提出了重大挑战。具体来说，他们在 (a) 方面遇到了障碍
准确地再现目标视频中的动作，以及 (b) 创建多样化的
视觉变化。例如，静态图像的直接扩展
视频的定制方法常常会导致错综复杂的纠葛
外观和运动数据。为了解决这个问题，我们在这里展示视频运动
定制（VMC）框架，一种新颖的一次性调整方法，旨在
在视频扩散模型中调整时间注意力层。我们的方法
引入了一种新颖的运动蒸馏目标，使用之间的残差向量
连续帧作为运动参考。然后扩散过程保留
低频运动轨迹，同时减轻高频运动轨迹
图像空间中与运动无关的噪声。我们验证我们的方法
跨越各种现实世界运动的最先进的视频生成模型
上下文。我们的代码、数据和项目演示可以在以下位置找到：
https://video-motion-customization.github.io
]]></description>
      <guid>http://arxiv.org/abs/2312.00845</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>走向持续学习中的无冗余子网络。 （arXiv：2312.00840v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00840</link>
      <description><![CDATA[灾难性遗忘（CF）是持续学习中的一个突出问题。
参数隔离通过为每个参数屏蔽一个子网来解决这一挑战
任务以减轻对旧任务的干扰。然而，这些子网络
根据重量大小构建，不一定对应
权重的重要性，导致维持不重要的权重和
构建冗余子网。为了克服这个限制，受到启发
信息瓶颈，消除相邻网络之间的冗余
层，我们建议 \textbf{\underline{I}nformation \underline{B}ottleneck
\underline{M}要求子网络（IBM）}消除内部冗余
子网络。具体来说，IBM 将有价值的信息积累为重要的信息
构建无冗余子网络的权重，不仅有效
通过冻结子网络来缓解 CF，同时也促进新任务
通过传递有价值的知识进行培训。此外，IBM
分解隐藏的表示以自动化构建过程并使得
它灵活。大量实验表明 IBM 始终如一
优于最先进的方法。值得注意的是，IBM 超越了
最先进的参数隔离方法，数量减少 70%
子网络内的参数数量减少了 80%，训练时间减少了 80%。
]]></description>
      <guid>http://arxiv.org/abs/2312.00840</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>稀疏击败密集：重新思考雷达相机深度完成中的监督。 （arXiv：2312.00844v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00844</link>
      <description><![CDATA[人们普遍认为密集监督优于稀疏监督
监管深度完成领域，但深层次原因
这一点很少被讨论。在本文中，我们发现使用的挑战
用于训练雷达相机深度预测模型的稀疏监督是
投影变换崩溃（PTC）。 PTC 意味着稀疏
监督引导模型学习意外的折叠投影
图像/雷达/激光雷达空间之间的转换。基于这一见解，我们
提出一种新颖的“中断补偿”框架来处理 PTC，从而
重新审视在深度完成任务中使用稀疏监督。这
中断部分故意丢弃之间的位置对应关系
图像/雷达/LiDAR，而补偿部分利用3D空间和2D
语义信息来补偿被丢弃的有利位置
一致。大量的实验结果表明我们的框架
（稀疏监督）优于最先进的（密集监督）
平均绝对误差提高 11.6$\%$，加速提高 1.6\times$。代码
可以在...
]]></description>
      <guid>http://arxiv.org/abs/2312.00844</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:07 GMT</pubDate>
    </item>
    <item>
      <title>噪声医学图像概率无监督配准的异方差不确定性估计。 (arXiv:2312.00836v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.00836</link>
      <description><![CDATA[本文提出了一种异方差不确定性估计框架
无监督的医学图像配准。现有方法依赖于目标
（例如均方误差）假设图像上的噪声水平均匀，
忽略噪声的异方差和输入相关特征
真实世界医学图像中的分布。这进一步引入了噪声
由于对异常值的不期望的惩罚而导致的梯度，导致不自然
变形和性能下降。为了缓解这种情况，我们建议
具有相对 $\gamma$ 指数的自适应加权方案
建模后位移估计器的信噪比 (SNR)
使用单独的方差估计器来防止模型出现异方差噪声
避免被误差残差的虚假梯度驱走，导致
更准确的位移估计。为了说明多功能性和
为了验证所提出方法的有效性，我们在两个方面测试了我们的框架
三个医学图像数据集的代表性配准架构。
我们提出的框架始终优于其他基线
定量和定性，同时还提供准确和合理的
不确定性措施。配对 t 检验表明我们在注册方面的改进
准确性具有统计显着性。该代码将在以下位置公开发布：
\url{https://voldemort108x.github.io/hetero_uncertainty/}。
]]></description>
      <guid>http://arxiv.org/abs/2312.00836</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>用于医学图像无监督图像配准的自适应对应评分框架。 (arXiv:2312.00837v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.00837</link>
      <description><![CDATA[我们提出了一种无监督医学图像的自适应训练方案
登记。现有方法依赖图像重建作为主要方法
监督信号。然而，干扰变量（例如噪声和共视性）
常常会导致医学图像之间失去对应关系，违反了
物理波（例如超声波）中的朗伯假设与一致
成像采集。由于无监督学习方案依赖于强度
恒常性地建立图像之间的对应关系以进行重建，这
引入了未按典型模型建模的虚假误差残差
培训目标。为了缓解这个问题，我们提出了一个自适应框架
在期间用对应评分图重新加权误差残差
训练，防止参数位移估计器漂移
由于噪声梯度，这会导致性能下降。为了显示
我们的方法的多功能性和有效性，我们测试了我们的框架
跨三个医学图像的三个代表性配准架构
数据集以及其他基线。我们提出的自适应框架
在数量和质量上始终优于其他方法。
配对 t 检验表明我们的改进具有统计显着性。这
代码将公开于
\url{https://voldemort108x.github.io/AdaCS/}。
]]></description>
      <guid>http://arxiv.org/abs/2312.00837</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:06 GMT</pubDate>
    </item>
    <item>
      <title>烤宽面条：分层乐谱蒸馏，用于解开物体重新照明。 （arXiv：2312.00833v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00833</link>
      <description><![CDATA[专业艺术家、摄影师和其他视觉内容创作者使用
重新照明物体以达到照片所需的效果。很遗憾，
允许重新照明的手动工具具有陡峭的学习曲线，并且
很难掌握。尽管生成编辑方法现在启用了某些形式
图像编辑、重新照明仍然超出了今天的能力；现存的
方法很难保留图像的其他方面——颜色、形状和
纹理——编辑后保持一致。我们提出烤宽面条，这是一种方法
实现直观的文本引导重新照明控制。烤宽面条学习照明
先验通过使用分数蒸馏采样来蒸馏扩散的先验
模型，已根据合成重新照明数据进行了微调。为了训练烤宽面条，
我们策划了一个新的合成数据集 ReLiT，其中包含重新点亮的 3D 对象资产
来自多个光源位置。尽管进行了合成图像的训练，
定量结果表明，烤宽面条重新照亮了现实世界的图像，而
保留输入图像的其他方面，优于最先进的技术
文本引导的图像编辑方法。千层面使现实和受控
自然图像和数字艺术作品的结果，受到人类的青睐
在超过 91% 的情况下优于其他方法。最后，我们展示了
我们的学习目标的多功能性，通过扩展它以允许着色，
另一种形式的图像编辑。
]]></description>
      <guid>http://arxiv.org/abs/2312.00833</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>AV-RIR：视听室脉冲响应估计。 （arXiv：2312.00834v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2312.00834</link>
      <description><![CDATA[准确估计房间脉冲响应 (RIR)，捕获
环境的声学特性，对于语音处理和 AR/VR 很重要
应用程序。我们提出了 AV-RIR，一种新颖的多模态多任务学习
根据给定的混响语音信号准确估计 RIR 的方法
以及相应环境的视觉线索。 AV-RIR 建立在小说的基础上
基于神经编解码器的架构，可有效捕获环境几何形状
和材料特性并解决语音去混响作为辅助任务
通过使用多任务学习。我们还提出了 Geo-Mat 功能，可增强
将材料信息转化为视觉提示和 CRIP，从而改善后期混响
通过图像到 RIR 检索估计的 RIR 中的成分减少了 86%。经验
结果表明，AV-RIR 在数量上优于以前的纯音频和
仅视觉方法通过在各种方面实现 36% - 63% 的改进
RIR 估计中的声学指标。此外，它还实现了更高的
人类评价中的偏好分数。作为辅助福利，去混响
AV-RIR 的演讲展示了与最先进的技术相比具有竞争力的性能
各种口语处理任务并且优于混响时间
真实世界 AVSpeech 数据集中的错误分数。两者的定性示例
合成混响语音和增强语音可以在以下位置找到
https://www.youtube.com/watch?v=tTsKhviukAE。
]]></description>
      <guid>http://arxiv.org/abs/2312.00834</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:05 GMT</pubDate>
    </item>
    <item>
      <title>连接噪声建模以增强噪声检测的统一框架。 （arXiv：2312.00827v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00827</link>
      <description><![CDATA[嘈杂的标签会损害模型的性能，使得学习研究变得
嘈杂的标签是一个重要的话题。两种传统方法是噪声建模
和噪声检测。然而，这两种方法通常被研究
他们是独立的，而且他们的合作工作也很有限。在这个
在工作中，我们探索了这两种方法的整合，提出了一种
具有三个关键模块的互连结构：噪声建模、源
知识识别，以及利用噪声增强噪声检测
源知识整合方法。这种协作结构提供了
优点，例如区分硬底片和保持真正清洁
可能有可疑噪音的标签。我们在四个数据集上进行的实验，
具有三种类型的噪声和每个块的不同组合，
展示这些组件协作的有效性。我们的合作
结构方法将 top-1 分类准确率提高了 10%
在合成噪声数据集中为 3-5%，在现实世界噪声数据集中为 3-5%。这
结果还表明，这些成分对
各种噪声场景下的整体性能。这些发现提供了
设计定制的噪声标签学习方法的宝贵见解
未来的特定噪声场景。我们的代码可供公众访问。
]]></description>
      <guid>http://arxiv.org/abs/2312.00827</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:04 GMT</pubDate>
    </item>
    <item>
      <title>用反事实例子探索和减轻视觉语言模型中的交叉社会偏见。 （arXiv：2312.00825v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00825</link>
      <description><![CDATA[虽然视觉语言模型 (VLM) 取得了卓越的性能
最近的改进，越来越多的证据表明这些模型还具有
关于性别和种族等社会属性的有害偏见。事先的
研究主要集中于单独探讨此类偏见属性
同时忽略与社会属性之间的交叉相关的偏见。
这可能是由于很难收集详尽的数据集
用于社交属性的各种组合的图像-文本对。为了解决这个问题
挑战，我们采用文本到图像的扩散模型来产生反事实
大规模探讨跨部门社会偏见的例子。我们的方法
利用带有交叉注意力控制的稳定扩散来产生一组
反事实的图像-文本对在描述上高度相似
主题（例如，给定的职业），而仅在描述上有所不同
交叉社会属性（例如种族和性别）。通过我们的
过度生成然后过滤方法，我们产生了 SocialCounterfactuals，
包含超过 171k 个用于探测的图像文本对的高质量数据集
与性别、种族和身体特征相关的交叉偏见。我们
进行广泛的实验来证明我们生成的有用性
用于探索和减轻交叉社会偏见的数据集
最先进的 VLM。
]]></description>
      <guid>http://arxiv.org/abs/2312.00825</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>DEVIAS：学习动作和场景的解开视频表示以实现整体视频理解。 （arXiv：2312.00826v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00826</link>
      <description><![CDATA[当观看视频时，人类可以自然地从视频中提取人类动作
周围的场景环境，即使动作场景组合不常见。
然而，与人类不同的是，视频动作识别模型通常会学习
来自训练中虚假相关性的场景偏向动作表示
数据，导致在脱离上下文的情况下性能不佳。尽管
场景去偏差模型在脱离上下文的场景中提高了性能，
他们经常忽略数据中有价值的场景信息。解决这个问题
挑战，我们提出动作和场景的解开视频表示
（DEVIAS），旨在实现整体视频理解。解开
我们的方法的动作和场景表示可以提供灵活性
根据下游任务调整动作或场景信息的重点
和数据集特征。分离的动作和场景表示
可能有利于上下文内和上下文外的视频理解。
为此，我们采用槽注意力来学习解开的动作和场景
使用单个模型的表示，以及进一步的辅助任务
引导槽注意。我们在上下文中验证了所提出的方法
数据集：UCF-101 和 Kinetics-400，以及脱离上下文的数据集：SCUBA 和 HAT。
我们提出的方法在不同数据集上显示出良好的性能
与基线相比，证明其在不同视频中的有效性
了解场景。
]]></description>
      <guid>http://arxiv.org/abs/2312.00826</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>InceptionCaps：适用于数据稀缺环境的高性能青光眼分类模型。 （arXiv：2312.00803v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00803</link>
      <description><![CDATA[青光眼是一种不可逆的眼部疾病，是导致青光眼的第二大原因。
全世界的视力障碍。缓慢视力丧失和无症状性质
这种疾病使其诊断具有挑战性。早期发现至关重要
防止不可逆转的失明。眼科医生主要使用视网膜
眼底图像作为一种非侵入性筛查方法。卷积神经网络
（CNN）已经证明了医学图像分类的高精度。
然而，CNN 的平移不变性和无法处理
对象之间的部分-整体关系使其不适合直接应用
对于青光眼眼底图像分类，因为它需要大量的
用于训练的标记图像。这项工作回顾了现有的技术水平
模型并提出了 InceptionCaps，一种基于深度学习的新型胶囊网络（CapsNet）
以预训练的 InceptionV3 作为卷积基础的学习模型，
自动青光眼分类。 InceptionCaps 的准确率达到了 0.956，
特异性为 0.96，AUC 为 0.9556，超过了几个
RIM-ONE v2 数据集上最先进的深度学习模型性能。
获得的结果证明了所提出的深度学习的鲁棒性
模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.00803</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>自适应多模态即时学习。 （arXiv：2312.00823v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.00823</link>
      <description><![CDATA[尽管当前的即时学习方法已成功设计为
有效地重用大型预训练模型，而无需对其大型模型进行微调
参数数量，它们仍然有需要解决的局限性，即
不考虑每幅图像中无意义补丁的不利影响
并且没有同时考虑样本内泛化和
样本外概括。在本文中，我们提出了一种自适应
多模态提示学习解决上述问题。为此，我们
利用先前的文本提示学习并提出一种新的图像提示学习。
图像提示学习实现样本内和样本外泛化，
首先屏蔽无意义的补丁，然后用可学习的内容填充它们
参数和文本信息。此外，每个提示
互相提供辅助信息，进一步加强这两者
种概括。真实数据集上的实验结果表明
在不同的下游任务方面，我们的方法优于 SOTA 方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.00823</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 Beta 散度的变分自监督对比学习。 （arXiv：2312.00824v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00824</link>
      <description><![CDATA[使用未标记和噪声数据学习判别语义空间
在多标签设置中仍未解决。我们提出一个对比
自监督学习方法对数据噪声具有鲁棒性，基于
变分方法的领域。该方法（VCL）利用变分
具有 beta 散度的对比学习可以从未标记的数据中稳健地学习
数据集，包括未经整理的数据集和嘈杂的数据集。我们展示了
通过严格的实验验证所提出方法的有效性，包括
具有多标签数据集的线性评估和微调场景
人脸理解领域。在几乎所有测试场景中，VCL 都超越了
最先进的自我监督方法的表现，取得了值得注意的成果
提高准确性。
]]></description>
      <guid>http://arxiv.org/abs/2312.00824</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>信息先验提高了多模式临床数据分类的可靠性。 （arXiv：2312.00794v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00794</link>
      <description><![CDATA[机器学习辅助临床决策支持有潜力
显着改善患者护理。然而，该领域现有的努力
对于不确定性的原则性量化在很大程度上仅限于
临时解决方案的应用并不能持续提高可靠性。
在这项工作中，我们考虑随机神经网络并设计一个定制的
基于网络参数的多模态数据驱动（M2D2）先验分布。我们
使用简单且可扩展的高斯平均场变分推理来训练
使用 M2D2 先验的贝叶斯神经网络。我们训练并评估
使用 MIMIC-IV 和相应的临床时间序列数据提出的方法
MIMIC-CXR 中的胸部 X 射线图像用于急性护理分类
状况。我们的实证结果表明，所提出的方法产生了更多
与确定性和贝叶斯神经网络相比，可靠的预测模型
基线。
]]></description>
      <guid>http://arxiv.org/abs/2312.00794</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>人才面试：在线考试的网络客户端作弊检测。 （arXiv：2312.00795v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00795</link>
      <description><![CDATA[Covid-19 大流行后，在线考试更具吸引力。此外，
在招聘过程中，采用在线考试。但作弊的情况却更多
在线考试的可能性。每次考试分配一名监考人员的数量增加
成本。此时，自动监考系统会检测到可能的作弊状态。
本文提出了一个端到端的系统和子模块以获得更好的结果
用于在线监考。物体检测、人脸识别、人声
我们的系统中使用了检测和分割。此外，我们提出的
该模型适用于用户的 PC，即基于客户端的系统。所以，服务器成本
被淘汰。据我们所知，这是第一次基于客户端的在线
招聘采用监考制度。网上考试比较多
Covid-19 大流行后具有吸引力。此外，在招聘过程中，网上
使用考试。但网上作弊的可能性更大
考试。为每次考试分配一名监考人员会增加成本。在此刻，
自动监考系统检测可能的作弊状态。本文
提出了一个端到端系统和子模块，以获得更好的在线结果
监考。物体检测、人脸识别、人声检测等
我们的系统中使用了分段。此外，我们提出的模型适用于
用户的 PC，即基于客户端的系统。因此，消除了服务器成本。
据我们所知，这是第一次基于客户端的在线监考
系统已用于招聘。此外，这个作弊系统还有效
网址：https://www.talent-interview.com/tr/。
]]></description>
      <guid>http://arxiv.org/abs/2312.00795</guid>
      <pubDate>Tue, 05 Dec 2023 03:15:01 GMT</pubDate>
    </item>
    </channel>
</rss>