<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于无相声散射远场数据的三维形状重建深度学习框架</title>
      <link>https://arxiv.org/abs/2407.09525</link>
      <description><![CDATA[arXiv:2407.09525v1 公告类型：新
摘要：逆散射问题在许多领域都至关重要，包括医学成像、声纳、传感、无损评估等。感兴趣的问题可以从检测形状到障碍物的构成特性。两者的挑战在于，这个问题是不适当的，尤其是在信息有限的情况下。话虽如此，多年来人们已经付出了巨大的努力来开发解决这个问题的方法。在这里，我们使用一种不同的方法，一种基于数据的方法。具体来说，我们开发了一个深度学习框架，使用有限的信息，使用单个入射波、单个频率和无相位远场数据进行形状重建。这是通过 (a) 使用由 3D 变分自动编码器学习的紧凑概率形状潜在空间，以及 (b) 训练卷积神经网络将声散射信息映射到这种形状表示来实现的。所提出的框架在合成 3D 粒子数据集以及流行的 3D 形状识别数据集 ShapeNet 上进行了评估。如通过大量结果所证明的，尽管数据中存在显著差异，但所提出的方法仍能够对大量复杂的散射体形状（如飞机和汽车）进行精确的重建。]]></description>
      <guid>https://arxiv.org/abs/2407.09525</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>学徒制启发优雅：协同知识提炼赋能脉冲神经网络实现高效的单眼情绪识别</title>
      <link>https://arxiv.org/abs/2407.09521</link>
      <description><![CDATA[arXiv:2407.09521v1 公告类型：新
摘要：我们引入了一种新颖的多模态协同知识提炼方案，专门用于高效的单眼运动识别任务。该方法允许轻量级、单模态学生脉冲神经网络 (SNN) 从事件框架多模态教师网络中提取丰富的知识。这种方法的核心优势在于它能够利用传统帧中发现的大量、较粗略的时间线索进行有效的情绪识别。因此，我们的方法能够熟练地解释传统帧域中的时间和空间信息，从而无需专门的传感设备，例如基于事件的相机。使用现有和我们编译的单眼情绪识别数据集充分证明了我们方法的有效性，在准确性和效率方面实现了无与伦比的性能，超越了现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2407.09521</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>MuseCL：通过多语义对比学习预测城市社会经济指标</title>
      <link>https://arxiv.org/abs/2407.09523</link>
      <description><![CDATA[arXiv:2407.09523v1 公告类型：新
摘要：预测城市区域内的社会经济指标对于促进城市和人类住区的包容性、复原力和可持续性至关重要。虽然先驱研究试图利用多模态数据进行社会经济预测，但共同探索其潜在语义仍然是一项重大挑战。为了解决这一差距，本文介绍了一种用于细粒度城市区域分析和社会经济预测的多语义对比学习 (MuseCL) 框架。在这个框架内，我们通过构建街景和遥感图像的对比样本对来启动该过程，利用人类流动性和兴趣点 (POI) 分布的相似性从视觉模态中获取语义特征。此外，我们使用预先训练的文本编码器从嵌入这些区域的 POI 文本中提取语义见解。为了合并获得的视觉和文本特征，我们设计了一个创新的基于跨模态的注意力融合模块，该模块利用对比机制进行整合。针对多个城市和指标的实验结果一致凸显了 MuseCL 的优越性，与各种竞争基线模型相比，其 R^2 平均提高了 10%。这项工作的代码已在 https://github.com/XixianYong/MuseCL 上公开发布。]]></description>
      <guid>https://arxiv.org/abs/2407.09523</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>视觉域适应的可辨别性和可转移性的几何理解</title>
      <link>https://arxiv.org/abs/2407.09524</link>
      <description><![CDATA[arXiv:2407.09524v1 公告类型：新
摘要：为了克服相同分布假设的限制，无监督域自适应（UDA）的不变表示学习在计算机视觉和模式识别社区中取得了重大进展。在 UDA 场景中，训练和测试数据属于不同的域，而任务模型被学习为不变的。最近，可迁移性和可辨别性之间的经验联系受到越来越多的关注，这是理解不变表示的关键。然而，这些能力的理论研究和对学习到的特征结构的深入分析尚未探索。在这项工作中，我们从几何角度系统地分析了可迁移性和可辨别性的本质。我们的理论结果为理解共同正则化关系提供了见解，并证明了学习这些能力的可能性。从方法论角度看，这些能力被表述为域/聚类子空间之间的几何属性（即正交性和等价性），并被表征为多个矩阵的范数/秩之间的关系。推导出两个优化友好的学习原则，这也确保了一些直观的解释。此外，推导出了共正则化参数的可行范围以平衡几何结构的学习。基于理论结果，提出了一种面向几何的模型，通过核范数优化来增强可迁移性和可辨别性。大量实验结果验证了所提模型在实证应用中的有效性，并验证了几何能力可以在推导出的可行范围内得到充分学习。]]></description>
      <guid>https://arxiv.org/abs/2407.09524</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>拓扑数据分析与卷积神经网络融合研究</title>
      <link>https://arxiv.org/abs/2407.09518</link>
      <description><![CDATA[arXiv:2407.09518v1 Announce Type: new 
摘要：卷积神经网络（CNN）难以捕捉复杂高维数据的多维结构信息，限制了其特征学习能力。本文提出一种基于拓扑数据分析（TDA）和CNN的特征融合方法，即TDA-CNN。该方法将CNN捕获的数值分布特征与TDA捕获的拓扑结构特征相结合，提高CNN的特征学习和表示能力。TDA-CNN将特征提取分为CNN通道和TDA通道，CNN通道提取数值分布特征，TDA通道提取拓扑结构特征。将两类特征融合形成组合特征表示，并通过注意机制自适应学习各特征的重要性权重。在Intel Image、性别图像、书法家书法风格等数据集上的实验验证表明，TDA-CNN使VGG16、DenseNet121、GoogleNet网络的性能分别提升了17.5%、7.11%、4.45%，特征聚类能力和重要特征识别能力均有提升，有效提升了模型的决策能力。]]></description>
      <guid>https://arxiv.org/abs/2407.09518</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>探索手势和阴影对洗手动作识别的影响</title>
      <link>https://arxiv.org/abs/2407.09520</link>
      <description><![CDATA[arXiv:2407.09520v1 公告类型：新
摘要：在现实世界中，基于摄像头的应用系统可能面临许多挑战，包括环境因素和分布变化。在本文中，我们使用洗手动作识别的具体应用，研究姿势和阴影如何影响分类器的性能。为此，我们生成具有所需变化的合成数据以引入受控的分布偏移。使用我们的合成数据集，我们将分类器的故障点定义为系统性能开始急剧下降的地方，并且我们表明这些故障点受到姿势和阴影条件的严重影响。特别是，更重和更大的阴影会产生更早的故障点。此外，有趣的是，随着姿势的较大变化，模型准确度几乎下降到零。此外，我们提出了一种简单的缓解姿势引起的故障点的策略，即利用来自非规范姿势的额外训练数据。结果表明，额外训练姿势的最佳选择是与规范姿势有中等偏差且旋转 50-60 度的姿势。]]></description>
      <guid>https://arxiv.org/abs/2407.09520</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>3DGS.zip：3D 高斯分层压缩方法综述</title>
      <link>https://arxiv.org/abs/2407.09510</link>
      <description><![CDATA[arXiv:2407.09510v1 公告类型：新
摘要：我们介绍了一项关于 3D Gaussian Splatting 压缩方法的正在进行的调查，重点关注它们在各种基准测试中的统计性能。这项调查旨在通过以表格形式总结不同压缩方法的关键统计数据来促进可比性。评估的数据集包括 TanksAndTemples、MipNeRF360、DeepBlending 和 SyntheticNeRF。对于每种方法，我们报告峰值信噪比 (PSNR)、结构相似性指数 (SSIM)、学习感知图像补丁相似性 (LPIPS) 以及结果大小（以兆字节 (MB) 为单位），由各自的作者提供。这是一个正在进行的开放项目，我们邀请研究社区以 GitHub 问题或拉取请求的形式做出贡献。请访问 http://w-m.github.io/3dgs-compression-survey/ 了解更多信息和表格的可排序版本。]]></description>
      <guid>https://arxiv.org/abs/2407.09510</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>通过优化照明光谱来控制物体的颜色外观</title>
      <link>https://arxiv.org/abs/2407.09511</link>
      <description><![CDATA[arXiv:2407.09511v1 公告类型：新
摘要：我们开发了一种创新的照明系统，它可以改变特定的目标颜色，同时保持灯光自然呈现白色。通过精确控制照明的光谱功率分布 (SPD) 并利用独特的同色异谱现象，我们的系统以您从未见过的方式实现了独特的颜色变化。我们的系统计算给定材料的最佳照明 SPD 以密集地诱导同色异谱，然后使用各种颜色的 LED 合成照明。我们在 2024 年巴黎时装周上成功展示了该系统的实施。当模特走上舞台时，她们的礼服开始了迷人的转变。我们的系统改变了礼服的颜色，展示了从一种令人惊叹的颜色到另一种令人惊叹的颜色的令人印象深刻的过渡。]]></description>
      <guid>https://arxiv.org/abs/2407.09511</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的利用相似度和图像哈希对视频中的图像进行版权检测</title>
      <link>https://arxiv.org/abs/2407.09504</link>
      <description><![CDATA[arXiv:2407.09504v1 公告类型：新
摘要：互联网上可用的信息量巨大，很难确定特定作品是受版权保护作品的复制品还是副本，尤其是当我们谈论视觉表现时。计划制定策略来识别报告中受版权保护图像的使用情况。尽管如此，我们仍希望解决在视频中包含受版权保护图像的问题，以及可以识别视频中使用的受版权保护图像的相似程度的算法，即使对于不经常出现的视频片段，最终也可以在这些边缘上执行特征化任务。机器学习 (ML) 和人工智能 (AI) 对于解决此问题至关重要。许多协会一直在开发各种算法来监控受版权保护作品的识别。这项工作意味着专注于这些算法，识别数据中的设计，并构建更合理的受版权保护图像分类和检测模型。我们使用了不同的算法，如图像处理、卷积神经网络（CNN）、图像哈希等。关键词——版权、人工智能（AI）、版权图像、卷积神经网络（CNN）、图像处理、相似度、图像哈希。]]></description>
      <guid>https://arxiv.org/abs/2407.09504</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>1-Lipschitz 神经距离场</title>
      <link>https://arxiv.org/abs/2407.09505</link>
      <description><![CDATA[arXiv:2407.09505v1 公告类型：新
摘要：神经隐式曲面是一种很有前途的几何处理工具，它将实体对象表示为神经网络的零级集。这些方法通常被训练为近似所考虑对象的有符号距离函数，在表面附近表现出很好的视觉保真度和质量，但它们的属性往往会随着距离的增加而降低，这使得在没有复杂范围分析技术帮助的情况下很难执行几何查询。基于 Lipschitz 神经网络的最新进展，我们引入了一种用于近似给定对象的有符号距离函数的新方法。由于我们的神经函数在构造上是 1-Lipschitz，因此它不会高估距离，从而保证了即使远离表面也能保持稳健性。此外，1-Lipschitz 约束允许我们使用不同的损失函数，称为 hinge-Kantorovitch-Rubinstein 损失，它将梯度推得尽可能接近单位范数，从而降低迭代查询中的计算成本。由于此损失函数只需要对占用率进行粗略估计即可进行优化，这意味着无需知道真实距离函数。因此，我们能够计算即使是质量较差的几何图形（例如嘈杂的点云或三角形汤）的神经隐式表示。我们证明，我们的方法能够近似平面或空间中任何封闭或开放的表面或曲线的距离函数，同时仍允许稳健地执行球体追踪或最近点投影。]]></description>
      <guid>https://arxiv.org/abs/2407.09505</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>具有精选数据的自消费生成模型可证明优化人类偏好</title>
      <link>https://arxiv.org/abs/2407.09499</link>
      <description><![CDATA[arXiv:2407.09499v1 公告类型：新
摘要：生成模型的快速发展带来了生成质量的显著飞跃，模糊了合成数据和真实数据之间的界限。网络规模的数据集现在很容易受到合成数据的不可避免污染，直接影响未来生成模型的训练。目前，文献中已经出现了一些关于自耗生成模型（又称迭代再训练）的理论结果，表明模型崩溃或稳定可能是可能的，具体取决于每次再训练步骤中使用的生成数据的比例。然而，在实践中，合成数据在使用和上传到网上之前，通常会受到人工反馈并由用户策划。例如，许多流行的文本到图像生成模型的界面，如 Stable Diffusion 或 Midjourney，会针对给定的查询生成图像的几种变体，最终可以由用户策划。在本文中，我们从理论上研究了数据管理对生成模型迭代再训练的影响，并表明它可以看作是一种 \emph{隐式偏好优化机制}。然而，与标准偏好优化不同，生成模型无法访问成对比较所需的奖励函数或负样本。此外，我们的研究不需要访问密度函数，只需要访问样本。我们证明，如果根据奖励模型管理数据，则迭代再训练过程的预期奖励将最大化。我们进一步提供了在每个步骤中使用正比例真实数据时再训练循环稳定性的理论结果。最后，我们对合成数据集和 CIFAR10 进行了说明性实验，表明这种程序会放大奖励模型的偏差。]]></description>
      <guid>https://arxiv.org/abs/2407.09499</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>PARSE-Ego4D：针对自我中心视频的个人行动推荐建议</title>
      <link>https://arxiv.org/abs/2407.09503</link>
      <description><![CDATA[arXiv:2407.09503v1 公告类型：新
摘要：智能辅助不仅涉及理解，还涉及行动。现有的以自我为中心的视频数据集包含丰富的视频注释，但不包含智能助手可以立即执行的操作。为了解决这一差距，我们发布了 PARSE-Ego4D，这是一组针对 Ego4D 数据集的新个人动作推荐注释。我们采用多阶段方法来生成和评估这些注释。首先，我们使用提示设计的大型语言模型 (LLM) 来生成上下文感知动作建议，并确定了超过 18,000 条动作建议。虽然这些合成动作建议很有价值，但 LLM 的固有局限性需要人工评估。为了确保高质量和以用户为中心的建议，我们进行了一项大规模的人工注释研究，为所有 PARSE-Ego4D 提供了人类偏好的基础。我们分析评分者间的一致性并评估参与者的主观偏好。基于我们的合成数据集和完整的人工注释，我们提出了几项基于自我中心视频的行动建议新任务。我们鼓励改进延迟和能耗要求的新颖解决方案。PARSE-Ego4D 中的注释将为致力于为增强现实和虚拟现实系统构建行动推荐系统的研究人员和开发人员提供支持。]]></description>
      <guid>https://arxiv.org/abs/2407.09503</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>Simplicits：无网格、几何无关、弹性模拟</title>
      <link>https://arxiv.org/abs/2407.09497</link>
      <description><![CDATA[arXiv:2407.09497v1 公告类型：新
摘要：从显式网格到隐式神经场等，3D 表示的激增推动了对表示无关的模拟器的需求。我们提出了一种无数据、无网格和无网格的解决方案，用于对任何几何表示中经历较大非线性变形的任何对象进行弹性模拟。我们注意到，每个标准几何表示都可以简化为在空间中任何一点查询的占用函数，并且我们在这个通用接口之上定义了一个模拟器。对于每个对象，我们拟合一个小型隐式神经网络，该网络对空间变化的权重进行编码，作为简化的变形基础。这些权重经过训练，可以通过随机扰动来学习物体中物理上显著的运动。我们的损失确保我们通过对变形体积进行蒙特卡罗采样随机评估弹性能量，从而找到最能最小化变形能量的权重空间基础。在运行时，我们在简化的基础上进行模拟，并将变形采样回原始域。我们的实验证明了该方法在数据上的多功能性、准确性和速度，包括有符号距离函数、点云、神经基元、断层扫描、辐射场、高斯片、表面网格和体积网格，以及展示各种材料能量、接触模型和时间积分方案。]]></description>
      <guid>https://arxiv.org/abs/2407.09497</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:13 GMT</pubDate>
    </item>
    <item>
      <title>OT-VP：针对测试时间适应的最佳传输引导视觉提示</title>
      <link>https://arxiv.org/abs/2407.09498</link>
      <description><![CDATA[arXiv:2407.09498v1 公告类型：新
摘要：虽然视觉变换器 (ViT) 在学习表示方面表现出了非凡的能力，但当应用于看不见的领域时，它们的性能就会受到影响。以前的方法要么在训练阶段进行提示学习，要么在测试时通过熵最小化修改模型参数。前者经常忽略未标记的目标数据，而后者不能完全解决域转移问题。在这项工作中，我们的方法，即最佳传输引导的测试时间视觉提示 (OT-VP)，通过利用测试时的提示学习来对齐目标和源域，而无需访问训练过程或更改预训练的模型参数来处理这些问题。该方法涉及通过优化最佳传输距离来学习目标域的通用视觉提示。仅通过学习四个提示标记，OT-VP 在三个基准数据集上的单源和多源设置中实现了平均准确率 $5.0\%$ 和 $1.5\%$ 的提高，分别是最先进方法的 $1.2\times$ 和 $1.5\times$ 的改进。]]></description>
      <guid>https://arxiv.org/abs/2407.09498</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:13 GMT</pubDate>
    </item>
    <item>
      <title>探索热成像技术：用于面部检测、识别和情感的综合面部数据集</title>
      <link>https://arxiv.org/abs/2407.09494</link>
      <description><![CDATA[arXiv:2407.09494v1 公告类型：新
摘要：该数据集包括使用 UNI-T UTi165A 相机拍摄的 6823 张热图像，用于人脸检测、识别和情绪分析。它包括 2485 张描绘情绪（快乐、悲伤、愤怒、自然、惊讶）的人脸识别图像、2054 张用于人脸识别的图像和 2284 张用于人脸检测的图像。该数据集涵盖各种条件、调色板、拍摄角度和缩放级别，温度范围为 -10°C 至 400°C，分辨率为 19,200 像素。它是推进热成像技术、辅助算法开发和跨不同调色板进行人脸识别基准测试的宝贵资源。此外，它还有助于面部运动识别，促进计算机视觉、心理学和神经科学的跨学科合作。该数据集提高了热人脸检测和识别研究的透明度，可应用于安全、医疗保健和人机交互。]]></description>
      <guid>https://arxiv.org/abs/2407.09494</guid>
      <pubDate>Tue, 16 Jul 2024 06:21:12 GMT</pubDate>
    </item>
    </channel>
</rss>