<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>无需重新训练即可使 CNN 适应鱼眼相机</title>
      <link>https://arxiv.org/abs/2404.08187</link>
      <description><![CDATA[arXiv:2404.08187v1 公告类型：新
摘要：大多数图像处理方法都假设图像处于透视投影中或可以校正为透视投影。然而，在许多应用中，使用具有较大视场 (FOV) 的非常规相机（例如鱼眼相机）是有益的。出现的问题是，如果不对原始图像进行大量裁剪，则无法将这些大视场图像校正为透视投影。为了解决这个问题，我们提出了整流卷积（RectConv）；一种新方法，用于调整预先训练的卷积网络以处理新的非透视图像，而无需任何重新训练。用 RectConv 层替换网络的卷积层使网络能够看到校正后的补丁和整个 FOV。我们演示了 RectConv 采用多个预训练网络对两个公开数据集的鱼眼图像进行分割和检测。我们的方法不需要额外的数据或培训，并且直接对从相机捕获的本机图像进行操作。我们相信这项工作是朝着适应可用于透视图像的大量资源以在广泛的相机几何形状上运行而迈出的一步。]]></description>
      <guid>https://arxiv.org/abs/2404.08187</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>从弱监督语义分割的不确定性推理和亲和力多样化的角度解决歧义问题</title>
      <link>https://arxiv.org/abs/2404.08195</link>
      <description><![CDATA[arXiv:2404.08195v1 公告类型：新
摘要：具有图像级标签的弱监督语义分割（WSSS）旨在实现密集的任务，而无需费力的注释。然而，由于上下文和模糊区域的模糊性，WSSS 的性能，特别是生成类激活图（CAM）和细化伪掩模的阶段，广泛受到模糊性的影响，而之前的文献几乎没有注意到。在这项工作中，我们提出了UniA，一个统一的单阶段WSSS框架，分别从不确定性推断和亲和力多样化的角度有效地解决这个问题。当激活类对象时，我们认为错误激活源于特征提取过程中对模糊区域的偏差。因此，我们设计了一种具有概率高斯分布的更鲁棒的特征表示，并引入不确定性估计来避免偏差。特别提出了分布损失来监督该过程，它有效地捕获歧义并对特征之间的复杂依赖关系进行建模。在精炼伪标签时，我们观察到流行的精炼方法的亲和力在歧义之间是相似的。为此，提出了亲和力多样化模块来促进语义之间的多样性。提出了一种相互补充的改进，以最初纠正多个推断的伪标签的模糊亲和力。更重要的是，进一步设计了对比亲和力损失来使不相关语义之间的关系多样化，从而可靠地将多样性传播到整个特征表示中，并有助于生成更好的伪掩模。在 PASCAL VOC、MS COCO 和医学 ACDC 数据集上进行了大量实验，验证了 UniA 处理歧义的效率以及相对于最近的单阶段甚至大多数多阶段竞争对手的优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.08195</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>注意你的邻居：免训练开放词汇语义分割</title>
      <link>https://arxiv.org/abs/2404.08181</link>
      <description><![CDATA[arXiv:2404.08181v1 公告类型：新
摘要：尽管深度学习在语义分割等密集视觉识别问题上取得了重大进展，但传统方法仍受到固定类集的限制。与此同时，视觉语言基础模型（例如 CLIP）由于其强大的泛化性，在许多零样本图像级任务中表现出了显着的有效性。最近，一系列工作研究了在开放词汇语义分割（OVSS）中利用这些模型。然而，现有的方法通常依赖于不切实际的监督预训练或访问额外的预训练网络。在这项工作中，我们为免训练 OVSS 提出了一个强大的基线，称为邻居感知 CLIP (NACLIP)，代表了针对此场景量身定制的 CLIP 的直接改编。我们的方法在 CLIP 视觉变换器的自注意力中强制定位补丁，尽管这对于密集的预测任务至关重要，但在 OVSS 文献中却被忽视了。通过结合有利于分割的设计选择，我们的方法显着提高了性能，而不需要额外的数据、辅助预训练网络或广泛的超参数调整，使其对于现实应用程序非常实用。在 8 个流行的语义分割基准上进行了实验，在大多数场景下都获得了最先进的性能。我们的代码可在 https://github.com/sinahmr/NACLIP 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.08181</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习远程光电容积描记法模型相似性测量域变化</title>
      <link>https://arxiv.org/abs/2404.08184</link>
      <description><![CDATA[arXiv:2404.08184v1 公告类型：新
摘要：深度学习模型的训练数据和部署环境之间的域转移差异可能会导致模型无法泛化的严重性能问题。我们研究了远程光电体积描记法（rPPG）背景下的域转移问题，这是一种基于视频的心率推断技术。我们提出了基于模型相似性的指标，该指标可用作域转移的衡量标准，并且我们证明了这些指标与经验绩效之间的高度相关性。所提出的具有可行相关性的指标之一 DS-diff 并不假设可以访问目标域的真实情况，即它可以应用于野外数据。为此，我们研究了一个模型选择问题，其中评估域的真实结果未知，结果表明，与平均案例基线相比，性能提高了 13.9%。]]></description>
      <guid>https://arxiv.org/abs/2404.08184</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>颜色恒常性的自监督学习</title>
      <link>https://arxiv.org/abs/2404.08127</link>
      <description><![CDATA[arXiv:2404.08127v1 公告类型：新
摘要：颜色恒定性（CC）描述了视觉系统感知物体的能力，尽管光照条件发生变化，但该物体具有相对恒定的颜色。虽然人类的 CC 及其局限性已被仔细表征，但仍不清楚视觉系统在发育过程中如何获得这种能力。在这里，我们提出的第一项研究表明，CC 在通过不变性学习目标以自我监督方式训练的神经网络中发展。在学习过程中，对象在不断变化的照明下呈现，而网络的目标是将同一对象的后续视图映射到附近的潜在表示上。这产生了在很大程度上不受光照条件影响的表征，为 CC 如何通过自我监督学习的形式在人类认知发展过程中出现提供了一个合理的例子。]]></description>
      <guid>https://arxiv.org/abs/2404.08127</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>SciFlow：通过自清洁迭代增强轻量级光流模型</title>
      <link>https://arxiv.org/abs/2404.08135</link>
      <description><![CDATA[arXiv:2404.08135v1 公告类型：新
摘要：光流估计对于各种视觉任务至关重要。尽管最近取得了巨大的进步，但实现设备上的实时光流估计仍然是一个复杂的挑战。首先，光流模型必须足够轻量级，以满足计算和内存限制，以确保设备上的实时性能。其次，实时设备上操作的必要性施加了限制，削弱了模型充分处理流量估计中的模糊性的能力，从而加剧了保持流量准确性的难度。本文介绍了两种协同技术，自清洁迭代（SCI）和回归焦点损失（RFL），旨在增强光流模型的能力，重点是解决光流回归模糊性。事实证明，这些技术在减轻误差传播方面特别有效，误差传播是采用迭代细化的光流模型中的一个普遍问题。值得注意的是，这些技术在模型参数和推理延迟方面增加的开销可以忽略不计甚至为零，从而保持了实时设备上的效率。我们提出的 SCI 和 RFL 技术（为简洁起见，统称为 SciFlow）的有效性在我们的实验中通过两种不同的轻量级光流模型架构得到了证明。值得注意的是，与基准模型相比，SciFlow 在域内场景中使错误指标（EPE 和 Fl-all）大幅减少高达 6.3% 和 10.5%，在 Sintel 上的跨域场景中分别减少高达 6.2% 和 13.5%和 KITTI 2015 数据集。]]></description>
      <guid>https://arxiv.org/abs/2404.08135</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>视觉情境感知人员跌倒检测</title>
      <link>https://arxiv.org/abs/2404.08088</link>
      <description><![CDATA[arXiv:2404.08088v1 公告类型：新
摘要：随着全球人口老龄化，跌倒相关事件的数量不断增加。有效的跌倒检测系统，特别是在医疗保健领域，对于减轻与此类事件相关的风险至关重要。本研究评估了视觉环境（包括背景物体）对跌倒检测分类器准确性的作用。我们提出了一个分割管道来半自动分离图像中的个体和对象。 ResNet-18、EfficientNetV2-S 和 Swin-Small 等成熟模型均经过训练和评估。在训练期间，基于像素的变换应用于分割的对象，然后在不分割的原始图像上评估模型。我们的研究结果强调了视觉环境对跌倒检测的显着影响。将高斯模糊应用于图像背景显着提高了所有模型的性能和泛化能力。床、椅子或轮椅等背景物体可能会对跌倒检测系统造成挑战，导致误报。然而，我们证明了训练期间特定于对象的上下文转换可以有效缓解这一挑战。使用显着图的进一步分析支持了我们的观察，即视觉上下文在分类任务中至关重要。我们创建了数据集处理 API 和分割管道，可在 https://github.com/A-NGJ/image-segmentation-cli 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.08088</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>S3Editor：用于人脸视频编辑的稀疏语义解缠自训练框架</title>
      <link>https://arxiv.org/abs/2404.08111</link>
      <description><![CDATA[arXiv:2404.08111v1 公告类型：新
摘要：人脸属性编辑在各种应用中起着至关重要的作用。然而，现有方法在实现高质量结果同时保持身份、编辑忠实度和时间一致性方面遇到了挑战。这些挑战根源于与训练管道相关的问题，包括有限的监督、架构设计和优化策略。在这项工作中，我们介绍了 S3Editor，一种用于面部视频编辑的稀疏语义解缠自训练框架。 S3Editor 是一个通用解决方案，通过三个关键贡献全面解决这些挑战。首先，S3Editor采用自我训练范式，通过半监督来增强训练过程。其次，我们提出了一种具有动态路由机制的语义分离架构，可以满足不同的编辑需求。第三，我们提出了一种结构化稀疏优化方案，可以识别并停用恶意神经元，以进一步消除非目标属性的影响。 S3Editor 与模型无关，并且与各种编辑方法兼容。我们广泛的定性和定量结果证实，我们的方法显着增强了身份保存、编辑保真度以及时间一致性。]]></description>
      <guid>https://arxiv.org/abs/2404.08111</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>重新思考文本到图像生成模型时代的艺术版权侵权</title>
      <link>https://arxiv.org/abs/2404.08030</link>
      <description><![CDATA[arXiv:2404.08030v1 公告类型：新
摘要：最近的文本到图像生成模型（例如稳定扩散）非常擅长模仿和生成受版权保护的内容，引起了艺术家对其独特风格可能被不当复制的担忧。理解生成模型如何复制“艺术风格”比复制单个图像更复杂，因为风格由一组元素（或签名）组成，这些元素经常在整个作品中共同出现，其中每件作品可能会有很大差异。在我们的论文中，我们首先将“艺术版权侵权”问题重新表述为图像集的分类问题，而不是探究图像方面的相似性。然后，我们介绍 ArtSavant，这是一种实用（即高效且易于理解）的工具，用于 (i) 通过将艺术家的独特风格与 WikiArt 策划的 372 名艺术家作品的参考数据集进行比较来确定艺术家的独特风格，以及 (ii) 识别是否识别出的风格会重新出现在生成的图像中。我们利用两种互补的方法对图像集进行艺术风格分类，包括 TagMatch，这是一种新颖的本质上可解释和可归因的方法，使其更适合非技术利益相关者（艺术家、律师、法官等）更广泛的使用。然后，我们利用 ArtSavant 进行了一项大规模的实证研究，以定量了解 3 种流行的文本到图像生成模型中艺术风格复制的流行情况。也就是说，在多产艺术家（包括许多著名艺术家）的数据集中，只有 20% 的艺术家的风格似乎存在通过当今流行的文本到图像生成模型的简单提示而被复制的风险。]]></description>
      <guid>https://arxiv.org/abs/2404.08030</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>Latent Guard：文本到图像生成的安全框架</title>
      <link>https://arxiv.org/abs/2404.08031</link>
      <description><![CDATA[arXiv:2404.08031v1 公告类型：新
摘要：由于能够生成高质量图像，文本到图像（T2I）模型可以被用来创建不适当的内容。为了防止滥用，现有的安全措施要么基于易于规避的文本黑名单，要么基于有害内容分类，需要大量数据集进行训练且灵活性较低。因此，我们提出了 Latent Guard，这是一个旨在改进文本到图像生成过程中的安全措施的框架。受基于黑名单的方法的启发，Latent Guard 在 T2I 模型的文本编码器之上学习一个潜在空间，可以在其中检查输入文本嵌入中是否存在有害概念。我们提出的框架由特定于使用大型语言模型的任务的数据生成管道、临时架构组件以及从生成的数据中受益的对比学习策略组成。我们的方法的有效性在三个数据集和四个基线上得到了验证。代码和数据将在 https://github.com/rt219/LatentGuard 共享。]]></description>
      <guid>https://arxiv.org/abs/2404.08031</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>利用深度学习实时检测和分析车辆和行人</title>
      <link>https://arxiv.org/abs/2404.08081</link>
      <description><![CDATA[arXiv:2404.08081v1 公告类型：新
摘要：计算机视觉，特别是车辆和行人识别对于自动驾驶、人工智能和视频监控的发展至关重要。当前的交通监控系统在实时有效识别小物体和行人方面面临很大困难，对公共安全构成严重风险并导致交通效率低下。认识到这些困难，我们的项目专注于创建和验证先进的深度学习框架，该框架能够处理复杂的视觉输入，以便在各种环境情况下精确、实时地识别汽车和人。在代表复杂城市环境的数据集上，我们训练和评估了不同版本的 YOLOv8 和 RT-DETR 模型。 YOLOv8 Large 版本被证明是最有效的，特别是在行人识别方面，具有很高的精度和鲁棒性。结果（包括平均精度和召回率）证明了该模型能够显着改善交通监控和安全性。这项研究对计算机视觉中的实时、可靠检测做出了重要补充，为交通管理系统建立了新的基准。]]></description>
      <guid>https://arxiv.org/abs/2404.08081</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>人工智能引导的特征分割技术对单晶金刚石生长特征进行建模</title>
      <link>https://arxiv.org/abs/2404.08017</link>
      <description><![CDATA[arXiv:2404.08017v1 公告类型：新
摘要：长期以来，金刚石生长的目标一直是通过工艺改进，在大面积的生长晶体上持续生产高质量材料，从而实现从光学晶体到量子探测器的各种应用。机器学习为实现这一目标提供了一条充满希望的道路，但也面临着挑战，例如数据集中特征的复杂性、它们的时间依赖性以及每次增长运行产生的数据量。由于数据集的低容量和高特征复杂性，从图像到图像的准确空间特征提取对于实时监测钻石生长至关重要但也很复杂。本文比较了钻石生长领域中各种传统的和机器学习驱动的特征提取方法，提出了一种新颖的深度学习驱动的语义分割方法，用于隔离和分类钻石、口袋持有人和背景等几何特征的精确像素掩模，以及及其基于形状和尺寸的衍生特征。使用以注释为中心的人机交互软件架构来训练数据集，并使用主动学习、数据增强和模型辅助标记进行选择性数据标记的模块，我们的方法实现了有效的注释准确性，并大大减少了标记时间和成本。事实证明，深度学习算法在从具有许多特征的数据集中准确学习复杂表示方面非常高效。我们基于 DeeplabV3plus 架构的顶级模型在感兴趣特征分类方面实现了出色的准确度，口袋支架的准确度为 96.31%，钻石顶部的准确度为 98.60%，钻石侧面特征的准确度为 91.64%。]]></description>
      <guid>https://arxiv.org/abs/2404.08017</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>SurvMamba：用于生存预测的多粒度多模态交互的状态空间模型</title>
      <link>https://arxiv.org/abs/2404.08027</link>
      <description><![CDATA[arXiv:2404.08027v1 公告类型：新
摘要：将病理图像与基因组数据相结合的多模态学习显着提高了生存预测的准确性。然而，现有方法尚未充分利用整个幻灯片图像（WSI）和转录组数据中固有的层次结构，从中可以得出更好的模内表示和模间集成。此外，许多现有研究试图通过注意力机制来改进多模态表示，这不可避免地导致处理高维 WSI 和转录组数据时的高度复杂性。最近，一种名为 Mamba 的结构化状态空间模型因其在低复杂度长序列建模方面的卓越性能而成为一种有前景的方法。在本研究中，我们提出了具有多粒度多模式交互的 Mamba（SurvMamba）用于生存预测。 SurvMamba 采用分层交互 Mamba (HIM) 模块实现，该模块促进不同粒度的高效模内交互，​​从而捕获更详细的局部特征以及丰富的全局表示。此外，Interaction Fusion Mamba (IFM) 模块用于级联模间交互融合，为生存预测提供更全面的特征。对五个 TCGA 数据集的综合评估表明 SurvMamba 在性能和计算成本方面优于其他现有方法。]]></description>
      <guid>https://arxiv.org/abs/2404.08027</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>对深度学习技术及其在手写识别中的范围的包容性回顾</title>
      <link>https://arxiv.org/abs/2404.08011</link>
      <description><![CDATA[arXiv:2404.08011v1 公告类型：新
摘要：深度学习表达了一类机器学习算法，能够将原始输入组合到中间特征层中。这些深度学习算法在不同领域都展现了出色的成果。深度学习尤其见证了计算机视觉和模式识别领域中人类水平表现的巨大成就。为了在不同领域实现最先进的性能，深度学习使用了不同的架构，并且这些架构使用激活函数在任何架构的隐藏层和输出层之间执行各种计算。本文对深度学习在手写识别领域的现有研究进行了综述。尽管最近的进展表明深度学习方法为加速或证明手写识别的准确结果提供了有价值的手段，但根据广泛的文献调查，本研究发现深度学习尚未发生更多革命性变化，并且还需要进一步改进。解决了该领域许多最紧迫的挑战，但在现有技术的基础上已经取得了有希望的进展。此外，用于训练的标记数据的可用性不足也带来了该领域的问题。尽管如此，目前的手写识别调查预计深度学习将在实验室和临床上带来变革，并有可能改变图像处理、语音识别、计算机视觉、机器翻译、机器人和控制、医学成像、医学信息处理、生物识别等多个领域。信息学、自然语言处理、网络安全等等。]]></description>
      <guid>https://arxiv.org/abs/2404.08011</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>利用不完善的通信增强自动驾驶车辆的协作感知</title>
      <link>https://arxiv.org/abs/2404.08013</link>
      <description><![CDATA[arXiv:2404.08013v1 公告类型：新
摘要：相机馈送和传感器测量的共享和联合处理，称为协作感知（CP），已成为一种实现更高感知质量的新技术。 CP 可以提高自动驾驶车辆 (AV) 的安全性，因为其个人视觉感知质量会受到恶劣天气条件（雾霾天气）、低照度、蜿蜒道路和拥挤交通的影响。为了弥补以前方法的局限性，在本文中，我们提出了一种在受限通信下实现优化 CP 的新方法。我们方法的核心是从可用的前方车辆列表中招募最佳助手，以扩大视觉范围并提高自我车辆的物体检测（OD）准确性。在这个两步过程中，我们首先根据视觉范围和最低运动模糊来选择对 CP 贡献最大的辅助车辆。接下来，我们在候选车辆之间实施无线电块优化，以进一步提高通信效率。我们特别关注行人检测作为示例场景。为了验证我们的方法，我们使用 CARLA 模拟器为不同的驾驶场景创建带注释的视频数据集，在这些场景中，行人检测对于视力受损的自动驾驶汽车来说是一项挑战。我们的结果证明了我们的两步优化过程在提高具有挑战性的场景中协作感知的整体性能方面的有效性，从而显着提高了不利条件下的驾驶安全性。最后，我们注意到网络假设采用了 LTE Release 14 模式 4 侧链路通信，通常用于车对车 (V2V) 通信。尽管如此，我们的方法很灵活，适用于任意 V2V 通信。]]></description>
      <guid>https://arxiv.org/abs/2404.08013</guid>
      <pubDate>Mon, 15 Apr 2024 06:18:09 GMT</pubDate>
    </item>
    </channel>
</rss>