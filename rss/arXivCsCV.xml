<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 24 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过对比学习和不确定性估计增强 Sentinel 2 图像的主动学习</title>
      <link>https://arxiv.org/abs/2405.13285</link>
      <description><![CDATA[arXiv:2405.13285v1 公告类型：新 
摘要：在本文中，我们介绍了一种新方法，旨在通过将半监督学习（SSL）与主动学习策略相结合来提高卫星图像分析中的标签效率。我们的方法利用对比学习以及通过蒙特卡罗 Dropout (MC Dropout) 进行的不确定性估计，特别关注使用 Eurosat 数据集分析的 Sentinel-2 图像。我们探索了我们的方法在具有平衡和不平衡类别分布的场景中的有效性。我们的结果表明，对于不平衡的类别，我们的方法优于随机方法，可以显着节省标记工作量，同时保持较高的分类准确性。这些发现凸显了我们的方法在促进可扩展且具有成本效益的卫星图像分析方面的潜力，特别有利于广泛的环境监测和土地利用分类任务。关于初步结果的说明：本文提出了一种主动学习的新方法，并包括将随机选择与我们提出的方法进行比较的初始实验的结果。我们承认这些结果是初步的。我们目前正在进行进一步的实验，并将在未来几周内用更多发现更新本文，包括与其他方法的比较。]]></description>
      <guid>https://arxiv.org/abs/2405.13285</guid>
      <pubDate>Fri, 24 May 2024 06:20:07 GMT</pubDate>
    </item>
    <item>
      <title>具有稀疏扫描先验的视觉变换器</title>
      <link>https://arxiv.org/abs/2405.13335</link>
      <description><![CDATA[arXiv:2405.13335v1 Announce Type: new 
摘要：近年来，Transformers在计算机视觉任务中取得了令人瞩目的进展。然而，它们的全局建模往往伴随着巨大的计算开销，与人眼高效的信息处理形成鲜明对比。受人眼稀疏扫描机制的启发，我们提出了一种 \textbf{S}parse \textbf{S}can \textbf{S}elf-\textbf{A}ttention 机制（$\rm{S}^3\rm{A}$）。该机制为每个 token 预定义一系列感兴趣的锚点，并利用局部注意力机制对这些锚点周围的空间信息进行高效建模，避免了冗余的全局建模和对局部信息的过度关注。这种方法既能反映人眼的功能，又能显著降低视觉模型的计算负荷。在 $\rm{S}^3\rm{A}$ 的基础上，我们引入了 \textbf{S}parse \textbf{S}can \textbf{Vi}sion \textbf{T}transformer (SSViT)。大量实验表明 SSViT 在各种任务中均表现出色。具体而言，在 ImageNet 分类中，无需额外监督或训练数据，SSViT 便可实现 \textbf{84.4\%/85.7\%} 的 top-1 准确率，且 \textbf{4.4G/18.2G} FLOP。SSViT 在对象检测、实例分割和语义分割等下游任务中也表现出色。其稳健性在各种数据集中得到进一步验证。代码将在 \url{https://github.com/qhfan/SSViT} 上提供。]]></description>
      <guid>https://arxiv.org/abs/2405.13335</guid>
      <pubDate>Fri, 24 May 2024 06:20:07 GMT</pubDate>
    </item>
    <item>
      <title>闪耀您的数据：天文成像中基于扩散的增强方法</title>
      <link>https://arxiv.org/abs/2405.13267</link>
      <description><![CDATA[arXiv:2405.13267v1 公告类型：新 
摘要：天文学和人工智能的交叉领域遇到了重大挑战，这些挑战涉及噪声背景、较低分辨率 (LR) 以及来自詹姆斯·韦伯等先进望远镜的图像过滤和存档的复杂过程等问题。考虑到原始图像在特征空间中的分散性，我们提出了一个基于 \underline{f}eature \underline{l}earning 和 \underline{a} 的 \textit{两阶段增强框架}，名为 \textbf{FLARE}增强\underline{r}解决方案\underline{e}nhancement。我们首先应用较低分辨率 (LR) 到较高分辨率 (HR) 的转换，然后进行标准增强。其次，我们集成了扩散方法，使用类串联提示综合生成样本。通过使用加权百分位数合并这两个阶段，我们重新调整特征空间分布，使分类模型能够建立独特的决策边界，并在各种域内和域外任务上实现卓越的泛化。我们对几个下游 cosmos 数据集以及跨 8 类细粒度和 4 类宏观分类任务的最优分布 \textbf{SpaceNet} 数据集进行了实验。与相似的基线相比，FLARE 在细粒度任务中获得了最高的性能增益 20.78%，而在不同的分类模型中，FLARE 表现出平均 +15% 的一致增量。这一结果强调了 FLARE 方法在提高图像分类精度方面的有效性，最终增强了天文学研究成果的可靠性。 % 我们的代码和 SpaceNet 数据集将很快向公众发布。我们的代码和 SpaceNet 数据集可在 \href{https://github.com/Razaimam45/PlanetX_Dxb}{\textit{https://github.com/Razaimam45/PlanetX\_Dxb}} 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.13267</guid>
      <pubDate>Fri, 24 May 2024 06:20:06 GMT</pubDate>
    </item>
    <item>
      <title>使用进出网进行单色虚拟 H&E 染色</title>
      <link>https://arxiv.org/abs/2405.13278</link>
      <description><![CDATA[arXiv:2405.13278v1 公告类型：新 
摘要：虚拟染色通过从未染色或不同染色图像数字化生成染色图像来简化传统染色程序。虽然传统染色方法涉及耗时的化学过程，但虚拟染色提供了一种高效且基础设施成本低的替代方案。利用基于显微镜的技术，例如共焦显微镜，研究人员可以加快组织分析，而无需进行物理切片。然而，对于习惯于传统组织学染色图像的病理学家和外科医生来说，解释灰度或伪彩色显微图像仍然是一个挑战。为了填补这一空白，各种研究探索了数字模拟染色来模拟目标组织学染色。本文介绍了一种新颖的网络——In-and-Out Net，专为虚拟染色任务而设计。基于生成对抗网络（GAN），我们的模型有效地将反射共焦显微镜（RCM）图像转换为苏木精和伊红（H＆E）染色图像。我们使用皮肤组织的氯化铝预处理来增强 RCM 图像中的细胞核对比度。使用具有两个荧光通道的虚拟 H\&amp;E 标签训练模型，无需图像配准并提供像素级地面实况。我们的贡献包括提出最佳训练策略、进行比较分析来展示最先进的性能、通过消融研究验证模型以及收集完美匹配的输入和地面实况图像而无需配准。 In-and Out Net 展示了有希望的结果，为虚拟染色任务提供了有价值的工具，并推进了组织学图像分析领域。]]></description>
      <guid>https://arxiv.org/abs/2405.13278</guid>
      <pubDate>Fri, 24 May 2024 06:20:06 GMT</pubDate>
    </item>
    <item>
      <title>利用强化学习技术和实时处理监控摄像头图像的交通信号灯智能定时进行交通控制</title>
      <link>https://arxiv.org/abs/2405.13256</link>
      <description><![CDATA[arXiv:2405.13256v1 公告类型：新 
摘要：交通灯配时的优化管理是减少城市交通的最有效因素之一。在大多数旧系统中，采用固定定时和人为因素来控制流量，这在时间和成本方面都不是很有效。如今，交通管理领域的方法基于人工智能的使用。在该方法中，通过使用视频监控摄像机图像的实时处理和强化学习，根据多个参数确定并应用交通灯的最佳定时。在研究中，深度学习方法被用于车辆检测，使用YOLOv9-C模型来估计车辆的数量和速度等其他特征。最后，通过使用多因素强化学习和 DQN Rainbow 算法在 OpenAI Gym 的城市环境模拟器中对车辆进行建模，将计时应用于十字路口的交通灯。此外，使用迁移学习以及在伊朗汽车图像上重新训练模型提高了模型的准确性。该方法的结果表明，该模型在分析监控摄像机和寻找最佳时机方面都相当准确，并且据观察，它比以前的研究具有更好的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.13256</guid>
      <pubDate>Fri, 24 May 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>图像合成中的计算权衡：扩散、屏蔽令牌和下一个令牌预测</title>
      <link>https://arxiv.org/abs/2405.13218</link>
      <description><![CDATA[arXiv:2405.13218v1 公告类型：新 
摘要：几乎所有最近的图像合成方法，包括扩散、掩码令牌预测和下一个令牌预测，都使用 Transformer 网络架构。尽管有这个共同的主干，但还没有对这些方法如何影响性能和效率进行直接的、计算控制的比较。我们通过以 FLOP 为单位衡量的计算预算来分析每种方法的可扩展性。我们发现，以下一个令牌预测为主导的令牌预测方法在提示跟随方面显着优于扩散。在图像质量方面，虽然下一个标记预测最初表现更好，但缩放趋势表明它最终会通过扩散来匹配。我们比较了每种方法的推理计算效率，发现下一个令牌预测是迄今为止最有效的。根据我们的发现，我们建议针对图像质量和低延迟的应用程序进行扩散；当提示跟随或吞吐量更重要时，以及下一个令牌预测。]]></description>
      <guid>https://arxiv.org/abs/2405.13218</guid>
      <pubDate>Fri, 24 May 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>铁路技术地图 (RTM) 组件识别的迁移学习方法</title>
      <link>https://arxiv.org/abs/2405.13229</link>
      <description><![CDATA[arXiv:2405.13229v1 公告类型：新 
摘要：多年来铁路运输的极度普及迫切需要在全球范围内维持高效的铁路管理系统。尽管如此，目前存在大量计算机辅助设计铁路技术地图 (RTM)，但仅以便携式文档格式 (PDF) 提供。这项研究工作使用深度学习和光学字符识别技术，提出了一种通用系统，可将给定输入图像中的相关地图组件数据数字化，并为每个图像创建一个格式化文本文件。在使用的 YOLOv3、SSD 和 Faster-RCNN 目标检测模型中，Faster-RCNN 产生最高的平均精度 (mAP) 和最高的 F1 得分值，分别为 0.68 和 0.76。此外，获得的结果证明，当包含图像的文本通过复杂的预处理管道发送以消除失真时，可以改善 OCR 的结果。]]></description>
      <guid>https://arxiv.org/abs/2405.13229</guid>
      <pubDate>Fri, 24 May 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>助力城市交通管理：高架 3D LiDAR 用于数据收集和高级物体检测分析</title>
      <link>https://arxiv.org/abs/2405.13202</link>
      <description><![CDATA[arXiv:2405.13202v1 公告类型：新 
摘要：光探测和测距（LiDAR）技术的最新发展极大地提高了城市环境中的 3D 物体检测能力。本文提出了一种新颖的框架，利用高架 LiDAR 传感器的强大功能，改变交通场景中 3D 物体的检测和分析。我们展示了我们的方法论收集复杂 3D 点云数据的卓越能力，这使我们能够准确、详细地捕捉城市交通的动态。由于获取真实交通数据集的限制，我们利用模拟器生成特定场景的3D点云。为了支持我们的实验分析，我们首先模拟各种 3D 点云交通相关对象。然后，我们使用该数据集作为训练和评估 3D 对象检测模型的基础，以识别和监控模拟城市交通环境中的车辆和行人。接下来，我们对基于点体素区域的卷积神经网络（PV-RCNN）架构进行微调，使其更适合处理和理解城市交通模拟生成的大量点云数据。我们的结果表明了所提出的解决方案在准确检测交通场景中的物体方面的有效性，并凸显了激光雷达在提高城市安全和推进智能交通系统方面的作用。]]></description>
      <guid>https://arxiv.org/abs/2405.13202</guid>
      <pubDate>Fri, 24 May 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>通过微手势理解实现无身份的人工情感智能</title>
      <link>https://arxiv.org/abs/2405.13206</link>
      <description><![CDATA[arXiv:2405.13206v1 Announce Type: new 
摘要：本研究关注人体肢体语言中一类特殊的动作——微手势（MG）。微手势不同于一般的说明性手势，它不是有意为之向他人传达信息的行为，而是由内心感受驱动的无意行为。这一特点为微手势带来了两个值得重新思考的新挑战。第一，为其他动作识别设计的策略是否完全适用于微手势。第二，微手势作为补充数据，能否为情感理解提供额外的见解。在识别微手势时，我们探索了各种增强策略，这些策略考虑到微手势的细微空间和短暂时间特征，通常伴有重复性，以确定更合适的增强方法。考虑到时间域信息对微手势的重要性，我们引入了一种简单高效的即插即用时空平衡融合方法。我们不仅在所考虑的微手势数据集上研究了我们的方法，还在主流动作数据集上进行了实验。结果表明，我们的方法在微手势识别和其他数据集上表现良好，与以前的微手势识别方法相比，取得了最先进的性能。对于基于微手势的情感理解，我们构建了复杂的情感推理场景。我们使用大型语言模型进行的评估表明，微手势在增强全面情感理解方面发挥着重要而积极的作用。我们开发的场景可以扩展到其他基于微手势的任务，例如欺骗检测和访谈。我们确认我们的新见解有助于推动微手势和情感人工智能的研究。]]></description>
      <guid>https://arxiv.org/abs/2405.13206</guid>
      <pubDate>Fri, 24 May 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>CamViG：使用多模态变换器实现摄像头感知图像到视频的生成</title>
      <link>https://arxiv.org/abs/2405.13195</link>
      <description><![CDATA[arXiv:2405.13195v1 公告类型：新 
摘要：我们扩展了多模态转换器，将 3D 相机运动作为视频生成任务的调节信号。生成视频模型变得越来越强大，因此将研究重点集中在控制此类模型输出的方法上。我们建议通过在生成的视频过程中根据三维相机运动的编码来调节生成的视频，从而将虚拟 3D 相机控制添加到生成视频方法中。结果表明，我们 (1) 能够在视频生成过程中从单帧和相机信号开始成功控制相机，(2) 我们证明使用传统计算机视觉方法生成的 3D 相机路径的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.13195</guid>
      <pubDate>Fri, 24 May 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>用于光学遥感图像中海冰识别的全局-局部细节引导变压器</title>
      <link>https://arxiv.org/abs/2405.13197</link>
      <description><![CDATA[arXiv:2405.13197v1 公告类型：新 
摘要：海冰识别对于反映气候变化、保障船舶航行安全具有重要意义。最近，许多基于深度学习的方法被提出并应用于分割和识别海冰区域。然而，海冰区域规模多样、边缘轮廓曲折且精细，难以区分不同类型的海冰，对现有的海冰识别模型提出了挑战。本文提出了一种用于光学遥感图像中海冰识别的全局局部细节引导变换器（GDGT）方法。在GDGT中，设计了全局-局部特征融合机制来融合全局结构相关特征和局部空间细节特征。此外，开发了细节引导解码器，以在特征重建过程中保留更高分辨率的细节信息，从而提高海冰识别的性能。对生成的海冰数据集的实验证明了GDGT的有效性和先进性。]]></description>
      <guid>https://arxiv.org/abs/2405.13197</guid>
      <pubDate>Fri, 24 May 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>通过代理选择和轨迹预测物理方法增强交互建模</title>
      <link>https://arxiv.org/abs/2405.13152</link>
      <description><![CDATA[arXiv:2405.13152v1 公告类型：新 
摘要：在这项研究中，我们解决了大多数现有车辆轨迹预测方法固有的局限性，这些方法在考虑智能体之间的交互时，不加区别地将所有智能体纳入预定的邻近范围内。这些方法通常采用基于注意力的架构或图神经网络来编码交互，这引入了三个挑战：（i）不加区别地选择所有附近的代理大大增加了模型的计算需求，特别是在那些交互丰富的场景中。 (ii)此外，当前时间代理的简单化特征提取不足以充分捕捉交互的微妙动态。 (iii) 由于注意力机制和图神经网络固有的低可解释性，模型倾向于将不可靠的相关系数分配给某些代理，从而对轨迹预测的准确性产生不利影响。为了缓解这些问题，我们引入了 ASPILin，这是一种新颖的方法，通过考虑交互代理当前和未来的车道来增强交互代理的选择，并将这种考虑扩展到所有历史框架。利用智能体的状态，我们估计智能体之间最近的未来距离以及到达该距离所需的时间。然后，将它们与当前距离相结合，得出物理相关系数来编码交互。在流行的轨迹预测数据集上进行的实验表明，我们的方法高效且简单，优于其他最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.13152</guid>
      <pubDate>Fri, 24 May 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>KPConvX：利用内核注意力现代化内核点卷积</title>
      <link>https://arxiv.org/abs/2405.13194</link>
      <description><![CDATA[arXiv:2405.13194v1 公告类型：新 
摘要：在深度点云理解领域，KPConv 是一种独特的架构，它使用核点在空间中定位卷积权重，而不是依赖多层感知器（MLP）编码。虽然它最初取得了成功，但后来被最近采用更新设计和训练策略的 MLP 网络超越。基于核点原理，我们提出了两种新颖的设计：KPConvD（深度 KPConv），一种更轻的设计，可以使用更深的架构；KPConvX，一种创新设计，可以使用内核注意力值来缩放 KPConvD 的深度卷积权重。使用具有现代架构和训练策略的 KPConvX，我们能够在 ScanObjectNN、Scannetv2 和 S3DIS 数据集上超越当前最先进的方法。我们通过消融研究验证我们的设计选择并发布我们的代码和模型。]]></description>
      <guid>https://arxiv.org/abs/2405.13194</guid>
      <pubDate>Fri, 24 May 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>面向图像字幕的检索增强架构</title>
      <link>https://arxiv.org/abs/2405.13127</link>
      <description><![CDATA[arXiv:2405.13127v1 公告类型：新 
摘要：图像字幕模型的目标是通过生成准确反映输入图像内容的自然语言描述来弥合视觉和语言模态之间的差距。近年来，研究人员利用基于深度学习的模型，在视觉特征的提取和多模态连接的设计方面取得了进展来解决这一任务。这项工作提出了一种开发图像字幕模型的新方法，该模型利用外部 kNN 存储器来改进生成过程。具体来说，我们提出了两种模型变体，其中包含基于视觉相似性的知识检索器组件、表示输入图像的可微分编码器以及基于上下文线索和从外部存储器检索的文本来预测标记的 kNN 增强语言模型。我们在 COCO 和 nocaps 数据集上实验验证了我们的方法，并证明合并显式外部记忆可以显着提高字幕的质量，尤其是在较大的检索语料库中。这项工作为检索增强字幕模型提供了宝贵的见解，并为更大规模地改进图像字幕开辟了新途径。]]></description>
      <guid>https://arxiv.org/abs/2405.13127</guid>
      <pubDate>Fri, 24 May 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>NieR：基于法线的光照场景渲染</title>
      <link>https://arxiv.org/abs/2405.13097</link>
      <description><![CDATA[arXiv:2405.13097v1 公告类型：新
摘要：在现实世界的道路场景中，不同的材料特性会导致复杂的光反射现象，因此准确的色彩再现对于增强模拟驾驶环境的真实感和安全性至关重要。然而，现有的方法往往难以捕捉到全光谱的照明效果，特别是在视点变化会导致材料颜色发生显著变化的动态场景中。为了应对这一挑战，我们引入了 NieR（基于法线的照明场景渲染），这是一个新颖的框架，它考虑到了不同材料表面上光反射的细微差别，从而实现了更精确的渲染。为了模拟照明合成过程，我们提出了 LD（光分解）模块，它可以捕捉表面上的照明反射特性。此外，为了解决动态照明场景，我们提出了 HNGD（分层法线梯度致密化）模块来克服稀疏高斯表示的局限性。具体来说，我们根据法线梯度动态调整高斯密度。实验评估表明，我们的方法在视觉质量方面优于最先进的（SOTA）方法，并在性能指标上表现出显著优势。代码可在https://wanghongsheng01.github.io/NieR/获取。]]></description>
      <guid>https://arxiv.org/abs/2405.13097</guid>
      <pubDate>Fri, 24 May 2024 06:19:59 GMT</pubDate>
    </item>
    </channel>
</rss>