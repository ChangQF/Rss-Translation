<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Wed, 20 Dec 2023 03:12:05 GMT</lastBuildDate>
    <item>
      <title>SAI3D：分割 3D 场景中的任何实例。 （arXiv：2312.11557v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11557</link>
      <description><![CDATA[3D 实例分割的进步传统上与
带注释的数据集的可用性，将其应用限制在狭窄的范围内
对象类别的范围。最近的努力试图利用
用于开放集语义推理的视觉语言模型，例如 CLIP，但是这些
方法很难区分相同类别的对象并依赖
关于不普遍适用的特定提示。在本文中，我们
介绍 SAI3D，一种新颖的零样本 3D 实例分割方法，
协同地利用几何先验和语义线索
分段任意模型 (SAM)。我们的方法将 3D 场景划分为几何形状
图元，然后逐渐合并到 3D 实例分割中
与多视图 SAM 掩模一致。此外，我们设计了一个
具有动态阈值机制的分层区域生长算法，
这很大程度上提高了细粒度3D场景解析的鲁棒性。
对 Scan-Net 和更具挑战性的 ScanNet++ 数据集的实证评估
展示我们方法的优越性。值得注意的是，SAI3D 的性能优于
现有的开放词汇基线，甚至超越了完全监督的方法
ScanNet++ 上的类不可知分割。
]]></description>
      <guid>http://arxiv.org/abs/2312.11557</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:05 GMT</pubDate>
    </item>
    <item>
      <title>CR-SFP：学习软滤波器修剪的一致表示。 （arXiv：2312.11555v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11555</link>
      <description><![CDATA[软过滤器修剪〜（SFP）已成为一种有效的修剪技术
允许修剪后的过滤器更新并有机会重新生长到
网络。然而，这种修剪策略应用训练和修剪
替代方式，这不可避免地导致表述不一致
训练时的重建网络~(R-NN) 和修剪后的网络之间
network~(P-NN) 进行推理，导致性能下降。在这个
论文中，我们建议通过学习一致的表示来缩小这一差距
用于软过滤器修剪，称为 CR-SFP。具体来说，对于每次训练
步骤，CR-SFP 同时优化 R-NN 和 P-NN
相同训练数据的扭曲版本，同时迫使它们
通过双向最小化后验分布来保持一致
KL-散度损失。同时，R-NN 和 P-NN 共享主干参数，因此
仅引入额外的分类器参数。经过训练，我们可以
导出 P-NN 进行推理。 CR-SFP 是一种简单而有效的培训
框架来提高 P-NN 的准确性，而无需引入任何额外的
推理成本。它还可以与多种修剪标准相结合
损失函数。大量实验证明我们的 CR-SFP 能够实现
跨各种 CNN 架构的一致改进。值得注意的是，在 ImageNet 上，
我们的 CR-SFP 在 ResNet18 上减少了超过 41.8% 的 FLOP，top-1 为 69.2%
准确率，在相同训练设置下将 SFP 提高 2.1\%。代码
将在 GitHub 上公开发布。
]]></description>
      <guid>http://arxiv.org/abs/2312.11555</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:04 GMT</pubDate>
    </item>
    <item>
      <title>StarVector：从图像生成可缩放矢量图形代码。 （arXiv：2312.11556v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11556</link>
      <description><![CDATA[可扩展矢量图形 (SVG) 已成为现代图像中不可或缺的一部分
渲染应用程序由于其分辨率的无限可扩展性，
多功能的可用性和编辑功能。 SVG 在以下领域特别受欢迎
网页开发和图形设计领域。 SVG 的现有方法
使用深度学习进行建模通常很难生成复杂的 SVG
仅限于需要大量处理的较简单的
简化。本文介绍了 StarVector，一种多模态 SVG 生成方法
有效集成代码生成大型语言模型的模型
（CodeLLM）和视觉模型。我们的方法利用 CLIP 图像编码器
从基于像素的图像中提取视觉表示，然后
通过适配器模块转换为视觉标记。这些视觉标记是
置于 SVG 标记嵌入之前，并且该序列由以下公式建模
StarCoder 模型使用下一个令牌预测，有效地学习对齐
视觉和代码标记。这使得 StarVector 能够生成不受限制的 SVG
准确地表示像素图像。为了评估 StarVector 的性能，
我们推出 SVG-Bench，一个用于评估 SVG 方法的综合基准
跨多个数据集和相关指标。在此基准范围内，我们
引入新颖的数据集，包括 SVG-Stack，这是一个大型数据集
真实世界的 SVG 示例，并使用它来将 StarVector 预训练为大型
SVG 的基础模型。我们的结果表明显着增强
视觉质量和复杂性处理优于当前方法，标志着显着
SVG 生成技术的进步。代号及型号：
https://github.com/joanrod/star-vector
]]></description>
      <guid>http://arxiv.org/abs/2312.11556</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:04 GMT</pubDate>
    </item>
    <item>
      <title>使用自然语言进行迭代运动编辑。 （arXiv：2312.11538v1 [cs.GR]）</title>
      <link>http://arxiv.org/abs/2312.11538</link>
      <description><![CDATA[文本到运动扩散模型可以从文本生成逼真的动画
提示，但不支持细粒度的运动编辑控件。在本文中
我们提出了一种使用自然语言迭代指定本地的方法
编辑现有的角色动画，这是大多数计算机中常见的任务
动画工作流程。我们的关键思想是使用以下方式表示运动编辑空间
一组运动学运动运算符，它们具有明确定义的语义，用于说明如何
修改目标运动的特定帧。我们提供了一种算法
利用预先存在的语言模型来翻译文本描述
对运动编辑操作符 (MEO) 序列进行运动编辑。赋予新的
MEO 生成的关键帧，我们使用基于扩散的关键帧插值
生成最终动议。通过用户研究和定量评估，我们
证明我们的系统可以执行尊重
动画师的编辑意图，保持忠实于原始动画（他们编辑
原始动画，没有显着改变它），并产生逼真的效果
角色动画结果。
]]></description>
      <guid>http://arxiv.org/abs/2312.11538</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:03 GMT</pubDate>
    </item>
    <item>
      <title>FER-C：面部表情识别的分布外软校准基准测试。 （arXiv：2312.11542v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11542</link>
      <description><![CDATA[我们提出了用于校准面部表情识别的软基准
（FER）。虽然之前的工作重点是识别情感状态，但我们发现
FER 模型未经校准。当
分布外（OOD）变化进一步加剧了面部的模糊性
表达式。虽然大多数 OOD 基准测试都提供硬标签，但我们认为
用于评估 FER 模型的真实标签应该是软的，以便更好地
反映面部行为背后的模糊性。我们的框架提出了软
非常接近基于平均信息损失的标签
不同类型的 OOD 转变。最后，我们展示了校准的好处
在我们的基准测试中测试了五种最先进的 FER 算法。
]]></description>
      <guid>http://arxiv.org/abs/2312.11542</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:03 GMT</pubDate>
    </item>
    <item>
      <title>通过信息追踪学习可解释的查询以进行可解释的图像分类。 （arXiv：2312.11548v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11548</link>
      <description><![CDATA[信息追踪（IP）是一种可解释的预测算法，它贪婪地
按以下顺序选择一系列关于数据的可解释查询
信息增益，根据观察到的每一步更新其后验
查询-答案对。标准范式使用手工制作的字典
由领域专家或大型语言模型策划的潜在数据查询
在人工提示后。然而，在实践中，手工制作的词典是
受限于策展人的专业知识和提示的启发
工程。本文介绍了一种新颖的方法：学习字典
直接来自数据集的可解释查询。我们的查询字典学习
通过增加IP的变分将问题表述为优化问题
具有可学习字典参数的公式。制定可学习和
可解释的查询，我们利用大视野的潜在空间和
像 CLIP 这样的语言模型。为了解决优化问题，我们提出了一个新的
受经典稀疏字典启发的查询字典学习算法
学习。我们的实验表明，学习字典显着
优于使用大型语言模型生成的手工字典。
]]></description>
      <guid>http://arxiv.org/abs/2312.11548</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:03 GMT</pubDate>
    </item>
    <item>
      <title>Customize-It-3D：使用特定于主题的知识先验从单个图像创建高质量 3D。 （arXiv：2312.11535v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11535</link>
      <description><![CDATA[在本文中，我们提出了一种新颖的两阶段方法，该方法充分利用
参考图像提供的信息来建立定制知识
先于图像到 3D 生成。虽然以前的方法主要依赖于
一般扩散先验，很难产生与
参考图像，我们提出了一个特定于主题的多模态扩散模型。
该模型不仅通过考虑着色模式来帮助 NeRF 优化
改进了几何形状，同时也增强了粗糙结果的纹理以实现
卓越的精细化。这两个方面都有助于忠实地对齐 3D
内容与主题有关。大量的实验证明了我们的优越性
方法，Customize-It-3D，大大优于以前的作品。
它能够产生忠实的 360 度重建，具有令人印象深刻的视觉质量，
使其非常适合各种应用，包括文本转 3D 创建。
]]></description>
      <guid>http://arxiv.org/abs/2312.11535</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:02 GMT</pubDate>
    </item>
    <item>
      <title>FastSR-NeRF：通过简单的超分辨率管道提高消费设备上的 NeRF 效率。 （arXiv：2312.11537v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11537</link>
      <description><![CDATA[最近提出了超分辨率（SR）技术来升级
神经辐射场（NeRF）的输出并生成高质量图像
提高推理速度。然而现有的NeRF+SR方法增加了训练
使用额外的输入特征、损失函数和/或昂贵的开销
培训程序，例如知识蒸馏。在本文中，我们的目标是
利用 SR 提高效率，无需昂贵的培训或架构
变化。具体来说，我们构建了一个简单的 NeRF+SR 管道，可以直接
结合现有模块，我们提出了一种轻量级增强技术，
随机补丁采样，用于训练。与现有的 NeRF+SR 方法相比，我们的
管道减轻了 SR 计算开销，并且可训练高达 23 倍
速度更快，使其可以在 Apple 等消费设备上运行
MacBook。实验表明，我们的流程可以将 NeRF 输出提高 2-4 倍，同时
保持高质量，在 NVIDIA 上将推理速度提高高达 18 倍
M1 Pro 芯片上的 V100 GPU 和 12.8x。我们的结论是 SR 可以是一个简单但
提高消费者 NeRF 模型效率的有效技术
设备。
]]></description>
      <guid>http://arxiv.org/abs/2312.11537</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:02 GMT</pubDate>
    </item>
    <item>
      <title>初始种子向量的综合转变暴露了基于潜在的扩散模型的脆弱性。 （arXiv：2312.11473v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11473</link>
      <description><![CDATA[条件扩散模型的最新进展带来了巨大的成果
各个领域的能力。然而，了解影响
初始种子载体的变化仍然是一个尚未得到充分研究的关注领域。
特别是，基于潜在的扩散模型显示图像中的不一致
当使用次优初始值初始化时，在标准条件下生成
种子载体。了解初始种子向量对生成的影响
样本，我们提出了一个可靠性评估框架来评估
当初始种子向量为时生成扩散模型的样本
经历各种合成转变。我们的结果表明轻微
对最先进稳定的初始种子向量的操作
扩散（Rombach et al., 2022）可能会导致显着的干扰
生成样本，从而创建没有效果的图像
条件变量。相比之下，GLIDE（Nichol et al., 2022）在
即使初始种子向量发生变换，也能生成可靠的样本。
因此，我们的研究揭示了选择的重要性和影响
基于潜在的扩散模型中的初始种子向量。
]]></description>
      <guid>http://arxiv.org/abs/2312.11473</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:01 GMT</pubDate>
    </item>
    <item>
      <title>迈向超低成本智能手机显微镜。 （arXiv：2312.11479v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11479</link>
      <description><![CDATA[COVID-19 的爆发暴露了我们技术工具的不足
家庭健康监测，最近的研究表明，
智能手机作为通用光学显微成像平台
应用程序。然而，他们中的大多数使用实验室级光机
组件和透射照明，以确保焦点调节能力和
成像质量高，导致设备成本较高。在这里我们提出一个
适用于智能手机显微镜的超低成本解决方案。为了实现焦点可调，
我们设计了一个类似跷跷板的结构，能够转换大位移
一侧变成另一侧的小位移（减少到~9.1%），这
利用 3D 打印材料固有的灵活性。我们取得了
调焦精度~5微米，比机械加工高40倍
3D 打印镜头支架本身的精度。对于显微成像，我们使用
以现成的智能手机相机镜头为目标，并内置
手电筒作为照明。补偿最终的图像质量
为了解决退化问题，我们开发了一种基于学习的图像增强方法。我们使用
CycleGAN 架构用于从智能手机显微镜建立映射
图像到台式显微镜图像，无需配对。我们验证了成像
不同生物医学样品上的性能。除了智能手机，我们还保留了
设备的全部成本低于 4 美元。我们认为这些努力是为了降低
智能手机显微镜的成本将有利于其在各个领域的应用
场景，例如现场检测、现场诊断和家庭健康
监视。
]]></description>
      <guid>http://arxiv.org/abs/2312.11479</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:01 GMT</pubDate>
    </item>
    <item>
      <title>自适应平滑激活可改善放射扫描的疾病诊断和器官分割。 （arXiv：2312.11480v1 [cs.NE]）</title>
      <link>http://arxiv.org/abs/2312.11480</link>
      <description><![CDATA[在这项研究中，我们提出了一种新的激活函数，称为自适应平滑
激活单元（ASAU），专为优化梯度传播而定制，从而
提高卷积网络在医学图像分析中的熟练程度。
我们将这个新的激活函数应用于两个重要且常用的激活函数
医学图像分析的一般任务：自动疾病诊断和器官
CT 和 MRI 中的分割。我们对 RadImageNet 的严格评估
腹部/骨盆（CT 和 MRI）数据集和肝脏肿瘤分割基准
(LiTS) 2017 表明我们的 ASAU 集成框架不仅实现了
与 ReLU 相比，分类准确度（疾病
腹部 CT 和 MRI 检测），但也实现了 1\%-3\% 的改善
骰子系数与广泛使用的“健康肝组织”激活相比
分割。这些改进为开发
诊断工具，特别是对于复杂、具有挑战性的病理。这
ASAU 卓越的性能和适应性凸显了其潜力
集成到广泛的图像分类和分割任务中。
]]></description>
      <guid>http://arxiv.org/abs/2312.11480</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:01 GMT</pubDate>
    </item>
    <item>
      <title>评估 GPT4-V 的结构化推理任务。 （arXiv：2312.11524v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.11524</link>
      <description><![CDATA[多模态有望解锁大型语言模型的进一步用途。
最近，最先进的语言模型 GPT-4 通过视觉得到了增强
能力。我们对 GPT-4V 和其他五个产品进行了及时评估
结构化推理任务的基线，例如数学推理、视觉推理
数据分析和代码生成。我们展示了视觉思维链
将思想链扩展到多模式法学硕士，产生了显着的成果
对香草模型的改进。我们还进行了分类分析
这些模型表现良好和表现不佳的场景，强调
与连贯多模态推理相关的挑战。
]]></description>
      <guid>http://arxiv.org/abs/2312.11524</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:01 GMT</pubDate>
    </item>
    <item>
      <title>用于定量 MRI 参数估计的无偏神经网络。 （arXiv：2312.11468v1 [physical.med-ph]）</title>
      <link>http://arxiv.org/abs/2312.11468</link>
      <description><![CDATA[目的：开发基于神经网络（NN）的定量 MRI 参数
具有最小偏差和接近理论最小值的方差的估计量，
Cram\&#39;er-Rao 界。

理论和方法：我们明确惩罚神经网络估计的偏差
在训练期间，这涉及对多个噪声实现进行平均
相同的测量值。所得神经网络的偏差和方差属性为
研究了两种定量神经成像应用。

结果：在模拟中，所提出的策略减少了估计偏差
整个参数空间并实现接近 Cram\&#39;er-Rao 的方差
边界。在体内，我们观察到估计的参数图之间具有良好的一致性
使用所提出的神经网络和传统估计器，例如非线性
最小二乘拟合，而最先进的神经网络显示出更大的偏差。

结论：使用所提出的策略训练的神经网络大约是最小的
方差无偏估计量并提供显着改进的计算
与传统估算器相比，其效率具有可比或更高的精度。
]]></description>
      <guid>http://arxiv.org/abs/2312.11468</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自动检查电力线绝缘子的异常检测。 （arXiv：2312.11470v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.11470</link>
      <description><![CDATA[绝缘子的检查对于确保电力系统可靠运行非常重要
电源系统。最近，深度学习被探索用于自动化
利用无人机捕获的航空图像以及
强大的物体检测模型。然而，纯粹基于对象检测
方法表现出类不平衡导致的故障检测精度差
绝缘体，特别是对于早期故障。为了解决这个问题
为了提高数据效率，本文提出了一种两阶段方法
利用对象检测与异常检测相结合来可靠地
检测绝缘体中的故障。文章采用了可解释的深度神经网络
用于异常检测的基于网络的一类分类器，减少了
依赖大量可用的故障绝缘体图像，这可能是
在实际应用中很难获得。异常检测模型为
使用两个数据集进行训练——代表数据丰富和数据稀缺
场景——以无监督和半监督的方式。结果表明
训练数据集中仅包含六个真实异常
显着提高了模型的性能，并实现了可靠的
检测绝缘子中罕见的故障。分析
异常检测模型提供的解释表明该模型是
能够准确识别绝缘盘上的故障区域，同时还
表现出一些错误的预测。
]]></description>
      <guid>http://arxiv.org/abs/2312.11470</guid>
      <pubDate>Wed, 20 Dec 2023 03:12:00 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉变压器集合进行胶质母细胞瘤肿瘤分割。 (arXiv:2312.11467v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.11467</link>
      <description><![CDATA[胶质母细胞瘤是最具攻击性和最致命的大脑类型之一
癌症，与其他类型的癌症相比，存活率较低。分析
磁共振成像 (MRI) 扫描是最有效的方法之一
胶质母细胞瘤等脑癌的诊断和治疗。准确的
治疗计划和治疗通常需要 MRI 图像中的肿瘤分割
治疗方法的风险评估。在这里，我们提出了一个新颖的管道，Brain
智能神经网络 (BRAINNET) 辅助放射学，它利用
MaskFormer，一种视觉变换器模型，可生成强大的肿瘤分割
使。我们分别使用来自三个模型的九个预测的集合
在三个正交 2D 切片方向（轴向、矢状、
和冠状）3D 脑 MRI 体积。我们在以下平台上训练和测试我们的模型
公开可用的 UPenn-GBM 数据集，由 3D 多参数 MRI 组成
(mpMRI) 对 611 名受试者进行扫描。使用 Dice 系数 (DC) 和 95% Hausdorff
距离（HD）进行评估，我们的模型在以下方面取得了最先进的结果
分割所有三个不同的肿瘤区域——肿瘤核心（DC = 0.894，HD =
2.308）、整个肿瘤（DC = 0.891，HD = 3.552）和增强肿瘤（DC = 0.812，
高清 = 1.608）。
]]></description>
      <guid>http://arxiv.org/abs/2312.11467</guid>
      <pubDate>Wed, 20 Dec 2023 03:11:59 GMT</pubDate>
    </item>
    </channel>
</rss>