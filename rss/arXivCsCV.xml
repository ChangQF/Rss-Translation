<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 22 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过基于网格的交叉点预测从点云重建表面</title>
      <link>https://arxiv.org/abs/2403.14085</link>
      <description><![CDATA[arXiv:2403.14085v1 公告类型：新
摘要：点云表面重建是计算机视觉和计算机图形学领域的一项重要任务。基于 SDF 的方法擅长以最小的误差和伪像重建平滑网格，但在表示开放表面方面却很困难。另一方面，基于 UDF 的方法可以有效地表示开放表面，但通常会在表面附近引入噪声，从而导致网格中出现伪影。在这项工作中，我们提出了一种直接预测点对采样线段与隐式曲面之间的交点的新颖方法。该方法不仅保留了表示开放表面的能力，而且还消除了网格中的伪影。我们的方法在三个数据集上展示了最先进的性能：ShapeNet、MGN 和 ScanNet。该代码将在接受后提供。]]></description>
      <guid>https://arxiv.org/abs/2403.14085</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LiDAR 强度增强训练进行无监督本征图像分解</title>
      <link>https://arxiv.org/abs/2403.14089</link>
      <description><![CDATA[arXiv:2403.14089v1 公告类型：新
摘要：无监督内在图像分解（IID）是在没有这些基本事实的情况下将自然图像分离为反照率和阴影的过程。最近采用光检测和测距（LiDAR）强度的模型表现出了令人印象深刻的性能，尽管推理过程中 LiDAR 强度的必要性限制了其实用性。因此，非常需要在推理过程中仅采用单个图像的 IID 模型，同时保持与具有图像加 LiDAR 强度的模型一样高的 IID 质量。为了应对这一挑战，我们提出了一种新颖的方法，在推理过程中仅利用图像，而在训练过程中利用图像和 LiDAR 强度。具体来说，我们引入了一种部分共享模型，该模型使用不同的特定编码器分别接受图像和 LiDAR 强度，但在特定组件中将它们一起处理以学习共享表示。此外，为了提高 IID 质量，我们提出了反照率对准损失和图像激光雷达转换 (ILC) 路径。反照率对齐损失将图像的灰度反照率与从 LiDAR 强度推断的灰度反照率对齐，从而减少由于 LiDAR 强度中不存在投射阴影而导致图像中反照率的投射阴影。此外，为了在保留图像内容的同时将输入图像转换为反照率和阴影样式，编码器将输入图像分为样式代码和内容代码。 ILC 路径相互转换图像和 LiDAR 强度，它们共享内容但风格不同，有助于风格与内容的明显区分。因此，LIET 实现了与具有 LiDAR 强度的现有模型相当的 IID 质量，同时在推理过程中仅使用没有 LiDAR 强度的图像。]]></description>
      <guid>https://arxiv.org/abs/2403.14089</guid>
      <pubDate>Fri, 22 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>利用热模态增强弱光条件下的重建</title>
      <link>https://arxiv.org/abs/2403.14053</link>
      <description><![CDATA[arXiv:2403.14053v1 公告类型：新
摘要：神经辐射场（NeRF）通过学习多视图图像中场景的隐式体积表示来实现逼真的新颖视图合成，忠实地传达色度信息。然而，传感器噪声会污染低值像素信号，并且有损相机图像信号处理器将进一步消除极暗情况下接近零的强度，从而降低合成性能。现有的方法从原始图像重建低光场景，但很难恢复黑暗区域的纹理和边界细节。此外，它们不适合依赖显式表示的高速模型。为了解决这些问题，我们提出了Thermal-NeRF，它以热图像和可见光原始图像作为输入，考虑到热相机对照明变化具有鲁棒性，并且原始图像保留黑暗中任何可能的线索，以同时完成可见光和热视图合成。此外，还建立了第一个多视图热可见光数据集（MVTV）以支持多模态 NeRF 的研究。 Thermal-NeRF 在细节保留和噪声平滑之间实现了最佳权衡，并提供了比以前的工作更好的合成性能。最后，我们证明这两种模式在 3D 重建中是互惠互利的。]]></description>
      <guid>https://arxiv.org/abs/2403.14053</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>来自太空的语义：航空领域机器人的卫星引导热语义分割注释</title>
      <link>https://arxiv.org/abs/2403.14056</link>
      <description><![CDATA[arXiv:2403.14056v1 公告类型：新
摘要：我们提出了一种新方法，通过利用卫星数据产品以及机载全球定位和姿态估计，自动为从飞行器捕获的热图像生成语义分割注释。这项新功能克服了由于缺乏带注释的热场数据集以及手动注释的时间和成本而开发现场机器人热语义感知算法的挑战，从而能够以大规模并行方式对现场采集工作中的热数据进行精确、快速的注释规模。通过将热调节细化步骤与视觉基础模型相结合，我们的方法可以使用低分辨率卫星土地覆盖数据生成高精度语义分割标签，而成本几乎为零。它通过使用昂贵的高分辨率选项实现了 98.5% 的性能，并且与基于当前用于生成 RGB 图像注释的大型视觉语言模型的流行零样本语义分割方法相比，性能提高了 70-160%。代码可在以下网址获取：https://github.com/connorlee77/aerial-auto-segment。]]></description>
      <guid>https://arxiv.org/abs/2403.14056</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>EventDance：用于基于事件的对象识别的无监督无源跨模式适应</title>
      <link>https://arxiv.org/abs/2403.14082</link>
      <description><![CDATA[arXiv:2403.14082v1 公告类型：新
摘要：在本文中，由于隐私和商业问题，我们首次尝试实现基于事件的对象识别的跨模式（即图像到事件）适应，而无需访问任何标记的源图像数据。由于事件相机的新颖性以及图像和事件之间明显的模态差距，解决这个新问题并非易事。特别是，由于只有源模型可用，因此如何仅使用未标记的目标事件数据从源模型中提取知识，同时实现知识迁移是一个障碍。为此，我们针对这个无监督的无源跨模式适应问题提出了一个新颖的框架，称为 EventDance。重要的是，受事件到视频重建方法的启发，我们提出了一种基于重建的模态桥接（RMB）模块，该模块以自监督的方式从事件重建强度帧。这使得构建代理图像以从源模型中提取知识（即标签）成为可能。然后，我们提出了一种多表示知识适应（MKA）模块，该模块将知识转移到学习具有多种表示类型的事件的目标模型，以充分探索事件的时空信息。连接源模型和目标模型的两个模块相互更新，以达到最佳性能。在具有两种自适应设置的三个基准数据集上进行的实验表明，EventDance 与利用源数据的先前方法相当。]]></description>
      <guid>https://arxiv.org/abs/2403.14082</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>通过视觉信息基础进行多模态幻觉控制</title>
      <link>https://arxiv.org/abs/2403.14003</link>
      <description><![CDATA[arXiv:2403.14003v1 公告类型：新
摘要：生成视觉语言模型（VLM）很容易生成听起来合理的文本答案，但这些答案并不总是基于输入图像。我们研究了这种通常被称为“幻觉”的现象，并表明它源于对语言先验的过度依赖。特别是，我们表明，随着生成更多令牌，对视觉提示的依赖就会减少，并且这种行为与幻觉的出现密切相关。为了减少幻觉，我们引入了多模态互信息解码（M3ID），这是一种用于即时放大的新采样方法。 M3ID放大了参考图像对语言先验的影响，因此有利于在视觉提示下生成具有更高互信息的标记。 M3ID 可以在推理时应用于任何预训练的自回归 VLM，无需进一步训练，并且计算开销最小。如果可以选择训练，我们表明 M3ID 可以与直接偏好优化 (DPO) 配合使用，以提高模型对提示图像的依赖，而无需任何标签。我们的实证研究结果表明，我们的算法保持了预先训练的 VLM 的流畅性和语言能力，同时通过减少视觉上不可靠的答案来减少幻觉。具体来说，对于 LLaVA 13B 模型，M3ID 和 M3ID+DPO 分别将字幕任务中幻觉物体的百分比减少了 25% 和 28%，并将 POPE 等 VQA 基准的准确性提高了 21% 和 24%。]]></description>
      <guid>https://arxiv.org/abs/2403.14003</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>EcoSense：通过边缘云协作实现近岸船舶检测的节能智能传感</title>
      <link>https://arxiv.org/abs/2403.14027</link>
      <description><![CDATA[arXiv:2403.14027v1 公告类型：新
摘要：由于算法的复杂性和系统部署的复杂性，检测近海海洋物体面临着挑战。我们提出了一种困难感知的边缘云协作传感系统，该系统将任务分为对象定位和细粒度分类。根据对象的估计难度，在边缘或云端对对象进行分类。该框架包括一个用于对象定位、分类和难度估计的低功耗设备定制前端模型，以及一个用于细粒度分类的基于变压器图卷积网络的后端模型。我们的系统在广泛使用的海洋物体检测数据集上表现出卓越的性能（mAP@0.5 +4.3%}），在系统层面显着降低了数据传输量（降低了95.43%）和能耗（降低了72.7%}）。我们在各种嵌入式系统平台和涉及无人机部署的现实场景中验证了所提出的系统。]]></description>
      <guid>https://arxiv.org/abs/2403.14027</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:58 GMT</pubDate>
    </item>
    <item>
      <title>ConGeo：跨地面视图变化的鲁棒跨视图地理定位</title>
      <link>https://arxiv.org/abs/2403.13965</link>
      <description><![CDATA[arXiv:2403.13965v1 公告类型：新
摘要：跨视图地理定位旨在通过将地面查询图像与其相应的地理参考鸟瞰图进行匹配来定位地面查询图像。在现实场景中，该任务需要容纳用户以不同方向和缩小视野 (FoV) 捕获的不同地面图像。然而，现有的学习流程是特定于方向或特定于 FoV 的，需要针对不同的地面视图变化进行单独的模型训练。此类模型严重依赖于训练数据中的北对齐空间对应和预定义的 FoV，从而损害了它们在不同设置下的稳健性。为了应对这一挑战，我们提出了 ConGeo，一种用于地理定位的单模态和跨模态对比方法：它通过强制地面之间的接近度来增强特征表示的鲁棒性和一致性，以提高模型的方向不变性及其对 FoV 变化的弹性查看同一位置的变化。作为跨视图地理定位的通用学习目标，当集成到最先进的管道中时，ConGeo 显着提高了三个基本模型在四个地理定位基准上针对不同地面视图变化的性能，并且优于竞争方法为每个地面视图变化训练单独的模型。]]></description>
      <guid>https://arxiv.org/abs/2403.13965</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>SeFFeC：用于细粒度面部编辑的语义面部特征控制</title>
      <link>https://arxiv.org/abs/2403.13972</link>
      <description><![CDATA[arXiv:2403.13972v1 公告类型：新
摘要：我们提出了语义面部特征控制（SeFFeC）——一种细粒度面部形状编辑的新方法。我们的方法能够操纵人类可理解的语义面部特征，例如鼻子长度或嘴巴宽度，这些特征是由不同组的面部标志定义的。与现有方法相比，面部标志的使用可以精确测量面部特征，从而无需任何手动注释标签即可训练 SeFFeC。 SeFFeC 由基于变压器的编码器网络组成，该网络将预训练生成模型的潜在向量和面部特征嵌入作为输入，并学习修改潜在向量以执行所需的面部编辑操作。为了确保所需的特征测量向目标值改变而不改变不相关的特征，我们引入了一种新颖的语义人脸特征损失。定性和定量结果表明，SeFFeC 能够对 23 种面部特​​征进行精确和细粒度的控制，其中一些特征以前无法通过其他方法进行控制，而无需手动注释。与现有方法不同，SeFFeC 还提供对面部特征的精确值的确定性控制以及更加局部化和解开的面部编辑。]]></description>
      <guid>https://arxiv.org/abs/2403.13972</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>水下检测中图像分割的不确定性驱动的主动学习</title>
      <link>https://arxiv.org/abs/2403.14002</link>
      <description><![CDATA[arXiv:2403.14002v1 公告类型：新
摘要：主动学习旨在选择最少量的数据来训练模型，该模型的性能与使用整个数据集训练的模型类似。我们研究了主动学习在水下基础设施检查任务中图像分割的潜力，这些任务通常会收集大量数据。管道检测图像通常语义重复，但质量差异很大。我们使用互信息作为获取函数，使用蒙特卡罗 dropout 计算。为了评估该框架的有效性，DenseNet 和 HyperSeg 使用主动学习的 CamVid 数据集进行了训练。此外，HyperSeg 还使用包含 50,000 多个图像的管道检查数据集进行训练。对于管道数据集，采用主动学习的 HyperSeg 使用 12.5% 的数据实现了 67.5% 的平均 IoU，使用相同数量的随机选择的图像实现了 61.4% 的平均 IoU。这表明在水下检测任务中使用主动学习分割模型可以显着降低成本。]]></description>
      <guid>https://arxiv.org/abs/2403.14002</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN、扩散模型和风格迁移技术增强指纹图像合成</title>
      <link>https://arxiv.org/abs/2403.13916</link>
      <description><![CDATA[arXiv:2403.13916v1 公告类型：新
摘要：我们提出了涉及生成对抗网络和扩散模型的新颖方法，以便合成高质量、活体和欺骗性的指纹图像，同时保留独特性和多样性等特征。我们通过各种方法从噪声中生成活体指纹，并使用图像转换技术将活体指纹图像转换为欺骗图像。为了基于有限的训练数据生成不同类型的欺骗图像，我们通过配备 Wasserstein 度量和梯度惩罚 (CycleWGAN-GP) 的循环自动编码器结合风格转移技术，以避免模式崩溃和不稳定。我们发现，当欺骗训练数据包含明显的欺骗特征时，它会改善实时到欺骗的翻译。我们主要通过Fr&#39;echet起始距离（FID）和错误接受率（FAR）来评估生成的活体指纹图像的多样性和真实性。我们的最佳扩散模型的 FID 为 15.78。类似的 WGAN-GP 模型实现了略高的 FID，同时由于与训练数据匹配时的 FAR 略低，因此在独特性评估中表现更好，这表明具有更好的创造力。此外，我们给出的示例图像表明 DDPM 模型显然可以生成逼真的指纹图像。]]></description>
      <guid>https://arxiv.org/abs/2403.13916</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>ACDG-VTON：用于虚拟试穿的准确且封闭的扩散生成</title>
      <link>https://arxiv.org/abs/2403.13951</link>
      <description><![CDATA[arXiv:2403.13951v1 公告类型：新
摘要：虚拟试穿（VTON）涉及生成穿着选定服装的人的图像。特别是基于扩散的方法可以创建高质量的图像，但它们很难保持输入服装的身份。我们发现这个问题源于扩散训练公式中的细节。为了解决这个问题，我们提出了一种独特的训练方案，限制了扩散训练的范围。我们使用在训练期间与目标图像完美对齐的控制图像。反过来，这可以在推理过程中准确地保留服装细节。我们展示了我们的方法不仅可以有效保留服装细节，还可以进行分层、造型和试鞋。我们的方法在单个推理周期中运行多件服装试穿，并且可以支持高质量的放大生成，而无需在更高分辨率下进行训练。最后，我们证明我们的方法在准确性和质量方面超越了先前的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.13951</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>衡量共同创意图像生成的多样性</title>
      <link>https://arxiv.org/abs/2403.13826</link>
      <description><![CDATA[arXiv:2403.13826v1 公告类型：新
摘要：质量和多样性已被提出作为评估共同创作系统生成的内容的合理启发法，但迄今为止，对于后者的构成或如何衡量，几乎没有达成一致。所提出的评估生成模型多样性的方法具有局限性，因为它们将模型的输出与基本事实进行比较，而在大型预训练生成模型时代可能无法使用，或者需要大量不切实际的计算。我们提出了一种基于神经网络编码熵的替代方案，用于比较图像集之间的多样性，该替代方案不需要真实知识并且易于计算。我们还比较了两个预先训练的网络，并展示了选择与我们想要评估的多样性概念之间的关系。最后，我们讨论了这些衡量指标在交互系统、模型评估以及更广泛的计算创造力中的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2403.13826</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>ExMap：利用可解释性热图实现无监督群体对虚假相关性的鲁棒性</title>
      <link>https://arxiv.org/abs/2403.13870</link>
      <description><![CDATA[arXiv:2403.13870v1 公告类型：新
摘要：群体鲁棒性策略旨在减轻深度学习模型中因训练数据集中存在的虚假相关性而产生的学习偏差。然而，大多数现有方法依赖于获取组的标签分布，这是耗时且昂贵的。因此，需要寻求无监督的群体鲁棒性策略。基于可以根据可解释性热图准确推断训练模型的分类策略的见解，我们引入了 ExMap，这是一种无监督的两阶段机制，旨在增强传统分类器中的群体鲁棒性。 ExMap 利用聚类模块根据模型的可解释性热图推断伪标签，然后在训练期间使用伪标签代替实际标签。我们的实证研究验证了 ExMap 的有效性 - 我们证明它弥补了与其监督同行的性能差距，并且优于现有的部分监督和无监督方法。此外，ExMap 可以与现有的群体鲁棒性学习策略无缝集成。最后，我们展示了它在解决多重捷径缓解新问题方面的潜力\footnote{代码可在\url{https://github.com/rwchakra/exmap}}获得。]]></description>
      <guid>https://arxiv.org/abs/2403.13870</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>CoMo：通过语言引导姿势代码编辑生成可控运动</title>
      <link>https://arxiv.org/abs/2403.13900</link>
      <description><![CDATA[arXiv:2403.13900v1 公告类型：新
摘要：文本到动作模型擅长有效地生成人体动作，但现有方法缺乏对生成过程的细粒度可控性。因此，修改动作中的微妙姿势或在特定时刻插​​入新动作仍然是一个挑战，限制了这些方法在不同场景中的适用性。鉴于这些挑战，我们引入了 CoMo，一种可控运动生成模型，擅长利用大型语言模型 (LLM) 的知识先验来准确生成和编辑运动。具体来说，CoMo 将运动分解为离散且具有语义意义的姿势代码，每个代码封装了身体部位的语义，表示“左膝轻微弯曲”等基本信息。给定文本输入，CoMo 自回归生成姿势代码序列，然后将其解码为 3D 运动。利用姿势代码作为可解释的表示，法学硕士可以通过根据编辑指令调整姿势代码来直接干预运动编辑。实验表明，与最先进的模型相比，CoMo 在运动生成方面实现了具有竞争力的性能，而在人体研究中，CoMo 在运动编辑能力方面大大超越了之前的工作。]]></description>
      <guid>https://arxiv.org/abs/2403.13900</guid>
      <pubDate>Fri, 22 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    </channel>
</rss>