<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>更好地致电 SAL：学习如何分割激光雷达中的任何内容</title>
      <link>https://arxiv.org/abs/2403.13129</link>
      <description><![CDATA[arXiv:2403.13129v1 公告类型：新
摘要：我们提出 $\texttt{SAL}$ ($\texttt{S}$egment $\texttt{A}$nything in $\texttt{L}$idar) 方法，该方法由文本提示的零样本模型组成对激光雷达中的任何对象进行分割和分类，以及一个伪标签引擎，可以在无需人工监督的情况下促进模型训练。虽然 $\textit{Lidar Panoptic Segmentation}$ (LPS) 的既定范例依赖于对先验定义的少数对象类的手动监督，但我们利用 2D 视觉基础模型“免费”生成 3D 监督。我们的伪标签由实例掩码和相应的 CLIP 令牌组成，我们使用校准的多模态数据将其提升到激光雷达。通过在这些标签上训练我们的模型，我们将 2D 基础模型提炼成我们的 Lidar $\texttt{SAL}$ 模型。即使没有手动标签，我们的模型在与类别无关的分割方面也达到了 91\%$，在完全监督的最先进的零样本 LPS 方面达到了 44\%$。此外，我们优于一些不提取图像特征而仅将图像特征提升到 3D 的基线。更重要的是，我们证明 $\texttt{SAL}$ 支持任意类提示，可以轻松扩展到新的数据集，并且随着自标记数据量的增加而显示出巨大的改进潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.13129</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 Sentinel-2 图像自动标记的极地海冰分类并行工作流程</title>
      <link>https://arxiv.org/abs/2403.13135</link>
      <description><![CDATA[arXiv:2403.13135v1 公告类型：新
摘要：极地海冰覆盖进退模式的观测是全球变暖的重要指标。本研究旨在开发一个强大、有效且可扩展的系统，使用 Sentinel-2 (S2) 图像将极地海冰分类为厚/雪覆盖、年轻/薄或开放水域。由于 S2 卫星正在积极捕捉地球表面的高分辨率图像，因此有大量图像需要分类。一个主要障碍是缺乏标记的 S2 训练数据（图像）来充当基本事实。我们展示了一种可扩展且准确的方法，使用仔细确定的颜色阈值来分割和自动标记 S2 图像。我们采用使用 PySpark 的并行工作流程，对基于薄云和阴影过滤颜色分割的自动标记 S2 图像进行缩放并实现 9 倍的数据加载和 16 倍的地图缩减加速，以生成标签数据。然后，使用此过程生成的自动标记数据来训练 U-Net 机器学习模型，从而获得良好的分类准确性。由于训练 U-Net 分类模型计算量大且耗时，因此我们将 U-Net 模型训练分布在 DGX 集群上，使用 Horovod 框架将其扩展到 8 个 GPU，加速比为 7.21 倍，且不影响模型的准确性。以南极罗斯海地区为例，在过滤掉S2图像中的薄云和阴影后，在自动标记数据上训练的U-Net模型对自动标记训练数据集的分类准确率达到98.97%。]]></description>
      <guid>https://arxiv.org/abs/2403.13135</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>SceneScript：使用自回归结构化语言模型重建场景</title>
      <link>https://arxiv.org/abs/2403.13064</link>
      <description><![CDATA[arXiv:2403.13064v1 公告类型：新
摘要：我们介绍了 SceneScript，这是一种使用自回归、基于标记的方法直接将完整场景模型生成为结构化语言命令序列的方法。我们提出的场景表示受到变压器和法学硕士最近成功的启发，并偏离了通常将场景描述为网格、体素网格、点云或辐射场的更传统的方法。我们的方法使用场景语言编码器-解码器架构直接从编码的视觉数据推断结构化语言命令集。为了训练 SceneScript，我们生成并发布了一个名为 Aria Synthetic Environments 的大型合成数据集，其中包含 10 万个高质量室内场景，以及以自我为中心的场景演练的真实感和真实注释渲染。我们的方法在建筑布局估计方面提供了最先进的结果，在 3D 对象检测方面提供了有竞争力的结果。最后，我们探讨了 SceneScript 的一个优势，即能够通过对结构化语言进行简单添加来轻松适应新命令，我们将针对粗略 3D 对象部分重建等任务进行说明。]]></description>
      <guid>https://arxiv.org/abs/2403.13064</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>HuLP：人类在环预测</title>
      <link>https://arxiv.org/abs/2403.13078</link>
      <description><![CDATA[arXiv:2403.13078v1 公告类型：新
摘要：本文介绍了 HuLP，一种人机交互的预后模型，旨在提高临床环境中预后模型的可靠性和可解释性，特别是在面临缺失协变量和结果的复杂性时。 HuLP 提供了一种创新方法，使人类专家能够进行干预，使临床医生能够与模型的预测进行交互并纠正模型的预测，从而促进人类和人工智能模型之间的协作，以产生更准确的预后。此外，HuLP 通过利用神经网络并提供有效处理丢失数据的定制方法来解决丢失数据的挑战。传统方法常常难以捕捉患者群体中的细微差别，从而导致预后预测受到影响。 HuLP 根据成像特征估算缺失的协变量，与临床医生的工作流程更加紧密地结合并提高可靠性。我们在两个真实世界的公开医学数据集上进行实验，以证明 HuLP 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.13078</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>使用端到端深度学习在铁路轨道上进行列车自我路径检测</title>
      <link>https://arxiv.org/abs/2403.13094</link>
      <description><![CDATA[arXiv:2403.13094v1 公告类型：新
摘要：本文介绍了“列车自我路径检测”的任务，这是一种专为智能车载视觉系统设计的铁路轨道检测的改进方法。尽管现有的研究缺乏精确性并且通常统一考虑视野内的所有轨道，但我们提出的任务特别旨在识别潜在复杂和动态铁路环境中火车的直接路径或“自我路径”。在此基础上，我们用自我路径注释扩展了 RailSem19 数据集，促进了这一方向的进一步研究。我们研究的核心是 TEP-Net，这是一个专为自我路径检测量身定制的端到端深度学习框架，具有可配置的模型架构、动态数据增强策略和特定领域的损失函数。利用基于回归的方法，TEP-Net 的性能优于 SOTA：在以比以前更细致的方式解决轨迹检测问题的同时，我们的模型在测试集上实现了 97.5% 的 IoU，并且比所有现有方法更快。进一步的比较分析强调了 TEP-Net 背后概念选择的相关性，证明了其在不同环境条件和操作动态下的稳健性的固有倾向。这项工作为智能驾驶辅助系统和自动列车运营的开发开辟了有前景的途径，为更安全、更高效的铁路运输铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2403.13094</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>我们什么时候不需要更大的视觉模型？</title>
      <link>https://arxiv.org/abs/2403.13043</link>
      <description><![CDATA[arXiv:2403.13043v1 公告类型：新
摘要：扩大视觉模型的尺寸已经成为获得更强大的视觉表示的事实上的标准。在这项工作中，我们讨论了不需要更大的视觉模型的点。首先，我们展示了尺度缩放 (S$^2$) 的威力，其中预训练和冻结的较小视觉模型（例如 ViT-B 或 ViT-L）在多个图像尺度上运行，可以胜过较大的模型（例如，ViT-H 或 ViT-G）关于分类、分割、深度估计、多模态 LLM (MLLM) 基准和机器人操作。值得注意的是，S$^2$ 在 V* 基准上详细理解 MLLM 方面实现了最先进的性能，超越了 GPT-4V 等模型。我们研究了与模型大小缩放相比 S$^2$ 成为首选缩放方法的条件。虽然较大的模型具有在困难示例上更好泛化的优势，但我们表明，较大视觉模型的特征可以通过多尺度较小模型的特征很好地近似。这表明当前大型预训练模型学习到的大多数（如果不是全部）表示也可以从多尺度较小模型中获得。我们的结果表明，多尺度的较小模型具有与较大模型相当的学习能力，并且用 S$^2$ 预训练较小模型可以匹配甚至超过较大模型的优势。我们发布了一个 Python 包，可以通过一行代码在任何视觉模型上应用 S$^2$：https://github.com/bfshi/scaling_on_scales。]]></description>
      <guid>https://arxiv.org/abs/2403.13043</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>Magic Fixup：通过观看动态视频简化照片编辑</title>
      <link>https://arxiv.org/abs/2403.13044</link>
      <description><![CDATA[arXiv:2403.13044v1 公告类型：新
摘要：我们提出了一种生成模型，在给定粗略编辑的图像的情况下，合成遵循规定布局的逼真输出。我们的方法从原始图像中转移精细细节并保留其各部分的特性。然而，它使其适应新布局定义的照明和环境。我们的主要见解是，视频是这项任务的强大监督来源：物体和摄像机运动提供了许多关于世界如何随着视点、照明和物理交互而变化的观察。我们构建一个图像数据集，其中每个样本都是以随机选择的时间间隔从同一视频中提取的一对源帧和目标帧。我们使用两个模拟预期测试时用户编辑的运动模型将源帧向目标扭曲。我们从预训练的扩散模型开始，监督我们的模型将扭曲的图像转换为地面实况。我们的模型设计明确地实现了从源帧到生成图像的精细细节传输，同时严格遵循用户指定的布局。我们表明，通过使用简单的分割和粗略的二维操作，我们可以合成忠实于用户输入的逼真编辑，同时解决二阶效果，例如协调编辑对象之间的照明和物理交互。]]></description>
      <guid>https://arxiv.org/abs/2403.13044</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>Tel2Veh：融合电信数据和车流，通过时空框架预测无摄像头交通</title>
      <link>https://arxiv.org/abs/2403.12991</link>
      <description><![CDATA[arXiv:2403.12991v1 公告类型：新
摘要：车流是交通的关键指标，通常受到探测器覆盖范围的限制。随着广泛的移动网络覆盖范围的出现，我们可以利用道路上的移动用户活动或蜂窝流量作为车辆流量的代理。然而，由于来自不同用户类型的数据，蜂窝流量的计数可能与车辆流量不直接一致，因此我们提出了一项新任务：使用蜂窝流量预测无摄像头区域的车辆流量。为了揭示多源数据中的相关性，我们在选定的道路上部署了摄像头来建立 Tel2Veh 数据集，其中包括广泛的蜂窝交通和稀疏的车辆流量。为了应对这一挑战，我们提出了一个框架，该框架可以独立提取特征并将其与基于图神经网络（GNN）的融合相集成以辨别差异，从而能够使用蜂窝流量预测不可见的车辆流量。这项工作推进了电信数据在交通运输中的使用，并开创了电信和基于视觉的数据的融合，为交通管理提供了解决方案。]]></description>
      <guid>https://arxiv.org/abs/2403.12991</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>用于面部表情识别的带有注意力融合的情绪屏蔽自动编码器</title>
      <link>https://arxiv.org/abs/2403.13039</link>
      <description><![CDATA[arXiv:2403.13039v1 公告类型：新
摘要：面部表情识别（FER）是计算机视觉中的一项关键任务，在各个领域都有不同的应用。有限的 FER 数据集阻碍了表情识别模型的泛化能力，解决这一挑战对于提高性能至关重要。我们的论文提出了一种集成 MAE-Face 自监督学习（SSL）方法和融合注意力机制进行表情分类的创新方法，特别是在第六届野外情感行为分析（ABAW）竞赛中得到展示。此外，我们提出了预处理技术来强调基本的面部特征，从而提高模型在训练和验证集上的性能，特别是在 Aff-wild2 数据集上得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2403.13039</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>TAPTR：使用 Transformer 作为检测来跟踪任意点</title>
      <link>https://arxiv.org/abs/2403.13042</link>
      <description><![CDATA[arXiv:2403.13042v1 公告类型：新
摘要：在本文中，我们提出了一个简单而强大的框架，用于使用 TRansformers 跟踪任意点（TAPTR）。基于点跟踪与目标检测和跟踪非常相似的观察，我们借鉴 DETR 类算法的设计来解决 TAP 的任务。在所提出的框架中，在每个视频帧中，每个跟踪点都表示为点查询，它由位置部分和内容部分组成。与 DETR 一样，每个查询（其位置和内容特征）自然会逐层更新。它的可见性是通过其更新的内容功能来预测的。属于同一跟踪点的查询可以通过沿着时间维度的自注意力来交换信息。由于所有此类操作都是在类似 DETR 的算法中精心设计的，因此该模型在概念上非常简单。我们还采用了一些有用的设计，例如光流模型的成本量，并开发简单的设计来提供长时间信息，同时减轻特征漂移问题。我们的框架在各种 TAP 数据集上展示了强大的性能和最先进的性能，推理速度更快。]]></description>
      <guid>https://arxiv.org/abs/2403.13042</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>OSSCAR：具有组合优化的视觉和语言模型中的一次性结构化剪枝</title>
      <link>https://arxiv.org/abs/2403.12983</link>
      <description><![CDATA[arXiv:2403.12983v1 公告类型：新
摘要：结构化剪枝是降低大型视觉和语言模型推理成本的一种有前途的方法。通过删除精心选择的结构，例如神经元或注意力头，可以在标准深度学习硬件上实现这种方法的改进。在这项工作中，我们专注于一次性（训练后）设置中的结构化剪枝，这不需要在剪枝后重新训练模型。我们针对这个问题提出了一种新颖的组合优化框架，基于分层重建目标和允许可扩展优化的仔细重新表述。此外，我们设计了一种新的局部组合优化算法，该算法利用低秩更新来实现高效的局部搜索。我们的框架具有时间和内存效率高的特点，并且显着改进了视觉模型（例如 ResNet50、MobileNet）和语言模型（例如 OPT-1.3B - OPT-30B）上最先进的一次性方法。对于语言模型，例如 OPT-2.7B，与最先进的 ZipLM 方法相比，OSSCAR 可以将 WikiText 上的测试复杂度降低 125 倍，推理时间加速 2 倍。我们的框架也快了 $6\time$ - $8\time$。值得注意的是，我们的工作考虑了具有数百亿个参数的模型，这比之前结构化剪枝文献中考虑的参数大了 100 倍。]]></description>
      <guid>https://arxiv.org/abs/2403.12983</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>BaCon：通过平衡的特征级对比学习促进不平衡的半监督学习</title>
      <link>https://arxiv.org/abs/2403.12986</link>
      <description><![CDATA[arXiv:2403.12986v1 公告类型：新
摘要：半监督学习 (SSL) 减少了深度学习中对大量注释的需求，但 SSL 中数据分布不平衡这一更现实的挑战在很大程度上仍未得到探索。在类不平衡半监督学习（CISSL）中，不可靠的伪标签引入的偏差可能会因数据分布不平衡而加剧。大多数现有方法通过重新加权或重新采样在实例级别解决这个问题，但其性能受到对有偏差的骨干表示的依赖的严重限制。其他一些方法确实执行特征级别的调整，例如特征混合，但可能会引入不利的噪声。在本文中，我们讨论了 CISSL 问题的更平衡特征分布的好处，并进一步提出了平衡特征级对比学习方法（BaCon）。我们的方法以精心设计的对比方式直接规范实例表示的分布。具体来说，按类特征中心被计算为正锚点，而负锚点则通过简单而有效的机制选择。利用与分布相关的温度调整来动态控制类别对比度。我们的方法通过在各种设置下的 CIFAR10-LT、CIFAR100-LT、STL10-LT 和 SVHN-LT 数据集上进行综合实验证明了其有效性。例如，BaCon 在 CIFAR10-LT 上超越了基于 FixMatch 的实例级方法 ABC，准确率提高了 1.21%，并且在 CIFAR100-LT 上超越了最先进的特征级方法 CoSSL，准确率提高了 0.63%。当遇到更极端的不平衡程度时，BaCon也表现出比其他方法更好的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2403.12986</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>提高对象检测和分类 AI 模型抵御对抗性补丁攻击的鲁棒性</title>
      <link>https://arxiv.org/abs/2403.12988</link>
      <description><![CDATA[arXiv:2403.12988v1 公告类型：新
摘要：对抗性补丁攻击旨在破坏深度神经网络 (DNN) 的完整性，显着影响专为对象检测和分类任务而设计的人工智能 (AI) 系统。这项工作的主要目的是保护模型免受现实世界中针对对象检测和分类的物理攻击。我们分析攻击技术并提出稳健的防御方法。我们使用利用对象形状、纹理和位置的对抗性补丁攻击，成功地将模型置信度降低了 20% 以上。利用修复预处理技术，我们有效地恢复了原始的置信水平，证明了强大的防御在减轻这些威胁方面的重要性。在对交通标志分类的人工智能模型进行微调后，我们对其进行了基于模拟像素化补丁的物理对抗攻击，导致错误分类。我们的修复防御方法显着增强了模型的弹性，尽管存在对抗性攻击，仍能实现高精度和可靠的定位。这一贡献提高了对象检测和分类网络应对对抗性挑战的弹性和可靠性，为关键应用程序提供了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2403.12988</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度下降训练形态神经网络：一些理论见解</title>
      <link>https://arxiv.org/abs/2403.12975</link>
      <description><![CDATA[arXiv:2403.12975v1 公告类型：新
摘要：形态神经网络或层可以成为促进数学形态学进步的强大工具，无论是在完整格算子的表示等理论方面，还是在图像处理管道的开发方面。然而，当这些架构计数超过几个形态层时，它们就很难训练，至少在使用基于梯度下降的优化算法的流行机器学习框架内是这样。在本文中，我们根据 Bouligand 导数的非光滑优化概念，研究了基于微分的方法和反向传播应用于形态网络的潜力和局限性。我们提供见解和第一理论指导，特别是关于初始化和学习率。]]></description>
      <guid>https://arxiv.org/abs/2403.12975</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>SportsNGEN：持续生成多人体育游戏</title>
      <link>https://arxiv.org/abs/2403.12977</link>
      <description><![CDATA[arXiv:2403.12977v1 公告类型：新
摘要：我们提出了一种基于 Transformer 解码器的模型 SportsNGEN，该模型针对运动员和球跟踪序列进行训练，能够生成逼真且持续的游戏玩法。我们在专业网球跟踪数据的大型数据库上训练和评估 SportsNGEN，并证明通过将生成的模拟与击球分类器以及开始和结束比赛的逻辑相结合，该系统能够模拟整个网球比赛。此外，SportsNGEN 的通用版本可以通过微调包括该球员的比赛数据来针对特定球员进行定制。我们表明，我们的模型经过了良好的校准，可以通过评估反事实或假设选项来为教练和广播公司提供见解。最后，我们显示的定性结果表明同样的方法适用于足球。]]></description>
      <guid>https://arxiv.org/abs/2403.12977</guid>
      <pubDate>Thu, 21 Mar 2024 06:17:00 GMT</pubDate>
    </item>
    </channel>
</rss>