<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>一种用于双阶段 CNN 检测方法中 FP 抑制的 PST 算法</title>
      <link>https://arxiv.org/abs/2406.18553</link>
      <description><![CDATA[arXiv:2406.18553v1 Announce Type: new 
摘要：行人检测是近几十年来计算机视觉领域的一个热点问题，因为它具有广泛的应用前景，而行人检测面临的最大挑战就是在行人检测过程中产生的假阳性（FP）。各种基于卷积神经网络的检测策略的出现大大提高了行人检测的准确率，但仍然没有很好地解决这个问题。本文深入分析了两阶段 CNN 检测方法的检测框架，发现检测结果中出现假阳性是由于其训练策略漏掉了一些错误的提议，从而削弱了后续子网络的分类能力，很难抑制错误的提议。为了解决这个问题，本文提出了一种行人敏感的训练算法，有效地帮助两阶段 CNN 检测方法学会区分行人和非行人样本，并抑制最终检测结果中的假阳性。所提出的训练算法的核心是重新设计两阶段 CNN 检测方法的训练提议生成流程，可以避免一定数量的错误提议误导其训练过程。借助所提算法，MetroNext（一款体积更小但更准确的地铁乘客检测器）的检测精度得到进一步提升，从而进一步降低了地铁乘客检测结果中的误报率。基于各种具有挑战性的基准数据集的实验结果证明了所提算法通过消除误报来提高行人检测精度的可行性。与竞争对手相比，MetroNext-PST 在准确率、参数总数和推理时间方面表现出更好的整体预测性能，因此它可以成为针对移动和边缘设备量身定制的实用行人追踪解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.18553</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>种植：基于多卫星时间序列的人工林识别数据集</title>
      <link>https://arxiv.org/abs/2406.18554</link>
      <description><![CDATA[arXiv:2406.18554v1 公告类型：新
摘要：保护和恢复森林生态系统对于生物多样性保护和碳封存至关重要。全球范围内的森林监测对于确定保护工作的优先次序和评估至关重要。卫星遥感是提供全球覆盖的唯一可行解决方案，但迄今为止，大规模森林监测仅限于单一模式和单一时间点。在本文中，我们提供了一个由五颗公共卫星的数据组成的数据集，用于识别全球的人工林和人工树种。每种卫星模式都包含一个多年时间序列。该数据集名为 \PlantD，包含 64 个树木标签类别（46 个属和 40 个物种）的 200 多万个示例，分布在 41 个国家/地区。发布此数据集是为了促进使用多模式、多尺度、多时间数据源进行森林监测的研究。此外，我们还介绍了初步基线结果并评估了该数据集的模态融合和数据增强方法。]]></description>
      <guid>https://arxiv.org/abs/2406.18554</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>GFFE：用于低延迟实时渲染的 G 缓冲区自由帧外推</title>
      <link>https://arxiv.org/abs/2406.18551</link>
      <description><![CDATA[arXiv:2406.18551v1 公告类型：新
摘要：实时渲染一直包含光线追踪等要求越来越高的效果。然而，以高分辨率和高帧速率渲染此类效果仍然具有挑战性。与 DLSS 3 和 FSR 3 等帧插值方法相比，帧外推方法不会引入额外的延迟，它通过基于先前帧生成未来帧来提高帧速率。然而，由于缺乏去遮挡区域的信息，这是一项更具挑战性的任务，而且由于需要 G 缓冲区作为输入，最近的方法也具有较高的引擎集成成本。我们提出了一种 \emph{G 缓冲区免费} 帧外推 (GFFE)，它具有新颖的启发式框架和高效的神经网络，可以在不引入额外延迟的情况下实时生成新帧。我们分析了动态片段的运动和不同类型的去遮挡，并设计了相应的外推块模块来处理它们。填充遮挡后，使用轻量级阴影校正网络校正阴影，提升整体质量。GFFE 相比之前的插值以及依赖 G 缓冲区的外推方法，实现了相当或更好的效果，性能更高效，更易于游戏集成。]]></description>
      <guid>https://arxiv.org/abs/2406.18551</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>解码决策推理：基于反事实的知识发现模型</title>
      <link>https://arxiv.org/abs/2406.18552</link>
      <description><![CDATA[arXiv:2406.18552v1 公告类型：新
摘要：在医学成像中，特别是在早期疾病检测和预后任务中，辨别人工智能模型预测背后的原理对于评估其决策的可靠性至关重要。传统的解释方法在识别医学图像分类中可辨别的决定性特征方面面临挑战，因为医学图像分类中的判别特征很微妙或不明显。为了弥补这一差距，我们提出了一个可解释的模型，该模型同时具备决策推理和特征识别能力。我们的方法不仅可以检测有影响力的图像模式，还可以揭示驱动模型最终预测的决定性特征。通过实施我们的方法，我们可以有效地识别和可视化数据驱动模型利用的类特定特征，从而深入了解深度学习模型的决策过程。我们在医学预测任务这一苛刻的领域验证了我们的模型，证明了其在提高医疗保健领域人工智能可靠性以及在预后理解有限的疾病中发现新知识方面的有效性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.18552</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>深度图像合成神经网络中预测不确定性的可视化分析</title>
      <link>https://arxiv.org/abs/2406.18545</link>
      <description><![CDATA[arXiv:2406.18545v1 公告类型：新
摘要：深度神经网络 (DNN) 在不同人工智能系统中的广泛应用，导致近年来它们被用于解决具有挑战性的可视化问题。虽然复杂的 DNN 提供了令人印象深刻的概括，但必须理解与其预测相关的质量、置信度、稳健性和不确定性。彻底了解这些数量会产生可操作的见解，帮助应用科学家做出明智的决策。不幸的是，DNN 的内在设计原理不能产生预测不确定性，因此需要为不同的可视化应用单独制定稳健的不确定性感知模型。为此，本文展示了如何使用各种方法有效地估计 DNN 的预测不确定性和敏感性，然后针对深度图像合成任务进行交互式比较和对比。我们的检查表明，不确定性感知的深度可视化模型可以生成信息丰富、质量上乘且多样化的插图。此外，预测不确定性提高了深度可视化模型的鲁棒性和可解释性，使其对于依赖视觉分析的各个科学领域来说实用且方便。]]></description>
      <guid>https://arxiv.org/abs/2406.18545</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>多模态融合深度学习模型在疾病识别中的应用</title>
      <link>https://arxiv.org/abs/2406.18546</link>
      <description><![CDATA[arXiv:2406.18546v1 公告类型：新
摘要：本文介绍了一种创新的多模态融合深度学习方法，以克服传统单模态识别技术的缺点。这些缺点包括信息不完整和诊断准确性有限。在特征提取阶段，应用包括卷积神经网络 (CNN)、循环神经网络 (RNN) 和 transformers 在内的尖端深度学习模型从基于图像、时间和结构化的数据源中提取高级特征。融合策略组件旨在确定针对特定疾病识别任务的最佳融合模式。在实验部分，对所提出的多模态融合模型和现有的单模识别方法的性能进行了比较。研究结果表明，多模态融合模型在多个评估指标上都具有显著优势。]]></description>
      <guid>https://arxiv.org/abs/2406.18546</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>预训练视觉语言模型作为部分注释器</title>
      <link>https://arxiv.org/abs/2406.18550</link>
      <description><![CDATA[arXiv:2406.18550v1 Announce Type: new 
摘要：预训练的视觉语言模型通过学习海量数据来建模图像和自然语言的统一表示，可以广泛应用于下游的机器学习任务。除了零样本推理之外，为了使预训练模型更好地适应下游任务的要求，人们通常使用少样本或参数高效的微调、知识蒸馏等方法。然而，对样本进行标注非常耗时，而大量未标注样本却很容易获得。本文研究了一种新的“预训练标注-弱监督学习”范式，用于预训练模型的应用，并在图像分类任务上进行了实验。具体来说，基于CLIP，我们用多个提示模板对图像样本进行标注，得到多个候选标签，形成嘈杂的部分标签数据集，并设计了一种协同一致性正则化算法来解决这个问题。我们的方法同时训练两个神经网络，它们相互协同净化训练标签并获取用于自我训练的伪标签，同时采用原型相似性对齐和有噪声的监督对比学习来优化模型表示。在实验中，我们的方法在不引入额外标签信息的情况下实现了远超零样本推理的性能，并且优于其他弱监督学习和少样本微调方法，并获得更小的部署模型。我们的代码可在以下网址获取：\url{https://anonymous.4open.science/r/Co-Reg-8CF9}。]]></description>
      <guid>https://arxiv.org/abs/2406.18550</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>基于集合的三维CAD模型特征提取方法</title>
      <link>https://arxiv.org/abs/2406.18543</link>
      <description><![CDATA[arXiv:2406.18543v1 公告类型：新
摘要：特征提取是实现产品生命周期内特征信息自动传输的关键技术。由于 CAD 模型主要捕获产品的 3D 几何形状，因此特征提取严重依赖于几何信息。然而，现有的特征提取方法由于对几何信息的解释不同，往往会产生不准确的结果。本报告提出了一种基于集合的特征提取方法来解决这一不确定性问题。与寻求准确特征结果的现有方法不同，我们的方法旨在将几何信息的不确定性转换为一组特征子图。首先，我们定义基本几何实体的凸性并引入两级属性邻接图的概念。其次，设计特征提取工作流程以确定特征边界并从 CAD 模型中识别特征子图。这组特征子图可用于进一步的特征识别。使用 C++ 和 UG/Open 编写了一个特征提取系统，以证明我们提出的方法的可行性。]]></description>
      <guid>https://arxiv.org/abs/2406.18543</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:33 GMT</pubDate>
    </item>
    <item>
      <title>GS-ROR：通过 SDF Priors 实现反射物体重新照明的 3D 高斯溅射</title>
      <link>https://arxiv.org/abs/2406.18544</link>
      <description><![CDATA[arXiv:2406.18544v1 公告类型：新
摘要：3D 高斯溅射 (3DGS) 因其细致的表达能力和高效的渲染速度而显示出强大的新视图合成能力。不幸的是，使用 3DGS 创建可重新点亮的 3D 资源仍然存在问题，尤其是对于反射对象，因为它的不连续表示增加了约束几何的困难。受先前研究的启发，有符号距离场 (SDF) 可以作为几何正则化的有效方法。然而，高斯和 SDF 之间的直接结合会显著减慢训练速度。为此，我们提出了 GS-ROR，用于在 SDF 先验的帮助下使用 3DGS 重新点亮反射对象。我们方法的核心是延迟高斯和 SDF 之间深度和法线的相互监督，从而避免了 SDF 昂贵的体积渲染。由于这种相互监督，学习到的延迟高斯函数受到很好的约束，并且时间成本极低。由于高斯函数是在延迟着色模式下渲染的，而 alpha 混合高斯函数是平滑的，因此单个高斯函数可能仍然是异常值，从而产生浮动伪影。因此，我们进一步引入了 SDF 感知修剪策略来去除远离 SDF 定义的表面的高斯异常值，从而避免浮动问题。因此，我们的方法在重新照明质量方面优于现有的基于高斯的逆渲染方法。与基于 NeRF 的方法相比，我们的方法还表现出具有竞争力的重新照明质量，最多只需 25% 的训练时间，并且允许在 RTX4090 上以每秒 200 帧以上的速度渲染。]]></description>
      <guid>https://arxiv.org/abs/2406.18544</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:33 GMT</pubDate>
    </item>
    <item>
      <title>通过样本选择完善 3D 点云法线估计</title>
      <link>https://arxiv.org/abs/2406.18541</link>
      <description><![CDATA[arXiv:2406.18541v1 公告类型：new 
摘要：近年来，点云法线估计作为一种经典的基础算法，在三维几何处理领域引起了广泛的关注。尽管目前基于神经网络的方法取得了显著的效果，但其鲁棒性仍然受到训练数据质量和模型性能的影响。在本研究中，我们设计了一个法线估计的基本框架，通过结合全局信息和各种约束机制来增强现有模型。此外，我们采用了基于置信度的策略来选择合理的样本进行公平和稳健的网络训练。引入的样本置信度可以集成到损失函数中，以平衡不同样本对模型训练的影响。最后，我们利用现有的定向方法来校正估计的非定向法线，在定向和非定向任务中都取得了最先进的性能。大量的实验结果表明，我们的方法在广泛使用的基准上效果很好。]]></description>
      <guid>https://arxiv.org/abs/2406.18541</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:32 GMT</pubDate>
    </item>
    <item>
      <title>利用多模态变换器生成人工智能驱动的 LiDAR 点云生成</title>
      <link>https://arxiv.org/abs/2406.18542</link>
      <description><![CDATA[arXiv:2406.18542v1 公告类型：新
摘要：集成传感和通信是 6G 无线通信系统的关键推动因素。多种传感模式将使基站能够更准确地表示环境，从而实现情境感知通信。一些广泛配备的传感器（如摄像头和雷达传感器）可以提供一些环境感知。然而，它们不足以生成精确的环境表征，尤其是在恶劣的天气条件下。另一方面，激光雷达传感器提供了更准确的表征，然而，它们的高成本阻碍了它们的广泛采用。本文提出了一种通过从图像和雷达数据中合成激光雷达点云来增强无线通信系统的新方法。具体来说，它使用多模态变换器架构和预训练编码模型来实现精确的激光雷达生成。所提出的框架在 DeepSense 6G 数据集上进行了评估，这是一个为情境感知无线应用策划的真实世界数据集。我们的结果证明了所提出的方法在准确生成激光雷达点云方面的有效性。我们实现了 10.3931 的修正均方误差。对图像的目视检查表明，我们的模型可以成功捕捉不同环境下 LiDAR 点云中存在的大多数结构。这将使基站能够实现更精确的环境感知。通过将 LiDAR 合成与现有的传感模式相结合，我们的方法可以增强各种无线应用的性能，包括光束和阻塞预测。]]></description>
      <guid>https://arxiv.org/abs/2406.18542</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:32 GMT</pubDate>
    </item>
    <item>
      <title>TexPainter：具有多视图一致性的生成网格纹理</title>
      <link>https://arxiv.org/abs/2406.18539</link>
      <description><![CDATA[arXiv:2406.18539v1 公告类型：新
摘要：预训练扩散模型的最新成功开启了在野外自动生成任意 3D 网格纹理的可能性。然而，这些模型是在屏幕空间中训练的，而将它们转换为多视图一致的纹理图像对输出质量构成了重大障碍。在本文中，我们提出了一种强制多视图一致性的新方法。我们的方法基于这样的观察：预训练扩散模型中的潜在空间对于每个摄像机视图都是单独加噪的，因此很难通过直接操纵潜在代码来实现多视图一致性。基于著名的去噪扩散隐式模型 (DDIM) 方案，我们建议使用基于优化的颜色融合来强制一致性并通过梯度反向传播间接修改潜在代码。我们的方法进一步放宽了摄像机视图之间的顺序依赖性假设。通过对一系列通用 3D 模型进行评估，我们发现，与同类竞争产品相比，我们的简单方法提高了生成纹理的一致性和整体质量。我们的实现可从以下网址获取：https://github.com/Quantuman134/TexPainter]]></description>
      <guid>https://arxiv.org/abs/2406.18539</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:31 GMT</pubDate>
    </item>
    <item>
      <title>充分利用每一个真实样本：超像素样本梯度模型窃取</title>
      <link>https://arxiv.org/abs/2406.18540</link>
      <description><![CDATA[arXiv:2406.18540v1 公告类型：新
摘要：模型窃取（MS）涉及查询和观察机器学习模型的输出以窃取其功能。查询数据的质量至关重要，但获取大量真实数据进行 MS 通常具有挑战性。最近的研究通过使用生成模型减少了对真实数据的依赖。然而，当需要高维查询数据时，这些方法由于查询成本高和模型崩溃的风险而不切实际。在这项工作中，我们提出使用样本梯度（SG）来增强每个真实样本的效用，因为 SG 为受害者模型的决策边界提供了关键指导。然而，在模型窃取场景中使用 SG 面临两个挑战：1. 像素级梯度估计需要大量查询量并且容易受到防御。2. 样本梯度的估计具有显着的方差。本文提出了在有限真实样本约束下的模型窃取的超像素样本梯度窃取（SPSG）。 SPSG 的基本思想是模仿受害者模型的低方差块级梯度而不是像素级梯度，通过两个步骤实现高效的样本梯度估计。首先，我们对查询图像执行块级扰动，以估计图像不同区域的平均梯度。然后，我们通过阈值策略过滤梯度以降低方差。详尽的实验表明，在相同数量的真实样本的情况下，SPSG 的准确率、一致性和对抗成功率显著超越了目前最先进的 MS 方法。代码可在 https://github.com/zyl123456aB/SPSG_attack 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.18540</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:31 GMT</pubDate>
    </item>
    <item>
      <title>AddBiomechanics 数据集：大规模捕捉人体运动的物理特性</title>
      <link>https://arxiv.org/abs/2406.18537</link>
      <description><![CDATA[arXiv:2406.18537v1 公告类型：新
摘要：虽然近年来利用廉价传感器重建 3D 人体姿势取得了长足进步，但量化人体运动的动态（包括肌肉产生的关节扭矩和外力）仍然是一项挑战。之前尝试从重建的人体姿势估计物理特性，但由于缺乏针对各种运动的高质量姿势和力数据，因此受到了阻碍。我们提出了 AddBiomechanics 数据集 1.0，其中包括 273 名人类受试者的物理精确人体动态、超过 70 小时的运动和力板数据，总计超过 2400 万帧。为了构建这个数据集，需要新的分析方法，本文也对此进行了报告。我们提出了使用该数据集从运动中估计人体动态的基准，并提出了几个基线结果。AddBiomechanics 数据集可在 https://addbiomechanics.org/download_data.html 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2406.18537</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:30 GMT</pubDate>
    </item>
    <item>
      <title>VideoQA-SC：用于视频问答的自适应语义通信</title>
      <link>https://arxiv.org/abs/2406.18538</link>
      <description><![CDATA[arXiv:2406.18538v1 公告类型：新
摘要：尽管语义通信 (SC) 已显示出在高效传输文本、语音和图像等多模态数据方面的潜力，但视频的 SC 主要集中在像素级重建上。然而，这些 SC 系统可能不是下游智能任务的最佳选择。此外，没有像素级视频重建的 SC 系统通过实现更高的带宽效率和各种智能任务的实时性能而具有优势。这种系统设计的难点在于提取与任务相关的紧凑语义表示及其在嘈杂信道上的准确传递。在本文中，我们提出了一种用于视频问答 (VideoQA) 任务的端到端 SC 系统，称为 VideoQA-SC。我们的目标是直接基于嘈杂或衰落的无线信道上的视频语义完成 VideoQA 任务，从而无需在接收器处进行视频重建。为此，我们开发了一种时空语义编码器，用于有效提取视频语义，以及一种基于学习的带宽自适应深度联合源信道编码 (DJSCC) 方案，用于高效且稳健的视频语义传输。实验表明，在各种信道条件和带宽限制下，VideoQA-SC 优于传统和先进的基于 DJSCC 的 SC 系统，后者依赖于接收器的视频重建。特别是，当信噪比较低时，与先进的基于 DJSCC 的 SC 系统相比，VideoQA-SC 可以将答案准确率提高 5.17%，同时节省近 99.5% 的带宽。我们的结果表明，面向任务的 SC 系统设计在视频应用中具有巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.18538</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:30 GMT</pubDate>
    </item>
    </channel>
</rss>