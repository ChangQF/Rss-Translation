<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 08 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>统一端到端V2X协同自动驾驶</title>
      <link>https://arxiv.org/abs/2405.03971</link>
      <description><![CDATA[arXiv:2405.03971v1 公告类型：新
摘要：V2X 合作通过集成来自车辆和基础设施的传感器数据，被认为是推进自动驾驶技术的关键方法。目前的研究主要集中在增强感知准确性上，往往忽视了通过端到端学习对事故预测准确性的系统性提升，导致对自动驾驶安全问题的重视不够。为了应对这一挑战，本文介绍了UniE2EV2X框架，这是一种V2X集成的端到端自动驾驶系统，将关键驾驶模块整合在统一网络中。该框架采用可变形的基于注意力的数据融合策略，有效促进车辆和基础设施之间的合作。主要优点包括：1）显着增强智能体的感知和运动预测能力，从而提高事故预测的准确性； 2）保证数据融合过程的高可靠性； 3）与模块化方法相比，具有卓越的端到端感知。此外，我们在具有挑战性的 DeepAccident（一个专为 V2X 协同驾驶而设计的模拟数据集）上实现了 UniE2EV2X 框架。]]></description>
      <guid>https://arxiv.org/abs/2405.03971</guid>
      <pubDate>Wed, 08 May 2024 09:14:14 GMT</pubDate>
    </item>
    <item>
      <title>IPFed：用于用户身份验证的身份保护联合学习</title>
      <link>https://arxiv.org/abs/2405.03955</link>
      <description><![CDATA[arXiv:2405.03955v1 公告类型：新
摘要：随着隐私保护相关法律法规的发展，收集个人数据进行机器学习变得越来越困难。在此背景下，联邦学习（即不共享个人数据的分布式学习）被提出。在本文中，我们重点关注用户身份验证的联邦学习。我们表明，现有方法很难同时实现隐私保护和高精度。为了应对这些挑战，我们提出了 IPFed，它是使用随机投影进行类嵌入的隐私保护联邦学习。此外，我们证明 IPFed 能够进行与最先进方法相当的学习。在人脸图像数据集上的实验表明，IPFed 可以保护个人数据的隐私，同时保持最先进方法的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.03955</guid>
      <pubDate>Wed, 08 May 2024 09:14:13 GMT</pubDate>
    </item>
    <item>
      <title>在注意力层上进行简单的 LoRA 调节将改善您的扩散模型</title>
      <link>https://arxiv.org/abs/2405.03958</link>
      <description><![CDATA[arXiv:2405.03958v1 公告类型：新
摘要：当前最先进的扩散模型采用包含卷积层和 (qkv) 自注意力层的 U-Net 架构。 U-Net 处理图像，同时以每个采样步骤的时间嵌入输入以及与所需条件生成相对应的类或标题嵌入输入为条件。这种调节涉及对卷积层的缩放和移位操作，但不会直接影响注意力层。虽然这些标准的架构选择肯定是有效的，但不调节注意力层会让人感觉任意且可能不是最理想的。在这项工作中，我们表明，只需将 LoRA 调节添加到注意力层而不更改或调整 U-Net 架构的其他部分，就可以提高图像生成质量。例如，在 EDM 扩散模型中添加 LoRA 调节，无条件和类别条件 CIFAR-10 生成的 FID 分数为 1.91/1.75，比 1.97/1.79 的基线有所提高。]]></description>
      <guid>https://arxiv.org/abs/2405.03958</guid>
      <pubDate>Wed, 08 May 2024 09:14:13 GMT</pubDate>
    </item>
    <item>
      <title>部分指纹身份验证与相对位姿联合估计</title>
      <link>https://arxiv.org/abs/2405.03959</link>
      <description><![CDATA[arXiv:2405.03959v1 公告类型：新
【摘要】：当前,便携式电子设备越来越普及。出于轻量化的考虑，他们的指纹识别模块通常使用尺寸有限的传感器。然而，部分指纹几乎没有可匹配的特征，特别是当手指按压姿势或图像质量存在差异时，这使得部分指纹验证具有挑战性。大多数现有方法将指纹位置校正和身份验证视为独立的任务，忽略了它们之间的耦合关系——相对姿势估计通常依赖于成对特征作为锚点，并且认证精度往往会随着更精确的姿势对齐而提高。因此，在本文中，我们提出了一种联合估计部分指纹的身份验证和相对姿势的方法，旨在利用它们固有的相关性来相互改进。为此，我们提出了一种多任务CNN（卷积神经网络）-Transformer混合网络，并设计了预训练任务来增强特征提取能力。在多个公共数据集（NIST SD14、FVC2002 DB1A &amp; DB3A、FVC2004 DB1A &amp; DB2A、FVC2006 DB1A）和内部数据集上的实验表明，我们的方法在部分指纹验证和相对姿态估计方面均实现了最先进的性能，同时比以前的方法更有效。]]></description>
      <guid>https://arxiv.org/abs/2405.03959</guid>
      <pubDate>Wed, 08 May 2024 09:14:13 GMT</pubDate>
    </item>
    <item>
      <title>MVDiff：可扩展且灵活的多视图扩散，用于从单视图重建 3D 对象</title>
      <link>https://arxiv.org/abs/2405.03894</link>
      <description><![CDATA[arXiv:2405.03894v1 公告类型：新
摘要：为 3D 重建任务生成一致的多个视图仍然是现有图像到 3D 扩散模型的挑战。一般来说，将 3D 表示合并到扩散模型中会降低模型的速度以及通用性和质量。本文提出了一个通用框架，可以从单个图像生成一致的多视图图像，或者利用场景表示转换器和视图条件扩散模型。在模型中，我们引入对极几何约束和多视图注意力来增强 3D 一致性。只需一张图像输入，我们的模型就能够生成在评估指标（包括 PSNR、SSIM 和 LPIPS）方面超越基线方法的 3D 网格。]]></description>
      <guid>https://arxiv.org/abs/2405.03894</guid>
      <pubDate>Wed, 08 May 2024 09:14:12 GMT</pubDate>
    </item>
    <item>
      <title>传感和计算机视觉在 6G 无线通信中的作用</title>
      <link>https://arxiv.org/abs/2405.03945</link>
      <description><![CDATA[arXiv:2405.03945v1 公告类型：新
摘要：最近，我们目睹了传感技术在自动驾驶、机器人和元宇宙领域的显着进展和广泛采用。考虑到用于分析传感信息的计算机视觉 (CV) 技术的快速发展，我们预计 6G 中利用传感和 CV 技术的无线应用将会激增。在本文中，我们全面概述了 6G 的传感和 CV 辅助无线通信 (SVWC) 框架。通过强大的CV技术分析高分辨率传感信息，SVWC可以快速准确地了解无线环境，然后执行无线任务。为了证明 SVWC 的功效，我们设计了 SVWC 的整个流程，包括传感数据集收集、DL 模型训练和实际无线任务的执行。通过对6G通信场景的数值评估，我们发现SVWC在定位精度、数据速率和访问延迟方面比传统5G系统取得了可观的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2405.03945</guid>
      <pubDate>Wed, 08 May 2024 09:14:12 GMT</pubDate>
    </item>
    <item>
      <title>Trio-ViT：无 Softmax 的高效视觉变压器的训练后量化和加速</title>
      <link>https://arxiv.org/abs/2405.03882</link>
      <description><![CDATA[arXiv:2405.03882v1 公告类型：新
摘要：受 Transformers 在自然语言处理 (NLP) 领域巨大成功的推动，Vision Transformers (ViT) 得到了迅速发展并在各种计算机视觉任务中取得了显著的表现。然而，其庞大的模型大小和密集的计算阻碍了 ViT 在嵌入式设备上的部署，需要有效的模型压缩方法，例如量化。不幸的是，由于存在对硬件不友好且对量化敏感的非线性操作，特别是 {Softmax}，完全量化 ViT 中的所有操作并非易事，这会导致准确率大幅下降或硬件成本不可忽略。为了应对与 \textit{标准 ViT} 相关的挑战，我们将注意力集中在 \textit{高效 ViT} 的量化和加速上，这不仅可以消除麻烦的 Softmax，还可以集成具有低计算复杂度的线性注意力，并据此提出 \emph{Trio-ViT}。具体而言，在算法层面，我们开发了一种{定制的训练后量化引擎}，充分考虑了无 Softmax 高效 ViT 的独特激活分布，旨在提高量化精度。此外，在硬件层面，我们构建了一个专用于高效 ViT 特定卷积-Transformer 混合架构的加速器，从而提高了硬件效率。大量实验结果一致证明了我们的 Trio-ViT 框架的有效性。{特别是，我们可以在与最先进的 ViT 加速器相当的精度下获得高达 $\uparrow$$\mathbf{7.2}\times$ 和 $\uparrow$$\mathbf{14.6}\times$ FPS，以及 $\uparrow$$\mathbf{5.9}\times$ 和 $\uparrow$$\mathbf{2.0}\times$ DSP 效率。}代码将在接受后公开发布。]]></description>
      <guid>https://arxiv.org/abs/2405.03882</guid>
      <pubDate>Wed, 08 May 2024 09:14:11 GMT</pubDate>
    </item>
    <item>
      <title>BadFusion：针对 3D 对象检测的面向 2D 的后门攻击</title>
      <link>https://arxiv.org/abs/2405.03884</link>
      <description><![CDATA[arXiv:2405.03884v1 公告类型：新
摘要：3D物体检测在自动驾驶中发挥着重要作用；然而，它对后门攻击的脆弱性已经变得显而易见。通过注入“触发器”来毒害训练数据集，后门攻击操纵检测器对包含这些触发器的输入的预测。现有针对 3D 物体检测的后门攻击主要毒害 3D LiDAR 信号，其中注入大尺寸 3D 触发器以确保其在稀疏 3D 空间中的可见性，使其易于检测且在现实场景中不切实际。
  在本文中，我们深入研究了 3D 对象检测的鲁棒性，通过 2D 摄像头探索新的后门攻击面。鉴于普遍采用相机和 LiDAR 信号融合来实现高保真 3D 感知，我们研究了相机信号破坏该过程的潜在潜力。尽管相机信号的密集性使得可以使用几乎难以察觉的小尺寸触发器来误导 2D 对象检测，但实现针对 3D 对象检测的面向 2D 的后门攻击并非易事。主要挑战来自将相机信号转换为 3D 空间的融合过程，从而损害了 2D 触发器与目标输出的关联。为了解决这个问题，我们提出了一种针对用于 3D 对象检测的 LiDAR 相机融合方法的创新型 2D 后门攻击，称为 BadFusion，以在整个融合过程中保持触发有效性。评估证明了 BadFusion 的有效性，与现有的面向 2D 的攻击相比，攻击成功率显着提高。]]></description>
      <guid>https://arxiv.org/abs/2405.03884</guid>
      <pubDate>Wed, 08 May 2024 09:14:11 GMT</pubDate>
    </item>
    <item>
      <title>通过跨模式嵌入增强表观人格特质分析</title>
      <link>https://arxiv.org/abs/2405.03846</link>
      <description><![CDATA[arXiv:2405.03846v1 公告类型：新
摘要：自动人格特质评估对于高质量的人机交互至关重要。能够分析人类行为的系统可用于自动驾驶汽车、医学研究和监视等。我们提出了一种多模态深度神经网络，具有连体扩展，用于在短视频记录上进行训练并利用模态不变嵌入进行明显的人格特质预测。在此任务中，利用声音、视觉和文本信息来获得高性能解决方案。由于分析数据集的目标分布高度集中，因此第三位数字的变化是相关的。我们提出的方法解决了极值代表性不足的挑战，实现了 0.0033 MAE 平均改进，并且比没有引入模块的基线多模态 DNN 显示出明显的优势。]]></description>
      <guid>https://arxiv.org/abs/2405.03846</guid>
      <pubDate>Wed, 08 May 2024 09:14:10 GMT</pubDate>
    </item>
    <item>
      <title>VSA4VQA：将矢量符号架构扩展到自然图像的视觉问答</title>
      <link>https://arxiv.org/abs/2405.03852</link>
      <description><![CDATA[arXiv:2405.03852v1 公告类型：新
摘要：虽然矢量符号架构（VSA）在空间认知建模方面很有前景，但其应用目前仅限于人工生成的图像和简单的空间查询。我们提出了 VSA4VQA - VSA 的一种新颖的 4D 实现，它为视觉问答 (VQA) 的挑战性任务实现了自然图像的心理表征。 VSA4VQA 是第一个将 VSA 扩展到复杂空间查询的模型。我们的方法基于语义指针架构（SPA）来对超维向量空间中的对象进行编码。为了对自然图像进行编码，我们扩展了 SPA，除了对象的空间位置之外还包括对象的宽度和高度的尺寸。为了执行空间查询，我们进一步引入学习的空间查询掩码，并集成预先训练的视觉语言模型来回答与属性相关的问题。我们在 GQA 基准数据集上评估我们的方法，并表明它可以有效地编码自然图像，实现与最先进的零样本 VQA 深度学习方法相比的竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2405.03852</guid>
      <pubDate>Wed, 08 May 2024 09:14:10 GMT</pubDate>
    </item>
    <item>
      <title>视频理解的基础模型：调查</title>
      <link>https://arxiv.org/abs/2405.03770</link>
      <description><![CDATA[arXiv:2405.03770v1 公告类型：新
摘要：视频基础模型（ViFM）旨在学习各种视频理解任务的通用表示。 ViFM 利用大规模数据集和强大的模型，通过从视频数据中捕获强大且通用的特征来实现这一目标。这项调查分析了 200 多个视频基础模型，全面概述了分为 3 个主要类别的 14 个不同视频任务的基准和评估指标。此外，我们还针对 6 种最常见的视频任务对这些模型进行了深入的性能分析。我们将 ViFM 分为三类：1）基于图像的 ViFM，它针对视频任务调整现有图像模型；2）基于视频的 ViFM，它利用视频特定的编码方法；3）通用基础模型（UFM），它结合了单一框架内的多种模式（图像、视频、音频和文本等）。通过比较各种 ViFM 在不同任务上的表现，这项调查提供了有关其优缺点的宝贵见解，指导视频理解的未来进步。我们的分析令人惊讶地表明，在大多数视频理解任务中，基于图像的基础模型始终优于基于视频的模型。此外，利用多种模式的 UFM 在视频任务上表现出卓越的性能。我们在以下位置分享了这项工作中研究的 ViFM 的完整列表：\url{https://github.com/NeeluMadan/ViFM_Survey.git}]]></description>
      <guid>https://arxiv.org/abs/2405.03770</guid>
      <pubDate>Wed, 08 May 2024 09:14:09 GMT</pubDate>
    </item>
    <item>
      <title>MoDiPO：通过人工智能反馈驱动的直接偏好优化实现文本到动作对齐</title>
      <link>https://arxiv.org/abs/2405.03803</link>
      <description><![CDATA[arXiv:2405.03803v1 公告类型：新
摘要：扩散模型通过自然语言条件提供卓越的生成质量和细粒度的可控性，彻底改变了人类运动生成领域。它们固有的随机性，即从单个输入生成各种输出的能力，是它们成功的关键。然而，这种多样性不应不受限制，因为它可能会导致不可能的世代。相反，它应该被限制在文本对齐和现实生成的范围内。为了解决这个问题，我们提出了 MoDiPO（运动扩散 DPO），这是一种利用直接偏好优化（DPO）来对齐文本到运动模型的新颖方法。我们通过利用人工智能反馈来简化 DPO 所需的收集人类偏好的费力且昂贵的过程。这使我们能够使用在线和离线生成的运动偏好对来尝试新颖的 DPO 策略。为了促进未来的研究，我们贡献了一个运动偏好数据集，我们称之为“Pick-a-Move”。我们从定性和定量两个方面证明，我们提出的方法可以产生更加真实的运动。特别是，MoDiPO 显着改善了 Frechet 起始距离 (FID)，同时保留了相同的 RPrecision 和多模态性能。]]></description>
      <guid>https://arxiv.org/abs/2405.03803</guid>
      <pubDate>Wed, 08 May 2024 09:14:09 GMT</pubDate>
    </item>
    <item>
      <title>基于串联的 CNN 架构的迭代滤波器修剪</title>
      <link>https://arxiv.org/abs/2405.03715</link>
      <description><![CDATA[arXiv:2405.03715v1 公告类型：新
摘要：模型压缩和硬件加速对于深度神经网络的资源高效部署至关重要。现代物体检测器具有高度互连的卷积层和级联。在这项工作中，我们研究了如何将剪枝应用于此类架构，以 YOLOv7 为例。我们提出了一种基于卷积层的连接图来处理串联层的方法。通过自动化迭代敏感性分析、修剪和后续模型微调，我们可以在参数数量和 FLOP 方面显着减小模型大小，同时保持可比的模型精度。最后，我们将修剪后的模型部署到 FPGA 和 NVIDIA Jetson Xavier AGX。与未修剪的模型相比，修剪后的模型的卷积层速度提高了 2 倍，并且在 FPGA 上达到了 14 FPS 的实时能力。我们的代码可在 https://github.com/fzi-forschungszentrum-informatik/iterative-yolo-pruning 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.03715</guid>
      <pubDate>Wed, 08 May 2024 09:14:08 GMT</pubDate>
    </item>
    <item>
      <title>用于少镜头图像分类的类相关补丁嵌入选择</title>
      <link>https://arxiv.org/abs/2405.03722</link>
      <description><![CDATA[arXiv:2405.03722v1 公告类型：新
摘要：有效的图像分类取决于从前景和背景元素中辨别相关特征，其中前景通常包含关键信息。虽然人类能够熟练地对曝光有限的图像进行分类，但人工神经网络常常难以从稀有样本中进行特征选择。为了应对这一挑战，我们提出了一种选择与类相关的补丁嵌入的新方法。我们的方法包括将支持图像和查询图像分割成补丁，使用预先训练的视觉变换器（ViT）对它们进行编码，以分别获得类嵌入和补丁嵌入。随后，我们使用类嵌入来过滤补丁嵌入，以仅保留与类相关的嵌入。对于每张图像，我们计算类嵌入和每个补丁嵌入之间的相似度，按降序对相似度序列进行排序，并且只保留排名靠前的补丁嵌入。通过优先考虑类嵌入和补丁嵌入之间的相似性，我们选择排名靠前的补丁嵌入与类嵌入融合以形成全面的图像表示，从而增强跨实例的模式识别。我们的策略有效地减轻了与类无关的补丁嵌入的影响，从而提高了预训练模型的性能。对流行的少样本分类基准进行的大量实验证明了我们的方法的简单性、有效性和计算效率，在 5 样本和 1 样本场景下均优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2405.03722</guid>
      <pubDate>Wed, 08 May 2024 09:14:08 GMT</pubDate>
    </item>
    <item>
      <title>Leafy Spurge 数据集：航空无人机图像中的真实杂草分类</title>
      <link>https://arxiv.org/abs/2405.03702</link>
      <description><![CDATA[arXiv:2405.03702v1 公告类型：新
摘要：入侵植物物种对农业和荒地地区的生态环境有害。大戟属植物（Euphorbia esula）是一种从东欧传播到北美大部分地区的植物。当与当代计算机视觉系统、无人驾驶飞行器或无人机结合使用时，可以跟踪问题植物（如大戟属植物）的扩张，并提高控制这些杂草的机会。我们收集了美国蒙大拿州西部草原大戟属植物存在和不存在的数据集，然后用商用无人机对这些地区进行了勘测。我们根据这些数据训练了图像分类器，我们表现最好的模型，即预先训练的 DINOv2 视觉转换器，以 0.84 的准确率（测试集）识别了大戟属植物。这个结果表明，大戟属植物的分类是可处理的，但尚未解决。我们发布了这个独特的标记和未标记的无人机航拍图像数据集，供机器学习社区探索。提高大戟科植物的分类性能将使生态学、保护和遥感等领域受益。代码和数据可在我们的网站上找到：leafy-spurge-dataset.github.io。]]></description>
      <guid>https://arxiv.org/abs/2405.03702</guid>
      <pubDate>Wed, 08 May 2024 09:14:07 GMT</pubDate>
    </item>
    </channel>
</rss>