<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 17 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于共享特征可视化的并行反向传播</title>
      <link>https://arxiv.org/abs/2405.09827</link>
      <description><![CDATA[arXiv:2405.09827v1 公告类型：新
摘要：高级视觉大脑区域包含一些子区域，在这些子区域中，神经元似乎对特定语义类别（如面部或身体）的示例反应比对物体的反应更强烈。然而，最近的研究表明，虽然这一发现平均而言成立，但一些类别外的刺激也会激活这些区域中的神经元。这可能是由于首选类别中常见的视觉特征也存在于其他图像中。在这里，我们提出了一种基于深度学习的方法来可视化这些特征。对于每个神经元，我们通过基于深度神经网络的潜在激活对图像的响应进行建模来识别驱动其选择性的相关视觉特征。给定一个强烈激活神经元的类别外图像，我们的方法首先从首选类别中识别一个参考图像，从而产生类似的特征激活模式。然后，我们将两幅图像的潜在激活反向传播到像素级，同时增强已识别的共享维度并减弱非共享特征。该程序突出显示了包含驱动模型神经元响应的共同特征的图像区域。我们将该算法应用于猕猴 IT 皮层中身体选择性区域的新记录，以了解为什么某些物体图像会激发这些神经元。可视化显示与猕猴身体部分相似的物体部分，揭示了这些物体的神经偏好。]]></description>
      <guid>https://arxiv.org/abs/2405.09827</guid>
      <pubDate>Fri, 17 May 2024 06:19:22 GMT</pubDate>
    </item>
    <item>
      <title>PillarNeXt：通过引入Voxel2Pillar特征编码和提取多尺度特征来改进3D检测器</title>
      <link>https://arxiv.org/abs/2405.09828</link>
      <description><![CDATA[arXiv:2405.09828v1 公告类型：新
摘要：多线激光雷达在自动驾驶汽车中得到广泛应用，因此基于点云的3D检测器对于自动驾驶至关重要。由于不同类型的物体尺寸差异很大，提取丰富的多尺度特征对于自动驾驶中基于点云的3D检测器至关重要。但由于实时性的要求，大尺寸卷积核很少用于在骨干中提取大规模特征。目前的3D检测器通常使用特征金字塔网络来获取大规模特征；然而，一些包含较少点云的物体在下采样过程中会进一步丢失，导致性能下降。由于基于支柱的方案比基于体素的方案需要的计算量少得多，因此它们更适合构建实时3D检测器。因此，我们提出了一种基于支柱的方案PillarNeXt。我们重新设计了3D检测器的特征编码、骨干和颈部。我们提出了 Voxel2Pillar 特征编码，它使用稀疏卷积构造函数来构建具有更丰富点云特征（尤其是高度特征）的支柱。此外，还添加了额外的可学习参数，这使初始支柱能够实现更高的性能。我们在提出的完全稀疏主干中提取多尺度和大规模特征，它不使用大尺寸卷积核；主干由提出的多尺度特征提取模块组成。颈部由提出的稀疏 ConvNeXt 组成，其简单的结构显着提高了性能。在 Waymo Open Dataset 上验证了所提出的 PillarNeXt 的有效性，并且提高了车辆、行人和骑自行车的人的物体检测精度；我们还详细验证了每个提出的模块的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.09828</guid>
      <pubDate>Fri, 17 May 2024 06:19:22 GMT</pubDate>
    </item>
    <item>
      <title>LeMeViT：具有可学习元令牌的高效视觉转换器，用于遥感图像解释</title>
      <link>https://arxiv.org/abs/2405.09789</link>
      <description><![CDATA[arXiv:2405.09789v1 公告类型：新
摘要：由于遥感图像中存在空间冗余，包含丰富信息的稀疏标记通常会参与自注意力（SA），以减少计算中的总体标记数量，避免 Vision Transformers 中高计算成本的问题。然而，此类方法通常通过手工制作或并行不友好的设计来获得稀疏令牌，这对在效率和性能之间达到更好的平衡提出了挑战。与它们不同的是，本文提出使用可学习的元标记来制定稀疏标记，可以有效地学习关键信息，同时提高推理速度。从技术上讲，元标记首先通过交叉注意力从图像标记初始化。然后，我们提出双重交叉注意（DCA）来促进图像令牌和元令牌之间的信息交换，其中它们在双分支结构中交替充当查询和键（值）令牌，与自学习相比，显着降低了计算复杂度。注意力。通过在早期阶段使用具有密集视觉标记的 DCA，我们获得了各种大小的分层架构 LeMeViT。在分类和密集预测任务中的实验结果表明，与基线模型相比，LeMeViT 具有显着的 1.7 倍加速比、更少的参数和具有竞争力的性能，并在效率和性能之间实现了更好的权衡。]]></description>
      <guid>https://arxiv.org/abs/2405.09789</guid>
      <pubDate>Fri, 17 May 2024 06:19:21 GMT</pubDate>
    </item>
    <item>
      <title>MediSyn：用于广泛医学 2D 和 3D 图像合成的文本引导扩散模型</title>
      <link>https://arxiv.org/abs/2405.09806</link>
      <description><![CDATA[arXiv:2405.09806v1 公告类型：新
摘要：扩散模型最近获得了巨大的关注，因为它们能够根据文本提示生成高保真和多样化的图像和视频。在医学领域，该应用程序有望解决数据稀缺的严峻挑战，这是数据共享障碍、严格的患者隐私法规以及患者群体和人口统计差异造成的结果。通过生成真实且变化的医学 2D 和 3D 图像，这些模型为算法训练和研究提供了丰富的、尊重隐私的资源。为此，我们引入了 MediSyn，这是一对经过指令调整的文本引导潜在扩散模型，能够跨专业和模式生成高保真且多样化的医学 2D 和 3D 图像。通过既定的指标，我们在文本提示引导下显示了广泛的医学图像和视频合成的显着改进。]]></description>
      <guid>https://arxiv.org/abs/2405.09806</guid>
      <pubDate>Fri, 17 May 2024 06:19:21 GMT</pubDate>
    </item>
    <item>
      <title>从无监督领域适应的角度重新思考几乎没有监督的分割</title>
      <link>https://arxiv.org/abs/2405.09777</link>
      <description><![CDATA[arXiv:2405.09777v1 公告类型：新
摘要：本文研究了一个极具挑战性的问题，即几乎没有监督的医学图像分割（BSS），其中训练数据集包含有限的标记数据，仅具有单切片注释和大量未标记的图像。目前，最先进的 (SOTA) BSS 方法利用基于配准的范例，根据图像配准将单切片注释传播到体积伪标签中，以构建完整的标记集。然而，这种范例有一个关键的限制：图像配准生成的伪标签不可靠且有噪声。受此启发，我们提出了一个新的视角：仅使用单注释切片作为标记集来训练模型，而不依赖于图像配准。为此，我们将 BSS 表述为无监督域适应（UDA）问题。具体来说，我们首先设计了一种新颖的无噪声标记数据构建算法（NFC），用于切片到体积标记数据合成，这可能会导致副作用：合成图像和原始图像之间的域转移。然后，进一步引入频率和空间混合策略（FSX）来减轻 UDA 的域转移。大量实验表明我们的方法为 BSS 提供了一种有前途的替代方案。值得注意的是，所提出的仅使用一个标记切片的方法在左心房分割上获得了 80.77% 的骰子得分，比 SOTA 好 61.28%。该代码将在本文发表后发布。]]></description>
      <guid>https://arxiv.org/abs/2405.09777</guid>
      <pubDate>Fri, 17 May 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>尺寸不变性很重要：重新思考不平衡多对象显着对象检测的指标和损失</title>
      <link>https://arxiv.org/abs/2405.09782</link>
      <description><![CDATA[arXiv:2405.09782v1 公告类型：新
摘要：本文探讨了显着目标检测（SOD）中评估指标的尺寸不变性，特别是当多个不同尺寸的目标共存于同一图像中时。我们观察到，当前的指标对大小敏感，较大的对象受到关注，而较小的对象往往被忽略。我们认为评估应该是大小不变的，因为如果没有额外的语义信息，基于大小的偏差是不合理的。为了实现这一目标，我们提出了一种通用方法，单独评估每个显着对象，然后组合结果，有效缓解不平衡。我们进一步开发了专门针对此目标的优化框架，在检测不同尺寸的物体方面取得了显着的改进。从理论上讲，我们提供了支持新指标有效性的证据，并提出了 SOD 的泛化分析。大量的实验证明了我们方法的有效性。代码可在 https://github.com/Ferry-Li/SI-SOD 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.09782</guid>
      <pubDate>Fri, 17 May 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>从 NeRF 到高斯 Splats 再到 NeRF</title>
      <link>https://arxiv.org/abs/2405.09717</link>
      <description><![CDATA[arXiv:2405.09717v1 公告类型：新
摘要：对于视图数量有限（通常以自我为中心）的机器人应用，神经辐射场 (NeRF) 等参数表示比高斯泼溅 (GS) 等非参数表示能够更好地推广到非常不同的视图来自训练数据中的数据；然而 GS 的渲染速度比 NeRF 快得多。我们开发了一个在两者之间来回转换的程序。我们的方法实现了 NeRF（不同视图上的卓越 PSNR、SSIM 和 LPIPS，以及紧凑的表示）和 GS（实时渲染和轻松修改表示的能力）的最佳效果；与从头开始训练两者相比，这些转换的计算成本很小。]]></description>
      <guid>https://arxiv.org/abs/2405.09717</guid>
      <pubDate>Fri, 17 May 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>用于 3D 相机评估的防撞指标</title>
      <link>https://arxiv.org/abs/2405.09755</link>
      <description><![CDATA[arXiv:2405.09755v1 公告类型：新
摘要：3D 相机已成为机器人和自动驾驶应用的重要信息源。这些相机为机器人提供了捕获和利用点云的能力，使它们能够导航周围环境并避免与其他物体发生碰撞。然而，当前的标准相机评估指标通常无法考虑特定的应用环境。这些指标通常侧重于倒角距离 (CD) 或推土机距离 (EMD) 等指标，这些指标可能无法直接转化为现实场景中的性能。为了解决这一限制，我们提出了一种新的点云评估指标，专门用于评估 3D 相机对于避免碰撞这一关键任务的适用性。该指标结合了特定于应用的考虑因素，可以更准确地衡量相机在确保安全机器人导航方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.09755</guid>
      <pubDate>Fri, 17 May 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>Point2SSM++：从点云进行解剖形状模型的自监督学习</title>
      <link>https://arxiv.org/abs/2405.09707</link>
      <description><![CDATA[arXiv:2405.09707v1 公告类型：新
摘要：基于对应的统计形状建模 (SSM) 是临床研究中形态分析的强大技术。SSM 有助于在人群水平上表征和量化骨骼和器官等解剖形状，有助于病理学和疾病诊断以及治疗计划。尽管 SSM 具有潜力，但由于自动构建方法需要完整、对齐的形状表面表示，其开销巨大，因此在医学研究中仍未得到充分利用。此外，基于优化的技术依赖于引起偏差的假设或模板，并且由于整个队列同时进行优化，因此推理时间延长。为了克服这些挑战，我们引入了 Point2SSM++，这是一种原则性的、自监督的深度学习方法，可直接从解剖形状的点云表示中学习对应点。Point2SSM++ 对未对齐和不一致的输入具有鲁棒性，可提供准确采样单个形状表面的 SSM，同时有效捕获人群水平的统计数据。此外，我们展示了 Point2SSM++ 的原则性扩展，以使其适应动态时空和多解剖用例，展示了 Point2SSM++ 框架的广泛多功能性。此外，我们还展示了针对动态时空和多解剖场景定制的 Point2SSM++ 扩展，展示了该框架的广泛多功能性。通过对各种解剖结构、评估指标和临床相关的下游任务进行广泛的验证，我们证明了 Point2SSM++ 优于现有的最先进深度学习模型和传统方法。Point2SSM++ 大大增强了 SSM 生成的可行性，并大大拓宽了其潜在的临床应用范围。]]></description>
      <guid>https://arxiv.org/abs/2405.09707</guid>
      <pubDate>Fri, 17 May 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>SOK-Bench：具有一致的开放世界知识的情景视频推理基准</title>
      <link>https://arxiv.org/abs/2405.09713</link>
      <description><![CDATA[arXiv:2405.09713v1 公告类型：新
摘要：从现实世界的视觉上下文和场景中学习常识推理是迈向高级人工智能的关键一步。然而，现有的视频推理基准仍然不足，因为它们主要是为事实或情景推理而设计的，很少涉及现实世界中更广泛的知识。我们的工作旨在更深入地研究推理评估，特别是在动态、开放世界和结构化上下文知识中。我们提出了一个新的基准（SOK-Bench），由 44K 问题和 10K 情况组成，并在视频中描述了实例级注释。推理过程需要理解和应用情境知识和一般知识来解决问题。为了创建这样的数据集，我们提出了一种自动且可扩展的生成方法，通过指示 LLM 和 MLLM 的组合来生成问答对、知识图和基本原理。具体来说，我们首先从视频中提取可观察的情境实体、关系和过程来获取情境知识，然后扩展到可见内容之外的开放世界知识。通过多次对话作为迭代来促进任务生成，并随后通过我们设计的自我提示和演示进行纠正和完善。通过明确的情境事实和隐含的常识的语料库，我们生成相关的问答对和推理过程，最后进行人工审查以保证质量。我们在基准上评估了最近主流的大型视觉语言模型，并发现了一些富有洞察力的结论。欲了解更多信息，请参阅我们的基准测试：www.bobbywu.com/SOKBench。]]></description>
      <guid>https://arxiv.org/abs/2405.09713</guid>
      <pubDate>Fri, 17 May 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>用于实例分割的合成到真实无监督域自适应</title>
      <link>https://arxiv.org/abs/2405.09682</link>
      <description><![CDATA[arXiv:2405.09682v1 公告类型：新
摘要：无监督域适应（UDA）旨在将从标记源域学到的知识转移到未标记目标域。虽然用于合成到现实世界（synth-to-real）的 UDA 方法在语义分割和对象检测等任务中表现出显着的性能，但针对实例分割任务提出的方法却很少。在本文中，我们介绍了 UDA4Inst，这是一种用于自动驾驶实例分割的合成真实 UDA 模型。我们在实例级别提出了一种新颖的跨域双向数据混合方法，以充分利用来自源域和目标域的数据。还采用稀有等级平衡和类别模块训练来进一步提高性能。值得注意的是，我们是第一个展示两个新的合成到真实实例分割基准的结果，UrbanSyn-&gt;Cityscapes 上的 mAP 为 39.0，Synscapes-&gt;Cityscapes 上的 mAP 为 35.7。 UDA4Inst 还在 SYNTHIA-&gt;Cityscapes 上取得了最先进的结果，mAP 为 31.3，比最新方法高出 15.6。我们的代码将被发布。]]></description>
      <guid>https://arxiv.org/abs/2405.09682</guid>
      <pubDate>Fri, 17 May 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>来自未分割医学图像的弱监督贝叶斯形状建模</title>
      <link>https://arxiv.org/abs/2405.09697</link>
      <description><![CDATA[arXiv:2405.09697v1 公告类型：新
摘要：解剖形状分析在临床研究和假设检验中发挥着关键作用，其中形式与功能之间的关系至关重要。基于对应关系的统计形状建模（SSM）有利于群体水平的形态测量，但需要一个繁琐的、可能会引起偏差的构建管道。深度学习的最新进展通过直接从未分割的医学图像提供 SSM 预测来简化这一推理过程。然而，所提出的方法受到充分监督，并且需要利用传统的 SSM 构建管道来创建训练数据，从而继承了相关的负担和限制。为了应对这些挑战，我们引入了一种弱监督深度学习方法，使用点云监督从图像中预测 SSM。具体来说，我们建议减少与最先进的完全贝叶斯变分信息瓶颈 DeepSSM (BVIB-DeepSSM) 模型相关的监督。 BVIB-DeepSSM 是一种有效的、有原则的框架，用于通过量化任意和认知不确定性来预测图像中的概率解剖形状。虽然原始的 BVIB-DeepSSM 方法需要地面实况对应点形式的强监督，但所提出的方法通过更容易获得的点云表面表示来利用弱监督。此外，所提出的方法以完全数据驱动的方式学习对应关系，而无需事先假设形状队列的预期变化。我们的实验表明，这种方法可以产生与完全监督场景相似的准确性和不确定性估计，同时大大增强了 SSM 构建模型训练的可行性。]]></description>
      <guid>https://arxiv.org/abs/2405.09697</guid>
      <pubDate>Fri, 17 May 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>AD 对齐：在深度学习中模拟类人泛化的认知域适应</title>
      <link>https://arxiv.org/abs/2405.09582</link>
      <description><![CDATA[arXiv:2405.09582v1 公告类型：新
摘要：领域适应对于使深度学习模型能够跨不同领域进行泛化至关重要，这是一项因表示和认知细微差别而变得复杂的任务。在本文中，我们介绍了 AD-Aligning，这是一种将对抗性训练与源-目标域对齐相结合以增强泛化能力的新颖方法。通过使用 Coral 损失和标准损失进行预训练，AD 对齐将目标域统计数据与预训练编码器的统计数据对齐，在适应域移位的同时保持鲁棒性。通过对不同数据集和领域转移场景（包括噪声引起的转移和认知领域适应任务）的广泛实验，我们证明了 AD-Aligning 与 Deep Coral 和 ADDA 等现有方法相比具有优越的性能。我们的研究结果强调了 AD-Aligning 能够模拟人类感知中固有的细微认知过程，这使其成为需要适应性强且稳健的领域适应策略的现实应用程序的有前景的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2405.09582</guid>
      <pubDate>Fri, 17 May 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>使用混合数据集训练深度学习模型，以实现真实 SAR 图像上的鲁棒自动目标检测</title>
      <link>https://arxiv.org/abs/2405.09588</link>
      <description><![CDATA[arXiv:2405.09588v1 公告类型：新
摘要：在这项工作中，我们建议解决阻碍 SAR 图像中地面目标自动目标检测（ATD）算法开发的几个挑战。为了解决缺乏代表性训练数据的问题，我们提出了一种深度学习方法，使用 MOCEM 模拟器生成的合成目标签名来训练 ATD 模型。我们定义了一个结壳管道，将合成目标合并到真实背景中。使用这个混合数据集，我们训练专门定制的 ATD 模型，以弥合合成数据和真实数据之间的领域差距。我们的方法特别依赖于大量基于物理的数据增强技术和两种深度学习检测架构的对抗训练。然后，我们在几个数据集上测试这些模型，包括（1）真实 SAR 图像的拼凑而成，（2）真实背景中包含真实目标的图像，以及（3）真实背景中包含合成背景对象的图像。结果表明，生成的混合数据集不受图像重叠偏差的影响。我们的方法可以在真实数据上达到高达 90% 的平均精度，同时专门使用合成目标进行训练。]]></description>
      <guid>https://arxiv.org/abs/2405.09588</guid>
      <pubDate>Fri, 17 May 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>基于掩码的物体检测隐形后门攻击</title>
      <link>https://arxiv.org/abs/2405.09550</link>
      <description><![CDATA[arXiv:2405.09550v1 公告类型：新
摘要：深度学习模型在目标检测领域取得了前所未有的性能，在自动驾驶和安全等领域取得了突破。然而，深度学习模型很容易受到后门攻击。这些攻击促使模型的行为与标准模型类似，无需触发；然而，他们在检测到预定义的触发器后会采取恶意行为。尽管对图像分类中的后门攻击进行了广泛的研究，但它们在目标检测中的应用仍然相对未得到充分探索。鉴于对象检测在关键的现实场景中的广泛应用，这些漏洞的敏感性和潜在影响怎么强调都不为过。在这项研究中，我们提出了一种利用基于掩码的方法对目标检测进行有效的隐形后门攻击。针对对象检测探索了三种不同的攻击场景：对象消失、对象错误分类和对象生成攻击。通过大量的实验，我们全面检验了这些攻击的有效性，并测试了某些防御方法，以确定有效的对策。]]></description>
      <guid>https://arxiv.org/abs/2405.09550</guid>
      <pubDate>Fri, 17 May 2024 06:19:15 GMT</pubDate>
    </item>
    </channel>
</rss>