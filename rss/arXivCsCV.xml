<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 21 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Transformer 增强型 UNet 用于多光谱 LandSat 图像中复杂背景中的烟雾分割</title>
      <link>https://arxiv.org/abs/2406.13105</link>
      <description><![CDATA[arXiv:2406.13105v1 公告类型：新
摘要：已经进行了许多研究以从卫星图像中检测烟雾。然而，这些先前的方法在检测复杂背景下的各种烟雾方面仍然无效。由于密度、颜色、光照和背景（例如云、霾和/或薄雾）的变化，以及稀薄烟雾的背景性质，烟雾在检测方面带来了挑战。本文通过提出一种称为 VTrUNet 的新分割模型来解决这些挑战，该模型由一个虚拟波段构造模块（用于捕获光谱模式）和一个变压器增强的 UNet（用于捕获远程上下文特征）组成。该模型以六个波段的图像为输入：红色、绿色、蓝色、近红外和两个短波红外波段。为了展示所提模型的优势，本文介绍了改进 UNet 的各种可能的模型架构的大量结果，并得出了有趣的结论，包括在模型中添加更多模块并不总能带来更好的性能。本文还将所提出的模型与最近提出的相关烟雾分割模型进行了比较，结果表明所提出的模型效果最好，并且在预测性能上取得了显著的提升]]></description>
      <guid>https://arxiv.org/abs/2406.13105</guid>
      <pubDate>Fri, 21 Jun 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>CU-Net：一种用于在 BraTS 2019 数据集上进行有效脑肿瘤分割的 U-Net 架构</title>
      <link>https://arxiv.org/abs/2406.13113</link>
      <description><![CDATA[arXiv:2406.13113v1 公告类型：新
摘要：从 MRI 扫描中准确分割脑肿瘤对于制定有效的治疗计划和改善患者预后非常重要。本研究介绍了使用 BraTS 2019 数据集对脑肿瘤进行分割的 Columbia-University-Net (CU-Net) 架构的新实现。CU-Net 模型具有对称的 U 形结构，并使用卷积层、最大池化和上采样操作来实现高分辨率分割。我们的 CU-Net 模型的 Dice 得分达到 82.41%，超过了其他两个最先进的模型。分割精度的提高凸显了模型的稳健性和有效性，有助于准确描绘肿瘤边界，这对于手术计划和放射治疗至关重要，并最终有可能改善患者的预后。]]></description>
      <guid>https://arxiv.org/abs/2406.13113</guid>
      <pubDate>Fri, 21 Jun 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>引导式情境门控：学习利用视网膜眼底图像中的显著病变</title>
      <link>https://arxiv.org/abs/2406.13126</link>
      <description><![CDATA[arXiv:2406.13126v1 公告类型：新
摘要：有效地表示医学图像，尤其是视网膜图像，由于病理体征（称为病变）的外观、大小和背景信息的变化而面临相当大的挑战。准确区分这些病变对于诊断糖尿病视网膜病变等视力威胁问题至关重要。虽然已经引入了基于视觉注意的神经网络来从视网膜图像中学习空间背景和通道相关性，但它们往往无法捕捉局部病变背景。为了解决这一限制，我们提出了一种称为引导上下文门控的新型注意机制，这是一种独特的方法，它集成了上下文公式、通道相关性和引导门控来学习全局背景、空间相关性和局部病变背景。我们对现有注意机制的定性评估强调了引导上下文门控在可解释性方面的优越性。值得注意的是，在 Zenodo-DR-7 数据集上的实验表明，在评估视网膜病变的严重程度时，与先进的注意力机制相比，准确率提高了 2.63%，与最先进的 Vision Transformer 相比，准确率提高了 6.53%，即使每个类别的训练样本不平衡且有限。]]></description>
      <guid>https://arxiv.org/abs/2406.13126</guid>
      <pubDate>Fri, 21 Jun 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>RITA：一个实时交互的语音虚拟形象框架</title>
      <link>https://arxiv.org/abs/2406.13093</link>
      <description><![CDATA[arXiv:2406.13093v1 公告类型：新
摘要：RITA 提出了一种基于生成模型的高质量实时交互框架，设计时充分考虑了实际应用。我们的框架能够将用户上传的照片转换为可以进行实时对话交互的数字化身。通过利用生成模型的最新进展，我们开发了一个多功能平台，它不仅可以通过动态对话化身增强用户体验，还为虚拟现实、在线教育和交互式游戏等应用开辟了新途径。这项工作展示了集成计算机视觉和自然语言处理技术以创建沉浸式和交互式数字角色的潜力，突破了我们与数字内容交互方式的界限。]]></description>
      <guid>https://arxiv.org/abs/2406.13093</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>使用潜在扩散模型在几秒钟内对 3D 高斯场景进行采样</title>
      <link>https://arxiv.org/abs/2406.13099</link>
      <description><![CDATA[arXiv:2406.13099v1 公告类型：新
摘要：我们提出了一种 3D 场景的潜在扩散模型，该模型可以仅使用 2D 图像数据进行训练。为了实现这一点，我们首先设计了一个自动编码器，将多视图图像映射到 3D 高斯图块，并同时构建这些图块的压缩潜在表示。然后，我们在潜在空间上训练一个多视图扩散模型来学习一个高效的生成模型。该管道不需要对象掩码或深度，适用于具有任意相机位置的复杂场景。我们对两个复杂的现实世界场景的大型数据集——MVImgNet 和 RealEstate10K 进行了仔细的实验​​。我们表明，我们的方法能够在短短 0.2 秒内生成 3D 场景，无论是从头开始，从单个输入视图，还是从稀疏输入视图。它产生多样化和高质量的结果，同时运行速度比非潜在扩散模型和早期的基于 NeRF 的生成模型快一个数量级]]></description>
      <guid>https://arxiv.org/abs/2406.13099</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>通过单目摄像头进行头部姿势估计和 3D 神经表面重建，用于导航和安全插入自然开口</title>
      <link>https://arxiv.org/abs/2406.13048</link>
      <description><![CDATA[arXiv:2406.13048v1 公告类型：新
摘要：随着模拟在医疗保健和干预中的重要性不断增加，人们期待建立一个简化且低成本的平台来执行个性化的诊断和治疗。3D Slicer不仅可以执行医学图像分析和可视化，还可以提供手术导航和手术规划功能。在本文中，我们选择3D Slicer作为基础平台，并使用单目相机作为传感器。然后，我们使用神经辐射场（NeRF）算法完成人体头部的3D模型重建。我们比较了NeRF算法在生成3D人体头部场景中的准确性，并利用MarchingCube算法生成相应的3D网格模型。通过单摄像头视觉获得的个体头部姿势被实时传输到3D Slicer内创建的场景中。本文介绍的演示包括3D Slicer场景中人体头部模型与检测到的头部姿势之间的实时同步变换。此外，我们还测试了一个场景，其中用单摄像头跟踪的 ArUco Maker 标记的工具同步指向头部姿势的实时变换。这些演示表明，我们的方法可以为鼻咽拭子采集或插管提供可行的实时模拟平台。]]></description>
      <guid>https://arxiv.org/abs/2406.13048</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>用于植物应激分类的类别特定数据增强</title>
      <link>https://arxiv.org/abs/2406.13081</link>
      <description><![CDATA[arXiv:2406.13081v1 公告类型：新
摘要：数据增强是改进基于深度学习的图像分类器以识别和分类植物应激的强大工具。然而，从大量候选者中选择一组有效的增强仍然是一个关键挑战，特别是在不平衡和混杂的数据集中。我们提出了一种使用遗传算法自动进行特定类数据增强的方法。我们证明了我们的方法在大豆 [Glycine max (L.) Merr] 应激分类中的实用性，其中症状在叶子上观察到；由于数据集中的混杂类别，这是一个特别具有挑战性的问题。我们的方法产生了显着的性能，在大豆叶片应激数据集上实现了 97.61% 的平均每类准确率和 98% 的总体准确率。我们的方法显着提高了最具挑战性的类别的准确率，分别从 83.01% 显着提高到 88.89%，从 85.71% 显着提高到 94.05%。
我们在本研究中得出的一个关键观察结果是，可以以计算效率高的方式识别高性能增强策略。我们仅使用不同的增强对基线模型的线性层进行微调，从而减少了与从头开始训练每个增强策略的分类器相关的计算负担，同时实现了出色的性能。这项研究代表了用于植物胁迫分类的自动数据增强策略的进步，特别是在混杂数据集的背景下。我们的研究结果为定制增强技术及其对疾病管理策略、作物产量和全球粮食安全的潜在影响的越来越多的研究做出了贡献。所提出的方法有可能提高基于深度学习的工具在农业中管理植物胁迫的准确性和效率。]]></description>
      <guid>https://arxiv.org/abs/2406.13081</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>用于自动昆虫监测的机器学习流程</title>
      <link>https://arxiv.org/abs/2406.13031</link>
      <description><![CDATA[arXiv:2406.13031v1 公告类型：新
摘要：气候变化和其他人为因素导致昆虫数量急剧下降，危及生物多样性和人类社会所依赖的生态系统服务。然而，关于昆虫丰度的数据仍然严重不足。传统上用于监测陆生脊椎动物的相机陷阱现在正在针对昆虫，尤其是飞蛾进行修改。我们描述了一个完整的、基于开源机器学习的软件流程，用于通过相机陷阱自动监测飞蛾，包括物体检测、飞蛾/非飞蛾分类、飞蛾物种的细粒度识别和个体跟踪。我们相信，我们的工具已经在三大洲使用，代表了昆虫学大规模可扩展数据收集的未来。]]></description>
      <guid>https://arxiv.org/abs/2406.13031</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>实时也门货币检测</title>
      <link>https://arxiv.org/abs/2406.13034</link>
      <description><![CDATA[arXiv:2406.13034v1 公告类型：新
摘要：纸币识别是视障人士面临的一个主要问题。因此，我们提出了一个应用程序，通过深度学习技术帮助视障人士识别不同类型的也门货币。由于货币在日常生活中的任何商业交易中都发挥着重要作用，因此对于个人（尤其是盲人或视障人士）或对数据进行分类的系统来说，实时检测和识别纸币变得非常必要。本文介绍了一种针对视障人士的实时也门货币检测系统。所提出的系统利用深度学习方法帮助视障人士顺利识别纸币。为了实现实时识别，我们已将系统部署到移动应用程序中。]]></description>
      <guid>https://arxiv.org/abs/2406.13034</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>分段相关加权和：一种有效的高光谱图像光谱匹配方法</title>
      <link>https://arxiv.org/abs/2406.13006</link>
      <description><![CDATA[arXiv:2406.13006v1 公告类型：新 
摘要：将目标光谱与光谱库中的已知光谱进行匹配是高光谱成像研究中材料识别的常用方法。高光谱光谱在不同波长段上表现出精确的吸收特征，这些吸收的独特形状和位置为每种材料创建了不同的光谱特征，有助于识别它们。因此，只有特定位置才可以考虑材料识别。本研究引入了分段相关性加权和方法，该方法计算库和测试光谱的各个部分之间的相关性指数，并得出匹配指数，使用分配的权重支持正相关并惩罚负相关。在地球和火星表面的高光谱图像中，对该方法的矿物识别的有效性进行了评估。]]></description>
      <guid>https://arxiv.org/abs/2406.13006</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>NTIRE 2024 夜间摄影渲染挑战赛</title>
      <link>https://arxiv.org/abs/2406.13007</link>
      <description><![CDATA[arXiv:2406.13007v1 公告类型：新
摘要：本文回顾了 NTIRE 2024 夜间摄影渲染挑战赛。挑战赛的目标是找到处理夜间拍摄的原始相机图像的解决方案，从而在标准 RGB (sRGB) 空间中生成照片质量的输出图像。与前一年的比赛不同，挑战赛图像是用手机收集的，算法的速度也与输出质量一起进行了测量。为了评估结果，考虑到任务的主观性，要求足够数量的观众评估所提解决方案的视觉质量。有 2 个提名：质量和效率。输出质量排名前 5 位的解决方案按评估时间排序（见图 1）。排名靠前的参与者的解决方案有效地代表了夜间摄影渲染的最新技术。更多结果可在 https://nightimaging.org 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.13007</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>ClaudesLens：计算机视觉模型中的不确定性量化</title>
      <link>https://arxiv.org/abs/2406.13008</link>
      <description><![CDATA[arXiv:2406.13008v1 公告类型：新
摘要：在一个使用人工智能做出更多决策的世界里，确保这些决策有充分依据至关重要。神经网络是人工智能的现代基石。基于现代神经网络的计算机视觉模型通常用于对象分类任务。正确对具有 \textit{确定性} 的对象进行分类在最近变得非常重要。然而，量化神经网络输出的固有 \textit{不确定性} 是一项具有挑战性的任务。在这里，我们展示了一种基于香农熵量化和评估不同计算机视觉模型输出不确定性的可能方法。通过在从输入到网络参数的不同部分添加不同级别的扰动，人们将熵引入系统。通过量化和评估基于提出的 PI 和 PSI 指标的扰动模型，我们可以得出结论，我们的理论框架可以深入了解计算机视觉模型预测的不确定性。我们相信，这一理论框架可以应用于神经网络的不同应用。我们相信，香农熵最终可能会在 SOTA（最先进）量化人工智能不确定性的方法中发挥更大的作用。有一天，我们也许能够将香农熵应用于我们的神经系统。]]></description>
      <guid>https://arxiv.org/abs/2406.13008</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>使用迁移学习技术对皮肤癌图像进行分类</title>
      <link>https://arxiv.org/abs/2406.12954</link>
      <description><![CDATA[arXiv:2406.12954v1 公告类型：新
摘要：皮肤癌是最常见和最致命的癌症类型之一。在良性阶段早期诊断皮肤癌对于降低癌症死亡率至关重要。为了在早期检测皮肤癌，必须使用自动化系统来挽救许多患者的生命。许多先前的研究已经使用各种深度学习和迁移学习模型解决了皮肤癌诊断问题。然而，现有文献在准确性和耗时方面存在局限性。在这项工作中，我们应用了五种不同的预训练迁移学习方法对良性和恶性阶段的皮肤癌检测进行二元分类。为了提高这些模型的准确性，我们对不同的层和激活函数进行了微调。我们使用公开的 ISIC 数据集来评估迁移学习方法。为了提高模型稳定性，应用数据增强技术来提高输入数据集的随机性。使用不同的超参数（例如批量大小、时期和优化器）来评估这些方法。实验结果表明，ResNet-50模型准确率为0.935，F1-score为0.86，精确率为0.94。]]></description>
      <guid>https://arxiv.org/abs/2406.12954</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>利用视频帧循环 (RoVF) 重新识别猫鼬</title>
      <link>https://arxiv.org/abs/2406.13002</link>
      <description><![CDATA[arXiv:2406.13002v1 公告类型：新
摘要：用于动物重新识别的深度学习方法对保护产生了重大影响，大大减少了许多下游任务（例如健康状况监测）所需的时间。我们提出了一种称为视频帧循环 (RoVF) 的方法，该方法使用基于感知器架构的循环头从视频剪辑中迭代构建嵌入。RoVF 使用基于视频帧中个体共现的三重态损失进行训练，其中个体 ID 不可用。我们在惠灵顿动物园收集的猫鼬数据集上测试了此方法和基于 DINOv2 Transformer 架构的各种模型。我们的方法实现了 top-1 重新识别准确率 $49\%$，高于最佳 DINOv2 模型 ($42\%$)。我们发现，该模型可以匹配人类无法匹配的个体观察结果，而且我们的模型 (RoVF) 在微调最少的情况下表现优于比较模型。在未来的工作中，我们计划通过使用前置任务来改进这些模型，将它们应用于动物行为分类，并执行超参数搜索以进一步优化模型。]]></description>
      <guid>https://arxiv.org/abs/2406.13002</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>语义图一致性：超越补丁，规范自监督视觉 Transformer</title>
      <link>https://arxiv.org/abs/2406.12944</link>
      <description><![CDATA[arXiv:2406.12944v1 公告类型：新
摘要：使用视觉变换器 (ViT) 的自监督学习 (SSL) 已被证明对表示学习有效，这可以从各种下游任务的出色表现中看出。尽管取得了这些成功，但现有的基于 ViT 的 SSL 架构并未充分利用 ViT 主干，尤其是 ViT 的补丁令牌。在本文中，我们引入了一种新颖的语义图一致性 (SGC) 模块来规范基于 ViT 的 SSL 方法并有效利用补丁令牌。我们将图像重新概念化为图形，以图像补丁为节点，并通过使用图形神经网络的显式消息传递将关系归纳偏差注入 SSL 框架。我们的 SGC 损失充当正则化器，利用 ViT 的未充分利用的补丁令牌来构建图形并在图像的多个视图之间强制图形特征之间的一致性。在 ImageNet、RESISC 和 Food-101 等各种数据集上进行的大量实验表明，我们的方法显著提高了学习表征的质量，在使用有限的标记数据进行线性评估时，性能提高了 5-10%。这些实验与一系列全面的消融相结合，证明了我们的方法在各种设置中的前景。]]></description>
      <guid>https://arxiv.org/abs/2406.12944</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:54 GMT</pubDate>
    </item>
    </channel>
</rss>