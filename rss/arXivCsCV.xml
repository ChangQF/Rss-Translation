<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Fri, 29 Dec 2023 06:18:24 GMT</lastBuildDate>
    <item>
      <title>通过具有多领域学习的协作增强网络进行夜间人员重新识别。 （arXiv：2312.16246v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16246</link>
      <description><![CDATA[流行的夜间 ReID 方法通常结合了重新照明网络和
ReID网络采用顺序方式，这不仅限制了ReID
性能取决于重新照明图像的质量，但也忽略了
图像重新照明和行人重新识别之间的有效协作建模
任务。为了解决这些问题，我们提出了一种新颖的协作增强
称为 CENet 的网络，它在一个网络中执行多级特征交互
并行框架，用于夜间行人 ReID。特别是，CENet 是一个
并行变压器网络，其中设计的并行结构可以
避免重新照明图像的质量对ReID性能的影响。到
在图像重新照明和人物之间执行有效的协作建模
ReID 任务中，我们集成了 CENet 中的多级特征交互。
具体来说，我们共享 Transformer 编码器来构建低级功能
交互，然后进行特征蒸馏以传递
从图像重新照明到 ReID 的高级功能。此外，尺寸
现有的现实世界夜间行人 ReID 数据集规模较小且规模较大
合成数据与真实世界数据存在巨大的领域差距。到
利用小规模的现实世界和大规模的合成训练数据，
我们开发了一种多领域学习算法，它交替利用两者
种数据以减少CENet训练中的域间差异。
对两个真实夜间数据集 \textit{Night600} 和
\textit{RGBNT201$_{rgb}$}，以及合成夜间 ReID 数据集
验证CENet的有效性。我们将发布代码和合成
数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.16246</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>从原始数据实现准确且时间一致的视频恢复。 （arXiv：2312.16247v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16247</link>
      <description><![CDATA[去噪和去马赛克是重建图像的两个基本步骤
从原始数据中清理全彩视频，同时执行视频去噪和
联合去马赛克，即 VJDD，可以带来更好的视频恢复
性能优于单独执行它们。除了修复
准确性，VJDD 的另一个关键挑战在于时间一致性
连续帧。当感知正则化项出现时，这个问题会加剧
被引入以提高视频感知质量。为了解决这些
挑战，我们通过一致且准确的潜在特征提出了一个新的 VJDD 框架
空间传播，利用先前帧的估计作为先验
知识以确保当前帧的一致恢复。数据时态
一致性（DTC）损失和关系感知一致性（RPC）损失是
据此设计。与常用的基于流的损失相比，
提出的损失可以规避由以下原因引起的误差累积问题
流量估计不准确并有效处理视频中的强度变化，
大大提高输出视频的时间一致性，同时保留
纹理细节。大量实验证明了领先的 VJDD 性能
我们的方法在恢复精度、感知质量和时间方面的评价
一致性。代码和数据集可在
\url{https://github.com/GuoShi28/VJDD}。
]]></description>
      <guid>http://arxiv.org/abs/2312.16247</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>iKUN：无需重新培训即可与追踪者对话。 （arXiv：2312.16245v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16245</link>
      <description><![CDATA[参考多目标跟踪（RMOT）旨在基于跟踪多个目标
关于输入文本描述。之前的作品通过简单的整合就实现了
多对象跟踪器中的额外文本模块。然而，他们通常
需要重新训练整个框架，优化上有困难。在
在这项工作中，我们提出了一个可插入的知识统一网络，称为 iKUN，
以即插即用的方式与现成的跟踪器进行通信。
具体来说，知识统一模块（KUM）被设计为自适应地
基于文本指导提取视觉特征。同时，为提高
定位精度，我们提出了卡尔曼滤波器（NKF）的神经版本
根据电流动态调整过程噪声和观测噪声
运动状态。此外，为了解决开集长尾问题
文本描述的分布，一种测试时相似性校准方法
提出用伪频率来细化置信度得分。广泛的
Refer-KITTI 数据集上的实验验证了我们框架的有效性。
最后，为了加快RMOT的发展，我们也贡献了更多的力量
具有挑战性的数据集 Refer-Dance，通过扩展公共 DanceTrack 数据集
动作和着装描述。代码和数据集将于
https://github.com/dyhBUPT/iKUN。
]]></description>
      <guid>http://arxiv.org/abs/2312.16245</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>推进行人重新识别：基于张量的特征融合和多线性子空间学习。 （arXiv：2312.16226v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16226</link>
      <description><![CDATA[行人重新识别（PRe-ID）是一个计算机视觉问题，一直是一个
过去几年的丰富研究领域。它的目的是识别跨领域的人
不同的不重叠的相机视图。在本文中，我们提出了一部小说
结合张量特征表示和多线性的PRe-ID系统
子空间学习。我们的方法利用了预训练卷积的力量
神经网络（CNN）作为强大的深度特征提取器，以及两个
互补描述符、局部最大出现次数 (LOMO) 和 Gaussian Of
高斯（GOG）。然后，基于张量的跨视图二次判别分析
（TXQDA）用于学习判别子空间，增强
不同个体之间的可分离性。马哈拉诺比斯距离用于
查询和图库样本之间的匹配和相似度计算。最后，我们
通过在三个数据集 VIPeR、GRID、
和 PRID450。
]]></description>
      <guid>http://arxiv.org/abs/2312.16226</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>合并来自不同任务和领域的视觉转换器。 （arXiv：2312.16240v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16240</link>
      <description><![CDATA[这项工作的目标是合并经过训练的各种 Vision Transformer (ViT)
不同的任务（即具有不同对象类别的数据集）或域
（即具有相同类别但不同环境的数据集）合并为一个
统一的模型，在每个任务或领域上仍然产生良好的性能。以前的
模型合并工作集中于 CNN 或 NLP 模型，留下 ViT
合并研究未受影响。为了填补这个空白，我们首先探索并发现
现有的模型合并方法不能很好地处理整个ViT的合并
型，仍有改进空间。为了实现整体的合并
ViT，我们提出了一个简单但有效的门控网络，它可以合并所有
各种层（例如 Embedding、Norm、Attention 和 MLP）并选择
合适的分类器。具体来说，门控网络是通过未标记的进行训练的
来自所有任务（域）的数据集，并预测其中的概率
输入所属的任务（域），用于在推理过程中合并模型。到
进一步提高合并模型的性能，特别是当
合并任务的难度增加，我们设计了一种新颖的模型权重度量
相似性，并利用其实现可控组合权重合并。
对各种新建立的基准进行综合实验，验证
所提出的 ViT 合并框架对于不同任务的优越性和
域。我们的方法甚至可以合并超过 10 个来自不同视觉的 ViT 模型
对每项任务的性能影响可以忽略不计的任务。
]]></description>
      <guid>http://arxiv.org/abs/2312.16240</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>通过可逆即时学习和高质量数据模拟方法进行模态缺失 RGBT 跟踪。 （arXiv：2312.16244v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16244</link>
      <description><![CDATA[当前RGBT跟踪研究主要集中在模态完备的跟踪上
场景，忽略了现实场景中模态缺失的挑战。在
在这项工作中，我们全面调查了模态缺失的影响
RGBT 跟踪挑战并提出一种新颖的可逆提示学习
方法，它将内容保留提示集成到训练有素的
跟踪模型适应各种模态缺失场景，
模态缺失 RGBT 跟踪。特别是，鉴于缺少一种模态
场景中，我们建议利用可用的方式来生成提示
适应 RGBT 跟踪模型的缺失模式。但是，那
可用模式和缺失模式之间的跨模式差距通常会导致
即时生成中的语义扭曲和信息丢失。为了处理这个
问题，我们提出了可逆即时学习方案，将
根据提示中的提示完全重建输入可用模式
一代模型。考虑到缺少模态缺失的 RGBT 跟踪
数据集和许多模态缺失的场景很难捕获，我们设计
一种基于分层组合方案的高质量数据模拟方法
生成现实世界中模态缺失的数据。广泛的实验三
模态缺失数据集表明我们的方法取得了显着的性能
与最先进的方法相比有所改进。我们将发布代码
和模拟数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.16244</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>TEMP3D：遮挡下的时间连续 3D 人体姿势估计。 （arXiv：2312.16221v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16221</link>
      <description><![CDATA[现有的 3D 人体姿态估计方法在这两个方面都表现得非常好
单目和多视图设置。然而，它们的功效会减弱
在存在严重遮挡的情况下显着，这限制了它们的实用性
公用事业。对于视频序列，时间连续性可以帮助推断准确的
姿势，尤其是在严重遮挡的帧中。在本文中，我们的目标是利用
这种通过人类运动先验实现时间连续性的潜力，再加上
大规模 3D 姿势预训练和自监督学习，以增强
给定视频序列中的 3D 姿态估计。这导致暂时
对未标记的野外视频进行连续 3D 姿态估计，其中可能包含
遮挡，同时完全依赖于预先训练的 3D 姿势模型。我们建议
一种名为 TEMP3D 的无监督方法，可在给定的条件下对齐运动先验模型
使用现有 SOTA 基于单图像的 3D 姿态估计的野外视频
在遮挡下给出时间连续输出的方法。来评估我们的
方法，我们在 Occlusion Human3.6M 数据集（我们的定制数据集）上进行测试
其中包含非常大（高达 100%）的人体遮挡
纳入 Human3.6M 数据集。我们在 Occlusiond 上取得了 SOTA 成绩
Human3.6M 和 OcMotion 数据集，同时保持在
非遮挡数据。网址：https://sites.google.com/ucr.edu/temp3d
]]></description>
      <guid>http://arxiv.org/abs/2312.16221</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>通过关键代币的加权调整来细分任何事件。 （arXiv：2312.16222v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16222</link>
      <description><![CDATA[在本文中，我们深入探讨了定制细分市场的微妙挑战
用于与事件数据集成的任何模型 (SAM)
目标是在
以事件为中心的领域。这一努力的核心问题之一是
从以事件为中心的数据派生的嵌入的精确对准和校准
以便它们与源自 RGB 图像的图像和谐一致。
利用具有配对事件和 RGB 的庞大数据集存储库
图像，我们的主张是利用和推断深刻的知识
封装在预先训练的 SAM 框架内。作为基石
为了实现这一目标，我们引入了多尺度特征蒸馏方法。
该方法严格优化了令牌嵌入的对齐方式
源自事件数据及其 RGB 图像对应项，从而
保持并增强整体架构的稳健性。
考虑到中间代币嵌入的独特意义
层用于更高级别的嵌入，我们的策略以准确为中心
校准关键令牌嵌入。这种有针对性的校准旨在
有效管理高层嵌入中的差异
来自事件和图像域。针对不同的情况进行了广泛的实验
数据集证明了所提出的蒸馏方法的有效性。
此 http URL 中的代码
]]></description>
      <guid>http://arxiv.org/abs/2312.16222</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Hyper-VolTran：通过超网络快速且可通用的一次性图像到 3D 对象结构。 （arXiv：2312.16218v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16218</link>
      <description><![CDATA[从单一视图解决图像到 3D 的问题是一个不适定问题，并且当前
通过扩散模型解决该问题的神经重建方法仍然依赖于
针对特定场景的优化，限制了其泛化能力。
克服现有方法在泛化和
为了保持一致性，我们引入了一种新颖的神经渲染技术。我们的方法
采用有符号距离函数作为表面表示，并且
通过几何编码体积合并可概括的先验，并且
超网络。具体来说，我们的方法从以下内容构建神经编码卷
生成多视图输入。我们调整SDF网络的权重
在测试时以输入图像为条件，以允许模型适应新颖的
通过超网络以前馈方式进行场景。减少伪影
从综合视图中得出，我们建议使用体积转换器
模块来改进图像特征的聚合而不是处理每个特征
分别观点。通过我们提出的称为 Hyper-VolTran 的方法，我们
避免场景优化的瓶颈并保持一致性
跨越从多个视点生成的图像。我们的实验表明
我们提出的方法的优点是结果一致且快速
一代。
]]></description>
      <guid>http://arxiv.org/abs/2312.16218</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>AI Mirage：人工幻觉时代的冒名顶替者偏见和 Deepfake 检测挑战。 （arXiv：2312.16220v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16220</link>
      <description><![CDATA[本文对法医学中的认知偏差进行了全面分析
和数字取证，检查它们对决策的影响
这些领域的流程。它探讨了各种类型的认知偏差
在法医调查和数字法医分析过程中可能出现的情况，
例如确认偏差、期望偏差、对错误的过度自信，
情境偏差和归因偏差。它还评估现有方法
以及用于减轻这些背景下的认知偏差的技术，评估
旨在减少偏见和改善的干预措施的有效性
决策结果。此外，本文还引入了一种新的认知
偏见，称为“冒充者偏见”，可能会影响生成人工智能的使用
取证和数字取证中的情报 (AI) 工具。冒充者偏见
是怀疑所生成输出的真实性或有效性的倾向
通过人工智能工具，例如深度伪造，以音频、图像和视频的形式。这
偏见可能会导致错误的判断或错误的指控，从而损害
法医证据的可靠性和可信度。该论文讨论了
冒充者偏见的潜在原因和后果，并提出了一些建议
预防或抵消它的策略。通过解决这些主题，本文
旨在为理解认知偏差提供有价值的见解
法医实践并为未来的研究和提供建议
提高司法鉴定客观性和有效性的实际应用
调查。
]]></description>
      <guid>http://arxiv.org/abs/2312.16220</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 RLDF 对扩散模型进行迭代提示重新标记。 （arXiv：2312.16204v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16204</link>
      <description><![CDATA[扩散模型在许多领域都表现出了令人印象深刻的性能，包括
图像生成、时间序列预测和强化学习。这
算法表现出优于传统 GAN 的性能
基于变压器的方法。然而，该模型遵循自然规律的能力
语言指令（例如，物体之间的空间关系、生成
复杂的场景）仍然不能令人满意。这是一项重要的研究
区来增强这种能力。先前的工作采用强化学习
调整扩散模型的行为。然而，RL 方法不仅
需要仔细的奖励设计和复杂的超参数调整，但也失败了
纳入丰富的自然语言反馈。在这项工作中，我们建议
迭代提示重新标记（IP-RLDF），一种将图像对齐的新颖算法
通过迭代图像采样和提示重新标记来生成文本。 IP-RLDF优先
根据文本对一批图像进行采样，然后重新标记文本
提示不匹配的文本图像对和分类器反馈。我们进行
对三种不同模型（包括 SDv2、GLIGEN 和
SDXL，测试他们按照说明生成图像的能力。和
IP-RLDF，我们在具有挑战性的任务上提高了 15.22%（绝对提高）
空间关系 VISOR 基准测试，展示了相比之下的优越性能
到以前的 RL 方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.16204</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>日晷：通过直接、环境和复杂的照明分解了解 3D 卫星。 （arXiv：2312.16215v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16215</link>
      <description><![CDATA[卫星图像的 3D 建模在环境领域至关重要
科学、城市规划、农业和灾害应对。然而，
传统3D建模技术在遥感领域面临独特的挑战
上下文，包括广泛区域的有限多视图基线，不同
直接照明、环境照明、复杂照明条件以及随时间变化的场景
跨捕获的变化。在这项工作中，我们介绍了日晷（SUNDIAL），一个综合性的
使用神经辐射度进行卫星图像 3D 重建的方法
字段。我们共同学习卫星场景几何、照明组件，以及
在此单模型方法中太阳方向，并提出二次阴影光线
投射技术 1) 使用倾斜太阳角度改善场景几何形状
渲染阴影，2) 启用场景反照率的基于物理的解开
照明，以及 3) 确定直接照明的分量，
环境（天空）和复杂的来源。为了实现这一目标，我们将照明融入其中
神经渲染中遥感文献的线索和几何先验
方法，对卫星场景的物理属性（例如阴影）进行建模，
分散的天空照明以及复杂的植被照明和阴影
和水。我们评估 SUNDIAL 与现有基于 NeRF 的性能
卫星场景建模技术并展示改进的场景和
照明解开、新颖的视图和照明渲染以及几何和
对具有小基线、稀疏的挑战性场景进行太阳方向估计
输入和可变照明。
]]></description>
      <guid>http://arxiv.org/abs/2312.16215</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>ManipLLM：用于以对象为中心的机器人操作的具体多模式大语言模型。 （arXiv：2312.16217v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16217</link>
      <description><![CDATA[机器人操纵依赖于准确预测接触点和
末端执行器方向，以确保成功操作。然而，以学习为基础
机器人操作，通常在模拟器中的有限类别上进行训练
努力实现普遍性，特别是当面临
广泛的类别。因此，我们引入了一种创新的机器人方法
利用多模式强大的推理能力进行操作
大型语言模型（MLLM），以增强稳定性和泛化性
操纵。通过微调注入的适配器，我们保留了固有的
MLLM 的常识和推理能力，同时为他们配备
操纵能力。基本的见解在于引入的
微调范式，包括对象类别理解、可供性
先验推理和以对象为中心的姿势预测来刺激推理
MLLM 的操纵能力。在推理过程中，我们的方法利用 RGB
图像和文字提示以思维链预测末端执行器的姿势。
建立初始接触后，主动阻抗适应策略
引入以闭环方式规划即将到来的航路点。而且，
在现实世界中，我们设计了一个测试时间适应（TTA）策略来进行操作
使模型更好地适应当前的现实场景配置。
模拟器和现实世界中的实验显示了有前途的性能
马尼普法学硕士。更多详细信息和演示可以在以下位置找到：
https://sites.google.com/view/manipllm。
]]></description>
      <guid>http://arxiv.org/abs/2312.16217</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>INFAMOUS-NeRF：使用具有神经辐射场的语义对齐超网络改进面部建模。 （arXiv：2312.16197v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16197</link>
      <description><![CDATA[我们提出了 INFAMOUS-NeRF，一种隐式可变形人脸模型，它引入了
超网络到 NeRF 以提高存在时的表示能力
许多培训科目。同时，INFAMOUS-NeRF解决了经典问题
超网络通过学习权衡表示能力和可编辑性
尽管存在特定于主题的模型，但语义上对齐的潜在空间，所有
不需要大型预训练模型。 INFAMOUS-NeRF 进一步介绍了
改进沿面边界的 NeRF 渲染的新约束。我们的
约束可以利用光度表面渲染和多视图
监督指导表面颜色预测并改善附近的渲染
表面。最后，我们介绍一种新颖的、损失引导的自适应采样方法
通过减少采样冗余来实现更有效的 NeRF 训练。我们展示
定量和定性表明我们的方法实现了更高的代表性
在受控和野外环境中都比先前的面部建模方法更强大
设置。代码和模型将在发布后发布。
]]></description>
      <guid>http://arxiv.org/abs/2312.16197</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>时间旅行像素：双时态特征与遥感图像变化检测基础模型的集成。 （arXiv：2312.16202v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.16202</link>
      <description><![CDATA[变化检测是遥感领域的一个重要研究领域，在
观察和分析表面变化。尽管显着
通过基于深度学习的方法取得的进步，执行
时空复杂遥感中的高精度变化检测
情景仍然是一个巨大的挑战。最近出现的
基础模型，具有强大的普适性和泛化性
能力，提供潜在的解决方案。然而，弥合数据和
任务仍然是一个重大障碍。在本文中，我们介绍了时间
Traveling Pixels (TTP)，一种整合潜在知识的新颖方法
将 SAM 基础模型引入变更检测。这个方法有效
解决一般知识转移的领域转变和挑战
表达多时相的同质和异质特征
图片。 LEVIR-CD 上获得的最先进结果强调了
TTP 的功效。该代码可在 \url{https://kychen.me/TTP} 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.16202</guid>
      <pubDate>Fri, 29 Dec 2023 06:18:17 GMT</pubDate>
    </item>
    </channel>
</rss>