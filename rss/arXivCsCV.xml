<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Tue, 23 Jan 2024 06:18:40 GMT</lastBuildDate>
    <item>
      <title>MotionMix：用于可控运动生成的弱监督扩散。 （arXiv：2401.11115v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11115</link>
      <description><![CDATA[随着 3D 人体动作的可控生成成为一个重要课题
世界拥抱数字化转型。现有作品，尽管前景光明
随着扩散模型的出现，进步很大程度上依赖于精心
捕获并注释（例如文本）的高质量运动语料库，
现实世界中的资源密集型努力。这激发了我们提出的
MotionMix，一个简单而有效的弱监督扩散模型
利用噪声和未注释的运动序列。具体来说，我们
将扩散模型的去噪目标分为两个阶段：
在初始 $T-T^*$ 步骤中获得条件粗略运动近似
通过学习嘈杂的注释运动，然后是无条件的
在最后 $T^*$ 步骤中使用以下方法细化这些初步动议
未注释的动议。值得注意的是，尽管从两个不完美的来源中学习
数据，与完全相比，我们的模型不会损害运动生成质量
访问黄金数据的监督方法。在多个方面进行了广泛的实验
基准测试表明我们的 MotionMix 作为一个多功能框架，
在文本到动作方面始终实现最先进的性能，
动作到动作、音乐到舞蹈任务。
]]></description>
      <guid>http://arxiv.org/abs/2401.11115</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>弱监督语义分割的空间结构约束。 （arXiv：2401.11122v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11122</link>
      <description><![CDATA[图像级标签在弱监督语义中盛行
分割任务由于其易于使用。由于图像级标签可以
仅表明特定类别的物体存在或不存在，
基于可视化的技术已被广泛采用来提供对象
位置线索。考虑类激活图（CAM）只能定位
物体最具辨别力的部分，最近的方法通常采用
扩展策略，扩大激活区域以获得更完整的对象
本土化。然而，如果没有适当的约束，扩展的激活将
轻松侵入背景区域。在本文中，我们提出空间
用于弱监督语义分割的结构约束（SSC）
减轻不需要的物体对注意力扩展的过度激活。
具体来说，我们提出了一个 CAM 驱动的重建模块来直接
从深层 CAM 特征重建输入图像，这限制了
通过保留粗略空间来扩散最后一层对象注意力
图像内容的结构。此外，我们建议激活
自调制模块可通过以下方式改进 CAM，使其具有更精细的空间结构细节
增强区域一致性。没有外部显着性模型来提供
背景线索，我们的方法在 PASCAL 上达到 72.7\% 和 47.0\% mIoU
VOC 2012 和 COCO 数据集分别证明了我们的优越性
提议的方法。
]]></description>
      <guid>http://arxiv.org/abs/2401.11122</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>跨域面部表情识别的自适应全局局部表示学习和选择。 （arXiv：2401.11085v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11085</link>
      <description><![CDATA[域转移对跨域面部表情提出了重大挑战
由于不同类别之间的分布差异而导致的识别（CD-FER）
域。目前的工作主要集中在学习领域不变特征
通过全局特征适应，同时忽略了可转移性
当地特色。此外，这些方法缺乏歧视性监督
在目标数据集上训练期间，导致特征恶化
目标域中的表示。为了解决这些限制，我们提出了一个
自适应全局局部表示学习和选择（AGLRLS）框架。
该框架结合了全球-本地对抗性适应和
语义感知伪标签生成，以增强学习
训练期间的域不变和判别特征。与此同时，一个
引入全局-局部预测一致性学习来提高
推理过程中的分类结果。具体来说，该框架包括
独立的全局-局部对抗性学习模块
域不变的全局和局部特征独立。我们还设计了一个
语义感知伪标签生成模块，用于计算语义标签
基于全局和局部特征。此外，一种新颖的动态阈值
采用策略来利用独立的学习最佳阈值
预测全局和局部特征，确保过滤掉不可靠的特征
伪标签，同时保留可靠的标签。这些标签用于
通过端到端的对抗性学习过程进行模型优化
方式。在推理过程中，全局-局部预测一致性模块是
开发用于从多个预测中自动学习最佳结果。
我们基于公正的评估进行全面的实验和分析
基准。结果表明，所提出的框架优于
目前的竞争方法有很大优势。
]]></description>
      <guid>http://arxiv.org/abs/2401.11085</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>VONet：使用并行 U-Net Attention 和对象顺序 VAE 进行无监督视频对象学习。 （arXiv：2401.11110v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11110</link>
      <description><![CDATA[无监督视频对象学习旨在将视频场景分解为
结构对象表示，无需任何深度、光学监督
流，或分段。我们提出了 VONet，这是一种创新方法
灵感来自 MONet。在利用 U-Net 架构的同时，VONet 采用
高效且有效的并行注意力推理过程，生成
同时对所有插槽进行注意掩码。此外，为了增强
连续视频帧中每个掩模的时间一致性，VONet
开发了一个对象方式的顺序 VAE 框架。这些的整合
创新的编码器端技术，结合富有表现力的
基于 Transformer 的解码器，将 VONet 确立为领先的无监督方法
用于跨五个 MOVI 数据集的对象学习，涵盖不同的视频
复杂性。代码可在 https://github.com/hnyu/vonet 获取。
]]></description>
      <guid>http://arxiv.org/abs/2401.11110</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>DengueNet：利用时空卫星图像对资源有限的国家进行登革热预测。 （arXiv：2401.11114v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11114</link>
      <description><![CDATA[登革热对发展中国家构成了重大挑战
卫生基础设施不足。缺乏全面的
医疗保健系统可能会加剧登革热感染的严重性
导致危及生命的情况。快速应对登革热疫情
由于信息交换和集成有限，也具有挑战性。尽管
及时的登革热疫情预测有可能预防此类疫情的爆发，
大多数登革热预测研究主要依赖于数据
这给个别国家带来了沉重的收集负担。在这个
研究中，我们的目标是通过以下方式改善资源有限国家的健康公平
探索高分辨率卫星图像作为
非传统且易于访问的数据源。通过利用财富
公开且易于获取的卫星图像，我们提出了
基于 Sentinel Hub（基于云的）的可扩展卫星提取框架
计算平台。此外，我们还推出了 DengueNet，一种创新的
结合了 Vision Transformer、Radioomics 和 Long Short-term 的架构
从卫星图像中提取和整合时空特征的存储器。
这使得登革热周的预测成为可能。评估
我们提出的方法的有效性，我们对五个进行了实验
哥伦比亚的直辖市。我们使用的数据集包含 780
用于训练和评估的高分辨率 Sentinel-2 卫星图像。这
使用平均绝对误差 (MAE) 评估 DengueNet 的性能
公制。在五个城市中，DengueNet 的平均 MAE 为
43.92。我们的研究结果有力地支持了卫星图像作为
登革热预测的宝贵资源，特别是在告知公众方面
手动收集数据稀缺的国家内的卫生政策
登革热病毒流行严重。
]]></description>
      <guid>http://arxiv.org/abs/2401.11114</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>Make-A-Shape：千万级 3D 形状模型。 （arXiv：2401.11067v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11067</link>
      <description><![CDATA[在训练大型生成模型方面取得了重大进展
自然语言和图像。然而，3D 生成模型的进步是
受到大量培训资源需求的阻碍，以及
低效、不紧凑且表达能力较差的表示。这张纸
推出了 Make-A-Shape，这是一种新的 3D 生成模型，旨在提高效率
大规模培训，可利用1000万公开数据
形状。在技​​术方面，我们首先创新了小波树表示
通过制定子带系数滤波方案对形状进行紧凑编码
有效地利用系数关系。然后我们进行表示
可通过设计子带系数包装由扩散模型生成
在低分辨率网格中布局表示的方案。此外，我们
推导出子带自适应训练策略来有效地训练我们的模型
学习生成粗略和细节小波系数。最后，我们扩展我们的
框架由额外的输入条件控制，使其能够
从各种模式生成形状，例如单/多视图图像、点
云和低分辨率体素。在我们大量的实验中，我们
演示各种应用，例如无条件生成、形状
完成，以及各种模式的条件生成。我们的
这种方法不仅在提供高质量方面超越了最先进的技术
结果还可以在几秒钟内有效地生成形状，通常
在大多数情况下只需 2 秒即可实现此目的。
]]></description>
      <guid>http://arxiv.org/abs/2401.11067</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>UltrAvatar：具有真实性引导纹理的逼真的可动画 3D 头像扩散模型。 （arXiv：2401.11078v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11078</link>
      <description><![CDATA[3D 头像生成方面的最新进展引起了广泛关注。
这些突破旨在产生更逼真的动画化身，缩小
虚拟和现实世界体验之间的差距。大部分现有作品
采用分数蒸馏采样（SDS）损失，并结合可微分
渲染器和文本条件，指导扩散模型生成 3D
头像。然而，SDS 经常会产生过于平滑的结果，且面部特征很少
细节，因此与祖先采样相比缺乏多样性。上
另一方面，其他作品从单个图像生成 3D 头像，其中
不良照明效果、透视图和劣质图像的挑战
质量使他们难以可靠地重建 3D 面部网格
对齐完整的纹理。在本文中，我们提出了一种新颖的 3D 头像
称为 UltrAvatar 的生成方法，具有增强的几何保真度，以及
基于物理的渲染（PBR）纹理的卓越质量，没有不需要的
灯光。为此，所提出的方法提出了漫反射颜色
提取模型和真实性引导纹理扩散模型。前者
消除不需要的照明效果以显示真实的漫射颜色，以便
生成的头像可以在各种光照条件下渲染。后者
遵循两个基于梯度的指导来生成要渲染的 PBR 纹理
多样化的面部识别特征和细节更好地与 3D 网格对齐
几何学。我们证明了所提议的有效性和鲁棒性
方法，在很大程度上优于最先进的方法
实验。
]]></description>
      <guid>http://arxiv.org/abs/2401.11078</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>图像保护：使用条件视觉语言模型进行推理并反事实地混淆不安全内容。 （arXiv：2401.11035v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11035</link>
      <description><![CDATA[恶意行为者越来越多地利用社交媒体平台来
分享不安全的内容，例如描述性活动、网络欺凌的图像，
和自残。因此，主要平台都使用人工智能（AI）
以及人为调节来混淆这些图像以使其更安全。两个关键
混淆不安全图像的准确理由是
必须提供混淆图像区域，并且应该提供敏感区域
为了用户的安全而进行模糊处理（\textit{e.g.} 模糊）。这个过程涉及到
解决两个关键问题：（1）不安全图像混淆的原因
要求平台提供准确的理由，必须基于
不安全的图像特定属性，以及 (2) 图像中的不安全区域必须
被最小程度地混淆，同时仍然描绘安全区域。在这项工作中，
我们首先通过设计一个执行视觉推理来解决这些关键问题
以预先训练的不安全图像为条件的视觉推理模型（VLM）
分类器提供基于不安全图像的准确理由
属性，然后提出反事实解释算法
首先，最低限度地识别和混淆不安全区域以确保安全查看
利用不安全的图像分类器归因矩阵来指导分割
进行更优化的子区域分割，然后进行知情的贪婪搜索
确定修改所需的最小子区域数量
基于归因分数的分类器输出。广泛的实验
来自社交网络的未经整理的数据强调了我们提议的有效性
方法。我们在以下位置提供代码：
https://github.com/SecureAIAutonomyLab/ConditionalVLM
]]></description>
      <guid>http://arxiv.org/abs/2401.11035</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>PhotoBot：通过自然语言进行参考引导的交互式摄影。 （arXiv：2401.11061v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11061</link>
      <description><![CDATA[我们介绍 PhotoBot，一个基于
高级人类语言指导和机器人之间的相互作用
摄影师。我们建议通过以下方式向用户传达摄影建议
从精选图库中检索的参考图片。我们利用一个
视觉语言模型 (VLM) 和用于表征参考的对象检测器
通过文字描述来描述图片并使用大语言模型（LLM）
根据用户的语言查询检索相关参考图片
基于文本的推理。将参考图片与观察到的图片对应起来
场景中，我们利用视觉转换器的预先训练的特征，该特征能够
捕获显着变化的图像之间的语义相似性。使用这些
特征，我们通过求解一个 RGB-D 相机的姿态调整
透视 n 点 (PnP) 问题。我们在现实世界中展示了我们的方法
配备腕部摄像头的机械手。我们的用户研究表明照片
由 PhotoBot 拍摄的照片通常比由
用户本身，通过人类反馈来衡量。
]]></description>
      <guid>http://arxiv.org/abs/2401.11061</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>通过高效训练学习图像大小调整 (LRET) 有助于提高大规模数字组织病理学图像分类模型的性能。 （arXiv：2401.11062v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11062</link>
      <description><![CDATA[组织学检查在肿瘤学研究和诊断中发挥着至关重要的作用。
诊断。采用全幻灯片图像数字扫描 (WSI) 已
创造了利用基于深度学习的图像分类的机会
加强诊断和风险分层的方法。技术限制
当前训练深度卷积神经网络 (DCNN) 的方法结果
模型性能次优并进行训练和部署
无法获得全面的分类模型。在这项研究中，我们引入了一个
解决传统方法主要局限性的新颖方法
组织病理学分类模型训练。我们的方法称为 Learned
通过高效训练（LRET）调整大小，结合高效的训练技术
调整图像大小以促进更大组织学的无缝集成
将图像补丁转换为最先进的分类模型，同时保留
重要的结构信息。

我们使用 LRET 方法结合两种不同的调整大小技术来
使用多个不同的 DCNN 训练三个不同的组织学图像数据集
架构。我们的研究结果表明，
分类性能和训练效率。跨越各个领域
实验表明，LRET 始终优于现有方法，产生
大规模、多类别的准确率大幅提高 15-28%
肿瘤分类任务由 74 种不同的脑肿瘤类型组成。不 LRET
不仅提高了分类精度，而且大大减少了训练
次，释放更快模型开发和迭代的潜力。这
这项工作的影响扩展到医学成像领域更广泛的应用
以及更远的地方，将高分辨率图像有效地集成到深度
学习渠道对于推动研究和发展的进步至关重要
临床实践。
]]></description>
      <guid>http://arxiv.org/abs/2401.11062</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>HOSC：一种用于保留隐式神经表示中的尖锐特征的周期性激活函数。 （arXiv：2401.10967v1 [cs.NE]）</title>
      <link>http://arxiv.org/abs/2401.10967</link>
      <description><![CDATA[最近提出了隐式表示信号（例如图像）的方法，
通常使用基于坐标的神经网络架构的场景或几何图形
不要利用激活函数的选择，或者仅在有限的情况下这样做
程度。在本文中，我们介绍了双曲振荡函数（HOSC），
一种具有可控锐度参数的新颖激活函数。不同于任何
之前的激活，HOSC经过专门设计，可以更好地捕获
输入信号的突然变化，因此产生尖锐或尖锐的特征
基础数据以及平滑的低频转换。由于其
简单性和模块化，HOSC 提供即插即用功能，可以
可以很容易地融入到任何现有的使用神经网络作为方法的方法中
隐式表示信号的方式。我们将 HOSC 与其他产品进行基准比较
一系列一般任务中的流行激活，根据经验显示
提高所获得的表示的质量，提供
HOSC 功效背后的数学动机，并讨论其
限制。
]]></description>
      <guid>http://arxiv.org/abs/2401.10967</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>快速注册 VR 面部动画的逼真头像。 （arXiv：2401.11002v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11002</link>
      <description><![CDATA[虚拟现实 (VR) 有望带来让人感觉更丰富的社交互动
比其他媒体更具沉浸感。做到这一点的关键是能够准确地制作动画
戴着 VR 耳机时逼真的头像。虽然
将特定人物的头像高质量注册到头戴式摄像头
(HMC) 图像可以在离线设置中实现，通用的性能
实时模型显着退化。网上报名也是
由于倾斜的相机视图和模态的差异，这具有挑战性。在这个
工作中，我们首先展示头像和耳机相机之间的域差距
图像是困难的主要来源之一，其中基于变压器的
架构在域一致的数据上实现了高精度，但会降低
当域间隙被重新引入时。基于这一发现，我们开发了
将问题分解为两个部分的系统设计：1）迭代
接受域内输入的细化模块，以及 2）通用化身引导
以当前估计为条件的图像到图像风格转换模块
表情和头部姿势。这两个模块相互加强，如图
当显示接近事实的示例时，风格迁移变得更容易，
更好的域间隙消除有助于注册。我们的系统生产
高效地获得高质量结果，无需昂贵的离线
注册生成个性化标签。我们验证准确性并
通过对商品进行大量实验来提高我们方法的效率
耳机，展示了相对于直接回归方法的显着改进
以及线下报名。
]]></description>
      <guid>http://arxiv.org/abs/2401.11002</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>亥姆霍兹分解和光流：一种表征 GCamP 记录的新方法。 （arXiv：2401.11008v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.11008</link>
      <description><![CDATA[在深度睡眠和麻醉状态下皮质的自发模式
激活经常以慢速行波的形式出现。慢波睡眠
是一种重要的认知状态，特别是因为它与记忆相关
合并。然而，尽管进行了广泛的研究，但确切的机制仍不清楚
还是不太理解。新方法，例如高速宽场成像
GCamP 活动提供了新的潜力。这里我们展示了如何记录数据
麻醉下的转基因小鼠可以被处理来分析源、库和
流动模式。最大限度地利用数据 新颖的数据手段
处理是必要的。因此，我们（1）简要介绍一下
在产生慢波中发挥作用并证明（2）新颖的过程
方法来表征 GCamP 录音中的模式。虽然慢波是
差异很大，但它表明有些人惊人地相似。启用
定量分析方法并检查此类原型的结构
我们提出了一种表征慢波的新方法：
基于梯度的像素密集密集光流的亥姆霍兹分解
GCamP 对比度 (df/f)。它允许检测激活的源和汇
并从神经流的全局模式中辨别它们。聚合特征可以
使用变分自动编码器进行分析。结果揭示了规律
慢波之间的关系，并显示它们与实验条件的关系。
该方法揭示了潜在慢速中不同特征的复杂拓扑
波空间并确定每个阶段的原型示例。
]]></description>
      <guid>http://arxiv.org/abs/2401.11008</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>一款 VR 严肃游戏，旨在增强对语音阅读障碍学生的同理心。 （arXiv：2401.10926v1 [cs.HC]）</title>
      <link>http://arxiv.org/abs/2401.10926</link>
      <description><![CDATA[阅读障碍是一种神经发育障碍，估计会影响大约
占人口的5-10%。特别是，语音阅读障碍会导致问题
将单词的声音与其书面形式联系起来。这导致
阅读速度慢、阅读不准确、阅读困难等困难
解码不熟悉的单词。此外，阅读障碍也可能是一种具有挑战性和
对于学生来说这是令人沮丧的经历，因为他们可能会感到被误解或
受到同龄人或教育者的侮辱。由于这些原因，使用
补偿工具和策略对于阅读障碍至关重要
学生享有与非诵读困难学生相同的机会。然而，
一般来说，人们低估了这个问题并且没有意识到其重要性
支持方法论。鉴于此，本文的主要目的
是提出一款虚拟现实（VR）严肃游戏，通过该游戏，教师、
学生和一般来说，非诵读困难的人都可以理解哪些是
患有阅读障碍的学生的问题以及提供的基本效用
对他们的支持。在游戏中，玩家必须按照以下步骤制作药水：
用字母写成的食谱是专门为复制而设计的
患有阅读障碍的人经历的阅读困难。任务必须是
首先在没有任何帮助的情况下解决，然后通过接收支持工具和
策略的理念是玩家可以将自己置于他人的位置
阅读障碍者并了解支持方法的真正需要。
]]></description>
      <guid>http://arxiv.org/abs/2401.10926</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>一步学习，一步复习。 （arXiv：2401.10962v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2401.10962</link>
      <description><![CDATA[随着视觉微调的兴起，视觉微调引起了人们的广泛关注。
预先训练的视觉模型。目前流行的方法，充分微调，
遭受知识遗忘的问题，因为它只关注拟合
下游训练集。在本文中，我们提出了一种新颖的权重
基于回滚的微调方法，称为 OLOR（一步学习，一步
审查）。 OLOR 将微调与优化器相结合，并结合了权重
在每一步将项回滚到权重更新项中。这确保了
上下游模型权重范围一致，有效
减少知识遗忘并提高微调性能。在
此外，还提出了分层惩罚以采用惩罚衰减，并且
多样化的衰减率来调整各层的权重回滚水平
适应不同的下游任务。通过对各种方面的大量实验
图像分类、目标检测、语义分割等任务，
和实例分割，我们证明了一般适用性和
我们提出的 OLOR 的最先进的性能。代码可在
https://github.com/rainbow-xiao/OLOR-AAAI-2024。
]]></description>
      <guid>http://arxiv.org/abs/2401.10962</guid>
      <pubDate>Tue, 23 Jan 2024 06:18:34 GMT</pubDate>
    </item>
    </channel>
</rss>