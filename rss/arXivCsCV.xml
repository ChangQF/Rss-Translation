<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 20 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>NeRO：神经路面重建</title>
      <link>https://arxiv.org/abs/2405.10554</link>
      <description><![CDATA[arXiv:2405.10554v1 公告类型：新
摘要：在计算机视觉和图形学中，路面的精确重建对于各种应用至关重要，尤其是在自动驾驶中。本文介绍了一种利用多层感知器 (MLP) 框架的新方法，通过输入世界坐标 x 和 y 重建路面的高度、颜色和语义信息。我们的方法 NeRO 使用基于 MLP 的编码技术，显着提高了复杂细节的性能，加快了训练速度并减少了神经网络的大小。该方法的有效性通过其卓越的性能得到证明，这为使用语义应用渲染路面指明了一个有希望的方向，特别是在需要可视化道路状况、4D 标记和语义分组的应用中。]]></description>
      <guid>https://arxiv.org/abs/2405.10554</guid>
      <pubDate>Mon, 20 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>CM-UNet：用于遥感图像语义分割的混合 CNN-Mamba UNet</title>
      <link>https://arxiv.org/abs/2405.10530</link>
      <description><![CDATA[arXiv:2405.10530v1 公告类型：新
摘要：由于大规模图像尺寸和目标变化，当前基于 CNN 和 Transformer 的遥感图像语义分割方法对于捕获远程依赖性不是最佳的，或者受限于复杂的计算复杂性。在本文中，我们提出了 CM-UNet，包括用于提取局部图像特征的基于 CNN 的编码器和用于聚合和集成全局信息的基于 Mamba 的解码器，促进遥感图像的高效语义分割。具体来说，引入 CSMamba 块来构建核心分割解码器，该解码器采用通道和空间注意力作为 vanilla Mamba 的门激活条件，以增强特征交互和全局局部信息融合。此外，为了进一步细化 CNN 编码器的输出特征，采用多尺度注意力聚合（MSAA）模块来合并不同尺度的特征。通过集成CSMamba模块和MSAA模块，CM-UNet有效捕获大规模遥感图像的长距离依赖关系和多尺度全局上下文信息。在三个基准上获得的实验结果表明，所提出的 CM-UNet 在各种性能指标上都优于现有方法。代码可在 https://github.com/XiaoBuL/CM-UNet 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.10530</guid>
      <pubDate>Mon, 20 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>通过可逆神经网络提高遥感图像压缩的感知质量</title>
      <link>https://arxiv.org/abs/2405.10518</link>
      <description><![CDATA[arXiv:2405.10518v1 公告类型：新
摘要：解码遥感图像以实现高感知质量，特别是在低比特率下，仍然是一个重大挑战。为了解决这个问题，我们提出了基于可逆神经网络的遥感图像压缩（INN-RSIC）方法。具体来说，我们从现有的图像压缩算法中捕获压缩失真，并通过 INN 将其编码为一组高斯分布的潜在变量。这确保了解码图像中的压缩失真变得独立于地面实况。因此，通过利用INN的逆映射，我们可以将解码图像与一组随机重采样的高斯分布变量一起输入到逆网络中，有效地生成具有更好感知质量的增强图像。为了有效地学习压缩失真，采用通道扩展、哈尔变换和可逆块来构建 INN。此外，我们引入了量化模块（QM）来减轻格式转换的影响，从而增强框架的泛化性并提高增强图像的感知质量。大量实验表明，我们的 INN-RSIC 在感知质量方面显着优于现有最先进的传统和基于深度学习的图像压缩方法。]]></description>
      <guid>https://arxiv.org/abs/2405.10518</guid>
      <pubDate>Mon, 20 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>保护视觉语言模型免受修补视觉提示注入器的影响</title>
      <link>https://arxiv.org/abs/2405.10529</link>
      <description><![CDATA[arXiv:2405.10529v1 公告类型：新
摘要：大型语言模型变得越来越突出，也标志着人工智能的下一个前沿领域正在向多模态转变，其中它们的嵌入被用作生成文本内容的提示。视觉语言模型 (VLM) 处于这一进步的最前沿，提供了结合视觉和文本数据以增强理解和交互的创新方法。然而，这种集成也扩大了攻击面。正如许多现有文献所证明的那样，基于补丁的对抗攻击被认为是物理视觉应用中最现实的威胁模型。在本文中，我们建议解决修补视觉提示注入问题，即攻击者利用对抗性修补程序在 VLM 中生成目标内容。我们的调查表明，修补的对抗性提示表现出对像素随机化的敏感性，这一特征即使针对旨在抵消此类防御的自适应攻击也仍然强大。利用这一见解，我们引入了 SmoothVLM，这是一种植根于平滑技术的防御机制，专门用于保护 VLM 免受修补的视觉提示注入器的威胁。我们的框架将两个领先的 VLM 上的攻击成功率显着降低到 0% 到 5.0% 之间，同时实现良性图像的约 67.3% 到 95.0% 的上下文恢复，展示了安全性和可用性之间的平衡。]]></description>
      <guid>https://arxiv.org/abs/2405.10529</guid>
      <pubDate>Mon, 20 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>MixCut：一种用于面部表情识别的数据增强方法</title>
      <link>https://arxiv.org/abs/2405.10489</link>
      <description><![CDATA[arXiv:2405.10489v1 公告类型：新
摘要： 在面部表情识别任务中，由于训练样本量较小，研究人员总是得到表情分类的准确率较低的结果。为了解决此类问题，我们提出了一种新的数据增强方法，名为 MixCut。在该方法中，我们首先以随机比例在像素级别对两个原始训练样本进行插值以生成新样本。然后，对新样本的随机正方形区域进行像素去除，生成最终的训练样本。我们在 Fer2013Plus 和 RAF-DB 上评估了 MixCut 方法。通过MixCut，我们在Fer2013Plus上实现了85.63%的八标签分类准确率，在RAF-DB上实现了87.88%的七标签分类准确率，有效提高了面部表情图像识别的分类精度。同时，在 Fer2013Plus 上，与其他三种数据增强方法（CutOut、Mixup 和 CutMix）相比，MixCut 的性能分别提高了 +0.59%、+0.36% 和 +0.39%。与这三种数据增强方法相比，MixCut 将 RAF-DB 的分类准确度提高了 +0.22%、+0.65% 和 +0.5%。]]></description>
      <guid>https://arxiv.org/abs/2405.10489</guid>
      <pubDate>Mon, 20 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>多尺度语义先验特征引导的城市街景图像深度神经网络</title>
      <link>https://arxiv.org/abs/2405.10504</link>
      <description><![CDATA[arXiv:2405.10504v1 公告类型：新
摘要：街景图像作为重要的移动测绘数据源已被广泛应用。街景图像修复是街景图像处理的关键一步，不仅是为了隐私保护，也是为了城市环境测绘应用。本文提出了一种新颖的深度神经网络（DNN）、多尺度语义先验特征引导图像修复网络（MFN），用于修复街景图像，它可以生成没有移动物体（例如行人、车辆）的静态街景图像。为了增强全局上下文理解，引入了语义先验提示器，以从大型预训练模型中学习丰富的语义先验。我们通过堆叠多个语义金字塔聚合（SPA）模块来设计提示器，捕获广泛的视觉特征模式。提出了一种带有解码器的语义增强图像生成器，该生成器在每个尺度级别都结合了新颖的级联可学习先验传输（LPT）模块。对于每个解码器块，应用注意力转移机制来捕获长期依赖性，并将语义先验特征与图像特征融合，以自适应方式恢复合理的结构。此外，采用后台感知数据处理方案来防止在洞内产生幻觉物体。 Apolloscapes 和 Cityscapes 数据集上的实验表明，MAE 和 LPIPS 的性能优于最先进的方法，分别提高了约 9.5% 和 41.07%。还进行了多组人员之间的视觉比较调查以提供性能评估，结果表明所提出的 MFN 为隐私保护提供了一种有前途的解决方案，并为具有街景图像的城市应用生成更可靠的场景。]]></description>
      <guid>https://arxiv.org/abs/2405.10504</guid>
      <pubDate>Mon, 20 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>ART3D：用于文本引导艺术场景生成的 3D 高斯溅射</title>
      <link>https://arxiv.org/abs/2405.10508</link>
      <description><![CDATA[arXiv:2405.10508v1 公告类型：新
摘要：在本文中，我们通过介绍 ART3D（一种结合了扩散模型和 3D 高斯喷射技术的新颖框架）来探讨 3D 艺术场景生成中存在的挑战。我们的方法通过创新的图像语义传输算法有效地弥合了艺术图像和现实图像之间的差距。通过利用深度信息和初始艺术图像，我们生成点云图，解决领域差异。此外，我们提出了深度一致性模块来增强 3D 场景一致性。最后，3D 场景作为优化高斯图的初始点。实验结果表明，与现有方法相比，ART3D 在内容和结构一致性指标方面均具有卓越的性能。 ART3D 通过提供生成高质量 3D 艺术场景的创新解决方案，显着推进了人工智能在艺术创作领域的发展。]]></description>
      <guid>https://arxiv.org/abs/2405.10508</guid>
      <pubDate>Mon, 20 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>一种新颖的单目标跟踪边界框回归方法</title>
      <link>https://arxiv.org/abs/2405.10444</link>
      <description><![CDATA[arXiv:2405.10444v1 公告类型：新
摘要：鉴于目标出现在序列的第一帧中，在帧序列中定位目标是一个涉及多个阶段的难题。通常，最先进的方法侧重于在视觉编码或关系建模阶段引入新颖的想法。然而，在这项工作中，我们表明从学习的联合搜索和模板特征中进行边界框回归也非常重要。虽然以前的方法严重依赖于表示搜索和模板之间交互的充分学习的特征，但我们假设输入卷积边界框网络的感受野在准确确定对象位置方面发挥着重要作用。为此，我们引入了两种新颖的边界框回归网络：inception 和可变形网络。实验和消融研究表明，我们安装在最近的 ODTrack 上的初始模块在三个基准测试中优于后者：GOT-10k、UAV123 和 OTB2015。]]></description>
      <guid>https://arxiv.org/abs/2405.10444</guid>
      <pubDate>Mon, 20 May 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>冰图中的区域级标签可以对海冰类型进行像素级分割</title>
      <link>https://arxiv.org/abs/2405.10456</link>
      <description><![CDATA[arXiv:2405.10456v1 公告类型：新
摘要：完全监督的深度学习方法在海冰分类方面表现出了令人印象深刻的准确性，但由于难以获取此类数据，它们对高分辨率标签的依赖提出了重大挑战。作为回应，我们的弱监督学习方法通​​过利用专家注释的冰图中的较低分辨率区域标签提供了一种令人信服的替代方案。该方法通过在训练过程中引入区域损失表示来测量预测的海冰类型分布与冰图导出的海冰类型分布之间的差异，从而实现了出色的像素级分类性能。利用 AI4Arctic 海冰挑战数据集，我们的方法在测绘分辨率和分类精度方面优于完全监督的 U-Net 基准（AutoIce 挑战的顶级解决方案），标志着自动化操作海冰测绘的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2405.10456</guid>
      <pubDate>Mon, 20 May 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>超越传统的单一对象跟踪：一项调查</title>
      <link>https://arxiv.org/abs/2405.10439</link>
      <description><![CDATA[arXiv:2405.10439v1 公告类型：新
摘要：单目标跟踪是关键领域许多应用的重要任务。然而，它仍然被认为是最具挑战性的视觉任务之一。近年来，计算机视觉，特别是对象跟踪，见证了许多新技术的引入或采用，为性能开辟了新的前沿。在本次调查中，我们探讨了视觉领域的一些前沿技术，例如序列模型、生成模型、自监督学习、无监督学习、强化学习、元学习、持续学习和领域适应，并重点关注它们的应用在单个目标跟踪中。我们提出了一种基于新颖技术和趋势的单对象跟踪方法的新颖分类。此外，我们对流行跟踪基准上提出的方法报告的性能进行了比较分析。此外，我们分析了所提出方法的优缺点，并为单对象跟踪中的非传统技术提供了指南。最后，我们提出了单目标跟踪未来研究的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2405.10439</guid>
      <pubDate>Mon, 20 May 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>具有参考令牌的接地 3D-LLM</title>
      <link>https://arxiv.org/abs/2405.10370</link>
      <description><![CDATA[arXiv:2405.10370v1 公告类型：新
摘要：先前关于 3D 场景理解的研究主要开发了针对特定任务或所需的特定任务微调的专用模型。在这项研究中，我们提出了 Grounded 3D-LLM，它探索了 3D 大型多模态模型 (3D LMM) 在统一生成框架内整合各种 3D 视觉任务的潜力。该模型使用场景指代标记作为特殊名词短语来引用 3D 场景，从而能够处理交织 3D 和文本数据的序列。它提供了一种使用特定于任务的指令模板将 3D 视觉任务转换为语言格式的自然方法。为了促进在后续语言建模中使用指称标记，我们策划了大规模的基础语言数据集，通过引导现有的对象标签在短语级别提供更精细的场景文本对应。随后，我们引入了对比语言场景预训练（CLASP）来有效利用这些数据，从而将 3D 视觉与语言模型相结合。我们的全面评估涵盖密集字幕和 3D QA 等开放式任务，以及对象检测和语言基础等封闭式任务。跨多个 3D 基准的实验揭示了 Grounded 3D-LLM 的领先性能和广泛适用性。代码和数据集将在项目页面发布：https://groundedscenellm.github.io/grounded_3d-llm.github.io。]]></description>
      <guid>https://arxiv.org/abs/2405.10370</guid>
      <pubDate>Mon, 20 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>Drone-type-Set：用于无人机检测和跟踪的无人机类型检测基准</title>
      <link>https://arxiv.org/abs/2405.10398</link>
      <description><![CDATA[arXiv:2405.10398v1 公告类型：新
摘要：无人机（UAV）市场一直在显着增长，考虑到无人机以低成本提供，可能会被滥用用于贩毒、间谍和恐怖袭击等非法目的，对国家安全构成高风险。 ， 正在崛起。因此，检测和跟踪未经授权的无人机以防止未来威胁生命、设施和安全的攻击成为必要。无人机检测可以使用不同的传感器进行，而由于人工智能技术的发展，基于图像的检测就是其中之一。然而，由于缺乏无人机类型数据集，了解未经授权的无人机类型是挑战之一。为此，在本文中，我们提供了各种无人机的数据集，并对所提出的数据集上已识别的目标检测模型进行了比较，包括不同版本的 YOLO 算法，例如 v3、v4 和 v5 以及 Detectronv2。提供了不同模型的实验结果以及每种方法的描述。收集的数据集可以在 https://drive.google.com/drive/folders/1EPOpqlF4vG7hp4MYnfAecVOsdQ2JwBEd?usp=share_link 中找到]]></description>
      <guid>https://arxiv.org/abs/2405.10398</guid>
      <pubDate>Mon, 20 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>通过姿势编码变分自动编码器进行多样性感知手语制作</title>
      <link>https://arxiv.org/abs/2405.10423</link>
      <description><![CDATA[arXiv:2405.10423v1 公告类型：新
摘要：本文解决了多样性意识手语生成的问题，我们想要给出手语者的图像（或序列），并生成具有相同姿势但不同属性（\textit{例如}性别、肤色）的另一幅图像。 ）。为此，我们扩展了变分推理范式，以包含有关姿势和属性条件的信息。该公式提高了合成图像的质量。生成器框架以 UNet 架构的形式呈现，以确保输入姿势的空间保留，并且我们包含来自变分推理的视觉特征，以保持对外观和风格的控制。我们用单独的解码器生成每个身体部位。这种架构允许生成器提供更好的整体结果。 SMILE II 数据集上的实验表明，所提出的模型在多样性、每像素图像质量和姿势估计方面的定量表现优于最先进的基线。从数量上来说，它忠实地为签名者再现了非手动功能。]]></description>
      <guid>https://arxiv.org/abs/2405.10423</guid>
      <pubDate>Mon, 20 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>用于视频异常检测的网络系统：教程和调查</title>
      <link>https://arxiv.org/abs/2405.10347</link>
      <description><![CDATA[arXiv:2405.10347v1 公告类型：新
摘要：智慧城市中监控摄像头的日益普及，加上在线视频应用的激增，加剧了人们对公共安全和隐私保护的担忧，这促使自动视频异常检测（VAD）成为人工智能领域的一项基础研究任务。人工智能）社区。随着深度学习和边缘计算的进步，VAD与智慧城市和视频互联网等新兴应用相结合，取得了重大进展，已经超越了算法工程的传统研究范围，发展到可部署的VAD网络系统（NSVAD），人工智能、车联网和计算领域交叉探索的实用热点。在本文中，我们描述了各种深度学习驱动的VAD路线的基本假设、学习框架和适用场景，为NSVAD新手提供详尽的教程。本文通过回顾最新进展和典型解决方案，并汇总可在 https://github.com/fdjingliu/NSVAD 访问的可用研究资源（例如文献、代码、工具和研讨会）来阐明核心概念。此外，我们展示了我们在工业物联网和智慧城市方面最新的 NSVAD 研究，以及可部署 NSVAD 的端云协作架构，以进一步阐明其潜在的研究和应用范围。最后，本文预测了未来的发展趋势，并讨论了人工智能与计算技术的融合如何解决现有的研究挑战并促进开放机会，为未来的研究人员和工程师提供富有洞察力的指南。]]></description>
      <guid>https://arxiv.org/abs/2405.10347</guid>
      <pubDate>Mon, 20 May 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>RGB 引导 ToF 成像系统：基于深度学习的方法综述</title>
      <link>https://arxiv.org/abs/2405.10357</link>
      <description><![CDATA[arXiv:2405.10357v1 公告类型：新
摘要：将 RGB 相机集成到 ToF 成像系统中已成为感知现实世界的重要技术。 RGB 引导的 ToF 成像系统对于多种应用至关重要，包括人脸反欺骗、显着性检测和轨迹预测。根据工作范围的距离不同，RGB引导的ToF成像系统的实现方案也不同。具体来说，具有均匀照明场的 ToF 传感器可以输出密集的深度，但分辨率较低，通常用于近距离测量。相比之下，激光雷达发射激光脉冲，只能捕获稀疏的深度，通常用于远距离检测。在这两种情况下，RGB引导ToF成像的深度质量改进对应于两个子任务：引导深度超分辨率和引导深度补全。鉴于最近深度学习对该领域的重大推动，本文全面回顾了 RGB 引导 ToF 成像的相关工作，包括网络结构、学习策略、评估指标、基准数据集和目标函数。此外，我们还对广泛使用的基准数据集上最先进的方法进行了定量比较。最后，我们讨论了未来的趋势和实际应用中进一步研究的挑战。]]></description>
      <guid>https://arxiv.org/abs/2405.10357</guid>
      <pubDate>Mon, 20 May 2024 06:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>