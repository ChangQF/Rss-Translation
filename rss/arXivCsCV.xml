<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CV 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 计算机视觉和模式识别 (cs.CV) 在 arXiv.org 电子打印存档上更新</description>
    <lastBuildDate>Mon, 04 Dec 2023 03:14:50 GMT</lastBuildDate>
    <item>
      <title>BAM-DETR：用于视频中时间句子接地的边界对齐力矩检测变压器。 （arXiv：2312.00083v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00083</link>
      <description><![CDATA[时间句子基础旨在定位与语言相关的时刻
描述。最近，类似 DETR 的方法取得了显着进展
从可学习的查询中解码目标时刻的中心和长度。
然而，它们遇到了中心未对准的问题。
矩中心固有的模糊性，导致预测不准确。到
为了解决这个问题，我们引入了一种新颖的面向边界的矩公式。
在我们的范式中，模型不再需要找到精确的中心，而是
相反，足以预测区间内的任何锚点，从中
直接估计起始点和偏移量。基于这个想法，我们设计了一个
边界对准力矩检测变压器（BAM-DETR），配备
双通道解码过程。具体来说，它细化了锚点并
使用全局和以边界为中心的并行路径内的边界
分别注意。这种单独的设计使模型能够专注于
所需区域，从而能够精确细化矩预测。更远，
我们提出了一种基于质量的排名方法，确保高提案
本地化质量优先于不完整的质量。广泛的
实验验证了我们方法的优势，我们的模型记录了新的
在三个基准上取得了最先进的结果。代码位于
https://github.com/Pilhyeon/BAM-DETR。
]]></description>
      <guid>http://arxiv.org/abs/2312.00083</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:50 GMT</pubDate>
    </item>
    <item>
      <title>HiFi 调谐器：针对扩散模型的高保真主体驱动微调。 （arXiv：2312.00079v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00079</link>
      <description><![CDATA[本文探讨了高保真个性化图像的进展
通过利用预先训练的文本到图像扩散生成
楷模。虽然以前的方法在生成
基于文本描述和一些输入图像的多功能场景、挑战
坚持保持生成图像中的主题保真度。在
在这项工作中，我们引入了一种名为 HiFi Tuner 的创新算法来增强
个性化图像生成过程中对象的外观保留。我们的
所提出的方法采用参数有效的微调框架，包括
去噪过程和关键反演过程。主要增强功能包括
利用掩模引导，一种新颖的参数正则化技术，
并结合逐步的主题表征来提升
样本保真度。此外，我们提出了参考引导生成
利用参考图像的关键反转来减轻
不需要的主题变化和伪影。我们进一步将我们的方法扩展到
新颖的图像编辑任务：通过文本替换图像中的主题
操纵。在 DreamBooth 数据集上进行的实验评估
使用稳定扩散模型展示了有希望的结果。仅微调
文本嵌入将 CLIP-T 分数提高了 3.6 分，并改进了 DINO
比 Textual Inversion 得分高 9.6 分。当微调所有参数时，
HiFi Tuner 将 CLIP-T 分数提高 1.2 分，将 DINO 分数提高 1.2 分
超越 DreamBooth，建立了新的技术水平。
]]></description>
      <guid>http://arxiv.org/abs/2312.00079</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>综合、诊断和优化：迈向细粒度视觉语言理解。 （arXiv：2312.00081v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00081</link>
      <description><![CDATA[视觉语言模型 (VLM) 在各个方面都表现出了卓越的性能
各种下游任务。然而，理解细粒度的视觉语言
诸如属性和对象间关系之类的概念仍然是
重大挑战。虽然一些基准测试旨在更精细地评估 VLM
粒度，他们的主要关注点仍然是语言方面，而忽略了
视觉维度。在这里，我们强调评估 VLM 的重要性
无论是文字还是视觉的角度。我们引入了渐进式管道
合成特定属性不同的图像，同时确保一致性
在所有其他方面。利用这个数据引擎，我们精心设计了一个
基准，SPEC，诊断对物体大小、位置的理解，
存在，并计数。随后，我们对四项内容进行了全面评估
SPEC 上领先的 VLM。令人惊讶的是，他们的表现接近随机猜测，
揭示了显着的局限性。考虑到这一点，我们提出了一个简单但
在细粒度的理解中优化 VLM 的有效方法，实现
在不影响零样本的情况下显着改进 SPEC
表现。两个额外的细粒度基准测试的结果也显示
持续改进，进一步验证我们的可转移性
方法。
]]></description>
      <guid>http://arxiv.org/abs/2312.00081</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>用于高效存储海量 4D 功能磁共振成像的紧凑隐式神经表示。 (arXiv:2312.00082v1 [eess.IV])</title>
      <link>http://arxiv.org/abs/2312.00082</link>
      <description><![CDATA[功能磁共振成像（fMRI）数据是一种广泛使用的数据
四维生物医学数据，要求有效压缩但
由于其复杂的时间性，给压缩带来了独特的挑战
动态、低信噪比和复杂的潜在冗余。
本文报告了一种专门为 fMRI 定制的新型压缩范例
基于隐式神经表征（INR）的数据。提议的方法
专注于消除时间序列之间的各种冗余，包括
(i) 对区域内动态进行空间相关建模，(ii)
分解可重复使用的神经元激活模式，并使用适当的
初始化与非线性融合一起描述区域间
相似。上述方案恰当地结合了fMRI的独特特征
数据和公开数据集的实验结果表明
所提出方法的有效性，超越了最先进的算法
传统的图像质量评估指标和功能磁共振成像下游任务。
本文的这项工作为共享低功耗海量功能磁共振成像数据铺平了道路
带宽和高保真度。
]]></description>
      <guid>http://arxiv.org/abs/2312.00082</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:49 GMT</pubDate>
    </item>
    <item>
      <title>CRAFT：用于人脸识别训练的过滤器的上下文重新激活。 （arXiv：2312.00072v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00072</link>
      <description><![CDATA[深度 CNN 主干网的第一层将过滤器应用于图像以进行提取
后续层可用的基本功能。在训练期间，一些过滤器可能
变为非活动状态，意味着过滤器中的所有权重都接近零。不活动的过滤器
最终模型中的 ter 代表错失了提取有用信息的机会
特征。这种现象在专门的 CNN 中尤其普遍，例如
用于人脸识别（相对于 ImageNet 等）。例如，在一个
最广泛的人脸识别模型（ArcFace），大约一半的卷积
第一层中的过滤器处于非活动状态。我们提出了一种新颖的方法
并专门针对人脸识别网络进行了测试，称为“CRAFT：
用于人脸识别训练的过滤器的上下文重新激活”。CRAFT
在训练期间识别不活动的过滤器并根据
在训练的那个阶段的强过滤器的背景。我们表明，CRAFT 可以减少
非活动过滤器的比例平均从 44% 降至 32%，并发现过滤器
标准训练未发现的模式。与无标准训练相比
重新激活，CRAFT 展示了标准模型精度的提高
人脸识别基准数据集，包括 AgeDB-30、CPLFW、LFW、CALFW 和
CFP-FP，以及更具挑战性的数据集，如 IJBB 和 IJBC。
]]></description>
      <guid>http://arxiv.org/abs/2312.00072</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>通过软挖掘加速神经场训练。 （arXiv：2312.00075v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00075</link>
      <description><![CDATA[我们提出了一种通过有效地加速神经场训练的方法
选择采样地点。虽然神经场最近变得流行，
它通常通过对训练域进行均匀采样来进行训练，或者通过
手工启发法。我们证明了收敛和最终训练的改进
质量可以通过基于重要性的软挖掘技术来实现
采样：我们不是完全考虑或忽略像素，而是
用标量来衡量相应的损失。为了实现我们的想法，我们使用 Langevin
蒙特卡罗采样。我们表明，通过这样做，具有较高误差的区域是
被更频繁地选择，导致性能提高超过 2 倍
收敛速度。本研究的代码和相关资源是公开的
可以在 https://ubc-vision.github.io/nf-soft-mining/ 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.00075</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:48 GMT</pubDate>
    </item>
    <item>
      <title>GLiDR：稀疏 LiDAR 点云的拓扑正则化图生成网络。 （arXiv：2312.00068v1 [cs.RO]）</title>
      <link>http://arxiv.org/abs/2312.00068</link>
      <description><![CDATA[稀疏的激光雷达点云导致静态结构细节严重丢失
并减少可用于导航的静态点的密度。减少
在多种情况下，密度可能不利于导航。我们观察到
尽管稀疏性很高，但在大多数情况下，LiDAR 的全局拓扑
可以推断出静态结构的轮廓。我们利用这个属性来
获得单个静态 LiDAR 扫描的骨干骨架
连接组件是其全局拓扑的代理。我们利用
骨干沿着静态结构增加新点以克服稀疏性。
新引入的点可以对应于现有的静态结构或
先前被动态对象遮挡的静态点。尽最大努力
据我们所知，我们是第一个将这种策略用于稀疏激光雷达点的人
云。接近我们方法的现有解决方案无法识别和保留
全局静态激光雷达拓扑并生成次优点。我们建议
GLiDR，一种使用拓扑正则化的图生成网络
0 维持久同源 (PH) 约束。这使得 GLiDR 能够
沿着拓扑一致的全局静态引入更新的静态点
激光雷达骨干。 GLiDR 使用 32 倍稀疏动态生成精确的静态点
扫描和执行优于三个数据集的基线。新的
引入的静态点使 GLiDR 的性能优于基于 LiDAR 的导航
SLAM 在多种设置中。 GLiDR 产生一种有价值的副产品——准确的
静态和动态对象的二进制分割掩码，有助于
受限环境中的导航规划和安全。
]]></description>
      <guid>http://arxiv.org/abs/2312.00068</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>SICKLE：带有多个关键裁剪参数注释的多传感器卫星图像数据集。 （arXiv：2312.00069v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00069</link>
      <description><![CDATA[精心策划的数据集的可用性推动了 Machine 的成功
学习 (ML) 模型。尽管人们更容易获得地球观测数据
农业方面，缺乏经过整理和标记的数据集，这限制了
它在训练遥感 (RS) ML 模型方面的潜力
农业。为此，我们引入了一个史无前例的数据集，称为
SICKLE，它构成了 3 个多分辨率图像的时间序列
不同的卫星：Landsat-8、Sentinel-1 和 Sentinel-2。我们的数据集
2018 年 1 月期间构成多光谱、热和微波传感器 -
2021 年 3 月期间。我们通过考虑构建每个时间序列
主要从事水稻种植的农民所遵循的耕作方式
印度泰米尔纳德邦高韦里三角洲地区；并注释掉
具有多种分辨率下关键裁剪参数的相应图像
（即 3m、10m 和 30m）。我们的数据集包含 2,370 个季节样本，来自
388 个独特的地块，平均面积为 0.38 英亩，用于对 21 种作物进行分类
类型遍布三角洲 4 个地区，总数约为 209,000
卫星图像。在 2,370 个样品中，有 351 个稻田样品来自 145 个地块
用多个裁剪参数进行注释；比如水稻的品种，
生长季节和每英亩产量的生产力。我们家也是一
最早考虑生长季节活动相关的研究之一
作物物候（涵盖播种、移栽和收获日期）
感兴趣的参数。我们在三个任务上对 SICKLE 进行基准测试：作物类型、作物
物候（播种、移栽、收获）和产量预测
]]></description>
      <guid>http://arxiv.org/abs/2312.00069</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:47 GMT</pubDate>
    </item>
    <item>
      <title>MoMask：3D 人体运动的生成蒙版建模。 （arXiv：2312.00063v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00063</link>
      <description><![CDATA[我们介绍 MoMask，一种新颖的文本驱动 3D 蒙版建模框架
人体运动的产生。在MoMask中，分层量化方案是
用于将人体运动表示为多层离散运动标记
高保真细节。从基础层开始，进行一系列运动
通过向量量化得到的tokens，增加的残差tokens
订单被导出并存储在层次结构的后续层中。这
因此后面是两个不同的双向变压器。为了
基础层运动标记，指定一个 Masked Transformer 来预测
在训练阶段根据文本输入随机屏蔽运动标记。
在生成（即推理）阶段，从空序列开始，我们的
Masked Transformer 迭代地填充缺失的标记；随后，一个
Residual Transformer 学习逐步预测下一层 token
基于当前层的结果。大量的实验表明
MoMask 在文本到动作生成方面优于最先进的方法
任务，HumanML3D 数据集上的 FID 为 0.045（相对于 T2M-GPT 的 0.141），
在 KIT-ML 上分别为 0.228（vs 0.514）。 MoMask 也可以无缝
应用于相关任务，无需进一步模型微调，例如文本引导
时间修复。
]]></description>
      <guid>http://arxiv.org/abs/2312.00063</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>来自预训练扩散模型的无监督关键点。 （arXiv：2312.00065v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00065</link>
      <description><![CDATA[关键点和地标的无监督学习已经取得了显着的成果
在现代神经网络架构的帮助下取得了进步，但性能
尚未与受监督的同行相媲美，使其实用性
可疑的。我们利用文本到图像传播中的新兴知识
模型，以获得更强大的无监督关键点。我们的核心理念是找到
文本嵌入将导致生成模型始终如一地关注
图像中的紧凑区域（即关键点）。为此，我们只需优化
文本嵌入，使得去噪网络内的交叉注意力映射
局部化为具有较小标准差的高斯分布。我们验证我们的
多个数据集上的性能：CelebA、CUB-200-2011、Tai-Chi-HD、
DeepFashion 和 Human3.6m 数据集。我们取得显着改善
准确性，有时甚至优于监督的准确性，特别是对于数据
这是不结盟且较少策划的。我们的代码是公开的，可以
通过我们的项目页面找到：https://ubc-vision.github.io/StableKeypoints/
]]></description>
      <guid>http://arxiv.org/abs/2312.00065</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>利用 AI 预测乳腺癌，以进行个体风险调整 MRI 筛查和早期检测。 （arXiv：2312.00067v1 [物理.med-ph]）</title>
      <link>http://arxiv.org/abs/2312.00067</link>
      <description><![CDATA[终生患乳腺癌风险增加的女性接受补充疗法
年度筛查 MRI。我们建议预测乳房发育的风险
根据目前的 MRI，一年内患癌症，目标是减少
筛查负担并促进早期发现。人工智能算法是
12,694 名接受筛查或治疗的患者的 53,858 个乳房上出现了发育异常
诊断性 MRI 历经 12 年积累，已确诊 2,331 例癌症。第一个
U-Net 经过训练可以分割病变并识别关注区域。一秒
训练卷积网络使用特征来检测恶性癌症
由U-Net提取。然后对该网络进行微调以估计风险
在放射科医生认为正常的情况下，一年内患癌症的几率
或可能是良性的。该人工智能的风险预测是​​通过
对来自高风险筛查队列的 9,183 个乳房进行回顾性分析，
未用于训练。统计分析侧重于权衡
省略检查的次数与阴性预测值之间的关系，以及
潜在的早期检测与阳性预测值。人工智能算法
确定了 52% 的患者中与未来肿瘤一致的关注区域
筛查检测到的癌症。经过直接审查，放射科医生发现 71.3%
的癌症在诊断前与 MRI 具有明显的相关性，其中 65%
AI 模型确定了相关性。重新评估这些区域 10%
所有具有较高 AI 预测风险的病例可能导致高达 33%
放射科医生的早期检测。此外，筛查负担可能会增加
通过建议后期随访，降低了 16% 的低风险病例
不影响当前的癌症发病率。随着数据集的增加和
提高图像质量，我们期望这种新的人工智能辅助、自适应筛选能够
有意义地减轻筛查负担并改善早期发现。
]]></description>
      <guid>http://arxiv.org/abs/2312.00067</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>LEAP：法学硕士-以自我为中心的行动计划的一代。 （arXiv：2312.00055v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.00055</link>
      <description><![CDATA[我们引入了 LEAP（如图 1 所示），这是一种生成
通过使用大语言模型（LLM）的基于视频的行动计划。
这些动作程序代表了运动、知觉和结构方面
动作，由子动作、前置条件和后置条件以及控制组成
流动。 LEAP 的行动计划以自我为中心的视频为中心，并采用
法学硕士的最新发展既可以作为项目知识的来源，也可以作为
多模态视频信息的聚合器和评估器。我们将 LEAP 应用于
EPIC Kitchens 数据集的大部分 (87\%) 训练集，并发布
由此产生的行动计划作为公开可用的数据集在此处
（https://drive.google.com/drive/folders/1Cpkw_TI1IIxXdzor0pOXG3rWJWuKU5Ex?usp=drive_link）。
我们使用 LEAP 作为次要监督来源，利用其行动计划
应用于动作识别和预期网络的损失项。我们
由于训练，这两项任务的表现都得到了显着提高
与 LEAP 数据集。我们的方法在 EPIC Kitchens 上获得第一名
截至 11 月 17 日，受限制网络中的动作识别排行榜
RGB 输入（参见补充材料）。
]]></description>
      <guid>http://arxiv.org/abs/2312.00055</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>对于文本到图像生成模型，概率版权保护可能会失败。 （arXiv：2312.00057v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00057</link>
      <description><![CDATA[文本到图像生成模型的蓬勃发展引起了人们的担忧
他们制作侵犯版权内容的风险很高。虽然有概率
版权保护方法提供了针对此类行为的概率保证
侵权，在本文中，我们引入了 Virtually Assured Amplification
Attack (VA3)，一种暴露漏洞的新型在线攻击框架
这些保护机制。拟议的框架显着增强了
持续互动中产生侵权内容的概率
具有生成模型和每个模型的下限成功概率
订婚。我们的理论和实验结果表明
我们的方法的有效性并强调实施的潜在风险
文本转图像实际应用中的概率版权保护
生成模型。代码可在 https://github.com/South7X/VA3 获取。
]]></description>
      <guid>http://arxiv.org/abs/2312.00057</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>使用小波变换和深度残差神经网络进行演示攻击检测。 （arXiv：2312.00040v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00040</link>
      <description><![CDATA[生物识别身份验证在安全方面变得越来越普遍
身份验证系统。然而，生物识别物质可能会被欺骗
冒名顶替者以多种方式。在其他冒名顶替者攻击中，打印攻击、
掩码攻击和重放攻击属于演示攻击类别。
生物识别图像，尤其是虹膜和面部，很容易受到
不同的呈现攻击。这项研究应用了深度学习方法
减轻生物识别访问控制系统中的演示攻击。我们的
本文的贡献有两个：首先，我们应用了小波变换
从生物识别图像中提取特征。其次，我们修改了深度
残差神经网络并将其应用于欺骗数据集，试图
检测演示攻击。这项研究应用了所提出的方法
生物识别欺骗数据集，即 ATVS、CASIA 二类和 CASIA 裁剪图像
套。本研究中使用的数据集包含捕获的图像
受控和非受控环境以及不同的分辨率
和尺寸。我们在 ATVS Iris 数据集上获得了 93% 的最佳准确率。为了
CASIA 两类和 CASIA 裁剪数据集，我们实现了 91% 的测试准确率
和82%，分别。
]]></description>
      <guid>http://arxiv.org/abs/2312.00040</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>使用卷积神经网络和本地二进制模式进行演示攻击检测。 （arXiv：2312.00041v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2312.00041</link>
      <description><![CDATA[使用生物识别技术来验证用户身份并控制对安全的访问
近年来，生物识别访问变得非常流行
控制系统经常被政府和私人使用
公司。然而，这些系统在以下情况下可能会带来安全风险：
部署时未考虑生物特征识别攻击的可能性
（也称为欺骗）。演示攻击是一个严重的威胁，因为
他们不需要大量的时间、费用或技能来执行
对当今使用的许多生物识别系统仍然有效。这项研究
比较三种不同的基于软件的面部和虹膜方法
图像中的演示攻击检测。第一种方法使用 Inception-v3，
谷歌预训练的深度卷积神经网络（CNN）
ImageNet 挑战赛，针对这个问题进行了重新训练。第二个使用
基于改进的 Spoofnet 架构的浅层 CNN，经过训练
通常情况下。第三种是使用局部二进制模式的基于纹理的方法
（腰痛）。使用的数据集是ATVS-FIr数据集，包含真实和虚假
虹膜图像，以及 CASIA 人脸反欺骗数据集，其中包含真实的
图像以及变形照片、剪切照片和视频回放演示
攻击。我们还提出了第三组结果，基于裁剪版本
CASIA 图像。
]]></description>
      <guid>http://arxiv.org/abs/2312.00041</guid>
      <pubDate>Mon, 04 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    </channel>
</rss>