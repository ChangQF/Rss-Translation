<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Tue, 30 Jan 2024 12:23:00 GMT</lastBuildDate>
    <item>
      <title>数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aej89s/datasets/</link>
      <description><![CDATA[除了kaggle，您还从哪里获取数据集？    ;由   提交/u/joab_kc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aej89s/datasets/</guid>
      <pubDate>Tue, 30 Jan 2024 07:57:44 GMT</pubDate>
    </item>
    <item>
      <title>C/C++ 代码中的反向传播算法错误（梯度下降对我不起作用）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1adt56m/backpropagation_algorithm_error_in_cc_code/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1adt56m/backpropagation_algorithm_error_in_cc_code/</guid>
      <pubDate>Mon, 29 Jan 2024 11:27:24 GMT</pubDate>
    </item>
    <item>
      <title>中途</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1adew3t/midjourney/</link>
      <description><![CDATA[谁已经在使用 Midjourney？我需要什么工具才能开始，请帮助我   由   提交/u/Simple-Bookkeeper947  /u/Simple-Bookkeeper947 reddit.com/r/neuralnetworks/comments/1adew3t/midjourney/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1adew3t/midjourney/</guid>
      <pubDate>Sun, 28 Jan 2024 22:20:14 GMT</pubDate>
    </item>
    <item>
      <title>模型选择和对初始随机种子的敏感性。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1acsul8/model_selection_and_sensitivity_to_initial_random/</link>
      <description><![CDATA[各位聪明人， 我已经自学了机器学习几年，并且正在尝试神经网络。 专注于回归问题，我有一些关于神经网络选择的基本问题。  我正在尝试预测具有高度随机性的硬回归问题。通过算法、激活函数、插补和缩放所有修复，我注意到回归结果和准确性可能会根据不同的初始随机猜测而变化，即一切都相同，但每次运行都会产生不同的准确性。 经过几次之后运行，有一个特定的运行，我对性能感到满意，所以我节省了重量和偏差，并转向生产。  我感觉不对的是，这个特定的运行是由于特定的随机启动而起作用的。在我看来，这很容易出现过度拟合。  抱歉，非常基本，我可能会错过一些东西或完全错误，如果愚蠢的话请道歉。 干杯 尼尔森    由   提交/u/Nelson_Chow  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1acsul8/model_selection_and_sensitivity_to_initial_random/</guid>
      <pubDate>Sun, 28 Jan 2024 03:16:32 GMT</pubDate>
    </item>
    <item>
      <title>计算可比较的嵌入：两座塔、连体网络和三元组损失</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1abg6q1/compute_comparable_embeddings_two_towers_siamese/</link>
      <description><![CDATA[       由   提交/u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1abg6q1/compute_comparable_embeddings_two_towers_siamese/</guid>
      <pubDate>Fri, 26 Jan 2024 11:26:28 GMT</pubDate>
    </item>
    <item>
      <title>YOLO 揭秘：清晰指南</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19fip2c/yolo_unraveled_a_clear_guide/</link>
      <description><![CDATA[   ​ 此处 &lt; !-- SC_ON --&gt;  由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/19fip2c/yolo_unraveled_a_clear_guide/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19fip2c/yolo_unraveled_a_clear_guide/</guid>
      <pubDate>Thu, 25 Jan 2024 20:16:48 GMT</pubDate>
    </item>
    <item>
      <title>我这几天发表的每一篇博文在谷歌上的排名都在第五位以内。这一切都归功于 Junia.ai 的博客文章工作流程。以下是自动链接的预览，它将进一步提高您网站的搜索引擎优化：</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19exhkp/every_one_of_the_blog_post_i_published_in_the/</link>
      <description><![CDATA[       由   提交/u/Lunaopty  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19exhkp/every_one_of_the_blog_post_i_published_in_the/</guid>
      <pubDate>Thu, 25 Jan 2024 01:34:22 GMT</pubDate>
    </item>
    <item>
      <title>与我的人工智能伙伴 Synthia 就神经网络的复杂性进行了一场精彩的对话。 🤖✨ 查看我最新文章中的见解和问答环节。让我们一起来揭开AI的奥秘吧！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19dgjxy/engaging_in_a_fascinating_conversation_with/</link>
      <description><![CDATA[   本文采用了一种独特的方法，通过想象的神经网络进行问答环节网络。我们不会通过传统的视角深入研究错综复杂的技术，而是将神经网络拟人化，邀请它阐明其内部工作原理，揭开其决策过程的神秘面纱，并揭示其存在的细微差别。通过这种富有想象力的对话，我们的目标是以一种令人耳目一新的独特方式揭开神经网络的秘密，为读者提供一个深入而平易近人的视角来了解人工智能的迷人世界。 &lt;!-- SC_ON - -&gt;  由   提交/u/ardesai1907  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19dgjxy/engaging_in_a_fascinating_conversation_with/</guid>
      <pubDate>Tue, 23 Jan 2024 05:00:15 GMT</pubDate>
    </item>
    <item>
      <title>突然validation_loss下降到零</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19deubj/suddenly_validation_loss_drops_to_zero/</link>
      <description><![CDATA[      有人见过这样的val_dice曲线吗？ 真的不合理，max_epoch=100learning_reate=8e-4，不涉及lr_scheduler。 除了验证，训练过程也是这样，train_loss突然激增。 大家有什么想法或者建议吗？谢谢大家。 https://preview.redd.it/4nl5qakly3ec1.png?width=576&amp;format=png&amp;auto=webp&amp;s=43307a87e91072394dcc369b1dbe2f2308fdad7c ​ &lt; p&gt;https://preview.redd.it/7wbvlnu3z3ec1。 png?width=567&amp;format=png&amp;auto=webp&amp;s=b93e45020116da1dd26140559796e7abeda79346   由   提交/u/No-Supermarket-2567   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19deubj/suddenly_validation_loss_drops_to_zero/</guid>
      <pubDate>Tue, 23 Jan 2024 03:27:05 GMT</pubDate>
    </item>
    <item>
      <title>采访麻省理工学院林肯实验室的 Zack Serlin：正式方法......</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19bke9d/interview_with_zack_serlin_mit_lincoln/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19bke9d/interview_with_zack_serlin_mit_lincoln/</guid>
      <pubDate>Sat, 20 Jan 2024 20:00:19 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络中的类脑学习：综述</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19amfdl/braininspired_learning_in_artificial_neural/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2305.11252 摘要：  人工神经网络（ANN）已成为以下领域的重要工具：机器学习，在图像和语音生成、游戏和机器人等多个领域取得了显着的成功。然而，人工神经网络的运行机制与生物大脑的运行机制之间存在根本差异，特别是在学习过程方面。本文对当前人工神经网络中的类脑学习表示进行了全面回顾。我们研究了更多生物学上合理的机制的整合，例如突触可塑性，以增强这些网络的能力。此外，我们深入研究了这种方法的潜在优势和挑战。最终，我们为这个快速发展的领域的未来研究找到了有希望的途径，这可以让我们更接近理解智能的本质。    [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19amfdl/braininspired_learning_in_artificial_neural/</guid>
      <pubDate>Fri, 19 Jan 2024 16:03:08 GMT</pubDate>
    </item>
    <item>
      <title>温度、Top-k 和 Top-p 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19ahr5a/temperature_topk_and_topp_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19ahr5a/temperature_topk_and_topp_explained/</guid>
      <pubDate>Fri, 19 Jan 2024 12:14:04 GMT</pubDate>
    </item>
    <item>
      <title>全连接层。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1997h71/full_connected_layers/</link>
      <description><![CDATA[我正在尝试学习神经网络，但目前不了解很多数学知识，所以我有一个问题要问那些知道自己的知识的人关于.我在 python 中使用的神经网络是完全连接的，显然这很好，但它违背了我的直觉，也违背了我认为神经网络的好处。当然，拥有许多不同类型的连接可以存储更复杂的信息。   由   提交/u/Unlucky_Culture_6996   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1997h71/full_connected_layers/</guid>
      <pubDate>Wed, 17 Jan 2024 20:55:24 GMT</pubDate>
    </item>
    <item>
      <title>输入复杂度和所需的隐藏层之间到底有什么关系？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1995sxc/what_exactly_is_the_relationship_between_input/</link>
      <description><![CDATA[ 由   提交/u/swampshark19  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1995sxc/what_exactly_is_the_relationship_between_input/</guid>
      <pubDate>Wed, 17 Jan 2024 19:49:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 闪电模型只需很少的代码行即可完成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/</link>
      <description><![CDATA[      我刚刚建立了一个Python库来帮助构建PyTorch闪电模型只需很少的代码行。我很想听听您的想法！ https://github.com/brianrisk/lightning_factory&lt; /p&gt; 闪电工厂概览&lt; /p&gt; ​ ​   由   提交/u/qwaver-io  /u/qwaver-io  reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/</guid>
      <pubDate>Wed, 17 Jan 2024 16:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>