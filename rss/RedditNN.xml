<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Tue, 15 Apr 2025 06:30:26 GMT</lastBuildDate>
    <item>
      <title>图像分类的视觉变压器</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jz17vd/vision_transformer_for_image_classification/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/ushing-internal      [注释]            ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jz17vd/vision_transformer_for_image_classification/</guid>
      <pubDate>Mon, 14 Apr 2025 15:09:34 GMT</pubDate>
    </item>
    <item>
      <title>这个脑部计算机界面现在是一条双向街道</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jygndk/this_braincomputer_interface_is_now_a_twoway/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/keghn      [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jygndk/this_braincomputer_interface_is_now_a_twoway/</guid>
      <pubDate>Sun, 13 Apr 2025 20:04:09 GMT</pubDate>
    </item>
    <item>
      <title>网络层次结构控制混乱</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jygmra/network_hierarchy_controls_chaos/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/keghn       [注释]            ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jygmra/network_hierarchy_controls_chaos/</guid>
      <pubDate>Sun, 13 Apr 2025 20:03:25 GMT</pubDate>
    </item>
    <item>
      <title>在基于LLM的类风湿关节炎诊断中发现推理预测未对准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jxbg58/uncovering_reasoningprediction_misalignment_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项研究介绍了 PRERAID数据集 -153精心设计的临床病例，专门设计，旨在评估风湿性关节炎诊断中LLM的诊断准确性和LLM的推理质量。他们使用此数据集发现了有关诊断预测与潜在推理之间的不一致的不一致。 关键的技术发现：-LLMS（GPT -4，Claude，gemini）达到70-80％的诊断分类中的准确性为70-80％ - 但是，诊断的最佳临床推理得分最大的诊断量很大 -  GEST -GETS afterice pertive pertical pertive pertical pertistices pertistical cocive abter -ecival budt tern abor -gpt -4表现-4表现率-4 44的44级表现。 52.9% reasoning quality - When requiring both correct diagnosis AND sound reasoning, success rates dropped to 44-52% - Models frequently misapplied established diagnostic criteria despite appearing confident - The largest reasoning errors included misinterpreting laboratory results and incorrectly citing classification criteria I think this disconnect between prediction and reasoning represents a fundamental challenge for medical AI.尽管我们经常专注于准确度指标，但这项研究表明，即使是最先进的模型也可以通过有缺陷的推理过程得出正确的结论。这应该让我们停止有关在临床环境中部署的停顿 - 这种模型是“出于错误的原因”的“正确的”模型。  我认为这里的方法特别有价值 - 通过创建一个专家注释，其专家注释既关注结果和推理，   ，它们提供了一个用于评估医疗AI超过简单准确度量指标的模板。我们需要在不同的医学领域进行更多这样的评估。  tldr：即使LLM正确诊断出类风湿关节炎，他们也经常使用有缺陷的医学推理来到达那里。这揭示了预测准确性和实际临床理解之间的差距。  在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jxbg58/uncovering_reasoningprediction_misalignment_in/</guid>
      <pubDate>Sat, 12 Apr 2025 07:00:46 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的最新突破2025</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jxanp8/the_latest_breakthroughs_in_artificial/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32;  /u/codeagencyblog   [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jxanp8/the_latest_breakthroughs_in_artificial/</guid>
      <pubDate>Sat, 12 Apr 2025 06:05:43 GMT</pubDate>
    </item>
    <item>
      <title>有效的领域特定预测用于检测历史语言变化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jwk4lo/efficient_domainspecific_pretraining_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我遇到了一种聪明的方法，用于检测使用专用语言模型随时间变化的含义如何变化。研究人员开发了一种专门针对历时语言学的预处理技术（随着时间的推移，语言变化的研究）。 关键的创新是时间吸引力的掩盖。 The model learns to pay special attention to temporal context by strategically masking words that are likely to undergo semantic drift. Main technical points: * They modified standard masked language model pretraining to incorporate temporal information * Words likely to undergo semantic change are masked at higher rates * They leverage parameter-efficient fine-tuning techniques (adapters, LoRA) rather than full retraining * The approach was evaluated on standard semantic change detection benchmarks like SemEval-2020 Task 1 * Their specialized models consistently outperformed existing state-of-the-art approaches Results: * Achieved superior performance across multiple languages (English, German, Latin, Swedish) * Successfully detected both binary semantic change (changed/unchanged) and ranked semantic shift magnitude * Demonstrated effective performance even with limited training data * Showed particular strength in identifying subtle semantic shifts that general models错过的 我认为这种方法代表了我们处理专门的NLP任务的重要转变。与其为所有事物使用通用LLM，还显示了使用定制的预处理目标创建专用模型的价值。 For historical linguists and digital humanities researchers, this could dramatically accelerate the study of language evolution by automating what was previously manual analysis. The techniques here could also extend beyond linguistics to other domains where detecting subtle changes over time is important - perhaps in tracking concept drift in scientific literature or evolving terminology in specialized fields. TLDR: Researchers created specialized language models for检测单词含义随时间变化，使用新颖的时刻意识到的掩盖技术在预训练期间明显优于多种语言和基准的先前方法。  在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]     32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jwk4lo/efficient_domainspecific_pretraining_for/</guid>
      <pubDate>Fri, 11 Apr 2025 07:25:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何“地图”现实：AI中编码的指南[替代帖子]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jw9y9u/how_neural_networks_map_reality_a_guide_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我想在未来关于单物质性的curse of the Monosementity，Remensionalition of Remensionalition，以及On等等。尽管我担心某些部分可能太抽象而无法轻易理解，因此我为ML和编码进行了快速介绍，作为对这些主题的垫脚石。 它的目的不一定是为了给您完整的技术解释，而是更多的直觉，而是对他们的工作方式和他们的工作方式。希望它有帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dman140      [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jw9y9u/how_neural_networks_map_reality_a_guide_to/</guid>
      <pubDate>Thu, 10 Apr 2025 21:56:12 GMT</pubDate>
    </item>
    <item>
      <title>Pyresason -ML集成教程（二进制分类器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jw76pd/pyreason_ml_integration_tutorial_binary_classifier/</link>
      <description><![CDATA[    src =“ https://external-preview.redd.it/ik_usycdzq3_dguxdqq7xzzjv4xcazzzjv4xcaotwlnecpvowp0a.jpg？宽度= 320＆amp; crop = smart＆amp; auto = webp＆amp; s = 65E63920069F881FBA9285B78865EC55A3815B55“ title =“ pyrison -ml集成教程（二进制分类器）”/&gt;   ＆＃32;提交由＆＃32;态href =“ https://youtube.com/watch?v=_2ua1cbjwtg&amp;si = vb84b90wbzl9iknq”&gt; [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jw76pd/pyreason_ml_integration_tutorial_binary_classifier/</guid>
      <pubDate>Thu, 10 Apr 2025 19:58:37 GMT</pubDate>
    </item>
    <item>
      <title>AI的新颖可解释性方法发现神经元对齐不是深度学习的基础</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_for_ai_discovers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     tl; dr：   spotlight resonance方法（srm）表明，神经元的对准并不是基本的。相反，这是功能形式引入的各向异性的结果，例如Relu和Tanh。  这些功能破坏了旋转对称性和特定的特定方向  - 使我们的功能形式选择的     伪造，而不是深度学习的基本特性。这是通过 直接因果关系在代表性对准和激活函数之间的直接因果关系 ！  这对您意味着什么：  完全普遍的一般解释性工具建立在固体数学基础上。它可以通过： 所有架构〜所有任务〜所有层 它的通用指标，可用于优化神经元和表示之间的对齐 - 提高AI的可解释性。 使用它已经揭示了几个基本的AI发现…  p&gt; p&gt; p&gt; p&gt; &lt;强度 - 基于神经元的可解释性 - 神经元对齐是一种坐标人工制品，是人类的选择，而不是深度学习原理。激活功能创建特权方向，这是由于元素的应用（例如Relu，tanh），破坏旋转对称和偏见的代表几何。   -     -  a 几何&gt;几何&gt;几何&gt;有助于统一 ：神经元素的选择性，毫无疑问，毫无疑问，线性的不吻合，可能是新的，可能是     functions already demonstrated which affect representational geometry. - Predictive theory enabling activation function design to directly shape representational geometry — inducing alignment, anti-alignment, or isotropy — whichever is best for the task. - Demonstrates these privileged bases are the true fundamental quantity. - Presents evidence of interpretable神经元（&#39;祖母神经元&#39;）对空间上变化的天空，车辆和眼睛的反应 - 在非斜线MLPS  中。见解：  功能形式的选择→各向异性对称性破坏→基础特权→表示对准→可解释的神经元      paper介绍：    通过学习过程中的训练在训练过程中出现了直接由对称性的训练，该训练直接由对中的对称性进行训练。神经元的对齐不是基本的：更改功能基础的重新对齐。 该几何框架具有预测性，因此可以用于指导指导架构功能形式的设计，以实现表现更好的网络。使用此指标，可以优化功能形式以产生例如更强的对齐方式，因此提高了对人类安全性的网络可解释性。    它的工作原理：      srm旋转来自自私的基础的Bivector Planes中的聚光灯。使用此IT跟踪潜在层激活中的密度振荡 - 揭示了由建筑对称性破坏引起的激活聚类。 希望这对大家来说很有趣：）    🛠️代码实现     &lt;！ -  sc_on-&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_method_for_ai_discovers/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_for_ai_discovers/</guid>
      <pubDate>Thu, 10 Apr 2025 11:46:11 GMT</pubDate>
    </item>
    <item>
      <title>神经网络营销组合建模，基于变压器的渠道嵌入和L1正则化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jvtju0/neural_network_marketing_mix_modeling_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究这种使用神经网络而不是传统统计方法的新方法来营销组合建模（MMM）。 The researchers developed a specialized transformer architecture with a dual-attention mechanism designed specifically for marketing data. The key technical components: - Dual-attention mechanism that separately models immediate (performance) and delayed (brand) effects - Hierarchical attention structure with two levels: one for individual channels and another for cross-channel interactions - Specialized transformer architecture calibrated for marketing data patterns like seasonality and campaign spikes - Efficient encoding layer that converts marketing variables into embeddings while preserving temporal relationships Main results: - 22% higher prediction accuracy compared to traditional MMM approaches - Requires only 20% of the data needed by conventional methods - Successfully validated across 12 brands in retail, CPG, and电信 - 尽管模型的复杂性增加，但仍保持可解释性 - 有效地捕获了短期和长期营销效果 我认为这是公司如何处理营销分析的方式的重大转变。数据效率方面尤其重要 - 许多企业在历史数据有限的情况下挣扎，因此可以很好地执行较少数据的模型可以使高级MMM民主化。解决直接效应和延迟影响的双重注意机制似乎可以解决营销归因的基本挑战之一。   虽然计算要求对于较小的组织来说可能是陡峭的，但改善的准确性可以证明许多人的投资合理。我很想知道这种方法是如何处理有限的历史数据的新营销渠道的，本文并未完全解决该渠道。  tldr：nnn是一种专门的神经网络，用于营销组合建模，使传统方法的表现优于22％，而所需的数据则少5倍。它使用双重发音变压器体系结构来捕获跨频道的立即和延迟的营销效果。   Full Summary在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jvtju0/neural_network_marketing_mix_modeling_with/</guid>
      <pubDate>Thu, 10 Apr 2025 09:13:00 GMT</pubDate>
    </item>
    <item>
      <title>在LLM API中检测模型替代：验证方法的评估</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近遇到了一种用于检测LLM API中模型替代的新方法 - 本质上是检查API提供商是否正在用更便宜的替代方案交换您支付的型号。 研究人员开发了“ fingerprinting” a fingerprinting a＆quot a a＆quot a”可以通过分析精心制作的提示的响应模式来识别具有明显准确性的特定LLM的技术。 关键技术点： *他们的检测系统达到了98％+在区分主要LLM对之间的精确度 * OpenAI, Anthropic, and Cohere APIs * Substitution rates varied but reached up to 12% during some testing periods The methodology breaks down into three main steps: 1. Generating model-specific fingerprints through prompt engineering 2. Training a classifier on these distinctive response patterns 3. Systematically testing API endpoints to detect model switching I think this research has significant implications for how we interact与商业LLM API。作为与这些系统合作的人，我经常想知道我是否得到了要付费的确切模型，尤其是在性能似乎不一致的情况下。这为用户提供了一种验证他们收到的内容并使提供商负责的方法。 我认为，因此我们会看到对AI服务中透明度的更多需求。指纹技术可能会激发监视工具，这些工具可能成为需要一致，可预测的模型性能的企业API用户的标准实践。  tldr：研究人员开发了一种准确的方法来检测何时LLM API提供者何时秘密交换宣传模型。测试主要提供商表明，这种情况的发生比您想象的要多 - 当您要求GPT-4时，有时您可能会获得GPT-3.5-Turbo。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</guid>
      <pubDate>Wed, 09 Apr 2025 11:30:25 GMT</pubDate>
    </item>
    <item>
      <title>减少数字神经网络的记忆大小</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在运行一个完全基于numpy构建的相当简单的神经网络，并且表现良好，但是训练有素的模型的大小相当大（＆gt; 25MB）。我的模型的参数（例如，权重，偏见等）是dtype float64的，这意味着大小为768 x 768的ndarray已经产生半MB（每条条目1字节）。  我已经阅读了有关使用float32或float16作为dtypes的信息，但是它们似乎并没有减小神经网络的记忆大小，所以我想知道还有哪些其他选项？  拥有大于25MB的型号不一定是交易破坏者，但我总是会收到“大文件”。一旦我将其推向Github，就要警告，所以我想探索是否有更多轻量级的方法可以做到这一点。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1ju7ljo/reducing_the_memory_size_size_of_a_numpy_neural_neural_neal_network/]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</guid>
      <pubDate>Tue, 08 Apr 2025 07:06:50 GMT</pubDate>
    </item>
    <item>
      <title>MDS-A：用于测试时间适应的新数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32;态href =“ https://youtube.com/watch?v=MMSVSOFHNYYO＆amp; si = okj0q120f1rkbz-8”&gt; [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</guid>
      <pubDate>Mon, 07 Apr 2025 23:23:43 GMT</pubDate>
    </item>
    <item>
      <title>是真的吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  稀疏连接使输入使一组输入连接到隐藏层中的特定神经元，例如，如果您知道特定的域。但是，如果您不知道特定的域并且使其完全连接，这意味着您将所有输入连接到整个隐藏层，完全连接的网络会集中精力并尝试实现稀疏连接之类的东西吗？提交由＆＃32; /u/u/u/zestyclose-produce17     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</guid>
      <pubDate>Sun, 06 Apr 2025 14:23:40 GMT</pubDate>
    </item>
    <item>
      <title>交互式AI演示 - 可视化图像内生长的合成大脑（独立研究）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是一名独立的AI研究人员，从事两个独立但相关的实验项目。我想分享一个实时的WebGL演示，以获得反馈和好奇心。这不是商业化，不是为了游戏，而只是纯认知AI实验。  项目：神经像素AI系统 这个WebGL项目编码PNG图像中的人造大脑。目的是随着神经元从像素信息增长而来的结构和活动的出现。 每个像素编码突触或符号数据。 神经元在视觉上自我组织会随着时间的推移而自动组织。   整个系统都是确定性的，但由pseudo-eviludo-evi            href =“ https://www.dfgamesstudio.com/neural-pixel-ai-system/”&gt; https://www.dfgamesstudio.com/neural-pixel-ai-system/ 符号/认知AI架构旨在通过梦想合成，记忆衰减，情绪调节和通过一个称为“ADNσ”的系统的符号演变来模拟模块化意识。我知道这是非常规的，但我相信具有视觉逻辑的混合符号/神经系统值得探索。 谢谢！ - &gt;＆＃32;提交由＆＃32; /u/u/conanfredleseul     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</guid>
      <pubDate>Sun, 06 Apr 2025 02:19:38 GMT</pubDate>
    </item>
    </channel>
</rss>