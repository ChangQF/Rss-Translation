<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Sat, 08 Feb 2025 18:20:31 GMT</lastBuildDate>
    <item>
      <title>尝试我的新免费教育应用程序。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ikk59t/try_my_new_free_educational_app/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;  准备好使用TensorFlow优化器玩一些乐趣吗？选择您的功能，调整超参数，并使用我的新（免费和OpenSource）应用程序享受结果，使我最小化！  最小化我的应用   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/foollat​​ter2597     [link]  ＆＃32;   [注释]     /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ikk59t/try_my_new_free_educational_app/</guid>
      <pubDate>Sat, 08 Feb 2025 10:07:59 GMT</pubDate>
    </item>
    <item>
      <title>在没有模型蒸馏的语言模型中，引导性长链经过思考推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ikhom6/bootstrap_long_chainofthought_reasoning_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  螺栓引入了一种新的方法，可以改善语言模型推理而无需模型蒸馏或其他训练。关键思想是使用自举迭代的思想链，使模型可以通过自我审查和改进来改善自己的推理过程。 关键技术点： - 介绍一个多阶段的推理过程，其中模型是模型生成，审查和完善其自己的思想链 - 使用精心设计的提示来指导模型通过推理改进的不同方面 - 通过结构化的引导方法保持连贯性，该方法可以保留有效的推理，同时纠正错误时 - 与现有模型一起使用，而无需其他培训或从较大模型进行蒸馏 结果： - 与标准的经过想象的提示相比，与模型大小相比，有效地提高了多个推理基准的性能 - 更可靠的推理链 - 更好地处理复杂多步骤问题 我认为这种方法可以改变我们对提高语言模型功能的看法。与其总是需要更大的模型或更多培训，我们也许可以通过巧妙的提示和迭代策略获得更好的性能。引导技术可能可能应用于推理以外的其他类型的任务。 我认为，计算成本和提高性能之间的权衡对于实际应用而言至关重要。螺栓的迭代性质意味着更长的推理时间，但是在不进行重新训练的情况下提高推理的能力可能使许多用例中的值得。  tldr：新方法通过让他们审查和改进他们的语言模型来更好地帮助语言模型推理。自己的思想链推理。无需额外的培训，只需巧妙的提示和迭代即完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ikhom6/bootstrap_long_chainofthought_reasoning_in/</guid>
      <pubDate>Sat, 08 Feb 2025 07:13:15 GMT</pubDate>
    </item>
    <item>
      <title>使用不同的传感器数据频率，可以将Convolutuonal神经网络用于天气预测吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ik80cm/can_convolutuonal_neural_networks_be_used_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  假设有传感器以不同的间隔为1分钟，5分钟15分钟20分钟以不同的间隔为气象输入。可以训练CNN从所有这些传感器中获取数据并预测未来1小时的降雨概率吗？当新数据被用不同的传感器馈送时，它是否能够使概率更加准确？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/peneaple_throw_105      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ik80cm/can_convolutuonal_neural_networks_be_used_for/</guid>
      <pubDate>Fri, 07 Feb 2025 22:44:32 GMT</pubDate>
    </item>
    <item>
      <title>基于内容的推荐系统 - 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ik113q/contentbased_recommender_systems_explained/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/u/personal-trainer-541      link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ik113q/contentbased_recommender_systems_explained/</guid>
      <pubDate>Fri, 07 Feb 2025 17:51:30 GMT</pubDate>
    </item>
    <item>
      <title>得分流：通过基于连续得分的偏好学习优化LLM代理工作流程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ijrfu7/scoreflow_optimizing_llm_agent_workflows_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了ScoreFlow，这是一种使用连续优化和定量反馈来优化语言模型代理工作流程的新方法。关键创新是Score-DPO，它扩展了直接偏好优化以处理数值得分，而不仅仅是二进制偏好。 关键的技术方面： - 使用基于得分的梯度-Score-dpo在策略空间中连续优化包含定量反馈的损失函数 - 多代理工作流优化框架 - 基于梯度的学习，用于平滑策略更新 主要结果： - 多种任务类型的基线方法提高了8.2％ - 使用Score Flow的较小模型超过较大的较大模型基线模型 - 有效地回答，编程和数学推理任务 - 在多代理协调方案 中显示了好处 我认为这种方法对于我们需要优化复杂的代理工作流程的实用应用程序可能特别影响。使用定量反馈而不仅仅是二进制偏好的能力打开了更细微的训练信号。对于具有资源限制的部署场景而言，较小的模型可以胜过较大的模型。 我认为，连续优化方法对于代理工作流程很有意义 - 离散优化可以导致生意，无法预测的行为更改。流畅的策略更新应导致更稳定和可靠的代理行为。 我看到的主要限制是，本文没有用大量代理或潜在的不稳定性完全解决具有冲突反馈信号的潜在不稳定性。这些将是跟进工作的重要领域。  tldr：ScoreFlow使用基于连续得分的优化优化LLM代理工作流程，实现比基线更好的性能，同时使较小的型号能够胜过较大的模型。 。  完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ijrfu7/scoreflow_optimizing_llm_agent_workflows_through/</guid>
      <pubDate>Fri, 07 Feb 2025 09:47:51 GMT</pubDate>
    </item>
    <item>
      <title>通过Cauchy损失和最佳运输，强大的潜在一致性训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  潜在一致性模型（LCMS）的新训练方法修改了噪声时间表，以达到更好的图像质量，同时保持LCMS吸引人的快速推理速度。关键创新是在训练过程中引入其他中间步骤，同时保留推理时间的有效抽样过程。 主要技术点： - 修改后的噪声时间表包含训练期间更多的颗粒状步骤 - 动态加权方案调整了不同噪声的重要性级别 - 优化的采样策略平衡质量和速度 - 无需建筑变化或所需的其他参数 - 维护原始4-8步骤推理过程 结果： - 标准图像质量指标的改善15-20％ - 更好地保存精细的细节和纹理 - 与基线​​LCM的可比推理速度 - 在诸如面部之类的复杂功能上的提高性能 - 对多个标准基准测试 我认为这种方法对于质量和速度重要的实际应用可能特别有价值。在推理时间，提高输出质量而无需计算开销的能力表明，我们可能会看到生产系统中采用的这一技术。该方法也可能适用于图像生成以外的其他类型的一致性模型。 我认为关键限制是改进是随着训练复杂性的提高带来的。虽然推理仍然很快，但额外的培训步骤可能会使初始模型开发更加重要。培训期间的修改噪声调度而不是体系结构变化。 完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</guid>
      <pubDate>Thu, 06 Feb 2025 09:36:26 GMT</pubDate>
    </item>
    <item>
      <title>用于改进视力语言的特定于实例的负面挖掘，以促进分割任务的迅速生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种新方法，以使用实例特定的负面挖掘来改善跨多个任务的基于及时的分割。核心想法是挖掘每个实例特定的负面示例，以学习更好的判别特征。 关键技术点： - 使用两阶段的体系结构：提示生成，然后是负面挖掘 - 来自相似 - 在同一图像中查看实例 - 在没有特定任务培训的情况下学习实例特定的歧视功能 - 与现有的骨干网络（如Sam and Shem）集成 - 使用对比度学习，以最大程度地在正面和负面特征和负面特征 结果中最大化。改进标准基准测试（可可，ADE20K）的基线方法 - 跨多个任务的工作 - 显示更好地处理相似实例和重叠对象 - 尽管采矿步骤进行了额外的采矿步骤 - 在基于及时的细分任务上达到SOTA，但仍保持竞争性推理速度 我认为，这种方法对于我们需要可以处理多个任务的灵活分割系统的现实应用程序可能会产生影响。特定于实例的负面挖掘似乎是一种自然的方法，可以帮助模型学习更多强大的功能，尤其是在具有相似对象的情况下。在部署方案中，它在没有特定任务的培训的情况下起作用的事实特别有趣。 我看到的主要限制是采矿过程中的计算开销，尽管作者报告了影响易于管理。我很想知道如何使用许多类似对象的对象来扩展到非常大的场景。  tldr：使用实例特定的负面挖掘的新实例分割方法，可以提高未经特定于任务培训的多个任务的准确性。通过学习的判别特征可以更好地处理类似对象。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</guid>
      <pubDate>Wed, 05 Feb 2025 09:57:06 GMT</pubDate>
    </item>
    <item>
      <title>凸优化理论预测了大语言模型的最佳学习率时间表</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ihgfao/convex_optimization_theory_predicts_optimal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文在现代深度学习中使用的经典凸优化理论与经验成功的学习率计划之间建立了关键联系。研究人员得出了数学证据，表明余弦学习率衰减自然来自优化范围。 主要技术要点： - 开发的理论框架与深度学习计划连接经典优化 - 证明余弦衰减时间表可最大程度地减少convex的融合界限问题 - 显示线性热身通过优化镜头具有理论上的理由 - 在ImageNet，语言模型和其他标准基准上进行了验证的结果 - 发现使用理论上最佳的时间表 发现最终模型性能提高了10-15％为主要通过反复试验开发的实践提供了宝贵的数学基础。虽然分析侧重于凸病例，但与经验结果的一致性表明，见解很好地转移到了深度学习中。这些证明可以帮助开发更好的自动调度方法。 我认为可以扩展框架以分析其他训练组件，例如动量和重量衰减。与经典优化理论的联系为利用数十年的理论工作开辟了可能性。  tldr：研究证明了流行的学习速率时间表（余弦衰减，线性热身）在理论上是凸优化的最佳选择，与经验的发现相匹配。结果验证了当前的实践并为改进培训方法提供了基础。 &gt;完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ihgfao/convex_optimization_theory_predicts_optimal/</guid>
      <pubDate>Tue, 04 Feb 2025 12:22:37 GMT</pubDate>
    </item>
    <item>
      <title>彼得·萨特（Peter Sutor）第1部分（访谈）的高维计算（HDC）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1igtag7/hyperdimensional_computing_hdc_with_peter_sutor/</link>
      <description><![CDATA[   &lt;A href =“ https://www.reddit.com/r/nealurnetworks/comments/comments/1igtag7/hyperdimensional_computing_hdc_with_with_with_peter_peter_sutor_sutor_sutor_sutor/” 1 (Interview)&quot; src=&quot;https://external-preview.redd.it/4BIXZ9D2AObAHxxh29oFMhMercVoKSpeXfUs7Tw4rQ8.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=386e944cf63091dcf8f48a1bc874cdd82fec00f9&quot; title=&quot;Hyperdimensional Computing (HDC) with Peter辅助第1部分（访谈）“/&gt;   ＆＃32;提交由＆＃32; /u/u/u/neurosymbolic     [link]   ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1igtag7/hyperdimensional_computing_hdc_with_peter_sutor/</guid>
      <pubDate>Mon, 03 Feb 2025 16:37:26 GMT</pubDate>
    </item>
    <item>
      <title>计算隐藏层的批处理规范</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我试图理解隐藏层的批处理规范的详细信息。我知道，对于给定的神经元，例如x  l ，我们需要在所有迷你批次样本上计算平均值和差异，以在将其激活中进行标准化，然后再将其喂入下一层。&lt; 我想了解上述计算是如何完成的。一种方法可能是处理迷你批次的每个元素并在L层中收集神经元的统计数据，并忽略后续层。一旦计算了L层中所有元素的均值和差异，请再次处理L+1层的小批量元素，依此类推。这似乎很浪费。这是正确的吗？ 如果没有，请分享所执行的确切计算的描述。我混淆的根源是，L层中的标准化会影响为L+1层的值。因此，除非我们知道L层L层的均值和差异，否则我们如何将下一层标准化。预先感谢您。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/far-cantaloupe4144      [link]  ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</guid>
      <pubDate>Mon, 03 Feb 2025 06:09:34 GMT</pubDate>
    </item>
    <item>
      <title>曲率引导的Langevin Monte Carlo用于多速度参数估计</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文使用曲率引导的langevin monte carlo（CLMC）介绍了一种新的方法，用于估算多CHIRP信号的参数。关键创新是将参数空间中的几何信息与随机抽样相结合，以更好地处理重叠的频率组件。 主要技术贡献： - 将曲率信息集成到langevin Monte Carlo框架中 - 基于自适应步骤尺寸机制局部几何特性 - 参数空间中处理多模式分布的新方法 - 用于指导采样的二阶信息的实现 结果显示： - 与标准方法相比，参数估计的准确性提高了，相比之下SNR条件（显示为-5dB） - 与传统LMC相比，更可靠的紧密间隔频率组件分离 - 更快的收敛速度 - 成功处理多达4个重叠的Chirp组件 我认为这项工作可以打开新的可能性对于雷达和声纳等应用，精确的频率分析至关重要。更好地分开重叠组件的能力对于信号明确性至关重要的无线通信和医学成像应用程序可能特别有价值。 我认为，主要限制是计算复杂性缩放的组件数量，这可能会限制真实 - 时间应用程序。该方法还需要仔细的参数调整，这可能会使实际部署具有挑战性。  tldr：新方法将曲率信息与langevin Monte Carlo结合在一起，以提高多种速度参数估计，显示出提高的精度和稳健性。组件。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</guid>
      <pubDate>Sun, 02 Feb 2025 20:11:28 GMT</pubDate>
    </item>
    <item>
      <title>Elman网络 - 您能解释一下它们是什么以及它们的工作方式吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/no_refrigerator_7841      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</guid>
      <pubDate>Sat, 01 Feb 2025 22:08:02 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt由其中的1亿[the Perceptron]制成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</link>
      <description><![CDATA[   &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1ifg22m/chatgpt_is_is_made_made_from_100_100_million_million_of_these_these_these_these_the_the/ The Perceptron]&quot; src=&quot;https://external-preview.redd.it/U1IJ9eKTia76Ow5ICVeLU61NCB0VVx601um6MG5Ptj0.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2ae8cfdcbe86ede11fe4e7902603fb428ebd0c3d&quot; title=&quot;ChatGPT is made from 100 million of these [perceptron]“/&gt;   ＆＃32;提交由＆＃32; /u/keghn     [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</guid>
      <pubDate>Sat, 01 Feb 2025 20:51:43 GMT</pubDate>
    </item>
    <item>
      <title>让PPL访问免费GPU-会喜欢Beta反馈🦾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨！我是一家YC支持公司的创始人，我们正在努力使训练ML型号非常容易且非常便宜。在接下来的两个星期中，我们正在运行 *免费 * Beta，并会喜欢您的一些反馈。  如果听起来很有趣，请随时在此处查看我们： https://github.com/tensorpool/tensorpool/tensorpool    tldr;免费gpus😂  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/joshkmartinez     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1iffhll/giving_ppl_access_to_free_gpus_gpus_gpus_would_love_beta/”]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Sat, 01 Feb 2025 20:26:06 GMT</pubDate>
    </item>
    <item>
      <title>接地的文本对图像扩散模型，用于受控高质量图像生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了object-diffusion，该模型在对象名称和边界框上调节文本到图像扩散模型以启用对象的精确渲染和放置在特定位置。 对象散布将控制网的架构与Gligen的接地技术集成在一起，并显着提高了受控图像生成的精度和质量。 该模型优于当前状态 - 在开源数据集接受培训的艺术模型，在精确度和质量指标方面取得了显着改进。 对象散布可以综合多样，高质量的高效率图像，这些图像始终与指定的控制布局保持一致。 p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/next_cockhack_2615      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</guid>
      <pubDate>Thu, 30 Jan 2025 00:30:50 GMT</pubDate>
    </item>
    </channel>
</rss>