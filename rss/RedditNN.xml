<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Thu, 07 Mar 2024 18:16:24 GMT</lastBuildDate>
    <item>
      <title>了解注意力和变压器的资源</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</link>
      <description><![CDATA[请分享一些好的资源（文章、YouTube 视频），以易于理解的方式解释注意力和 Transformers 的概念。我看过一些视频，但不太明白。还有任何可以帮助我更好地理解这一点的先决条件。   由   提交/u/Anxious-Buddha  /u/Anxious-Buddha reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</guid>
      <pubDate>Tue, 05 Mar 2024 17:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如何找到其他网络来对我创建的数据集进行基准测试？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</link>
      <description><![CDATA[大家好。我开发了一个使用 Transformer 架构的动态手势识别系统。因为手势集是 nieche，所以我必须创建自己的数据集。 我的数据形状是 X.shape = (样本数，时间序列长度，特征数） y.shape =（样本数，类数） 其中样本数是总量每个类别的样本总数。每个样本的时间序列和特征的长度都是恒定的。 Y 是一个单热编码向量，其中每个真实类别用 1 标记，行的其余部分为零。 &lt; p&gt;我想用其他网络测试我的数据集，但是，我很难找到接受此数据格式的其他网络。您可以推荐什么作为搜索关键字？或者我应该以不同的方式格式化我的数据？   由   提交/u/ege6211  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</guid>
      <pubDate>Tue, 05 Mar 2024 13:08:11 GMT</pubDate>
    </item>
    <item>
      <title>如果您知道，请向我解释一下 Synthesia AI 视频生成器的工作原理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</link>
      <description><![CDATA[他们正在通过视频神经合成生成视频。请帮助我了解它是如何工作的。 https://www.synthesia.io   由   提交 /u/Acrobatic-Jaguar-599   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</guid>
      <pubDate>Mon, 04 Mar 2024 20:11:36 GMT</pubDate>
    </item>
    <item>
      <title>LLM 分词器解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</guid>
      <pubDate>Sun, 03 Mar 2024 10:17:54 GMT</pubDate>
    </item>
    <item>
      <title>卡尔加里大学推出改变游戏规则的结构化稀疏方法：SRigL</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</guid>
      <pubDate>Sun, 03 Mar 2024 07:48:03 GMT</pubDate>
    </item>
    <item>
      <title>仓储物流中的计算机视觉</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b43x7b/computer_vision_in_warehousing_and_logistics/</link>
      <description><![CDATA[     &lt; /td&gt; 在此 文章您将了解计算机视觉如何优化物流和仓储流程。  仓储行业正在快速适应在线购物的需求。计算机视觉改善库存管理、流程优化和质量控制。它可以自动执行手动任务并优化许多操作。OpenCV.ai 团队描述了该领域最流行的 AI 实施用例。  更多详细信息为此处  https://reddit.com/link/1b43x7b/ video/6569h6yq3slc1/player   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1b43x7b/computer_vision_in_warehousing_and_logistics/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b43x7b/computer_vision_in_warehousing_and_logistics/</guid>
      <pubDate>Fri, 01 Mar 2024 20:02:27 GMT</pubDate>
    </item>
    <item>
      <title>集中您的注意力（使用自适应 IIR 滤波器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</link>
      <description><![CDATA[EMNLP 2023：https://aclanthology.org/2023.emnlp-main.772/ arXiv：https://arxiv.org/abs/2305.14952 OpenReview：https://openreview.net/forum?id=DlQeSfGYfS 摘要：  我们提出了一个新层，其中使用二阶动态（即依赖于输入的）无限脉冲响应（IIR）滤波器来处理应用常规注意之前的输入序列。输入被分成块，并且这些滤波器的系数是根据先前的块确定的，以保持因果关系。尽管其阶数相对较低，但因果自适应滤波器将注意力集中在相关序列元素上。新层以控制理论为基础，并被证明可以推广对角状态空间层。该层的性能与最先进的网络相当，参数仅为其一小部分，时间复杂度与输入大小成次二次方。无论是在参数数量还是在多个远程序列问题上获得的性能水平方面，所获得的层都优于 Hyena、GPT2 和 Mega 等层。     由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</guid>
      <pubDate>Thu, 29 Feb 2024 10:49:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyReason 进行推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</guid>
      <pubDate>Wed, 28 Feb 2024 16:53:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Real-ESRGAN 改善低分辨率图像和视频？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</link>
      <description><![CDATA[      https://preview.redd.it/xgzciubci2lc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=7e52aa3f9827f91 5e724fa50258c1abd669cfdc1 在本教程中，我们将学习如何将低分辨率图像改进为高分辨率结果。 我们将使用相关的 Python 库创建一个新的 Conda 环境。然后，我们将学习如何使用 real-ESRGAN 提高图像和视频的质量。 您可以在此处找到视频教程的链接：https://youtu.be/d-CPvHkltXA 您可以在此处找到说明：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/Real-ESRGAN 享受 Eran #realesrgantutorial #RealESRGAN #realesrgantutorial #improveimagequality #improveimageresolution #realesrganimageupscaler #realesrganimageupscaler #aiimageupscalerfree #freeaiimageupscaling #python #RealESRGAN #increaseimageresolution   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</guid>
      <pubDate>Tue, 27 Feb 2024 05:57:14 GMT</pubDate>
    </item>
    <item>
      <title>选择您自己的编码助手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/High_Sleep3694   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</guid>
      <pubDate>Mon, 26 Feb 2024 11:26:52 GMT</pubDate>
    </item>
    <item>
      <title>液体神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</link>
      <description><![CDATA[大家好，请问您能给我提供学习LNN（液体神经网络）的资源或工具（代码，最好使用TF）或路线图吗因为我有一个项目要在现实生活中的某个应用程序上处理它们。我已经对 ML、神经网络、CNN、RNN、LSTM、迁移学习有很强的背景。非常感谢您的帮助！    由   提交/u/Hussein_Jammal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</guid>
      <pubDate>Mon, 26 Feb 2024 07:12:08 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec 使用的单词数？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b060r6/number_of_words_to_use_for_a_word2vec/</link>
      <description><![CDATA[如果我使用 word2vec 为另一个进行情感分析的网络标记单词，我应该用多少个单词来训练它？如果我最多使用第 n 个最常用的单词，那么电子邮件中包含不在数据集中的单词的可能性有多大？我试图找到第 10,000 个最常见单词的频率，但没有成功。   由   提交 /u/ConflictUnfair   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b060r6/number_of_words_to_use_for_a_word2vec/</guid>
      <pubDate>Mon, 26 Feb 2024 02:09:10 GMT</pubDate>
    </item>
    <item>
      <title>超参数调整：网格搜索与随机搜索</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ayc7dp/hyperparameters_tuning_grid_search_vs_random/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ayc7dp/hyperparameters_tuning_grid_search_vs_random/</guid>
      <pubDate>Fri, 23 Feb 2024 21:24:48 GMT</pubDate>
    </item>
    <item>
      <title>像我 5 岁一样解释扩散模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ayc6fd/explain_diffusion_models_like_im_5/</link>
      <description><![CDATA[有人可以帮助我理解扩散模型吗？我已经快到了，但还没有完全实现。 我知道您拍摄一张图像，逐步为其添加噪点，然后从中去除一些噪点，并以稍微较少的噪点重复此操作，直到您知道要添加多少噪点。删除即可得到原始图像。我还了解到，您可以在其中添加文本编码以创建文本标题和生成的图像之间的相关性。但是如何生成图像？ 当我提供提示时，反向扩散模型是否给出了一组全新的、完全随机的噪声？然后利用如何去除噪声的先验知识来获得图像？ 如果是这样，语义从哪里出现并带有以前从未见过的提示？我隐约了解 U-net 以及如何从中生成语义和掩码，但是它在扩散过程中的哪个位置？ TYIA!! &lt;!-- SC_ON - -&gt;  由   提交/u/Alternative_Leg_3111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ayc6fd/explain_diffusion_models_like_im_5/</guid>
      <pubDate>Fri, 23 Feb 2024 21:23:45 GMT</pubDate>
    </item>
    <item>
      <title>图像分割神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1axwssm/image_segmentation_neural_network/</link>
      <description><![CDATA[大家好，我第一次发帖，我有一个问题：我可以采用语义神经网络并将其更改为现在有一个注意力块吗？就像是否有一个已知的程序可以将一个图像的神经网络更改为另一个图像+其显着图的神经网络？ 这是为了比较，以了解注意块对分割的总体结果。   由   提交/u/karimredditor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1axwssm/image_segmentation_neural_network/</guid>
      <pubDate>Fri, 23 Feb 2024 09:54:02 GMT</pubDate>
    </item>
    </channel>
</rss>