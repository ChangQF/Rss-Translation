<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Fri, 15 Nov 2024 01:19:47 GMT</lastBuildDate>
    <item>
      <title>SWE-agent：优化代理-计算机接口以实现自动化软件工程任务</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1grkc2e/sweagent_optimizing_agentcomputer_interfaces_for/</link>
      <description><![CDATA[我一直在阅读 SWE-agent 论文，其中介绍了一种自定义代理-计算机接口 (ACI)，使语言模型能够自主执行软件工程任务。关键创新在于如何构建 LM 和计算机环境之间的接口，以实现更有效的代码操作和测试。 主要技术要点： - 构建自定义 ACI，为代码编辑、文件导航和执行提供结构化的交互模式 - 使用语言模型在 ACI 框架内生成响应 - 在 SWE-bench 上进行评估，成功率达到 12.5%，而之前使用 RAG 的成功率为 3.8% - 界面允许通过执行反馈进行迭代开发 - 结合文件系统导航和多文件编辑功能 主要结果： - 与之前的方法相比，SWE-bench 基准测试提高了 3 倍以上 - 代理可以成功导航代码库、修改多个文件并验证更改 - 性能因任务复杂性和代码库大小而有很大差异 - 界面设计选择强烈影响代理功能和成功率 这对于实际的自动化软件工程具有重要意义。结果表明，精心设计的 LM 和计算机环境之间的接口可以显著提高它们完成实际编程任务的能力。这指向了构建功能更强大的自动化编程系统的潜在方法，尽管在扩展到更复杂的任务方面仍然存在重大挑战。 TLDR：本文介绍了一种代理-计算机接口，可帮助语言模型更好地与编程环境交互，通过结构化的交互模式在软件工程基准测试任务上显示出 3 倍的改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1grkc2e/sweagent_optimizing_agentcomputer_interfaces_for/</guid>
      <pubDate>Fri, 15 Nov 2024 00:58:43 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型是进化算法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gr7rjt/diffusion_models_are_evolutionary_algorithms/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gr7rjt/diffusion_models_are_evolutionary_algorithms/</guid>
      <pubDate>Thu, 14 Nov 2024 15:47:57 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的单一关键参数：检测及其对模型性能的影响</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gr6uc7/single_critical_parameters_in_large_language/</link>
      <description><![CDATA[我一直在阅读这篇关于大型语言模型中的“超权重”的论文 - 参数的数量级明显大于典型分布。研究人员分析了这些异常权重在几种流行的 LLM 架构中的存在及其影响。 关键技术贡献是对 LLM 中权重分布的系统分析，并提出了在训练和部署期间识别/处理超权重的方法。他们引入了量化“超权重现象”的指标以及在模型优化过程中管理这些异常值的技术。 主要发现： - 超级权重通常出现在不同的 LLM 架构中，通常比中值权重大 2-3 个数量级 - 尽管这些异常值占权重的 &lt;1%，但它们可以占总参数幅度的 10-30% - 标准量化方法在超级权重上表现不佳，导致准确性显着下降 - 提出的专门处理方法可以在保留超级权重信息的同时改善模型压缩 对于模型优化和部署具有重要的实际意义： - 当前的压缩技术可能会因错误处理超级权重而无意中降低模型性能 - 需要更复杂的量化方案来考虑整个权重范围 - 训练程序可能会进行修改以鼓励更均衡的权重分布 - 了解超级权重可以带来更高效的模型架构 TLDR：LLM 通常包含“超级权重”，尽管很少见，但具有巨大影响力。论文分析了这种现象，并提出了在模型优化和部署过程中处理这些异常值的更好方法。 完整摘要在此处。论文此处。    提交人    /u/Successful-Western27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gr6uc7/single_critical_parameters_in_large_language/</guid>
      <pubDate>Thu, 14 Nov 2024 15:07:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 RAM 瓶颈问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gqlkfq/how_to_resolve_ram_bottleneck_issues/</link>
      <description><![CDATA[我当前的项目有两层： - 一个转换器，用于在非常专业的训练集上训练词嵌入； - 一个附加神经网络，它将回收这些词嵌入以训练句子相似度。 现在，我正在一台共享电脑上进行训练，其（理论）RAM 容量为 32gb，尽管由于多个用户在服务器上工作，可用 RAM 通常只有其一半，而且随着数据集的增加，这似乎会导致瓶颈。目前，由于内存限制，我无法在 50 万个句子上进行训练。 可以说，我编写代码的方式可能不是超级高效。本质上，我循环遍历样本集，将每个句子编码为初始张量（平均池化词嵌入），并将张量存储在列表中以进行训练。这意味着在训练期间，所有 500k 张量始终位于 RAM 中，我不确定是否有更有效的方法来做到这一点。 或者，我考虑在云中进行训练。实际上，当前的训练集仍然很小，我预计它在未来会显着增加。在这种情况下，机密性和安全性是关键，我想知道哪些平台值得研究？ 感谢任何反馈！    提交人    /u/RDA92   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gqlkfq/how_to_resolve_ram_bottleneck_issues/</guid>
      <pubDate>Wed, 13 Nov 2024 19:42:01 GMT</pubDate>
    </item>
    <item>
      <title>从零开始实现分层图像分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gqj2sr/hierarchical_image_classification_from_scratch/</link>
      <description><![CDATA[      您好，是否可以使用 Keras 等框架实现分层图像分类？是否可以导出这些以进行部署？谢谢。 PS：抱歉我的英语不好。 https://preview.redd.it/5qo7kdl47p0e1.png?width=481&amp;format=png&amp;auto=webp&amp;s=54104e82454a52978d1db9512518a82ac94b8363    提交人    /u/Zealousideal-Sea3892   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gqj2sr/hierarchical_image_classification_from_scratch/</guid>
      <pubDate>Wed, 13 Nov 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>🚀 分析了各种 TTS 模型在不同输入长度（从 5 个单词到 200 个单词）下的延迟！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gp07vz/analyzed_the_latency_of_various_tts_models_across/</link>
      <description><![CDATA[       由    /u/rbgo404  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gp07vz/analyzed_the_latency_of_various_tts_models_across/</guid>
      <pubDate>Mon, 11 Nov 2024 19:06:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么 model_q4.onnx 和 model_q4f16.onnx 不是比 model.onnx 小 4 倍？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</link>
      <description><![CDATA[我在https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/tree/main/onnx:上看到&gt;   文件名 大小    model.onnx 654 MB   model_fp16.onnx 327 MB   model_q4.onnx 200 MB   model_q4f16.onnx 134 MB   我的理解是：  model.onnx 是 fp32 模型， model_fp16.onnx 是权重量化为 fp16 的模型  我不明白 model_q4.onnx 和 model_q4f16.onnx 的大小&gt;  为什么 model_q4.onnx 是 200 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4.onnx 意味着权重被量化为 4 位。 为什么 model_q4f16.onnx 是 134 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4f16.onnx 意味着权重被量化为 4 位并且激活是 fp16，因为 https://llm.mlc.ai/docs/compilation/configure_quantization.html 指出：  qAfB(_id)，其中 A 表示用于存储权重的位数，B 表示用于存储激活的位数。   并且在张量流的神经网络量化框架中，为什么激活需要比权重（8 位）更多的位（16 位）？ 表示激活不计入模型大小（可以理解）。     提交人    /u/Franck_Dernoncourt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</guid>
      <pubDate>Fri, 08 Nov 2024 17:36:44 GMT</pubDate>
    </item>
    <item>
      <title>能“嗅觉”的人工智能？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</link>
      <description><![CDATA[我一直在阅读有关 Osmo 的文章，这是一家初创公司，它使用人工智能通过分析气味的分子结构来预测和重现气味，他们认为这可能会影响从医疗保健到香水等领域。 想到机器以这种精确度“嗅觉”真是令人着迷，但我很好奇——这实际上会如何改变我们体验周围世界的方式？我想我很难看到人工智能驱动的气味技术能够以实际或意想不到的方式影响日常生活或特定行业，所以我想听听不同的观点。    提交人    /u/Frosty_Programmer672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</guid>
      <pubDate>Thu, 07 Nov 2024 13:47:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么深度学习的热潮让几乎所有人都感到意外</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gl6uvr/why_the_deep_learning_boom_caught_almost_everyone/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gl6uvr/why_the_deep_learning_boom_caught_almost_everyone/</guid>
      <pubDate>Wed, 06 Nov 2024 19:31:11 GMT</pubDate>
    </item>
    <item>
      <title>第一次尝试：训练并使用 NN 模型进行“与训练集相似的摄影”选择，有什么建议吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gl0r7d/first_try_training_and_using_nn_model_for/</link>
      <description><![CDATA[大家好！ 我对训练一个 NN 模型很感兴趣，该模型将为我执行“最佳照片选择”过程。 作为一名业余体育摄影师，我想自动化处理所拍摄照片的初始“好照片”步骤。 假设：使用数千张“好”通过之前选择并发布的不同环境和不同人群中特定体育活动的图像，我可以训练一些 CV NN 模型来对我提供的新图像进行评分，从而自动完成初始照片选择的过程。 目前，我已经开始深入研究微调基线训练的 ViT 模型（https://huggingface.co/google/vit-base-patch16-224 获取模型及其简介）。 我的初始训练代码： # Training loop for epoch in range(10): for i, (images, labels) in enumerate(train_loader): output = model(images, labels=labels) loss = output.loss loss.backward() optimizer.step() optimizer.zero_grad() if i % 100 == 0: print(f&#39;Epoch [{epoch+1}/{10}], 步骤 [{i+1}/{len(train_loader)}], 损失：{loss.item():.4f}&#39;)  我使用上面的代码对一些非常压缩的照片（从 2000x3000 的图片到正方形 224x224）进行了 100 次编码训练，并使其对一张图像进行评分，使用我能从中抓取的第一件事，使用模糊的常识，谷歌和谷歌双子座的建议，即 cosine_similarity(a, b): return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)) 即我训练一个模型，让它对我的参考图像进行分类（返回每个图像的特征，作为所有参考图像的 .logits.squeeze），然后我让它对我的测试图像进​​行分类，然后我比较测试图像特征与所有参考图像特征的余弦相似度，得到一个余弦相似度列表。 所以，问题是： - 我是否在朝着正确的方向挖掘？VisionTransformer 是一个不错的选择吗，或者某些 CNN 变体在我的训练池大小上会更加稳健？ - 提高训练重要性是否能让我制作一个合理微调的模型？ - 我可以使用哪些其他方法将模型输出用作测试图像的识别分数？ 老实说，NN 不是我的专业领域，所以我愿意接受建议。    提交人    /u/Xenolog   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gl0r7d/first_try_training_and_using_nn_model_for/</guid>
      <pubDate>Wed, 06 Nov 2024 15:13:28 GMT</pubDate>
    </item>
    <item>
      <title>网络物理系统中的元认知</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</guid>
      <pubDate>Mon, 04 Nov 2024 12:49:25 GMT</pubDate>
    </item>
    <item>
      <title>正确的模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</link>
      <description><![CDATA[因此，我的任务是根据之前的值和下一个变量（例如电机的速度和旋转）预测无人机的电池消耗。 我会使用 RNN（类似 LSTM）来根据之前的值预测下一个值，但也有其他依赖于电池消耗的参数（电机旋转、位置等...）。 我应该使用什么模型？    提交人    /u/martin3698753   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</guid>
      <pubDate>Mon, 04 Nov 2024 09:46:45 GMT</pubDate>
    </item>
    <item>
      <title>提高直播视频质量</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</link>
      <description><![CDATA[我收到了一个有很多噪音和伪影的模拟视频。假设我通过数字转换器播放了这个视频，但质量仍然很差。是否有任何神经网络可以在没有大延迟的情况下从实时视频中去除噪音和伪影？    提交人    /u/Braven111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</guid>
      <pubDate>Mon, 04 Nov 2024 08:39:29 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶加权神经网络：提高效率和性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</link>
      <description><![CDATA[       由    /u/musescore1983  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</guid>
      <pubDate>Mon, 04 Nov 2024 05:56:00 GMT</pubDate>
    </item>
    <item>
      <title>还没有见过很多代表训练网络中权重的图像。它们很漂亮。这是我的。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</link>
      <description><![CDATA[        提交者    /u/bombsy_rosalina   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</guid>
      <pubDate>Sun, 03 Nov 2024 21:29:21 GMT</pubDate>
    </item>
    </channel>
</rss>