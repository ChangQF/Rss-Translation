<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Fri, 11 Apr 2025 06:27:09 GMT</lastBuildDate>
    <item>
      <title>神经网络如何“地图”现实：AI中编码的指南[替代帖子]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jw9y9u/how_neural_networks_map_reality_a_guide_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我想在未来关于单物质性的curse of the Monosementity，Remensionalition of Remensionalition，以及On等等。尽管我担心某些部分可能太抽象而无法轻易理解，因此我为ML和编码进行了快速介绍，作为对这些主题的垫脚石。 它的目的不一定是为了给您完整的技术解释，而是更多的直觉，而是对他们的工作方式和他们的工作方式。希望它有帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dman140     link link link&gt; [link]&gt; [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jw9y9u/how_neural_networks_map_reality_a_guide_to/</guid>
      <pubDate>Thu, 10 Apr 2025 21:56:12 GMT</pubDate>
    </item>
    <item>
      <title>Pyresason -ML集成教程（二进制分类器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jw76pd/pyreason_ml_integration_tutorial_binary_classifier/</link>
      <description><![CDATA[    src =“ https://external-preview.redd.it/ik_usycdzq3_dguxdqq7xzzjv4xcazzzjv4xcaotwlnecpvowp0a.jpg？宽度= 320＆amp; crop = smart＆amp; auto = webp＆amp; s = 65E63920069F881FBA9285B78865EC55A3815B55“ title =“ pyrison -ml集成教程（二进制分类器）”/&gt;   ＆＃32;提交由＆＃32;态href =“ https://youtube.com/watch?v=_2ua1cbjwtg&amp;si = vb84b90wbzl9iknq”&gt; [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jw76pd/pyreason_ml_integration_tutorial_binary_classifier/</guid>
      <pubDate>Thu, 10 Apr 2025 19:58:37 GMT</pubDate>
    </item>
    <item>
      <title>AI的新颖可解释性方法发现神经元对齐不是深度学习的基础</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_for_ai_discovers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     tl; dr：   spotlight resonance方法（srm）表明，神经元的对准并不是基本的。相反，这是功能形式引入的各向异性的结果，例如Relu和Tanh。  这些功能破坏了旋转对称性和特定的特定方向  - 使我们的功能形式选择的     伪造，而不是深度学习的基本特性。这是通过 直接因果关系在代表性对准和激活函数之间的直接因果关系 ！  这对您意味着什么：  完全普遍的一般解释性工具建立在固体数学基础上。它可以通过： 所有架构〜所有任务〜所有层 它的通用指标，可用于优化神经元和表示之间的对齐 - 提高AI的可解释性。 使用它已经揭示了几个基本的AI发现…  p&gt; p&gt; p&gt; p&gt; &lt;强度 - 基于神经元的可解释性 - 神经元对齐是一种坐标人工制品，是人类的选择，而不是深度学习原理。激活功能创建特权方向，这是由于元素的应用（例如Relu，tanh），破坏旋转对称和偏见的代表几何。   -     -  a 几何&gt;几何&gt;几何&gt;有助于统一 ：神经元素的选择性，毫无疑问，毫无疑问，线性的不吻合，可能是新的，可能是     functions already demonstrated which affect representational geometry. - Predictive theory enabling activation function design to directly shape representational geometry — inducing alignment, anti-alignment, or isotropy — whichever is best for the task. - Demonstrates these privileged bases are the true fundamental quantity. - Presents evidence of interpretable神经元（&#39;祖母神经元&#39;）对空间上变化的天空，车辆和眼睛的反应 - 在非斜线MLPS  中。见解：  功能形式的选择→各向异性对称性破坏→基础特权→表示对准→可解释的神经元      paper介绍：    通过学习过程中的训练在训练过程中出现了直接由对称性的训练，该训练直接由对中的对称性进行训练。神经元的对齐不是基本的：更改功能基础的重新对齐。 该几何框架具有预测性，因此可以用于指导指导架构功能形式的设计，以实现表现更好的网络。使用此指标，可以优化功能形式以产生例如更强的对齐方式，因此提高了对人类安全性的网络可解释性。    它的工作原理：      srm旋转来自自私的基础的Bivector Planes中的聚光灯。使用此IT跟踪潜在层激活中的密度振荡 - 揭示了由建筑对称性破坏引起的激活聚类。 希望这对大家来说很有趣：）    🛠️代码实现     &lt;！ -  sc_on-&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_method_for_ai_discovers/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jvvwik/novel_interpretability_method_for_ai_discovers/</guid>
      <pubDate>Thu, 10 Apr 2025 11:46:11 GMT</pubDate>
    </item>
    <item>
      <title>神经网络营销组合建模，基于变压器的渠道嵌入和L1正则化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jvtju0/neural_network_marketing_mix_modeling_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究这种使用神经网络而不是传统统计方法的新方法来营销组合建模（MMM）。 The researchers developed a specialized transformer architecture with a dual-attention mechanism designed specifically for marketing data. The key technical components: - Dual-attention mechanism that separately models immediate (performance) and delayed (brand) effects - Hierarchical attention structure with two levels: one for individual channels and another for cross-channel interactions - Specialized transformer architecture calibrated for marketing data patterns like seasonality and campaign spikes - Efficient encoding layer that converts marketing variables into embeddings while preserving temporal relationships Main results: - 22% higher prediction accuracy compared to traditional MMM approaches - Requires only 20% of the data needed by conventional methods - Successfully validated across 12 brands in retail, CPG, and电信 - 尽管模型的复杂性增加，但仍保持可解释性 - 有效地捕获了短期和长期营销效果 我认为这是公司如何处理营销分析的方式的重大转变。数据效率方面尤其重要 - 许多企业在历史数据有限的情况下挣扎，因此可以很好地执行较少数据的模型可以使高级MMM民主化。解决直接效应和延迟影响的双重注意机制似乎可以解决营销归因的基本挑战之一。   虽然计算要求对于较小的组织来说可能是陡峭的，但改善的准确性可以证明许多人的投资合理。我很想知道这种方法是如何处理有限的历史数据的新营销渠道的，本文并未完全解决该渠道。  tldr：nnn是一种专门的神经网络，用于营销组合建模，使传统方法的表现优于22％，而所需的数据则少5倍。它使用双重发音变压器体系结构来捕获跨频道的立即和延迟的营销效果。   Full Summary在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jvtju0/neural_network_marketing_mix_modeling_with/</guid>
      <pubDate>Thu, 10 Apr 2025 09:13:00 GMT</pubDate>
    </item>
    <item>
      <title>在LLM API中检测模型替代：验证方法的评估</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近遇到了一种用于检测LLM API中模型替代的新方法 - 本质上是检查API提供商是否正在用更便宜的替代方案交换您支付的型号。 研究人员开发了“ fingerprinting” a fingerprinting a＆quot a a＆quot a”可以通过分析精心制作的提示的响应模式来识别具有明显准确性的特定LLM的技术。 关键技术点： *他们的检测系统达到了98％+在区分主要LLM对之间的精确度 * OpenAI, Anthropic, and Cohere APIs * Substitution rates varied but reached up to 12% during some testing periods The methodology breaks down into three main steps: 1. Generating model-specific fingerprints through prompt engineering 2. Training a classifier on these distinctive response patterns 3. Systematically testing API endpoints to detect model switching I think this research has significant implications for how we interact与商业LLM API。作为与这些系统合作的人，我经常想知道我是否得到了要付费的确切模型，尤其是在性能似乎不一致的情况下。这为用户提供了一种验证他们收到的内容并使提供商负责的方法。 我认为，因此我们会看到对AI服务中透明度的更多需求。指纹技术可能会激发监视工具，这些工具可能成为需要一致，可预测的模型性能的企业API用户的标准实践。  tldr：研究人员开发了一种准确的方法来检测何时LLM API提供者何时秘密交换宣传模型。测试主要提供商表明，这种情况的发生比您想象的要多 - 当您要求GPT-4时，有时您可能会获得GPT-3.5-Turbo。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</guid>
      <pubDate>Wed, 09 Apr 2025 11:30:25 GMT</pubDate>
    </item>
    <item>
      <title>减少数字神经网络的记忆大小</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在运行一个完全基于numpy构建的相当简单的神经网络，并且表现良好，但是训练有素的模型的大小相当大（＆gt; 25MB）。我的模型的参数（例如，权重，偏见等）是dtype float64的，这意味着大小为768 x 768的ndarray已经产生半MB（每条条目1字节）。  我已经阅读了有关使用float32或float16作为dtypes的信息，但是它们似乎并没有减小神经网络的记忆大小，所以我想知道还有哪些其他选项？  拥有大于25MB的型号不一定是交易破坏者，但我总是会收到“大文件”。一旦我将其推向Github，就要警告，所以我想探索是否有更多轻量级的方法可以做到这一点。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1ju7ljo/reducing_the_memory_size_size_of_a_numpy_neural_neural_neal_network/]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</guid>
      <pubDate>Tue, 08 Apr 2025 07:06:50 GMT</pubDate>
    </item>
    <item>
      <title>MDS-A：用于测试时间适应的新数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32;态href =“ https://youtube.com/watch?v=MMSVSOFHNYYO＆amp; si = okj0q120f1rkbz-8”&gt; [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</guid>
      <pubDate>Mon, 07 Apr 2025 23:23:43 GMT</pubDate>
    </item>
    <item>
      <title>是真的吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  稀疏连接使输入使一组输入连接到隐藏层中的特定神经元，例如，如果您知道特定的域。但是，如果您不知道特定的域并且使其完全连接，这意味着您将所有输入连接到整个隐藏层，完全连接的网络会集中精力并尝试实现稀疏连接之类的东西吗？提交由＆＃32; /u/u/u/zestyclose-produce17     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</guid>
      <pubDate>Sun, 06 Apr 2025 14:23:40 GMT</pubDate>
    </item>
    <item>
      <title>魅力：一种多尺度令牌化方法，用于在基于VIT的美学评估中保存视觉信息</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsoaer/charm_a_multiscale_tokenization_approach_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  魅力：使用VITS  视觉变形金刚的图像美学评估的新型令牌化方法显示出对图像美学评估（IAA）的巨大希望，但是标准的预处理（resizie，crop，crop）破坏了关键的审美习惯。作者介绍了“魅力”。 a tokenization approach that selectively preserves high-resolution details in some image regions while downscaling others. Key innovations: * Selective resolution preservation: Maintains original resolution in some patches while downscaling others * Aspect ratio preservation: Works with images&#39; natural dimensions rather than forcing square crops * Multi-scale integration: Combines information from different scales via position and scale embeddings * Random patch selection: Surprisingly outperforms more sophisticated selection strategies Results across multiple datasets: * Up to 7.5% improvement in PLCC (Pearson correlation) * Up to 8.1% improvement in SRCC (Spearman相关性） *最高 14.8％分类准确性的提高 *更快的收敛性（较小的数据集上的培训时期少了50％） * *与不同的VOT体系结构（VIT-SMALL，DIV2-MALL，DINOV2-SMALL，DINOV2-LARGE）一起使用，我认为这是对ATEST的录制范围和计算机的评估方法的方法。图像中的美取决于构图，纵横比和细节的细节 - 准确的预处理销毁了哪些标准预处理。随机贴片选择效果最佳，特别有趣，这表明美学评估受益于一种数据增强形式，从而减少了模型过多地专注于显着物体的趋势。 该方法与现有VIT的兼容性无需其他预培训，而无需其他预培训使其立即有用，使其对研究人员和开发者在应用程序上的应用程序和开发者涉及涉及图像Apphicts Apps apps apps appsy appsy appsy的应用程序。   tldr ：魅力通过选择性地保留高分辨率贴片和宽高比可以增强图像美学评估的性能，随机补丁选择优于其他策略。  。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsoaer/charm_a_multiscale_tokenization_approach_for/</guid>
      <pubDate>Sun, 06 Apr 2025 07:02:20 GMT</pubDate>
    </item>
    <item>
      <title>交互式AI演示 - 可视化图像内生长的合成大脑（独立研究）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是一名独立的AI研究人员，从事两个独立但相关的实验项目。我想分享一个实时的WebGL演示，以获得反馈和好奇心。这不是商业化，不是为了游戏，而只是纯认知AI实验。  项目：神经像素AI系统 这个WebGL项目编码PNG图像中的人造大脑。目的是随着神经元从像素信息增长而来的结构和活动的出现。 每个像素编码突触或符号数据。 神经元在视觉上自我组织会随着时间的推移而自动组织。   整个系统都是确定性的，但由pseudo-eviludo-evi            href =“ https://www.dfgamesstudio.com/neural-pixel-ai-system/”&gt; https://www.dfgamesstudio.com/neural-pixel-ai-system/ 符号/认知AI架构旨在通过梦想合成，记忆衰减，情绪调节和通过一个称为“ADNσ”的系统的符号演变来模拟模块化意识。我知道这是非常规的，但我相信具有视觉逻辑的混合符号/神经系统值得探索。 谢谢！ - &gt;＆＃32;提交由＆＃32; /u/u/conanfredleseul     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</guid>
      <pubDate>Sun, 06 Apr 2025 02:19:38 GMT</pubDate>
    </item>
    <item>
      <title>如何训练多视图注意模型以结合NGram和Biobert嵌入</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js9auj/how_to_train_a_multiview_attention_model_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我希望您做得很好，我正在努力构建一个多视图模型，该模型使用注意机制结合了两种类型的功能：Ngram嵌入式和Biobert Embeddings    目标是通过使用这些不同的视图来创建富裕的代表，并使用这些不同的视图来创建富裕的表示。但是，我不确定如何构建训练过程，以便注意力机制学会从每个视图中有意义地对齐功能。我的意思是，我不能直接直接在标签上训练它，因为这就像在分类任务上训练常规的MLP有没有人从事类似方向的工作？ 我还没有尝试过任何具体的事情，因为我仍然对如何接近培训这种基于注意力的多视觉模型感到困惑。我不确定目标应该是什么以及如何使其学习有意义的注意力。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/connect-courage6458     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js9auj/how_to_train_a_multiview_attention_model_to/</guid>
      <pubDate>Sat, 05 Apr 2025 17:54:58 GMT</pubDate>
    </item>
    <item>
      <title>有人可以回答吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js5r4n/anyone_can_answer_that/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   如果有3个输入，我有3个隐藏的层，例如，一个神经元将取得所有3个输入，但增加了2个输入的权重，而不是第三个输入，而第二个神经元则关注第二和第三个输入的重量和第二个输入的重量和重新量的重量，也是第二个NEROR的重量。这是正确的吗？或神经网络中的神经元。例如，如果您有3个输入（x1，x2，x3），则一个感知器可能会集中在第一个和第三个输入（x1和x3）上（x1和x3），并给予它们高权重（例如，0.9和0.8），而将第二个输入（x2）给出了非常小的重量或零重量（例如，0.1或0）。同时，另一个感知者可能会专注于第二和第三个输入（x2和x3），从而使它们具有很高的权重（例如，0.7和0.9），并减少了第一个输入（x1）的重量（x1），以接近零。提交由＆＃32; /u/u/u/zestyclose-produce17     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js5r4n/anyone_can_answer_that/</guid>
      <pubDate>Sat, 05 Apr 2025 15:17:31 GMT</pubDate>
    </item>
    <item>
      <title>有人真的知道NLP是如何工作的吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js1igr/does_anyone_actually_know_how_nlp_works/</link>
      <description><![CDATA[    src =“ https://preview.itd.it/89rqqg5n60te1.png？ NLP有效????? /&gt;    &lt;！ -  sc_off-&gt;   01   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/poopo-hitshit       [注释] ] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js1igr/does_anyone_actually_know_how_nlp_works/</guid>
      <pubDate>Sat, 05 Apr 2025 11:38:58 GMT</pubDate>
    </item>
    <item>
      <title>用于增强扩散模型控制的频率指导缩放</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jrxv14/frequencydecomposed_guidance_scaling_for_enhanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   fresca是一种开创性的方法，可以通过作者所说的“缩放空间”来理解和操纵扩散模型。通过分析扩散模型如何自然地在deno的过程中在各个时间步处缩放不同的特征，他们发现了一种固有的结构，可以在不进行其他培训的情况下进行精确的图像编辑。   的关键技术贡献包括：   发现，在整个范围中 实现了与任何预验证的扩散模型一起使用的实施，而无需进行微调或其他网络 在多个图像操作任务中进行最新的结果结果，包括颜色调整，样式传输和本地编辑，包括   extripers offiel offief offief interfusion   extife extirals extirals extrips extress（类似于范围），这些方法是不同的，这些方法是差异的，这些绘制了范围不同的图像（范围差异）（ - something that&#39;s been present but untapped in these models until now. The results are impressive across various manipulation tasks: * Color manipulation: Changing color schemes while preserving textures and object identities * Style transfer: Applying styles to specific objects without affecting others * Local editing: Making precise changes to targeted areas while keeping the rest of the image intact * 一致的优势：在保持有针对性的更改的同时，在保存图像身份方面胜过现有技术   技术实施涉及计算每个时间段的模型输出与输入之间的比率与识别缩放因素，然后将目标调整应用于这些因素以修改特定属性。弗雷斯卡（Fresca）没有将它们视为黑匣子，而是揭示了它们具有内部结构，可以反映人类如何层次处理视觉信息。这可能会导致图像生成和编辑工具中更直观，更精确的控制。 我认为最令人兴奋的方面是，这种功能始终存在于扩散模型中，但只需要正确理解和利用。 It suggests there may be other untapped capabilities in these models we haven&#39;t yet discovered. The limitations around model dependency and the somewhat empirical process for identifying optimal timesteps for specific manipulations will need to be addressed in future work. TLDR: FreSca discovers and manipulates an inherent &quot;scaling space&quot;在扩散模型中，在不同的时间段上处理不同的图像特征，在没有其他培训的情况下进行精确的图像编辑。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jrxv14/frequencydecomposed_guidance_scaling_for_enhanced/</guid>
      <pubDate>Sat, 05 Apr 2025 07:14:55 GMT</pubDate>
    </item>
    <item>
      <title>努力在医学成像中选择正确的CNN XAI方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jqyfov/struggling_to_pick_the_right_xai_method_for_cnn/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   嘿，大家！&lt; /strong&gt; 我正在撰写论文，以使用可解释的AI（XAI）与CNN进行肺炎检测。 The goal is to make model predictions more transparent and trustworthy—especially for clinicians—by showing why a chest X-ray is classified as pneumonia or not. I’m currently exploring different XAI methods like Grad-CAM, LIME, and SHAP, but I’m struggling to decide which one best explains my model’s decisions. Would love to hear your thoughts or experiences with XAI in医学成像。任何建议或见解都将非常有帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/divedent-Ad914     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jqyfov/struggling_to_pick_the_right_xai_method_for_cnn/</guid>
      <pubDate>Fri, 04 Apr 2025 00:07:10 GMT</pubDate>
    </item>
    </channel>
</rss>