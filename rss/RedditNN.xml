<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Thu, 30 Nov 2023 18:17:28 GMT</lastBuildDate>
    <item>
      <title>图神经网络中的池化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/187j31s/pooling_in_graph_neural_networks/</link>
      <description><![CDATA[大家好， 我正在尝试消化这篇名为“用于胰腺癌组织学分类的图卷积神经网络”的论文;.  论文中说：我们连接每个 GCN 层的输出，然后使用“自注意力池层”来连接每个 GCN 层的输出。选择决定图类别的 50% 高权重节点。 Github.com/bmirds/slide2graph 我只是想知道是否有人可以解释池化用简单的术语来解释图卷积神经网络？ 我不是这个领域的，所以非常感谢。   由   提交/u/kakashi1992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/187j31s/pooling_in_graph_neural_networks/</guid>
      <pubDate>Thu, 30 Nov 2023 13:55:41 GMT</pubDate>
    </item>
    <item>
      <title>架构调优过程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/185xht4/architecture_tuning_process/</link>
      <description><![CDATA[我总是在尝试决定架构时迷失： 我有很强的数学背景并理解所有概念以及常用技术。当我开始处理新数据集时，这感觉毫无用处......我总是立即陷入困境 - 我应该按什么顺序进行实验？我不是在谈论不同的架构系列，而是给定一个系列，比如说简单的全连接前馈网络（MLP）。与超参数不同，我不能使用调谐器或具有明确定义的搜索空间，它是无限的和多维的。我倾向于从浅层网络（一层或两层）开始，并对隐藏单元的数量进行扫描。这工作正常，但不可能达到我看到其他人在相同数据集上使用的更深、更强大的网络。 我想我正在寻找一些启发式规则来指导我的直觉，什么是合理的当我改变其他事情时，假设可能不会改变太多，即我应该首先优化什么，然后在优化其他事情时保持不变？或者我应该考虑某些比率，例如增加/减少层数？当我深入开始并尝试处理过度拟合时，我经常会得到一条上升的损失曲线，或者到处都是。 接下来，超参数和架构之间存在相互作用 - 如果我解决了在一个架构上，然后开始摆弄正则化 lambda 或 dropout 率，我期望我的架构不再是最佳的 - 也许我可以让模型变得更复杂，因为我正在正则化？也许不同的激活函数也需要对架构进行更改？  ​ 我完全明白这是一个反复试验的过程，我确实已经尝试了很多，但当我这样做时，我感到非常失落得出结论，他们从不概括...一些一般的经验法则将不胜感激，数学规则似乎并不能指导我在这里，所以我很想听听你的经验！您如何解决这个问题？   由   提交/u/Success-Dangerous  /u/Success-Dangerous reddit.com/r/neuralnetworks/comments/185xht4/architecture_tuning_process/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/185xht4/architecture_tuning_process/</guid>
      <pubDate>Tue, 28 Nov 2023 14:36:20 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/184g03v/help_nedeed/</link>
      <description><![CDATA[当您刚刚开始学习神经网络和人工智能时，您可以推荐哪些书籍？ &lt;!-- SC_ON - -&gt;  由   提交 /u/John__Dow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/184g03v/help_nedeed/</guid>
      <pubDate>Sun, 26 Nov 2023 17:35:49 GMT</pubDate>
    </item>
    <item>
      <title>我可以在不使用 Conv2dtranspose 的情况下开发 gan 生成器架构吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/180jl9g/can_i_develop_a_gan_generator_architecture/</link>
      <description><![CDATA[我正在研究图像到图像的翻译 gan，我使用 conv2dtranspose 和上采样层开发了一个生成器，但训练太难了，我面临着模式 colllabs&lt; br /&gt; 所以我决定重建我的生成器架构。我可以使用密集层代替 conv2dtranspose 和上采样层吗？   由   提交/u/FortunePowerful3273  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/180jl9g/can_i_develop_a_gan_generator_architecture/</guid>
      <pubDate>Tue, 21 Nov 2023 15:29:12 GMT</pubDate>
    </item>
    <item>
      <title>自动联想网络测试</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1802phu/test_for_auto_associative_network/</link>
      <description><![CDATA[我已经让你从头开始使用我的一个项目，测试这个东西是否正常工作的正确方法是什么   由   提交/u/Spiderbyte2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1802phu/test_for_auto_associative_network/</guid>
      <pubDate>Mon, 20 Nov 2023 23:38:35 GMT</pubDate>
    </item>
    <item>
      <title>Google 的 Switch Transformers C - 2048 专家（3.1 TB 的 1.6T 参数）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17zyy35/googles_switch_transformers_c_2048_experts_16t/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17zyy35/googles_switch_transformers_c_2048_experts_16t/</guid>
      <pubDate>Mon, 20 Nov 2023 21:04:50 GMT</pubDate>
    </item>
    <item>
      <title>我的梯度下降无法正常工作的原因可能是什么？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17zkix9/what_could_be_the_reason_my_gradient_descent_isnt/</link>
      <description><![CDATA[我制作了一个简单的神经网络脚本，它采用两个输入和两个输出以及三节点隐藏层。在 Learn() 函数中我尝试过编码梯度下降。经过大约 10-20 次迭代后，成本变得非常接近于零，但由于某种原因，梯度仍然是一个相当高的值，并且从权重和偏差中减去更多，使成本为负。看起来不是学习率太高，设置为0.1。 这里是代码。 （我使用 Unity C#） 还有其他人知道可能出了什么问题吗？任何帮助将不胜感激！ 顺便说一句，如果这是一个非常初级的问题，我很抱歉，但我就是无法弄清楚。 &lt;!-- SC_ON - -&gt;  由   提交/u/JontePonte64  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17zkix9/what_could_be_the_reason_my_gradient_descent_isnt/</guid>
      <pubDate>Mon, 20 Nov 2023 09:15:00 GMT</pubDate>
    </item>
    <item>
      <title>StyleTTS 2：通过大型语音语言模型的风格扩散和对抗性训练实现人类水平的文本转语音</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17z8mdj/styletts_2_towards_humanlevel_texttospeech/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17z8mdj/styletts_2_towards_humanlevel_texttospeech/</guid>
      <pubDate>Sun, 19 Nov 2023 22:16:32 GMT</pubDate>
    </item>
    <item>
      <title>具有逻辑约束的学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17ywwu6/learning_with_logical_constraints/</link>
      <description><![CDATA[   /u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17ywwu6/learning_with_logical_constraints/</guid>
      <pubDate>Sun, 19 Nov 2023 13:12:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LoRA 微调法学硕士 - 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17yeh56/how_to_finetune_llms_using_lora_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了如何使用低秩适应（LoRA）微调大型语言模型。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17yeh56/how_to_finetune_llms_using_lora_explained/</guid>
      <pubDate>Sat, 18 Nov 2023 19:54:10 GMT</pubDate>
    </item>
    <item>
      <title>AI 时代的 GPU 生存工具包：每个开发人员必须了解的最低限度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17ydfop/gpu_survival_toolkit_for_the_ai_age_the_bare/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17ydfop/gpu_survival_toolkit_for_the_ai_age_the_bare/</guid>
      <pubDate>Sat, 18 Nov 2023 19:04:43 GMT</pubDate>
    </item>
    <item>
      <title>分类 ANN 损失上下波动</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17ya2jr/classification_ann_loss_going_up_and_down/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17ya2jr/classification_ann_loss_going_up_and_down/</guid>
      <pubDate>Sat, 18 Nov 2023 16:27:12 GMT</pubDate>
    </item>
    <item>
      <title>如果将时间上连续的数据值输入到连续的网络输入神经元中，普通的反向传播网络是否可以用于时间序列数据？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17x9b6r/can_ordinary_backpropagation_networks_be_used_for/</link>
      <description><![CDATA[问题：如果要使用神经网络进行未来股票市场价格预测，其中您有股票价格值的时间序列，可以普通的反向传播网络可以用于此目的吗？ 我想在 3 天的时间内每 15 分钟获取一次股票价格（这样就会有 3 x 24 x 4 = 288 个价格值） ），然后将这些值（以标准化形式）输入到具有 288 个输入神经元的反向传播网络中。然后，该网络设置将用于预测未来几个小时内的股票价格将发生什么变化。 该设置在以下方面是否与长短期记忆 (LSTM) 网络一样有效：未来价格预测？或者 LSTM 网络是否提供了超越普通反向传播网络的功能？   由   提交/u/GA64  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17x9b6r/can_ordinary_backpropagation_networks_be_used_for/</guid>
      <pubDate>Fri, 17 Nov 2023 06:58:22 GMT</pubDate>
    </item>
    <item>
      <title>Meta 从《卡拉狄加》中学到了什么，这个注定失败的模型在 ChatGPT 前两周推出</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17x8nez/what_meta_learned_from_galactica_the_doomed_model/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17x8nez/what_meta_learned_from_galactica_the_doomed_model/</guid>
      <pubDate>Fri, 17 Nov 2023 06:13:12 GMT</pubDate>
    </item>
    <item>
      <title>二值图像分类的神经网络问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/17x0bf9/problem_with_nn_for_binary_image_classification/</link>
      <description><![CDATA[嗨，我正在尝试构建一个用于二值图像分类的神经网络。我尝试了增强、迁移学习和微调，但是当我训练模型时，我获得了训练集 (0.9) 和验证集 (0.85) 的良好准确度，但验证的损失函数很高。然后，当我尝试在测试集上使用它时，我得到的准确度相当低（0.6）。有人有什么建议吗？谢谢！   由   提交 /u/Sophia_Gi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/17x0bf9/problem_with_nn_for_binary_image_classification/</guid>
      <pubDate>Thu, 16 Nov 2023 23:06:35 GMT</pubDate>
    </item>
    </channel>
</rss>