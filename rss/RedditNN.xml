<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 10 Aug 2024 03:23:08 GMT</lastBuildDate>
    <item>
      <title>吐槽我的第二个 AI 视频项目</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eoagws/roast_my_second_ai_video_project/</link>
      <description><![CDATA[        提交人    /u/vtimevlessv   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eoagws/roast_my_second_ai_video_project/</guid>
      <pubDate>Fri, 09 Aug 2024 20:44:06 GMT</pubDate>
    </item>
    <item>
      <title>5 分钟内了解梯度下降</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1en6cjz/gradient_descent_in_5min/</link>
      <description><![CDATA[      大家好！我是波士顿大学数据科学的兼职教授，刚刚开始将我的讲座上传到 YouTube。希望我走在正确的轨道上，但我也非常希望听到关于如何改进内容或交付方式的建议！    提交人    /u/how_i_think_about   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1en6cjz/gradient_descent_in_5min/</guid>
      <pubDate>Thu, 08 Aug 2024 13:44:31 GMT</pubDate>
    </item>
    <item>
      <title>人工智能模型搜索引擎</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1emn2xa/search_engine_for_ai_models/</link>
      <description><![CDATA[当今世界上有很多开源 AI 模型，很多人都在使用它们为企业构建产品。 拥有一个可以帮助他们为他们的产品选择合适的 AI 模型的搜索引擎，您认为这会有所帮助吗？ 查看投票    由   提交  /u/Red_Pudding_pie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1emn2xa/search_engine_for_ai_models/</guid>
      <pubDate>Wed, 07 Aug 2024 20:53:38 GMT</pubDate>
    </item>
    <item>
      <title>需要为“非程序员”提供 CLI 方面的帮助（法学硕士，但这可能是一个错误的选择）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1elre7x/need_help_with_cli_for_nonprogrammers_llms_but/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1elre7x/need_help_with_cli_for_nonprogrammers_llms_but/</guid>
      <pubDate>Tue, 06 Aug 2024 19:53:32 GMT</pubDate>
    </item>
    <item>
      <title>一种新型神经网络更易于解释：卡尔莫哥洛夫-阿诺德神经网络颠覆了人工智能的运作方式</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ektloo/a_new_type_of_neural_network_is_more/</link>
      <description><![CDATA[    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ektloo/a_new_type_of_neural_network_is_more/</guid>
      <pubDate>Mon, 05 Aug 2024 17:24:21 GMT</pubDate>
    </item>
    <item>
      <title>自压缩神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ek17cj/selfcompressing_neural_networks/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ek17cj/selfcompressing_neural_networks/</guid>
      <pubDate>Sun, 04 Aug 2024 17:48:56 GMT</pubDate>
    </item>
    <item>
      <title>我不明白我的输出</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ejset0/i_dont_understand_my_output/</link>
      <description><![CDATA[我不明白为什么我的输出具有 (1,2) 的形式，我有一个输出神经元，我希望它具有 (1,1) 的形式 我想预测 XOR，我还没有添加反向传播，但是如果我有 2 个数字一个数组，我想我不能这样做 import numpy as np input = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) output = np.array([0], [1], [1], [0]]) class Layer(): def __init__(self, input_size, output_size): self.weights = np.random.randn(output_size, input_size) self.biases = np.zeros((output_size, 1)) def forward(self, input): self.input = 输入 self.output = np.dot(self.weights, self.input) + self.biases 返回 self.output def behind(self, output_gradient, learning_rate): pass layer1 = Layer(4, 4) layer1.forward(inputs) layer2 = Layer(4, 1) layer2.forward(layer1.output) print(layer2.output)     提交人    /u/Queasy_Employment635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ejset0/i_dont_understand_my_output/</guid>
      <pubDate>Sun, 04 Aug 2024 10:47:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 K-means 分割图像？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ej13ga/how_to_segment_images_using_kmeans/</link>
      <description><![CDATA[      https://preview.redd.it/riy1uhlfpfgd1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=c305e8346b291bc721613aae5ac7c7f48355632e 了解如何使用 K-means 聚类算法进行图像分割。   在此视频中，您将首先学习如何将图像加载到 Python 中并使用 OpenCV 对其进行预处理，以将其转换为适合输入到 K 均值聚类算法的格式。 然后，您将 K 均值算法应用于预处理后的图像并指定所需的聚类数量。 最后，您将演示如何通过将图像中的每个像素分配给其对应的聚类来获得图像分割，并且您将展示当您改变聚类数量时分割如何变化。   您可以在我的博客文章页面中找到更多类似的教程：https://eranfeit.net/blog/ 查看本教程：https://youtu.be/a2Kti9UGtrU&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg      由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ej13ga/how_to_segment_images_using_kmeans/</guid>
      <pubDate>Sat, 03 Aug 2024 11:28:09 GMT</pubDate>
    </item>
    <item>
      <title>torch 高斯随机权重初始化和 L2 正则化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ei8whq/torch_gaussian_random_weights_initialization_and/</link>
      <description><![CDATA[我有一个线性/全连接的 torch 层，它接受 latent_dim 维输入。该层中的神经元数量 = 高度 \ 宽度*:  # 定义当前层的超参数 - height = 20 width = 20 latent_dim = 128 # 初始化线性层 - linear_wts = nn.Parameter(data = torch.empty(height * width, latent_dim), require_grad = True) &#39;&#39;&#39; torch.nn.init.normal_(tensor, mean=0.0, std=1.0, generator=None) 用从正态分布中抽取的值填充输入张量 - N(mean, std^2) &#39;&#39;&#39; nn.init.normal_(tensor = som_wts, mean = 0.0, std = 1 / np.sqrt(latent_dim)) print(f&#39;1/sqrt(d) = {1 / np.sqrt(latent_dim):.4f}&#39;) print(f&#39;SOM 随机 wts; min = {som_wts.min().item():.4f} &amp;&#39; f&#39; max = {som_wts.max().item():.4f}&#39; ) print(f&#39;SOM 随机 wts; mean = {som_wts.mean().item():.4f} &amp;&#39; f&#39; std-dev = {som_wts.std().item():.4f}&#39; ) # 1/sqrt(d) = 0.0884 # SOM 随机 wts；min = -0.4051 &amp; max = 0.3483 # SOM 随机 wts；mean = 0.0000 &amp; std-dev = 0.0880  问题 1：对于 std-dev = 0.0884（近似值），根据最小值和最大值 -0.4051 和 0.3483，似乎正常初始化程序正在计算平均值 = 0 的 +3.87 个标准差和平均值 = 0 的 -4.4605 个标准差。这是正确的理解吗？我假设权重是从距离平均值 +3 和 -3 个标准差中抽取的？ 问题 2：我希望这个线性层的输出是 L2 正则化的，这样它位于单位超球面上。为此，似乎有 2 个选项：  执行一次性操作：```linear_wts.data.copy_(nn.Parameter(data = F.normalize(input = linear_wts.data, p = 2.0, dim = 1)))```然后照常训练 获取层的输出为：```F.relu(linear_wts(x))```然后执行 L2 规范化（针对每个训练步骤）：```F.normalize(input = F.relu(linear_wts(x)), p = 2.0, dim = 1)```  我认为选项 2 更正确。有什么想法吗？    提交人    /u/grid_world   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ei8whq/torch_gaussian_random_weights_initialization_and/</guid>
      <pubDate>Fri, 02 Aug 2024 12:33:43 GMT</pubDate>
    </item>
    <item>
      <title>Dosidicus - 具有神经网络和赫布学习功能的电子宠物</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ehxcnf/dosidicus_tamagotchistyle_digital_pet_with_a/</link>
      <description><![CDATA[如果 Tamagotchi 拥有神经网络并能学习东西会怎样？ https://github.com/ViciousSquid/Dosidicus [正在进行中]  * Squid 根据其需求和环境做出自主决策并能形成联想 * 照顾好自己的需求，否则他会生病甚至死亡！ * 7 种具有各自特征的不同性格类型 * 实现赫布学习* 具有实时可视化和解释的大脑工具 * 网络可以显示权重变化的原因 在内部进行探索，看看一切是如何运作的——刺激大脑可以直接影响鱿鱼的行为。 欢迎合作和功能建议！    提交人    /u/DefinitelyNotEmu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ehxcnf/dosidicus_tamagotchistyle_digital_pet_with_a/</guid>
      <pubDate>Fri, 02 Aug 2024 01:12:30 GMT</pubDate>
    </item>
    <item>
      <title>你好，我是新手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ehv5jv/hello_im_new_to_this/</link>
      <description><![CDATA[您好，我今年 13 岁，快 14 岁了，我对机器人和人工智能非常感兴趣，我找到了 Harrison Kinsley 和 Daniel Kukiela 合著的《从头开始构建神经网络》一书，我即将开始阅读，所以如果您有任何提示或建议可以了解有关 ANN 的更多信息，那就太好了，谢谢     提交人    /u/SimplyNotHim   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ehv5jv/hello_im_new_to_this/</guid>
      <pubDate>Thu, 01 Aug 2024 23:29:46 GMT</pubDate>
    </item>
    <item>
      <title>我创建了一个 SWE 套件来轻松构建 SWE 代理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eh7otj/i_created_a_swe_kit_to_easily_build_swe_agents/</link>
      <description><![CDATA[大家好！我很高兴与大家分享一个新项目：SWEKit，这是一个使用 Composio 工具生态系统构建软件工程代理的强大框架。 目标 SWEKit 允许您：  使用 CrewAI 和 LlamaIndex 等框架构建开箱即用的代理。 添加或优化代理的能力。 根据 SWE-Bench 对您的代理进行基准测试。  实施细节  使用的工具：Composio、CrewAI、Python  设置：  安装您选择的代理框架和 Composio 插件 代理需要 github 访问令牌才能与您的存储库配合使用 您还需要设置 API 密钥适用于您计划使用的 LLM 提供程序  搭建并运行您的代理 工作区环境： SWEKit 支持不同的工作区环境：  主机：在主机上运行。 Docker：在 Docker 容器内运行。 E2B：在 E2B 沙箱内运行。 FlyIO：在 FlyIO 机器内运行。  运行基准测试：  SWE-Bench 使用来自流行 Python 开源项目的实际问题来评估软件工程代理的性能。  GitHub 欢迎探索该项目，如果发现它有用，请给它一颗星，并让我知道您的想法或改进建议！🌟    提交人    /u/kingai404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eh7otj/i_created_a_swe_kit_to_easily_build_swe_agents/</guid>
      <pubDate>Thu, 01 Aug 2024 04:20:03 GMT</pubDate>
    </item>
    <item>
      <title>定制代理工作流和分布式处理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ef365r/customized_agentic_workflows_and_distributed/</link>
      <description><![CDATA[大家好！我刚刚为我的平台开发完此功能，并希望获得一些反馈。 平台是 isari.ai  您可以在主页上观看有关如何使用它的演示😊 如果您想合作或成为此计划的一部分，请给我发送 DM 或加入 Discord 服务器，我非常乐意回复！ 我很感激任何和所有的反馈🙏    提交人    /u/akitsushima   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ef365r/customized_agentic_workflows_and_distributed/</guid>
      <pubDate>Mon, 29 Jul 2024 15:58:43 GMT</pubDate>
    </item>
    <item>
      <title>带有神经网络的电子宠物 [项目]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1edn440/tamagotchistyle_digital_pet_with_a_neural_network/</link>
      <description><![CDATA[我试图更多地了解神经网络，并构建了这只拥有 7 个神经元的数字鱿鱼： https://github.com/ViciousSquid/Dosidicus 鱿鱼自主移动，根据其当前状态（饥饿、困倦等）做出决定。他需要一些照顾，否则他就会死。 他的大脑完全可见且可编辑。他的行为可以直接修改，也可以观察到他对环境因素的反应。鱿鱼有一个视锥，他用它来寻找食物。 使用“操作”菜单与鱿鱼互动。这一半是教育研究，一半是电子宠物。 编辑：发布您的高分！    提交人    /u/DefinitelyNotEmu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1edn440/tamagotchistyle_digital_pet_with_a_neural_network/</guid>
      <pubDate>Sat, 27 Jul 2024 18:30:35 GMT</pubDate>
    </item>
    <item>
      <title>神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eddd7n/neural_network/</link>
      <description><![CDATA[我发现这个视频非常清楚地解释了神经网络 https://youtu.be/gIMoApcTa64?si=pb1JG5-wz8jIK3fA    提交人    /u/Far_Condition_88   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eddd7n/neural_network/</guid>
      <pubDate>Sat, 27 Jul 2024 10:36:20 GMT</pubDate>
    </item>
    </channel>
</rss>