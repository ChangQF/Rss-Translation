<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Sun, 10 Mar 2024 06:15:50 GMT</lastBuildDate>
    <item>
      <title>通过 JavaScript 代码召唤的远古之神。 Armaaruss 军用无人机和士兵检测系统（Armaaruss 模型系统版本 1）。编程方面的一项新创新，可以帮助士兵和平民检测无人机并躲避无人机袭击，而无需重新训练模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1banquu/an_ancient_god_summoned_through_javascript_code/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1banquu/an_ancient_god_summoned_through_javascript_code/</guid>
      <pubDate>Sat, 09 Mar 2024 17:57:52 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络在 2 个预期输出之间取平均值。 （废品机械师中的 NN）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_between_the_2_expected_outputs/</link>
      <description><![CDATA[所以我在游戏中构建了一个神经网络（废料机制），为了使其工作，我必须制作另外 8 个神经网络，并且偏移量为 0.1每个 NN 上的权重之一，然后计算正常 NN 的成本和偏移 NN 之间的偏移量，并据此计算我必须改变该权重多少。我认为它首先有效，但是当我尝试输入更多输入时，它是两者之间的平均值。示例：  期望值 1: 2 2 期望值 2: 0 0 NN 计算出的值：0.7 1.0 我知道我没有解释清楚，英语是我的第二语言，它的语言真的很难解释，我真的很抱歉。 激活函数：Leaky ReLU ​  &amp;# 32；由   提交/u/Business-Ad2  /u/Business-Ad2  reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_ Between_the_2_expected_outputs/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_between_the_2_expected_outputs/</guid>
      <pubDate>Sat, 09 Mar 2024 12:08:28 GMT</pubDate>
    </item>
    <item>
      <title>SymbolicAI：结合生成模型和求解器的基于逻辑的方法框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b9ktaq/symbolicai_a_framework_for_logicbased_approaches/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.00854 代码：https://github .com/ExtensityAI/symbolicai 基准：https://github。 com/ExtensityAI/benchmark 摘要：  我们推出SymbolicAI，一个多功能的模块化AI框架采用基于逻辑的方法来进行生成过程中的概念学习和流程管理。 SymbolicAI 通过将大型语言模型 (LLM) 视为基于自然和形式语言指令执行任务的语义解析器，实现了生成模型与各种求解器的无缝集成，从而弥合了符号推理和生成 AI 之间的差距。我们利用概率编程原理来处理复杂的任务，并利用可微分和经典编程范式及其各自的优势。该框架引入了一组用于数据流操作的多态、组合和自引用操作，使 LLM 输出与用户目标保持一致。因此，我们可以在具有零次和少次学习能力的各种基础模型的能力与精通解决特定问题的专门的、微调的模型或求解器之间进行转换。反过来，该框架有助于创建和评估可解释的计算图。最后，我们引入了用于评估这些计算图的质量衡量标准及其经验分数，并提出了一个基准来比较一组复杂工作流程中的各种最先进的法学硕士。我们将经验得分称为“通过交叉相似性进行关系轨迹评估的向量嵌入”，或简称为VERTEX得分。框架代码库和基准测试链接如下。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b9ktaq/symbolicai_a_framework_for_logicbased_approaches/</guid>
      <pubDate>Fri, 08 Mar 2024 10:14:47 GMT</pubDate>
    </item>
    <item>
      <title>引入多尺度特征调制网络以推进水下图像增强</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b9e3j7/multiscale_feature_modulation_network_introduced/</link>
      <description><![CDATA[   /u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b9e3j7/multiscale_feature_modulation_network_introduced/</guid>
      <pubDate>Fri, 08 Mar 2024 03:38:36 GMT</pubDate>
    </item>
    <item>
      <title>了解注意力和变压器的资源</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</link>
      <description><![CDATA[请分享一些好的资源（文章、YouTube 视频），以易于理解的方式解释注意力和 Transformers 的概念。我看过一些视频，但不太明白。还有任何可以帮助我更好地理解这一点的先决条件。   由   提交/u/Anxious-Buddha  /u/Anxious-Buddha reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</guid>
      <pubDate>Tue, 05 Mar 2024 17:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如何找到其他网络来对我创建的数据集进行基准测试？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</link>
      <description><![CDATA[大家好。我开发了一个使用 Transformer 架构的动态手势识别系统。因为手势集是 nieche，所以我必须创建自己的数据集。 我的数据形状是 X.shape = (样本数，时间序列长度，特征数） y.shape =（样本数，类数） 其中样本数是总量每个类别的样本总数。每个样本的时间序列和特征的长度都是恒定的。 Y 是一个单热编码向量，其中每个真实类别用 1 标记，行的其余部分为零。 &lt; p&gt;我想用其他网络测试我的数据集，但是，我很难找到接受此数据格式的其他网络。您可以推荐什么作为搜索关键字？或者我应该以不同的方式格式化我的数据？   由   提交/u/ege6211  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</guid>
      <pubDate>Tue, 05 Mar 2024 13:08:11 GMT</pubDate>
    </item>
    <item>
      <title>如果您知道，请向我解释一下 Synthesia AI 视频生成器的工作原理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</link>
      <description><![CDATA[他们正在通过视频神经合成生成视频。请帮助我了解它是如何工作的。 https://www.synthesia.io   由   提交 /u/Acrobatic-Jaguar-599   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</guid>
      <pubDate>Mon, 04 Mar 2024 20:11:36 GMT</pubDate>
    </item>
    <item>
      <title>LLM 分词器解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</guid>
      <pubDate>Sun, 03 Mar 2024 10:17:54 GMT</pubDate>
    </item>
    <item>
      <title>卡尔加里大学推出改变游戏规则的结构化稀疏方法：SRigL</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</guid>
      <pubDate>Sun, 03 Mar 2024 07:48:03 GMT</pubDate>
    </item>
    <item>
      <title>集中您的注意力（使用自适应 IIR 滤波器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</link>
      <description><![CDATA[EMNLP 2023：https://aclanthology.org/2023.emnlp-main.772/ arXiv：https://arxiv.org/abs/2305.14952 OpenReview：https://openreview.net/forum?id=DlQeSfGYfS 摘要：  我们提出了一个新层，其中使用二阶动态（即依赖于输入的）无限脉冲响应（IIR）滤波器来处理应用常规注意之前的输入序列。输入被分成块，并且这些滤波器的系数是根据先前的块确定的，以保持因果关系。尽管其阶数相对较低，但因果自适应滤波器将注意力集中在相关序列元素上。新层以控制理论为基础，并被证明可以推广对角状态空间层。该层的性能与最先进的网络相当，参数仅为其一小部分，时间复杂度与输入大小成次二次方。无论是在参数数量还是在多个远程序列问题上获得的性能水平方面，所获得的层都优于 Hyena、GPT2 和 Mega 等层。     由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</guid>
      <pubDate>Thu, 29 Feb 2024 10:49:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyReason 进行推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</guid>
      <pubDate>Wed, 28 Feb 2024 16:53:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Real-ESRGAN 改善低分辨率图像和视频？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</link>
      <description><![CDATA[      https://preview.redd.it/xgzciubci2lc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=7e52aa3f9827f91 5e724fa50258c1abd669cfdc1 在本教程中，我们将学习如何将低分辨率图像改进为高分辨率结果。 我们将使用相关的 Python 库创建一个新的 Conda 环境。然后，我们将学习如何使用 real-ESRGAN 提高图像和视频的质量。 您可以在此处找到视频教程的链接：https://youtu.be/d-CPvHkltXA 您可以在此处找到说明：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/Real-ESRGAN 享受 Eran #realesrgantutorial #RealESRGAN #realesrgantutorial #improveimagequality #improveimageresolution #realesrganimageupscaler #realesrganimageupscaler #aiimageupscalerfree #freeaiimageupscaling #python #RealESRGAN #increaseimageresolution   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</guid>
      <pubDate>Tue, 27 Feb 2024 05:57:14 GMT</pubDate>
    </item>
    <item>
      <title>选择您自己的编码助手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/High_Sleep3694   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</guid>
      <pubDate>Mon, 26 Feb 2024 11:26:52 GMT</pubDate>
    </item>
    <item>
      <title>液体神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</link>
      <description><![CDATA[大家好，请问您能给我提供学习LNN（液体神经网络）的资源或工具（代码，最好使用TF）或路线图吗因为我有一个项目要在现实生活中的某个应用程序上处理它们。我已经对 ML、神经网络、CNN、RNN、LSTM、迁移学习有很强的背景。非常感谢您的帮助！    由   提交/u/Hussein_Jammal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</guid>
      <pubDate>Mon, 26 Feb 2024 07:12:08 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec 使用的单词数？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b060r6/number_of_words_to_use_for_a_word2vec/</link>
      <description><![CDATA[如果我使用 word2vec 为另一个进行情感分析的网络标记单词，我应该用多少个单词来训练它？如果我最多使用第 n 个最常用的单词，那么电子邮件中包含不在数据集中的单词的可能性有多大？我试图找到第 10,000 个最常见单词的频率，但没有成功。   由   提交 /u/ConflictUnfair   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b060r6/number_of_words_to_use_for_a_word2vec/</guid>
      <pubDate>Mon, 26 Feb 2024 02:09:10 GMT</pubDate>
    </item>
    </channel>
</rss>