<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 09 Nov 2024 15:17:23 GMT</lastBuildDate>
    <item>
      <title>为什么 model_q4.onnx 和 model_q4f16.onnx 不是比 model.onnx 小 4 倍？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</link>
      <description><![CDATA[我在https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/tree/main/onnx:上看到&gt;   文件名 大小    model.onnx 654 MB   model_fp16.onnx 327 MB   model_q4.onnx 200 MB   model_q4f16.onnx 134 MB   我的理解是：  model.onnx 是 fp32 模型， model_fp16.onnx 是权重量化为 fp16 的模型  我不明白 model_q4.onnx 和 model_q4f16.onnx 的大小&gt;  为什么 model_q4.onnx 是 200 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4.onnx 意味着权重被量化为 4 位。 为什么 model_q4f16.onnx 是 134 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4f16.onnx 意味着权重被量化为 4 位并且激活是 fp16，因为 https://llm.mlc.ai/docs/compilation/configure_quantization.html 指出：  qAfB(_id)，其中 A 表示用于存储权重的位数，B 表示用于存储激活的位数。   并且在张量流的神经网络量化框架中，为什么激活需要比权重（8 位）更多的位（16 位）？ 表示激活不计入模型大小（可以理解）。     提交人    /u/Franck_Dernoncourt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</guid>
      <pubDate>Fri, 08 Nov 2024 17:36:44 GMT</pubDate>
    </item>
    <item>
      <title>能“嗅觉”的人工智能？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</link>
      <description><![CDATA[我一直在阅读有关 Osmo 的文章，这是一家初创公司，它使用人工智能通过分析气味的分子结构来预测和重现气味，他们认为这可能会影响从医疗保健到香水等领域。 想到机器以这种精确度“嗅觉”真是令人着迷，但我很好奇——这实际上会如何改变我们体验周围世界的方式？我想我很难看到人工智能驱动的气味技术能够以实际或意想不到的方式影响日常生活或特定行业，所以我想听听不同的观点。    提交人    /u/Frosty_Programmer672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</guid>
      <pubDate>Thu, 07 Nov 2024 13:47:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么深度学习的热潮让几乎所有人都感到意外</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gl6uvr/why_the_deep_learning_boom_caught_almost_everyone/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gl6uvr/why_the_deep_learning_boom_caught_almost_everyone/</guid>
      <pubDate>Wed, 06 Nov 2024 19:31:11 GMT</pubDate>
    </item>
    <item>
      <title>第一次尝试：训练并使用 NN 模型进行“与训练集相似的摄影”选择，有什么建议吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gl0r7d/first_try_training_and_using_nn_model_for/</link>
      <description><![CDATA[大家好！ 我对训练一个 NN 模型很感兴趣，该模型将为我执行“最佳照片选择”过程。 作为一名业余体育摄影师，我想自动化处理所拍摄照片的初始“好照片”步骤。 假设：使用数千张“好”通过之前选择并发布的不同环境和不同人群中特定体育活动的图像，我可以训练一些 CV NN 模型来对我提供的新图像进行评分，从而自动完成初始照片选择的过程。 目前，我已经开始深入研究微调基线训练的 ViT 模型（https://huggingface.co/google/vit-base-patch16-224 获取模型及其简介）。 我的初始训练代码： # Training loop for epoch in range(10): for i, (images, labels) in enumerate(train_loader): output = model(images, labels=labels) loss = output.loss loss.backward() optimizer.step() optimizer.zero_grad() if i % 100 == 0: print(f&#39;Epoch [{epoch+1}/{10}], 步骤 [{i+1}/{len(train_loader)}], 损失：{loss.item():.4f}&#39;)  我使用上面的代码对一些非常压缩的照片（从 2000x3000 的图片到正方形 224x224）进行了 100 次编码训练，并使其对一张图像进行评分，使用我能从中抓取的第一件事，使用模糊的常识，谷歌和谷歌双子座的建议，即 cosine_similarity(a, b): return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)) 即我训练一个模型，让它对我的参考图像进行分类（返回每个图像的特征，作为所有参考图像的 .logits.squeeze），然后我让它对我的测试图像进​​行分类，然后我比较测试图像特征与所有参考图像特征的余弦相似度，得到一个余弦相似度列表。 所以，问题是： - 我是否在朝着正确的方向挖掘？VisionTransformer 是一个不错的选择吗，或者某些 CNN 变体在我的训练池大小上会更加稳健？ - 提高训练重要性是否能让我制作一个合理微调的模型？ - 我可以使用哪些其他方法将模型输出用作测试图像的识别分数？ 老实说，NN 不是我的专业领域，所以我愿意接受建议。    提交人    /u/Xenolog   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gl0r7d/first_try_training_and_using_nn_model_for/</guid>
      <pubDate>Wed, 06 Nov 2024 15:13:28 GMT</pubDate>
    </item>
    <item>
      <title>网络物理系统中的元认知</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</guid>
      <pubDate>Mon, 04 Nov 2024 12:49:25 GMT</pubDate>
    </item>
    <item>
      <title>正确的模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</link>
      <description><![CDATA[因此，我的任务是根据之前的值和下一个变量（例如电机的速度和旋转）预测无人机的电池消耗。 我会使用 RNN（类似 LSTM）根据之前的值预测下一个值，但也有其他依赖于电池消耗的参数（电机旋转、位置等...）。 我应该使用什么模型？    提交人    /u/martin3698753   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</guid>
      <pubDate>Mon, 04 Nov 2024 09:46:45 GMT</pubDate>
    </item>
    <item>
      <title>提高直播视频质量</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</link>
      <description><![CDATA[我收到了一个有很多噪音和伪影的模拟视频。假设我通过数字转换器播放了这个视频，但质量仍然很差。是否有任何神经网络可以在没有大延迟的情况下从实时视频中去除噪音和伪影？    提交人    /u/Braven111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</guid>
      <pubDate>Mon, 04 Nov 2024 08:39:29 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶加权神经网络：提高效率和性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</link>
      <description><![CDATA[       由    /u/musescore1983  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</guid>
      <pubDate>Mon, 04 Nov 2024 05:56:00 GMT</pubDate>
    </item>
    <item>
      <title>罗伯特·赫克特-尼尔森的遗产</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</link>
      <description><![CDATA[Robert Hecht-Nielsen 在 80 年代末在 UCSD 教授了人工神经网络的研究生课程。非常棒的基础内容。Bob 也是一名冲浪者，他非常想在他的冲浪板中嵌入一些翻译功能，这样他就可以与海豚互动。我的路径与神经网络不同，所以不太了解最新情况。事情是这样的，Bob 有 386，你们有斗鱼的东西。快到 2025 年了，那里没有冲浪者怎么办？    提交人    /u/blatherer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</guid>
      <pubDate>Sun, 03 Nov 2024 23:19:07 GMT</pubDate>
    </item>
    <item>
      <title>还没有见过很多代表训练网络中权重的图像。它们很漂亮。这是我的。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</link>
      <description><![CDATA[        提交者    /u/bombsy_rosalina   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</guid>
      <pubDate>Sun, 03 Nov 2024 21:29:21 GMT</pubDate>
    </item>
    <item>
      <title>遗传算法优于 NN？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</link>
      <description><![CDATA[我有一个最小化问题：  我有一个已知的参考函数，计算速度慢，但性能很好 我设法用一个简单的 NN 很好地近似它 现在我想让它变得更好，因为参考函数已知有缺陷  问题是我无法判断函数的单个输出是好是坏。我只能把它放在一个黑匣子里，在那里使用数千次，然后得到一个性能分数。 你会如何处理这个问题？我正在考虑在我的 NN 上使用遗传算法，但我不知道从哪里开始。我记得不久前读过一篇关于这个的论文，但再也找不到了。 我也可以完全忘记我的参考函数及其 NN 近似，在这种情况下，我会回到标准最小化问题，我想知道是否有任何使用 NN 的方法，或者切换到经典最小化算法会更好。    提交人    /u/PittMarson   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</guid>
      <pubDate>Sun, 03 Nov 2024 20:07:07 GMT</pubDate>
    </item>
    <item>
      <title>120 个狗品种，超过 10,000 张图片：狗分类的深度学习教程🐕‍🦺</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</link>
      <description><![CDATA[      https://preview.redd.it/htuma7v2aqyd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1eb955978bdc315fcc5a58ef3696afd3a070080e 📽️ 在我们的最新视频教程中，我们将使用 NasLarge 预训练模型🚀和一个包含 120 种独特犬种的 10,000 多张图像的海量数据集创建一个犬种识别模型📸. 您将学到的内容： 🔹 数据准备：我们首先下载一个包含超过 20,000 张狗图像的数据集，这些图像整齐地分为 120 个类别。您将学习如何使用 Python、OpenCV 和 Numpy 加载和预处理数据，确保它完全可以进行训练。 🔹 CNN 架构和 NAS 模型：我们将使用 Nas Large 模型，并根据我们自己的需求对其进行自定义。 🔹 模型训练：利用 Tensorflow 和 Keras 的强大功能来定义和训练我们基于 Nas Large 模型的自定义 CNN 模型。我们将配置损失函数、优化器和评估指标，以在训练期间实现最佳性能。 🔹 预测新图像：观看我们对预先训练的模型进行测试！我们将展示如何使用该模型对新鲜的、从未见过的恐龙图像进行预测，并见证人工智能的魔力。   在此处查看我们的教程：https://youtu.be/vH1UVKwIhLo&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg 您可以在此处找到完整的代码：https://medium.com/p/b0008357e39c 您可以在此处找到更多教程并加入我的时事通讯：https://eranfeit.net/ 享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</guid>
      <pubDate>Sun, 03 Nov 2024 18:16:25 GMT</pubDate>
    </item>
    <item>
      <title>Oasis：基于扩散变压器的模型，用于生成可玩的视频游戏</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</link>
      <description><![CDATA[decart 和 etched 开发的 Oasis 已经发布，它可以输出可玩的视频游戏，用户可以执行移动、跳跃、检查库存等操作。这不像谷歌的 GameNGen，它只能输出游戏视频（但不能播放）。在此处查看演示和其他详细信息：https://youtu.be/INsEs1sve9k    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</guid>
      <pubDate>Sat, 02 Nov 2024 09:55:08 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的偏差</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</link>
      <description><![CDATA[大家好，我最近开始研究神经网络。让我有些困惑的概念是偏差。我理解偏差在神经网络中的用途，但我仍然不明白两件事：  各个隐藏层中的每个单元是否都有自己的偏差，或者每个隐藏层的所有单元是否有共同的偏差？ 我不明白为什么在某些情况下偏差通过一个单元来表示，并附加自己的权重。它不应该是一个参数，因此不应该作为一个单元出现吗？     提交人    /u/Annual_Inflation_235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</guid>
      <pubDate>Thu, 31 Oct 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>运行此代码需要多少普通内存</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</link>
      <description><![CDATA[import torch 导入 torch.nn 作为 nn class TransformerBlock(nn.Module): def __init__(self, embed_size, heads, dropout, forward_expansion): super(TransformerBlock, self).__init__() self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads) self.norm1 = nn.LayerNorm(embed_size) self.norm2 = nn.LayerNorm(embed_size) self.feed_forward = nn.Sequential( nn.Linear(embed_size, forward_expansion * embed_size), nn.ReLU(), nn.Linear(forward_expansion * embed_size, embed_size) ) self.dropout1 = nn.Dropout(dropout) self.dropout2 = nn.Dropout(dropout) def forward(self, x):tention = self.attention(x, x, x)[0] x = self.dropout1(self.norm1(attention + x)) forward = self.feed_forward(x) out = self.dropout2(self.norm2(forward + x)) return out class ChatGPT(nn.Module): def __init__(self, embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout): super(ChatGPT, self).__init__() self.embed_size = embed_size self.word_embedding = nn.Embedding(vocab_size, embed_size) self.position_embedding = nn.Embedding(max_length, embed_size) self.transformer_blocks = nn.ModuleList( [TransformerBlock(embed_size, num_heads, dropout, forward_expansion) for _ in range(num_layers)] ) self.fc_out = nn.Linear(embed_size, vocab_size) self.dropout = nn.Dropout(dropout) def forward(self, x): N, seq_length = x.shape positions = torch.arange(0, seq_length).expand(N, seq_length).to(x.device) out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) for transformer in self.transformer_blocks: out = transformer(out) out = self.fc_out(out) return out # 大型模型的模型超参数（类似于 GPT-3） embed_size = 12288 # 大型模型的嵌入大小 num_heads = 96 # 注意力头的数量 num_layers = 96 # 数量Transformer 块的数量 vocab_size = 50257 # 词汇表的大小（GPT-3 使用更大的词汇表） max_length = 2048 # 输入序列的最大长度 forward_expansion = 4 # 前馈层的扩展因子 dropout = 0.1 # 丢失率 # 初始化模型 model_0 = ChatGPT(embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout)  ```     submitted by    /u/Budget-Relief1307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</guid>
      <pubDate>Wed, 30 Oct 2024 15:41:01 GMT</pubDate>
    </item>
    </channel>
</rss>