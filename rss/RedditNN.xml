<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 07 Dec 2024 01:20:57 GMT</lastBuildDate>
    <item>
      <title>流匹配增强潜在扩散，实现高效的高分辨率图像合成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h7ai9x/flow_matching_enhances_latent_diffusion_for/</link>
      <description><![CDATA[本文介绍了一种将流匹配与潜在扩散模型相结合以提高图像生成效率的方法。关键创新是使用流匹配直接学习潜在空间中的最优轨迹，而不是依赖于标准的去噪扩散。 主要技术要点： - 引入高斯假设以有效计算潜在空间中的流匹配 - 使用具有交叉注意的 U-Net 主干进行条件反射 - 保持潜在扩散模型的自动编码器结构 - 实现随机流匹配以优化轨迹 - 与基线​​扩散模型相比，训练速度提高 2-3 倍 结果： - 在标准基准上提高了 FID 分数 - 更少的推理步骤，更好的样本质量 - 更稳定的训练动态 - 降低训练和推理的计算要求 - 与标准扩散方法相比，结果相当或更好 我认为这对计算资源有限的研究人员和组织尤其有影响。更快的训练时间和更低的计算要求可以使高级图像生成更容易实现。该方法还为其他生成任务提出了一条更高效的架构之路。 我看到了快速原型设计和生成模型迭代中的潜在应用，尽管高斯假设存在一些限制，可能需要进一步研究。这种方法在训练效率优先于最终样本质量的情况下似乎特别有前景。 TLDR：流匹配 + 潜在扩散 = 更快的训练和推理，同时保持质量。关键创新是使用高斯假设在潜在空间中进行有效的轨迹学习。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h7ai9x/flow_matching_enhances_latent_diffusion_for/</guid>
      <pubDate>Thu, 05 Dec 2024 14:33:36 GMT</pubDate>
    </item>
    <item>
      <title>霍普菲尔德神经网络中的类分形吸引盆。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6zd6t/fractallike_basins_of_attraction_in_hopfield/</link>
      <description><![CDATA[https://reddit.com/link/1h6zd6t/video/uzz843zo5y4e1/player    由   提交  /u/Mountain_Raise9581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6zd6t/fractallike_basins_of_attraction_in_hopfield/</guid>
      <pubDate>Thu, 05 Dec 2024 03:12:28 GMT</pubDate>
    </item>
    <item>
      <title>PointNet Ensemble 改进了 CERN 的反物质湮灭位置重建</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6fdsk/pointnet_ensemble_improves_antimatter/</link>
      <description><![CDATA[研究人员开发了一种深度学习方法，用于检测和分类 CERN 的 ALPHA 实验中的反氢湮没事件。关键创新是将 CNN 架构与专为反物质特征检测而设计的自定义物理信息层相结合。 关键技术要点： - 自定义神经网络架构处理来自硅顶点探测器的原始探测器数据 - 在真实和模拟的反氢湮没事件上训练的模型 - 根据已知的反物质行为实现物理信息正则化 - 使用数据增强来处理有限的训练示例 - 实现实时处理（每个事件&lt;1ms） 结果： - 测试集准确率为 99.9% - 假阳性率为 0.1% - 性能与人类专家分析相匹配 - 针对传统重建方法进行了验证 - 在不同的实验条件下保持准确性 我认为这项工作为将 ML 应用于其他罕见物理事件开辟了有趣的可能性。实时处理事件的能力可以实现传统分析流程无法实现的新型实验。基于物理的架构方法也可能很好地转移到其他粒子物理问题。 我特别感兴趣的是他们如何处理有限的训练数据挑战——反物质事件极其罕见且成本高昂。他们的数据增强和基于物理的正则化技术对于具有类似约束的其他领域可能很有价值。 TLDR：深度学习系统在 CERN 检测反物质湮灭事件的准确率达到 99.9%，使用基于物理的神经网络将分析时间从数小时缩短到几毫秒。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6fdsk/pointnet_ensemble_improves_antimatter/</guid>
      <pubDate>Wed, 04 Dec 2024 12:59:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 LVM 自动注释数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6b9ti/autoannotate_datasets_with_lvms/</link>
      <description><![CDATA[       由    /u/erol444  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6b9ti/autoannotate_datasets_with_lvms/</guid>
      <pubDate>Wed, 04 Dec 2024 08:17:00 GMT</pubDate>
    </item>
    <item>
      <title>“裂脑实验”获得的经验教训是否有助于开发更智能的神经网络/机器学习软件？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5sbvw/can_the_lessons_learned_with_the_split_brain/</link>
      <description><![CDATA[如果你不知道，这种名为“胼胝体切开术”的手术是用于帮助治疗严重癫痫患者的最后手段。嗯，它的副作用是它也会将大脑的意识一分为二。 这意味着大脑的一侧会在人不愿意的情况下控制身体的一半，他们的手会不受控制地抓取东西等等。虽然这听起来可能有些极端，但两种意识仍然在某种程度上是相连的，仍然是一个人，而不是“邪恶版”你自己或类似的东西。 关于这个主题有很多视频，但本质上： 从已经完成的所有研究来看，人们相信（或证明，我不是神经科学家）大脑是由几个&quot;黑匣子&quot; 组成的处理隔间和半独立的意识，它们都同步协同工作。 但是，每个&quot;隔间&quot; 都专门用于特定任务，例如视觉信息、运动控制、通信等。 因此，拥有一个有点类似/模仿人类大脑这种区域划分的神经网络是否可以实现更聪明的人工智能？    提交人    /u/KalyanDipak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5sbvw/can_the_lessons_learned_with_the_split_brain/</guid>
      <pubDate>Tue, 03 Dec 2024 17:07:35 GMT</pubDate>
    </item>
    <item>
      <title>控制图像生成。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5oha4/control_image_generation/</link>
      <description><![CDATA[大家好，有没有办法使用本地数据库中的项目来控制图像的生成。例如： - 我输入一个提示或房间的图像，或者两者兼而有之。 - 该模型将为我生成一个房间，其中的所有项目都来自本地数据库（mongodb 或 sql）。现在我的问题： - 怎么做？ - 如果是，那么如何构建它？ - 如何设置数据库结构？     提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5oha4/control_image_generation/</guid>
      <pubDate>Tue, 03 Dec 2024 14:21:34 GMT</pubDate>
    </item>
    <item>
      <title>霍普菲尔德神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5gasl/hopfield_neural_networks/</link>
      <description><![CDATA[John Hopfield 今年与 G. Hinton 一起获得了诺贝尔物理学奖。有人玩过 Hopfield 神经网络系统吗？我玩过，而且对于这样一个简单的系统，它们具有一些有趣的特性。我将盆地映射为存储的记忆数量的函数。它们看起来像分形。如果有人感兴趣，我很乐意发布和分享。    提交人    /u/Mountain_Raise9581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5gasl/hopfield_neural_networks/</guid>
      <pubDate>Tue, 03 Dec 2024 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>用于计算机视觉和机器学习的 13 种图像数据清理工具</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4yet4/13_image_data_cleaning_tools_for_computer_vision/</link>
      <description><![CDATA[        提交人    /u/codingdecently   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4yet4/13_image_data_cleaning_tools_for_computer_vision/</guid>
      <pubDate>Mon, 02 Dec 2024 16:06:40 GMT</pubDate>
    </item>
    <item>
      <title>L1 与 L2 正则化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4rubo/l1_vs_l2_regularization/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4rubo/l1_vs_l2_regularization/</guid>
      <pubDate>Mon, 02 Dec 2024 10:15:38 GMT</pubDate>
    </item>
    <item>
      <title>用 C 语言更新密集分层神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4pl5i/update_to_dense_layered_nn_in_c/</link>
      <description><![CDATA[大家好！大约两周前，我发布了一篇关于从头开始用 C 语言创建的密集分层神经网络的文章。我想发布一篇关于我所做工作的一些更新的文章。该网络目前支持与分类相关的 NN，GitHub 已清理干净以供查看。任何反馈都将不胜感激。 https://github.com/Asu-Ghi/Personal_Projects/tree/main/MiniNet 感谢您的时间    提交人    /u/AsuGhi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4pl5i/update_to_dense_layered_nn_in_c/</guid>
      <pubDate>Mon, 02 Dec 2024 07:25:23 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能训练一个模型，将视频中的所有鞋子都替换为 Crocs 鞋？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h1mbz9/would_it_be_possible_to_train_a_model_to_replace/</link>
      <description><![CDATA[对于新手（我）来说，这会有多难呢？    提交人    /u/Edgele55Placebo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h1mbz9/would_it_be_possible_to_train_a_model_to_replace/</guid>
      <pubDate>Thu, 28 Nov 2024 03:03:28 GMT</pubDate>
    </item>
    <item>
      <title>VanceNet 神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h1m2a8/vancenet_neural_network/</link>
      <description><![CDATA[我制作了一个名为 VanceNet 的神经网络，它旨在识别和分析复杂系统中的模式。它还使用基于动态能量的神经元、进化更新和分形分析来适应和发展。通过跟踪熵和分形维数等指标，VanceNet 生成越来越复杂的模式，使其可用于生成艺术、混沌系统建模和科学研究等应用。如果您想了解更多信息，请查看此处的研究论文：VanceNet    提交人    /u/AnyCookie10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h1m2a8/vancenet_neural_network/</guid>
      <pubDate>Thu, 28 Nov 2024 02:48:49 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的异常检测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h0a90g/transformer_based_anomaly_detection/</link>
      <description><![CDATA[我正在尝试构建一个基于 Transformer 自动编码器架构的异常检测模型，该模型将根据重建误差检测股票价格异常。将使用过去 5 年（最好是 15 到 20 只股票）的 OHCLV 历史数据来训练模型，并使用实时 API 并通过 Kafka 进行提取以进行测试。 这将是我第一次在基于 Transformer 的架构上工作的项目。任何熟悉这些概念的人都可以告诉我在这个项目上我会遇到什么样的障碍，请提及任何可以帮助我构建这个项目的宝贵资源。    提交人    /u/East-Agent9391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h0a90g/transformer_based_anomaly_detection/</guid>
      <pubDate>Tue, 26 Nov 2024 12:02:50 GMT</pubDate>
    </item>
    <item>
      <title>对由医生监督的法学硕士 (LLM) 进行医学聊天支持的大规模评估表明患者满意度有所提高</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gy8wcv/largescale_evaluation_of_a_physiciansupervised/</link>
      <description><![CDATA[本文介绍了医学 LLM 助手的实际部署，该助手可帮助大规模分类和处理患者问询。该系统使用多阶段架构，结合了医学知识注入、对话能力和安全护栏。 关键技术组件：- 与 LLM 集成的自定义医学知识库- 用于查询理解和响应生成的多阶段管道- 用于检测超出范围的请求的安全分类系统- 用于验证的合成患者测试框架- 人在环监控系统 部署结果：- 在法国为 200,000 多名用户提供服务- 92% 的用户满意率- 医生工作量显着减少- 保留测试用例的安全得分为 99.9%- 平均响应时间在 30 秒以下 我认为这表明经过严格约束的 LLM 可以安全地部署用于基本的医疗分类和信息提供。具有明确安全检查的多阶段架构似乎是高风险领域的一种有前途的方法。然而，该系统仅限于文本交互，并且依赖于患者的准确症状报告，这表明我们距离完全自动化的医疗护理还很远。 综合测试框架特别有趣 - 它对于在现实世界测试存在风险的其他受监管领域开发类似系统可能很有价值。 TLDR：使用具有安全保障的多阶段架构的生产医学 LLM 助理在实际部署中显示出有希望的结果，处理 200k+ 用户，满意度达到 92%，同时减少了医生的工作量。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gy8wcv/largescale_evaluation_of_a_physiciansupervised/</guid>
      <pubDate>Sat, 23 Nov 2024 20:23:27 GMT</pubDate>
    </item>
    <item>
      <title>Design2Code：评估 Web 开发中屏幕截图到代码生成的多模式 LLM</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gx897w/design2code_evaluating_multimodal_llms_for/</link>
      <description><![CDATA[本文介绍了一种名为 Design2Code 的系统基准，用于评估多模式 LLM 将网页截图转换为功能性 HTML/CSS 代码的效果。该方法涉及使用自动和人工评估在 484 个真实网页示例中测试 GPT-4V、Claude 3 和 Gemini 等模型。 关键技术要点：* 创建了一个多样化的网页截图数据集，并与真实代码配对* 开发了评估视觉元素回忆和布局准确性的自动指标* 测试了不同的提示策略，包括零样本和少样本方法* 使用自动指标和人工评估比较模型性能* 发现当前模型在视觉元素回忆方面实现了约 70% 的准确率，但在精确布局方面存在困难 主要结果：* GPT-4V 总体表现最佳，其次是 Claude 3 和 Gemini* 模型经常错过较小的视觉元素，并且难以准确定位* 随着网页复杂度的增加，布局准确性显着下降* 使用类似示例的少样本提示可将性能提高 5-10%* 人工评估者仅将 45% 的生成代码评为完全正常运行 我认为这个基准对于衡量多模式代码生成的进度很有价值，类似于 BLEU分数有助于跟踪机器翻译的改进。结果突出显示了当前模型需要改进的特定领域，特别是在保持视觉保真度和处理复杂布局方面。这可能有助于将研究工作集中在这些挑战上。 我认为研究结果还表明，虽然自动网页生成尚未准备好用于生产，但它已经可以作为开发人员的辅助工具，特别是对于更简单的布局和初始原型。 TLDR：新的基准测试 AI 将网页设计转换为代码的能力。当前模型可以识别大多数视觉元素，但在精确布局方面存在困难。GPT-4V 处于领先地位，但需要进行重大改进才能用于生产。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gx897w/design2code_evaluating_multimodal_llms_for/</guid>
      <pubDate>Fri, 22 Nov 2024 13:48:52 GMT</pubDate>
    </item>
    </channel>
</rss>