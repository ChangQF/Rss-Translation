<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Mon, 25 Mar 2024 12:23:33 GMT</lastBuildDate>
    <item>
      <title>如何使用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Mon, 25 Mar 2024 09:05:45 GMT</pubDate>
    </item>
    <item>
      <title>FeatUp：一种机器学习算法，可升级深度神经网络的分辨率以提高计算机视觉任务的性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</guid>
      <pubDate>Mon, 25 Mar 2024 06:46:48 GMT</pubDate>
    </item>
    <item>
      <title>我需要有关 SoftMax 函数的说明</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</link>
      <description><![CDATA[我最近一直在开发一个深度学习库，以更好地理解机器学习概念，现在我正在实现一个软最大激活函数，一切似乎都是正确的，因为我检查了现有 softmax 计算器上的输出和导数的值并且它们匹配起来，但是当我让我的网络进行训练时，它没有学到任何东西，输出要么是 [0.5, 0.4] ish，要么是它们不考虑目标，随机变为 0.9。  当我的数据集中有多个样本（例如图像分类器）时，各个样本的所有输出加起来为 1，这令人困惑。我知道 softmax 应该将 1 个样本的输出分配为“概率”但我不明白为什么它发生在我的数据集的样本之间 我很困惑，softmax 是否只是一个常规激活函数，或者它是否像一个特殊情况。我看到一个视频，他们将 softmax 视为一层而不是激活函数，这让我怀疑与其他激活函数相比，softmax 函数是否具有不同的反向传播步骤。当我将最后一个激活函数更改为 sigmoid、tanH 或 ReLU 时，一切正常。 非常感谢任何反馈或评论，因为我花了几个小时在这上面。   由   提交 /u/chjammy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</guid>
      <pubDate>Sun, 24 Mar 2024 19:13:17 GMT</pubDate>
    </item>
    <item>
      <title>回归网络中使用什么样的激活函数？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmentm/what_kind_of_activation_functions_are_used_in/</link>
      <description><![CDATA[我正在从头开始编码一个神经网络，并且想知道哪种激活函数最适合回归问题（我正在尝试让它评估输入）。我的权重和偏差应该在什么样的范围内，它们应该是负数还是正数。训练过程与分类网络有何不同？感谢任何帮助:)   由   提交 /u/Crisps_Beluker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmentm/what_kind_of_activation_functions_are_used_in/</guid>
      <pubDate>Sun, 24 Mar 2024 07:02:21 GMT</pubDate>
    </item>
    <item>
      <title>大学人工智能项目帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/</link>
      <description><![CDATA[我正在做一个项目，我们利用神经网络模型来评估描述性答卷。目前我们只有大约 120 篇论文来训练它，即 2 套试卷。这够了吗？ bert 是这个项目的好模型吗？   由   提交/u/Similar-Ranger4226   reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/</guid>
      <pubDate>Sun, 24 Mar 2024 05:20:09 GMT</pubDate>
    </item>
    <item>
      <title>训练 LLMS 遵循人类反馈指令 (RLHF) - 论文解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkxae4/training_llms_to_follow_instructions_with_human/</link>
      <description><![CDATA[       由   提交/u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkxae4/training_llms_to_follow_instructions_with_human/</guid>
      <pubDate>Fri, 22 Mar 2024 11:45:40 GMT</pubDate>
    </item>
    <item>
      <title>思维链推理如何帮助神经网络计算</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkq1wk/how_chainofthought_reasoning_helps_neural/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkq1wk/how_chainofthought_reasoning_helps_neural/</guid>
      <pubDate>Fri, 22 Mar 2024 03:40:49 GMT</pubDate>
    </item>
    <item>
      <title>关于CNN池化工具的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</link>
      <description><![CDATA[HI AI &amp;机器学习专家： 我是一名设计师，试图从高层次上理解 CNN。我被池化工具卡住了。 如果我理解正确的话，请告诉我：池化工具更像是轮廓、对比、凹陷的工具，让某些特征突出，同时减少计算负载，因为通过这些关键轮廓、对比度、凹面等部分，CNN 提取了足够的关键信息以供后续 ANN 处理。 我理解正确吗？我期待您的专家意见。谢谢！   由   提交/u/Ivory8977  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</guid>
      <pubDate>Thu, 21 Mar 2024 21:54:47 GMT</pubDate>
    </item>
    <item>
      <title>帮助描述性答卷评估器 NN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</link>
      <description><![CDATA[我是一名大学生，目前正在进行人工智能项目。它是一个答卷评估器，其中神经网络输入已经评估的答卷及其相应的分数。我对神经网络了解不多，所以谁能告诉我使用哪种神经网络模型。我正在考虑将 bert 和 cnn 配对。请建议良好的模型配对，以制作最准确的模型   由   提交/u/Consistent_Peanut998   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</guid>
      <pubDate>Thu, 21 Mar 2024 17:02:26 GMT</pubDate>
    </item>
    <item>
      <title>NN用于研究？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjyfiw/nn_for_research/</link>
      <description><![CDATA[未来几十年的机器学习研究领域会怎样？我只见过物理、生物和化学研究领域的负责人，但是机器学习研究领域怎么样？我应该考虑未来30-40年在这个领域的学习吗？最后，需求是什么，任何东西都会有帮助。   由   提交/u/Background_Bowler236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjyfiw/nn_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 04:43:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的基本神经网络偶尔会无法“学习”，但通常会产生约 95% 的准确率？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjt0mg/why_does_my_basic_neural_network_occasionally/</link>
      <description><![CDATA[我正在关注这个简单的教程，但是在这个数据集中进行替换并进行相应的调整。  我已经让它工作了（大多数时候），并且网络可以预测 URL 是网络钓鱼还是合法，准确率约为 95%（当它工作时）。  偶尔，也许有五分之一的情况，产生的权重最终对预测完全无用。这是神经网络训练的常见问题吗？如果需要，我可以提供代码，但代码与教程中的代码几乎相同，除了输入和输出神经元数量的一些更改以及显然对不同数据的不同处理之外。 就像这样在训练过程的开始阶段就出现了一些问题，并且无法逃脱它所发现的灾难。 有人在工作中遇到过类似的情况吗？我对这一切都非常陌生，所以如果这个问题很天真，我深表歉意。   由   提交 /u/allthenine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjt0mg/why_does_my_basic_neural_network_occasionally/</guid>
      <pubDate>Thu, 21 Mar 2024 00:17:10 GMT</pubDate>
    </item>
    <item>
      <title>半监督和自监督学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjkpvl/semisupervised_and_selfsupervised_learning/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjkpvl/semisupervised_and_selfsupervised_learning/</guid>
      <pubDate>Wed, 20 Mar 2024 18:34:46 GMT</pubDate>
    </item>
    <item>
      <title>自然语言指令诱导神经元网络中的成分泛化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1biry2e/natural_language_instructions_induce/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1biry2e/natural_language_instructions_induce/</guid>
      <pubDate>Tue, 19 Mar 2024 18:50:46 GMT</pubDate>
    </item>
    <item>
      <title>像素完美：工程师的新方法使图像成为焦点</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bilj9u/pixel_perfect_engineers_new_approach_brings/</link>
      <description><![CDATA[   /u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bilj9u/pixel_perfect_engineers_new_approach_brings/</guid>
      <pubDate>Tue, 19 Mar 2024 14:26:06 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何学习？数学公式解释了它们如何检测相关模式</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bid6t5/how_do_neural_networks_learn_a_mathematical/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bid6t5/how_do_neural_networks_learn_a_mathematical/</guid>
      <pubDate>Tue, 19 Mar 2024 05:52:47 GMT</pubDate>
    </item>
    </channel>
</rss>