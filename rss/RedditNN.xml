<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Mon, 03 Mar 2025 12:35:02 GMT</lastBuildDate>
    <item>
      <title>以子任务为导向的增强微调通过结构化分解增强了LLM发行问题的分辨率</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j1l62m/subtaskoriented_reinforced_finetuning_enhances/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   sorft：将软件问题分解为可管理的子任务  sorft引入一种新颖的微调方法，该方法可以通过将复杂的编程将复杂的任务分解为子任务并使用强制性地进行效果的效果。 Subtask-oriented planning: The model first plans out smaller, manageable subtasks before coding - Sequential Execution: Implements solutions step-by-step, following a natural programming workflow - Reinforcement Learning: Uses RL to reward successful code that compiles and passes tests - Code Navigation Integration: Incorporates real-world software engineering practices like file探索  结果：  -   25％改善在代码生成准确性上比基线模型比基线模型 - 实现 24.6％Pass@1 在微调7B基本模型后，在Swe -Bench上 - 在处理更高的代码和更高的代码 per&gt; per&gt;  &lt;认为这种方法特别有价值，因为它反映了人类程序员的实际工作方式。通过将问题分解为较小的组件，该模型生成的解决方案不仅更有可能成功，而且更容易理解和维护。  我认为，加强学习与子任务计划的集成解决了当前代码生成模型的基本限制 - 他们经常尝试在没有适当计划的情况下立即解决所有问题。这种顺序方法最终可能会导致AI助手，这些助手可以以与现有的开发工作流充分整合的方式处理更复杂的软件工程任务。     tldr： sorft改善代码生成，通过将编程问题分解为子任务，并使用强大的范围完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j1l62m/subtaskoriented_reinforced_finetuning_enhances/</guid>
      <pubDate>Sun, 02 Mar 2025 07:09:38 GMT</pubDate>
    </item>
    <item>
      <title>最后一年项目：建立基于自适应聊天的导师</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0vxv6/final_year_project_building_an_adaptive_chatbased/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我是最后一年的学生，我需要提出一个项目。我打算为其处理的项目一个基于聊天的系统，该系统适应用户的喜好。请我需要可以帮助构建该项目的想法和资源。 您的评论非常感谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ajax_shotz     [link]  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1j0vxv6/final_year_year_project_building_an_adaptive_chatbassed/]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0vxv6/final_year_project_building_an_adaptive_chatbased/</guid>
      <pubDate>Sat, 01 Mar 2025 09:42:00 GMT</pubDate>
    </item>
    <item>
      <title>科学假设生成的多代理AI系统：生物医学发现中的设计和验证</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0u187/multiagent_ai_system_for_scientific_hypothesis/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了建立在Gemini 2.0上的多代理AI系统，该系统通过迭代的发电，辩论和进化过程来生成和评估科学假设。该系统实施了锦标赛风格的方法，其中不同的AI代理提出了假设，然后通过结构化的辩论对其进行严格评估和完善。 关键技术要点： *架构使用多个可以用计算资源扩展的异步AI代理，这些AI使用了计算资源 *实现“生成debate-evolve a”受到科学方法的启发 *在三个生物医学领域进行验证的循环：药物重新利用，目标发现和细菌进化 *使用文献分析，途径建模和机械推理的组合 *通过实验性验证之前的结果，通过在实验室验证 的结果中，对假设进行了结构化的辩论：肝纤维化的靶标在器官模型中得到证实 *与未发表的实验发现相匹配的独立提出的细菌基因转移机制 *产生的假设比基线方法   ，我认为这是朝着AI-Assisted Scientific Discoverion迈出的重要步骤，尤其是在生物素中。显着的实验验证实际验证的可检验假设的能力是值得注意的。尽管该系统没有取代人类科学家，但它可以显着加速假设的产生和测试周期。 我认为，关键的创新是结构化的多代理辩论方法，而不是仅仅产生思想，而是系统对其进行批判性评估并逐渐发展。这反映了人类科学家的工作方式并似乎产生了更高质量的假设。  tldr：多代理AI系统使用生成的驱动循环来产生科学的假设，在生物医学领域进行了实验验证。显示了加速科学发现过程的希望。  完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0u187/multiagent_ai_system_for_scientific_hypothesis/</guid>
      <pubDate>Sat, 01 Mar 2025 07:24:40 GMT</pubDate>
    </item>
    <item>
      <title>不确定这是否是发布此信息的正确位置</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//github.com/choc1024/iac       我知道它不是很快，也不是如此之多，如果有很多东西，我都不会有这样的特征，并且可以与您分享，或者我会喜欢它，并且您会在您的特点上，并且您会在您的特点如果不是这样，请向我推荐另一个subreddit。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/i/im_chatgpt4    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1j0iq9n/not_sure_sure_this_is_is_is_the_right_tplace_tplace_to_to_to_post_this/”&gt; [links]    [注释]      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</guid>
      <pubDate>Fri, 28 Feb 2025 21:23:59 GMT</pubDate>
    </item>
    <item>
      <title>在没有单词限制的情况下免费进行语音文本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</link>
      <description><![CDATA[        ＆＃32;提交由＆＃32; /u/u/u/cool-hornet-8191      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</guid>
      <pubDate>Fri, 28 Feb 2025 16:01:17 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的临床注释的整合，以增强疾病轨迹预测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种基于变压器的方法，用于分析临床注释和预测患者轨迹。关键方法论贡献是将时间注意机制与特定领域的医学文本处理整合到预测患者预后的多个方面。 主要技术点：•多头注意的架构适用于临床注意事项序列，专门针对临床注释序列•预处理管道•跨越多个治疗术语的范围范围•先前验证•先前的时间术语•以前的时间范围•零舒适的范围•零舒适的范围，零，• （重新入院，住院时间，进步） 结果：•基线模型的再入院预测准确性提高了12％•在现场长度预测中的准确性提高了15％•在具有多种合并症的复杂案例上的出色表现•多种合并症的复杂案例•维持多个合并症的质量保持了预测质量，而不同的医疗专业 我认为，这项工作朝着更全面的临床支持系统支持系统。与结构化数据一起处理非结构化临床笔记的能力可以帮助捕获当前系统错过的微妙模式。 However, the computational requirements and need for high-quality training data may limit immediate widespread adoption. I think the zero-shot capabilities are particularly noteworthy, as they suggest potential applications in rare conditions or emerging health challenges where training data is limited. TLDR: Transformer model analyzes clinical notes to predict patient trajectories, showing improved accuracy over baselines and zero-shot capabilities.可以增强临床决策支持，但需要仔细验证。 完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</guid>
      <pubDate>Fri, 28 Feb 2025 10:13:04 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类是否需要单次编码？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j03vjh/does_multilabel_classification_require_onehot/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个数据集，该数据集基本上包含一个相对于8个同时类标记的内容字符串，每个类都有几个选项（即多标签）。在整个类中将所有选项添加在一起，总共有23个独特的标签。 最初，我通过使用8个单独的多级分类器来解决此问题，尽管它效果很好，但考虑到每个分类器都需要一个特定的内容和切片，它可能会犯错误。另外，我更喜欢“简单性”。只需要关心一个神经网络而不是8个分类器。  结果，我建立了一个具有多标签输出层的神经网络，该层产生了单热编码的输出。我现在确定的问题是，这个神经网似乎并没有库存，标签在课堂内是相互排斥的（例如，第一堂课有4个可能的标签，但只有1个标签，但应该是非零的标签）。 因此，我的印象是，我得到这样的方式，这样做的方式是这样做的，我可能需要训练很多数据，因此我有一个有效的培训，我是否有一个有效的需要，我是否需要一个人，我是否需要一个eccod。我可以使用产生8个标签的数组的输出层（而不是23个标签），并且其值是非二进制的，但直接反映了选项。因此，例如，如果1类最好的标签是第三个标签，则输出层返回“ 3”。而不是[0,0,1,0 ...]。如果是这样，我必须对当前使用Sigmoid激活函数和二进制Crossentropyloss函数的输出层进行哪些调整。  当然也欢迎其他任何想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j03vjh/does_multilabel_classification_require_onehot/</guid>
      <pubDate>Fri, 28 Feb 2025 09:29:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用卷积神经网络对疟疾细胞进行分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1izmrzi/how_to_classify_malaria_cells_using_convolutional/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    本教程提供了一份逐步指南，介绍了如何使用TensorFlow和Keras实施和培训CNN模型进行疟疾细胞分类。                      数据准备中的数据准备，您可以在此部分进行培训，并在此部分下载数据，并准备该数据供应数据，并准备该数据供您进行数据准备。这涉及到诸如准备数据，分类为训练和测试集，以及必要时进行数据扩展。       cnn模型构建和培训 -  在第二部分中，您将专注于建立卷积神经网络（CNN）模型，用于用于疟疾细胞的二元分类。这包括模型自定义，定义层和使用准备好的数据训练模型。     模型测试和预测 -  最终部分涉及使用以前从未见过的新图像测试训练的模型。您将加载已保存的模型并使用它来对此新图像进行预测以确定是否感染。       您可以在博客中找到代码的链接：      href =“ https://medium.com/@feitgemel/how-to-complasify-malaria-cells-using-convolutional-neur-network-c00859bc6b46”&gt; https://medium.com/@feitgemel/how-to-classify-malaria-cells-using-convolutional-neurner-network-c00859bc6b46     您可以找到更多教程，并在此处加入我的新闻通讯： https://eranfeit.net/                 href =“ https://youtu.be/wlpuw3ggpqo＆amp;list=uulftiwjjhah6bviswkljum9sg”&gt; https://youtu.be/youtu.be/wlpuw3ggppqo&amp;/ wlppuppqo&amp;list=ulist=uulfftiiwjjjjjjjhah6bvis     在提交由＆＃32; /u/feitgemel     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1izmrzi/how_to_classify_malaria_cells_using_convolutional/</guid>
      <pubDate>Thu, 27 Feb 2025 18:30:29 GMT</pubDate>
    </item>
    <item>
      <title>稳定垃圾邮件：增强梯度归一化，以进行更高效的4位LLM训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1izcdva/stablespam_enhanced_gradient_normalization_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一种新方法结合了尖峰感动的动量和优化的4位量化，以启用比16位亚当的稳定训练，同时使用明显更少的内存。关键的创新是通过仔细的梯度监控在低度训练期间检测和预防优化的不稳定性。 主要技术点： - 引入尖峰 - 尖峰 - 施加 spike -avare动量重置，以梯度统计量，以调查潜在的不稳定性 - 检测潜在的不稳定性 - 使用动态调整量表的量表量尺度，以量表为基础量表，以4位的量度为基础量表 - 该量度的量表 - 以4位的量度为基础量表 - 该量表 - 以4位的量级为基础量表 - 该量表 - 以4位的量级为基础量表 - 保持重量和梯度量化量表的单独跟踪 - 与现有的优化器和体系结构兼容 关键结果： - 匹配或超过16位的ADAM性能，同时使用75％的记忆力 - 成功地训练Bert -large到4位精确的4位精确培训 - 从1E -4到1E -4的学习率稳定培训 - 在1e -4的范围内显示出稳定的培训 - 参数 我认为这对于使ML研究民主化可能会产生影响。培训大型模型目前需要大量的GPU资源，并且能够以4位精确的精度进行培训，而无需牺牲稳定性或准确性，这可能会使研究预算有限的实验室更容易获得研究。 我认为，Spike-Aware Momentum Reset Reset Technique    可以证明，不仅可以证明一种不仅能够改善最优先级的其他情况&lt;其他情况&gt;其他情况&lt;其他情况&gt; &lt;其他情况&lt;&lt;其他情况。方法可以通过仔细的动量管理和优化的量化来实现稳定的4位模型训练，将16位性能与少75％的内存使用量匹配。   full unshore   。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1izcdva/stablespam_enhanced_gradient_normalization_for/</guid>
      <pubDate>Thu, 27 Feb 2025 10:03:19 GMT</pubDate>
    </item>
    <item>
      <title>Anyon可以推荐一些最佳初学者友好的卷积神经网络教程，这将导致智能照明系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/arnoldpaclarinjr     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</guid>
      <pubDate>Wed, 26 Feb 2025 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>偏爱感知的LLM框架，用于事实基础营销内容生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一个新框架，用于生成营销内容，以保持说服力和事实准确性之间保持平衡。 The core innovation is a two-stage architecture combining a retrieval module for product specifications with a controlled generation approach. Key technical components: - Grounded generation module that references source product specifications during content creation - Persuasion scoring mechanism measuring effectiveness across multiple marketing dimensions - Fact alignment checker comparing generated content against source material - Novel将50,000个产品描述与相应的营销材料结合的数据集 结果显示：-23％的说服力提高了基线模型（通过人类评估测量）-91％的事实准确性在合并产品规格时保持了实际的事实准确性 - 合并产品规格的大量降低幻觉降低了幻觉产品的幻觉效果，与标准LLM的销售方法相比，可以自动销售自动流动 - 在自动销售中保持自然的影响 我认为，最有趣的技术方面是它们如何处理创意营销语言和事实约束之间的权衡。检索功能的方法可能有可能应用于需要创造力和准确性的其他领域。  tldr：AI营销内容生成的新框架，可保持事实准确性，同时优化说服力，显示出23％的提高有效性，同时保持91％的事实准确性。     完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</guid>
      <pubDate>Wed, 26 Feb 2025 09:59:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间缩放方法在数学推理任务中显示出有限的多语言概括</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键洞察力是使用测试时间缩放来改善跨多种语言的数学推理，而无需重新训练模型。 The researchers apply this technique to competition-level mathematics problems that go well beyond basic arithmetic. Main technical points: - Test-time scaling involves generating multiple solution attempts (5-25) and selecting the most consistent answer - Problems were carefully translated to preserve mathematical meaning while allowing natural language variation - Evaluation used competition-level problems including algebra, geometry, and proofs - Performance gains were consistent across all tested语言 - 特别注意维持数学符号一致性 关键结果： - 测试时间缩放在所有问题类型和语言中的准确性提高了准确性 - 改进在多步推理问题中最为明显的效果 - 性能提高 - 缩放的缩放相似，无论源语言的质量如何，对数学推理能力                                I think the methodological contribution here - showing that test-time scaling works consistently across languages - is particularly valuable for developing multilingual mathematical AI systems. The limitations around cultural mathematical contexts and translation edge cases suggest interesting directions for future work. TLDR: Test-time scaling improves mathematical在竞争级别的问题上证明，跨语言始终如一地推理。  完整的总结在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</guid>
      <pubDate>Tue, 25 Feb 2025 12:05:01 GMT</pubDate>
    </item>
    <item>
      <title>负责人AI的课程材料</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我目前正在设计负责人AI 的课程，我想寻求帮助，以找到课程内容，任何大学课程或您认为相关的任何大学课程或研究的良好免费材料，请分享。提交由＆＃32; /u/u/over_reward9875    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1iwely0/course_materials_for_responsible_ai/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 16:56:17 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/u/sersion-trainer-541       [注释]         ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>CNN和Tensorboard的新手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  开始学习如何训练CNN，好奇，如果val_accranacy中的初始尖峰是正常的，或者如果峰值是正常的，那么如果Spike drop Drop表示某种过度贴身或某种东西？我本来可以肯定的是，如果Val_accuracy保持较低，但随着模型继续训练，似乎会逐渐增加。这也可以是过度拟合验证数据的模型吗？我正在使用每班大约1500张图像的数据集。谢谢！ 〜一个试图学习cnns   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/stkoopchoop      [注释]           ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</guid>
      <pubDate>Sun, 23 Feb 2025 08:32:09 GMT</pubDate>
    </item>
    </channel>
</rss>