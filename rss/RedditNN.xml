<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Mon, 24 Feb 2025 01:18:55 GMT</lastBuildDate>
    <item>
      <title>负责人AI的课程材料</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我目前正在设计负责AI 的课程对于课程内容，您认为有相关的任何大学课程或研究，请分享。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/over_reward9875    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1iwely0/course_materials_for_responsible_ai/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 16:56:17 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/u/personal-trainer-541      [link]  ＆＃32;   [commist]        &lt; /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>CNN和Tensorboard的新手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  开始学习如何训练CNN，好奇是否在val_accuracy中的初始尖峰是正常或如果尖峰掉落表示某种过度拟合或其他内容？我本来可以肯定的是，如果Val_accuracy保持较低，但随着模型继续训练，似乎会逐渐增加。这也可以是过度拟合验证数据的模型吗？我正在使用每班大约1500张图像的数据集。谢谢！ 〜一个试图学习cnns   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skoopchoop     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</guid>
      <pubDate>Sun, 23 Feb 2025 08:32:09 GMT</pubDate>
    </item>
    <item>
      <title>多模式奖励基地：评估视觉模型奖励功能的综合基准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了多模式奖励贝恩，这是视觉奖励模型的全面评估框架。框架测试使用超过2,000个测试用例，包括准确性，偏差检测，安全考虑和鲁棒性，包括精度，偏差检测，安全考虑和鲁棒性。 关键技术要点： - 使用标准化指标评估6个显着的奖励模型 - 测试涵盖多个功能：响应质量，事实准确性，安全/偏见，跨模式理解 - 引入多模式对齐方式的新颖评估方法 - 为奖励模型提供定量基准测试性能 - 确定当前模型中的特定故障模式 主要结果： - 模型在基本文本评估上显示出强大的性能（＆gt; 80％） - 跨模式理解得分显着下降（〜40-60％） - 安全/偏差检测的较高差异（30-70％范围） - 不同内容类型的性能不一致 - 大多数模型都在涉及这两种模式的复杂推理任务 我认为这项工作的重点是当前奖励模型功能的关键差距，尤其是在处理多模式内容方面。基准可以帮助我们标准化我们如何评估这些模型并推动诸如安全性和偏见检测等领域的改进。 我认为最有价值的贡献是暴露特定的故障模式 - 准确显示当前模型的位置在何处跌落在何处，帮助未来重点。研究工作。结果表明，我们需要从根本上采用新的方法来处理奖励模型中的跨模式内容。  tldr：新的基准测试揭示了视觉奖励模型处理复杂的多模式任务的能力，尤其是在安全性和偏置检测。为改进提供了清晰的指标。 在这里&lt; /a&gt;。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</guid>
      <pubDate>Sun, 23 Feb 2025 07:00:22 GMT</pubDate>
    </item>
    <item>
      <title>Chase：使用LLMS自动生成硬评估问题的框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使LLMS生成挑战性问题的新框架研究如何系统地创建高质量的测试问题。核心方法论通过明确提示策略使用迭代自我测试和有针对性的难度校准。 关键的技术组件： - 具有中间验证的多阶段生成过程 - 自我评估循环，其中LLM批评其自身的输出 - 难以通过参数化提示来定位 - 使用多个模型的交叉验证来验证问题质量 结果： - 问题质量提高40％使用自我测试与基本提示-35％通过迭代精致更好地对齐和预期难度 - 匹配所需的复杂性水平的精度为80％ - 显着降低了琐碎或畸形的问题 我认为这项工作为实用的基础提供了基础用于开发更好的评估数据集。产生校准难度水平的能力可以更精确地帮助基准模型功能。尽管当前的实施使用GPT-4，但原理应扩展到其他LLM。 系统产生问题的系统方法似乎是迈向更严格的测试方法的重要一步。但是，我看到有关将其扩展到非常大的数据集并确保在不同领域的质量一致的一些开放性问题。  tldr：新方法演示了如何通过自我测试和迭代的改进来获得LLMS来产生更好的测试问题，随着问题质量和难度校准的可衡量改善。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</guid>
      <pubDate>Sat, 22 Feb 2025 07:12:27 GMT</pubDate>
    </item>
    <item>
      <title>通过对比度学习从时间序列数据中学习内在的神经表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一种对比度学习方法，将神经活动动态映射到几何表示，提取他们所说的“柏拉图式”人群级神经记录的形状。该方法将时间嵌入与几何约束结合在一起，以揭示基本的组织原理。 关键技术方面： - 在神经时间序列数据上使用对比度学习来学习低维的嵌入 - 应用拓扑结构来强制执行几何结构 - 验证 - 验证 - 验证 - 验证在来自不同物种的多个神经记录数据集中 - 显示了基本几何模式的一致出现（球体，托里等） - 证明了不同神经种群和大脑区域之间的鲁棒性 结果证明了： - 神经种群自然组织成几何歧管 - 这些几何模式在不同的时间范围内保留了这些几何模式 - 在任务和自发活动中始终出现表示的表示 - 方法工作在数十个到数千个神经元的种群上 - 几何结构与行为和认知变量相关 我认为这种方法可以为了解神经种群的编码和过程信息提供新的框架。几何视角可能有助于弥合单神经元和人口水平分析之间的差距。 我认为，如果我们可以可靠地将神经活动映射到神经假体和脑部计算机界面中，则最有趣的潜在影响是一致的几何表示，它可以使解码神经信号更加稳健。  tldr：新方法使用对比度学习如何显示神经种群将信息组织成几何形状，为神经计算提供潜在的通用原理。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</guid>
      <pubDate>Fri, 21 Feb 2025 09:59:51 GMT</pubDate>
    </item>
    <item>
      <title>接近神经网络和机器学习理论的在线课程。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iu02so/online_courses_that_approach_neural_networks_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一名电气工程师，我想开始学习有关A.I.基础知识及其在嵌入式系统上的实现。但是，有关这些主题的大多数在线课程似乎都提供了更多的“ pratical”。通过向学生扔Python和Matlab包裹，而无需教授神经网络的实际运作方式。如果有人能够向我推荐一门课程（免费或付费），我将不胜感激，以了解神经网络和机器学习的基础，包括神经元的模型和Network的培训。   &lt;！ -  sc_on-- &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1IU02SO/Online_courses_that_that_that_ apphact_neural_networks_and/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iu02so/online_courses_that_approach_neural_networks_and/</guid>
      <pubDate>Thu, 20 Feb 2025 14:44:29 GMT</pubDate>
    </item>
    <item>
      <title>基于内存的视觉基础模型，用于3D膝盖MRI分割的混合动力降温</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1itt241/memorybased_visual_foundation_model_with_hybrid/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种基于内存的视觉模型，称为SAMRI-2用于3D医疗图像分割，特别专注于MRI扫描中的膝盖软骨和半月板。关键创新是将记忆机制与混合洗牌策略结合在一起，以更好地处理3D空间关系，同时保持计算效率。 主要技术点： - 使用带有变压器的基于变压器的体系结构来处理3D卷 - 实施一种新颖的“混合洗牌策略”在有助于保持空间一致性的训练过程中 - 每次扫描仅需要3次点击作为提示 - 接受了270次患者扫描培训，对57例外部病例进行了测试 - 与3D -VNET和其他Transformer Baselines进行了比较 结果： -  &lt;强&gt;骰子得分比以前的方法提高了5％ - 胫骨软骨分割精度提高了12％ -  厚度测量显示3倍更好的精度 - 在不同的MRI机/协议上保持性能 - 每次扫描的处理时间约为30秒 我认为这种方法对于临床部署可能特别有价值，因为它与最小用户输入之间的自动化平衡。基于内存的设计似乎比以前的方法更有效地处理医学扫描的3D性质。 我认为混合洗牌策略是一种有趣的技术贡献，可以适用于其他3D视觉任务。只需单击3个点击即可维持准确性的能力。  tldr：基于膝关节MRI分析的新型内存模型，将强度的精度与最小的用户输入相结合（3次点击）。使用混合洗牌策略有效地处理3D数据。 完整摘要在这里。 Paper 在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1itt241/memorybased_visual_foundation_model_with_hybrid/</guid>
      <pubDate>Thu, 20 Feb 2025 07:34:20 GMT</pubDate>
    </item>
    <item>
      <title>引入CNN学习工具</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1it64cd/introducing_cnn_learning_tool/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用我的新互动应用程序探索卷积神经网络（CNN）的内部工作。观看每一层如何处理您的草图，对行动中的深度学习有更清晰的了解。 （这也很有趣） 链接： Applepear.streamlit.app    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/foreltert2597     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1it64cd/introducing_cnn_learning_tool/</guid>
      <pubDate>Wed, 19 Feb 2025 14:00:06 GMT</pubDate>
    </item>
    <item>
      <title>硬件优化的本地稀疏注意力，以进行有效的长篇下说建模</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1it2oyq/hardwareoptimized_native_sparse_attention_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键贡献是一种新的稀疏注意方法，它与可训练的端到端训练相一致。本机稀疏注意（NSA）不使用复杂的预处理或动态稀疏模式，而是使用与GPU内存访问模式相匹配的块 -  sparse模式。 主要技术点： - 引入固定但可学习的稀疏模式，这些模式与硬件保持一致 - 在正常训练期间学习模式，而无需预处理 - 使用针对GPU内存访问优化的块 -  sparse结构 - 与密集的关注相比，达到2-3倍的速度 - 在使用50-75％的计算 之间保持准确性 跨不同设置的结果： - 语言建模：匹配密集的注意力困惑 - 机器翻译：可比的BLEU分数 - 图像分类：与密集的注意力相似的准确性 - 量表很好随着序列长度的增加 - 在不同模型大小 之间有效地工作，我认为这种方法可以使变压器模型在资源约束环境中更实用。硬件对齐方式意味着理论效率的提高实际上转化为现实世界的性能改进，与许多现有的稀疏注意方法不同。 我认为块 -  sparse模式在某些情况下可能限制了块，代表了一种良好的交易 - 灵活性和效率之间的依据。在训练过程中学习这些模式的能力尤其重要，因为它允许模型使稀疏性适应任务。  tldr：新的稀疏注意方法，与硬件约束相一致并在训练，训练，学习稀疏模式时，达到2-3倍的速度而没有准确的损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1it2oyq/hardwareoptimized_native_sparse_attention_for/</guid>
      <pubDate>Wed, 19 Feb 2025 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>从多类变为多标签训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个神经网络，其中有1个输入层2隐藏层和1个输出层。现在，我将其用作多类分类器，这意味着输出是0到15之间的值（总计16个可能的和相互排斥的类）。但是，作为下一步，我想培训一个具有7个类的多标签分类器，并且每个班级都有多达6个子类，因此我希望每个类都有标签。  与多类培训相比，这有何不同？我想主要区别在于输入（例如标签）和输出层？到目前为止，我一直在输出层中使用SoftMax作为激活函数。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</guid>
      <pubDate>Tue, 18 Feb 2025 12:48:25 GMT</pubDate>
    </item>
    <item>
      <title>具有高精度肌肉和脂肪指标的人体组成分析的自动多组织CT分割模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种自动深度学习系统，用于分割和量化CT扫描的肌肉和脂肪组织。关键的技术创新是将修改后的U -NET体系结构与自定义损失功能中编码的解剖约束相结合。 关键技术点： - 修改了U -NET体系结构，对500个手动标记的CT扫描进行了培训 - 通过纳入扫描 - 解剖学验证 - 通过结合了解剖学。损失损失功能，以惩罚不可能的组织布置 - 生成不同组织类型的3D体积测量 - 每次扫描的处理时间为2-3分钟VS小时手动分析 结果： - 肌肉组织分割的精度为96％ - 皮下脂肪的精度为95％的精度 - 内脏脂肪的精度为94％ - 对3位专家放射科医生的测量结果进行了验证 - 跨不同身体的测量值类型 我认为这可能会通过将人体组成分析所需的时间从小时减少到几分钟来显着影响临床工作流程。高精度和解剖学意识的方法表明，它可能足够可靠用于临床使用。尽管需要更多的验证，尤其是对于边缘病例和极端身体组成，该系统显示出有望改善肿瘤学，营养和运动医学的治疗计划。 我认为解剖学约束的整合特别聪明 - 它有助于防止纯粹的深度学习方法可能产生的身体上不可能的细分。这种领域知识的整合对于其他医学成像任务可能很有价值。  tldr：自动化的CT扫描分析系统将深度学习与解剖学规则结合在一起，以2--的2--; 94％的精度来测量肌肉和脂肪组织。 3分钟。显示出临床使用的希望，但需要更广泛的验证。摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</guid>
      <pubDate>Tue, 18 Feb 2025 12:44:32 GMT</pubDate>
    </item>
    <item>
      <title>物理知情的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irnodl/physics_informed_neural_networks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/nickb     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irnodl/physics_informed_neural_networks/</guid>
      <pubDate>Mon, 17 Feb 2025 16:22:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用U-NET和TensorFlow分割X射线肺</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irlh6f/how_to_segment_xray_lungs_using_unet_and/</link>
      <description><![CDATA[    &lt;！ -  sc_off-&gt;   本教程提供了有关如何使用TensorFlow/keras实现和训练X射线肺部分段的U-NET模型的分步指南。 🔍     构建UNET模型：学习如何使用TensorFlow和Keras构建模型。   模型培训：我们将指导您完成培训过程，优化模型以生成肺部位置的口罩  测试和评估：运行预训练的模型在新的新鲜图像上，并在预测的蒙版旁边可视化测试图像。   您可以在博客中找到代码的链接： https://eranfeit.net.net/how-to-to-segment-x -ray-rungs-using-u-net and-tensorFlow/  中等用户的完整代码描述： https://medium.com/@feitgemel/how-to-segment-x-ray-lungs-using-u-net-and-ant-tensorflow-59b5a99a893f   您可以找到更多教程，然后在此处加入我的新闻通讯： https://eranfeit.net/        &lt;强&gt;在此处查看我们的教程： [ https://youtu.be/-aejmcdeoom＆amp;list=uulftifftiwjjhah6bviswkljum9sg]（％20Https：/youtu.be/-aejmcdeoom; 享受  eran      #python #opencv＃tensorflow #tepeeplearning #imagesegentration #imagesementation #unet＃resunet #machinelearningproject #machinelearningproject #segentation #segentation #sementation       div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/feitgemel     [link]        [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irlh6f/how_to_segment_xray_lungs_using_unet_and/</guid>
      <pubDate>Mon, 17 Feb 2025 14:48:24 GMT</pubDate>
    </item>
    <item>
      <title>多语言语音模型的缩放定律：培训0.25b-18b参数模型的见解150种语言</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irfuvs/scaling_laws_for_multilingual_speech_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员在多语言语音识别和通过培训模型翻译中系统地研究缩放行为，跨不同尺寸（300m至1B参数）和数据数量（1K至10K）每种语言小时）。他们根据计算，数据和模型量表为性能开发预测方程。 关键技术方面： - 确定模型大小，培训数据和绩效之间的幂律关系 - 发现添加语言可以改善性能在降低回报之前，至〜8-10语言 - 开发的“猫头鹰得分”量化多语言转移效率的度量 - 证明较大的模型在3个模型体系结构和2种训练方法中显示出更好的跨语性转移 - 验证缩放定律 结果显示： - 错误率遵循指数-0.32的功率定律缩放率-0.32对于模型尺寸 - 跨语言转移通过log（n）改进，其中n是语言数 - 高资源语言从缩放中受益于低资源的缩放量 -  compute-optimal培训需要平衡模型大小和数据数量 - 体系结构的选择小于规模和数据数量 我认为这项工作将有助于组织对多语言模型的资源分配做出更好的决定。缩放定律可以指导有关模型大小，语言选择和数据收集的选择。但是，对高​​资源语言的关注意味着我们仍然需要对真正低资源场景的更多研究。  tldr：系统研究揭示了多语言语音AI的可预测缩放模式语言数量。结果为构建更好的系统提供了实用的指导。 。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irfuvs/scaling_laws_for_multilingual_speech_models/</guid>
      <pubDate>Mon, 17 Feb 2025 09:12:48 GMT</pubDate>
    </item>
    </channel>
</rss>