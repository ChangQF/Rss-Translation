<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Wed, 10 Jan 2024 12:26:24 GMT</lastBuildDate>
    <item>
      <title>我们是否可以说 Siamese 网络使用的 GPU RAM 是基准模型的两倍？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19342b2/can_we_say_that_the_siamese_network_uses_twice_as/</link>
      <description><![CDATA[如标题所示，可以吗？   由   提交 /u/JohnTheWeak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19342b2/can_we_say_that_the_siamese_network_uses_twice_as/</guid>
      <pubDate>Wed, 10 Jan 2024 09:04:50 GMT</pubDate>
    </item>
    <item>
      <title>MoE-Mamba：专家混合的高效选择性状态空间模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.04081 代码：https ://github.com/llm-random/llm-random 摘要：  状态空间模型（SSM）已成为顺序建模领域的有力竞争者，挑战 Transformers 的主导地位。与此同时，Mixture of Experts (MoE) 显着改进了基于 Transformer 的法学硕士，包括最近最先进的开源模型。我们建议，为了释放 SSM 的扩展潜力，它们应该与 MoE 结合起来。我们在 Mamba 上展示了这一点，这是一个最近基于 SSM 的模型，它实现了类似 Transformer 的卓越性能。我们的模型 MoE-Mamba 的性能优于 Mamba 和 Transformer-MoE。特别是，MoE-Mamba 以减少 2.2 倍的训练步骤达到与 Mamba 相同的性能，同时保留了 Mamba 针对 Transformer 的推理性能增益。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</guid>
      <pubDate>Wed, 10 Jan 2024 04:00:49 GMT</pubDate>
    </item>
    <item>
      <title>设计一个反向传播网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19280p8/design_a_counterpropagation_network/</link>
      <description><![CDATA[       这就是问题 ​ https://preview.redd.it/xzwshhckxcbc1.jpg?width=788&amp;format=pjpg&amp;auto=webp&amp;s=73a1f777b44a 97ba8798c900220a5ad36d57c95b 我做了这个设计，但我无法处理更多 ​ https://preview.redd.it/fcd6lwokxcbc1.jpg?width=899&amp;format=pjpg&amp;auto=webp&amp; s=1ebab6e4af7b8cf617439456d6d2913f79f7e941 ​   由   提交 /u/Adept-Yak2242    reddit.com/r/neuralnetworks/comments/19280p8/design_a_counterpropagation_network/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19280p8/design_a_counterpropagation_network/</guid>
      <pubDate>Tue, 09 Jan 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>完全自动化的 GPT 博客案例研究</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1926v40/completely_automated_gpt_blog_case_study/</link>
      <description><![CDATA[ 由   提交 /u/PikeMerry   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1926v40/completely_automated_gpt_blog_case_study/</guid>
      <pubDate>Tue, 09 Jan 2024 05:13:17 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 网络的帮助/建议</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/191izew/helpadvice_with_lstmnetworks/</link>
      <description><![CDATA[       ​ https://preview.redd.it/8ekj0m6u97bc1.png?width=2596&amp;format=png&amp;auto=webp&amp;s=f69367e2579fcdd4b9720660fa4d56d8 3255dd91 我是rnn lstm 中的新功能。我用这是基本的 lstm 模型来解释我的问题。 ​ https://preview.redd.it/hbhef6kv97bc1.png?width=931&amp;format=png&amp;auto=webp&amp;s=b532db72a9abad77202de4ecc7 fe4ad2b33f3233&lt; /p&gt; 如何实现这样的 lstm 模型。我想按顺序将预编码和固定代码发送到 lstm 模型中，并预测它的错误错误或重构名称。 ​ ​ &lt; /div&gt;  由   提交 /u/Surprise_Nearby   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/191izew/helpadvice_with_lstmnetworks/</guid>
      <pubDate>Mon, 08 Jan 2024 11:18:12 GMT</pubDate>
    </item>
    <item>
      <title>自动驾驶汽车中的计算机视觉</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriving_cars/</link>
      <description><![CDATA[        由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriven_cars/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriving_cars/</guid>
      <pubDate>Mon, 08 Jan 2024 09:06:38 GMT</pubDate>
    </item>
    <item>
      <title>从头开始的 NEAT 算法（很难）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190x2nu/neat_algorithm_from_scratch_it_was_hard/</link>
      <description><![CDATA[   /u/keghn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190x2nu/neat_algorithm_from_scratch_it_was_hard/</guid>
      <pubDate>Sun, 07 Jan 2024 17:19:38 GMT</pubDate>
    </item>
    <item>
      <title>NIST 确定了操纵人工智能系统行为的网络攻击类型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190kncb/nist_identifies_types_of_cyberattacks_that/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190kncb/nist_identifies_types_of_cyberattacks_that/</guid>
      <pubDate>Sun, 07 Jan 2024 05:23:10 GMT</pubDate>
    </item>
    <item>
      <title>2023 年十篇值得关注的人工智能研究论文</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190gozu/ten_noteworthy_ai_research_papers_of_2023/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190gozu/ten_noteworthy_ai_research_papers_of_2023/</guid>
      <pubDate>Sun, 07 Jan 2024 01:59:09 GMT</pubDate>
    </item>
    <item>
      <title>我用 Python 创建了一个神经网络，可以在虚幻引擎中按程序生成这些关卡。最终图像是我创建的，并提供给神经网络进行学习:]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18z1fob/i_created_a_neural_network_in_python_that/</link>
      <description><![CDATA[       由   提交/u/atomiclollypop  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18z1fob/i_created_a_neural_network_in_python_that/</guid>
      <pubDate>Fri, 05 Jan 2024 07:48:48 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 Neuro Symbolic 频道值得关注的 5 件事</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18yg3xz/5_things_to_watch_for_in_2024_on_the_neuro/</link>
      <description><![CDATA[   /u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18yg3xz/5_things_to_watch_for_in_2024_on_the_neuro/</guid>
      <pubDate>Thu, 04 Jan 2024 15:44:04 GMT</pubDate>
    </item>
    <item>
      <title>随机变压器：通过揭开变压器背后的所有数学原理来了解变压器的工作原理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18y28q4/the_random_transformer_understand_how/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18y28q4/the_random_transformer_understand_how/</guid>
      <pubDate>Thu, 04 Jan 2024 02:50:59 GMT</pubDate>
    </item>
    <item>
      <title>帮助提高模型效率</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18xwheq/help_with_model_efficiency_improvement/</link>
      <description><![CDATA[        由   提交/u/Gold-Ad4040   /u/Gold-Ad4040  reddit.com/r/neuralnetworks/comments/18xwheq/help_with_model_efficiency_improvement/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18xwheq/help_with_model_efficiency_improvement/</guid>
      <pubDate>Wed, 03 Jan 2024 22:42:38 GMT</pubDate>
    </item>
    <item>
      <title>关于人工神经网络的博客</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18xbxfj/blog_on_artificial_neural_network/</link>
      <description><![CDATA[      https://bhargavoza.com/blogs/Artificial%20Neural%20Network  https://preview.redd.it /zwvcphhqy5ac1.png?width=1007&amp;format=png&amp;auto=webp&amp;s=ea7cd84820900c92b298e26a8e5308faa24852d2 嘿，我在人工神经网络上写了这篇博客。它是如何工作的以及它背后的每个数学方程。另外，我在 numpy 的帮助下用 Python 从头开始​​开发了一个完整的训练周期。 我恳请您访问我的博客并提供一些反馈。   由   提交/u/Troniq777  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18xbxfj/blog_on_artificial_neural_network/</guid>
      <pubDate>Wed, 03 Jan 2024 05:49:31 GMT</pubDate>
    </item>
    <item>
      <title>预测器（回归）性能面临的挑战：MAE 持续为 0.26 且二元向量预测不准确</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18xbg5b/challenges_with_predictor_regression_performance/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18xbg5b/challenges_with_predictor_regression_performance/</guid>
      <pubDate>Wed, 03 Jan 2024 05:23:37 GMT</pubDate>
    </item>
    </channel>
</rss>