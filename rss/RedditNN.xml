<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 09 Feb 2024 21:12:03 GMT</lastBuildDate>
    <item>
      <title>计算机视觉如何让人们看起来更有吸引力</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1amvuxn/how_computer_vision_makes_people_look_more/</link>
      <description><![CDATA[在本文中，OpenCV.ai 团队研究了消除瑕疵和协调肤色的算法。此外，他们还深入分析了领先的面部美化商业解决方案，他们通过一系列真实案例研究来比较其性能。 简介 探索计算机视觉技术在面部增强方面的能力彻底审查。我们深入研究消除瑕疵、均匀肤色等的算法。此外，我们还概述了流行的面部改善商业解决方案，并附有各种案例研究。 在本文中，您将发现：  构建一个解决方案 在照片中的哪些位置进行更改？ 面部皮肤面膜 特定瑕疵面膜 如何进行这些更改？&lt; /li&gt; 端到端解决方案 测试开源 商业解决方案 还有更多 完整文章是 此处    由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1amvuxn/how_computer_vision_makes_people_look_more/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1amvuxn/how_computer_vision_makes_people_look_more/</guid>
      <pubDate>Fri, 09 Feb 2024 19:06:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN + LSTM 组合的视频分类损失没有减少，指标也没有改善</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1amhb7t/video_classification_using_cnn_lstm_combination/</link>
      <description><![CDATA[      I我正在尝试构建一个视频分类器，使用预训练的 Resent 作为特征提取器，使用 LSTM 进行时间学习，并使用完全连接的层作为基本分类器。我的数据集有 10 个类。我检查了很多资源，显然 cnn LSTM 组合可以对视频进行分类，我的作业也有这个要求。我正在使用交叉熵损失，数据集中存在不平衡，“正常”类的注释几乎是第二高类的两倍。我在堆栈溢出中发布了相同的内容，有人可以识别这个问题吗？谢谢   由   提交/u/Jaded-Association927   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1amhb7t/video_classification_using_cnn_lstm_combination/</guid>
      <pubDate>Fri, 09 Feb 2024 06:01:03 GMT</pubDate>
    </item>
    <item>
      <title>我们应该缩放神经网络中的 Y 目标变量吗？情况总是如此吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1am48l9/should_we_scale_the_y_target_variable_in_neural/</link>
      <description><![CDATA[大家好，  当前处理仅包含数值特征的数据集。这里的想法是预测美国不同地区的房价。我拥有的大多数信息都是数字格式的。  我的数据问题在于目标变量价格列的范围从 75000 到或多或少 77700000，而其他变量的范围仅从 0 到 1000。在查找论文时，大多数人提到没有有理由扩大目标，因为这样做没有任何好处。问题是，当我在这种情况下训练神经网络模型时，我得到如下结果： Epoch 1/100 139/139 [============ ==================] - 1s 3ms/步 - 损失：425583738880.0000 - mse：425583738880.0000 - val_loss：398226030592.0000 - val_mse：398225965056.0000 Epoch 2/100  139/139 [================================] - 0s 2ms/步 - 损耗：425583509504.0000 - mse：425583509504.0000 - val_loss: 398225899520.0000 - val_mse: 398225899520.0000 测量训练测试 0 MSE 4.201119e+11 4.532716e+11 1 MAE 5.378588e+05 5.494696e+0 52 R- squared -2​​.211378e+00 -1.994764e+00  我的想法是这样的事情有意义吗？  scaler = StandardScaler()  X_train = scaler.fit_transform(X_train)  X_test = scaler.transform(X_test)  y_train =scaler.fit_transform(y_train.values.reshape(-1, 1))  y_test =scaler.transform(y_test.values.reshape(-1, 1))  什么对于这种情况，最好的方法是什么？我该如何处理目标变量？  谢谢   由   提交 /u/Minute-Fix-1493   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1am48l9/should_we_scale_the_y_target_variable_in_neural/</guid>
      <pubDate>Thu, 08 Feb 2024 19:41:19 GMT</pubDate>
    </item>
    <item>
      <title>华为：在现实世界中通过不确定性做出值得信赖的决策</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aj525f/hua_wei_trustworthy_decision_making_in_the_real/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aj525f/hua_wei_trustworthy_decision_making_in_the_real/</guid>
      <pubDate>Mon, 05 Feb 2024 01:57:37 GMT</pubDate>
    </item>
    <item>
      <title>通过多面体透镜解释神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aiz1pw/interpreting_neural_networks_through_the_polytope/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aiz1pw/interpreting_neural_networks_through_the_polytope/</guid>
      <pubDate>Sun, 04 Feb 2024 21:26:02 GMT</pubDate>
    </item>
    <item>
      <title>开发神经网络的更简单方法？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ai71su/easier_way_to_develop_your_neural_networks/</link>
      <description><![CDATA[开发神经网络很困难，所需的编码量和经验是一个很大的障碍。 拥有 GUI很方便，但它不能包含神经网络的所有复杂性。 如果我们有一个混合了编程和 GUI 的平台，这样人们就可以从两个世界的优点中受益，那会怎么样。&lt; /p&gt; 您愿意在下一个项目中尝试一下吗？ 查看投票 a&gt;   由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ai71su/easier_way_to_develop_your_neural_networks/</guid>
      <pubDate>Sat, 03 Feb 2024 21:42:56 GMT</pubDate>
    </item>
    <item>
      <title>您希望自动化检测哪些异常和错误？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ai4lto/what_anomaly_and_bug_detections_would_you_like_to/</link>
      <description><![CDATA[我正在开发神经网络调试工具 (https: //github.com/FlorianDietz/comgra))。目前它对于可视化和深入的手动分析很有用，这是张量板和其他工具所缺乏的。我想扩展它以自动执行许多常见的分析和异常检测，以节省开发人员的时间. 我正在寻找对您最有用的建议。 它是如何工作的： 您对类似的试验进行了多次试验具有相似任务、具有不同超参数的网络。该工具记录所有相关数据并自动检测诸如“梯度消失”之类的异常情况。或“损失具有异常高的方差”或“分类不平衡，对 X 类型的目标效果不佳”。 第二步，它在每个试验的超参数与这些试验中检测到的异常之间执行相关性分析。然后，它会为每个具有统计意义的发现生成一个警告列表。例如： “学习率高于 3e-4 的试验中有 30% 的梯度消失，而学习率低于 3e-4 的试验的梯度为 0%。” ” “使用架构变体 X 的试验中有 50% 的损失差异异常高，而使用其他架构变体的试验只有 10%。” 拥有大量自动生成的警告列表可以让您非常快速地识别错误。此外，如果没有生成警告，那么您可以对模型的稳定性更有信心。 当然，许多警告也可能是不值得调查的误报，但我认为这更好无缘无故地被警告，而不是错过一个真正重要的问题。 你觉得这个想法怎么样？ 你认为什么类型的异常最有意义？寻找？   由   提交 /u/Smart-Emu5581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ai4lto/what_anomaly_and_bug_detections_would_you_like_to/</guid>
      <pubDate>Sat, 03 Feb 2024 19:55:09 GMT</pubDate>
    </item>
    <item>
      <title>您使用哪种深度神经网络？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ai344i/which_deep_neural_network_do_you_use/</link>
      <description><![CDATA[深度学习模型有很多种类型。 您多次看到过哪一种模型的实际应用？ p&gt; 查看投票    ;由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ai344i/which_deep_neural_network_do_you_use/</guid>
      <pubDate>Sat, 03 Feb 2024 18:48:25 GMT</pubDate>
    </item>
    <item>
      <title>一段时间后，神经网络输出保持不变。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ai1ae7/neural_network_outputs_stay_the_same_after_some/</link>
      <description><![CDATA[大家好，我正在做一个关于gymnasium环境的项目（以前被Openai称为gym）。我的项目涉及手动设置神经网络的权重（包括偏差）以使 BipedalWalker 代理行走。 但是在模拟中几秒钟，输出停止变化并保持不变，有效地“冻结” ;代理。 我试图看看这是否是梯度或权重本身的问题，但我找不到任何可说的来支持这一点。 我也认为可能是我的网络太简单（24 个输入，20 个隐藏，4 个输出），但我的一位教授已经用相同的方法完成了一个非常相似的项目，并且它对他有用。 我是使用Tahn激活，因为我需要我的输出在[-1,1]范围内，这很容易消失梯度，所以这可能是问题吗？ 有关我的问题的一些信息，以便您可以理解：  我的项目是在一个连续的环境中。我的神经网络的每一帧都会获得一组输入值，并且必须返回一组输出值。 不涉及任何训练，我使用进化策略改变权重（向其添加噪声），然后在神经网络中手动设置这些权重并测试其性能。  无论我对它们进行变异或进化，它总是会导致神经网络陷入困境并返回相同的结果值。 提前谢谢你们。   由   提交 /u/DocMenios   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ai1ae7/neural_network_outputs_stay_the_same_after_some/</guid>
      <pubDate>Sat, 03 Feb 2024 17:28:06 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的训练需要时间？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ahec61/training_of_neural_networks_take_time/</link>
      <description><![CDATA[神经网络的训练是否需要花费很多时间，有时你甚至不知道该怎么办。  查看投票  &amp; #32；由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ahec61/training_of_neural_networks_take_time/</guid>
      <pubDate>Fri, 02 Feb 2024 21:09:22 GMT</pubDate>
    </item>
    <item>
      <title>人工智能与艺术：未来的画笔</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ahdwxd/ai_and_art_the_brush_of_the_future/</link>
      <description><![CDATA[我希望您能找到来自 OpenCV.ai 团队表现出色！ 简短介绍： 本文探讨了人工智能在创造新形式的数字和互动艺术。我们深入研究生成算法作为创造者的作用，为创造力的本质提供新的见解。此外，我们回顾了生成式人工智能的基本工具，这对创建数字杰作有很大帮助。此外，我们还讨论了人工智能如何为动态和交互式艺术装置做出贡献，以新颖的方式吸引观众。 您将在本文中看到：  什么是生成式人工智能？ 生成式人工智能简史 什么是稳定扩散：ControlNet、LoRA 什么是修复 接下来是什么？ - AI 生成的视频 AI 如何改变沉浸式体验  更多详细信息 此处 感谢您的反馈和评论。 &lt; /div&gt;  由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1ahdwxd/ai_and_art_the_brush_of_the_future/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ahdwxd/ai_and_art_the_brush_of_the_future/</guid>
      <pubDate>Fri, 02 Feb 2024 20:51:50 GMT</pubDate>
    </item>
    <item>
      <title>云端神经网络训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1agyr3h/neural_network_training_on_cloud/</link>
      <description><![CDATA[你好 我正在尝试找到一个可以训练我的网络的基于云的平台。有什么建议吗？ PS：我的经济条件有限，所以我非常喜欢低价平台。   由   提交/u/joab_kc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1agyr3h/neural_network_training_on_cloud/</guid>
      <pubDate>Fri, 02 Feb 2024 08:10:45 GMT</pubDate>
    </item>
    <item>
      <title>OLMo：加速语言模型科学 [pdf]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1agu1ty/olmo_accelerating_the_science_of_language_models/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1agu1ty/olmo_accelerating_the_science_of_language_models/</guid>
      <pubDate>Fri, 02 Feb 2024 03:26:35 GMT</pubDate>
    </item>
    <item>
      <title>知道如何使用云服务来训练您的神经网络？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1agkjhz/know_how_to_use_cloud_services_to_train_your/</link>
      <description><![CDATA[当你想要训练你的神经网络时，你知道如何集成云服务来获取其计算能力吗？ 查看民意调查   由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1agkjhz/know_how_to_use_cloud_services_to_train_your/</guid>
      <pubDate>Thu, 01 Feb 2024 20:20:07 GMT</pubDate>
    </item>
    <item>
      <title>使用云服务训练神经网络是否复杂？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1agjnsb/are_cloud_services_complex_to_use_for_training/</link>
      <description><![CDATA[当您在云服务上训练神经网络时，使用前的设置很复杂吗？ 查看民意调查   由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1agjnsb/are_cloud_services_complex_to_use_for_training/</guid>
      <pubDate>Thu, 01 Feb 2024 19:43:30 GMT</pubDate>
    </item>
    </channel>
</rss>