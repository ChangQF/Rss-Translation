<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sun, 08 Dec 2024 01:27:50 GMT</lastBuildDate>
    <item>
      <title>构建用于视网膜图像诊断的 CNN 模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h8s8l5/build_a_cnn_model_for_retinal_image_diagnosis/</link>
      <description><![CDATA[      https://preview.redd.it/c593xsy5ff5e1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=c8aa34edbd1f8ad72c86643e9be11239ca2d2a10 👁️ 使用 TensorFlow 和 Keras 进行 CNN 图像分类以进行视网膜健康诊断！ 👁️ 如何收集和预处理超过 80,000 个视网膜图像的数据集，设计 CNN 深度学习模型，并对其进行训练以准确区分这些健康类别。 您将学到什么： 🔹 数据收集和预处理：了解如何获取和准备视网膜图像以进行最佳模型训练。 🔹 CNN 架构设计：创建针对视网膜图像分类量身定制的架构。 🔹 训练过程：探索模型训练的复杂性，包括参数调整和验证技术。 🔹 模型评估：了解如何在单独的测试数据集上评估训练有素的 CNN 的性能。   您可以在博客中找到代码链接：https://eranfeit.net/build-a-cnn-model-for-retinal-image-diagnosis/ 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程：https://youtu.be/PVKI_fXNS1E&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h8s8l5/build_a_cnn_model_for_retinal_image_diagnosis/</guid>
      <pubDate>Sat, 07 Dec 2024 13:14:22 GMT</pubDate>
    </item>
    <item>
      <title>是否有论文或惯例将神经网络作为另一个神经网络的特征？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h8ioh4/is_there_a_paper_or_a_convention_to_take_neural/</link>
      <description><![CDATA[  由    /u/civilianlink  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h8ioh4/is_there_a_paper_or_a_convention_to_take_neural/</guid>
      <pubDate>Sat, 07 Dec 2024 02:41:16 GMT</pubDate>
    </item>
    <item>
      <title>流匹配增强潜在扩散，实现高效的高分辨率图像合成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h7ai9x/flow_matching_enhances_latent_diffusion_for/</link>
      <description><![CDATA[本文介绍了一种将流匹配与潜在扩散模型相结合以提高图像生成效率的方法。关键创新是使用流匹配直接学习潜在空间中的最优轨迹，而不是依赖于标准的去噪扩散。 主要技术要点： - 引入高斯假设以有效计算潜在空间中的流匹配 - 使用具有交叉注意的 U-Net 主干进行条件反射 - 保持潜在扩散模型的自动编码器结构 - 实现随机流匹配以优化轨迹 - 与基线​​扩散模型相比，训练速度提高 2-3 倍 结果： - 在标准基准上提高了 FID 分数 - 更少的推理步骤，更好的样本质量 - 更稳定的训练动态 - 降低训练和推理的计算要求 - 与标准扩散方法相比，结果相当或更好 我认为这对计算资源有限的研究人员和组织尤其有影响。更快的训练时间和更低的计算要求可以使高级图像生成更容易实现。该方法还为其他生成任务提出了一条更高效的架构之路。 我看到了快速原型设计和生成模型迭代中的潜在应用，尽管高斯假设存在一些限制，可能需要进一步研究。这种方法在训练效率优先于最终样本质量的情况下似乎特别有前景。 TLDR：流匹配 + 潜在扩散 = 更快的训练和推理，同时保持质量。关键创新是使用高斯假设在潜在空间中进行有效的轨迹学习。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h7ai9x/flow_matching_enhances_latent_diffusion_for/</guid>
      <pubDate>Thu, 05 Dec 2024 14:33:36 GMT</pubDate>
    </item>
    <item>
      <title>霍普菲尔德神经网络中的类分形吸引盆。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6zd6t/fractallike_basins_of_attraction_in_hopfield/</link>
      <description><![CDATA[https://reddit.com/link/1h6zd6t/video/uzz843zo5y4e1/player    由   提交  /u/Mountain_Raise9581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6zd6t/fractallike_basins_of_attraction_in_hopfield/</guid>
      <pubDate>Thu, 05 Dec 2024 03:12:28 GMT</pubDate>
    </item>
    <item>
      <title>PointNet Ensemble 改进了 CERN 的反物质湮灭位置重建</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6fdsk/pointnet_ensemble_improves_antimatter/</link>
      <description><![CDATA[研究人员开发了一种深度学习方法，用于检测和分类 CERN 的 ALPHA 实验中的反氢湮没事件。关键创新是将 CNN 架构与专为反物质特征检测而设计的自定义物理信息层相结合。 关键技术要点： - 自定义神经网络架构处理来自硅顶点探测器的原始探测器数据 - 在真实和模拟的反氢湮没事件上训练的模型 - 根据已知的反物质行为实现物理信息正则化 - 使用数据增强来处理有限的训练示例 - 实现实时处理（每个事件&lt;1ms） 结果： - 测试集准确率为 99.9% - 假阳性率为 0.1% - 性能与人类专家分析相匹配 - 针对传统重建方法进行了验证 - 在不同的实验条件下保持准确性 我认为这项工作为将 ML 应用于其他罕见物理事件开辟了有趣的可能性。实时处理事件的能力可以实现传统分析流程无法实现的新型实验。基于物理的架构方法也可能很好地转移到其他粒子物理问题。 我特别感兴趣的是他们如何处理有限的训练数据挑战——反物质事件极其罕见且成本高昂。他们的数据增强和基于物理的正则化技术对于具有类似约束的其他领域可能很有价值。 TLDR：深度学习系统在 CERN 检测反物质湮灭事件的准确率达到 99.9%，使用基于物理的神经网络将分析时间从数小时缩短到几毫秒。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6fdsk/pointnet_ensemble_improves_antimatter/</guid>
      <pubDate>Wed, 04 Dec 2024 12:59:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 LVM 自动注释数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h6b9ti/autoannotate_datasets_with_lvms/</link>
      <description><![CDATA[       由    /u/erol444  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h6b9ti/autoannotate_datasets_with_lvms/</guid>
      <pubDate>Wed, 04 Dec 2024 08:17:00 GMT</pubDate>
    </item>
    <item>
      <title>“裂脑实验”获得的经验教训是否有助于开发更智能的神经网络/机器学习软件？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5sbvw/can_the_lessons_learned_with_the_split_brain/</link>
      <description><![CDATA[如果你不知道，这种名为“胼胝体切开术”的手术是用于帮助治疗严重癫痫患者的最后手段。嗯，它的副作用是它也会将大脑的意识一分为二。 这意味着大脑的一侧会在人不愿意的情况下控制身体的一半，他们的手会不受控制地抓取东西等等。虽然这听起来可能有些极端，但两种意识仍然在某种程度上是相连的，仍然是一个人，而不是“邪恶版”你自己或类似的东西。 关于这个主题有很多视频，但本质上： 从已经完成的所有研究来看，人们相信（或证明，我不是神经科学家）大脑是由几个&quot;黑匣子&quot; 组成的处理隔间和半独立的意识，它们都同步协同工作。 但是，每个&quot;隔间&quot; 都专门用于特定任务，例如视觉信息、运动控制、通信等。 因此，拥有一个有点类似/模仿人类大脑这种区域划分的神经网络是否可以实现更聪明的人工智能？    提交人    /u/KalyanDipak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5sbvw/can_the_lessons_learned_with_the_split_brain/</guid>
      <pubDate>Tue, 03 Dec 2024 17:07:35 GMT</pubDate>
    </item>
    <item>
      <title>控制图像生成。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5oha4/control_image_generation/</link>
      <description><![CDATA[大家好，有没有办法使用本地数据库中的项目来控制图像的生成。例如： - 我输入一个提示或房间的图像，或者两者兼而有之。 - 该模型将为我生成一个房间，其中的所有项目都来自本地数据库（mongodb 或 sql）。现在我的问题： - 怎么做？ - 如果是，那么如何构建它？ - 如何设置数据库结构？     提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5oha4/control_image_generation/</guid>
      <pubDate>Tue, 03 Dec 2024 14:21:34 GMT</pubDate>
    </item>
    <item>
      <title>霍普菲尔德神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h5gasl/hopfield_neural_networks/</link>
      <description><![CDATA[John Hopfield 今年与 G. Hinton 一起获得了诺贝尔物理学奖。有人玩过 Hopfield 神经网络系统吗？我玩过，而且对于这样一个简单的系统，它们具有一些有趣的特性。我将盆地映射为存储的记忆数量的函数。它们看起来像分形。如果有人感兴趣，我很乐意发布和分享。    提交人    /u/Mountain_Raise9581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h5gasl/hopfield_neural_networks/</guid>
      <pubDate>Tue, 03 Dec 2024 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>用于计算机视觉和机器学习的 13 种图像数据清理工具</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4yet4/13_image_data_cleaning_tools_for_computer_vision/</link>
      <description><![CDATA[        提交人    /u/codingdecently   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4yet4/13_image_data_cleaning_tools_for_computer_vision/</guid>
      <pubDate>Mon, 02 Dec 2024 16:06:40 GMT</pubDate>
    </item>
    <item>
      <title>L1 与 L2 正则化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4rubo/l1_vs_l2_regularization/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4rubo/l1_vs_l2_regularization/</guid>
      <pubDate>Mon, 02 Dec 2024 10:15:38 GMT</pubDate>
    </item>
    <item>
      <title>用 C 语言更新密集分层神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h4pl5i/update_to_dense_layered_nn_in_c/</link>
      <description><![CDATA[大家好！大约两周前，我发布了一篇关于从头开始用 C 语言创建的密集分层神经网络的文章。我想发布一篇关于我所做工作的一些更新的文章。该网络目前支持与分类相关的 NN，GitHub 已清理干净以供查看。任何反馈都将不胜感激。 https://github.com/Asu-Ghi/Personal_Projects/tree/main/MiniNet 感谢您的时间    提交人    /u/AsuGhi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h4pl5i/update_to_dense_layered_nn_in_c/</guid>
      <pubDate>Mon, 02 Dec 2024 07:25:23 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能训练一个模型，将视频中的所有鞋子都替换为 Crocs 鞋？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h1mbz9/would_it_be_possible_to_train_a_model_to_replace/</link>
      <description><![CDATA[对于新手（我）来说，这会有多难呢？    提交人    /u/Edgele55Placebo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h1mbz9/would_it_be_possible_to_train_a_model_to_replace/</guid>
      <pubDate>Thu, 28 Nov 2024 03:03:28 GMT</pubDate>
    </item>
    <item>
      <title>VanceNet 神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h1m2a8/vancenet_neural_network/</link>
      <description><![CDATA[我制作了一个名为 VanceNet 的神经网络，它旨在识别和分析复杂系统中的模式。它还使用基于动态能量的神经元、进化更新和分形分析来适应和发展。通过跟踪熵和分形维数等指标，VanceNet 生成越来越复杂的模式，使其可用于生成艺术、混沌系统建模和科学研究等应用。如果您想了解更多信息，请查看此处的研究论文：VanceNet    提交人    /u/AnyCookie10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h1m2a8/vancenet_neural_network/</guid>
      <pubDate>Thu, 28 Nov 2024 02:48:49 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的异常检测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h0a90g/transformer_based_anomaly_detection/</link>
      <description><![CDATA[我正在尝试构建一个基于 Transformer 自动编码器架构的异常检测模型，该模型将根据重建误差检测股票价格异常。将使用过去 5 年（最好是 15 到 20 只股票）的 OHCLV 历史数据来训练模型，并使用实时 API 并通过 Kafka 进行提取以进行测试。 这将是我第一次在基于 Transformer 的架构上工作的项目。任何熟悉这些概念的人都可以告诉我在这个项目上我会遇到什么样的障碍，请提及任何可以帮助我构建这个项目的宝贵资源。    提交人    /u/East-Agent9391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h0a90g/transformer_based_anomaly_detection/</guid>
      <pubDate>Tue, 26 Nov 2024 12:02:50 GMT</pubDate>
    </item>
    </channel>
</rss>