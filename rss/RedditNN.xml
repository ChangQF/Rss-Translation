<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 12 Feb 2025 15:18:25 GMT</lastBuildDate>
    <item>
      <title>我的 NN 学习之旅下一步应该做什么？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1inr3bn/what_should_be_next_in_my_nn_learning_journey/</link>
      <description><![CDATA[大家好，前段时间，我开始学习神经网络，纯粹是出于对它们背后数学的兴趣。从那时起，我写了四篇 Medium 文章，总结我所学到的知识：  从头开始手动构建神经网络：初学者的 Hello World 爬下斜坡：神经网络的梯度下降 神经网络中的规范化和管理梯度下降挑战 从头开始构建卷积神经网络  当我开始时，我对神经网络一无所知。现在，我的下一个目标是在 PyTorch 中实现 CNN，然后深入研究循环神经网络。 然而，我收到了一些批评，人们认为了解 NN 在数学和内部的工作原理（尽管我的了解并不深入）根本没有价值，因为大多数 ML/AI 工程师使用预先构建的模型，而不需要了解在底层构建它们所涉及的内容。其中一些反馈让我停下来思考，让我质疑我是否应该继续使用 RNN。 在您看来，了解神经网络在幕后工作的细节是否有实际价值？或者，从实践上讲，对 ML/AI 领域的人来说无关紧要？    提交人    /u/Flaky_Profession_619   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1inr3bn/what_should_be_next_in_my_nn_learning_journey/</guid>
      <pubDate>Wed, 12 Feb 2025 13:43:57 GMT</pubDate>
    </item>
    <item>
      <title>用于高效多语言 LLM 安全检测的双人强化学习框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1innz0u/twoplayer_reinforcement_learning_framework_for/</link>
      <description><![CDATA[本文介绍了一种双人强化学习方法，用于在多语言 LLM 中实施护栏。核心创新是使用马尔可夫博弈框架，其中两个 RL 代理一起工作 - 一个专注于安全审核，另一个专注于保持对话质量。 关键技术要点： - 仅使用 2% 的基本模型参数进行参数高效微调 - 自定义奖励函数平衡内容安全性和响应效用 - 两个 RL 玩家之间交替优化 - 用于多语言理解和文化适应的专用模块 - 实时审核能力，延迟开销最小 结果显示： - 有害/不适当内容减少 27% - 与无审核基线相比，有用响应保留率为 92% - 适用于 8 种语言 - 与以前的方法相比，计算成本更低 - 成功处理明确和细微的安全违规行为 我认为这种方法对于在安全性和性能都很重要的生产环境中部署 LLM 特别有影响。参数效率意味着它可以集成到现有系统中而无需大量的计算开销。随着人工智能部署变得更加全球化，多语言能力尤为重要。 但是，我认为有一些限制需要考虑。不同语言之间的不同表现表明需要在文化适应方面做更多的工作。在模棱两可的情况下，保守的方法可能还需要针对不同的用例进行调整。 TLDR：用于 LLM 护栏的双人 RL 框架使用适用于多种语言的参数高效微调，将有害内容减少了 27%，同时保持了 92% 的有用响应。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1innz0u/twoplayer_reinforcement_learning_framework_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:27:08 GMT</pubDate>
    </item>
    <item>
      <title>评估法学硕士作为会议代表的能力：跨不同模式和参与策略的绩效分析</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1imwq43/evaluating_llms_as_meeting_delegates_a/</link>
      <description><![CDATA[本文介绍了一种用于测试 LLM 作为会议代表的系统评估框架，其中采用了一种新颖的两阶段架构来进行会议理解和总结。关键技术贡献是一个包含 100 份带注释的会议记录的基准数据集，以及一种专注于信息提取和上下文理解的评估方法。 主要技术要点： - 两阶段架构：上下文理解模块，然后是响应生成 - 跨 4 个关键指标进行评估：信息提取、摘要连贯性、行动项跟踪和上下文保留 - 单轮和多轮交互之间的比较 - 测试多个 LLM 架构，包括 GPT-4、Claude 等 关键结果： - GPT-4 在关键点识别方面实现了 82% 的准确率 - 多轮交互显示摘要质量提高了 15% - 在技术讨论中性能显着下降（30-40%） - 模型在不同会议类型和文化背景下表现出不一致的性能 我认为这项工作为自动会议文档开辟了实际应用，特别是对于日常商务会议。多轮改进表明交互式细化可能是这些系统前进的关键途径。 我认为技术讨论和跨文化交流的局限性凸显了在全球组织中部署的重要挑战。结果表明，在广泛采用之前，我们需要在领域适应和文化背景理解方面做更多的工作。 TLDR：LLM 作为会议代表的新基准和评估框架，在基本会议理解方面显示出有希望的结果，但在技术和跨文化背景下仍然存在重大挑战。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1imwq43/evaluating_llms_as_meeting_delegates_a/</guid>
      <pubDate>Tue, 11 Feb 2025 11:45:22 GMT</pubDate>
    </item>
    <item>
      <title>第二部分：Peter Sutor 的超维计算 (HDC)（访谈）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1imc73h/pt_ii_hyperdimensional_computing_hdc_with_peter/</link>
      <description><![CDATA[        由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1imc73h/pt_ii_hyperdimensional_computing_hdc_with_peter/</guid>
      <pubDate>Mon, 10 Feb 2025 17:50:58 GMT</pubDate>
    </item>
    <item>
      <title>邀请合作者参与可微分几何损失函数库的开发</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ilzops/inviting_collaborators_for_a_differentiable/</link>
      <description><![CDATA[您好，我是斯坦福大学的研究生，致力于飞机设计的形状优化。 我正在寻找合作者，共同在 pytorch 中创建可微分几何损失函数库。 我在此处的存储库中放置了几个初始提交，以让您了解内容可能是什么样子：Github repo 在 Twitter 上邀请合作者    提交人    /u/atharvaaalok1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ilzops/inviting_collaborators_for_a_differentiable/</guid>
      <pubDate>Mon, 10 Feb 2025 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>我用 Java 实现了 NEAT（增强拓扑的神经进化）！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ilpgk3/i_made_an_implementation_of_neat_neuroevolution/</link>
      <description><![CDATA[嘿， 我最近用 Java 实现了 NEAT（增强拓扑的神经进化）！我试图让它尽可能忠实于原始论文和源代码。我发现目前还没有足够的实现，所以我用 Java 实现了它，目前我也在开发 JavaScript 版本！ https://github.com/joshuadam/NEAT-Java 欢迎任何反馈和批评！这是我的第一个大型项目之一，我从中学到了很多东西，我为此感到非常自豪！ 谢谢    提交人    /u/joshua_damian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ilpgk3/i_made_an_implementation_of_neat_neuroevolution/</guid>
      <pubDate>Sun, 09 Feb 2025 21:16:41 GMT</pubDate>
    </item>
    <item>
      <title>部署难题：处理提前一天的 XGBoost 预测中的动态特征重要性</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iliiwo/struggling_with_deployment_handling_dynamic/</link>
      <description><![CDATA[我正在使用 XGBoost 和滚动窗口创建一个时间序列预测模型，该模型在训练和测试期间有效。该模型仅预测未来一天的能源使用情况，因为我认为这是最准确的。我们的训练和测试显示出了很好的前景，然而，我在部署方面遇到了困难。问题在于，最重要的特征是前几天的使用情况，它可能与第二天呈负相关或正相关。由于我几乎每天都使用滚动窗口，因此它在某种程度上是独一无二的，并且与当天高度吻合，但预测效果非常好。在部署期间，我无法获得最新的特征重要性，因为我需要与之对应的目标，也就是我试图预测的确切值。因此，我可以转移目标，每天进行训练，直到前一天，并且仍然使用最后几天的特征，但与训练和测试相比，这最终会很糟糕。例如：我有 1 月 1 日的数据 1 月 2 日 尝试预测 1 月 3 日（无数据） 1 月 1 日的目标（能源使用情况）严重依赖于 1 月 2 日，因此我们可以对截至 1 日的所有数据进行训练，因为它有一个目标，可用于计算特征重要性的最佳“增益”。我可以包括 1 月 2 日的特征，但不会有正确的特征重要性。目前看来我几乎是在试图预测特征重要性。 这很重要，因为如果前一天的能源使用情况发生逆转，第二天的温度就会大幅下降，例如没有人再使用空调，那么前一天就会从正相关变为负相关。 我已经为模型构建了一些 K 均值聚类，但即便如此，仍然存在一些差异，如果我试图预测下一个 K 聚类，我就会遇到同样的问题，对吗？这种趋势会存在很长时间，然后可能突然下降，下一个 K 集群的预测将不准确。 TLDR 如何预测高度依赖前一天变化很大的特征重要性    提交人    /u/ElegantBreath6062   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iliiwo/struggling_with_deployment_handling_dynamic/</guid>
      <pubDate>Sun, 09 Feb 2025 16:27:52 GMT</pubDate>
    </item>
    <item>
      <title>关于选择研究生论文项目的建议</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ild9cz/advice_on_choosing_a_grad_school_dissertation/</link>
      <description><![CDATA[大家好， 我正在为研究生院选择 SNNS 论文项目，真的需要一些建议。我的目标是在机器人领域（希望是在人工智能领域）找到一份好工作。以下是我为该项目考虑的选项： 传感器选项（任一种）：视觉触觉传感器 算法选项：脉冲图神经网络 (SGNN) 神经架构搜索 (NAS) 脉冲卷积神经网络 (SCNN) 你们认为这些选项中的哪一个会在我的简历上留下深刻的印象并有助于在未来获得行业工作？如果能提供优缺点，我将不胜感激。 谢谢！   由    /u/PurpleConversation8  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ild9cz/advice_on_choosing_a_grad_school_dissertation/</guid>
      <pubDate>Sun, 09 Feb 2025 12:02:07 GMT</pubDate>
    </item>
    <item>
      <title>多步骤多语言交互使 LLM 越狱攻击更加有效</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1il94av/multistep_multilingual_interactions_enable_more/</link>
      <description><![CDATA[研究人员引入了一种通过自然对话交互测试 LLM 安全性的系统方法，展示了简单的对话模式如何可靠地绕过内容过滤。他们表明，与使用复杂的提示或令牌操作相比，通过多轮对话进行渐进式社会工程可实现高成功率。 关键技术要点：- 开发了可重复的方法来测试对话越狱- 针对 GPT-4、Claude 和 LLaMA 模型变体进行了测试- 绕过安全措施的成功率达到 92%- 多轮对话比单次尝试更有效- 创建有害输出类别的分类法- 在多种对话模式和主题中验证了结果 结果细分：- 安全绕过成功率因模型而异（GPT-4：92%，Claude：88%）- 自然语言模式比明确提示更有效- 逐步操作比直接请求显示出更高的成功率- 效果在多轮对话中持续存在- 不同有害内容类型的成功率保持稳定 我认为这项工作暴露了当前 LLM 安全机制中令人担忧的弱点。这些技术的简单性和可靠性表明我们需要从根本上重新思考如何实施 AI 安全护栏。当前的方法似乎容易受到基本社会工程学的攻击，这可能会带来问题，因为这些模型的部署范围会更广。 我认为该方法为系统性安全测试提供了有价值的框架，但我担心这些发现可能会被滥用。领先模型的高成功率表明，这并不是特定实现中的孤立问题。 TLDR：简单的对话技巧可以可靠地绕过 LLM 安全措施，成功率高达 92%，这表明当前的 AI 安全方法需要显着改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1il94av/multistep_multilingual_interactions_enable_more/</guid>
      <pubDate>Sun, 09 Feb 2025 07:05:21 GMT</pubDate>
    </item>
    <item>
      <title>无需模型提炼，在语言模型中实现引导式长链思维推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ikhom6/bootstrap_long_chainofthought_reasoning_in/</link>
      <description><![CDATA[BOLT 引入了一种新颖的方法来改进语言模型推理，而无需模型提炼或额外的训练。关键思想是使用引导程序迭代地细化思路链，使模型能够通过自我审查和细化来改进自己的推理过程。 关键技术点： - 引入一个多阶段推理过程，其中模型生成、审查和细化自己的思路链 - 使用精心设计的提示引导模型完成推理细化的不同方面 - 通过结构化的引导方法保持一致性，在纠正错误的同时保留有效推理 - 适用于现有模型，而无需从更大的模型中进行额外的训练或提炼 结果： - 在多个推理基准上提高了性能 - 随模型大小有效扩展 - 与标准思路链提示相比，推理链更可靠 - 更好地处理复杂的多步骤问题 我认为这种方法可以改变我们对改进语言模型能力的看法。我们可能不需要总是需要更大的模型或更多的训练，而是能够通过巧妙的提示和迭代策略获得更好的性能。引导技术可能应用于推理之外的其他类型的任务。 我认为，在实际应用中，计算成本和性能提升之间的权衡将是重要的考虑因素。BOLT 的迭代性质意味着更长的推理时间，但无需重新训练即可改进推理的能力可能使其在许多用例中都值得。 TLDR：新方法通过让语言模型回顾和改进自己的思路链推理来帮助它们更好地推理。无需额外的训练，只需巧妙的提示和迭代。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ikhom6/bootstrap_long_chainofthought_reasoning_in/</guid>
      <pubDate>Sat, 08 Feb 2025 07:13:15 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络可以使用不同的传感器数据频率进行天气预测吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ik80cm/can_convolutuonal_neural_networks_be_used_for/</link>
      <description><![CDATA[假设有传感器以 1 分钟、5 分钟、15 分钟、20 分钟等不同间隔提供气象输入。是否可以训练 CNN 从所有这些传感器获取数据并预测未来 1 小时内的降雨概率？随着新数据输入不同的传感器，它能否使概率更加准确？    提交人    /u/Pineapple_throw_105   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ik80cm/can_convolutuonal_neural_networks_be_used_for/</guid>
      <pubDate>Fri, 07 Feb 2025 22:44:32 GMT</pubDate>
    </item>
    <item>
      <title>基于内容的推荐系统 - 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ik113q/contentbased_recommender_systems_explained/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ik113q/contentbased_recommender_systems_explained/</guid>
      <pubDate>Fri, 07 Feb 2025 17:51:30 GMT</pubDate>
    </item>
    <item>
      <title>ScoreFlow：通过持续基于分数的偏好学习优化 LLM 代理工作流程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ijrfu7/scoreflow_optimizing_llm_agent_workflows_through/</link>
      <description><![CDATA[本文介绍了 ScoreFlow，这是一种使用持续优化和定量反馈来优化语言模型代理工作流的新方法。关键创新是 Score-DPO，它扩展了直接偏好优化以处理数字分数而不仅仅是二元偏好。 关键技术方面： - 使用基于分数的梯度在策略空间中进行持续优化 - 结合定量反馈的 Score-DPO 损失函数 - 多代理工作流优化框架 - 基于梯度的学习以实现平滑的策略更新 主要结果： - 在多种任务类型中比基线方法提高了 8.2% - 使用 ScoreFlow 的较小模型优于较大的基线模型 - 在问答、编程和数学推理任务上有效 - 在多代理协调场景中显示出好处 我认为这种方法对于我们需要优化复杂代理工作流的实际应用可能特别有影响力。使用定量反馈而不仅仅是二元偏好的能力开辟了更细微的训练信号。较小模型的表现优于较大模型这一事实对于资源受限的部署场景尤其有趣。 我认为持续优化方法对于代理工作流非常有意义 - 离散优化可能导致不稳定、不可预测的行为变化。平稳的策略更新应该会带来更稳定、更可靠的代理行为。 我看到的主要限制是，该论文没有完全解决大量代理的可扩展性或反馈信号冲突的潜在不稳定性问题。这些将是后续工作的重要领域。 TLDR：ScoreFlow 使用基于分数的持续优化来优化 LLM 代理工作流，实现比基线更好的性能，同时使较小的模型能够胜过较大的模型。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ijrfu7/scoreflow_optimizing_llm_agent_workflows_through/</guid>
      <pubDate>Fri, 07 Feb 2025 09:47:51 GMT</pubDate>
    </item>
    <item>
      <title>通过柯西损失和最优传输进行稳健的潜在一致性训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</link>
      <description><![CDATA[潜在一致性模型 (LCM) 的新训练方法修改了噪声计划，以实现更好的图像质量，同时保持了使 LCM 具有吸引力的快速推理速度。关键创新是在训练期间引入额外的中间步骤，同时保留推理时的高效采样过程。 主要技术要点：- 修改后的噪声计划在训练期间包含更细粒度的步骤 - 动态加权方案调整不同噪声级别的重要性 - 优化的采样策略平衡质量和速度 - 无需架构更改或额外参数 - 保持原始的 4-8 步推理过程 结果：- 标准图像质量指标提高 15-20% - 更好地保留精细细节和纹理 - 与基线​​ LCM 相当的推理速度 - 提高了面部等复杂特征的性能 - 跨多个标准基准进行测试 我认为这种方法对于质量和速度都很重要的实际应用特别有价值。在推理时无需计算开销即可提高输出质量的能力表明我们可能会看到这种技术被采用在生产系统中。该方法也可能适用于图像生成以外的其他类型的一致性模型。 我认为关键的限制是改进伴随着训练复杂性的增加。虽然推理仍然很快，但额外的训练步骤可能会使初始模型开发更加资源密集。 TLDR：潜在一致性模型的新训练技术在不减慢推理速度的情况下将图像质量提高了 15-20%，这是通过训练期间修改噪声调度而不是架构更改来实现的。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</guid>
      <pubDate>Thu, 06 Feb 2025 09:36:26 GMT</pubDate>
    </item>
    <item>
      <title>实例特定负向挖掘用于改进分割任务中的视觉语言提示生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</link>
      <description><![CDATA[本文介绍了一种新的实例分割方法，该方法使用特定于实例的负挖掘来改进跨多个任务的基于提示的分割。核心思想是挖掘特定于每个实例的反面例子，以学习更好的判别特征。 关键技术点： - 采用两阶段架构：提示生成，然后进行反面挖掘 - 从同一图像中看起来相似的实例中挖掘硬反面例子 - 学习特定于实例的判别特征，无需特定任务的训练 - 与现有的主干网络（如 SAM 和 SEEM）集成 - 使用对比学习最大化正特征和负特征之间的分离 结果： - 在标准基准（COCO、ADE20K）上优于基线方法 - 无需重新训练即可跨多个任务工作 - 更好地处理相似实例和重叠对象 - 尽管增加了挖掘步骤，仍保持具有竞争力的推理速度 - 在基于提示的分割任务上实现 SOTA 我认为这种方法对于现实世界的应用可能非常有影响，因为我们需要能够处理多项任务的灵活分割系统。特定于实例的反面挖掘似乎是一种帮助模型学习更稳健特征的自然方法，尤其是在具有相似对象的情况下。事实上，它无需特定任务的训练就能工作，这对于部署场景来说尤其有趣。 我看到的主要限制是挖掘过程的计算开销，尽管作者报告说影响是可控的。我很好奇这如何扩展到具有许多相似物体的非常大的场景。 TLDR：使用特定于实例的负挖掘的新实例分割方法，可在没有特定于任务的训练的情况下提高多个任务的准确性。通过学习到的判别特征展示对相似对象的更好处理。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</guid>
      <pubDate>Wed, 05 Feb 2025 09:57:06 GMT</pubDate>
    </item>
    </channel>
</rss>