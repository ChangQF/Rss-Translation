<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Fri, 14 Jun 2024 15:16:54 GMT</lastBuildDate>
    <item>
      <title>寻求长期短期记忆网络的帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dfpz2k/looking_for_a_help_with_long_short_term_memory/</link>
      <description><![CDATA[大家好， 我正在尝试用 Python 构建一个长期短期记忆模型，其想法是从线性加速度 (x,y,z) 和角速度 (x,y,z) 预测旋转矩阵的 9 个分量，因此有 6 个输入变量。 我使用了文献中发现的标准架构，它与我的想法类似。但是，我认为该模型表现不佳，并且容易过度拟合。 有人对我如何尝试改进我的模型有什么建议吗？    提交人    /u/DesperateChemist9234   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dfpz2k/looking_for_a_help_with_long_short_term_memory/</guid>
      <pubDate>Fri, 14 Jun 2024 12:46:14 GMT</pubDate>
    </item>
    <item>
      <title>训练问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dfj9ne/training_question/</link>
      <description><![CDATA[我用 Java 创建了自己的前馈神经网络，使用了 ReLu、Soft Max 和交叉熵损失，但我遇到了一些有趣的问题。例如，在训练它识别 MNIST 数字时，它可以达到高达 50% 的准确率，然后就没有改进了。我剪辑了幅度为 5 或更大的梯度，学习率为 0.0001。我摆弄了这些数字以使其变得更好，但这是我能做的最好的。有人能回答吗？我可能知道一个可能的问题，我只考虑正确答案的熵损失以及它如何影响整个网络。任何帮助都将不胜感激！    提交人    /u/Gullible_Big5193   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dfj9ne/training_question/</guid>
      <pubDate>Fri, 14 Jun 2024 05:18:24 GMT</pubDate>
    </item>
    <item>
      <title>对于那些想要了解 LMM 的人来说，我发现了一篇非常优秀的教育文章。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1df25y5/i_found_an_excellent_educational_post_for_those/</link>
      <description><![CDATA[我为所有一直想深入研究本地 LLM 但又被丰富的术语和运行模型的方法吓到的人找到了一篇很棒的帖子： https://www.gdcorner.com/blog/2024/06/12/NoBSIntroToLLMs-1-GettingStarted.html 它彻底解释了行业中使用的一切，而没有试图向你推销课程——我自己浏览过，它们都是相关的。    提交人    /u/Alex_GD_SkillPotion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1df25y5/i_found_an_excellent_educational_post_for_those/</guid>
      <pubDate>Thu, 13 Jun 2024 15:46:46 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 3 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1deajmi/ai_reading_list_part_3/</link>
      <description><![CDATA[大家好， AI 阅读清单的第三部分可在此处获取。在本部分中，我们将探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读清单中的以下 5 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1deajmi/ai_reading_list_part_3/</guid>
      <pubDate>Wed, 12 Jun 2024 16:14:52 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散 3 培养基简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de9xm5/briefly_about_stable_diffusion_3_medium/</link>
      <description><![CDATA[硬件：SD3 适合在标准消费级 GPU 上使用，由于 VRAM 使用率低，性能不会下降。  可信吗？ 是的。 精细调整：能够从小数据集中继承最精细的细节，非常适合进一步训练。  可信吗？ 是的。 速度提升：针对 TensorRT 优化的版本即将推出，速度提高 50%。  可信吗？ 是的。 AMD 优化：AMD 已针对各种设备优化了 SD3 Medium 的推理，包括 AMD 最新的 APU、消费级 GPU 和 MI-300X 企业级 GPU。  可信吗？值得怀疑。 许可：Stable Diffusion 3 Medium 可供个人和研究使用。新的 Creator 许可证使专业用户能够使用 SD3，同时支持 Stability 使 AI 民主化的使命，保持对开放 AI 的承诺。 Creator 许可证：每月 20 美元 - https://stability.ai/license    提交人    /u/Alex_GD_SkillPotion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de9xm5/briefly_about_stable_diffusion_3_medium/</guid>
      <pubDate>Wed, 12 Jun 2024 15:49:19 GMT</pubDate>
    </item>
    <item>
      <title>文章：多相机校准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de96cl/article_multiple_cameras_calibration/</link>
      <description><![CDATA[在这篇 文章中，您将了解：  为什么要使用多台摄像机 什么是时间同步 如何校准多台摄像机  如果这不是该 subreddit 的相关内容，请告诉我。    提交人    /u/Computer_Vision4883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de96cl/article_multiple_cameras_calibration/</guid>
      <pubDate>Wed, 12 Jun 2024 15:17:03 GMT</pubDate>
    </item>
    <item>
      <title>以人为本的可解释人工智能（Mark Reidl，佐治亚理工学院）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de5z2p/human_centered_explainable_ai_mark_reidl_georgia/</link>
      <description><![CDATA[       由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de5z2p/human_centered_explainable_ai_mark_reidl_georgia/</guid>
      <pubDate>Wed, 12 Jun 2024 12:55:23 GMT</pubDate>
    </item>
    <item>
      <title>我对最新 Apple 演示的看法。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ddgy2z/my_opinion_on_the_latest_apple_presentation/</link>
      <description><![CDATA[我喜欢的： Siri：我们终于等到了这个——她现在更聪明了：能够理解语音错误，保持对话上下文，如果您不会说话，现在还可以键入文本命令。此外，她了解所有操作系统功能，如果您需要查找特定内容，她可以帮助您弄清楚。 如果需要，Siri 还可以查看屏幕上的内容，这肯定会给人留下深刻印象。 总体而言，Siri 在 Apple Intelligence 层中得到了展示，这是一种个人语言模型，可以向用户学习，以便随着时间的推移更好地理解他们——这是接管 A.I. 缩写的巧妙尝试。 语言模型可以生成和重写内容、对通知/电子邮件进行排序和汇总、自动填充数据、创建预设快速回复、在后台搜索等。 他们已将图像生成集成到 Image Playground 应用程序中。质量仍然很差，但一切都在设备上，因此您可以生成 Lensa 风格的肖像、“Genmoji”表情符号、从照片中删除对象等等。 语言模型在云端运行，Apple 将其命名为“Personal Claude Compute”，大概是为了减少批评。他们承诺不会将数据存储在云中，允许专家审核系统，并且仅将云用于“计算”或“推理”。助手会从它所知道的关于您的所有信息中学习——涵盖所有设备和应用程序。 总的来说，AI 功能看起来很有趣，我很高兴尝试一下。 此外，如果您允许，Siri 可以引用 ChatGPT（他们承诺将来会提供更多模型），这是一种将 Apple 较弱的语言模型与 OpenAI 较强的语言模型联系起来的巧妙方法。 MacOS：最后，您可以从 Mac 控制您的 iPhone。不仅可以看到屏幕内容，还可以使用 iPhone Mirroring 使用鼠标和键盘实际控制手机。在此模式下，推送通知、音频等也会出现在 Mac 上，而且特别酷的是：iPhone 屏幕保持锁定状态，因此没有人可以偷看。 iOS：最后，您可以使用 FaceID 或密码等额外保护来锁定应用程序，甚至可以隐藏已安装的应用程序，这样如果您将 iPhone 借给别人，它们就更难找到。 iOS：iMessage 现在支持在没有蜂窝信号的情况下通过卫星发送消息 - 适用于 iPhone 14 并允许您发送常规短信和 iMessage。很棒的功能，迫不及待想在 iOS 18 发布后在海上测试它。 iOS：在使用 iPad/iPhone 通话期间，您可以共享屏幕并将控制权交给另一端的人（！），因此您现在可以通过 FaceApp 帮助亲人设置他们的设备。 此外，在通话过程中，您可以启动“自动转录”，对话将保存为笔记本中的文本。 iPad OS：他们展示了一款适用于 iPad 的新计算器，它不仅仅是一个计算器，还集成了数学和笔记：全变量、用 Apple Pencil 手写公式、创建图表等。 iPad OS：他们推出了“智能手写”——这是我在现实生活中会喜欢的功能：您用 Apple Pencil 书写文字，您的涂鸦会自动变成更易读的文本。 这是多年来最好的 Apple 演示，向他们致敬。   由    /u/Alex_GD_SkillPotion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ddgy2z/my_opinion_on_the_latest_apple_presentation/</guid>
      <pubDate>Tue, 11 Jun 2024 15:29:06 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助！构建 Micrograd</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</link>
      <description><![CDATA[我正在尝试浏览这个视频，在 1:50:29 处出现此错误：  TypeError Traceback (most recent call last) Cell In[151], line 1 ----&gt; 1 draw_dot(n(x)) Cell In[148], line 18, in draw_dot(root) 15 def draw_dot(root): 16 dot = Digraph(format=&#39;svg&#39;, graph_attr={&#39;rankdir&#39;: &#39;LR&#39;}) # LR = 从左到右 ---&gt; 18 nodes, edge = trace(root) 19 for n in nodes: 20 uid = str(id(n)) Cell In[148], line 12, in trace(root) 10 edge.add((child,v)) 11 build(child) ---&gt; 12 build(root) 13 return nodes, edge Cell In[148], line 7, in trace.&lt;locals&gt;.build(v) 6 def build(v): ----&gt; 7 if v not in nodes: 8 nodes.add(v) 9 for child in v._prev: TypeError: unhashable type: &#39;list&#39;  作为参考，我在回复中删除了我正在使用的整个 Jupyter 笔记本；我真的无法弄清楚这一点，这非常令人沮丧（我对此很陌生）。请帮忙。非常感谢。 :)     由    /u/no4-h 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</guid>
      <pubDate>Tue, 11 Jun 2024 02:20:03 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能：解码器和 GPT 模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dcqxvf/generative_ai_decoders_and_gpt_models/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dcqxvf/generative_ai_decoders_and_gpt_models/</guid>
      <pubDate>Mon, 10 Jun 2024 17:17:50 GMT</pubDate>
    </item>
    <item>
      <title>实际上看到了CNN深度神经网络模型吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dcq1us/what_actually_sees_a_cnn_deep_neural_network_model/</link>
      <description><![CDATA[      https://preview.redd.it/bo6edxn3wr5d1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=f29872abc1925300e92d7accf7d7f58c180732d0 在本视频中，我们深入探讨了深度神经网络的迷人世界，并可视化了其各层的结果，为分类过程提供了宝贵的见解   如何可视化 CNN 深度神经网络模型？ 在训练过程中实际看到的是什么? 选择的过滤器是什么，每个神经元的结果是什么。 在本部分中，我们将重点展示各层的结果。 非常有趣！     本视频是 🎥 图像分类教程系列：五部分 🐵 的一部分   我们将指导您完成对图像中的猴子物种进行分类的整个过程。我们首先介绍数据准备，您将在其中学习如何下载、探索和预处理图像数据。 接下来，我们深入研究卷积神经网络 (CNN) 的基础知识，并演示如何构建、训练和评估 CNN 模型以进行准确分类。 在第三个视频中，我们使用 Keras Tuner 优化超参数来微调 CNN 模型的性能。接下来，我们将在第四个视频中探索预训练模型的强大功能， 特别侧重于对 VGG16 模型进行微调以获得卓越的分类准确度。     您可以在此处找到视频教程的链接：https://youtu.be/yg4Gs5_pebY&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran   Python #Cnn #TensorFlow #Deeplearning #basicsofcnnindeeplearning #cnnmachinelearningmodel #tensorflowconvolutionalneuralnetworktutorial    提交人    /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dcq1us/what_actually_sees_a_cnn_deep_neural_network_model/</guid>
      <pubDate>Mon, 10 Jun 2024 16:41:43 GMT</pubDate>
    </item>
    <item>
      <title>ML Ops 简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc3yfi/introduction_to_ml_ops/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc3yfi/introduction_to_ml_ops/</guid>
      <pubDate>Sun, 09 Jun 2024 20:53:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么会有偏见？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc34vf/why_biases/</link>
      <description><![CDATA[      神经网络中偏差的用途是什么？ChatGPT 告诉我它会“转移”激活函数（这意味着如果添加偏差，它不会通过原点）。 这对我来说没有意义，因为如果偏差只是将自己添加到加权和中，函数本身没有理由转移。 同样，在所有条件相同的情况下，为什么不直接使用更强的权重而不是添加偏差，这似乎是毫无理由的额外工作。 更新：我已经发现偏差如何“转移”（使用这个词来描述正在发生的事情的非常误导的方式）激活函数。没有发生字面上的“转移”；发生的情况是，偏差只是增加了加权和（根据偏差），因此使其等同于如果函数实际上在 x 轴上移动（通过偏差）并且只将加权和作为其输入时激活函数所返回的值。如有疑问，请继续阅读。 这里有一个图片示例： 注意：加权和 = 2 且偏差 = 2。因此，当两者相加时，您将得到 4（呵呵哈哈……） 蓝线表示如果我们将加权和 (w1 * inp1) + 等... + 偏差输入到 S 型函数中。红线表示如果我们只输入加权和而不在 S 型函数中添加偏差，然后修改函数，使其在 x 轴上移动 2。 如您所见，当 x = 4 时，蓝线显示 y 为 .982 同样，当 x = 2 时，红线显示 y 为 .982 如果您认为我错了，请随时发表评论。    提交人    /u/mistr_bean   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc34vf/why_biases/</guid>
      <pubDate>Sun, 09 Jun 2024 20:18:45 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 2 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc00tg/ai_reading_list_part_2/</link>
      <description><![CDATA[大家好， 我在这里创建了一个新系列，我们将探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读材料中的以下 6 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc00tg/ai_reading_list_part_2/</guid>
      <pubDate>Sun, 09 Jun 2024 18:06:50 GMT</pubDate>
    </item>
    <item>
      <title>体素化三维物体的特征识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dbcvgg/feature_recognition_for_voxelized_3d_objects/</link>
      <description><![CDATA[嗨。我见过人们如何使用神经网络来识别 2D 图像上的特征或对图像上描绘的物体进行分类。例如，检测人脸或分辨照片上的动物种类。但是 3D 物体的特征识别呢？理论上，我可以将 3D 模型从网格格式转换为体素格式，并使用几乎相同的算法进行特征识别，以分辨哪些体素与手、头、眼睛等相关。 是否有任何现有的模型可以完成这种任务？如果我想构建这样的东西，我会遇到什么挑战？    提交人    /u/zergon321   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dbcvgg/feature_recognition_for_voxelized_3d_objects/</guid>
      <pubDate>Sat, 08 Jun 2024 21:08:47 GMT</pubDate>
    </item>
    </channel>
</rss>