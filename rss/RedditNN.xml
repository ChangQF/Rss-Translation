<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 19 Jun 2024 03:17:16 GMT</lastBuildDate>
    <item>
      <title>AI 阅读清单 - 第 4 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1diob1c/ai_reading_list_part_4/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1diob1c/ai_reading_list_part_4/</guid>
      <pubDate>Tue, 18 Jun 2024 11:25:26 GMT</pubDate>
    </item>
    <item>
      <title>溯因学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1di3kjq/abductive_learning/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1di3kjq/abductive_learning/</guid>
      <pubDate>Mon, 17 Jun 2024 17:20:23 GMT</pubDate>
    </item>
    <item>
      <title>注意力层作为输入数据过滤器</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dhjc2i/attention_layer_as_input_data_filter/</link>
      <description><![CDATA[嗨，我找不到关于此事的决定性来源。在将输入数据进一步传递到网络之前，是否可以使用注意层作为输入数据的一种过滤器？是否可以使用它来减少输入的维度（例如类似于 PCA - 只有注意层会用网络进行训练）并因此减少网络架构（例如，我们可以使用接受较小输入维度的网络）？    提交人    /u/Smooth-Ad9045   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dhjc2i/attention_layer_as_input_data_filter/</guid>
      <pubDate>Sun, 16 Jun 2024 22:40:32 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络训练人工智能驾驶</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgzwo3/training_an_ai_to_drive_using_neural_network/</link>
      <description><![CDATA[        提交人    /u/Flimsy_Roll_5666   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgzwo3/training_an_ai_to_drive_using_neural_network/</guid>
      <pubDate>Sun, 16 Jun 2024 04:42:52 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 是人工智能监控工具吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgn8sl/is_openai_an_ai_surveillance_tool/</link>
      <description><![CDATA[        提交人    /u/BackgroundResult   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgn8sl/is_openai_an_ai_surveillance_tool/</guid>
      <pubDate>Sat, 15 Jun 2024 17:39:15 GMT</pubDate>
    </item>
    <item>
      <title>寻求多视图模型方面的帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgcvud/looking_for_help_with_a_multiview_model/</link>
      <description><![CDATA[我正在使用 MURA 数据集，并尝试使用每个患者的 5-7 个视图来训练我的模型，我关注了论文并阅读了许多文章，但似乎永远无法获得他们在论文中声称的准确度，这可能是一个很大的原因，因为我似乎找不到他们正在使用的确切网络架构，而我只是在他们提供的非常小的信息位之间填补空白，目前我使用 xception 预训练模型作为我的 base_model 并通过它输入 7 个视图，以便可以将它们连接起来，然后是全局平均池化层，然后是 512 密集层，最后是输出层，哦，我似乎忘了提到目标，我试图仅使用其中 7 个中的 5 个来对骨骼类型进行分类，有人能告诉我为什么我不能达到高于 70% 的准确度，即使他们声称对于完全相同的任务，准确度高达 95 和 97    由    /u/youssefkhalifa 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgcvud/looking_for_help_with_a_multiview_model/</guid>
      <pubDate>Sat, 15 Jun 2024 07:53:26 GMT</pubDate>
    </item>
    <item>
      <title>寻求长期短期记忆网络的帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dfpz2k/looking_for_a_help_with_long_short_term_memory/</link>
      <description><![CDATA[大家好， 我正在尝试用 Python 构建一个长期短期记忆模型，其想法是从线性加速度 (x,y,z) 和角速度 (x,y,z) 预测旋转矩阵的 9 个分量，因此有 6 个输入变量。 我使用了文献中发现的标准架构，它与我的想法类似。但是，我认为该模型表现不佳，并且容易过度拟合。 有人对我如何尝试改进我的模型有什么建议吗？    提交人    /u/DesperateChemist9234   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dfpz2k/looking_for_a_help_with_long_short_term_memory/</guid>
      <pubDate>Fri, 14 Jun 2024 12:46:14 GMT</pubDate>
    </item>
    <item>
      <title>训练问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dfj9ne/training_question/</link>
      <description><![CDATA[我用 Java 创建了自己的前馈神经网络，使用了 ReLu、Soft Max 和交叉熵损失，但我遇到了一些有趣的问题。例如，在训练它识别 MNIST 数字时，它可以达到高达 50% 的准确率，然后就没有改进了。我剪辑了幅度为 5 或更大的梯度，学习率为 0.0001。我摆弄了这些数字以使其变得更好，但这是我能做的最好的。有人能回答吗？我可能知道一个可能的问题，我只考虑正确答案的熵损失以及它如何影响整个网络。任何帮助都将不胜感激！    提交人    /u/Gullible_Big5193   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dfj9ne/training_question/</guid>
      <pubDate>Fri, 14 Jun 2024 05:18:24 GMT</pubDate>
    </item>
    <item>
      <title>对于那些想要了解 LMM 的人来说，我发现了一篇非常优秀的教育文章。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1df25y5/i_found_an_excellent_educational_post_for_those/</link>
      <description><![CDATA[我为所有一直想深入研究本地 LLM 但又被丰富的术语和运行模型的方法吓到的人找到了一篇很棒的帖子： https://www.gdcorner.com/blog/2024/06/12/NoBSIntroToLLMs-1-GettingStarted.html 它彻底解释了行业中使用的一切，而没有试图向你推销课程——我自己浏览过，它们都是相关的。    提交人    /u/Alex_GD_SkillPotion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1df25y5/i_found_an_excellent_educational_post_for_those/</guid>
      <pubDate>Thu, 13 Jun 2024 15:46:46 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 3 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1deajmi/ai_reading_list_part_3/</link>
      <description><![CDATA[大家好， AI 阅读清单的第三部分可在此处获取。在本部分中，我们将探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读清单中的以下 5 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1deajmi/ai_reading_list_part_3/</guid>
      <pubDate>Wed, 12 Jun 2024 16:14:52 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散 3 培养基简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de9xm5/briefly_about_stable_diffusion_3_medium/</link>
      <description><![CDATA[硬件：SD3 适合在标准消费级 GPU 上使用，由于 VRAM 使用率低，性能不会下降。  可信吗？ 是的。 精细调整：能够从小数据集中继承最精细的细节，非常适合进一步训练。  可信吗？ 是的。 速度提升：针对 TensorRT 优化的版本即将推出，速度提高 50%。  可信吗？ 是的。 AMD 优化：AMD 已针对各种设备优化了 SD3 Medium 的推理，包括 AMD 最新的 APU、消费级 GPU 和 MI-300X 企业级 GPU。  可信吗？值得怀疑。 许可：Stable Diffusion 3 Medium 可供个人和研究使用。新的 Creator 许可证使专业用户能够使用 SD3，同时支持 Stability 使 AI 民主化的使命，保持对开放 AI 的承诺。 Creator 许可证：每月 20 美元 - https://stability.ai/license    提交人    /u/Alex_GD_SkillPotion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de9xm5/briefly_about_stable_diffusion_3_medium/</guid>
      <pubDate>Wed, 12 Jun 2024 15:49:19 GMT</pubDate>
    </item>
    <item>
      <title>文章：多相机校准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de96cl/article_multiple_cameras_calibration/</link>
      <description><![CDATA[在这篇 文章中，您将了解：  为什么要使用多台摄像机 什么是时间同步 如何校准多台摄像机  如果这不是该 subreddit 的相关内容，请告诉我。    提交人    /u/Computer_Vision4883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de96cl/article_multiple_cameras_calibration/</guid>
      <pubDate>Wed, 12 Jun 2024 15:17:03 GMT</pubDate>
    </item>
    <item>
      <title>以人为本的可解释人工智能（Mark Reidl，佐治亚理工学院）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1de5z2p/human_centered_explainable_ai_mark_reidl_georgia/</link>
      <description><![CDATA[       由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1de5z2p/human_centered_explainable_ai_mark_reidl_georgia/</guid>
      <pubDate>Wed, 12 Jun 2024 12:55:23 GMT</pubDate>
    </item>
    <item>
      <title>我对最新 Apple 演示的看法。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ddgy2z/my_opinion_on_the_latest_apple_presentation/</link>
      <description><![CDATA[我喜欢的： Siri：我们终于等到了这个——她现在更聪明了：能够理解语音错误，保持对话上下文，如果您不会说话，现在还可以键入文本命令。此外，她了解所有操作系统功能，如果您需要查找特定内容，她可以帮助您弄清楚。 如果需要，Siri 还可以查看屏幕上的内容，这肯定会给人留下深刻印象。 总体而言，Siri 在 Apple Intelligence 层中得到了展示，这是一种个人语言模型，可以向用户学习，以便随着时间的推移更好地理解他们——这是接管 A.I. 缩写的巧妙尝试。 语言模型可以生成和重写内容、对通知/电子邮件进行排序和汇总、自动填充数据、创建预设快速回复、在后台搜索等。 他们已将图像生成集成到 Image Playground 应用程序中。质量仍然很差，但一切都在设备上，因此您可以生成 Lensa 风格的肖像、“Genmoji”表情符号、从照片中删除对象等等。 语言模型在云端运行，Apple 将其命名为“Personal Claude Compute”，大概是为了减少批评。他们承诺不会将数据存储在云中，允许专家审核系统，并且仅将云用于“计算”或“推理”。助手会从它所知道的关于您的所有信息中学习——涵盖所有设备和应用程序。 总的来说，AI 功能看起来很有趣，我很高兴尝试一下。 此外，如果您允许，Siri 可以引用 ChatGPT（他们承诺将来会提供更多模型），这是一种将 Apple 较弱的语言模型与 OpenAI 较强的语言模型联系起来的巧妙方法。 MacOS：最后，您可以从 Mac 控制您的 iPhone。不仅可以看到屏幕内容，还可以使用 iPhone Mirroring 使用鼠标和键盘实际控制手机。在此模式下，推送通知、音频等也会出现在 Mac 上，而且特别酷的是：iPhone 屏幕保持锁定状态，因此没有人可以偷看。 iOS：最后，您可以使用 FaceID 或密码等额外保护来锁定应用程序，甚至可以隐藏已安装的应用程序，这样如果您将 iPhone 借给别人，它们就更难找到。 iOS：iMessage 现在支持在没有蜂窝信号的情况下通过卫星发送消息 - 适用于 iPhone 14 并允许您发送常规短信和 iMessage。很棒的功能，迫不及待想在 iOS 18 发布后在海上测试它。 iOS：在使用 iPad/iPhone 通话期间，您可以共享屏幕并将控制权交给另一端的人（！），因此您现在可以通过 FaceApp 帮助亲人设置他们的设备。 此外，在通话过程中，您可以启动“自动转录”，对话将保存为笔记本中的文本。 iPad OS：他们展示了一款适用于 iPad 的新计算器，它不仅仅是一个计算器，还集成了数学和笔记：全变量、用 Apple Pencil 手写公式、创建图表等。 iPad OS：他们推出了“智能手写”——这是我在现实生活中会喜欢的功能：您用 Apple Pencil 书写文字，您的涂鸦会自动变成更易读的文本。 这是多年来最好的 Apple 演示，向他们致敬。   由    /u/Alex_GD_SkillPotion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ddgy2z/my_opinion_on_the_latest_apple_presentation/</guid>
      <pubDate>Tue, 11 Jun 2024 15:29:06 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助！构建 Micrograd</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</link>
      <description><![CDATA[我正在尝试浏览这个视频，在 1:50:29 处出现此错误：  TypeError Traceback (most recent call last) Cell In[151], line 1 ----&gt; 1 draw_dot(n(x)) Cell In[148], line 18, in draw_dot(root) 15 def draw_dot(root): 16 dot = Digraph(format=&#39;svg&#39;, graph_attr={&#39;rankdir&#39;: &#39;LR&#39;}) # LR = 从左到右 ---&gt; 18 nodes, edge = trace(root) 19 for n in nodes: 20 uid = str(id(n)) Cell In[148], line 12, in trace(root) 10 edge.add((child,v)) 11 build(child) ---&gt; 12 build(root) 13 return nodes, edge Cell In[148], line 7, in trace.&lt;locals&gt;.build(v) 6 def build(v): ----&gt; 7 if v not in nodes: 8 nodes.add(v) 9 for child in v._prev: TypeError: unhashable type: &#39;list&#39;  作为参考，我在回复中删除了我正在使用的整个 Jupyter 笔记本；我真的无法弄清楚这一点，这非常令人沮丧（我对此很陌生）。请帮忙。非常感谢。 :)     由    /u/no4-h 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</guid>
      <pubDate>Tue, 11 Jun 2024 02:20:03 GMT</pubDate>
    </item>
    </channel>
</rss>