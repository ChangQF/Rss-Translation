<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 05 Jun 2024 12:27:30 GMT</lastBuildDate>
    <item>
      <title>“人工智能概述”中的谷歌与幻觉</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d7z2ut/google_vs_hallucinations_in_ai_overviews/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d7z2ut/google_vs_hallucinations_in_ai_overviews/</guid>
      <pubDate>Tue, 04 Jun 2024 14:51:27 GMT</pubDate>
    </item>
    <item>
      <title>关于理解前馈网络的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d7pqyu/question_on_understanding_the_feed_forward_network/</link>
      <description><![CDATA[我现在可以从头开始创建自己的前馈网络（推导出所有反向传播方程），但我很难说服自己这些东西有效。显然它在实践中有效，但更具体地说，我几乎可以说服自己，具有多个层的单输入 NN（使用 relu 激活）可以基于样本数据对任何函数进行建模。但是，我很难说服自己这真的适用于多维输入（尤其是超过 2 维）。你们有什么直觉吗？此外，我觉得梯度下降不会起作用，因为它只会找到局部最小值，而不能真正精确地近似随机函数。我想直观地了解为什么这实际上不仅在 2D 中有效，而且在 3D 及更高版本中也有效。任何直觉和/或帮助都将不胜感激！    提交人    /u/Gullible_Big5193   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d7pqyu/question_on_understanding_the_feed_forward_network/</guid>
      <pubDate>Tue, 04 Jun 2024 05:38:53 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络 | 深度学习动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d772lh/convolutional_neural_networks_deep_learning/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d772lh/convolutional_neural_networks_deep_learning/</guid>
      <pubDate>Mon, 03 Jun 2024 15:22:51 GMT</pubDate>
    </item>
    <item>
      <title>CNN 接受场 | 深度学习动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d76lfi/cnn_receptive_field_deep_learning_animated/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d76lfi/cnn_receptive_field_deep_learning_animated/</guid>
      <pubDate>Mon, 03 Jun 2024 15:02:54 GMT</pubDate>
    </item>
    <item>
      <title>使用语言代理进行推理（Swarat Chaudhuri，德克萨斯大学奥斯汀分校）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d6k089/reasoning_with_language_agents_swarat_chaudhuri/</link>
      <description><![CDATA[        由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d6k089/reasoning_with_language_agents_swarat_chaudhuri/</guid>
      <pubDate>Sun, 02 Jun 2024 18:36:46 GMT</pubDate>
    </item>
    <item>
      <title>人工智能/机器学习/数据科学领域 400 多个开放实习职位列表</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d6ivfm/list_of_over_400_open_internship_positions_in/</link>
      <description><![CDATA[        提交人    /u/ai_jobs   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d6ivfm/list_of_over_400_open_internship_positions_in/</guid>
      <pubDate>Sun, 02 Jun 2024 17:47:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 和 Python 检测视频中的移动物体</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d5tgwt/how_to_detect_moving_objects_in_video_using/</link>
      <description><![CDATA[      https://preview.redd.it/28l94k28704d1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=457f2e76027f72903d91​​603d11ead72dccd421dc 您是否曾想过使用 Python 和 OpenCV 检测视频中的移动物体？ 本教程已为您准备好了！我们将逐步教您如何使用 OpenCV 的函数来检测视频中的移动汽车。  本教程将为您提供在 Python 和 OpenCV 中进行移动（！！）物体检测和跟踪所需的工具。    在此处查看我们的视频：https://youtu.be/YSLVAxgclCo&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg 代码链接：​​https://github.com/feitgemel/Open-CV/tree/main/Detect%20moving%20objects%20in%20%20fixed%20background 享受， Eran    提交人    /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d5tgwt/how_to_detect_moving_objects_in_video_using/</guid>
      <pubDate>Sat, 01 Jun 2024 18:30:04 GMT</pubDate>
    </item>
    <item>
      <title>更有效地编码音频数据？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d4u3q9/encoding_audio_data_more_efficiently/</link>
      <description><![CDATA[嗨，我有下面的架构，它非常简单，用 MAE 计算时平均误差约为 0.052。这还不算太糟，但一些高频信息丢失了，出于很多原因，我不得不消除这个问题。 训练和测试数据由 8 个长向量组成，我想将它们编码为单个标量。 数据非常多样化。另外，我不想应用傅立叶变换，我只想使用原始音频数据。 你有什么想法可以更有效地对数据进行编码吗？我的意思是有什么技巧或其他东西可以减少损失？从数学上来说，这也许是不可能的，但我就是无法停止思考可能的解决方案。 我很乐意用生成时间换取准确性，我的观点是在损失可忽略不计的情况下尽可能地降低维数。 class Autoencoder(nn.Module): def __init__(self): super().__init__() self.encoder = nn.Sequential( nn.Linear(8, 1), ) self.decoder = nn.Sequential( nn.Linear(1, 8), ) def forward(self, x): x = self.encoder(x) x = self.decoder(x) return x def encode(self, x): return self.encoder(x) def decrypt(self, x): return self.decoder(x)  我认为我的训练算法很好，我使用 MSE、lr=1e-3、batch_size=64、adam 优化器，没什么太有趣的。     由    /u/Huge_Development_922  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d4u3q9/encoding_audio_data_more_efficiently/</guid>
      <pubDate>Fri, 31 May 2024 12:11:36 GMT</pubDate>
    </item>
    <item>
      <title>生物医学与医学工程的人工智能：神经网络项目</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d3xa69/ai_for_bme_neural_networks_project/</link>
      <description><![CDATA[嗨，我目前正在参加生物医学应用的人工智能课程。 我本应在 5 月 27 日提交一个项目，但是我被截止日期困住了，并且遇到了一些个人问题。教授很好心地将截止日期延长到 5 月 31 日，但是我还剩一天时间，我仍然无法完成我的项目，演示也需要一个 .ppt，我目前正在处理它。 目前时间不多了，迫切需要发布这篇文章，我恳请您帮助开发代码并帮助我不会输掉这门课程。 我本来应该训练一个呼吸暂停检测模型，但在信号处理中迷失了方向。 现在我正尝试用纯数据做一些更简单的事情，但我一直收到错误，我不知道如何修复。 如果您有兴趣，这是我尝试使用的数据库，但如果您碰巧有一个额外的项目，只要它是一个医疗检测/诊断项目，我就会接受它。 UCI 皮肤病学数据库    由   提交  /u/room02   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d3xa69/ai_for_bme_neural_networks_project/</guid>
      <pubDate>Thu, 30 May 2024 06:13:13 GMT</pubDate>
    </item>
    <item>
      <title>神经网络自省</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d3h7c6/neural_network_introspection/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d3h7c6/neural_network_introspection/</guid>
      <pubDate>Wed, 29 May 2024 17:04:44 GMT</pubDate>
    </item>
    <item>
      <title>新的脉冲神经元缩小了生​​物神经元和人工神经元之间的差距</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d2xdpe/a_new_spiking_neuron_narrows_the_gap_between/</link>
      <description><![CDATA[  由    /u/keghn  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d2xdpe/a_new_spiking_neuron_narrows_the_gap_between/</guid>
      <pubDate>Tue, 28 May 2024 23:05:06 GMT</pubDate>
    </item>
    <item>
      <title>评估速度非常慢，并且随着评估的进行，每次迭代的时间都会变得更长。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d2sqn6/eval_speed_is_very_slow_and_per_iteration_time/</link>
      <description><![CDATA[因此，在使用 hf 训练器时，我将 eval 累积步骤设置为 1 以修复 cuda OOM 错误，评估速度非常低，有什么解决方法吗？    提交人    /u/bubblegumbro7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d2sqn6/eval_speed_is_very_slow_and_per_iteration_time/</guid>
      <pubDate>Tue, 28 May 2024 19:54:42 GMT</pubDate>
    </item>
    <item>
      <title>如何为 CNN 设置自定义过滤器权重？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d2p4sq/how_to_set_custom_filter_weights_for_cnns/</link>
      <description><![CDATA[我需要测试带有默认过滤器的 CNN 与带有自定义过滤器的 CNN 的性能。但我不知道为自定义过滤器选择什么值，也找不到任何可以解释我的问题的资料来源。我知道有一些过滤器，如 sobel 和 laplacian。但它们对我的问题不起作用。我的问题是对小灰度图像进行分类。这些 9x9 2 维数组包含 0 到 255 或 0 到 1 之间的值（标准化后）。假设我希望过滤器检测一个角落。让示例图像看起来像这样： [1, 1, 1, 0, ...] [1, 0, 0, 0, ...] [1, 0, 0, 0, ...] [0, 0, 0, 0, ...] . . .  表示图像左上角有一个白色角。旨在检测这些特征的自定义过滤器会是这样的吗？ [[1., 1., 1.], [1., 0., 0.], [1., 0., 0.]]  如果有人可以向我解释如何为 CNN 创建自定义过滤器或可以提供宝贵的资源，那就太棒了。 我需要测试具有默认过滤器的 CNN 与具有自定义过滤器的 CNN 的性能。但我不知道为自定义过滤器选择什么值，也找不到任何可以解释我的问题的来源。我知道有一些像 sobel 和 laplacian 这样的过滤器。但它们不解决我的问题。我的问题是对小灰度图像进行分类。这些 9x9 2 维数组包含 0 到 255 或 0 到 1 之间的值（标准化后）。并且假设我想要过滤器检测一个角落。示例图像看起来像这样： [1, 1, 1, 0, ...] [1, 0, 0, 0, ...] [1, 0, 0, 0, ...] [0, 0, 0, 0, ...] . . .  表示在图像的左上角有一个白色的角。旨在检测这些特征的自定义过滤器会简单地这样吗？  [[1., 1., 1.], [1., 0., 0.], [1., 0., 0.]]  如果有人可以向我解释如何为 CNN 创建自定义过滤器或者可以提供宝贵的资源，那就太棒了。     提交人    /u/undefined_flower   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d2p4sq/how_to_set_custom_filter_weights_for_cnns/</guid>
      <pubDate>Tue, 28 May 2024 17:30:25 GMT</pubDate>
    </item>
    <item>
      <title>您是否使用 Google Colab 来训练您的神经网络？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d1z84o/do_you_use_google_colab_to_train_your_neural/</link>
      <description><![CDATA[查看投票    由    /u/Red_Pudding_pie 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d1z84o/do_you_use_google_colab_to_train_your_neural/</guid>
      <pubDate>Mon, 27 May 2024 19:06:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 MediaPipe、PointNet、ThreeJS 和 Embeddings 进行 ASL ⭤ 英语翻译</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d1k4d9/asl_english_translation_w_mediapipe_pointnet/</link>
      <description><![CDATA[      https://reddit.com/link/1d1k4d9/video/hu6qpuv2lw2d1/player 大家好！我是 Kevin Thomas，本拿比南中学（也是不列颠哥伦比亚省聋哑学校所在地）的 11 年级学生！ 在过去的几个月里，我一直在开发一种在美国手语 (ASL) 和英语之间进行翻译的工具。大多数现有的 ASL 翻译工具都是建立在 ASL 与英语是同一种语言的误解之上的。基本上，他们只将失聪视为一种残疾，只想克服听觉障碍，而不是将失聪翻译成 ASL 本身的语言。 在我的 ASL 老师的指导下，我一直在从事一个项目，该项目旨在促进这种翻译，同时尊重和保留 ASL 作为主要语言。对于 ASL 接收，我使用 Google MediaPipe 增强了超过 100,000 张 ASL 字母图像，并训练了一个 PointNet 模型来对聋哑人士的手势进行分类。对于 ASL 表达，我增强了超过 9,000 个 ASL 手势视频，嵌入了相应的单词，然后使用 ThreeJS 来标记听力正常的人士所说的单词。我还使用了 LLM 来提高准确性，并在英语和 ASL 语法之间进行翻译。 这是一个演示（和解释器）YouTube 视频 这是 GitHub 存储库 我只是在过去几个月才开始研究 ML/AI！我很感激任何反馈、机会或资源，以继续学习和成长！欢迎随时通过 Reddit DM 或 kevin.jt2007@gmail.com 与我联系！同时喜欢这个 Linkedin 帖子 也会有很大帮助 🙏🫶    提交人    /u/TrustedMercury   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d1k4d9/asl_english_translation_w_mediapipe_pointnet/</guid>
      <pubDate>Mon, 27 May 2024 05:16:17 GMT</pubDate>
    </item>
    </channel>
</rss>