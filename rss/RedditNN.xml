<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Wed, 15 May 2024 21:14:57 GMT</lastBuildDate>
    <item>
      <title>人工智能在足球领域的应用</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1csor2q/ai_in_soccer/</link>
      <description><![CDATA[在欧洲冠军联赛决赛之前，OpenCV.ai 团队观察了足球中 CV 实施的一些重要用例。在这篇文章中，您将了解计算机视觉技术如何使足球中的人工智能成为现代比赛的重要方面。    由   提交 /u/Correct_Jackfruit744   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1csor2q/ai_in_soccer/</guid>
      <pubDate>Wed, 15 May 2024 16:16:10 GMT</pubDate>
    </item>
    <item>
      <title>Kubernetes ML 和 AI 工作负载公平调度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1csnp9d/kubernetes_ml_and_ai_workloads_fair_scheduling/</link>
      <description><![CDATA[       由   提交 /u/codingdecently   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1csnp9d/kubernetes_ml_and_ai_workloads_fair_scheduling/</guid>
      <pubDate>Wed, 15 May 2024 15:31:55 GMT</pubDate>
    </item>
    <item>
      <title>可验证顺序决策中的多模态、预训练模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cs7j01/multimodal_pretrained_models_in_verifiable/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cs7j01/multimodal_pretrained_models_in_verifiable/</guid>
      <pubDate>Wed, 15 May 2024 00:17:28 GMT</pubDate>
    </item>
    <item>
      <title>奇异值分解 (SVD) 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cs0gxi/singular_value_decomposition_svd_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cs0gxi/singular_value_decomposition_svd_explained/</guid>
      <pubDate>Tue, 14 May 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>从扫描的书籍中提取单词：使用 Python 和 OpenCV 的分步教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1crt9zh/extracting_words_from_scanned_books_a_stepbystep/</link>
      <description><![CDATA[      https://preview.redd.it/4qzf5zcphe0d1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=0494bdeed742fb0 1f1c3884da549873e7eacd696  我们的视频教程将向您展示如何从扫描的书页中提取单个单词，并为您提供从任何书籍中提取所需文本所需的代码。 我们将引导您完成整个过程，从将图像转换为灰度并应用阈值处理，到使用 OpenCV 函数检测文本行并按其在页面上的位置对它们进行排序。 您将能够轻松提取扫描文档中的文本并执行分词。   在此处查看我们的视频：https://youtu .be/c61w6H8pdzs&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg  代码链接：https://github.com/feitgemel/Open-CV/tree/main/Words-Segmentation   享受， Eran   ImageSegmentation #PythonOpenCV #ContourDetection #ComputerVision #AdvancedOpenCV #extracttext #extractwords   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1crt9zh/extracting_words_from_scanned_books_a_stepbystep/</guid>
      <pubDate>Tue, 14 May 2024 14:17:08 GMT</pubDate>
    </item>
    <item>
      <title>Transformers 能在多大程度上模拟上下文中的牛顿法？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1crno5x/how_well_can_transformers_emulate_incontext/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03183 代码： https://anonymous.4open.science/r/transformer_higher_order-B80B/ 摘要：  基于 Transformer 的模型表现出了卓越的情境学习能力，促进了对其潜在机制的广泛研究。最近的研究表明，Transformers 可以实现上下文学习的一阶优化算法，甚至可以实现线性回归的二阶优化算法。在这项工作中，我们研究 Transformer 是否可以执行线性回归之外的更高阶优化方法。我们建立了具有 ReLU 层的线性注意力 Transformer 可以近似逻辑回归任务的二阶优化算法，并且仅用更多层的误差的对数即可实现 ϵ 误差。作为副产品，我们展示了即使是线性仅注意 Transformer 也能仅用两层实现牛顿迭代的单步矩阵求逆的能力。这些结果表明 Transformer 架构有能力实现超越梯度下降的复杂算法。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1crno5x/how_well_can_transformers_emulate_incontext/</guid>
      <pubDate>Tue, 14 May 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>这里的研究员和安的初学者是matlab的神经网络训练算法名称在pytorch中是一样的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cr3m0u/researcher_here_and_a_beginner_in_ann_are_matlabs/</link>
      <description><![CDATA[是 pytorch 中可用的 matlab 神经网络训练算法，如 levenberg–Marquardt、贝叶斯正则化和缩放共轭梯度训练算法，还是它们在不同的环境下名字？我没有像其他研究机构那样有钱买 matlab，但我会使用 pytorch + 抱歉这个菜鸟问题   由   提交 /u/callmetopperwithat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cr3m0u/researcher_here_and_a_beginner_in_ann_are_matlabs/</guid>
      <pubDate>Mon, 13 May 2024 16:30:26 GMT</pubDate>
    </item>
    <item>
      <title>使用一个站点的数据训练的人工神经网络可以在不同的站点上使用吗？查看环境建模和软件中空间/地理领域迁移学习的新研究</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cqtnzf/can_artificial_neural_networks_trained_with_data/</link>
      <description><![CDATA[ 由   提交/u/_Mat_San_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cqtnzf/can_artificial_neural_networks_trained_with_data/</guid>
      <pubDate>Mon, 13 May 2024 07:42:27 GMT</pubDate>
    </item>
    <item>
      <title>通过通用李群预条件子实现基于曲率的 SGD</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cq8h78/curvatureinformed_sgd_via_general_purpose/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.04553 代码（玩具实验）：https://github.com/lixilinx/psgd_torch 代码（大规模实验）：&lt; a href=&quot;https://github.com/opooladz/Preconditioned-Stochastic-Gradient-Descent&quot;&gt;https://github.com/opooladz/Precondition-Stochastic-Gradient-Descent 摘要：  我们提出了一种利用从 Hessian 向量乘积或参数和梯度的有限差分获得的曲率信息来加速随机梯度下降（SGD）的新方法，类似于BFGS算法。我们的方法涉及两个预处理器：无矩阵预处理器和低秩近似预处理器。我们使用对随机梯度噪声具有鲁棒性并且不需要线搜索或阻尼的标准在线更新两个预处理器。为了保持相应的对称性或不变性，我们的预处理器被限制为某些连接的李群。李群的等方差性质简化了预处理器拟合过程，而其不变性质消除了二阶优化器中通常需要的阻尼的需要。因此，参数更新的学习率和预处理器拟合的步长自然被归一化，并且它们的默认值在大多数情况下都适用。我们提出的方法为以低计算开销提高 SGD 的收敛性提供了一个有前途的方向。我们证明，在多种现代深度学习架构中，预处理 SGD (PSGD) 在视觉、NLP 和 RL 任务上的表现优于 SoTA。我们在本文中提供了用于复制玩具和大规模实验的代码。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cq8h78/curvatureinformed_sgd_via_general_purpose/</guid>
      <pubDate>Sun, 12 May 2024 13:58:54 GMT</pubDate>
    </item>
    <item>
      <title>如何使用PyTorch加速模型训练？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cprgs4/how_to_accelerate_the_model_training_with_pytorch/</link>
      <description><![CDATA[大家好！我叫 Maicon Melo Alves，是一名专门研究 AI 工作负载的高性能计算 (HPC) 系统分析师。  我想宣布我的书“使用 PyTorch 2.X 加速模型训练”已出版最近由 Packt 推出。  本书适合想要了解如何使用 PyTorch 加速机器学习模型训练过程的中级数据科学家、工程师和开发人员。 如果您认为这本书可以帮助其他专业人士，请与您的社区分享这篇文章！ 😊  非常感谢   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cprgs4/how_to_accelerate_the_model_training_with_pytorch/</guid>
      <pubDate>Sat, 11 May 2024 21:17:47 GMT</pubDate>
    </item>
    <item>
      <title>Tic-Tac-Toe 机器人，使用强化学习在 Python 中是不可能打败的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cpn2e4/tictactoe_bot_which_is_impossible_to_beat_in/</link>
      <description><![CDATA[我想用 python 创建一个最基本的 Tic-Tac-Toe 机器人，它与自己对战，它随机启动并因获胜而获得奖励，使得好的举动，并因做出非常糟糕的举动而受到惩罚，我将如何开始以及需要哪些模块才能运行一个非常基本的模块。干杯   由   提交/u/Just_Bed_995   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cpn2e4/tictactoe_bot_which_is_impossible_to_beat_in/</guid>
      <pubDate>Sat, 11 May 2024 17:50:57 GMT</pubDate>
    </item>
    <item>
      <title>如何使用卷积神经网络、Keras 调谐器超参数和迁移学习对猴子图像进行分类？ （第三部分）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1corzcv/how_to_classify_monkeys_images_using/</link>
      <description><![CDATA[视频 3：使用 Keras Tuner 增强分类： 🎯 利用Keras Tuner。 那么，我们如何决定应该定义多少层？每个卷积层中有多少个过滤器？ 我们应该使用 Dropout 层吗？它的值应该是多少？ 哪个学习率值更好？以及更多类似的问题。   优化 CNN 模型的超参数，微调其性能，并实现更高的准确度。 了解超参数调整的潜力并提高分类结果的精度。   这是第 3 部分的链接：https://github.com/feitgemel/TensorFlowProjects/tree/master/Monkey-Species   我分享了一个链接视频说明中的 Python 代码。   本教程第 1 部分。完整教程共 5 部分： 🎥 图像分类教程系列：五个部分🐵 在这五个视频中，我们将指导您完成对图像中的猴子物种进行分类的整个过程。我们首先介绍数据准备，您将学习如何下载、探索和预处理图像数据。 接下来，我们深入研究卷积神经网络 (CNN) 的基础知识并演示如何构建、训练和评估 CNN 模型以实现准确分类。 在第三个视频中，我们使用 Keras Tuner 优化超参数来微调 CNN 模型的性能。接下来，我们在第四个视频中探索预训练模型的威力， 特别关注微调 VGG16 模型以实现卓越的分类精度。 最后，在第五个视频中，我们深入研究深度神经网络的迷人世界，并将其层的结果可视化，为分类过程提供有价值的见解     享受 Eran   Python #Cnn #TensorFlow #Deeplearning #basicsofcnnindeeplearning #cnnmachinelearningmodel #tensorflowconvolutionalneuralnetworktutorial  &amp;# 32；由   提交 /u/Feitgemel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1corzcv/how_to_classify_monkeys_images_using/</guid>
      <pubDate>Fri, 10 May 2024 15:15:35 GMT</pubDate>
    </item>
    <item>
      <title>Instagram 推荐算法背后的工程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cok370/the_engineering_behind_instagrams_recommendation/</link>
      <description><![CDATA[   /u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cok370/the_engineering_behind_instagrams_recommendation/</guid>
      <pubDate>Fri, 10 May 2024 07:52:12 GMT</pubDate>
    </item>
    <item>
      <title>立方毫米的大脑以惊人的细节绘制出来</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1co99n1/cubic_millimetre_of_brain_mapped_in_spectacular/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1co99n1/cubic_millimetre_of_brain_mapped_in_spectacular/</guid>
      <pubDate>Thu, 09 May 2024 22:00:16 GMT</pubDate>
    </item>
    <item>
      <title>VideoPrism：用于视频理解的基础视觉编码器</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1co8d3w/videoprism_a_foundational_visual_encoder_for/</link>
      <description><![CDATA[ 由   提交/u/nickb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1co8d3w/videoprism_a_foundational_visual_encoder_for/</guid>
      <pubDate>Thu, 09 May 2024 21:20:45 GMT</pubDate>
    </item>
    </channel>
</rss>