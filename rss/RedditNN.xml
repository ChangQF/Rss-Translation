<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Mon, 01 Apr 2024 21:12:38 GMT</lastBuildDate>
    <item>
      <title>零射击还是不射击？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/</link>
      <description><![CDATA[我正在考虑使用包含 { en-hi, hi-en, en-bn, bn-en } 对的数据集微调 mT5，然后测试 hi-bn &amp; 的翻译质量bn-hi 对。这是 (hi-bn, bn-hi) 零样本翻译吗？我很困惑，因为 mT5 已经在 mC4 数据集上进行了预训练，该数据集包含 101 种语言，包括英语（en）、印地语（hi）、孟加拉语（bn）。   由   提交/u/Anxious-Buddha  /u/Anxious-Buddha reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/</guid>
      <pubDate>Mon, 01 Apr 2024 20:48:38 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我理解代码吗</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</link>
      <description><![CDATA[从tensorflow.keras导入tensorflow as tf 从tensorflow.keras.preprocessing.image导入层、模型、优化器导入ImageDataGenerator  class BottleneckBlock(tf.keras.layers.Layer): def init(self, inchannels, out_channels, stride=1): super(BottleneckBlock, self)。init_() self.conv1 = tf.keras.layers.Conv2D(out_channels, kernel_size=1, strides=stride, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers .BatchNormalization() self.relu = tf.keras.layers.ReLU() self.conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=1, padding=&#39;same&#39;, use_bias=False) self .bn2 = tf.keras.layers.BatchNormalization() self.conv3 = tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=1, padding=&#39;same&#39;, use_bias=False) self.bn3 = tf.keras.layers.BatchNormalization() self.downsample = tf.keras.Sequential([ tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=stride, use_bias=False), tf.keras.layers .BatchNormalization() ]) if stride != 1 else None self.stride = stride def call(self, x):identity = x out = self.conv1(x) out = self .bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3 （out）如果 self.downsample 不是 None：identity = self.downsample(x) out += Identity out = self.relu(out) return out  class CNN(models.Model ): def init(self, block,layers, numclasses=10): super(CNN, self).init_() self .in_channels = 64 self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers.BatchNormalization() self .relu = tf.keras.layers.ReLU() self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=&#39;相同&#39;) self.layer1 = self._make_layer(块, 64, 层[0]) self.layer2 = self._make_layer(块, 128, 层[1], 步幅=2) self.layer3 = self._make_layer(块, 256, 层[2], 步幅=2 ） self.layer4 = self._make_layer（块，512，层[3]，步幅= 2） self.avgpool = tf.keras.layers.GlobalAveragePooling2D（） self.fc = tf.keras.layers.Dense（num_classes）&lt; /p&gt; def _make_layer(self, block, out_channels,blocks, stride=1): 层 = []layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * 4 # block.expansion = 4 for _ in range(1,blocks):layers.append(block(self.in_channels,out_channels)) return tf.keras.Sequential(layers) def call(self, x): x = self .conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3 (x) x = self.layer4(x) x = self.avgpool(x) x = self.fc(x) 返回x  def ResNet50(num_classes=10): 返回CNN (BottleneckBlock, [3, 4, 6, 3], num_classes) 数据集和数据生成器 train_datagen = ImageDataGenerator( rescale=1./255,heart_range=0.2, Zoom_range=0.2 , Horizo​​ntal_flip=True) train_generator = train_datagen.flow_from_directory( &#39;/kaggle/input/prostate-cancer&#39;, target_size=(224, 224), batch_size=32, class_mode=&#39;categorical&#39;) 使用示例 model = ResNet50(num_classes=len(train_generator.class_indices)) model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=&#39;categorical_crossentropy&#39;,metrics=[ &#39;准确度&#39;]) model.fit(train_generator, epochs=10) def Predict_image_class(image_path): img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224)) img_array = tf.keras.preprocessing.image.img_to_array(img) img_array = tf.expand_dims(img_array, 0) # 创建批量轴 img_array /= 255. # 标准化predicted_class = model.predict(img_array) return tf.argmax(predicted_class[ 0]).numpy() 使用示例 image_path = &#39;/kaggle/input/predict-img/0001.png&#39; Predicted_class = Predict_image_class(image_path) print(f&quot;Predicted类: {predicted_class}&quot;)   由   提交 /u/Warm-Perspective-390   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</guid>
      <pubDate>Mon, 01 Apr 2024 04:51:51 GMT</pubDate>
    </item>
    <item>
      <title>深度学习项目构想</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</link>
      <description><![CDATA[你好， 我目前正在学习深度学习课程，我必须完成一个期末项目。我们主要介绍了 MLP / CNN / 基本架构和框架，以及一点点 RNN 和 LLM，但我想重点关注一个利用 CNN 的项目。老实说，我没有太多好主意，所以我一直在寻找一些有用或有趣的主题的灵感。我也一直在 Kaggle 上查找数据集。 感谢您的任何意见！谢谢！   由   提交/u/beanbeandoedoe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</guid>
      <pubDate>Mon, 01 Apr 2024 03:35:12 GMT</pubDate>
    </item>
    <item>
      <title>黑匣子内部：卷积神经网络可视化！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bshff9/inside_the_black_box_convolutional_neural_nets/</link>
      <description><![CDATA[   /u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bshff9/inside_the_black_box_convolutional_neural_nets/</guid>
      <pubDate>Sun, 31 Mar 2024 18:38:14 GMT</pubDate>
    </item>
    <item>
      <title>我在一个函数上训练了 LSTM，使其在输入前 50 个数据点后预测下一个数据点！每一帧都是另一个训练纪元！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bs8obr/i_trained_an_lstm_on_a_function_such_that_it/</link>
      <description><![CDATA[   /u/frinnedfodern   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bs8obr/i_trained_an_lstm_on_a_function_such_that_it/</guid>
      <pubDate>Sun, 31 Mar 2024 11:55:14 GMT</pubDate>
    </item>
    <item>
      <title>批量归一化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bs7olg/batch_normalization/</link>
      <description><![CDATA[      &amp;# 32；由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bs7olg/batch_normalization/</guid>
      <pubDate>Sun, 31 Mar 2024 10:58:12 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 迁移学习：使用 Mobilenet 和 Python 对图像进行分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</link>
      <description><![CDATA[      https://preview.redd.it/zyusaigsrfrc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=b6b7442176ceca4d52bef 6dba7571da7af8e6b91 在本视频中，我们将向您展示如何使用 TensorFlow 和 Mobilenet 通过迁移学习来训练图像分类模型。  我们将指导您完成图像数据预处理、微调预训练 Mobilenet 模型以及使用验证数据评估其性能的过程。  视频教程的链接在这里：https://youtu.be/xsBm_DTSbB0 &lt; p&gt;我还在视频说明中分享了 Python 代码。 享受吧， Eran #TensorFlow #Mobilenet #ImageClassification #TransferLearning #Python #DeepLearning #机器学习 #ArtificialIntelligence #PretrainedModels #ImageRecognition #OpenCV #ComputerVision #Cnn   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</guid>
      <pubDate>Sat, 30 Mar 2024 08:58:14 GMT</pubDate>
    </item>
    <item>
      <title>受大脑启发的混沌尖峰反向传播</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</guid>
      <pubDate>Fri, 29 Mar 2024 17:10:30 GMT</pubDate>
    </item>
    <item>
      <title>BART 模型解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bqptwh/bart_model_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了BART模型的架构以及它是如何预训练的。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bqptwh/bart_model_explained/</guid>
      <pubDate>Fri, 29 Mar 2024 13:53:04 GMT</pubDate>
    </item>
    <item>
      <title>负责任的法学硕士（陈天龙，麻省理工学院 - Metacog AI）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bpdgxg/accountable_llms_tianlong_chen_mit_metacog_ai/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bpdgxg/accountable_llms_tianlong_chen_mit_metacog_ai/</guid>
      <pubDate>Wed, 27 Mar 2024 21:23:53 GMT</pubDate>
    </item>
    <item>
      <title>探索用于生成音乐可解释人工智能的变分自动编码器架构、配置和数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bpb1ko/exploring_variational_autoencoder_architectures/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bpb1ko/exploring_variational_autoencoder_architectures/</guid>
      <pubDate>Wed, 27 Mar 2024 19:47:02 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络的基本深度学习算法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bo7wno/essential_deep_learning_algorithms_for_artificial/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/Emily-joe  /u/Emily-joe  artiba.org/blog/essential-deep-learning-algorithms-for-artificial-neural-networks&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bo7wno/essential_deep_learning_algorithms_for_artificial/</guid>
      <pubDate>Tue, 26 Mar 2024 13:28:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Mon, 25 Mar 2024 09:05:45 GMT</pubDate>
    </item>
    <item>
      <title>FeatUp：一种机器学习算法，可升级深度神经网络的分辨率以提高计算机视觉任务的性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</guid>
      <pubDate>Mon, 25 Mar 2024 06:46:48 GMT</pubDate>
    </item>
    <item>
      <title>我需要有关 SoftMax 函数的说明</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</link>
      <description><![CDATA[我最近一直在开发一个深度学习库，以更好地理解机器学习概念，现在我正在实现一个软最大值激活函数，一切似乎都是正确的，因为我检查了现有 softmax 计算器上的输出和导数的值并且它们匹配起来，但是当我让我的网络进行训练时，它没有学到任何东西，输出要么是 [0.5, 0.4] ish，要么是它们不考虑目标，随机变为 0.9。  当我的数据集中有多个样本（例如图像分类器）时，各个样本的所有输出加起来为 1，这令人困惑。我知道 softmax 应该将 1 个样本的输出分配为“概率”但我不明白为什么它会发生在我的数据集的样本之间 我很困惑，softmax 是否只是一个常规激活函数，或者它是否像一个特殊情况。我看到一个视频，他们将 softmax 视为一层而不是激活函数，这让我怀疑与其他激活函数相比，softmax 函数是否具有不同的反向传播步骤。当我将最后一个激活函数更改为 sigmoid、tanH 或 ReLU 时，一切正常。 非常感谢任何反馈或评论，因为我花了几个小时在这上面。   由   提交 /u/chjammy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</guid>
      <pubDate>Sun, 24 Mar 2024 19:13:17 GMT</pubDate>
    </item>
    </channel>
</rss>