<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Sat, 01 Mar 2025 06:23:52 GMT</lastBuildDate>
    <item>
      <title>不确定这是否是发布此信息的正确位置</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//github.com/choc1024/iac       我知道它不是很快，也不是如此之多，如果有很多东西，我都不会有这样的特征，并且可以与您分享，或者我会喜欢它，并且您会在您的特点上，并且您会在您的特点如果不是这样，请向我推荐另一个subreddit。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/i/im_chatgpt4    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1j0iq9n/not_sure_sure_this_is_is_is_the_right_tplace_tplace_to_to_to_post_this/”&gt; [links]    [注释]      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</guid>
      <pubDate>Fri, 28 Feb 2025 21:23:59 GMT</pubDate>
    </item>
    <item>
      <title>在没有单词限制的情况下免费进行语音文本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</link>
      <description><![CDATA[        ＆＃32;提交由＆＃32; /u/u/u/cool-hornet-8191      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</guid>
      <pubDate>Fri, 28 Feb 2025 16:01:17 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的临床注释的整合，以增强疾病轨迹预测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种基于变压器的方法，用于分析临床注释和预测患者轨迹。关键方法论贡献是将时间注意机制与特定领域的医学文本处理整合到预测患者预后的多个方面。 主要技术点：•多头注意的架构适用于临床注意事项序列，专门针对临床注释序列•预处理管道•跨越多个治疗术语的范围范围•先前验证•先前的时间术语•以前的时间范围•零舒适的范围•零舒适的范围，零，• （重新入院，住院时间，进步） 结果：•基线模型的再入院预测准确性提高了12％•在现场长度预测中的准确性提高了15％•在具有多种合并症的复杂案例上的出色表现•多种合并症的复杂案例•维持多个合并症的质量保持了预测质量，而不同的医疗专业 我认为，这项工作朝着更全面的临床支持系统支持系统。与结构化数据一起处理非结构化临床笔记的能力可以帮助捕获当前系统错过的微妙模式。 However, the computational requirements and need for high-quality training data may limit immediate widespread adoption. I think the zero-shot capabilities are particularly noteworthy, as they suggest potential applications in rare conditions or emerging health challenges where training data is limited. TLDR: Transformer model analyzes clinical notes to predict patient trajectories, showing improved accuracy over baselines and zero-shot capabilities.可以增强临床决策支持，但需要仔细验证。 完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</guid>
      <pubDate>Fri, 28 Feb 2025 10:13:04 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类是否需要单次编码？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j03vjh/does_multilabel_classification_require_onehot/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个数据集，该数据集基本上包含一个相对于8个同时类标记的内容字符串，每个类都有几个选项（即多标签）。在整个类中将所有选项添加在一起，总共有23个独特的标签。 最初，我通过使用8个单独的多级分类器来解决此问题，尽管它效果很好，但考虑到每个分类器都需要一个特定的内容和切片，它可能会犯错误。另外，我更喜欢“简单性”。只需要关心一个神经网络而不是8个分类器。  结果，我建立了一个具有多标签输出层的神经网络，该层产生了单热编码的输出。我现在确定的问题是，这个神经网似乎并没有库存，标签在课堂内是相互排斥的（例如，第一堂课有4个可能的标签，但只有1个标签，但应该是非零的标签）。 因此，我的印象是，我得到这样的方式，这样做的方式是这样做的，我可能需要训练很多数据，因此我有一个有效的培训，我是否有一个有效的需要，我是否需要一个人，我是否需要一个eccod。我可以使用产生8个标签的数组的输出层（而不是23个标签），并且其值是非二进制的，但直接反映了选项。因此，例如，如果1类最好的标签是第三个标签，则输出层返回“ 3”。而不是[0,0,1,0 ...]。如果是这样，我必须对当前使用Sigmoid激活函数和二进制Crossentropyloss函数的输出层进行哪些调整。  当然也欢迎其他任何想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j03vjh/does_multilabel_classification_require_onehot/</guid>
      <pubDate>Fri, 28 Feb 2025 09:29:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用卷积神经网络对疟疾细胞进行分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1izmrzi/how_to_classify_malaria_cells_using_convolutional/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    本教程提供了一份逐步指南，介绍了如何使用TensorFlow和Keras实施和培训CNN模型进行疟疾细胞分类。                      数据准备中的数据准备，您可以在此部分进行培训，并在此部分下载数据，并准备该数据供应数据，并准备该数据供您进行数据准备。这涉及到诸如准备数据，分类为训练和测试集，以及必要时进行数据扩展。       cnn模型构建和培训 -  在第二部分中，您将专注于建立卷积神经网络（CNN）模型，用于用于疟疾细胞的二元分类。这包括模型自定义，定义层和使用准备好的数据训练模型。     模型测试和预测 -  最终部分涉及使用以前从未见过的新图像测试训练的模型。您将加载已保存的模型并使用它来对此新图像进行预测以确定是否感染。       您可以在博客中找到代码的链接：      href =“ https://medium.com/@feitgemel/how-to-complasify-malaria-cells-using-convolutional-neur-network-c00859bc6b46”&gt; https://medium.com/@feitgemel/how-to-classify-malaria-cells-using-convolutional-neurner-network-c00859bc6b46     您可以找到更多教程，并在此处加入我的新闻通讯： https://eranfeit.net/                 href =“ https://youtu.be/wlpuw3ggpqo＆amp;list=uulftiwjjhah6bviswkljum9sg”&gt; https://youtu.be/youtu.be/wlpuw3ggppqo&amp;/ wlppuppqo&amp;list=ulist=uulfftiiwjjjjjjjhah6bvis     在提交由＆＃32; /u/feitgemel     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1izmrzi/how_to_classify_malaria_cells_using_convolutional/</guid>
      <pubDate>Thu, 27 Feb 2025 18:30:29 GMT</pubDate>
    </item>
    <item>
      <title>稳定垃圾邮件：增强梯度归一化，以进行更高效的4位LLM训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1izcdva/stablespam_enhanced_gradient_normalization_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一种新方法结合了尖峰感动的动量和优化的4位量化，以启用比16位亚当的稳定训练，同时使用明显更少的内存。关键的创新是通过仔细的梯度监控在低度训练期间检测和预防优化的不稳定性。 主要技术点： - 引入尖峰 - 尖峰 - 施加 spike -avare动量重置，以梯度统计量，以调查潜在的不稳定性 - 检测潜在的不稳定性 - 使用动态调整量表的量表量尺度，以量表为基础量表，以4位的量度为基础量表 - 该量度的量表 - 以4位的量度为基础量表 - 该量表 - 以4位的量级为基础量表 - 该量表 - 以4位的量级为基础量表 - 保持重量和梯度量化量表的单独跟踪 - 与现有的优化器和体系结构兼容 关键结果： - 匹配或超过16位的ADAM性能，同时使用75％的记忆力 - 成功地训练Bert -large到4位精确的4位精确培训 - 从1E -4到1E -4的学习率稳定培训 - 在1e -4的范围内显示出稳定的培训 - 参数 我认为这对于使ML研究民主化可能会产生影响。培训大型模型目前需要大量的GPU资源，并且能够以4位精确的精度进行培训，而无需牺牲稳定性或准确性，这可能会使研究预算有限的实验室更容易获得研究。 我认为，Spike-Aware Momentum Reset Reset Technique    可以证明，不仅可以证明一种不仅能够改善最优先级的其他情况&lt;其他情况&gt;其他情况&lt;其他情况&gt; &lt;其他情况&lt;&lt;其他情况。方法可以通过仔细的动量管理和优化的量化来实现稳定的4位模型训练，将16位性能与少75％的内存使用量匹配。   full unshore   。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1izcdva/stablespam_enhanced_gradient_normalization_for/</guid>
      <pubDate>Thu, 27 Feb 2025 10:03:19 GMT</pubDate>
    </item>
    <item>
      <title>Anyon可以推荐一些最佳初学者友好的卷积神经网络教程，这将导致智能照明系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/arnoldpaclarinjr     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</guid>
      <pubDate>Wed, 26 Feb 2025 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>偏爱感知的LLM框架，用于事实基础营销内容生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一个新框架，用于生成营销内容，以保持说服力和事实准确性之间保持平衡。 The core innovation is a two-stage architecture combining a retrieval module for product specifications with a controlled generation approach. Key technical components: - Grounded generation module that references source product specifications during content creation - Persuasion scoring mechanism measuring effectiveness across multiple marketing dimensions - Fact alignment checker comparing generated content against source material - Novel将50,000个产品描述与相应的营销材料结合的数据集 结果显示：-23％的说服力提高了基线模型（通过人类评估测量）-91％的事实准确性在合并产品规格时保持了实际的事实准确性 - 合并产品规格的大量降低幻觉降低了幻觉产品的幻觉效果，与标准LLM的销售方法相比，可以自动销售自动流动 - 在自动销售中保持自然的影响 我认为，最有趣的技术方面是它们如何处理创意营销语言和事实约束之间的权衡。检索功能的方法可能有可能应用于需要创造力和准确性的其他领域。  tldr：AI营销内容生成的新框架，可保持事实准确性，同时优化说服力，显示出23％的提高有效性，同时保持91％的事实准确性。     完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</guid>
      <pubDate>Wed, 26 Feb 2025 09:59:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间缩放方法在数学推理任务中显示出有限的多语言概括</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键洞察力是使用测试时间缩放来改善跨多种语言的数学推理，而无需重新训练模型。 The researchers apply this technique to competition-level mathematics problems that go well beyond basic arithmetic. Main technical points: - Test-time scaling involves generating multiple solution attempts (5-25) and selecting the most consistent answer - Problems were carefully translated to preserve mathematical meaning while allowing natural language variation - Evaluation used competition-level problems including algebra, geometry, and proofs - Performance gains were consistent across all tested语言 - 特别注意维持数学符号一致性 关键结果： - 测试时间缩放在所有问题类型和语言中的准确性提高了准确性 - 改进在多步推理问题中最为明显的效果 - 性能提高 - 缩放的缩放相似，无论源语言的质量如何，对数学推理能力                                I think the methodological contribution here - showing that test-time scaling works consistently across languages - is particularly valuable for developing multilingual mathematical AI systems. The limitations around cultural mathematical contexts and translation edge cases suggest interesting directions for future work. TLDR: Test-time scaling improves mathematical在竞争级别的问题上证明，跨语言始终如一地推理。  完整的总结在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</guid>
      <pubDate>Tue, 25 Feb 2025 12:05:01 GMT</pubDate>
    </item>
    <item>
      <title>负责人AI的课程材料</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我目前正在设计负责人AI 的课程，我想寻求帮助，以找到课程内容，任何大学课程或您认为相关的任何大学课程或研究的良好免费材料，请分享。提交由＆＃32; /u/u/over_reward9875    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1iwely0/course_materials_for_responsible_ai/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 16:56:17 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/u/sersion-trainer-541       [注释]         ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>CNN和Tensorboard的新手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  开始学习如何训练CNN，好奇，如果val_accranacy中的初始尖峰是正常的，或者如果峰值是正常的，那么如果Spike drop Drop表示某种过度贴身或某种东西？我本来可以肯定的是，如果Val_accuracy保持较低，但随着模型继续训练，似乎会逐渐增加。这也可以是过度拟合验证数据的模型吗？我正在使用每班大约1500张图像的数据集。谢谢！ 〜一个试图学习cnns   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/stkoopchoop      [注释]           ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</guid>
      <pubDate>Sun, 23 Feb 2025 08:32:09 GMT</pubDate>
    </item>
    <item>
      <title>多模式奖励基地：评估视觉模型奖励功能的综合基准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了多模式奖励贝恩，这是视觉奖励模型的全面评估框架。框架测试使用超过2,000个测试用例，包括准确性，偏差检测，安全考虑和鲁棒性，包括 关键技术要点： - 使用标准化指标跨越多个功能：响应质量，事实准确，偏见，跨模态理解方法 - 进行多种功能 - 评估6个显着的奖励模型 - 评估6个突出的奖励模型 - 用于评估6个突出的奖励模型 -  performance - Identifies specific failure modes in current models Main results: - Models show strong performance (&gt;80%) on basic text evaluation - Cross-modal understanding scores drop significantly (~40-60%) - High variance in safety/bias detection (30-70% range) - Inconsistent performance across different content types - Most models struggle with complex reasoning tasks involving both modalities I think this work highlights当前奖励模型功能的关键差距，尤其是在处理多模式内容方面。基准可以帮助我们标准化我们如何评估这些模型并推动安全和偏见检测等领域的改进。 我认为，最有价值的贡献是揭露特定的故障模式 - 准确地表明当前模型的位置短缺有助于集中于未来的研究工作。结果表明，我们需要从根本上使用新的方法来处理奖励模型中的跨模式内容。  tldr：新的基准测试标准揭示了视觉奖励模型处理复杂多模式任务的能力，尤其是在安全性和偏见检测中。提供了改进的清晰指标。  在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</guid>
      <pubDate>Sun, 23 Feb 2025 07:00:22 GMT</pubDate>
    </item>
    <item>
      <title>Chase：使用LLMS自动生成硬评估问题的框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使LLMS生成挑战性问题的新框架研究如何系统地创建高质量的测试问题。核心方法论通过明确提示策略使用迭代性自我测试和有针对性的难度校准。 关键的技术组成部分： - 具有中间验证的多阶段生成过程 - 自我评估循环，LLM批评其自身的输出 - 通过参数提示 - 交叉 -  valify -pp  我认为这项工作为开发更好的评估数据集提供了实用的基础。产生校准难度水平的能力可以更精确地帮助基准模型功能。尽管当前的实施使用GPT-4，但原理应扩展到其他LLM。 系统产生问题的系统方法似乎是迈向更严格的测试方法的重要一步。但是，我看到了一些关于将其扩展到非常大的数据集并确保不同领域的质量一致的问题。  tldr：新方法演示了如何通过自我测试和迭代的改进来使LLMS产生更好的测试问题，并具有可衡量的问题质量和难度校准。 href =“ https://aimodels.fyi/papers/arxiv/how-to-to-get-get-your-llm-to-generate”&gt;完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</guid>
      <pubDate>Sat, 22 Feb 2025 07:12:27 GMT</pubDate>
    </item>
    <item>
      <title>通过对比度学习从时间序列数据中学习内在的神经表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一种对比度学习方法，将神经活动动态映射到几何表示，提取他们所说的“柏拉图式”人群级神经记录的形状。 The method combines temporal embedding with geometric constraints to reveal fundamental organizational principles. Key technical aspects: - Uses contrastive learning on neural time series data to learn low-dimensional embeddings - Applies topological constraints to enforce geometric structure - Validates across multiple neural recording datasets from different species - Shows consistent emergence of basic geometric patterns (spheres, tori, etc.) - Demonstrates robustness across different neural population sizes and brain regions Results demonstrate: - Neural populations naturally organize into geometric manifolds - These geometric patterns are preserved across different timescales - The representations emerge consistently in both task and spontaneous activity - Method works on populations ranging from dozens to thousands of neurons - Geometric structure correlates with behavioral and cognitive variables 我认为这种方法可以为了解神经种群的编码和过程信息提供新的框架。 The geometric perspective might help bridge the gap between single-neuron and population-level analyses. I think the most interesting potential impact is in neural prosthetics and brain-computer interfaces - if we can reliably map neural activity to consistent geometric representations, it could make decoding neural signals more robust. TLDR: New method uses contrastive learning to show how neural populations将信息组织成几何形状，为神经计算提供潜在的通用原理。  完整摘要”。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</guid>
      <pubDate>Fri, 21 Feb 2025 09:59:51 GMT</pubDate>
    </item>
    </channel>
</rss>