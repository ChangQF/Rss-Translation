<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 12 Jan 2024 21:12:15 GMT</lastBuildDate>
    <item>
      <title>🎨 使用 Tensorflow 和 Python 的神经风格迁移教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/195195z/neural_style_transfer_tutorial_with_tensorflow/</link>
      <description><![CDATA[      https://preview.redd.it/k8xazw7ps1cc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=8e3d290829f6 01169dfc1014ad18824bb3844115 🚀 在本视频教程中，我们将使用艺术 Python 库生成图像 探索神经风格迁移的迷人领域，并学习如何将图像与您选择的风格合并  p&gt; 以下是您将学到的内容： 🔍 从 TensorFlow 模型中心下载模型：探索使用 TensorFlow 模型中心预训练模型的便利性。  我们将引导您完成为您的艺术事业找到完美模型的步骤。  🖼️ 预处理图像以进行神经风格迁移：优化图像以实现风格迁移成功！  学习基本的预处理步骤，从调整大小到标准化，确保您的结果非常出色。  🎭 应用和可视化风格迁移：深入研究“风格迁移质量” GitHub 存储库。跟随我们应用神经网络来区分风格和生成的图像特征。  观看您的图像以比以往更高的质量进行转换。 您可以在此处找到代码：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/style-transfer 视频链接：https://youtu.be/QgEg61WyTe0 欣赏 Eran ​ #python #styletransferquality #tensorflow #NeuralStyleTransfer #PythonAI #ArtTech   &amp;# 32；由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/195195z/neural_style_transfer_tutorial_with_tensorflow/</guid>
      <pubDate>Fri, 12 Jan 2024 17:56:28 GMT</pubDate>
    </item>
    <item>
      <title>🎨 使用 Tensorflow 和 Python 的神经风格迁移教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1951963/neural_style_transfer_tutorial_with_tensorflow/</link>
      <description><![CDATA[      https://preview.redd.it/k8xazw7ps1cc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=8e3d290829f6 01169dfc1014ad18824bb3844115 🚀 在本视频教程中，我们将使用艺术 Python 库生成图像 探索神经风格迁移的迷人领域，并学习如何将图像与您选择的风格合并  p&gt; 以下是您将学到的内容： 🔍 从 TensorFlow 模型中心下载模型：探索使用 TensorFlow 模型中心预训练模型的便利性。  我们将引导您完成为您的艺术事业找到完美模型的步骤。  🖼️ 预处理图像以进行神经风格迁移：优化图像以实现风格迁移成功！  学习基本的预处理步骤，从调整大小到标准化，确保您的结果非常出色。  🎭 应用和可视化风格迁移：深入研究“风格迁移质量” GitHub 存储库。跟随我们应用神经网络来区分风格和生成的图像特征。  观看您的图像以比以往更高的质量进行转换。 您可以在此处找到代码：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/style-transfer 视频链接：https://youtu.be/QgEg61WyTe0 欣赏 Eran ​ #python #styletransferquality #tensorflow #NeuralStyleTransfer #PythonAI #ArtTech   &amp;# 32；由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1951963/neural_style_transfer_tutorial_with_tensorflow/</guid>
      <pubDate>Fri, 12 Jan 2024 17:56:28 GMT</pubDate>
    </item>
    <item>
      <title>推理捷径</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/194fhgs/reasoning_shortcuts/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/194fhgs/reasoning_shortcuts/</guid>
      <pubDate>Thu, 11 Jan 2024 23:09:10 GMT</pubDate>
    </item>
    <item>
      <title>在尖峰神经网络中学习长序列</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1945g0p/learning_long_sequences_in_spiking_neural_networks/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00955 摘要：  尖峰神经网络（SNN）从大脑中汲取灵感，使节能计算。自从 Transformer 出现以来，SNN 一直在努力与现代序列任务上的人工网络竞争，因为它们继承了循环神经网络 (RNN) 的局限性，并且增加了使用不可微二元尖峰激活进行训练的挑战。然而，最近人们对 Transformer 的高效替代方案重新产生了兴趣，催生了名为状态空间模型 (SSM) 的最先进的循环架构。这项工作首次系统地研究了最先进的 SSM 与用于远程序列建模的 SNN 的交叉点。结果表明，基于 SSM 的 SNN 在成熟的远程序列建模基准的所有任务上都可以优于 Transformer。研究还表明，基于 SSM 的 SNN 在顺序图像分类上可以使用更少的参数优于当前最先进的 SNN。最后，引入了一种新颖的特征混合层，提高了 SNN 的准确性，同时挑战了有关二元激活在 SNN 中的作用的假设。这项工作为将强大的基于 SSM 的架构（例如大型语言模型）部署到神经形态硬件以实现节能的远程序列建模铺平了道路。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1945g0p/learning_long_sequences_in_spiking_neural_networks/</guid>
      <pubDate>Thu, 11 Jan 2024 16:17:26 GMT</pubDate>
    </item>
    <item>
      <title>我们是否可以说 Siamese 网络使用的 GPU RAM 是基准模型的两倍？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/19342b2/can_we_say_that_the_siamese_network_uses_twice_as/</link>
      <description><![CDATA[如标题所示，可以吗？   由   提交 /u/JohnTheWeak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/19342b2/can_we_say_that_the_siamese_network_uses_twice_as/</guid>
      <pubDate>Wed, 10 Jan 2024 09:04:50 GMT</pubDate>
    </item>
    <item>
      <title>MoE-Mamba：专家混合的高效选择性状态空间模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.04081 代码：https ://github.com/llm-random/llm-random 摘要：  状态空间模型（SSM）已成为顺序建模领域的有力竞争者，挑战 Transformers 的统治地位。与此同时，Mixture of Experts (MoE) 显着改进了基于 Transformer 的法学硕士，包括最近最先进的开源模型。我们建议，为了释放 SSM 的扩展潜力，它们应该与 MoE 结合起来。我们在 Mamba 上展示了这一点，这是一个最近基于 SSM 的模型，它实现了类似 Transformer 的卓越性能。我们的模型 MoE-Mamba 的性能优于 Mamba 和 Transformer-MoE。特别是，MoE-Mamba 以减少 2.2 倍的训练步骤达到与 Mamba 相同的性能，同时保留了 Mamba 针对 Transformer 的推理性能增益。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</guid>
      <pubDate>Wed, 10 Jan 2024 04:00:49 GMT</pubDate>
    </item>
    <item>
      <title>完全自动化的 GPT 博客案例研究</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1926v40/completely_automated_gpt_blog_case_study/</link>
      <description><![CDATA[ 由   提交 /u/PikeMerry   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1926v40/completely_automated_gpt_blog_case_study/</guid>
      <pubDate>Tue, 09 Jan 2024 05:13:17 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 网络的帮助/建议</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/191izew/helpadvice_with_lstmnetworks/</link>
      <description><![CDATA[       ​ https://preview.redd.it/8ekj0m6u97bc1.png?width=2596&amp;format=png&amp;auto=webp&amp;s=f69367e2579fcdd4b9720660fa4d56d8 3255dd91 我是rnn lstm 中的新功能。我用这是基本的 lstm 模型来解释我的问题。 ​ https://preview.redd.it/hbhef6kv97bc1.png?width=931&amp;format=png&amp;auto=webp&amp;s=b532db72a9abad77202de4ecc7 fe4ad2b33f3233&lt; /p&gt; 如何实现这样的 lstm 模型。我想按顺序将预编码和固定代码发送到 lstm 模型中，并预测它的错误错误或重构名称。 ​ ​ &lt; /div&gt;  由   提交 /u/Surprise_Nearby   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/191izew/helpadvice_with_lstmnetworks/</guid>
      <pubDate>Mon, 08 Jan 2024 11:18:12 GMT</pubDate>
    </item>
    <item>
      <title>自动驾驶汽车中的计算机视觉</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriving_cars/</link>
      <description><![CDATA[        由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriven_cars/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/191h0s0/computer_vision_in_selfdriving_cars/</guid>
      <pubDate>Mon, 08 Jan 2024 09:06:38 GMT</pubDate>
    </item>
    <item>
      <title>从头开始的 NEAT 算法（很难）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190x2nu/neat_algorithm_from_scratch_it_was_hard/</link>
      <description><![CDATA[   /u/keghn   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190x2nu/neat_algorithm_from_scratch_it_was_hard/</guid>
      <pubDate>Sun, 07 Jan 2024 17:19:38 GMT</pubDate>
    </item>
    <item>
      <title>NIST 确定了操纵人工智能系统行为的网络攻击类型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190kncb/nist_identifies_types_of_cyberattacks_that/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190kncb/nist_identifies_types_of_cyberattacks_that/</guid>
      <pubDate>Sun, 07 Jan 2024 05:23:10 GMT</pubDate>
    </item>
    <item>
      <title>2023 年十篇值得关注的人工智能研究论文</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/190gozu/ten_noteworthy_ai_research_papers_of_2023/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/190gozu/ten_noteworthy_ai_research_papers_of_2023/</guid>
      <pubDate>Sun, 07 Jan 2024 01:59:09 GMT</pubDate>
    </item>
    <item>
      <title>我用 Python 创建了一个神经网络，可以在虚幻引擎中按程序生成这些关卡。最终图像是我创建的，并提供给神经网络进行学习:]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18z1fob/i_created_a_neural_network_in_python_that/</link>
      <description><![CDATA[       由   提交/u/atomiclollypop  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18z1fob/i_created_a_neural_network_in_python_that/</guid>
      <pubDate>Fri, 05 Jan 2024 07:48:48 GMT</pubDate>
    </item>
    <item>
      <title>2024 年 Neuro Symbolic 频道值得关注的 5 件事</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18yg3xz/5_things_to_watch_for_in_2024_on_the_neuro/</link>
      <description><![CDATA[   /u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18yg3xz/5_things_to_watch_for_in_2024_on_the_neuro/</guid>
      <pubDate>Thu, 04 Jan 2024 15:44:04 GMT</pubDate>
    </item>
    <item>
      <title>随机变压器：通过揭开变压器背后的所有数学原理来了解变压器的工作原理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/18y28q4/the_random_transformer_understand_how/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/18y28q4/the_random_transformer_understand_how/</guid>
      <pubDate>Thu, 04 Jan 2024 02:50:59 GMT</pubDate>
    </item>
    </channel>
</rss>