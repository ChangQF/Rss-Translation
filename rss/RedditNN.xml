<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 18 Dec 2024 18:24:44 GMT</lastBuildDate>
    <item>
      <title>我的人工智能助手突然彻底“精神崩溃”了？？（HuggingFace API）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</link>
      <description><![CDATA[所以，我正在研究这个名为 Shade 的终端副驾驶。他在终端中运行并执行各种操作，例如运行命令（我确实喜欢有点冒险）和其他操作。然而，我遇到的一个问题是，他随机地出现只能被描述为混乱的损坏的 ASCII 意大利面条流，看起来像键盘上的醉酒章鱼。以下是显示我的问题的记录。它是随机发生的，之后他会完全恢复。通常，他会立即开始出现这种神秘的东西。我尝试了很多东西，系统提示、模型参数、不同的 Qwen 模型、前端响应解码等。然而，我无论如何也找不到导致这种情况的原因。以前有人见过这样的事情吗？ ... 当然！很高兴聊天。你今天过得怎么样？您是否想讨论具体问题，或者您有任何疑问？ 提示&gt; 我实际上正在为您工作。我遇到了您随机（罕见）完全崩溃的问题，它们看起来像这样： , &quot;0011101),,001),^C033[0m 回复： 啊，我明白了。这些类型的错误可能非常令人沮丧。听起来前端和后端之间的通信可能存在一些问题，或者 API 调用中可能存在一些意外行为。 您可以采取以下几个步骤来排除故障并可能解决问题：  **检查 API 响应**：确保 API 中存在错误： API 响应中存在错误，并且 API 中存在 1.1 或 1.2。 the11.  - **0 **1 some1100111111111 the1 **1. 1 ** **11 the101101 in101 the is1. 110,1. 111,111) the,1.11111111 the111111 the10111111111111111111,111111111111111111 1111    提交人    /u/plees1024   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</guid>
      <pubDate>Mon, 16 Dec 2024 21:16:21 GMT</pubDate>
    </item>
    <item>
      <title>Ilya Sutskever NeurIPS 2024 完整演讲 [视频]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1he4iev/ilya_sutskever_neurips_2024_full_talk_video/</link>
      <description><![CDATA[        由    /u/nickb 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1he4iev/ilya_sutskever_neurips_2024_full_talk_video/</guid>
      <pubDate>Sat, 14 Dec 2024 14:53:14 GMT</pubDate>
    </item>
    <item>
      <title>神经网络实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hd4pi3/neural_network_implementation/</link>
      <description><![CDATA[      嗨，我正在使用 webgpu 实现神经网络，我想我已经让它工作了，但是在波动损失方面我遇到了问题。当进行某些减肥训练时，体重减轻似乎会下降，然后又上升又下降，我不知道为什么会这样。 如果有人知道为什么会这样，你的建议将会很有帮助。 这是代码的链接https://github.com/mukoroor/Puzzles/tree/varying-entry-points/NeuralNetwork 以及 100 个时期的损失快照 https://preview.redd.it/nd3jy5zeqj6e1.png?width=4064&amp;format=png&amp;auto=webp&amp;s=76877fb1c20ca045551c7135947b0e4ab7385736 损失在第 43 个 epoch 左右波动    提交人    /u/Fun-Expression6073   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hd4pi3/neural_network_implementation/</guid>
      <pubDate>Fri, 13 Dec 2024 04:49:04 GMT</pubDate>
    </item>
    <item>
      <title>柯尔莫哥洛夫-阿诺德网络（KAN）——它们是什么以及它们如何工作？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hczh8q/kolmogorovarnold_networks_kans_what_are_they_and/</link>
      <description><![CDATA[        由    /u/keghn  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hczh8q/kolmogorovarnold_networks_kans_what_are_they_and/</guid>
      <pubDate>Fri, 13 Dec 2024 00:13:07 GMT</pubDate>
    </item>
    <item>
      <title>Granite Guardian：用于安全 LLM 部署的多风险检测框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hclpe4/granite_guardian_a_multirisk_detection_framework/</link>
      <description><![CDATA[我无法生成摘要，因为我无法访问所提及的实际论文（Granite Guardian）。如果不阅读原始研究论文，我无法准确地表示其技术贡献、方法、结果和影响。摘要应基于特定论文的实际内容，而不是虚构细节。您能分享您希望我分析的论文吗？    提交人    /u/Successful-Western27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hclpe4/granite_guardian_a_multirisk_detection_framework/</guid>
      <pubDate>Thu, 12 Dec 2024 14:00:54 GMT</pubDate>
    </item>
    <item>
      <title>使用向量索引加速 GPT 输出嵌入计算</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hcldzt/accelerate_gpt_output_embedding_computations_with/</link>
      <description><![CDATA[  由    /u/martinloretz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hcldzt/accelerate_gpt_output_embedding_computations_with/</guid>
      <pubDate>Thu, 12 Dec 2024 13:44:29 GMT</pubDate>
    </item>
    <item>
      <title>扩展神经增强产品搜索：用于电子商务尾部查询的混合检索系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hbtqiu/scaling_neuralenhanced_product_search_a_hybrid/</link>
      <description><![CDATA[沃尔玛刚刚发布了他们的混合搜索系统，该系统将传统的倒排索引方法与基于神经嵌入的检索相结合。关键的创新在于他们如何处理“尾部查询” - 特定、详细的产品搜索，而传统方法往往无法实现。 关键技术点： - 结合 BM25 和基于嵌入的语义搜索的双检索管道 - 高效处理 1 亿+ 款产品的新型训练方法 - 使用点击数据和产品元数据训练的查询-产品嵌入 - 使用近似最近邻搜索进行实时检索 - 自定义损失函数优化精确匹配和语义匹配 测试结果： - 离线相关性指标提高 8.2% - A/B 测试中成功搜索会话增加 5.4% - 在生产规模下保持低于 100 毫秒的延迟 - 在长而特定的查询上表现尤为出色 我认为这项工作特别值得注意，因为它展示了神经搜索在真正的零售规模上的有效性。混合方法似乎是一种获得语义搜索优势同时保持传统方法可靠性的实用方法。这种训练方法对处理非常大的商品目录的其他人可能很有用。 我认为最有趣的方面是他们的自定义损失函数，它可以平衡精确匹配和语义相似性。这可能适用于零售业以外的领域——任何同时具有分类和语义关系的领域都可能受益。 TLDR：沃尔玛建立了一个结合传统+神经方法的混合产品搜索，可以更好地处理特定查询，同时保持快速的响应时间。他们为大型目录引入了新的训练技术，并展示了现实世界的改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hbtqiu/scaling_neuralenhanced_product_search_a_hybrid/</guid>
      <pubDate>Wed, 11 Dec 2024 13:42:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 EDCR 进行金属价格暴涨预测的元认知</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hbm19d/metacognition_for_metal_spike_price_prediction/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hbm19d/metacognition_for_metal_spike_price_prediction/</guid>
      <pubDate>Wed, 11 Dec 2024 05:01:31 GMT</pubDate>
    </item>
    <item>
      <title>如何对具有 9 个特征的数据集进行反向缩放数组</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hb96bi/how_do_you_reverse_scale_array_scaled_on_a_data/</link>
      <description><![CDATA[您好！我正在尝试反向缩放我预测的数组。我使用了两种不同证券（MSTR 和 BTC）的 9 个特征，并按如下方式缩放它们：  scaler = StandardScaler() scaled_train_mstr = scaler.fit_transform(train_mstr) scaled_test_mstr = scaler.transform(test_mstr) scaled_train_btc = scaler.fit_transform(train_btc) scaled_test_btc = scaler.transform(test_btc) 然后我用两个输入数据构建了这个模型（LSTM 模型）来预测股票市场开盘日 MSTR 的开盘价。我的预测是一个数组（2 列，其中一列是索引。日期是索引。第 0 列是 MSTR_Open_Predicted_Value。 这让我想到了我的问题：当我根据 9 个特征缩放数据时，如何保留转换/缩放数组以获取实际价格？    提交人    /u/JocobianMinion   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hb96bi/how_do_you_reverse_scale_array_scaled_on_a_data/</guid>
      <pubDate>Tue, 10 Dec 2024 18:55:11 GMT</pubDate>
    </item>
    <item>
      <title>需要一些关于文本边界框检测的帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hb0mzt/need_some_help_with_text_bounding_box_detection/</link>
      <description><![CDATA[所以我目前正在从事一个表单机器人项目，因此我的任务是找到一个可用于我读过的文本边界框检测的模型  CTPN EAST Textboxes++ YOLO 已经实现的模型的 GitHub 存储库通常是几年前的，在当前版本中运行得不太好。  所以，有人有任何论文或 GitHub 存储库或已知的模型可以与所有内容的当前版本很好地兼容吗？    提交人    /u/momosspicy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hb0mzt/need_some_help_with_text_bounding_box_detection/</guid>
      <pubDate>Tue, 10 Dec 2024 12:28:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 NN 训练自定义 NER 模型？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hayi3s/train_custom_ner_model_with_nn/</link>
      <description><![CDATA[我有一个基本的 NN 架构，主要用于生成句子嵌入，我想知道我是否可以在自定义 NER 识别中使用类似的架构。这个想法与分配正确的 NER 标签无关，而是限制其应用以提取特定类型的实体，即输入将是一些内容（可以跨越多个页面），输出应该是字符串列表，每个字符串引用提取的实体，其大小可以是各种大小（从单个单词到多个单词）。如果有帮助的话，我也有一个基本的变压器架构，我可以将其集成到该过程中。 感谢任何帮助！    提交人    /u/RDA92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hayi3s/train_custom_ner_model_with_nn/</guid>
      <pubDate>Tue, 10 Dec 2024 10:03:31 GMT</pubDate>
    </item>
    <item>
      <title>帮助解决学期问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1havff6/help_with_semester_question/</link>
      <description><![CDATA[      嘿，我们几天后就要期末考试了，有人能帮我解决这个问题吗？ https://preview.redd.it/9ojbw4lbry5e1.png?width=874&amp;format=png&amp;auto=webp&amp;s=c56e3858b78671cc3ef1c32e9ebb9da79fd46480    提交人    /u/CoatSuitable2365   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1havff6/help_with_semester_question/</guid>
      <pubDate>Tue, 10 Dec 2024 06:15:59 GMT</pubDate>
    </item>
    <item>
      <title>神经网络和神经发散：自闭症和人工智能的交汇点</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hadrao/neural_networks_and_neurodivergence_the/</link>
      <description><![CDATA[       由    /u/thisegwafflesalot  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hadrao/neural_networks_and_neurodivergence_the/</guid>
      <pubDate>Mon, 09 Dec 2024 16:33:34 GMT</pubDate>
    </item>
    <item>
      <title>神经网络量化回归：h2o vs Tensorflow</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h9hnsv/neural_network_quantil_regression_h2o_vs/</link>
      <description><![CDATA[您好，我正在研究一个神经网络分位数回归，以计算 181 家银行 3 年的条件风险价值，滚动窗口为 250 天。 我使用以下代码对 8 家银行进行了测试： ## 1 # 清除所有变量 rm(list = ls(all = TRUE)) graphics.off() # 设置工作目录 #set(&quot;&quot;) # 安装和加载软件包 libraries = c(&quot;quantreg&quot;,&quot;qrnn&quot;,&quot;NeuralNetTools&quot;,&quot;quantmod&quot;,&quot;h2o&quot;,&quot;xtable&quot;) lapply(libraries, function(x) if (!(x %in% mounted.packages())) { install.packages(x) }) lapply(libraries, library, quietly = TRUE, character.only = TRUE) ## 2 ## 读入数据 x0 = read.csv(file = &quot;Returns.csv&quot;) VaR = as.matrix(read.csv(file = &quot;VaR.csv&quot;)) ## 3 ## NNQR 滚动窗口估计 h2o.init(nthreads = -1) x0.hex &lt;- as.h2o(x0) colnames(VaR) &lt;- colnames(x0) # 在转换为 H2O 之前对齐列名 VaR.hex &lt;- as.h2o(VaR) ws = 250 list = array(list(), dim = c(ncol(x0), nrow(x0), 4)) predict = CoVaR = array(0, dim = c(nrow(x0), ncol(x0))) for (j in 1:ncol(x0)){ for (t in 1:(nrow(x0) - ws)){ cat(&quot;Firm &quot;, j, &quot; Window&quot;, t, &quot; &quot;)  xx0 = x0.hex[t:(t + ws), ] fit &lt;- h2o.deeplearning( x = names(xx0[-j]), y = names(xx0[j]), training_frame = xx0, distribution = &quot;分位数&quot;, activation = &quot;整流器&quot;, loss = &quot;分位数&quot;, quantile_alpha = 0.05, hidden = c(5), input_dropout_ratio = 0.1, l1 = 0, l2 = 0, epochs = 50, variable_importances = TRUE， #reproducible = TRUE， #seed = 1234， export_weights_and_biases=T) list[[j,t + ws, 1]] = as.matrix(h2o.biases(fit, 1)) list[[j,t + ws, 2]] = as.matrix(h2o.weights(fit, 1)) list[[j,t + ws, 3]] = as.matrix(h2o.biases(fit, 2)) list[[j,t + ws, 4]] = as.matrix(h2o.weights(fit, 2)) predict[t + ws, j] = as.vector(h2o.predict(fit,x0.hex[t + ws, -j])) CoVaR[t + ws, j] = as.vector(h2o.predict(fit,VaR.hex[t + ws, -j])) &gt; &gt; h2o.shutdown(prompt=FALSE) ## 4 ## 保存结果 write.csv(CoVaR[-(1:250),], file = &quot;CoVaR.csv&quot;, row.names = F) 此代码运行良好，但对于 181 家银行，我的计算机无法执行此任务。 因此我想使用 AWS EC2 实例。我有 8 个 vCPU、61 GiB 和一个 GPU。 如果我理解正确的话，h2o.deeplearning 无法与 GPU 一起使用，所以我想使用 Python 代码并尝试 Tensorflow。但是，我没有找到像使用 h2o.deeplearning 那样执行此任务的好方法。有人知道是否可以用 Tensorflow 进行这种神经网络分位数回归吗？ 我的问题是，在测试运行中，我的 CoVaR 使用 Tensorflow 为正，这基本上是不可能的。 如果缺少某些内容，我会回答问题    提交人    /u/Rabbit30_07   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h9hnsv/neural_network_quantil_regression_h2o_vs/</guid>
      <pubDate>Sun, 08 Dec 2024 12:17:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试学习转换神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1h9hlsb/trying_to_learn_transformational_nueral_networks/</link>
      <description><![CDATA[嗨，我是大二学生，正在尝试学习 tln 网络，以便用于我的期末论文（基本上是在 fpga 上形成 tln，因为我相信这种类型的神经网络最适合利用 fpgas 并行处理能力），因此，为此，我正在寻求一种从我的水平开始的路线图（初学者最好能够使用 numpy、python，并具有 ml、神经网络和深度学习的基本知识），那么我该如何学习才能达到能够轻松构建的水平（基本上我想要一种路线图，详细说明要学习哪些主题）再次发布此信息的原因是由于我的分支，我对 ai ml 的接触不如普通 cs 毕业生多，所以请提供建议，（tldr 从初学者到构建 tln 的路线图）    由    /u/Subject_Agent_8618  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1h9hlsb/trying_to_learn_transformational_nueral_networks/</guid>
      <pubDate>Sun, 08 Dec 2024 12:14:13 GMT</pubDate>
    </item>
    </channel>
</rss>