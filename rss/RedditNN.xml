<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Wed, 10 Apr 2024 09:15:37 GMT</lastBuildDate>
    <item>
      <title>使用 NEAT 算法训练 ANN 来扮演策划者的角色</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bz8pdo/training_an_ann_using_the_neat_algorithm_to_play/</link>
      <description><![CDATA[几天前我发布了一些相关内容，并放弃了该方法，转而使用 NEAT 算法。我相信它显示了学习的能力，但目前它从随机猜测变成了在所有 8 次尝试中一遍又一遍地进行相同的猜测，直到该物种陷入停滞状态并在灭绝时重置。 我使用的是 Pycharm，唯一需要包含的包是 clean-python，代码已上传到此处。 非常感谢任何帮助。   由   提交 /u/xXXx_underscore_xXXx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bz8pdo/training_an_ann_using_the_neat_algorithm_to_play/</guid>
      <pubDate>Mon, 08 Apr 2024 20:38:16 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 分类器中通道不匹配的运行时错误</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bylq14/runtimeerror_with_channel_mismatch_in_pytorch/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bylq14/runtimeerror_with_channel_mismatch_in_pytorch/</guid>
      <pubDate>Mon, 08 Apr 2024 01:44:20 GMT</pubDate>
    </item>
    <item>
      <title>您可以通过在每次运行时简单地对其进行评级来训练神经网络吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1byk6c5/can_you_train_a_neural_network_by_simply_giving/</link>
      <description><![CDATA[我目前正在尝试为我正在创建的游戏训练机器人。这是一款 2D 游戏，具有由各种形状组成的复杂地图。机器人和角色发射能够弹跳的子弹。由于我是一个卑微的人，我自己无法计算出正确的轨迹并计算与神经网络输出相比的成本。但是，我可以对神经网络启动时的表现进行评分。我可以通过简单地给它一个评级来训练它吗？如果可以，怎么做？   由   提交/u/angrily_pessimistic  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1byk6c5/can_you_train_a_neural_network_by_simply_giving/</guid>
      <pubDate>Mon, 08 Apr 2024 00:30:53 GMT</pubDate>
    </item>
    <item>
      <title>击败 AlphaGo 的“循环”技术能否对抗 AlphaZero？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bycyq5/would_the_loop_technique_that_beat_alphago_work/</link>
      <description><![CDATA[去年，Stuart Russell 的团队制定了击败 AlphaGo 的策略。一位顶级业余选手使用“循环”赢得比赛。人类很容易发现并消灭这种策略。因为这种策略大概没有出现在 AlphaGo 训练集中的许多人类对弈中，所以 AlphaGo 未能识别它并输了。 https://www.ft.com/content/175e5314-a7f7-4741-a786-273219f433a1&lt; /a&gt; 我的问题：由于 AlphaZero 没有接受过人类玩游戏的训练，而是通过自我对弈学习的，所以它不应该容易受到这种“黑客攻击”的影响。真的？    由   提交 /u/ok_gid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bycyq5/would_the_loop_technique_that_beat_alphago_work/</guid>
      <pubDate>Sun, 07 Apr 2024 19:29:52 GMT</pubDate>
    </item>
    <item>
      <title>尝试制作一个能够学习扮演主谋角色的人工智能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bxd0i8/trying_to_make_an_ai_that_learns_to_play/</link>
      <description><![CDATA[嘿，我是制作神经网络的新手，我想制作一个学习玩游戏的 mastermind，认为这是一个好地方开始。我已经制作了一个可以破解代码的机器人，但我想制作一个可以学习的人工智能。我已经让它运行了，但从我所看到的情况看，它并没有变得更好，我做了另一个文件使用数字 0-2 将组合降低到 2 位，以给它一个更小的环境，但它似乎仍然无法学习（我让它经历了 70000 集，但仍然一无所获）。我想知道是否有人可以帮助这个项目。  这里是我的代码。    由   提交 /u/xXXx_underscore_xXXx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bxd0i8/trying_to_make_an_ai_that_learns_to_play/</guid>
      <pubDate>Sat, 06 Apr 2024 14:33:58 GMT</pubDate>
    </item>
    <item>
      <title>滑动窗口注意力解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvtqnv/sliding_window_attention_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvtqnv/sliding_window_attention_explained/</guid>
      <pubDate>Thu, 04 Apr 2024 17:52:12 GMT</pubDate>
    </item>
    <item>
      <title>简化的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvnilo/neural_networks_simplified/</link>
      <description><![CDATA[大家好！我已经阅读了很多有关 ANN 工作原理的文章，但我确实有几个问题。假设我们希望程序识别猫的图片。 我们有： 输入节点 - 数千种不同情况、姿势、颜色和不同特征的猫图片。它可以识别这些图片中每个像素的颜色和亮度值，并识别猫图片中常见的图案。 （我们的大脑通过不止一次地生活和看到某些事物来下意识地做到这一点） 权重 - 每个输入都被赋予一个值，该值决定其强度，因此“权重”可以被定义为“权重”。进行以下计算时它携带的。因此，像素的位置和颜色在确定特征时具有或多或少的权重。 （这可能类似于我们将某些特征放在一起来帮助我们识别某些东西。可伸缩的爪子 - 食肉动物的牙齿，它喵喵叫 - 它有四条腿） |训练如何进行？ 隐藏层 - 通过数学计算处理数据。给定这些输入，爪子 + 猫的声音 + 牙齿 + 四足动物 =  输出 - 猫  程序是否在隐藏层中从其他经过训练的模型中挑选来识别特征？爪子、牙齿和动物声音的模型。  我可能还有更多问题，但如果没有之前问题的答案，我就无法提出这些问题：D    由   提交 /u/Suitable-Cream-3200   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvnilo/neural_networks_simplified/</guid>
      <pubDate>Thu, 04 Apr 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>神经A星</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvl306/neural_a_star/</link>
      <description><![CDATA[我正在研究神经网络，以完成关于神经星算法的论文，并阅读论文（https://arxiv.org/pdf/2009.07476）其中解释了如何选择节点，它说用于获取节点索引（作为一个热矩阵）的函数用作反向传播中的缩进函数。但这是什么意思？   由   提交/u/JuriPH  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvl306/neural_a_star/</guid>
      <pubDate>Thu, 04 Apr 2024 11:47:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络验证：采访泰勒·约翰逊、范德比尔……</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvdst3/neural_network_verification_an_interview_with/</link>
      <description><![CDATA[   /u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvdst3/neural_network_verification_an_interview_with/</guid>
      <pubDate>Thu, 04 Apr 2024 04:02:27 GMT</pubDate>
    </item>
    <item>
      <title>使用深度度量学习为食谱数据集创建嵌入模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/</link>
      <description><![CDATA[大家好，我想为我自己的食谱数据集创建一个嵌入模型。目标是创建一个神经网络，将每个食谱（由其成分列表、食谱标签列表及其标题表示）作为输入。  网络应该使用深度度量学习来创建一个嵌入模型，以能够很好地区分菜谱的方式表示菜谱。我考虑过使用带有三元组损失函数的三元组网络，并在三元组数据集上进行训练。每个三元组将由一个锚点（配方本身）、一个正样本（相似的配方）和一个负样本（非常不同的配方）组成。  目标是最小化锚点和正样本之间的距离，同时最大化锚点和负样本之间的距离。由于我对神经网络和自然语言处理相对较新，因此我非常感谢您对这种方法的想法和见解。  您认为这种方法适合我的任务吗？我应该注意哪些潜在的陷阱或挑战？此外，如果您能为我提供有关如何成功执行该项目的指南，我将不胜感激。谢谢。    由   提交/u/Pspecial-Pepper494   reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/</guid>
      <pubDate>Wed, 03 Apr 2024 23:42:59 GMT</pubDate>
    </item>
    <item>
      <title>构建 FPS ai，有个问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bu7o2r/building_an_fps_ai_have_a_question/</link>
      <description><![CDATA[我计划构建一个 fps 机器人，它不访问任何游戏内存，但使用图像识别。我知道如何减少射击和识别敌人的部分，但我正在努力想出一个在地图上移动的解决方案。 我不认为 3D 空间处理是一个现实的解决方案，因为那会多慢啊。我当前的想法是使用迷你地图和图像将其与整个地图的数字网格版本相匹配，以获取我的位置的值。  然后，我将学习如何训练我的模型，以根据我在类似位置的真实游戏玩法来预测下一个要面对的方向。我打算采用两种方法之一。其中之一是发送我的原始迷你地图的屏幕截图，其中包含我按下的键、我面向的方向等信息，并将其传递给 CNN。另一个是预处理屏幕截图，将其与网格地图进行匹配，以获得代表网格所在的数值，然后将其加上所有关键和方向信息传递给 RNN。  这样的事情合理可能吗？这是实现这一目标的一种稍微聪明的方法吗？这是我第一个如此规模的项目，也是第一次使用 NN，所以我还有很多不知道的地方。   由   提交/u/Gabe750  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bu7o2r/building_an_fps_ai_have_a_question/</guid>
      <pubDate>Tue, 02 Apr 2024 19:28:12 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络压缩图像</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bu53fn/compressing_images_with_neural_networks/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bu53fn/compressing_images_with_neural_networks/</guid>
      <pubDate>Tue, 02 Apr 2024 17:49:08 GMT</pubDate>
    </item>
    <item>
      <title>“有人能帮我解释一下这个结果吗？我还没能找出问题所在。”</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1btb9iq/could_someone_help_me_explain_this_result_i/</link>
      <description><![CDATA[我正在使用 R 中的 h2o 库训练神经网络。但是，当我对测试集执行预测时，我收到一个具有相同内容的数据帧行。对于每个 ID，我不应该收到基于其他变量（所有类别）的 CR 变量的预测吗？  我的输出在图像中 ​ 脚本： Library(h2o)  &gt;库（readxl） 库（插入符号） 库（dplyr） ​ #加载 &gt; 骰子 &lt;- read_excel(&quot;clean_export_dice.xlsx&quot;) set.seed(123) ​  # 训练和测试 df index &lt;- createDataPartition(dice$CR, p=0.8, list=FALSE)treino_dice &lt;- dice[index,]  &gt;test_dice &lt;- dice[-index, ] ​ # 个字符作为 ID test_dice$ID &lt; ;- as.character( data_test$ID) ​ # init H2O h2o.init()  ​ # 数据作为 h2o treino_dice_h2o &lt;- as.h2o(treino_dice) h2o_test_dice &lt;- as.h2o(test_dice)&lt; /p&gt;  ​ # 个响应特征 预测器 &lt;- setdiff(names(dice_treino_h2o), c(&quot;ID&quot;, &quot;CR&quot;) ) 响应 &lt;- &quot;CR&quot; ​ # 转为变量因子 for (column in预测变量）{ treino_h2o_dice[[column]] &lt;- as.factor(h2o_treino_dice[[column]]) h2o_test_dice[[column]] &lt;- as.factor( h2o_test_dice[[列]] ) } ​ h2o_threin_dice[[answer]] &lt;- as.factor(h2o_threin_dice[[answer ]]) h2o_test_dice[[answer]] &lt;- as.factor(h2o_test_dice[[answer]]) ​ # train模型 模型 &lt;- h2o.deeplearning( x = 预测变量， y = 响应， training_frame = dice_treino_h2o,&lt; /p&gt;  激活 = &quot;DoneWithDropout&quot;, 隐藏 = c(10, 10, 10), epochs = 10 )&lt; /p&gt;  ​ #use Predict previsoes &lt;- h2o.predict(model, h2o_test_data) ​  预期 &lt;- as.data.frame(预期) 查看(预期)   由   提交/u/Beneficial-Street546  /u/Beneficial-Street546 reddit.com/r/neuralnetworks/comments/1btb9iq/could_someone_help_me_explain_this_result/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1btb9iq/could_someone_help_me_explain_this_result_i/</guid>
      <pubDate>Mon, 01 Apr 2024 18:20:38 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我理解代码吗</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</link>
      <description><![CDATA[从tensorflow.keras导入tensorflow as tf 从tensorflow.keras.preprocessing.image导入层、模型、优化器导入ImageDataGenerator  class BottleneckBlock(tf.keras.layers.Layer): def init(self, inchannels, out_channels, stride=1): super(BottleneckBlock, self)。init_() self.conv1 = tf.keras.layers.Conv2D(out_channels, kernel_size=1, strides=stride, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers .BatchNormalization() self.relu = tf.keras.layers.ReLU() self.conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=1, padding=&#39;same&#39;, use_bias=False) self .bn2 = tf.keras.layers.BatchNormalization() self.conv3 = tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=1, padding=&#39;same&#39;, use_bias=False) self.bn3 = tf.keras.layers.BatchNormalization() self.downsample = tf.keras.Sequential([ tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=stride, use_bias=False), tf.keras.layers .BatchNormalization() ]) if stride != 1 else None self.stride = stride def call(self, x):identity = x out = self.conv1(x) out = self .bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3 （out）如果 self.downsample 不是 None：identity = self.downsample(x) out += Identity out = self.relu(out) return out  class CNN(models.Model ): def init(self, block,layers, numclasses=10): super(CNN, self).init_() self .in_channels = 64 self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers.BatchNormalization() self .relu = tf.keras.layers.ReLU() self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=&#39;相同&#39;) self.layer1 = self._make_layer(块, 64, 层[0]) self.layer2 = self._make_layer(块, 128, 层[1], 步幅=2) self.layer3 = self._make_layer(块, 256, 层[2], 步幅=2 ） self.layer4 = self._make_layer（块，512，层[3]，步幅= 2） self.avgpool = tf.keras.layers.GlobalAveragePooling2D（） self.fc = tf.keras.layers.Dense（num_classes）&lt; /p&gt; def _make_layer(self, block, out_channels,blocks, stride=1): 层 = []layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * 4 # block.expansion = 4 for _ in range(1,blocks):layers.append(block(self.in_channels,out_channels)) return tf.keras.Sequential(layers) def call(self, x): x = self .conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3 (x) x = self.layer4(x) x = self.avgpool(x) x = self.fc(x) 返回x  def ResNet50(num_classes=10): 返回CNN (BottleneckBlock, [3, 4, 6, 3], num_classes) 数据集和数据生成器 train_datagen = ImageDataGenerator( rescale=1./255,heart_range=0.2, Zoom_range=0.2 , Horizo​​ntal_flip=True) train_generator = train_datagen.flow_from_directory( &#39;/kaggle/input/prostate-cancer&#39;, target_size=(224, 224), batch_size=32, class_mode=&#39;categorical&#39;) 使用示例 model = ResNet50(num_classes=len(train_generator.class_indices)) model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=&#39;categorical_crossentropy&#39;,metrics=[ &#39;准确度&#39;]) model.fit(train_generator, epochs=10) def Predict_image_class(image_path): img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224)) img_array = tf.keras.preprocessing.image.img_to_array(img) img_array = tf.expand_dims(img_array, 0) # 创建批量轴 img_array /= 255. # 标准化predicted_class = model.predict(img_array) return tf.argmax(predicted_class[ 0]).numpy() 使用示例 image_path = &#39;/kaggle/input/predict-img/0001.png&#39; Predicted_class = Predict_image_class(image_path) print(f&quot;Predicted类: {predicted_class}&quot;)   由   提交 /u/Warm-Perspective-390   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</guid>
      <pubDate>Mon, 01 Apr 2024 04:51:51 GMT</pubDate>
    </item>
    <item>
      <title>深度学习项目构想</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</link>
      <description><![CDATA[你好， 我目前正在学习深度学习课程，我必须完成一个期末项目。我们主要介绍了 MLP / CNN / 基本架构和框架，以及一点点 RNN 和 LLM，但我想重点关注一个利用 CNN 的项目。老实说，我没有太多好主意，所以我一直在寻找一些有用或有趣的主题的灵感。我也一直在 Kaggle 上查找数据集。 感谢您的任何意见！谢谢！   由   提交/u/beanbeandoedoe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</guid>
      <pubDate>Mon, 01 Apr 2024 03:35:12 GMT</pubDate>
    </item>
    </channel>
</rss>