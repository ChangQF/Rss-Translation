<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sun, 17 Nov 2024 06:22:59 GMT</lastBuildDate>
    <item>
      <title>无论我怎么尝试，MobileNetV2 的准确率都无法超过 50%</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gso22k/mobilenetv2_not_going_past_50_accuracy_no_matter/</link>
      <description><![CDATA[因此，就上下文而言，我正在尝试创建一个可以根据面部图像识别情绪的 CNN。我正在使用 FER-2013 数据集。最初，我尝试自己构建一个 CNN，但没有达到足够好的准确度，所以我决定使用预先训练的模型 MobileNetV2 。该模型没有过度拟合，但无论我尝试什么来增加模型复杂性，例如数据增强和训练预训练模型的最后几层都没有奏效。我已经对模型进行了 30 次训练，但准确度和验证损失分别稳定在略低于 50% 和 1.3。我还能做些什么来提高模型的准确性？    提交人    /u/Ok-Understanding9822   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gso22k/mobilenetv2_not_going_past_50_accuracy_no_matter/</guid>
      <pubDate>Sat, 16 Nov 2024 14:10:06 GMT</pubDate>
    </item>
    <item>
      <title>您能推荐什么看起来像从基础到高级的人工智能项目列表？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gsidhe/what_can_you_recommend_that_looks_like_a_list_of/</link>
      <description><![CDATA[您能推荐什么看起来像从基础到高级的人工智能项目列表？ 我说的是从基础到高级的逐步变化，以及人工智能和神经网络的所有重要内容。 此外，这应该是符合该想法的最小项目数量。 如果该列表由您创建而不是某些链接，那就更好了。 例如 项目 1 是识别手写数字 项目 2 ......    提交人    /u/imtaevi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gsidhe/what_can_you_recommend_that_looks_like_a_list_of/</guid>
      <pubDate>Sat, 16 Nov 2024 07:42:28 GMT</pubDate>
    </item>
    <item>
      <title>创建了一个神经网络库并托管了一个 bug smash！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gs0rui/created_a_neural_network_library_and_hosting_a/</link>
      <description><![CDATA[大家好！我和我的朋友一直在从头开始开发一个神经网络库，仅使用 NumPy 进行矩阵运算/矢量化。我们正在举办一场有现金奖励的 bug 消除活动，并希望社区能够测试我们的库并为我们找到尽可能多的 bug。该库可在 Pypi 上获得：https://pypi.org/project/ncxlib/ 该库支持：  输入/隐藏/输出层 激活函数：Sigmoid、ReLU、Leaky ReLU、Softmax 和 TanH 优化器：Adam、RMS Prop、SGD、带动量的 SGD 损失函数：二元和分类交叉熵、MSE 大量用于图像和原始表格数据的预处理器  有关 bug smash 和我们的库文档的所有信息可在以下位置找到： https://www.ncxlib.com 谢谢！我们希望收到大量改进反馈。    提交人    /u/cwcoogan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gs0rui/created_a_neural_network_library_and_hosting_a/</guid>
      <pubDate>Fri, 15 Nov 2024 16:50:48 GMT</pubDate>
    </item>
    <item>
      <title>学习深度学习进行学术研究</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gs0lym/learning_deep_learning_for_academic_research/</link>
      <description><![CDATA[嗨，我很快就要开始攻读工程领域的博士学位了，研究工作的一部分将涉及深度学习。我对 Python 很熟悉，过去也学过 C 语言课程。我想听听一些关于如何学习深度学习的工作原理以及如何构建和使用模型进行学术研究的建议。 我想强调的是，我对使用深度学习技能尽快找到工作并不感兴趣。我更感兴趣的是学习它背后的数学原理、神经网络的工作原理、如何优化事物等。 那么首先，开始编写模型的最佳编程语言是什么？我知道，当需要将模型与研究数据拟合时，我可能不会使用自己编写的模型。我很可能使用预先构建的模型。但是，我仍然希望能够自己使用线性代数从头开始构建基本模型，因为我想知道它的内部工作原理。 此外，如何学习深度学习的东西？你能推荐学习资源吗？课程、教科书或视频系列？谢谢。    提交人    /u/miss3star   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gs0lym/learning_deep_learning_for_academic_research/</guid>
      <pubDate>Fri, 15 Nov 2024 16:43:56 GMT</pubDate>
    </item>
    <item>
      <title>DPK：用于大型语言模型开发的可扩展数据准备框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gs0doh/dpk_a_scalable_data_preparation_framework_for/</link>
      <description><![CDATA[数据准备工具包 (DPK) 引入了一个可扩展的开源工具包，用于为大型语言模型准备训练数据。关键的创新在于其模块化架构，可以从本地机器扩展到大型集群，同时保持一致的数据处理能力。 主要技术组件： - 用于创建自定义数据转换的可扩展模块系统 - 用于文本和代码数据处理的内置转换 - 可从单台机器扩展到数千个 CPU 核心的可扩展执行 - 用于链接多个转换的管道架构 - 支持流式和批处理模式 主要结果和功能： - 成功用于为 Granite 模型准备训练数据 - 处理自然语言和代码数据 - 在不同规模的部署中提供一致的结果 - 允许使用最少的样板代码进行自定义模块开发 - 支持与现有数据处理工作流集成 对于 LLM 开发，实际意义重大。传统的数据准备管道通常会遇到规模和一致性问题。 DPK 提供了一种标准化的方法，可以随着项目需求而发展 - 从笔记本电脑上的初始实验到计算集群上的全面训练数据准备。 从理论角度来看，DPK 的架构展示了如何在水平扩展的同时保持确定性数据处理。这对于可重复的 ML 研究和开发尤为重要。 TLDR：开源工具包，可简化和扩展 LLM 开发的数据准备，并在现实世界的模型训练中得到验证。通过可扩展的转换模块支持本地和分布式处理。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gs0doh/dpk_a_scalable_data_preparation_framework_for/</guid>
      <pubDate>Fri, 15 Nov 2024 16:34:09 GMT</pubDate>
    </item>
    <item>
      <title>在训练神经网络时，是否有人尝试过从简单数据开始，然后逐渐增加复杂性，而不是一次性将整个数据集投入其中？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1grxq4a/when_training_a_neural_network_has_anyone_tried/</link>
      <description><![CDATA[只是好奇。如果已经这样做了，我还没有听说过，但直觉上它似乎可以帮助它更快地学习概念，因为它类似于人类的学习方式。    提交人    /u/Envy_AI   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1grxq4a/when_training_a_neural_network_has_anyone_tried/</guid>
      <pubDate>Fri, 15 Nov 2024 14:36:17 GMT</pubDate>
    </item>
    <item>
      <title>定制神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1grus22/custom_neural_network/</link>
      <description><![CDATA[Tensorflow 或 PyTorch 可用于创建自定义神经网络吗？例如，我想创建一个具有 n 个隐藏层的神经网络，或者我想以特定方式重新排列神经元。    提交人    /u/MarvelousMartel   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1grus22/custom_neural_network/</guid>
      <pubDate>Fri, 15 Nov 2024 12:00:39 GMT</pubDate>
    </item>
    <item>
      <title>SWE-agent：优化代理-计算机接口以实现自动化软件工程任务</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1grkc2e/sweagent_optimizing_agentcomputer_interfaces_for/</link>
      <description><![CDATA[我一直在阅读 SWE-agent 论文，其中介绍了一种自定义代理-计算机接口 (ACI)，使语言模型能够自主执行软件工程任务。关键创新在于如何构建 LM 和计算机环境之间的接口，以实现更有效的代码操作和测试。 主要技术要点： - 构建自定义 ACI，为代码编辑、文件导航和执行提供结构化的交互模式 - 使用语言模型在 ACI 框架内生成响应 - 在 SWE-bench 上进行评估，成功率达到 12.5%，而之前使用 RAG 的成功率为 3.8% - 界面允许通过执行反馈进行迭代开发 - 结合文件系统导航和多文件编辑功能 主要结果： - 与之前的方法相比，SWE-bench 基准测试提高了 3 倍以上 - 代理可以成功导航代码库、修改多个文件并验证更改 - 性能因任务复杂性和代码库大小而有很大差异 - 界面设计选择强烈影响代理功能和成功率 这对于实际的自动化软件工程具有重要意义。结果表明，精心设计的 LM 和计算机环境之间的接口可以显著提高它们完成实际编程任务的能力。这指向了构建功能更强大的自动化编程系统的潜在方法，尽管在扩展到更复杂的任务方面仍然存在重大挑战。 TLDR：本文介绍了一种代理-计算机接口，可帮助语言模型更好地与编程环境交互，通过结构化的交互模式在软件工程基准测试任务上显示出 3 倍的改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1grkc2e/sweagent_optimizing_agentcomputer_interfaces_for/</guid>
      <pubDate>Fri, 15 Nov 2024 00:58:43 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型是进化算法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gr7rjt/diffusion_models_are_evolutionary_algorithms/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gr7rjt/diffusion_models_are_evolutionary_algorithms/</guid>
      <pubDate>Thu, 14 Nov 2024 15:47:57 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的单一关键参数：检测及其对模型性能的影响</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gr6uc7/single_critical_parameters_in_large_language/</link>
      <description><![CDATA[我一直在阅读这篇关于大型语言模型中的“超权重”的论文 - 参数的数量级明显大于典型分布。研究人员分析了这些异常权重在几种流行的 LLM 架构中的存在及其影响。 关键技术贡献是对 LLM 中权重分布的系统分析，并提出了在训练和部署期间识别/处理超权重的方法。他们引入了量化“超权重现象”的指标以及在模型优化过程中管理这些异常值的技术。 主要发现： - 超级权重通常出现在不同的 LLM 架构中，通常比中值权重大 2-3 个数量级 - 尽管这些异常值占权重的 &lt;1%，但它们可以占总参数幅度的 10-30% - 标准量化方法在超级权重上表现不佳，导致准确性显着下降 - 提出的专门处理方法可以在保留超级权重信息的同时改善模型压缩 对于模型优化和部署具有重要的实际意义： - 当前的压缩技术可能会因错误处理超级权重而无意中降低模型性能 - 需要更复杂的量化方案来考虑整个权重范围 - 训练程序可能会进行修改以鼓励更均衡的权重分布 - 了解超级权重可以带来更高效的模型架构 TLDR：LLM 通常包含“超级权重”，尽管很少见，但具有巨大影响力。论文分析了这种现象，并提出了在模型优化和部署过程中处理这些异常值的更好方法。 完整摘要在此处。论文此处。    提交人    /u/Successful-Western27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gr6uc7/single_critical_parameters_in_large_language/</guid>
      <pubDate>Thu, 14 Nov 2024 15:07:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 RAM 瓶颈问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gqlkfq/how_to_resolve_ram_bottleneck_issues/</link>
      <description><![CDATA[我当前的项目有两层： - 一个转换器，用于在非常专业的训练集上训练词嵌入； - 一个附加神经网络，它将回收这些词嵌入以训练句子相似度。 现在，我正在一台共享电脑上进行训练，其（理论）RAM 容量为 32gb，尽管由于多个用户在服务器上工作，可用 RAM 通常只有其一半，而且随着数据集的增加，这似乎会导致瓶颈。目前，由于内存限制，我无法在 50 万个句子上进行训练。 可以说，我编写代码的方式可能不是超级高效。本质上，我循环遍历样本集，将每个句子编码为初始张量（平均池化词嵌入），并将张量存储在列表中以进行训练。这意味着在训练期间，所有 500k 张量始终位于 RAM 中，我不确定是否有更有效的方法来做到这一点。 或者，我考虑在云中进行训练。实际上，当前的训练集仍然很小，我预计它在未来会显着增加。在这种情况下，机密性和安全性是关键，我想知道哪些平台值得研究？ 感谢任何反馈！    提交人    /u/RDA92   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gqlkfq/how_to_resolve_ram_bottleneck_issues/</guid>
      <pubDate>Wed, 13 Nov 2024 19:42:01 GMT</pubDate>
    </item>
    <item>
      <title>从零开始实现分层图像分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gqj2sr/hierarchical_image_classification_from_scratch/</link>
      <description><![CDATA[      您好，是否可以使用 Keras 等框架实现分层图像分类？是否可以导出这些以进行部署？谢谢。 PS：抱歉我的英语不好。 https://preview.redd.it/5qo7kdl47p0e1.png?width=481&amp;format=png&amp;auto=webp&amp;s=54104e82454a52978d1db9512518a82ac94b8363    提交人    /u/Zealousideal-Sea3892   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gqj2sr/hierarchical_image_classification_from_scratch/</guid>
      <pubDate>Wed, 13 Nov 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>🚀 分析了各种 TTS 模型在不同输入长度（从 5 个单词到 200 个单词）下的延迟！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gp07vz/analyzed_the_latency_of_various_tts_models_across/</link>
      <description><![CDATA[       由    /u/rbgo404  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gp07vz/analyzed_the_latency_of_various_tts_models_across/</guid>
      <pubDate>Mon, 11 Nov 2024 19:06:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么 model_q4.onnx 和 model_q4f16.onnx 不是比 model.onnx 小 4 倍？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</link>
      <description><![CDATA[我在https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/tree/main/onnx:上看到&gt;   文件名 大小    model.onnx 654 MB   model_fp16.onnx 327 MB   model_q4.onnx 200 MB   model_q4f16.onnx 134 MB   我的理解是：  model.onnx 是 fp32 模型， model_fp16.onnx 是权重量化为 fp16 的模型  我不明白 model_q4.onnx 和 model_q4f16.onnx 的大小&gt;  为什么 model_q4.onnx 是 200 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4.onnx 意味着权重被量化为 4 位。 为什么 model_q4f16.onnx 是 134 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4f16.onnx 意味着权重被量化为 4 位并且激活是 fp16，因为 https://llm.mlc.ai/docs/compilation/configure_quantization.html 指出：  qAfB(_id)，其中 A 表示用于存储权重的位数，B 表示用于存储激活的位数。   并且在张量流的神经网络量化框架中，为什么激活需要比权重（8 位）更多的位（16 位）？ 表示激活不计入模型大小（可以理解）。     提交人    /u/Franck_Dernoncourt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gmo750/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</guid>
      <pubDate>Fri, 08 Nov 2024 17:36:44 GMT</pubDate>
    </item>
    <item>
      <title>能“嗅觉”的人工智能？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</link>
      <description><![CDATA[我一直在阅读有关 Osmo 的文章，这是一家初创公司，它使用人工智能通过分析气味的分子结构来预测和重现气味，他们认为这可能会影响从医疗保健到香水等领域。 想到机器以这种精确度“嗅觉”真是令人着迷，但我很好奇——这实际上会如何改变我们体验周围世界的方式？我想我很难看到人工智能驱动的气味技术能够以实际或意想不到的方式影响日常生活或特定行业，所以我想听听不同的观点。    提交人    /u/Frosty_Programmer672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1glqsz5/ai_that_can_smell/</guid>
      <pubDate>Thu, 07 Nov 2024 13:47:00 GMT</pubDate>
    </item>
    </channel>
</rss>