<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 25 Dec 2024 18:21:24 GMT</lastBuildDate>
    <item>
      <title>转换后的训练集数据最终存储于 NN/CNN 的哪里？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlqcae/where_does_the_converted_training_set_data_ends/</link>
      <description><![CDATA[      因此，进行训练，训练结束后，以类似的方式开始探测，数据通过网络运行以获得概率。假设我有 100 张图像要训练我的 CNN 网络。 这里的想法是，这 100 张图像最终会出现在网络中的什么位置，它们会以什么形式存储？......以及在网络内部的什么位置，它们最终会出现在网络中的什么位置。 因此，有 100 张图像，它们的值最终会出现在哪里，我的意思是，网络如何存储这么多图像，必须有一个地方存放它们，它们在反复反向传播后会驻留在整个网络中？ 我很难理解它们（训练集）的存储方式和位置，它们是作为网络中的权重还是神经元值存储的？ 例如，当您探测网络并在图像卷积后进行前向传递时，这些训练集不会被前向传递后分配给神经元的新值覆盖吗？ 所以我的问题是： 训练集是为了帮助您在训练模型后预测您需要什么正在使用单幅图像进行探测，以使其更准确？我如何使用一张图片对分布在网络中哪个位置的训练集进行探测？以及训练集图像值变成什么样。 我理解探测和步骤（从损失函数级别进行前向传递和反向传播）我不理解使用多幅图像作为集合的训练部分，如 - 数据转换为什么，神经元值，权重？ - 这些转换后的数据最终在网络中的什么位置，它存储在哪里（训练集） 没有关于训练集以及它们最终在哪里或转换为什么以及它们在网络中的位置的教程详细信息，我的意思是我还没有设法找到它 编辑：制作了一个图表。 https://preview.redd.it/iwp0m0ojc09e1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a5a0c34c62b8765085a33e8cf2a5079ddf458033 https://preview.redd.it/p3zga7ojc09e1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=55fcb7e73ac3670676adb9771db56ad1e6613a4c .    提交人    /u/No-Earth-374   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlqcae/where_does_the_converted_training_set_data_ends/</guid>
      <pubDate>Wed, 25 Dec 2024 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>分析 DAI 稳定币机制和稳定性的形式逻辑框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlgo0m/formal_logic_framework_for_analyzing_dai/</link>
      <description><![CDATA[本文提出了一个基于形式逻辑的框架，使用 Prolog 分析 DAI 稳定币系统。关键创新是将 DAI 的复杂机制转化为可以模拟和验证其稳定性属性的程序模型。 关键技术方面： - 在 Prolog 的声明式逻辑编程范式中实现 DAI 的核心机制 - 抵押品要求、清算程序和价格反馈的形式化表示 - 模拟市场场景和压力测试稳定性机制的能力 - 用于分析稳定币设计的开源框架 主要结果： - 成功建模了 DAI 的主要稳定机制 - 展示了加密抵押如何与算法方法相结合 - 确定了系统对各种市场条件的响应 - 创建了可重复使用的稳定币分析框架 我认为这项工作为分析其他稳定币设计和 DeFi 协议开辟了重要的可能性。正式框架可以帮助开发人员在部署之前识别潜在的漏洞，并帮助监管机构了解这些系统。 我认为简化的市场行为建模的局限性很大——现实世界的动态比纯逻辑编程所能捕捉到的要复杂得多。然而，这里奠定的基础可以通过更复杂的市场模型进行扩展。 TLDR：研究人员创建了一个基于 Prolog 的形式框架来分析 DAI 的稳定机制，提供了一种系统的方法来理解和验证稳定币设计。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlgo0m/formal_logic_framework_for_analyzing_dai/</guid>
      <pubDate>Tue, 24 Dec 2024 16:11:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么不平衡的数据增强没有明确的定义？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlfe7z/why_is_data_augmentation_for_imbalances_not/</link>
      <description><![CDATA[好的，我们知道我们可以在预处理期间增强数据并保存该数据，生成具有方差的新样本，同时增加样本量并解决类别不平衡问题 我们还知道，使用原始数据集，您可以通过转换管道应用转换，这意味着在应用转换时，您的模型在每个时期都会看到不同版本的图像。但是，如果数据集不平衡，它仍然保持不变，因为模型仍然看到更多的多数类，但是每个样本都会提供方差，从而增加了普遍性。据我们所知，转换管道中的数据增强不会改变数据集大小。 因此，解决不平衡的最佳做法是什么？是否可以通过增强来增加数据集而不是使用转换管道？因为在预处理阶段和训练期间进行增强可能会过度增强你的图像，并可能改变实际问题的定义。 - 一些背景信息我有 3700 张眼底图像，并计划使用一些深度 CNN 架构    提交人    /u/amulli21   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlfe7z/why_is_data_augmentation_for_imbalances_not/</guid>
      <pubDate>Tue, 24 Dec 2024 15:07:30 GMT</pubDate>
    </item>
    <item>
      <title>人工智能解读野性的呼唤</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hl8yms/ai_decodes_the_calls_of_the_wild/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hl8yms/ai_decodes_the_calls_of_the_wild/</guid>
      <pubDate>Tue, 24 Dec 2024 08:02:30 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试学习如何编写一个简单的神经网络，或者至少理解一个</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hkxu2o/im_trying_to_learn_how_to_code_a_simple_neural/</link>
      <description><![CDATA[如果有人知道任何真正有用的网站视频来了解它们，那就太棒了    提交人    /u/a_person_thats_alive   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hkxu2o/im_trying_to_learn_how_to_code_a_simple_neural/</guid>
      <pubDate>Mon, 23 Dec 2024 21:26:01 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的简单介绍</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hij671/a_gentle_introduction_to_graph_neural_networks/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hij671/a_gentle_introduction_to_graph_neural_networks/</guid>
      <pubDate>Fri, 20 Dec 2024 12:54:11 GMT</pubDate>
    </item>
    <item>
      <title>有谁能帮我用这个带图像的神经网络 CNN FC LAYER</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hhry7o/can_anyone_help_me_with_this_cnn_fc_layer_for/</link>
      <description><![CDATA[      我这里有一张图表  https://preview.redd.it/zff75yqvus7e1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=4f7663381adddd07abbca79b6544fd6617a2ca83 那么它是不是像 ANN，有些人说不是，我见过人们只是从输入中添加数字而没有进行权重计算，我真的很困惑。    提交人    /u/No-Earth-374   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hhry7o/can_anyone_help_me_with_this_cnn_fc_layer_for/</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 和 Keras 进行 U-net 医学分割（息肉分割）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hh82eu/unet_medical_segmentation_with_tensorflow_and/</link>
      <description><![CDATA[      https://preview.redd.it/vwimpgpwgn7e1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=35d2e6df6c91ff36e0764b21c3d80f4bd12b6ad4 本教程提供了如何使用 TensorFlow/Keras 实现和训练用于息肉分割的 U-Net 模型的分步指南。 本教程分为四个部分：   🔹 数据预处理和准备 在此部分中，您将加载和预处理息肉数据集，包括调整图像和蒙版的大小、将蒙版转换为二进制格式以及将数据拆分为训练、验证和测试集。 🔹 U-Net 模型架构 此部分使用 Keras 定义 U-Net 模型架构。它包括卷积层的构建块、构建 U-Net 的编码器和解码器部分以及定义最终输出层。 🔹 模型训练 在这里，您将加载预处理的数据并训练 U-Net 模型。您将编译模型、定义训练参数（如学习率和批量大小），并使用回调进行模型检查点、降低学习率和提前停止。训练历史也是可视化的。 🔹 评估和推理最后一部分演示了如何加载训练好的模型，对测试数据进行推理，并可视化预测的分割蒙版。   您可以在博客中找到代码链接：https://eranfeit.net/u-net-medical-segmentation-with-tensorflow-and-keras-polyp-segmentation/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/u-net-medical-segmentation-with-tensorflow-and-keras-polyp-segmentation-ddf66a6279f4 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/YmWHTuefiws&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hh82eu/unet_medical_segmentation_with_tensorflow_and/</guid>
      <pubDate>Wed, 18 Dec 2024 18:26:28 GMT</pubDate>
    </item>
    <item>
      <title>我的人工智能助手突然彻底“精神崩溃”了？？（HuggingFace API）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</link>
      <description><![CDATA[所以，我正在研究这个名为 Shade 的终端副驾驶。他在终端中运行并执行各种操作，例如运行命令（我确实喜欢有点冒险）和其他操作。然而，我遇到的一个问题是，他随机地出现只能被描述为混乱的损坏的 ASCII 意大利面条流，看起来像键盘上的醉酒章鱼。以下是显示我的问题的记录。它是随机发生的，之后他会完全恢复。通常，他会立即开始出现这种神秘的东西。我尝试了很多东西，系统提示、模型参数、不同的 Qwen 模型、前端响应解码等。然而，我无论如何也找不到导致这种情况的原因。以前有人见过这样的事情吗？ ... 当然！很高兴聊天。你今天过得怎么样？您是否想讨论具体问题，或者您有任何疑问？ 提示&gt; 我实际上正在为您工作。我遇到了您随机（罕见）完全崩溃的问题，它们看起来像这样： , &quot;0011101),,001),^C033[0m 回复： 啊，我明白了。这些类型的错误可能非常令人沮丧。听起来前端和后端之间的通信可能存在一些问题，或者 API 调用中可能存在一些意外行为。 您可以采取以下几个步骤来排除故障并可能解决问题：  **检查 API 响应**：确保 API 中存在错误： API 响应中存在错误，并且 API 中存在 1.1 或 1.2。 the11.  - **0 **1 some1100111111111 the1 **1. 1 ** **11 the101101 in101 the is1. 110,1. 111,111) the,1.11111111 the111111 the10111111111111111111,111111111111111111 1111    提交人    /u/plees1024   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</guid>
      <pubDate>Mon, 16 Dec 2024 21:16:21 GMT</pubDate>
    </item>
    <item>
      <title>Ilya Sutskever NeurIPS 2024 完整演讲 [视频]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1he4iev/ilya_sutskever_neurips_2024_full_talk_video/</link>
      <description><![CDATA[        由    /u/nickb 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1he4iev/ilya_sutskever_neurips_2024_full_talk_video/</guid>
      <pubDate>Sat, 14 Dec 2024 14:53:14 GMT</pubDate>
    </item>
    <item>
      <title>神经网络实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hd4pi3/neural_network_implementation/</link>
      <description><![CDATA[      嗨，我正在使用 webgpu 实现神经网络，我想我已经让它工作了，但是在波动损失方面我遇到了问题。当进行某些减肥训练时，体重减轻似乎会下降，然后又上升又下降，我不知道为什么会这样。 如果有人知道为什么会这样，你的建议将会很有帮助。 这是代码的链接https://github.com/mukoroor/Puzzles/tree/varying-entry-points/NeuralNetwork 以及 100 个时期的损失快照 https://preview.redd.it/nd3jy5zeqj6e1.png?width=4064&amp;format=png&amp;auto=webp&amp;s=76877fb1c20ca045551c7135947b0e4ab7385736 损失在第 43 个 epoch 左右波动    提交人    /u/Fun-Expression6073   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hd4pi3/neural_network_implementation/</guid>
      <pubDate>Fri, 13 Dec 2024 04:49:04 GMT</pubDate>
    </item>
    <item>
      <title>柯尔莫哥洛夫-阿诺德网络（KAN）——它们是什么以及它们如何工作？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hczh8q/kolmogorovarnold_networks_kans_what_are_they_and/</link>
      <description><![CDATA[        由    /u/keghn  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hczh8q/kolmogorovarnold_networks_kans_what_are_they_and/</guid>
      <pubDate>Fri, 13 Dec 2024 00:13:07 GMT</pubDate>
    </item>
    <item>
      <title>Granite Guardian：用于安全 LLM 部署的多风险检测框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hclpe4/granite_guardian_a_multirisk_detection_framework/</link>
      <description><![CDATA[我无法生成摘要，因为我无法访问所提及的实际论文（Granite Guardian）。如果不阅读原始研究论文，我无法准确地表示其技术贡献、方法、结果和影响。摘要应基于特定论文的实际内容，而不是虚构细节。您能分享您希望我分析的论文吗？    提交人    /u/Successful-Western27   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hclpe4/granite_guardian_a_multirisk_detection_framework/</guid>
      <pubDate>Thu, 12 Dec 2024 14:00:54 GMT</pubDate>
    </item>
    <item>
      <title>使用向量索引加速 GPT 输出嵌入计算</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hcldzt/accelerate_gpt_output_embedding_computations_with/</link>
      <description><![CDATA[  由    /u/martinloretz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hcldzt/accelerate_gpt_output_embedding_computations_with/</guid>
      <pubDate>Thu, 12 Dec 2024 13:44:29 GMT</pubDate>
    </item>
    <item>
      <title>扩展神经增强产品搜索：用于电子商务尾部查询的混合检索系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hbtqiu/scaling_neuralenhanced_product_search_a_hybrid/</link>
      <description><![CDATA[沃尔玛刚刚发布了他们的混合搜索系统，该系统将传统的倒排索引方法与基于神经嵌入的检索相结合。关键的创新在于他们如何处理“尾部查询” - 特定、详细的产品搜索，而传统方法往往无法实现。 关键技术点： - 结合 BM25 和基于嵌入的语义搜索的双检索管道 - 高效处理 1 亿+ 款产品的新型训练方法 - 使用点击数据和产品元数据训练的查询-产品嵌入 - 使用近似最近邻搜索进行实时检索 - 自定义损失函数优化精确匹配和语义匹配 测试结果： - 离线相关性指标提高 8.2% - A/B 测试中成功搜索会话增加 5.4% - 在生产规模下保持低于 100 毫秒的延迟 - 在长而特定的查询上表现尤为出色 我认为这项工作特别值得注意，因为它展示了神经搜索在真正的零售规模上的有效性。混合方法似乎是一种获得语义搜索优势同时保持传统方法可靠性的实用方法。这种训练方法对处理非常大的商品目录的其他人可能很有用。 我认为最有趣的方面是他们的自定义损失函数，它可以平衡精确匹配和语义相似性。这可能适用于零售业以外的领域——任何同时具有分类和语义关系的领域都可能受益。 TLDR：沃尔玛建立了一个结合传统+神经方法的混合产品搜索，可以更好地处理特定查询，同时保持快速的响应时间。他们为大型目录引入了新的训练技术，并展示了现实世界的改进。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hbtqiu/scaling_neuralenhanced_product_search_a_hybrid/</guid>
      <pubDate>Wed, 11 Dec 2024 13:42:53 GMT</pubDate>
    </item>
    </channel>
</rss>