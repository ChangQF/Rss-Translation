<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 25 Jan 2025 09:16:05 GMT</lastBuildDate>
    <item>
      <title>梦想学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i91h6u/dreaming_learning/</link>
      <description><![CDATA[一种在神经网络中包含新颖性并为时间序列范式转变准备网络的新方法 https://arxiv.org/abs/2410.18156    提交人    /u/neuralessandro   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i91h6u/dreaming_learning/</guid>
      <pubDate>Fri, 24 Jan 2025 17:54:58 GMT</pubDate>
    </item>
    <item>
      <title>通过测试时间回归理解序列模型：神经架构中的联想记忆框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i8ym2u/understanding_sequence_models_through_testtime/</link>
      <description><![CDATA[本文介绍了一种测试时回归框架，该框架以一种新颖的方式进行序列建模 - 它不依赖标准注意力机制，而是在推理过程中执行回归以构建联想记忆连接。 关键技术要点：* 该模型在推理期间而不是仅在训练期间执行动态内存更新 * 使用双线性投影技术在序列元素和记忆状态之间进行映射 * 实现 O(n) 复杂度，同时保持与 O(n²) 注意力模型的竞争性能 * 在长距离依赖任务上显示出强大的效果 * 在序列长度 &gt;1000 个标记上显示出持续的改进 主要实证发现：* 与标准注意力机制相比，速度提高 15-20% * 内存使用量与序列长度成线性比例 * 与完全注意力基线相比，准确率保持 98% * 在需要联想回忆的任务上特别强大 * 适用于多种架构（Transformers、RNN） 我认为这种方法可以为我们在实践中处理长序列的方式带来有意义的改进。线性缩放属性使其特别适用于处理较长的文档或时间序列。虽然内存权衡需要仔细考虑，但在推理过程中建立联想连接的能力为自适应模型开辟了新的可能性。 我怀疑我们会看到这个框架适用于特定领域，如文档 QA 和时间序列预测，其中联想记忆方面可能特别有价值。与现有架构的兼容性使其非常实用。 TLDR：新框架在推理时执行回归以构建联想记忆，实现线性复杂度，同时保持强大的性能。显示出对长序列任务的特殊希望。 完整摘要在这里。论文此处    由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i8ym2u/understanding_sequence_models_through_testtime/</guid>
      <pubDate>Fri, 24 Jan 2025 15:56:39 GMT</pubDate>
    </item>
    <item>
      <title>学习经历</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i8thnh/learning_experience/</link>
      <description><![CDATA[你好。我是一名研究生，大学毕业后过去两年一直在主要从事研究的公司和公共机构工作。不幸的是，我的大部分工作都是用 Tensorflow、Keras 或 PyTorch 构建 NN，并找到最适合我的数据的超参数。所以，大概两年来，我一直在连续几个小时尝试各种不同的超参数（我有点夸张，但你应该明白我的意思，我并没有真正从头开始“构建”一个网络之类的东西）。不幸的是，我一直处于相当孤独的境地，这让我无法从同行那里学到很多东西。在我看来，NN 还有更多的东西，虽然我不是数学奇才，但我还是想开始构建自己的 NN。为此，我需要一些资源来给你“直觉”选择特定的层...等等，而不仅仅是强行进入一个好的 NN。你有什么建议吗？非常感谢。    提交人    /u/Dismal_Appearance275   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i8thnh/learning_experience/</guid>
      <pubDate>Fri, 24 Jan 2025 11:40:59 GMT</pubDate>
    </item>
    <item>
      <title>怀疑数据极不平衡</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i8pmpq/doubt_for_extremely_unbalanced_data/</link>
      <description><![CDATA[最近几天，我一直在尝试在极不平衡的数据集上训练神经网络，但结果并不够好，有 10 个类，其中 4 个或 5 个没有获得好的结果。我可以开始对它们进行分组，但我想尝试至少为少数类别获得不错的结果。 这是数据集 Kaggle 数据集 我所做的预处理如下： - 获取贷款发生时的时间数据 datos_crudos[&#39;loan_age_years&#39;] = (reference_date - datos_crudos[&#39;issue_d&#39;]).dt.days / 365 datos_crudos[&#39;credit_history_years&#39;] = (reference_date - datos_crudos[&#39;earliest_cr_line&#39;]).dt.days / 365 datos_crudos[&#39;days_since_last_payment&#39;] = (reference_date - datos_crudos[&#39;last_pymnt_d&#39;]).dt.days datos_crudos[&#39;days_since_last_credit_pull&#39;] = (reference_date - datos_crudos[&#39;last_credit_pull_d&#39;]).dt.days - 删除包含 40% 或更多 NaN 的列 - 分类和数值数据的插补 categorical_imputer = SimpleImputer(strategy=&#39;constant&#39;, fill_value=&#39;Missing&#39;) numerical_imputer = IterativeImputer(max_iter=10, random_state=42) - 独热编码、标签编码器和序数编码器 也做了这个 -通过随机森林进行特征选择 -过采样和欠采样技术，使用 SMOTE 当前 361097 已全额付款 124722 已注销 27114 逾期（31-120 天） 6955 已发出 5062 宽限期内 3748 逾期（16-30 天） 1357 不符合信用政策。状态：已全额付款 1189 违约 712 不符合信用政策。状态：已扣款 471  undersample_strategy = { &#39;当前&#39;：100000， &#39;已全额付款&#39;：80000  oversample_strategy = { &#39;已扣款&#39;：50000， &#39;默认&#39;：30000， &#39;已签发&#39;：50000， &#39;逾期 (31-120 天)&#39;：30000， &#39;宽限期内&#39;：30000， &#39;逾期 (16-30 天)&#39;： 30000, “不符合信用政策。状态：已全额付款”：30000， “不符合信用政策。状态：已关闭&#39;：30000   - 计算类权重 - 焦点损失函数 - 由于数据不平衡，我正在观看 F1 Macro 这是架构 model = Sequential([ Dense(1024,activation=&quot;relu&quot;,input_dim=X_train.shape[1]), BatchNormalization(), Dropout(0.4), Dense(512,activation=&quot;relu&quot;), BatchNormalization(), Dropout(0.3), Dense(256,activation=&quot;relu&quot;), BatchNormalization(), Dropout(0.3), Dense(128,activation=&quot;relu&quot;), BatchNormalization(), Dropout(0.2), Dense(64,activation=&quot;relu&quot;), BatchNormalization(), Dropout(0.2), Dense(10,activation=&quot;softmax&quot;) # 10 类 ]) 并且报告分类，最大的问题是第 3、6 和 8 类，一些 epoch 获得的这些类的指标非常低 Epoch 7: F1-Score Macro = 0.5840 5547/5547 [================================] - 11s 2ms/step 精度召回率 f1-score 支持 0 1.00 0.93 0.96 9125 1 0.99 0.85 0.92 120560 2 0.94 0.79 0.86 243 3 0.20 0.87 0.33 141 4 0.14 0.88 0.24 389 5 0.99 0.95 0.97 41300 6 0.02 0.00 0.01 1281 7 0.48 1.00 0.65 1695 8 0.02 0.76 0.04 490 9 0.96 0.78 0.86 2252 准确度 0.87 177476 宏平均值 0.58 0.78 0.58 177476 加权平均值 0.98 0.87 0.92 177476  您知道缺少什么才能获得更好的结果吗？    提交人    /u/Unhappy_Passion9866   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i8pmpq/doubt_for_extremely_unbalanced_data/</guid>
      <pubDate>Fri, 24 Jan 2025 06:54:42 GMT</pubDate>
    </item>
    <item>
      <title>医学黑色素瘤检测 | 使用 Unet 的 TensorFlow U-Net 教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i88hfw/medical_melanoma_detection_tensorflow_unet/</link>
      <description><![CDATA[      https://preview.redd.it/o4te29de1see1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=55ee2be35ceab748043a4dcedb3611341cddfed9 本教程提供了有关如何使用 TensorFlow/Keras 实现和训练用于黑色素瘤检测的 U-Net 模型的分步指南。  🔍 您将学到的内容 🔍： 数据准备：我们首先向您展示如何访问和预处理大量黑色素瘤图像和相应蒙版的数据集。  数据增强：探索增强数据集的技术。它将增加并改善模型的结果模型构建：构建 U-Net，并学习如何使用 TensorFlow 和 Keras 构建模型。  模型训练：我们将指导您完成训练过程，优化您的模型以区分黑色素瘤和非黑色素瘤皮肤病变。  测试和评估：在新的新鲜图像上运行预先训练的模型。探索如何生成突出显示图像中黑色素瘤区域的蒙版。  可视化结果：当我们将预测的蒙版与实际的地面真实蒙版进行比较时，实时查看结果。   您可以在博客中找到代码链接：https://eranfeit.net/medical-melanoma-detection-tensorflow-u-net-tutorial-using-unet/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/medical-melanoma-detection-tensorflow-u-net-tutorial-using-unet-c89e926e1339 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/P7DnY0Prb2U&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg 享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i88hfw/medical_melanoma_detection_tensorflow_unet/</guid>
      <pubDate>Thu, 23 Jan 2025 17:17:26 GMT</pubDate>
    </item>
    <item>
      <title>关于项目查询</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</link>
      <description><![CDATA[目前，我正在研究 zenodo 中一个名为“超声图像中胎儿头部生物测量的大规模注释数据集”的数据集。我的数据集包含超声图像和相应的分割蒙版。我叠加了这些图像，现在我想计算头围、双顶径等，并使用这 20 个特征进行相关性分析。但不幸的是，我没有任何领域专家。在这种情况下，如果我以 Q1 期刊为目标，我该做些什么来验证？我的数据集没有任何现有的工作！有人可以帮忙吗？    提交人    /u/Boring_Conclusion_19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</guid>
      <pubDate>Sun, 19 Jan 2025 18:09:43 GMT</pubDate>
    </item>
    <item>
      <title>大规模 AI 红队行动的实践经验和威胁模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</link>
      <description><![CDATA[本文对红队 100 种生成式 AI 产品进行了系统分析，开发了全面的威胁模型分类和测试方法。关键技术贡献是创建了一个通过实际测试识别和分类人工智能系统漏洞的结构化框架。 主要技术要点： - 开发了一个涵盖提示注入、数据提取和系统操作的攻击分类法 - 创建了结合自动和手动探测的标准化测试程序 - 记录不同人工智能架构中的攻击模式和防御机制 - 量化跨系统类型各种攻击媒介的成功率 - 映射常见的漏洞模式和防御效果 关键结果： - 80% 的测试系统显示出至少一种形式的提示注入的漏洞 - 多步骤攻击比单步骤攻击更为成功 - 系统对相同攻击的响应根据提示构造而有很大差异 - 手动测试发现的漏洞比自动化方法多 2.3 倍 - 结合多种攻击媒介时防御效果降低了 35% 我认为这项工作为理解大规模人工智能系统漏洞提供了重要基础。虽然之前已经进行过单独的红队测试，但拥有 100 个系统的数据使我们能够识别在小型研究中无法发现的系统弱点和模式。 我认为该方法可以成为 AI 安全测试的标准框架，尽管 AI 发展的快速步伐意味着特定的攻击媒介需要不断更新。关于手动测试有效性的发现表明我们不能仅仅依赖自动化安全措施。 TLDR：对 100 个 AI 系统的红队测试的分析揭示了常见的漏洞模式并建立了系统安全测试的框架。手动测试优于自动化方法，多向量攻击显示出更高的成功率。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</guid>
      <pubDate>Thu, 16 Jan 2025 14:35:28 GMT</pubDate>
    </item>
    <item>
      <title>通过选择性权重矩阵更新实现动态 LLM 自适应：特定任务的自适应框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</link>
      <description><![CDATA[核心贡献是一种自适应学习机制，允许 Transformer 在推理过程中修改其权重，而无需额外训练。这种“Transformer²”方法引入了一种双重注意系统，可以同时处理内容和元学习模式。 关键技术点：- 在推理过程中使用梯度近似进行动态权重调整- 实现实时参数更新的元学习层- 结合标准和自适应自注意力的双重注意机制- 通过选择性权重更新实现高效的内存管理- 在生成特定于任务的适应性调整的同时保持基本权重 结果显示出显着的改进：- 在复杂推理基准上的性能提高了 15%- 更好地处理边缘情况和新输入- 最小的计算开销（标准 Transformer 的 1.2 倍）- 在不同任务类型中的响应更一致- 提高了长序列任务的性能 我认为这可以有意义地改变我们处理模型适应的方式。与微调或快速工程相比，拥有可以在推理过程中自我修改的模型为适应开辟了一些有趣的可能性。计算效率尤其值得注意——以前对自适应模型的尝试通常有很大的开销。 我还认为双重注意机制可能会影响我们设计未来 Transformer 架构的方式。同时处理内容和元学习模式的能力似乎是一种有价值的架构模式，可以更广泛地应用。 TLDR：新的 Transformer 架构可以使用高效的双重注意机制在推理过程中调整其权重。以最小的计算开销显示出 15% 的更好性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</guid>
      <pubDate>Wed, 15 Jan 2025 13:36:40 GMT</pubDate>
    </item>
    <item>
      <title>热图像分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</link>
      <description><![CDATA[高中时我接到一个小任务 - 制作一个小型神经网络进行图像分类。我用 VGG 和小型数据库（大约 2k 张图像）制作了它。一切都很顺利，直到它（神经网络）开始对测试数据做出奇怪的预测。它说测试数据集中的每一张图片都与类别 0（即人类）相关......现在我被它困住了......如果有人能帮助我，我将不胜感激并提供任何有关我的 NN 的信息    提交人    /u/Apprehensive_Tap_269   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</guid>
      <pubDate>Tue, 14 Jan 2025 18:52:37 GMT</pubDate>
    </item>
    <item>
      <title>SimpleGrad：一个易于理解的类 pytorch 框架实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</link>
      <description><![CDATA[      我构建了一个简单易懂的类似 PyTorch 的框架，旨在作为一种学习工具，帮助理解自动求导和深度学习框架的内部工作原理。我计划将其扩展到 CNN 和 Attention 层。 我在 reddit 上发帖不多，如有任何问题，请多包涵。 – 非常感谢您的反馈和问题！    提交人    /u/T_Hansda   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</guid>
      <pubDate>Mon, 13 Jan 2025 11:10:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么 L1 正则化会产生稀疏权重</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</guid>
      <pubDate>Sun, 12 Jan 2025 09:20:12 GMT</pubDate>
    </item>
    <item>
      <title>U-net 图像分割 | 如何分割图像中的人物</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</link>
      <description><![CDATA[      https://preview.redd.it/cuvm3dtoffce1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=c8e94c412194ba8c05f86c3bb6f675922ba956f8 本教程提供了如何使用 TensorFlow/Keras 实现和训练用于人员分割的 U-Net 模型的分步指南。 本教程分为四个部分：   第 1 部分：数据预处理和准备 在此部分中，您将加载和预处理人员数据集，包括调整图像和蒙版的大小、将蒙版转换为二进制格式以及将数据拆分为训练、验证和测试集。   第 2 部分：U-Net 模型架构 此部分使用 Keras 定义 U-Net 模型架构。它包括卷积层的构建块、构建 U-Net 的编码器和解码器部分以及定义最终输出层。   第 3 部分：模型训练 在这里，您将加载预处理的数据并训练 U-Net 模型。您编译模型，定义训练参数（如学习率和批量大小），并使用回调进行模型检查点、学习率降低和提前停止。   第 4 部分：模型评估和推理 最后一部分演示了如何加载训练好的模型，对测试数据进行推理，并可视化预测的分割蒙版。   您可以在博客中找到代码链接：https://eranfeit.net/u-net-image-segmentation-how-to-segment-persons-in-images/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/u-net-image-segmentation-how-to-segment-persons-in-images-2fd282d1005a 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/ZiGMTFle7bw&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</guid>
      <pubDate>Sat, 11 Jan 2025 20:46:01 GMT</pubDate>
    </item>
    <item>
      <title>代理实验室：基于法学硕士的自主科学研究框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</link>
      <description><![CDATA[新框架引入了一种自动化研究流程，使用 LLM 代理在人工监督下开展科学研究。该系统实施了三个阶段的流程：文献综述、实验和报告撰写。 关键技术组件：* 具有针对不同研究任务的专门角色的分层代理结构 * 在关键决策点集成人工反馈循环 * 用于实施实验的代码生成功能 * 结合文献和实验结果的自动论文合成 * 自定义提示系统以保持各阶段的研究一致性 评估结果：* 与基线自动化研究方法相比，成本降低了 84% * 生成的代码与盲审中的人类 ML 从业者的质量相匹配 * 成功重现了现有 ML 论文的结果 * 人类审阅者将输出质量评为与研究生水平的研究相当 我认为这可能会对我们开展 ML 研究的方式产生重大影响，特别是对于超参数优化和架构搜索等任务。在保持质量的同时实现文献综述自动化的能力可以帮助研究人员专注于新颖的方向而不是背景工作。 我认为主要的限制是系统对现有文献的依赖——它可能难以应对真正新颖的研究方向。该框架似乎更适合系统地探索已知领域，而不是突破性的新概念。 TLDR：基于 LLM 的研究自动化框架在人工监督下进行端到端 ML 研究方面显示出有希望的结果，在保持研究质量的同时显着降低了成本。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</guid>
      <pubDate>Sat, 11 Jan 2025 14:57:31 GMT</pubDate>
    </item>
    <item>
      <title>元思维链：教授法学硕士模拟思维链背后的推理过程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</link>
      <description><![CDATA[这项工作引入了元思维链（Meta-CoT），它通过明确地模拟元推理过程（模型如何决定采取哪些推理步骤以及为什么）来扩展常规的思维链提示。关键创新是结合过程监督（跟踪推理路径）、合成数据生成和搜索算法，帮助模型学习更好的推理策略。 关键技术点：* 使用过程监督来跟踪模型如何探索不同的解决路径* 通过观察成功的推理模式生成合成训练数据* 实现指令调整和基于 RL 的优化* 开发元推理解释的验证方法* 研究跨模型大小和架构的扩展行为 结果：* 与标准 CoT 相比，模型在推理任务上表现出更好的性能* 生成的解释与人类的推理模式更加一致* 训练管道成功地将指令调整与 RL 结合起来* 框架展示了处理多种推理策略的能力* 显示模型大小和元推理能力之间的相关性 我认为这种方法可以帮助创建更透明的人工智能系统，可以更好地解释他们的决策过程。过程监督和合成数据的结合似乎是提高推理能力的一种实用方法，而不需要大量人工标记的数据。 我认为关键的挑战将是验证元推理解释的质量，并确保它们真正反映模型的内部过程，而不是事后合理化。计算开销也可能限制实际应用。 TLDR：通过结合过程监督、合成数据和搜索算法，新框架可帮助语言模型不仅学习要采取哪些推理步骤，而且还学习为什么这些步骤有意义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</guid>
      <pubDate>Fri, 10 Jan 2025 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>对我关于 GCN 的新方法进行评分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</link>
      <description><![CDATA[您好，我在 ResearchGate 上发布了关于 GCN 的新方法，其中新应用了类别理论中的熵，这提高了 %% 的测试准确率。请不要嘲笑我，祝您有美好的一天并发表评论您的想法 :))    提交人    /u/ksrio64   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</guid>
      <pubDate>Thu, 09 Jan 2025 21:59:30 GMT</pubDate>
    </item>
    </channel>
</rss>