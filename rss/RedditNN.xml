<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 22 Mar 2024 00:56:53 GMT</lastBuildDate>
    <item>
      <title>关于CNN池化工具的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</link>
      <description><![CDATA[HI AI &amp; HI AI机器学习专家： 我是一名设计师，试图从高层次上理解 CNN。我被池化工具卡住了。 如果我理解正确的话，请告诉我：池化工具更像是轮廓、对比、凹陷的工具，让某些特征突出，同时减少计算负载，因为通过这些关键轮廓、对比度、凹面等部分，CNN 提取了足够的关键信息以供后续 ANN 处理。 我理解正确吗？我期待您的专家意见。谢谢！   由   提交/u/Ivory8977  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</guid>
      <pubDate>Thu, 21 Mar 2024 21:54:47 GMT</pubDate>
    </item>
    <item>
      <title>帮助描述性答卷评估器 NN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</link>
      <description><![CDATA[我是一名大学生，目前正在进行人工智能项目。它是一个答卷评估器，其中神经网络输入已经评估的答卷及其相应的分数。我对神经网络了解不多，所以谁能告诉我使用哪种神经网络模型。我正在考虑将 bert 和 cnn 配对。请建议良好的模型配对，以制作最准确的模型   由   提交/u/Consistent_Peanut998   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</guid>
      <pubDate>Thu, 21 Mar 2024 17:02:26 GMT</pubDate>
    </item>
    <item>
      <title>NN用于研究？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjyfiw/nn_for_research/</link>
      <description><![CDATA[未来几十年的机器学习研究领域会怎样？我只见过物理、生物和化学研究领域的负责人，但是机器学习研究领域怎么样？我应该考虑未来30-40年在这个领域的学习吗？最后，需求是什么，任何东西都会有帮助。   由   提交/u/Background_Bowler236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjyfiw/nn_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 04:43:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的基本神经网络偶尔会无法“学习”，但通常会产生约 95% 的准确率？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjt0mg/why_does_my_basic_neural_network_occasionally/</link>
      <description><![CDATA[我正在关注这个简单的教程，但是在这个数据集中进行替换并进行相应的调整。  我已经让它工作了（大多数时候），并且网络可以预测 URL 是网络钓鱼还是合法，准确率约为 95%（当它工作时）。  偶尔，也许有五分之一的情况，产生的权重最终对预测完全无用。这是神经网络训练的常见问题吗？如果需要，我可以提供代码，但代码与教程中的代码几乎相同，除了输入和输出神经元数量的一些更改以及显然对不同数据的不同处理之外。 就像这样在训练过程的开始阶段就出现了一些问题，并且无法逃脱它所发现的灾难。 有人在工作中遇到过类似的情况吗？我对这一切都非常陌生，所以如果这个问题很天真，我深表歉意。   由   提交 /u/allthenine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjt0mg/why_does_my_basic_neural_network_occasionally/</guid>
      <pubDate>Thu, 21 Mar 2024 00:17:10 GMT</pubDate>
    </item>
    <item>
      <title>半监督和自监督学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bjkpvl/semisupervised_and_selfsupervised_learning/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bjkpvl/semisupervised_and_selfsupervised_learning/</guid>
      <pubDate>Wed, 20 Mar 2024 18:34:46 GMT</pubDate>
    </item>
    <item>
      <title>自然语言指令诱导神经元网络中的成分泛化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1biry2e/natural_language_instructions_induce/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1biry2e/natural_language_instructions_induce/</guid>
      <pubDate>Tue, 19 Mar 2024 18:50:46 GMT</pubDate>
    </item>
    <item>
      <title>像素完美：工程师的新方法使图像成为焦点</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bilj9u/pixel_perfect_engineers_new_approach_brings/</link>
      <description><![CDATA[   /u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bilj9u/pixel_perfect_engineers_new_approach_brings/</guid>
      <pubDate>Tue, 19 Mar 2024 14:26:06 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何学习？数学公式解释了它们如何检测相关模式</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bid6t5/how_do_neural_networks_learn_a_mathematical/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bid6t5/how_do_neural_networks_learn_a_mathematical/</guid>
      <pubDate>Tue, 19 Mar 2024 05:52:47 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的时间之箭</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bhnp5i/arrows_of_time_for_large_language_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.17505 摘要：  我们通过以下方法研究自回归大型语言模型执行的概率建模：时间方向性的角度。我们凭经验发现此类模型在模拟自然语言的能力方面表现出时间不对称性：尝试预测下一个标记与尝试预测前一个标记时的平均对数困惑度存在差异。这种差异同时是微妙的，并且在各种模式（语言、模型大小、训练时间……）中非常一致。从理论上讲，这是令人惊讶的：从信息论的角度来看，不应该存在这样的差异。我们提供了一个理论框架来解释这种不对称性是如何从稀疏性和计算复杂性考虑中出现的，并概述了我们的结果所带来的一些观点。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bhnp5i/arrows_of_time_for_large_language_models/</guid>
      <pubDate>Mon, 18 Mar 2024 10:43:41 GMT</pubDate>
    </item>
    <item>
      <title>对反向传播算法的疑问。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bhcz4b/doubt_about_backpropagration_algorithm/</link>
      <description><![CDATA[大家好，我是人工智能方面的新手，也是工程专业的学生。因此，我正在尝试编写一个具有两个隐藏层和一个输出层神经元的多层感知器，以在没有任何库的情况下仅使用线性代数来执行回归任务。我认为我理解反向传播背后的数学原理，但在编码时我有疑问。 ​ 在反向传播期间，我写了类似的内容这个（只是为了知道，我在编码之前在三星笔记中编写代码）： ​ % 第二个隐藏层 dE_dY = grad3*w3 dY_dI = g(L2_input,derivative = &quot;True&quot;) grad2 = dE_dy*dI_dy dI_dW = L1_output &lt; p&gt;​ W2 = W2 -(learning_rate)*(-grad2*dI_dW) ​ 这部分是我的代码正在更新第二个隐藏层的权重。我的问题是尺寸。因为当我计算 grad2 时，在我的例子中是相同维度的 2 个列向量的乘法，例如 (1xn)*(1xn)，如你所知，我无法将其相乘。  ​ 由于我知道权重矩阵的维度，例如 MxN，我知道 --&gt; (learning_rate)*(-grad2*dI_dW) &lt;--- 需要具有相同的维度。这样，实现维度 MxN 的唯一可能性是如果我实现操作 dI_dy.*dI_dy，其中运算符“.*”是将 dI_dy 的每个元素乘以 dI_dy 的每个元素，得到 (1xn)。 ​ 我的疑问是：在数学中，- -&gt;dI_dy*dI_dy&lt;--- 只是一个乘法，但是当我编码时，似乎我需要使用“.*”，但我不知道这是否正确。&lt; /p&gt; ​ 只是想知道，我正在 MATLAB 中编程。 很抱歉，文字很长，如果我说得不够清楚，请告诉我（我的母语不是英语）。 ​   由   提交 /u/Jotavebechis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bhcz4b/doubt_about_backpropagration_algorithm/</guid>
      <pubDate>Mon, 18 Mar 2024 00:04:27 GMT</pubDate>
    </item>
    <item>
      <title>LLM 应用程序的评估指标摘要（RAG、聊天机器人、摘要）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bh82wf/summary_of_eval_metrics_for_llm_apps_rag_chatbot/</link>
      <description><![CDATA[       由   提交/u/jdogbro12  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bh82wf/summary_of_eval_metrics_for_llm_apps_rag_chatbot/</guid>
      <pubDate>Sun, 17 Mar 2024 20:43:50 GMT</pubDate>
    </item>
    <item>
      <title>验证链 (COVE) 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bh5xv3/chainofverification_cove_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bh5xv3/chainofverification_cove_explained/</guid>
      <pubDate>Sun, 17 Mar 2024 19:18:42 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习进行脑肿瘤分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bh2lna/brain_tumor_classification_using_deep_learning/</link>
      <description><![CDATA[      https://preview .redd.it/yapyr9cmexoc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=355d17b34d2478a44d9427cd80b11f6916c440c5 欢迎来到脑肿瘤初学者教程，在这里我们深入探讨 CNN 的世界（卷积神经网络）及其在图像分类和脑肿瘤检测中的突破性应用。 这是一个简单的卷积神经网络教程，演示如何在图像数据集中检测脑肿瘤。 我们将使用 CNN 构建和训练模型，并查看模型的准确性和准确性。丢失，然后我们将使用新图像测试和预测肿瘤。 以下是视频链接：https:/ /youtu.be/-147KGbGI3g 享受 Eran #cnnforimageclassification #cnnmachinelearningmodel #cnnml #deeplearningbraintumorclassification #aiDetectbraintumor   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bh2lna/brain_tumor_classification_using_deep_learning/</guid>
      <pubDate>Sun, 17 Mar 2024 17:04:01 GMT</pubDate>
    </item>
    <item>
      <title>马达琳网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bgtmx6/madaline_network/</link>
      <description><![CDATA[是否有一个正式的证据来说明为什么要设置更新规则，我知道与简单的反向传播相比，这是一个愚蠢的模型，我很容易理解（链式法则和错误道具）但是 Madaline 规则感觉很奇怪，只是想到而不是派生的东西    由   提交/u/borisshootspancakes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bgtmx6/madaline_network/</guid>
      <pubDate>Sun, 17 Mar 2024 09:32:34 GMT</pubDate>
    </item>
    <item>
      <title>关于 RNN 的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bg3gm8/question_about_rnns/</link>
      <description><![CDATA[在 RNN 中，神经元的输出是否会：  直接返回到与输入相同的神经元？  或  回到上一层，然后再次触发同一个神经元，同时也触发其他神经元？   如果这两种类型的 RNN 都存在，它们的名字是什么？   由   提交/u/BePoliter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bg3gm8/question_about_rnns/</guid>
      <pubDate>Sat, 16 Mar 2024 10:55:40 GMT</pubDate>
    </item>
    </channel>
</rss>