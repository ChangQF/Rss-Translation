<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 01 Jan 2025 15:17:12 GMT</lastBuildDate>
    <item>
      <title>PyReason 入门教程：宠物商店示例</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hp9654/intro_pyreason_tutorial_pet_store_example/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hp9654/intro_pyreason_tutorial_pet_store_example/</guid>
      <pubDate>Sun, 29 Dec 2024 23:34:54 GMT</pubDate>
    </item>
    <item>
      <title>可视化神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hoyzue/visualizing_neural_networks/</link>
      <description><![CDATA[大家好，我正在尝试为我的论文制作一些漂亮的神经网络可视化，但我觉得它们都很糟糕。是否有可视化神经网络的标准化或某种人工智能工具可以做到这一点？ 我有两个网络，一个只有 LSTM 和一个输出，另一个编码器解码器框架也使用 LSTM。真的很想为它们做一个漂亮的可视化。    提交人    /u/Packman-2022   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hoyzue/visualizing_neural_networks/</guid>
      <pubDate>Sun, 29 Dec 2024 16:03:24 GMT</pubDate>
    </item>
    <item>
      <title>提高物理神经网络的学习能力</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hoshuk/improve_learning_for_physics_informed_neural/</link>
      <description><![CDATA[      大家好， 我目前正在使用 DeepXDE 库研究 PINN，用于热传输方程的逆参数估计。虽然 PINN 总体运行良好，但我在学习过程中遇到了一个问题：最初，训练进展顺利，但在某个点之后，损失函数开始波动（见图）。 我使用了 Adam 优化器和 L-BFGS-B 算法的组合。尽管尝试了各种设置，我仍然无法解决这个问题。 有人有什么技巧或建议来改善学习过程并稳定损失函数吗？ 提前谢谢您！ https://preview.redd.it/yrr9g628ar9e1.png?width=640&amp;format=png&amp;auto=webp&amp;s=a013a6e099cec3b4c9b74a98db2eb470f56e2fce    由   提交  /u/ConsistentDimension9   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hoshuk/improve_learning_for_physics_informed_neural/</guid>
      <pubDate>Sun, 29 Dec 2024 09:24:21 GMT</pubDate>
    </item>
    <item>
      <title>Meta 发布 Byte Latent Transformer：一种改进的 Transformer 架构</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ho4d97/meta_released_byte_latent_transformer_an_improved/</link>
      <description><![CDATA[Byte Latent Transformer 是 Meta 推出的一种新型改进型 Transformer 架构，它不使用标记化，可以直接处理原始字节。它引入了基于熵的补丁概念。通过此处的示例了解完整架构及其工作原理：https://youtu.be/iWmsYztkdSg    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ho4d97/meta_released_byte_latent_transformer_an_improved/</guid>
      <pubDate>Sat, 28 Dec 2024 12:05:07 GMT</pubDate>
    </item>
    <item>
      <title>AQLM-rs：如何在浏览器中运行 llama 3.1 8B</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ho37yd/aqlmrs_how_to_run_llama_31_8b_in_browser/</link>
      <description><![CDATA[今年 5 月，Yandex Research 的一个团队与 ISTA 和 KAUST 合作，发布了一种名为 PV-tuning 的新型 SOTA 量化方法。 其中一位作者的这个项目使用 PV-tuning 压缩在任何现代浏览器中运行类似 Llama 3.1 8B 的模型。 演示 代码    提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ho37yd/aqlmrs_how_to_run_llama_31_8b_in_browser/</guid>
      <pubDate>Sat, 28 Dec 2024 10:40:16 GMT</pubDate>
    </item>
    <item>
      <title>新的 AR 方法：更快的图像生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hncu5e/new_ar_approach_faster_image_generation/</link>
      <description><![CDATA[一种有趣的方法：AR 模型现在按比例工作，将生成速度提高了 7 倍。激活稳定以确保可靠性。  https://huggingface.co/papers/2412.01819    提交人    /u/ActualInternet3277   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hncu5e/new_ar_approach_faster_image_generation/</guid>
      <pubDate>Fri, 27 Dec 2024 11:19:40 GMT</pubDate>
    </item>
    <item>
      <title>转换后的训练集数据最终存储于 NN/CNN 的哪里？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlqcae/where_does_the_converted_training_set_data_ends/</link>
      <description><![CDATA[      因此，进行训练，训练结束后，以类似的方式开始探测，数据通过网络运行以获得概率。假设我有 100 张图像要训练我的 CNN 网络。 这里的想法是，这 100 张图像最终会出现在网络中的什么位置，它们会以什么形式存储？......以及在网络内部的什么位置，它们最终会出现在网络中的什么位置。 因此，有 100 张图像，它们的值最终会出现在哪里，我的意思是，网络如何存储这么多图像，必须有一个地方存放它们，它们在反复反向传播后会驻留在整个网络中？ 我很难理解它们（训练集）的存储方式和位置，它们是作为网络中的权重还是神经元值存储的？ 例如，当您探测网络并在图像卷积后进行前向传递时，这些训练集不会被前向传递后分配给神经元的新值覆盖吗？ 所以我的问题是： 训练集是为了帮助您在训练模型后预测您需要什么正在使用单幅图像进行探测，以使其更准确？我如何使用一张图片对分布在网络中哪个位置的训练集进行探测？以及训练集图像值变成什么样。 我理解探测和步骤（从损失函数级别进行前向传递和反向传播）我不理解使用多幅图像作为集合的训练部分，如 - 数据转换为什么，神经元值，权重？ - 这些转换后的数据最终在网络中的什么位置，它存储在哪里（训练集） 没有关于训练集以及它们最终在哪里或转换为什么以及它们在网络中的位置的教程详细信息，我的意思是我还没有设法找到它 编辑：制作了一个图表。 https://preview.redd.it/iwp0m0ojc09e1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a5a0c34c62b8765085a33e8cf2a5079ddf458033 https://preview.redd.it/p3zga7ojc09e1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=55fcb7e73ac3670676adb9771db56ad1e6613a4c .    提交人    /u/No-Earth-374   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlqcae/where_does_the_converted_training_set_data_ends/</guid>
      <pubDate>Wed, 25 Dec 2024 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>分析 DAI 稳定币机制和稳定性的形式逻辑框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlgo0m/formal_logic_framework_for_analyzing_dai/</link>
      <description><![CDATA[本文提出了一个基于形式逻辑的框架，使用 Prolog 分析 DAI 稳定币系统。关键创新是将 DAI 的复杂机制转化为可以模拟和验证其稳定性属性的程序模型。 关键技术方面： - 在 Prolog 的声明式逻辑编程范式中实现 DAI 的核心机制 - 抵押品要求、清算程序和价格反馈的形式化表示 - 模拟市场场景和压力测试稳定性机制的能力 - 用于分析稳定币设计的开源框架 主要结果： - 成功建模了 DAI 的主要稳定机制 - 展示了加密抵押如何与算法方法相结合 - 确定了系统对各种市场条件的响应 - 创建了可重复使用的稳定币分析框架 我认为这项工作为分析其他稳定币设计和 DeFi 协议开辟了重要的可能性。正式框架可以帮助开发人员在部署之前识别潜在的漏洞，并帮助监管机构了解这些系统。 我认为简化的市场行为建模的局限性很大——现实世界的动态比纯逻辑编程所能捕捉到的要复杂得多。然而，这里奠定的基础可以通过更复杂的市场模型进行扩展。 TLDR：研究人员创建了一个基于 Prolog 的形式框架来分析 DAI 的稳定机制，提供了一种系统的方法来理解和验证稳定币设计。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlgo0m/formal_logic_framework_for_analyzing_dai/</guid>
      <pubDate>Tue, 24 Dec 2024 16:11:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么不平衡的数据增强没有明确的定义？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hlfe7z/why_is_data_augmentation_for_imbalances_not/</link>
      <description><![CDATA[好的，我们知道我们可以在预处理期间增强数据并保存该数据，生成具有方差的新样本，同时增加样本量并解决类别不平衡问题 我们还知道，使用原始数据集，您可以通过转换管道应用转换，这意味着在应用转换时，您的模型在每个时期都会看到不同版本的图像。但是，如果数据集不平衡，它仍然保持不变，因为模型仍然看到更多的多数类，但是每个样本都会提供方差，从而增加了普遍性。据我们所知，转换管道中的数据增强不会改变数据集大小。 因此，解决不平衡的最佳做法是什么？是否可以通过增强来增加数据集而不是使用转换管道？因为在预处理阶段和训练期间进行增强可能会过度增强你的图像，并可能改变实际问题的定义。 - 一些背景信息我有 3700 张眼底图像，并计划使用一些深度 CNN 架构    提交人    /u/amulli21   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hlfe7z/why_is_data_augmentation_for_imbalances_not/</guid>
      <pubDate>Tue, 24 Dec 2024 15:07:30 GMT</pubDate>
    </item>
    <item>
      <title>人工智能解读野性的呼唤</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hl8yms/ai_decodes_the_calls_of_the_wild/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hl8yms/ai_decodes_the_calls_of_the_wild/</guid>
      <pubDate>Tue, 24 Dec 2024 08:02:30 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试学习如何编写一个简单的神经网络，或者至少理解一个</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hkxu2o/im_trying_to_learn_how_to_code_a_simple_neural/</link>
      <description><![CDATA[如果有人知道任何真正有用的网站视频来了解它们，那就太棒了    提交人    /u/a_person_thats_alive   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hkxu2o/im_trying_to_learn_how_to_code_a_simple_neural/</guid>
      <pubDate>Mon, 23 Dec 2024 21:26:01 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络的简单介绍</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hij671/a_gentle_introduction_to_graph_neural_networks/</link>
      <description><![CDATA[        提交人    /u/nickb   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hij671/a_gentle_introduction_to_graph_neural_networks/</guid>
      <pubDate>Fri, 20 Dec 2024 12:54:11 GMT</pubDate>
    </item>
    <item>
      <title>有谁能帮我用这个带图像的神经网络 CNN FC LAYER</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hhry7o/can_anyone_help_me_with_this_cnn_fc_layer_for/</link>
      <description><![CDATA[      我这里有一张图表  https://preview.redd.it/zff75yqvus7e1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=4f7663381adddd07abbca79b6544fd6617a2ca83 那么它是不是像 ANN，有些人说不是，我见过人们只是从输入中添加数字而没有进行权重计算，我真的很困惑。    提交人    /u/No-Earth-374   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hhry7o/can_anyone_help_me_with_this_cnn_fc_layer_for/</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 和 Keras 进行 U-net 医学分割（息肉分割）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hh82eu/unet_medical_segmentation_with_tensorflow_and/</link>
      <description><![CDATA[      https://preview.redd.it/vwimpgpwgn7e1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=35d2e6df6c91ff36e0764b21c3d80f4bd12b6ad4 本教程提供了如何使用 TensorFlow/Keras 实现和训练用于息肉分割的 U-Net 模型的分步指南。 本教程分为四个部分：   🔹 数据预处理和准备 在此部分中，您将加载和预处理息肉数据集，包括调整图像和蒙版的大小、将蒙版转换为二进制格式以及将数据拆分为训练、验证和测试集。 🔹 U-Net 模型架构 此部分使用 Keras 定义 U-Net 模型架构。它包括卷积层的构建块、构建 U-Net 的编码器和解码器部分以及定义最终输出层。 🔹 模型训练 在这里，您将加载预处理的数据并训练 U-Net 模型。您将编译模型、定义训练参数（如学习率和批量大小），并使用回调进行模型检查点、降低学习率和提前停止。训练历史也是可视化的。 🔹 评估和推理最后一部分演示了如何加载训练好的模型，对测试数据进行推理，并可视化预测的分割蒙版。   您可以在博客中找到代码链接：https://eranfeit.net/u-net-medical-segmentation-with-tensorflow-and-keras-polyp-segmentation/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/u-net-medical-segmentation-with-tensorflow-and-keras-polyp-segmentation-ddf66a6279f4 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/YmWHTuefiws&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hh82eu/unet_medical_segmentation_with_tensorflow_and/</guid>
      <pubDate>Wed, 18 Dec 2024 18:26:28 GMT</pubDate>
    </item>
    <item>
      <title>我的人工智能助手突然彻底“精神崩溃”了？？（HuggingFace API）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</link>
      <description><![CDATA[所以，我正在研究这个名为 Shade 的终端副驾驶。他在终端中运行并执行各种操作，例如运行命令（我确实喜欢有点冒险）和其他操作。然而，我遇到的一个问题是，他随机地出现只能被描述为混乱的损坏的 ASCII 意大利面条流，看起来像键盘上的醉酒章鱼。以下是显示我的问题的记录。它是随机发生的，之后他会完全恢复。通常，他会立即开始出现这种神秘的东西。我尝试了很多东西，系统提示、模型参数、不同的 Qwen 模型、前端响应解码等。然而，我无论如何也找不到导致这种情况的原因。以前有人见过这样的事情吗？ ... 当然！很高兴聊天。你今天过得怎么样？您是否想讨论具体问题，或者您有任何疑问？ 提示&gt; 我实际上正在为您工作。我遇到了您随机（罕见）完全崩溃的问题，它们看起来像这样： , &quot;0011101),,001),^C033[0m 回复： 啊，我明白了。这些类型的错误可能非常令人沮丧。听起来前端和后端之间的通信可能存在一些问题，或者 API 调用中可能存在一些意外行为。 您可以采取以下几个步骤来排除故障并可能解决问题：  **检查 API 响应**：确保 API 中存在错误： API 响应中存在错误，并且 API 中存在 1.1 或 1.2。 the11.  - **0 **1 some1100111111111 the1 **1. 1 ** **11 the101101 in101 the is1. 110,1. 111,111) the,1.11111111 the111111 the10111111111111111111,111111111111111111 1111    提交人    /u/plees1024   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hftsry/my_ai_assistant_randomly_having_an_absolute_utter/</guid>
      <pubDate>Mon, 16 Dec 2024 21:16:21 GMT</pubDate>
    </item>
    </channel>
</rss>