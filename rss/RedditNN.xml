<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Fri, 28 Jun 2024 18:18:49 GMT</lastBuildDate>
    <item>
      <title>神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dq3eej/neural_network/</link>
      <description><![CDATA[      伙计们，请告诉我什么样的神经网络可以制作出如此酷的图片，或者我可以在哪里获得这样的布局    提交人    /u/Brilliant-Use-9856   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dq3eej/neural_network/</guid>
      <pubDate>Thu, 27 Jun 2024 21:58:55 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能的快速入门</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dq1t3p/quick_and_dirty_intro_to_neurosymbolic_ai/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dq1t3p/quick_and_dirty_intro_to_neurosymbolic_ai/</guid>
      <pubDate>Thu, 27 Jun 2024 20:50:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 和 Opencv 进行文本检测 | 使用 EasyOCR 进行 OCR | 计算机视觉教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dpueub/text_detection_with_python_and_opencv_ocr_using/</link>
      <description><![CDATA[      https://preview.redd.it/jdt1d5wcn59d1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=24bb544b9e57dec962f1eadb3c0eb1b384500316 在本视频中，我向您展示了如何使用 Python、OpenCV 和 EasyOCR 进行光学字符识别 (OCR)！ 按照本 10 分钟教程的步骤，您将能够检测图像上的文本！   您可以在我的博客文章页面中找到更多类似的教程：https://eranfeit.net/blog/ 在此处查看我们的视频：https://youtu.be/DycbnT_pWKw&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受， Eran     Python #OpenCV #ObjectDetection #ComputerVision #EasyOCR   由    /u/Feitgemel  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dpueub/text_detection_with_python_and_opencv_ocr_using/</guid>
      <pubDate>Thu, 27 Jun 2024 15:44:05 GMT</pubDate>
    </item>
    <item>
      <title>利用 AI 和 RGB-D 进行 3D 盒子测量</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dptrle/3d_box_measurement_utilizing_ai_and_rgbd/</link>
      <description><![CDATA[       由    /u/erol444  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dptrle/3d_box_measurement_utilizing_ai_and_rgbd/</guid>
      <pubDate>Thu, 27 Jun 2024 15:16:34 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络中使用的激活函数</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dp6kgb/activation_functions_used_in_deep_neural_networks/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dp6kgb/activation_functions_used_in_deep_neural_networks/</guid>
      <pubDate>Wed, 26 Jun 2024 19:01:42 GMT</pubDate>
    </item>
    <item>
      <title>觉得这个视频很有帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dp1jeh/found_this_video_really_helpful/</link>
      <description><![CDATA[https://youtu.be/Ixl3nykKG9M?si=LK8y7J3TO8gBfAim    由   提交  /u/blaze_284   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dp1jeh/found_this_video_really_helpful/</guid>
      <pubDate>Wed, 26 Jun 2024 15:34:41 GMT</pubDate>
    </item>
    <item>
      <title>使用二维矩阵作为 LSTM / RNN 模型的特征输入</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1do9nmj/using_a_2d_matrix_as_a_feature_input_to_lstm_rnn/</link>
      <description><![CDATA[我正在构建一个 LSTM 模型来预测每天在商店层面销售的商品组合。请注意，这是一个探索性模型，我对不同类型的 SKU / 产品之间的相关性有一个很好的了解。输入特征将包括每个 SKU 的不同特征作为矩阵的行（因此列将是特征，行将是 SKU ID）。该模型的输出将是大小为 N 的一维向量（其中 N 是 SKU 的数量），标签（GT）将提供每日销售的百分比细分。现在我也明白，使用 softmax 激活的输出并不能直接转化为百分比，但我需要的只是一个大概的估计（我也可以使用 KL 散度损失，因为我们需要的只是销售分布以匹配预测） 所以主要问题是如何将这个二维矩阵转换为一维特征向量？我的愚蠢想法是使用相同的顺序将其展平（例如 SKU1-SKU2- 等 ..这当然会出现特定日期的销售缺失问题，并且将是一个 0 的向量），并且因为在推理过程中我知道这个顺序，所以我将使用相同的顺序。每当引入新的 SKU 时，我只需使用新顺序从头开始重新训练模型即可。 就像我说的，以上只是第一次通过，因此任何意见、指针都将受到高度赞赏（跨越所有时间步骤 :P）    提交人    /u/immortanslow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1do9nmj/using_a_2d_matrix_as_a_feature_input_to_lstm_rnn/</guid>
      <pubDate>Tue, 25 Jun 2024 16:05:51 GMT</pubDate>
    </item>
    <item>
      <title>我利用 Strava 活动训练了一个神经网络，以预测我的比赛时间</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dna5fg/i_trained_a_neural_network_with_my_strava/</link>
      <description><![CDATA[https://github.com/nst/StravaNeuralNetwork 我仍然发现这些预测非常不精确，希望得到评论和建议。    提交人    /u/Dull_Replacement8890   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dna5fg/i_trained_a_neural_network_with_my_strava/</guid>
      <pubDate>Mon, 24 Jun 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>我已经训练了一个神经网络来合并我的世界皮肤。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dn47gy/ive_trained_a_neural_network_to_merge_minecraft/</link>
      <description><![CDATA[        提交人    /u/Cfgodndje28   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dn47gy/ive_trained_a_neural_network_to_merge_minecraft/</guid>
      <pubDate>Mon, 24 Jun 2024 03:40:21 GMT</pubDate>
    </item>
    <item>
      <title>构建一个 Python 库来快速为 RAG 创建+搜索知识图谱——想要做出贡献吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dmm1e5/building_a_python_library_to_quickly_createsearch/</link>
      <description><![CDATA[如果您的文档包含相互关联的概念，知识图谱可以提高您的 RAG 准确性。 并且，您可以使用最新版本的 knowledge-graph-rag 库自动为现有文档创建 + 搜索 KG。 只需 3 行代码即可完成所有操作。 在此示例中，我使用医疗文档。该库的工作原理如下：  从语料库中提取实体（例如器官、疾病、疗法等） 提取它们之间的关系（例如疗法的缓解效果、斑块的积累等） 使用 LLM 从这些表示中创建知识图谱。 当用户发送查询时，将其分解为要搜索的实体。 搜索 KG 并在 LLM 调用的上下文中使用结果。  这是 repo：https://github.com/sarthakrastogi/graph-rag 如果您想贡献或对功能有建议，请在 Github 上提出。    由    /u/sarthakai 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dmm1e5/building_a_python_library_to_quickly_createsearch/</guid>
      <pubDate>Sun, 23 Jun 2024 13:22:19 GMT</pubDate>
    </item>
    <item>
      <title>LinkedIn 使用 Graph RAG 将他们的工单解决时间从 40 小时缩短至 15 小时。让我们创建一个库，让每个人都可以使用它？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dlwchd/linkedin_used_graph_rag_to_cut_down_their_ticket/</link>
      <description><![CDATA[首先，我了解一下他们是如何做到的： 他们通过将客户支持工单解析为结构化的树形表示来创建 KG，并保留其内部关系。 工单基于上下文相似性、依赖性和引用进行链接 - 所有这些都构成了一个综合图。 KG 中的每个节点都是嵌入的，因此它们可以进行语义搜索和检索。 RAG QA 系统通过遍历和按语义相似性搜索来识别相关子图。 然后，它从 KG 中生成上下文感知答案，并通过 MRR 进行评估，结果显着改善。 论文：https://arxiv.org/pdf/2404.17723 如果您也想实现 Graph RAG，我正在创建一个 Python 库，它可以自动为您的 vectordb 中的文档创建此图表。它还使您可以轻松检索与最佳匹配相关的相关文档。 如果您有兴趣做出贡献或有任何建议，请在 Github 上提出。 这是该库的 repo：https://github.com/sarthakrastogi/graph-rag/tree/main    提交人    /u/sarthakai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dlwchd/linkedin_used_graph_rag_to_cut_down_their_ticket/</guid>
      <pubDate>Sat, 22 Jun 2024 14:01:14 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 5 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dlqcc8/ai_reading_list_part_5/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dlqcc8/ai_reading_list_part_5/</guid>
      <pubDate>Sat, 22 Jun 2024 07:41:23 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器 | 深度学习动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dlgrr3/autoencoders_deep_learning_animated/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dlgrr3/autoencoders_deep_learning_animated/</guid>
      <pubDate>Fri, 21 Jun 2024 22:40:25 GMT</pubDate>
    </item>
    <item>
      <title>简单解释 LoRA 的实际工作原理 (ELI5)</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dl55h7/simply_explaining_how_lora_actually_works_eli5/</link>
      <description><![CDATA[假设在您的 LLM 中，您有维度为 d x k 的原始权重矩阵 W。 您的传统训练过程会直接更新 W - 如果 d x k 很大，那么参数数量将非常庞大，需要大量计算。 因此，我们在权重更新之前使用低秩分解对其进行分解。方法如下 - 我们将权重更新 (Delta W) 表示为两个低秩矩阵 A 和 B 的乘积，使得 Delta W = BA。 这里，A 是维度为 r x k 的矩阵，B 是维度为 d x r 的矩阵。这里，r（秩）比 d 和 k 小得多。 现在，矩阵 A 用一些随机高斯值初始化，矩阵 B 用零初始化。 为什么？因此最初 Delta W = BA 可以为 0。 现在开始训练过程： 在权重更新期间，仅更新较小的矩阵 A 和 B - 这大大减少了需要调整的参数数量。 对原始权重矩阵 W 的有效更新是 Delta W = BA，它使用更少的参数来近似 W 的变化。 让我们比较一下 LoRA 之前和之后要更新的参数： 之前，要更新的参数是 d x k（记住 W 的尺寸）。 但是现在，参数数量减少到 (d x r) + (r x k)。这个值要小得多，因为秩 r 被认为比 d 和 k 小得多。 这就是低秩近似如何通过这种紧凑的表示为您提供有效的微调。 训练速度更快，需要的计算和内存更少，同时仍然可以从微调数据集中捕获重要信息。 我还使用 Artifacts 制作了一个快速动画来解释（大约花了 10 秒）： https://www.linkedin.com/posts/sarthakrastogi_simply-explaining-how-lora-actually-works-activity-7209893533011333120-RSsz    提交人    /u/sarthakai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dl55h7/simply_explaining_how_lora_actually_works_eli5/</guid>
      <pubDate>Fri, 21 Jun 2024 14:19:55 GMT</pubDate>
    </item>
    <item>
      <title>案例研究：人工智能和计算机视觉——在麦克风后面和舞台上</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dl2r07/case_study_artificial_intelligence_and_computer/</link>
      <description><![CDATA[在案例研究回顾中，您将了解机器人如何创作交响乐。神经网络创造热门歌曲，3D 投影在舞台上表演，音乐服务根据声谱图对曲目进行评分。音乐文化是不断发展的技术的完美游乐场 完整文章位于 OpenCV.ai 博客中。链接此处。    提交人    /u/Computer_Vision4883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dl2r07/case_study_artificial_intelligence_and_computer/</guid>
      <pubDate>Fri, 21 Jun 2024 12:24:53 GMT</pubDate>
    </item>
    </channel>
</rss>