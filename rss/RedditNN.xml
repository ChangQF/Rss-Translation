<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Tue, 11 Jun 2024 12:28:37 GMT</lastBuildDate>
    <item>
      <title>需要帮助！构建 Micrograd</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</link>
      <description><![CDATA[我正在尝试浏览这个视频，在 1:50:29 处出现此错误：  TypeError Traceback (most recent call last) Cell In[151], line 1 ----&gt; 1 draw_dot(n(x)) Cell In[148], line 18, in draw_dot(root) 15 def draw_dot(root): 16 dot = Digraph(format=&#39;svg&#39;, graph_attr={&#39;rankdir&#39;: &#39;LR&#39;}) # LR = 从左到右 ---&gt; 18 nodes, edge = trace(root) 19 for n in nodes: 20 uid = str(id(n)) Cell In[148], line 12, in trace(root) 10 edge.add((child,v)) 11 build(child) ---&gt; 12 build(root) 13 return nodes, edge Cell In[148], line 7, in trace.&lt;locals&gt;.build(v) 6 def build(v): ----&gt; 7 if v not in nodes: 8 nodes.add(v) 9 for child in v._prev: TypeError: unhashable type: &#39;list&#39;  作为参考，我在回复中删除了我正在使用的整个 Jupyter 笔记本；我真的无法弄清楚这一点，这非常令人沮丧（我对此很陌生）。请帮忙。非常感谢。 :)     由    /u/no4-h 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dd3ajm/need_help_building_micrograd/</guid>
      <pubDate>Tue, 11 Jun 2024 02:20:03 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能：解码器和 GPT 模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dcqxvf/generative_ai_decoders_and_gpt_models/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dcqxvf/generative_ai_decoders_and_gpt_models/</guid>
      <pubDate>Mon, 10 Jun 2024 17:17:50 GMT</pubDate>
    </item>
    <item>
      <title>实际上看到了CNN深度神经网络模型吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dcq1us/what_actually_sees_a_cnn_deep_neural_network_model/</link>
      <description><![CDATA[      https://preview.redd.it/bo6edxn3wr5d1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=f29872abc1925300e92d7accf7d7f58c180732d0 在本视频中，我们深入探讨了深度神经网络的迷人世界，并可视化了其各层的结果，为分类过程提供了宝贵的见解   如何可视化 CNN 深度神经网络模型？ 在训练过程中实际看到的是什么? 选择的过滤器是什么，每个神经元的结果是什么。 在本部分中，我们将重点展示各层的结果。 非常有趣！     本视频是 🎥 图像分类教程系列：五部分 🐵 的一部分   我们将指导您完成对图像中的猴子物种进行分类的整个过程。我们首先介绍数据准备，您将在其中学习如何下载、探索和预处理图像数据。 接下来，我们深入研究卷积神经网络 (CNN) 的基础知识，并演示如何构建、训练和评估 CNN 模型以进行准确分类。 在第三个视频中，我们使用 Keras Tuner 优化超参数来微调 CNN 模型的性能。接下来，我们将在第四个视频中探索预训练模型的强大功能， 特别侧重于对 VGG16 模型进行微调以获得卓越的分类准确性。     您可以在此处找到视频教程的链接：https://youtu.be/yg4Gs5_pebY&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran   Python #Cnn #TensorFlow #Deeplearning #basicsofcnnindeeplearning #cnnmachinelearningmodel #tensorflowconvolutionalneuralnetworktutorial    提交人    /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dcq1us/what_actually_sees_a_cnn_deep_neural_network_model/</guid>
      <pubDate>Mon, 10 Jun 2024 16:41:43 GMT</pubDate>
    </item>
    <item>
      <title>ML Ops 简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc3yfi/introduction_to_ml_ops/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc3yfi/introduction_to_ml_ops/</guid>
      <pubDate>Sun, 09 Jun 2024 20:53:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么会有偏见？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc34vf/why_biases/</link>
      <description><![CDATA[      神经网络中偏差的用途是什么？ChatGPT 告诉我它会“转移”激活函数（这意味着如果添加偏差，它不会通过原点）。 这对我来说没有意义，因为如果偏差只是将自己添加到加权和中，函数本身没有理由转移。 同样，在所有条件相同的情况下，为什么不直接使用更强的权重而不是添加偏差，这似乎是毫无理由的额外工作。 更新：我已经发现偏差如何“转移”（使用这个词来描述正在发生的事情的非常误导的方式）激活函数。没有发生字面上的“转移”；发生的情况是，偏差只是增加了加权和（根据偏差），因此使其等同于如果函数实际上在 x 轴上移动（通过偏差）并且只将加权和作为其输入时激活函数所返回的值。如有疑问，请继续阅读。 这里有一个图片示例： 注意：加权和 = 2 且偏差 = 2。因此，当两者相加时，您将得到 4（呵呵哈哈……） 蓝线表示如果我们将加权和 (w1 * inp1) + 等... + 偏差输入到 S 型函数中。红线表示如果我们只输入加权和而不在 S 型函数中添加偏差，然后修改函数，使其在 x 轴上移动 2。 如您所见，当 x = 4 时，蓝线显示 y 为 .982 同样，当 x = 2 时，红线显示 y 为 .982 如果您认为我错了，请随时发表评论。    提交人    /u/mistr_bean   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc34vf/why_biases/</guid>
      <pubDate>Sun, 09 Jun 2024 20:18:45 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 2 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dc00tg/ai_reading_list_part_2/</link>
      <description><![CDATA[大家好， 我在这里创建了一个新系列，我们将探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读材料中的以下 6 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dc00tg/ai_reading_list_part_2/</guid>
      <pubDate>Sun, 09 Jun 2024 18:06:50 GMT</pubDate>
    </item>
    <item>
      <title>体素化三维物体的特征识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dbcvgg/feature_recognition_for_voxelized_3d_objects/</link>
      <description><![CDATA[嗨。我见过人们如何使用神经网络来识别 2D 图像上的特征或对图像上描绘的物体进行分类。例如，检测人脸或分辨照片上的动物种类。但是 3D 物体的特征识别呢？理论上，我可以将 3D 模型从网格格式转换为体素格式，并使用几乎相同的算法进行特征识别，以分辨哪些体素与手、头、眼睛等相关。 是否有任何现有的模型可以完成这种任务？如果我想构建这样的东西，我会遇到什么挑战？    提交人    /u/zergon321   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dbcvgg/feature_recognition_for_voxelized_3d_objects/</guid>
      <pubDate>Sat, 08 Jun 2024 21:08:47 GMT</pubDate>
    </item>
    <item>
      <title>人工智能阅读清单</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dayhe6/ai_reading_list/</link>
      <description><![CDATA[大家好， 我在这里创建了一个新系列，我们将在其中探讨前 OpenAI 首席科学家 Ilya Sutskever 给 John Carmack 的阅读材料中的前 5 项。Ilya 接着说：“如果你真的学会了所有这些，你就会知道今天重要的事情的 90%”。 我希望这对你们中的一些人有用。非常欢迎反馈！:)    提交人    /u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dayhe6/ai_reading_list/</guid>
      <pubDate>Sat, 08 Jun 2024 08:47:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 dILP 进行归纳逻辑编程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dabwgl/inductive_logic_programming_with_dilp/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dabwgl/inductive_logic_programming_with_dilp/</guid>
      <pubDate>Fri, 07 Jun 2024 14:19:19 GMT</pubDate>
    </item>
    <item>
      <title>选择手写单词</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1da7d7g/select_handwritten_word/</link>
      <description><![CDATA[      大家好， 我目前正在做一个项目，需要一些指导。如何从二值化图像中检测和选择手写单词？我一直在努力解决这个问题，如果您能分享任何建议或资源，我将不胜感激。 https://preview.redd.it/kcbfv9dsm45d1.png?width=990&amp;format=png&amp;auto=webp&amp;s=b80ae1c68d25fa66729b74a1787f829f73ddf70d 提前感谢您的帮助！    提交人    /u/Dependent-Ad914   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1da7d7g/select_handwritten_word/</guid>
      <pubDate>Fri, 07 Jun 2024 10:28:15 GMT</pubDate>
    </item>
    <item>
      <title>回归任务的批量标准化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1da5f1q/batch_normalization_for_a_regression_task/</link>
      <description><![CDATA[我是机器学习的新手，正在研究用于回归任务的神经网络。我有 788 个输入神经元和一个输出神经元，以及大量的训练输入/正确输出。我正在使用 MSE 作为成本函数。我一直在阅读有关批量标准化如何改善这些网络的文章，这涉及标准化每个层的输入。我的 788 个输入中的每一个都是布尔值，所以我不确定标准化它们是否有意义。如果我理解过程正确，我应该为批次（激活函数之前）取我的整个 z 值集，对其进行标准化，然后乘以 gamma 并添加 beta，并且 gamma/beta 应该与权重一起在每个节点上单独训练。很多问题：  我最初的理解是它正在标准化批次中的每个输入。因此，如果我有 788 个输入神经元并且正在进行 256 个样本的批次，我将对神经元 1 取 256 个样本的均值/方差，对神经元 2 取 256 个样本的均值/方差，等等。现在我在网上看到的东西看起来好像是在寻找 788 个输入的均值/方差，如下所示：https://i.ytimg.com/vi/BZh1ltr5Rkg/hqdefault.jpg 我还期望每个神经元都有自己的 gamma/beta（输出层除外，因为它不使用批量标准化）。这是正确的吗？ 在实际用例中，不会有批次。在没有批次且标准化没有意义的实际情况下，这如何工作？     提交人    /u/tic-tac135   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1da5f1q/batch_normalization_for_a_regression_task/</guid>
      <pubDate>Fri, 07 Jun 2024 08:05:14 GMT</pubDate>
    </item>
    <item>
      <title>问题：Python 生成狭缝光衍射图案以及真实图像的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d9gpcl/question_python_generated_light_diffraction/</link>
      <description><![CDATA[嗨。我是一名学生，正在尝试制作一个神经网络，该神经网络可以对使用 Python 创建的光衍射图像进行分类。问题是，当在新的 PythonG 生成的图像上进行测试时，该模型在准确度和分类报告/混淆矩阵方面取得了非常高的分数，但当我给它提供从互联网上找到的真实图像时，它的表现非常差。我怀疑这与真实图像的噪声不太理想有关，现在我试图将噪声引入我的训练数据集。有什么建议吗？    提交人    /u/AncientGearAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d9gpcl/question_python_generated_light_diffraction/</guid>
      <pubDate>Thu, 06 Jun 2024 12:13:29 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下吗？（概率神经网络）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d9fx56/can_anyone_explain_probabilistic_neural_networks/</link>
      <description><![CDATA[      我的老师给了我们这个他解决了的例子，但我不明白。特别是多变量函数求和部分。有人能给我解释一下吗？    提交人    /u/Ikossys   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d9fx56/can_anyone_explain_probabilistic_neural_networks/</guid>
      <pubDate>Thu, 06 Jun 2024 11:29:48 GMT</pubDate>
    </item>
    <item>
      <title>不确定我的项目</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d98u9u/unsure_about_my_project/</link>
      <description><![CDATA[我是一名计算机科学专业的最后一年学生，我还没有完成我的 FYP 项目。我和我的团队已经研究了很长一段时间，我们找到了一个想法，有时感觉它具有革命性，有时感觉我们可能在浪费时间，更不用说对它可实现性的怀疑了。 我们的想法是设计一个 SNN 模型，使用某种同态加密对加密数据进行计算。我们为此决定的应用程序是欺诈检测，银行和金融机构可以使用它来检测欺诈交易，而无需解密数据进行处理。 我很感激关于这个想法的反馈和想法，以及任何与项目相关的建议或推荐。    提交人    /u/Other-Community9534   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d98u9u/unsure_about_my_project/</guid>
      <pubDate>Thu, 06 Jun 2024 03:32:33 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能概览”中的谷歌与幻觉</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1d7z2ut/google_vs_hallucinations_in_ai_overviews/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1d7z2ut/google_vs_hallucinations_in_ai_overviews/</guid>
      <pubDate>Tue, 04 Jun 2024 14:51:27 GMT</pubDate>
    </item>
    </channel>
</rss>