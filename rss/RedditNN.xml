<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Wed, 22 May 2024 12:27:27 GMT</lastBuildDate>
    <item>
      <title>矢量搜索 - HNSW 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cxw7d7/vector_search_hnsw_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了分层可导航小世界（HNSW）算法的工作原理，这是矢量数据库搜索/索引的流行方法。 我希望它对你们中的一些人有用在那里。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cxw7d7/vector_search_hnsw_explained/</guid>
      <pubDate>Wed, 22 May 2024 09:35:51 GMT</pubDate>
    </item>
    <item>
      <title>图形游戏——测试你对神经网络的理解</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cxgbry/graph_game_test_your_understanding_of_neural/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cxgbry/graph_game_test_your_understanding_of_neural/</guid>
      <pubDate>Tue, 21 May 2024 19:23:32 GMT</pubDate>
    </item>
    <item>
      <title>您的 GPU 的 VRAM 是多少？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cx6mb0/what_is_the_vram_of_your_gpu/</link>
      <description><![CDATA[查看投票 &lt; /div&gt;  由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cx6mb0/what_is_the_vram_of_your_gpu/</guid>
      <pubDate>Tue, 21 May 2024 12:25:13 GMT</pubDate>
    </item>
    <item>
      <title>所以我用 C 创建了一个简单的神经网络 - 第 2 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cx5jt9/so_i_created_a_simple_neural_network_in_c_part_2/</link>
      <description><![CDATA[我之前发布了一篇关于创建简单神经网络的文章：https://old.reddit.com/r/C_Programming/comments/1csjkuz/so_i_created_a_simple_neural_network_in_c/ 现在，我已经完成了错误修复，代码似乎与每日措丁相比，能够正确工作。 https://pastebin.com/X5BXz7iX 以下是供人们验证的示例输入和输出： 示例输出和门 输入数量：2 行：8 输出数量：1 初始成本：0.474202 最终成本：0.000104 ti[0]: 0.000000 ti[1]: 0.000000 NN: 0.000909 ti[2 ]: 0.000000 ti[3]: 1.000000 NN: 0.010387 ti[4]: 1.000000 ti[5]: 0.000000 NN: 0.010470 ti[6]: 1.000000 ti[7]: 1.000000 NN: 0.985895 或门 输入数量: 2 行: 8 输出数量: 1 初始成本:0.178242 最终成本:0.000134 ti[0]: 0.000000 ti[1]: 0.000000 NN: 0.017959 ti[2]: 0.000000 ti[3]: 1.000000 NN: 0.990073 ti[4]: 1.000000 ti[5]: 0.000000 NN: 0.989876 ti[6]: 1.000000 ti[7]: 1.000000 NN: 0.996675 异或门 输入数量: 2 行: 8 输出数量: 1 初始成本:0.334069 最终成本:0.000298 ti[ 0]: 0.000000 ti[1]: 0.000000 NN: 0.019019 ti[2]: 0.000000 ti[3]: 1.000000 NN: 0.983565 ti[4]: 1.000000 ti[5]: 0.000000 NN: 0.983540 ti[6] : 1.000000 钛[7]: 1.000000 NN: 0.017053 加法器初始成本:0.722847 最终成本:0.001003 ti[0]: 0.000000 ti[1]: 0.000000 NN: 0.000128 0.033483 ti[2]: 0.000000 ti[3]: 1.0 00000 NN: 0.022985 0.978335 ti [4]: 1.000000 ti[5]: 0.000000 NN: 0.023032 0.978289 ti[6]: 1.000000 ti[7]: 1.000000 NN: 0.970122 0.999995  欢迎所有反馈和建议。&lt; /p&gt;   由   提交/u/GovtOfficer420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cx5jt9/so_i_created_a_simple_neural_network_in_c_part_2/</guid>
      <pubDate>Tue, 21 May 2024 11:26:57 GMT</pubDate>
    </item>
    <item>
      <title>使用人工神经网络预测对流风暴的新研究。该预测模型是针对瑞士气象局雷暴跟踪系统量身定制的，可以预测对流单元路径、雷达反射率（风暴强度的代表）和区域。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cwr4d5/new_study_on_the_forecasting_of_convective_storms/</link>
      <description><![CDATA[   /u/_Mat_San_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cwr4d5/new_study_on_the_forecasting_of_convective_storms/</guid>
      <pubDate>Mon, 20 May 2024 21:34:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么神经网络在生命游戏中挣扎</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cvj4so/why_neural_networks_struggle_with_the_game_of_life/</link>
      <description><![CDATA[   /u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cvj4so/why_neural_networks_struggle_with_the_game_of_life/</guid>
      <pubDate>Sun, 19 May 2024 07:54:46 GMT</pubDate>
    </item>
    <item>
      <title>柯尔莫哥洛夫-阿诺德网络 (KAN) 解释：</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cvgi0m/kolmogorovarnold_networks_kans_explained/</link>
      <description><![CDATA[最近发布了一种名为 KAN 的新神经网络架构，与传统神经网络相比，它能够捕获更复杂的非线性。在这个新教程中了解数学知识以及 KAN 的工作原理：https://youtu.be/LpUP9-VOlG0?si=sNk8vUeYNX3vxVPf&lt; /a&gt;   由   提交/u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cvgi0m/kolmogorovarnold_networks_kans_explained/</guid>
      <pubDate>Sun, 19 May 2024 05:00:41 GMT</pubDate>
    </item>
    <item>
      <title>计算损失函数的梯度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cv1nqq/calculate_graident_of_loss_function/</link>
      <description><![CDATA[      考虑如下所示的神经网络。 https://preview.redd.it/p6x5cfq4t71d1.png?width=1114&amp;format=png&amp;auto=webp&amp;s=29e980d9727769e2d89bb3740 52aabf055e23f39 考虑我们有一个用于二元分类的交叉熵损失函数：L=−[𝑦 ln(𝑎)+(1−𝑦) ln(1−𝑎)]，其中𝑎是输出层激活函数的概率。我们构建了网络的计算图，如下所示。下面的蓝色字母是中间变量标签，可以帮助你理解上面的网络架构图和计算图之间的联系。  当 𝑦=1 时，损失函数的 g**radient 是多少？ 𝑊11？ **将您的答案写到小数点后三位。注：请使用计算图法。可以直接使用链式规则计算梯度，但如果根本不使用计算图，则无法正确评分。尝试填写上面的红色框。这个问题不需要编码，可以很容易地通过分析得到答案。 https://preview.redd.it/1y2d9vgmn81d1.png?width=1172&amp;format=png&amp;auto=webp&amp;s=091d1657110510243e253970dc0 e1522f2edeca1 提示&lt; /p&gt; https://preview.redd。 it/3x9bpr6at71d1.png?width=1182&amp;format=png&amp;auto=webp&amp;s=ea220648ee1874a22daadb6dd719c1952516ccba   由   提交 /u/Cheemsilla   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cv1nqq/calculate_graident_of_loss_function/</guid>
      <pubDate>Sat, 18 May 2024 16:53:52 GMT</pubDate>
    </item>
    <item>
      <title>如何微调预训练模型以生成特定于角色的回复？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ctsa9p/how_to_finetune_a_pretrained_model_for/</link>
      <description><![CDATA[大家好， 我正在开发一个 NLP 项目，我需要从基于电视节目的角色生成回复对于给定的输入句子或问题，我是一个完全的初学者，但我对 NLP 最常见的主题有基本的了解。我有一个由各种角色的对话台词组成的数据集。我的目标是微调预训练的语言模型，以便它可以生成这些角色风格的响应。我的问题是如何使 llm 接受 2 个输入，或者如何将所需的字符嵌入到输入中。我的下一步应该是什么？   由   提交/u/confusedvampy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ctsa9p/how_to_finetune_a_pretrained_model_for/</guid>
      <pubDate>Fri, 17 May 2024 00:29:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在足球领域的应用</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1csor2q/ai_in_soccer/</link>
      <description><![CDATA[在欧洲冠军联赛决赛之前，OpenCV.ai 团队观察了足球中 CV 实施的一些重要用例。在这篇文章中，您将了解计算机视觉技术如何使足球中的人工智能成为现代比赛的重要方面。    由   提交 /u/Correct_Jackfruit744   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1csor2q/ai_in_soccer/</guid>
      <pubDate>Wed, 15 May 2024 16:16:10 GMT</pubDate>
    </item>
    <item>
      <title>可验证顺序决策中的多模态、预训练模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cs7j01/multimodal_pretrained_models_in_verifiable/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cs7j01/multimodal_pretrained_models_in_verifiable/</guid>
      <pubDate>Wed, 15 May 2024 00:17:28 GMT</pubDate>
    </item>
    <item>
      <title>奇异值分解 (SVD) 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cs0gxi/singular_value_decomposition_svd_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cs0gxi/singular_value_decomposition_svd_explained/</guid>
      <pubDate>Tue, 14 May 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>从扫描的书籍中提取单词：使用 Python 和 OpenCV 的分步教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1crt9zh/extracting_words_from_scanned_books_a_stepbystep/</link>
      <description><![CDATA[      https://preview.redd.it/4qzf5zcphe0d1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=0494bdeed742fb0 1f1c3884da549873e7eacd696  我们的视频教程将向您展示如何从扫描的书页中提取单个单词，并为您提供从任何书籍中提取所需文本所需的代码。 我们将引导您完成整个过程，从将图像转换为灰度并应用阈值处理，到使用 OpenCV 函数检测文本行并按其在页面上的位置对它们进行排序。 您将能够轻松提取扫描文档中的文本并执行分词。   在此处查看我们的视频：https://youtu .be/c61w6H8pdzs&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg  代码链接：https://github.com/feitgemel/Open-CV/tree/main/Words-Segmentation   享受， Eran   ImageSegmentation #PythonOpenCV #ContourDetection #ComputerVision #AdvancedOpenCV #extracttext #extractwords   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1crt9zh/extracting_words_from_scanned_books_a_stepbystep/</guid>
      <pubDate>Tue, 14 May 2024 14:17:08 GMT</pubDate>
    </item>
    <item>
      <title>Transformers 能在多大程度上模拟上下文中的牛顿法？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1crno5x/how_well_can_transformers_emulate_incontext/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2403.03183 代码：https://anonymous.4open.science/r/transformer_higher_order-B80B/ 摘要：  基于 Transformer 的模型已经展示了卓越的上下文学习能力，促使人们对其底层机制进行了广泛的研究。最近的研究表明，Transformer 可以为上下文学习实现一阶优化算法，甚至可以为线性回归的情况实现二阶优化算法。在这项工作中，我们研究了 Transformers 是否可以执行超出线性回归情况的高阶优化方法。我们确定具有 ReLU 层的线性注意 Transformers 可以近似逻辑回归任务的二阶优化算法，并且仅使用对数级的误差更多层来实现 ϵ 误差。作为副产品，我们展示了即使是仅使用线性注意的 Transformers 也能够仅使用两层来实现矩阵求逆的牛顿迭代的单步能力。这些结果表明 Transformer 架构能够实现复杂的算法，而不仅仅是梯度下降。    [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1crno5x/how_well_can_transformers_emulate_incontext/</guid>
      <pubDate>Tue, 14 May 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>这里的研究员和安的初学者是matlab的神经网络训练算法名称在pytorch中是一样的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1cr3m0u/researcher_here_and_a_beginner_in_ann_are_matlabs/</link>
      <description><![CDATA[是 matlab 中神经网络的训练算法，如 levenberg–Marquardt、贝叶斯正则化和缩放共轭梯度训练算法，它们在 pytorch 中可用，还是在不同的环境下名字？我没有像其他研究机构那样有钱买 matlab，但我会使用 pytorch + 抱歉这个菜鸟问题   由   提交 /u/callmetopperwithat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1cr3m0u/researcher_here_and_a_beginner_in_ann_are_matlabs/</guid>
      <pubDate>Mon, 13 May 2024 16:30:26 GMT</pubDate>
    </item>
    </channel>
</rss>