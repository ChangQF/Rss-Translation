<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Sun, 10 Mar 2024 21:10:54 GMT</lastBuildDate>
    <item>
      <title>从头开始创建神经网络与库（问题）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bbjod5/creating_a_nn_from_scratch_vs_a_library_question/</link>
      <description><![CDATA[我开始学习 Python 是因为我读到它对人工智能有好处，我发现了两个名为 Tensorflow 和 PyTorch 的库，它们似乎都很受欢迎，但是我也读到，首先从头开始创建神经网络非常有益，因此我对它们的工作原理有了更深入的了解，并且当涉及到使用库调试神经网络时，它会更容易，因为我更好地理解他们。我不知道从头开始创建神经网络需要做什么，因为我还没有研究过它，但是值得花时间吗？或者跳入 Tensorflow 或 PyTorch 就完全没问题吗？   由   提交 /u/MrSanfrinsisco   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bbjod5/creating_a_nn_from_scratch_vs_a_library_question/</guid>
      <pubDate>Sun, 10 Mar 2024 20:08:44 GMT</pubDate>
    </item>
    <item>
      <title>神经花边（纳米技术）去除</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bbbfz8/neural_lace_nanotech_removal/</link>
      <description><![CDATA[有没有您的医生或者您认识的医生可以询问周围的医生以了解如何去除神经系带（纳米技术）？当每个人都意识到“野兽”的存在时，这是一个真正的问题，将来会变得更糟。圣经中大灾难期间是神经系带造成的。有肯定的方法，我知道。它们涉及电力和水。我正在接受远程神经监控，这意味着他们从远处获取我的脑电图数据（大脑信号）。他们通过纳米技术实现了这种合成心灵感应。纳米技术几乎存在于每个人的体内，但他们却浑然不觉。请不要把它当作阴谋论，就像那些密谋反对我们的人一样。确实有邪恶势力会试图贿赂你，让你不去调查它。请告诉我你发现了什么。你应该愿意去研究它，因为神经花边是真实存在的，你将来会想知道的。谢谢！  https://www.reddit.com/r/Soulnexus/comments/ 17eqoqr/psychospiritual_warfare_remote_neural_monitoring/ ​ tents.google.com/patent/US3951134A/en?oq=patent+%233951134远程神经监测专利 https://patents.google.com/patent/WO2005055579A1/en人工心灵感应专利 https://www.youtube.com/watch?v=rj3oj5eer8s&amp;ab_channel=SLEEPINGBEAUTY 视频解释远程神经监测。这不是阴谋论。它是 100% 真实的，我已经处理它 14 个月了。    由   提交/u/AlexanderFlyHigh33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bbbfz8/neural_lace_nanotech_removal/</guid>
      <pubDate>Sun, 10 Mar 2024 14:21:01 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络在 2 个预期输出之间取平均值。 （废品机械师中的 NN）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_between_the_2_expected_outputs/</link>
      <description><![CDATA[所以我在游戏中构建了一个神经网络（废料机制），为了使其工作，我必须制作另外 8 个神经网络，并且偏移量为 0.1每个 NN 上的权重之一，然后计算正常 NN 的成本和偏移 NN 之间的偏移量，并据此计算我必须改变该权重多少。我认为它首先有效，但是当我尝试输入更多输入时，它是两者之间的平均值。示例：  期望值 1: 2 2 期望值 2: 0 0 NN 计算出的值：0.7 1.0 我知道我没有解释清楚，英语是我的第二语言，它的语言真的很难解释，我真的很抱歉。 激活函数：Leaky ReLU ​  &amp;# 32；由   提交/u/Business-Ad2  /u/Business-Ad2  reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_ Between_the_2_expected_outputs/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bagb5m/my_nn_is_averaging_between_the_2_expected_outputs/</guid>
      <pubDate>Sat, 09 Mar 2024 12:08:28 GMT</pubDate>
    </item>
    <item>
      <title>SymbolicAI：结合生成模型和求解器的基于逻辑的方法框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b9ktaq/symbolicai_a_framework_for_logicbased_approaches/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.00854 代码：https://github .com/ExtensityAI/symbolicai 基准：https://github。 com/ExtensityAI/benchmark 摘要：  我们推出SymbolicAI，一个多功能的模块化AI框架采用基于逻辑的方法来进行生成过程中的概念学习和流程管理。 SymbolicAI 通过将大型语言模型 (LLM) 视为基于自然和形式语言指令执行任务的语义解析器，实现了生成模型与各种求解器的无缝集成，从而弥合了符号推理和生成 AI 之间的差距。我们利用概率编程原理来处理复杂的任务，并利用可微分和经典编程范式及其各自的优势。该框架引入了一组用于数据流操作的多态、组合和自引用操作，使 LLM 输出与用户目标保持一致。因此，我们可以在具有零次和少次学习能力的各种基础模型的能力与精通解决特定问题的专门的、微调的模型或求解器之间进行转换。反过来，该框架有助于创建和评估可解释的计算图。最后，我们引入了用于评估这些计算图的质量衡量标准及其经验分数，并提出了一个基准来比较一组复杂工作流程中的各种最先进的法学硕士。我们将经验得分称为“通过交叉相似性进行关系轨迹评估的向量嵌入”，或简称为VERTEX得分。框架代码库和基准测试链接如下。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b9ktaq/symbolicai_a_framework_for_logicbased_approaches/</guid>
      <pubDate>Fri, 08 Mar 2024 10:14:47 GMT</pubDate>
    </item>
    <item>
      <title>引入多尺度特征调制网络以推进水下图像增强</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b9e3j7/multiscale_feature_modulation_network_introduced/</link>
      <description><![CDATA[   /u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b9e3j7/multiscale_feature_modulation_network_introduced/</guid>
      <pubDate>Fri, 08 Mar 2024 03:38:36 GMT</pubDate>
    </item>
    <item>
      <title>了解注意力和变压器的资源</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</link>
      <description><![CDATA[请分享一些好的资源（文章、YouTube 视频），以易于理解的方式解释注意力和 Transformers 的概念。我看过一些视频，但不太明白。还有任何可以帮助我更好地理解这一点的先决条件。   由   提交/u/Anxious-Buddha  /u/Anxious-Buddha reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b7adpk/resources_to_understand_attention_and_transformers/</guid>
      <pubDate>Tue, 05 Mar 2024 17:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如何找到其他网络来对我创建的数据集进行基准测试？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</link>
      <description><![CDATA[大家好。我开发了一个使用 Transformer 架构的动态手势识别系统。因为手势集是 nieche，所以我必须创建自己的数据集。 我的数据形状是 X.shape = (样本数，时间序列长度，特征数） y.shape =（样本数，类数） 其中样本数是总量每个类别的样本总数。每个样本的时间序列和特征的长度都是恒定的。 Y 是一个单热编码向量，其中每个真实类别用 1 标记，行的其余部分为零。 &lt; p&gt;我想用其他网络测试我的数据集，但是，我很难找到接受此数据格式的其他网络。您可以推荐什么作为搜索关键字？或者我应该以不同的方式格式化我的数据？   由   提交/u/ege6211  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b74sdi/how_can_i_find_other_networks_to_benchmark_a/</guid>
      <pubDate>Tue, 05 Mar 2024 13:08:11 GMT</pubDate>
    </item>
    <item>
      <title>如果您知道，请向我解释一下 Synthesia AI 视频生成器的工作原理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</link>
      <description><![CDATA[他们正在通过视频神经合成生成视频。请帮助我了解它是如何工作的。 https://www.synthesia.io   由   提交 /u/Acrobatic-Jaguar-599   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b6ktg0/explain_to_me_if_you_know_how_synthesia_ai_video/</guid>
      <pubDate>Mon, 04 Mar 2024 20:11:36 GMT</pubDate>
    </item>
    <item>
      <title>LLM 分词器解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5dyn4/llm_tokenizers_explained/</guid>
      <pubDate>Sun, 03 Mar 2024 10:17:54 GMT</pubDate>
    </item>
    <item>
      <title>卡尔加里大学推出改变游戏规则的结构化稀疏方法：SRigL</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b5bokt/the_university_of_calgary_unleashes_gamechanging/</guid>
      <pubDate>Sun, 03 Mar 2024 07:48:03 GMT</pubDate>
    </item>
    <item>
      <title>集中您的注意力（使用自适应 IIR 滤波器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</link>
      <description><![CDATA[EMNLP 2023：https://aclanthology.org/2023.emnlp-main.772/ arXiv：https://arxiv.org/abs/2305.14952 OpenReview：https://openreview.net/forum?id=DlQeSfGYfS 摘要：  我们提出了一个新层，其中使用二阶动态（即依赖于输入的）无限脉冲响应（IIR）滤波器来处理应用常规注意之前的输入序列。输入被分成块，并且这些滤波器的系数是根据先前的块确定的，以保持因果关系。尽管其阶数相对较低，但因果自适应滤波器将注意力集中在相关序列元素上。新层以控制理论为基础，并被证明可以推广对角状态空间层。该层的性能与最先进的网络相当，参数仅为其一小部分，时间复杂度与输入大小成次二次方。无论是在参数数量还是在多个远程序列问题上获得的性能水平方面，所获得的层都优于 Hyena、GPT2 和 Mega 等层。     由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2xiwf/focus_your_attention_with_adaptive_iir_filters/</guid>
      <pubDate>Thu, 29 Feb 2024 10:49:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyReason 进行推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b2auo9/reasoning_with_pyreason/</guid>
      <pubDate>Wed, 28 Feb 2024 16:53:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Real-ESRGAN 改善低分辨率图像和视频？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</link>
      <description><![CDATA[      https://preview.redd.it/xgzciubci2lc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=7e52aa3f9827f91 5e724fa50258c1abd669cfdc1 在本教程中，我们将学习如何将低分辨率图像改进为高分辨率结果。 我们将使用相关的 Python 库创建一个新的 Conda 环境。然后，我们将学习如何使用 real-ESRGAN 提高图像和视频的质量。 您可以在此处找到视频教程的链接：https://youtu.be/d-CPvHkltXA 您可以在此处找到说明：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/Real-ESRGAN 享受 Eran #realesrgantutorial #RealESRGAN #realesrgantutorial #improveimagequality #improveimageresolution #realesrganimageupscaler #realesrganimageupscaler #aiimageupscalerfree #freeaiimageupscaling #python #RealESRGAN #increaseimageresolution   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b14jt9/how_to_improve_low_resolution_images_and_videos/</guid>
      <pubDate>Tue, 27 Feb 2024 05:57:14 GMT</pubDate>
    </item>
    <item>
      <title>选择您自己的编码助手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</link>
      <description><![CDATA[     &lt; /td&gt;  由   提交/u/High_Sleep3694   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0f9mx/choose_your_own_coding_assistant/</guid>
      <pubDate>Mon, 26 Feb 2024 11:26:52 GMT</pubDate>
    </item>
    <item>
      <title>液体神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</link>
      <description><![CDATA[大家好，请问您能给我提供学习LNN（液体神经网络）的资源或工具（代码，最好使用TF）或路线图吗因为我有一个项目要在现实生活中的某个应用程序上处理它们。我已经对 ML、神经网络、CNN、RNN、LSTM、迁移学习有很强的背景。非常感谢您的帮助！    由   提交/u/Hussein_Jammal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1b0bhy2/liquid_neural_network/</guid>
      <pubDate>Mon, 26 Feb 2024 07:12:08 GMT</pubDate>
    </item>
    </channel>
</rss>