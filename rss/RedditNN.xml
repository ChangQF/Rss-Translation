<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Sat, 24 Feb 2024 09:11:47 GMT</lastBuildDate>
    <item>
      <title>超参数调整：网格搜索与随机搜索</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ayc7dp/hyperparameters_tuning_grid_search_vs_random/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ayc7dp/hyperparameters_tuning_grid_search_vs_random/</guid>
      <pubDate>Fri, 23 Feb 2024 21:24:48 GMT</pubDate>
    </item>
    <item>
      <title>像我 5 岁一样解释扩散模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ayc6fd/explain_diffusion_models_like_im_5/</link>
      <description><![CDATA[有人可以帮助我理解扩散模型吗？我已经快到了，但还没有完全实现。 我知道您拍摄一张图像，逐步为其添加噪点，然后从中去除一些噪点，并以稍少的噪点重复此操作，直到您知道要添加多少噪点。删除即可得到原始图像。我还了解到，您可以在其中添加文本编码以创建文本标题和生成的图像之间的相关性。但是如何生成图像？ 当我提供提示时，反向扩散模型是否给出了一组全新的、完全随机的噪声？然后利用如何去除噪声的先验知识来获得图像？ 如果是这样，语义从哪里出现并带有以前从未见过的提示？我隐约了解 U-net 以及如何从中生成语义和掩码，但是它在扩散过程中的哪个位置？ TYIA!! &lt;!-- SC_ON - -&gt;  由   提交/u/Alternative_Leg_3111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ayc6fd/explain_diffusion_models_like_im_5/</guid>
      <pubDate>Fri, 23 Feb 2024 21:23:45 GMT</pubDate>
    </item>
    <item>
      <title>图像分割神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1axwssm/image_segmentation_neural_network/</link>
      <description><![CDATA[大家好，我第一次发帖，我有一个问题：我可以采用语义神经网络并将其更改为现在有一个注意力块吗？就像是否有一个已知的程序可以将一个图像的神经网络更改为另一个图像+其显着图的神经网络？ 这是为了比较，以了解注意块对分割的总体结果。   由   提交/u/karimredditor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1axwssm/image_segmentation_neural_network/</guid>
      <pubDate>Fri, 23 Feb 2024 09:54:02 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习进行动物行为识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1axaavl/animal_behavior_recognition_using_machine_learning/</link>
      <description><![CDATA[我希望您能很好地找到这篇文章。来自 文章 a href=&quot;http://OpenCV.ai&quot;&gt;OpenCV.ai 回顾了动物行为识别和动物姿势检测中的关键人工智能方法，展示了它们在从神经生物学到兽医学等领域的应用。此外，它还强调了最近科学进步在理解和管理动物行为方面的重要性。 在本文中，您将了解：  深入理解行为识别学习 深度学习动物姿态识别方法 动物行为识别技术 基于深度学习的应用示例  完整文章位于此处.   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1axaavl/animal_behavior_recognition_using_machine_learning/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1axaavl/animal_behavior_recognition_using_machine_learning/</guid>
      <pubDate>Thu, 22 Feb 2024 16:16:38 GMT</pubDate>
    </item>
    <item>
      <title>将涂鸦变成多个视图</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ax3nqr/turning_a_doodle_into_multiple_views/</link>
      <description><![CDATA[嗨，有什么办法可以将涂鸦变成同一对象的多个视图吗？ （图片） 很像 https://github.com/alexjc/neural-doodle 但生成多个我画的一些物体的视图。  谢谢！   由   提交/u/Specialist_Ice_5715   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ax3nqr/turning_a_doodle_into_multiple_views/</guid>
      <pubDate>Thu, 22 Feb 2024 10:53:00 GMT</pubDate>
    </item>
    <item>
      <title>构建神经网络 - Python 还是 Java？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ax28bo/building_neural_network_python_or_java/</link>
      <description><![CDATA[你好， ​ 我想从头开始构建一个神经网络，不张量流没什么，要深入了解神经网络。 ​ 问题是：我要用哪种语言来做？ 我的项目将在 Minecraft 上制作，它仅使用 Java 语言，但我觉得用 python 制作神经网络更容易。但我不知道我是否能够使用 python 访问所有数据。 ​ 你觉得怎么样？    由   提交 /u/SpellGlittering1901   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ax28bo/building_neural_network_python_or_java/</guid>
      <pubDate>Thu, 22 Feb 2024 09:19:16 GMT</pubDate>
    </item>
    <item>
      <title>由光构成的神经网络：研究团队开发光纤人工智能系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1awtgws/neural_networks_made_of_light_research_team/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1awtgws/neural_networks_made_of_light_research_team/</guid>
      <pubDate>Thu, 22 Feb 2024 01:15:55 GMT</pubDate>
    </item>
    <item>
      <title>简单的 JavaScript 代码可以帮助士兵和平民检测和躲避无人机袭击和敌方入侵者（准备立即部署）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1awj5fm/simple_javascript_code_that_could_help_soldiers/</link>
      <description><![CDATA[​ 两个利用对象检测的 JavaScript 项目。一种方法是使用简单的代码来帮助检测敌方无人机。另一个使用简单的代码可以帮助检测敌方士兵。这两个应用程序都可以立即部署 https://www.academia.edu/115181929/Aerial_Object_Detection_updated_for_combat_deployment_  等待模型加载，然后单击按钮启用网络摄像头 - 此时它将变得可见并可供使用。当找到空中物体时，应用程序会发出蜂鸣声。空中物体在您附近盘旋的时间越长，蜂鸣声就越长。对于士兵来说，这可能意味着无人机正在瞄准他们。理想情况下，士兵可以在手机上使用该应用程序，并将该设备连接到车辆的顶部区域或在战壕中睡觉时连接到身体上。请记住，必须取出 SIM 卡，并且手机无线连接必须保持“关闭”状态。在战斗环境中。在部署之前，士兵应该连接到 WiFi 并启动应用程序。应用程序启动后，士兵可以在部署到战区时禁用 WiFi 并保持应用程序运行。为了在战斗中检测空中物体，安卓手机应安装在背包顶部或头盔顶部。在民用环境中，打开无线功能的手机可以放置在屋顶上。通过互联网连接，用户可以通过 facebook live 远程查看空中场景 https:// www.academia.edu/115225324/Intruder_Detection_App_urban_warfare_and_counter_insurgency_with_Javascript 等待模型加载，然后单击按钮启用网络摄像头，此时它将变得可见以供使用。当检测到入侵者时，应用程序会发出蜂鸣声。该应用程序还会发出语音警报，说“检测到入侵者”。当检测到入侵者时。该应用程序允许手机安装在不同的地方，它可以检测到入侵者何时在该区域。这可以用于清理和反叛乱行动。这对于平民在城市环境中对抗暴徒和其他犯罪分子也很有用。该应用程序可以防止伏击攻击。手机可以放置在墙壁的裂缝和其他隐蔽的位置。通过互联网连接，用户可以通过 facebook live 远程查看场景，并查看入侵者何时获得未经授权的访问。   由   提交 /u/AnthonyofBoston   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1awj5fm/simple_javascript_code_that_could_help_soldiers/</guid>
      <pubDate>Wed, 21 Feb 2024 18:19:33 GMT</pubDate>
    </item>
    <item>
      <title>CNN 中激活层的反向传播</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aw2874/backpropagation_for_activation_layer_in_cnn/</link>
      <description><![CDATA[您好，我正在尝试在 CNN 上学习和实现反向传播。我理解大部分方程，但我还没有找到激活层的方程。如果我理解正确的话，它是Conv层-激活-池化。我得到了池化和卷积层的方程，但我不确定激活情况。如果您可以向我展示任何资源或实际的方程式，那将会有很大帮助，谢谢。   由   提交/u/MobileOk8440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aw2874/backpropagation_for_activation_layer_in_cnn/</guid>
      <pubDate>Wed, 21 Feb 2024 03:49:09 GMT</pubDate>
    </item>
    <item>
      <title>基于某个示例生成动画的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1avphyo/a_neural_network_to_generate_animations_based_on/</link>
      <description><![CDATA[您好！我正在制作一个带有大量非常相似的动画的视频游戏。例如：一个 2D 人向右跳 2 米。是否有一个神经网络可以根据之前的动画创建一个这个家伙向右跳跃 3 米的动画？ 谢谢！   由   提交 /u/SomethingsAwesome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1avphyo/a_neural_network_to_generate_animations_based_on/</guid>
      <pubDate>Tue, 20 Feb 2024 18:52:57 GMT</pubDate>
    </item>
    <item>
      <title>使用在 msnit 数据集上训练的神经元网络无法识别自己的数字</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1avjpj8/having_trouble_recognizing_my_own_digits_with_a/</link>
      <description><![CDATA[我真的不明白我做错了什么，我的图像与 Mnist 数据集中的图像具有相同的形状（28,28），当我用 plt.imshow(img_flat) plt.show() 展示它们，它们看起来完全一样，但几天来我不明白为什么我的图像无法识别，数据集中的图像...我做了一个 YT 教程，但完全相同的代码对我不起作用... #My own data model = tf.keras.models.load_model(“手写.model”)  img = cv2.imread(“Digits/digit11.png”) grey = cv2.cvtColor(img, cv2 .COLOR_BGR2GRAY) # grey = tf.keras.utils.normalize(gray, axis=1) img_flat = grey.reshape(28, 28) # 形式 (1, 784) 预测= model.predict(np.expand_dims(img_flat, axis=0)) print(f&quot;这个数字可能是 {np.argmax(prediction)}&quot;)  #MNIST Data  Prediction = model.predict(np.expand_dims(x_train[27], axis=0)) print(f&quot;这个数字可能是 {np.argmax(prediction)}&quot;) /&gt; 这是我的代码，mnsit 中的所有数字都可以完美识别... 非常感谢任何帮助...    ;由   提交/u/xXSavardoXx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1avjpj8/having_trouble_recognizing_my_own_digits_with_a/</guid>
      <pubDate>Tue, 20 Feb 2024 15:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用带有 kmeans 的句子嵌入模型逐渐增加 CPU 负载</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1avcvsf/gradually_increasing_cpu_load_on_using_sentence/</link>
      <description><![CDATA[我有一个基于 ML 的生产应用程序，使用 Flask，使用 Gunicorn Workers 部署在 GCP 服务器上。在每个传入请求中，都会收到一个文本句子。 它使用句子转换器（All-MiniLM-L6-v2 模型），该模型会全局加载一次，以创建嵌入传入文本，然后使用预先训练的 kmeans（也全局加载）来预测/将其映射到意图集群。基本上，目标是找到句子的意图。 我有足够的资源，请求的数量也恒定，文本也相似，但每天CPU负载都在逐渐增加。第一天的平均响应时间约为 200 毫秒，10 天后现在为 400 毫秒。 我尝试在代码本身中使用“del”命令删除嵌入变量，同时还强制 python 垃圾收集器在主进程执行完成后执行的线程中使用“gc.collect()”，但问题仍然出现。 我注意到的一件事是，如果我不使用 del 和 gc。收集（）后，RAM开始逐渐下降。对于这两种情况，RAM 是恒定的，但现在 CPU 使用率每天都在逐渐增加，因此负载和响应时间也随之增加。 我花了数周的时间在这个问题上尝试调试它，但没有找到解决方案，如有任何帮助，我们将不胜感激。   由   提交/u/Devinco001  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1avcvsf/gradually_increasing_cpu_load_on_using_sentence/</guid>
      <pubDate>Tue, 20 Feb 2024 08:34:56 GMT</pubDate>
    </item>
    <item>
      <title>二值化神经网络简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1auncw7/intro_to_binarized_neural_networks/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1auncw7/intro_to_binarized_neural_networks/</guid>
      <pubDate>Mon, 19 Feb 2024 13:31:48 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可训练性的边界是分形的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aulcsw/the_boundary_of_neural_network_trainability_is/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aulcsw/the_boundary_of_neural_network_trainability_is/</guid>
      <pubDate>Mon, 19 Feb 2024 11:41:43 GMT</pubDate>
    </item>
    <item>
      <title>在中国，RTX 2080 Ti经过修改，将神经网络内存增加到22 GB</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aspb45/in_china_the_rtx_2080_ti_was_modified_by/</link>
      <description><![CDATA[       由   提交/u/One-Procedure-466   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aspb45/in_china_the_rtx_2080_ti_was_modified_by/</guid>
      <pubDate>Sat, 17 Feb 2024 01:10:37 GMT</pubDate>
    </item>
    </channel>
</rss>