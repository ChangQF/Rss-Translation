<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Thu, 10 Apr 2025 01:22:20 GMT</lastBuildDate>
    <item>
      <title>在LLM API中检测模型替代：验证方法的评估</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近遇到了一种用于检测LLM API中模型替代的新方法 - 本质上是检查API提供商是否正在用更便宜的替代方案交换您支付的型号。 研究人员开发了“ fingerprinting” a fingerprinting a＆quot a a＆quot a”可以通过分析精心制作的提示的响应模式来识别具有明显准确性的特定LLM的技术。 关键技术点： *他们的检测系统达到了98％+在区分主要LLM对之间的精确度 * OpenAI, Anthropic, and Cohere APIs * Substitution rates varied but reached up to 12% during some testing periods The methodology breaks down into three main steps: 1. Generating model-specific fingerprints through prompt engineering 2. Training a classifier on these distinctive response patterns 3. Systematically testing API endpoints to detect model switching I think this research has significant implications for how we interact与商业LLM API。作为与这些系统合作的人，我经常想知道我是否得到了要付费的确切模型，尤其是在性能似乎不一致的情况下。这为用户提供了一种验证他们收到的内容并使提供商负责的方法。 我认为，因此我们会看到对AI服务中透明度的更多需求。指纹技术可能会激发监视工具，这些工具可能成为需要一致，可预测的模型性能的企业API用户的标准实践。  tldr：研究人员开发了一种准确的方法来检测何时LLM API提供者何时秘密交换宣传模型。测试主要提供商表明，这种情况的发生比您想象的要多 - 当您要求GPT-4时，有时您可能会获得GPT-3.5-Turbo。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jv3i4j/detecting_model_substitution_in_llm_apis_an/</guid>
      <pubDate>Wed, 09 Apr 2025 11:30:25 GMT</pubDate>
    </item>
    <item>
      <title>减少数字神经网络的记忆大小</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在运行一个完全基于numpy构建的相当简单的神经网络，并且表现良好，但是训练有素的模型的大小相当大（＆gt; 25MB）。我的模型的参数（例如，权重，偏见等）是dtype float64的，这意味着大小为768 x 768的ndarray已经产生半MB（每条条目1字节）。  我已经阅读了有关使用float32或float16作为dtypes的信息，但是它们似乎并没有减小神经网络的记忆大小，所以我想知道还有哪些其他选项？  拥有大于25MB的型号不一定是交易破坏者，但我总是会收到“大文件”。一旦我将其推向Github，就要警告，所以我想探索是否有更多轻量级的方法可以做到这一点。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1ju7ljo/reducing_the_memory_size_size_of_a_numpy_neural_neural_neal_network/]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ju7ljo/reducing_the_memory_size_of_a_numpy_neural_network/</guid>
      <pubDate>Tue, 08 Apr 2025 07:06:50 GMT</pubDate>
    </item>
    <item>
      <title>MDS-A：用于测试时间适应的新数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32;态href =“ https://youtube.com/watch?v=MMSVSOFHNYYO＆amp; si = okj0q120f1rkbz-8”&gt; [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jtzesj/mdsa_new_dataset_for_testtime_adaptation/</guid>
      <pubDate>Mon, 07 Apr 2025 23:23:43 GMT</pubDate>
    </item>
    <item>
      <title>是真的吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  稀疏连接使输入使一组输入连接到隐藏层中的特定神经元，例如，如果您知道特定的域。但是，如果您不知道特定的域并且使其完全连接，这意味着您将所有输入连接到整个隐藏层，完全连接的网络会集中精力并尝试实现稀疏连接之类的东西吗？提交由＆＃32; /u/u/u/zestyclose-produce17     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsv9cn/is_that_true/</guid>
      <pubDate>Sun, 06 Apr 2025 14:23:40 GMT</pubDate>
    </item>
    <item>
      <title>魅力：一种多尺度令牌化方法，用于在基于VIT的美学评估中保存视觉信息</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsoaer/charm_a_multiscale_tokenization_approach_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  魅力：使用VITS  视觉变形金刚的图像美学评估的新型令牌化方法显示出对图像美学评估（IAA）的巨大希望，但是标准的预处理（resizie，crop，crop）破坏了关键的审美习惯。作者介绍了“魅力”。 a tokenization approach that selectively preserves high-resolution details in some image regions while downscaling others. Key innovations: * Selective resolution preservation: Maintains original resolution in some patches while downscaling others * Aspect ratio preservation: Works with images&#39; natural dimensions rather than forcing square crops * Multi-scale integration: Combines information from different scales via position and scale embeddings * Random patch selection: Surprisingly outperforms more sophisticated selection strategies Results across multiple datasets: * Up to 7.5% improvement in PLCC (Pearson correlation) * Up to 8.1% improvement in SRCC (Spearman相关性） *最高 14.8％分类准确性的提高 *更快的收敛性（较小的数据集上的培训时期少了50％） * *与不同的VOT体系结构（VIT-SMALL，DIV2-MALL，DINOV2-SMALL，DINOV2-LARGE）一起使用，我认为这是对ATEST的录制范围和计算机的评估方法的方法。图像中的美取决于构图，纵横比和细节的细节 - 准确的预处理销毁了哪些标准预处理。随机贴片选择效果最佳，特别有趣，这表明美学评估受益于一种数据增强形式，从而减少了模型过多地专注于显着物体的趋势。 该方法与现有VIT的兼容性无需其他预培训，而无需其他预培训使其立即有用，使其对研究人员和开发者在应用程序上的应用程序和开发者涉及涉及图像Apphicts Apps apps apps appsy appsy appsy的应用程序。   tldr ：魅力通过选择性地保留高分辨率贴片和宽高比可以增强图像美学评估的性能，随机补丁选择优于其他策略。  。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsoaer/charm_a_multiscale_tokenization_approach_for/</guid>
      <pubDate>Sun, 06 Apr 2025 07:02:20 GMT</pubDate>
    </item>
    <item>
      <title>交互式AI演示 - 可视化图像内生长的合成大脑（独立研究）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是一名独立的AI研究人员，从事两个独立但相关的实验项目。我想分享一个实时的WebGL演示，以获得反馈和好奇心。这不是商业化，不是为了游戏，而只是纯认知AI实验。  项目：神经像素AI系统 这个WebGL项目编码PNG图像中的人造大脑。目的是随着神经元从像素信息增长而来的结构和活动的出现。 每个像素编码突触或符号数据。 神经元在视觉上自我组织会随着时间的推移而自动组织。   整个系统都是确定性的，但由pseudo-eviludo-evi            href =“ https://www.dfgamesstudio.com/neural-pixel-ai-system/”&gt; https://www.dfgamesstudio.com/neural-pixel-ai-system/ 符号/认知AI架构旨在通过梦想合成，记忆衰减，情绪调节和通过一个称为“ADNσ”的系统的符号演变来模拟模块化意识。我知道这是非常规的，但我相信具有视觉逻辑的混合符号/神经系统值得探索。 谢谢！ - &gt;＆＃32;提交由＆＃32; /u/u/conanfredleseul     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jsju6y/interactive_ai_demo_visualizing_a_synthetic_brain/</guid>
      <pubDate>Sun, 06 Apr 2025 02:19:38 GMT</pubDate>
    </item>
    <item>
      <title>如何训练多视图注意模型以结合NGram和Biobert嵌入</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js9auj/how_to_train_a_multiview_attention_model_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我希望您做得很好，我正在努力构建一个多视图模型，该模型使用注意机制结合了两种类型的功能：Ngram嵌入式和Biobert Embeddings    目标是通过使用这些不同的视图来创建富裕的代表，并使用这些不同的视图来创建富裕的表示。但是，我不确定如何构建训练过程，以便注意力机制学会从每个视图中有意义地对齐功能。我的意思是，我不能直接直接在标签上训练它，因为这就像在分类任务上训练常规的MLP有没有人从事类似方向的工作？ 我还没有尝试过任何具体的事情，因为我仍然对如何接近培训这种基于注意力的多视觉模型感到困惑。我不确定目标应该是什么以及如何使其学习有意义的注意力。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/connect-courage6458     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js9auj/how_to_train_a_multiview_attention_model_to/</guid>
      <pubDate>Sat, 05 Apr 2025 17:54:58 GMT</pubDate>
    </item>
    <item>
      <title>有人可以回答吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js5r4n/anyone_can_answer_that/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   如果有3个输入，我有3个隐藏的层，例如，一个神经元将取得所有3个输入，但增加了2个输入的权重，而不是第三个输入，而第二个神经元则关注第二和第三个输入的重量和第二个输入的重量和重新量的重量，也是第二个NEROR的重量。这是正确的吗？或神经网络中的神经元。例如，如果您有3个输入（x1，x2，x3），则一个感知器可能会集中在第一个和第三个输入（x1和x3）上（x1和x3），并给予它们高权重（例如，0.9和0.8），而将第二个输入（x2）给出了非常小的重量或零重量（例如，0.1或0）。同时，另一个感知者可能会专注于第二和第三个输入（x2和x3），从而使它们具有很高的权重（例如，0.7和0.9），并减少了第一个输入（x1）的重量（x1），以接近零。提交由＆＃32; /u/u/u/zestyclose-produce17     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js5r4n/anyone_can_answer_that/</guid>
      <pubDate>Sat, 05 Apr 2025 15:17:31 GMT</pubDate>
    </item>
    <item>
      <title>有人真的知道NLP是如何工作的吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1js1igr/does_anyone_actually_know_how_nlp_works/</link>
      <description><![CDATA[    src =“ https://preview.itd.it/89rqqg5n60te1.png？ NLP有效????? /&gt;    &lt;！ -  sc_off-&gt;   01   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/poopo-hitshit       [注释] ] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1js1igr/does_anyone_actually_know_how_nlp_works/</guid>
      <pubDate>Sat, 05 Apr 2025 11:38:58 GMT</pubDate>
    </item>
    <item>
      <title>用于增强扩散模型控制的频率指导缩放</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jrxv14/frequencydecomposed_guidance_scaling_for_enhanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   fresca是一种开创性的方法，可以通过作者所说的“缩放空间”来理解和操纵扩散模型。通过分析扩散模型如何自然地在deno的过程中在各个时间步处缩放不同的特征，他们发现了一种固有的结构，可以在不进行其他培训的情况下进行精确的图像编辑。   的关键技术贡献包括：   发现，在整个范围中 实现了与任何预验证的扩散模型一起使用的实施，而无需进行微调或其他网络 在多个图像操作任务中进行最新的结果结果，包括颜色调整，样式传输和本地编辑，包括   extripers offiel offief offief interfusion   extife extirals extirals extrips extress（类似于范围），这些方法是不同的，这些方法是差异的，这些绘制了范围不同的图像（范围差异）（ - something that&#39;s been present but untapped in these models until now. The results are impressive across various manipulation tasks: * Color manipulation: Changing color schemes while preserving textures and object identities * Style transfer: Applying styles to specific objects without affecting others * Local editing: Making precise changes to targeted areas while keeping the rest of the image intact * 一致的优势：在保持有针对性的更改的同时，在保存图像身份方面胜过现有技术   技术实施涉及计算每个时间段的模型输出与输入之间的比率与识别缩放因素，然后将目标调整应用于这些因素以修改特定属性。弗雷斯卡（Fresca）没有将它们视为黑匣子，而是揭示了它们具有内部结构，可以反映人类如何层次处理视觉信息。这可能会导致图像生成和编辑工具中更直观，更精确的控制。 我认为最令人兴奋的方面是，这种功能始终存在于扩散模型中，但只需要正确理解和利用。 It suggests there may be other untapped capabilities in these models we haven&#39;t yet discovered. The limitations around model dependency and the somewhat empirical process for identifying optimal timesteps for specific manipulations will need to be addressed in future work. TLDR: FreSca discovers and manipulates an inherent &quot;scaling space&quot;在扩散模型中，在不同的时间段上处理不同的图像特征，在没有其他培训的情况下进行精确的图像编辑。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jrxv14/frequencydecomposed_guidance_scaling_for_enhanced/</guid>
      <pubDate>Sat, 05 Apr 2025 07:14:55 GMT</pubDate>
    </item>
    <item>
      <title>努力在医学成像中选择正确的CNN XAI方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jqyfov/struggling_to_pick_the_right_xai_method_for_cnn/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   嘿，大家！&lt; /strong&gt; 我正在撰写论文，以使用可解释的AI（XAI）与CNN进行肺炎检测。 The goal is to make model predictions more transparent and trustworthy—especially for clinicians—by showing why a chest X-ray is classified as pneumonia or not. I’m currently exploring different XAI methods like Grad-CAM, LIME, and SHAP, but I’m struggling to decide which one best explains my model’s decisions. Would love to hear your thoughts or experiences with XAI in医学成像。任何建议或见解都将非常有帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/divedent-Ad914     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jqyfov/struggling_to_pick_the_right_xai_method_for_cnn/</guid>
      <pubDate>Fri, 04 Apr 2025 00:07:10 GMT</pubDate>
    </item>
    <item>
      <title>ROR BENCH：评估语言模型对朗诵的敏感性与基本问题的推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jqfevt/rorbench_evaluating_language_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项新研究引入了 ror bench （对推理基准的朗诵），旨在测试语言模型是通过问题还是简单地背诵记忆的模式。研究人员创建了1,500个小学数学问题，具有测试相同概念但可以简单的模式匹配的变化。 关键发现： * GPT-4，Claude 3 Opus和Gemini 1.5 Pro在标准问题上表现出明显更好的性能，而在标准问题上，与在相同的概念上进行了相同的概念相比，与78.5％的质量相比，均为7.5％compliatiation * 1％，但仅在78.5％上均可遵循7.5％的质量。不同的数学操作和模型类型 *经过思考的链条促使性能提高了，但并没有消除与“反事实”变化最大的推理差距 *模型。 - 看起来类似于培训示例但需要不同推理的问题 我认为这项研究突出了当前LLM的基本限制，在典型评估中很容易错过。解决标准问题和变化之间的差距表明这些模型不是发展真正的数学理解，而是利用模式识别。这可以解释为什么在实际推理任务中部署LLM经常会导致意外的失败 - 他们缺乏人类发展的灵活推理能力。 我认为这对我们如何处理AI安全和能力研究有影响。如果即使是小学的数学问题也揭示了推理中的这种脆弱性，我们应该对声称单独扩展会产生强大的推理能力非常谨慎。更多地关注专门设计用于建立真正理解的新型体系结构或训练方法似乎是必要的。  tldr：领先的LLM（GPT-4，Claude，gemini）在标准数学问题上表现良好，但在测试相同概念的变化方面，表明他们依靠记忆，而不是真实的推理。 href =“ https://aimodels.fyi/papers/arxiv/recitation-erecitation-over-reasoning-how-cutting-denguage”&gt;完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jqfevt/rorbench_evaluating_language_models/</guid>
      <pubDate>Thu, 03 Apr 2025 11:00:17 GMT</pubDate>
    </item>
    <item>
      <title>通过注意力图训练4D场景重建</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jpmdcu/trainingfree_4d_scene_reconstruction_via/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近读了一篇论文，该论文介绍了一种从无需任何培训的情况下从视频中提取3D运动的方法。该方法称为EASI3R，建立在DUST3R（一种从图像对创建3D场景结构的模型），并添加后处理以将相机运动与对象运动分开。 关键见解使用几何约束，而不是从数据中学习。这是通过分析框架之间的点对应关系和使用RANSAC来确定属于静态背景与移动对象的点的对应关系的。    主要技术贡献：   使用dust3r使用dust3r来提取3D点对应关系在框架之间提取框架    li&gt; li li li li fire n olim li fimit  轨迹在多个框架上跟踪时间一致性的点 簇按运动模式通过运动模式来处理多个移动对象 需要在运动数据集中进行零培训或进行微调。 benchmarks Works on complex real-world scenes with multiple independent objects Functions with as few as two frames but improves with longer sequences Shows robustness to challenges like occlusions and lighting changes Maintains DUSt3R&#39;s capabilities while adding motion analysis  I think this approach could be particularly valuable for robotics and在没有广泛培训数据的情况下，需要在新环境中了解运动的自主系统。区分与摄像机运动的能力是导航和互动的基础。 我也认为这是对“大量数据上的“火车”的有趣反击”。趋势，表明几何理解在计算机视觉中仍然具有重要位置。它表明将几何约束与学习的特征结合在一起的混合方法可能是一个富有成果的方向。    tldr： easi3r提取物通过在dust3r上构建和使用几何约束来从视频中进行3D运动，并使用几何约束来将摄像机运动与对象运动分开 - 没有任何训练。 href =“ https://aimodels.fyi/papers/arxiv/arxiv/easi3r-estimating-disentangled-motion-motion-from-dust3r-without”&gt;完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jpmdcu/trainingfree_4d_scene_reconstruction_via/</guid>
      <pubDate>Wed, 02 Apr 2025 11:35:14 GMT</pubDate>
    </item>
    <item>
      <title>机械学检查神经网络 - 我的第一个视频，我会喜欢反馈！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jpj6j2/mechanistically_examining_neural_networks_my/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/aneesh6214      [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jpj6j2/mechanistically_examining_neural_networks_my/</guid>
      <pubDate>Wed, 02 Apr 2025 07:47:55 GMT</pubDate>
    </item>
    <item>
      <title>解开梯度下降：窥视AI的学习方式（以有趣的类比！）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1jpb56j/unpacking_gradient_descent_a_peek_into_how_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！我最近一直在深入研究AI，并想分享一种很酷的方式来思考梯度下降，这是机器学习的无名英雄之一。想象一下，您是山上蒙住眼睛的寻宝者，试图找到最低的山谷。你唯一的线索？脚下的斜率。您下坡采取很小的台阶，感觉到朝下。简而言之，这是梯度下降 -  ai的方式通过一点一点地调整参数来“感觉”更好地预测。 我从我一直在研究的一个项目中汲取了类比（AI概念的小指南），并陷入了我的困扰。这是它如何使用数学的快速片段：您从a = 1，b = 1和学习率alpha = 0.1之类的参数开始。然后，您计算出损失（例如，预测表中的1.591），并根据梯度进行调整。太大的一步，你超越了；太小了，您永远卡住了！ 对于任何好奇的人来说，我还忽略了这与神经网络如何联系在一起，就像一个感知者如何学习AN和大门，或者像Adam这样的优化者如何平滑旅程。您最喜欢解释梯度下降的方法是什么？或者，一旦找到正确的类比，还是其他任何AI概念，它们会为您点击吗？很想听听您的想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/msahmad     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1jpb56j/unpacking_gradient_descent_a_peek_into_how_ai/</guid>
      <pubDate>Wed, 02 Apr 2025 00:12:50 GMT</pubDate>
    </item>
    </channel>
</rss>