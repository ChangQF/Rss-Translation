<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description></description>
    <lastBuildDate>Wed, 22 Jan 2025 18:22:44 GMT</lastBuildDate>
    <item>
      <title></title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</link>
      <description><![CDATA[目前，我正在研究 zenodo 中一个名为“超声图像中胎儿头部生物测量的大规模注释数据集”的数据集。我的数据集包含超声图像和相应的分割掩模。我叠加了这些图像，现在我想计算头围、双顶径等，并使用这 20 个特征进行相关性分析。但不幸的是，我没有任何领域专家。在这种情况下，如果我以 Q1 期刊为目标，我该做些什么来验证？我的数据集没有任何现有的工作！有人可以帮忙吗？    提交人    /u/Boring_Conclusion_19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</guid>
      <pubDate>Sun, 19 Jan 2025 18:09:43 GMT</pubDate>
    </item>
    <item>
      <title>大规模 AI 红队行动的实践经验和威胁模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</link>
      <description><![CDATA[本文对红队 100 种生成式 AI 产品进行了系统分析，开发了全面的威胁模型分类和测试方法。关键技术贡献是创建了一个通过实际测试识别和分类人工智能系统漏洞的结构化框架。 主要技术要点： - 开发了一个涵盖提示注入、数据提取和系统操作的攻击分类法 - 创建了结合自动和手动探测的标准化测试程序 - 记录不同人工智能架构中的攻击模式和防御机制 - 量化跨系统类型各种攻击媒介的成功率 - 映射常见的漏洞模式和防御效果 关键结果： - 80% 的测试系统显示出至少一种形式的提示注入的漏洞 - 多步骤攻击比单步骤攻击更为成功 - 系统对相同攻击的响应根据提示构造而有很大差异 - 手动测试发现的漏洞比自动化方法多 2.3 倍 - 结合多种攻击媒介时防御效果降低了 35% 我认为这项工作为理解大规模人工智能系统漏洞提供了重要基础。虽然之前已经进行过单独的红队测试，但拥有 100 个系统的数据使我们能够识别在小型研究中无法发现的系统弱点和模式。 我认为该方法可以成为 AI 安全测试的标准框架，尽管 AI 发展的快速步伐意味着特定的攻击媒介需要不断更新。关于手动测试有效性的发现表明我们不能仅仅依赖自动化安全措施。 TLDR：对 100 个 AI 系统的红队测试的分析揭示了常见的漏洞模式并建立了系统安全测试的框架。手动测试优于自动化方法，多向量攻击显示出更高的成功率。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</guid>
      <pubDate>Thu, 16 Jan 2025 14:35:28 GMT</pubDate>
    </item>
    <item>
      <title>通过选择性权重矩阵更新实现动态 LLM 自适应：特定任务的自适应框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</guid>
      <pubDate>Wed, 15 Jan 2025 13:36:40 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</link>
      <description><![CDATA[高中时我接到一个小任务 - 制作一个小型神经网络进行图像分类。我用 VGG 和小型数据库（大约 2k 张图像）制作了它。一切都很顺利，直到它（神经网络）开始对测试数据做出奇怪的预测。它说测试数据集中的每一张图片都与类别 0（即人类）相关......现在我被它困住了......如果有人能帮助我，我将不胜感激并提供任何有关我的 NN 的信息    提交人    /u/Apprehensive_Tap_269   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</guid>
      <pubDate>Tue, 14 Jan 2025 18:52:37 GMT</pubDate>
    </item>
    <item>
      <title>SimpleGrad：一个易于理解的类 pytorch 框架实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</link>
      <description><![CDATA[      我构建了一个简单易懂的类似 PyTorch 的框架，旨在作为一种学习工具，帮助理解自动求导和深度学习框架的内部工作原理。我计划将其扩展到 CNN 和 Attention 层。 我在 reddit 上发帖不多，如有任何问题，请多包涵。 – 非常感谢您的反馈和问题！    提交人    /u/T_Hansda   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</guid>
      <pubDate>Mon, 13 Jan 2025 11:10:47 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</guid>
      <pubDate>Sun, 12 Jan 2025 09:20:12 GMT</pubDate>
    </item>
    <item>
      <title>U-net 图像分割 | 如何分割图像中的人物</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</guid>
      <pubDate>Sat, 11 Jan 2025 20:46:01 GMT</pubDate>
    </item>
    <item>
      <title>代理实验室：基于法学硕士的自主科学研究框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</guid>
      <pubDate>Sat, 11 Jan 2025 14:57:31 GMT</pubDate>
    </item>
    <item>
      <title>元思维链：教授法学硕士模拟思维链背后的推理过程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</link>
      <description><![CDATA[这项工作引入了元思维链（Meta-CoT），它通过明确地模拟元推理过程（模型如何决定采取哪些推理步骤以及为什么）来扩展常规的思维链提示。关键创新是结合过程监督（跟踪推理路径）、合成数据生成和搜索算法，帮助模型学习更好的推理策略。 关键技术点：* 使用过程监督来跟踪模型如何探索不同的解决路径* 通过观察成功的推理模式生成合成训练数据* 实现指令调整和基于 RL 的优化* 开发元推理解释的验证方法* 研究跨模型大小和架构的扩展行为 结果：* 与标准 CoT 相比，模型在推理任务上表现出更好的性能* 生成的解释与人类的推理模式更加一致* 训练管道成功地将指令调整与 RL 结合起来* 框架展示了处理多种推理策略的能力* 显示模型大小和元推理能力之间的相关性 我认为这种方法可以帮助创建更透明的人工智能系统，可以更好地解释他们的决策过程。过程监督和合成数据的结合似乎是提高推理能力的一种实用方法，而不需要大量人工标记的数据。 我认为关键的挑战将是验证元推理解释的质量，并确保它们真正反映模型的内部过程，而不是事后合理化。计算开销也可能限制实际应用。 TLDR：通过结合过程监督、合成数据和搜索算法，新框架可帮助语言模型不仅学习要采取哪些推理步骤，而且还学习为什么这些步骤有意义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</guid>
      <pubDate>Fri, 10 Jan 2025 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>对我关于 GCN 的新方法进行评分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</link>
      <description><![CDATA[您好，我在 ResearchGate 上发布了关于 GCN 的新方法，其中新应用了类别理论中的熵，这提高了 %% 的测试准确率。请不要嘲笑我，祝您有美好的一天并发表评论您的想法 :))    提交人    /u/ksrio64   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</guid>
      <pubDate>Thu, 09 Jan 2025 21:59:30 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</link>
      <description><![CDATA[我遇到的最令人印象深刻的 Python 笔记本是 Marimo，我强烈建议您尝试一下。需要澄清的是，Marimo 并没有赞助我；我只是喜欢使用它！ https://docs.marimo.io/    提交人    /u/ReceptionLow2817   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</guid>
      <pubDate>Thu, 09 Jan 2025 02:07:12 GMT</pubDate>
    </item>
    <item>
      <title>NeuralSVG：文本到矢量生成的隐式表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</guid>
      <pubDate>Wed, 08 Jan 2025 20:22:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试模仿生物神经元的行为来模拟人工智能神经元的行为</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</guid>
      <pubDate>Tue, 07 Jan 2025 01:09:19 GMT</pubDate>
    </item>
    <item>
      <title>[工具发布] 神经网络工具包（NNT）——神经网络的可视化开发环境</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</guid>
      <pubDate>Mon, 06 Jan 2025 10:22:37 GMT</pubDate>
    </item>
    <item>
      <title>准确判断人工智能对书籍和电影的影响程度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</link>
      <description><![CDATA[👋大家好 歌词介绍 像我们许多人一样，我深爱文学和电影。大约一年来，我一直在思考人工智能如何在文学和电影领域发挥作用。我确信这将导致作家和作者的贬值。在我看来，这不是未来的问题，而是现在的问题。当一部新的、非常成功的系列、电影或书籍发布时，一部分观众会自动认为人工智能一定参与其中。这反过来又破坏了数百甚至数千名专业作家的巨大努力。未来，这种情况显然只会恶化。 问题 我知道有五种通用的人工智能检测器（主要用于分析文章），据我所知，它们都是通过分析文本来寻找 ChatGPT 和其他 LLM 的典型模式。另一方面，有很多所谓的“人性化工具”，这些工具使人工智能生成的文本看起来更像人类，从而使检测变得复杂。更不用说文本可能是人工智能生成的，但由人类手动编辑，反之亦然的可能性了。 问题 我对专家的意见非常感兴趣。如果我们增加尽可能多的文本分析层次——例如，检查作者的草稿、过去的作品、正在审查的文件的元数据（如果技术上可行的话，包括创建时间和编辑频率）、在审查过程中给作者一个随机任务来分析他们的写作风格等——是否有可能准确确定人工智能对其作品的影响程度？例如：  由人工智能生成并由人类编辑 由人类编写并由人工智能编辑 完全由人工智能编写 完全由人类编写  是否可以通过使用适当的场景和示例训练神经网络来实现这种检测？    提交人    /u/YouranusAlien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</guid>
      <pubDate>Sun, 05 Jan 2025 16:52:21 GMT</pubDate>
    </item>
    </channel>
</rss>