<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Mon, 08 Jul 2024 09:17:24 GMT</lastBuildDate>
    <item>
      <title>如果提供微调 API，则可以通用地越狱 LLM 的安全输入和输出</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dxir6y/a_universal_way_to_jailbreak_llms_safety_inputs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dxir6y/a_universal_way_to_jailbreak_llms_safety_inputs/</guid>
      <pubDate>Sun, 07 Jul 2024 15:12:23 GMT</pubDate>
    </item>
    <item>
      <title>创建库以将 58 种 LLM 提示技术应用于您的提示。加入我吧？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dwqi7y/creating_library_to_apply_58_llm_prompting/</link>
      <description><![CDATA[OpenAI、Microsoft 等在这篇论文中调查了 58 种提示技术： https://arxiv.org/pdf/2406.06608 我正在创建一个库来自动将这些技术应用于你的提示： https://github.com/sarthakrastogi/quality-prompts 例如，System2Attention 就是这样一种技术，它可以过滤回答用户查询所需的相关上下文。 只需在你的提示上调用 .system2attention() 就可以了。 类似地，在少量提示中，假设你有大量的示例输入和标签。 您所要做的就是调用 .few_shot() 方法，库将应用 kNN 进行搜索并仅添加最相关的少样本示例。 提示在运行时根据用户的消息动态定制。 让我们编写高质量的提示！ 如果您想为图书馆做出贡献，请提出 PR！ Colab 笔记本入门： https://colab.research.google.com/github/sarthakrastogi/quality-prompts/blob/main/examples/few_shot_prompt_usage.ipynb    由    /u/sarthakai  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dwqi7y/creating_library_to_apply_58_llm_prompting/</guid>
      <pubDate>Sat, 06 Jul 2024 14:11:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有框架的情况下构建一个简单的神经网络！只需数学和 Python</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dv4n7a/how_to_build_a_simple_neural_network_without/</link>
      <description><![CDATA[嗨，ML 社区！ 我制作了一个针对初学者的视频（至少是我尽我所能了，哈哈），介绍了神经网络的起源以及如何从头开始构建最简单的网络。无需框架或库，仅使用数学和 Python，目的是让人们参与到这个令人着迷的话题中！ 在制作视频时，我尝试使用尽可能多的动画和 manim 来帮助可视化概念 :) 视频可以在这里看到仅使用数学和 Python 从头构建最简单的 AI 神经网络 - AI 的起源 Ep.1 (youtube.com) 它涵盖：  神经网络的起源 感知器背后的理论 权重、偏差，这些是什么？ 如何实现感知器 如何进行简单的线性回归 使用最简单的成本函数 - 平均绝对误差 (MAE) 微分微积分（计算导数） 最小化成本 进行简单的线性回归  我试着以非常慢的速度进行，因为正如我所提到的，该视频是为初学者制作的！这是我打算制作的一系列视频中的第一个。 （当然取决于人们是否喜欢它们！） 我希望这能给某人带来价值！谢谢！    提交人    /u/fx2mx3   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dv4n7a/how_to_build_a_simple_neural_network_without/</guid>
      <pubDate>Thu, 04 Jul 2024 11:26:11 GMT</pubDate>
    </item>
    <item>
      <title>你喜欢吗？音乐 - UDIO，视频 - LUMA，由 meatbags 编辑。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1duivsm/how_do_you_like_it_music_udio_video_luma_edited/</link>
      <description><![CDATA[        提交者    /u/Alex_GD_SkillPotion   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1duivsm/how_do_you_like_it_music_udio_video_luma_edited/</guid>
      <pubDate>Wed, 03 Jul 2024 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么在进行线性回归时需要 MSE 作为感知器的成本函数吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1du94pm/can_someone_explain_why_the_mse_is_needed_as_a/</link>
      <description><![CDATA[我最近编写了一个 3 层神经网络，其中我的激活函数是 S 型函数，而成本函数只是平方误差。理解导数相当容易，我理解了梯度下降背后的直觉。但是，当我编写一个没有激活函数的感知器来练习线性回归时，我很快意识到我的数学错了。训练函数将根据输入计算平方误差，并使用以下公式调整权重：误差 * 输入 * 学习率。 我还知道，对于带有感知器的逻辑回归，如果我们有一个输入 0 或 1 的激活函数，我们可以根据以下公式调整权重：误差 * 输入 * 学习率。 我很快意识到我的成本函数需要是 MSE 或 MAE，基本上是一个依赖于整个数据集的函数。直观上看，这是有道理的，但我只是不明白为什么在训练神经网络时，我可以根据单个输入调整权重，但对于简单线性回归，我需要承担整个数据集引起的误差。我很感激直观的解释，但数学解释会更有帮助。    提交人    /u/flying-toaster17   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1du94pm/can_someone_explain_why_the_mse_is_needed_as_a/</guid>
      <pubDate>Wed, 03 Jul 2024 08:12:28 GMT</pubDate>
    </item>
    <item>
      <title>在实践中尝试 Kolmogorov-Arnold 网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dtw5fk/trying_kolmogorovarnold_networks_in_practice/</link>
      <description><![CDATA[  由    /u/Ameobea  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dtw5fk/trying_kolmogorovarnold_networks_in_practice/</guid>
      <pubDate>Tue, 02 Jul 2024 20:41:08 GMT</pubDate>
    </item>
    <item>
      <title>我的 Python 代码是一个神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dt5a1w/my_python_code_is_a_neural_network/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dt5a1w/my_python_code_is_a_neural_network/</guid>
      <pubDate>Mon, 01 Jul 2024 21:57:18 GMT</pubDate>
    </item>
    <item>
      <title>我想使用 ANN 开展一个大学图像分类项目，而且我希望它非常简单，因为截止日期已经很近了。我还希望它有点创新。有什么想法吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dslgg9/i_wanna_work_on_a_university_image_classification/</link>
      <description><![CDATA[  由    /u/_PHATEME_  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dslgg9/i_wanna_work_on_a_university_image_classification/</guid>
      <pubDate>Mon, 01 Jul 2024 05:41:48 GMT</pubDate>
    </item>
    <item>
      <title>剖析我的第一个有文档记录的机器学习项目</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1drwvpb/roast_my_first_documented_ml_project/</link>
      <description><![CDATA[      嘿，群体智能， 和在座的许多人一样，我对机器学习，尤其是神经网络非常着迷。我的目标是传播这种迷恋，并让其他人对这个领域感到兴奋。 我向这个专家社区寻求对我的第一个完整记录的图像识别项目的反馈。我从头开始处理这个主题，并将其分解为以下结构：  图像基础知识 模型结构 数据集 使用 Python 进行训练 使用 Python 进行测试（ChatGPT 图像）  我尝试从头开始解释要点，因为我经常看到 YouTube 视频从主题的一半开始。我把从“什么是像素”到“测试经过训练的 CNN”的所有内容都浓缩到 15 分钟内。 在互联网世界中，15 分钟可能感觉像永远一样长。如果您很着急，请随意跳过视频并就引起您注意的任何一点给我反馈。 提前致谢。    提交人    /u/vtimevlessv   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1drwvpb/roast_my_first_documented_ml_project/</guid>
      <pubDate>Sun, 30 Jun 2024 08:29:32 GMT</pubDate>
    </item>
    <item>
      <title>因为它是由神经网络意见产生的，所以从 r/Art 中删除了？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dqv3r8/removed_from_rart_because_it_was_made_by_a_neural/</link>
      <description><![CDATA[        提交人    /u/laugh_haileyx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dqv3r8/removed_from_rart_because_it_was_made_by_a_neural/</guid>
      <pubDate>Fri, 28 Jun 2024 21:42:37 GMT</pubDate>
    </item>
    <item>
      <title>深度学习论文摘要</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dqgeuz/deep_learning_paper_summaries/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组对来自 NeurIPS、CVPR、ICCV、ICML 2016-24 等各种著名会议的深度学习论文进行了全面的总结。一些值得注意的例子包括：  DreamBooth：针对主题驱动生成对文本到图像扩散模型进行微调，CVPR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/DreamBooth.md Segment Anything，ICCV&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Segment_Anything.md 一张图片胜过一个词：使用个性化文本到图像生成文本反转，ICVR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Textual_inversion.md 具有深度语言理解的逼真文本到图像扩散模型，NIPS&#39;22 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/imagen.md 一张图片胜过 16X16 个单词：用于大规模图像识别的 Transformers，ICLR&#39;21 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Vision_Transformer.md Big Bird：用于更长序列的变换器，NIPS&#39;20 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Big_Bird_Transformers.md  如果您发现这些摘要有用，您可以贡献自己的摘要。 repo 将不断更新来自领先会议的更多论文摘要。    提交人    /u/vlg_iitr   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dqgeuz/deep_learning_paper_summaries/</guid>
      <pubDate>Fri, 28 Jun 2024 10:25:37 GMT</pubDate>
    </item>
    <item>
      <title>神经符号人工智能的快速入门</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dq1t3p/quick_and_dirty_intro_to_neurosymbolic_ai/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dq1t3p/quick_and_dirty_intro_to_neurosymbolic_ai/</guid>
      <pubDate>Thu, 27 Jun 2024 20:50:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 和 Opencv 进行文本检测 | 使用 EasyOCR 进行 OCR | 计算机视觉教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dpueub/text_detection_with_python_and_opencv_ocr_using/</link>
      <description><![CDATA[      https://preview.redd.it/jdt1d5wcn59d1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=24bb544b9e57dec962f1eadb3c0eb1b384500316 在本视频中，我向您展示了如何使用 Python、OpenCV 和 EasyOCR 进行光学字符识别 (OCR)！ 按照本 10 分钟教程的步骤，您将能够检测图像上的文本！   您可以在我的博客文章页面中找到更多类似的教程：https://eranfeit.net/blog/ 在此处查看我们的视频：https://youtu.be/DycbnT_pWKw&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受， Eran     Python #OpenCV #ObjectDetection #ComputerVision #EasyOCR   由    /u/Feitgemel  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dpueub/text_detection_with_python_and_opencv_ocr_using/</guid>
      <pubDate>Thu, 27 Jun 2024 15:44:05 GMT</pubDate>
    </item>
    <item>
      <title>利用 AI 和 RGB-D 进行 3D 盒子测量</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dptrle/3d_box_measurement_utilizing_ai_and_rgbd/</link>
      <description><![CDATA[       由    /u/erol444  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dptrle/3d_box_measurement_utilizing_ai_and_rgbd/</guid>
      <pubDate>Thu, 27 Jun 2024 15:16:34 GMT</pubDate>
    </item>
    <item>
      <title>深度神经网络中使用的激活函数</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dp6kgb/activation_functions_used_in_deep_neural_networks/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dp6kgb/activation_functions_used_in_deep_neural_networks/</guid>
      <pubDate>Wed, 26 Jun 2024 19:01:42 GMT</pubDate>
    </item>
    </channel>
</rss>