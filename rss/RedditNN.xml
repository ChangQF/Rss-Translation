<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Tue, 05 Nov 2024 01:14:26 GMT</lastBuildDate>
    <item>
      <title>网络物理系统中的元认知</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjdfjv/metacognition_in_cyberphysical_systems/</guid>
      <pubDate>Mon, 04 Nov 2024 12:49:25 GMT</pubDate>
    </item>
    <item>
      <title>正确的模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</link>
      <description><![CDATA[因此，我的任务是根据之前的值和下一个变量（例如电机的速度和旋转）预测无人机的电池消耗。 我会使用 RNN（类似 LSTM）根据之前的值预测下一个值，但也有其他依赖于电池消耗的参数（电机旋转、位置等...）。 我应该使用什么模型？    提交人    /u/martin3698753   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gjakzi/right_model/</guid>
      <pubDate>Mon, 04 Nov 2024 09:46:45 GMT</pubDate>
    </item>
    <item>
      <title>提高直播视频质量</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</link>
      <description><![CDATA[我收到了一个有很多噪音和伪影的模拟视频。假设我通过数字转换器播放了这个视频，但质量仍然很差。是否有任何神经网络可以在没有大延迟的情况下从实时视频中去除噪音和伪影？    提交人    /u/Braven111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj9qp4/improve_quality_of_live_video/</guid>
      <pubDate>Mon, 04 Nov 2024 08:39:29 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶加权神经网络：提高效率和性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</link>
      <description><![CDATA[       由    /u/musescore1983  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj7kpx/fourier_weighted_neural_networks_enhancing/</guid>
      <pubDate>Mon, 04 Nov 2024 05:56:00 GMT</pubDate>
    </item>
    <item>
      <title>罗伯特·赫克特-尼尔森的遗产</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</link>
      <description><![CDATA[Robert Hecht-Nielsen 在 80 年代末在 UCSD 教授了人工神经网络的研究生课程。非常棒的基础内容。Bob 也是一名冲浪者，他非常想在他的冲浪板中嵌入一些翻译马力，这样他就可以与海豚互动。我的路径与神经网络不同，所以不太了解最新情况。事情是这样的，Bob 有 386，你们有斗鱼的东西。快到 2025 年了，那里没有冲浪者怎么办？    提交人    /u/blatherer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</guid>
      <pubDate>Sun, 03 Nov 2024 23:19:07 GMT</pubDate>
    </item>
    <item>
      <title>还没有见过很多代表训练网络中权重的图像。它们很漂亮。这是我的。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</link>
      <description><![CDATA[        提交者    /u/bombsy_rosalina   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</guid>
      <pubDate>Sun, 03 Nov 2024 21:29:21 GMT</pubDate>
    </item>
    <item>
      <title>遗传算法优于 NN？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</link>
      <description><![CDATA[我有一个最小化问题：  我有一个已知的参考函数，计算速度慢，但性能很好 我设法用一个简单的 NN 很好地近似它 现在我想让它变得更好，因为参考函数已知有缺陷  问题是我无法判断函数的单个输出是好是坏。我只能把它放在一个黑匣子里，在那里使用数千次，然后得到一个性能分数。 你会如何处理这个问题？我正在考虑在我的 NN 上使用遗传算法，但我不知道从哪里开始。我记得不久前读过一篇关于这个的论文，但再也找不到了。 我也可以完全忘记我的参考函数及其 NN 近似，在这种情况下，我会回到标准最小化问题，我想知道是否有任何使用 NN 的方法，或者切换到经典最小化算法会更好。    提交人    /u/PittMarson   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</guid>
      <pubDate>Sun, 03 Nov 2024 20:07:07 GMT</pubDate>
    </item>
    <item>
      <title>120 个狗品种，超过 10,000 张图片：狗分类的深度学习教程🐕‍🦺</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</link>
      <description><![CDATA[      https://preview.redd.it/htuma7v2aqyd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1eb955978bdc315fcc5a58ef3696afd3a070080e 📽️ 在我们的最新视频教程中，我们将使用 NasLarge 预训练模型🚀和一个包含 120 种独特犬种的 10,000 多张图像的海量数据集创建一个犬种识别模型📸. 您将学到的内容： 🔹 数据准备：我们首先下载一个包含超过 20,000 张狗图像的数据集，这些图像整齐地分为 120 个类别。您将学习如何使用 Python、OpenCV 和 Numpy 加载和预处理数据，确保它完全可以进行训练。 🔹 CNN 架构和 NAS 模型：我们将使用 Nas Large 模型，并根据我们自己的需求对其进行自定义。 🔹 模型训练：利用 Tensorflow 和 Keras 的强大功能来定义和训练我们基于 Nas Large 模型的自定义 CNN 模型。我们将配置损失函数、优化器和评估指标，以在训练期间实现最佳性能。 🔹 预测新图像：观看我们对预先训练的模型进行测试！我们将展示如何使用该模型对新鲜的、从未见过的恐龙图像进行预测，并见证人工智能的魔力。   在此处查看我们的教程：https://youtu.be/vH1UVKwIhLo&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg 您可以在此处找到完整的代码：https://medium.com/p/b0008357e39c 您可以在此处找到更多教程并加入我的时事通讯：https://eranfeit.net/ 享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</guid>
      <pubDate>Sun, 03 Nov 2024 18:16:25 GMT</pubDate>
    </item>
    <item>
      <title>神经语言模型中嵌入层的目的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gikyzx/purpose_of_embedding_layer_in_neural_language/</link>
      <description><![CDATA[所以我正在参加一个关于机器学习的讲座，我们正在学习 3blue1brown 在他的视频系列中关于大型语言模型的内容，即给定一组单词，如何预测下一个单词。 让我困惑的是关于词嵌入的解释和词嵌入的实现不合逻辑。 词嵌入的解释：它是一些高维空间，其中单词被映射到向量，这些向量在高维空间中仍然共享一些意义概念。讲座中的解释显示了彼此相关的单词在集群中更接近的图形。 3blue1brown 的解释是这样的，男人和女人的向量之间的差异类似于国王和王后的向量，所以你可以做一些看起来像数学的事情来得到：王后 = 国王 - 男人 + 女人。 换句话说，词嵌入的解释声称它们捕获了语义关系！ 但是，当你真正实现嵌入时，而不是真正实现而只是使用 torch.nn.Embedding，所有这些都变得没用，嵌入层的用途对我来说变得模糊。 nn.Embedding 基本上给你一种将整数映射到随机初始化的向量的可能性。因此，您应该自己定义标记和整数之间的映射，可以是 Python 字典，也可以只使用文本并从 0 到文本末尾索引单词，然后声明相同的索引在嵌入中。 nn.Embedding 本质上只是根据您的 vocab_size（标记数）和您想要的嵌入向量的更高维度创建一个矩阵。然后，您可以通过传入带有这些索引的张量来访问该矩阵的每一行。 换句话说，单词嵌入的实现只会给您随机的、未经训练的向量。映射由您完成。 它可能朝着您必须训练嵌入的方向发展，以使其变成所教的内容以及您在谷歌搜索“词嵌入”时通常会找到的内容。 但如果这是真的，我们究竟想通过在神经网络中使用嵌入层来实现什么？ 因为如果嵌入层未经训练，它实际上不会为网络本身带来任何好处。它只是将文本映射到向量的一种方式，仅此而已。嵌入层的权重会以某种方式进行调整，以便我尝试使用网络完成的任何工作都可以正常工作。这并不意味着嵌入层会变成这个词向量空间，其中相似的单词彼此更接近。或者这仍然会作为副作用发生？    提交人    /u/elm1ra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gikyzx/purpose_of_embedding_layer_in_neural_language/</guid>
      <pubDate>Sun, 03 Nov 2024 11:42:05 GMT</pubDate>
    </item>
    <item>
      <title>Oasis：基于扩散变压器的模型，用于生成可玩的视频游戏</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</link>
      <description><![CDATA[decart 和 etched 开发的 Oasis 已经发布，它可以输出可玩的视频游戏，用户可以执行移动、跳跃、检查库存等操作。这不像谷歌的 GameNGen，它只能输出游戏视频（但不能播放）。在此处查看演示和其他详细信息：https://youtu.be/INsEs1sve9k    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</guid>
      <pubDate>Sat, 02 Nov 2024 09:55:08 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的偏差</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</link>
      <description><![CDATA[大家好，我最近开始研究神经网络。让我有些困惑的概念是偏差。我理解偏差在神经网络中的用途，但我仍然不明白两件事：  各个隐藏层中的每个单元是否都有自己的偏差，或者每个隐藏层的所有单元是否有共同的偏差？ 我不明白为什么在某些情况下偏差通过一个单元来表示，并附加自己的权重。它不应该是一个参数，因此不应该作为一个单元出现吗？     提交人    /u/Annual_Inflation_235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</guid>
      <pubDate>Thu, 31 Oct 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>运行此代码需要多少普通内存</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</link>
      <description><![CDATA[import torch 导入 torch.nn 作为 nn class TransformerBlock(nn.Module): def __init__(self, embed_size, heads, dropout, forward_expansion): super(TransformerBlock, self).__init__() self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads) self.norm1 = nn.LayerNorm(embed_size) self.norm2 = nn.LayerNorm(embed_size) self.feed_forward = nn.Sequential( nn.Linear(embed_size, forward_expansion * embed_size), nn.ReLU(), nn.Linear(forward_expansion * embed_size, embed_size) ) self.dropout1 = nn.Dropout(dropout) self.dropout2 = nn.Dropout(dropout) def forward(self, x):tention = self.attention(x, x, x)[0] x = self.dropout1(self.norm1(attention + x)) forward = self.feed_forward(x) out = self.dropout2(self.norm2(forward + x)) return out class ChatGPT(nn.Module): def __init__(self, embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout): super(ChatGPT, self).__init__() self.embed_size = embed_size self.word_embedding = nn.Embedding(vocab_size, embed_size) self.position_embedding = nn.Embedding(max_length, embed_size) self.transformer_blocks = nn.ModuleList( [TransformerBlock(embed_size, num_heads, dropout, forward_expansion) for _ in range(num_layers)] ) self.fc_out = nn.Linear(embed_size, vocab_size) self.dropout = nn.Dropout(dropout) def forward(self, x): N, seq_length = x.shape positions = torch.arange(0, seq_length).expand(N, seq_length).to(x.device) out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) for transformer in self.transformer_blocks: out = transformer(out) out = self.fc_out(out) return out # 大型模型的模型超参数（类似于 GPT-3） embed_size = 12288 # 大型模型的嵌入大小 num_heads = 96 # 注意力头的数量 num_layers = 96 # 数量Transformer 块的数量 vocab_size = 50257 # 词汇表的大小（GPT-3 使用更大的词汇表） max_length = 2048 # 输入序列的最大长度 forward_expansion = 4 # 前馈层的扩展因子 dropout = 0.1 # 丢失率 # 初始化模型 model_0 = ChatGPT(embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout)  ```     submitted by    /u/Budget-Relief1307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</guid>
      <pubDate>Wed, 30 Oct 2024 15:41:01 GMT</pubDate>
    </item>
    <item>
      <title>🌟 游戏开发的人工智能：改变游戏世界的未来！🌟</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</link>
      <description><![CDATA[正在寻找加速角色、位置和纹理创建的方法？想看看 AI 如何加速开发并激发新想法吗？ 🎮 欢迎参加 AI 重塑游戏开发的演示！使用 ControlNet、ChatGPT、Stable Diffusion 等示例，我将展示人工智能如何显著增强和优化游戏创作过程。 🚀 您会发现什么？ - 如何使用 AI 在几秒钟内创建姿势和场景 - 轻松为特定项目训练模型 - 将手绘与神经网络集成的示例 不要错过获得灵感并从全新视角看待游戏开发的机会！ 👉 观看演示    提交人    /u/Bozhenart   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</guid>
      <pubDate>Tue, 29 Oct 2024 14:34:21 GMT</pubDate>
    </item>
    <item>
      <title>机器学习与知识的集成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</guid>
      <pubDate>Tue, 29 Oct 2024 03:29:55 GMT</pubDate>
    </item>
    <item>
      <title>FSF 致力于实现机器学习应用的自由</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</guid>
      <pubDate>Mon, 28 Oct 2024 14:25:38 GMT</pubDate>
    </item>
    </channel>
</rss>