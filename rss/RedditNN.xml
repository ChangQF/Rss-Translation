<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Mon, 10 Mar 2025 12:35:29 GMT</lastBuildDate>
    <item>
      <title>Pokechamp：使用LLMS增强Minimax搜索专家级口袋妖怪战斗</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j6btmh/pokechamp_enhancing_minimax_search_with_llms_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究这款新的Pokéchamp纸，该纸将LLMS与Minimax搜索相结合，以创建专家级的Pokémon战斗代理商。关键的创新是在最小框架内使用LLM作为国家评估者，而不是直接要求他们选择动作。 该技术的运作良好：  达到90％+在Pokémon摊销上以某些格式的pokémonShowdate    opperfers  opperfers   obperfers  仅使用1-2圈lookahead  展示专家级别的表现 显示了复杂的战略思维，例如适当的风险评估和计划 达到VGC格式的第99.7个百分点，在OU格式中达到95个百分点，     llms（gpt-4，claude Backuation and and）  我认为这种方法可以直接使用LLM直接用于顺序决策。通过实施Minimax搜索，系统明确考虑对手的反击，而不仅仅是针对当前转弯进行优化。这可以应用于LLM与LookAhead计划斗争的许多其他战略领域。 我认为，特别值得注意的是，这种成功是在一个比国际象棋或棋子更为复杂的环境中，其中有部分信息和大量的状态空间。计算要求很大，但结果表明，适当的搜索技术可以在没有特定领域的培训的情况下将LLM转变为专家游戏玩法的代理商。  tldr：研究人员将LLM与Minimax搜索相结合，以创建专家级别的Pokémon战斗代理，以击败Prom System prom System  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j6btmh/pokechamp_enhancing_minimax_search_with_llms_for/</guid>
      <pubDate>Sat, 08 Mar 2025 07:16:16 GMT</pubDate>
    </item>
    <item>
      <title>刚刚完成学习CNN模型 - 寻找更多建议！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j6a2zi/just_finished_learning_cnn_models_looking_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近完成了CNN模型上出色的YouTube播放列表 code by aarohi （&lt; https://youtube.com/playlist?list=plv8cp2nvcy8dpvcsmot71kymgmmcr59mf&amp; si = funpyb5k1d6omres ），我不得不说 - 这是一次很棒的学习经历！ 她很好地解释了一切，以易于遵循的方式涵盖了理论和实施。那里肯定还有其他很棒的资源，但是这个资源弹出在我的屏幕上，我给了一个镜头 - 完全值得。 如果您想巩固对CNN型号的了解，我强烈建议您检查一下。这里有其他人使用此播放列表或找到了学习CNN体系结构的其他重要资源吗？很想听听您的建议！ 从我学到的知识中，播放列表涵盖了Lenet，Alexnet，VGG，Googlenet和Resnet等体系结构，它们在推进计算机视觉方面都起着重要作用。但是我知道还有其他模型带来了重大改进。我可能错过的其他CNN架构值得探索吗？期待您的建议！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/earker-loss-5961     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j6a2zi/just_finished_learning_cnn_models_looking_for/</guid>
      <pubDate>Sat, 08 Mar 2025 05:21:30 GMT</pubDate>
    </item>
    <item>
      <title>使用截面上粘附的语言模板评估LLM推理与记忆的记忆</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j5lexj/evaluating_llm_reasoning_vs_memorization_using/</link>
      <description><![CDATA[LINGOLY-TOO: Using Obfuscated Linguistics to Separate Memorization from Reasoning I&#39;ve been looking at a new evaluation method that tackles one of our field&#39;s persistent problems: how do we know if language models are actually reasoning or just regurgitating memorized patterns? The authors created a clever benchmark called Lingoly-too将语言拼图模板与“正交混淆”相结合。 - 基本上改变了在保留语言结构时拼写拼写的方式。 This lets them measure how well models generalize linguistic reasoning versus just pattern matching. Key technical points:  Linguistic templatization: Created systematically varied puzzles across phonological, morphological, syntactic, semantic, and pragmatic categories Orthographic obfuscation: Modified拼写模式在保存基础结构时  测量指标：量化“ obfuscation Gap” (performance drop between normal and obfuscated versions) Model testing: Evaluated GPT-3.5, GPT-4, Claude 2, Llama-2, and Mistral in zero-shot, one-shot, and few-shot settings Results: Found substantial performance drops (15-25%) when models faced obfuscated versions of otherwise familiar puzzle structures Few-shot improvements: Providing examples helped but didn&#39;t close the reasoning gap Best performer: GPT-4 showed strongest capabilities but still demonstrated significant limitations  Results breakdown:  Morphological and phonological puzzles showed the largest obfuscation差距 通常在句法难题上表现最好的模型 经过经过经验的提示有所帮助，但无法消除性能差距 基准测试当前的模型在模式下表现出色，但要揭示出与抽象的理由     我的基金会的依据，我们应该在某种程度上遇到任何模型：模式？对于实际应用，这种区别非常重要。如果模型主要是模型匹配，则它们可能在模式不同的新颖方案中失败，但是基本的推理应该转移。 我认为这也表明我们需要更加谨慎地谨慎地解释基准结果。模型可能仅仅是因为它以前看到了类似的模式，这可能会在语言推理任务上得分，这并不是因为它已经开发出一般的推理能力。 用于模型开发，这表明了潜在的培训改进 - 也许故意改变了地面形式，同时保持潜在的结构可以帮助发展更强大的推理能力。在常规和故意拼写错误的语言难题上测试语言模型。结果表明，当前模型在很大程度上依赖于记忆，当表面模式发生变化时，性能下降了15-25％，但基本推理保持不变。  总结。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j5lexj/evaluating_llm_reasoning_vs_memorization_using/</guid>
      <pubDate>Fri, 07 Mar 2025 11:30:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不能动态训练模型？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j4texx/why_cant_we_train_models_dynamically/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大脑通过不断添加和完善数据来学习；每次渴望升级时，它都不会在改进的数据集上从头开始擦拭并从头开始重新启动。 神经网络受到大脑的启发，那么为什么它们需要分段训练阶段呢？就像Openai从GPT 3到GPT 4的跳跃时一样，它们必须再次从空白板开始。 ，为什么我们不能继续添加和优化数据，即使使用了模型？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/haunting-stretch8069     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j4texx/why_cant_we_train_models_dynamically/</guid>
      <pubDate>Thu, 06 Mar 2025 11:29:29 GMT</pubDate>
    </item>
    <item>
      <title>基于语义的证据检索和两步分类越南事实检查</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j4t4iq/semanticbased_evidence_retrieval_and_twostep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   SEMVIQA系统通过一个集成了多模式处理能力的语义问题回答框架，引入了一种新颖的方法来检查越南人的事实。 By transforming fact claims into questions and using a vector database for retrieval, it achieves both accuracy and efficiency for Vietnamese information verification. Key technical points: - Semantic vector database approach: Uses Weaviate to store and retrieve information based on meaning relationships rather than keywords - Claim-to-question transformation: Employs GPT-4 to convert fact claims into可搜索的问题，提高检索准确性 -  多模式处理：使用剪辑和重新连接进行视觉特征提取的文本和图像 -   Phogpt Integration ：利用越南语的语言模型用于文本处理 -   85.33％的viquad DataSet Quielad DataSet eftery&gt; 1.  1. &lt;1.7的平均值。改进比基线越南质量检查模型 我认为这项工作尤其重要，因为它解决了非英语语言的事实检查工具的显着差距。矢量数据库方法可以适应其他低资源语言，面临类似的挑战。特别有希望的是，他们如何设法达到强大的绩效，同时保持合理的响应时间 - 对于用户需要快速验证的现实应用程序至关重要。 将索赔转换为问题的方法非常聪明，因为它基本上将事实检查问题介绍为检索问题。这避开了直接事实验证的一些困难。但是，我担心对GPT-4等专有模型的依赖，这可能会限制部署选项。 我有兴趣了解该系统对故意误导或模棱两可的主张的执行方式，这在本文中未经过广泛的测试。 The current Wikipedia-based knowledge source is also a limitation that would need to be addressed for broader real-world usage. TLDR: SemViQA is a Vietnamese fact-checking system using semantic vector search and multimodal processing that achieves 85% accuracy on ViQuAD through an innovative approach of converting claims to questions for efficient retrieval. 完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j4t4iq/semanticbased_evidence_retrieval_and_twostep/</guid>
      <pubDate>Thu, 06 Mar 2025 11:09:43 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络中的权重初始化 - 解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j49pjw/weights_initialization_in_neural_networks/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/u/sersion-trainer-541       [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j49pjw/weights_initialization_in_neural_networks/</guid>
      <pubDate>Wed, 05 Mar 2025 18:15:24 GMT</pubDate>
    </item>
    <item>
      <title>MAMUT：生成多种数学公式变体用于增强语言模型培训</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j41qys/mamut_generating_diverse_mathematical_formula/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   mamut引入了一个系统的框架，用于通过修改现有公式以创建具有控制难度级别的新示例来生成数学培训数据。 By parsing equations into abstract syntax trees and applying constrained transformations, it produces mathematically valid variations that can be used to create specialized datasets for language model training. The key technical aspects include:  A multi-stage transformation process that parses math expressions into abstract syntax trees Five types of transforms: variable substitution, constant substitution, term加法/删除，结构转换和复杂性调整 数学约束规则，确保所有生成的变化保持有效且可解决的 难以控制的难度控制，允许对更简单或更复杂的问题进行有针对性的生成   与GPT-4的评估框架对GPT-4的评估框架相比：  MAMUT在生成有效的数学内容 人类评估者中优于GPT-4，在72％的情况下，人类评估者更喜欢Mamut生成的内容 在Mamut-In-eNerated数据集上培训的语言模型在MAMUT生成的数据集上培训了Math Marksks and Gerage verra and verra verra verra verra verra verra verra verra contraip  域  我认为这种以数据为中心的方法解决了当前语言模型的数学推理中的基本限制。通过大规模创建各种有效的数学示例，Mamut提供了改善LLM的途径，而无需更改模型体系结构。这使我想起了“数据是新的石油”。透视图，但专门用于数学推理。 我认为教育应用也可能很重要。通过受控难度进展，创建个性化的实践问题可以帮助自适应学习系统。教师可以使用它来产生家庭作业变化或测试问题而无需花费数小时的时间来创建它们。 该框架确实在处理单词问题和更高级的数学领域的框架确实存在局限性，但它提供了可以扩展的坚实基础。  tldr：mamut：MamAmut是一种培训框架，可以使数学上的模型变化，以使数学上的数学形式变化，以使数学上的数字构建范围，以使数学范围用于数学的范围。 GPT-4在创建有效的数学内容并改善数学推理任务上的模型性能时。 完整摘要。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j41qys/mamut_generating_diverse_mathematical_formula/</guid>
      <pubDate>Wed, 05 Mar 2025 12:17:18 GMT</pubDate>
    </item>
    <item>
      <title>在开发RNN网络方面需要帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j32quw/need_help_with_developing_rnn_network/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j32quw/need_help_with_developing_rnn_network/</guid>
      <pubDate>Tue, 04 Mar 2025 04:32:24 GMT</pubDate>
    </item>
    <item>
      <title>使用基本神经网络展示进化论</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j2wqad/showing_evolution_theory_using_basic_neural/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/u/mosp-ice-566       [注释]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j2wqad/showing_evolution_theory_using_basic_neural/</guid>
      <pubDate>Mon, 03 Mar 2025 23:28:18 GMT</pubDate>
    </item>
    <item>
      <title>以子任务为导向的增强微调通过结构化分解增强了LLM发行问题的分辨率</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j1l62m/subtaskoriented_reinforced_finetuning_enhances/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   sorft：将软件问题分解为可管理的子任务  sorft引入一种新颖的微调方法，该方法可以通过将复杂的编程将复杂的任务分解为子任务并使用强制性地进行效果的效果。 Subtask-oriented planning: The model first plans out smaller, manageable subtasks before coding - Sequential Execution: Implements solutions step-by-step, following a natural programming workflow - Reinforcement Learning: Uses RL to reward successful code that compiles and passes tests - Code Navigation Integration: Incorporates real-world software engineering practices like file探索  结果：  -   25％改善在代码生成准确性上比基线模型比基线模型 - 实现 24.6％Pass@1 在微调7B基本模型后，在Swe -Bench上 - 在处理更高的代码和更高的代码 per&gt; per&gt;  &lt;认为这种方法特别有价值，因为它反映了人类程序员的实际工作方式。通过将问题分解为较小的组件，该模型生成的解决方案不仅更有可能成功，而且更容易理解和维护。  我认为，加强学习与子任务计划的集成解决了当前代码生成模型的基本限制 - 他们经常尝试在没有适当计划的情况下立即解决所有问题。这种顺序方法最终可能会导致AI助手，这些助手可以以与现有的开发工作流充分整合的方式处理更复杂的软件工程任务。     tldr： sorft改善代码生成，通过将编程问题分解为子任务，并使用强大的范围完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j1l62m/subtaskoriented_reinforced_finetuning_enhances/</guid>
      <pubDate>Sun, 02 Mar 2025 07:09:38 GMT</pubDate>
    </item>
    <item>
      <title>最后一年项目：建立基于自适应聊天的导师</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0vxv6/final_year_project_building_an_adaptive_chatbased/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我是最后一年的学生，我需要提出一个项目。我打算为其处理的项目一个基于聊天的系统，该系统适应用户的喜好。请我需要可以帮助构建该项目的想法和资源。 您的评论非常感谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ajax_shotz     [link]  &lt;a href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1j0vxv6/final_year_year_project_building_an_adaptive_chatbassed/]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0vxv6/final_year_project_building_an_adaptive_chatbased/</guid>
      <pubDate>Sat, 01 Mar 2025 09:42:00 GMT</pubDate>
    </item>
    <item>
      <title>科学假设生成的多代理AI系统：生物医学发现中的设计和验证</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0u187/multiagent_ai_system_for_scientific_hypothesis/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了建立在Gemini 2.0上的多代理AI系统，该系统通过迭代的发电，辩论和进化过程来生成和评估科学假设。该系统实施了锦标赛风格的方法，其中不同的AI代理提出了假设，然后通过结构化的辩论对其进行严格评估和完善。 关键技术要点： *架构使用多个可以用计算资源扩展的异步AI代理，这些AI使用了计算资源 *实现“生成debate-evolve a”受到科学方法的启发 *在三个生物医学领域进行验证的循环：药物重新利用，目标发现和细菌进化 *使用文献分析，途径建模和机械推理的组合 *通过实验性验证之前的结果，通过在实验室验证 的结果中，对假设进行了结构化的辩论：肝纤维化的靶标在器官模型中得到证实 *与未发表的实验发现相匹配的独立提出的细菌基因转移机制 *产生的假设比基线方法   ，我认为这是朝着AI-Assisted Scientific Discoverion迈出的重要步骤，尤其是在生物素中。显着的实验验证实际验证的可检验假设的能力是值得注意的。尽管该系统没有取代人类科学家，但它可以显着加速假设的产生和测试周期。 我认为，关键的创新是结构化的多代理辩论方法，而不是仅仅产生思想，而是系统对其进行批判性评估并逐渐发展。这反映了人类科学家的工作方式并似乎产生了更高质量的假设。  tldr：多代理AI系统使用生成的驱动循环来产生科学的假设，在生物医学领域进行了实验验证。显示了加速科学发现过程的希望。  完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0u187/multiagent_ai_system_for_scientific_hypothesis/</guid>
      <pubDate>Sat, 01 Mar 2025 07:24:40 GMT</pubDate>
    </item>
    <item>
      <title>不确定这是否是发布此信息的正确位置</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//github.com/choc1024/iac       我知道它不是很快，也不是如此之多，如果有很多东西，我都不会有这样的特征，并且可以与您分享，或者我会喜欢它，并且您会在您的特点上，并且您会在您的特点如果不是这样，请向我推荐另一个subreddit。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/i/im_chatgpt4    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1j0iq9n/not_sure_sure_this_is_is_is_the_right_tplace_tplace_to_to_to_post_this/”&gt; [links]    [注释]      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0iq9n/not_sure_if_this_is_the_right_place_to_post_this/</guid>
      <pubDate>Fri, 28 Feb 2025 21:23:59 GMT</pubDate>
    </item>
    <item>
      <title>在没有单词限制的情况下免费进行语音文本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</link>
      <description><![CDATA[        ＆＃32;提交由＆＃32; /u/u/u/cool-hornet-8191      ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j0b1lg/made_a_free_ai_text_to_speech_with_no_word_limit/</guid>
      <pubDate>Fri, 28 Feb 2025 16:01:17 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的临床注释的整合，以增强疾病轨迹预测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种基于变压器的方法，用于分析临床注释和预测患者轨迹。关键方法论贡献是将时间注意机制与特定领域的医学文本处理整合到预测患者预后的多个方面。 主要技术点：•多头注意的架构适用于临床注意事项序列，专门针对临床注释序列•预处理管道•跨越多个治疗术语的范围范围•先前验证•先前的时间术语•以前的时间范围•零舒适的范围•零舒适的范围，零，• （重新入院，住院时间，进步） 结果：•基线模型的再入院预测准确性提高了12％•在现场长度预测中的准确性提高了15％•在具有多种合并症的复杂案例上的出色表现•多种合并症的复杂案例•维持多个合并症的质量保持了预测质量，而不同的医疗专业 我认为，这项工作朝着更全面的临床支持系统支持系统。与结构化数据一起处理非结构化临床笔记的能力可以帮助捕获当前系统错过的微妙模式。 However, the computational requirements and need for high-quality training data may limit immediate widespread adoption. I think the zero-shot capabilities are particularly noteworthy, as they suggest potential applications in rare conditions or emerging health challenges where training data is limited. TLDR: Transformer model analyzes clinical notes to predict patient trajectories, showing improved accuracy over baselines and zero-shot capabilities.可以增强临床决策支持，但需要仔细验证。 完整摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1j04glq/transformerbased_integration_of_clinical_notes/</guid>
      <pubDate>Fri, 28 Feb 2025 10:13:04 GMT</pubDate>
    </item>
    </channel>
</rss>