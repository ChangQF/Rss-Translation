<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 28 Aug 2024 12:30:47 GMT</lastBuildDate>
    <item>
      <title>帮助 LSTM 进行批处理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1f28uv1/help_with_batching_for_an_lstm/</link>
      <description><![CDATA[嗨，我是深度学习的新手，我想学习如何为 LSTM 批量处理数据。我的问题是我有多个数据集，具体来说是 10 个，每个数据集都是来自同一实验的不同试验的数据。每个数据集的长度为 2880 x 5（4 个输入，1 个输出）。我怎样才能让 LSTM 知道每个序列都是不同的试验？训练数据和测试数据的分离过程是怎样的？如果您需要更多信息，请告诉我。提前谢谢您    提交人    /u/CarelessJellyfish9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1f28uv1/help_with_batching_for_an_lstm/</guid>
      <pubDate>Tue, 27 Aug 2024 04:51:18 GMT</pubDate>
    </item>
    <item>
      <title>哪一个主观上看起来最有趣</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1f28t2k/which_one_subjectively_looks_the_most_interesting/</link>
      <description><![CDATA[        提交人    /u/DesmosGrapher314   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1f28t2k/which_one_subjectively_looks_the_most_interesting/</guid>
      <pubDate>Tue, 27 Aug 2024 04:48:15 GMT</pubDate>
    </item>
    <item>
      <title>受限玻尔兹曼机 RBM 1</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1f24o3b/restricted_boltzmann_machines_rbm_1/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1f24o3b/restricted_boltzmann_machines_rbm_1/</guid>
      <pubDate>Tue, 27 Aug 2024 01:09:40 GMT</pubDate>
    </item>
    <item>
      <title>伊隆·马斯克神经网络提示的令人难忘的优美回应</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1f1u2mg/hauntingly_beautiful_response_from_elon_musks/</link>
      <description><![CDATA[        提交人    /u/whucklemewish   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1f1u2mg/hauntingly_beautiful_response_from_elon_musks/</guid>
      <pubDate>Mon, 26 Aug 2024 17:32:58 GMT</pubDate>
    </item>
    <item>
      <title>寻找深度学习资源来掌握 CNN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ezxmmz/looking_for_deep_learning_resources_to_master_cnns/</link>
      <description><![CDATA[大家好， 我是一名博士生，拥有分析学硕士学位，专注于计算数据科学，在数学和统计学方面有深厚的背景。 目前，我正在深入研究 CNN，这是我自学的一部分，同时准备选择一个论文主题。我对神经网络有相当的了解，目前正在研究流行的 CNN 架构，如 AlexNet 和 GoogleNet，对它们进行编码以了解它们的工作原理，并了解某些架构优于其他架构的原因。 我主要在寻找深入研究 CNN 的研究论文，但如果有一本非常好的书，我也会接受。任何关于下一步该看什么的建议都很棒。    提交人    /u/Joergyll   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ezxmmz/looking_for_deep_learning_resources_to_master_cnns/</guid>
      <pubDate>Sat, 24 Aug 2024 05:11:52 GMT</pubDate>
    </item>
    <item>
      <title>类似这样的问题是如何解决的？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eznyeh/how_are_problems_like_this_solved/</link>
      <description><![CDATA[该神经网络的准确率从未超过 0.667。这类问题通常是如何解决的？ from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential import numpy as np inputs = [ [1], [2], [3], ] outputs = [ [0], [1], [0] ] x_train = np.array(inputs) y_train = np.array(outputs) model = Sequential() model.add(Dense(1000, &quot;sigmoid&quot;)) model.add(Dense(1000, &quot;sigmoid&quot;)) model.add(Dense(1, &quot;sigmoid&quot;)) model.compile(&quot;adam&quot;, &quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;]) history = model.fit(x_train, y_train, epochs=1000) 我认为发生这种情况是因为输入和输出的性质（输入：1、2、3，而输出是 0,1,0)，结果相互矛盾。但这在构建神经网络时非常常见，所以我想知道这个问题通常是如何解决的。    提交人    /u/jaroslavtavgen   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eznyeh/how_are_problems_like_this_solved/</guid>
      <pubDate>Fri, 23 Aug 2024 21:12:27 GMT</pubDate>
    </item>
    <item>
      <title>torch.argmin() 非可微性解决方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ez2zi8/torchargmin_nondifferentiability_workaround/</link>
      <description><![CDATA[我正在实现一个基于地形约束的神经网络层。该层可以被认为类似于 2D 网格图，或者基于深度学习的自组织图。它由 4 个参数组成，即高度、宽度、潜在维数和 p 范数（用于距离计算）。每个单元/神经元的维数等于潜在维数。此类的最简代码为： class Topography(nn.Module): def __init__( self, latent_dim:int = 128, height:int = 20, width:int = 20, p_norm:int = 2 ): super().__init__() self.latent_dim = latent_dim self.height = height self.width = width self.p_norm = p_norm # 创建包含索引 2D 坐标的 2D 张量 locs = np.array(list(np.array([i, j]) for i in range(self.height) for j in range(self.width))) self.locations = torch.from_numpy(locs).to(torch.float32) del locs # 线性层的可训练权重 - self.lin_wts = nn.Parameter(data = torch.empty(self.height * self.width, self.latent_dim), require_grad = True) # 高斯初始化，平均值 = 0 且 std-dev = 1 / sqrt(d)- self.lin_wts.data.normal_(mean = 0.0, std = 1 / np.sqrt(self.latent_dim)) def forward(self, z): # L2 标准化 &#39;z&#39; 将其转换为单位向量- z = F.normalize(z, p = self.p_norm, dim = 1) # 每个输入到所有 SOM 单元的成对平方 L2 距离（L2 范数距离）- pairwise_squaredl2dist = torch.square( torch.cdist( x1 = z, # 还将所有 lin_wts 转换为单位向量- x2 = F.normalize(input = self.lin_wts, p = self.p_norm, dim = 1), p = self.p_norm ) ) # 对于每个输入 zi，计算“lin_wts”中的最近单元 - nearest_indices = torch.argmin(pairwise_squaredl2dist, dim = 1) # 获取 2D 坐标索引 - nearest_2d_indices = self.locations[closest_indices] # 计算最近单元和其他每个单元之间的 L2 距离 - l2_dist_squared_topo_neighb = torch.square(torch.cdist(x1 = nearest_2d_indices.to(torch.float32), x2 = self.locations, p = self.p_norm)) del nearest_indices, nearest_2d_indices return l2_dist_squared_topo_neighb, pairwise_squaredl2dist  对于给定的输入“z”（比如编码器的输出） ViT/CNN），它计算距离最近的单元，然后使用径向基函数核/高斯（逆）函数在该最近单元周围创建地形结构 - 在下面的&quot;topo_neighb&quot; 张量中完成。 由于&quot;torch.argmin()&quot;给出类似于独热编码向量的索引，这些向量根据定义是不可微的，我正在尝试创建一个解决方法： # 2D 单元数 - height = 20 width = 20 # 每个单元的维数指定为 - latent_dim = 128 # 使用 L2-norm 进行距离计算 - p_norm = 2 topo_layer = Topography(latent_dim = latent_dim, height = height, width = width, p_norm = p_norm) optimizer = torch.optim.SGD(params = topo_layer.parameters(), lr = 0.001, influence = 0.9) batch_size = 1024 # 创建一个输入向量 - z = torch.rand(batch_size, latent_dim) l2_dist_squared_topo_neighb, pairwise_squaredl2dist = topo_layer(z) # l2_dist_squared_topo_neighb.size(), pairwise_squaredl2dist.size() # (torch.Size([1024, 400]), torch.Size([1024, 400])) curr_sigma = torch.tensor(5.0) # 计算相对于最近单元的高斯拓扑邻域结构- topo_neighb = torch.exp(torch.div(torch.neg(l2_dist_squared_topo_neighb), ((2.0 * torch.square(curr_sigma)) + 1e-5))) # 计算地形损失- loss_topo = (topo_neighb * pairwise_squaredl2dist).sum(dim = 1).mean() loss_topo.backward() optimizer.step()  现在，成本函数的值发生了变化，减少。此外，作为健全性检查，我正在记录“topo_layer.lin_wts”的 L2 范数，以反映其权重正在使用梯度进行更新。 这是正确的实现，还是我遗漏了什么？    提交人    /u/grid_world   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ez2zi8/torchargmin_nondifferentiability_workaround/</guid>
      <pubDate>Fri, 23 Aug 2024 03:37:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络初始化 - 随机 x 结构化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1evw88a/neural_network_initialization_random_x_structured/</link>
      <description><![CDATA[我在 ANN 领域还没有那么多经验，所以我希望这个问题没有完全偏离图表 :) 我发现神经网络用随机值初始化其权重和偏差，以确保这些值不会在相同或对称的值上初始化。 我完全理解为什么它们不能相同 - 除了一个节点之外的所有节点都是多余的。 我无法理解的是为什么它们不能是对称的。我在 YouTube 上没有找到关于它的一个视频，当我一直问为什么不这样做时，GPT 低调地告诉我，如果你有一系列相关权重（假设为 -10 到 10），那么实际上最好将它们初始化得尽可能远，而不是使用其中一种随机算法。 GPT 提到的唯一问题是完全分离的节点的交付。 谁能向我解释为什么每个人都使用随机初始化？    提交人    /u/kotvic_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1evw88a/neural_network_initialization_random_x_structured/</guid>
      <pubDate>Mon, 19 Aug 2024 08:00:12 GMT</pubDate>
    </item>
    <item>
      <title>玻尔兹曼机与神经网络相比如何？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1evlay4/how_do_boltzmann_machines_compare_to_neural/</link>
      <description><![CDATA[  由    /u/WishIWasBronze  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1evlay4/how_do_boltzmann_machines_compare_to_neural/</guid>
      <pubDate>Sun, 18 Aug 2024 22:02:25 GMT</pubDate>
    </item>
    <item>
      <title>到目前为止我看到的用 Mistral 构建 LLM 应用程序的最简单的方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1evio91/easiest_way_i_have_seen_so_far_to_build_an_llm/</link>
      <description><![CDATA[        由    /u/mandelbrot1981  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1evio91/easiest_way_i_have_seen_so_far_to_build_an_llm/</guid>
      <pubDate>Sun, 18 Aug 2024 20:12:20 GMT</pubDate>
    </item>
    <item>
      <title>面向初学者的超级易懂、无需数学的神经网络入门课程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1evds7p/super_accessible_no_math_intro_to_neural_networks/</link>
      <description><![CDATA[        由    /u/how_i_think_about  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1evds7p/super_accessible_no_math_intro_to_neural_networks/</guid>
      <pubDate>Sun, 18 Aug 2024 16:45:24 GMT</pubDate>
    </item>
    <item>
      <title>高级 OpenCV 教程：如何在相似图像中找出差异</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eufd3s/advanced_opencv_tutorial_how_to_find_differences/</link>
      <description><![CDATA[      https://preview.redd.it/f335jf8wk7jd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=b6e60c2d1f20044e485f2c3c445346f96282a8ac 在本 Python 和 OpenCV 教程中，我们将探索如何在相似图像中找出差异。 使用 OpenCV 函数，我们将从原始图像中提取两张相似的图像，然后使用 HSV、掩蔽和更多 OpenCV 函数，我们将创建一个包含差异的新图像。 最后，我们将提取并标记两个原始相似图像上的差异。   [您可以在我的博客文章页面中找到更多类似的教程：]()https://eranfeit.net/blog/ 在此处查看我们的视频：https://youtu.be/03tY_OF0_Jg&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg    享受， Eran      由    /u/Feitgemel  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eufd3s/advanced_opencv_tutorial_how_to_find_differences/</guid>
      <pubDate>Sat, 17 Aug 2024 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>潜在空间可视化：PCA、t-SNE、UMAP | 深度学习动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1eu43in/latent_space_visualisation_pca_tsne_umap_deep/</link>
      <description><![CDATA[        由    /u/keghn  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1eu43in/latent_space_visualisation_pca_tsne_umap_deep/</guid>
      <pubDate>Sat, 17 Aug 2024 00:06:28 GMT</pubDate>
    </item>
    <item>
      <title>当我们不再理解人工智能的那一刻 [AlexNet]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1esj76c/the_moment_we_stopped_understanding_ai_alexnet/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1esj76c/the_moment_we_stopped_understanding_ai_alexnet/</guid>
      <pubDate>Thu, 15 Aug 2024 01:52:15 GMT</pubDate>
    </item>
    <item>
      <title>亲社会法学硕士：Soroush Vosoughi</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1esb2qx/prosocial_llms_soroush_vosoughi/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1esb2qx/prosocial_llms_soroush_vosoughi/</guid>
      <pubDate>Wed, 14 Aug 2024 19:57:55 GMT</pubDate>
    </item>
    </channel>
</rss>