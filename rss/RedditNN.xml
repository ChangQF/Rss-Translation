<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Wed, 26 Feb 2025 15:19:37 GMT</lastBuildDate>
    <item>
      <title>Anyon可以推荐一些最佳初学者友好的卷积神经网络教程，这将导致智能照明系统</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/arnoldpaclarinjr     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyoe8b/can_anyon_recommend_some_of_the_best/</guid>
      <pubDate>Wed, 26 Feb 2025 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>偏爱感知的LLM框架，用于事实基础营销内容生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一个新框架，用于生成营销内容，以保持说服力和事实准确性之间保持平衡。核心创新是一种两阶段的体系结构，将产品规格的检索模块与受控生成方法相结合。 关键的技术组件： -  接地生成模块，该模块在期间引用源产品规格内容创建 -  说服评分机制测量多个营销维度的有效性 -  事实对准检查器将生成的内容与源材料进行比较 - 新颖将50,000个产品描述与相应的营销材料结合的数据集 结果显示： - 相对于基线模型的说服力提高了23％（通过人类评估衡量） - 合并产品规格时维持的91％的事实准确性 - 大幅度降低了幻觉的产品与标准LLM方法相比，功能 - 更好地保留关键卖点，同时保持自然语言流量 我认为这可能会有意义地影响企业的自动化方式内容创建。扩展营销内容同时保持准确性的能力解决了当前AI营销工具中的主要痛点。该框架还提供了一种量化和优化参与和真实性之间的平衡的方法。 我认为，最有趣的技术方面是它们如何处理创意营销语言和事实约束之间的权衡。检索提升的方法可能可能应用于需要创造力和准确性的其他领域。  tldr：AI营销内容生成的新框架，该框架生成的新框架可以保持事实准确性，同时优化说服力，显示23％的效率提高，同时提高了有效性，而保持91％的事实准确性。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iyk47b/preferenceaware_llm_framework_for_factgrounded/</guid>
      <pubDate>Wed, 26 Feb 2025 09:59:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间缩放方法在数学推理任务中显示出有限的多语言概括</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键洞察力是使用测试时间缩放来改善跨多种语言的数学推理，而无需重新训练模型。研究人员将此技术应用于竞争级的数学问题，这些问题远远超出了基本算术。 主要技术要点： - 测试时间缩放涉及生成多个解决方案尝试（5-25）并选择最一致的答案 - 仔细翻译问题以保持数学含义，同时允许自然语言变化 - 评估使用了竞争级别的问题，包括代数，几何和证明 - 在所有经过测试的所有测试中，性能提高均一致语言 - 特别注意维持数学符号一致性 关键结果： - 测试时间缩放提高了所有问题类型和语言的精度 - 在多步推理问题中，改进最为明显 - 性能提高相似地缩放不管源语言如何 - 翻译质量对数学推理能力的影响最小超越语言边界。这可能会导致全球更易于访问的AI数学辅导系统和教育工具。 我认为这里的方法论贡献 - 表明测试时间缩放始终跨语言起作用 - 对于开发多语言数学AI系统特别有价值。  文化数学环境和翻译边缘案例的局限性提出了有趣的未来工作的方向。  tldr：测试时间缩放改进数学在竞争级别的问题上证明了跨语言的一致推理。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ixtf5q/testtime_scaling_methods_show_limited/</guid>
      <pubDate>Tue, 25 Feb 2025 12:05:01 GMT</pubDate>
    </item>
    <item>
      <title>负责人AI的课程材料</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我目前正在设计负责AI 的课程对于课程内容，您认为有相关的任何大学课程或研究，请分享。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/over_reward9875    href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1iwely0/course_materials_for_responsible_ai/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwely0/course_materials_for_responsible_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 16:56:17 GMT</pubDate>
    </item>
    <item>
      <title>辍学解释了</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</link>
      <description><![CDATA[       ＆＃32;提交由＆＃32; /u/u/u/personal-trainer-541      [link]  ＆＃32;   [commist]        &lt; /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iwcdm8/dropout_explained/</guid>
      <pubDate>Sun, 23 Feb 2025 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>CNN和Tensorboard的新手</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  开始学习如何训练CNN，好奇是否在val_accuracy中的初始尖峰是正常或如果尖峰掉落表示某种过度拟合或其他内容？我本来可以肯定的是，如果Val_accuracy保持较低，但随着模型继续训练，似乎会逐渐增加。这也可以是过度拟合验证数据的模型吗？我正在使用每班大约1500张图像的数据集。谢谢！ 〜一个试图学习cnns   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skoopchoop     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw5mib/new_to_cnns_and_tensorboard/</guid>
      <pubDate>Sun, 23 Feb 2025 08:32:09 GMT</pubDate>
    </item>
    <item>
      <title>多模式奖励基地：评估视觉模型奖励功能的综合基准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了多模式奖励贝恩，这是视觉奖励模型的全面评估框架。框架测试使用超过2,000个测试用例，包括准确性，偏差检测，安全考虑和鲁棒性，包括精度，偏差检测，安全考虑和鲁棒性。 关键技术要点： - 使用标准化指标评估6个显着的奖励模型 - 测试涵盖多个功能：响应质量，事实准确性，安全/偏见，跨模式理解 - 引入多模式对齐方式的新颖评估方法 - 为奖励模型提供定量基准测试性能 - 确定当前模型中的特定故障模式 主要结果： - 模型在基本文本评估上显示出强大的性能（＆gt; 80％） - 跨模式理解得分显着下降（〜40-60％） - 安全/偏差检测的较高差异（30-70％范围） - 不同内容类型的性能不一致 - 大多数模型都在涉及这两种模式的复杂推理任务 我认为这项工作的重点是当前奖励模型功能的关键差距，尤其是在处理多模式内容方面。基准可以帮助我们标准化我们如何评估这些模型并推动诸如安全性和偏见检测等领域的改进。 我认为最有价值的贡献是暴露特定的故障模式 - 准确显示当前模型的位置在何处跌落在何处，帮助未来重点。研究工作。结果表明，我们需要从根本上采用新的方法来处理奖励模型中的跨模式内容。  tldr：新的基准测试揭示了视觉奖励模型处理复杂的多模式任务的能力，尤其是在安全性和偏置检测。为改进提供了清晰的指标。 在这里&lt; /a&gt;。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iw4bnl/multimodal_rewardbench_a_comprehensive_benchmark/</guid>
      <pubDate>Sun, 23 Feb 2025 07:00:22 GMT</pubDate>
    </item>
    <item>
      <title>Chase：使用LLMS自动生成硬评估问题的框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使LLMS生成挑战性问题的新框架研究如何系统地创建高质量的测试问题。核心方法论通过明确提示策略使用迭代自我测试和有针对性的难度校准。 关键的技术组件： - 具有中间验证的多阶段生成过程 - 自我评估循环，其中LLM批评其自身的输出 - 难以通过参数化提示来定位 - 使用多个模型的交叉验证来验证问题质量 结果： - 问题质量提高40％使用自我测试与基本提示-35％通过迭代精致更好地对齐和预期难度 - 匹配所需的复杂性水平的精度为80％ - 显着降低了琐碎或畸形的问题 我认为这项工作为实用的基础提供了基础用于开发更好的评估数据集。产生校准难度水平的能力可以更精确地帮助基准模型功能。尽管当前的实施使用GPT-4，但原理应扩展到其他LLM。 系统产生问题的系统方法似乎是迈向更严格的测试方法的重要一步。但是，我看到有关将其扩展到非常大的数据集并确保在不同领域的质量一致的问题。  tldr：新方法演示了如何使LLMS通过自我测试和迭代的改进来产生更好的测试问题，随着问题质量和难度校准的可衡量改善。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ivd5gj/chase_a_framework_for_automated_generation_of/</guid>
      <pubDate>Sat, 22 Feb 2025 07:12:27 GMT</pubDate>
    </item>
    <item>
      <title>通过对比度学习从时间序列数据中学习内在的神经表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一种对比度学习方法，将神经活动动态映射到几何表示，提取他们所说的“柏拉图式”人群级神经记录的形状。该方法将时间嵌入与几何约束结合在一起，以揭示基本的组织原理。 关键技术方面： - 在神经时间序列数据上使用对比度学习来学习低维的嵌入 - 应用拓扑结构来强制执行几何结构 - 验证 - 验证 - 验证 - 验证在来自不同物种的多个神经记录数据集中 - 显示了基本几何模式的一致出现（球体，托里等） - 证明了不同神经种群和大脑区域之间的鲁棒性 结果证明了： - 神经种群自然组织成几何歧管 - 这些几何模式在不同的时间范围内保留了这些几何模式 - 在任务和自发活动中始终出现表示的表示 - 方法工作在数十个到数千个神经元的种群上 - 几何结构与行为和认知变量相关 我认为这种方法可以为了解神经种群的编码和过程信息提供新的框架。几何视角可能有助于弥合单神经元和人口水平分析之间的差距。 我认为，如果我们可以可靠地将神经活动映射到神经假体和脑部计算机界面中，则最有趣的潜在影响是一致的几何表示，它可以使解码神经信号更加稳健。  tldr：新方法使用对比度学习如何显示神经种群将信息组织成几何形状，为神经计算提供潜在的通用原理。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iunfqx/learning_intrinsic_neural_representations_from/</guid>
      <pubDate>Fri, 21 Feb 2025 09:59:51 GMT</pubDate>
    </item>
    <item>
      <title>接近神经网络和机器学习理论的在线课程。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iu02so/online_courses_that_approach_neural_networks_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一名电气工程师，我想开始学习有关A.I.基础知识及其在嵌入式系统上的实现。但是，有关这些主题的大多数在线课程似乎都提供了更多的“ pratical”。通过向学生扔Python和Matlab包裹，而无需教授神经网络的实际运作方式。如果有人能够向我推荐一门课程（免费或付费），我将不胜感激，以了解神经网络和机器学习的基础，包括神经元的模型和Network的培训。   &lt;！ -  sc_on-- &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/neuralnetworks/comments/comments/1IU02SO/Online_courses_that_that_that_ apphact_neural_networks_and/”&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iu02so/online_courses_that_approach_neural_networks_and/</guid>
      <pubDate>Thu, 20 Feb 2025 14:44:29 GMT</pubDate>
    </item>
    <item>
      <title>基于内存的视觉基础模型，用于3D膝盖MRI分割的混合动力降温</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1itt241/memorybased_visual_foundation_model_with_hybrid/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种基于内存的视觉模型，称为SAMRI-2用于3D医疗图像分割，特别专注于MRI扫描中的膝盖软骨和半月板。关键创新是将记忆机制与混合洗牌策略结合在一起，以更好地处理3D空间关系，同时保持计算效率。 主要技术点： - 使用带有变压器的基于变压器的体系结构来处理3D卷 - 实施一种新颖的“混合洗牌策略”在有助于保持空间一致性的训练过程中 - 每次扫描仅需要3次点击作为提示 - 接受了270次患者扫描培训，对57例外部病例进行了测试 - 与3D -VNET和其他Transformer Baselines进行了比较 结果： -  &lt;强&gt;骰子得分比以前的方法提高了5％ - 胫骨软骨分割精度提高了12％ -  厚度测量显示3倍更好的精度 - 在不同的MRI机/协议上保持性能 - 每次扫描的处理时间约为30秒 我认为这种方法对于临床部署可能特别有价值，因为它与最小用户输入之间的自动化平衡。基于内存的设计似乎比以前的方法更有效地处理医学扫描的3D性质。 我认为混合洗牌策略是一种有趣的技术贡献，可以适用于其他3D视觉任务。只需单击3个点击即可维持准确性的能力。  tldr：基于膝关节MRI分析的新型内存模型，将强度的精度与最小的用户输入相结合（3次点击）。使用混合洗牌策略有效地处理3D数据。 完整摘要在这里。 Paper 在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1itt241/memorybased_visual_foundation_model_with_hybrid/</guid>
      <pubDate>Thu, 20 Feb 2025 07:34:20 GMT</pubDate>
    </item>
    <item>
      <title>引入CNN学习工具</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1it64cd/introducing_cnn_learning_tool/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用我的新互动应用程序探索卷积神经网络（CNN）的内部工作。观看每一层如何处理您的草图，对行动中的深度学习有更清晰的了解。 （这也很有趣） 链接： Applepear.streamlit.app    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/foreltert2597     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1it64cd/introducing_cnn_learning_tool/</guid>
      <pubDate>Wed, 19 Feb 2025 14:00:06 GMT</pubDate>
    </item>
    <item>
      <title>硬件优化的本地稀疏注意力，以进行有效的长篇下说建模</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1it2oyq/hardwareoptimized_native_sparse_attention_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键贡献是一种新的稀疏注意方法，它与可训练的端到端训练相一致。本机稀疏注意（NSA）不使用复杂的预处理或动态稀疏模式，而是使用与GPU内存访问模式相匹配的块 -  sparse模式。 主要技术点： - 引入固定但可学习的稀疏模式，这些模式与硬件保持一致 - 在正常训练期间学习模式，而无需预处理 - 使用针对GPU内存访问优化的块 -  sparse结构 - 与密集的关注相比，达到2-3倍的速度 - 在使用50-75％的计算 之间保持准确性 跨不同设置的结果： - 语言建模：匹配密集的注意力困惑 - 机器翻译：可比的BLEU分数 - 图像分类：与密集的注意力相似的准确性 - 量表很好随着序列长度的增加 - 在不同模型大小 之间有效地工作，我认为这种方法可以使变压器模型在资源约束环境中更实用。硬件对齐方式意味着理论效率的提高实际上转化为现实世界的性能改进，与许多现有的稀疏注意方法不同。 我认为块 -  sparse模式在某些情况下可能限制了块，代表了一种良好的交易 - 灵活性和效率之间的依据。在训练过程中学习这些模式的能力尤其重要，因为它允许模型使稀疏性适应任务。  tldr：新的稀疏注意方法，与硬件约束相一致并在训练，训练，学习稀疏模式时，达到2-3倍的速度而没有准确的损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1it2oyq/hardwareoptimized_native_sparse_attention_for/</guid>
      <pubDate>Wed, 19 Feb 2025 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>从多类变为多标签训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个神经网络，其中有1个输入层2隐藏层和1个输出层。现在，我将其用作多类分类器，这意味着输出是0到15之间的值（总计16个可能的和相互排斥的类）。但是，作为下一步，我想培训一个具有7个类的多标签分类器，并且每个班级都有多达6个子类，因此我希望每个类都有标签。  与多类培训相比，这有何不同？我想主要区别在于输入（例如标签）和输出层？到目前为止，我一直在输出层中使用SoftMax作为激活函数。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</guid>
      <pubDate>Tue, 18 Feb 2025 12:48:25 GMT</pubDate>
    </item>
    <item>
      <title>具有高精度肌肉和脂肪指标的人体组成分析的自动多组织CT分割模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种自动深度学习系统，用于分割和量化CT扫描的肌肉和脂肪组织。关键的技术创新是将修改后的U -NET体系结构与自定义损失功能中编码的解剖约束相结合。 关键技术点： - 修改了U -NET体系结构，对500个手动标记的CT扫描进行了培训 - 通过纳入扫描 - 解剖学验证 - 通过结合了解剖学。损失损失功能，以惩罚不可能的组织布置 - 生成不同组织类型的3D体积测量 - 每次扫描的处理时间为2-3分钟VS小时手动分析 结果： - 肌肉组织分割的精度为96％ - 皮下脂肪的精度为95％的精度 - 内脏脂肪的精度为94％ - 对3位专家放射科医生的测量结果进行了验证 - 跨不同身体的测量值类型 我认为这可能会通过将人体组成分析所需的时间从小时减少到几分钟来显着影响临床工作流程。高精度和解剖学意识的方法表明，它可能足够可靠用于临床使用。尽管需要更多的验证，尤其是对于边缘病例和极端身体组成，该系统显示出有望改善肿瘤学，营养和运动医学的治疗计划。 我认为解剖学约束的整合特别聪明 - 它有助于防止纯粹的深度学习方法可能产生的身体上不可能的细分。这种领域知识的整合对于其他医学成像任务可能很有价值。  tldr：自动化的CT扫描分析系统将深度学习与解剖学规则结合在一起，以2--的2--; 94％的精度来测量肌肉和脂肪组织。 3分钟。显示出临床使用的希望，但需要更广泛的验证。摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</guid>
      <pubDate>Tue, 18 Feb 2025 12:44:32 GMT</pubDate>
    </item>
    </channel>
</rss>