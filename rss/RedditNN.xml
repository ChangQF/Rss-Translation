<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Thu, 09 Jan 2025 21:15:28 GMT</lastBuildDate>
    <item>
      <title>Marimo 蟒蛇笔记本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</link>
      <description><![CDATA[我遇到的最令人印象深刻的 Python 笔记本是 Marimo，我强烈建议您尝试一下。需要澄清的是，Marimo 并没有赞助我；我只是喜欢使用它！ https://docs.marimo.io/    提交人    /u/ReceptionLow2817   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</guid>
      <pubDate>Thu, 09 Jan 2025 02:07:12 GMT</pubDate>
    </item>
    <item>
      <title>NeuralSVG：文本到矢量生成的隐式表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</guid>
      <pubDate>Wed, 08 Jan 2025 20:22:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试模仿生物神经元的行为来模拟人工智能神经元的行为</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</guid>
      <pubDate>Tue, 07 Jan 2025 01:09:19 GMT</pubDate>
    </item>
    <item>
      <title>[工具发布] 神经网络工具包（NNT）——神经网络的可视化开发环境</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</link>
      <description><![CDATA[      我开发了一个用于设计和试验神经网络的可视化工具，它是作为 ComfyUI 的一组自定义节点构建的。目标是创建一个环境，通过视觉交互和实时反馈使神经网络概念变得更加具体。 特点：  基于节点的界面，用于构建神经架构 60 个自定义节点，用于各种层类型和操作 张量操作和梯度的实时可视化 带有视觉反馈的交互式训练过程 支持包括 transformer 和注意机制在内的现代架构 内置工具，用于数据加载、预处理和分析  技术能力：  密集层、卷积层、LSTM 层和 RNN 层 各种注意机制（原始、线性、局部等） 位置编码选项（正弦、学习、旋转、不在场证明） 具有可配置的训练节点用于优化器和损失函数 用于数学运算的综合张量运算节点 用于梯度、雅可比矩阵和 Hessians 的高级可视化工具 加载和保存各种模型格式  教育用例：  尝试不同的架构 理解注意力机制 直观地探索张量运算 实时分析训练动态  该工具包允许您构建任何东西，从基本的 MLP 到更复杂的架构，如自动编码器、GAN 或基于变压器的模型。网络的每个组件都可以实时检查和修改。 GitHub：https://github.com/inventorado/ComfyUI_NNT https://preview.redd.it/7i4etnwwmcbe1.png?width=12724&amp;format=png&amp;auto=webp&amp;s=b2c3ff0dd316b0d4799c1ce24f966d85737eb3ae 这是早期版本，侧重于教育和实验用途。来自神经网络社区的反馈将特别有价值。    提交人    /u/inventorado   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</guid>
      <pubDate>Mon, 06 Jan 2025 10:22:37 GMT</pubDate>
    </item>
    <item>
      <title>准确判断人工智能对书籍和电影的影响程度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</link>
      <description><![CDATA[👋大家好 歌词介绍 像我们许多人一样，我深爱文学和电影。大约一年来，我一直在思考人工智能如何在文学和电影领域发挥作用。我确信这将导致作家和作者的贬值。在我看来，这不是未来的问题，而是现在的问题。当一部新的、非常成功的系列、电影或书籍发布时，一部分观众会自动认为人工智能一定参与其中。这反过来又破坏了数百甚至数千名专业作家的巨大努力。未来，这种情况显然只会恶化。 问题 我知道有五种通用的人工智能检测器（主要用于分析文章），据我所知，它们都是通过分析文本来寻找 ChatGPT 和其他 LLM 的典型模式。另一方面，有很多所谓的“人性化工具”，这些工具使人工智能生成的文本看起来更像人类，从而使检测变得复杂。更不用说文本可能是人工智能生成的，但由人类手动编辑，反之亦然的可能性了。 问题 我对专家的意见非常感兴趣。如果我们增加尽可能多的文本分析层次——例如，检查作者的草稿、过去的作品、正在审查的文件的元数据（如果技术上可行的话，包括创建时间和编辑频率）、在审查过程中给作者一个随机任务来分析他们的写作风格等——是否有可能准确确定人工智能对其作品的影响程度？例如：  由人工智能生成并由人类编辑 由人类编写并由人工智能编辑 完全由人工智能编写 完全由人类编写  是否可以通过使用适当的场景和示例训练神经网络来实现这种检测？    提交人    /u/YouranusAlien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</guid>
      <pubDate>Sun, 05 Jan 2025 16:52:21 GMT</pubDate>
    </item>
    <item>
      <title>第一个神经网络 - 帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hu3o06/first_neural_network_help/</link>
      <description><![CDATA[因此，我正在构建我的第一个用于（多类）分类目的的神经网络。这个想法相当简单，接受一些段落向量嵌入（通过 python 的 sentence_transformer 包生成），将其传递给 2 个隐藏层并得到一个大小为 N 的输出层，其中 N 是可能状态的数量，每个状态代表来自主题列表的一个主题，最能描述该段落。 参数为： - 每个输入段落向量的嵌入大小为 768；  - 第一个隐藏层的大小为 768x768，使用线性激活函数 - 第二个隐藏层的大小为 768x768，使用 ReLU 激活函数 - 第三层的大小为 768xN，使用 Softmax 激活函数 - 优化器是 Adam，损失函数是分类交叉熵 不可否认，激活函数的选择相当随意，我还没有读到哪个可能是分类用例的最佳选择，虽然到目前为止，据我了解，如果目标是分类，则 softmax 是在输出层上使用的激活函数。  到目前为止，我已经在大小为 1000 的数据集上对它进行了训练，我知道这个数据集不是很大，而且我也不会期待完美的结果（并且数据集会日益增长），但似乎有些不对劲。首先，训练指标似乎并没有从一个步骤到下一个步骤或一个时期到下一个时期有所改善。 此外，如果我训练模型并随后传递一个新的段落向量进行预测，则输出向量会吐出一个大小为 N 的向量，该向量全由 1 组成（实际标签可能性范围从 1 到 12）。  我这里遗漏了什么吗？如何解释这种输出？我的一个想法是，我在我的用例中贴错了标签，即，我应该将其归类为一个由 0 组成的数组，而不是将属于类“8”的实体标记为“8”，而是将其归类为除第 8 位为 1 之外的所有 0 的数组？    提交人    /u/RDA92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hu3o06/first_neural_network_help/</guid>
      <pubDate>Sun, 05 Jan 2025 10:05:45 GMT</pubDate>
    </item>
    <item>
      <title>训练神经网络进行手部运动识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1htk2iv/training_a_neural_network_for_hand_movement/</link>
      <description><![CDATA[我正在使用自己的数据集训练神经网络来识别特定的手部动作。由于我自己创建了数据集，因此它仅包含有限数量的图像，并且我已经应用了数据增强来增加数据集大小。 但是，我在某些类别上仍然得到较差的结果。鉴于我的数据集很小并且由主体执行手势的图像组成，我想知道：  我是否应该裁剪图像中的手以专注于手势，还是最好将整个主体包含在图像中？ 您能否推荐一些轻量级的预训练模型（大小为几 MB）供我用于此任务？     提交人    /u/Wonderful-Beat3355   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1htk2iv/training_a_neural_network_for_hand_movement/</guid>
      <pubDate>Sat, 04 Jan 2025 17:57:25 GMT</pubDate>
    </item>
    <item>
      <title>一些神经元真的能够被两种不同的模式激活吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hthbkk/is_it_true_that_some_neurons_can_be_activated_by/</link>
      <description><![CDATA[我记得我曾经看过一个视频，解释神经网络如何对图像进行分类。在这个视频中，他们展示了前几层如何关注简单的模式，比如边缘或点，但是随着我们向上看，我们看到激活某些神经元的模式，我们开始识别眼睛或手之类的东西，最终我们可以看到蛇、飞机等等。但是在这个视频中，他们还展示了一些神经元可以被两个看似不相关的概念激活，比如猫和汽车，或者狐狸和汽车，或者诸如此类的东西。他们解释说这是有道理的，神经元必须能够执行多任务，毕竟模式比神经元多，所以它们当然必须识别不止一种东西，然后其他神经元可以通过寻找其他模式来细化结果，比如眼睛或轮子。我记得很清楚，但我找不到视频。但是我不需要视频，我只需要确保这是真的，那么，是吗？单个神经元能被两种不同的模式激活吗？    提交人    /u/Frigorifico   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hthbkk/is_it_true_that_some_neurons_can_be_activated_by/</guid>
      <pubDate>Sat, 04 Jan 2025 15:56:03 GMT</pubDate>
    </item>
    <item>
      <title>无法正确预测</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1htgjyo/not_able_to_predoct_properly/</link>
      <description><![CDATA[免责声明：这是我第一次创建神经网络 因此，我创建了一个神经网络来预测手写数字（参见 Samson zhangs 视频）现在在 mnsit 数据集上训练它的准确率约为 88%，但每当我提供自己的输入（用 paint 制作的 28x28 绘图）时，它都无法正确预测 sm1 可以帮忙吗（我正在为我的学校项目尝试这样做）    提交人    /u/SorbetMajor7934   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1htgjyo/not_able_to_predoct_properly/</guid>
      <pubDate>Sat, 04 Jan 2025 15:20:40 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合和欠拟合 - 简单解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1htgf1u/overfitting_and_underfitting_simply_explained/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1htgf1u/overfitting_and_underfitting_simply_explained/</guid>
      <pubDate>Sat, 04 Jan 2025 15:14:06 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络无法识别使用 HTML Canvas 绘制的 PNG 中的数字，但它可以识别在其他应用程序中绘制的 PNG 中的数字。有人能帮我找出原因吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hsp5l9/my_neural_network_cant_recognise_digits_from_pngs/</link>
      <description><![CDATA[我用 Python 创建了一个神经网络，并使用来自 MNIST 数据集的 100 张图像对其进行了训练。它可以以相对较高的准确度识别我在 Figma 等应用程序中创建的 28x28 PNG 中的数字，但似乎无法识别我使用 HTML Canvas 绘制的 28x28 图像。 这是我的 Python 代码，它使用 imageio 库加载 PNG： print (&quot;loading ... my_own_images/2828_my_own_image.png&quot;) img_array = imageio.v3.imread(&#39;my_own_images/2828_my_own_image.png&#39;, mode=&#39;F&#39;)  # 从 28x28 重塑为 784 个值的列表，反转值 img_data = 255.0 - img_array.reshape(784)  # 将数据缩放到 0.01 到 1.0 的范围 img_data = (img_data / 255.0 * 0.99) + 0.01 如果有人有任何建议，我将不胜感激 - 尽管我为 HTML 画布提供的 React.js 代码很长，但我很乐意在必要时提供任何进一步的代码。    提交人    /u/RedGiraffeElephant   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hsp5l9/my_neural_network_cant_recognise_digits_from_pngs/</guid>
      <pubDate>Fri, 03 Jan 2025 15:36:12 GMT</pubDate>
    </item>
    <item>
      <title>制作一个国际象棋引擎可视化 GUI，让你了解基于神经网络的国际象棋引擎是如何思考的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hs7x0s/making_a_chess_engine_visualization_gui_that_lets/</link>
      <description><![CDATA[      大家好，我是一名高中生，正在为一个使用 lc0 的学校项目开发这款国际象棋可视化工具，该工具通过详细输出模式和引擎分析制作了神经网络评估热图。您可以与引擎对战，也可以将其用作分析工具，以了解基于 NN 的引擎如何“思考”。链接到 youtube 预览：https://www.youtube.com/watch?v=7nbWr8TR6nA 预览 github：https://github.com/jay63683/BlackBox-Chess-a-XAI-leela-chess-GUI 需要 Processing 才能运行。或者，如果您不想下载 Processing，您可以直接观看视频教程。计划将引擎切换到 ONNX 以进行未来的更新，这样我就可以使用 ONNX 工具更深入地解释流程。非常感谢您的反馈。    由   提交  /u/Lower_Junket_222   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hs7x0s/making_a_chess_engine_visualization_gui_that_lets/</guid>
      <pubDate>Thu, 02 Jan 2025 23:31:17 GMT</pubDate>
    </item>
    <item>
      <title>PyReason 入门教程：宠物商店示例</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hp9654/intro_pyreason_tutorial_pet_store_example/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hp9654/intro_pyreason_tutorial_pet_store_example/</guid>
      <pubDate>Sun, 29 Dec 2024 23:34:54 GMT</pubDate>
    </item>
    <item>
      <title>可视化神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hoyzue/visualizing_neural_networks/</link>
      <description><![CDATA[大家好，我正在尝试为我的论文制作一些漂亮的神经网络可视化，但我觉得它们都很糟糕。是否有可视化神经网络的标准化或某种人工智能工具可以做到这一点？ 我有两个网络，一个只有 LSTM 和一个输出，另一个编码器解码器框架也使用 LSTM。真的很想为它们做一个漂亮的可视化。    提交人    /u/Packman-2022   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hoyzue/visualizing_neural_networks/</guid>
      <pubDate>Sun, 29 Dec 2024 16:03:24 GMT</pubDate>
    </item>
    <item>
      <title>提高物理神经网络的学习能力</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hoshuk/improve_learning_for_physics_informed_neural/</link>
      <description><![CDATA[      大家好， 我目前正在使用 DeepXDE 库研究 PINN，用于热传输方程的逆参数估计。虽然 PINN 总体运行良好，但我在学习过程中遇到了一个问题：最初，训练进展顺利，但在某个点之后，损失函数开始波动（见图）。 我使用了 Adam 优化器和 L-BFGS-B 算法的组合。尽管尝试了各种设置，我仍然无法解决这个问题。 有人有什么技巧或建议来改善学习过程并稳定损失函数吗？ 提前谢谢您！ https://preview.redd.it/yrr9g628ar9e1.png?width=640&amp;format=png&amp;auto=webp&amp;s=a013a6e099cec3b4c9b74a98db2eb470f56e2fce    由   提交  /u/ConsistentDimension9   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hoshuk/improve_learning_for_physics_informed_neural/</guid>
      <pubDate>Sun, 29 Dec 2024 09:24:21 GMT</pubDate>
    </item>
    </channel>
</rss>