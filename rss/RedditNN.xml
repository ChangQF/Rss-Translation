<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 22 Jun 2024 09:14:57 GMT</lastBuildDate>
    <item>
      <title>AI 阅读清单 - 第 5 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dlqcc8/ai_reading_list_part_5/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dlqcc8/ai_reading_list_part_5/</guid>
      <pubDate>Sat, 22 Jun 2024 07:41:23 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器 | 深度学习动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dlgrr3/autoencoders_deep_learning_animated/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dlgrr3/autoencoders_deep_learning_animated/</guid>
      <pubDate>Fri, 21 Jun 2024 22:40:25 GMT</pubDate>
    </item>
    <item>
      <title>简单解释 LoRA 的实际工作原理 (ELI5)</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dl55h7/simply_explaining_how_lora_actually_works_eli5/</link>
      <description><![CDATA[假设在您的 LLM 中，您有维度为 d x k 的原始权重矩阵 W。 您的传统训练过程会直接更新 W - 如果 d x k 很大，那么参数数量将非常庞大，需要大量计算。 因此，我们在权重更新之前使用低秩分解对其进行分解。方法如下 - 我们将权重更新 (Delta W) 表示为两个低秩矩阵 A 和 B 的乘积，使得 Delta W = BA。 这里，A 是维度为 r x k 的矩阵，B 是维度为 d x r 的矩阵。这里，r（秩）比 d 和 k 小得多。 现在，矩阵 A 用一些随机高斯值初始化，矩阵 B 用零初始化。 为什么？因此最初 Delta W = BA 可以为 0。 现在开始训练过程： 在权重更新期间，仅更新较小的矩阵 A 和 B - 这大大减少了需要调整的参数数量。 对原始权重矩阵 W 的有效更新是 Delta W = BA，它使用更少的参数来近似 W 的变化。 让我们比较一下 LoRA 之前和之后要更新的参数： 之前，要更新的参数是 d x k（记住 W 的尺寸）。 但是现在，参数数量减少到 (d x r) + (r x k)。这个值要小得多，因为秩 r 被认为比 d 和 k 小得多。 这就是低秩近似如何通过这种紧凑的表示为您提供有效的微调。 训练速度更快，需要的计算和内存更少，同时仍然可以从微调数据集中捕获重要信息。 我还使用 Artifacts 制作了一个快速动画来解释（大约花了 10 秒）： https://www.linkedin.com/posts/sarthakrastogi_simply-explaining-how-lora-actually-works-activity-7209893533011333120-RSsz    提交人    /u/sarthakai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dl55h7/simply_explaining_how_lora_actually_works_eli5/</guid>
      <pubDate>Fri, 21 Jun 2024 14:19:55 GMT</pubDate>
    </item>
    <item>
      <title>案例研究：人工智能和计算机视觉——在麦克风后面和舞台上</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dl2r07/case_study_artificial_intelligence_and_computer/</link>
      <description><![CDATA[在案例研究回顾中，您将了解机器人如何创作交响乐。神经网络创造热门歌曲，3D 投影在舞台上表演，音乐服务根据声谱图对曲目进行评分。音乐文化是不断发展的技术的完美游乐场 完整文章位于 OpenCV.ai 博客中。链接此处。    提交人    /u/Computer_Vision4883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dl2r07/case_study_artificial_intelligence_and_computer/</guid>
      <pubDate>Fri, 21 Jun 2024 12:24:53 GMT</pubDate>
    </item>
    <item>
      <title>概率电路（YooJung Choi，亚利桑那州立大学）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dkfzjg/probabilistic_circuits_yoojung_choi_asu/</link>
      <description><![CDATA[        由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dkfzjg/probabilistic_circuits_yoojung_choi_asu/</guid>
      <pubDate>Thu, 20 Jun 2024 16:32:32 GMT</pubDate>
    </item>
    <item>
      <title>高维函数上的神经网络基准测试</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dk9zc3/benchmark_neural_networks_on_highdimensional/</link>
      <description><![CDATA[对于个人项目，我有兴趣在高维函数逼近的背景下对某些神经网络架构进行基准测试。具体来说，我对 R^d 中在 [0,1]^d 上定义的连续、平滑、Hölder 和 Sobolev 函数感兴趣。  是否有人知道文献中是否通常使用 *标准* 高维函数列表来对此类模型进行基准测试？例如，在优化文献中，有一个标准函数列表，例如此处找到的函数，用于对各种优化算法进行基准测试。 如果没有这样的列表，应该如何构建一个有代表性的函数列表？这种选择会在问题中引入归纳偏差，因此我想确保列表尽可能具有代表性。  谢谢！    提交人    /u/JM753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dk9zc3/benchmark_neural_networks_on_highdimensional/</guid>
      <pubDate>Thu, 20 Jun 2024 12:06:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和政治可以共存——但新技术不应该掩盖选举往往获胜的领域——在实地</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1djixkv/ai_and_politics_can_coexist_but_new_technology/</link>
      <description><![CDATA[    /u/CWang   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1djixkv/ai_and_politics_can_coexist_but_new_technology/</guid>
      <pubDate>Wed, 19 Jun 2024 13:16:26 GMT</pubDate>
    </item>
    <item>
      <title>需要编码伙伴</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1djbrna/need_coding_partner/</link>
      <description><![CDATA[我是编码新手，对 PyTorch 一无所知。我需要一个像我这样的合作伙伴，这样我就不会对开发 nn 和 ai 失去兴趣，也不必孤军奋战。年龄大概在 17-18 岁左右，这样我的智力就不会无人能及    提交人    /u/Purple-Meaning-6306   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1djbrna/need_coding_partner/</guid>
      <pubDate>Wed, 19 Jun 2024 05:46:08 GMT</pubDate>
    </item>
    <item>
      <title>AI 阅读清单 - 第 4 部分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1diob1c/ai_reading_list_part_4/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1diob1c/ai_reading_list_part_4/</guid>
      <pubDate>Tue, 18 Jun 2024 11:25:26 GMT</pubDate>
    </item>
    <item>
      <title>溯因学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1di3kjq/abductive_learning/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1di3kjq/abductive_learning/</guid>
      <pubDate>Mon, 17 Jun 2024 17:20:23 GMT</pubDate>
    </item>
    <item>
      <title>注意力层作为输入数据过滤器</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dhjc2i/attention_layer_as_input_data_filter/</link>
      <description><![CDATA[嗨，我找不到关于此事的决定性来源。在将输入数据进一步传递到网络之前，是否可以使用注意层作为输入数据的一种过滤器？是否可以使用它来减少输入的维度（例如类似于 PCA - 只有注意层会用网络进行训练）并因此减少网络架构（例如，我们可以使用接受较小输入维度的网络）？    提交人    /u/Smooth-Ad9045   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dhjc2i/attention_layer_as_input_data_filter/</guid>
      <pubDate>Sun, 16 Jun 2024 22:40:32 GMT</pubDate>
    </item>
    <item>
      <title>注意力层作为输入数据过滤器</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dhi18r/attention_layer_as_input_data_filter/</link>
      <description><![CDATA[嗨，我找不到关于此事的决定性来源。在将输入数据进一步传递到网络之前，是否可以使用注意层作为输入数据的一种过滤器？是否可以使用它来减少输入的维度（例如类似于 PCA - 只有注意层会用网络进行训练）并因此减少网络架构（例如，我们可以使用接受较小输入维度的网络）？    提交人    /u/Smooth-Ad9045   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dhi18r/attention_layer_as_input_data_filter/</guid>
      <pubDate>Sun, 16 Jun 2024 21:38:39 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络训练人工智能驾驶</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgzwo3/training_an_ai_to_drive_using_neural_network/</link>
      <description><![CDATA[        提交人    /u/Flimsy_Roll_5666   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgzwo3/training_an_ai_to_drive_using_neural_network/</guid>
      <pubDate>Sun, 16 Jun 2024 04:42:52 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 是人工智能监控工具吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgn8sl/is_openai_an_ai_surveillance_tool/</link>
      <description><![CDATA[        提交人    /u/BackgroundResult   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgn8sl/is_openai_an_ai_surveillance_tool/</guid>
      <pubDate>Sat, 15 Jun 2024 17:39:15 GMT</pubDate>
    </item>
    <item>
      <title>寻求多视图模型方面的帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1dgcvud/looking_for_help_with_a_multiview_model/</link>
      <description><![CDATA[我正在使用 MURA 数据集，并尝试使用每个患者的 5-7 个视图来训练我的模型，我关注了论文并阅读了许多文章，但似乎始终无法获得他们在论文中声称的准确度，这可能是一个很大的原因，因为我似乎找不到他们正在使用的确切网络架构，而我只是在他们提供的非常小的信息位之间填补空白，目前我使用 xception 预训练模型作为我的 base_model 并通过它输入 7 个视图，以便可以将它们连接起来，然后是全局平均池化层，然后是 512 密集层，最后是输出层，哦，我似乎忘了提到目标，我试图仅使用其中的 7 个中的 5 个来对骨骼类型进行分类，有人能告诉我为什么我不能达到高于 70% 的准确度，即使他们声称对于完全相同的任务，准确度高达 95 和97    由    /u/youssefkhalifa 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1dgcvud/looking_for_help_with_a_multiview_model/</guid>
      <pubDate>Sat, 15 Jun 2024 07:53:26 GMT</pubDate>
    </item>
    </channel>
</rss>