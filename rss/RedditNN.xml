<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Mon, 03 Feb 2025 15:17:29 GMT</lastBuildDate>
    <item>
      <title>计算隐藏层的批量标准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</link>
      <description><![CDATA[我试图了解对隐藏层执行批量规范的细节。我理解，对于给定的神经元，比如说 l 层中的 Xl，我们需要计算所有小批量样本的平均值和方差，以标准化其激活，然后再将其输入到下一层。 我想了解上述计算究竟是如何完成的。一种方法可能是处理小批量的每个元素并收集 l 层神经元的统计数据，并忽略后续层。一旦计算出 l 层中所有元素的平均值和方差，就再次处理 l+1 层的小批量元素，依此类推。这似乎相当浪费。这是正确的吗？ 如果不是，请分享正在执行的确切计算的描述。我感到困惑的根源是 l 层的标准化会影响进入 l+1 层的值。因此，除非我们知道 l 层的平均值和方差，否则我们如何标准化下一层。提前谢谢您。    由   提交  /u/Far-Cantaloupe4144   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</guid>
      <pubDate>Mon, 03 Feb 2025 06:09:34 GMT</pubDate>
    </item>
    <item>
      <title>用于多啁啾参数估计的曲率引导朗之万蒙特卡罗方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</link>
      <description><![CDATA[本文介绍了一种使用曲率引导的朗之万蒙特卡罗 (CLMC) 估计多啁啾信号参数的新方法。关键创新是将参数空间的几何信息与随机采样相结合，以更好地处理重叠频率分量。 主要技术贡献：- 将曲率信息集成到朗之万蒙特卡罗框架中 - 基于局部几何特性的自适应步长机制 - 处理参数空间中多峰分布的新方法 - 引导采样的二阶信息的实现 结果表明：- 与标准方法相比，参数估计精度有所提高 - 在低 SNR 条件下性能更佳（最高可达 -5dB） - 更可靠地分离紧密间隔的频率分量 - 与传统 LMC 相比收敛速度更快 - 成功处理多达 4 个重叠的啁啾分量 我认为这项工作为雷达和声纳等精确频率分析至关重要的应用开辟了新的可能性。更好地分离重叠组件的能力对于无线通信和医学成像应用尤其有价值，因为信号清晰度至关重要。 我认为主要的限制是计算复杂度随组件数量的增加而扩大，这可能会限制实时应用。该方法还需要仔细调整参数，这可能会使实际部署具有挑战性。 TLDR：新方法将曲率信息与朗之万蒙特卡罗相结合，以获得更好的多啁啾参数估计，在处理重叠频率分量时显示出更高的准确性和稳健性。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</guid>
      <pubDate>Sun, 02 Feb 2025 20:11:28 GMT</pubDate>
    </item>
    <item>
      <title>Elman 网络 - 你能解释一下它们是什么以及它们如何工作吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</link>
      <description><![CDATA[  由    /u/No_Refrigerator_7841  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</guid>
      <pubDate>Sat, 01 Feb 2025 22:08:02 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 由 1 亿个感知器组成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</link>
      <description><![CDATA[        由    /u/keghn 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</guid>
      <pubDate>Sat, 01 Feb 2025 20:51:43 GMT</pubDate>
    </item>
    <item>
      <title>让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 支持的公司的创始人，我们正在尝试让训练 ML 模型变得非常容易和便宜。在接下来的 2 周内，我们将运行 *免费* 测试版，并希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看我们：https://github.com/tensorpool/tensorpool TLDR；免费 GPU 😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Sat, 01 Feb 2025 20:26:06 GMT</pubDate>
    </item>
    <item>
      <title>建立文本到图像扩散模型以实现受控的高质量图像生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</link>
      <description><![CDATA[本文提出了 ObjectDiffusion，这是一种以对象名称和边界框为条件的文本到图像扩散模型，以实现对对象在特定位置的精确渲染和放置。 ObjectDiffusion 将 ControlNet 的架构与 GLIGEN 的基础技术相结合，显著提高了受控图像生成的精度和质量。 所提出的模型优于目前在开源数据集上训练的最先进的模型，在精度和质量指标上取得了显着的提升。 ObjectDiffusion 可以合成多样化、高质量、高保真度的图像，并与指定的控制布局保持一致。 论文链接：https://www.arxiv.org/abs/2501.09194    由   提交  /u/Next_Cockroach_2615   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</guid>
      <pubDate>Thu, 30 Jan 2025 00:30:50 GMT</pubDate>
    </item>
    <item>
      <title>我需要为我的项目标记你的数据</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iccmca/i_need_to_label_your_data_for_my_project/</link>
      <description><![CDATA[您好！ 我正在开展一个涉及机器学习的私人项目，具体涉及数据标记领域。 目前，我的团队正在接受标记方面的培训，需要接触真实数据集，以了解标记真实数据所面临的挑战和细微差别。 我们正在寻找拥有需要标记的数据集的人员或项目，以便我们进行合作。我们将标记您的数据，我们唯一的要求就是在我们完成标记过程后，请您填写一份简单的反馈表。 您可以成为公司的一员，从事个人项目，或参与任何计划 — 真的，任何事情都可以。我们所需要的只是需要标记的数据。 如果您有数据集（文本、图像、音频、视频或任何其他类型的数据）或认识有数据集的人，请随时给我发送 DM，以便我们讨论细节    提交人    /u/rafacvs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iccmca/i_need_to_label_your_data_for_my_project/</guid>
      <pubDate>Tue, 28 Jan 2025 21:18:27 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我刚刚做了一些工作，制作了一个推荐系统，使用知识感知耦合图神经网络和变换器，如果有人可以帮助我，请给我留言，我有一些参考，但需要帮助理解它们</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ibzjmc/hi_guys_i_just_did_some_work_on_making_a/</link>
      <description><![CDATA[  由    /u/Busy_Low_1903  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ibzjmc/hi_guys_i_just_did_some_work_on_making_a/</guid>
      <pubDate>Tue, 28 Jan 2025 11:32:39 GMT</pubDate>
    </item>
    <item>
      <title>免费的深度学习初学者课程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ibuz0b/free_beginner_course_to_get_into_deep_learning/</link>
      <description><![CDATA[大家好！ 嘿，我刚刚开始写一份时事通讯，希望它能帮助人们了解深度学习的基础知识，并澄清一些我在学习过程中发现很难理解的事情。我在每个方面都花了不少时间，所以如果有人想从基础开始，我想在这里分享一下。 https://www.linkedin.com/newsletters/neural-notes-understanding-ai-7282889158631534592/    提交人    /u/BeautifulBitter7188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ibuz0b/free_beginner_course_to_get_into_deep_learning/</guid>
      <pubDate>Tue, 28 Jan 2025 05:55:36 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我开始学习 CNN，我想制作一个模型来去除这些黑点，还可以构建损坏的文本。现在我有 70 张这样的图片，我已经用 photoshop 清理过了。如果有人能给我一些关于如何开始的指导。谢谢</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ib61cb/hello_guys_so_i_started_learning_cnn_and_i_want/</link>
      <description><![CDATA[        提交人    /u/Sure_Recipe_2143   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ib61cb/hello_guys_so_i_started_learning_cnn_and_i_want/</guid>
      <pubDate>Mon, 27 Jan 2025 11:03:38 GMT</pubDate>
    </item>
    <item>
      <title>将 XGBoost 与 Pytorch 结合起来。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iad01o/combining_xgboost_with_pytorch/</link>
      <description><![CDATA[我一直在尝试将 XGBoost 和 PyTorch 结合起来，看看它们如何相互补充。我们的想法是使用 XGBoost 的预测并将其输出输入 PyTorch 进行深度学习，从而创建一种混合模型。结果非常有趣——似乎这种方法在某些情况下确实可以提高性能。  想知道是否有其他人尝试过类似的东西或对这个组合有见解？很想听听您的想法或建议！  https://machinelearningsite.com/machine-learning-using-xgboost/    提交人    /u/kolbenkraft   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iad01o/combining_xgboost_with_pytorch/</guid>
      <pubDate>Sun, 26 Jan 2025 12:11:48 GMT</pubDate>
    </item>
    <item>
      <title>从 pickle 加载模型-没有名为“ModuleName”的模块</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iabhwn/loading_model_from_pickle_no_module_named/</link>
      <description><![CDATA[我有 2 个项目，一个用于训练各种神经网络模型和 LLM，然后应该通过 API 调用（对于 LLM）或通过 pickle 从第二个项目加载，该项目是一种文本分析算法（包括文本解析大型 PDF 和其他更简单的 nlp 任务）。  我遇到的问题是，当我 pickle 我的神经网络并尝试将其加载到第二个工作区中时，我收到 ModuleNotFoundError “没有名为“neuralnet”的模块&quot;，neuralnet 是一个文件（neuralnet.py（其中包含实际的神经网络逻辑并训练模型。我试图将文件复制到第一个工作区，但仍然遇到同样的错误。 显然我在保存和加载模型方面做错了什么？有人遇到过类似的困难吗？    提交人    /u/RDA92   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iabhwn/loading_model_from_pickle_no_module_named/</guid>
      <pubDate>Sun, 26 Jan 2025 10:47:06 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 幻觉提高药物发现绩效：多模型分析</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i9rkqj/leveraging_llm_hallucinations_to_enhance_drug/</link>
      <description><![CDATA[研究人员探索了 LLM 中的受控幻觉如何通过实现新分子的生成而真正有益于药物发现。他们开发了在生成分子结构时调整 GPT-4 幻觉率的方法，并分析了幻觉水平与类药物化合物新颖性之间的关系。 关键技术要点： - 实施温度缩放和核采样以控制幻觉率 - 使用标准指标（有效性、类药性、新颖性）评估生成的分子 - 测试不同的幻觉水平及其对分子特性的影响 - 分析分子新颖性和化学可行性之间的权衡 - 开发快速工程技术来指导分子生成 结果表明： - 中等幻觉率（0.4-0.6）产生了最有前途的分子 - 生成的化合物保持了基本的化学有效性 - 更高的新颖性与增加的幻觉率相关 - 模型展示了创建以前未知的结构的能力 - 输出质量因采样参数而显着变化 我认为这可以通过提供新的候选分子来源来改变早期药物发现。虽然计算可行性并不能保证现实世界的可行性，但快速生成新结构的能力可以加速初步筛选过程。关键挑战将是通过实验验证这些化合物并确保安全。 该方法需要在以下方面做更多工作：- 物理合成验证 - 毒性筛选 - 与现有管道集成 - 可重复性标准 - 法规遵从性 TLDR：研究人员发现，受控的 LLM 幻觉可以产生新的、化学上有效的候选药物。通过调整幻觉率，他们平衡了分子新颖性与化学可行性。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i9rkqj/leveraging_llm_hallucinations_to_enhance_drug/</guid>
      <pubDate>Sat, 25 Jan 2025 17:07:40 GMT</pubDate>
    </item>
    <item>
      <title>梦想学习</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i91h6u/dreaming_learning/</link>
      <description><![CDATA[一种在神经网络中包含新颖性并为时间序列范式转变准备网络的新方法 https://arxiv.org/abs/2410.18156    提交人    /u/neuralessandro   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i91h6u/dreaming_learning/</guid>
      <pubDate>Fri, 24 Jan 2025 17:54:58 GMT</pubDate>
    </item>
    <item>
      <title>通过测试时间回归理解序列模型：神经架构中的联想记忆框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i8ym2u/understanding_sequence_models_through_testtime/</link>
      <description><![CDATA[本文介绍了一种测试时回归框架，该框架以一种新颖的方式进行序列建模 - 它不依赖标准注意力机制，而是在推理过程中执行回归以构建联想记忆连接。 关键技术要点：* 该模型在推理期间而不是仅在训练期间执行动态内存更新 * 使用双线性投影技术在序列元素和记忆状态之间进行映射 * 实现 O(n) 复杂度，同时保持与 O(n²) 注意力模型的竞争性能 * 在长距离依赖任务上显示出强大的效果 * 在序列长度 &gt;1000 个标记上显示出持续的改进 主要实证发现：* 与标准注意力机制相比，速度提高 15-20% * 内存使用量与序列长度成线性比例 * 与完全注意力基线相比，准确率保持 98% * 在需要联想回忆的任务上特别强大 * 适用于多种架构（Transformers、RNN） 我认为这种方法可以为我们在实践中处理长序列的方式带来有意义的改进。线性缩放属性使其特别适用于处理较长的文档或时间序列。虽然内存权衡需要仔细考虑，但在推理过程中建立联想连接的能力为自适应模型开辟了新的可能性。 我怀疑我们会看到这个框架适用于特定领域，如文档 QA 和时间序列预测，其中联想记忆方面可能特别有价值。与现有架构的兼容性使其非常实用。 TLDR：新框架在推理时执行回归以构建联想记忆，实现线性复杂度，同时保持强大的性能。显示出对长序列任务的特殊希望。 完整摘要在这里。论文此处    由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i8ym2u/understanding_sequence_models_through_testtime/</guid>
      <pubDate>Fri, 24 Jan 2025 15:56:39 GMT</pubDate>
    </item>
    </channel>
</rss>