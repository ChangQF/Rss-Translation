<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 19 Jan 2024 03:16:02 GMT</lastBuildDate>
    <item>
      <title>全连接层。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1997h71/full_connected_layers/</link>
      <description><![CDATA[我正在尝试学习神经网络，但目前不了解很多数学知识，所以我有一个问题要问那些知道自己的知识的人关于.我在 python 中使用的神经网络是完全连接的，显然这很好，但它违背了我的直觉，也违背了我认为神经网络的好处。当然，拥有许多不同类型的连接可以存储更复杂的信息。   由   提交/u/Unlucky_Culture_6996   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1997h71/full_connected_layers/</guid>
      <pubDate>Wed, 17 Jan 2024 20:55:24 GMT</pubDate>
    </item>
    <item>
      <title>输入复杂度和所需的隐藏层之间到底有什么关系？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1995sxc/what_exactly_is_the_relationship_between_input/</link>
      <description><![CDATA[ 由   提交/u/swampshark19  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1995sxc/what_exactly_is_the_relationship_between_input/</guid>
      <pubDate>Wed, 17 Jan 2024 19:49:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 闪电模型只需很少的代码行即可完成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/</link>
      <description><![CDATA[      我刚刚建立了一个Python库来帮助构建PyTorch闪电模型只需很少的代码行。我很想听听您的想法！ https://github.com/brianrisk/lightning_factory&lt; /p&gt; 闪电工厂概览&lt; /p&gt; ​ ​   由   提交/u/qwaver-io  /u/qwaver-io  reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1990pgj/pytorch_lightning_models_made_with_very_few_lines/</guid>
      <pubDate>Wed, 17 Jan 2024 16:30:56 GMT</pubDate>
    </item>
    <item>
      <title>大脑连接性突破：在不同物种中发现相似的神经网络模式</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/198zhok/brain_connectivity_breakthrough_similar_neural/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/198zhok/brain_connectivity_breakthrough_similar_neural/</guid>
      <pubDate>Wed, 17 Jan 2024 15:42:08 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/198dh3l/transformers_are_multistate_rnns/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/198dh3l/transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 20:48:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和计算机视觉解决方案预算实用指南 |第 1 部分 硬件</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1988ehe/practical_guides_to_budget_your_ai_and_computer/</link>
      <description><![CDATA[      ​&lt; /p&gt; https://preview.redd。 it/efs28iav6ucc1.jpg?width=2800&amp;format=pjpg&amp;auto=webp&amp;s=0ae07562cdd592cbb203f11df5ccbd78abf83213 关于计算机视觉定价的好文章。希望您能顺利找到它。 简短描述： 2024年，随着越来越多的公司融入人工智能，许多企业主面临着挑战。借助 OpenCV.ai 的专家见解，了解将 AI 集成到您的业务中的基本注意事项。从为计算机视觉解决方案选择合适的相机到导航不同的计算平台，文章提供了实用指导。探索网络和电源优化的细微差别，迈出人工智能驱动成功的第一步。在本系列文章中，我们将指导您了解从硬件和软件选择到人工智能法律方面的所有要点。让我们从第 1 部分开始 |硬件。   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1988ehe/practical_guides_to_budget_your_ai_and_computer/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1988ehe/practical_guides_to_budget_your_ai_and_computer/</guid>
      <pubDate>Tue, 16 Jan 2024 17:26:04 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1986kc1/transformers_are_multistate_rnns/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06104 代码：https ://github.com/schwartz-lab-NLP/TOVA 摘要：  Transformers 被认为在概念上与到上一代最先进的 NLP 模型 - 循环神经网络 (RNN)。在这项工作中，我们证明了仅解码器 Transformer 实际上可以被概念化为无限多状态 RNN——一种具有无限隐藏状态大小的 RNN 变体。我们进一步证明，通过固定隐藏状态的大小，预训练的 Transformer 可以转换为有限多状态 RNN。我们观察到一些现有的转换器缓存压缩技术可以被构建为这样的转换策略，并引入了一种新的策略，TOVA，它比这些策略更简单。我们对多个远程任务进行的实验表明，TOVA 优于所有其他基线策略，同时几乎与完整（无限）模型相当，并且在某些情况下仅使用原始缓存大小的 1/8。我们的结果表明，变压器解码器 LLM 在实践中通常表现为 RNN。他们还提出了缓解最痛苦的计算瓶颈之一——缓存大小的选项。我们在 此 https URL 公开发布我们的代码。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1986kc1/transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 16:12:45 GMT</pubDate>
    </item>
    <item>
      <title>遗传算法的前馈网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/196s6wq/feedfoward_network_with_genetic_algorithm/</link>
      <description><![CDATA[大家好！我正在尝试创建一个神经网络来在赛道上行驶，但它太难了，比我想象的要难。我使用遗传算法和具有 2 个隐藏层的神经网络，每个隐藏层有 10 个隐藏神经元，为了选择最好的，我使用波前算法。我在 Unity 中编码，这是我的 github 存储库。如果您能帮助我，我将不胜感激： https://github.com/lucasramosdev/self-driven -汽车  ​   由   提交 /u/Proscrite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/196s6wq/feedfoward_network_with_genetic_algorithm/</guid>
      <pubDate>Sun, 14 Jan 2024 22:26:07 GMT</pubDate>
    </item>
    <item>
      <title>损失被限制在我的 GCN 模型中 [P]</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/196lpjc/loss_is_getting_clamped_in_my_gcn_model_p/</link>
      <description><![CDATA[​ 我已经使用 pytorch 在具有相同边缘索引的图上训练了以下模型（任务是图分类）电子健康记录，其中每个图代表患者数据，节点向量是从组合知识图导出的） class mdl(torch.nn.Module): def init(self, input_size, hidden_​​size，output_size，dropout_rate）： super（GCNClassifier，self）.init（） self.conv1 = GCNConv（input_size，hidden_​​size） self.conv2 = GCNConv（hidden_​​size，output_size） self.dropout = torch.nn.Dropout（dropout_rate）def向前（self，x，edge_index）：x = self.conv1（x，edge_index）x = F.relu（x）x = self.dropout（x）x = self.conv2（x，edge_index）x = torch.mean (x, dim=0, keepdim=True) return x  问题是损失被限制在特定值 我尝试了各种学习率值并尝试了各种技术，如动量和学习率调度，但损失仍然保持不变 我尝试使用以下循环训练上述模型 #training (graphVec) 800 个图（每个图形状为 [5,20]) #y_train 是形状为 [800,1] 的 0 和 1 的张量，用于二元分类 num_epochs = 100（对于 epoch） range(num_epochs): model.train() for i in range(len(graphVec)): # 在每次迭代中将每个图传递给模型 output = model(graphVec[i], edge_index) loss = criteria(output, y_train[ i])loss.backward()optimizer.step()optimizer.zero_grad()#StepLR调度器步骤scheduler.step()print(output)#打印每个epoch的损失和学习率current_lr=optimizer.param_groups[0][&#39;lr &#39;] print(f&#39;Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Learning Rate: {current_lr}&#39;)  但是我我的损失严重受限（损失并没有随着时代的推移而减少）我该怎么办？   由   提交/u/Willing-Cell1790  /u/Willing-Cell1790 reddit.com/r/neuralnetworks/comments/196lpjc/loss_is_getting_clamped_in_my_gcn_model_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/196lpjc/loss_is_getting_clamped_in_my_gcn_model_p/</guid>
      <pubDate>Sun, 14 Jan 2024 17:54:53 GMT</pubDate>
    </item>
    <item>
      <title>科学家展示了大脑使用的浅层学习机制如何与深度学习竞争</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/196j4du/scientists_show_how_shallow_learning_mechanism/</link>
      <description><![CDATA[   /u/SparklySpencer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/196j4du/scientists_show_how_shallow_learning_mechanism/</guid>
      <pubDate>Sun, 14 Jan 2024 16:03:09 GMT</pubDate>
    </item>
    <item>
      <title>KL 散度数学解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/196d7qh/kl_divergence_mathematics_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了KL散度背后的数学直觉。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/196d7qh/kl_divergence_mathematics_explained/</guid>
      <pubDate>Sun, 14 Jan 2024 10:44:32 GMT</pubDate>
    </item>
    <item>
      <title>🎨 使用 Tensorflow 和 Python 的神经风格迁移教程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/195195z/neural_style_transfer_tutorial_with_tensorflow/</link>
      <description><![CDATA[      https://preview.redd.it/k8xazw7ps1cc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=8e3d290829f6 01169dfc1014ad18824bb3844115 🚀 在本视频教程中，我们将使用艺术 Python 库生成图像 探索神经风格迁移的迷人领域，并学习如何将图像与您选择的风格合并  p&gt; 以下是您将学到的内容： 🔍 从 TensorFlow 模型中心下载模型：探索使用 TensorFlow 模型中心预训练模型的便利性。  我们将引导您完成为您的艺术事业找到完美模型的步骤。  🖼️ 预处理图像以进行神经风格迁移：优化图像以实现风格迁移成功！  学习基本的预处理步骤，从调整大小到标准化，确保您的结果非常出色。  🎭 应用和可视化风格迁移：深入研究“风格迁移质量” GitHub 存储库。跟随我们应用神经网络来区分风格和生成的图像特征。  观看您的图像以比以往更高的质量进行转换。 您可以在此处找到代码：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/style-transfer 视频链接：https://youtu.be/QgEg61WyTe0 欣赏 Eran ​ #python #styletransferquality #tensorflow #NeuralStyleTransfer #PythonAI #ArtTech   &amp;# 32；由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/195195z/neural_style_transfer_tutorial_with_tensorflow/</guid>
      <pubDate>Fri, 12 Jan 2024 17:56:28 GMT</pubDate>
    </item>
    <item>
      <title>推理捷径</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/194fhgs/reasoning_shortcuts/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/194fhgs/reasoning_shortcuts/</guid>
      <pubDate>Thu, 11 Jan 2024 23:09:10 GMT</pubDate>
    </item>
    <item>
      <title>在尖峰神经网络中学习长序列</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1945g0p/learning_long_sequences_in_spiking_neural_networks/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00955 摘要：  尖峰神经网络（SNN）从大脑中汲取灵感，使节能计算。自从 Transformer 出现以来，SNN 一直在努力与现代序列任务上的人工网络竞争，因为它们继承了循环神经网络 (RNN) 的局限性，并且增加了使用不可微二元尖峰激活进行训练的挑战。然而，最近人们对 Transformer 的高效替代方案重新产生了兴趣，催生了名为状态空间模型 (SSM) 的最先进的循环架构。这项工作首次系统地研究了最先进的 SSM 与用于远程序列建模的 SNN 的交叉点。结果表明，基于 SSM 的 SNN 在成熟的远程序列建模基准的所有任务上都可以优于 Transformer。研究还表明，基于 SSM 的 SNN 在顺序图像分类上可以使用更少的参数优于当前最先进的 SNN。最后，引入了一种新颖的特征混合层，提高了 SNN 的准确性，同时挑战了有关二元激活在 SNN 中的作用的假设。这项工作为将强大的基于 SSM 的架构（例如大型语言模型）部署到神经形态硬件以实现节能的远程序列建模铺平了道路。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1945g0p/learning_long_sequences_in_spiking_neural_networks/</guid>
      <pubDate>Thu, 11 Jan 2024 16:17:26 GMT</pubDate>
    </item>
    <item>
      <title>MoE-Mamba：专家混合的高效选择性状态空间模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.04081 代码：https ://github.com/llm-random/llm-random 摘要：  状态空间模型（SSM）已成为顺序建模领域的有力竞争者，挑战 Transformers 的主导地位。与此同时，Mixture of Experts (MoE) 显着改进了基于 Transformer 的法学硕士，包括最近最先进的开源模型。我们建议，为了释放 SSM 的扩展潜力，它们应该与 MoE 结合起来。我们在 Mamba 上展示了这一点，这是一个最近基于 SSM 的模型，它实现了类似 Transformer 的卓越性能。我们的模型 MoE-Mamba 的性能优于 Mamba 和 Transformer-MoE。特别是，MoE-Mamba 以减少 2.2 倍的训练步骤达到与 Mamba 相同的性能，同时保留了 Mamba 针对 Transformer 的推理性能增益。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/192z0iv/moemamba_efficient_selective_state_space_models/</guid>
      <pubDate>Wed, 10 Jan 2024 04:00:49 GMT</pubDate>
    </item>
    </channel>
</rss>