<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Mon, 25 Nov 2024 09:19:41 GMT</lastBuildDate>
    <item>
      <title>对由医生监督的法学硕士 (LLM) 进行医学聊天支持的大规模评估表明患者满意度有所提高</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gy8wcv/largescale_evaluation_of_a_physiciansupervised/</link>
      <description><![CDATA[本文介绍了医学 LLM 助手的实际部署，该助手可帮助大规模分类和处理患者问询。该系统使用多阶段架构，结合了医学知识注入、对话能力和安全护栏。 关键技术组件：- 与 LLM 集成的自定义医学知识库- 用于查询理解和响应生成的多阶段管道- 用于检测超出范围的请求的安全分类系统- 用于验证的合成患者测试框架- 人在环监控系统 部署结果：- 在法国为 200,000 多名用户提供服务- 92% 的用户满意率- 医生工作量显着减少- 保留测试用例的安全得分为 99.9%- 平均响应时间在 30 秒以下 我认为这表明经过严格约束的 LLM 可以安全地部署用于基本的医疗分类和信息提供。具有明确安全检查的多阶段架构似乎是高风险领域的一种有前途的方法。然而，该系统仅限于文本交互，并且依赖于患者的准确症状报告，这表明我们距离完全自动化的医疗护理还很远。 综合测试框架特别有趣 - 它对于在现实世界测试存在风险的其他受监管领域开发类似系统可能很有价值。 TLDR：使用具有安全保障的多阶段架构的生产医学 LLM 助理在实际部署中显示出有希望的结果，处理 200k+ 用户，满意度达到 92%，同时减少了医生的工作量。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gy8wcv/largescale_evaluation_of_a_physiciansupervised/</guid>
      <pubDate>Sat, 23 Nov 2024 20:23:27 GMT</pubDate>
    </item>
    <item>
      <title>有人知道如何在 Stable DIffusion 中制作逼真的边缘光吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gxd96y/does_anyone_know_how_to_make_a_realistic_rim/</link>
      <description><![CDATA[我见过别人做过类似的事情，他们拍了一个人，没有仔细画出边缘光，ST 之后他们把一切都做得很逼真，但我做得不太好，告诉我我可以使用什么模型以及它的设置？    提交人    /u/Desperate_Shock9436   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gxd96y/does_anyone_know_how_to_make_a_realistic_rim/</guid>
      <pubDate>Fri, 22 Nov 2024 17:29:23 GMT</pubDate>
    </item>
    <item>
      <title>Design2Code：评估 Web 开发中屏幕截图到代码生成的多模式 LLM</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gx897w/design2code_evaluating_multimodal_llms_for/</link>
      <description><![CDATA[本文介绍了一种名为 Design2Code 的系统基准，用于评估多模式 LLM 将网页截图转换为功能性 HTML/CSS 代码的效果。该方法涉及使用自动和人工评估在 484 个真实网页示例中测试 GPT-4V、Claude 3 和 Gemini 等模型。 关键技术要点：* 创建了一个多样化的网页截图数据集，并与真实代码配对* 开发了评估视觉元素回忆和布局准确性的自动指标* 测试了不同的提示策略，包括零样本和少样本方法* 使用自动指标和人工评估比较模型性能* 发现当前模型在视觉元素回忆方面实现了约 70% 的准确率，但在精确布局方面存在困难 主要结果：* GPT-4V 总体表现最佳，其次是 Claude 3 和 Gemini* 模型经常错过较小的视觉元素，并且难以准确定位* 随着网页复杂度的增加，布局准确性显着下降* 使用类似示例的少样本提示可将性能提高 5-10%* 人工评估者仅将 45% 的生成代码评为完全正常运行 我认为这个基准对于衡量多模式代码生成的进度很有价值，类似于 BLEU分数有助于跟踪机器翻译的改进。结果突出显示了当前模型需要改进的特定领域，特别是在保持视觉保真度和处理复杂布局方面。这可能有助于将研究工作集中在这些挑战上。 我认为研究结果还表明，虽然自动网页生成尚未准备好用于生产，但它已经可以作为开发人员的辅助工具，特别是对于更简单的布局和初始原型。 TLDR：新的基准测试 AI 将网页设计转换为代码的能力。当前模型可以识别大多数视觉元素，但在精确布局方面存在困难。GPT-4V 处于领先地位，但需要进行重大改进才能用于生产。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gx897w/design2code_evaluating_multimodal_llms_for/</guid>
      <pubDate>Fri, 22 Nov 2024 13:48:52 GMT</pubDate>
    </item>
    <item>
      <title>通过人工智能实现更绿色的供应链？分享您的专业知识！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gwukod/greener_supply_chains_through_ai_share_your/</link>
      <description><![CDATA[供应链的发展速度比以往任何时候都快，人工智能 (AI) 正在成为推动可持续发展的必备要素。从似乎比我们更早知道我们需要什么的库存系统，到简化运营的人力资源工具，人工智能正在改变游戏规则。 我正在深入探讨这个问题：人工智能的采用对供应链的环境绩效有何影响？要回答这个问题，我需要您的专业知识（也许还需要花费您一点时间）。 如果您有 10 分钟的空闲时间，我希望您通过此调查分享您的见解：https://nyenrode.eu.qualtrics.com/jfe/form/SV_dmPtjoM1s9mwZ38    提交人    /u/skillkil   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gwukod/greener_supply_chains_through_ai_share_your/</guid>
      <pubDate>Fri, 22 Nov 2024 00:12:58 GMT</pubDate>
    </item>
    <item>
      <title>构建预测特定股票的 NN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gwozxp/building_a_nn_that_predicts_a_specific_stock/</link>
      <description><![CDATA[我目前正在攻读计算机科学学位的最后一年，正在为我的最终项目构建 CNN。  我对投资等很感兴趣，所以我认为这可能是一个有趣的副业。 你们认为它的可行性如何？  显然它不会很好地预测它，但是嘿，副业不应该是百万美元的发明。    提交人    /u/Ethanlynam   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gwozxp/building_a_nn_that_predicts_a_specific_stock/</guid>
      <pubDate>Thu, 21 Nov 2024 20:11:25 GMT</pubDate>
    </item>
    <item>
      <title>Prompt-in-Decoder：可分解任务上 Transformer 模型的高效并行解码</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gwfnm7/promptindecoder_efficient_parallel_decoding_for/</link>
      <description><![CDATA[本文的关键技术进步是一种称为“一次编码，并行解码”（EODP）的方法，它使变压器能够在解码过程中同时处理多个输出序列。这种方法可以缓存编码器输出并在不同的提示中重复使用它们，从而减少计算开销。 主要技术要点： - 编码器计算与解码器操作分离，允许单次编码 - 通过缓存的编码器状态可以并行解码多个提示 - 通过高效的缓存策略优化内存使用率 - 方法在提高计算效率的同时保持输出质量 - 在机器翻译和文本摘要任务上进行测试 - 与传统顺序解码相比，速度提高了 2-3 倍 结果： - 机器翻译：速度提高 2.4 倍，对 BLEU 分数的影响最小（&lt;0.1） - 文本摘要：速度提高 2.1 倍，同时保持 ROUGE 分数 - 内存开销与并行序列数量线性相关 - 适用于标准编码器-解码器转换器架构 我认为这对于更有效地部署大型语言模型非常重要，尤其是在延迟和计算成本很重要的生产环境中。批量解码多个提示的能力可以使基于 Transformer 的系统在实际应用中更加实用。 我认为主要的限制在于它目前仅在标准编码器-解码器架构上进行演示 - 看看这是否/如何扩展到具有交叉注意或动态计算的更复杂的 Transformer 变体将会很有趣。 TLDR：新方法通过缓存编码器状态实现 Transformer 模型中多个提示的并行解码，在不牺牲输出质量的情况下实现 2-3 倍的加速。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gwfnm7/promptindecoder_efficient_parallel_decoding_for/</guid>
      <pubDate>Thu, 21 Nov 2024 12:57:55 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的体育模拟引擎，用于生成逼真的多人游戏和战略分析</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gvyifx/transformerbased_sports_simulation_engine_for/</link>
      <description><![CDATA[我一直在审查这篇关于使用多智能体方法生成持续体育游戏序列的新论文。关键技术贡献是一个结合位置编码、动作生成和新颖的一致性鉴别器的框架，以产生长时间、逼真的多人运动序列。 主要技术组成部分： - 多尺度转换器架构，可处理本地玩家交互和全局游戏状态 - 分层动作生成，将复杂的游戏玩法分解为协调的单个动作 - 物理感知约束系统，确保生成的动作遵循逼真的游戏规则 - 新颖的一致性损失，惩罚生成的序列之间的不连续性 - 课程训练方法，从短序列开始，逐渐增加持续时间 评估结果： - 生成的序列保持一致性长达 30 秒（明显长于基线） - 人类评估者将生成的序列评为逼真的概率为 72% - 系统成功捕获团队级策略和阵型 - 计算要求规模与序列长度呈线性关系 这对体育模拟、训练和分析具有重要意义。这可以实现更好的 AI 驱动的体育游戏开发和自动精彩片段生成。该框架可能会扩展到其他需要持续协调行为的多智能体场景。 TLDR：新的多智能体框架通过结合变压器、分层动作生成和连贯性约束来生成扩展的体育游戏序列。在序列长度和真实感方面显示出很强的效果。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gvyifx/transformerbased_sports_simulation_engine_for/</guid>
      <pubDate>Wed, 20 Nov 2024 19:53:53 GMT</pubDate>
    </item>
    <item>
      <title>学习技巧和技术的书籍推荐</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gvrqov/book_recommendations_for_learning_tricks_and/</link>
      <description><![CDATA[寻找与神经网络：行业秘诀类似的书籍，但更新和/或不同。    由    /u/Richienb  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gvrqov/book_recommendations_for_learning_tricks_and/</guid>
      <pubDate>Wed, 20 Nov 2024 15:14:36 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可实现 1,000 多人的高保真行为模拟</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1guyuki/large_language_models_enable_highfidelity/</link>
      <description><![CDATA[我发现这篇论文很有趣，因为它使用 LLM 创建行为模拟的技术方法。研究人员开发了一个系统，该系统根据来自真实人物的访谈数据生成数字代理，在复制人类行为模式方面实现了高保真度。 关键技术方面： - 架构将基于 LLM 的代理与结构化面试处理相结合 - 代理接受个人叙述训练以模拟决策 - 针对一般社会调查答复进行验证 - 在不同人口统计群体中对 1,052 名个人进行测试 主要结果： - 与人类一致性相比，复制调查答复的准确率为 85% - 在不同种族和意识形态群体中保持表现 - 成功再现社会心理学研究的实验结果 - 与传统模拟方法相比，减少了人口偏见 对社会科学研究的影响是巨大的。该方法可以通过以下方式实现更准确的政策测试和社会动态研究： - 为模拟研究创建代表性人群 - 在不同群体中测试干预措施 - 模拟复杂的社会互动 - 减少研究中的人口统计偏见 需要考虑的技术限制： - 当前的验证仅限于调查回复和受控实验 - 长期行为一致性需要进一步研究 - 处理不断变化的社会背景仍不确定 - 创建数字表示时的隐私考虑 TLDR：新方法创建了使用 LLM 和访谈数据准确模拟人类行为的数字代理，在复制调查回复时达到 85% 的准确率。在减少人口统计偏见的同时，显示出社会科学研究的前景。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1guyuki/large_language_models_enable_highfidelity/</guid>
      <pubDate>Tue, 19 Nov 2024 14:49:09 GMT</pubDate>
    </item>
    <item>
      <title>C 语言中的神经网络框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gur7ih/neural_net_framework_in_c/</link>
      <description><![CDATA[大家好！这是我的第一篇帖子，但我想听听大家对我最近一直在研究的神经网络框架的反馈。它完全用 C 实现，任何反馈都会受到欢迎。这只是我一直在研究的一个附带项目，到目前为止，这个过程很有收获。  相关文件包括 main.c、network.c、forward.c、backward.c 和 utils.c https://github.com/Asu-Ghi/Personal_Projects/tree/main/C_Projects/Neural  感谢您的时间！     提交人    /u/AsuGhi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gur7ih/neural_net_framework_in_c/</guid>
      <pubDate>Tue, 19 Nov 2024 06:45:27 GMT</pubDate>
    </item>
    <item>
      <title>Memoripy：通过短期和长期存储为人工智能带来记忆</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gul9nt/memoripy_bringing_memory_to_ai_with_shortterm/</link>
      <description><![CDATA[嘿 r/neuralnetworks！ 我一直在研究 Memoripy，这是一个为 AI 应用程序带来真实记忆功能的 Python 库。无论您是在构建对话式 AI、虚拟助手还是需要一致、上下文感知响应的项目​​，Memoripy 都能提供结构化的短期和长期记忆存储，以使交互随着时间的推移保持意义。 Memoripy 将交互组织到短期和长期记忆中，优先考虑近期事件，同时保留重要细节以备将来使用。这可确保 AI 保持相关上下文，而不会被不必要的数据淹没。 通过语义聚类，类似的记忆被分组在一起，使 AI 能够快速高效地检索相关上下文。为了模拟我们忘记和强化信息的方式，Memoripy 具有记忆衰退和强化功能，其中不太有用的记忆会逐渐消失，而经常访问的记忆会保持清晰。 Memoripy 的关键方面之一是它专注于本地存储。它旨在与本地托管的 LLM 无缝协作，非常适合注重隐私并希望避免外部 API 调用的开发人员。Memoripy 还与 OpenAI 和 Ollama 集成。 如果这听起来像您可以使用的东西，请在GitHub上查看！它是开源的，我很想听听您如何使用它或您可能有的任何反馈。    提交人    /u/xazarall   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gul9nt/memoripy_bringing_memory_to_ai_with_shortterm/</guid>
      <pubDate>Tue, 19 Nov 2024 01:16:43 GMT</pubDate>
    </item>
    <item>
      <title>TSMamba：基于 Mamba 的 SOTA 时间序列模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gu149g/tsmamba_sota_time_series_model_based_on_mamba/</link>
      <description><![CDATA[TSMamba 是一个基于 Mamba（Transformer 的替代品）的时间序列预测模型，可生成最先进的时间序列结果。该模型使用双向编码器，甚至支持零样本预测。在此处查看更多详细信息：https://youtu.be/WvMDKCfJ4nM    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gu149g/tsmamba_sota_time_series_model_based_on_mamba/</guid>
      <pubDate>Mon, 18 Nov 2024 09:38:17 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络来学习蛇以赢得胜利</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gtyouj/using_neural_network_to_learn_snake_to_win/</link>
      <description><![CDATA[      neuralnetwork #machinelearning    提交人    /u/koyiljon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gtyouj/using_neural_network_to_learn_snake_to_win/</guid>
      <pubDate>Mon, 18 Nov 2024 06:33:42 GMT</pubDate>
    </item>
    <item>
      <title>我不知所措，需要帮助。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gtfnzl/im_overwhelmed_and_i_need_help/</link>
      <description><![CDATA[所以，我参加了 8 月份开始的博士课程，我的主要研究围绕深度学习、神经网络和激活函数展开。我的导师给了我一些材料，可以帮助我学习神经网络和激活函数。然而，入门材料非常多，我需要更多时间来学习基本概念。但我的导师让我在一周内阅读 200 篇关于激活函数的论文，这对我来说太过沉重，甚至在我完成基础知识之前。我刚刚学习了梯度下降，需要花大量时间才能理解基本材料。我现在很难理解我正在阅读的研究论文，因为我没有时间完全了解基础知识。但我的导师希望我每周报告我读过的论文。到目前为止，我已经阅读了 4 篇论文，但我看不懂其中任何一篇。它们对我来说就像古典希腊文一样。我告诉我的导师，我很难理解这些论文，因为我的基础知识没有被涵盖，但我的导师似乎并不介意。 现在，我陷入了困境。一方面，我必须就难以理解的论文撰写报告，这真的让我筋疲力尽，另一方面，我还需要更多时间来涵盖神经网络的基础知识。在这种情况下，我真的不知道我该怎么做。    提交人    /u/Intelligent-Role379   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gtfnzl/im_overwhelmed_and_i_need_help/</guid>
      <pubDate>Sun, 17 Nov 2024 15:15:04 GMT</pubDate>
    </item>
    <item>
      <title>我喜欢以可视化的方式处理模型架构。你呢？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gtddy0/i_like_working_with_model_architecture_visually/</link>
      <description><![CDATA[我不知道你是怎么想的，但我觉得 CNN（以及一般模型）的视觉表示被严重低估了。根据我的经验，当你能在脑海中“走遍”模型时，做项目会容易得多。 也许只有我这样。我肯定会把自己描述成一个视觉学习者。但我很好奇，你有过类似的经历吗？你在做项目时会将模型的结构形象化吗？ 在过去的一个月里，我一直在努力将一个（相对简单的）模型可视化。（项目链接：https://youtu.be/zLEt5oz5Mr8 ）。 你对此有何看法？    提交人    /u/vtimevlessv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gtddy0/i_like_working_with_model_architecture_visually/</guid>
      <pubDate>Sun, 17 Nov 2024 13:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>