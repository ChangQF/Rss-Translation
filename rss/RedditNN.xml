<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络，深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的subreddit。</description>
    <lastBuildDate>Tue, 18 Feb 2025 21:16:08 GMT</lastBuildDate>
    <item>
      <title>从多类变为多标签训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个神经网络，其中有1个输入层2隐藏层和1个输出层。现在，我将其用作多类分类器，这意味着输出是0到15之间的值（总计16个可能的和相互排斥的类）。但是，作为下一步，我想培训一个具有7个类的多标签分类器，并且每个班级都有多达6个子类，因此我希望每个类都有标签。  与多类培训相比，这有何不同？我想主要区别在于输入（例如标签）和输出层？到目前为止，我一直在输出层中使用SoftMax作为激活函数。  感谢任何见解！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rda92     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbwra/going_from_multiclass_to_multilabel_training/</guid>
      <pubDate>Tue, 18 Feb 2025 12:48:25 GMT</pubDate>
    </item>
    <item>
      <title>具有高精度肌肉和脂肪指标的人体组成分析的自动多组织CT分割模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种自动深度学习系统，用于分割和量化CT扫描的肌肉和脂肪组织。关键的技术创新是将修改后的U -NET体系结构与自定义损失功能中编码的解剖约束相结合。 关键技术点： - 修改了U -NET体系结构，对500个手动标记的CT扫描进行了培训 - 通过纳入扫描 - 解剖学验证 - 通过结合了解剖学。损失不可能的组织布置的损失函数 - 生成不同组织类型的3D体积测量 - 每次扫描的处理时间为2-3分钟，而手动分析 结果：-96％的肌肉组织段精度 -  955皮下脂肪的准确性％ - 内脏脂肪的精度为94％ - 对3位专家放射科医生的测量进行了验证 - 不同体型的一致性 我认为这可以通过减少身体组成所需的时间来重大影响临床工作流程分析从小时到几分钟。高精度和解剖学意识的方法表明，它可能足够可靠用于临床使用。尽管需要更多的验证，尤其是对于边缘病例和极端身体组成，该系统显示出有望改善肿瘤学，营养和运动医学的治疗计划。 我认为解剖学约束的整合特别聪明 - 它有助于防止纯粹的深度学习方法可能产生的身体上不可能的细分。这种领域知识的整合对于其他医学成像任务可能很有价值。  tldr：自动化的CT扫描分析系统将深度学习与解剖学规则结合在一起，以2--的2--; 94％的精度来测量肌肉和脂肪组织。 3分钟。显示出临床使用的希望，但需要更广泛的验证。摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1isbu5z/automated_multitissue_ct_segmentation_model_for/</guid>
      <pubDate>Tue, 18 Feb 2025 12:44:32 GMT</pubDate>
    </item>
    <item>
      <title>物理知情的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irnodl/physics_informed_neural_networks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/nickb     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irnodl/physics_informed_neural_networks/</guid>
      <pubDate>Mon, 17 Feb 2025 16:22:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用U-NET和TensorFlow分割X射线肺</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irlh6f/how_to_segment_xray_lungs_using_unet_and/</link>
      <description><![CDATA[    &lt;！ -  sc_off-&gt;   本教程提供了有关如何使用TensorFlow/keras实现和训练X射线肺部分段的U-NET模型的分步指南。 🔍     构建UNET模型：学习如何使用TensorFlow和Keras构建模型。   模型培训：我们将指导您完成培训过程，优化模型以生成肺部位置的口罩  测试和评估：运行预训练的模型在新的新鲜图像上，并在预测的蒙版旁边可视化测试图像。   您可以在博客中找到代码的链接： https://eranfeit.net.net/how-to-to-segment-x -ray-rungs-using-u-net and-tensorFlow/  中等用户的完整代码描述： https://medium.com/@feitgemel/how-to-segment-x-ray-lungs-using-u-net-and-ant-tensorflow-59b5a99a893f   您可以找到更多教程，然后在此处加入我的新闻通讯： https://eranfeit.net/        &lt;强&gt;在此处查看我们的教程： [ https://youtu.be/-aejmcdeoom＆amp;list=uulftifftiwjjhah6bviswkljum9sg]（％20Https：/youtu.be/-aejmcdeoom; 享受  eran      #python #opencv＃tensorflow #tepeeplearning #imagesegentration #imagesementation #unet＃resunet #machinelearningproject #machinelearningproject #segentation #segentation #sementation       div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/feitgemel     [link]        [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irlh6f/how_to_segment_xray_lungs_using_unet_and/</guid>
      <pubDate>Mon, 17 Feb 2025 14:48:24 GMT</pubDate>
    </item>
    <item>
      <title>多语言语音模型的缩放定律：培训0.25b-18b参数模型的见解150种语言</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1irfuvs/scaling_laws_for_multilingual_speech_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员在多语言语音识别和通过培训模型翻译中系统地研究缩放行为，跨不同尺寸（300m至1B参数）和数据数量（1K至10K）每种语言小时）。他们根据计算，数据和模型量表为性能开发预测方程。 关键技术方面： - 确定模型大小，培训数据和绩效之间的幂律关系 - 发现添加语言可以改善性能在降低回报之前，至〜8-10语言 - 开发的“猫头鹰得分”量化多语言转移效率的度量 - 证明较大的模型在3个模型体系结构和2种训练方法中显示出更好的跨语性转移 - 验证缩放定律 结果显示： - 错误率遵循指数-0.32的功率定律缩放率-0.32对于型号尺寸 - 跨语言转移通过log（n）改进，其中n是语言数量 - 高资源语言从缩放中受益于缩放量比低资源较低的语言 - 计算 - 最佳培训需要平衡模型尺寸和数据数量 - 建筑选择 - 体系结构选择问题很重要小于规模和数据数量 我认为这项工作将帮助组织对多语言模型的资源分配做出更好的决定。缩放定律可以指导有关模型大小，语言选择和数据收集的选择。但是，对高​​资源语言的关注意味着我们仍然需要对真正低资源场景的更多研究。  tldr：系统研究揭示了多语言语音AI的可预测缩放模式语言数量。结果为构建更好的系统提供了实用的指导。 。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1irfuvs/scaling_laws_for_multilingual_speech_models/</guid>
      <pubDate>Mon, 17 Feb 2025 09:12:48 GMT</pubDate>
    </item>
    <item>
      <title>桥接2d-3d域间隙，具有通信感知潜在的辐射场</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iqmoj8/bridging_2d3d_domain_gap_with_correspondenceaware/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一种新颖的方法，将潜在的辐射场与3D感知的2D图像表示结合在一起，有效地弥合了2D图像操纵和3D一致性之间的差距。关键创新是一个通信感知自动编码框架，该框架在跨不同观点的几何一致性的同时保持有效的编辑。 主要技术方面： - 双分支架构：一个用于2D功能提取，另一个用于3d-warreweaweave to 3d-warreweaweave。处理 - 可确保跨视图的空间一致性的新颖对应损失 - 对本地和全局编辑的有效潜在空间优化 - 与现有基于NERF的架构进行集成，同时降低计算开销 结果显示： - 最先进 - 视图合成基准的表现 - 提高了编辑功能，同时保持3D一致性 - 与完整的3D方法相比，记忆要求较低 - 更好地处理复杂照明方案 我认为这种方法可能会显着影响内容创建工作流程3D，其中3D一致性至关重要。计算需求的减少同时保持质量使其与现实世界应用特别相关。该框架能够处理本地和全球编辑的能力，同时保留3D一致性，可以使其对于虚拟生产和增强现实应用程序都有价值。 我认为，最有趣的方面是他们如何结合了将其结合起来的好处。具有3D意识的2D图像操纵，而无需显式3D建模。这可能会为熟悉2D工作流但需要3D一致性的内容创建者提供更直观的工具。  tldr：新方法将潜在的辐射字段与3D-Aware 2D表示形式相结合，以启用高质量的视图合成和合成。在保持3D一致性的同时进行编辑。   。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iqmoj8/bridging_2d3d_domain_gap_with_correspondenceaware/</guid>
      <pubDate>Sun, 16 Feb 2025 07:05:21 GMT</pubDate>
    </item>
    <item>
      <title>自学CNN，RNN，LSTM用于学位级别应用</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ipye5a/selflearning_cnn_rnn_lstm_for_degree_level/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是最后一年的生物医学工程专业的学生，​​他们对在医疗保健领域的应用有浓厚的兴趣，例如，促进疾病的早期发现使用CNN左右。我的大部分软技能来自MATLAB或C ++，我已经接触了可能与NN有关的信号处理或医学成像等课程。 我的目标很简单，我想应用于NN喜欢CNN通过图像分割进行疾病检测，甚至使用RNN进行生理信号相关分析。我的主要问题是，我应该从哪里开始？社区的任何渠道，书籍甚至文章建议吗？那些在我的问题上有经验的人有什么快速提示吗？甚至更具体地与生物医学领域有关。非常感谢任何相关建议。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/grimgrix     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ipye5a/selflearning_cnn_rnn_lstm_for_degree_level/</guid>
      <pubDate>Sat, 15 Feb 2025 10:10:14 GMT</pubDate>
    </item>
    <item>
      <title>自我引用：通过自我监督的上下文消融改善LLM引文产生</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ipwbr9/selfcite_improving_llm_citation_generation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   selfcite引入了一种自我监督的方法，用于教授LLM，以将信息正确归因于文本生成期间的源文档。关键的创新是使用对比度学习来帮助模型确定应引用输入上下文的哪些部分，而无需手动引用标签。 主要技术点： - 片段输入文档输入到连贯的块中进行引用匹配 - 使用注意 - 基于链接生成的文本与源的链接的上下文归因 - 在真实和随机文档对之间实现对比度学习 - 训练模型以自动区分引用的内容 - 提高了引文准确性，同时保持发电质量 关键结果： - 引用精度提高了多个模型尺寸（在7B -70B参数模型上测试） - 与基线​​模型相比降低了幻觉速率 - 在学术和通用域文本中保持或改善了发电质量的Rouge分数 - 随着模型大小的增加而有效地扩展。 /p&gt; 我认为这种方法可以通过提供内置源归因来显着提高AI生成内容的可靠性。自我监督的性质意味着它可以在没有昂贵的手动标签的情况下广泛应用。对于研究和技术写作应用程序，这可以帮助自动化文献综述，同时保持严格的引用标准。 我看到了学术写作援助和新闻业的特殊价值，而准确的源归因至关重要。该方法还可以通过使索赔更容易追溯到原始来源来帮助进行事实检查。  tldr：自我监督的方法教LLM在没有手动标签的情况下在文本生成期间准确引用来源，从而提高归属准确性在保持发电质量的同时。 完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ipwbr9/selfcite_improving_llm_citation_generation/</guid>
      <pubDate>Sat, 15 Feb 2025 07:30:51 GMT</pubDate>
    </item>
    <item>
      <title>新的学作为人类概念交流的桥梁</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ip7iik/neologisms_as_a_bridge_for_humanai_conceptual/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文研究了我们当前的词汇和概念框架如何限制我们正确理解和讨论AI系统的能力。核心论点是，我们需要专门为描述AI行为和能力而开发的新术语，而不是从人类认知中借用拟人化术语。 关键技术点： - 对ML研究中常用的术语分析（学习，学习，学习，理解，智力）及其如何创建错误的类比 - 研究神经网络如何通过人类认知没有直接相似的数学转换来处理信息 - 展示当前语言如何导致对AI功能的系统性误解 - 开发新的AI特定特异性的框架技术词汇 主要发现： - 人类认知术语不能准确地映射到ML模型操作 - 当前的术语会产生对AI功能的错误期望 - 缺乏精确的词汇障碍者的技术讨论者的技术讨论 - 神经网络信息处理基本上是不同的不同从人类认知 我认为这项工作突出了AI研究和交流中的一个关键问题。没有准确的术语，我们冒着高估和低估AI功能的风险。 AI特异性词汇的发展可以帮助弥合技术现实和公众理解之间的差距，尽管广泛采用新术语将是具有挑战性的。 我认为本文本可以为提出的新的新典范提供更多具体的例子术语和特定用例。开发新词汇的框架是牢固的，但是实际实施指导是有限的。  tldr：我们需要专门设计用于描述AI系统的新词汇，而不是使用人类的认知术语，因为当前的语言会造成误解并吸引技术技术。理解。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ip7iik/neologisms_as_a_bridge_for_humanai_conceptual/</guid>
      <pubDate>Fri, 14 Feb 2025 10:15:30 GMT</pubDate>
    </item>
    <item>
      <title>一定步骤后模型损失爆炸</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ip60lf/model_loss_explodes_after_a_certain_steps/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ip60lf/model_loss_explodes_after_a_certain_steps/</guid>
      <pubDate>Fri, 14 Feb 2025 08:22:18 GMT</pubDate>
    </item>
    <item>
      <title>Matryoshka量化：一种用于具有嵌套精度级别的单个模型的多尺度训练方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iofoh9/matryoshka_quantization_a_multiscale_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员提出了一种嵌套的量化方法，其中单个模型可以通过权重的层次表示在多个位宽度上运行。关键的想法是构建量化，以使较高的精度表示包含较低精度版本所需的所有信息 - 类似于嵌套的Matryoshka娃娃的工作方式。 关键技术点： - 权重分解为嵌套的组件，这些组件可以合并以达到不同的精度水平 - 使用专门的损失函数同时优化多个位宽度的训练 - 与训练后量化和量化感知训练兼容 - 在高达7b参数的视觉和语言模型上证明 - 在大多数情况下，单位基准基线的准确性在0.5％以内 结果显示：-8位→4位嵌套模型的性能类似于单独量化的版本类似 - 与单精制模型相比，存储开销仅为12.5％ - 在没有重新加载的精确度之间的动态切换 - 与现有的量化方法一起使用，例如GPTQ和AWQ  我认为这对于边缘部署方案可能特别影响，在这些方案中，相同模型需要在具有不同计算功能的设备上运行。在不存储多个版本的情况下动态调整精度的能力可以使大型模型在资源约束环境中更实用。 我认为下一个有趣的方向是： - 在较大型号（30b+）上测试 - 硬件特定于硬件优化 - 与其他压缩技术集成（例如修剪） - 探索甚至较低的位宽度表示  tldr：新颖的量化方法，该方法可以使单个模型通过多个精度运行嵌套重量表示。在启用灵活的部署时保持准确性。  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iofoh9/matryoshka_quantization_a_multiscale_training/</guid>
      <pubDate>Thu, 13 Feb 2025 09:52:56 GMT</pubDate>
    </item>
    <item>
      <title>除了变压器之外，是否有模型体系结构可以使用小数据集，一些GPU和“几个”参数生成良好的文本？这足以生成连贯的英语文本作为简短的答案。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1inx3ys/is_there_a_model_architecture_beyond_transformer/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/challenger_official     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1inx3ys/is_there_a_model_architecture_beyond_transformer/</guid>
      <pubDate>Wed, 12 Feb 2025 17:57:25 GMT</pubDate>
    </item>
    <item>
      <title>在我的NN学习旅程中应该是什么。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1inr3bn/what_should_be_next_in_my_nn_learning_journey/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我开始学习神经网络纯粹是出于对他们背后的数学而出现的兴趣。从那以后，我写了四个中等文章，总结了我学到的知识：   从头开始构建神经网络：初学者的你好世界         从头开始卷积神经网络   当我开始时，我对神经网络的了解为零。现在，我的下一个目标是在Pytorch中实施CNN，然后深入研究经常性的神经网络。 但是，我已经收到了一些杂乱无章，人们认为了解NNS在数学上和内部工作（即使我的不是我的）该深度）根本不是有价值的，因为大多数ML/AI Engnieers都使用预制模型，而无需了解在引擎盖下构建它们的内容。这些反馈中有一些让我停下来，使我质疑我是否应该继续使用RNN。 您认为，是否有实际价值可以理解详细信息神经网络在场景后面的工作方式？还是对ML/AI中的人几乎没有任何后果？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/flaky_profession_619      [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1inr3bn/what_should_be_next_in_my_nn_learning_journey/</guid>
      <pubDate>Wed, 12 Feb 2025 13:43:57 GMT</pubDate>
    </item>
    <item>
      <title>有效多语言LLM安全检测的两人增强器学习框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1innz0u/twoplayer_reinforcement_learning_framework_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了一种两者增强的学习方法，用于在多语言LLMS中实现护栏。核心创新是使用Markov游戏框架，其中两个RL代理共同使用 - 一个专注于安全措施，另一个侧重于保持对话质量。 关键技术点： - 仅使用2个参数效率微调微调基本模型参数的百分比 - 平衡内容安全性和响应实用程序的自定义奖励功能 - 两个RL播放器之间的交替优化 - 用于多语言理解和文化适应的专业模块 - 实时适度能力，最小的延迟范围 结果显示： - 有害/不适当内容的降低27％ - 有用响应的保存92％，而不是修改的基准 - 跨8种语言有效 - 与以前的方法相比，计算成本降低 - 成功处理明确和细微的安全违规  我认为这种方法可能对在安全和性能重要的生产环境中部署LLM尤其有影响。参数效率意味着可以将其集成到没有大量计算开销的情况下。随着人工智能部署变得更加全局，多语言功能尤其重要。 但是，我认为需要考虑一些局限性。各种语言的各种表现都表明，文化适应需要更多的工作。含糊不清的情况下的保守方法也可能需要调整不同的用例。  tldr：LLM护栏的两播放器RL RL框架可实现27％的有害内容降低，同时维持92％的帮助响应，使用参数 - 跨多种语言的有效微调。  。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1innz0u/twoplayer_reinforcement_learning_framework_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:27:08 GMT</pubDate>
    </item>
    <item>
      <title>评估LLM作为会议代表：跨不同模型和参与策略的绩效分析</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1imwq43/evaluating_llms_as_meeting_delegates_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了一个系统的评估框架，用于测试LLMS作为会议代表，并具有新颖的两阶段体系结构，用于满足理解和摘要。关键的技术贡献是100个带注释的会议记录的基准数据集，并配对，其重点是信息提取和上下文理解的评估方法。 主要技术要点： - 两阶段架构：上下文理解模块，然后是响应模块。 - 跨4个关键指标的评估：信息提取，摘要连贯性，动作项跟踪和上下文保留 - 单转交换和多转交互之间的比较 - 多个LLM的测试包括GPT -4，Claude和其他人在内的结构 关键结果：-GPT -4在关键点识别上达到了82％的精度 - 多转交流显示出15％的摘要质量 - 性能显着降级（30） -40％）在技术讨论中 - 模型显示不同的会议类型和文化背景的表现不一致 我认为这项工作为自动会议开辟了实际应用文档，特别是用于常规业务会议。多转弯的改进表明，交互式完善可能是这些系统的重要途径。 我认为，技术讨论和跨文化交流的局限性突出了全球组织部署的重要挑战。结果表明，在广泛采用之前，我们需要在领域的适应和文化背景理解方面进行更多工作。  tldr：LLMS作为会议代表的新基准和评估框架的新基准和评估框架，显示出基本的会议理解的有希望的结果，但仍然存在重大挑战，但仍在技术和跨文化环境。  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1imwq43/evaluating_llms_as_meeting_delegates_a/</guid>
      <pubDate>Tue, 11 Feb 2025 11:45:22 GMT</pubDate>
    </item>
    </channel>
</rss>