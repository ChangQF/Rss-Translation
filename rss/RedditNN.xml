<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 05 Apr 2024 12:23:07 GMT</lastBuildDate>
    <item>
      <title>滑动窗口注意力解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvtqnv/sliding_window_attention_explained/</link>
      <description><![CDATA[   /u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvtqnv/sliding_window_attention_explained/</guid>
      <pubDate>Thu, 04 Apr 2024 17:52:12 GMT</pubDate>
    </item>
    <item>
      <title>简化的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvnilo/neural_networks_simplified/</link>
      <description><![CDATA[大家好！我已经阅读了很多有关 ANN 工作原理的文章，但我确实有几个问题。假设我们希望程序识别猫的图片。 我们有： 输入节点 - 数千种不同情况、姿势、颜色和不同特征的猫图片。它可以识别这些图片中每个像素的颜色和亮度值，并识别猫图片中常见的图案。 （我们的大脑通过不止一次地生活和看到某些事物来下意识地做到这一点） 权重 - 每个输入都被赋予一个值，该值决定其强度，因此“权重”可以被定义为“权重”。进行以下计算时它携带的。因此，像素的位置和颜色在确定特征时具有或多或少的权重。 （这可能类似于我们将某些特征放在一起来帮助我们识别某些东西。可伸缩的爪子 - 食肉动物的牙齿，它喵喵叫 - 它有四条腿）|训练如何进行？ 隐藏层 - 通过数学计算处理数据。给定这些输入，爪子 + 猫的声音 + 牙齿 + 四足动物 =  输出 - 猫  程序是否在隐藏层中从其他经过训练的模型中挑选来识别特征？爪子、牙齿和动物声音的模型。  我可能还有更多问题，但如果没有之前问题的答案，我就无法提出这些问题：D    由   提交 /u/Suitable-Cream-3200   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvnilo/neural_networks_simplified/</guid>
      <pubDate>Thu, 04 Apr 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>神经A星</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvl306/neural_a_star/</link>
      <description><![CDATA[我正在研究神经网络，以完成关于神经星算法的论文，并阅读论文（https://arxiv.org/pdf/2009.07476）其中解释了如何选择节点，它说用于获取节点索引（作为一个热矩阵）的函数用作反向传播中的缩进函数。但这是什么意思？   由   提交/u/JuriPH  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvl306/neural_a_star/</guid>
      <pubDate>Thu, 04 Apr 2024 11:47:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络验证：采访泰勒·约翰逊、范德比尔……</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bvdst3/neural_network_verification_an_interview_with/</link>
      <description><![CDATA[   /u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bvdst3/neural_network_verification_an_interview_with/</guid>
      <pubDate>Thu, 04 Apr 2024 04:02:27 GMT</pubDate>
    </item>
    <item>
      <title>使用深度度量学习为食谱数据集创建嵌入模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/</link>
      <description><![CDATA[大家好，我想为我自己的食谱数据集创建一个嵌入模型。目标是创建一个神经网络，将每个食谱（由其成分列表、食谱标签列表及其标题表示）作为输入。  网络应该使用深度度量学习来创建一个嵌入模型，以能够很好地区分菜谱的方式表示菜谱。我考虑过使用带有三元组损失函数的三元组网络，并在三元组数据集上进行训练。每个三元组将由一个锚点（配方本身）、一个正样本（相似的配方）和一个负样本（非常不同的配方）组成。  目标是最小化锚点和正样本之间的距离，同时最大化锚点和负样本之间的距离。由于我对神经网络和自然语言处理相对较新，因此我非常感谢您对这种方法的想法和见解。  您认为这种方法适合我的任务吗？我应该注意哪些潜在的陷阱或挑战？此外，如果您能为我提供有关如何成功执行该项目的指南，我将不胜感激。谢谢。    由   提交/u/Pspecial-Pepper494   reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bv87i8/creating_an_embedding_model_for_recipe_dataset/</guid>
      <pubDate>Wed, 03 Apr 2024 23:42:59 GMT</pubDate>
    </item>
    <item>
      <title>构建 FPS ai，有个问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bu7o2r/building_an_fps_ai_have_a_question/</link>
      <description><![CDATA[我计划构建一个 fps 机器人，它不访问任何游戏内存，但使用图像识别。我知道如何减少射击和识别敌人的部分，但我正在努力想出一个在地图上移动的解决方案。 我不认为 3D 空间处理是一个现实的解决方案，因为那会多慢啊。我当前的想法是使用迷你地图和图像将其与整个地图的数字网格版本相匹配，以获取我的位置的值。  然后，我将学习如何训练我的模型，以根据我在类似位置的真实游戏玩法来预测下一个要面对的方向。我打算采用两种方法之一。其中之一是发送我的原始迷你地图的屏幕截图，其中包含我按下的键、我面向的方向等信息，并将其传递给 CNN。另一个是预处理屏幕截图，将其与网格地图进行匹配，以获得代表网格所在的数值，然后将其加上所有关键和方向信息传递给 RNN。  这样的事情合理可能吗？这是实现这一目标的一种稍微聪明的方法吗？这是我第一个如此规模的项目，也是第一次使用 NN，所以我还有很多不知道的地方。   由   提交/u/Gabe750  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bu7o2r/building_an_fps_ai_have_a_question/</guid>
      <pubDate>Tue, 02 Apr 2024 19:28:12 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络压缩图像</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bu53fn/compressing_images_with_neural_networks/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bu53fn/compressing_images_with_neural_networks/</guid>
      <pubDate>Tue, 02 Apr 2024 17:49:08 GMT</pubDate>
    </item>
    <item>
      <title>零射击还是不射击？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/</link>
      <description><![CDATA[我正在考虑使用包含 { en-hi, hi-en, en-bn, bn-en } 对的数据集微调 mT5，然后测试 hi-bn &amp; 的翻译质量bn-hi 对。这是 (hi-bn, bn-hi) 零样本翻译吗？我很困惑，因为 mT5 已经在 mC4 数据集上进行了预训练，该数据集包含 101 种语言，包括英语（en）、印地语（hi）、孟加拉语（bn）。   由   提交/u/Anxious-Buddha  /u/Anxious-Buddha reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1btf93r/zero_shot_or_not/</guid>
      <pubDate>Mon, 01 Apr 2024 20:48:38 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我理解代码吗</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</link>
      <description><![CDATA[从tensorflow.keras导入tensorflow as tf 从tensorflow.keras.preprocessing.image导入层、模型、优化器导入ImageDataGenerator  class BottleneckBlock(tf.keras.layers.Layer): def init(self, inchannels, out_channels, stride=1): super(BottleneckBlock, self)。init_() self.conv1 = tf.keras.layers.Conv2D(out_channels, kernel_size=1, strides=stride, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers .BatchNormalization() self.relu = tf.keras.layers.ReLU() self.conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=1, padding=&#39;same&#39;, use_bias=False) self .bn2 = tf.keras.layers.BatchNormalization() self.conv3 = tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=1, padding=&#39;same&#39;, use_bias=False) self.bn3 = tf.keras.layers.BatchNormalization() self.downsample = tf.keras.Sequential([ tf.keras.layers.Conv2D(out_channels * 4, kernel_size=1, strides=stride, use_bias=False), tf.keras.layers .BatchNormalization() ]) if stride != 1 else None self.stride = stride def call(self, x):identity = x out = self.conv1(x) out = self .bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3 （out）如果 self.downsample 不是 None：identity = self.downsample(x) out += Identity out = self.relu(out) return out  class CNN(models.Model ): def init(self, block,layers, numclasses=10): super(CNN, self).init_() self .in_channels = 64 self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding=&#39;same&#39;, use_bias=False) self.bn1 = tf.keras.layers.BatchNormalization() self .relu = tf.keras.layers.ReLU() self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=&#39;相同&#39;) self.layer1 = self._make_layer(块, 64, 层[0]) self.layer2 = self._make_layer(块, 128, 层[1], 步幅=2) self.layer3 = self._make_layer(块, 256, 层[2], 步幅=2 ） self.layer4 = self._make_layer（块，512，层[3]，步幅= 2） self.avgpool = tf.keras.layers.GlobalAveragePooling2D（） self.fc = tf.keras.layers.Dense（num_classes）&lt; /p&gt; def _make_layer(self, block, out_channels,blocks, stride=1): 层 = []layers.append(block(self.in_channels, out_channels, stride)) self.in_channels = out_channels * 4 # block.expansion = 4 for _ in range(1,blocks):layers.append(block(self.in_channels,out_channels)) return tf.keras.Sequential(layers) def call(self, x): x = self .conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3 (x) x = self.layer4(x) x = self.avgpool(x) x = self.fc(x) 返回x  def ResNet50(num_classes=10): 返回CNN (BottleneckBlock, [3, 4, 6, 3], num_classes) 数据集和数据生成器 train_datagen = ImageDataGenerator( rescale=1./255,heart_range=0.2, Zoom_range=0.2 , Horizo​​ntal_flip=True) train_generator = train_datagen.flow_from_directory( &#39;/kaggle/input/prostate-cancer&#39;, target_size=(224, 224), batch_size=32, class_mode=&#39;categorical&#39;) 使用示例 model = ResNet50(num_classes=len(train_generator.class_indices)) model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=&#39;categorical_crossentropy&#39;,metrics=[ &#39;准确度&#39;]) model.fit(train_generator, epochs=10) def Predict_image_class(image_path): img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224)) img_array = tf.keras.preprocessing.image.img_to_array(img) img_array = tf.expand_dims(img_array, 0) # 创建批量轴 img_array /= 255. # 标准化predicted_class = model.predict(img_array) return tf.argmax(predicted_class[ 0]).numpy() 使用示例 image_path = &#39;/kaggle/input/predict-img/0001.png&#39; Predicted_class = Predict_image_class(image_path) print(f&quot;Predicted类: {predicted_class}&quot;)   由   提交 /u/Warm-Perspective-390   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bsuyyt/can_someone_help_me_understand_the_code/</guid>
      <pubDate>Mon, 01 Apr 2024 04:51:51 GMT</pubDate>
    </item>
    <item>
      <title>深度学习项目构想</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</link>
      <description><![CDATA[你好， 我目前正在学习深度学习课程，我必须完成一个期末项目。我们主要介绍了 MLP / CNN / 基本架构和框架，以及一点点 RNN 和 LLM，但我想重点关注一个利用 CNN 的项目。老实说，我没有太多好主意，所以我一直在寻找一些有用或有趣的主题的灵感。我也一直在 Kaggle 上查找数据集。 感谢您的任何意见！谢谢！   由   提交/u/beanbeandoedoe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bstl1i/dl_project_idea/</guid>
      <pubDate>Mon, 01 Apr 2024 03:35:12 GMT</pubDate>
    </item>
    <item>
      <title>黑匣子内部：卷积神经网络可视化！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bshff9/inside_the_black_box_convolutional_neural_nets/</link>
      <description><![CDATA[   /u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bshff9/inside_the_black_box_convolutional_neural_nets/</guid>
      <pubDate>Sun, 31 Mar 2024 18:38:14 GMT</pubDate>
    </item>
    <item>
      <title>我在一个函数上训练了 LSTM，使其在输入前 50 个数据点后预测下一个数据点！每一帧都是另一个训练纪元！</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bs8obr/i_trained_an_lstm_on_a_function_such_that_it/</link>
      <description><![CDATA[   /u/frinnedfodern   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bs8obr/i_trained_an_lstm_on_a_function_such_that_it/</guid>
      <pubDate>Sun, 31 Mar 2024 11:55:14 GMT</pubDate>
    </item>
    <item>
      <title>批量归一化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bs7olg/batch_normalization/</link>
      <description><![CDATA[      &amp;# 32；由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bs7olg/batch_normalization/</guid>
      <pubDate>Sun, 31 Mar 2024 10:58:12 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 迁移学习：使用 Mobilenet 和 Python 对图像进行分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</link>
      <description><![CDATA[      https://preview.redd.it/zyusaigsrfrc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=b6b7442176ceca4d52bef 6dba7571da7af8e6b91 在本视频中，我们将向您展示如何使用 TensorFlow 和 Mobilenet 通过迁移学习来训练图像分类模型。  我们将指导您完成图像数据预处理、微调预训练 Mobilenet 模型以及使用验证数据评估其性能的过程。  视频教程的链接在这里：https://youtu.be/xsBm_DTSbB0 &lt; p&gt;我还在视频描述中分享了 Python 代码。 享受吧， Eran #TensorFlow #Mobilenet #ImageClassification #TransferLearning #Python #DeepLearning #机器学习 #ArtificialIntelligence #PretrainedModels #ImageRecognition #OpenCV #ComputerVision #Cnn   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</guid>
      <pubDate>Sat, 30 Mar 2024 08:58:14 GMT</pubDate>
    </item>
    <item>
      <title>受大脑启发的混沌尖峰反向传播</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</guid>
      <pubDate>Fri, 29 Mar 2024 17:10:30 GMT</pubDate>
    </item>
    </channel>
</rss>