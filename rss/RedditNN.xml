<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Wed, 18 Sep 2024 01:11:53 GMT</lastBuildDate>
    <item>
      <title>死亡的 relu 神经元</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fj3jj0/dead_relu_neurons/</link>
      <description><![CDATA[如果网络早期部分的输出发生变化，即使神经元前面的权重保持不变，死亡的 relu 神经元能否恢复？    提交人    /u/Outrageous-Key-4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fj3jj0/dead_relu_neurons/</guid>
      <pubDate>Tue, 17 Sep 2024 16:22:31 GMT</pubDate>
    </item>
    <item>
      <title>尝试用 Python 编写自己的神经网络</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fiuen9/trying_to_program_my_own_neural_network_in_python/</link>
      <description><![CDATA[您有任何可以帮助我开始的视频或文档吗？谢谢！    提交人    /u/MatFSouza   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fiuen9/trying_to_program_my_own_neural_network_in_python/</guid>
      <pubDate>Tue, 17 Sep 2024 09:12:54 GMT</pubDate>
    </item>
    <item>
      <title>Llama 3.1 70B 和 Llama 3.1 70B Instruct 压缩了 6.4 倍，现在重 22 GB</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fiseqq/llama_31_70b_and_llama_31_70b_instruct_compressed/</link>
      <description><![CDATA[我们使用与 IST Austria 和 KAUST 共同开发的 PV-Tuning 方法压缩了 Llama 3.1 70B 和 Llama 3.1 70B Instruct。  该模型现在小了 6.4 倍（141 GB --&gt; 22 GB）。  您将需要 3090 GPU 来运行模型，但您可以在自己的电脑上执行此操作。  您可以在此处下载压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main   由    /u/azalio  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fiseqq/llama_31_70b_and_llama_31_70b_instruct_compressed/</guid>
      <pubDate>Tue, 17 Sep 2024 06:58:31 GMT</pubDate>
    </item>
    <item>
      <title>元认知 AI：通过查找 ML 错误来恢复约束</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fhwh3g/metacognitive_ai_recovering_constraints_by/</link>
      <description><![CDATA[        由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fhwh3g/metacognitive_ai_recovering_constraints_by/</guid>
      <pubDate>Mon, 16 Sep 2024 04:46:21 GMT</pubDate>
    </item>
    <item>
      <title>C++ 中的轻量级 NeuralNet 库（使用 opencl 加速即将推出！！！）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fhfzsz/light_weight_neuralnet_library_in_c_acceleration/</link>
      <description><![CDATA[我用 C++ 编写了这个库来实现基本的神经网络功能...它目前足以满足我当前的应用需求...但希望很快使用 opencl 实现加速，以便将来实现未来的 NN 扩展：https://github.com/narenr94/nn    提交人    /u/narenr94   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fhfzsz/light_weight_neuralnet_library_in_c_acceleration/</guid>
      <pubDate>Sun, 15 Sep 2024 16:03:05 GMT</pubDate>
    </item>
    <item>
      <title>哪款笔记本电脑最适合人工智能和深度神经网络？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fgt18w/which_laptop_is_best_for_ai_and_deep_neural/</link>
      <description><![CDATA[我正在寻找可以处理 AI 和深度神经网络任务的第一台游戏笔记本电脑，我发现 ASUS TUF 系列符合我的预算。但是，我不确定哪种型号最适合我的工作，因为它们的硬件配置不同。有人能帮我比较这两个型号并建议哪一个更适合我吗？  选项 1： ASUS TUF Gaming F15 FX507VI 15.6 英寸FHD（1920 x 1080）16：9 IPS 144Hz 显示屏 英特尔酷睿 i7-13620H 处理器 16GB DDR5 4800 RAM 1TB SSD 存储 GeForce RTX 4070 笔记本电脑 GPU，8GB GDDR6 英文键盘  选项 2： 华硕 TUF Gaming F15 FX507ZI 15.6 英寸FHD（1920 x 1080）16：9 IPS 144Hz 显示屏 英特尔酷睿 i7-12700H 处理器 16GB DDR4 3200MHz RAM 1TB SSD 存储 GeForce RTX 4070 笔记本电脑 GPU，8GB GDDR6 我注意到的主要区别是： RAM 类型：DDR5 与 DDR4 CPU 代：i7-13620H 与 i7-12700H 如果您能提供任何关于这些差异如何影响 AI 和深度学习任务性能的见解，我将不胜感激。如果有人有其他笔记本电脑建议，请随时分享！    提交人    /u/Beneficial_Book8360   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fgt18w/which_laptop_is_best_for_ai_and_deep_neural/</guid>
      <pubDate>Sat, 14 Sep 2024 18:51:52 GMT</pubDate>
    </item>
    <item>
      <title>Diffumon - 一个简单的扩散模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fgnqld/diffumon_a_simple_diffusion_model/</link>
      <description><![CDATA[        提交人    /u/RogueStargun   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fgnqld/diffumon_a_simple_diffusion_model/</guid>
      <pubDate>Sat, 14 Sep 2024 14:47:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Res-Unet 分割皮肤黑色素瘤</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ffviuu/how_to_segment_skin_melanoma_using_resunet/</link>
      <description><![CDATA[      https://preview.redd.it/ovbaog5e2lod1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=04e8471f298ac46058edcf0787f3055588385c77 本教程提供了有关如何使用 TensorFlow 和 Keras 实现和训练 Res-UNet 模型以进行皮肤黑色素瘤检测和分割的分步指南。 什么您将学到：  构建 Res-Unet 模型：了解如何使用 TensorFlow 和 Keras 构建模型。 模型训练：我们将指导您完成训练过程，优化您的模型以区分黑色素瘤和非黑色素瘤皮肤病变。 测试和评估：在新的新鲜图像上运行预先训练的模型。  探索如何生成突出显示图像中黑色素瘤区域的蒙版。 可视化结果：在我们将预测蒙版与实际地面真实蒙版进行比较时实时查看结果。 您可以在此处找到更多教程并加入我的时事通讯：https://eranfeit.net/   查看我们的教程在这里：https://youtu.be/5inxPSZz7no&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    提交人    /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ffviuu/how_to_segment_skin_melanoma_using_resunet/</guid>
      <pubDate>Fri, 13 Sep 2024 14:02:56 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 | GenAI 动画</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fdqhhq/variational_autoencoders_genai_animated/</link>
      <description><![CDATA[        提交人    /u/keghn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fdqhhq/variational_autoencoders_genai_animated/</guid>
      <pubDate>Tue, 10 Sep 2024 19:25:39 GMT</pubDate>
    </item>
    <item>
      <title>元认知人工智能的 TRAP 框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fd1drr/trap_framework_for_metacognitive_ai/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fd1drr/trap_framework_for_metacognitive_ai/</guid>
      <pubDate>Mon, 09 Sep 2024 21:41:45 GMT</pubDate>
    </item>
    <item>
      <title>捕捉时间序列数据中价格峰值的技术</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fcj86i/techniques_for_capturing_price_spikes_in_time/</link>
      <description><![CDATA[我正在研究一个时间序列预测模型，每 5 分钟预测一次价格，但在有效处理价格飙升方面遇到了困难。这些峰值是价格的突然急剧变化（包括正值和负值），我当前的 LSTM 模型很难准确预测它们。 以下是我到目前为止尝试过的方法：  自定义损失函数（如加权 MSE），用于强调峰值期间的误差。 特征工程，使用滞后特征、移动平均线、波动性和 RSI 指标来捕捉峰值发生之前的市场行为。  我很感激任何建议或替代方法，特别是在深度学习领域（例如混合模型、高级损失函数或注意力机制），以提高模型对这些极端变化的性能。 注意：由于项目限制，我不能使用传统方法，如 ARIMA 或 SARIMA，而必须只关注深度学习技术。   由    /u/BroccoliSimple5428  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fcj86i/techniques_for_capturing_price_spikes_in_time/</guid>
      <pubDate>Mon, 09 Sep 2024 06:47:43 GMT</pubDate>
    </item>
    <item>
      <title>想要创建一个真正擅长塔防游戏的神经网络。我需要学习什么才能创建它？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fc2tiv/seeking_to_create_a_neural_network_that_is_really/</link>
      <description><![CDATA[我希望能够创建一个 AI，给定一个 X x Y 块网格、一个起点和一个终点，以及网格中放置的随机数量的障碍物，它可以从这两个点创建最长的路径。我需要学习什么才能做到这一点，我在制作迷宫时如何直观地显示迷宫，以便监控我的进度？哪些资源/程序最适合帮助我学习和实现这一点？    提交人    /u/victorysheep   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fc2tiv/seeking_to_create_a_neural_network_that_is_really/</guid>
      <pubDate>Sun, 08 Sep 2024 17:11:14 GMT</pubDate>
    </item>
    <item>
      <title>终身学习的视觉概念基础：杨业洲</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fbd92f/visual_concept_grounding_for_lifelong_learning/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fbd92f/visual_concept_grounding_for_lifelong_learning/</guid>
      <pubDate>Sat, 07 Sep 2024 18:09:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么我增加核数量后 CNN 会失败？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1fb4t3o/why_my_cnn_failed_after_i_increased_the_number_of/</link>
      <description><![CDATA[我有一个 CNN，它只有 1 个卷积层，有 16 个 3x3 内核，步幅设置为 (1,1)。这组参数提供了强大的模型性能。但是，在所有其他参数保持不变的情况下，我将内核数量增加到 32。然后我的模型突然失败了，在训练集上的准确率为 50%，在验证集上的准确率为 40%。然后我在失败模型的基础上将步幅重置为 (2, 2)，模型的性能再次变得强大。所以，我有两个问题：1. 为什么增加内核数量会导致失败？2. 为什么增加步幅会让失败的模型重新成功？感谢您的回复！    提交人    /u/I_AM_Chang_Three   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1fb4t3o/why_my_cnn_failed_after_i_increased_the_number_of/</guid>
      <pubDate>Sat, 07 Sep 2024 11:31:52 GMT</pubDate>
    </item>
    <item>
      <title>您知道我可以在哪里找到详尽的人工智能研究术语列表吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1f9j6k7/any_idea_on_where_i_could_find_an_exhaustive_list/</link>
      <description><![CDATA[我希望找到一份详尽的术语列表。包括人工智能研究中提到的术语。    提交人    /u/EconomyPumpkin2050   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1f9j6k7/any_idea_on_where_i_could_find_an_exhaustive_list/</guid>
      <pubDate>Thu, 05 Sep 2024 10:34:09 GMT</pubDate>
    </item>
    </channel>
</rss>