<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Sat, 30 Mar 2024 18:17:04 GMT</lastBuildDate>
    <item>
      <title>TensorFlow 迁移学习：使用 Mobilenet 和 Python 对图像进行分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</link>
      <description><![CDATA[      https://preview.redd.it/zyusaigsrfrc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=b6b7442176ceca4d52bef 6dba7571da7af8e6b91 在本视频中，我们将向您展示如何使用 TensorFlow 和 Mobilenet 通过迁移学习来训练图像分类模型。  我们将指导您完成图像数据预处理、微调预训练 Mobilenet 模型以及使用验证数据评估其性能的过程。  视频教程的链接在这里：https://youtu.be/xsBm_DTSbB0 &lt; p&gt;我还在视频说明中分享了 Python 代码。 享受吧， Eran #TensorFlow #Mobilenet #ImageClassification #TransferLearning #Python #DeepLearning #机器学习 #ArtificialIntelligence #PretrainedModels #ImageRecognition #OpenCV #ComputerVision #Cnn   由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1brddq9/tensorflow_transfer_learning_classify_images_with/</guid>
      <pubDate>Sat, 30 Mar 2024 08:58:14 GMT</pubDate>
    </item>
    <item>
      <title>受大脑启发的混沌尖峰反向传播</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bquik4/braininspired_chaotic_spiking_backpropagation/</guid>
      <pubDate>Fri, 29 Mar 2024 17:10:30 GMT</pubDate>
    </item>
    <item>
      <title>BART 模型解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bqptwh/bart_model_explained/</link>
      <description><![CDATA[您好， 我创建了一个视频 这里我解释了BART模型的架构以及它是如何预训练的。 我希望它对你们中的一些人有用。非常欢迎反馈！ :)   由   提交/u/Personal-Trainer-541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bqptwh/bart_model_explained/</guid>
      <pubDate>Fri, 29 Mar 2024 13:53:04 GMT</pubDate>
    </item>
    <item>
      <title>负责任的法学硕士（陈天龙，麻省理工学院 - Metacog AI）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bpdgxg/accountable_llms_tianlong_chen_mit_metacog_ai/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bpdgxg/accountable_llms_tianlong_chen_mit_metacog_ai/</guid>
      <pubDate>Wed, 27 Mar 2024 21:23:53 GMT</pubDate>
    </item>
    <item>
      <title>探索用于生成音乐可解释人工智能的变分自动编码器架构、配置和数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bpb1ko/exploring_variational_autoencoder_architectures/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bpb1ko/exploring_variational_autoencoder_architectures/</guid>
      <pubDate>Wed, 27 Mar 2024 19:47:02 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络的基本深度学习算法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bo7wno/essential_deep_learning_algorithms_for_artificial/</link>
      <description><![CDATA[    &lt; /a&gt;   由   提交/u/Emily-joe  /u/Emily-joe  artiba.org/blog/essential-deep-learning-algorithms-for-artificial-neural-networks&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bo7wno/essential_deep_learning_algorithms_for_artificial/</guid>
      <pubDate>Tue, 26 Mar 2024 13:28:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn93sm/how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Mon, 25 Mar 2024 09:05:45 GMT</pubDate>
    </item>
    <item>
      <title>FeatUp：一种机器学习算法，可升级深度神经网络的分辨率以提高计算机视觉任务的性能</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</link>
      <description><![CDATA[       由   提交/u/UpvoteBeast  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bn76uj/featup_a_machine_learning_algorithm_that_upgrades/</guid>
      <pubDate>Mon, 25 Mar 2024 06:46:48 GMT</pubDate>
    </item>
    <item>
      <title>我需要有关 SoftMax 函数的说明</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</link>
      <description><![CDATA[我最近一直在开发一个深度学习库，以更好地理解机器学习概念，现在我正在实现一个软最大激活函数，一切似乎都是正确的，因为我检查了现有 softmax 计算器上的输出和导数的值并且它们匹配起来，但是当我让我的网络进行训练时，它没有学到任何东西，输出要么是 [0.5, 0.4] ish，要么是它们不考虑目标，随机变为 0.9。  当我的数据集中有多个样本（例如图像分类器）时，各个样本的所有输出加起来为 1，这令人困惑。我知道 softmax 应该将 1 个样本的输出分配为“概率”但我不明白为什么它发生在我的数据集的样本之间 我很困惑，softmax 是否只是一个常规激活函数，或者它是否像一个特殊情况。我看到一个视频，他们将 softmax 视为一层而不是激活函数，这让我怀疑与其他激活函数相比，softmax 函数是否具有不同的反向传播步骤。当我将最后一个激活函数更改为 sigmoid、tanH 或 ReLU 时，一切正常。 非常感谢任何反馈或评论，因为我花了几个小时在这上面。   由   提交 /u/chjammy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmsq2f/i_need_clarification_on_the_softmax_function/</guid>
      <pubDate>Sun, 24 Mar 2024 19:13:17 GMT</pubDate>
    </item>
    <item>
      <title>回归网络中使用什么样的激活函数？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmentm/what_kind_of_activation_functions_are_used_in/</link>
      <description><![CDATA[我正在从头开始编码一个神经网络，并且想知道哪种激活函数最适合回归问题（我正在尝试让它评估输入）。我的权重和偏差应该在什么样的范围内，它们应该是负数还是正数。训练过程与分类网络有何不同？感谢任何帮助:)   由   提交 /u/Crisps_Beluker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmentm/what_kind_of_activation_functions_are_used_in/</guid>
      <pubDate>Sun, 24 Mar 2024 07:02:21 GMT</pubDate>
    </item>
    <item>
      <title>大学人工智能项目帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/</link>
      <description><![CDATA[我正在做一个项目，我们利用神经网络模型来评估描述性答卷。目前我们只有大约 120 篇论文来训练它，即 2 套试卷。这够了吗？ bert 是这个项目的好模型吗？   由   提交/u/Similar-Ranger4226   reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bmd4aw/college_ai_project_help/</guid>
      <pubDate>Sun, 24 Mar 2024 05:20:09 GMT</pubDate>
    </item>
    <item>
      <title>训练 LLMS 遵循人类反馈指令 (RLHF) - 论文解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkxae4/training_llms_to_follow_instructions_with_human/</link>
      <description><![CDATA[       由   提交/u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkxae4/training_llms_to_follow_instructions_with_human/</guid>
      <pubDate>Fri, 22 Mar 2024 11:45:40 GMT</pubDate>
    </item>
    <item>
      <title>思维链推理如何帮助神经网络计算</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkq1wk/how_chainofthought_reasoning_helps_neural/</link>
      <description><![CDATA[       由   提交/u/nickb  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkq1wk/how_chainofthought_reasoning_helps_neural/</guid>
      <pubDate>Fri, 22 Mar 2024 03:40:49 GMT</pubDate>
    </item>
    <item>
      <title>关于CNN池化工具的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</link>
      <description><![CDATA[HI AI &amp; HI AI ML 专家： 我是一名设计师，试图从高层次上理解 CNN。我被池化工具卡住了。 如果我理解正确的话，请告诉我：池化工具更像是轮廓、对比、凹陷的工具，让某些特征突出，同时减少计算负载，因为通过这些关键轮廓、对比度、凹面等部分，CNN 提取了足够的关键信息以供后续 ANN 处理。 我理解正确吗？我期待您的专家意见。谢谢！   由   提交/u/Ivory8977  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkio8l/question_about_pooling_tool_in_cnn/</guid>
      <pubDate>Thu, 21 Mar 2024 21:54:47 GMT</pubDate>
    </item>
    <item>
      <title>帮助描述性答卷评估器 NN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</link>
      <description><![CDATA[我是一名大学生，目前正在进行人工智能项目。它是一个答卷评估器，其中神经网络输入已经评估的答卷及其相应的分数。我对神经网络了解不多，所以谁能告诉我使用哪种神经网络模型。我正在考虑将 bert 和 cnn 配对。请建议良好的模型配对，以制作最准确的模型   由   提交/u/Consistent_Peanut998   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bkbhrn/help_with_descriptive_answersheet_evaluater_nn/</guid>
      <pubDate>Thu, 21 Mar 2024 17:02:26 GMT</pubDate>
    </item>
    </channel>
</rss>