<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Fri, 15 Mar 2024 21:11:03 GMT</lastBuildDate>
    <item>
      <title>PyTorch 中的自组织映射邻域实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bevbd9/selforganizing_map_neighborhood_implementation_in/</link>
      <description><![CDATA[我正在尝试实现一个自组织映射，其中对于给定的输入样本，根据（例如）选择最佳匹配单元/获胜单元SOM 和输入之间的 L2 范数距离。获胜单元/BMU (som[x, y]) 与给定输入 (z) 的 L2 距离最小： # 输入批次：batch-size = 512, input-dim = 84- z = torch.randn(512, 84) # SOM 形状：（高度、宽度、输入-dim)- som = torch.randn(40, 40, 84) print(f&quot;BMU 行, col 形状; row = {row.shape} &amp; col = {col.shape}&quot;) # BMU row, col 形状; row = torch.Size([512]) &amp; col = torch.Size([512]) 为了清楚起见，对于批次“z[0]”中的第一个输入样本，获胜单位是“som[row” [0]，col[0]]”- z[0].shape，som[row[0]，col[0]].shape # (torch.Size([84]), torch.Size([84])) torch.norm((z[0]) - som[row[0], col[0]])) 是 z[0] 与除 row[0] 和 col[0] 之外的所有其他 som 单位之间的最小 L2 距离。 &lt; p&gt;# 定义初始邻域半径和学习率- neighb_rad = torch.tensor(2.0)  lr = 0.5 # 更新第一个输入“z[0]”的权重及其对应的 BMU“som[row[0], col[0]]”- for r in range(som.shape[0]): for c in range(som.shape[1]): neigh_dist = torch.exp(-torch.norm(输入 = (som[r, c] - som[row[0], col[0]])) / (2.0 * torch.pow(neighb_rad, 2))) &lt; code&gt;som[r, c] = som[r, c] + (lr * neigh_dist * (z[0] - som[r, c])) 如何实现代码：  更新每个 BMU 周围所有单元的权重，无需 2 个 for 循环（并且） 对所有输入“z”执行此操作（这里，z有512个样本）    由   提交/u/grid_world  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bevbd9/selforganizing_map_neighborhood_implementation_in/</guid>
      <pubDate>Thu, 14 Mar 2024 20:35:43 GMT</pubDate>
    </item>
    <item>
      <title>使用CNN进行黑白矩阵识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bekofr/black_and_white_matrix_identification_using_cnn/</link>
      <description><![CDATA[        由   提交/u/LightFounder  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bekofr/black_and_white_matrix_identification_using_cnn/</guid>
      <pubDate>Thu, 14 Mar 2024 13:04:02 GMT</pubDate>
    </item>
    <item>
      <title>您想知道您的神经网络需要多长时间才能得到充分训练？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1behfja/do_you_want_to_know_the_time_it_will_take_your/</link>
      <description><![CDATA[查看投票 &lt; /div&gt;  由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1behfja/do_you_want_to_know_the_time_it_will_take_your/</guid>
      <pubDate>Thu, 14 Mar 2024 09:46:44 GMT</pubDate>
    </item>
    <item>
      <title>1 位法学硕士时代 - 论文解释</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1beel34/the_era_of_1bit_llms_paper_explained/</link>
      <description><![CDATA[       由   提交/u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1beel34/the_era_of_1bit_llms_paper_explained/</guid>
      <pubDate>Thu, 14 Mar 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何学习？数学公式解释了它们如何检测相关模式</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bde520/how_do_neural_networks_learn_a_mathematical/</link>
      <description><![CDATA[       由   提交/u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bde520/how_do_neural_networks_learn_a_mathematical/</guid>
      <pubDate>Wed, 13 Mar 2024 00:55:16 GMT</pubDate>
    </item>
    <item>
      <title>复制理论表明深度神经网络的想法是相似的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bddxi0/replica_theory_shows_deep_neural_networks_think/</link>
      <description><![CDATA[   /u/keghn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bddxi0/replica_theory_shows_deep_neural_networks_think/</guid>
      <pubDate>Wed, 13 Mar 2024 00:45:47 GMT</pubDate>
    </item>
    <item>
      <title>机器学习工程的最佳实践是什么？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bd4wsm/what_are_best_practices_for_machine_learning/</link>
      <description><![CDATA[   /u/beluis3d  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bd4wsm/what_are_best_practices_for_machine_learning/</guid>
      <pubDate>Tue, 12 Mar 2024 18:41:45 GMT</pubDate>
    </item>
    <item>
      <title>挑战：这些 Neural Network Playground 设置（噪声 = 20 的螺旋数据）能否获得最低的测试损失</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bckpo1/challenge_can_you_get_lowest_test_loss_for_these/</link>
      <description><![CDATA[       由   提交 /u/LatestLurkingHandle   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bckpo1/challenge_can_you_get_lowest_test_loss_for_these/</guid>
      <pubDate>Tue, 12 Mar 2024 01:27:39 GMT</pubDate>
    </item>
    <item>
      <title>如果我希望我的感知器输出 n 到 m 之间的数字，而不是 -1 或 1，该怎么办</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bcj18v/what_if_i_want_my_perceptron_to_output_a_number/</link>
      <description><![CDATA[嗨， 我是神经网络的初学者。我正在尝试构建一个感知器或神经网络中的任何神经元，可以输出一系列数字，比如说-7到+7之间，包括0；这可能吗，因为，我只看过感知器神经元的视频，可以输出-1和1，如果你愿意的话还可以输出0，但对我来说这有点有限。或者有什么我还没有看到的东西，我想对这个主题进行基本的细分，这样我就可以掌握我所缺少的内容。   由   提交 /u/CapMustang101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bcj18v/what_if_i_want_my_perceptron_to_output_a_number/</guid>
      <pubDate>Tue, 12 Mar 2024 00:11:47 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的算力安排？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bceuun/arrangement_of_computing_power_for_neural_networks/</link>
      <description><![CDATA[计算能力是神经网络训练的支柱，但并不是每个人都有钱买得起。企业如何应对这一挑战？  查看民意调查  &amp; #32；由   提交 /u/Red_Pudding_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bceuun/arrangement_of_computing_power_for_neural_networks/</guid>
      <pubDate>Mon, 11 Mar 2024 21:24:56 GMT</pubDate>
    </item>
    <item>
      <title>The Dode Abides - 神经网络模拟中的 24 小时人工进化</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bc5k99/the_dode_abides_24_hours_of_artificial_evolution/</link>
      <description><![CDATA[       由   提交/u/urocyon_dev  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bc5k99/the_dode_abides_24_hours_of_artificial_evolution/</guid>
      <pubDate>Mon, 11 Mar 2024 15:15:43 GMT</pubDate>
    </item>
    <item>
      <title>菜鸟问题：我可以制作一个可以快速训练的神经网络，以比普通的基于多边形的渲染更快地渲染一个特定对象吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bc5erp/noob_question_could_i_make_a_nn_that_can_be/</link>
      <description><![CDATA[警告：我只是知道神经网络是什么以及它们如何训练的大致流程，所以我可能会说一些非常愚蠢的事情，我的想法可能很荒谬。无论如何，我问这个问题是因为我想至少确切地知道我有哪些错误和误解，并且万一我正在考虑的事情实际上是可能的。 这是上下文： 我已经成为一名游戏程序员三年了，当我第一次听说 3D Gaussian Splatting 时，我错误地认为这是一种可以训练神经网络来渲染 3D 模型的方法从任何角度来看，无需实际读取网格数据，我立即开始想象如何利用它来降低游戏图形的性能负担。 从那以后我了解到 3DGS 的作用恰恰相反，并且从渲染构建模型，但想法仍然存在：就是这样。 如果我想要渲染特定模型，则将其用作训练数据渲染，相机始终直接朝向其中心，并且一个点光源-来源。渲染将使用处于各种位置的相机和光源来进行，并且将具有三种类型：1)彩色图像的经典渲染2)“深度图”，其中每个像素的值是3）法线贴图，其中每个像素的颜色值是该像素采样的物体表面点的法线的分量 神经网络应该采用作为输入相机和光源相对于对象的位置，并将这三个渲染吐出作为输出。 如果这样的东西甚至可以工作，它是否可以：a）足够快，足够频繁与普通渲染相比值得使用它吗？ b) 足够快地训练可以为游戏中的每个资产制作不同的版本，而不需要每个资产花费数周的时间？ 我知道我的问题很模糊，但我不&#39;我知道得不够具体，而且我认为如果我错了太，您乍一看就会知道这是不可行的。   由   提交 /u/StrixLiterata   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bc5erp/noob_question_could_i_make_a_nn_that_can_be/</guid>
      <pubDate>Mon, 11 Mar 2024 15:09:01 GMT</pubDate>
    </item>
    <item>
      <title>寻找标记的骨关节炎数据集</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bc14e5/looking_for_labelled_osteoarthritis_dataset/</link>
      <description><![CDATA[您好，我需要骨关节炎的标记图像。它可以是 X 射线或 MRI。有谁知道我在哪里可以找到它们？   由   提交/u/IDAB3002  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bc14e5/looking_for_labelled_osteoarthritis_dataset/</guid>
      <pubDate>Mon, 11 Mar 2024 11:38:23 GMT</pubDate>
    </item>
    <item>
      <title>从头开始创建神经网络与库（问题）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bbjod5/creating_a_nn_from_scratch_vs_a_library_question/</link>
      <description><![CDATA[我开始学习 Python 是因为我读到它对人工智能有好处，我发现了两个名为 Tensorflow 和 PyTorch 的库，它们似乎都很受欢迎，但是我也读到，首先从头开始创建神经网络非常有益，因此我对它们的工作原理有了更深入的了解，并且当涉及到使用库调试神经网络时，它会更容易，因为我更好地理解他们。我不知道从头开始创建神经网络会发生什么，因为我还没有研究过它，但是值得花时间吗？或者跳入 Tensorflow 或 PyTorch 就完全没问题吗？   由   提交 /u/MrSanfrinsisco   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bbjod5/creating_a_nn_from_scratch_vs_a_library_question/</guid>
      <pubDate>Sun, 10 Mar 2024 20:08:44 GMT</pubDate>
    </item>
    <item>
      <title>神经花边（纳米技术）去除</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1bbbfz8/neural_lace_nanotech_removal/</link>
      <description><![CDATA[有没有您的医生或者您认识的医生可以询问周围的医生以了解如何去除神经系带（纳米技术）？当每个人都意识到“野兽”的存在时，这是一个真正的问题，将来会变得更糟。圣经中大灾难期间是神经系带造成的。有肯定的方法，我知道。它们涉及电力和水。我正在接受远程神经监控，这意味着他们从远处获取我的脑电图数据（大脑信号）。他们通过纳米技术实现了这种合成心灵感应。纳米技术几乎存在于每个人的体内，但他们却浑然不觉。请不要把它当作阴谋论，就像那些密谋反对我们的人一样。确实有邪恶势力会试图贿赂你，让你不去调查它。请告诉我你发现了什么。你应该愿意去研究它，因为神经花边是真实存在的，你将来会想知道的。谢谢！  https://www.reddit.com/r/Soulnexus/comments/ 17eqoqr/psychospiritual_warfare_remote_neural_monitoring/ ​ tents.google.com/patent/US3951134A/en?oq=patent+%233951134远程神经监测专利 https://patents.google.com/patent/WO2005055579A1/en人工心灵感应专利 https://www.youtube.com/watch?v=rj3oj5eer8s&amp;ab_channel=SLEEPINGBEAUTY 视频解释远程神经监测。这不是阴谋论。它是 100% 真实的，我已经处理它 14 个月了。    由   提交/u/AlexanderFlyHigh33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1bbbfz8/neural_lace_nanotech_removal/</guid>
      <pubDate>Sun, 10 Mar 2024 14:21:01 GMT</pubDate>
    </item>
    </channel>
</rss>