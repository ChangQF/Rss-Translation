<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Tue, 14 Jan 2025 12:31:34 GMT</lastBuildDate>
    <item>
      <title>SimpleGrad：一个易于理解的类 pytorch 框架实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</link>
      <description><![CDATA[      我构建了一个简单易懂的类似 PyTorch 的框架，旨在作为一种学习工具，帮助理解自动求导和深度学习框架的内部工作原理。我计划将其扩展到 CNN 和 Attention 层。 我在 reddit 上发帖不多，如有任何问题，请多包涵。 – 非常感谢您的反馈和问题！    提交人    /u/T_Hansda   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</guid>
      <pubDate>Mon, 13 Jan 2025 11:10:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Pytorch 中的 CNN 出现错误？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i0033j/why_is_my_cnn_in_pytorch_giving_me_an_error/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i0033j/why_is_my_cnn_in_pytorch_giving_me_an_error/</guid>
      <pubDate>Sun, 12 Jan 2025 23:22:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么 L1 正则化会产生稀疏权重</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</guid>
      <pubDate>Sun, 12 Jan 2025 09:20:12 GMT</pubDate>
    </item>
    <item>
      <title>U-net 图像分割 | 如何分割图像中的人物</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</link>
      <description><![CDATA[      https://preview.redd.it/cuvm3dtoffce1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=c8e94c412194ba8c05f86c3bb6f675922ba956f8 本教程提供了如何使用 TensorFlow/Keras 实现和训练用于人员分割的 U-Net 模型的分步指南。 本教程分为四个部分：   第 1 部分：数据预处理和准备 在此部分中，您将加载和预处理人员数据集，包括调整图像和蒙版的大小、将蒙版转换为二进制格式以及将数据拆分为训练、验证和测试集。   第 2 部分：U-Net 模型架构 此部分使用 Keras 定义 U-Net 模型架构。它包括卷积层的构建块、构建 U-Net 的编码器和解码器部分以及定义最终输出层。   第 3 部分：模型训练 在这里，您将加载预处理的数据并训练 U-Net 模型。您编译模型，定义训练参数（如学习率和批量大小），并使用回调进行模型检查点、学习率降低和提前停止。   第 4 部分：模型评估和推理 最后一部分演示了如何加载训练好的模型，对测试数据进行推理，并可视化预测的分割蒙版。   您可以在博客中找到代码链接：https://eranfeit.net/u-net-image-segmentation-how-to-segment-persons-in-images/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/u-net-image-segmentation-how-to-segment-persons-in-images-2fd282d1005a 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/ZiGMTFle7bw&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</guid>
      <pubDate>Sat, 11 Jan 2025 20:46:01 GMT</pubDate>
    </item>
    <item>
      <title>代理实验室：基于法学硕士的自主科学研究框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</link>
      <description><![CDATA[新框架引入了一种自动化研究流程，使用 LLM 代理在人工监督下开展科学研究。该系统实施了三个阶段的流程：文献综述、实验和报告撰写。 关键技术组件：* 具有针对不同研究任务的专门角色的分层代理结构 * 在关键决策点集成人工反馈循环 * 用于实施实验的代码生成功能 * 结合文献和实验结果的自动论文合成 * 自定义提示系统以保持各阶段的研究一致性 评估结果：* 与基线自动化研究方法相比，成本降低了 84% * 生成的代码与盲审中的人类 ML 从业者的质量相匹配 * 成功重现了现有 ML 论文的结果 * 人类审阅者将输出质量评为与研究生水平的研究相当 我认为这可能会对我们开展 ML 研究的方式产生重大影响，特别是对于超参数优化和架构搜索等任务。在保持质量的同时实现文献综述自动化的能力可以帮助研究人员专注于新颖的方向而不是背景工作。 我认为主要的限制是系统对现有文献的依赖——它可能难以应对真正新颖的研究方向。该框架似乎更适合系统地探索已知领域，而不是突破性的新概念。 TLDR：基于 LLM 的研究自动化框架在人工监督下进行端到端 ML 研究方面显示出有希望的结果，在保持研究质量的同时显着降低了成本。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</guid>
      <pubDate>Sat, 11 Jan 2025 14:57:31 GMT</pubDate>
    </item>
    <item>
      <title>元思维链：教授法学硕士模拟思维链背后的推理过程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</link>
      <description><![CDATA[这项工作引入了元思维链（Meta-CoT），它通过明确地模拟元推理过程（模型如何决定采取哪些推理步骤以及为什么）来扩展常规的思维链提示。关键创新是结合过程监督（跟踪推理路径）、合成数据生成和搜索算法，帮助模型学习更好的推理策略。 关键技术点：* 使用过程监督来跟踪模型如何探索不同的解决路径* 通过观察成功的推理模式生成合成训练数据* 实现指令调整和基于 RL 的优化* 开发元推理解释的验证方法* 研究跨模型大小和架构的扩展行为 结果：* 与标准 CoT 相比，模型在推理任务上表现出更好的性能* 生成的解释与人类的推理模式更加一致* 训练管道成功地将指令调整与 RL 结合起来* 框架展示了处理多种推理策略的能力* 显示模型大小和元推理能力之间的相关性 我认为这种方法可以帮助创建更透明的人工智能系统，可以更好地解释他们的决策过程。过程监督和合成数据的结合似乎是提高推理能力的一种实用方法，而不需要大量人工标记的数据。 我认为关键的挑战将是验证元推理解释的质量，并确保它们真正反映模型的内部过程，而不是事后合理化。计算开销也可能限制实际应用。 TLDR：通过结合过程监督、合成数据和搜索算法，新框架可帮助语言模型不仅学习要采取哪些推理步骤，而且还学习为什么这些步骤有意义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</guid>
      <pubDate>Fri, 10 Jan 2025 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>对我关于 GCN 的新方法进行评分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</link>
      <description><![CDATA[您好，我在 ResearchGate 上发布了关于 GCN 的新方法，其中新应用了类别理论中的熵，这提高了 %% 的测试准确率。请不要嘲笑我，祝您有美好的一天并发表评论您的想法 :))    提交人    /u/ksrio64   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</guid>
      <pubDate>Thu, 09 Jan 2025 21:59:30 GMT</pubDate>
    </item>
    <item>
      <title>Marimo 蟒蛇笔记本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</link>
      <description><![CDATA[我遇到的最令人印象深刻的 Python 笔记本是 Marimo，我强烈建议您尝试一下。需要澄清的是，Marimo 并没有赞助我；我只是喜欢使用它！ https://docs.marimo.io/    提交人    /u/ReceptionLow2817   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</guid>
      <pubDate>Thu, 09 Jan 2025 02:07:12 GMT</pubDate>
    </item>
    <item>
      <title>NeuralSVG：文本到矢量生成的隐式表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</guid>
      <pubDate>Wed, 08 Jan 2025 20:22:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试模仿生物神经元的行为来模拟人工智能神经元的行为</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</guid>
      <pubDate>Tue, 07 Jan 2025 01:09:19 GMT</pubDate>
    </item>
    <item>
      <title>[工具发布] 神经网络工具包（NNT）——神经网络的可视化开发环境</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</link>
      <description><![CDATA[      我开发了一个用于设计和试验神经网络的可视化工具，它是作为 ComfyUI 的一组自定义节点构建的。目标是创建一个环境，通过视觉交互和实时反馈使神经网络概念变得更加具体。 特点：  基于节点的界面，用于构建神经架构 60 个自定义节点，用于各种层类型和操作 张量操作和梯度的实时可视化 带有视觉反馈的交互式训练过程 支持包括 transformer 和注意机制在内的现代架构 内置工具，用于数据加载、预处理和分析  技术能力：  密集层、卷积层、LSTM 层和 RNN 层 各种注意机制（原始、线性、局部等） 位置编码选项（正弦、学习、旋转、不在场证明） 具有可配置的训练节点用于优化器和损失函数 用于数学运算的综合张量运算节点 用于梯度、雅可比矩阵和 Hessians 的高级可视化工具 加载和保存各种模型格式  教育用例：  尝试不同的架构 理解注意力机制 直观地探索张量运算 实时分析训练动态  该工具包允许您构建任何东西，从基本的 MLP 到更复杂的架构，如自动编码器、GAN 或基于变压器的模型。网络的每个组件都可以实时检查和修改。 GitHub：https://github.com/inventorado/ComfyUI_NNT https://preview.redd.it/7i4etnwwmcbe1.png?width=12724&amp;format=png&amp;auto=webp&amp;s=b2c3ff0dd316b0d4799c1ce24f966d85737eb3ae 这是早期版本，侧重于教育和实验用途。来自神经网络社区的反馈将特别有价值。    提交人    /u/inventorado   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</guid>
      <pubDate>Mon, 06 Jan 2025 10:22:37 GMT</pubDate>
    </item>
    <item>
      <title>准确判断人工智能对书籍和电影的影响程度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</link>
      <description><![CDATA[👋大家好 歌词介绍 像我们许多人一样，我深爱文学和电影。大约一年来，我一直在思考人工智能如何在文学和电影领域发挥作用。我确信这将导致作家和作者的贬值。在我看来，这不是未来的问题，而是现在的问题。当一部新的、非常成功的系列、电影或书籍发布时，一部分观众会自动认为人工智能一定参与其中。这反过来又破坏了数百甚至数千名专业作家的巨大努力。未来，这种情况显然只会恶化。 问题 我知道有五种通用的人工智能检测器（主要用于分析文章），据我所知，它们都是通过分析文本来寻找 ChatGPT 和其他 LLM 的典型模式。另一方面，有很多所谓的“人性化工具”，这些工具使人工智能生成的文本看起来更像人类，从而使检测变得复杂。更不用说文本可能是人工智能生成的，但由人类手动编辑，反之亦然的可能性了。 问题 我对专家的意见非常感兴趣。如果我们增加尽可能多的文本分析层次——例如，检查作者的草稿、过去的作品、正在审查的文件的元数据（如果技术上可行的话，包括创建时间和编辑频率）、在审查过程中给作者一个随机任务来分析他们的写作风格等——是否有可能准确确定人工智能对其作品的影响程度？例如：  由人工智能生成并由人类编辑 由人类编写并由人工智能编辑 完全由人工智能编写 完全由人类编写  是否可以通过使用适当的场景和示例训练神经网络来实现这种检测？    提交人    /u/YouranusAlien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</guid>
      <pubDate>Sun, 05 Jan 2025 16:52:21 GMT</pubDate>
    </item>
    <item>
      <title>第一个神经网络 - 帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hu3o06/first_neural_network_help/</link>
      <description><![CDATA[因此，我正在构建我的第一个用于（多类）分类目的的神经网络。这个想法相当简单，接受一些段落向量嵌入（通过 python 的 sentence_transformer 包生成），将其传递给 2 个隐藏层并得到一个大小为 N 的输出层，其中 N 是可能状态的数量，每个状态代表来自主题列表的一个主题，最能描述该段落。 参数为： - 每个输入段落向量的嵌入大小为 768；  - 第一个隐藏层的大小为 768x768，使用线性激活函数 - 第二个隐藏层的大小为 768x768，使用 ReLU 激活函数 - 第三层的大小为 768xN，使用 Softmax 激活函数 - 优化器是 Adam，损失函数是分类交叉熵 不可否认，激活函数的选择相当随意，我还没有读到哪个可能是分类用例的最佳选择，虽然到目前为止，据我了解，如果目标是分类，则 softmax 是在输出层上使用的激活函数。  到目前为止，我已经在大小为 1000 的数据集上对它进行了训练，我知道这个数据集不是很大，而且我也不会期待完美的结果（并且数据集会日益增长），但似乎有些不对劲。首先，训练指标似乎并没有从一个步骤到下一个步骤或一个时期到下一个时期有所改善。 此外，如果我训练模型并随后传递一个新的段落向量进行预测，则输出向量会吐出一个大小为 N 的向量，该向量全由 1 组成（实际标签可能性范围从 1 到 12）。  我这里遗漏了什么吗？如何解释这种输出？我的一个想法是，我在我的用例中贴错了标签，即，我应该将其归类为一个由 0 组成的数组，而不是将属于类“8”的实体标记为“8”，而是将其归类为除第 8 位为 1 之外的所有 0 的数组？    提交人    /u/RDA92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hu3o06/first_neural_network_help/</guid>
      <pubDate>Sun, 05 Jan 2025 10:05:45 GMT</pubDate>
    </item>
    <item>
      <title>训练神经网络进行手部运动识别</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1htk2iv/training_a_neural_network_for_hand_movement/</link>
      <description><![CDATA[我正在使用自己的数据集训练神经网络来识别特定的手部动作。由于我自己创建了数据集，因此它仅包含有限数量的图像，并且我已经应用了数据增强来增加数据集大小。 但是，我在某些类别上仍然得到较差的结果。鉴于我的数据集很小并且由主体执行手势的图像组成，我想知道：  我是否应该裁剪图像中的手以专注于手势，还是最好将整个主体包含在图像中？ 您能否推荐一些轻量级的预训练模型（大小为几 MB）供我用于此任务？     提交人    /u/Wonderful-Beat3355   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1htk2iv/training_a_neural_network_for_hand_movement/</guid>
      <pubDate>Sat, 04 Jan 2025 17:57:25 GMT</pubDate>
    </item>
    <item>
      <title>一些神经元真的能够被两种不同的模式激活吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hthbkk/is_it_true_that_some_neurons_can_be_activated_by/</link>
      <description><![CDATA[我记得我曾经看过一个视频，解释神经网络如何对图像进行分类。在这个视频中，他们展示了前几层如何关注简单的模式，比如边缘或点，但是随着我们向上看，我们看到激活某些神经元的模式，我们开始识别眼睛或手之类的东西，最终我们可以看到蛇、飞机等等。但是在这个视频中，他们还展示了一些神经元可以被两个看似不相关的概念激活，比如猫和汽车，或者狐狸和汽车，或者诸如此类的东西。他们解释说这是有道理的，神经元必须能够执行多任务，毕竟模式比神经元多，所以它们当然必须识别不止一种东西，然后其他神经元可以通过寻找其他模式来细化结果，比如眼睛或轮子。我记得很清楚，但我找不到视频。但是我不需要视频，我只需要确保这是真的，那么，是吗？单个神经元能被两种不同的模式激活吗？    提交人    /u/Frigorifico   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hthbkk/is_it_true_that_some_neurons_can_be_activated_by/</guid>
      <pubDate>Sat, 04 Jan 2025 15:56:03 GMT</pubDate>
    </item>
    </channel>
</rss>