<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Mon, 04 Nov 2024 03:26:25 GMT</lastBuildDate>
    <item>
      <title>罗伯特·赫克特-尼尔森的遗产</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</link>
      <description><![CDATA[Robert Hecht-Nielsen 在 80 年代末在 UCSD 教授了人工神经网络的研究生课程。非常棒的基础内容。Bob 也是一名冲浪者，他非常想在他的冲浪板中嵌入一些翻译马力，这样他就可以与海豚互动。我的路径与神经网络不同，所以不太了解最新情况。事情是这样的，Bob 有 386，你们有斗鱼的东西。快到 2025 年了，那里没有冲浪者怎么办？    提交人    /u/blatherer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gj09f9/robert_hechtnielsen_legacy/</guid>
      <pubDate>Sun, 03 Nov 2024 23:19:07 GMT</pubDate>
    </item>
    <item>
      <title>还没有见过很多代表训练网络中权重的图像。它们很漂亮。这是我的。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</link>
      <description><![CDATA[        提交者    /u/bombsy_rosalina   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gixs78/havent_seen_many_images_representing_weights_in/</guid>
      <pubDate>Sun, 03 Nov 2024 21:29:21 GMT</pubDate>
    </item>
    <item>
      <title>遗传算法优于 NN？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</link>
      <description><![CDATA[我有一个最小化问题：  我有一个已知的参考函数，计算速度慢，但性能很好 我设法用一个简单的 NN 很好地近似它 现在我想让它变得更好，因为参考函数已知有缺陷  问题是我无法判断函数的单个输出是好是坏。我只能把它放在一个黑匣子里，在那里使用数千次，然后得到一个性能分数。 你会如何处理这个问题？我正在考虑在我的 NN 上使用遗传算法，但我不知道从哪里开始。我记得不久前读过一篇关于这个的论文，但再也找不到了。 我也可以完全忘记我的参考函数及其 NN 近似，在这种情况下，我会回到标准最小化问题，我想知道是否有任何使用 NN 的方法，或者切换到经典最小化算法会更好。    提交人    /u/PittMarson   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1givw8w/genetic_algorithm_over_nn/</guid>
      <pubDate>Sun, 03 Nov 2024 20:07:07 GMT</pubDate>
    </item>
    <item>
      <title>120 个狗品种，超过 10,000 张图片：狗分类的深度学习教程🐕‍🦺</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</link>
      <description><![CDATA[      https://preview.redd.it/htuma7v2aqyd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1eb955978bdc315fcc5a58ef3696afd3a070080e 📽️ 在我们的最新视频教程中，我们将使用 NasLarge 预训练模型🚀和一个包含 120 种独特犬种的 10,000 多张图像的海量数据集创建一个犬种识别模型📸. 您将学到的内容： 🔹 数据准备：我们首先下载一个包含超过 20,000 张狗图像的数据集，这些图像整齐地分为 120 个类别。您将学习如何使用 Python、OpenCV 和 Numpy 加载和预处理数据，确保它完全可以进行训练。 🔹 CNN 架构和 NAS 模型：我们将使用 Nas Large 模型，并根据我们自己的需求对其进行自定义。 🔹 模型训练：利用 Tensorflow 和 Keras 的强大功能来定义和训练我们基于 Nas Large 模型的自定义 CNN 模型。我们将配置损失函数、优化器和评估指标，以在训练期间实现最佳性能。 🔹 预测新图像：观看我们对预先训练的模型进行测试！我们将展示如何使用该模型对新鲜的、从未见过的恐龙图像进行预测，并见证人工智能的魔力。   在此处查看我们的教程：https://youtu.be/vH1UVKwIhLo&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg 您可以在此处找到完整的代码：https://medium.com/p/b0008357e39c 您可以在此处找到更多教程并加入我的时事通讯：https://eranfeit.net/ 享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gitb18/120_dog_breeds_more_than_10000_images_deep/</guid>
      <pubDate>Sun, 03 Nov 2024 18:16:25 GMT</pubDate>
    </item>
    <item>
      <title>神经语言模型中嵌入层的目的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gikyzx/purpose_of_embedding_layer_in_neural_language/</link>
      <description><![CDATA[所以我正在参加一个关于机器学习的讲座，我们正在学习 3blue1brown 在他的视频系列中关于大型语言模型的内容，即给定一组单词，如何预测下一个单词。 让我困惑的是关于词嵌入的解释和词嵌入的实现不合逻辑。 词嵌入的解释：它是一些高维空间，其中单词被映射到向量，这些向量在高维空间中仍然共享一些意义概念。讲座中的解释显示了彼此相关的单词在集群中更接近的图形。 3blue1brown 的解释是这样的，男人和女人的向量之间的差异类似于国王和王后的向量，所以你可以做一些看起来像数学的事情来得到：王后 = 国王 - 男人 + 女人。 换句话说，词嵌入的解释声称它们捕获了语义关系！ 但是，当你真正实现嵌入时，而不是真正实现而只是使用 torch.nn.Embedding，所有这些都变得没用，嵌入层的用途对我来说变得模糊。 nn.Embedding 基本上给你一种将整数映射到随机初始化的向量的可能性。因此，您应该自己定义标记和整数之间的映射，可以是 Python 字典，也可以只使用文本并从 0 到文本末尾索引单词，然后声明相同的索引在嵌入中。 nn.Embedding 本质上只是根据您的 vocab_size（标记数）和您想要的嵌入向量的更高维度创建一个矩阵。然后，您可以通过传入带有这些索引的张量来访问该矩阵的每一行。 换句话说，单词嵌入的实现只会给您随机的、未经训练的向量。映射由您完成。 它可能朝着您必须训练嵌入的方向发展，以使其变成所教的内容以及您在谷歌搜索“词嵌入”时通常会找到的内容。 但如果这是真的，我们究竟想通过在神经网络中使用嵌入层来实现什么？ 因为如果嵌入层未经训练，它实际上不会为网络本身带来任何好处。它只是将文本映射到向量的一种方式，仅此而已。嵌入层的权重会以某种方式进行调整，以便我尝试使用网络完成的任何工作都可以正常工作。这并不意味着嵌入层会变成这个词向量空间，其中相似的单词彼此更接近。或者这仍然会作为副作用发生？    提交人    /u/elm1ra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gikyzx/purpose_of_embedding_layer_in_neural_language/</guid>
      <pubDate>Sun, 03 Nov 2024 11:42:05 GMT</pubDate>
    </item>
    <item>
      <title>Oasis：基于扩散变压器的模型，用于生成可玩的视频游戏</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</link>
      <description><![CDATA[decart 和 etched 开发的 Oasis 已经发布，它可以输出可玩的视频游戏，用户可以执行移动、跳跃、检查库存等操作。这不像谷歌的 GameNGen，它只能输出游戏视频（但不能播放）。在此处查看演示和其他详细信息：https://youtu.be/INsEs1sve9k    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ght148/oasis_diffusion_transformer_based_model_to/</guid>
      <pubDate>Sat, 02 Nov 2024 09:55:08 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的偏差</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</link>
      <description><![CDATA[大家好，我最近开始研究神经网络。让我有些困惑的概念是偏差。我理解偏差在神经网络中的用途，但我仍然不明白两件事：  各个隐藏层中的每个单元是否都有自己的偏差，或者每个隐藏层的所有单元是否有共同的偏差？ 我不明白为什么在某些情况下偏差通过一个单元来表示，并附加自己的权重。它不应该是一个参数，因此不应该作为一个单元出现吗？     提交人    /u/Annual_Inflation_235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</guid>
      <pubDate>Thu, 31 Oct 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>运行此代码需要多少普通内存</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</link>
      <description><![CDATA[import torch 导入 torch.nn 作为 nn class TransformerBlock(nn.Module): def __init__(self, embed_size, heads, dropout, forward_expansion): super(TransformerBlock, self).__init__() self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads) self.norm1 = nn.LayerNorm(embed_size) self.norm2 = nn.LayerNorm(embed_size) self.feed_forward = nn.Sequential( nn.Linear(embed_size, forward_expansion * embed_size), nn.ReLU(), nn.Linear(forward_expansion * embed_size, embed_size) ) self.dropout1 = nn.Dropout(dropout) self.dropout2 = nn.Dropout(dropout) def forward(self, x):tention = self.attention(x, x, x)[0] x = self.dropout1(self.norm1(attention + x)) forward = self.feed_forward(x) out = self.dropout2(self.norm2(forward + x)) return out class ChatGPT(nn.Module): def __init__(self, embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout): super(ChatGPT, self).__init__() self.embed_size = embed_size self.word_embedding = nn.Embedding(vocab_size, embed_size) self.position_embedding = nn.Embedding(max_length, embed_size) self.transformer_blocks = nn.ModuleList( [TransformerBlock(embed_size, num_heads, dropout, forward_expansion) for _ in range(num_layers)] ) self.fc_out = nn.Linear(embed_size, vocab_size) self.dropout = nn.Dropout(dropout) def forward(self, x): N, seq_length = x.shape positions = torch.arange(0, seq_length).expand(N, seq_length).to(x.device) out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) for transformer in self.transformer_blocks: out = transformer(out) out = self.fc_out(out) return out # 大型模型的模型超参数（类似于 GPT-3） embed_size = 12288 # 大型模型的嵌入大小 num_heads = 96 # 注意力头的数量 num_layers = 96 # 数量Transformer 块的数量 vocab_size = 50257 # 词汇表的大小（GPT-3 使用更大的词汇表） max_length = 2048 # 输入序列的最大长度 forward_expansion = 4 # 前馈层的扩展因子 dropout = 0.1 # 丢失率 # 初始化模型 model_0 = ChatGPT(embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout)  ```     submitted by    /u/Budget-Relief1307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</guid>
      <pubDate>Wed, 30 Oct 2024 15:41:01 GMT</pubDate>
    </item>
    <item>
      <title>🌟 游戏开发的人工智能：改变游戏世界的未来！🌟</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</link>
      <description><![CDATA[正在寻找加速角色、位置和纹理创建的方法？想看看 AI 如何加速开发并激发新想法吗？ 🎮 欢迎参加 AI 重塑游戏开发的演示！使用 ControlNet、ChatGPT、Stable Diffusion 等示例，我将展示人工智能如何显著增强和优化游戏创作过程。 🚀 您会发现什么？ - 如何使用 AI 在几秒钟内创建姿势和场景 - 轻松为特定项目训练模型 - 将手绘与神经网络集成的示例 不要错过获得灵感并从全新视角看待游戏开发的机会！ 👉 观看演示    提交人    /u/Bozhenart   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</guid>
      <pubDate>Tue, 29 Oct 2024 14:34:21 GMT</pubDate>
    </item>
    <item>
      <title>机器学习与知识的集成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</guid>
      <pubDate>Tue, 29 Oct 2024 03:29:55 GMT</pubDate>
    </item>
    <item>
      <title>FSF 致力于实现机器学习应用的自由</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</guid>
      <pubDate>Mon, 28 Oct 2024 14:25:38 GMT</pubDate>
    </item>
    <item>
      <title>组合 DQN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ge11g0/combining_dqns/</link>
      <description><![CDATA[将 3 个 DQN 组合成一个 DQN 的最佳方法是什么。每个 DQN 都有类似的参数，就像它们在不同的任务上工作但仍然相似。例如，假设我们有一个有敌人和状态的游戏。首先，您可以使用 3 个动作。 1) 使用剑 2) 使用弓 3) 使用魔法 如果您使用剑，您可以使用 2 种不同的动作，如轻攻击或重攻击。如果您使用弓，您可以用它击中敌人的近战，或者使用箭（如果有）等。 我不想创建一个可以决定第一个动作（将使用什么样的武器）的 DQN，然后为每种武器决定将采取什么样的动作，而是想为每种武器创建一个 DQN，它确切知道如何使用一种武器，然后将它们组合成 1。最终的网络应该从状态中了解将使用哪种武器以及这些武器将采取什么动作。    提交人    /u/volvol7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ge11g0/combining_dqns/</guid>
      <pubDate>Mon, 28 Oct 2024 12:42:23 GMT</pubDate>
    </item>
    <item>
      <title>寻求针对 CVPR、ICML 等会议正在进行的完整论文的合作。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gd64zq/looking_for_collaborations_on_ongoing/</link>
      <description><![CDATA[大家好， 我们小组，印度理工学院鲁尔基分校视觉与语言小组，最近有三篇研讨会论文被 NeurIPS 研讨会接受！🚀 我们还建立了一个网站 👉 VLG，展示我们参与过的其他出版物，因此我们的团队正在稳步建立 ML 和 AI 研究组合。目前，我们正在合作撰写几篇正在进行的论文，目的是向 CVPR 和 ICML 等顶级会议提交全文。 话虽如此，我们还有更多让我们兴奋的想法。尽管如此，我们的主要限制之一是无法获得适当的指导和 GPU 和 API 的资金，这对于试验和扩展我们的一些概念至关重要。如果您或您的实验室有兴趣一起工作，我们很乐意探索我们感兴趣领域的交集以及您可能带来的任何新想法！ 如果您有可用资源或有兴趣讨论潜在的合作，请随时联系我们！期待着建立联系并共同建立有影响力的东西！这是我们的 Open Slack 的链接👉 Open Slack    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gd64zq/looking_for_collaborations_on_ongoing/</guid>
      <pubDate>Sun, 27 Oct 2024 08:09:34 GMT</pubDate>
    </item>
    <item>
      <title>你们用什么椅子来编码？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gc78dz/what_chairs_are_you_guys_using_to_code_with/</link>
      <description><![CDATA[我需要一把椅子放在我的办公桌上。你对哪些椅子感到满意？    由   提交  /u/EleTriCTNT   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gc78dz/what_chairs_are_you_guys_using_to_code_with/</guid>
      <pubDate>Fri, 25 Oct 2024 23:01:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使其具有适应性？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gb7sus/neural_networks_making_it_adaptive/</link>
      <description><![CDATA[ 我目前是一名学习 ANN 概念的初学者，有人可以为我的新研究提供意见吗？ 键的形成：  形成标准：如果它导致损失函数显着减少（提高性能），则两个神经元之间会形成新的连接。 实施：定期评估当前未连接的神经元之间的潜在连接。如果在神经元 iii 和神经元 jjj 之间添加连接使损失降低超过阈值 ϵadd\epsilon_{\text{add}}ϵadd​，则我们添加该连接。  键断裂：  断裂标准：如果现有连接对网络性能贡献不大，或者移除它不会显著增加损失函数，则将其移除。 实施：监控现有连接的权重。如果权重 wijw_{ij}wij​ 的绝对值低于阈值 ϵremove\epsilon_{\text{remove}}ϵremove​，或者连接对性能的贡献很小，则我们移除该连接。      提交人    /u/South-Ad-1977   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gb7sus/neural_networks_making_it_adaptive/</guid>
      <pubDate>Thu, 24 Oct 2024 17:10:31 GMT</pubDate>
    </item>
    </channel>
</rss>