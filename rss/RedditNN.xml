<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络、深度学习和机器学习的 Reddit 子版块。</description>
    <lastBuildDate>Tue, 20 Feb 2024 18:18:21 GMT</lastBuildDate>
    <item>
      <title>使用在 msnit 数据集上训练的神经网络无法识别自己的数字</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1avjpj8/having_trouble_recognizing_my_own_digits_with_a/</link>
      <description><![CDATA[我真的不明白我做错了什么，我的图像与 Mnist 数据集中的图像具有相同的形状（28,28），当我用 plt.imshow(img_flat) plt.show() 显示它们，它们看起来完全一样，但从几天开始我就无法弄清楚为什么我的图像无法识别，数据集中的图像...我做了一个 YT 教程，但完全相同的代码对我不起作用... #My own data model = tf.keras.models.load_model(“手写.model”)  img = cv2.imread(“Digits/digit11.png”) grey = cv2.cvtColor(img, cv2 .COLOR_BGR2GRAY) # grey = tf.keras.utils.normalize(gray, axis=1) img_flat = grey.reshape(28, 28) # 形式 (1, 784) 预测= model.predict(np.expand_dims(img_flat, axis=0)) print(f&quot;这个数字可能是 {np.argmax(prediction)}&quot;)  #MNIST Data  Prediction = model.predict(np.expand_dims(x_train[27], axis=0)) print(f&quot;这个数字可能是 {np.argmax(prediction)}&quot;) /&gt; 这是我的代码，mnsit 中的所有数字都可以完美识别... 非常感谢任何帮助...    ;由   提交/u/xXSavardoXx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1avjpj8/having_trouble_recognizing_my_own_digits_with_a/</guid>
      <pubDate>Tue, 20 Feb 2024 15:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用带有 kmeans 的句子嵌入模型逐渐增加 CPU 负载</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1avcvsf/gradually_increasing_cpu_load_on_using_sentence/</link>
      <description><![CDATA[我有一个基于 ML 的生产应用程序，使用 Flask，使用 Gunicorn Workers 部署在 GCP 服务器上。在每个传入请求中，都会收到一个文本句子。 它使用句子转换器（All-MiniLM-L6-v2 模型），该模型会全局加载一次，以创建嵌入传入文本，然后使用预先训练的 kmeans（也全局加载）来预测/将其映射到意图集群。基本上，目标是找到句子的意图。 我有足够的资源，请求的数量也恒定，文本也相似，但每天CPU负载都在逐渐增加。第一天的平均响应时间约为 200 毫秒，10 天后现在为 400 毫秒。 我尝试在代码本身中使用“del”命令删除嵌入变量，同时还强制 python 垃圾收集器在主进程执行完成后执行的线程中使用“gc.collect()”，但问题仍然出现。 我注意到的一件事是，如果我不使用 del 和 gc。收集（）后，RAM开始逐渐下降。对于这两种情况，RAM 是恒定的，但现在 CPU 使用率每天都在逐渐增加，因此负载和响应时间也随之增加。 我花了数周的时间在这个问题上尝试调试它，但没有找到解决方案，如有任何帮助，我们将不胜感激。   由   提交/u/Devinco001  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1avcvsf/gradually_increasing_cpu_load_on_using_sentence/</guid>
      <pubDate>Tue, 20 Feb 2024 08:34:56 GMT</pubDate>
    </item>
    <item>
      <title>二值化神经网络简介</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1auncw7/intro_to_binarized_neural_networks/</link>
      <description><![CDATA[       由   提交/u/Neurosymbolic  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1auncw7/intro_to_binarized_neural_networks/</guid>
      <pubDate>Mon, 19 Feb 2024 13:31:48 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可训练性的边界是分形的</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aulcsw/the_boundary_of_neural_network_trainability_is/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aulcsw/the_boundary_of_neural_network_trainability_is/</guid>
      <pubDate>Mon, 19 Feb 2024 11:41:43 GMT</pubDate>
    </item>
    <item>
      <title>越狱：LLM安全培训为何失败？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1at6o51/jailbroken_how_does_llm_safety_training_fail/</link>
      <description><![CDATA[       由   提交/u/Personal-Trainer-541   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1at6o51/jailbroken_how_does_llm_safety_training_fail/</guid>
      <pubDate>Sat, 17 Feb 2024 17:04:32 GMT</pubDate>
    </item>
    <item>
      <title>关于手写数字识别神经网络的问题</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1asziad/questions_about_hand_write_digit_recognition/</link>
      <description><![CDATA[所以我阅读并观看了一些关于创建手写数字识别神经网络的 YouTube 视频，但我在实现它时仍然遇到一些麻烦，我正在使用纯c++ 没有任何库（我可能使用专用矩阵库）。因此，假设我有一个 64x64 px 灰度位图，缩放比例为 0 到 1，根据我从观看和阅读的文章和 YouTube 视频中了解到的情况，我想首先将位图切割成更小的块，例如 4px x 4px 并得到该区域的加权和（如果像素的位置有不同的权重和值）（隐藏层 1）并传递到隐藏层 2，隐藏层 2 将通过隐藏层的权重和来确定它是曲线还是直线1 画一条直线或一条曲线，然后最终确定从 0 到 1 的值，并相应地调整权重和偏差（这也是神经网络学习的另一个词）。我是人工智能和神经网络的新手，所以我不知道我的概念是否在正确的轨道上，所以如果我犯了任何错误，请纠正我，谢谢。我的另一个问题是，图像识别是否使用类似的系统，但添加了图像 DNA 来加快处理速度并使其更加准确？   由   提交 /u/GateCodeMark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1asziad/questions_about_hand_write_digit_recognition/</guid>
      <pubDate>Sat, 17 Feb 2024 11:04:13 GMT</pubDate>
    </item>
    <item>
      <title>在中国，RTX 2080 Ti经过修改，将神经网络内存增加到22 GB</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aspb45/in_china_the_rtx_2080_ti_was_modified_by/</link>
      <description><![CDATA[       由   提交/u/One-Procedure-466   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aspb45/in_china_the_rtx_2080_ti_was_modified_by/</guid>
      <pubDate>Sat, 17 Feb 2024 01:10:37 GMT</pubDate>
    </item>
    <item>
      <title>这学期我正在写关于“定量金融中的神经网络”的学士论文。有人对我的研究主题应该是什么有建议吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1asmms4/im_writing_my_bachelor_thesis_on_neural_networks/</link>
      <description><![CDATA[ 由   提交 /u/Plane-Blacksmith-877   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1asmms4/im_writing_my_bachelor_thesis_on_neural_networks/</guid>
      <pubDate>Fri, 16 Feb 2024 23:12:30 GMT</pubDate>
    </item>
    <item>
      <title>通过细粒度奖励训练语言模型以生成带有引文的文本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ask6qx/training_language_models_to_generate_text_with/</link>
      <description><![CDATA[ 由   提交/u/nickb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ask6qx/training_language_models_to_generate_text_with/</guid>
      <pubDate>Fri, 16 Feb 2024 21:29:59 GMT</pubDate>
    </item>
    <item>
      <title>纯Python中的神经网络库</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1asgn6m/neural_network_lib_in_pure_python/</link>
      <description><![CDATA[大家好。有人可以建议我一个用纯 python 编写的神经网络库吗？我需要一个简单的库，主要用于语言处理，它是出于教育目的，所以我不太关心性能和可扩展性。 我不想要张量流，因为它太大了。 2. 用 C 语言编写，3. 取决于 CPU/GPU。我发现的所有替代方案都非常相似。另一方面，我不想自己编写梯度计算等，因此lib应该包含最常用的层等。   由   提交 /u/my-handicapped-pet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1asgn6m/neural_network_lib_in_pure_python/</guid>
      <pubDate>Fri, 16 Feb 2024 19:03:49 GMT</pubDate>
    </item>
    <item>
      <title>如何让照片看起来像画作</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1asbiw4/how_to_make_photos_look_like_paintings/</link>
      <description><![CDATA[      https://preview.redd.it/oetqx16svyic1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=71f82a02610e6629ffca65fb2c7660190d14c767 嗨，  🎨 发现将自己的照片变成美丽的画作是多么容易 🖼️ 这是基于风格化神经绘画库的很酷的效果。使用简单，结果令人印象深刻， 您可以在这里找到说明：https://github.com/feitgemel/Python-Code-Cool-Stuff/tree/master/How%20to%20make%20photos%20look%20like%20paintings  教程视频的链接：https://youtu.be/m1QhxOWeeRc 享受 Eran #convertphototodigitalart #makephotolooklikepainting #makephotoslooklikepaintings #makepicturelooklikepainting #convertphotointopainting #howtoturnphotosintopaintings  &amp;# 32；由   提交 /u/Feitgemel   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1asbiw4/how_to_make_photos_look_like_paintings/</guid>
      <pubDate>Fri, 16 Feb 2024 15:37:15 GMT</pubDate>
    </item>
    <item>
      <title>激活的三个十年：神经网络 400 个激活函数的综合调查</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1arov80/three_decades_of_activations_a_comprehensive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.09092 摘要：  神经网络已被证明是解决复杂问题的高效工具生活的许多方面都存在问题。最近，随着深度学习的出现，它们的重要性和实际可用性进一步得到加强。神经网络成功的重要条件之一是选择合适的激活函数，将非线性引入模型。过去的文献中已经提出了许多类型的这些函数，但没有一个综合来源包含它们的详尽概述。即使根据我们的经验，缺乏这种概述也会导致冗余和无意中重新发现已经存在的激活函数。为了弥补这一差距，我们的论文提出了一项涉及 400 个激活函数的广泛调查，其规模比以前的调查大几倍。我们的综合汇编也参考了这些调查；然而，其主要目标是提供先前发布的激活函数的最全面的概述和系统化，并提供其原始来源的链接。第二个目标是更新当前对这一系列函数的理解。    [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1arov80/three_decades_of_activations_a_comprehensive/</guid>
      <pubDate>Thu, 15 Feb 2024 20:11:36 GMT</pubDate>
    </item>
    <item>
      <title>引领未来：了解人工智能法案对产品公司的要求</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1arn0gu/navigating_the_future_understanding_the_ai_act/</link>
      <description><![CDATA[这个博客文章是关于《人工智能法案》要求的，专门为基于产品的企业设计。它介绍了应对人工智能监管环境的基本背景、可能的障碍和战略建议，帮助 OpenCV.ai 读者做好适应这些发展的准备。 在本文中，您将发现：   什么是《人工智能法案》？  主要目标  《人工智能法案》禁止什么？  行业影响 挑战 机遇  实现新的人工智能监管合规性 合规步骤 最佳实践   完整文章ia 此处 &lt; !-- SC_ON --&gt;  由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/neuralnetworks/comments/1arn0gu/navigating_the_future_understanding_the_ai_act/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1arn0gu/navigating_the_future_understanding_the_ai_act/</guid>
      <pubDate>Thu, 15 Feb 2024 18:55:08 GMT</pubDate>
    </item>
    <item>
      <title>深度学习如何使条码扫描受益</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1arehn0/how_does_dl_benefit_barcode_scanning/</link>
      <description><![CDATA[首先，我是 Scanbot SDK 团队的一员。话虽这么说，我想分享一篇关于条形码背景下的深度学习的文章。对于那些好奇如何使用深度学习来训练条形码扫描软件的人来说，这可能会很有用。 TL;DR：深度学习模型识别模式的能力使其成为条形码检测的完美工具，在传统计算机上进行了改进愿景逼近。深度学习提高了移动条码扫描在定位、识别和处理条码方面的性能。  全文链接   由   提交/u/Slight-Astronaut-737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1arehn0/how_does_dl_benefit_barcode_scanning/</guid>
      <pubDate>Thu, 15 Feb 2024 12:37:37 GMT</pubDate>
    </item>
    <item>
      <title>思想扩散：扩散语言模型中的思想链推理</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1aq579h/diffusion_of_thoughts_chainofthought_reasoning_in/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07754 代码：https ://github.com/HKUNLP/diffusion-of-thoughts 摘要：  扩散模型在以下领域获得了关注：文本处理，与传统自回归模型相比具有许多潜在优势。这项工作探索了扩散模型和思想链（CoT）的集成，这是一种完善的技术，可以提高自回归语言模型的推理能力。我们提出思想扩散 (DoT)，允许推理步骤通过扩散过程随着时间的推移而扩散。与以从左到右、逐个标记的方式做出决策的传统自回归语言模型相比，DoT 在计算和推理性能之间的权衡方面提供了更大的灵活性。我们的实验结果证明了 DoT 在多位数乘法和小学数学问题中的有效性。此外，DoT 还展示了有前景的自我纠正能力，以及自一致性解码等现有推理增强技术的优势。我们的研究结果有助于理解和发展扩散语言模型的推理能力。    [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1aq579h/diffusion_of_thoughts_chainofthought_reasoning_in/</guid>
      <pubDate>Tue, 13 Feb 2024 21:32:36 GMT</pubDate>
    </item>
    </channel>
</rss>