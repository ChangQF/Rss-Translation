<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Thu, 06 Feb 2025 15:17:58 GMT</lastBuildDate>
    <item>
      <title>通过柯西损失和最优传输进行稳健的潜在一致性训练</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</link>
      <description><![CDATA[潜在一致性模型 (LCM) 的新训练方法修改了噪声计划，以实现更好的图像质量，同时保持了使 LCM 具有吸引力的快速推理速度。关键创新是在训练期间引入额外的中间步骤，同时保留推理时的高效采样过程。 主要技术要点：- 修改后的噪声计划在训练期间包含更细粒度的步骤 - 动态加权方案调整不同噪声级别的重要性 - 优化的采样策略平衡质量和速度 - 无需架构更改或额外参数 - 保持原始的 4-8 步推理过程 结果：- 标准图像质量指标提高 15-20% - 更好地保留精细细节和纹理 - 与基线​​ LCM 相当的推理速度 - 提高了面部等复杂特征的性能 - 跨多个标准基准进行测试 我认为这种方法对于质量和速度都很重要的实际应用特别有价值。在推理时无需计算开销即可提高输出质量的能力表明我们可能会在生产系统中采用这种技术。该方法也可能适用于图像生成以外的其他类型的一致性模型。 我认为关键的限制是改进伴随着训练复杂性的增加。虽然推理仍然很快，但额外的训练步骤可能会使初始模型开发更加资源密集。 TLDR：潜在一致性模型的新训练技术在不减慢推理速度的情况下将图像质量提高了 15-20%，这是通过训练期间修改噪声调度而不是架构更改来实现的。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iiysw8/robust_latent_consistency_training_via_cauchy/</guid>
      <pubDate>Thu, 06 Feb 2025 09:36:26 GMT</pubDate>
    </item>
    <item>
      <title>实例特定负向挖掘用于改进分割任务中的视觉语言提示生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</link>
      <description><![CDATA[本文介绍了一种新的实例分割方法，该方法使用特定于实例的负挖掘来改进跨多个任务的基于提示的分割。核心思想是挖掘特定于每个实例的反面例子，以学习更好的判别特征。 关键技术点： - 采用两阶段架构：提示生成，然后进行反面挖掘 - 从同一图像中看起来相似的实例中挖掘硬反面例子 - 学习特定于实例的判别特征，无需特定任务的训练 - 与现有的主干网络（如 SAM 和 SEEM）集成 - 使用对比学习最大化正特征和负特征之间的分离 结果： - 在标准基准（COCO、ADE20K）上优于基线方法 - 无需重新训练即可跨多个任务工作 - 更好地处理相似实例和重叠对象 - 尽管增加了挖掘步骤，仍保持具有竞争力的推理速度 - 在基于提示的分割任务上实现 SOTA 我认为这种方法对于现实世界的应用可能非常有影响，因为我们需要能够处理多项任务的灵活分割系统。特定于实例的反面挖掘似乎是一种帮助模型学习更稳健特征的自然方法，尤其是在具有相似对象的情况下。事实上，它无需特定任务的训练就能工作，这对于部署场景来说尤其有趣。 我看到的主要限制是挖掘过程的计算开销，尽管作者报告说影响是可控的。我很好奇这如何扩展到具有许多相似物体的非常大的场景。 TLDR：使用特定于实例的负挖掘的新实例分割方法，可在没有特定于任务的训练的情况下提高多个任务的准确性。通过学习到的判别特征展示对相似对象的更好处理。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ii6oh9/instancespecific_negative_mining_for_improved/</guid>
      <pubDate>Wed, 05 Feb 2025 09:57:06 GMT</pubDate>
    </item>
    <item>
      <title>凸优化理论预测大型语言模型的最佳学习率计划</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ihgfao/convex_optimization_theory_predicts_optimal/</link>
      <description><![CDATA[这篇论文在经典凸优化理论和现代深度学习中使用的经验成功的学习率计划之间建立了关键联系。研究人员得出数学证明，表明余弦学习率衰减自然地从优化界限中出现。 主要技术要点： - 开发将经典优化与深度学习调度联系起来的理论框架 - 证明余弦衰减计划可以最小化凸问题的收敛界限 - 通过优化镜头显示线性预热具有理论依据 - 在 ImageNet、语言模型和其他标准基准上验证结果 - 使用理论上最优的计划发现最终模型性能提高了 10-15％ 我认为这项工作为主要通过反复试验开发出来的实践提供了宝贵的数学基础。虽然分析侧重于凸情况，但与经验结果的一致性表明这些见解可以很好地转移到深度学习中。这些证明可以帮助开发更好的自动调度方法。 我认为该框架可以扩展到分析其他训练组件，如动量和权重衰减。与经典优化理论的联系为利用数十年的理论工作开辟了可能性。 TLDR：研究证明，流行的学习率计划（余弦衰减、线性热身）在凸优化下在理论上是最优的，与经验发现相符。结果验证了当前的做法并为改进训练方法提供了基础。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ihgfao/convex_optimization_theory_predicts_optimal/</guid>
      <pubDate>Tue, 04 Feb 2025 12:22:37 GMT</pubDate>
    </item>
    <item>
      <title>超维计算 (HDC) 与 Peter Sutor 第 1 部分（访谈）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1igtag7/hyperdimensional_computing_hdc_with_peter_sutor/</link>
      <description><![CDATA[       由    /u/Neurosymbolic  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1igtag7/hyperdimensional_computing_hdc_with_peter_sutor/</guid>
      <pubDate>Mon, 03 Feb 2025 16:37:26 GMT</pubDate>
    </item>
    <item>
      <title>计算隐藏层的批量标准</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</link>
      <description><![CDATA[我试图了解对隐藏层执行批量规范的细节。我理解，对于给定的神经元，比如说 l 层中的 Xl，我们需要计算所有小批量样本的平均值和方差，以标准化其激活，然后再将其输入到下一层。 我想了解上述计算究竟是如何完成的。一种方法可能是处理小批量的每个元素并收集 l 层神经元的统计数据，并忽略后续层。一旦计算出 l 层中所有元素的平均值和方差，就再次处理 l+1 层的小批量元素，依此类推。这似乎相当浪费。这是正确的吗？ 如果不是，请分享正在执行的确切计算的描述。我感到困惑的根源是 l 层的标准化会影响进入 l+1 层的值。因此，除非我们知道 l 层的平均值和方差，否则我们如何标准化下一层。提前谢谢您。    由   提交  /u/Far-Cantaloupe4144   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1igiluz/calculating_batch_norm_for_hidden_layers/</guid>
      <pubDate>Mon, 03 Feb 2025 06:09:34 GMT</pubDate>
    </item>
    <item>
      <title>用于多啁啾参数估计的曲率引导朗之万蒙特卡罗方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</link>
      <description><![CDATA[本文介绍了一种使用曲率引导的朗之万蒙特卡罗 (CLMC) 估计多啁啾信号参数的新方法。关键创新是将参数空间的几何信息与随机采样相结合，以更好地处理重叠频率分量。 主要技术贡献：- 将曲率信息集成到朗之万蒙特卡罗框架中 - 基于局部几何特性的自适应步长机制 - 处理参数空间中多峰分布的新方法 - 引导采样的二阶信息的实现 结果表明：- 与标准方法相比，参数估计精度有所提高 - 在低 SNR 条件下性能更佳（最高可达 -5dB） - 更可靠地分离紧密间隔的频率分量 - 与传统 LMC 相比收敛速度更快 - 成功处理多达 4 个重叠的啁啾分量 我认为这项工作为雷达和声纳等精确频率分析至关重要的应用开辟了新的可能性。更好地分离重叠组件的能力对于无线通信和医学成像应用尤其有价值，因为信号清晰度至关重要。 我认为主要的限制是计算复杂度随组件数量的增加而扩大，这可能会限制实时应用。该方法还需要仔细调整参数，这可能会使实际部署具有挑战性。 TLDR：新方法将曲率信息与朗之万蒙特卡罗相结合，以获得更好的多啁啾参数估计，在处理重叠频率分量时显示出更高的准确性和稳健性。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ig6dha/curvatureguided_langevin_monte_carlo_for/</guid>
      <pubDate>Sun, 02 Feb 2025 20:11:28 GMT</pubDate>
    </item>
    <item>
      <title>Elman 网络 - 你能解释一下它们是什么以及它们如何工作吗？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</link>
      <description><![CDATA[  由    /u/No_Refrigerator_7841  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifhrkp/elman_networks_can_you_explain_what_they_are_and/</guid>
      <pubDate>Sat, 01 Feb 2025 22:08:02 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 由 1 亿个感知器组成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</link>
      <description><![CDATA[        由    /u/keghn 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ifg22m/chatgpt_is_made_from_100_million_of_these_the/</guid>
      <pubDate>Sat, 01 Feb 2025 20:51:43 GMT</pubDate>
    </item>
    <item>
      <title>让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 支持的公司的创始人，我们正在尝试让训练 ML 模型变得非常容易和便宜。在接下来的 2 周内，我们将运行 *免费* 测试版，并希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看我们：https://github.com/tensorpool/tensorpool TLDR；免费 GPU 😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iffhll/giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Sat, 01 Feb 2025 20:26:06 GMT</pubDate>
    </item>
    <item>
      <title>建立文本到图像扩散模型以实现受控的高质量图像生成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</link>
      <description><![CDATA[本文提出了 ObjectDiffusion，该模型以对象名称和边界框为条件对文本到图像的扩散模型进行条件设定，以实现对对象在特定位置的精确渲染和放置。 ObjectDiffusion 将 ControlNet 的架构与 GLIGEN 的基础技术相结合，显著提高了受控图像生成的精度和质量。 所提出的模型优于目前在开源数据集上训练的最先进的模型，在精度和质量指标上取得了显着的提升。 ObjectDiffusion 可以合成多样化、高质量、高保真度的图像，并与指定的控制布局保持一致。 论文链接：https://www.arxiv.org/abs/2501.09194    由   提交  /u/Next_Cockroach_2615   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1id9buv/grounding_texttoimage_diffusion_models_for/</guid>
      <pubDate>Thu, 30 Jan 2025 00:30:50 GMT</pubDate>
    </item>
    <item>
      <title>我需要为我的项目标记你的数据</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iccmca/i_need_to_label_your_data_for_my_project/</link>
      <description><![CDATA[您好！ 我正在开展一个涉及机器学习的私人项目，具体涉及数据标记领域。 目前，我的团队正在接受标记方面的培训，需要接触真实数据集，以了解标记真实数据所面临的挑战和细微差别。 我们正在寻找拥有需要标记的数据集的人员或项目，以便我们进行合作。我们将标记您的数据，我们唯一的要求就是在我们完成标记过程后，请您填写一份简单的反馈表。 您可以成为公司的一员，从事个人项目，或参与任何计划 — 真的，任何事情都可以。我们所需要的只是需要标记的数据。 如果您有数据集（文本、图像、音频、视频或任何其他类型的数据）或认识有数据集的人，请随时给我发送 DM，以便我们讨论细节    提交人    /u/rafacvs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iccmca/i_need_to_label_your_data_for_my_project/</guid>
      <pubDate>Tue, 28 Jan 2025 21:18:27 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我刚刚做了一些工作，制作了一个推荐系统，使用知识感知耦合图神经网络和变换器，如果有人可以帮助我，请给我留言，我有一些参考，但需要帮助理解它们</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ibzjmc/hi_guys_i_just_did_some_work_on_making_a/</link>
      <description><![CDATA[  由    /u/Busy_Low_1903  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ibzjmc/hi_guys_i_just_did_some_work_on_making_a/</guid>
      <pubDate>Tue, 28 Jan 2025 11:32:39 GMT</pubDate>
    </item>
    <item>
      <title>免费的深度学习初学者课程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ibuz0b/free_beginner_course_to_get_into_deep_learning/</link>
      <description><![CDATA[大家好！ 嘿，我刚刚开始写一份时事通讯，希望它能帮助人们了解深度学习的基础知识，并澄清一些我在学习过程中发现很难理解的事情。我在每个方面都花了不少时间，所以如果有人想从基础开始，我想在这里分享一下。 https://www.linkedin.com/newsletters/neural-notes-understanding-ai-7282889158631534592/    提交人    /u/BeautifulBitter7188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ibuz0b/free_beginner_course_to_get_into_deep_learning/</guid>
      <pubDate>Tue, 28 Jan 2025 05:55:36 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我开始学习 CNN，我想制作一个模型来去除这些黑点，还可以构建损坏的文本。现在我有 70 张这样的图片，我已经用 photoshop 清理了它们。如果有人能给我一些关于如何开始的指导。谢谢</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ib61cb/hello_guys_so_i_started_learning_cnn_and_i_want/</link>
      <description><![CDATA[        提交人    /u/Sure_Recipe_2143   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ib61cb/hello_guys_so_i_started_learning_cnn_and_i_want/</guid>
      <pubDate>Mon, 27 Jan 2025 11:03:38 GMT</pubDate>
    </item>
    <item>
      <title>将 XGBoost 与 Pytorch 结合起来。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1iad01o/combining_xgboost_with_pytorch/</link>
      <description><![CDATA[我一直在尝试将 XGBoost 和 PyTorch 结合起来，看看它们如何相互补充。我们的想法是使用 XGBoost 的预测并将其输出输入 PyTorch 进行深度学习，从而创建一种混合模型。结果非常有趣——似乎这种方法在某些情况下确实可以提高性能。  想知道是否有其他人尝试过类似的东西或对这个组合有见解？很想听听您的想法或建议！  https://machinelearningsite.com/machine-learning-using-xgboost/    提交人    /u/kolbenkraft   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1iad01o/combining_xgboost_with_pytorch/</guid>
      <pubDate>Sun, 26 Jan 2025 12:11:48 GMT</pubDate>
    </item>
    </channel>
</rss>