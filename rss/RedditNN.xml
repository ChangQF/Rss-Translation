<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Sat, 02 Nov 2024 01:14:40 GMT</lastBuildDate>
    <item>
      <title>神经网络中的偏差</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</link>
      <description><![CDATA[大家好，我最近开始研究神经网络。让我有些困惑的概念是偏差。我理解偏差在神经网络中的用途，但我仍然不明白两件事：  各个隐藏层中的每个单元是否都有自己的偏差，或者每个隐藏层的所有单元是否有共同的偏差？ 我不明白为什么在某些情况下偏差通过一个单元来表示，并附加自己的权重。它不应该是一个参数，因此不应该作为一个单元出现吗？     提交人    /u/Annual_Inflation_235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ggctva/bias_in_nn/</guid>
      <pubDate>Thu, 31 Oct 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>运行此代码需要多少普通内存</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</link>
      <description><![CDATA[import torch 导入 torch.nn 作为 nn class TransformerBlock(nn.Module): def __init__(self, embed_size, heads, dropout, forward_expansion): super(TransformerBlock, self).__init__() self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads) self.norm1 = nn.LayerNorm(embed_size) self.norm2 = nn.LayerNorm(embed_size) self.feed_forward = nn.Sequential( nn.Linear(embed_size, forward_expansion * embed_size), nn.ReLU(), nn.Linear(forward_expansion * embed_size, embed_size) ) self.dropout1 = nn.Dropout(dropout) self.dropout2 = nn.Dropout(dropout) def forward(self, x):tention = self.attention(x, x, x)[0] x = self.dropout1(self.norm1(attention + x)) forward = self.feed_forward(x) out = self.dropout2(self.norm2(forward + x)) return out class ChatGPT(nn.Module): def __init__(self, embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout): super(ChatGPT, self).__init__() self.embed_size = embed_size self.word_embedding = nn.Embedding(vocab_size, embed_size) self.position_embedding = nn.Embedding(max_length, embed_size) self.transformer_blocks = nn.ModuleList( [TransformerBlock(embed_size, num_heads, dropout, forward_expansion) for _ in range(num_layers)] ) self.fc_out = nn.Linear(embed_size, vocab_size) self.dropout = nn.Dropout(dropout) def forward(self, x): N, seq_length = x.shape positions = torch.arange(0, seq_length).expand(N, seq_length).to(x.device) out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) for transformer in self.transformer_blocks: out = transformer(out) out = self.fc_out(out) return out # 大型模型的模型超参数（类似于 GPT-3） embed_size = 12288 # 大型模型的嵌入大小 num_heads = 96 # 注意力头的数量 num_layers = 96 # 数量Transformer 块的数量 vocab_size = 50257 # 词汇表的大小（GPT-3 使用更大的词汇表） max_length = 2048 # 输入序列的最大长度 forward_expansion = 4 # 前馈层的扩展因子 dropout = 0.1 # 丢失率 # 初始化模型 model_0 = ChatGPT(embed_size, num_heads, num_layers, vocab_size, max_length, forward_expansion, dropout)  ```     submitted by    /u/Budget-Relief1307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gfpjyx/how_much_normal_ram_would_i_need_to_just_run_this/</guid>
      <pubDate>Wed, 30 Oct 2024 15:41:01 GMT</pubDate>
    </item>
    <item>
      <title>🌟 游戏开发的人工智能：改变游戏世界的未来！🌟</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</link>
      <description><![CDATA[正在寻找加速角色、位置和纹理创建的方法？想看看 AI 如何加速开发并激发新想法吗？ 🎮 欢迎参加 AI 重塑游戏开发的演示！使用 ControlNet、ChatGPT、Stable Diffusion 等示例，我将展示人工智能如何显著增强和优化游戏创作过程。 🚀 您会发现什么？ - 如何使用 AI 在几秒钟内创建姿势和场景 - 轻松为特定项目训练模型 - 将手绘与神经网络集成的示例 不要错过获得灵感并从全新视角看待游戏开发的机会！ 👉 观看演示    提交人    /u/Bozhenart   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gew3ly/ai_for_game_development_transforming_the_future/</guid>
      <pubDate>Tue, 29 Oct 2024 14:34:21 GMT</pubDate>
    </item>
    <item>
      <title>机器学习与知识的集成</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1geleye/machine_learning_integration_with_knowledge/</guid>
      <pubDate>Tue, 29 Oct 2024 03:29:55 GMT</pubDate>
    </item>
    <item>
      <title>FSF 致力于实现机器学习应用的自由</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ge3cqh/fsf_is_working_on_freedom_in_machine_learning/</guid>
      <pubDate>Mon, 28 Oct 2024 14:25:38 GMT</pubDate>
    </item>
    <item>
      <title>组合 DQN</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1ge11g0/combining_dqns/</link>
      <description><![CDATA[将 3 个 DQN 组合成一个 DQN 的最佳方法是什么。每个 DQN 都有类似的参数，就像它们在不同的任务上工作但仍然相似。例如，假设我们有一个有敌人和状态的游戏。首先，您可以使用 3 个动作。 1) 使用剑 2) 使用弓 3) 使用魔法 如果您使用剑，您可以使用 2 种不同的动作，如轻攻击或重攻击。如果您使用弓，您可以用它击中敌人的近战，或者使用箭（如果有）等。 我不想创建一个可以决定第一个动作（将使用什么样的武器）的 DQN，然后为每种武器决定将采取什么样的动作，而是想为每种武器创建一个 DQN，它确切知道如何使用一种武器，然后将它们组合成 1。最终的网络应该从状态中了解将使用哪种武器以及这些武器将采取什么动作。    提交人    /u/volvol7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1ge11g0/combining_dqns/</guid>
      <pubDate>Mon, 28 Oct 2024 12:42:23 GMT</pubDate>
    </item>
    <item>
      <title>寻求针对 CVPR、ICML 等会议正在进行的完整论文的合作。</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gd64zq/looking_for_collaborations_on_ongoing/</link>
      <description><![CDATA[大家好， 我们小组，印度理工学院鲁尔基分校视觉与语言小组，最近有三篇研讨会论文被 NeurIPS 研讨会接受！🚀 我们还建立了一个网站 👉 VLG，展示我们参与过的其他出版物，因此我们的团队正在稳步建立 ML 和 AI 研究组合。目前，我们正在合作撰写几篇正在进行的论文，目的是向 CVPR 和 ICML 等顶级会议提交全文。 话虽如此，我们还有更多让我们兴奋的想法。尽管如此，我们的主要限制之一是无法获得适当的指导和 GPU 和 API 的资金，这对于试验和扩展我们的一些概念至关重要。如果您或您的实验室有兴趣一起工作，我们很乐意探索我们感兴趣领域的交集以及您可能带来的任何新想法！ 如果您有可用资源或有兴趣讨论潜在的合作，请随时联系我们！期待着建立联系并共同建立有影响力的东西！这是我们的 Open Slack 的链接👉 Open Slack    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gd64zq/looking_for_collaborations_on_ongoing/</guid>
      <pubDate>Sun, 27 Oct 2024 08:09:34 GMT</pubDate>
    </item>
    <item>
      <title>你们用什么椅子来编码？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gc78dz/what_chairs_are_you_guys_using_to_code_with/</link>
      <description><![CDATA[我需要一把椅子放在我的办公桌上。你对哪些椅子感到满意？    由   提交  /u/EleTriCTNT   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gc78dz/what_chairs_are_you_guys_using_to_code_with/</guid>
      <pubDate>Fri, 25 Oct 2024 23:01:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使其具有适应性？</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gb7sus/neural_networks_making_it_adaptive/</link>
      <description><![CDATA[ 我目前是一名学习 ANN 概念的初学者，有人可以为我的新研究提供意见吗？ 键的形成：  形成标准：如果它导致损失函数显着减少（提高性能），则两个神经元之间会形成新的连接。 实施：定期评估当前未连接的神经元之间的潜在连接。如果在神经元 iii 和神经元 jjj 之间添加连接使损失降低超过阈值 ϵadd\epsilon_{\text{add}}ϵadd​，则我们添加该连接。  键断裂：  断裂标准：如果现有连接对网络性能贡献不大，或者移除它不会显著增加损失函数，则将其移除。 实施：监控现有连接的权重。如果权重 wijw_{ij}wij​ 的绝对值低于阈值 ϵremove\epsilon_{\text{remove}}ϵremove​，或者连接对性能的贡献很小，则我们移除该连接。      提交人    /u/South-Ad-1977   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gb7sus/neural_networks_making_it_adaptive/</guid>
      <pubDate>Thu, 24 Oct 2024 17:10:31 GMT</pubDate>
    </item>
    <item>
      <title>请给我推荐一门课程，让我可以学习如何用特定语言训练由聚合参数组成的神经网络......</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1gb11h3/please_suggest_me_a_course_that_i_can_follow_to/</link>
      <description><![CDATA[大家好。 我认为现在是时候开始研究神经网络如何帮助系统管理员了，具体来说就是 FreeBSD 系统管理员，因为我喜欢使用 FreeBSD 胜过任何其他操作系统；比 Linux 更喜欢。但这不是重点。 基本上，我想尝试使用一组 bhyve 命令来训练神经网络，以便它能够预测和理解您想要从输入文本中执行的操作。我从小就喜欢虚拟化。我非常喜欢 bhyve。 在这 3 年的努力中，我尝试学习如何管理 FreeBSD，在 bhyve 上花费了大量时间。 了解 bhyve 是让我使用 FreeBSD 的第一个原因。我也很想研究深度学习和神经网络，因为我认为在不久的将来，这些技术将在较低水平上集成到操作系统中.... 话虽如此，我希望您能为我指明正确的方向，因为我想学习如何使用 bhyve 管理程序所需的特殊语言来训练神经网络，以便网络可以预测用户想要做什么，他/她想要“给” bhyve 哪些 bhyve 命令和参数。 非常感谢。    提交人    /u/loziomario   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1gb11h3/please_suggest_me_a_course_that_i_can_follow_to/</guid>
      <pubDate>Thu, 24 Oct 2024 12:06:39 GMT</pubDate>
    </item>
    <item>
      <title>为 VQA 推导场景图中的域关系</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1g9gzgo/abducing_domain_relationships_in_scene_graphs_for/</link>
      <description><![CDATA[        提交人    /u/Neurosymbolic   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1g9gzgo/abducing_domain_relationships_in_scene_graphs_for/</guid>
      <pubDate>Tue, 22 Oct 2024 12:31:42 GMT</pubDate>
    </item>
    <item>
      <title>数据清理：清理 ML 数据集的 9 种方法</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1g9cdwz/data_cleaning_9_ways_to_clean_your_ml_datasets/</link>
      <description><![CDATA[       由    /u/codingdecently  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1g9cdwz/data_cleaning_9_ways_to_clean_your_ml_datasets/</guid>
      <pubDate>Tue, 22 Oct 2024 07:20:21 GMT</pubDate>
    </item>
    <item>
      <title>解释基本文本分类神经网络背后的理论（构建垃圾邮件检测器）</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1g8t5tt/theory_behind_basic_text_classification_neural/</link>
      <description><![CDATA[        由    /u/maksyche  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1g8t5tt/theory_behind_basic_text_classification_neural/</guid>
      <pubDate>Mon, 21 Oct 2024 15:58:00 GMT</pubDate>
    </item>
    <item>
      <title>MSE 帮助</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1g8hrrv/mse_help/</link>
      <description><![CDATA[大家好，我刚刚用 C++ 开发了一个基本的神经网络，我使用均方误差来计算多个训练示例的成本。当找到成本相对于输出节点值的导数时，我注意到如果代入平均成本，导数将始终为正，所以我想知道 NN 如何知道将权重推向哪个方向。我可以让网络匹配一个训练示例，但是只要我添加 2 个，输出就会明显偏离。抱歉，这是一个愚蠢的问题，因为我对此很陌生，对微积分了解不多。谢谢！    提交人    /u/williiiifff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1g8hrrv/mse_help/</guid>
      <pubDate>Mon, 21 Oct 2024 04:42:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 和 OpenCV 轻松检测硬币</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1g86vmw/easy_coin_detection_with_python_and_opencv/</link>
      <description><![CDATA[      https://preview.redd.it/cjusqueiqyvd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=853c718f2f0a7ea0f13d421342572d724ed05bce 如何使用 Python 和 OpenCV 检测和计算图像中的硬币？   在本教程中，我们将引导您逐步使用图像处理技术识别图像中的硬币，按大小对硬币进行排序，并标记每个硬币硬币和相应数字。   我们首先将图像转换为灰度，然后应用模糊以帮助滤除噪音。 然后，我们将使用 Canny 函数检测边缘并找到每枚硬币周围的轮廓。   对检测到的区域进行排序后，我们将循环遍历每个区域并在其周围或内部显示一个圆圈。   本教程基于 Python 和 OpenCV。    您可以在我的博客文章页面中找到更多类似的教程：https://eranfeit.net/blog/   在此处查看我们的视频：https://youtu.be/_Coth4YESzk&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg     享受， Eran    提交人    /u/Feitgemel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1g86vmw/easy_coin_detection_with_python_and_opencv/</guid>
      <pubDate>Sun, 20 Oct 2024 19:30:13 GMT</pubDate>
    </item>
    </channel>
</rss>