<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>神经网络、深度学习和机器学习</title>
    <link>https://www.reddit.com/r/neuralnetworks/?format=xml.rss</link>
    <description>关于人工神经网络，深度学习和机器学习的子版块。</description>
    <lastBuildDate>Thu, 23 Jan 2025 12:32:22 GMT</lastBuildDate>
    <item>
      <title>关于项目查询</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</link>
      <description><![CDATA[目前，我正在研究 zenodo 中一个名为“超声图像中胎儿头部生物测量的大规模注释数据集”的数据集。我的数据集包含超声图像和相应的分割掩模。我叠加了这些图像，现在我想计算头围、双顶径等，并使用这 20 个特征进行相关性分析。但不幸的是，我没有任何领域专家。在这种情况下，如果我以 Q1 期刊为目标，我该做些什么来验证？我的数据集没有任何现有的工作！有人可以帮忙吗？    提交人    /u/Boring_Conclusion_19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i54r74/regarding_a_project_query/</guid>
      <pubDate>Sun, 19 Jan 2025 18:09:43 GMT</pubDate>
    </item>
    <item>
      <title>大规模 AI 红队行动的实践经验和威胁模型</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</link>
      <description><![CDATA[本文对红队 100 种生成式 AI 产品进行了系统分析，开发了全面的威胁模型分类和测试方法。关键技术贡献是创建了一个通过实际测试识别和分类人工智能系统漏洞的结构化框架。 主要技术要点： - 开发了一个涵盖提示注入、数据提取和系统操作的攻击分类法 - 创建了结合自动和手动探测的标准化测试程序 - 记录不同人工智能架构中的攻击模式和防御机制 - 量化跨系统类型各种攻击媒介的成功率 - 映射常见的漏洞模式和防御效果 关键结果： - 80% 的测试系统显示出至少一种形式的提示注入的漏洞 - 多步骤攻击比单步骤攻击更为成功 - 系统对相同攻击的响应根据提示构造而有很大差异 - 手动测试发现的漏洞比自动化方法多 2.3 倍 - 结合多种攻击媒介时防御效果降低了 35% 我认为这项工作为理解大规模人工智能系统漏洞提供了重要基础。虽然之前已经进行过单独的红队测试，但拥有 100 个系统的数据使我们能够识别在小型研究中无法发现的系统弱点和模式。 我认为该方法可以成为 AI 安全测试的标准框架，尽管 AI 发展的快速步伐意味着特定的攻击媒介需要不断更新。关于手动测试有效性的发现表明我们不能仅仅依赖自动化安全措施。 TLDR：对 100 个 AI 系统的红队测试的分析揭示了常见的漏洞模式并建立了系统安全测试的框架。手动测试优于自动化方法，多向量攻击显示出更高的成功率。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i2q9dp/practical_lessons_and_threat_models_from/</guid>
      <pubDate>Thu, 16 Jan 2025 14:35:28 GMT</pubDate>
    </item>
    <item>
      <title>通过选择性权重矩阵更新实现动态 LLM 自适应：特定任务的自适应框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</link>
      <description><![CDATA[核心贡献是一种自适应学习机制，允许 Transformer 在推理过程中修改其权重，而无需额外训练。这种“Transformer²”方法引入了一种双重注意系统，可以同时处理内容和元学习模式。 关键技术点：- 在推理过程中使用梯度近似进行动态权重调整- 实现实时参数更新的元学习层- 结合标准和自适应自注意力的双重注意机制- 通过选择性权重更新实现高效的内存管理- 在生成特定于任务的适应性调整的同时保持基本权重 结果显示出显着的改进：- 在复杂推理基准上的性能提高了 15%- 更好地处理边缘情况和新输入- 最小的计算开销（标准 Transformer 的 1.2 倍）- 在不同任务类型中的响应更一致- 提高了长序列任务的性能 我认为这可以有意义地改变我们处理模型适应的方式。与微调或快速工程相比，拥有可以在推理过程中自我修改的模型为适应开辟了一些有趣的可能性。计算效率尤其值得注意——以前对自适应模型的尝试通常有很大的开销。 我还认为双重注意机制可能会影响我们设计未来 Transformer 架构的方式。同时处理内容和元学习模式的能力似乎是一种有价值的架构模式，可以更广泛地应用。 TLDR：新的 Transformer 架构可以使用高效的双重注意机制在推理过程中调整其权重。以最小的计算开销显示出 15% 的更好性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1xj3k/dynamic_llm_adaptation_through_selective_weight/</guid>
      <pubDate>Wed, 15 Jan 2025 13:36:40 GMT</pubDate>
    </item>
    <item>
      <title>热图像分类</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</link>
      <description><![CDATA[高中时我接到一个小任务 - 制作一个小型神经网络进行图像分类。我用 VGG 和小型数据库（大约 2k 张图像）制作了它。一切都很顺利，直到它（神经网络）开始对测试数据做出奇怪的预测。它说测试数据集中的每一张图片都与类别 0（即人类）相关......现在我被它困住了......如果有人能帮助我，我将不胜感激并提供任何有关我的 NN 的信息    提交人    /u/Apprehensive_Tap_269   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i1dcoq/image_classification_for_thermal_images/</guid>
      <pubDate>Tue, 14 Jan 2025 18:52:37 GMT</pubDate>
    </item>
    <item>
      <title>SimpleGrad：一个易于理解的类 pytorch 框架实现</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</link>
      <description><![CDATA[      我构建了一个简单易懂的类似 PyTorch 的框架，旨在作为一种学习工具，帮助理解自动求导和深度学习框架的内部工作原理。我计划将其扩展到 CNN 和 Attention 层。 我在 reddit 上发帖不多，如有任何问题，请多包涵。 – 非常感谢您的反馈和问题！    提交人    /u/T_Hansda   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1i0bnyl/simplegrad_a_easy_to_understand_implementation_of/</guid>
      <pubDate>Mon, 13 Jan 2025 11:10:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么 L1 正则化会产生稀疏权重</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</link>
      <description><![CDATA[        提交人    /u/Personal-Trainer-541   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hzj13d/why_l1_regularization_produces_sparse_weights/</guid>
      <pubDate>Sun, 12 Jan 2025 09:20:12 GMT</pubDate>
    </item>
    <item>
      <title>U-net 图像分割 | 如何分割图像中的人物</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</link>
      <description><![CDATA[      https://preview.redd.it/cuvm3dtoffce1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=c8e94c412194ba8c05f86c3bb6f675922ba956f8 本教程提供了如何使用 TensorFlow/Keras 实现和训练用于人员分割的 U-Net 模型的分步指南。 本教程分为四个部分：   第 1 部分：数据预处理和准备 在此部分中，您将加载和预处理人员数据集，包括调整图像和蒙版的大小、将蒙版转换为二进制格式以及将数据拆分为训练、验证和测试集。   第 2 部分：U-Net 模型架构 此部分使用 Keras 定义 U-Net 模型架构。它包括卷积层的构建块、构建 U-Net 的编码器和解码器部分以及定义最终输出层。   第 3 部分：模型训练 在这里，您将加载预处理的数据并训练 U-Net 模型。您编译模型，定义训练参数（如学习率和批量大小），并使用回调进行模型检查点、学习率降低和提前停止。   第 4 部分：模型评估和推理 最后一部分演示了如何加载训练好的模型，对测试数据进行推理，并可视化预测的分割蒙版。   您可以在博客中找到代码链接：https://eranfeit.net/u-net-image-segmentation-how-to-segment-persons-in-images/ Medium 用户的完整代码说明：https://medium.com/@feitgemel/u-net-image-segmentation-how-to-segment-persons-in-images-2fd282d1005a 您可以在这里找到更多教程，并加入我的时事通讯：https://eranfeit.net/ 在这里查看我们的教程： https://youtu.be/ZiGMTFle7bw&amp;list=UULFTiWJJhaH6BviSWKLJUM9sg   享受 Eran    由   提交  /u/Feitgemel   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hz5f3m/unet_image_segmentation_how_to_segment_persons_in/</guid>
      <pubDate>Sat, 11 Jan 2025 20:46:01 GMT</pubDate>
    </item>
    <item>
      <title>代理实验室：基于法学硕士的自主科学研究框架</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</link>
      <description><![CDATA[新框架引入了一种自动化研究流程，使用 LLM 代理在人工监督下开展科学研究。该系统实施了三个阶段的流程：文献综述、实验和报告撰写。 关键技术组件：* 具有针对不同研究任务的专门角色的分层代理结构 * 在关键决策点集成人工反馈循环 * 用于实施实验的代码生成功能 * 结合文献和实验结果的自动论文合成 * 自定义提示系统以保持各阶段的研究一致性 评估结果：* 与基线自动化研究方法相比，成本降低了 84% * 生成的代码与盲审中的人类 ML 从业者的质量相匹配 * 成功重现了现有 ML 论文的结果 * 人类审阅者将输出质量评为与研究生水平的研究相当 我认为这可能会对我们开展 ML 研究的方式产生重大影响，特别是对于超参数优化和架构搜索等任务。在保持质量的同时实现文献综述自动化的能力可以帮助研究人员专注于新颖的方向而不是背景工作。 我认为主要的限制是系统对现有文献的依赖——它可能难以应对真正新颖的研究方向。该框架似乎更适合系统地探索已知领域，而不是突破性的新概念。 TLDR：基于 LLM 的研究自动化框架在人工监督下进行端到端 ML 研究方面显示出有希望的结果，在保持研究质量的同时显着降低了成本。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hyxlja/agent_laboratory_an_llmbased_framework_for/</guid>
      <pubDate>Sat, 11 Jan 2025 14:57:31 GMT</pubDate>
    </item>
    <item>
      <title>元思维链：教授法学硕士模拟思维链背后的推理过程</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</link>
      <description><![CDATA[这项工作引入了元思维链（Meta-CoT），它通过明确地模拟元推理过程（模型如何决定采取哪些推理步骤以及为什么）来扩展常规的思维链提示。关键创新是结合过程监督（跟踪推理路径）、合成数据生成和搜索算法，帮助模型学习更好的推理策略。 关键技术点：* 使用过程监督来跟踪模型如何探索不同的解决路径* 通过观察成功的推理模式生成合成训练数据* 实现指令调整和基于 RL 的优化* 开发元推理解释的验证方法* 研究跨模型大小和架构的扩展行为 结果：* 与标准 CoT 相比，模型在推理任务上表现出更好的性能* 生成的解释与人类的推理模式更加一致* 训练管道成功地将指令调整与 RL 结合起来* 框架展示了处理多种推理策略的能力* 显示模型大小和元推理能力之间的相关性 我认为这种方法可以帮助创建更透明的人工智能系统，可以更好地解释他们的决策过程。过程监督和合成数据的结合似乎是提高推理能力的一种实用方法，而不需要大量人工标记的数据。 我认为关键的挑战将是验证元推理解释的质量，并确保它们真正反映模型的内部过程，而不是事后合理化。计算开销也可能限制实际应用。 TLDR：通过结合过程监督、合成数据和搜索算法，新框架可帮助语言模型不仅学习要采取哪些推理步骤，而且还学习为什么这些步骤有意义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hycq8o/meta_chainofthought_teaching_llms_to_model/</guid>
      <pubDate>Fri, 10 Jan 2025 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>对我关于 GCN 的新方法进行评分</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</link>
      <description><![CDATA[您好，我在 ResearchGate 上发布了关于 GCN 的新方法，其中新应用了类别理论中的熵，这提高了 %% 的测试准确率。请不要嘲笑我，祝您有美好的一天并发表评论您的想法 :))    提交人    /u/ksrio64   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hxohoh/rate_my_new_method_about_gcn/</guid>
      <pubDate>Thu, 09 Jan 2025 21:59:30 GMT</pubDate>
    </item>
    <item>
      <title>Marimo 蟒蛇笔记本</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</link>
      <description><![CDATA[我遇到的最令人印象深刻的 Python 笔记本是 Marimo，我强烈建议您尝试一下。需要澄清的是，Marimo 并没有赞助我；我只是喜欢使用它！ https://docs.marimo.io/    提交人    /u/ReceptionLow2817   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hx1t9g/marimo_python_notebook/</guid>
      <pubDate>Thu, 09 Jan 2025 02:07:12 GMT</pubDate>
    </item>
    <item>
      <title>NeuralSVG：文本到矢量生成的隐式表示</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</link>
      <description><![CDATA[  由    /u/nickb  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hwtwpu/neuralsvg_an_implicit_representation_for/</guid>
      <pubDate>Wed, 08 Jan 2025 20:22:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试模仿生物神经元的行为来模拟人工智能神经元的行为</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hvffw0/attempt_to_model_ai_neuron_behavior_after/</guid>
      <pubDate>Tue, 07 Jan 2025 01:09:19 GMT</pubDate>
    </item>
    <item>
      <title>[工具发布] 神经网络工具包（NNT）——神经网络的可视化开发环境</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</link>
      <description><![CDATA[      我开发了一个用于设计和试验神经网络的可视化工具，它是作为 ComfyUI 的一组自定义节点构建的。目标是创建一个环境，通过视觉交互和实时反馈使神经网络概念变得更加具体。 特点：  基于节点的界面，用于构建神经架构 60 个自定义节点，用于各种层类型和操作 张量操作和梯度的实时可视化 带有视觉反馈的交互式训练过程 支持包括 transformer 和注意机制在内的现代架构 内置工具，用于数据加载、预处理和分析  技术能力：  密集层、卷积层、LSTM 层和 RNN 层 各种注意机制（原始、线性、局部等） 位置编码选项（正弦、学习、旋转、不在场证明） 具有可配置的训练节点用于优化器和损失函数 用于数学运算的综合张量运算节点 用于梯度、雅可比矩阵和 Hessians 的高级可视化工具 加载和保存各种模型格式  教育用例：  尝试不同的架构 理解注意力机制 直观地探索张量运算 实时分析训练动态  该工具包允许您构建任何东西，从基本的 MLP 到更复杂的架构，如自动编码器、GAN 或基于变压器的模型。网络的每个组件都可以实时检查和修改。 GitHub：https://github.com/inventorado/ComfyUI_NNT https://preview.redd.it/7i4etnwwmcbe1.png?width=12724&amp;format=png&amp;auto=webp&amp;s=b2c3ff0dd316b0d4799c1ce24f966d85737eb3ae 这是早期版本，侧重于教育和实验用途。来自神经网络社区的反馈将特别有价值。    提交人    /u/inventorado   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1huvzfg/tool_release_neural_network_toolkit_nnt_a_visual/</guid>
      <pubDate>Mon, 06 Jan 2025 10:22:37 GMT</pubDate>
    </item>
    <item>
      <title>准确判断人工智能对书籍和电影的影响程度</title>
      <link>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</link>
      <description><![CDATA[👋大家好 歌词介绍 像我们许多人一样，我深爱文学和电影。大约一年来，我一直在思考人工智能如何在文学和电影领域发挥作用。我确信这将导致作家和作者的贬值。在我看来，这不是未来的问题，而是现在的问题。当一部新的、非常成功的系列、电影或书籍发布时，一部分观众会自动认为人工智能一定参与其中。这反过来又破坏了数百甚至数千名专业作家的巨大努力。未来，这种情况显然只会恶化。 问题 我知道有五种通用的人工智能检测器（主要用于分析文章），据我所知，它们都是通过分析文本来寻找 ChatGPT 和其他 LLM 的典型模式。另一方面，有很多所谓的“人性化工具”，这些工具使人工智能生成的文本看起来更像人类，从而使检测变得复杂。更不用说文本可能是人工智能生成的，但由人类手动编辑，反之亦然的可能性了。 问题 我对专家的意见非常感兴趣。如果我们增加尽可能多的文本分析层次——例如，检查作者的草稿、过去的作品、正在审查的文件的元数据（如果技术上可行的话，包括创建时间和编辑频率）、在审查过程中给作者一个随机任务来分析他们的写作风格等——是否有可能准确确定人工智能对其作品的影响程度？例如：  由人工智能生成并由人类编辑 由人类编写并由人工智能编辑 完全由人工智能编写 完全由人类编写  是否可以通过使用适当的场景和示例训练神经网络来实现这种检测？    提交人    /u/YouranusAlien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/neuralnetworks/comments/1hubath/accurately_determining_the_extent_of_ai_influence/</guid>
      <pubDate>Sun, 05 Jan 2025 16:52:21 GMT</pubDate>
    </item>
    </channel>
</rss>