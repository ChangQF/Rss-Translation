<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于 CTR 预测的协作集成框架</title>
      <link>https://arxiv.org/abs/2411.13700</link>
      <description><![CDATA[arXiv:2411.13700v1 公告类型：新
摘要：基础模型的最新进展已经建立了缩放定律，使开发更大的模型以实现增强的性能，从而激发了对大规模推荐模型的广泛研究。但是，即使有大量数据，简单地增加推荐系统中的模型大小也并不总能带来预期的性能改进。在本文中，我们提出了一个新颖的框架，即协作集成训练网络 (CETNet)，以利用多个不同的模型（每个模型都有自己的嵌入表）来捕获独特的特征交互模式。与简单的模型扩展不同，我们的方法强调通过协作学习实现多样性和协作，其中模型迭代地改进其预测。为了动态平衡每个模型的贡献，我们引入了一种使用通用 softmax 的基于置信度的融合机制，其中模型置信度是通过否定熵计算的。这种设计确保更自信的模型对最终预测有更大的影响，同时受益于其他模型的互补优势。我们在三个公共数据集（AmazonElectronics、TaobaoAds 和 KuaiVideo）以及 Meta 的大规模工业数据集上验证了我们的框架，证明了其优于单个模型和最先进的基线的性能。此外，我们在 Criteo 和 Avazu 数据集上进行了进一步的实验，以将我们的方法与多嵌入范式进行比较。我们的结果表明，我们的框架在较小的嵌入尺寸下实现了相当或更好的性能，为 CTR 预测任务提供了可扩展且高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.13700</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LEADRE：多方位知识增强型法学硕士赋能展示广告推荐系统</title>
      <link>https://arxiv.org/abs/2411.13789</link>
      <description><![CDATA[arXiv:2411.13789v1 公告类型：新
摘要：展示广告为广告商、发布商和用户提供了重要价值。传统的展示广告系统采用由检索、粗略排名和最终排名组成的多阶段架构。然而，传统的检索方法依赖于基于 ID 的学习来对机制进行排名，无法充分利用广告的内容信息，这妨碍了它们提供多样化推荐列表的能力。
为了解决这一限制，我们建议利用 LLM 的广泛世界知识。然而，在试图最大限度地提高 LLM 的有效性时，出现了三个关键挑战：“如何捕捉用户兴趣”、“如何弥合 LLM 和广告系统之间的知识差距”和“如何有效部署 LLM”。为了克服这些挑战，我们引入了一个基于 LLM 的新型框架，称为 LLM 赋能展示广告推荐系统 (LEADRE)。 LEADRE 包含三个核心模块：（1）意图感知提示工程引入多方面知识，设计意图感知对，对 LLM 进行微调，以生成符合用户个人兴趣的广告。（2）广告特定知识对齐结合辅助微调任务和直接偏好优化 (DPO)，使 LLM 与广告语义和商业价值对齐。（3）高效系统部署通过集成延迟容忍和延迟敏感服务，将 LEADRE 部署在线环境中。大量离线实验证明了 LEADRE 的有效性，并验证了各个模块的贡献。在线 A/B 测试表明，LEADRE 分别为微信公众号和朋友圈服务用户带来了 1.57% 和 1.17% 的 GMV 提升。LEADRE 已在两个平台上部署，每天服务数百亿次请求。]]></description>
      <guid>https://arxiv.org/abs/2411.13789</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HARec：用于推荐系统中探索和利用的双曲图-LLM 对齐</title>
      <link>https://arxiv.org/abs/2411.13865</link>
      <description><![CDATA[arXiv:2411.13865v1 公告类型：新
摘要：现代推荐系统通常会创建信息茧房，限制用户接触多样化内容。为了增强用户体验，一个关键挑战是开发能够平衡内容探索和利用的系统，允许用户调整他们的推荐偏好。直观地讲，这种平衡可以通过树形结构表示来实现，其中深度搜索有助于利用，广度搜索有助于探索。然而，目前的研究面临两个挑战：（1）欧几里得方法无法完全捕捉层次结构，在平衡探索-利用方面缺乏灵活性，而（2）双曲方法尽管具有更好的层次建模，但由于依赖欧几里得文本编码器，因此语义对齐不足。为了应对这些挑战，我们提出了 HARec，这是一个双曲表示学习框架，它将用户-项目协作信息与双曲空间中的文本描述联合对齐。我们的框架引入了两项关键技术创新：(1) 分层感知图 llm 对齐机制，可实现更好的分层表示；(2) 双曲线分层树结构，便于用户调整探索-利用权衡。大量实验表明，HARec 的表现始终优于欧几里得和双曲线基线，实用性指标提高了 5.49%，多样性指标提高了 11.39%。]]></description>
      <guid>https://arxiv.org/abs/2411.13865</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过单纯复形实现拓扑感知的流行度去偏</title>
      <link>https://arxiv.org/abs/2411.13892</link>
      <description><![CDATA[arXiv:2411.13892v1 公告类型：新
摘要：推荐系统 (RS) 在跨各种在线平台提供个性化内容方面发挥着关键作用，它利用协同过滤 (CF) 作为根据用户历史交互数据生成推荐的关键技术。CF 的最新进展是由图神经网络 (GNN) 的采用推动的，该网络将用户-项目交互建模为二分图，从而能够捕获高阶协同信号。尽管取得了成功，但基于 GNN 的方法仍面临重大挑战，因为用户-项目交互图的拓扑中存在固有的流行度偏差，导致推荐偏向流行项目而不是鲜为人知的项目。
为了应对这一挑战，我们提出了一种新颖的拓扑感知流行度去偏框架，即测试时间单纯传播 (TSP)，它结合了单纯复形 (SC) 来增强 GNN 的表达能力。与专注于成对关系的传统方法不同，我们的方法通过 SC 捕获多阶关系，从而提供更全面的用户-项目交互表示。通过丰富尾部项目的邻域并利用 SC 进行特征平滑，TSP 可以传播多阶协作信号并有效缓解有偏传播。
我们的 TSP 模块设计为即插即用解决方案，允许无缝集成到基于 GNN 的预训练模型中，而无需微调其他参数。在五个真实数据集上进行的大量实验证明了我们的方法的卓越性能，特别是在长尾推荐任务中。可视化结果进一步证实，TSP 产生更均匀的项目表示分布，从而带来更公平、更准确的推荐。]]></description>
      <guid>https://arxiv.org/abs/2411.13892</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BEST-STD：用于口语术语检测的双向 Mamba 增强语音标记</title>
      <link>https://arxiv.org/abs/2411.14100</link>
      <description><![CDATA[arXiv:2411.14100v1 公告类型：交叉 
摘要：口语术语检测 (STD) 通常会因依赖帧级特征和计算密集型的基于 DTW 的模板匹配而受到阻碍，从而限制了其实用性。为了应对这些挑战，我们提出了一种新颖的方法，将语音编码为离散的、与说话者无关的语义标记。这有助于使用基于文本的搜索算法进行快速检索，并有效地处理词汇表以外的术语。我们的方法侧重于在同一术语的不同话语中生成一致的标记序列。我们还提出了一种在 Mamba 编码器中的双向状态空间建模，该编码器在自监督学习框架中训练，以学习上下文帧级特征，这些特征进一步编码为离散标记。我们的分析表明，我们的语音标记比现有标记器表现出更大的说话者不变性，使它们更适合 STD 任务。在 LibriSpeech 和 TIMIT 数据库上进行的经验评估表明，我们的方法优于现有的 STD 基线，同时效率更高。]]></description>
      <guid>https://arxiv.org/abs/2411.14100</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenScholar：利用检索增强型语言模型合成科学文献</title>
      <link>https://arxiv.org/abs/2411.14199</link>
      <description><![CDATA[arXiv:2411.14199v1 公告类型：交叉 
摘要：科学进步取决于研究人员综合不断增长的文献的能力。大型语言模型 (LM) 能否帮助科学家完成这项任务？我们推出了 OpenScholar，这是一种专门的检索增强型 LM，它通过从 4500 万篇开放获取论文中识别相关段落并综合引用支持的响应来回答科学查询。为了评估 OpenScholar，我们开发了 ScholarQABench，这是第一个用于文献搜索的大规模多领域基准，包括 2,967 个专家编写的查询和 208 个计算机科学、物理学、神经科学和生物医学领域的长格式答案。在 ScholarQABench 上，尽管 OpenScholar-8B 是一个较小的开放模型，但在正确性方面比 GPT-4o 高出 5%，比 PaperQA2 高出 7%。 GPT4o 有 78% 到 90% 的时间会产生幻觉，而 OpenScholar 的引用准确率却与人类专家相当。OpenScholar 的数据存储、检索器和自反馈推理循环也改进了现成的 LM：例如，OpenScholar-GPT4o 将 GPT-4o 的正确率提高了 12%。在人工评估中，与专家撰写的答案相比，专家分别有 51% 和 70% 的时间更喜欢 OpenScholar-8B 和 OpenScholar-GPT4o 的答案，而 GPT4o 的正确率仅为 32%。我们开源了所有代码、模型、数据存储、数据和公开演示。]]></description>
      <guid>https://arxiv.org/abs/2411.14199</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>记忆约束下的稠密检索器的梯度累积方法</title>
      <link>https://arxiv.org/abs/2406.12356</link>
      <description><![CDATA[arXiv:2406.12356v3 公告类型：替换 
摘要：InfoNCE 损失通常用于在信息检索任务中训练密集检索器。众所周知，大批量对于使用 InfoNCE 损失进行稳定有效的训练至关重要，这需要大量的硬件资源。由于对大批量的依赖，密集检索器存在应用和研究的瓶颈。最近，内存减少方法已被广泛采用，通过分解前向和后向或使用存储库来解决硬件瓶颈。然而，当前的方法仍然存在训练速度慢和不稳定的问题。为了解决这些问题，我们提出了对比累积（ContAccum），这是一种稳定有效的密集检索器训练内存减少方法，它使用双存储库结构来利用先前生成的查询和段落表示。在广泛使用的五个信息检索数据集上的实验表明，ContAccum 不仅可以超越现有的内存减少方法，而且可以超越高资源场景。此外，理论分析和实验结果证实，ContAccum 比当前的存储库利用方法提供更稳定的双编码器训练。]]></description>
      <guid>https://arxiv.org/abs/2406.12356</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于轻量级嵌入的推荐系统的全面性能基准测试</title>
      <link>https://arxiv.org/abs/2406.17335</link>
      <description><![CDATA[arXiv:2406.17335v2 公告类型：替换 
摘要：自 Web 创建以来，推荐系统 (RS) 一直是信息过滤中不可或缺的机制。最先进的 RS 主要依赖于分类特征，这些特征由嵌入向量编码，导致嵌入表过大。为了防止过度参数化的嵌入表损害可扩展性，学术界和工业界都在压缩 RS 嵌入方面付出了越来越多的努力。然而，尽管基于轻量级嵌入的 RS (LERS) 蓬勃发展，但评估协议却千差万别，导致在将 LERS 性能与现实世界的可用性联系起来时遇到障碍。此外，尽管轻量级嵌入的共同目标是轻量级，但 LERS 的评估只能在两个主要推荐任务——协同过滤和基于内容的推荐之间进行选择。缺乏对跨任务可转移性的讨论阻碍了统一、更具可扩展性的解决方案的开发。受这些问题的启发，本研究通过全面的基准测试过程研究了各种 LERS 的性能、效率和跨任务可转移性。此外，我们提出了一种使用幅度修剪的高效嵌入压缩方法，这是一种易于部署但极具竞争力的基线，其性能优于各种复杂的 LERS。我们的研究揭示了 LERS 在两个任务中不同的表现，揭示了它们的有效性和通用性。为了支持基于边缘的推荐，我们在 Raspberry Pi 4 上测试了所有 LERS，其中暴露了效率瓶颈。最后，我们总结了本文，总结了 LERS 性能、模型选择建议以及未来研究中 LERS 周围尚未充分探索的挑战。为了鼓励未来的研究，我们在 \href{此链接}{https://github.com/chenxing1999/recsys-benchmark} 上发布了源代码和工件。]]></description>
      <guid>https://arxiv.org/abs/2406.17335</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络搜索中语义嵌入模型的成对判断公式</title>
      <link>https://arxiv.org/abs/2408.04197</link>
      <description><![CDATA[arXiv:2408.04197v2 公告类型：替换 
摘要：语义嵌入模型 (SEM) 是一种基于神经网络的孪生架构，在信息检索和自然语言处理中发展势头强劲。为了以监督的方式训练 SEM 进行 Web 搜索，通常利用搜索引擎查询日志自动制定成对判断作为训练数据。尽管语义嵌入在搜索引擎行业的应用日益广泛，但在制定有效的成对判断以训练 SEM 方面所做的工作却很少。在本文中，我们首次深入研究了用于生成 SEM 成对判断的各种策略。一个有趣（也许令人惊讶）的发现表明，在成对学习排名 (LTR) 领域广泛使用的传统成对判断制定策略对于训练 SEM 并不一定有效。通过基于主要商业搜索引擎的查询日志和点击活动的大规模实证研究，我们展示了 SEM 的有效策略，并强调了混合启发式方法（即点击 &gt; 未点击）相对于 LTR 中的原子启发式方法（例如点击 &gt; 跳过）的优势。我们总结了训练 SEM 的最佳实践，并为未来的研究提供了有希望的见解。]]></description>
      <guid>https://arxiv.org/abs/2408.04197</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RRADistill：提炼法学硕士的长尾查询段落排名能力在搜索引擎上进行文档重新排名</title>
      <link>https://arxiv.org/abs/2410.18097</link>
      <description><![CDATA[arXiv:2410.18097v3 公告类型：替换 
摘要：大型语言模型 (LLM) 擅长理解查询和文档之间的语义关系，即使是冗长而复杂的长尾查询也是如此。由于用户参与度低且反馈有限，这些查询对于基于反馈的排名具有挑战性，因此 LLM 的排名能力非常有价值。然而，LLM 的规模大且推理速度慢，因此需要开发更小、更高效的模型 (sLLM)。最近，将排名标签生成集成到蒸馏技术中变得至关重要，但现有方法未充分利用 LLM 的功能并且很麻烦。我们的研究 RRADistill：重新排名能力蒸馏，为编码器和解码器模型提出了一种高效的标签生成流程和新颖的 sLLM 训练方法。我们引入了一种基于编码器的方法，使用术语控制层来捕获术语匹配信号，并引入了一种基于解码器的模型，该模型具有排名层以增强理解。在韩国搜索平台上进行的 A/B 测试验证了我们的方法在提高长尾查询重新排名方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.18097</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>控制推理中的多样性：使用有针对性的类别偏好引导扩散推荐模型</title>
      <link>https://arxiv.org/abs/2411.11240</link>
      <description><![CDATA[arXiv:2411.11240v2 公告类型：替换 
摘要：多样性控制是缓解偏差放大和过滤气泡问题的重要任务。所需的多样性程度可能会根据用户的日常情绪或业务策略而波动。然而，现有的控制多样性的方法往往缺乏灵活性，因为多样性是在训练过程中决定的，在推理过程中不容易修改。我们提出了 \textbf{D3Rec}（\underline{D}isentangled \underline{D}iffusion model for \underline{D}iversified \underline{Rec}ommendation），这是一种端到端方法，可控制推理时的准确度-多样性权衡。D3Rec 通过 (1) 根据类别偏好生成推荐、(2) 在推理阶段控制类别偏好以及 (3) 适应任意目标类别偏好来满足我们的三个要求。在前向过程中，D3Rec 通过添加噪音来消除潜伏在用户交互中的类别偏好。然后，在逆向过程中，D3Rec 通过去噪步骤生成推荐，同时反映所需的类别偏好。在现实世界和合成数据集上进行的大量实验验证了 D3Rec 在推理时控制多样性的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.11240</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>REAR：面向开放域问答的相关性感知检索增强框架</title>
      <link>https://arxiv.org/abs/2402.17497</link>
      <description><![CDATA[arXiv:2402.17497v2 公告类型：replace-cross 
摘要：考虑到内部参数知识有限，检索增强生成 (RAG) 已被广泛用于扩展大型语言模型 (LLM) 的知识范围。尽管在 RAG 研究方面付出了巨大的努力，但在现有方法中，LLM 无法准确评估检索文档的相关性，因此可能会导致对外部知识（例如检索文档）的误导甚至不正确的利用。为了解决这个问题，在本文中，我们提出了 REAR，一种用于开放域问答 (QA) 的相关性感知检索增强方法。作为主要动机，我们旨在增强 LLM 对外部知识可靠性的自我意识，从而在 RAG 系统中自适应地利用外部知识。具体而言，我们为基于 LLM 的 RAG 系统开发了一种新颖的架构，通过结合专门设计的评估模块来精确评估检索文档的相关性。此外，我们提出了一种基于双粒度相关性融合和抗噪声训练的改进训练方法。通过结合架构和训练方面的改进，我们提出的 REAR 可以通过有效地感知检索到的文档的相关性来更好地利用外部知识。在四个开放域 QA 任务上的实验表明，REAR 明显优于之前许多竞争性 RAG 方法。我们的代码可以在 https://github.com/RUCAIBox/REAR 上访问。]]></description>
      <guid>https://arxiv.org/abs/2402.17497</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学术网络的内容感知分析：以 CORD19 数据集为例</title>
      <link>https://arxiv.org/abs/2411.00262</link>
      <description><![CDATA[arXiv:2411.00262v2 公告类型：替换交叉
摘要：本文研究了科研网络中关键要素（即文章、研究人员和期刊）之间的关系。我们介绍了一种通过基于 HITS 算法在网络中传播主题信息来使用语义信息的新方法。主题信息是通过使用命名实体识别和实体链接得出的。在我们的案例中，MedCAT 用于从 CORD19 数据集中提取主题，该数据集是关于 COVID-19 和冠状病毒科学网络的学术文章语料库。我们的方法侧重于 COVID-19 领域，利用 CORD-19 数据集来证明在引文框架内整合主题相关信息的有效性。通过应用混合 HITS 算法，我们表明合并主题数据会显着影响文章排名，从而更深入地了解学术界的结构。]]></description>
      <guid>https://arxiv.org/abs/2411.00262</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BERTrend：用于新兴趋势检测的神经主题建模</title>
      <link>https://arxiv.org/abs/2411.05930</link>
      <description><![CDATA[arXiv:2411.05930v2 公告类型：replace-cross 
摘要：检测和跟踪大型不断发展的文本语料库中的新兴趋势和弱信号对于监测科学文献、管理品牌声誉、监视关键基础设施以及更普遍的任何类型的基于文本的事件检测等应用至关重要。现有的解决方案通常无法捕捉细微的上下文或动态跟踪随时间演变的模式。BERTrend 是一种新方法，它使用在线环境中的神经主题建模来解决这些限制。它引入了一种新的指标，通过考虑文档数量和更新频率来量化主题随时间推移的流行度。该指标将主题分类为噪声、弱信号或强信号，标记新兴、快速增长的主题以供进一步研究。在两个大型真实数据集上进行的实验证明了 BERTrend 能够准确检测和跟踪有意义的弱信号，同时滤除噪声，为监测大规模不断发展的文本语料库中的新兴趋势提供了全面的解决方案。该方法还可用于对过去事件的回顾性分析。此外，大型语言模型与 BERTrend 的使用为事件趋势的可解释性提供了有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.05930</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>