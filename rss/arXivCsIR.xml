<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 08 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>解释（不那么）显而易见的事情：简单快速地解释 STAN，下一个兴趣点推荐系统</title>
      <link>https://arxiv.org/abs/2410.03841</link>
      <description><![CDATA[arXiv:2410.03841v1 公告类型：新
摘要：近年来，人们付出了很多努力来解释机器学习系统。然而，一些机器学习方法本质上是可解释的，因此并非完全是黑盒。这使开发人员无需开发复杂且昂贵的可解释性技术即可理解输出。除此之外，可解释性应该根据问题的背景进行量身定制。在依赖于协同过滤的推荐系统中，推荐基于类似用户的行为，因此解释应该说明哪些其他用户与当前用户相似。同样，如果推荐系统基于序列预测，解释还应该说明哪些输入时间步长最具影响力。我们在 STAN（用于下一个位置推荐的时空注意网络）中展示了这种理念/范式，这是一个基于协同过滤和序列预测的下一个兴趣点推荐系统。我们还表明解释有助于“调试”输出。]]></description>
      <guid>https://arxiv.org/abs/2410.03841</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMTemporalComparator：一种分析大型语言模型时间适应差异的工具</title>
      <link>https://arxiv.org/abs/2410.04195</link>
      <description><![CDATA[arXiv:2410.04195v1 公告类型：新
摘要：本研究解决了分析在不同时间段的数据上训练的大型语言模型 (LLM) 中的时间差异的挑战。为了促进对这些差异的自动探索，我们提出了一个新颖的系统，该系统基于用户定义的查询以系统的方式比较两个 LLM 版本的输出。该系统首先生成一个以用户指定的关键字为基础的分层主题结构，以便对主题类别进行有组织的比较。随后，它评估两个 LLM 生成的文本，以识别词汇、信息呈现和潜在主题的差异。这种完全自动化的方法不仅简化了对公众舆论和文化规范变化的识别，而且还增强了我们对机器学习应用程序对时间变化的适应性和稳健性的理解。通过促进持续模型适应和比较总结的研究，这项工作有助于开发更透明的机器学习模型，能够捕捉不断变化的社会背景的细微差别。]]></description>
      <guid>https://arxiv.org/abs/2410.04195</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于元数据的数据探索与大型语言模型的检索增强生成</title>
      <link>https://arxiv.org/abs/2410.04231</link>
      <description><![CDATA[arXiv:2410.04231v1 公告类型：新
摘要：考虑到可用的元数据非常有限，开发有效搜索必要数据集的能力是帮助数据用户识别相关数据集的迫切要求。对于这一挑战，利用第三方数据正在成为一种有价值的改进来源。我们的研究引入了一种新的数据探索架构，它采用一种检索增强生成 (RAG) 形式来增强基于元数据的数据发现。该系统将大型语言模型 (LLM) 与外部向量数据库集成，以识别不同类型数据集之间的语义关系。所提出的框架提供了一种评估异构数据源之间语义相似性和改进数据探索的新方法。我们的研究包括四个关键任务的实验结果：1) 推荐相似的数据集、2) 建议可组合的数据集、3) 估计标签和 4) 预测变量。我们的结果表明，与传统元数据方法相比，RAG 可以增强相关数据集的选择，尤其是来自不同类别的数据集。然而，不同任务和模型的性能各不相同，这证实了根据具体用例选择适当技术的重要性。研究结果表明，这种方法有望解决数据探索和发现方面的挑战，尽管对于估计任务，还需要进一步改进。]]></description>
      <guid>https://arxiv.org/abs/2410.04231</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐中异构公平性的社会选择</title>
      <link>https://arxiv.org/abs/2410.04551</link>
      <description><![CDATA[arXiv:2410.04551v1 公告类型：新
摘要：推荐系统中的算法公平性需要密切关注可能有竞争利益的不同利益相关者的需求。该领域的先前工作通常受到固定的、单一目标的公平性定义的限制，这些定义内置于算法或优化标准中，这些标准应用于单个公平性维度，或者最多在各个维度上相同地应用。这些狭隘的概念化限制了将公平意识解决方案适应实践中出现的广泛利益相关者需求和公平性定义的能力。我们的工作从计算社会选择的角度使用多代理框架来处理推荐公平性。在本文中，我们探讨了不同社会选择机制的属性，并展示了跨多个数据集的多个异构公平性定义的成功集成。]]></description>
      <guid>https://arxiv.org/abs/2410.04551</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过观察数据的市场期望值估计进行排名策略学习</title>
      <link>https://arxiv.org/abs/2410.04568</link>
      <description><![CDATA[arXiv:2410.04568v1 公告类型：新
摘要：我们开发了一个决策框架，将双边电子商务市场中搜索或推荐引擎的排名策略学习问题转化为使用观察数据的预期奖励优化问题。作为一种价值分配机制，排名策略将检索到的项目分配到指定的插槽，以便在购物旅程的任何给定阶段最大化用户从插槽项目中获得的效用。这种分配的目标反过来可以相对于底层概率用户浏览模型定义为在给定排名上下文的情况下，呈现的项目上与用户意图匹配的交互事件的预期数量。通过认识到排名作为一种干预行动的影响，以告知用户与插槽项目的交互以及交互事件对市场的相应经济价值，我们将市场的预期回报表述为所有呈现的排名行动的集体价值。这个公式中的关键要素是上下文价值分布的概念，它不仅表示将价值归因于会话中的排名干预，还表示市场奖励在用户会话中的分配。我们从观察数据中构建了市场预期回报的经验估计，这些数据考虑了会话上下文中经济价值的异质性以及从观察用户活动数据中学习的分布变化。然后可以通过标准贝叶斯推理技术优化经验预期回报估计来训练排名策略。我们报告了主要电子商务平台中产品搜索排名任务的经验结果，展示了在经验回报估计上训练的排名策略与上下文价值分布的极端选择之间的基本权衡。]]></description>
      <guid>https://arxiv.org/abs/2410.04568</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解码 MIE：一种使用主题提取和从属关系解析的新型数据集方法</title>
      <link>https://arxiv.org/abs/2410.04602</link>
      <description><![CDATA[arXiv:2410.04602v1 公告类型：新
摘要：医学信息学文献的快速扩张对综合和分析研究趋势提出了重大挑战。本研究介绍了一个来自欧洲医学信息学 (MIE) 会议论文集的新数据集，解决了该领域对复杂分析工具的需求。利用 Triple-A 软件，我们从“健康技术和信息学研究”期刊系列中发表的 4,606 篇文章中提取和处理了元数据和摘要，重点关注 1996 年以后的 MIE 会议。我们的方法结合了先进的技术，例如使用 TextRank 算法进行隶属关系解析。结果数据集以 JSON 格式提供，提供了文献计量详细信息、提取的主题和标准化隶属关系信息的全面视图。对这些数据的分析揭示了多年来数字对象标识符使用、引用趋势和作者归属的有趣模式。值得注意的是，我们观察到作者数据不一致以及出版物中短暂的语言多样性。该数据集对医学信息学界做出了重大贡献，使纵向研究趋势、协作网络分析和深入的文献计量调查成为可能。通过提供涵盖近三十年会议论文集的丰富、结构化的资源，我们旨在促进快速发展的医学信息学领域的新见解和进步。]]></description>
      <guid>https://arxiv.org/abs/2410.04602</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于会话推荐的项目集群感知提示学习</title>
      <link>https://arxiv.org/abs/2410.04756</link>
      <description><![CDATA[arXiv:2410.04756v1 公告类型：新
摘要：基于会话的推荐 (SBR) 旨在通过分析单个会话内的项目序列来捕获动态用户偏好。然而，大多数现有方法主要关注会话内项目关系，忽略了不同会话之间项目之间的联系（会话间关系），这限制了它们完全捕获复杂项目交互的能力。虽然一些方法结合了会话间信息，但它们通常计算成本高，导致训练时间更长且效率降低。为了应对这些挑战，我们提出了 CLIP-SBR（基于会话的推荐的集群感知项目提示学习）框架。CLIP-SBR 由两个模块组成：1）项目关系挖掘模块，它构建一个全局图来有效地模拟会话内和会话间关系，2）项目集群感知提示学习模块，它使用软提示将这些关系有效地集成到 SBR 模型中。我们在八种 SBR 模型和三个基准数据集上对 CLIP-SBR 进行了评估，一致证明了其推荐性能的提升，并将 CLIP-SBR 确立为基于会话的推荐任务的强大解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.04756</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过项目损失均衡来纠正推荐系统中的流行度偏差</title>
      <link>https://arxiv.org/abs/2410.04830</link>
      <description><![CDATA[arXiv:2410.04830v1 公告类型：新
摘要：推荐系统 (RS) 经常受到流行度偏差的影响，一小部分流行项目由于其高交互率而主导推荐结果，而许多不太受欢迎的项目则被忽略。这种现象不成比例地使具有主流品味的用户受益，而忽略了具有小众兴趣的用户，导致用户之间的不公平，并加剧了不同用户组之间的推荐质量差异。在本文中，我们提出了一种通过干预推荐模型的训练过程来解决此问题的处理内方法。从机器学习中的公平经验风险最小化中汲取灵感，我们通过一个附加项增强了推荐模型的目标函数，旨在最小化训练过程中不同项目组之间的损失值差异。我们的方法通过对两个真实数据集的大量实验进行评估，并与最先进的基线进行了比较。结果表明，我们的方法在减轻流行偏见的不公平性方面具有卓越的效果，同时对推荐准确性造成的损失却可以忽略不计。]]></description>
      <guid>https://arxiv.org/abs/2410.04830</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FELLAS：使用 LLM 作为外部服务来增强联合顺序推荐</title>
      <link>https://arxiv.org/abs/2410.04927</link>
      <description><![CDATA[arXiv:2410.04927v1 公告类型：新
摘要：联邦顺序推荐 (FedSeqRec) 因其保护用户隐私的能力而受到越来越多的关注。不幸的是，FedSeqRec 的性能仍然不令人满意，因为 FedSeqRec 中使用的模型必须是轻量级的，以适应通信带宽和客户端设备上的计算资源限制。最近，大型语言模型 (LLM) 表现出强大的可转移和通用语言理解能力，因此，在 NLP 领域，许多下游任务现在使用 LLM 作为服务来实现卓越的性能，而无需构建复杂的模型。受这一成功实践的启发，我们提出了一个通用的 FedSeqRec 框架 FELLAS，旨在通过利用 LLM 作为外部服务来增强 FedSeqRec。具体来说，FELLAS 使用 LLM 服务器来提供项目级和序列级表示帮助。中央服务器查询项目级表示服务，以使用文本信息丰富原始的基于 ID 的项目嵌入，而每个客户端访问序列级表示服务。但是，调用序列级表示服务需要客户端将序列发送到外部 LLM 服务器。为了保护隐私，我们实现了 dx-privacy 满足序列扰动，这为客户的敏感数据提供了保障。此外，还设计了一种基于对比学习的方法，将知识从嘈杂的序列表示转移到客户的序列推荐模型。此外，为了实证验证 FELLAS 的隐私保护能力，我们提出了两种交互式项目推理攻击。使用两种广泛使用的序列推荐模型在三个数据集上进行的大量实验证明了 FELLAS 的有效性和隐私保护能力。]]></description>
      <guid>https://arxiv.org/abs/2410.04927</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用知识图谱和大型语言模型进行法律文章推荐：以中国刑法为例</title>
      <link>https://arxiv.org/abs/2410.04949</link>
      <description><![CDATA[arXiv:2410.04949v1 Announce Type: new 
摘要：法院效率是社会稳定的重要保障，然而在世界大多数国家，基层法院案件积压严重，判决严重依赖司法人员的认知劳动，缺乏提升效率的智能工具。针对这一问题，我们提出了一种基于知识图谱（KG）和大型语言模型（LLM）的高效法律文章推荐方法。首先，我们提出了一个案例增强型法律文章知识图谱（CLAKG）作为数据库，用于存储现行法律法规、历史案例信息以及法律文章与历史案例之间的对应关系。此外，我们引入了一种基于LLM的自动化CLAKG构建方法。在此基础上，我们提出了一种闭环的法律文章推荐方法。最后，通过对“中国裁判文书网”网站裁判文书的一系列实验，我们将案例法律文章推荐的准确率从0.549提高到了0.694，表明我们提出的方法明显优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2410.04949</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论专家发现系统的偏见评估</title>
      <link>https://arxiv.org/abs/2410.05018</link>
      <description><![CDATA[arXiv:2410.05018v1 公告类型：新
摘要：在大型组织中，识别特定主题的专家对于利用跨团队和部门的内部知识至关重要。所谓的企业专家检索系统会根据有关员工及其所执行工作的大量异构数据自动发现和构建员工的专业知识。评估这些系统需要全面的地面实况专家注释，而这些注释很难获得。因此，注释过程通常依赖于知识领域的自动建议来验证。本案例研究分析了这些建议如何影响专家查找系统的评估。我们在一个流行的基准上证明，系统验证的注释会导致传统基于术语的检索模型的性能被高估，甚至使与较新的神经方法的比较无效。我们还用同义词扩充知识领域，以揭示对其组成词的字面提及的强烈偏见。最后，我们提出了对注释过程的约束，以防止这些有偏见的评估，并表明这仍然允许高实用性的注释建议。这些发现应为专家发现的基准创建或选择提供参考，以保证方法的有意义的比较。]]></description>
      <guid>https://arxiv.org/abs/2410.05018</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的生成推荐的有效推理</title>
      <link>https://arxiv.org/abs/2410.05165</link>
      <description><![CDATA[arXiv:2410.05165v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的生成推荐取得了显著的成功，但其实际部署成本高昂，特别是由于自回归解码导致的过高的推理延迟。对于无损 LLM 解码加速，推测解码 (SD) 已成为一种有前途的解决方案。然而，将 SD 应用于生成推荐带来了独特的挑战，因为需要通过波束搜索生成前 K 个项目（即 K 个不同的标记序列）作为推荐列表。这导致 SD 中的验证更加严格，其中目标 LLM 中的所有前 K 个序列都必须在每个解码步骤中由草稿模型成功起草。为了缓解这种情况，我们考虑 1) 增强草稿模型和目标 LLM 之间的前 K 个序列比对，以及 2) 放宽验证策略以减少琐碎的 LLM 调用。为此，我们提出了一个名为 AtSpeed 的对齐框架，该框架提出了严格 top-K 验证下 top-K 对齐的 AtSpeed-S 优化目标。此外，我们引入了一种宽松采样验证策略，允许高概率的非 top-K 起草序列被接受，从而大大减少了 LLM 调用。相应地，我们提出了 AtSpeed-R 用于这种宽松采样验证下的 top-K 对齐。在两个真实数据集上的经验结果表明，AtSpeed 显著加速了基于 LLM 的生成推荐，例如，在严格 top-K 验证下加速近 2 倍，在宽松采样验证下加速高达 2.5 倍。代码和数据集将在不久的将来发布。]]></description>
      <guid>https://arxiv.org/abs/2410.05165</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结合开箱模拟和重要性采样来调整大规模推荐系统</title>
      <link>https://arxiv.org/abs/2410.03697</link>
      <description><![CDATA[arXiv:2410.03697v1 公告类型：交叉 
摘要：推荐系统规模的不断扩大需要进行大量调整以响应市场动态和系统变化。我们解决了调整大型广告推荐平台的挑战，该平台具有多个影响关键绩效指标 (KPI) 的连续参数。传统方法（如开箱蒙特卡罗模拟器）虽然准确，但由于评估大量参数设置的成本高昂，因此计算成本高昂。为了缓解这种情况，我们提出了一种混合方法模拟器引导重要性采样 (SGIS)，它将开箱模拟与重要性采样 (IS) 相结合。SGIS 利用两种技术的优势：它在参数空间上执行粗略枚举以识别有希望的初始设置，然后使用 IS 迭代优化这些设置。这种方法显着降低了计算成本，同时保持了 KPI 估计的高精度。我们通过模拟和现实世界的实验证明了 SGIS 的有效性，表明与传统方法相比，它以更低的计算开销实现了 KPI 的显着改进。]]></description>
      <guid>https://arxiv.org/abs/2410.03697</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>C3PA：专家注释和法规感知隐私政策的开放数据集，可实现可扩展的监管合规审计</title>
      <link>https://arxiv.org/abs/2410.03925</link>
      <description><![CDATA[arXiv:2410.03925v1 公告类型：交叉 
摘要：开发用于分析和提取隐私政策中组织数据习惯的工具和技术对于可扩展的法规合规性审计至关重要。不幸的是，这些工具在识别合规性问题和修复方面的能力越来越有限。毕竟，大多数都是使用与法规无关的注释隐私政策数据集开发的，这些数据集是在具有里程碑意义的隐私法规（例如欧盟的 GDPR 和加利福尼亚的 CCPA）出台之前获得的。在本文中，我们描述了第一个开放的法规感知专家注释隐私政策数据集 C3PA（CCPA 隐私政策条款注释），旨在应对这一挑战。C3PA 包含超过 48K 个专家标记的隐私政策文本段，这些文本段与来自 411 个独特组织的对 CCPA 特定披露要求的回应有关。我们证明 C3PA 数据集非常适合帮助自动审计与 CCPA 相关的披露要求的合规性。]]></description>
      <guid>https://arxiv.org/abs/2410.03925</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多语言链接语料库中的实体插入：以维基百科为例</title>
      <link>https://arxiv.org/abs/2410.04254</link>
      <description><![CDATA[arXiv:2410.04254v1 公告类型：交叉 
摘要：链接是信息网络的基本组成部分，它将孤立的知识片段变成比其各部分之和丰富得多的信息网络。但是，向网络添加新链接并非易事：它不仅需要识别合适的源实体和目标实体对，还需要理解源的内容以在文本中找到链接的合适位置。后一个问题尚未得到有效解决，特别是在源中缺少可以作为插入到目标实体的链接的锚点的文本跨度的情况下。为了弥补这一差距，我们引入并实施了信息网络中实体插入的任务。以维基百科为例，我们通过经验表明，这个问题对编辑者来说既相关又具有挑战性。我们用 105 种语言编制了一个基准数据集，并开发了一个称为 LocEI（本地化实体插入）的实体插入框架及其多语言变体 XLocEI。我们表明，XLocEI 的表现优于所有基线模型（包括使用 GPT-4 等 LLM 的最先进的基于提示的排名），并且可以以零样本方式应用于训练期间未见过的语言，且性能下降最小。这些发现对于在实践中应用实体插入模型非常重要，例如，支持编辑者在 300 多个语言版本的维基百科中添加链接。]]></description>
      <guid>https://arxiv.org/abs/2410.04254</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>