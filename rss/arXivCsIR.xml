<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 04 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SCTc-TE：时态事件预测的综合公式和基准</title>
      <link>https://arxiv.org/abs/2312.01052</link>
      <description><![CDATA[arXiv:2312.01052v2 公告类型：替换
摘要：时间复杂事件预测旨在根据历史中观察到的事件来预测未来事件。大多数时间复杂事件的表述都是非结构化的或没有广泛的时间信息，导致表示效果较差且预测能力有限。为了弥补这些差距，我们创新性地引入了结构化、复杂和时间完整的时间事件（SCTc-TE）的公式。按照这个全面的公式，我们开发了一个完全自动化的管道，并从大约 60 万篇新闻文章中构建了一个名为 MidEast-TE 的大规模数据集。该数据集重点关注2015年至2022年主要中东地区国家之间的合作和冲突事件。不仅限于数据集的构建，更重要的是，我们通过区分各种上下文信息（即本地和本地信息）的关键作用来改进预测方法。全球背景。因此，我们提出了一种新方法 LoGo，它能够利用本地和全局上下文进行 SCTc-TE 预测。我们在我们提出的 MidEast-TE 数据集和原始 GDELT-TE 数据集上评估我们提出的方法。实验结果证明了我们的预测模型 LoGo 的有效性。代码和数据集通过 https://github.com/yecchen/GDELT-ComplexEvent 发布。]]></description>
      <guid>https://arxiv.org/abs/2312.01052</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>用于对话推荐的选择链分层策略学习</title>
      <link>https://arxiv.org/abs/2310.17922</link>
      <description><![CDATA[arXiv:2310.17922v2 公告类型：替换
摘要：会话推荐系统（CRS）通过多轮交互对话阐明用户偏好，最终实现精确且令人满意的推荐。然而，当代的CRS仅限于每轮基于单一属性类型（例如颜色）查询二元或多选题，这会导致过多的交互轮数并降低用户体验。为了解决这个问题，我们提出了一种更现实、更高效的会话推荐问题设置，称为多类型属性多轮会话推荐（MTAMCR），它使得CRS能够在每轮中查询涵盖多种类型属性的多项选择问题，从而提高交互效率。此外，通过将 MTAMCR 制定为分层强化学习任务，我们提出了选择链分层策略学习（CoCHPL）框架，以提高 MTAMCR 的提问效率和推荐有效性。具体来说，针对选项的长期策略（即询问或推荐）决定了行动类型，而两个短期选项内策略通过多步骤推理和选择依次生成属性或项目链，优化多样性和提问属性的相互依赖。最后，对四个基准的广泛实验证明了 CoCHPL 优于主流最先进方法的性能。]]></description>
      <guid>https://arxiv.org/abs/2310.17922</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能代理推进搜索前沿</title>
      <link>https://arxiv.org/abs/2311.01235</link>
      <description><![CDATA[arXiv:2311.01235v2 公告类型：替换
摘要：正如我们信息检索 (IR) 研究界的许多人所知道和认识到的那样，搜索远不是一个已解决的问题。每天都有数百万人在搜索引擎上苦苦挣扎。通常，他们的困境与任务的内在复杂性以及搜索系统未能完全理解任务并提供相关结果有关。该任务激励搜索，创造搜索者试图弥合/解决的差距/问题情况，并在他们完成不同任务方面时驱动搜索行为。复杂的搜索任务需要的不仅仅是基本事实查找或重新查找的支持。支持复杂任务的方法研究包括生成查询和网站建议、个性化和情境化搜索以及开发新的搜索体验（包括跨越时间和空间的搜索体验）。最近出现的生成人工智能（AI）和基于该技术的辅助代理的出现，有可能为搜索者，特别是那些从事复杂任务的搜索者提供进一步的帮助。这些进步对于智能系统的设计和搜索本身的未来具有深远的影响。本文基于作者在 2023 年 ACM SIGIR 会议上的主题演讲，探讨了这些问题以及 AI 代理如何推进搜索系统功能的前沿，特别关注信息交互和复杂任务的完成。]]></description>
      <guid>https://arxiv.org/abs/2311.01235</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>多粒度引导融合解码器</title>
      <link>https://arxiv.org/abs/2404.02581</link>
      <description><![CDATA[arXiv:2404.02581v1 公告类型：交叉
摘要：在开放域问答（ODQA）中，识别相关上下文作为证据并避免检索结果中的虚假内容至关重要。在解码阶段使用串联多个上下文的模型架构（即 Fusion-in-Decoder）表现出了良好的性能，但从看似合理的上下文中生成了不正确的输出。为了解决这个问题，我们提出了多粒度引导融合解码器（MGFiD），可以跨多个粒度级别识别证据。基于多任务学习，MGFiD 将段落重新排序与句子分类相协调。它将明显的句子聚合成一个锚向量来指示解码器。此外，它通过重用段落重新排序的结果进行段落修剪来提高解码效率。通过我们的实验，MGFiD 在自然问题 (NQ) 和 TriviaQA (TQA) 数据集上的性能优于现有模型，凸显了其多粒度解决方案的优势。]]></description>
      <guid>https://arxiv.org/abs/2404.02581</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>生成对比异构图神经网络</title>
      <link>https://arxiv.org/abs/2404.02810</link>
      <description><![CDATA[arXiv:2404.02810v1 公告类型：交叉
摘要：异构图（HG）可以通过多种类型的节点和边有效地建模现实世界中的复杂关系。近年来，受自监督学习的启发，对比异构图神经网络（HGNN）通过利用数据增强和判别器来完成下游任务，显示出了巨大的潜力。然而，由于图的离散性和抽象性，数据增强仍然受到限制。为了解决上述限制，我们提出了一种新颖的 \textit{生成对比异构图神经网络（GC-HGNN）}。具体来说，我们首先提出一种异构图生成学习增强对比范式。该范例包括：1）使用掩码自动编码器的对比视图增强策略。 2）位置感知和语义感知的正样本采样策略，用于生成硬负样本。 3）用于捕获局部和全局信息的分层对比学习策略。此外，分层对比学习和采样策略旨在在生成对比视角下构建增强的判别器。最后，我们将我们的模型与八个真实数据集的十七个基线进行比较。我们的模型在节点分类和链接预测任务方面优于最新的对比和生成基线。为了重现我们的工作，我们在 https://github.com/xxx 开源了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2404.02810</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>代币追踪：使用 ChatLLM 探索对话式 AI 中的上下文深度</title>
      <link>https://arxiv.org/abs/2404.02402</link>
      <description><![CDATA[arXiv:2404.02402v1 公告类型：交叉
摘要：使用大型语言模型 (LLM) 的对话建模需要对上下文有细致入微的理解，才能生成连贯且与上下文相关的响应。在本文中，我们提出了 Token Trails，这是一种利用令牌类型嵌入来导航对话中复杂的上下文细微差别的新颖方法。我们的框架利用令牌类型嵌入来区分用户话语和机器人响应，从而促进上下文感知回复的生成。通过全面的实验和评估，我们证明了 Token Trails 在提高对话理解和响应生成方面的有效性，实现了最先进的性能。我们的结果强调了上下文建模在对话式人工智能中的重要性，并强调了 Token Trails 推动该领域发展的巨大潜力，为更复杂和上下文感知的聊天机器人交互铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2404.02402</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>SemEval-2024 上的 uTeBC-NLP 任务 9：法学硕士可以成为横向思考者吗？</title>
      <link>https://arxiv.org/abs/2404.02474</link>
      <description><![CDATA[arXiv:2404.02474v1 公告类型：交叉
摘要：受人类认知的启发，Jiang 等人（2023c）创建了一个评估法学硕士横向思维（跳出框框）的基准。在此基准的基础上，我们研究了不同的激励方法如何提高法学硕士在这项任务上的表现，以揭示他们固有的创新思维能力。通过参与 SemEval-2024、任务 9、句子谜题子任务，我们探索了提示工程方法：思想链 (CoT) 和直接提示、通过信息描述进行增强，以及使用检索增强生成 (RAG) 管道采用情境化提示。我们的实验涉及三个 LLM，包括 GPT-3.5、GPT-4 和 Zephyr-7B-beta。我们使用 GPT-4 生成谜语和选项之间思维路径的数据集，并由人类验证质量。研究结果表明，压缩的信息提示可以提高性能。动态上下文学习可显着提高模型性能。此外，在我们的数据集上微调 Zephyr 可以增强其他常识数据集的性能，强调创新思维的价值。]]></description>
      <guid>https://arxiv.org/abs/2404.02474</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>使用位向量的高效多向量密集检索</title>
      <link>https://arxiv.org/abs/2404.02805</link>
      <description><![CDATA[arXiv:2404.02805v1 公告类型：新
摘要：密集检索技术采用预先训练的大型语言模型来构建查询和段落的高维表示。这些表示计算段落的相关性。使用有效的相似性度量进行查询。在这一行中，通过在每个令牌级别上对查询和文档进行编码，多向量表示显示出更高的有效性，但代价是内存占用和查询延迟增加了一个数量级。最近，PLAID 通过引入基于质心的术语表示来解决这些问题，以减少多向量系统对内存的影响。通过利用质心交互机制，PLAID 过滤掉不相关的文档，从而降低连续排名阶段的成本。本文提出了“使用位向量的高效多向量密集检索”（EMVB），这是一种在多向量密集检索中进行高效查询处理的新颖框架。首先，EMVB 使用优化的位向量对段落进行高效的预过滤步骤。其次，质心交互的计算按列进行，利用 SIMD 指令，从而减少其延迟。第三，EMVB 利用乘积量化 (PQ) 来减少存储向量表示的内存占用，同时允许快速后期交互。第四，我们引入了每文档术语过滤方法，进一步提高了最后一步的效率。 MS MARCO 和 LoTTE 上的实验表明，与 PLAID 相比，EMVB 的速度提高了 2.8 倍，同时内存占用量减少了 1.8 倍，且检索精度没有损失。]]></description>
      <guid>https://arxiv.org/abs/2404.02805</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>循环中的法学硕士：利用大型语言模型注释进行低资源语言的主动学习</title>
      <link>https://arxiv.org/abs/2404.02261</link>
      <description><![CDATA[arXiv:2404.02261v1 公告类型：交叉
摘要：由于语言资源和数据标记专业知识有限，低资源语言在人工智能开发中面临重大障碍，导致它们稀有且昂贵。数据的稀缺和现有工具的缺乏加剧了这些挑战，特别是因为这些语言可能无法在各种 NLP 数据集中得到充分表示。为了解决这一差距，我们建议利用法学硕士在主动学习循环中的潜力进行数据注释。最初，我们进行评估以评估注释者之间的一致性和一致性，以促进选择合适的法学硕士注释者。然后，使用主动学习范例将所选注释器集成到分类器的训练循环中，从而最大限度地减少所需的查询数据量。实证评估，特别是使用 GPT-4-Turbo，展示了近乎最先进的性能，同时显着减少了数据需求，与人工注释相比，预计潜在成本节省至少 42.45 倍。我们提出的解决方案显示出在大幅降低资源匮乏环境中与自动化相关的货币和计算成本方面的巨大潜力。通过弥合低资源语言和人工智能之间的差距，这种方法促进了更广泛的包容性，并展示了跨不同语言环境实现自动化的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.02261</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>经过扩展查询训练的排序器的惊人效果</title>
      <link>https://arxiv.org/abs/2404.02587</link>
      <description><![CDATA[arXiv:2404.02587v1 公告类型：新
摘要：文本排名系统中的一个重要问题是处理形成查询分布尾部的硬查询。由于存在不常见、未指定或不完整的查询，可能会出现困难。在这项工作中，我们提高了困难查询的排名性能，而不影响其他查询的性能。首先，我们使用相关文档进行基于 LLM 的查询丰富来训练查询。接下来，专门的排名器仅针对丰富的硬查询而不是原始查询进行微调。我们将专业排名器和基本排名器的相关性分数以及为每个查询估计的查询性能分数结合起来。我们的方法不同于现有的方法，现有的方法通常对所有查询使用单个排序器，这种方法偏向于简单查询，而简单查询构成了查询分布的大部分。在我们对 DL-Hard 数据集进行的广泛实验中，我们发现，使用基础和专用排名器的基于原则性查询性能的评分方法可显着提高段落排名任务的高达 25% 和文档排名任务的高达 48.4%与使用原始查询的基准性能相比，甚至优于 SOTA 模型。]]></description>
      <guid>https://arxiv.org/abs/2404.02587</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>通过混合结构摘要和基于 LLM 的数据增强改进主题相关性模型</title>
      <link>https://arxiv.org/abs/2404.02616</link>
      <description><![CDATA[arXiv:2404.02616v1 公告类型：新
摘要： 查询与文档之间的主题相关性是社交搜索的重要组成部分，可以评价文档与用户需求的匹配程度。在大众点评等大多数社交搜索场景中，搜索相关性建模始终面临两个挑战。一是社交搜索中的很多文档都很长并且有很多冗余信息。二是搜索相关性模型的训练数据很难获取，尤其是多分类相关性模型。为了解决上述两个问题，我们首先将查询与基于查询的摘要和无查询的文档摘要连接起来作为主题相关性模型的输入，这可以帮助模型学习查询与文档核心主题之间的相关程度。然后，我们利用大语言模型（LLM）的语言理解和生成能力，从现有训练数据中的查询和文档重写并生成查询，这可以构造新的查询-文档对作为训练数据。大量的离线实验和在线A/B测试表明，所提出的方法有效地提高了相关性建模的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.02616</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>DUQGen：通过多样化综合查询生成实现神经排序器的有效无监督域​​适应</title>
      <link>https://arxiv.org/abs/2404.02489</link>
      <description><![CDATA[arXiv:2404.02489v1 公告类型：新
摘要：最先进的神经排序器在大型特定任务训练数据（例如 MS-MARCO）上进行预训练，已被证明在无需域适应（也称为零样本）的各种排序任务中表现出强大的性能。然而，零样本神经排序可能不是最优的，因为它没有利用目标域信息。不幸的是，获取足够大和高质量的目标训练数据来改进现代神经排序器可能既昂贵又耗时。为了解决这个问题，我们提出了一种用于排名的无监督域适应的新方法 DUQGen，它解决了先前文献中的一个关键差距，即如何自动生成有效且多样化的合成训练数据，以微调现代神经排名器以实现新的目标。领域。具体来说，DUQGen 通过识别相似文档的集群来生成目标域的更有效表示；并通过对生成的文档集群进行概率采样来生成更加多样化的训练数据集。我们在标准 BEIR 集合上进行的广泛实验表明，DUQGen 始终优于所有零样本基线，并且在 18 个数据集中的 16 个数据集上显着优于 SOTA 基线，所有数据集平均相对改进为 4%。我们通过彻底的分析来补充我们的结果，以便更深入地了解所提出的方法的性能，并确定有希望进一步改进的领域。]]></description>
      <guid>https://arxiv.org/abs/2404.02489</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>无偏见学习排名符合现实：百度大规模搜索数据集的经验教训</title>
      <link>https://arxiv.org/abs/2404.02543</link>
      <description><![CDATA[arXiv:2404.02543v1 公告类型：新
摘要：无偏学习排名（ULTR）是一个完善的框架，用于从用户点击中学习，而收集数据的排名器通常会产生偏见。虽然 ULTR 技术在理论上是合理的并且经过了广泛的模拟测试，但缺乏经验验证，尤其是在现代搜索引擎上。从百度搜索引擎收集的 WSDM Cup 2023 发布的数据集为评估著名 ULTR 技术的实际性能提供了难得的机会。尽管在 WSDM Cup 2023 和随后的 NTCIR ULTRE-2 任务期间提交了多次作品，但仍不清楚观察到的改进是否源于应用 ULTR 或其他学习技术。我们重新审视并扩展了可用的实验。我们发现，无偏见的学习排名技术并没有带来明显的性能改进，特别是与排名损失和查询文档特征的选择带来的明显差异相比。我们的实验表明 ULTR 显着改善了点击预测。然而，点击预测的这些收益并不会转化为专家相关性注释的排名性能的提高，这意味着结论在很大程度上取决于该基准测试中如何衡量成功。]]></description>
      <guid>https://arxiv.org/abs/2404.02543</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>RAT：用于点击率预测的检索增强变压器</title>
      <link>https://arxiv.org/abs/2404.02249</link>
      <description><![CDATA[arXiv:2404.02249v1 公告类型：新
摘要：预测点击率 (CTR) 是 Web 应用程序的一项基本任务，其中的关键问题是设计有效的功能交互模型。当前的方法主要集中于对单个样本内的特征交互进行建模，而忽略了可以作为增强预测的参考上下文的潜在跨样本关系。为了弥补这一缺陷，本文开发了一种检索增强变压器（RAT），旨在获取样本内和样本间的细粒度特征交互。通过检索相似的样本，我们为每个目标样本构建增强输入。然后，我们构建具有级联注意力的 Transformer 层，以捕获样本内和样本间特征交互，促进综合推理以改进 CTR 预测，同时保持效率。对现实世界数据集的大量实验证实了 RAT 的有效性，并表明了其在长尾场景中的优势。代码已开源于\url{https://github.com/YushenLi807/WWW24-RAT}。]]></description>
      <guid>https://arxiv.org/abs/2404.02249</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>生成人工智能的网页内容控制调查</title>
      <link>https://arxiv.org/abs/2404.02309</link>
      <description><![CDATA[arXiv:2404.02309v1 公告类型：新
摘要：围绕生成式 AI 的突破性进展最近引起了一波关注，最终引发了一系列诉讼，其中包括针对 Stability AI 和 OpenAI 的高调诉讼。这种法律不确定性的情况引发了关于内容创作者和出版商保护其网络知识产权的权利的广泛讨论。欧洲和美国法律已经提供了粗略的指导方针，为规范网络数据使用的技术解决方案指明了方向。在本课程中，研究人员和从业者研究了许多网络标准和选择退出格式，使出版商能够将其数据排除在生成人工智能模型的开发之外。新兴的人工智能/机器学习选择退出协议在数据主权方面很有价值，但它再次为网站所有者带来了不利的情况，因为他们被大量最近需要考虑的临时标准压垮了。在我们的工作中，我们希望调查不同的提案、想法和举措，并在当前关于网络出版商控制的讨论的背景下提供全面的法律和技术背景。]]></description>
      <guid>https://arxiv.org/abs/2404.02309</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    </channel>
</rss>