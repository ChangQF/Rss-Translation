<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>GraphEx：基于图的广告主关键词推荐提取方法</title>
      <link>https://arxiv.org/abs/2409.03140</link>
      <description><![CDATA[arXiv:2409.03140v1 公告类型：新
摘要：在线卖家和广告商会为其列出的产品推荐关键词，他们竞标这些产品以提高销量。产生此类建议的一个流行范例是极端多标签分类 (XMC)，它涉及将关键词标记/映射到项目。我们概述了在电子商务平台上使用传统的基于项目查询的标记或映射技术进行关键词推荐的局限性。我们介绍了 GraphEx，这是一种基于图形的创新方法，它使用从项目标题中提取标记排列来向卖家推荐关键词。此外，我们证明，在实际应用中，依赖精确度/召回率等传统指标可能会产生误导，因此需要结合多种指标来评估实际场景中的表现。这些指标旨在评估关键词与项目的相关性以及买家拓展的潜力。GraphEx 的表现优于 eBay 的生产模型，实现了上述目标。它支持资源受限的生产环境中的近乎实时的推理，并可有效扩展到数十亿个项目。]]></description>
      <guid>https://arxiv.org/abs/2409.03140</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于联邦原型的对比学习用于隐私保护跨域推荐</title>
      <link>https://arxiv.org/abs/2409.03294</link>
      <description><![CDATA[arXiv:2409.03294v1 公告类型：新
摘要：跨域推荐 (CDR) 旨在通过从数据丰富的域中传输知识来提高稀疏域中的推荐准确性。然而，现有的 CDR 方法通常假设跨域的用户项目交互数据可用，忽略了用户隐私问题。此外，这些方法在稀疏重叠用户的情况下会降低性能，因为它们通常依赖于大量完全共享的用户来实现有效的知识传递。为了应对这些挑战，我们提出了一种基于联合原型的对比学习 (CL) 方法，用于隐私保护 CDR，称为 FedPCL-CDR。该方法利用不重叠的用户信息和原型来提高多域性能，同时保护用户隐私。FedPCL-CDR 包括两个模块：本地域（客户端）学习和全局服务器聚合。在本地域中，FedPCL-CDR 将所有用户数据聚类以学习代表性原型，有效利用非重叠用户信息并解决稀疏重叠用户问题。然后，它通过以 CL 方式使用从服务器返回的本地和全局原型来促进知识转移。同时，全局服务器从本地域聚合代表性原型以学习本地和全局原型。原型和联邦学习 (FL) 的结合可确保敏感用户数据保持分散，只有原型在域之间共享，从而保护用户隐私。使用两个真实世界数据集对四个 CDR 任务进行的大量实验表明，FedPCL-CDR 的表现优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2409.03294</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOBIUS：面向百度赞助搜索的下一代查询广告匹配</title>
      <link>https://arxiv.org/abs/2409.03449</link>
      <description><![CDATA[arXiv:2409.03449v1 公告类型：新
摘要：百度是中国最大的商业网络搜索引擎，每天为数亿在线用户提供各种各样的查询服务。为了构建高效的赞助搜索引擎，我们过去采用三层漏斗状结构，在低响应延迟的要求和计算资源的限制下，从数十亿广告候选中筛选和排序数百个广告。给定用户查询，顶部匹配层负责向下一层提供语义相关的广告候选，而底部的排名层则更关注这些广告的商业指标（例如，CPM，ROI等）。匹配和排名目标之间的明显分离导致较低的商业回报。Mobius 项目是为了解决这个严重的问题而成立的。这是我们首次尝试训练匹配层，通过直接从数十亿个查询广告对中预测 CTR（点击率），将 CPM 作为查询广告相关性之外的额外优化目标。具体来说，本文将详细说明我们如何采用主动学习来克服离线训练神经点击网络时匹配层点击历史的不足，以及如何使用 SOTA ANN 搜索技术更有效地检索广告（此处“ANN”代表近似最近邻搜索）。我们将解决方案贡献给 Mobius-V1，作为我们下一代查询广告匹配系统的第一个版本。]]></description>
      <guid>https://arxiv.org/abs/2409.03449</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HGAMN：用于百度地图多语言 POI 检索的异构图注意力匹配网络</title>
      <link>https://arxiv.org/abs/2409.03504</link>
      <description><![CDATA[arXiv:2409.03504v1 公告类型：新
摘要：人们对国际旅行的兴趣日益浓厚，这提高了以多种语言检索兴趣点的需求。这甚至比在出国旅行时用不熟悉的语言查找当地场所（如餐馆和风景名胜）更好。多语言 POI 检索使用户能够使用多种语言的查询以所需语言找到所需的 POI，已成为当今百度地图等全球地图应用程序不可或缺的功能。这项任务并非易事，因为有两个关键挑战：（1）访问稀疏性和（2）多语言查询-POI 匹配。为此，我们提出了一种异构图注意力匹配网络 (HGAMN) 来同时解决这两个挑战。具体而言，我们使用百度地图的搜索日志构建了一个包含两种类型节点的异构图：POI 节点和查询节点。为了缓解挑战 1，我们在不同的 POI 节点之间构建边，将低频 POI 与高频 POI 连接起来，从而实现知识从高频 POI 到高频 POI 的迁移。为了缓解挑战 2，我们根据查询和 POI 之间的共现关系在 POI 和查询节点之间构建边，其中不同语言和表述的查询可以针对单个 POI 进行聚合。此外，我们开发了一个基于注意力机制的网络来联合学习异构图的节点表示，并进一步设计了一个交叉注意力模块来融合两种类型节点的表示以进行查询-POI 相关性评分。在百度地图的大规模真实世界数据集上进行的大量实验证明了 HGAMN 的优越性和有效性。此外，HGAMN 已经在百度地图投入生产，并成功维持每天数亿次请求的服务。]]></description>
      <guid>https://arxiv.org/abs/2409.03504</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们相信他们说的话还是他们做的事？多模态用户嵌入提供个性化解释</title>
      <link>https://arxiv.org/abs/2409.02965</link>
      <description><![CDATA[arXiv:2409.02965v1 公告类型：交叉 
摘要：随着社交媒体的快速发展，分析社交网络用户数据的重要性也被提上日程。社交媒体中的用户表示学习是一个关键的研究领域，在此基础上我们可以进行个性化的内容传递，或者检测恶意行为者。社交网络用户数据比许多其他类型的数据更复杂，具有固有的多模态性质。已经提出了各种多模态方法来利用文本（即帖子内容）和关系（即用户间交互）信息来学习更高质量的用户嵌入。图神经网络模型的出现使得社交网络中用户文本嵌入和用户交互图的端到端集成成为可能。然而，大多数这些方法并没有充分阐明数据的哪些方面——文本或图结构信息——对预测特定任务下的每个特定用户更有帮助，这给个性化的下游分析和不可信的信息过滤带来了一些负担。我们为社交网络提出了一个简单而有效的框架，称为贡献感知多模态用户嵌入 (CAMUE)。我们已经通过经验证据证明，我们的方法可以提供个性化的可解释预测，自动减轻不可靠信息的影响。我们还进行了案例研究，以证明我们的结果是多么合理。我们观察到，对于大多数用户来说，图形结构信息比文本信息更值得信赖，但在某些情况下，文本更有帮助。我们的工作为更可解释、更可靠、更有效的社交媒体用户嵌入铺平了道路，从而可以更好地个性化内容交付。]]></description>
      <guid>https://arxiv.org/abs/2409.02965</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>iText2KG：使用大型语言模型构建增量知识图谱</title>
      <link>https://arxiv.org/abs/2409.03284</link>
      <description><![CDATA[arXiv:2409.03284v1 公告类型：交叉 
摘要：大多数可用数据都是非结构化的，因此很难获取有价值的信息。自动构建知识图谱 (KG) 对于结构化数据并使其可访问至关重要，可让用户有效地搜索信息。KG 还有助于洞察、推理和推理。传统的 NLP 方法（例如命名实体识别和关系提取）是信息检索的关键，但面临局限性，包括使用预定义的实体类型和需要监督学习。当前的研究利用大型语言模型的功能，例如零次或少量学习。然而，未解决和语义重复的实体和关系仍然带来挑战，导致图不一致并需要大量的后处理。此外，大多数方法都依赖于主题。在本文中，我们提出了 iText2KG，这是一种无需后处理的增量、主题独立的 KG 构建方法。这种即插即用的零样本方法适用于广泛的知识图谱构建场景，包含四个模块：文档提取器、增量实体提取器、增量关系提取器以及图谱集成器和可视化。我们的方法在三个场景中表现出比基线方法更好的性能：将科学论文转换为图谱、将网站转换为图谱以及将简历转换为图谱。]]></description>
      <guid>https://arxiv.org/abs/2409.03284</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 RAG 的上下文响应预测系统问答系统</title>
      <link>https://arxiv.org/abs/2409.03708</link>
      <description><![CDATA[arXiv:2409.03708v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在各种自然语言处理 (NLP) 任务中表现出多功能性，包括它们作为有效问答系统的潜力。然而，为了在行业环境中响应特定客户查询提供准确和相关的信息，LLM 需要访问全面的知识库以避免幻觉。检索增强生成 (RAG) 成为解决这一挑战的一种有前途的技术。然而，使用 RAG 为实际应用开发准确的问答框架面临几个挑战：1) 数据可用性问题，2) 评估生成内容的质量，3) 人工评估的成本高昂。在本文中，我们介绍了一个端到端框架，该框架将具有 RAG 功能的 LLM 用于行业用例。给定客户查询，所提出的系统将检索相关知识文档并利用它们以及以前的聊天记录，为大型零售公司的联络中心的客户服务代理生成响应建议。通过全面的自动化和人工评估，我们表明该解决方案在准确性和相关性方面优于当前基于 BERT 的算法。我们的研究结果表明，基于 RAG 的 LLM 可以减轻人工客户服务代表的工作量，从而为他们提供出色的支持。]]></description>
      <guid>https://arxiv.org/abs/2409.03708</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WildVis：百万级野外聊天日志的开源可视化工具</title>
      <link>https://arxiv.org/abs/2409.03753</link>
      <description><![CDATA[arXiv:2409.03753v1 公告类型：交叉 
摘要：现实世界对话数据的日益普及为研究人员研究用户与聊天机器人之间的互动提供了令人兴奋的机会。然而，这些数据的庞大数量使得手动检查单个对话变得不切实际。为了克服这一挑战，我们引入了 WildVis，这是一种能够快速、多功能和大规模对话分析的交互式工具。WildVis 根据一系列标准在文本和嵌入空间中提供搜索和可视化功能。为了管理百万级数据集，我们实施了优化，包括搜索索引构建、嵌入预计算和压缩以及缓存，以确保在几秒钟内响应用户交互。我们通过三个案例研究展示了 WildVis 的实用性：促进聊天机器人滥用研究、可视化和比较数据集中的主题分布以及描述用户特定的对话模式。WildVis 是开源的，设计为可扩展的，支持其他数据集和定制的搜索和可视化功能。]]></description>
      <guid>https://arxiv.org/abs/2409.03753</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>池化和注意力：基于 LLM 的嵌入模型的有效设计是什么？</title>
      <link>https://arxiv.org/abs/2409.02727</link>
      <description><![CDATA[arXiv:2409.02727v2 公告类型：replace-cross 
摘要：大型语言模型 (LLM) 在生成任务中的重大进步导致越来越多的工作探索基于 LLM 的嵌入模型。虽然这些采用不同池化和注意力策略的模型在公共嵌入基准上取得了最先进的性能，但仍然存在关于什么构成基于 LLM 的嵌入模型的有效设计的问题。然而，这些模型通常在不同的数据集上进行训练，使用不同的 LLM 基础模型或训练设置。此外，对公共嵌入基准的评估通常无法报告统计显着性，因此很难确定哪些设计真正有助于最终性能。这为寻求基于 LLM 的嵌入模型的最佳训练方案的从业者带来了复杂化的过程。在这项研究中，我们进行了一项大规模实验，通过使用相同的训练数据和基础模型（但在池化和注意力策略上有所不同）训练一系列基于 LLM 的嵌入模型。结果表明，没有一刀切的解决方案：虽然双向注意力和额外的可训练池化层在文本相似性和信息检索任务中表现出色，但它们在聚类和分类任务中并没有明显超越更简单的设计，如 EOS-last 标记池化和默认因果注意力。此外，我们提出了一种新的池化策略，即多层可训练池化，它使用交叉注意力网络转换所有隐藏层的输出，而不仅仅是最后一层。与现有的池化方法相比，该方法在文本相似性和检索任务中具有统计优势。总体而言，本文阐明了基于 LLM 的嵌入模型的有效训练策略。]]></description>
      <guid>https://arxiv.org/abs/2409.02727</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>