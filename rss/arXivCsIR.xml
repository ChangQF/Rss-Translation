<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过融合实体解码进行实体消歧</title>
      <link>https://arxiv.org/abs/2404.01626</link>
      <description><![CDATA[arXiv:2404.01626v1 公告类型：交叉
摘要：实体消歧（ED）将知识库中模糊实体的提及与其所指实体联系起来，是实体链接（EL）的核心组成部分。与标准化 ZELDA 基准下的分类方法相比，现有的生成方法显示出更高的准确性。然而，生成方法需要大规模预训练且生成效率低下。最重要的是，实体描述可能包含区分相似实体的关键信息，但常常被忽视。我们提出了一种编码器-解码器模型，以通过更详细的实体描述来消除实体的歧义。给定文本和候选实体，编码器学习文本和每个候选实体之间的交互，为每个候选实体生成表示。然后，解码器将候选实体的表示融合在一起并选择正确的实体。我们在各种实体消歧基准上进行的实验证明了该模型强大而稳健的性能，特别是与 GENRE 相比，在 ZELDA 基准中提高了 1.5%。此外，我们将此方法集成到检索/阅读器框架中，并观察到与 EntQA 相比，GERBIL 基准中的端到端实体链接提高了 1.5%。]]></description>
      <guid>https://arxiv.org/abs/2404.01626</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>再匹配：稳健高效的局部知识图匹配，提高结构和语义相似度</title>
      <link>https://arxiv.org/abs/2404.02126</link>
      <description><![CDATA[arXiv:2404.02126v1 公告类型：交叉
摘要：知识图在问答和事实检查等各种应用中发挥着关键作用。抽象含义表示（AMR）将文本表示为知识图。评估这些图表的质量涉及将它们在结构上相互匹配以及在语义上与源文本匹配。现有的 AMR 指标效率低下，并且难以捕获语义相似性。我们还缺乏评估 AMR 图之间结构相似性的系统评估基准。为了克服这些限制，我们引入了一种新颖的 AMR 相似性度量，即重新匹配，以及一种名为 RARE 的新的结构相似性评估。在最先进的指标中，复赛在结构相似性方面排名第二；在 STS-B 和 SICK-R 基准测试中，语义相似度领先 1--5 个百分点。重新匹配也比下一个最有效的指标快五倍。]]></description>
      <guid>https://arxiv.org/abs/2404.02126</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>超越是与否：通过对细粒度相关性标签进行评分来提高零样本法学硕士排名</title>
      <link>https://arxiv.org/abs/2310.14122</link>
      <description><![CDATA[arXiv:2310.14122v3 公告类型：替换
摘要：由最近的法学硕士支持的零样本文本排名器通过简单的提示即可实现显着的排名性能。现有的逐点 LLM 排名器提示大多要求模型从“是”和“否”等二元相关性标签中进行选择。然而，缺乏中间相关性标签选项可能会导致法学硕士为与查询部分相关的文档提供嘈杂或有偏见的答案。我们建议将细粒度的相关性标签合并到 LLM 排名器的提示中，使他们能够更好地区分与查询相关性不同级别的文档，从而得出更准确的排名。我们研究了提示模板的两种变体，以及不同数量的相关级别。我们在 8 个 BEIR 数据集上的实验表明，添加细粒度的相关标签可以显着提高 LLM 排名器的性能。]]></description>
      <guid>https://arxiv.org/abs/2310.14122</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>BERT-作业抄袭检测系统的增强检索工具</title>
      <link>https://arxiv.org/abs/2404.01582</link>
      <description><![CDATA[arXiv:2404.01582v1 公告类型：交叉
摘要：文本抄袭检测任务是一种常见的自然语言处理任务，旨在检测给定文本是否包含抄袭或抄袭其他文本。在现有的研究中，由于缺乏高质量的数据集，高水平抄袭的检测仍然是一个挑战。在本文中，我们提出了一种基于GPT-3.5的抄袭文本数据生成方法，该方法产生了32,927对文本抄袭检测数据集，涵盖了广泛的抄袭方法，弥补了这部分研究的空白。同时，我们提出了一种基于Faiss with BERT的高效率、高精度的抄袭识别方法。我们的实验表明，该模型的性能在多个指标上优于其他模型，包括准确度、精确度、召回率和 F1 分数分别为 98.86%、98.90%、98.86% 和 0.9888。最后，我们还提供了一个人性化的演示平台，允许用户上传文本库并直观地参与抄袭分析。]]></description>
      <guid>https://arxiv.org/abs/2404.01582</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>将法学硕士转变为跨模式和跨语言检索系统</title>
      <link>https://arxiv.org/abs/2404.01616</link>
      <description><![CDATA[arXiv:2404.01616v1 公告类型：交叉
摘要：大型语言模型（LLM）是在纯文本数据上进行训练的，这些数据远远超出了具有配对语音和文本数据的语言。与此同时，基于双编码器（DE）的检索系统将查询和文档投影到同一嵌入空间中，并证明了它们在检索和双文本挖掘方面的成功。为了匹配多种语言的语音和文本，我们建议使用 LLM 来初始化多模态 DE 检索系统。与传统方法不同，我们的系统在LLM预训练期间不需要语音数据，并且可以利用LLM的多语言文本理解能力来匹配检索训练期间未见过的语言的语音和文本。我们基于 LLM 的多模态检索系统能够匹配 102 种语言的语音和文本，尽管只接受了 21 种语言的训练。我们的系统优于之前经过所有 102 种语言明确训练的系统。这些语言的 Recall@1 平均绝对提高了 10%。此外，我们的模型演示了跨语言语音和文本匹配，并通过现成的机器翻译数据进一步增强了这一点。]]></description>
      <guid>https://arxiv.org/abs/2404.01616</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能和社交媒体分析发现 GLP-1 受体激动剂的不良副作用</title>
      <link>https://arxiv.org/abs/2404.01358</link>
      <description><![CDATA[arXiv:2404.01358v1 公告类型：交叉
摘要： FDA 批准后发现的药物不良副作用（ASE）对患者安全构成威胁。为了及时发现被忽视的 ASE，我们开发了一种数字健康方法，能够分析来自社交媒体、已发表的临床研究、制造商报告和 ChatGPT 的大量公共数据。我们发现了与胰高血糖素样肽 1 受体激动剂 (GLP-1 RA) 相关的 ASE，该市场预计到 2030 年将呈指数增长，达到 1,335 亿美元。使用命名实体识别 (NER) 模型，我们的方法成功检测到 21 种潜在的 ASE FDA 批准后被忽视，包括烦躁和麻木。我们的数据分析方法利用尖端的人工智能驱动的社交媒体分析，彻底改变了与新部署药物相关的未报告 ASE 的检测。它可以通过释放社交媒体的力量来支持监管机构和制造商快速发现隐藏的 ASE 风险，从而提高市场上新药的安全性。]]></description>
      <guid>https://arxiv.org/abs/2404.01358</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>OpenChemIE：化学文献信息提取工具包</title>
      <link>https://arxiv.org/abs/2404.01462</link>
      <description><![CDATA[arXiv:2404.01462v1 公告类型：交叉
摘要：从化学文献中提取信息对于构建数据驱动化学的最新反应数据库至关重要。完整的提取需要结合文本、表格和图形中的信息，而之前的工作主要研究从单一模式中提取反应。在本文中，我们提出 OpenChemIE 来解决这一复杂的挑战，并能够在文档级别提取反应数据。 OpenChemIE 分两步解决该问题：从各个模式中提取相关信息，然后整合结果以获得最终的反应列表。第一步，我们采用专门的神经模型，每个模型都解决化学信息提取的特定任务，例如从文本或图形中解析分子或反应。然后，我们使用化学信息算法整合这些模块的信息，从而可以从反应条件和底物范围研究中提取细粒度的反应数据。我们的机器学习模型在单独评估时达到了最先进的性能，并且我们精心注释了具有 R 基团的具有挑战性的反应方案数据集，以评估我们的整个流程，实现了 69.5% 的 F1 分数。此外，直接与 Reaxys 化学数据库进行比较时，我们的反应提取结果的准确度为 64.3%。我们以开源包的形式以及通过 Web 界面向公众免费提供 OpenChemIE。]]></description>
      <guid>https://arxiv.org/abs/2404.01462</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>用于自回归事件时态图生成的集合对齐框架</title>
      <link>https://arxiv.org/abs/2404.01532</link>
      <description><![CDATA[arXiv:2404.01532v1 公告类型：交叉
摘要：事件时间图已被证明是文本中事件之间复杂时间关系的方便有效的表示。最近的研究采用预先训练的语言模型自动回归生成线性图来构建事件时间图，已经显示出有希望的结果。然而，这些方法通常会导致图生成不理想，因为线性化图表现出集合特征，而这些特征是由语言模型顺序处理的。这种差异源于传统的文本生成目标，导致由于目标序列中的元素未对齐而导致对正确预测的错误惩罚。为了应对这些挑战，我们将任务重新定义为条件集生成问题，提出了一个专为有效利用大型语言模型（LLM）而定制的集对齐框架。该框架结合了数据增强和集合属性正则化，旨在减轻与线性化图边缘序列相关的文本生成损失惩罚，从而鼓励生成更多关系边缘。实验结果表明，我们的框架超越了事件时间图生成的现有基线。此外，在零样本设置下，通过我们的框架引入的结构知识显着提高了模型泛化能力，特别是当可用的训练示例有限时。]]></description>
      <guid>https://arxiv.org/abs/2404.01532</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>结合自然语言处理和机器学习检测财经新闻话语层面的时态性</title>
      <link>https://arxiv.org/abs/2404.01337</link>
      <description><![CDATA[arXiv:2404.01337v1 公告类型：交叉
摘要：彭博新闻、CNN Business 和福布斯等财经相关新闻是市场筛选系统的宝贵真实数据来源。在新闻中，专家分享的观点超出了简单的技术分析，包括政治、社会学和文化因素等背景。在同一篇文章中，专家经常讨论不同资产的表现。一些关键陈述仅仅是对过去事件的描述，而另一些则是预测。因此，了解文本中关键陈述的时间性对于将上下文信息与有价值的预测分开至关重要。我们提出了一种新颖的系统，可以在话语层面检测金融相关新闻的时效性，该系统结合了自然语言处理和机器学习技术，并利用句法和语义依赖性等复杂特征。更具体地说，我们试图提取主要陈述的主导时态，这些时态可以是明确的，也可以是隐含的。我们已经在由具有该领域知识的研究人员注释的金融相关新闻标记数据集上测试了我们的系统。实验结果表明，与替代的基于规则的基线方法相比，检测精度较高。最终，这项研究通过识别金融决策的预测知识，为最先进的市场筛选做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2404.01337</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在狄利克雷分配的主题建模自动检测财经新闻中的相关信息、预测和预测</title>
      <link>https://arxiv.org/abs/2404.01338</link>
      <description><![CDATA[arXiv:2404.01338v1 公告类型：交叉
摘要：财经新闻是非结构化信息源，可以挖掘这些信息来提取市场筛选应用的知识。从源源不断的金融相关新闻中手动提取相关信息非常麻烦，并且超出了许多投资者的技能范围，他们最多只能关注一些消息来源和作者。因此，我们专注于分析财经新闻，以识别相关文本，并在该文本中进行预测和预测。我们提出了一种新颖的自然语言处理（NLP）系统，通过考虑话语层面的相关性和暂时性，帮助投资者检测非结构化文本源中的相关金融事件。首先，我们对文本进行分段，将密切相关的文本分组在一起。其次，我们应用共同引用解析来发现段内的内部依赖关系。最后，我们使用潜在狄利克雷分配（LDA）进行相关主题建模，以将相关文本与不太相关的文本分开，然后使用面向机器学习的时间方法分析相关文本以识别预测和推测性陈述。我们创建了一个由 2,158 条财经新闻条目组成的实验数据集，这些新闻条目由 NLP 研究人员手动标记，以评估我们的解决方案。用于识别相关文本和预测/预测的 ROUGE-L 值分别为 0.662 和 0.982。据我们所知，这是第一篇在话语层面共同考虑相关性和时间性的工作。它通过结合多段落主题分割和共指解析来分离作者表达模式，使用 LDA 进行主题建模来检测相关文本，以及话语时序分析来识别预测和预测，从而有助于将人类联想话语能力转移到专家系统。文本中的预测。]]></description>
      <guid>https://arxiv.org/abs/2404.01338</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>下一步该何去何从：LLM 的零样本推广以实现下一个 POI 推荐</title>
      <link>https://arxiv.org/abs/2404.01855</link>
      <description><![CDATA[arXiv:2404.01855v1 公告类型：新
摘要：下一个兴趣点（POI）推荐为用户探索周围环境提供了有价值的建议。现有的研究依赖于从大规模用户的签到数据构建推荐模型，这是特定于任务的并且需要大量的计算资源。最近，预训练的大语言模型（LLM）在各种 NLP 任务中取得了显着的进步，并且还针对推荐场景进行了研究。然而，法学硕士的泛化能力仍有待探索，以解决下一个 POI 建议，其中应提取用户的地理移动模式。尽管有研究利用法学硕士来提出下一项建议，但他们未能考虑地理影响和顺序过渡。因此，他们无法有效地解决下一个 POI 推荐任务。为此，我们设计了新颖的提示策略并进行实证研究来评估 LLM（例如 ChatGPT）预测用户下次签到的能力。具体来说，我们考虑了人类运动行为的几个基本因素，包括用户地理偏好、空间距离和顺序转换，并将推荐任务制定为排名问题。通过对两个广泛使用的现实世界数据集进行广泛的实验，我们得出了几个关键发现。实证评估表明，LLM 具有良好的零样本推荐能力，并且可以提供准确合理的预测。我们还发现，法学硕士无法准确理解地理背景信息，并且对候选 POI 的呈现顺序敏感，这表明了法学硕士的局限性，需要进一步研究稳健的人员流动推理​​机制。]]></description>
      <guid>https://arxiv.org/abs/2404.01855</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>IISAN：通过解耦 PEFT 有效调整多模态表示以实现顺序推荐</title>
      <link>https://arxiv.org/abs/2404.02059</link>
      <description><![CDATA[arXiv:2404.02059v1 公告类型：新
摘要：多模态基础模型利用强大的表示学习功能，在顺序推荐系统中具有变革性。虽然参数高效微调 (PEFT) 通常用于调整推荐任务的基础模型，但大多数研究优先考虑参数效率，往往忽视 GPU 内存效率和训练速度等关键因素。为了解决这一差距，我们的论文引入了 IISAN（用于多模态表示的模内和模间侧自适应网络），这是一种简单的即插即用架构，使用解耦 PEFT 结构并利用模内和模间自适应。
  IISAN 的性能可与完全微调 (FFT) 和最先进的 PEFT 相媲美。更重要的是，它显着降低了多模式顺序推荐任务的 GPU 内存使用量，从 47GB 减少到仅 3GB。此外，与 FFT 相比，它还将每个 epoch 的训练时间从 443 秒缩短到 22 秒。这也是相对于 Adapter 和 LoRA 的显着改进，后者需要 37-39 GB GPU 内存和每个 epoch 350-380 秒的训练时间。
  此外，我们提出了一种新的复合效率指标 TPME（训练时间、参数和 GPU 内存效率），以减轻“参数效率代表整体效率”的普遍误解。 TPME 为不同方法之间的实际效率比较提供了更全面的见解。此外，我们还对所有 PEFT 和 FFT 方法进行了易于理解的效率分析，这证明了 IISAN 的优越性。我们在 https://github.com/jjGenAILab/IISAN 发布了我们的代码和其他材料。]]></description>
      <guid>https://arxiv.org/abs/2404.02059</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>规划和编辑您检索的内容以增强工具学习</title>
      <link>https://arxiv.org/abs/2404.00450</link>
      <description><![CDATA[arXiv:2404.00450v1 公告类型：交叉
摘要：最近在将外部工具与大型语言模型 (LLM) 集成方面取得的进展开辟了新的领域，在数学推理、代码生成器和智能助手方面都有应用。然而，现有的方法依赖于简单的一次性检索策略，无法有效、准确地筛选相关工具。本文介绍了一种新颖的 \modelname (\modelmeaning) 方法，包括“计划和检索（P\&amp;R）”和“编辑和基础（E\&amp;G）”范式。 P\&amp;R 范式由用于筛选相关工具的神经检索模块和基于 LLM 的查询规划器组成，该查询规划器将复杂的查询分解为可操作的任务，从而提高工具利用的有效性。 E\&amp;G 范式利用 LLM 根据用户场景丰富工具描述，弥合用户查询和工具功能之间的差距。实验结果表明，这些范式显着提高了工具检索任务中的召回率和 NDCG，显着超越了当前最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2404.00450</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>针对黑盒神经排序模型的多粒度对抗攻击</title>
      <link>https://arxiv.org/abs/2404.01574</link>
      <description><![CDATA[arXiv:2404.01574v1 公告类型：新
摘要：对抗性排名攻击因其在探测漏洞方面的成功而受到越来越多的关注，从而增强了神经排名模型的鲁棒性。传统的攻击方法对目标文档采用单一粒度（例如单词级或句子级）的扰动。然而，将扰动限制在单一粒度级别可能会降低创建对抗性示例的灵活性，从而减少攻击的潜在威胁。因此，我们专注于通过结合多粒度扰动来生成高质量的对抗性示例。实现这一目标涉及解决组合爆炸问题，这需要在所有可能的粒度、位置和文本片段级别上确定扰动的最佳组合。为了应对这一挑战，我们将多粒度对抗攻击转变为顺序决策过程，其中下一个攻击步骤中的扰动受到当前攻击步骤中扰动文档的影响。由于攻击过程只能在没有直接中间信号的情况下访问最终状态，因此我们使用强化学习来执行多粒度攻击。在强化学习过程中，两个代理协同工作，将多粒度漏洞识别为攻击目标，并将扰动候选者组织成最终的扰动序列。实验结果表明，我们的攻击方法在攻击有效性和不可察觉性方面都超过了主流基线。]]></description>
      <guid>https://arxiv.org/abs/2404.01574</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>CIRP：多模式产品捆绑的跨项目关系预训练</title>
      <link>https://arxiv.org/abs/2404.01735</link>
      <description><![CDATA[arXiv:2404.01735v1 公告类型：新
摘要：产品捆绑一直是一种流行的营销策略，在网上购物场景中是有益的。有效的产品捆绑方法取决于高质量的项目表示，这需要捕获各个项目的语义和跨项目关系。然而，以前的项目表示学习方法，无论是特征融合还是图学习，都存在跨模态对齐不足的问题，并且难以捕获冷启动项目的跨项目关系。鉴于多模态预训练模型在各种多模态下游任务上的良好表现，它们可能是潜在的解决方案。然而，在当前的多模态预训练模型中，跨项目关系尚未得到充分探索。为了弥补这一差距，我们提出了一种新颖且简单的框架跨项目关系预训练（CIRP），用于产品捆绑中的项目表示学习。具体来说，我们采用多模式编码器来生成图像和文本表示。然后，我们利用跨项目对比损失（CIC）和单个项目的图像文本对比损失（ITC）作为预训练目标。我们的方法寻求将跨项目关系建模功能集成到多模态编码器中，同时保留深度对齐的多模态语义。因此，即使对于没有关系的冷启动项，它们的表示仍然是关系感知的。此外，为了消除潜在的噪声并降低计算成本，我们利用关系剪枝模块来消除噪声和冗余关系。我们将 CIRP 提取的商品表示应用于产品捆绑模型 ItemKNN，并且在三个电子商务数据集上进行的实验表明 CIRP 优于各种领先的表示学习方法。]]></description>
      <guid>https://arxiv.org/abs/2404.01735</guid>
      <pubDate>Wed, 03 Apr 2024 06:16:42 GMT</pubDate>
    </item>
    </channel>
</rss>