<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>WavePulse：电台直播的实时内容分析</title>
      <link>https://arxiv.org/abs/2412.17998</link>
      <description><![CDATA[arXiv:2412.17998v1 公告类型：新
摘要：广播仍然是大众信息传播的普遍媒介，AM/FM 电台覆盖的美国人比基于智能手机的社交网络或直播电视还要多。越来越多的广播也通过互联网在线播放和访问。我们提出了 WavePulse，这是一个实时记录、记录和分析广播内容的框架。虽然我们的框架普遍适用，但我们在与专注于 2024 年总统大选的政治科学家团队的合作项目中展示了 WavePulse 的有效性。我们使用 WavePulse 在三个月内监控 396 个新闻广播电台的直播，处理了近 500,000 小时的音频流。这些流被转换成带时间戳的日记记录，并进行了分析以跟踪国家和州一级的关键政治科学问题的答案。我们的分析揭示了地方问题如何与国家趋势相互作用，从而提供了对信息流的洞察。我们的结果表明 WavePulse 在捕获和分析来自网络的广播直播内容方面非常有效。代码和数据集可在 \url{https://wave-pulse.io} 上访问。]]></description>
      <guid>https://arxiv.org/abs/2412.17998</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>物联网智能建筑中时间概率相关知识提取</title>
      <link>https://arxiv.org/abs/2412.18042</link>
      <description><![CDATA[arXiv:2412.18042v1 公告类型：新
摘要：智能建筑融合了各种新兴的物联网 (IoT) 应用，全面管理能源效率、人类舒适度、自动化和安全性。然而，知识提取框架的开发是基础。目前，缺乏统一且实用的框架来对建筑物内的异构传感器数据进行建模。在本文中，我们提出了一个实用的推理框架，用于提取智能建筑内的状态到事件知识。我们的建议包括基于物联网的 API 集成、本体模型设计和时间概率相关的知识提取方法。利用建筑拓扑本体 (BOT) 来构建建筑物内传感器和空间之间的空间关系。我们利用 Apache Jena Fuseki 的 SPARQL 服务器来存储和查询 RDF 三元组数据。可以提取两种类型的知识：基于时间戳的异常事件检测概率和基于时间间隔的多个事件结合概率。我们在真实的智能建筑环境中进行了实验（为期 78 天）。收集了灯光和电梯状态的数据以供评估。评估揭示了几个推断事件，例如房间占用、电梯轨迹跟踪以及两个事件的结合。检测到的事件计数和概率的数值展示了智能建筑中自动控制的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.18042</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对商品冷启动推荐进行快速调整</title>
      <link>https://arxiv.org/abs/2412.18082</link>
      <description><![CDATA[arXiv:2412.18082v1 公告类型：新
摘要：项目冷启动问题对于在线推荐系统至关重要，因为冷启动阶段的成功决定了项目是否可以转变为热门项目。提示学习是自然语言处理 (NLP) 中用于解决零样本或少样本问题的强大技术，已被用于推荐系统以应对类似的挑战。然而，现有的方法通常依赖于基于内容的属性或文本描述进行提示，我们认为这可能不是冷启动推荐的最佳方法，因为 1) 推荐任务存在语义差距，2) 热身项目引起的模型偏差为模型贡献了大部分正反馈，这是冷启动问题的核心，阻碍了冷启动项目的推荐质量。我们建议利用高价值的正反馈（称为尖峰反馈）作为提示信息，同时解决上述两个问题。我们通过实验证明，与现有作品中提出的内容描述相比，正反馈更适合作为提示信息，因为它可以弥补语义鸿沟。此外，我们提出了逐项个性化提示网络来编码峰值反馈，以缓解正反馈优势问题造成的模型偏差。在四个真实数据集上进行的大量实验证明了我们的模型优于最先进的方法。此外，PROMO 已成功部署在一个流行的短视频共享平台（一个拥有十亿用户规模的商业短视频应用程序）上，在冷启动场景中在各种商业指标上实现了显着的性能提升]]></description>
      <guid>https://arxiv.org/abs/2412.18082</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BRIDGE：通过指令驱动生成进行捆绑推荐</title>
      <link>https://arxiv.org/abs/2412.18092</link>
      <description><![CDATA[arXiv:2412.18092v1 公告类型：新
摘要：捆绑推荐旨在向用户推荐一组相互关联的项目。然而，多样化的交互类型和稀疏的交互矩阵通常会对以前的方法提出挑战，使其无法准确预测用户捆绑的采用情况。受远程监督策略和生成范式的启发，我们提出了一种用于捆绑推荐的新框架 BRIDGE。它由两个主要组件组成，即基于相关性的项目聚类和伪捆绑生成模块。受远程监督方法的启发，前者是在不使用外部数据的情况下生成更多辅助信息，例如有指导意义的项目聚类，以供训练。随后，将此信息与来自用户历史交互的协作信号聚合以创建伪“理想”捆绑包。此功能使 BRIDGE 能够探索捆绑包的各个方面，而不仅限于现有的现实世界捆绑包。它有效地弥合了用户想象力和预定义捆绑包之间的差距，从而提高了捆绑包推荐性能。实验结果验证了我们的模型在五个基准数据集上优于最先进的基于排名的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.18092</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从成对到排名：利用伪排名攀登理想的协同过滤阶梯</title>
      <link>https://arxiv.org/abs/2412.18168</link>
      <description><![CDATA[arXiv:2412.18168v1 公告类型：新
摘要：直观地说，理想的协同过滤 (CF) 模型应该从用户对所有项目的完整排名中学习，以做出最佳的 top-K 推荐。由于实践中缺乏这样的完整排名，大多数 CF 模型依赖成对损失函数来近似完整排名，导致巨大的性能差距。在本文中，我们使用多重序数分类概念提供了一种新颖的分析，以揭示成对近似与理想情况之间不可避免的差距。然而，在实践中弥合这一差距面临着两个艰巨的挑战：(1) 现实世界的数据集都不包含完整的排名信息；(2) 不存在能够消耗排名信息的损失函数。为了克服这些挑战，我们提出了一种伪排名范式 (PRP)，通过引入由原始噪声注入机制监督的伪排名来解决排名信息的缺乏问题。此外，我们提出了一种新的排名损失函数，旨在有效处理排名信息。为了确保我们的方法能够抵御伪排名中的潜在误差，我们为排名损失函数配备了基于梯度的置信度机制，以检测和缓解异常梯度。在四个真实数据集上进行的大量实验表明，PRP 的表现明显优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.18168</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解锁隐藏的宝藏：利用未标记的数据增强推荐</title>
      <link>https://arxiv.org/abs/2412.18170</link>
      <description><![CDATA[arXiv:2412.18170v1 公告类型：新
摘要：协同过滤 (CF) 是推荐系统的基石，但有效利用大量未标记数据是一项重大挑战。当前的研究重点是通过提取与负样本非常接近的子集来解决未标记数据的挑战。遗憾的是，其余数据被忽略，未能将这些宝贵信息完全整合到用户偏好的构建中。为了解决这一差距，我们引入了一种新颖的正-中-负 (PNN) 学习范式。PNN 引入了一个中性类，包含难以直接归类为正样本或负样本的复杂项目。通过基于这种三重部分排名训练模型，PNN 为学习复杂的用户偏好提供了一种有希望的解决方案。通过理论分析，我们将 PNN 与单向部分 AUC (OPAUC) 联系起来以验证其有效性。然而，实现 PNN 范式在技术上具有挑战性，因为：(1) 在没有监督信号的情况下，很难将未标记数据分类为中性或负面；(2) 不存在任何可以处理集合级三重排名关系的损失函数。为了应对这些挑战，我们提出了一种半监督学习方法，结合用户感知注意力模型来获取知识和细化分类。此外，一种具有两步质心排名方法的新型损失函数可以处理集合级排名。在四个真实数据集上进行的大量实验表明，当与 PNN 结合使用时，各种代表性 CF 模型可以持续显著地提高其性能。即使使用简单的矩阵分解，PNN 也可以实现与复杂的图神经网络相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.18170</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Molar：具有协同过滤对齐的多模态 LLM，用于增强序列推荐</title>
      <link>https://arxiv.org/abs/2412.18176</link>
      <description><![CDATA[arXiv:2412.18176v1 公告类型：新
摘要：顺序推荐 (SR) 系统在过去十年中发生了重大变化，从传统的协同过滤过渡到深度学习方法，最近又过渡到大型语言模型 (LLM)。虽然 LLM 的采用推动了实质性的进步，但这些模型本质上缺乏协同过滤信息，主要依赖于文本内容数据而忽略了其他模态，因此无法实现最佳推荐性能。为了解决这一限制，我们提出了 Molar，这是一个多模态大型语言顺序推荐框架，它将多种内容模态与 ID 信息相结合，以有效捕获协作信号。Molar 使用 MLLM 从文本和非文本数据中生成统一的项目表示，从而促进全面的多模态建模并丰富项目嵌入。此外，它通过后对齐机制整合了协同过滤信号，该机制将基于内容和基于 ID 的模型中的用户表示对齐，确保精确的个性化和强大的性能。通过将多模态内容与协同过滤洞察无缝结合，Molar 可以捕捉用户兴趣和上下文语义，从而实现卓越的推荐准确性。大量实验证明，Molar 的表现明显优于传统和基于 LLM 的基线，凸显了其在利用多模态数据和协同信号进行顺序推荐任务方面的优势。源代码可在 https://anonymous.4open.science/r/Molar-8B06/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.18176</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过压缩实现高效的长上下文语言模型检索</title>
      <link>https://arxiv.org/abs/2412.18232</link>
      <description><![CDATA[arXiv:2412.18232v1 公告类型：新
摘要：长上下文语言模型 (LCLM) 已成为执行信息检索 (IR) 的新范例，它通过在单一上下文中处理整个语料库来实现信息的直接提取和检索，展现出超越传统稀疏和密集检索方法的潜力。然而，在上下文中处理大量段落进行检索在计算上是昂贵的，并且在推理过程中处理它们的表示会进一步延长处理时间；因此，我们的目标是通过段落压缩使 LCLM 检索更高效，并可能更有效。具体来说，我们提出了一种针对 LCLM 检索量身定制的新压缩方法，该方法经过训练可以最大限度地提高检索性能，同时最大限度地缩短压缩段落的长度。为了实现这一点，我们生成了合成数据，其中压缩段落会自动创建并根据给定查询的检索成功率标记为已选择或已拒绝，然后我们通过偏好优化使用此数据训练提出的长上下文检索 (CoLoR) 压缩模型，同时在其上添加长度正则化损失以强制简洁。通过对 9 个数据集进行大量实验，我们表明 CoLoR 将检索性能提高了 6%，同时将上下文大小压缩了 1.91 倍。]]></description>
      <guid>https://arxiv.org/abs/2412.18232</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的推荐自动图构建框架</title>
      <link>https://arxiv.org/abs/2412.18241</link>
      <description><![CDATA[arXiv:2412.18241v1 公告类型：新
摘要：图神经网络 (GNN) 已成为从图结构数据中学习以进行推荐的最先进的方法。然而，大多数现有的基于 GNN 的推荐方法侧重于基于预定义图的模型结构和学习策略的优化，而忽略了图构建阶段的重要性。早期的图构建工作通常依赖于特定规则或众包，这些规则要么过于简单，要么过于劳动密集。最近的工作开始利用大型语言模型 (LLM) 来自动化图构建，因为它们具有丰富的开放世界知识和卓越的推理能力。然而，它们通常存在两个限制：(1) 全局视图不可见（例如，忽略上下文信息）和 (2) 构建效率低下。为此，我们引入了 AutoGraph，这是一个基于 LLM 的自动图构建框架，用于推荐。具体来说，我们首先使用 LLM 推断用户偏好和项目知识，并将其编码为语义向量。接下来，我们使用矢量量化从语义向量中提取潜在因素。然后将潜在因素作为额外节点合并以链接用户/项目节点，从而生成具有深入全局视图语义的图。我们进一步设计基于元路径的消息聚合以有效地聚合语义和协作信息。该框架与模型无关，并与不同的主干模型兼容。在三个真实数据集上进行的大量实验证明了 AutoGraph 与现有基线方法相比的有效性和效率。我们已经在华为广告平台部署了 AutoGraph，在线 A/B 测试中 RPM 提高了 2.69%，eCPM 提高了 7.31%。目前 AutoGraph 已被用作主要流量模型，服务于数亿人。]]></description>
      <guid>https://arxiv.org/abs/2412.18241</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RaSeRec：检索增强序列推荐</title>
      <link>https://arxiv.org/abs/2412.18378</link>
      <description><![CDATA[arXiv:2412.18378v1 公告类型：新 
摘要：尽管现行的监督和自监督学习 (SSL) 增强顺序推荐 (SeRec) 模型已经通过强大的神经网络架构实现了更高的性能，但我们认为它们仍然存在两个局限性：(1) 偏好漂移，其中基于过去数据训练的模型难以适应不断变化的用户偏好； (2) 内隐记忆，其中头部模式主导参数学习，使得回忆长尾变得更加困难。在这项工作中，我们探索了 SeRec 中的检索增强，以解决这些限制。为此，我们提出了一个检索增强顺序推荐框架，名为 RaSeRec，其主要思想是维护一个动态存储库以适应偏好漂移并检索相关记忆以明确增强用户建模。它包括两个阶段：(i) 基于协作的预训练，学习推荐和检索； (ii) 检索增强微调，学习利用检索到的记忆。在三个数据集上进行的大量实验充分证明了 RaSeRec 的优越性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.18378</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>交互式推荐的对比表示</title>
      <link>https://arxiv.org/abs/2412.18396</link>
      <description><![CDATA[arXiv:2412.18396v1 公告类型：新
摘要：交互式推荐 (IR) 最近因其能够快速捕捉动态兴趣并优化短期和长期目标而受到广泛关注。IR 代理通常通过深度强化学习 (DRL) 实现，因为 DRL 本质上与 IR 的动态特性兼容。然而，DRL 目前并不完美适用于 IR。由于动作空间大和样本效率低下的问题，训练 DRL 推荐代理具有挑战性。关键点在于无法提取有用的特征作为推荐代理优化其策略的高质量表示。为了解决这个问题，我们提出了交互式推荐的对比表示 (CRIR)。CRIR 有效地从显式交互中提取潜在的高级偏好排名特征，并利用这些特征来增强用户的表示。具体来说，CRIR 通过一个表示网络提供表示，并通过我们提出的偏好排名对比学习 (PRCL) 对其进行细化。 PRCL 的关键见解是它可以执行对比学习，而无需依赖涉及高级表示或大型潜在动作集的计算。此外，我们还提出了一种数据利用机制和一种代理训练机制，以便更好地将 CRIR 适应 DRL 主干。已经进行了大量的实验，以证明我们的方法在训练基于 DRL 的 IR 代理时对样本效率的卓越改进。]]></description>
      <guid>https://arxiv.org/abs/2412.18396</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合知识编辑以丰富信息并提升概率</title>
      <link>https://arxiv.org/abs/2412.17872</link>
      <description><![CDATA[arXiv:2412.17872v1 公告类型：交叉 
摘要：大型语言模型中存储的知识需要及时更新以反映现实世界信息的动态性质。为了更新知识，大多数知识编辑方法都侧重于低层，因为最近对知识回忆过程的调查表明，答案信息在低层得到了丰富。然而，这些探测只能揭示原始答案的关键回忆阶段，而编辑的目标是纠正模型对目标答案的预测。这种不一致表明探测方法和相关的编辑方法都存在缺陷。为了缓解不一致并识别关键的编辑区域，我们提出了一种基于对比的探测方法，并找到了模型行为在原始答案和目标答案之间出现分歧的两个关键阶段：低层的信息丰富和高层的概率提升。基于这些见解，我们开发了联合知识编辑信息丰富和概率提升 (JEEP) 方法，该方法联合编辑低层和高层以修改两个关键的回忆阶段。考虑到双重修改导致的相互干扰和遗忘增加，JEEP 旨在确保对不同区域的更新具有相同的目标并且是互补的。我们通过在各种模型（即 GPT-J (6B) 和 LLaMA (7B)）上编辑多达数千个事实并解决各种编辑目标（即添加事实和反事实知识）来严格评估 JEEP。在所有测试场景中，JEEP 都实现了最佳性能，验证了我们的探测方法的揭示和编辑方法的设计的有效性。我们的代码和数据可在 https://github.com/Eric8932/JEEP 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.17872</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双向主题匹配：通过主题建模量化语料库之间的主题重叠</title>
      <link>https://arxiv.org/abs/2412.18376</link>
      <description><![CDATA[arXiv:2412.18376v1 公告类型：交叉 
摘要：本研究介绍了双向主题匹配 (BTM)，这是一种跨语料库主题建模的新方法，可量化语料库之间的主题重叠和分歧。BTM 是一个灵活的框架，可以结合各种主题建模方法，包括 BERTopic、Top2Vec 和潜在狄利克雷分配 (LDA)。BTM 采用双模型方法，为每个语料库训练单独的主题模型并相互应用它们以实现全面的跨语料库比较。这种方法有助于识别共享主题和独特主题，从而提供对主题关系的细致入微的见解。通过基于余弦相似度的方法进行验证，证明了 BTM 的稳健性，具有强大的一致性指标和处理异常主题的明显优势。关于气候新闻文章的案例研究展示了 BTM 的实用性，揭示了专注于气候变化和气候行动的语料库之间的显著主题重叠和区别。 BTM 的灵活性和精确性使其成为从政治话语分析到跨学科研究等各种应用的宝贵工具。通过整合共享和独特主题分析，BTM 提供了一个探索主题关系的综合框架，并可能扩展到多语言和动态数据集。这项工作突出了 BTM 的方法贡献及其在各个领域推进话语分析的能力。]]></description>
      <guid>https://arxiv.org/abs/2412.18376</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GeAR：用于检索增强生成的图形增强代理</title>
      <link>https://arxiv.org/abs/2412.18431</link>
      <description><![CDATA[arXiv:2412.18431v1 公告类型：交叉
摘要：检索增强生成系统依赖于有效的文档检索功能。从设计上讲，传统的稀疏或密集检索器在多跳检索场景中面临挑战。在本文中，我们介绍了 GeAR，它通过两项关键创新提高了 RAG 性能：(i) 图形扩展，增强了任何传统的基础检索器，例如 BM25，以及 (ii) 包含图形扩展的代理框架。我们的评估证明了 GeAR 在三个多跳问答数据集上的卓越检索性能。此外，我们的系统在具有挑战性的 MuSiQue 数据集上取得了最先进的结果，改进率超过 10%，同时与其他多步检索系统相比，需要更少的标记和迭代。]]></description>
      <guid>https://arxiv.org/abs/2412.18431</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMTreeRec：释放大型语言模型的强大功能以实现冷启动推荐</title>
      <link>https://arxiv.org/abs/2404.00702</link>
      <description><![CDATA[arXiv:2404.00702v3 Announce Type: replace 
摘要：由于训练数据的缺乏，推荐系统容易出现系统冷启动问题，难以提供有效的推荐。为了解决这个问题，大型语言模型（LLM）可以将推荐任务建模为语言分析任务，并基于其庞大的开放世界知识提供零样本结果。然而，项目语料库的规模对LLM提出了挑战，导致大量的token消耗，使其无法在现实世界的推荐系统中部署。为了应对这一挑战，我们引入了一个基于树的LLM推荐框架LLMTreeRec，它将所有项目结构化为项目树，以提高LLM的项目检索效率。LLMTreeRec在两个广泛使用的数据集上的系统冷启动设置下实现了最先进的性能，甚至可以与使用大量训练数据的传统深度推荐系统相媲美。此外，LLMTreeRec在华为工业系统的A/B测试中优于基线模型。因此，LLMTreeRec 证明了其作为行业友好型解决方案的有效性，并且已成功部署到网上。我们的代码可在以下网址获取：https://github.com/Applied-Machine-Learning-Lab/LLMTreeRec。]]></description>
      <guid>https://arxiv.org/abs/2404.00702</guid>
      <pubDate>Wed, 25 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>