<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 — 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Mon, 29 Jan 2024 03:14:06 GMT</lastBuildDate>
    <item>
      <title>基于生成大语言模型的上下文驱动的交互式查询模拟。 （arXiv：2312.09631v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.09631</link>
      <description><![CDATA[模拟用户交互可以实现更加面向用户的评估
信息检索（IR）系统。虽然用户模拟具有成本效益
并且可重复，许多方法通常缺乏对真实用户的保真度
行为。最值得注意的是，当前的用户模型忽略了用户的上下文，这
是感知相关性和与对象交互的主要驱动力
搜索结果。为此，本文引入了模拟
上下文驱动的查询重构。提出的查询生成方法
基于最新的大型语言模型 (LLM) 方法并考虑用户的
整个搜索会话模拟过程中的上下文。相比简单
上下文无关的查询生成方法，这些方法表现更好
有效性并允许模拟更高效的 IR 会话。
同样，我们的评估比当前考虑更多的交互环境
基于会话的测量并揭示有趣的补充见解
除了既定的评估协议之外。我们以指示结束
为未来的工作提供一个完全开放的实验设置。
]]></description>
      <guid>http://arxiv.org/abs/2312.09631</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:05 GMT</pubDate>
    </item>
    <item>
      <title>基于 GNN 的推荐中针对边缘级扰动的公平鲁棒性。 （arXiv：2401.13823v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2401.13823</link>
      <description><![CDATA[推荐社区的努力正在从单一的重点转向
考虑效用以外的因素，例如公平性和
鲁棒性。推荐模型的稳健性通常与其
受到攻击时保持原有效用的能力。有限的
研究探索了推荐模型的稳健性
公平性，例如，受到攻击的群体之间的绩效平等
场景。在本文中，我们的目标是评估基于图的鲁棒性
当受到基于以下内容的攻击时，涉及公平性的推荐系统
边缘级扰动。为此，我们考虑了四种不同的公平性
运营化，包括消费者和提供商的观点。
对三个数据集的实验揭示了扰动对
有针对性的公平理念，揭示现有评估的主要缺陷
协议的稳健性。例如，我们观察到扰动影响
消费者公平性高于供应商公平性，令人震惊
对前者不公平。源代码：
https://github.com/jackmedda/CPFairRobust
]]></description>
      <guid>http://arxiv.org/abs/2401.13823</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:05 GMT</pubDate>
    </item>
    <item>
      <title>学习检索大型语言模型的上下文示例。 （arXiv：2307.07164v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2307.07164</link>
      <description><![CDATA[大型语言模型 (LLM) 已证明其学习能力
在上下文中，允许他们根据一些输入输出执行各种任务
例子。然而，情境学习的有效性很大程度上取决于
取决于所选示例的质量。在本文中，我们提出了一部小说
迭代训练能够识别高质量的密集检索器的框架
法学硕士的上下文示例。我们的框架最初训练奖励模型
根据LLM的反馈来评估候选实例的质量，然后
通过知识蒸馏来训练基于双编码器的密集检索器。我们的
对一组 30 美元任务的实验表明，我们的框架
显着提高情境学习绩效。此外，我们还展示了
我们的框架对训练期间看不见的任务的泛化能力。一个
深入分析表明，我们的模型通过检索来提高性能
具有相似模式的例子，并且各法学硕士的收益是一致的
尺寸不同。代码和数据可在
https://github.com/microsoft/LMOps/tree/main/llm_retriever 。
]]></description>
      <guid>http://arxiv.org/abs/2307.07164</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行表示学习以进行推荐。 （arXiv：2310.15950v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2310.15950</link>
      <description><![CDATA[受以下因素的影响，推荐系统取得了显着的进步
深度学习和图神经网络，特别是在捕获复杂的
用户-项目关系。然而，这些基于图的推荐器很大程度上依赖于
基于 ID 的数据，可能会忽略有价值的文本信息
与用户和项目相关联，导致学到的信息较少
交涉。此外，隐式反馈数据的利用引入了
潜在的噪音和偏差，给用户的有效性带来挑战
偏好学习。将大型语言模型（LLM）集成到
传统的基于 ID 的推荐系统受到了关注，但面临以下挑战：
可扩展性问题、纯文本依赖的限制和提示输入
需要解决实际中有效实施的制约因素
推荐系统。为了应对这些挑战，我们提出了一种与模型无关的模型
RLMRec 框架，旨在通过 LLM 授权增强现有推荐系统
表征学习。它提出了一种集成的推荐范式
使用法学硕士进行表示学习以捕获用户复杂的语义方面
行为和偏好。 RLMRec 结合了辅助文本信号，
开发由法学硕士授权的用户/项目分析范例，并调整
法学硕士的语义空间与协作的表示空间
通过跨视图对齐框架的关系信号。这项工作进一步
建立理论基础，证明结合文本
通过互信息最大化提高信号的质量
交涉。在我们的评估中，我们将 RLMRec 与最先进的技术相结合
推荐模型，同时还分析其效率和对噪声的鲁棒性
数据。我们的实施代码可在
https://github.com/HKUDS/RLMRec。
]]></description>
      <guid>http://arxiv.org/abs/2310.15950</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>JetBrains IDE 中基于嵌入的搜索。 （arXiv：2401.14975v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2401.14975</link>
      <description><![CDATA[大多数现代集成开发环境 (IDE) 和代码编辑器都具有
在开放的环境中搜索可用功能和项目的功能
项目。在 JetBrains IDE 中，此功能称为 Search Everywhere：它允许
用户搜索文件、操作、类、符号、设置和任何内容
来自单个入口点的 VCS 历史记录。然而，它可以与
通过不考虑语义的算法获得的候选者，例如，
同义词、复杂的单词排列、词性修改，以及
打字错误。在这项工作中，我们描述了我们实施的机器学习方法
提高搜索项目的可发现性。我们也有共同的障碍
在这个过程中遇到了什么以及我们是如何克服的。
]]></description>
      <guid>http://arxiv.org/abs/2401.14975</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:03 GMT</pubDate>
    </item>
    <item>
      <title>扰动有助于降低投资风险吗？通过分割变分对抗训练进行风险意识股票推荐。 （arXiv：2304.11043v2 [q-fin.RM] 已更新）</title>
      <link>http://arxiv.org/abs/2304.11043</link>
      <description><![CDATA[在股票市场上，成功的投资需要在以下因素之间取得良好的平衡：
利润和风险。基于学习排序范式，股票推荐
在量化金融领域已被广泛研究以推荐具有较高估值的股票
投资者的回报率。尽管努力盈利，许多现有的
推荐方法在风险控制方面仍然存在一定的局限性，
在实际股票投资中可能会导致难以忍受的账面损失。到
有效降低风险，我们从对抗性学习中汲取灵感并
提出一种新颖的分割变分对抗训练（SVAT）方法
具有风险意识的股票推荐。本质上，SVAT鼓励存量模式
对风险股票示例的对抗性扰动敏感
通过从扰动中学习来增强模型的风险意识。生成
代表性的对抗性例子作为风险指标，我们设计了一个变分
扰动发生器来模拟不同的风险因素。特别是，
变分架构使我们的方法能够提供粗略的风险
为投资者进行量化，显示出额外的优势
可解释性。对几个真实世界股票市场数据集的实验
证明我们的 SVAT 方法的优越性。通过降低波动性
股票推荐模型，SVAT有效降低投资风险
在以下方面优于最先进的基线 30% 以上
风险调整后的利润。所有实验数据和源代码均可用
在
https://drive.google.com/drive/folders/14AdM7WENEvIp5x5bV3zV_i4Aev21C9g6?usp=sharing。
]]></description>
      <guid>http://arxiv.org/abs/2304.11043</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:03 GMT</pubDate>
    </item>
    <item>
      <title>噪声的力量：重新定义 RAG 系统的检索。 （arXiv：2401.14887v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14887</link>
      <description><![CDATA[检索增强生成（RAG）系统代表了重要的
相对于传统大型语言模型（LLM）的进步。 RAG 系统增强
通过合并通过检索的外部数据来生成它们的能力
信息检索（IR）阶段，克服标准法学硕士的局限性，
这仅限于他们预先训练的知识和有限的上下文窗口。
该领域的大多数研究主要集中在生成
RAG 系统内的法学硕士方面。我们的研究彻底地填补了这一空白
批判性地分析 IR 组件对 RAG 系统的影响。这张纸
分析猎犬应具备哪些特征才能有效
RAG 的及时制定，重点关注应提交的文件类型
检索到。我们评估各种要素，例如文档的相关性
提示、它们的位置以及上下文中包含的数字。我们的
调查结果显示，除其他见解外，包括不相关的文件可以
意外地将性能提高了 30% 以上，准确度与此相矛盾
我们最初假设质量下降。这些发现要求
制定适合特定需求的专门方法
将检索与语言生成模型相结合，并为
未来的研究。这些结果强调需要开发专门的
将检索与语言生成模型相结合的策略，从而
为今后该领域的研究奠定基础。
]]></description>
      <guid>http://arxiv.org/abs/2401.14887</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>用于数十亿级在线推荐系统的宏观图神经网络。 （arXiv：2401.14939v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14939</link>
      <description><![CDATA[预测十亿规模推荐系统中的点击率 (CTR)
由于以下原因，对图神经网络（GNN）提出了长期的挑战
聚合数十亿个数据所涉及的压倒性计算复杂性
邻居。为了解决这个问题，基于 GNN 的 CTR 模型通常会采样数百个
邻居们拿出数十亿来促进高效的在线推荐。
然而，仅对一小部分邻居进行采样会导致严重的后果
抽样偏差和未能涵盖用户或项目的全部范围
行为模式。为了应对这一挑战，我们将传统的
用户-项目推荐图作为“微推荐图”并引入
更适合十亿规模的宏推荐图（MAG）
建议。 MAG 解决了计算复杂度问题
将节点数量从数十亿减少到数百个。
具体来说，MAG 将具有相似行为的微节点（用户和项目）分组
模式形成宏节点。随后，我们介绍定制的Macro Graph
神经网络（MacGNN）在宏观层面上聚合信息并进行修正
宏节点的嵌入。 MacGNN 已经为淘宝首页提供服务
两个月来，为超过十亿用户提供了推荐。广泛的
对三个公共基准数据集和一个工业数据集进行离线实验
数据集显示 MacGNN 显着优于 12 个 CTR 基线
同时保持计算效率。此外，在线 A/B 测试证实
MacGNN 在十亿级推荐系统中的优势。
]]></description>
      <guid>http://arxiv.org/abs/2401.14939</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>分析宏观经济因素对英国银行业信用风险的影响。 （arXiv：2401.14943v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14943</link>
      <description><![CDATA[宏观经济因素对银行信用风险有着至关重要的影响，
不能由银行直接控制，因此需要一个
基于宏观经济的信用风险早期预警体系。通过比较
不同的预测模型（传统统计和机器学习
算法），本研究旨在检验宏观经济决定因素的影响
关于英国银行业信用风险并评估最准确的信用风险估计
使用预测分析。本研究发现基于方差
多分裂决策树算法是最精确的预测模型
结果可解释、可靠且稳健。我们的模型性能达到了 95%
准确性并证明失业率和通货膨胀率显着
英国银行业背景下的信用风险预测。我们的研究结果提供了
有价值的见解，例如信用风险与
通货膨胀、失业率和国民储蓄，以及负值
信用风险与国债、贸易逆差总额之间的关系
国民收入。此外，我们凭经验证明了之间的关系
国民储蓄和不良贷款，从而证明了节俭的悖论。
这些发现有利于信用风险管理团队监控
宏观经济因素阈值并实施关键改革以缓解
信用风险。
]]></description>
      <guid>http://arxiv.org/abs/2401.14943</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:02 GMT</pubDate>
    </item>
    <item>
      <title>挑战社会推荐中的低同质性。 （arXiv：2401.14606v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14606</link>
      <description><![CDATA[利用社交关系来解决用户-项目的稀疏问题
社会同质性假设下的推荐交互数据。
然而，社交推荐范式主要关注基于同质性的
关于用户偏好。虽然社交信息可以增强推荐，但它
无法保证与用户偏好的一致性，从而存在以下风险：
引入信息冗余。我们凭经验发现，社会
真实推荐数据中的图表表现出较低的偏好感知同质性，
这限制了社交推荐模型的效果。为全面
提取社交图中潜在的偏好感知同质信息，我们
提出社会异质性缓解重新布线（SHARe），这是一种以数据为中心的方法
用于增强现有基于图的社交推荐模型的框架。我们
采用Graph Rewiring技术捕获并添加高度同质的社交
关系，并减少低度的同性（或异性）关系。为了更好的细化
来自可靠社会关系的用户表示，我们整合了
将对比学习方法引入SHARe的训练中，旨在校准
用于增强图重新布线结果的用户表示。实验
现实世界的数据集表明，所提出的框架不仅表现出增强的
跨不同同质性比率的性能，而且还提高了性能
现有最先进（SOTA）的社交推荐模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.14606</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:01 GMT</pubDate>
    </item>
    <item>
      <title>用于跨域推荐的快速增强联合内容表示学习。 （arXiv：2401.14678v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14678</link>
      <description><![CDATA[跨域推荐（CDR）作为一种有效的技术
近年来，缓解数据稀疏问题得到了广泛的研究。
然而，以前的工作可能会导致域隐私泄露，因为它们需要
将不同领域的数据聚合到一个集中式服务器中
培训过程。尽管有几项研究进行了隐私保护 CDR
通过联邦学习（FL），它们仍然具有以下局限性：1）它们
需要将用户的个人信息上传到中心服务器，构成
泄露用户隐私的风险。 2）现有的联邦方法主要依赖
原子项目 ID 来表示项目，这会阻止它们对项目进行建模
统一的特征空间，增加了知识转移的挑战
域。 3）都是以了解重叠用户为前提
域之间，这在实际应用中被证明是不切实际的。到
针对上述限制，我们重点关注跨域隐私保护
建议（PCDR）并提出 PFCR 作为我们的解决方案。对于限制 1，我们
通过专门利用用户与本地的交互来开发 FL 模式
客户端并设计一种梯度加密的加密方法。为了
限制 2，我们通过描述在通用特征空间中对项目进行建模
文本。对于限制 3，我们首先学习联合内容表示，
利用自然语言的通用性在不同语言之间建立桥梁
域。随后，我们制定了两个及时的微调策略来定制
目标域的预训练模型。对两个真实世界进行了大量实验
数据集证明了我们的 PFCR 方法相对于 SOTA 的优越性
接近。
]]></description>
      <guid>http://arxiv.org/abs/2401.14678</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:01 GMT</pubDate>
    </item>
    <item>
      <title>使用中级感知特征和情感词嵌入进行表达感知音乐表演检索。 （arXiv：2401.14826v1 [cs.SD]）</title>
      <link>http://arxiv.org/abs/2401.14826</link>
      <description><![CDATA[本文探讨了跨模态音乐检索的特定子任务。我们
考虑检索表演或演绎的微妙任务
基于对其风格、表现特征的描述的音乐作品，或
同一作品的一系列不同表演所产生的情感。我们观察到
一个通用的跨模式系统，经过训练可以学习通用的文本音频
嵌入空间不会为此任务产生最佳结果。通过介绍
两项更改——文本编码器和音频编码器各一项——我们
在钢琴演奏数据集上展示改进的演奏以及
相关的自由文本描述。在文字方面，我们使用情感丰富的
词嵌入（EWE），在音频方面，我们提取中级感知
功能而不是通用的音频嵌入。我们的结果凸显了
从音乐和情感中学到的中级感知特征的有效性
在捕捉音乐时从带有情感标签的文本中学习到丰富的词嵌入
跨模式设置中的表达。此外，我们的可解释中级
特征提供了在检索和检索中引入可解释性的途径
下游推荐流程。
]]></description>
      <guid>http://arxiv.org/abs/2401.14826</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:01 GMT</pubDate>
    </item>
    <item>
      <title>去中心化 POI 推荐中的物理轨迹推理攻击与防御。 （arXiv：2401.14583v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14583</link>
      <description><![CDATA[作为基于位置的社交中不可或缺的个性化服务
网络（LBSN），兴趣点（POI）建议旨在帮助
个人发现有吸引力和引人入胜的地方。但是，那
精准推荐能力依赖于强大的服务器采集
海量用户历史签到数据，存在重大风险
侵犯隐私。尽管一些协作学习（CL）框架
POI推荐增强推荐弹性，让用户持续关注
设备上的个人数据，他们仍然分享个人知识以改进
推荐性能，从而留下潜在的漏洞
攻击者。鉴于此，我们设计了一种新的物理轨迹推理攻击
（PTIA）公开用户的历史轨迹。具体来说，对于每个用户来说，
我们通过分析聚合信息来识别一组交互的 POI
来自目标 POI 及其相关 POI。我们评估有效性
跨两种去中心化 CL 的两个真实数据集上的 PTIA
POI推荐框架。实证结果表明 PTIA
对用户的历史轨迹构成重大威胁。此外，
本地差分隐私（LDP），传统的隐私保护方法
CL 框架也被证明对 PTIA 无效。有鉴于此，
我们提出了一种基于对抗性的针对 PTIA 的新型防御机制（AGD）
游戏消除敏感 POI 及其相关 POI 中的信息。
经过大量实验，AGD 被证明是精确且有效的。
实用，对推荐性能的影响最小。
]]></description>
      <guid>http://arxiv.org/abs/2401.14583</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:00 GMT</pubDate>
    </item>
    <item>
      <title>按结果集多样化进行新近度排名。 （arXiv：2401.14595v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.14595</link>
      <description><![CDATA[在本文中，我们提出了一种自动网络搜索检索方法
检测新近敏感查询并增加普通查询的新鲜度
文档排名的程度与需要的概率成正比
最近的内容。我们建议通过使用结果来解决新近度排名问题
多样化原则并处理查询的非主题歧义
当最近内容的需求只能通过以下方式检测到时出现
不确定。我们的离线和在线实验涉及数以百万计的查询
真实的搜索引擎用户表现出满意度的显着提高
向用户展示由我们的方法生成的搜索结果。
]]></description>
      <guid>http://arxiv.org/abs/2401.14595</guid>
      <pubDate>Mon, 29 Jan 2024 03:14:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应机器翻译的语言建模方法。 （arXiv：2401.14559v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.14559</link>
      <description><![CDATA[一致性是高质量翻译的关键要求。这是
尤其重要的是遵守预先批准的术语并适应
更正了特定领域项目中的翻译。机器翻译（MT）
在领域适应领域取得了重大进展。然而，
领域内数据稀缺在翻译环境中很常见，因为缺乏
专业数据集和术语，或不一致和不准确
可用的域内翻译。在这种资源不足的场景下
域内数据来微调机器翻译模型，生成的翻译
与相关背景保持一致是具有挑战性的。在实时适应的同时
可以利用少量的域内数据来改进翻译
苍蝇，由于支持的上下文限制，它仍然具有挑战性
效率限制。大型语言模型（LLM）最近表明
情境学习的有趣能力，他们学会复制
某些输入输出文本生成模式，无需进一步微调。
这些功能为特定领域的数据开辟了新的视野
增强和实时自适应机器翻译。这项工作试图解决两个主要问题
相关问题：1）在涉及人机交互和连续的场景中
反馈，我们能否利用语言模型来提高自适应机器翻译的质量
在推理时？ 2）在缺乏足够的域内数据的情况下，我们能否
使用预训练的大规模语言模型来改进MT领域的流程
适应？
]]></description>
      <guid>http://arxiv.org/abs/2401.14559</guid>
      <pubDate>Mon, 29 Jan 2024 03:13:59 GMT</pubDate>
    </item>
    </channel>
</rss>