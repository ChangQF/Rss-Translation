<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Thu, 21 Dec 2023 06:17:52 GMT</lastBuildDate>
    <item>
      <title>高效的标题重排序器，可实现快速且改进的知识密集型 NLP。 （arXiv：2312.12430v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.12430</link>
      <description><![CDATA[我们通过广播查询编码器引入高效标题重排器，这是一本小说
标题重新排名技术可将有效的标题重新排名速度提高 20 倍至 40 倍
比香草通道重新排序。然而，培训的挑战之一
Efficient Title Reranker 的缺点是不稳定。分析问题我们发现
一些非常困难的基本事实可能会充当噪声标签，导致准确性下降
下降以及模型概率输出中的一些极值导致 nan。到
为了解决这些问题，我们引入了 Sigmoid 技巧，这是一种新颖的技术
减少两种情况的梯度更新，从而实现更好的检索
功效。实验证明了 ETR 和 sigmoid 技巧的有效性，因为我们
在短裙知识基准上取得了四个最先进的位置。
]]></description>
      <guid>http://arxiv.org/abs/2312.12430</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型进行多领域点击率预测的统一框架。 （arXiv：2312.10743v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.10743</link>
      <description><![CDATA[点击率 (CTR) 预测是在线领域的一项关键任务
推荐平台，因为它涉及估计用户的概率
通过点击广告或物品来参与其中。鉴于
提供各种服务，例如在线购物、拼车、食品
商业平台的交付和专业服务、推荐
这些平台中的系统需要跨多个平台进行点击率预测
域而不仅仅是单个域。但是，多域点击
率（MDCTR）预测仍然是在线推荐中的一项具有挑战性的任务，因为
域之间复杂的相互影响。传统MDCTR模型
通常将域编码为离散标识符，忽略丰富的语义
信息基础。因此，他们很难推广到新的
域。此外，现有模型很容易被某些特定的模型所支配。
域，这会导致其他域的性能显着下降
（即“跷跷板现象”）。在本文中，我们提出了一种新颖的解决方案
Uni-CTR来解决上述挑战。 Uni-CTR 利用大型骨干网
语言模型 (LLM)，用于学习捕获的分层语义表示
域之间的共性。 Uni-CTR 还使用多个特定领域的
网络来捕获每个域的特征。请注意，我们设计了一个
掩蔽损失策略，使这些特定于域的网络与
骨干法学硕士。这允许特定于域的网络在以下情况下保持不变：
合并新的或删除的域，从而增强灵活性和
系统的可扩展性显着。三个公共实验结果
数据集显示 Uni-CTR 优于最先进的 (SOTA) MDCTR 模型
显著地。此外，Uni-CTR 在以下方面表现出显着的有效性：
零样本预测。我们将Uni-CTR应用在工业场景中，
确认其效率。
]]></description>
      <guid>http://arxiv.org/abs/2312.10743</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>一种基于多尺度CNN和残差LSTM的新型扩散推荐算法（arXiv：2312.10885v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.10885</link>
      <description><![CDATA[顺序推荐旨在从历史数据中推断用户偏好
交互序列并预测用户可能感兴趣的下一个项目
未来。当前的主流设计方法是将项目表示为
固定向量，捕获项目和用户之间的潜在关系
基于交互顺序的偏好。然而，仅依靠单一
固定项嵌入可能会削弱系统的建模能力，并且
用户偏好所表现出的全局动态和局部显着性需要
杰出的。为了解决这些问题，本文提出了一种新的扩散方法
基于多尺度CNN和残差lstm（AREAL）的推荐算法。我们
将扩散模型引入推荐系统，将项目表示为
概率分布而不是固定向量。这种方法使得
自适应反映item的多个方面并生成item
以去噪方式分布。我们使用多尺度CNN和残差lstm
提取用户历史的局部和全局依赖性特征的方法
交互作用，并以注意力机制区分权重为指导
反向扩散恢复的特点提议的有效性
该方法通过对两个真实世界数据集进行的实验进行了验证。
具体而言，AREAL 比最佳基线提高了 2.63%，
就 HR@20 而言，分别为 4.25%；就 NDCG@20 而言，分别为 5.05% 和 3.94%
数据集。
]]></description>
      <guid>http://arxiv.org/abs/2312.10885</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>GraphPro：图预训练和快速学习推荐。 （arXiv：2311.16716v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2311.16716</link>
      <description><![CDATA[基于 GNN 的推荐器在复杂的用户项目建模方面表现出色
通过多跳消息传递进行交互。然而，现有的方法常常
忽视了不断发展的用户-项目交互的动态本质，这阻碍了
适应不断变化的用户偏好和新的分布变化
到达的数据。因此，它们在现实世界动态中的可扩展性和性能
环境有限。在这项研究中，我们提出了 GraphPro，一个框架
结合了参数高效和动态图预训练以及提示
学习。这种新颖的组合使 GNN 能够有效捕获
长期用户偏好和短期行为动态，使
提供准确、及时的建议。我们的 GraphPro 框架
通过无缝集成解决不断变化的用户偏好的挑战
时间提示机制和图结构提示学习机制
进入预训练的 GNN 模型。时间提示机制对时间进行编码
有关用户-项目交互的信息，使模型能够自然地捕获
时间上下文，而图结构提示学习机制使得
转移预先训练的知识以适应行为动态，而无需
需要持续增量训练。我们进一步引入动态
模拟真实世界动态场景的推荐评估设置和
更好地缩小线下和线上的差距。我们广泛的实验
包括大规模工业部署展示了轻量级插件
与各种最先进的技术集成时，我们的 GraphPro 具有可扩展性
推荐者，强调GraphPro在有效性方面的优势，
稳健性和效率。
]]></description>
      <guid>http://arxiv.org/abs/2311.16716</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>没有偏见！用于个性化推荐的公平联合图神经网络。 （arXiv：2312.10080v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.10080</link>
      <description><![CDATA[确保推荐系统 (RS) 跨人口群体的公平性
由于RS在应用中的集成度不断提高，例如
个性化医疗、金融和电子商务。基于图的 RS 发挥着
在捕获实体之间复杂的高阶交互方面发挥着至关重要的作用。
然而，将这些图模型集成到联邦学习（FL）中
具有公平约束的范式提出了巨大的挑战，因为这需要
访问整个交互图和敏感的用户信息（例如
性别、年龄等）在中央服务器。本文针对普遍存在的
RS 中针对不同人口群体的固有偏见问题
损害 FL 环境中敏感用户属性的隐私
基于图的模型。为了解决群体偏见，我们提出了 F2PGNN（Fair
联合个性化图神经网络），一种利用
个性化图神经网络 (GNN) 的力量与公平性相结合
考虑因素。此外，我们使用差异隐私技术来强化
隐私保护。对三个公开可用的实验评估
数据集展示了 F2PGNN 将群体不公平性降低了 47% 的功效
- 与最先进的技术相比，提高了 99%，同时保护隐私并维护
实用程序。结果验证了我们的框架的重要性
在 FL 内使用 GNN 实现公平且个性化的推荐
景观。
]]></description>
      <guid>http://arxiv.org/abs/2312.10080</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>通过 Householder 量化进行深度哈希。 （arXiv：2311.04207v2 [cs.CV] 已更新）</title>
      <link>http://arxiv.org/abs/2311.04207</link>
      <description><![CDATA[哈希是大规模图像相似性搜索的核心，最近
通过深度学习技术，方法得到了显着改进。这样的
算法通常学习数据的连续嵌入。为了避免
随后昂贵的二值化步骤，常见的解决方案是采用损失
结合相似性学习项的函数（以确保相似的图像是
分组到附近的嵌入）和量化惩罚项（以确保
嵌入条目接近二值化条目，例如-1或1）。仍然，
这两个术语之间的相互作用可以使学习变得更加困难
嵌入更差。我们提出了一种替代量化策略
将学习问题分解为两个阶段：首先，执行相似性
在没有量化的情况下学习嵌入空间；其次，找到一个最优的
嵌入的正交变换，因此嵌入的每个坐标
接近其符号，然后通过量化变换后的嵌入
标志功能。第二步，我们参数化正交变换
使用 Householder 矩阵有效地利用随机梯度下降。
由于相似性度量在正交条件下通常是不变的
转换，这种量化策略在以下方面是免费的：
表现。由此产生的算法是无监督的、快速的、无超参数的
并且可以在任何现有的深度哈希或度量学习之上运行
算法。我们提供了大量的实验结果表明这种方法
在广泛使用的图像数据集上带来最先进的性能，并且，
与其他量化策略不同，带来了持续的改进
现有深度哈希算法的性能。
]]></description>
      <guid>http://arxiv.org/abs/2311.04207</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>重新思考开放世界假设下的跨域顺序推荐。 （arXiv：2311.04590v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2311.04590</link>
      <description><![CDATA[跨域顺序推荐（CDSR）方法旨在处理数据
单域序列中存在的稀疏性和冷启动问题
建议（SDSR）。现有的 CDSR 作品设计了其复杂的结构
依靠重叠用户来传播跨域信息。
然而，当前的 CDSR 方法做出了封闭世界假设，完全假设
跨多个域的重叠用户以及数据分布
从训练环境到测试环境保持不变。作为一个
结果，这些方法通常会导致在线性能较低
由于数据分布的变化，现实世界的平台。为了解决这些
为了应对开放世界假设下的挑战，我们设计了一个 \textbf{A}daptive
\textbf{M}ulti-\textbf{I}ninterest \textbf{D}跨域的偏向框架
顺序推荐（\textbf{AMID}），由多兴趣组成
信息模块（\textbf{MIM}）和双鲁棒估计器（\textbf{DRE}）。
我们的框架适应开放世界环境并可以改进模型
大多数现成的 CDSR 单域顺序骨干模型。我们的
MIM 建立利益集团，同时考虑重叠和
不重叠的用户，使我们能够有效地探索用户意图和
明确的兴趣。为了减轻跨多个领域的偏见，我们开发了
CDSR 方法的 DRE。我们还提供了理论分析
证明了我们提出的估计器在偏差和
尾部绑定，与之前工作中使用的 IPS 估计器相比。
]]></description>
      <guid>http://arxiv.org/abs/2311.04590</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>基于会话的推荐的自我对比学习。 （arXiv：2306.01266v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2306.01266</link>
      <description><![CDATA[基于会话的推荐，旨在预测用户的下一项
根据现有的项目序列交互的兴趣，吸引了
随着用户和项目的改进，对比学习 (CL) 的应用不断增长
交涉。然而，这些对比目标：（1）服务于相似的目标
充当交叉熵损失，同时忽略项目表示空间
优化; (2)通常需要复杂的建模，包括复杂的建模
正/负样本结构和额外的数据增强。在这个
工作中，我们引入了自我对比学习（SCL），它简化了
CL 的应用并增强了基于 CL 的最先进的性能
推荐技术。具体来说，SCL 被制定为一个目标
直接促进item之间均匀分布的函数
表示并有效地取代所有现有的对比目标
最先进模型的组件。与之前的作品不同，SCL 消除了
需要任何正/负样本构建或数据增强，
导致项目表示空间的可解释性增强，并且
促进其对现有推荐系统的扩展。通过
在三个基准数据集上进行的实验，我们证明了 SCL 一致
通过统计提高最先进模型的性能
意义。值得注意的是，我们的实验表明 SCL 提高了性能
两个表现最好的模型的 P@10（精度）分别提高了 8.2% 和 9.5%，以及 9.9%
不同基准的 MRR@10（平均倒数排名）平均为 11.2%。
此外，我们的分析阐明了对齐和
表示的一致性以及 SCL 的有效性
计算成本。
]]></description>
      <guid>http://arxiv.org/abs/2306.01266</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的预算嵌入表。 （arXiv：2310.14884v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2310.14884</link>
      <description><![CDATA[当代推荐系统 (RS) 的核心是潜在因素
为用户提供优质推荐体验的模型。这些型号
使用通常具有统一且固定大小的嵌入向量来
代表用户和项目。随着用户和物品数量的不断增长，
这种设计变得低效且难以扩展。最近的轻量级嵌入
方法使不同的用户和项目具有不同的嵌入大小，
但通常存在两个主要缺点。首先，他们限制了
嵌入大小搜索来优化启发式平衡推荐
质量和内存复杂性，其中需要权衡系数
手动调整每个请求的内存预算。隐式强制执行
内存复杂度项甚至无法限制参数的使用，使得
生成的嵌入表无法严格满足内存预算。第二，
大多数解决方案，尤其是基于强化学习的解决方案都派生并
逐个实例优化每个用户/项目的嵌入大小
的基础，影响了搜索效率。在本文中，我们提出预算
嵌入表（BET），一种生成表级操作的新颖方法（即
所有用户和项目的嵌入大小）保证满足
预先指定的内存预算。此外，通过利用基于集合的动作
制定和参与集合表示学习，我们提出了一种创新的
由动作适应度预测器提供支持的动作搜索策略，可以有效地
评估每个表级操作。实验表明最先进的
当 BET 与三个流行的数据集配对时，在两个现实世界数据集上的性能
不同内存预算下的推荐模型。
]]></description>
      <guid>http://arxiv.org/abs/2310.14884</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>BSL：理解和改进 Softmax 损失以进行推荐。 （arXiv：2312.12882v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2312.12882</link>
      <description><![CDATA[损失函数引导推荐模型的优化方向
对模型性能至关重要，但收到的信息相对较少
最近推荐研究中的关注。在各种损失中，我们发现
Softmax 损失 (SL) 不仅表现出色，而且表现出色
还具有更好的稳健性和公平性。然而，目前的文献还缺乏
全面解释SL的功效。为解决这个问题
基于研究空白，我们对 SL 进行了理论分析，并揭示了三个见解：
1）优化SL相当于执行分布式鲁棒
对负数据进行优化（DRO），从而学习对抗扰动
负分布并产生对噪声负数的鲁棒性。 2）
与其他损失函数相比，SL 隐含地惩罚了预测
方差，导致预测值之间的差距较小，从而
产生更公平的结果。基于这些见解，我们进一步提出
新颖的损失函数双边 SoftMax 损失 (BSL)，扩展了以下优点
SL 到正侧和负侧。 BSL 通过应用相同的方法来增强 SL
Log-Expectation-Exp 结构用于正例，就像用于负例一样，
使模型对噪声正值也具有鲁棒性。值得注意的是，BSL 是
简单且易于实现——只需要额外一行代码
与SL相比。对四个真实世界数据集和三个
代表性骨干证明了我们提案的有效性。这
代码可在 https://github.com/junkangwu/BSL 获取
]]></description>
      <guid>http://arxiv.org/abs/2312.12882</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>用于视听同步的多模态变压器蒸馏。 （arXiv：2210.15563v2 [cs.CV] 已更新）</title>
      <link>http://arxiv.org/abs/2210.15563</link>
      <description><![CDATA[视听同步的目的是判断嘴部是否有动作
和视频中的讲话是同步的。 VocaLiST 达到最先进水平
通过结合多模态 Transformer 来建模视听性能
交互信息。但它需要大量的计算资源，使得
对于现实世界的应用来说不切实际。本文提出了一种MTDVocaLiST
模型，由我们提出的多模式 Transformer 蒸馏训练
（MTD）损失。 MTD 损失使 MDVocaLiST 模型能够深度模仿
VocaLiST Transformer 中的交叉注意力分布和值关系。
此外，我们利用不确定性加权来充分利用相互作用
跨所有层的信息。我们提出的方法在两个方面是有效的：
从蒸馏方法角度来看，MTD损失优于其他强方法
蒸馏基线。从蒸馏模型的性能角度来看：1）
MTDVocaLiST 的性能优于类似大小的 SOTA 模型、SyncNet 和 Perfect Match
型号分别降低了15.65%和3.35%； 2）MTDVocaLiST减小了VocaLiST的模型大小
83.52%，但仍保持相似的表现。
]]></description>
      <guid>http://arxiv.org/abs/2210.15563</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>微调大型语言模型以实现自适应机器翻译。 （arXiv：2312.12740v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.12740</link>
      <description><![CDATA[本文介绍了 Mistral 7B（通用型）的微调结果
大语言模型 (LLM)，用于自适应机器翻译 (MT)。这
微调过程涉及利用零样本和单样本的组合
医学领域内的翻译提示。主要目标是
增强Mistral 7B的实时自适应MT能力，使其能够适应
在推理时翻译到所需的域。结果，
特别是对于西班牙语到英语的机器翻译，展示微调的功效
模型，展示了零样本和单样本的质量改进
翻译场景，超越了 Mistral 7B 的基准性能。尤其，
经过微调的 Mistral 在零射击方面优于 ChatGPT“gpt-3.5-turbo”
翻译，同时实现可比的一次性翻译质量。而且，
经过微调的 Mistral 的零射击平移与 NLLB 3.3B 相匹配
性能，一次性翻译质量超过NLLB 3.3B。
这些发现强调了微调高效法学硕士的重要性，例如
Mistral 7B 产生的高质量零样本翻译可与
面向任务的模型，例如 NLLB 3.3B。此外，获得的自适应增益
一次性翻译可与商业法学硕士相媲美，例如
聊天GPT。我们的实验表明，使用相对较小的数据集
20,000 个片段，融合了零次和一次提示，
微调显着增强了 Mistral 的情境学习能力，
特别是对于实时自适应机器翻译。
]]></description>
      <guid>http://arxiv.org/abs/2312.12740</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>实时广告系统中广告和创意的并行排名。 （arXiv：2312.12750v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.12750</link>
      <description><![CDATA[“创意是广告服务的核心和灵魂”。有效的
创意可以创造双赢的场景：广告商可以触达目标用户，
更有效地实现营销目标，用户可以更快速地找到
感兴趣的产品和平台可以产生更多的广告收入。和
随着人工智能生成内容的出现，广告商现在可以制作大量内容
以最低的成本提供创意内容。当前的挑战在于如何
广告系统可以实时选择最相关的创意
每个用户个人。现有方法通常执行广告的连续排名
或创意，限制创意模块的有效性和
效率。在本文中，我们首次提出了一种新颖的架构
用于在线并行估计广告和创意排名，以及
相应的离线联合优化模型。在线架构使
复杂的个性化创意建模，同时减少整体延迟。
CTR估算的离线联合模型允许相互了解和
广告与创意之间的协同优化。此外，我们还优化了
所涉及的隐式反馈排序任务的离线评估指标
在广告创意排名中。我们进行了大量的实验来与我们的进行比较
两种最先进的方法。结果证明了以下方法的有效性
我们在线下评估和现实世界广告平台上的方法
在线响应时间、点击率和每千次展示费用方面。
]]></description>
      <guid>http://arxiv.org/abs/2312.12750</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:46 GMT</pubDate>
    </item>
    <item>
      <title>分类、比率和教授数据：倒数排名的案例。 （arXiv：2312.12672v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.12672</link>
      <description><![CDATA[搜索引擎结果页面通常被抽象为二进制相关性
向量，因此是分类数据，这意味着只有有限的一组
允许进行操作，最值得注意的是出现频率的列表，
无法确定中位数和平均值。比较检索
因此，系统通常使用分类到数字的有效性
映射。之前的一篇论文认为，任何期望的分类到数字
可以使用映射，只要两者之间存在有争议的联系
SERP 的每个类别以及分配给该类别的分数
映射。此外，一旦建立了合理的联系，那么
映射值可以被视为比率尺度上的实值观测值，
允许计算平均值。写这篇文章是为了支持
这种观点，并回应持续不断的说法，即 SERP 分数可能只会
如果对有效性施加非常严格的条件，则进行平均
映射。
]]></description>
      <guid>http://arxiv.org/abs/2312.12672</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>Lookahead：具有无损生成精度的大型语言模型推理加速框架。 （arXiv：2312.12728v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.12728</link>
      <description><![CDATA[随着大型语言模型 (LLM) 在各个方面取得了重大进步
各种任务，例如回答问题、翻译、文本摘要等
对话系统，对信息准确性的需求变得至关重要，
特别是对于为数十亿用户提供服务的严肃金融产品，例如
支付宝。为了解决这个问题，支付宝开发了检索增强一代
(RAG) 系统为法学硕士提供最准确和最新的信息。
然而，对于服务于数百万用户的现实世界产品，推论
与单纯的实验模型相比，法学硕士的速度成为一个关键因素。

因此，本文提出了一个加速推理的通用框架
过程，从而大幅提高速度并降低成本
我们的 RAG 系统具有无损生成精度。在传统的推论中
过程中，每个令牌均由 LLM 顺序生成，从而导致一个时间
消耗与生成的代币数量成正比。为了增强这一点
过程中，我们的框架名为 \textit{lookahead}，引入了一个
\textit{多分支}策略。不是一次生成一个令牌，
我们提出了一个 \textit{基于 Trie 的检索} (TR) 过程，该过程使得
同时生成多个分支，每个分支都是一个序列
代币。随后，对于每个分支，一个 \textit{验证和接受} (VA)
执行过程以识别最长的正确子序列作为最终的
输出。我们的策略有两个明显的优势：（1）它保证了绝对的
输出的正确性，避免任何近似算法，以及（2）
我们的方法的最坏情况性能相当于传统的
过程。我们进行了大量的实验来证明显着的
通过应用我们的推理加速框架实现的改进。
]]></description>
      <guid>http://arxiv.org/abs/2312.12728</guid>
      <pubDate>Thu, 21 Dec 2023 06:17:45 GMT</pubDate>
    </item>
    </channel>
</rss>