<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 12 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>解决 Roblox 游戏推荐中的内容差距：基于 LLM 的个人资料生成和重新排序</title>
      <link>https://arxiv.org/abs/2502.06802</link>
      <description><![CDATA[arXiv:2502.06802v1 公告类型：新
摘要：Roblox 上有大量动态的用户生成内容，因此创建有效的游戏推荐需要深入了解游戏内容。传统的推荐模型难以应对游戏文本特征（例如标题和描述）不一致和稀疏的特性。大型语言模型 (LLM) 的最新进展为通过分析游戏内文本数据来增强推荐系统提供了机会。本文解决了两个挑战：为游戏生成高质量、结构化的文本特征，而无需大量人工注释，并验证这些特征以确保它们提高推荐相关性。我们提出了一种提取游戏内文本并使用 LLM 从原始玩家互动中推断类型和游戏目标等属性的方法。此外，我们引入了一种基于 LLM 的重新排名机制来评估生成的文本特征的有效性，从而增强个性化和用户满意度。除了推荐之外，我们的方法还支持已在生产中部署的基于用户参与度的完整性检测等应用程序。这个可扩展的框架展示了游戏内文本理解的潜力，可以提高 Roblox 的推荐质量，并使推荐适应其独特的用户生成的生态系统。]]></description>
      <guid>https://arxiv.org/abs/2502.06802</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用神经检索方法进行存储库级代码搜索</title>
      <link>https://arxiv.org/abs/2502.07067</link>
      <description><![CDATA[arXiv:2502.07067v1 公告类型：新
摘要：本文介绍了一种用于存储库级代码搜索的多阶段重新排序系统，该系统利用大型开源存储库的大量可用提交历史记录来帮助修复错误。我们将存储库级代码搜索的任务定义为从代码存储库的当前状态中检索与解决用户的问题或错误最相关的文件集。所提出的方法将基于 BM25 的提交消息检索与使用 CodeBERT 的神经重新排序相结合，以识别最相关的文件。通过从不同的存储库及其提交历史记录中学习模式，系统可以为手头的任务显示相关文件。该系统利用提交消息和源代码进行相关性匹配，并在正常和 oracle 设置中进行评估。在由 7 个流行的开源存储库创建的新数据集上进行的实验表明，在一系列不同的查询中，MAP、MRR 和 P@1 比 BM25 基线提高了高达 80%，证明了这种方法的有效性。我们希望这项工作有助于 LLM 代理成为更好的代码搜索和理解工具。我们的代码和获得的结果都是公开的。]]></description>
      <guid>https://arxiv.org/abs/2502.07067</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DOGR：在生成检索中利用面向文档的对比学习</title>
      <link>https://arxiv.org/abs/2502.07219</link>
      <description><![CDATA[arXiv:2502.07219v1 公告类型：新
摘要：生成检索是信息检索中的一种创新方法，利用生成语言模型 (LM) 为给定查询生成文档标识符 (docid) 的排序列表。它通过用模型参数替换大型外部索引来简化检索流程。然而，现有的工作仅仅学习了查询和文档标识符之间的关系，无法直接表示查询和文档之间的相关性。为了解决上述问题，我们提出了一个新颖的通用生成检索框架，即利用面向文档的生成检索对比学习 (DOGR)，它利用对比学习来改进生成检索任务。它采用两阶段学习策略，通过直接交互全面捕捉查询和文档之间的关系。此外，还实施了负采样方法和相应的对比学习目标，以增强语义表示的学习，从而促进对查询和文档之间关系的彻底理解。实验结果表明，与现有的生成检索方法相比，DOGR 在两个公共基准数据集上实现了最先进的性能。进一步的实验表明，我们的框架对于常见的标识符构造技术通常有效。]]></description>
      <guid>https://arxiv.org/abs/2502.07219</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协同过滤的流匹配</title>
      <link>https://arxiv.org/abs/2502.07303</link>
      <description><![CDATA[arXiv:2502.07303v1 公告类型：新
摘要：生成模型通过捕捉用户兴趣和偏好的底层分布，在协同过滤方面显示出巨大的前景。然而，现有的方法存在后验近似不准确和与推荐数据的离散性质不一致的问题，限制了它们的表达能力和实际性能。为了解决这些限制，我们提出了 FlowCF，这是一种基于流的新型推荐系统，利用流匹配进行协同过滤。我们通过两项关键创新来定制流匹配以应对推荐中的独特挑战：(1) 与用户行为模式保持一致的行为引导先验，以处理稀疏和异构的用户项目交互，(2) 离散流框架，以保留隐式反馈的二元性质，同时保持流匹配的优势，例如稳定的训练和高效的推理。大量实验表明，FlowCF 以最快的推理速度在各种数据集上实现了最先进的推荐准确率，使其成为现实世界推荐系统的一种引人注目的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.07303</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CreAgent：平台-创作者信息不对称下的推荐系统长期评估</title>
      <link>https://arxiv.org/abs/2502.07307</link>
      <description><![CDATA[arXiv:2502.07307v1 公告类型：新
摘要：确保推荐系统 (RS) 的长期可持续性成为一个关键问题。RS 的传统离线评估方法通常关注即时用户反馈，例如点击次数，但它们往往忽略了内容创建者的长期影响。在现实世界的内容平台上，创作者可以根据用户反馈和偏好趋势有策略地制作和上传新项目。虽然以前的研究试图对创作者行为进行建模，但它们往往忽视了信息不对称的作用。这种不对称的出现是因为创作者主要可以访问他们制作​​的项目的反馈，而平台拥有有关整个用户反馈范围的数据。然而，当前的 RS 模拟器未能考虑到这种不对称，导致长期评估不准确。为了解决这一差距，我们提出了 CreAgent，一个由大型语言模型 (LLM) 赋能的创作者模拟代理。通过结合博弈论的信念机制和快慢思维框架，CreAgent 有效地模拟了信息不对称条件下的创作者行为。此外，我们使用近端策略优化 (PPO) 对 CreAgent 进行微调，增强了 CreAgent 的模拟能力。我们的可信度验证实验表明，CreAgent 与真实平台和创作者之间的行为非常吻合，从而提高了长期 RS 评估的可靠性。此外，通过涉及 CreAgent 的 RS 模拟，我们可以探索公平性和多样性感知的 RS 算法如何为各个利益相关者带来更好的长期绩效。CreAgent 和模拟平台可在 https://github.com/shawnye2000/CreAgent 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2502.07307</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>排名竞赛中基于提示的文档修改</title>
      <link>https://arxiv.org/abs/2502.07315</link>
      <description><![CDATA[arXiv:2502.07315v1 公告类型：新
摘要：我们研究使用大型语言模型 (LLM) 的基于提示的方法来修改文档，以便在竞争性搜索环境中提升其排名。我们的方法受到利用 LLM 作为排名器的先前工作的启发。我们通过在以前的排名竞赛和我们组织的竞赛中将其部署为机器人来评估我们的方法。我们的研究结果表明，我们的方法有效地提高了文档排名，同时保持了对原始内容的高度忠实度并保持了整体文档质量。]]></description>
      <guid>https://arxiv.org/abs/2502.07315</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成幽灵：调查隐藏在人工智能生成视频中的排名偏见</title>
      <link>https://arxiv.org/abs/2502.07327</link>
      <description><![CDATA[arXiv:2502.07327v1 公告类型：新
摘要：随着人工智能生成内容 (AIGC) 的快速发展，高质量人工智能生成视频的创作变得越来越快、越来越容易，导致互联网上充斥着各种视频内容。然而，这些视频对内容生态系统的影响在很大程度上仍未被探索。视频信息检索仍然是访问视频内容的基本方法。基于检索模型在临时和图像检索任务中通常偏向人工智能生成的内容的观察，我们调查了在具有挑战性的视频检索环境中是否会出现类似的偏见，其中时间和视觉因素可能会进一步影响模型行为。为了探索这一点，我们首先构建了一个包含真实视频和人工智能生成的视频的综合基准数据集，以及一组公平和严格的指标来评估偏见。这个基准由两个最先进的开源视频生成模型生成的 13,000 个视频组成。我们精心设计了一套严格的指标来准确衡量这种偏好，考虑到 AIGC 视频有限的帧速率和次优质量可能引起的偏差。然后，我们应用了三种现成的视频检索模型来对这个混合数据集执行检索任务。我们的研究结果表明，检索中明显偏向于 AI 生成的视频。进一步的研究表明，将 AI 生成的视频纳入检索模型的训练集会加剧这种偏差。与在图像模态中观察到的偏好不同，我们发现视频检索偏差源于看不见的视觉和时间信息，使得视频偏差的根本原因是这两个因素的复杂相互作用。为了减轻这种偏差，我们使用对比学习方法对检索模型进行了微调。这项研究的结果强调了 AI 生成的视频对检索系统的潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2502.07327</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ETimeline：基于大型语言模型的广泛时间线生成数据集</title>
      <link>https://arxiv.org/abs/2502.07474</link>
      <description><![CDATA[arXiv:2502.07474v1 公告类型：新
摘要：时间线生成对于全面了解事件随时间的发展具有重要意义。它的目标是按时间顺序组织新闻，这有助于识别在单独查看新闻时可能被掩盖的模式和趋势，从而更容易跟踪故事的发展并了解关键事件之间的相互关系。时间线现在在各种商业产品中很常见，但该领域的学术研究却很少。此外，当前的数据集需要改进以增强实用性和扩大覆盖范围。在本文中，我们提出了 ETimeline，它涵盖了超过 13,000 篇新闻文章，涵盖 28 个新闻领域的 600 条双语时间线。具体来说，我们收集了超过 120,000 篇新闻文章的候选池，并使用大型语言模型 (LLM) Pipeline 来提高性能，最终产生了 ETimeline。数据分析凸显了 ETimeline 的吸引力。此外，我们还提供新闻池数据以供进一步研究和分析。这项工作有助于推动时间线生成研究，并支持广泛的任务，包括主题生成和事件关系。我们相信这个数据集将成为创新研究的催化剂，并弥合学术界和工业界在理解技术服务的实际应用方面的差距。数据集可在 https://zenodo.org/records/11392212 上找到]]></description>
      <guid>https://arxiv.org/abs/2502.07474</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IU4Rec：基于兴趣单元的电商平台产品组织与推荐</title>
      <link>https://arxiv.org/abs/2502.07658</link>
      <description><![CDATA[arXiv:2502.07658v1 公告类型：新
摘要：大多数推荐系统通常遵循基于产品的范式，利用用户与产品的交互来识别最吸引用户的商品。然而，这种基于产品的范式对于闲鱼来说有明显的缺点~\footnote{闲鱼是中国最大的在线 C2C 电子商务平台，其中很大一部分产品是由个人卖家发布的}。闲鱼上个人卖家发布的大部分产品通常库存有限，一旦产品售出，就不再可供分销。这导致闲鱼上分发的大多数商品互动相对较少，影响了依赖于累积用户与商品互动的传统推荐的有效性。为了解决这些问题，我们引入了 \textbf{IU4Rec}，一个基于 \textbf{I}nterest \textbf{U}nit 的两阶段 \textbf{Rec} 推荐系统框架。我们首先根据类别、图像和语义等属性将产品分组。然后，这些 IU 被集成到推荐系统中，提供产品和技术创新。IU4Rec 首先根据类别、图像和语义等属性将产品分组，形成兴趣单元 (IU)。然后，我们将推荐流程重新设计为两个阶段。在第一阶段，重点是推荐这些兴趣单元，捕捉广泛的兴趣。在第二阶段，它引导用户在所选兴趣单元内的类似产品中找到最佳选择。用户-IU 交互被纳入我们的排名模型，与特定于项目的交互相比，它具有更持久的 IU 行为的优势。在生产数据集和在线 A/B 测试上的实验结果证明了我们提出的以 IU 为中心的推荐方法的有效性和优越性。]]></description>
      <guid>https://arxiv.org/abs/2502.07658</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>exHarmony：用于对审稿人分配问题进行基准测试的作者和引文</title>
      <link>https://arxiv.org/abs/2502.07683</link>
      <description><![CDATA[arXiv:2502.07683v1 公告类型：新
摘要：同行评审过程对于确保学术工作的质量和可靠性至关重要，但分配合适的审稿人仍然是一项重大挑战。传统的手动方法劳动密集且通常无效，导致非建设性或有偏见的评审。本文介绍了 exHarmony（eHarmony，但用于将专家与手稿联系起来）基准，旨在通过将审稿人分配问题 (RAP) 重新想象为检索任务来应对这些挑战。利用来自 OpenAlex 的大量数据，我们提出了一种新颖的方法，该方法将来自作者、最相似专家和引用关系的大量信号视为手稿合适审稿人的潜在指标。这种方法使我们能够开发一个标准的基准数据集来评估审稿人分配问题，而无需明确的标签。我们对各种方法进行了基准测试，包括传统词汇匹配、静态神经嵌入和情境化神经嵌入，并引入了评估指标，用于评估 RAP 情境中的相关性和多样性。我们的结果表明，虽然传统方法表现相当好，但经过学术文献训练的情境化嵌入表现出最佳性能。研究结果强调了进一步研究以提高审稿人任务的多样性和有效性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.07683</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多模态大型语言模型生成 CTR 驱动的广告图像</title>
      <link>https://arxiv.org/abs/2502.06823</link>
      <description><![CDATA[arXiv:2502.06823v1 公告类型：交叉 
摘要：在网络数据中，广告图像对于吸引用户注意力和提高广告效果至关重要。大多数现有的产品背景生成方法主要关注美学质量，可能无法实现令人满意的在线性能。为了解决这一限制，我们探索使用多模态大型语言模型 (MLLM) 生成广告图像，以点击率 (CTR) 为主要目标进行优化。首先，我们构建有针对性的预训练任务，并利用大规模电子商务多模态数据集为 MLLM 配备初始的广告图像生成任务能力。为了进一步提高生成图像的点击率，我们提出了一种新颖的奖励模型，通过强化学习 (RL) 对预训练的 MLLM 进行微调，它可以联合利用多模态特征并准确反映用户的点击偏好。同时，我们开发了以产品为中心的偏好优化策略，以确保生成的背景内容经过微调后能够与产品特征保持一致，从而提高广告图像的整体相关性和有效性。大量实验表明，我们的方法在线上和离线指标上都达到了最佳性能。我们的代码和预训练模型已公开发布：https://github.com/Chenguoz/CAIG。]]></description>
      <guid>https://arxiv.org/abs/2502.06823</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索体育运动背后的规律</title>
      <link>https://arxiv.org/abs/2502.07491</link>
      <description><![CDATA[arXiv:2502.07491v1 公告类型：交叉 
摘要：本文提出了一个使用 ARIMA 和 LSTM 相结合的混合模型进行时间序列预测的综合框架。该模型结合了特征工程技术，包括嵌入和 PCA，将原始数据转换为低维表示，同时保留关键信息。嵌入技术用于将分类数据转换为连续向量，便于捕获复杂的关系。PCA 用于降低维数和提取主成分，从而提高模型性能和计算效率。为了处理数据中的线性和非线性模式，ARIMA 模型捕获线性趋势，而 LSTM 模型模拟复杂的非线性依赖关系。混合模型在历史数据上进行训练，并实现了高精度，低 RMSE 和 MAE 分数就是明证。此外，本文采用运行测试来评估序列的随机性，从而深入了解底层模式。进行了消融研究以验证模型中不同组件的作用，证明了每个模块的重要性。本文还利用 SHAP 方法量化传统优势对预测结果的影响，详细了解特征重要性。KNN 方法用于确定最佳预测区间，进一步提高模型的准确性。结果突出了将传统统计方法与现代深度学习技术相结合对体育领域稳健时间序列预测的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.07491</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AURO：推荐系统中自适应用户保留优化的强化学习</title>
      <link>https://arxiv.org/abs/2310.03984</link>
      <description><![CDATA[arXiv:2310.03984v2 公告类型：替换 
摘要：强化学习 (RL) 领域因其在推荐系统中优化用户保留的能力而受到越来越多的关注。此优化过程中的主要障碍是环境非平稳性，这源于用户行为模式随时间不断而复杂的演变，例如交互率和保留倾向的变化。这些变化对现有的 RL 推荐算法构成了重大挑战，导致动态和奖励分配转变问题。本文介绍了一种称为 \textbf{A}daptive \textbf{U}ser \textbf{R}etention \textbf{O}ptimization (AURO) 的新方法来应对这一挑战。为了在非平稳环境中导航推荐策略，AURO 在策略网络中引入了一个状态抽象模块。该模块使用新的基于值的损失函数进行训练，使其输出与当前策略的估计性能保持一致。由于强化学习的策略性能对环境漂移很敏感，因此损失函数使状态抽象能够反映环境变化并通知推荐策略进行相应调整。此外，环境的非平稳性引入了隐式冷启动问题，其中推荐策略不断与表现出新行为模式的用户进行交互。AURO 鼓励在基于性能的拒绝抽样的保护下进行探索，以在成本敏感的在线环境中保持稳定的推荐质量。在用户保留模拟器、MovieLens 数据集和实时短视频推荐平台中进行了广泛的实证分析，证明了 AURO 在所有评估的基线算法中均具有卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2310.03984</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UniHGKR：统一指令感知异构知识检索器</title>
      <link>https://arxiv.org/abs/2410.20163</link>
      <description><![CDATA[arXiv:2410.20163v2 公告类型：替换 
摘要：现有的信息检索 (IR) 模型通常假设知识源和用户查询具有同质结构，这限制了它们在现实世界中的适用性，因为现实世界中的检索本质上是异构和多样化的。在本文中，我们介绍了 UniHGKR，这是一种统一的指令感知异构知识检索器，它 (1) 为异构知识构建统一的检索空间，(2) 遵循不同的用户指令来检索指定类型的知识。UniHGKR 由三个主要阶段组成：异构自监督预训练、文本锚定嵌入对齐和指令感知检索器微调，使其能够在不同的检索环境中进行推广。该框架具有高度可扩展性，具有基于 BERT 的版本和在大型语言模型上训练的 UniHGKR-7B 版本。此外，我们还推出了第一个原生异构知识检索基准 CompMix-IR。它包括两个具有各种指令的检索场景、超过 9,400 个问答 (QA) 对以及一个包含 1000 万个条目的语料库，涵盖四种不同类型的数据。大量实验表明，UniHGKR 在 CompMix-IR 上的表现始终优于最先进的方法，在两个场景中分别实现了高达 6.36% 和 54.23% 的相对改进。最后，通过为我们的检索器配备开放域异构 QA 系统，我们在流行的 ConvMix 任务上取得了新的最先进的结果，绝对改进高达 5.90 分。]]></description>
      <guid>https://arxiv.org/abs/2410.20163</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接对话和协作信号以实现对话推荐</title>
      <link>https://arxiv.org/abs/2412.06949</link>
      <description><![CDATA[arXiv:2412.06949v2 公告类型：替换 
摘要：对话推荐系统 (CRS) 利用对话中的上下文信息来生成推荐，但通常由于缺乏协同过滤 (CF) 信号而遇到困难，而协同过滤信号可以捕获准确推荐所必需的用户-项目交互模式。我们引入了 Reddit-ML32M，这是一个将 Reddit 对话与 MovieLens 32M 上的交互链接起来的数据集，通过利用协作知识和解决对话数据集中的交互稀疏性来丰富项目表示。我们提出了一个基于 LLM 的框架，该框架使用 Reddit-ML32M 将 LLM 生成的建议与 CF 嵌入对齐，从而优化排名以获得更好的性能。我们根据三组基线评估我们的框架：仅使用来自 CRS 任务的交互的基于 CF 的推荐器、传统的 CRS 模型和依赖于对话上下文而没有项目表示的基于 LLM 的方法。我们的方法取得了持续的改进，包括命中率提高了 12.32%，NDCG 提高了 9.9%，优于依赖对话上下文但缺乏协作项目表示的最佳基线。]]></description>
      <guid>https://arxiv.org/abs/2412.06949</guid>
      <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>