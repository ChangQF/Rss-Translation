<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 28 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>具有上限 $L_1$-范数距离度量的鲁棒无核二次曲面孪生支持向量机</title>
      <link>https://arxiv.org/abs/2405.16982</link>
      <description><![CDATA[arXiv:2405.16982v1 公告类型：新 
摘要：孪生支持向量机（TSVM）是一种非常经典且实用的模式分类分类器。然而，传统的 TSVM 有两个局限性。首先，它使用 L_2-范数距离度量，这导致它对异常值敏感。其次，需要选择合适的核函数和核参数进行非线性分类。为了有效避免这两个问题，本文提出了一种鲁棒上限L_1范数无核二次曲面孪生支持向量机（CL_1QTSVM）。我们模型的优点简要总结如下。 1）通过采用上限 L_1 范数距离度量，进一步提高了我们模型的鲁棒性。 2）我们的模型是一种无核方法，避免了选择合适的核函数和核参数的耗时过程。 3）引入L_2范数正则化项，提高模型的泛化能力。 4）为了有效地求解所提出的模型，开发了迭代算法。 5)进一步讨论了所开发算法的收敛性、时间复杂度和局部最优解的存在性。对多种类型数据集的数值实验验证了所提出模型的分类性能和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2405.16982</guid>
      <pubDate>Tue, 28 May 2024 06:19:29 GMT</pubDate>
    </item>
    <item>
      <title>ReCODE：使用神经常微分方程对重复消耗进行建模</title>
      <link>https://arxiv.org/abs/2405.16550</link>
      <description><![CDATA[arXiv:2405.16550v1 公告类型：新 
摘要：在现实世界的推荐系统中，例如在音乐领域，重复消费是一种常见现象，即用户经常重复收听一小部分喜欢的歌曲或艺术家。重复消费建模的关键点是捕获用户重复消费商品之间的时间模式。现有的研究通常依赖于启发式假设，例如假设时间间隙呈指数分布。然而，由于现实世界推荐系统的高度复杂性，这些预定义的分布可能无法捕获复杂的动态用户消费模式，从而导致性能次优。受到神经常微分方程 (ODE) 在捕捉复杂系统动态方面的灵活性的启发，我们提出了 ReCODE，这是一种新颖的模型不可知框架，利用神经常微分方程对重复消耗进行建模。 ReCODE由两个基本组成部分组成：用户的静态偏好预测模块和用户动态重复意图的建模。通过考虑即时选择和历史消费模式，ReCODE 提供了目标环境中用户偏好的全面建模。此外，ReCODE与现有的各种推荐模型无缝集成，包括基于协作和基于顺序的模型，使其可以轻松应用于不同的场景。两个真实数据集上的实验结果一致表明，ReCODE 显着提高了基础模型的性能，并且优于其他基线方法。]]></description>
      <guid>https://arxiv.org/abs/2405.16550</guid>
      <pubDate>Tue, 28 May 2024 06:19:28 GMT</pubDate>
    </item>
    <item>
      <title>NoteLLM-2：用于推荐的多模态大表示模型</title>
      <link>https://arxiv.org/abs/2405.16789</link>
      <description><![CDATA[arXiv:2405.16789v1 公告类型：新 
摘要：大型语言模型（LLM）已经表现出卓越的文本理解能力。现有的作品探索了它们在文本嵌入任务中的应用。然而，利用法学硕士来协助多模态表示任务的工作却很少。在这项工作中，我们研究了法学硕士在增强多模式项目到项目（I2I）推荐中的多模式表征的潜力。一种可行的方法是迁移多模态大型语言模型（MLLM）来执行表示任务。然而，预训练 MLLM 通常需要收集高质量、网络规模的多模态数据，导致训练过程复杂且成本高昂。这导致社区严重依赖开源 MLLM，阻碍了针对表示场景的定制培训。因此，我们的目标是设计一种端到端的训练方法，定制任何现有的 LLM 和视觉编码器的集成，以构建高效的多模态表示模型。初步实验表明，这种端到端方法中经过微调的 LLM 往往会忽略图像内容。为了克服这一挑战，我们提出了一种新颖的训练框架 NoteLLM-2，专为多模态表示而设计。我们提出了两种增强对视觉信息的关注的方法。第一种方法是基于提示视点，将多模态内容分为视觉内容和文本内容。 NoteLLM-2采用多模式内容学习方法来教导法学硕士关注两种模式并聚合关键信息。第二种方法是从模型架构出发，利用后期融合机制将视觉信息直接融合到文本信息中。已经进行了大量的实验来验证我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.16789</guid>
      <pubDate>Tue, 28 May 2024 06:19:28 GMT</pubDate>
    </item>
    <item>
      <title>多行为生成推荐</title>
      <link>https://arxiv.org/abs/2405.16871</link>
      <description><![CDATA[arXiv:2405.16871v1 公告类型：新 
摘要：多行为顺序推荐（MBSR）旨在整合交互的行为类型以获得更好的推荐。现有方法侧重于下一项预测目标，忽略了将目标行为类型整合到学习目标中的价值。在本文中，我们提出了 MBGen，一种新颖的多行为顺序生成推荐框架。我们将 MBSR 任务制定为连续的两步过程：（1）给定项目序列，MBGen 首先预测下一个行为类型以框架用户意图，（2）给定项目序列和目标行为类型，MBGen 然后预测下一个行为类型项目。为了对这样一个两步过程进行建模，我们将行为和项目标记为标记，并构建一个将行为和项目交错放置的单个标记序列。此外，MBGen 学习在统一的生成推荐范式中自回归生成下一个行为和项目标记，自然地实现多任务能力。此外，我们利用生成推荐中令牌序列的异构性，并提出了一种位置路由稀疏架构来高效且有效地扩展模型。对公共数据集的大量实验表明，MBGen 在多个任务上显着优于现有的 MBSR 模型。]]></description>
      <guid>https://arxiv.org/abs/2405.16871</guid>
      <pubDate>Tue, 28 May 2024 06:19:28 GMT</pubDate>
    </item>
    <item>
      <title>用于用户兴趣探索的法学硕士：混合方法</title>
      <link>https://arxiv.org/abs/2405.16363</link>
      <description><![CDATA[arXiv:2405.16363v1 公告类型：新 
摘要：传统的推荐系统通过学习和强化过去的用户-项目交互而受到强大的反馈循环的影响，这反过来又限制了新的用户兴趣的发现。为了解决这个问题，我们引入了一种混合分层框架，结合了大型语言模型（LLM）和用于用户兴趣探索的经典推荐模型。该框架通过“兴趣集群”控制法学硕士和经典推荐模型之间的接口，其粒度可以由算法设计者明确确定。它首先使用语言表示“兴趣簇”来推荐下一个新的兴趣，并采用微调的 LLM 来生成严格位于这些预定义簇内的新兴趣描述。在低级别，它通过限制经典推荐模型将这些生成的兴趣基于项目级策略，在本例中是基于变压器的序列推荐器，以返回属于高级别生成的新颖集群的项目。我们在为数十亿用户提供服务的工业规模商业平台上展示了​​这种方法的功效。现场实验表明，新奇兴趣的探索和平台的整体用户享受都显着增加。]]></description>
      <guid>https://arxiv.org/abs/2405.16363</guid>
      <pubDate>Tue, 28 May 2024 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>Cocktail：与 LLM 生成的文档集成的综合信息检索基准</title>
      <link>https://arxiv.org/abs/2405.16546</link>
      <description><![CDATA[arXiv:2405.16546v1 公告类型：新 
摘要：大型语言模型（LLM）的激增导致人工智能生成的内容（AIGC）涌入互联网，将信息检索（IR）系统的语料库从单纯的人类编写转变为与 LLM 生成的共存内容。 AIGC 的激增对 IR 系统的影响仍然是一个悬而未决的问题，主要挑战是缺乏针对研究人员的专用基准。在本文中，我们介绍了 Cocktail，这是一个为在 LLM 时代的混合源数据环境中评估 IR 模型而量身定制的综合基准。 Cocktail 由 16 个不同的数据集组成，其中包含跨各种文本检索任务和领域的人工编写和法学硕士生成的混合语料库。此外，为了避免之前在法学硕士中包含的数据集信息的潜在偏差，我们还引入了一个名为 NQ-UTD 的最新数据集，其中包含从最近事件派生的查询。通过进行 1,000 多项实验，根据 Cocktail 中的基准数据集评估最先进的检索模型，我们发现神经检索模型中排名性能和源偏差之间存在明显的权衡，强调了设计时采用平衡方法的必要性未来的红外系统。我们希望 Cocktail 能够成为 LLM 时代 IR 研究的基础资源，所有数据和代码均可在 \url{https://github.com/KID-22/Cocktail} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.16546</guid>
      <pubDate>Tue, 28 May 2024 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>BankFair：平衡不同用户流量下推荐系统的准确性和公平性</title>
      <link>https://arxiv.org/abs/2405.16120</link>
      <description><![CDATA[arXiv:2405.16120v1 公告类型：新
摘要：出于可持续性和经济方面的考虑，需要双边推荐平台来满足用户和提供商的需求。先前的研究通常表明双方的需求在紧迫性上有所不同：提供商有相对长期的曝光要求，而用户则希望获得短期、准确的服务。然而，我们的实证研究表明，现有的平衡公平性和准确性的方法在实际应用中往往无法在用户流量波动的情况下同时确保长期公平性和短期准确性。值得注意的是，当用户流量较低时，用户体验往往会显著下降。然后，我们进行了理论分析，证实用户流量是这种权衡问题的关键因素。在用户流量变化的情况下确保准确性和公平性仍然是一个挑战。受经济学中破产问题的启发，我们提出了一种新颖的公平感知重新排名方法，称为 BankFair。 BankFair 直观地使用 Talmud 规则来利用高用户流量时段来弥补低流量时段，从而确保一致的用户服务，同时保持长期公平性。BankFair 由两个模块组成：(1) 利用 Talmud 规则确定不同用户流量时段所需的公平度；(2) 根据 Talmud 规则确定的公平度实施在线重新排名算法。在一个公开可用的数据集和一个真实的工业数据集上进行的实验表明，BankFair 在准确性和提供商公平性方面均优于所有基准。]]></description>
      <guid>https://arxiv.org/abs/2405.16120</guid>
      <pubDate>Tue, 28 May 2024 06:19:26 GMT</pubDate>
    </item>
    <item>
      <title>微调大型语言模型以实现个性化排名</title>
      <link>https://arxiv.org/abs/2405.16127</link>
      <description><![CDATA[arXiv:2405.16127v1 公告类型：新 
摘要：大型语言模型（LLM）在各个领域都表现出了卓越的性能，这促使研究人员研究它们在推荐系统中的潜在用途。然而，由于预训练 LLM 所使用的数据与推荐任务的具体要求之间存在巨大差异，直接将 LLM 应用于推荐任务已被证明具有挑战性。在这项研究中，我们引入了直接多偏好优化（DMPO），这是一个简化的框架，旨在弥合差距并增强法学硕士在推荐任务上的一致性。 DMPO 通过同时最大化正样本的概率和最小化多个负样本的概率来增强基于 LLM 的推荐器的性能。我们进行了实验评估，将 DMPO 与传统推荐方法和其他基于 LLM 的推荐方法进行比较。结果表明，DMPO 显着提高了法学硕士在少数场景中跨三个现实世界公共数据集的推荐能力。此外，实验表明 DMPO 在跨域推荐中表现出优异的泛化能力。案例研究阐明了这些持续改进背后的原因，并强调了 DMPO 作为可解释推荐系统的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.16127</guid>
      <pubDate>Tue, 28 May 2024 06:19:26 GMT</pubDate>
    </item>
    <item>
      <title>在可证明通信效率的联合推荐系统中实现公平</title>
      <link>https://arxiv.org/abs/2405.15788</link>
      <description><![CDATA[arXiv:2405.15788v1 公告类型：新 
摘要：为了减少多个客户端并行训练造成的通信开销，各种联邦学习（FL）技术使用随机客户端采样。尽管如此，由于每个用户作为单独客户端的孤立性质，确保随机抽样的有效性并确定联合推荐系统 (FRS) 中抽样的最佳客户端数量仍然具有挑战性。在公共和私有特征可以分离的模型中，这一挑战更加严重，并且 FL 只允许公共特征（项目梯度）的通信。在本研究中，我们建立了样本复杂性界限，该界限决定了在此类模型中提高通信效率和保持准确性所需的理想客户端数量。根据我们的理论发现，我们凭经验证明 RS-FairFRS 降低了通信成本（约 47%）。其次，我们证明了客户之间存在类别不平衡，这引起了对 FRS 的重大股权担忧。与集中式机器学习不同，FRS 中的客户端无法共享原始数据，包括敏感属性。为此，我们引入了 RS-FairFRS，这是建立在基于随机采样的 FRS 之上的无意识 FRS 下的第一个公平性。虽然随机采样提高了通信效率，但我们提出了一种新颖的两阶段双公平更新技术，以实现公平性，而不会泄露参与训练的活跃客户端的受保护属性。我们对现实世界数据集和不同敏感特征的结果表明，人口统计偏差显着减少（约 40%），为在 FRS 中实现公平性和沟通效率提供了一条有前途的途径，同时又不影响 FRS 的整体准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.15788</guid>
      <pubDate>Tue, 28 May 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>基于学习的模型，用于构建用户配置文件以实现个性化信息访问</title>
      <link>https://arxiv.org/abs/2405.15791</link>
      <description><![CDATA[arXiv:2405.15791v1 公告类型：新 
摘要：本研究通过考虑用于表达文档内容和信息需求的词汇差异来为文献做出贡献。用户被纳入所有研究阶段，以便为他们提供适合其背景和偏好的相关信息，满足他们的精确需求。为了在此阶段更好地表达文档内容和信息，采用深度学习模型来学习文档和查询的复杂表示。这些模型可以捕获文本数据中的分层、顺序或基于注意力的模式。]]></description>
      <guid>https://arxiv.org/abs/2405.15791</guid>
      <pubDate>Tue, 28 May 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>IQLS：利用元数据对复杂、多功能数据进行基于大型语言模型的查询的框架</title>
      <link>https://arxiv.org/abs/2405.15792</link>
      <description><![CDATA[arXiv:2405.15792v1 公告类型：新 
摘要：随着数据量和复杂性的增加，检索数据已成为一项更加困难的任务，需要更多的知识和资源。对于物流行业来说尤其如此，新技术的数据收集提供了大量互连的实时数据。智能查询和学习系统 (IQLS) 通过允许使用自然语言来简化数据检索，从而简化了流程。它将结构化数据映射到基于可用元数据和可用数据模型的框架中。该框架为由大型语言模型支持的代理创建了一个环境。该代理利用数据的分层性质，通过做出多个小的上下文感知决策而不是一次性数据检索来迭代过滤。数据过滤后，IQLS 使代理能够完成用户通过接口查询给出的任务。这些接口的范围从多式联运信息检索到多重约束下的路线规划。后者让代理定义一个动态对象，该对象是根据查询参数确定的。该对象代表能够在道路网络中导航的驾驶员。道路网络被描述为具有基于数据的属性的图表。使用 Dijkstra 算法的修改版本，可以确定给定约束下的最佳路线。在整个过程中，用户保持与系统交互和引导的能力。 IQLS 在加拿大物流行业的案例研究中得到展示，允许使用自然语言轻松地进行地理空间、视觉、表格和文本数据的语义查询。]]></description>
      <guid>https://arxiv.org/abs/2405.15792</guid>
      <pubDate>Tue, 28 May 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>使用人类反馈增强主观内容描述</title>
      <link>https://arxiv.org/abs/2405.15786</link>
      <description><![CDATA[arXiv:2405.15786v1 公告类型：新 
摘要：提供信息检索服务的代理可以使用文本文档语料库。语料库中的文档可能包含诸如主观内容描述（SCD）之类的注释——与文档的不同句子相关联的附加数据。每个SCD与语料库中的多个句子相关联，并且彼此之间具有关系。代理使用 SCD 创建答案来响应用户提供的查询。然而，代理使用的 SCD 可能反映另一个用户的主观观点。因此，代理的用户可能认为答案是错误的，因为SCD可能不完全匹配代理的用户的感知。一种幼稚且成本高昂的方法是要求每个用户自己完全创建所有 SCD。为了利用现有知识，本文提出了 ReFrESH，一种人类对 SCD 进行保留关系、依赖反馈的增强的方法。代理的用户可以向代理提供有关错误答案的反馈。然后 ReFrESH 使用此反馈来增量更新 SCD。然而，人类的反馈并不总是明确的。因此，本文还提出了一种方法来决定如何纳入反馈以及何时更新 SCD。总而言之，SCD 可以根据人类反馈进行更新，从而允许用户根据自己的需求创建更具体的 SCD。]]></description>
      <guid>https://arxiv.org/abs/2405.15786</guid>
      <pubDate>Tue, 28 May 2024 06:19:24 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型自动从科学文献中提取化学食品安全危害</title>
      <link>https://arxiv.org/abs/2405.15787</link>
      <description><![CDATA[arXiv:2405.15787v1 公告类型：新 
摘要：过去几十年来，食品安全领域发表的科学论文数量持续增加。因此，食品安全专家不可能阅读所有与食品安全和食物链中危害发生有关的相关文献。然而，重要的是食品安全专家了解最新的发现，并能够以简单、简洁的方式获取这些信息。在这项研究中，提出了一种通过大型语言模型从科学文献中自动提取化学危害的方法。大语言模型开箱即用，应用于科学摘要；不需要额外的模型训练或大型计算集群。测试了三种不同的模型提示方式，以评估哪种方式最适合当前的任务。使用两种验证食品（绿叶蔬菜和贝类）对提示进行了优化，并使用三种测试食品（乳制品、玉米和鲑鱼）评估了最佳提示的最终性能。发现提示的具体措辞对结果有相当大的影响。将任务分解为更小的步骤的提示总体效果最佳。该提示的平均准确度达到 93%，并包含许多已纳入食品监测计划的化学污染物，验证了食品安全领域相关危害的成功检索。结果展示了大型语言模型对于从科学文献中自动提取信息的任务有多么有价值。]]></description>
      <guid>https://arxiv.org/abs/2405.15787</guid>
      <pubDate>Tue, 28 May 2024 06:19:24 GMT</pubDate>
    </item>
    <item>
      <title>基于多媒体的新项目推荐的多模态不变学习</title>
      <link>https://arxiv.org/abs/2405.15783</link>
      <description><![CDATA[arXiv:2405.15783v1 公告类型：新 
摘要：基于多媒体的推荐通过学习用户的内容偏好来提供个性化的项目建议。随着数字设备和应用程序的激增，随着时间的推移，大量的新项目被迅速创建。如何在推理时快速提供新项目的推荐是具有挑战性的。更糟糕的是，现实世界的项目表现出不同程度的模态缺失（例如，许多短视频上传时没有文字描述）。尽管许多努力都致力于基于多媒体的推荐，但它们要么无法处理新的多媒体项目，要么假设建模过程中的模态完整性。
  在本文中，我们强调了解决新项目推荐的模态缺失问题的必要性。我们认为，用户固有的内容偏好是稳定的，并且更好地保持对任意模态缺失环境的不变性。因此，我们从不变学习的新角度来解决这个问题。然而，如何从有限的用户行为训练数据构建环境以概括任何缺失的模态是具有挑战性的。为了解决这个问题，我们提出了一种新颖的多模态不变学习推荐（又名 MILK）框架。具体来说，MILK 首先设计了一个跨模态对齐模块，以保持预训练多媒体项特征的语义一致性。之后，MILK 设计了具有循环混合的多模态异构环境来增强训练数据，以模仿不变用户偏好学习中缺失的任何模态。对三个真实数据集的广泛实验验证了我们提出的框架的优越性。代码可在 https://github.com/HaoyueBai98/MILK 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.15783</guid>
      <pubDate>Tue, 28 May 2024 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>CLARINET：增强语言模型以提出检索所需的澄清问题</title>
      <link>https://arxiv.org/abs/2405.15784</link>
      <description><![CDATA[arXiv:2405.15784v1 公告类型：新
摘要：用户经常提出需要澄清的模棱两可的请求。我们研究在信息检索环境中提出澄清问题的问题，其中系统经常面临模棱两可的搜索查询，并且将检索模型中的不确定性转化为自然语言问题具有挑战性。我们提出了 CLARINET，这是一个通过选择答案可以最大程度地确定正确候选人的问题来提出信息澄清问题的系统。我们的方法通过增强大型语言模型 (LLM) 以条件检索分布，端到端微调以生成每次都能最大化真实候选人排名的问题。当在现实世界中搜索书籍的用户检索数据集上进行评估时，我们的系统比传统的启发式方法（例如检索成功率的信息增益高出 17%）和香草提示的 LLM 高出 39%。]]></description>
      <guid>https://arxiv.org/abs/2405.15784</guid>
      <pubDate>Tue, 28 May 2024 06:19:23 GMT</pubDate>
    </item>
    </channel>
</rss>