<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 09 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>推荐系统中语气感知解释的影响</title>
      <link>https://arxiv.org/abs/2405.05061</link>
      <description><![CDATA[arXiv:2405.05061v1 公告类型：交叉
摘要：在推荐系统中，解释的呈现在支持用户的决策过程中起着至关重要的作用。尽管现有的许多研究都集中在解释内容的效果（透明度或说服力）上，但解释表达在很大程度上被忽视了。语气，如正式语气和幽默语气，与表达能力直接相关，是人类交流中的重要元素。然而，关于推荐系统背景下语气对解释的影响的研究还不够。因此，本研究通过在线用户研究，从感知效果、领域差异和用户属性三个方面探讨解释语气的效果。我们使用大型语言模型创建一个数据集，以生成电影、酒店和家居产品领域中各种语气的虚构项目和解释。收集的数据分析揭示了不同领域的音调的不同感知效果。此外，发现年龄和性格特征等用户属性会影响语气的影响。这项研究强调了语气在推荐系统解释中的关键作用，表明对语气的关注可以增强用户体验。]]></description>
      <guid>https://arxiv.org/abs/2405.05061</guid>
      <pubDate>Thu, 09 May 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 Neo4j 对 SIMON 密码进行密码分析</title>
      <link>https://arxiv.org/abs/2405.04735</link>
      <description><![CDATA[arXiv:2405.04735v1 公告类型：交叉
摘要：物联网 (IoT) 设备数量呈指数级增长，引入了多种轻量级加密算法 (LEA)。虽然 LEA 旨在增强物联网设备收集和传输的数据的完整性、隐私性和安全性，但假设所有 LEA 都是安全的并表现出类似的保护级别是危险的。为了提高加密强度，密码分析人员和算法设计者经常使用各种密码分析技术来探测 LEA，以识别 LEA 的漏洞和限制。尽管最近利用启发式方法和偏差分布表 (PDDT) 提高了密码分析的效率，但该过程仍然效率低下，启发式的随机性抑制了可重现的结果。然而，PDDT 的使用提供了利用知识图识别差异之间关系的机会，从而识别整个 PDDT 的有效路径。本文介绍了知识图谱的新颖用途，用于识别 SIMON LEA 中差异之间的复杂关系，从而识别整个差异的最佳路径，并提高 SIMON 差异安全分析的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.04735</guid>
      <pubDate>Thu, 09 May 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>超图增强双半监督图分类</title>
      <link>https://arxiv.org/abs/2405.04773</link>
      <description><![CDATA[arXiv:2405.04773v1 公告类型：交叉
摘要：本文研究半监督图分类，旨在在标记图有限和未标记图丰富的场景中准确预测图的类别。尽管图神经网络（GNN）的能力很有前景，但它们通常需要大量昂贵的标记图，而大量的未标记图却无法得到有效利用。此外，GNN 本质上仅限于使用消息传递机制对局部邻域信息进行编码，因此缺乏对节点之间高阶依赖关系进行建模的能力。为了应对这些挑战，我们提出了一种名为 HEAL 的超图增强型 DuAL 框架，用于半监督图分类，该框架分别从超图和线图的角度捕获图语义。具体来说，为了更好地探索节点之间的高阶关系，我们设计了一种超图结构学习来自适应学习除成对关系之外的复杂节点依赖关系。同时，基于学习到的超图，我们引入了线图来捕获超边之间的交互，从而更好地挖掘底层语义结构。最后，我们开发了一种关系一致性学习，以促进两个分支之间的知识转移并提供更好的相互指导。对现实世界图数据集的大量实验验证了所提出的方法相对于现有最先进方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.04773</guid>
      <pubDate>Thu, 09 May 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>多边际损失：推荐系统中的提议和应用</title>
      <link>https://arxiv.org/abs/2405.04614</link>
      <description><![CDATA[arXiv:2405.04614v1 公告类型：交叉 
摘要：推荐系统通过根据预测的偏好推荐项目来引导用户浏览大量信息。基于协同过滤的深度学习技术由于其简单易用的特性而重新受到欢迎，仅依赖于用户与项目的交互。通常，这些系统由三个主要组件组成：交互模块、损失函数和负采样策略。最初，研究人员专注于通过开发复杂的交互模块来提高性能。然而，最近出现了一种转向改进损失函数和负采样策略的转变。这种转变导致人们对对比学习的兴趣增加，对比学习将相似的对拉近，同时将不相似的对拉远。对比学习涉及大量数据增强、大批量和硬负采样等关键实践，但这些也带来了高内存需求和某些负样本利用不足等挑战。提出的多边距损失 (MML) 通过为负样本引入多个边距和不同的权重来解决这些挑战。这使得 MML 不仅能够高效利用最难的负样本，还能利用其他非平凡负样本，从而提供更简单但有效的损失函数，其表现优于更复杂的方法，尤其是在资源有限的情况下。在两个著名数据集上进行的实验表明，当使用较少数量的负样本时，MML 的性能比基线对比损失函数提高了 20%。]]></description>
      <guid>https://arxiv.org/abs/2405.04614</guid>
      <pubDate>Thu, 09 May 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>基于边缘的内存计算架构上检索增强生成的稳健实现</title>
      <link>https://arxiv.org/abs/2405.04700</link>
      <description><![CDATA[arXiv:2405.04700v1 公告类型：交叉
摘要：部署在边缘设备上的大型语言模型（LLM）通过微调和更新其参数的特定部分来学习。尽管可以优化此类学习方法以减少资源利用率，但所需的总体资源仍然是边缘设备的沉重负担。相反，检索增强生成（RAG）是一种资源高效的LLM学习方法，可以在不更新模型参数的情况下提高LLM生成内容的质量。然而，基于 RAG 的 LLM 可能会涉及在每次用户与 LLM 交互中对个人资料数据的重复搜索。这种搜索可能会导致显着的延迟以及用户数据的积累。减少延迟的传统方法会限制保存的用户数据的大小，从而随着用户数据的不断增长而降低 RAG 的可扩展性。这仍然是一个悬而未决的问题：如何使 RAG 摆脱边缘设备延迟和可扩展性的限制？在本文中，我们提出了一种通过内存计算 (CiM) 架构来加速 RAG 的新颖框架。它通过在内存内执行原位计算来加速矩阵乘法，同时避免计算单元和内存之间昂贵的数据传输。我们的框架 Robust CiM-backed RAG (RoCR) 利用新颖的基于对比学习的训练方法和噪声感知训练，可以使 RAG 能够使用 CiM 有效地搜索配置文件数据。据我们所知，这是第一个利用 CiM 加速 RAG 的工作。]]></description>
      <guid>https://arxiv.org/abs/2405.04700</guid>
      <pubDate>Thu, 09 May 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>myAURA：通过知识图稀疏化和可视化进行癫痫管理的个性化健康库</title>
      <link>https://arxiv.org/abs/2405.05229</link>
      <description><![CDATA[arXiv:2405.05229v1 公告类型：新
摘要：目的：我们报告以患者为中心的 myAURA 应用程序和一套方法的开发，旨在帮助癫痫患者、护理人员和研究人员做出护理和自我管理决策。
  材料和方法：myAURA 依赖于与癫痫相关的前所未有的异构数据资源的联合，例如生物医学数据库、社交媒体和电子健康记录。开发了一种通用的开源方法来计算多层知识图，通过以人为中心的生物医学词典的术语链接所有这些异构数据。
  结果：该方法的威力首先在药物相互作用现象的研究中得到体现。此外，我们采用了一种新颖的网络稀疏方法，该方法使用加权图的度量主干，揭示了推理、推荐和可视化的最重要边缘，例如患者在社交媒体上讨论的药理学因素。网络稀疏化方法还允许我们从社交媒体中提取重点数字群体，这些群体的话语与癫痫或其他生物医学问题更相关。最后，我们根据焦点小组和其他利益相关者的意见，介绍以患者为中心的 myAURA 设计和试点测试，包括其用户界面。
  讨论：通过稀疏的多层知识图搜索和探索 myAURA 异构数据源的能力，以及将这些层组合在单个地图中，对于集成癫痫相关信息来说是有用的功能。
  结论：我们的利益相关者驱动的、可扩展的方法来整合传统和非传统数据源，实现了癫痫的生物医学发现和数据驱动的患者自我管理，并且可推广到其他慢性疾病。]]></description>
      <guid>https://arxiv.org/abs/2405.05229</guid>
      <pubDate>Thu, 09 May 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>使用张量序列进行语言建模</title>
      <link>https://arxiv.org/abs/2405.04590</link>
      <description><![CDATA[arXiv:2405.04590v1 公告类型：交叉
摘要：我们提出了一种基于最简单的张量网络（即张量序列）的新型张量网络语言模型，称为“张量序列语言模型”（TTLM）。 TTLM 在由单词张量积构造的指数空间中表示句子，但以低维方式计算句子的概率。我们证明二阶 RNN、循环算术电路 (RAC) 和乘法积分 RNN 的架构本质上是 TTLM 的特殊情况。对真实语言建模任务的实验评估表明，所提出的 TTLM 变体（即 TTLM-Large 和 TTLM-Tiny）优于具有低规模隐藏单元的普通循环神经网络（RNN）。 （代码可在 https://github.com/shuishen112/tensortrainlm 获取。）]]></description>
      <guid>https://arxiv.org/abs/2405.04590</guid>
      <pubDate>Thu, 09 May 2024 06:18:36 GMT</pubDate>
    </item>
    <item>
      <title>用于社交推荐的双域协作去噪</title>
      <link>https://arxiv.org/abs/2405.04942</link>
      <description><![CDATA[arXiv:2405.04942v1 公告类型：新
摘要：社交推荐利用社交网络来补充推荐任务中的用户-项目交互数据，旨在缓解推荐系统中的数据稀疏问题。然而，现有的社交推荐方法面临以下挑战：社交网络和交互数据都包含大量噪声，而这种噪声通过图神经网络（GNN）传播不仅不能提高推荐性能，还可能干扰模型的正常训练。尽管去噪对于社交网络和交互数据很重要，但只有有限的研究考虑了社交网络的去噪，并且都忽略了交互数据的去噪，从而阻碍了去噪效果和推荐性能。基于此，我们提出了一种名为“社交推荐双域协作去噪”的新颖模型（$\textbf{DCDSR}$）。 DCDSR包括两个主要模块：结构级协同去噪模块和嵌入空间协同去噪模块。在结构级协同去噪模块中，首先利用交互域的信息来指导社交网络去噪。随后，使用去噪后的社交网络来监督交互数据的去噪。嵌入空间协同去噪模块致力于通过双域嵌入协同扰动的对比学习来抵抗噪声跨域扩散问题。此外，还引入了一种新颖的对比学习策略，名为 Anchor-InfoNCE，以更好地利用对比学习的去噪能力。在三个真实数据集上评估我们的模型，验证了 DCDSR 具有相当大的去噪效果，从而优于最先进的社交推荐方法。]]></description>
      <guid>https://arxiv.org/abs/2405.04942</guid>
      <pubDate>Thu, 09 May 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>通过密集检索对书面论文进行分级相关性评分</title>
      <link>https://arxiv.org/abs/2405.05200</link>
      <description><![CDATA[arXiv:2405.05200v1 公告类型：新
摘要：论文自动评分将论文的评分过程自动化，为提高学生的写作水平提供了很大的优势。虽然整体论文评分研究很普遍，但在针对特定质量特征对论文进行评分方面存在明显差距。在这项工作中，我们关注相关性特征，它衡量学生在整篇论文中保持主题的能力。我们提出了一种采用密集检索编码器对书面论文进行相关性分级评分的新颖方法。然后，不同相关级别的论文的密集表示在嵌入空间中形成簇，这样它们的质心就可能足够分开，以有效地表示它们的相关级别。因此，我们在这些质心上使用简单的 1-Nearest-Neighbor 分类来确定未见过的文章的相关性级别。作为一种有效的无监督密集编码器，我们利用 Contriever，它经过对比学习预先训练，并表现出与监督密集检索模型相当的性能。我们使用广泛使用的 ASAP++ 数据集在特定任务（即对同一任务进行训练和测试）和跨任务（即对未见过的任务进行测试）场景上测试了我们的方法。我们的方法在特定于任务的场景中建立了新的最先进的性能，而其对跨任务场景的扩展则表现出与该场景的最先进的模型相当的性能。我们还分析了我们的方法在更实际的小样本场景中的性能，表明它可以显着降低标签成本，同时仅牺牲 10% 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.05200</guid>
      <pubDate>Thu, 09 May 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>全阶段学习排序：多阶段系统的统一框架</title>
      <link>https://arxiv.org/abs/2405.04844</link>
      <description><![CDATA[arXiv:2405.04844v1 公告类型：新
摘要：概率排序原理（PRP）已被认为是信息检索（IR）系统设计的基本标准。该原则要求 IR 模块返回的结果列表根据潜在的用户兴趣进行排名，以便最大化结果的效用。
  然而，我们指出，在当代 IR 系统的每个阶段不加区别地应用 PRP 是不合适的。此类系统包含多个阶段（例如，检索、预排名、排名和重新排名阶段，如本文所述）。每个阶段模型固有的\emph{选择偏差}都会显着影响最终呈现给用户的结果。
  为了解决这个问题，我们提出了一种改进的多阶段系统排序原则，即广义概率排序原则（GPRP），以强调系统管道每个阶段的选择偏差以及用户的潜在兴趣。
  我们通过一个名为 Full Stage Learning to Rank 的统一算法框架来实现 GPRP。我们的核心思想是首先估计后续阶段的选择偏差，然后学习最符合下游模块选择偏差的排名模型，从而将其排名靠前的结果传递到系统输出的最终排名列表中。
  我们在领先的短视频推荐平台之一中使用模拟和在线 A/B 测试，对我们开发的 Full Stage Learning to Rank 解决方案进行了广泛的实验评估。该算法被证明在检索和排序阶段都是有效的。自部署以来，该算法为平台带来了一致且显着的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2405.04844</guid>
      <pubDate>Thu, 09 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>利用知识图在新闻探索中实现上滚和下钻操作，以进行尽职调查和风险管理</title>
      <link>https://arxiv.org/abs/2405.04929</link>
      <description><![CDATA[arXiv:2405.04929v1 公告类型：新
摘要：有效的新闻探索在现实世界的应用中至关重要，特别是在金融领域，其中许多控制和风险评估任务依赖于公共新闻报道的分析。该领域当前的流程主要依赖于手动操作，通常涉及基于关键字的搜索和广泛的关键字列表的编译。在本文中，我们介绍了 NCEXPLORER，这是一个采用类似 OLAP 操作设计的框架，旨在增强新闻探索体验。 NCEXPLORER 使用户能够使用汇总操作来获得更广泛的内容概述，并使用钻取操作来获得详细的见解。这些操作是通过与外部知识图（KG）集成来实现的，包含基于事实和基于本体的结构。这种集成显着增强了探索能力，提供了一种更全面、更有效的方法来揭示新闻内容中嵌入的底层结构和细微差别。通过具有大师资格的评估人员对 Amazon Mechanical Turk 进行的广泛实证研究证明，NCEXPLORER 使用真实世界新闻数据集，在一系列主题领域中优于现有最先进的新闻搜索方法。]]></description>
      <guid>https://arxiv.org/abs/2405.04929</guid>
      <pubDate>Thu, 09 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>SVD-AE：用于协作过滤的简单自动编码器</title>
      <link>https://arxiv.org/abs/2405.04746</link>
      <description><![CDATA[arXiv:2405.04746v1 公告类型：新
摘要：推荐系统的协同过滤（CF）方法已经得到了广泛的研究，从基于矩阵分解和自动编码器到基于图过滤的方法。最近，人们提出了几乎不需要训练的轻量级方法来减少总体计算。然而，现有方法在准确性、效率和鲁棒性之间的权衡方面仍有改进的空间。特别是，就上述权衡而言，还没有针对 \emph{balanced} CF 进行精心设计的封闭式研究。在本文中，我们设计了SVD-AE，一种简单而有效的基于奇异向量分解（SVD）的线性自动编码器，其闭式解可以基于CF的SVD定义。 SVD-AE 不需要迭代训练过程，因为它的封闭式解可以立即计算。此外，考虑到评级矩阵的噪声性质，我们探索了现有 CF 方法和 SVD-AE 针对此类噪声交互的鲁棒性。因此，我们证明了基于截断 SVD 的简单设计选择可用于增强推荐的噪声鲁棒性，同时提高效率。代码可在 https://github.com/seoyoungh/svd-ae 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.04746</guid>
      <pubDate>Thu, 09 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>基于基础模型的推荐的联合适应</title>
      <link>https://arxiv.org/abs/2405.04840</link>
      <description><![CDATA[arXiv:2405.04840v1 公告类型：新
摘要：随着大型语言模型，特别是具有泛化能力的基础模型的成功，应用基础模型进行推荐成为改进现有推荐系统的新范式。如何使基础模型能够以合理的通信和计算成本及时捕获用户偏好的变化，同时保护隐私，成为一个新的开放挑战。本文提出了一种新颖的联合适应机制，以保护隐私的方式增强基于基础模型的推荐系统。具体来说，每个客户端将使用其私有数据学习一个轻量级个性化适配器。然后，适配器与预先训练的基础模型协作，以细粒度的方式高效地提供推荐服务。重要的是，用户的私人行为数据仍然安全，因为它不与服务器共享。这种基于数据本地化的隐私保护是通过联邦学习框架来体现的。该模型可以确保共享知识被纳入所有适配器中，同时保留每个用户的个人偏好。四个基准数据集的实验结果证明了我们的方法的优越性能。实现代码可用于简化再现性。]]></description>
      <guid>https://arxiv.org/abs/2405.04840</guid>
      <pubDate>Thu, 09 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>利用主题建模增强知识检索，实现基于知识的对话</title>
      <link>https://arxiv.org/abs/2405.04713</link>
      <description><![CDATA[arXiv:2405.04713v1 公告类型：新
摘要：知识检索是构建基于知识的对话系统的主要挑战之一。常见的方法是使用带有分布式近似最近邻数据库的神经检索器来快速找到相关的知识句子。在这项工作中，我们提出了一种利用知识库上的主题建模来进一步提高检索准确性的方法，从而改善响应生成。此外，我们还尝试了大型语言模型 ChatGPT，以利用改进的检索性能来进一步改善生成结果。两个数据集的实验结果表明，我们的方法可以提高检索和生成性能。结果还表明，当提供相关知识时，ChatGPT 是基于知识的对话的更好的响应生成器。]]></description>
      <guid>https://arxiv.org/abs/2405.04713</guid>
      <pubDate>Thu, 09 May 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以弥补评估中缺失的相关性判断</title>
      <link>https://arxiv.org/abs/2405.04727</link>
      <description><![CDATA[arXiv:2405.04727v1 公告类型：新
摘要：未经判断的文档或信息检索基准中的漏洞被认为与评估无关，在衡量有效性方面没有任何收获。然而，这些缺失的判断可能会无意中在评估中引入偏差，因为它们在检索模型中的流行程度在很大程度上取决于汇集过程。因此，填充孔对于确保可靠和准确的评估至关重要。收集所有文档的人类判断既麻烦又不切实际。在本文中，我们的目标是利用大型语言模型（LLM）来自动标记未判断的文档。我们的目标是指导法学硕士使用详细的说明对漏洞进行细粒度的相关性判断。为此，我们通过在TREC DL轨道的相关性判断中随机丢弃相关文档，系统地模拟了不同程度漏洞的场景。我们的实验揭示了我们基于法学硕士的方法与真实相关性判断之间的强相关性。基于我们在三个 TREC DL 数据集上进行的模拟实验，在仅保留 10% 判断的极端情况下，我们的方法在 Vicu\~na-7B 和 GPT-3.5 Turbo 上实现了平均 0.87 和 0.92 的 Kendall tau 相关性分别。]]></description>
      <guid>https://arxiv.org/abs/2405.04727</guid>
      <pubDate>Thu, 09 May 2024 06:18:32 GMT</pubDate>
    </item>
    </channel>
</rss>