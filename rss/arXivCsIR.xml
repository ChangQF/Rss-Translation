<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 11 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>IntellBot：用于传递网络威胁知识的检索增强型 LLM 聊天机器人</title>
      <link>https://arxiv.org/abs/2411.05442</link>
      <description><![CDATA[arXiv:2411.05442v1 公告类型：新
摘要：在快速发展的网络安全领域，智能聊天机器人越来越受到重视。人工智能、机器学习和自然语言处理使这些聊天机器人能够处理用户查询并提供威胁情报。这有助于让专业人士和公众随时获得网络安全知识。传统的基于规则的聊天机器人通常缺乏灵活性，难以适应用户交互。相比之下，基于大型语言模型的聊天机器人提供跨多个领域的上下文相关信息，并适应不断变化的对话环境。在这项工作中，我们开发了 IntellBot，这是一款先进的网络安全聊天机器人，它建立在大型语言模型和 Langchain 等尖端技术之上，并采用检索增强生成模型来提供卓越的功能。这个聊天机器人从不同的数据源收集信息，以创建一个全面的知识库，涵盖已知的漏洞、最近的网络攻击和新出现的威胁。它提供量身定制的响应，作为网络安全洞察的主要中心。通过提供对相关信息和资源的即时访问，此 IntellBot 可增强威胁情报、事件响应和整体安全态势，从而节省时间并让用户掌握网络安全最佳实践知识。此外，我们使用两阶段评估策略分析了副驾驶的性能。我们通过间接方法获得了高于 0.8 的 BERT 分数，余弦相似度分数在 0.8 到 1 之间，这证实了副驾驶的准确性。此外，我们利用 RAGAS 评估 RAG 模型，所有评估指标均一致产生高于 0.77 的分数，突显了我们系统的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.05442</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对快速列表重新排序的单标记解码的早期首次复现和改进</title>
      <link>https://arxiv.org/abs/2411.05508</link>
      <description><![CDATA[arXiv:2411.05508v1 公告类型：新
摘要：最近的进展表明，大型语言模型 (LLM) 作为列表式重排器表现出色，但它们的高计算需求仍然是广泛采用的障碍。此外，传统的语言建模 (LM) 目标并不非常适合重排任务。FIRST 是一种新颖的方法，它通过集成学习排序目标并利用仅第一个生成的 token 的逻辑来解决这些挑战，从而与传统的 LLM 重排器相比显着降低了推理延迟。在本研究中，我们将 FIRST 的评估扩展到 TREC 深度学习数据集 (DL19-22)，验证其在不同领域的稳健性。我们研究了不同的第一阶段检索器对 FIRST 重排器的影响，观察到收益递减和与传统 LLM 重排器一致的模式。通过将 FIRST 目标应用于更广泛的骨干模型，我们实现了超越原始实现的有效性。我们的实验证实，使用单标记逻辑快速重新排序不会损害域外重新排序质量。为了更好地量化原始研究中的计算节省，我们测量并比较了延迟，发现各种模型和基准测试的延迟提高了 21%-42%。此外，虽然 LM 训练隐式地改善了零样本单标记重新排序，但我们的实验也提出了一个问题，即 LM 预训练是否会阻碍后续使用 FIRST 目标进行微调。这些发现为未来应用中更高效、更有效的列表式重新排序铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2411.05508</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么是这些文件？具有分层类别路径的可解释生成检索</title>
      <link>https://arxiv.org/abs/2411.05572</link>
      <description><![CDATA[arXiv:2411.05572v1 公告类型：新
摘要：生成检索最近成为传统信息检索方法的新替代方案。然而，现有的生成检索方法在给出查询时直接解码docid，无法为用户提供解释作为“为什么检索此文档？”的答案。为了解决这一限制，我们提出了分层类别路径增强生成检索（HyPE），它通过在解码docid之前逐步生成分层类别路径来增强可解释性。HyPE利用分层类别路径作为解释，从广泛的语义类别发展到具体的语义类别。该方法通过使用查询和文档之间的共享类别路径，根据查询对同一文档进行不同的解释，并通过由粗到细的方式反映文档的语义结构来提供合理的解释。 HyPE 利用外部高质量语义层级构建类别路径，利用 LLM 为每个文档选择合适的候选路径，并使用路径增强数据集优化生成式检索模型。在推理过程中，HyPE 利用路径感知重排序策略聚合各种主题信息，从而在最终排序的 docid 列表中优先显示最相关的文档。我们大量的实验表明，HyPE 不仅具有高水平的可解释性，而且还提高了文档检索任务中的检索性能。]]></description>
      <guid>https://arxiv.org/abs/2411.05572</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用高级歌曲描述符实现基于自然语言的音乐推荐</title>
      <link>https://arxiv.org/abs/2411.05649</link>
      <description><![CDATA[arXiv:2411.05649v1 公告类型：新
摘要：依赖于语言模型 (LM) 的推荐系统在帮助用户浏览大型目录方面越来越受欢迎。LM 通常利用来自训练数据或用户偏好的项目高级描述符，即类别或消费上下文。这已被证明在电影或产品等领域是有效的。然而，在音乐领域，了解 LM 如何有效地利用歌曲描述符进行基于自然语言的音乐推荐相对有限。在本文中，我们评估了 LM 在根据用户的自然语言描述和具有流派、情绪和聆听环境等描述符的项目推荐歌曲方面的有效性。我们将推荐任务表述为一个密集的检索问题，并在 LM 越来越熟悉与任务和领域相关的数据时对其进行评估。我们的研究结果表明，随着 LM 针对一般语言相似性、信息检索以及将较长的描述映射到音乐中较短的高级描述符进行微调，性能得到了提高。]]></description>
      <guid>https://arxiv.org/abs/2411.05649</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士 (LLM) 在上市平台上实现自然语言搜索</title>
      <link>https://arxiv.org/abs/2411.05048</link>
      <description><![CDATA[arXiv:2411.05048v1 公告类型：交叉 
摘要：企业搜索要求用户具备查询、配置和元数据的复杂知识，这使得他们难以根据需要访问信息。大多数上市 (GTM) 平台都使用高级搜索，这是一种界面，使用户能够使用类别或关键字按各种字段过滤查询，但从历史上看，这已被证明是极其麻烦的，因为用户面临着看似数百个选项、字段和按钮。因此，使用自然语言查询长期以来一直是理想的选择，大型语言模型 (LLM) 进一步增强了这一概念。
在本文中，我们为卖家实施和评估了 Zoominfo 产品的解决方案，该产品使用自然语言提示 LLM，通过实体提取生成搜索字段，然后将其转换为搜索查询。中间搜索字段为每个查询提供了许多优势，包括消除语法错误、更简单的基本事实以及 LLM 解释的直观格式。
我们将此管道与许多先进的提示工程策略相结合，包括复杂的系统消息、少量提示、思路链 (CoT) 推理和执行细化。此外，我们手动创建了 500 多个自然语言查询的基本事实，从而实现了 Llama-3-8B-Instruct 的监督微调，并引入了复杂的数值指标。
通过对单个搜索实体的精确、Jaccard、余弦和语义相似性，对封闭、开源和微调的 LLM 模型进行了全面的实验，以证明我们方法的有效性。总体而言，最准确的封闭模型对每个查询的平均准确率为 97%，只有一个字段的表现低于 90%，与微调模型的结果相当。]]></description>
      <guid>https://arxiv.org/abs/2411.05048</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FineTuneBench：商业微调 API 将知识注入 LLM 的效果如何？</title>
      <link>https://arxiv.org/abs/2411.05059</link>
      <description><![CDATA[arXiv:2411.05059v1 公告类型：交叉 
摘要：人们对微调前沿大型语言模型 (LLM) 以注入新信息和更新现有知识非常感兴趣。虽然来自 OpenAI 和 Google 等提供商的商业 LLM 微调 API 承诺灵活适应各种应用程序，但微调的有效性仍不清楚。在本研究中，我们介绍了 FineTuneBench，这是一个评估框架和数据集，用于了解商业微调 API 成功学习新知识和更新知识的能力。我们分析了五种具有商用微调 API 的前沿 LLM，包括 GPT-4o 和 Gemini 1.5 Pro，在两种环境下的有效性：(1) 提取新信息，例如最近的新闻事件和新的人物资料，以及 (2) 更新现有知识，例如更新的医疗指南和代码框架。我们的结果揭示了所有模型通过微调有效学习新信息的能力都存在重大缺陷，所有模型的平均泛化准确率为 37%。在更新现有知识（例如纳入医疗指南更新）时，商用微调 API 的能力更加有限（平均泛化准确率为 19%）。总体而言，微调 GPT-4o mini 对注入新知识和更新知识最有效，其次是 GPT-3.5 Turbo 和 GPT-4o。Gemini 1.5 Flesh 和 Gemini 1.5 Pro 的微调 API 无法学习新知识或更新现有知识。这些发现凸显了使用当前商用微调服务在常见场景中实现可靠知识注入的重大缺陷。我们在 https://github.com/kevinwu23/StanfordFineTuneBench 开源了 FineTuneBench 数据集。]]></description>
      <guid>https://arxiv.org/abs/2411.05059</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用离线强化学习改进多领域任务导向对话系统</title>
      <link>https://arxiv.org/abs/2411.05340</link>
      <description><![CDATA[arXiv:2411.05340v1 公告类型：交叉 
摘要：面向任务的对话 (TOD) 系统旨在通过对话完成用户定义的任务。通过利用预先训练的大型语言模型，TOD 系统已朝着端到端建模的方向发展。仅使用监督学习对预训练的语言模型进行微调会导致曝光偏差和 token 丢失问题，并使模型无法完成用户的任务。为了解决这些问题，我们提出了一个 TOD 系统，该系统利用统一的预训练语言模型 GPT2 作为基础模型。它使用监督学习和强化学习 (RL) 进行优化。使用不可微的奖励函数可以缓解 TOD 系统中的问题。奖励是使用成功率和 BLEU 评估指标的加权总和来计算的。奖励计算中的成功率和 BLEU 指标指导语言模型完成用户任务，同时确保连贯流畅的响应。我们的模型是通过在对话会话层面微调一个预训练模型而得到的，该对话会话层面包括用户话语、信念状态、系统行为和系统响应。在 MultiWOZ2.1 上的实验结果表明，与基线相比，我们的模型将告知率提高了 1.60%，成功率提高了 3.17%。]]></description>
      <guid>https://arxiv.org/abs/2411.05340</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Ev2R：评估自动事实核查中的证据检索</title>
      <link>https://arxiv.org/abs/2411.05375</link>
      <description><![CDATA[arXiv:2411.05375v1 公告类型：交叉 
摘要：当前的自动事实核查 (AFC) 方法通常通过预测的判决隐式地评估证据，或者通过将检索到的证据与预定义的封闭知识源（例如 Wikipedia）进行比较来评估证据。然而，这些方法存在局限性，因为它们依赖于为不同目的开发的评估指标和封闭知识源施加的限制。自然语言生成 (NLG) 评估的最新进展为证据评估提供了新的可能性。在这项工作中，我们引入了 Ev2R，这是一个 AFC 的评估框架，它包含三种证据评估方法：基于参考、代理参考和无参考。我们通过与人工评分和对抗性测试的一致性来评估它们的有效性，并证明基于提示的评分者，特别是那些利用 LLM 和参考证据的评分者，优于传统的评估方法。]]></description>
      <guid>https://arxiv.org/abs/2411.05375</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论推荐中的生成代理</title>
      <link>https://arxiv.org/abs/2310.10108</link>
      <description><![CDATA[arXiv:2310.10108v3 公告类型：替换 
摘要：推荐系统是当今信息传播的基石，但离线指标和在线性能之间的脱节极大地阻碍了它们的发展。为了应对这一挑战，我们设想了一个推荐模拟器，利用大型语言模型 (LLM) 所展示的人类级智能的最新突破。我们提出了 Agent4Rec，一个推荐中的用户模拟器，利用 LLM 赋能的生成代理，配备专门为推荐系统量身定制的用户配置文件、记忆和操作模块。具体来说，这些代理的配置文件模块使用真实世界的数据集（例如 MovieLens、Steam、Amazon-Book）初始化，捕捉用户独特的品味和社交特征；记忆模块记录事实和情感记忆，并与情感驱动的反射机制相结合；动作模块支持各种各样的行为，涵盖品味驱动和情感驱动的行为。每个代理都以逐页的方式与个性化推荐模型进行交互，依赖于预先实现的基于协同过滤的推荐算法。我们深入研究 Agent4Rec 的功能和局限性，旨在探索一个基本研究问题：“LLM 赋能的生成代理在多大程度上可以在推荐系统中忠实地模拟真实、自主人类的行为？”对 Agent4Rec 进行广泛而多方面的评估，突出了代理与用户个性化偏好之间的一致性和偏差。除了单纯的性能比较之外，我们还探索了富有洞察力的实验，例如模拟过滤气泡效应和发现推荐任务中潜在的因果关系。我们的代码可在 https://github.com/LehengTHU/Agent4Rec 上找到。]]></description>
      <guid>https://arxiv.org/abs/2310.10108</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思维逻辑查询：利用知识图谱引导大型语言模型回答复杂逻辑查询</title>
      <link>https://arxiv.org/abs/2404.04264</link>
      <description><![CDATA[arXiv:2404.04264v4 公告类型：替换 
摘要：尽管大型语言模型（LLM）在许多任务中表现出色，但在面对需要知识准确性的任务时，它存在产生幻觉甚至错误答案的风险。在处理需要多个逻辑推理步骤的逻辑查询时，这个问题变得更加明显。另一方面，基于知识图谱（KG）的问答方法能够借助知识图谱准确地识别正确答案，但当知识图谱本身稀疏和不完整时，其准确性可能会迅速下降。如何以互惠互利的方式将知识图谱推理与 LLM 结合起来，以减轻 LLM 的幻觉问题以及知识图谱的不完整性问题，仍然是一个关键挑战。在本文中，我们提出了“思维逻辑查询”（LGOT），这是第一个将 LLM 与基于知识图谱的逻辑查询推理相结合的方法。 LGOT 无缝结合了知识图谱推理和 LLM，有效地将复杂的逻辑查询分解为易于回答的子问题。通过利用知识图谱推理和 LLM，它成功地为每个子问题得出答案。通过汇总这些结果并为每个步骤选择最高质量的候选答案，LGOT 为复杂问题获得了准确的结果。我们的实验结果表明，性能得到了显着提升，与 ChatGPT 相比，提升幅度高达 20%。]]></description>
      <guid>https://arxiv.org/abs/2404.04264</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于聚类的图协同过滤</title>
      <link>https://arxiv.org/abs/2404.10321</link>
      <description><![CDATA[arXiv:2404.10321v2 公告类型：替换 
摘要：图卷积网络 (GCN) 在学习推荐系统的用户和项目表示方面取得了显著成功。其功效的核心是能够明确利用来自一阶和高阶邻居节点的协作信号。然而，大多数现有的基于 GCN 的方法在执行高阶图卷积时忽略了用户的多种兴趣。因此，来自不可靠邻居节点（例如，具有不同兴趣的用户）的噪声信息会对目标节点的表示学习产生负面影响。此外，在不区分高阶邻居的情况下进行图卷积运算会在堆叠更多层时遭受过度平滑问题，从而导致性能下降。在本文中，我们的目标是从高阶邻居节点捕获更多有价值的信息，同时避免噪声，以便更好地进行目标节点的表示学习。为了实现这一目标，我们提出了一种基于 GCN 的新型推荐模型，称为基于集群的图形协同过滤 (ClusterGCF)。该模型对特定于集群的图执行高阶图卷积，这些图是通过捕获用户的多种兴趣并识别它们之间的共同兴趣而构建的。具体来说，我们设计了一种无监督且可优化的软节点聚类方法，将用户和项目节点分类到多个集群中。基于软节点聚类结果和用户-项目交互图的拓扑结构，我们为不同集群的节点分配概率以构建特定于集群的图。为了评估 ClusterGCF 的有效性，我们在四个公开可用的数据集上进行了广泛的实验。实验结果表明，我们的模型可以显着提高推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10321</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RRADistill：提炼法学硕士的段落排序能力，用于搜索引擎中长尾查询的文档重新排序</title>
      <link>https://arxiv.org/abs/2410.18097</link>
      <description><![CDATA[arXiv:2410.18097v2 公告类型：替换 
摘要：大型语言模型 (LLM) 擅长理解查询和文档之间的语义关系，即使是冗长而复杂的长尾查询也是如此。由于用户参与度低且反馈有限，这些查询对于基于反馈的排名具有挑战性，因此 LLM 的排名能力非常有价值。然而，LLM 的规模大且推理速度慢，因此需要开发更小、更高效的模型 (sLLM)。最近，将排名标签生成集成到蒸馏技术中变得至关重要，但现有方法未充分利用 LLM 的功能并且很麻烦。我们的研究 RRADistill：重新排名能力蒸馏，为编码器和解码器模型提出了一种高效的标签生成流程和新颖的 sLLM 训练方法。我们引入了一种基于编码器的方法，使用术语控制层来捕获术语匹配信号，并引入了一种基于解码器的模型，该模型具有排名层以增强理解。在韩国搜索平台上进行的 A/B 测试验证了我们的方法在提高长尾查询重新排名方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.18097</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用概率深度监督实现抗噪声的 QoS 预测</title>
      <link>https://arxiv.org/abs/2308.02580</link>
      <description><![CDATA[arXiv:2308.02580v3 公告类型：replace-cross 
摘要：准确的服务质量 (QoS) 预测对于提高 Web 推荐系统中的用户满意度至关重要，但现有的预测模型往往忽略特征噪声，主要关注标签噪声。在本文中，我们提出了概率深度监督网络 (PDS-Net)，这是一个强大的框架，旨在有效识别和减轻特征噪声，从而提高 QoS 预测准确性。PDS-Net 采用双分支架构：主分支利用解码器网络从已知特征中学习基于高斯的先验分布，而第二个分支基于真实标签得出后验分布。PDS-Net 的一个关键创新是其基于条件的噪声识别损失函数，它可以精确识别对象（用户或服务）中的噪声特征。一旦识别出噪声特征，PDS-Net 就会细化特征的先验分布，使其与后验分布对齐，并将调整后的分布传播到中间层，有效减少噪声干扰。在两个真实 QoS 数据集上进行的大量实验表明，PDS-Net 的表现始终优于现有模型，与最先进的方法相比，数据集 D1 上的 MAE 平均提高了 8.91%，数据集 D2 上的 MAE 平均提高了 8.32%。这些结果凸显了 PDS-Net 能够准确捕捉复杂的用户-服务关系并处理特征噪声，凸显了其在不同 QoS 预测环境中的稳健性和多功能性。]]></description>
      <guid>https://arxiv.org/abs/2308.02580</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Limpeh ga li gong：新加坡式英语注释的挑战</title>
      <link>https://arxiv.org/abs/2410.16156</link>
      <description><![CDATA[arXiv:2410.16156v2 公告类型：replace-cross 
摘要：新加坡英语，又称口语化新加坡英语，是一种在多元文化新加坡的口头和社会交流中形成的语言。在这项工作中，我们致力于一项基本的自然语言处理 (NLP) 任务：新加坡英语句子的词性 (POS) 标记。为了进行分析，我们构建了一个并行的新加坡英语数据集，其中包含直接的英语翻译和 POS 标签，翻译和 POS 注释由新加坡英语母语人士完成。我们的实验表明，基于自动转换和转换器的标记器在与人工注释的 POS 标签进行评估时，准确率仅为 $\sim 80\%$，这表明该语言的计算分析确实有改进的空间。我们阐述了新加坡英语注释中的挑战：其形式和语义上的不一致性、语言中高度依赖上下文的粒子、其结构独特的表达方式以及语言在不同媒介上的变化。我们的任务定义、最终标签和结果反映了分析由各种方言形成的口语所面临的挑战，并为未来超越 POS 标记的研究铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.16156</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>