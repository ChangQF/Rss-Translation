<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 15 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LoCo 和 M2-BERT 进行基准测试并构建长上下文检索模型</title>
      <link>https://arxiv.org/abs/2402.07440</link>
      <description><![CDATA[arXiv:2402.07440v2 公告类型：替换
摘要：检索管道（许多机器学习系统的一个组成部分）在文档较长（例如 10K 标记或更多）以及识别相关文档需要合成整个文本信息的领域中表现不佳。开发适合这些领域的长上下文检索编码器提出了三个挑战：（1）如何评估长上下文检索性能，（2）如何预训练基本语言模型来表示短上下文（对应于查询）和长上下文（对应于文档），以及（3）如何在 GPU 内存限制所施加的批量大小限制下微调该模型以进行检索。为了应对这些挑战，我们首先引入 LoCoV1，这是一种新颖的 12 任务基准，旨在测量分块不可能或无效的长上下文检索。接下来我们介绍 M2-BERT 检索编码器，这是一种基于 Monarch Mixer 架构构建的 80M 参数状态空间编码器模型，能够扩展到长达 32K 令牌的文档。我们描述了一种预训练数据混合，它允许该编码器处理短上下文序列和长上下文序列，以及一种微调方法，该方法使该基本模型适应仅使用单样本批次进行检索。最后，我们在 LoCoV1 上验证了 M2-BERT 检索编码器，发现它的性能比基于 Transformer 的竞争模型至少高 23.3 个点，尽管包含的参数少了 90 倍以上。]]></description>
      <guid>https://arxiv.org/abs/2402.07440</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>通过检索到的语言模型演示进行情境学习：一项调查</title>
      <link>https://arxiv.org/abs/2401.11624</link>
      <description><![CDATA[arXiv:2401.11624v3 公告类型：replace-cross
摘要：语言模型，特别是预训练的大型语言模型，已经展现出了作为少样本上下文学习器（ICL）的非凡能力，只需在输入上下文中进行几次演示即可适应新任务。然而，模型执行 ICL 的能力对小样本演示的选择很敏感。最近的一项发展是检索针对每个输入查询定制的演示，而不是使用一组固定的演示。演示检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且还被证明可以减少手动示例选择中固有的偏差。鉴于 ICL 令人鼓舞的结果和不断增长的研究以及检索到的演示，我们对该领域的研究进行了广泛的回顾。在本次调查中，我们讨论并比较了检索模型、检索训练过程和推理算法的不同设计选择。]]></description>
      <guid>https://arxiv.org/abs/2401.11624</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>使用基于最近邻的硬负例对时态 GNN 进行鲁棒训练</title>
      <link>https://arxiv.org/abs/2402.09239</link>
      <description><![CDATA[arXiv:2402.09239v1 公告类型：交叉
摘要：时间图神经网络 Tgnn 在未来链接预测任务中表现出了最先进的性能。这些 TGNN 的训练是通过基于无监督损失的均匀随机采样来进行的。在训练期间，在正例的背景下，损失是根据无信息的负例计算的，这会引入冗余和次优性能。在本文中，我们提出了 Tgnn 的改进无监督学习，用基于重要性的负采样代替均匀负采样。我们从理论上激励并定义了负例抽样的动态计算分布。最后，通过对三个真实世界数据集的实证评估，我们表明使用基于提议的负采样的损失进行训练的 Tgnn 提供了一致的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2402.09239</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中的协作语义对齐</title>
      <link>https://arxiv.org/abs/2310.09400</link>
      <description><![CDATA[arXiv:2310.09400v3 公告类型：替换
摘要：传统推荐系统主要利用基于身份（ID）的用户和商品表示，而预训练语言模型（PLM）的出现引入了丰富的商品描述语义建模。然而，PLM 经常忽​​视重要的协作过滤信号，导致在合并协作和语义表示空间以及微调语义表示以更好地与热启动条件保持一致方面面临挑战。我们的工作引入了 CARec，这是一种将协作过滤与语义表示相结合的尖端模型，确保这些表示在语义空间内保持一致，同时保留关键语义。我们在四个真实数据集上进行的实验显示了显着的性能改进。 CARec 的协作对齐方法还将其适用性扩展到冷启动场景，在该场景中，它展示了推荐准确性的显着增强。该代码将在纸质材料被接受后提供。]]></description>
      <guid>https://arxiv.org/abs/2310.09400</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>用于冷启动项目推荐的大型语言模型交互模拟器</title>
      <link>https://arxiv.org/abs/2402.09176</link>
      <description><![CDATA[arXiv:2402.09176v1 公告类型：新
摘要：推荐冷项是协作过滤模型长期面临的挑战，因为这些冷项缺乏历史用户交互来对其协作特征进行建模。冷项的内容与其行为模式之间的差距使得很难为冷项生成准确的行为嵌入。现有的冷启动模型使用映射函数根据冷项的内容特征生成虚假的行为嵌入。然而，这些生成的嵌入与真实的行为嵌入有显着差异，导致对冷推荐性能产生负面影响。为了应对这一挑战，我们提出了一个LLM交互模拟器（LLM-InS）来根据内容方面对用户的行为模式进行建模。该模拟器允许推荐系统模拟每个冷项的生动交互，并将它们直接从冷项转换为热项。具体来说，我们概述了定制的 LLM 模拟器的设计和培训过程，该模拟器可以模拟用户和物品的行为模式。此外，我们引入了一种有效的“过滤和细化”方法，以充分利用法学硕士的模拟能力。最后，我们提出了一种更新方法来更新项目的嵌入。我们基于模拟和真实的交互，在推荐模型中统一了冷品和热品的训练。使用真实行为嵌入的大量实验表明，我们提出的模型 LLM-InS 在冷启动项目推荐方面优于九种最先进的冷启动方法和三种 LLM 模型。]]></description>
      <guid>https://arxiv.org/abs/2402.09176</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>eCeLLM：从大规模、高质量的指令数据中泛化电子商务的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.08831</link>
      <description><![CDATA[arXiv:2402.08831v1 公告类型：交叉
摘要：随着人们在开发有效的电子商务模型方面付出了巨大的努力，传统的电子商务模型在通用电子商务建模方面取得的成功有限，并且在新用户和新产品方面的表现不尽如人意，这是典型的域外泛化挑战。同时，大型语言模型（LLM）在许多领域的通才建模和域外泛化性方面表现出了出色的性能。为了充分释放它们对电子商务的力量，在本文中，我们构建了第一个开源、大规模、高质量的电子商务基准指令数据集ECInstruct。利用 ECInstruct，我们通过指令调整通用 LLM 开发了 eCeLLM，这是一系列电子商务 LLM。我们全面的实验和评估表明，eCeLLM 模型的性能大大优于基线模型，包括最先进的 GPT-4 和领域内评估中最先进的特定任务模型。此外，eCeLLM 对域外设置（包括未见过的产品和未见过的指令）表现出出色的泛化性，凸显了其作为通用电子商务模型的优越性。 ECInstruct 数据集和 eCeLLM 模型在为电子商务提供多功能且有效的法学硕士方面都显示出巨大的潜力。 ECInstruct 和 eCeLLM 模型可通过 https://ninglab.github.io/eCeLLM 公开访问。]]></description>
      <guid>https://arxiv.org/abs/2402.08831</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:13 GMT</pubDate>
    </item>
    <item>
      <title>通过保形预测对顺序推荐系统进行置信感知微调</title>
      <link>https://arxiv.org/abs/2402.08976</link>
      <description><![CDATA[arXiv:2402.08976v1 公告类型：新
摘要：在顺序推荐系统中，通常使用交叉熵（CE）损失，但无法在训练期间利用项目置信度得分。认识到信心在使训练目标与评估指标保持一致方面的关键作用，我们提出了 CPFT，这是一种多功能框架，通过在微调期间将基于保形预测 (CP) 的损失与 CE 损失相结合来增强推荐信心。 CPFT 动态生成一组很有可能包含真实情况的项目，通过合并验证数据来丰富训练过程，而不会影响其在模型选择中的作用。这种创新方法与基于 CP 的损失相结合，更加注重细化推荐集，从而提高对潜在项目预测的置信度。通过基于 CP 的损失来微调项目置信度，CPFT 显着增强了模型性能，从而提供更精确、更值得信赖的推荐，从而提高用户信任度和满意度。我们对五个不同数据集和四个不同序列模型的广泛评估证实了 CPFT 通过战略置信度优化对提高推荐质量具有重大影响。论文被接受后将提供对框架代码的访问。]]></description>
      <guid>https://arxiv.org/abs/2402.08976</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>基于推荐会话的推荐算法</title>
      <link>https://arxiv.org/abs/2402.09130</link>
      <description><![CDATA[arXiv:2402.09130v1 公告类型：新
摘要：互联网的巨大发展，无论是在地理范围还是在日常生活中利用其可能性方面，都决定了大量数据的创建和收集。由于规模巨大，无法使用传统方法对其进行分析，因此有必要使用现代方法和技术。除其他外，建议领域还提供了此类方法。本研究的目的是在推荐系统领域提出一种新算法，该算法基于来自各种信息集的数据，包括静态（对象类别、对象特征）和动态（用户行为）。]]></description>
      <guid>https://arxiv.org/abs/2402.09130</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>通过基于会话的推荐中的替代培训增强 ID 和文本融合</title>
      <link>https://arxiv.org/abs/2402.08921</link>
      <description><![CDATA[arXiv:2402.08921v1 公告类型：新
摘要：基于会话的推荐近年来受到越来越多的关注，其目的是根据用户在会话中的历史行为提供量身定制的建议。
  为了推进这一领域的发展，人们开发了多种方法，其中基于 ID 的方法通常表现出良好的性能。然而，这些方法经常面临长尾项目的挑战，并忽略其他丰富形式的信息，特别是有价值的文本语义信息。为了整合文本信息，已经引入了各种方法，大多数都遵循朴素的融合框架。令人惊讶的是，我们观察到，通过遵循朴素的融合框架，融合这两种模式并不总是优于最佳的单一模式。进一步的调查揭示了朴素融合中潜在的不平衡问题，其中 ID 占主导地位，而文本模态训练不足。这表明意外的观察结果可能源于朴素融合未能有效平衡两种模式，往往过度依赖更强的 ID 模式。这一见解表明，朴素融合在组合 ID 和文本方面可能不如之前预期的那么有效。为了解决这个问题，我们提出了一种新颖的替代训练策略 AlterRec。它将ID和文本的训练分开，从而避免了naive fusion中出现的不平衡问题。此外，AlterRec 设计了一种新颖的策略来促进两种模式之间的交互，使它们能够相互学习并更有效地整合文本。综合实验证明了 AlterRec 在基于会话的推荐中的有效性。该实现可在 https://github.com/Juanhui28/AlterRec 上找到。]]></description>
      <guid>https://arxiv.org/abs/2402.08921</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>多标签零样本产品属性值提取</title>
      <link>https://arxiv.org/abs/2402.08802</link>
      <description><![CDATA[arXiv:2402.08802v1 公告类型：新
摘要：电商平台应提供详细的产品描述（属性值），以实现有效的产品搜索和推荐。然而，属性值信息通常不可用于新产品。为了预测看不见的属性值，需要大量标记的训练数据来训练传统的监督学习模型。通常，手动标记大量新产品配置文件既困难又耗时且成本高昂。在本文中，我们提出了一种新颖的方法，可以在没有标记数据（零样本设置）的情况下高效地从新产品中提取看不见的属性值。我们提出了 HyperPAVE，一种多标签零样本属性值提取模型，利用异构超图中的归纳推理。特别是，我们提出的技术构建异构超图来捕获复杂的高阶关系（即用户行为信息），以学习图节点更准确的特征表示。此外，我们提出的 HyperPAVE 模型使用归纳链接预测机制来推断未见节点之间的未来连接。这使得 HyperPAVE 能够识别新的属性值，而无需标记训练数据。我们对 MAVE 数据集的不同类别进行了广泛的消融研究实验。结果表明，我们提出的 HyperPAVE 模型在零样本设置中的属性值提取方面显着优于现有的基于分类、基于生成的大型语言模型。]]></description>
      <guid>https://arxiv.org/abs/2402.08802</guid>
      <pubDate>Thu, 15 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    </channel>
</rss>