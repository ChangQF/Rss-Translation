<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Mon, 15 Jan 2024 03:15:04 GMT</lastBuildDate>
    <item>
      <title>使用语料库特定词汇改进学习稀疏检索。 （arXiv：2401.06703v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06703</link>
      <description><![CDATA[我们探索利用语料库特定词汇来改善两者
学习稀疏检索系统的效率和有效性。我们发现
在目标语料库上预训练底层 BERT 模型，具体来说
针对纳入文档扩展的不同词汇量
处理，在某些场景下将检索质量提高高达 12%
延迟减少高达 50%。我们的实验表明，采用
语料库特定词汇量和词汇量的增加会降低平均词汇量
帖子列表长度进而减少延迟。消融研究表明
自定义词汇、文档扩展之间有趣的交互
技术和稀疏模型的稀疏化目标。两者功效
效率的提高转移到不同的检索方法，例如
uniCOIL 和 SPLADE 并提供了一种简单而有效的方法来提供新的
学习稀疏检索系统的效率-效果权衡。
]]></description>
      <guid>http://arxiv.org/abs/2401.06703</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>用于大规模转化漏斗优化的无模型近似贝叶斯学习。 （arXiv：2401.06710v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06710</link>
      <description><![CDATA[根据消费者状态灵活选择广告操作
对于现代营销活动至关重要。我们研究的问题是
确定最佳的顺序个性化干预措施，最大限度地提高
新产品的采用概率。我们通过以下方式对消费者行为进行建模
捕获每个消费者状态的转换漏斗（例如，交互
与公司的历史）并允许消费者行为作为函数而变化
她的国家和公司的连续干预。我们展示我们的模型
以非常高的准确度捕获消费者行为（样本外 AUC 超过
0.95）在现实世界的电子邮件营销数据集中。然而，这会导致非常
大规模学习问题，企业必须学习特定于州的知识
消费者互动中各种干预措施的影响。我们提议写一本小说
针对这个问题的基于归因的决策算法，我们称之为
无模型近似贝叶斯学习。我们的算法继承了
汤普森抽样的强盗的可解释性和可扩展性并保持
对每个州特定干预措施价值的大致信念。这
当算法与消费者交互时，信念就会更新。尽管是
贝叶斯更新的近似，我们证明了我们的渐近最优性
算法并分析其收敛速度。我们证明我们的算法
在广泛的模拟中显着优于传统方法
根据真实世界的电子邮件营销数据集进行校准。
]]></description>
      <guid>http://arxiv.org/abs/2401.06710</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>LLMRS：释放基于 LLM 的软件购买推荐系统的潜力。 （arXiv：2401.06676v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06676</link>
      <description><![CDATA[推荐系统无处不在，从 Spotify 播放列表建议到
亚马逊产品建议。然而，取决于方法或
数据集，这些系统通常无法捕获用户偏好并生成
一般性建议。大型语言模型 (LLM) 的最新进展
为分析用户查询提供有希望的结果。然而，采用这些
捕捉用户偏好和效率的模型仍然是一个悬而未决的问题。在
在本文中，我们提出了 LLMRS，一种基于 LLM 的零样本推荐系统，其中
我们采用预先训练的 LLM 将用户评论编码为评论分数，
生成用户定制的建议。我们在 LLMRS 上进行了实验
真实世界数据集，亚马逊产品评论，用于软件购买使用
案例。结果表明 LLMRS 优于基于排名的基线模型
在成功从产品评论中捕获有意义的信息的同时，
从而提供更可靠的建议。
]]></description>
      <guid>http://arxiv.org/abs/2401.06676</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>DQNC2S：基于 DQN 的跨流危机事件汇总器。 （arXiv：2401.06683v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06683</link>
      <description><![CDATA[同时汇总多个与灾难相关的数据流是
特别具有挑战性，因为现有的检索和重新排名策略受到
多流数据固有的冗余和有限的可扩展性
多查询设置。这项工作提出了一种危机时间表的在线方法
基于深度 Q 网络弱注释的生成。它即时选择
相关文本片段，无需人工注释，也无需
内容重新排名。这使得推理时间与数量无关
输入查询。所提出的方法还将冗余滤波器合并到
奖励函数有效处理跨流内容重叠。这
取得的 ROUGE 和 BERTScore 结果优于表现最佳的结果
CrisisFACTS 2022 基准上的模型。
]]></description>
      <guid>http://arxiv.org/abs/2401.06683</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:02 GMT</pubDate>
    </item>
    <item>
      <title>SemIoE 本体：基于 IoE 的行业的语义模型解决方案。 （arXiv：2401.06667v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06667</link>
      <description><![CDATA[最近，工业 5.0 作为一种新颖的范例而受到关注，它定义了
接下来的具体步骤是朝着越来越智能、绿色意识和
以用户为中心的数字系统。在智能设备泛滥的时代
工业领域采用的技术越来越复杂和自主，
物联网及其演变，被称为万物互联
（简称 IoE），还涉及人、机器人、流程和数据
网络，代表了行业提供经验的主要驱动力
以及处于生态系统中心的人类的需求。然而，由于
所涉及实体的极端异质性、其内在需求和
合作能力以及适应以用户为中心的动态目标
背景下，需要特别注意整合和处理
这种 IoE 产生的数据。这就是本文的目的，
其中我们提出了一种新颖的语义模型，该模型形式化了基本的
万物互联的参与者、元素和信息以及它们之间的关系。在
我们的设计，我们专注于最先进的设计原则，特别是
重用和抽象，构建“SemIoE”，一个继承的轻量级本体
并从众所周知的综合参考本体中扩展概念。
定义的语义层代表了一个核心数据模型，可以扩展到
拥抱任何现代工业场景。它代表了 IoE 的基础
知识图，除此之外，作为额外的贡献，我们分析并
为基于 IoE 的行业定义一些基本服务。
]]></description>
      <guid>http://arxiv.org/abs/2401.06667</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:01 GMT</pubDate>
    </item>
    <item>
      <title>Mapping Transformer 利用嵌入进行跨语言文档表示。 （arXiv：2401.06583v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06583</link>
      <description><![CDATA[文档的推荐系统已成为查找相关内容的工具
网络上的内容。然而，这些系统在以下方面存在局限性：
推荐与查询语言不同的语言的文档，这
意味着他们可能会忽视非母语的资源。这项研究
专注于使用 Transformer 跨语言表示文档
映射到跨语言的利用文档表示 (TLDR)
领域。四种多语言预训练 Transformer 模型（mBERT、mT5 XLM
RoBERTa、ErnieM）使用 20 种语言的三种映射方法进行评估
代表欧洲五种选定语言的组合的对
联盟。诸如伴侣检索率和倒数排名之类的指标被用来
衡量映射的 TLDR 与非映射的 TLDR 相比的有效性。这
结果凸显了通过以下方式实现的跨语言表示的力量
预训练的变压器和映射方法表明了一种有前途的方法
超越语言联系，在两种特定的语言之间扩展的方向
语言。
]]></description>
      <guid>http://arxiv.org/abs/2401.06583</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>Ada-Retrieval：用于顺序推荐的自适应多轮检索范式。 （arXiv：2401.06633v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06633</link>
      <description><![CDATA[检索模型旨在选择一小组匹配的候选项目
给定用户的偏好。他们在大规模的
推荐系统，因为后续模型（例如排序器）高度依赖于
候选项目的质量。然而，大多数现有的检索模型都采用
单轮推理范式，可能无法充分捕捉动态
用户偏好的性质并停留在项目空间的一个区域。在这个
论文中，我们提出了 Ada-Retrieval，一种自适应多轮检索范式
推荐系统迭代地细化用户表示以更好地
在整个项目空间中捕获潜在的候选者。 Ada 检索包括
两个关键模块：项目表示适配器和用户表示
适配器，旨在将上下文信息注入项目和用户
交涉。该框架保持了与模型无关的设计，允许
与各种骨干模型（例如 RNN 或 Transformer）无缝集成。
我们对三个广泛使用的公共数据集进行了实验，其中包含五个
强大的顺序推荐器作为骨干模型。我们的结果表明
Ada-Retrieval 显着增强了各种基础的性能
模型，在不同数据集上观察到一致的改进。我们的
代码和数据可公开获取：
https://github.com/ll0ruc/Ada-Retrieval。
]]></description>
      <guid>http://arxiv.org/abs/2401.06633</guid>
      <pubDate>Mon, 15 Jan 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>UNEX-RL：通过单向执行增强多阶段推荐系统的长期奖励。 （arXiv：2401.06470v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06470</link>
      <description><![CDATA[近年来，人们对利用强化手段越来越感兴趣
学习（RL）以优化推荐系统中的长期奖励。自从
工业推荐系统通常被设计为多级系统，
使用单个智能体的强化学习方法在优化多个阶段时面临挑战
同时地。原因在于不同阶段有不同的观察
空间，因此不能由单个代理建模。为了解决这个问题，我们
提出一种新颖的基于单向执行的多智能体强化
学习（UNEX-RL）框架，加强多阶段的长期奖励
推荐系统。我们证明单向执行是一个关键特征
多阶段推荐系统的出现，给应用带来新的挑战
多智能体强化学习（MARL）的，即观察依赖
和级联效应。为了应对这些挑战，我们提供了级联
信息链（CIC）方法将独立观察结果与
依赖于行动的观察并使用 CIC 来有效地培训 UNEX-RL。我们也
讨论 UNEX-RL 的实用方差减少技术。最后，我们展示
UNEX-RL 在公共数据集和在线推荐系统上的有效性
系统拥有超过1亿用户。具体来说，UNEX-RL 显示了 0.558%
与单智能体强化学习算法相比，用户的使用时间有所增加
在线A/B实验，凸显UNEX-RL在工业中的有效性
推荐系统。
]]></description>
      <guid>http://arxiv.org/abs/2401.06470</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>INTERS：通过指令调整释放大型语言模型在搜索中的力量。 （arXiv：2401.06532v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.06532</link>
      <description><![CDATA[大型语言模型 (LLM) 在以下方面表现出了令人印象深刻的能力
各种自然语言处理任务。尽管如此，他们的应用
由于很少出现，信息检索（IR）任务仍然具有挑战性
许多 IR 特定概念在自然语言中的出现。虽然基于提示
方法可以为法学硕士提供任务描述，但它们通常在以下方面存在不足：
促进对IR任务的全面理解和执行，从而
限制了法学硕士的适用性。为了解决这一差距，在这项工作中，我们探索了
指令调整的潜力可提高法学硕士在 IR 任务中的熟练程度。我们
引入一种新颖的指令调优数据集 INTERS，包含 21 项任务
跨越三个基本的 IR 类别：查询理解、文档
理解，以及查询-文档关系的理解。数据是
源自 43 个不同的数据集和手动编写的模板。我们的
实证结果表明，INTERS 显着提高了性能
各种公开的法学硕士，例如 LLaMA、Mistral 和 Phi
搜索相关任务。此外，我们还进行了全面的分析
确定基础模型选择、指令设计、体积的影响
说明和任务多样性对绩效的影响。我们制作数据集和
对其进行微调的模型可公开访问 https://github.com/DaoD/INTERS。
]]></description>
      <guid>http://arxiv.org/abs/2401.06532</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>TRACE：用于快速数据洞察的时间关系近似立方体引擎。 （arXiv：2401.06336v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06336</link>
      <description><![CDATA[一大类数据问题可以建模为识别重要的
由用户定义的指标驱动的数据片。本文提出了 TRACE，一个
时间关系近似立方体引擎，可实现交互式分析
这种切片的前期成本较低——无论是空间还是计算。确实如此
这是通过随着时间的推移具体化立方体最重要的部分来实现的
针对一大类分析查询的交互式查询，例如哪一部分
我的企业收入增长最高（[子类别=运动器材，
性别=女性]），哪些部分在每用户收入方面落后（[州= CA，
年龄=20-30]）。支持许多用户定义的指标，包括常见的
聚合，例如 SUM、COUNT、DISTINCT COUNT 以及更复杂的聚合，例如
平均的。我们针对各种业务用例实施和部署了 TRACE。
]]></description>
      <guid>http://arxiv.org/abs/2401.06336</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>在基于社交的项目推荐中使用 Transformer Layer 改进图卷积网络。 （arXiv：2401.06436v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06436</link>
      <description><![CDATA[在这项工作中，我们提出了一种改进 GCN 的方法
预测社交网络中的评分。我们的模型是从标准扩展而来的
具有多层变压器架构的模型。该项目的主要焦点是
论文是关于网络中节点嵌入的编码器架构。使用
基于图的卷积层的嵌入层，注意力
机制可以重新排列特征空间以获得更有效的嵌入
用于下游任务。实验表明我们提出的架构
在传统的链接预测任务上取得了比 GCN 更好的性能。
]]></description>
      <guid>http://arxiv.org/abs/2401.06436</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>MuGI：通过多文本生成与大型语言模型集成增强信息检索。 （arXiv：2401.06311v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06311</link>
      <description><![CDATA[大型语言模型 (LLM) 已成为语言领域的关键力量
技术。他们强大的推理能力和广泛的知识
存储库实现了卓越的零样本泛化能力
自然语言处理领域的各个方面，包括信息
检索（IR）。在本文中，我们对此进行了深入的调查
法学硕士为 IR 生成的文档的实用性。我们介绍一个简单的
有效的框架，多文本生成集成（MuGI），以增强
现有的 IR 方法。具体来说，我们提示法学硕士生成多个
伪引用并与查询集成以进行检索。免培训的
MuGI 模型超越了现有的查询扩展策略，树立了新标准
在稀疏检索中。它超过了 ANCE 和 DPR 等受监管的同行，
在 TREC DL 数据集上的 BM25 实现了超过 18% 的显着增强，并且
BEIR 增长 7.5%。通过 MuGI，我们打造了快速、高保真的
重新排列管道。这允许相对较小的 110M 参数检索器
在域内评估中超越了较大的 3B 模型的性能，同时
还缩小了分配外情况下的差距。我们发布我们的代码
以及 https://github.com/lezhang7/Retrieval_MuGI 上生成的所有引用。
]]></description>
      <guid>http://arxiv.org/abs/2401.06311</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>用于系统评论筛选自动化的零样本生成大型语言模型。 （arXiv：2401.06320v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.06320</link>
      <description><![CDATA[系统评价对于循证医学至关重要，因为它们
全面分析已发表的针对特定问题的研究成果。
进行此类审查通常需要大量资源和时间，尤其是在
筛选阶段，评估出版物摘要是否纳入
在评论中。本研究调查了使用零样本大样本的有效性
用于自动筛选的语言模型〜（LLM）。我们评估有效性
八个不同的法学硕士并研究了一种使用
预定义的召回阈值来确定出版物是否应该被
纳入系统评价。我们综合评价五项
标准测试集表明指令微调起着重要作用
在筛选中的作用，校准使法学硕士对于实现
有针对性的召回，并将两者与零样本模型集合相结合
与最先进的方法相比，可以节省大量筛选时间。
]]></description>
      <guid>http://arxiv.org/abs/2401.06320</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>学习无监督语义文档表示以进行基于方面的细粒度情感分析。 （arXiv：2401.06210v1 [cs.LG]）</title>
      <link>http://arxiv.org/abs/2401.06210</link>
      <description><![CDATA[文档表示是许多机器上 NLP 任务的核心
理解。以无监督方式学习的一般表示
保留通用性，可用于各种应用。在实践中，
情感分析（SA）一直是一项具有挑战性的任务，被认为是
与语义深度相关，通常用于评估一般表示。
现有的无监督文档表示学习方法可以是
分为两个系列：顺序系列，明确采用
考虑单词的顺序和非顺序的单词，这不
明确地这样做。然而，他们俩都有自己的弱点。在
在本文中，我们提出了一个模型来克服两者遇到的困难
方法族。实验表明我们的模型优于
流行的 SA 数据集上最先进的方法和基于方面的细粒度
SA大幅领先。
]]></description>
      <guid>http://arxiv.org/abs/2401.06210</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>MultiSlot ReRanker：推荐系统中基于通用模型的重排序框架。 （arXiv：2401.06293v1 [cs.AI]）</title>
      <link>http://arxiv.org/abs/2401.06293</link>
      <description><![CDATA[在本文中，我们提出了一个基于通用模型的重新排名框架，
MultiSlot ReRanker，同时优化相关性、多样性和
新鲜。具体来说，我们的顺序贪婪算法（SGA）是高效的
足够（线性时间复杂度）用于大规模生产推荐
引擎。线下面积提升了 $+6\%$ 至 $ +10\%$
接收者操作特征曲线（AUC）这主要是由于明确
对列表中的项目之间的相互影响进行建模，并利用第二个
通过多个目标的排名分数。此外，我们还概括了
离线重放理论到多槽重新排名场景，并进行权衡
多个目标之间。离线重播效果还有待进一步提升
通过帕累托最优。此外，我们还构建了一个多槽重新排名模拟器
基于与 Ray 框架集成的 OpenAI Gym。它可以很容易地
针对不同的假设进行配置，以快速对加固进行基准测试
学习和监督学习算法。
]]></description>
      <guid>http://arxiv.org/abs/2401.06293</guid>
      <pubDate>Mon, 15 Jan 2024 03:14:56 GMT</pubDate>
    </item>
    </channel>
</rss>