<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 18 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用基础模型增强菜谱检索：数据增强视角</title>
      <link>https://arxiv.org/abs/2312.04763</link>
      <description><![CDATA[arXiv:2312.04763v2 公告类型：替换 
摘要：在公共嵌入空间中学习食谱和食物图像表示并非易事，但对于跨模态食谱检索至关重要。在本文中，我们通过利用基础模型进行数据增强，为这个问题提出了一个新的视角。利用基础模型（即 Llama2 和 SAM）的卓越功能，我们建议通过提取与对应物相关的可对齐信息来增强食谱和食物图像。具体来说，Llama2 用于从食谱中生成文本描述，旨在捕捉食物图像的视觉线索，SAM 用于生成与食谱中关键成分相对应的图像片段。为了充分利用增强数据，我们引入了数据增强检索框架 (DAR) 来增强跨模态检索的食谱和图像表示学习。我们首先将适配器层注入预训练的 CLIP 模型以降低计算成本，而不是完全微调所有参数。此外，我们还提出了多级圆损失来对齐原始数据对和增强数据对，从而为正对和负对分配不同的惩罚。在 Recipe1M 数据集上，我们的 DAR 大大优于所有现有方法。大量的消融研究验证了 DAR 每个组件的有效性。]]></description>
      <guid>https://arxiv.org/abs/2312.04763</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:48 GMT</pubDate>
    </item>
    <item>
      <title>AgentPoison：通过毒害内存或知识库对 LLM 代理进行红队攻击</title>
      <link>https://arxiv.org/abs/2407.12784</link>
      <description><![CDATA[arXiv:2407.12784v1 公告类型：交叉 
摘要：LLM 代理在各种应用中都表现出色，这主要归功于它们在推理、利用外部知识和工具、调用 API 以及执行操作与环境交互方面的高级能力。当前的代理通常使用记忆模块或检索增强生成 (RAG) 机制，从知识库中检索具有类似嵌入的过去知识和实例，以通知任务规划和执行。然而，对未经验证的知识库的依赖引发了人们对其安全性和可信度的重大担忧。为了发现此类漏洞，我们提出了一种新颖的红队方法 AgentPoison，这是第一个针对通用和基于 RAG 的 LLM 代理的后门攻击，通过毒害其长期记忆或 RAG 知识库。具体来说，我们将触发器生成过程形成为约束优化，通过将触发的实例映射到唯一的嵌入空间来优化后门触发器，从而确保每当用户指令包含优化的后门触发器时，都会以高概率从中毒内存或知识库中检索到恶意演示。同时，没有触发器的良性指令仍将保持正常性能。与传统的后门攻击不同，AgentPoison 不需要额外的模型训练或微调，优化的后门触发器表现出卓越的可转移性、上下文连贯性和隐蔽性。大量实验证明了 AgentPoison 在攻击三种类型的现实世界 LLM 代理方面的有效性：基于 RAG 的自动驾驶代理、知识密集型 QA 代理和医疗保健 EHRAgent。在每个代理上，AgentPoison 的平均攻击成功率高于 80%，对良性性能的影响最小（不到 1%），中毒率低于 0.1%。]]></description>
      <guid>https://arxiv.org/abs/2407.12784</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>通过影响函数进行推荐反学习</title>
      <link>https://arxiv.org/abs/2307.02147</link>
      <description><![CDATA[arXiv:2307.02147v2 公告类型：替换 
摘要：推荐反学习是一项新兴任务，旨在帮助用户从训练有素的推荐模型中删除不可用的数据（例如，一些历史行为）。现有方法通过在删除不可用数据后完全或部分重新训练模型来处理反学习请求。然而，由于完全重新训练的计算成本高，部分训练的性能损失可能性高，这些方法是不切实际的。从这个角度来看，理想的推荐反学习方法应该以更有效的方式获得与完全重新训练类似的模型，即实现完全、高效和无害的反学习。
在这项工作中，我们提出了一种新的基于影响函数的推荐反学习 (IFRU) 框架，该框架通过影响函数估计不可用数据对模型的影响，从而有效地更新模型而无需重新训练。鉴于最近的推荐模型使用历史数据来构建优化损失和计算图（例如邻域聚合），IFRU 联合估计不可用数据对优化损失的直接影响和对计算图的溢出影响，以追求完全的反学习。此外，我们提出了一种基于重要性的剪枝算法来降低影响函数的成本。IFRU 是无害的，适用于主流可微分模型。大量实验表明，与基于再训练的方法相比，IFRU 实现了 250 倍以上的加速，推荐性能与完全再训练相当。代码可在 https://github.com/baiyimeng/IFRU 获得。]]></description>
      <guid>https://arxiv.org/abs/2307.02147</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>跨模态图像文本检索的对象感知查询扰动</title>
      <link>https://arxiv.org/abs/2407.12346</link>
      <description><![CDATA[arXiv:2407.12346v1 公告类型：交叉 
摘要：预训练的视觉和语言 (V\&amp;L) 模型大大提高了跨模态图像文本检索的性能。然而，一般来说，由于单词和图像中的小物体之间的粗略对齐，V\&amp;L 模型对小物体的检索性能有限。相反，众所周知，人类的认知是以物体为中心的，我们会更加关注重要的物体，即使它们很小。为了弥合人类认知和 V\&amp;L 模型能力之间的差距，我们提出了一种基于“对象感知查询扰动”的跨模态图像文本检索框架。所提出的方法生成检测到的对象的关键特征子空间，并使用该子空间扰动相应的查询以提高图像中的对象感知。在我们提出的方法中，可以实现对象感知的跨模态图像文本检索，同时保持现有 V\&amp;L 模型的丰富表达能力和检索性能，而无需进行额外的微调。在四个公共数据集上的综合实验表明，我们的方法优于传统算法。]]></description>
      <guid>https://arxiv.org/abs/2407.12346</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>E5-V：具有多模态大型语言模型的通用嵌入</title>
      <link>https://arxiv.org/abs/2407.12580</link>
      <description><![CDATA[arXiv:2407.12580v1 公告类型：交叉 
摘要：多模态大型语言模型 (MLLM) 在一般视觉和语言理解方面显示出了令人鼓舞的进步。然而，使用 MLLM 表示多模态信息仍然在很大程度上未被探索。在这项工作中，我们引入了一个新框架 E5-V，旨在使 MLLM 适应实现通用多模态嵌入。我们的研究结果强调了与以前的方法相比，MLLM 在表示多模态输入方面的巨大潜力。通过利用带有提示的 MLLM，E5-V 有效地弥合了不同类型输入之间的模态差距，即使没有微调，也在多模态嵌入中表现出强大的性能。我们为 E5-V 提出了一种单模态训练方法，其中模型专门针对文本对进行训练。与传统的图像-文本对多模态训练相比，该方法表现出显着的改进，同时将训练成本降低了约 95%。此外，这种方法消除了昂贵的多模态训练数据收集的需要。针对四类任务的大量实验证明了 E5-V 的有效性。作为通用多模态模型，尽管仅基于单一模态进行训练，E5-V 在每个任务中不仅达到甚至超越了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.12580</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>爱尔兰传统舞蹈音乐的柯尔莫哥洛夫复杂性</title>
      <link>https://arxiv.org/abs/2407.12000</link>
      <description><![CDATA[arXiv:2407.12000v1 公告类型：交叉 
摘要：我们使用 Lempel-Ziv 压缩估计爱尔兰传统舞蹈音乐中旋律的 Kolmogorov 复杂度。音乐的“曲调”以所谓的“ABC 符号”呈现，只是字母表中的字母序列：我们没有节奏变化，所有音符的长度相等。我们对算法复杂度的估计可用于区分“简单”或“容易”的曲调（重复次数较多）和“困难”的曲调（重复次数较少），这对学习曲调的学生很有用。我们进一步对两种曲调类别（里尔舞曲和吉格舞曲）的复杂性进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2407.12000</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>ModalChorus：通过模态融合图进行多模态嵌入的视觉探测和对齐</title>
      <link>https://arxiv.org/abs/2407.12315</link>
      <description><![CDATA[arXiv:2407.12315v1 公告类型：交叉 
摘要：多模态嵌入构成了视觉语言模型的基础，例如 CLIP 嵌入，这是最广泛使用的文本图像嵌入。然而，这些嵌入容易受到跨模态特征的细微错位的影响，导致模型性能下降和泛化能力下降。为了解决这个问题，我们设计了 ModalChorus，这是一个用于多模态嵌入的视觉探测和对齐的交互式系统。ModalChorus 主要提供一个两阶段的过程：1) 使用模态融合图 (MFM) 进行嵌入探测，这是一种新颖的参数化降维方法，它集成了度量和非度量目标以增强模态融合；2) 嵌入对齐，允许用户以交互方式表达点集和集合对齐的意图。 CLIP 嵌入与现有降维（例如 t-SNE 和 MDS）和数据融合（例如数据上下文映射）方法的定量和定性比较表明，与常见的视觉语言数据集相比，MFM 在展示跨模态特征方面具有优势。案例研究表明，ModalChorus 可以在从零样本分类到跨模态检索和生成的各种场景中促进直观地发现错位并高效地重新对齐。]]></description>
      <guid>https://arxiv.org/abs/2407.12315</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>用于跨域推荐的图信号处理</title>
      <link>https://arxiv.org/abs/2407.12374</link>
      <description><![CDATA[arXiv:2407.12374v1 公告类型：新
摘要：跨域推荐 (CDR) 通过利用密集域中的用户-项目交互来缓解数据稀疏性和冷启动问题，从而扩展了传统的推荐系统。虽然 CDR 为提高推荐性能提供了巨大的潜力，但大多数现有的 CDR 方法都对重叠用户的比例以及源域和目标域之间的内在差异很敏感。为了克服这些限制，在本文中，我们探索了图信号处理 (GSP) 在 CDR 场景中的应用。我们提出了基于 GSP 的统一 CDR 框架 CGSP，它采用了通过灵活结合目标相似性和源桥接相似性构建的跨域相似性图。通过处理为来自源域或目标域的用户计算的个性化图形信号，我们的框架有效地支持域间和域内推荐。我们的实证评估表明，CGSP 在域内和域间推荐场景中始终优于各种基于编码器的 CDR 方法，尤其是在重叠用户比例较低的情况下，凸显了其在实际应用中的重要实际意义。]]></description>
      <guid>https://arxiv.org/abs/2407.12374</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>RankTower：增强双塔预排序模型的协同框架</title>
      <link>https://arxiv.org/abs/2407.12385</link>
      <description><![CDATA[arXiv:2407.12385v1 公告类型：新
摘要：在大规模排名系统中，级联架构已被广泛采用以实现效率和有效性之间的平衡。预排名模块在为后续排名模块选择候选子集方面起着至关重要的作用。对于预排名模型来说，保持效率和准确性之间的平衡以遵守在线延迟约束至关重要。在本文中，我们提出了一种名为RankTower的新型神经网络架构，旨在有效捕获用户-项目交互，同时遵循用户-项目解耦范式以确保在线推理效率。所提出的方法采用混合训练目标，从级联排名系统的完整阶段获得的样本中学习，针对不同的样本空间优化不同的目标。该策略旨在增强预排名模型的排名能力并与现有的级联排名系统进行改进。在公共数据集上进行的实验结果表明，RankTower 明显优于最先进的预排名模型。]]></description>
      <guid>https://arxiv.org/abs/2407.12385</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>搜索引擎、法学硕士还是两者兼而有之？评估回答健康问题的信息搜索策略</title>
      <link>https://arxiv.org/abs/2407.12468</link>
      <description><![CDATA[arXiv:2407.12468v1 公告类型：新
摘要：搜索引擎传统上是信息搜索的主要工具。然而，新的大型语言模型 (LLM) 最近在多项任务中表现出了卓越的能力，具体来说，它们作为问答系统的采用正变得越来越普遍。预计基于 LLM 的对话系统和传统的网络引擎将在未来继续共存，以各种方式支持最终用户。但需要对这两种系统在促进准确信息搜索方面的有效性进行更多的科学研究。在本研究中，我们关注它们在回答健康问题方面的优点。我们进行了一项广泛的研究，比较了不同的网络搜索引擎、LLM 和检索增强 (RAG) 方法。我们的研究揭示了有趣的结论。例如，我们观察到，随着我们在排名列表中进一步向下导航，可能回答健康问题的网页质量不会下降。然而，根据我们的评估，网络引擎在找到健康问题的正确答案方面不如 LLM 准确。另一方面，LLM 对输入提示非常敏感，我们还发现 RAG 可以带来非常有效的信息搜索方法。]]></description>
      <guid>https://arxiv.org/abs/2407.12468</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>优化查询生成以增强 RAG 中的文档检索功能</title>
      <link>https://arxiv.org/abs/2407.12325</link>
      <description><![CDATA[arXiv:2407.12325v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种语言任务中表现出色，但它们经常会产生不正确的信息，这种现象称为“幻觉”。检索增强生成 (RAG) 旨在通过使用文档检索获得准确响应来缓解这种情况。然而，由于查询模糊，RAG 仍然面临幻觉。本研究旨在通过使用查询文档对齐分数优化查询生成来改进 RAG，使用 LLM 细化查询以提高文档检索的精度和效率。实验表明，我们的方法改进了文档检索，平均准确率提高了 1.6%。]]></description>
      <guid>https://arxiv.org/abs/2407.12325</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>GUME：长尾多模态推荐的图表和用户模态增强</title>
      <link>https://arxiv.org/abs/2407.12338</link>
      <description><![CDATA[arXiv:2407.12338v1 公告类型：新
摘要：多模态推荐系统 (MMRS) 因其能够联合利用来自用户行为和产品图像和文本的信息而受到研究界的广泛关注。以前的研究有两个主要问题。首先，推荐系统中的许多长尾项目的交互数据有限，因此很难学习全面且信息丰富的表示。然而，过去的 MMRS 研究忽略了这个问题。其次，用户的模态偏好对他们的行为至关重要。然而，以前的研究主要集中在学习项目模态表示上，而用户模态表示仍然相对简单。为了应对这些挑战，我们提出了一种用于长尾多模态推荐的新型图形和用户模态增强 (GUME)。具体来说，我们首先使用项目之间的多模态相似性来增强用户-项目图。这提高了长尾项目的连通性，并帮助它们通过图传播学习高质量的表示。然后，我们构建了两种类型的用户模态：显式交互特征和扩展兴趣特征。通过使用用户模态增强策略来最大化这两个特征之间的互信息，我们提高了用户模态表示的泛化能力。此外，我们设计了一种模态数据对齐策略来消除内部和外部的噪音。在四个公开数据集上的大量实验证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.12338</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>ClaimCompare：用于评估破坏新颖性的专利对的数据管道</title>
      <link>https://arxiv.org/abs/2407.12193</link>
      <description><![CDATA[arXiv:2407.12193v1 公告类型：新
摘要：专利申请流程中的一个基本步骤是确定是否存在破坏新颖性的先前专利。申请人和审查员通常会执行此步骤，以评估每年提交的数百万份申请中拟议发明的新颖性。然而，进行这种搜索需要大量时间和劳动力，因为搜索者必须处理复杂的法律和技术术语，同时还要涵盖大量的法律主张。使用信息检索和机器学习方法来检测破坏新颖性的专利的自动化方法为简化这一过程提供了一种有希望的途径，但专注于这一领域的研究仍然有限。在本文中，我们介绍了一种新颖的数据管道 ClaimCompare，旨在生成适合训练 IR 和 ML 模型的标记专利权利要求数据集，以应对破坏新颖性评估的挑战。据我们所知，ClaimCompare 是第一个可以生成多个破坏新颖性的专利数据集的管道。为了说明此流程的实际意义，我们利用它来构建一个样本数据集，该数据集包含超过 27,000 项电化学领域的专利：来自 USPTO 的 1,045 项基础专利，每项专利都与 25 项相关专利相关联，这些专利根据其对基础专利的新颖性破坏程度进行标记。随后，我们进行了初步实验，展示了此数据集在微调变压器模型以识别破坏新颖性的专利方面的有效性，结果显示 MRR 和 P@1 分别提高了 29.2% 和 32.7%。]]></description>
      <guid>https://arxiv.org/abs/2407.12193</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>Mindful-RAG：检索增强生成中的故障点研究</title>
      <link>https://arxiv.org/abs/2407.12216</link>
      <description><![CDATA[arXiv:2407.12216v1 公告类型：新 
摘要：大型语言模型 (LLM) 擅长生成连贯且与上下文相关的文本，但在处理领域特定和事实问答任务中的知识密集型查询时面临挑战。检索增强生成 (RAG) 系统通过合并外部知识源（例如结构化知识图谱 (KG)）来缓解这种情况。然而，尽管可以访问包含必要事实的 KG 提取信息，但 LLM 往往难以产生准确的答案。我们的研究通过分析现有基于 KG 的 RAG 方法中的错误模式并确定八个关键故障点来调查这一困境。我们观察到这些错误主要是由于没有足够关注辨别问题的意图以及没有充分收集知识图谱事实中的相关上下文而发生的。基于这一分析，我们提出了 Mindful-RAG 方法，这是一个专为基于意图和上下文一致的知识检索而设计的框架。该方法明确针对已识别的失败，并提高了 LLM 提供的响应的正确性和相关性，比现有方法迈出了重大一步。]]></description>
      <guid>https://arxiv.org/abs/2407.12216</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>静态剪枝的神经通道质量评估</title>
      <link>https://arxiv.org/abs/2407.12170</link>
      <description><![CDATA[arXiv:2407.12170v1 公告类型：新
摘要：神经网络——尤其是那些使用大型预训练语言模型的网络——已经以各种方式改进了搜索引擎。最突出的是，它们可以估计段落或文档与用户查询的相关性。在这项工作中，我们从这个方向出发，探索神经网络是否可以有效预测文档中的哪些段落不太可能与提交给搜索引擎的任何查询相关。我们将这种与查询无关的段落相关性估计称为段落质量。我们发现，我们用于估计段落质量的新方法允许在保持统计等效有效性的同时对段落语料库进行大量修剪；我们的最佳方法可以在各种检索管道中一致地修剪语料库中 25% 以上的段落。如此大规模的修剪减少了神经搜索引擎在计算资源、功耗和碳足迹方面的运营成本——无论是在处理查询时（由于索引大小较小），还是在索引时（轻量级模型可以在昂贵的密集或学习稀疏编码步骤之前修剪低质量段落）。这项工作为开发更先进的神经“学习索引什么”方法奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2407.12170</guid>
      <pubDate>Thu, 18 Jul 2024 06:20:41 GMT</pubDate>
    </item>
    </channel>
</rss>