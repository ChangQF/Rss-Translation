<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 07 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>FedHCDR：具有超图信号解耦的联合跨域推荐</title>
      <link>https://arxiv.org/abs/2403.02630</link>
      <description><![CDATA[arXiv:2403.02630v2 公告类型：replace-cross
摘要：近年来，跨域推荐（CDR）引起了人们的广泛关注，它利用来自多个域的用户数据来提高推荐性能。然而，当前的 CDR 方法需要跨域共享用户数据，从而违反了通用数据保护条例 (GDPR)。因此，针对联合跨域推荐（FedCDR）提出了多种方法。然而，不同领域的数据异构性不可避免地影响联邦学习的整体性能。在本研究中，我们提出了 FedHCDR，一种具有超图信号解耦功能的新型联合跨域推荐框架。具体来说，为了解决跨域的数据异构性，我们引入了一种称为超图信号解耦（HSD）的方法，将用户特征解耦为域专有和域共享的特征。该方法采用高通和低通超图滤波器来解耦域独占和域共享的用户表示，这些用户表示由局部全局双向传输算法训练。此外，设计了超图对比学习（HCL）模块，通过扰动用户超图来增强域共享用户关系信息的学习。对三种现实场景进行的大量实验表明，FedHCDR 的性能显着优于现有基准。]]></description>
      <guid>https://arxiv.org/abs/2403.02630</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:11 GMT</pubDate>
    </item>
    <item>
      <title>Pfeed：使用预先计算的嵌入相似性生成近乎实时的个性化提要</title>
      <link>https://arxiv.org/abs/2402.16073</link>
      <description><![CDATA[arXiv:2402.16073v2 公告类型：替换
摘要：在个性化推荐系统中，嵌入通常用于对客户操作和项目进行编码，然后使用近似最近邻搜索在嵌入空间中执行检索。然而，这种方法可能会带来两个挑战：1）用户嵌入可能会限制所捕获兴趣的多样性，2）保持它们最新的需要需要昂贵的实时基础设施。在本文中，我们提出了一种在实际工业环境中克服这些挑战的方法。该方法利用预先计算的嵌入及其各自的相似性，动态更新客户资料并每两分钟编写一个提要。我们在荷兰和比利时最大的电子商务平台之一 Bol 测试并部署了这种方法来个性化促销商品。该方法增强了客户参与度和体验，使转化率显着提高了 4.9%。]]></description>
      <guid>https://arxiv.org/abs/2402.16073</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:10 GMT</pubDate>
    </item>
    <item>
      <title>学习基于 ID 的推荐的类别树：探索可微向量量化的力量</title>
      <link>https://arxiv.org/abs/2308.16761</link>
      <description><![CDATA[arXiv:2308.16761v5 公告类型：替换
摘要：类别信息在提高推荐系统的质量和个性化方面起着至关重要的作用。然而，项目类别信息的可用性并不总是存在，特别是在基于 ID 的推荐的情况下。在这项工作中，我们提出了一种新方法来自动学习和生成实体（即用户或项目）类别树以进行基于 ID 的推荐。具体来说，我们设计了一种用于自动类别树生成的可微向量量化框架，即 CAGE，它能够从随机初始化的状态开始，以端到端的方式同时学习和细化类别代码表示和实体嵌入。凭借其高适应性，CAGE 可以轻松集成到顺序和非顺序推荐系统中。我们在不同的推荐模型中验证了 CAGE 在各种推荐任务上的有效性，包括列表完成、协同过滤和点击率预测。我们发布代码和数据供其他人重现报告的结果。]]></description>
      <guid>https://arxiv.org/abs/2308.16761</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>异构用户推荐系统中的保留引起的偏差</title>
      <link>https://arxiv.org/abs/2402.13959</link>
      <description><![CDATA[arXiv:2402.13959v2 公告类型：替换
摘要：我研究了具有用户流入和流失动态的推荐系统（RS）的概念模型。当流入和流失平衡时，用户分布达到稳定状态。更改推荐算法会改变稳定状态并创建一个过渡期。在此期间，RS 的行为与其新的稳态不同。特别是，在过渡期获得的 A/B 实验指标是 RS 长期性能的有偏差指标。然而，学者和实践者经常在引入新算法后不久进行 A/B 测试以验证其有效性。这种 A/B 实验范式被广泛认为是评估 RS 改进的黄金标准，因此可能会得出错误的结论。我还简要讨论了用户保留动态造成的数据偏差。]]></description>
      <guid>https://arxiv.org/abs/2402.13959</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:09 GMT</pubDate>
    </item>
    <item>
      <title>通过生成伪标签进行无监督多语言密集检索</title>
      <link>https://arxiv.org/abs/2403.03516</link>
      <description><![CDATA[arXiv:2403.03516v1 公告类型：交叉
摘要：密集检索方法在多语言信息检索中表现出了良好的性能，其中查询和文档可以使用不同的语言。然而，密集检索器通常需要大量的配对数据，这在多语言场景中提出了更大的挑战。本文介绍了 UMR，一种在没有任何配对数据的情况下训练的无监督多语言密集检索器。我们的方法利用多语言语言模型的序列似然估计功能来获取用于训练密集检索器的伪标签。我们提出了一个两阶段框架，它迭代地提高了多语言密集检索器的性能。两个基准数据集的实验结果表明，UMR 优于监督基线，展示了在没有配对数据的情况下训练多语言检索器的潜力，从而增强了其实用性。我们的源代码、数据和模型可在 https://github.com/MiuLab/UMR 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2403.03516</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:08 GMT</pubDate>
    </item>
    <item>
      <title>蜘蛛网：类人类别学习的增量和分层模型</title>
      <link>https://arxiv.org/abs/2403.03835</link>
      <description><![CDATA[arXiv:2403.03835v1 公告类型：交叉
摘要：Cobweb 是一种类似人类的类别学习系统，与其他增量分类模型的不同之处在于使用类别效用度量构建分层组织的认知树状结构。此前的研究表明，Cobweb 可以捕捉基础水平、典型性、粉丝效应等心理效应。然而，对蜘蛛网作为人类分类模型的更广泛的评估仍然缺乏。目前的研究解决了这一差距。它建立了蛛网与经典人类类别学习效应的一致性。它还探讨了 Cobweb 在单个模型中展示示例和原型学习的灵活性。这些发现为 Cobweb 作为人类类别学习的综合模型的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2403.03835</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:08 GMT</pubDate>
    </item>
    <item>
      <title>Mamba4Rec：通过选择性状态空间模型实现高效顺序推荐</title>
      <link>https://arxiv.org/abs/2403.03900</link>
      <description><![CDATA[arXiv:2403.03900v1 公告类型：新
摘要：顺序推荐旨在估计动态用户偏好和历史用户行为之间的顺序依赖性。尽管基于 Transformer 的模型已被证明对于顺序推荐是有效的，但它们面临着由于注意力算子的二次计算复杂性而导致的推理低效问题，尤其是对于长程行为序列。受到状态空间模型（SSM）最近成功的启发，我们提出了 Mamba4Rec，这是第一个探索选择性 SSM 在高效顺序推荐方面的潜力的工作。基于基本的 Mamba 模块（具有高效的硬件感知并行算法的选择性 SSM），我们结合了一系列顺序建模技术，以进一步提升模型性能，同时保持推理效率。在两个公共数据集上的实验表明，Mamba4Rec 能够很好地解决有效性-效率困境，并在有效性和效率方面击败基于 RNN 和基于注意力的基线。]]></description>
      <guid>https://arxiv.org/abs/2403.03900</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>用于检索和推荐的桥梁语言和项目</title>
      <link>https://arxiv.org/abs/2403.03952</link>
      <description><![CDATA[arXiv:2403.03952v1 公告类型：新
摘要：本文介绍了 BLaIR，一系列专门针对推荐场景的预训练句子嵌入模型。 BLaIR 经过训练可以学习项目元数据和潜在自然语言上下文之间的相关性，这对于检索和推荐项目非常有用。为了预训练 BLaIR，我们收集了 Amazon Reviews 2023，这是一个新数据集，包含来自 33 个类别的超过 5.7 亿条评论和 4800 万个商品，显着超出了之前版本的范围。我们评估了 BLaIR 跨多个领域和任务的泛化能力，包括一项名为复杂产品搜索的新任务，指的是在给定长而复杂的自然语言上下文的情况下检索相关项目。利用像ChatGPT这样的大型语言模型，我们相应地构建了一个半合成评估集Amazon-C4。新任务以及传统检索和推荐任务的实证结果表明，BLaIR 表现出强大的文本和项目表示能力。我们的数据集、代码和检查点位于：https://github.com/hyp1231/AmazonReviews2023。]]></description>
      <guid>https://arxiv.org/abs/2403.03952</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>回溯：检索查询的原因</title>
      <link>https://arxiv.org/abs/2403.03956</link>
      <description><![CDATA[arXiv:2403.03956v1 公告类型：新
摘要：许多在线内容门户允许用户提出问题来补充他们的理解（例如，讲座）。虽然信息检索 (IR) 系统可以为此类用户查询提供答案，但它们不会直接帮助内容创建者（例如想要改进其内容的讲师）识别导致用户提出这些问题的片段。我们引入回溯任务，其中系统检索最有可能引起用户查询的文本段。我们形式化了三个现实世界领域，回溯对于改善内容交付和沟通非常重要：理解（a）学生在讲座领域感到困惑的原因，（b）读者在新闻文章领域的好奇心，以及（c）用户情绪在对话域中。我们评估流行的信息检索方法和语言建模方法的零样本性能，包括双编码器、重排序和基于似然的方法以及 ChatGPT。虽然传统的 IR 系统检索语义相关的信息（例如，针对“投影多次是否仍会导致同一点？”查询的“投影矩阵”的详细信息），但它们经常会错过因果相关的上下文（例如，讲师指出“投影”两次得到与一次预测相同的答案”）。我们的结果表明回溯还有改进的空间，并且需要新的检索方法。我们希望我们的基准测试能够改进未来的回溯检索系统，生成系统，从而改进内容生成并识别影响用户查询的语言触发器。我们的代码和数据都是开源的：https://github.com/rosewang2008/backtracing。]]></description>
      <guid>https://arxiv.org/abs/2403.03956</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>实现高效且有效地学习大型语言模型以进行推荐</title>
      <link>https://arxiv.org/abs/2403.03536</link>
      <description><![CDATA[arXiv:2403.03536v1 公告类型：新
摘要：大语言模型（LLM）的显着进步催生了一个有前途的研究方向，即利用 LLM 作为推荐器（LLMRec）。 LLMRec 的功效源于法学硕士固有的开放世界知识和推理能力。 LLMRec通过基于用户交互数据的指令调优获得推荐能力。然而，为了保护用户隐私和优化效用，LLMRec 故意忘记特定用户数据也至关重要，这通常被称为推荐遗忘。在 LLM 时代，推荐取消学习在 \textit{低效率} 和 \textit{无效} 方面对 LLMRec 提出了新的挑战。现有的去学习方法需要更新 LLMRec 中的数十亿个参数，这是昂贵且耗时的。此外，它们总是会在遗忘过程中影响模型的效用。为此，我们提出了 \textbf{E2URec}，第一个 \underline{E}fficient 和 \underline{E}ffective \underline{U}nLLM\underline{Rec} 学习方法。我们提出的 E2URec 通过仅更新一些额外的 LoRA 参数来提高遗忘效率，并通过采用师生框架来提高遗忘效率，在该框架中我们维护多个教师网络来指导遗忘过程。大量实验表明，E2URec 在两个真实数据集上的性能优于最先进的基线。具体来说，E2URec 可以有效地忘记特定数据，而不影响推荐性能。源代码位于 \url{https://github.com/justarter/E2URec}。]]></description>
      <guid>https://arxiv.org/abs/2403.03536</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:06 GMT</pubDate>
    </item>
    <item>
      <title>通过解缠图对比学习进行意图感知推荐</title>
      <link>https://arxiv.org/abs/2403.03714</link>
      <description><![CDATA[arXiv:2403.03714v1 公告类型：新
摘要：由于从用户行为数据中强大的学习能力，基于图神经网络（GNN）的推荐系统已成为主流趋势之一。从行为数据中理解用户意图是推荐系统的关键，这对基于 GNN 的推荐系统提出了两个基本要求。一是如何学习复杂多样的意图，特别是当用户行为在现实中通常不充分时。另一个是不同的行为有不同的意图分布，那么如何建立它们的关系以获得更可解释的推荐系统。在本文中，我们通过解缠图对比学习（IDCL）提出了意图感知推荐，它同时学习可解释的意图和这些意图的行为分布。具体来说，我们首先将用户行为数据建模为用户-项目-概念图，并设计一个基于 GNN 的行为解缠模块来学习不同的意图。然后，我们提出意图对比学习来增强意图解开，同时推断行为分布。最后，引入编码率降低正则化，使不同意图的行为正交。大量实验证明了 IDCL 在实质性改进和可解释性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.03714</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:06 GMT</pubDate>
    </item>
    <item>
      <title>生成新闻推荐</title>
      <link>https://arxiv.org/abs/2403.03424</link>
      <description><![CDATA[arXiv:2403.03424v1 公告类型：新
摘要：大多数现有的新闻推荐方法通过在候选新闻和历史点击新闻产生的用户表示之间进行语义匹配来解决此任务。然而，他们忽视了不同新闻文章之间的高层联系，也忽视了这些新闻文章与用户之间的深刻关系。这些方法的定义规定它们只能按原样传递新闻文章。相反，将几篇相关新闻文章整合成一个连贯的叙述将有助于用户更快、更全面地了解事件。在本文中，我们提出了一种新颖的生成新闻推荐范式，包括两个步骤：（1）利用大语言模型（LLM）的内部知识和推理能力来执行候选新闻和用户表示之间的高级匹配； （2）根据相关新闻与用户兴趣之间的关联，生成连贯且逻辑结构清晰的叙述，从而吸引用户进一步阅读新闻。具体来说，我们提出 GNR 来实现生成新闻推荐范式。首先，我们利用LLM生成主题级表示并将其与语义级表示相结合，构建新闻和用户的双层表示。接下来，为了生成连贯的叙述，我们探索新闻关系并根据用户偏好过滤相关新闻。最后，我们提出了一种名为 UIFT 的新颖训练方法来训练法学硕士将多篇新闻文章融合成一个连贯的叙述。大量实验表明，GNR 可以提高推荐准确性，并最终生成更加个性化且与事实一致的叙述。]]></description>
      <guid>https://arxiv.org/abs/2403.03424</guid>
      <pubDate>Thu, 07 Mar 2024 06:18:05 GMT</pubDate>
    </item>
    </channel>
</rss>