<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>绕过流行度偏见：重新利用模型以获得更好的长尾推荐</title>
      <link>https://arxiv.org/abs/2410.02776</link>
      <description><![CDATA[arXiv:2410.02776v1 公告类型：新
摘要：推荐系统在塑造我们在网上遇到的信息方面发挥着至关重要的作用，无论是在社交媒体上还是在使用内容平台时，从而影响我们的信念、选择和行为。许多最近的研究都涉及推荐系统的公平性问题，通常关注的主题包括确保所有个人用户或用户组平等地获取信息和机会、推广多样化的内容以避免过滤气泡和回音室、提高透明度和可解释性，以及遵守道德和可持续的做法。在这项工作中，我们的目标是在在线内容平台上的出版商之间实现更公平的曝光分配，特别关注那些可能受到不公平待遇的高质量长尾内容的出版商。我们提出了一种新颖的方法，重新利用工业推荐系统的现有组件，为代表性不足的出版商提供有价值的曝光，同时保持较高的推荐质量。为了证明我们提案的有效性，我们进行了大规模在线 AB 实验，报告了表明预期结果的结果，并分享了该方法在生产环境中长期应用的一些见解。]]></description>
      <guid>https://arxiv.org/abs/2410.02776</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从电子商务网站结构中学习变体产品关系和变体属性</title>
      <link>https://arxiv.org/abs/2410.02779</link>
      <description><![CDATA[arXiv:2410.02779v1 公告类型：新
摘要：我们引入了 VARM，即变体关系匹配器策略，以识别电子商务目录中的变体产品对。实体解析的传统定义关注的是产品提及是否指的是相同的基础产品。然而，这无法捕捉对电子商务应用至关重要的产品关系，例如在同一网页上列出相似但不相同的产品或分享评论。在这里，我们在变体产品关系中制定了一种新型的实体解析来捕获这些相似的电子商务产品链接。与传统定义相比，新定义需要识别两种产品是否是彼此的变体匹配，以及它们之间有哪些不同的属性。为了满足这两个要求，我们开发了一种利用编码和生成 AI 模型优势的策略。首先，我们构建一个数据集来捕获网页产品链接，从而捕获变体产品关系，以训练编码 LLM 来预测任何给定产品对的变体匹配。其次，我们使用 RAG 提示的生成式 LLM 来提取变体产品组之间的差异和共同属性。为了验证我们的策略，我们使用来自世界领先的电子商务零售商之一的真实数据评估了模型性能。结果表明，我们的策略优于其他解决方案，并为利用这些新型产品关系铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.02779</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DifFaiRec：具有条件扩散模型的生成公平推荐器</title>
      <link>https://arxiv.org/abs/2410.02791</link>
      <description><![CDATA[arXiv:2410.02791v1 公告类型：新
摘要：虽然推荐系统可以根据用户的偏好自动向用户发送商品，但它们往往会对群体或个人造成不公平。例如，当用户可以根据敏感的社交属性分为两组，并且两组之间的活动存在显著差异时，学习到的推荐算法将导致两组之间的推荐差距，从而导致群体不公平。在本文中，我们提出了一种名为基于扩散的公平推荐器（DifFaiRec）的新型推荐算法来提供公平的推荐。DifFaiRec 建立在条件扩散模型之上，因此具有从用户对项目的评分中学习用户偏好分布的强大能力，并且能够有效地生成多样化的推荐。为了保证公平性，我们设计了一个反事实模块来降低模型对受保护属性的敏感性并提供数学解释。基准数据集上的实验证明了 DifFaiRec 优于竞争基线。]]></description>
      <guid>https://arxiv.org/abs/2410.02791</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>新闻推荐大型语言模型中的认知偏差</title>
      <link>https://arxiv.org/abs/2410.02897</link>
      <description><![CDATA[arXiv:2410.02897v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 越来越成为新闻推荐系统的重要组成部分，但在这些系统中使用 LLM 会带来新的风险，例如 LLM 中认知偏见的影响。认知偏见是指判断过程中偏离规范或理性的系统模式，这可能导致 LLM 的输出不准确，从而威胁新闻推荐系统的可靠性。具体而言，受认知偏见影响的基于 LLM 的新闻推荐系统可能导致错误信息的传播、刻板印象的强化和回音室的形成。在本文中，我们探讨了多种认知偏见对基于 LLM 的新闻推荐系统的潜在影响，包括锚定偏见、框架偏见、现状偏见和群体归因偏见。此外，为了促进未来提高基于 LLM 的新闻推荐系统可靠性的研究，我们讨论了通过数据增强、提示工程和学习算法方面来减轻这些偏见的策略。]]></description>
      <guid>https://arxiv.org/abs/2410.02897</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过评分细化简化共形信息检索</title>
      <link>https://arxiv.org/abs/2410.02914</link>
      <description><![CDATA[arXiv:2410.02914v1 公告类型：新
摘要：信息检索 (IR) 方法（如检索增强生成）是现代应用的基础，但通常缺乏统计保证。共形预测通过检索保证包含相关信息的集合来解决此问题，但现有方法会产生大型集合，从而导致计算成本高且响应时间长。在这项工作中，我们引入了一种分数细化方法，该方法将简单的单调变换应用于检索分数，从而导致显著较小的共形集，同时保持其统计保证。在各种 BEIR 基准上进行的实验验证了我们的方法在生成包含相关信息的紧凑集方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.02914</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于检索的推测进行归纳生成推荐</title>
      <link>https://arxiv.org/abs/2410.02939</link>
      <description><![CDATA[arXiv:2410.02939v1 公告类型：新
摘要：生成式推荐 (GR) 是一种新兴的范式，它将项目标记为离散标记，并学习自回归生成下一个标记作为预测。尽管有效，但 GR 模型在传导环境中运行，这意味着它们只能生成在训练期间看到的项目，而无需应用启发式重新排名策略。在本文中，我们提出了 SpecGR，这是一个即插即用的框架，使 GR 模型能够在归纳环境中推荐新项目。SpecGR 使用具有归纳能力的起草模型来提出候选项目，其中可能包括现有项目和新项目。然后，GR 模型充当验证者，接受或拒绝候选者，同时保留其强大的排名能力。我们进一步引入了引导式重新起草技术，使提出的候选者与生成式推荐模型的输出更加一致，从而提高了验证效率。我们考虑了两种起草变体：(1) 使用辅助起草模型以获得更好的灵活性，或 (2) 利用 GR 模型自己的编码器进行参数高效的自起草。在三个真实数据集上进行的大量实验表明，SpecGR 表现出强大的归纳推荐能力，并且在比较的方法中具有最佳的整体性能。我们的代码可在以下网址获得：https://github.com/Jamesding000/SpecGR。]]></description>
      <guid>https://arxiv.org/abs/2410.02939</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有收敛性的几何协同过滤</title>
      <link>https://arxiv.org/abs/2410.03064</link>
      <description><![CDATA[arXiv:2410.03064v1 公告类型：新
摘要：潜在变量协同过滤方法由于其简单性和有效性而成为建模用户点击交互的标准方法。然而，在分析这些方法的数学性质方面，特别是在防止过度拟合身份方面，研究工作有限，而且这些方法通常使用忽略项目之间几何形状的损失函数。在这项工作中，我们引入了协同过滤中的泛化差距概念，并针对潜在协同过滤模型对其进行了分析。我们提出了一个产生损失函数的几何上限，以及一种有意义地利用项目元数据的几何形状来改进推荐的方法。我们展示了如何最小化这些损失，并给出了一种新的潜在协同过滤算法的配方，由于我们的结果具有几何性质，我们将其称为 GeoCF。然后，我们通过实验证明，我们提出的 GeoCF 算法在 Movielens20M 和 Netflix 数据集以及两个大型内部数据集上的表现优于其他所有现有方法。总之，我们的工作提出了一种理论上合理的方法，为更好地理解协同过滤的泛化铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.03064</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据高效的海量工具检索：一种基于语言模型的查询工具对齐强化学习方法</title>
      <link>https://arxiv.org/abs/2410.03212</link>
      <description><![CDATA[arXiv:2410.03212v1 公告类型：新
摘要：与外部工具和 API 集成的大型语言模型 (LLM) 的最新进展已通过使用上下文学习或微调成功解决了复杂任务。尽管取得了这些进展，但由于严格的输入长度限制，大规模工具检索仍然具有挑战性。作为回应，我们提出了一种从广泛的存储库中进行预检索的策略，有效地将问题定义为大规模工具检索 (MTR) 任务。我们引入了 MTRB（大规模工具检索基准）来评估具有大量工具的真实世界工具增强 LLM 场景。该基准专为低资源场景而设计，包括多种工具集合，其描述经过细化以确保一致性和清晰度。它由三个子集组成，每个子集包含 90 个测试样本和 10 个训练样本。为了处理低资源 MTR 任务，我们提出了一个新的查询工具对齐 (QTA) 框架，该框架利用 LLM 通过排名函数和直接偏好优化 (DPO) 方法重写用户查询来增强查询工具对齐。这种方法在 MTRB 基准的 top-5 和 top-10 检索任务中始终优于现有的最先进模型，根据衡量前 k 个结果中工具检索充分性的指标 Sufficiency@k，改进率高达 93.28%。此外，消融研究验证了我们框架的有效性，突出了它即使在有限的注释样本下也能优化性能的能力。具体来说，我们的框架仅使用一个注释样本就实现了 Sufficiency@k 高达 78.53% 的性能提升。此外，QTA 表现出强大的跨数据集通用性，强调了其在实际应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.03212</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式兴趣点推荐</title>
      <link>https://arxiv.org/abs/2410.03265</link>
      <description><![CDATA[arXiv:2410.03265v1 公告类型：新
摘要：大型语言模型应用于推荐任务，例如要购买的物品和要阅读的新闻文章。兴趣点是基于多模态数据集的语言表示的顺序推荐的一个相当新的领域。作为证明我们概念的第一步，我们专注于基于每个用户过去访问历史的餐厅推荐。在选择下一家要去的餐厅时，用户会考虑餐厅的类型和位置，如果有的话，还会考虑那里供应的菜肴的图片。我们从 Foursquare 数据集和 FoodX-251 数据集创建了一个伪餐厅签到历史数据集，通过使用名为 LLaVA 的多模态模型将图片转换为文本描述，并使用了 2023 年提出的基于语言的顺序推荐框架 Recformer。在这个半多模态数据集上训练的模型的表现优于在没有图片描述的同一数据集上训练的另一个模型。这表明这种半多模态模型反映了实际的人类行为，我们通往多模态推荐模型的道路正朝着正确的方向发展。]]></description>
      <guid>https://arxiv.org/abs/2410.03265</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EB-NeRD：用于新闻推荐的大规模数据集</title>
      <link>https://arxiv.org/abs/2410.03432</link>
      <description><![CDATA[arXiv:2410.03432v1 公告类型：新
摘要：个性化内容推荐对于从视频流到社交网络的数字媒体内容体验至关重要。然而，几个特定领域的挑战阻碍了推荐系统在新闻出版中的应用。为了应对这些挑战，我们引入了 Ekstra Bladet 新闻推荐数据集 (EB-NeRD)。该数据集包含来自超过一百万唯一用户的数据和来自 Ekstra Bladet 的超过 3700 万个印象日志。它还包括超过 125,000 篇丹麦新闻文章的集合，包括标题、摘要、正文和元数据（例如类别）。EB-NeRD 是 RecSys &#39;24 挑战赛的基准数据集，展示了如何使用数据集来解决设计有效且负责任的新闻出版推荐系统的技术和规范挑战。数据集可在以下网址获得：https://recsys.eb.dk。]]></description>
      <guid>https://arxiv.org/abs/2410.03432</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Dreamming 用户多模态表征用于微视频推荐</title>
      <link>https://arxiv.org/abs/2410.03538</link>
      <description><![CDATA[arXiv:2410.03538v1 公告类型：新
摘要：在线微视频平台的激增凸显了高级推荐系统缓解信息过载和提供定制内容的必要性。尽管取得了进展，但准确及时地捕捉动态用户兴趣仍然是一项艰巨的挑战。受柏拉图表示假说的启发，该假说认为不同的数据模态会趋向于一个共享的现实统计模型，我们引入了 DreamUMM（梦想用户多模态表示），这是一种利用用户历史行为在多模态空间中创建实时用户表示的新方法。DreamUMM 采用一种将用户视频偏好与多模态相似性相关联的闭式解决方案，假设用户兴趣可以在统一的多模态空间中得到有效表示。此外，我们针对缺乏近期用户行为数据的场景提出了 Candidate-DreamUMM，仅从候选视频中推断兴趣。广泛的在线 A/B 测试表明，用户参与度指标（包括活跃天数和播放次数）显著改善。DreamUMM 在两个拥有数亿日活跃用户的微视频平台上成功部署，证明了其在个性化微视频内容交付方面的实用性和可扩展性。我们的工作通过提供经验证据支持用户兴趣表示驻留在多模态空间中的潜力，为表征收敛的持续探索做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.03538</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用相关性同义词库作为全局解释来发现信息检索模型中的偏见</title>
      <link>https://arxiv.org/abs/2410.03584</link>
      <description><![CDATA[arXiv:2410.03584v1 公告类型：新
摘要：解释神经相关性模型的大多数努力都集中在局部解释上，这些解释解释了文档与查询的相关性，但对于预测模型对未见查询-文档对的行为无用。我们提出了一种新方法，通过构建包含语义相关查询和文档术语对的“相关性词库”来全局解释神经相关性模型。该词库用于增强词汇匹配模型（如 BM25）以近似神经模型的预测。我们的方法包括训练神经相关性模型来对部分查询和文档段的相关性进行评分，然后使用该模型来识别词汇空间中的相关术语。我们根据排名有效性和对目标神经排名模型的保真度来评估获得的词库解释。值得注意的是，我们的词库揭示了排名模型中品牌名称偏见的存在，证明了我们解释方法的一个优势。]]></description>
      <guid>https://arxiv.org/abs/2410.03584</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>YouTube 视频分析助力患者参与：结肠镜检查准备视频证据</title>
      <link>https://arxiv.org/abs/2410.02830</link>
      <description><![CDATA[arXiv:2410.02830v1 公告类型：交叉 
摘要：视频可以成为一种有效的方法，为患者教育提供情境化、即时的医疗信息。然而，从主题识别和检索到提取和分析医疗信息以及从患者角度的可理解性，视频分析都是极具挑战性的任务。这项研究展示了一种数据分析流程，该流程利用方法从 YouTube 视频中检索有关准备结肠镜检查的医疗信息，结肠镜检查是一项备受诟病和讨厌的程序，患者发现很难充分准备。我们首先使用 YouTube 数据 API 收集所选搜索关键字所需视频的元数据，并使用 Google Video Intelligence API 分析文本、帧和对象数据。然后，我们注释 YouTube 视频材料的医疗信息、视频可理解性和整体推荐。我们开发了一个双向长短期记忆 (BiLSTM) 模型来识别视频中的医学术语，并构建三个分类器，根据编码的医疗信息和视频可理解性的级别以及视频是否推荐对视频进行分组。我们的研究为医疗保健利益相关者提供了指导方针和可扩展的方法，以生成新的教育视频内容，加强对大量健康状况的管理。]]></description>
      <guid>https://arxiv.org/abs/2410.02830</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于可扩展框架的社会文化规范库构建，用于社会意识对话</title>
      <link>https://arxiv.org/abs/2410.03049</link>
      <description><![CDATA[arXiv:2410.03049v1 公告类型：交叉 
摘要：社会文化规范是社会交往中个人行为的指导原则，强调尊重、合作和适当的行为，这有利于包括对话信息检索、上下文信息检索和检索增强机器学习在内的任务。我们提出了一种可扩展的方法，使用大型语言模型 (LLM) 为社会意识对话构建社会文化规范 (SCN) 库。我们构建了一个全面且可公开访问的中国社会文化规范库。我们的方法利用富含上下文框架的社会意识对话作为主要数据源来约束生成过程并减少幻觉。这使得能够提取高质量和细致入微的自然语言规范陈述，利用话语相对于情况的实用含义。由于用黄金框架注释的真实对话并不容易获得，我们建议使用合成数据。我们的实证结果表明：(i) 从合成数据中得出的 SCN 质量与使用金色框架注释的真实对话中的 SCN 质量相当，(ii) 从使用银色（预测）或金色框架注释的真实数据中提取的 SCN 质量优于没有框架注释的 SCN。我们进一步展示了在基于 RAG（检索增强生成）模型中提取的 SCN 的有效性，可以推理多个下游对话任务。]]></description>
      <guid>https://arxiv.org/abs/2410.03049</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 驱动的上下文扩展和前缀调整的 VAE 增强短文本主题建模</title>
      <link>https://arxiv.org/abs/2410.03071</link>
      <description><![CDATA[arXiv:2410.03071v1 公告类型：交叉 
摘要：主题建模是一种强大的技术，可用于揭示文档集合中的隐藏主题。然而，传统主题模型的有效性通常依赖于足够的词共现，而短文本中缺乏这种共现。因此，现有的方法，无论是概率方法还是神经方法，都经常难以从这些数据中提取有意义的模式，从而导致主题不连贯。为了应对这一挑战，我们提出了一种新方法，利用大型语言模型 (LLM) 将短文本扩展为更详细的序列，然后再应用主题建模。为了进一步提高效率并解决 LLM 生成的文本中的语义不一致问题，我们建议使用前缀调整来训练较小的语言模型，并结合变分自动编码器进行短文本主题建模。我们的方法显着提高了短文本主题建模性能，这已在具有极端数据稀疏性的真实数据集上进行了大量实验，优于当前最先进的主题模型。]]></description>
      <guid>https://arxiv.org/abs/2410.03071</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>