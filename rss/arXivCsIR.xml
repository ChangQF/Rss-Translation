<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 29 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>360Brew：个性化排名和推荐的解码器专用基础模型</title>
      <link>https://arxiv.org/abs/2501.16450</link>
      <description><![CDATA[arXiv:2501.16450v1 公告类型：新
摘要：排名和推荐系统是众多在线体验的基础，从搜索结果到个性化内容交付。这些系统已经发展成为复杂的多层架构，利用庞大的数据集，通常包含数千个预测模型。这些模型的维护和增强是一个劳动密集型过程，需要大量的特征工程。这种方法不仅加剧了技术债务，而且阻碍了将这些系统扩展到新兴问题领域的创新。在本报告中，我们介绍了我们的研究，以解决这些挑战，方法是利用一个大型基础模型和一个用于排名和推荐任务的文本界面。我们说明了我们的方法的几个主要优势：（1）单个模型可以管理涉及排名和推荐的多个预测任务，（2）具有文本界面的解码器模型由于其对推理能力的理解，可以推广到新的推荐界面和域外问题，以及（3）通过使用自然语言界面进行任务定义和口头表达成员行为及其社交联系，我们消除了对特征工程和维护模型依赖关系的复杂有向无环图的需求。我们介绍了我们的研究预生产模型 360Brew V1.0，这是一个 150B 参数的仅解码器模型，已在 LinkedIn 的数据和任务上进行了训练和微调。该模型能够解决 LinkedIn 平台各个部分的 30 多个预测任务，实现与基于离线指标的当前生产系统相当或超过其性能水平，而无需针对特定任务进行微调。值得注意的是，这些任务中的每一个通常都由专用模型来解决，这些模型由与我们规模相似或更大的团队开发和维护多年。]]></description>
      <guid>https://arxiv.org/abs/2501.16450</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高阶推荐系统的超图扩散</title>
      <link>https://arxiv.org/abs/2501.16722</link>
      <description><![CDATA[arXiv:2501.16722v1 公告类型：新
摘要：推荐系统依靠协同过滤 (CF) 通过利用历史用户-项目交互中的模式来预测用户偏好。虽然传统的 CF 方法主要侧重于学习用户和项目的紧凑向量嵌入，但基于图神经网络 (GNN) 的方法已成为一种强大的替代方案，利用用户-项目交互图的结构来提高推荐准确性。然而，现有的基于 GNN 的模型，如 LightGCN 和 UltraGCN，通常面临两个主要限制：无法完全考虑异嗜性交互，其中用户与不同的项目类别互动，以及多层 GNN 中的过度平滑问题，这阻碍了它们对复杂的高阶关系进行建模的能力。为了解决这些差距，我们引入了 WaveHDNN，一种创新的小波增强超图扩散框架。 WaveHDNN 集成了异质感知协作编码器，旨在捕获不同类别中的用户-商品交互，以及多尺度分组结构编码器，后者利用小波变换有效地对局部图形结构进行建模。此外，还采用了跨视图对比学习来保持稳健且一致的表示。在基准数据集上进行的实验验证了 WaveHDNN 的有效性，证明了其捕获异质和局部结构信息的卓越能力，从而提高了推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2501.16722</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的安全联合图形过滤</title>
      <link>https://arxiv.org/abs/2501.16888</link>
      <description><![CDATA[arXiv:2501.16888v1 公告类型：新
摘要：推荐系统通常依赖于基于图的过滤器，例如规范化的项目-项目邻接矩阵和低通滤波器。虽然有效，但这些组件的集中计算引发了对隐私、安全和用户数据道德使用的担忧。这项工作提出了两个分散的框架，用于安全地计算这些关键的图形组件，而无需集中敏感信息。第一种方法利用轻量级多方计算和分布式奇异向量计算来私下计算关键图形过滤器。第二种方法通过结合低秩近似来扩展该框架，从而实现通信效率和预测性能之间的权衡。对基准数据集的实证评估表明，所提出的方法在确保数据机密性和保持低通信成本的同时，实现了与集中式最先进系统相当的准确性。我们的结果强调了隐私保护分散架构在现代推荐系统中弥合效用和用户数据保护之间差距的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.16888</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文档截图检索器易受像素中毒攻击</title>
      <link>https://arxiv.org/abs/2501.16902</link>
      <description><![CDATA[arXiv:2501.16902v1 公告类型：新
摘要：密集检索领域的最新进展引入了基于视觉语言模型 (VLM) 的检索器，例如 DSE 和 ColPali，它们利用嵌入为向量的文档屏幕截图来实现有效搜索，并提供比传统纯文本方法更简化的管道。在本研究中，我们提出了三种像素中毒攻击方法，旨在破坏基于 VLM 的检索器，并评估它们在各种攻击设置和参数配置下的有效性。我们的实证结果表明，即使将单个对抗性屏幕截图注入检索语料库也会严重破坏搜索结果，在 DSE 的情况下，41.9% 的查询会毒害前 10 个检索到的文档，在 ColPali 的情况下，这一比例为 26.4%。这些漏洞率明显超过了对纯文本检索器的等效攻击。此外，当针对一小组已知查询时，攻击成功率会提高，在某些情况下会完全成功。通过揭示视觉语言模型固有的漏洞，这项工作凸显了与其部署相关的潜在风险。]]></description>
      <guid>https://arxiv.org/abs/2501.16902</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强长文档检索：利用大型语言模型的细粒度块表示</title>
      <link>https://arxiv.org/abs/2501.17039</link>
      <description><![CDATA[arXiv:2501.17039v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 在包括信息检索在内的各个领域都表现出非凡的威力。以前的大多数做法都涉及利用这些模型为每个查询、每个段落或每个文档单独创建单个嵌入，检索增强生成 (RAG) 框架就是这种策略的典型代表。虽然这种方法已被证明是有效的，但我们认为，由于它依赖于相对粗粒度的表示，因此无法完全捕捉文档级文本的细微复杂性。为了解决这一限制，我们引入了一种新颖的细粒度方法，旨在提高长文档相关性评分的准确性。我们的方法首先将长文档分成块，每个块都使用 LLM 嵌入，以便与查询表示进行匹配。在计算相关性得分时，我们通过加权求和的方法汇总查询块相关性得分，从而得到查询与整个文档的综合得分。尽管看似简单，但我们的实验结果表明，这种方法优于标准表示方法，并且显著降低了嵌入生成延迟。此外，通过精心优化成对损失函数，我们获得了优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.17039</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URAG：实施统一混合 RAG，为大学招生聊天机器人提供精准答案——HCMUT 案例研究</title>
      <link>https://arxiv.org/abs/2501.16276</link>
      <description><![CDATA[arXiv:2501.16276v1 公告类型：交叉 
摘要：随着人工智能的快速发展，特别是在自然语言处理领域，大型语言模型 (LLM) 已成为教育问答系统（尤其是大学招生聊天机器人）的关键。检索增强生成 (RAG) 等概念和其他先进技术已经得到开发，通过整合特定的大学数据来增强这些系统，使 LLM 能够就招生和学术咨询提供明智的回应。然而，这些增强的 RAG 技术通常涉及高昂的运营成本，并且需要训练复杂的专业模块，这对实际部署构成了挑战。此外，在教育背景下，提供准确的答案以防止错误信息至关重要，如果没有适当的策略和方法，基于 LLM 的系统将很难完成这项任务。在本文中，我们介绍了统一 RAG (URAG) 框架，这是一种混合方法，可显着提高响应的准确性，特别是对于关键查询。实验结果表明，URAG 增强了我们内部的轻量级模型，使其性能与最先进的商业模型相当。此外，为了验证其实际适用性，我们在教育机构进行了一项案例研究，获得了积极的反馈和赞誉。这项研究不仅证明了 URAG 的有效性，还强调了其在教育环境中实际实施的可行性。]]></description>
      <guid>https://arxiv.org/abs/2501.16276</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RAPID：基于文本的视频事件检索的检索增强并行推理起草</title>
      <link>https://arxiv.org/abs/2501.16303</link>
      <description><![CDATA[arXiv:2501.16303v1 公告类型：交叉 
摘要：由于多媒体内容的快速增长，使用文本查询从视频中检索事件变得越来越具有挑战性。现有的基于文本的视频事件检索方法通常侧重于对象级描述，而忽略了上下文信息的关键作用。当查询缺乏足够的上下文（例如缺少位置详细信息或背景元素不明确）时，这种限制尤其明显。为了应对这些挑战，我们提出了一种名为 RAPID（检索增强并行推理起草）的新系统，它利用大型语言模型 (LLM) 和基于提示的学习的进步来语义上纠正用户查询并使用相关的上下文信息丰富用户查询。然后通过并行检索处理这些丰富的查询，然后进行评估步骤，根据它们与原始查询的对齐情况选择最相关的结果。通过对我们定制开发的数据集进行大量实验，我们证明 RAPID 明显优于传统检索方法，尤其是对于上下文不完整的查询。我们的系统在参加 2024 年胡志明市人工智能挑战赛时，成功从超过 300 小时的视频中检索事件，验证了其速度和准确性。通过对 RAPID 与比赛组织者提出的基线进行比较的进一步评估，证明了其卓越的有效性，凸显了我们方法的优势和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2501.16303</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于存储神经网络的增强近似最近邻搜索</title>
      <link>https://arxiv.org/abs/2501.16375</link>
      <description><![CDATA[arXiv:2501.16375v1 公告类型：交叉 
摘要：随着最新的机器学习研究采用 ANN，大规模近似最近邻搜索 (ANN) 越来越受到关注。如果数据太大而无法放入内存中，则需要从存储设备中存储的数据（而不是从内存中）中搜索与给定查询向量最相似的向量。NAND 闪存等存储设备的容量比 DRAM 等内存设备大，但它们读取数据的延迟也更大。因此，用于存储的 ANN 方法需要与传统内存 ANN 方法完全不同的方法。由于在合理假设下，搜索所需时间仅由从存储器中获取的数据量决定的近似值成立，因此我们的目标是最小化搜索时间同时最大化召回率。对于基于分区的 ANN，向量在索引构建阶段被划分为簇。在搜索阶段，选择一些簇，从存储中获取所选簇中的向量，并从获取的向量中检索最近的向量。因此，关键点是准确选择包含真实最近邻向量的簇。我们通过提出一种通过神经网络预测正确簇的方法来实现这一点，该神经网络通过交替监督学习和重复簇分配逐渐完善。与最先进的 SPANN 和使用 k 均值聚类和线性搜索的穷举方法相比，所提出的方法在 SIFT1M 上实现了 90% 的召回率，而从存储中获取的数据分别减少了 80% 和 58%。]]></description>
      <guid>https://arxiv.org/abs/2501.16375</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VeriFact：使用电子健康记录验证法学硕士生成的临床文本中的事实</title>
      <link>https://arxiv.org/abs/2501.16672</link>
      <description><![CDATA[arXiv:2501.16672v1 公告类型：交叉 
摘要：临床医学中缺乏确保大型语言模型 (LLM) 生成的文本事实准确性的方法。VeriFact 是一种人工智能系统，它结合了检索增强生成和 LLM-as-a-Judge，以验证 LLM 生成的文本是否由基于电子健康记录 (EHR) 的患者病史事实支持。为了评估这个系统，我们引入了 VeriFact-BHC，这是一个新的数据集，它将出院摘要中的简要医院课程叙述分解为一组简单的陈述，并带有临床医生注释，以确定每个陈述是否由患者的 EHR 临床记录支持。临床医生之间的最高一致性为 88.5%，而与经过去噪和裁定的普通人类临床医生基本事实相比，VeriFact 的一致性高达 92.7%，这表明 VeriFact 超越了普通临床医生根据患者医疗记录核实文本的能力。VeriFact 可能会通过消除当前的评估瓶颈来加速基于 LLM 的 EHR 应用程序的开发。]]></description>
      <guid>https://arxiv.org/abs/2501.16672</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为多模态推荐生成负样本</title>
      <link>https://arxiv.org/abs/2501.15183</link>
      <description><![CDATA[arXiv:2501.15183v2 公告类型：替换 
摘要：多模态推荐系统 (MMRS) 因其能够利用来自各种模态的信息来提高推荐质量而备受关注。然而，现有的负采样技术往往难以有效利用多模态数据，导致性能不佳。在本文中，我们确定了 MMRS 负采样中的两个关键挑战：(1) 生成与正样本形成对比的有凝聚力的负样本和 (2) 在不同模态之间保持平衡的影响。为了应对这些挑战，我们提出了 NegGen，这是一个利用多模态大型语言模型 (MLLM) 生成平衡和对比负样本的新框架。我们设计了三个不同的提示模板，使 NegGen 能够跨多种模态分析和操纵项目属性，然后生成引入更好的监督信号并确保模态平衡的负样本。此外，NegGen 采用因果学习模块来分离干预的关键特征和不相关的项目属性的影响，从而实现对用户偏好的细粒度学习。在真实数据集上进行的大量实验表明，NegGen 在负采样和多模态推荐方面的表现均优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2501.15183</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用段落嵌入对大型语言模型进行高效的列表重新排序</title>
      <link>https://arxiv.org/abs/2406.14848</link>
      <description><![CDATA[arXiv:2406.14848v2 公告类型：replace-cross 
摘要：最近的研究已经证明了在段落排名中使用大型语言模型 (LLM) 的有效性。列表方法（例如 RankGPT）已成为此任务的新前沿。然而，RankGPT 模型的效率受到最大上下文长度和 LLM 推理相对较高的延迟的限制。为了解决这些问题，在本文中，我们提出了 PE-Rank，利用单个段落嵌入作为良好的上下文压缩来实现高效的列表段落重新排名。通过将每个段落视为特殊标记，我们可以直接将段落嵌入输入 LLM，从而减少输入长度。此外，我们引入了一种推理方法，可以动态地将解码空间约束到这些特殊标记，从而加速解码过程。为了使模型适应重新排名，我们采用列表学习对排名损失进行训练。多个基准测试的评估结果表明，PE-Rank 在预填充和解码方面均显著提高了效率，同时保持了有竞争力的排名效果。代码可在 https://github.com/liuqi6777/pe_rank 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14848</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>材料研究的基础大型语言模型</title>
      <link>https://arxiv.org/abs/2412.09560</link>
      <description><![CDATA[arXiv:2412.09560v2 公告类型：replace-cross 
摘要：材料的发现和开发对于应对全球挑战至关重要。然而，材料科学文献的指数级增长包含大量文本数据，这在知识提取、综合和科学推理方面造成了重大瓶颈。大型语言模型 (LLM) 通过自动分析和预测提供了前所未有的机会来加速材料研究。尽管如此，它们的有效部署需要特定领域的适应才能理解和解决与领域相关的任务。在这里，我们介绍了 LLaMat，这是一组材料科学的基础模型，它是通过在大量材料文献和晶体学数据上对 LLaMA 模型进行持续预训练而开发的。通过系统评估，我们证明 LLaMat 在材料特定的 NLP 和结构化信息提取方面表现出色，同时保持了一般的语言能力。专门的 LLaMat-CIF 变体展示了前所未有的晶体结构生成能力，可以预测整个元素周期表中具有高覆盖率的稳定晶体。有趣的是，尽管 LLaMA-3 的性能优于 LLaMA-2，但我们观察到 LLaMat-2 在各种材料科学任务中表现出意想不到的增强领域特定性能，包括从文本和表格中提取结构化信息，尤其是在晶体结构生成中，这是过度训练的 LLM 中潜在的适应刚性。总之，本研究证明了领域适应对于开发可用于材料研究的实用 LLM 副驾驶的有效性。除了材料科学之外，我们的研究结果还揭示了 LLM 领域适应的重要考虑因素，例如模型选择、训练方法和领域特定性能，这可能会影响专门的科学 AI 系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2412.09560</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>