<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 03 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>UQA：乌尔都语问答语料库</title>
      <link>https://arxiv.org/abs/2405.01458</link>
      <description><![CDATA[arXiv:2405.01458v1 公告类型：交叉
摘要：本文介绍了 UQA，这是一个用于乌尔都语问答和文本理解的新颖数据集，乌尔都语是一种资源匮乏的语言，拥有超过 7000 万母语人士。 UQA 是通过使用一种名为 EATS（Enclose to Anchor、Translate、Seek）的技术翻译斯坦福问答数据集 (SQuAD2.0)（一个大型英语 QA 数据集）而生成的，该技术保留了翻译后的上下文段落中的答案范围。该论文描述了在 Google Translator 和 Seamless M4T 这两个候选模型中选择和评估最佳翻译模型的过程。该论文还在 UQA 上对几种最先进的多语言 QA 模型进行了基准测试，包括 mBERT、XLM-RoBERTa 和 mT5，并报告了有希望的结果。对于 XLM-RoBERTa-XL，我们的 F1 分数为 85.99，EM 为 74.56。 UQA 是开发和测试乌尔都语多语言 NLP 系统以及增强现有模型的跨语言可移植性的宝贵资源。此外，本文还展示了 EATS 在为其他语言和领域创建高质量数据集方面的有效性。 UQA 数据集和代码可在 www.github.com/sameearif/UQA 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.01458</guid>
      <pubDate>Fri, 03 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>关于机器生成报告的评估</title>
      <link>https://arxiv.org/abs/2405.00982</link>
      <description><![CDATA[arXiv:2405.00982v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 已经提供了满足信息需求的新方法。尽管在将它们应用于文档排名和短文本生成等设置方面取得了长足进步，但它们仍然难以编写完整、准确且可验证的长篇报告。具有这些品质的报告对于满足用户复杂、细微或多方面的信息需求是必不可少的。在这篇观点论文中，我们汇集了来自行业和学术界以及各种相关研究领域的意见，以提出我们对自动报告生成的愿景，以及——至关重要的——一个可以评估此​​类报告的灵活框架。与其他摘要任务相比，自动报告生成从对信息需求的详细描述开始，说明报告的必要背景、要求和范围。此外，生成的报告应该完整、准确且可验证。这些品质在很多分析报告撰写环境中都是可取的（即使不是必需的），需要重新思考如何构建和评估具有这些品质的系统。为了促进构建这些系统的新努力，我们提出了一个评估框架，该框架借鉴了各种评估中发现的想法。为了测试完整性和准确性，该框架使用以问题和答案形式表达的信息块，这些信息块需要成为任何高质量生成报告的一部分。此外，对将报告中提出的主张映射到其源文档的引文进行评估可确保可验证性。]]></description>
      <guid>https://arxiv.org/abs/2405.00982</guid>
      <pubDate>Fri, 03 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>消除风险，而不是举报：用于降低举报人重新识别风险的半自动文本清理工具</title>
      <link>https://arxiv.org/abs/2405.01097</link>
      <description><![CDATA[arXiv:2405.01097v1 公告类型：交叉
摘要：举报对于确保公共和私营部门的透明度和问责制至关重要。然而，（潜在的）举报人常常害怕或面临报复，即使是匿名举报。他们披露的具体内容和独特的写作风格可能会重新将他们视为来源。欧盟 WBD 等法律措施的范围和有效性有限。因此，防止重新识别的计算方法是鼓励举报人挺身而出的重要补充工具。然而，当前的文本清理工具遵循一刀切的方法，并且对匿名性的看法过于有限。他们的目标是通过用占位符替换典型的高风险单词（例如人名和其他 NE 标签）及其组合来降低识别风险。然而，这种方法对于举报场景来说是不够的，因为它忽略了文本特征（包括写作风格）进一步重新识别的潜力。因此，我们提出、实施和评估一种新颖的分类和缓解策略，用于重写文本，其中涉及举报人评估风险和效用。我们的原型工具半自动评估单词/术语级别的风险，并应用适应风险的匿名化技术来生成语法脱节但经过适当净化的文本。然后，我们使用经过微调的法学硕士进行释义，以使文本连贯且风格中立。我们使用 ECHR 的法庭案例和现实世界举报人证词的摘录来评估我们工具的有效性，并使用流行的 IMDb62 电影评论数据集统计衡量针对作者归属 (AA) 攻击和效用损失的保护。我们的方法可以将 AA 准确率从 98.81% 显着降低到 31.22%，同时保留高达 73.1% 的原始内容语义。]]></description>
      <guid>https://arxiv.org/abs/2405.01097</guid>
      <pubDate>Fri, 03 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>我们真的在下一个篮子推荐中实现了更好的超准确表现吗？</title>
      <link>https://arxiv.org/abs/2405.01143</link>
      <description><![CDATA[arXiv:2405.01143v1 公告类型：新
摘要：下一篮子推荐（NBR）是一种特殊类型的顺序推荐，越来越受到关注。到目前为止，大多数 NBR 研究都集中在优化推荐的准确性上，而优化超准确指标（例如项目公平性和多样性）在很大程度上仍未得到探索。最近对 NBR 的研究发现，推荐重复项目和探索项目之间存在显着的性能差异。与探索项目相比，重复项目贡献了大部分用户的感知准确性。根据这些发现，我们确定了一条潜在的“捷径”，可以在保持高精度的同时优化超准确度的指标。为了利用和验证这种捷径的存在，我们提出了一个即插即用的两步重复探索（TREx）框架，该框架分别处理重复项目和探索项目，其中我们设计了一个简单但高效的重复模块来确保高精度，而两个探索模块的目标是仅优化超出精度的指标。在两个广泛使用的数据集上进行了实验。一系列超出准确度的指标，即。五个公平性指标和三个多样性指标。我们的实验结果验证了TREx的有效性。表面上看，这似乎是个好消息：我们可以同时实现高精度和改进的超准确指标。然而，我们认为我们的算法解决方案 TREx 的现实价值可能是有限的，并反映了评估设置的合理性。我们最终挑战了现有的评估范式，特别是在超准确指标的背景下，并为研究人员提供了见解，以克服潜在的陷阱并确定在优化准确性和超准确指标时要考虑的合理指标。]]></description>
      <guid>https://arxiv.org/abs/2405.01143</guid>
      <pubDate>Fri, 03 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 RAG 驱动的精度在咖啡叶病修复中克服法学硕士挑战</title>
      <link>https://arxiv.org/abs/2405.01310</link>
      <description><![CDATA[arXiv:2405.01310v1 公告类型：新
摘要：本研究介绍了一种创新的人工智能驱动的精准农业系统，利用 YOLOv8 进行疾病识别，利用检索增强生成 (RAG) 进行情境感知诊断。该系统专注于应对影响卡纳塔克邦咖啡生产部门的疾病挑战，将复杂的对象检测技术与语言模型相结合，以解决与大型语言模型 (LLM) 相关的固有限制。我们的方法不仅解决了 LLM 中的幻觉问题，还引入了动态疾病识别和补救策略。实时监控、协作数据集扩展和组织参与确保了系统在不同农业环境中的适应性。建议的系统的效果不仅限于自动化，旨在确保粮食供应、保护生计和促进生态友好的农业实践。通过促进精准的疾病识别，该系统有助于可持续和环保的农业，减少对农药的依赖。展望未来，该项目设想不断发展 RAG 集成物体检测系统，强调可扩展性、可靠性和可用性。这项研究致力于成为农业积极变革的灯塔，与全球为实现可持续和技术增强的粮食生产所做的努力保持一致。]]></description>
      <guid>https://arxiv.org/abs/2405.01310</guid>
      <pubDate>Fri, 03 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 PACE 对活动驱动的音乐聆听进行建模</title>
      <link>https://arxiv.org/abs/2405.01417</link>
      <description><![CDATA[arXiv:2405.01417v1 公告类型：新
摘要：虽然音乐推荐系统文献中广泛研究了聆听情境主题，但经常忽略常规用户行为的整合。在本文中，我们提出了 PACE（基于 PAttern 的用户消费嵌入），这是一种利用周期性收听行为构建用户嵌入的框架。 PACE 利用用户的多渠道时间序列消费模式来构建可理解的用户向量。我们相信通过 PACE 学习到的嵌入揭示了用户聆听动态的重复性质。通过将此框架应用于长期用户历史，我们通过听音乐时执行的活动的预测任务来评估嵌入。验证任务的兴趣有两个，它不仅显示了我们方法的相关性，还提供了一种了解用户音乐消费习惯的深刻方法。]]></description>
      <guid>https://arxiv.org/abs/2405.01417</guid>
      <pubDate>Fri, 03 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>使用块最大剪枝实现更快的稀疏检索学习</title>
      <link>https://arxiv.org/abs/2405.01117</link>
      <description><![CDATA[arXiv:2405.01117v1 公告类型：新
摘要：学习稀疏检索系统旨在将上下文语言模型的有效性与倒排索引等传统数据结构的可扩展性结合起来。然而，这些系统生成的索引与使用传统检索模型的索引存在显着偏差，导致专为传统结构开发的现有查询优化的性能存在差异。这些差异源于查询和文档统计的结构变化，包括子词标记化，导致查询更长、词汇量更小以及发布列表中不同的分数分布。本文介绍了块最大修剪（BMP），这是一种创新的动态修剪策略，专为学习稀疏检索环境中出现的索引而定制。 BMP 采用块过滤机制将文档空间划分为小的、连续的文档范围，然后动态聚合和排序这些文档范围，并仅在必要时在定义的安全提前终止标准的指导下或基于近似检索要求进行完全处理。通过严格的实验，我们表明 BMP 大大优于现有的动态剪枝策略，在安全检索上下文中提供无与伦比的效率，并在近似检索任务中改进精度和效率之间的权衡。]]></description>
      <guid>https://arxiv.org/abs/2405.01117</guid>
      <pubDate>Fri, 03 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>生成相关性反馈和自适应重排序的收敛：TREC DL 2023 上格拉斯哥大学 Terrier 团队</title>
      <link>https://arxiv.org/abs/2405.01122</link>
      <description><![CDATA[arXiv:2405.01122v1 公告类型：新
摘要：本文描述了我们对 TREC 2023 深度学习赛道的参与。我们提交了在两种稀疏检索方法（即 BM25 和 SPLADE）上以零样本和伪相关反馈设置应用来自大型语言模型的生成相关性反馈的运行。我们将第一阶段与使用 monoELECTRA 交叉编码器评分的 BM25 语料库图的自适应重新排名相结合。我们研究了这些生成方法对于第一阶段检索中不同查询类型的功效。在重新排序中，我们研究了具有不同第一阶段的自适应重新排序的操作点，以找到图遍历中第一阶段不再对整个检索管道的性能产生影响的点。我们发现生成查询重构的应用带来了一些性能提升。然而，我们在 P@10 和 nDCG@10 方面的最强运行应用了自适应重排序和生成伪相关反馈，即 uogtr_b_grf_e_gb。]]></description>
      <guid>https://arxiv.org/abs/2405.01122</guid>
      <pubDate>Fri, 03 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>具有有限敏感属性的公平推荐：一种分布式鲁棒优化方法</title>
      <link>https://arxiv.org/abs/2405.01063</link>
      <description><![CDATA[arXiv:2405.01063v1 公告类型：新
摘要：由于推荐系统在求职、电子商务等各个领域都不可或缺，为具有不同敏感属性的用户提供公平的推荐成为必然要求。现有的增强推荐系统公平性的方法假定所有敏感属性都可用，但由于隐私问题或捕获这些属性的手段不足，这些属性可能很难获得。在实践中，这些方法的功效是有限的，这促使我们研究如何利用有限的敏感属性信息来促进公平。
  为了实现这一目标，重建缺失的敏感属性非常重要。然而，由于现实世界敏感属性重构问题和法律规定的复杂性，重构错误是不可避免的。因此，我们追求对重建误差具有鲁棒性的公平学习方法。为此，我们提出了分布式鲁棒公平优化（DRFO），它最大限度地减少了丢失敏感属性（而不是重建概率分布）的所有潜在概率分布的最坏情况不公平性，以考虑重建错误的影响。我们提供理论和经验证据来证明，当只能访问有限的敏感属性时，我们的方法可以有效确保推荐系统的公平性。]]></description>
      <guid>https://arxiv.org/abs/2405.01063</guid>
      <pubDate>Fri, 03 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>“情境学习”或：我如何学会停止担忧并热爱“应用信息检索”</title>
      <link>https://arxiv.org/abs/2405.01116</link>
      <description><![CDATA[arXiv:2405.01116v1 公告类型：新
摘要：随着大语言模型 (LLM) 能力的不断增强，上下文学习 (ICL) 已发展成为自然语言处理 (NLP) 的新范式，而不是针对下游特定的 LLM 参数进行微调。在带有标记示例的任务中，少量此类示例被附加到提示指令中，用于控制解码器的生成过程。因此，ICL 在概念上类似于非参数方法，例如 $k$-NN，其中每个实例的预测本质上取决于局部拓扑，即一组局部的相似实例及其标签（称为少数实例） -拍摄示例）。这表明 ICL 中的测试实例类似于 IR 中的查询，并且从训练集中检索到的 ICL 中的类似示例与从 IR 中的集合中检索到的一组文档相关。虽然标准的无监督排序模型可用于从训练集中检索这些少数样本，但可以通过重新定义特定于下游任务效用的相关性概念来提高示例的有效性，即考虑如果将示例包含在提示指令中可以导致正确的预测，则该示例是相关的。通过这种特定于任务的相关性概念，可以训练监督排序模型（例如，双编码器或交叉编码器），该模型有可能学习如何最佳地选择少数样本。我们相信，神经排序器的最新进展可能会为这项任务找到一个用例，即优化选择示例以实现更有效的下游 ICL 预测。]]></description>
      <guid>https://arxiv.org/abs/2405.01116</guid>
      <pubDate>Fri, 03 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>多语言信息检索中的语言公平性</title>
      <link>https://arxiv.org/abs/2405.00978</link>
      <description><![CDATA[arXiv:2405.00978v1 公告类型：新
摘要：多语言信息检索（MLIR）考虑对多种语言的文档进行排名的问题，以查询以可能不同于任何这些语言的语言表达的查询。最近的研究发现，诸如组合代表单一文档语言的排名列表或使用多语言预训练语言模型之类的方法表现出对一种语言优于其他语言的偏好。这导致不同语言的文档受到系统性的不公平对待。这项工作提出了一种语言公平性指标，用于通过使用 Kruskal-Wallis 测试的统计等价性测试来评估不同语言的文档是否公平排名。与大多数先前关于群体公平性的工作相比，我们不认为任何语言是不受保护的群体。因此，我们提出的度量 PEER（EqualExpected Rank 的概率）是第一个专门用于捕获 MLIR 系统的语言公平性的公平性度量。我们在人工排名列表上展示了 PEER 的行为。我们还在两个公开可用的基准上评估真实的 MLIR 系统，并表明 PEER 分数与先前关于 MLIR 公平性的分析结果一致。我们的实现与 ir-measures 兼容，可从 http://github.com/hltcoe/peer_measure 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.00978</guid>
      <pubDate>Fri, 03 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>基于多意图感知的会话推荐</title>
      <link>https://arxiv.org/abs/2405.00986</link>
      <description><![CDATA[arXiv:2405.00986v1 公告类型：新
摘要：基于会话的推荐（SBR）旨在预测用户在正在进行的会话期间将与之交互的以下项目。大多数现有的 SBR 模型专注于设计复杂的基于神经的编码器来学习会话表示，捕获会话项之间的关系。然而，他们倾向于关注最后一项，忽略会话中可能存在的不同用户意图。此限制会导致性能显着下降，尤其是对于较长的会话。为了解决这个问题，我们提出了一种新颖的 SBR 模型，称为多意图感知基于会话的推荐模型（MiaSRec）。它采用指示会话中项目频率的频率嵌入向量来增强有关重复项目的信息。 MiaSRec 通过派生以每个项目为中心的多个会话表示并动态选择重要的表示来表示各种用户意图。大量实验结果表明，MiaSRec 在六个数据集上的性能优于现有最先进的 SBR 模型，尤其是那些平均会话长度较长的数据集，MRR@20 和 Recall@20 分别实现了 6.27% 和 24.56% 的增益。我们的代码可在 https://github.com/jin530/MiaSRec 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.00986</guid>
      <pubDate>Fri, 03 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>用于大规模流式密集检索的 PLAID SHIRTTT</title>
      <link>https://arxiv.org/abs/2405.00975</link>
      <description><![CDATA[arXiv:2405.00975v1 公告类型：新
摘要：PLAID 是 ColBERT 后期交互双编码器的有效实现，使用预训练语言模型进行排序，在单语言、跨语言和多语言检索方面始终保持最先进的性能。 PLAID 与 ColBERT 的不同之处在于将术语分配给簇并将这些术语表示为簇质心加上压缩残差向量。虽然 PLAID 在批量实验中有效，但在文档随时间到达的流设置中，其性能会下降，因为用于选择集群质心的早期令牌可能无法很好地对新令牌的表示进行建模。在 TB 级临时文本上运行的 PLAID 流式分层索引 (PLAID SHIRTTT) 使用基于分层分片的多阶段增量索引解决了这一问题。 ClueWeb09 和多语言 NeuCLIR 集合上的实验分别证明了该方法对于迄今为止由 ColBERT 架构索引的最大集合和多语言环境中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.00975</guid>
      <pubDate>Fri, 03 May 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>多语言信息检索的蒸馏</title>
      <link>https://arxiv.org/abs/2405.00977</link>
      <description><![CDATA[arXiv:2405.00977v1 公告类型：新
摘要：最近在跨语言信息检索（CLIR）方面的工作（其中查询和文档使用不同的语言）已经显示了 Translate-Distill 框架的优势，该框架使用翻译和蒸馏来训练跨语言神经双编码器模型。但是，Translate-Distill 仅支持单一文档语言。多语言信息检索 (MLIR) 对多语言文档集合进行排名，比 CLIR 更难训练，因为该模型必须为不同语言的文档分配可比较的相关性分数。这项工作扩展了 Translate-Distill，并为 MLIR 提出了多语言 Translate-Distill (MTD)。我们表明，使用 MTD 训练的 ColBERT-X 模型的性能优于使用多语言翻译训练（这是之前最先进的训练方法）训练的模型，在 nDCG@20 中高出 5% 至 25%，在 nDCG@20 中高出 15% 至 45%在地图中。我们还表明，该模型对于训练批次中混合语言的方式具有鲁棒性。我们的实现可以在 GitHub 上找到。]]></description>
      <guid>https://arxiv.org/abs/2405.00977</guid>
      <pubDate>Fri, 03 May 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>高效且负责任地适应大型语言模型以实现强大的 Top-k 推荐</title>
      <link>https://arxiv.org/abs/2405.00824</link>
      <description><![CDATA[arXiv:2405.00824v1 公告类型：新
摘要：传统的推荐系统 (RS) 通常经过优化，以在所有训练样本中统一提高性能指标。
这使得数据驱动的 RS 很难满足多样化的用户需求，因为这些用户的属性各不相同。不同群体之间的性能差异可能会损害模型对子群体的稳健性。虽然最近的研究已经显示出在调整大型语言模型 (LLM) 以解决困难样本方面取得了有希望的结果，但来自数百万用户的长用户查询可能会降低 LLM 的性能并增加成本、处理时间和推理延迟。这对 LLM 用于推荐的实际适用性提出了挑战。为了解决这个问题，我们提出了一个混合任务分配框架，该框架利用了 LLM 和传统 RS 的功能。通过采用两阶段方法来提高对子群体的稳健性，我们促进了任务的战略分配，以高效和负责任地适应 LLM。我们的策略首先识别出弱用户和不活跃用户，这些用户在 RS 中排名表现不佳。接下来，我们对此类用户使用上下文学习方法，其中每个用户交互历史都被情境化为一个独特的排名任务并交给 LLM。我们通过结合各种推荐算法（协同过滤和学习排名推荐模型）和两个 LLM（开源和闭源）来测试我们的混合框架。我们在三个真实数据集上的结果显示，弱用户显著减少，RS 对子群体的稳健性（\approx12\%）和整体性能得到改善，而成本却没有不成比例地增加。]]></description>
      <guid>https://arxiv.org/abs/2405.00824</guid>
      <pubDate>Fri, 03 May 2024 06:18:22 GMT</pubDate>
    </item>
    </channel>
</rss>