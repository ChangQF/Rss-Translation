<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 29 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>推荐系统中潜在因子模型的综述</title>
      <link>https://arxiv.org/abs/2405.18068</link>
      <description><![CDATA[arXiv:2405.18068v1 公告类型：新
摘要：推荐系统是数字时代必不可少的工具，可为电子商务、娱乐和社交媒体等领域的用户提供个性化内容。在为创建这些系统而开发的众多方法中，潜在因子模型已被证明特别有效。本调查系统地回顾了推荐系统中的潜在因子模型，重点关注其核心原理、方法和最新进展。通过涵盖学习数据、模型架构、学习策略和优化技术的结构化框架来检查文献。分析包括贡献分类和对所使用的学习数据类型的详细讨论，例如隐式反馈、信任和内容数据、各种模型（例如概率、非线性和神经模型），以及对各种学习策略的探索，例如在线学习、迁移学习和主动学习。此外，该调查还讨论了用于训练潜在因子模型的优化策略，以提高其性能和可扩展性。通过确定趋势、差距和潜在的研究方向，本调查旨在为希望推动推荐系统领域发展的研究人员和从业者提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2405.18068</guid>
      <pubDate>Wed, 29 May 2024 18:18:13 GMT</pubDate>
    </item>
    <item>
      <title>用于点击率预测的统一低秩压缩框架</title>
      <link>https://arxiv.org/abs/2405.18146</link>
      <description><![CDATA[arXiv:2405.18146v1 公告类型：新 
摘要：深度点击率（CTR）预测模型在现代工业推荐场景中发挥着重要作用。然而，高内存开销和计算成本限制了它们在资源受限环境中的部署。低秩近似是计算机视觉和自然语言处理模型的有效方法，但其在压缩CTR预测模型中的应用较少。由于内存和计算资源有限，CTR预测模型的压缩通常面临三个基本挑战，即（1）。如何减小模型大小以适应边缘设备？（2）。如何加速CTR预测模型推理？（3）。压缩后如何保留原始模型的能力？以前的低秩压缩研究大多采用张量分解，可以实现较高的参数压缩率，但会带来AUC的下降和额外的计算开销。为了应对这些挑战，我们提出了一个统一的低秩分解框架来压缩CTR预测模型。我们发现，即使使用最经典的矩阵分解 SVD 方法，我们的框架也能实现比原始模型更好的性能。为了进一步提高我们框架的有效性，我们对输出特征进行局部压缩，而不是压缩模型权重。我们的统一低秩压缩框架可以应用于各种 CTR 预测模型中的嵌入表和 MLP 层。在两个学术数据集和一个真实的工业基准上进行的大量实验表明，在模型尺寸缩小 3-5 倍的情况下，我们的压缩模​​型可以比未压缩的原始模型实现更快的推理和更高的 AUC。我们的代码位于 https://github.com/yuhao318/Atomic_Feature_Mimicking。]]></description>
      <guid>https://arxiv.org/abs/2405.18146</guid>
      <pubDate>Wed, 29 May 2024 18:18:13 GMT</pubDate>
    </item>
    <item>
      <title>重新思考推荐系统：基于集群的算法选择</title>
      <link>https://arxiv.org/abs/2405.18011</link>
      <description><![CDATA[arXiv:2405.18011v1 公告类型：新
摘要：基于集群的算法选择涉及在用户集群中选择推荐算法以获得性能提升。目前还没有研究尝试过多种聚类方法和推荐算法的组合。我们想表明，在算法选择之前对用户进行聚类可以提高推荐算法的性能。我们的研究涵盖了八个数据集、四种聚类方法和八种推荐算法。我们为每个集群选择性能最佳的推荐算法。我们的工作表明，基于集群的算法选择是一种优化推荐算法性能的有效技术。对于八个数据集中的五个，我们报告 nDCG@10 增加了 19.28% (0.032) 和 360.38% (0.191)，与没有事先进行聚类的算法选择相比。]]></description>
      <guid>https://arxiv.org/abs/2405.18011</guid>
      <pubDate>Wed, 29 May 2024 18:18:12 GMT</pubDate>
    </item>
    <item>
      <title>ReChorus2.0：模块化、任务灵活的推荐库</title>
      <link>https://arxiv.org/abs/2405.18058</link>
      <description><![CDATA[arXiv:2405.18058v1 公告类型：new 
摘要：随着推荐系统应用领域的迅速拓展，越来越多的研究关注推荐系统的各个方面，数据输入、模型和任务设置各不相同。因此，需要一个灵活的库来帮助研究人员实现他们所需的实验策略。现有的针对推荐场景的开放库已经能够复现各种推荐方法并提供了标准实现。然而，这些库往往对数据施加了一定的限制，很少支持同一个模型执行不同的任务和输入格式，限制了用户进行定制化的探索。为了填补这个空白，我们提出了ReChorus2.0，一个面向推荐研究人员的模块化、任务灵活的库。我们基于ReChorus，升级了支持的输入格式、模型以及训练和评估策略，以帮助实现更多数据类型的推荐任务。ReChorus2.0的主要贡献包括：（1）实现复杂而实用的任务，包括重排序和CTR预测任务；（2）加入各种情境感知和重排序推荐器； (3) 扩展现有和新模型，以使用相同模型支持不同的任务；(4) 支持高度定制的输入，包括印象日志、负面项目或点击标签，以及用户、项目和情况上下文。总而言之，ReChorus2.0 是一个全面而灵活的库，更符合推荐场景中的实际问题，满足更多样化的研究需求。ReChorus2.0 的实现和详细教程可以在 https://github.com/THUwangcy/ReChorus 找到。]]></description>
      <guid>https://arxiv.org/abs/2405.18058</guid>
      <pubDate>Wed, 29 May 2024 18:18:12 GMT</pubDate>
    </item>
    <item>
      <title>使用多模态数据的基于注意的顺序推荐系统</title>
      <link>https://arxiv.org/abs/2405.17959</link>
      <description><![CDATA[arXiv:2405.17959v1 公告类型：新
摘要：基于用户过去行为建模动态偏好的顺序推荐系统对电子商务至关重要。最近对这些系统的研究考虑了各种类型的信息，例如图像和文本。然而，多模态数据尚未直接用于向用户推荐产品。在本研究中，我们提出了一种基于注意的顺序推荐方法，该方法采用图像、文本和类别等项目的多模态数据。首先，我们从预先训练的 VGG 和 BERT 中提取图像和文本特征，并将类别转换为多标记形式。随后，独立于项目序列和多模态表示执行注意操作。最后，通过注意力融合函数整合个体注意力信息。此外，我们对每种模态应用多任务学习损失以提高泛化性能。从亚马逊数据集获得的实验结果表明，该方法优于传统的顺序推荐系统。]]></description>
      <guid>https://arxiv.org/abs/2405.17959</guid>
      <pubDate>Wed, 29 May 2024 18:18:11 GMT</pubDate>
    </item>
    <item>
      <title>源回音室：探索用户、数据和推荐系统反馈回路中源偏差的升级</title>
      <link>https://arxiv.org/abs/2405.17998</link>
      <description><![CDATA[arXiv:2405.17998v1 公告类型：新
摘要：最近，研究人员发现神经检索模型更喜欢人工智能生成的内容 (AIGC)，这称为源偏差。与主动搜索行为相比，推荐是另一种重要的信息获取方式，用户更容易受到源偏差的影响。此外，深入研究推荐场景，随着 AIGC 融入涉及用户、数据和推荐系统的反馈回路中，它会逐渐污染候选项目、用户交互历史，并最终污染用于训练推荐模型的数据。源偏差如何以及在多大程度上影响反馈回路内的神经推荐模型仍然未知。在本研究中，我们将源偏差的研究扩展到推荐系统领域，具体研究其对反馈回路不同阶段的影响。我们将 AIGC 集成到推荐内容生态系统的进展概念化为三个不同的阶段——HGC 占主导地位、HGC-AIGC 共存和 AIGC 占主导地位——分别代表过去、现在和未来状态。通过对来自不同领域的三个数据集进行大量实验，我们证明了源偏差的普遍性，并揭示了整个反馈回路中源偏差被放大的潜在数字回声室。这种趋势有可能创建一个推荐生态系统，其中有限的信息源（例如 AIGC）被不成比例地推荐。为了抵消这种偏差并防止其在反馈回路中升级，我们引入了一种黑盒去偏差方法，该方法可以保持模型对 HGC 和 AIGC 的公正性。我们的实验结果验证了所提出的去偏差方法的有效性，证实了它破坏反馈回路的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.17998</guid>
      <pubDate>Wed, 29 May 2024 18:18:11 GMT</pubDate>
    </item>
    <item>
      <title>数据、排序和内在维度对分层可导航小世界中回忆的影响</title>
      <link>https://arxiv.org/abs/2405.17813</link>
      <description><![CDATA[arXiv:2405.17813v1 公告类型：新
摘要：向量搜索系统在 AI 应用中起着关键作用，通常依赖于分层可导航小世界 (HNSW) 算法。然而，使用深度学习模型生成的向量在真实场景下 HNSW 的行为仍未得到充分探索。现有的近似最近邻 (ANN) 基准和研究通常过度依赖 MNIST 或 SIFT1M 等简单数据集，无法反映当前用例的复杂性。我们的调查重点是 HNSW 在一系列数据集中的有效性，包括为模拟特定内在维度而定制的合成向量、具有流行嵌入模型的广泛使用的检索基准以及具有 CLIP 模型的专有电子商务图像数据。我们调查了最流行的 HNSW 向量数据库并整理了它们的默认参数，以在论文期间提供现实的固定参数化。
我们发现，与精确的 K 最近邻 (KNN) 搜索相比，近似 HNSW 搜索的召回率与向量空间的固有维数有关，并且受数据插入顺序的显著影响。我们的方法强调了插入顺序（由可测量属性（例如逐点局部固有维数 (LID) 或已知类别）决定）如何将召回率提高多达 12 个百分点。我们还观察到，对于某些模型，使用 HNSW 而不是 KNN 运行流行的基准数据集可以将排名提高多达三个位置。这项工作强调了在使用近似向量搜索算法开发强大的向量搜索系统时需要更细致的基准和设计考虑。本研究提出了许多具有不同现实世界适用性的场景，旨在更好地提高对 ANN 算法和嵌入的理解和未来发展]]></description>
      <guid>https://arxiv.org/abs/2405.17813</guid>
      <pubDate>Wed, 29 May 2024 18:18:10 GMT</pubDate>
    </item>
    <item>
      <title>SLMRec：为顺序推荐提供小型语言模型</title>
      <link>https://arxiv.org/abs/2405.17890</link>
      <description><![CDATA[arXiv:2405.17890v1 公告类型：新
摘要：顺序推荐 (SR) 任务涉及根据用户过去的交互来预测用户可能与之交互的下一个项目。SR 模型检查用户操作的顺序，以辨别更复杂的行为模式和时间动态。最近的研究表明 LLM 对顺序推荐系统的巨大影响，无论是将顺序推荐视为语言建模，还是作为用户表示的骨干。虽然这些方法提供了出色的性能，但很少有证据表明大型语言模型的必要性以及需要多大的语言模型，特别是在顺序推荐场景中。同时，由于 LLM 的规模巨大，在通常需要每天处理数十亿流量日志的现实平台中应用基于 LLM 的模型效率低下且不切实际。在本文中，我们通过对大规模行业数据集进行大量实验来探索 LLM 深度的影响。令人惊讶的是，我们发现 LLM 的大多数中间层都是多余的。受此启发，我们为 SR 开发了小型语言模型，即 SLMRec，它采用了一种简单而有效的知识提炼方法。此外，SLMRec 与其他训练后效率技术（如量化和修剪）正交，因此可以结合使用。综合实验结果表明，所提出的 SLMRec 模型仅使用基于 LLM 的推荐模型中 13% 的参数就获得了最佳性能，同时在训练和推理时间成本方面分别实现了高达 6.6 倍和 8.0 倍的加速。]]></description>
      <guid>https://arxiv.org/abs/2405.17890</guid>
      <pubDate>Wed, 29 May 2024 18:18:10 GMT</pubDate>
    </item>
    <item>
      <title>用于顺序推荐的数据集再生</title>
      <link>https://arxiv.org/abs/2405.17795</link>
      <description><![CDATA[arXiv:2405.17795v1 公告类型：新
摘要：顺序推荐 (SR) 系统是现代推荐系统的重要组成部分，因为它旨在捕捉用户不断变化的偏好。人们做出了巨大的努力来增强 SR 系统的功能。这些方法通常遵循 \textbf{以模型为中心} 范式，该范式涉及基于固定数据集开发有效模型。然而，这种方法往往忽略了数据中固有的潜在质量问题和缺陷。在 \textbf{以数据为中心} AI 潜力的推动下，我们提出了一种新颖的以数据为中心的范式，用于使用与模型无关的数据集再生框架（称为 DR4SR）开发理想的训练数据集。该框架能够再生具有出色跨架构通用性的数据集。此外，我们引入了 DR4SR+ 框架，该框架结合了模型感知数据集个性化器，可针对目标模型专门定制再生数据集。为了证明以数据为中心的范式的有效性，我们将我们的框架与各种以模型为中心的方法相结合，并在四个广泛采用的数据集上观察到显著的性能改进。此外，我们进行了深入分析，以探索以数据为中心的范式的潜力并提供有价值的见解。代码可以在 \textcolor{blue}{\url{https://anonymous.4open.science/r/KDD2024-86EA/}} 找到]]></description>
      <guid>https://arxiv.org/abs/2405.17795</guid>
      <pubDate>Wed, 29 May 2024 18:18:09 GMT</pubDate>
    </item>
    <item>
      <title>学会不带标签的公平：基于分布的公平排名学习框架</title>
      <link>https://arxiv.org/abs/2405.17798</link>
      <description><![CDATA[arXiv:2405.17798v1 Announce Type: new 
摘要：排序算法作为检索系统的重要组成部分，在以往的研究中得到了不断的改进，尤其是基于相关性的效用算法。近年来，由于对潜在歧视和回音室问题的日益关注，越来越多的研究尝试提出了关于排序公平性的研究。这些尝试包括传统的基于分数的方法，使用预定义的评分函数或选择策略将曝光资源分配给不同的群体，以及基于学习的方法，根据数据样本学习评分函数。基于学习的模型比传统方法更灵活，性能更好。然而，大多数基于学习的模型都是在过时的数据集上训练和测试的，这些数据集几乎没有公平性标签。最先进的模型利用基于相关性的效用分数代替公平性标签来训练它们的公平意识损失，但插入替代并不能保证损失最小。这种不一致性对模型的准确性和性能提出了挑战，尤其是当通过梯度下降实现学习时。因此，我们提出了一种基于分布的公平学习框架 (DLF)，该框架不需要标签，而是用目标公平性曝光分布替换不可用的公平性标签。在 TREC 公平排名轨迹数据集上的实验研究证实，与最先进的公平排名框架相比，我们提出的框架实现了更好的公平性性能，同时更好地控制了公平性相关性权衡。]]></description>
      <guid>https://arxiv.org/abs/2405.17798</guid>
      <pubDate>Wed, 29 May 2024 18:18:09 GMT</pubDate>
    </item>
    <item>
      <title>RREH：用于半配对跨模态检索的重构关系嵌入哈希</title>
      <link>https://arxiv.org/abs/2405.17777</link>
      <description><![CDATA[arXiv:2405.17777v1 公告类型：新
摘要：哈希因其计算高效和易于存储而闻名，在跨模态检索中得到了广泛的探索。当前大多数哈希模型都以数据点之间直接一一映射为前提。然而，在实际操作中，跨模态的数据对应关系可能部分提供。在本研究中，我们介绍了一种专为半配对跨模态检索任务设计的创新无监督哈希技术，称为重构关系嵌入哈希（RREH）。RREH 假设多模态数据共享一个公共子空间。对于配对数据，RREH 通过寻找共享表示来探索异构模态的潜在一致信息。对于非配对数据，为了有效捕获潜在的判别特征，非配对数据和锚点之间的高阶关系被嵌入到潜在子空间中，并通过高效的线性重构来计算。锚点从成对数据中采样，提高了哈希学习的效率。RREH 在统一框架中训练底层特征和二进制编码，同时保留高阶重构关系。凭借精心设计的目标函数和离散优化算法，RREH 具有可扩展性，适用于大规模数据集并有助于实现高效的跨模态检索。在评估过程中，使用部分成对数据对所提方法进行测试，以确定其优于现有几种方法。]]></description>
      <guid>https://arxiv.org/abs/2405.17777</guid>
      <pubDate>Wed, 29 May 2024 18:18:08 GMT</pubDate>
    </item>
    <item>
      <title>促进文化包容性：优化嵌入空间以实现平衡的音乐推荐</title>
      <link>https://arxiv.org/abs/2405.17607</link>
      <description><![CDATA[arXiv:2405.17607v1 公告类型：新
摘要：音乐推荐系统中的流行度偏差（收听次数最多的艺术家和曲目被推荐的次数更多）也会沿着人口统计和文化轴传播偏差。在这项工作中，我们在基于原型的矩阵分解方法中识别了针对代表性不足的文化群体的艺术家的推荐中的这些偏差。与传统的矩阵分解方法不同，基于原型的方法是可解释的。这使我们能够将对少数族裔艺术家的推荐中观察到的偏差（结果）直接与嵌入空间的特定属性（原因）联系起来。我们通过在嵌入空间中捕捉用户​​和歌曲的文化细微差别来减轻音乐推荐中的流行度偏差。为了在保持推荐质量的同时应对这些挑战，我们提出了两种对嵌入空间的新颖增强：i）我们提出了一种方法来过滤掉用于表示每个用户和项目的不相关原型以提高通用性，以及 ii）我们引入正则化技术来加强嵌入空间内原型的更均匀分布。我们的结果表明，在减少流行偏见、提高音乐推荐中的人口和文化公平性方面取得了显著的进步，同时实现了具有竞争力的（如果不是更好的）整体表现。]]></description>
      <guid>https://arxiv.org/abs/2405.17607</guid>
      <pubDate>Wed, 29 May 2024 18:18:07 GMT</pubDate>
    </item>
    <item>
      <title>使用集成提示、文档融合和相关反馈进行生成查询重构</title>
      <link>https://arxiv.org/abs/2405.17658</link>
      <description><![CDATA[arXiv:2405.17658v1 公告类型：新
摘要：查询重构 (QR) 是一组技术，用于将用户的原始搜索查询转换为更符合用户意图并改善其搜索体验的文本。最近，零样本 QR 是一种很有前途的方法，因为它能够利用大型语言模型中固有的知识。受到使其他任务受益的集成提示策略成功的启发，我们研究它们是否可以改进查询重构。在此背景下，我们提出了两种基于集成的提示技术，GenQREnsemble 和 GenQRFusion，它们利用零样本指令的释义来生成多组关键字，最终提高检索性能。我们进一步介绍了它们的检索后变体，以结合来自各种来源的相关性反馈，包括模拟人类用户的 oracle 和“评论家”LLM。我们证明，在多个基准测试中，查询重构的集合可以在 nDCG@10 的预检索设置中将检索效率提高 18%，在后检索设置中将检索效率提高 9%，优于所有之前报告的 SOTA 结果。我们进行后续分析，以调查反馈文档的影响、纳入特定领域的指令、过滤重构并生成可能对人类搜索者更有益的流畅重构。总之，本文介绍的技术和结果为自动检索查询重构树立了新标杆，并为未来的研究指明了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2405.17658</guid>
      <pubDate>Wed, 29 May 2024 18:18:07 GMT</pubDate>
    </item>
    <item>
      <title>RAGSys：项目冷启动推荐系统作为 RAG 系统</title>
      <link>https://arxiv.org/abs/2405.17587</link>
      <description><![CDATA[arXiv:2405.17587v1 公告类型：新
摘要：大型语言模型 (LLM) 在实际应用中前景广阔，但它们的通用知识往往无法满足特定领域的需求。微调是一种常见方法，可能会遭受灾难性遗忘并阻碍普遍性。上下文学习 (ICL) 提供了一种替代方案，它可以利用检索增强生成 (RAG) 为 LLM 提供针对少量学习任务的相关演示。本文探讨了 ICL 演示检索系统所需的品质。我们认为，在这种情况下，ICL 检索类似于项目冷启动推荐系统，优先考虑发现并最大化信息增益而不是严格相关性。我们提出了一种新颖的评估方法来衡量 LLM 在 NLP 任务上的后续表现，从而无需主观多样性分数。我们的研究结果证明了多样性和质量偏差在有效 ICL 检索到的演示中的关键作用，并强调了推荐系统技术在该领域的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.17587</guid>
      <pubDate>Wed, 29 May 2024 18:18:06 GMT</pubDate>
    </item>
    <item>
      <title>通过拓扑感知检索增强文本生成</title>
      <link>https://arxiv.org/abs/2405.17602</link>
      <description><![CDATA[arXiv:2405.17602v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 在生成文本方面取得了令人瞩目的进步，但它们往往受到输入中所包含知识的限制，并且容易产生不准确或幻觉的内容。为了解决这些问题，检索增强生成 (RAG) 被用作一种有效的策略，通过从外部数据库中提取额外的文本来增强可用的知识库并将响应锚定在现实中。在实际应用中，文本通常通过图中的实体链接，例如学术论文中的引文或社交网络中的评论。本文利用这些拓扑关系来指导 RAG 中的检索过程。具体来说，我们探索了两种拓扑连接：基于邻近度（关注紧密连接的节点）和基于角色（关注共享相似子图结构的节点）。我们的实证研究证实了它们与文本关系的相关性，从而引导我们开发一个拓扑感知的检索增强生成框架。该框架包括一个检索模块，该模块根据文本的拓扑关系选择文本，以及一个聚合模块，该模块将这些文本集成到提示中以刺激 LLM 进行文本生成。我们已经整理了已建立的文本归因网络并进行了全面的实验来验证该框架的有效性，证明了其通过拓扑感知增强 RAG 的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.17602</guid>
      <pubDate>Wed, 29 May 2024 18:18:06 GMT</pubDate>
    </item>
    </channel>
</rss>