<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 17 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>HyPA-RAG：面向 AI 法律和政策应用的混合参数自适应检索增强生成系统</title>
      <link>https://arxiv.org/abs/2409.09046</link>
      <description><![CDATA[arXiv:2409.09046v1 公告类型：新 
摘要：虽然大型语言模型 (LLM) 在文本生成和问答方面表现出色，但它们在 AI 法律和政策方面的有效性受到过时知识、幻觉和复杂背景下的推理不足的限制。检索增强生成 (RAG) 系统通过整合外部知识来提高响应准确性，但在解释定性和定量 AI 法律文本时，检索错误、上下文整合不佳和成本高昂方面存在困难。本文介绍了一种针对 AI 法律和政策量身定制的混合参数自适应 RAG (HyPA-RAG) 系统，以纽约市地方法律 144 (LL144) 为例。HyPA-RAG 使用查询复杂性分类器进行自适应参数调整，结合密集、稀疏和知识图谱方法的混合检索策略，以及具有特定问题类型和指标的评估框架。通过动态调整参数，HyPA-RAG 显著提高了检索准确率和响应保真度。在 LL144 上的测试表明，其正确性、忠实度和上下文精确度均有所提高，满足了复杂、高风险的 AI 法律和政策应用中对适应性 NLP 系统的需求。]]></description>
      <guid>https://arxiv.org/abs/2409.09046</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过协调双塔动态语义标记生成器释放法学硕士的推荐潜力</title>
      <link>https://arxiv.org/abs/2409.09253</link>
      <description><![CDATA[arXiv:2409.09253v1 Announce Type: new 
摘要：预训练大型语言模型（LLM）以其前所未有的语义理解和逻辑推理能力，在开发下一代推荐系统（RS）方面展现出巨大的潜力。然而，当前方法采用的静态索引范式极大地限制了LLM在推荐方面的利用能力，不仅导致语义知识和协作知识之间的一致性不足，而且忽视了高阶用户-项目交互模式。在本文中，我们提出了双塔动态语义推荐器（TTDS），这是第一个采用动态语义索引范式的生成式RS，旨在同时解决上述问题。更具体地说，我们首次设计了一个动态知识融合框架，将双塔语义标记生成器集成到基于LLM的推荐器中，分层地为项目和用户分配有意义的语义索引，并据此预测目标项目的语义索引。此外，提出了一种双模态变分自动编码器，以促进语义和协作知识之间的多粒度对齐。最后，提出了一系列专门为捕获高阶用户项目交互模式而定制的新型调整任务，以利用用户历史行为。在三个公共数据集上进行的大量实验证明了所提出的方法在开发基于 LLM 的生成 RS 方面的优势。与领先的基线方法相比，所提出的 TTDS 推荐器在命中率上平均提高了 19.41%，在 NDCG 指标上平均提高了 20.84%。]]></description>
      <guid>https://arxiv.org/abs/2409.09253</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在顺序推荐系统中测量近期偏差</title>
      <link>https://arxiv.org/abs/2409.09722</link>
      <description><![CDATA[arXiv:2409.09722v1 公告类型：新
摘要：顺序推荐系统中的近期偏差是指在用户会话中过分强调近期项目。这种偏差会降低推荐的偶然性，并阻碍系统捕捉用户长期兴趣的能力，从而导致用户脱离。我们提出了一个简单而有效的新指标，专门用于量化近期偏差。我们的研究结果还表明，我们提出的指标中测量的高近期偏差也会对推荐性能产生不利影响，减轻这一偏差会提高我们实验中评估的所有模型的推荐性能，从而凸显了测量近期偏差的重要性。]]></description>
      <guid>https://arxiv.org/abs/2409.09722</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CROSS-JEM：用于短文本排序任务的准确高效交叉编码器</title>
      <link>https://arxiv.org/abs/2409.09795</link>
      <description><![CDATA[arXiv:2409.09795v1 公告类型：新
摘要：根据一组项目与给定查询的相关性对其进行排名是搜索和推荐中的核心问题。基于 Transformer 的排名模型是此类任务的最新方法，但它们对每个查询项目进行独立评分，而忽略了其他相关项目的联合上下文。这导致排名准确度不理想且计算成本高昂。为此，我们提出了具有联合高效建模的交叉编码器 (CROSS-JEM)，这是一种新颖的排名方法，使基于 Transformer 的模型能够联合对查询的多个项目进行评分，从而最大限度地提高参数利用率。CROSS-JEM 利用 (a) 冗余和标记重叠来联合评分多个项目，这些项目通常是搜索和推荐中出现的短文本短语，以及 (b) 一种模拟排名概率的新颖训练目标。与标准交叉编码器相比，CROSS-JEM 实现了最先进的准确度和 4 倍以上的排名延迟。我们的贡献有三方面：（i）我们强调了排名应用程序对每个查询的数千个项目进行评分的需求与当前交叉编码器的有限功能之间的差距；（ii）我们引入了 CROSS-JEM，以便对每个查询的多个项目进行联合有效评分；（iii）我们在标准公共数据集和专有数据集上展示了最先进的准确性。CROSS-JEM 为设计量身定制的基于早期注意力的排名模型开辟了新方向，这些模型结合了严格的生产约束，例如项目多样性和延迟。]]></description>
      <guid>https://arxiv.org/abs/2409.09795</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成系统中的可信度：一项调查</title>
      <link>https://arxiv.org/abs/2409.10102</link>
      <description><![CDATA[arXiv:2409.10102v1 公告类型：新
摘要：检索增强生成 (RAG) 已迅速发展成为大型语言模型 (LLM) 开发的关键范例。虽然目前该领域的大部分研究都集中在性能优化上，特别是在准确性和效率方面，但 RAG 系统的可信度仍然是一个仍在探索的领域。从积极的角度来看，RAG 系统有望通过从庞大的外部数据库中为 LLM 提供有用且最新的知识来增强 LLM，从而缓解长期存在的幻觉问题。而从消极的角度来看，如果检索到的信息不合适或利用不当，RAG 系统就有生成不良内容的风险。为了解决这些问题，我们提出了一个统一的框架，从六个关键维度评估 RAG 系统的可信度：事实性、稳健性、公平性、透明度、问责制和隐私性。在这个框架内，我们彻底审查了每个维度的现有文献。此外，我们针对六个维度创建了评估基准，并对各种专有和开源模型进行了全面的评估。最后，我们根据调查结果确定了未来研究的潜在挑战。通过这项工作，我们旨在为未来的研究奠定结构化基础，并为提高 RAG 系统在实际应用中的可信度提供实用见解。]]></description>
      <guid>https://arxiv.org/abs/2409.10102</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多类别分类增强个性化食谱推荐</title>
      <link>https://arxiv.org/abs/2409.10267</link>
      <description><![CDATA[arXiv:2409.10267v1 公告类型：新
摘要：本文旨在解决多样化烹饪偏好领域中个性化食谱推荐的挑战。问题领域涉及食谱推荐，利用关联分析和分类等技术。关联分析探索不同成分之间的关​​系和联系，以增强用户体验。同时，分类方面涉及根据用户定义的成分和偏好对食谱进行分类。本文的一个独特之处在于考虑属于多个类别的食谱和成分，认识到烹饪组合的复杂性。这需要一种复杂的分类和推荐方法，确保系统适应食谱分类的性质。本文不仅寻求推荐食谱，还探索实现准确和个性化推荐的过程。]]></description>
      <guid>https://arxiv.org/abs/2409.10267</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中的因果发现：示例和讨论</title>
      <link>https://arxiv.org/abs/2409.10271</link>
      <description><![CDATA[arXiv:2409.10271v1 公告类型：新
摘要：因果关系越来越受到人工智能和机器学习社区的关注。本文给出了使用因果图对推荐系统问题进行建模的示例。具体来说，我们通过将来自开源数据集的观察数据与先验知识相结合，着手因果发现任务来学习因果图。由此产生的因果图显示，只有少数变量有效地影响了所分析的反馈信号。这与机器学习社区最近在大规模模型（例如神经网络）中包含越来越多变量的趋势形成了鲜明对比。]]></description>
      <guid>https://arxiv.org/abs/2409.10271</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>beeFormer：在推荐系统中弥合语义和交互相似性之间的差距</title>
      <link>https://arxiv.org/abs/2409.10309</link>
      <description><![CDATA[arXiv:2409.10309v1 公告类型：新
摘要：推荐系统通常使用文本辅助信息来改进其预测，尤其是在冷启动或零样本推荐场景中，而传统的协同过滤方法无法使用。近年来，已经提出了许多用于推荐系统文本挖掘辅助信息的方法，其中最突出的是句子 Transformers。然而，这些模型被训练来预测语义相似性，而不利用具有推荐系统特有的隐藏模式的交互数据。在本文中，我们提出了 beeFormer，一个使用交互数据训练句子 Transformer 模型的框架。我们证明，使用 beeFormer 训练的模型可以在数据集之间传递知识，同时不仅优于语义相似性句子 Transformers，而且优于传统的协同过滤方法。我们还表明，对来自不同领域的多个数据集进行训练可以在单个模型中积累知识，从而释放了训练通用的、与领域无关的句子 Transformer 模型来挖掘推荐系统的文本表示的可能性。我们在 https://github.com/recombee/beeformer 上发布了源代码、训练模型和其他详细信息，允许复制我们的实验。]]></description>
      <guid>https://arxiv.org/abs/2409.10309</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型增强硬样本识别用于去噪推荐</title>
      <link>https://arxiv.org/abs/2409.10343</link>
      <description><![CDATA[arXiv:2409.10343v1 公告类型：新
摘要：隐式反馈通常用于构建推荐系统，由于误点击和位置偏差等因素，它不可避免地会面临噪音。先前的研究试图通过基于其不同的模式（例如更高的损失值）识别噪声样本，并通过样本删除或重新加权来减轻噪音，从而缓解这种情况。尽管取得了进展，但我们观察到现有方法难以区分硬样本和噪声样本，因为它们通常表现出相似的模式，从而限制了它们在去噪推荐中的有效性。为了应对这一挑战，我们提出了一个大型语言模型增强硬样本去噪 (LLMHD) 框架。具体来说，我们构建了一个基于 LLM 的评分器来评估项目与用户偏好的语义一致性，该一致性基于总结的历史用户交互进行量化。得到的分数用于评估样本的硬度，以实现逐点或成对训练目标。为了确保效率，我们引入了一种基于方差的样本修剪策略来在评分之前过滤潜在的硬样本。此外，我们提出了一个迭代偏好更新模块，旨在不断完善总结的用户偏好，该偏好可能会因用户与物品交互的假阳性而产生偏差。在三个真实数据集和四个骨干推荐器上进行的大量实验证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.10343</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在基于扩散模型的推荐中加入无分类器指导</title>
      <link>https://arxiv.org/abs/2409.10494</link>
      <description><![CDATA[arXiv:2409.10494v1 公告类型：新
摘要：本文介绍了一种基于扩散的推荐系统，该系统结合了无分类器指导。大多数当前推荐系统使用传统方法（例如协作或基于内容的过滤）提供推荐。扩散是一种新的生成 AI 方法，它改进了以前的生成 AI 方法，例如变分自动编码器 (VAE) 和生成对抗网络 (GAN)。我们将扩散纳入推荐系统，该系统反映了用户浏览和评价项目时的顺序。虽然一些当前的推荐系统采用了扩散，但它们并没有采用无分类器指导，这是整个扩散模型的一项新创新。在本文中，我们提出了一种扩散推荐系统，它增强了底层推荐系统模型以提高性能，并结合了无分类器指导。我们的研究结果表明，在各种数据集上的几个推荐任务的大多数指标上，与最先进的推荐系统相比，它都有所改进。特别是，我们的方法展示了在数据稀疏时提供更好建议的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.10494</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过数据增强增强社交网络广告预测的比较研究</title>
      <link>https://arxiv.org/abs/2404.13812</link>
      <description><![CDATA[arXiv:2404.13812v3 公告类型：交叉 
摘要：在不断发展的社交网络广告领域，数据量和准确性对预测模型的性能起着至关重要的作用。然而，稳健预测算法的开发往往受到现实世界数据集中有限的规模和潜在偏差的阻碍。本研究提出并探索了社交网络广告数据的生成增强框架。我们的框架探索了三种用于数据增强的生成模型——生成对抗网络 (GAN)、变分自动编码器 (VAE) 和高斯混合模型 (GMM)——以丰富社交网络广告分析有效性背景下的数据可用性和多样性。通过对特征空间进行综合扩展，我们发现通过数据增强，各种分类器的性能得到了定量改善。此外，我们比较了每种数据增强技术带来的相对性能提升，为从业者选择合适的技术来提高模型性能提供了见解。本文通过展示合成数据增强缓解了社交网络广告领域中小型或不平衡数据集带来的限制，为文献做出了贡献。同时，本文还提供了不同数据增强方法实用性的比较视角，从而指导从业者选择合适的技术来增强模型性能。]]></description>
      <guid>https://arxiv.org/abs/2404.13812</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AlpaPICO：使用 LLM 从临床试验文件中提取 PICO 帧</title>
      <link>https://arxiv.org/abs/2409.09704</link>
      <description><![CDATA[arXiv:2409.09704v1 公告类型：交叉 
摘要：近年来，临床试验报告的发表数量激增，这使得进行系统评价变得具有挑战性。从临床试验研究自动提取人群、干预、比较和结果 (PICO) 可以减轻传统上耗时的手动审查系统评价的过程。现有的 PICO 框架提取方法涉及监督方法，该方法依赖于以 BIO 标签标记形式手动注释的数据点的存在。最近的方法，例如上下文学习 (ICL)，已被证明对许多下游 NLP 任务有效，需要使用标记示例。在这项工作中，我们采用 ICL 策略，利用在 LLM 预训练阶段收集的大型语言模型 (LLM) 的预训练知识，在无监督设置下自动从临床试验文档中提取与 PICO 相关的术语，以绕过大量注释数据实例的可用性。此外，为了展示 LLM 在具有大量注释样本的 Oracle 场景中的最高效率，我们采用了指令调整策略，即采用低秩自适应 (LORA) 在低资源环境中对 PICO 帧提取任务的巨型模型进行训练。我们的实证结果表明，我们提出的基于 ICL 的框架在所有版本的 EBM-NLP 数据集上都产生了可比的结果，而我们提出的指令调整版本的框架在所有不同的 EBM-NLP 数据集上都产生了最先进的结果。我们的项目可在 \url{https://github.com/shrimonmuke0202/AlpaPICO.git} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.09704</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实排序学习中实用安全的近端排序策略优化</title>
      <link>https://arxiv.org/abs/2409.09881</link>
      <description><![CDATA[arXiv:2409.09881v1 公告类型：交叉 
摘要：反事实学习排名 (CLTR) 可能存在风险，并且在各种情况下都可能产生次优模型，从而损害部署时的性能。引入安全 CLTR 是为了在使用逆倾向评分纠正位置偏差时减轻这些风险。然而，现有的 CLTR 安全措施不适用于最先进的 CLTR 方法，无法处理信任偏差，并且依赖于对用户行为的特定假设。我们提出了一种新颖的方法，即近端排名策略优化 (PRPO)，它无需对用户行为进行假设即可在部署时提供安全性。PRPO 消除了学习与安全排名模型太不相似的排名行为的动机。因此，PRPO 对学习模型可以降低性能指标的程度施加了限制，而不依赖于任何特定的用户假设。我们的实验表明，PRPO 比现有的安全逆倾向评分方法提供更高的性能。即使在最大对抗的情况下，PRPO 也始终保持安全。通过避免假设，PRPO 是第一个在部署中具有无条件安全性的方法，并且可以转化为现实世界应用的强大安全性。]]></description>
      <guid>https://arxiv.org/abs/2409.09881</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于近似最近邻搜索的欧氏空间中高维向量的实用渐近最优量化</title>
      <link>https://arxiv.org/abs/2409.09913</link>
      <description><![CDATA[arXiv:2409.09913v1 公告类型：交叉 
摘要：高维欧几里得空间中的近似最近邻 (ANN) 查询是数据库系统中的关键运算符。对于此查询，量化是为压缩向量和减少内存消耗而开发的一类流行方法。最近，一种称为 RaBitQ 的方法在这些方法中实现了最先进的性能。它在使用相同压缩率时在准确性和效率方面都产生了更好的经验性能，并提供了严格的理论保证。然而，该方法仅适用于以高压缩率 (32 倍) 压缩向量，并且缺乏通过使用更多空间来实现更高精度的支持。在本文中，我们通过扩展 RaBitQ 引入了一种新的量化方法来解决这个问题。新方法继承了 RaBitQ 的理论保证，并在空间和误差界限之间的权衡方面实现了渐近最优性，这将在本研究中得到证明。此外，我们还介绍了该方法的有效实现，使其能够应用于 ANN 查询，从而减少空间和时间消耗。在现实世界数据集上进行的大量实验证实，在使用相同内存量时，我们的方法在准确率和效率方面始终优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2409.09913</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiffATR：基于扩散的音频文本检索生成模型</title>
      <link>https://arxiv.org/abs/2409.10025</link>
      <description><![CDATA[arXiv:2409.10025v1 公告类型：交叉 
摘要：现有的音频文本检索 (ATR) 方法本质上是判别模型，旨在最大化条件似然，表示为 p(candidates|query)。然而，这种方法未能考虑内在数据分布 p(query)，导致难以辨别分布外的数据。在这项工作中，我们尝试从生成的角度解决这一限制，并将音频和文本之间的关系建模为它们的联合概率 p(candidates,query)。为此，我们提出了一个基于扩散的 ATR 框架 (DiffATR)，它将 ATR 建模为一个迭代过程，逐步从噪声中生成联合分布。在整个训练阶段，DiffATR 从生成和判别的角度进行了优化：生成器通过生成损失进行细化，而特征提取器受益于对比损失，从而结合了两种方法的优点。在 AudioCaps 和 Clotho 数据集上进行的实验表现出色，验证了我们方法的有效性。值得注意的是，在没有任何改动的情况下，我们的 DiffATR 在域外检索设置中始终表现出色。]]></description>
      <guid>https://arxiv.org/abs/2409.10025</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>