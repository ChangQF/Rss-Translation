<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 03 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型改进文本嵌入</title>
      <link>https://arxiv.org/abs/2401.00368</link>
      <description><![CDATA[arXiv:2401.00368v3 公告类型：replace-cross 
摘要：在本文中，我们介绍了一种新颖而简单的方法，仅使用合成数据和不到 1k 个训练步骤即可获得高质量的文本嵌入。与现有方法不同，现有方法通常依赖于使用数十亿个弱监督文本对进行多阶段中间预训练，然后使用一些标记数据集进行微调，而我们的方法不需要构建复杂的训练流程或依赖手动收集的数据集，而这些数据集通常受到任务多样性和语言覆盖范围的限制。我们利用专有的 LLM 为 93 种语言的数十万个文本嵌入任务生成多样化的合成数据。然后，我们使用标准对比损失在合成数据上微调开源解码器专用 LLM。实验表明，我们的方法在竞争激烈的文本嵌入基准上实现了强大的性能，而无需使用任何标记数据。此外，当使用合成数据和标记数据进行微调时，我们的模型在 BEIR 和 MTEB 基准上创造了新的最先进结果。]]></description>
      <guid>https://arxiv.org/abs/2401.00368</guid>
      <pubDate>Tue, 04 Jun 2024 03:17:00 GMT</pubDate>
    </item>
    <item>
      <title>数学剽窃的分类</title>
      <link>https://arxiv.org/abs/2401.16969</link>
      <description><![CDATA[arXiv:2401.16969v2 公告类型：替换 
摘要：抄袭是一个紧迫的问题，随着大型语言模型的出现，抄袭问题更加突出。现有的抄袭检测系统可以可靠地发现复制和适度改写的文本，但无法发现思想抄袭，尤其是在大量使用形式数学符号的数学科学领域。我们做出了两点贡献。首先，我们通过注释可能抄袭的 122 个科学文献对建立了数学内容重用的分类法。其次，我们分析了在新建立的分类法上检测抄袭和数学内容相似性的最佳方法。我们发现，抄袭和数学内容相似性的最佳方法分别实现了 0.06 和 0.16 的总体检测分数 (PlagDet)。表现最佳的方法无法检测到所有七种新建立的数学相似性类型的大多数情况。概述的贡献将有利于剽窃检测系统、推荐系统、问答系统和搜索引擎的研究。我们将实验代码和带注释的数据集提供给社区：https://github.com/gipplab/Taxonomy-of-Mathematical-Plagiarism]]></description>
      <guid>https://arxiv.org/abs/2401.16969</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>多跳问答</title>
      <link>https://arxiv.org/abs/2204.09140</link>
      <description><![CDATA[arXiv:2204.09140v2 公告类型：replace-cross 
摘要：问答 (QA) 任务长期以来一直受到广泛的研究兴趣。它与语言理解和知识检索任务的相关性，以及简单的设置使得问答任务对于强人工智能系统至关重要。最近在简单问答任务上取得的成功已将焦点转移到更复杂的设置上。其中，多跳问答 (MHQA) 是近年来研究最多的任务之一。广义上讲，MHQA 是回答自然语言问题的任务，这些问题涉及提取和组合多条信息并进行多步推理。多跳问题的一个例子是“阿根廷 PGA 锦标赛纪录保持者在全球赢得了多少场比赛？”。回答这个问题需要两条信息：“谁是阿根廷 PGA 锦标赛的纪录保持者？”和“[Sub Q1 的答案] 赢得了多少场比赛？”。回答多跳问题和执行多步推理的能力可以显著提高 NLP 系统的实用性。因此，该领域出现了大量高质量的数据集、模型和评估策略。“多跳”的概念有些抽象，这导致需要多跳推理的任务种类繁多。这导致不同的数据集和模型彼此之间差异很大，使得该领域的概括和调查具有挑战性。我们的目标是提供 MHQA 任务的通用和正式定义，并组织和总结现有的 MHQA 框架。我们还概述了构建 MHQA 数据集的一些最佳实践。本书提供了系统而全面的介绍，以及对这项非常有趣但颇具挑战性的任务的现有尝试的结构。]]></description>
      <guid>https://arxiv.org/abs/2204.09140</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>将海量文本嵌入基准扩展到法语</title>
      <link>https://arxiv.org/abs/2405.20468</link>
      <description><![CDATA[arXiv:2405.20468v1 公告类型：交叉
摘要：近年来，已经出现了许多可用的嵌入模型，并广泛应用于各种 NLP 任务。海量文本嵌入基准 (MTEB) 大大简化了选择一个在英语中表现良好的模型，但扩展到其他语言仍然具有挑战性。这就是为什么我们扩展 MTEB 以提出第一个针对法语的大规模句子嵌入基准的原因。我们不仅在易于使用的界面中收集了 22 个现有数据集，而且还创建了三个新的法语数据集，用于对 8 个不同任务进行全局评估。我们对 46 个精心挑选的嵌入模型进行了大规模比较，进行了全面的统计测试，并分析了模型性能与它们的许多特征之间的相关性。我们发现，即使没有一个模型在所有任务上都是最好的，在句子相似性上预先训练的大型多语言模型表现特别好。我们的工作附带开源代码、新数据集和公共排行榜。]]></description>
      <guid>https://arxiv.org/abs/2405.20468</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行问答系统中段落重新排序的段落特定提示调整</title>
      <link>https://arxiv.org/abs/2405.20654</link>
      <description><![CDATA[arXiv:2405.20654v1 公告类型：交叉 
摘要：有效的段落检索和重新排序方法已被广泛用于在开放域问答任务中识别合适的候选人，最近的研究已经利用 LLM 对检索到的段落进行重新排序，方法是根据每个段落的条件问题的对数似然性。虽然这些方法已经显示出有希望的结果，但性能对人工编写的提示（或硬提示）特别敏感，并且微调 LLM 可能计算密集且耗时。此外，这种方法限制了问题段落相关性对和段落特定知识的利用，以增强 LLM 的排名能力。在本文中，我们提出了针对段落的提示调整以在开放域问答（PSPT）中进行重新排序：一种参数高效的方法，可以微调可学习的段落特定软提示，结合来自有限问题段落相关性对的段落特定知识。该方法涉及根据以每段话和学习到的软提示为条件生成问题的模型的对数似然性对检索到的段落进行排序。我们利用 Llama-2-chat-7B 模型在三个公开可用的开放域问答数据集上进行了广泛的实验，结果证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.20654</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>Hopfield 模型作为联想记忆的分析</title>
      <link>https://arxiv.org/abs/2402.04264</link>
      <description><![CDATA[arXiv:2402.04264v1 公告类型：交叉 
摘要：本文深入研究了 Hopfield 神经网络模型，从生物神经系统中汲取灵感。探索从概述模型的基础开始，结合机械统计的见解来加深我们的理解。该研究专注于音频检索，展示了 Hopfield 模型的联想记忆能力。通过实际实施，网络被训练来检索不同的模式。]]></description>
      <guid>https://arxiv.org/abs/2402.04264</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>设计天文学研究中大型语言模型的评估框架</title>
      <link>https://arxiv.org/abs/2405.20389</link>
      <description><![CDATA[arXiv:2405.20389v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 正在改变科学研究的方式。必须了解研究人员如何与这些模型互动，以及天文学等科学子社区如何从中受益。但是，目前没有评估 LLM 在天文学中的使用情况的标准。因此，我们提出了一项关于天文学研究人员如何与 LLM 互动的评估研究的实验设计。我们部署了一个 Slack 聊天机器人，它可以通过检索增强生成 (RAG) 回答用户的查询；这些回复基于 arXiv 中的天文学论文。我们记录并匿名化用户问题和聊天机器人答案、用户对 LLM 回复的赞成和反对、用户对 LLM 的反馈以及检索到的文档和与查询的相似度分数。我们的数据收集方法将使未来能够对天文学的 LLM 工具进行动态评估。]]></description>
      <guid>https://arxiv.org/abs/2405.20389</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>SelfGNN：用于顺序推荐的自监督图神经网络</title>
      <link>https://arxiv.org/abs/2405.20878</link>
      <description><![CDATA[arXiv:2405.20878v1 公告类型：新
摘要：顺序推荐通过对用户的时间和顺序交互模式进行建模，有效地解决了信息过载问题。为了克服监督信号的局限性，最近的方法在推荐系统中采用了自监督学习技术。然而，仍有两个关键挑战尚未解决。首先，现有的顺序模型主要关注单个交互序列的长期建模，忽略了不同用户行为之间有价值的短期协作关系。其次，现实世界的数据通常包含噪音，特别是在用户的短期行为中，这些噪音可能来自临时意图或误点击。这种噪音会对图和序列模型的准确性产生负面影响，进一步使建模过程复杂化。为了应对这些挑战，我们提出了一种称为自监督图神经网络（SelfGNN）的顺序推荐新框架。SelfGNN 框架根据时间间隔对短期图进行编码，并利用图神经网络（GNN）来学习短期协作关系。它通过区间融合和动态行为建模捕获多个粒度级别的长期用户和项目表示。重要的是，我们的个性化自增强学习结构通过基于长期用户兴趣和个人稳定性减轻短期图中的噪声来增强模型的鲁棒性。在四个真实数据集上进行的大量实验表明，SelfGNN 的表现优于各种最先进的基线。我们的模型实现代码可在 https://github.com/HKUDS/SelfGNN 获得。]]></description>
      <guid>https://arxiv.org/abs/2405.20878</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>CWRCzech：100M 查询文档捷克点击数据集及其在 Web 相关性排名中的应用</title>
      <link>https://arxiv.org/abs/2405.20994</link>
      <description><![CDATA[arXiv:2405.20994v1 公告类型：新
摘要：我们介绍了捷克语点击网页排名数据集 CWRCzech，这是一个 100M 查询文档捷克语点击数据集，用于相关性排名，其用户行为数据来自 Seznam.cz 的搜索引擎日志。据我们所知，CWRCzech 是迄今为止发布的最大的原始文本点击数据集。它提供了搜索结果中的文档位置以及有关用户行为的信息：2760 万个点击文档和 1080 万个停留时间。此外，我们还发布了一个手动注释的捷克语相关性任务测试，其中包含近 50k 个查询文档对，每个对至少由 2 名注释者注释。最后，我们分析了用户行为数据如何改善相关性排名，并表明在足够规模上自动利用的数据上训练的模型可以超越在人工注释数据上训练的模型的性能。 CWRCzech 是在学术非商业许可下发布的，研究社区可以通过 https://github.com/seznam/CWRCzech 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.20994</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>通过变分自动编码器实现信息最大化以实现跨域推荐</title>
      <link>https://arxiv.org/abs/2405.20710</link>
      <description><![CDATA[arXiv:2405.20710v1 公告类型：新
摘要：跨域顺序推荐（CDSR）方法旨在解决单域顺序推荐（SDSR）中存在的数据稀疏性和冷启动问题。现有的 CDSR 方法通常依赖于重叠用户，设计复杂的跨域模块来捕获可以跨不同域传播的用户潜在兴趣。然而，它们传播的信息仅限于重叠用户和具有丰富历史行为记录的用户。因此，这些方法在大多数用户不重叠（冷启动）和长尾的现实场景中往往表现不佳。在这项研究中，我们引入了一个新的 CDSR 框架，称为信息最大化变分自动编码器（\textbf{\texttt{IM-VAE}}）。在这里，我们建议使用伪序列生成器来增强下游细粒度 CDSR 模型的用户交互历史输入，以缓解冷启动问题。我们还提出了一个生成推荐框架，该框架结合了三个受相互信息最大化 (MIM) 理论 \cite{mcgill1954multivariate} 启发的正则化器，以捕捉跨域共享的用户兴趣与特定于某些域的兴趣之间的语义差异，并解决用户实际交互序列与生成的伪序列之间的信息差距。据我们所知，本文是第一篇考虑开放世界推荐场景中伪序列信息解缠和去噪的 CDSR 工作。实证实验表明，\texttt{IM-VAE} 在两个现实世界跨域数据集上对各种用户（包括冷启动用户和尾部用户）的表现均优于最先进的方法，证明了 \texttt{IM-VAE} 在开放世界推荐中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.20710</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>流行度感知对齐与对比，以减轻流行度偏差</title>
      <link>https://arxiv.org/abs/2405.20718</link>
      <description><![CDATA[arXiv:2405.20718v1 公告类型：新 
摘要：由于现实世界数据集中项目分布不均，协同过滤 (CF) 通常面临流行度偏差的重大挑战。这种偏差导致流行和不流行项目之间存在显着的准确性差距。它不仅妨碍了准确的用户偏好理解，而且加剧了推荐系统中的马太效应。为了缓解流行度偏差，现有的努力集中在强调不受欢迎的项目或分离项目表示与其流行度之间的相关性。尽管有效，但现有工作仍然面临两个持续的挑战：（1）如何从流行项目中提取共同的监督信号以改进不受欢迎的项目表示，以及（2）如何缓解流行度偏差造成的表示分离。在这项工作中，我们对流行度偏差进行了实证分析，并提出了流行度感知对齐和对比 (PAAC) 来解决两个挑战。具体来说，我们使用在流行商品表示中建模的常见监督信号，并提出一种新颖的流行度感知监督对齐模块来学习不受欢迎的商品表示。此外，我们建议重新加权对比学习损失，以从流行度中心的角度缓解表示分离。最后，我们通过在三个真实数据集上进行大量实验，验证了 PAAC 在缓解流行度偏差方面的有效性和合理性。我们的代码可在 https://github.com/miaomiao-cai2/KDD2024-PAAC 上找到。]]></description>
      <guid>https://arxiv.org/abs/2405.20718</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>因果蒸馏可缓解推荐系统中的性能异质性</title>
      <link>https://arxiv.org/abs/2405.20626</link>
      <description><![CDATA[arXiv:2405.20626v1 公告类型：新
摘要：推荐性能通常呈现用户的长尾分布——一小部分头部用户享受到比其他用户更准确的推荐服务。我们揭示了这种性能异质性问题的两个来源：历史交互的不均匀分布（自然来源）；推荐模型的偏差训练（模型来源）。由于解决这个问题不能牺牲整体性能，明智的选择是在保持自然异质性的同时消除模型偏差。去偏差训练的关键在于消除影响用户历史行为和下一次行为的混杂因素的影响。新兴的因果推荐方法通过对用户行为之间的因果关系进行建模来实现这一点，但可能会忽略实践中难以衡量的未观察到的混杂因素（例如，朋友建议）。为了解决未观察到的混杂因素，我们借助因果理论中的前门调整（FDA），并提出了一个因果多教师蒸馏框架（CausalD）。 FDA 需要适当的中介变量来估计历史行为对下一个行为的因果影响。为此，我们为 CausalD 配备了多个异构推荐模型来建模中介变量分布。然后，FDA 估计的因果效应是推荐预测对中介变量分布和历史行为先验分布的期望，这在技术上是通过多教师集成实现的。为了追求高效的推理，CausalD 进一步将多位教师提炼为一个学生模型，以直接推断因果效应并提出建议。]]></description>
      <guid>https://arxiv.org/abs/2405.20626</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型增强长尾用户和项目的顺序推荐</title>
      <link>https://arxiv.org/abs/2405.20646</link>
      <description><![CDATA[arXiv:2405.20646v1 公告类型：新
摘要：顺序推荐系统 (SRS) 旨在根据用户过去的互动预测用户的后续偏好，并已应用于电子商务和社交网络平台等各个领域。然而，由于大多数用户只与有限数量的商品互动，而大多数商品很少被消费，因此实际的 SRS 遇到了挑战。这些挑战被称为长尾用户和长尾商品困境，通常会给传统的 SRS 方法带来障碍。缓解这些挑战至关重要，因为它们会显著影响用户满意度和业务盈利能力。虽然一些研究工作已经缓解了这些问题，但它们仍在努力解决由于互动稀缺而导致的跷跷板或噪音等问题。大型语言模型 (LLM) 的出现为从语义角度解决这些挑战提供了一条有希望的途径。在本研究中，我们引入了用于顺序推荐的大型语言模型增强框架 (LLM-ESR)，该框架利用 LLM 中的语义嵌入来增强 SRS 性能，而不会增加计算开销。为了应对长尾项目挑战，我们提出了一种双视图建模方法，将来自 LLM 的语义信息与来自传统 SRS 的协作信号融合在一起。为了应对长尾用户挑战，我们引入了一种检索增强自蒸馏技术，通过整合来自相似用户的更丰富的交互数据来改进用户偏好表示。通过使用三种广泛使用的 SRS 模型在三个真实数据集上进行的全面实验，我们提出的增强框架与现有方法相比表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.20646</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐的知识增强型多意图转换器网络</title>
      <link>https://arxiv.org/abs/2405.20565</link>
      <description><![CDATA[arXiv:2405.20565v1 公告类型：新 
摘要：将知识图谱纳入推荐系统引起了业界越来越多的关注，因为知识图谱在为底层模型提供丰富的补充信息和可解释性方面具有巨大潜力。然而，简单地将知识图谱集成到推荐系统中通常会给业界带来负面反馈，这是因为忽略了以下两个因素：i）用户的多种意图，这涉及知识图谱中的不同节点。例如，在电子商务场景中，用户可能会表现出对特定款式、品牌或颜色的偏好。ii）知识噪音，这是知识增强推荐 (KGR) 中普遍存在的问题，在行业场景中更为严重。与不包含知识的方法相比，项目的不相关知识属性可能会导致模型性能较差。为了应对这些挑战，我们提出了一种新方法，即用于推荐的知识增强多意图转换器网络（KGTN），包括两个主要模块：基于图转换器的全局意图建模和意图下的知识对比去噪。具体而言，基于图转换器的全局意图专注于捕获可学习的用户意图，通过使用图转换器结合来自用户-项目-关系-实体交互的全局信号，同时学习意图感知的用户/项目表示。意图下的知识对比去噪致力于学习精确而鲁棒的表示。它利用意图感知表示来采样相关知识，并提出一种局部-全局对比机制来增强与噪声无关的表示学习。在基准数据集上进行的大量实验表明，我们提出的方法优于最先进的方法。阿里巴巴大规模工业推荐平台上的在线 A/B 测试结果也表明了 KGTN 在真实场景中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.20565</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:53 GMT</pubDate>
    </item>
    </channel>
</rss>