<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 29 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>EHR-SeqSQL：用于交互式探索电子健康记录的顺序文本到 SQL 数据集</title>
      <link>https://arxiv.org/abs/2406.00019</link>
      <description><![CDATA[arXiv:2406.00019v2 公告类型：replace-cross 
摘要：在本文中，我们介绍了 EHR-SeqSQL，这是一种用于电子健康记录 (EHR) 数据库的新型顺序文本到 SQL 数据集。EHR-SeqSQL 旨在解决文本到 SQL 解析中关键但尚未充分探索的方面：交互性、组合性和效率。据我们所知，EHR-SeqSQL 不仅是最大的，也是第一个包含顺序和上下文问题的医学文本到 SQL 数据集基准。我们提供了数据分割和旨在评估组合泛化能力的新测试集。我们的实验证明了多轮方法在学习组合性方面优于单轮方法。此外，我们的数据集将特制的标记集成到 SQL 查询中以提高执行效率。借助 EHR-SeqSQL，我们旨在弥合文本到 SQL 领域的实际需求与学术研究之间的差距。 EHR-SeqSQL 可通过 \href{https://github.com/seonhee99/EHR-SeqSQL}{此 https URL} 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.00019</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:35 GMT</pubDate>
    </item>
    <item>
      <title>从视觉语言模型角度评估图像文本检索基准的脆弱性</title>
      <link>https://arxiv.org/abs/2407.15239</link>
      <description><![CDATA[arXiv:2407.15239v2 公告类型：replace-cross 
摘要：图像文本检索 (ITR) 是信息检索 (IR) 中的一项重要任务，由预训练的视觉语言模型 (VLM) 驱动，这些模型始终能够实现最先进的性能。然而，一个重大挑战在于现有 ITR 基准的脆弱性。在该任务的标准数据集中，标题通常提供场景的广泛摘要，而忽略了有关特定概念的详细信息。此外，当前的评估设置假设图像和文本之间存在简单的二元匹配，并且侧重于模态内关系而不是跨模态关系，这可能导致对模型性能的误解。受此差距的启发，在本研究中，我们专注于检查 ITR 评估流程的脆弱性，重点关注概念粒度。我们首先分析两个常见的基准，MS-COCO 和 Flickr30k，并将它们与增强版本 MS-COCO-FG 和 Flickr30k-FG 进行比较，给定一组指定的捕捉概念粒度的语言特征。我们发现 Flickr30k-FG 和 MS COCO-FG 在所有选定的特征上始终获得更高的分数。为了研究 VLM 在粗粒度和细粒度数据集上的性能，我们引入了扰动的分类。我们将这些扰动应用于选定的数据集。我们在零样本条件下在标准和细粒度数据集上评估了四种最先进的模型 - ALIGN、AltCLIP、CLIP 和 GroupViT，分别在应用和不应用扰动的情况下进行评估。结果表明，虽然扰动通常会降低模型性能，但细粒度数据集的性能下降幅度小于标准数据集。此外，所有设置中的相对性能下降在所有模型和数据集中都是一致的，这表明问题出在基准测试中。我们在论文的最后提出了改进 ITR 评估流程的议程。]]></description>
      <guid>https://arxiv.org/abs/2407.15239</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:35 GMT</pubDate>
    </item>
    <item>
      <title>训练期间我们真的需要图卷积吗？用于高效推荐的轻量级训练后 Graph-ODE</title>
      <link>https://arxiv.org/abs/2407.18910</link>
      <description><![CDATA[arXiv:2407.18910v1 公告类型：交叉 
摘要：图卷积网络 (GCN) 在训练推荐系统 (RecSys) 中的效率和可扩展性一直是人们关注的问题，阻碍了它们在实际应用中的部署。本文对训练阶段图卷积的必要性进行了严格的审查，并介绍了一种创新的替代方案：轻量级后训练图常微分方程 (LightGODE)。我们的调查显示，GCN 的好处在测试期间比在训练期间更为明显。受此启发，LightGODE 采用了一种新颖的后训练图卷积方法，该方法绕过了 GCN 的计算密集型消息传递，并采用非参数连续图常微分方程 (ODE) 来动态建模节点表示。这种方法大大缩短了训练时间，同时实现了细粒度的训练后图卷积，从而避免了原始训练嵌入空间的扭曲，即所谓的嵌入差异问题。我们在几个不同规模的真实数据集上验证了我们的模型，结果表明 LightGODE 不仅在效率和有效性方面优于基于 GCN 的模型，而且还显著缓解了通常与更深的图卷积层相关的嵌入差异。我们的 LightGODE 挑战了 RecSys 训练中的主流范式，并建议重新评估图卷积的作用，从而有可能指导未来高效的大规模基于图的 RecSys 的发展。]]></description>
      <guid>https://arxiv.org/abs/2407.18910</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:34 GMT</pubDate>
    </item>
    <item>
      <title>AMIR：自动反驳错误信息——基于 COVID-19 疫苗接种数据集的推荐系统</title>
      <link>https://arxiv.org/abs/2310.19834</link>
      <description><![CDATA[arXiv:2310.19834v2 公告类型：replace-cross 
摘要：近年来，虚假信息已成为一种主要的社会威胁；特别是在 COVID-19 大流行的背景下，它造成了严重破坏，例如，加剧了人们对疫苗的犹豫。当务之急是制定具有成本效益、可扩展的打击虚假信息的解决方案。这项工作探讨了如何利用从社交媒体获取的现有信息，并通过更多经过精心策划的事实核查数据存储库进行扩充，以促进大规模自动反驳虚假信息。虽然本文中的想法可以推广并重新应用于更广泛的虚假信息缓解背景下，使用多种信息源并迎合各种社交媒体平台，但这项工作只是概念证明，因此，它的范围仅限于对推文的反驳，以及在有关 COVID-19 的虚假信息的特定背景下。它利用了两个公开可用的数据集，即FaCov（经过事实核查的文章）和有关 COVID-19 疫苗接种的误导性（社交媒体 Twitter）数据。]]></description>
      <guid>https://arxiv.org/abs/2310.19834</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:34 GMT</pubDate>
    </item>
    <item>
      <title>解码知识主张：通过语义分析评估科学出版物的贡献</title>
      <link>https://arxiv.org/abs/2407.18646</link>
      <description><![CDATA[arXiv:2407.18646v1 公告类型：交叉 
摘要：科学出版物的激增对使用出版物数量作为科学进步的衡量标准提出了挑战，需要采用其他指标来强调科学贡献的质量和新颖性，而不是单纯的数量。本文提出使用放松词移动距离 (RWMD)，一种语义文本相似性度量，来评估科学论文的新颖性。我们假设 RWMD 可以更有效地衡量科学知识的增长。为了检验这一假设，我们应用 RWMD 来评估开创性论文，以 Hirsch 的 H-Index 论文为主要案例研究。我们将 RWMD 结果分为三组：1) H-Index 相关论文、2) 科学计量学研究和 3) 不相关论文，旨在辨别冗余文献和炒作与真正的创新。研究结果表明，强调知识主张可以更深入地了解科学贡献，标志着 RWMD 成为传统引用指标的一种有前途的替代方法，从而更好地追踪重大的科学突破。]]></description>
      <guid>https://arxiv.org/abs/2407.18646</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>AutoRDF2GML：促进图形机器学习中的 RDF 集成</title>
      <link>https://arxiv.org/abs/2407.18735</link>
      <description><![CDATA[arXiv:2407.18735v1 公告类型：交叉 
摘要：在本文中，我们介绍了 AutoRDF2GML，这是一个旨在将 RDF 数据转换为针对图形机器学习任务定制的数据表示的框架。AutoRDF2GML 首次实现了基于内容的特征（即基于 RDF 数据类型属性的特征）和基于拓扑的特征（即基于 RDF 对象属性的特征）的创建。AutoRDF2GML 以自动特征提取为特点，即使不太熟悉 RDF 和 SPARQL 的用户也可以生成可用于图形机器学习任务（例如链接预测、节点分类和图形分类）的数据表示。此外，我们提出了四个新的图形机器学习基准数据集，这些数据集是使用我们的框架从大型 RDF 知识图创建的。这些数据集是评估图形机器学习方法（例如图形神经网络）的宝贵资源。总的来说，我们的框架有效地弥合了图形机器学习和语义网社区之间的差距，为基于 RDF 的机器学习应用铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2407.18735</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>使用文献计量学检测非常规作者实践并研究其对全球研究指标的影响，2019-2023 年</title>
      <link>https://arxiv.org/abs/2407.18331</link>
      <description><![CDATA[arXiv:2407.18331v1 公告类型：交叉 
摘要：2019 年至 2023 年间，16 所大学的研究产出增长了全球平均水平的 15 倍以上，同时作者动态也发生了重大变化（例如，第一作者减少、高产作者增加、多机构作者增加以及每篇出版物作者率增加）。本研究使用文献计量方法，发现了一些模式，表明人们依赖非常规的作者身份实践（例如赠予、荣誉和出售作者身份）来夸大出版指标。该研究强调，大学、政策制定者、资助机构、排名机构、认证机构、学术出版商和研究人员需要进行改革，以维护学术诚信并确保全球排名系统的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2407.18331</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>构建 CORD-19 疫苗数据集</title>
      <link>https://arxiv.org/abs/2407.18471</link>
      <description><![CDATA[arXiv:2407.18471v1 公告类型：交叉 
摘要：我们引入了新的数据集“CORD-19-Vaccination”，以满足专门研究 COVID-19 疫苗相关研究的科学家的需求。该数据集是从 CORD-19 数据集 [Wang et al., 2020] 中提取的，并增加了语言详细信息、作者人口统计、关键字和每篇论文主题的新列。Facebook 的 fastText 模型用于识别语言 [Joulin et al., 2016]。为了建立作者人口统计（作者隶属关系、实验室/机构位置和实验室/机构国家列），我们处理了每篇论文的 JSON 文件，然后使用 Google 的搜索 API 进一步增强以确定国家/地区值。&#39;Yake&#39; 用于从每篇论文的标题、摘要和正文中提取关键字，并使用 LDA（潜在狄利克雷分配）算法添加主题信息 [Campos et al., 2020, 2018a,b]。为了评估数据集，我们演示了一个问答任务，类似于 CORD-19 Kaggle 挑战赛中使用的任务 [Goldbloom et al., 2022]。为了进一步评估，使用 Dernoncourt et al. [2016] 的模型对每篇论文的摘要进行了顺序句子分类。我们对训练数据集进行了部分手动注释，并使用了预先训练的 BERT-PubMed 层。&#39;CORD-19-Vaccination&#39; 包含 30,000 篇研究论文，对于 NLP 研究（例如文本挖掘、信息提取和问答）非常有价值，具体到 COVID-19 疫苗研究领域。]]></description>
      <guid>https://arxiv.org/abs/2407.18471</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>一种灵活且可扩展的网上野生动物广告收集方法</title>
      <link>https://arxiv.org/abs/2407.18898</link>
      <description><![CDATA[arXiv:2407.18898v1 公告类型：新
摘要：野生动物贩运者越来越多地在网络空间开展活动。当他们在网上市场上宣传和销售野生动物产品时，他们会留下活动的数字痕迹。这创造了一个新的机会：通过分析这些痕迹，我们可以深入了解贩运网络的运作方式以及如何破坏它们。然而，收集这些信息很困难。网上市场销售大量产品，识别真正涉及野生动物的广告是一项难以自动化的复杂任务。此外，鉴于数据量惊人，我们需要可扩展的机制来获取、过滤和存储广告，并使它们可供分析。在本文中，我们提出了一种大规模收集野生动物贩运数据的新方法。我们提出了一种数据收集管道，将用于数据发现和获取的范围爬虫与基础模型和机器学习分类器相结合，以识别相关广告。我们描述了使用此管道创建的数据集，据我们所知，它是同类中最大的数据集：它包含从 41 个市场获得的近一百万个广告，涵盖 235 个物种和 20 种语言。源代码可在 \url{https://github.com/VIDA-NYU/wildlife_pipeline} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2407.18898</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>金融股票研究报告的结构——识别财务分析师报告中最常见的问题，以使用 Llama 3 和 GPT-4 实现股票研究自动化</title>
      <link>https://arxiv.org/abs/2407.18327</link>
      <description><![CDATA[arXiv:2407.18327v1 公告类型：交叉
摘要：本研究通过将金融股票研究报告 (ERR) 的内容映射到类别中来对其进行剖析。
对 ERR 中回答的问题的实证分析不足。特别是，人们不了解某些信息出现的频率、哪些信息被认为是必要的，以及哪些信息需要人类判断才能提炼成 ERR。
该研究逐句分析了 72 个 ERR，将其 4940 个句子归类为 169 个独特的问题原型。我们没有预先定义问题，而是仅从 ERR 中的陈述中得出问题。这种方法提供了对观察到的 ERR 内容的公正看法。随后，我们使用公开的公司报告对问题的自动化潜力进行分类。如果问题的答案可以在公司报告中访问，则答案被标记为“文本可提取”。
ERR 中 78.7% 的问题可以自动化。这些可自动化的问题包括 48.2% 的文本可提取问题（适合大型语言模型 (LLM) 处理）和 30.5% 的数据库可提取问题。只有 21.3% 的问题需要人类判断来回答。
我们使用 Llama-3-70B 和 GPT-4-turbo-2024-04-09 进行了实证验证，语言生成和信息提取方面的最新进展使 ERR 中大约 80% 的语句能够实现自动化。令人惊讶的是，这些模型很好地互补了彼此的优势和劣势。
研究证实，ERR 的当前编写过程可能会从额外的自动化中受益，从而提高质量和效率。因此，这项研究使我们能够量化在 ERR 编写过程中引入大型语言模型的潜在影响。
完整的问题列表（包括原型及其频率）将在同行评审后在线提供。]]></description>
      <guid>https://arxiv.org/abs/2407.18327</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>REAPER：基于推理的复杂 RAG 系统检索规划</title>
      <link>https://arxiv.org/abs/2407.18553</link>
      <description><![CDATA[arXiv:2407.18553v1 公告类型：新
摘要：复杂对话系统通常使用检索到的证据来促进事实响应。此类 RAG（检索增强生成）系统从大量异构数据存储中进行检索，这些数据存储通常被构建为多个索引或 API，而不是单个整体源。对于给定的查询，需要从一个或一小部分可能的检索源中检索相关证据。复杂查询甚至可能需要多步检索。例如，零售网站上的对话代理在回答客户有关过去订单的问题时，需要首先检索适当的客户订单，然后在订购产品的背景下检索与客户问题相关的证据。大多数 RAG 代理通过交错推理和检索步骤来处理此类思路链 (CoT) 任务。但是，每个推理步骤都会直接增加系统的延迟。对于大型模型（&gt;100B 个参数），这种延迟成本是巨大的——大约需要几秒。多代理系统可能会将查询分类到与检索源相关联的单个代理，但这意味着（小型）分类模型决定了大型语言模型的性能。在这项工作中，我们提出了 REAPER（基于 REAsoning 的 PlannER）——一种基于 LLM 的规划器，用于在对话系统中生成检索计划。与基于分类的规划相比，我们在延迟方面表现出显著的改善，并且能够轻松扩展到新的和未见过的用例。虽然我们的方法可以应用于任何 RAG 系统，但我们在 Rufus（亚马逊的对话式购物助手）的背景下展示了我们的结果。]]></description>
      <guid>https://arxiv.org/abs/2407.18553</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>人机智能协作，利用大型语言模型从数据驱动的增材制造研究中提取科学信息</title>
      <link>https://arxiv.org/abs/2407.18827</link>
      <description><![CDATA[arXiv:2407.18827v1 公告类型：新
摘要：近年来，增材制造 (AM) 的数据驱动研究取得了重大成功。这导致了大量科学文献的出现。这些作品中的知识包括尚未以综合方式挖掘和形式化的 AM 和人工智能 (AI) 背景。从这些作品中提取科学信息需要大量的精力和时间。AM 领域专家贡献了二十多篇评论论文来总结这些作品。然而，特定于 AM 和 AI 环境的信息仍然需要手动提取。BERT（Transformers 的双向编码器表示）或 GPT（生成预训练 Transformers）等基础模型在文本数据上取得的最新成功为加快科学信息提取提供了可能性。我们提出了一个框架，使 AM 和 AI 专家能够协作，从数据驱动的 AM 文献中不断提取科学信息。基于所提出的框架实现了一个演示工具，并进行了案例研究以提取与数据集、建模、传感和 AM 系统类别相关的信息。我们展示了 LLM（大型语言模型）加快从数据驱动的 AM 文献中提取相关信息的能力。将来，该框架可用于从工程学科中更广泛的设计和制造文献中提取信息。]]></description>
      <guid>https://arxiv.org/abs/2407.18827</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱与大型语言模型的协同作用：全面回顾与未来展望</title>
      <link>https://arxiv.org/abs/2407.18470</link>
      <description><![CDATA[arXiv:2407.18470v1 公告类型：新
摘要：最近的进步见证了大型语言模型 (LLM) 的崛起，它具有强大的语言能力，但也存在事实不一致和不透明等缺点。相反，知识图谱 (KG) 包含可验证的知识和符号推理能力，从而弥补了 LLM 的不足。在此背景下，KG 和 LLM 之间的协同作用成为一个关键的研究方向。我们在本文中的贡献是对 KG 与 LLM 集成的最新发展进行了全面剖析。通过对它们的汇合点和方法的细致分析，我们引入了一个统一的框架，旨在阐明和激发从事同源学科的学者的进一步探索。该框架具有双重目的：它巩固现有知识，同时勾勒出现实世界部署的新途径，从而扩大学术研究的转化影响力。]]></description>
      <guid>https://arxiv.org/abs/2407.18470</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>FedUD：利用不一致的数据进行跨平台联合点击率预测</title>
      <link>https://arxiv.org/abs/2407.18472</link>
      <description><![CDATA[arXiv:2407.18472v1 公告类型：新
摘要：点击率 (CTR) 预测在在线广告平台中起着重要作用。大多数现有方法使用来自广告平台本身的数据进行 CTR 预测。由于用户行为也存在于许多其他平台（例如媒体平台）上，因此进一步利用这些互补信息来更好地建模用户兴趣并提高 CTR 预测性能是有益的。但是，出于隐私考虑，来自不同平台的数据无法上传到服务器进行集中模型训练。垂直联邦学习 (VFL) 提供了一种可能的解决方案，它能够保留各个参与方的原始数据并以隐私保护的方式学习协作模型。然而，传统的 VFL 方法仅使用跨各方具有公共密钥的对齐数据，这严重限制了它们的应用范围。在本文中，我们提出了 FedUD，它除了能够利用对齐数据之外，还能够利用未对齐数据来实现更准确的联邦 CTR 预测。FedUD 包含两个步骤。在第一步中，FedUD 像传统的 VFL 一样利用跨方对齐的数据，但它还包括一个知识提炼模块。该模块从客户方的高级表示中提取有用的知识，并指导表示传输网络的学习。在第二步中，FedUD 应用学习到的知识来丰富主机方未对齐数据的表示，以便对齐和未对齐的数据都可以为联合模型训练做出贡献。在两个真实数据集上进行的实验证明了 FedUD 在联合 CTR 预测方面的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2407.18472</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>通过查找相关且重要的著作来支持循证医学</title>
      <link>https://arxiv.org/abs/2407.18383</link>
      <description><![CDATA[arXiv:2407.18383v1 公告类型：新
摘要：在本文中，我们提出了一种提高医学 IR 相关性和可靠性的新方法，该方法建立在证据水平 (LoE) 的概念之上。LoE 框架根据底层经验证据将医学出版物分为 7 个不同的级别。尽管 LoE 框架与医学研究和循证实践相关，但只有少数医学出版物明确说明了其 LoE。因此，我们开发了一个分类模型，用于自动将 LoE 分配给医学出版物，该模型成功地将 MEDLINE 数据库中的 2600 多万份文档分类为 LoE 类。随后在 TREC PM 数据集上进行的检索实验表明，当使用 LoE 作为搜索过滤器时，检索相关性有显着提高。]]></description>
      <guid>https://arxiv.org/abs/2407.18383</guid>
      <pubDate>Mon, 29 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    </channel>
</rss>