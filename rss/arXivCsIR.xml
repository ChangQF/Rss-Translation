<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 29 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用语言模型进行人类水平的预测</title>
      <link>https://arxiv.org/abs/2402.18563</link>
      <description><![CDATA[arXiv:2402.18563v1 公告类型：交叉
摘要：预测未来事件对于政策和决策非常重要。在这项工作中，我们研究语言模型（LM）是否可以达到与人类预测者竞争的水平。为了实现这一目标，我们开发了一种检索增强的 LM 系统，旨在自动搜索相关信息、生成预测和聚合预测。为了促进我们的研究，我们从竞争性预测平台收集了大量问题数据集。根据 LM 知识截止后发布的测试集，我们根据人类预测的汇总来评估我们系统的端到端性能。平均而言，该系统接近竞争性预测者的人群总数，并且在某些情况下甚至超过了它。我们的工作表明，使用语言模型来预测未来可以提供大规模的准确预测，并有助于为机构决策提供信息。]]></description>
      <guid>https://arxiv.org/abs/2402.18563</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>通过挖掘和评估媒体报道数据对公司进行自动 ESG 评估：NLP 方法和工具</title>
      <link>https://arxiv.org/abs/2212.06540</link>
      <description><![CDATA[arXiv:2212.06540​​v2 公告类型：替换
摘要：背景：可持续的企业行为越来越受到社会的重视，并影响企业声誉和客户信任。因此，公司定期发布可持续发展报告，以阐明其对环境、社会和治理（ESG）因素的影响。问题：可持续发展报告是由公司自己撰写的，因此被视为公司控制的来源。相反，研究表明非企业渠道（例如媒体报道）是 ESG 透明度的主要驱动力。然而，分析有关 ESG 因素的媒体报道具有挑战性，因为 (1) 发表的新闻文章数量每天都在增长，(2) 媒体报道数据不一定涉及 ESG 相关主题，这意味着必须仔细过滤它，并且 ( 3）大多数媒体报道数据是非结构化的。研究目标：我们的目标是自动从文本媒体反应中提取 ESG 相关信息，以计算给定公司的 ESG 分数。我们的目标是降低 ESG 数据收集成本，并将 ESG 信息向公众开放。贡献：我们的贡献有三方面：首先，我们发布了包含 432,411 个新闻标题的语料库，这些新闻标题被注释为与环境、治理、社会相关或 ESG 无关。其次，我们提出了名为 ESG-Miner 的工具支持方法，能够自动分析和评估企业 ESG 绩效的头条新闻。第三，我们在实验中证明了我们的方法的可行性，并将 ESG-Miner 应用于 3000 个手动标记的标题。我们的方法正确处理了 96.7% 的标题，并且在检测与环境相关的标题及其正确情绪方面表现出了出色的性能。我们鼓励其他研究人员和从业者使用 ESG-Miner：https://www.esg-miner.com。]]></description>
      <guid>https://arxiv.org/abs/2212.06540</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>安全协同过滤</title>
      <link>https://arxiv.org/abs/2306.05292</link>
      <description><![CDATA[arXiv:2306.05292v2 公告类型：替换
摘要：出色的尾部性能对于算法公平性、类别不平衡和风险敏感决策等现代机器学习任务至关重要，因为它确保有效处理数据集中具有挑战性的样本。尾部性能也是个性化推荐系统成功的重要决定因素，以降低失去低满意度用户的风险。本研究引入了一种“安全”的协同过滤方法，该方法优先考虑不太满意的用户的推荐质量，而不是关注平均性能。我们的方法最大限度地降低了条件风险价值（CVaR），它代表了用户损失尾部的平均风险。为了克服网络规模推荐系统的计算挑战，我们开发了一种强大而实用的算法，该算法扩展了最具可扩展性的方法，即隐式交替最小二乘法（iALS）。对现实世界数据集的实证评估证明了我们的方法具有出色的尾部性能，同时保持了有竞争力的计算效率。]]></description>
      <guid>https://arxiv.org/abs/2306.05292</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>使用多个基于消息的网络表示检测 Twitter 上的反疫苗内容</title>
      <link>https://arxiv.org/abs/2402.18335</link>
      <description><![CDATA[arXiv:2402.18335v1 公告类型：交叉
摘要： Twitter 等社交媒体平台通过转发和回复的概念，在促进在线思想传播和讨论方面发挥着基础作用。然而，这些特征也导致了在 COVID-19 大流行疫苗推出期间错误/虚假信息的传播。使用 COVID-19 疫苗作为案例研究，我们根据一组已知的反疫苗标签和关键词，分析了 Twitter 上三种基于消息的交互（引用转发、提及和回复）衍生的多种社交网络表征。每个网络代表一个特定的标签或关键词，根据一小群参与者的说法，这些标签或关键词被标记为“有争议的”和“无争议的”。对于每个网络，我们提取基于全局和局部网络的度量的组合，将其用作二元分类的特征向量。我们的结果表明，使用简单的基于网络的指标可以高精度地从无争议术语中检测出有争议的术语。此外，这些结果证明了网络表示作为与语言无关的模型的潜力，可以大规模检测错误/虚假信息，无论内容如何，​​跨多个社交媒体平台。]]></description>
      <guid>https://arxiv.org/abs/2402.18335</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>用于极端分类的图正则编码器训练</title>
      <link>https://arxiv.org/abs/2402.18434</link>
      <description><![CDATA[arXiv:2402.18434v1 公告类型：交叉
摘要：深度极限分类（XC）旨在训练编码器架构和随附的分类器架构，以使用来自大量标签的最相关的标签子集来标记数据点。 XC 在排名、推荐和标记中的应用经常会遇到训练数据量极小的尾部标签。图卷积网络（GCN）提供了一种方便但计算成本昂贵的方法来利用任务元数据并提高这些设置中的模型精度。本文正式证明，在几个用例中，通过用非 GCN 架构替换 GCN 完全可以避免 GCN 的巨大计算成本。论文指出，在这些设置中，使用图数据来规范编码器训练比实现 GCN 更有效。基于这些见解，提出了一种替代范例 RAMEN，以在 XC 设置中利用图形元数据，从而在推理计算成本零增加的情况下提供显着的性能提升。 RAMEN 可扩展到具有多达 100 万个标签的数据集，并且在基准数据集上提供的预测精度比最先进的方法（包括使用图元数据训练 GCN 的方法）高出 15%。 RAMEN 在源自流行搜索引擎点击日志的专有推荐数据集上的准确度比最佳基线高出 10%。 RAMEN 的代码将公开发布。]]></description>
      <guid>https://arxiv.org/abs/2402.18434</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>用于检索增强生成的大型语言模型的无监督信息细化训练</title>
      <link>https://arxiv.org/abs/2402.18150</link>
      <description><![CDATA[arXiv:2402.18150v1 公告类型：交叉
摘要：检索增强生成（RAG）通过合并检索中的附加信息来增强大型语言模型（LLM）。然而，研究表明，法学硕士在有效利用检索到的信息方面仍然面临挑战，甚至忽视它或被它误导。关键原因是法学硕士的培训并没有明确让法学硕士学会如何利用不同质量的输入检索文本。在本文中，我们提出了一个新颖的视角，将 RAG 中的法学硕士的角色视为“信息提炼者”，这意味着无论检索到的文本的正确性、完整性或有用性如何，法学硕士都可以始终如一地将知识整合到检索到的文本中，并且模型参数来生成比检索到的文本更简洁、准确和完整的文本。为此，我们提出了一种名为 InFO-RAG 的信息细化训练方法，以无监督的方式优化 RAG 的 LLM。 InFO-RAG 成本低廉，并且适用于各种任务。在问答、槽填充、语言建模、对话和代码生成等不同任务中对 11 个数据集进行零样本预测的大量实验表明，InFO-RAG 将 LLaMA2 的性能平均提高了 9.39% 相对点。 InFO-RAG 还显示了 RAG 的上下文学习和鲁棒性方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2402.18150</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>砍掉头部结束冲突：解释和缓解语言模型中知识冲突的机制</title>
      <link>https://arxiv.org/abs/2402.18154</link>
      <description><![CDATA[arXiv:2402.18154v1 公告类型：交叉
摘要：最近，检索增强和工具增强已经证明了通过提供外部上下文来扩展语言模型（LM）内部记忆边界的卓越能力。然而，内部记忆和外部环境不可避免地发生冲突，导致语言模型内部的知识冲突。本文旨在通过信息流的视角解读知识冲突的机制，进而通过关键点的精准干预来缓解冲突。我们发现在后面的层中有一些具有相反效果的注意力头，其中记忆头可以从内部记忆中回忆知识，上下文头可以从外部上下文中检索知识。此外，我们揭示了 LM 中出现知识冲突的关键点是记忆头和上下文头不一致的信息流的整合。受这些见解的启发，我们提出了一种名为 Pruning Head via PathH PatchHing (PH3) 的新方法，它可以通过修剪冲突的注意力头而无需更新模型参数来有效地缓解知识冲突。 PH3可以灵活控制8个LM使用内部存储器（$\uparrow$ 44.0%）或外部上下文（$\uparrow$ 38.5%）。此外，PH3 还可以提高 LM 在开放域 QA 任务上的性能。我们还进行了广泛的实验来证明我们的方法的跨模型、交叉关系和跨格式泛化。]]></description>
      <guid>https://arxiv.org/abs/2402.18154</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>使用自然逻辑进行信息检索和合成的复杂性类别的分类</title>
      <link>https://arxiv.org/abs/2402.18566</link>
      <description><![CDATA[arXiv:2402.18566v1 公告类型：新
摘要：鉴于大型语言模型的新兴推理能力，信息检索变得越来越复杂。现代信息检索系统不仅仅是检索文档，还宣称它们可以根据潜在的许多不同文档、冲突的数据源和使用推理来合成答案。但是，不同类型的问题有不同的答案，不同的答案有不同的复杂性。在本文中，我们介绍了一种基于自然演绎演算的新颖框架，用于分析问题答案的复杂性，如 Prawitz (1965) 中提出的。我们的框架是新颖的，因为据我们所知，没有人使用这种逻辑作为复杂性类别的基础，而且也没有其他现有的复杂性类别使用任何类似的方法来描述。我们确定了三个可判定的片段，特别是称为前向片段、查询片段和计划片段，并将其与证明完整的一阶微积分所需的片段进行比较，而众所周知，一阶微积分的定理证明是不可判定的。]]></description>
      <guid>https://arxiv.org/abs/2402.18566</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>JMLR：联合医学法学硕士和检索培训，增强推理和专业问答能力</title>
      <link>https://arxiv.org/abs/2402.17887</link>
      <description><![CDATA[arXiv:2402.17887v1 公告类型：交叉
摘要：随着医疗数据的爆发式增长和人工智能技术的快速发展，精准医疗已成为提升医疗服务质量和效率的关键。在这种背景下，大型语言模型（LLM）在医学知识获取和问答系统中发挥着越来越重要的作用。为了进一步提高这些系统在医学领域的性能，我们引入了一种创新方法，在微调阶段联合训练信息检索（IR）系统和法学硕士。这种方法，我们称之为联合医学法学硕士和检索训练（JMLR），旨在克服传统模型在处理医学问答任务时面临的挑战。通过采用同步训练机制，JMLR 减少了对计算资源的需求，并增强了模型利用医学知识进行推理和回答问题的能力。我们的实验结果表明，JMLR-13B（Amboos 上为 81.2%，MedQA 上为 61.3%）优于使用传统预训练和微调 Meditron-70B 的模型（AMBOSS 上为 76.4%，MedQA 上为 60.3%）。对于相同 7B 规模的模型，JMLR-7B（Amboos 上为 68.7%，MedQA 上为 51.7%）显着优于其他公共模型（Meditron-7B：50.1%、47.9%），证明了其在成本（我们的训练时间）方面的优越性：37小时，传统方法：144小时），医疗问答任务的效率和效果。通过这项工作，我们为医疗保健提供了一种新的、高效的知识增强工具，展示了将 IR 和 LLM 培训整合到精准医疗信息检索和问答系统中的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.17887</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>基于语言模型的本体新概念放置框架</title>
      <link>https://arxiv.org/abs/2402.17897</link>
      <description><![CDATA[arXiv:2402.17897v1 公告类型：交叉
摘要：我们研究使用语言模型将从文本中提取的新概念插入到本体中的任务。我们探索了一种包含三个步骤的方法：边缘搜索，即找到一组要插入的候选位置（即概念之间的包含），边缘形成和丰富，利用本体结构来生成和增强边缘候选，以及边缘选择最终找到要放入的边缘。在所有步骤中，我们建议利用神经方法，其中我们应用基于嵌入的方法和与预训练语言模型（PLM）的对比学习，例如用于边缘搜索的 BERT，并采用基于 BERT 微调的多标签边缘- 交叉编码器和大型语言模型 (LLM)，例如 GPT 系列、FLAN-T5 和 Llama 2，用于边缘选择。我们评估了使用 SNOMED CT 本体和 MedMentions 实体链接基准创建的最新数据集的方法。我们框架中的最佳设置使用经过微调的 PLM 进行搜索，并使用多标签交叉编码器进行选择。 LLM 的零样本提示仍然不足以完成任务，我们提出了 LLM 的可解释指令调整以提高性能。我们的研究展示了 PLM 的优势，并强调了 LLM 令人鼓舞的表现，这激励了未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.17897</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>基于大语言模型的代理平台的个性化推荐前景</title>
      <link>https://arxiv.org/abs/2402.18240</link>
      <description><![CDATA[arXiv:2402.18240v1 公告类型：新
摘要：以GPT为代表的新型面向Agent的信息系统，促使我们审视信息系统基础设施，以支持Agent级的信息处理，并适应基于大语言模型（LLM）的Agent的特点，例如互动性。在这项工作中，我们展望了基于 LLM 的 Agent 平台上推荐系统的前景，并引入了一种名为 Rec4Agentverse 的新颖推荐范式，由 Agent Items 和 Agent Recommender 组成。 Rec4Agentverse强调Agent Items和Agent Recommender之间的协作，从而促进个性化信息服务并增强传统用户推荐反馈循环之外的信息交换。此外，我们展望了 Rec4Agentverse 的演变，并将其概念化为基于 Agent Item、Agent Recommender 和用户之间交互和信息交换增强的三个阶段。一项涉及 Rec4Agentverse 多个案例的初步研究验证了其巨大的应用潜力。最后，我们讨论了未来研究的潜在问题和有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2402.18240</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>DynaWarp——高效、大规模的日志存储和检索</title>
      <link>https://arxiv.org/abs/2402.18355</link>
      <description><![CDATA[arXiv:2402.18355v1 公告类型：新
摘要：现代大型监控系统必须近乎实时地处理和存储大量日志数据。在查询时，系统必须使用支持结构根据日志消息的内容查找相关日志，这些支持结构可以扩展到这些数据量，同时仍然可以高效使用。我们展示了新颖的 DynaWarp 成员资格草图，能够回答多集多成员资格查询，可以用作流日志数据现有索引结构的替代方案。在我们的实验中，DynaWarp 所需的存储空间比测试的最先进的倒排索引减少了 93%，并且与测试的最先进的隶属草图相比，误报率减少了四个数量级。此外，DynaWarp 的查询吞吐量比测试的倒排索引高出 250 倍，查询吞吐量比测试的成员资格草图高出 240 倍。]]></description>
      <guid>https://arxiv.org/abs/2402.18355</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行语料库引导的查询扩展</title>
      <link>https://arxiv.org/abs/2402.18031</link>
      <description><![CDATA[arXiv:2402.18031v1 公告类型：新
摘要：最近的研究表明，大型语言模型（LLM）生成的查询扩展可以通过生成以扩展形式回答查询的假设文档来显着增强信息检索系统。然而，扩展和检索语料库之间的错位带来了挑战，由于法学硕士内在知识有限，导致出现幻觉和过时信息等问题。受伪相关性反馈（PRF）的启发，我们引入了语料库引导查询扩展（CSQE）来促进语料库中嵌入的知识的合并。 CSQE利用LLM的相关性评估能力来系统地识别最初检索的文档中的关键句子。这些源自语料库的文本随后与法学硕士知识支持的扩展一起用于扩展查询，从而改进查询和目标文档之间的相关性预测。大量实验表明，CSQE 无需任何培训即可表现出强大的性能，特别是对于法学硕士缺乏知识的查询。]]></description>
      <guid>https://arxiv.org/abs/2402.18031</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的序列级语义表示融合</title>
      <link>https://arxiv.org/abs/2402.18166</link>
      <description><![CDATA[arXiv:2402.18166v1 公告类型：新
摘要：随着推荐系统的快速发展，可以用来提高推荐性能的辅助信息越来越多。特别地，我们重点关注项目（例如产品标题）相关 \emph{文本数据} 的利用，并研究如何在顺序推荐中将文本特征与 ID 特征有效地融合。然而，两种项目特征存在不同的数据特​​征，使得直接融合方法（例如添加文本和ID嵌入作为项目表示）变得不太有效。为了解决这个问题，我们提出了一种新颖的 {\ul \emph{Te}}xt-I{\ul \emph{D}} 语义融合方法，用于顺序 {\ul \emph{Rec}} 推荐，即 \textbf{ \我们的}。我们方法的核心思想是通过更好地集成全局上下文来进行序列级语义融合方法。关键策略在于我们通过傅里叶变换将文本嵌入和 ID 嵌入从 \emph{时域} 转换为 \emph{频域}。在频域中，原始序列的全局顺序特征本质上聚合到变换后的表示中，因此我们可以采用简单的乘法运算来有效地融合两种项目特征。我们的融合方法可以被证明具有与上下文卷积相同的效果，从而实现序列级语义融合。为了进一步提高融合性能，我们建议通过专家混合（MoE）调制方法自适应地注入位置信息，从而增强文本编码器中文本嵌入的可区分性。我们的实现可以在这个存储库中找到：\textcolor{magenta}{\url{https://github.com/RUCAIBox/TedRec}}。]]></description>
      <guid>https://arxiv.org/abs/2402.18166</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[RE] 为下一个购物篮推荐建立个性化商品频率信息模型</title>
      <link>https://arxiv.org/abs/2402.17925</link>
      <description><![CDATA[arXiv:2402.17925v1 公告类型：新
摘要：本文重点复制和扩展了论文“为下一个篮子推荐建模个性化项目频率信息”的结果，该论文引入了 TIFU-KNN 模型，并提出利用个性化项目频率（PIF）进行下一个篮子推荐（NBR） ）。我们利用了原始论文中使用的公开杂货购物数据集，并纳入了其他数据集来评估研究结果的普遍性。我们使用 Recall@K、NDCG@K、个性化命中率 (PHR) 和平均倒数排名 (MRR) 等指标评估模型的性能。此外，我们还考虑了平均购物篮大小、商品受欢迎程度和新颖性等用户特征，对公平性进行了彻底的检查。最后，我们引入了新颖的 $\beta$-VAE 架构来对 NBR 进行建模。实验结果证实，复制模型 TIFU-KNN 在各种数据集和指标上均优于基线模型“个人最高频率”。研究结果还强调了一些数据集中较小的篮子尺寸带来的挑战，并为未来提高 NBR 性能的研究提出了途径。]]></description>
      <guid>https://arxiv.org/abs/2402.17925</guid>
      <pubDate>Thu, 29 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    </channel>
</rss>