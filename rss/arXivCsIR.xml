<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 13 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 进行多文档财务问答</title>
      <link>https://arxiv.org/abs/2411.07264</link>
      <description><![CDATA[arXiv:2411.07264v1 公告类型：新
摘要：我们提出了两种新的多文档金融问答方法。首先，一种方法是使用语义标记，然后查询索引以获取上下文（RAG_SEM）。其次，一种基于知识图谱（KG_RAG）的方法，该方法使用语义标记，并从图形数据库中检索知识图谱三元组作为上下文。KG_RAG 使用使用小模型构建的知识图谱，该模型使用大型教师模型通过知识蒸馏进行微调。该数据包括 2021、2022 和 2023 年 Apple、Microsoft、Alphabet、NVIDIA、Amazon 和 Tesla 的 18 份 10K 报告。数据中的问题列表包含 111 个复杂问题，其中包括许多难以回答且答案并不完全明显的深奥问题。作为评估指标，我们使用总体得分以及分段得分进行测量，包括忠实度、相关性、正确性、相似性、基于 LLM 的总体得分和 rouge 得分以及嵌入的相似性。我们发现这两种方法都明显优于普通 RAG。KG_RAG 在九个指标中的四个方面优于 RAG_SEM。]]></description>
      <guid>https://arxiv.org/abs/2411.07264</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AdaS&S：深度推荐系统中自动嵌入大小搜索的一次性超网络方法</title>
      <link>https://arxiv.org/abs/2411.07504</link>
      <description><![CDATA[arXiv:2411.07504v1 公告类型：新
摘要：深度学习推荐模型（DLRM）利用嵌入层来表示各种分类特征。传统的 DLRM 对所有特征采用统一的嵌入大小，导致性能不佳和参数冗余。因此，许多自动嵌入大小搜索（AES）工作专注于获得具有强大模型性能的混合嵌入大小。然而，以前的 AES 工作很难同时解决几个挑战：（1）嵌入大小的搜索结果不稳定；（2）AES 结果的推荐效果不令人满意；（3）嵌入的内存成本不可控。为了应对这些挑战，我们提出了一种新颖的一次性 AES 框架 AdaS&amp;S，其中构建了一个包含各种候选嵌入的超网络，并在其中执行 AES 作为搜索网络架构。我们的框架包含两个主要阶段：在第一阶段，我们将训练参数与搜索嵌入大小分离，并提出自适应采样方法来产生训练有素的超网络，从而进一步有助于产生稳定的 AES 结果。在第二阶段，为了获得有利于模型效果的嵌入大小，我们设计了一个强化学习搜索过程，该过程利用之前训练好的超网络。同时，为了让搜索适应特定的资源约束，我们引入了资源竞争惩罚来平衡模型有效性和嵌入的内存成本。我们在公共数据集上进行了大量实验，以展示 AdaS&amp;S 的优越性。我们的方法可以将 AUC 提高约 0.3%，同时节省约 20% 的模型参数。实证分析还表明，AdaS&amp;S 中搜索结果的稳定性明显超过其他方法。]]></description>
      <guid>https://arxiv.org/abs/2411.07504</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 CTR 预测的特征交互融合自蒸馏网络</title>
      <link>https://arxiv.org/abs/2411.07508</link>
      <description><![CDATA[arXiv:2411.07508v1 公告类型：新 
摘要：点击率（CTR）预估在推荐系统、在线广告和搜索引擎中起着至关重要的作用。当前大多数方法通过堆叠或并行结构对特征交互进行建模，有些方法采用知识蒸馏进行模型压缩。然而，我们观察到这些方法的一些局限性：（1）在并行结构模型中，显式和隐式组件是独立且同时执行的，这导致特征集内的信息共享不足。（2）知识蒸馏技术的引入带来了师生框架设计复杂、知识传递效率低下的问题。（3）数据集和构建高阶特征交互的过程包含显著的噪声，限制了模型的有效性。为了解决这些限制，我们提出了 FSDNet，这是一个包含即插即用融合自蒸馏模块的 CTR 预估框架。具体而言，FSDNet 在每一层在显式和隐式特征交互之间建立连接，增强了不同特征之间的信息共享。然后使用最深的融合层作为教师模型，利用自我蒸馏来指导浅层的训练。对四个基准数据集的实证评估验证了该框架的有效性和泛化能力。代码可在 https://github.com/coder-qiu/FSDNet 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.07508</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向推荐系统的自动模型设计</title>
      <link>https://arxiv.org/abs/2411.07569</link>
      <description><![CDATA[arXiv:2411.07569v1 公告类型：新
摘要：深度学习模型的日益普及为开发基于人工智能的推荐系统创造了新的机会。使用深度神经网络设计推荐系统需要精心的架构设计，进一步的优化需要在联合优化模型架构和硬件方面进行大量的协同设计工作。设计自动化，例如自动机器学习 (AutoML)，对于充分利用推荐模型设计的潜力是必要的，包括模型选择和模型硬件协同设计策略。我们引入了一种利用权重共享来探索丰富解决方案空间的新范式。我们的范式创建了一个大型超网来搜索最佳架构和协同设计策略，以应对推荐领域中数据多模态性和异构性的挑战。从模型的角度来看，超网包括各种运算符、密集连接和维度搜索选项。从协同设计的角度来看，它包含多功能的内存处理 (PIM) 配置以生成硬件高效的模型。我们的解决方案空间的规模、异质性和复杂性带来了一些挑战，我们通过提出各种训练和评估超级网络的技术来解决这些挑战。我们精心设计的模型在三个点击率 (CTR) 预测基准上表现出色，在仅关注架构搜索时，其性能优于手动设计和 AutoML 制作的模型，具有最先进的性能。从协同设计的角度来看，我们在推荐模型中实现了 2 倍的 FLOP 效率、1.8 倍的能源效率和 1.5 倍的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2411.07569</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无开销的用户端推荐系统</title>
      <link>https://arxiv.org/abs/2411.07589</link>
      <description><![CDATA[arXiv:2411.07589v1 Announce Type: new 
摘要：传统上，推荐算法是为服务开发人员设计的。但最近，提出了一种称为用户端推荐系统的新范式。用户端推荐系统由最终用户构建和使用，与传统的提供商端推荐系统形成鲜明对比。即使提供商提供的官方推荐系统不公平，最终用户也可以自己创建和享受自己的用户端推荐系统。虽然用户端推荐系统的概念很有吸引力，但问题是它们需要用户和官方系统之间巨大的沟通成本。即使最高效的用户端推荐系统所需的成本也比提供商端推荐系统高出约 5 倍。如此高的成本阻碍了用户端推荐系统的采用。在本文中，我们提出了无开销的用户端推荐系统 RecCycle，它实现了没有任何通信开销的用户端推荐系统。RecCycle 的主要思想是回收提供商推荐系统提供的过去推荐结果。 RecCycle 的成分可以“免费”检索，这大大降低了用户端推荐的成本。在实验中，我们确认 RecCycle 的性能与最先进的用户端推荐算法一样好，同时 RecCycle 显著降低了成本。]]></description>
      <guid>https://arxiv.org/abs/2411.07589</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过推荐系统推进可持续发展：一项调查</title>
      <link>https://arxiv.org/abs/2411.07658</link>
      <description><![CDATA[arXiv:2411.07658v1 公告类型：新
摘要：人类行为模式和消费模式已成为环境恶化和气候变化的关键决定因素，与交通、能源利用和资源消耗有关的日常决策共同引发了重大的生态影响。推荐系统根据用户偏好和历史交互数据生成个性化建议，对个人行为轨迹产生相当大的影响。然而，传统的推荐系统主要针对用户参与度和经济指标进行优化，无意中忽略了其建议对环境和社会的影响，可能会催化过度消费并强化不可持续的行为模式。鉴于它们在塑造用户决策方面发挥的关键作用，迫切需要可持续的推荐系统，该系统结合了可持续性原则来促进生态意识和社会责任感的选择。这项全面的调查通过对可持续推荐系统进行系统分析来解决这一关键的研究空白。由于这些系统可以同时推进多个可持续发展目标——包括资源节约、可持续消费者行为和社会影响增强——因此，研究它们在不同应用领域的实施情况可以提供更严格的分析框架。通过对涵盖交通、食品、建筑和辅助部门的特定领域实施的方法分析，我们可以更好地阐明这些系统如何整体推进可持续发展目标，同时解决特定行业的制约因素和机遇。此外，我们勾勒出未来研究方向，使推荐系统的发展超越可持续发展倡导，转向促进社会的环境复原力和社会意识。]]></description>
      <guid>https://arxiv.org/abs/2411.07658</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负采样下推荐损失函数的理论分析</title>
      <link>https://arxiv.org/abs/2411.07770</link>
      <description><![CDATA[arXiv:2411.07770v1 公告类型：新
摘要：推荐系统 (RS) 在电子商务、音乐流媒体和社交媒体等不同领域都发挥着关键作用。本文对 RS 中流行的损失函数进行了比较分析：二元交叉熵 (BCE)、分类交叉熵 (CCE) 和贝叶斯个性化排名 (BPR)。通过探索这些损失函数在不同负采样设置中的行为，我们发现当使用一个负样本时，BPR 和 CCE 是等效的。此外，我们证明所有损失都具有一个共同的全局最小值。RS 的评估主要依赖于称为归一化折扣累积增益 (NDCG) 和平均倒数排名 (MRR) 的排名指标。我们为负采样设置生成不同损失的界限，以建立 NDCG 的概率下限。我们表明，NDCG 上的 BPR 边界比 BCE 上的边界弱，这与 BPR 在 RS 训练中优于 BCE 的普遍假设相矛盾。对五个数据集和四个模型的实验从经验上支持了这些理论发现。我们的代码可在 \url{https://anonymous.4open.science/r/recsys_losses} 获得。]]></description>
      <guid>https://arxiv.org/abs/2411.07770</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用人类意图分析和大型语言模型进行音乐发现对话生成</title>
      <link>https://arxiv.org/abs/2411.07439</link>
      <description><![CDATA[arXiv:2411.07439v1 公告类型：交叉 
摘要：对话式音乐检索系统可以帮助用户通过对话发现符合他们喜好的音乐。为了实现这一点，对话式音乐检索系统应该通过 1) 理解用户查询和 2) 用自然语言和检索到的音乐做出响应，无缝地参与多轮对话。一个简单的解决方案是利用此类对话日志的数据驱动方法。然而，可用于研究的数据集很少，而且在数量和质量方面受到限制。在本文中，我们提出了一个数据生成框架，用于使用大型语言模型 (LLM) 和用户意图、系统操作和音乐属性进行丰富的音乐发现对话。这是通过 i) 使用扎根理论进行对话意图分析、ii) 通过级联数据库过滤生成属性序列以及 iii) 使用大型语言模型生成话语来实现的。通过将此框架应用于 Million Song 数据集，我们创建了 LP-MusicDialog，这是一个基于大型语言模型的伪音乐对话数据集，包含超过 288,000 个音乐对话，使用了超过 319,000 个音乐项目。我们的评估表明，在对话一致性、项目相关性和自然性方面，合成数据集与现有的小型人类对话数据集相媲美。此外，我们使用该数据集训练了一个对话音乐检索模型，并展示了令人鼓舞的结果。]]></description>
      <guid>https://arxiv.org/abs/2411.07439</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用模糊图注意网络和动态负采样增强链接预测</title>
      <link>https://arxiv.org/abs/2411.07482</link>
      <description><![CDATA[arXiv:2411.07482v1 公告类型：交叉 
摘要：链接预测对于理解复杂网络至关重要，但传统的图神经网络 (GNN) 通常依赖于随机负采样，导致性能不佳。本文介绍了模糊图注意网络 (FGAT)，这是一种集成模糊粗糙集进行动态负采样和增强节点特征聚合的新方法。模糊负采样 (FNS) 根据模糊相似性系统地选择高质量负边，提高训练效率。FGAT 层结合了模糊粗糙集原理，实现了稳健且有判别力的节点表示。在两个研究合作网络上的实验证明了 FGAT 卓越的链接预测准确性，通过利用模糊粗糙集的强大功能进行有效的负采样和节点特征学习，其表现优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2411.07482</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于多层嵌入的检索解锁法律知识</title>
      <link>https://arxiv.org/abs/2411.07739</link>
      <description><![CDATA[arXiv:2411.07739v1 公告类型：交叉 
摘要：这项工作通过提出一种基于多层嵌入的法律和立法文本检索方法来解决捕捉法律知识复杂性的挑战。不仅为单个文章创建嵌入，还为其组成部分（段落、条款）和结构分组（书籍、标题、章节等）创建嵌入，我们试图通过使用密集的嵌入向量来捕捉法律信息的细微差别，以不同的粒度级别表示它。我们的方法通过允许检索增强生成系统提供准确的响应来满足各种信息需求，无论是针对特定段还是整个部分，都可以根据用户的查询进行定制。我们探索了法律文本中的关于性、语义分块和固有层次结构的概念，认为这种方法增强了法律信息检索。尽管重点关注的是巴西的立法方法和遵循民法传统的巴西宪法，但我们的研究结果原则上应适用于不同的法律体系，包括遵循普通法传统的法律体系。此外，所提出方法的原则超出了法律领域，为组织和检索以分层文本编码的信息为特征的任何领域的信息提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.07739</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索增强大型语言模型中参数知识细化的查询优化</title>
      <link>https://arxiv.org/abs/2411.07820</link>
      <description><![CDATA[arXiv:2411.07820v1 公告类型：交叉 
摘要：我们引入了 \textit{Extract-Refine-Retrieve-Read} (ERRR) 框架，这是一种新颖的方法，旨在通过定制查询优化来弥补检索增强生成 (RAG) 系统中的预检索信息差距，以满足大型语言模型 (LLM) 的特定知识要求。与 RAG 中使用的传统查询优化技术不同，ERRR 框架首先从 LLM 中提取参数知识，然后使用专门的查询优化器来优化这些查询。此过程可确保仅检索生成准确响应所必需的最相关信息。此外，为了增强灵活性并降低计算成本，我们为我们的管道提出了一种可训练方案，该方案利用较小的可调模型作为查询优化器，并通过从较大的教师模型中进行知识提炼来完善。我们对各种问答 (QA) 数据集和不同检索系统的评估表明，ERRR 的表现始终优于现有基线，证明它是一个多功能且经济高效的模块，可用于提高 RAG 系统的实用性和准确性。]]></description>
      <guid>https://arxiv.org/abs/2411.07820</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>显性和隐性语义排序框架</title>
      <link>https://arxiv.org/abs/2304.04918</link>
      <description><![CDATA[arXiv:2304.04918v2 公告类型：替换 
摘要：许多实际应用中的核心挑战是从可变且有限的候选集中将查询与最佳文档匹配。现有的行业解决方案，尤其是延迟受限的服务，通常依赖于牺牲质量来换取速度的相似性算法。在本文中，我们介绍了一个通用的语义学习排名框架，即自训练语义交叉注意排名 (sRank)。这个基于 Transformer 的框架使用线性成对损失和可变的训练批次大小，实现了质量提升和高效率，并且已有效应用于 Microsoft 在现实世界的大规模数据集上的两个行业任务：智能回复 (SR) 和环境临床智能 (ACI) 中显示收益。在智能回复中，sRank 通过根据消费者和支持代理消息从预定义的解决方案中选择最佳回复来协助现场客户提供技术支持。与之前的系统相比，它在 SR 任务上的离线 top-one 准确率提高了 11.7%，并且自 2021 年 1 月正式发布以来，在遥测记录中编写消息的时间减少了 38.7%。在 ACI 任务中，sRank 选择相关的历史医生模板作为文本摘要模型的指导，以生成更高质量的医疗笔记。它在生成的医疗笔记中实现了 35.5% 的 top-one 准确率增益，以及 46% 的相对 ROUGE-L 增益。]]></description>
      <guid>https://arxiv.org/abs/2304.04918</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于内容的推荐系统协作生成</title>
      <link>https://arxiv.org/abs/2403.18480</link>
      <description><![CDATA[arXiv:2403.18480v2 公告类型：替换 
摘要：生成模型已成为增强推荐系统的一种有前途的实用工具。为了更好地推荐，在统一的生成框架中对项目内容和用户项目协作交互进行建模至关重要。尽管一些现有的基于大型语言模型 (LLM) 的方法有助于融合内容信息和协作信号，但它们从根本上依赖于文本语言生成，这与推荐任务并不完全一致。如何在为项目推荐量身定制的生成框架中整合内容知识和协作交互信号仍然是一个开放的研究挑战。
在本文中，我们提出了基于内容的推荐系统协作生成，即 ColaRec。ColaRec 是一个序列到序列框架，专门用于直接生成推荐项目标识符。确切地说，输入序列包括与用户交互的项目有关的数据，输出序列表示建议项目的生成标识符 (GID)。为了对协作信号进行建模，GID 由预训练的协同过滤模型构建，用户则表示为交互项目的内容集合。为此，ColaRec 在统一框架中捕获协作信号和内容信息。然后，提出了一个项目索引任务来执行基于内容的语义空间和基于交互的协作空间之间的对齐。此外，还引入了对比损失，以确保具有相似协作 GID 的项目具有相似的内容表示。为了验证 ColaRec 的有效性，我们在四个基准数据集上进行了实验。实证结果表明 ColaRec 具有卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.18480</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对快速列表重新排序的单标记解码的早期首次复现和改进</title>
      <link>https://arxiv.org/abs/2411.05508</link>
      <description><![CDATA[arXiv:2411.05508v2 公告类型：替换 
摘要：最近的进展表明，大型语言模型 (LLM) 作为列表式重排器表现出色，但它们的高计算需求仍然是广泛采用的障碍。此外，传统的语言建模 (LM) 目标并不非常适合重排任务。FIRST 是一种新颖的方法，它通过集成学习排序目标并利用仅第一个生成的 token 的 logit 来解决这些挑战，从而与传统的 LLM 重排器相比显着降低了推理延迟。在本研究中，我们将 FIRST 的评估扩展到 TREC 深度学习数据集 (DL19-22)，验证其在不同领域的稳健性。我们研究了不同的第一阶段检索器对 FIRST 重排器的影响，观察到收益递减和与传统 LLM 重排器一致的模式。通过将 FIRST 目标应用于更广泛的骨干模型，我们实现了超越原始实现的有效性。我们的实验证实，使用单标记逻辑快速重新排序不会损害域外重新排序质量。为了更好地量化原始研究中的计算节省，我们测量并比较了延迟，发现各种模型和基准测试的延迟提高了 21%-42%。此外，虽然 LM 训练隐式地改善了零样本单标记重新排序，但我们的实验也提出了一个问题，即 LM 预训练是否会阻碍后续使用 FIRST 目标进行微调。这些发现为未来应用中更高效、更有效的列表式重新排序铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2411.05508</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用图神经网络对针对伊斯兰教的仇恨言论进行可解释的识别</title>
      <link>https://arxiv.org/abs/2311.04916</link>
      <description><![CDATA[arXiv:2311.04916v4 公告类型：replace-cross 
摘要：网络平台上的仇视伊斯兰教语言助长了不宽容，因此检测和消除仇恨言论对于促进和谐至关重要。传统的仇恨言论检测模型依赖于 NLP 技术，如标记化、词性标记和编码器-解码器模型。然而，图神经网络 (GNN) 能够利用数据点之间的关系，从而提供更有效的检测和更大的可解释性。在这项工作中，我们将演讲表示为节点，并根据其上下文和相似性将它们与边连接起来以开发图形。本研究引入了一种使用 GNN 识别和解释针对伊斯兰教的仇恨言论的新范式。我们的模型利用 GNN 来理解仇恨言论的背景和模式，通过预先训练的 NLP 生成的词嵌入连接文本，实现最先进的性能并提高检测准确性，同时提供有价值的解释。这凸显了 GNN 在打击网络仇恨言论和营造更安全、更包容的网络环境方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2311.04916</guid>
      <pubDate>Wed, 13 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>