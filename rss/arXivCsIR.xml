<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过自提示释放大型语言模型在零样本关系提取中的威力</title>
      <link>https://arxiv.org/abs/2410.01154</link>
      <description><![CDATA[arXiv:2410.01154v1 公告类型：新
摘要：零样本关系提取 (RE) 的最新研究集中在使用大型语言模型 (LLM)，因为它们具有令人印象深刻的零样本能力。然而，当前的方法通常表现不佳，主要是因为缺乏理解各种句子和关系所需的详细、特定于上下文的提示。为了解决这个问题，我们引入了自提示框架，这是一种旨在充分利用 LLM 中嵌入的 RE 知识的新方法。具体来说，我们的框架采用三阶段多样性方法来提示 LLM，从头开始生成多个封装特定关系的合成样本。这些生成的样本充当上下文学习样本，提供明确和特定于上下文的指导，以有效地提示 LLM 进行 RE。在基准数据集上的实验评估表明，我们的方法优于现有的基于 LLM 的零样本 RE 方法。此外，我们的实验证实了我们的生成流程在生成可提高性能的高质量合成数据方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.01154</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphRevisedIE：使用图形修订网络进行多模态信息提取</title>
      <link>https://arxiv.org/abs/2410.01160</link>
      <description><![CDATA[arXiv:2410.01160v1 公告类型：新
摘要：从视觉丰富的文档 (VRD) 中提取关键信息 (KIE) 一直是文档智能中的一项具有挑战性的任务，因为不仅 VRD 的布局复杂多样，使得模型难以推广，而且缺乏利用 VRD 中多模态特征的方法。在本文中，我们提出了一个名为 GraphRevisedIE 的轻量级模型，该模型有效地嵌入了 VRD 中的文本、视觉和布局特征等多模态特征，并利用图形修订和图形卷积来丰富具有全局上下文的多模态嵌入。在多个真实数据集上进行的大量实验表明，GraphRevisedIE 可以推广到各种布局的文档，并且与以前的 KIE 方法相比实现了相当或更好的性能。我们还发布了一个包含真实文档和合成文档的营业执照数据集，以促进文档 KIE 的研究。]]></description>
      <guid>https://arxiv.org/abs/2410.01160</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集成视觉和文本输入，使用 CLIP 搜索大规模地图集</title>
      <link>https://arxiv.org/abs/2410.01190</link>
      <description><![CDATA[arXiv:2410.01190v1 公告类型：新
摘要：尽管地图在数字收藏中普遍存在且具有历史重要性，但当前浏览和探索地图集的方法主要局限于目录记录和结构化元数据。在本文中，我们探索使用自然语言输入（“带有海怪的地图”）、视觉输入（即反向图像搜索）和多模态输入（示例地图 + “更多灰度”）以交互方式搜索大型地图集的潜力。作为案例研究，我们采用了 562,842 张可通过国会图书馆 API 公开访问的地图图像。为此，我们使用多模态对比语言图像预训练 (CLIP) 机器学习模型为这些地图生成嵌入，并开发代码以使用这些输入策略实现探索性搜索功能。我们展示了与国会图书馆地理和地图部门工作人员协商创建的搜索示例结果，并描述了这些搜索查询的优势、劣势和可能性。此外，我们引入了一个包含 10,504 个地图-标题对的微调数据集，以及一个用于在此数据集上微调 CLIP 模型的架构。为了方便重复使用，我们在文档化的交互式 Jupyter 笔记本中提供了所有代码，并将所有代码置于公共领域。最后，我们讨论了将这些方法应用于画廊、图书馆、档案馆和博物馆所拥有的数字化和原生数字化收藏品的机会和挑战。]]></description>
      <guid>https://arxiv.org/abs/2410.01190</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PairDistill：用于密集检索的成对相关性蒸馏</title>
      <link>https://arxiv.org/abs/2410.01383</link>
      <description><![CDATA[arXiv:2410.01383v1 公告类型：新
摘要：从海量数据集中有效检索信息 (IR) 依赖于先进的技术来提取相关信息以响应查询。与传统的稀疏检索方法相比，密集检索的最新进展显示出了显著的效果。为了进一步提高检索性能，知识蒸馏技术（通常利用强大的跨编码器重排器）得到了广泛的探索。然而，现有的方法主要从逐点重排器中提取知识，逐点重排器为文档分配绝对相关性分数，因此面临着与不一致比较相关的挑战。本文介绍了成对相关性蒸馏 (PairDistill) 来利用成对重排，在类似相关文档之间提供细粒度的区分，以丰富密集检索模型的训练。我们的实验表明，PairDistill 优于现有方法，在多个基准测试中取得了新的最先进的结果。这凸显了 PairDistill 在有效推进密集检索技术方面的潜力。我们的源代码和经过训练的模型已发布在 https://github.com/MiuLab/PairDistill]]></description>
      <guid>https://arxiv.org/abs/2410.01383</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分析单音和复音符号音乐的字节对编码：重点关注乐句分割</title>
      <link>https://arxiv.org/abs/2410.01448</link>
      <description><![CDATA[arXiv:2410.01448v1 公告类型：新
摘要：字节对编码 (BPE) 是一种常用于自然语言处理以构建子词词汇表的算法，最近已应用于符号音乐。鉴于符号音乐与文本有很大不同，尤其是复音，我们研究了 BPE 如何处理不同类型的音乐内容。本研究对 BPE 在各种乐器中的行为进行了定性分析，并评估了其对单音和复音音乐乐句分割任务的影响。我们的研究结果表明，BPE 训练过程高度依赖于乐器，并且 BPE“超级标记”成功捕捉到了抽象的音乐内容。在乐句分割任务中，BPE 显著提高了复音设置下的性能，但仅在特定范围的 BPE 合并内提高了单音曲调的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.01448</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>层层剥开：对神经新闻推荐器中编码器架构的深入评估</title>
      <link>https://arxiv.org/abs/2410.01470</link>
      <description><![CDATA[arXiv:2410.01470v1 公告类型：新
摘要：编码器架构通过嵌入新闻和用户的语义和上下文信息在神经新闻推荐器中发挥着关键作用。因此，研究主要集中在增强新闻和用户编码器的表示能力以提高推荐器性能。尽管编码器架构对新闻和用户表示的质量有重大影响，但现有的编码器设计分析仅关注整体下游推荐性能。这提供了对编码器相似性的片面评估，忽略了它们行为中更细微的差异，并可能导致次优模型选择。在这项工作中，我们对神经新闻推荐系统中的编码器架构进行了全面分析。我们系统地评估了最突出的新闻和用户编码器架构，重点关注它们的 (i) 表示相似性（用中央核对齐来衡量）、(ii) 生成的推荐列表的重叠（用 Jaccard 相似性量化）和 (iii) 整体推荐性能。我们的分析表明，某些编码技术的复杂性往往在经验上是不合理的，这凸显了更简单、更高效的架构的潜力。通过隔离各个组件的影响，我们为研究人员和从业者提供了宝贵的见解，使他们能够就编码器选择做出更明智的决定，并避免新闻推荐器设计中不必要的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2410.01470</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>旅游目的地推荐中广泛和间接查询的精细子主题查询重构</title>
      <link>https://arxiv.org/abs/2410.01598</link>
      <description><![CDATA[arXiv:2410.01598v1 公告类型：新
摘要：在查询驱动的旅行推荐系统 (RS) 中，了解具有挑战性的自然语言 (NL) 目的地查询（例如措辞广泛的“青年友好活动”或间接描述“高中毕业旅行”）背后的用户意图至关重要。此类查询具有挑战性，因为潜在用户意图的范围广泛且微妙，这混淆了检索方法从可用的文本描述（例如 WikiVoyage）推断相关目的地的能力。虽然查询重构 (QR) 已被证明可通过解决用户意图来有效增强检索，但现有的 QR 方法往往只关注扩大可能匹配的查询子主题的范围（广度）或阐述查询的潜在含义（深度），但不能同时兼顾两者。在本文中，我们介绍了精细子主题查询重构 (EQR)，这是一种基于大型语言模型的 QR 方法，通过生成具有丰富信息的精细化潜在查询子主题，兼具广度和深度。我们还发布了 TravelDest，这是一个用于查询驱动的旅游目的地 RS 的新数据集。在 TravelDest 上的实验表明，与现有的最先进 QR 方法相比，EQR 在召回率和准确率方面取得了显著的提升。]]></description>
      <guid>https://arxiv.org/abs/2410.01598</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行文本聚类分类</title>
      <link>https://arxiv.org/abs/2410.00927</link>
      <description><![CDATA[arXiv:2410.00927v1 公告类型：交叉 
摘要：文本聚类在手动标记成本过高的实际应用中仍然很有价值。它通过根据相似文本的表示形式对其进行分组，从而促进信息的有效组织和分析。但是，实现这种方法需要对下游数据和复杂的相似性指标进行微调的嵌入器。为了解决这个问题，本研究提出了一种新颖的文本聚类框架，该框架有效地利用了大型语言模型 (LLM) 的上下文学习能力。我们建议通过 LLM 将文本聚类转换为分类任务，而不是微调嵌入器。首先，我们提示 LLM 为给定的数据集生成潜在标签。其次，在整合 LLM 生成的类似标签后，我们提示 LLM 为数据集中的每个样本分配最合适的标签。我们的框架已通过实验证明，其性能可与采用嵌入的最先进的聚类方法相媲美或更佳，且无需复杂的微调或聚类算法。我们的代码可供公众使用，网址为 https://anonymous.4open.science/r/Text-Clustering-via-LLM-E500。]]></description>
      <guid>https://arxiv.org/abs/2410.00927</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将学习委托给自动化吗？：法学硕士聊天机器人、搜索引擎和书籍的比较研究</title>
      <link>https://arxiv.org/abs/2410.01396</link>
      <description><![CDATA[arXiv:2410.01396v1 公告类型：交叉 
摘要：学习是信息搜索行为背后的关键动机。随着基于 LLM 的聊天机器人的出现，学生越来越多地将这些工具作为获取知识的主要资源。然而，从教科书和网络搜索等传统资源的转变引起了教育工作者的担忧。他们担心这些完全自动化的 LLM 可能会导致学生将搜索的关键步骤委托为学习。在本文中，我们系统地从教育者的角度揭示了三个主要问题。为了解决这些问题，我们对 92 名大学生进行了一项混合方法研究，以比较三种具有不同自动化水平的学习来源。我们的结果表明，LLM 支持全面理解关键概念而不促进被动学习，尽管它们在知识保留方面的有效性有限。此外，我们发现学业成绩影响学习成果和搜索模式。值得注意的是，能力较高的学习者通过阅读密集型行为而不是依赖搜索活动更深入地参与内容。]]></description>
      <guid>https://arxiv.org/abs/2410.01396</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RecPrompt：使用大型语言模型进行新闻推荐的自调整提示框架</title>
      <link>https://arxiv.org/abs/2312.10463</link>
      <description><![CDATA[arXiv:2312.10463v3 公告类型：替换 
摘要：新闻推荐严重依赖自然语言处理 (NLP) 方法来分析、理解和分类内容，从而能够根据用户兴趣和阅读行为提供个性化建议。像 GPT-4 这样的大型语言模型 (LLM) 在理解自然语言方面表现出色。然而，它们对新闻推荐系统的适用程度仍有待验证。本文介绍了第一个用于新闻推荐的自调整提示框架 RecPrompt，它利用 LLM 的功能执行复杂的新闻推荐任务。该框架包含一个新闻推荐器和一个提示优化器，它应用迭代引导过程通过自动提示工程来增强推荐。针对 400 名用户的大量实验结果表明，与深度神经模型相比，RecPrompt 的 AUC 提高了 3.36%，MRR 提高了 10.49%，nDCG@5 提高了 9.64%，nDCG@10 提高了 6.20%。此外，我们还引入了 TopicScore，这是一种新颖的指标，通过评估 LLM 总结用户感兴趣主题的能力来评估可解释性。结果表明，LLM 能够准确识别感兴趣的主题并提供全面的基于主题的解释。]]></description>
      <guid>https://arxiv.org/abs/2312.10463</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电子商务搜索中查询重构建模的可扩展性和延展性</title>
      <link>https://arxiv.org/abs/2402.11202</link>
      <description><![CDATA[arXiv:2402.11202v2 公告类型：替换 
摘要：客户行为数据对电子商务搜索系统有重大影响。然而，在不太常见的查询的情况下，相关的行为数据往往是稀疏和嘈杂的，无法为搜索机制提供足够的支持。为了应对这一挑战，引入了查询重构的概念。它表明不太常见的查询可以利用具有相似含义的流行查询的行为模式。在亚马逊产品搜索中，查询重构已显示出其在提高搜索相关性和增加总收入方面的有效性。尽管如此，将这种方法应用于在流量较低和多语言环境复杂的地区运营的小型或新兴企业在可扩展性和可扩展性方面提出了挑战。本研究重点是通过构建一个查询重构解决方案来克服这一挑战，该解决方案即使在面对有限的训练数据、质量和规模以及相对复杂的语言特征时也能有效运行。在本文中，我们概述了在亚马逊产品搜索基础设施中实施的解决方案，该解决方案涵盖了一系列元素，包括改进数据挖掘过程、重新定义模型训练目标和重塑训练策略。通过对搜索排名和广告匹配进行在线 A/B 测试，验证了所提解决方案的有效性。值得注意的是，与传统实施相比，在搜索排名中采用所提解决方案分别导致日语和印地语案例的总收入增加了 0.14% 和 0.29%，在英语案例中增加了 0.08% 的增量收益；而在搜索广告匹配中，日语案例中的广告收入增加了 0.36%。]]></description>
      <guid>https://arxiv.org/abs/2402.11202</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一次训练，随处部署：用于多模态推荐的 Matryoshka 表示学习</title>
      <link>https://arxiv.org/abs/2409.16627</link>
      <description><![CDATA[arXiv:2409.16627v2 公告类型：替换 
摘要：尽管语言和视觉建模最近取得了进展，但将丰富的多模态知识集成到推荐系统中仍然面临重大挑战。这主要是因为需要有效的推荐，这需要自适应和交互式响应。在本研究中，我们专注于顺序推荐，并引入了一个轻量级框架，称为全尺寸 Matryoshka 表示学习多模态推荐 (fMRLRec)。我们的 fMRLRec 以不同的粒度捕获项目特征，学习信息表示以在多个维度上进行有效的推荐。为了整合来自不同模态的项目特征，fMRLRec 采用简单的映射将多模态项目特征投影到对齐的特征空间中。此外，我们设计了一种有效的线性变换，将较小的特征嵌入到较大的特征中，大大减少了对推荐数据进行大规模训练的内存要求。结合改进的状态空间建模技术，fMRLRec 可以扩展到不同的维度，只需要一次训练就可以生成针对各种粒度的多个模型。我们在多个基准数据集上证明了 fMRLRec 的有效性和效率，其性能始终优于最先进的基线方法。我们的代码和数据已在 https://github.com/yueqirex/fMRLRec 上公开。]]></description>
      <guid>https://arxiv.org/abs/2409.16627</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于机器学习的多阶段系统对真实患者数据进行视力预测</title>
      <link>https://arxiv.org/abs/2204.11970</link>
      <description><![CDATA[arXiv:2204.11970v5 公告类型：replace-cross 
摘要：在眼科中，玻璃体内手术药物治疗 (IVOM) 是一种广泛用于治疗与年龄相关性黄斑变性 (AMD)、糖尿病性黄斑水肿 (DME) 以及视网膜静脉阻塞 (RVO) 相关的疾病的方法。然而，在现实世界中，尽管接受了治疗，患者仍经常会在数年的时间尺度上遭受视力丧失，而由于数据异构且不完整，预测视力 (VA) 和在现实条件下尽早发现恶化具有挑战性。在本文中，我们介绍了一种工作流程，用于开发一个研究兼容的数据语料库，该语料库融合了德国最高护理医院眼科的不同 IT 系统。广泛的数据语料库可以预测患者及其 VA 在三种疾病中的预期进展。对于 AMD 疾病，我们发现视力会随着时间的推移而显著下降。在我们提出的多阶段系统中，我们随后将 VA 进展分为三组治疗“赢家”、“稳定者”和“输家”（WSL 分类方案）。我们使用一组深度神经网络进行 OCT 生物标志物分类，分类准确率（F1 分数）超过 98%，使我们能够完成不完整的 OCT 文档，同时允许我们利用它们进行更精确的 VA 建模过程。我们的 VA 预测需要至少四次 VA 检查和可选的 OCT 生物标志物，这些检查和生物标志物来自同一时间段，以预测预测时间范围内的 VA 进展，而我们的预测目前仅限于 IVOM/无治疗。我们在宏观平均 F1 分数中实现了 69% 的最终预测准确率，同时与眼科医生的 57.8 和 50 +- 10.7% F1 分数处于同一范围内。]]></description>
      <guid>https://arxiv.org/abs/2204.11970</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱嵌入的块对角正交关系与矩阵实体</title>
      <link>https://arxiv.org/abs/2401.05967</link>
      <description><![CDATA[arXiv:2401.05967v3 公告类型：replace-cross 
摘要：知识图谱嵌入 (KGE) 的主要目的是学习实体和关系的低维表示，以预测缺失的事实。虽然基于旋转的方法（如 RotatE 和 QuatE）在 KGE 中表现良好，但它们面临两个挑战：模型灵活性有限，需要关系大小与实体维度成比例增加，并且难以将模型推广到更高维的旋转。为了解决这些问题，我们引入了 OrthogonalE，这是一种新颖的 KGE 模型，它采用矩阵表示实体，采用具有黎曼优化的块对角正交矩阵表示关系。这种方法增强了 KGE 模型的通用性和灵活性。实验结果表明，我们的新 KGE 模型 OrthogonalE 既通用又灵活，明显优于最先进的 KGE 模型，同时大幅减少了关系参数的数量。]]></description>
      <guid>https://arxiv.org/abs/2401.05967</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大规模合成监督进行跨语言开放领域问答的预训练</title>
      <link>https://arxiv.org/abs/2402.16508</link>
      <description><![CDATA[arXiv:2402.16508v3 公告类型：replace-cross 
摘要：跨语言开放域问答 (CLQA) 是一个复杂的问题，包括从多语言知识库中进行跨语言检索，然后使用查询语言生成答案。这两个步骤通常由单独的模型处理，需要大量带注释的数据集，并且通常需要辅助资源，例如机器翻译系统来跨语言沟通。在本文中，我们表明可以使用单个编码器-解码器模型来解决 CLQA。为了有效地训练这个模型，我们提出了一种基于利用维基百科中的跨语言链接结构的自监督方法。我们演示了如何使用链接的维基百科页面通过一种完形填空查询形式来合成跨语言检索的监督信号，并生成更自然的问题来监督答案生成。总之，我们展示了我们的方法 \texttt{CLASS} 在监督和零样本语言自适应设置（包括使用机器翻译的设置）中均优于同类方法。]]></description>
      <guid>https://arxiv.org/abs/2402.16508</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>