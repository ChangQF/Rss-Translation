<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 12 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MRP-LLM：用于隐私保护的多任务反射式大型语言模型下一个 POI 推荐</title>
      <link>https://arxiv.org/abs/2412.07796</link>
      <description><![CDATA[arXiv:2412.07796v1 公告类型：新 
摘要：大型语言模型 (LLM) 已显示出在下一个兴趣点 (POI) 推荐方面的巨大潜力。然而，现有方法仅执行直接零样本提示，导致用户偏好提取无效、协作信号注入不足以及缺乏用户隐私保护。因此，我们提出了一种新颖的多任务反射大型语言模型，用于隐私保护下一个 POI 推荐 (MRP-LLM)，旨在利用 LLM 进行更好的下一个 POI 推荐，同时保护用户隐私。具体而言，多任务反射偏好提取模块首先利用 LLM 将每个用户的细粒度（即分类、时间和空间）偏好提炼到知识库 (KB) 中。邻居偏好检索模块从 KB 中检索并总结相似用户的偏好以获得协作信号。随后，多任务下一个 POI 推荐模块将用户的偏好与类似用户的偏好聚合在一起，通过多任务提示生成下一个 POI 推荐。同时，在数据收集过程中，专门设计了隐私传输模块来保护敏感的 POI 数据。在三个真实数据集上进行的大量实验证明了我们提出的 MRP-LLM 在提供更准确的下一个 POI 推荐方面非常有效，同时保护了用户隐私。]]></description>
      <guid>https://arxiv.org/abs/2412.07796</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RALI@TREC iKAT 2024：通过对话搜索中的检索融合实现个性化</title>
      <link>https://arxiv.org/abs/2412.07998</link>
      <description><![CDATA[arXiv:2412.07998v1 公告类型：新
摘要：Recherche Appliquee en Linguistique Informatique (RALI) 团队参加了 2024 年 TREC 交互式知识协助 (iKAT) 赛道。在个性化对话搜索中，有效捕捉用户复杂的搜索意图需要将上下文信息和用户个人资料中的关键元素纳入查询重构中。用户个人资料通常包含许多相关部分，每个部分都可能补充用户的信息需求。很难忽视其中任何一个，而引入过多的这些部分则有偏离原始查询的风险并阻碍搜索性能。我们将这一挑战称为过度个性化。为了解决这个问题，我们提出了不同的策略，通过融合不同个性化级别的查询生成的排名列表。]]></description>
      <guid>https://arxiv.org/abs/2412.07998</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>个性化联合推荐系统教程：最新进展和未来方向</title>
      <link>https://arxiv.org/abs/2412.08071</link>
      <description><![CDATA[arXiv:2412.08071v1 Announce Type: new 
摘要：个性化是推荐系统（RecSys）的基石，旨在筛选出冗余信息，为用户提供量身定制的服务。然而，传统的基于云端的推荐系统需要集中式的数据收集，存在较大的用户隐私泄露风险。为了应对这一挑战，联邦推荐系统（FedRecSys）应运而生，引起了广泛关注。FedRecSys允许用户将个人数据保留在本地，仅共享隐私敏感度较低的模型参数进行全局模型训练，大大增强了系统的隐私保护能力。在分布式学习框架下，用户行为数据明显的非独立同分布特性给联邦优化带来了新的障碍。同时，联邦学习同时学习多个模型的能力为个性化用户建模提供了机会。因此，个性化FedRecSys（PFedRecSys）的开发至关重要，具有重要意义。本教程旨在介绍 PFedRecSys，包括 (1) PFedRecSys 现有研究概述，(2) PFedRecSys 的综合分类法，涵盖四个关键研究方向 - 客户端适应、服务器端聚合、通信效率、隐私和保护，以及 (3) 探索 PFedRecSys 中的开放挑战和有希望的未来方向。本教程旨在为不断发展的 RecSys 领域的后续探索和实际实施奠定坚实的基础并激发新视角。]]></description>
      <guid>https://arxiv.org/abs/2412.08071</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于顺序推荐的多模态差异学习</title>
      <link>https://arxiv.org/abs/2412.08103</link>
      <description><![CDATA[arXiv:2412.08103v1 公告类型：新
摘要：顺序推荐在对用户的历史行为进行建模以预测下一个项目方面引起了广泛关注。随着互联网平台上多模态数据（例如图像、文本）的蓬勃发展，顺序推荐也受益于多模态数据的整合。大多数方法将项目的模态特征作为辅助信息引入，并简单地将它们连接起来以学习统一的用户兴趣。然而，这些方法在建模多模态差异方面遇到了局限性。我们认为用户兴趣和项目关系在不同的模态中有所不同。为了解决这个问题，我们提出了一种新颖的顺序推荐多模态差异学习框架，简称为 MDSRec。具体而言，我们首先通过构建具有行为信号的模态感知项目关系图来探索项目关系的差异，以增强项目表示。然后，为了捕捉不同模态中用户兴趣的差异，我们设计了一个以兴趣为中心的注意力机制来独立建模不同模态中的用户序列表示。最后，我们融合了来自多种模态的用户嵌入以实现准确的项目推荐。在五个真实世界数据集上的实验结果证明了 MDSRec 优于最先进的基线以及多模态差异学习的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.08103</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过平衡相关性和多样性来增强顺序推荐</title>
      <link>https://arxiv.org/abs/2412.08300</link>
      <description><![CDATA[arXiv:2412.08300v1 公告类型：新 
摘要：通过生成新的有效数据，数据增强已成为缓解顺序推荐中数据稀疏问题的一种有前途的方法。现有的工作侧重于增强原始数据，但很少探讨增强数据的不平衡相关性和多样性问题，从而导致语义漂移问题或性能改进有限。在本文中，我们提出了一种新颖的平衡数据增强顺序推荐插件 (BASRec) 来生成平衡相关性和多样性的数据。BASRec 包含两个模块：单序列增强和跨序列增强。前者利用启发式运算符的随机性为单个用户生成多样化的序列，然后在表示级别融合多样化和原始序列以获得相关性。此外，我们设计了一种重新加权策略，使模型能够基于这两个属性自适应地学习偏好。跨序列增强从两个方向对不同的序列表示进行非线性混合。它生成足够多样化但保留原始序列重要语义的虚拟序列表示。这两个模块增强了模型从单用户和跨用户视角发现细粒度偏好知识的能力。大量实验验证了 BASRec 的有效性。在 GRU4Rec 上平均改进高达 72.0%，在 SASRec 上平均改进高达 33.8%，在 FMLP-Rec 上平均改进高达 68.5%。我们证明 BASRec 生成的数据在相关性和多样性之间取得了比现有方法更好的平衡。源代码可在 https://github.com/KingGugu/BASRec 获得。]]></description>
      <guid>https://arxiv.org/abs/2412.08300</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AltFS：深度推荐系统中使用大型语言模型进行机构轻量级特征选择</title>
      <link>https://arxiv.org/abs/2412.08516</link>
      <description><![CDATA[arXiv:2412.08516v1 公告类型：新
摘要：特征选择对于提高推荐系统的模型效率和预测性能至关重要。传统方法依赖于代理模型（例如决策树或神经网络）来估计特征重要性。然而，这种方法本质上是有局限性的，因为由于训练条件不理想（例如特征共线性、高维稀疏性和数据不足），代理模型可能无法在所有情况下有效学习。在本文中，我们提出了 AltFS，一种用于深度推荐系统的轻代理特征选择方法。AltFS 将大型语言模型 (LLM) 的语义推理与代理模型的任务特定学习相结合。最初，LLM 将生成特征重要性的语义排名，然后由代理模型对其进行细化，将世界知识与任务特定的见解相结合。对来自现实世界推荐平台的三个公共数据集进行的大量实验证明了 AltFS 的有效性。我们的代码可公开复制。]]></description>
      <guid>https://arxiv.org/abs/2412.08516</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 增强型生成检索进行偏好辨别</title>
      <link>https://arxiv.org/abs/2412.08604</link>
      <description><![CDATA[arXiv:2412.08604v1 公告类型：新
摘要：顺序推荐系统旨在根据用户的交互历史为他们提供个性化推荐。为了实现这一点，它们通常会结合辅助信息，例如项目的文本描述和辅助任务，例如预测用户的偏好和意图。尽管我们付出了许多努力来增强这些模型，但它们仍然受到个性化限制的影响。为了解决这个问题，我们提出了一个新范式，我们称之为偏好辨别。在偏好辨别中，我们明确地根据用户在其上下文中的偏好来调节生成顺序推荐系统。为此，我们使用基于用户评论和特定于项目的数据的大型语言模型 (LLM) 生成用户偏好。为了评估顺序推荐系统的偏好辨别能力，我们引入了一个新颖的基准，该基准可在各种场景中提供整体评估，包括偏好引导和情绪跟随。我们使用我们的基准评估当前最先进的方法，并表明它们难以准确辨别用户偏好。因此，我们提出了一种名为 Mender 的新方法（$\textbf{M}$ultimodal Prefer$\textbf{en}$ce $\textbf{d}$iscern$\textbf{er}$），该方法改进了现有方法并在我们的基准测试中取得了最佳性能。我们的结果表明，即使在训练期间没有观察到人类偏好，Mender 也可以有效地受到人类偏好的引导，为更加个性化的顺序推荐系统铺平了道路。我们将在发布后开源代码和基准测试。]]></description>
      <guid>https://arxiv.org/abs/2412.08604</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐的集群增强联合图神经网络</title>
      <link>https://arxiv.org/abs/2412.08066</link>
      <description><![CDATA[arXiv:2412.08066v1 公告类型：交叉 
摘要：在推荐系统中，个人交互数据可以有效地建模为每个用户的单独图。基于图神经网络 (GNN) 的推荐技术已经变得非常流行，因为它们可以通过将单个图聚合成全局交互图来捕获用户和项目之间的高阶协作信号。然而，这种集中式方法本质上对用户隐私和安全构成了威胁。最近，基于联合 GNN 的推荐技术已经成为缓解隐私问题的有希望的解决方案。然而，当前的实现要么将设备上的训练限制在无人陪伴的单个图上，要么需要依赖额外的第三方服务器来接触其他单个图，这也增加了隐私泄露的风险。为了应对这一挑战，我们提出了一种用于推荐的集群增强联合图神经网络框架，名为 CFedGR，它引入了高阶协作信号以隐私保护的方式增强单个图。具体来说，服务器对预训练的用户表示进行聚类以识别高阶协作信号。此外，还设计了两种有效的策略来减少设备和服务器之间的通信。在三个基准数据集上进行的大量实验验证了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.08066</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多维核查价值：为人类事实核查人员设计人工智能辅助索赔优先级</title>
      <link>https://arxiv.org/abs/2412.08185</link>
      <description><![CDATA[arXiv:2412.08185v1 公告类型：交叉 
摘要：鉴于网上流传的大量潜在虚假声明，声明优先级排序对于分配有限的人力资源进行事实核查至关重要。在本研究中，我们将声明优先级排序视为一项信息检索 (IR) 任务：就像多维 IR 相关性一样，许多因素会影响用户认为哪些搜索结果相关，核查价值也是多方面的、主观的，甚至是个人的，许多因素会影响事实核查人员如何分类和选择要检查的声明。我们的研究调查了核查价值的多维性质和有效的工具支持，以协助事实核查人员进行声明优先级排序。在方法论上，我们通过设计进行研究，并结合混合方法评估。我们开发了一个人工智能辅助声明优先级排序原型，作为探索事实核查人员如何在声明优先级排序中使用多维核查价值因素的探针，同时探究事实核查人员的需求，并探索满足这些需求的设计空间。
我们与 16 名专业事实核查员一起开展了一项研究，旨在调查：1）参与者如何评估不同核查维度的相对重要性，并在索赔选择中应用不同的优先级；2）他们如何创建基于 GPT 的定制搜索过滤器以及相应的优点和局限性；3）他们使用我们的原型的整体用户体验。我们的工作在多维 IR 相关性和事实核查可核性之间做出了概念贡献，研究结果证明了相应工具支持的价值。具体来说，我们发现了事实核查员隐含使用的分层优先级策略，揭示了他们工作流程中一个未被充分探索的方面，并提出了可行的设计建议，以改进跨多维可核查性的索赔分类，并通过 LLM 集成定制此流程。]]></description>
      <guid>https://arxiv.org/abs/2412.08185</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于学术本体生成的大型语言模型：工程领域的广泛分析</title>
      <link>https://arxiv.org/abs/2412.08258</link>
      <description><![CDATA[arXiv:2412.08258v1 公告类型：交叉 
摘要：研究主题的本体对于构建科学知识、使科学家能够浏览大量研究以及构成搜索引擎和推荐系统等智能系统的骨干至关重要。然而，手动创建这些本体既昂贵又缓慢，而且往往会导致过时和过于笼统的表示。作为一种解决方案，研究人员一直在研究如何自动化或半自动化生成这些本体的过程。本文全面分析了大型语言模型 (LLM) 识别不同研究主题之间语义关系的能力，这是开发此类本体的关键步骤。为此，我们基于 IEEE 词库开发了一个黄金标准来评估识别主题对之间四种关系类型的任务：更广泛、更狭窄、相同和其他。我们的研究评估了 17 个 LLM 的性能，这些 LLM 在规模、可访问性（开放与专有）和模型类型（完整与量化）方面有所不同，同时还评估了四种零样本推理策略。一些模型取得了出色的成绩，包括 Mixtral-8x7B、Dolphin-Mistral-7B 和 Claude 3 Sonnet，F1 分数分别为 0.847、0.920 和 0.967。此外，我们的研究结果表明，较小的量化模型通过快速工程优化后，可以提供与更大的专有模型相当的性能，同时需要的计算资源要少得多。]]></description>
      <guid>https://arxiv.org/abs/2412.08258</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NyayaAnumana 和 INLegalLlama：最大的印度法律判决预测数据集和用于增强决策分析的专用语言模型</title>
      <link>https://arxiv.org/abs/2412.08385</link>
      <description><![CDATA[arXiv:2412.08385v1 公告类型：交叉 
摘要：人工智能 (AI) 与法律判决预测 (LJP) 的整合有可能改变法律格局，特别是在印度这样的司法管辖区，那里有大量积压案件给法律系统带来负担。本文介绍了 NyayaAnumana，这是为 LJP 编制的最大、最多样化的印度法律案例语料库，共包含 7,02,945 个预处理案例。NyayaAnumana 结合了大多数主要印度语言的单词“Nyay”（判决）和“Anuman”（预测或推断），包括来自最高法院、高等法院、审裁法院、地区法院和日常命令的广泛案件，因此提供了无与伦比的多样性和覆盖范围。我们的数据集超越了 PredEx 和 ILDC 等现有数据集，为法律领域的高级 AI 研究提供了全面的基础。
除了数据集之外，我们还介绍了 INLegalLlama，这是一种针对印度法律体系的复杂性而量身定制的领域特定生成式大型语言模型 (LLM)。它是通过基于基础 LLaMa 模型的两阶段训练方法开发的。首先，使用持续预训练注入印度法律文件。其次，进行特定于任务的监督微调。这种方法使模型能够更深入地了解法律背景。
我们的实验表明，整合各种法院数据可显著提高模型准确性，在预测任务中实现约 90% 的 F1 分数。INLegalLlama 不仅提高了预测准确性，而且还提供了易于理解的解释，满足了 AI 辅助法律决策对可解释性的需求。]]></description>
      <guid>https://arxiv.org/abs/2412.08385</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>InvDiff：扩散模型中减轻偏差的不变指导</title>
      <link>https://arxiv.org/abs/2412.08480</link>
      <description><![CDATA[arXiv:2412.08480v1 公告类型：交叉 
摘要：作为最成功的生成模型之一，扩散模型在合成高质量图像方面表现出了显著的效果。这些模型以无监督的方式学习底层的高维数据分布。尽管扩散模型取得了成功，但它们是高度数据驱动的，容易继承现实世界数据中存在的不平衡和偏差。一些研究试图通过为已知偏差设计文本提示或使用偏差标签构建无偏数据来解决这些问题。虽然这些方法显示出更好的结果，但现实世界的场景通常包含各种未知的偏差，而获得偏差标签尤其具有挑战性。在本文中，我们强调了在不依赖辅助偏差注释的情况下减轻预训练扩散模型中偏差的必要性。为了解决这个问题，我们提出了一个框架 InvDiff，旨在学习用于扩散指导的不变语义信息。具体来说，我们建议识别训练数据中的潜在偏差并设计一个新的去偏差训练目标。然后，我们采用轻量级可训练模块，该模块自动保留不变的语义信息，并使用它同时引导扩散模型的采样过程朝着无偏结果发展。值得注意的是，我们只需要在轻量级可学习模块中学习少量参数，而无需改变预先训练的扩散模型。此外，我们提供了理论保证，即 InvDiff 的实现相当于降低泛化的错误上限。在三个公开可用的基准上进行的大量实验结果表明，InvDiff 有效地减少了偏差，同时保持了图像生成的质量。我们的代码可在 https://github.com/Hundredl/InvDiff 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.08480</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 Graph-RAG 和 Prompt Engineering 增强基于 LLM 的自动化需求可追溯性和合规性检查</title>
      <link>https://arxiv.org/abs/2412.08593</link>
      <description><![CDATA[arXiv:2412.08593v1 公告类型：交叉 
摘要：确保软件需求规范 (SRS) 与更高级别的组织或国家要求保持一致至关重要，尤其是在金融和航空航天等受监管的环境中。在这些领域，保持一致性、遵守监管框架、最大限度地减少错误和满足关键期望对于系统的可靠运行至关重要。大型语言模型 (LLM) 的广泛采用凸显了它们的巨大潜力，但在检索相关信息和增强推理能力方面仍有很大的改进空间。这项研究表明，将强大的 Graph-RAG 框架与先进的提示工程技术（如思维链和思维树）相结合，可以显着提高性能。与基线 RAG 方法和简单的提示策略相比，这种方法提供了更准确和上下文感知的结果。虽然这种方法在性能上表现出显着的改进，但它也带来了挑战。在不同环境中实施既昂贵又复杂，需要仔细适应特定场景。此外，它的有效性在很大程度上依赖于完整和准确的输入数据，而这些数据可能并不总是随时可用的，这进一步限制了它的可扩展性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2412.08593</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行表示学习以用于推荐</title>
      <link>https://arxiv.org/abs/2310.15950</link>
      <description><![CDATA[arXiv:2310.15950v5 公告类型：替换 
摘要：在深度学习和图神经网络的影响下，推荐系统取得了重大进步，特别是在捕捉复杂的用户-项目关系方面。然而，这些基于图的推荐器严重依赖基于 ID 的数据，可能会忽略与用户和项目相关的有价值的文本信息，导致学习到的表示信息量较少。此外，隐式反馈数据的使用会引入潜在的噪音和偏差，对用户偏好学习的有效性构成挑战。虽然将大型语言模型 (LLM) 集成到传统的基于 ID 的推荐器中引起了人们的关注，但为了在实际推荐系统中有效实施，需要解决诸如可扩展性问题、纯文本依赖的限制和提示输入约束等挑战。为了应对这些挑战，我们提出了一个与模型无关的框架 RLMRec，旨在通过 LLM 赋能的表示学习来增强现有的推荐器。它提出了一种将表示学习与 LLM 相结合的推荐范式，以捕捉用户行为和偏好的复杂语义方面。RLMRec 结合辅助文本信号，开发由 LLM 赋能的用户/项目分析范式，并通过跨视图对齐框架将 LLM 的语义空间与协作关系信号的表示空间对齐。这项工作进一步建立了理论基础，证明通过互信息最大化结合文本信号可以提高表示的质量。在我们的评估中，我们将 RLMRec 与最先进的推荐模型相结合，同时分析了其效率和对噪声数据的鲁棒性。我们的实现代码可在 https://github.com/HKUDS/RLMRec 获得。]]></description>
      <guid>https://arxiv.org/abs/2310.15950</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MARec：冷启动建议的元数据对齐</title>
      <link>https://arxiv.org/abs/2404.13298</link>
      <description><![CDATA[arXiv:2404.13298v3 公告类型：替换 
摘要：对于许多推荐系统，主要数据源是用户点击的历史记录。相关的点击矩阵通常非常稀疏，因为用户 x 产品的数量可能远大于点击次数。这种稀疏性在冷启动设置中更加突出，这使得有效使用元数据信息至关重要。在这项工作中，我们提出了一种通过利用内容元数据来解决冷启动推荐的简单方法，即冷启动推荐的元数据对齐。我们表明，这种方法可以轻松增强现有的矩阵分解和自动编码器方法，从而能够在更温暖的设置中平稳过渡到表现最佳的算法。我们的实验结果表明了三个独立的贡献：首先，我们表明，我们提出的框架在具有不同稀疏性和规模特征的 4 个冷启动数据集上大大超过了 SOTA 结果，在报告的排名指标上的增益范围从 +8.4% 到 +53.8%；第二，我们对语义特征的效用进行了消融研究，并证明利用这些特征获得的额外收益在+46.8%到+105.5%之间；第三，我们的方法在热身设置中具有很强的竞争力，我们提出的闭式解决方案平均仅比 SOTA 结果高出 0.8%。]]></description>
      <guid>https://arxiv.org/abs/2404.13298</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>