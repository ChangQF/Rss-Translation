<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>https://arxiv.org/rss/</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 31 Jan 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于 LLM 推荐的数据高效微调</title>
      <link>https://arxiv.org/abs/2401.17197</link>
      <description><![CDATA[利用大型语言模型（LLM）进行推荐最近引起了相当多的关注，其中微调在 LLM 的适应中发挥着关键作用。然而，在快速扩展的推荐数据上微调法学硕士的成本限制了其实际应用。为了应对这一挑战，小样本微调提供了一种很有前途的方法，可以使法学硕士快速适应新的推荐数据。我们提出了基于 LLM 的高效推荐的数据修剪任务，旨在识别为 LLM 的小样本微调量身定制的代表性样本。虽然核心集选择与所提出的任务密切相关，但现有的核心集选择方法通常依赖于次优启发式指标，或者需要对大规模推荐数据进行成本高昂的优化。
  为了解决这些问题，我们在基于LLM的推荐背景下引入了数据修剪任务的两个目标：1）高精度旨在识别可以带来高整体性能的有影响力的样本； 2）高效率强调了数据修剪过程的低成本。为了实现这两个目标，我们提出了一种基于两个分数（即影响分数和努力分数）的新颖数据修剪方法，以有效地识别有影响力的样本。特别是，引入影响分数来准确估计样本去除对整体性能的影响。为了实现数据修剪过程的低成本，我们使用小型代理模型来代替 LLM 以获得影响力得分。考虑到替代模型和法学硕士之间的潜在差距，我们进一步提出了一个努力分数，以优先考虑专门针对法学硕士的一些硬样本。三个现实世界数据集的实证结果验证了我们提出的方法的有效性。特别是，所提出的方法仅使用 2% 的样本就超越了全数据微调，减少了 97% 的时间成本。]]></description>
      <guid>https://arxiv.org/abs/2401.17197</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:02 GMT</pubDate>
    </item>
    <item>
      <title>KAUCUS：用于培训语言模型助手的知识增强用户模拟器</title>
      <link>https://arxiv.org/abs/2401.16454</link>
      <description><![CDATA[通过创建可以生成有用交互数据的模拟器，可以开发有效的多轮指令跟踪助手。除了依赖其内在权重之外，理想的用户模拟器还应该能够以其原始形式快速引导外部知识，以模拟互联网上可用的文本的多样性。以前的用户模拟器通常缺乏多样性，大多是封闭的领域，并且需要严格的模式，这使得它们无法有效地快速扩展以合并外部知识。在这方面，我们引入了 Kaucus，一个知识增强的用户模拟器框架，概述了创建多样化用户模拟器的过程，该过程可以无缝地利用外部知识并有利于下游辅助模型训练。通过两个基于 GPT-J 的模拟器，即检索增强模拟器和摘要控制模拟器，我们生成不同的模拟器辅助交互。通过基于奖励和偏好模型的评估，我们发现这些交互可以作为有用的训练数据并创建更有用的下游助手。我们还发现，通过检索增强或摘要控制整合知识有助于创造更好的助手。]]></description>
      <guid>https://arxiv.org/abs/2401.16454</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:02 GMT</pubDate>
    </item>
    <item>
      <title>剖析用户对搜索结果解释的需求</title>
      <link>https://arxiv.org/abs/2401.16509</link>
      <description><![CDATA[人们对搜索引擎透明度的需求日益增长，以了解搜索结果的策划方式并增强用户的信任。先前的研究引入了搜索结果解释，重点是如何解释，假设解释是有益的。我们的研究后退一步来检查是否需要搜索解释以及它们何时可能提供好处。此外，我们还总结了有用解释的关键特征，并分享了用户对 Google 和 Bing 提供的解释功能的看法。对非技术人员的采访表明，用户并不总是寻求或理解搜索解释，并且大多希望它们能够完成复杂且关键的任务。他们发现谷歌的搜索解释过于明显，但很欣赏谷歌对搜索结果提出质疑的能力。根据我们的研究结果，我们提供搜索引擎的设计建议和解释，以帮助用户更好地评估搜索结果并增强他们的搜索体验。]]></description>
      <guid>https://arxiv.org/abs/2401.16509</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:02 GMT</pubDate>
    </item>
    <item>
      <title>数学抄袭的分类</title>
      <link>https://arxiv.org/abs/2401.16969</link>
      <description><![CDATA[抄袭是一个紧迫的问题，尤其是在大型语言模型可用的情况下。现有的抄袭检测系统可以可靠地发现复制和适度改写的文本，但无法发现抄袭思想，尤其是在大量使用形式数学符号的数学科学中。我们做出了两项贡献。首先，我们通过注释可能被抄袭的 122 个科学文档对来建立数学内容重用的分类法。其次，我们分析了在新建立的分类法上检测抄袭和数学内容相似性的最佳方法。我们发现，针对抄袭和数学内容相似度表现最好的方法的总体检测得分 (PlagDet) 分别为 0.06 和 0.16。性能最佳的方法未能检测到所有七种新建立的数学相似性类型中的大多数情况。概述的贡献将有利于抄袭检测系统、推荐系统、问答系统和搜索引擎的研究。我们向社区提供实验的代码和带注释的数据集：https://github.com/gipplab/Taxonomy-of-Mathematical-Plagiarism]]></description>
      <guid>https://arxiv.org/abs/2401.16969</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:01 GMT</pubDate>
    </item>
    <item>
      <title>Re3val：强化和重新排序的生成检索</title>
      <link>https://arxiv.org/abs/2401.16979</link>
      <description><![CDATA[生成检索模型将指向语料库中信息的指针编码为模型参数内的索引。这些模型作为更大管道的一部分，为知识密集型 NLP 任务生成检索信息条件。然而，我们发现了两个局限性：生成检索不考虑上下文信息。其次，无法为下游读者调整检索，因为解码页面标题是不可微分的操作。本文介绍了 Re3val，它使用有限的数据通过生成重排序和强化学习进行训练。 Re3val 利用通过密集通道检索获取的上下文对检索到的页面标题进行重新排序，并利用 REINFORCE 最大限度地提高受约束解码产生的奖励。此外，我们从预训练数据集中生成问题，以减轻认知不确定性并弥合预训练和微调数据集之间的领域差距。随后，我们使用重新排名页面标题从 KILT 数据库中提取上下文并重新排名。在确定前 5 个重新排名的上下文后，Re3val 展示了与五个 KILT 数据集的所有其他生成检索模型相比的前 1 个 KILT 分数。]]></description>
      <guid>https://arxiv.org/abs/2401.16979</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:01 GMT</pubDate>
    </item>
    <item>
      <title>AutoIE：从科学文献中提取信息的自动化框架</title>
      <link>https://arxiv.org/abs/2401.16672</link>
      <description><![CDATA[在快速发展的科学研究领域，从不断增长的科学论文中有效地提取关键信息仍然是一项艰巨的挑战。本文介绍了一种创新框架，旨在自动从科学 PDF 文档中提取重要数据，使研究人员能够更轻松地洞察未来的研究轨迹。 AutoIE 独特地集成了四个新颖的​​组件：（1）基于多语义特征融合的 PDF 文档布局分析方法； (2) 科学文本中的高级功能块识别； (3) 提取和关联分子筛合成信息的协同技术； （4）针对分子筛文献量身定制的在线学习范式。我们的 SBERT 模型在 CoNLL04 和 ADE 数据集上获得了 87.19 和 89.65 的高 Marco F1 分数。此外，AutoIE在石化分子筛合成领域的实际应用也证明了其功效，高达78%的准确率。这项研究为增强分子筛合成中的数据管理和解释铺平了道路。对于这个专业领域的经验丰富的专家和新手来说，这是一笔宝贵的财富。]]></description>
      <guid>https://arxiv.org/abs/2401.16672</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:00 GMT</pubDate>
    </item>
    <item>
      <title>检测科学传播中的法学硕士辅助写作：我们到了吗？</title>
      <link>https://arxiv.org/abs/2401.16807</link>
      <description><![CDATA[以 ChatGPT 为代表的大型语言模型 (LLM) 极大地重塑了文本生成，特别是在写作辅助领域。虽然道德考虑强调了透明承认法学硕士使用的重要性，特别是在科学传播领域，但真正的承认仍然很少见。鼓励准确确认法学硕士辅助写作的一个潜在途径是使用自动检测器。我们对四个尖端的 LLM 生成的文本检测器的评估表明，与一个简单的临时检测器相比，它们的性能不理想，该检测器旨在识别 LLM 扩散期间突然的写作风格变化。我们认为，开发专门用于法学硕士辅助书写检测的专用检测器是必要的。此类检测器可以在促进对法学硕士参与科学传播的更真实认可、解决当前致谢实践中的挑战方面发挥至关重要的作用。]]></description>
      <guid>https://arxiv.org/abs/2401.16807</guid>
      <pubDate>Wed, 31 Jan 2024 18:13:00 GMT</pubDate>
    </item>
    <item>
      <title>走向广告牌广告免费时段分配的遗憾</title>
      <link>https://arxiv.org/abs/2401.16464</link>
      <description><![CDATA[在客户中创造并最大化影响力是广告商的核心目标之一，因此，近年来仍然是一个活跃的研究领域。在这种广告技术中，广告商在付费的基础上联系影响力提供者以获取其内容的特定数量的观看次数。现在，如果影响力提供者可以提供所需的观看次数或更多，他将收到全额付款，否则将收到部分付款。对于一个影响力提供者来说，他的观点多了或者少了，对他来说都是一种损失。这被形式化为“遗憾”，自然地，在影响力提供者的背景下，目标将是最小化这个数量。在本文中，我们在广告牌广告的背景下解决这个问题，并将其视为离散优化问题。我们针对这个问题提出了四种有效的解决方法，并对它们进行分析以了解它们的时间和空间复杂度。我们使用现实数据集实现所有解决方案方法，并将获得的结果与文献中现有的解决方案进行比较。我们观察到，所提出的解决方案可以减少遗憾，同时减少计算时间。]]></description>
      <guid>https://arxiv.org/abs/2401.16464</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:59 GMT</pubDate>
    </item>
    <item>
      <title>FakeClaim：用于识别 2023 年以色列-哈马斯战争假新闻的多平台驱动数据集</title>
      <link>https://arxiv.org/abs/2401.16625</link>
      <description><![CDATA[我们贡献了第一个公开的数据集，其中包含来自不同平台的事实主张和关于 2023 年以色列-哈马斯战争的虚假 YouTube 视频，用于自动虚假 YouTube 视频分类。 FakeClaim 数据以 30 种语言从 60 个事实核查组织收集，并补充了来自事实核查组织的元数据，这些元数据由经过培训的专门从事事实核查的记者策划。此外，我们使用文本信息和用户评论对 YouTube 视频子集中的假视频进行分类。我们使用预先训练的模型对具有不同特征组合的每个视频进行分类。我们性能最佳的微调语言模型 Universal Sentence Encoder (USE) 的 Macro F1 达到 87\%，这表明经过训练的模型有助于使用用户讨论中的评论来揭穿假视频。该数据集可在 Github\footnote{https://github.com/Gautamshahi/FakeClaim} 上找到]]></description>
      <guid>https://arxiv.org/abs/2401.16625</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:59 GMT</pubDate>
    </item>
    <item>
      <title>历史感知会话密集检索</title>
      <link>https://arxiv.org/abs/2401.16659</link>
      <description><![CDATA[会话式搜索通过支持用户和系统之间的多轮交互来促进复杂的信息检索。支持此类交互需要全面理解会话输入，以便根据历史信息制定良好的搜索查询。特别是，搜索查询应包括先前对话轮次的相关信息。然而，当前的会话密集检索方法主要依赖于使用整个会话搜索会话来微调预先训练的临时检索器，该会话可能冗长且嘈杂。此外，现有方法受到现有数据集中手动监督信号数量的限制。为了解决上述问题，我们提出了一种历史感知会话密集检索（HAConvDR）系统，该系统融合了两种思想：上下文去噪查询重构和基于历史转折的实际影响自动挖掘监督信号。对两个公共对话搜索数据集的实验证明了 HAConvDR 改进的历史建模能力，特别是对于主题转移的长时间对话。]]></description>
      <guid>https://arxiv.org/abs/2401.16659</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:59 GMT</pubDate>
    </item>
    <item>
      <title>结合主题建模和引文网络分析来研究欧洲人权法院关于尊重私人和家庭生活的权利的判例法</title>
      <link>https://arxiv.org/abs/2401.16429</link>
      <description><![CDATA[随着HUDOC等法律判例法数据库持续快速增长，法律研究人员找到有效的方法来处理如此大规模的数据集已变得至关重要。此类判例法数据库通常由案例的文本内容以及案例之间的引用组成。本文重点关注欧洲人权法院关于《欧洲人权公约》第 8 条的判例法，即尊重私人和家庭生活、家庭和通信的权利。在本研究中，我们展示并比较了主题建模和引文网络分别根据其一般主题和引文模式查找和组织第 8 条判例法的潜力。此外，我们还探讨了与仅应用其中一种方法相比，结合这两种技术是否会带来更好的结果。我们在 Aricle 8 驱逐判例法的独特手动收集和注释数据集上评估了组合方法的有效性。我们的实验结果表明，我们的组合（基于文本和引文）方法在查找和分组判例法方面提供了最佳结果，为学者提供了一种有效的方法来提取和分析特定问题的相关案例。]]></description>
      <guid>https://arxiv.org/abs/2401.16429</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:58 GMT</pubDate>
    </item>
    <item>
      <title>Covid-19相关论文的信息检索和提取工具</title>
      <link>https://arxiv.org/abs/2401.16430</link>
      <description><![CDATA[背景：COVID-19 大流行对全世界的卫生系统造成了严重影响。它的重要性以及个人和组织对制定解决该问题的对策的兴趣日益浓厚，导致科学期刊上的新研究激增。目标：我们寻求开发一种工具，以一种新颖的方式整合应用于 COVID-19 开放研究数据集 (CORD-19) 的信息检索 (IR) 和提取 (IE) 的各个方面。本文的主要重点是为研究人员提供更好的 COVID-19 相关论文搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。方法：我们基于研究方面，应用潜在狄利克雷分配（LDA）对 CORD-19 中所有英文摘要的主题进行建模。每个摘要的相关命名实体都被提取出来并链接到相应的 UMLS 概念。使用正则表达式和 K 最近邻算法对相关论文进行排名。结果：我们的工具显示出通过自动对 CORD-19 论文进行基于主题的搜索来帮助研究人员的潜力。尽管如此，我们发现，更微调的主题建模参数和提高研究方面分类器模型的准确性可能会带来更准确和可靠的工具。结论：我们强调需要新的自动化工具来帮助研究人员找到相关的 COVID-19 文档，并自动提取其中包含的有用信息。我们的工作表明，结合不同的算法和模型可能会带来浏览 COVID-19 纸质数据的新方法。]]></description>
      <guid>https://arxiv.org/abs/2401.16430</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:58 GMT</pubDate>
    </item>
    <item>
      <title>通过在线广告中的自我监督预训练提高转化率预测</title>
      <link>https://arxiv.org/abs/2401.16432</link>
      <description><![CDATA[预测转化率 (CVR) 的任务是在线广告系统的核心，旨在优化出价以满足广告商的绩效要求。即使最近深度神经网络兴起，这些预测通常是由因式分解机 (FM) 做出的，尤其是在推理延迟至关重要的商业环境中。这些模型使用逻辑回归框架对由过去用户活动形成的与当前任务相关的标记表格数据进行训练。
  许多广告商只关心点击归因的转化。预测给定点击转化的训练模型的一个主要挑战来自数据稀疏性——点击很少，归因于点击的转化甚至更少。然而，通过添加非点击归因于训练集的转化来减轻稀疏性会损害模型校准。由于校准对于实现广告商目标至关重要，因此这是不可行的。
  在这项工作中，我们使用众所周知的自监督预训练思想，并使用对所有转化事件（包括点击归因和非点击归因）进行训练的辅助自动编码器模型作为特征提取器来丰富主要的 CVR 预测模型。由于主模型不会对非点击归因的转化进行训练，因此这不会影响校准。我们通过使用专为表格数据设计的损失函数，将基本的自监督预训练思想应用于我们的在线广告设置，通过确保自动编码器的稳定性来促进持续学习，并将神经网络合并到大规模实时广告中在严格的延迟限制下对数万个广告进行排名，并且不会产生重大的工程成本。我们在离线、训练期间和在线 A/B 测试中都展示了改进。继 A/B 测试取得成功后，我们的解决方案现已完全部署到雅虎原生广告系统中。]]></description>
      <guid>https://arxiv.org/abs/2401.16432</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:58 GMT</pubDate>
    </item>
    <item>
      <title>通过神经模式关联器进行篮内推荐</title>
      <link>https://arxiv.org/abs/2401.16433</link>
      <description><![CDATA[篮内推荐（WBR）是指在购物过程中推荐商品直至完成非空购物篮的任务。虽然该领域的最新创新在基准数据集上展示了显着的性能改进，但它们往往忽视了实践中用户行为的复杂性，例如 1) 多种购物意图的共存，2) 此类意图的多粒度，以及 3)购物过程中的交错行为（转换意图）。本文提出了神经模式关联器（NPA），这是一种深度项目关联挖掘模型，可以显式地模拟上述因素。具体来说，受矢量量化的启发，NPA 模型学习将常见的用户意图（或项目组合模式）编码为量化表示（又名密码本），从而允许在推理阶段通过注意力驱动的查找来识别用户的购物意图。这会产生连贯且可自我解释的建议。我们在多个广泛的数据集上评估了所提出的 NPA 模型，涵盖杂货电子商务（购物篮完成）和音乐（播放列表扩展）领域，其中我们的定量评估表明 NPA 模型显着优于各种现有的 WBR 解决方案，反映了明确建模复杂用户意图的好处。]]></description>
      <guid>https://arxiv.org/abs/2401.16433</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:58 GMT</pubDate>
    </item>
    <item>
      <title>通过推荐系统正则化减轻位置偏差</title>
      <link>https://arxiv.org/abs/2401.16427</link>
      <description><![CDATA[公平性是近年来的热门研究课题。与公平密切相关的一个研究课题是偏见和去偏见。在不同类型的偏见问题中，立场偏见是最常见的症状之一。位置偏差意味着位于推荐列表顶部的推荐项目比位于同一列表底部的项目更有可能被点击。为了缓解这个问题，我们建议使用正则化技术来减少偏差效应。在实验部分，我们证明我们的方法优于其他现代算法。]]></description>
      <guid>https://arxiv.org/abs/2401.16427</guid>
      <pubDate>Wed, 31 Jan 2024 18:12:57 GMT</pubDate>
    </item>
    </channel>
</rss>