<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>排名的公平性不断提高：同质网络上的 HITS 和 PageRank</title>
      <link>https://arxiv.org/abs/2402.13787</link>
      <description><![CDATA[arXiv:2402.13787v3 公告类型：replace-cross
摘要：在本文中，我们研究了链接分析算法阻止少数群体达到高排名位置的条件。我们发现，最常见的基于链接的算法使用中心性指标（例如 PageRank 和 HITS），可以重现甚至放大针对网络中少数群体的偏见。然而，它们的行为有所不同：一方面，我们凭经验表明 PageRank 反映了大多数排名位置的度分布，并且它可以均衡排名靠前的节点中少数群体的代表性；另一方面，我们发现 HITS 通过新颖的理论分析并得到实证结果的支持，放大了同质网络中预先存在的偏见。我们发现 HITS 中偏差放大的根本原因是网络中存在的同质性水平，通过具有两个社区的不断发展的网络模型进行建模。我们阐述了对合成数据集和真实数据集的理论分析，并提出了未来工作的方向。]]></description>
      <guid>https://arxiv.org/abs/2402.13787</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>召回率、鲁棒性和词典编纂评估</title>
      <link>https://arxiv.org/abs/2302.11370</link>
      <description><![CDATA[arXiv:2302.11370v5 公告类型：替换
摘要：虽然最初是为了评估项目集而开发的，但召回率通常用于评估项目的排名，包括推荐系统、检索系统和其他机器学习系统生成的项目的排名。在没有正式评价动机的情况下应用回忆导致了对回忆的批评，认为它是一种模糊或不恰当的措施。鉴于这场争论，我们从正式的角度反思了排名中召回率的衡量。我们的分析由三个原则组成：召回率、鲁棒性和词典编排评估。首先，我们正式将“回忆导向”定义为指标对有兴趣查找每个相关项目的用户的敏感性。其次，我们从对可能的内容消费者和提供者的鲁棒性角度分析召回导向，将召回与最近关于公平排名的对话联系起来。最后，我们通过开发一种基于词典比较的实用的基于偏好的评估方法来扩展回忆的概念和理论处理。通过对三个推荐任务和 17 个信息检索任务的广泛实证分析，我们确定我们的新评估方法 lexirecall 具有收敛效度（即，它与现有的召回指标相关），并且在判别力和稳定性方面表现出更高的灵敏度在缺少标签的情况下。我们的概念、理论和实证分析极大地加深了我们对召回的理解，并通过与稳健性和公平性的联系推动其采用。]]></description>
      <guid>https://arxiv.org/abs/2302.11370</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程回归进行多兴趣个性化检索的基于密度的用户表示</title>
      <link>https://arxiv.org/abs/2310.20091</link>
      <description><![CDATA[arXiv:2310.20091v4 公告类型：替换
摘要：对用户多样化和动态兴趣的准确建模仍然是个性化推荐系统设计中的重大挑战。现有的用户建模方法（例如单点和多点表示）存在局限性。准确性、多样性、计算成本和适应性。为了克服这些缺陷，我们引入了基于密度的用户表示（DUR），这是一种利用高斯过程回归进行有效的多兴趣推荐和检索的新颖模型。我们的方法 GPR4DUR 利用 DUR 来捕获用户兴趣变化，无需手动调整，结合了不确定性意识，并且可以很好地扩展到大量用户。使用真实离线数据集的实验证实了 GPR4DUR 的适应性和效率，而模拟用户的在线实验则证明了其通过有效利用模型不确定性来解决探索与利用权衡的能力。]]></description>
      <guid>https://arxiv.org/abs/2310.20091</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型的多角色功能进行开放域问答</title>
      <link>https://arxiv.org/abs/2403.05217</link>
      <description><![CDATA[arXiv:2403.05217v1 公告类型：交叉
摘要：开放域问答（ODQA）已成为信息系统中的关键研究热点。现有的方法遵循两个主要范式来收集证据：（1）\textit{retrieve-then-read}范式从外部语料库中检索相关文档； (2) \textit{generate-then-read} 范式采用大型语言模型 (LLM) 来生成相关文档。然而，两者都不能完全满足证据的多方面要求。为此，我们提出了 LLMQA，这是一个通用框架，它将 ODQA 过程制定为三个基本步骤：查询扩展、文档选择和答案生成，结合了基于检索和基于生成的证据的优势。由于法学硕士展示了完成各种任务的出色能力，因此我们指示法学硕士在我们的框架内扮演生成者、重新排序者和评估者等多重角色，将他们整合到 ODQA 流程中进行协作。此外，我们引入了一种新颖的提示优化算法来完善角色扮演提示并引导法学硕士产生更高质量的证据和答案。在广泛使用的基准（NQ、WebQ 和 TriviaQA）上进行的大量实验结果表明，LLMMA 在答案准确性和证据质量方面均实现了最佳性能，展示了其推进 ODQA 研究和应用的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.05217</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>当代大数据推荐系统及其应用：调查</title>
      <link>https://arxiv.org/abs/2206.02631</link>
      <description><![CDATA[arXiv:2206.02631v3 公告类型：替换
摘要：这篇调查论文对推荐系统的演变和当代前景进行了全面分析，推荐系统已广泛应用于无数的网络应用程序中。它深入研究了为在线产品或服务量身定制的个性化推荐方法的进展，将一系列推荐技术分为四个主要类别：基于内容的、协作过滤的、基于知识的和混合方法，每种方法都旨在满足特定的上下文。该文件深入回顾了推荐系统领域的历史基础和前沿创新，特别关注利用大数据分析的实施。它进一步概述并探讨了当前一代推荐系统遇到的主要挑战，包括与数据稀疏性、可扩展性以及多样化推荐输出的必要性相关的问题。该调查强调这些挑战是该学科后续研究工作的有希望的方向。此外，本文还研究了推荐系统驱动的各种现实生活应用程序，解决了将这些系统无缝集成到日常生活中所遇到的障碍。最终，该调查强调了大数据技术推动的推荐系统的进步如何有可能显着增强现实世界的体验。]]></description>
      <guid>https://arxiv.org/abs/2206.02631</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士与律师：在英国大型判例法数据集中识别简易判决的子集</title>
      <link>https://arxiv.org/abs/2403.04791</link>
      <description><![CDATA[arXiv:2403.04791v1 公告类型：交叉
摘要：为了进行法律的计算研究，有效识别与特​​定法律问题相关的法院判决数据集是一项至关重要但具有挑战性的工作。这项研究解决了与大型法律语料库合作的文献中关于如何将案件（在我们的案件简易判决中）与英国法院判决的大型语料库分离出来的空白。我们介绍了两种计算方法的比较分析：(1) 基于传统自然语言处理的方法，利用专家生成的关键字和逻辑运算符；(2) Claude 2 大语言模型的创新应用，根据内容对案例进行分类具体提示。我们使用包含 356,011 个英国法院判决的剑桥法律语料库，并确定大型语言模型的加权 F1 分数为 0.94，而关键字的加权 F1 分数为 0.78。尽管进行了迭代细化，基于关键字的搜索逻辑仍无法捕捉法律语言中的细微差别。我们识别并提取了 3,102 个简易判决案件，使我们能够绘制它们在一段时间内在英国各个法院的分布情况。该论文标志着采用先进的自然语言处理来解决核心法律研究任务的开创性一步，展示了这些技术如何弥合系统性差距并提高法律信息的可访问性。我们共享提取的数据集指标以支持对总结判断的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2403.04791</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>自动从半结构化采访记录中提取信息</title>
      <link>https://arxiv.org/abs/2403.04819</link>
      <description><![CDATA[arXiv:2403.04819v1 公告类型：交叉
摘要：本文探讨了旨在从半结构化访谈笔录中提取信息的自动化系统的开发和应用。鉴于传统定性分析方法（例如编码）的劳动密集型性质，对能够促进分析过程的工具有很大的需求。我们的研究调查了各种主题建模技术，并得出结论：分析采访文本的最佳模型是 BERT 嵌入和 HDBSCAN 聚类的组合。我们提供了一个用户友好的软件原型，使研究人员（包括那些没有编程技能的人员）能够有效地处理和可视化访谈数据的主题结构。该工具不仅有利于定性分析的初始阶段，而且还提供了对所揭示主题的相互关联性的见解，从而增强了定性分析的深度。]]></description>
      <guid>https://arxiv.org/abs/2403.04819</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>记不住长文档中的详细信息？你需要一些休息和恢复</title>
      <link>https://arxiv.org/abs/2403.05004</link>
      <description><![CDATA[arXiv:2403.05004v1 公告类型：交叉
摘要：长上下文大语言模型（LLM）有望完成长文档问答（QA）等任务，但它们往往会错过上下文文档中间的重要信息（arXiv：2307.03172v3）。在这里，我们引入 $\textit{R&amp;R}$ ——两种新颖的基于提示的方法的组合，称为 $\textit{reprompting}$ 和 $\textit{in-contextretrieve}$ (ICR) ——以缓解这种效果在基于文档的 QA 中。在重新提示中，我们在整个上下文文档中定期重复提示指令，以提醒法学硕士其原始任务。在 ICR 中，我们不是指示 LLM 直接回答问题，而是指示它检索与给定问题最相关的前 $k$ 段落编号，然后将其用作第二个 QA 提示中的缩写上下文。我们使用 GPT-4 Turbo 和 Claude-2.1 在长达 80k token 的文档上测试 R&amp;R，并观察到 ​​QA 准确度平均提高了 16 个点。我们的进一步分析表明，R&amp;R 提高了基于长文档的 QA 的性能，因为它缩短了相关上下文和指令之间的距离。最后，我们表明，与短上下文分块方法相比，R&amp;R 可以使用更大的块，从而减少 LLM 调用和输出标记的成本，同时最大限度地减少准确性的下降。]]></description>
      <guid>https://arxiv.org/abs/2403.05004</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>嵌入的余弦相似度真的是相似度吗？</title>
      <link>https://arxiv.org/abs/2403.05440</link>
      <description><![CDATA[arXiv:2403.05440v1 公告类型：新
摘要：余弦相似度是两个向量之间角度的余弦，或者等效地是它们归一化之间的点积。一个流行的应用是通过将余弦相似性应用于学习的低维特征嵌入来量化高维对象之间的语义相似性。在实践中，这可能比嵌入向量之间的非标准化点积效果更好，但有时也更糟糕。为了深入了解这一经验观察，我们研究了从正则化线性模型派生的嵌入，其中封闭式解决方案有助于分析洞察。我们通过分析得出余弦相似性如何产生任意且因此无意义的“相似性”。对于某些线性模型，相似性甚至不是唯一的，而对于其他模型，它们则由正则化隐式控制。我们讨论线性模型之外的含义：学习深度模型时采用不同正则化的组合；当对所得嵌入进行余弦相似性时，这些会产生隐式和意想不到的效果，使结果变得不透明并且可能是任意的。基于这些见解，我们警告不要盲目使用余弦相似度并概述替代方案。]]></description>
      <guid>https://arxiv.org/abs/2403.05440</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>SupplyGraph：使用图神经网络进行供应链规划的基准数据集</title>
      <link>https://arxiv.org/abs/2401.15299</link>
      <description><![CDATA[arXiv:2401.15299v1 公告类型：交叉
摘要：图神经网络（GNN）在交通、生物信息学、语言处理和计算机视觉等不同领域获得了广泛的关注。然而，将 GNN 应用到供应链网络的研究明显缺乏。供应链网络本质上是类似图的结构，这使其成为应用 GNN 方法的主要候选者。这为优化、预测和解决最复杂的供应链问题开辟了无限可能。这种方法的一个主要挫折在于缺乏现实世界的基准数据集来促进使用 GNN 研究和解决供应链问题。为了解决这个问题，我们提出了一个现实世界的时间任务基准数据集，该数据集来自孟加拉国领先的快速消费品公司之一，重点关注用于生产目的的供应链规划。该数据集包括作为节点特征的时态数据，以实现销售预测、生产计划和工厂问题识别。通过利用该数据集，研究人员可以利用 GNN 来解决众多供应链问题，从而推进供应链分析和规划领域的发展。来源：https://github.com/CIOL-SUST/SupplyGraph]]></description>
      <guid>https://arxiv.org/abs/2401.15299</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>调整大型语言模型以实现可控推荐</title>
      <link>https://arxiv.org/abs/2403.05063</link>
      <description><![CDATA[arXiv:2403.05063v1 公告类型：新
摘要：受到大型语言模型（LLM）卓越的通用智能的启发，研究人员已经开始探索其在下一代推荐系统中的应用，即会话式、可解释性和可控性的系统。然而，现有文献主要集中于将特定领域的知识整合到法学硕士中以提高准确性，往往忽略了遵循指示的能力。为了解决这一差距，我们首先引入了一系列监督学习任务，并使用源自传统推荐模型的标签进行了增强，旨在明确提高法学硕士遵守特定推荐指令的熟练程度。随后，我们开发了一种基于强化学习的对齐程序，以进一步增强法学硕士响应用户意图和减少格式错误的能力。通过对两个真实世界数据集的广泛实验，我们的方法显着提高了法学硕士遵守推荐系统内指令的能力，同时保持高水平的准确性性能。]]></description>
      <guid>https://arxiv.org/abs/2403.05063</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>具有用户表示排斥的多塔多兴趣推荐</title>
      <link>https://arxiv.org/abs/2403.05122</link>
      <description><![CDATA[arXiv:2403.05122v1 公告类型：新
摘要：在信息过载的时代，推荐系统的价值已得到学术界和工业界的深刻认识。特别是多兴趣顺序推荐是近年来受到越来越多关注的一个子领域。通过生成多用户表示，多兴趣学习模型在理论上和经验上都表现出比单用户表示模型更优越的表达能力。尽管该领域取得了重大进展，但三个主要问题仍然困扰着多兴趣学习方法的性能和可采用性：训练和部署目标之间的差异、无法访问项目信息以及由于其单一性而难以被工业采用。塔式建筑。我们通过提出一种具有用户表示排斥的新颖的多塔多兴趣框架来解决这些挑战。多个大型工业数据集的实验结果证明了我们提出的框架的有效性和普遍性。]]></description>
      <guid>https://arxiv.org/abs/2403.05122</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>Spotify 通过图神经网络进行个性化有声读物推荐</title>
      <link>https://arxiv.org/abs/2403.05185</link>
      <description><![CDATA[arXiv:2403.05185v1 公告类型：新
摘要：在不断发展的数字音频领域，以其音乐和谈话内容而闻名的 Spotify 最近向其庞大的用户群推出了有声读物。虽然这一举措很有希望，但也给个性化推荐带来了重大挑战。与音乐和播客不同，有声读物最初需要付费，在购买前无法轻易浏览，这对推荐的相关性提出了更高的要求。此外，在现有平台中引入新的内容类型会面临极端的数据稀疏性，因为大多数用户不熟悉这种新的内容类型。最后，向数百万用户推荐内容需要模型快速反应且可扩展。为了应对这些挑战，我们利用播客和音乐用户偏好，引入 2T-HGNN，这是一种可扩展的推荐系统，由异构图神经网络 (HGNN) 和两塔 (2T) 模型组成。这种新颖的方法揭示了微妙的项目关系，同时确保低延迟和复杂性。我们将用户与 HGNN 图解耦，并提出了一种创新的多链路邻居采样器。这些选择与 2T 组件一起显着降低了 HGNN 模型的复杂性。涉及数百万用户的实证评估显示，个性化推荐的质量显着提高，新有声读物的启动率提高了 46%，流媒体播放率提高了 23%。有趣的是，我们模型的影响不仅限于有声读物，还使播客等成熟产品受益。]]></description>
      <guid>https://arxiv.org/abs/2403.05185</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>ACORN：向量嵌入和结构化数据的高性能和谓词不可知搜索</title>
      <link>https://arxiv.org/abs/2403.04871</link>
      <description><![CDATA[arXiv:2403.04871v1 公告类型：新
摘要：应用程序越来越多地利用混合模态数据，并且必须联合搜索矢量数据（例如嵌入图像、文本和视频）以及结构化数据（例如属性和关键字）。针对这种混合搜索设置提出的方法要么性能不佳，要么支持严格限制的搜索谓词集（例如，仅一小部分相等谓词），这使得它们对于许多应用程序来说不切实际。为了解决这个问题，我们提出了 ACORN，一种高性能和谓词不可知的混合搜索方法。 ACORN 建立在分层可导航小世界 (HNSW) 之上，这是一种最先进的基于图的近似最近邻索引，并且可以通过扩展现有的 HNSW 库来有效实现。 ACORN 引入了谓词子图遍历的思想来模拟理论上理想但不切实际的混合搜索策略。 ACORN 的谓词不可知构造算法旨在实现这种有效的搜索策略，同时支持广泛的谓词集和查询语义。我们在先前的基准数据集上系统地评估了 ACORN，其中包括简单、低基数谓词集和先前方法不支持的复杂多模态数据集。我们证明 ACORN 在所有数据集上都实现了最先进的性能，在固定召回率下吞吐量提高了 2-1,000 倍，优于之前的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.04871</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习使 GPTRec 与超准确目标保持一致</title>
      <link>https://arxiv.org/abs/2403.04875</link>
      <description><![CDATA[arXiv:2403.04875v1 公告类型：新
摘要：Transformer 模型（例如 BERT4Rec 和 SASRec）的改编，根据基于准确性的指标（例如 NDCG）在顺序推荐任务中实现了最先进的性能。这些模型将项目视为标记，然后采用评分和排名方法（Top-K 策略），其中模型首先计算项目分数，然后根据该分数对它们进行排名。虽然这种方法对于基于准确性的指标效果很好，但很难用它来优化更复杂的超准确指标，例如多样性。最近，使用不同的 Next-K 策略的 GPTRec 模型被提出作为 Top-K 模型的替代方案。与传统的 Top-K 推荐相比，Next-K 逐项生成推荐，因此可以解释复杂的项与项之间的相互依赖性，这对于超准确度测量非常重要。然而，最初的 GPTRec 论文仅关注实验的准确性，需要解决如何针对复杂的超准确指标优化模型。事实上，为超准确目标训练 GPTRec 具有挑战性，因为可用于训练推荐系统的交互训练数据通常需要与超准确推荐目标保持一致。为了解决错位问题，我们使用两阶段方法训练 GPTRec：在第一阶段，我们使用师生方法来训练 GPTRec，模仿传统 Top-K 模型的行为；在第二阶段，我们使用强化学习来调整模型以实现超准确的目标。特别是，我们尝试增加推荐多样性并减少流行度偏差。我们对两个数据集的实验表明，在四分之三的情况下，GPTRec 的 Next-K 生成方法比经典的贪婪重排序技术在准确性和次要指标之间提供了更好的权衡。]]></description>
      <guid>https://arxiv.org/abs/2403.04875</guid>
      <pubDate>Mon, 11 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    </channel>
</rss>