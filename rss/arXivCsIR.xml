<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 07 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>具有图形结构的高级 RAG 模型：优化复杂知识推理和文本生成</title>
      <link>https://arxiv.org/abs/2411.03572</link>
      <description><![CDATA[arXiv:2411.03572v1 公告类型：新
摘要：本研究旨在通过引入图结构来优化现有的检索增强生成模型（RAG），以提高模型在处理复杂知识推理任务时的性能。传统RAG模型在面对复杂的图结构信息（如知识图谱、层级关系等）时存在处理效率不足的问题，影响生成结果的质量和一致性。本研究提出一种结合图神经网络（GNN）处理图结构数据的方案，使模型能够捕捉实体之间的复杂关系，从而提高生成文本的知识一致性和推理能力。实验采用Natural Questions（NQ）数据集，并将其与多个现有的生成模型进行了比较。结果表明，本文提出的基于图的RAG模型在质量、知识一致性和推理能力方面均优于传统生成模型，尤其是在处理需要多维推理的任务时。通过增强检索模块与图神经网络的结合，本研究中的模型能够更好地处理复杂的知识背景信息，在多个实际应用场景中具有广泛的潜在价值。]]></description>
      <guid>https://arxiv.org/abs/2411.03572</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络精华的精华:元搜索引擎</title>
      <link>https://arxiv.org/abs/2411.03701</link>
      <description><![CDATA[arXiv:2411.03701v1 公告类型：新
摘要：网络上的信息源呈指数级增长，而使用搜索引擎等工具搜索信息的技术不断进步，这给用户带来了许多问题，他们不知道哪种工具最适合他们的查询，哪种工具不适合。此时，元搜索引擎开始发挥作用，它通过并行向多个搜索引擎发送查询并优化这些搜索引擎的结果，以通过自己出色的工作提供最佳结果，从而减轻用户负担。这些引擎不拥有网页数据库，而是将搜索词发送到搜索引擎公司维护的数据库，从所有查询的搜索引擎中获取结果，然后编译结果以呈现给用户。在本文中，我们描述了典型元搜索引擎的工作原理，然后根据不同的参数对传统搜索引擎和元搜索引擎进行了比较研究，并展示了元搜索引擎如何优于其他搜索引擎。]]></description>
      <guid>https://arxiv.org/abs/2411.03701</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>合成查询变体与生成大型语言模型的数据融合</title>
      <link>https://arxiv.org/abs/2411.03881</link>
      <description><![CDATA[arXiv:2411.03881v1 公告类型：新
摘要：在信息检索 (IR) 实验中考虑查询方差有利于提高检索效率。特别是基于不同主题相关查询的排名集合比仅基于单个查询的排名检索出更好的结果。最近，生成指令调整的大型语言模型 (LLM) 在捕捉人类语言的各种不同任务上得到了改进。为此，这项工作探索了在数据融合实验中使用指令调整的 LLM 生成的合成查询变体的可行性。更具体地说，我们引入了一种轻量级、无监督且经济高效的方法，该方法利用原则性提示和数据融合技术。在我们的实验中，当提供有关该主题的额外上下文信息时，LLM 会产生更有效的查询。此外，我们基于四个 TREC 新闻专线基准的分析表明，基于合成查询变体的数据融合明显优于单个查询的基线，并且也优于伪相关反馈方法。我们向社区公开分享代码和查询数据集，作为后续研究的资源。]]></description>
      <guid>https://arxiv.org/abs/2411.03881</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为检索者提供细粒度指导：在检索增强生成中利用 LLM 的反馈</title>
      <link>https://arxiv.org/abs/2411.03957</link>
      <description><![CDATA[arXiv:2411.03957v1 公告类型：新
摘要：检索增强生成 (RAG) 已被证明是一种有效的方法，可缓解大型语言模型 (LLM) 中固有的幻觉问题。以前的方法通常基于语义相似性来训练检索器，缺乏对 RAG 的优化。最近的研究提出将检索器与 LLM 的偏好信号对齐。然而，这些偏好信号对于通常语言能力较弱的密集检索器来说通常很难理解和有效学习。从引导式发现学习等教学理论中汲取灵感，我们提出了一个新颖的框架 FiGRet（针对检索器的细粒度指导），它利用 LLM 的语言能力从更细粒度、以信息为中心的角度构建示例，以指导检索器的学习。具体来说，我们的方法利用 LLM 从检索器表现不佳的样本中构建易于理解的示例，重点关注与 RAG 场景高度相关的三个学习目标：相关性、全面性和纯度。这些示例作为支架，最终使检索器与 LLM 的偏好保持一致。此外，我们采用双重课程学习策略，并利用 LLM 和检索器之间的相互反馈来进一步提高 RAG 系统的性能。一系列实验表明，我们提出的框架提高了配备不同检索器的 RAG 系统的性能，并且适用于各种 LLM。]]></description>
      <guid>https://arxiv.org/abs/2411.03957</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在不断发展的语料库中实现可重复的混合时间旅行检索</title>
      <link>https://arxiv.org/abs/2411.04051</link>
      <description><![CDATA[arXiv:2411.04051v1 公告类型：新
摘要：在某些情况下，需要排序列表的可重复性，例如在提取不断发展的文档语料库的子集以用于下游研究任务时，或在专利检索或医学系统评价等领域，对可重复性有很高的期望。但是，由于文档更改或添加到语料库时全局术语统计会发生变化，因此使用典型排序检索模型的查询甚至无法重现文档语料库中未更改的部分。因此，布尔检索通常仍然是此类设置中的首选机制。
我们提出了一种混合检索系统，该系统结合了 Lucene 的快速检索和基于列存储的检索系统，可维护版本化和带时间戳的索引。后者允许重新执行先前提出的查询，从而产生相同的排序列表，并进一步允许对不断发展的集合（如 Web 档案）进行时间旅行查询，同时保持原始排名。因此，即使文档集合和术语统计数据发生变化，不断发展的文档集合中的检索结果是完全可重现的。]]></description>
      <guid>https://arxiv.org/abs/2411.04051</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DM4Steal：图神经网络链接窃取攻击的扩散模型</title>
      <link>https://arxiv.org/abs/2411.03364</link>
      <description><![CDATA[arXiv:2411.03364v1 公告类型：交叉 
摘要：图已成为推荐系统发展中不可或缺的一部分，尤其是随着图神经网络（GNN）的快速发展。通过探索丰富的节点特征和链接信息的优点，GNN 旨在提供个性化和准确的建议。同时，在这种背景下，GNN 的隐私泄露也引起了特别的关注。先前的研究表明，恶意用户可以利用辅助知识通过目标 GNN 模型的决策来提取目标图中的敏感链接数据，这些数据是推荐系统不可或缺的。这对推荐系统中使用的数据的完整性和机密性构成了重大风险。尽管很重要，但之前关于 GNN 隐私泄露的研究仍然在三个方面受到挑战，即有限的窃取攻击场景、次优攻击性能和对防御的适应性。为了解决这些问题，我们提出了一种基于扩散模型的链接窃取攻击，称为 DM4Steal。它在三个关键方面与以前的工作不同。 (i) 通用性：针对六种辅助知识有限的攻击场景，我们提出了一种新颖的扩散模型训练策略，使 DM4Steal 可以迁移到不同的攻击场景。(ii) 有效性：得益于扩散模型在训练过程中保留的语义结构，DM4Steal 能够通过 GNN 决策过程学习目标图的精确拓扑。(iii) 适应性：当 GNN 处于防御性（例如 DP、Dropout）时，DM4Steal 依靠多次采样分数模型所带来的稳定性将性能下降降至最低，因此 DM4Steal 对防御性 GNN 实施了成功的自适应攻击。]]></description>
      <guid>https://arxiv.org/abs/2411.03364</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动化的 LLM 可以从科学文献中提取网状材料的合成细节</title>
      <link>https://arxiv.org/abs/2411.03484</link>
      <description><![CDATA[arXiv:2411.03484v1 公告类型：交叉 
摘要：从科学文献中自动提取知识可以潜在地加速材料发现。我们研究了一种使用大型语言模型 (LLM) 从科学文献中提取网状材料合成协议的方法。为此，我们引入了一个知识提取管道 (KEP)，它可以自动执行 LLM 辅助的段落分类和信息提取。通过将带有上下文学习 (ICL) 的提示工程应用于一组开源 LLM，我们证明 LLM 可以从 PDF 文档中检索化学信息，而无需进行微调或训练，并且降低了幻觉风险。通过比较五个开源 LLM 系列在段落分类和信息提取任务中的表现，我们观察到即使 ICL 提示中仅包含少数示例段落，模型性能也非常出色。结果表明，KEP 方法在减少自动科学知识提取中的人工注释和数据管理工作方面具有潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.03484</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEGMN：一种用于图相似性学习的结构增强图匹配网络</title>
      <link>https://arxiv.org/abs/2411.03624</link>
      <description><![CDATA[arXiv:2411.03624v1 公告类型：交叉 
摘要：图相似度计算（GSC）旨在量化两个图之间的相似度得分。尽管最近基于图神经网络（GNN）的 GSC 方法在消息传递中利用了图内结构，但很少有方法充分利用边所呈现的结构来增强其连接节点的表示。此外，由于 GNN 的节点表示局限于图内结构，以前的跨图节点嵌入匹配缺乏对图对整体结构的感知，导致相似度得分不合理。直观地看，分配图中表示的跨图结构有助于纠正不适当的匹配。因此，我们提出了一种结构增强型图匹配网络（SEGMN）。SEGMN 配备了双嵌入学习模块和结构感知匹配模块，在嵌入学习和跨图匹配中都实现了结构增强。双嵌入学习模块将相邻边表示合并到每个节点中以实现结构增强表示。结构感知匹配模块通过分配图卷积实现跨图结构增强。每个跨图节点对的相似度得分可以通过聚合来自结构相关节点对的消息来纠正。基准数据集上的实验结果表明，SEGMN 在 GED 回归任务中的表现优于最先进的 GSC 方法，并且结构感知匹配模块是即插即用的，可以进一步将基线的性能提高高达 25%。]]></description>
      <guid>https://arxiv.org/abs/2411.03624</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您所需要的只是词汇化：检查词汇知识在组合 QALD 系统中的影响</title>
      <link>https://arxiv.org/abs/2411.03906</link>
      <description><![CDATA[arXiv:2411.03906v1 公告类型：交叉 
摘要：在本文中，我们研究了词汇化对基于链接数据 (QALD) 的问答系统的影响。众所周知，在解释 SPARQL 的自然语言问题时，关键挑战之一在于弥合词汇鸿沟，即将查询中的单词映射到正确的词汇元素。我们在本文中认为，词汇化，即关于给定词汇的单词潜在解释的明确知识，可以大大简化任务并提高 QA 系统的性能。为了实现这一目标，我们提出了一个组合 QA 系统，该系统可以利用组合方式的明确词汇知识来推断 SPARQL 查询中问题的含义。我们表明，在给定词汇知识的情况下，此类系统的性能远远超出当前的 QA 系统，与 QALD-9 上的最佳 QA 系统相比，微观 $F_1$ 分数可提高高达 $35.8\%$。这表明包含明确词汇知识的重要性和潜力。相比之下，我们表明 LLM 利用词汇知识的能力有限，与没有词汇知识的版本相比，只有微小的改进。这表明 LLM 无法根据问题各部分的含义对问题进行组合解释，这是组合方法的一个关键特征。总之，我们的工作为 QALD 研究开辟了新途径，强调了词汇化和组合性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2411.03906</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于在线近似最近邻搜索的实时自适应多流 GPU 系统</title>
      <link>https://arxiv.org/abs/2408.02937</link>
      <description><![CDATA[arXiv:2408.02937v2 公告类型：替换 
摘要：近年来，近似最近邻搜索 (ANNS) 在现代搜索和推荐系统中发挥了关键作用，尤其是在检索增强生成等新兴 LLM 应用中。人们越来越多地探索利用 GPU 的并行计算能力来满足 ANNS 的大量需求。然而，现有的系统主要关注离线场景，忽略了需要实时插入新向量的在线应用程序的不同要求。这种限制使得此类系统对于实际场景效率低下。此外，由于以前的架构依赖于串行执行流，因此难以有效地支持实时插入。在本文中，我们介绍了一种新颖的实时自适应多流 GPU ANNS 系统 (RTAMS-GANNS)。我们的架构通过三个关键改进实现了其目标：1）我们最初研究了现有 GPU ANNS 系统中的实时插入机制，发现它们依赖于重复复制和内存分配，这严重阻碍了 GPU 的实时性。作为解决方案，我们引入了一种基于内存块的动态向量插入算法，其中包括就地重新排列。2）为了实现并行的实时向量插入，我们引入了一种多流并行执行模式，这与在单个流中串行运行的现有系统不同。我们的系统利用动态资源池，允许多个流同时执行而无需额外的执行阻塞。3）通过大量的实验和比较，我们的方法有效地处理了不同数据集中不同的 QPS 级别，将延迟降低了 40%-80%。所提出的系统还已部署在现实世界的工业搜索和推荐系统中，每天为数亿用户提供服务，并取得了良好的效果。]]></description>
      <guid>https://arxiv.org/abs/2408.02937</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CheX-GPT：利用大型语言模型增强胸部 X 光报告标注</title>
      <link>https://arxiv.org/abs/2401.11505</link>
      <description><![CDATA[arXiv:2401.11505v2 公告类型：replace-cross 
摘要：自由文本放射学报告为各种医疗任务提供了丰富的数据源，但有效地标记这些文本仍然具有挑战性。传统的基于规则的标记方法无法捕捉各种自由文本模式的细微差别。此外，使用专家注释数据的模型受到数据稀缺和预定义类别的限制，影响其性能、灵活性和可扩展性。为了解决这些问题，我们的研究提供了三个主要贡献：1）我们使用精心设计的提示展示了 GPT 作为熟练标记器的潜力。2）仅利用 GPT 标记的数据，我们训练了一个基于 BERT 的标记器 CheX-GPT，它比 GPT 对应物运行得更快、更高效。3）为了对标记器性能进行基准测试，我们引入了一个公开可用的专家注释测试集 MIMIC-500，其中包含来自 MIMIC 验证集的 500 个案例。我们的研究结果表明，CheX-GPT 不仅在标记准确度方面优于现有模型，而且还展示了卓越的效率、灵活性和可扩展性，这得益于我们引入 MIMIC-500 数据集进行稳健的基准测试。代码和模型可在 https://github.com/Soombit-ai/CheXGPT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2401.11505</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ELASTIC：用于顺序兴趣压缩的高效线性注意力</title>
      <link>https://arxiv.org/abs/2408.09380</link>
      <description><![CDATA[arXiv:2408.09380v3 公告类型：replace-cross 
摘要：最先进的顺序推荐模型严重依赖于 transformer 的注意力机制。然而，自注意力的二次计算和内存复杂性限制了其对用户长距离行为序列建模的可扩展性。为了解决这个问题，我们提出了 ELASTIC，一种用于顺序兴趣压缩的高效线性注意力，只需要线性时间复杂度，并将模型容量与计算成本分离。具体来说，ELASTIC 引入了一种具有线性调度器注意机制的固定长度兴趣专家，它将长期行为序列压缩为更紧凑的表示，从而将 GPU 内存使用量减少高达 90%，推理速度提高 2.7 倍。所提出的线性调度器注意机制显着降低了二次复杂度，并使模型能够充分建模极长序列。此外，为了保持对各种用户兴趣进行建模的能力，ELASTIC 初始化了一个庞大的可学习兴趣记忆库，并以可忽略不计的计算开销从记忆中稀疏地检索压缩的用户兴趣。所提出的兴趣记忆检索技术在保持相同计算成本的同时显著扩展了可用兴趣空间的基数，从而在推荐准确性和效率之间达成了权衡。为了验证我们提出的 ELASTIC 的有效性，我们在各种公共数据集上进行了广泛的实验，并将其与几个强大的序列推荐器进行了比较。实验结果表明，ELASTIC 的表现始终远超基线，同时也凸显了 ELASTIC 在建模长序列时的计算效率。我们将公开我们的实现代码。]]></description>
      <guid>https://arxiv.org/abs/2408.09380</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PersianRAG：波斯语检索增强生成系统</title>
      <link>https://arxiv.org/abs/2411.02832</link>
      <description><![CDATA[arXiv:2411.02832v2 公告类型：replace-cross 
摘要：检索增强生成 (RAG) 模型将大规模预训练生成模型与外部检索机制相结合，在各种自然语言处理 (NLP) 任务中取得了显著的成功。然而，将 RAG 模型应用于波斯语这种资源匮乏的语言，面临着独特的挑战。这些挑战主要涉及系统的预处理、嵌入、检索、提示构建、语言建模和响应评估。在本文中，我们解决了为波斯语实现一个称为 PersianRAG 的真实 RAG 系统的挑战。我们提出了克服这些障碍的新解决方案，并使用多个波斯语基准数据集评估了我们的方法。我们的实验结果证明了 PersianRAG 框架能够增强波斯语问答任务的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.02832</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于科学关键词生成的自组合数据增强</title>
      <link>https://arxiv.org/abs/2411.03039</link>
      <description><![CDATA[arXiv:2411.03039v2 公告类型：replace-cross 
摘要：最先进的关键短语生成模型需要大量训练数据才能获得良好的性能。然而，获取带关键短语标签的文档可能具有挑战性且成本高昂。为了解决这个问题，我们提出了一种自组合数据增强方法。更具体地说，我们根据共享的关键短语来衡量训练文档的相关性，并组合相似的文档来生成合成样本。我们方法的优势在于它能够创建额外的训练样本，以保持领域一致性，而无需依赖外部数据或资源。我们在三个不同领域的多个数据集上的结果表明，我们的方法可以持续改进关键短语的生成。对计算机科学领域生成的关键短语的定性分析证实了其代表性的改进。]]></description>
      <guid>https://arxiv.org/abs/2411.03039</guid>
      <pubDate>Thu, 07 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>