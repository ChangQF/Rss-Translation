<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语句：使用大型语言模型从表格中提取 ESG KPI 的通用信息</title>
      <link>https://arxiv.org/abs/2406.19102</link>
      <description><![CDATA[arXiv:2406.19102v1 公告类型：交叉 
摘要：环境、社会和治理 (ESG) KPI 评估组织在气候变化、温室气体排放、水消耗、废物管理、人权、多样性和政策等问题上的表现。ESG 报告通过表格传达这些宝贵的定量信息。不幸的是，由于表格结构和内容的高度可变性，提取这些信息很困难。我们提出了 Statements，这是一种用于提取定量事实和相关信息的新型领域无关数据结构。我们建议将表格转换为语句作为一项新的监督深度学习通用信息提取任务。我们引入了 SemTabNet - 一个包含超过 100K 个带注释表格的数据集。通过研究基于 T5 的语句提取模型系列，我们的最佳模型生成的语句与基本事实相似度为 82%（相比基线为 21%）。我们通过将我们的模型应用于 ESG 报告中的 2700 多个表格来展示语句的优势。声明的同质性使得可以对大量 ESG 报告中的广泛信息进行探索性数据分析。]]></description>
      <guid>https://arxiv.org/abs/2406.19102</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>一种用于超过四个词干的音乐源分离的词干无关单解码器系统</title>
      <link>https://arxiv.org/abs/2406.18747</link>
      <description><![CDATA[arXiv:2406.18747v1 公告类型：交叉 
摘要：尽管最近在音频源分离的多个子任务方面取得了重大进展，但很少有音乐源分离系统支持四主干人声、鼓、贝斯和其他 (VDBO) 设置之外的分离。在目前支持超出此设置的源分离的极少数系统中，大多数仍然依赖于只能支持固定预定义主干集的不灵活的解码器设置。在这些不灵活的系统中增加主干支持相应地需要增加计算复杂性，使得这些系统的扩展对于长尾乐器在计算上不可行。在这项工作中，我们提出了 Banquet，这是一个仅使用一个解码器即可实现多个主干源分离的系统。带分割源分离模型被扩展为与乐器识别 PaSST 模型协同工作，以在基于查询的设置中工作。在 MoisesDB 数据集上，Banquet 仅需 24.9 M 个可训练参数，在 VDBO 词干上的性能水平接近明显更复杂的 6 词干混合变压器 Demucs，在吉他和钢琴上的表现也优于后者。基于查询的设置允许分离狭窄的乐器类别（例如干净的原声吉他），并且可以成功应用于提取不太常见的词干（例如簧片和风琴）。实现可在 https://github.com/kwatcharasupat/query-bandit 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.18747</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>利用掩码图像-文本对进行考虑查询-目标关系的零样本组合图像检索</title>
      <link>https://arxiv.org/abs/2406.18836</link>
      <description><![CDATA[arXiv:2406.18836v1 公告类型：交叉 
摘要：本文提出了一种新的零样本组合图像检索 (CIR) 方法，该方法考虑了掩码图像-文本对的查询-目标关系。CIR 的目标是使用查询图像和查询文本检索目标图像。现有方法使用文本反转网络将查询图像转换为伪词以组成图像和文本，并使用预先训练的视觉语言模型实现检索。但是，它们没有考虑查询-目标关系来训练文本反转网络以获取检索信息。在本文中，我们提出了一种新的零样本 CIR 方法，该方法使用掩码图像-文本对进行端到端训练。通过利用使用掩码策略方便获得的丰富图像-文本对来学习查询-目标关系，预计可以使用以检索为重点的文本反转网络实现准确的零样本 CIR。实验结果证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.18836</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>Hire：用于图像文本匹配的具有多种关系增强的混合模式交互</title>
      <link>https://arxiv.org/abs/2406.18579</link>
      <description><![CDATA[arXiv:2406.18579v1 公告类型：交叉 
摘要：图像文本匹配（ITM）是计算机视觉中的一个基本问题。关键问题在于联合学习视觉和文本表示以准确估计它们的相似性。大多数现有方法侧重于模态内的特征增强或跨模态的特征交互，然而，这些方法忽略了基于与具有丰富上下文语义的相应句子匹配的对象间关系的对象表示的上下文信息。在本文中，我们提出了一种用于图像文本匹配的具有多种关系增强的混合模态交互（称为 \textit{Hire}），它将对象和单词之间的模态内和模态间语义与隐式和显式关系建模相关联。特别是，显式模态内空间语义图推理网络旨在通过对象的空间位置和场景图的显式关系来改善具有显着空间和语义关系连接的视觉对象的上下文表示。为了提高显式关系检测的容错性，我们在显式建模之前对潜在关系交互使用隐式关系建模。然后通过模态间交互注意和跨模态对齐联合细化视觉和文本语义表示。为了将对象的上下文与文本上下文关联起来，我们通过跨级别的对象句子和基于单词图像的交互注意进一步细化视觉语义表示。大量实验验证了所提出的隐式和显式建模的混合模态交互对图像文本匹配更有利。并且所提出的 \textit{Hire} 在 MS-COCO 和 Flickr30K 基准上获得了新的最佳结果。]]></description>
      <guid>https://arxiv.org/abs/2406.18579</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>逐步进行重新排序：研究使用大型语言模型进行重新排序的预过滤</title>
      <link>https://arxiv.org/abs/2406.18740</link>
      <description><![CDATA[arXiv:2406.18740v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 凭借其多样化的零样本能力彻底改变了无数自然语言处理任务。事实上，现有的工作已经表明，LLM 可以有效地用于许多任务，例如信息检索 (IR) 和段落排名。然而，目前最先进的结果严重依赖于所使用的 LLM 的能力。目前，专有和非常大的 LLM（例如 GPT-4）是性能最高的段落重新排序器。因此，没有资源利用顶级 LLM 或闭源 LLM 的用户处于劣势。在本文中，我们研究了在 IR 中段落重新排序之前使用预过滤步骤的情况。我们的实验表明，通过使用少量人工生成的相关性分数，再加上 LLM 相关性评分，可以在重新排名之前有效地过滤掉不相关的段落。我们的实验还表明，这种预过滤可以让 LLM 在重新排序任务中表现得更好。事实上，我们的结果表明，较小的模型（如 Mixtral）可以与更大的专有模型（例如 ChatGPT 和 GPT-4）相媲美。]]></description>
      <guid>https://arxiv.org/abs/2406.18740</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>IR 中哪些神经元很重要？应用基于梯度的积分方法来理解交叉编码器</title>
      <link>https://arxiv.org/abs/2406.19309</link>
      <description><![CDATA[arXiv:2406.19309v1 公告类型：新
摘要：随着最近检索增强生成 (RAG) 的加入，信息检索 (IR) 的范围和重要性得到了扩大。因此，更深入地了解 IR 模型的重要性也随之增加。然而，IR 的可解释性仍未得到充分探索，尤其是在模型的内部机制方面。在本文中，我们探讨了在 IR 环境中采用基于积分梯度的方法来识别模型中单个神经元的作用的可能性。特别是，我们对所谓的“相关性”神经元的作用以及它们如何处理看不见的数据提供了新的见解。最后，我们进行了深入的修剪研究以验证我们的发现。]]></description>
      <guid>https://arxiv.org/abs/2406.19309</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>DRAK：通过法学硕士 (LLM) 中的领域特定检索增强知识解锁分子见解</title>
      <link>https://arxiv.org/abs/2406.18535</link>
      <description><![CDATA[arXiv:2406.18535v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在特定领域（例如生物分子）的独特语法方面遇到挑战。现有的微调或模态对齐技术难以弥合领域知识差距并理解复杂的分子数据，从而限制了 LLM 在专业领域的发展。为了克服这些限制，我们提出了一个可扩展且适应性强的非参数知识注入框架，称为领域特定检索增强知识 (DRAK)，旨在增强特定领域的推理能力。利用知识感知提示和金标签诱导推理，DRAK 在分子领域积累了深厚的专业知识，并能够处理广泛的分析任务。我们评估了两种不同形式的 DRAK 变体，证明 DRAK 在 Mol-Instructions 数据集中的六个分子任务上超过了之前的基准。大量实验证实了 DRAK 的强大性能及其揭示分子奥秘的潜力，为 LLM 解决特定领域的知识密集型任务提供了统一的范例。我们的代码即将推出。]]></description>
      <guid>https://arxiv.org/abs/2406.18535</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>对话信息访问中用户模拟目标的形式化表征</title>
      <link>https://arxiv.org/abs/2406.19007</link>
      <description><![CDATA[arXiv:2406.19007v1 公告类型：新
摘要：用户模拟是一种很有前途的方法，可以自动训练和评估对话信息访问代理，从而能够生成合成对话并促进大规模可重复的实验。然而，不同用途的用户模拟目标仍然定义不明确，阻碍了有效模拟器的开发。在这项工作中，我们正式描述了用户模拟器的不同目标：训练旨在最大限度地提高与真实用户的行为相似性，而评估则侧重于准确预测现实世界中对话代理的性能。通过实证研究，我们证明优化一个目标并不一定会导致另一个目标的性能提高。这一发现强调了根据模拟器的预期用途进行量身定制的设计考虑的必要性。通过建立明确的目标并提出具体的措施来根据这些目标评估用户模拟器，我们为开发专门针对其预期用途的模拟器铺平了道路，最终带来了更有效的对话代理。]]></description>
      <guid>https://arxiv.org/abs/2406.19007</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>基于 T5 的排名和总结，实现高效的课程推荐</title>
      <link>https://arxiv.org/abs/2406.19018</link>
      <description><![CDATA[arXiv:2406.19018v1 公告类型：新
摘要：在本文中，我们实现并评估了课程推荐系统的两阶段检索流程，该系统根据技能-职业对对课程进行排名。生产中的推荐系统 BrightFit 提供来自多个来源的课程推荐。一些课程描述很长而且很嘈杂，而在线系统中的检索和排名必须非常高效。我们开发了一个两步检索流程，使用在 MSMARCO 上微调的 RankT5 作为重新排名器。我们比较了两个课程描述的摘要器：一个我们为该任务微调的 LongT5 模型，以及一个具有上下文学习的生成式 LLM（Vicuna）。我们尝试使用量化来减小排名模型的大小并提高推理速度。我们使用 A/B 测试和用户问卷在两个新标记的数据集上评估我们的排名器。在两个标记数据集上，我们提出的带自动摘要的两阶段排序方法比生产中的 (BM25) 排序方法取得了显著的改进：在这两个数据集上，nDCG@10 得分从 0.482 提高到 0.684，从 0.447 提高到 0.844。我们还通过使用量化版本的 RankT5 实现了 40% 的速度提升。29 位受访者完成的问卷证实了排序质量的提高，但 A/B 测试并未证实这一点。在 A/B 测试中，BM25 排序的点击率高于提出的两阶段检索。我们得出结论，基于 T5 的在线课程推荐重新排序和摘要比单步词汇检索的效果要好得多，并且量化对 RankT5 有很大影响。然而，在线评估中，除了相关性之外，其他因素（例如检索结果的速度和可解释性）以及个人偏好也发挥着作用。]]></description>
      <guid>https://arxiv.org/abs/2406.19018</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>对话式信息搜索系统的可靠且透明的响应生成</title>
      <link>https://arxiv.org/abs/2406.19281</link>
      <description><![CDATA[arXiv:2406.19281v1 公告类型：新
摘要：虽然以前的对话式信息搜索 (CIS) 研究主要集中在段落检索、重新排序和查询重写上，但将检索到的信息合成为连贯的响应的挑战仍然存在。拟议的研究深入探讨了 CIS 系统中响应生成的复杂性。开放式信息搜索对话引入了多个挑战，可能会导致系统响应中出现潜在的陷阱。该研究的重点是根据检索到的段落生成响应，并公开系统的局限性。具体研究问题围绕获取信心丰富的信息块、自动检测不完整或不正确的响应、生成传达系统局限性的响应以及评估增强的响应。通过解决这些研究任务，该研究旨在促进对话响应生成的进步，促进 CIS 对话中更值得信赖的互动，并为扎实透明的系统铺平道路，以满足信息驱动世界中用户的需求。]]></description>
      <guid>https://arxiv.org/abs/2406.19281</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>使用聚类和自监督学习进行多模态食品推荐</title>
      <link>https://arxiv.org/abs/2406.18962</link>
      <description><![CDATA[arXiv:2406.18962v1 公告类型：新
摘要：食品推荐系统是数字生活方式服务领域的关键组成部分，旨在帮助用户发现符合其独特饮食偏好的食谱和食品。通常，多模态描述为每种食谱提供详尽的资料，从而确保推荐既个性化又准确。我们对两个数据集的初步调查表明，与 ID 特征相比，预训练的多模态密集表示在封装交互关系时可能会导致性能下降。这一观察结果表明，ID 特征在建模交互式协作信号方面具有相对优势。因此，当代的前沿方法用多模态信息作为补充特征来增强 ID 特征，而忽略了食谱之间的潜在语义关系。为了纠正这个问题，我们提出了 CLUSSL，这是一种采用聚类和自监督学习的新型食品推荐框架。具体而言，CLUSSL 制定了针对每种模态的离散/连续特征的模态特定图，从而将语义特征转化为结构表示。此外，CLUSSL 通过图卷积操作获取与不同模态相关的食谱表示。提出了一种自监督学习目标，以促进来自不同单峰图的食谱表示之间的独立性。对真实数据集的全面实验证实，CLUSSL 在性能上始终超越最先进的推荐基准。]]></description>
      <guid>https://arxiv.org/abs/2406.18962</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>通过稀疏性补全增强图学习以进行推荐</title>
      <link>https://arxiv.org/abs/2406.18984</link>
      <description><![CDATA[arXiv:2406.18984v1 公告类型：新
摘要：图学习模型已广泛应用于基于协同过滤（CF）的推荐系统。由于数据稀疏性问题，原始输入的图结构缺乏潜在的正偏好边，这大大降低了推荐的性能。在本文中，我们研究如何更有效地增强CF的图结构，从而优化图节点的表示。先前的工作将矩阵完成技术引入CF，提出使用随机完成方法或表面结构完成来解决这个问题。然而，这些方法大多采用随机数值填充，缺乏对噪声扰动的控制，限制了对节点高阶交互特征的深入探索，导致图表示有偏差。
在本文中，我们提出了一种基于稀疏性完成的放大图学习框架（称为AGL-SC）。首先，我们利用图神经网络挖掘用户和项目节点之间的直接交互特征，并将其用作编码器的输入。其次，我们设计了一种基于分解的方法来挖掘高阶交互特征。这些特征作为隐藏层潜在空间中的扰动因子，以促进生成增强。最后，通过变分推理，将上述多阶特征整合在一起，实现缺失图结构的补全和增强。我们在四个与推荐任务相关的真实数据集上进行了基准和策略实验。实验结果表明，AGL-SC 明显优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.18984</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>面向个性化联合多场景多任务推荐</title>
      <link>https://arxiv.org/abs/2406.18938</link>
      <description><![CDATA[arXiv:2406.18938v1 公告类型：新
摘要：在现代推荐系统应用中，例如电子商务，预测多个目标（例如点击率（CTR）和浏览后点击率和转化率（CTCVR））很常见。多任务推荐系统在研究和实际应用中越来越受欢迎。现有的多任务推荐系统可处理不同的业务场景，合并和建模这些场景可解锁共享知识以提高整体性能。随着新的和更复杂的现实世界推荐场景的出现，数据隐私问题使得难以训练处理多个独立场景的单个全局多任务推荐模型。
在本文中，我们提出了一种个性化联合多场景多任务推荐的新框架，称为 PF-MSMTrec。我们将每个场景分配给一个专用客户端，每个客户端都使用混合专家 (MMoE) 结构。我们提出的方法旨在解决这种设置中多个优化冲突带来的独特挑战。我们引入了一种自下而上的联合学习机制。首先，我们设计了一个参数模板来解耦专家网络的参数。因此，场景参数是联邦参数聚合的共享知识，而任务特定参数是个性化的局部参数。其次，我们通过联邦通信轮对每个专家网络的参数进行个性化联邦学习，利用三个模块：联邦批量规范化、冲突协调和个性化聚合。最后，我们在任务塔网络上进行另一轮个性化联邦参数聚合，以获得多个任务的预测结果。我们在两个公共数据集上进行了广泛的实验，结果表明我们提出的方法超越了最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.18938</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>一种出乎意料的简单而有效的对话段落检索多查询重写方法</title>
      <link>https://arxiv.org/abs/2406.18960</link>
      <description><![CDATA[arXiv:2406.18960v1 公告类型：新
摘要：对话段落检索具有挑战性，因为它通常需要解决对先前话语的引用，并且需要处理自然语言的复杂性，例如共指和省略。为了应对这些挑战，通常使用预先训练的序列到序列神经查询重写器来根据对话历史生成单个去语境化查询。先前的研究表明，将同一用户话语的多个查询重写组合起来对检索性能有积极影响。我们建议使用神经查询重写器来生成多个查询，并展示如何有效地将这些查询集成到段落检索管道中。我们方法的主要优势在于它的简单性：它利用了波束搜索算法的工作原理，并且可以在不增加额外成本的情况下生成多个查询重写。我们的贡献还包括设计在稀疏和密集首次检索中使用多查询重写的方法。我们证明，在标准段落检索管道上应用我们的方法可以在不牺牲效率的情况下提供最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.18960</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>ELCoRec：通过数值和分类特征的共同传播来增强语言理解并提出建议</title>
      <link>https://arxiv.org/abs/2406.18825</link>
      <description><![CDATA[arXiv:2406.18825v1 公告类型：新
摘要：大型语言模型在自然语言处理 (NLP) 领域蓬勃发展，其推荐潜力备受关注。尽管面向推荐的微调模型表现出智能，但由于 LLM 在解释数值特征方面的固有弱点以及长上下文的开销，LLM 很难完全理解用户行为模式，其中用户行为之间的时间关系、不同评分之间的细微定量信号以及项目的各种侧面特征尚未得到很好的探索。现有的工作仅在给定的文本数据上微调单个 LLM，而没有向其中引入重要信息，导致这些问题未得到解决。在本文中，我们提出了 ELCoRec，通过数值和分类特征的共同传播来增强语言理解，以进行推荐。具体而言，我们建议通过 GAT 专家模型将偏好理解能力注入 LLM，通过并行传播时间关系、评级信号以及历史项目的各种侧面信息，可以更好地编码用户偏好。并行传播机制可以稳定异构特征并提供信息丰富的用户偏好编码，然后以单个标记嵌入为代价通过软提示将其注入语言模型。为了进一步获得用户最近的兴趣，我们提出了一种新颖的最近交互增强提示 (RAP) 模板。针对强基线的三个数据集的实验结果验证了 ELCoRec 的有效性。代码可在 https://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.18825</guid>
      <pubDate>Fri, 28 Jun 2024 06:20:14 GMT</pubDate>
    </item>
    </channel>
</rss>