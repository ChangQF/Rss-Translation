<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 30 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 ABCDE 评估集群 ID 分配方案</title>
      <link>https://arxiv.org/abs/2409.18254</link>
      <description><![CDATA[arXiv:2409.18254v1 公告类型：新
摘要：聚类 ID 分配方案用不同的 ID 标记聚类中的每个聚类。ID 分配的目标是语义 ID 稳定性，这意味着，只要有可能，与历史聚类具有相同底层概念的聚类理想情况下应该接收与历史聚类相同的 ID。语义 ID 稳定性允许聚类的用户引用具有跨聚类/时间稳定 ID 的概念聚类。本文讨论了评估 ID 分配方案的相对优点的问题。特别是，它考虑了具有 ID 分配的历史聚类，以及具有由基线和实验分配的 ID 的新聚类。它生成了表征基线和实验之间 ID 分配差异的大小和质量的指标。这是通过将聚类 ID 分配问题转化为聚类成员问题，并使用 ABCDE 对其进行评估来实现的。 ABCDE 是一种复杂且可扩展的技术，用于评估实际应用中集群成员的差异，其中数十亿个项目被分组为数百万个集群，并且一些项目比其他项目更重要。本文还描述了 ID 分配方案的基本评估设置的几种概括。例如，评估同时改变集群成员和集群 ID 的变化相当简单。这些想法通过示例进行了充分说明。]]></description>
      <guid>https://arxiv.org/abs/2409.18254</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成检索与多级相关性相结合</title>
      <link>https://arxiv.org/abs/2409.18409</link>
      <description><![CDATA[arXiv:2409.18409v1 公告类型：新
摘要：生成检索代表了一种新颖的信息检索方法。它使用编码器-解码器架构直接生成查询的相关文档标识符 (docid)。虽然这种方法有很多好处，但当前的方法仅限于二进制相关数据的场景，忽略了文档具有多级相关性的可能性。扩展生成检索以适应多级相关性带来了挑战，包括需要协调 docid 对的可能性概率以及多个相关文档共享相同标识符的可能性。为了应对这些挑战，我们引入了一个名为 GRaded Generative Retrieval (GR$^2$) 的框架。GR$^2$ 专注于两个关键组件：确保相关且不同的标识符，并实施多级约束对比训练。首先，我们创建在语义上相关且足够不同的标识符，以有效地表示单个文档。这是通过结合 docid 生成和自动编码器模型来联合优化 docid 的相关性和独特性来实现的。其次，我们结合了相关性等级之间的关系信息来指导训练过程。我们使用约束对比训练策略，根据查询的表示和相关文档的标识符各自的相关性等级，使查询的表示和相关文档的标识符更紧密地结合在一起。在具有多级和二元相关性的数据集上进行的大量实验证明了 GR$^2$ 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.18409</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型二分图上的高效 Top-k s-Biplexes 搜索</title>
      <link>https://arxiv.org/abs/2409.18473</link>
      <description><![CDATA[arXiv:2409.18473v1 公告类型：新
摘要：在二分图中，如果子图的每个顶点与对立集上除最多 $s$ 个顶点之外的所有顶点相邻，则子图为 $s$-biplex。从给定图中枚举 $s$-biplexes 是二分图分析中的一个基本问题。然而，在现实世界的数据工程中，找到所有 $s$-biplexes 既没有必要，也不在计算上可承受。一个更现实的问题是从大型输入图中识别一些最大的 $s$-biplexes。我们将问题表述为 {\em top-$k$ $s$-biplex 搜索 (TBS) 问题}，旨在找到具有最多顶点的前 $k$ 个最大 $s$-biplexes，其中 $k$ 是输入参数。我们证明，对于任何固定的 $k\ge 1$，TBS 问题都是 NP-hard。然后，我们提出了一种分支算法 MVBP，该算法打破了简单的 $2^n$ 枚举算法。此外，从实用角度，我们研究了三种提高 MVBP 性能的技术：2 跳分解、单边边界和渐进搜索。复杂度分析表明，改进的算法 FastMVBP 的运行时间为 $O^*(\gamma_s^{d_2})$，其中 $\gamma_s&lt;2$，$d_2$ 是一个比稀疏真实世界图中顶点数量小得多的参数，例如在拥有超过 $3$ 百万个顶点的 AmazonRatings 数据集中，$d_2$ 只有 $67$。最后，我们在八个真实世界和合成数据集上进行了大量实验，以证明所提算法的经验效率。特别是，FastMVBP 在几个实例中比基准算法高出多达三个数量级。]]></description>
      <guid>https://arxiv.org/abs/2409.18473</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分解 ABCDE 中的 Jaccard 距离和 Jaccard 指数</title>
      <link>https://arxiv.org/abs/2409.18522</link>
      <description><![CDATA[arXiv:2409.18522v1 公告类型：新
摘要：ABCDE 是一种用于评估非常大的聚类之间差异的复杂技术。其表征两个聚类之间差异大小的主要指标是 JaccardDistance，它是固定一组（加权）项目的所有聚类空间中的真实距离度量。JaccardIndex 是表征两个聚类相似性的补充指标。它与 JaccardDistance 的关系很简单：JaccardDistance + JaccardIndex = 1。本文进一步分解了 JaccardDistance 和 JaccardIndex。在每种情况下，分解都会产生影响和质量指标。影响指标衡量聚类差异大小的各个方面，而质量指标则使用人工判断来衡量聚类差异对聚类质量的改善程​​度。本文的分解为聚类变化提供了更多、更深入的见解。它们还解锁了调试和探索聚类差异性质的新技术。新指标在数学上表现良好，并且通过简单的方程相互关联。虽然这项工作可以看作是 ABCDE 的另一种形式框架，但我们更愿意将其视为互补。它确实提供了关于聚类变化的幅度和质量的不同视角，用户可以从每种方法中使用他们想要的任何方法来更深入地了解变化。]]></description>
      <guid>https://arxiv.org/abs/2409.18522</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于语料库的检索增强澄清问题的生成</title>
      <link>https://arxiv.org/abs/2409.18575</link>
      <description><![CDATA[arXiv:2409.18575v1 公告类型：新
摘要：本研究旨在开发模型，以生成基于语料库的澄清问题，用于网络搜索，以确保问题与检索语料库中的可用信息一致。我们展示了检索增强语言模型 (RAG) 在此过程中的有效性，强调了它们能够 (i) 联合建模用户查询和检索语料库以查明不确定性并端到端地要求澄清，以及 (ii) 建模更多证据文档，这些文档可用于增加所提问题的广度。然而，我们观察到，在当前数据集中，语料库在很大程度上不支持搜索意图，这对训练和评估都是有问题的。这导致问题生成模型“产生幻觉”，即建议语料库中没有的意图，这可能会对性能产生不利影响。为了解决这个问题，我们提出了数据集增强方法，将基本事实澄清与检索语料库对齐。此外，我们探索了在推理过程中增强证据池相关性的技术，但发现在语料库中识别基本事实意图仍然具有挑战性。我们的分析表明，这一挑战部分是由于当前数据集偏向澄清分类法，并要求能够支持生成语料库信息澄清的数据。]]></description>
      <guid>https://arxiv.org/abs/2409.18575</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少即是多：面向推荐系统中可持续性意识的说服性解释</title>
      <link>https://arxiv.org/abs/2409.18690</link>
      <description><![CDATA[arXiv:2409.18690v1 公告类型：新
摘要：推荐系统在支持实现联合国可持续发展目标 (SDG) 方面发挥着重要作用。在推荐系统中，解释可以支持不同的目标，例如增加用户对推荐的信任、说服用户购买特定商品或增加对推荐背后原因的理解。在本文中，我们讨论了“可持续发展意识说服性解释”的概念，我们认为这是支持实现上述可持续发展目标的主要概念。这种解释与大多数现有的解释方法正交，因为它们侧重于“少即是多”的原则，而现有的电子商务平台本身并不包括这一原则。基于对三个项目领域的用户研究，我们分析了可持续发展意识说服性解释的潜在影响。研究结果在用户接受度和此类解释的潜在影响方面令人鼓舞。]]></description>
      <guid>https://arxiv.org/abs/2409.18690</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有大型项目目录的顺序推荐的可扩展交叉熵损失</title>
      <link>https://arxiv.org/abs/2409.18721</link>
      <description><![CDATA[arXiv:2409.18721v1 公告类型：新
摘要：可扩展性问题在现代推荐系统生产化中起着至关重要的作用。即使是轻量级架构也可能由于中间计算而遭受高计算过载，从而限制了它们在实际应用中的实用性。具体而言，应用完整的交叉熵 (CE) 损失通常会在推荐质量方面产生最先进的性能。然而，在处理大型项目目录时，它会受到 GPU 内存利用率过高的影响。本文在顺序学习设置中引入了一种新颖的可扩展交叉熵 (SCE) 损失函数。它近似具有大型目录的数据集的 CE 损失，在不影响推荐质量的情况下提高了时间效率和内存使用率。与传统的负采样方法不同，我们的方法采用选择性 GPU 高效计算策略，专注于目录中最具信息量的元素，特别是那些最有可能是假阳性的元素。这是通过最大内积搜索在模型输出的子集上近似 softmax 分布来实现的。在多个数据集上的实验结果表明，与其他方案相比，SCE 能够将峰值内存使用量降低 100 倍，同时保持甚至超过其指标值。所提出的方法还为不同领域的大规模开发（例如大型语言模型）开辟了新的前景。]]></description>
      <guid>https://arxiv.org/abs/2409.18721</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用关键模式进行跨域关键字提取</title>
      <link>https://arxiv.org/abs/2409.18724</link>
      <description><![CDATA[arXiv:2409.18724v1 公告类型：新
摘要：领域依赖性和注释主观性对监督关键词提取提出了挑战。基于二阶关键性模式存在于社区层面并且可以从带注释的关键词提取数据集中学习的前提，本文提出了一种监督关键词提取排名方法，该方法使用由独立特征（例如子语言领域和术语长度）和三类依赖特征（启发式特征、特异性特征和代表性特征）组成的关键性模式对关键词进行排序。该方法使用两个基于卷积神经网络的模型从关键词数据集中学习关键性模式，并通过使用引导抽样策略训练这两个模型来克服注释的主观性。实验表明，该方法不仅在10个关键词数据集上取得了平均top-10-F-measure为0.316的一般监督关键词抽取最佳性能，而且在4个训练过程中排除的数据集上也取得了平均top-10-F-measure为0.346的跨领域稳健性能。这种跨领域稳健性归功于社区级关键性模式数量有限且与语言领域具有一定程度的独立性、独立特征与依赖特征的区分以及平衡过度风险和缺乏负面训练数据的采样训练策略。]]></description>
      <guid>https://arxiv.org/abs/2409.18724</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跟踪软件安全主题</title>
      <link>https://arxiv.org/abs/2409.18351</link>
      <description><![CDATA[arXiv:2409.18351v1 公告类型：交叉 
摘要：软件安全事件每天都在发生，每月都会发布数千份软件安全报告。因此，软件安全研究人员、工程师和其他利益相关者很难实时关注他们感兴趣的软件安全主题。在本文中，我们提出了一种解决此问题的新工具 SOSK。SOSK 允许用户导入软件安全报告集合。它对报告的文本描述进行预处理并提取最重要的关键字。基于关键字嵌入向量的相似性，SOSK 可以从一组更小的用户提供的关键字中扩展和/或细化关键字集。因此，SOSK 允许用户定义他们感兴趣的任何主题并有效地检索与该主题相关的安全报告。我们的初步评估表明，SOSK 可以扩展关键字并检索与用户请求相关的报告。]]></description>
      <guid>https://arxiv.org/abs/2409.18351</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经协同过滤检测人类语义轨迹中的异常</title>
      <link>https://arxiv.org/abs/2409.18427</link>
      <description><![CDATA[arXiv:2409.18427v1 公告类型：交叉 
摘要：人类轨迹异常检测在包括安全监控和公共卫生在内的广泛应用中变得越来越重要。然而，现有的轨迹异常检测方法主要集中在车辆级交通上，而人类级轨迹异常检测仍未得到充分探索。由于人类轨迹数据通常非常稀疏，机器学习方法已成为识别复杂模式的首选方法。然而，对这些模型的潜在偏见和稳健性的担忧加剧了对更透明和可解释的替代方案的需求。为了应对这些挑战，我们的研究重点是开发一种轻量级异常检测模型，专门用于检测人类轨迹中的异常。我们提出了一种神经协同过滤方法来建模和预测正常移动性。我们的方法旨在模拟用户的日常生活模式而无需先验知识，从而在数据稀疏或不完整的情况下（例如冷启动情况下）提高性能。我们的算法由两个主要模块组成。第一个是协同过滤模块，它应用协同过滤来模拟个人到感兴趣地点的正常移动。第二个是神经模块，负责解释人类轨迹数据中固有的复杂时空关系。为了验证我们的方法，我们使用模拟和真实世界的数据集与众多最先进的轨迹异常检测方法进行了广泛的实验。]]></description>
      <guid>https://arxiv.org/abs/2409.18427</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们是否需要特定领域的嵌入模型？一项实证研究</title>
      <link>https://arxiv.org/abs/2409.18511</link>
      <description><![CDATA[arXiv:2409.18511v1 公告类型：交叉 
摘要：嵌入模型在各种 NLP 应用程序中表示和检索信息方面起着至关重要的作用。大型语言模型 (LLM) 的最新进展进一步增强了嵌入模型的性能，这些模型在几乎涵盖所有领域的大量文本上进行训练。这些模型通常在通用数据集（如海量文本嵌入基准 (MTEB)）上进行基准测试，在这些数据集上它们表现出卓越的性能。然而，一个关键问题出现了：当通用模型在已经包含专业领域文本的大量语料库上进行训练时，是否有必要开发特定领域的嵌入模型？在本文中，我们以金融领域为例，对这个问题进行了实证研究。我们介绍了金融海量文本嵌入基准 (FinMTEB)，它是 MTEB 的对应物，由金融领域特定的文本数据集组成。我们评估了七种最先进的嵌入模型在 FinMTEB 上的性能，并观察到与在 MTEB 上的性能相比，性能显著下降。为了解释这种下降可能是由 FinMTEB 的更高复杂性导致的，我们提出了四种措施来量化数据集复杂性并控制我们分析中的这一因素。我们的分析提供了令人信服的证据，表明最先进的嵌入模型很难捕捉特定领域的语言和语义模式，即使在大型通用语料库上进行训练也是如此。这项研究揭示了在 LLM 时代开发特定领域嵌入模型的必要性，为研究人员和从业者提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.18511</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释丰富驱动的图谱推理器 (EDGAR)，适用于大型知识图谱，并可应用于药物再利用</title>
      <link>https://arxiv.org/abs/2409.18659</link>
      <description><![CDATA[arXiv:2409.18659v1 公告类型：交叉 
摘要：知识图谱 (KG) 表示现实世界实体之间的联系和关系。我们提出了一种名为 Enrichment-Driven GrAph Reasoner (EDGAR) 的 KG 链接预测框架，该框架通过挖掘实体局部规则来推断新边。这种方法利用了富集分析，这是一种成熟的统计方法，用于识别差异表达基因集共有的机制。EDGAR 的推理结果本质上是可解释和可排序的，p 值表示每个基于富集的规则的统计意义。
我们展示了该框架在大型生物医学 KG ROBOKOP 上的有效性，重点关注阿尔茨海默病 (AD) 的药物再利用作为案例研究。最初，我们从 KG 中提取了 14 种已知药物，并通过富集分析确定了 20 种背景生物标志物，揭示了与 AD 共享药物疗效相关的功能途径。随后，利用前 1000 个富集结果，我们的系统确定了另外 1246 种用于 AD 治疗的候选药物。前 10 个候选药物通过医学文献中的证据进行了验证。
EDGAR 部署在 ROBOKOP 中，并配有 Web 用户界面。这是第一项将富集分析应用于大型图完成和药物再利用的研究。]]></description>
      <guid>https://arxiv.org/abs/2409.18659</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用预训练语言模型进行多标签分类，根据安全网精神病院临床记录进行自杀表型分析</title>
      <link>https://arxiv.org/abs/2409.18878</link>
      <description><![CDATA[arXiv:2409.18878v1 公告类型：交叉 
摘要：准确识别和分类自杀事件可以更好地预防自杀，减轻运营负担，并提高高敏锐度精神病环境中的护理质量。预先训练的语言模型有望从非结构化的临床叙述中识别自杀倾向。我们使用两种微调策略（多个单标签和单个多标签）评估了四个基于 BERT 的模型的性能，用于从 500 份带注释的精神病评估记录中检测共存的自杀事件。这些笔记被标记为自杀意念 (SI)、自杀企图 (SA)、自杀暴露 (ES) 和非自杀性自残 (NSSI)。RoBERTa 使用二元相关性 (acc=0.86，F1=0.78) 优于其他模型。MentalBERT (F1=0.74) 也超过了 BioClinicalBERT (F1=0.72)。使用单个多标签分类器进行微调的 RoBERTa 进一步提高了性能（acc=0.88，F1=0.81），突出了在领域相关数据上进行预训练的模型和单个多标签分类策略提高了效率和性能。
关键词：基于 EHR 的表型分析；自然语言处理；EHR 数据的二次利用；自杀分类；基于 BERT 的模型；精神病学；心理健康]]></description>
      <guid>https://arxiv.org/abs/2409.18878</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LML：语言模型学习数据集以进行数据增强预测</title>
      <link>https://arxiv.org/abs/2409.18957</link>
      <description><![CDATA[arXiv:2409.18957v1 公告类型：交叉 
摘要：本文介绍了一种使用大型语言模型 (LLM) 进行分类任务的新方法，这些任务通常使用机器学习 (ML) 模型来处理。与严重依赖数据清理和特征工程的 ML 模型不同，此方法使用 LLM 简化了流程。本文提出了一种称为“语言模型学习 (LML)”的新概念，由一种称为“数据增强预测 (DAP)”的新方法提供支持。LLM 使用类似于人类手动探索和理解数据并使用数据作为参考来决定分类的方法执行分类。对训练数据进行总结和评估，以确定最能导致每个标签分类的特征。在 DAP 过程中，系统使用数据摘要自动创建查询，该查询用于从数据集中检索相关行。LLM 使用数据摘要和相关行生成分类，即使数据复杂也能确保令人满意的准确性。 DAP 中使用数据摘要和类似数据可确保情境感知决策。所提出的方法在提示中使用“充当可解释的机器学习模型”一词，通过允许用户查看每个预测背后的逻辑来增强预测的可解释性。在某些测试案例中，该系统的准确率超过 90%，证明了该系统的有效性及其在各种场景中超越传统 ML 模型的潜力。代码可在 https://github.com/Pro-GenAI/LML-DAP 获得]]></description>
      <guid>https://arxiv.org/abs/2409.18957</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于结构感知推荐嵌入演化的图形增强优化器</title>
      <link>https://arxiv.org/abs/2310.03032</link>
      <description><![CDATA[arXiv:2310.03032v3 公告类型：替换 
摘要：嵌入在现代推荐系统中起着关键作用，因为它们是现实世界实体的虚拟表示，也是后续决策模型的基础。在本文中，我们提出了一种新颖的嵌入更新机制，即结构感知嵌入演化（简称 SEvo），以鼓励相关节点在每一步中进行类似的演化。与通常用作中间模块的 GNN（图神经网络）不同，SEvo 能够在训练期间以最小的计算开销将图结构信息直接注入嵌入中。从理论上分析了 SEvo 及其潜在变体的收敛特性，以证明设计的有效性。此外，SEvo 可以无缝集成到现有的优化器中，以实现最先进的性能。特别是 SEvo 增强的 AdamW 和矩估计校正在一系列模型和数据集中表现出一致的改进，提出了一种在显式 GNN 模块之外有效利用图结构信息的新颖技术路线。]]></description>
      <guid>https://arxiv.org/abs/2310.03032</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>