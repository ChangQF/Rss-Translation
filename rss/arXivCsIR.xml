<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 06 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在可区分搜索索引中引入多样性</title>
      <link>https://arxiv.org/abs/2502.02788</link>
      <description><![CDATA[arXiv:2502.02788v1 公告类型：新
摘要：可微分搜索索引 (DSI) 是一种最新的信息检索范例，它使用基于变压器的神经网络架构作为文档索引来简化检索过程。可微分索引具有许多优点，可以对索引进行修改、更新或扩展。在这项工作中，我们探索了平衡相关性和新信息内容（多样性）以训练受最大边际相关性 (MMR) 启发的 DSI 系统，并展示了我们的方法相对于简单的 DSI 训练的优势。我们对使用我们的方法在 NQ320K 和 MSMARCO 数据集上获得的相关性和多样性度量进行了定量和定性评估，并与简单的 DSI 进行了比较。使用我们的方法，可以在不对相关性产生任何重大影响的情况下实现多样性。由于我们在训练 DSI 时引入了多样性，因此训练后的模型已经学会了在保持相关性的同时实现多样化。这消除了使用 MMR 通常执行的后处理步骤来引入召回集多样性的需要。我们的方法将对信息检索问题有用，因为相关性和多样性都很重要，例如子主题检索。我们的工作还可以轻松扩展到增量 DSI 设置，这将使索引在检索多样化召回集的同时实现快速更新。]]></description>
      <guid>https://arxiv.org/abs/2502.02788</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TD3：基于 Tucker 分解的序列推荐数据集蒸馏方法</title>
      <link>https://arxiv.org/abs/2502.02854</link>
      <description><![CDATA[arXiv:2502.02854v1 公告类型：新
摘要：在以数据为中心的人工智能时代，推荐系统的重点已经从以模型为中心的创新转向以数据为中心的方法。现代人工智能模型的成功建立在大规模数据集之上，但这也导致了巨大的训练成本。数据集蒸馏已成为一种关键解决方案，它可以浓缩大型数据集以加速模型训练，同时保持模型性能。然而，浓缩离散且顺序相关的用户项目交互，特别是具有广泛项目集的用户项目交互，带来了相当大的挑战。本文介绍了 \textbf{TD3}，这是一种基于 \textbf{T}ucker \textbf{D} 分解的新型 \textbf{D} 数据集 \textbf{D} 蒸馏方法，位于元学习框架内，专为顺序推荐而设计。TD3 从原始数据中提取出一个完全表达性的 \emph{合成序列摘要}。为了有效地降低计算复杂度并提取精细的潜在模式，Tucker 分解将摘要分解为四个因素：\emph{合成用户潜在因子}，\emph{时间动态潜在因子}，\emph{共享项目潜在因子}，以及模拟它们之间的互连的 \emph{关系核心}。此外，提出了双层优化中的替代目标，以对齐从在原始数据和合成序列摘要上训练的模型中提取的特征空间，超越了简单的性能匹配方法。在 \emph{内循环} 中，增强技术允许学习者紧密贴合合成摘要，确保在 \emph{外循环} 中准确更新它。为了加速优化过程并解决长依赖关系，RaT-BPTT 用于双层优化。在多个公共数据集上的实验和分析证实了所提设计的优越性和跨架构通用性。代码发布在 https://github.com/USTC-StarTeam/TD3。]]></description>
      <guid>https://arxiv.org/abs/2502.02854</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>控制搜索排名，控制世界：什么是好的搜索引擎？</title>
      <link>https://arxiv.org/abs/2502.02957</link>
      <description><![CDATA[arXiv:2502.02957v1 公告类型：新
摘要：本文探讨了“什么是好的搜索引擎？”这个道德问题。由于搜索引擎是全球在线信息的守门人，因此它们必须以道德的方式做好自己的工作。虽然互联网已经有几十年的历史了，但从跨学科的角度来看，这个话题仍然没有得到充分的探索。本文提出了一种新颖的基于角色的方法，涉及四种搜索引擎行为类型的道德模型：客户服务人员、图书管理员、记者和教师。它参考信息检索研究领域，并通过涉及 COVID-19 全球大流行的案例研究探讨了这些道德模型。它还从搜索引擎发展的历史角度反映了这四种道德模型，从 1990 年代早期的粗略努力，到最近基于大型语言模型的对话式信息搜索系统承担谷歌等成熟网络搜索引擎角色的前景。最后，本文概述了在搜索引擎不断发展的过程中，为当前和未来监管和问责提供参考的考虑因素。该论文应该引起信息检索研究人员和其他对搜索引擎伦理感兴趣的人的兴趣。]]></description>
      <guid>https://arxiv.org/abs/2502.02957</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FACTER：公平感知共形阈值和快速工程，实现基于 LLM 的公平推荐系统</title>
      <link>https://arxiv.org/abs/2502.02966</link>
      <description><![CDATA[arXiv:2502.02966v1 公告类型：新
摘要：我们提出了 FACTER，这是一个基于 LLM 的推荐系统的公平感知框架，它将共形预测与动态提示工程相结合。通过引入自适应语义方差阈值和违规触发机制，FACTER 会在出现偏见模式时自动收紧公平约束。我们进一步开发了一个对抗性提示生成器，利用历史违规来减少重复的人口统计学偏见，而无需重新训练 LLM。MovieLens 和亚马逊的实证结果表明，FACTER 大幅减少了公平违规（高达 95.5%），同时保持了较高的推荐准确性，揭示了语义方差是偏见的有力代理。]]></description>
      <guid>https://arxiv.org/abs/2502.02966</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估印度会议论文集的研究影响力：来自合作和引用的见解</title>
      <link>https://arxiv.org/abs/2502.02997</link>
      <description><![CDATA[arXiv:2502.02997v1 公告类型：新
摘要：会议是科学交流的重要渠道。然而，会议数量的增加和随后论文集的出版引发了人们对此类活动中展示的研究质量的质疑。本调查深入研究了 Springer 网络和系统系列讲义索引中的会议出版物。在本系列全球举办的 570 场国际会议中，有 177 场专门在印度举办。这 177 场会议共发表了 11,066 篇论文作为会议论文集。所有这些出版物以及会议详细信息均来自 Scopus 数据库。该研究旨在评估这些会议论文集的研究影响并确定主要贡献者。结果显示，每年的平均引用次数呈下降趋势。所有出版物的集体平均引用率为 1.01。印度和国际作者共同撰写的论文（5.6%）的平均影响力更高，为 1.44，而仅由印度作者撰写的论文（84.9%）的平均影响力为 0.97。值得注意的是，印度合作撰写的论文是最大的贡献者之一，主要来自私立学院和大学。只有 19% 的论文显示与不同声望的机构合作，但与与类似声望的机构合作相比，其影响力要高得多。这项研究强调了提高学术论坛研究质量的重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.02997</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FuXi-$\alpha$：基于特征交互增强 Transformer 的扩展推荐模型</title>
      <link>https://arxiv.org/abs/2502.03036</link>
      <description><![CDATA[arXiv:2502.03036v1 公告类型：新
摘要：受缩放定律和大型语言模型的启发，大规模推荐模型的研究引起了广泛关注。最近的进展表明，将顺序推荐模型扩展为大规模推荐模型可能是一种有效的策略。当前最先进的顺序推荐模型主要使用自注意力机制来处理项目之间的显式特征交互，而隐式交互则通过前馈网络 (FFN) 进行管理。然而，这些模型通常不能充分整合时间和位置信息，要么将它们添加到注意力权重中，要么将它们与潜在表示混合，这限制了它们的表达能力。最近的模型 HSTU 进一步减少了对隐式特征交互的关注，从而限制了其性能。我们提出了一个名为 FuXi-$\alpha$ 的新模型来解决这些问题。该模型引入了一种自适应多通道自注意力机制，可以清楚地模拟时间、位置和语义特征，以及一个多阶段 FFN 来增强隐式特征交互。我们的离线实验表明，我们的模型优于现有模型，并且其性能随着模型规模的增加而不断提高。此外，我们在华为音乐应用程序中进行了在线 A/B 测试，结果显示每位用户平均播放的歌曲数量增加了 $4.76\%$，每位用户平均收听时长增加了 $5.10\%$。我们的代码已在 https://github.com/USTC-StarTeam/FuXi-alpha 上发布。]]></description>
      <guid>https://arxiv.org/abs/2502.03036</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是通用推荐学习器</title>
      <link>https://arxiv.org/abs/2502.03041</link>
      <description><![CDATA[arXiv:2502.03041v1 公告类型：新
摘要：在现实世界的推荐系统中，通常使用对任务特定数据集的监督学习来解决不同的任务，这些数据集具有精心设计的模型架构。我们证明大型语言模型 (LLM) 可以充当通用推荐学习器，能够在统一的输入输出框架内处理多个任务，从而无需专门的模型设计。为了提高 LLM 的推荐性能，我们引入了一个用于项目表示的多模态融合模块和一个用于高效候选生成的序列设置方法。当应用于工业规模数据时，我们的 LLM 与为不同推荐任务精心设计的专家模型相比取得了有竞争力的结果。此外，我们的分析表明，推荐结果对文本输入高度敏感，凸显了快速工程在优化工业规模推荐系统方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.03041</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TREC 和 CLEF 中德国 IR 社区的科学计量分析</title>
      <link>https://arxiv.org/abs/2502.03065</link>
      <description><![CDATA[arXiv:2502.03065v1 公告类型：新
摘要：在本研究中，基于 OpenAlex 提供的元数据以及使用 GROBID 框架从出版物全文中提取的进一步元数据，分析了 2000 年至 2022 年期间德国信息检索社区对文本检索会议 (TREC) 和评估论坛会议和实验室 (CLEF) 检索活动的影响。分析是在机构和研究人员层面进行的。研究发现，无论是在作者层面还是在机构层面，德国 IR 社区都对 CLEF 做出了主要贡献。此外，研究还表明，生产力遵循洛特卡定律的假设。]]></description>
      <guid>https://arxiv.org/abs/2502.03065</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据坝：一种用于规范和管理大规模系统中数据流的新框架</title>
      <link>https://arxiv.org/abs/2502.03218</link>
      <description><![CDATA[arXiv:2502.03218v1 公告类型：新
摘要：在大数据时代，有效管理动态数据流至关重要，因为传统的存储模型难以实现实时调节和风险溢出。本文介绍了一种新颖的框架——数据坝，旨在通过动态调整流速来优化数据流入、存储和流出，以防止拥塞，同时最大限度地提高资源利用率。受物理大坝机制的启发，该框架采用智能水闸控制和预测分析来根据系统条件（例如带宽可用性、处理能力和安全约束）来调节数据流。模拟结果表明，与静态基线模型相比，数据坝显著降低了平均存储水平（371.68 vs. 426.27 单位）并增加了总流出量（7999.99 vs. 7748.76 单位）。通过在波动的数据负载下确保稳定且自适应的流出率，这种方法提高了系统效率，减轻了溢出风险，并且优于现有的静态流控制策略。所提出的框架为大规模分布式系统中的动态数据管理提供了一种可扩展的解决方案，为更具弹性和高效的实时处理架构铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.03218</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行推荐的意图表征学习</title>
      <link>https://arxiv.org/abs/2502.03307</link>
      <description><![CDATA[arXiv:2502.03307v1 公告类型：新
摘要：基于意图的推荐系统因揭示潜在的细粒度偏好而备受关注。意图作为交互的潜在因素，对于提高推荐的可解释性至关重要。大多数方法将意图定义为与交互一起更新的可学习参数。然而，现有的框架往往忽略了文本信息（例如，用户评论、项目描述），而文本信息对于缓解交互意图的稀疏性至关重要。探索这些多模态意图，特别是表示空间的固有差异，带来了两个关键挑战：i）如何对齐多模态意图并有效缓解噪声问题；ii）如何跨模态提取和匹配潜在的关键意图。为了应对这些挑战，我们提出了一个与模型无关的框架，即使用大型语言模型的意图表示学习（IRLLRec），它利用大型语言模型（LLM）来构建多模态意图并增强推荐。具体来说，IRLLRec 采用双塔架构来学习多模态意图表示。接下来，我们提出成对和平移对齐来消除模态间差异并增强对噪声输入特征的鲁棒性。最后，为了更好地匹配基于文本和交互的意图，我们采用动量蒸馏对融合意图表示进行师生学习。对三个数据集的实证评估表明，我们的 IRLLRec 框架优于基线。实现可在 https://github.com/wangyu0627/IRLLRec 获得。]]></description>
      <guid>https://arxiv.org/abs/2502.03307</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Hier-SUCB 的交互式可视化推荐</title>
      <link>https://arxiv.org/abs/2502.03375</link>
      <description><![CDATA[arXiv:2502.03375v1 公告类型：新
摘要：可视化推荐旨在实现对海量数据集的快速可视化分析。在现实场景中，快速收集和理解用户偏好以覆盖来自不同背景的用户（包括不同的技能水平和分析任务）至关重要。以前的个性化可视化推荐方法是非交互式的，并且依赖于新用户的初始用户数据。因此，这些模型无法有效地探索选项或适应实时反馈。为了解决这一限制，我们提出了一种交互式个性化可视化推荐 (PVisRec) 系统，该系统从以前的交互中学习用户反馈。为了提供更具交互性和准确性的推荐，我们提出了 Hier-SUCB，这是 PVisRec 设置中的上下文组合半强盗。从理论上讲，我们展示了改进的整体遗憾界限，时间等级相同，但动作空间等级有所提高。我们通过大量实验进一步证明了 Hier-SUCB 的有效性，它与离线方法相当，并且在可视化推荐设置中优于其他强盗算法。]]></description>
      <guid>https://arxiv.org/abs/2502.03375</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DenseReviewer：基于密集检索的系统评价筛选优先级工具</title>
      <link>https://arxiv.org/abs/2502.03400</link>
      <description><![CDATA[arXiv:2502.03400v1 公告类型：新
摘要：筛选是一项耗时且劳动密集型的医学系统评价任务，但也是必需的，因为通常需要筛选数以万计的研究。优先考虑要筛选的相关研究可以使下游系统评价创建任务更早开始并节省时间。在之前的工作中，我们开发了一种密集检索方法，在标题和摘要筛选阶段根据审稿人的反馈对相关研究进行优先排序。我们的方法在有效性和效率方面都优于以前的主动学习方法。在此演示中，我们通过创建 (1) 基于 Web 的筛选工具来扩展这项先前的工作，该工具使最终用户能够筛选利用最先进方法的研究，以及 (2) 一个集成模型和反馈机制的 Python 库，允许研究人员开发和展示新的主动学习方法。我们描述了该工具的设计并展示了它如何帮助筛选。该工具可在 https://densereviewer.ielab.io 上找到。源代码也在https://github.com/ielab/densereviewer开源。]]></description>
      <guid>https://arxiv.org/abs/2502.03400</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调查企业社会责任举措：考察企业应对新冠肺炎疫情的案例</title>
      <link>https://arxiv.org/abs/2502.03421</link>
      <description><![CDATA[arXiv:2502.03421v1 公告类型：新
摘要：在当今信息自由的时代，政策制定者在做出影响相关利益相关者的决策时必须考虑大量信息。虽然信息源和文件数量的增加增加了基于可用文本语料库的决策的可信度，但政策制定者很难理解这些信息。本文展示了政策制定者如何实施一些最流行的主题识别方法、潜在狄利克雷分配、深度分布式表示方法、文本摘要方法、基于单词的句子排名方法和用于句子提取的 TextRank 方法，以总结大量文档的内容以了解信息过载的要点。在 Covid-19 大流行的早期和晚期，我们将流行的 NLP 方法应用于企业新闻稿，这导致了全球前所未有的健康和社会经济危机，在面对未来类似的未见危机时，政策制定和法规对于规范企业的员工和社会福利实践变得尤为重要。本研究中采取的步骤可以复制，以从任何其他社会决策环境中的相关文献中获得见解。]]></description>
      <guid>https://arxiv.org/abs/2502.03421</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PalimpChat：声明性和交互式人工智能分析</title>
      <link>https://arxiv.org/abs/2502.03368</link>
      <description><![CDATA[arXiv:2502.03368v1 公告类型：交叉 
摘要：得益于生成架构和大型语言模型的进步，数据科学家现在可以编写机器学习操作的管道来处理大量非结构化数据。最近的进展见证了声明式 AI 框架（例如 Palimpzest、Lotus 和 DocETL）的兴起，这些框架用于构建优化且日益复杂的管道，但这些系统通常只有专家程序员才能访问。在此演示中，我们展示了 PalimpChat，这是一个基于聊天的 Palimpzest 界面，它通过让用户仅通过自然语言创建和运行复杂的 AI 管道来弥补这一差距。通过集成基于 ReAct 的推理代理 Archytas 以及 Palimpzest 的关系和基于 LLM 的运算符套件，PalimpChat 提供了一个实际的例子，说明聊天界面如何让非专家真正访问声明式 AI 框架。
我们的演示系统可在线公开。在 SIGMOD&#39;25 上，参与者可以探索三个真实场景——科学发现、法律发现和房地产搜索——或者将 PalimpChat 应用于他们自己的数据集。在本文中，我们重点介绍 Palimpzest 优化器支持的 PalimpChat 如何简化复杂的 AI 工作流程，例如提取和分析生物医学数据。]]></description>
      <guid>https://arxiv.org/abs/2502.03368</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因素链式论文与审稿人匹配</title>
      <link>https://arxiv.org/abs/2310.14483</link>
      <description><![CDATA[arXiv:2310.14483v3 公告类型：替换 
摘要：随着学术会议论文提交量的快速增加，对自动和准确的论文-审稿人匹配的需求比以往任何时候都更加迫切。该领域的先前研究考虑了各种因素来评估审稿人的专业知识与论文的相关性，例如论文与审稿人之前作品之间的语义相似性、共同主题和引用联系。然而，这些研究大多只关注一个因素，导致对论文-审稿人相关性的评估不完整。为了解决这个问题，我们提出了一个统一的论文-审稿人匹配模型，该模型共同考虑了语义、主题和引用因素。具体来说，在训练过程中，我们对所有因素共享的语境化语言模型进行指令调整，以捕捉它们的共性和特征；在推理过程中，我们将这三个因素链接起来，以便根据提交的内容逐步、从粗到细地搜索合格的审稿人。在机器学习、计算机视觉、信息检索和数据挖掘等各个领域的四个数据集（其中一个是我们新贡献的）上的实验一致证明了我们提出的因素链模型与最先进的论文审稿人匹配方法和科学的预训练语言模型相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2310.14483</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>