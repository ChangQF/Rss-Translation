<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 12 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>二分网络中的链接预测</title>
      <link>https://arxiv.org/abs/2406.06658</link>
      <description><![CDATA[arXiv:2406.06658v1 公告类型：交叉 
摘要：二分网络是非常适合表示涉及两种不同类型实体之间交互的系统（例如在线约会平台、求职服务或电子商务网站）的模型。这些模型可用于处理许多任务，包括最有用的任务之一的链接预测，尤其是设计推荐系统。但是，如果这项任务在单分（即标准）网络上进行时引起了人们的极大兴趣，那么对于二分网络来说，情况就远非如此了。在本研究中，我们通过对 19 种能够处理二分图的链接预测方法进行实验比较来解决这一差距。有些直接来自文献，有些是我们根据最初为单分网络设计的技术改编的。我们还建议将基于图卷积网络 (GCN) 的推荐系统重新用作二分网络的新型链接预测解决方案。为了进行实验，我们构建了具有各种拓扑结构的 3 个真实二分网络数据集的基准。我们的结果表明，近年来备受关注的基于 GCN 的个性化推荐系统可以在二分网络中产生成功的链接预测结果。此外，不依赖于任何学习过程的纯启发式指标（如结构扰动方法 (SPM)）也可以取得成功。]]></description>
      <guid>https://arxiv.org/abs/2406.06658</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>安娜卡列尼娜再次来袭：预先训练的 LLM 嵌入可能有利于高绩效学习者</title>
      <link>https://arxiv.org/abs/2406.06599</link>
      <description><![CDATA[arXiv:2406.06599v1 公告类型：交叉 
摘要：使用预训练的 LLM 嵌入将学生对开放式问题的回答无监督地聚类为行为和认知档案是一种新兴技术，但人们对其如何很好地捕捉具有教学意义的信息知之甚少。我们在学生对生物学开放式问题的回答的背景下对此进行了调查，这些问题之前已由专家分析并聚类为理论驱动的知识档案 (KP)。将这些 KP 与纯数据驱动的聚类技术发现的 KP 进行比较，我们报告称大多数 KP 的可发现性较差，除了包含正确答案的 KP。我们将这种“可发现性偏差”追溯到预训练的 LLM 嵌入空间中 KP 的表示。]]></description>
      <guid>https://arxiv.org/abs/2406.06599</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能高效分析复杂政策文件：以第 14110 号行政命令为例</title>
      <link>https://arxiv.org/abs/2406.06657</link>
      <description><![CDATA[arXiv:2406.06657v1 公告类型：交叉 
摘要：政策文件，如立法、法规和行政命令，对于塑造社会至关重要。然而，它们的篇幅和复杂性使得解释和应用具有挑战性和耗时性。人工智能（AI），特别是大型语言模型（LLM），有可能自动化分析这些文档的过程，提高准确性和效率。本研究旨在评估人工智能在简化政策分析方面的潜力，并确定当前人工智能方法的优势和局限性。该研究侧重于问答和涉及从政策文件中提取内容的任务。以行政命令 14110“安全、可靠和值得信赖的人工智能开发和使用”作为测试案例进行了案例研究。四个商业人工智能系统被用于分析文档并回答一组代表性政策问题。将人工智能系统的性能与人类专家进行的手动分析进行了比较。研究发现，两个人工智能系统 Gemini 1.5 Pro 和 Claude 3 Opus 表现出支持政策分析的巨大潜力，可以从复杂文档中提取准确可靠的信息。它们的表现与人类分析师相当，但效率明显更高。然而，实现可重复性仍然是一个挑战，需要进一步研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2406.06657</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐的 Matryoshka 表示学习</title>
      <link>https://arxiv.org/abs/2406.07432</link>
      <description><![CDATA[arXiv:2406.07432v1 公告类型：新
摘要：表征学习对于基于深度神经网络的推荐系统至关重要，它可以在固定维度的用户和项目向量中捕获用户偏好和项目特征。与现有的表征学习方法不同，现有的表征学习方法要么统一处理每个用户偏好和项目特征，要么将它们分类为离散聚类，我们认为在现实世界中，用户偏好和项目特征自然地以分层方式表达和组织，这为表征学习带来了新的方向。在本文中，我们介绍了一种用于推荐的新型套娃表征学习方法 (MRL4Rec)，通过该方法，我们将用户和项目向量重构为具有增量维度和重叠向量空间的套娃表征，以明确表示不同层次上的用户偏好和项目特征。我们从理论上确定，构建特定于每个级别的训练三元组对于保证准确的套娃表征学习至关重要。随后，我们提出了套娃负采样机制来构建训练三元组，这进一步确保了套娃表示学习在捕捉分层用户偏好和项目特征方面的有效性。实验表明，MRL4Rec 可以在多个真实数据集上持续且显著地超越许多最先进的竞争对手。我们的代码可在 https://github.com/Riwei-HEU/MRL 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2406.07432</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络增强检索用于法学硕士问答</title>
      <link>https://arxiv.org/abs/2406.06572</link>
      <description><![CDATA[arXiv:2406.06572v1 公告类型：交叉 
摘要：检索增强生成通过提供事实支持彻底改变了大型语言模型 (LLM) 的输出。然而，它很难捕捉到复杂推理问题所需的所有知识。现有的检索方法通常将参考文档分成段落，单独处理它们。然而，这些段落往往是相互关联的，例如连续的段落或共享相同关键词的段落。因此，识别相关性对于增强检索过程至关重要。在本文中，我们提出了一种称为 GNN-Ret 的新型检索方法，该方法利用图神经网络 (GNN) 通过考虑段落之间的相关性来增强检索。具体来说，我们首先通过连接与结构相关和与关键字相关的段落来构建段落图。然后利用图神经网络 (GNN) 来利用段落之间的关系并改进支持段落的检索。此外，我们扩展了我们的方法，使用名为 RGNN-Ret 的循环图神经网络 (RGNN) 来处理多跳推理问题。在每个步骤中，RGNN-Ret 都会集成来自先前步骤的段落图，从而增强对支持段落的检索。在基准数据集上进行的大量实验表明，GNN-Ret 使用单个 LLM 查询实现的问答准确率高于需要多个查询的强基线，并且 RGNN-Ret 进一步提高了准确率并实现了最先进的性能，在 2WikiMQA 数据集上的准确率提高了 10.4%。]]></description>
      <guid>https://arxiv.org/abs/2406.06572</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>德顿语文本信息检索：初步研究</title>
      <link>https://arxiv.org/abs/2406.07331</link>
      <description><![CDATA[arXiv:2406.07331v1 公告类型：新
摘要：德顿语是东帝汶的官方语言之一，与葡萄牙语并列。这是一种资源匮乏的语言，使用者超过 932,400 人，在东帝汶于 2002 年恢复独立后开始发展。媒体主要使用德顿语，每天有十多家全国性在线报纸积极播报德顿语新闻。然而，由于不存在针对德顿语的信息检索解决方案，因此在互联网上查找德顿语信息具有挑战性。这项工作旨在研究和开发能够应用信息检索技术来开发针对德顿语的搜索解决方案的解决方案。我们介绍了对德顿语进行临时检索任务的实验的初步结果。]]></description>
      <guid>https://arxiv.org/abs/2406.07331</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>可解释冷启动推荐的图形推理</title>
      <link>https://arxiv.org/abs/2406.07420</link>
      <description><![CDATA[arXiv:2406.07420v1 公告类型：新
摘要：冷启动问题，即新用户或项目没有交互历史，仍然是推荐系统 (RS) 中的一个关键挑战。一种常见的解决方案是使用知识图谱 (KG) 来训练实体嵌入或图神经网络 (GNN)。由于 KG 不仅包含用户/项目交互，还包含辅助数据，因此这些方法可以为冷用户或项目提供相关建议。然而，图推理 (GR) 方法使用 KG 中的关系找到从用户到要推荐的项目的路径，并且在 RS 的背景下，已用于可解释性。在本研究中，我们提出了 GRECS：一个将 GR 适应冷启动推荐的框架。通过利用从用户开始的显式路径而不是仅依赖实体嵌入，GRECS 可以通过浏览图表找到与用户偏好相对应的项目，即使在用户信息有限的情况下也是如此。我们的实验表明，GRECS 可以缓解冷启动问题，并且在 5 个标准数据集上的表现优于竞争基线，同时具有可解释性。这项研究强调了 GR 在开发更适合管理冷用户和项目的可解释推荐系统方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.07420</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>探索用于 Tetun 语相关性判断的大型语言模型</title>
      <link>https://arxiv.org/abs/2406.07299</link>
      <description><![CDATA[arXiv:2406.07299v1 公告类型：新
摘要：Cranfield 范式一直是开发测试集的基础方法，相关性判断通常由人类评估员进行。然而，大型语言模型 (LLM) 的出现为自动化这些任务带来了新的可能性。本文探讨了使用 LLM 自动化相关性评估的可行性，特别是在低资源语言的背景下。在我们的研究中，LLM 用于自动化相关性判断任务，通过提供一系列 Tetun 中的查询文档对作为输入文本。这些模型的任务是为每对分配相关性分数，然后将这些分数与人类注释者的分数进行比较，以评估注释者之间的一致性水平。我们的调查结果与高资源语言研究中报告的结果非常吻合。]]></description>
      <guid>https://arxiv.org/abs/2406.07299</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>Fetch-A-Set：用于历史文档检索的大规模无 OCR 基准测试</title>
      <link>https://arxiv.org/abs/2406.07315</link>
      <description><![CDATA[arXiv:2406.07315v1 公告类型：新
摘要：本文介绍了 Fetch-A-Set (FAS)，这是一种针对立法历史文献分析系统量身定制的综合基准，解决了历史背景下大规模文档检索的挑战。该基准包含一个可追溯到 17 世纪的庞大文档库，既可作为训练资源，又可作为检索系统的评估基准。它通过专注于文化遗产领域内复杂的提取任务，填补了文献中的一个关键空白。提出的基准解决了历史文献分析的多方面问题，包括查询的文本到图像检索和从文档片段中提取图像到文本的主题，同时适应不同程度的文档可读性。该基准旨在通过为强大的历史文献检索系统的开发和评估提供基线和数据来促进该领域的进步，特别是在具有广泛历史范围的场景中。]]></description>
      <guid>https://arxiv.org/abs/2406.07315</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>排序重叠中的平局处理</title>
      <link>https://arxiv.org/abs/2406.07121</link>
      <description><![CDATA[arXiv:2406.07121v1 公告类型：新
摘要：排序偏向重叠 (RBO) 是一种用于不确定排名的相似性度量：它是顶部加权的，当仅知道排名的前缀或它们只有一些共同项时，就可以计算出来。它被广泛用于分析搜索引擎之间的差异，例如，通过比较它们对相同查询检索到的文档的排名。然而，在这些情况下，找到具有相同分数的并列文档是很常见的。不幸的是，RBO 中对并列的处理仍然很肤浅和不完整，因为不清楚如何仅从排名前缀计算它。此外，现有的处理并列的方法与统计学领域传统上遵循的方法非常不同，最显著的是在 Kendall 和 Spearman 等等级相关系数中发现的。在本文中，我们提出了一种用于处理并列的 RBO 的通用公式，通过展示如何执行前缀评估来完成原始定义。我们还使用它来全面开发与统计文献中发现的一致的两种变体：一种是当有参考排名可供比较时，另一种是当没有参考排名可供比较时。总体而言，这三种变体为研究人员在将排名与 RBO 进行比较时提供了灵活性，通过明确确定平局的含义以及应如何处理它们。最后，使用合成数据和 TREC 数据，我们展示了这些新的平局感知 RBO 度量的使用。我们表明，得分可能与原始的平局不感知 RBO 度量有很大不同，在原始平局不感知 RBO 度量中，平局必须随机或通过任意标准（例如文档 ID）打破。总体而言，这些结果证明需要适当考虑 RBO​​ 等排名相似性度量中的平局。]]></description>
      <guid>https://arxiv.org/abs/2406.07121</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>针对成本受限数据源的检索的渐进式查询扩展</title>
      <link>https://arxiv.org/abs/2406.07136</link>
      <description><![CDATA[arXiv:2406.07136v1 公告类型：新
摘要：长期以来，查询扩展一直被用来提高查询检索器的准确性。早期的研究依赖于伪相关反馈 (PRF) 技术，该技术使用从第一阶段检索到的文档中提取的术语来增强查询。但是，文档可能很嘈杂，从而妨碍了排名的有效性。为了避免这种情况，最近的研究改用大型语言模型 (LLM) 来生成额外的内容来扩展查询。这些技术容易产生幻觉，也关注 LLM 的使用成本。然而，在几个重要的实际场景中，成本可能由检索决定，在这些场景中，语料库仅通过 API 提供，API 对每个检索到的文档收取费用。我们建议将经典的 PRF 技术与 LLM 相结合，并创建一个渐进式查询扩展算法 ProQE，该算法在检索更多文档时迭代扩展查询。ProQE 与稀疏和密集检索系统兼容。我们在四个检索数据集上的实验结果表明，ProQE 的性能比最先进的基线高出 37%，并且最具成本效益。]]></description>
      <guid>https://arxiv.org/abs/2406.07136</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>通过 Transformer 模型利用多传感器遥感影像中的气候变量预测葡萄病害</title>
      <link>https://arxiv.org/abs/2406.07094</link>
      <description><![CDATA[arXiv:2406.07094v1 公告类型：新
摘要：葡萄病害的早期发现和管理对于实现可持续葡萄栽培至关重要。本文介绍了一种利用 TabPFN 模型的新框架，该模型使用来自多传感器遥感图像的气候变量来预测葡萄病害。通过将先进的机器学习技术与详细的环境数据相结合，我们的方法显着提高了葡萄园病害预测的准确性和效率。TabPFN 模型的实验评估展示了与传统梯度提升决策树（如 XGBoost、CatBoost 和 LightGBM）相当的性能。该模型能够处理复杂数据并提供每像素疾病影响概率，从而实现精准、有针对性的干预，从而有助于实现更可持续的疾病管理实践。我们的研究结果强调了将 Transformer 模型与遥感数据相结合在精准农业中的变革潜力，为改善作物健康和生产力同时减少环境影响提供了可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.07094</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>通过用户查询引导目录丰富</title>
      <link>https://arxiv.org/abs/2406.07098</link>
      <description><![CDATA[arXiv:2406.07098v1 公告类型：新
摘要：知识图谱 (KG) 丰富技术对于依赖于不断发展的产品目录的商业应用越来越重要。然而，由于潜在丰富的搜索空间巨大，知识图谱完成 (KGC) 方法的预测精度较低，因此对于现实世界的目录来说并不可靠。此外，丰富的候选事实与用户的相关性各不相同。虽然对知识图谱中不完整的三元组做出正确的预测一直是 KGC 方法的主要关注点，但何时应用此类预测的相关性却被忽视了。受产品搜索用例的启发，我们解决了使用用户搜索行为和用户属性与产品的关联为目录生成相关完成的角度。在本文中，我们提出了识别可丰富数据点的直觉，并使用通用知识图谱来展示性能优势。具体来说，我们从用户查询中提取更有可能正确和相关的实体-谓词对，并使用这些对来指导 KGC 方法的预测。我们在两个流行的百科全书 KG，DBPedia 和 YAGO 4 上评估了我们的方法。我们的自动和人工评估结果表明，查询指导可以显著提高预测的正确性和相关性。]]></description>
      <guid>https://arxiv.org/abs/2406.07098</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型为虚拟助手生成合成查询</title>
      <link>https://arxiv.org/abs/2406.06729</link>
      <description><![CDATA[arXiv:2406.06729v1 公告类型：新
摘要：虚拟助手 (VA) 是重要的信息检索平台，可帮助用户通过口头命令完成各种任务。语音识别系统 (语音转文本) 使用仅对文本进行训练的查询先验来区分语音上令人困惑的替代方案。因此，生成类似于现有 VA 用法的合成查询可以极大地提高 VA 的能力——尤其是对于尚未在配对音频/文本数据中出现的用例。
在本文中，我们对使用大型语言模型 (LLM) 生成与基于模板的方法互补的合成查询进行了初步探索。我们调查这些方法 (a) 是否生成与来自流行 VA 的随机抽样、代表性和匿名用户查询类似的查询，以及 (b) 生成的查询是否特定。
我们发现与基于模板的方法相比，LLM 会生成更详细的查询，并且引用特定于实体的方面。生成的查询与 VA 用户查询类似，并且足够具体，可以检索相关实体。我们得出结论，LLM 和模板生成的查询是互补的。]]></description>
      <guid>https://arxiv.org/abs/2406.06729</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>TIM：通知系统中的时间交互模型</title>
      <link>https://arxiv.org/abs/2406.07067</link>
      <description><![CDATA[arXiv:2406.07067v1 公告类型：新
摘要：现代移动应用程序严重依赖通知系统来获取每日活跃用户并增强用户参与度。为了能够主动联系用户，系统必须决定何时向用户发送通知。尽管许多研究人员已经研究了优化发送通知的时间，但他们只利用了用户的上下文特征，而没有对用户的行为模式进行建模。此外，这些努力仅侧重于单个通知，缺乏对优化一段时间内多个通知的整体时间的研究。为了弥补这些差距，我们提出了时间交互模型 (TIM)，该模型通过估计我们的短视频应用程序快手一天内每个时间段的点击率来建模用户的行为模式。TIM 利用长期用户历史交互序列特征，例如通知收据、点击、观看时间和有效观看次数，并使用时间注意单元 (TAU) 来提取用户行为模式。此外，我们提供了一种优雅的整体通知发送时间控制策略，以提高用户参与度，同时最大限度地减少干扰。我们通过离线实验和在线 A/B 测试评估了 TIM 的有效性。结果表明，TIM 是一种可靠的用户行为预测工具，可以显著提高用户参与度，而不会造成过度干扰。]]></description>
      <guid>https://arxiv.org/abs/2406.07067</guid>
      <pubDate>Wed, 12 Jun 2024 06:19:51 GMT</pubDate>
    </item>
    </channel>
</rss>