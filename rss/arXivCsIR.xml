<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用多数投票的本地大型语言模型进行动态情绪分析：影响餐厅评价的因素研究</title>
      <link>https://arxiv.org/abs/2407.13069</link>
      <description><![CDATA[arXiv:2407.13069v1 公告类型：交叉 
摘要：在线平台上的用户生成内容 (UGC) 使营销研究人员能够了解消费者对产品和服务的偏好。随着大型语言模型 (LLM) 的进步，一些研究利用该模型进行注释和情感分析。然而，LLM 的准确性和超参数之间的关系尚未得到彻底研究。此外，现有文献中很少考虑 LLM 每次试验结果的可变性和可重复性问题。由于实际的人工注释使用多数投票来解决注释者之间的分歧，本研究将多数投票机制引入使用本地 LLM 的情感分析模型。通过对餐厅评估的在线评论进行三次分析，我们证明使用中型模型多次尝试的多数投票比使用大型模型一次尝试产生更稳健的结果。此外，我们进行了进一步的分析，以调查每个方面对整体评估的影响。]]></description>
      <guid>https://arxiv.org/abs/2407.13069</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>BRIGHT：推理密集型检索的现实且具有挑战性的基准</title>
      <link>https://arxiv.org/abs/2407.12883</link>
      <description><![CDATA[arXiv:2407.12883v1 公告类型：交叉 
摘要：现有的检索基准主要由信息搜索查询（例如来自搜索引擎的聚合问题）组成，其中关键字或基于语义的检索通常就足够了。然而，许多复杂的现实世界查询需要深入推理才能识别超出表面形式匹配的相关文档。例如，查找编码问题的文档需要了解所涉及函数的逻辑和语法。为了更好地对此类具有挑战性的查询进行基准检索，我们引入了 BRIGHT，这是第一个需要深入推理才能检索相关文档的文本检索基准。BRIGHT 由从不同领域（如经济学、心理学、机器人技术、软件工程、地球科学等）收集的 1,398 个现实世界查询构建而成，这些查询来自自然发生或精心策划的人类数据。广泛的评估表明，即使是最先进的检索模型在 BRIGHT 上的表现也很差。 MTEB 排行榜 [38] 上的领先模型获得了 59.0 nDCG@10,2 的分数，在 BRIGHT 上产生了 18.0 的 nDCG@10 分数。我们进一步证明，使用大型语言模型 (LLM) 生成的思想链推理来增强查询可将性能提高多达 12.2 分。此外，BRIGHT 在基准模型的预训练过程中能够抵御数据泄露，这一点我们通过展示相似的性能来验证，即使训练数据中包含基准中的文档也是如此。我们相信 BRIGHT 为未来在更现实和更具挑战性的环境中研究检索系统铺平了道路。我们的代码和数据可在 https://brightbenchmark.github.io 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.12883</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>检索增强机器学习：综合与机遇</title>
      <link>https://arxiv.org/abs/2407.12982</link>
      <description><![CDATA[arXiv:2407.12982v1 公告类型：交叉 
摘要：在语言建模领域，增强检索组件的模型已成为解决自然语言处理 (NLP) 领域面临的若干挑战（包括知识基础、可解释性和可扩展性）的有前途的解决方案。尽管主要关注 NLP，但我们认为检索增强范式可以扩展到更广泛的机器学习 (ML) 领域，例如计算机视觉、时间序列预测和计算生物学。因此，这项工作通过综合 ML 中各个领域的文献和当前文献中缺少的一致符号，引入了此范式的正式框架，即检索增强机器学习 (REML)。此外，我们发现，虽然许多研究使用检索组件来增强其模型，但缺乏与基础信息检索 (IR) 研究的整合。我们通过研究构成 REML 框架的每个组件来弥补开创性的 IR 研究与当代 REML 研究之间的差距。最终，这项工作的目标是为各个学科的研究人员提供全面、形式化结构的检索增强模型框架，从而促进未来的跨学科研究。]]></description>
      <guid>https://arxiv.org/abs/2407.12982</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>使用万亿令牌数据存储扩展基于检索的语言模型</title>
      <link>https://arxiv.org/abs/2407.12854</link>
      <description><![CDATA[arXiv:2407.12854v1 公告类型：交叉 
摘要：关于训练数据量和参数数量的缩放定律使我们能够预测不同配置下预训练语言模型 (LM) 的成本效益权衡。在本文中，我们考虑了缩放的另一个维度：推理时可用的数据量。具体而言，我们发现增加基于检索的 LM 使用的数据存储的大小可以单调地改善语言建模和几个下游任务，而不会出现明显的饱和，因此，在知识密集型任务上，使用大型数据存储增强的较小模型优于较大的仅 LM 模型。通过绘制具有不同数据存储、模型和预训练数据大小的计算最佳缩放曲线，我们表明使用更大的数据存储可以显着提高相同训练计算预算的模型性能。我们通过构建一个名为 MassiveDS 的 1.4 万亿令牌数据存储（这是迄今为止最大、最多样化的基于检索的 LM 开源数据存储）并设计一个高效的管道来以计算可访问的方式研究数据存储扩展，从而开展了我们的研究。最后，我们分析了改进检索器、数据存储质量过滤和其他设计选择对我们观察到的扩展趋势的影响。总体而言，我们的结果表明，数据存储大小应被视为 LM 效率和性能权衡的一个组成部分。为了方便未来的研究，我们在 https://github.com/RulinShao/retrieval-scaling 开源了我们的数据存储和代码。]]></description>
      <guid>https://arxiv.org/abs/2407.12854</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>论文 SEA 中的自动化同行评审：标准化、评估和分析</title>
      <link>https://arxiv.org/abs/2407.12857</link>
      <description><![CDATA[arXiv:2407.12857v1 公告类型：交叉 
摘要：近年来，科学论文的快速增长使传统的审查机制不堪重负，导致出版物质量参差不齐。尽管现有方法已经探索了大型语言模型 (LLM) 在自动科学审查方面的能力，但它们生成的内容往往是通用的或部分的。为了解决上述问题，我们引入了一个自动化论文审查框架 SEA。它由三个模块组成：标准化、评估和分析，分别由模型 SEA-S、SEA-E 和 SEA-A 表示。首先，SEA-S 提炼 GPT-4 的数据标准化能力，以整合一篇论文的多个评论。然后，SEA-E 利用标准化数据进行微调，使其能够生成建设性的评论。最后，SEA-A 引入了一种称为不匹配分数的新评估指标来评估论文内容和评论之间的一致性。此外，我们设计了一种自我纠正策略来增强一致性。从八个场馆收集的数据集的大量实验结果表明，SEA 可以为作者改进论文提供有价值的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.12857</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>电信领域问答系统的 RAG 指标评估</title>
      <link>https://arxiv.org/abs/2407.12873</link>
      <description><![CDATA[arXiv:2407.12873v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 被广泛用于使大型语言模型 (LLM) 在各个领域执行问答 (QA) 任务。然而，基于开源 LLM 的专业领域 RAG 在评估生成的响应方面面临挑战。文献中流行的框架是 RAG 评估 (RAGAS)，这是一个使用 LLM 进行评估的公开库。RAGAS 的一个缺点是缺乏评估指标数值推导的细节。这项工作的成果之一是针对一些指标（忠诚度、上下文相关性、答案相关性、答案正确性、答案相似性和事实正确性）对该包进行了修改，通过该修改，我们使用任何 LLM 提供提示的中间输出。接下来，我们分析修改后的 RAGAS 包输出的专家评估，并观察在电信领域使用它的挑战。我们还研究了正确检索和错误检索下指标的影响，并观察到很少有指标在正确检索时具有更高的值。我们还研究了基础嵌入和通过预训练和微调适应的领域之间的指标差异。最后，我们评论了使用这些指标进行野外电信 QA 任务的适用性和挑战。]]></description>
      <guid>https://arxiv.org/abs/2407.12873</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:53 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统综合回顾：从理论到实践</title>
      <link>https://arxiv.org/abs/2407.13699</link>
      <description><![CDATA[arXiv:2407.13699v1 公告类型：新
摘要：推荐系统 (RS) 通过提供个性化项目建议在增强用户体验方面发挥着不可或缺的作用。这项调查全面回顾了 2017 年至 2024 年 RS 的进展，有效地将理论进步与实际应用联系起来。我们探索从基于内容和协同过滤等传统 RS 技术到涉及深度学习、基于图的模型、强化学习和大型语言模型的高级方法的发展。我们还讨论了专门的系统，例如上下文感知、基于评论和公平感知的 RS。这项调查的主要目标是将理论与实践联系起来。它解决了电子商务、医疗保健和金融等各个领域的挑战，强调了对可扩展、实时和可信赖的解决方案的需求。通过这项调查，我们促进了学术研究和行业实践之间更强有力的伙伴关系。这项调查提供的见解旨在指导行业专业人士优化 RS 部署并启发未来的研究方向，特别是在应对新兴技术和社会趋势方面]]></description>
      <guid>https://arxiv.org/abs/2407.13699</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>事实核查中声明真实性的自动论证生成：架构与方法综述</title>
      <link>https://arxiv.org/abs/2407.12853</link>
      <description><![CDATA[arXiv:2407.12853v1 公告类型：交叉 
摘要：自动事实核查 (AFC) 是对声明准确性的自动验证。AFC 在辨别真相和错误信息方面至关重要，尤其是考虑到每天在线生成大量内容。当前的研究重点是通过元数据分析和语言审查来预测声明的真实性，重点是证明判决的合理性。本文概述了最近的方法，提出了一个全面的分类法，并介绍了该领域研究的发展。还讨论了方法的比较分析和提高事实核查可解释性的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2407.12853</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:52 GMT</pubDate>
    </item>
    <item>
      <title>用于单应性估计的语义感知表征学习</title>
      <link>https://arxiv.org/abs/2407.13284</link>
      <description><![CDATA[arXiv:2407.13284v1 公告类型：新
摘要：单应性估计是从图像对中确定变换的任务。我们的方法侧重于采用无检测器特征匹配方法来解决这个问题。以前的工作强调了结合语义信息的重要性，但仍然缺乏一种有效的方法来利用语义信息。以前的方法将语义视为预处理，导致语义的使用过于粗粒度，在处理不同任务时缺乏适应性。在我们的工作中，我们寻求另一种使用语义信息的方法，即语义感知特征表示学习框架。基于此，我们提出了一种新的无检测器特征匹配方法 SRMatcher，它鼓励网络学习集成的语义特征表示。具体来说，为了捕捉精确而丰富的语义，我们利用了最近流行的在大量数据集上训练的视觉基础模型 (VFM) 的功能。然后，提出了一种跨图像语义感知融合块 (SFB)，将其细粒度语义特征集成到特征表示空间中。通过这种方式，通过减少匹配对中语义不一致导致的错误，我们提出的 SRMatcher 能够提供更准确、更真实的结果。大量实验表明，SRMatcher 超越了坚实的基线，并在多个真实世界数据集上获得了 SOTA 结果。与之前的 SOTA 方法 GeoFormer 相比，SRMatcher 在 HPatches 上将累积曲线下面积 (AUC) 增加了约 11\%。此外，SRMatcher 可以作为其他匹配方法（如 LoFTR）的即插即用框架，从而显着提高精度。]]></description>
      <guid>https://arxiv.org/abs/2407.13284</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>DCNv3：面向 CTR 预测的下一代深度交叉网络</title>
      <link>https://arxiv.org/abs/2407.13349</link>
      <description><![CDATA[arXiv:2407.13349v1 公告类型：新
摘要：深度交叉网络及其衍生模型由于在计算成本和性能之间实现了有效平衡，已成为点击率（CTR）预测的重要范例。然而，这些模型面临四个主要限制：（1）虽然大多数模型声称能够捕获高阶特征交互，但它们通常通过深度神经网络（DNN）隐式且不可解释地进行，这限制了模型预测的可信度；（2）现有的显式特征交互方法的性能通常弱于隐式DNN，从而削弱了它们的必要性；（3）许多模型无法在增强特征交互顺序的同时自适应地过滤噪声；（4）大多数模型的融合方法无法为不同的交互方法提供合适的监督信号。
针对已发现的局限性，本文提出了下一代深度交叉网络（DCNv3）和浅层和深度交叉网络（SDCNv3）。这些模型在保证特征交叉建模可解释性的同时，指数级提升特征交叉的阶数，实现真正的Deep Crossing而非Deep⨯。同时，我们采用Self-Mask操作滤除噪音，将交叉网络的参数数量减少一半。在融合层，我们采用简单有效的Tri-BCE损失权重计算方法，提供合适的监督信号。在6个数据集上进行了全面的实验，证明了DCNv3和SDCNv3的有效性、效率和可解释性。代码、运行日志和详细的超参数配置可在此处获取：https://anonymous.4open.science/r/DCNv3-E352。]]></description>
      <guid>https://arxiv.org/abs/2407.13349</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>信息图表语言：理解科学故事中概念隐喻的使用</title>
      <link>https://arxiv.org/abs/2407.13416</link>
      <description><![CDATA[arXiv:2407.13416v1 公告类型：新
摘要：我们应用认知语言学的方法，将概念隐喻理论 (CMT) 映射到可视化领域，以解决科学信息图中经常使用的视觉概念隐喻模式。隐喻在视觉交流中起着至关重要的作用，经常被用来解释复杂的概念。然而，它们的使用往往是基于直觉，而不是遵循正式的过程。目前，我们缺乏理解和描述可视化中隐喻使用的工具和语言，以至于分类学和语法可以指导视觉组件（例如信息图表）的创建。我们对科学表示中的视觉概念映射的分类是基于现有科学信息图中视觉组件的细分。我们通过详细分析从四个领域（生物医学、气候、空间和人类学）收集的数据来展示这种映射的发展，这些数据代表了科学视觉交流中使用的各种视觉概念隐喻。这项研究使我们能够识别领域内视觉概念隐喻的使用模式，解决关于为什么使用特定概念隐喻的歧义，并更好地全面理解科学信息图表中的视觉隐喻使用。我们的分析表明，本体论和方向性概念隐喻在翻译复杂的科学概念时应用最为广泛。为了支持我们的发现，我们基于收集的数据库开发了一个视觉探索工具，该工具将单个信息图表置于时空尺度上，并说明视觉概念隐喻的细分。]]></description>
      <guid>https://arxiv.org/abs/2407.13416</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:51 GMT</pubDate>
    </item>
    <item>
      <title>ROLeR：推荐系统离线强化学习中的有效奖励塑造</title>
      <link>https://arxiv.org/abs/2407.13163</link>
      <description><![CDATA[arXiv:2407.13163v1 公告类型：新
摘要：离线强化学习 (RL) 是现实世界推荐系统的有效工具，它能够对用户的动态兴趣进行建模，并且具有交互性。大多数现有的离线 RL 推荐系统都专注于基于模型的 RL，通过从离线数据中学习世界模型，并通过与该模型交互来构建推荐策略。虽然这些方法在推荐性能方面取得了进展，但基于模型的离线 RL 方法的有效性通常受到奖励模型估计准确性和模型不确定性的限制，这主要是由于离线记录数据和用户与在线平台交互时的真实数据之间存在极大差异。为了填补这一空白，基于模型的 RL 方法需要更准确的奖励模型和不确定性估计。本文提出了一种新的基于模型的离线强化学习推荐系统奖励塑造方法 ROLeR，用于推荐系统中的奖励和不确定性估计。具体而言，设计了一种非参数奖励塑造方法来改进奖励模型。此外，还设计了灵活且更具代表性的不确定性惩罚以适应推荐系统的需求。在四个基准数据集上进行的大量实验表明，ROLeR 与现有基线相比实现了最先进的性能。源代码可在 https://github.com/ArronDZhang/ROLeR 下载。]]></description>
      <guid>https://arxiv.org/abs/2407.13163</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>通过最大化相互信息将推荐解释与评分和特征相结合</title>
      <link>https://arxiv.org/abs/2407.13274</link>
      <description><![CDATA[arXiv:2407.13274v1 公告类型：新
摘要：提供基于自然语言的解释来证明推荐有助于提高用户的满意度并获得用户的信任。然而，由于当前的解释生成方法通常以模仿现有用户评论为目标进行训练，生成的解释通常与推荐项目的预测评级或某些重要特征不一致，因此在帮助用户在推荐平台上做出明智的决定方面不是最优的。为了解决这个问题，我们提出了一种灵活的模型无关方法，称为 MMI（最大化互信息）框架，以增强生成的自然语言解释与预测评级/重要项目特征之间的一致性。具体来说，我们建议使用互信息 (MI) 作为对齐的度量并训练神经 MI 估计器。然后，我们将训练有素的解释生成模型作为骨干模型，并在 MI 估计器的指导下通过强化学习进一步对其进行微调，这会奖励与推荐项目的预测评级或预定义特征更一致的生成解释。在三个数据集上进行的实验表明，我们的 MMI 框架可以增强不同的骨干模型，使它们在与预测评分和项目特征的对齐方面优于现有基线。此外，用户研究证实，MI 增强的解释确实有助于用户做出决策，并且由于其更好的对齐属性而与其他基线相比更受欢迎。]]></description>
      <guid>https://arxiv.org/abs/2407.13274</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:50 GMT</pubDate>
    </item>
    <item>
      <title>如果配备工具，大型语言模型可以成为优秀的医学编码器</title>
      <link>https://arxiv.org/abs/2407.12849</link>
      <description><![CDATA[arXiv:2407.12849v1 公告类型：新 
摘要：本研究提出了一种用于自动 ICD-10-CM 医学编码的新型两阶段 Retrieve-Rank 系统，并将其性能与 Vanilla 大型语言模型 (LLM) 方法进行了比较。在 100 个单项医疗状况的数据集上对这两个系统进行评估后，Retrieve-Rank 系统在预测正确的 ICD-10-CM 代码方面实现了 100% 的准确率，明显优于 Vanilla LLM (GPT-3.5-turbo)，后者的准确率仅为 6%。我们的分析表明，Retrieve-Rank 系统在处理不同专业的各种医学术语时具有卓越的精度。虽然这些结果很有希望，但我们承认使用简化输入的局限性，并且需要在更复杂、更现实的医疗案例上进行进一步测试。这项研究有助于持续努力提高医学编码的效率和准确性，凸显了基于检索的方法的重要性。]]></description>
      <guid>https://arxiv.org/abs/2407.12849</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>MLSA4Rec：Mamba 与低秩分解自注意力相结合用于顺序推荐</title>
      <link>https://arxiv.org/abs/2407.13135</link>
      <description><![CDATA[arXiv:2407.13135v1 公告类型：新 
摘要：在电子商务、在线教育和流媒体服务等应用中，顺序推荐系统起着至关重要的作用。尽管基于自注意力的顺序推荐模型在捕捉用户交互历史中项目之间的依赖关系方面表现出色，但其二次复杂度和缺乏结构偏差限制了它们的适用性。最近，一些工作用具有线性复杂度和结构偏差的 Mamba 取代了顺序推荐器中的自注意力模块。然而，这些工作并没有注意到两种方法之间的互补性。为了解决这个问题，本文提出了一种新的混合推荐框架，Mamba 结合低秩分解自注意力进行顺序推荐（MLSA4Rec），其复杂度与用户历史交互序列的长度成线性关系。具体来说，MLSA4Rec 设计了一个高效的 Mamba-LSA 交互模块。该模块引入一个线性复杂度的低秩分解的自注意力（LSA）模块，并通过Mamba为其注入结构偏差。LSA模块从不同角度分析用户偏好，并通过门控的信息传输机制，动态引导Mamba关注用户历史交互中的重要信息。最后，MLSA4Rec结合Mamba和LSA模块提炼的用户偏好信息，准确预测用户下一次可能的交互。据我们所知，这是第一个将Mamba和自注意力结合在序贯推荐系统中的研究。实验结果表明，MLSA4Rec在三个真实数据集上的推荐准确率优于现有的自注意力和基于Mamba的序贯推荐模型，展示了Mamba与自注意力结合的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.13135</guid>
      <pubDate>Fri, 19 Jul 2024 06:20:49 GMT</pubDate>
    </item>
    </channel>
</rss>