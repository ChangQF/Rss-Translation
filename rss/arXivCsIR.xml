<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 23 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>了解模型解释的算法透明度在文本到 SQL 语义解析中的影响</title>
      <link>https://arxiv.org/abs/2410.16283</link>
      <description><![CDATA[arXiv:2410.16283v1 公告类型：新
摘要：解释人工智能的决策对于培养用户对这些系统的适当信任至关重要。本文研究了结构化预测任务的解释，称为“文本到 SQL 语义解析”，它将自然语言问题转换为结构化查询语言 (SQL) 程序。在这个任务设置中，我们设计了三个级别的模型解释，每个级别都暴露了不同数量的模型决策细节（称为“算法透明度”），并研究了不同的模型解释如何对用户体验产生不同的影响。我们对 $\sim$100 名参与者的研究表明 (1) 低/高透明度的解释通常会导致用户对模型决策的依赖减少/增加，而中等透明度的解释则达到了良好的平衡。我们还表明：（2）只有中等透明度的参与者组能够进一步参与互动，并随着时间的推移表现出越来越高的表现，并且（3）他们在研究前后表现出的信任变化最小。]]></description>
      <guid>https://arxiv.org/abs/2410.16283</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>STAR：一种使用大型语言模型进行推荐的简单无训练方法</title>
      <link>https://arxiv.org/abs/2410.16458</link>
      <description><![CDATA[arXiv:2410.16458v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展为推荐系统 (RecSys) 任务提供了有前途的新方法。虽然目前最先进的方法依赖于微调 LLM 来实现最佳结果，但这个过程成本高昂，并且带来了显著的工程复杂性。相反，绕过微调并直接使用 LLM 的方法资源密集程度较低，但往往无法完全捕获语义和协作信息，导致与经过微调的方法相比性能不佳。在本文中，我们提出了一种简单的无训练推荐方法 (STAR)，这是一种利用 LLM 的框架，可以应用于各种推荐任务而无需微调。我们的方法涉及一个检索阶段，该阶段使用来自 LLM 的语义嵌入结合协作用户信息来检索候选项目。然后，我们应用 LLM 进行成对排名以增强下一项预测。在 Amazon Review 数据集上的实验结果显示，即使仅使用我们的检索阶段，下一个项目预测的性能也具有竞争力。与最佳监督模型相比，我们的完整方法在美容方面的 Hits@10 性能为 +23.8%，在玩具和游戏方面为 +37.5%，在运动和户外方面为 -1.8%。该框架为传统监督模型提供了一种有效的替代方案，凸显了 LLM 在推荐系统中的潜力，而无需大量训练或自定义架构。]]></description>
      <guid>https://arxiv.org/abs/2410.16458</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于实时视频推荐的由粗到细动态提升建模</title>
      <link>https://arxiv.org/abs/2410.16755</link>
      <description><![CDATA[arXiv:2410.16755v1 公告类型：新
摘要：随着短视频平台的兴起，视频推荐技术面临着更加复杂的挑战。目前，视频推荐流程中有多个非个性化模块，迫切需要个性化建模技术来改进。受到在线营销中提升模型成功的启发，我们尝试在视频推荐场景中实现提升模型。然而，我们面临两个主要挑战：1）治疗的设计和利用，2）用户实时兴趣的捕捉。为了解决这些问题，我们设计调整不同时长视频的分布作为治疗，并提出了由粗到细的动态提升模型（CDUM）用于实时视频推荐。CDUM由两个模块组成，CPM和FIC。前一个模块充分利用用户的离线特征来建模他们的长期偏好，而后一个模块利用在线实时上下文特征和请求级候选来建模用户的实时兴趣。这两个模块协同工作，动态识别和定位特定用户群并有效地应用治疗。此外，我们在离线公开数据集和工业数据集以及在线 A/B 测试上进行了全面的实验，证明了我们提出的 CDUM 的优越性和有效性。我们提出的 CDUM 最终在快手平台上全面部署，每天为数亿用户提供服务。源代码将在论文被接受后提供。]]></description>
      <guid>https://arxiv.org/abs/2410.16755</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成检索中的桥接搜索和推荐：一项任务是否会对另一项任务有帮助？</title>
      <link>https://arxiv.org/abs/2410.16823</link>
      <description><![CDATA[arXiv:2410.16823v1 公告类型：新
摘要：用于搜索和推荐的生成检索是一种很有前途的项目检索范例，它为依赖外部索引和最近邻搜索的传统方法提供了一种替代方案。相反，生成模型直接将输入与项目 ID 关联。鉴于大型语言模型 (LLM) 的突破，这些生成系统可以在将各种信息检索 (IR) 任务集中在一个模型中方面发挥关键作用，该模型执行查询理解、检索、推荐、解释、重新排名和响应生成等任务。尽管人们对这种统一的 IR 系统生成方法的兴趣日益浓厚，但文献中尚未充分证实使用单一多任务模型相对于多个专门模型的优势。本文研究了这种统一方法是否以及何时能够在搜索和推荐的 IR 任务中胜过特定任务的模型，这些任务广泛共存于 Spotify、YouTube 和 Netflix 等多个工业在线平台。先前的研究表明：(1) 生成推荐系统学习到的项目潜在表示偏向于流行度，(2) 基于内容和基于协作过滤的信息可以改善项目的表示。受此启发，我们的研究由两个假设指导：[H1] 联合训练规范了对每个项目流行度的估计，[H2] 联合训练规范了项目的潜在表示，其中搜索捕获项目基于内容的方面，而推荐捕获协作过滤方面。我们对模拟数据和真实数据进行的大量实验支持 [H1] 和 [H2] 都是统一搜索和推荐生成模型相对于单任务方法的有效性改进的关键贡献者。]]></description>
      <guid>https://arxiv.org/abs/2410.16823</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经协同过滤分类模型获得预测可靠性</title>
      <link>https://arxiv.org/abs/2410.16838</link>
      <description><![CDATA[arXiv:2410.16838v1 公告类型：新
摘要：神经协同过滤是推荐系统领域的最先进领域；它提供了一些获得准确预测和推荐的模型。这些模型是基于回归的，它们只返回评级预测。本文提出使用基于分类的方法，返回评级预测及其可靠性。额外的信息（预测可靠性）可用于各种相关的协同过滤领域，例如检测托儿攻击、推荐解释或导航工具以显示用户和项目依赖关系。此外，可以优雅地向用户提供推荐可靠性：“你可能会喜欢这部电影”，“几乎肯定会喜欢这首歌”，等等。本文提供了所提出的神经架构；它还测试了其推荐结果的质量是否与最先进的基线一样好。值得注意的是，与基线相比，使用所提出的架构可以改善个人评级预测。实验利用四个流行的公共数据集进行，结果显示质量结果具有普遍性。总体而言，所提出的架构提高了个人评分预测质量，保持了推荐结果，并为一系列相关的协同过滤领域打开了大门。]]></description>
      <guid>https://arxiv.org/abs/2410.16838</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型提高 Pinterest 搜索相关性</title>
      <link>https://arxiv.org/abs/2410.17152</link>
      <description><![CDATA[arXiv:2410.17152v1 公告类型：新
摘要：为了提高 Pinterest 搜索的相关性评分，我们将大型语言模型 (LLM) 集成到我们的搜索相关性模型中，利用精心设计的文本表示来有效预测 Pin 的相关性。我们的方法使用搜索查询以及内容表示，其中包括从生成视觉语言模型中提取的标题。这些内容通过基于链接的文本数据、历史上高质量的参与查询、用户策划的板块、Pin 标题和 Pin 描述进一步丰富，从而创建用于预测搜索相关性的强大模型。我们使用半监督学习方法有效地扩大训练数据量，超越昂贵的人工标记数据。通过利用多语言 LLM，我们的系统将训练数据扩展到包括看不见的语言和领域，尽管初始数据和注释者专业知识仅限于英语。此外，我们从基于 LLM 的模型中提炼出实时可用的模型架构和特性。我们为我们提出的技术提供了全面的离线实验验证，并展示了通过最终部署的大规模系统所取得的收益。]]></description>
      <guid>https://arxiv.org/abs/2410.17152</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用直接偏好优化 LLM：数据效率视角</title>
      <link>https://arxiv.org/abs/2410.16586</link>
      <description><![CDATA[arXiv:2410.16586v1 公告类型：交叉 
摘要：将大型语言模型 (LLM) 的输出与人类偏好对齐（例如，通过强化学习和人类反馈或 RLHF）对于确保其在现实场景中的有效性至关重要。尽管 LLM 对齐技术取得了重大进步，但不同类型的偏好数据对模型性能的影响尚未得到系统探索。在本研究中，我们研究了直接偏好优化 (DPO) 在微调预训练 LLM 中的可扩展性、数据效率和有效性，旨在减少它们对大量偏好数据的依赖，而这些数据的收集成本很高。我们 (1) 系统地比较使用不同百分比的组合偏好判断数据集微调的模型的性能，以定义 DPO 的改进曲线并评估其在数据受限环境中的有效性；(2) 为开发选择性偏好数据使用的最佳方法提供见解。我们的研究表明，增加用于训练的数据量通常会增强和稳定模型性能。此外，使用多种数据集的组合可以显著提高模型的有效性。此外，当使用不同类型的提示分别训练模型时，使用对话提示训练的模型比使用问答提示训练的模型表现更好。]]></description>
      <guid>https://arxiv.org/abs/2410.16586</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Distill-SynthKG：提炼知识图谱合成工作流程，提高覆盖率和效率</title>
      <link>https://arxiv.org/abs/2410.16597</link>
      <description><![CDATA[arXiv:2410.16597v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 生成的知识图谱 (KG) 对于需要知识密集型推理的检索增强生成 (RAG) 应用越来越有价值。然而，现有的 KG 提取方法主要依赖于基于提示的方法，这对于处理大规模语料库效率低下。由于缺乏专门的 KG 构造设计，这些方法通常会遭受信息丢失，尤其是在处理长文档时。此外，无本体 KG 构造的评估数据集和方法也存在差距。为了克服这些限制，我们提出了 SynthKG，这是一种基于 LLM 的多步骤、文档级无本体 KG 合成工作流程。通过在合成的文档-KG 对上微调较小的 LLM，我们将多步骤过程简化为称为 Distill-SynthKG 的单步 KG 生成方法，从而大大减少了 LLM 推理调用的次数。此外，我们重新利用现有的问答数据集来建立 KG 评估数据集并引入新的评估指标。使用 Distill-SynthKG 生成的 KG，我们还为 RAG 设计了一个基于图的新型检索框架。实验结果表明，Distill-SynthKG 不仅在 KG 质量上超越了所有基线模型（包括高达八倍大的模型），而且在检索和问答任务中也始终表现出色。我们提出的图检索框架在多个基准数据集上的表现也优于所有 KG 检索方法。我们公开发布了 SynthKG 数据集和 Distill-SynthKG 模型，以支持进一步的研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2410.16597</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打破困惑与炒作：理解生成式人工智能的真正潜力</title>
      <link>https://arxiv.org/abs/2410.16629</link>
      <description><![CDATA[arXiv:2410.16629v1 公告类型：交叉 
摘要：本文探讨了生成式人工智能 (genAI) 的细微差别，特别关注基于神经网络的模型，如大型语言模型 (LLM)。虽然 genAI 既获得了乐观的热情，也受到了怀疑的批评，但这项工作旨在对其能力、局限性以及可能对社会功能和个人互动产生的深远影响进行平衡的审查。第一部分通过详细讨论 LLM 如何学习、它们的计算需求、与支持技术的区别特征以及其准确性和可靠性的固有局限性，揭开了基于语言的 genAI 的神秘面纱。现实世界的例子说明了这些技术的实际应用和含义。本文的后半部分采用系统视角，评估 LLM 与现有技术的集成如何提高生产力并解决新出现的问题。它强调需要大量投资来了解最近进步的影响，倡导进行充分知情的对话，以合乎道德和负责任的方式将 genAI 融入各个领域。本文最后提出了前瞻性的发展和建议，强调了利用 genAI 潜力同时降低其风险的前瞻性方法。]]></description>
      <guid>https://arxiv.org/abs/2410.16629</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越检索：在对话推荐系统中生成叙述</title>
      <link>https://arxiv.org/abs/2410.16780</link>
      <description><![CDATA[arXiv:2410.16780v1 公告类型：交叉 
摘要：大型语言模型生成和推理能力的最新进展为开发真正的对话式推荐系统提供了机会。然而，有效地将推荐系统知识集成到针对推荐任务的自然语言生成 LLM 中仍然是一个挑战。本文通过做出两个关键贡献来解决这一挑战。
首先，我们为对话式推荐中的自然语言生成任务引入了一个新的数据集 (REGEN)。REGEN（通过生成叙述增强的评论）通过丰富的用户叙述扩展了亚马逊产品评论数据集，包括产品偏好的个性化解释、推荐商品的产品代言以及用户购买历史摘要。REGEN 已公开发布，以促进进一步研究。此外，我们使用众所周知的生成指标建立基准，并使用评估者 LLM 对新数据集进行自动评估。其次，本文介绍了一种融合架构（带有 LLM 的 CF 模型），作为 REGEN 的基线。据我们所知，这是首次尝试分析 LLM 在理解推荐信号和生成丰富叙述方面的能力。我们证明 LLM 可以利用基于交互的 CF 嵌入从简单的融合架构中有效学习，并且可以使用与项目相关的元数据和个性化数据进一步增强这一点。我们的实验表明，与单独使用任一类型的嵌入相比，结合使用 CF 和内容嵌入可以使关键语言指标提高 4-12%。我们还提供了分析来解释 CF 和内容嵌入如何有助于这项新的生成任务。]]></description>
      <guid>https://arxiv.org/abs/2410.16780</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弥合模态差距：图像文本匹配的维度信息对齐和稀疏空间约束</title>
      <link>https://arxiv.org/abs/2410.16853</link>
      <description><![CDATA[arXiv:2410.16853v1 公告类型：交叉 
摘要：许多基于对比学习的模型在图文匹配任务中取得了良好的效果。这些模型的关键在于分析图文对之间的相关性，这涉及到对应维度中嵌入的跨模态交互。然而，不同模态的嵌入来自不同的模型或模块，存在明显的模态差距。直接交互这样的嵌入缺乏合理性，可能会捕获不准确的相关性。因此，我们提出了一种名为DIAS的新方法来从两个方面弥合模态差距：（1）我们在相应维度上对齐来自不同模态的嵌入的信息表示，以确保相关性计算基于相似信息的交互。（2）引入模态间和模态内不匹配对的空间约束，以保证模型语义对齐的有效性。此外，还提出了一种稀疏相关算法来选择强相关的空间关系，使模型能够学习到更多显著特征，避免受到弱相关性的误导。大量实验证明了 DIAS 的优越性，在 Flickr30k 和 MSCOCO 基准上实现了 4.3\%-10.2\% 的 rSum 改进。]]></description>
      <guid>https://arxiv.org/abs/2410.16853</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型增强答案归因，实现忠实文本生成</title>
      <link>https://arxiv.org/abs/2410.17112</link>
      <description><![CDATA[arXiv:2410.17112v1 公告类型：交叉 
摘要：近年来，大型语言模型 (LLM) 的日益普及改变了用户与基于 AI 的对话系统交互和提出问题的方式。提高生成的 LLM 答案可信度的一个重要方面是能够将响应中的单个声明追溯到支持它们的相关来源，这一过程称为答案归因。虽然最近的工作已经开始探索 LLM 中的答案归因任务，但仍然存在一些挑战。在这项工作中，我们首先进行案例研究，分析现有答案归因方法的有效性，重点关注答案细分和证据检索的子任务。根据观察到的缺点，我们提出了新的方法来生成更独立和情境化的声明，以便更好地检索和归因。对新方法进行了评估，并证明可以提高答案归因组件的性能。最后，我们讨论并概述了该任务的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2410.17112</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TELII：时间事件级别倒排索引，用于在大型 Covid-19 EHR 数据集上进行群组发现</title>
      <link>https://arxiv.org/abs/2410.17134</link>
      <description><![CDATA[arXiv:2410.17134v1 公告类型：交叉 
摘要：队列发现是电子健康记录 (EHR) 数据临床研究中的关键步骤。时间查询在队列发现中很常见，在处理大型 EHR 数据集时可能非常耗时且容易出错。在这项工作中，我们介绍了 TELII，这是一种时间事件级倒排索引方法，专为大型 EHR 数据集上的队列发现而设计。TELII 旨在预先计算和存储关系以及事件之间的时间差，从而提供快速准确的时间查询功能。我们为 OPTUM 去识别的 COVID-19 EHR 数据集实施了 TELII，该数据集包含来自 887 万名​​患者的数据。我们演示了四个常见的时间查询任务及其使用 TELII 和 MongoDB 后端的实现。我们的结果表明，TELII 的时间查询速度比现有的非时间倒排索引快 2000 倍。 TELII 的响应时间达到毫秒级，使用户能够快速探索事件关系并找到研究问题的初步证据。TELII 不仅实用且易于实施，而且还可以轻松适应其他 EHR 数据集。这些优势凸显了 TELII 有潜力成为基于 EHR 的应用程序的查询引擎，确保快速、准确且用户友好的查询响应。]]></description>
      <guid>https://arxiv.org/abs/2410.17134</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型赋能个性化网络代理</title>
      <link>https://arxiv.org/abs/2410.17236</link>
      <description><![CDATA[arXiv:2410.17236v1 公告类型：交叉 
摘要：Web 代理已成为一个有前途的方向，可根据用户指令自动完成 Web 任务，从而显著提升用户体验。最近，Web 代理已从传统代理发展为基于大型语言模型 (LLM) 的 Web 代理。尽管现有的基于 LLM 的 Web 代理取得了成功，但它们忽视了个性化数据（例如，用户配置文件和历史 Web 行为）在帮助理解用户的个性化指令和执行定制操作方面的重要性。为了克服这一限制，我们首先制定了 LLM 赋能的个性化 Web 代理的任务，该代理集成了个性化数据和用户指令，以个性化指令理解和操作执行。为了解决缺乏全面评估基准的问题，我们构建了一个个性化 Web 代理基准 (PersonalWAB)，其中包含用户指令、个性化用户数据、Web 功能和三个个性化 Web 任务的两个评估范例。此外，我们提出了一个个性化用户记忆增强对齐 (PUMA) 框架，以使 LLM 适应个性化 Web 代理任务。 PUMA 利用具有特定任务检索策略的记忆库来过滤相关的历史 Web 行为。然后，PUMA 根据这些行为，通过微调和直接偏好优化来对齐 LLM 以执行个性化操作。大量实验验证了 PUMA 优于 PersonalWAB 上现有的 Web 代理。]]></description>
      <guid>https://arxiv.org/abs/2410.17236</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RecPrompt：使用大型语言模型的自调整新闻推荐提示框架</title>
      <link>https://arxiv.org/abs/2312.10463</link>
      <description><![CDATA[arXiv:2312.10463v4 公告类型：替换 
摘要：新闻推荐严重依赖自然语言处理 (NLP) 方法来分析、理解和分类内容，从而能够根据用户兴趣和阅读行为提供个性化建议。像 GPT-4 这样的大型语言模型 (LLM) 在理解自然语言方面表现出色。然而，它们对新闻推荐系统的适用程度仍有待验证。本文介绍了第一个用于新闻推荐的自调整提示框架 RecPrompt，利用 LLM 的功能执行复杂的新闻推荐任务。该框架包含一个新闻推荐器和一个提示优化器，它应用迭代引导过程通过自动提示工程来增强推荐。针对 400 名用户的大量实验结果表明，与深度神经模型相比，RecPrompt 的 AUC 提高了 3.36%，MRR 提高了 10.49%，nDCG@5 提高了 9.64%，nDCG@10 提高了 6.20%。此外，我们还引入了 TopicScore，这是一种新颖的指标，通过评估 LLM 总结用户感兴趣主题的能力来评估可解释性。结果表明，LLM 能够准确识别感兴趣的主题并提供全面的基于主题的解释。]]></description>
      <guid>https://arxiv.org/abs/2312.10463</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>