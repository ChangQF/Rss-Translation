<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Wed, 17 Jan 2024 06:18:21 GMT</lastBuildDate>
    <item>
      <title>差异隐私对推荐准确性和流行度偏差的影响。 （arXiv：2401.03883v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2401.03883</link>
      <description><![CDATA[基于协作过滤的推荐系统利用大量
用户行为数据，带来严重的隐私风险。因此，常常是随机的
噪声被添加到数据中以确保差分隐私（DP）。然而，为了
迄今为止，尚不清楚这会以何种方式影响个性化
建议。在这项工作中，我们研究 DP 如何影响推荐准确性
和流行度偏差，当应用于最先进的训练数据时
推荐模型。我们的发现有三个方面：首先，我们发现几乎
当应用 DP 时，所有用户的推荐都会发生变化。二、推荐
准确率大幅下降，而推荐商品的受欢迎程度则大幅下降
急剧增加，表明受欢迎程度偏差恶化。第三，我们发现DP
对于喜欢不受欢迎商品的用户来说，更严重地加剧了受欢迎程度偏差
而不是那些喜欢流行商品的用户。
]]></description>
      <guid>http://arxiv.org/abs/2401.03883</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>Starling：一种 I/O 高效的磁盘驻留图索引框架，用于数据段上的高维向量相似性搜索。 （arXiv：2401.02116v2 [cs.DB] 已更新）</title>
      <link>http://arxiv.org/abs/2401.02116</link>
      <description><![CDATA[高维向量相似性搜索 (HVSS) 作为一种搜索方法正在日益受到重视。
适用于各种数据科学和人工智能应用的强大工具。作为矢量数据
随着规模的扩大，内存索引提出了重大挑战，因为
主存需求大幅增加。一个潜在的解决方案涉及
利用基于磁盘的实现，存储和搜索矢量数据
NVMe SSD 等高性能设备。然而，为数据实施 HVSS
向量数据库中的分段被证明是复杂的，其中单个机器
包括多个部分以实现系统可扩展性。在此背景下，各
段在有限的内存和磁盘空间下运行，需要一个微妙的
准确性、效率和空间成本之间的平衡。现有的基于磁盘的
方法存在缺陷，因为它们不能全面满足所有这些要求
同时地。在本文中，我们介绍了 Starling，一种 I/O 高效的
优化数据布局和搜索的磁盘驻留图索引框架
细分市场内的战略。它有两个主要组成部分：(1) 数据布局
合并内存中的导航图和重新排序的基于磁盘的图
增强局部性，减少搜索路径长度并最小化磁盘
带宽浪费； (2) 旨在最小化成本的块搜索策略
矢量查询执行期间的磁盘 I/O 操作。通过广泛
实验，我们验证了有效性、效率和可扩展性
椋鸟。在一个2GB内存和10GB磁盘容量的数据段上，Starling
可容纳多达 3300 万个 128 维向量，为 HVSS 提供
平均准确率和前 10 名召回率超过 0.9，延迟低于 1
毫秒。结果展示了 Starling 的卓越表现
与相比，吞吐量提高了 43.9$\times$，查询延迟降低了 98%
最先进的方法，同时保持相同的准确性水平。
]]></description>
      <guid>http://arxiv.org/abs/2401.02116</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>具有方面学习的多方面密集检索器的再现性分析和增强。 （arXiv：2401.03648v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2401.03648</link>
      <description><![CDATA[多方面密集检索旨在合并方面信息（例如，
品牌和类别）进入双编码器以促进相关性匹配。作为一个
早期且具有代表性的多方面密集型寻回犬，MADRAL 学习了几种
额外的方面嵌入并将显式方面与隐式方面融合
“其他”为最终表示。 MADRAL 根据专有数据进行评估
其代码尚未发布，因此验证其有效性具有挑战性
在其他数据集上。我们未能向公众重现其有效性
MA-亚马逊的数据，促使我们探究其原因并重新审视其
成分。我们提出了几种组件替代方案进行比较，
包括用“CLS”替换“OTHER”并用第一个表示方面
几个内容标记。通过大量的实验，我们证实学习
从头开始的“其他”方面融合是有害的。相比之下，我们提出的
变体可以极大地提高检索性能。我们的研究不仅
揭示了 MADRAL 的局限性，但也提供了宝贵的见解
用于未来更强大的多方面密集检索模型的研究。代码
发布时间：
https://github.com/sunxiaojie99/Reproducibility-for-MADRAL。
]]></description>
      <guid>http://arxiv.org/abs/2401.03648</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>RecRanker：指令调优大型语言模型作为 Top-k 推荐的排名器。 （arXiv：2312.16018v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.16018</link>
      <description><![CDATA[大型语言模型 (LLM) 已展现出卓越的能力
已广泛部署在各个领域，包括推荐系统
系统。许多研究都采用了专门的 \textit{prompts} 来利用
法学硕士固有的情境学习能力。例如，法学硕士是
提示充当列表排名的零样本排名者，评估候选人
由检索模型生成的用于推荐的项目。最近的研究
进一步使用指令调整技术使 LLM 与人类偏好保持一致
以获得更有希望的建议。尽管有潜力，但目前的研究
忽略了多个排名任务的整合以增强模型
表现。此外，传统推荐模型的信号为
没有集成到LLM中，限制了当前系统的性能。

在本文中，我们介绍了 RecRanker，它专为将 LLM 指令调整为
充当顶级\textit{k}\textbf{Rec}建议的\textbf{Ranker}。
具体来说，我们引入了基于聚类的重要性感知采样
抽样，以及对高质量抽样的重复抽样的惩罚，
具有代表性且多样化的训练数据。为了增强提示，我们引入
位置转移策略以减轻位置偏差并增强提示
结合传统推荐模型的辅助信息，从而
丰富了法学硕士的背景理解。随后，我们利用
采样数据以使用增强的数据集组装指令调整数据集
提示包含三个不同的排序任务：逐点、成对和
列表排名。我们进一步提出了一种混合排名方法来增强
通过整合这些排名任务来建模性能。我们的实证评估
证明我们提出的 RecRanker 在直接和
顺序推荐场景。
]]></description>
      <guid>http://arxiv.org/abs/2312.16018</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>针对推荐系统的中毒攻击：一项调查。 （arXiv：2401.01527v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2401.01527</link>
      <description><![CDATA[现代推荐系统 (RS) 已经取得了巨大的成功，但它们
仍然容易受到恶意活动的影响，尤其是中毒攻击。这些
攻击涉及将恶意数据注入RS的训练数据集中，
从而损害其完整性并操纵推荐结果
为获取非法利益。本调查报告提供了系统且
中毒攻击研究领域的最新回顾
建议（PAR）。提出了一种新颖且全面的分类法，
将现有 PAR 方法分为三个不同的类别：
特定于组件的、目标驱动的和能力探索。对于每个类别，我们
详细讨论其机制以及相关方法。此外，
本文强调了该领域未来潜在的研究途径。
此外，为了促进 PAR 的实证比较并对其进行基准测试，我们
引入一个开源库 ARLib，它包含全面的
PAR 模型和通用数据集的集合。该库发布于
https://github.com/CoderWZW/ARLib。
]]></description>
      <guid>http://arxiv.org/abs/2401.01527</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>工程设计知识的语言和结构基础。 （arXiv：2312.06355v2 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2312.06355</link>
      <description><![CDATA[文物描述是工程设计的主要载体
知识既是设计过程的结果，也是设计过程的驱动力。虽然
人工制品可以用不同的内涵来描述，设计过程
需要一个描述来体现工程设计知识，即
通过复杂的实体放置在文本中表达
关系。由于大型语言模型仅从各种文本中学习
一系列字符/标记，这些尚未生成包含以下内容的文本
明确的工程设计事实。现有的本体论设计理论有
不太可能指导目前应用程序的大语言模型
仅限于构思和学习目的。在这篇文章中，我们解释了
来自 33,881 个大样本的工程设计知识作为知识图
专利文件。我们检查这些知识图谱的组成部分
了解工程设计知识的语言和结构基础。
在语言基础方面，我们观察到实体和关系可以
可以推广到 64 种和 24 种语言语法。虽然关系主要
捕获属性（&#39;of&#39;）、结构（&#39;in&#39;、&#39;with&#39;）、目的（&#39;to&#39;、&#39;for&#39;）、
层次结构（“包括”）、例证（“例如”）和行为（“至”、
&#39;from&#39;），可以使用以下方式具体识别层次关系
75 种独特的语法。为了理解结构基础，我们汲取灵感
从对生物/生态网络的各种研究中发现主题
专利知识图谱。我们确定了四个 3 节点和四个 4 节点模式
还可以进一步收敛简化为序列[-&gt;...-&gt;]，聚合
[-&gt;...&lt;-] 和层次结构 [&lt;-...-&gt;]。有望指导大语言模型
基于设计工具，我们提出了一些具体化的监管规则
抽象子图中的实体和关系，同时解释
层次结构。
]]></description>
      <guid>http://arxiv.org/abs/2312.06355</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>利用多行为数据中的可替代和互补关系进行基于会话的推荐。 （arXiv：2312.14957v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.14957</link>
      <description><![CDATA[基于会话的推荐 (SR) 旨在向特定对象动态推荐项目
基于一系列最近的用户-项目交互的用户。最多
现有的SR研究采用了先进的深度学习方法。但是，那
大多数人只考虑特殊的行为类型（例如点击），而少数人则只考虑特殊的行为类型（例如点击）
考虑多类型行为而忽视充分利用
产品（项目）之间的关系。针对这种情况，本文提出了
新颖的方法，称为可替代和互补关系
多行为数据（表示为 SCRM）以更好地探索关系
产品之间进行有效推荐。具体来说，我们首先
根据用户的顺序构建可替代和互补的图
通过共同考虑“点击”和“购买”来确定每个会话中的行为
行为。然后我们设计一个去噪网络来消除虚假关系，
并通过特定的方法进一步考虑对这两种关系的约束
设计的损失函数。对两个电子商务数据集进行广泛的实验
证明我们的模型相对于最先进的方法的优越性，并且
SCRM 中每个组件的有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.14957</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>TSRankLLM：用于文本排名的法学硕士的两阶段改编。 （arXiv：2311.16720v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2311.16720</link>
      <description><![CDATA[文本排序是各种信息检索中的关键任务
应用程序，以及最近预训练语言模型（PLM）的成功，
特别是大型语言模型（LLM），引起了人们对其的兴趣
应用于文本排名。消除 PLM 和 PLM 之间的错位
文本排名，利用监督排名数据进行微调已被广泛
探索过。然而，之前的研究主要集中在仅编码器和
编码器-解码器 PLM 和仅解码器的 LLM 研究仍然缺乏。一个
RankLLaMA 是个例外，它建议直接监督微调
（SFT）全面探索 LLaMA。在我们的工作中，我们认为两阶段
进步范式会更有益。首先，我们建议持续
使用大规模弱监督语料库对法学硕士进行预训练（CPT）。
其次，我们执行与RankLLaMA一致的SFT，并提出改进的
进一步优化策略。我们在多个基准上的实验结果
展示我们的方法的卓越性能，涵盖域内和
域外场景。
]]></description>
      <guid>http://arxiv.org/abs/2311.16720</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>用于多方面密集检索的多粒度感知方面学习模型。 （arXiv：2312.02538v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.02538</link>
      <description><![CDATA[密集检索方法主要集中在非结构化文本和
人们对各个方面的结构化数据的关注较少，例如，
产品具有类别和品牌等方面。最近的工作提出了两个
将方面信息合并到项目表示中的方法
通过预测与项目方面相关的值来有效检索。
尽管它们很有效，但他们将这些值视为孤立的类（例如，“智能
住宅”、“住宅、花园和花园”工具”和“美容与美容”健康”）并忽略他们的
细粒度的语义关系。此外，他们要么强制学习
CLS 代币的各个方面，这可能会使其与其指定用途相混淆
用于表示整个内容语义，或学习额外的方面嵌入
仅具有价值预测目标，这可能是不够的
特别是当项目方面没有注释值时。意识到
针对这些限制，我们提出了一种多粒度感知的方面学习模型
（MURAL）用于多方面密集检索。它利用方面信息
跨越各种粒度来捕获粗粒度和细粒度的语义
价值观之间的关系。此外，MURAL 还包含单独的方面
嵌入作为变压器编码器的输入，以便掩码语言模型
即使没有方面值，目标也可以帮助隐式方面学习
注释。对两个真实世界的产品数据集进行了广泛的实验
小程序显示 MURAL 的性能优于最先进的基线
显著地。
]]></description>
      <guid>http://arxiv.org/abs/2312.02538</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>通过 Householder 量化进行深度哈希。 （arXiv：2311.04207v3 [cs.CV] 已更新）</title>
      <link>http://arxiv.org/abs/2311.04207</link>
      <description><![CDATA[哈希是大规模图像相似性搜索的核心，最近
通过深度学习技术，方法得到了显着改进。这样的
算法通常学习数据的连续嵌入。为了避免
随后昂贵的二值化步骤，常见的解决方案是采用损失
结合相似性学习项的函数（以确保相似的图像是
分组到附近的嵌入）和量化惩罚项（以确保
嵌入条目接近二值化条目，例如-1或1）。仍然，
这两个术语之间的相互作用可以使学习变得更加困难
嵌入更差。我们提出了一种替代量化策略
将学习问题分解为两个阶段：首先，执行相似性
在没有量化的情况下学习嵌入空间；其次，找到一个最优的
嵌入的正交变换，因此嵌入的每个坐标
接近其符号，然后通过量化变换后的嵌入
标志功能。第二步，我们参数化正交变换
使用 Householder 矩阵有效地利用随机梯度下降。
由于相似性度量在正交条件下通常是不变的
转换，这种量化策略在以下方面是免费的：
表现。由此产生的算法是无监督的、快速的、无超参数的
并且可以在任何现有的深度哈希或度量学习之上运行
算法。我们提供了大量的实验结果表明这种方法
在广泛使用的图像数据集上带来最先进的性能，并且，
与其他量化策略不同，带来了持续的改进
现有深度哈希算法的性能。
]]></description>
      <guid>http://arxiv.org/abs/2311.04207</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>人工智能生成的图像给文本图像检索带来了看不见的相关性偏差。 （arXiv：2311.14084v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2311.14084</link>
      <description><![CDATA[随着生成模型的进步，人工智能生成内容（AIGC）正在
变得更加现实，充斥着互联网。最近的一项研究表明
这种现象会导致网络搜索文本检索中的来源偏差。
具体来说，神经检索模型倾向于将生成的文本排名高于
人类书写的文本。在本文中，我们将这种偏见的研究扩展到
跨模态检索。首先，我们成功构建了一个合适的基准
探究偏见的存在。随后对此进行了广泛的实验
基准测试显示人工智能生成的图像引入了隐形的相关性偏差
文本图像检索模型。具体来说，我们的实验表明
文本图像检索模型倾向于将人工智能生成的图像排名高于
真实图像，即使人工智能生成的图像没有表现出更多
与查询视觉相关的特征比真实图像更重要。这个看不见的
相关性偏差在具有不同训练数据的检索模型中普遍存在
和架构。此外，我们随后的探索表明
将人工智能生成的图像纳入检索模型的训练数据中
加剧了无形的相关性偏差。上述现象引发
恶性循环，使得无形的相关性偏差越来越大
严肃的。阐明隐形相关性的潜在原因并解决
针对上述问题，我们介绍一种有效的培训方法，旨在
减轻无形的相关性偏差。随后，我们应用我们提出的
去偏差方法追溯性地识别隐形相关性的原因，
揭示人工智能生成的图像诱导图像编码器嵌入
将附加信息添加到他们的表示中。该信息展示了
具有不同语义的生成图像之间具有一定的一致性，并且可以
使检索器估计出更高的相关性分数。
]]></description>
      <guid>http://arxiv.org/abs/2311.14084</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>GraphPro：图预训练和快速学习推荐。 （arXiv：2311.16716v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2311.16716</link>
      <description><![CDATA[基于 GNN 的推荐器在复杂的用户项目建模方面表现出色
通过多跳消息传递进行交互。然而，现有的方法常常
忽视了不断发展的用户-项目交互的动态本质，这阻碍了
适应不断变化的用户偏好和新的分布变化
到达的数据。因此，它们在现实世界动态中的可扩展性和性能
环境有限。在这项研究中，我们提出了 GraphPro，一个框架
结合了参数高效和动态图预训练以及提示
学习。这种新颖的组合使 GNN 能够有效捕获
长期用户偏好和短期行为动态，使
提供准确、及时的建议。我们的 GraphPro 框架
通过无缝集成解决不断变化的用户偏好的挑战
时间提示机制和图结构提示学习机制
进入预训练的 GNN 模型。时间提示机制对时间进行编码
有关用户-项目交互的信息，使模型能够自然地捕获
时间上下文，而图结构提示学习机制使得
转移预先训练的知识以适应行为动态，而无需
需要持续增量训练。我们进一步引入动态
模拟真实世界动态场景的推荐评估设置和
更好地缩小线下和线上的差距。我们广泛的实验
包括大规模工业部署展示了轻量级插件
与各种最先进的技术集成时，我们的 GraphPro 具有可扩展性
推荐者，强调GraphPro在有效性方面的优势，
稳健性和效率。
]]></description>
      <guid>http://arxiv.org/abs/2311.16716</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>尽我所能，而不是尽我所能。 （arXiv：2306.10345v2 [cs.AI] 已更新）</title>
      <link>http://arxiv.org/abs/2306.10345</link>
      <description><![CDATA[本文提出了一种称为 TMR 的模型，用于从中挖掘有价值的信息
模拟数据环境。我们打算完成此提交
纸。
]]></description>
      <guid>http://arxiv.org/abs/2306.10345</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可能会主导信息访问：神经检索器对法学硕士生成的文本有偏见。 （arXiv：2310.20501v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2310.20501</link>
      <description><![CDATA[最近，大型语言模型（LLM）的出现彻底改变了
信息检索（IR）应用程序的范例，尤其是在网络中
搜索。凭借其生成类人文本的卓越能力，法学硕士
在互联网上创建了大量文本。因此，IR 系统在
LLMs时代面临着新的挑战：现在的索引文档不仅是
由人类编写，但也由法学硕士自动生成。这些如何
LLM 生成的文件对 IR 系统的影响是一个紧迫且仍然存在的问题
未探索的问题。在这项工作中，我们对
在人工编写和 LLM 生成的场景中使用不同的 IR 模型
涉及文本。令人惊讶的是，我们的研究结果表明神经检索
模型倾向于将 LLM 生成的文档排名更高。我们参考这个类别
神经检索模型对法学硕士生成的文本的偏见
\textbf{来源偏差}。此外，我们发现这种偏见不仅限于
第一阶段神经检索器，但扩展到第二阶段神经检索器
重新排名。然后，我们从文本的角度进行深入分析
压缩并观察神经模型可以更好地理解语义
LLM生成文本的信息，我们进一步证实了这一点
理论分析。为了减轻来源偏差，我们还提出了
优化目标的即插即用去偏约束，以及
实验结果表明了有效性。最后我们讨论一下潜力
由于观察到的来源偏差而引起严重担忧，并希望我们的发现
可以为 IR 界及其他领域敲响重要的警钟。到
促进LLM时代对IR的未来探索，构建了两个新的
基准和代码稍后将在以下位置提供：
\url{https://github.com/KID-22/LLM4IR-Bias}。
]]></description>
      <guid>http://arxiv.org/abs/2310.20501</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>通过级联引导的对抗训练实现更稳健、更准确的顺序推荐。 （arXiv：2304.05492v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2304.05492</link>
      <description><![CDATA[顺序推荐模型，从时间顺序中学习的模型
用户-项目交互，在许多方面优于传统推荐模型
设置。尽管顺序推荐模型取得了成功，但它们
稳健性最近受到质疑。大自然独有的两个属性
顺序推荐模型的组合可能会损害其鲁棒性 - 级联
训练期间引起的影响以及模型过度依赖的倾向
时间信息。为了解决这些漏洞，我们建议
级联引导的对抗性训练，一种新的对抗性训练程序，
专为顺序推荐模型而设计。我们的方法
利用顺序建模中存在的内在级联效应
在训练期间对项目嵌入产生战略对抗性扰动。
在四个公共平台上训练最先进的序列模型的实验
来自不同领域的数据集表明我们的训练方法产生了
卓越的模型排名准确性和卓越的模型对真实项目的鲁棒性
与标准模型训练和模型训练相比，替代扰动
通用对抗训练。
]]></description>
      <guid>http://arxiv.org/abs/2304.05492</guid>
      <pubDate>Wed, 17 Jan 2024 06:18:14 GMT</pubDate>
    </item>
    </channel>
</rss>