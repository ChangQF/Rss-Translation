<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 30 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>从群论角度对评估指标进行排序</title>
      <link>https://arxiv.org/abs/2408.16009</link>
      <description><![CDATA[arXiv:2408.16009v1 公告类型：新
摘要：面对确定最合适的指标来验证新提出的模型的优点的挑战，决策过程绝非易事。鉴于比较排名本身就带来了一系列艰巨的挑战，而且可能没有适用于所有场景的通用指标，情况并没有好转。此外，为特定环境设计的指标（例如推荐系统）有时会扩展到其他领域，而没有全面掌握其底层机制，从而导致无法预料的结果和潜在的滥用。使问题进一步复杂化的是，不同的指标可能会强调排名的不同方面，这经常导致模型结果的看似矛盾的比较，并阻碍评估的可信度。
我们在排名评估指标领域揭示了这些方面。首先，我们展示了导致评估不一致的实例，这是常用指标中潜在不信任的根源；通过量化这种分歧的频率，我们证明了这些分歧在排名中很常见。之后，我们使用与创建指标的可能领域分离的对称群的数学形式来概念化排名；通过这种方法，我们可以严格而正式地建立排名评估指标的基本数学属性，这对于更深入地理解不一致评估的来源至关重要。最后，我们进行了讨论，将我们的理论分析与实际应用联系起来，强调在通常评估排名的每个领域中哪些属性很重要。总之，我们的分析揭示了排名评估指标，强调不一致的评估不应被视为不信任的根源，而应被视为谨慎选择未来如何评估我们的模型的需要。]]></description>
      <guid>https://arxiv.org/abs/2408.16009</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于跨域点击率预测的高效迁移学习框架</title>
      <link>https://arxiv.org/abs/2408.16238</link>
      <description><![CDATA[arXiv:2408.16238v1 公告类型：新
摘要：自然内容和广告共存于工业推荐系统中，但在数据分布上有所不同。具体来说，与自然内容相比，与广告相关的流量要稀疏得多，这促使人们开发将知识从更丰富的源自然内容领域转移到更稀疏的广告领域。挑战包括管理大量源数据带来的效率低下，以及 CTR 模型每日更新导致的“灾难性遗忘”问题。为此，我们提出了一种新颖的三级异步框架，即跨域点击率预测的高效迁移学习框架 (E-CDCTR)，将自然内容的全面知识转移到广告 CTR 模型。该框架由三个关键部分组成：微型预训练模型（TPM），在长期自然数据上训练具有几个基本特征的微型CTR模型；完全预训练模型（CPM），在短期自然数据上训练具有与目标广告相同的网络结构和输入特征的CTR模型；广告CTR模型（A-CTR），其参数初始化来自CPM，并从TPM中获得多个历史嵌入作为额外特征，然后对广告数据进行微调。TPM为CPM和A-CTR提供了更丰富的用户和项目表示，有效缓解了每日更新中固有的遗忘问题。CPM通过提供知识初始化进一步增强了广告模型，从而缓解了广告CTR模型通常遇到的数据稀疏性挑战。这种三级跨领域迁移学习框架为解决数据稀疏性和“灾难性遗忘”提供了有效的解决方案，并取得了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2408.16238</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SynDL：大规模合成测试集合</title>
      <link>https://arxiv.org/abs/2408.16312</link>
      <description><![CDATA[arXiv:2408.16312v1 公告类型：新
摘要：大规模测试集在信息检索 (IR) 研究中起着至关重要的作用。然而，根据 Cranfield 范式和对公开数据集的研究，现有的信息检索研究通常是在小规模数据集上进行的，这些数据集依赖于人类评估者进行相关性判断 - 这是一个耗时且昂贵的过程。最近的研究表明，大型语言模型 (LLM) 能够以极低的成本产生可靠的相关性判断，同时具有人类的准确性。在本文中，为了解决缺少大规模临时文档检索数据集的问题，我们通过额外的语言模型合成标签扩展了 TREC 深度学习轨道 (DL) 测试集，以使研究人员能够大规模测试和评估他们的搜索系统。具体来说，这样的测试集包括前几年轨道的 1,900 多个测试查询。我们将系统评估与过去几年的人工标签进行比较，发现我们综合创建的大规模测试集合可以产生高度相关的系统排名。]]></description>
      <guid>https://arxiv.org/abs/2408.16312</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统会推广本地音乐吗？使用音乐流数据的可重复性研究</title>
      <link>https://arxiv.org/abs/2408.16430</link>
      <description><![CDATA[arXiv:2408.16430v1 公告类型：新
摘要：本文研究了推荐系统对本地音乐表现的影响，讨论了对 LFM-2b 公共数据集进行实证研究的先前发现。这项先前的研究表明，不同的推荐系统表现出算法偏差，使音乐消费转向或反对本地内容。然而，LFM-2b 用户并不能反映音乐流媒体服务的多样化受众。为了评估本研究结论的稳健性，我们使用来自全球音乐流媒体服务的专有收听数据进行了比较分析，我们与本文一起公开发布了这些数据。我们观察到我们的数据集和 LFM-2b 之间的本地音乐消费模式存在显著差异，这表明在仅基于 LFM-2b 对本地音乐得出结论时应谨慎行事。此外，我们表明原始工作中表现出的算法偏差在我们的数据集中有所不同，并且几个未探索的模型参数可以显着影响这些偏差并影响研究对这两个数据集的结论。最后，我们讨论了准确标记本地音乐的复杂性，强调了由于不可靠、有偏见或不完整的标签而导致误导性结论的风险。为了鼓励进一步研究并确保可重复性，我们公开分享了我们的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2408.16430</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformers 与 ACT-R 相遇：重复感知和顺序聆听课程推荐</title>
      <link>https://arxiv.org/abs/2408.16578</link>
      <description><![CDATA[arXiv:2408.16578v1 公告类型：新
摘要：音乐流媒体服务通常利用顺序推荐系统根据过去的收听会话顺序来预测向用户展示的最佳音乐。尽管如此，大多数顺序推荐方法都忽略或没有充分考虑重复行为。这是音乐推荐的一个关键限制，因为随着时间的推移重复听同一首歌是一种常见现象，甚至可以改变用户对这首歌的看法。在本文中，我们介绍了 PISA（使用 ACT-R 的心理学信息会话嵌入），这是一个克服这一限制的会话级顺序推荐系统。PISA 采用 Transformer 架构学习嵌入收听会话和用户的表示，使用受 Anderson 的 ACT-R（思维理性的自适应控制）启发的注意力机制，这是一种对人类信息访问和记忆动态进行建模的认知架构。这种方法使我们能够从用户行为中捕获动态和重复的模式，使我们能够有效地预测他们在后续会话中将听的歌曲，无论是重复的还是新的。我们利用 Last.fm 的公开收听数据和全球音乐流媒体服务 Deezer 的专有数据证明了 PISA 的实证相关性，证实了重复建模对于顺序收听会话推荐至关重要。除了本文外，我们还公开发布了我们的专有数据集，以促进该领域的未来研究，并公开了 PISA 的源代码，以方便其未来的使用。]]></description>
      <guid>https://arxiv.org/abs/2408.16578</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Jina-ColBERT-v2：通用多语言后期交互检索器</title>
      <link>https://arxiv.org/abs/2408.16672</link>
      <description><![CDATA[arXiv:2408.16672v1 公告类型：新
摘要：多向量密集模型（例如 ColBERT）已被证明在信息检索中非常有效。由于其双编码器架构以及索引和搜索方面的最新优​​化，ColBERT 的后期交互评分近似于跨编码器中看到的联合查询文档注意，同时保持更接近传统密集检索模型的推理效率。在本文中，我们对 ColBERT 模型架构和训练流程进行了多项改进，利用了更成熟的单向量嵌入模型范式中成功的技术，特别是那些适用于异构多​​语言数据的技术。我们的新模型 Jina-ColBERT-v2 在一系列英语和多语言检索任务中表现出色，同时与以前的模型相比，存储需求减少了高达 50%。]]></description>
      <guid>https://arxiv.org/abs/2408.16672</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向推荐者的极其数据高效且基于 LLM 的生成式强化学习代理</title>
      <link>https://arxiv.org/abs/2408.16032</link>
      <description><![CDATA[arXiv:2408.16032v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的最新进展使得人们能够理解网页上下文、产品详细信息和人工指令。利用 LLM 作为强化学习中奖励模型或策略的基础架构已经越来越受欢迎——一项显著的成就是 InstructGPT 的成功。RL 算法在最大化长期客户满意度和避免工业推荐系统中的短期、短视目标方面发挥了重要作用，工业推荐系统通常依赖深度学习模型来预测即时点击或购买。
在这个项目中，使用 WebShop 基准环境、数据、模拟器和预训练模型检查点实现和评估了几种 RL 方法。目标是训练一个 RL 代理，在给出描述所需产品的详细人工指令的情况下最大化购买奖励。 RL 代理是通过对具有各种目标的预训练 BERT 模型进行微调、从没有奖励模型的偏好中学习以及采用当代训练技术（例如 InstructGPT 中使用的近端策略优化 (PPO) 和直接偏好优化 (DPO)）来开发的。本报告还评估了使用生成轨迹训练的 RL 代理。评估是在 WebShop 模拟器环境中使用 Thompson 抽样进行的。
模拟在线实验表明，在生成的轨迹上训练的代理表现出与使用人类轨迹训练的代理相当的任务性能。这展示了一种极其低成本的数据高效训练强化学习代理的方法。此外，在有限的训练时间（&lt;2 小时）内，不使用任何图像，DPO 代理在 T4 GPU 上训练约 3000 步或 30 分钟后实现了 19% 的成功率，而 PPO 代理的成功率仅为 15%。]]></description>
      <guid>https://arxiv.org/abs/2408.16032</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>物联网数据中的高效 $k$-NN 搜索：基于树的索引结构中的重叠优化</title>
      <link>https://arxiv.org/abs/2408.16036</link>
      <description><![CDATA[arXiv:2408.16036v1 公告类型：交叉 
摘要：物联网 (IoT) 中互联设备的激增导致数据呈指数级增长，通常称为大数据。高效检索这种异构数据需要强大的索引机制来进行有效组织。然而，仍然存在一个重大挑战：索引构建期间数据空间分区的重叠。这种重叠增加了搜索和检索期间的节点访问，导致更高的资源消耗、性能瓶颈并阻碍系统可扩展性。为了解决这个问题，我们提出了三种创新的启发式方法，旨在量化和战略性地减少数据空间分区重叠。基于体积的方法 (VBM) 通过计算分区之间的交叉体积来提供详细的评估，从而提供对空间关系的更深入了解。基于距离的方法 (DBM) 通过使用分区中心和半径之间的距离来评估重叠来提高效率，提供了一种简化而准确的方法。最后，基于对象的方法 (OBM) 通过对多个分区中的对象进行计数提供了一种实用的解决方案，从而直观地了解数据空间动态。实验结果证明了这些方法在减少搜索时间方面的有效性，凸显了它们在改善数据空间分区和提高整体系统性能方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.16036</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在多模态大型语言模型兴起的时代，重新思考图像检索的稀疏词汇表征</title>
      <link>https://arxiv.org/abs/2408.16296</link>
      <description><![CDATA[arXiv:2408.16296v1 公告类型：交叉 
摘要：在本文中，我们重新思考了图像检索的稀疏词汇表示。通过利用支持视觉提示的多模态大型语言模型 (M-LLM)，我们可以提取图像特征并将其转换为文本数据，从而使我们能够利用自然语言处理中用于图像检索任务的高效稀疏检索算法。为了帮助 LLM 提取图像特征，我们应用数据增强技术进行密钥扩展，并使用图像和文本数据之间的相关性度量来分析影响。我们在基于关键字的图像检索场景中，通过经验证明了我们的图像检索方法与基于传统视觉语言模型的方法相比具有更高的精确度和召回率，其中关键字作为搜索查询。我们还证明，通过迭代地将关键字合并到搜索查询中可以提高检索性能。]]></description>
      <guid>https://arxiv.org/abs/2408.16296</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文本规范化与中世纪宪章分类相关吗？</title>
      <link>https://arxiv.org/abs/2408.16446</link>
      <description><![CDATA[arXiv:2408.16446v1 公告类型：交叉 
摘要：本研究考察了历史文本规范化对中世纪宪章分类的影响，特别关注文档的年代确定和定位。使用来自数字档案的中世纪高地德语宪章数据集，我们评估了各种分类器，包括传统和基于变压器的模型，有和没有规范化。我们的结果表明，给定的规范化对定位任务的改进很小，但降低了年代确定的准确性，这意味着原始文本包含规范化可能掩盖的关键特征。我们发现支持向量机和梯度提升优于其他模型，这质疑了变压器在这种用例中的效率。结果提出了一种选择性的历史文本规范化方法，强调了保留一些对文档分析中的分类任务至关重要的文本特征的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.16446</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GenRec：使用大型语言模型的生成序列推荐</title>
      <link>https://arxiv.org/abs/2407.21191</link>
      <description><![CDATA[arXiv:2407.21191v2 公告类型：替换 
摘要：顺序推荐是一项从历史用户项目交互数据中捕获隐藏的用户偏好并为用户推荐下一个项目的任务。通过利用基于分类的学习方法，该领域已经取得了重大进展。受到 NLP 中“预训练、提示和预测”的最新范式的启发，我们将顺序推荐视为序列到序列的生成任务，并提出了一种名为生成推荐（GenRec）的新模型。与学习显式用户和项目表示的基于分类的模型不同，GenRec 利用 Transformer 的序列建模功能并采用掩码项目预测目标来有效学习隐藏的双向序列模式。与现有的生成顺序推荐模型不同，GenRec 不依赖于手动设计的硬提示。GenRec 的输入是文本用户项目序列，输出是排名靠前的下一个项目。此外，GenRec 是轻量级的，在资源匮乏的环境中仅需几个小时即可进行有效训练，因此非常适合实际场景，并有助于在顺序推荐领域实现大型语言模型的民主化。我们进行了大量的实验，结果表明，GenRec 可以在各种公共实际数据集上进行推广，并取得了最先进的结果。我们的实验还验证了所提出的掩码项目预测目标的有效性，该目标可大幅提高模型性能。]]></description>
      <guid>https://arxiv.org/abs/2407.21191</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>智能多模式搜索：Adobe Express 中的上下文稀疏和密集嵌入集成</title>
      <link>https://arxiv.org/abs/2408.14698</link>
      <description><![CDATA[arXiv:2408.14698v2 公告类型：替换 
摘要：随着用户内容和查询变得越来越多模式化，对有效的多模式搜索系统的需求也随之增长。传统搜索系统通常依赖于索引图像的文本和元数据注释，而 CLIP 等多模式嵌入则支持使用文本和图像嵌入进行直接搜索。然而，基于嵌入的方法在集成上下文特征（例如用户语言环境和新近度）方面面临挑战。构建可扩展的多模式搜索系统需要对多个组件进行微调。本文介绍了一种多模式搜索架构和一系列 AB 测试，用于优化 Adob​​e Express 模板搜索中的嵌入和多模式技术。我们讨论了嵌入模型选择、嵌入在匹配和排名中的作用以及密集和稀疏嵌入之间的平衡等考虑因素。我们的迭代方法展示了如何利用稀疏、密集和上下文特征来增强短查询和长查询搜索，显著降低空值率（超过 70\%）并提高点击率 (CTR)。我们的研究结果为开发强大的多模式搜索系统提供了见解，从而增强了复杂查询的相关性。]]></description>
      <guid>https://arxiv.org/abs/2408.14698</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>摘要、重点和行动项目：LLM 支持的会议回顾系统的设计、实施和评估</title>
      <link>https://arxiv.org/abs/2307.15793</link>
      <description><![CDATA[arXiv:2307.15793v2 公告类型：replace-cross 
摘要：会议在工作协调中起着关键的基础作用。近年来，由于向混合和远程工作的转变，越来越多的会议转向在线计算机中介空间。这导致了新的问题（例如，在参与度较低的会议上花费更多时间）和新的机会（例如，自动转录/字幕和回顾支持）。用于对话摘要的大型语言模型 (LLM) 的最新进展有可能通过减少个人的会议负担并提高会议输出的清晰度和一致性来改善会议体验。尽管有这种潜力，但由于记录较长且无法根据用户的上下文捕捉不同的回顾需求，它们面临技术限制。为了解决这些差距，我们设计、实施和评估了上下文中的会议回顾系统。我们首先概念化两个突出的回顾表示——重要亮点和结构化的分层会议记录视图。我们开发了一个系统，以对话摘要作为其构建块来实现这些表示。最后，我们在七位用户的工作会议中评估了该系统的有效性。我们的研究结果表明，使用基于 LLM 的对话摘要进行会议回顾很有前景，并且需要在不同背景下同时使用这两种表示。然而，我们发现基于 LLM 的回顾仍然缺乏对参与者个人相关内容的理解，可能会遗漏重要细节，错误归因可能会对群体动态产生不利影响。我们确定了协作机会，例如高质量回顾可以实现的共享回顾文档。我们报告了设计 AI 系统的意义，以便与用户合作，从自然互动中学习和改进，以克服与个人相关性和总结质量相关的限制。]]></description>
      <guid>https://arxiv.org/abs/2307.15793</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从数据创建者到数据重用者：距离很重要</title>
      <link>https://arxiv.org/abs/2402.07926</link>
      <description><![CDATA[arXiv:2402.07926v2 公告类型：replace-cross 
摘要：共享研究数据对于数据重用是必要的，但还不够。开放科学政策更注重数据共享而不是重用，但两者都很复杂、劳动密集、成本高昂，并且需要多个利益相关者进行基础设施投资。数据重用的价值在于创建者和重用者之间的关系。通过解决知识交流，而不是利益相关者之间的单纯交易，可以更明智地投资数据管理和知识基础设施。借鉴数据共享和重用的实证研究，我们开发了数据创建者和数据重用者之间距离的理论结构，确定了影响有效传递知识能力的六个距离维度：领域、方法、协作、策展、目的以及时间和时间性。我们解决了这些维度的社会和社会技术方面，探索了它们可能减少或增加创建者和重用者之间距离的方法。我们对数据创建者和潜在重复使用者之间距离的理论框架，为四类利益相关者提供了如何使数据共享和重复使用更有效的建议：数据创建者、数据重复使用者、数据档案管理员和资助机构。共享研究数据需要“全村人”的参与——重复使用数据也需要全村人。我们的目标是激发新的研究问题、新的研究和对有效和高效地流通研究数据的新投资；并确定数据和研究生命周期每个阶段的投资标准。]]></description>
      <guid>https://arxiv.org/abs/2402.07926</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>