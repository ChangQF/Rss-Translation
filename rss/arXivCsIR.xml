<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 05 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>深度自适应兴趣网络：基于情境感知学习的个性化推荐</title>
      <link>https://arxiv.org/abs/2409.02425</link>
      <description><![CDATA[arXiv:2409.02425v1 公告类型：新
摘要：在个性化推荐系统中，准确捕捉用户不断变化的兴趣并将其与上下文信息相结合是一个重要的研究领域。本文提出了一种称为深度自适应兴趣网络（DAIN）的新模型，该模型动态地建模用户的兴趣，同时结合上下文感知学习机制，实现精准和自适应的个性化推荐。DAIN 利用深度学习技术构建自适应兴趣网络结构，可以实时捕捉用户的兴趣变化，同时通过整合上下文信息进一步优化推荐结果。在多个公共数据集上进行的实验表明，DAIN 在推荐性能和计算效率方面均表现出色。这项研究不仅为个性化推荐系统提供了一种新的解决方案，也为上下文感知学习在推荐系统中的应用提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.02425</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AlignGroup：学习并协调群体共识与成员偏好，以进行群体推荐</title>
      <link>https://arxiv.org/abs/2409.02580</link>
      <description><![CDATA[arXiv:2409.02580v1 Announce Type: new 
摘要：群体活动是人类社会的重要行为，为群体提供个性化推荐被称为群体推荐任务。现有的群体偏好推断方法通常可以分为两种策略：1）通过聚合成员的个性化偏好来确定群体偏好；2）通过捕捉群体成员在共同妥协后的一致决策来推断群体共识。然而，前者缺乏群体层面的考虑，而后者忽略了个人用户的细粒度偏好。为此，我们提出了一种新颖的群体推荐方法AlignGroup，该方法同时关注群体共识和群体成员的个人偏好来推断群体决策。具体而言，AlignGroup通过精心设计的超图神经网络探索群体共识，该网络可以有效地学习群体内和群体间的关系。此外，AlignGroup 创新性地利用自监督对齐任务来捕捉细粒度的群体决策，将群体共识与成员的共同偏好对齐。在两个真实数据集上进行的大量实验验证了我们的 AlignGroup 在群组推荐任务和用户推荐任务上的表现均优于最先进的方法，并且优于大多数基线的效率。]]></description>
      <guid>https://arxiv.org/abs/2409.02580</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双曲空间中的时尚商品推荐模型</title>
      <link>https://arxiv.org/abs/2409.02599</link>
      <description><![CDATA[arXiv:2409.02599v1 公告类型：新
摘要：在这项工作中，我们提出了一种时尚商品推荐模型，将双曲几何融入用户和商品表示中。使用双曲空间，我们的模型旨在根据商品的视觉数据和用户的购买历史捕捉商品之间的隐式层次结构。在训练期间，我们应用了一个多任务学习框架，该框架在损失函数中同时考虑双曲距离和欧几里得距离。我们在三个数据集上进行的实验表明，我们的模型比以前仅在欧几里得空间中训练的模型表现更好，证实了我们模型的有效性。我们的消融研究表明，多任务学习起着关键作用，消除欧几里得损失会大大降低模型性能。]]></description>
      <guid>https://arxiv.org/abs/2409.02599</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RouterRetriever：探索多专家嵌入模型中路由的优势</title>
      <link>https://arxiv.org/abs/2409.02685</link>
      <description><![CDATA[arXiv:2409.02685v1 公告类型：新
摘要：信息检索方法通常依赖于在大型通用领域数据集（如 MSMARCO）上训练的单个嵌入模型。虽然这种方法可以生成具有合理整体性能的检索器，但在特定领域数据上训练的模型通常会在各自的领域内产生更好的结果。虽然信息检索领域的先前工作已经通过多任务训练解决了这个问题，但结合多个领域特定专家检索器的主题仍未得到探索，尽管它在语言模型生成中很受欢迎。在这项工作中，我们引入了 RouterRetriever，这是一种利用多个领域特定专家以及路由机制来为每个查询选择最合适的专家的检索模型。它很轻量，可以轻松添加或删除专家而无需额外培训。在 BEIR 基准上的评估表明，RouterRetriever 的表现优于 MSMARCO 训练（+2.1 绝对 nDCG@10）和多任务训练（+3.2）模型。这是通过采用我们的路由机制实现的，该机制超越了语言建模中常用的其他路由技术（平均 +1.8）。此外，即使在没有特定数据集专家的情况下，该优势也可以很好地推广到其他数据集。据我们所知，RouterRetriever 是第一项展示在检索任务中使用具有有效路由的多个领域特定专家嵌入模型优于单个通用嵌入模型的工作。]]></description>
      <guid>https://arxiv.org/abs/2409.02685</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建可扩展、有效且可控的搜索和排名平台</title>
      <link>https://arxiv.org/abs/2409.02856</link>
      <description><![CDATA[arXiv:2409.02856v1 公告类型：新
摘要：现代电子商务平台提供大量产品选择，这使得客户很难找到他们喜欢的、与当前会话意图相关的商品。这就是为什么电子商务平台拥有近乎实时的可扩展和适应性个性化排名和搜索系统至关重要。虽然科学文献中存在许多构建此类系统的方法，但由于复杂性和性能限制，许多方法不适合大规模工业使用。因此，工业排名系统通常采用计算效率高但过于简单的检索或候选生成方法，这些方法忽略了近乎实时和异构的客户信号，导致体验不够个性化和相关。此外，相关的客户体验由完全不同的系统提供，这增加了复杂性、维护和不一致的体验。
在本文中，我们介绍了一个个性化、适应性强的近实时排名平台，该平台可在浏览和搜索等各种用例中重复使用，并且能够在重负载（每秒数千个请求）下满足数百万个商品和客户的需求。我们通过不同的排名层采用基于转换器的模型，这些模型可以直接从客户动作序列中学习复杂的行为模式，同时能够结合时间（例如会话中）和上下文信息。我们通过在一个大型在线电子商务平台上进行的一系列全面的离线和在线真实世界实验来验证我们的系统，并且我们展示了它与现有系统相比的优势，无论是在客户体验方面还是在净收入方面。最后，我们分享了从构建一个全面的现代排名平台以用于大型电子商务环境中获得的经验教训。]]></description>
      <guid>https://arxiv.org/abs/2409.02856</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NUDGE：用于检索的轻量级非参数嵌入微调</title>
      <link>https://arxiv.org/abs/2409.02343</link>
      <description><![CDATA[arXiv:2409.02343v1 公告类型：交叉 
摘要：从预训练的嵌入模型中对密集向量嵌入（$k$-NN 检索）进行 $k$-最近邻搜索是文本和图像以及检索增强生成 (RAG) 管道的主要检索方法。在实践中，应用程序开发人员经常对嵌入进行微调以提高其在数据集和手头查询工作负载上的准确性。现有的方法要么对预训练模型本身进行微调，要么更有效地（但以准确性为代价）训练适配器模型来转换预训练模型的输出。我们提出了 NUDGE，这是一组新颖的非参数嵌入微调方法，它们比现有的两组方法都更准确、更高效。NUDGE 直接修改数据记录的嵌入以最大限度地提高 $k$-NN 检索的准确性。我们对 NUDGE 的非参数方法进行了全面的理论和实验研究。我们表明，即使底层问题是 NP-Hard，也可以有效地解决受约束的变化。这些约束还确保了对嵌入的更改是适度的，避免了对预训练期间学习的语义造成较大的扭曲。在对五个预训练模型和九个标准文本和图像检索数据集进行的实验中，NUDGE 可在几分钟内运行，并且通常比现有的微调方法将 NDCG@10 提高 10% 以上。平均而言，与微调预训练模型和训练适配器相比，NUDGE 的准确率分别提高了 3.3 倍和 4.3 倍，运行速度分别提高了 200 倍和 3 倍。]]></description>
      <guid>https://arxiv.org/abs/2409.02343</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种有效的广告牌标签分配方法</title>
      <link>https://arxiv.org/abs/2409.02455</link>
      <description><![CDATA[arXiv:2409.02455v1 公告类型：交叉 
摘要：广告牌广告因其投资回报率高而广受欢迎。为了使这种广告方式更有效，需要将产品的相关信息传达给相关人群。如果可以将相关标签集映射到正确的位置，则可以实现这一点。正式地，我们将这个问题称为广告牌广告中的标签分配问题。给定轨迹、广告牌数据库和一组选定的广告牌位置和标签，这个问题要求输出选定标签到选定位置的映射，以最大化影响力。我们将其建模为传统二分匹配的一种变体，称为一对多二分匹配 (OMBM)。与传统的二分匹配不同，一个标签只能分配给一个位置；在 OMBM 中，一个标签可以分配给多个位置，而反之亦然。我们提出了一种迭代解决方案，将标签逐步分配给位置。本文通过一个示例解释了所提出的方法。我们还对所提出的解决方案进行了复杂性分析。在真实世界轨迹和广告牌数据集上的实验结果证明了我们所提出的解决方案的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2409.02455</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>iRangeGraph：针对范围过滤最近邻搜索改进范围专用图</title>
      <link>https://arxiv.org/abs/2409.02571</link>
      <description><![CDATA[arXiv:2409.02571v1 公告类型：交叉 
摘要：范围过滤近似最近邻 (RFANN) 搜索在学术界和工业界引起了越来越多的关注。给定一组数据对象，每个数据对象都是一对高维向量和一个数值，以向量和数值范围为参数的 RFANN 查询将返回数值在查询范围内且向量最接近查询向量的数据对象。为了处理这个查询，最近的一项研究提出为所有可能的查询范围构建 $O(n^2)$ 个专用的基于图的索引，以便对 $n$ 个对象的数据库进行高效处理。由于存储所有这些索引的成本过高，因此该研究改为构建压缩索引，这大大降低了内存消耗。然而，这会导致性能不佳，因为压缩是有损的。在本研究中，我们不是为每个可能的查询范围实现一个压缩索引以准备查询，而是为中等数量的范围实现基于图的索引（称为元素图）。然后，我们提供了一种有效且高效的算法，该算法可以在查询过程中使用元素图为任何查询范围构建索引。我们证明构建此类索引所需的时间很短。我们还介绍了一项针对真实数据集的实验研究，该研究提供了证据，表明物化元素图仅占用适中的空间，并且所提出的方法能够在不同的查询工作负载中实现卓越而稳定的查询性能。]]></description>
      <guid>https://arxiv.org/abs/2409.02571</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>池化和注意力：基于 LLm 的嵌入模型的有效设计是什么？</title>
      <link>https://arxiv.org/abs/2409.02727</link>
      <description><![CDATA[arXiv:2409.02727v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在生成任务中的重大进步导致越来越多的工作探索基于 LLM 的嵌入模型。虽然这些采用不同池化和注意力策略的模型在公共嵌入基准上取得了最先进的性能，但仍然存在关于什么构成基于 LLM 的嵌入模型的有效设计的问题。然而，这些模型通常在不同的数据集上进行训练，使用不同的 LLM 基础模型或训练设置。此外，对公共嵌入基准的评估通常无法报告统计显着性，因此很难确定哪些设计真正有助于最终性能。这为寻求基于 LLM 的嵌入模型的最佳训练方案的从业者带来了复杂化的过程。在这项研究中，我们进行了一项大规模实验，通过使用相同的训练数据和基础模型（但在池化和注意力策略上有所不同）训练一系列基于 LLM 的嵌入模型。结果表明，没有一刀切的解决方案：虽然双向注意力和额外的可训练池化层在文本相似性和信息检索任务中表现出色，但它们在聚类和分类任务中并没有明显超越更简单的设计，如 EOS-last 标记池化和默认因果注意力。此外，我们提出了一种新的池化策略，即多层可训练池化，它使用交叉注意力网络转换所有隐藏层的输出，而不仅仅是最后一层。与现有的池化方法相比，该方法在文本相似性和检索任务中具有统计优势。总体而言，本文阐明了基于 LLM 的嵌入模型的有效训练策略。]]></description>
      <guid>https://arxiv.org/abs/2409.02727</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生物信息学检索增强数据 (BRAD) 数字助理</title>
      <link>https://arxiv.org/abs/2409.02864</link>
      <description><![CDATA[arXiv:2409.02864v1 公告类型：交叉 
摘要：我们展示了生物信息学检索增强数据 (BRAD) 数字助理的原型。BRAD 集成了一套工具来处理从代码执行到在线搜索的各种生物信息学任务。我们通过 (1) 使用检索增强生成 (RAG) 改进问答、(2) BRAD 运行和编写复杂软件管道的能力以及 (3) BRAD 在个人和代理团队之间组织和分配任务的能力来展示 BRAD 的功能。我们使用 BRAD 实现生物信息学工作流程的自动化，执行从基因富集和搜索档案到自动代码生成和运行生物标志物识别管道等任务。BRAD 是朝着最终目标迈出的一步，即开发由独立循环驱动的实验室数字孪生，用于假设生成和数字生物学实验的测试。]]></description>
      <guid>https://arxiv.org/abs/2409.02864</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式推荐系统：综述</title>
      <link>https://arxiv.org/abs/2302.03883</link>
      <description><![CDATA[arXiv:2302.03883v2 公告类型：替换 
摘要：推荐系统（RS）已成为在线服务不可或缺的工具包。它们配备了各种深度学习技术，可根据标识符和属性信息对用户偏好进行建模。随着短视频、新闻等多媒体服务的出现，在推荐时理解这些内容变得至关重要。此外，多模态特征也有助于缓解 RS 中的数据稀疏问题。因此，多模态推荐系统（MRS）最近引起了学术界和工业界的广泛关注。在本文中，我们将主要从技术角度对 MRS 模型进行全面概述。首先，我们总结了 MRS 的一般程序和主要挑战。然后，我们根据四个类别介绍现有的 MRS 模型，即模态编码器、特征交互、特征增强和模型优化。此外，为了方便那些想要研究这个领域的人，我们还总结了数据集和代码资源。最后，我们讨论了 MRS 的一些有前景的未来方向并总结了本文。为了访问所调查论文的更多细节，例如实现代码，我们开源了一个存储库。]]></description>
      <guid>https://arxiv.org/abs/2302.03883</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CaDRec：情境化和去偏见推荐模型</title>
      <link>https://arxiv.org/abs/2404.06895</link>
      <description><![CDATA[arXiv:2404.06895v3 公告类型：替换 
摘要：旨在挖掘用户行为模式的推荐模型作为日常生活中必不可少的应用之一，引起了极大的关注。最近在图神经网络（GNN）或去偏方法方面的研究取得了显着的进展。然而，它们仍然存在（1）由与 GNN 的递归卷积引起的节点嵌入过度平滑，以及（2）由于流行度和用户个人偏见导致交互分布倾斜的问题。本文提出了一种情境化和去偏推荐模型（CaDRec）。为了克服过度平滑问题，我们探索了一种新颖的超图卷积算子，它可以通过引入结构上下文和顺序上下文在卷积过程中选择有效邻居。为了解决分布倾斜的问题，我们提出了两种解开交互的策略：（1）对个体偏见进行建模以学习无偏项目嵌入，以及（2）将项目流行度与位置编码结合起来。此外，我们通过数学方法证明了更新项目嵌入的梯度不平衡会加剧流行度偏差，因此采用正则化和加权方案作为解决方案。在四个数据集上进行的大量实验证明了 CaDRec 相对于最先进 (SOTA) 方法的优越性。我们的源代码和数据发布在 https://github.com/WangXFng/CaDRec。]]></description>
      <guid>https://arxiv.org/abs/2404.06895</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NFARec：一种负反馈感知推荐模型</title>
      <link>https://arxiv.org/abs/2404.06900</link>
      <description><![CDATA[arXiv:2404.06900v3 公告类型：替换 
摘要：基于图神经网络 (GNN) 的模型已被广泛研究用于推荐，因为它们可以准确提取高质量推荐系统所需的高阶协作信号。然而，它们忽略了通过负反馈获得的宝贵信息，涉及两个方面：（1）不同的用户可能对同一项目持有相反的反馈，这妨碍了 GNN 中的最佳信息传播；（2）即使某个项目与用户的偏好大相径庭，他们仍可能会选择它并提供负面评分。在本文中，我们提出了一种负反馈感知推荐模型 (NFARec)，以最大限度地发挥负反馈的杠杆作用。为了有效地将信息沿最佳路径传输给多跳邻居，NFARec 采用反馈感知相关性来指导超图卷积 (HGC) 来学习用户的结构表示。此外，NFARec 还包含一项辅助任务——基于 Transformer Hawkes 过程预测下一次交互的反馈情绪极性（即正面或负面）。该任务有助于通过学习用户在之前的连续反馈模式中表达的情绪并预测未来的交互来理解用户。大量实验表明，NFARec 的表现优于竞争基线。我们的源代码和数据发布在 https://github.com/WangXFng/NFARec。]]></description>
      <guid>https://arxiv.org/abs/2404.06900</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型评估使用小样本提示的命名实体识别</title>
      <link>https://arxiv.org/abs/2408.15796</link>
      <description><![CDATA[arXiv:2408.15796v2 公告类型：替换 
摘要：本文评估了使用大型语言模型进行命名实体识别 (NER) 的少样本提示。传统的 NER 系统依赖于大量标记数据集，这些数据集的获取成本高昂且耗时。少样本提示或上下文学习使模型能够用最少的示例识别实体。我们在 NER 任务中评估了 GPT-4 等最先进的模型，将它们的少样本性能与完全监督的基准进行比较。结果表明，虽然存在性能差距，但大型模型在适应数据非常有限的新实体类型和领域方面表现出色。我们还探讨了提示工程、引导输出格式和上下文长度对性能的影响。这项研究强调了少样本学习在减少对大型标记数据集的需求、增强 NER 可扩展性和可访问性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.15796</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Jina-ColBERT-v2：通用多语言后期交互检索器</title>
      <link>https://arxiv.org/abs/2408.16672</link>
      <description><![CDATA[arXiv:2408.16672v3 公告类型：替换 
摘要：多向量密集模型（例如 ColBERT）已被证明在信息检索中非常有效。由于其双编码器架构以及索引和搜索方面的最新优​​化，ColBERT 的后期交互评分近似于跨编码器中看到的联合查询文档注意，同时保持更接近传统密集检索模型的推理效率。在本文中，我们介绍了一种新颖的架构和训练框架，以支持长上下文窗口和多语言检索。我们的新模型 Jina-ColBERT-v2 在一系列英语和多语言检索任务中表现出色，]]></description>
      <guid>https://arxiv.org/abs/2408.16672</guid>
      <pubDate>Thu, 05 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>