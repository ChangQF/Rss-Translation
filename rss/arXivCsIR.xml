<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>面向下一代基于 LLM 的推荐系统：调查与展望</title>
      <link>https://arxiv.org/abs/2410.19744</link>
      <description><![CDATA[arXiv:2410.19744v1 公告类型：新
摘要：大型语言模型（LLM）不仅彻底改变了自然语言处理（NLP）领域，而且由于其出色的语言理解能力以及令人印象深刻的泛化能力和推理能力，还可能在许多其他领域带来范式转变。因此，最近的研究积极尝试利用LLM的力量来改进推荐系统，并且必须彻底回顾基于LLM的推荐系统的最新进展和挑战。与现有工作不同，本综述不仅仅根据LLM的技术框架分析基于LLM的推荐系统的分类。相反，它从推荐系统社区的角度研究了LLM如何更好地服务于推荐任务，从而增强了大型语言模型与推荐系统研究及其实际应用的结合。此外，与推荐系统相关的学术研究和工业应用之间的长期差距尚未得到很好的讨论，尤其是在大型语言模型时代。在本篇综述中，我们引入了一种源自推荐本质的新分类法，深入研究了基于大型语言模型的推荐系统的应用及其工业实现。具体来说，我们提出了一个三层结构，更准确地反映了推荐系统从研究到实际实现的发展进程，包括表示和理解、规划和利用以及工业部署。此外，我们讨论了这一新兴领域的关键挑战和机遇。论文的最新版本维护在：https://github.com/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey。]]></description>
      <guid>https://arxiv.org/abs/2410.19744</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过海报双模协同的交叉注意力融合解析电影类型</title>
      <link>https://arxiv.org/abs/2410.19764</link>
      <description><![CDATA[arXiv:2410.19764v1 公告类型：新
摘要：电影海报不仅仅是装饰性的；它们经过精心设计，可以捕捉电影的精髓，例如其类型、故事情节和基调/氛围。几十年来，电影海报一直以数字海报的形式出现在电影院墙壁、广告牌上，现在又出现在我们的数字屏幕上。电影类型分类在电影营销、观众参与和推荐系统中起着关键作用。之前对电影类型分类的探索主要在情节摘要、字幕、预告片和电影场景中进行。电影海报提供了电影发行前诱人的一瞥，可以激发公众的兴趣。在本文中，我们提出了从视觉和文本角度利用电影海报来解决多标签电影类型分类问题的框架。首先，我们使用 OCR 从电影海报中提取文本并检索相关嵌入。接下来，我们引入了一个基于交叉注意力的融合模块，用于为视觉和文本嵌入分配注意力权重。在验证我们的框架时，我们使用了来自互联网电影数据库 (IMDb) 的 13882 张海报。实验结果表明，我们的模型表现出了良好的性能，甚至优于一些著名的当代架构。]]></description>
      <guid>https://arxiv.org/abs/2410.19764</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>作者不详：评估作者提取库对全球在线新闻文章的性能</title>
      <link>https://arxiv.org/abs/2410.19771</link>
      <description><![CDATA[arXiv:2410.19771v1 公告类型：新
摘要：对大量在线新闻内容的分析需要对底层元数据提取方法进行强有力的验证。识别给定网络新闻文章的作者就是一个可以解决各种研究问题的例子。虽然存在许多现成的作者提取解决方案，但很少有工作比较性能（特别是在多语言环境中）。在本文中，我们提供了一个手动编码的在线新闻文章作者跨语言数据集，并使用它来评估五个现有软件包和一个定制模型的性能。我们的评估表明，Go-readability 和 Trafilatura 是作者提取最一致的解决方案，但我们发现所有软件包在不同语言中产生的结果差异很大。这些发现对于希望在其分析流程中使用作者数据的研究人员来说很重要，主要表明需要对特定语言和地区进行进一步验证才能依赖结果。]]></description>
      <guid>https://arxiv.org/abs/2410.19771</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Telco-DPR：用于评估 3GPP 技术规范检索模型的混合数据集</title>
      <link>https://arxiv.org/abs/2410.19790</link>
      <description><![CDATA[arXiv:2410.19790v1 公告类型：新
摘要：本文提出了一种使用第三代合作伙伴计划 (3GPP) 技术文档的电信领域问答 (QA) 系统。同时，还介绍了一个混合数据集 Telco-DPR，它由混合格式的精选 3GPP 语料库组成，结合了文本和表格。此外，该数据集还包括一组合成问题/答案对，旨在评估 QA 系统对此类数据的检索性能。使用 top-K 准确度和平均倒数排名 (MRR) 评估和比较了检索模型，包括稀疏模型、最佳匹配 25 (BM25)，以及密集模型，例如密集段落检索器 (DPR) 和密集分层检索 (DHR)。结果表明，DHR 是一种检索器模型，通过在文档和段落级别进行微调，利用分层段落选择，在检索相关技术信息方面优于传统方法，前 10 名准确率达到 86.2%。此外，还对所提出的 QA 系统中使用的检索器增强生成 (RAG) 技术进行了评估，以展示使用混合数据集和 DHR 的好处。所提出的 QA 系统使用开发的 RAG 模型和生成式预训练 Transformer (GPT)-4，与同一数据集上的先前基准相比，答案准确率提高了 14%。]]></description>
      <guid>https://arxiv.org/abs/2410.19790</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多模式、自主、多代理系统的个性化推荐系统</title>
      <link>https://arxiv.org/abs/2410.19855</link>
      <description><![CDATA[arXiv:2410.19855v1 公告类型：新
摘要：本文介绍了一种使用多模式、自主、多代理系统的高度开发的个性化推荐系统。该系统专注于结合未来的人工智能技术和 Gemini-1.5-pro 和 LLaMA-70B 等 LLM，以改善客户服务体验，尤其是在电子商务领域。我们的方法使用多代理、多模式系统为用户提供最佳建议。整个系统由三个代理组成。第一个代理推荐适合回答给定问题的产品，而第二个代理根据属于这些推荐产品的图像提出后续问题，然后由第三个代理进行自主搜索。它还具有实时数据提取、基于用户偏好的推荐和自适应学习功能。在复杂的查询过程中，应用程序使用 Symphony 进行处理，并使用 Groq API 快速回答，响应时间短。它使用多模式方式全面利用文本和图像，从而优化产品推荐和客户互动。]]></description>
      <guid>https://arxiv.org/abs/2410.19855</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FLOW：用于同时增强推荐和用户代理的反馈循环框架</title>
      <link>https://arxiv.org/abs/2410.20027</link>
      <description><![CDATA[arXiv:2410.20027v1 公告类型：新
摘要：由大型语言模型驱动的代理表现出了卓越的推理和执行能力，吸引了研究人员探索其在推荐领域的潜力。以前的研究主要集中于独立增强推荐代理或用户代理的能力，但没有考虑推荐代理和用户代理之间的交互和协作。为了解决这一差距，我们提出了一个名为 FLOW 的新框架，它通过引入反馈循环实现了推荐代理和用户代理之间的协作。具体来说，推荐代理通过分析用户代理对先前推荐项目的反馈来完善对用户偏好的理解，而用户代理则利用推荐的项目来深入了解用户的潜在兴趣。这种迭代细化过程增强了推荐代理和用户代理的推理能力，从而实现了更精确的推荐和更准确的用户行为模拟。为了证明反馈循环的有效性，我们在三个广泛使用的推荐领域数据集上评估了推荐性能和用户模拟性能。实验结果表明，反馈循环可以同时提高推荐和用户代理的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.20027</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DQRM：深度量化推荐模型</title>
      <link>https://arxiv.org/abs/2410.20046</link>
      <description><![CDATA[arXiv:2410.20046v1 公告类型：新
摘要：目前，大规模推荐模型是许多大型互联网公司的主要工作负载。这些推荐器的特点是具有大量嵌入表，这些表很少被用户和项目特征的索引访问。这些 1TB+ 表的大小对推荐模型的训练和推理造成了严重的内存瓶颈。在这项工作中，我们基于最先进的深度学习推荐模型 (DLRM) 提出了一种新颖的推荐框架，该框架体积小、功能强大且运行和训练效率高。所提出的框架使云服务器上的推理更加高效，探索了在较小的边缘设备上部署强大推荐器的可能性，并优化了数据并行设置下分布式训练中通信开销的工作负载。具体而言，我们表明量化感知训练 (QAT) 可以施加强大的正则化效果来缓解 DLRM 遭受的严重过拟合问题。因此，我们实现了 DLRM 模型的 INT4 量化，而准确率没有任何下降。我们进一步提出了两种技术，专门针对推荐模型中的嵌入表改进和加速传统 QAT 工作负载。此外，为了实现高效训练，我们在得到良好支持的指定稀疏化的基础上将嵌入表的梯度量化为 INT8。我们表明，将梯度稀疏化和量化结合在一起可以显著减少通信量。简而言之，具有 INT4 的 DQRM 模型可以在 0.27 GB 模型大小的 Kaggle 上实现 79.07% 的准确率，在 1.57 GB 的 Terabyte 数据集上实现 81.21% 的准确率，甚至优于模型大小大得多的 FP32 DLRM（Kaggle 上为 2.16 GB，Terabyte 上为 12.58）。]]></description>
      <guid>https://arxiv.org/abs/2410.20046</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoMIR：无需相关标签的有效零样本医疗信息检索</title>
      <link>https://arxiv.org/abs/2410.20050</link>
      <description><![CDATA[arXiv:2410.20050v1 公告类型：新
摘要：医学信息检索 (MIR) 对于从各种来源（包括电子健康记录、科学文献和医学数据库）检索相关医学知识至关重要。然而，由于缺乏相关标记数据，在医学领域实现有效的零样本密集检索面临着巨大的挑战。在本文中，我们介绍了一种称为自学习假设文档嵌入 (SL-HyDE) 的新方法来解决这个问题。SL-HyDE 利用大型语言模型 (LLM) 作为生成器，根据给定的查询生成假设文档。这些生成的文档封装了关键的医学背景，指导密集检索器识别最相关的文档。自学习框架利用未标记的医学语料库逐步完善伪文档生成和检索，而无需任何相关标记数据。此外，我们还提出了中国医学信息检索基准 (CMIRB)，这是一个基于真实医学场景的综合评估框架，涵盖五项任务和十个数据集。通过在 CMIRB 上对十个模型进行基准测试，我们建立了一个严格的医学信息检索系统评估标准。实验结果表明，SL-HyDE 在检索准确率方面明显优于现有方法，同时在各种 LLM 和检索器配置中表现出强大的泛化能力和可扩展性。CMIRB 数据和评估代码可在以下网址公开获取：https://github.com/CMIRB-benchmark/CMIRB。]]></description>
      <guid>https://arxiv.org/abs/2410.20050</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多领域自适应检索</title>
      <link>https://arxiv.org/abs/2410.20056</link>
      <description><![CDATA[arXiv:2410.20056v1 公告类型：新
摘要：文档检索（例如搜索和检索增强生成）通常涉及非结构化的数据集：每个文档中没有明确内部结构的自由格式文本。但是，文档可以具有结构化形式，由文章标题、消息正文或 HTML 标头等字段组成。为了解决这一差距，我们引入了多字段自适应检索 (MFAR)，这是一个灵活的框架，可容纳结构化数据上的任意数量和任何类型的文档索引。我们的框架包括两个主要步骤：(1) 将现有文档分解为字段，每个字段通过密集和词汇方法独立索引，以及 (2) 学习一个模型，该模型通过调节文档查询来自适应地预测字段的重要性，从而允许对最可能的字段进行动态加权。我们发现，我们的方法可以优化使用跨字段类型的密集表示与词汇表示，显著提高现有检索器中的文档排名，并实现多字段结构化数据的最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.20056</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用子模函数优化 (SFO) 优化关键词排名以实现相关性和多样性</title>
      <link>https://arxiv.org/abs/2410.20080</link>
      <description><![CDATA[arXiv:2410.20080v1 公告类型：新
摘要：关键短语排名通过有效地索引和检索相关信息，在信息检索和摘要中起着至关重要的作用。自然语言处理方面的进步，尤其是大型语言模型 (LLM)，已经改进了关键短语的提取和排名。然而，传统方法往往忽视多样性，导致关键短语冗余。我们提出了一种使用子模块函数优化 (SFO) 来平衡关键短语排名中的相关性和多样性的新方法。通过将任务定义为子模块最大化，我们的方法选择了多样化和有代表性的关键短语。在基准数据集上的实验表明，我们的方法在相关性和多样性指标方面都优于现有方法，在执行时间上实现了 SOTA 性能。我们的代码可以在线获取。]]></description>
      <guid>https://arxiv.org/abs/2410.20080</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UniHGKR：统一指令感知异构知识检索器</title>
      <link>https://arxiv.org/abs/2410.20163</link>
      <description><![CDATA[arXiv:2410.20163v1 公告类型：新
摘要：现有的信息检索 (IR) 模型通常假设知识源和用户查询具有同质结构，这限制了它们在现实世界中的适用性，因为现实世界中的检索本质上是异构和多样化的。在本文中，我们介绍了 UniHGKR，这是一种统一的指令感知异构知识检索器，它 (1) 为异构知识构建统一的检索空间，(2) 遵循不同的用户指令来检索指定类型的知识。UniHGKR 由三个主要阶段组成：异构自监督预训练、文本锚定嵌入对齐和指令感知检索器微调，使其能够在不同的检索环境中进行推广。该框架具有高度可扩展性，具有基于 BERT 的版本和在大型语言模型上训练的 UniHGKR-7B 版本。此外，我们还推出了第一个原生异构知识检索基准 CompMix-IR。它包括两个具有各种指令的检索场景、超过 9,400 个问答 (QA) 对以及一个包含 1000 万个条目的语料库，涵盖四种不同类型的数据。大量实验表明，UniHGKR 在 CompMix-IR 上的表现始终优于最先进的方法，在两个场景中分别实现了高达 6.36% 和 54.23% 的相对改进。最后，通过为我们的检索器配备开放域异构 QA 系统，我们在流行的 ConvMix 任务上取得了新的最先进的结果，绝对改进高达 4.80 分。]]></description>
      <guid>https://arxiv.org/abs/2410.20163</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Quam：通过查询亲和力模型实现自适应检索</title>
      <link>https://arxiv.org/abs/2410.20286</link>
      <description><![CDATA[arXiv:2410.20286v1 公告类型：新
摘要：构建相关性模型以根据用户信息需求对文档进行排名是信息检索和 NLP 社区的核心任务。除了直接的临时搜索设置之外，许多知识密集型任务都由第一阶段检索阶段提供支持，用于上下文选择，然后是更复杂的任务特定模型。然而，大多数第一阶段排名阶段本质上受到初始排名文档的召回限制。最近，已经提出了自适应重新排名技术来克服这个问题，通过不断从整个语料库中选择文档，而不是仅考虑初始文档池。然而，到目前为止，这些方法仅限于启发式设计选择，特别是在文档选择标准方面。在这项工作中，我们提出了一种统一的观点，即通过提出 Quam，一种利用相关性感知文档相似性图来提高召回率的 \textit{查询亲和性模型}，尤其是在低重排预算的情况下。我们大量的实验证据表明，我们提出的方法 Quam 比标准重排基线将召回率提高了 26\%。此外，查询亲和性建模和相关性感知文档图模块可以注入任何自适应检索方法中。实验结果表明，现有的自适应检索方法将召回率提高了 12\%。我们的工作代码可在 \url{https://github.com/Mandeep-Rathee/quam} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.20286</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WindTunnel——大型语料库的社区意识抽样框架</title>
      <link>https://arxiv.org/abs/2410.20301</link>
      <description><![CDATA[arXiv:2410.20301v1 公告类型：新
摘要：进行全面的信息检索实验（例如搜索或检索增强生成）通常需要很高的计算成本。这是因为评估检索算法需要索引整个语料库，而这比正在评估的（查询，结果）对集要大得多。这个问题在大数据和神经检索中尤为明显，因为索引变得越来越耗时且复杂。在本文中，我们介绍了 WindTunnel，这是 Yext 开发的一种新框架，用于生成大型语料库的代表性样本，从而实现高效的端到端信息检索实验。通过保留数据集的社区结构，WindTunnel 克服了当前采样方法的局限性，从而提供了更准确的评估。]]></description>
      <guid>https://arxiv.org/abs/2410.20301</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于图的近似最近邻搜索高效且有效地检索密集-稀疏混合向量</title>
      <link>https://arxiv.org/abs/2410.20381</link>
      <description><![CDATA[arXiv:2410.20381v1 公告类型：新
摘要：用于文本嵌入向量表示的 ANNS 通常用于信息检索，其中两个重要的信息表示是稀疏和密集向量。虽然已经证明结合这些表示可以提高准确性，但当前分别进行稀疏和密集向量搜索的方法存在可扩展性低和系统复杂度高的问题。或者，建立统一的索引面临着准确性和效率的挑战。为了解决这些问题，我们提出了一种基于图的密集-稀疏混合向量 ANNS 算法。首先，我们提出了一种分布对齐方法来提高准确性，该方法对密集和稀疏向量进行预采样以分析它们的距离分布统计，从而使准确率提高 1%$\sim$9%。其次，为了提高效率，我们设计了一种自适应的两阶段计算策略，最初只计算密集距离，然后计算混合距离。此外，我们修剪稀疏向量以加快计算速度。与原始实现相比，我们实现了$\sim2.1\times$加速。经过深入的实验表明，与现有的混合向量搜索算法相比，我们的算法在同等精度下实现了 8.9x$\sim$11.7x 的吞吐量。]]></description>
      <guid>https://arxiv.org/abs/2410.20381</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨领域推荐的一致性引导偏好解缠</title>
      <link>https://arxiv.org/abs/2410.20580</link>
      <description><![CDATA[arXiv:2410.20580v1 公告类型：新
摘要：发现不同领域的用户偏好对于跨域推荐系统至关重要，尤其是当平台缺乏全面的用户-项目交互数据时。共享用户的有限存在通常会妨碍对共同偏好的有效建模。虽然利用共享项目的属性（例如类别和流行度）可以增强跨域推荐性能，但域间共享项目的稀缺性限制了该领域的研究。为了解决这个问题，我们提出了一种一致性引导的偏好解缠 (CoPD) 方法，旨在通过以下方式改进跨域推荐：i) 明确提取共享项目属性以指导共享用户偏好的学习；ii) 解缠这些偏好以识别域间转移的特定用户兴趣。CoPD 在共享和特定域的项目嵌入上引入了一致性约束，有助于提取共享属性。此外，它利用这些属性通过流行度加权损失引导将用户偏好解缠为兴趣和一致性的单独嵌入。在真实数据集上进行的实验证明了我们提出的 CoPD 优于现有竞争基线的性能，凸显了其在增强跨域推荐性能方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.20580</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>