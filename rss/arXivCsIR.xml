<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Mon, 24 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在抹布中，猎犬到发电机的相关性是否传播了？</title>
      <link>https://arxiv.org/abs/2502.15025</link>
      <description><![CDATA[ARXIV：2502.15025V1公告类型：新 
摘要：检索增强发电（RAG）是合并外部知识的框架，通常是以从集合中检索到的一组文档的形式，作为提示的一部分，是大型语言模型（LLM）的一部分下游任务，例如问答。不同于标准检索任务的目标是最大化一组顶级文档的相关性，而抹布系统的目标是最大程度地提高其总效用，其中文档的效用表明将其作为附加上下文信息的一部分包括在内在LLM提示中，改进了下游任务。现有研究调查了抹布环境与知识密集型语言任务（KILT）的相关性的作用，其中相关性基本上采取了答案遏制的形式。相比之下，在我们的工作中，相关性与查询与寻求任务的文档之间的局部重叠相对应。具体来说，我们利用IR测试收集来经验研究抹布上下文是否由局部相关文档组成，导致下游性能的改善。我们的实验导致了以下发现：（a）相关性与效用之间存在很小的正相关性； （b）随着上下文大小的增加（k-shot k的较高值），这种相关性降低； （c）更有效的检索模型通常会导致更好的下游破布性能。]]></description>
      <guid>https://arxiv.org/abs/2502.15025</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GNN-CODER：使用联合GNN和Transformer提高语义代码检索</title>
      <link>https://arxiv.org/abs/2502.15202</link>
      <description><![CDATA[ARXIV：2502.15202V1公告类型：新 
摘要：代码检索是现代软件开发的关键组成部分，尤其是在大型项目中。但是，依靠基于序列的模型的现有方法通常无法完全利用代码固有的结构依赖性，从而导致次优的检索性能，尤其是在结构复杂的代码片段中。在本文中，我们介绍了基于图神经网络（GNN）的新型框架GNN-Coder，以利用抽象语法树（AST）。我们首次尝试研究GNN集成的变压器如何通过捕获代码的结构和语义特征来促进语义检索任务的发展。我们进一步提出了一种针对AST量身定制的创新图形合并方法，它利用子节点的数量作为突出AST内固有拓扑关系的关键特征。该设计有效地集成了顺序和分层表示，增强了模型捕获代码结构和语义的能力。此外，我们引入了平均角缘（MAM），这是一种量化代码嵌入分布的均匀性的新型指标，提供了特征可分离性的标准化度量。所提出的方法达到了较低的MAM，表明更具歧视性的特征表示。这突显了GNN-Coder区分代码片段的卓越能力，从而提高了检索准确性。实验结果表明，GNN-Coder显着提高了检索性能，CSN数据集的MRR有1 \％-10 \％的提高，并且COSQA数据集的零拍摄性能显着20 \％。]]></description>
      <guid>https://arxiv.org/abs/2502.15202</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于BERT的学术合作的混合建议系统</title>
      <link>https://arxiv.org/abs/2502.15223</link>
      <description><![CDATA[ARXIV：2502.15223V1公告类型：新 
摘要：大学是学术合作的枢纽，通过跨学科对话促进学生和教师之间各种思想和观点的交流。但是，随着大学规模的扩大，通过学生章节，班级和教职委员会的传统网络方法变得繁琐。为了应对这一挑战，提出了一个特定于学术的个人资料推荐系统，以连接任何大学社区中志趣相投的利益相关者。这项研究评估了三种技术：术语频率段文档频率（TF-IDF），来自变形金刚（BERT）的双向编码器表示以及产生有效建议的混合方法。由于数据集的未标记性质，因此，对基于亲和力繁殖的重新进行了重新标记，以了解相似概况的分组。混合模型表现出了出色的性能，其相似性得分，剪影得分，戴维斯 - 博丁指数和归一化的折扣累积增益（NDCG）证明了这一点，在建议中实现了多样性和相关性之间的最佳平衡。此外，最佳模型已作为移动应用程序实施，该应用程序会根据用户的技能和协作兴趣动态提出相关的配置文件，从而结合了上下文理解。该应用程序的潜在影响很大，因为它有望通过部署智能推荐系统来增强大型学术机构中的网络机会。]]></description>
      <guid>https://arxiv.org/abs/2502.15223</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从文档到对话：建立kg-rag增强了AI助手</title>
      <link>https://arxiv.org/abs/2502.15237</link>
      <description><![CDATA[ARXIV：2502.15237V1公告类型：新 
摘要：Adobe Experience Platform AI Assistant是一种会话工具，使组织能够通过聊天机器人与专有企业数据无缝互动。但是，由于访问限制，大型语言模型（LLMS）无法检索这些内部文档，从而限制了它们产生准确的零击响应的能力。为了克服这一限制，我们使用由知识图（KG）提供动力的检索型生成（RAG）框架来从外部知识源检索相关信息，使LLMS能够回答有关私人或以前看不见的文档收集的问题。在本文中，我们提出了一种新颖的方法，用于建立高质量的低噪声KG。我们应用了几种技术，包括使用种子概念，基于相似性的过滤的增量实体分辨率，将置信分数分配给实体关联对，以过滤高信心对，以及将事实链接到源文档以供出处。我们的kg-rag系统检索相关的元素，这些元素将添加到用户提示上的上下文，然后发送到LLM生成响应的LLM。我们的评估表明，与现有生产系统相比，这种方法显着提高了响应相关性，将无关的答案降低了50％，并将完全相关的答案增加了88％。]]></description>
      <guid>https://arxiv.org/abs/2502.15237</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>轻巧但高效：带有位置提示的外部专注图卷积网络进行顺序建议</title>
      <link>https://arxiv.org/abs/2502.15331</link>
      <description><![CDATA[ARXIV：2502.15331V1公告类型：新 
摘要：基于图的顺序推荐系统（GSR）由于能够同时处理用户 - 项目相互作用和项目之间的顺序关系，因此获得了大量的研究关注。当前的GSR通常用于图形编码（例如，图形变压器）的复合或深入结构。然而，它们具有很高的计算复杂性，阻碍了资源受限的边缘设备上的部署。此外，在图形变压器中编码的相对位置在考虑序列内的复杂位置依赖性方面很难。为此，我们提出了一个外部专注的卷积网络，并带有位置提示，即依次推荐，即EA-GPS。具体而言，我们首先引入了一个外部专注图卷积网络，该网络通过两个外部内存单元线性地测量节点之间的全局关联。然后，我们提出一个基于位置提示的解码器，该解码器将绝对项目位置视为外部提示。通过引入长度自适应的顺序掩盖和软注意力网络，这种解码器促进了模型，以捕获序列中的长期位置依赖关系和上下文关系。五个现实世界数据集的广泛实验结果表明，所提出的EA-GP的表现优于最新方法。值得注意的是，它在保持较小的参数规模和较低的训练开销的同时，达到了出色的性能。这项工作的实施可在https://github.com/zzy-graphmininglab/ea-gps上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2502.15331</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在CTR预测中压缩嵌入的通用框架</title>
      <link>https://arxiv.org/abs/2502.15355</link>
      <description><![CDATA[ARXIV：2502.15355V1公告类型：新 
摘要：准确的点击率（CTR）预测对于在线广告和推荐系统至关重要。最近的深度学习进步提高了捕获特征交互和了解用户兴趣的能力。但是，优化嵌入层通常仍被忽略。代表分类和顺序特征的嵌入表可能会变得过大，超过GPU内存限制，并需要在CPU内存中存储。由于频繁的GPU-CPU数据传输，这会导致高内存消耗和延迟增加。为了应对这些挑战，我们引入了模型不合时宜的嵌入压缩框架（MEC）框架，该框架通过量化预训练的嵌入方式来压缩嵌入表，而无需牺牲建议质量。我们的方法包括两个阶段：首先，我们将受欢迎程度加权的正则化来平衡高频和低频功能之间的代码分布。然后，我们整合了一种对比度学习机制，以确保量化代码的均匀分布，从而增强嵌入的独特性。三个数据集的实验表明，与现有模型相比，我们的方法在维持或改善建议性能的同时，将内存使用量减少了50倍以上。在我们的项目存储库中可以访问实现代码https://github.com/ustc-starteam/mec。]]></description>
      <guid>https://arxiv.org/abs/2502.15355</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缩放稀疏和密集检索仅解码器llms</title>
      <link>https://arxiv.org/abs/2502.15526</link>
      <description><![CDATA[ARXIV：2502.15526V1公告类型：新 
摘要：扩展大语言模型（LLMS）已显示出改善检索模型性能的巨大潜力；但是，先前的研究主要集中于经过对比损失（CL）训练的密集检索，忽略了其他检索范式和优化技术的缩放行为，例如稀疏的检索和知识蒸馏（KD）。在这项工作中，我们进行了一项系统的比较研究，以了解不同的检索范式（稀疏与密集）和微调目标（CL与KD与它们的组合）如何影响不同模型量表的检索性能。使用MSMARCO段落作为培训数据集，仅解码器的LLM（Llama-3系列：1B，3B，8B）和固定的计算预算，我们评估了对内域（MSMARCO，TREC，TREC DL）和 -  OUT-的各种培训配置域（贝尔）基准。我们的主要发现表明：（1）缩放行为仅在CL中显然出现，在CL中，较大的模型获得了显着的性能增长，而KD训练的模型显示出最小的改进，在1B，3B和8B尺度上表现相似。 （2）稀疏的检索模型在内域（MSMARCO，TREC DL）和不域外（Beir）基准测试方面始终超过了较高的检索，并且对不完美的监督信号表现出更大的鲁棒性。 （3）我们成功地扩展了稀疏的检索模型，其中Cl和KD损失在8B尺度上的结合，实现最新的（SOTA）会导致所有评估集。]]></description>
      <guid>https://arxiv.org/abs/2502.15526</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>审计的多峰模型和建议之间的桥接域间隙</title>
      <link>https://arxiv.org/abs/2502.15542</link>
      <description><![CDATA[ARXIV：2502.15542V1公告类型：新 
摘要：随着多模式含量在线的爆炸性增长，预训练的视觉语言模型已显示出多模式推荐的巨大潜力。但是，尽管这些模型在以冷冻方式应用时实现了不错的性能，但令人惊讶的是，由于较大的领域差距（例如，特征分配差异和任务目标错位）在预训练和个性化的建议之间，采用联合培训方法，而是导致绩效比基线更糟。现有方法要么依赖简单的功能提取，要么需要计算昂贵的完整模型微调，以平衡有效性和效率。为了应对这些挑战，我们提出\ textbf {p} arameter-forvity \ textbf {t} uning for \ textbf {m} ult-imodal \ textbf {rec textbf {rec} oumendation（\ textbf {ptmrec}），一个新颖的框架，是一个新颖的框架。通过知识引导的双阶段，在预训练的模型和推荐系统之间参数有效培训策略。该框架不仅消除了对昂贵的额外预训练的需求，而且还可以灵活地适应各种参数有效的调整方法。]]></description>
      <guid>https://arxiv.org/abs/2502.15542</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过LLMS在XR中取回跨格式检索生成，以进行上下文感知的维护援助</title>
      <link>https://arxiv.org/abs/2502.15604</link>
      <description><![CDATA[ARXIV：2502.15604V1公告类型：新 
摘要：本文介绍了对检索功能生成（RAG）系统的详细评估，该评估集成了大型语言模型（LLMS），以增强信息检索和指导生成，用于跨不同数据格式的维护人员。我们评估了八个LLM的性能，强调了关键指标，例如响应速度和准确性，这些指标是使用BLEU和流星评分进行了量化的。我们的发现表明，诸如GPT-4和GPT-4O-MINI之类的高级模型显着超过其对应的，尤其是在解决需要多格式数据集成的复杂查询时。结果验证了系统能够及时，准确的响应的能力，突出了抹布框架优化维护操作的潜力。未来的研究将着重于精炼这些模型的检索技术并增强响应生成，特别是对于复杂的场景，最终改善了该系统在动态现实世界环境中的实际适用性。]]></description>
      <guid>https://arxiv.org/abs/2502.15604</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态知识选择器和评估者，用于推荐使用知识图</title>
      <link>https://arxiv.org/abs/2502.15623</link>
      <description><![CDATA[ARXIV：2502.15623V1公告类型：新 
摘要：近年来，建议系统通常采用知识图提供的边缘信息，并结合了建议字段中图网络的高阶连接性的优势。但是，该方法受标签的稀疏性的限制，无法很好地学习图形结构，并且知识图中的许多嘈杂实体将影响建议结果的准确性。为了减轻上述问题，我们提出了一种由协作信号指导的动态知识选择和评估方法，以在知识图中提取信息。具体而言，我们使用链路线评估员来评估不同社区对建议任务的贡献，并采用知识选择器策略在评估之前过滤较少的信息知识。我们对三个公共数据集进行了基线模型比较和实验消融评估。实验表明，我们提出的模型的表现优于当前最新基线模型，并且通过消融实验证明了模型中的每个模块效率。]]></description>
      <guid>https://arxiv.org/abs/2502.15623</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索调查系统可能是危险的医疗通信者</title>
      <link>https://arxiv.org/abs/2502.14898</link>
      <description><![CDATA[ARXIV：2502.14898V1公告类型：交叉 
摘要：患者长期以来一直在网上寻求健康信息，并且越来越多，他们正在转向生成的AI来回答与健康相关的查询。鉴于医疗领域的高赌注，诸如检索型生成和引文接地等技术已被广泛促进，作为减少幻觉和提高AI生成反应的准确性的方法，并已被广泛采用到搜索引擎中。本文认为，即使这些方法从幻觉中汲取了从源文档中汲取的字面意义上的内容，它们仍然可能具有很大的误导。患者可能与阅读原始资料相比，患者可以从AI生成的产出明显不同，更不用说咨询知识渊博的临床医生了。通过对包括有争议的诊断和程序安全在内的主题的大规模查询分析，我们通过定量和定性的证据来支持我们的论点，证明了当前系统所产生的次优答案。特别是，我们强调了这些模型如何倾向于将事实降低，忽略关键的相关来源，并加强患者的误解或偏见。我们提出了一系列建议，例如融入沟通语用学和增强对源文件的理解 - 可以帮助减轻这些问题并超越医疗领域。]]></description>
      <guid>https://arxiv.org/abs/2502.14898</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Pathrag：基于图形的修剪检索增强产生</title>
      <link>https://arxiv.org/abs/2502.14902</link>
      <description><![CDATA[ARXIV：2502.14902V1公告类型：交叉 
摘要：通过从外部数据库中检索知识，检索增强的生成（RAG）改善了大语言模型（LLMS）的响应质量。典型的破布方法将文本数据库分为块，以平坦的结构组织它们以进行有效的搜索。为了更好地捕获整个文本数据库中固有的依赖关系和结构化关系，研究人员建议将文本信息组织到索引图中，基于Asgraph的抹布。但是，我们认为，当前基于图的抹布方法的局限性在于检索到的信息的冗余，而不是其不足。此外，以前的方法使用平坦的结构在提示中组织检索的信息，从而导致次优性能。为了克服这些局限性，我们提出了PathRag，该Pathrag从索引图中检索了关键的关系路径，并将这些路径转换为文本形式以提示LLM。具体而言，Pathrag通过基于流动的修剪有效地减少了冗余信息，同时指导LLMS通过基于路径的提示产生更合乎逻辑和相干的响应。实验结果表明，Pathrag始终在六个数据集和五个评估维度上胜过最先进的基线。该代码可在以下链接中找到：https：//github.com/bupt-gamma/pathrag]]></description>
      <guid>https://arxiv.org/abs/2502.14902</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenSearch-SQL：通过动态几次和一致性对齐来增强文本到SQL</title>
      <link>https://arxiv.org/abs/2502.14913</link>
      <description><![CDATA[ARXIV：2502.14913V1公告类型：交叉 
摘要：尽管多机构协作大语言模型（LLM）在文本到SQL任务中取得了重大突破，但它们的性能仍然受到各种因素的限制。这些因素包括框架不完整，未能遵循说明和模型幻觉问题。为了解决这些问题，我们提出了OpenSearch-SQL，将文本到SQL任务划分为四个主要模块：预处理，提取，生成和改进，以及基于一致性比对机制的对齐模块。该体系结构通过对齐模块对准代理的输入和输出，从而减少了随后的指令和幻觉的故障。此外，我们设计了一种称为SQL样的中间语言，并基于SQL样的结构化COT进行了优化。同时，我们以自学成才的查询-COT-SQL的形式制定了一种动态的几次策略。这些方法显着改善了文本到SQL任务中LLM的性能。
  在模型选择方面，我们直接应用了基本LLM，而无需任何后培训，从而简化了任务链并增强了框架的可移植性。实验结果表明，OpenSearch-SQL的执行精度（EX）为69.3％，在鸟类开发集中达到72.28％，基于奖励的有效性效率评分（R-VES）为69.36％，这三个为69.36％指标在提交时排名第一。这些结果证明了该方法在有效性和效率方面具有全面的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.14913</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>猛禽：产品表对象识别的精制方法</title>
      <link>https://arxiv.org/abs/2502.14918</link>
      <description><![CDATA[Arxiv：2502.14918V1公告类型：交叉 
摘要：从文档中提取表是各个行业的关键任务，尤其是在发票和报告等业务文件上。基于检测变压器（DETR）的现有系统，例如表变压器（TATR），提供表检测解决方案（TD）和表结构识别（TSR），但面临各种表格格式的挑战，以及诸如不正确的区域检测和重叠列之类的常见错误。这项研究介绍了Raptor，这是一种模块化后处理系统，旨在增强最新模型，以改善桌子提取，尤其是用于产品表。 Raptor解决了经常性的TD和TSR问题，改善了精度和结构预测。对于TD，我们使用DETR（在ICDAR 2019上接受了培训）和TATR（在PubTables-1M和Fintabnet上接受培训），而TSR仅依靠TATR。合并了一种遗传算法，以使用私人产品表来优化猛禽的模块参数，以满足工业需求。我们在两个私人数据集的私人数据集，公共温顺的数据集（包含与我们的目标产品表相似的表）以及ICDAR 2013和ICDAR 2019数据集中评估了我们的方法。结果表明，尽管我们的方法在产品表上表现出色，但它也保持了各种表格格式的合理性能。一项消融研究进一步验证了每个模块在我们系统中的贡献。]]></description>
      <guid>https://arxiv.org/abs/2502.14918</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检测实体的未来相关环境提到</title>
      <link>https://arxiv.org/abs/2502.15332</link>
      <description><![CDATA[Arxiv：2502.15332V1公告类型：交叉 
摘要：能够自动识别未来上下文中是否引用实体的能力可以具有多个应用程序，包括决策，计划和趋势预测。本文着重于检测以实体为中心文本中的隐性未来参考，以解决信息处理中对自动化时间分析的日益增长的需求。我们首先介绍了一个围绕来自Wikipedia的流行实体而建立的19,540个句子的新颖数据集，该句子由这些实体出现的未来相关和与未来相关的上下文组成。作为第二个贡献，我们评估了几种语言模型的性能，包括大型语言模型（LLMS）在没有明确的时间参考的情况下区分未来的内容的任务。]]></description>
      <guid>https://arxiv.org/abs/2502.15332</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>