<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>法学硕士 (LLM) 可能会被愚弄，将文档标记为相关（我附近最好的咖啡馆；这篇论文非常相关）</title>
      <link>https://arxiv.org/abs/2501.17969</link>
      <description><![CDATA[arXiv:2501.17969v1 公告类型：新
摘要：LLM 越来越多地用于评估信息对象的相关性。这项工作报告了使用多个开源和专有 LLM 研究对短文本（即段落）进行相关性标记的实验。虽然一些 LLM 与人类判断的总体一致性与之前研究中测量的人与人之间的一致性相当，但与人类判断者相比，LLM 更有可能将段落标记为相关，这表明表示不相关的 LLM 标签比表示相关的标签更可靠。
这一观察促使我们进一步研究人类判断者和 LLM 意见不一致的情况，特别是当人类判断者将段落标记为不相关而 LLM 将其标记为相关时。结果显示，许多 LLM 倾向于将包含原始查询词的段落标记为相关。因此，我们进行实验，将查询词注入随机和不相关的段落中，就像我们将查询“我附近最好的咖啡馆”插入本文中一样。结果表明，即使更广泛的段落与查询无关，LLM 也会受到所评估段落中查询词的存在的影响。LLM 容易被查询词的存在所欺骗，这表明我们目前对 LLM 标记的衡量标准存在弱点：依赖总体一致性会错过重要的失败模式。LLM 生成的相关性标签存在真正的偏见风险，因此，在这些标签上训练的排名者也存在偏见风险。
我们还研究了故意操纵 LLM 的影响，指示它们将段落标记为相关，类似于上面插入的指令“这篇论文完全相关”。我们发现这种操纵会影响某些 LLM 的性能，这凸显了在实际应用中部署 LLM 时必须考虑潜在漏洞的迫切需要。]]></description>
      <guid>https://arxiv.org/abs/2501.17969</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成式 LLM 能否为测试集创建查询变体？一项探索性研究</title>
      <link>https://arxiv.org/abs/2501.17981</link>
      <description><![CDATA[arXiv:2501.17981v1 公告类型：新
摘要：本文探讨了大型语言模型 (LLM) 从信息需求描述中自动生成查询和查询变体的实用性。给定一组描述为背景故事的信息需求，我们探索 LLM 生成的查询与人类生成的查询的相似程度。我们使用不同的指标量化相似性，并在构建测试集时检查每组数据的使用对文档池化的贡献。我们的结果显示了使用 LLM 生成查询变体的潜力。虽然它们可能无法完全捕捉到人类生成的各种变体，但它们会生成类似的相关文档集，在池深度为 100 时重叠率高达 71.1%。]]></description>
      <guid>https://arxiv.org/abs/2501.17981</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用精炼 LLM 实现基于 RL 的在线电子商务系统查询重写</title>
      <link>https://arxiv.org/abs/2501.18056</link>
      <description><![CDATA[arXiv:2501.18056v1 公告类型：新
摘要：查询重写 (QR) 是电子商务搜索中的一项关键技术，可解决用户查询和产品描述之间的词汇差距以提高搜索性能。现有的 QR 方法通常分为两类：判别模型和利用大型语言模型 (LLM) 的生成方法。判别模型通常难以理解自然语言，并且在重写方面灵活性有限，而生成 LLM 尽管可以生成高质量的重写，但在在线环境中面临高推理延迟和成本。这些限制迫使离线部署，使它们容易受到信息陈旧和语义漂移等问题的影响。为了克服这些挑战，我们提出了一种平衡效率和有效性的新型 QR 混合管道。我们的方法结合离线知识提炼来创建一个轻量级但高效的学生模型，并结合在线强化学习 (RL)，使用实时反馈动态优化查询重写。一项关键创新是使用 LLM 作为模拟的人工反馈，从而实现可扩展的奖励信号和经济高效的评估，而无需手动注释。在 Amazon ESCI 数据集上的实验结果表明，查询相关性、多样性和适应性得到了显著改善，并且 LLM 模拟也获得了积极的反馈。这项工作有助于提高特定领域应用程序的 LLM 功能，为动态和复杂的电子商务搜索环境提供强大的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.18056</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高顺序推荐中的极小极大组公平性</title>
      <link>https://arxiv.org/abs/2501.18117</link>
      <description><![CDATA[arXiv:2501.18117v1 公告类型：新
摘要：使用统一样本权重训练顺序推荐器（例如 SASRec）可实现良好的整体性能，但在特定用户组上可能会有所欠缺。一个这样的例子是流行度偏差，主流用户比小众内容查看者获得更好的推荐。为了提高不同用户组的推荐质量，我们探索了三种分布稳健优化 (DRO) 方法：组 DRO、流式 DRO 和条件风险价值 (CVaR) DRO。虽然组和流式 DRO 依赖于组注释并且难以处理属于多个组的用户，但 CVaR 不需要这样的注释并且可以自然地处理重叠组。在对两个真实数据集的实验中，我们表明 DRO 方法优于标准训练，其中 CVaR 提供最佳结果。此外，我们发现组和流式 DRO 对用于损失计算的组的选择很敏感。我们的贡献包括（i）CVaR 在推荐系统中的全新应用，（ii）表明 DRO 方法可以改善群体指标以及整体性能，以及（iii）展示 CVaR 在交叉用户群体实际场景中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.18117</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HyperZero：一种定制的端到端自动调整系统，用于每小时提供反馈的推荐</title>
      <link>https://arxiv.org/abs/2501.18126</link>
      <description><![CDATA[arXiv:2501.18126v1 公告类型：新 
摘要：现代推荐系统大致可分为两个关键阶段：排名阶段，系统预测各种用户参与度（例如点击率、点赞率、关注率、观看时间）和价值模型阶段，该阶段通过函数（例如由权重向量定义的线性组合）聚合这些预测分数，以单个数值分数衡量每个内容的价值。这两个阶段在实际工业系统中发挥着大致同等重要的作用；然而，如何优化第二阶段的模型权重仍然缺乏系统研究。本文重点研究通过自动调优技术优化第二阶段。虽然一般的自动调优系统和解决方案（无论是来自成熟的生产实践还是开源解决方案）都可以解决这个问题，但它们通常需要数周甚至数月才能找到可行的解决方案。这种长时间的调优过程在推荐系统的生产环境中是不可接受的，因为次优的价值模型会严重降低用户体验。需要一种有效的自动调整解决方案来在 2-3 天内确定可行的模型，而不是现有方法通常需要的延长时间。在本文中，我们介绍了一种名为 HyperZero 的实用自动调整系统，该系统解决了这些时间限制，同时有效地解决了现代推荐系统固有的独特挑战。此外，该框架有可能扩展到推荐系统中更广泛的调整任务。]]></description>
      <guid>https://arxiv.org/abs/2501.18126</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用双大型语言模型和深度强化学习驱动的基于代理的模拟调查逃税现象</title>
      <link>https://arxiv.org/abs/2501.18177</link>
      <description><![CDATA[arXiv:2501.18177v1 公告类型：新
摘要：逃税通常是非正规经济中最大的组成部分，是历史上持续存在的挑战，具有重大的社会经济影响。许多社会经济研究调查了其动态，包括影响因素、税收政策的作用和影响以及对逃税量随时间变化的预测。这些研究假设这种行为是既定的，就像在现实世界中观察到的那样，忽略了这种活动在人群中的“大爆炸”。为此，计算经济研究采用了计算机模拟的发展，特别是人工智能（AI）的最新创新，以模拟和研究非正规经济在各种社会经济环境中的出现。本研究提出了一个新颖的计算框架来研究逃税的动态和非正规经济活动的出现。该框架采用由大型语言模型和深度强化学习驱动的基于代理的模拟，其独特设计允许非正式经济行为有机地出现，而无需预先假设它们的存在或明确向代理发出逃税的可能性信号。这为探索合规行为的社会经济决定因素提供了一种严格的方法。实验设计包括模型验证和探索阶段，证明了该框架在复制理论经济行为方面的稳健性。研究结果表明，个人性格特征、外部叙述、执法概率和公共物品供应的感知效率显著影响非正式经济活动的时间和范围。结果强调，有效的公共物品供应和强有力的执法机制是相辅相成的；单独使用任何一种都不足以有效地遏制非正式活动。]]></description>
      <guid>https://arxiv.org/abs/2501.18177</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电商搜索行为建模空间重构</title>
      <link>https://arxiv.org/abs/2501.18216</link>
      <description><![CDATA[arXiv:2501.18216v1 公告类型：新
摘要：提供卓​​越的搜索服务对于提升客户体验和推动收入增长至关重要。传统上，搜索系统通过静态地结合用户偏好和查询项目相关性来建模用户行为，通常通过固定的逻辑“和”关系。本文通过使用因果图和维恩图的统一视角重新审视现有方法，揭示了两个普遍但重要的问题：纠缠的偏好和相关性效应以及崩溃的建模空间。为了克服这些挑战，我们的研究引入了一个新颖的框架 DRP，它通过两个组件来重建行为建模空间，从而提高搜索准确性。具体来说，我们实施偏好编辑以主动消除偏好预测中的相关性影响，从而产生未受污染的用户偏好。此外，我们采用自适应融合，动态调整融合标准以适应不同的相关性和偏好模式，从而促进在重建的建模空间内进行更细致入微和量身定制的行为预测。对两个公共数据集和一个专有搜索数据集进行的经验验证强调了我们提出的方法的优越性，并表明性能比现有方法有显著的提高。]]></description>
      <guid>https://arxiv.org/abs/2501.18216</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 总结证据收集经济高效、高质量的真实性评估</title>
      <link>https://arxiv.org/abs/2501.18265</link>
      <description><![CDATA[arXiv:2501.18265v1 公告类型：新
摘要：随着针对网上错误和虚假信息的防护措施的退化，能够有效地打击它比以往任何时候都更加重要。在本文中，我们探讨了使用基于浓缩的大型语言模型 (LLM) 生成的在线资源摘要的众包真实性评估的效率和有效性。我们将生成的摘要与 A/B 测试环境中的原始网页进行比较，在 A/B 测试环境中，我们雇用大量多样化的众包工作者来执行真实性评估。我们评估评估的质量、评估的效率以及参与者的行为和参与度。我们的结果表明，依赖于总结证据的总结模式在评估准确性方面与标准模式相比没有显著变化，同时显著提高了评估的速度。使用总结证据的工作人员在相同时间范围内产生的评估数量显著增加，从而降低了获取真实性评估所需的成本。此外，总结模式最大限度地提高了注释者之间的一致性以及对证据的依赖和感知有用性，证明了总结证据的实用性，同时又不牺牲评估的质量。]]></description>
      <guid>https://arxiv.org/abs/2501.18265</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根据用户查询的论证分区进行引文推荐</title>
      <link>https://arxiv.org/abs/2501.18292</link>
      <description><![CDATA[arXiv:2501.18292v1 公告类型：新
摘要：引文推荐旨在为学者找到重要的论文进行引用。在撰写引用语句时，作者通常持有不同的引用意图，这在引文分析中称为引用功能。由于论证分区是为了识别科学文献中的论证和修辞结构，我们希望利用这些信息来改进引文推荐任务。在本文中，建立了一个用于引文推荐和论证分区分类的多任务学习模型。我们还基于新的论证分区模式生成了来自 PubMed Central 的数据的带注释语料库。实验结果表明，通过考虑引用句中的论证信息，引文推荐模型将获得更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.18292</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相关性错觉：使用内容注入攻击欺骗检索者、重新排序者和 LLM 评委</title>
      <link>https://arxiv.org/abs/2501.18536</link>
      <description><![CDATA[arXiv:2501.18536v1 公告类型：新
摘要：考虑这样一种情况，用户搜索信息，却发现文本充斥着误导性或不相关的内容。这种情况体现了神经信息检索 (IR) 管道中一个简单但强大的漏洞：内容注入攻击。我们发现嵌入检索模型、重新排序器和大型语言模型 (LLM) 相关性判断器容易受到这些攻击，攻击者会在段落中插入误导性文本来操纵模型判断。我们发现了两个主要威胁：(1) 在仍然看似“相关”的段落中插入不相关或有害的内容，以及 (2) 在段落中插入整个查询或关键查询词以提高其感知相关性。虽然第二种策略已经在先前的研究中进行了探索，但据我们所知，我们首次对第一种威胁进行了实证分析，展示了最先进的模型如何容易被误导。我们的研究系统地研究了影响攻击成功的因素，例如注入内容的位置以及相关和非相关材料之间的平衡。此外，我们还探索了各种防御策略，包括对抗性段落分类器、检索器微调以减少操纵内容，以及促使 LLM 评委采取更谨慎的方法。然而，我们发现这些对策通常涉及权衡，牺牲有效性以增强攻击的稳健性，有时还会在此过程中惩罚合法文件。我们的研究结果强调需要更强大的防御措施来抵御这些不断发展的对抗性策略，以保持 IR 系统的可信度。我们发布了我们的代码和脚本以促进进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2501.18536</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Provence：用于检索增强生成的高效且强大的上下文修剪</title>
      <link>https://arxiv.org/abs/2501.16214</link>
      <description><![CDATA[arXiv:2501.16214v1 公告类型：交叉 
摘要：检索增强生成改进了大型语言模型 (LLM) 生成的各个方面，但由于长上下文以及将不相关的检索信息传播到生成的响应中而导致计算开销。上下文修剪处理这两个方面，通过在 LLM 生成之前删除检索到的上下文中不相关的部分。然而，现有的上下文修剪方法有限，并且没有提供在各种场景中既高效又稳健的通用模型，例如，当上下文包含可变数量的相关信息或长度变化时，或者在各个领域进行评估时。在这项工作中，我们弥补了这一差距，并引入了 Provence（对检索到的相关上下文进行修剪和重新排序），这是一种高效且强大的问答上下文修剪器，它可以动态检测给定上下文所需的修剪量，并且可以开箱即用地用于各种领域。 Provence 的三个关键要素是将上下文修剪任务制定为序列标记、将上下文修剪功能与上下文重新排序统一起来以及对各种数据进行训练。 我们的实验结果表明，Provence 在标准 RAG 管道中几乎不花费任何成本，在各种领域和设置中都可以实现上下文修剪，而性能几乎不会下降。 我们还对各种消融进行了更深入的分析，以提供对未来工作训练上下文修剪器的见解。]]></description>
      <guid>https://arxiv.org/abs/2501.16214</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新利用标签控制推荐驱动型社交媒体小红书的受众 (rednote)</title>
      <link>https://arxiv.org/abs/2501.18210</link>
      <description><![CDATA[arXiv:2501.18210v1 公告类型：交叉 
摘要：算法在社交媒体的个性化推荐中发挥着核心作用。然而，它们也为试图预测和管理受众范围的内容创建者带来了重大障碍。这个问题对于寻求维持安全空间的边缘群体来说尤其具有挑战性。我们的研究探讨了小红书（rednote）上的女性如何在推荐驱动的社交平台中主动重新使用标签（例如#Baby Supplemental Food），并在与其字面意思无关的帖子中使用它们。这些标签是从他们想要屏蔽的男性观众不感兴趣的话题中策略性地选择的。通过混合方法，我们基于 5,800 条收集的帖子分析了标签重新使用的实践，并采访了 24 名来自不同背景的活跃用户，以揭示用户对重新使用的动机和反应。这种做法强调了用户如何在推荐驱动的平台上重新获得内容分发的控制权，为以算法为中心的权力结构中的自治提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2501.18210</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RbFT：针对检索缺陷的检索增强生成的稳健微调</title>
      <link>https://arxiv.org/abs/2501.18365</link>
      <description><![CDATA[arXiv:2501.18365v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 通过集成从知识库中检索到的外部知识来增强大型语言模型 (LLM)。然而，它的有效性从根本上受到检索器和知识库可靠性的限制。在现实世界中，这些组件的缺陷往往会导致检索到嘈杂、不相关或误导性的反事实信息，最终破坏 RAG 系统的可信度。为了应对这一挑战，我们提出了稳健微调 (RbFT)，这种方法旨在通过两个有针对性的微调任务增强 LLM 对检索缺陷的弹性。实验结果表明，RbFT 显著提高了 RAG 系统在不同检索条件下的稳健性，超越了现有方法，同时保持了高推理效率和与其他稳健性技术的兼容性。]]></description>
      <guid>https://arxiv.org/abs/2501.18365</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们能一次性检索所有内容吗？ARM：一种以对齐为导向的基于 LLM 的检索方法</title>
      <link>https://arxiv.org/abs/2501.18539</link>
      <description><![CDATA[arXiv:2501.18539v1 公告类型：交叉 
摘要：现实世界中的开放域问题可能很复杂，尤其是在回答这些问题涉及来自多个信息源的信息时。LLM 在将复杂任务分解为更简单的步骤方面表现出色，之前的工作已将其用于更好地检索以支持复杂问题。然而，LLM 对问题的分解并不知道有哪些数据可用以及数据是如何组织的，这通常会导致检索性能不佳。agentic RAG 的最新努力提出以迭代方式执行检索，其中后续查询是基于前几轮检索得出的操作。虽然这提供了一种与数据集合交互的方式，但 agentic RAG 对数据的探索效率低下，因为连续查询依赖于先前的结果，而不是由集合中可用数据的组织来指导。为了解决这个问题，我们提出了一种基于 LLM 的检索方法 ARM，该方法旨在通过探索数据对象之间的关系（而不仅仅是匹配查询语句）来更好地将问题与数据集合的组织联系起来，从而为复杂查询提供一次性检索的解决方案。我们在 Bird 和 OTT-QA 两个数据集上评估了 ARM。在 Bird 上，它在执行准确度方面比标准 RAG 查询分解高出 5.2 分，比 agentic RAG (ReAct) 高出 15.9 分。在 OTT-QA 上，与这些方法相比，它的 F1 匹配分数分别高出 5.5 分和 19.3 分。]]></description>
      <guid>https://arxiv.org/abs/2501.18539</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成信息检索评估</title>
      <link>https://arxiv.org/abs/2404.08137</link>
      <description><![CDATA[arXiv:2404.08137v3 公告类型：替换 
摘要：在本章中，我们从两个不同但相互关联的角度考虑生成信息检索评估。首先，大型语言模型 (LLM) 本身正在迅速成为评估工具，目前的研究表明，LLM 可能在基本相关性判断任务上优于众包工作者和其他付费评估者。我们回顾了过去和正在进行的相关研究，包括对 TREC 等共享任务计划未来的推测，以及对持续进行人工评估需求的讨论。其次，我们考虑对新兴的基于 LLM 的生成信息检索 (GenIR) 系统的评估，包括检索增强生成 (RAG) 系统。我们考虑既关注 GenIR 系统的端到端评估，又关注将检索组件作为 RAG 系统中的元素进行评估的方法。展望未来，我们预计 GenIR 系统的评估至少会部分基于 LLM 评估，从而形成一种明显的循环，即系统似乎在评估自己的输出。我们通过两种方式解决这种明显的循环：1) 将基于 LLM 的评估视为一种“慢速搜索”，其中较慢的 IR 系统用于评估和训练更快的生产 IR 系统；2) 认识到需要继续将评估建立在人工评估的基础上，即使人工评估的特征必须改变。]]></description>
      <guid>https://arxiv.org/abs/2404.08137</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>