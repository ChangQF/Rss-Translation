<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 11 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用推荐系统减少同行制作平台上的内容差距</title>
      <link>https://arxiv.org/abs/2307.08669</link>
      <description><![CDATA[arXiv:2307.08669v4 公告类型：replace-cross
摘要：像维基百科这样的同行生产平台通常会遇到内容差距的问题。先前的研究表明，推荐系统可以通过引导编辑关注代表性不足的主题来帮助解决这个问题。然而，目前尚不清楚这种方法是否会导致推荐的相关性降低，从而导致推荐项目的整体参与度降低。为了回答这个问题，我们首先对 SuggestBot（维基百科的任务路由推荐系统）进行了离线分析（研究 1），然后进行了为期三个月的对照实验（研究 2）。我们的结果表明，向用户展示代表性不足的主题的文章可以增加这些文章的工作比例，而不会显着降低整体推荐的采用率。我们讨论了我们的结果的含义，包括忽略文章发现过程如何人为地缩小同行生产平台上的推荐范围。]]></description>
      <guid>https://arxiv.org/abs/2307.08669</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>YAGO 4.5：一个庞大、干净、分类丰富的知识库</title>
      <link>https://arxiv.org/abs/2308.11884</link>
      <description><![CDATA[arXiv:2308.11884v2 公告类型：replace-cross
摘要：知识库（KB）在许多知识密集型任务中都有应用，尤其是在信息检索中。维基数据是最大的公共通用知识库之一。然而，其协作性质导致了复杂的模式和分类。 YAGO 4 KB 通过合并 Schema.org 的本体来清理分类法，从而产生适合自动推理的更清晰的结构。然而，它也删除了维基数据分类的大部分内容，而这对于信息检索至关重要。在本文中，我们使用维基数据分类法的很大一部分扩展了 YAGO 4 - 同时尊重逻辑约束以及类和实例之间的区别。这就产生了 YAGO 4.5，这是一个新的、逻辑上一致的 YAGO 版本，添加了丰富的信息类层。内在和外在评估显示了新资源的价值。]]></description>
      <guid>https://arxiv.org/abs/2308.11884</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>CaseLink：用于法律案例检索的归纳图学习</title>
      <link>https://arxiv.org/abs/2403.17780</link>
      <description><![CDATA[arXiv:2403.17780v2 公告类型：替换
摘要： 在判例法中，先例是用来支持法官对某一案件作出的判决和律师意见的相关案例。这种相关性被称为个案参考关系。为了从庞大的案例库中高效地查找相关案例，检索工具被法律从业者广泛使用。现有的法律案例检索模型主要通过比较个案的文本表示来工作。尽管它们获得了不错的检索精度，但案例之间内在的案例连接关系尚未得到很好的利用来进行案例编码，因此限制了检索性能的进一步提高。案件池中存在三种案件关联关系：案件引用关系、案件语义关系、案件法律指控关系。由于法律案例检索任务中的归纳方式，使用案例参考作为输入不适用于测试。因此，本文提出了一种基于归纳图学习的 CaseLink 模型，利用案件内在的连通性进行法律案件检索，并采用新颖的全局案件图来表示案件语义关系和案件法律指控关系。提出了一种新颖的对案例节点度进行正则化的对比目标，以利用案例参考关系携带的信息来优化模型。我们在两个基准数据集上进行了广泛的实验，证明了 CaseLink 的最先进的性能。代码已发布于https://github.com/yanran-tang/CaseLink。]]></description>
      <guid>https://arxiv.org/abs/2403.17780</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>生成 IR 评估方法的比较</title>
      <link>https://arxiv.org/abs/2404.04044</link>
      <description><![CDATA[arXiv:2404.04044v2 公告类型：替换
摘要：信息检索系统越来越多地包含生成组件。例如，在检索增强生成（RAG）系统中，检索组件可能提供基本事实来源，而生成组件则总结并增强其响应。在其他系统中，大型语言模型 (LLM) 可能会直接生成响应，而无需咨询检索组件。虽然生成信息检索（Gen-IR）系统有多种定义，但在本文中，我们重点关注那些系统响应不是从固定的文档或段落集合中提取的系统。对查询的响应可能是全新的文本。由于传统的 IR 评估方法在该模型下失效，因此我们探索了将传统离线评估方法扩展到 Gen-IR 环境的各种方法。离线 IR 评估传统上采用付费人工评估员，但越来越多的法学硕士正在取代人工评估，展示出与众包标签相似或优于众包标签的能力。鉴于 Gen-IR 系统不会从固定的集合中生成响应，我们假设 Gen-IR 评估方法必须在很大程度上依赖于 LLM 生成的标签。除了基于二元和分级相关性的方法之外，我们还探索基于显式子主题、成对偏好和嵌入的方法。我们首先根据几个 TREC Deep Learning Track 任务的人类评估来验证这些方法；然后我们应用这些方法来评估几个纯生成系统的输出。对于每种方法，我们都考虑其自主行动的能力（无需人工标签或其他输入）以及支持人工审核的能力。要信任这些方法，我们必须确信它们的结果与人类评估一致。为此，评估标准必须透明，以便评估人员可以对结果进行审核。]]></description>
      <guid>https://arxiv.org/abs/2404.04044</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>从以模型为中心到以人为中心：修订距离作为法学硕士应用程序中文本评估的指标</title>
      <link>https://arxiv.org/abs/2404.07108</link>
      <description><![CDATA[arXiv:2404.07108v1 公告类型：交叉
摘要：评估大型语言模型（LLM）是基础，特别是在实际应用中。传统的评估方法通常主要为法学硕士开发而设计，产生的数字分数忽略了用户体验。因此，在人工智能驱动的写作辅助应用程序中，我们的研究重点从以模型为中心的评估转向以人为中心的评估。我们提出的指标称为“修订距离”，利用法学硕士来建议模仿人类写作过程的修订编辑。它是通过计算法学硕士生成的修订编辑来确定的。受益于生成的修订编辑详细信息，我们的指标可以以人类可理解的方式提供不言自明的文本评估结果，超越上下文无关的分数。我们的结果表明，对于简单的写作任务，“修订距离”与既定指标（ROUGE、Bert 分数和 GPT 分数）一致，但提供了更有洞察力、更详细的反馈并更好地区分文本。此外，在具有挑战性的学术写作任务的背景下，我们的指标仍然可以提供可靠的评估，而其他指标往往难以做到这一点。此外，我们的指标对于缺乏参考文本的场景也具有巨大的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.07108</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐系统的 Ripple 知识图卷积网络</title>
      <link>https://arxiv.org/abs/2305.01147</link>
      <description><![CDATA[arXiv:2305.01147v2 公告类型：替换
摘要：利用知识图谱辅助深度学习模型进行推荐决策，最近被证明可以有效提高模型的可解释性和准确性。本文介绍了一种名为 RKGCN 的端到端深度学习模型，该模型动态分析每个用户的偏好并推荐合适的商品。它将项目侧和用户侧的知识图谱结合起来，丰富其表示形式，最大限度地利用知识图谱中的丰富信息。 RKGCN能够在三种不同场景下提供更加个性化和相关的推荐。实验结果表明，我们的模型在电影、书籍和音乐等三个现实世界数据集上的有效性优于 5 个基线模型。]]></description>
      <guid>https://arxiv.org/abs/2305.01147</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>预训练的顺序推荐框架：零样本传输的流行度动态</title>
      <link>https://arxiv.org/abs/2401.01497</link>
      <description><![CDATA[arXiv:2401.01497v2 公告类型：替换
摘要：顺序推荐器对于在线应用程序的成功至关重要，例如电子商务、视频流和社交媒体。虽然模型架构不断改进，但对于每个新的应用领域，我们仍然需要从头开始训练新模型以获得高质量的推荐。另一方面，预训练的语言和视觉模型在零样本或少量样本适应新应用领域方面取得了巨大成功。受同行人工智能领域预训练模型成功的启发，我们提出了一种新颖的预训练序列推荐框架：PrepRec。我们通过对项目流行度动态建模来学习通用项目表示。通过对五个真实世界数据集的广泛实验，我们表明，在没有任何辅助信息的情况下，PrepRec 不仅可以零样本迁移到新领域，而且与仅使用最先进的序列推荐模型相比，还可以实现具有竞争力的性能模型大小的一小部分。此外，通过简单的事后插值，PrepRec 可以将现有顺序推荐器的性能在 Recall@10 中平均提高 13.8%，在 NDCG@10 中提高 29.5%。我们在 https://anonymous.4open.science/r/PrepRec--2F60/ 上提供了 PrepRec 的匿名实现]]></description>
      <guid>https://arxiv.org/abs/2401.01497</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>米尔格拉姆在知识空间中的实验：个体导航策略</title>
      <link>https://arxiv.org/abs/2404.06591</link>
      <description><![CDATA[arXiv:2404.06591v1 公告类型：交叉
摘要：我们这个时代的数据洪流特征导致了信息过载，对有效地在数字环境中找到出路构成了重大挑战。解决这个问题需要深入了解我们如何浏览大量信息。先前的研究已经发现了个体在地理、社会和信息空间中导航的多种模式，但在知识空间中导航策略的个体差异在很大程度上仍未得到探索。为了弥补这一差距，我们进行了一项在线实验，参与者在维基百科上玩导航游戏并完成有关其个人信息的调查问卷。利用在英语维基百科上训练的图形嵌入，我们的研究确定了参与者采用的独特策略：当目标是名人时，参与者通常使用目标的地理和职业信息进行导航，让人想起中心驱动和邻近驱动分别接近。我们发现，玩同一游戏的许多参与者表现出“群体智慧”效应：这组策略对目标周围的信息景观提供了良好的估计，表明个体差异是相互补充的。]]></description>
      <guid>https://arxiv.org/abs/2404.06591</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>图思维链：通过图推理增强大型语言模型</title>
      <link>https://arxiv.org/abs/2404.07103</link>
      <description><![CDATA[arXiv:2404.07103v1 公告类型：交叉
摘要：大型语言模型（LLM）虽然表现出卓越的性能，但也存在幻觉，尤其是在知识密集型任务上。现有的工作建议用从外部知识语料库检索到的单个文本单元来增强法学硕士，以缓解这个问题。然而，在许多领域，文本是相互关联的（例如，书目图中的学术论文通过引文和共同作者链接），形成（文本属性）图。此类图中的知识不仅编码在单个文本/节点中，而且还编码在它们的关联连接中。为了促进用图增强法学硕士的研究，我们手动构建了一个名为 GRBench 的图推理基准数据集，其中包含 1,740 个问题，可以用 10 个领域图的知识来回答。然后，我们提出了一个简单而有效的框架，称为图思想链（Graph-CoT），通过鼓励法学硕士在图上迭代推理，用图来增强法学硕士。每个 Graph-CoT 迭代都包含三个子步骤：LLM 推理、LLM-图交互和图执行。我们在 GRBench 上使用三个 LLM 主干进行系统实验，其中 Graph-CoT 始终优于基线。代码可在 https://github.com/PeterGriffinJin/Graph-CoT 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07103</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>集合编码器：使用交叉编码器进行列表式段落重排序的排列不变段落间注意</title>
      <link>https://arxiv.org/abs/2404.06912</link>
      <description><![CDATA[arXiv:2404.06912v1 公告类型：新
摘要：交叉编码器是有效的段落重新排序器。但是，当一次对多个段落重新排序时，现有的交叉编码器无法有效地优化多个输入排列的输出排序，因为它们的段落交互不是排列不变的。此外，它们的高内存占用限制了列表训练期间的段落数量。为了解决这些问题，我们提出了 Set-Encoder，这是一种新的交叉编码器架构，它（1）通过并行通道处理引入通道间注意，以确保输入通道之间的排列不变性，并且（2）使用融合注意内核来一次可以进行更多段落的训练。在 TREC 深度学习和 TIREx 的实验中，Set-Encoder 比之前参数数量相似的交叉编码器更有效。与较大的模型相比，Set-Encoder 效率更高，并且达到同等水平甚至更有效。]]></description>
      <guid>https://arxiv.org/abs/2404.06912</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>Quati：来自母语人士的巴西葡萄牙语信息检索数据集</title>
      <link>https://arxiv.org/abs/2404.06976</link>
      <description><![CDATA[arXiv:2404.06976v1 公告类型：新
摘要：尽管葡萄牙语是世界上使用最广泛的语言之一，但该语言缺乏高质量的信息检索数据集。我们推出了 Quati，一个专门为巴西葡萄牙语设计的数据集。它包含由母语人士提出的一系列查询以及来自精选优质巴西葡萄牙语网站的一组精选文档。与随机抓取的网站相比，这些网站更有可能被真实用户经常访问，从而确保语料库更具代表性和相关性。为了标记查询-文档对，我们使用最先进的法学硕士，它显示注释者间的一致性水平与我们评估中的人类表现相当。我们提供了注释方法的详细描述，使其他人能够为其他语言创建类似的数据集，从而提供一种经济有效的方式来创建高质量的 IR 数据集，每个查询具有任意数量的标记文档。最后，我们评估各种开源和商业检索器作为基线系统。 Quati 可在 https://huggingface.co/datasets/unicamp-dl/quati 上公开获取，所有脚本可在 https://github.com/unicamp-dl/quati 上获取。]]></description>
      <guid>https://arxiv.org/abs/2404.06976</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>TransTARec：用于下一个 POI 推荐的时间自适应翻译嵌入模型</title>
      <link>https://arxiv.org/abs/2404.07096</link>
      <description><![CDATA[arXiv:2404.07096v1 公告类型：新
摘要：位置获取技术的快速发展使得由于冗余的用户签到记录而导致的兴趣点（POI）推荐成为可能。在本文中，我们关注下一个 POI 推荐，其中下一个 POI 是基于前一个 POI 的。我们观察到时间在下一个 POI 推荐中起着重要作用，但在最近提出的翻译嵌入方法中被忽略了。为了解决这一不足，我们提出了一种用于下一个 POI 推荐的时间自适应翻译嵌入模型 (TransTARec)，该模型自然地将时间影响、顺序动态和用户偏好合并到单个组件中。在方法上，我们将（前一个时间戳、用户、下一个时间戳）三元组视为联合翻译向量，并开发基于神经的融合操作来融合用户偏好和时间影响。 TransTARec 的优越性已通过对现实世界数据集的大量实验得到证实，它不仅来自时间影响的引入，还来自与用户偏好和顺序动态的直接统一。]]></description>
      <guid>https://arxiv.org/abs/2404.07096</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>CaDRec：情境化和去偏推荐模型</title>
      <link>https://arxiv.org/abs/2404.06895</link>
      <description><![CDATA[arXiv:2404.06895v1 公告类型：新
摘要：旨在挖掘用户行为模式的推荐模型作为日常生活中的重要应用之一引起了人们的广泛关注。最近关于图神经网络（GNN）或去偏方法的工作取得了显着的成果。然而，它们仍然面临（1）由 GNN 递归卷积引起的过度平滑节点嵌入，以及（2）由于流行度和用户个人偏差而导致的交互分布的倾斜。本文提出了一种情境化和去偏的推荐模型（CaDRec）。为了克服过度平滑问题，我们探索了一种新颖的超图卷积算子，它可以通过引入结构上下文和顺序上下文在卷积过程中选择有效的邻居。为了解决倾斜分布，我们提出了两种解开交互的策略：（1）对个体偏差进行建模以学习无偏差的项目嵌入，以及（2）将项目流行度与位置编码相结合。此外，我们从数学上表明，更新项目嵌入的梯度不平衡会加剧流行度偏差，因此采用正则化和加权方案作为解决方案。对四个数据集的广泛实验证明了 CaDRec 相对于最先进的 (SOTA) 方法的优越性。我们的源代码和数据发布在https://github.com/WangXFng/CaDRec。]]></description>
      <guid>https://arxiv.org/abs/2404.06895</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>NFARec：负反馈感知推荐模型</title>
      <link>https://arxiv.org/abs/2404.06900</link>
      <description><![CDATA[arXiv:2404.06900v1 公告类型：新
摘要：基于图神经网络（GNN）的模型在推荐方面已被广泛研究，因为它们可以准确地提取高质量推荐系统所需的高阶协作信号。然而，他们在两个方面忽略了通过负反馈获得的有价值的信息：（1）不同的用户可能对同一项目持有相反的反馈，这阻碍了 GNN 中的最佳信息传播；（2）即使项目与用户的想法有很大偏差偏好，他们可能仍然会选择它并提供负面评价。在本文中，我们提出了一种负反馈感知推荐模型（NFARec），可以最大限度地利用负反馈。为了沿着最佳路径有效地将信息传输到多跳邻居，NFARec 采用反馈感知相关性来指导超图卷积（HGC）学习用户的结构表示。此外，NFARec 还包含一项辅助任务——基于 Transformer Hawkes Process 预测下一次交互的反馈情绪极性（即积极或消极）。该任务通过学习用户之前的顺序反馈模式中表达的情绪并预测未来的交互，有利于理解用户。大量实验表明，NFARec 的性能优于竞争基线。我们的源代码和数据发布在https://github.com/WangXFng/NFARec。]]></description>
      <guid>https://arxiv.org/abs/2404.06900</guid>
      <pubDate>Thu, 11 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    </channel>
</rss>