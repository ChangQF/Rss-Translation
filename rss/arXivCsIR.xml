<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 19 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于用户响应预测的时间兴趣网络</title>
      <link>https://arxiv.org/abs/2308.08487</link>
      <description><![CDATA[arXiv:2308.08487v2 公告类型：替换
摘要：用户响应预测在工业推荐系统（例如在线展示广告）中至关重要。在推荐模型的所有特征中，用户行为是最关键的。许多研究表明，由于行为与候选项目之间的语义或时间相关性，用户的行为反映了她对候选项目的兴趣。虽然文献已经单独研究了这些相关性，但研究人员尚未对它们进行组合分析，即语义-时间相关性。我们凭经验测量这种相关性并观察直观而稳健的模式。然后，我们检查了几种流行的用户兴趣模型，令人惊讶的是，它们都没有很好地学习这种相关性。
  为了填补这一空白，我们提出了一个时间兴趣网络（TIN）来同时捕获行为和目标之间的语义时间相关性。除了语义编码之外，我们还通过结合目标感知时间编码来表示行为和目标来实现这一目标。此外，我们通过部署目标感知注意力和目标感知表示来捕获语义和时间相关性，从而进行显式的四向交互。我们对两个流行的公共数据集进行了综合评估，我们提出的 TIN 在 GAUC 上分别比表现最好的基线高出 0.43% 和 0.29%。在腾讯广告平台的在线 A/B 测试中，TIN 较基础模型实现了 1.65% 的成本提升和 1.93% 的 GMV 提升。自2023年10月起已成功部署在生产环境中，服务微信朋友圈流量。我们已在 https://github.com/zhongxy1003/TIN 发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2308.08487</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的顺序推荐的注意力校准</title>
      <link>https://arxiv.org/abs/2308.09419</link>
      <description><![CDATA[arXiv:2308.09419v2 公告类型：替换
摘要：基于 Transformer 的顺序推荐（SR）近年来蓬勃发展，其关键组成部分是自注意力机制。人们普遍认为，自注意力能够通过学习这些项目的更大注意力权重，从一系列交互的项目中有效地选择那些信息丰富且相关的项目，以进行下一个项目的预测。然而，现实情况可能并不总是如此。我们对一些具有代表性的基于 Transformer 的 SR 模型的实证分析表明，将较大的注意力权重分配给相关性较低的项目并不罕见，这可能会导致推荐不准确。通过进一步深入分析，我们发现可能导致注意力权重分配不准确的两个因素：次优位置编码和噪声输入。为此，在本文中，我们的目标是解决现有工作中这一重大但具有挑战性的差距。具体来说，我们提出了一个简单而有效的框架，称为基于变压器的顺序推荐的注意力校准（AC-TSR）。在AC-TSR中，分别设计了一种新颖的空间校准器和对抗性校准器来直接校准那些错误分配的注意力权重。前者旨在明确捕获项目之间的空间关系（即顺序和距离），以便更精确地计算注意力权重。后者旨在根据每个项目对下一个项目预测的贡献来重新分配注意力权重。 AC-TSR 适应性强，可以无缝集成到各种现有的基于变压器的 SR 模型中。对四个基准真实世界数据集的广泛实验结果通过显着的推荐性能增强证明了我们提出的 ACTSR 的优越性。源代码可在 https://github.com/AIM-SE/AC-TSR 获取。]]></description>
      <guid>https://arxiv.org/abs/2308.09419</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>NineRec：用于评估可转移推荐的基准数据集套件</title>
      <link>https://arxiv.org/abs/2309.07705</link>
      <description><![CDATA[arXiv:2309.07705v3 公告类型：替换
摘要：大型基础模型通过上游预训练和下游微调，由于模型性能的提高和重复工程的显着减少，在广泛的人工智能社区中取得了巨大的成功。相比之下，推荐系统领域中的可迁移的一劳永逸模型（称为 TransRec）取得的进展有限。 TransRec的发展遇到了多重挑战，其中缺乏大规模、高质量的迁移学习推荐数据集和基准套件是最大的障碍之一。为此，我们引入了 NineRec，一个 TransRec 数据集套件，它包含一个大规模源域推荐数据集和九个不同的目标域推荐数据集。 NineRec 中的每个项目都附有描述性文本和高分辨率封面图像。利用 NineRec，我们通过学习原始多模态特征来实现 TransRec 模型，而不是仅仅依赖于预先提取的现成特征。最后，我们通过几种经典网络架构展示了强大的 TransRec 基准测试结果，为该领域提供了宝贵的见解。为了促进进一步的研究，我们将在 https://github.com/westlake-repl/NineRec 发布我们的代码、数据集、基准测试和排行榜。]]></description>
      <guid>https://arxiv.org/abs/2309.07705</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>Sheaf4Rec：用于基于图的推荐系统的 Sheaf 神经网络</title>
      <link>https://arxiv.org/abs/2304.09097</link>
      <description><![CDATA[arXiv:2304.09097v3 公告类型：替换
摘要：图神经网络（GNN）的最新进展促进了其在包括推荐系统在内的各种应用中的广泛采用。事实证明，GNN 可以通过对图进行有效建模来有效解决推荐系统带来的挑战，其中节点表示用户或项目，边表示偏好关系。然而，当前的 GNN 技术通过单个静态向量来表示节点，这可能不足以捕获用户和项目的复杂复杂性。为了克服这些限制，我们提出了一种集成受类别理论启发的尖端模型的解决方案：Sheaf4Rec。与单向量表示不同，层神经网络及其相应的拉普拉斯算子使用向量空间表示每个节点（和边）。我们的方法利用了这一理论，产生了更全面的表示，可以在推理过程中有效地利用，提供了一种适用于各种图形相关任务的通用方法，并展示了无与伦比的性能。我们提出的模型在 F1-Score@10 上表现出高达 8.53% 的显着相对改进，在 NDCG@10 上表现出高达 11.29% 的令人印象深刻的增长，优于现有的最先进模型，例如神经图协同过滤（ NGCF）、KGTORe 和其他最近开发的基于 GNN 的模型。除了卓越的预测能力之外，Sheaf4Rec 在效率方面也显示出显着的改进：与其他基于 GNN 的竞争对手模型相比，我们观察到运行时间大幅提高，范围从 2.5% 到 37%，这表明在实现更好的性能。代码可在 https://github.com/antoniopurificato/Sheaf4Rec 获取。]]></description>
      <guid>https://arxiv.org/abs/2304.09097</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>我们的模型在 MovieLens 上取得了出色的性能：这意味着什么？</title>
      <link>https://arxiv.org/abs/2307.09985</link>
      <description><![CDATA[arXiv:2307.09985v2 公告类型：替换
摘要：推荐系统（RecSys）评估的典型基准数据集由平台上在一段时间内生成的用户-项目交互组成。交互生成机制部分解释了用户为何与某个项目交互（例如，点赞、购买、评分），以及特定交互发生时的上下文。在本研究中，我们对 MovieLens 数据集进行了细致的分析，并解释了使用该数据集评估推荐算法的潜在影响。我们从分析中得出了一些主要发现。首先，用户与MovieLens平台交互的不同阶段的用户交互存在显着差异。早期的交互很大程度上定义了用户画像，影响了后续的交互。其次，用户交互很大程度上受到平台内部推荐算法推荐的候选电影的影响。删除接近用户最后几次交互发生的交互会导致学习用户偏好的难度增加，从而降低推荐准确性。第三，改变用户交互的顺序使得顺序算法更难捕获渐进的交互过程。基于这些发现，我们进一步讨论了 MovieLens 系统采用的交互生成机制与典型的现实世界推荐场景之间的差异。总之，在 MovieLens 数据集上实现出色推荐准确度的模型在实践中可能无法表现出至少两种差异的卓越性能：（i）用户-项目交互生成上下文中的差异，以及（ii）用户对项目集合的了解。]]></description>
      <guid>https://arxiv.org/abs/2307.09985</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>与未标记的悬空案例的实体对齐</title>
      <link>https://arxiv.org/abs/2403.10978</link>
      <description><![CDATA[arXiv:2403.10978v1 公告类型：交叉
摘要：我们研究了未标记悬空情况下的实体对齐问题，这意味着源图中存在实体或目标图中没有对应的实体，并且这些实体保持未标记状态。当源图和目标图的尺度不同时，就会出现问题，并且标记可匹配对比标记悬空实体要便宜得多。为了解决这个问题，我们提出了一种新颖的基于 GNN 的悬挂检测和实体对齐框架。虽然这两个任务共享相同的 GNN 并一起训练，但检测到的悬空实体在对齐中被删除。我们的框架的特点是设计了实体和关系注意机制，用于表示学习中的选择性邻域聚合，以及用于对悬挂实体进行无偏估计的正未标记学习损失。实验结果表明，我们设计的每个组件都对总体对齐性能做出了贡献，该性能与基线相当或优于基线，即使基线另外还有 30% 的悬挂实体标记为训练数据。]]></description>
      <guid>https://arxiv.org/abs/2403.10978</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>多行为推荐中公平性的因果干预</title>
      <link>https://arxiv.org/abs/2209.04589</link>
      <description><![CDATA[arXiv:2209.04589v2 公告类型：替换
摘要：推荐系统通常从各种用户行为中学习用户兴趣，包括点击和点击后行为（例如点赞和收藏）。然而，这些行为不可避免地表现出受欢迎度偏差，从而导致一些不公平问题：1）对于质量相似的商品，更受欢迎的商品获得更多的曝光； 2）更糟糕的是，人气较低的热门商品可能会获得更多曝光。现有的减轻流行度偏差的工作盲目地消除了偏差，并且通常忽略了项目质量的影响。我们认为不同用户行为之间的关系（例如转化率）实际上反映了项目质量。因此，为了解决不公平问题，我们建议通过考虑多种用户行为来减轻流行度偏差。
  在这项工作中，我们研究了多行为推荐中交互生成过程背后的因果关系。具体来说，我们发现：1）项目流行度是暴露项目和用户点击后交互之间的混杂因素，导致第一个不公平； 2）一些隐藏的混杂因素（例如物品生产者的声誉）会影响物品的受欢迎程度和质量，从而导致第二种不公平。为了缓解这些混杂问题，我们提出了一个因果框架来估计因果效应，该框架利用后门调整来阻止混杂因素引起的后门路径。在推理阶段，我们消除了流行度的负面影响，并利用质量的良好效果进行推荐。对两个真实世界数据集的实验验证了我们提出的框架的有效性，该框架在不牺牲推荐准确性的情况下增强了公平性。]]></description>
      <guid>https://arxiv.org/abs/2209.04589</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>顺序推荐的等变对比学习</title>
      <link>https://arxiv.org/abs/2211.05290</link>
      <description><![CDATA[arXiv:2211.05290v4 公告类型：替换
摘要：对比学习（CL）有利于利用信息丰富的自我监督信号训练顺序推荐模型。现有的解决方案应用一般的顺序数据增强策略来生成正对并鼓励它们的表示保持不变。然而，由于用户行为序列的固有属性，一些增强策略（例如项目替换）可能会导致用户意图的变化。不加区别地学习所有增强策略的不变表示可能不是最理想的。因此，我们提出了顺序推荐的等变对比学习（ECL-SR），它赋予SR模型强大的判别能力，使得学习到的用户行为表示对侵入性增强（例如项目替换）敏感而对轻度增强（例如特征级别）不敏感漏失掩蔽）。具体来说，我们使用条件判别器来捕获由于项目替换而导致的行为差异，这鼓励用户行为编码器与侵入性增强等效。对四个基准数据集的综合实验表明，与最先进的 SR 模型相比，所提出的 ECL-SR 框架实现了具有竞争力的性能。源代码可在 https://github.com/Tokkiu/ECL 获取。]]></description>
      <guid>https://arxiv.org/abs/2211.05290</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 Transformer 的深度学习对多语言仇恨言论进行分析和检测</title>
      <link>https://arxiv.org/abs/2401.11021</link>
      <description><![CDATA[arXiv:2401.11021v1 公告类型：交叉
摘要：仇恨言论是基于实际或感知的身份方面（例如种族主义、宗教或性取向）直接攻击或煽动针对团体或个人成员的仇恨的有害内容。这可能会影响社交媒体平台上的社交生活，因为通过社交媒体分享的仇恨内容可能会伤害个人和社区。随着网上仇恨言论的流行，对作为 NLP 任务的自动检测的需求也在增加。在这项工作中，所提出的方法是使用基于 Transformer 的模型来检测社交媒体（如 Twitter、Facebook、WhatsApp、Instagram 等）中的仇恨言论。所提出的模型独立于语言，并已在意大利语、英语、德语、孟加拉。黄金标准数据集来自著名研究人员 Zeerak Talat、Sara Tonelli、Melanie Siegel 和 Rezaul Karim。所提出的仇恨语音检测模型的成功率高于现有的基线和最先进的模型，孟加拉语数据集的准确率为 89%，英语为 91%，德语数据集为 91%，意大利数据集为 91%。是77%。所提出的算法显示出对基准方法的显着改进。]]></description>
      <guid>https://arxiv.org/abs/2401.11021</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>基于崩溃报告挖掘的错误定位的影响：开发者的视角</title>
      <link>https://arxiv.org/abs/2403.10753</link>
      <description><![CDATA[arXiv:2403.10753v1 公告类型：交叉
摘要：开发人员经常使用崩溃报告来了解错误的根本原因。然而，从这些信息中定位有错误的源代码片段是一项具有挑战性的任务，尤其是当日志数据库包含许多崩溃报告时。为了缓解这个问题，最近的研究提出并评估了对崩溃报告数据进行分组并使用堆栈跟踪信息来定位错误的方法。主要通过将候选错误代码片段与错误修复提交中实际更改的代码进行比较来评估此类方法的有效性——这发生在回顾性存储库挖掘研究的背景下。因此，现有文献仍然缺乏讨论这些方法在软件公司日常生活中的使用，这可以解释开发人员对使用这些方法的看法。在本文中，我们报告了在一家软件公司的三个开发团队中使用一种方法对崩溃报告进行分组并在 18 个月内每周查找有缺陷代码的经验。我们收集了超过 750,000 份崩溃报告，提出了 130 多个问题，并收集了 18 名开发人员和团队负责人的反馈。在其他结果中，我们观察到与崩溃报告组相关的系统日志量并不是开发人员用来选择要分析的候选错误的唯一标准。相反，我们考虑了其他因素，例如需要提供客户优先的功能以及解决复杂崩溃报告的难度（例如架构债务）。本研究中研究的方法在大多数情况下都能正确提示有问题的文件 - 该方法的精确度约为 80%。在这项研究中，开发人员还分享了他们对可疑文件的有用性的看法以及从崩溃报告中提取的修复相关错误的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.10753</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>对比学习有必要吗？顺序推荐中数据增强与对比学习的研究</title>
      <link>https://arxiv.org/abs/2403.11136</link>
      <description><![CDATA[arXiv:2403.11136v1 公告类型：新
摘要：顺序推荐系统（SRS）旨在根据用户的历史交互数据预测用户的未来行为。最近的研究越来越多地利用对比学习（CL）来利用无监督信号来缓解 SRS 中的数据稀疏问题。一般来说，基于 CL 的 SRS 首先通过使用数据增强策略来增强原始序列交互数据，并采用对比训练方案来强制来自相同原始交互数据的那些序列的表示相似。尽管 CL 越来越受欢迎，但数据增强作为 CL 的基本组成部分尚未受到足够的重视。这就提出了一个问题：仅通过数据增强是否有可能获得更好的推荐结果？为了回答这个问题，我们在热启动和冷启动设置下的四个真实数据集上对八种广泛使用的数据增强策略以及最先进的基于 CL 的 SRS 方法进行了基准测试。有趣的是，我们的研究得出的结论是，与一些基于 CL 的方法相比，某些数据增强策略可以实现相似甚至更好的性能，这证明了以更少的计算开销显着缓解数据稀疏问题的潜力。我们希望我们的研究能够进一步激发对复杂 CL 技术关键功能组件的更多基础研究。我们处理的数据集和代码可在 https://github.com/AIM-SE/DA4Rec 上获取。]]></description>
      <guid>https://arxiv.org/abs/2403.11136</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>ConvSDG：对话式搜索的会话数据生成</title>
      <link>https://arxiv.org/abs/2403.11335</link>
      <description><![CDATA[arXiv:2403.11335v1 公告类型：新
摘要：会话式搜索通过允许与搜索引擎进行多轮交互，为用户提供了更便捷的搜索界面。然而，会话密集检索方法的有效性受到其微调所需的训练数据稀缺的限制。因此，生成更多带有相关标签的训练对话会话可能会提高搜索性能。基于大型语言模型 (LLM) 在文本生成方面的强大功能，我们提出了 ConvSDG，这是一个简单而有效的框架，用于探索使用 LLM 进行会话数据生成来促进会话搜索的可行性。在此框架内，我们根据相关性判断的可用性，通过无监督和半监督学习设计对话/会话级和查询级数据生成。生成的数据用于微调会话密集检索器。对四个广泛使用的数据集进行的广泛实验证明了我们的 ConvSDG 框架与几个强大的基线相比的有效性和广泛适用性。]]></description>
      <guid>https://arxiv.org/abs/2403.11335</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐的双通道多重图神经网络</title>
      <link>https://arxiv.org/abs/2403.11624</link>
      <description><![CDATA[arXiv:2403.11624v1 公告类型：新
摘要：高效的推荐系统在准确捕获反映个人偏好的用户和项目属性方面发挥着至关重要的作用。一些现有的推荐技术已经开始将重点转向对现实推荐场景中用户和商品之间的各种类型的交互关系进行建模，例如在线购物平台上的点击、标记收藏夹和购买。然而，这些方法仍然存在两个显着的缺点：（1）对用户和项目之间的多重关系形成的各种行为模式对表示学习的影响的建模和利用不足，以及（2）忽略了行为中不同关系的影响推荐系统场景中目标关系的模式。在本研究中，我们引入了一种新颖的推荐框架，即双通道多重图神经网络（DCMGNN），它解决了上述挑战。它结合了显式行为模式表示学习器来捕获由多重用户-项目交互关系组成的行为模式，并包括关系链表示学习和关系链感知编码器来发现各种辅助关系对目标关系的影响，不同关系之间的依赖关系，并挖掘行为模式中关系的适当顺序。对三个现实世界数据集的广泛实验表明，我们的模型超越了各种最先进的推荐方法。在 R@10 和 N@10 方面，它在所有数据集上平均分别优于最佳基线 10.06% 和 12.15%。]]></description>
      <guid>https://arxiv.org/abs/2403.11624</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>迈向统一的多模式个性化：用于生成推荐及其他领域的大型视觉语言模型</title>
      <link>https://arxiv.org/abs/2403.10667</link>
      <description><![CDATA[arXiv:2403.10667v1 公告类型：新
摘要：开发一种能够有效利用异构资源并响应广泛的个性化需求的通用模型一直是社区的长期愿望。我们的日常选择，尤其是在时尚和零售等领域，很大程度上是由图片和文字描述等多模式数据决定的。这些方式不仅提供直观的指导，而且还满足个性化的用户偏好。然而，主流的个性化方法主要关注ID或基于文本的推荐问题，未能理解跨越各种任务或模式的信息。在本文中，我们的目标是建立多模态个性化系统（UniMP）的统一范式，该范式有效地利用多模态数据，同时消除与特定于任务和模态的定制相关的复杂性。我们认为基础生成模型的进步提供了实现目标所需的灵活性和有效性。有鉴于此，我们开发了一个通用且可扩展的个性化生成框架，可以处理广泛的个性化需求，包括项目推荐、产品搜索、偏好预测、解释生成以及进一步的用户引导图像生成。我们的方法通过无缝摄取交错的跨模式用户历史信息，增强了用于个性化任务的基础语言模型的能力，确保为用户提供更精确和定制的体验。为了训练和评估所提出的多模式个性化任务，我们还引入了一个涵盖各种用户需求的新颖且全面的基准。我们对现实世界基准的实验展示了该模型的潜力，优于专门针对每项任务的竞争方法。]]></description>
      <guid>https://arxiv.org/abs/2403.10667</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    <item>
      <title>通过多正对比学习提高密集检索器针对拼写错误的鲁棒性</title>
      <link>https://arxiv.org/abs/2403.10939</link>
      <description><![CDATA[arXiv:2403.10939v1 公告类型：新
摘要：密集检索已成为段落检索的新范式。尽管它对无拼写错误的查询有效，但在处理包含拼写错误的查询时它并不健壮。当前致力于提高密集检索器的拼写错误鲁棒性的工作将（i）数据增强以在训练期间获取拼写错误的查询与（ii）额外的鲁棒性子任务相结合，这些子任务旨在将原始的、无拼写错误的查询与其拼写错误的变体对齐。尽管每个查询可以使用多个拼写变体作为正样本，但某些方法假设每个锚点有一个正样本和一组负样本，并通过对比学习来解决鲁棒性子任务；因此，没有充分利用多重肯定（打字查询）。相反，在这项工作中，我们认为所有可用的积极因素都可以同时使用，并采用支持多种积极因素（多积极因素）的对比学习。两个数据集的实验结果表明，我们提出的同时利用所有正样本并在鲁棒子任务上采用多正样本对比学习的方法，相对于使用单个正样本的对比学习，可以提高鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2403.10939</guid>
      <pubDate>Tue, 19 Mar 2024 06:16:39 GMT</pubDate>
    </item>
    </channel>
</rss>