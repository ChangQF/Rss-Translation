<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>多模式建议的调整和培训框架</title>
      <link>https://arxiv.org/abs/2403.12384</link>
      <description><![CDATA[arXiv:2403.12384v2 公告类型：替换
摘要：随着多媒体应用的发展，多模式推荐发挥着重要作用，因为它们可以利用用户交互之外的丰富上下文。现有方法主要以多模态信息为辅助，利用它们来帮助学习ID特征；然而，多模态内容特征和ID特征之间存在语义差距，直接使用多模态信息作为辅助会导致用户和项目的表示不一致。在本文中，我们首先系统地研究了多模态推荐中的错位问题，并提出了一种名为 AlignRec 的解决方案。在AlignRec中，推荐目标被分解为三种对齐方式，即内容内的对齐方式、内容与分类ID之间的对齐方式以及用户与项目之间的对齐方式。每个对齐都具有特定的目标函数，并集成到我们的多模式推荐框架中。为了有效地训练我们的 AlignRec，我们建议从预训练第一个对齐开始以获得统一的多模态特征，然后将这些特征作为输入来训练以下两个对齐。由于分析每个多模态特征是否有助于训练至关重要，因此我们设计了三类新的指标来评估中间性能。我们对三个真实世界数据集进行的广泛实验一致验证了 AlignRec 与九个基线相比的优越性。我们还发现AlignRec生成的多模态特征比当前使用的多模态特征更好，这些特征将被开源。]]></description>
      <guid>https://arxiv.org/abs/2403.12384</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>利用高分辨率功能改进基于深度哈希的图像检索</title>
      <link>https://arxiv.org/abs/2403.13747</link>
      <description><![CDATA[arXiv:2403.13747v1 公告类型：交叉
摘要：深度哈希技术已成为高效图像检索的主要方法。传统上，这些方法利用预先训练的卷积神经网络 (CNN)（例如 AlexNet 和 VGG-16）作为特征提取器。然而，数据集日益复杂，对这些骨干架构捕获有效图像检索所必需的有意义的特征提出了挑战。在这项研究中，我们探索了将通过最先进的技术学习到的高分辨率特征用于图像检索任务的功效。具体来说，我们提出了一种利用高分辨率网络（HRNet）作为深度哈希任务的骨干的新颖方法，称为高分辨率哈希网络（HHNet）。与所有测试的基准数据集（包括 CIFAR-10、NUS-WIDE、MS COCO 和 ImageNet）中的现有方法相比，我们的方法表现出了卓越的性能。对于复杂的数据集，这种性能提升更为明显，这凸显了为复杂的图像检索任务学习高分辨率特征的需要。此外，我们对不同的 HRNet 配置进行了全面分析，并为深度哈希任务的最佳架构提供了见解]]></description>
      <guid>https://arxiv.org/abs/2403.13747</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>I^3 Retriever：将隐式交互纳入预先训练的语言模型中以进行段落检索</title>
      <link>https://arxiv.org/abs/2306.02371</link>
      <description><![CDATA[arXiv:2306.02371v3 公告类型：替换
摘要：段落检索是许多信息系统中的一项基本任务，例如网络搜索和问答，其中效率和有效性都是关键问题。近年来，基于预训练语言模型（PLM）的神经检索器（例如双编码器）取得了巨大成功。然而，研究发现，由于忽略了查询和候选段落之间的交互信息，双编码器的性能往往受到限制。因此，人们提出了各种交互范例来提高普通双编码器的性能。特别是，最近最先进的方法经常在模型推理过程中引入后期交互。然而，这种基于后期交互的方法通常会在大型语料库上带来大量的计算和存储成本。尽管它们很有效，但对效率和空间占用的关注仍然是限制基于交互的神经检索模型应用的重要因素。为了解决这个问题，我们将隐式交互合并到双编码器中，并提出 I^3 检索器。特别是，我们的隐式交互范例利用生成的伪查询来模拟查询-通道交互，从而以端到端的方式与查询和通道编码器联合优化。它可以完全预计算和缓存，其推理过程仅涉及查询向量和通道向量的简单点积运算，这使得它与普通双编码器一样高效。我们在 MSMARCO 和 TREC2019 深度学习数据集上进行了全面的实验，证明了 I^3 检索器在有效性和效率方面的优越性。此外，所提出的隐式交互与用于段落检索的特殊预训练和知识蒸馏兼容，从而带来了新的最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2306.02371</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>研究稀疏注意力对交叉编码器的影响</title>
      <link>https://arxiv.org/abs/2312.17649</link>
      <description><![CDATA[arXiv:2312.17649v2 公告类型：替换
摘要：交叉编码器是有效的段落和文档重新排序器，但效率低于其他神经或经典检索模型。之前的一些研究已经应用窗口自注意力来提高交叉编码器的效率。然而，这些研究没有调查不同注意力模式或窗口大小的潜力和局限性。我们缩小了这一差距，并系统地分析了如何在不损害重新排名有效性的情况下减少代币交互。通过不对称注意力和不同窗口大小的实验，我们发现查询标记不需要关注段落或文档标记来进行有效的重新排序，并且非常小的窗口大小就足够了。在我们的实验中，即使是 4 个 token 的窗口，其效率仍然与以前的交叉编码器相当，同时将内存需求减少至少 22% / 59%，并且在段落/文档的推理时间上加快 1% / 43%。]]></description>
      <guid>https://arxiv.org/abs/2312.17649</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>用途：使用状态序列模型进行动态用户建模</title>
      <link>https://arxiv.org/abs/2403.13344</link>
      <description><![CDATA[arXiv:2403.13344v1 公告类型：交叉
摘要：用户嵌入在用户参与度预测和个性化服务中发挥着至关重要的作用。序列建模的最新进展激发了人们对从行为数据中学习用户嵌入的兴趣。然而，基于行为的用户嵌入学习面临着动态用户建模的独特挑战。当用户不断与应用程序交互时，应定期更新用户嵌入，以考虑用户最近和长期的行为模式。现有方法高度依赖缺乏历史行为记忆的无状态序列模型。他们必须要么丢弃历史数据并仅使用最新数据，要么联合重新处理新旧数据。这两种情况都会产生大量的计算开销。为了解决这个限制，我们引入了用户状态嵌入（USE）。 USE 生成用户嵌入并反映用户不断变化的行为，而无需通过存储以前的模型状态并在将来重新访问它们来进行彻底的重新处理。此外，我们引入了一种名为未来 W 行为预测的新颖训练目标，通过预测更广泛的即将到来的用户行为来超越下一个令牌预测的局限性。通过将其与相同用户预测（一种基于对比学习的目标，预测行为序列的不同片段是否属于同一用户）相结合，我们进一步提高了嵌入的独特性和代表性。我们使用 Snapchat 用户的行为日志在静态（即固定用户行为序列）和动态（即定期更新的用户行为序列）设置下对 8 个下游任务进行了实验。我们展示了 USE 相对于既定基线的卓越性能。结果强调了 USE 在将历史和近期用户行为序列集成到动态用户建模中的用户嵌入中的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2403.13344</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>用于带噪声标签的跨模式检索的统一最优传输框架</title>
      <link>https://arxiv.org/abs/2403.13480</link>
      <description><![CDATA[arXiv:2403.13480v1 公告类型：交叉
摘要：跨模态检索（CMR）旨在建立不同模态之间的交互，其中监督式 CMR 因其在学习语义类别辨别方面的灵活性而正在兴起。尽管以前的监督 CMR 方法表现出色，但它们的成功很大程度上可以归因于注释良好的数据。然而，即使对于单模态数据，精确注释也是昂贵且耗时的，并且在多模态场景中变得更具挑战性。在实践中，大量多模态数据是从互联网上收集并进行粗略标注，这不可避免地引入了噪声标签。使用这种误导性标签进行训练将带来两个关键挑战——强制多模态样本\emph{对齐不正确的语义}和\emph{扩大异构间隙}，从而导致检索性能不佳。为了应对这些挑战，这项工作提出了 UOT-RCL，一种基于最佳传输 (OT) 的鲁棒跨模态检索的统一框架。首先，我们提出了基于部分 OT 的语义对齐来逐步纠正噪声标签，其中设计了一种新颖的跨模态一致成本函数来混合不同模态并提供精确的运输成本。其次，为了缩小多模态数据的差异，提出了一种基于 OT 的关系对齐来推断语义级跨模态匹配。这两个组成部分都利用多模式数据之间的固有相关性来促进有效的成本函数。在三个广泛使用的跨模态检索数据集上进行的实验表明，我们的 UOT-RCL 超越了最先进的方法，并显着提高了针对噪声标签的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2403.13480</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>不再有优化规则：支持 LLM 的基于策略的多模式查询优化器（版本 1）</title>
      <link>https://arxiv.org/abs/2403.13597</link>
      <description><![CDATA[arXiv:2403.13597v1 公告类型：交叉
摘要：大语言模型（LLM）标志着机器学习和深度学习领域的关键时刻。最近对其查询规划的能力进行了研究，包括单模态和多模态查询。然而，目前还没有关于LLM的查询优化能力的工作。作为显着影响查询计划执行性能的关键（甚至可能是最重要的）步骤，这样的分析和尝试是不容错过的。从另一个方面来看，现有的查询优化器通常是基于规则或基于规则+基于成本的，即依赖于手动创建的规则来完成查询计划重写/转换。考虑到现代优化器包含数百到数千条规则，按照类似的方式设计多模式查询优化器非常耗时，因为我们必须枚举尽可能多的多模式优化规则，而这并不好今天谈到。在本文中，我们研究了LLM的查询优化能力，并使用LLM设计了LaPuda，一种新颖的基于LLM和策略的多模式查询优化器。 LaPuda不需要罗列具体、详细的规则，只需要一些抽象的策略来指导LLM的优化，节省了大量的时间和人力。此外，为了防止LLM出现错误或负优化，我们借鉴梯度下降的思想，提出了引导成本下降（GCD）算法来进行优化，使得优化能够保持在正确的方向上。在我们的评估中，我们的方法在大多数情况下始终优于基线。例如，我们的方法生成的优化计划的执行速度比基线高 1~3 倍。]]></description>
      <guid>https://arxiv.org/abs/2403.13597</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>DESIRE-ME：使用专家混合的领域增强监督信息检索</title>
      <link>https://arxiv.org/abs/2403.13468</link>
      <description><![CDATA[arXiv:2403.13468v1 公告类型：新
摘要：开放域问答要求检索系统能够应对问题的多样性和多样性，并在广泛的查询类型和主题中提供准确的答案。为了通过独特的模型处理这种主题异质性，我们提出了 DESIRE-ME，这是一种神经信息检索模型，利用 Mixture-of-Experts 框架来组合多个专门的神经模型。我们依靠维基百科数据来训练有效的神经门控机制，该机制对传入的查询进行分类，并相应地权衡不同特定领域专家的预测。这使得 DESIRE-ME 能够自适应地专注于多个领域。通过对公开数据集的广泛实验，我们表明我们的建议可以有效地推广领域增强神经模型。 DESIRE-ME 擅长自适应处理开放域问题，在 NDCG@10 中提升高达 12%，在 P@1（底层最先进的密集检索模型）中提升高达 22%。]]></description>
      <guid>https://arxiv.org/abs/2403.13468</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>一种用于视频和评论联合推荐的大语言模型增强序列推荐器</title>
      <link>https://arxiv.org/abs/2403.13574</link>
      <description><![CDATA[arXiv:2403.13574v1 公告类型：新
摘要：在在线视频平台中，阅读或撰写有趣视频的评论已成为视频观看体验的重要组成部分。然而，现有的视频推荐系统主要对用户与视频的交互行为进行建模，缺乏对用户行为建模中评论的考虑。在本文中，我们提出了一种新颖的推荐方法，称为LSVCR，利用用户与视频和评论的交互历史记录，从而联合进行个性化视频和评论推荐。具体来说，我们的方法由两个关键组件组成，即顺序推荐（SR）模型和补充大语言模型（LLM）推荐器。 SR 模型充当我们方法的主要推荐主干（在部署中保留），允许高效的用户偏好建模。同时，我们利用 LLM 推荐器作为补充组件（在部署中丢弃），以更好地从异构交互行为中捕获潜在的用户偏好。为了整合 SR 模型和补充 LLM 推荐器的优点，我们设计了一个两阶段训练范例。第一阶段是个性化偏好对齐，旨在对齐两个组件的偏好表示，从而增强 SR 模型的语义。第二阶段是面向推荐的微调，其中根据特定目标对对齐增强的SR模型进行微调。视频和评论推荐任务中的大量实验证明了 LSVCR 的有效性。此外，快手平台上的在线A/B测试验证了我们的方法带来的实际好处。特别是，我们的评论观看时间整体显着增加了 4.13%。]]></description>
      <guid>https://arxiv.org/abs/2403.13574</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>当 SMILES 具有语言时：在药物 SMILES 字符串上使用文本分类方法进行药物分类</title>
      <link>https://arxiv.org/abs/2403.12984</link>
      <description><![CDATA[arXiv:2403.12984v1 公告类型：交叉
摘要：复杂的化学结构（如药物）通常由 SMILES 字符串定义为分子和键的序列。这些 SMILES 字符串用于不同的复杂的基于机器学习的药物相关研究和表示工作。为了摆脱复杂的表征，在这项工作中，我们提出了一个问题：如果我们将药物 SMILES 视为常规句子并进行文本分类以进行药物分类会怎么样？我们的实验以极具竞争力的分数证实了这种可能性。该研究探索了将每个原子和键视为句子成分的概念，采用基本的 NLP 方法对药物类型进行分类，证明复杂的问题也可以用更简单的视角来解决。数据和代码可在此处获取：https://github.com/azminewasi/Drug-Classification-NLP。]]></description>
      <guid>https://arxiv.org/abs/2403.12984</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>Flickr30K-CFQ：用于文本图像检索的紧凑且碎片化的查询数据集</title>
      <link>https://arxiv.org/abs/2403.13317</link>
      <description><![CDATA[arXiv:2403.13317v1 公告类型：新
摘要： 随着互联网上多模态信息的爆炸式增长，单模态搜索已经不能满足互联网应用的需求。需要进行文本图像检索研究以实现不同模态之间的高质量和高效检索。现有的文本图像检索研究大多基于通用视觉语言数据集（例如MS-COCO、Flickr30K），其中查询语句僵化且不自然（即冗长和形式）。为了克服这个缺点，我们构建了一个新的紧凑和碎片查询挑战数据集（名为 Flickr30K-CFQ）来建模文本图像检索任务，考虑多种查询内容和风格，包括紧凑和细粒度的实体关系语料库。我们提出了一种基于 LLM 的提示工程的新型查询增强文本图像检索方法。实验表明，我们提出的 Flickr30-CFQ 揭示了现有视觉语言数据集在现实文本图像任务中的不足。我们基于 LLM 的查询增强方法应用于不同的现有文本图像检索模型，在公共数据集和挑战集 Flickr30-CFQ 上的查询理解性能分别提高了 0.9% 和 2.4% 以上。我们的项目可以在 https://sites.google.com/view/Flickr30K-cfq 中匿名获取。]]></description>
      <guid>https://arxiv.org/abs/2403.13317</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行丰富文本的顺序推荐</title>
      <link>https://arxiv.org/abs/2403.13325</link>
      <description><![CDATA[arXiv:2403.13325v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展正在改变推荐系统（RS）的范式。然而，当推荐场景中的项目包含丰富的文本信息时，例如网购中的产品描述或社交媒体上的新闻标题，LLM需要更长的文本来全面描述历史用户行为序列。这给基于 LLM 的推荐系统带来了重大挑战，例如超长度限制、大量时间和空间开销以及次优模型性能。为此，在本文中，我们设计了一种利用大型语言模型进行富文本顺序推荐（LLM-TRSR）的新颖框架。具体来说，我们首先建议对用户历史行为进行分段，然后采用基于 LLM 的摘要器来总结这些用户行为块。特别是，从卷积神经网络（CNN）和循环神经网络（RNN）模型在用户建模中的成功应用中汲取灵感，我们在本文中引入了两种独特的摘要技术，分别是分层摘要和循环摘要。然后，我们将包含用户偏好摘要、最近用户交互和候选项目信息的提示文本构建到基于 LLM 的推荐器中，随后使用监督微调（SFT）技术对其进行微调，以产生我们的最终推荐模型。我们还使用低秩适应（LoRA）进行参数高效微调（PEFT）。我们在两个公共数据集上进行了实验，结果清楚地证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.13325</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>利用大脑信号改善法律案件检索</title>
      <link>https://arxiv.org/abs/2403.13242</link>
      <description><![CDATA[arXiv:2403.13242v1 公告类型：新
摘要：近十年来，法律案例检索任务越来越受到 IR 界的关注。具有隐式用户反馈（例如点击）的相关性反馈技术已被证明在传统搜索任务（例如网页搜索）中是有效的。然而，在法律案件检索中，收集相关性反馈面临着一些在现有反馈范式下难以解决的挑战。首先，法律案例检索是一项复杂的任务，因为用户通常需要详细了解法律案例之间的关系，以正确判断其相关性。传统的反馈信号（例如点击）过于粗糙而无法使用，因为它们不反映任何细粒度的相关信息。其次，法律案件文件通常很长，用户往往需要甚至几十分钟才能阅读和理解它们。当用户几乎点击并检查文档的每个部分时，简单的行为信号（例如点击和眼球追踪注视）几乎没有用处。在本文中，我们探讨了利用脑信号解决法律案例检索中的反馈问题的可能性。大脑信号处理的最新进展表明，可以通过脑机接口（BMI）以细粒度收集人类情绪，而不会中断用户的任务。因此，我们提出了一种利用脑电图信号来优化检索结果的法律案件检索框架。我们收集并创建了一个带有用户脑电信号的法律案件检索数据集，并提出了几种方法来提取有效的脑电图特征以进行相关反馈。我们提出的特征通过SVM-RFE模型实现了71%的反馈预测准确率，并且我们提出的考虑到用户多样化需求的排序方法可以显着提高用户对法律案件检索的满意度。实验结果表明，重新排序的结果列表使用户更加满意。]]></description>
      <guid>https://arxiv.org/abs/2403.13242</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>后期交互模型的匹配机制和令牌剪枝分析</title>
      <link>https://arxiv.org/abs/2403.13291</link>
      <description><![CDATA[arXiv:2403.13291v1 公告类型：新
摘要：随着预训练语言模型的发展，密集检索模型已成为依赖精确匹配和稀疏词袋表示的传统检索模型的有希望的替代品。与大多数使用双编码器将每个查询或文档编码为密集向量的密集检索模型不同，最近提出的后期交互多向量模型（即 ColBERT 和 COIL）通过以下方式实现了最先进的检索有效性：使用所有标记嵌入来表示文档和查询，并通过最大和运算对它们的相关性进行建模。然而，这些细粒度的表示可能会导致实际搜索系统无法接受的存储开销。在本研究中，我们系统地分析了这些后期交互模型的匹配机制，并表明最大和运算严重依赖于共现信号和文档中的一些重要单词。基于这些发现，我们提出了几种简单的文档剪枝方法来减少存储开销，并比较不同剪枝方法在不同后期交互模型上的有效性。我们还利用查询修剪方法来进一步减少检索延迟。我们对域内和域外数据集进行了广泛的实验，结果表明，所使用的一些剪枝方法可以显着提高这些后期交互模型的效率，而不会显着损害其检索效果。]]></description>
      <guid>https://arxiv.org/abs/2403.13291</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>Mathlib4 的语义搜索引擎</title>
      <link>https://arxiv.org/abs/2403.13310</link>
      <description><![CDATA[arXiv:2403.13310v1 公告类型：新
摘要：交互式定理证明器 Lean 能够验证形式数学证明，并得到不断扩大的社区的支持。该生态系统的核心是其数学库 mathlib4，它为不断扩大的数学理论的形式化奠定了基础。然而，在 mathlib4 中搜索定理可能具有挑战性。为了在 mathlib4 中成功搜索，用户通常需要熟悉其命名约定或文档字符串。因此，创建一个可以被对 mathlib4 熟悉程度不同的个人轻松使用的语义搜索引擎非常重要。在本文中，我们提出了一个 mathlib4 的语义搜索引擎，它接受非正式查询并查找相关定理。我们还为 mathlib4 建立了评估各种搜索引擎性能的基准。]]></description>
      <guid>https://arxiv.org/abs/2403.13310</guid>
      <pubDate>Thu, 21 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    </channel>
</rss>