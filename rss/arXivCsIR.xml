<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 17 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>训练一次，灵活使用：多方面神经新闻推荐的模块化框架</title>
      <link>https://arxiv.org/abs/2307.16089</link>
      <description><![CDATA[arXiv:2307.16089v2 公告类型：替换
摘要：最近的神经新闻推荐器（NNR）扩展了基于内容的推荐（1）通过调整候选新闻和用户历史之间的其他方面（例如主题、情绪）或（2）通过使推荐多样化。这些方面。这种定制是通过将附加约束“硬编码”到 NNR 的架构和/或训练目标中来实现的：所需推荐行为的任何变化都需要使用修改后的目标重新训练模型。这阻碍了多方面新闻推荐器的广泛采用。在这项工作中，我们介绍了 MANNeR，一个用于多方面神经新闻推荐的模块化框架，支持在推理时对各个方面进行动态定制。以基于度量的学习为骨干，MANNeR 学习特定方面的新闻编码器，然后灵活且线性地将所得特定方面的相似度分数组合到不同的排名函数中，从而减轻了对模型的特定于排名函数的重新训练的需要。大量实验结果表明，MANNeR 在基于标准内容的推荐以及单方面和多方面定制方面始终优于最先进的 NNR。最后，我们验证 MANNeR 的方面定制模块对于语言和域传输具有鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2307.16089</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士在多语言密集检索中综合多种语言的训练数据</title>
      <link>https://arxiv.org/abs/2311.05800</link>
      <description><![CDATA[arXiv:2311.05800v2 公告类型：替换
摘要：由于多种语言可用的训练数据不均匀且稀缺，密集检索模型在多语言检索中取得的成功有限。合成训练数据生成很有前景（例如 InPars 或 Promptagator），但仅针对英语进行了研究。因此，为了研究跨语言和单语言检索任务的模型能力，我们开发了 SWIM-IR，这是一个包含 33 种（资源从高到低）语言的综合检索训练数据集，用于微调多语言密集检索器，而无需任何人工监督。为了构建 SWIM-IR，我们提出 SAP（总结然后询问提示），其中大语言模型 (LLM) 在查询生成步骤之前生成文本摘要。 SAP 协助法学硕士以目标语言生成信息丰富的查询。使用 SWIM-IR，我们探索多语言密集检索模型的综合微调，并在三个检索基准上对其进行稳健评估：XOR-Retrieve（跨语言）、MIRACL（单语言）和 XTREME-UP（跨语言）。我们的模型称为 SWIM-X，与人类监督的密集检索模型（例如 mContriever-X）具有竞争力，发现 SWIM-IR 可以廉价地替代昂贵的人类标记检索训练数据。 SWIM-IR 数据集和 SWIM-X 模型可在 https://github.com/google-research-datasets/SWIM-IR 获取。]]></description>
      <guid>https://arxiv.org/abs/2311.05800</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>生成信息检索评估</title>
      <link>https://arxiv.org/abs/2404.08137</link>
      <description><![CDATA[arXiv:2404.08137v2 公告类型：替换
摘要：本文是即将出版的关于生成信息检索的书中的一章草稿，该书由 Chirag Shah 和 Ryen White 共同编辑。在本章中，我们从两个不同但相互关联的角度考虑生成信息检索评估。首先，大型语言模型（LLM）本身正在迅速成为评估工具，当前的研究表明，在基本相关性判断任务上，LLM 可能优于众包工作者和其他付费评估人员。我们回顾了过去和正在进行的相关研究，包括对共享任务计划（如 TREC）未来的猜测，以及对人类评估持续需求的讨论。其次，我们考虑对新兴的基于法学硕士的生成信息检索（GenIR）系统的评估，包括检索增强生成（RAG）系统。我们考虑的方法既关注 GenIR 系统的端到端评估，又关注作为 RAG 系统元素的检索组件的评估。展望未来，我们预计 GenIR 系统的评估至少部分基于基于法学硕士的评估，从而形成明显的循环，系统似乎在评估自己的输出。我们通过两种方式解决这种明显的循环：1）将基于 LLM 的评估视为“慢速搜索”的一种形式，其中较慢的 IR 系统用于评估和训练较快的生产 IR 系统； 2）认识到持续需要在人类评估中进行基础评估，即使人类评估的特征必须改变。]]></description>
      <guid>https://arxiv.org/abs/2404.08137</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>TabSQLify：通过表分解增强法学硕士的推理能力</title>
      <link>https://arxiv.org/abs/2404.10150</link>
      <description><![CDATA[arXiv:2404.10150v1 公告类型：交叉
摘要：表格推理是一项具有挑战性的任务，需要理解自然语言问题和结构化表格数据。大型语言模型 (LLM) 在自然语言理解和生成方面表现出了令人印象深刻的能力，但由于输入长度有限，它们经常难以处理大型表。在本文中，我们提出了 TabSQLify，这是一种新颖的方法，它利用文本到 SQL 生成将表分解为更小的相关子表，在执行推理任务之前仅包含用于回答问题或验证语句的基本信息。在我们对四个具有挑战性的数据集的综合评估中，与依赖完整表格作为输入的主流方法相比，我们的方法表现出可比或优越的性能。此外，我们的方法可以显着减少输入上下文长度，使其对于大规模表推理应用程序更具可扩展性和效率。我们的方法在 WikiTQ 基准测试中表现非常出色，准确率达到 64.7%。此外，在 TabFact 基准测试中，它实现了 79.5% 的高精度。这些结果超过了 gpt-3.5-turbo (chatgpt) 上其他基于 LLM 的基线模型。 TabSQLify 可以减小表大小，从而显着减轻 LLM 在处理大型表时的计算负载，而不会影响性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10150</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>可压缩且可搜索：具有学习图像压缩功能的人工智能原生多模态检索系统</title>
      <link>https://arxiv.org/abs/2404.10234</link>
      <description><![CDATA[arXiv:2404.10234v1 公告类型：交叉
摘要：各种形式的数字内容数量不断增长，需要高效的存储和检索方法。传统方法难以应对多媒体数据不断增加的复杂性和规模。在本文中，我们提出的框架通过将人工智能原生多模态搜索功能与神经图像压缩相融合来解决这一挑战。首先，我们分析可压缩性和可搜索性之间的复杂关系，认识到两者在存储和检索系统的效率中发挥的关键作用。通过使用简单的适配器来桥接学习图像压缩（LIC）和对比语言图像预训练（CLIP）的功能，同时保留语义保真度和多模态数据的检索。对柯达数据集的实验评估证明了我们方法的有效性，与现有方法相比，显示了压缩效率和搜索准确性的显着增强。我们的工作标志着大数据时代可扩展且高效的多模式搜索系统的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2404.10234</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>高效知识路径推理：知识图谱指导领域问答大语言模型</title>
      <link>https://arxiv.org/abs/2404.10384</link>
      <description><![CDATA[arXiv:2404.10384v1 公告类型：交叉
摘要：大型语言模型（LLM），例如 GPT3.5、GPT4 和 LLAMA2，在许多任务上表现出奇的好，并且优于人类专家。然而，在许多特定领域的评估中，这些法学硕士常常因相关语料库的训练不足而出现幻觉问题。此外，对大型模型进行微调可能会面临LLM不开源或高质量领域指令构建困难等问题。因此，知识图谱等结构化知识数据库可以更好地为法学硕士提供领域背景知识，充分利用法学硕士的推理和分析能力。在之前的一些工作中，通过问题检索子图时，会多次调用LLM来确定当前三元组是否适合包含在子图中。特别是对于需要多跳推理路径的问题，频繁调用LLM会消耗大量的算力。而且，在选择推理路径时，LLM每一步都会被调用一次，如果其中一个步骤选择错误，就会导致后续步骤的错误累积。本文基于LLM集成并优化了一个从KG中选择推理路径的管道，可以减少对LLM的依赖。此外，我们提出了一种基于思想链（CoT）和页面排名的简单有效的子图检索方法，它可以返回最有可能包含答案的路径。我们在三个数据集上进行实验：GenMedGPT-5k [14]、WebQuestions [2] 和 CMCQA [21]。最后，RoK 可以证明，使用更少的 LLM 调用就可以实现与之前的 SOTA 模型相同的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.10384</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>促进马格里布和阿拉伯地区 TEI 的语言多样性</title>
      <link>https://arxiv.org/abs/2404.10371</link>
      <description><![CDATA[arXiv:2404.10371v1 公告类型：新
摘要：该项目针对马格里布地区的口头语料库和丰富的文本资源。它特别关注12个多世纪以来仍然存在的古典阿拉伯语言的连续性，以及受利比亚、罗马、希伯来和奥斯曼影响以及最近的法语、西班牙语和意大利语所维持的方言语言的极端混合。语言干扰。简而言之，马格里布是一个文献研究极其丰富但尚未开发的地方。]]></description>
      <guid>https://arxiv.org/abs/2404.10371</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>沉默的螺旋：大型语言模型如何扼杀信息检索？——开放领域问答案例研究</title>
      <link>https://arxiv.org/abs/2404.10496</link>
      <description><![CDATA[arXiv:2404.10496v1 公告类型：新
摘要：将大型语言模型（LLM）与检索系统相结合的检索增强生成（RAG）实践已经变得越来越普遍。然而，法学硕士衍生内容渗透到网络并影响检索生成反馈循环的影响在很大程度上是未知领域。在本研究中，我们构建并迭代运行一个模拟管道，以深入研究 LLM 文本对 RAG 系统的短期和长期影响。以流行的开放领域问答（ODQA）任务为切入点，我们的研究结果揭示了潜在的数字“沉默螺旋”效应，法学硕士生成的文本在搜索排名中始终优于人类创作的内容，从而减少了存在和人类在线贡献的影响。这种趋势有可能造成一个不平衡的信息生态系统，其中法学硕士生成的错误内容不受控制地扩散可能会导致准确信息的边缘化。我们敦促学术界关注这一潜在问题，确保多样化和真实的数字信息环境。]]></description>
      <guid>https://arxiv.org/abs/2404.10496</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>LegalPro-BERT：通过微调 BERT 大语言模型对法律条款进行分类</title>
      <link>https://arxiv.org/abs/2404.10097</link>
      <description><![CDATA[arXiv:2404.10097v1 公告类型：交叉
【摘要】：合同是组织中常用的一种法律文件。合同审查是一个完整且重复的过程，以避免商业风险和责任。合同分析需要对协议中的关键条款和段落进行识别和分类。合同条款的识别和验证可能是一项耗时且具有挑战性的任务，需要训练有素且费用昂贵的律师、律师助理或其他法律助理的服务。由于模型训练需要领域专业的法律语言以及法律领域缺乏足够的标记数据，利用人工智能和自然语言处理对合同中的法律条款进行分类是复杂的。在这种情况下，使用通用模型并不有效，因为合同中使用了通用模型可能无法识别的专门法律词汇。为了解决这个问题，我们建议使用预先训练的大型语言模型，随后根据法律分类进​​行校准。我们提出了 LegalPro-BERT，这是一种 BERT 变压器架构模型，我们对其进行微调以有效处理法律条款的分类任务。我们进行了实验来测量指标并将其与当前基准结果进行比较。我们发现 LegalPro-BERT 优于本研究中用于比较的先前基准。]]></description>
      <guid>https://arxiv.org/abs/2404.10097</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>基于聚类的图协同过滤</title>
      <link>https://arxiv.org/abs/2404.10321</link>
      <description><![CDATA[arXiv:2404.10321v1 公告类型：新
摘要：图卷积网络（GCN）在学习推荐系统的用户和项目表示方面取得了巨大成功。其功效的核心是能够显式地利用来自一阶和高阶相邻节点的协作信号。然而，大多数现有的基于 GCN 的方法在执行高阶图卷积时忽略了用户的多重兴趣。因此，来自不可靠邻居节点（例如，具有不同兴趣的用户）的噪声信息会对目标节点的表示学习产生负面影响。此外，在堆叠更多层时，在不区分高阶邻居的情况下进行图卷积操作会遇到过度平滑的问题，从而导致性能下降。在本文中，我们的目标是从高阶相邻节点捕获更有价值的信息，同时避免噪声，以便更好地学习目标节点的表示。为了实现这一目标，我们提出了一种新颖的基于 GCN 的推荐模型，称为基于集群的图协同过滤（ClusterGCF）。该模型对特定于簇的图进行高阶图卷积，这些图是通过捕获用户的多种兴趣并识别它们之间的共同兴趣而构建的。具体来说，我们设计了一种无监督且可优化的软节点聚类方法，将用户和项目节点分类为多个集群。基于软节点聚类结果和用户-项目交互图的拓扑，我们为不同聚类的节点分配概率以构建特定于聚类的图。为了评估 ClusterGCF 的有效性，我们对四个公开可用的数据集进行了广泛的实验。实验结果表明我们的模型可以显着提高推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10321</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的推荐的精确有效的忘却</title>
      <link>https://arxiv.org/abs/2404.10327</link>
      <description><![CDATA[arXiv:2404.10327v1 公告类型：新
摘要：基于大语言模型的推荐（LLMRec）的演变范式通过使用推荐数据的参数高效微调（PEFT）来定制大语言模型（LLM）。法学硕士中包含用户数据引发了隐私问题。为了保护用户，LLMRec 中的忘却过程（特别是从已建立的 LLMRec 模型中删除不可用的数据（例如历史行为））变得至关重要。然而，现有的去学习方法不足以满足LLM-Rec的独特特征，这主要是由于计算成本高或数据擦除不完整。在本研究中，我们引入了适配器分区和聚合（APA）框架，用于在保持推荐性能的同时进行精确有效的忘却。 APA 通过为分区训练数据分片建立不同的适配器并仅重新训练受不可用数据影响的适配器来实现这一目标。为了保持推荐性能并降低相当大的推理成本，APA 采用参数级适配器聚合，并对各个测试样本进行样本自适应关注。广泛的实验证实了我们提出的框架的有效性和效率]]></description>
      <guid>https://arxiv.org/abs/2404.10327</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:47 GMT</pubDate>
    </item>
    </channel>
</rss>