<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 04 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>COS-Mix：余弦相似度与距离融合，提升信息检索效果</title>
      <link>https://arxiv.org/abs/2406.00638</link>
      <description><![CDATA[arXiv:2406.00638v1 公告类型：新
摘要：本研究提出了一种用于检索增强生成 (RAG) 的新型混合检索策略，该策略集成了余弦相似度和余弦距离度量以提高检索性能，特别是对于稀疏数据。传统的余弦相似度度量被广泛用于捕获高维空间中向量之间的相似性。然而，事实证明，这种度量在某些情况下可以产生任意结果。为了解决这一限制，我们结合了余弦距离度量，通过量化向量之间的差异来提供互补的视角。我们的方法是在专有数据上进行实验的，与最近使用开源数据集的出版物不同。所提出的方法展示了增强的检索性能，并提供了对文档或项目之间语义关系的更全面理解。这种混合策略为知识密集型应用中高效、准确地检索相关信息提供了一种有前途的解决方案，利用 BM25（稀疏）检索、向量（密集）检索和基于余弦距离的检索等技术促进高效的信息检索。]]></description>
      <guid>https://arxiv.org/abs/2406.00638</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:04 GMT</pubDate>
    </item>
    <item>
      <title>顺序推荐中实用的两阶段 LLM 增强范式</title>
      <link>https://arxiv.org/abs/2406.00333</link>
      <description><![CDATA[arXiv:2406.00333v1 公告类型：新 
摘要：集成大型语言模型（LLM）的训练范式正在逐渐重塑序列推荐系统（SRS），并已显示出有希望的结果。然而，大多数现有的LLM增强方法依赖于项目端的丰富文本信息和实例级监督微调（SFT）将协作信息注入LLM，这在许多应用中效率低下且受到限制。为了缓解这些问题，本文提出了一种新颖的、易于实践的两阶段LLM增强范式（TSLRec）用于SRS。具体而言，在信息重构阶段，我们在预训练的SRS模型的帮助下设计了一个新的用户级SFT任务用于协同信息注入，该任务更高效并且兼容有限的文本信息。我们的目标是让LLM尝试推断每个项目的潜在类别，并从用户的交互序列中重构相应用户对所有类别的偏好分布。在信息增强阶段，我们将每件商品输入 LLM，以获得一组增强的嵌入，这些嵌入结合了协作信息和 LLM 推理功能。然后可以使用这些嵌入帮助训练未来的各种 SRS 模型。最后，我们在三个 SRS 基准数据集上验证了 TSLRec 的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2406.00333</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:03 GMT</pubDate>
    </item>
    <item>
      <title>让推荐系统更具知识性：整合辅助信息的框架</title>
      <link>https://arxiv.org/abs/2406.00615</link>
      <description><![CDATA[arXiv:2406.00615v1 公告类型：新
摘要：基于会话的推荐系统通常只关注使用三元组（user_id、timestamp、item_id）来预测用户的下一步行动。在本文中，我们旨在利用辅助信息帮助推荐系统捕捉无法检测到的模式和信号。具体来说，我们提出了一个通用框架，将特定于项目的辅助信息合并到推荐系统中，以提高其性能，而无需对原始模型架构进行太多修改。在多个模型和数据集上的实验结果证明，借助辅助信息，我们的推荐系统的表现远远优于最先进的模型，并且收敛速度更快。此外，我们提出了一种新型损失来规范推荐系统使用的注意机制并评估其对模型性能的影响。此外，通过分析，我们提出了一些关于潜在进一步改进的见解。]]></description>
      <guid>https://arxiv.org/abs/2406.00615</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:03 GMT</pubDate>
    </item>
    <item>
      <title>用于产品搜索相关性判断的大型语言模型</title>
      <link>https://arxiv.org/abs/2406.00247</link>
      <description><![CDATA[arXiv:2406.00247v1 公告类型：新 
摘要：检索和重新排序的项目与搜索查询的高相关性是成功产品搜索的基石，但衡量项目与查询的相关性是产品信息检索中最具挑战性的任务之一，产品搜索的质量受到可用相关性标记数据的精度和规模的高度影响。在本文中，我们介绍了一系列利用大型语言模型 (LLM) 来自动大规模判断查询项目对 (QIP) 相关性的技术。使用由人工评估人员注释的数百万个 QIP 的独特数据集，我们测试和优化超参数以微调具有和不具有低秩自适应 (LoRA) 的十亿参数 LLM，以及 LLM 微调中的各种项目属性连接和提示模式，并考虑项目属性包含与相关性预测质量之间的权衡。我们展示了比前几代 LLM 以及现成模型的基线有显著改进的成果，相关性注释与人类相关性评估器相当。我们的发现对产品搜索中相关性判断自动化这一不断发展的领域具有直接影响。]]></description>
      <guid>https://arxiv.org/abs/2406.00247</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:02 GMT</pubDate>
    </item>
    <item>
      <title>BeFA：一种用于多媒体推荐的通用行为驱动功能适配器</title>
      <link>https://arxiv.org/abs/2406.00323</link>
      <description><![CDATA[arXiv:2406.00323v1 公告类型：新
摘要：多媒体推荐系统专注于利用行为信息和内容信息来建模用户偏好。通常，它使用预先训练的特征编码器来提取内容特征，然后将它们与行为特征融合。然而，预训练的特征编码器通常会同时从整个内容中提取特征，包括过多与偏好无关的细节。我们推测这可能导致提取的特征不包含足够的特征来准确反映用户偏好。为了验证我们的假设，我们引入了一种归因分析方法，用于直观地分析内容特征。结果表明，某些产品的内容特征表现出信息漂移和信息遗漏的问题，降低了特征的表达能力。基于这一发现，我们提出了一种有效且高效的通用行为驱动特征适配器（BeFA）来解决这些问题。该适配器在行为信息的指导下重建内容特征，使内容特征准确反映用户偏好。大量实验证明了该适配器在所有多媒体推荐方法中的有效性。论文被接受后，代码将会公开。]]></description>
      <guid>https://arxiv.org/abs/2406.00323</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:02 GMT</pubDate>
    </item>
    <item>
      <title>ImplicitSLIM 及其如何改进基于嵌入的协同过滤</title>
      <link>https://arxiv.org/abs/2406.00198</link>
      <description><![CDATA[arXiv:2406.00198v1 公告类型：新
摘要：我们提出了 ImplicitSLIM，一种用于稀疏高维数据的新型无监督学习方法，可应用于协同过滤。稀疏线性方法 (SLIM) 及其变体表现出色，但它们占用大量内存且难以扩展。ImplicitSLIM 通过以计算成本低且内存效率高的方式从类似 SLIM 的模型中提取嵌入来改进基于嵌入的模型，而无需显式学习繁重的类似 SLIM 的模型。我们表明，ImplicitSLIM 可提高性能并加快最先进和经典协同过滤方法的收敛速度。ImplicitSLIM、相关模型和应用程序的源代码可在 https://github.com/ilya-shenbin/ImplicitSLIM 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.00198</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:01 GMT</pubDate>
    </item>
    <item>
      <title>LLM-RankFusion：缓解 LLM 排名中的内在不一致性</title>
      <link>https://arxiv.org/abs/2406.00231</link>
      <description><![CDATA[arXiv:2406.00231v1 公告类型：新
摘要：通过提示大型语言模型 (LLM) 对段落进行排名可以在现代信息检索 (IR) 系统中取得良好的效果。一种常见的方法是通过提示 LLM 进行成对比较来对排名列表进行排序。然而，基于排序的方法需要一致的比较才能正确地对段落进行排序，我们表明 LLM 经常违反这一点。我们在基于 LLM 的成对比较中确定了两种内在不一致性：顺序不一致导致在切换段落顺序时产生冲突的结果，以及传递不一致导致所有偏好对中出现非传递三元组。在本文中，我们提出了 LLM-RankFusion，这是一个基于 LLM 的排名框架，可以缓解这些不一致性并生成一个强大的排名列表。 LLM-RankFusion 使用上下文学习 (ICL) 来演示与顺序无关的比较和校准，以估计两段文章之间的潜在偏好概率，从而缓解顺序不一致问题。然后，我们通过汇总来自多个排名器的排名结果来解决传递性不一致问题。在我们的实验中，我们通过经验表明，LLM-RankFusion 可以显著减少不一致的成对比较结果，并通过使最终排名列表更加稳健来提高排名质量。]]></description>
      <guid>https://arxiv.org/abs/2406.00231</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:01 GMT</pubDate>
    </item>
    <item>
      <title>提取基本且解开的知识以增强推荐</title>
      <link>https://arxiv.org/abs/2406.00012</link>
      <description><![CDATA[arXiv:2406.00012v1 公告类型：新
摘要：推荐模型在各种工业场景中发挥着至关重要的作用，但经常面临由快速变化的数据分布引起的灾难性遗忘问题，例如不断变化的用户兴趣、促销期间的点击信号波动等。为了缓解这个问题，一种常见的方法是重用历史数据中的知识。然而，保存大量快速积累的数据很困难，这会导致巨大的存储开销。然后提出了通过参数知识库记忆旧数据的方法，将大量原始数据压缩为模型参数。尽管具有灵活性，但如何提高参数知识库的记忆和泛化能力仍然具有挑战性。在本文中，我们提出了两个约束来从过去的数据中提取基本知识和解开知识，以实现合理和广义的推荐增强，从而在不增加参数知识库大小的情况下提高了参数知识库的能力。基本原则有助于将输入压缩为代表性向量，以捕获与任务相关的信息并过滤掉噪声信息。解缠原则减少了存储信息的冗余，并促使知识库专注于捕获解缠的不变模式。这两个规则共同促进了信息的合理压缩，以实现稳健和广义的知识表示。在两个数据集上进行的大量实验证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.00012</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:00 GMT</pubDate>
    </item>
    <item>
      <title>论文：文档摘要及其在关键词提取和图像检索中的应用</title>
      <link>https://arxiv.org/abs/2406.00013</link>
      <description><![CDATA[arXiv:2406.00013v1 公告类型：新
摘要：自动摘要是减少文本文档以生成保留原始文档最重要点的摘要的过程。在这项工作中，我们研究了两个问题 - i）将文本文档总结为关键字/标题集，用于图像推荐，ii）生成与文本文档很好地融合相关性和情感的意见摘要。首先，我们介绍了我们的工作，即推荐图像以增强大量现有的纯文本新闻文章。我们使用概率模型和词相似性启发式方法来生成标题并提取关键短语，然后使用具有相关反馈机制的排名聚合框架对其进行重新排名。我们表明，这种通常用于标记文档、文本信息检索的排名聚合和相关反馈也有助于改进图像检索。这些查询被输入到雅虎搜索引擎以获取相关图像 1。我们提出的方法比所有现有基线表现更好。此外，我们提出了一组用于观点总结的子模块函数。观点总结内置了总结和情绪检测的任务。然而，检测情绪并同时提取总结并不容易。这两个任务相互冲突，因为压缩的需求可能会丢失带有情绪的句子，而情绪检测的需求可能会带来冗余句子。然而，使用子模块性，我们展示了如何在这两个要求之间取得平衡。我们的函数生成的总结具有良好的文档情绪和总结情绪之间的相关性以及良好的 ROUGE 分数。我们还比较了所提出的子模块函数的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.00013</guid>
      <pubDate>Wed, 05 Jun 2024 03:18:00 GMT</pubDate>
    </item>
    <item>
      <title>EnterpriseEM：针对企业语义搜索的微调嵌入</title>
      <link>https://arxiv.org/abs/2406.00010</link>
      <description><![CDATA[arXiv:2406.00010v1 公告类型：新
摘要：企业面临着管理专有非结构化数据的重大挑战，这阻碍了高效的信息检索。这导致了人工智能驱动的信息检索解决方案的出现，旨在巧妙地提取相关见解以解决员工的疑问。这些解决方案通常利用预先训练的嵌入模型和生成模型作为基础组件。虽然预训练的嵌入可能根据其原始训练目标表现出接近度或差异度，但它们可能与企业特定数据的独特特征不完全一致，导致与企业环境的检索目标不一致。在本文中，我们提出了一种专门针对企业环境微调预训练嵌入模型的方法。通过调整嵌入以更好地适应企业中普遍存在的检索任务，我们旨在提高信息检索解决方案的性能。我们讨论了微调的过程、其对检索准确性的影响以及对企业信息管理的潜在好处。我们的研究结果表明，微调嵌入模型在提高企业环境中搜索结果的准确性和相关性方面非常有效。]]></description>
      <guid>https://arxiv.org/abs/2406.00010</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:59 GMT</pubDate>
    </item>
    <item>
      <title>DisCo：实现推荐系统表格和语义空间之间的和谐解耦与协作</title>
      <link>https://arxiv.org/abs/2406.00011</link>
      <description><![CDATA[arXiv:2406.00011v2 公告类型：新
摘要：推荐系统在电子商务、社交媒体等各种应用中发挥着重要作用。传统的推荐方法通常在表格表示空间中对协作信号进行建模。尽管个性化建模和效率很高，但潜在的语义依赖关系却被忽略了。随后出现了将语义引入推荐的方法，从语义表示空间中注入知识，而一般语言理解被压缩。然而，现有的语义增强推荐方法侧重于对齐两个空间，在此过程中两个空间的表示趋于接近，而独特的模式被丢弃且没有得到很好的探索。在本文中，我们提出了 DisCo 来从两个表示空间中分离出独特的模式，并将两个空间协作以进行推荐增强，其中捕获了两个空间的特殊性和一致性。具体来说，我们提出了 1）一个双侧注意力网络来捕获域内模式和域间模式，2）一个充分性约束来保留每个表示空间的任务相关信息并过滤掉噪声，以及 3）一个解缠约束来避免模型丢弃唯一信息。这些模块在两个表示空间的解缠和协作之间取得平衡，以产生信息模式向量，这些向量可以作为额外特征并附加到任意推荐主干以进行增强。实验结果验证了我们的方法对不同模型的优越性以及 DisCo 在不同主干上的兼容性。还进行了各种消融研究和效率分析来证明每个模型组件的合理性。]]></description>
      <guid>https://arxiv.org/abs/2406.00011</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:59 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch-IE：用于信息提取的快速且可重复的原型设计</title>
      <link>https://arxiv.org/abs/2406.00007</link>
      <description><![CDATA[arXiv:2406.00007v1 公告类型：新
摘要：信息提取 (IE) 的目标是从非结构化或半结构化文档中获取结构化表示。然而，由于需要集成多个子任务，开发 IE 模型非常复杂。此外，在不同任务之间表示数据以及将数据集转换为特定于任务的模型输入带来了进一步的挑战。为了简化研究人员的这项工作，我们引入了 PyTorch-IE，这是一个基于深度学习的框架，专门设计用于实现 IE 模型的快速、可重复和可重用实现。PyTorch-IE 提供了一个灵活的数据模型，能够通过集成来自各种数据类型（如纯文本或半结构化文本，甚至图像）的相互依赖的注释层来创建复杂的数据结构。我们提出了任务模块来解耦数据表示和特定于模型的表示的关注点，从而提高代码的灵活性和可重用性。 PyTorch-IE 还扩展了对广泛使用的库的支持，例如用于训练的 PyTorch-Lightning、用于数据集读取的 HuggingFace 数据集和用于实验配置的 Hydra。还提供了用于轻松设置新项目的补充库和 GitHub 模板。通过确保功能性和多功能性，PyTorch-IE 为从事信息提取的研究社区提供了重要支持。]]></description>
      <guid>https://arxiv.org/abs/2406.00007</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:58 GMT</pubDate>
    </item>
    <item>
      <title>KnowledgeHub：辅助科学发现的端到端工具</title>
      <link>https://arxiv.org/abs/2406.00008</link>
      <description><![CDATA[arXiv:2406.00008v1 公告类型：新
摘要：本文介绍了 KnowledgeHub 工具，这是一种科学文献信息提取 (IE) 和问答 (QA) 管道。这是通过支持提取转换为文本和结构化表示的 PDF 文档来实现的。然后可以构建一个本体，用户在其中定义他们想要捕获的实体和关系的类型。基于浏览器的注释工具可以根据本体注释 PDF 文档的内容。命名实体识别 (NER) 和关系分类 (RC) 模型可以在生成的注释上进行训练，并可用于注释文档中未注释的部分。知识图谱由这些实体和关系三元组构建，可以查询这些三元组以从数据中获得见解。此外，我们集成了一套大型语言模型 (LLM)，可用于 QA 和摘要，这些模型通过检索组件以所包含的文档为基础。 KnowledgeHub 是一个独特的工具，支持注释、IE 和 QA，让用户全面了解知识发现渠道。]]></description>
      <guid>https://arxiv.org/abs/2406.00008</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:58 GMT</pubDate>
    </item>
    <item>
      <title>使用基础模型探索联合推荐系统的未来</title>
      <link>https://arxiv.org/abs/2406.00004</link>
      <description><![CDATA[arXiv:2406.00004v2 公告类型：新
摘要：近年来，联邦学习 (FL) 和推荐系统 (RS) 的集成，即联邦推荐系统 (FRS)，因通过将私人数据保存在客户端设备上来保护用户隐私而受到关注。然而，由于 FL 的隐私要求和 RS 的典型数据稀疏性问题，FRS 面临着数据异构性和稀缺性等固有限制。像 ChatGPT 这样的模型由迁移学习和自监督学习的概念赋予力量，因此它们可以在微调或提示后轻松应用于下游任务。这些模型，即所谓的基础模型 (FM)，专注于理解人类的意图并按照其在特定任务中的设计角色执行，这些模型因在图像和语言领域产生高质量内容而得到广泛认可。因此，FM 的成就启发了 FRS 的设计并提出了一个有前途的研究方向：集成基础模型来解决上述限制。在本研究中，我们对 FRS 和 FM 进行了全面回顾。具体来说，我们：1）总结当前 FRS 和 FM 的常用方法；2）回顾 FRS 和 FM 带来的挑战；3）讨论未来的潜在研究方向；4）介绍 FRS 领域的一些常见基准和评估指标。我们希望本立场文件能够提供必要的背景和指导，以探索这个有趣且新兴的话题。]]></description>
      <guid>https://arxiv.org/abs/2406.00004</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:57 GMT</pubDate>
    </item>
    <item>
      <title>解开抽象多文档摘要的特殊性</title>
      <link>https://arxiv.org/abs/2406.00005</link>
      <description><![CDATA[arXiv:2406.00005v1 公告类型：新
摘要：多文档摘要 (MDS) 从文档集生成摘要。集合中的每个文档都描述与主题相关的概念，而每个文档也有其独特的内容。然而，文档特异性在现有的 MDS 方法中很少受到关注。忽略每个文档的具体信息会限制生成的摘要的全面性。为了解决这个问题，在本文中，我们提出将特定内容从一个文档集中的文档中分离出来。特定表示学习器学习特定于文档的表示，通过提出的正交约束鼓励它们彼此远离。我们进行了广泛的分析，并发现了有趣的结果，即特定信息和文档集​​表示具有独特的优势，它们的组合为 MDS 提供了更全面的解决方案。此外，我们发现在 MDS 设置下，公共（即共享）信息对整体性能的贡献不大。实现代码可在 https://github.com/congboma/DisentangleSum 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.00005</guid>
      <pubDate>Wed, 05 Jun 2024 03:17:57 GMT</pubDate>
    </item>
    </channel>
</rss>