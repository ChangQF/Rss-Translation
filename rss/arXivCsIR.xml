<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Mon, 11 Dec 2023 03:14:46 GMT</lastBuildDate>
    <item>
      <title>FreestyleRet：从风格多样化的查询中检索图像。 （arXiv：2312.02428v2 [cs.CV] 已更新）</title>
      <link>http://arxiv.org/abs/2312.02428</link>
      <description><![CDATA[图像检索旨在根据给定的查询检索相应的图像。
在应用场景中，用户想要表达自己的检索意图
通过各种查询方式。然而，当前的检索任务主要是
专注于文本查询检索探索，导致检索查询有限
选项以及用户意图中潜在的模糊性或偏见。在本文中，我们
提出基于风格多样化查询的图像检索任务，该任务使得
基于各种查询样式的检索。为了方便新颖的设置，我们
提出第一个多样化风格检索数据集，包含多样化查询
样式包括文本、草图、低分辨率和艺术。我们还提出了一个
轻量级风格多样化的检索框架。适用于各种查询样式
输入，我们应用 Gram 矩阵来提取查询的纹理特征，
将它们聚集到具有特定风格基础的风格空间中。然后我们采用
style-init提示调整模块使视觉编码器能够理解
查询的纹理和样式信息。实验表明我们的
模型，采用 style-init 提示调整策略，优于现有模型
风格多样化检索任务的检索模型。而且，
风格多样化查询~（素描+文字、美术+文字等）可以同时进行
在我们的模型中检索到。来自其他查询的辅助信息增强了
相应查询中的检索性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.02428</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:46 GMT</pubDate>
    </item>
    <item>
      <title>探索推荐系统基于适配器的迁移学习：实证研究和实践见解。 （arXiv：2305.15036v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2305.15036</link>
      <description><![CDATA[适配器是一个具有一些可调参数的插件神经网络模块，具有
作为一种参数有效的迁移学习技术来适应
下游任务的预训练模型，特别是自然语言模型
处理（NLP）和计算机视觉（CV）领域。同时，学习
直接来自原始项目模态特征的推荐模型——例如文本
NLP 和 CV 图像的结合——可以实现有效且可转移的推荐系统
系统（称为 TransRec）。鉴于此，一个自然的问题就出现了：能否
基于适配器的学习技术实现参数高效的 TransRec
很好的表现？

为此，我们进行实证研究来解决几个关键问题
子问题。首先，我们询问基于适配器的 TransRec 是否执行
与基于标准全参数微调的 TransRec 相比？可以
保留不同项目模式的推荐，例如文本 RS 和
视觉RS。如果是，我们对这些现有适配器进行基准测试，这些适配器已被证明
在 NLP 和 CV 任务以及项目推荐任务中发挥作用。第三，我们
仔细研究基于适配器的 TransRec 的几个关键因素：
在哪里以及如何插入这些适配器？最后我们看看效果
基于适配器的 TransRec，通过扩展其源训练数据或扩展
降低目标训练数据。我们的论文提供了重要的见解和实用的
统一指导可转让推荐——研究较少
推荐场景。我们在以下位置发布我们的代码和其他材料：
https://github.com/westlake-repl/Adapter4Rec/。
]]></description>
      <guid>http://arxiv.org/abs/2305.15036</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>时间图模型无法捕获全局时间动态。 （arXiv：2309.15730v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2309.15730</link>
      <description><![CDATA[最近发布的时间图基准在以下背景下进行了分析
动态链接属性预测。我们概述了我们的观察结果并提出了
“最近流行的节点”表现优异的简单无优化基线
时间图中中型和大型数据集的其他方法
基准。我们提出了两种基于 Wasserstein 距离的措施，可以
量化数据集的短期和长期全球动态的强度。
通过分析我们出乎意料的强大基线，我们展示了标准阴性如何
抽样评估可能不适合具有强时态性的数据集
动力学。我们还展示了简单的负采样如何产生模型
训练过程中退化，导致无法排名，完全饱和
时间图网络的预测。我们提出改进的负采样
培训和评估方案并证明其有用性。我们进行
与没有负采样的非对比训练模型进行比较。
我们的结果提供了一个具有挑战性的基线，并表明时间图
网络架构需要深入反思以解决以下问题
重要的全球动态，例如社交媒体、加密货币市场或
电子商务。我们开源基线、措施和建议的代码
负抽样方案。
]]></description>
      <guid>http://arxiv.org/abs/2309.15730</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>LM-Cocktail：通过模型合并对语言模型进行弹性调整。 （arXiv：2311.13534v4 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2311.13534</link>
      <description><![CDATA[预训练的语言模型不断进行微调，以更好地支持
下游应用。然而，此操作可能会导致重大
超出目标域的一般任务的性能下降。到
为了克服这个问题，我们提出了 LM-Cocktail，它可以对
模型从总体角度保持弹性。我们的方法是在
模型合并的形式，其中微调的语言模型与
预训练的基础模型或通过加权来自其他领域的对等模型
平均的。尽管简单，LM-Cocktail 却非常有效：
结果模型能够在整体上取得很强的实证表现
一般任务的范围，同时在其目标方面保持卓越的能力
领域。我们用 LLama 和 BGE 模型进行了全面的实验
流行的基准测试，包括 FLAN、MMLU、MTEB，其结果验证了
我们提出的方法的有效性。代码和检查点可在
https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail。
]]></description>
      <guid>http://arxiv.org/abs/2311.13534</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>基于排序的快速精确固定半径最近邻搜索。 （arXiv：2212.07679v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2212.07679</link>
      <description><![CDATA[固定半径近邻搜索是一种基本的数据操作，
检索到查询点的用户指定距离内的所有数据点。
有有效的算法可以提供快速的 \emph{approximate} 查询
响应，但它们通常有一个计算密集型索引阶段，并且
需要仔细调整参数。因此，精确的暴力破解和基于树的
搜索方法仍然被广泛使用。在这里，我们提出了一个新的固定半径附近
邻居搜索方法，称为 SNN，与暴力搜索相比显着改进
在索引和查询时间方面强制和基于树的方法可证明返回
准确的结果，并且不需要调整参数。 SNN 利用排序
数据点按其第一主成分来修剪查询搜索空间。
使用高级别的有效实现可以进一步加速
基本线性代数子程序 (BLAS)。我们提供我们的理论分析
方法并展示其单独使用时的实际性能
应用在 DBSCAN 聚类算法中。
]]></description>
      <guid>http://arxiv.org/abs/2212.07679</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>DSI++：使用新文档更新变压器内存。 （arXiv：2212.09744v3 [cs.CL] 已更新）</title>
      <link>http://arxiv.org/abs/2212.09744</link>
      <description><![CDATA[可区分搜索索引 (DSI) 对模型中的文档语料库进行编码
参数并使用相同的模型直接回答用户查询。尽管
DSI 模型的强大性能，将它们部署在语料库
随着时间的推移发生的变化在计算上是昂贵的，因为重新索引语料库
需要重新训练模型。在这项工作中，我们介绍了 DSI++，一个持续的
DSI 面临的学习挑战是在更新文档的同时逐步索引新文档
能够回答与先前和新索引的文档相关的查询。
在不同的模型尺度和文档标识符表示中，我们展示了
不断对新文档建立索引会导致大量遗忘
以前索引的文档。我们还假设并验证了该模型
在训练过程中经历遗忘事件，导致学习不稳定。到
为了缓解这些问题，我们研究了两种方法。第一个重点是
修改训练动态。平坦的最小值隐式缓解
遗忘，因此我们针对更平坦的损失盆地进行优化，并表明该模型
稳定地记住更多文档（$+12\%$）。接下来我们引入一个生成式
内存对文档的伪查询进行采样并在期间补充它们
持续索引以防止忘记检索任务。广泛的
基于自然问题的新型连续索引基准实验
(NQ) 和 MS MARCO 证明我们提出的解决方案可以减轻遗忘
显著地。具体来说，它使平均 Hits@10 提高了 $+21.1\%$
NQ 的竞争基准，模型更新所需费用减少 6 倍
与重新训练 DSI 模型以增量索引五个语料库相比
按顺序。
]]></description>
      <guid>http://arxiv.org/abs/2212.09744</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:44 GMT</pubDate>
    </item>
    <item>
      <title>通过自然语言处理进行非法暗网分类：根据文本信息对网页的非法内容进行分类。 （arXiv：2312.04944v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.04944</link>
      <description><![CDATA[这项工作旨在扩展之前在非法行为背景下所做的工作
活动分类，执行三个不同的步骤。首先，我们创建了
113995 个洋葱站点和暗市的异构数据集。然后我们
比较了预先训练的可转移模型，即 ULMFit（通用语言
模型微调），Bert（双向编码器表示
Transformers）和 RoBERTa（稳健优化的 BERT 方法）
传统的文本分类方法，如 LSTM（长短期记忆）
神经网络。最后，我们制定了两种非法活动分类
方法，一种用于暗网上的非法内容，另一种用于识别
特定类型的药物。结果表明 Bert 获得了最佳方法，
对暗网的一般内容和毒品类型进行了分类 96.08%
准确率高达 91.98%。
]]></description>
      <guid>http://arxiv.org/abs/2312.04944</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    <item>
      <title>对 Verizon Media 原生广告中的意外点击进行公正过滤。 （arXiv：2312.05017v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.05017</link>
      <description><![CDATA[Verizon Media (VZM) 原生广告是 VZM 规模最大、速度最快的广告之一
业务不断增长，营业额达到数亿美元
过去的一年。驱动用于预测事件的 VZM 原生模型
概率，例如点击概率和转化概率，是 OFFSET - a
功能增强的基于协作过滤的事件预测算法。在
这项工作我们重点关注预测点击率 (CTR) 的挑战
当我们意识到某些点击的停留时间很短并且被定义时
作为意外点击。意外点击意味着两者之间的亲和力很小
用户和广告，因此预测相似的用户将点击广告是
不准确。因此，删除具有停留时间的点击可能是有益的
低于训练集中的预定义阈值。然而，我们不能
忽略这些积极事件，因为过滤这些事件将导致模型欠佳
预测。以前的方法尝试应用过滤然后添加
对点击率预测的修正偏差，但没有带来收入提升
因此没有被采纳。在这项工作中，我们提出了一种新方法，其中
意外点击的正权重分布在所有
负面事件（跳过），基于其导致意外事件的可能性
点击次数，如辅助模型预测的那样。这些可能性被视为
正确标记负面事件，将我们的训练从仅使用
二进制标签并在我们的训练中采用二进制交叉熵损失函数
过程。在显示离线性能改进后，修改后的模型是
测试在线服务 VZM 原生用户，收入提升 1.18%
生产模型与意外点击无关。
]]></description>
      <guid>http://arxiv.org/abs/2312.05017</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    <item>
      <title>用于改进 Yahoo Gemini Native 中广告点击预测的软频率上限。 （arXiv：2312.05052v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.05052</link>
      <description><![CDATA[雅虎的原生广告（也称为 Gemini 原生）为数十亿人提供服务
每日广告展示量，年投放量达数亿
美元。驱动用于预测点击的 Gemini 原生模型
概率 (pCTR) 和转换概率 (pCONV) 是 OFFSET - 一个特征
基于增强型协同过滤（CF）的事件预测算法。 \抵消
是一种一次性算法，它会为每一批新记录的数据更新其模型
使用基于随机梯度下降（SGD）的方法的数据。自偏移
由于稀疏性，通过特征（即无用户模型）来表示用户
问题，基于规则的硬频率上限（HFC）用于控制数量
特定用户观看特定广告的次数。此外，相关统计数据显示
用户广告疲劳导致点击率 (CTR) 急剧下降。
因此，为了提高点击预测精度，我们提出了软频率
上限（SFC）方法，其中频率特征被纳入
OFFSET模型作为用户广告特征，其权重向量是通过logistic学习的
回归作为 OFFSET 训练的一部分。软频率在线评估
通过桶测试的上限算法显示收入显着提升了 7.3%。
此后，频率特征增强模型已投入生产
服务所有流量，并为雅虎双子座带来巨大的收入提升
本国的。我们还报告了相关统计数据，其中显示，除其他外，
虽然用户的性别不会影响广告疲劳，但后者似乎会增加
随着用户的年龄。
]]></description>
      <guid>http://arxiv.org/abs/2312.05052</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:43 GMT</pubDate>
    </item>
    <item>
      <title>STraceBERT：使用语义应用程序跟踪进行源代码检索。 （arXiv：2312.04731v1 [cs.SE]）</title>
      <link>http://arxiv.org/abs/2312.04731</link>
      <description><![CDATA[软件逆向工程是软件工程中的一项重要任务，
安全性，但这可能是一个具有挑战性的过程，特别是对于对抗性的
文物。为了应对这一挑战，我们提出了 STraceBERT，一种新颖的方法
利用 Java 动态分析工具记录对核心 Java 的调用
库，并在记录的应用程序跟踪上预训练 BERT 风格的模型
用于从候选集中有效检索方法源代码。我们的
实验证明了 STraceBERT 在检索
源代码与现有方法的比较。我们提出的方法提供了
有望解决软件逆向代码检索问题
工程并为该领域的进一步研究开辟了新途径。
]]></description>
      <guid>http://arxiv.org/abs/2312.04731</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>CAR：菜谱检索的整合、增强和监管。 （arXiv：2312.04763v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.04763</link>
      <description><![CDATA[在公共嵌入空间中学习食谱和食物图像表示是
对于跨模式菜谱检索来说，这并不简单，但至关重要。在本文中，我们
提出了具有三种新技术的 CAR 框架，即 Consolidation、
增强和调节，用于跨模式食谱检索。我们介绍
适配器层以更少的计算来巩固预训练的 CLIP 模型
成本比完全繁琐的微调所有参数要好。此外，
利用基础模型（即SAM和LLM）的强大能力，
我们建议通过提取相关信息来增强食谱和食物图像
给对方。 SAM生成与成分对应的图像片段
在菜谱中，法学硕士则从菜谱中产生视觉想象描述
食谱，旨在捕捉食物图像的视觉线索。此外，我们
引入圆损失来调节跨模态嵌入空间，它分配
对正负对有不同的惩罚。随着额外的增强
来自配方和图像的数据，提出了多级圆损失，适用于
圆损失不仅针对原始图像-配方对，而且针对图像片段
以及食谱、视觉想象描述和食物图像以及任意两个
食谱中的部分。在 Recipe1M 数据集上，我们提出的 CAR 优于所有
与现有方法相比有很大差距。广泛的消融研究
旨在验证 CAR 各组成部分的有效性。我们即将会做到
我们的代码和模型是公开的。
]]></description>
      <guid>http://arxiv.org/abs/2312.04763</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    <item>
      <title>通过文本检索增强预测化学。 （arXiv：2312.04881v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2312.04881</link>
      <description><![CDATA[本文重点讨论使用自然语言描述来增强
化学领域的预测模型。传统上，化学信息学
模型使用从数据中手动提取的大量结构化数据进行训练
文学。在本文中，我们介绍了 TextReact，这是一种直接
使用从文献中检索的文本增强预测化学。
TextReact 检索与给定化学反应相关的文本描述，
然后将它们与反应的分子表示对齐。这
通过集成在
预测器训练。我们凭经验验证了两种化学的框架
任务：反应条件推荐和一步逆合成。经过
利用文本检索，TextReact 的性能显着优于最先进的技术
仅根据分子数据训练的化学信息学模型。
]]></description>
      <guid>http://arxiv.org/abs/2312.04881</guid>
      <pubDate>Mon, 11 Dec 2023 03:14:42 GMT</pubDate>
    </item>
    </channel>
</rss>