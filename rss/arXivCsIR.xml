<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>授权基于检索的对话建议与对比用户偏好</title>
      <link>https://arxiv.org/abs/2503.22005</link>
      <description><![CDATA[ARXIV：2503.22005V1公告类型：新 
摘要：对话推荐系统（CRS）旨在提出用户可能通过多转交谈更喜欢的目标项目。最近的研究强调，在用户对话中捕捉情感可以提高建议准确性。但是，他们采用了单个用户表示，这可能无法区分对比的用户意图，例如喜欢和不喜欢，可能会导致次优性能。为此，我们提出了一种新颖的对话推荐模型，称为对比用户偏好扩展和学习（珊瑚）。首先，珊瑚通过使用LLMS的推理能力进行对比偏好扩展来提取用户的隐藏偏好。基于潜在的偏好，珊瑚明确区分了对比的偏好，并通过偏好感知学习将其利用为推荐过程。广泛的实验表明，珊瑚在三个基准数据集中的现有方法显着优于现有方法，在召回@10中提高了高达99.72％的方法。代码和数据集可从https://github.com/kookeej/coral获得]]></description>
      <guid>https://arxiv.org/abs/2503.22005</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HyperMan：下一个POI推荐的超图增强的元学习自适应网络</title>
      <link>https://arxiv.org/abs/2503.22049</link>
      <description><![CDATA[ARXIV：2503.22049V1公告类型：新 
摘要：下一个利益点（POI）推荐旨在通过利用历史记入序列来预测用户的下一个位置。尽管现有的方法显示出令人鼓舞的结果，但他们经常难以捕获复杂的高阶关系并有效地适应各种用户行为，尤其是在解决寒冷的问题时。为了应对这些挑战，我们提出了超图增强的元学习自适应网络（HyperMan），这是一个新型框架，将异质性超图建模与难以感知的元学习机制集成到下一个POI建议。具体而言，设计了三种类型的异质性超系统旨在捕获高阶关系：在特定时间（时间行为超越）的用户访问行为，POIS（空间功能性HyperEdge）之间的空间相关性和用户长期偏好（用户偏好）。此外，引入了一种多样性感知的元学习机制，以动态调整学习策略，考虑到用户行为多样性。对现实世界数据集的广泛实验表明，HyperMan可以实现卓越的性能，有效地应对冷启动挑战并显着提高建议精度。]]></description>
      <guid>https://arxiv.org/abs/2503.22049</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在您制作之前出售它：通过个性化的AI生成的物品革新电子商务</title>
      <link>https://arxiv.org/abs/2503.22182</link>
      <description><![CDATA[ARXIV：2503.22182V1公告类型：新 
摘要：电子商务彻底改变了零售，但其传统的工作流程效率仍然降低，与产品设计和制造库存相关的时间和资源成本很大。本文介绍了一个在阿里巴巴部署的新型系统，该系统利用AI生成的项目（AIGI）通过个性化的文本到图像生成来解决这些挑战，以进行电子商务产品设计。 AIGI启用了一种创新的业务模式，称为“在您制作之前出售它”，商人可以根据文本描述设计时尚物品并使用数字模型生成逼真的图像。只有当项目收到一定数量的订单时，商人才开始生产它们，这在很大程度上会降低对物理原型的依赖，从而加速上市时间。为了实现这种有希望的应用程序，我们确定了基本的关键科学挑战，即，捕获用户对多个生成的候选图像的群体级个性化偏好。为此，我们为扩散模型（即灌注）提出了个性化的组级偏好对齐框架。我们首先使用基于功能交叉的个性化插件来设计用于用户偏好估计的灌注奖励模型。然后，我们通过个性化的自适应网络开发灌注，以模拟用户之间的各种偏好，并得出小组级偏好优化目标，以捕获多个候选者之间的比较行为。离线和在线实验都证明了我们提出的算法的有效性。与人类设计的对应物相比，AI生成的项目的点击率和转换率都取得了超过13％的相对改进，从而验证了AI生成的项目对电子商务平台的革命性潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.22182</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用零击语言相似性转移提高低资源检索效果</title>
      <link>https://arxiv.org/abs/2503.22508</link>
      <description><![CDATA[ARXIV：2503.22508V1公告类型：新 
摘要：全球化和殖民化导致世界上绝大多数人仅使用一小部分语言（例如英语和法语）进行交流，不包括许多其他语言。这严重影响了许多现已贫困的脆弱或濒危语言的生存能力，例如Occitan和Sicilian。这些语言通常具有一些特征，例如语法和词典的元素，以及其他高资源语言，例如法语或意大利语。它们可以将它们聚集成具有不同程度的相互可理解性的语言品种组。当前的搜索系统通常不受许多这些低资源品种的培训，而是导致搜索用户以高资源语言表达其需求。当大多数信息内容用高资源语言表达，抑制低资源语言的检索时，此问题就会更加复杂。我们表明，当前的搜索系统在语言品种之间并不强大，严重影响了检索效率。因此，这些系统希望利用神经模型的能力弥合这些品种之间的差异。这可以使用户可以在低资源的品种中表达自己的需求，并在高资源中检索最相关的文档。为了解决这个问题，我们在成对的语言品种上提出了微调的神经排名，从而使它们接触到他们的语言相似之处。我们发现，这种方法可以改善直接训练模型的品种的性能，从而使这些模型正规化，以概括和表现更好，甚至在看不见的语言对。我们还探讨了这种方法是否可以在语言家族中转移，并观察到为未来研究打开大门的混合结果。]]></description>
      <guid>https://arxiv.org/abs/2503.22508</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多阶段微调对跨编码重新置换器的有效性</title>
      <link>https://arxiv.org/abs/2503.22672</link>
      <description><![CDATA[ARXIV：2503.22672V1公告类型：新 
摘要：最先进的跨编码器可以进行微调，以在通过重新排列中非常有效。跨编码器作为重新率的典型的微调过程需要大量的手动标记数据，一个对比度学习目标以及一组启发式采样的负面因素。相反，一种替代性微调的方法是教授模型，以使用蒸馏目标模仿高效的大语言模型的排名。这些微调策略可以单独或顺序应用。在这项工作中，我们系统地研究了在单个阶段独立进行微调或在两个阶段进行依次进行微调时，在点盘编码器的有效性。我们的实验表明，使用对比度学习对点进行微调微调的有效性确实与对多阶段方法进行微调的模型的有效性相当。代码可在https://github.com/fpezzuti/multistage-finetuning上进行复制。]]></description>
      <guid>https://arxiv.org/abs/2503.22672</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在建议之前先思考：释放顺序推荐的潜在推理能力</title>
      <link>https://arxiv.org/abs/2503.22675</link>
      <description><![CDATA[ARXIV：2503.22675V1公告类型：新 
摘要：顺序推荐（SEQREC）旨在通过从用户的历史互动中捕获顺序模式，在许多现实世界推荐系统中扮演至关重要的角色来预测下一项。但是，现有方法主要采用直接的前向计算范式，其中序列编码器的最终隐藏状态用作用户表示。我们认为，由于其计算深度有限，这种推论范式努力模拟用户偏好的复杂发展性质，并且缺乏对长尾项目的细微理解，从而导致了次优性能。为了解决此问题，我们提出\ textBf {reachec}，这是推荐系统的第一个推理时间计算框架，该框架通过隐式多步电推理增强用户表示。具体而言，ReareC自动调节性将序列的最后一个隐藏状态馈入顺序推荐剂，同时结合了特殊的推理位置嵌入，以使原始项目从多步推理空间中编码空间。此外，我们介绍了两种基于推理的研究方法，集合推理学习（ERL）和渐进式推理学习（PRL），以进一步有效利用Rearec的推理潜力。对五个公共现实世界数据集和不同SEQREC体系结构进行的广泛实验证明了我们提出的READEC的一般性和有效性。值得注意的是，事后分析表明，READEC显着将多个顺序推荐骨架的性能上限提高了约30 \％-50 \％。因此，我们认为这项工作可以为未来的推理计算研究开辟一条新的且有希望的途径，以进行连续推荐。]]></description>
      <guid>https://arxiv.org/abs/2503.22675</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Oaei-llm-t：用于理解本体匹配系统中LLM幻觉的Tbox基准数据集</title>
      <link>https://arxiv.org/abs/2503.21813</link>
      <description><![CDATA[ARXIV：2503.21813V1公告类型：交叉 
摘要：使用大语言模型（LLM）的下游任务不可避免地幻觉。尽管解决幻觉成为基于LLM的本体匹配（OM）系统的重大挑战，但我们引入了一个名为OAEI-LLM-T的新基准数据集。数据集从本体学评估计划（OAEI）中的Tbox（即模式匹配）数据集演变，捕获执行OM任务的不同LLMS的幻觉。这些特定于OM特异性的幻觉被仔细地分为两个主要类别和六个子类别。我们展示了数据集在构建基于LLM的OM系统的LLM排行榜和微调基础LLMS方面的实用性。]]></description>
      <guid>https://arxiv.org/abs/2503.21813</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于偏好的学习，并通过检索增强生成用于会话问题回答</title>
      <link>https://arxiv.org/abs/2503.22303</link>
      <description><![CDATA[ARXIV：2503.22303V1公告类型：交叉 
摘要：会话询问答案（CONSQA）涉及多个子任务，i）了解其上下文中不完整的问题，ii）检索相关信息，iii）以生成答案。这项工作提出了赞美，这是一种基于管道的Convqa方法，该方法为三个子任务中的每个子任务训练LLM适配器。由于在实践中无法使用标记的单个子任务的培训数据，因此，赞美以最终的答复性能作为反馈信号从其世代中学习，而无需人工干预，并将中间信息（如相关证据）视为弱标记的数据。我们通过对每个子任务的成功样本进行了对比，我们将直接优化优化。在我们的实验中，我们显示了这种训练范式的有效性：赞美显示了每个子任务的改进，并在流行的Convqa基准测试中实现了新的最先进的表现，通过获得15.5个百分点的确定点比基线的精度提高了15.5个百分点。]]></description>
      <guid>https://arxiv.org/abs/2503.22303</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Othink-MR1：通过动态增强学习刺激多模式的广义推理能力</title>
      <link>https://arxiv.org/abs/2503.16081</link>
      <description><![CDATA[arxiv：2503.16081v2公告类型：替换 - 交叉 
摘要：多模式的大语言模型（MLLM）已获得处理多种输入数据类型并在各种应用程序上产生相关的，上下文相关的输出的能力。虽然受监督的微调（SFT）一直是提高特定于任务优化的MLLM功能的主要方法，但它通常在培养重要的广义推理能力方面差不多。尽管加强学习（RL）在克服这些局限性方面具有巨大的希望，但它遇到了两个重大挑战：（1）其在多模式任务中的广义能力仍然很大程度上尚未探索，（2）其训练限制，包括持续的Kullback-Leibler-Leibler差异或Clamper divergence或Clamper策略，通常会导致下botsptimal bottleneplenepleleneplelenects。为了应对这些挑战，我们提出了Othink-Mr1，这是一个高级MLLM，配备了多模式任务的深刻理解和推理能力。具体而言，我们使用动态的Kullback-Leibler策略（GRPO-D）介绍了小组相对策略优化，该策略显着增强了增强学习（RL）的性能。对于QWEN2-VL-2B-INSTRUCTION，GRPO-D在两个改编的数据集上的同一任务评估中，相对提高了SFT的相对提高超过5.72％，超过GRPO的相对提高超过13.59％。此外，GRPO-D表现出显着的交叉任务概括能力，在交叉任务评估中，平均相对改善超过SFT 61.63％。这些结果表明，在一个多模式任务上接受GRPO-D训练的MLLM可以有效地转移到另一个任务中，从而强调了我们所提出的Othink-MR1模型的出色广义推理能力。]]></description>
      <guid>https://arxiv.org/abs/2503.16081</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMMORRF：多模式多语言模块化等级融合</title>
      <link>https://arxiv.org/abs/2503.20698</link>
      <description><![CDATA[ARXIV：2503.20698V2公告类型：替换 - 交叉 
摘要：视频固有地包含多种方式，包括视觉事件，文本叠加，声音和语音，所有这些对于检索都很重要。但是，最新的多模式模型（如广阔的语言和语言模型）是建立在视觉模型（VLM）上的，因此过于优先考虑视觉信号。检索基准测试基准通过专注于视觉查询并忽略其他方式进一步加剧了这一偏见。我们创建了一个搜索系统MMMORRF，该系统从视觉和音频模式中提取文本和功能，并将它们与新颖的模态感知的加权相互等级融合相结合。 MMMORRF既有效又有效，可以根据用户的信息需求而不是视觉描述性查询来搜索视频时实用。我们评估了MMMORRF在Multivent 2.0和TVR上，这两个多模式基准测试旨在旨在更具针对性的信息需求，并发现它比领先的多模式编码器改善了NDCG@20乘81％，在单一模式检索中提高了37％，这表明了整合多元化模态的价值。]]></description>
      <guid>https://arxiv.org/abs/2503.20698</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>马尼拉大都会中的健康寻求行为的网络密度分析：COVID-19的回顾性分析Google趋势数据</title>
      <link>https://arxiv.org/abs/2503.21162</link>
      <description><![CDATA[ARXIV：2503.21162V2公告类型：替换 - 交叉 
摘要：这项研究通过对Google趋势数据的网络密度分析，研究了马尼拉大都会，国家首都大都会，国家首都地区的COVID-19与健康寻求行为的时间方面。从2020年3月至2021年3月，使用15天和30天的滚动窗口检查了五个类别（英国症状，菲律宾症状，面部磨损，隔离和新正常）的总共15个关键字。该方法涉及使用在不同的网络（0.4、0.5、0.6、0.6、0.8）和分析的距离时使用距离距离相关系数构建网络图的方法系数。结果揭示了三个关键的发现：（1）阈值和网络指标之间的逆关系，表明较高的阈值提供了更有意义的关键字关系； （2）在最初的大流行月份，随后逐渐下降的网络连通性； （3）关键字关系中的不同模式，随着大流行在时间上的发展，从以政策为中心的搜索转变为更症状的查询。 30天的窗口分析显示，与15天的窗户相比，搜索活动更稳定，这表明立即搜索行为的相关性更强。这些见解有助于健康沟通，因为它强调了基于网络搜索行为从政府或私营部门传播战略和认真的信息的需求（例如，优先级以告知某些症状，而不是概述冠状病毒是什么）。]]></description>
      <guid>https://arxiv.org/abs/2503.21162</guid>
      <pubDate>Mon, 31 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>