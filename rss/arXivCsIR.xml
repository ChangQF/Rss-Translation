<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Thu, 25 Jan 2024 03:14:39 GMT</lastBuildDate>
    <item>
      <title>使用文本挖掘和语义图完成构建上下文知识图以提供个性化学习建议。 （arXiv：2401.13609v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13609</link>
      <description><![CDATA[在上下文中对学习对象 (LO) 进行建模使学习者能够
从基本的记忆水平学习目标提升到更高层次
一个，即具有应用和分析目标的级别。尽管
分层数据模型通常用于数字学习平台，使用
基于图的模型能够表示这些平台中 LO 的上下文。
这为学习路径的个性化推荐奠定了基础。
本文将层次数据模型转化为知识
介绍并评估了使用文本挖掘的 LO 的图 (KG) 模型。我们
利用自定义文本挖掘管道来挖掘之间的语义关系
专家策划的分层模型的元素。我们评估KG结构
使用图质量控制指标进行关系提取以及比较
算法语义与专家定义的相似性。结果显示
知识图谱中的关系在语义上与定义的关系相当
领域专家，并且所提出的知识图谱改进了领域专家的表示和链接
通过增加图社区和介数来了解 LO 的上下文
中心性。
]]></description>
      <guid>http://arxiv.org/abs/2401.13609</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>更好地理解开放域会话搜索中的用户满意度。 （arXiv：2204.02659v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2204.02659</link>
      <description><![CDATA[随着对话式搜索的日益普及，如何评估
会话式搜索系统的性能已成为一个重要问题
在IR社区。现有的对话式搜索评估工作可以
主要分为两类：（1）基于
语义相似性（例如 BLUE、METEOR 和 BERTScore），或 (2) 直接
使用传统方法评估系统的响应排名性能
搜索方法（例如 nDCG、RBP 和 nERR）。然而，这些方法要么忽略
用户的信息需求或忽略用户的混合主动性
对话式搜索。这就提出了如何准确建模用户的问题
对话式搜索场景中的满意度。由于明确询问用户
提供满意度反馈很困难，传统的 IR 研究通常
依赖克兰菲尔德范式（即第三方注释）和用户行为
建模来估计用户在搜索中的满意度。然而，可行性和
这两种方法的有效性尚未得到充分探讨
对话式搜索。在本文中，我们深入探讨了评估
从用户满意度的角度进行对话式搜索。我们建立一个
新颖的会话式搜索实验平台并构建中文
包含丰富注释的开放域会话搜索行为数据集
和搜索行为数据。我们还收集第三方满意度标注
在会话级别和轮次级别上，研究该方案的可行性
对话式搜索场景中的克兰菲尔德范式。实验结果
显示出用户之间的一些一致性和相当大的差异
满意度标注和第三方标注。我们还建议对话
用于捕获会话级用户的连续或结束行为模型 (DCEBM)
基于回合级别信息的满意度。
]]></description>
      <guid>http://arxiv.org/abs/2204.02659</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是推荐系统的零样本排名器。 （arXiv：2305.08845v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2305.08845</link>
      <description><![CDATA[最近，大型语言模型 (LLM)（例如 GPT-4）已经证明
令人印象深刻的通用任务解决能力，包括潜力
方法推荐任务。沿着这一研究方向，这项工作旨在
研究作为推荐者排名模型的法学硕士的能力
系统。我们首先将推荐问题形式化为条件排名
任务，将顺序交互历史视为条件和项目
由其他候选生成模型检索为候选。为了解决
LLM的排名任务，我们精心设计提示模板并进行
对两个广泛使用的数据集进行了广泛的实验。我们表明法学硕士有
有前途的零样本排名能力，但（1）难以感知顺序
历史交互，并且 (2) 可能会因受欢迎程度或项目位置而产生偏差
在提示中。我们证明这些问题可以通过使用来缓解
特别设计的提示和引导策略。配备这些
洞察力，零样本法学硕士甚至可以挑战传统的推荐模型
当多个候选生成器检索对候选进行排名时。这
代码和处理后的数据集可在
https://github.com/RUCAIBox/LLMRank。
]]></description>
      <guid>http://arxiv.org/abs/2305.08845</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:38 GMT</pubDate>
    </item>
    <item>
      <title>使用基于指令的模型的细粒度合约 NER。 （arXiv：2401.13545v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13545</link>
      <description><![CDATA[最近，基于指令的技术在以下方面取得了重大进展：
提高小样本学习场景中的性能。他们通过以下方式实现这一目标
弥合预训练语言模型和微调之间的差距
具体的下游任务。尽管取得了这些进步，大型计算机的性能
信息提取任务（如命名实体）中的语言模型 (LLM)
使用提示或指令的识别（NER）仍然达不到要求
监督基线。造成这种性能差距的原因可以归结为
NER 和 LLM 之间的根本差异。 NER 本质上是一个序列
标记任务，模型必须将实体类型标签分配给个体
句子中的标记。相比之下，法学硕士被设计为文本生成
任务。语义标签和文本生成之间的区别导致
表现不佳。在本文中，我们将 NER 任务转化为
法学硕士可以轻松调整的文本生成任务。这涉及到
通过特定于任务的说明和答案选择来增强源句子，
允许识别自然中的实体及其类型
语言。我们通过整合监督学习来利用法学硕士的优势
在他们之内。这一联合战略的目标是提高
法学硕士负责 NER 等提取任务，同时解决幻觉问题
LLM 生成的内容中经常出现的问题。新颖的语料库合约 NER
包括七个经常观察到的合同类别，包括指定的
与 18 种不同法律实体类型相关的实体与
我们的基线模型。我们的模型和数据集可供社区使用
未来的研究 * .
]]></description>
      <guid>http://arxiv.org/abs/2401.13545</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>推荐中公平提供者曝光的成本敏感元学习策略。 （arXiv：2401.13566v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13566</link>
      <description><![CDATA[在设计推荐服务时，重要的是要考虑到
所有内容提供商的利益，不仅包括新人，还包括
少数民族人口群体。在各种情况下，某些提供商团体发现
他们自己在项目目录中的代表性不足，这种情况可能会影响
推荐结果。因此，平台所有者经常寻求监管
这些提供商组在推荐列表中的曝光情况。在本文中，我们
提出一种新颖的成本敏感方法来保证这些目标
成对推荐模型中的暴露水平。这种方法量化了，
从而减轻了数量之间的差异
分配给各组的建议及其在项目目录中的贡献，
在公平原则下。我们的结果表明，这种方法，同时
将群体暴露与其分配的水平保持一致，不会影响
原始推荐实用程序。源代码和预处理数据可以
检索于
https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure。
]]></description>
      <guid>http://arxiv.org/abs/2401.13566</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:37 GMT</pubDate>
    </item>
    <item>
      <title>SciMMIR：科学多模态信息检索基准。 （arXiv：2401.13478v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13478</link>
      <description><![CDATA[多模态信息检索（MMIR）是一个快速发展的领域，其中
取得了重大进展，特别是在图像-文本配对方面，
高级表示学习和跨模态对齐研究。
然而，当前评估图像文本中 MMIR 性能的基准
科学领域内的配对显示出显着的差距，其中图表和表格
用学术语言描述的图像通常不起重要作用。
为了弥补这一差距，我们开发了专门的科学 MMIR (SciMMIR)
通过利用开放获取的论文集提取相关数据来进行基准测试
到科学领域。该基准测试包含 530K 精心策划的
图像-文本对，从带有详细标题的图形和表格中提取
科学文献。我们进一步用两级注释图像-文本对
子集-子类别层次结构注释，以方便更全面的
基线评估。我们进行了零样本和微调评估
突出的多模态图像描述和视觉语言模型，例如
剪辑和BLIP。我们的分析为 MMIR 在科学领域提供了重要见解
域，包括预训练和微调设置的影响以及
视觉和文本编码器的影响。我们所有的数据和检查点都是
公开地址：https://github.com/Wusiwei0410/SciMMIR。
]]></description>
      <guid>http://arxiv.org/abs/2401.13478</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>TPRF：一种基于 Transformer 的伪相关反馈模型，用于高效且有效的检索。 （arXiv：2401.13509v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13509</link>
      <description><![CDATA[本文考虑了密集的伪相关反馈（PRF）方法
资源受限环境（例如廉价云环境）中的检索器
实例或嵌入式系统（例如智能手机和智能手表），其中
内存和 CPU 有限，并且不存在 GPU。为此，我们提出一个
基于变压器的 PRF 方法 (TPRF)，其内存占用要小得多
与其他采用的深度语言模型相比，推理时间更快
PRF 机制，具有边际有效性损失。 TPRF 学习如何
有效结合密集通道的相关反馈信号
交涉。具体来说，TPRF提供了一种建模机制
查询和相关反馈信号之间的关系和权重。
该方法与所使用的特定密集表示无关，因此可以
一般适用于任何密集的猎犬。
]]></description>
      <guid>http://arxiv.org/abs/2401.13509</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:36 GMT</pubDate>
    </item>
    <item>
      <title>具有自适应参考数据的去中心化协作学习，用于设备上 POI 推荐。 （arXiv：2401.13448v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13448</link>
      <description><![CDATA[在基于位置的社交网络中，兴趣点 (POI) 推荐
帮助用户发现有趣的地方。有一种趋势是从
基于云的模型到设备上的隐私保护建议
减少对服务器的依赖。由于本地用户-项目交互的稀缺
对于单个设备，仅依靠本地实例是不够的。
协作学习（CL）的出现是为了促进用户之间的模型共享，其中
参考数据是一个中介，允许用户交换他们的软
决策而不直接共享他们的私人数据或参数，确保
隐私并从协作中受益。然而，现有的基于 CL 的
推荐通常对所有用户使用单一参考。参考数据
考虑到不同的用户，对一个用户有价值可能对另一个用户有害
优先。用户可能不会对外部项目提供有意义的软决策
他们的兴趣范围。因此，对所有数据使用相同的参考数据
合作可能会阻碍知识交流并导致次优结果
表现。为了解决这一差距，我们引入了去中心化协作
使用自适应参考数据学习 (DARD) 框架，该框架打造了自适应
有效用户协作的参考数据。它首先生成一个
具有变换和概率的脱敏公共参考数据池
数据生成方法。对于每个用户，选择自适应参考
通过训练损失跟踪和影响函数来并行执行数据。
本地模型使用个人私有数据进行训练，并与
地理和语义邻居。两人合作期间
用户，他们根据一组组合的适应性交换软决策
参考数据。我们对两个真实世界数据集的评估突出了 DARD
推荐性能的优越性并解决推荐的稀缺性
可用的参考数据。
]]></description>
      <guid>http://arxiv.org/abs/2401.13448</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>SpeechDPR：用于开放域口语问答的端到端口语段落检索。 （arXiv：2401.13463v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.13463</link>
      <description><![CDATA[语音问答 (SQA) 对于机器回复用户的问题至关重要
通过在给定的口头段落中找到答案范围来提出问题。 SQA 已
以前在没有 ASR 的情况下实现的以避免识别错误
词汇外（OOV）问题。然而，现实世界的问题
开放域SQA（openSQA），其中机器需要首先检索
另外，可能包含来自口头档案的答案的段落，
从未被考虑过。本文提出了第一个已知的端到端框架，
语音密集通道检索器 (SpeechDPR)，用于
openSQA 问题。 SpeechDPR 通过以下方式学习句子级语义表示
从无监督 ASR (UASR) 的级联模型中提取知识，
文本密集检索器（TDR）。不需要手动转录的语音数据。
初步实验表明，其性能与级联模型相当
UASR 和 TDR，当 UASR 较差时明显更好，验证了这一点
方法对语音识别错误更加鲁棒。
]]></description>
      <guid>http://arxiv.org/abs/2401.13463</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在联合在线学习排名中忘记客户？ （arXiv：2401.13410v1 [cs.CR]）</title>
      <link>http://arxiv.org/abs/2401.13410</link>
      <description><![CDATA[数据保护立法，例如欧盟的通用数据保护
法规 (GDPR) 确立了 \textit{被遗忘的权利}：用户
（客户）可以要求使用其数据做出的贡献从
学习到的模型。在本文中，我们研究如何消除
参与联合在线排名学习 (FOLTR) 系统的客户。
在 FOLTR 系统中，排名器是通过将本地更新聚合到
全球排名模型。本地更新是通过在线方式学习的
客户端级别使用发生在内部的查询和隐式交互
那个特定的客户。通过这样做，每个客户端的本地数据不会与
其他客户端或使用集中式搜索服务，同时
客户可以从有效的全球排名模型中受益
联盟中每个客户的贡献。

在本文中，我们研究了一种有效且高效的忘却方法，该方法可以
删除客户的贡献而不影响整体排名
有效性，并且无需从头开始重新训练全球排名器。 A
关键的挑战是如何衡量模型是否忘记了
来自已请求删除的客户 $c^*$ 的贡献。为此，我们
指示 $c^*$ 执行中毒攻击（向此客户端更新添加噪音）
然后我们衡量攻击的影响是否在以下情况下减轻：
忘记学习的过程已经发生。通过四个数据集的实验，我们
展示遗忘策略的有效性和效率
不同的参数设置组合。
]]></description>
      <guid>http://arxiv.org/abs/2401.13410</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>查询排名中文档组的曝光预测。 （arXiv：2401.13434v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13434</link>
      <description><![CDATA[信息检索系统的主要目标是为用户提供
与用户查询最相关的文档。为此，现代IR
系统通常会部署一个重新排序管道，其中一组文档被
通过轻量级第一阶段检索过程检索，然后通过
更有效但昂贵的模型。然而，重新排名的成功
管道很大程度上依赖于第一阶段检索的性能，
因为在重新排名阶段通常不会识别新文档。
此外，这可能会影响特定群体的暴露量
文件，例如来自特定人口群体的文件，可以接收
在最终的排名中。例如，风险敞口的公平分配变得更加
如果第一阶段检索返回的数据太少，则具有挑战性或不可能
来自某些组的文档，因为组文档的数量
排名对曝光的影响比对文档位置的影响更大。有了这个
请注意，预测一组人的暴露量是有益的
文档可能会在第一阶段检索的结果中收到
流程，以确保有足够数量的文件
包括来自每个组的。在本文中，我们介绍了新任务
查询曝光预测（QEP）。具体来说，我们提出第一种方法
用于预测文档组将发生的暴露分布
接收给定的查询。我们的新方法称为 GEP，使用词法
来自各个文件组的信息来估计暴露
小组将获得排名。我们在 TREC 2021 和 2022 上的实验
Fair Ranking Track 测试集显示我们提出的 GEP 方法结果
曝光预测比预测准确率高达 40%
适应现有查询性能预测和资源分配
接近。
]]></description>
      <guid>http://arxiv.org/abs/2401.13434</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:34 GMT</pubDate>
    </item>
    <item>
      <title>是时候了：将时间性纳入检索增强语言模型。 （arXiv：2401.13222v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13222</link>
      <description><![CDATA[网络是全球知识存储库，被数十亿人使用
人们搜索信息。确保用户收到最相关的信息
和最新信息，特别是在存在多个版本的情况下
不同时间点的网络内容仍然是一个严峻的挑战
信息检索。最近，这一挑战因
增加使用在维基百科或网络内容上训练的问答工具
并由大型语言模型（LLM）\citep{chatgpt}提供支持，该模型已
被发现编造信息（或幻觉），并且此外还被证明
与信息的时间维度作斗争。甚至猎犬
增强语言模型 (RALM) 包含文档数据库
减少LLM幻觉无法正确处理时态查询。这
导致 RALM 响应诸如“谁赢得了比赛”之类的查询的情况
温布尔登锦标赛？”，通过检索与温布尔登相关的文档段落
但无法根据它们的新近程度来区分它们
是。

在本文中，我们提出并评估了 TempRALM，一种时间感知的方法
带有少量学习扩展的检索器增强语言模型（RALM），
它考虑了语义和时间相关的文档
相对于给定的查询，而不是仅仅依赖于语义相似性。我们
表明我们的方法可将性能提高高达 74%
基线 RALM 模型，无需模型预训练、重新计算或
替换 RALM 文档索引，或添加其他计算密集型
元素。
]]></description>
      <guid>http://arxiv.org/abs/2401.13222</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>用于早期识别和分类暗网站的大数据架构。 （arXiv：2401.13320v1 [cs.DC]）</title>
      <link>http://arxiv.org/abs/2401.13320</link>
      <description><![CDATA[暗网因其与非法活动的关联而臭名昭著
并且越来越需要系统来自动监控这一点
空间。本文提出了一种端到端的可扩展架构，用于早期
识别新的 Tor 站点并对其内容进行日常分析。这
解决方案是使用开源大数据堆栈构建的，用于数据服务
Kubernetes、Kafka、Kubeflow、MinIO，不断发现洋葱
不同来源的地址（威胁情报、代码存储库、网络 Tor
网关和 Tor 存储库），从 Tor 下载 HTML 并
使用 MinHash LSH 对内容进行重复数据删除，并使用 BERTopic 进行分类
建模（SBERT 嵌入、UMAP 降维、HDBSCAN 文档
聚类和 c-TF-IDF 主题关键字）。 93天内，系统识别出
80,049 个洋葱服务并描述了其中 90% 的特征，应对了这一挑战
Tor 波动性。发现大量重复内容，其中
只有 6.1% 的独特网站。从黑暗网站的 HTML 文件中，31 个不同的
低级主题被提取、手动标记，并分为 11 个高级主题
主题。最受欢迎的五个内容包括性和暴力内容，
存储库、搜索引擎、梳理、加密货币和市场。
在实验过程中，我们确定了 14 个位点，其中有 13,946 个克隆，它们共享一个
每天的镜像率非常相似，表明存在广泛的共同点
网络钓鱼网络。在相关工作中，本研究是最
基于迄今为止的主题的洋葱服务的代表性特征。
]]></description>
      <guid>http://arxiv.org/abs/2401.13320</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>使用预检索查询预测器预测 IR 个性化性能。 （arXiv：2401.13351v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2401.13351</link>
      <description><![CDATA[个性化通常可以提高查询的性能，但在少数情况下
有时它也可能会伤害它。如果我们能够预测并因此禁用
针对这些情况进行个性化设置，整体性能会更高
用户将对个性化系统更加满意。我们使用一些
最先进的预检索查询性能预测器并提出了一些
其他包括用于先前目的的用户个人资料信息。我们
研究这些预测变量之间的相关性以及预测变量之间的差异
个性化和原始查询。我们还使用分类和
回归技术来改进结果并最终达到比
最大理想性能的三分之一。我们认为这是一个好的开始
在这个研究领域内的点，这当然需要更多的努力和
改进。
]]></description>
      <guid>http://arxiv.org/abs/2401.13351</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:33 GMT</pubDate>
    </item>
    <item>
      <title>进入交火：评估使用语言模型众包枪支暴力报告。 （arXiv：2401.12989v1 [cs.CL]）</title>
      <link>http://arxiv.org/abs/2401.12989</link>
      <description><![CDATA[枪支暴力是一个紧迫且日益严重的人权问题，影响到近乎
社会结构的各个方面，从医疗保健和教育到
心理学和经济。有关枪支事件的可靠数据至关重要
制定更有效的公共政策和应急响应。但是，那
缺乏全面的数据库和现场调查的风险阻碍了
大多数国家的人权组织无法收集所需的数据。这里，
我们与巴西人权组织合作开展系统性调查
评估语言模型以协助监控现实世界的枪支
来自社交媒体数据的事件。我们提出了一个经过微调的基于 BERT 的模型
Twitter（现在是 X）上的文本，用于区分枪支暴力报道与普通报道
葡萄牙语文本。我们的模型获得了 0.97 的高 AUC 分数。然后我们
将我们的模型合并到 Web 应用程序中并进行实时测试
干涉。我们研究并采访了巴西分析师，他们不断
对社交媒体文本进行事实核查，以识别新的枪支暴力事件。定性
评估表明我们的解决方案帮助所有分析师更多地利用他们的时间
有效地扩大了他们的搜索能力。定量评估显示
我们模型的使用与更多分析师的互动有关
在线用户举报枪支暴力。综上所述，我们的研究结果表明
现代自然语言处理技术可以帮助支持以下工作
人权组织。
]]></description>
      <guid>http://arxiv.org/abs/2401.12989</guid>
      <pubDate>Thu, 25 Jan 2024 03:14:32 GMT</pubDate>
    </item>
    </channel>
</rss>