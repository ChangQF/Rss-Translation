<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 02 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>评估表格表示法以回答文档中表格中的问题：使用 3GPP 规范的案例研究</title>
      <link>https://arxiv.org/abs/2408.17008</link>
      <description><![CDATA[arXiv:2408.17008v1 公告类型：新
摘要：随着文档语料库在问答中的广泛使用，一个与技术文档特别相关的重要方面是从散布着文本的表格中提取信息的能力。这方面的主要挑战是，与自由流动​​的文本或孤立的表格集不同，表格在相关块方面的表示并不明显。我们进行了一系列实验，检查了散布着文本的表格数据的各种表示，以了解不同表示的相对优势。我们选择了第三代合作伙伴计划 (3GPP) 文档语料库，因为它们大量散布着表格。我们创建了专家策划的问答数据集来评估我们的方法。我们得出结论，每个单元格中包含相应表头信息的行级表示可以提高检索的性能，从而利用表格数据中存在的结构信息。]]></description>
      <guid>https://arxiv.org/abs/2408.17008</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解用户：基于意图的排名数据集</title>
      <link>https://arxiv.org/abs/2408.17103</link>
      <description><![CDATA[arXiv:2408.17103v1 公告类型：新
摘要：随着信息检索系统的不断发展，对这些系统进行准确的评估和基准测试变得至关重要。网络搜索数据集（例如 MS MARCO）主要提供简短的关键字查询，而没有附带意图或描述，这对理解潜在的信息需求构成了挑战。本文提出了一种扩充此类数据集以注​​释信息查询描述的方法，重点关注两个著名的基准数据集：TREC-DL-21 和 TREC-DL-22。我们的方法涉及利用最先进的 LLM 来分析和理解基准数据集中各个查询中的隐含意图。通过提取关键语义元素，我们为这些查询构建了详细且上下文丰富的描述。为了验证生成的查询描述，我们采用众包作为一种可靠的手段，以获得关于描述的准确性和信息量的不同人类观点。此信息可用作排名、查询重写或其他任务的评估集。]]></description>
      <guid>https://arxiv.org/abs/2408.17103</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的多任务快速推荐调整</title>
      <link>https://arxiv.org/abs/2408.17214</link>
      <description><![CDATA[arXiv:2408.17214v1 公告类型：new 
摘要：随着业务场景的扩展，现实的推荐系统在处理多任务学习框架中不断涌现的新任务时面临着挑战。在本文中，我们尝试在处理新任务时提高多任务推荐的泛化能力。我们发现在大多数多任务学习方法中，联合训练会提高新任务的性能，但总会对现有任务产生负面影响。此外，这种对新任务的重新训练机制增加了训练成本，限制了多任务推荐模型的泛化能力。基于这种考虑，我们旨在设计一种合适的任务间共享机制，同时保持新任务学习中的联合优化效率。提出了一种新颖的两阶段快速调整 MTL 框架（MPT-Rec），以解决多任务推荐系统中的任务无关性和训练效率问题。具体来说，我们在多任务预训练阶段解开任务特定和任务共享的信息，然后使用任务感知提示将知识从其他任务有效地转移到新任务。通过冻结预训练任务中的参数，MPT-Rec 解决了新任务可能带来的负面影响，并大大降低了训练成本。在三个真实数据集上进行的大量实验证明了我们提出的多任务学习框架的有效性。与 SOTA 多任务学习方法相比，MPT-Rec 取得了最佳性能。此外，它保持了可比的模型性能，但在新任务学习中大大提高了训练效率（即在完整训练方式中最多使用 10% 的参数）。]]></description>
      <guid>https://arxiv.org/abs/2408.17214</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模拟工作流程的元数据实践</title>
      <link>https://arxiv.org/abs/2408.17309</link>
      <description><![CDATA[arXiv:2408.17309v1 公告类型：新
摘要：计算机模拟是科学知识生成的重要支柱。理解、重现和探索模拟结果依赖于跟踪和组织描述数值实验的元数据。然而，用于理解现实世界系统的模型以及模拟它们所需的计算机器通常很复杂，并且会产生大量异构元数据。在这里，我们介绍了获取和处理元数据的一般做法，这些做法与软件和硬件无关，对用户来说非常灵活。这些包括两个步骤：1）记录和存储原始元数据，2）选择和构造元数据。作为概念验证，我们开发了 Archivist，这是一个 Python 工具来帮助完成第二步，并使用它将我们的实践应用于神经科学和水文学的不同高性能计算用例。我们的实践和 Archivist 可以轻松应用于现有工作流程，而无需进行大量重组。它们支持可持续的数值工作流程，促进基于通用模拟的研究中的可重复性和数据重用。]]></description>
      <guid>https://arxiv.org/abs/2408.17309</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>并非所有视频都会过时：通过学习消除发布间隔偏差来实现短视频推荐</title>
      <link>https://arxiv.org/abs/2408.17332</link>
      <description><![CDATA[arXiv:2408.17332v1 公告类型：新
摘要：短视频推荐系统通常对最近发布的视频表现出偏见。然而，并不是所有的视频都会过时；某些经典视频仍然可以吸引用户的注意力。这种时间维度上的偏见可能会因用户和视频之间的匹配模型而进一步加剧，因为该模型是从预先存在的交互中学习的。从真实数据中，我们观察到不同的视频在吸引用户注意力方面对新近度有不同的敏感度。我们基于因果图建模短视频推荐的分析表明，发布间隔是一个混杂因素，在用户和视频之间建立了后门路径。为了解决这种混杂效应，我们提出了一种与模型无关的因果架构，称为学习消除发布间隔偏差 (LDRI)。LDRI 可以联合学习匹配模型和视频新近度敏感度感知器。在推理阶段，我们应用了后门调整，通过干预每个视频有效地阻止了后门路径。在两个基准上进行的大量实验表明，LDRI 始终优于骨干模型，并且与最先进的模型相比表现出优异的性能。额外的综合分析证实了 LDRI 的去混杂能力。]]></description>
      <guid>https://arxiv.org/abs/2408.17332</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>rerankers：一个用于统一排名方法的轻量级 Python 库</title>
      <link>https://arxiv.org/abs/2408.17344</link>
      <description><![CDATA[arXiv:2408.17344v1 公告类型：新
摘要：本文介绍了 rerankers，这是一个 Python 库，它为最常用的重新排序方法提供了一个易于使用的界面。重新排序是许多检索流程不可或缺的组成部分；然而，它存在许多方法，依赖于不同的实现方法。 \texttt{rerankers} 将这些方法统一到一个用户友好的界面中，允许从业者和研究人员只需更改一行 Python 代码即可探索不同的方法。此外，rerankers 确保其实现尽可能少地依赖，并尽可能重复使用原始实现，从而保证我们简化的界面与更复杂的界面相比不会降低性能。完整的源代码和受支持模型列表会定期更新，可在 https://github.com/answerdotai/rerankers 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.17344</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>纵向模块化，链接流的模块化</title>
      <link>https://arxiv.org/abs/2408.16877</link>
      <description><![CDATA[arXiv:2408.16877v1 公告类型：交叉 
摘要：时间网络通常用于模拟现实生活中的现象。当这些现象代表交互并以细粒度的时间分辨率捕获时，它们被建模为链接流。社区检测是一项重要的网络分析任务。虽然存在许多用于静态网络的方法，并且已经开发了一些用于表示为快照序列的时间网络的方法，但很少有作品可以处理链接流。本文介绍了著名的模块化质量函数对链接流的首次改编。与现有方法不同，它与分析的时间尺度无关。在介绍质量函数及其与现有静态和动态模块化定义的关系之后，我们通过实验展示了它与动态社区评估的相关性。]]></description>
      <guid>https://arxiv.org/abs/2408.16877</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 EigenTrust 的实用拜占庭容错协议的零信任架构区块链原型模型，用于管理分散式临床试验</title>
      <link>https://arxiv.org/abs/2408.16885</link>
      <description><![CDATA[arXiv:2408.16885v1 公告类型：交叉 
摘要：COVID-19 大流行迫使去中心化临床试验 (DCT) 应运而生，因为这样可以保留患者、加速试验、提高数据可访问性、实现虚拟护理并通过集成系统促进无缝通信。然而，在 DCT 中集成系统会使临床数据面临潜在的安全威胁，使其在任何阶段都容易被盗，存在很高的协议偏差风险和监控问题。为了缓解这些挑战，区块链技术充当了一个安全框架，充当去中心化账本，通过建立零信任架构来创建不可变的环境，其中数据在经过验证之前被视为不可信。结合支持物联网 (IoT) 的可穿戴设备，区块链可在 DCT 自动化和操作期间确保临床试验数据在私有区块链上的传输。本文提出了零信任架构区块链 (z-TAB) 的原型模型，用于在 DCT 运营管理期间集成患者生成的临床试验数据。基于 EigenTrust 的实用拜占庭容错 (T-PBFT) 算法已被纳入共识协议，利用 Hyperledger Fabric。此外，还集成了物联网 (IoT)，以简化区块链平台内利益相关者之间的数据处理。已经进行了严格的评估以评估系统的质量。]]></description>
      <guid>https://arxiv.org/abs/2408.16885</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别和聚类 PvP 游戏中团队组成的对抗关系以实现有效的平衡分析</title>
      <link>https://arxiv.org/abs/2408.17180</link>
      <description><![CDATA[arXiv:2408.17180v1 公告类型：交叉 
摘要：如何在游戏设置中量化平衡？这个问题对于游戏设计师来说至关重要，尤其是在玩家对战 (PvP) 游戏中，分析预定义团队组合之间的强度关系（例如多人在线战斗竞技场 (MOBA) 游戏中的英雄组合或纸牌游戏中的卡组）对于增强游戏玩法和实现平衡至关重要。我们已经开发了两种超越简单胜率的高级措施来量化零和竞争场景中的平衡。这些措施来自胜利值估计，它采用通过 Bradley-Terry 模型的强度评级近似值和通过矢量量化的反关系近似值，显着降低了与传统胜利值估计相关的计算复杂性。在这些模型的整个学习过程中，我们识别出有用的组合类别并确定它们的反关系，与人类玩家的体验保持一致，而不需要特定的游戏知识。我们的方法依赖于一种简单的技术，即在极小的状态空间中使用确定性矢量量化过程来提高离散表示中的码本利用率。我们的框架已在流行的在线游戏中得到验证，包括《帝国时代 II》、《炉石传说》、《荒野乱斗》和《英雄联盟》。在这些游戏中观察到的强度关系的准确性与传统的成对获胜值预测相当，同时也为分析提供了更易于管理的复杂性。最终，我们的研究结果有助于更深入地了解 PvP 游戏动态，并提出了一种可显着改善游戏平衡评估和设计的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.17180</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>认知偏差在推荐生态系统中的重要性</title>
      <link>https://arxiv.org/abs/2408.12492</link>
      <description><![CDATA[arXiv:2408.12492v2 公告类型：替换 
摘要：几十年来，心理学、社会学和行为经济学一直在研究认知偏见。传统上，它们被认为是一种消极的人类特征，分别导致决策能力低下、刻板印象强化或可被利用来操纵消费者。我们认为认知偏见也体现在推荐生态系统的不同部分和推荐过程的不同阶段。更重要的是，我们对这种传统的对认知偏见的不利观点提出异议，并声称某些认知偏见在推荐系统中是有益的。具体来说，我们提供经验证据表明，在推荐管道的各个组成部分中都可以观察到特征积极效应、宜家效应和文化同质性等偏见，包括输入数据（如评级或辅助信息）、推荐算法或模型（以及因此推荐的项目）以及用户与系统的交互。在三个涵盖招聘和娱乐领域的小型实验中，我们研究了上述偏见的普遍性。我们最终提倡不带偏见地考虑认知偏差，以改进用户和项目模型以及推荐算法。]]></description>
      <guid>https://arxiv.org/abs/2408.12492</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SynDL：用于段落检索的大规模合成测试集</title>
      <link>https://arxiv.org/abs/2408.16312</link>
      <description><![CDATA[arXiv:2408.16312v2 公告类型：替换 
摘要：大规模测试集在信息检索 (IR) 研究中起着至关重要的作用。然而，根据 Cranfield 范式和对公开数据集的研究，现有的信息检索研究通常是在小规模数据集上进行的，这些数据集依赖于人类评估者进行相关性判断 - 这是一个耗时且昂贵的过程。最近的研究表明，大型语言模型 (LLM) 能够以极低的成本产生可靠的相关性判断，同时具有人类的准确性。在本文中，为了解决缺少大规模临时文档检索数据集的问题，我们通过额外的语言模型合成标签扩展了 TREC 深度学习轨道 (DL) 测试集，以使研究人员能够大规模测试和评估他们的搜索系统。具体来说，这样的测试集包括前几年轨道的 1,900 多个测试查询。我们将系统评估与过去几年的人工标签进行比较，发现我们综合创建的大规模测试集合可以产生高度相关的系统排名。]]></description>
      <guid>https://arxiv.org/abs/2408.16312</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越“一刀切”：用于嵌入模型选择的多领域、多任务框架</title>
      <link>https://arxiv.org/abs/2404.00458</link>
      <description><![CDATA[arXiv:2404.00458v2 公告类型：replace-cross 
摘要：本立场文件提出了一种系统方法来开发一个框架，以帮助选择最有效的自然语言处理 (NLP) 任务嵌入模型，以应对专有和开源编码器模型激增所带来的挑战。]]></description>
      <guid>https://arxiv.org/abs/2404.00458</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用结构化知识库增强大型语言模型的元数据管理</title>
      <link>https://arxiv.org/abs/2404.05893</link>
      <description><![CDATA[arXiv:2404.05893v4 公告类型：replace-cross 
摘要：元数据在确保数据集的可查找性、可访问性、互操作性和可重用性方面起着至关重要的作用。本文研究了大型语言模型 (LLM)，特别是 GPT-4，在提高对元数据标准的遵守方面的潜力。我们对来自 NCBI BioSample 存储库的 200 条描述与肺癌有关的人类样本的随机数据记录进行了实验，评估了 GPT-4 建议编辑以遵守元数据标准的能力。我们通过同行评审流程计算了字段名称-字段值对的遵守准确度，并观察到对标准数据字典的遵守率从 79% 提高到 80%（p&lt;0.5）。然后，我们以 CEDAR 模板的文本描述的形式向 GPT-4 提供域信息，并记录了从 79% 到 97% 的显着提高（p&lt;0.01）。这些结果表明，虽然 LLM 可能无法在无人协助的情况下纠正遗留元数据以确保符合标准，但当与结构化知识库集成时，它们确实有望用于自动元数据管理]]></description>
      <guid>https://arxiv.org/abs/2404.05893</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>感知相似性用于衡量博弈中的决策风格和政策多样性</title>
      <link>https://arxiv.org/abs/2408.06051</link>
      <description><![CDATA[arXiv:2408.06051v2 公告类型：replace-cross 
摘要：定义和衡量决策风格（也称为游戏风格）在游戏中至关重要，这些风格反映了广泛的个性和多样性。然而，找到一种普遍适用的衡量这些风格的标准是一项挑战。基于游戏风格距离（第一个基于游戏屏幕和原始动作来衡量游戏风格相似性的无监督指标），我们引入了三项增强功能来提高准确性：具有不同状态粒度的多尺度分析、植根于心理学的感知内核以及利用交并法进行有效评估。这些创新不仅提高了测量精度，而且还提供了对人类对相似性的认知的见解。在两款赛车游戏和七款 Atari 游戏中，我们的技术显着提高了零样本游戏风格分类的精度，在少于 512 个观察-动作对的情况下实现了超过 90% 的准确率，这还不到这些游戏的一半。此外，我们对 2048 和围棋的实验证明了离散游戏风格测量在益智和棋盘游戏中的潜力。我们还开发了一种使用这些测量来评估决策多样性的算法。我们的发现改进了端到端游戏分析的测量和多样化游戏风格的人工智能的发展。]]></description>
      <guid>https://arxiv.org/abs/2408.06051</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>