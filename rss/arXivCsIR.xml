<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 31 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>GleanVec：通过极简非线性降维加速向量搜索</title>
      <link>https://arxiv.org/abs/2410.22347</link>
      <description><![CDATA[arXiv:2410.22347v1 公告类型：新
摘要：嵌入模型可以生成高维向量，其相似性反映了语义亲和力。因此，准确及时地检索与给定查询相似的大型集合中的向量已成为广泛应用的关键组成部分。特别是，跨模态检索（例如，使用文本查询查找图像）正在迅速发展。在这里，实现高精度具有挑战性，因为查询通常具有与数据库向量不同的统计分布。此外，高向量维数使这些搜索系统承受计算和内存压力，导致性能不佳。在这项工作中，我们提出了新的线性和非线性降维方法，以加速高维向量搜索，同时在分布内 (ID) 和分布外 (OOD) 查询的设置中保持准确性。线性 LeanVec-Sphering 优于其他线性方法，训练速度更快，没有超参数，并且允许更灵活地设置目标维度。非线性广义 LeanVec (GleanVec) 使用分段线性方案进一步提高搜索精度，同时保持计算灵活性。初步实验结果表明，LeanVec-Sphering 和 GleanVec 推动了向量搜索的最新发展。]]></description>
      <guid>https://arxiv.org/abs/2410.22347</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的搜索引擎：提供事实和可验证来源的虚假承诺</title>
      <link>https://arxiv.org/abs/2410.22349</link>
      <description><![CDATA[arXiv:2410.22349v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的应用程序正在从研究原型发展成为服务于数百万用户的产品，影响着人们编写和消费信息的方式。一个突出的例子是答案引擎的出现：基于 LLM 的生成搜索引擎取代了传统搜索引擎。答案引擎不仅检索与用户查询相关的来源，而且还合成引用来源的答案摘要。为了了解这些系统的局限性，我们首先对 21 名参与者进行了一项研究，评估了与答案与传统搜索引擎的交互，并确定了 16 个答案引擎的局限性。根据这些见解，我们提出了 16 条答案引擎设计建议，并与 8 个指标相关联。在三个流行引擎（You.com、Perplexity.ai、BingChat）上实施我们的指标的自动评估量化了常见的局限性（例如，频繁出现幻觉、引用不准确）和独特的功能（例如，答案信心的变化），结果反映了用户研究的见解。我们发布了答案引擎评估基准 (AEE)，以促进基于 LLM 的应用程序的透明评估。]]></description>
      <guid>https://arxiv.org/abs/2410.22349</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RuleRAG：基于规则引导的检索增强生成，使用语言模型进行问答</title>
      <link>https://arxiv.org/abs/2410.22353</link>
      <description><![CDATA[arXiv:2410.22353v1 公告类型：新
摘要：检索增强生成 (RAG) 框架通过检索外部语料库并基于增强上下文生成，在知识密集型问答 (QA) 中展现出巨大的潜力。然而，现有的方法只考虑查询本身，既没有为检索者指定检索偏好，也没有告知生成器如何参考检索到的文档来获取答案，这对 QA 性能构成了重大挑战。为了解决这些问题，我们提出了使用 LM 的规则引导的检索增强生成，它明确引入符号规则作为上下文学习的演示 (RuleRAG-ICL)，以指导检索者按照规则的方向检索逻辑相关的文档，并统一指导生成器生成由同一套规则指导的答案。此外，查询和规则的组合可以进一步用作监督微调数据来更新检索器和生成器（RuleRAG-FT），以实现更好的基于规则的指令遵循能力，从而检索出更有支持性的结果并生成更容易接受的答案。为了强调规则的作用，我们构建了五个规则感知的 QA 基准，包括三个时间场景和两个静态场景，并为 RuleRAG 配备了多种检索器和生成器。实验表明，无需训练的 RuleRAG-ICL 在五个基准测试中平均比标准 RAG 有效地提高了 Recall@10 分数的检索质量 +89.2%，精确匹配分数的生成准确率 +103.1%，进一步微调的 RuleRAG-FT 持续获得更显著的性能提升。大量分析表明，RuleRAG 随着检索到的文档数量的增加而具有很好的扩展性，并且对未训练的规则表现出泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2410.22353</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于顺序推荐中分层偏好建模的对偶对比变换器</title>
      <link>https://arxiv.org/abs/2410.22790</link>
      <description><![CDATA[arXiv:2410.22790v1 公告类型：新
摘要：顺序推荐系统（SRS）旨在通过全面建模嵌入在用户-项目交互序列中的用户复杂偏好来预测用户可能感兴趣的后续项目。然而，大多数现有的SRS通常基于项目ID信息对用户的单一低级偏好进行建模，而忽略了项目属性信息（例如项目类别）所揭示的高级偏好。此外，它们通常利用有限的序列上下文信息来预测下一个项目，而忽略了更丰富的项目间语义关系。为此，在本文中，我们提出了一种新颖的分层偏好建模框架，以实质性地建模复杂的低级和高级偏好动态，以实现准确的顺序推荐。具体而言，在该框架中，设计了一种新颖的双变压器模块和一种新颖的对偶对比学习方案，以分别有区别地学习用户的低级和高级偏好，并有效地增强低级和高级偏好学习。此外，我们还设计了一种新颖的语义增强上下文嵌入模块，以生成更具信息量的上下文嵌入，从而进一步提高推荐性能。在六个真实数据集上进行的大量实验证明了我们提出的方法优于最先进的方法，也证明了我们设计的合理性。]]></description>
      <guid>https://arxiv.org/abs/2410.22790</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于个性化推荐的 LLM 中的因果关系增强行为序列建模</title>
      <link>https://arxiv.org/abs/2410.22809</link>
      <description><![CDATA[arXiv:2410.22809v1 公告类型：新
摘要：推荐系统的最新进展集中在利用大型语言模型 (LLM) 来改进用户偏好建模，并取得了有希望的成果。然而，目前基于 LLM 的方法难以充分利用用户行为序列，导致个性化推荐的偏好建模不够理想。在本研究中，我们提出了一种新颖的反事实微调 (CFT) 方法来解决这个问题，通过明确强调行为序列在生成推荐时的作用。具体来说，我们采用反事实推理来识别行为序列对模型输出的因果影响，并引入一个根据这些影响直接拟合地面真实标签的任务，实现明确强调的目标。此外，我们开发了一种 token 级加权机制来调整不同项目 token 的强调强度，反映了在预测项目时从较早到较晚的 token 的行为序列影响的减小。在真实数据集上的大量实验表明，CFT 有效地改进了行为序列建模。我们的代码可以在 https://github.com/itsmeyjt/CFT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.22809</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解并改进对抗性协同过滤以实现稳健推荐</title>
      <link>https://arxiv.org/abs/2410.22844</link>
      <description><![CDATA[arXiv:2410.22844v1 公告类型：新 
摘要：对抗性协同过滤 (ACF) 通常通过对抗性训练对用户和项目嵌入施加对抗性扰动，被广泛认为是增强协同过滤 (CF) 推荐系统抵御中毒攻击的鲁棒性的有效策略。此外，大量研究已经通过经验表明，与传统 CF 相比，ACF 还可以提高推荐性能。尽管取得了这些经验上的成功，但对 ACF 在性能和鲁棒性方面的有效性的理论理解仍然不清楚。为了弥补这一差距，在本文中，我们首先从理论上证明，与干净和中毒数据环境中使用相同的训练周期相比，ACF 可以实现比传统 CF 更低的推荐误差。此外，通过在 ACF 优化过程中建立推荐误差减少的界限，我们发现根据不同用户的嵌入尺度应用个性化扰动幅度可以进一步提高 ACF 的有效性。基于这些理论理解，我们提出了个性化幅度对抗性协同过滤 (PamaCF)。大量实验表明，PamaCF 可有效防御各种类型的中毒攻击，同时显著提高推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2410.22844</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DataRec：标准化推荐数据处理和分析的框架</title>
      <link>https://arxiv.org/abs/2410.22972</link>
      <description><![CDATA[arXiv:2410.22972v1 公告类型：新
摘要：由于研究人员和公司的极大兴趣，推荐系统成为机器学习应用的基石。然而，最近人们对可重复性的需要产生了担忧，这使得确定合适的流程变得具有挑战性。已经提出了几种框架来提高可重复性，涵盖了从数据读取到性能评估的整个过程。尽管付出了这些努力，但这些解决方案往往忽视了数据管理的作用，没有促进互操作性，并且忽视了数据分析，尽管它对推荐器性能的影响是众所周知的。为了解决这些差距，我们提出了 DataRec，它有助于使用和操作推荐数据集。DataRec 支持以各种格式读写，提供过滤和拆分技术，并使用众所周知的指标实现数据分布分析。它通过允许以与多个推荐框架兼容的格式导出数据来鼓励统一的数据操作方法。]]></description>
      <guid>https://arxiv.org/abs/2410.22972</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 Next Set 推荐的通用集合级优化框架</title>
      <link>https://arxiv.org/abs/2410.23023</link>
      <description><![CDATA[arXiv:2410.23023v1 公告类型：新 
摘要：下一组推荐（NSRec）涵盖了相关任务，例如下一个篮子推荐和时间集预测，是一个热门研究课题。尽管已经对该主题进行了大量尝试，但仍存在一些缺点：（i）现有研究仍然局限于使用下一项推荐（NIRec）中常见的目标函数，例如二元交叉熵和BPR，它们是基于单个项目比较计算的；（ii）它们强调构建复杂的学习模型来捕捉序列集之间复杂的依赖关系，但经常忽略其目标函数中的关键依赖关系；（iii）序列集内的多样性因素经常被忽视。在本研究中，我们致力于为下一组推荐（SNSRec）揭示一个通用的、集合级的优化框架，提供时间集内多样性分布和复杂依赖关系的整体融合。为实现这一目标，我们做出了以下贡献：（i）我们利用结构化行列式点过程 (SDPP)，直接将序列中的时间集建模为一个有凝聚力的实体，其中概率 DPP 分布优先考虑结构集合（序列集）而不是单个项目；（ii）我们引入了共现表示来辨别和确认不同集合的重要性；（iii）我们提出了一个集合级优化标准，它整合了整个集合序列中的多样性分布和依赖关系，指导模型推荐相关且多样化的集合。在真实数据集上进行的大量实验表明，我们的方法在相关性和多样性方面始终优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.23023</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CORAL：对多轮对话检索增强生成进行基准测试</title>
      <link>https://arxiv.org/abs/2410.23090</link>
      <description><![CDATA[arXiv:2410.23090v1 公告类型：新
摘要：检索增强生成 (RAG) 已成为通过外部知识检索增强大型语言模型 (LLM) 的强大范例。尽管受到广泛关注，但现有的学术研究主要集中在单轮 RAG 上，在解决实际应用中发现的多轮对话的复杂性方面存在重大差距。为了弥补这一差距，我们引入了 CORAL，这是一个大规模基准，旨在评估现实多轮对话环境中的 RAG 系统。CORAL 包括从维基百科自动派生的各种信息搜索对话，并解决了开放域覆盖、知识强度、自由形式响应和主题转换等关键挑战。它支持对话 RAG 的三个核心任务：段落检索、响应生成和引用标记。我们提出了一个统一的框架来标准化各种对话式 RAG 方法，并在 CORAL 上对这些方法进行了全面的评估，展示了改进现有方法的巨大机会。]]></description>
      <guid>https://arxiv.org/abs/2410.23090</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的推荐与定制情境学习的实时个性化</title>
      <link>https://arxiv.org/abs/2410.23136</link>
      <description><![CDATA[arXiv:2410.23136v1 公告类型：新 
摘要：频繁更新基于大型语言模型 (LLM) 的推荐系统以适应新的用户兴趣（就像传统系统那样）是不切实际的，因为训练成本太高，即使使用加速方法也是如此。这项工作探索了通过利用上下文学习 (ICL) 来适应动态用户兴趣而无需任何模型更新，这允许 LLM 从输入中提供的少量示例中学习新任务。使用新兴趣示例作为 ICL 少量示例，LLM 可以直接学习实时兴趣，避免模型更新的需要。然而，现有的基于 LLM 的推荐器在推荐调整期间通常会失去上下文学习能力，而原始 LLM 的上下文学习缺乏针对推荐的重点。为了解决这个问题，我们提出了 RecICL，它为实时推荐定制了针对推荐的上下文学习。 RecICL 以上下文学习格式组织训练示例，确保上下文学习能力在调整期间得到保留并与推荐任务保持一致。
大量实验证明了 RecICL 在提供实时推荐方面的有效性，无需更新模型。我们的代码可在 https://github.com/ym689/rec_icl 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.23136</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReasoningRec：通过 LLM 推理连接个性化推荐和人类可解释的解释</title>
      <link>https://arxiv.org/abs/2410.23180</link>
      <description><![CDATA[arXiv:2410.23180v1 公告类型：新
摘要：本文介绍了基于推理的推荐框架 ReasoningRec，该框架利用大型语言模型 (LLM) 来弥合推荐与人类可解释的解释之间的差距。与依赖隐式用户-项目交互的传统推荐系统相比，ReasoningRec 使用 LLM 来对用户和项目进行建模，重点关注偏好、厌恶和解释推理。该框架利用较大的 LLM 为用户偏好生成综合解释，随后用于微调较小的 LLM 以提高推荐准确性和人类可解释的解释。我们的实验研究调查了推理和上下文信息对个性化推荐的影响，揭示了上下文和个性化数据的质量显著影响了 LLM 生成合理解释的能力。实证评估表明，ReasoningRec 在推荐预测方面比最先进的方法高出 12.5%，同时还能提供人类可理解的解释。代码可在此处获取：https://github.com/millenniumbismay/reasoningrec。]]></description>
      <guid>https://arxiv.org/abs/2410.23180</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于指针网络的多标签多类意图联合提取与检测方法</title>
      <link>https://arxiv.org/abs/2410.22476</link>
      <description><![CDATA[arXiv:2410.22476v1 公告类型：交叉 
摘要：在面向任务的对话系统中，意图检测对于解释用户查询和提供适当的响应至关重要。现有研究主要解决具有单一意图的简单查询，缺乏有效的系统来处理具有多种意图的复杂查询并提取不同的意图范围。此外，多语言、多意图数据集明显缺失。本研究解决了三个关键任务：从查询中提取多个意图范围、检测多种意图以及开发多语言多标签意图数据集。我们引入了一种从现有基准数据集中精选的新型多标签多类意图检测数据集 (MLMCID-dataset)。我们还提出了一种基于指针网络的架构 (MLMCID) 来提取意图范围并以六元组的形式检测具有粗粒度和细粒度标签的多种意图。综合分析表明，我们的基于指针网络的系统在各种数据集的准确性和 F1 分数方面优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2410.22476</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HijackRAG：针对检索增强大型语言模型的劫持攻击</title>
      <link>https://arxiv.org/abs/2410.22832</link>
      <description><![CDATA[arXiv:2410.22832v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 系统通过集成外部知识来增强大型语言模型 (LLM)，使其适用于各种应用且具有成本效益。然而，对这些系统的日益依赖也带来了潜在的安全风险。在这项工作中，我们揭示了一个新的漏洞，即检索提示劫持攻击 (HijackRAG)，它使攻击者能够通过将恶意文本注入知识数据库来操纵 RAG 系统的检索机制。当 RAG 系统遇到目标问题时，它会生成攻击者预先确定的答案而不是正确的答案，从而破坏系统的完整性和可信度。我们将 HijackRAG 形式化为一个优化问题，并提出了针对攻击者不同知识水平的黑盒和白盒攻击策略。在多个基准数据集上进行的大量实验表明，HijackRAG 始终实现高攻击成功率，优于现有的基线攻击。此外，我们证明了这种攻击可以在不同的检索器模型之间转移，这强调了它对 RAG 系统造成的广泛风险。最后，我们对各种防御机制的探索表明，它们不足以对抗 HijackRAG，这强调了迫切需要更强大的安全措施来保护实际部署中的 RAG 系统。]]></description>
      <guid>https://arxiv.org/abs/2410.22832</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SciPIP：基于法学硕士的科学论文创意提出器</title>
      <link>https://arxiv.org/abs/2410.23166</link>
      <description><![CDATA[arXiv:2410.23166v1 公告类型：交叉 
摘要：知识的指数级增长和跨学科研究的日益复杂给研究人员带来了重大挑战，包括信息过载和探索新想法的困难。GPT-4 等大型语言模型 (LLM) 的进步已显示出增强想法提议的巨大潜力，但如何有效利用大型模型进行合理的想法提议尚未得到深入探索。本文提出了一种科学论文想法提出器 (SciPIP)。基于用户提供的研究背景，SciPIP 从文献数据库中检索有用的论文，同时利用 LLM 的功能产生更多新颖可行的想法。为此，1）我们构建了一个文献检索数据库，提取大量论文的多维信息以供快速访问。然后，提出了一种基于语义、实体和引文共现的文献检索方法，基于用户提供的背景从多个方面搜索相关文献。 2）在文献检索之后，我们引入双路径想法提出策略，一条路径从检索到的文献中推断解决方案，另一条路径通过模型头脑风暴产生原创想法。然后将两者结合起来，在可行性和原创性之间取得良好的平衡。通过在自然语言处理 (NLP) 领域的大量实验，我们证明了 SciPIP 可以检索与现有顶级会议论文相似的引用，并产生许多与之一致的想法。此外，我们使用大型语言模型评估了 SciPIP 生成的其他想法的原创性，进一步验证了我们提出的方法的有效性。代码和数据库发布在 https://github.com/cheerss/SciPIP。]]></description>
      <guid>https://arxiv.org/abs/2410.23166</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向科技信息的语义对抗和媒体对抗跨媒体检索</title>
      <link>https://arxiv.org/abs/2203.08615</link>
      <description><![CDATA[arXiv:2203.08615v3 Announce Type: replace 
摘要：科技信息跨媒体检索是跨媒体研究中的重要任务之一。跨媒体科技信息检索从海量多源异构科技资源中获取目标信息，帮助设计出符合用户需求的应用，包括科技信息推荐、个性化科技信息检索等。跨媒体检索的核心是学习一个共同的子空间，不同媒体的数据映射到这个子空间后可以直接进行比较。在子空间学习中，现有方法往往侧重于对媒体内数据的区分性和映射后媒体间数据的不变性进行建模，而忽略了映射前后媒体间数据的语义一致性和语义内数据的媒体区分性，从而限制了跨媒体检索的效果。为此，我们提出了一种面向科技信息的语义对抗和媒体对抗的跨媒体检索方法（SMCR），以寻找有效的公共子空间。具体而言，SMCR 除了对媒体内语义判别性进行建模外，还最小化了媒体间语义一致性的损失，以保持映射前后的语义相似性。此外，SMCR 构建了一个基本特征映射网络和一个精炼特征映射网络，以共同最小化语义内的媒体判别性损失，从而增强特征映射网络混淆媒体判别网络的能力。在两个数据集上的实验结果表明，所提出的 SMCR 在跨媒体检索中的表现优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2203.08615</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>