<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 31 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>C-RAG：检索增强语言模型的认证生成风险</title>
      <link>https://arxiv.org/abs/2402.03181</link>
      <description><![CDATA[arXiv:2402.03181v5 公告类型：replace-cross 
摘要：尽管大型语言模型 (LLM) 在各种应用中都具有令人印象深刻的功能，但它们仍然存在可信度问题，例如幻觉和错位。检索增强语言模型 (RAG) 已被提出通过建立外部知识来增强生成的可信度，但对其生成风险的理论理解仍未得到探索。在本文中，我们回答：1）RAG 是否确实可以降低生成风险，2）如何为 RAG 和 vanilla LLM 的生成风险提供可证明的保证，以及 3）哪些充分条件使 RAG 模型能够降低生成风险。我们提出了 C-RAG，这是第一个用于认证 RAG 模型生成风险的框架。具体而言，我们为 RAG 模型提供共形风险分析并认证生成风险的上限置信度，我们将其称为共形生成风险。我们还为测试分布偏移下的一般有界风险函数的共形生成风险提供了理论保证。我们证明，当检索模型和转换器的质量不低时，RAG 的共形生成风险低于单个 LLM。我们深入的实证结果证明了我们在四个最先进的检索模型上四个广泛使用的 NLP 数据集上的共形生成风险保证的合理性和严密性。]]></description>
      <guid>https://arxiv.org/abs/2402.03181</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:09 GMT</pubDate>
    </item>
    <item>
      <title>EHR-SeqSQL：用于交互式探索电子健康记录的顺序文本到 SQL 数据集</title>
      <link>https://arxiv.org/abs/2406.00019</link>
      <description><![CDATA[arXiv:2406.00019v3 公告类型：replace-cross 
摘要：在本文中，我们介绍了 EHR-SeqSQL，这是一种用于电子健康记录 (EHR) 数据库的新型顺序文本到 SQL 数据集。EHR-SeqSQL 旨在解决文本到 SQL 解析中关键但尚未充分探索的方面：交互性、组合性和效率。据我们所知，EHR-SeqSQL 不仅是最大的，也是第一个包含顺序和上下文问题的医学文本到 SQL 数据集基准。我们提供了数据分割和旨在评估组合泛化能力的新测试集。我们的实验证明了多轮方法在学习组合性方面优于单轮方法。此外，我们的数据集将特制的标记集成到 SQL 查询中以提高执行效率。借助 EHR-SeqSQL，我们旨在弥合文本到 SQL 领域的实际需求与学术研究之间的差距。 EHR-SeqSQL 可在 https://github.com/seonhee99/EHR-SeqSQL 上获取。]]></description>
      <guid>https://arxiv.org/abs/2406.00019</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:09 GMT</pubDate>
    </item>
    <item>
      <title>顺序推荐的重复填充</title>
      <link>https://arxiv.org/abs/2403.06372</link>
      <description><![CDATA[arXiv:2403.06372v2 Announce Type: replace 
摘要：序列推荐旨在根据用户的历史交互为其提供个性化的建议。在训练序列模型时，填充是一种广泛采用的技术，主要有两个原因：1）绝大多数模型只能处理固定长度的序列；2）基于批处理的训练需要确保每个批次中的序列具有相同的长度。特殊值 \emph{0} 通常被用作填充内容，它不包含实际信息，在模型计算中被忽略。这种常识性的填充策略将我们引向了一个从未被探索过的问题：\emph{我们能否通过填充其他内容来充分利用这些空闲的输入空间，以进一步提高模型性能和训练效率？}
在本文中，我们提出了一种简单而有效的填充方法，称为 \textbf{Rep}eated \textbf{Pad}ding（\textbf{RepPad}）。具体来说，我们使用原始交互序列作为填充内容，并在模型训练时将其填充到填充位置。此操作可以执行有限次，也可以重复执行，直到输入序列的长度达到最大限制。我们的RepPad可以看作是一种序列级的数据增强策略。与大多数现有工作不同，我们的方法不包含可训练的参数或超参数，是一种即插即用的数据增强操作。在各类序列模型和五个真实数据集上进行的大量实验证明了我们方法的有效性和效率。在GRU4Rec上的平均推荐性能提升高达60.3\%，在SASRec上的平均推荐性能提升高达24.3\%。我们还从多个角度对RepPad的有效性进行了深入的分析和解释。我们的数据集和代码可以在\url{https://github.com/KingGugu/RepPad}获得。]]></description>
      <guid>https://arxiv.org/abs/2403.06372</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:08 GMT</pubDate>
    </item>
    <item>
      <title>多行为生成推荐</title>
      <link>https://arxiv.org/abs/2405.16871</link>
      <description><![CDATA[arXiv:2405.16871v2 公告类型：替换 
摘要：多行为顺序推荐 (MBSR) 旨在整合行为类型的交互以提供更好的推荐。现有方法侧重于下一项预测目标，而忽略了将目标行为类型整合到学习目标中的价值。在本文中，我们提出了 MBGen，一种新颖的多行为顺序生成推荐框架。我们将 MBSR 任务制定为一个连续的两步过程：(1) 给定项目序列，MBGen 首先预测下一个行为类型以构建用户意图，(2) 给定项目序列和目标行为类型，MBGen 然后预测下一个项目。为了对这样的两步过程进行建模，我们将行为和项目都标记为标记，并构建一个单一的标记序列，其中行为和项目交错放置。此外，MBGen 学习在统一的生成推荐范式中自回归地生成下一个行为和项目标记，自然地实现了多任务能力。此外，我们利用生成推荐中标记序列的异构性，并提出一种位置路由稀疏架构，以高效且有效地扩展模型。在公共数据集上进行的大量实验表明，MBGen 在多个任务中的表现明显优于现有的 MBSR 模型。]]></description>
      <guid>https://arxiv.org/abs/2405.16871</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:08 GMT</pubDate>
    </item>
    <item>
      <title>JaColBERTv2.5：优化多向量检索器，利用有限的资源打造最先进的日本检索器</title>
      <link>https://arxiv.org/abs/2407.20750</link>
      <description><![CDATA[arXiv:2407.20750v1 公告类型：新
摘要：神经信息检索在资源丰富的语言中发展迅速，但在资源较少的语言（如日语）中，数据稀缺等挑战阻碍了其发展。因此，尽管多语言模型计算效率低下且无法捕捉语言细微差别，但它们仍然主导着日语检索。虽然最近的多向量单语模型（如 JaColBERT）缩小了这一差距，但它们在大规模评估中仍然落后于多语言方法。这项工作解决了资源较少环境中多向量检索器的次优训练方法，重点是日语。我们系统地评估和改进了 JaColBERT 以及更广泛的多向量模型的推理和训练设置的关键方面。我们通过一种新颖的检查点合并步骤进一步提高了性能，展示了它是一种将微调的好处与原始检查点的泛化能力相结合的有效方法。基于我们的分析，我们引入了一种新颖的训练方法，从而产生了 JaColBERTv2.5 模型。JaColBERTv2.5 仅包含 1.1 亿个参数，在 4 个 A100 GPU 上训练时间不到 15 小时，在所有常见基准测试中均显著优于所有现有方法，平均得分达到 0.754，远高于之前的最佳成绩 0.720。为了支持未来的研究，我们将最终模型、中间检查点和所有使用的数据公开。]]></description>
      <guid>https://arxiv.org/abs/2407.20750</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:07 GMT</pubDate>
    </item>
    <item>
      <title>通过销售进行学习：为大型语言模型配备产品知识以实现情境驱动的推荐</title>
      <link>https://arxiv.org/abs/2407.20856</link>
      <description><![CDATA[arXiv:2407.20856v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展为情境驱动的产品推荐等应用开辟了新的可能性。然而，这些模型在这种情况下的有效性在很大程度上取决于它们对产品库存的全面理解。本文提出了一种新方法，通过训练 LLM 以情境化方式响应包含产品 ID 的合成搜索查询，为 LLM 配备产品知识。我们深入分析了这种方法，评估了它的有效性，概述了它的好处，并强调了它的局限性。本文还讨论了这种方法的潜在改进和未来方向，全面了解了 LLM 在产品推荐中的作用。]]></description>
      <guid>https://arxiv.org/abs/2407.20856</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:07 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的推荐系统增量学习初步研究</title>
      <link>https://arxiv.org/abs/2312.15599</link>
      <description><![CDATA[arXiv:2312.15599v2 公告类型：替换 
摘要：调整大型语言模型以进行推荐 (LLM4Rec) 已显示出良好的效果。然而，在现实场景中部署 LLM4Rec 的挑战在很大程度上仍未得到探索。特别是，推荐模型需要逐步适应不断变化的用户偏好，而由于大型语言模型 (LLM) 的独特特性，LLM4Rec 中传统增量学习方法的适用性仍然不明确。
在本研究中，我们实证评估了 LLM4Rec 的两种常用增量学习策略（完全再训练和微调）。令人惊讶的是，这两种方法都没有显著提高 LLM4Rec 的性能。我们并没有否定增量学习的作用，而是将预期性能提升的不足归因于 LLM4Rec 架构与增量学习之间的不匹配：LLM4Rec 采用单一自适应模块来学习建议，限制了其在增量学习环境中同时捕捉长期和短期用户偏好的能力。为了验证这一推测，我们在 LLM4Rec 中引入了一个用于增量学习的长期和短期自适应感知调优 (LSAT) 框架。与单一自适应模块方法不同，LSAT 利用两个不同的自适应模块来独立学习长期和短期用户偏好。实证结果验证了 LSAT 可以提高性能，从而验证了我们的推测。我们的代码发布在：https://github.com/TianhaoShi2001/LSAT。]]></description>
      <guid>https://arxiv.org/abs/2312.15599</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:07 GMT</pubDate>
    </item>
    <item>
      <title>强大的 A/B 测试指标及其查找位置</title>
      <link>https://arxiv.org/abs/2407.20665</link>
      <description><![CDATA[arXiv:2407.20665v1 公告类型：新
摘要：在线控制实验，俗称 A/B 测试，是现实世界推荐系统评估的基础。通常，最终用户会被随机分配一些系统变体，然后在整个实验过程中跟踪、收集和汇总大量指标。北极星指标（例如长期增长或收入）用于评估哪种系统变体应被视为更优越。因此，大多数收集到的指标本质上都是支持性的，并且有助于 (i) 了解实验如何影响用户体验，或 (ii) 在北极星指标变化不大（即假阴性或 II 类错误）时做出自信的决策。后者并不简单：假设一种治疗变体导致会话次数更少但时间更长，观看次数更多但参与度更低；这应该被视为积极还是消极的结果？
那么问题就变成了：在使用 A/B 测试进行决策时，我们如何评估支持指标的效用？在线平台通常会在任何给定时间运行数十次实验。这提供了有关干预措施和治疗效果的大量信息，可用于评估指标的在线评估效用。我们建议收集这些信息并利用它来量化感兴趣指标的 I 型、II 型和 III 型错误，以及它们的统计功效测量分布（例如 $z$ 分数和 $p$ 值）。我们展示了为两个大型短视频平台 ShareChat 和 Moj 大规模构建此管道的结果和见解；利用数百次过去的实验来寻找具有高统计功效的在线指标。]]></description>
      <guid>https://arxiv.org/abs/2407.20665</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>RevGNN：用于学术审稿人推荐的负采样增强对比图学习</title>
      <link>https://arxiv.org/abs/2407.20684</link>
      <description><![CDATA[arXiv:2407.20684v1 公告类型：新
摘要：获取学术投稿的审稿人是一个具有挑战性的推荐场景。最近的图学习驱动模型在推荐领域取得了显着进展，但它们在学术审稿人推荐任务中的表现可能会受到严重的假阴性问题的影响。这源于未观察到的边缘代表负样本的假设。事实上，匿名评审的机制导致审稿人与投稿之间的互动曝光不足，导致未观察到的互动数量高于审稿人拒绝参与所导致的互动数量。因此，研究如何更好地理解学术审稿人推荐中未观察到的互动的负面标签是一项重大挑战。本研究旨在解决学术审稿人推荐中未观察到的互动的模糊性。具体来说，我们提出了一种无监督的伪负标签策略来增强图对比学习（GCL）以推荐学术投稿的审稿人，我们称之为 RevGNN。 RevGNN 采用两阶段编码器结构，使用伪负标签对科学知识和行为进行编码，以近似评论偏好。在三个真实数据集上进行的大量实验表明，RevGNN 在四个指标上的表现均优于所有基线。此外，进一步的详细分析证实了 RevGNN 中每个组件的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.20684</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>Graphite：基于图的极端多标签短文本分类器，用于关键短语推荐</title>
      <link>https://arxiv.org/abs/2407.20462</link>
      <description><![CDATA[arXiv:2407.20462v1 公告类型：新
摘要：关键词推荐一直是广告和电子商务中的一个关键问题，广告商/卖家被推荐竞标关键词（搜索查询）以增加他们的销售额。这是一项具有挑战性的任务，因为在线平台上显示的商品数量众多，用户在对显示商品表现出不同兴趣的同时，可能会搜索各种查询。此外，查询/关键词推荐需要在资源受限的环境中实时进行。这个问题可以定义为极端多标签（XML）短文本分类，方法是将输入文本标记为标签，并使用关键词作为标签。传统的神经网络模型要么不可行，要么由于标签空间较大而具有较慢的推理延迟。我们提出了 Graphite，这是一种基于图形的分类器模型，可提供与标准文本分类模型相当的实时关键词推荐。此外，它不使用 GPU 资源，这在生产环境中可能受到限制。由于其轻量级特性和较小的占用空间，它可以在非常大的数据集上进行训练，而最先进的 XML 模型由于极端的资源要求而失败。Graphite 具有确定性、透明性，并且本质上比基于神经网络的模型更具可解释性。我们对我们的模型在 eBay 的英语网站的 40 个类别中的表现进行了全面分析。]]></description>
      <guid>https://arxiv.org/abs/2407.20462</guid>
      <pubDate>Thu, 01 Aug 2024 03:17:05 GMT</pubDate>
    </item>
    </channel>
</rss>