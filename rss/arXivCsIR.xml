<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 08 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>来自专利工件描述的工程设计知识图，用于设计过程中的检索增强生成</title>
      <link>https://arxiv.org/abs/2307.06985</link>
      <description><![CDATA[尽管大语言模型 (LLM) 非常受欢迎，但它需要明确的上下文事实来支持设计过程中特定领域的知识密集型任务。因此，使用法学硕士构建的应用程序应该采用检索增强生成（RAG）以更好地适应设计过程。在本文中，我们提出了一种数据驱动的方法，用于从专利文档中识别明确的事实，这些专利文档提供了超过 800 万件人工制品的标准描述。在我们的方法中，我们使用 44,227 个句子和事实的数据集训练基于 roBERTa Transformer 的序列分类模型。将句子中的标记分类为实体或关系时，我们的方法使用另一个分类器来识别给定实体对的特定关系标记，以便识别形式为头实体 :: 关系 :: 尾实体的显式事实。在构建事实的基准方法中，我们使用线性分类器和图神经网络（GNN），两者都结合了基于 BERT Transformer 的标记嵌入来预测实体和关系之间的关联。我们将我们的方法应用于 4,870 项风扇系统相关专利，并填充了包含约 300 万个事实的知识库。在检索代表通用领域知识以及特定子系统和问题的知识的事实后，我们演示了这些事实如何将法学硕士置于上下文中，以生成与设计过程更相关的文本。]]></description>
      <guid>https://arxiv.org/abs/2307.06985</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:27 GMT</pubDate>
    </item>
    <item>
      <title>带标签的交互式主题模型</title>
      <link>https://arxiv.org/abs/2311.09438</link>
      <description><![CDATA[主题模型对于理解广泛的文档集合很有价值，但它们并不总是能识别最相关的主题。经典的概率和基于锚的主题模型提供交互式版本，允许用户引导模型转向更相关的主题。然而，神经主题模型一直缺乏这样的交互特征。为了纠正这个缺陷，我们为神经主题模型引入了用户友好的交互。这种交互允许用户为主题分配单词标签，从而导致主题模型的更新，其中主题中的单词与给定标签紧密对齐。我们的方法包含两种不同类型的神经主题模型。第一个包括主题嵌入可训练并在训练过程中不断发展的模型。第二种涉及主题嵌入在训练后集成的模型，提供了不同的主题细化方法。为了促进用户与这些神经主题模型的交互，我们开发了一个交互界面。该界面使用户能够根据需要参与主题并重新标记主题。我们通过人体研究评估我们的方法，用户可以重新标记主题以查找相关文档。使用我们的方法，用户标记可以提高文档排名分数，与没有用户标记相比，有助于找到与给定查询更相关的文档。]]></description>
      <guid>https://arxiv.org/abs/2311.09438</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:27 GMT</pubDate>
    </item>
    <item>
      <title>按结果集多样化进行新近度排名</title>
      <link>https://arxiv.org/abs/2401.14595</link>
      <description><![CDATA[在本文中，我们提出了一种网络搜索检索方法，该方法自动检测近期敏感查询，并按与最近内容的需求概率成比例的程度增加普通文档排名的新鲜度。我们建议通过使用结果多样化原则来解决新近度排名问题，并处理当只能在不确定的情况下检测到最近内容中的需求时出现的查询的非主题歧义。我们对来自真实搜索引擎用户的数百万个查询进行的离线和在线实验表明，用户对我们的方法生成的搜索结果的满意度显着提高。]]></description>
      <guid>https://arxiv.org/abs/2401.14595</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:26 GMT</pubDate>
    </item>
    <item>
      <title>请求级建议中的未来影响分解</title>
      <link>https://arxiv.org/abs/2401.16108</link>
      <description><![CDATA[在推荐系统中，强化学习解决方案在优化用户与系统之间的交互序列的长期性能方面显示出了有希望的结果。出于实际原因，策略的操作通常被设计为推荐项目列表，以更有效地处理用户频繁且持续的浏览请求。在此列表式推荐场景中，用户状态会根据相应 MDP 公式中的每个请求进行更新。然而，这种请求级的表述与用户的项目级行为本质上是不一致的。在本研究中，我们证明即使在请求级 MDP 下，项目级优化方法也可以更好地利用项目特征并优化策略的性能。我们通过在模拟和在线实验中比较标准请求级方法与所提出的项目级参与者-评论家框架的性能来支持这一说法。此外，我们还表明，基于奖励的未来分解策略可以更好地表达逐项的未来影响，并提高长期推荐的准确性。为了更全面地理解分解策略，我们提出了一种基于模型的重新加权框架，具有对抗性学习，可进一步提高性能并研究其与基于奖励的策略的相关性。]]></description>
      <guid>https://arxiv.org/abs/2401.16108</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:26 GMT</pubDate>
    </item>
    <item>
      <title>检测对话式搜索中生成的原生广告</title>
      <link>https://arxiv.org/abs/2402.04889</link>
      <description><![CDATA[YouChat 和 Microsoft Copilot 等会话式搜索引擎使用大型语言模型 (LLM) 来生成查询答案。使用该技术在这些答案中生成和集成广告只是一小步 - 而不是将广告与有机搜索结果分开放置。这种类型的广告让人想起原生广告和植入式广告，这两者都是非常有效的微妙和操纵性广告形式。在不久的将来，信息寻求者很可能会面临法学硕士技术的这种使用，特别是考虑到与法学硕士相关的高计算成本，为此提供者需要开发可持续的商业模式。本文研究了法学硕士是否也可以用作针对生成的原生广告的对策，即阻止它们。为此，我们编译了一个包含广告倾向查询和自动集成广告生成答案的大型数据集，以在识别广告的任务上尝试微调句子转换器和最先进的法学硕士。在我们的实验中，句子转换器实现了 0.9 以上的检测精度和召回值，而所研究的法学硕士却难以完成这项任务。]]></description>
      <guid>https://arxiv.org/abs/2402.04889</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>SPARQL 生成：针对生命科学知识图问答的 OpenLLaMA 微调分析</title>
      <link>https://arxiv.org/abs/2402.04627</link>
      <description><![CDATA[最近，大型语言模型 (LLM) 在各种自然语言处理应用中取得的成功，为利用 LLM 的知识图谱新型问答系统开辟了道路。然而，阻碍其实现的主要障碍之一是缺乏将问题转换为相应 SPARQL 查询的训练数据，特别是在特定于领域的 KG 的情况下。为了克服这一挑战，在本研究中，我们评估了几种微调 OpenLlama LLM 以回答生命科学知识图问题的策略。特别是，我们提出了一种端到端数据增强方法，用于将给定知识图上的一组现有查询扩展到语义丰富的问题​​到 SPARQL 查询对的更大数据集，甚至可以对这些数据集进行微调对是稀缺的。在这种情况下，我们还研究了查询中语义“线索”的作用，例如有意义的变量名称和内联注释。最后，我们在现实世界的 Bgee 基因表达知识图谱上评估了我们的方法，结果表明，与具有随机变量名称且不包含注释的基线相比，语义线索可以将模型性能提高高达 33%。]]></description>
      <guid>https://arxiv.org/abs/2402.04627</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>多元联盟路线图</title>
      <link>https://arxiv.org/abs/2402.05070</link>
      <description><![CDATA[随着人工智能系统的功能不断增强和普及，人工智能系统的设计目的是为所有人（即具有不同价值观和观点的人）提供服务，这一点变得越来越重要。然而，调整模型以服务多元人类价值观仍然是一个开放的研究问题。在这篇文章中，我们提出了多元对齐的路线图，特别是使用语言模型作为测试平台。我们确定并形式化了三种可能的方法来定义和实施人工智能系统中的多元化：1）奥弗顿多元化模型，提出一系列合理的反应； 2）可引导的多元化模型，可以引导反映某些观点； 3) 分布多元模型，针对分布中的给定群体进行了良好校准。我们还提出并形式化了三类可能的多元基准：1）多目标基准，2）权衡可引导基准，激励模型转向任意权衡，以及3）陪审团多元基准，明确模拟不同的人类评级。我们使用这个框架来论证当前的对齐技术可能从根本上限制了多元人工智能；事实上，我们强调了来自我们自己的实验和其他工作的经验证据，即标准对齐程序可能会减少模型中的分布多元化，从而激发了对多元对齐进行进一步研究的需要。]]></description>
      <guid>https://arxiv.org/abs/2402.05070</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>基于图的近似最近邻搜索的自适应入口点选择的理论和实证分析</title>
      <link>https://arxiv.org/abs/2402.04713</link>
      <description><![CDATA[我们对基于图的近似最近邻搜索（ANNS）的自适应入口点选择进行了理论和实证分析。我们引入了新颖的概念：$b\textit{-monotonic path}$ 和 $B\textit{-MSNET}$，它们比 MSNET 等现有概念更好地捕获实际算法中的实际图形。我们证明，在比以前的工作更一般的条件下，自适应入口点选择比固定中心入口点提供了更好的性能上限。根据经验，我们在各种数据集上验证了该方法在准确性、速度和内存使用方面的有效性，特别是在具有分布外数据和硬实例的挑战性场景中。我们的全面研究为优化现实世界高维数据应用中基于图的 ANNS 的入口点提供了更深入的见解。]]></description>
      <guid>https://arxiv.org/abs/2402.04713</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:24 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士进行无监督密集检索器排名</title>
      <link>https://arxiv.org/abs/2402.04853</link>
      <description><![CDATA[本文介绍了一种新颖的无监督技术，该技术利用大型语言模型（LLM）来确定针对特定测试（目标）语料库的最合适的密集检索器。选择合适的密集检索器对于许多 IR 应用程序至关重要，这些应用程序使用这些检索器，在公共数据集上进行训练，在新的私有目标语料库中进行编码或进行搜索。当应用于在领域或任务上与原始训练集不同的目标语料库时，密集检索器的有效性可能会显着降低。在目标语料库未标记的情况下，该问题变得更加明显，例如在零样本场景下，无法直接评估模型在目标语料库上的有效性。因此，无监督地选择最佳预训练的密集检索器，特别是在域转移的条件下，成为一个关键的挑战。现有的对密集检索器进行排名的方法不足以解决这些域转移场景。
  为了解决这个问题，我们的方法利用法学硕士通过分析目标语料库中的文档子集来创建伪相关查询、标签和参考列表。这允许根据密集检索器对这些伪相关信号的性能进行排名。值得注意的是，该策略是第一个完全依赖于目标语料库数据的策略，消除了训练数据和测试标签的必要性。我们通过编制尖端密集检索器的综合库并将我们的方法与传统密集检索器选择基准进行比较来评估我们方法的有效性。研究结果表明，我们提出的解决方案在密集检索器的选择和排名方面都超过了现有的基准。]]></description>
      <guid>https://arxiv.org/abs/2402.04853</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:24 GMT</pubDate>
    </item>
    <item>
      <title>基于人类反馈的多智能体强化学习的多模态查询建议</title>
      <link>https://arxiv.org/abs/2402.04867</link>
      <description><![CDATA[在快速发展的信息检索领域，搜索引擎努力为用户提供更加个性化和相关的结果。查询建议系统通过帮助用户制定有效的查询，在实现这一目标方面发挥着至关重要的作用。然而，现有的查询建议系统主要依赖于文本输入，可能限制用户查询图像的搜索体验。在本文中，我们介绍了一种新颖的多模态查询建议（MMQS）任务，其目的是基于用户查询图像生成查询建议，以提高搜索结果的意向性和多样性。我们提出了 RL4Sugg 框架，利用大型语言模型 (LLM) 的强大功能以及来自人类反馈的多智能体强化学习来优化生成过程。通过全面的实验，我们验证了 RL4Sugg 的有效性，与现有最佳方法相比，效果提高了 18%。此外，MMQS 已被转移到现实世界的搜索引擎产品中，从而提高了用户参与度。我们的研究推进了查询建议系统，并为多模式信息检索提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2402.04867</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:24 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的可靠性质量测量</title>
      <link>https://arxiv.org/abs/2402.04457</link>
      <description><![CDATA[用户想知道推荐的可靠性；如果没有可靠性证据，他们不会接受高预测。推荐系统应提供与预测相关的可靠性值。对可靠性测量的研究需要存在简单、合理且通用的可靠性质量测量。对推荐系统质量测量的研究主要集中在准确性上。此外，还对新颖性、偶然性和多样性进行了研究；然而，对可靠性/置信度质量测量的研究严重缺乏。
  本文提出了可靠性质量预测度量（RPI）和可靠性质量推荐度量（RRI）。这两种质量测量都基于这样的假设：可靠性测量越合适，应用时提供的准确度结果就越好。当适当的可靠性值与其预测相关联时（即与正确预测相关的高可靠性值或与不正确的预测相关的低可靠性值），这些可靠性质量测量显示出准确性的提高。
  所提出的可靠性质量指标将导致全新推荐系统可靠性措施的设计。这些措施可以应用于不同的矩阵分解技术以及基于内容、情境感知和社交推荐的方法。可以使用所提出的可靠性质量指标来测试、比较和改进所设计的推荐系统可靠性措施。]]></description>
      <guid>https://arxiv.org/abs/2402.04457</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>RA-Rec：基于 LLM 推荐的高效 ID 表示对齐框架</title>
      <link>https://arxiv.org/abs/2402.04527</link>
      <description><![CDATA[大语言模型 (LLM) 最近已成为各种自然语言处理任务的强大工具，带来了将 LLM 与推荐系统相结合的新浪潮，称为基于 LLM 的 RS。当前的方法通常分为两个主要范式，即ID直接使用范式和ID翻译范式，注意到它们的核心弱点源于缺乏推荐知识和独特性。为了解决这个限制，我们提出了一种新的范式，即 ID 表示，它以互补的方式将预先训练的 ID 嵌入合并到 LLM 中。在这项工作中，我们提出了 RA-Rec，一种用于基于 LLM 推荐的高效 ID 表示对齐框架，它与多种基于 ID 的方法和 LLM 架构兼容。具体来说，我们将 ID 嵌入视为软提示，并设计了创新的对齐模块和高效的调整方法，以及定制的对齐数据构造。大量实验表明，RA-Rec 的性能大大优于当前最先进的方法，在使用不到 10 倍的训练数据的情况下，绝对 HitRate@100 提高了高达 3.0%。]]></description>
      <guid>https://arxiv.org/abs/2402.04527</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>NORMY：开放检索会话问答的非统一历史建模</title>
      <link>https://arxiv.org/abs/2402.04548</link>
      <description><![CDATA[开放检索对话式问答 (OrConvQA) 回答给定对话作为上下文和文档集合的问题。典型的 OrConvQA 管道由三个模块组成：一个用于从集合中检索相关文档的检索器，一个用于在给定问题和上下文的情况下对它们重新排序的重新排序器，以及一个用于提取答案范围的读取器。对话轮流可以提供有价值的上下文来回答最终的查询。最先进的 OrConvQA 系统对管道的所有三个模块使用相同的历史建模。我们假设这是次优的。具体来说，我们认为管道的第一个模块需要更广泛的上下文，以免错过相关文档，而最后一个模块需要更窄的上下文来确定确切的答案范围。我们提出 NORMY，第一个无监督的非均匀历史建模管道，它为每个模块生成最佳的对话历史。我们进一步提出了一种新颖的 NORMY 检索器，它在对话历史中采用关键短语提取，并利用之前检索到的段落作为附加上下文。我们还通过扩展 doc2dial 数据集为 OrConvQA 创建了一个新数据集。我们实施了各种最先进的历史建模技术，并在三个数据集上分别对管道的每个模块进行了全面评估：OR-QUAC、我们的 doc2dial 扩展和 ConvMix。我们大量的实验表明，NORMY 在各个模块和端到端系统方面均优于最先进的技术。]]></description>
      <guid>https://arxiv.org/abs/2402.04548</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>为 ClueWeb22-B 语料库构建检索系统</title>
      <link>https://arxiv.org/abs/2402.04357</link>
      <description><![CDATA[包含近 100 亿份文档的 ClueWeb22 数据集于 2022 年发布，用于支持学术和行业研究。该项目的目标是为此数据集的“超级头”部分（B 类）的英语部分建立检索基线。然后，研究界可以使用这些基线来比较他们的系统，并生成数据来训练/评估新的检索和排名算法。该报告涵盖了稀疏和密集的第一阶段检索以及为此数据集实现的神经重新排序器。这些系统可作为卡内基梅隆大学集群上的服务使用。]]></description>
      <guid>https://arxiv.org/abs/2402.04357</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:22 GMT</pubDate>
    </item>
    <item>
      <title>AutoML 在推荐系统中的潜力</title>
      <link>https://arxiv.org/abs/2402.04453</link>
      <description><![CDATA[自动机器学习 (AutoML) 极大地推进了机器学习 (ML) 的应用，包括模型压缩、机器翻译和计算机视觉。推荐系统（RecSys）可以看作是机器学习的一种应用。然而，AutoML 在 RecSys 社区中几乎没有受到关注； RecSys 也没有在 AutoML 社区中引起显着关注。只有少数且相对简单的自动推荐系统 (AutoRecSys) 库采用 AutoML 技术。但是，这些库基于学生项目，不提供 AutoML 库的功能和全面开发。我们着手确定 AutoML 库在想要实施推荐系统的无经验用户的场景中的表现。我们比较了来自 15 个库的 60 个 AutoML、AutoRecSys、ML 和 RecSys 算法（包括平均预测器基线）在 14 个显式反馈 RecSys 数据集上的预测性能。为了模拟缺乏经验的用户的视角，使用默认超参数评估算法。我们发现 AutoML 和 AutoRecSys 库表现最佳。 AutoML 库在 14 个数据集中的 6 个（43%）中表现最佳，但并不总是同一个 AutoML 库表现最佳。单一最佳库是 AutoRecSys 库 Auto-Surprise，它在五个数据集上表现最好 (36%)。在三个数据集 (21%) 上，AutoML 库表现不佳，而具有默认参数的 RecSys 库表现最好。尽管 RecSys 算法在每个数据集的前 5 名中占所有位置的 50%，但平均落后于 AutoML。机器学习算法通常表现最差。]]></description>
      <guid>https://arxiv.org/abs/2402.04453</guid>
      <pubDate>Thu, 08 Feb 2024 15:13:22 GMT</pubDate>
    </item>
    </channel>
</rss>