<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 30 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>马尔可夫推荐过程中的价值函数分解</title>
      <link>https://arxiv.org/abs/2501.17409</link>
      <description><![CDATA[arXiv:2501.17409v1 公告类型：新
摘要：推荐系统的最新进展表明，用户与系统的交互本质上形成了长期优化问题，可以采用在线强化学习来提高推荐性能。通用解决方案框架包含一个价值函数，该函数估计用户未来的预期累积奖励并指导推荐策略的训练。为了避免局部最大值，该策略可以在推理过程中探索潜在的高质量动作，以增加找到更好未来奖励的机会。为了适应逐步推荐过程，一种广泛采用的学习价值函数的方法是从用户两个连续状态的值之间的差异中学习。然而，我们认为这种范式涉及随机过程中的错误近似。具体而言，在每个训练样本中的当前状态和下一个状态之间，存在来自随机策略和不确定用户环境的两个独立随机因素。在这些混合随机因素下进行原始时间差分 (TD) 学习可能会导致对长期奖励的次优估计。作为解决方案，我们表明可以通过分解原始时间差异损失分别近似这两个因素。解缠学习框架可以实现更准确的估计，学习速度更快，并且对动作探索的鲁棒性更高。作为我们提出的方法的实证验证，我们使用基于公共数据集构建的在线模拟环境进行离线实验。]]></description>
      <guid>https://arxiv.org/abs/2501.17409</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的推荐的不确定性量化和分解</title>
      <link>https://arxiv.org/abs/2501.17630</link>
      <description><![CDATA[arXiv:2501.17630v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 被广泛用于推荐，但我们证明 LLM 在其推荐中经常表现出不确定性。为了确保 LLM 在生成推荐中的可信使用，我们强调评估 LLM 生成的推荐的可靠性的重要性。我们首先介绍一个用于估计预测不确定性的新框架，以定量测量基于 LLM 的推荐的可靠性。我们进一步建议将预测不确定性分解为推荐不确定性和提示不确定性，从而能够对不确定性的主要来源进行深入分析。通过大量实验，我们 (1) 证明预测不确定性有效地表明了基于 LLM 的推荐的可靠性，(2) 使用分解的不确定性度量调查不确定性的来源，(3) 提出不确定性感知提示以降低预测不确定性并增强推荐。我们的源代码和模型权重可在 https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025 获得]]></description>
      <guid>https://arxiv.org/abs/2501.17630</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的序列推荐的卓越量化指导</title>
      <link>https://arxiv.org/abs/2501.17670</link>
      <description><![CDATA[arXiv:2501.17670v1 公告类型：新
摘要：扩散模型 (DM) 因其强大的数据分布建模能力和生成高质量项目的能力而成为顺序推荐的有前途的方法。现有工作通常会将噪声添加到下一个项目，并根据用户的交互序列逐步对其进行去噪，从而生成与用户兴趣紧密相关的项目。然而，我们发现这个范式有两个关键问题。首先，序列的长度和内容通常是异构的，由于随机的用户行为而表现出噪音。使用这样的序列作为指导可能会妨碍 DM 准确理解用户兴趣。其次，DM 容易出现数据偏差，往往只生成主导训练数据集的热门项目，从而无法满足不同用户的个性化需求。为了解决这些问题，我们提出了基于扩散的序列推荐的区分量化指导 (DiQDiff)，旨在提取强大的指导以了解用户兴趣并在 DM 中为个性化用户兴趣生成区分项目。为了提取强大的指导，DiQDiff 引入了语义矢量量化 (SVQ)，使用码本将序列量化为语义矢量（例如，协作信号和类别兴趣），这可以丰富指导以更好地理解用户兴趣。为了生成区分项目，DiQDiff 通过对比差异最大化 (CDM) 对生成进行个性化，它使用对比损失最大化去噪轨迹之间的距离，以防止针对不同用户的偏差生成。在四个广泛使用的数据集上进行了大量实验，以将 DiQDiff 与多个基线模型进行比较。DiQDiff 与领先方法相比的卓越推荐性能证明了其在序列推荐任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.17670</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WARP：高效的多向量检索引擎</title>
      <link>https://arxiv.org/abs/2501.17788</link>
      <description><![CDATA[arXiv:2501.17788v1 公告类型：新
摘要：我们研究了 ColBERT 及其最新变体 XTR 等多向量检索方法的效率。我们引入了 WARP，这是一种检索引擎，它通过三项关键创新大幅提高了基于 XTR 的 ColBERT 检索器的效率：(1) WARP$_\text{SELECT}$ 用于动态相似性插补，(2) 隐式解压缩以绕过昂贵的向量重建，以及 (3) 两阶段缩减过程以实现高效评分。结合优化的 C++ 内核和专门的推理运行时，WARP 与 XTR 的参考实现相比将端到端延迟降低了 41 倍，从而实现了比官方 ColBERT 实现的 PLAID 快 3 倍的速度。
我们研究了 ColBERT 及其最新变体 XTR 等多向量检索方法的效率。我们推出了 WARP，这是一种检索引擎，它通过三项关键创新大幅提高了基于 XTR 的 ColBERT 检索器的效率：(1) WARP$_\text{SELECT}$ 用于动态相似性插补，(2) 检索期间隐式解压缩，以及 (3) 两阶段缩减过程以实现高效评分。得益于高度优化的 C++ 内核和采用专门的推理运行时，WARP 可以将端到端查询延迟相对于 XTR 的参考实现减少 41 倍。因此，它比官方的 ColBERTv2 PLAID 引擎实现了 3 倍的速度提升，同时保持了检索质量。]]></description>
      <guid>https://arxiv.org/abs/2501.17788</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习技术对乌尔都语文本进行文档级情感分析</title>
      <link>https://arxiv.org/abs/2501.17175</link>
      <description><![CDATA[arXiv:2501.17175v1 公告类型：交叉 
摘要：文档级乌尔都语情绪分析 (SA) 是一项具有挑战性的自然语言处理 (NLP) 任务，因为它处理资源匮乏的语言中的大型文档。在大型文档中，有大量的单词表现出不同的观点。深度学习 (DL) 模型由复杂的神经网络架构组成，这些架构能够学习数据的不同特征来对各种情绪进行分类。除了音频、图像和视频分类之外，DL 算法现在广泛用于基于文本的分类问题。为了探索乌尔都语 SA 的强大 DL 技术，我们应用了五种不同的 DL 架构，即双向长短期记忆 (BiLSTM)、卷积神经网络 (CNN)、具有双向长短期记忆的卷积神经网络 (CNN-BiLSTM)、来自 Transformer 的双向编码器表示 (BERT)。在本文中，我们提出了一种将 BiLSTM 与单层多滤波器卷积神经网络 (BiLSTM-SLMFCNN) 相结合的 DL 混合模型。通过使用适用于文档级别 (SA) 的预训练乌尔都语词嵌入，将所提出的和基线技术应用于乌尔都语客户支持数据集和 IMDB 乌尔都语电影评论数据集。对这些技术的结果进行了评估，我们提出的模型优于乌尔都语 SA 的所有其他 DL 技术。BiLSTM-SLMFCNN 的表现优于基线 DL 模型，在小型、中型和大型 IMDB 乌尔都语电影评论数据集和乌尔都语客户支持数据集上分别实现了 83{\%}、79{\%}、83{\%} 和 94{\%} 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2501.17175</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能驱动的脑心互联组实时系统评价：最大限度地减少研究浪费并推进证据综合</title>
      <link>https://arxiv.org/abs/2501.17181</link>
      <description><![CDATA[arXiv:2501.17181v1 公告类型：交叉 
摘要：脑心互连组 (BHI) 结合了神经病学和心脏病学，但受到证据综合效率低下、质量标准遵守不力和研究浪费的阻碍。为了应对这些挑战，我们开发了一个人工智能驱动的系统来增强 BHI 领域的系统评价。该系统集成了对人群、干预、比较器、结果和研究设计 (PICOS) 的自动检测、使用向量嵌入的语义搜索、基于图形的查询和主题建模以识别冗余和未充分探索的领域。核心组件包括一个 Bi-LSTM 模型，可实现 87% 的 PICOS 合规性准确率，一个准确率达到 95.7% 的研究设计分类器，以及带有 GPT-3.5 的检索增强生成 (RAG)，其在基于图形和主题驱动的查询方面优于 GPT-4。该系统提供实时更新，通过动态数据库减少研究浪费，并提供带有仪表板和对话式 AI 的交互式界面。虽然该系统最初是为 BHI 开发的，但其适应性架构使其能够应用于各个生物医学领域，支持严格的证据综合、高效的资源分配和明智的临床决策。]]></description>
      <guid>https://arxiv.org/abs/2501.17181</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于观点总结的方面感知分解</title>
      <link>https://arxiv.org/abs/2501.17191</link>
      <description><![CDATA[arXiv:2501.17191v1 公告类型：交叉 
摘要：观点总结在从大规模在线评论中获取有意义的见解方面起着关键作用。为了使这个过程更易于解释和扎实，我们提出了一种由评论方面指导的模块化方法，将方面识别、观点整合和元评论综合的任务分开，从而提高透明度和易于检查。我们在代表科学研究、商业和产品领域的数据集上进行了广泛的实验。结果表明，与强大的基线模型相比，我们的方法生成了更有根据的摘要，这已通过自动和人工评估得到验证。此外，我们的模块化方法结合了基于评论方面的推理，比知识无关的分解提示产生了更具信息量的中间输出。这些中间输出还可以有效地支持人类从大量评论中总结意见。]]></description>
      <guid>https://arxiv.org/abs/2501.17191</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨语言的《古兰经》问答方法</title>
      <link>https://arxiv.org/abs/2501.17449</link>
      <description><![CDATA[arXiv:2501.17449v1 公告类型：交叉 
摘要：问答系统在资源有限、数据稀缺的语言中面临严重限制，这使得开发稳健的模型尤其具有挑战性。古兰经问答系统具有重要意义，因为它有助于更​​深入地理解古兰经，古兰经是全球十多亿人的圣书。然而，这些系统面临着独特的挑战，包括用现代标准阿拉伯语写的问题与用古典阿拉伯语写的古兰经经文中的答案之间的语言差异，以及现有数据集的规模较小，这进一步限制了模型的性能。为了应对这些挑战，我们采用跨语言方法，(1) 数据集增强：通过机器翻译扩展和丰富数据集，将阿拉伯语问题转换为英语，改写问题以创造语言多样性，并从古兰经的英语翻译中检索答案以满足多语言训练要求； （2）语言模型微调：利用 BERT-Medium、RoBERTa-Base、DeBERTa-v3-Base、ELECTRA-Large、Flan-T5、Bloom 和 Falcon 等预训练模型来满足《古兰经》问答的特定要求。实验结果表明，这种跨语言方法显著提高了模型性能，其中 RoBERTa-Base 实现了最高的 MAP@10（0.34）和 MRR（0.52），而 DeBERTa-v3-Base 在 Recall@10（0.50）和 Precision@10（0.24）方面表现出色。这些发现强调了跨语言策略在克服语言障碍和推进《古兰经》问答系统方面的有效性]]></description>
      <guid>https://arxiv.org/abs/2501.17449</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用多模式法学硕士 (LLM) 实现启发性用户界面搜索</title>
      <link>https://arxiv.org/abs/2501.17799</link>
      <description><![CDATA[arXiv:2501.17799v2 公告类型：交叉 
摘要：灵感搜索是探索设计以启发和激发新创意作品的过程，在移动用户界面 (UI) 设计中至关重要。然而，探索广阔的 UI 参考空间仍然是一个挑战。现有的基于 AI 的 UI 搜索方法通常会错过关键语义，例如目标用户或应用程序的心情。此外，这些模型通常需要元数据（如视图层次结构），从而限制了它们的实际用途。我们使用多模态大型语言模型 (MLLM) 从移动 UI 图像中提取和解释语义。我们通过形成性研究确定了关键的 UI 语义，并开发了一个基于语义的 UI 搜索系统。通过计算和人工评估，我们证明我们的方法明显优于现有的 UI 检索方法，为 UI 设计人员提供了更丰富、更符合上下文的搜索体验。我们增强了对移动 UI 设计语义的理解，并强调了 MLLM 在灵感搜索中的潜力，为未来的研究提供了丰富的 UI 语义数据集。]]></description>
      <guid>https://arxiv.org/abs/2501.17799</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数字病理学中单向量 WSI 表征学习的聚合方案</title>
      <link>https://arxiv.org/abs/2501.17822</link>
      <description><![CDATA[arXiv:2501.17822v1 公告类型：交叉 
摘要：在计算病理学中有效整合全幻灯片图像 (WSI) 的关键步骤是为每个 WSI 分配一个高质量的特征向量，即一个嵌入。随着许多预训练深度神经网络的存在和基础模型的出现，提取子图像（即图块或补丁）的嵌入非常简单。然而，对于 WSI，鉴于其高分辨率和千兆像素特性，将它们作为单个图像输入现有 GPU 是不可行的。因此，WSI 通常被分成许多补丁。将每个补丁输入到预先训练的模型中，每个 WSI 都可以由一组补丁表示，因此，一组嵌入。因此，在这样的设置中，WSI 表示学习简化为集合表示学习，其中对于每个 WSI，我们都可以访问一组补丁嵌入。为了从一组块嵌入中为每个 WSI 获取单个嵌入，文献中提出了多种基于集合的学习方案。在本文中，我们评估了多种最近开发的聚合技术（主要是集合表示学习技术）在 TCGA 中的 WSI 搜索性能，包括简单的平均或最大池化操作、深度集、记忆网络、焦点注意、高斯混合模型 (GMM) Fisher 向量以及深度稀疏和二元 Fisher 向量，这些向量在四个不同的主要部位（包括膀胱、乳腺、肾脏和结肠）上的表现。此外，我们根据块嵌入的最小距离中值（一种用于 WSI 检索的非聚合方法）对这些方法的搜索性能进行了基准测试。]]></description>
      <guid>https://arxiv.org/abs/2501.17822</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图序列对齐和均匀性：面向增强型推荐系统</title>
      <link>https://arxiv.org/abs/2412.04276</link>
      <description><![CDATA[arXiv:2412.04276v2 公告类型：替换 
摘要：基于图和顺序的方法是两种流行的推荐范例，每种方法在各自的领域都表现出色，但缺乏利用其他方法信号的能力。为了解决这个问题，我们提出了一种集成两种方法以提高性能的新方法。我们的框架使用基于图神经网络 (GNN) 和顺序推荐器作为单独的子模块，同时共享联合优化的统一嵌入空间。为了实现积极的知识转移，我们设计了一个损失函数，在子模块内和子模块之间强制对齐和统一。在三个真实数据集上进行的实验表明，所提出的方法明显优于单独使用任何一种方法，并取得了最先进的结果。我们的实现在 https://github.com/YuweiCao-UIC/GSAU.git 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2412.04276</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WavePulse：电台直播的实时内容分析</title>
      <link>https://arxiv.org/abs/2412.17998</link>
      <description><![CDATA[arXiv:2412.17998v2 公告类型：替换 
摘要：广播仍然是大众信息传播的普遍媒介，AM/FM 电台覆盖的美国人比基于智能手机的社交网络或直播电视还要多。越来越多的广播也通过互联网在线播放和访问。我们提出了 WavePulse，这是一个实时记录、记录和分析广播内容的框架。虽然我们的框架普遍适用，但我们在与专注于 2024 年总统大选的政治科学家团队的合作项目中展示了 WavePulse 的有效性。我们使用 WavePulse 在三个月内监控 396 个新闻广播电台的直播，处理了近 500,000 小时的音频流。这些流被转换成带时间戳的日记记录，并进行了分析以跟踪国家和州一级的关键政治科学问题的答案。我们的分析揭示了地方问题如何与国家趋势相互作用，从而提供了对信息流的洞察。我们的结果表明 WavePulse 在捕获和分析来自网络的广播直播内容方面非常有效。代码和数据集可在 \url{https://wave-pulse.io} 上访问。]]></description>
      <guid>https://arxiv.org/abs/2412.17998</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LayerPlexRank：通过多路复用网络中的代数连通性探索节点中心性和层影响力</title>
      <link>https://arxiv.org/abs/2405.05576</link>
      <description><![CDATA[arXiv:2405.05576v2 公告类型：replace-cross 
摘要：随着复杂网络中中心性的计算在技术、生物和社会系统中变得越来越重要，精确且可扩展的排名方法对于理解这些网络至关重要。本文介绍了 LayerPlexRank，这是一种使用代数连通性指标同时评估多路复用网络中节点中心性和层影响力的算法。该方法通过使用随机游走有效地评估跨层结构变化，考虑到图的整体连通性，增强了排名算法的稳健性。我们通过对各种现实世界数据集的理论分析和实证验证证实了 LayerPlexRank 的实用性，并将其与已建立的中心性度量进行了对比。]]></description>
      <guid>https://arxiv.org/abs/2405.05576</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论具有比例排序函数的信息检索博弈中的无遗憾动态收敛</title>
      <link>https://arxiv.org/abs/2405.11517</link>
      <description><![CDATA[arXiv:2405.11517v3 公告类型：replace-cross 
摘要：在网络上发布内容的发布者采取策略性行为，其行为可以在在线学习框架内建模。遗憾是机器学习的核心概念，是评估此框架内学习代理性能的规范指标。我们证明，任何具有凹激活函数的比例内容排名函数都会引发无遗憾学习动态收敛的游戏。此外，对于比例排名函数，我们证明了激活函数的凹度、诱导游戏的社会凹度和诱导游戏的凹度的等价性。我们还使用最先进的无遗憾动态算法研究了在不同激活函数选择下，发布者和用户福利之间的经验权衡。此外，我们展示了排名函数的选择和生态系统结构的变化如何影响这些福利措施以及动态的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2405.11517</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>