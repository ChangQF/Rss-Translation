<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 24 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>迈向实体解析的通用密集阻塞</title>
      <link>https://arxiv.org/abs/2404.14831</link>
      <description><![CDATA[arXiv:2404.14831v1 公告类型：交叉
摘要：分块是实体解析的关键步骤，基于神经网络的表示模型的出现导致了密集分块的发展，成为探索分块中深层语义的有前途的方法。然而，以前的先进自监督密集阻塞方法需要对目标域进行特定领域的训练，这限制了这些方法的好处和快速适应。为了解决这个问题，我们提出了 UBlocker，这是一种密集拦截器，它使用自监督对比学习在独立于领域、易于获得的表格语料库上进行预训练。通过进行与领域无关的预训练，UBlocker可以适应各种下游阻塞场景，而无需针对特定领域进行微调。为了评估我们的实体拦截器的通用性，我们还构建了一个新的基准，涵盖来自多个领域和场景的广泛拦截任务。我们的实验表明，所提出的 UBlocker 在没有任何特定领域学习的情况下，显着优于以前的自监督和无监督密集块方法，并且与最先进的稀疏块方法具有可比性和补充性。]]></description>
      <guid>https://arxiv.org/abs/2404.14831</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>用于少量关键词识别的多样本动态时间扭曲</title>
      <link>https://arxiv.org/abs/2404.14903</link>
      <description><![CDATA[arXiv:2404.14903v1 公告类型：交叉
摘要：在多样本关键词识别中，每个关键词类别由多个口语实例（称为样本）表示。检测目标序列中的关键字的简单方法包括使用子序列动态时间扭曲查询所有类别的所有样本。然而，所得到的处理时间相对于属于每个类别的样本数量线性增加。 ，每个类只能查询一个 Fr\&#39;echet 均值，从而减少处理时间，但通常也会导致检测性能较差，因为在这项工作中，多样本动态时间没有充分捕获查询样本的可变性。提出扭曲来计算包含所有查询样本的可变性的特定于类的成本张量，为了显着降低推理过程中的计算复杂性，在小样本的实验评估中，在应用动态时间扭曲之前将这些成本张量转换为成本矩阵。关键字发现，结果表明，该方法产生的性能与使用所有单独的查询样本作为模板非常相似，而运行时间仅比使用 Fr\&#39;echet 方法时稍慢。]]></description>
      <guid>https://arxiv.org/abs/2404.14903</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>操纵推荐系统：中毒攻击和对策调查</title>
      <link>https://arxiv.org/abs/2404.14942</link>
      <description><![CDATA[arXiv:2404.14942v1 公告类型：交叉
摘要：推荐系统已成为在线服务不可或缺的一部分，可帮助用户在数据海洋中定位特定信息。然而，现有的研究表明，一些推荐系统容易受到中毒攻击，特别是那些涉及学习方案的推荐系统。中毒攻击是指攻击者将精心设计的数据注入模型训练过程中，目的是操纵系统的最终建议。基于人工智能的最新进展，此类攻击最近变得越来越重要。尽管已经制定了许多针对中毒攻击的对策，但它们尚未系统地与攻击的特性联系起来。因此，评估缓解策略的各自风险和潜在成功即使不是不可能，也是很困难的。本调查旨在通过主要关注中毒攻击及其对策来填补这一空白。这与之前主要关注攻击及其检测方法的调查形成鲜明对比。通过详尽的文献综述，我们为中毒攻击提供了一种新颖的分类法，将其维度形式化，并相应地组织了文献中描述的 30 多种攻击。此外，我们还审查了 40 多种检测和/或防止中毒攻击的对策，评估它们针对特定类型攻击的有效性。这项全面的调查应作为保护推荐系统免受中毒攻击的参考点。本文最后讨论了该领域的未解决问题以及未来研究的影响方向。 https://github.com/tamlhp/awesome-recsys-poisoning 提供了与中毒攻击相关的丰富资源库。]]></description>
      <guid>https://arxiv.org/abs/2404.14942</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>通过学习用户编辑的潜在偏好来调整 LLM 代理</title>
      <link>https://arxiv.org/abs/2404.15269</link>
      <description><![CDATA[arXiv:2404.15269v1 公告类型：交叉
摘要：我们基于用户对代理输出的编辑来研究语言代理的交互式学习。在诸如写作助理之类的典型设置中，用户与语言代理交互以在给定上下文的情况下生成响应，并且除了提高正确性之外，还可以选择编辑代理响应以根据他们的潜在偏好对其进行个性化。编辑反馈是自然生成的，使其成为提高代理与用户偏好的一致性以及随着时间的推移降低用户编辑成本的合适候选者。我们提出了一个学习框架 PRELUDE，它根据历史编辑数据推断用户潜在偏好的描述，并使用它来定义驱动未来响应生成的提示策略。这避免了对代理进行微调，这种微调成本高昂，难以随着用户数量的增长而扩展，甚至可能会降低其在其他任务上的性能。此外，学习描述性偏好可以提高可解释性，允许用户查看和修改学习到的偏好。然而，用户偏好可能很复杂，并且会根据上下文而变化，这使得学习变得困难。为了解决这个问题，我们提出了一种名为 CIPHER 的简单而有效的算法，该算法利用大型语言模型 (LLM) 根据用户编辑来推断用户对给定上下文的偏好。未来，CIPHER 从历史上 k 个最接近的上下文中检索推断的偏好，并形成响应生成的聚合偏好。我们引入了两种交互式环境——摘要和电子邮件写作，以使用 GPT-4 模拟用户进行评估。我们与直接检索用户编辑但不学习描述性偏好的算法以及学习上下文无关偏好的算法进行比较。在这两项任务中，CIPHER 实现了最低的编辑距离成本，并学习与地面真实偏好显示出显着相似性的偏好]]></description>
      <guid>https://arxiv.org/abs/2404.15269</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>先进文本匿名化方法的基准测试：新颖与传统方法的比较研究</title>
      <link>https://arxiv.org/abs/2404.14465</link>
      <description><![CDATA[arXiv:2404.14465v1 公告类型：交叉
摘要：在数据隐私领域，有效匿名文本的能力至关重要。随着深度学习，特别是 Transformer 架构的普及，人们对利用这些先进模型执行文本匿名化任务的兴趣日益浓厚。本文提出了一项全面的基准测试研究，将基于 Transformer 的模型和大型语言模型 (LLM) 的性能与传统文本匿名化架构进行比较。利用以其稳健性和多样性而闻名的 CoNLL-2003 数据集，我们评估了多个模型。我们的结果展示了每种方法的优点和缺点，为现代方法与传统方法的有效性提供了清晰的视角。值得注意的是，虽然现代模型在捕捉上下文细微差别方面表现出先进的能力，但某些传统架构仍然保持高性能。这项工作旨在指导研究人员选择最适合其匿名化需求的模型，同时也揭示该领域未来发展的潜在路径。]]></description>
      <guid>https://arxiv.org/abs/2404.14465</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>用于特定领域问答的检索增强生成</title>
      <link>https://arxiv.org/abs/2404.14760</link>
      <description><![CDATA[arXiv:2404.14760v1 公告类型：交叉
摘要：问答（QA）已成为大型语言模型高级开发中的重要应用。用于问答的一般预训练大语言模型并未经过训练来正确理解特定领域的知识或术语，例如金融、医疗保健、教育和产品的客户服务。为了更好地满足特定领域的理解，我们为 Adob​​e 产品构建了一个内部问答系统。我们提出了一种新颖的框架来编译大型问答数据库，并开发用于大型语言模型的检索感知微调的方法。我们展示了对检索器的微调导致了最后一代的重大改进。我们的整体方法减少了生成过程中的幻觉，同时将最新的检索信息保留在上下文中以进行上下文基础。]]></description>
      <guid>https://arxiv.org/abs/2404.14760</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>用于视听检索的锚感知深度度量学习</title>
      <link>https://arxiv.org/abs/2404.13789</link>
      <description><![CDATA[arXiv:2404.13789v1 公告类型：交叉
摘要：度量学习最小化相似（正）数据点对之间的差距，并增加不相似（负）数据点对的分离，旨在捕获底层数据结构并增强视听跨模态检索（AV）等任务的性能。 -CMR）。最近的工作采用采样方法在训练期间从嵌入空间中选择有影响力的数据点。然而，由于训练数据点的稀缺，模型训练未能充分探索空间，导致整体正负分布的表示不完整。在本文中，我们提出了一种创新的锚感知深度度量学习（AADML）方法，通过揭示现有数据点之间的潜在相关性来应对这一挑战，从而提高共享嵌入空间的质量。具体来说，我们的方法通过考虑作为锚点的每个样本与其语义相似样本之间的依赖关系，建立基于相关图的流形结构。通过使用注意力驱动机制对该底层流形结构内的相关性进行动态加权，获得每个锚点的锚点意识（AA）分数。这些 AA 分数充当数据代理来计算度量学习方法中的相对距离。在两个视听基准数据集上进行的大量实验证明了我们提出的 AADML 方法的有效性，显着超越了最先进的模型。此外，我们研究了 AA 代理与各种度量学习方法的集成，进一步凸显了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.13789</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型监控灾难期间的关键基础设施</title>
      <link>https://arxiv.org/abs/2404.14432</link>
      <description><![CDATA[arXiv:2404.14432v1 公告类型：交叉
摘要：关键基础设施（CIF），例如医疗保健和交通设施，对于社区的运作至关重要，特别是在大规模紧急情况下。在本文中，我们探讨了大型语言模型 (LLM) 的潜在应用，通过社交媒体网络中传播的信息来监测受自然灾害影响的 CIF 的状态。为此，我们分析了两个不同国家的两起灾难事件的社交媒体数据，以确定报告的对 CIF 的影响及其影响严重程度和运行状态。我们采用最先进的开源法学硕士来执行计算任务，包括检索、分类和推理，所有这些都在零样本设置中进行。通过广泛的实验，我们使用标准评估指标报告这些任务的结果，并揭示对法学硕士的优势和劣势的见解。我们注意到，虽然法学硕士在分类任务中表现良好，但他们在推理任务中遇到了挑战，特别是当上下文/提示复杂且冗长时。此外，我们概述了未来探索的各种潜在方向，这些方向在法学硕士用于灾难响应任务的初始采用阶段可能是有益的。]]></description>
      <guid>https://arxiv.org/abs/2404.14432</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>评论树：基于树的多跳问答动态迭代检索框架</title>
      <link>https://arxiv.org/abs/2404.14464</link>
      <description><![CDATA[arXiv:2404.14464v1 公告类型：交叉
摘要：多跳问答是一个知识密集型的复杂问题。大型语言模型（LLM）利用其思想链（CoT）能力逐步推理复杂问题，检索增强可以有效减轻LLM中过时和未知知识造成的事实错误。最近的工作在 CoT 推理中引入了检索增强来解决多跳问答。然而，这些链式方法存在以下问题：1）检索到不相关的段落可能会误导推理； 2）链结构中的一个错误可能会导致错误的级联。
  在本文中，我们提出了一种称为评论树（ToR）的动态检索框架，其中根节点是问题，其他节点是检索中的段落，将不同的推理路径从根节点延伸到其他节点。我们的框架根据推理路径上的段落动态地决定启动新的搜索、拒绝或接受。与相关工作相比，我们引入了树结构来单独处理每个检索到的段落，减轻了不相关段落对推理路径的误导作用；推理路径延伸的多样性减少了单个推理错误对整体的影响。我们对三个不同的多跳问答数据集进行了实验。结果表明，与基线方法相比，ToR 在检索和响应生成方面都实现了最先进的性能。此外，我们提出了两种基于树的搜索优化策略，剪枝和有效扩展，以减少时间开销并增加路径扩展的多样性。我们将发布我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2404.14464</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>用于分布外推荐的跨域因果偏好学习</title>
      <link>https://arxiv.org/abs/2404.14856</link>
      <description><![CDATA[arXiv:2404.14856v1 公告类型：新
摘要：推荐系统使用用户的历史交互来了解他们的偏好，并从大量候选项目中提供个性化推荐。当前的推荐系统主要依赖于训练和测试数据集具有相同分布的假设，这在现实中可能不成立。事实上，训练数据集和测试数据集之间的分布变化通常是由于用户属性的演变而发生的，这降低了传统推荐系统的性能，因为它们无法进行分布外（OOD）泛化，特别是在以下情况下：数据稀疏性。这项研究深入探讨了 OOD 泛化的挑战，并提出了一种名为“分布外推荐的跨域因果偏好学习”(CDCOR) 的新颖模型，其中涉及采用域对抗网络来发现用户的域共享偏好，并利用因果结构学习器捕获因果不变性来处理 OOD 问题。通过对两个真实世界数据集的广泛实验，我们验证了我们的模型在处理数据稀疏和分布外环境的各种场景方面的卓越性能。此外，我们的方法超越了基准模型，展示了分布外泛化的出色能力。]]></description>
      <guid>https://arxiv.org/abs/2404.14856</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>PLAID 的再现性研究</title>
      <link>https://arxiv.org/abs/2404.14989</link>
      <description><![CDATA[arXiv:2404.14989v1 公告类型：新
摘要：ColBERTv2 的 PLAID（性能优化的后期交互驱动程序）算法使用集群术语表示来检索并逐步修剪文档，以实现最终（精确）文档评分。在本文中，我们复制并填补了原始作品中缺失的空白。通过研究PLAID引入的参数，我们发现其Pareto前沿是由其三个参数之间的仔细平衡形成的；超出建议设置的偏差可能会大大增加延迟，但不一定会提高其有效性。然后，我们将 PLAID 与论文中缺失的一个重要基线进行比较：重新排序词汇系统。我们发现，应用 ColBERTv2 作为初始 BM25 结果池的重新排序器可以在低延迟设置中提供更好的效率-效果权衡。然而，由于词汇匹配调用的限制，重新排序无法在较高延迟设置下达到最高效率，并且无法提供详尽的 ColBERTv2 搜索的近似值。我们发现，最近提出的重新排名修改方案克服了这一限制，引入了得分最高的文档的邻居，在使用注释良好的数据集进行评估时，为 ColBERTv2 的所有操作点提供了帕累托前沿。出于好奇为什么重新排序方法与 PLAID 具有很强的竞争力，我们分析了 PLAID 用于检索的标记表示集群，发现大多数集群主要与单个标记对齐，反之亦然。考虑到重新排名基线所表现出的竞争性权衡，这项工作强调了在评估检索引擎的效率时仔细选择相关基线的重要性。]]></description>
      <guid>https://arxiv.org/abs/2404.14989</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>文本本体学习简述：从浅层学习、深度学习到大型语言模型趋势</title>
      <link>https://arxiv.org/abs/2404.14991</link>
      <description><![CDATA[arXiv:2404.14991v1 公告类型：新
摘要：本体提供了语义 Web 应用程序中共享知识的正式表示，从文本中学习本体涉及从给定的文本语料库构建本体。在过去的几年里，本体学习经历了浅层学习和深度学习方法论，每种方法在寻求知识提取和表示方面都具有独特的优势和局限性。这些方法的一个新趋势是依靠大型语言模型来增强本体学习。本文回顾了本体学习的方法和挑战。分析了基于浅层学习和深度学习的本体学习技术的方法和局限性，为利用大型语言模型增强本体学习的前沿工作提供了全面的知识。此外，它还提出了几个值得注意的未来方向，以进一步探索大型语言模型与本体学习任务的集成。]]></description>
      <guid>https://arxiv.org/abs/2404.14991</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>生成检索中的提前规划：通过同时解码指导自回归生成</title>
      <link>https://arxiv.org/abs/2404.14600</link>
      <description><![CDATA[arXiv:2404.14600v1 公告类型：新
摘要：本文介绍了 PAG——一种新颖的优化和解码方法，该方法通过同步解码指导生成检索模型中文档标识符的自回归生成。为此，PAG 为每个文档构建了一个基于集合的顺序标识符。受信息检索中词袋假设的启发，基于集合的标识符建立在词汇标记的基础上。另一方面，顺序标识符是通过量化基于相关性的文档表示来获得的。对 MSMARCO 和 TREC Deep Learning Track 数据的大量实验表明，PAG 的性能大幅优于最先进的生成检索模型（例如，MS MARCO 的 MRR 提高了 15.6%），同时在查询方面实现了 22 倍的速度提升潜伏。]]></description>
      <guid>https://arxiv.org/abs/2404.14600</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>用于生成推荐的基于对比量化的语义代码</title>
      <link>https://arxiv.org/abs/2404.14774</link>
      <description><![CDATA[arXiv:2404.14774v1 公告类型：新
摘要：随着大型语言模型的成功，生成检索已成为一种新的推荐检索技术。它可以分为两个阶段：第一阶段涉及构建离散代码（即代码），第二阶段涉及通过变压器架构顺序解码代码。当前的方法通常通过重建基于项目文本表示的量化来构建项目语义代码，但它们无法捕获在推荐系统中对项目关系进行建模时至关重要的项目差异。在本文中，我们建议通过同时考虑项目关系和语义信息来构建项目的代码表示。具体来说，我们采用预先训练的语言模型来提取项目的文本描述并将其转换为项目的嵌入。然后，我们建议增强基于编码器-解码器的 RQVAE 模型，并具有对比目标来学习项目代码。具体来说，我们使用解码器从样本本身生成的嵌入作为正实例，将其他样本生成的嵌入作为负实例。因此，我们有效地增强了所有项目之间的项目差异，更好地保留了项目邻域。最后，我们在顺序推荐模型上使用生成检索来训练和测试语义代码。我们的实验表明，与之前的基线相比，我们的方法在 MIND 数据集上将 NDCG@5 提高了 43.76%，在 Office 数据集上将 Recall@10 提高了 80.95%。]]></description>
      <guid>https://arxiv.org/abs/2404.14774</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>从匹配到生成：生成信息检索调查</title>
      <link>https://arxiv.org/abs/2404.14851</link>
      <description><![CDATA[arXiv:2404.14851v1 公告类型：新
摘要：信息检索（IR）系统是用户获取信息的重要工具，广泛应用于搜索引擎、问答、推荐系统等场景。传统的 IR 方法基于相似性匹配来返回排序的文档列表，一直是可靠的信息获取手段，多年来主导着 IR 领域。随着预训练语言模型的进步，生成信息检索（GenIR）已成为一种新颖的范式，近年来受到越来越多的关注。目前，GenIR 的研究可分为两个方面：生成文档检索（GR）和可靠响应生成。 GR 利用生成模型的参数来记忆文档，无需显式索引即可通过直接生成相关文档标识符来进行检索。而可靠响应生成则利用语言模型直接生成用户寻求的信息，突破了传统IR在文档粒度和相关性匹配方面的限制，提供了更大的灵活性、效率和创造性，从而更好地满足实际需求。本文旨在系统回顾GenIR的最新研究进展。我们将总结GR在模型训练、文档识别、增量学习、下游任务自适应、多模态GR和生成推荐方面的进展，以及内部知识记忆、外部知识增强、生成响应等方面在可靠响应生成方面的进展带有引文和个人信息助手。我们还回顾了 GenIR 系统的评估、挑战和未来前景。本综述旨在为GenIR领域的研究人员提供全面的参考，鼓励该领域的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2404.14851</guid>
      <pubDate>Wed, 24 Apr 2024 06:20:14 GMT</pubDate>
    </item>
    </channel>
</rss>