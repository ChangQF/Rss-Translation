<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>从矩阵秩的角度理解和扩展协同过滤优化</title>
      <link>https://arxiv.org/abs/2410.23300</link>
      <description><![CDATA[arXiv:2410.23300v1 公告类型：新
摘要：协同过滤 (CF) 方法在现实世界的推荐系统中占据主导地位，因为它们能够学习高质量、稀疏的 ID 嵌入表，从而有效地捕捉用户偏好。这些表随用户和项目的数量线性扩展，并经过训练以确保交互的用户-项目对的嵌入之间具有高相似性，同时保持非交互对的低相似性。尽管它们具有高性能，但鼓励非交互对的分散需要昂贵的正则化（例如负采样），从而损害运行时间和可扩展性。现有研究倾向于通过简化学习过程来解决这些挑战，方法是降低模型复杂性或采样数据，以性能换取运行时间。在这项工作中，我们超越了模型级修改，研究了不同学习策略下嵌入表的属性。通过理论分析，我们发现嵌入表的奇异值与不同的 CF 损失函数有着内在联系。这些发现已在真实数据集上得到实证验证，证明了更高稳定秩的实际优势，稳定秩是矩阵秩的连续版本，用于编码奇异值的分布。基于这些见解，我们提出了一种有效的热启动策略，用于规范用户和项目嵌入的稳定秩。我们表明，在早期训练阶段进行稳定秩正则化可以促进更高质量的嵌入，从而使训练速度提高高达 66%。此外，稳定秩正则化可以充当负采样的代理，与具有较小负采样率的损失函数相比，性能提升高达 21%。总体而言，我们的分析将当前的 CF 方法统一在一个新视角下，即对稳定秩的优化，从而激发了一种灵活的正则化方法。]]></description>
      <guid>https://arxiv.org/abs/2410.23300</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>展示链接电池数据以加速电池科学的知识流</title>
      <link>https://arxiv.org/abs/2410.23303</link>
      <description><![CDATA[arXiv:2410.23303v1 公告类型：新
摘要：电池对于过渡到气候友好型未来至关重要，从而导致电池研究激增。Scopus（Elsevier）仅在 2023 年就列出了 14,388 篇提及“锂离子电池”的论文，个人无法跟上。本文讨论了基于结构化、语义和链接数据的策略来管理这种信息过载。结构化数据遵循预定义的、机器可读的格式；语义数据包括上下文元数据；链接数据引用其他语义数据，形成一个相互关联的信息网络。我们使用与电池相关的本体 BattINFO 来标准化术语并实现自动数据提取和分析。我们的方法集成了全文搜索和机器可读数据，增强了数据检索和电池测试。我们的目标是统一商业电池信息并为电池社区开发工具，例如独立于制造商的循环程序描述和用于大型语言模型的外部存储器。虽然这只是第一步，但这种方法大大加快了电池研究，使电池测试数字化，并邀请社区参与持续改进。我们提供结构化数据和访问这些数据的工具，这些工具是开源的。]]></description>
      <guid>https://arxiv.org/abs/2410.23303</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现具有更好模态对齐的跨模态文本分子检索</title>
      <link>https://arxiv.org/abs/2410.23715</link>
      <description><![CDATA[arXiv:2410.23715v1 公告类型：新
摘要：跨模态文本-分子检索模型旨在学习文本和分子模态的共享特征空间以进行准确的相似度计算，这有助于在药物设计中快速筛选具有特定性质和活性的分子。然而，以前的工作有两个主要缺陷。首先，考虑到文本序列和分子图之间的巨大差距，它们在捕获模态共享特征方面不足。其次，它们主要依靠对比学习和对抗训练进行跨模态对齐，这两者都主要关注一阶相似性，而忽略了可以在嵌入空间中捕获更多结构信息的二阶相似性。为了解决这些问题，我们提出了一种具有两重改进的新型跨模态文本-分子检索模型。具体而言，在两个特定于模态的编码器之上，我们堆叠了一个基于存储库的特征投影仪，其中包含可学习的记忆向量，以更好地提取模态共享特征。更重要的是，在模型训练过程中，我们为每个实例计算四种相似性分布（文本到文本、文本到分子、分子到分子和分子到文本相似性分布），然后最小化这些相似性分布之间的距离（即二阶相似性损失）以增强跨模态对齐。实验结果和分析有力地证明了我们模型的有效性。特别是，我们的模型实现了 SOTA 性能，比之前报告的最好结果高出 6.4%。]]></description>
      <guid>https://arxiv.org/abs/2410.23715</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别然后推荐：面向无监督群组推荐</title>
      <link>https://arxiv.org/abs/2410.23757</link>
      <description><![CDATA[arXiv:2410.23757v1 公告类型：新 
摘要：群组推荐（GR）旨在向用户群组推荐项目，已成为推荐系统的一个有前途且实用的方向。本文指出了最先进的 GR 模型的两个问题。（1）预定义和固定数量的用户组不足以满足实时工业推荐系统的需求，因为组分布可能会动态变化。（2）现有 GR 方法的训练模式是监督的，需要昂贵的用户组和组项目标签，从而导致注释成本高昂。为此，我们提出了一种新颖的无监督群组推荐框架，名为 \underline{I}identify \underline{T}hen \underline{R}ecommend（\underline{ITR}），其中它首先以无监督的方式识别用户组，即使没有预定义的组数量，然后设计两个前置任务来进行自监督群组推荐。具体而言，在群组识别阶段，我们首先估计每个用户点的自适应密度，其中密度较高的区域更有可能被识别为群组中心。然后，设计启发式合并与分裂策略来发现用户群组和决策边界。随后，在自监督学习阶段，提出拉动与排斥前置任务来优化用户群组分布。此外，还设计了伪群组推荐前置任务来辅助推荐。大量实验证明了 ITR 在用户推荐（例如 22.22\% NDCG@5 $\uparrow$）和群组推荐（例如 22.95\% NDCG@5 $\uparrow$）方面的优越性和有效性。此外，我们在工业推荐器上部署了 ITR 并取得了令人欣喜的结果。]]></description>
      <guid>https://arxiv.org/abs/2410.23757</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越内容相关性：评估检索模型中的指导遵循情况</title>
      <link>https://arxiv.org/abs/2410.23841</link>
      <description><![CDATA[arXiv:2410.23841v1 公告类型：新
摘要：大型语言模型 (LLM) 中的指令跟踪能力已取得显著进展，通过详细的提示实现了更复杂的用户交互。然而，检索系统并没有跟上这些进步，它们中的大多数仍然依赖于传统的词汇和语义匹配技术，无法完全捕捉用户意图。最近的努力引入了指令感知检索模型，但这些模型主要关注内在内容相关性，而忽略了定制偏好对更广泛的文档级属性的重要性。本研究评估了各种检索模型在内容相关性之外的指令跟踪能力，包括基于 LLM 的密集检索和重新排序模型。我们开发了 InfoSearch，这是一种新颖的检索评估基准，涵盖六个文档级属性：受众、关键字、格式、语言、长度和来源，并引入了新颖的指标——严格指令遵从率 (SICR) 和加权指令敏感度评估 (WISE)，以准确评估模型对指令的响应能力。我们的研究结果表明，虽然重新排序模型在指令遵循方面通常优于检索模型，但它们在处理某些属性方面仍面临挑战。此外，尽管指令微调和模型大小增加可以提高性能，但大多数模型都未能实现我们基准评估的全面指令遵从性。]]></description>
      <guid>https://arxiv.org/abs/2410.23841</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行医学信息提取和查询生成</title>
      <link>https://arxiv.org/abs/2410.23851</link>
      <description><![CDATA[arXiv:2410.23851v1 公告类型：新
摘要：本文介绍了一种将大型语言模型 (LLM) 集成到临床试验检索过程中的系统，提高了将患者与符合条件的试验进行匹配的有效性，同时保持了信息隐私并允许专家监督。我们评估了六个 LLM 的查询生成，重点关注需要最少计算资源的开源和相对较小的模型。我们的评估包括两个闭源模型和四个开源模型，其中一个专门在医学领域进行训练，五个通用模型。我们将 LLM 生成的查询所实现的检索效果与医学专家创建的查询和文献中的最新方法进行了比较。我们的研究结果表明，评估的模型的检索效果与专家创建的查询相当或更高。LLM 始终优于文献中的标准基线和其他方法。性能最佳的 LLM 具有快速响应时间，范围从 1.7 到 8 秒，并生成可管理的查询词数量（平均 15-63 个），使其适合实际实施。我们的总体研究结果表明，利用小型开源 LLM 进行临床试验检索可以平衡医疗环境中的性能、计算效率和实际适用性。]]></description>
      <guid>https://arxiv.org/abs/2410.23851</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过与法学硕士 (LLM) 的相对比较调查政治搜索查询建议中的偏见</title>
      <link>https://arxiv.org/abs/2410.23879</link>
      <description><![CDATA[arXiv:2410.23879v1 公告类型：新
摘要：搜索查询建议会影响用户与搜索引擎的交互，进而影响他们遇到的信息。因此，搜索查询建议中的偏见会导致出现有偏见的搜索结果，并影响意见的形成。这在政治领域尤其重要。由于网络搜索引擎的主题依赖性、复杂性和主观性，检测和量化网络搜索引擎中的偏见非常困难。查询建议缺乏上下文和短语性，这加剧了这个问题。在多步骤方法中，我们结合了大型语言模型、成对比较和基于 Elo 的评分的优点，以识别和量化英语搜索查询建议中的偏见。我们将我们的方法应用于美国政治新闻领域，并比较了 Google 和 Bing 中的偏见。]]></description>
      <guid>https://arxiv.org/abs/2410.23879</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意差距：跨模态嵌入对齐的通用方法</title>
      <link>https://arxiv.org/abs/2410.23437</link>
      <description><![CDATA[arXiv:2410.23437v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 系统通过整合外部知识来增强文本生成，但由于语义差距，在跨不同文本模态检索上下文时往往会遇到困难。我们引入了一种基于广义投影的方法，该方法受到迁移学习中的适配器模块的启发，可以有效地弥合各种文本类型之间的差距，例如编程代码和伪代码，或英语和法语句子。我们的方法强调速度、准确性和数据效率，需要最少的资源进行训练和推理。通过轻量级投影网络将来自异构文本模态的嵌入对齐到统一空间，我们的模型明显优于传统检索方法，如 Okapi BM25 算法和密集段落检索 (DPR) 等模型，同时接近句子变换器的准确性。大量的评估证明了我们的方法在不同任务中的有效性和通用性，凸显了其在实时、资源受限应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.23437</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示推荐平台中用户满意度与创作者生产力之间的权衡</title>
      <link>https://arxiv.org/abs/2410.23683</link>
      <description><![CDATA[arXiv:2410.23683v1 公告类型：交叉 
摘要：在用户生成内容 (UGC) 平台上，推荐算法显著影响了创作者制作内容的动机，因为他们争夺算法分配的用户流量。这种现象微妙地塑造了内容池的数量和多样性，这对于平台的可持续性至关重要。在这项工作中，我们从理论和经验上证明，纯相关性驱动的低探索强度策略可以提高短期用户满意度，但会破坏内容池的长期丰富性。相反，更积极的探索策略可能会略微损害用户满意度，但会促进更高的内容创作量。我们的研究结果揭示了 UGC 平台上即时用户满意度和整体内容制作之间的根本权衡。基于这一发现，我们提出了一种有效的优化方法来确定最佳探索强度，平衡用户和创作者的参与度。我们的模型可以作为 UGC 平台上推荐算法的部署前审计工具，帮助将其短期目标与可持续的长期目标保持一致。]]></description>
      <guid>https://arxiv.org/abs/2410.23683</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MoTaDual：模态-任务双重对齐，用于增强零样本合成图像检索</title>
      <link>https://arxiv.org/abs/2410.23736</link>
      <description><![CDATA[arXiv:2410.23736v1 公告类型：交叉 
摘要：组合图像检索 (CIR) 是一项具有挑战性的视觉语言任务，利用双模态（图像+文本）查询来检索目标图像。尽管监督 CIR 的性能令人印象深刻，但对昂贵的手动标记三元组的依赖限制了其可扩展性和零样本能力。为了解决这个问题，提出了零样本组合图像检索 (ZS-CIR) 以及基于投影的方法。然而，这类方法面临两个主要问题，即预训练（图像 $\leftrightarrow$ 文本）和推理（图像+文本 $\rightarrow$ 图像）之间的任务差异，以及模态差异。后者涉及基于纯文本投影训练的方法，因为在推理过程中需要从参考图像中提取特征。在本文中，我们提出了一个两阶段框架来解决这两个差异。首先，为了确保效率和可扩展性，我们在大规模字幕数据集上预先训练了文本反转网络。随后，我们提出了模态-任务对偶对齐 (MoTaDual) 作为第二阶段，其中大型语言模型 (LLM) 生成三元组数据进行微调，此外，在多模态环境中引入提示学习，以有效缓解模态和任务差异。实验结果表明，我们的 MoTaDual 在四个广泛使用的 ZS-CIR 基准上实现了最佳性能，同时保持了较低的训练时间和计算成本。代码将很快发布。]]></description>
      <guid>https://arxiv.org/abs/2410.23736</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>审核谷歌的搜索算法：衡量巴西、英国和美国的新闻多样性</title>
      <link>https://arxiv.org/abs/2410.23842</link>
      <description><![CDATA[arXiv:2410.23842v1 公告类型：交叉 
摘要：本研究通过分析巴西、英国和美国的搜索结果，研究了谷歌搜索算法对新闻多样性的影响。它探讨了谷歌的系统如何优先考虑有限数量的新闻媒体。该研究利用算法审计技术，用赫芬达尔-赫希曼指数 (HHI) 和基尼系数测量来源集中度，揭示了显著的集中趋势。该研究强调了对多个搜索查询进行横向分析的重要性，因为仅关注单个结果页面可能会掩盖这些模式。评估了诸如受欢迎程度、政治偏见和新近度等因素对新闻排名的影响。研究结果表明，搜索结果略微向左偏斜，并且偏爱受欢迎的、通常是全国性的媒体。这种偏见，加上优先考虑最近内容的倾向，表明谷歌的算法可能会加剧现有的媒体不平等。通过分析迄今为止最大的数据集——221,863 个搜索结果——这项研究提供了全面、纵向的见解，表明算法如何影响公众获取各种新闻来源的渠道。]]></description>
      <guid>https://arxiv.org/abs/2410.23842</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的模型中长度引起的嵌入崩溃</title>
      <link>https://arxiv.org/abs/2410.24200</link>
      <description><![CDATA[arXiv:2410.24200v1 公告类型：交叉 
摘要：文本嵌入可用于各种应用，但它们在较长的文本上的性能会下降。在本文中，我们发现性能下降是由于一种称为长度崩溃的现象，其中较长的文本嵌入会崩溃到一个狭窄的空间。这种崩溃导致不同文本长度的嵌入之间的分布不一致，最终损害下游任务的性能。理论上，通过考虑自注意力机制固有地充当低通滤波器，我们证明长序列会增加自注意力机制的低通滤波效果的衰减率。随着层的加深，过多的低通滤波会导致 token 信号仅保留其直流 (DC) 分量，这意味着输入的 token 特征图将崩溃到一个狭窄的空间，尤其是在长文本中。基于上述分析，我们建议通过在 softmax() 中引入温度来缓解不良的长度崩溃限制，从而实现更高的低滤波器衰减率。无需调整的方法称为 TempScale，可以插入多个基于变压器的嵌入模型中。从经验上讲，我们证明 TempScale 可以改进现有的嵌入模型，尤其是在长文本输入上，在 Massive Text Embedding Benchmark (MTEB) 的 40 个数据集上性能提升高达 0.53%，在 LongEmbed 的 4 个数据集上性能提升高达 0.82%，LongEmbed 专门针对长上下文检索。]]></description>
      <guid>https://arxiv.org/abs/2410.24200</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过影响函数进行推荐反学习</title>
      <link>https://arxiv.org/abs/2307.02147</link>
      <description><![CDATA[arXiv:2307.02147v4 公告类型：替换 
摘要：推荐反学习是一项新兴任务，旨在帮助用户从训练有素的推荐模型中删除不可用的数据（例如，一些历史行为）。现有方法通过在删除不可用数据后完全或部分重新训练模型来处理反学习请求。然而，由于完全重新训练的计算成本高，部分训练很可能损害性能，这些方法是不切实际的。从这个角度来看，理想的推荐反学习方法应该以更有效的方式获得与完全重新训练类似的模型，即实现完全、高效和无害的反学习。
在这项工作中，我们提出了一种新的基于影响函数的推荐反学习 (IFRU) 框架，该框架通过影响函数估计不可用数据对模型的影响，从而有效地更新模型而无需重新训练。鉴于最近的推荐模型使用历史数据来构建优化损失和计算图（例如，邻域聚合），IFRU 联合估计不可用数据对优化损失的直接影响和对计算图的溢出影响，以追求完全的反学习。此外，我们提出了一种基于重要性的剪枝算法来降低影响函数的成本。IFRU 是无害的，适用于主流可微分模型。大量实验表明，与基于再训练的方法相比，IFRU 实现了 250 倍以上的加速，推荐性能与完全再训练相当。代码可在 https://github.com/baiyimeng/IFRU 获得。]]></description>
      <guid>https://arxiv.org/abs/2307.02147</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐中意图学习的端到端可学习聚类</title>
      <link>https://arxiv.org/abs/2401.05975</link>
      <description><![CDATA[arXiv:2401.05975v4 公告类型：替换 
摘要：意图学习旨在学习用户的意图，以便理解用户并进行项目推荐，近年来已成为研究的热点。然而，现有的方法存在复杂而繁琐的交替优化问题，限制了性能和可扩展性。为此，我们提出了一种新的意图学习方法\underline{ELCRec}，通过将行为表示学习统一到一个\underline{E}nd-to-end \underline{L}可学习的\underline{C}聚类框架中，以实现有效和高效的\underline{Rec}推荐。具体来说，我们对用户行为序列进行编码，并将聚类中心（潜在意图）初始化为可学习的神经元。然后，我们设计了一个新颖的可学习聚类模块来分离不同的聚类中心，从而解耦用户的复杂意图。同时，它通过强制行为嵌入靠近聚类中心来引导网络从行为中学习意图。这允许通过小批量数据同时优化推荐和聚类。此外，我们提出了使用聚类中心作为自监督信号的意图辅助对比学习，进一步增强了相互促进。实验结果和理论分析都从六个角度证明了ELCRec的优越性。与亚军相比，ELCRec在Beauty数据集上将NDCG@5提高了8.9％，计算成本降低了22.5％。此外，由于其可扩展性和普遍适用性，我们将该方法部署在拥有1.3亿页面访问量的工业推荐系统上并取得了可喜的效果。代码可以在GitHub上找到（https://github.com/yueliu1999/ELCRec）。深度组推荐/意图学习方法的集合（论文、代码、数据集）可以在GitHub上找到（https://github.com/yueliu1999/Awesome-Deep-Group-Recommendation）。]]></description>
      <guid>https://arxiv.org/abs/2401.05975</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Pistis-RAG：通过人类反馈增强检索增强生成</title>
      <link>https://arxiv.org/abs/2407.00072</link>
      <description><![CDATA[arXiv:2407.00072v5 公告类型：替换 
摘要：当语义相关性本身不能保证提高生成质量时，RAG 系统会面临限制。由于大型语言模型 (LLM) 对小样本提示的排序很敏感，这个问题变得尤为明显，这会影响模型性能。为了应对这一挑战，使用结构化反馈（例如复制、重新生成或不喜欢的选项）将 LLM 输出与人类偏好保持一致，提供了一种有希望的改进方法。此反馈应用于整个输入列表，而不是为单个文档提供特定评级，使其成为 Listwide Labels Learning-to-Rank 任务。
为了解决这个任务，我们提出了 Pistis-RAG，这是一个新的 RAG 框架，采用以内容为中心的方法设计，以更好地将 LLM 与人类偏好保持一致。Pistis-RAG 有效地利用了人类反馈，提高了内容排名和生成质量。为了验证我们的框架，我们使用公共数据集来模拟人类反馈，使我们能够有效地评估和改进我们的方法。实验结果表明，与基线 RAG 系统相比，Pistis-RAG 提高了与人类偏好的匹配度，MMLU（英语）准确率提高了 6.06%，C-EVAL（中文）准确率提高了 7.08%。这些结果凸显了 Pistis-RAG 在克服传统 RAG 方法的局限性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.00072</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>