<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 24 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DEGAP：用于具有槽查询的基于模板的事件参数提取模型的双事件引导自适应前缀</title>
      <link>https://arxiv.org/abs/2405.13325</link>
      <description><![CDATA[arXiv:2405.13325v1 公告类型：交叉 
摘要：事件参数提取（EAE）的最新进展涉及在训练和推理过程中将有益的辅助信息合并到模型中，例如检索的实例和事件模板。此外，一些研究将可学习的前缀向量引入到模型中。这些方法面临三个挑战：（1）由于检索的缺陷，相关事件实例的利用不足； （二）忽视相关活动模板提供的重要信息； (3)前缀的优势由于无法满足EAE的特定信息需求而受到限制。在这项工作中，我们提出了DEGAP，它通过两个简单但有效的组件解决了上述挑战：（1）双前缀，其中面向实例的前缀和面向模板的前缀分别被训练以从不同的事件实例和模板中学习信息，然后向EAE模型提供相关信息作为线索，无需检索； (2)事件引导的自适应门控机制，根据目标事件引导前缀充分发挥其优势。大量实验表明，我们的方法在四个数据集（ACE05、RAMS、WIKIEVENTS 和 MLEE）上实现了最先进的性能。进一步的分析验证了所提出设计的重要性和主要组件的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.13325</guid>
      <pubDate>Fri, 24 May 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>解决财务问答的基于案例的推理方法</title>
      <link>https://arxiv.org/abs/2405.13044</link>
      <description><![CDATA[arXiv:2405.13044v1 公告类型：交叉 
摘要：衡量机器对人类语言的理解通常涉及评估其推理能力，即得出问题答案的逻辑过程。虽然最近的语言模型在基于文本的任务中表现出了显着的熟练程度，但它们在涉及文本、表格和数字等异构信息的复杂推理问题上的功效仍然不确定。为了解决这一差距，FinQA 引入了金融文档的数值推理数据集，同时提出了程序生成方法。我们的调查显示，一半的错误 (48%) 源于生成的错误操作。为了解决这个问题，我们提出了一种使用基于案例的推理（CBR）来解决数字推理问题的新方法，这是一种人工智能范式，通过提供类似的案例（即类似的问题和相应的逻辑程序）来提供问题解决指导。我们的模型检索相关案例来解决给定的问题，然后根据检索到的案例和上下文信息生成答案。通过在 FinQA 数据集上的实验，我们展示了我们的方法的竞争性能，并且还表明，通过扩展案例库，我们可以帮助解决 FinQA 所表现出的弱点的复杂的多步骤程序。]]></description>
      <guid>https://arxiv.org/abs/2405.13044</guid>
      <pubDate>Fri, 24 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>对话式数据生成最新进展调查</title>
      <link>https://arxiv.org/abs/2405.13003</link>
      <description><![CDATA[arXiv:2405.13003v1 公告类型：交叉 
摘要：会话系统的最新进展显着增强了各个领域的人机交互。然而，由于缺乏专门的对话数据，训练这些系统具有挑战性。传统上，会话数据集是通过众包创建的，但事实证明这种方法成本高昂、规模有限且劳动密集型。作为一种解决方案，合成对话数据的开发已经出现，利用技术来扩充现有数据集或将文本资源转换为对话格式，从而为数据集创建提供更高效和可扩展的方法。在本次调查中，我们对多轮对话数据生成进行了系统而全面的回顾，重点关注三种类型的对话系统：开放域、面向任务和信息搜索。我们根据种子数据创建、话语生成和质量过滤方法等关键组件对现有研究进行分类，并介绍一个概述对话数据生成系统主要原理的通用框架。此外，我们还研究了用于评估合成对话数据的评估指标和方法，解决了该领域当前的挑战，并探索了未来研究的潜在方向。我们的目标是通过概述最先进的方法并强调该领域进一步研究的机会，加速研究人员和从业者的进步。]]></description>
      <guid>https://arxiv.org/abs/2405.13003</guid>
      <pubDate>Fri, 24 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>IM-RAG：通过学习内心独白进行多轮检索增强生成</title>
      <link>https://arxiv.org/abs/2405.13021</link>
      <description><![CDATA[arXiv:2405.13021v1 公告类型：交叉 
摘要：尽管检索增强生成（RAG）范式可以使用外部知识来增强和基础大型语言模型（LLM）的输出，以减轻生成幻觉和静态知识库问题，但它们在采用信息检索时仍然受到灵活性有限的影响。 IR）系统具有不同的功能，多轮检索过程中的可解释性受到限制，并且缺乏端到端优化。为了应对这些挑战，我们提出了一种以法学硕士为中心的新颖方法 IM-RAG，它将 IR 系统与法学硕士相结合，通过学习内心独白（IM，即人类内心的声音来叙述自己的想法）来支持多轮 RAG。在 IM 过程中，LLM 充当核心推理模型（即 Reasoner），通过检索器提出查询以收集更多信息，或者根据对话上下文提供最终答案。我们还引入了 Refiner，它可以提高 Retriever 的输出，有效地弥合 Reasoner 和具有不同功能的 IR 模块之间的差距，并促进多轮通信。整个 IM 过程通过强化学习 (RL) 进行优化，其中包含进度跟踪器以提供中间步骤奖励，并且答案预测通过监督微调 (SFT) 进一步单独优化。我们使用 HotPotQA 数据集进行了广泛的实验，这是基于检索的多步骤问答的流行基准。结果表明，我们的方法实现了最先进的 (SOTA) 性能，同时在集成 IR 模块方面提供了高度灵活性，并且在学习的内心独白中表现出了很强的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2405.13021</guid>
      <pubDate>Fri, 24 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>自上而下的分区以实现高效的列表排序</title>
      <link>https://arxiv.org/abs/2405.14589</link>
      <description><![CDATA[arXiv:2405.14589v1 公告类型：新 
摘要：大型语言模型（LLM）对自然语言处理和信息检索的许多方面产生了重大影响。与以前基于编码器的方法不同，这些生成模型的扩大的上下文窗口允许一次对多个文档进行排名，通常称为列表方式排名。然而，在模型的单个推理中可以排序的文档数量仍然存在限制，导致广泛采用滑动窗口方法来识别排序列表中 k 个最相关的项目。我们认为，滑动窗口方法不太适合按列表重新排序，因为它（1）无法以其当前形式并行化，（2）导致重复对最佳文档集重新评分的冗余计算步骤： (3) 采用自下而上的方法，优先考虑排名最低的文档而不是排名最高的文档进行评分。受这些缺点的启发，以及一项初步研究表明列表排序器在上下文窗口开始时偏向于相关文档，我们提出了一种新颖的算法，将排名划分为深度 k 并自上而下地处理文档。与滑动窗口方法不同，我们的算法由于使用了枢轴元素而本质上是可并行的，它可以同时与任意深度的文档进行比较。这样做，当深度为 100 时，我们将预期的推理调用数量减少了约 33%，同时在多个强大的重新排序器中匹配了先前方法的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.14589</guid>
      <pubDate>Fri, 24 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>对机器的愤怒：检索增强法学硕士解释</title>
      <link>https://arxiv.org/abs/2405.13000</link>
      <description><![CDATA[arXiv:2405.13000v1 公告类型：交叉 
摘要：本文演示了 RAGE，一种交互式工具，用于解释具有检索功能的大型语言模型 (LLM)；即，能够查询外部源并将相关信息提取到其输入上下文中。我们的解释是反事实的，因为它们识别了输入上下文的某些部分，当删除这些部分时，会改变向法学硕士提出的问题的答案。 RAGE 包括修剪方法来导航可能的解释的广阔空间，允许用户查看生成答案的出处。]]></description>
      <guid>https://arxiv.org/abs/2405.13000</guid>
      <pubDate>Fri, 24 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>ASI++：走向分布平衡的端到端生成检索</title>
      <link>https://arxiv.org/abs/2405.14280</link>
      <description><![CDATA[arXiv:2405.14280v1 公告类型：新
摘要：生成检索是信息检索中一种很有前途的新范式，它采用 seq2seq 模型将文档特征编码为参数，并根据搜索查询解码相关文档标识符 (ID)。现有的生成检索解决方案通常依赖于预处理阶段来预定义文档 ID，这可能会受到这些 ID 与检索任务之间语义差距的影响。然而，由于现实世界数据的长尾分布特性，ID 分配和检索任务的端到端训练具有挑战性，导致 ID 空间利用率低下且不平衡。为了解决这些问题，我们提出了 ASI++，一种新颖的完全端到端生成检索方法，旨在同时学习平衡的 ID 分配并提高检索性能。ASI++ 建立在 vanilla ASI 的完全端到端训练框架之上，并引入了几项关键创新。首先，分布平衡标准解决了 ID 分配中的不平衡问题，从而促进了 ID 空间的更高效利用。接下来，表示瓶颈标准增强了密集表示，以缓解学习 ID 分配中的瓶颈。最后，信息一致性标准将这些过程集成到基于信息论的联合优化框架中。我们进一步探索了用于学习 ID 分配的各种模块结构，包括神经量化、可微分乘积量化和残差量化。在公共数据集和工业数据集上进行的大量实验证明了 ASI++ 在提高检索性能和实现平衡 ID 分配方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.14280</guid>
      <pubDate>Fri, 24 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>展望未来：深度情境化顺序推荐</title>
      <link>https://arxiv.org/abs/2405.14359</link>
      <description><![CDATA[arXiv:2405.14359v1 公告类型：新
摘要：顺序推荐专注于从用户行为历史中挖掘有用的模式，以更好地估计他对候选项目的偏好。以前的解决方案采用循环网络或检索方法来获取用户的个人资料表示，从而执行偏好估计。在本文中，我们提出了一种新的顺序推荐框架，称为展望未来（LIFT），它构建并利用顺序推荐的上下文。LIFT 中的上下文是指用户当前的个人资料，可以基于过去和未来的行为来表示。因此，学习到的上下文将更有效地预测顺序推荐中用户的行为。显然，不可能使用真实的未来信息来预测当前行为，因此我们提出了一种新的基于检索的框架，使用最相似交互的未来信息作为目标交互的未来上下文，而不会泄露数据。此外，为了利用嵌入在上下文本身中的内在信息，我们引入了一种结合行为掩蔽的创新预训练方法。该方法旨在促进上下文表示的有效获取。我们证明，通过检索方法从全局用户池中找到相关上下文将大大提高偏好估计性能。在我们对真实世界数据集进行的大量实验中，LIFT 在顺序推荐中的点击率预测任务上表现出比强基线显著的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2405.14359</guid>
      <pubDate>Fri, 24 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>使用用户模拟识别会话推荐系统中的故障</title>
      <link>https://arxiv.org/abs/2405.14249</link>
      <description><![CDATA[arXiv:2405.14249v1 公告类型：新 
摘要：我们提出了一种系统测试会话推荐系统的会话故障的方法。它涉及检查系统和模拟用户之间生成的一组预定义故障类型的对话，提取负责任的对话路径，并根据潜在的对话意图来表征它们。用户模拟具有简单、成本效益和时间效率的优点，可以获取可识别潜在故障的对话。所提出的方法可以用作诊断工具以及改进会话推荐系统的开发工具。我们将我们的方法应用于现有对话推荐系统和用户模拟器的案例研究中，证明只需几次迭代，我们就可以使系统对对话故障更加鲁棒。]]></description>
      <guid>https://arxiv.org/abs/2405.14249</guid>
      <pubDate>Fri, 24 May 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的云-边缘-设备协作学习，用于下一个 POI 推荐</title>
      <link>https://arxiv.org/abs/2405.13811</link>
      <description><![CDATA[arXiv:2405.13811v1 公告类型：新 
摘要：基于位置的社交网络（LBSN）的快速扩张凸显了有效的下一个兴趣点（POI）推荐的重要性，它利用历史签到数据来预测用户下一个要访问的 POI。传统的集中式深度神经网络 (DNN) 提供令人印象深刻的 POI 推荐性能，但由于隐私问题和有限的时效性而面临挑战。为此，引入了设备上 POI 推荐，利用联邦学习 (FL) 和去中心化方法来确保隐私和推荐的及时性。然而，这些方法通常会受到设备计算压力的影响，并且很难适应新的用户和地区。本文介绍了一种新颖的协作学习框架，即基于扩散的云边缘设备协作学习下一个 POI 推荐 (DCPR)，该框架利用了以其在各个领域的成功而闻名的扩散模型。 DCPR 采用云边缘设备架构运行，提供特定区域和高度个性化的 POI 建议，同时减少设备上的计算负担。 DCPR 通过全球和本地学习过程的独特融合，最大限度地减少设备上的计算需求。我们对两个真实世界数据集的评估表明，DCPR 在推荐准确性、效率以及对新用户和区域的适应性方面表现出色，标志着设备上 POI 推荐技术向前迈出了重要一步。]]></description>
      <guid>https://arxiv.org/abs/2405.13811</guid>
      <pubDate>Fri, 24 May 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能搜索引擎作为公共知识的仲裁者：对偏见和权威的审计</title>
      <link>https://arxiv.org/abs/2405.14034</link>
      <description><![CDATA[arXiv:2405.14034v1 公告类型：新
摘要：本文报告了一项关于生成式 AI 系统（ChatGPT、Bing Chat 和 Perplexity）的审计研究，该研究调查了这些新搜索引擎如何构建响应并为具有公共重要性的话题建立权威。我们在 7 天内使用一组 48 个真实查询收集了 4 个主题的系统响应，并使用情绪分析、归纳编码和源分类分析了数据。结果概述了这些系统中系统响应的性质，并提供了基于查询和主题的情绪偏见以及来源中的商业和地理偏见的证据。用于支持主张的来源质量参差不齐，严重依赖新闻和媒体、商业和数字媒体网站。对系统用户的启示强调了在做出与公共利益和个人福祉相关的决策时需要批判性地审查生成式 AI 系统的输出。]]></description>
      <guid>https://arxiv.org/abs/2405.14034</guid>
      <pubDate>Fri, 24 May 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>Lusifer：用于在线推荐系统的基于 LLM 的用户模拟反馈环境</title>
      <link>https://arxiv.org/abs/2405.13362</link>
      <description><![CDATA[arXiv:2405.13362v1 公告类型：新
摘要：训练基于强化学习的推荐系统通常会因缺乏动态和真实的用户交互而受到阻碍。Lusifer 是一种利用大型语言模型 (LLM) 的新环境，它通过生成模拟用户反馈来解决这一限制。它综合用户配置文件和交互历史来模拟对推荐项目的响应和行为。此外，每次评级后都会更新用户配置文件以反映不断变化的用户特征。使用 MovieLens100K 数据集作为概念证明，Lusifer 展示了对用户行为和偏好的准确模拟。本文介绍了 Lusifer 的操作流程，包括提示生成和迭代用户配置文件更新。在验证 Lusifer 产生真实动态反馈的能力的同时，未来的研究可以利用这种环境来训练强化学习系统，为在线推荐系统中的用户模拟提供可扩展和可调整的框架。]]></description>
      <guid>https://arxiv.org/abs/2405.13362</guid>
      <pubDate>Fri, 24 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 k-medoids 进行任意距离的分布式近似相似性搜索</title>
      <link>https://arxiv.org/abs/2405.13795</link>
      <description><![CDATA[arXiv:2405.13795v1 公告类型：新 
摘要：本文提出了 GMASK，一种接受任意距离函数的分布式近似相似性搜索的通用算法。 GMASK 需要一种聚类算法，该算法可在数据集中引入 Voronoi 区域并返回每个区域的代表元素。然后，它创建适合高维度和稀疏性的大型数据集的多级索引结构，通常存储在分布式系统中。许多相似性搜索算法依赖于 $k$-means，通常与欧几里得距离相关，这不适用于特定问题。相反，在这项工作中，我们使用 $k$-medoids 实现 GMASK，以使其兼容任何距离和更广泛的问题。实验结果验证了该方法在真实数据集上的适用性，提高了近似相似搜索替代算法的性能。此外，结果证实了关于在高维数据集中使用 Minkowski 距离的某些实例的优势的现有直觉。]]></description>
      <guid>https://arxiv.org/abs/2405.13795</guid>
      <pubDate>Fri, 24 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>自动评分检索/生成系统的工作台</title>
      <link>https://arxiv.org/abs/2405.13177</link>
      <description><![CDATA[arXiv:2405.13177v1 公告类型：新 
摘要：这篇资源论文解决了自回归大型语言模型 (LLM) 时代评估信息检索 (IR) 系统的挑战。由于基于法学硕士的系统产生的反应的多样性，依赖于段落级别判断的传统方法不再有效。我们提供了一个工作台来探索几种替代评估方法来判断包含法学硕士的系统响应的相关性： 1. 询问法学硕士响应是否相关； 2. 询问法学硕士的答复涵盖了哪组要点（即相关的关键事实）； 3. 要求法学硕士回答一组考试问题并给出答案。
  该工作台旨在促进新的、可重用的测试集合的开发。研究人员可以手动完善金块和考试问题集，观察它们对系统评估和排行榜排名的影响。
  资源位于 https://github.com/TREMA-UNH/autograding-workbench]]></description>
      <guid>https://arxiv.org/abs/2405.13177</guid>
      <pubDate>Fri, 24 May 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>大规模推荐系统中基于流聚类和内存网络增强用户兴趣</title>
      <link>https://arxiv.org/abs/2405.13238</link>
      <description><![CDATA[arXiv:2405.13238v1 公告类型：新 
摘要：推荐系统（RS）根据用户兴趣提供个性化推荐服务，广泛应用于各种平台。然而，有大量用户由于缺乏消费行为而兴趣稀疏，导致推荐结果不佳。这个问题在大规模RS中普遍存在，并且特别难以解决。为了解决这个问题，我们提出了一种名为用户兴趣增强（UIE）的新颖解决方案，该解决方案使用基于流聚类和记忆网络生成的增强向量和个性化增强向量从不同角度增强用户兴趣，包括用户个人资料和用户历史行为序列。 UIE不仅显着提高了兴趣稀疏的用户的模型性能，而且还显着提高了其他用户的模型性能。 UIE是一个基于排名模型的、易于实现的端到端解决方案。此外，我们扩展了我们的解决方案，并将类似的方法应用于长尾项目，也取得了出色的改进。此外，我们还在大型工业RS中进行了广泛的离线和在线实验。结果表明，我们的模型显着优于其他模型，特别是对于兴趣稀疏的用户。截至目前，UIE已在多个大型RS中全面部署，并取得了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2405.13238</guid>
      <pubDate>Fri, 24 May 2024 06:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>