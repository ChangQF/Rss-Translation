<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 09 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>迈向全召回：通过AI驱动的元数据标准化增强公平性</title>
      <link>https://arxiv.org/abs/2504.05307</link>
      <description><![CDATA[ARXIV：2504.05307V1公告类型：新 
摘要：当前的元数据通常会遭受不完整，不一致和格式不正确，阻碍了有效的数据重用和发现。使用GPT-4和元数据知识库（Cedar），我们设计了一种标准化科学数据集元数据的方法，以确保遵守社区标准。标准化过程涉及纠正和完善元数据条目，以符合已建立的准则，从而显着提高搜索性能和召回指标。该研究使用生物样品和地理存储库来证明这些增强功能的影响，并展示了标准化的元数据如何导致更好的检索结果。平均召回率显着提高，随着生物样品的基线原始数据集和GEO的基线原始数据集，我们提出的元数据标准化管道从17.65 \％上升到62.87 \％。这一发现突出了将先进的AI模型与结构化元数据策展工具集成到更有效和可靠的数据检索中的变革性影响。]]></description>
      <guid>https://arxiv.org/abs/2504.05307</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>罕见：通过上下文感知重新筹集广告收入框架</title>
      <link>https://arxiv.org/abs/2504.05308</link>
      <description><![CDATA[ARXIV：2504.05308V1公告类型：新 
摘要：现代推荐系统在优化电子商务平台优化搜索结果相关性方面出色。在保持这种相关性的同时，平台寻求机会通过搜索结果调整来最大化收入。为了解决相关性和收入之间的权衡，我们提出了$ \ mathsf {稀有} $（$ \ textbf {r} $ aising $ \ textbf {a} $ dvertisement $ \ textbf {re} re} $ calue）框架。 $ \ mathsf {稀有} $堆叠单击模型和重新骑行模型。我们培训具有损失功能的$ \ Mathsf {Rare} $框架，以找到收入和相关性权衡。根据我们的经验，点击模型在$ \ mathsf {稀有} $框架中至关重要。我们建议并比较两个不同的点击模型，以考虑搜索结果中项目的上下文。首次点击模型是带有串联（GBDT-C）的梯度提高决策树，其中包括传统的GBDT模型中的上下文，用于单击预测。第二个模型Saint-Q适应了顺序注意模型，以捕获搜索结果之间的影响。我们的实验表明，提出的点击模型的表现要比基线的表现并提高了我们框架的整体质量。将公开发布的工业数据集的实验显示$ \ Mathsf {Rare} $的重大收入改进，同时保持高相关性。]]></description>
      <guid>https://arxiv.org/abs/2504.05308</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ITERQR：基于LLM的查询重写在电子商务搜索系统中的迭代框架</title>
      <link>https://arxiv.org/abs/2504.05309</link>
      <description><![CDATA[ARXIV：2504.05309V1公告类型：新 
摘要：现代电子商务搜索系统的本质在于根据用户的查询，将用户的意图和可用的候选人匹配，提供个性化和精确的服务。但是，由于输入模棱两可和错字，用户的查询可能不正确，导致搜索不准确。这些情况可以通过查询重写：将查询修改为其他表示或扩展。但是，传统查询重写在静态重写词汇上的回复，同时，该词汇与电子商务系统中的领域知识和现实世界中的常识都缺乏互动。在本文中，具有生成大型语言模型（LLMS）文本内容的能力，我们提供了一个迭代框架来生成查询重写。该框架在每次迭代中结合了一个三阶段的过程：通过检索型发电（抹布）（抹布）和通过思考链（COT）进行查询理解的域知识的重写；在线信号收集，具有自动重写更新的在线信号； LLM具有多任务目标的LLM培训，以生成新的重写。我们的作品（命名为iterQr）提供了一个综合框架，以生成\ textbf {q} uery \ textbf {r} ewrite，并具有两个域 /现实世界知识。它会在\ textbf {iter} ations期间自动更新和自我更正重写。 \方法{}已部署在Meituan交付的搜索系统（中国领先的食品交付平台）中，为用户提供了显着改善的服务。]]></description>
      <guid>https://arxiv.org/abs/2504.05309</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>砂砾：基于图形的召回改进，用于以任务为导向的电子商务查询</title>
      <link>https://arxiv.org/abs/2504.05310</link>
      <description><![CDATA[ARXIV：2504.05310V1公告类型：新 
摘要：许多电子商务搜索管道具有四个阶段，即：检索，过滤，排名和个性化级别。检索阶段必须是有效的，并且会产生高回忆，因为在以后的阶段不能考虑第一阶段错过的相关产品。对于用户要求在上下文强度且难以理解的情况下，这对于以任务为导向的查询（具有可行意图的查询）是具有挑战性的。为了培养电子商务领域的研究，我们使用LLM使用LLM创建了一个新颖的基准，该基准是在现有的ESCI产品搜索数据集上运行的LLM。此外，我们提出了一种新型方法“基于图形的召回召回改进，针对任务的查询改进”（砂砾），以满足最关键的第一阶段召回改善需求。砂砾会导致对最先进的词汇，密集和学识渊博的基线的稳健和统计学上的显着改善。我们的系统支持传统和以任务为导向的电子商务查询，最高可召回6.3％的召回率。在索引阶段，Grit首先使用用户点击或手动注释数据构建产品产品相似性图。在检索过程中，它将邻居定位具有更高的上下文和行动相关性的邻居，并将其优先于最初检索的较少相关候选人。这导致了更全面和相关的第一阶段结果集，可改善整体系统召回率。总体而言，砂砾利用图形使用相邻节点提供的局部关系和上下文见解来丰富第一阶段的检索结果。我们表明，该方法不仅在所有引入的参数中都具有鲁棒性，而且还可以有效地在各种第一阶段检索方法的顶部工作。]]></description>
      <guid>https://arxiv.org/abs/2504.05310</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>朝着基于自适应内存的优化来增强检索生成</title>
      <link>https://arxiv.org/abs/2504.05312</link>
      <description><![CDATA[ARXIV：2504.05312V1公告类型：新 
摘要：通过将非参数知识从外部知识基础整合到模型中，检索出的生成（RAG）已成为提高响应准确性的一种有希望的方法，同时减轻事实错误和幻觉。该方法已广泛应用于诸如问答（QA）之类的任务。但是，现有的抹布方法与开放域质量检查质量检查任务相加，因为它们执行独立的检索操作，并直接将检索到的信息纳入生成，而无需维持汇总内存或使用自适应检索策略，从而导致冗余信息和不足信息集成的噪音。为了应对这些挑战，我们提出了基于自适应内存的优化，用于增强抹布（amber），用于开放域质量标学QA任务，该任务包括基于代理的内存更新者，自适应信息收集器和多个粒度内容过滤器，并在迭代的内存更新中共同工作。具体而言，Amber通过多代理协作方法整合并优化了语言模型的内存，从而确保了从以前的检索步骤中进行全面的知识集成。它动态调整了检索查询，并决定何时根据累积知识停止检索，从而提高了检索效率和有效性。此外，它通过在多个级别上过滤不相关的内容来降低噪声，从而保留基本信息以提高整体模型性能。我们对几个开放域QA数据集进行了广泛的实验，结果证明了我们方法及其组件的优势和有效性。源代码可用\ footNote {https://anonymon.4open.science/r/amber-b203/}。]]></description>
      <guid>https://arxiv.org/abs/2504.05312</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对联邦顺序建议的系统调查</title>
      <link>https://arxiv.org/abs/2504.05313</link>
      <description><![CDATA[ARXIV：2504.05313V1公告类型：新 
摘要：顺序建议是一种高级建议技术，它利用用户行为的顺序来通过对用户偏好中的时间依赖性和模式进行建模来生成个性化建议。但是，它要求服务器集中收集用户的数据，这对不同用户的数据隐私构成了威胁。近年来，联邦学习已成为一种分布式体系结构，使参与者能够在当地保留其私人数据的同时训练全球模型。这项调查先驱者联合顺序推荐（FEDSR），每个用户作为联合培训的参与者加入，以实现平衡数据隐私和模型性能的建议服务。我们首先介绍了FedSr的背景和独特的挑战。然后，我们从两个级别审查现有的解决方案，每个解决方案包括两种特定技术。此外，我们讨论了FEDSR的关键挑战和未来的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2504.05313</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式定量语言用于生成建议</title>
      <link>https://arxiv.org/abs/2504.05314</link>
      <description><![CDATA[ARXIV：2504.05314V1公告类型：新 
摘要：生成建议已成为一种有希望的范式，目的是直接生成目标候选者的标识符。大多数现有的方法试图利用预先训练的语言模型（PLM）中嵌入的先验知识来提高建议性能。但是，他们通常无法适应PLM的一般语言知识与推荐系统的特定需求之间的差异。此外，他们很少考虑项目的多模式信息之间的互补知识，这代表了用户的多方面偏好。为了促进有效的建议知识转移，我们提出了一种新的方法，称为生成推荐的多模式定量语言（MQL4GREC）。我们的关键思想是将项目从不同的领域和模式转换为统一语言，这可以作为传输建议知识的桥梁。具体来说，我们首先介绍定量翻译器将项目的文本和图像内容从各个域转换为一种新的简洁语言，称为定量语言，所有项目共享相同的词汇。然后，我们设计了一系列定量语言生成任务，以通过语义信息和先验知识丰富定量语言。最后，我们通过预先培训和微调将推荐知识从不同领域和模式转移到建议任务。我们通过广泛的实验和现有方法的比较来评估MQL4GREC的有效性，分别在三个不同数据集中，NDCG度量分别在NDCG指标上提高了11.18 \％，14.82 \％和7.95％的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.05314</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相干性改善了通过大语言模型的可解释建议</title>
      <link>https://arxiv.org/abs/2504.05315</link>
      <description><![CDATA[ARXIV：2504.05315V1公告类型：新 
摘要：可解释的推荐系统旨在阐明每个建议背后的解释，从而使用户能够理解基础逻辑。先前的作品以多任务方式执行评级预测和解释生成。但是，这些作品在预测的评级和解释之间遭受了不连贯的影响。为了解决这个问题，我们提出了一个新颖的框架，该框架采用大型语言模型（LLM）生成评级，将其转换为评级向量，并最终基于评级向量和用户信息信息来生成解释。此外，我们建议利用公开可用的LLM和预训练的情感分析模型自动评估没有人类注释的连贯性。在三个可解释建议数据集上进行的广泛实验结果表明，所提出的框架是有效的，表现优于最先进的基线，可解释性的提高为7.3 \％，文本质量为4.4 \％。]]></description>
      <guid>https://arxiv.org/abs/2504.05315</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过修改文本生成来扩展组成的图像检索学习</title>
      <link>https://arxiv.org/abs/2504.05316</link>
      <description><![CDATA[ARXIV：2504.05316V1公告类型：新 
摘要：组成的图像检索（CIR）旨在使用参考图像和修改文本作为查询的组合搜索感兴趣的图像。尽管有最近的进步，但由于培训数据和费力的三胞胎注释过程，该任务仍然具有挑战性。为了解决这个问题，本文提议合成培训三胞胎，以增加CIR问题的培训资源。具体而言，我们通过训练利用大型多模型的修改文本生成器来开始，并在整个训练和微调阶段扩大CIR学习。在训练过程中，我们利用受过训练的发电机直接创建以图像成对为条件的面向文本的合成三胞胎（MTST）。对于微调，我们首先合成反向修改文本，将目标图像连接回参考图像。随后，我们设计了一种两跳比对的策略，以逐步缩小多模式对和目标图像之间的语义差距。我们最初以周期方式学习了使用原始三重态及其相反版本的隐式原型，然后将隐式原型特征与修改文本相结合，以促进与目标图像的准确对齐。广泛的实验验证了生成的三胞胎的功效，并确认我们提出的方法在CIRR和FashionIQ基准上都具有竞争性回忆。]]></description>
      <guid>https://arxiv.org/abs/2504.05316</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于综合数据以获取上下文归因的回答</title>
      <link>https://arxiv.org/abs/2504.05317</link>
      <description><![CDATA[ARXIV：2504.05317V1公告类型：新 
摘要：问题回答（QA）占LLM使用“野外”的很大一部分。但是，LLM有时会产生虚假或误导性的反应，也称为“幻觉”。因此，将生成的答案扎根于上下文提供的信息（即提供生成的文本的证据）是LLMS的可信度至关重要的。提供此信息是上下文归因的任务。在本文中，我们系统地研究了针对此任务的基于LLM的方法，即我们研究（i）零射击推断，（ii）LLM结合，以及（iii）对较大LLMS产生的合成数据的小LMS进行微调。我们的关键贡献是Synqa：合成上下文归因数据的新型生成策略。给定选定的上下文句子，LLM生成了这些句子支持的QA对。这利用LLMS在文本生成中的自然优势，同时确保合成训练数据中的清晰归因路径。我们表明，通过SynQA合成的归因数据对于在不同质量检查任务和域中的上下文归因的小型LMS合成非常有效。最后，通过用户研究，我们验证了QA上下文归因的小LMS（对Synqa的合成数据进行微调）的实用性。]]></description>
      <guid>https://arxiv.org/abs/2504.05317</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过通才推荐人有效的多任务学习</title>
      <link>https://arxiv.org/abs/2504.05318</link>
      <description><![CDATA[ARXIV：2504.05318V1公告类型：新 
摘要：多任务学习（MTL）是一种通用的机器学习技术，它允许模型在不同任务上共享信息并提高所有这些建议的准确性。许多现有的MTL实现都存在可伸缩性问题，因为培训和推理性能会随着任务数量的增加而降低，这可能会限制基于MTL的建议系统的生产用例情况。受到大型语言模型的最新进展的启发，我们开发了一种端到端的高效且可扩展的通才推荐人（GREC）。 GREC通过利用NLP头部，并行变压器以及宽而深的结构来处理多模式输入，以获取全面的数据信号。然后，通过新提出的任务句子级别路由机制将这些输入组合和馈送，以扩展多个任务的模型功能，而不会损害性能。离线评估和在线实验表明，GREC的表现明显胜过我们以前的推荐解决方案。 GREC已成功部署在最大的电信网站之一，每天有效地管理大量在线流量。]]></description>
      <guid>https://arxiv.org/abs/2504.05318</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测建模：基于大规模使用日志的BIM命令建议</title>
      <link>https://arxiv.org/abs/2504.05319</link>
      <description><![CDATA[ARXIV：2504.05319V1公告类型：新 
摘要：在建筑，工程和建筑（AEC）行业中，建筑信息建模（BIM）和基于模型的设计的采用受到了这种看法的阻碍，即使用BIM创作工具比传统的2D起草需要更多的努力。为了提高设计效率，本文提出了一个BIM命令建议框架，该框架可以根据用户的历史交互预测实时的最佳下一个操作。我们为大型原始BIM日志数据提供了一种综合的过滤和增强方法，并引入了新颖的命令建议模型。我们的模型建立在最初为大型语言模型（LLMS）开发的最新变压器主骨基础上，结合了自定义功能融合模块，专用损失功能和目标学习策略。在案例研究中，提出的方法适用于从BIM创作软件矢量工作中全球收集的320亿行实际日志数据。实验结果表明，我们的方法可以从不同国家，学科和项目的匿名用户互动序列中学习通用且可推广的建模模式。在为下一个命令生成建议时，我们的方法将获得大约84％的召回@10。]]></description>
      <guid>https://arxiv.org/abs/2504.05319</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用进化的多字搜索查询文档聚类</title>
      <link>https://arxiv.org/abs/2504.05320</link>
      <description><![CDATA[ARXIV：2504.05320V1公告类型：新 
摘要：文本聚类由于能够识别模式和小组相关信息的能力，因此在各个领域都具有显着价值。在很大程度上依赖于文档之间计算的相似性度量的当前方法通常在准确性和可解释性上受到限制。我们根据一组进化的搜索查询提出了一种新的问题的方法。群集形成为一组文档，该文档与一组查询中的单个搜索查询匹配。优化查询以最大化返回的文档数量并最大程度地减少群集之间的重叠（由一个以上查询返回的文档）。查询包含多个单词的地方，它们被脱节地解释。我们发现将一个单词分配为root并约束查询构造很有用，以使任何其他查询单词返回的文档集与root Word返回的集合相交。并非集合中的所有文档都由集合中的任何搜索查询返回，因此，一旦完成搜索查询进化，将执行第二阶段，从而将KNN算法应用于将所有未分配的文档分配给其最近的群集。我们使用8个文本数据集描述了该方法和结果，将有效性与众所周知的现有算法进行了比较。我们注意到，除了实现这些数据集上的最高精度外，搜索查询格式还提供了可解释和可修改的定性好处，同时提供了群集结构的因果解释。]]></description>
      <guid>https://arxiv.org/abs/2504.05320</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>价值：通过加权Trie在赞助的搜索中通过加权Trie重写查询的价值了解的大语言模型</title>
      <link>https://arxiv.org/abs/2504.05321</link>
      <description><![CDATA[ARXIV：2504.05321V1公告类型：新 
摘要：在赞助的搜索广告领域中，将广告与用户查询的搜索意图匹配至关重要。查询对象词（即出价关键字）的重写是一种至关重要的技术，它引起了极大的关注。最近，随着LLMS的流行，生成检索方法已被证明有效地产生了高相关性重写。但是，我们已经确定了现有方法的重要限制：虽然针对特定域的微调LLM增强了语义相关性，但这些模型对其生成的产出（例如商业价值）的内在价值没有感知。因此，在SFT之后，经常采用RLHF阶段来解决此问题。然而，传统的偏好一致性方法通常会在对齐细粒度的值时面临挑战，并且容易过度拟合，从而降低了生成的结果的有效性和质量。为了应对这些挑战，我们提出了价值（通过加权Trie进行查询重写的价值感知的大语言模型），这是确保产生高价值和高度相关的BIDWORDS的第一个框架。我们的方法利用了加权Trie，这是对传统TRIE数据结构的创新修改。通过在解码过程中使用TRIE的价值信息调节LLM的输出概率分布，我们可以限制生成空间并指导文本生产的轨迹。离线实验证明了我们方法在语义匹配和偏好对齐中的有效性，显示了价值属性的显着改善，超过五倍。在线A/B测试进一步表明，我们的每米尔（RPM）度量收入增加了1.64％。自2024年10月以来，价值已在我们的广告系统上部署，并为中国最大的购物狂欢节提供了两次促销活动。]]></description>
      <guid>https://arxiv.org/abs/2504.05321</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>平衡利益和风险：成瘾感知社交媒体推荐人的RL方法</title>
      <link>https://arxiv.org/abs/2504.05322</link>
      <description><![CDATA[ARXIV：2504.05322V1公告类型：新 
摘要：社交媒体平台为用户提供了宝贵的机会，可以收集信息，与朋友互动并享受娱乐。但是，它们的上瘾潜力构成了重大挑战，包括过度使用和负面的心理或行为影响[4,2,8]。这项研究探讨了减轻强迫社交媒体使用的策略，同时保留其收益并确保经济可持续性，重点关注推荐人的推荐人。
  我们分析了用户行为是由内在的多样性和环境互动引起的，为下一代社交媒体推荐的洞察力提供了优先级的幸福感。具体而言，我们使用推荐人可用的措施来检查过度使用和成瘾的时间可预测性，旨在为防止成瘾的机制提供信息，同时避免用户脱离接触[7]。
  在基于RL的成瘾建模的基于RL的计算框架[6]的基础上，我们的研究介绍了： - 推荐系统适应用户偏好，引入了非平稳和非马克维亚动力学。
   - 用户和推荐人的差异化状态表示，以捕获细微的交互。
   - 明显的用法条件轻巧和大量使用 - 用来延长健康参与的RL的局限性。
   - 过度使用影响的复杂性，突出了它们在用户适应中的作用[7]。
  模拟说明了基于模型（MB）和无模型（MF）决策如何与环境动态相互作用以影响用户行为和成瘾。结果揭示了推荐系统在塑造成瘾趋势或促进更健康的参与度中的重要作用。这些发现支持道德，适应性推荐设计，并推进可持续的社交媒体生态系统[9，1]。
  关键字：多代理系统，推荐系统，成瘾，社交媒体]]></description>
      <guid>https://arxiv.org/abs/2504.05322</guid>
      <pubDate>Wed, 09 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>