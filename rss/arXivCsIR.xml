<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>结合知识图谱和 LLM 实现危险化学品信息管理和再利用</title>
      <link>https://arxiv.org/abs/2412.09644</link>
      <description><![CDATA[arXiv:2412.09644v1 公告类型：新
摘要：人类健康越来越受到危险物质（特别是持久性和毒性化学物质）的威胁。科学研究​​表明，这些物质（通常以复杂混合物的形式出现）与各种疾病之间存在联系。然而，这些信息分散在多个来源，人类和机器几乎无法获取。本文评估了当前发布/访问危险化学品信息的做法，并提出了一个新颖的平台，旨在方便在紧急情况下检索关键化学数据。该平台汇总来自多个来源的信息并将其组织成结构化知识图。用户可以通过可视化界面（如 Neo4J Bloom 和仪表板）或通过使用聊天机器人的自然语言查询来访问这些信息。我们的研究结果表明，当数据集遵循 FAIR 原则时，访问重要化学信息所需的时间和精力显著减少。此外，我们讨论了从开发和实施该平台中吸取的经验教训，并为数据所有者和发布者提供了建议，以增强数据重用和互操作性。这项工作旨在提高医疗保健专业人员对化学信息的可访问性和可用性，从而支持患者在面临化学中毒风险时获得更好的健康结果并做出明智的决策。]]></description>
      <guid>https://arxiv.org/abs/2412.09644</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中的犹豫与容忍</title>
      <link>https://arxiv.org/abs/2412.09950</link>
      <description><![CDATA[arXiv:2412.09950v1 公告类型：新
摘要：推荐系统中的用户交互本质上很复杂，通常涉及的行为超出了简单的接受或拒绝。一种特别常见的行为是犹豫，用户在推荐项目时会深思熟虑，表示不确定。我们的大规模调查分别有 6,644 和 3,864 个回复，证实犹豫不仅普遍存在，而且对用户体验也有深远的影响。当用户花费更多时间参与他们最终不感兴趣的内容时，这会导致负面情绪，我们称这种现象为容忍。调查显示，这种容忍行为通常在犹豫之后出现，并会削弱对平台的信任、满意度和长期忠诚度。例如，点击可能反映出对更多信息的需求，而不是真正的兴趣，而长时间接触不合适的内容会加剧挫败感。用户意图和系统解释之间的这种不一致会给推荐训练带来噪音，导致建议增加不确定性和脱离。为了解决这些问题，我们确定了表明容忍行为的信号，并分析了来自电子商务和短视频平台的数据集。分析显示，容忍行为的增加与用户活动减少之间存在很强的相关性。我们将这些见解整合到一个主要短视频平台的推荐系统的训练过程中。四个独立的在线 A/B 实验的结果表明，用户留存率显著提高，而额外的计算成本却很少。这些发现强调了认识到犹豫是一种普遍存在的用户行为并解决容忍问题的重要性，以提高满意度、建立信任并维持推荐系统的长期参与度。]]></description>
      <guid>https://arxiv.org/abs/2412.09950</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用矩阵分解进行密集检索中的静态剪枝</title>
      <link>https://arxiv.org/abs/2412.09983</link>
      <description><![CDATA[arXiv:2412.09983v1 公告类型：新
摘要：在密集检索时代，文档索引和检索主要基于将文本文档转换为嵌入的编码模型。检索效率与文档数​​量和嵌入的大小成正比。最近的研究表明，可以在不牺牲（在某些情况下甚至提高）检索效率的情况下减小嵌入大小。然而，这些研究引入的方法依赖于查询，因此它们不能离线应用，并且在查询处理期间需要额外的计算，从而对检索效率产生负面影响。在本文中，我们提出了一种新的静态修剪方法，用于使用主成分分析来降低嵌入的维数。这种方法与查询无关，可以离线执行，从而显着提高密集检索效率，而对系统效率的影响可以忽略不计。我们的实验表明，对于不同的密集检索模型，我们提出的方法将文档表示的维数降低了 50% 以上，NDCG@10 降低了 5%。]]></description>
      <guid>https://arxiv.org/abs/2412.09983</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MST-R：检索系统和度量评估的多阶段调整</title>
      <link>https://arxiv.org/abs/2412.10313</link>
      <description><![CDATA[arXiv:2412.10313v1 公告类型：新
摘要：监管文件包含丰富的细微术语和专业语义。FRAG 系统：利用预训练（或冻结）组件的冻结检索增强生成器面临着检索器和应答性能的挑战。我们提出了一个使用多阶段调整 (MST) 策略将检索器性能调整到目标域的系统。我们的检索方法称为 MST-R (a) 首先使用硬负挖掘对向量存储中使用的编码器进行微调，(b) 然后使用混合检索器，使用互惠秩融合结合稀疏和密集检索器，然后 (c) 通过仅微调前 k 个检索结果来调整交叉注意编码器。我们在为 RIRAG 挑战赛发布的数据集上对系统性能进行基准测试（作为 COLING 2025 的 RegNLP 研讨会的一部分）。我们取得了显著的性能提升，在 RegNLP 挑战排行榜上名列前茅。我们还表明，一种简单的回答方法在 RePASs 指标上的得分超过了所有基线和预先训练的 Llama 模型。通过分析这一异常现象，我们为未来的研究提出了重要的启示。]]></description>
      <guid>https://arxiv.org/abs/2412.10313</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接人工智能与科学：AI4Science 大规模文献分析的启示</title>
      <link>https://arxiv.org/abs/2412.09628</link>
      <description><![CDATA[arXiv:2412.09628v1 公告类型：交叉 
摘要：人工智能已被证明是一种推动广泛学科科学研究的变革性工具。然而，人工智能和科学界之间仍然存在巨大的差距，限制了人工智能方法在推动广泛科学发现方面发挥的全部潜力。现有的弥合这一差距的努力往往依赖于对小样本文献的定性检查，对更广泛的 AI4Science 领域提供了有限的视角。在这项工作中，我们对 AI4Science 文献进行了大规模分析，首先使用大型语言模型来识别顶级科学和人工智能场所出版物中的科学问题和人工智能方法。利用这个新的数据集，我们定量地突出了人工智能方法和这个综合领域中的科学问题之间的关键差异，揭示了跨科学学科更深入的人工智能整合的巨大机会。此外，我们还通过链接预测的视角探讨了促进人工智能与科学界合作的潜力和挑战。我们的研究结果和工具旨在促进更有影响力的跨学科合作，并通过更深入、更广泛的人工智能整合加速科学发现。]]></description>
      <guid>https://arxiv.org/abs/2412.09628</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估英国政府当前作为人工智能数据提供者角色的方法</title>
      <link>https://arxiv.org/abs/2412.09632</link>
      <description><![CDATA[arXiv:2412.09632v1 公告类型：交叉 
摘要：生成式 AI 训练语料库的组成仍然是严密保守的秘密，导致 AI 开发人员和组织数据所有者之间的信息不对称，他们的数字资产可能在他们不知情的情况下被纳入语料库。虽然这种不对称是众所周知的持续诉讼的主题，但它也阻碍了对开放数据源对 AI 训练影响的衡量。为了解决这个问题，我们引入并实施了两种方法来评估开放数据在大型语言模型 (LLM) 训练中的使用情况，并“窥视幕后”，以观察英国政府目前作为 AI 数据提供者的贡献。第一种方法是利用 LLM“反学习”的消融研究，旨在研究英国政府网站上的信息对 LLM 的重要性及其在公民查询任务中的表现。第二种方法是信息泄露研究，旨在确定法学硕士是否知道英国政府开放数据计划 data.gov.uk 上发布的数据集中包含的信息。我们的研究结果表明，英国政府网站是 AI 的重要数据来源（跨主题异构），而 data.gov.uk 则不是。本文是一份技术报告，深入解释了上述实验的设计、机制和局限性。它附有一份关于 ODI 网站的补充非技术报告，我们在报告中总结了实验和主要发现，对其进行了解释，并为英国政府在寻求制定 AI 政策时提出了一套可行的建议。虽然我们关注的是英国开放政府数据，但我们相信本文介绍的方法提出了一种可重复的方法来解决 AI 训练语料库的不透明性问题，并为组织提供了一个评估和最大化其对 AI 发展贡献的框架。]]></description>
      <guid>https://arxiv.org/abs/2412.09632</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思维逻辑查询：利用知识图谱引导大型语言模型回答复杂逻辑查询</title>
      <link>https://arxiv.org/abs/2404.04264</link>
      <description><![CDATA[arXiv:2404.04264v5 公告类型：替换 
摘要：尽管大型语言模型（LLM）在许多任务中表现出色，但在面对需要知识准确性的任务时，它存在产生幻觉甚至错误答案的风险。在处理需要多个逻辑推理步骤的逻辑查询时，这个问题变得更加明显。另一方面，基于知识图谱（KG）的问答方法能够借助知识图谱准确地识别正确答案，但当知识图谱本身稀疏和不完整时，其准确性可能会迅速下降。如何以互惠互利的方式将知识图谱推理与 LLM 结合起来，以减轻 LLM 的幻觉问题以及知识图谱的不完整性问题，仍然是一个关键挑战。在本文中，我们提出了“思维逻辑查询”（LGOT），这是第一个将 LLM 与基于知识图谱的逻辑查询推理相结合的方法。 LGOT 无缝结合了知识图谱推理和 LLM，有效地将复杂的逻辑查询分解为易于回答的子问题。通过利用知识图谱推理和 LLM，它成功地为每个子问题得出答案。通过汇总这些结果并为每个步骤选择最高质量的候选答案，LGOT 为复杂问题获得了准确的结果。我们的实验结果表明，性能得到了显着提升，与 ChatGPT 相比，提升幅度高达 20%。]]></description>
      <guid>https://arxiv.org/abs/2404.04264</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基础模型探索联合推荐系统的未来</title>
      <link>https://arxiv.org/abs/2406.00004</link>
      <description><![CDATA[arXiv:2406.00004v3 公告类型：替换 
摘要：近年来，联邦学习 (FL) 和推荐系统 (RS) 的集成，即联邦推荐系统 (FRS)，因通过将私人数据保存在客户端设备上来保护用户隐私而受到关注。然而，由于 FL 的隐私要求和 RS 的典型数据稀疏性问题，FRS 面临着数据异构性和稀缺性等固有限制。像 ChatGPT 这样的模型由迁移学习和自监督学习的概念赋予力量，因此它们可以在微调或提示后轻松应用于下游任务。这些模型，即所谓的基础模型 (FM)，专注于理解人类的意图并按照其在特定任务中的设计角色执行，这些模型因在图像和语言领域产生高质量内容而得到广泛认可。因此，FM 的成就启发了 FRS 的设计并提出了一个有前途的研究方向：集成基础模型来解决上述限制。在本研究中，我们对 FRS 和 FM 进行了全面回顾。具体来说，我们：1）总结当前 FRS 和 FM 的常用方法；2）回顾 FRS 和 FM 带来的挑战；3）讨论未来的潜在研究方向；4）介绍 FRS 领域的一些常见基准和评估指标。我们希望本立场文件能够提供必要的背景和指导，以探索这个有趣且新兴的话题。]]></description>
      <guid>https://arxiv.org/abs/2406.00004</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>