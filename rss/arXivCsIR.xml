<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://arxiv.org/</link>
    <description>计算机科学 - 信息检索 (cs.IR) 更新 arXiv.org 电子打印档案</description>
    <lastBuildDate>Wed, 06 Dec 2023 03:14:23 GMT</lastBuildDate>
    <item>
      <title>HeteFedRec：具有模型异构性的联合推荐系统。 （arXiv：2307.12810v3 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2307.12810</link>
      <description><![CDATA[由于隐私保护的性质，联合推荐系统
(FedRecs) 在设备上的领域引起了越来越多的兴趣
推荐系统。然而，大多数现有的 FedRecs 只允许参与
客户协作训练同一公众的推荐模型
参数大小。为所有客户训练相同大小的模型可以导致
由于客户拥有不同的资源，因此性能不佳。例如，
训练数据有限的客户可能更喜欢训练较小的推荐
模型避免过多的数据消耗，同时客户端有足够的数据
将受益于更大的模型来实现更高的推荐准确性。到
针对上述挑战，本文介绍了 HeteFedRec，一种新颖的 FedRec
框架，可以分配个性化模型尺寸
参与者。在HeteFedRec中，我们提出了一种异构推荐模型
聚合策略，包括统一的双任务学习机制和
维度去相关正则化，以允许知识聚合
不同尺寸的推荐模型。此外，基于关系的集成
提出知识蒸馏方法，有效地从
异构项目嵌入。在三个方面进行了广泛的实验
真实世界的推荐数据集证明了推荐的有效性和效率
HeteFedRec在异构环境下训练联邦推荐系统的研究
设置。
]]></description>
      <guid>http://arxiv.org/abs/2307.12810</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>图像搜索的当代艺术：通过视觉语言模型迭代用户意图扩展。 （arXiv：2312.01656v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2312.01656</link>
      <description><![CDATA[图像搜索是探索广阔空间的基本且用户友好的方法
数字图像画廊。然而，现有的图像搜索方法严重
依赖于标签匹配或图像相似度等接近度测量，需要
精确的用户输入以获得满意的结果。为了满足日益增长的需求
当代图像搜索引擎，能够准确理解用户的需求
搜索意图，我们引入了创新的用户意图扩展框架。
我们的框架利用视觉语言模型来解析和组合多模态
用户输入以提供更准确和令人满意的结果。它包括
两阶段过程：1）包含语言解析的解析阶段
具有大型语言模型的模块，可增强文本的理解
输入，以及集成了交互式的视觉解析模块
分割模块可快速识别图像中详细的视觉元素；
2）结合多个用户搜索意图的逻辑组合阶段
转化为统一的逻辑表达式，以实现复杂的更复杂的操作
搜索场景。此外，意图扩展框架使用户能够
与搜索结果执行灵活的上下文交互，以进一步
迭代地指定或调整其详细的搜索意图。我们实施了
框架到图像搜索系统中，用于 NFT（不可替代代币）搜索和
进行了一项用户研究，以评估其可用性和新颖特性。这
结果表明，所提出的框架显着提高了用户的
图像搜索体验。尤其是语法分析和语境化
交互在允许用户表达他们的搜索意图方面被证明是有用的
更准确并参与更愉快的迭代搜索体验。
]]></description>
      <guid>http://arxiv.org/abs/2312.01656</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>对下一篮子建议的实证研究。 （arXiv：2312.02550v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02550</link>
      <description><![CDATA[下一个篮子推荐系统（NBR）的功能是推荐后续的
通过对用户的偏好进行建模而得出的购物篮
来自购买历史记录，通常表现为一系列历史记录
篮子。鉴于其在电子商务行业的广泛适用性，
近年来，对 NBR 的研究引起了越来越多的关注。
尽管各种 NBR 方法不断涌现，但仍面临着巨大的挑战
问题在于缺乏系统、统一的评价框架
这些方法论。各种研究经常使用 NBR 方法来评估
不同的数据集和不同的实验设置，阻碍了公平和
对方法性能进行有效的比较评估。为了弥补这一点
差距，本研究对 NBR 进行了系统的实证调查，回顾了
领域内的开创性工作并审查其各自的优点和
缺点。随后，我们在统一上实现指定的NBR算法
数据集，采用一致的实验配置，并评估其
通过相同的指标表现。这种方法论的严谨性建立了
用于公正评估不同 NBR 方法的连贯框架。它
预计这项研究将奠定坚实的基础并作为
为这一充满活力的领域即将进行的研究工作提供了关键参考。
]]></description>
      <guid>http://arxiv.org/abs/2312.02550</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>RankZephyr：有效且稳健的零次列表重新排名是轻而易举的！。 （arXiv：2312.02724v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02724</link>
      <description><![CDATA[在信息检索中，专有的大语言模型 (LLM)，例如
GPT-4 以及 LLaMA 和 Vicuna 等开源对应产品发挥了至关重要的作用
在重新排名中的作用。然而，开源和封闭模式之间的差距
持续存在，依赖于专有的、不透明的模型限制
再现性。为了解决这一差距，我们引入了 RankZephyr，
最先进的开源法学硕士，用于列表式零样本重新排名。兰克·泽弗
不仅弥补了与 GPT-4 的有效性差距，而且在某些情况下超越了
专有模型。我们对多个数据集的综合评估
（TREC 深度学习轨道；来自 BEIR 的新闻和新冠病毒）展示了这种能力。
RankZephyr 受益于战略培训选择，并且具有弹性
初始文档排序和重新排序的文档数量的变化。
此外，我们的模型在 NovelEval 测试集上的表现优于 GPT-4，包括
超过培训期的疑问和段落，解决了以下问题
数据污染。为了促进这个快速发展领域的进一步研究，
我们提供重现结果所需的所有代码
https://github.com/castorini/rank_llm。
]]></description>
      <guid>http://arxiv.org/abs/2312.02724</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>用于文档检索的自适应潜在实体扩展。 （arXiv：2306.17082v2 [cs.IR] 已更新）</title>
      <link>http://arxiv.org/abs/2306.17082</link>
      <description><![CDATA[尽管神经相关性排序技术取得了相当大的进步，但搜索
引擎仍然难以有效地处理复杂的查询 - 无论是在方面
的精确度和召回率。稀疏和密集伪相关反馈 (PRF)
方法有可能克服召回的局限性，但只是
效率高、精度高，位居前列。在这项工作中，我们解决了
使用三种互补技术对复杂查询进行搜索的问题。
首先，我们证明在稀疏或稀疏之前应用强大的神经重新排序器
密集的PRF可以提高检索效率5-8%。这一改进在
PRF 的有效性可直接归因于提高 PRF 的精度
反馈设置。其次，我们提出了一种增强的扩展模型，Latent Entity
扩展（LEE），应用细粒度单词和基于实体的相关性
结合本地化特征的建模。具体来说，我们发现通过
包括用于扩展的单词和实体，进一步实现 2-8%
NDCG 的改进。我们的分析还表明，LEE 在很大程度上是稳健的
跨数据集的参数，并且在以实体为中心的查询上表现良好。
第三，我们在检索过程中包含一个“自适应”组件，该组件
在评分期间使用扩展迭代地细化重新排名池
模型并避免重新排序其他文档。我们发现这个组合
的技术在 TREC Robust 上实现了最佳 NDCG、MAP 和 R@1000 结果
2004 和 CODEC 文档数据集，展示了在
扩张成效。
]]></description>
      <guid>http://arxiv.org/abs/2306.17082</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>草案：密集检索增强的少样本主题分类器框架。 （arXiv：2312.02532v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02532</link>
      <description><![CDATA[随着多样化信息量的不断增长，分类的需求
随意的话题变得越来越关键。为了应对这一挑战，
我们介绍 DRAFT，一个简单的框架，旨在训练分类器
少样本主题分类。 DRAFT 使用特定主题的几个示例：
查询以使用密集检索器模型构建定制数据集。
多查询检索（MQR）算法，有效处理多个
与特定主题相关的查询，用于构建定制的
数据集。随后，我们使用定制数据集微调分类器
来确定主题。为了证明我们提出的方法的有效性，我们
对广泛使用的分类基准数据集进行评估
手动构建的数据集，包含 291 个不同的主题，模拟不同的主题
实际应用中遇到的内容。草案显示有竞争力或
与使用情境学习的基线相比，性能优越，例如
如 GPT-3 175B 和 InstructGPT 175B，在少数主题分类任务上
尽管参数减少了 177 倍，但仍证明了其有效性。
]]></description>
      <guid>http://arxiv.org/abs/2312.02532</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>用于多方面密集检索的多粒度感知方面学习模型。 （arXiv：2312.02538v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02538</link>
      <description><![CDATA[密集检索方法主要集中在非结构化文本和
人们对各个方面的结构化数据的关注较少，例如，
产品具有类别和品牌等方面。最近的工作提出了两个
将方面信息合并到项目表示中的方法
通过预测与项目方面相关的值来有效检索。
尽管它们很有效，但他们将这些值视为孤立的类（例如，“智能
住宅”、“住宅、花园和花园”工具”和“美容与美容”健康”）并忽略他们的
细粒度的语义关系。此外，他们要么强制学习
CLS 代币的各个方面，这可能会使其与其指定用途相混淆
用于表示整个内容语义，或学习额外的方面嵌入
仅具有价值预测目标，这可能是不够的
特别是当项目方面没有注释值时。意识到
针对这些限制，我们提出了一种多粒度感知的方面学习模型
（MURAL）用于多方面密集检索。它利用方面信息
跨越各种粒度来捕获粗粒度和细粒度的语义
价值观之间的关系。此外，MURAL 还包含单独的方面
嵌入作为变压器编码器的输入，以便掩码语言模型
即使没有方面值，目标也可以帮助隐式方面学习
注释。对两个真实世界的产品数据集进行了广泛的实验
小程序显示 MURAL 的性能优于最先进的基线
显著地。
]]></description>
      <guid>http://arxiv.org/abs/2312.02538</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>PEFA：用于大规模基于嵌入的检索模型的无参数适配器。 （arXiv：2312.02429v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02429</link>
      <description><![CDATA[基于嵌入的检索模型（ERM）已成为一个有前途的框架
由于强大的大型语言模型，可以解决大规模文本检索问题。
尽管如此，微调企业风险管理以达到最先进的结果是可以的
由于数据规模极大且复杂，成本高昂
多级管道（例如预训练、微调、蒸馏）。在这个
为了快速工作，我们提出了 PEFA 框架，即 ParamEter-Free Adapters
在优化过程中无需任何向后传递即可调整 ERM。在指数建设中
阶段，PEFA 为 ERM 配备非参数 k 最近邻 (kNN)
成分。在推理阶段，PEFA 执行两个凸组合
评分函数，一个来自 ERM，另一个来自 kNN。基于
邻域定义，PEFA 框架引入了两个实现，即
使用双 ANN 索引的 PEFA-XL（即超大）和 PEFA-XS（即超大）
小）使用单个 ANN 索引。根据经验，PEFA 取得了显着的成果
改进了两个检索应用程序。对于文档检索，关于
Recall@100 metric，PEFA 不仅通过 Trivia-QA 改进了预训练的 ERM
平均 13.2%，而且还对 NQ-320K 上的 ERM 进行了平均 5.5% 的微调，
分别。对于产品搜索，PEFA 改进了产品的 Recall@100
对于 PEFA-XS 和 PEFA-XL，ERM 平均微调 5.3% 和 14.5%，
分别。我们的代码可在 https://github.com/ 获取
amzn/pecos/tree/mainline/examples/pefa-wsdm24
]]></description>
      <guid>http://arxiv.org/abs/2312.02429</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>E4SRec：用于顺序推荐的大型语言模型的优雅有效的可扩展解决方案。 （arXiv：2312.02443v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02443</link>
      <description><![CDATA[大型语言模型 (LLM) 的最新进展引起了人们的兴趣
在推荐系统中发挥其潜力。由于 LLM 是
现有的推荐方法专为自然语言任务而设计
主要将推荐任务转变为开放域自然
语言生成任务。然而，这种方法需要拥有物品
丰富的语义信息，经常产生超出范围的结果，并受到影响
由于效率明显低下且可扩展性有限。此外，实用
基于ID的推荐策略，依赖于大量独特的
代表用户和项目的身份（ID）在
现实世界的推荐系统由于其有效性和效率。
然而，法学硕士无法对 ID 进行建模，这带来了巨大的困难。
寻求利用法学硕士进行个性化推荐时面临的挑战。在
在本文中，我们介绍了一种优雅、有效、高效、可扩展的解决方案
用于顺序推荐 (E4SRec) 的大型语言模型，可无缝地
将法学硕士与专门利用传统推荐系统的
代表项目的 ID。具体来说，E4SRec 将 ID 序列作为输入，
确保生成的输出落入候选列表之内。
此外，E4SRec 具有生成整个排名的能力
列表在单个转发过程中，并且只需要最小的可插拔集
参数，针对每个数据集进行训练，同时保留整个 LLM
冻结了。我们证实我们的有效性、效率和可扩展性
通过对四种广泛使用的系统进行综合实验，提出了 E4SRec
真实世界的数据集。实现代码可访问
https://github.com/HestiaSky/E4SRec/。
]]></description>
      <guid>http://arxiv.org/abs/2312.02443</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>LLaRA：将大型语言模型与顺序推荐器结合起来。 （arXiv：2312.02445v1 [cs.IR]）</title>
      <link>http://arxiv.org/abs/2312.02445</link>
      <description><![CDATA[顺序推荐旨在预测与用户匹配的后续项目
基于她/他的历史互动的偏好。随着发展
大型语言模型（LLM），人们越来越有兴趣探索
通过将法学硕士视为一种语言来进行顺序推荐的潜力
建模任务。先前的作品使用以下任一方式表示文本提示中的项目
ID 索引或文本索引并将提示输入 LLM，但达不到要求
要么概括全面的世界知识，要么展示足够的
顺序理解。发挥传统优势互补
推荐者（对用户行为知识进行编码）和法学硕士（拥有
关于项目的世界知识），我们提出 LLaRA——一种大语言和
推荐助手框架。具体来说，LLaRA 代表以下项：
LLM 的输入提示使用一种新颖的混合方法，该方法集成了基于 ID 的项目
具有文本项特征的传统推荐器的嵌入。观看
“用户的顺序行为”作为推荐的新模式，我们
使用适配器来弥合 ID 嵌入之间的模态差距
传统推荐器和法学硕士的输入空间。此外，代替
直接向法学硕士公开混合提示，我们应用课程学习
逐步提高训练复杂性的方法。我们首先热身LLM
带有纯文本提示，与法学硕士的语言更自然地保持一致
建模能力。此后，我们逐步过渡到混合动力
提示、训练适配器将来自于的行为知识纳入其中
传统的顺序推荐进入法学硕士。广泛的实验
证明LLaRA框架的功效。我们的代码和数据可在
https://github.com/ljy0ustc/LLaRA。
]]></description>
      <guid>http://arxiv.org/abs/2312.02445</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>FreestyleRet：从风格多样化的查询中检索图像。 （arXiv：2312.02428v1 [cs.CV]）</title>
      <link>http://arxiv.org/abs/2312.02428</link>
      <description><![CDATA[图像检索旨在根据给定的查询检索相应的图像。
在应用场景中，用户想要表达自己的检索意图
通过各种查询方式。然而，当前的检索任务主要是
专注于文本查询检索探索，导致检索查询有限
选项以及用户意图中潜在的模糊性或偏见。在本文中，我们
提出基于风格多样化查询的图像检索任务，该任务使得
基于各种查询样式的检索。为了方便新颖的设置，我们
提出第一个多样化风格检索数据集，包含多样化查询
样式包括文本、草图、低分辨率和艺术。我们还提出了一个
轻量级风格多样化的检索框架。适用于各种查询样式
输入，我们应用 Gram 矩阵来提取查询的纹理特征，
将它们聚集到具有特定风格基础的风格空间中。然后我们采用
style-init提示调整模块使视觉编码器能够理解
查询的纹理和样式信息。实验表明我们的
模型，采用 style-init 提示调整策略，优于现有模型
风格多样化检索任务的检索模型。而且，
风格多样化查询~（素描+文字、美术+文字等）可以同时进行
在我们的模型中检索到。来自其他查询的辅助信息增强了
相应查询中的检索性能。
]]></description>
      <guid>http://arxiv.org/abs/2312.02428</guid>
      <pubDate>Wed, 06 Dec 2023 03:14:19 GMT</pubDate>
    </item>
    </channel>
</rss>