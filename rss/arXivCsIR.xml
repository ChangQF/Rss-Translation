<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>重新思考令牌检索在多向量检索中的作用</title>
      <link>https://arxiv.org/abs/2304.01982</link>
      <description><![CDATA[arXiv:2304.01982v3 公告类型：replace-cross
摘要：ColBERT [Khattab 和 Zaharia，2020] 等多向量检索模型允许查询和文档之间进行标记级交互，因此在许多信息检索基准上实现了最先进的技术。然而，它们的非线性评分函数无法扩展到数百万个文档，因此需要一个三阶段的推理过程：通过令牌检索检索初始候选，访问所有令牌向量，并对初始候选文档进行评分。非线性评分函数应用于每个候选文档的所有标记向量，使得推理过程复杂且缓慢。在本文中，我们的目标是通过重新思考标记检索的作用来简化多向量检索。我们提出了 XTR（ConteXtualized Token Retriever），它引入了一个简单而新颖的目标函数，鼓励模型首先检索最重要的文档标记。对令牌检索的改进允许 XTR 仅使用检索到的令牌而不是文档中的所有令牌对候选者进行排名，并启用新设计的评分阶段，该阶段比 ColBERT 便宜两到三个数量级。在流行的 BEIR 基准上，XTR 无需任何蒸馏即可将最先进技术提升 2.8 nDCG@10。详细的分析证实了我们重新审视令牌检索阶段的决定，因为与 ColBERT 相比，XTR 表现出更好的令牌检索阶段召回率。]]></description>
      <guid>https://arxiv.org/abs/2304.01982</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>咖啡树锈病流行的经济流行病学分析</title>
      <link>https://arxiv.org/abs/2304.14515</link>
      <description><![CDATA[arXiv:2304.14515v3 公告类型：replace-cross
【摘要】：咖啡叶锈病是一种常见的植物病害,可导致全球咖啡供应量和质量下降,造成巨大的经济损失。虽然一些用于应对锈病大流行的流行病干预政策（PIP）在商业上是可行的，但它们似乎只能为农民提供部分流行病学缓解。在这项工作中，我们开发了一个高分辨率的经济流行病学模型，该模型可以捕捉锈病大流行在咖啡树农场中的传播及其相关的经济影响。通过对哥伦比亚的案例进行广泛模拟，该国主要由小型咖啡农场组成，是世界第二大咖啡生产国，我们的结果表明，在不直接解决锈病流行的情况下维持任何利润在经济上是不切实际的。此外，即使假设农民事先完全了解农场的流行病状况和天气，任何与锈病流行相关的努力也只能获得有限的投资利润，大约为4%。在更现实的情况下，任何与锈病大流行相关的努力预计都会导致经济损失，这表明咖啡市场预计将出现重大干扰。]]></description>
      <guid>https://arxiv.org/abs/2304.14515</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐实体的时间方面的多种模型</title>
      <link>https://arxiv.org/abs/1803.07890</link>
      <description><![CDATA[arXiv:1803.07890v4 公告类型：替换
摘要：实体方面推荐是语义搜索中的一项新兴任务，可帮助用户发现与实体相关的偶然且突出的信息，其中显着性（例如流行度）是先前工作中最重要的因素。然而，实体方面是暂时动态的，并且通常由随时间推移发生的事件驱动。对于这种情况，仅基于显着特征的方面建议可能会给出不令人满意的结果，原因有两个。首先，显着性通常是在很长一段时间内积累的，并且不考虑新近度。其次，与事件实体相关的许多方面都强烈依赖于时间。在本文中，我们研究给定实体的时间方面推荐任务，其目的是推荐最​​相关的方面并考虑时间以改善搜索体验。我们提出了一种新颖的以事件为中心的集成排名方法，该方法从多个时间和类型相关的模型中学习，并动态地权衡显着性和新近度特征。通过对现实世界查询日志的广泛实验，我们证明了我们的方法是稳健的，并且比竞争基线具有更好的有效性。]]></description>
      <guid>https://arxiv.org/abs/1803.07890</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>LLaRA：大型语言推荐助手</title>
      <link>https://arxiv.org/abs/2312.02445</link>
      <description><![CDATA[arXiv:2312.02445v3 公告类型：替换
摘要：顺序推荐旨在根据用户过去的参与顺序来预测用户与项目的下一次交互。最近，大型语言模型（LLM）的出现引发了人们对利用它们进行顺序推荐的兴趣，将其视为语言建模。以前的研究将法学硕士输入提示中的项目表示为 ID 索引或文本元数据。然而，这些方法往往无法概括全面的世界知识或表现出足够的行为理解。为了结合传统推荐器捕获用户行为模式和法学硕士编码项目世界知识的互补优势，我们引入了大型语言推荐助手（LLaRA）。具体来说，它使用了一种新颖的混合提示方法，将传统推荐模型学习到的基于 ID 的项目嵌入与文本项目特征相结合。将“用户的顺序行为”视为文本之外的独特模态，我们使用投影仪将传统推荐者的 ID 嵌入与法学硕士的输入空间对齐。此外，不是直接向法学硕士公开混合提示，而是采用课程学习策略来逐步提高培训复杂性。最初，我们使用纯文本提示来预热法学硕士，这更适合其固有的语言建模能力。随后，我们逐步过渡到混合提示，训练模型将传统顺序推荐器的行为知识无缝融入法学硕士。实证结果验证了我们提出的框架的有效性。代码可在 https://github.com/ljy0ustc/LLaRA 获取。]]></description>
      <guid>https://arxiv.org/abs/2312.02445</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>探索不同的声音：识别音乐语料库中的异常值</title>
      <link>https://arxiv.org/abs/2404.06103</link>
      <description><![CDATA[arXiv:2404.06103v1 公告类型：交叉
摘要： 现有的音乐推荐系统研究主要集中在推荐相似的音乐，从而往往忽视了多样化和独特的音乐录音。由于音乐本身固有的多样性，音乐异常值可以提供有价值的见解。在本文中，我们探索音乐异常值，研究它们对音乐发现和推荐系统的潜在用处。我们认为，并非所有异常值都应该被视为噪音，因为它们可以提供有趣的视角并有助于更丰富地理解艺术家的作品。我们引入“真正”音乐异常值的概念并为其提供定义。这些真正的异常值可以揭示艺术家曲目的独特方面，并有可能通过让听众接触新颖和多样化的音乐体验来增强音乐发现。]]></description>
      <guid>https://arxiv.org/abs/2404.06103</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>RAR-b：推理作为检索基准</title>
      <link>https://arxiv.org/abs/2404.06347</link>
      <description><![CDATA[arXiv:2404.06347v1 公告类型：交叉
摘要：语义文本相似度（STS）和信息检索任务（IR）任务是过去几年记录嵌入模型进展的两个主要途径。在新兴的检索增强生成（RAG）范式下，我们设想需要评估嵌入模型的下一级语言理解能力，并有意识地查看其中存储的推理能力。针对这个问题，我们提出一个问题：检索器可以解决推理问题吗？通过将推理任务转化为检索任务，我们发现，如果没有经过推理级语言理解的专门训练，当前最先进的检索器模型可能还远远不能胜任协助法学硕士的作用，尤其是在推理方面——密集的任务。此外，尽管经过训练以了解指令，但具有指令意识的 IR 模型通常在推理任务的推理时间内没有指令的情况下会表现得更好，这为研究界带来了一个被忽视的检索器-法学硕士行为差距。然而，最近基于解码器的嵌入模型在缩小差距方面显示出了巨大的希望，突出了嵌入模型实现推理级语言理解的途径。我们还表明，尽管当前现成的重排序模型在这些任务上失败了，但通过微调向它们注入推理能力仍然比双编码器更容易，并且我们能够实现状态-通过微调重新排名模型，在所有任务中实现最先进的性能。我们发布了推理检索基准 (RAR-b)，这是一套完整的任务和设置，用于评估检索器模型中存储的推理能力。 RAR-b 可从 https://github.com/gowitheflow-1998/RAR-b 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.06347</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>从具有状态、姿势和视点变化的图像集合中学习对象的状态不变表示</title>
      <link>https://arxiv.org/abs/2404.06470</link>
      <description><![CDATA[arXiv:2404.06470v1 公告类型：交叉
摘要：我们在更常用的其他不变性中添加了一种不变性——状态不变性，用于学习识别和检索的对象表示。通过状态不变性，我们的意思是对于对象结构形式的变化具有鲁棒性，例如当雨伞被折叠时，或者当一件衣服被扔在地板上时。尽管存在这种状态变化，但人类通常在识别物体方面没有困难，因此我们自然会面临这样的问题：是否有可能设计出具有类似能力的神经架构。为此，我们提出了一个新颖的数据集，ObjectsWithStateChange，它捕获从任意视点记录的对象图像中的状态和姿势变化。我们相信该数据集将促进细粒度对象识别和能够状态改变的对象检索的研究。此类研究的目标是训练能够生成对象嵌入的模型，该对象嵌入对状态变化保持不变，同时对视点、姿势、照明等变化引起的变换保持不变。为了证明 ObjectsWithStateChange 数据集的有用性，我们还提出一种课程学习策略，该策略使用每个时期后学习到的嵌入空间中的相似关系来指导训练过程。该模型通过比较不同类别内和不同类别之间视觉上相似的对象来学习区分特征，鼓励它区分由于状态变化而可能难以区分的对象。我们相信，这种策略增强了模型捕获可能涉及状态变化的对象的细粒度任务的判别性特征的能力，从而不仅在我们的新数据集上，而且在其他两个具有挑战性的多数据集上，提高了对象级任务的性能。查看 ModelNet40 和 ObjectPI 等数据集。]]></description>
      <guid>https://arxiv.org/abs/2404.06470</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>使用结构化知识库可增强大型语言模型的元数据管理</title>
      <link>https://arxiv.org/abs/2404.05893</link>
      <description><![CDATA[arXiv:2404.05893v1 公告类型：交叉
摘要：元数据在确保数据集的可查找性、可访问性、互操作性和可重用性方面发挥着至关重要的作用。本文研究了大型语言模型 (LLM)（特别是 GPT-4）在提高对元数据标准的遵守方面的潜力。我们对来自 NCBI BioSample 存储库的 200 个描述与肺癌相关的人类样本的随机数据记录进行了实验，评估了 GPT-4 提出编辑建议以遵守元数据标准的能力。我们通过同行评审过程计算了字段名称-字段值对的遵守准确性，我们观察到遵守标准数据字典的边际平均改进从 79% 到 80% (p&lt;0.01)。然后，我们以 CEDAR 模板文本描述的形式向 GPT-4 提示域信息，并记录了从 79% 显着提高到 97% (p&lt;0.01)。这些结果表明，虽然法学硕士可能无法在没有帮助的情况下纠正遗留元数据以确保令人满意地遵守标准，但当与结构化知识库集成时，它们确实显示出在自动化元数据管理中使用的前景。]]></description>
      <guid>https://arxiv.org/abs/2404.05893</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>通过检索增强个性化大型语言模型的优化方法</title>
      <link>https://arxiv.org/abs/2404.05970</link>
      <description><![CDATA[arXiv:2404.05970v1 公告类型：交叉
摘要：本文研究了个性化大型语言模型（LLM）的检索增强方法，这可能对各种应用程序和领域产生重大影响。我们提出了首次尝试优化检索模型，将有限数量的个人文档传递给大型语言模型，以实现个性化生成。我们开发了两种优化算法，从下游个性化生成任务中征求反馈以进行检索优化——一种基于强化学习，其奖励函数是使用任意个性化生成指标定义的，另一种基于从下游 LLM 到检索模型的知识蒸馏。本文还介绍了一个生成前和生成后检索器选择模型，该模型决定为每个 LLM 输入选择哪个检索器。对语言模型个性化 (LaMP) 基准的各种任务进行的广泛实验表明，七个数据集中有六个在统计上有显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2404.05970</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>实时搜索中的事件增强检索</title>
      <link>https://arxiv.org/abs/2404.05989</link>
      <description><![CDATA[arXiv:2404.05989v1 公告类型：交叉
摘要：基于嵌入的检索（EBR）方法广泛应用于主流搜索引擎检索系统中，并且在最近消除 LLM 错觉的检索增强方法中至关重要。然而，现有的EBR模型往往面临“语义漂移”问题以及对关键信息关注不够，导致后续步骤检索结果的采用率较低。这个问题在实时搜索场景中尤为明显，互联网上热门事件的多种表达方式使得实时检索严重依赖于关键事件信息。为了解决这个问题，本文提出了一种称为 EER 的新方法，通过改进传统 EBR 的双编码器模型来增强实时检索性能。我们将对比学习与成对学习结合起来以实现编码器优化。此外，为了加强对事件中关键事件信息的关注，我们在文档编码器之后添加了解码器模块，引入了基于提示调整的生成事件三元组提取方案，并通过比较学习将事件与查询编码器优化相关联。该解码器模块可以在推理过程中删除。大量实验表明，EER 可以显着提高实时搜索检索性能。我们相信这种方法将为信息检索领域提供新的视角。代码和数据集可在 https://github.com/open-event-hub/Event-enhanced_Retrieval 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.05989</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>多模态模型和排序模型的端到端训练</title>
      <link>https://arxiv.org/abs/2404.06078</link>
      <description><![CDATA[arXiv:2404.06078v1 公告类型：新
摘要：传统的推荐系统严重依赖 ID 特征，经常遇到与冷启动和泛化相关的挑战。对预先提取的内容特征进行建模可以缓解这些问题，但由于训练任务和模型参数之间的差异，仍然不是最佳解决方案。端到端训练为这些问题提供了一个有前途的解决方案，但大多数现有工作主要集中在检索模型上，而多模态技术没有得到充分利用。在本文中，我们提出了一种名为EM3的工业多模态推荐框架：多模态模型和排序模型的端到端训练，该框架充分利用多模态信息，并允许个性化排序任务直接训练多模态模型中的核心模块以获得更多信息。面向任务的内容功能，不会造成过多的资源消耗。首先，我们提出 Fusion-Q-Former，它由转换器和一组可训练查询组成，用于融合不同的模态并生成固定长度和鲁棒的多模态嵌入。其次，在用户内容兴趣的序列建模中，我们利用低秩适应技术来缓解巨大的资源消耗和长序列长度之间的冲突。第三，我们提出了一种新颖的 Content-ID-Contrastive 学习任务，通过将内容和 ID 相互对齐来补充内容和 ID 的优势，获得更多面向任务的内容嵌入和更通用的 ID 嵌入。在实验中，我们在两种场景下的不同排名模型上实现了 EM3，在离线评估和在线 A/B 测试方面均取得了显着改进，验证了我们方法的通用性。还进行消融研究和可视化。此外，我们还对两个公共数据集进行了实验，以表明我们提出的方法优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.06078</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>DRE：通过在数据级别对齐大型语言模型来生成推荐解释</title>
      <link>https://arxiv.org/abs/2404.06311</link>
      <description><![CDATA[arXiv:2404.06311v1 公告类型：新
摘要：推荐系统在各个领域发挥着至关重要的作用，它根据用户行为来推荐项目。然而，呈现推荐时缺乏透明度可能会导致用户困惑。在本文中，我们介绍了数据级推荐解释（DRE），这是一种针对黑盒推荐模型的非侵入式解释框架。与现有方法不同，DRE不需要推荐模型的任何中间表示或潜在对齐训练，从而减轻了推荐模型的负担。潜在的性能问题。我们提出了一种数据级对齐方法，利用大型语言模型来推理用户数据和推荐项目之间的关系。此外，我们通过引入目标感知的用户偏好蒸馏来解决丰富解释细节的挑战，利用项目评论。基准数据集的实验结果证明了 DRE 在提供准确且以用户为中心的解释、增强用户对推荐项目的参与度方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.06311</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:37 GMT</pubDate>
    </item>
    <item>
      <title>LLM 增强检索：通过语言模型和文档级嵌入增强检索模型</title>
      <link>https://arxiv.org/abs/2404.05825</link>
      <description><![CDATA[arXiv:2404.05825v1 公告类型：新
摘要：与传统的稀疏或词袋方法相比，最近基于嵌入的检索或密集检索已显示出最先进的结果。本文通过大型语言模型（LLM）增强介绍了一种与模型无关的文档级嵌入框架。此外，它还改进了检索模型训练过程中的一些重要组成部分，例如负采样、损失函数等。通过实现这个LLM增强检索框架，我们已经能够显着提高广泛使用的检索器模型的有效性例如双编码器（Contriever、DRAGON）和后期交互模型（ColBERTv2），从而在 LoTTE 数据集和 BEIR 数据集上取得了最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.05825</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>用于不确定性协同过滤的 Wasserstein 相关图注意网络</title>
      <link>https://arxiv.org/abs/2404.05962</link>
      <description><![CDATA[arXiv:2404.05962v1 公告类型：新
摘要：协同过滤（CF）是推荐系统中的一项基本技术，它仅通过利用用户-项目交互来提供个性化推荐。然而，大多数CF方法将用户和物品表示为潜在空间中的固定点，缺乏捕获不确定性的能力。在本文中，我们提出了一种新颖的方法，称为 Wasserstein 依赖图注意力网络（W-GAT），用于不确定性的协同过滤。我们利用图注意力网络和 Wasserstein 距离来解决 LightGCN 和 Kullback-Leibler 散度（KL）散度的局限性，以学习每个用户和项目的高斯嵌入。此外，我们的方法进一步结合了 Wasserstein 相关的互信息，以增加正对之间的相似性并解决 KL 散度带来的挑战。三个基准数据集的实验结果表明，与几个代表性基线相比，W-GAT 具有优越性。广泛的实验分析验证了 W-GAT 通过对用户偏好范围和与项目相关的类别进行建模来捕获不确定性的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.05962</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    <item>
      <title>AiSAQ：具有产品量化功能的全存储 ANN，用于无 DRAM 信息检索</title>
      <link>https://arxiv.org/abs/2404.06004</link>
      <description><![CDATA[arXiv:2404.06004v1 公告类型：新
摘要：在基于近似邻近图的近似最近邻搜索（ANNS）方法中，DiskANN 在使用 RAM 和存储的大规模数据集上实现了良好的召回-速度平衡。尽管它声称通过乘积量化（PQ）加载压缩向量来节省内存使用量，但其内存使用量与数据集规模成比例增加。在本文中，我们提出了带有乘积量化的全存储人工神经网络（AiSAQ），它将压缩向量卸载到存储中。即使对于数十亿规模的数据集，我们的方法在查询搜索中也能实现 $\sim$10 MB 的内存使用，而性能下降较小。 AiSAQ还减少了查询搜索之前的索引加载时间，从而实现了多个数十亿级数据集之间的索引切换，并显着增强了检索增强生成（RAG）的灵活性。该方法适用于所有基于图的 ANNS 算法，并且将来可以与更高规格的 ANNS 方法相结合。]]></description>
      <guid>https://arxiv.org/abs/2404.06004</guid>
      <pubDate>Wed, 10 Apr 2024 06:17:36 GMT</pubDate>
    </item>
    </channel>
</rss>