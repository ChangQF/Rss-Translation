<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 18 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用深度自动编码器增强上下文感知推荐系统的共形可预测性</title>
      <link>https://arxiv.org/abs/2412.12110</link>
      <description><![CDATA[arXiv:2412.12110v1 公告类型：新
摘要：在推荐系统 (RS) 领域，神经协同过滤代表了一个重要的里程碑，它结合了矩阵分解和深度神经网络，取得了有希望的结果。矩阵分解等传统方法通常依赖于线性模型，限制了它们捕获用户、项目和上下文之间复杂交互的能力。由于高维数据集无法捕获用户、项目和上下文因素之间的关系，这种限制在高维数据集中尤为明显。无监督学习和降维任务利用自动编码器，基于神经网络的模型以其编码和解码数据的能力而闻名。自动编码器学习输入的潜在表示，在捕获复杂模式和特征的同时减小数据集大小。在本文中，我们介绍了一个将神经上下文矩阵分解与自动编码器相结合的框架，以预测用户对项目的评分。我们全面概述了该框架的设计和实施。为了评估其性能，我们对各种真实数据集进行了实验，并将结果与​​最先进的方法进行了比较。我们还将共形预测的概念扩展到预测评级，并引入了共形预测评级 (CPR)。对于 RS，我们定义了非共形分数，这是共形预测的一个关键概念，并证明它满足可交换性属性。]]></description>
      <guid>https://arxiv.org/abs/2412.12110</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>搜索个人收藏</title>
      <link>https://arxiv.org/abs/2412.12330</link>
      <description><![CDATA[arXiv:2412.12330v1 公告类型：新 
摘要：本文介绍了个人文档集信息检索的历史。]]></description>
      <guid>https://arxiv.org/abs/2412.12330</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 是知识图谱推理器：LLM 的直觉感知知识图谱推理，用于冷启动顺序推荐</title>
      <link>https://arxiv.org/abs/2412.12464</link>
      <description><![CDATA[arXiv:2412.12464v1 公告类型：新
摘要：知识图谱 (KG) 表示图结构中实体之间的关系，已被广泛研究为实现考虑项目准确内容信息的推荐的有前途的工具。然而，传统的基于 KG 的推荐方法面临着根本性的挑战：对时间信息的考虑不足和冷启动场景下的性能不佳。另一方面，大型语言模型 (LLM) 可以被视为具有从网络数据中学习到的丰富知识的数据库，它们最近因其作为推荐系统的潜在应用而受到关注。虽然将 LLM 视为推荐系统的方法可以利用 LLM 的高推荐素养，但它们的输入令牌限制使得考虑整个推荐域数据集变得不切实际并导致可扩展性问题。为了应对这些挑战，我们提出了一个 LLM 的直觉感知知识图谱推理模型 (LIKR)。我们的主要思想是将 LLM 视为推理器，为 KG 输出直观的探索策略。为了整合 LLM 和 KG 的知识，我们通过强化学习训练了一个推荐代理，使用一个集成了不同推荐策略（包括 LLM 的直觉和 KG 嵌入）的奖励函数。通过提示工程融入时间意识并从有限的交互中生成用户偏好的文本表示，LIKR 可以提高冷启动场景中的推荐性能。此外，LIKR 可以通过使用 KG 来表示推荐域数据集并将 LLM 的输出限制为 KG 探索策略来避免可扩展性问题。在真实数据集上的实验表明，我们的模型在冷启动顺序推荐场景中的表现优于最先进的推荐方法。]]></description>
      <guid>https://arxiv.org/abs/2412.12464</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用分布感知稳健学习增强基于 LLM 的相关性建模</title>
      <link>https://arxiv.org/abs/2412.12504</link>
      <description><![CDATA[arXiv:2412.12504v1 公告类型：新
摘要：随着预训练大型语言模型 (LLM) 的快速发展，最近的努力已经利用了 LLM 在相关性建模中的能力，从而提高了性能。这通常是通过在特定注释的数据集上微调 LLM 来确定查询和项目之间的相关性来完成的。然而，当通过微调和推理将 LLM 用于相关性建模时，存在两个限制。首先，除了简单的是或否答案之外，它本身对于执行细微任务效率不高，例如评估搜索相关性。因此，它可能倾向于过度自信，难以区分搜索引擎中使用的细粒度相关性（例如，强相关性、弱相关性、不相关性）。其次，当面对现实场景中的数据分布变化时，它表现出显着的性能下降。在本文中，我们提出了一种新颖的分布感知稳健学习框架（DaRL），用于支付宝搜索中的相关性建模。具体来说，我们设计了一个有效的损失函数来增强基于 LLM 的相关性建模在各种细粒度的查询项目相关性上的可辨别性。为了提高基于 LLM 的相关性建模的通用性，我们首先提出了分布感知样本增强（DASA）模块。该模块利用分布外（OOD）检测技术主动选择原始训练集未很好覆盖的适当样本进行模型微调。此外，我们采用多阶段微调策略来同时提高分布内（ID）和 OOD 性能，缩小它们之间的性能差距。DaRL 已在线部署，为支付宝的保险产品搜索提供服务……]]></description>
      <guid>https://arxiv.org/abs/2412.12504</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于短文本分类的标记级图</title>
      <link>https://arxiv.org/abs/2412.12754</link>
      <description><![CDATA[arXiv:2412.12754v1 公告类型：新
摘要：短文本分类是信息检索 (IR) 中的常见子任务。图形机器学习的最新进展引起了人们对资源匮乏场景的基于图形的方法的兴趣，并显示出在此类设置中的前景。然而，现有方法面临一些限制，例如不考虑相同单词的不同含义或来自传导方法的约束。我们提出了一种完全基于通过预训练语言模型 (PLM) 获得的标记构建文本图的方法。通过在创建图（-节点）时应用 PLM 对文本进行标记和嵌入，我们的方法可以捕获上下文和语义信息，克服词汇限制，并允许上下文相关的词义。与传统的 PLM 微调相比，我们的方法还使分类更有效，参数更少，从而使用少量样本进行更稳健的训练。实验结果表明，我们的方法如何始终如一地获得更高的分数或与现有方法相当的性能，代表了基于图形的文本分类技术的进步。为了支持我们工作的可重复性，我们将所有实现公开给社区\footnote{\url{https://github.com/doGregor/TokenGraph}}。]]></description>
      <guid>https://arxiv.org/abs/2412.12754</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>顺序推荐综述</title>
      <link>https://arxiv.org/abs/2412.12770</link>
      <description><![CDATA[arXiv:2412.12770v1 公告类型：新
摘要：与大多数传统推荐问题不同，顺序推荐侧重于通过利用交互项目之间的内部顺序和依赖关系来学习用户的偏好，这受到了研究人员和从业人员的极大关注。近年来，我们见证了该领域的巨大进步和成就，因此有必要进行新的调查。在本次调查中，我们从新的角度（即项目属性的构建）研究 SR 问题，并总结了顺序推荐中使用的最新技术，例如纯基于 ID 的 SR、带有辅助信息的 SR、多模态 SR、生成式 SR、LLM 驱动的 SR、超长 SR 和数据增强 SR。此外，我们介绍了顺序推荐中的一些前沿研究主题，例如开放域 SR、以数据为中心的 SR、云边缘协作 SR、连续 SR、SR for good 和可解释 SR。我们相信，我们的调查可以为该领域的读者提供宝贵的路线图。]]></description>
      <guid>https://arxiv.org/abs/2412.12770</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RemoteRAG：保护隐私的 LLM 云 RAG 服务</title>
      <link>https://arxiv.org/abs/2412.12775</link>
      <description><![CDATA[arXiv:2412.12775v1 公告类型：新
摘要：检索增强生成 (RAG) 通过从可信文献中检索相关文档并将其集成到用户查询的上下文中来提高大型语言模型的服务质量。最近，云 RAG 服务的兴起使得用户可以方便地查询相关文档。然而，直接将查询发送到云端会带来潜在的隐私泄露。在本文中，我们首次正式定义了隐私保护云 RAG 服务来保护用户查询，并提出了 RemoteRAG 作为隐私、效率和准确性的解决方案。对于隐私，我们引入了 $(n,\epsilon)$-DistanceDP 来表征用户查询的隐私泄露和从相关文档推断出的泄露。为了提高效率，我们将搜索范围从全部文档限制为与由 $(n,\epsilon)$-DistanceDP 生成的扰动嵌入相关的少数选定文档，这样隐私保护所需的计算和通信成本就会显著降低。为了提高准确性，我们通过详细的理论分析确保小范围包含与用户查询相关的目标文档。实验结果还表明，RemoteRAG 可以抵抗现有的嵌入反转攻击方法，同时在各种设置下实现无损失的检索。此外，RemoteRAG 非常高效，在从总共 $10^6$ 个文档中检索时仅需要 $0.67$ 秒和 $46.66$KB 的数据传输（使用未优化的隐私保护方案则需要 $2.72$ 小时和 $1.43$ GB）。]]></description>
      <guid>https://arxiv.org/abs/2412.12775</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于推荐学习的调查：基础知识、分类、评估和未解决的问题</title>
      <link>https://arxiv.org/abs/2412.12836</link>
      <description><![CDATA[arXiv:2412.12836v1 公告类型：新
摘要：推荐系统在塑造用户行为和决策方面具有越来越大的影响力，突显了它们在各个领域的影响力日益增强。同时，机器学习模型在推荐系统中的广泛采用引发了对用户隐私和安全的重大担忧。随着隐私法规的遵守变得越来越重要，迫切需要解决推荐反学习的问题，即从学习到的推荐模型中消除特定训练数据的记忆。尽管它很重要，但由于协作交互和模型参数带来的独特挑战，传统的机器反学习方法并不适合推荐反学习。本调查全面回顾了推荐反学习的最新进展，探讨了与这一新兴领域相关的设计原则、挑战和方法。我们提供了一个统一的分类法，对不同的推荐反学习方法进行分类，然后总结了广泛使用的基准和评估指标。通过回顾当前的研究状况，本综述旨在指导开发更高效、可扩展且更强大的推荐反学习技术。此外，我们还确定了该领域的开放性研究问题，这不仅可为推荐反学习的未来创新铺平道路，还可为不同机器学习应用中更广泛的反学习任务铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2412.12836</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AIR-Bench：自动异构信息检索基准</title>
      <link>https://arxiv.org/abs/2412.13102</link>
      <description><![CDATA[arXiv:2412.13102v2 公告类型：新 
摘要：评估在信息检索 (IR) 模型的进步中起着至关重要的作用。然而，当前的基准测试基于预定义域和人工标记的数据，在经济高效地满足新兴领域的评估需求方面面临限制。为了应对这一挑战，我们提出了自动异构信息检索基准 (AIR-Bench)。AIR-Bench 具有三个主要特点：1) 自动化。AIR-Bench 中的测试数据由大型语言模型 (LLM) 自动生成，无需人工干预。2) 异构。AIR-Bench 中的测试数据是针对不同的任务、领域和语言生成的。3) 动态。AIR-Bench 涵盖的领域和语言不断扩充，为社区开发者提供越来越全面的评估基准。我们开发了可靠且强大的数据生成管道，可根据真实语料库自动创建多样化且高质量的评估数据集。我们的研究结果表明，AIR-Bench 中生成的测试数据与人工标记的测试数据非常吻合，这使得 AIR-Bench 成为评估 IR 模型的可靠基准。AIR-Bench 中的资源可在 https://github.com/AIR-Bench/AIR-Bench 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2412.13102</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RAG Playground：RAG 系统中检索策略和提示工程的系统评估框架</title>
      <link>https://arxiv.org/abs/2412.12322</link>
      <description><![CDATA[arXiv:2412.12322v1 公告类型：交叉 
摘要：我们介绍了 RAG Playground，这是一个用于系统评估检索增强生成 (RAG) 系统的开源框架。该框架实现并比较了三种检索方法：朴素向量搜索、重新排序和混合向量关键字搜索，并结合使用不同提示策略的 ReAct 代理。我们引入了一个具有新指标的综合评估框架，并提供了在各种检索配置中比较不同语言模型 (Llama 3.1 和 Qwen 2.5) 的实证结果。我们的实验表明，通过混合搜索方法和结构化的自我评估提示，性能得到了显着提升，在我们的多指标评估框架上实现了高达 72.7% 的通过率。结果还强调了提示工程在 RAG 系统中的重要性，我们的自定义提示代理在检索准确性和响应质量方面表现出持续的改进。]]></description>
      <guid>https://arxiv.org/abs/2412.12322</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>细化维度以改进基于聚类的跨语言主题模型</title>
      <link>https://arxiv.org/abs/2412.12433</link>
      <description><![CDATA[arXiv:2412.12433v1 公告类型：交叉 
摘要：基于聚类的主题模型的最新研究通过引入管道来对上下文表示进行聚类，在单语主题识别方面表现良好。然而，由于多语言语言模型生成的语言相关维度 (LDD) 的存在，该管道在跨语言识别主题方面并不是最理想的。为了解决这个问题，我们在基于聚类的主题模型的管道中引入了一个新颖的基于 SVD 的维度细化组件。该组件有效地抵消了 LDD 的负面影响，使模型能够准确地识别跨语言的主题。我们在三个数据集上的实验表明，使用维度细化组件更新的管道通常优于其他最先进的跨语言主题模型。]]></description>
      <guid>https://arxiv.org/abs/2412.12433</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LITA：一种高效的 LLM 辅助迭代主题增强框架</title>
      <link>https://arxiv.org/abs/2412.12459</link>
      <description><![CDATA[arXiv:2412.12459v1 公告类型：交叉 
摘要：主题建模广泛用于揭示文本语料库中的主题结构，但传统模型在以领域为中心的应用中往往难以实现特异性和连贯性。引导方法（例如 SeededLDA 和 CorEx）结合了用户提供的种子词来提高相关性，但仍然是劳动密集型和静态的。大型语言模型 (LLM) 提供了动态主题细化和发现的潜力，但它们的应用通常会产生高昂的 API 成本。为了应对这些挑战，我们提出了 LLM 辅助迭代主题增强框架 (LITA)，这是一种 LLM 辅助方法，它将用户提供的种子与基于嵌入的聚类和迭代细化相结合。LITA 识别少量模棱两可的文档并使用 LLM 将它们重新分配给现有或新主题，从而最大限度地降低 API 成本，同时提高主题质量。在两个数据集上进行的关于主题质量和聚类性能指标的实验表明，LITA 的表现优于五种基线模型，包括 LDA、SeededLDA、CorEx、BERTopic 和 PromptTopic。我们的工作为推进主题建模和文本聚类提供了一个高效且适应性强的框架。]]></description>
      <guid>https://arxiv.org/abs/2412.12459</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过查询引导的激活重新填充来增强长上下文管理</title>
      <link>https://arxiv.org/abs/2412.12486</link>
      <description><![CDATA[arXiv:2412.12486v2 公告类型：交叉 
摘要：由于大型语言模型 (LLM) 固有的上下文窗口限制和大量键值 (KV) 激活的计算负担，处理长上下文对其提出了重大挑战，这严重影响了效率。对于信息搜索任务，完整的上下文感知通常是不必要的，因为查询的信息需求可以根据其复杂性从局部细节动态地扩展到全局视角。然而，现有的方法很难有效地适应这些动态信息需求。
在本文中，我们提出了一种通过查询引导的激活重新填充 (ACRE) 处理长上下文信息搜索任务的方法。ACRE 为长上下文构建了一个双层 KV 缓存，其中第 1 层 (L1) 缓存紧凑地捕获全局信息，第 2 层 (L2) 缓存提供详细和本地化信息。 ACRE 在两个缓存之间建立代理关系，允许输入查询关注 L1 缓存，并使用 L2 缓存中的相关条目动态地重新填充它。该机制将全局理解与查询特定的局部细节相结合，从而改善答案解码。在各种长上下文信息搜索数据集上的实验证明了 ACRE 的有效性，实现了性能和效率的提升。]]></description>
      <guid>https://arxiv.org/abs/2412.12486</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EXIT：用于增强检索增强生成的上下文感知提取压缩</title>
      <link>https://arxiv.org/abs/2412.12559</link>
      <description><![CDATA[arXiv:2412.12559v2 公告类型：交叉 
摘要：我们引入了 EXIT，这是一个提取上下文压缩框架，可提高问答 (QA) 中检索增强生成 (RAG) 的有效性和效率。当前的 RAG 系统在检索模型无法对最相关的文档进行排名时经常会遇到困难，从而导致以延迟和准确性为代价包含更多上下文。虽然抽象压缩方法可以大大减少标记数，但它们的逐个标记生成过程会显著增加端到端延迟。相反，现有的提取方法可以减少延迟，但依赖于独立的、非自适应的句子选择，无法充分利用上下文信息。EXIT 通过对检索到的文档中的句子进行分类来解决这些限制 - 同时保留它们的上下文依赖性 - 实现可并行的、上下文感知的提取，以适应查询复杂性和检索质量。我们对单跳和多跳 QA 任务的评估表明，EXIT 在 QA 准确率方面始终超越现有压缩方法，甚至超越未压缩基线，同时还大幅减少了推理时间和标记数量。通过提高有效性和效率，EXIT 为在 RAG 管道中开发可扩展、高质量的 QA 解决方案提供了一个有希望的方向。我们的代码可在 https://github.com/ThisIsHwang/EXIT 上找到]]></description>
      <guid>https://arxiv.org/abs/2412.12559</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SynthCypher：用于知识图谱中文本到密码查询的完全合成数据生成框架</title>
      <link>https://arxiv.org/abs/2412.12612</link>
      <description><![CDATA[arXiv:2412.12612v1 公告类型：交叉 
摘要：Cypher 是 Neo4j 图形数据库的查询语言，在实现基于图形的分析和数据探索方面发挥着关键作用。虽然已经有大量研究致力于自然语言到 SQL 查询生成 (Text2SQL)，但图形数据库的类似问题（称为 Text2Cypher）仍未得到充分探索。在这项工作中，我们介绍了 SynthCypher，这是一种完全合成和自动化的数据生成管道，旨在解决这一差距。SynthCypher 采用了一种新颖的 LLMSupervised 生成验证框架，确保跨不同领域和查询复杂性的 Cypher 查询在语法和语义上都是正确的。使用此管道，我们创建了 SynthCypher 数据集，这是一个包含 29.8k Text2Cypher 实例的大规模基准。在 SynthCypher 上对开源大型语言模型 (LLM)（包括 LLaMa-3.1-8B、Mistral-7B 和 QWEN-7B）进行微调，在 Text2Cypher 测试集上的性能显著提升了 40%，在针对图形数据库调整的 SPIDER 基准上的性能提升了 30%。这项工作表明，高质量的合成数据可以有效提升 Text2Cypher 任务的最新水平。]]></description>
      <guid>https://arxiv.org/abs/2412.12612</guid>
      <pubDate>Wed, 18 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>