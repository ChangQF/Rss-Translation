<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 06 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>推荐系统中多任务学习的成对排名损失</title>
      <link>https://arxiv.org/abs/2406.02163</link>
      <description><![CDATA[arXiv:2406.02163v2 公告类型：替换 
摘要：多任务学习 (MTL) 在推荐系统等现实世界的广告应用中起着至关重要的作用，旨在实现稳健的表示，同时最大限度地减少资源消耗。MTL 致力于同时优化多个任务以构建服务于不同目标的统一模型。在在线广告系统中，点击率 (CTR) 和转化率 (CVR) 等任务通常同时被视为 MTL 问题。然而，人们忽视了转化 ($y_{cvr}=1$) 需要先前的点击 ($y_{ctr}=1$)。换句话说，虽然某些 CTR 任务与相应的转化相关联，但其他任务缺乏这种关联。此外，与发生转化的 CTR 任务相比，没有发生转化的 CTR 任务中出现噪声的可能性明显更高，现有方法缺乏区分这两种情况的能力。在本研究中，将与转化相对应的曝光标签视为确定性指标，并通过计算模型预测之间的 \textbf{p}air\textbf{wise} \textbf{r}anking (PWiseR) 损失（表现为成对排名损失）引入了一种新的任务特定损失，以鼓励模型更多地依赖它们。为了证明所提出的损失函数的效果，使用四个不同的公共 MTL 数据集（即阿里巴巴 FR、NL、US 和 CCP）以及专有工业数据集对不同的 MTL 和单任务学习 (STL) 模型进行了实验。结果表明，就 AUC 指标而言，我们提出的损失函数在大多数情况下优于 BCE 损失函数。]]></description>
      <guid>https://arxiv.org/abs/2406.02163</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>CoopHash：通过变分 MCMC 教学进行多用途描述符和对比对生成器的协作学习，用于监督图像哈希处理</title>
      <link>https://arxiv.org/abs/2210.04288</link>
      <description><![CDATA[arXiv:2210.04288v3 公告类型：replace-cross 
摘要：利用监督信息可以在图像哈希领域获得卓越的检索性能，但如果没有足够的标记数据，性能会显著下降。提高性能的一个有效解决方案是采用生成模型，例如生成对抗网络 (GAN)，在图像哈希模型中生成合成数据。然而，基于 GAN 的方法很难训练，这阻止了哈希方法联合训练生成模型和哈希函数。这种限制导致检索性能不理想。为了克服这个限制，我们提出了一个基于能量的合作学习的新型框架，即生成合作哈希网络。该框架通过两个组件联合学习强大的数据生成表示和稳健的哈希函数：自上而下的对比对生成器，用于合成对比图像；自下而上的多用途描述符，用于同时从多个角度表示图像，包括概率密度、哈希码、潜在代码和类别。这两个组件通过一种新颖的基于可能性的合作学习方案联合学习。我们在几个真实数据集上进行了实验，结果表明，所提出的方法优于竞争的哈希监督方法，与目前最先进的监督哈希方法相比，相对改进高达 10\%，并且在分布外检索中表现出明显更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2210.04288</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:53 GMT</pubDate>
    </item>
    <item>
      <title>将狄德罗的 \textit{Encyclop\'edie} 中的命名实体链接到 Wikidata</title>
      <link>https://arxiv.org/abs/2406.03221</link>
      <description><![CDATA[arXiv:2406.03221v1 公告类型：交叉 
摘要：狄德罗的《\textit{Encyclop\&#39;edie}》是一部 18 世纪欧洲参考书，旨在收集那个时代的知识。\textit{Wikipedia} 有着同样的抱负，但范围要大得多。然而，这两部百科全书之间缺乏数字联系，这可能会阻碍对它们的比较以及对知识如何演变的研究。\textit{Wikipedia} 的一个关键元素是 Wikidata，它使用结构化数据图支持文章。在本文中，我们描述了 10,300 多个 \textit{Encyclop\&#39;edie} 条目的注释，并使用 Wikidata 标识符使我们能够将这些条目连接到图表。我们考虑了地理和人类实体。\textit{Encyclop\&#39;edie} 不包含传记条目，因为它们大多作为位置的子条目出现。我们提取了所有地理条目，并完整注释了所有包含人类实体描述的条目。这代表了超过 2,600 个指向位置或人类实体的链接。此外，我们还注释了超过 9,500 个仅包含地理内容的条目。我们描述了注释过程以及应用示例。此资源可在 https://github.com/pnugues/encyclopedie_1751 上找到]]></description>
      <guid>https://arxiv.org/abs/2406.03221</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>推荐可解释性的可视化：调查与新视角</title>
      <link>https://arxiv.org/abs/2305.11755</link>
      <description><![CDATA[arXiv:2305.11755v3 公告类型：替换 
摘要：为推荐提供系统生成的解释是迈向透明和可信推荐系统的重要一步。可解释的推荐系统为其输出提供了人类可理解的理由。在过去的二十年里，可解释的推荐引起了推荐系统研究界的广泛关注。本文旨在全面回顾推荐系统中视觉解释的研究成果。更具体地说，我们系统地回顾了基于四个维度的推荐系统中解释的文献，即解释目标、解释范围、解释风格和解释格式。认识到可视化的重要性，我们从解释可视化的角度来研究推荐系统文献，即将可视化用作解释的显示风格。因此，我们得出了一套可能对设计推荐系统中的解释可视化具有建设性的指导方针，并确定了未来该领域工作的前景。本评论的目的是帮助推荐研究人员和从业者更好地理解视觉可解释的推荐研究的潜力，并支持他们在当前和未来的推荐系统中系统地设计视觉解释。]]></description>
      <guid>https://arxiv.org/abs/2305.11755</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>面向开放世界跨领域序列推荐：一种与模型无关的对比去噪方法</title>
      <link>https://arxiv.org/abs/2311.04760</link>
      <description><![CDATA[arXiv:2311.04760v3 Announce Type: replace 
摘要：跨域顺序推荐（CDSR）旨在解决传统顺序推荐（SR）系统中存在的数据稀疏问题。
现有方法旨在设计一个特定的跨域单元，该单元可以依靠行为丰富的重叠用户在多个域之间传输和传播信息。然而，在现实世界的推荐系统中，CDSR场景通常由大多数行为稀疏的长尾用户和仅存在于一个域的冷启动用户组成。这导致现有CDSR方法在现实世界行业平台中的性能下降。因此，提高开放世界CDSR场景中模型的一致性和有效性对于构建CDSR模型（\textit{1st} CH）至关重要。最近，一些SR方法利用辅助行为来补充长尾用户的信息。然而，这些多行为 SR 方法无法在 CDSR 中提供令人满意的性能，因为它们忽视了目标和辅助行为之间的语义差距，以及跨领域的用户兴趣偏差（\textit{2nd} CH）。]]></description>
      <guid>https://arxiv.org/abs/2311.04760</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:52 GMT</pubDate>
    </item>
    <item>
      <title>Docs2KG：大型语言模型辅助异构文档的统一知识图谱构建</title>
      <link>https://arxiv.org/abs/2406.02962</link>
      <description><![CDATA[arXiv:2406.02962v1 公告类型：交叉
摘要：即使保守估计，80% 的企业数据也驻留在非结构化文件中，存储在可容纳异构格式的数据湖中。传统搜索引擎已无法满足信息搜索需求，尤其是当任务是浏览和探索以形成洞察力时。换句话说，没有明显的搜索关键字可用。知识图谱由于其自然的视觉吸引力可以减轻人类的认知负荷，成为异构数据集成和知识表示的最佳候选者。
在本文中，我们介绍了 Docs2KG，这是一种新颖的框架，旨在从多样化和异构的非结构化文档（包括电子邮件、网页、PDF 文件和 Excel 文件）中提取多模态信息。Docs2KG 动态生成表示提取的关键信息的统一知识图谱，可实现对文档数据湖的高效查询和探索。与专注于特定领域数据源或预先设计的模式的现有方法不同，Docs2KG 提供了一种灵活且可扩展的解决方案，可以适应各种文档结构和内容类型。所提出的框架统一了支持大量下游任务的数据处理，并提高了领域可解释性。Docs2KG 可在 https://docs2kg.ai4wa.com 上公开访问，演示视频可在 https://docs2kg.ai4wa.com/Video 上观看。]]></description>
      <guid>https://arxiv.org/abs/2406.02962</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>用于公平意识认知诊断的路径特定因果推理</title>
      <link>https://arxiv.org/abs/2406.03064</link>
      <description><![CDATA[arXiv:2406.03064v1 公告类型：交叉 
摘要：认知诊断（CD）是智能教育的基本组成部分之一，它利用学生和练习数据来预测学生对不同知识概念的熟练程度。由于学生与练习交互数据的稀缺，大多数现有方法都侧重于充分利用可用数据，例如练习内容和学生信息（例如教育背景）。尽管取得了很大进展，但学生敏感信息的滥用尚未引起足够的重视。由于CD在智能教育中的重要地位，在进行诊断预测时使用敏感信息将导致严重的社会问题。此外，数据驱动的神经网络很容易被输入数据和输出预测之间的捷径误导，从而加剧了这一问题。因此，消除敏感信息在CD模型中的负面影响至关重要。对此，我们认为学生的敏感属性也可以提供有用的信息，只有与敏感信息直接相关的捷径才应该从诊断过程中消除。因此，我们采用因果推理并设计了一种新颖的路径特定因果推理框架 (PSCRF) 来实现这一目标。具体来说，我们首先利用编码器提取特征并生成学生一般信息和敏感信息的嵌入。然后，我们设计了一种新颖的面向属性的预测器来解耦敏感属性，其中与公平性相关的敏感特征将被消除而其他有用信息将被保留。最后，我们设计了一个多因素约束来同时确保公平性和诊断性能。在现实世界数据集（例如 PISA 数据集）上进行的大量实验证明了我们提出的 PSCRF 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.03064</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>探索面向大型语言模型的用户检索集成以实现跨领域序列推荐</title>
      <link>https://arxiv.org/abs/2406.03085</link>
      <description><![CDATA[arXiv:2406.03085v1 公告类型：交叉 
摘要：跨域顺序推荐（CDSR）旨在挖掘和传输不同域中用户的顺序偏好，以缓解长期存在的冷启动问题。传统的 CDSR 模型通过用户和项目建模捕获协作信息，同时忽略了有价值的语义信息。最近，大型语言模型（LLM）展示了强大的语义推理能力，促使我们引入它们以更好地捕获语义信息。然而，将 LLM 引入 CDSR 并非易事，因为有两个关键问题：无缝信息集成和特定领域的生成。为此，我们提出了一个名为 URLLM 的新框架，旨在通过同时探索用户检索方法和 LLM 上的领域基础来提高 CDSR 性能。具体来说，我们首先提出一种新颖的双图顺序模型来捕获多样化的信息，以及一种对齐和对比学习方法来促进领域知识的转移。随后，采用用户检索生成模型将结构信息无缝集成到 LLM 中，充分利用其新兴的推理能力。此外，我们提出了一种特定于领域的策略和一个细化模块来防止域外生成。与最先进的基线相比，在亚马逊上进行的大量实验证明了 URLLM 的信息集成和特定于领域的生成能力。我们的代码可在 https://github.com/TingJShen/URLLM 上找到]]></description>
      <guid>https://arxiv.org/abs/2406.03085</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:51 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐的大型语言模型中的协作信息文本编码</title>
      <link>https://arxiv.org/abs/2406.03210</link>
      <description><![CDATA[arXiv:2406.03210v1 公告类型：新
摘要：在调整大型语言模型以用于推荐 (LLMRec) 时，整合协作信息至关重要。现有方法通过从头开始学习 LLM 潜在空间中的协作嵌入或通过从外部模型映射来实现这一点。但是，它们无法以文本格式表示信息，这可能与 LLM 不太一致。为了弥补这一差距，我们引入了 BinLLM，这是一种新颖的 LLMRec 方法，可通过文本编码无缝集成协作信息。BinLLM 将来自外部模型的协作嵌入转换为二进制序列——一种 LLM 可以理解和直接操作的特定文本格式，方便 LLM 直接使用文本格式的协作信息。此外，BinLLM 提供了使用点分十进制表示法压缩二进制序列的选项，以避免长度过长。大量实验验证了 BinLLM 以与 LLM 更一致的方式引入协作信息，从而提高了性能。我们在https://github.com/zyang1580/BinLLM 发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2406.03210</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:50 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为推荐解释的评估者</title>
      <link>https://arxiv.org/abs/2406.03248</link>
      <description><![CDATA[arXiv:2406.03248v2 公告类型：新
摘要：推荐系统的可解释性引起了学术界和工业界的极大关注。人们为可解释的推荐做出了许多努力，但评估解释的质量仍然是一个具有挑战性且尚未解决的问题。近年来，利用 LLM 作为评估者为自然语言处理任务（例如情绪分类、信息提取）提供了一条有希望的途径，因为它们在指令遵循和常识推理方面表现出强大的能力。然而，评估推荐解释文本与这些 NLG 任务不同，因为它的标准与人类感知有关，通常是主观的。在本文中，我们研究了 LLM 是否可以作为推荐解释的评估者。为了回答这个问题，我们利用了以前工作中给出的解释的真实用户反馈，并另外收集了第三方注释和 LLM 评估。我们设计并应用了一个 3 级元评估策略来衡量评估者标签与用户提供的基本事实之间的相关性。我们的实验表明，在适当的提示和设置下，LLM（例如 GPT4）可以提供类似的评估。我们还提供了进一步的见解，将人工标签与 LLM 评估过程相结合，并利用多个异构 LLM 评估器的集合来提高评估的准确性和稳定性。我们的研究证实，使用 LLM 作为评估器可以成为评估推荐解释文本的准确、可重复且经济高效的解决方案。我们的代码可在 https://github.com/Xiaoyu-SZ/LLMasEvaluator 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.03248</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:50 GMT</pubDate>
    </item>
    <item>
      <title>了解你的邻居：由 Call Graphlets 提供支持的通用和零样本二元函数搜索</title>
      <link>https://arxiv.org/abs/2406.02606</link>
      <description><![CDATA[arXiv:2406.02606v1 公告类型：交叉 
摘要：二进制代码相似性检测是恶意软件分析、漏洞研究和抄袭检测等领域应用的一个重要问题。本文提出了一种新型图神经网络架构，结合一种称为调用图元的新型图数据表示。调用图元对二进制可执行文件中每个函数周围的邻域进行编码，通过一系列统计特征捕获局部和全局上下文。然后设计一个专门的图神经网络模型来操作这个图表示，学习将其映射到使用深度度量学习对语义代码相似性进行编码的特征向量。所提出的方法在四个不同的数据集上进行了评估，涵盖了不同的架构、编译器工具链和优化级别。实验结果表明，与跨架构、单架构和零样本任务中的基线技术相比，调用图元和新型图神经网络架构的组合实现了最先进的性能。此外，我们提出的方法在针对域外函数内联任务进行评估时也表现良好。总的来说，该工作为进行二进制代码相似性检测提供了一种通用且有效的基于图神经网络的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2406.02606</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:50 GMT</pubDate>
    </item>
    <item>
      <title>用于快速相似性搜索的双度量框架</title>
      <link>https://arxiv.org/abs/2406.02891</link>
      <description><![CDATA[arXiv:2406.02891v1 公告类型：新
摘要：我们提出了一种用于设计最近邻数据结构的新“双度量”框架。我们的框架假设两个差异函数：一个准确但计算成本高昂的地面实况度量，以及一个更便宜但不太准确的代理度量。在理论和实践中，我们都展示了如何仅使用代理度量来构建数据结构，使得查询过程达到昂贵度量的准确性，同时仅使用有限数量的两个度量调用。我们的理论结果为两种流行的最近邻搜索算法实例化了这个框架：DiskANN 和 Cover Tree。在这两种情况下，我们都表明，只要用于构建数据结构的代理度量在有界因子范围内近似地面实况度量，我们的数据结构就可以实现相对于地面实况度量的任意好的近似保证。在实证方面，我们将该框架应用于文本检索问题，该问题由计算成本相差很大的 ML 模型评估两个相异函数。我们观察到，对于 MTEB 基准中的几乎所有数据集，我们的方法都比重新排序等替代方案实现了更好的准确率-效率权衡。]]></description>
      <guid>https://arxiv.org/abs/2406.02891</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:49 GMT</pubDate>
    </item>
    <item>
      <title>面向任务的查询基准（ToQB）</title>
      <link>https://arxiv.org/abs/2406.02943</link>
      <description><![CDATA[arXiv:2406.02943v1 公告类型：新
摘要：面向任务的查询（例如，播放视频、订购食物或叫出租车的一次性查询）对于评估虚拟助手、聊天机器人和其他基于大型语言模型 (LLM) 的服务的质量至关重要。但是，面向任务的查询的标准基准尚未可用，因为相关 NLP（自然语言处理）领域的现有基准主要集中在面向任务的对话上。因此，我们提出了一种新方法，用于使用现有的面向任务的对话数据集和 LLM 服务有效地生成面向任务的查询基准 (ToQB)。我们的方法包括制定底层 NLP 任务以总结每次对话中说话者的原始意图，详细说明使用 LLM 服务执行设计的 NLP 任务的关键步骤，并概述用于自动化基准生成过程主要部分的框架。通过涵盖三个领域（即两个单任务领域和一个多任务领域）的案例研究，我们展示了如何为这三个领域定制 LLM 提示（例如，省略系统话语或说话者标签）并描述生成的面向任务的查询。生成的 ToQB 数据集已向公众开放。我们进一步讨论了社区贡献者可以添加到 ToQB 的新领域及其实际应用。]]></description>
      <guid>https://arxiv.org/abs/2406.02943</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:49 GMT</pubDate>
    </item>
    <item>
      <title>CAPRI-FAIR：情境 POI 推荐框架中多边公平性的集成</title>
      <link>https://arxiv.org/abs/2406.03109</link>
      <description><![CDATA[arXiv:2406.03109v1 公告类型：新
摘要：兴趣点 (POI) 推荐是一种情境感知推荐，它考虑了时空约束和情境，例如距离、高峰营业时间和以前的用户签到。鉴于这类系统不仅能够影响消费者的旅行体验，还能够影响 POI 的业务，因此从多个角度考虑公平性非常重要。不幸的是，这些系统往往向不活跃的用户提供不太准确的推荐，并且较少向不受欢迎的 POI 提供曝光。本文的目标是开发一种后过滤方法，将提供商和消费者公平因素纳入预先存在的推荐模型中，以满足公平性指标（如项目曝光度）和性能指标（如精度和距离），使系统对消费者和提供商都更具可持续性。实验表明，在重新评分推荐项目时使用提供商公平性的线性评分模型可以在性能和长尾曝光度之间取得最佳平衡，在某些情况下不会显着降低精度。当尝试通过向不活跃用户推荐更受欢迎的 POI 来解决消费者公平性问题时，结果只有部分推荐模型和数据集的准确率有所提高。最后，当考虑两个参数之间的权衡时，不幸的是，达到消费者和提供商公平性帕累托前沿的组合实现了最低的准确率值。我们发现这种权衡的性质在很大程度上取决于模型和数据集。]]></description>
      <guid>https://arxiv.org/abs/2406.03109</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:49 GMT</pubDate>
    </item>
    <item>
      <title>用于对话推荐的项目语言模型</title>
      <link>https://arxiv.org/abs/2406.02844</link>
      <description><![CDATA[arXiv:2406.02844v1 公告类型：新
摘要：大型语言模型 (LLM) 因其新兴能力而在复杂对话理解、推理和编码等任务上取得了巨大成功。这些新兴能力已通过多模态扩展，包括图像、音频和视频功能。另一方面，推荐系统对于信息搜索和项目发现需求至关重要。最近，有人尝试将 LLM 应用于推荐。当前尝试的一个困难是底层 LLM 通常不在推荐系统数据上进行训练，推荐系统数据主要包含用户交互信号并且通常不公开。另一个困难是用户交互信号通常与自然语言文本具有不同的模式，目前尚不清楚与传统推荐系统方法相比，LLM 训练设置是否可以从交互信号中学习更多非平凡知识。最后，很难为不同的用例训练多个 LLM，并且在从推荐系统数据中学习时保留原始语言和推理能力。为了解决这三个限制，我们提出了一个项目语言模型 (ILM)，它由一个项目编码器和一个冻结的 LLM 组成，前者用于生成对用户交互信号进行编码的文本对齐项目表示，后者可以使用保留的预训练知识来理解这些项目表示。我们进行了广泛的实验，证明了语言对齐和用户交互知识在项目编码器中的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.02844</guid>
      <pubDate>Fri, 07 Jun 2024 03:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>