<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Mon, 17 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于LLM的新闻推荐系统的调查</title>
      <link>https://arxiv.org/abs/2502.09797</link>
      <description><![CDATA[ARXIV：2502.09797V1公告类型：新 
摘要：新闻推荐系统在减轻信息过载问题方面起着至关重要的作用。近年来，由于大语言模型技术的成功应用，研究人员使用了歧视性的大语言模型（DLLM）或生成性大语言模型（GLLMS）来提高新闻推荐系统的性能。尽管最近的几项调查审查了对基于深度学习的新闻推荐系统（例如公平，保护隐私和责任）的重大挑战，但缺乏对基于大语言模型（LLM）基于基于的新闻新闻推荐系统的系统调查。为了审查不同的核心方法并系统地探索潜在问题，我们根据基于LLM的新闻推荐系统的伞将基于DLLM和基于GLLM的新闻推荐系统分类。在这项调查中，我们首先概述了基于深度学习的新闻推荐系统的开发。然后，我们根据三个方面回顾了基于LLM的新闻推荐系统：面向新闻的建模，面向用户的建模和面向预测的建模。接下来，我们从各个角度研究了挑战，包括数据集，基准测试工具和方法论。此外，我们进行了广泛的实验，以分析大型语言模型技术如何影响不同新闻推荐系统的性能。最后，我们全面探讨了LLM时代基于LLM的新闻建议的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2502.09797</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>焊工弧的数据和决策可追溯性</title>
      <link>https://arxiv.org/abs/2502.09827</link>
      <description><![CDATA[ARXIV：2502.09827V1公告类型：新 
摘要：太空协议将摘自MITER和NIST的供应链可追溯性得出的原则：制造元框架（NIST IR 8536）到一个复杂的多方系统中，以实现内省，审计和重播数据和决策，最终导致最终导致结局决定。决策可追溯性的核心目标是确保WA系统内的透明度，问责制和诚信。这是通过从系统的输入一直到最终决定的清晰，可审核的路径来完成的。这种可追溯性使系统能够跟踪影响特定结果的各种算法和数据流。]]></description>
      <guid>https://arxiv.org/abs/2502.09827</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的大型推荐模型：迈向一项最佳的规模法律</title>
      <link>https://arxiv.org/abs/2502.09888</link>
      <description><![CDATA[ARXIV：2502.09888V1公告类型：新 
摘要：对扩展建议模型的追求会面临扩展模型容量和保持计算障碍性之间的内在张力。虽然先前的研究探讨了推荐系统的规模法律，但对于大多数工业应用，其资源密集型范式通常需要数以万计的A100 GPU小时。这项工作解决了一个关键的差距：在严格的计算预算下实现可持续模型缩放。我们提出了登山者，这是一个资源有效的推荐框架，其中包括两个协同组件：用于算法创新的Astro模型体系结构和用于工程优化的涡轮加速框架。 Astro（适应性伸缩变压器用于推荐）采用了两种核心创新：（1）多尺度序列分区，可通过层次块从O（N^2D）降低到O（N^2D）到O（N^2D/NB），通过层次块，通过更有效的缩放来缩放序列长度； （2）动态温度调制，可自适应地调整由固有多模式分布的注意力评分，该分布由固有的多scenario和多行为相互作用引起。登山者在没有绩效降级的情况下，辅以涡轮（两阶段的统一排名和批处理输出），这是一个共同设计的加速框架，集成了梯度感知功能压缩和记忆效率高的键值缓存。多个数据集上的全面离线实验验证了登山者表现出更理想的缩放曲线。据我们所知，这是第一个公开记录的框架，其中受控的模型缩放驱动了连续的在线度量增长（总升降机为12.19％），而没有资源成本过高。登山者已成功部署在中国最大的音乐流媒体平台之一的Netase Cloud Music上，每天为数千万用户提供服务。]]></description>
      <guid>https://arxiv.org/abs/2502.09888</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Archrag：基于社区的基于社区的分层检索生成一代</title>
      <link>https://arxiv.org/abs/2502.09891</link>
      <description><![CDATA[ARXIV：2502.09891V1公告类型：新 
摘要：被证明是在将外部知识集成到大型语言模型（LLMS）中，以解决问题 - 答案（QA）任务有效。最先进的抹布方法通常使用图形数据作为外部数据，因为它们捕获了丰富的语义信息和链接实体之间的关系。但是，现有的基于图的抹布方法无法准确地从图中识别相关信息，也无法在在线检索过程中消耗大量令牌。为了解决这些问题，我们引入了一种基于图形的新型抹布方法，称为属性基于社区的分层抹布（ArchRag），通过使用属性社区来增强问题，并引入一种基于LLM的新型基于LLM的层次结构聚类方法。为了从图中检索最相关的信息以获取该问题，我们为归因社区构建了一种新颖的分层索引结构，并开发了有效的在线检索方法。实验结果表明，根据准确性和代币成本，Archrag优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.09891</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对推荐系统的LLM驱动代理的调查</title>
      <link>https://arxiv.org/abs/2502.10050</link>
      <description><![CDATA[ARXIV：2502.10050V1公告类型：新 
摘要：推荐系统是许多在线平台的重要组成部分，但是传统方法仍然在理解复杂的用户偏好并提供可解释的建议方面难以进行。大语言模型（LLM）的出现通过实现自然语言相互作用和可解释的推理，有可能改变推荐系统中的研究，从而提供了一种有希望的方法。这项调查对LLM驱动代理在推荐系统中的新兴应用进行了系统的综述。我们在当前研究中识别和分析了三个关键范式：（1）推荐的方法，这些方法利用智能代理来增强基本建议机制； （2）面向互动的方法，通过自然对话和可解释的建议促进动态用户参与； （3）面向仿真的方法，这些方法采用多代理框架来建模复杂的用户交互和系统动态。除了范式分类之外，我们还分析了LLM驱动推荐代理的建筑基础，研究其基本组件：个人资料构建，内存管理，战略计划和行动执行。我们的调查扩展到了该领域基准数据集和评估框架的全面分析。这项系统的检查不仅阐明了LLM驱动的代理推荐系统的当前状态，而且还列出了这个变革性领域的关键挑战和有希望的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2502.10050</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Semantica：使用LLM指导的语义树覆盖层的分散搜索</title>
      <link>https://arxiv.org/abs/2502.10151</link>
      <description><![CDATA[ARXIV：2502.10151V1公告类型：新 
摘要：集中式搜索引擎是互联网的关键，但导致了不良的力量集中。分散的替代方案无法提供平等的文件检索准确性和速度。但是，当正确捕获文档的语义时，语义覆盖网络可能接近集中解决方案的性能。这项工作使用大型语言模型的嵌入方式来捕获语义并实现语义叠加网络的承诺。我们提出的称为Semantica的算法构建了一个使用语言模型计算的文档嵌入的前缀树（TRIE）。用户根据文档的嵌入方式相互连接，以确保直接链接语义上相似的用户。因此，这种构造使用户更有可能由他们直接连接到网络连接图中的用户或用户接近的用户来回答用户搜索。我们的算法的实现还可以通过在树上产生“克隆”用户标识符来适应单个用户的语义多样性。我们的实验使用仿真和现实世界的工作负载，以显示Semantica快速识别并连接到类似用户的能力。 Semantica的语义用户比当前的最新方法高出十倍。同时，Semantica可以检索相同的网络负载的相关文档数量的两倍以上。我们还公开使用代码，以促进该地区的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2502.10151</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SessionRec：下一个会话预测范例，用于生成顺序建议</title>
      <link>https://arxiv.org/abs/2502.10157</link>
      <description><![CDATA[ARXIV：2502.10157V1公告类型：新 
摘要：我们介绍了SessionRec，这是一种新型的下一会议预测范式（NSPP），以解决生成的顺序建议，以解决传统的下一步预测范式（NIPP）和现实世界建议方案之间的基本错位。与Nipp的项目级自回归生成不同，与实际的基于会话的用户交互相矛盾，我们的框架通过层次序列聚集（Intra/Interra）介绍了会话感知表示的表示学习，从而降低了注意力计算的复杂性，同时启用了大规模负面互动的隐式建模，以及一个基于会话的预测目标，可以通过下一届会议中的多项目推荐更好地捕捉用户的多元化兴趣。此外，我们发现，在下一个会话预测范式下，在会话中纳入项目的排名损失可以显着提高生成序列建议模型的排名有效性。我们还验证了SessionREC表现出与LLMS中观察到的明确的大法缩放定律。在Meituan应用程序中在公共数据集和在线A/B测试上进行的广泛实验证明了SessionRec的有效性。拟议的范式通过其模型 - 静态架构和计算效率为开发工业规模的生成推荐系统建立了新的基础。]]></description>
      <guid>https://arxiv.org/abs/2502.10157</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线推荐系统的混合跨阶段协调预制模型</title>
      <link>https://arxiv.org/abs/2502.10284</link>
      <description><![CDATA[ARXIV：2502.10284V1公告类型：新 
摘要：大规模推荐系统通常采用层层结构，包括检索，预先排名，排名和重新排列阶段。凭着严格的延迟要求，预先级别使用轻量级模型来从大量检索的候选人中进行初步选择。但是，最近的著作仅着重于提高排名的一致性，仅依赖于下游阶段。由于下游输入是从预先排名的输出中得出的，因此它们将加剧样本选择偏置（SSB）问题和MATTHEW效应，从而导致次优结果。为了解决限制，我们提出了一种新型混合跨阶段预处理模型（HCCP），以整合来自上游（检索）和下游（排名，重新排列）阶段的信息。具体而言，跨阶段的协调是指预先级别对整个流的适应性，以及作为上游和下游之间更有效桥梁的作用。 HCCP包括混合样品构建和混合客观优化。混合样品构造从整个流中捕获了多级未暴露数据，并重新排列它们，成为预先学习的最佳指导“地面真相”。混合客观优化包含一致性和长尾精度的联合优化，我们提出的保证金信息损失。它是专门设计的，旨在从此类混合未暴露的样品中学习，改善整体性能并减轻SSB问题。附录描述了拟议损失在选择潜在阳性方面的功效的证明。广泛的离线和在线实验表明，HCCP通过改善跨阶段协调来优于SOTA方法。在JD电子商务推荐系统中，它贡献了高达14.9％的UCVR和1.3％的UCTR。关于代码隐私，我们提供了一个伪代码供参考。]]></description>
      <guid>https://arxiv.org/abs/2502.10284</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在双面平台中使用推荐系统的优先排名实验设计</title>
      <link>https://arxiv.org/abs/2502.09806</link>
      <description><![CDATA[ARXIV：2502.09806V1公告类型：交叉 
摘要：在线双面市场中单位之间的相互依赖性使实验环境中的因果效应复杂化。我们提出了一种新型的实验设计，以减轻在线双面市场中项目侧干预措施的总平均治疗效果（TATE）时的干扰偏差。我们的双面优先排名（TSPR）设计使用推荐系统作为实验工具。 TSPR根据其在向用户显示的列表中的治疗状态进行战略性优先级。我们设计了TSPR，为用户提供一致的平台体验，通过确保访问所有项目并始终如一地实现所有用户的治疗方法。我们使用在线旅行社的搜索印象数据集通过模拟来评估我们的实验设计。我们的方法可以密切估计真正的模拟泰特，而基线项目端估计器显着高估了泰特。]]></description>
      <guid>https://arxiv.org/abs/2502.09806</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kggen：用语言模型从纯文本中提取知识图</title>
      <link>https://arxiv.org/abs/2502.09956</link>
      <description><![CDATA[ARXIV：2502.09956V1公告类型：交叉 
摘要：最近对KGS建立基础模型的兴趣强调了一个基本挑战：知识图数据相对稀缺。最著名的kg主要是人类标记，是通过图案匹配创建的，或使用早期NLP技术提取。尽管人类生成的公斤供应不足，但自动提取的kg质量值得怀疑。我们以文本到千克生成器（KGGEN）的形式提出了这种数据稀缺问题的解决方案，该软件包使用语言模型从专门文本创建高质量的图形。与其他KG提取器不同，KGGEN簇相关的实体可减少提取的kg中的稀疏性。 Kggen可作为python库（\ texttt {pip install kg-gen}）提供，使每个人都可以使用。与Kggen一起，我们释放了第一个基准测试，即节点和边缘（矿山）中信息的度量，以测试提取器从纯文本中产生有用的kg的能力。我们对现有提取器进行基准测试我们的新工具，并表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.09956</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Proreco：过程发现建议系统</title>
      <link>https://arxiv.org/abs/2502.10230</link>
      <description><![CDATA[ARXIV：2502.10230V1公告类型：交叉 
摘要：过程发现旨在自动从历史执行数据（事件日志）中得出过程模型。尽管在过去25年中已经提出了各种过程发现算法，但在主导的发现算法上尚未达成共识。选择最合适的发现算法仍然是一个挑战，这是由于竞争质量措施和不同的用户要求。手动从给定事件日志的一系列选项中手动选择最合适的过程发现算法是一项耗时且容易出错的任务。本文介绍了Proreco，Proreco是一种过程发现建议系统，旨在根据用户偏好和事件日志特征推荐最合适的算法。 Proreco结合了最先进的发现算法，扩展了以前工作的特征池，并利用可解释的AI（XAI）技术来为其建议提供解释。]]></description>
      <guid>https://arxiv.org/abs/2502.10230</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>广告中的中间人偏见：将键形建议的相关性与搜索保持一致</title>
      <link>https://arxiv.org/abs/2502.00131</link>
      <description><![CDATA[ARXIV：2502.00131V2公告类型：替换 
摘要：根据他们的库存，推荐电子商务销售商在其上进行广告以增加买方参与度（点击/销售）。键形必须与项目相关；否则，它可能会导致卖方不满和目标差 - 采用过滤器。在这项工作中，我们描述了培训相关过滤器模型的缺点，这些模型在偏见的点击/销售信号上。我们将广告商键形相关性重新概念化为两个动态系统之间的互动 - 广告会产生键形和搜索，这些键形和搜索是一个中间人，可以吸引买家。我们讨论了搜索相关系统（中间人偏见）的偏见，以及需要使广告客户键形和搜索相关性信号相结合。我们还比较了跨编码器和双重编码器在建模这种比对的性能以及在eBay卖方的这种解决方案的可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2502.00131</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>2021年东京奥运会多语言新闻文章数据集</title>
      <link>https://arxiv.org/abs/2502.06648</link>
      <description><![CDATA[ARXIV：2502.06648V2公告类型：替换 
摘要：在本文中，我们介绍了涵盖2021年东京奥运会的多语言新闻文章的数据集。从1,918家不同的出版商那里收集了10,940篇新闻报道，涵盖了2021年奥运会的1,350次次级活动，并在2021年7月1日至2021年8月14日之间发表。这些文章以不同语言家庭和不同语言家庭以及不同语言家庭以及不同语言的语言和不同的脚本。为了创建数据集，首先通过收集和分析新闻文章的服务检索了原始新闻文章。然后，使用在线聚类算法对文章进行分组，每个组包含有关同一子事件的文章。最后，对小组进行了手动注释和评估。该数据集的开发旨在提供评估多语言新闻集群算法的性能的资源，为此提供有限的数据集。它还可以用来从不同的角度分析2021年东京奥运会的动态和事件。该数据集以CSV格式提供，可以从Clarin.si存储库中访问。]]></description>
      <guid>https://arxiv.org/abs/2502.06648</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChoruscVr：整个空间点击转换率建模的合唱监督</title>
      <link>https://arxiv.org/abs/2502.08277</link>
      <description><![CDATA[ARXIV：2502.08277V2公告类型：替换 
摘要：点击转换率（CVR）估计是许多推荐收入业务系统的至关重要的任务，例如电子商务和广告。从样本的角度来看，典型的CVR阳性样品通常会经过接触的漏斗，以点击转化。由于缺乏未点击样本的事后标签，CVR学习任务通常仅使用点击样本，而不是所有暴露的样本，即单击率（CTR）学习任务。但是，在在线推断期间，在相同的假定暴露空间上估算了CVR和CTR，这会导致训练和推理之间的样本空间不一致，即样本选择偏置（SSB）。为了减轻SSB，以前的智慧建议设计新颖的辅助任务，以使CVR在未单击的培训样本（例如CTCVR和反事实CVR等）上进行学习，等等。尽管在某种程度上减轻了SSB在建模过程中，负样本（未点击）和事实的负样本（单击但未转换），这使得CVR模型缺乏鲁棒性。为了满足这一差距，我们提出了一种新颖的合唱模型，以实现整个空间中的CVR学习。]]></description>
      <guid>https://arxiv.org/abs/2502.08277</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐的图形基础模型：一项全面调查</title>
      <link>https://arxiv.org/abs/2502.08346</link>
      <description><![CDATA[ARXIV：2502.08346V2公告类型：替换 
摘要：推荐系统（RS）是浏览大量在线信息的基本工具，深度学习进步在提高排名准确性方面起着越来越重要的作用。其中，图形神经网络（GNN）在提取高阶结构信息方面表现出色，而大语言模型（LLMS）旨在处理和理解自然语言，从而使这两种方法都非常有效且广泛采用。最近的研究集中在图基础模型（GFMS）上，该模型将GNN和LLM的优势整合到通过利用基于图的用户项目关系的基于图形的结构以及文本理解以及文本理解来更有效地建模RS问题。在这项调查中，我们通过引入明确的当前方法的分类法，深入研究方法论细节，并突出关键挑战和未来方向，从而提供了基于GFM的RS技术的全面概述。通过综合最近的进步，我们旨在为基于GFM的推荐系统的不断发展的景观提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.08346</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>