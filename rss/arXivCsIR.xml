<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 23 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>排序与对齐：实现有效的无源图域自适应</title>
      <link>https://arxiv.org/abs/2408.12185</link>
      <description><![CDATA[arXiv:2408.12185v1 公告类型：交叉 
摘要：图神经网络 (GNN) 在图域自适应方面取得了令人印象深刻的性能。然而，由于隐私和存储问题，在现实世界中可能无法使用广泛的源图。为此，我们研究了一个尚未充分探索但实用的无源图域自适应问题，它将知识从源模型而不是源图转移到目标域。为了解决这个问题，我们引入了一种新的基于 GNN 的方法，称为 Rank and Align (RNA)，它使用光谱序列对图相似性进行排序以实现稳健的语义学习，并将非谐波图与靠近源域的谐波图对齐以进行子图提取。特别是，为了克服标签稀缺性，我们采用光谱序列算法来推断稳健的成对排名，这可以使用相似性学习目标指导语义学习。为了描述分布变化，我们利用谱聚类和轮廓系数来检测谐波图，源模型可以轻松对其进行分类。为了减少潜在的领域差异，我们通过对抗性边缘采样过程从非谐波图中提取领域不变子图，从而指导 GNN 的不变学习。在多个基准数据集上进行的大量实验证明了我们提出的 RNA 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.12185</guid>
      <pubDate>Fri, 23 Aug 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>RuleAlign：通过诊断规则对齐让大型语言模型成为更好的医生</title>
      <link>https://arxiv.org/abs/2408.12579</link>
      <description><![CDATA[arXiv:2408.12579v1 公告类型：交叉 
摘要：GPT-4、MedPaLM-2 和 Med-Gemini 等大型语言模型 (LLM) 在各种医学基准上的表现都堪比人类专家。然而，他们在做出类似于医生的专业诊断方面仍然面临挑战，特别是在有效收集患者信息和推理最终诊断方面。为此，我们引入了 RuleAlign 框架，旨在将 LLM 与特定的诊断规则对齐。我们开发了一个包含患者和医生之间基于规则的通信的医学对话数据集，并通过偏好学习设计了一种对齐学习方法。实验结果证明了所提出方法的有效性。我们希望我们的工作能够为探索 LLM 作为 AI 医生的潜力提供灵感。]]></description>
      <guid>https://arxiv.org/abs/2408.12579</guid>
      <pubDate>Fri, 23 Aug 2024 06:21:00 GMT</pubDate>
    </item>
    <item>
      <title>古老智慧，现代工具：探索古印度哲学的检索增强法学硕士</title>
      <link>https://arxiv.org/abs/2408.11903</link>
      <description><![CDATA[arXiv:2408.11903v1 公告类型：交叉 
摘要：LLM 彻底改变了信息检索和知识传播的格局。然而，它们在专业领域的应用往往受到事实不准确和幻觉的阻碍，尤其是在长尾知识分布中。我们探索检索增强生成 (RAG) 模型在专业知识领域用于长篇问答 (LFQA) 的潜力。我们提出了 VedantaNY-10M，这是一个从关于古印度哲学 Advaita Vedanta 的大量公开讨论中精选出来的数据集。我们开发了一个 RAG 模型，并将其与标准的非 RAG LLM 进行对比，重点关注转录、检索和生成性能。计算语言学家和领域专家的人工评估表明，RAG 模型在产生事实和全面的反应方面明显优于标准模型，幻觉更少。此外，基于关键词的混合检索器强调独特的低频词，进一步改善了结果。我们的研究为有效整合现代大型语言模型与古代知识系统提供了见解。包含数据集和代码的项目页面：https://sites.google.com/view/vedantany-10m]]></description>
      <guid>https://arxiv.org/abs/2408.11903</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>人类水平预测的推理和工具</title>
      <link>https://arxiv.org/abs/2408.12036</link>
      <description><![CDATA[arXiv:2408.12036v1 公告类型：交叉 
摘要：在网络规模数据集上训练的语言模型 (LM) 之所以取得巨大成功，很大程度上是因为它们能够记住大量的训练数据，即使只出现在几个例子中。这些能力在诸如问答等任务的评估中通常是可取的，但也引发了人们对这些模型是否可以表现出真正的推理能力或只能成功模仿训练数据中的模式的质疑。这种区别在预测任务中尤为明显，因为答案并不存在于训练数据中，模型必须推理才能做出合乎逻辑的推论。我们提出了推理和预测工具 (RTF)，这是一个推理和行动 (ReAct) 代理的框架，可以动态检索更新的信息并使用配备的工具运行数值模拟。我们用来自竞争性预测平台的问题评估我们的模型，并证明我们的方法与人类预测相比具有竞争力，并且可以超越人类预测。这表明，有了正确的工具，LM 确实可以像人类一样思考和适应，为现实世界的决策提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2408.12036</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:59 GMT</pubDate>
    </item>
    <item>
      <title>认知偏差在推荐生态系统中的重要性</title>
      <link>https://arxiv.org/abs/2408.12492</link>
      <description><![CDATA[arXiv:2408.12492v1 公告类型：新
摘要：几十年来，心理学、社会学和行为经济学一直在研究认知偏见。传统上，它们被认为是一种消极的人类特征，分别导致决策能力低下、刻板印象强化或可被利用来操纵消费者。我们认为认知偏见也体现在推荐生态系统的不同部分和推荐过程的不同阶段。更重要的是，我们对这种传统的对认知偏见的有害观点提出异议，并声称某些认知偏见在推荐系统中是有益的。具体来说，我们提供经验证据表明，在推荐管道的各个组成部分中都可以观察到特征正效应、宜家效应和文化同质性等偏见，包括输入数据（如评级或辅助信息）、推荐算法或模型（以及因此推荐的项目）以及用户与系统的交互。在三个涵盖招聘和娱乐领域的小型实验中，我们研究了上述偏见的普遍性。我们最终提倡不带偏见地考虑认知偏差，以改进用户和项目模型以及推荐算法。]]></description>
      <guid>https://arxiv.org/abs/2408.12492</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>用于多跳问答的分层检索增强生成模型</title>
      <link>https://arxiv.org/abs/2408.11875</link>
      <description><![CDATA[arXiv:2408.11875v1 公告类型：交叉 
摘要：多跳问答 (QA) 需要通过整合多条信息来解决复杂问题，从而进行复杂的推理。然而，现有的 QA 系统面临着诸如信息过时、上下文窗口长度限制以及准确率与数量权衡等挑战。为了解决这些问题，我们提出了一个新颖的框架，即具有 Rethink 的分层检索增强生成模型 (HiRAG)，包括分解器、定义器、检索器、过滤器和摘要器五个关键模块。我们引入了一种新的分层检索策略，该策略结合了文档级别的稀疏检索和块级别的密集检索，有效地整合了它们的优势。此外，我们提出了一种单候选检索方法来减轻多候选检索的局限性。我们还构建了两个新的语料库，即 Indexed Wikicorpus 和 Profile Wikicorpus，以解决知识过时和不足的问题。
我们在四个数据集上的实验结果表明，HiRAG 在大多数指标上都优于最先进的模型，而且我们的 Indexed Wikicorpus 是有效的。HiRAG 的代码可在 https://github.com/2282588541a/HiRAG 上找到]]></description>
      <guid>https://arxiv.org/abs/2408.11875</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:58 GMT</pubDate>
    </item>
    <item>
      <title>引文评估中忠诚度指标与人类的比较分析</title>
      <link>https://arxiv.org/abs/2408.12398</link>
      <description><![CDATA[arXiv:2408.12398v1 公告类型：新
摘要：大型语言模型 (LLM) 通常会生成不受支持或无法验证的内容，称为“幻觉”。为了解决这个问题，使用检索增强的 LLM 将引文包含在其内容中，将内容建立在可验证的来源中。尽管取得了这样的进展，但手动评估引文对相关陈述的支持程度仍然是一项重大挑战。先前的研究通过利用忠诚度指标自动估计引文支持来解决这一挑战。然而，他们将这种引文支持估计限制在二元分类场景中，忽略了实际场景中的细粒度引文支持。为了研究忠诚度指标在细粒度场景中的有效性，我们提出了一个比较评估框架，该框架评估指标在区分三类支持级别（完全支持、部分支持和不支持）的引文方面的有效性。我们的框架采用相关性分析、分类评估和检索评估来全面衡量指标得分与人类判断之间的一致性。我们的结果表明，没有一个指标在所有评估中始终表现出色，这凸显了准确评估细粒度支持水平的复杂性。特别是，我们发现表现最好的指标很难区分部分支持与完全支持或不支持。基于这些发现，我们为开发更有效的指标提供了实用建议。]]></description>
      <guid>https://arxiv.org/abs/2408.12398</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>DLCRec：一种管理基于 LLM 的推荐系统中多样性的新方法</title>
      <link>https://arxiv.org/abs/2408.12470</link>
      <description><![CDATA[arXiv:2408.12470v1 公告类型：新
摘要：大型语言模型 (LLM) 集成到推荐系统中已导致性能大幅提升。然而，这往往以降低推荐多样性为代价，这会对用户满意度产生负面影响。为了解决这个问题，可控推荐已经成为一种有前途的方法，它允许用户指定他们的偏好并接收满足他们不同需求的推荐。尽管具有潜力，但现有的可控推荐系统通常依赖于简单的机制（例如单一提示）来调节多样性 - 这种方法无法捕捉用户偏好的全部复杂性。为了应对这些限制，我们提出了 DLCRec，这是一个新颖的框架，旨在实现对基于 LLM 的推荐中多样性的细粒度控制。与传统方法不同，DLCRec 采用细粒度任务分解策略，将推荐过程分解为三个连续的子任务：类型预测、类型填充和项目预测。这些子任务是独立训练的，并根据用户定义的控制数字按顺序推断，确保对多样性进行更精确的控制。此外，与多样性相关的用户行为数据的稀缺性和分布不均对微调提出了重大挑战。为了克服这些障碍，我们引入了两种数据增强技术，以增强模型对噪声和分布外数据的鲁棒性。这些技术使模型接触到更广泛的模式，提高了其在生成具有不同多样性水平的推荐时的适应性。我们广泛的实证评估表明，DLCRec 不仅可以精确控制多样性，而且在多种推荐场景中的表现也优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2408.12470</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>图协同过滤的公平增强</title>
      <link>https://arxiv.org/abs/2408.12208</link>
      <description><![CDATA[arXiv:2408.12208v1 公告类型：新
摘要：推荐领域的最新发展利用了图神经网络 (GNN) 的协作能力，从用户项目网络中学习用户的偏好。尽管新兴法规解决了自动化系统的公平性问题，但图协同过滤中的不公平问题仍未得到充分探索，尤其是从消费者的角度来看。尽管对消费者不公平性做出了许多贡献，但其中只有少数作品深入研究了 GNN。最新缓解算法的形式化以及它们在前沿模型上的有效性和可靠性存在明显差距。本文通过重现最新的缓解方法之一，对最近强调图协同过滤中不公平问题的研究做出了有力的回应。重现的技术通过学习公平的图形增强来调整系统公平性水平。在基于 11 个 GNN、5 个非 GNN 模型和 5 个跨不同领域的真实网络的实验设置下，我们的调查显示公平图增强对高效用模型和大型数据集始终有效。公平增强图的可迁移性实验为未来的推荐研究开辟了新的问题。源代码：https://github.com/jackmedda/FA4GCF。]]></description>
      <guid>https://arxiv.org/abs/2408.12208</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>个性化电子商务的大规模动态产品图像生成和推荐</title>
      <link>https://arxiv.org/abs/2408.12392</link>
      <description><![CDATA[arXiv:2408.12392v1 公告类型：新
摘要：将基于潜在扩散的图像生成与上下文强盗相结合，可以大规模创建引人注目的个性化产品图像，这在以前是不可能实现的，或者成本太高。在本文中，我们展示了如何利用这些技术来增加电子商务在线重定向活动中用户对推荐的参与度。]]></description>
      <guid>https://arxiv.org/abs/2408.12392</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:56 GMT</pubDate>
    </item>
    <item>
      <title>DimeRec：通过生成扩散模型增强顺序推荐的统一框架</title>
      <link>https://arxiv.org/abs/2408.12153</link>
      <description><![CDATA[arXiv:2408.12153v1 公告类型：新
摘要：顺序推荐 (SR) 在推荐系统中起着关键作用，它根据用户非平稳的历史交互根据用户的偏好定制推荐。要在 SR 中实现高质量的性能，需要同时关注项目表示和多样性。然而，设计一种同时优化这些优点的 SR 方法仍然是一个长期的挑战。在本研究中，我们通过将最近的生成扩散模型 (DM) 集成到 SR 中来解决此问题。DM 已证明在表示学习和多样化图像生成中很有用。然而，由于学习目标（推荐与噪声重建）和各自学习空间（非平稳与平稳）的差异，SR 和 DM 的直接组合会导致性能不佳。为了解决这个问题，我们提出了一个新框架，称为 DimeRec（\textbf{Di}ffusion with \textbf{m}ulti-interest \textbf{e}nhanced \textbf{Rec}ommender）。DimeRec 协同结合了指导提取模块 (GEM) 和生成扩散聚合模块 (DAM)。GEM 从用户的非平稳交互历史中提取关键的平稳指导信号，而 DAM 采用以 GEM 的输出为条件的生成扩散过程来重建和生成一致的建议。我们的数值实验表明，DimeRec 在三个公开可用的数据集上的表现明显优于已建立的基线方法。此外，我们已成功在大型短视频推荐平台上部署了 DimeRec，为数亿用户提供服务。实时 A/B 测试证实，我们的方法既提高了用户花费的时间，又提高了结果的多样化。]]></description>
      <guid>https://arxiv.org/abs/2408.12153</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱处理的硬件加速：挑战与最新发展</title>
      <link>https://arxiv.org/abs/2408.12173</link>
      <description><![CDATA[arXiv:2408.12173v1 公告类型：新
摘要：知识图谱 (KG) 近年来引起了广泛关注，尤其是在语义网领域，并且在数据挖掘和搜索引擎等其他应用领域也越来越受欢迎。同时，不同类型的异构硬件的开发也取得了巨大进步，影响了 KG 的处理方式。本文的目的是对知识图谱硬件加速进行系统的文献综述。为此，我们对知识图谱技术的主要领域进行了分类，利用不同的硬件单元来加速某些知识图谱功能。然后，我们广泛描述了各自的工作，重点介绍了 KG 相关方案如何利用现代硬件加速器。根据我们的回顾，我们确定了各种研究差距和未来的探索方向，这些方向预计对学术界和行业从业者都具有重要价值。]]></description>
      <guid>https://arxiv.org/abs/2408.12173</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:55 GMT</pubDate>
    </item>
    <item>
      <title>它看起来是连续的吗？用于评估顺序建议的数据集分析</title>
      <link>https://arxiv.org/abs/2408.12008</link>
      <description><![CDATA[arXiv:2408.12008v1 公告类型：新
摘要：顺序推荐系统是一个重要且需求量很大的研究领域。此类系统旨在利用用户历史中的交互顺序来预测未来的交互。前提是交互顺序和顺序模式起着至关重要的作用。因此，使用具有顺序结构的数据集来正确评估顺序推荐系统至关重要。
我们应用了几种基于用户交互序列随机改组的方法来评估 15 个数据集的顺序结构强度，这些方法在最近顶级会议上发表的研究论文中经常用于顺序推荐系统评估。由于改组明确打破了数据集固有的顺序依赖关系，我们通过比较改组后的数据集和原始版本的指标来估计顺序模式的强度。我们的研究结果表明，几个流行的数据集具有相当弱的顺序结构。]]></description>
      <guid>https://arxiv.org/abs/2408.12008</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>基于行为模式挖掘的多行为推荐</title>
      <link>https://arxiv.org/abs/2408.12152</link>
      <description><![CDATA[arXiv:2408.12152v1 公告类型：新
摘要：多行为推荐系统通过利用辅助行为（例如页面浏览量和收藏量）来解决传统模型仅依赖于稀疏目标行为（如购买）的局限性，从而提高有效性。现有的多行为推荐方法通常遵循以下两种策略之一：一些方法从各个行为子图得出初始节点表示，然后将它们集成为综合配置文件；而另一些方法将多行为数据解释为异构图，应用图神经网络实现统一的节点表示。然而，这些方法没有充分探索用户和物品之间复杂的行为模式。为了弥补这一差距，我们引入了一种称为基于行为模式挖掘的多行为推荐（BPMR）的新算法。我们的方法广泛研究了用户和物品之间的各种交互模式，并利用这些模式作为提出推荐的特征。我们采用贝叶斯方法来简化推荐流程，有效地规避了图神经网络算法带来的挑战，例如由于过度平滑而无法准确捕捉用户偏好。我们对三个真实数据集的实验评估表明，BPMR 明显优于现有的最先进算法，在 Recall@10 指标上平均提高了 268.29%，在 NDCG@10 指标上平均提高了 248.02%。我们的 BPMR 代码可在 https://github.com/rookitkitlee/BPMR 上公开访问，供使用和进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2408.12152</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>对于低资源语言来说，跨语言密集段落检索的局限性是什么？</title>
      <link>https://arxiv.org/abs/2408.11942</link>
      <description><![CDATA[arXiv:2408.11942v1 公告类型：新
摘要：在本文中，我们分析了多语言密集段落检索器 (mDPR) 对资源极低的语言的能力。在跨语言开放检索答案生成 (CORA) 管道中，mDPR 在 26 种语言的多语言开放 QA 基准测试中取得了成功，其中 9 种在训练期间是未见过的。这些结果对于资源低的语言的问答 (QA) 很有希望。我们专注于 mDPR 表现不佳的两种资源极低的语言：阿姆哈拉语和高棉语。我们收集和管理数据集，以使用翻译语言建模 (TLM) 和问题段落对齐来训练 mDPR 模型。我们还研究了我们的扩展对检索结果中语言分布的影响。我们在 MKQA 和 AmQA 数据集上的结果表明，语言对齐为低资源语言带来了 mDPR 改进，但改进幅度不大，结果仍然很低。我们得出的结论是，实现 CORA 在极低资源环境中实现多语言开放式 QA 的承诺具有挑战性，因为模型、数据和评估方法相互交织。因此，在后续工作中需要关注这三个方面。我们发布了我们的代码以供可重复性和未来工作：https://anonymous.4open.science/r/Question-Answering-for-Low-Resource-Languages-B13C/]]></description>
      <guid>https://arxiv.org/abs/2408.11942</guid>
      <pubDate>Fri, 23 Aug 2024 06:20:53 GMT</pubDate>
    </item>
    </channel>
</rss>