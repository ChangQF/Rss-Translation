<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 20 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于图的索引范围检索</title>
      <link>https://arxiv.org/abs/2502.13245</link>
      <description><![CDATA[ARXIV：2502.13245V1公告类型：新 
摘要：在高维矢量空间中基于接近度的检索点是信息检索应用程序的关键一步。近年来，大约最近几年研究了大约最近的邻居搜索（ANN）问题，该问题确定了$ k $最近的邻居（大约很难）。但是，尽管在诸如重复检测，窃器检查和面部识别等领域中应用，但很少关注相关问题，即在查询的给定距离（范围检索问题）内找到所有点。在本文中，我们介绍了一组基于图的矢量指数范围检索的算法，该算法在ANN查询上获得了出色的性能。由于范围查询可能具有从无匹配的结果到数据库中数千个匹配结果，因此我们基于标准图搜索的修改引入了一组范围检索算法，这些算法适应了以前组的查询，并迅速终止。为后一个组寻找更多资源。由于缺乏现有的范围检索基准测试，我们还对现有嵌入数据集的范围特征进行了全面研究，并为八个现有数据集选择合适的范围检索半径，除了现有的基准外，还具有多达1亿点。我们在这些数据集上测试了算法，并在NAIVE基线方法上发现查询吞吐量最高100倍，平均提高了5-10倍，并且强劲的性能高达1亿个数据点。]]></description>
      <guid>https://arxiv.org/abs/2502.13245</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hawkbench：研究抹布方法的弹性在分层信息方面</title>
      <link>https://arxiv.org/abs/2502.13465</link>
      <description><![CDATA[ARXIV：2502.13465V1公告类型：新 
摘要：在现实世界中寻求信息的方案中，用户有动态和多样化的需求，需要抹布系统来展示适应性的弹性。为了全面评估当前抹布方法的弹性，我们介绍了霍克顿（Hawkbench），这是一种人体标记的多域基准测试，旨在严格评估跨分类任务类型的抹布性能。通过基于信息寻求行为的任务进行分层，Hawkbench提供了系统的系统评估，对抹布系统如何适应多样化的用户需求。
  与现有基准不同，该基准主要集中于特定的任务类型（主要是事实查询）并依靠不同的知识库，Hawkbench提供：（1）系统的任务分层以涵盖广泛的查询类型，包括Fortoid and Ariationale查询，（2 2）（2）（2 ）在所有任务类型中集成多域语料库以减轻语料库偏见，以及（3）严格的注释以进行高质量评估。
  Hawkbench包括1,600个高质量的测试样本，均匀分布在域和任务类型之间。使用此基准测试，我们评估了代表性的抹布方法，从答案质量和响应潜伏期分析了它们的性能。我们的发现强调了需要整合决策，查询解释和全球知识理解以提高RAG概括性的动态任务策略的需求。我们认为，Hawkbench是提高抹布方法的弹性及其实现通用信息寻求信息的能力的关键基准。]]></description>
      <guid>https://arxiv.org/abs/2502.13465</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM4TAG：通过大语言模型检索信息检索的自动标记系统</title>
      <link>https://arxiv.org/abs/2502.13481</link>
      <description><![CDATA[ARXIV：2502.13481V1公告类型：新 
摘要：标记系统在各种信息检索应用程序（例如搜索引擎和推荐系统）中起着至关重要的作用。最近，由于其广泛的世界知识，语义理解和推理能力，大型语言模型（LLM）已应用于标记系统。尽管表现出色，但现有方法仍然存在局限性，包括在全面检索相关候选标签方面的困难，适应新兴领域特定知识的挑战，以及缺乏可靠的标签置信度量化。为了解决上述这三个限制，我们提出了一个自动标记系统LLM4TAG。首先，基于图的标签召回模块旨在有效，全面地构建一个高度相关的候选标签集。随后，采用知识增强的标签生成模块来生成具有长期和短期知识注入的准确标签。最后，引入了TAG置信校准模块以生成可靠的标签置信分数。在三个大型工业数据集上进行的广泛实验表明，LLM4TAG的表现明显胜过最先进的基线和LLM4TAG，并且已在网上部署用于内容标签，可为数亿用户提供服务。]]></description>
      <guid>https://arxiv.org/abs/2502.13481</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复制Nevir：神经信息检索中的否定</title>
      <link>https://arxiv.org/abs/2502.13506</link>
      <description><![CDATA[ARXIV：2502.13506V1公告类型：新 
摘要：否定是人类交流的基本方面，但对于信息检索（IR）中语言模型（LMS）仍然是一个挑战。尽管现代神经IR系统在LMS上非常依赖，但对他们处理否定的处理很少。在这项研究中，我们重现并扩展了Nevir的发现，Nevir的结果是一项基准研究，该研究揭示了大多数IR模型在处理否定时的随机排名水平或低于随机排名的水平。我们复制尼维尔的原始实验，并评估新开发的最新IR模型。我们的发现表明，最近新兴的类别列表的大语言模型（LLM）Rerankers-优于其他模型，但仍然表现不佳。此外，我们利用Dorverair是一种基准数据集，旨在以广泛的否定为排除查询，以评估否定理解的普遍性。我们的发现表明，一个数据集上的微调并不能可靠地改善另一个数据集的性能，这表明其数据分布有显着差异。此外，我们观察到，只有交叉编码器和LISTWISE LLM RERANKERS在两个否定任务中都能达到合理的绩效。]]></description>
      <guid>https://arxiv.org/abs/2502.13506</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打破簇：基于文本的顺序推荐的均匀性优化</title>
      <link>https://arxiv.org/abs/2502.13530</link>
      <description><![CDATA[ARXIV：2502.13530V1公告类型：新 
摘要：传统的顺序推荐（SR）方法在很大程度上依赖于显式项目ID来捕获用户偏好随着时间的流逝。这种依赖在冷启动场景和域转移任务中引入了关键限制，在这些方案和域转移任务中，看不见的项目和新环境通常缺乏已建立的ID映射。为了克服这些局限性，最近的研究已转向利用纯文本信息进行建议，从而改善了跨领域的模型概括和适应性。尽管很有希望，但基于文本的SR面临着独特的困难：项目的文本描述通常具有语义相似性，从而导致群集项目表示，损害其统一性，这是促进多样性和增强推荐系统中的概括至关重要的属性。在本文中，我们探索了一个新颖的框架，以改善基于文本的SR中项目表示的统一性。我们的分析表明，序列中的项目表现出标志性的语义相似性，这意味着它们的表示比整体上的项目更接近，并且对于较不受欢迎的项目而言，这种效果更为明显，与其更流行的对应物相比，这种效果形成了更紧密的簇。基于这些发现，我们提出了一个单位，该单元采用了三种成对项目采样策略：统一的一般抽样策略，序列驱动的采样策略和受欢迎程度驱动的采样策略。每种策略都采用不同程度的排斥来选择性地调整项目对之间的距离，从而在考虑序列上下文和项目流行度的同时，完善表示表示均匀性。在多个现实世界数据集上进行的广泛实验表明，我们提出的方法的表现优于最先进的模型，从而验证了单位在增强表示表示均匀性和建议准确性方面的有效性。源代码可在https://github.com上获得。 /ccwwhhh/model-rec。]]></description>
      <guid>https://arxiv.org/abs/2502.13530</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>爆发过滤器气泡：通过对齐大语言模型增强偶然性建议</title>
      <link>https://arxiv.org/abs/2502.13539</link>
      <description><![CDATA[ARXIV：2502.13539V1公告类型：新 
摘要：推荐系统（RSS）经常患有反馈循环现象，例如，RSS受到其建议偏见的数据培训。这导致了过滤器气泡效应，从而增强了均匀内容并降低了用户满意度。为此，提出了提供意外但相关项目的偶然性建议。最近，由于其广泛的世界知识和推理能力，大型语言模型（LLMS）在偶然性预测中表现出了潜力。但是，他们仍然面临挑战，将偶然性判断与人类评估，处理较长的用户行为序列以及满足工业RSS的延迟要求。为了解决这些问题，我们提出了Seral（具有一致性大语言模型的Serendipity建议），该框架包括三个阶段：（1）认知配置文件生成，将用户行为压缩为多层配置文件； （2）使用丰富的训练数据将偶然性判断与人类偏好保持一致的序列对齐； （3）将Serengpt有效地整合到工业RSS管道中的附近适应。在线实验表明，Seral提高了曝光率（PVR），点击和偶然性项目的交易增加了5.7％，29.56％和27.6％，从而增强了用户体验，而不会对总体收入产生太大影响。现在，它已完全部署在淘宝应用主页的“猜猜您喜欢的东西”中。]]></description>
      <guid>https://arxiv.org/abs/2502.13539</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动作片：上下文的代币化动作序列，用于生成推荐</title>
      <link>https://arxiv.org/abs/2502.13581</link>
      <description><![CDATA[Arxiv：2502.13581V1公告类型：新 
摘要：生成推荐（GR）是一种新兴范式，将用户操作将其示为离散令牌模式，并作为预测产生自动加压。但是，现有的GR模型将每个操作都独立地化，将相同的固定令牌分配给所有序列中相同的动作，而无需考虑上下文关系。缺乏上下文意识可能会导致次优的性能，因为相同的动作可能会根据其周围环境而具有不同的含义。为了解决这个问题，我们建议动作件在象征性动作序列时明确合并上下文。在ActionPiese中，每个动作都表示为一组项目特征，它们用作初始令牌。鉴于动作序列语料库，我们通过将特征模式合并为新令牌来构建词汇，这是基于单个集合和相邻集合中的同时出现频率的基础。考虑到特征集的无序性质，我们进一步介绍了集合置换正则化，该置换置换会产生具有相同语义的动作序列的多个分割。公共数据集上的实验表明，动作件始终优于现有的动作令牌方法，将ndcg@$ 10 $提高到$ 6.00 \％\％$ $ $ $ $ $ 12.82 \％$。]]></description>
      <guid>https://arxiv.org/abs/2502.13581</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>谈话：大语模型的多模式音乐推荐</title>
      <link>https://arxiv.org/abs/2502.13713</link>
      <description><![CDATA[ARXIV：2502.13713V1公告类型：新 
摘要：我们提出了Talkplay，这是一种多式联运音乐推荐系统，该系统将建议任务重新制定为大型语言模型代币产生。 Talkplay通过扩展的令牌词汇代表音乐，该词汇编码多种模式 - 音频，歌词，元数据，语义标签和播放列表共发生。使用这些丰富的表示，该模型学会通过对音乐推荐对话进行的下一步预测来生成建议，这需要学习协会自然语言查询和响应以及音乐项目。换句话说，该公式将音乐推荐转化为自然语言理解任务，该任务预测对话代币的能力直接优化了查询项目的相关性。我们的方法消除了传统的建议管道的复杂性，从而使查询意识到的音乐建议的端到端学习。在实验中，谈话是成功训练的，并且在各个方面都超过了基线方法，这表明了强烈的上下文理解是对话音乐的推荐者。]]></description>
      <guid>https://arxiv.org/abs/2502.13713</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Trustrag：一个具有检索增强发电的信息助理</title>
      <link>https://arxiv.org/abs/2502.13719</link>
      <description><![CDATA[ARXIV：2502.13719V1公告类型：新 
摘要：\ ac {rag}已成为一种至关重要的技术，用于增强具有实时和域特异性知识的大型模型。尽管已经提出了许多改进和开源工具来完善\ ac {rag}框架的准确性，但对提高产生结果的可信度的关注很少。为了解决这一差距，我们介绍了Trustrag，这是一个新颖的框架，从三个角度：索引，检索和世代增强\ ac {rag}。具体而言，在索引阶段，我们提出了一种语义增强的分量策略，该策略结合了层次结构索引，以补充每个块的上下文信息，以确保语义完整性。在检索阶段，我们引入了一种基于公用事业的过滤机制，以识别高质量的信息，在减少输入长度的同时支持答案的生成。在一代阶段，我们提出了细粒度的引用增强，该引文提高了响应中的意见句子，并在句子级别处于引文关系，从而提高了引文的准确性。我们开放源trustrag框架，并提供了一个为基于摘要的问题回答任务\ footNote {https://huggingface.co/spaces/golaxy/trustrag}而设计的演示工作室。基于这些，我们旨在帮助研究人员：1）系统地增强\ ac {rag}系统的可信度，以及（2）开发自己的\ ac {rag}系统，具有更可靠的输出。]]></description>
      <guid>https://arxiv.org/abs/2502.13719</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的图形嵌入式用于基于会话的推荐以及项目功能的嵌入</title>
      <link>https://arxiv.org/abs/2502.13763</link>
      <description><![CDATA[ARXIV：2502.13763V1公告类型：新 
摘要：在基于会话的推荐系统中，预测基于会话中用户的先前行为。最新的顺序建议算法要么使用图形神经网络在图中对会话进行建模，要么通过利用项目功能来利用会话的相似性。在本文中，我们结合了这两种方法，并提出了一种新颖的方法，即图形卷积网络扩展（GCNext），该方法通过图卷积网络将项目特征直接纳入图表。 GCNext创建了一个丰富的功能项目共发生图形，并以无监督的方式学习相应的项目嵌入。我们在三个数据集上显示，将gcnext集成到顺序推荐算法中可以显着提高最近邻邻方法的性能以及神经网络模型。我们的灵活扩展很容易纳入最先进的方法，并将MRR@20提高到12.79％。]]></description>
      <guid>https://arxiv.org/abs/2502.13763</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成大型推荐模型：LLMS中的新兴趋势供推荐</title>
      <link>https://arxiv.org/abs/2502.13783</link>
      <description><![CDATA[ARXIV：2502.13783V1公告类型：新 
摘要：在信息过载的时代，推荐系统在过滤数据和传递个性化内容方面起着关键作用。功能交互和用户行为建模方面的最新进展显着增强了这些系统的回忆和排名过程。随着大语言模型（LLM）的兴起，已经出现了新的机会，以进一步改善推荐系统。本教程探讨了整合LLM的两种主要方法：LLMS增强建议，这些建议利用了一般LLM的推理能力，以及生成的大型建议模型，这些模型的重点是扩展和复杂。虽然前者在现有文献中得到了广泛的涵盖，但后者仍然没有被忽视。该教程旨在通过提供有关生成大型推荐模型的全面概述，包括其最近的进步，挑战和潜在的研究方向，以填补这一空白。关键主题包括数据质量，扩展法，用户行为挖掘以及培训和推理的效率。通过与本教程互动，参与者将深入了解该领域的最新发展和未来机会，从而有助于学术研究和实际应用。此探索的及时性质支持推荐系统的快速发展，为研究人员和从业人员提供了宝贵的指导。]]></description>
      <guid>https://arxiv.org/abs/2502.13783</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于流式传输近似最近邻居搜索的图形索引的现场更新</title>
      <link>https://arxiv.org/abs/2502.13826</link>
      <description><![CDATA[ARXIV：2502.13826V1公告类型：新 
摘要：大约最近的邻居搜索（ANN）的索引是信息检索的基本组件，并广泛用于数据库，搜索，建议和抹布系统。在这些情况下，将文档或其他对象插入并从工作集中插入并以高速率删除，需要对矢量索引进行大量更新。基于接近图指数的算法是ANN的最有效指数，赢得了许多基准竞赛。但是，以高速率更新此类图形索引是一项挑战，同时在多次更新后支持稳定的召回率。由于该图是单独链接的，因此删除很难，因为没有快速的方法可以找到已删除的顶点的邻居。因此，为了更新图形，最新的算法（例如FreshDiskann）在批处理中积累删除并定期合并，删除边缘以删除了顶点并修改图形以确保回忆稳定性。在本文中，我们介绍了IP-Diskann（Inplaceupdate-Diskann），这是第一种算法通过有效处理每次插入和就地删除来避免批处理合并的算法。我们使用标准基准测试的实验表明，IP-Diskann在高回报和低回报方案的各种冗长更新模式上都有稳定的召回。此外，其查询吞吐量和更新速度比使用批处理合并算法和HNSW更好。]]></description>
      <guid>https://arxiv.org/abs/2502.13826</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过公平抽样来减轻协作过滤中的受欢迎程度偏见</title>
      <link>https://arxiv.org/abs/2502.13840</link>
      <description><![CDATA[ARXIV：2502.13840V1公告类型：新 
摘要：推荐系统通常会遇到流行偏见，在建议中经常相互作用的项目过多代表。这种偏见源于影响训练数据的倾向因素，导致暴露不平衡。在本文中，我们引入了一种公平的采样（FS）方法来解决此问题，以确保用户和项目以同样的概率为正面和负面实例。与传统的反向倾向得分（IPS）方法不同，FS不需要倾向估计，从而消除了与计算不准确相关的错误。我们的理论分析表明，FS有效地中和倾向因素的影响，实现了公正的学习。实验结果验证了FS在点和配对的推荐任务中均优于最先进的方法，从而在不牺牲准确性的情况下增强了建议公平性。该实现可从https://anonymon.4open.science/r/fair-smpling获得。]]></description>
      <guid>https://arxiv.org/abs/2502.13840</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用内存优化的LLM用户代理来增强跨域建议</title>
      <link>https://arxiv.org/abs/2502.13843</link>
      <description><![CDATA[arxiv：2502.13843v1公告类型：新 
摘要：基于大语言模型（LLM）的用户代理已经成为通过模拟用户交互来改善推荐系统的强大工具。但是，由于记忆结构效率低下，现有的方法与跨域情景遇到了困难，从而导致信息保留无关，并且无法解决社会影响因素，例如受欢迎程度。为了解决这些限制，我们介绍了AgentCF ++，这是一个具有双层内存架构的新型框架和两步融合机制，可有效地过滤域特异性偏好。此外，我们提出了具有共享内存的利益集团，从而使模型可以捕获普及趋势对具有相似兴趣的用户的影响。通过对多个跨域数据集进行的大量实验，AgentCF ++表现出优于基线模型的性能，突出了其在提炼推荐系统的用户行为模拟方面的有效性。我们的代码可在https://anonymon.4open.science/r/agentcf-plus上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.13843</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过个性化推理增强基于LLM的建议</title>
      <link>https://arxiv.org/abs/2502.13845</link>
      <description><![CDATA[ARXIV：2502.13845V1公告类型：新 
摘要：当前由大语言模型（LLMS）提供动力的当前建议系统由于缺乏明确的逻辑结构而经常将其推理能力降低。为了解决此限制，我们介绍了COT-REC，该框架通过合并两个关键过程：用户偏好分析和项目感知评估，将思想链（COT）推理集成到LLM驱动的建议中。 COT-REC分为两个关键阶段：（1）确定用户偏好和项目感知的个性化数据提取，以及（2）个性化数据应用程序，在此信息中利用此信息来完善建议。我们的实验分析表明，COT-REC通过更好地利用LLMS的推理潜力来提高建议准确性。该实现可在https://anonymon.4open.science/r/cot-rec上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2502.13845</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>