<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 16 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>流式矢量量化检索器实现大规模推荐的实时索引</title>
      <link>https://arxiv.org/abs/2501.08695</link>
      <description><![CDATA[arXiv:2501.08695v1 Announce Type: new 
摘要：检索器是推荐系统中最重要的一个环节，在严格的延迟限制下，负责高效地选择可能的正样本进入后续环节。因此，大规模系统往往依赖于近似计算和索引来粗略地缩小候选规模，并采用简单的排序模型。考虑到简单模型缺乏产生精确预测的能力，现有的大多数方法主要侧重于结合复杂的排序模型。然而，索引有效性的另一个基本问题仍未解决，这也成为复杂化的瓶颈。在本文中，我们提出了一种新颖的索引结构：流式矢量量化模型，作为新一代的检索范式。流式矢量量化实时地将项目与索引关联，赋予其即时性。此外，通过对可能的变体进行细致的验证，它还实现了索引平衡和可修复性等额外好处，使其能够像现有方法一样支持复杂的排序模型。作为一种轻量级且易于实现的架构，流式 VQ 已在抖音和抖音精简版中部署并取代了所有主流检索器，从而显著提高了用户参与度。]]></description>
      <guid>https://arxiv.org/abs/2501.08695</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$\texttt{InfoHier}$：通过编码和嵌入进行分层信息提取</title>
      <link>https://arxiv.org/abs/2501.08717</link>
      <description><![CDATA[arXiv:2501.08717v1 公告类型：新
摘要：分析大规模数据集，尤其是涉及复杂和高维数据（如图像）的数据集，尤其具有挑战性。虽然自监督学习 (SSL) 已被证明可有效学习未标记数据的表示，但它通常侧重于扁平、非层次结构，而忽略了许多现实世界数据集中存在的多层次关系。层次聚类 (HC) 可以通过将数据组织成树状结构来发现这些关系，但它通常依赖于难以捕捉各种数据类型复杂性的严格相似性度量。为了解决这些问题，我们设想了 $\texttt{InfoHier}$，这是一个将 SSL 与 HC 相结合的框架，用于共同学习稳健的潜在表示和层次结构。这种方法利用 SSL 提供自适应表示，增强了 HC 捕获复杂模式的能力。同时，它集成了 HC 损失来改进 SSL 训练，从而产生更符合底层信息层次结构的表示。 $\texttt{InfoHier}$ 有可能提高聚类和表示学习的表现力和性能，为数据分析、管理和信息检索带来显著的益处。]]></description>
      <guid>https://arxiv.org/abs/2501.08717</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMDocIR：长文档的多模态检索基准测试</title>
      <link>https://arxiv.org/abs/2501.08828</link>
      <description><![CDATA[arXiv:2501.08828v1 公告类型：新
摘要：多模态文档检索旨在从大量文档中识别和检索各种形式的多模态内容，例如图形、表格、图表和布局信息。尽管它很重要，但目前明显缺乏一个强大的基准来有效评估系统在多模态文档检索中的性能。为了解决这一差距，这项工作引入了一个名为 MMDocIR 的新基准，它包含两个不同的任务：页面级和布局级检索。前者侧重于在长文档中定位最相关的页面，而后者则针对特定布局的检测，提供比整页分析更细粒度的粒度。布局可以指各种元素，例如文本段落、公式、图形、表格或图表。 MMDocIR 基准包含丰富的数据集，其中包含 1,685 个问题的专业注释标签和 173,843 个问题的引导标签，使其成为推进多模态文档检索训练和评估的关键资源。通过严格的实验，我们发现 (i) 视觉检索器的表现明显优于文本检索器，(ii) MMDocIR 训练集可以有效地促进多模态文档检索的训练过程，(iii) 利用 VLM 文本的文本检索器的表现远优于使用 OCR 文本的文本检索器。这些发现强调了集成视觉元素进行多模态文档检索的潜在优势。]]></description>
      <guid>https://arxiv.org/abs/2501.08828</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DNMDR：用于安全用药推荐的动态网络和多视图药物表征</title>
      <link>https://arxiv.org/abs/2501.08572</link>
      <description><![CDATA[arXiv:2501.08572v1 公告类型：交叉 
摘要：药物推荐（MR）是一个有前途的研究课题，在医疗保健和临床领域有着广泛的应用。然而，现有的方法主要依靠顺序建模和静态图进行表示学习，忽略了患者时间访问的不同医疗事件中的动态相关性，导致节点的全局结构探索不足。此外，减轻药物相互作用（DDI）是决定MR系统效用的另一个问题。为了应对上述挑战，本文提出了一种融合动态网络和多视图药物表示（DNMDR）的新型MR方法。具体而言，基于时间EHR中的离散访问构建动态异构网络的加权快照序列，并联合训练所有动态网络以获得不同医疗事件中的结构相关性和历史健康状况中的时间依赖性，从而实现具有语义特征和结构关系的全面患者表征。此外，结合药物分子结构内部视角和药物对交互视角中的药物共现和不良药物相互作用 (DDI)，可以获得安全的药物表示，从而获得高质量的药物组合推荐。最后，在真实世界数据集上进行了广泛的实验以进行性能评估，实验结果表明，所提出的 DNMDR 方法在 PRAUC、Jaccard、DDI 率等各种指标上均优于最先进的基线模型。]]></description>
      <guid>https://arxiv.org/abs/2501.08572</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于知识图谱的检索增强生成模式匹配</title>
      <link>https://arxiv.org/abs/2501.08686</link>
      <description><![CDATA[arXiv:2501.08686v1 公告类型：交叉 
摘要：传统的基于相似性的模式匹配方法由于缺少常识和领域特定知识，无法解决领域特定复杂映射场景中的语义歧义和冲突。大型语言模型 (LLM) 的幻觉问题也使基于 LLM 的模式匹配难以解决上述问题。因此，我们提出了一种基于知识图谱的检索增强生成模型，用于模式匹配，称为 KG-RAG4SM。具体而言，KG-RAG4SM 引入了新颖的基于向量、基于图遍历和基于查询的图检索，以及一种混合方法和排名方案，可从外部大型知识图谱 (KG) 中识别最相关的子图。我们展示了基于 KG 的检索增强 LLM 能够为复杂的匹配案例生成更准确的结果，而无需任何重新训练。我们的实验结果表明，在 MIMIC 数据集上，KG-RAG4SM 在精度和 F1 得分方面分别比基于 LLM 的最先进 (SOTA) 方法 (例如 Jellyfish-8B) 高出 35.89% 和 30.50%；在 Synthea 数据集上，带有 GPT-4o-mini 的 KG-RAG4SM 在精度和 F1 得分方面分别比基于预训练语言模型 (PLM) 的 SOTA 方法 (例如 SMAT) 高出 69.20% 和 21.97%。结果还表明，我们的方法在端到端模式匹配方面效率更高，并且可以扩展以从大型 KG 中进行检索。我们对来自现实世界模式匹配场景的数据集的案例研究表明，我们的解决方案很好地缓解了 LLM 在模式匹配方面的幻觉问题。]]></description>
      <guid>https://arxiv.org/abs/2501.08686</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相位（范数）检索框架的连续方法</title>
      <link>https://arxiv.org/abs/2501.08927</link>
      <description><![CDATA[arXiv:2501.08927v1 公告类型：交叉 
摘要：本文研究了连续框架的性质，特别关注了希尔伯特空间中的相位恢复和范数恢复。我们引入了连续近 Riesz 基的概念，并证明了它们在可逆算子下的不变性。给出了连续框架的相位和范数恢复性质的一些等价条件。我们研究了扰动下相位恢复的稳定性。此外，研究了可分离希尔伯特空间的张量积框架，并建立了分量与其张量积之间的相位恢复和范数恢复性质的等价性。]]></description>
      <guid>https://arxiv.org/abs/2501.08927</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>融合自监督学习进行推荐</title>
      <link>https://arxiv.org/abs/2407.19692</link>
      <description><![CDATA[arXiv:2407.19692v3 公告类型：替换 
摘要：推荐系统广泛部署在各种网络环境中，而自监督学习 (SSL) 最近在该领域引起了广泛关注。对比学习 (CL) 因其生成自监督信号的强大能力而成为主要的 SSL 范式。主流的基于图对比学习 (GCL) 的方法通常通过各种数据增强技术创建对比视图来实现 CL。尽管这些方法是有效的，但我们认为仍然存在一些挑战。i) 数据增强（例如，丢弃边缘或添加噪声）需要额外的图卷积 (GCN) 或建模操作，这非常耗时并且可能会损害嵌入质量。ii) 现有的基于 CL 的方法使用传统的 CL 目标来捕获自监督信号。然而，很少有研究探索从更多角度获取 CL 目标，并试图融合来自这些 CL 目标的不同信号以提高推荐性能。
为了克服这些挑战，我们提出了一种用于推荐的高阶融合图对比学习 (HFGCL) 框架。具体来说，我们不是使用数据增强，而是使用来自 GCN 过程的高阶信息来创建对比视图。此外，为了整合来自各种 CL 目标的自监督信号，我们提出了一个高级 CL 目标。通过确保正对与来自两个对比视图的负样本保持距离，我们有效地融合了来自不同 CL 目标的自监督信号，从而增强了正对之间的相互信息。在三个公共数据集上的实验结果表明，与最先进的基线相比，HFGCL 具有更出色的推荐性能和效率。]]></description>
      <guid>https://arxiv.org/abs/2407.19692</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SupplyGraph：使用图神经网络进行供应链规划的基准数据集</title>
      <link>https://arxiv.org/abs/2401.15299</link>
      <description><![CDATA[arXiv:2401.15299v3 公告类型：replace-cross 
摘要：图神经网络 (GNN) 已在交通运输、生物信息学、语言处理和计算机视觉等不同领域获得关注。然而，在将 GNN 应用于供应链网络方面，研究明显不足。供应链网络本质上具有图结构，使其成为应用 GNN 方法的主要候选者。这为优化、预测和解决最复杂的供应链问题开辟了一个无限可能的世界。这种方法的一个主要缺点是缺乏现实世界的基准数据集来促进使用 GNN 研究和解决供应链问题。为了解决这个问题，我们提供了一个用于时间任务的真实基准数据集，该数据集来自孟加拉国一家领先的快速消费品公司，专注于生产目的的供应链规划。该数据集包括时间数据作为节点特征，以实现销售预测、生产计划和工厂问题的识别。通过利用该数据集，研究人员可以使用 GNN 来解决众多供应链问题，从而推动供应链分析和规划领域的发展。来源：https://github.com/CIOL-SUST/SupplyGraph]]></description>
      <guid>https://arxiv.org/abs/2401.15299</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>