<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 01 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Bioptic——基于疗效且不受靶点影响的小分子搜索引擎</title>
      <link>https://arxiv.org/abs/2406.14572</link>
      <description><![CDATA[arXiv:2406.14572v2 公告类型：replace-cross 
摘要：虚拟筛选最近取得的成功得益于大型模型和广泛的化学库。然而，将这些元素结合起来具有挑战性：模型越大，运行成本就越高，因此超大型库不可行。为了解决这个问题，我们开发了一种与目标无关、基于功效的分子搜索模型，该模型使我们能够找到具有相似生物活性的结构不同的分子。我们使用最佳实践来设计基于处理器优化的 SIMD 指令的快速检索系统，使我们能够以 100% 的召回率筛选超大型 40B Enamine REAL 库。我们对我们的模型和几种最先进的模型进行了广泛的基准测试，以了解新分子的速度性能和检索质量。]]></description>
      <guid>https://arxiv.org/abs/2406.14572</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:14 GMT</pubDate>
    </item>
    <item>
      <title>FlowVQA：使用流程图映射视觉问答中的多模态逻辑</title>
      <link>https://arxiv.org/abs/2406.19237</link>
      <description><![CDATA[arXiv:2406.19237v2 公告类型：replace-cross 
摘要：现有的视觉问答基准缺乏视觉基础和复杂性，特别是在评估空间推理技能方面。我们引入了 FlowVQA，这是一种新颖的基准，旨在评估视觉问答多模态语言模型以流程图为视觉背景进行推理的能力。FlowVQA 包含来自三个不同内容源的 2,272 张精心生成并经过人工验证的流程图图像，以及 22,413 个不同的问答对，以测试一系列推理任务，包括信息定位、决策和逻辑进展。我们使用各种策略对一套开源和专有多模态语言模型进行了彻底的基线评估，然后进行了方向偏差分析。结果强调了基准作为推进多模态建模领域的重要工具的潜力，为提高模型在视觉和逻辑推理任务中的性能提供了一个专注且具有挑战性的环境。]]></description>
      <guid>https://arxiv.org/abs/2406.19237</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:14 GMT</pubDate>
    </item>
    <item>
      <title>GEO：生成引擎优化</title>
      <link>https://arxiv.org/abs/2311.09735</link>
      <description><![CDATA[arXiv:2311.09735v3 公告类型：replace-cross 
摘要：大型语言模型 (LLM) 的出现开创了一种新的搜索引擎范式，它使用生成模型来收集和总结信息以回答用户查询。我们在生成引擎 (GE) 的统一框架下形式化的这项新兴技术可以生成准确和个性化的响应，迅速取代 Google 和 Bing 等传统搜索引擎。生成引擎通常通过合成来自多个来源的信息并使用 LLM 对其进行总结来满足查询。虽然这种转变显著提高了 $\textit{用户}$ 效用和 $\textit{生成搜索引擎}$ 流量，但它对第三个利益相关者——网站和内容创建者提出了巨大的挑战。鉴于生成引擎的黑箱和快速移动特性，内容创建者几乎无法控制其内容的显示时间以及方式。随着生成引擎的普及，我们必须确保创作者经济不会受到不利影响。为了解决这个问题，我们引入了生成引擎优化 (GEO)，这是第一个新范式，它通过灵活的黑盒优化框架来优化和定义可见性指标，从而帮助内容创作者提高其内容在生成引擎响应中的可见性。我们通过引入 GEO-bench（跨多个域的不同用户查询的大规模基准）以及用于回答这些查询的相关网络资源来促进系统评估。通过严格的评估，我们证明 GEO 可以将生成引擎响应的可见性提高高达 $40\%$。此外，我们表明这些策略的有效性因领域而异，强调了对特定领域的优化方法的需求。我们的工作开辟了信息发现系统的新领域，对生成引擎的开发人员和内容创作者都具有深远的影响。]]></description>
      <guid>https://arxiv.org/abs/2311.09735</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:13 GMT</pubDate>
    </item>
    <item>
      <title>JMLR：医学法学硕士与检索训练联合开展，提升推理能力和专业答疑能力</title>
      <link>https://arxiv.org/abs/2402.17887</link>
      <description><![CDATA[arXiv:2402.17887v4 公告类型：replace-cross 
摘要：大型语言模型 (LLM) 在医学知识获取和问答方面表现出了巨大的潜力。然而，即使经过特定领域的预训练，LLM 也可能产生幻觉并产生事实上不正确的结果。以前，检索增强生成 (RAG) 在解决幻觉方面取得的成功有限。与 RAG 中检索模型与 LLM 分开训练的先前方法不同，我们在微调阶段引入了 JMLR（联合训练 LLM 和信息检索）。同步训练机制增强了 JMLR 检索临床指南和利用医学知识推理和回答问题的能力，并减少了对计算资源的需求。我们在重要的医学问答应用上评估了 JMLR。我们的实验结果表明，在医学问答数据集上，JMLR-13B（70.5%）的表现优于之前使用传统预训练和微调的最先进的开源模型 Meditron-70B（68.9%）和使用 RAG 的 Llama2-13B（67.7%）。综合评估表明，JMLR-13B 比 Claude3-Opus 更能提高推理质量并减少幻觉。此外，JMLR-13B（148 GPU 小时）的训练速度也比 Meditron-70B（42630 GPU 小时）快得多。通过这项工作，我们为医疗保健提供了一种新的高效知识增强方法，展示了将检索和 LLM 培训集成到医学问答系统中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.17887</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:13 GMT</pubDate>
    </item>
    <item>
      <title>GRILLBot 实践：为适应性会话任务助手部署大型语言模型的经验教训和权衡</title>
      <link>https://arxiv.org/abs/2402.07647</link>
      <description><![CDATA[arXiv:2402.07647v2 公告类型：替换 
摘要：我们应对为复杂的现实任务构建现实世界的多模式助手的挑战。我们描述了开发和部署 GRILLBot 的实用性和挑战，GRILLBot 是 Alexa Prize TaskBot Challenge 中部署的领先系统（分别在 2022 年和 2023 年获得一等奖和二等奖）。基于我们的开放助手工具包 (OAT) 框架，我们提出了一种混合架构，该架构利用大型语言模型 (LLM) 和针对需要极低延迟的特定子任务进行调整的专用模型。OAT 允许我们以结构化和可部署的方式定义何时、如何以及应该使用哪些 LLM。对于基于知识的问答和实时任务适应，我们表明 LLM 推理能力优于任务上下文和世界知识，这超过了延迟问题。对于对话状态管理，我们实施了一种代码生成方法，并表明专门的小型模型的有效性为 84%，延迟降低了 100 倍。总体而言，我们在 Alexa TaskBot 挑战赛中为复杂的现实世界多模式环境中的用户部署传统模型和 LLM 提供了见解并讨论了权衡利弊。随着 LLM 变得更加强大和高效，这些经验将继续发展——从根本上重塑 OAT 和未来的助手架构。]]></description>
      <guid>https://arxiv.org/abs/2402.07647</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:12 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中的透明度、隐私和公平性</title>
      <link>https://arxiv.org/abs/2406.11323</link>
      <description><![CDATA[arXiv:2406.11323v2 公告类型：替换 
摘要：推荐系统已成为我们日常在线体验中不可或缺的一部分，也是人工智能和机器学习最广泛的应用之一。因此，可信人工智能的法规和要求（例如《欧洲人工智能法案》中包括透明度、隐私和公平性等概念）也与实践中推荐系统的设计高度相关。本论文从推荐系统的角度详细阐述了与这三个概念相关的方面，即：（i）透明度和认知模型，（ii）隐私和有限的偏好信息，以及（iii）推荐系统中的公平性和流行性偏见。具体而言，关于方面 (i)，我们强调了将心理学理论融入推荐系统透明设计过程的实用性。我们将这种类型的系统称为心理学信息推荐系统。在方面 (ii)，我们研究并解决了差异隐私推荐中准确性和隐私之间的权衡。我们设计了一种基于高效邻域重用概念的协同过滤新推荐方法，该方法减少了需要使用差分隐私保护的用户数量。此外，我们解决了在基于会话和冷启动推荐的设置中用户偏好信息（例如点击数据）可用性有限的相关问题。关于方面 (iii)，我们分析了推荐系统中的流行度偏差。我们发现某项的推荐频率与该项的流行度呈正相关。这也导致对流行内容不感兴趣的用户受到不公平对待。最后，我们使用基于代理的建模技​​术研究劳动力市场算法决策支持的长期公平性动态。]]></description>
      <guid>https://arxiv.org/abs/2406.11323</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:12 GMT</pubDate>
    </item>
    <item>
      <title>具有最优传输的交互式主题模型</title>
      <link>https://arxiv.org/abs/2406.19928</link>
      <description><![CDATA[arXiv:2406.19928v1 公告类型：交叉 
摘要：主题模型被广泛用于分析文档集合。虽然当分析师不熟悉语料库时，它们对于发现语料库中的潜在主题很有价值，但分析师通常也从了解语料库中的内容开始。这可能是通过从初次浏览语料库中获得的类别，或者希望通过从高级理论框架（例如政治意识形态）派生的预定义类别集来分析语料库。在这些情况下，分析师希望采用一种主题建模方法，该方法结合了他们对语料库的理解，同时支持与模型的各种形式的交互。在这项工作中，我们提出了 EdTM，作为一种标签名称监督主题建模的方法。EdTM 将主题建模建模为一个分配问题，同时利用基于 LM/LLM 的文档主题亲和力并使用最佳传输进行全局连贯的主题分配。在实验中，我们展示了我们的框架与少样本 LLM 分类器以及基于聚类和 LDA 的主题模型相比的有效性。此外，我们还展示了 EdTM 能够整合各种形式的分析师反馈，同时保持对嘈杂分析师输入的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2406.19928</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:11 GMT</pubDate>
    </item>
    <item>
      <title>用于大型非结构化法律文件的分类及其解释的分层神经框架</title>
      <link>https://arxiv.org/abs/2309.10563</link>
      <description><![CDATA[arXiv:2309.10563v3 公告类型：替换 
摘要：自动法律判决预测及其解释受到长篇案例文件问题的影响，这些文件通常超过数万字，并且结构不统一。从此类文件中预测判决并提取其解释是一项艰巨的任务，对于没有结构注释的文件更是如此。我们将此问题定义为“稀缺的带注释的法律文件”，并使用基于深度学习的分类框架（我们称之为 MESc；“基于多阶段编码器的监督聚类”；）探索它们缺乏结构信息和篇幅过长的问题，以进行判断预测。我们探索了具有数十亿个参数的 LLM（GPT-Neo 和 GPT-J）对法律文本的适应性及其域内（法律）迁移学习能力。除此之外，我们还将它们的性能和适应性与 MESc 进行了比较，并比较了结合其最后一层的嵌入的影响。对于此类分层模型，我们还提出了一种解释提取算法，称为 ORSE（基于遮挡敏感度的相关句子提取器）；该算法基于模型的输入遮挡敏感度，使用文档中最相关的句子来解释预测。我们探索了这些方法，并使用 ILDC 数据集和 LexGLUE 数据集的子集对来自印度、欧盟和美国的法律文件进行了广泛的实验和消融研究，以测试其有效性。MESc 的总性能至少比之前最先进的方法高出约 2 分，而应用于 MESc 的 ORSE 的总性能平均比基线可解释性分数高出 50%。]]></description>
      <guid>https://arxiv.org/abs/2309.10563</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:11 GMT</pubDate>
    </item>
    <item>
      <title>用于延迟受限语义通信的无速率随机编码</title>
      <link>https://arxiv.org/abs/2406.19804</link>
      <description><![CDATA[arXiv:2406.19804v1 公告类型：新
摘要：我们从无速率的角度考虑了具有失真和感知约束的联合源信道编码问题，其目的是解决不确定信道上传输的可靠性（失真/感知）和有效性（速率）之间的平衡。我们找到了具有上述两个约束的可实现联合源信道编码速率的新的有限块长度界限。为了实现 JSCC 编码的卓越无速率特性，我们对各种有限块长度代码进行了多级优化。基于这两者，我们提出了一种新的 JSCC 编码方案，称为无速率随机编码 (RSC)。我们通过实验证明，所提出的 RSC 可以实现可变的传输速率，同时保持失真和感知之间的良好平衡。]]></description>
      <guid>https://arxiv.org/abs/2406.19804</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:10 GMT</pubDate>
    </item>
    <item>
      <title>TocBERT：使用双向 Transformer 提取医学文档结构</title>
      <link>https://arxiv.org/abs/2406.19526</link>
      <description><![CDATA[arXiv:2406.19526v1 公告类型：交叉 
摘要：文本分割在自然语言处理 (NLP) 领域至关重要。它在信息检索和文档摘要等多个 NLP 下游任务中发挥着重要作用。在这项工作中，我们提出了一种新的解决方案，即 TocBERT，用于使用双向转换器对文本进行分割。TocBERT 表示一种监督解决方案，经过训练可以从语义表示中检测标题和副标题。此任务被表述为命名实体识别 (NER) 问题。该解决方案已应用于医学文本分割用例，其中 Bio-ClinicalBERT 模型经过微调以分割 MIMIC-III 数据集的出院摘要。TocBERT 的性能已在 250 条注释的人工标记的地面实况语料库上进行了评估。在线性文本分割问题上，其 F1 得分为 84.6%，在分层文本分割问题上，其 F1 得分为 72.8%。其表现优于精心设计的基于规则的解决方案，尤其是在区分标题和副标题方面。]]></description>
      <guid>https://arxiv.org/abs/2406.19526</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:10 GMT</pubDate>
    </item>
    <item>
      <title>Doc2Token：通过预测电子商务搜索中缺失的标记来弥补词汇差距</title>
      <link>https://arxiv.org/abs/2406.19647</link>
      <description><![CDATA[arXiv:2406.19647v1 公告类型：新
摘要：解决信息检索中的“词汇不匹配”问题是电子商务搜索引擎面临的一个核心挑战，因为产品页面经常会遗漏客户搜索的重要关键词。Doc2Query[1] 是一种流行的文档扩展技术，它可以预测文档的搜索查询，并将预测的查询包含在文档中以供检索。但是，这种方法对于电子商务搜索来说效率低下，因为预测的查询标记通常已经存在于文档中。在本文中，我们提出了 Doc2Token，这是一种预测文档中缺失的相关标记（而不是查询）并将这些标记包含在文档中以供检索的技术。对于预测缺失标记的任务，我们引入了一个新的指标“新颖的 ROUGE 分数”。Doc2Token 在新颖的 ROUGE 分数和预测多样性方面被证明优于 Doc2Query。 Doc2Token 还通过减少训练和推理时间实现了效率提升。我们将该功能部署到生产中，并在在线 A/B 测试中观察到了显著的收入增长，并在 Walmart.com 上全面推出了该功能。
[1] R. Nogueira、W. Yang、J. Lin、K. Cho，通过查询预测进行文档扩展，arXiv 预印本 arXiv:1904.08375 (2019)]]></description>
      <guid>https://arxiv.org/abs/2406.19647</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:09 GMT</pubDate>
    </item>
    <item>
      <title>通过知识引导的案例重构学习可解释的法律案例检索</title>
      <link>https://arxiv.org/abs/2406.19760</link>
      <description><![CDATA[arXiv:2406.19760v1 公告类型：新
摘要：法律案例检索对于寻找类似案件对于维护司法公正至关重要。与一般的网络搜索不同，法律案例检索涉及处理冗长、复杂且高度专业化的法律文件。该领域的现有方法往往忽视了法律专家知识的结合，而这对于准确理解和建模法律案例至关重要，导致检索性能不令人满意。本文介绍了 KELLER，一种基于大型语言模型 (LLM) 的法律知识引导的案例重构方法，用于有效且可解释的法律案例检索。通过结合有关犯罪和法律文章的专业法律知识，我们使大型语言模型能够准确地将原始法律案例重构为简明的犯罪子事实，其中包含案件的基本信息。在两个法律案例检索基准上进行的大量实验表明，KELLER 在复杂法律案例查询上的检索性能和鲁棒性优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2406.19760</guid>
      <pubDate>Mon, 01 Jul 2024 06:22:09 GMT</pubDate>
    </item>
    </channel>
</rss>