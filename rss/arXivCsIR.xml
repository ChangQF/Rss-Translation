<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于日语法律文本检索的自适应两阶段微调法学硕士</title>
      <link>https://arxiv.org/abs/2412.13205</link>
      <description><![CDATA[arXiv:2412.13205v1 公告类型：新
摘要：文本检索 (TR) 涉及从大型存储库中查找和检索与用户查询相关的基于文本的内容，并应用于法律文件检索等实际场景。虽然大多数现有研究都集中在英语上，但有限的工作涉及日语背景。在本文中，我们介绍了一个专门为日语法律背景设计的新数据集，并提出了一种针对该领域的新型两阶段管道。
在第一阶段，该模型学习对全局背景的广泛理解，增强其泛化和对各种查询的适应性。在第二阶段，该模型经过微调以解决特定于法律场景的复杂查询。进行了广泛的实验以证明我们的方法的卓越性能，其性能优于现有基线。
此外，我们的管道在英语环境中被证明是有效的，超越了 MS MARCO 数据集上的可比基线。我们已在 GitHub 上公开了我们的代码，并且可以通过 HuggingFace 访问模型检查点。]]></description>
      <guid>https://arxiv.org/abs/2412.13205</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>JudgeBlender：集成判断以进行自动相关性评估</title>
      <link>https://arxiv.org/abs/2412.13268</link>
      <description><![CDATA[arXiv:2412.13268v1 公告类型：新
摘要：检索系统的有效训练和评估需要大量的相关性判断，这些判断传统上是从人类评估员那里收集的——这个过程既昂贵又耗时。大型语言模型 (LLM) 在为搜索任务生成相关性标签方面表现出色，为手动评估提供了潜在的替代方案。当前的方法通常依赖于单个 LLM，例如 GPT-4，尽管它很有效，但价格昂贵且容易出现模型内偏差，这可能会有利于利用类似模型的系统。在这项工作中，我们引入了 JudgeBlender，这是一个使用较小的开源模型来提供相关性判断的框架，它结合了多个 LLM（LLMBlender）或多个提示（PromptBlender）的评估。通过利用 LLMJudge 基准 [18]，我们将 JudgeBlender 与最先进的方法和 LLMJudge 挑战赛中的最佳表现者进行了比较。我们的结果表明，JudgeBlender 取得了具有竞争力的表现，表明非常大的模型对于可靠的相关性评估通常是不必要的。]]></description>
      <guid>https://arxiv.org/abs/2412.13268</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>轻量级但细粒度：用于共享账户顺序推荐的具有子空间对齐的图形胶囊卷积网络</title>
      <link>https://arxiv.org/abs/2412.13408</link>
      <description><![CDATA[arXiv:2412.13408v1 公告类型：新 
摘要：共享账户顺序推荐 (SSR) 旨在为具有不同顺序偏好的多个用户共享的账户提供个性化推荐。先前对 SSR 的研究难以捕捉共享帐户混合序列中交互与不同潜在用户之间的细粒度关联。此外，大多数现有的 SSR 方法（例如基于 RNN 或基于 GCN 的方法）具有二次计算复杂度，阻碍了在资源受限的设备上部署 SSR。为此，我们提出了一种用于共享帐户顺序推荐的具有子空间对齐的轻量级图胶囊卷积网络，名为 LightGC$^2$N。具体来说，我们设计了一个轻量级图胶囊卷积网络。它通过在胶囊图上仔细传播消息来促进交互和潜在用户之间的细粒度匹配。此外，我们提出了一种有效的子空间对齐方法。该方法细化了序列表示，然后将其与潜在用户的精细聚类偏好对齐。在四个真实数据集上的实验结果表明，LightGC$^2$N 在准确率和效率方面优于九种最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.13408</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型增强推荐系统：分类、趋势、应用和未来</title>
      <link>https://arxiv.org/abs/2412.13432</link>
      <description><![CDATA[arXiv:2412.13432v1 公告类型：新
摘要：大型语言模型 (LLM) 在各个领域都具有变革潜力，包括推荐系统 (RS)。已经有少数研究专注于通过 LLM 增强 RS。然而，以前的努力主要集中在 LLM 作为 RS，这可能会面临 LLM 不容忍推理成本的挑战。最近，将 LLM 集成到 RS 中，称为 LLM 增强推荐系统 (LLMERS)，由于其有可能解决实际应用中的延迟和内存限制而引起了人们的极大兴趣。本文全面介绍了旨在利用 LLM 增强 RS 功能的最新研究成果。我们发现该领域的一个关键转变是将 LLM 纳入在线系统，特别是避免在推理过程中使用它们。我们的调查根据要增强的 RS 模型的组件将现有的 LLMERS 方法分为三种主要类型：知识增强、交互增强和模型增强。我们对每个类别进行了深入分析，讨论了近期研究的方法、挑战和贡献。此外，我们还重点介绍了几个有望进一步推动 LLMERS 领域的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2412.13432</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型弥补知识感知推荐中用户端的知识差距</title>
      <link>https://arxiv.org/abs/2412.13544</link>
      <description><![CDATA[arXiv:2412.13544v1 公告类型：新 
摘要：近年来，知识图谱作为商品端辅助信息被集成到推荐系统中，提高了推荐准确性。然而，由于用户端特征的粒度不当和固有的稀缺性，构建和集成结构化用户端知识仍然是一项重大挑战。大型语言模型 (LLM) 的最新进展利用其对人类行为的理解和广泛的现实世界知识，提供了弥合这一差距的潜力。然而，将 LLM 生成的信息集成到推荐系统中存在挑战，包括噪声信息的风险和需要额外的知识转移。在本文中，我们提出了一种基于 LLM 的用户端知识推理方法以及精心设计的推荐框架来应对这些挑战。我们的方法使用 LLM 根据历史行为推断用户兴趣，将这些用户端信息与商品端和协作数据相结合以构建混合结构：协作兴趣知识图 (CIKG)。此外，我们提出了一个基于 CIKG 的推荐框架，其中包括用户兴趣重建模块和跨域对比学习模块，以减轻潜在噪音并促进知识转移。我们在三个真实数据集上进行了广泛的实验，以验证我们方法的有效性。与竞争基线相比，我们的方法实现了最先进的性能，特别是对于具有稀疏交互的用户。]]></description>
      <guid>https://arxiv.org/abs/2412.13544</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义融合：通过两阶段对齐和行为语义标记化协调推荐系统</title>
      <link>https://arxiv.org/abs/2412.13771</link>
      <description><![CDATA[arXiv:2412.13771v1 公告类型：新
摘要：大型语言模型 (LLM) 具有出色的推理能力，善于从历史行为中辨别出深刻的用户兴趣，从而为推荐系统的进步提供了一条有希望的途径。然而，推荐系统中常见的稀疏协作语义与 LLM 中的密集标记表示之间存在显着差异。在我们的研究中，我们提出了一个新颖的框架，将传统推荐模型与 LLM 的强大功能完美地融合在一起。我们通过提出的对齐标记化模块将 ItemID 转换为与 LLM 空间在语义上对齐的序列来启动这种集成。此外，我们设计了一系列专门的监督学习任务，旨在将协作信号与自然语言语义的微妙之处结合起来。为了确保实际适用性，我们通过预先缓存每个用户的前 K 个结果来优化在线推理，从而减少延迟并提高效率。大量实验证据表明，我们的模型显著提高了召回率指标，并显示出推荐系统显著的可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2412.13771</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>异构图协同过滤</title>
      <link>https://arxiv.org/abs/2412.13825</link>
      <description><![CDATA[arXiv:2412.13825v1 公告类型：新
摘要：对于现代推荐系统，使用低维潜在表示根据观察到的交互来嵌入用户和项目已经变得很普遍。然而，许多现有的推荐模型主要针对粗粒度和同质交互而设计，这限制了它们在两个关键维度上的有效性。首先，这些模型未能利用存在于不同类型的用户行为（例如页面浏览、收藏、评论和购买）中的关系依赖关系。其次，他们难以捕捉驱动用户交互模式的细粒度潜在因素。为了解决这些限制，我们提出了一个异构图协同过滤模型 MixRec，它擅长解开用户的多行为交互模式并揭示每个行为背后的潜在意图因素。我们的模型通过结合意图解开和多行为建模来实现这一点，并由参数化的异构超图架构实现。此外，我们引入了一种新颖的对比学习范式，该范式自适应地探索自监督数据增强的优势，从而增强模型对数据稀疏性和关系异质性表现力的弹性。为了验证 MixRec 的有效性，我们在三个公共数据集上进行了广泛的实验。结果清楚地证明了其卓越的性能，远远优于各种最先进的基线。我们的模型是开源的，可在以下网址获取：https://github.com/HKUDS/MixRec。]]></description>
      <guid>https://arxiv.org/abs/2412.13825</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>也许你正在寻找 CroQS：用​​于文本到图像检索的跨模式查询建议</title>
      <link>https://arxiv.org/abs/2412.13834</link>
      <description><![CDATA[arXiv:2412.13834v1 公告类型：新
摘要：查询建议是信息检索中广泛采用的一种技术，它增强了系统的交互性和文档集合的浏览体验。在跨模态检索中，许多工作都侧重于从自然语言查询中检索相关项目，而很少有人探索查询建议解决方案。在这项工作中，我们解决了跨模态检索中的查询建议问题，引入了一项新任务，该任务侧重于建议探索视觉上一致的集合子集所需的最小文本修改，遵循“也许你正在寻找”的前提。为了促进方法的评估和开发，我们提出了一个名为 CroQS 的定制基准。该数据集包括初始查询、分组结果集和每个组的人为定义的建议查询。我们建立了专用指标来严格评估各种方法在此任务上的性能，测量代表性、集群特异性以及建议查询与原始查询的相似性。相关领域的基准方法（例如图像字幕和内容摘要）已针对此任务进行了调整，以提供参考性能分数。尽管与人类表现相差甚远，但我们的实验表明，基于 LLM 和基于字幕的方法在 CroQS 上都取得了具有竞争力的结果，相对于初始查询，聚类特异性的召回率提高了 115% 以上，代表性 mAP 提高了 52% 以上。数据集、基准方法的实现以及包含我们实验的笔记本可在此处获得：https://paciosoft.com/CroQS-benchmark/]]></description>
      <guid>https://arxiv.org/abs/2412.13834</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CRM：可控条件的检索模型</title>
      <link>https://arxiv.org/abs/2412.13844</link>
      <description><![CDATA[arXiv:2412.13844v1 公告类型：新
摘要：推荐系统（RecSys）旨在将用户与大量候选项目联系起来，同时与平台的业务目标保持一致。典型的工业RecSys由两个主要阶段组成，即检索和排名：（1）检索阶段旨在搜索数百个满足用户兴趣的项目候选；（2）基于检索到的项目，排名阶段旨在通过对每个项目候选进行多个目标估计来选择最佳的十几个项目，包括分类和回归目标。与排名模型相比，检索模型在推理过程中缺乏项目候选信息，因此检索模型通常仅通过分类目标（例如点击率）进行训练，但未能结合回归目标（例如预期观看时间），这限制了检索的有效性。在本文中，我们提出了可控检索模型 (CRM)，将回归信息作为条件特征集成到双塔检索范式中。此修改使检索阶段能够填补与排名模型的目标差距，增强了检索模型有效搜索满足用户兴趣和条件的项目候选的能力。我们通过真实的 A/B 测试验证了 CRM 的有效性，并展示了其在快手短视频推荐系统中的成功部署，该系统服务于超过 4 亿用户。]]></description>
      <guid>https://arxiv.org/abs/2412.13844</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 IBM Watson 服务的认知构思支持框架</title>
      <link>https://arxiv.org/abs/2412.14025</link>
      <description><![CDATA[arXiv:2412.14025v1 公告类型：新
摘要：创意生成是组织创新的核心活动。所产生创意的创造力不仅取决于从组织知识库中检索到的知识，还取决于从其他资源中检索到的外部知识。不幸的是，由于搜索和检索机制的能力有限，尤其是在处理非结构化数据时，组织通常无法有效利用知识库中的知识。在本文中，我们提出了一种使用 IBM Watson DeepQA 服务的新型创意认知支持框架。IBM Watson 是一个问答系统，它模仿人类的认知能力来检索和排序信息。所提出的框架基于联想记忆 (SIAM) 模型中的创意搜索，以帮助组织通过发现检索到的数据之间的新关系来开发创意。为了评估所提出系统的有效性，使用一组既定的创造力标准来选择和评估所产生的想法。]]></description>
      <guid>https://arxiv.org/abs/2412.14025</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文档的信息论生成聚类</title>
      <link>https://arxiv.org/abs/2412.13534</link>
      <description><![CDATA[arXiv:2412.13534v1 公告类型：交叉 
摘要：我们提出了生成聚类（GC）来对一组文档 $\mathrm{X}$ 进行聚类，方法是使用由大型语言模型 (LLM) 生成的文本 $\mathrm{Y}$，而不是对原始文档 $\mathrm{X}$ 进行聚类。由于 LLM 提供概率分布，因此可以通过 KL 散度以信息论方式严格定义两个文档之间的相似性。我们还提出了一种使用重要性抽样的自然、新颖的聚类算法。我们表明 GC 实现了最先进的性能，通常比任何以前的聚类方法都好很多。此外，我们展示了生成文档检索的一个应用，其中通过层次聚类对文档进行索引，我们的方法提高了检索准确性。]]></description>
      <guid>https://arxiv.org/abs/2412.13534</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>像素级视觉实体链接的反向区域到实体注释</title>
      <link>https://arxiv.org/abs/2412.13614</link>
      <description><![CDATA[arXiv:2412.13614v1 公告类型：交叉 
摘要：视觉实体链接 (VEL) 是实现细粒度视觉理解的关键任务，将图像中的对象 (视觉提及) 与知识库中的实体进行匹配。以前的 VEL 任务依赖于文本输入，但为复杂场景编写查询可能具有挑战性。点击或边界框等视觉输入提供了更方便的替代方案。因此，我们提出了一项新任务，即像素级视觉实体链接 (PL-VEL)，它使用视觉输入中的像素掩码来引用对象，补充了 VEL 的引用方法。为了促进这项任务的研究，我们通过一个完全自动化的反向区域实体注释框架构建了 MaskOVEN-Wiki 数据集。该数据集包含超过 500 万个注释，将像素级区域与实体级标签对齐，这将推动视觉理解向细粒度发展。此外，由于像素掩码对应于图像中的语义区域，我们通过视觉语义标记化方法增强了先前的补丁交互注意力和区域交互注意力。人工评估结果表明，反向标注框架的标注成功率为 94.8%。实验结果表明，在该数据集上训练的模型与零样本模型相比，准确率提高了 18 个百分点。此外，语义标记化方法的准确率比训练基线提高了 5 个百分点。]]></description>
      <guid>https://arxiv.org/abs/2412.13614</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RAG-RewardBench：对检索增强生成中的奖励模型进行基准测试以实现偏好对齐</title>
      <link>https://arxiv.org/abs/2412.13746</link>
      <description><![CDATA[arXiv:2412.13746v1 公告类型：交叉 
摘要：尽管现有的检索增强语言模型 (RALM) 在提供可信响应和可靠来源方面取得了重大进展，但它们往往忽视了与人类偏好的有效对齐。在对齐过程中，奖励模型 (RM) 充当人类价值观指导优化的重要代理。然而，如何评估和选择可靠的 RM 进行 RALM 中的偏好对齐仍不清楚。为此，我们提出了 RAG-RewardBench，这是第一个在 RAG 设置中评估 RM 的基准。首先，我们设计了四个关键且具有挑战性的 RAG 特定场景来评估 RM，包括多跳推理、细粒度引用、适当弃权和冲突鲁棒性。然后，我们结合了 18 个 RAG 子集、6 个检索器和 24 个 RALM 来增加数据源的多样性。最后，我们采用 LLM-as-a-judge 方法来提高偏好注释的效率和有效性，与人工注释表现出很强的相关性。基于 RAG-RewardBench，我们对 45 个 RM 进行了全面评估，并揭示了它们在 RAG 场景中的局限性。此外，我们还发现，现有的经过训练的 RALM 在偏好对齐方面几乎没有任何改进，这凸显了转向偏好对齐训练的必要性。我们在 https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ 公开发布了我们的基准和代码，以供将来使用。]]></description>
      <guid>https://arxiv.org/abs/2412.13746</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态检索中的对抗性中心</title>
      <link>https://arxiv.org/abs/2412.14113</link>
      <description><![CDATA[arXiv:2412.14113v1 公告类型：交叉 
摘要：Hubness 是高维向量空间中的一种现象，其中自然分布中的单个点异常接近许多其他点。这是信息检索中一个众所周知的问题，它导致某些项目意外（错误地）与许多查询相关。在本文中，我们研究了攻击者如何利用 hubness 将多模态检索系统中的任何图像或音频输入转变为对抗性中心。对抗性中心可用于注入通用对抗性内容（例如垃圾邮件），这些内容将响应数千个不同的查询进行检索，以及针对与攻击者选择的特定概念相关的查询进行有针对性的攻击。我们提出了一种创建对抗性中心的方法，并根据流行的矢量数据库 Pinecone 的教程在基准多模态检索数据集和图像到图像检索系统上评估生成的中心。例如，在文本标题到图像检索中，单个对抗性中心在 25,000 个测试查询中超过 21,000 个被检索为最相关的前 1 个图像（相比之下，最常见的自然中心仅在 102 个查询中是前 1 个响应）。我们还调查了减轻自然中心的技术是否是针对对抗性中心的有效防御，并表明它们对针对与特定概念相关的查询的中心无效。]]></description>
      <guid>https://arxiv.org/abs/2412.14113</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DELRec：提炼序列模式以增强基于 LLM 的序列推荐</title>
      <link>https://arxiv.org/abs/2406.11156</link>
      <description><![CDATA[arXiv:2406.11156v4 公告类型：替换 
摘要：顺序推荐 (SR) 任务旨在通过学习用户的行为序列并捕捉用户过去交互与其不断变化的偏好之间的联系来预测用户的下一次交互。传统的 SR 模型通常只关注捕获训练数据中的顺序模式，而忽略了来自外部来源的项目标题中嵌入的更广泛的上下文和语义信息。这限制了它们的预测能力和适应性。大型语言模型 (LLM) 最近在 SR 任务中显示出良好的前景，因为它们具有先进的理解能力和强大的泛化能力。研究人员试图通过结合传统 SR 模型中的信息来增强基于 LLM 的推荐性能。然而，以前的方法遇到了一些问题，例如 1) 文本信息有限导致推荐性能不佳，2) LLM 对传统 SR 模型信息的理解和利用不完整，3) 基于 LLM 的方法过于复杂且可解释性低。为了提高基于 LLM 的 SR 的性能，我们提出了一个新框架，即提炼序列模式以增强基于 LLM 的序列推荐 (DELRec)，旨在从传统 SR 模型中提取知识，并使 LLM 能够轻松理解和利用提取的知识来提供更有效的 SR。DELRec 包含两个主要阶段：1）从传统 SR 模型中提取模式，重点是通过两种精心设计的策略使用软提示提取传统 SR 模型表现出的行为模式；2）基于 LLM 的序列推荐，旨在微调 LLM 以有效地使用提炼的辅助信息来执行 SR 任务。在四个真实数据集上进行的大量实验结果验证了 DELRec 框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.11156</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>