<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>后用户主义推荐系统：一份宣言</title>
      <link>https://arxiv.org/abs/2410.11870</link>
      <description><![CDATA[arXiv:2410.11870v1 公告类型：新
摘要：我们将用户主义推荐定义为一种仅以用户和系统之间的关系为框架的推荐系统方法。后用户主义推荐提出了一个更大的关系领域，利益相关者嵌入其中，并将推荐功能（可能将创作者与观众联系起来）与生成媒体区分开来。我们认为，在生成媒体时代，用户主义推荐与个性化媒体生成变得难以区分，因此后用户主义推荐是推荐系统研究的唯一前进道路。]]></description>
      <guid>https://arxiv.org/abs/2410.11870</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三模态融合：将视觉、文本和图形数据与大型语言模型相结合，以实现多行为推荐</title>
      <link>https://arxiv.org/abs/2410.12228</link>
      <description><![CDATA[arXiv:2410.12228v1 公告类型：新
摘要：整合多种数据模态对于提高个性化推荐系统的性能至关重要。传统模型通常依赖于单一数据源，缺乏准确捕捉项目特征和用户行为的多面性所需的深度。本文介绍了一种新的多行为推荐框架，通过与大型语言模型 (LLM) 对齐，利用三模态（即视觉、文本和图形数据）的融合。通过结合视觉信息，我们可以捕捉上下文和美学项目特征；文本数据可以详细了解用户兴趣和项目特征；图形数据阐明了项目行为异构图中的关系。我们提出的模型称为三模态融合 (TMF)，利用 LLM 的强大功能来对齐和集成这三种模态，实现对用户行为的全面表示。LLM 以自然语言对用户的交互进行建模，包括行为和项目特征。最初，我们仅使用基于自然语言的提示来预热 LLM。然后，我们设计了基于交叉注意和自注意机制的模态融合模块，将来自其他模型的不同模态集成到同一个嵌入空间中，并将它们合并到 LLM 中。大量实验证明了我们的方法在提高推荐准确率方面的有效性。进一步的消融研究验证了我们模型设计的有效性和 TMF 的优势。]]></description>
      <guid>https://arxiv.org/abs/2410.12228</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用推荐系统的大型语言模型理解知识图谱</title>
      <link>https://arxiv.org/abs/2410.12229</link>
      <description><![CDATA[arXiv:2410.12229v1 公告类型：新
摘要：最近，知识图谱 (KG) 的引入通过促进发现项目之间的潜在关联，大大推进了推荐系统的发展。然而，现有的方法仍然面临一些限制。首先，大多数 KG 都存在事实缺失或范围有限的问题。这可能导致知识表示出现偏差，从而限制模型的性能。其次，现有方法通常将文本信息转换为 ID，导致不同项目之间失去自然语义联系。第三，由于现有方法的逐层信息传播机制效率低下，容易引入大量噪音，因此难以捕捉全局 KG 中的高阶关系。为了解决这些限制，我们提出了一种名为 CoLaKG 的新方法，该方法利用大型语言模型 (LLM) 进行知识感知推荐。LLM 广泛的世界知识和卓越的推理能力使它们能够补充 KG。此外，LLM 强大的文本理解能力可以更好地理解语义信息。基于此，我们首先从知识图谱中提取以每个项目为中心的子图，并将其转换为 LLM 的文本输入。然后，LLM 输出对这些以项目为中心的子图的理解，随后将其转换为语义嵌入。此外，为了利用知识图谱的全局信息，我们使用这些语义嵌入构建项目-项目图，该图可以直接捕获项目之间的高阶关联。通过我们设计的表示对齐和邻居增强模块，语义嵌入和项目-项目图中的结构信息都有效地集成到推荐模型中。在四个真实数据集上进行的大量实验证明了我们方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2410.12229</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有潜在混杂因素的推荐系统的多原因去混杂</title>
      <link>https://arxiv.org/abs/2410.12366</link>
      <description><![CDATA[arXiv:2410.12366v1 公告类型：新 
摘要：在推荐系统中，各种潜在混杂因素（例如，用户的社交环境和物品的公众吸引力）可以以不同的方式影响用户行为、物品曝光和反馈。这些因素可能会直接或间接地影响用户反馈，并且通常在物品或用户之间共享，从而使它们成为多原因潜在混杂因素。然而，现有的方法通常无法同时考虑用户与其反馈之间的潜在混杂因素以及物品与用户反馈之间的潜在混杂因素。为了解决多原因潜在混杂因素的问题，我们提出了一种具有潜在混杂因素的推荐系统的多原因去混杂方法（MCDCF）。MCDCF 利用多原因因果效应估计，使用用户行为数据来学习与用户和物品相关的潜在混杂因素的替代品。具体来说，MCDCF 将用户与之交互的多个项目和与项目交互的多个用户视为处理变量，使其能够学习影响用户与其反馈之间以及项目与用户反馈之间因果关系估计的潜在混杂因素的替代品。此外，我们从理论上证明了 MCDCF 方法的合理性。在三个真实数据集上进行的大量实验表明，我们的 MCDCF 方法可以有效恢复与用户和项目相关的潜在混杂因素，从而减少偏差并提高推荐准确性。]]></description>
      <guid>https://arxiv.org/abs/2410.12366</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QUIDS：通过对偶空间建模生成查询意图</title>
      <link>https://arxiv.org/abs/2410.12400</link>
      <description><![CDATA[arXiv:2410.12400v1 公告类型：新
摘要：查询理解是信息检索 (IR) 的重要组成部分，旨在识别文本查询的潜在搜索意图。然而，大多数现有方法将此任务过度简化为查询分类或聚类，无法完全捕捉查询背后的细微意图。在本文中，我们解决了查询意图生成的任务：使用给定查询的相关和不相关文档自动生成搜索查询的详细和精确的意图描述。这些意图描述可以帮助用户理解搜索引擎为何认为排名靠前的文档相关，并为检索过程提供更多透明度。我们提出了一个双空间模型，该模型使用返回文档中的语义相关性和不相关性信息来解释对查询意图的理解。具体而言，在编码过程中，我们在表示空间中投射、分离和区分相关和不相关的文档。然后，我们在新的解缠空间中引入了语义解耦模型，其中无关信息的语义从相关空间中删除，确保只捕获基本和相关的意图。此过程细化了对查询的理解，并为搜索结果提供了更准确的解释。在基准数据上进行的实验表明，我们的方法可以生成高质量的查询意图描述，其表现优于此任务的现有方法以及最先进的基于查询的摘要方法。注意力得分的 token 级可视化表明，我们的模型有效地减少了对不相关意图主题的关注。我们的研究结果为查询意图生成开辟了有希望的研究和应用方向，特别是在探索性搜索中。]]></description>
      <guid>https://arxiv.org/abs/2410.12400</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻推荐系统中的双重潜在混杂偏差</title>
      <link>https://arxiv.org/abs/2410.12451</link>
      <description><![CDATA[arXiv:2410.12451v1 公告类型：新
摘要：推荐系统广泛应用于各个领域，以预测用户对个性化体验的偏好，并增强用户参与度和满意度。然而，传统的推荐系统因混杂偏差而变得复杂，特别是在存在影响项目曝光和用户反馈的潜在混杂因素的情况下。现有的去偏方法通常无法捕捉交互数据中潜在混杂因素引起的复杂交互，尤其是当双重潜在混杂因素同时影响用户和项目端时。为了解决这个问题，我们提出了一种新颖的去偏方法，该方法联合整合了工具变量 (IV) 方法和可识别变分自动编码器 (iVAE)，用于推荐系统中的去偏表示学习，称为 IViDR。具体来说，IViDR 利用用户特征的嵌入作为 IV 来解决项目和用户反馈之间的潜在混杂因素造成的混杂偏差，并重建项目的嵌入以获得去偏的交互数据。此外，IViDR 采用可识别变分自动编码器 (iVAE) 从原始和去偏的交互数据中推断出项目曝光和用户反馈之间潜在混杂因素的可识别表示。此外，我们还对使用 IV 的合理性和潜在表示的可识别性进行了理论分析。在合成数据集和真实世界数据集上进行的大量实验表明，IViDR 在减少偏差和提供可靠建议方面优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.12451</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一经济和语言模型以增强石油市场的情绪分析</title>
      <link>https://arxiv.org/abs/2410.12473</link>
      <description><![CDATA[arXiv:2410.12473v1 公告类型：新 
摘要：原油是全球经济的重要组成部分，其价格受经济趋势、政治事件和自然灾害等各种因素的影响。基于历史数据的传统预测方法在预测方面有其局限性，但自然语言处理的最新进展为基于事件的分析带来了新的可能性。特别是，语言模型 (LM) 及其进步，生成式预训练转换器 (GPT)，已显示出对大量自然语言进行分类的潜力。然而，这些 LM 通常难以处理特定领域的术语，从而限制了它们在原油领域的有效性。为了解决这一差距，我们推出了 CrudeBERT，这是一种专门针对原油市场的微调 LM。结果表明，CrudeBERT 的情绪得分与 WTI 期货曲线更加接近，并显着增强了价格预测，强调了将经济原则融入 LM 的关键作用。]]></description>
      <guid>https://arxiv.org/abs/2410.12473</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RosePO：将法学硕士推荐人与人文价值观相结合</title>
      <link>https://arxiv.org/abs/2410.12519</link>
      <description><![CDATA[arXiv:2410.12519v1 公告类型：新
摘要：最近，人们对利用大型语言模型 (LLM) 进行推荐系统的兴趣日益浓厚，这种系统通常通过监督微调 (SFT) 将预训练的 LLM 适应推荐场景。然而，预训练和 SFT 阶段都无法明确模拟用户对不同项目的偏好的比较关系。为了构建一个“有用且无害”的基于 LLM 的推荐器，我们提出了一个通用框架——具有平滑个性化偏好优化的推荐 (RosePO)，它在训练后阶段更好地与定制的人类价值观保持一致。具体而言，除了自然与 SFT 数据一致的输入和选择的响应之外，我们还设计了一种专门用于增强帮助性的拒绝采样策略，以及两种旨在减轻偏见以促进无害的策略。为了确保对自动构建的偏好数据中存在的不确定标签的鲁棒性，我们在优化目标中引入了偏好预言机预测的个性化平滑因子。对三个真实数据集的评估证明了我们方法的有效性，不仅展示了推荐性能的提高，而且还减轻了语义幻觉和流行偏见。]]></description>
      <guid>https://arxiv.org/abs/2410.12519</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GeoLife+：根据 GeoLife 数据集校准的大规模模拟轨迹数据集</title>
      <link>https://arxiv.org/abs/2410.11853</link>
      <description><![CDATA[arXiv:2410.11853v1 公告类型：交叉 
摘要：分析个人人类轨迹数据有助于我们了解人类流动性，并发现许多商业和学术应用。获取轨迹数据进行研究的主要方法有两种：一种是使用真实世界数据集（如 GeoLife），另一种是使用模拟来合成数据。真实世界数据提供了对真实人类活动的洞察，但由于自愿参与，此类数据通常很稀疏。相反，模拟数据可能更全面，但可能会捕捉到不切实际的人类行为。在这篇数据和资源论文中，我们通过利用真实数据的统计特征和模拟数据的全面性来结合两者的优势。具体来说，我们从真实世界的 GeoLife 数据集中提取特征，例如个人每日平均出行次数、平均回转半径以及最大和最小出行距离。我们校准了生活模式模拟（一种对人类流动性的真实模拟），以重现这些特征。因此，我们使用遗传算法校准模拟参数以模仿 GeoLife 特征。为了进行校准，我们模拟了许多随机模拟设置，测量了生成的轨迹与 GeoLife 的相似性，并迭代（经过多代）组合与 GeoLife 最相似的轨迹数据集的参数设置。使用校准后的模拟，我们模拟了大型轨迹数据集，我们称之为 GeoLife+，其中 + 表示 Kleene Plus，表示至少发生一次的无限复制。我们提供模拟 GeoLife+ 数据，其中 5 年内有 182、1k 和 5k 个用户，一年内有 10k 和 50k 个用户，6 个月内有 100k 个用户。]]></description>
      <guid>https://arxiv.org/abs/2410.11853</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SociaLens 进行在线数字调查新闻</title>
      <link>https://arxiv.org/abs/2410.11890</link>
      <description><![CDATA[arXiv:2410.11890v1 公告类型：交叉 
摘要：随着互联网、大数据、机器学习 (ML) 和人工智能的兴起，媒体公司经历了重大转型。大型语言模型 (LLM) 的出现为这种转变增添了另一个方面。研究人员认为，在这些技术的帮助下，调查性数字新闻将进入一个新时代。使用一套智能的数据收集和分析工具，记者将能够以前所未有的方式创建数据驱动的内容和见解。在本文中，我们介绍了一种多功能且自主的调查性新闻工具，称为 {\em SociaLens}，用于从在线来源识别和提取查询特定数据，响应探索性查询并完全自主地使用 ML 分析得出大量数据所涉及的结论。我们设想它在调查性新闻、执法和社会政策规划中的应用。所提出的系统利用 ML 技术与 LLM 和高级大数据搜索技术的集成。我们通过一个发展中国家强奸事件的案例研究来说明 SociaLens 的功能，并表明记者无需具备他们可能缺乏的编码专业知识即可获得细致入微的见解。SociaLens 被设计为一个聊天机器人，能够进行上下文对话、查找和收集与查询相关的数据、启动 ML 任务来响应查询、生成文本和视觉报告，所有这些都在聊天机器人环境中完全自主地完成。]]></description>
      <guid>https://arxiv.org/abs/2410.11890</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型代理进行推荐的道德案例</title>
      <link>https://arxiv.org/abs/2410.12123</link>
      <description><![CDATA[arXiv:2410.12123v1 公告类型：交叉 
摘要：我们的信息和通信环境未能达到网络化全球通信可能服务的理想。确定其所有病因很困难，但现有的推荐系统很可能发挥了一定作用。在本文中，我们借鉴了计算哲学的规范工具，并借鉴了自然语言处理和推荐系统的经验和技术见解，为替代方法提供了道德依据。我们认为，现有的推荐系统激励了大规模监视，集中了权力，沦为狭隘行为主义的牺牲品，并损害了用户代理。研究人员和工程师不应该只是试图完全避免算法，或者对当前范式进行渐进式改进，而应该探索一种替代范式：使用语言模型 (LM) 代理来获取和管理符合用户偏好和价值观的内容，并用自然语言表达。使用 LM 代理进行推荐有其自身的挑战，包括与候选生成、计算效率、偏好建模和提示注入相关的挑战。尽管如此，如果成功实施，LM 代理可以：引导我们穿越数字公共领域，而无需依赖大规模监视；将权力从平台转移到用户；针对重要事项进行优化，而不仅仅是针对行为代理；支撑我们的代理，而不是破坏它。]]></description>
      <guid>https://arxiv.org/abs/2410.12123</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种具有偏好解析的、便于实践的 LLM 增强范式，用于顺序推荐</title>
      <link>https://arxiv.org/abs/2406.00333</link>
      <description><![CDATA[arXiv:2406.00333v2 公告类型：替换 
摘要：集成大型语言模型（LLM）的训练范式正在逐渐重塑顺序推荐系统（SRS），并已显示出令人鼓舞的结果。然而，大多数现有的LLM增强方法依赖于项目端的丰富文本信息和实例级监督微调（SFT）将协作信息注入LLM，这在许多应用中效率低下且受到限制。为了缓解这些问题，本文提出了一种适用于SRS的具有偏好解析（P2Rec）的实践友好的LLM增强范式。具体而言，在信息重构阶段，我们在预训练的SRS模型的帮助下设计了一个新的用户级SFT任务用于协作信息注入，该任务效率更高并且与有限的文本信息兼容。我们的目标是让 LLM 学会从每个用户的交互序列中重建相应的先验偏好分布，其中 LLM 需要有效地解析每个项目的潜在类别以及不同项目之间的关系才能完成此任务。在信息增强阶段，我们将每个项目输入 LLM 以获得一组增强的嵌入，这些嵌入结合了协作信息和 LLM 推理能力。然后可以使用这些嵌入来帮助训练未来的各种 SRS 模型。最后，我们在三个 SRS 基准数据集上验证了我们的 TSLRec 的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2406.00333</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PromptDSI：基于提示的无排练实例增量学习文档检索</title>
      <link>https://arxiv.org/abs/2406.12593</link>
      <description><![CDATA[arXiv:2406.12593v2 公告类型：替换 
摘要：可微分搜索索引 (DSI) 利用预训练语言模型 (PLM) 进行高效的文档检索，而无需依赖外部索引。然而，DSI 需要完全重新训练才能处理动态语料库中的更新，从而导致严重的计算效率低下。我们引入了 PromptDSI，这是一种基于提示的无排练方法，用于实例式增量学习文档检索。PromptDSI 将提示附加到 DSI 的冻结 PLM 编码器上，利用其强大的表示来有效地索引新语料库，同时保持稳定性和可塑性之间的平衡。我们消除了基于提示的持续学习方法的初始前向传递，这使训练和推理时间加倍。此外，我们提出了一个主题感知提示池，它使用神经主题嵌入作为固定键。此策略确保了提示的多样化和有效使用，解决了查询键匹配机制崩溃导致的参数利用不足问题。我们的实证评估表明，基于 BERT 的 PromptDSI 在管理遗忘方面与 IncDSI 相当，同时将新语料库的性能在 NQ320k 上的 Hits@10 提高了 4% 以上，在 MS MARCO 300k 上的 MRR@10 提高了 3% 以上。]]></description>
      <guid>https://arxiv.org/abs/2406.12593</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DIRAS：检索增强生成中文档相关性的有效 LLM 注释</title>
      <link>https://arxiv.org/abs/2406.14162</link>
      <description><![CDATA[arXiv:2406.14162v3 公告类型：替换 
摘要：检索增强生成 (RAG) 被广泛用于对特定领域文档的查询做出响应。但是，在回答需要对信息进行综合分析的查询时，RAG 实现是否会遗漏重要信息（例如，告诉我今天股市的好消息。）？为了解决这些问题，RAG 开发人员需要为他们感兴趣的领域注释信息检索 (IR) 数据，这很有挑战性，因为 (1) 特定领域的查询通常需要超越浅层语义相关性的细致入微的相关性定义；(2) 人工或 GPT-4 注释成本高昂，无法覆盖所有（查询、文档）对（即注释选择偏差），从而损害了评估 IR 召回的有效性。为了应对这些挑战，我们提出了 DIRAS（具有可扩展性的领域特定信息检索注释），这是一种无需手动注释的模式，可对开源 LLM 进行微调，以考虑细微的相关性定义并使用校准的相关性分数注释（部分）相关性标签。广泛的评估表明，DIRAS 使较小的（8B）LLM 在注释和排名未见过的（查询、文档）对方面达到 GPT-4 级别的性能，并且有助于现实世界的 RAG 开发。所有代码、LLM 生成和人工注释都可以在 \url{https://github.com/EdisonNi-hku/DIRAS} 中找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14162</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越项目间关系：动态适应增强基于 LLM 的顺序推荐</title>
      <link>https://arxiv.org/abs/2408.07427</link>
      <description><![CDATA[arXiv:2408.07427v2 公告类型：替换 
摘要：顺序推荐系统 (SRS) 根据用户历史交互序列预测用户可能喜欢的下一个项目。受各种 AI 应用中大型语言模型 (LLM) 兴起的启发，基于 LLM 的 SRS 的研究激增。尽管现有的基于 LLM 的 SRS 具有吸引人的性能，但仍存在一些局限性，包括忽略项目内关系、忽略长期协作知识以及使用不灵活的架构设计进行适应。为了缓解这些问题，我们提出了一种基于 LLM 的顺序推荐模型，名为 DARec。 DARec 建立在用于捕捉项目间关系的粗粒度自适应之上，并进一步增强了以下功能：(1) 上下文掩蔽，可对项目内关系进行建模，以帮助 LLM 更好地理解 SRS 上下文中的标记和项目语义；(2) 协作知识注入，可帮助 LLM 整合长期协作知识；(3) 动态自适应机制，使用贝叶斯优化灵活选择分层适配器架构，以便更好地整合不同的顺序信息。大量实验表明，DARec 可以动态、自适应地有效处理顺序推荐。]]></description>
      <guid>https://arxiv.org/abs/2408.07427</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>