<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 11 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DomainRAG：评估特定领域检索增强生成的中国基准</title>
      <link>https://arxiv.org/abs/2406.05654</link>
      <description><![CDATA[arXiv:2406.05654v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 提供了一种有前途的解决方案来解决大型语言模型 (LLM) 的各种限制，例如幻觉和难以跟上实时更新。这种方法在专家和领域特定应用中尤其重要，因为 LLM 难以涵盖专家知识。因此，在这种情况下评估 RAG 模型至关重要，但当前的研究通常依赖维基百科等一般知识来源来评估模型解决常识问题的能力。在本文中，我们在特定领域的背景下通过 RAG 设置在大学入学中评估了 LLM。我们确定了 RAG 模型所需的六种能力，包括对话 RAG 中的能力、分析结构信息、忠实于外部知识、去噪、解决时间敏感问题以及理解多文档交互。每种能力都有一个与共享语料库相关联的数据集来评估 RAG 模型的性能。我们评估了流行的 LLM，例如 Llama、Baichuan、ChatGLM 和 GPT 模型。实验结果表明，现有的闭卷 LLM 在处理特定领域的问题时会遇到困难，这凸显了 RAG 模型解决专家问题的需求。此外，RAG 模型在理解对话历史、分析结构信息、去噪、处理多文档交互和忠实于专家知识方面的能力还有提升空间。我们期待未来的研究能够更好地解决这些问题。]]></description>
      <guid>https://arxiv.org/abs/2406.05654</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:29 GMT</pubDate>
    </item>
    <item>
      <title>实现可靠的临时科学信息提取：以两个材料数据集为例</title>
      <link>https://arxiv.org/abs/2406.05348</link>
      <description><![CDATA[arXiv:2406.05348v1 公告类型：交叉 
摘要：我们探索 GPT-4 从科学文献中执行基于模式的临时信息提取的能力。我们特别评估它是否可以通过基本的提示方法复制两个现有的材料科学数据集，前提是它们最初是从手稿中手动提取的。我们聘请材料科学家进行详细的手动错误分析，以评估模型在忠实提取所需信息方面遇到的困难，并借鉴他们的见解提出研究方向来解决这一广泛重要的任务。]]></description>
      <guid>https://arxiv.org/abs/2406.05348</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:28 GMT</pubDate>
    </item>
    <item>
      <title>将“叽叽喳喳”与“聊天”区分开来：自监督的声音和语言视觉基础</title>
      <link>https://arxiv.org/abs/2406.05629</link>
      <description><![CDATA[arXiv:2406.05629v1 公告类型：交叉 
摘要：我们提出了 DenseAV，这是一种新颖的双编码器接地架构，它仅通过观看视频即可学习高分辨率、语义上有意义且视听一致的特征。我们表明，DenseAV 可以在没有明确定位监督的情况下发现单词的“含义”和声音的“位置”。此外，它可以在没有监督的情况下自动发现并区分这两种类型的关联。我们表明，DenseAV 的定位能力源自一种新的多头特征聚合运算符，该运算符直接比较密集的图像和音频表示以进行对比学习。相比之下，许多其他学习“全局”音频和视频表示的系统无法定位单词和声音。最后，我们贡献了两个新的数据集，以通过语音和声音提示的语义分割来改进对 AV 表示的评估。在这些和其他数据集上，我们表明 DenseAV 在语音和声音提示的语义分割方面的表现远远优于现有技术。 DenseAV 在跨模态检索方面的表现优于之前最先进的 ImageBind，所用参数不到一半。项目页面：\href{https://aka.ms/denseav}{https://aka.ms/denseav}]]></description>
      <guid>https://arxiv.org/abs/2406.05629</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:28 GMT</pubDate>
    </item>
    <item>
      <title>UMBRELA：UMbrela 是 Bing RELevance Assessor 的（开源复制品）</title>
      <link>https://arxiv.org/abs/2406.06519</link>
      <description><![CDATA[arXiv:2406.06519v1 公告类型：新
摘要：大量的相关性判断对于检索系统的有效训练和准确评估是必不可少的。传统上，这些判断是由人类评估员做出的，这使得这个过程既昂贵又费力。微软必应的 Thomas 等人最近的一项研究表明，大型语言模型 (LLM) 可以准确执行相关性评估任务并提供人类质量的判断，但不幸的是，他们的研究没有产生任何可重复使用的软件工件。我们的工作提出了 UMBRELA（UMbrela 的递归缩写，即 Bing RELevance Assessor），这是一个开源工具包，它使用 OpenAI 的 GPT-4o 模型重现了 Thomas 等人的结果，并为原始论文添加了更多细微差别。在 TREC 2019 至 2023 的深度学习轨道中，我们发现 LLM 得出的相关性判断与有效的多阶段检索系统生成的排名高度相关。我们的工具包设计为易于扩展，可以集成到现有的多阶段检索和评估管道中，为研究人员提供研究检索评估方法的宝贵资源。UMBRELA 将用于 TREC 2024 RAG 轨道，以协助相关性评估，我们设想我们的工具包将成为该领域进一步创新的基础。UMBRELA 可在 https://github.com/castorini/umbrela 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.06519</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:27 GMT</pubDate>
    </item>
    <item>
      <title>TLEX：一种从 TimeML 时间图中提取精确时间线的有效方法</title>
      <link>https://arxiv.org/abs/2406.05265</link>
      <description><![CDATA[arXiv:2406.05265v1 公告类型：交叉 
摘要：时间线提供了事件和时间的完全排序，可用于许多自然语言理解任务。然而，可以直接从文本中得出的定性时间图（例如 TimeML 注释）通常仅明确显示事件和时间的部分排序。在这项工作中，我们将解决点代数问题的先前工作应用于从 TimeML 注释文本中提取时间线的任务，并开发一种精确的端到端解决方案，我们称之为 TLEX（TimeLine EXtraction）。TLEX 将 TimeML 注释转换为按主干和分支结构排列的时间线集合。与之前的工作一样，TLEX 检查时间图的一致性并解决它；然而，它增加了两个新功能。首先，它可以识别出涉及不一致的特定关系（然后可以手动纠正）；其次，TLEX 对时间线中顺序不确定的部分进行了新颖的识别，这些信息对于下游任务（例如对齐来自不同时间线的事件）至关重要。我们对 TLEX 中的算法组件进行了详细描述和分析，并通过将 TLEX 应用于来自四个语料库的 385 个 TimeML 注释文本进行了实验评估。我们发现 123 个文本不一致，181 个文本有多个“现实世界”或主时间线，四个语料库中有 2,541 个不确定部分。抽样评估表明，TLEX 在五个维度上的准确率为 98--100%，置信度为 95%：时间点的排序、主时间线的数量、时间点在主时间线和从属时间线上的位置、分支时间线的连接点以及不确定部分的位置。我们提供了 TLEX 的参考实现、所有文本的提取时间线以及不一致文本的手动更正。]]></description>
      <guid>https://arxiv.org/abs/2406.05265</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:27 GMT</pubDate>
    </item>
    <item>
      <title>贪婪 SLIM：一种基于 SLIM 的偏好引出方法</title>
      <link>https://arxiv.org/abs/2406.06061</link>
      <description><![CDATA[arXiv:2406.06061v1 公告类型：新
摘要：偏好引出是一种主动学习方法，用于解决推荐系统的冷启动问题。粗略地说，要求新用户对一些精心挑选的项目进行评分，以便为他们计算合适的推荐。据我们所知，我们是第一个提出基于 SLIM 的偏好引出方法的人，SLIM 是一种最先进的 top-N 推荐技术。我们的方法主要包括一种新的 SLIM 训练技术，我们称之为贪婪 SLIM。该技术迭代地选择训练项目，以贪婪地最小化 SLIM 损失。我们进行了离线实验以及用户研究来评估这种新方法的性能。结果非常出色，尤其是在用户研究方面。我们得出结论，贪婪 SLIM 似乎比广泛使用的基于潜在因子模型的方法更适合偏好引出。]]></description>
      <guid>https://arxiv.org/abs/2406.06061</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:26 GMT</pubDate>
    </item>
    <item>
      <title>社交和电子商务领域生成式人工智能落地调查——行业观点</title>
      <link>https://arxiv.org/abs/2406.06475</link>
      <description><![CDATA[arXiv:2406.06475v1 公告类型：新
摘要：最近，生成式人工智能（GAI）及其新兴能力为增强和革新工业推荐系统（Recsys）提供了独特的机会。尽管在这些领域的交叉点上研究力度不断加大，但将 GAI 集成到工业推荐系统仍处于起步阶段，这主要是由于现代工业推荐系统基础设施、运营和产品复杂性的复杂性。借鉴我们成功将 GAI 集成到几个主要社交和电子商务平台的经验，本调查旨在全面研究底层系统和人工智能基础、解决方案框架、与关键研究进展的联系，并总结在将 GAI 集成到工业推荐系统的过程中遇到的实际见解和挑战。作为该领域的开创性工作，我们希望概述相关领域的代表性发展，阐明行业中实际的 GAI 采用，并激发未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2406.06475</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:26 GMT</pubDate>
    </item>
    <item>
      <title>用于文档排名模型细化的加权 KL 散度</title>
      <link>https://arxiv.org/abs/2406.05977</link>
      <description><![CDATA[arXiv:2406.05977v1 公告类型：新
摘要：基于 Transformer 的文本文档搜索检索和重新排序模型通常通过知识蒸馏和对比学习进行改进。教师和学生模型之间的紧密分布匹配可能很难，因为当教师表现不佳时，过度校准可能会降低训练效果。本文对比性地重新加权 KL 散度项，以优先考虑学生和教师模型之间的一致性，以正确区分正面和负面文档。本文在 MS MARCO 和 BEIR 数据集上分析和评估了所提出的损失函数，以证明其在提高测试学生模型的相关性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.05977</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>基于WT-ResNet的城市轨道交通列车传动系统故障诊断模型</title>
      <link>https://arxiv.org/abs/2406.06031</link>
      <description><![CDATA[arXiv:2406.06031v1 公告类型：新
摘要：本研究提出了一种基于小波变换残差神经网络（WT-ResNet）的城市轨道交通系统故障诊断新模型。该模型融合了小波变换在特征提取和 ResNet 在模式识别方面的优势，提高了诊断的准确性和鲁棒性。实验结果证明了该模型在城市轨道列车故障识别方面的有效性，为改进维护策略和减少停机时间铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2406.06031</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>通过生成流网络建模用户留存</title>
      <link>https://arxiv.org/abs/2406.06043</link>
      <description><![CDATA[arXiv:2406.06043v1 公告类型：新
摘要：推荐系统旨在满足用户的日常需求。虽然大多数现有研究都侧重于最大限度地提高用户对系统的参与度，但最近有人指出，用户回来使用服务的频率也反映了推荐的质量和稳定性。然而，优化这种用户保留行为并非易事，并带来了一些挑战，包括难以处理的离开和返回用户活动、稀疏和延迟信号，以及用户保留与他们对推荐列表中每个项目的即时反馈之间的不确定关系。在这项工作中，我们将保留信号视为用户会话结束时满意度的总体估计，并建议通过概率流来估计该信号。这种基于流的建模技术可以将保留奖励反向传播到用户会话中的每个推荐项目，我们表明，结合传统的学习排名目标的流程最终优化了即时用户反馈和用户保留的非折扣累积奖励。我们通过在两个公共数据集上的离线实证研究和在工业平台上的在线 A/B 测试来验证我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.06043</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>通过区域间知识转移和自适应传播确定潜在湿地区域的优先次序</title>
      <link>https://arxiv.org/abs/2406.05578</link>
      <description><![CDATA[arXiv:2406.05578v1 公告类型：新
摘要：湿地对社区很重要，它的好处包括水净化、防洪、娱乐和旅游等。因此，确定和优先考虑潜在的湿地区域是一个关键的决策问题。虽然数据驱动的解决方案是可行的，但由于美国西南部许多感兴趣的地区湿地比例较低（3-6\%），数据稀疏性使这一问题变得复杂。这使得开发数据驱动模型来帮助指导识别更多湿地区域变得困难。为了解决这一限制，我们提出了两种策略：（1）第一种是将知识从湿地丰富的地区（如美国东部）转移到湿地较少的地区（如湿地较少的西南部地区）。认识到这些地区在土壤特征、人口分布和土地利用方面可能彼此非常不同，我们提出了一种领域解缠策略，该策略仅识别和转移学习模型的适用方面。 (2) 我们对此进行了补充，采用了一种依赖于自适应传播机制的空间数据丰富策略。对于图神经网络 (GNN)，该机制区分了相互产生正负影响的节点对。总而言之，给定两个属于不同区域的空间单元，我们识别特定于域和可共享域的特征，并且对于每个区域，我们依靠自适应传播来丰富周围单元的特征。我们进行了严格的实验，以证实我们提出的方法与最先进的基线相比的有效性、稳健性和可扩展性。此外，一项消融研究表明，每个模块对于优先考虑潜在湿地都至关重要，这证明了我们的假设是正确的。]]></description>
      <guid>https://arxiv.org/abs/2406.05578</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:24 GMT</pubDate>
    </item>
    <item>
      <title>用于广告投放优化的异步学习用户嵌入</title>
      <link>https://arxiv.org/abs/2406.05898</link>
      <description><![CDATA[arXiv:2406.05898v1 公告类型：新 
摘要：用户表示对于推荐系统至关重要，因为它有助于通过捕获低维向量中的用户偏好和行为来提供个性化推荐。高质量的用户嵌入可以捕捉细微的偏好，实现精确的相似度计算，并适应随时间变化的偏好以保持相关性。推荐系统的有效性在很大程度上取决于用户嵌入的质量。我们建议通过类似 Transformer 的大规模特征学习模块，每天从 Meta 平台中基于序列的多模态用户活动中异步学习数十亿用户的高保真用户嵌入。异步学习的用户表示嵌入 (ALURE) 通过图学习进一步转换为用户相似度图，然后与用户实时活动相结合，为整个广告投放系统检索高度相关的广告候选。我们的方法在线下和线上实验中都显示出显着的收益。]]></description>
      <guid>https://arxiv.org/abs/2406.05898</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:24 GMT</pubDate>
    </item>
    <item>
      <title>PTF-FSR：一种无参数传输的联邦序列推荐系统</title>
      <link>https://arxiv.org/abs/2406.05387</link>
      <description><![CDATA[arXiv:2406.05387v1 公告类型：新
摘要：顺序推荐系统取得了重大进展。最近，由于对用户数据隐私的担忧日益增加，一些研究人员已经实现了顺序推荐的联邦学习，又称联邦顺序推荐系统（FedSeqRecs），其中公共顺序推荐模型在中央服务器和客户端之间共享和频繁传输以实现协作学习。虽然这些解决方案在一定程度上缓解了用户隐私问题，但它们存在两个影响其实际可用性的重大限制：（1）它们需要全局共享的顺序推荐模型。然而，在现实场景中，推荐模型是平台和服务提供商的关键知识产权。因此，服务提供商可能不愿意披露他们精心开发的模型。（2）通信成本很高，因为它们与模型参数的数量相关。这变得尤其成问题，因为当顺序推荐进入大型语言模型时代时，当前的 FedSeqRec 将不再适用。
为了克服上述挑战，本文提出了一种无参数传输的联邦顺序推荐框架 (PTF-FSR)，该框架可确保模型和数据隐私保护，以满足服务提供商和系统用户的隐私需求。此外，由于 PTF-FSR 仅在隐私保护下传输与模型大小无关的预测结果，因此这种新的联邦学习架构可以容纳更复杂、更大的顺序推荐模型。在三个广泛使用的推荐数据集上进行的大量实验，采用了基于 ID 和无 ID 范式的各种顺序推荐模型，证明了我们提出的框架的有效性和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2406.05387</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>I-SIRch：基于人工智能的概念注释工具，用于公平提取和分析产科调查中的安全见解</title>
      <link>https://arxiv.org/abs/2406.05505</link>
      <description><![CDATA[arXiv:2406.05505v1 公告类型：新
摘要：产妇护理是一个复杂的系统，涉及患者、提供者和护理环境之间的治疗和互动。为了提高患者的安全性和结果，了解影响医疗保健服务的人为因素（例如个人决定、当地设施）至关重要。然而，目前大多数用于分析医疗保健数据的工具仅关注生物医学概念（例如健康状况、程序和测试），而忽视了人为因素的重要性。我们开发了一种名为 I-SIRch 的新方法，使用人工智能自动识别和标记英国医疗保健安全调查处 (HSIB) 制作的描述不良产妇事件的产妇医疗保健调查报告中的人为因素概念。这些事件调查报告旨在确定整个医疗保健系统的学习和改善产妇安全的机会。I-SIRch 使用真实数据进行训练，并在真实数据和模拟数据上进行测试，以评估其在识别人为因素概念方面的表现。当应用于真实报告时，该模型实现了高水平的准确性，正确识别了 97 份报告中 90% 句子中的相关概念。应用 I-SIRch 分析这些报告发现，某些人为因素对不同种族的母亲影响不成比例。我们的工作表明，使用自动化工具识别产妇事故调查报告中的人为因素概念的潜力，而不是仅仅关注生物医学概念。这种方法为理解影响产妇安全和人口健康结果的社会、技术和组织因素之间的复杂相互作用开辟了新的可能性。通过更全面地了解产妇保健服务，我们可以制定有针对性的干预措施来解决差异并改善产妇结果。]]></description>
      <guid>https://arxiv.org/abs/2406.05505</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>衡量缺少标签的大规模推荐系统中的公平性</title>
      <link>https://arxiv.org/abs/2406.05247</link>
      <description><![CDATA[arXiv:2406.05247v1 公告类型：新
摘要：在大规模推荐系统中，大量的项目使得无法获得每个产品的准确用户偏好，从而导致标签缺失的常见问题。通常，只有之前推荐给用户的项目才具有相关的基本事实数据。尽管对完全观察到的用户-项目交互的公平性进行了广泛的研究，但在缺少标签的情况下的公平性挑战仍未得到充分探索。以前的方法通常将这些缺少标签的样本视为负数，这可能会严重偏离基本事实公平性指标。我们的研究通过提出一种采用少量随机流量来准确估计公平性指标的新方法来解决这一差距。我们为公平性指标的估计误差给出了理论界限，并用真实数据的经验证据支持我们的发现。我们对合成数据和 TikTok 的真实数据进行的数值实验验证了我们的理论，并展示了我们新方法的效率和有效性。据我们所知，我们是第一个强调在数据集收集中随机流量对于推荐公平性的必要性的人，第一个发布来自 TikTok 的公平性相关数据集，并在缺少标签的大规模推荐系统背景下提供公平性指标的可靠估计的人。]]></description>
      <guid>https://arxiv.org/abs/2406.05247</guid>
      <pubDate>Wed, 12 Jun 2024 03:16:22 GMT</pubDate>
    </item>
    </channel>
</rss>