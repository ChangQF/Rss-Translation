<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 21 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型的按标记有影响力的训练数据检索</title>
      <link>https://arxiv.org/abs/2405.11724</link>
      <description><![CDATA[arXiv:2405.11724v1 公告类型：交叉
摘要：给定大型语言模型（LLM）生成，我们如何识别哪些训练数据导致了这一生成？在本文中，我们提出了RapidIn，一个适用于法学硕士的可扩展框架，用于估计每个训练数据的影响。所提出的框架由两个阶段组成：缓存和检索。首先，我们将梯度向量压缩超过 200,000 倍，允许它们缓存在磁盘或 GPU/CPU 内存中。然后，对于给定的一代，RapidIn 有效地遍历缓存的梯度以在几分钟内估计影响，实现超过 6,326 倍的加速。此外，RapidIn 支持多 GPU 并行化，可大幅加速缓存和检索。我们的实证结果证实了 RapidIn 的效率和有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.11724</guid>
      <pubDate>Tue, 21 May 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>具有比例排名函数的信息检索博弈中无悔动力学的收敛性</title>
      <link>https://arxiv.org/abs/2405.11517</link>
      <description><![CDATA[arXiv:2405.11517v1 公告类型：交叉
摘要：在网络上发布内容的出版商采取战略性行动，其行为可以在在线学习框架内建模。遗憾是机器学习的核心概念，是评估该框架内学习代理表现的规范指标。我们证明，任何具有凹激活函数的比例内容排名函数都会引发无悔学习动态收敛的博弈。此外，对于比例排序函数，我们证明了激活函数的凹性、诱导博弈的社会凹性和诱导博弈的凹性的等价性。我们还使用最先进的无遗憾动态算法，研究了在不同的激活函数选择下，发布者和用户的福利之间的实证权衡。此外，我们还证明了排名函数的选择和生态系统结构的变化如何影响这些福利措施以及动态的收敛速度。]]></description>
      <guid>https://arxiv.org/abs/2405.11517</guid>
      <pubDate>Tue, 21 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>提高法学硕士问答的准确性：本体论来救援！</title>
      <link>https://arxiv.org/abs/2405.11706</link>
      <description><![CDATA[arXiv:2405.11706v1 公告类型：交叉
摘要：越来越多的证据表明，具有大型语言模型 (LLM) 的问答 (QA) 系统采用企业 SQL 数据库的知识图/语义表示（即文本到 SPARQL），与系统相比能够实现更高的准确性直接在 SQL 数据库上回答问题（即文本到 SQL）。我们之前的基准研究表明，通过使用知识图谱，准确率从 16% 提高到 54%。问题仍然是：如何进一步提高准确率并降低错误率？基于我们之前研究的观察结果，即不准确的 LLM 生成的 SPARQL 查询遵循错误的路径，我们提出了一种方法，包括 1) 基于本体的查询检查 (OBQC)：通过利用知识图的本体进行检查来检测错误如果LLM生成的SPARQL查询与本体的语义匹配，并且2)LLM修复：使用LLM的错误解释来修复SPARQL查询。通过使用数据基准聊天，我们的主要发现是我们的方法将整体准确率提高到 72%，其中包括额外 8% 的“我不知道”未知结果。因此，总体错误率为20%。这些结果进一步证明，投资知识图谱（即本体论）可以为 LLM 支持的问答系统提供更高的准确性。]]></description>
      <guid>https://arxiv.org/abs/2405.11706</guid>
      <pubDate>Tue, 21 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>Reindex-Then-Adapt：改进大型语言模型以实现对话式推荐</title>
      <link>https://arxiv.org/abs/2405.12119</link>
      <description><![CDATA[arXiv:2405.12119v1 公告类型：新
摘要：大语言模型（LLM）通过熟练地索引项目内容、理解复杂的会话上下文以及生成相关的项目标题，正在彻底改变会话推荐系统。然而，控制推荐项目的分布仍然是一个挑战。由于无法捕获目标会话推荐平台上快速变化的数据分布（例如项目流行度），这会导致性能不佳。在对话式推荐中，法学硕士通过自回归生成标题（作为多个标记）来推荐项目，这使得获取和控制所有项目的推荐变得困难。因此，我们提出了一个 Reindex-Then-Adapt (RTA) 框架，它将多令牌项目标题转换为 LLM 内的单个令牌，然后相应地调整这些单令牌项目标题的概率分布。 RTA 框架结合了法学硕士和传统推荐系统 (RecSys) 的优点：像法学硕士一样理解复杂的查询；同时像传统 RecSys 一样有效地控制会话推荐中的推荐项目分布。我们的框架展示了三个不同的对话推荐数据集和两个适应设置的准确度指标的改进]]></description>
      <guid>https://arxiv.org/abs/2405.12119</guid>
      <pubDate>Tue, 21 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>演示：高效图文匹配的统计视角</title>
      <link>https://arxiv.org/abs/2405.11496</link>
      <description><![CDATA[arXiv:2405.11496v1 公告类型：交叉 
摘要：图像文本匹配一直是一个长期存在的问题，它试图通过语义理解将视觉和语言联系起来。由于能够管理大规模原始数据，无监督的基于哈希的方法最近引起了人们的关注。它们通常使用自然距离构建语义相似性结构，随后为模型优化过程提供指导。然而，相似性结构可能会在语义分布的边界上产生偏差，导致顺序优化过程中的错误积累。为了解决这个问题，我们引入了一种新的哈希方法，称为基于分布的结构挖掘和一致性学习 (DEMO)，用于有效的图像文本匹配。从统计角度来看，DEMO 使用多个增强视图来表征每个图像，这些视图被视为从其内在语义分布中抽取的样本。然后，我们采用非参数分布散度来确保稳健而精确的相似性结构。此外，我们引入了协作一致性学习，它不仅可以保留汉明空间中的相似性结构，还可以以自监督的方式鼓励来自不同方向的检索分布保持一致。通过在三个基准图像文本匹配数据集上的大量实验，我们证明了 DEMO 与许多最先进的方法相比取得了优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.11496</guid>
      <pubDate>Tue, 21 May 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>CaseGNN++：通过图增强进行法律案例检索的图对比学习</title>
      <link>https://arxiv.org/abs/2405.11791</link>
      <description><![CDATA[arXiv:2405.11791v1 公告类型：新
摘要：法律案例检索（LCR）是一种专门的信息检索任务，旨在找到与给定查询案例相关的案例。 LCR对于帮助法律从业者寻找先例具有至关重要的意义。现有的LCR方法大多基于传统的词汇模型和语言模型，在检索方面取得了可喜的性能。然而，法律文档中固有的特定领域的结构信息还有待利用来进一步提高性能。我们之前的工作 CaseGNN 成功地利用文本属性图和图神经网络来解决法律结构信息忽视的问题。尽管如此，仍有两个方面需要进一步研究：（1）文本归因案例图中丰富边缘信息的利用不足限制了 CaseGNN 生成信息丰富的案例表示。 (2)法律数据集中标记数据的不足阻碍了CaseGNN模型的训练。在本文中，提出了从 CaseGNN 扩展而来的 CaseGNN++，以同时利用边缘信息和附加标签数据来发现 LCR 模型的潜在潜力。具体来说，提出了基于边缘特征的图注意层（EUGAT），以在图建模过程中全面更新节点和边缘特征，从而充分利用法律案件的结构信息。此外，CaseGNN++ 还开发了一种具有图增强功能的新型图对比学习目标，以提供额外的训练信号，从而增强 CaseGNN++ 模型的法律理解能力。对 COLIEE 2022 和 COLIEE 2023 的两个基准数据集进行的大量实验表明，与最先进的 LCR 方法相比，CaseGNN++ 不仅显着改进了 CaseGNN，而且还实现了卓越的性能。代码已发布在https://github.com/yanran-tang/CaseGNN。]]></description>
      <guid>https://arxiv.org/abs/2405.11791</guid>
      <pubDate>Tue, 21 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>支持成人在家自我管理 CVD 危险因素的推荐算法</title>
      <link>https://arxiv.org/abs/2405.11967</link>
      <description><![CDATA[arXiv:2405.11967v1 公告类型：新
摘要：推荐算法发展的新趋势之一是传播其支持人们管理健康的能力。本文重点讨论提高心血管疾病 (CVD) 预防有效性的问题，因为 CVD 是全世界死亡的主要原因。为了解决这个问题，提出了一种基于知识的推荐算法来支持成年人在家中对 CVD 危险因素进行自我管理。所提出的算法基于原始的多维推荐模型和新的用户档案模型，其中除了官方指南中概述的当前评估之外，还包括对 CVD 健康状况的预测评估。该算法的主要特点是将基于规则的逻辑与大型语言模型的能力相结合，为多维推荐的解释部分生成类人文本。对所提出算法的验证和评估表明所提出的推荐算法对于支持成年人在家自我管理 CVD 危险因素的有用性。与类似的基于知识的推荐算法相比，该算法评估了更多的CVD风险因素，并且生成的推荐具有更大的信息和语义容量。]]></description>
      <guid>https://arxiv.org/abs/2405.11967</guid>
      <pubDate>Tue, 21 May 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>生成人工智能对信息访问的社会技术影响</title>
      <link>https://arxiv.org/abs/2405.11612</link>
      <description><![CDATA[arXiv:2405.11612v1 公告类型：新
摘要： 可靠地获取可信信息是社会的一项关键需求，这对民主社会中的知识生产、公共卫生教育和促进公民知情具有重要意义。生成式人工智能技术可能会带来获取信息的新方法并提高现有信息检索系统的有效性，但我们才刚刚开始理解和应对其长期社会影响。在本章中，我们概述了在信息访问背景下使用生成式人工智能的一些系统性后果和风险。我们还提供评估和缓解建议，并讨论未来研究的挑战。]]></description>
      <guid>https://arxiv.org/abs/2405.11612</guid>
      <pubDate>Tue, 21 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>对用户疲劳进行建模以进行顺序推荐</title>
      <link>https://arxiv.org/abs/2405.11764</link>
      <description><![CDATA[arXiv:2405.11764v1 公告类型：新
摘要：推荐系统过滤掉符合用户兴趣的信息。然而，用户可能会对与自己在短时间内接触过的内容过于相似的推荐感到厌倦，这就是所谓的用户疲劳。尽管对于更好的用户体验很重要，但现有的推荐系统很少探讨用户疲劳问题。事实上，用户疲劳建模需要解决三个主要挑战，包括哪些特征支持它、它如何影响用户兴趣以及它的显式信号如何获得。在本文中，我们建议在顺序推荐（FRec）的兴趣学习中对用户疲劳进行建模。为了解决第一个挑战，基于多兴趣框架，我们将目标项目与历史项目连接起来，并构建一个兴趣感知的相似度矩阵作为支持疲劳建模的特征。关于第二个挑战，基于特征交叉，我们提出了一种疲劳增强的多兴趣融合来捕获长期兴趣。此外，我们开发了一个用于短期兴趣学习的疲劳门控循环单元，其中时间疲劳表示作为构建更新和重置门的重要输入。对于最后一个挑战，我们提出了一种新颖的序列增强来获取用于对比学习的显式疲劳信号。我们对现实世界的数据集进行了广泛的实验，包括两个公共数据集和一个大型工业数据集。实验结果表明，与最先进的模型相比，FRec 可以将 AUC 和 GAUC 分别提高高达 0.026 和 0.019。此外，大规模在线实验证明了 FRec 对于减少疲劳的有效性。我们的代码发布于https://github.com/tsinghua-fib-lab/SIGIR24-FRec。]]></description>
      <guid>https://arxiv.org/abs/2405.11764</guid>
      <pubDate>Tue, 21 May 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱修剪推荐</title>
      <link>https://arxiv.org/abs/2405.11531</link>
      <description><![CDATA[arXiv:2405.11531v1 公告类型：新
摘要：近年来，基于知识图谱的推荐系统（KGRS）蓬勃发展，它通过结构化知识丰富了用户、项目和实体的表示，并取得了显着的进步。尽管如此，其难以承受的计算成本仍然限制了研究人员探索更复杂的模型。我们观察到训练效率的瓶颈来自于知识图谱，它受到众所周知的知识爆炸问题的困扰。最近，一些工作尝试通过总结技术来瘦身膨胀的KG。然而，这些总结的节点可能会忽略协作信号，并偏离知识图谱中的节点代表现实世界中实体的符号抽象的事实。为此，在本文中，我们提出了一种名为 KGTrimmer 的新方法，用于针对推荐量身定制的知识图修剪，以删除不必要的节点，同时最大限度地减少性能下降。具体来说，我们从双视图的角度设计了一个重要性评估器。对于集体观点，我们通过基于丰富的协作信号提取社区共识来拥抱集体智慧的理念，即如果节点吸引了众多用户的注意，则节点被认为是重要的。对于整体视图，我们学习一个全局掩码，以从其固有属性或整体流行度中识别无价值的节点。接下来，我们构建一个端到端重要性感知的图神经网络，该网络注入过滤后的知识以增强有价值的用户-项目协作信号的提炼。最终，我们生成一个具有轻量级、稳定和鲁棒特性的剪枝知识图，以方便后续的推荐任务。在三个公开可用的数据集上进行了大量的实验，以证明 KGTrimmer 的有效性和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2405.11531</guid>
      <pubDate>Tue, 21 May 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>EmbSum：利用大型语言模型的摘要功能进行基于内容的推荐</title>
      <link>https://arxiv.org/abs/2405.11441</link>
      <description><![CDATA[arXiv:2405.11441v1 公告类型：新
摘要：基于内容的推荐系统在向数字世界的用户提供个性化内容方面发挥着至关重要的作用。在这项工作中，我们介绍了 EmbSum，这是一种新颖的框架，可以对用户和候选项目进行离线预计算，同时捕获用户参与历史记录中的交互。通过利用预训练的编码器-解码器模型和多注意力层，EmbSum 导出用户多嵌入（UPE）和内容多嵌入（CPE）来计算用户和候选项目之间的相关性得分。 EmbSum 通过在大型语言模型 (LLM) 的监督下生成用户兴趣摘要，主动学习长期的用户参与历史。 EmbSum 的有效性在来自不同领域的两个数据集上得到了验证，以更高的精度和更少的参数超越了最先进的 (SoTA) 方法。此外，该模型生成用户兴趣摘要的能力可以作为有价值的副产品，增强其在个性化内容推荐方面的实用性。]]></description>
      <guid>https://arxiv.org/abs/2405.11441</guid>
      <pubDate>Tue, 21 May 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>DocReLM：利用语言模型掌握文档检索</title>
      <link>https://arxiv.org/abs/2405.11461</link>
      <description><![CDATA[arXiv:2405.11461v1 公告类型：新
摘要：每年有超过 2 亿份已发表的学术文献和数百万份新文献被撰写，学术研究人员面临着在这个庞大的语料库中搜索信息的挑战。然而，现有的检索系统很难理解学术论文中存在的语义和领域知识。在这项工作中，我们证明通过利用大型语言模型，文档检索系统可以实现高级语义理解能力，显着优于现有系统。我们的方法包括使用大型语言模型生成的特定领域数据来训练检索器和重新排序器。此外，我们利用大型语言模型从检索到的论文参考文献中识别候选者，以进一步提高性能。我们使用由量子物理和计算机视觉领域的学术研究人员注释的测试集来评估我们系统的性能。结果显示，DocReLM 在计算机视觉方面取得了 44.12% 的 Top 10 准确率，而 Google Scholar 为 15.69%；在量子物理方面则提升至 36.21%，而 Google Scholar 为 12.96%。]]></description>
      <guid>https://arxiv.org/abs/2405.11461</guid>
      <pubDate>Tue, 21 May 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>MovieLens 信念数据集：收集在线推荐系统的预选择数据</title>
      <link>https://arxiv.org/abs/2405.11053</link>
      <description><![CDATA[arXiv:2405.11053v1 公告类型：新
摘要：设计推荐系统的一个日益重要的方面涉及考虑推荐将如何影响消费者的选择。本文通过介绍一种收集用户对未体验过的项目的信念（选择行为的关键预测因素）的方法来解决这个问题。我们在 MovieLens 平台上实现了这种方法，产生了一个丰富的数据集，其中结合了用户评分、信念和观察到的推荐。我们记录了此类数据收集面临的挑战，包括响应中的选择偏差和产品空间的有限覆盖范围。这种独特的资源使研究人员能够更深入地研究用户行为并分析没有推荐的用户选择、衡量推荐的有效性以及利用用户信念数据的原型算法，最终形成更具影响力的推荐系统。该数据集可以在 https://grouplens.org/datasets/movielens/ml_belief_2024/ 找到。]]></description>
      <guid>https://arxiv.org/abs/2405.11053</guid>
      <pubDate>Tue, 21 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>去噪推荐的双重校正框架</title>
      <link>https://arxiv.org/abs/2405.11272</link>
      <description><![CDATA[arXiv:2405.11272v1 公告类型：新
摘要：由于其在在线服务中的可用性和通用性，隐式反馈在推荐系统中更常用。然而，隐式反馈在现实推荐场景中通常会呈现噪声样本（例如误点击或非偏好行为），这会影响精确的用户偏好学习。为了克服噪声样本问题，一种流行的解决方案是在模型训练阶段丢弃噪声样本，这是因为观察到噪声样本比干净样本具有更高的训练损失。尽管有效，但我们认为该解决方案仍然有局限性。 (1) 高训练损失可能是由模型优化不稳定或硬样本造成的，而不仅仅是噪声样本。 (2)完全丢弃噪声样本会加剧数据稀疏性，缺乏充分的数据利用。为了解决上述限制，我们提出了一种去噪推荐的双重校正框架（DCF），它包含两个校正组件，从更精确的样本丢弃和避免更稀疏的数据的角度来看。在样本丢弃校正组件中，我们使用样本随时间变化的损失值来确定是否是噪声，从而提高了丢弃稳定性。我们没有直接平均，而是使用阻尼函数来减少异常值的偏差影响。此外，由于硬样本表现出较高的方差，我们通过浓度不等式得出损失的下限，以识别和重用硬样本。在渐进式标签校正中，我们迭代地重新标记高度确定性噪声样本并重新训练它们以进一步提高性能。最后，三个数据集和四个主干网的广泛实验结果证明了我们提出的框架的有效性和泛化性。]]></description>
      <guid>https://arxiv.org/abs/2405.11272</guid>
      <pubDate>Tue, 21 May 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>生成文档检索的瓶颈最小索引</title>
      <link>https://arxiv.org/abs/2405.10974</link>
      <description><![CDATA[arXiv:2405.10974v1 公告类型：新
摘要：我们应用信息论的视角来重新考虑生成文档检索（GDR），其中文档 $x \in X$ 由 $t \in T$ 索引，并且训练神经自回归模型来映射查询 $Q $ 至 $T$。 GDR可以被认为涉及从文档$X$到查询$Q$的信息传输，并要求通过索引$T$传输更多位。通过应用香农的率失真理论，可以根据互信息来分析索引的最优性，并且索引$T$的设计可以被视为GDR中的一个{\em瓶颈}。从这个角度重新表述 GDR 后，我们根据经验量化了 GDR 背后的瓶颈。最后，使用 NQ320K 和 MARCO 数据集，我们与以前的各种索引方法相比，评估了我们提出的瓶颈最小索引方法，并且我们表明它优于这些方法。]]></description>
      <guid>https://arxiv.org/abs/2405.10974</guid>
      <pubDate>Tue, 21 May 2024 06:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>