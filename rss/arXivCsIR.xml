<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 31 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过有偏插补进行不变去偏学习以进行推荐</title>
      <link>https://arxiv.org/abs/2412.20036</link>
      <description><![CDATA[arXiv:2412.20036v1 公告类型：新
摘要：先前的去偏研究利用无偏数据对模型训练进行监督。他们面临着获得无偏数据的高试验风险和实验成本。最近的研究尝试使用不变学习以无监督的方式分离用户对无偏推荐的不变偏好。然而，由于失去了与变异偏好的配合，它面临着模型准确率低和预测性能不稳定的缺点。在本文中，我们通过实验证明不变学习通过直接丢弃变异信息而导致信息丢失，这降低了泛化能力并导致无偏推荐中的模型性能下降。基于这种考虑，我们提出了一种新颖的轻量级知识蒸馏框架（KDDebias），从不变和变异信息中自动学习用户的无偏偏好。具体而言，在距离感知知识蒸馏过程中，将变异信息归因于不变的用户偏好。在三个公共数据集（即 Yahoo!R3、Coat 和 MIND）上进行的大量实验表明，通过对用户不同偏好进行有偏插补，我们提出的方法与推荐系统中 SOTA 无监督去偏模型相比，在学习参数不到 50% 的情况下实现了显著改进。我们的代码可在 https://github.com/BAI-LAB/KD-Debias 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2412.20036</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多中心药物推荐的可快速调整对比预训练模型</title>
      <link>https://arxiv.org/abs/2412.20040</link>
      <description><![CDATA[arXiv:2412.20040v1 公告类型：新
摘要：药物推荐是最重要的健康相关应用之一，最近引起了广泛的研究兴趣。大多数现有工作都集中在拥有丰富医疗数据的单个医院。然而，许多小医院只有少量记录，这阻碍了现有的药物推荐工作应用于现实世界。因此，我们寻求探索一个更实际的环境，即多中心药物推荐。在这种情况下，大多数医院的记录很少，但记录总数很大。虽然小型医院可能受益于总的丰富记录，但它也面临着不同医院之间数据分布差异很大的挑战。在这项工作中，我们引入了一种用于多中心药物推荐的新型对比预训练模型和快速调整 (TEMPT)，其中包括预训练和微调两个阶段。我们首先为预训练阶段设计两个自监督任务来学习一般的医学知识。它们是掩码预测和对比任务，用于提取输入诊断和程序的内部和相互关系。此外，我们设计了一种新颖的快速调整方法来捕获每家医院的具体信息，而不是采用常见的微调。一方面，所提出的快速调整可以更好地学习每家医院的异质性以适应各种分布。另一方面，它还可以缓解微调的灾难性遗忘问题。为了验证所提出的模型，我们在多中心医疗数据集公共 eICU 上进行了大量实验。实验结果说明了我们模型的有效性。实现代码可用于简化可重复性 https://github.com/Applied-Machine-Learning-Lab/TEMPT。]]></description>
      <guid>https://arxiv.org/abs/2412.20040</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有大型语言模型的主题感知知识图谱，用于推荐系统中的互操作性</title>
      <link>https://arxiv.org/abs/2412.20163</link>
      <description><![CDATA[arXiv:2412.20163v1 公告类型：新
摘要：在推荐系统中使用知识图谱已成为解决数据稀疏性和冷启动问题的常用方法之一。大型语言模型 (LLM) 的最新进展为处理知识图谱中的侧面和上下文信息提供了新的可能性。然而，由于需要领域专家的干预和系统特性的差异，跨不同系统的一致集成仍然具有挑战性。为了解决这些问题，我们提出了一种一致的方法，该方法使用 LLM 从侧面和上下文信息中提取一般和特定主题。首先，从侧面信息中迭代提取和更新一般主题。然后，使用上下文信息提取特定主题。最后，为了解决在特定主题提取过程中生成的同义主题，细化算法有效地处理和解决了这些问题。这种方法允许一般主题捕获跨不同项目特征的广泛知识，而特定主题强调详细属性，从而更全面地了解项目的语义特征和用户的偏好。实验结果表明，跨不同知识图谱的推荐性能显着提高。]]></description>
      <guid>https://arxiv.org/abs/2412.20163</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在 LinkedIn 的内容搜索引擎中引入语义功能</title>
      <link>https://arxiv.org/abs/2412.20366</link>
      <description><![CDATA[arXiv:2412.20366v1 公告类型：新
摘要：过去，向搜索引擎发出的大多数搜索查询都很短且简单。基于关键字的搜索引擎能够很好地回答此类查询。然而，会员现在养成了发出长而复杂的自然语言查询的习惯。回答此类查询需要搜索引擎发展为具有语义能力。在本文中，我们介绍了 LinkedIn 具有语义能力的新内容搜索引擎的设计及其对指标的影响。]]></description>
      <guid>https://arxiv.org/abs/2412.20366</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AmalREC：利用大型语言模型融合进行关系提取和分类的数据集</title>
      <link>https://arxiv.org/abs/2412.20427</link>
      <description><![CDATA[arXiv:2412.20427v1 公告类型：新
摘要：现有的关系分类和提取数据集通常表现出诸如受限的关系类型和特定领域偏差等限制。这项工作提出了一个通用框架，借助大型语言模型 (LLM) 从给定的元组生成结构良好的句子。本研究主要关注以下问题：(i) 如何从关系元组生成句子，(ii) 如何比较和排序它们，(iii) 我们能否结合各个方法的优势并将它们合并以生成质量更好的句子，以及 (iv) 如何评估最终数据集？对于第一个问题，我们采用多方面的 5 阶段流水线方法，利用 LLM 结合模板引导生成。我们引入了句子评估指数 (SEI)，它优先考虑语法正确性、流畅性、与人类一致的情绪、准确性和复杂性等因素来回答第二个问题的第一部分。为了回答第二个问题的第二部分，本研究引入了一个 SEI-Ranker 模块，该模块利用 SEI 选择最佳候选生成。然后策略性地合并最佳句子以生成最终的高质量句子。最后，我们在基于 LLM 和 SOTA 基线上评估我们的数据集以进行关系分类。建议的数据集具有 255 种关系类型，测试集中有 15K 个句子，训练集中有大约 150k 个句子，显著增强了关系多样性和复杂性。本研究不仅为 RE/RC 任务提供了一个新的综合基准数据集，还比较了不同的 LLM 从关系元组生成高质量句子的能力。]]></description>
      <guid>https://arxiv.org/abs/2412.20427</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用反事实对比学习进行无监督密集检索</title>
      <link>https://arxiv.org/abs/2412.20756</link>
      <description><![CDATA[arXiv:2412.20756v1 公告类型：新
摘要：从大型文档语料库中高效检索一组简明的候选集仍然是信息检索 (IR) 中的关键挑战。神经检索模型，尤其是使用转换器和预训练语言模型构建的密集检索模型，因其卓越的性能而广受欢迎。然而，也有人批评它们缺乏可解释性和易受对抗性攻击。为了应对这些挑战，我们建议通过增强密集检索模型对细粒度相关性信号的敏感性来提高其鲁棒性。在这种情况下实现敏感性的模型应该在文档的关键段落（确定其与查询的相关性）被修改时表现出高方差，同时对不相关段落的其他更改保持低方差。这种敏感性使密集检索模型能够针对试图提升文档而不实际增加其相关性的攻击产生稳健的结果。它还可以分析文档的哪一部分与查询实际相关，从而提高检索模型的可解释性。受因果关系和反事实分析的启发，我们提出了一系列基于博弈论和反事实段落无监督学习的反事实正则化方法。实验表明，我们的方法可以在不依赖段落级相关性注释的情况下提取关键段落。此外，正则化的密集检索模型表现出更高的对抗性攻击鲁棒性，超越了最先进的反攻击方法。]]></description>
      <guid>https://arxiv.org/abs/2412.20756</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ERPA：集成 OCR 和 LLM 的智能文档处理高效 RPA 模型</title>
      <link>https://arxiv.org/abs/2412.19840</link>
      <description><![CDATA[arXiv:2412.19840v1 公告类型：交叉 
摘要：本文介绍了 ERPA，这是一种创新的机器人流程自动化 (RPA) 模型，旨在增强 ID 数据提取并优化移民工作流程中的光学字符识别 (OCR) 任务。传统的 RPA 解决方案在处理大量文档时通常会面临性能限制，从而导致效率低下。ERPA 通过结合大型语言模型 (LLM) 来提高提取文本的准确性和清晰度，从而有效处理模糊字符和复杂结构，从而解决这些挑战。与 UiPath 和 Automation Anywhere 等领先平台的基准比较表明，ERPA 显着缩短了高达 94% 的处理时间，仅需 9.94 秒即可完成 ID 数据提取。这些发现凸显了 ERPA 彻底改变文档自动化的潜力，为当前的 RPA 解决方案提供了更快、更可靠的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.19840</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OneKE：基于 Docker 架构引导的 LLM 代理知识提取系统</title>
      <link>https://arxiv.org/abs/2412.20005</link>
      <description><![CDATA[arXiv:2412.20005v1 公告类型：交叉
摘要：我们介绍了一个基于docker的模式引导知识提取系统OneKE，它可以从Web和原始PDF书籍中提取知识，并支持各种领域（科学、新闻等）。具体来说，我们设计了具有多个代理和一个配置知识库的OneKE。不同的代理执行各自的角色，从而支持各种提取场景。配置知识库有助于模式配置、错误案例调试和更正，从而进一步提高性能。基准数据集上的经验评估证明了OneKE的有效性，而案例研究进一步阐明了它对跨多个领域的各种任务的适应性，突出了其广泛应用的潜力。我们已经在https://github.com/zjunlp/OneKE上开源了代码，并在http://oneke.openkg.cn/demo.mp4上发布了视频。]]></description>
      <guid>https://arxiv.org/abs/2412.20005</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>前 100 名男性职业网球运动员中的左撇子代表：多学科视角</title>
      <link>https://arxiv.org/abs/2412.20360</link>
      <description><![CDATA[arXiv:2412.20360v1 公告类型：交叉 
摘要：一种普遍的观点是，与总人口中左撇子的比例相比，左撇子网球运动员的比例过高。这项研究提供了数据分析支持的领域见解，可以帮助父母和教练做出决定，考虑孩子在没有强大的手臂优势的情况下是否应该以左手或右手开始打网球。与通常引用的男性人口中约 10% 的左撇子数字相比，来自 ATP 官方网站的过去几十年（1985-2016 年）排名前 100 名网球运动员的数据分析显示，左撇子精英网球运动员的比例过高（约 15%）。这些见解和数据分析可以为惯用手决策提供信息，推进教练和战略游戏概念，增强媒体报道/分析、左撇子事实和统计数据，并为网球设备制造提供信息。]]></description>
      <guid>https://arxiv.org/abs/2412.20360</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高级 NLP 模型与 LLM 在多语言地理实体检测中的性能比较</title>
      <link>https://arxiv.org/abs/2412.20414</link>
      <description><![CDATA[arXiv:2412.20414v1 公告类型：交叉 
摘要：先进的自然语言处理 (NLP) 方法与大型语言模型 (LLM) 的集成显著增强了从多语言文本中提取和分析地理空间数据的能力，影响了国家和国际安全等领域。本文在多语言地理实体检测的背景下，对领先的 NLP 模型——SpaCy、XLM-RoBERTa、mLUKE、GeoLM——和 LLM，特别是 OpenAI 的 GPT 3.5 和 GPT 4 进行了全面评估。利用来自英语、俄语和阿拉伯语 Telegram 频道的数据集，我们通过准确度、精确度、召回率和 F1 分数等指标来检查这些模型的性能，以评估它们在准确识别地理空间参考方面的有效性。分析揭示了每个模型的独特优势和挑战，强调了在不同语言环境中实现精确地理实体识别所涉及的复杂性。该实验得出的结论旨在指导更先进、更具包容性的 NLP 工具的增强和创建，从而推动地理空间分析领域及其在全球安全中的应用。]]></description>
      <guid>https://arxiv.org/abs/2412.20414</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Wikidata 架构的 LLM 基于本体的自动知识图谱构建</title>
      <link>https://arxiv.org/abs/2412.20942</link>
      <description><![CDATA[arXiv:2412.20942v1 公告类型：交叉 
摘要：我们提出了一种基于本体的知识图谱 (KG) 构建方法，该方法使用知识库上的大型语言模型 (LLM)。通过在知识库上生成能力问题 (CQ) 来发现知识范围，从 CQ 中提取关系，并尝试用 Wikidata 中的对应关系替换等效关系，从而创建本体。为了确保生成的 KG 的一致性和可解释性，我们根据提取的关系将 KG 的生成与创作的本体相结合。基准数据集上的评估表明，它在知识图谱构建任务中具有竞争力。我们的工作为可扩展的 KG 构建流程提供了一个有希望的方向，只需最少的人为干预，即可产生高质量且人类可解释的 KG，这些 KG 可与 Wikidata 语义互操作，从而实现潜在的知识库扩展。]]></description>
      <guid>https://arxiv.org/abs/2412.20942</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成人工智能在科学领域的兴起</title>
      <link>https://arxiv.org/abs/2412.20960</link>
      <description><![CDATA[arXiv:2412.20960v1 公告类型：交叉 
摘要：生成人工智能 (GenAI，generative AI) 已迅速成为科学研究的工具。为了探索生成 AI 在科学中的应用，我们使用 OpenAlex 进行了实证分析。通过分析 2017 年至 2023 年的 GenAI 出版物和其他 AI 出版物，我们描述了增长模式、GenAI 出版物在各个研究领域的传播以及生成 AI 科学研究的地理分布。我们还调查了团队规模和国际合作，以探索 GenAI 作为新兴的科学研究领域是否与其他 AI 技术相比表现出不同的合作模式。结果表明，生成 AI 在科学出版物中经历了快速增长和日益广泛的存在。GenAI 的使用现在已从计算机科学扩展到其他科学研究领域。在研究期间，美国研究人员贡献了全球近五分之二的 GenAI 出版物。紧随美国之后的是中国，一些中小型发达经济体在其研究出版物中展示了相对较高的 GenAI 部署水平。尽管总体而言，科学研究正变得越来越专业化和协作化，但我们的结果表明，GenAI 研究小组的团队规模往往比其他 AI 领域的团队规模略小。此外，尽管最近地缘政治紧张，但 GenAI 研究仍然表现出与其他 AI 技术相当的国际合作水平。]]></description>
      <guid>https://arxiv.org/abs/2412.20960</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向身份感知的跨模态检索：数据集和基线</title>
      <link>https://arxiv.org/abs/2412.21009</link>
      <description><![CDATA[arXiv:2412.21009v1 公告类型：交叉 
摘要：深度学习的最新进展显著增强了基于内容的检索方法，尤其是通过将图像和文本映射到共享嵌入空间的 CLIP 等模型。然而，这些方法通常会遇到领域特定实体和训练数据中缺失的长尾概念的问题，特别是在识别特定个体时。在本文中，我们探讨了身份感知跨模态检索的任务，该任务旨在根据自然语言查询检索特定上下文中的人物图像。这项任务在各种情况下都至关重要，例如搜索和浏览个性化视频集或国家广播公司维护的大型视听档案。我们引入了一个新数据集 COCO Person FaceSwap (COCO-PFS)，它源自广泛使用的 COCO 数据集，并丰富了来自 VGGFace2 的深度伪造生成的人脸。该数据集解决了训练和评估此任务模型所需的大规模数据集不足的问题。我们的实验评估了针对此任务重新设计的不同 CLIP 变体的性能，包括我们的架构 Identity-aware CLIP (Id-CLIP)，它通过有针对性的微调实现了具有竞争力的检索性能。我们的贡献为更强大的跨模态检索系统奠定了基础，该系统能够识别长尾身份和上下文细微差别。数据和代码可在 https://github.com/mesnico/IdCLIP 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.21009</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多行为顺序推荐的多粒度偏好增强型 Transformer</title>
      <link>https://arxiv.org/abs/2411.12179</link>
      <description><![CDATA[arXiv:2411.12179v2 公告类型：替换 
摘要：顺序推荐（SR）旨在根据用户从历史用户-商品交互中学习到的动态偏好来预测下一个购买商品。为了提高推荐的性能，学习动态异构跨类型行为依赖关系对于推荐系统是必不可少的。然而，多行为顺序推荐（MBSR）仍然存在一些挑战。一方面，现有方法仅在行为级或项目级建模异构多行为依赖关系，而建模交互级依赖关系仍然是一个挑战。另一方面，动态多粒度行为感知偏好很难在交互序列中捕捉，这反映了交互感知的顺序模式。为了应对这些挑战，我们提出了一个多粒度偏好增强的Transformer框架（M-GPT）。首先，M-GPT构建序列中历史跨类型交互的交互级图。然后进行图卷积，反复导出交互级多行为依赖表示，其中可以很好地学习特定顺序的历史跨类型交互之间的复杂相关性。其次，提出了一种配备多粒度用户偏好提取的新型多尺度 Transformer 架构，通过捕获时间行为感知的多粒度偏好来编码交互感知的序列模式。在真实数据集上的实验表明，我们的方法 M-GPT 始终优于各种最先进的推荐方法。]]></description>
      <guid>https://arxiv.org/abs/2411.12179</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的零索引互联网搜索增强生成</title>
      <link>https://arxiv.org/abs/2411.19478</link>
      <description><![CDATA[arXiv:2411.19478v2 公告类型：替换 
摘要：检索增强生成已成为增强大型语言模型性能的有效方法。这种方法通常依赖于内部检索模块，该模块使用各种索引机制来管理静态预处理语料库。然而，当需要将生成推理期间未更新到语料库中的最新信息集成到语料库中时，这种范式往往不够用。在本文中，我们探索了一种替代方法，该方法利用标准搜索引擎 API 动态集成最新的在线信息（不为任何固定语料库维护任何索引），从而提高生成内容的质量。我们设计了一个基于 LLM 的协作范式，其中包括：(i) 一个解析器-LLM，它确定是否需要互联网增强生成，如果需要，则通过单一推理提取搜索关键字；(ii) 一种混合排名策略，对检索到的 HTML 文件进行重新排名，以消除从搜索引擎 API 引入的偏见；以及 (iii) 提取器-LLM，它可以准确高效地从每个 HTML 文件中的新鲜内容中提取相关信息。我们进行了广泛的实证研究，以评估这种互联网搜索增强生成范式的性能。实验结果表明，我们的方法生成的内容质量显著提高。我们的系统已成功部署在生产环境中，以满足 01.AI 的生成推理请求。]]></description>
      <guid>https://arxiv.org/abs/2411.19478</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>