<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 20 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于检索的元知识增强大型语言模型</title>
      <link>https://arxiv.org/abs/2408.09017</link>
      <description><![CDATA[arXiv:2408.09017v1 公告类型：新
摘要：检索增强生成 (RAG) 是一种技术，用于在不改变底层模型参数的情况下，使用上下文相关、时间关键或领域特定信息来增强大型语言模型 (LLM)。然而，构建能够有效地从大量多样化的文档中合成信息的 RAG 系统仍然是一项重大挑战。我们为 LLM 引入了一种新颖的以数据为中心的 RAG 工作流程，将传统的检索后读取系统转变为更先进的准备后重写后检索后读取框架，以实现更高领域专家级的知识库理解。我们的方法依赖于为每个文档生成元数据和合成问答 (QA)，以及为基于元数据的文档集群引入元知识摘要 (MK Summary) 的新概念。提出的创新使个性化的用户查询增强和跨知识库的深入信息检索成为可能。我们的研究做出了两个重要贡献：使用 LLM 作为评估器并采用新的比较性能指标，我们证明 (1) 使用具有合成问题匹配的增强查询明显优于依赖文档分块的传统 RAG 管道 (p &lt; 0.01)，以及 (2) 元知识增强查询还显著提高了检索精度和召回率，以及最终答案的广度、深度、相关性和特异性。我们的方法具有成本效益，使用 Claude 3 Haiku 每 2000 篇研究论文的成本不到 20 美元，并且可以通过对语言或嵌入模型进行任何微调来调整，以进一步增强端到端 RAG 管道的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.09017</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:48 GMT</pubDate>
    </item>
    <item>
      <title>跨不同内容类型排名：多项式混合的稳健之美</title>
      <link>https://arxiv.org/abs/2408.09168</link>
      <description><![CDATA[arXiv:2408.09168v1 公告类型：新
摘要：越来越多的媒体流服务已将其产品扩展到包括多种内容类型的实体。例如，最初仅提供音乐的音频流服务现在也提供播客、商品和视频。由于不同内容类型的用户参与模式不同，将不同内容类型的项目排名到单个板块对传统的学习排名 (LTR) 算法提出了重大挑战。我们探索了一种跨内容类型排名的简单方法，称为多项混合 (MB)，可与大多数现有 LTR 算法结合使用。我们不仅从排名质量方面将 MB 与现有基线进行比较，还从其他行业相关角度进行比较，例如可解释性、易用性和在用户行为变化和排名模型再训练的动态环境中的稳定性。最后，我们报告了来自 Amazon Music 排名用例的 A/B 测试结果。]]></description>
      <guid>https://arxiv.org/abs/2408.09168</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:48 GMT</pubDate>
    </item>
    <item>
      <title>TC-RAG：图灵完备的 RAG 医学 LLM 系统案例研究</title>
      <link>https://arxiv.org/abs/2408.09199</link>
      <description><![CDATA[arXiv:2408.09199v1 公告类型：新 
摘要：为了增强特定领域的大型语言模型 (LLM)，检索增强生成 (RAG) 成为一种有前途的解决方案，可以缓解幻觉、知识过时和高度专业化查询中的专业知识有限等问题。然而，现有的 RAG 方法忽视了系统状态变量，而这些变量对于确保自适应控制、检索停止和系统收敛至关重要。在本文中，我们通过严格的证明介绍了 TC-RAG，这是一个新颖的框架，它通过结合图灵完备系统来管理状态变量来解决这些挑战，从而实现更高效、更准确的知识检索。通过利用具有自适应检索、推理和规划功能的内存堆栈系统，TC-RAG 不仅可以确保检索过程的受控停止，还可以通过 Push 和 Pop 操作减轻错误知识的积累。在医学领域的案例研究中，我们在真实医疗数据集上进行的大量实验表明，TC-RAG 的准确率比现有方法高出 7.20% 以上。我们的数据集和代码已在 https://https://github.com/Artessay/SAMA.git 上提供。]]></description>
      <guid>https://arxiv.org/abs/2408.09199</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:48 GMT</pubDate>
    </item>
    <item>
      <title>FabricQA-Extractor：使用自然语言问题从文档中提取信息的问答系统</title>
      <link>https://arxiv.org/abs/2408.09226</link>
      <description><![CDATA[arXiv:2408.09226v1 公告类型：新
摘要：阅读理解模型在提供一小段文本时回答用自然语言提出的问题。它们为解决数据管理中长期存在的挑战提供了机会：从非结构化文本中提取结构化数据。因此，有几种方法正在使用这些模型来执行信息提取。然而，这些现代方法留下了一个机会，因为它们没有利用目标提取表的关系结构。在本文中，我们介绍了一种新模型 Relation Coherence，它利用关系结构的知识来提高提取质量。我们将 Relation Coherence 模型作为 FabricQA-Extractor 的一部分，FabricQA-Extractor 是一个端到端系统，我们从头开始构建，用于对数百万个文档执行大规模提取任务。我们在两个包含数百万段的数据集上证明了 Relation Coherence 可以提高提取性能，并在大规模数据集上评估了 FabricQA-Extractor。]]></description>
      <guid>https://arxiv.org/abs/2408.09226</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:48 GMT</pubDate>
    </item>
    <item>
      <title>MLoRA：用于 CTR 预测的多域低秩自适应网络</title>
      <link>https://arxiv.org/abs/2408.08913</link>
      <description><![CDATA[arXiv:2408.08913v1 公告类型：新
摘要：点击率 (CTR) 预测是行业中的基本任务之一，尤其是在电子商务、社交媒体和流媒体中。它直接影响网站收入、用户满意度和用户保留率。然而，现实世界的生产平台通常涵盖各种领域以满足不同的客户需求。传统的 CTR 预测模型在多域推荐场景中挣扎，面临着数据稀疏性和跨域数据分布不同的挑战。现有的多域推荐方法为每个域引入了特定的域模块，这部分解决了这些问题，但通常会显着增加模型参数并导致训练不足。在本文中，我们提出了一种用于 CTR 预测的多域低秩自适应网络 (MLoRA)，其中我们为每个域引入了一个专门的 LoRA 模块。这种方法提高了模型在多域 CTR 预测任务中的性能，并且能够应用于各种深度学习模型。我们在几个多域数据集上评估了所提出的方法。实验结果表明，与最先进的基线相比，我们的 MLoRA 方法取得了显著的改进。此外，我们将其部署在 Alibaba.COM 的生产环境中。在线 A/B 测试结果表明了该方法在实际生产环境中的优越性和灵活性。我们的 MLoRA 代码已公开。]]></description>
      <guid>https://arxiv.org/abs/2408.08913</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:47 GMT</pubDate>
    </item>
    <item>
      <title>零售-GPT：利用检索增强生成 (RAG) 构建电子商务聊天助手</title>
      <link>https://arxiv.org/abs/2408.08925</link>
      <description><![CDATA[arXiv:2408.08925v1 公告类型：新
摘要：本研究介绍了 Retail-GPT，这是一款基于 RAG 的开源聊天机器人，旨在通过引导用户进行产品推荐和协助购物车操作来增强用户对零售电子商务的参与度。该系统是跨平台的，可适应各种电子商务领域，避免依赖特定的聊天应用程序或商业活动。Retail-GPT 进行类似人类的对话，解释用户需求，检查产品可用性并管理购物车操作，旨在充当虚拟销售代理并测试此类助手在不同零售业务中的可行性。]]></description>
      <guid>https://arxiv.org/abs/2408.08925</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:47 GMT</pubDate>
    </item>
    <item>
      <title>个性化联合协同过滤：变分自动编码器方法</title>
      <link>https://arxiv.org/abs/2408.08931</link>
      <description><![CDATA[arXiv:2408.08931v1 公告类型：新
摘要：联邦协同过滤 (FedCF) 是一个新兴领域，专注于在联邦环境中开发具有隐私保护的新推荐框架。现有的 FedCF 方法通常将分布式协同过滤 (CF) 算法与隐私保护机制相结合，然后将个性化信息保存到用户嵌入向量中。然而，用户嵌入通常不足以保存跨异构客户端的细粒度个性化的丰富信息。本文提出了一种新颖的个性化 FedCF 方法，将用户的个性化信息同时保存到潜在变量和神经模型中。具体来说，我们将用户知识的建模分解为两个编码器，每个编码器分别用于捕获共享知识和个性化知识。然后应用个性化门控网络来平衡全局和局部编码器之间的个性化和泛化。此外，为了有效地训练所提出的框架，我们将 CF 问题建模为专门的变分自动编码器 (VAE) 任务，将用户交互向量重构与缺失值预测相结合。解码器经过训练可以重构用户与之交互过的项目的隐式反馈，同时预测用户可能感兴趣但尚未与之交互的项目。基准数据集上的实验结果表明，所提出的方法优于其他基线方法，表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.08931</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:47 GMT</pubDate>
    </item>
    <item>
      <title>RoarGraph：用于高效跨模态近似最近邻搜索的投影二分图</title>
      <link>https://arxiv.org/abs/2408.08933</link>
      <description><![CDATA[arXiv:2408.08933v1 公告类型：新
摘要：近似最近邻搜索 (ANNS) 是许多应用程序的基本和关键组件，包括推荐系统和基于大型语言模型的应用程序。随着多模态神经模型的进步，将来自不同模态的数据转换为共享的高维空间作为特征向量，跨模态 ANNS 旨在使用来自一种模态（例如文本）的数据向量作为查询来检索来自另一种模态（例如图像或视频）的最相似项目。然而，来自不同模态的嵌入之间存在固有的分布差距，并且跨模态查询变为基础数据的分布外 (OOD)。因此，最先进的 ANNS 方法在 OOD 工作负载方面表现不佳。在本文中，我们定量分析了 OOD 工作负载的属性，以了解它们的 ANNS 效率。与单模态工作负载不同，我们发现 OOD 查询在空间上偏离基础数据，并且 OOD 查询的 k 个最近邻居在嵌入空间中彼此相距较远。该属性打破了现有 ANNS 方法的假设，并且与它们的高效搜索设计不匹配。根据 OOD 工作负载的见解，我们提出了投影二分图 (RoarGraph)，这是一种在查询分布指导下构建的高效 ANNS 图索引。大量实验表明，RoarGraph 在现代跨模态数据集上的表现明显优于最先进的方法，在 OOD 查询的 90% 召回率下实现了高达 3.56 倍的搜索速度提升。]]></description>
      <guid>https://arxiv.org/abs/2408.08933</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:47 GMT</pubDate>
    </item>
    <item>
      <title>从懒惰到多产：通过正无标记序列学习解决开放词汇极端分类中的缺失标签问题</title>
      <link>https://arxiv.org/abs/2408.08981</link>
      <description><![CDATA[arXiv:2408.08981v1 公告类型：新
摘要：开放词汇极端多标签分类 (OXMC) 扩展了传统的 XMC，允许在非常大的预定义标签集（通常为 $10^3$ 到 $10^{12}$ 个标签）之外进行预测，从而解决现实世界标记任务的动态性质。然而，数据注释中的自我选择偏差导致训练和测试数据中都存在大量缺失标签，尤其是对于不太流行的输入。这带来了两个关键挑战：生成模型通过生成标签不足而学会“懒惰”，并且由于测试集中的注释不足，评估变得不可靠。在这项工作中，我们引入了正向无标记序列学习 (PUSL)，它将 OXMC 重新定义为无限关键短语生成任务，解决了生成模型的懒惰问题。此外，我们建议采用一套评估指标 F1@$\mathcal{O}$ 和新提出的 B@$k$，以可靠地评估具有不完整基本事实的 OXMC 模型。在高度不平衡且标签缺失严重的电子商务数据集中，PUSL 生成的唯一标签多 30%，其 72% 的预测与实际用户查询一致。在偏差较小的 EURLex-4.3k 数据集上，PUSL 表现出优异的 F1 分数，尤其是当标签数量从 15 增加到 30 时。我们的方法有效地解决了 OXMC 中缺少标签的建模和评估挑战。]]></description>
      <guid>https://arxiv.org/abs/2408.08981</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:47 GMT</pubDate>
    </item>
    <item>
      <title>实现有效的作者归属：整合课堂增量学习</title>
      <link>https://arxiv.org/abs/2408.08900</link>
      <description><![CDATA[arXiv:2408.08900v1 公告类型：新
摘要：AA 是从一组预先定义的已知候选者中将未识别文档归因于其真实作者的过程，每个候选者都拥有多个样本。AA 的性质要求适应新兴的新作者，因为每个人都必须被视为独一无二的。这种独特性可以归因于各种因素，包括他们的文体偏好、专业领域、性别、文化背景以及影响其写作的其他个人特征。这些不同的属性促成了每位作者的独特性，因此 AA 系统必须识别和解释这些差异。然而，当前的 AA 基准通常忽略了这种独特性，并将问题定义为封闭世界分类，假设整个系统生命周期内作者数量固定，而忽略了新兴新作者的纳入。这种疏忽使得大多数现有方法对于 AA 的实际应用无效，因为持续学习至关重要。这些低效表现为当前模型要么抵制学习新作者，要么经历灾难性遗忘，即引入新数据会导致模型丢失以前获得的知识。为了解决这些低效问题，我们建议将 AA 重新定义为 CIL，在初始训练阶段后逐步引入新作者，使系统能够不断适应和学习。为了实现这一点，我们简要介绍了其他领域引入的后续 CIL 方法。此外，我们采用了几种众所周知的 CIL 方法，并在 AA 背景下检查了它们的优缺点。此外，我们概述了推进 CIL AA 系统的潜在未来方向。因此，我们的论文可以作为通过 CIL 范式将 AA 系统从封闭世界模型发展到持续学习的起点。]]></description>
      <guid>https://arxiv.org/abs/2408.08900</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:46 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯推理提高检索增强生成的质量</title>
      <link>https://arxiv.org/abs/2408.08901</link>
      <description><![CDATA[arXiv:2408.08901v1 公告类型：新
摘要：检索增强生成或 RAG 是现代大型语言模型或 LLM 应用程序最流行的模式。RAG 涉及获取用户查询并在通常在向量数据库中捕获的大型语料库中查找相关的上下文段落。一旦在向量数据库上进行第一级搜索，相关文本的前 n 个块将直接包含在上下文中并作为提示发送到 LLM。这种方法的问题在于文本块的质量取决于搜索的有效性。搜索后没有强大的后处理来确定块是否包含足够的信息以包含在提示中。此外，很多时候可能会有块在同一主题上有相互冲突的信息，而模型没有先前的经验来优先考虑哪个块以做出决定。很多时候，这导致模型提供一个存在冲突的陈述，并且它无法产生答案。在这项研究中，我们提出了一种贝叶斯方法来验证搜索结果中文本块的质量。贝叶斯定理试图将假设的条件概率与证据和先验概率联系起来。我们提出，找到文本块给出高质量答案的可能性并使用文本块质量的先验概率可以帮助我们提高 RAG 系统响应的整体质量。我们可以使用 LLM 本身来获取上下文段落相关性的可能性。对于文本块的先验概率，我们使用解析文档中的页码。假设是较早页面中的段落更有可能成为发现，并且与概括答案更相关。]]></description>
      <guid>https://arxiv.org/abs/2408.08901</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:46 GMT</pubDate>
    </item>
    <item>
      <title>利用项目级因果关系增强多视图学习进行捆绑推荐</title>
      <link>https://arxiv.org/abs/2408.08906</link>
      <description><![CDATA[arXiv:2408.08906v1 公告类型：新
摘要：捆绑包推荐旨在通过推荐一组相互关联的项目来提高企业盈利能力和用户便利性。在现实世界中，利用不对称项目从属关系的影响对于有效的捆绑包建模和理解用户偏好至关重要。为了解决这个问题，我们提出了 BunCa，这是一种采用项目级因果关系增强的多视图学习的新型捆绑包推荐方法。BunCa 通过两个视图提供用户和捆绑包的全面表示：连贯视图，利用多前景因果关系网络来实现项目之间的因果敏感关系，以及凝聚视图，采用 LightGCN 在用户和捆绑包之间传播信息。从两个视图结合对用户偏好和捆绑包构建进行建模，通过凝聚视图确保直接用户捆绑包交互中的严格凝聚力，并通过连贯视图捕获明确意图。同时，具体和离散对比学习的整合优化了多视角表征的一致性和自我区分性。在三个基准数据集上对 BunCa 进行的大量实验证明了这项新研究的有效性并验证了我们的假设。]]></description>
      <guid>https://arxiv.org/abs/2408.08906</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:46 GMT</pubDate>
    </item>
    <item>
      <title>我应该穿什么去参加希腊酒馆的聚会？时尚领域对话代理评估</title>
      <link>https://arxiv.org/abs/2408.08907</link>
      <description><![CDATA[arXiv:2408.08907v1 公告类型：新
摘要：大型语言模型 (LLM) 有望彻底改变在线时尚零售领域，增强客户体验和在线时尚发现。LLM 驱动的对话代理通过直接与客户互动引入了一种新的发现方式，使他们能够以自己的方式表达、改进需求、获得与他们的品味和意图相关的时尚和购物建议。对于电子商务中的许多任务，例如查找特定产品，对话代理需要将其与客户的交互转换为对不同后端系统的特定调用，例如搜索系统以展示一组相关产品。因此，评估 LLM 执行与调用其他服务相关的任务的能力至关重要。然而，由于缺乏相关和高质量的数据集，这些评估通常很复杂，并且不能与业务需求无缝契合等。为此，我们创建了一个多语言评估数据集，其中包含大型电子商务时尚平台中客户与时尚助理之间的 4000 次对话，以衡量 LLM 作为客户和后端引擎之间的助手的能力。我们评估了一系列模型，展示了我们的数据集如何根据业务需求进行扩展并促进工具的迭代开发。]]></description>
      <guid>https://arxiv.org/abs/2408.08907</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:46 GMT</pubDate>
    </item>
    <item>
      <title>随着大型语言模型的出现，通过探索性搜索增强探索性学习</title>
      <link>https://arxiv.org/abs/2408.08894</link>
      <description><![CDATA[arXiv:2408.08894v1 公告类型：新
摘要：在信息时代，学习者如何查找、评估和有效使用信息已成为一个具有挑战性的问题，尤其是大型语言模型 (LLM) 的复杂性增加，进一步使学习者在信息检索和搜索活动中感到困惑。本研究试图通过将探索性搜索策略与探索性学习理论相结合来解开这种复杂性，从学生学习的角度形成探索性学习的新理论模型。我们的工作通过结合高频探索和反馈循环来调整 Kolb 的学习模型，旨在促进学生的深度认知和高阶认知技能发展。此外，本文讨论并提出了如何将高级 LLM 集成到信息检索和信息理论中以支持学生的探索性搜索，从理论上促进学生与计算机的互动，并通过 LLM 支持他们在新时代的学习之旅。]]></description>
      <guid>https://arxiv.org/abs/2408.08894</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:45 GMT</pubDate>
    </item>
    <item>
      <title>LLMJudge：相关性判断法学硕士</title>
      <link>https://arxiv.org/abs/2408.08896</link>
      <description><![CDATA[arXiv:2408.08896v1 公告类型：新
摘要：LLMJudge 挑战赛是 SIGIR 2024 的 LLM4Eval 研讨会的一部分。测试集对于评估信息检索 (IR) 系统至关重要。搜索系统的评估和调整主要基于相关性标签，这些标签表明文档是否对特定搜索和用户有用。然而，大规模收集相关性判断成本高昂且耗费资源。因此，典型的实验依赖于第三方标记器，而这些标记器可能并不总是能产生准确的注释。LLMJudge 挑战赛旨在探索一种使用 LLM 生成相关性判断的替代方法。最近的研究表明，LLM 可以为搜索系统生成可靠的相关性判断。然而，目前尚不清楚哪些 LLM 的准确率可以与人类标注员相媲美，哪些提示最有效，经过微调的开源 LLM 与 GPT-4 等闭源 LLM 相比如何，合成生成的数据是否存在偏差，以及数据泄露是否会影响生成的标签的质量。本次挑战赛将调查这些问题，并将收集的数据作为一个包发布，以支持信息检索和搜索中的自动相关性判断研究。]]></description>
      <guid>https://arxiv.org/abs/2408.08896</guid>
      <pubDate>Wed, 21 Aug 2024 03:16:45 GMT</pubDate>
    </item>
    </channel>
</rss>