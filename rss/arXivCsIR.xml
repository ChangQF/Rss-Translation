<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Query2GMM：使用高斯混合模型学习表示，用于知识图推理</title>
      <link>https://arxiv.org/abs/2306.10367</link>
      <description><![CDATA[arXiv:2306.10367v2 公告类型：替换
摘要：知识图（KG）上的逻辑查询回答是一项基本但复杂的任务。实现这一目标的一种有前途的方法是将查询和实体联合嵌入到同一嵌入空间中。沿着这条线的研究表明，使用多模态分布来表示答案实体比单模态分布更合适，因为由于多跳查询的组合性质和不同的潜在语义，单个查询可能包含多个不相交的答案子集。关系。然而，现有的基于多模态分布的方法粗略地表示每个子集，而没有捕获其准确的基数，甚至由于缺乏有效的相似性度量，在推理过程中退化为单模态分布学习。为了更好地对具有多样化答案的查询进行建模，我们提出了 Query2GMM 来回答知识图上的逻辑查询。在 Query2GMM 中，我们使用单变量高斯混合模型 (GMM) 提出 GMM 嵌入来表示每个查询。查询的每个子集都按其基数、语义中心和分散度进行编码，从而可以精确表示多个子集。然后，我们为每个算子设计特定的神经网络，以处理多模态分布带来的固有复杂性，同时减轻级联错误。最后，我们设计了一种新的相似性度量来评估实体与查询的多答案子集之间的关系，从而实现有效的多模态分布学习推理。综合实验结果表明，Query2GMM 的绝对平均性能优于最好的竞争对手 $6.35\%$。]]></description>
      <guid>https://arxiv.org/abs/2306.10367</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是具有成对排名提示的有效文本排名器</title>
      <link>https://arxiv.org/abs/2306.17563</link>
      <description><![CDATA[arXiv:2306.17563v2 公告类型：替换
摘要：通过直接将查询和候选文档输入提示中，使用大型语言模型（LLM）对文档进行排名是一个有趣且实际的问题。然而，研究人员发现很难在基准数据集上超越经过微调的基线排名器。我们分析了现有方法使用的逐点和列表排名提示，并认为现成的法学硕士并不完全理解这些具有挑战性的排名公式。在本文中，我们建议通过使用一种称为配对排名提示（PRP）的新技术来显着减轻法学硕士的负担。我们的结果是文献中第一个使用中等规模的开源法学硕士在标准基准上实现最先进的排名性能的结果。在 TREC-DL 2019&amp;2020 上，基于具有 20B 参数的 Flan-UL2 模型的 PRP 的表现优于文献中先前的最佳方法，该方法基于具有 50 倍（估计）模型大小的黑盒商业 GPT-4，同时优于其他方法基于LLM的解决方案，例如InstructGPT，它有175B个参数，所有排名指标都提高了10%以上。通过在 7 个 BEIR 任务上使用相同的提示模板，PRP 的性能优于监督基线，并且在 NDCG@10 上比黑盒商业 ChatGPT 解决方案高出 4.2%，比基于点式 LLM 的解决方案高出 10% 以上。此外，我们提出了 PRP 的几种变体来提高效率，并表明即使具有线性复杂性，也有可能获得有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2306.17563</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>MagicLens：具有开放式指令的自监督图像检索</title>
      <link>https://arxiv.org/abs/2403.19651</link>
      <description><![CDATA[arXiv:2403.19651v1 公告类型：交叉
摘要：图像检索，即在给定参考图像的情况下查找所需图像，本质上包含丰富的、多方面的搜索意图，而仅使用基于图像的措施很难捕获这些意图。最近的工作利用文本指令让用户更自由地表达他们的搜索意图。然而，现有的工作主要集中在视觉上相似和/或可以通过一小组预定义关系来表征的图像对。本文的核心论文是文本指令可以检索具有超越视觉相似性的更丰富关系的图像。为了证明这一点，我们引入了 MagicLens，这是一系列支持开放式指令的自监督图像检索模型。 MagicLens 建立在一个关键的新颖见解之上：自然出现在同一网页上的图像对包含广泛的隐式关系（例如，内部视图），我们可以通过大型多模态模型合成指令来明确这些隐式关系（ LMM）和大型语言模型（LLM）。 MagicLens 使用从网络挖掘的具有丰富语义关系的 3670 万个（查询图像、指令、目标图像）三元组进行训练，在各种图像检索任务的八个基准上取得了与现有最​​先进 (SOTA) 方法相当或更好的结果。值得注意的是，它的性能优于之前的 SOTA，但在多个基准测试中模型尺寸缩小了 50 倍。对 140 万张未见过的图像语料库进行的额外人工分析进一步证明了 MagicLens 支持的搜索意图的多样性。]]></description>
      <guid>https://arxiv.org/abs/2403.19651</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>增强推荐系统：减轻虚假负面影响的策略</title>
      <link>https://arxiv.org/abs/2211.13912</link>
      <description><![CDATA[arXiv:2211.13912v2 公告类型：替换
摘要：在推荐系统的隐式协同过滤（CF）任务中，最近的工作主要集中在使用图神经网络（GNN）等有前景的技术进行模型结构设计。然而，适合这些模型的有效且高效的负采样方法仍然不发达。一项挑战是现有的硬负采样器在模型训练中往往会遭受更严重的过度拟合。在这项工作中，我们首先研究了过度拟合背后的原因，并在实验的支持下通过错误的假阴性实例选择来说明它。此外，我们凭经验观察到一个反直觉的现象，即用相当大比例的正样本嵌入来污染硬负样本的嵌入将导致预测精度的显着性能提升。除此之外，我们提出了一种新颖的负采样策略，即正主导负合成（PDNS）。此外，我们还提供了理论分析并推导了一种简单的 PDNS 等效算法，其中仅在损失函数中添加了一个软因子。对三个真实世界数据集的综合实验证明了我们提出的方法在有效性和鲁棒性方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2211.13912</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>打破长度障碍：LLM 增强的长文本用户行为点击率预测</title>
      <link>https://arxiv.org/abs/2403.19347</link>
      <description><![CDATA[arXiv:2403.19347v1 公告类型：新
摘要：随着大型语言模型（LLM）的兴起，最近的工作利用 LLM 来提高点击率（CTR）预测的性能。然而，我们认为部署 LLM 进行实际应用仍然存在一个关键障碍：LLM 在处理长文本用户行为时的效率。随着用户序列越来越长，法学硕士当前的效率不足以培训数十亿用户和项目。为了突破LLM的效率障碍，我们提出了行为聚合分层编码（BAHE）来提高基于LLM的CTR建模的效率。具体来说，BAHE 提出了一种新颖的分层架构，将用户行为的编码与行为间的交互解耦。首先，为了防止对相同用户行为的重复编码产生计算冗余，BAHE 采用 LLM 的预训练浅层从广泛的用户序列中提取最细粒度、原子用户行为的嵌入，并将其存储在离线数据库中。随后，LLM 更深的、可训练的层促进了复杂的行为间交互，从而生成全面的用户嵌入。这种分离允许高级用户表示的学习独立于低级行为编码，从而显着降低计算复杂性。最后，这些细化的用户嵌入与相应处理的项目嵌入相结合，被合并到 CTR 模型中以计算 CTR 分数。大量实验结果表明，对于使用 LLM 的 CTR 模型，BAHE 将训练时间和内存减少了五倍，特别是对于较长的用户序列。 BAHE已部署在实际系统中，可在8个A100 GPU上每天更新5000万个CTR数据，使LLM可用于工业CTR预测。]]></description>
      <guid>https://arxiv.org/abs/2403.19347</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>通过链接预测定向标准引文推荐和排名</title>
      <link>https://arxiv.org/abs/2403.18855</link>
      <description><![CDATA[arXiv:2403.18855v1 公告类型：交叉
摘要：我们探索链接预测作为自动呈现现有文献中可能与新文档主题或上下文相关的文档的代理。我们的模型使用基于变压器的图嵌入来编码每个文档的含义，并呈现为引文网络中的节点。我们表明，我们的模型生成的语义表示在推荐和排名任务中可以优于其他基于内容的方法。这提供了一种在领域中探索引文图的整体方法，在这些领域中，这些文档正确地相互引用至关重要，以便最大限度地减少任何不一致的可能性]]></description>
      <guid>https://arxiv.org/abs/2403.18855</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>Croissant：ML 就绪数据集的元数据格式</title>
      <link>https://arxiv.org/abs/2403.19546</link>
      <description><![CDATA[arXiv:2403.19546v1 公告类型：交叉
摘要：数据是机器学习 (ML) 的关键资源，但处理数据仍然是一个关键的摩擦点。本文介绍了 Croissant，一种数据集元数据格式，可简化 ML 工具和框架使用数据的方式。 Croissant 使数据集更具可发现性、可移植性和可互操作性，从而解决机器学习数据管理和负责任的人工智能方面的重大挑战。 Croissant 已经受到多个流行数据集存储库的支持，涵盖数十万个数据集，可以加载到最流行的 ML 框架中。]]></description>
      <guid>https://arxiv.org/abs/2403.19546</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>生成然后检索：使用 LLM 作为答案和查询生成器进行对话式响应检索</title>
      <link>https://arxiv.org/abs/2403.19302</link>
      <description><![CDATA[arXiv:2403.19302v1 公告类型：新
摘要：CIS 是 IR 中的一个突出领域，专注于开发交互式知识助手。这些系统必须在会话上下文中熟练地理解用户的信息需求并检索相关信息。为此，现有方法使用一个称为重写查询的查询来对用户的信息需求进行建模，并使用该查询进行段落检索。在本文中，我们提出了三种不同的方法来生成多个查询以增强检索。在这些方法中，我们利用大型语言模型（LLM）的功能来理解用户的信息需求并生成适当的响应，以生成多个查询。我们利用各种 LLM（包括 GPT-4 和 Llama-2 聊天）在零样本和少样本设置中实现和评估所提出的模型。此外，我们基于gpt 3.5判断提出了TREC iKAT的新基准。我们的实验揭示了我们提出的模型在 TREC iKAT 数据集上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19302</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的电商产品智能分类与个性化推荐</title>
      <link>https://arxiv.org/abs/2403.19345</link>
      <description><![CDATA[arXiv:2403.19345v1 公告类型：新
摘要：随着互联网的快速发展和信息的指数级增长，用户遇到信息过载和选择的难题。个性化推荐系统通过帮助用户过滤和选择适合其偏好和要求的信息，在减轻这一负担方面发挥着关键作用。这些系统不仅可以增强用户体验和满意度，还可以为企业和平台提供增强用户参与度、销售和广告效果的机会。本文对传统电子商务商品分类系统和个性化推荐系统的运行机制进行了比较分析。它描述了个性化推荐系统在电子商务、内容信息和媒体领域的重要性和应用。此外，它还深入研究了电子商务中个性化推荐系统面临的挑战，包括数据隐私、算法偏差、可扩展性和冷启动问题。阐述了应对这些挑战的策略。随后，本文概述了利用 BERT 模型和最近邻算法的个性化推荐系统，该系统专门针对 eBay 电子商务平台的迫切需求而定制。通过人工评估验证该推荐系统的有效性，并提供实际应用操作指南和结构化输出推荐结果，保证系统的可操作性和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2403.19345</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型擅长效用判断吗？</title>
      <link>https://arxiv.org/abs/2403.19216</link>
      <description><![CDATA[arXiv:2403.19216v1 公告类型：新
摘要：检索增强生成（RAG）被认为是缓解大语言模型（LLM）幻觉问题的一种有前途的方法，最近受到了研究人员的广泛关注。由于检索模型语义理解的局限性，RAG 的成功在很大程度上取决于法学硕士识别有用段落的能力。最近的努力探索了法学硕士评估检索中段落相关性的能力，但在评估段落在支持问答方面的效用方面的工作有限。在这项工作中，我们对法学硕士在开放领域 QA 效用评估中的能力进行了全面研究。具体来说，我们引入了基准测试程序和具有不同特征的候选段落的集合，促进了与五个代表性法学硕士的一系列实验。我们的实验表明：（i）受过良好指导的法学硕士可以区分相关性和实用性，并且法学硕士非常容易接受新生成的反事实段落。此外，（ii）我们在教学设计中仔细审查影响效用判断的关键因素。最后，（iii）为了验证实用性判断在实际检索增强应用中的有效性，我们使用利用实用性和直接密集检索结果判断的证据来深入研究法学硕士的质量保证能力。 (iv) 我们提出了一种 k 采样、列表方法来减少 LLM 对输入段落序列的依赖，从而促进后续答案的生成。我们相信，我们形式化和研究问题的方式以及我们的发现有助于对检索增强法学硕士进行批判性评估。我们的代码和基准可以在 \url{https://github.com/ict-bigdatalab/utility_judgments} 找到。]]></description>
      <guid>https://arxiv.org/abs/2403.19216</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中鲁棒硬负采样的增强贝叶斯个性化排名</title>
      <link>https://arxiv.org/abs/2403.19276</link>
      <description><![CDATA[arXiv:2403.19276v1 公告类型：新
摘要：在隐式协同过滤中，开发了硬负挖掘技术来加速和增强推荐模型的学习。然而，无意中选择的假阴性仍然是硬阴性采样中的一个主要问题，因为这些假阴性可能提供不正确的信息并误导模型学习。迄今为止，只有少数研究致力于解决假阴性问题，主要集中在设计复杂的采样算法来过滤假阴性。相比之下，本文将重点转向改进损失函数。我们发现最初为均匀负采样而设计的贝叶斯个性化排名（BPR）不足以适应硬采样场景。因此，我们引入了一种增强的贝叶斯个性化排名目标，称为 Hard-BPR，它是专门为动态硬负采样而设计的，以减轻假负的影响。这种方法简单而有效，适合实际部署。对三个现实世界数据集进行的广泛实验证明了我们方法的有效性和鲁棒性，以及区分假阴性的能力增强。]]></description>
      <guid>https://arxiv.org/abs/2403.19276</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>基于指令的超图预训练</title>
      <link>https://arxiv.org/abs/2403.19063</link>
      <description><![CDATA[arXiv:2403.19063v1 公告类型：新
摘要：预训练已被广泛探索，以增强图学习模型的适应性，将知识从大型数据集转移到下游任务，例如链接预测或分类。然而，训练目标之间的差距以及预训练和下游任务中数据分布的差异阻碍了预训练知识的迁移。受到预训练语言模型中广泛使用的基于指令的提示的启发，我们将指令引入到图预训练中。在本文中，我们提出了一种新颖的预训练框架，名为基于指令的超图预训练。为了克服预训练和下游任务之间的差异，应用基于文本的指令来为表示学习的特定任务提供明确的指导。与可学习提示的有效性取决于训练数据的质量和多样性相比，基于文本的指令本质上封装了任务信息，并支持模型泛化到预训练期间看到的结构之外。为了以上下文感知的方式捕获与任务信息的高阶关系，设计了一种新颖的提示超图卷积层，将指令集成到超图中的信息传播中。在三个公共数据集上进行的大量实验验证了 IHP 在各种场景下的优越性。]]></description>
      <guid>https://arxiv.org/abs/2403.19063</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>让大型语言模型成为更好的排名器</title>
      <link>https://arxiv.org/abs/2403.19181</link>
      <description><![CDATA[arXiv:2403.19181v1 公告类型：新
摘要：大型语言模型（LLM）的发展显着增强了各个领域的能力，导致推荐系统（RS）的概念化和开发方式发生范式转变。然而，现有的研究主要集中在逐点和成对的推荐范式上。由于利用大型语言模型的计算成本很高，这些方法在基于 LLM 的推荐系统中被证明效率低下。虽然一些研究深入研究了列表方式，但它们在对任务进行排序方面存在不足。这种不足归因于排名目标和语言生成目标之间的不一致。为此，本文介绍了具有对齐列表排名目标（ALRO）的语言模型框架。 ALRO 旨在弥合法学硕士的能力与推荐系统内排名任务的细微要求之间的差距。 ALRO 的一个关键特性是引入了软 lambda 损失，这是为适应语言生成任务而定制的 lambda 损失的改编。此外，ALRO 还采用了排列敏感的学习机制，可以解决生成模型中普遍存在的位置偏差问题，而不会在推理过程中施加额外的计算负担。我们的评估研究表明，ALRO 优于​​现有的基于嵌入的推荐方法和现有的基于 LLM 的推荐基线，凸显了其有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.19181</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>高召回率、小数据：实时法律检索系统中系统内评估的挑战</title>
      <link>https://arxiv.org/abs/2403.18962</link>
      <description><![CDATA[arXiv:2403.18962v1 公告类型：新
摘要：本文阐述了法律信息检索（IR）常见排名评估方法的一些挑战。我们通过实时法律搜索系统的日志数据和两项用户研究来展示这些挑战。我们概述了法律 IR 的各个方面，以及这些方面对常见评估方法的预期挑战的影响：基于显式和隐式反馈的测试集、用户调查和 A/B 测试。接下来，我们使用来自实时商业合法搜索引擎的数据来说明常见评估方法的挑战。我们特别关注随着时间的推移监控单个 IR 系统对文档排名（持续）变化的有效性的方法。我们展示了合法 IR 系统的特征与有限的用户数据的组合如何带来挑战，导致所讨论的常见评估方法不是最佳的。因此，在未来的工作中，我们将重点关注不太常见的评估方法，例如基于成本的评估模型。]]></description>
      <guid>https://arxiv.org/abs/2403.18962</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>实现 LLM-RecSys 与文本 ID 学习的结合</title>
      <link>https://arxiv.org/abs/2403.19021</link>
      <description><![CDATA[arXiv:2403.19021v1 公告类型：新
摘要：基于大型语言模型（LLM）的生成推荐将传统的基于排名的推荐风格转变为文本到文本的生成范式。然而，与本质上对人类词汇进行操作的标准 NLP 任务相比，当前生成推荐的研究很难使用简洁但有意义的 ID 表示在文本到文本框架内有效地编码推荐项。为了更好地使法学硕士与推荐需求保持一致，我们提出了 IDGen，使用人类语言标记将每个项目表示为独特、简洁、语义丰富、与平台无关的文本 ID。这是通过训练文本 ID 生成器以及基于 LLM 的推荐器来实现的，从而能够将个性化推荐无缝集成到自然语言生成中。值得注意的是，由于用户历史记录以自然语言表达并与原始数据集解耦，因此我们的方法表明了基础生成推荐模型的潜力。实验表明，我们的框架在标准实验设置下的顺序推荐方面始终优于现有模型。然后，我们探索了使用所提出的方法对从 19 个不同数据集收集的数据训练基础推荐模型的可能性，并在完全零样本设置下在不同平台上的 6 个未见过的数据集上测试了其推荐性能。结果表明，预训练基础模型的零样本性能与一些基于监督训练的传统推荐模型相当甚至更好，显示了IDGen范式作为生成推荐基础模型的潜力。代码和数据在 https://github.com/agiresearch/IDGenRec 上开源。]]></description>
      <guid>https://arxiv.org/abs/2403.19021</guid>
      <pubDate>Fri, 29 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    </channel>
</rss>