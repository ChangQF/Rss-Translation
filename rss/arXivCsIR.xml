<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>基于大型语言模型的对话推荐系统的协作检索</title>
      <link>https://arxiv.org/abs/2502.14137</link>
      <description><![CDATA[Arxiv：2502.14137V1公告类型：新 
摘要：会话推荐系统（CRS）旨在通过与用户的交互式对话提供个性化建议。尽管大型语言模型（LLMS）通过对上下文感知的用户偏好的高度理解增强了CRS，但他们通常很难利用行为数据，事实证明，这对于经典的协作过滤（CF）基于基于的方法很重要。因此，我们建议基于LLM的CRS的CRAG，合作检索增强发电。据我们所知，Crag是将最先进的LLM与CF结合使用以进行会话建议的第一种方法。我们对两个公开可用的电影对话推荐数据集进行了实验，即精制的Reddit数据集（我们将其命名Reddit-V2）以及Redial数据集，与几个CRS碱基相比，演示了CRAG的出色项目覆盖率和CRAG的建议性能。此外，我们观察到这些改进主要是由于最近发行的电影的推荐准确性更好。代码和数据可从https://github.com/yaochenzhu/crag获得。]]></description>
      <guid>https://arxiv.org/abs/2502.14137</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对萨卡纳（Sakana）自治研究的AI AI科学家的评估：一厢情愿或新兴的现实“人工一般研究智能”（AGRI）？</title>
      <link>https://arxiv.org/abs/2502.14297</link>
      <description><![CDATA[ARXIV：2502.14297V1公告类型：新 
摘要：迈向人工智能（AGI）和超级智能的重大步骤是AI自主进行研究的能力 - 我们称人工通用研究智能（AGRI）的意义。如果机器能够产生假设，进行实验并撰写研究论文而无需人工干预，它将改变科学。最近，Sakana.ai介绍了AI科学家，该系统声称自动化研究生命周期，引起兴奋和怀疑。
  我们评估了AI科学家，并发现它是AI驱动研究的里程碑。尽管它简化了某些方面，但它没有期望。文献评论很弱，实验近一半失败，手稿有时包含幻觉的结果。最值得注意的是，用户必须提供实验性管道，从而限制了AI科学家在研究设计和执行方面的自主权。
  尽管有局限性，AI科学家仍提高了研究自动化。许多评估工作表面评估工作的审阅者或讲师可能不会将其输出视为AI生成的。该系统以最少的人为努力和低成本生产研究论文。我们的分析表明，论文花费了几个小时的人类参与费用，这使其比人类研究人员快得多。与几年前的AI功能相比，这标志着Agri的进展。
  AI驱动的研究系统的兴起需要在信息检索（IR）和更广泛的科学社区中进行紧急讨论。增强文献检索，引文验证和评估基准可以提高AI生成的研究可靠性。我们提出了具体步骤，包括农业特定的基准测试，精致的同行评审和标准化的归因框架。 Agri是否成为AGI的垫脚石取决于学术和AI社区如何塑造其发展。]]></description>
      <guid>https://arxiv.org/abs/2502.14297</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实践中有效的AI：培训和部署有效的行业应用程序</title>
      <link>https://arxiv.org/abs/2502.14305</link>
      <description><![CDATA[ARXIV：2502.14305V1公告类型：新 
摘要：大型语言模型（LLMS）在广泛的工业应用中表现出了出色的性能，从搜索和建议到生成任务。尽管缩放定律表明较大的模型通常会产生更好的概括和性能，但它们的实质性计算要求通常使它们在大规模的许多现实世界中都不切实际。在本文中，我们介绍了培训小语言模型（SLM）的方法和见解，这些模型（SLM）可以提供高性能和部署的效率。我们专注于两种关键技术：（1）知识蒸馏和（2）通过量化和修剪进行模型压缩。这些方法使SLM能够保留其更大的质量，同时大大降低培训，服务成本和潜伏期。我们详细介绍了这些技术对大型专业社交网络平台上各种用例的影响，并共享部署课程 - 包括硬件优化策略，可增强基于预测性和基于推理的应用程序的速度和吞吐量。]]></description>
      <guid>https://arxiv.org/abs/2502.14305</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>渴望-LLM：通过外在行为语义整合增强大型语言模型作为推荐人</title>
      <link>https://arxiv.org/abs/2502.14735</link>
      <description><![CDATA[ARXIV：2502.14735V1公告类型：新 
摘要：大型语言模型（LLM）越来越多地作为基础骨干在开发高级推荐系统的发展中，通过广泛的知识和推理提供了增强的功能。现有的基于LLM的推荐系统（RSS）经常面临挑战，因为预训练LLM的语言语义与RSS必不可少的协作语义之间存在显着差异。这些系统使用预训练的语言语义，但通过LLM-Backbone从头开始学习协作语义。但是，LLM并不是为建议而设计的，导致协作效率低下，结果相关性较弱以及传统RS功能的整合不足。为了应对这些挑战，我们提出了急切的llm，这是一种仅解码器的基于LLM的生成推荐框架，该框架以非阻碍的方式整合了内源性和外在的行为和语义信息。具体而言，我们提出的是1）二元源知识富含的项目索引，该索引集成了用于外源信号的索引序列，从而实现了有效的范围内处理； 2）非侵入性多尺度一致性重建任务指导模型对协作和语义信号有更深入的了解； 3）旨在将模型的推荐性能与理解能力相平衡的退火适配器。我们通过对三个公共基准测试进行了严格的测试来证明急切的效果。]]></description>
      <guid>https://arxiv.org/abs/2502.14735</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>现代信息检索的多机构视角</title>
      <link>https://arxiv.org/abs/2502.14796</link>
      <description><![CDATA[Arxiv：2502.14796V1公告类型：新 
摘要：大型语言模型（LLM）的兴起引入了信息检索（IR）的新时代，其中曾经假定由人类仅生成的查询和文档也可以由自动化代理创建。这些代理可以制定查询，生成文档并执行排名。这种转变挑战了一些长期存在的IR范式，并要求重新评估理论框架和实际方法。我们主张一个多机构的观点，以更好地捕获查询代理，文档代理和排名代理之间的复杂相互作用。通过对各种多代理检索设置的经验探索，我们揭示了这些相互作用对系统性能的重大影响。我们的发现强调了需要重新审视经典的IR范式并开发新框架，以更有效的建模和对现代检索系统的评估。]]></description>
      <guid>https://arxiv.org/abs/2502.14796</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息检索中模型体系结构的调查</title>
      <link>https://arxiv.org/abs/2502.14822</link>
      <description><![CDATA[ARXIV：2502.14822V1公告类型：新 
摘要：本调查研究了信息检索（IR）中模型体系结构的演变，重点介绍了两个关键方面：用于特征提取和端到端系统体系结构的骨干模型以进行相关性估计。该评论有意将建筑考虑与培训方法分开，以提供对IR系统中结构创新的重点分析。我们追踪从传统的基于术语的方法到现代神经方法的发展，尤其是突出了基于变形金刚的模型和随后的大型语言模型的影响（LLMS）。我们通过讨论新出现的挑战和未来方向，包括针对性能和可扩展性的建筑优化，多模式，多语言数据的处理以及对传统搜索范式以外的新型应用领域的适应。]]></description>
      <guid>https://arxiv.org/abs/2502.14822</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向上下文bust llms：一种封闭式的微调方法</title>
      <link>https://arxiv.org/abs/2502.14100</link>
      <description><![CDATA[ARXIV：2502.14100V1公告类型：交叉 
摘要：大型语言模型（LLM）通过外部环境增强，例如通过检索型发电（RAG），通常在处理不完善的证据时面临挑战。他们倾向于过度依靠外部知识，使它们容易受到误导性和无助的背景。为了解决这一问题，我们提出了上下文持续llms的概念，该概念可以有效地平衡内部知识与外部背景，类似于人类的认知过程。具体而言，上下文持续的LLM只有在缺乏内部知识，确定内部和外部知识之间的矛盾并忽略无用的上下文时才能依靠外部上下文。为了实现这一目标，我们介绍了GRFT，这是一种轻巧和插件的封闭式表示方法。 GRFT由两个关键组成部分组成：检测和过滤有问题输入的门控机制，以及低级别表示适配器以调整隐藏的表示。通过训练仅在少于200个示例的模型大小的0.0004 \％的轻量级干预功能，GRFT可以有效地使LLMS适应上下文 - 弹性行为。]]></description>
      <guid>https://arxiv.org/abs/2502.14100</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更少的是：关于数据质量对单位测试的重要性</title>
      <link>https://arxiv.org/abs/2502.14212</link>
      <description><![CDATA[Arxiv：2502.14212V1公告类型：交叉 
摘要：单元测试对于软件开发和维护至关重要。有效的单元测试可确保并提高软件质量，但是编写单元测试是耗时且劳动密集型的。最近的研究提出了深度学习（DL）技术或大型语言模型（LLMS），以使单元测试生成自动化。这些模型通常在大型数据集上训练或微调。尽管人们对数据质量的重要性的认识越来越多，但对用于测试生成的数据集的质量的研究有限。为了弥合这一差距，我们系统地检查噪声对基于学习的测试生成模型的性能的影响。我们首先应用开放卡排序方法来分析最流行，最大的测试生成数据集Methods2test，以对八种不同类型的噪声进行分类。此外，我们对17位领域专家进行了详细的访谈，以验证和评估噪声分类法的重要性，合理性和正确性。然后，我们提出了一个自动清洁噪声框架CleanTest，旨在提高测试生成数据集的质量。 CleanTest包括三个过滤器：基于规则的语法过滤器，基于规则的相关性过滤器和基于模型的覆盖过滤器。为了评估其有效性，我们将清洁测试应用于两个广泛使用的测试生成数据集，即Methods2-Test和Atlas。我们的发现表明，43.52％和29.65％的数据集包含噪声，突出了其患病率。最后，我们使用四个LLM（即Codebert，Athenatest，Starcoder和Codellama7b）进行比较实验，以评估噪声对测试生成性能的影响。结果表明，过滤噪声会积极影响模型的测试产生能力。]]></description>
      <guid>https://arxiv.org/abs/2502.14212</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个基于轻质和大型模型的移动设备的玉器识别系统</title>
      <link>https://arxiv.org/abs/2502.14332</link>
      <description><![CDATA[Arxiv：2502.14332v1公告类型：交叉 
摘要：随着移动设备的广泛采用和开发，基于视觉的识别应用已成为研究中的热门话题。作为重要的文化遗产和艺术品，Jade在珠宝识别和文化遗物保存等领域中具有重要的应用。但是，现有的Jade识别系统仍然面临移动实施中的挑战，例如计算资源有限，实时要求和准确性问题。为了应对这些挑战，本文提出了一种基于尺寸模型协作的玉牌识别系统，旨在使用智能手机等移动设备来实现高效且准确的玉器识别。通过分析玉的尺寸，形状和表面纹理来视觉信息。然后，通过结合深度学习和传统的计算机视觉算法来构建协作多模型分类框架。该框架可以根据不同的JADE特性有效地选择和调整模型，从而在各种环境和设备上提供高精度的结果。实验结果表明，所提出的系统可以在移动设备上提供高识别精度和快速处理时间，同时消耗相对较低的计算资源。该系统不仅具有巨大的应用潜力，而且还为杰德识别的智能发展提供了新的想法和技术支持。]]></description>
      <guid>https://arxiv.org/abs/2502.14332</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可概括性数学推理的检索授权过程奖励模型</title>
      <link>https://arxiv.org/abs/2502.14361</link>
      <description><![CDATA[arxiv：2502.14361v1公告类型：交叉 
摘要：尽管大型语言模型（LLM）具有显着高级的数学推理，但已经开发了过程奖励模型（PRM）来评估推理步骤的逻辑有效性。但是，PRM仍在挑战（OOD）挑战方面挣扎。本文确定了关键的OOD问题，包括步骤OOD，是由模型类型和大小的推理模式差异以及问题OOD引起的，这是由于训练数据和现实世界中的问题之间的数据集变化引起的。为了解决这些问题，我们介绍了检索提升的过程奖励模型（检索），这是一个旨在解决这些OOD问题的新型框架。通过利用两阶段的检索增强机制，检索语义上相似的问题和步骤作为热身，增强了PRM评估目标步骤，改善不同模型和问题类型的概括和推理一致性的能力。我们的广泛实验表明，检索PRM在多个现实世界数据集上的表现优于现有基线。我们的开源贡献包括检索增强数据集，用于PRM培训的调谐框架以及检索模型，为PRM性能建立了新的标准。]]></description>
      <guid>https://arxiv.org/abs/2502.14361</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长上下文查询集中摘要的非结构化证据归因</title>
      <link>https://arxiv.org/abs/2502.14409</link>
      <description><![CDATA[ARXIV：2502.14409V1公告类型：交叉 
摘要：大语言模型（LLMS）能够从较长的上下文中生成连贯的摘要，给定用户查询。提取并正确地引用证据可以帮助提高这些摘要的透明度和可靠性。同时，LLM在他们理解和参与的信息方面遭受位置偏见，这可能会影响证据引用。尽管以前的工作集中在具有预定义水平的粒度（例如句子，段落，文档等）的证据引用上，但我们提出了长篇文章查询以非结构化证据引用的重点汇总的任务。我们展示了现有系统如何从其上下文中产生并正确地引用非结构化证据，而证据往往是“中间失落的”。为了减轻这种情况，我们使用非结构化的证据文本数据集（Sunset）创建摘要，这是一种使用新颖的域 - 无术管道生成的合成数据集，可以用作将LLMS调整为此任务的监督。我们在5个不同尺寸和4个数据集的5个LLM中证明了具有不同文档类型和长度的LLM，这些LLMS与日落数据相比，与基本模型相比，与日落数据相适应的相关性和事实一致的证据，在其上下文中提取更多不同地点的证据，并且可以产生更相关的证据，并且可以产生更相关的证据。和一致的摘要。]]></description>
      <guid>https://arxiv.org/abs/2502.14409</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多唱片网页信息从新闻网站提取</title>
      <link>https://arxiv.org/abs/2502.14625</link>
      <description><![CDATA[ARXIV：2502.14625V1公告类型：交叉 
摘要：在本文中，我们专注于从包含许多记录的网页中提取信息的问题，这是大规模网络数据时代越来越重要的任务。最近，神经网络方法的开发提高了网页中信息提取的质量。然而，大多数研究和数据集旨在研究详细的页面。尽管存在广泛的存在和实践意义，但这使多纪录的“列表页面”相对研究。
  为了解决此差距，我们创建了一个专门为列表页面设计的大规模开放式数据集。这是俄罗斯语言中此任务的第一个数据集。我们的数据集包含带有新闻列表的13,120个网页，大大超过了规模和复杂性的现有数据集。我们的数据集包含各种类型的属性，包括可选和多价值，提供了现实世界列表页面的现实表示。这些功能使我们的数据集成为从包含许多记录的页面中研究信息提取的宝贵资源。
  此外，我们提出了自己的多阶段信息提取方法。在这项工作中，我们探索并演示了将MarkuPlm应用于多唱片网页的具体挑战的几种策略。我们的实验验证了我们方法的优势。
  通过向公众发布数据集，我们旨在推进从多纪录页面中提取信息领域。]]></description>
      <guid>https://arxiv.org/abs/2502.14625</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>指导：通过LLM代理构建用户可控的推荐人</title>
      <link>https://arxiv.org/abs/2502.14662</link>
      <description><![CDATA[ARXIV：2502.14662V1公告类型：交叉 
摘要：传统的推荐系统通常采用用户平台范式，在该范围内，用户直接在平台推荐算法的控制下暴露。但是，建议算法的缺陷可能使用户在此范式下处于非常脆弱的位置。首先，许多复杂的模型通常都考虑到商业目标，重点关注平台的好处，这可能会阻碍他们保护和捕捉用户真正兴趣的能力。其次，通常使用所有用户的数据对这些模型进行优化，这可能会忽略单个用户的偏好。由于这些缺点，用户可能会在传统的用户平台直接曝光范式下遇到几个缺点，例如缺乏对推荐系统的控制，平台的潜在操作，回声室效果或由于由于缺乏对较低的用户的个性化的控制积极用户在协作学习过程中的主导地位。因此，迫切需要开发新的范式来保护用户利益并减轻这些问题。最近，一些研究人员引入了LLM代理以模拟用户行为，这些方法主要旨在优化平台侧性能，而在建议系统中尚未解决的核心问题。为了解决这些限制，我们提出了一个新的用户代理平台范式，在该范式中，代理可以用作用户和推荐系统之间的保护屏蔽，从而可以间接暴露。为此，我们首先构建了四个建议数据集，称为$ \ dataset $，以及每个记录的用户说明。]]></description>
      <guid>https://arxiv.org/abs/2502.14662</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从知识生成到知识验证：研究Chatgpt的生物医学生成能力</title>
      <link>https://arxiv.org/abs/2502.14714</link>
      <description><![CDATA[ARXIV：2502.14714V1公告类型：交叉 
摘要：LLM模型的生成能力在加速任务和关注方面提供了与其产生的知识的真实性的机会。为了解决这些问题，我们提出了一种计算方法，该方法系统地评估了生物医学知识的事实准确性，即LLM模型已被促使生成。我们的方法包括两个过程：以疾病为中心的关联的产生以及使用生物医学本体学的语义知识对它们进行验证。我们使用Chatgpt作为选择的LLM模型，我们设计了一组及时的工程过程，以在疾病，药物，症状和基因之间建立联系，以建立评估的基础。实验结果表明，鉴定疾病术语（88％-97％），药物名称（90％-91％）和遗传信息（88％-98％）的精度很高。症状术语识别准确性明显较低（49％-61％），如DOID，CHEBI，症状和GOSOLOGISE验证。对关联的验证揭示了疾病 - 药物和疾病 - 基因协会中文献覆盖率（89％-91％）。症状术语的低鉴定精度也有助于验证与症状相关的关联（49％-62％）。]]></description>
      <guid>https://arxiv.org/abs/2502.14714</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释的文本嵌入和文本相似性解释：底漆</title>
      <link>https://arxiv.org/abs/2502.14862</link>
      <description><![CDATA[ARXIV：2502.14862V1公告类型：交叉 
摘要：文本嵌入和文本嵌入模型是许多AI和NLP系统的骨干，尤其是涉及搜索的系统。但是，解释性挑战持续存在，特别是在解释获得的相似性分数时，这对于需要透明度的应用至关重要。在本文中，我们对专门解释这些相似性分数（一个新兴研究领域）的解释性方法进行了结构化概述。我们研究了方法的个人思想和技术，评估了它们提高文本嵌入的解释性的潜力并解释了预测的相似之处。]]></description>
      <guid>https://arxiv.org/abs/2502.14862</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>