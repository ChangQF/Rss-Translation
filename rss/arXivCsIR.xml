<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 26 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>外部大型基础模型：如何有效地为在线广告推荐数万亿个参数</title>
      <link>https://arxiv.org/abs/2502.17494</link>
      <description><![CDATA[ARXIV：2502.17494V2公告类型：新 
摘要：广告推荐是在线广告系统的重要服务，并且已经进行了积极研究。最近的研究表明，推荐模型的扩展和高级设计可以带来显着的性能提高。但是，随着模型量表的较大，这种先前的研究的差距大大增加，因为它们经常忽略了工业规模应用中的两个基本挑战。首先，培训和推理预算受到限制，可以为模型提供服务，从而超过可能产生延迟并损害用户体验。其次，随着新用户/广告的加入，并且现有用户/广告离开系统时，大批量数据以数据分布动态转移而到达流媒体模式。我们提出了外部大型基础模型（EXFM）框架，以应对被忽视的挑战。具体而言，我们开发了外部蒸馏和数据增强系统（DAS），以控制培训/推理的计算成本，同时保持高性能。我们以类似基础模型（FM）的方式设计教师，该模型可以为多个学生提供垂直模型（VM），以摊销其建筑成本。我们建议辅助负责人和学生适配器来减轻流媒体数据问题引起的FM和VM之间的数据分布差距。关于内部工业规模应用和公共数据集的全面实验表明，EXFM的绩效增长很大。]]></description>
      <guid>https://arxiv.org/abs/2502.17494</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>舌头查询启发用于模拟评估</title>
      <link>https://arxiv.org/abs/2502.17776</link>
      <description><![CDATA[ARXIV：2502.17776V1公告类型：新 
摘要：当用户努力召回特定标识符（例如文档标题）时，会发生小费（TOT）搜索。虽然常见，但现有的搜索系统通常无法有效地支持TOT方案。关于TOT检索的研究进一步受到收集查询的挑战的限制，因为当前的方法很大程度上依赖社区提问（CQA）网站，从而导致劳动密集型评估和领域偏见。为了克服这些局限性，我们介绍了两种用于引起TOT查询的方法 - 利用大型语言模型（LLM）和人类参与者 - 以促进对TOT检索系统的模拟评估。我们的基于LLM的TOT用户模拟器会大规模生成合成TOT查询，从而与基于CQA的TOT查询在电影域进行测试时如何等级TOT检索系统。此外，这些合成查询与CQA衍生的查询表现出很高的语言相似性。对于人类精选的查询，我们开发了一种使用视觉刺激将参与者置于TOT状态的界面，从而可以收集自然查询。在电影领域，系统级别的相关性和语言相似性分析证实，人类引起的查询既有效又非常类似于基于CQA的查询。这些方法减少了对基于CQA的数据收集的依赖，同时将覆盖范围扩大到代表性不足的领域（例如地标和人员）。 LLM引用的电影，地标和人域的查询已作为TREC 2024 TOT曲目中的测试查询发布，并计划在TREC 2025 Tot Track中包含人类精选的查询。此外，我们还提供了合成查询生成和人类查询收集接口的源代码，以及用于启发TOT查询的策划的视觉刺激。]]></description>
      <guid>https://arxiv.org/abs/2502.17776</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HyperG：用于结构化知识的超图增强LLM</title>
      <link>https://arxiv.org/abs/2502.18125</link>
      <description><![CDATA[ARXIV：2502.18125V1公告类型：新 
摘要：鉴于大量特定领域的知识以结构化格式存储，例如通过HTML组织的Web数据，大型语言模型（LLMS）有望完全理解这些结构化信息，以扩大其在各种现实世界下游任务中的应用。将LLM应用于结构化数据的当前方法分为两个主要类别：基于序列化和基于操作的方法。无论是依靠序列化还是使用类似SQL的操作作为中介机构，这两种方法都在完全捕获结构关系并有效处理稀疏数据时遇到困难。为了解决结构化数据的这些独特特征，我们提出了HyperG，这是一个基于超毛电的生成框架，旨在增强LLMS处理结构化知识的能力。具体而言，HyperG首先增强了具有上下文信息的稀疏数据，利用LLM的生成能力，并结合了及时的竞争性超毛学学习（PHL）网络，以编码数据中的增强信息和复杂的结构关系。为了验证HyperG的有效性和概括，我们对需要结构化知识的两个不同下游任务进行了广泛的实验。]]></description>
      <guid>https://arxiv.org/abs/2502.18125</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图融合的神经网络图相似性计算</title>
      <link>https://arxiv.org/abs/2502.18291</link>
      <description><![CDATA[Arxiv：2502.18291V1公告类型：新 
摘要：图形相似性学习，对于诸如图形分类和相似性搜索等任务至关重要，重点是衡量两个图形结构化实体之间的相似性。该领域的核心挑战是有效地管理图表之间的相互作用。传统方法通常需要为每个图对分开，冗余的计算，从而导致不必要的复杂性。本文通过引入称为图融合的平行图相互作用方法来彻底改变该方法。通过将图形对的节点序列合并到单个大图中，我们的方法利用了一种全局注意机制来促进相互作用计算并收获跨界洞察。我们进一步评估了两个不同级别的图形级别和节点级 - 引入两个创新但直接的相似性计算算法的图形对之间的相似性。在五个公共数据集中进行的广泛测试表明，我们的模型不仅胜过图形之间的基线模型和回归任务，还为性能和效率设定了新的基准。本文的代码是开源的，可在https://github.com/llirarry/gfm-code.git上找到]]></description>
      <guid>https://arxiv.org/abs/2502.18291</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一的贝叶斯关于常规和强大自适应过滤器的观点</title>
      <link>https://arxiv.org/abs/2502.18325</link>
      <description><![CDATA[ARXIV：2502.18325V1公告类型：新 
摘要：在这项工作中，我们介绍了有关自适应过滤器的起源和解释的新观点。通过从状态空间模型应用递归推断的贝叶斯原理，并使用有关解决方案结构的一系列简化，我们可以在统一的框架中介绍许多自适应过滤器的推导，这些自适应过滤器取决于观察噪声的概率模型。特别是，在高斯模型下，我们获得了文献中众所周知的解决方案（例如LMS，NLMS或Kalman滤波器），同时使用非高斯噪声，我们获得了自适应滤波器的新家族。值得注意的是，在假设拉普拉斯噪声的假设下，我们获得了一个坚固的过滤器系列，签名的eRror算法是一个众所周知的成员，而其他算法在拟议的框架中毫不费力地得出了全部。显示数值示例可以说明属性并更好地了解派生的自适应过滤器的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.18325</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>等级1：在信息检索中重新计算的测试时间计算</title>
      <link>https://arxiv.org/abs/2502.18418</link>
      <description><![CDATA[ARXIV：2502.18418V1公告类型：新 
摘要：我们介绍了Rank1，这是第一个训练有素的重读模型，以利用测试时间计算。 Rank1演示了使用推理语言模型（即OpenAI的O1，DeepSeek的R1等）的检索中的适用性，以迅速提高较小模型的性能。我们从Marco中的查询和段落中收集并开放一个数据集，其中包含60万多个R1推理痕迹的示例。在此数据集上训练的模型显示：（1）在数据集之后的高级推理和指令上的最先进性能； （2）由于能够响应用户输入提示，因此工作非常出色； （3）具有可解释的推理链，可以给予用户或基于抹布的系统。此外，我们证明了这些模型的量化版本在使用较少的计算/内存的同时保留了强烈的性能。总体而言，RANK1表明，测试时间计算允许从根本上进行搜索的可解释和性能的Reranker模型。]]></description>
      <guid>https://arxiv.org/abs/2502.18418</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Google搜索上的数据空隙和警告横幅</title>
      <link>https://arxiv.org/abs/2502.17542</link>
      <description><![CDATA[ARXIV：2502.17542V1公告类型：交叉 
摘要：社交媒体网站使用的内容审核系统是广泛兴趣和研究的一个主题，但对通过Web搜索引擎使用类似系统的使用知之甚少。例如，Google搜索试图通过将三个相应的警告横幅之一之一之一放在搜索页面的顶部，以帮助其用户导航三种不同类型的数据空隙（可用的搜索结果被认为是低质量，低率或快速变化的）。在这里，我们收集了140万个在社交媒体上共享的唯一搜索查询，以露出Google的警告横幅，检查何时以及为什么应用这些横幅，并训练深度学习模型，以识别Google分类以外的数据空隙。在三个数据收集浪潮（2023年10月，2024年3月，2024年9月）中，我们发现Google以大约1％的搜索查询返回了一个警告横幅，在一组查询中大量搅动，在跨波浪中收到横幅的一系列查询。低质量的横幅警告用户他们的结果“可能没有有关此主题的可靠信息”，它们的存在与搜索结果中的低质量域与搜索查询中与阴谋相关的关键字有关。即使返回高度相似的搜索结果，在短时间内，低质量的横幅存在也是不一致的。 2024年8月，低质量的横幅不再出现在我们收集的SERP上，但平均搜索结果质量在很大程度上没有变化，这表明它们可能已经被Google停止了。使用我们的深度学习模型来分析上下文中的查询和搜索结果，我们识别出比低质量横幅的低质量数据空隙的29至58倍，并在横幅消失后找到了相似的数字。我们的发现表明，需要对搜索引擎的内容审核实践提高透明度，尤其是在重要事件之类的重要事件中。]]></description>
      <guid>https://arxiv.org/abs/2502.17542</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有表达音乐性能检测功能的Gigamidi数据集</title>
      <link>https://arxiv.org/abs/2502.17726</link>
      <description><![CDATA[ARXIV：2502.17726V1公告类型：交叉 
摘要：1983年推出的乐器数字界面（MIDI），通过允许计算机和仪器进行有效沟通来彻底改变音乐的制作。 MIDI文件紧凑地编码音乐说明，从而促进便利的音乐共享。他们使音乐信息检索受益（MIR），协助有关音乐理解，计算音乐学和生成音乐的研究。 Gigamidi数据集包含超过140万个独特的MIDI文件，其中包括18亿个MIDI音符事件和超过530万个MIDI轨道。 Gigamidi目前是MIDI格式的最大符号音乐集，可用于研究目的。区分非表达和表达的MIDI轨道是具有挑战性的，因为MIDI文件并不能固有地做出这种区别。为了解决这个问题，我们介绍了一组创新的启发式方法，以检测表现力的音乐表现。其中包括独特的音符速度比（DNVR）启发式，该启发式分析了MIDI NOTE速度。独特的音符发作偏差比（DNODR）启发式，该启发式检查了注意发作时间的偏差； Note发作中值度量水平（NOMML）启发式启发式，该启发式评估了相对于度量水平的发作位置。我们的评估表明，这些启发式方法有效地区分了非表现性和表达性MIDI轨道。此外，经过评估后，我们使用我们的启发式Nomml创建了最实质性的表达MIDI数据集。这种策划的Gigamidi的迭代包括由Nomml检测到的表达性仪器轨道，其中包含所有通用MIDI仪器，占GIGAMIDI数据集的31％，总计1,655,649个曲目。]]></description>
      <guid>https://arxiv.org/abs/2502.17726</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在建议系统中揭示性别偏见并增强类别意识公平</title>
      <link>https://arxiv.org/abs/2502.17921</link>
      <description><![CDATA[Arxiv：2502.17921V1公告类型：交叉 
摘要：推荐系统现在是我们日常生活中不可或缺的一部分。我们依靠它们来完成诸如发现新电影，在社交媒体上找到朋友以及将求职者与相关机会联系起来的任务。鉴于它们的重要作用，我们必须确保这些建议没有社会刻板印象。因此，在推荐系统中评估和解决此类偏见至关重要。评估推荐物品公平性的先前工作未能捕捉到某些细微差别，因为它们主要集中于比较不同敏感群体的性能指标。在本文中，我们介绍了一组综合指标，以量化建议中的性别偏见。具体来说，我们表明了在更详细的水平上评估公平性的重要性，可以使用我们的指标使用推荐项目（例如电影类型）来捕获性别偏见来实现这一目标。此外，我们表明，使用类别意识的公平度量作为正规化术语以及训练期间的主要建议损失可以有效地最大程度地减少模型输出中的偏见。我们使用五个基线模型与两个流行的公平感知模型一起在三个现实世界数据集上进行了实验，以显示我们指标在评估性别偏见方面的有效性。与以前的指标相比，我们的指标有助于增强对推荐项目的偏见的洞察力。此外，我们的结果表明，合并我们的正则化项如何显着提高不同类别的建议的公平性，而不会在总体建议性能中实质性降低。]]></description>
      <guid>https://arxiv.org/abs/2502.17921</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于特定领域的生成检索的合成数据策略</title>
      <link>https://arxiv.org/abs/2502.17957</link>
      <description><![CDATA[ARXIV：2502.17957V1公告类型：交叉 
摘要：本文研究了开发针对领域特异性语料库的生成检索模型的综合数据生成策略，从而解决了手动注释内域查询所固有的可伸缩性挑战。我们研究了一个两阶段培训框架的数据策略：在第一阶段，该阶段的重点是学习从查询中解码文档标识符，我们研究了LLM生成的跨多个粒度（例如块，句子）和域相关搜索约束的查询，这些查询可以更好地捕获差异相关信号。在第二阶段，旨在通过偏好学习来完善文档排名，我们根据初始模型的预测探讨了挖掘艰苦负面因素的策略。在公共数据集上进行的有关不同领域的实验证明了我们的合成数据生成和硬采样方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.17957</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法师：多头注意力指导的嵌入较低的资源情感分类</title>
      <link>https://arxiv.org/abs/2502.17987</link>
      <description><![CDATA[ARXIV：2502.17987V1公告类型：交叉 
摘要：由于缺乏低资源班图语言的质量数据，文本分类和其他实际实施中提出了重大挑战。在本文中，我们介绍了一个高级模型，该模型将独立于语言的数据增强（LIDA）与多头关注的加权嵌入在一起，以选择性地增强关键数据点并提高文本分类性能。这种集成使我们能够创建强大的数据增强策略，这些策略在各种语言环境中都是有效的，从而确保我们的模型可以处理班图语的独特句法和语义特征。这种方法不仅解决了数据稀缺问题，而且还为低资源语言处理和分类任务的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.17987</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>vidorag：通过动态迭代推理剂的视觉文档检索启动生成</title>
      <link>https://arxiv.org/abs/2502.18017</link>
      <description><![CDATA[ARXIV：2502.18017V1公告类型：交叉 
摘要：从视觉上富裕的文档中了解信息仍然是传统检索型生成（RAG）方法的重大挑战。现有基准主要集中在基于图像的问题答案（QA）上，忽视了密集的视觉文档中有效检索，理解和推理的基本挑战。为了弥合这一差距，我们介绍了Vidoseek，这是一个新颖的数据集，旨在评估需要复杂推理的视觉丰富文档的抹布性能。基于它，我们确定了当前抹布方法中的关键局限性：（i）纯粹的视觉检索方法难以有效地整合文本和视觉特征，以及（ii）以前的方法通常分配不足的推理令牌，从而限制了它们的有效性。为了应对这些挑战，我们提出了Vidorag，这是一个新型的多代理RAG框架，该框架量身定制了跨视觉文档的复杂推理。 Vidorag采用高斯混合模型（GMM）的混合策略来有效处理多模式检索。为了进一步引起该模型的推理能力，我们引入了一个迭代代理工作流，其中包含了探索，摘要和反思，提供了一个框架，用于研究RAG域中的测试时间缩放。关于Vidoseek的广泛实验验证了我们方法的有效性和概括。值得注意的是，Vidorag在竞争性Vidoseek基准上优于现有方法超过10％。]]></description>
      <guid>https://arxiv.org/abs/2502.18017</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Afroxlmr-comet：多语言知识蒸馏与低资源语言的注意匹配</title>
      <link>https://arxiv.org/abs/2502.18020</link>
      <description><![CDATA[ARXIV：2502.18020V1公告类型：交叉 
摘要：通过知识蒸馏的语言模型压缩已成为一种在资源受限环境中部署大型语言模型的有前途的方法。但是，现有的方法通常在蒸馏多语言模型时通常难以保持性能，尤其是对于低资源语言。在本文中，我们提出了一种新型的混合蒸馏方法，该方法将传统知识蒸馏与简化的注意匹配机制相结合，该机制是专门为多语言环境设计的。我们的方法引入了非常紧凑的学生模型架构，比传统的多语言模型要小得多。我们评估了五种非洲语言的方法：Kinyarwanda，Swahili，Hausa，Igbo和Yoruba。蒸馏学生模型； Afroxlmr-comp成功地捕获了较大的教师模型（Afroxlmr-large）的输出分布和内部注意力模式，同时将模型大小降低了85％以上。实验结果表明，与教师模型相比，我们的混合方法可以实现竞争性能，在原始模型绩效的85％之内保持准确性，同时需要更少的计算资源。我们的工作为在资源受限的环境中部署有效的多语言模型提供了一个实用的框架，尤其是受益于涉及非洲语言的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2502.18020</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LevelRag：通过重写增强搜索器的多跳逻辑计划增强检索效果的生成</title>
      <link>https://arxiv.org/abs/2502.18139</link>
      <description><![CDATA[ARXIV：2502.18139V1公告类型：交叉 
摘要：检索增强的生成（RAG）是减轻大语言模型（LLMS）中幻觉并将外部知识整合到其反应中的关键方法。现有的抹布方法通常采用查询重写来阐明用户意图并管理多跳逻辑，同时使用混合检索来扩展搜索范围。但是，查询重写与密集回猎商的紧密耦合限制了其与混合检索的兼容性，阻碍了进一步的破布性能。为了应对这一挑战，我们引入了一个高级搜索器，将复杂的查询分解为原子查询，而与任何猎犬特定的优化无关。此外，为了利用稀疏检索器的优势进行精确的关键字检索，我们开发了一个新的稀疏搜索器，该稀疏搜索器采用Lucene语法来增强检索准确性。同时网络和密集的搜索器，这些组件在我们建议的方法中无缝协作，\ textbf {levelRag}。在LevelRag中，高级搜索器协调检索逻辑，而低级搜索者（稀疏，网络和密集）则完善了查询以进行最佳检索。这种方法增强了检索过程的完整性和准确性，克服了与当前查询重写技术相关的挑战。在五个数据集上进行的经验实验，包括单跳和多跳的问题答案任务，证明了与现有的抹布方法相比，LevelRag的出色性能。值得注意的是，LevelRag的表现优于最先进的专有模型GPT4O，强调了其有效性和对抹布场的潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2502.18139</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学相关性有多么重要：法律文章干预了法律案件检索和匹配</title>
      <link>https://arxiv.org/abs/2502.18292</link>
      <description><![CDATA[ARXIV：2502.18292V1公告类型：交叉 
摘要：法律案件检索（LCR）旨在根据给定查询自动搜索可比的法律案件，这对于提供相关先例至关重要，以支持智能法律制度的判决。由于目标类似，它通常与类似的案例匹配（LCM）任务相关联。为了解决这些问题，一个艰巨的挑战是评估司法领域内独特定义的法律理性相似性，这显然偏离了一般文本检索中的语义相似性。过去的作品要么标记为特定于域的因素，要么纳入参考法律以捕获法律理性信息。但是，他们对专家或不切实际的假设的极大依赖限制了它们在现实情况下的实际适用性。在本文中，我们提出了一个名为LCM-LAI的端到端模型，以解决上述挑战。通过细致的理论分析，LCM-LAI采用依赖的多任务学习框架来通过法律文章预测（LAP）子任务捕获法律案件中的法律理性信息，而没有任何其他推理假设。此外，LCM-Lai提出了一种文章意识到的注意机制，以根据法律分布评估跨案例句子之间的法律理性相似性，这比传统的语义相似性更有效。 Weperform一系列详尽的实验，包括涉及四个现实世界数据集的两个不同任务。结果表明，LCM-Lai可以实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.18292</guid>
      <pubDate>Wed, 26 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>