<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 18 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>绿色AI时代的标杆新闻推荐</title>
      <link>https://arxiv.org/abs/2403.04736</link>
      <description><![CDATA[arXiv:2403.04736v2 公告类型：替换
摘要：近年来，新闻推荐系统在学术界和工业界引起了极大的关注，强调需要一个标准化的基准来评估和比较这些系统的性能。同时，绿色人工智能倡导减少机器学习的能源消耗和环境影响。为了解决这些问题，我们引入了第一个用于新闻推荐的绿色人工智能基准测试框架，称为 GreenRec，并提出了一个用于评估推荐准确性和效率之间权衡的指标。我们的基准测试涵盖 30 个基本模型及其变体，涵盖传统的端到端训练范例以及我们提出的高效仅编码一次 (OLEO) 范例。通过消耗 2000 个 GPU 小时的实验，我们观察到，与最先进的端到端范例相比，OLEO 范例实现了有竞争力的准确性，并在可持续性指标方面实现了高达 2992% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2403.04736</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>通过神经模式关联器进行篮内推荐</title>
      <link>https://arxiv.org/abs/2401.16433</link>
      <description><![CDATA[arXiv:2401.16433v2 公告类型：替换
摘要： 篮内推荐（WBR）是指在购物过程中推荐商品直至完成非空购物篮的任务。虽然该领域的最新创新在基准数据集上展示了显着的性能改进，但它们往往忽视了实践中用户行为的复杂性，例如 1) 多种购物意图的共存，2) 此类意图的多粒度，以及 3)购物过程中的交错行为（转换意图）。本文提出了神经模式关联器（NPA），这是一种深度项目关联挖掘模型，可以显式地模拟上述因素。具体来说，受矢量量化的启发，NPA 模型学习将常见的用户意图（或项目组合模式）编码为量化表示（又名密码本），从而允许在推理阶段通过注意力驱动的查找来识别用户的购物意图。这会产生连贯且可自我解释的建议。我们在多个广泛的数据集上评估了所提出的 NPA 模型，涵盖杂货电子商务（购物篮完成）和音乐（播放列表扩展）领域，其中我们的定量评估表明 NPA 模型显着优于各种现有的 WBR 解决方案，反映了明确建模复杂用户意图的好处。]]></description>
      <guid>https://arxiv.org/abs/2401.16433</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>用于准确推荐的端到端图顺序表示学习</title>
      <link>https://arxiv.org/abs/2403.00895</link>
      <description><![CDATA[arXiv:2403.00895v3 公告类型：替换
摘要：最近推荐系统的进展集中在开发基于序列和基于图的方法。事实证明，这两种方法在对行为数据中的复杂关系进行建模方面非常有用，从而在个性化排名和下一项推荐任务中取得有希望的结果，同时保持良好的可扩展性。然而，它们从数据中捕获非常不同的信号。前一种方法通过与最近项目的有序交互直接代表用户，而后者旨在捕获交互图中的间接依赖关系。本文提出了一种利用这两种范式协同作用的新颖的多表示学习框架。我们对几个数据集的实证评估表明，使用所提出的框架对序列和图形组件进行相互训练可以显着提高推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2403.00895</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>SocialGenPod：具有去中心化个人数据存储的隐私友好型生成人工智能社交网络应用程序</title>
      <link>https://arxiv.org/abs/2403.10408</link>
      <description><![CDATA[arXiv:2403.10408v1 公告类型：交叉
摘要：我们提出了 SocialGenPod，这是一种去中心化且隐私友好的部署生成式 AI Web 应用程序的方式。与将用户数据与应用程序和服务提供商联系在一起的集中式 Web 和数据架构不同，我们展示了如何使用 Solid（一种去中心化的 Web 规范）将用户数据与生成式 AI 应用程序解耦。我们使用原型演示 SocialGenPod，该原型允许用户与不同的大型语言模型进行对话，可以选择利用检索增强生成来生成基于存储在允许用户直接或间接访问的任何 Solid Pod 中的私人文档的答案。 SocialGenPod 利用可靠的访问控制机制，让用户完全控制确定谁有权访问其 Pod 中存储的数据。 SocialGenPod 将所有用户数据（聊天记录、应用程序配置、个人文档等）安全地保存在用户的个人 Pod 中；与特定模型或应用程序提供商分开。除了更好的隐私控制之外，这种方法还可以实现跨不同服务和应用程序的可移植性。最后，我们讨论了由最先进模型的大量计算需求所带来的挑战，这是该领域未来研究应该解决的问题。我们的原型是开源的，可从以下网址获取：https://github.com/Viminas/socialgenpod/。]]></description>
      <guid>https://arxiv.org/abs/2403.10408</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>FeatUp：适用于任何分辨率特征的模型无关框架</title>
      <link>https://arxiv.org/abs/2403.10516</link>
      <description><![CDATA[arXiv:2403.10516v1 公告类型：交叉
摘要：深层特征是计算机视觉研究的基石，它捕获图像语义并使社区即使在零镜头或少镜头情况下也能解决下游任务。然而，这些特征通常缺乏空间分辨率来直接执行分割和深度预测等密集预测任务，因为模型会积极地池化大区域的信息。在这项工作中，我们引入了 FeatUp，这是一个与任务和模型无关的框架，用于恢复深层特征中丢失的空间信息。我们引入了 FeatUp 的两种变体：一种在单次前向传递中引导高分辨率信号的特征，另一种将隐式模型拟合到单个图像以在任何分辨率下重建特征。这两种方法都使用多视图一致性损失，与 NeRF 具有深刻的类比。我们的功能保留了其原始语义，并且可以交换到现有应用程序中，即使无需重新训练也能获得分辨率和性能提升。我们表明，FeatUp 在类激活图生成、分割和深度预测的迁移学习以及语义分割的端到端训练方面显着优于其他特征上采样和图像超分辨率方法。]]></description>
      <guid>https://arxiv.org/abs/2403.10516</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>VideoAgent：以大语言模型为代理的长格式视频理解</title>
      <link>https://arxiv.org/abs/2403.10517</link>
      <description><![CDATA[arXiv:2403.10517v1 公告类型：交叉
摘要：长视频理解是计算机视觉领域的一个重大挑战，需要一个能够对长多模态序列进行推理的模型。受人类对长视频理解的认知过程的推动，我们强调交互式推理和规划，而不是处理冗长的视觉输入的能力。我们引入了一种新颖的基于代理的系统 VideoAgent，它采用大型语言模型作为中央代理来迭代地识别和编译关键信息来回答问题，并以视觉语言基础模型作为翻译和检索视觉信息的工具。根据具有挑战性的 EgoSchema 和 NExT-QA 基准进行评估，VideoAgent 实现了 54.1% 和 71.3% 的零镜头准确率，平均仅使用 8.4 和 8.2 帧。这些结果证明了我们的方法比当前最先进的方法具有卓越的有效性和效率，凸显了基于代理的方法在推进长视频理解方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2403.10517</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>DRAGIN：基于大型语言模型实时信息需求的动态检索增强生成</title>
      <link>https://arxiv.org/abs/2403.10081</link>
      <description><![CDATA[arXiv:2403.10081v1 公告类型：交叉
摘要：动态检索增强生成（RAG）范式主动决定在大型语言模型（LLM）的文本生成过程中何时检索以及检索什么内容。该范例有两个关键要素：确定激活检索模块的最佳时刻（决定何时检索）以及在触发检索后制定适当的查询（确定检索什么）。然而，当前的动态 RAG 方法在这两方面都存在不足。首先，决定何时检索的策略通常依赖于静态规则。此外，决定检索内容的策略通常仅限于 LLM 最近的句子或最后几个标记，而 LLM 的实时信息需求可能跨越整个上下文。为了克服这些限制，我们引入了一个新的框架，DRAGIN，即基于法学硕士实时信息需求的动态检索增强生成。我们的框架专门设计用于根据法学硕士在文本生成过程中的实时信息需求来决定检索的时间和内容。我们在 4 个知识密集型生成数据集上全面评估 DRAGIN 以及现有方法。实验结果表明，DRAGIN 在所有任务上都取得了优异的性能，证明了我们方法的有效性。我们已在 GitHub 中开源了所有代码、数据和模型：https://github.com/oneal2000/DRAGIN/tree/main]]></description>
      <guid>https://arxiv.org/abs/2403.10081</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>音频文本检索的跨模态相似性一致性驱动的多尺度匹配</title>
      <link>https://arxiv.org/abs/2403.10146</link>
      <description><![CDATA[arXiv:2403.10146v1 公告类型：交叉
摘要：音频文本检索（ATR）可以在给定音频剪辑（A2T）的情况下检索相关标题，反之亦然（T2A），最近引起了广泛的研究关注。现有的方法通常将来自每种模态的信息聚合到单个向量中进行匹配，但这会牺牲局部细节，并且很难捕获模态内部和模态之间的复杂关系。此外，当前的 ATR 数据集缺乏全面的对齐信息，简单的二元对比学习标签忽视了样本之间细粒度语义差异的测量。为了应对这些挑战，我们提出了一种新颖的 ATR 框架，该框架从不同角度和更细粒度全面捕获多模态信息的匹配关系。具体来说，引入了细粒度的对齐方法，通过从局部到全局级别的多尺度过程实现更注重细节的匹配，以捕捉细致的跨模态关系。此外，我们开创了跨模式相似性一致性的应用，利用模式内相似性关系作为软监督来促进更复杂的对齐。大量实验验证了我们方法的有效性，在 AudioCaps 数据集上优于以前的方法，至少 3.9% (T2A) / 6.9% (A2T) R@1 和 2.9% (T2A) / 5.4% (A2T) R@ 的显着优势Clotho 数据集上的 1。]]></description>
      <guid>https://arxiv.org/abs/2403.10146</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>Magic Tokens：选择多样化的Token进行多模态物体重识别</title>
      <link>https://arxiv.org/abs/2403.10254</link>
      <description><![CDATA[arXiv:2403.10254v1 公告类型：交叉
摘要：单模态对象重新识别（ReID）在复杂视觉场景中保持鲁棒性方面面临着巨大挑战。相比之下，多模态对象 ReID 利用来自不同模态的互补信息，显示出实际应用的巨大潜力。然而，以前的方法可能很容易受到不相关背景的影响，并且通常忽略模态差距。为了解决上述问题，我们提出了一种名为 \textbf{EDITOR} 的新颖学习框架，用于从视觉 Transformer 中选择不同的标记来进行多模式对象 ReID。我们从一个共同的愿景 Transformer 开始，从不同的输入模式中提取标记化特征。然后，我们引入空间频率标记选择（SFTS）模块来自适应地选择具有空间和频率信息的以对象为中心的标记。之后，我们采用分层屏蔽聚合（HMA）模块来促进模态内部和跨模态的特征交互。最后，为了进一步减少背景的影响，我们提出了背景一致性约束（BCC）和以对象为中心的特征细化（OCFR）。它们被制定为两个新的损失函数，通过背景抑制改善特征辨别。因此，我们的框架可以为多模式对象 ReID 生成更具辨别力的特征。对三个多模态 ReID 基准的大量实验验证了我们方法的有效性。该代码可在 https://github.com/924973292/EDITOR 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.10254</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>应对生成的替代事实的危险：ChatGPT-4 伪造的 Omega 变体案例作为医疗错误信息的警示故事</title>
      <link>https://arxiv.org/abs/2403.09674</link>
      <description><![CDATA[arXiv:2403.09674v1 公告类型：交叉
摘要：在人工智能（AI）与医学研究交织的时代，真相的界定变得越来越复杂。这项研究表面上检查了一种所谓的新型 SARS-CoV-2 变体，称为 Omega 变体，展示了 S 基因区域的 31 个独特突变。然而，这种叙述的真正潜流是人工智能，特别是 ChatGPT-4，可以轻松地制造令人信服但完全虚构的科学数据。所谓的 Omega 变种是在一名完全接种疫苗、之前感染过的 35 岁男性中发现的，该男性出现了严重的 COVID-19 症状。通过详细的、尽管是人为的基因组分析和接触者追踪，这项研究反映了真实病例报告的严格方法，从而为令人信服但完全构建的叙述奠定了基础。整个案例研究由 OpenAI 的大型语言模型 ChatGPT-4 生成。制造的 Omega 变体具有一系列突变，包括以增强 ACE2 受体亲和力而闻名的 N501Y 和 E484K，以及表面上表明免疫逃避的 L452R 和 P681H。这种变体的人为交互动态——接种疫苗的个体出现严重症状，而未接种疫苗的接触者出现轻微症状——旨在模拟现实世界的复杂性，包括抗体依赖性增强（ADE）的建议。虽然欧米茄变体是人工智能生成的小说的产物，但这一练习的含义是真实而深刻的。正如本例所示，人工智能可以轻松生成可信但虚假的科学信息，这引起了人们对医学中可能出现错误信息的严重担忧。因此，这项研究起到了警示作用，强调了对来源进行严格评估的必要性，尤其是在 ChatGPT 等人工智能工具变得越来越复杂和广泛使用的时代。]]></description>
      <guid>https://arxiv.org/abs/2403.09674</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型作为对话推荐的生成用户模拟器</title>
      <link>https://arxiv.org/abs/2403.09738</link>
      <description><![CDATA[arXiv:2403.09738v1 公告类型：交叉
摘要：在对话推荐系统的评估中，合成用户是真实用户的具有成本效益的代理。大型语言模型在模拟类人行为方面显示出希望，这引发了它们代表不同用户群体的能力的问题。我们引入了一种新协议来衡量语言模型在会话推荐中准确模拟人类行为的程度。该协议由五个任务组成，每个任务旨在评估合成用户应表现出的关键属性：选择要谈论的项目、表达二元偏好、表达开放式偏好、请求建议和提供反馈。通过对基线模拟器的评估，我们证明这些任务有效地揭示了语言模型与人类行为的偏差，并提供了如何通过模型选择和提示策略来减少偏差的见解。]]></description>
      <guid>https://arxiv.org/abs/2403.09738</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>注意你的即时偏见！调查和减轻事实知识提取中的即时偏差</title>
      <link>https://arxiv.org/abs/2403.09963</link>
      <description><![CDATA[arXiv:2403.09963v1 公告类型：交叉
摘要：最近的研究表明，预训练语言模型（PLM）在事实知识提取中存在“提示偏差”，即提示往往会引入对特定标签的偏差。然而，模型中即时偏差的程度和影响仍未得到充分探索。作为回应，本文量化了各种类型提示的偏差，并评估了它们对不同基准的影响。我们表明：1）实验中的所有提示都表现出不可忽略的偏差，其中基于梯度的提示（例如 AutoPrompt 和 OptiPrompt）显示出明显更高水平的偏差； 2) 即时偏差可以通过过度拟合测试数据集来不合理地放大基准准确性，特别是在像 LAMA 这样的不平衡数据集上。基于这些发现，我们提出了一种基于表示的方法来减轻推理期间的即时偏差。具体来说，我们首先使用仅提示查询来估计有偏差的表示，然后将其从模型的内部表示中删除以生成无偏差的表示，这些表示用于产生最终的无偏差的输出。跨各种提示、PLM 和基准的实验表明，我们的方法不仅可以纠正提示偏差导致的过度拟合性能，而且还可以显着提高提示检索能力（绝对性能增益高达 10%）。我们的研究结果为 PLM 中基于提示的查询的基本预测机制提供了新的线索。希望我们的即插即用方法能够成为加强 PLM 以获得可靠知识库的黄金标准。代码和数据发布在https://github.com/FelliYang/PromptBias。]]></description>
      <guid>https://arxiv.org/abs/2403.09963</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>PPM：用于点击率预测的预训练插件模型</title>
      <link>https://arxiv.org/abs/2403.10049</link>
      <description><![CDATA[arXiv:2403.10049v1 公告类型：新
摘要：点击率（CTR）预测是推荐系统的核心任务。现有的方法（简称IDRec）依靠唯一的身份来表示不同的用户和项目，这种方法已经流行了几十年。一方面，IDRec经常面临冷启动问题导致的性能显着下降；另一方面，由于迭代效率的限制，IDRec 无法使用更长的训练数据。大多数先前的研究通过引入预训练的知识（例如预训练的用户模型或多模态嵌入）来缓解上述问题。然而，在线延迟的爆炸性增长可以归因于预训练模型中的巨大参数。因此，大多数人无法在工业推荐系统中采用IDRec端到端训练的统一模型，从而限制了预训练模型的潜力。为此，我们提出了一个$\textbf{P}$重新训练的$\textbf{P}$lug-in CTR $\textbf{M}$模型，即PPM。 PPM采用多模态特征作为输入，并利用大规模数据进行预训练。然后，将PPM插入IDRec模型中，以提高统一模型的性能和迭代效率。合并 IDRec 模型后，网络中的某些中间结果将被缓存，只有一部分参数参与训练和服务。因此，我们的方法可以成功部署端到端模型，而不会导致巨大的延迟增加。京东电商全面的线下实验和线上A/B测试证明了PPM的效率和有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.10049</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>整体优于总和：在上下文学习中使用聚合演示进行顺序推荐</title>
      <link>https://arxiv.org/abs/2403.10135</link>
      <description><![CDATA[arXiv:2403.10135v1 公告类型：新
摘要：大型语言模型（LLM）在各种 NLP 任务上表现出了出色的性能。为了使用法学硕士作为强大的顺序推荐器，我们探索了顺序推荐的上下文学习方法。我们研究了教学格式、任务一致性、演示选择和演示数量的影响。尽管使用很长的提示，但增加 ICL 中的演示数量并不能提高准确性，因此我们提出了一种名为 LLMSRec-Syn 的新颖方法，它将多个演示用户合并到一个聚合演示中。我们对三个推荐数据集的实验表明，LLMSRec-Syn 优于最先进的基于 LLM 的顺序推荐方法。在某些情况下，LLMSRec-Syn 的性能与监督学习方法相当甚至更好。我们的代码可在 https://github.com/demoleiwang/LLMSRec_Syn 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2403.10135</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    <item>
      <title>用于重新排序 SPLADE 的交叉编码器和 LLM 的彻底比较</title>
      <link>https://arxiv.org/abs/2403.10407</link>
      <description><![CDATA[arXiv:2403.10407v1 公告类型：新
摘要：我们在对有效 SPLADE 检索器进行重新排序的背景下，对交叉编码器和 LLM 重新排序器进行了比较研究。我们对 TREC 深度学习数据集和域外数据集（例如 BEIR 和 LoTTE）进行了大规模评估。在第一组实验中，我们展示了在 MS MARCO 上对 SPLADE 进行重新排序时，跨编码器重新排序器如何难以区分。观察结果在域外场景中发生变化，其中模型类型和要重新排序的文档数量都会对有效性产生影响。然后，我们关注基于大型语言模型的列表重排序器——尤其是 GPT-4。虽然 GPT-4 展示了令人印象深刻的（零样本）性能，但我们表明传统的交叉编码器仍然非常有竞争力。总的来说，我们的研究结果旨在为最近围绕基于法学硕士的重新排名器的兴奋提供更细致的视角——将它们定位为平衡搜索系统有效性和效率时需要考虑的另一个因素。]]></description>
      <guid>https://arxiv.org/abs/2403.10407</guid>
      <pubDate>Mon, 18 Mar 2024 06:17:38 GMT</pubDate>
    </item>
    </channel>
</rss>