<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 RAG 和群间互惠对全球媒体中的和平进行分类</title>
      <link>https://arxiv.org/abs/2410.13865</link>
      <description><![CDATA[arXiv:2410.13865v1 公告类型：新
摘要：本文介绍了一种使用检索增强生成 (RAG) 模型和正负群际互惠 (PIR/NIR) 概念识别全球媒体中和平见解的新方法。通过改进 PIR 和 NIR 的定义，我们可以对媒体文章中所代表的群际关系进行更准确、更有意义的分析。我们的方法提供了有助于或有损于国家层面和平的动态的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.13865</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>识别备受关注的电子商务搜索查询</title>
      <link>https://arxiv.org/abs/2410.13951</link>
      <description><![CDATA[arXiv:2410.13951v1 公告类型：新
摘要：在电子商务中，高考虑搜索任务通常需要谨慎而复杂的决策，并且需要客户投入大量的研究资金。我们考虑识别高考虑 (HC) 查询的任务。识别此类查询使电子商务网站能够使用有针对性的体验（例如帮助用户做出购买决策的精选 QA 小部件）更好地满足用户需求。我们通过提出一种基于参与度的查询排名 (EQR) 方法来探索这项任务，重点关注查询排名以指示产品搜索期间与查询相关的购物知识内容的潜在参与度。与以前预测趋势的研究不同，EQR 优先考虑与客户行为、财务和目录信息相关的查询级特征，而不是受欢迎程度信号。我们为 EQR 介绍了一种准确且可扩展的方法，并展示了证明其有效性的实验结果。离线实验显示出强大的排名性能。人工评估显示我们的模型识别的 HC 查询的准确率为 96%。该模型已实现商业部署，并证明其在下游客户影响方面优于人类选择的查询（通过参与度来衡量）。]]></description>
      <guid>https://arxiv.org/abs/2410.13951</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FinQAPT：通过端到端 LLM 驱动的问答管道支持财务决策</title>
      <link>https://arxiv.org/abs/2410.13959</link>
      <description><![CDATA[arXiv:2410.13959v1 公告类型：新
摘要：金融决策取决于对金融领域大量文档中嵌入的相关信息的分析。为了应对这一挑战，我们开发了 FinQAPT，这是一个端到端管道，可简化基于查询的相关财务报告识别，提取相关上下文，并利用大型语言模型 (LLM) 执行下游任务。为了评估管道，我们尝试了各种技术来使用 FinQA 数据集优化每个模块的性能。我们引入了一种新颖的基于聚类的负采样技术来增强上下文提取，并引入了一种称为动态 N-shot Prompting 的新颖提示方法来提高 LLM 的数字问答能力。在模块级别，我们在 FinQA 上实现了最先进的准确度，准确度达到 80.6%。然而，在管道级别，我们观察到由于从财务报告中提取相关上下文的挑战导致性能下降。我们对每个模块和端到端管道进行了详细的错误分析，找出了必须解决的具体挑战，以便开发出处理复杂财务任务的强大解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.13959</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tau@LLMJudge 最佳：使用 Llama3 进行基于标准的相关性评估</title>
      <link>https://arxiv.org/abs/2410.14044</link>
      <description><![CDATA[arXiv:2410.14044v1 公告类型：新
摘要：信息检索 (IR) 系统的传统评估依赖于人工注释的相关性标签，这种标签在规模上既有偏见又成本高昂。在这种情况下，大型语言模型 (LLM) 提供了一种替代方案，允许我们直接提示它们为与每个查询相关的段落分配相关性标签。在本研究中，我们通过探索两个假设，探索直接提示 LLM 分配相关性标签的替代方法：
假设 1 假设将“相关性”分解为特定标准（准确性、覆盖率、主题性和上下文契合度）是有帮助的。我们探索了促使大型语言模型 (LLM) 获得所有段落的标准级等级的不同方法，并考虑了将标准级等级汇总到相关性标签中的各种方法。假设 2 假设查询和段落之间的语言风格差异可能会对自动相关性标签预测产生负面影响。我们探索是否可以首先以查询的语言风格综合文章摘要，然后使用此摘要代替文章来评估其相关性，从而实现改进。
我们根据 2024 年夏季 LLMJudge 挑战赛的数据对我们的方法进行了实证评估，其中我们的“四个提示”方法在 Kendall 的 tau 中获得了最高分。]]></description>
      <guid>https://arxiv.org/abs/2410.14044</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Elasticsearch 优化检索增强生成，以增强问答系统</title>
      <link>https://arxiv.org/abs/2410.14167</link>
      <description><![CDATA[arXiv:2410.14167v1 Announce Type: new 
摘要：本研究旨在通过将Elasticsearch集成到检索增强生成（RAG）框架中，提高大规模语言模型（LLM）在回答问题时的准确率和质量。实验以斯坦福问答数据集（SQuAD）2.0版为测试数据集，比较了不同检索方法的性能，包括传统的基于关键词匹配或语义相似度计算的方法、BM25-RAG和TF-IDF-RAG，以及新提出的ES-RAG方案。结果表明，ES-RAG不仅在检索效率上具有明显优势，而且在准确率等关键指标上也表现良好，比TF-IDF-RAG高出0.51个百分点。此外，Elasticsearch强大的搜索能力和丰富的配置选项使得整个问答系统能够更好地处理复杂查询，并根据用户多样化的需求提供更灵活、高效的响应。未来的研究方向可以进一步探索如何优化Elasticsearch与LLM之间的交互机制，比如引入更高级别的语义理解和上下文感知能力，实现更加智能化、人性化的问答体验。]]></description>
      <guid>https://arxiv.org/abs/2410.14167</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型多模态模型生成个性化图像</title>
      <link>https://arxiv.org/abs/2410.14170</link>
      <description><![CDATA[arXiv:2410.14170v1 公告类型：新
摘要：个性化内容过滤，例如推荐系统，已成为缓解信息过载的关键基础设施。然而，这些系统仅仅过滤现有的内容，并且受到其有限的多样性的限制，难以满足用户多样化的内容需求。为了解决这一限制，个性化内容生成已成为一个具有广泛应用前景的方向。然而，现有的大多数研究都集中在个性化文本生成上，而对个性化图像生成的关注相对较少。个性化图像生成中有限的工作面临着从嘈杂的用户交互图像和复杂的多模态指令中准确捕捉用户的视觉偏好和需求的挑战。更糟糕的是，缺乏用于训练个性化图像生成模型的监督数据。
为了克服这些挑战，我们提出了一个名为 Pigeon 的个性化图像生成框架，它采用了具有三个专用模块的卓越大型多模态模型，可以从嘈杂的用户历史和多模态指令中捕捉用户​​的视觉偏好和需求。为了缓解数据稀缺的问题，我们引入了一个两阶段偏好对齐方案，包括掩蔽偏好重构和成对偏好对齐，以使 Pigeon 与个性化图像生成任务保持一致。我们将 Pigeon 应用于个性化贴纸和电影海报生成，其中大量定量结果和人工评估凸显了它优于各种生成基线。]]></description>
      <guid>https://arxiv.org/abs/2410.14170</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于冷启动建议的图形神经修补</title>
      <link>https://arxiv.org/abs/2410.14241</link>
      <description><![CDATA[arXiv:2410.14241v1 公告类型：新
摘要：推荐系统中的冷启动问题仍然是一个关键挑战。当前的解决方案通常在辅助数据上为冷用户/项目和热用户/项目训练混合模型，这可能会降低后者的体验。这一缺点限制了它们在实际场景中的可行性，因为现有热用户/项目的满意度至关重要。尽管图神经网络 (GNN) 通过有效的协作信号建模在热推荐方面表现出色，但它们尚未有效地用于用户项目图中的冷启动问题，这主要是由于缺乏冷用户/项目实体的初始连接。解决这个问题需要一个擅长冷启动推荐的 GNN，而不会牺牲现有推荐的性能。为此，我们引入了用于冷启动推荐的图神经修补 (GNP)，这是一个具有双重功能的定制 GNN 框架：GWarmer 用于对现有热用户/项目建模协作信号，而修补网络用于模拟和增强 GWarmer 在冷启动推荐方面的表现。在三个基准数据集上进行的大量实验证实了 GNP 在推荐热和冷用户/项目方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2410.14241</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SPFresh：十亿级向量搜索的增量就地更新</title>
      <link>https://arxiv.org/abs/2410.14452</link>
      <description><![CDATA[arXiv:2410.14452v1 公告类型：新
摘要：近似最近邻搜索 (ANNS) 现在广泛应用于各种应用，从信息检索、问答和推荐，到搜索相似的高维向量。随着向量数据量的不断增长，支持向量索引的更新变得非常重要，这是一种使向量 ANNS 高效准确的技术。由于高维性的诅咒，识别单个新向量的正确邻居通常成本高昂，这是索引更新的必要过程。为了分摊更新成本，现有系统维护一个二级索引来累积更新，主索引通过定期全局重建整个索引来合并更新。然而，这种方法的搜索延迟和准确性波动很大，更不用说它需要大量资源并且重建极其耗时。我们介绍了 SPFresh，一个支持就地向量更新的系统。 SPFresh 的核心是 LIRE，这是一种轻量级增量重新平衡协议，用于拆分向量分区并重新分配附近分区中的向量，以适应​​数据分布变化。LIRE 通过仅在分区之间的边界重新分配向量来实现低开销向量更新，在高质量向量索引中，此类向量的数量被视为很少。借助 LIRE，SPFresh 为基于全局重建的解决方案提供了卓越的查询延迟和准确性，与最先进的解决方案相比，在十亿规模的向量索引中，每日向量更新率为 1%，峰值时仅需要 1% 的 DRAM 和不到 10% 的内核。]]></description>
      <guid>https://arxiv.org/abs/2410.14452</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiSCo 与 LLM 相遇：对话搜索中稀疏检索和上下文提炼的统一方法</title>
      <link>https://arxiv.org/abs/2410.14609</link>
      <description><![CDATA[arXiv:2410.14609v1 公告类型：新
摘要：对话搜索 (CS) 是从对话语境中的语料库中检索相关文档的任务，将检索与对话语境建模相结合。随着大型语言模型 (LLM) 的爆炸式增长，CS 领域取得了重大进展，LLM 重写用户查询，考虑对话语境。然而，在推理时使用 LLM 会损害效率。当前的方法通过从人工重写的查询中提取嵌入来学习上下文建模任务，从而解决这个问题。然而，这些方法主要关注上下文建模，并且仅在独立于蒸馏的损失项中处理检索任务的对比部分。为了解决这些限制，我们提出了一种新的蒸馏方法，作为先前目标的放宽，统一检索和上下文建模。我们通过提炼对话和文档之间的相似性分数来放宽现有的训练目标，而不是仅仅依靠表示学习。我们提出的提炼目标允许在表示空间中拥有更多自由，并利用文档相关性的对比性质。通过在 5 个 CS 数据集上进行学习稀疏检索 (LSR) 实验，我们的方法在域内和域外检索性能方面都表现出显着的改进，超越了最先进的技术，在域外数据集的召回率上提高了多达 6 个点。此外，通过放宽目标，我们提出了一种多教师提炼，使用多个 LLM 作为教师，获得额外的收益，并在域内实验中超越教师本身。最后，对模型稀疏性的分析表明，我们的提炼可以更好地控制训练模型的稀疏性。]]></description>
      <guid>https://arxiv.org/abs/2410.14609</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强兽医学领域人工智能的可及性：连接分类器和电子健康记录</title>
      <link>https://arxiv.org/abs/2410.14625</link>
      <description><![CDATA[arXiv:2410.14625v1 公告类型：新
摘要：在快速发展的兽医医疗保健领域，将机器学习 (ML) 临床决策工具与电子健康记录 (EHR) 相结合有望提高诊断准确性和患者护理。然而，ML 分类器与兽医学现有 EHR 的无缝集成经常受到 EHR 系统僵化或 IT 资源有限可用性的阻碍。为了解决这一缺点，我们推出了 Anna，这是一种免费提供的软件解决方案，可实时为 EHR 实验室数据提供 ML 分类器结果。]]></description>
      <guid>https://arxiv.org/abs/2410.14625</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>P4GCN：具有隐私保护双方图卷积网络的垂直联合社交推荐</title>
      <link>https://arxiv.org/abs/2410.13905</link>
      <description><![CDATA[arXiv:2410.13905v1 公告类型：交叉 
摘要：近年来，图神经网络 (GNN) 已广泛用于社交推荐系统。然而，现实世界的场景往往存在与用户隐私和业务限制相关的挑战，阻碍了从其他平台直接访问有价值的社交信息。虽然许多现有方法已经在没有直接社交数据访问的情况下解决了基于矩阵分解的社交推荐，但在类似条件下开发基于 GNN 的联合社交推荐模型仍未得到广泛探索。为了解决这个问题，我们提出了一种新颖的垂直联合社交推荐方法，利用隐私保护的两方图卷积网络 (P4GCN) 来提高推荐准确性，而无需直接访问敏感的社交信息。首先，我们引入了一个三明治加密模块，以确保在协作计算过程中全面的数据隐私。其次，我们对隐私保证进行了彻底的理论分析，考虑到好奇方和诚实方的参与。在四个真实数据集上进行的大量实验表明，P4GCN 在推荐准确性方面优于最先进的方法。代码可在https://github.com/WwZzz/P4GCN获取。]]></description>
      <guid>https://arxiv.org/abs/2410.13905</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从文本描述中有效检索时间事件序列</title>
      <link>https://arxiv.org/abs/2410.14043</link>
      <description><![CDATA[arXiv:2410.14043v1 公告类型：交叉 
摘要：从文本描述中检索时间事件序列对于分析电子商务行为、监控社交媒体活动和跟踪犯罪事件等应用至关重要。在本文中，我们介绍了 TPP-LLM-Embedding，这是一种基于自然语言描述有效嵌入和检索事件序列的统一模型。我们的模型建立在 TPP-LLM 框架之上，该框架将大型语言模型与时间点过程相结合，对事件类型和时间进行编码，通过池化生成序列级表示。文本描述使用相同的架构嵌入，确保序列和描述共享嵌入空间。我们根据这些嵌入之间的相似性优化对比损失，使匹配对更接近并分离不匹配对。TPP-LLM-Embedding 能够实现高效检索，并且与跨不同数据集的基线模型相比表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.14043</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>轻量级关联感知表压缩</title>
      <link>https://arxiv.org/abs/2410.14066</link>
      <description><![CDATA[arXiv:2410.14066v1 公告类型：交叉 
摘要：数据湖越来越多地用于管理关系数据，这需要高效的开放存储格式，以提供高扫描性能和有竞争力的压缩率。虽然现有格式通过轻量级编码技术实现快速扫描，但它们在最小化存储空间方面已达到瓶颈。最近，相关性感知压缩方案已被证明可以进一步减小文件大小。然而，当前的方法要么产生大量的扫描开销，要么需要手动指定相关性，从而限制了它们的实用性。我们提出了 $\texttt{Virtual}$，这是一个与现有开放格式无缝集成的框架，可自动利用数据相关性，在最小化扫描性能开销的同时实现显着的压缩增益。在 $\texttt{data.gov}$ 数据集上的实验表明，与 Apache Parquet 相比，$\texttt{Virtual}$ 将文件大小减少了 40%。]]></description>
      <guid>https://arxiv.org/abs/2410.14066</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向稳健转录：探索用于训练数据增强的噪声注入策略</title>
      <link>https://arxiv.org/abs/2410.14122</link>
      <description><![CDATA[arXiv:2410.14122v1 公告类型：交叉 
摘要：自动钢琴转录 (APT) 的最新进展显著提高了系统性能，但噪声环境对系统性能的影响仍未得到充分探索。本研究调查了不同信噪比 (SNR) 水平的白噪声对最先进的 APT 模型的影响，并评估了在噪声增强数据上训练的 Onsets 和 Frames 模型的性能。我们希望这项研究能够提供有价值的见解，作为开发在各种声学条件下保持一致性能的转录模型的初步工作。]]></description>
      <guid>https://arxiv.org/abs/2410.14122</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChartifyText：通过 LLM 从包含数据的文本自动生成图表</title>
      <link>https://arxiv.org/abs/2410.14331</link>
      <description><![CDATA[arXiv:2410.14331v1 公告类型：交叉 
摘要：涉及数值的文本文档广泛应用于科学研究、经济、公共卫生和新闻等各种应用领域。然而，读者很难快速解读此类涉及数据的文本并获得深刻的见解。为了填补这一研究空白，这项工作旨在自动生成图表，以准确地向读者传达底层数据和想法，这本质上是一项具有挑战性的任务。挑战源于文本歧义、文本文档中数据的内在稀疏性和不确定性以及主观情绪差异。具体来说，我们提出了 ChartifyText，这是一种新颖的全自动方法，它利用大型语言模型 (LLM) 将复杂的数据相关文本转换为富有表现力的图表。它由两个主要模块组成：表格数据推理和富有表现力的图表生成。表格数据推理模块采用系统提示工程来指导 LLM（例如 GPT-4）推断表格数据，其中明确考虑了数据范围、不确定性、缺失数据值和相应的主观情绪。富有表现力的图表生成模块通过直观的视觉编码和简洁的文本增强了标准图表，以准确传达底层数据和见解。我们通过案例研究、对三位可视化专家的深入访谈以及一项精心设计的 15 名参与者的用户研究，广泛评估了 ChartifyText 对现实世界中涉及数据的文本文档的有效性。结果证明了 ChartifyText 在帮助读者高效、有效地理解涉及数据的文本方面的实用性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.14331</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>