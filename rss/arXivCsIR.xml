<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Tue, 18 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>胆汁：上下文几次促使见解发现发现</title>
      <link>https://arxiv.org/abs/2503.12062</link>
      <description><![CDATA[ARXIV：2503.12062V1公告类型：新 
摘要：数据和见解发现对于现代组织的决策至关重要。我们提出了一个纯种，这是一种llm辅助界面，使用户能够与表格数据集进行交互，并以自然语言询问复杂的查询。通过对各种提示的策略和语言模型进行基准测试，我们开发了一种端到端工具，该工具利用上下文几乎没有弹药的提示，从而在潜伏期，准确性和可扩展性方面实现了卓越的性能。善意使利益相关者有能力探索，分析和可视化其数据集，同时通过基于角色的访问控制和文本到SQL方法确保数据安全性。]]></description>
      <guid>https://arxiv.org/abs/2503.12062</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过语义代码弥合文本合并差距，以进行顺序推荐</title>
      <link>https://arxiv.org/abs/2503.12183</link>
      <description><![CDATA[Arxiv：2503.12183V1公告类型：新 
摘要：近年来，通过将丰富的侧面信息与基于ID的协作信息整合在一起，致力于增强顺序推荐系统。这项研究特别着重于利用与项目相关的文本元数据（例如标题和品牌）。尽管现有方法通过结合文本和ID表示取得了显着的成功，但它们通常很难在嵌入文本表示中嵌入的文本信息与从用户行为的顺序模式中取得平衡。鉴于此，我们提出了Cocorec，这是一种基于代码的新型文本和协作语义融合方法，用于顺序建议。我们方法背后的关键思想是使用语义代码弥合文本和协作信息之间的差距。具体而言，我们通过向量量化技术从多视文本嵌入中生成细粒的语义代码。随后，我们基于交叉注意机制开发一个代码引导的语义融合模块，以灵活地提取和整合来自文本表示的相关信息。为了进一步增强文本和协作语义的融合，我们介绍了一种优化策略，该策略采用了具有两个特定目标的代码掩蔽：掩盖的代码建模和屏蔽序列对齐。这些目标的优点在于利用面具预测任务和增强项目表示形式来捕获单个项目中的代码相关性，并增强建议骨干的序列建模。在四个公共数据集上进行的广泛实验证明了Cocorec的优越性，显示出比各种顺序推荐模型的显着改善。我们的代码可从https://anonymon.4open.science/r/cocorec-6e41获得。]]></description>
      <guid>https://arxiv.org/abs/2503.12183</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMSER：通过基于LLM的数据增强增强顺序推荐</title>
      <link>https://arxiv.org/abs/2503.12547</link>
      <description><![CDATA[ARXIV：2503.12547V1公告类型：新 
摘要：顺序推荐系统（SRS）已成为在线平台的基石，利用用户的历史互动数据来预测其下一次潜在参与。尽管采用了广泛的采用，但SRS经常努力应对长尾用户的困境，从而对互动记录有限的个人提出了不太有效的建议。大型语言模型（LLMS）的出现及其在项目之间辨别语义关系的深远能力，为通过数据增强增强SR提供了新的途径。 Nonetheless, current methodologies encounter obstacles, including the absence of collaborative signals and the prevalence of hallucination phenomena.In this work, we present LLMSeR, an innovative framework that utilizes Large Language Models (LLMs) to generate pseudo-prior items, thereby improving the efficacy of Sequential Recommender Systems (SRS).为了减轻协作信号不足的挑战，我们介绍了语义互动增强器（SIA），该方法可以集成语义和协作信息以全面增强用户交互数据。此外，为了削弱SRS幻觉的不利影响，我们开发了自适应可靠性验证（ARV），这是一种旨在评估生成的伪项目可靠性的验证技术。在补充这些进步的情况下，我们还设计了一种双通道训练策略，确保了将数据增强的无缝整合到SRS培训过程中。使用三种广泛使用的SRS模型进行的扩展实验证明了LLMSER的普遍性和功效。]]></description>
      <guid>https://arxiv.org/abs/2503.12547</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用小组推荐系统中领导力的动力</title>
      <link>https://arxiv.org/abs/2503.12877</link>
      <description><![CDATA[ARXIV：2503.12877V1公告类型：新 
摘要：在小组推荐系统（GRS）的领域中，有效解决小组成员的各种偏好提出了重大挑战。传统的GRS方法通常将个人偏好汇总为集体群体偏好以产生建议，这可能会忽略小组成员之间的复杂互动。我们介绍了一种新颖的方法来进行小组推荐，特别关注分享共同利益的小组。特别是，我们提出了一个基于Web的餐厅推荐系统，该系统通过建模小组成员之间的相互作用来增强用户满意度。从小组决策文献和利用图理论中汲取灵感，我们提出了一种建议算法，该算法强调了小组内的关系和信任的动态。通过将小组成员作为节点及其相互作用作为指示边缘，该算法捕获成对关系，以促进共识并改善与小组偏好的建议对齐。以相互作用为中心的框架最终旨在提高对建议选择的整体群体满意度。]]></description>
      <guid>https://arxiv.org/abs/2503.12877</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于非重叠跨域顺序推荐的Federated Expert的联合混合物</title>
      <link>https://arxiv.org/abs/2503.13254</link>
      <description><![CDATA[ARXIV：2503.13254V1公告类型：新 
摘要：在现实世界中，用户总是有多种兴趣，同时浏览不同的服务以丰富他们的日常生活，例如观看热门的简短视频/直播。为了确切地描述用户兴趣以获得更好的用户体验，最近的文献通过传输其他相关服务（又称域）知识来提高目标服务预测的准确性，提出了跨域技术。实际上，天真的跨域技术通常需要存在一些重叠的用户，并在跨域中共享整体信息，包括用户历史日志，用户/项目嵌入式和模型参数检查点。然而，其他域的用户端历史日志和嵌入在现实世界中的设计中并不总是可用，因为用户可能完全不是跨域中的不重叠的，或者隐私保护策略限制了跨域的个性化信息共享。因此，提出了一个具有挑战性但有价值的问题：如何仅利用其他域模型参数检查点来增强目标域预测准确性？为了回答这个问题，我们提出了FMOE-CDSR，该问题从联合学习的角度探讨了非叠层的跨域顺序推荐方案。]]></description>
      <guid>https://arxiv.org/abs/2503.13254</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>恢复：具有自然语言批评和叙述的数据集和基准</title>
      <link>https://arxiv.org/abs/2503.11924</link>
      <description><![CDATA[ARXIV：2503.11924V1公告类型：交叉 
摘要：本文介绍了一种新颖的数据集重新（用生成叙事增强的评论），旨在基于推荐的大语言模型（LLMS）的对话能力，从而解决了主要关注顺序项目预测的现有数据集的局限性。 Regen通过介绍两个关键的自然语言特征来扩展亚马逊产品评论数据集：（1）用户评论，代表用户“转向”查询，导致选择后续项目的选择，以及（2）叙述，富裕的文本输出与每个推荐项目相关的文本输出。叙述包括产品认可，购买说明以及用户偏好的摘要。
  此外，我们为对话推荐的任务建立了端到端的建模基准，在该任务中，培训了模型以生成建议和相应的叙述，并以用户历史记录（项目和评论）为条件。对于这项联合任务，我们介绍了一个建模框架Lumen（基于LLM的统一多任务模型，具有批评，建议和叙述），该模型使用LLM作为批评，检索和发电的骨干。我们还使用标准自动评估技术评估了数据集的质量，并通过培训传统和基于LLM的建议模型来基准测试。我们的结果表明，通过使建议者了解语言理解并将其与建议信号集成在一起，可以提高建议质量。此外，在我们的数据集中培训的LLM有效地产生了建议和上下文叙述，实现了与最先进的建议者和语言模型相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.11924</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM辅助理解隐私文件中的解释差距</title>
      <link>https://arxiv.org/abs/2503.12225</link>
      <description><![CDATA[ARXIV：2503.12225V1公告类型：交叉 
摘要：本文探讨了使用大型语言模型（LLM）从复杂的隐私政策中获取数据实践的简化解释时可能会表现出来的差距。我们体现了这些差距，以展示准确性，完整性，清晰度和代表性的问题，同时倡导继续研究，以通过个人助理和自动合规性检查实现LLM的真正潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.12225</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种新颖的关联和排名方法确定了影响STEM专业教育成果的因素</title>
      <link>https://arxiv.org/abs/2503.12321</link>
      <description><![CDATA[Arxiv：2503.12321V1公告类型：交叉 
摘要：提高本科在STEM中的成功需要确定影响学生成果的可行因素，从而使机构可以优先考虑关键杠杆率的变化点。我们使用一种称为D-Basis的新型协会算法来对与毕业相关的属性进行排名的新型协会算法，研究了美国东北两年的两年学院的学术，人口和机构因素。重要的是，所分析的数据包括从国家学生交换所的跟踪数据，这些数据是针对离开其原始机构以确定转移后结果的学生的。
  成功毕业的关键预测因素包括在入门词干课程中的表现，第一次数学课程的选择以及主要选择的灵活性。入门生物学，通用化学和数学课程的高级与毕业密切相关。同时，切换专业的学生 - 尤其是从STEM到非茎 - 总体毕业率更高。此外，佩尔的资格和人口因素，尽管总体上的预测性较低，但仍显示毕业和保留率的时间差异。
  研究结果凸显了早期学术支持在STEM网关课程中的重要性以及实施在主要选择方面具有灵活性的机构政策。提高学生在入学数学，生物学和化学课程中的成功可能会极大地影响毕业率。此外，定制的数学途径和对STEM课程的集中支持可以帮助机构优化学生的成绩。这项研究提供了数据驱动的见解，以指导策略以提高茎学位的完成。]]></description>
      <guid>https://arxiv.org/abs/2503.12321</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解开参与性数据物理化中的功率动态</title>
      <link>https://arxiv.org/abs/2503.13018</link>
      <description><![CDATA[ARXIV：2503.13018V1公告类型：交叉 
摘要：参与性数据物理化（PDP）因支持数据驱动的决策的潜力而被认可，这些利益相关者合作地将物理元素构建为普遍洞察力的可视化。但是，像所有参与过程一样，PDP受到潜在的权力动态的影响，这些动力可能会导致有关提取性参与，边缘化或排除等问题。我们首先通过开发一个本体论来确定这些权力动力学背后的决策，该本体论从可视化和参与式设计研究中综合了关键的理论见解，然后系统地将其应用于23个PDP工件的代表性语料库。通过揭示共同决定是如何以不同议程为指导的，本文提出了三个贡献：1）跨学科本体论，促进对现有和新颖的PDP工艺和过程的系统分析；这导致2）六个PDP议程，反映了当前PDP实践中关键的动力动态，从而揭示了利益相关者参与PDP实践的方向多样性； 3）一组批判性考虑，应该指导如何平衡动力动态，例如通过反思问题的代表，数据是背景信息，参与者表达其含义，以及参与者如何与灵活的人工制品构建不同。因此，这项研究通过指导研究人员和从业人员公开反思和共享数据物理化和参与式数据可视化的责任来推进女权主义研究议程。]]></description>
      <guid>https://arxiv.org/abs/2503.13018</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多代理系统的知识意识迭代检索</title>
      <link>https://arxiv.org/abs/2503.13275</link>
      <description><![CDATA[ARXIV：2503.13275V1公告类型：交叉 
摘要：我们介绍了一种新型的大型语言模型（LLM）驱动的代理框架，它通过利用动态发展的知识来迭代地完善查询并过滤上下文证据。该系统的一个定义特征是它将外部源与内部知识缓存的脱钩，该缓存逐渐更新以指导查询生成和证据选择。该设计减轻了偏置强化环路并实现动态，可追踪的搜索探索路径，从而优化了探索多种信息和通过自主代理决策保持准确性之间的权衡。我们的方法在广泛的开放域问题上进行了评估，以回答基准，包括镜像现实世界中的多个步骤任务，其中集成了来自多个来源的信息至关重要，尤其是考虑到缺乏明确推理或计划能力的LLM的脆弱性。结果表明，所提出的系统不仅胜过单步基线，无论任务难度如何，而且与常规的迭代检索方法相比，还通过基于循证的推理和提高效率来证明复杂任务中的明显优势。所提出的系统支持更新上下文的竞争和协作共享，从而实现多代理扩展。随着任务难度的增加，多代理配置的好处变得特别突出。收敛步骤的数量缩放了任务难度，表明具有成本效益的可伸缩性。]]></description>
      <guid>https://arxiv.org/abs/2503.13275</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有多标准评分的可拨数据的数据</title>
      <link>https://arxiv.org/abs/2501.03072</link>
      <description><![CDATA[ARXIV：2501.03072V2公告类型：替换 
摘要：随着推荐系统（RSS）的开发，出现了几种有前途的系统，例如上下文感知RS，多标准RS和组RS。多标准推荐系统（MCRS）旨在通过同时考虑多个属性或标准中的用户偏好来提供个性化建议。与通常专注于单个评级的传统RSS不同，这些系统通过考虑各个方面的各种偏好和需求来帮助用户做出更明智的决策。在本文中，我们发布了从Opentable.com爬行的可拨数据集。数据集可以被视为用于多标准建议的基准数据集。]]></description>
      <guid>https://arxiv.org/abs/2501.03072</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向有效的LLM培训范式进行CTR预测</title>
      <link>https://arxiv.org/abs/2503.01001</link>
      <description><![CDATA[Arxiv：2503.01001V3公告类型：替换 
摘要：大型语言模型（LLM）作为基于下一代排名的推荐系统表现出巨大的潜力。最近的许多作品表明，LLM可以显着超过常规点击率（CTR）预测方法。尽管结果如此有希望，但当前培训范式固有的计算效率低效率使得训练LLM在大型数据集上排名的建议任务特别具有挑战性。为了培训LLM进行CTR预测，大多数现有研究都采用了普遍的“滑窗”范式。给定$ m $用户交互的顺序，每次交互构建了独特的培训提示，将其指定为预测目标及其先前的$ n $交互作用。反过来，滑动窗口范式的总体复杂性为$ O（Mn^2）$，该范围随用户交互的长度线性扩展。因此，随着互动的长度的增加，直接采用通过这种策略培训LLM的LLM可能会导致高高的培训成本。为了减轻计算效率低下，我们提出了一种新颖的训练范式，即动态目标隔离（DTI），该训练在结构上平行于$ k $（$ k &gt;&gt; 1 $）目标相互作用的训练。此外，我们确定了两个主要的瓶颈 - 隐藏状态泄漏和过度拟合的位置偏见 - 将DTI限制为仅扩展到$ k $的少量值（例如5），然后提出了一个计算上的轻度解决方案，以有效地解决每个方案。通过对三个广泛采用的公共CTR数据集进行的广泛实验，我们从经验上表明，DTI平均将培训时间缩短了$ \ textbf {92％} $（例如，从$ 70.5 $ hrs降低到$ 5.31 $ HRS），而没有妥协Ctrictication Ctrictical Perdictication Perdictical Pervictical Pervictiation Perdictiation。]]></description>
      <guid>https://arxiv.org/abs/2503.01001</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在各种情况下，固有和外在因素分解供推荐</title>
      <link>https://arxiv.org/abs/2503.03524</link>
      <description><![CDATA[ARXIV：2503.03524V2公告类型：替换 
摘要：在推荐系统中，用户行为的模式（例如，购买，单击）可能在不同的上下文（例如时间和位置）中差异很大。这是因为用户行为由两种因素共同确定：内在因素反映了一致的用户偏好和外部因素，这些因素反映了外部激励措施在不同情况下可能会有所不同。区分内在和外在因素有助于更好地学习用户行为。但是，现有的研究仅考虑将它们与单个预定义的上下文（例如时间或位置）区分开来，而忽略了一个事实，即用户的外部因素可能会同时受到各种情况的相互作用的影响。在本文中，我们提出了固有的分解建议（IEDR）模型，该模型是一种通用框架，该框架与同时考虑各种情况的外在因素区分开来，从而更准确地分化了因素，从而提高了建议准确性。 IEDR包含一个上下文不变的对比度学习组件，以捕获内在因素，以及在各种情况相互作用下提取外在因素的分离组件。这两个组件共同努力，以实现有效的因素学习。对现实世界数据集的广泛实验表明，IEDR在学习分离的因素方面的有效性，并在NDCG中最多提高了4％的建议精度。]]></description>
      <guid>https://arxiv.org/abs/2503.03524</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DALL-M：使用LLMS的上下文感知临床数据增强</title>
      <link>https://arxiv.org/abs/2407.08227</link>
      <description><![CDATA[ARXIV：2407.08227V3公告类型：替换 - 交叉 
摘要：X射线图像在医学诊断中至关重要，但是它们的有效性在没有临床环境的情况下受到限制。放射科医生经常发现胸部X射线不足以诊断潜在的疾病，因此需要将结构化临床特征与放射学报告相结合。
  为了解决这个问题，我们介绍了DALL-M，这是一个新颖的框架，可通过生成上下文合成数据来增强临床数据集。 DALL-M增加结构化的患者数据，包括生命体征（例如心率，氧饱和度），放射学发现（例如，病变存在）和人口统计学因素。它将这些表格数据与从放射学报告和特定领域的资源（例如Radiopaedia，Wikipedia）中提取的上下文知识相结合，以确保临床一致性和可靠性。
  DALL-M遵循三相过程：（i）临床环境存储，（ii）专家查询产生和（iii）上下文感知功能增强。使用大型语言模型（LLM），它既可以为现有临床特征以及全新的临床相关特征生成上下文合成值。
  DALL-M适用于MIMIC-IV数据集的799例病例，将原始的9个临床特征扩展到91。用机器学习模型（包括决策树，随机森林，XGBOOST和TABNET）的经验验证表明，F1得分提高了16.5％，精确和回忆提高了25％。
  Dall-M通过保持数据完整性，同时增强医疗保健中的预测性建模，从而在临床数据增强中占据了一个重要的差距。我们的结果表明，集成LLM生成的合成特征可显着提高模型性能，从而使DALL-M成为AI驱动的医学诊断的可扩展且实用的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.08227</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成AI驱动的元数据建模方法</title>
      <link>https://arxiv.org/abs/2501.04008</link>
      <description><![CDATA[ARXIV：2501.04008V2公告类型：替换 - 交叉 
摘要：自数十年以来，元数据的建模一直是任何学术图书馆运作的核心。它的重要性只会随着构成图书馆外展的构成生成人工智能（AI）驱动的信息活动和服务的日益普及。但是，随着元数据的重要性的不断增长，设计了库元数据模型的过程，从而影响了其可重复性，人行横道和与其他元数据模型的互操作性。本文认为，上述问题源于一个基本的论点，即只有几个核心元数据模型对于使用它们的任何信息服务来说都是必要和足够的，而与内域内或域间设置的异质性无关。为此，本文提出了上述论文的相反观点，并以三个关键步骤证实了其论点。首先，它引入了一种新颖的方式，将图书馆元数据模型作为本体驱动的组成，即从感知到其强度定义的五个功能相互链接的表示级别的组成。其次，它引入了五个级别中每个级别中每个级别中隐含的表示形式，这累积地有助于概念上的库元数据模型。最后，最重要的是，它提出了一种生成的AI驱动的人类大型语言模型（LLM）协作基于基于元数据建模的方法，以消除每个表示级别中固有的纠缠，从而导致产生概念上的分离式元数据模型。在整篇文章中，这些论点是用代表性图书馆来处理癌症信息的情景和示例来体现的。]]></description>
      <guid>https://arxiv.org/abs/2501.04008</guid>
      <pubDate>Tue, 18 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>