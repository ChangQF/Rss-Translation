<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>https://rss.arxiv.org/rss/</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 05 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>以数据为中心的推荐系统调查</title>
      <link>https://rss.arxiv.org/abs/2401.17878</link>
      <description><![CDATA[推荐系统（RS）已成为减轻一系列现实应用中信息过载的重要工具。 RS 的最新趋势揭示了重大范式转变，将焦点从以模型为中心的创新转移到以数据为中心的工作（例如，提高数据质量和数量）。这种演变催生了以数据为中心的推荐系统（Data-Centric RS）的概念，标志着该领域的重大发展。本次调查首次系统概述了以数据为中心的推荐系统，涵盖 1) 推荐数据和以数据为中心的推荐系统的基本概念； 2）推荐数据的三个主要问题； 3）最近为解决这些问题而开展的研究； 4）以数据为中心的RS的几个潜在的未来方向。]]></description>
      <guid>https://rss.arxiv.org/abs/2401.17878</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>用于推荐中意图学习的端到端可学习聚类</title>
      <link>https://rss.arxiv.org/abs/2401.05975</link>
      <description><![CDATA[意图学习旨在学习用户的意图以进行用户理解和项目推荐，已成为近年来的研究热点。然而，现有方法存在复杂且繁琐的交替优化，限制了性能和可扩展性。为此，我们提出了一种新颖的意图学习方法，称为 \underline{ELCRec}，通过将行为表示学习统一到 \underline{E}nd-to-end \underline{L}earnable \underline{C}lustering 框架中，有效且高效的\underline{Rec}建议。具体来说，我们对用户的行为序列进行编码，并将聚类中心（潜在意图）初始化为可学习的神经元。然后，我们设计了一种新颖的可学习聚类模块来分离不同的聚类中心，从而解耦用户的复杂意图。同时，它通过强制行为嵌入靠近聚类中心来引导网络从行为中学习意图。这允许通过小批量数据同时优化推荐和聚类。此外，我们提出利用聚类中心作为自我监督信号的意图辅助对比学习，进一步增强相互促进。实验结果和理论分析从六个方面证明了ELCRec的优越性。与亚军相比，ELCRec 在 Beauty 数据集上将 NDCG@5 提高了 8.9%，并将计算成本降低了 22.5%。此外，由于其可扩展性和普遍适用性，我们将该方法部署在具有1.3亿页面浏览量的工业推荐系统上，并取得了可喜的结果。]]></description>
      <guid>https://rss.arxiv.org/abs/2401.05975</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>DQNC2S：基于 DQN 的跨流危机事件摘要器</title>
      <link>https://rss.arxiv.org/abs/2401.06683</link>
      <description><![CDATA[同时总结多个与灾难相关的数据流尤其具有挑战性，因为现有的检索和重新排序策略受到多流数据固有的冗余和多查询设置中有限的可扩展性的影响。这项工作提出了一种基于深度 Q 网络弱注释的危机时间线生成在线方法。它即时选择相关文本片段，无需人工注释或内容重新排名。这使得推理时间与输入查询的数量无关。所提出的方法还将冗余过滤器合并到奖励函数中，以有效处理跨流内容重叠。所取得的 ROUGE 和 BERTScore 结果优于 CrisisFACTS 2022 基准上表现最佳的模型。]]></description>
      <guid>https://rss.arxiv.org/abs/2401.06683</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:05 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统如何从大型语言模型中受益：一项调查</title>
      <link>https://rss.arxiv.org/abs/2306.05817</link>
      <description><![CDATA[随着在线服务的快速发展，推荐系统（RS）对于缓解信息过载变得越来越不可或缺。尽管取得了显着的进步，传统的推荐模型（CRM）仍然存在一些局限性，例如缺乏开放世界的知识，并且难以理解用户的潜在偏好和动机。同时，大语言模型（LLM）表现出了令人印象深刻的通用智能和类人能力，这主要源于其广泛的开放世界知识、推理能力以及对人类文化和社会的理解。因此，LLM的出现给推荐系统的设计带来了启发，并指出了一个有前途的研究方向，即我们是否可以将LLM纳入其中，并从他们的知识和能力中受益，以弥补CRM的局限性。在本文中，我们从现实推荐系统的整个流程的角度对这一研究方向进行了全面的调查。具体来说，我们从两个正交的方面总结了现有的工作：在哪里以及如何使LLM适应RS。对于 WHERE 问题，我们讨论了 LLM 在推荐管道的不同阶段可以发挥的作用，即特征工程、特征编码器、评分/排名函数、用户交互和管道控制器。对于HOW问题，我们研究了训练和推理策略，得出了两个细粒度的分类标准，即是否调整LLM，以及是否涉及传统的推理推荐模型。然后，我们从效率、有效性和道德三个方面强调了LLM适应RS的关键挑战。最后，我们总结了调查并讨论了未来的前景。我们积极维护论文和其他相关资源的 GitHub 存储库：https://github.com/CHIANGEL/Awesome-LLM-for-RecSys/。]]></description>
      <guid>https://rss.arxiv.org/abs/2306.05817</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>冷启动建议的时间和分布鲁棒优化</title>
      <link>https://rss.arxiv.org/abs/2312.09901</link>
      <description><![CDATA[协同过滤 (CF) 推荐模型高度依赖于用户-项目交互来学习 CF 表示，因此无法推荐冷启动项目。为了解决这个问题，先前的研究主要引入项目特征（例如缩略图）来进行冷启动项目推荐。他们在热启动项目上学习特征提取器，以将特征表示与交互对齐，然后利用特征提取器提取冷启动项目的特征表示以进行交互预测。不幸的是，由于时间特征的变化，冷启动项目的特征，尤其是流行的项目，往往与热启动项目的特征有所不同，从而阻止特征提取器准确地学习冷启动项目的特征表示。
  为了减轻时间特征变化的影响，我们考虑使用分布式鲁棒优化（DRO）来增强特征提取器的生成能力。尽管如此，现有的 DRO 方法面临着不一致的问题：DRO 训练期间强调的最坏情况热启动项目可能与冷启动项目分布不太一致。为了捕获时间特征变化并解决这种不一致问题，我们提出了一种具有新优化目标的新型时间 DRO，即 1）整合最坏情况因素以提高最坏情况性能，2）设计一个变化因素捕捉商品特征变化趋势，加强冷启动商品潜在热门群体的优化。对三个真实世界数据集的大量实验验证了我们的时间 DRO 在增强冷启动推荐模型泛化能力方面的优越性。代码可在 https://github.com/Linxyhaha/TDRO/ 获取。]]></description>
      <guid>https://rss.arxiv.org/abs/2312.09901</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:04 GMT</pubDate>
    </item>
    <item>
      <title>利用外部语料库实现知识密集型任务的统一语言模型</title>
      <link>https://rss.arxiv.org/abs/2402.01176</link>
      <description><![CDATA[大语言模型（LLM）的出现展示了它们在各个领域的功效，但它们经常产生幻觉，特别是在需要外部知识源的知识密集型任务中。为了提高语言模型的事实准确性，检索增强生成（RAG）已成为一种流行的解决方案。然而，传统的检索模块通常依赖于大规模文档索引，这可能与生成任务脱节。通过生成检索（GR）方法，语言模型可以通过直接生成相关文档标识符（DocID）来实现卓越的检索性能。然而，GR 与下游任务之间的关系以及 LLM 在 GR 中的潜力仍有待探索。在本文中，我们提出了一种统一的语言模型，通过无缝集成生成检索、闭卷生成和 RAG，利用外部语料库来处理各种知识密集型任务。为了通过统一的连续解码过程实现有效的检索和生成，我们引入了以下机制：（1）面向排名的DocID解码策略，通过直接从DocID排名列表中学习来提高排名能力； (2) 持续生成策略以促进有效且高效的 RAG； (3)精心设计的辅助DocID理解任务，以增强模型对DocID的理解及其与下游任务的相关性。我们的方法在广泛使用的 KILT 基准上使用骨干模型的两种变体进行评估：编码器-解码器 T5 模型和仅解码器的 LLM，Llama2。实验结果展示了我们的模型在检索和下游知识密集型任务中的卓越性能。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01176</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>区域影响约束下广告牌广告的遗憾最小化</title>
      <link>https://rss.arxiv.org/abs/2402.01294</link>
      <description><![CDATA[在典型的广告牌广告技术中，多个数字广告牌由影响力提供商拥有，并且许多广告商在付费的基础上与影响力提供商接触以获取其广告内容的特定数量的观看次数。如果影响力提供者提供了所需的或更多的影响力，那么他将收到全额付款或部分付款。对于影响力提供者来说，如果他提供的影响力多于或少于广告商所要求的，对他来说都是一种损失。这被形式化为“遗憾”，自然地，在影响力提供者的背景下，目标将是在广告商之间分配广告牌位置，以使总遗憾最小化。在本文中，我们将此问题作为离散优化问题进行研究，并提出了四种解决方法。第一个方法以增量贪婪方式从可用广告牌槽位中选择广告牌槽位，我们将此方法称为预算有效贪婪方法。在第二个中，我们在第一个中引入了随机性，其中我们对随机选择的广告牌位置样本执行边际增益计算。其余两种方法是对第二种方法的进一步改进。我们分析所有算法以了解它们的时间和空间复杂度。我们用现实生活中的轨迹和广告牌数据集来实现它们，并进行了大量的实验。据观察，随机预算有效贪婪方法需要合理的计算时间，同时最大限度地减少遗憾。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01294</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:03 GMT</pubDate>
    </item>
    <item>
      <title>使用窗口过滤器进行近似最近邻搜索</title>
      <link>https://rss.arxiv.org/abs/2402.00943</link>
      <description><![CDATA[我们定义并研究 $\textit{c-近似窗口搜索}$ 问题：近似最近邻搜索，其中数据集中的每个点都有一个数字标签，目标是在任意标签范围内找到查询的最近邻。许多语义搜索问题，例如使用时间戳过滤器的图像和文档搜索，或使用成本过滤器的产品搜索，都是该问题的自然示例。我们提出并从理论上分析了一种基于树的模块化框架，用于将解决传统 c 近似最近邻问题的索引转换为解决窗口搜索的数据结构。在配备随机标签值、对抗性构造的嵌入和具有真实时间戳的图像搜索嵌入的标准最近邻基准数据集上，我们在相同的召回水平下比现有解决方案获得了高达 75 倍的加速。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.00943</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>使用用于 KG 问答的实体预训练 GPT 生成 SPARQL</title>
      <link>https://rss.arxiv.org/abs/2402.00969</link>
      <description><![CDATA[知识图谱的受欢迎程度在过去几年中迅速增长。所有这些知识都可供人们通过互联网上的许多在线数据库查询。不过，如果非程序员用户能够访问他们想知道的任何信息，那将是一个巨大的成就。为了使用自然语言处理工具和通过许多挑战鼓励创造力来解决这项任务，人们付出了很多努力。我们的方法侧重于假设链接到自然语言问题的正确实体，并训练 GPT 模型以从中创建 SPARQL 查询。我们成功地隔离了任务的哪些属性在少量或零样本情况下最难解决，并且我们建议对所有实体（在 CWA 下）进行预训练以提高性能。我们在 3 次测试中获得了 62.703% 的 SPARQL 精确匹配准确率，实体链接挑战的 F1 为 0.809，问答挑战的 F1 为 0.009。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.00969</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:02 GMT</pubDate>
    </item>
    <item>
      <title>多代理会话推荐系统</title>
      <link>https://rss.arxiv.org/abs/2402.01135</link>
      <description><![CDATA[由于与用户进行流畅、多轮对话的强大能力，大型语言模型（LLM）有潜力进一步提高对话推荐系统（CRS）的性能。与 LLM 擅长的漫无目的的闲聊不同，CRS 有明确的目标。因此，控制LLM中的对话流程以成功向用户推荐合适的项目势在必行。此外，CRS中的用户反馈可以帮助系统更好地对用户偏好进行建模，而这一点已被现有研究所忽视。然而，单纯促使LLM进行对话式推荐并不能解决上述两个关键挑战。
  在本文中，我们提出了多代理会话推荐系统（MACRS），它包含两个基本模块。首先，我们设计了一个多智能体行为规划框架，它可以控制基于四个基于LLM的智能体的对话流。这种协作式多智能体框架将根据不同的对话行为生成各种候选响应，然后选择最合适的响应作为系统响应，这可以帮助MACRS规划合适的对话行为。其次，我们提出了一种用户反馈感知反射机制，该机制利用用户反馈来推理先前轮次中所犯的错误，以调整对话行为规划，并从隐式语义中获取更高级别的用户信息。我们基于用户模拟器进行了大量的实验，以证明 MACRS 在推荐和用户偏好收集方面的有效性。实验结果表明，与直接使用 LLM 相比，MACRS 展示了用户交互体验的改进。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01135</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>HimiRec：建模分层多兴趣推荐</title>
      <link>https://rss.arxiv.org/abs/2402.01253</link>
      <description><![CDATA[工业推荐系统通常由检索阶段和排名阶段组成，以处理数十亿规模的用户和项目。检索阶段检索与用户兴趣相关的候选项目进行推荐，受到了广泛关注。用户经常表现出分层的多重兴趣，体现在体育中某支NBA球队金州勇士队的重度用户，同时也是几乎整个动画的轻度用户。体育和动画都处于同一水平。然而，大多数现有方法隐式学习这种层次差异，使得更细粒度的兴趣信息被平均，限制了对用户重兴趣和其他轻兴趣的不同需求的详细理解。因此，我们在这项工作中提出了一种新颖的两阶段方法来显式建模分层多兴趣推荐。在第一个分层多兴趣挖掘阶段，分层聚类和基于变压器的模型自适应地生成用户感兴趣的圈或子圈。在第二阶段，检索空间的划分允许EBR模型只处理项目精准捕捉用户精细化兴趣。实验结果表明，所提出的方法实现了最先进的性能。我们的框架还在Lofter（最大的衍生内容社区之一，每月活跃用户数为1000万）成功部署了四个多月。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01253</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>通过法学硕士改进顺序推荐</title>
      <link>https://rss.arxiv.org/abs/2402.01339</link>
      <description><![CDATA[顺序推荐问题在过去几年中引起了相当多的研究关注，导致了众多推荐模型的兴起。在这项工作中，我们探索了如何使用大型语言模型（LLM）来构建或改进顺序推荐方法，这种模型如今在许多基于人工智能的应用程序中引入了颠覆性影响。具体来说，我们设计了三种正交方法以及这些方法的混合，以不同的方式利用法学硕士的力量。此外，我们通过关注每种方法所包含的技术方面并为每种方法确定一系列替代选择来研究每种方法的潜力。我们对三个数据集进行了广泛的实验，并探索了多种配置，包括不同的语言模型和基线推荐模型，以获得每种方法性能的全面了解。在其他观察中，我们强调，使用从 LLM 获得的嵌入来初始化最先进的顺序推荐模型（例如 BERT4Rec 或 SASRec）可以在准确性方面带来显着的性能提升。此外，我们发现针对推荐任务对 LLM 进行微调使其不仅能够学习任务，而且还能在一定程度上学习某个领域的概念。我们还表明，微调 OpenAI GPT 比微调 Google PaLM 2 带来更好的性能。总体而言，我们的大量实验表明，在未来的推荐方法中利用 LLM 具有巨大的潜在价值。我们公开共享实验的代码和数据，以确保可重复性。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01339</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>CF4J：Java 协同过滤</title>
      <link>https://rss.arxiv.org/abs/2402.01008</link>
      <description><![CDATA[推荐系统（RS）提供了一个相关工具来缓解信息过载问题。大量研究人员发表了数百篇论文来改进不同的 RS 特征。建议使用 RS 框架来简化 RS 研究人员：a）设计和实施推荐方法，b）加快实验的执行时间。在本文中，我们提出了 CF4J，这是一个 Java 库，旨在进行基于协同过滤的 RS 研究实验。 CF4J 的设计初衷是从研究人员到研究人员。它允许：a）RS数据集读取，b）完整且轻松地访问数据和中间或最终结果，c）扩展其主要功能，d）同时执行已实现的方法，e）为通过质量措施实施。总之，CF4J 作为一个专门为研究试错过程而设计的库。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01008</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    <item>
      <title>TransFR：具有预训练语言模型的可转移联合推荐</title>
      <link>https://rss.arxiv.org/abs/2402.01124</link>
      <description><![CDATA[联合推荐（FR）促进多个本地客户端共同学习全局模型而不泄露用户私人数据，已成为隐私保护推荐的流行架构。在传统的 FR 中，主导范式是利用离散身份来表示用户/客户端和项目，随后将其映射到特定领域的嵌入以参与模型训练。尽管性能相当可观，但我们揭示了联邦设置中不可忽视的三个固有限制，即跨域的不可转移性、冷启动设置中的不可用性以及联邦训练期间潜在的隐私侵犯。为此，我们提出了一种具有通用文本表示的可转移联合推荐模型 TransFR，它巧妙地结合了预训练语言模型所赋予的通用能力和通过微调本地私有数据所赋予的个性化能力。具体来说，它首先通过利用公共文本语料库的预训练模型来学习与领域无关的项目表示。为了适应联邦推荐，我们进一步引入了高效的联邦微调和本地培训机制。这有助于通过利用每个客户的私人行为数据来为每个客户提供个性化的本地负责人。通过将预训练和微调结合到FR中，它大大提高了转移到新领域的适应效率和解决冷启动问题的泛化能力。通过对多个数据集进行广泛的实验，我们证明我们的 TransFR 模型在准确性、可转移性和隐私性方面超越了几个最先进的 FR。]]></description>
      <guid>https://rss.arxiv.org/abs/2402.01124</guid>
      <pubDate>Mon, 05 Feb 2024 06:17:00 GMT</pubDate>
    </item>
    </channel>
</rss>