<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>将片段捆绑为一个整体：通过对有趣网页的子模块选择挖掘更完整的集群以进行网络主题检测</title>
      <link>https://arxiv.org/abs/2409.12380</link>
      <description><![CDATA[arXiv:2409.12380v1 公告类型：新
摘要：将有趣的网页组织成热门话题是了解多模态网络数据趋势的关键步骤之一。最先进的解决方案是首先将网页组织成大量多粒度的候选主题；通过估计其兴趣度进一步识别热门主题。然而，由于特征表示效率低下和主题生成无监督，这些候选主题包含大量热门主题片段。本文提出了一种捆绑-细化方法，从片段中挖掘更完整的热门主题。具体而言，捆绑步骤将片段主题组织成粗主题；接下来，细化步骤提出了一种基于子模块的方法，以可扩展的方式细化粗主题。我们提出的非常规方法简单而强大，通过利用子模块优化，我们的方法优于涉及精心设计和复杂步骤的传统排名方法。大量实验表明，所提出的方法在两个公共数据集上分别超越了最先进的方法（即潜在泊松反卷积 Pang 等人（2016））20% 的准确率和 10% 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2409.12380</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深入探讨推荐系统中的公平性、偏见、威胁和隐私：见解和未来研究</title>
      <link>https://arxiv.org/abs/2409.12651</link>
      <description><![CDATA[arXiv:2409.12651v1 公告类型：新
摘要：推荐系统对于在电子商务网站、流媒体服务和社交媒体平台上个性化数字体验至关重要。虽然这些系统对于现代数字交互必不可少，但它们面临着公平、偏见、威胁和隐私挑战。推荐系统中的偏见可能导致对特定用户和项目组的不公平对待，而公平性问题要求推荐对所有用户和项目都是公平的。这些系统还容易受到各种威胁，从而损害可靠性和安全性。此外，隐私问题源于个人数据的广泛使用，因此拥有强大的保护机制来保护用户信息至关重要。本研究探讨了推荐系统中的公平、偏见、威胁和隐私。它研究了算法决策如何无意中强化偏见或边缘化特定用户和项目组，强调了公平推荐策略的必要性。该研究还研究了可能破坏系统完整性的攻击形式的各种威胁，并讨论了先进的隐私保护技术。通过解决这些关键领域，该研究突出了当前的局限性，并提出了未来的研究方向，以提高推荐系统的稳健性、公平性和隐私性。最终，这项研究旨在帮助开发更值得信赖和更合乎道德的推荐系统，更好地服务于不同的用户群体。]]></description>
      <guid>https://arxiv.org/abs/2409.12651</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当 SparseMoE 遇到噪声交互：降噪推荐的综合视角</title>
      <link>https://arxiv.org/abs/2409.12730</link>
      <description><![CDATA[arXiv:2409.12730v1 公告类型：新
摘要：从隐式反馈中学习用户偏好是推荐系统的核心挑战之一，其难点在于隐式反馈中可能存在的噪声，因此，近来提出了各种去噪推荐方法，但大多数方法过于依赖超参数配置，不可避免地导致模型适应性和泛化性能不足。在本研究中，我们提出了一种用于去噪推荐的新型自适应集成学习（AEL），它使用稀疏门控网络作为大脑，选择合适的专家为不同的数据样本合成合适的去噪能力。为了解决集成学习模型复杂性的缺点并确保子推荐器的多样性，我们还提出了一种新方法，该方法通过堆叠组件来创建子推荐器，而不是直接构建它们。在各种数据集上的大量实验表明，即使在存在大量动态噪声的情况下，AEL 在各种流行指标上都优于其他方法。我们的代码可以在https://github.com/cpu9xx/AEL上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.12730</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HLLM：通过分层大型语言模型增强项目和用户建模的顺序推荐</title>
      <link>https://arxiv.org/abs/2409.12740</link>
      <description><![CDATA[arXiv:2409.12740v1 公告类型：新
摘要：大型语言模型 (LLM) 在各个领域取得了显著的成功，促使多项研究探索其在推荐系统中的潜力。然而，这些尝试迄今为止仅带来了对传统推荐模型的适度改进。此外，三个关键问题仍未得到充分探索：首先，LLM 预训练权重的真正价值，通常被认为可以封装世界知识；其次，推荐任务微调的必要性；最后，LLM 是否能在推荐系统中表现出与其他领域相同的可扩展性优势。在本文中，我们提出了一种新颖的分层大型语言模型 (HLLM) 架构，旨在增强顺序推荐系统。我们的方法采用两层模型：第一个项目 LLM 从项目的详细文本描述中提取丰富的内容特征，而第二个用户 LLM 利用这些特征根据用户的交互历史预测用户未来的兴趣。大量实验表明，我们的方法有效利用了开源 LLM 的预训练功能，进一步微调可显著提升性能。此外，HLLM 具有出色的可扩展性，最大配置使用 7B 参数进行项目特征提取和用户兴趣建模。此外，HLLM 提供出色的训练和服务效率，使其在实际应用中实用。对两个大型数据集 PixelRec 和 Amazon Reviews 的评估表明，HLLM 取得了最佳结果，远远优于传统的基于 ID 的模型。在线 A/B 测试中，HLLM 展示了显著的收益，验证了其在现实世界推荐场景中的实际影响。代码可在 https://github.com/bytedance/HLLM 获得。]]></description>
      <guid>https://arxiv.org/abs/2409.12740</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>项目共同暴露与缓解暴露偏差的相关性</title>
      <link>https://arxiv.org/abs/2409.12912</link>
      <description><![CDATA[arXiv:2409.12912v1 公告类型：新
摘要：通过向用户展示项目，隐式反馈推荐系统会影响记录的交互，并最终影响他们自己的推荐。这种影响称为曝光偏差，它可能导致过滤气泡和回音室等问题。先前的研究采用了具有曝光信息的多项逻辑模型 (MNL) 来减少合成数据的曝光偏差。
这篇扩展摘要总结了我们之前的研究，其中我们调查了 (i) 这些发现是否适用于人类生成的选择，(ii) 其他离散选择模型是否更好地缓解了偏差，以及 (iii) 项目的估计相关性可能取决于与其一起呈现的其他项目的相关性。我们在受控的在线用户研究中收集了一组有偏见和无偏见的选择数据集，并测量了过度曝光和竞争的影响。
我们发现：(i) 离散选择模型有效地缓解了人为选择数据的曝光偏差；(ii) 不同离散选择模型的稳健性没有显著差异；(iii) 只有多变量离散选择模型对项目之间的竞争具有稳健性。我们得出结论，离散选择模型可以有效缓解曝光偏差，因为它们考虑了项目共同曝光。此外，将项目与更受欢迎或不太受欢迎的项目一起展示可能会严重影响未来的推荐，因此必须跟踪项目曝光以克服曝光偏差。我们认为我们的工作对于理解什么是曝光偏差、它是如何形成的以及如何缓解它至关重要。]]></description>
      <guid>https://arxiv.org/abs/2409.12912</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>估计社交网络中共享效应的简单模型</title>
      <link>https://arxiv.org/abs/2409.12203</link>
      <description><![CDATA[arXiv:2409.12203v1 公告类型：交叉 
摘要：随机对照试验 (RCT) 是评估许多科学领域治疗效果的黄金标准。科技公司已采用 A/B 测试方法作为现代 RCT 的对应方法，其中最终用户被随机分配各种系统变体，并持续跟踪用户行为。然后，目标是估计治疗变体对业务感兴趣的某些指标的因果影响。
当随机化单元（在本例中为最终用户）的结果在统计上不独立时，这会混淆治疗效果的可识别性，并损害决策者对系统的可观察性。社交网络就是一个例子，因为它们旨在促进用户之间的互动。众所周知，这种设计干扰使共享效果等的测量变得复杂。在这项工作中，我们提出了一个基于马尔可夫决策过程 (MDP) 的简单模型，描述社交网络中的用户共享行为。我们在该模型下推导出治疗效果的无偏估计量，并通过可重复的合成实验证明其效果显著优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2409.12203</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于检索增强生成的熟悉度感知证据压缩</title>
      <link>https://arxiv.org/abs/2409.12468</link>
      <description><![CDATA[arXiv:2409.12468v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 通过从外部来源检索证据来整合非参数知识，从而改进大型语言模型 (LM)。然而，它往往难以过滤掉不一致和不相关的信息，这些信息可能会分散 LM 的任务注意力。虽然使用压缩模型压缩检索到的证据旨在解决这个问题，但压缩证据可能仍然不为用于下游任务的目标模型所熟悉，可能无法有效利用证据。我们提出了 FaviComp（熟悉度感知证据压缩），这是一种新颖的无训练证据压缩技术，它使检索到的证据对目标模型更熟悉，同时无缝集成来自模型的参数知识。具体而言，FaviComp 通过结合压缩模型和目标模型的标记概率来生成目标模型更熟悉的上下文，主动降低压缩证据对目标模型的困惑度。这种方法平衡了参数和非参数知识的集成，这在复杂任务中尤其有用，因为检索到的证据集可能不包含所有必要的信息。实验结果表明，FaviComp 在多个开放域 QA 数据集中始终优于现有基线，实现了高压缩率，并展示了参数和非参数知识的有效集成。]]></description>
      <guid>https://arxiv.org/abs/2409.12468</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于信息检索的故障定位多视角自适应对比学习</title>
      <link>https://arxiv.org/abs/2409.12519</link>
      <description><![CDATA[arXiv:2409.12519v1 公告类型：交叉 
摘要：大多数研究集中于基于信息检索的故障定位技术，这些技术为错误报告和源代码文件构建表示并通过相似性测量匹配它们的语义向量。然而，这种方法往往忽略了一些可能有助于提高定位性能的有用信息，例如 1）错误报告和源代码文件之间的交互关系；2）错误报告之间的相似关系；3）源代码文件之间的共引关系。在本文中，我们提出了一种名为信息检索故障定位的多视图自适应对比学习（MACL-IRFL）的新方法来学习上述软件故障定位关系。具体而言，我们首先分别从报告-代码交互视图、报告-报告相似性视图和代码-代码共引视图生成数据增强，并采用图神经网络在嵌入过程中从三个视图中聚合错误报告或源代码文件的信息。此外，我们在这些视图之间进行对比学习。我们的对比学习任务设计将强制错误报告表示对报告-报告和报告-代码视图共享的信息进行编码，并强制源代码文件表示对代码-代码和报告-代码视图共享的信息进行编码，从而减轻辅助信息的噪音。最后，为了评估我们的方法的性能，我们在五个开源 Java 项目上进行了广泛的实验。结果表明，我们的模型在 Accuracy@1、MAP 和 MRR 上分别比最佳基线提高了 28.93%、25.57% 和 20.35%。]]></description>
      <guid>https://arxiv.org/abs/2409.12519</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索用于产品属性值识别的大型语言模型</title>
      <link>https://arxiv.org/abs/2409.12695</link>
      <description><![CDATA[arXiv:2409.12695v1 公告类型：交叉 
摘要：产品属性值识别 (PAVI) 涉及从产品信息中自动识别属性及其值，从而实现产品搜索、推荐和比较等功能。现有方法主要依赖于微调预训练语言模型，例如 BART 和 T5，这些模型需要大量特定于任务的训练数据，并且难以推广到新属性。本文探讨了大型语言模型 (LLM)，例如 LLaMA 和 Mistral，作为 PAVI 的数据高效且稳健的替代方案。我们提出了各种策略：在零样本设置中比较一步和两步基于提示的方法，并通过上下文学习示例利用参数和非参数知识。我们还引入了一个基于预训练 T5 模型的密集演示检索器，并执行指令微调以明确训练 LLM 以执行特定于任务的指令。在两个产品基准上进行的大量实验表明，我们的两步方法显着提高了零样本设置下的性能，并且指令微调在使用训练数据时进一步提高了性能，证明了使用 LLM 进行 PAVI 的实际好处。]]></description>
      <guid>https://arxiv.org/abs/2409.12695</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMSearch：对大型模型作为多模式搜索引擎的潜力进行基准测试</title>
      <link>https://arxiv.org/abs/2409.12959</link>
      <description><![CDATA[arXiv:2409.12959v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的出现为 AI 搜索引擎铺平了道路，例如 SearchGPT，展示了人机交互的新范式。然而，大多数当前的 AI 搜索引擎仅限于纯文本设置，忽略了多模态用户查询和网站信息的文本-图像交错性质。最近，大型多模态模型 (LMM) 取得了令人瞩目的进步。然而，它们是否可以用作 AI 搜索引擎仍未得到充分探索，这使得 LMM 在多模态搜索中的潜力仍是一个悬而未决的问题。为此，我们首先设计了一个精致的管道 MMSearch-Engine，为任何 LMM 提供多模态搜索功能。在此基础上，我们引入了 MMSearch，这是一个全面的评估基准，用于评估 LMM 的多模态搜索性能。精选数据集包含 300 个手动收集的实例，涵盖 14 个子领域，与当前 LMM 的训练数据没有重叠，确保只能在搜索中获得正确答案。通过使用 MMSearch-Engine，通过执行三个单独的任务（重新查询、重新排序和总结）和一个具有完整搜索过程的具有挑战性的端到端任务来评估 LMM。我们对闭源和开源 LMM 进行了广泛的实验。在所有测试模型中，带有 MMSearch-Engine 的 GPT-4o 取得了最佳结果，在端到端任务中超越了商业产品 Perplexity Pro，证明了我们提出的流程的有效性。我们进一步进行了错误分析，以揭示当前的 LMM 仍然难以完全掌握多模态搜索任务，并进行消融研究以表明扩展 AI 搜索引擎测试时间计算的潜力。我们希望 MMSearch 可以提供独特的见解来指导多模态 AI 搜索引擎的未来发展。项目页面：https://mmsearch.github.io]]></description>
      <guid>https://arxiv.org/abs/2409.12959</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过协作信号和语义相关性实现顺序推荐</title>
      <link>https://arxiv.org/abs/2403.07623</link>
      <description><![CDATA[arXiv:2403.07623v2 公告类型：替换 
摘要：顺序推荐系统 (SRS) 可以通过对按时间顺序排列的历史行为进行建模来捕获动态用户偏好。尽管有效，但仅关注行为中的 \textit{协作信号} 并不能完全掌握用户兴趣。对内容特征（例如图像和文本）中反映的 \textit{语义相关性} 进行建模也很重要。为此，在本文中，我们旨在通过有效地将协作信号和语义相关性统一在一起来增强 SRS 任务。值得注意的是，我们通过经验指出，由于语义差距问题，实现这一目标并非易事。因此，我们提出了一种用于顺序推荐的端到端双流架构，称为 TSSR，以从基于 ID 和基于内容的序列中学习用户偏好。具体来说，我们首先提出了一种新颖的分层对比模块，包括粗粒度用户术语和细粒度项目术语，以对齐模态间表示。此外，我们还设计了一个双流架构来学习模态内序列的依赖关系和模态间序列的复杂交互，这可以在理解用户兴趣方面产生更多的表达能力。我们在五个公共数据集上进行了广泛的实验。实验结果表明，TSSR 可以产生比竞争基线更好的性能。我们还在 https://github.com/Mingyue-Cheng/TSSR 上公开了我们的实验代码。]]></description>
      <guid>https://arxiv.org/abs/2403.07623</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对无 ID 推荐系统的 LLM 驱动文本模拟攻击</title>
      <link>https://arxiv.org/abs/2409.11690</link>
      <description><![CDATA[arXiv:2409.11690v2 公告类型：替换 
摘要：无 ID 推荐范式已被提出来解决传统推荐系统难以对具有新 ID 的冷启动用户或项目进行建模的局限性。尽管无 ID 推荐系统很有效，但本研究发现，无 ID 推荐系统容易受到旨在推广特定目标项目的拟议文本模拟攻击 (TextSimu)。作为一种新型的文本中毒攻击，TextSimu 利用大型语言模型 (LLM) 通过模拟热门项目的特征来改变目标项目的文本信息。它在黑盒和白盒设置中均有效运行，利用两个关键组件：统一的流行度提取模块，用于捕获热门项目的基本特征，以及 N 角色一致性模拟策略，通过模拟热门项目创建多个角色来协作合成目标项目的精炼促销文本描述。为了抵御类似 TextSimu 的攻击，我们进一步探索了识别 LLM 生成的促销文本的检测方法。在三个数据集上进行的大量实验表明，TextSimu 比现有的投毒攻击更具威胁性，而我们的防御方法可以检测到 TextSimu 生成的目标项目的恶意文本。通过识别漏洞，我们旨在推动更强大的无 ID 推荐系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2409.11690</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>个人数据流可视化：来自 Booking.com 案例研究的见解</title>
      <link>https://arxiv.org/abs/2304.09603</link>
      <description><![CDATA[arXiv:2304.09603v4 公告类型：替换交叉 
摘要：商业组织持有和处理越来越多的个人数据。政策和法律不断变化，要求这些公司在收集、存储、处理和共享这些数据方面更加透明。本文报告了我们以 Booking.com 为例的研究工作，以可视化从其隐私政策中提取的个人数据流。通过展示公司如何共享其消费者的个人数据，我们提出了问题并扩展了讨论，探讨了使用隐私政策向在线用户告知个人数据流的真实规模和格局的挑战和局限性。这个案例研究可以为我们提供未来关于更多面向数据流的隐私政策分析以及在复杂商业生态系统中构建更全面的个人数据流本体的研究。]]></description>
      <guid>https://arxiv.org/abs/2304.09603</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>避免灾难性遗忘，实现视觉图像的渐进式概念形成</title>
      <link>https://arxiv.org/abs/2402.16933</link>
      <description><![CDATA[arXiv:2402.16933v2 公告类型：replace-cross 
摘要：深度神经网络在机器学习方面表现出色，特别是在视觉任务中，然而，它们在连续学习新任务时经常遭受灾难性遗忘。在这项工作中，我们介绍了 Cobweb4V，一种传统神经网络方法的替代方案。Cobweb4V 是一种新颖的视觉分类方法，它建立在 Cobweb 的基础上，Cobweb 是一种类似人类的学习系统，其灵感来自人类随着时间的推移逐步学习新概念的方式。在这项研究中，我们进行了全面的评估，展示了 Cobweb4V 在学习视觉概念方面的能力，与传统方法相比，需要更少的数据来实现有效的学习成果，随着时间的推移保持稳定的性能，并实现值得称赞的渐近行为，没有灾难性的遗忘效应。这些特征与人类认知中的学习策略相一致，将 Cobweb4V 定位为神经网络方法的有前途的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2402.16933</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>jina-embeddings-v3：使用任务 LoRA 进行多语言嵌入</title>
      <link>https://arxiv.org/abs/2409.10173</link>
      <description><![CDATA[arXiv:2409.10173v3 公告类型：replace-cross 
摘要：我们引入了 jina-embeddings-v3，这是一种具有 5.7 亿个参数的新型文本嵌入模型，在多语言数据和长上下文检索任务上实现了最先进的性能，支持最多 8192 个标记的上下文长度。该模型包括一组特定于任务的低秩自适应 (LoRA) 适配器，用于为查询文档检索、聚类、分类和文本匹配生成高质量嵌入。对 MTEB 基准的评估表明，jina-embeddings-v3 在英语任务上的表现优于 OpenAI 和 Cohere 的最新专有嵌入，同时在所有多语言任务中都比 multilingual-e5-large-instruct 实现了卓越的性能。默认输出维度为 1024，通过 Matryoshka 表示学习，用户可以灵活地将嵌入维度减少到 32 左右，而不会影响性能。]]></description>
      <guid>https://arxiv.org/abs/2409.10173</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>