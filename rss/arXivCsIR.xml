<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 20 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>先解释再排序：使用大型语言模型的自然语言解释对神经排序器进行尺度校准</title>
      <link>https://arxiv.org/abs/2402.12276</link>
      <description><![CDATA[arXiv:2402.12276v1 公告类型：新
摘要：排名系统中的尺度校准过程涉及调整排名器的输出，以与点击率或相关性等重要质量相对应，这对于反映现实世界的价值至关重要，从而提高系统的有效性和可靠性。尽管已经对学习排名模型中的校准排名损失进行了研究，但调整神经排名器规模的特定问题尚未得到彻底研究，神经排名器擅长处理文本信息。神经排序模型擅长处理文本数据，但由于其复杂性和所需的强化训练，将现有的尺度校准技术应用于这些模型会带来重大挑战，通常会导致次优结果。
  本研究深入探讨了大型语言模型 (LLM) 为与量表校准分数相关的查询和文档对提供不确定性测量的潜力。通过采用蒙特卡罗抽样来衡量法学硕士的相关概率，并结合自然语言解释（NLE）来阐明这种不确定性，我们对两个主要的文档排名数据集进行了全面测试。我们的研究结果表明，利用 NLE 的方法在各种训练场景下都优于现有的校准方法，从而可以得到更好的校准神经排序器。]]></description>
      <guid>https://arxiv.org/abs/2402.12276</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>TriSampler：用于密集检索的更好的负采样原理</title>
      <link>https://arxiv.org/abs/2402.11855</link>
      <description><![CDATA[arXiv:2402.11855v1 公告类型：新
摘要：负采样是密集检索的关键技术，对于训练有效的检索模型至关重要并显着影响检索性能。虽然现有的负采样方法通过利用硬负例取得了值得称赞的进展，但仍然缺乏构建负候选和设计负采样分布的综合指导原则。为了弥补这一差距，我们着手对密集检索中的负采样进行理论分析。这一探索最终揭示了准三角原理，这是一个新的框架，阐明了查询、正文档和负文档之间的三角相互作用。在这一指导原则的推动下，我们推出了 TriSampler，一种简单而高效的负采样方法。 TriSampler 的关键在于它能够在规定的约束区域内选择性地采样更多信息的负样本。实验评估表明，TriSampler 在各种代表性检索模型中始终获得卓越的检索性能。]]></description>
      <guid>https://arxiv.org/abs/2402.11855</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>FeB4RAG：在检索增强生成的背景下评估联合搜索</title>
      <link>https://arxiv.org/abs/2402.11891</link>
      <description><![CDATA[arXiv:2402.11891v1 公告类型：新
摘要：联合搜索系统聚合来自多个搜索引擎的结果，选择适当的来源来提高结果质量并与用户意图保持一致。随着检索增强生成 (RAG) 管道的日益普及，联合搜索可以在跨异构数据源获取相关信息以生成明智的响应方面发挥关键作用。然而，现有的数据集（例如在过去的 TREC FedWeb 跟踪中开发的数据集）早于 RAG 范式转变，并且缺乏对现代信息检索挑战的表征。为了弥补这一差距，我们提出了 FeB4RAG，这是一个专门为 RAG 框架内的联合搜索而设计的新颖数据集。该数据集源自广泛使用的 \beir 基准测试集合的 16 个子集合，包括为聊天机器人应用程序量身定制的 790 个信息请求（类似于对话查询），以及每个资源返回的最佳结果和相关的 LLM 衍生的相关性判断。此外，为了支持此集合的需求，我们演示了与简单的联合搜索方法相比，RAG 的高质量联合搜索系统对响应生成的影响。我们通过定性并排比较来比较 RAG 管道生成的答案来做到这一点。我们的收藏促进并支持新的联合搜索方法的开发和评估，特别是在 RAG 管道的背景下。]]></description>
      <guid>https://arxiv.org/abs/2402.11891</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>异质性意识跨校选修课推荐：混合联合方法</title>
      <link>https://arxiv.org/abs/2402.12202</link>
      <description><![CDATA[arXiv:2402.12202v1 公告类型：新
摘要：在现代教育时代，解决跨学校学习者的多样性至关重要，特别是在选课的个性化推荐系统中。然而，隐私问题往往限制跨学校数据共享，这阻碍了现有方法对稀疏数据进行建模和有效解决异质性的能力，最终导致推荐不理想。为此，我们提出了 HFRec，这是一种异构感知混合联合推荐系统，专为跨学校选修课推荐而设计。所提出的模型为每所学校构建异构图，结合学生之间的各种交互和历史行为来整合上下文和内容信息。我们设计了一种注意力机制来捕获异质性感知表示。此外，在联合计划下，我们通过自适应学习设置来训练基于学校的个别模型，以推荐量身定制的选修课。我们的 HFRec 模型展示了其在提供个性化选修建议同时维护隐私方面的有效性，因为它在开源和现实数据集上都优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2402.12202</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>用于词干提取的大型语言模型：承诺、陷阱和失败</title>
      <link>https://arxiv.org/abs/2402.11757</link>
      <description><![CDATA[arXiv:2402.11757v1 公告类型：新
摘要：文本词干提取是一种自然语言处理技术，用于将单词还原为其基本形式（也称为词根形式）。事实证明，在 IR 中使用词干提取通常可以提高 BM25 等关键字匹配模型的有效性。然而，传统的词干提取方法仅关注单个术语，忽视了上下文信息的丰富性。认识到这一差距，在本文中，我们研究了使用大型语言模型（LLM）通过利用其上下文理解能力来词干的有前景的想法。在这方面，我们确定了三种途径，每种途径在计算成本、有效性和鲁棒性方面都有不同的权衡：（1）使用LLM来词干集合的词汇，即出现在集合中的唯一单词的集合。集合（词汇词干提取），(2) 使用 LLM 分别对每个文档进行词干提取（上下文词干提取），以及 (3) 使用 LLM 从每个文档中提取不应词干提取的实体，然后使用词汇词干提取来对其余术语进行词干提取（基于实体的上下文词干提取）。通过一系列实证实验，我们将法学硕士在词干提取中的使用与传统词汇词干提取器（例如 Porter 和 Krovetz）在英语文本中的使用进行了比较。我们发现，虽然词汇词干提取和上下文词干提取无法比传统词干提取器实现更高的有效性，但在特定条件下，基于实体的上下文词干提取可以比单独使用 Porter 词干提取器实现更高的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.11757</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>提出最佳问题：将大型语言模型与对话式搜索中检索器的偏好保持一致</title>
      <link>https://arxiv.org/abs/2402.11827</link>
      <description><![CDATA[arXiv:2402.11827v1 公告类型：新
摘要：对话搜索与单轮检索任务不同，需要在对话上下文中理解当前问题。重写然后检索的常见方法旨在将问题脱离上下文，使现成的检索器能够自给自足，但由于从检索结果中合并信号的能力有限，大多数现有方法都会产生次优的查询重写。为了克服这一限制，我们提出了一种新颖的框架 RetPO（检索器偏好优化），该框架旨在优化语言模型（LM），以便根据目标检索系统的偏好重新制定搜索查询。该过程首先提示大型 LM 产生各种潜在的重写，然后收集这些重写的检索性能作为检索器的偏好。通过这个过程，我们构建了一个名为 RF 集合的大型数据集，其中包含检索器对 12K 对话中超过 410K 查询重写的反馈。此外，我们使用该数据集微调较小的 LM，使其与检索器的偏好作为反馈保持一致。由此产生的模型在最近的两个会话搜索基准测试中实现了最先进的性能，显着优于包括 GPT-3.5 在内的现有基准。]]></description>
      <guid>https://arxiv.org/abs/2402.11827</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 后的搜索引擎：生成式人工智能如何使搜索变得不那么可靠</title>
      <link>https://arxiv.org/abs/2402.11707</link>
      <description><![CDATA[arXiv:2402.11707v1 公告类型：新
摘要：在这篇评论中，我们讨论了搜索引擎的不断发展的性质，因为它们开始生成、索引和分发由生成人工智能 (GenAI) 创建的内容。我们的讨论强调了 GenAI 集成早期阶段的挑战，特别是围绕事实的不一致和偏见。我们讨论 GenAI 的输出如何带来一种毫无根据的可信度，同时降低透明度和采购能力。此外，搜索引擎已经在用充满错误的生成内容来回答查询，这进一步模糊了信息的来源并影响了信息生态系统的完整性。我们讨论所有这些因素如何降低搜索引擎的可靠性。最后，我们总结了一些活跃的研究方向和悬而未决的问题。]]></description>
      <guid>https://arxiv.org/abs/2402.11707</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为冷启动项目推荐的数据增强器</title>
      <link>https://arxiv.org/abs/2402.11724</link>
      <description><![CDATA[arXiv:2402.11724v1 公告类型：新
摘要：法学硕士的推理和泛化能力可以帮助我们更好地了解用户偏好和项目特征，为增强推荐系统提供令人兴奋的前景。虽然在用户与项目交互丰富的情况下有效，但传统的推荐系统很难在没有历史交互的情况下推荐冷启动项目。为了解决这个问题，我们建议利用法学硕士作为数据增强器来弥合训练期间冷启动项目的知识差距。我们采用 LLM 根据用户历史行为的文本描述和新项目描述来推断用户对冷启动项目的偏好。然后，通过辅助成对损失将增强的训练信号纳入下游推荐模型的学习中。通过在亚马逊公共数据集上的实验，我们证明了 LLM 可以有效增强冷启动项目的训练信号，从而显着改进各种推荐模型的冷启动项目推荐。]]></description>
      <guid>https://arxiv.org/abs/2402.11724</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>基于知识图的自适应传播会话推荐</title>
      <link>https://arxiv.org/abs/2402.11302</link>
      <description><![CDATA[arXiv:2402.11302v1 公告类型：新
摘要：基于会话的推荐系统（SBRS）根据用户的历史活动预测用户的下一个交互项目。虽然大多数 SBRS 在每个会话中本地捕获购买意图，但跨不同会话捕获项目的全局信息对于表征其一般属性至关重要。以前的工作通过构建图并合并邻居信息来捕获这种跨会话信息。然而，这种结合不能根据每个会话的独特意图自适应地变化，并且构建的图仅包含一种类型的用户-项目交互。为了解决这些限制，我们提出了具有会话自适应传播的基于知识图的会话推荐。具体来说，我们通过连接具有多类型边的项目来构建知识图，以表征各种用户-项目交互。然后，我们考虑学习会话中的用户意图，自适应地聚合项目的邻居信息。实验结果表明，配备我们构建的知识图和会话自适应传播可以将会话推荐骨干增强 10%-20%。此外，我们提供了一个工业案例研究，表明我们提出的框架比家得宝电子平台现有部署良好的模型实现了 2% 的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2402.11302</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>模式明智的透明顺序推荐</title>
      <link>https://arxiv.org/abs/2402.11480</link>
      <description><![CDATA[arXiv:2402.11480v1 公告类型：新
摘要：透明的决策过程对于开发可靠且值得信赖的推荐系统至关重要。对于顺序推荐，这意味着模型可以识别关键项目作为其推荐结果的理由。然而，同时实现模型透明度和推荐性能具有挑战性，特别是对于将整个项目序列作为输入而不进行筛选的模型。在本文中，我们提出了一个可解释的框架（名为 PTSR），它可以实现模式方面的透明决策过程。它将项目序列分解为多级模式，作为整个推荐过程的原子单元。每个模式对结果的贡献在概率空间中量化。通过精心设计的模式加权校正，可以在缺乏地面实况关键模式的情况下学习模式贡献。最终推荐的项目是最关键模式强烈认可的项目。对四个公共数据集的广泛实验证明了卓越的推荐性能，而案例研究则验证了模型的透明度。我们的代码可在 https://anonymous.4open.science/r/PTSR-2237 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.11480</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>用于协作过滤的邻域增强监督对比学习</title>
      <link>https://arxiv.org/abs/2402.11523</link>
      <description><![CDATA[arXiv:2402.11523v1 公告类型：新
摘要：协同过滤（CF）技术虽然在推荐任务中有效，但面临着数据稀疏的挑战。研究人员已经开始利用对比学习引入额外的自我监督信号来解决这个问题。然而，这种方法通常会无意中使目标用户/项目与其协作邻居保持距离，从而限制了其功效。为此，我们提出了一种解决方案，将锚节点的协作邻居视为最终目标损失函数中的正样本。本文重点开发两种独特的监督对比损失函数，有效地将监督信号与对比损失结合起来。我们通过梯度透镜分析了我们提出的损失函数，证明不同的正样本同时影响更新锚节点的嵌入。这些样本的影响取决于它们与锚节点和负样本的相似度。使用基于图的协同过滤模型作为骨干，并遵循与现有对比学习模型SGL相同的数据增强方法，我们有效地增强了推荐模型的性能。我们提出的邻域增强监督对比损失（NESCL）模型用我们的新颖损失函数替代了 SGL 中的对比损失函数，显示出显着的性能改进。在三个真实数据集 Yelp2018、Gowalla 和 Amazon-Book 上，我们的模型在 NDCG@20 上分别超过原始 SGL 10.09%、7.09% 和 35.36%。]]></description>
      <guid>https://arxiv.org/abs/2402.11523</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>探索下一代信息检索的 ChatGPT：机遇与挑战</title>
      <link>https://arxiv.org/abs/2402.11203</link>
      <description><![CDATA[arXiv:2402.11203v1 公告类型：新
摘要：人工智能（AI）的快速发展凸显了 ChatGPT 作为信息检索（IR）领域的关键技术。与之前的版本不同，ChatGPT 具有显着的优势，吸引了业界和学术界的关注。虽然有些人认为 ChatGPT 是一项突破性的创新，但另一些人则将其成功归因于产品开发和市场策略的有效整合。 ChatGPT 与 GPT-4 一起出现，标志着生成式 AI 进入了一个新阶段，生成的内容与训练示例不同，并且超越了 OpenAI 之前的 GPT-3 模型的能力。与 IR 任务中传统的监督学习方法不同，ChatGPT 挑战了现有的范式，在文本质量保证、模型偏差和效率方面带来了新的挑战和机遇。本文旨在研究 ChatGPT 对 IR 任务的影响，并对其未来潜在发展提供见解。]]></description>
      <guid>https://arxiv.org/abs/2402.11203</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>镜像梯度：通过探索平坦局部最小值走向稳健的多模态推荐系统</title>
      <link>https://arxiv.org/abs/2402.11262</link>
      <description><![CDATA[arXiv:2402.11262v1 公告类型：新
摘要：多模态推荐系统利用各种类型的信息对用户偏好和项目特征进行建模，帮助用户发现符合其兴趣的项目。多模态信息的集成缓解了推荐系统固有的挑战，例如数据稀疏问题和冷启动问题。然而，它同时放大了多模态信息输入带来的某些风险，例如信息调整风险和固有噪声风险。这些风险对推荐模型的稳健性提出了重大挑战。在本文中，我们从平坦局部最小值的新颖角度分析多模态推荐系统，并提出一种简洁而有效的梯度策略，称为镜像梯度（MG）。该策略可以隐式增强模型在优化过程中的鲁棒性，减轻多模态信息输入带来的不稳定风险。我们还提供了强有力的理论证据并进行了广泛的实证实验，以证明 MG 在各种多模态推荐模型和基准中的优越性。此外，我们发现所提出的 MG 可以补充现有的稳健训练方法，并且可以轻松扩展到各种高级推荐模型，使其成为训练多模态推荐系统的有前途的新基础范例。代码发布于 https://github.com/Qrange-group/Mirror-Gradient。]]></description>
      <guid>https://arxiv.org/abs/2402.11262</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的基础模型：调查和新视角</title>
      <link>https://arxiv.org/abs/2402.11143</link>
      <description><![CDATA[arXiv:2402.11143v1 公告类型：新
摘要：最近，基础模型（FM）凭借其广泛的知识库和复杂的架构，在推荐系统（RS）领域提供了独特的机会。在本文中，我们尝试彻底研究基于 FM 的推荐系统（FM4RecSys）。我们首先回顾一下FM4RecSys的研究背景。然后，我们对现有的 FM4RecSys 研究工作进行了系统的分类，可以分为四个不同的部分，包括数据特征、表示学习、模型类型和下游任务。在每个部分中，我们回顾了最近的主要研究进展，概述了代表性模型并讨论了它们的特征。此外，我们详细阐述了 FM4RecSys 的开放问题和机遇，旨在阐明该领域未来的研究方向。最后，我们回顾我们的发现并讨论该领域的新兴趋势。]]></description>
      <guid>https://arxiv.org/abs/2402.11143</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>电子商务搜索中查询重构建模的可扩展性和可扩展性</title>
      <link>https://arxiv.org/abs/2402.11202</link>
      <description><![CDATA[arXiv:2402.11202v1 公告类型：新
摘要：客户行为数据显着影响电子商务搜索系统。然而，在不太常见的查询的情况下，相关的行为数据往往稀疏且嘈杂，为搜索机制提供的支持不足。为了应对这一挑战，引入了查询重构的概念。它表明不太常见的查询可以利用具有相似含义的流行查询的行为模式。在亚马逊产品搜索中，查询重构已显示出其在提高搜索相关性和增加整体收入方面的有效性。尽管如此，针对在流量较低且多语言环境复杂的地区运营的小型或新兴企业采用这种方法在可扩展性和可扩展性方面提出了挑战。本研究的重点是通过构建一个查询重构解决方案来克服这一挑战，即使在面对有限的训练数据时，在质量和规模以及相对复杂的语言特征方面也能有效运行。在本文中，我们概述了在亚马逊产品搜索基础设施中实施的解决方案，其中包含一系列要素，包括改进数据挖掘流程、重新定义模型训练目标和重塑训练策略。通过搜索排名和广告匹配的在线 A/B 测试验证了所提出解决方案的有效性。值得注意的是，与传统实施方案相比，在搜索排名中采用所提出的解决方案使得日语和印地语案例中的总收入分别增加了 0.14% 和 0.29%，并且英语案例中的总收入增加了 0.08\%；而在日本的案例中，搜索广告匹配导致广告收入增长了 0.36%。]]></description>
      <guid>https://arxiv.org/abs/2402.11202</guid>
      <pubDate>Tue, 20 Feb 2024 06:17:18 GMT</pubDate>
    </item>
    </channel>
</rss>