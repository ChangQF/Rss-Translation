<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 12 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>多党派比例代表制</title>
      <link>https://arxiv.org/abs/2407.08571</link>
      <description><![CDATA[arXiv:2407.08571v1 公告类型：交叉 
摘要：图像搜索和检索任务可以延续有害的刻板印象，消除文化认同并扩大社会差距。当前减轻这些代表性危害的方法是平衡由少数（通常是二进制）属性定义的人口群体中检索到的项目数量。然而，大多数现有方法都忽略了由性别、种族和民族等群体属性组合确定的交叉群体。我们引入了多组比例代表制 (MPR)，这是一种衡量交叉群体代表性的新指标。我们开发了估计 MPR 的实用方法，提供了理论保证，并提出了优化算法以确保检索中的 MPR。我们证明，优化平等和比例代表制指标的现有方法可能无法促进 MPR。至关重要的是，我们的工作表明，优化 MPR 可以在由丰富函数类指定的多个交叉组中产生更多的比例代表制，并且通常对检索准确性的影响最小。]]></description>
      <guid>https://arxiv.org/abs/2407.08571</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>DS@GT eRisk 2024：用于社交媒体风险评估的句子转换器</title>
      <link>https://arxiv.org/abs/2407.08008</link>
      <description><![CDATA[arXiv:2407.08008v1 公告类型：交叉 
摘要：我们为 eRisk 2024 中的 DS@GT 团队提供了任务 1 和 3 的工作笔记。我们为任务 1 提出了一个排名系统，该系统基于贝克抑郁量表 (BDI-II) 问卷预测抑郁症状，使用根据问题相关性训练的二元分类器作为排名的代理。我们发现二元分类器在排名方面没有得到很好的校准，并且在评估过程中表现不佳。对于任务 3，我们使用来自 BERT 的嵌入来根据用户帖子历史预测饮食失调症状的严重程度。我们发现经典机器学习模型在这项任务上表现良好，最终与基线模型相媲美。文本数据的表示在这两个任务中都至关重要，我们发现句子转换器是下游建模的强大工具。源代码和模型可在 \url{https://github.com/dsgt-kaggle-clef/erisk-2024} 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.08008</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>FsPONER：领域特定场景中命名实体识别的少样本快速优化</title>
      <link>https://arxiv.org/abs/2407.08035</link>
      <description><![CDATA[arXiv:2407.08035v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 为命名实体识别 (NER) 任务提供了一条新途径。与微调相比，基于 LLM 的提示方法避免了训练的需要，节省了大量的计算资源，并且依赖于最少的注释数据。先前的研究在一般 NER 基准上取得了与完全监督的基于 BERT 的微调方法相当的性能。然而，之前的方法都没有研究过基于 LLM 的少样本学习在特定领域场景中的效率。为了解决这一差距，我们引入了 FsPONER，一种优化少样本提示的新方法，并评估其在特定领域 NER 数据集上的性能，重点关注工业制造和维护，同时使用多个 LLM——GPT-4-32K、GPT-3.5-Turbo、LLaMA 2-chat 和 Vicuna。 FsPONER 由三种基于随机采样、TF-IDF 向量和两者结合的少样本选择方法组成。随着少样本示例数量的增加，我们将这些方法与通用 GPT-NER 方法进行比较，并评估它们与微调 BERT 和 LLaMA 2-chat 的最佳 NER 性能。在考虑数据稀缺的现实场景中，采用 TF-IDF 的 FsPONER 在 F1 得分上比微调模型高出约 10%。]]></description>
      <guid>https://arxiv.org/abs/2407.08035</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>DALL-M：使用 LLM 进行情境感知临床数据增强</title>
      <link>https://arxiv.org/abs/2407.08227</link>
      <description><![CDATA[arXiv:2407.08227v1 公告类型：交叉 
摘要：X 射线图像在医学诊断中至关重要，但如果没有临床背景，其有效性就会受到限制。放射科医生经常发现胸部 X 光不足以诊断潜在疾病，需要全面的临床特征和数据整合。我们提出了一种新技术，通过增强临床表格数据的增强技术来增强临床背景，从而提高其在 AI 医学诊断中的适用性和可靠性。为了解决这个问题，我们引入了一种开创性的临床数据增强方法，该方法采用大型语言模型 (LLM) 来生成患者上下文合成数据。这种方法对于在医疗保健领域训练更强大的深度学习模型至关重要。它保留了真实患者数据的完整性，同时通过上下文相关的合成特征丰富了数据集，从而显着提高了模型性能。DALL-M 使用三阶段特征生成过程：（i）临床背景存储，（ii）专家查询生成，以及（iii）上下文感知特征增强。 DALL-M 通过合成胸部 X 光片图像和报告生成新的临床相关特征。它使用 MIMIC-IV 数据集中的九个特征应用于 799 个病例，创建了一组 91 个特征的增强集。这是首次根据患者的 X 光片报告、性别和年龄为现有特征和新特征生成上下文值，并在数据增强过程中产生新的上下文知识。使用机器学习模型（包括决策树、随机森林、XGBoost 和 TabNET）进行的经验验证表明，性能显著提高。加入增强特征后，F1 得分提高了 16.5%，准确率和召回率提高了约 25%。DALL-M 解决了临床数据增强中的一个关键差距，为生成上下文丰富的数据集提供了一个强大的框架。]]></description>
      <guid>https://arxiv.org/abs/2407.08227</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>FAR-Tr​​ans：用于金融资产推荐的投资数据集</title>
      <link>https://arxiv.org/abs/2407.08692</link>
      <description><![CDATA[arXiv:2407.08692v1 公告类型：新
摘要：金融资产推荐 (FAR) 是推荐系统的一个子域，它为投资者识别有用的金融证券，期望他们将资本投资于推荐的资产。FAR 解决方案分析和学习多种数据源，包括时间序列定价数据、客户资料信息和期望以及过去的投资。然而，大多数模型都是基于专有数据集开发的，因此无法与通用基准进行比较。在本文中，我们旨在通过引入 FAR-Tr​​ans 来解决这个问题，FAR-Tr​​ans 是 FAR 的第一个公共数据集，包含从一家大型欧洲金融机构获得的定价信息和散户投资者交易。我们还提供了 11 种 FAR 算法在数据上的基准比较，以用作未来的基线。数据集可以从 https://doi.org/10.5525/gla.researchdata.1658 下载。]]></description>
      <guid>https://arxiv.org/abs/2407.08692</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>小数据环境下的自动神经专利态势分析</title>
      <link>https://arxiv.org/abs/2407.08001</link>
      <description><![CDATA[arXiv:2407.08001v1 公告类型：交叉 
摘要：专利态势分析是识别与特定技术领域相关的所有专利的过程，对于评估知识产权背景的各个方面非常重要。传统上，构建专利态势分析非常费力且成本高昂，而近几十年来专利活动的迅速扩张推动了对高效且有效的自动化专利态势分析方法的需求日益增加。特别是，我们必须能够使用最少数量的标记示例来构建专利态势分析，因为为狭窄的技术领域标记专利需要高度专业化（因此昂贵）的技术知识。我们提出了一种自动化神经专利态势分析系统，该系统在困难示例上表现出显着提高的性能（“困难”示例上的 F_1 为 0.69，而之前报告的系统为 0.6），并且在训练数据少得多的情况下也有显着改进（在少至 24 个示例中总体为 0.75 F_1$）。此外，在评估这种自动化态势分析系统时，获取良好的数据是一项挑战；我们通过将 Abood 和 Feltenberger (2018) 的“种子/反种子”方法与主动学习相结合来收集决策边界附近的困难标记示例，展示了更高质量的训练数据生成程序。使用此程序，我们创建了一个用于训练和测试的标记 AI 专利新数据集。与之前的工作一样，我们将我们的方法与许多基线系统进行了比较，并发布了我们的代码和数据供其他人在此基础上进行构建。]]></description>
      <guid>https://arxiv.org/abs/2407.08001</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>超越基准：评估检索增强生成系统的嵌入模型相似性</title>
      <link>https://arxiv.org/abs/2407.08275</link>
      <description><![CDATA[arXiv:2407.08275v1 公告类型：新
摘要：嵌入模型的选择是检索增强生成 (RAG) 系统设计中的关键步骤。鉴于可用选项的数量庞大，识别相似模型的集群简化了此模型选择过程。仅依靠基准性能分数只能对模型相似性进行弱评估。因此，在本研究中，我们在 RAG 系统的背景下评估嵌入模型的相似性。我们的评估有两个方面：我们使用中心核对齐来逐对比较嵌入。此外，由于它与 RAG 系统特别相关，我们使用 Jaccard 和等级相似性来评估这些模型之间检索结果的相似性。我们在流行的基准信息检索 (BEIR) 的五个数据集中比较了不同系列的嵌入模型（包括专有模型）。通过实验，我们识别出与模型系列相对应的模型集群，但有趣的是，我们也识别出了一些跨系列的集群。此外，我们对 top-k 检索相似度的分析表明，低 k 值时方差较大。我们还识别出专有模型的可能开源替代方案，其中 Mistral 与 OpenAI 模型的相似度最高。]]></description>
      <guid>https://arxiv.org/abs/2407.08275</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>基于 ADMM 的 Transformer 半结构化模式修剪框架</title>
      <link>https://arxiv.org/abs/2407.08334</link>
      <description><![CDATA[arXiv:2407.08334v1 Announce Type: new 
摘要：NLP（自然语言处理）通过 Transformer 模型取得了巨大的成功。然而，该模型拥有数亿或数十亿个参数，这对于在个人计算机或小规模服务器上部署而言是巨大的负担。为了解决这个问题，我们要么使模型的权重矩阵相对稀疏，要么压缩注意层。模式剪枝是最重要的剪枝方法之一，它允许在每个划分的模式块中选择固定数量的参数并对其进行剪枝。然而​​，模式剪枝的效果受到每层权重区域内稀疏性的严格限制。在本文中，我们首先引入了基于交替方向乘子法（ADMM）的模式剪枝框架来重塑激活图的分布。具体而言，我们建议将 Transformer 上的模式剪枝表述为约束优化，并使用 ADMM 来优化问题。这样，初始的密集特征图就被转换为区域稀疏的特征图。因此，我们可以基于模式修剪方法实现更高的压缩率和更好的性能。此外，本文还提供了具有局部稀疏性的 ADMM 的理论推导。最后，我们还扩展了基于量化的 ADMM 框架以展示其泛化能力，并使用 SR-STE 避免梯度消失问题。我们对 GLUE 数据集上的分类任务进行了广泛的实验。值得注意的是，我们实现了 50% 的压缩率，同时保持了 COLA 上 55.4% 的马修斯相关性、RTE 上 68.8% 的准确率和总分为 80.1。我们的框架在 GLUE 数据集上的其他任务上也表现良好。]]></description>
      <guid>https://arxiv.org/abs/2407.08334</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>搜索、检查和提前终止：使用无注释证据检测虚假新闻</title>
      <link>https://arxiv.org/abs/2407.07931</link>
      <description><![CDATA[arXiv:2407.07931v1 公告类型：新
摘要：先驱研究认为，证据是除模式之外的虚假新闻检测的关键要素。现有的证据感知方法要么需要繁琐的预处理程序来确保相关且高质量的证据数据，要么在所有新闻案例中纳入所有可用证据，而不管检索到的数据的质量和数量如何。在本文中，我们提出了一种名为 \textbf{SEE} 的方法，该方法使用早期终止机制从网络搜索的无注释证据中检索有用信息。所提出的 SEE 由三个主要阶段构成：\textbf{S}使用新闻作为查询搜索在线资料并直接使用其标题作为证据而不进行任何注释或过滤程序；通过注意机制依次 \textbf{E} 检查新闻和每条证据，以使用检索到的信息产生新的隐藏状态；以及通过评估是否有足够的信心产生正确的预测来允许 \textbf{E} 在检查循环中提前终止。我们对具有未处理证据（即 Weibo21、GossipCop）和预处理证据（即 Snopes 和 PolitiFact）的数据集进行了广泛的实验。实验结果表明，所提出的方法优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.07931</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>CADC：对用户-商品交互进行编码以压缩推荐模型训练数据</title>
      <link>https://arxiv.org/abs/2407.08108</link>
      <description><![CDATA[arXiv:2407.08108v1 公告类型：新
摘要：深度学习推荐模型 (DLRM) 是当前电子商务行业的核心。然而，用于训练这些大型模型的训练数据量呈指数级增长，导致训练困难重重。训练数据集包含两种主要类型的信息：基于内容的信息（用户和项目的特征）和协作信息（用户和项目之间的交互）。减少训练数据集的一种方法是删除用户-项目交互。但这会大大减少协作信息，而协作信息对于保持准确性至关重要，因为它包含了交互历史。这种损失严重影响了 DLRM 的性能。
本文提出了一个重要的观察结果：如果可以捕获用户-项目交互历史以丰富用户和项目嵌入，那么交互历史就可以在不损失模型准确性的情况下进行压缩。因此，这项工作，即协作感知数据压缩 (CADC)，采用两步方法进行训练数据集压缩。在第一步中，我们使用用户-项目交互矩阵的矩阵分解来为用户和项目创建一个新的嵌入表示。一旦用户和项目嵌入通过交互历史信息得到丰富，该方法就会对训练数据集应用均匀随机采样，以大幅减少训练数据集的大小，同时最大限度地减少模型准确率的下降。CADC 的源代码可在 \href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md} 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.08108</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>专利权利要求关键词提取新方法</title>
      <link>https://arxiv.org/abs/2407.07923</link>
      <description><![CDATA[arXiv:2407.07923v1 公告类型：新
摘要：在专利申请处理中，现有技术的搜索至关重要，它包括检索与申请发明相关的其他文件。大多数方法都会向搜索引擎提供通过频率分析方法提取的关键字。我们建议并演示一种依赖于专利权利要求中提供信息方式的新方法。]]></description>
      <guid>https://arxiv.org/abs/2407.07923</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>增强社交媒体个性化：使用 Transformer 模型进行动态用户资料嵌入和多模式上下文分析</title>
      <link>https://arxiv.org/abs/2407.07925</link>
      <description><![CDATA[arXiv:2407.07925v1 公告类型：新
摘要：本研究调查了动态用户配置文件嵌入对社交网络中个性化情境感知体验的影响。对超过两千万个数据点的数据集进行了多语言和英语转换器模型的比较分析。分析包括广泛的指标和性能指标，以比较动态配置文件嵌入与非嵌入（实际上是静态配置文件嵌入）。进行了一项使用降级函数的比较研究。广泛的测试和研究证实，动态嵌入成功地跟踪了用户不断变化的品味和偏好，提供了更准确的推荐和更高的用户参与度。这些结果对于旨在通过相关功能和复杂的推荐引擎改善用户体验的社交媒体平台非常重要。]]></description>
      <guid>https://arxiv.org/abs/2407.07925</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>CaseGPT：基于语言模型和检索增强生成的案例推理框架</title>
      <link>https://arxiv.org/abs/2407.07913</link>
      <description><![CDATA[arXiv:2407.07913v1 公告类型：新
摘要：本文介绍了 CaseGPT，这是一种创新方法，它结合了大型语言模型 (LLM) 和检索增强生成 (RAG) 技术，以增强医疗保健和法律领域的案例推理。该系统通过启用基于不精确描述的模糊搜索来解决传统数据库查询的挑战，从而提高数据的可搜索性和可用性。CaseGPT 不仅可以检索相关案例数据，还可以根据从现有案例数据中辨别出的模式生成有见地的建议和推荐。此功能对于医疗诊断、法律先例研究和案例策略制定等任务特别有价值。本文深入讨论了该系统的方法、它在医学和法律领域的表现以及未来应用的潜力。我们的实验表明，CaseGPT 在准确率、召回率和效率方面明显优于传统的基于关键字和简单的基于 LLM 的系统。]]></description>
      <guid>https://arxiv.org/abs/2407.07913</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>通过 Web2Vec 检测 Web 内容中的健康错误信息：基于 Web2Vec 的结构化、内容化和上下文感知的方法</title>
      <link>https://arxiv.org/abs/2407.07914</link>
      <description><![CDATA[arXiv:2407.07914v1 公告类型：新
摘要：近年来，我们目睹了大量由用户直接生成的在线内容的激增，几乎没有任何形式的外部控制，从而导致错误信息的传播。对这一问题的有效解决方案的搜索仍在进行中，涵盖了从意见垃圾邮件到假新闻检测的不同应用领域。尽管产生虚假信息可能带来严重风险，但最近研究的一个场景是在线传播健康信息。该领域的早期方法主要侧重于应用于网页内容的基于用户的研究。最近，已经为网页和社交媒体内容开发了自动化方法，特别是随着 COVID-19 大流行的到来。这些方法主要基于与机器学习相关的从在线内容中提取的手工特征。在这种情况下，我们专注于网页内容，其中仍有研究空间来研究基于结构、内容和上下文的特征以评估网页的可信度。因此，本研究旨在研究此类特征与深度学习模型相结合的有效性，从最近在网络钓鱼网页检测领域提出的网页嵌入式表示（即 Web2Vec）开始。]]></description>
      <guid>https://arxiv.org/abs/2407.07914</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>项目：改进基于消息传递的 GNN 的训练和评估，以实现 top-k 推荐</title>
      <link>https://arxiv.org/abs/2407.07912</link>
      <description><![CDATA[arXiv:2407.07912v1 公告类型：新
摘要：图神经网络 (GNN)，尤其是基于消息传递的模型，在 top-k 推荐任务中变得突出，由于它们能够有效地从更广泛的环境中聚合信息，其表现优于矩阵分解模型。尽管 GNN 是用基于排名的指标来评估的，例如 NDCG@k 和 Recall@k，但它们仍然主要使用代理损失进行训练，例如 BPR 损失。在这项工作中，我们探索了使用排名损失函数直接优化评估指标，这是 GNN 社区在协同过滤方面尚未广泛研究的领域。我们利用排名的平滑近似来促进 GNN 的端到端训练，并提出了一种针对排名损失函数量身定制的个性化 PageRank 负采样策略。此外，我们使用归纳的以用户为中心的协议扩展了对 top-k 推荐任务的 GNN 模型的评估，从而更准确地反映了现实世界的应用。我们提出的方法在四个数据集和四个最近的 GNN 架构中的表现明显优于标准 BPR 损失和更高级的损失，同时还表现出更快的训练速度。展示了排名损失函数在改进协同过滤任务的 GNN 训练方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.07912</guid>
      <pubDate>Fri, 12 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    </channel>
</rss>