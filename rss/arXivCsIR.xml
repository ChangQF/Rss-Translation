<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Mamba 提供可扩展且高效的个性化推荐</title>
      <link>https://arxiv.org/abs/2409.17165</link>
      <description><![CDATA[arXiv:2409.17165v1 公告类型：新
摘要：在此工作中，我们建议使用 Mamba 处理个性化推荐系统中的表格数据。我们提出了 \textit{FT-Mamba}（Feature Tokenizer\,$+$\,Mamba），这是一种新颖的混合模型，它在 FT-Transformer 架构中用 Mamba 层替换 Transformer 层，用于处理个性化推荐系统中的表格数据。\textit{Mamba 模型} 为 Transformers 提供了一种有效的替代方案，通过增强状态空间模型 (SSM) 的功能，将计算复杂度从二次降低到线性。FT-Mamba 旨在提高推荐系统的可扩展性和效率，同时保持性能。我们在三个数据集上将 FT-Mamba 与双塔架构中基于 Transformer 的传统模型进行了比较：Spotify 音乐推荐、H\&amp;M 时尚推荐和疫苗消息推荐。每个模型都基于 160,000 个用户-动作对进行训练，并使用精度 (P)、召回率 (R)、平均倒数排名 (MRR) 和命中率 (HR) 在多个截断值下测量性能。我们的结果表明，FT-Mamba 在计算效率方面优于基于 Transformer 的模型，同时在关键推荐指标方面保持或超过性能。通过利用 Mamba 层，FT-Mamba 为大规模个性化推荐系统提供了可扩展且有效的解决方案，展示了 Mamba 架构在提高效率和准确性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.17165</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VectorSearch：通过语义嵌入和优化搜索增强文档检索</title>
      <link>https://arxiv.org/abs/2409.17383</link>
      <description><![CDATA[arXiv:2409.17383v1 公告类型：新
摘要：传统检索方法对于评估文档相似性至关重要，但在捕捉语义细微差别方面却举步维艰。尽管潜在语义分析 (LSA) 和深度学习取得了进步，但由于高维性和语义差距，实现全面的语义理解和准确检索仍然具有挑战性。上述挑战需要新技术来有效地降低维度并缩小语义差距。为此，我们提出了 VectorSearch，它利用先进的算法、嵌入和索引技术进行精细检索。通过利用创新的多向量搜索操作和使用高级语言模型对搜索进行编码，我们的方法显着提高了检索准确性。在真实数据集上的实验表明，VectorSearch 的表现优于基线指标，证明了其对大规模检索任务的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.17383</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用去噪辅助任务增强推荐</title>
      <link>https://arxiv.org/abs/2409.17402</link>
      <description><![CDATA[arXiv:2409.17402v1 公告类型：新 
摘要：用户的历史交互序列在训练能够准确预测用户偏好的推荐系统中起着至关重要的作用。然而，由于用户行为的任意性，这些序列中噪声的存在对推荐系统中预测他们的下一步行动提出了挑战。为了解决这个问题，我们的动机是基于这样的观察：以相等的权重训练噪声序列和干净序列（没有噪声的序列）会影响模型的性能。我们提出了一种新颖的自监督辅助任务联合训练（ATJT）方法，旨在更准确地重新加权推荐系统中的噪声序列。具体来说，我们从用户的原始序列中策略性地选择子集并进行随机替换以生成人工替换的噪声序列。随后，我们对这些人为替换的噪声序列和原始序列进行联合训练。通过有效的重新加权，我们将噪声识别模型的训练结果纳入推荐模型。我们使用一致的基础模型在三个数据集上评估了我们的方法。实验结果证明了引入自监督辅助任务来增强基础模型性能的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.17402</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Big ANN：NeurIPS'23 竞赛结果</title>
      <link>https://arxiv.org/abs/2409.17424</link>
      <description><![CDATA[arXiv:2409.17424v1 公告类型：新
摘要：2023 年 NeurIPS 2023 上举办的 Big ANN Challenge 专注于推进索引数据结构和搜索算法的最新技术，用于近似最近邻 (ANN) 搜索的实际变体，以反映日益增长的工作负载的复杂性和多样性。与之前强调扩大传统 ANN 搜索 ~\cite{DBLP:conf/nips/SimhadriWADBBCH21} 的挑战不同，本次比赛针对的是过滤搜索、分布外数据、ANNS 的稀疏和流式变体。参与者开发并提交了创新解决方案，并在计算资源受限的新标准数据集上进行了评估。结果显示，搜索准确性和效率比行业标准基线有显著提高，学术和工业团队都做出了显著贡献。本文总结了竞赛轨迹、数据集、评估指标和表现最佳的提交的创新方法，深入了解了近似最近邻搜索领域的当前进展和未来方向。]]></description>
      <guid>https://arxiv.org/abs/2409.17424</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最小化推荐系统中的实时实验：通过用户模拟来评估偏好引出策略</title>
      <link>https://arxiv.org/abs/2409.17436</link>
      <description><![CDATA[arXiv:2409.17436v1 公告类型：新
摘要：推荐系统中的策略评估通常涉及使用对真实用户的实时实验进行 A/B 测试，以评估新策略对相关指标的影响。然而，这种“黄金标准”在周期时间、用户成本和潜在用户保留方面成本很高。在制定“入职”新用户的政策时，这些成本可能尤其成问题，因为入职只发生一次。在这项工作中，我们描述了一种用于增强（和减少）实时实验使用的模拟方法。我们说明了它在评估用于 YouTube 音乐平台新用户的“偏好引出”算法中的部署。通过开发反事实稳健的用户行为模型，以及将此类模型与生产基础设施相结合的模拟服务，我们能够以一种可靠地预测其在实时部署时在关键指标上的表现的方式测试新算法。我们描述了我们的领域、我们的模拟模型和平台、实验和部署的结果，并提出了进一步推进现实模拟所需的未来步骤，作为实时实验的有力补充。]]></description>
      <guid>https://arxiv.org/abs/2409.17436</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长线、短线还是双管齐下？产品搜索排名中行为特征回溯时间窗口的探索</title>
      <link>https://arxiv.org/abs/2409.17456</link>
      <description><![CDATA[arXiv:2409.17456v1 公告类型：新
摘要：客户购物行为特征是电子商务中产品搜索排名模型的核心。在本文中，我们研究了回顾时间窗口在历史（查询，产品）级别聚合这些特征时的影响。通过研究使用长和短时间窗口的利弊，我们提出了一种整合不同时间窗口的这些历史行为特征的新方法。特别是，我们解决了在排名模型中使用查询级垂直信号以有效聚合来自不同行为特征的所有信息的关键性。我们还使用 Walmart.com 上的实时产品搜索流量为所提出的方法提供了轶事证据。]]></description>
      <guid>https://arxiv.org/abs/2409.17456</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型实现更相关的产品搜索排名：一项实证研究</title>
      <link>https://arxiv.org/abs/2409.17460</link>
      <description><![CDATA[arXiv:2409.17460v1 公告类型：新
摘要：由于缺乏排名相关性的黄金标准，训练用于电子商务产品搜索排名的学习排名模型可能具有挑战性。在本文中，我们将排名相关性分解为基于内容和基于参与度的方面，并建议在模型训练中利用大型语言模型 (LLM) 进行标签和特征生成，主要目的是提高模型对基于内容的相关性的预测能力。此外，我们在 LLM 输出上引入了不同的 S 形变换，以极化标签中的相关性分数，增强模型平衡基于内容和基于参与度的相关性的能力，从而对高度相关的项目进行整体优先排序。还对提出的设计进行了全面的在线测试和离线评估。我们的工作揭示了将 LLM 集成到电子商务产品搜索排名模型训练中的高级策略，为更有效、更平衡、排名相关性更高的模型提供了途径。]]></description>
      <guid>https://arxiv.org/abs/2409.17460</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进最短木板：稳健推荐系统的漏洞感知对抗训练</title>
      <link>https://arxiv.org/abs/2409.17476</link>
      <description><![CDATA[arXiv:2409.17476v1 公告类型：新
摘要：推荐系统在缓解各个领域的信息过载方面发挥着关键作用。尽管如此，这些系统固有的开放性引入了漏洞，允许攻击者将虚假用户插入系统的训练数据中，以扭曲某些项目的曝光，这被称为中毒攻击。对抗性训练已成为推荐系统中针对此类中毒攻击的一种显着防御机制。现有的对抗性训练方法对所有用户施加相同幅度的扰动，以增强系统对攻击的鲁棒性。然而，在现实中，我们发现攻击通常只影响一小部分易受攻击的用户。这些不加区分的扰动使得很难在不降低不受影响用户的推荐质量的情况下平衡对易受攻击用户的有效保护。为了解决这个问题，我们的研究深入研究了用户漏洞。考虑到投毒攻击会污染训练数据，我们注意到推荐系统与用户训练数据的拟合程度越高，用户纳入攻击信息的可能性就越大，这表明用户存在​​漏洞。利用这些见解，我们引入了漏洞感知对抗训练 (VAT)，旨在防御推荐系统中的投毒攻击。VAT 采用一种新颖的漏洞感知函数，根据系统与用户的拟合程度来估计用户的漏洞。在此估计的指导下，VAT 对每个用户应用自适应幅度的扰动，不仅降低了攻击的成功率，而且还保持了推荐的质量，甚至可能提高推荐的质量。全面的实验证实了 VAT 对不同推荐模型和各种攻击的卓越防御能力。]]></description>
      <guid>https://arxiv.org/abs/2409.17476</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GraphRAG 增强结构化数据检索：足球数据案例研究</title>
      <link>https://arxiv.org/abs/2409.17580</link>
      <description><![CDATA[arXiv:2409.17580v1 公告类型：新
摘要：从大型复杂数据集中提取有意义的见解带来了重大挑战，特别是在确保检索到的信息的准确性和相关性方面。传统的数据检索方法（例如顺序搜索和基于索引的检索）在处理复杂且相互关联的数据结构时通常会失败，从而导致输出不完整或误导。为了克服这些限制，我们引入了 Structured-GraphRAG，这是一个多功能框架，旨在增强自然语言查询中跨结构化数据集的信息检索。Structured-GraphRAG 利用多个知识图谱，以结构化格式表示数据并捕获实体之间的复杂关系，从而实现更细致入微、更全面的信息检索。这种基于图的方法通过将响应置于结构化格式中来降低语言模型输出中出现错误的风险，从而提高结果的可靠性。我们通过将 Structured-GraphRAG 的性能与最近发布的使用传统检索增强生成的方法的性能进行比较来证明其有效性。我们的研究结果表明，Structured-GraphRAG 显著提高了查询处理效率并缩短了响应时间。虽然我们的案例研究侧重于足球数据，但该框架的设计具有广泛的适用性，为数据分析提供了强大的工具，并增强了跨各种结构化领域的语言模型应用。]]></description>
      <guid>https://arxiv.org/abs/2409.17580</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于新闻推荐的高效逐点对排序学习</title>
      <link>https://arxiv.org/abs/2409.17711</link>
      <description><![CDATA[arXiv:2409.17711v1 公告类型：新
摘要：新闻推荐是一项具有挑战性的任务，涉及基于每个用户的交互历史和偏好的个性化。最近的研究利用预训练语言模型 (PLM) 的强大功能，通过使用主要分为三类的推理方法直接对新闻项目进行排名：逐点、成对和列表学习排名。虽然逐点方法提供了线性推理复杂性，但它们无法捕获对排名任务更有效的项目之间的关键比较信息。相反，成对和列表方法擅长结合这些比较，但在实际中受到限制：成对方法要么计算成本高昂，要么缺乏理论保证，而列表方法在实践中往往表现不佳。在本文中，我们提出了一种基于 PLM 的新闻推荐的新框架，该框架以可扩展的方式集成了逐点相关性预测和成对比较。我们对我们的框架进行了严格的理论分析，建立了我们的方法保证提高性能的条件。大量实验表明，我们的方法在 MIND 和 Adressa 新闻推荐数据集上优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.17711</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Top-K 顺序推荐的自回归生成策略</title>
      <link>https://arxiv.org/abs/2409.17730</link>
      <description><![CDATA[arXiv:2409.17730v1 公告类型：新
摘要：现代顺序推荐系统的目标通常是根据下一项预测来制定的。在本文中，我们探讨了基于生成变压器的模型对 Top-K 顺序推荐任务的适用性，其目标是预测用户在“不久的将来”可能与之交互的项目。
我们探索常用的自回归生成策略，包括贪婪解码、波束搜索和温度采样，以评估它们对 Top-K 顺序推荐任务的性能。此外，我们提出了基于多序列生成、温度采样和后续聚合的新型互惠等级聚合 (RRA) 和相关性聚合 (RA) 生成策略。
在不同数据集上进行的实验为常用策略的适用性提供了宝贵的见解，并表明与广泛使用的 Top-K 预测方法和单序列自回归生成策略相比，建议的方法可以在更长的时间范围内提高性能。]]></description>
      <guid>https://arxiv.org/abs/2409.17730</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少量样本成对排序提示：一种有效的非参数检索模型</title>
      <link>https://arxiv.org/abs/2409.17745</link>
      <description><![CDATA[arXiv:2409.17745v1 公告类型：新
摘要：尽管监督排名模型具有有效的优点，但它通常涉及复杂的处理 - 通常是多个阶段的任务特定预训练和微调。这促使研究人员探索利用能够以零样本方式工作的大型语言模型 (LLM) 的更简单的管道。然而，由于零样本推理不使用查询对及其相关文档的训练集，因此其性能通常比在这些示例对上进行训练的监督模型更差。受现有发现的启发，即训练示例通常会提高零样本性能，在我们的工作中，我们探索这是否也适用于排名模型。更具体地说，给定一个查询和一对文档，通过从训练集中增加类似查询的偏好示例来改进偏好预测任务。我们提出的成对小样本排序器在域内（TREC DL）和域外（BEIR 子集）检索基准上都表现出比零样本基线一致的改进。我们的方法还实现了与监督模型相近的性能，而无需任何复杂的训练流程。]]></description>
      <guid>https://arxiv.org/abs/2409.17745</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人文和历史研究多利益相关方推荐系统中的价值识别：以 Monasterium.net 数字档案馆为例</title>
      <link>https://arxiv.org/abs/2409.17769</link>
      <description><![CDATA[arXiv:2409.17769v1 公告类型：新
摘要：尽管推荐系统具有增强文化记录发现的潜力，但在人文和历史研究中仍未得到充分利用。本文对 Monasterium.net（一个历史法律文件的数字档案）中可能受到推荐影响的多个利益相关者进行了初步的价值识别。具体来说，我们讨论了其利益相关者的不同价值观和目标，例如编辑、聚合器、平台所有者、研究人员、出版商和资助机构。这些对利益相关者群体潜在冲突价值观的深入洞察允许设计和调整推荐系统，以增强其对人文和历史研究的实用性。此外，我们的研究结果将支持与其他利益相关者进行更深入的接触，以改进给定领域推荐系统的价值模型和评估指标。我们的结论嵌入并适用于其他数字档案馆和更广泛的文化遗产背景。]]></description>
      <guid>https://arxiv.org/abs/2409.17769</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于冷启动和缺失模态场景推荐的多模态单分支嵌入网络</title>
      <link>https://arxiv.org/abs/2409.17864</link>
      <description><![CDATA[arXiv:2409.17864v1 公告类型：新
摘要：大多数推荐系统采用协同过滤 (CF) 并根据过去的集体互动提供推荐。因此，当几乎没有或没有交互时，CF 算法的性能会下降，这种情况称为冷启动。为了解决这个问题，以前的工作依赖于利用用户或项目的协作数据和辅助信息的模型。与多模态学习类似，这些模型旨在在共享嵌入空间中结合协作和内容表示。在这项工作中，我们提出了一种新的多模态推荐技术，依赖于多模态单分支嵌入网络进行推荐 (SiBraR)。利用权重共享，SiBraR 使用相同的单分支嵌入网络在不同模态上编码交互数据以及多模态辅助信息。这使得 SiBraR 在缺少模态的场景中有效，包括冷启动。我们对来自三个不同推荐领域（音乐、电影和电子商务）的大规模推荐数据集进行了广泛的实验，并提供多模态内容信息（音频、文本、图像、标签和交互），结果表明 SiBraR 在冷启动场景中的表现明显优于 CF 以及最先进的基于内容的 RS，在热启动场景中也具有竞争力。我们表明，SiBraR 的推荐在缺失模态场景中是准确的，并且该模型能够将不同的模态映射到共享嵌入空间的同一区域，从而缩小模态差距。]]></description>
      <guid>https://arxiv.org/abs/2409.17864</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用检索增强生成增强旅游推荐系统以实现可持续城市旅行</title>
      <link>https://arxiv.org/abs/2409.18003</link>
      <description><![CDATA[arXiv:2409.18003v1 公告类型：新
摘要：旅游推荐系统 (TRS) 传统上专注于提供个性化的旅行建议，通常优先考虑用户偏好而不考虑更广泛的可持续发展目标。随着平衡环境影响、当地社区利益和游客满意度的需求日益增加，将可持续性融入 TRS 已变得至关重要。本文提出了一种使用大型语言模型 (LLM) 和改进的检索增强生成 (RAG) 管道增强可持续城市旅行的 TRS 的新方法。我们通过在即时增强阶段结合基于城市受欢迎程度和季节性需求的可持续性指标来增强传统的 RAG 系统。这种修改称为可持续性增强重新排名 (SAR)，可确保系统的建议与可持续发展目标保持一致。使用流行的开源 LLM（例如 Llama-3.1-Instruct-8B 和 Mistral-Instruct-7B）进行的评估表明，SAR 增强方法在大多数指标上始终与基线（没有 SAR）相匹配或优于基线，凸显了将可持续性纳入 TRS 的好处。]]></description>
      <guid>https://arxiv.org/abs/2409.18003</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>