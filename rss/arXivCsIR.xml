<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 02 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>链接的数组树：大数据的恒定时间搜索结构</title>
      <link>https://arxiv.org/abs/2504.00828</link>
      <description><![CDATA[ARXIV：2504.00828V1公告类型：交叉 
摘要：随着数据量继续迅速增长，传统的搜索算法，例如红黑树和B+树，表现挑战的面部越来越大，尤其是在具有密集存储访问的大数据方案中。本文介绍了链接的阵列树（LAT），这是一种新颖的数据结构，旨在实现固定时间复杂性，用于搜索，插入和删除操作。 LAT利用稀疏，非移动的层次结构布局，该布局可实现直接访问路径，而无需重新平衡或数据移动。它的记忆力低下，避免了指针繁重的结构，使其非常适合大规模和密集的工作量。虽然未在并行或并发条件下进行特殊测试，但该结构的静态布局和非互干操作表明在这种环境中可能存在潜在的优势。
  本文首先介绍了LAT的结构和算法，然后详细分析了其搜索，插入和删除操作中的时间复杂性。最后，它在数据密集型和稀疏使用方案中呈现了实验结果，以评估LAT的实际性能。]]></description>
      <guid>https://arxiv.org/abs/2504.00828</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Cracksql：由大语言模型提供动力的混合SQL方言翻译系统</title>
      <link>https://arxiv.org/abs/2504.00882</link>
      <description><![CDATA[ARXIV：2504.00882V1公告类型：交叉 
摘要：方言翻译在实现异构数据库系统中无缝交互中起关键作用。但是，由于句法差异和微妙的语义变化，将不同方言之间的SQL查询转换（例如，从PostgreSQL到MySQL）仍然是一项艰巨的任务。现有的方法包括手动重写，基于规则的系统和大型语言模型（LLM）的技术通常涉及高维护工作（例如，制定自定义翻译规则）或产生不可靠的结果（例如，LLM生成非存在的功能），尤其是在处理复杂的查询时。在此演示中，我们提出了CrackSQL，这是第一个结合了规则和基于LLM的方法来克服这些局限性的混合SQL方言翻译系统。 CrackSQL利用LLMS的适应性来最大程度地减少手动干预，同时通过通过基于功能的查询处理来分割冗长的复杂SQL来提高翻译精度。为了进一步提高鲁棒性，它结合了一种新型的交叉拨号语法嵌入模型，以进行精确的语法比对，以及一种自适应的局部到全球翻译策略，可有效解决相互依存的查询操作。 CrackSQL支持三种翻译模式，并提供多个部署和访问选项，包括Web控制台接口，PYPI软件包和命令行提示]]></description>
      <guid>https://arxiv.org/abs/2504.00882</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>强大的推荐系统：调查和未来方向</title>
      <link>https://arxiv.org/abs/2309.02057</link>
      <description><![CDATA[ARXIV：2309.02057V2公告类型：替换 
摘要：随着信息的快速增长，推荐系统已成为提供个性化建议和克服信息超负荷的组成部分。但是，他们的实际部署经常遇到``肮脏&#39;&#39;数据，在这些数据中，噪音或恶意信息可能会导致异常建议。因此，关于改善推荐系统对此类肮脏数据的鲁棒性的研究已引起了人们的重大关注。这项调查对有关推荐系统的鲁棒性的最新工作进行了全面审查。我们首先提出一种分类法，以组织当前的技术来承受恶意攻击和自然噪音。然后，我们探索每个类别中最新的方法，包括欺诈者检测，对抗性训练，可证明的可靠训练，以防御恶意攻击，正则化，净化，自我监督的学习，以防御恶意攻击。此外，我们总结了评估指标和常用数据集评估鲁棒性。我们讨论各种建议方案的鲁棒性及其与其他属性（例如准确性，可解释性，隐私和公平性）的相互作用。最后，我们深入研究了这个新兴领域的开放问题和未来的研究方向。我们的目标是为读者提供对强大推荐系统的全面了解，并确定未来研究和开发的关键途径。为了促进正在进行的探索，我们通过相关研究保持了不断更新的GitHub存储库：https：//github.com/kaike-zhang/robust-recommender-system。]]></description>
      <guid>https://arxiv.org/abs/2309.02057</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建模和分析非项目页面对顺序下一项目预测的影响</title>
      <link>https://arxiv.org/abs/2408.15953</link>
      <description><![CDATA[arxiv：2408.15953v4公告类型：替换 
摘要：分析用户与项目之间的交互序列，顺序推荐模型可以学习用户意图并对下一个项目做出预测。在项目交互之后，大多数系统还与我们所谓的非项目页面进行交互：这些页面与特定项目无关，但仍然可以提供对用户兴趣的见解，例如，例如导航页面。因此，我们提出了一种将这些非项目页面纳入顺序推荐模型中的一般方法，以增强下一项目的预测。
  首先，我们证明了非项目页面对使用假设测试框架催眠片的影响，并提出了在顺序推荐模型中表示非项目页面的方法。随后，我们适应了流行的顺序推荐模型，以整合非项目页面，并使用不同的项目表示策略以及处理嘈杂数据的能力进行调查。为了显示模型集成非项目页面的一般功能，我们为受控设置创建一个合成数据集，然后评估从两个现实世界数据集中包含非项目页面的改进。
  我们的结果表明，非项目页面是一个宝贵的信息来源，将它们纳入顺序推荐模型中，可以在所有分析的模型体系结构中提高下一项目预测的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.15953</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>uqabench：评估用户嵌入以提示在个性化问题中提示LLM</title>
      <link>https://arxiv.org/abs/2502.19178</link>
      <description><![CDATA[ARXIV：2502.19178V2公告类型：替换 
摘要：大语言模型（LLMS）在自然语言处理（NLP）方面取得了显着成功。在诸如建议之类的实际情况下，随着用户越来越多地寻求个性化的体验，将用户互动历史记录纳入LLM的背景以增强个性化变得至关重要。但是，从实用的效用角度来看，当直接用作文本提示时，用户交互的长度和噪音会带来挑战。一个有希望的解决方案是将相互作用压缩成紧凑的嵌入，作为软提示，以帮助LLMS生成个性化响应。尽管这种方法带来了效率，但出现了一个关键的问题：用户嵌入可以充分捕获有价值的信息并提示LLM？为了解决这个问题，我们提出了\ Name，这是一种基准，旨在评估用户嵌入在提示LLMS个性化中的有效性。我们建立一个公平，标准化的评估过程，包括预培训，微调和评估阶段。为了彻底评估用户嵌入，我们设计了任务的三个维度：序列理解，行动预测和兴趣感知。这些评估任务涵盖了行业在传统推荐任务中的需求，例如提高预测准确性及其对基于LLM的方法的愿望，例如准确了解用户兴趣并增强用户体验。我们对对用户嵌入的各种最新方法进行了广泛的实验。此外，我们揭示了利用用户嵌入来提示LLM的规模定律。基准可在线提供。]]></description>
      <guid>https://arxiv.org/abs/2502.19178</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FSPONER：在特定于域的方案中命名的实体识别的弹药及时优化很少</title>
      <link>https://arxiv.org/abs/2407.08035</link>
      <description><![CDATA[ARXIV：2407.08035V2公告类型：替换 - 交叉 
摘要：大语言模型（LLMS）为命名实体识别（NER）任务提供了新的途径。与微调的LLM驱动提示方法相比，避免了训练需要，保存大量的计算资源并依赖于最小的注释数据。先前的研究与完全监督的基于BERT基于NER基准的基于BERT的微调方法相当。但是，以前的方法都没有研究在特定领域的情况下基于LLM的少量学习效率。为了解决这一差距，我们介绍了FSPONER，这是一种新颖的方法，用于优化少量提示，并评估其在域特异性NER数据集上的性能，重点关注工业制造和维护，同时使用多个LLMS-GPT-4-32K，GPT-4-32K，GPT-3.5-TORBO，LLAMA 2-CHAT和VICUNA。 FSPONER由三种基于随机采样，TF-IDF矢量和两者组合的三种少量选择方法组成。我们将这些方法与通用GPT-NER方法进行了比较，因为几个示例的数量增加并评估了它们针对微调的BERT和LLAMA 2-CHAT的最佳NER性能。在考虑到数据稀缺的现实世界中，带有TF-IDF的FSPONER超过微调模型的F1分数约为10％。]]></description>
      <guid>https://arxiv.org/abs/2407.08035</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ntsebench：视觉语言模型的认知推理基准</title>
      <link>https://arxiv.org/abs/2407.10380</link>
      <description><![CDATA[ARXIV：2407.10380V3公告类型：替换 - 交叉 
摘要：认知文本和视觉推理任务，包括难题，系列和类比，要求能够快速推理，破译和评估文字和空间上的模式。由于对大量人类策划数据的广泛培训，LLM和VLM在常识性推理任务中表现出色，但是仍然在需要更深入认知理解的更复杂的推理方面挣扎。我们介绍了NTSEBench，这是一个新的数据集，旨在评估大型模型的认知多模式推理和解决问题的技能。该数据集包含2728个多项选择问题，并伴随着总共4,642张图像，分为26种不同类型。这些问题来自印度的全国NTSE考试，并具有视觉和文本一般能力挑战的混合，旨在评估智力和批判性思维技能，而不是死记硬背。我们使用最先进的LLM和VLM在数据集上建立基准。为了促进开源模型和礼节模型之间的比较，我们提出了四种不同的建模策略，以处理数据集实例中的不同模式（文本和图像）。]]></description>
      <guid>https://arxiv.org/abs/2407.10380</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tobugraph：基于图形的知识检索，可增强llm性能超越抹布</title>
      <link>https://arxiv.org/abs/2412.05447</link>
      <description><![CDATA[ARXIV：2412.05447V2公告类型：替换 - 交叉 
摘要：检索功能（RAG）是增强LLM检索功能的领先和最广泛使用的技术之一，但在商业用例中仍然面临着重大限制。 RAG主要依赖于嵌入空间中的查询厨师的文本到文本相似性，并且无法捕获跨块的更深层次的语义关系，对块的策略非常敏感，并且容易幻觉。为了应对这些挑战，我们提出了Tobugraph，这是一个基于图的检索框架，该框架首先是从非结构化数据中构造知识图。使用LLMS，Tobugraph提取了数据之间结构化知识和不同的关系，超越了抹布的文本到文本相似性。检索是通过图形遍历来实现的，利用提取的关系和结构来增强检索精度，从而消除了在减少幻觉的同时进行块状配置的需求。我们演示了Tobugraph在Tobu中的有效性，这是个人记忆组织和检索中生产中的现实应用。我们使用真实用户数据的评估表明，Tobugraph在精确和召回方面都优于多个抹布实现，从而通过提高检索准确性可显着改善用户体验。]]></description>
      <guid>https://arxiv.org/abs/2412.05447</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多维检查道：为人类事实检查者设计AI辅助主张优先级</title>
      <link>https://arxiv.org/abs/2412.08185</link>
      <description><![CDATA[ARXIV：2412.08185V2公告类型：替换 - 交叉 
摘要：鉴于大量潜在的虚假主张在线流传，索赔优先级对于分配有限的人力资源至关重要。在这项研究中，我们将主张优先级视为信息检索（IR）任务：与多维IR相关性一样，影响了许多因素，这些因素会影响搜索导致用户认为相关的搜索，CheckWorthiness也具有多方面的，主观的，甚至是个人的，甚至具有许多因素，并且有许多因素影响了事实检查者的triage和Speepts宣称要遵守的选择。我们的研究调查了核对道理的多维性质和有效的工具支持，以帮助事实检查者优先考虑。从方法上讲，我们通过设计与混合方法评估相结合进行了研究。
  具体而言，我们开发了AI辅助主张的优先原型，作为探索事实检查者如何使用多维支票方面的因素来确定主张的优先级，同时探讨事实检查器的需求并探索设计空间以满足这些需求。有16名专业事实检查员参与了我们的研究，我们发现了一个分层的优先级策略事实检查器隐含地使用了他们的工作流程的一个毫无疑问的方面，并提出了可行的设计建议，以改善跨越多维检查的主张分类，并通过LLM集成量身定制此过程。]]></description>
      <guid>https://arxiv.org/abs/2412.08185</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GME：通过多模式LLMS改善通用多模式检索</title>
      <link>https://arxiv.org/abs/2412.16855</link>
      <description><![CDATA[ARXIV：2412.16855V2公告类型：替换 - 交叉 
摘要：通用多模式检索（UMR）的目的是使用统一模型在各种模式上进行搜索，其中查询和候选者可以由纯文本，图像或两者组合组合。以前的工作已尝试采用多模式大语模型（MLLM），以仅使用文本数据实现UMR。但是，我们的初步实验表明，更多样化的多模式训练数据可以进一步释放MLLM的潜力。尽管具有有效性，但现有的多模式训练数据在模式方面却高度不平衡，这激发了我们开发训练数据合成管道并构建一个大型，高质量的融合模式训练数据集。基于合成训练数据，我们开发了一般的多模式嵌入器（GME），这是一种基于MLLM的密度捕捞剂。此外，我们构建了一个全面的UMR基准（UMRB）来评估我们方法的有效性。实验结果表明，我们的方法在现有的UMR方法中实现了最先进的性能。最后，我们提供了模型缩放和培训策略的深入分析，并对模型和合成数据进行消融研究。]]></description>
      <guid>https://arxiv.org/abs/2412.16855</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多代理系统的知识意识迭代检索</title>
      <link>https://arxiv.org/abs/2503.13275</link>
      <description><![CDATA[ARXIV：2503.13275V2公告类型：替换 - 交叉 
摘要：我们介绍了一种新型的大型语言模型（LLM）驱动的代理框架，它通过利用动态发展的知识来迭代地完善查询并过滤上下文证据。该系统的一个定义特征是它将外部源与内部知识缓存的脱钩，该缓存逐渐更新以指导查询生成和证据选择。该设计减轻了偏置强化环路并实现动态，可追踪的搜索探索路径，从而优化了探索多种信息和通过自主代理决策保持准确性之间的权衡。我们的方法在广泛的开放域问题上进行了评估，以回答基准，包括镜像现实世界中的多个步骤任务，其中集成了来自多个来源的信息至关重要，尤其是考虑到缺乏明确推理或计划能力的LLM的脆弱性。结果表明，所提出的系统不仅胜过单步基线，无论任务难度如何，而且与常规的迭代检索方法相比，还通过基于循证的推理和提高效率来证明复杂任务中的明显优势。所提出的系统支持更新上下文的竞争和协作共享，从而实现多代理扩展。随着任务难度的增加，多代理配置的好处变得特别突出。收敛步骤的数量缩放了任务难度，表明具有成本效益的可伸缩性。]]></description>
      <guid>https://arxiv.org/abs/2503.13275</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>零拍商业API可以提供监管级临床文本的识别吗？</title>
      <link>https://arxiv.org/abs/2503.20794</link>
      <description><![CDATA[ARXIV：2503.20794V2公告类型：替换 - 交叉 
摘要：我们评估了四种领先的解决方案在非结构化医学文本中取消识别 -  Azure Health Data Services，AWS Classion Medical，OpenAI GPT -4O和John Snow Labs  - 在48个由医学专家注释的临床文档的地面真相数据集上。该分析在实体级别和令牌级别进行的分析表明，John Snow Labs的医学语言模型解决方案实现了最高的精度，在受保护的健康信息（PHI）检测中的F1得分为96％，胜过Azure（91％），AWS（83％），以及GPT-4O（79％）（79％）。约翰·斯诺（John Snow Labs）不仅是实现调节级准确性（超过人类专家的解决方案）的唯一解决方案，而且是最具成本效益的解决方案：与Azure和GPT-4O相比，它便宜80％以上，并且是唯一未经代币预测的解决方案。其固定成本的本地部署模型避免了基于云的服务的每次要求升级，这使其成为可扩展且经济的选择。]]></description>
      <guid>https://arxiv.org/abs/2503.20794</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Coranking：与大小排名代理商的合作排名</title>
      <link>https://arxiv.org/abs/2503.23427</link>
      <description><![CDATA[ARXIV：2503.23427V2公告类型：替换 - 交叉 
摘要：大型语言模型（LLMS）已证明了较高的列表等级性能。但是，它们的出色性能通常依赖于大规模参数（\ EG，GPT-4）和重复的滑动窗口过程，这引入了重大效率挑战。在本文中，我们提出了\ textbf {Coranking}，这是一个新颖的协作排名框架，结合了大小排名模型，以实现高效和有效排名。 Coranking首先采用小型的Reranker来预先所有候选段落，将相关的段落带入列表的顶部（\ EG，TOP-20）。然后，将LLM listwise Reranker应用于这些排名最高的段落而不是整个列表，从而大大提高了整体排名效率。尽管效率更高，但先前的研究表明，LLM listwise Reranker在输入段落的顺序上具有明显的位置偏见。直接从小书籍中直接喂养排名最高的段落，可能会导致LLM Listwise Reranker的次优性能。为了减轻这个问题，我们引入了通过加固学习训练的通道调节器，该通讯是从小型阅读者中重新定位的，以与LLM对通过订单的偏好保持一致。对三个IR基准测试的广泛实验表明，与仅使用LLM ListWise Reranker相比，Coranking显着提高了效率（将排名延迟降低约70 \％），而实现了更好的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.23427</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>