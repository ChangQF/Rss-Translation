<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>预训练和微调：推荐系统作为大型模型</title>
      <link>https://arxiv.org/abs/2501.14268</link>
      <description><![CDATA[arXiv:2501.14268v1 Announce Type: new 
摘要：现实中，用户在不同时期、地域、场景等有不同的兴趣，这种兴趣变化非常剧烈，推荐系统难以捕捉，现有的多领域学习可以缓解这一问题。然而，工业推荐系统结构复杂，数据量巨大，训练成本极高，很难修改工业推荐系统的结构并重新训练。为了填补这一空白，我们将推荐系统视为大型预训练模型并对其进行微调。我们首先提出了微调的信息瓶颈理论，并对推荐系统中的微调技术进行了解释。为了适应推荐，我们设计了一种信息感知自适应核（IAK）技术来微调预训练的推荐系统。具体而言，我们将微调定义为两个阶段：知识压缩和知识匹配，并让 IAK 的训练阶段明确地近似这两个阶段。我们提出的从微调本质出发的方法具有很好的可解释性。大量的在线和离线实验证明了我们提出的方法的优越性。此外，我们还分享了在大型在线平台上部署该方法时获得的独特而重要的经验教训。我们还介绍了推荐系统中微调技术的潜在问题和相应的解决方案。采用 IAK 技术的推荐器已在十亿级在线食品平台的主页上部署了几个月，并在我们的业务中产生了可观的利润。]]></description>
      <guid>https://arxiv.org/abs/2501.14268</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多模式顺序推荐的分层时间感知专家混合</title>
      <link>https://arxiv.org/abs/2501.14269</link>
      <description><![CDATA[arXiv:2501.14269v1 公告类型：新
摘要：多模态顺序推荐 (SR) 利用多模态数据来学习比传统 SR 方法更全面的项目特征和用户偏好，这已成为学术界和工业界的重要课题。现有方法通常侧重于通过自适应模态融合来增强多模态信息效用，以从用户-项目交互序列中捕捉用户​​偏好的演变。然而，它们中的大多数都忽略了丰富的多模态数据中包含的冗余兴趣无关信息所造成的干扰。此外，它们主要依赖于仅基于时间顺序的隐式时间信息，而忽略了可以更有效地表示动态用户兴趣的显式时间信号。为了解决这些限制，我们提出了一种分层时间感知专家混合多模态顺序推荐 (HM4SR)，具有两级专家混合 (MoE) 和多任务学习策略。具体来说，第一个 MoE 称为交互式 MoE，它从每个项目的多模态数据中提取与用户兴趣相关的重要信息。然后，第二个 MoE 称为时间 MoE，它通过在模态编码中引入来自时间戳的显式时间嵌入来捕获用户动态兴趣。为了进一步解决数据稀疏性问题，我们提出了三个辅助监督任务：用于项目特征理解的序列级类别预测 (CP)、用于将序列上下文与用户兴趣对齐的 ID 对比学习 (IDCL) 以及用于将时间信息与模态相结合以进行动态兴趣建模的占位符对比学习 (PCL)。在四个公共数据集上进行的大量实验验证了 HM4SR 与几种最先进的方法相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.14269</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多阶段大型语言模型流水线在相关性评估方面可以胜过 GPT-4o</title>
      <link>https://arxiv.org/abs/2501.14296</link>
      <description><![CDATA[arXiv:2501.14296v1 公告类型：新
摘要：搜索系统的有效性是使用相关性标签来评估的，这些标签表明文档对特定查询和用户的有用性。虽然从真实用户那里获取这些相关性标签是理想的，但扩展此类数据收集具有挑战性。因此，使用第三方注释器，但它们不一致的准确性需要昂贵的审计、培训和监控。我们提出了一种基于 LLM 的模块化分类管道，将相关性评估任务分为多个阶段，每个阶段使用不同大小和功能的不同提示和模型。应用于 TREC 深度学习 (TREC-DL)，我们的一种方法显示 Krippendorff 的 $\alpha$ 准确度比 OpenAI 的 GPT-4o mini 提高了 18.4%，同时保持每百万输入令牌约 0.2 美元的成本，为相关性评估提供了更高效、更可扩展的解决方案。这种方法超过了 GPT-4o (5 美元) 的基准性能。通过流水线方法，即使是 GPT-4o 旗舰模型的准确率（以 \alpha$ 衡量）也可以提高 9.7%。]]></description>
      <guid>https://arxiv.org/abs/2501.14296</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索链增强生成</title>
      <link>https://arxiv.org/abs/2501.14342</link>
      <description><![CDATA[arXiv:2501.14342v1 公告类型：新 
摘要：本文介绍了一种训练 o1 类 RAG 模型的方法，该方法在生成最终答案之前逐步检索和推理相关信息。传统的 RAG 方法通常在生成过程之前执行单个检索步骤，由于检索结果不完善，这限制了它们在处理复杂查询时的有效性。相比之下，我们提出的方法 CoRAG（检索链增强生成）允许模型根据不断发展的状态动态地重新制定查询。为了有效地训练 CoRAG，我们利用拒绝抽样来自动生成中间检索链，从而增强仅提供正确最终答案的现有 RAG 数据集。在测试时，我们提出了各种解码策略，通过控制采样检索链的长度和数量来扩展模型的测试时间计算。多个基准测试的实验结果验证了 CoRAG 的有效性，特别是在多跳问答任务中，我们观察到 EM 得分与强基线相比提高了 10 多分。在 KILT 基准测试中，CoRAG 在各种知识密集型任务中建立了新的最先进性能。此外，我们还提供了全面的分析来了解 CoRAG 的扩展行为，为旨在开发事实和扎实基础模型的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.14342</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用小波超图扩散处理推荐系统中的异质性</title>
      <link>https://arxiv.org/abs/2501.14399</link>
      <description><![CDATA[arXiv:2501.14399v1 公告类型：新
摘要：推荐系统在跨各个领域提供个性化用户体验方面发挥着关键作用。然而，捕捉异质性模式和用户-项目交互的多维性质带来了重大挑战。为了解决这个问题，我们引入了 FWHDNN（基于融合的小波超图扩散神经网络），这是一个创新框架，旨在推进基于超图的推荐任务中的表示学习。该模型包含三个关键组件：（1）一个利用异质性感知超图扩散的交叉差异关系编码器，以适应不同类标签的消息传递，（2）一个多级集群编码器，采用基于小波变换的超图神经网络层来捕获多尺度拓扑关系，以及（3）一种集成的多模态融合机制，通过中间和后期融合策略结合结构和文本信息。在真实数据集上进行的大量实验表明，FWHDNN 在捕捉用户和物品之间的高阶互连方面的准确性、稳健性和可扩展性超越了最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2501.14399</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新挖掘生成伪标记域自适应的难样本</title>
      <link>https://arxiv.org/abs/2501.14434</link>
      <description><![CDATA[arXiv:2501.14434v1 公告类型：新
摘要：密集检索器已显示出神经信息检索的巨大潜力；然而，它们表现出对域转移的鲁棒性不足，从而限制了它们在不同域的零样本设置中的有效性。最先进的域自适应技术是生成伪标记 (GPL)。GPL 使用合成查询生成和最初挖掘的硬负样本，将知识从交叉编码器提炼到目标域中的密集检索器。在本文中，我们分析了域自适应模型检索到的文档，发现这些文档与目标查询的相关性高于非域自适应模型的文档。然后，我们建议在知识提炼阶段刷新硬负样本索引以挖掘更好的硬负样本。我们的重新挖掘 R-GPL 方法提高了 13/14 BEIR 数据集和 9/12 LoTTe 数据集的排名性能。我们的贡献是（i）分析领域适应和非领域适应模型返回的硬负样本，以及（ii）在 LoTTE 和 BEIR 数据集中应用带有和不带有硬负样本重新挖掘的 GPL 训练。]]></description>
      <guid>https://arxiv.org/abs/2501.14434</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>领域适应密集检索器的可解释性分析</title>
      <link>https://arxiv.org/abs/2501.14459</link>
      <description><![CDATA[arXiv:2501.14459v1 公告类型：新
摘要：密集检索器已显示出神经信息检索的巨大潜力；然而，它们表现出对域转移缺乏鲁棒性，从而限制了它们在不同领域的零样本设置中的有效性。先前的研究已经调查了无监督域自适应技术，以使密集检索器适应目标域。然而，这些研究并没有专注于可解释性分析，以了解这种适应如何改变模型的行为。在本文中，我们建议利用集成梯度框架来开发一种可解释性方法，为密集检索器提供基于实例和基于排名的解释。为了生成这些解释，我们引入了一个揭示查询和文档归因的新基线。该方法用于分析领域适应对两个数据集中查询和文档标记输入归因的影响：金融问答数据集 (FIQA) 和生物医学信息检索数据集 (TREC-COVID)。我们的可视化结果显示，与非适应模型相比，适应领域的模型更注重领域术语，例如“对冲”、“黄金”、“日冕”和“疾病”等术语。这项研究探讨了无监督领域适应技术如何影响密集寻回犬适应新领域时的行为。此外，我们证明了积分梯度是解释和分析这些不透明神经模型内部机制的可行选择。]]></description>
      <guid>https://arxiv.org/abs/2501.14459</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>领域适应性表现的相关因素</title>
      <link>https://arxiv.org/abs/2501.14466</link>
      <description><![CDATA[arXiv:2501.14466v1 公告类型：新
摘要：密集检索器已显示出神经信息检索的巨大潜力；然而，它们缺乏对域转移的鲁棒性，限制了它们在不同域的零样本设置中的有效性。在本文中，我们着手分析导致密集检索器成功适应域的可能因素。我们在生成的查询到测试域和源域之间包括域相似性代理。此外，我们进行了一个案例研究，比较了两种强大的域适应技术。我们发现生成的查询类型分布是一个重要因素，生成与测试文档共享相似域的查询可以提高域适应方法的性能。这项研究进一步强调了域定制生成查询的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.14466</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>刑事上诉案件知识图谱构建：来自法国最高法院的见解</title>
      <link>https://arxiv.org/abs/2501.14579</link>
      <description><![CDATA[arXiv:2501.14579v1 公告类型：新
摘要：尽管人们的兴趣日益浓厚，但以结构化形式准确可靠地表示非结构化数据（例如法院判决）仍然是一项挑战。应用于语言建模的生成式人工智能的最新进展使得文本能够转换为知识图谱，为分析和建模开辟了新的机会。本文提出了一个从上诉到法国最高法院的知识图谱构建框架。该框架包括特定领域的本体和派生数据集，为结构化法律数据表示和分析提供了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.14579</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Chat3GPP：3GPP 文档的开源检索增强生成框架</title>
      <link>https://arxiv.org/abs/2501.13954</link>
      <description><![CDATA[arXiv:2501.13954v1 公告类型：交叉 
摘要：第三代合作伙伴计划 (3GPP) 文件是全球电信的关键标准，同时由于其内容庞大、复杂且更新频繁，给电信领域的工程师和研究人员带来了重大挑战。大型语言模型 (LLM) 在自然语言处理任务中表现出色，但其通用性限制了它们在电信等特定领域的有效性。为了解决这个问题，我们提出了 Chat3GPP，这是一个针对 3GPP 规范量身定制的开源检索增强生成 (RAG) 框架。通过结合分块策略、混合检索和高效索引方法，Chat3GPP 可以高效地检索相关信息并生成对用户查询的准确响应，而无需进行特定领域的微调，它既灵活又可扩展，为适应 3GPP 以外的其他技术标准提供了巨大的潜力。我们在两个电信专用数据集上评估了 Chat3GPP，并证明了其与现有方法相比的卓越性能，展示了其在协议生成和代码自动化等下游任务中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.13954</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zep：用于代理内存的时间知识图谱架构</title>
      <link>https://arxiv.org/abs/2501.13956</link>
      <description><![CDATA[arXiv:2501.13956v1 公告类型：交叉 
摘要：我们介绍了 Zep，一种用于 AI 代理的新型内存层服务，它在深度内存检索 (DMR) 基准测试中的表现优于当前最先进的系统 MemGPT。此外，Zep 在比 DMR 更全面、更具挑战性的评估中表现出色，更好地反映了现实世界的企业用例。虽然现有的基于大型语言模型 (LLM) 的代理的检索增强生成 (RAG) 框架仅限于静态文档检索，但企业应用程序需要从各种来源（包括正在进行的对话和业务数据）动态集成知识。Zep 通过其核心组件 Graphiti 解决了这一根本限制——这是一种时间感知知识图谱引擎，可动态合成非结构化对话数据和结构化业务数据，同时保持历史关系。在 MemGPT 团队建立为其主要评估指标的 DMR 基准测试中，Zep 表现出色（94.8% vs 93.4%）。除了 DMR，Zep 的功能还通过更具挑战性的 LongMemEval 基准得到进一步验证，该基准通过复杂的时间推理任务更好地反映了企业用例。在这次评估中，Zep 取得了显著的成果，准确率提高了 18.5%，同时与基线实现相比，响应延迟减少了 90%。这些结果在跨会话信息合成和长期上下文维护等企业关键任务中尤为明显，证明了 Zep 在实际应用中部署的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.13956</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>定制大型语言模型的图形检索增强生成综述</title>
      <link>https://arxiv.org/abs/2501.13958</link>
      <description><![CDATA[arXiv:2501.13958v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 在广泛的任务中表现出了卓越的能力，但由于需要深厚的专业知识，它们在专业领域的应用仍然具有挑战性。检索增强生成 (RAG) 已成为一种有前途的解决方案，通过无缝集成外部知识库，可以在推理过程中实时访问特定领域的专业知识，为专业领域定制 LLM。尽管具有潜力，但基于平面文本检索的传统 RAG 系统面临三个关键挑战：(i) 专业环境中的复杂查询理解，(ii) 跨分布式源的知识集成困难，以及 (iii) 大规模系统效率瓶颈。本调查对基于图的检索增强生成 (GraphRAG) 进行了系统分析，这是一种彻底改变特定领域 LLM 应用的新范式。 GraphRAG 通过三项关键创新解决了传统 RAG 的局限性：（i）图形结构知识表示，明确捕获实体关系和域层次结构，（ii）高效的基于图形的检索技术，能够通过多跳推理能力实现保留上下文的知识检索，以及（iii）结构感知知识集成算法，利用检索到的知识准确、合乎逻辑地生成 LLM。在本次调查中，我们系统地分析了 GraphRAG 的技术基础，并研究了各个专业领域的当前实现情况，确定了关键的技术挑战和有前景的研究方向。社区在 \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} 中收集了 GraphRAG 的所有相关资源，包括研究论文、开源数据和项目。]]></description>
      <guid>https://arxiv.org/abs/2501.13958</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于学习的前提检索器协助数学形式化</title>
      <link>https://arxiv.org/abs/2501.13959</link>
      <description><![CDATA[arXiv:2501.13959v1 公告类型：交叉 
摘要：前提选择是数学形式化中至关重要但又具有挑战性的一步，尤其是对于经验有限的用户而言。由于缺乏可用的形式化项目，利用语言模型的现有方法通常会受到数据稀缺的影响。在这项工作中，我们引入了一种训练前提检索器的创新方法，以支持数学的形式化。我们的方法采用 BERT 模型将证明状态和前提嵌入到共享潜在空间中。检索模型在对比学习框架内进行训练，并结合了领域特定的标记器以及细粒度的相似度计算方法。实验结果表明，与现有基线相比，我们的模型具有很强的竞争力，在需要更少计算资源的同时实现了强大的性能。通过集成重新排名模块，性能得到进一步增强。为了简化形式化过程，我们将发布一个搜索引擎，使用户能够使用证明状态直接查询 Mathlib 定理，从而显着提高可访问性和效率。代码可在https://github.com/ruc-ai4math/Premise-Retrieval获得。]]></description>
      <guid>https://arxiv.org/abs/2501.13959</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CAPRAG：使用向量和图形检索增强生成的客户服务和自动报告大型语言模型解决方案</title>
      <link>https://arxiv.org/abs/2501.13993</link>
      <description><![CDATA[arXiv:2501.13993v1 公告类型：交叉 
摘要：银行业推出新功能和服务时，客户往往会不知所措，这为银行创造了一个机会，通过由大型语言模型 (LLM) 驱动的金融聊天机器人来提升用户体验。我们启动了一个 AI 代理，旨在为客户提供有关银行服务的相关信息和年度报告中的见解。我们提出了一种混合客户分析管道检索增强生成 (CAPRAG)，可以有效解决基于关系和上下文的查询，从而提高客户在数字银行领域的参与度。为了实现这一点，我们开发了一个处理管道来细化文本数据，我们在两个主要框架中使用了它：Vector RAG 和 Graph RAG。这种双重方法使我们能够用处理后的数据填充矢量和图形数据库，以实现高效检索。Cypher 查询组件用于有效地查询图形数据库。当用户提交查询时，它首先由查询扩展模块扩展，然后被路由以从混合知识库 (KB) 构建最终查询。然后，将最终查询发送到开源 LLM 以生成响应。总体而言，我们专为国际银行设计的创新解决方案可在日益复杂的数字环境中为银行客户提供服务，从而提高信息的清晰度和可访问性。]]></description>
      <guid>https://arxiv.org/abs/2501.13993</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedSlice：针对安全临床记录分段的精细调整大型语言模型</title>
      <link>https://arxiv.org/abs/2501.14105</link>
      <description><![CDATA[arXiv:2501.14105v1 公告类型：交叉 
摘要：从临床记录中提取部分对于下游分析至关重要，但由于格式多变且手动分段劳动密集，因此具有挑战性。虽然专有的大型语言模型 (LLM) 已显示出良好的前景，但隐私问题限制了它们的可访问性。本研究使用开源 LLM 开发了自动注释分段的流程，重点关注三个部分：现病史、间隔史以及评估和计划。我们对三个开源 LLM 进行了微调，以使用 487 个进度记录的精选数据集提取部分，并将结果与​​专有模型 (GPT-4o、GPT-4o mini) 进行比较。通过精度、召回率和 F1 分数评估内部和外部有效性。微调后的 Llama 3.1 8B 优于 GPT-4o (F1=0.92)。在外部有效性测试集上，性能仍然很高 (F1= 0.85)。经过微调的开源 LLM 可以在临床记录部分超越专有模型，在成本、性能和可访问性方面具有优势。]]></description>
      <guid>https://arxiv.org/abs/2501.14105</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>