<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 25 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CUPID：一对一社交发现平台的实时基于会话的互惠推荐系统</title>
      <link>https://arxiv.org/abs/2410.18087</link>
      <description><![CDATA[arXiv:2410.18087v1 公告类型：新
摘要：本研究介绍了 CUPID，这是一种基于会话的互惠推荐系统的新方法，专为实时一对一社交发现平台而设计。在这样的平台中，低延迟对于增强用户体验至关重要。然而，由于需要为每个推荐过程建模连续的用户行为，传统的基于会话的方法难以应对高延迟。此外，考虑到平台的互惠性质，用户彼此充当项目，使用传统方法在大型数据集上训练推荐模型在计算上是无法承受的。为了应对这些挑战，CUPID 将耗时的用户会话建模与实时用户匹配过程分离，以减少推理时间。此外，CUPID 采用了两阶段训练策略，将嵌入层和预测层的训练分开，通过将顺序模型推理的数量减少几百倍，显著减轻了计算负担。在大规模 Azar 数据集上进行的大量实验证明了 CUPID 在实际生产环境中的有效性。值得注意的是，与非异步系统相比，CUPID 将响应延迟降低了 76% 以上，同时显著提高了用户参与度。]]></description>
      <guid>https://arxiv.org/abs/2410.18087</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于动态实体替换与屏蔽策略的肝癌知识图谱构建RoBERTa-BiLSTM-CRF模型</title>
      <link>https://arxiv.org/abs/2410.18090</link>
      <description><![CDATA[arXiv:2410.18090v1 公告类型：新
摘要：背景：肝癌是我国第五大常见恶性肿瘤，也是第二大致命肿瘤。早期诊断至关重要，医生必须尽早发现患者是否患有肝癌。然而，诊断过程复杂且要求高。医生必须分析广泛的患者数据，包括身体状况、症状、病史以及各种检查和测试的结果，这些数据以结构化和非结构化的医疗格式记录。这给医疗保健专业人员带来了巨大的工作量。因此，整合知识图谱技术开发肝癌知识图谱辅助诊断和治疗系统符合国家对智能医疗的努力。这样的系统有望减轻医生在诊断和治疗肝癌方面面临的挑战。
方法：本文解决了构建肝细胞癌诊断知识图谱的主要挑战，例如公共数据源和真实电子病历之间的差异，而两者的有效整合仍然是一个关键问题。知识图谱构建过程包括概念层设计、数据预处理、实体识别、实体规范化、知识融合和图谱可视化六个步骤。提出了一种新的动态实体替换与屏蔽策略（DERM）用于命名实体识别。
结果：建立了肝癌知识图谱，包括疾病、症状、体质等7个实体类型，包含1495个实体。模型的识别准确率为93.23%，召回率为94.69%，F1得分为93.96%。]]></description>
      <guid>https://arxiv.org/abs/2410.18090</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$M^3EL$：用于多模态实体链接的多任务多主题数据集</title>
      <link>https://arxiv.org/abs/2410.18096</link>
      <description><![CDATA[arXiv:2410.18096v1 公告类型：新
摘要：多模态实体链接（MEL）是各种下游任务的基本组成部分。然而，现有的MEL数据集规模小、主题类型稀缺、任务覆盖范围有限，无法有效增强多模态模型的实体链接能力。为了解决这些障碍，我们提出了一个数据集构建流程，并发布了MEL的大规模数据集$M^3EL$。$M^3EL$包括79,625个实例，涵盖9种不同的多模态任务和5种不同的主题。此外，为了进一步提高模型对多模态任务的适应性，我们提出了一种模态增强训练策略。利用$M^3EL$作为语料，基于$\textit{CLIP} (\textit{ViT}-\textit{B}-\textit{32})$训练$\textit{CLIP}_{\textit{ND}}$模型，并与现有的多模态基线进行对比分析。实验结果表明，现有模型的表现远低于预期（ACC为49.4%-75.8%），分析得出数据集规模小、模态任务覆盖不足、主题多样性有限导致多模态模型泛化能力差。我们的数据集有效地解决了这些问题，使用$M^3EL$微调的$\textit{CLIP}_{\textit{ND}}$模型准确率有显著提升，在各项任务上平均提升了9.3%-25%。我们的数据集可在https://anonymous.4open.science/r/M3EL获取。]]></description>
      <guid>https://arxiv.org/abs/2410.18096</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RRADistill：提炼法学硕士的段落排序能力，用于搜索引擎中长尾查询的文档重新排序</title>
      <link>https://arxiv.org/abs/2410.18097</link>
      <description><![CDATA[arXiv:2410.18097v1 公告类型：新
摘要：大型语言模型 (LLM) 擅长理解查询和文档之间的语义关系，即使是冗长而复杂的长尾查询也是如此。由于用户参与度低且反馈有限，这些查询对于基于反馈的排名具有挑战性，因此 LLM 的排名能力非常有价值。然而，LLM 的规模大且推理速度慢，因此需要开发更小、更高效的模型 (sLLM)。最近，将排名标签生成集成到蒸馏技术中变得至关重要，但现有方法未充分利用 LLM 的功能并且很麻烦。我们的研究 RRADistill：重新排名能力蒸馏，为编码器和解码器模型提出了一种高效的标签生成流程和新颖的 sLLM 训练方法。我们引入了一种基于编码器的方法，使用术语控制层来捕获术语匹配信号，以及一种基于解码器的模型，该模型带有排名层以增强理解。在韩国搜索平台上进行的 A/B 测试验证了我们的方法在提高长尾查询重新排名方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.18097</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用实体关系图和模型感知对比采样提高文档检索的嵌入准确度</title>
      <link>https://arxiv.org/abs/2410.18105</link>
      <description><![CDATA[arXiv:2410.18105v1 公告类型：新
摘要：在本文中，我们介绍了 APEX-Embedding-7B（高级认知提取处理），这是一个 70 亿参数解码器专用文本特征提取模型，专为文档检索增强生成 (RAG) 任务而设计。我们的方法采用了两种训练技术，可显著改善事实焦点：（1）使用结构化实体关系图作为训练数据输入进行收敛前中断微调：旨在转移模型的注意力并产生对事实内容而不是语义风格的偏见 - 尽管没有直接接受过训练，但这可以提高纯文本的性能；（2）模型感知对比采样，创建一个平衡且均匀分布的硬负例和软负例整理图，直接由基础模型的能力决定。这种组合方法取得了显著的改进，增强了纯文本查询/文档对检索，在我们的评估中实现了 90.86% 的绝对 rank@1 准确率（与下一个领先模型相比提高了 6.26%），并且与纯文本相比，查询和文档文本的训练数据输入上下文大小平均减少了 37.71%。根据我们的评估，我们的模型为较长上下文文档检索任务的文本特征提取建立了新的最先进标准。]]></description>
      <guid>https://arxiv.org/abs/2410.18105</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型推荐模型的数据效率</title>
      <link>https://arxiv.org/abs/2410.18111</link>
      <description><![CDATA[arXiv:2410.18111v1 公告类型：新
摘要：大型推荐模型 (LRM) 是价值数十亿美元的在线广告行业的基础，在过渡到持续在线训练以适应快速变化的用户行为之前，需要处理数千亿个示例的海量数据集。海量数据直接影响计算成本和评估新方法的速度（研发速度）。
本文介绍了可操作的原则和高级框架，以指导从业者优化训练数据要求。这些策略已成功部署在 Google 最大的广告 CTR 预测模型中，并且广泛适用于 LRM 之外。我们概述了数据收敛的概念，描述了加速这种收敛的方法，最后详细说明了如何最佳地平衡训练数据量和模型大小。]]></description>
      <guid>https://arxiv.org/abs/2410.18111</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>昨日新闻：对错误信息检测模型的多维分布外泛化进行基准测试</title>
      <link>https://arxiv.org/abs/2410.18122</link>
      <description><![CDATA[arXiv:2410.18122v1 公告类型：新
摘要：本文介绍了 misinfo-general，这是一个用于评估错误信息模型执行分布外泛化能力的基准数据集。错误信息变化迅速，比主持人大规模注释的速度要快得多，导致训练和推理数据分布之间发生转变。因此，错误信息模型需要能够执行分布外泛化，这是现有数据集中研究不足的问题。我们确定了 6 个泛化轴——时间、事件、主题、出版商、政治偏见、错误信息类型——并为每个轴设计评估程序。我们还分析了一些基线模型，强调这些模型如何未能满足重要的要求。]]></description>
      <guid>https://arxiv.org/abs/2410.18122</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接破碎的主题：将神经主题模型与标签和作者对齐</title>
      <link>https://arxiv.org/abs/2410.18140</link>
      <description><![CDATA[arXiv:2410.18140v1 公告类型：新
摘要：主题模型是一种从大型文档集合中提取语义信息的流行方法。然而，最近的研究表明，这些模型生成的主题通常与人类意图不太吻合。虽然标签和作者信息等元数据可用，但尚未有效地纳入神经主题模型。为了解决这一差距，我们引入了 FANToM，这是一种将神经主题模型与标签和作者信息对齐的新方法。FANToM 允许在可用时包含这些元数据，为每个主题生成可解释的主题和作者分布。通过学习标签、主题和作者之间的对齐，我们的方法比传统主题模型表现出更大的表现力。实验结果表明，FANToM 在主题质量和对齐方面都比现有模型有所改进。此外，它还可以识别作者的兴趣和相似之处。]]></description>
      <guid>https://arxiv.org/abs/2410.18140</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SmartRAG：从环境反馈中联合学习与 RAG 相关的任务</title>
      <link>https://arxiv.org/abs/2410.18141</link>
      <description><![CDATA[arXiv:2410.18141v1 公告类型：新
摘要：RAG 系统由多个模块组成，以便协同工作。但是，这些模块通常是单独训练的。我们认为，像 RAG 这样包含多个模块的系统应该联合优化以实现最佳性能。为了证明这一点，我们设计了一个名为 \textbf{SmartRAG} 的特定管道，其中包括一个策略网络和一个检索器。策略网络可以充当 1) 决定何时检索的决策者，2) 生成最适合检索器的查询的查询重写器，以及 3) 产生有/无观察的最终响应的答案生成器。然后，我们建议使用强化学习算法联合优化整个系统，奖励旨在鼓励系统以最小的检索成本实现最佳性能。当联合优化时，所有模块都可以知道其他模块是如何工作的，从而找到作为一个完整系统协同工作的最佳方式。实证结果表明，联合优化的 SmartRAG 可以比单独优化的 SmartRAG 实现更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.18141</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NexusIndex：集成高级向量索引和多模型嵌入，实现强大的假新闻检测</title>
      <link>https://arxiv.org/abs/2410.18294</link>
      <description><![CDATA[arXiv:2410.18294v1 公告类型：新
摘要：数字平台上虚假新闻的泛滥凸显了对强大且可扩展的检测机制的需求。由于可扩展性和准确性的限制，传统方法往往无法处理大型和多样化的数据集。在本文中，我们提出了 NexusIndex，这是一种新颖的框架和模型，它通过集成高级语言模型、创新的 FAISSNexusIndex 层和注意力机制来增强虚假新闻检测。我们的方法利用多模型嵌入来捕获丰富的上下文和语义细微差别，显着提高文本解释和分类准确性。通过将文章转换为高维嵌入并有效地对其进行索引，NexusIndex 有助于在大量新闻文章中快速进行相似性搜索。FAISSNexusIndex 层进一步优化了此过程，实现了实时检测并增强了系统的可扩展性和性能。我们的实验结果表明，NexusIndex 在跨不同数据集的效率和准确性方面优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.18294</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索排名法学硕士：信息检索中的机械可解释性</title>
      <link>https://arxiv.org/abs/2410.18527</link>
      <description><![CDATA[arXiv:2410.18527v1 公告类型：新
摘要：Transformer 网络，尤其是那些性能与 GPT 模型相当的网络，以其强大的特征提取能力而闻名。然而，这些特征与人为设计特征的性质和相关性仍不清楚。在这项研究中，我们深入研究了最先进的基于微调的段落重新排序 Transformer 网络的机制。
我们的方法涉及对排名 LLM 中的神经元进行基于探测的逐层分析，以识别网络激活中已知的人为设计和语义特征的单个或组。我们探索了广泛的特征，包括词汇、文档结构、查询文档交互、高级语义、基于交互和 LLM 特定的特征，以更深入地了解推动 LLM 中排名决策的底层机制。
我们的结果揭示了一组在 LLM 激活中突出表现的特征，以及其他明显缺失的特征。此外，我们观察到 LLM 在处理低相关性查询和高相关性查询时以及遇到分布外查询和文档集时的不同行为。通过在激活中检查这些特性，我们旨在提高 LLM 在排名任务中的可解释性和性能。我们的研究结果为开发更有效、更透明的排名模型提供了宝贵的见解，对更广泛的信息检索社区具有重要意义。复制我们的研究结果所需的所有脚本和代码都已提供。]]></description>
      <guid>https://arxiv.org/abs/2410.18527</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于智能 ETL 和 LLM 的内容分类：欧洲智能旅游工具观测站的经验</title>
      <link>https://arxiv.org/abs/2410.18641</link>
      <description><![CDATA[arXiv:2410.18641v1 公告类型：新
摘要：目的：我们的研究项目重点是通过整合和分类 STT 来改进在线欧洲智能旅游工具 (STT) 观测站的内容更新。分类基于其分类法，它有助于最终用户的搜索过程。使用智能 ETL（提取、转换和加载）过程是这项工作的核心，其中 \emph{Smart} 表示使用人工智能 (AI)。
方法：描述 STT 的内容来自 PDF 目录，其中 PDF 抓取技术提取二维码、图像、链接和文本信息。删除目录之间的重复 STT，并使用大型语言模型 (LLM) 根据其文本信息对剩余的 STT 进行分类。最后，将数据转换为符合都柏林核心元数据结构（观测站的元数据结构），该结构因其广泛接受和灵活性而被选中。
结果：将 STT 导入天文台的智能 ETL 流程将 PDF 抓取技术与 LLM 相结合，用于基于文本内容的分类。我们的初步结果证明了 LLM 在基于文本内容的分类方面的潜力。
结论：所提出方法的可行性是朝着高效的基于内容的分类迈出的一步，不仅在智能旅游领域，而且适用于其他领域。未来的工作将主要集中在改进这一分类过程上。]]></description>
      <guid>https://arxiv.org/abs/2410.18641</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于语言的用户配置文件的端到端推荐训练</title>
      <link>https://arxiv.org/abs/2410.18870</link>
      <description><![CDATA[arXiv:2410.18870v1 公告类型：新
摘要：许多在线平台维护用户配置文件以实现个性化。不幸的是，这些配置文件通常不可解释或不易被用户修改。为了弥补这一缺点，我们探索了基于自然语言的用户配置文件，因为它们有望提高推荐系统的透明度和可审查性。虽然现有研究表明，标准 LLM 的基于语言的配置文件可能有效，但这种通用 LLM 不太可能是这项任务的最佳选择。在本文中，我们介绍了 LangPTune，这是第一个端到端学习方法，用于训练 LLM 以生成优化推荐效果的基于语言的用户配置文件。通过对各种训练配置和基准测试中的 LangPTune 进行全面评估，我们证明我们的方法明显优于现有的基于配置文件的方法。此外，它的性能水平接近最先进的、不太透明的推荐系统，为传统系统提供了一种强大且可解释的替代方案。最后，我们通过涉及众包工作者和基于 GPT-4 的评估的用户研究来验证这些基于语言的用户资料的相对可解释性。LangPTune 的实现可以在 https://github.com/ZhaolinGao/LangPTune 找到。]]></description>
      <guid>https://arxiv.org/abs/2410.18870</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用编程知识图谱进行上下文增强代码生成</title>
      <link>https://arxiv.org/abs/2410.18251</link>
      <description><![CDATA[arXiv:2410.18251v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 和代码 LLM (CLLM) 显著改进了代码生成，但它们在处理具有挑战性和复杂性的问题时经常面临困难。检索增强生成 (RAG) 通过在推理时检索和集成外部知识来解决此问题。然而，检索模型通常无法找到最相关的上下文，而上下文容量有限的生成模型在给定不相关数据时可能会产生幻觉。我们提出了一个新颖的框架，该框架利用编程知识图 (PKG) 来语义地表示和检索代码。这种方法通过关注最相关的段来实现细粒度的代码检索，同时通过树修剪技术减少不相关的上下文。PKG 与重新排名机制相结合，通过选择性地集成非 RAG 解决方案来减少更多的幻觉。我们提出了两种基于 PKG 的检索方法（块级和功能级），以优化上下文粒度。在 HumanEval 和 MBPP 基准测试中的评估表明，我们的方法可将 pass@1 准确率提高多达 20%，并且在 MBPP 上的表现比最先进的模型高出多达 34%。我们的贡献包括基于 PKG 的检索、用于提高检索精度的树修剪、用于稳健解决方案选择的重新排序方法以及用于使用相关注释和文档字符串自动扩充代码的填充中间 (FIM) 增强器模块。]]></description>
      <guid>https://arxiv.org/abs/2410.18251</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>链接、合成、检索：用于零样本信息检索的通用文档链接</title>
      <link>https://arxiv.org/abs/2410.18385</link>
      <description><![CDATA[arXiv:2410.18385v1 公告类型：交叉 
摘要：尽管信息检索 (IR) 取得了最近的进展，但零样本 IR 仍然是一项重大挑战，尤其是在处理新领域、语言和缺乏现有用户历史查询流量的新发布用例时。对于这种情况，通常使用查询增强，然后在与合成查询配对的文档数据上对预训练模型进行微调。在这项工作中，我们提出了一种新颖的通用文档链接 (UDL) 算法，该算法链接相似的文档以增强跨具有不同特征的多个数据集的合成查询生成。UDL 利用熵来选择相似性模型，并利用命名实体识别 (NER) 使用相似性分数对文档进行链接决策。我们的实证研究证明了 UDL 在不同数据集和 IR 模型中的有效性和通用性，在零样本情况下超越了最先进的方法。为可重复性而开发的代码包含在 https://github.com/eoduself/UDL 中]]></description>
      <guid>https://arxiv.org/abs/2410.18385</guid>
      <pubDate>Fri, 25 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>