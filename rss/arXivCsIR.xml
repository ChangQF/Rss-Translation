<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>推荐系统的最佳数据集大小：通过下采样评估算法的性能</title>
      <link>https://arxiv.org/abs/2502.08845</link>
      <description><![CDATA[ARXIV：2502.08845V1公告类型：新 
摘要：本论文研究数据集的减排，作为在保持竞争性能的同时优化推荐系统中能效率的一种策略。随着数据集尺寸的增加带来了计算和环境挑战，本研究探讨了绿色推荐系统中能效与建议质量之间的权衡，旨在减少环境影响。通过对七个数据集，12种算法和两个核心修剪的两种降采样方法，该研究表明运行时和碳排放量显着降低。例如，与整个数据集相比，30％的倒数采样部分可以将运行时减少52％，从而在培训单个数据集的单个算法时，导致碳排放量最高为51.02 kgco2e。分析表明，不同下采样部分下的算法性能取决于数据集特性，算法复杂性和特定的下采样配置（方案依赖性）。与表现较高的算法相比，一些算法显示出较低的NDCG@10分数，对训练数据的量显示较低的敏感性，从而在下层下采样部分具有更大的效率。平均而言，这些算法仅使用50％的训练集保留了81％的全尺寸性能。在某些下采样配置中，在确保测试集尺寸的同时逐渐包含了更多用户，他们甚至比使用完整数据集的NDCG@10分数更高。这些发现凸显了平衡可持续性和有效性的可行性，为设计节能推荐系统和促进可持续的AI实践提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2502.08845</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知的位置编码用于顺序建议</title>
      <link>https://arxiv.org/abs/2502.09027</link>
      <description><![CDATA[ARXIV：2502.09027V1公告类型：新 
摘要：编码用户活动以预测下一个动作的顺序推荐（SR）已成为开发商业个性化推荐系统的广泛采用的策略。现代SR模型的关键组成部分是注意机制，它综合了用户的历史活动。该机制通常是订单不变的，通常依赖于编码的位置（PE）。传统的SR模型只是将可学习的向量分配给每个位置，与传统推荐模型相比，仅带来适度的收益。此外，已经对量身定制的用于顺序建议的位置进行了有限的研究，在满足其独特要求方面留下了很大的差距。为了弥合这一差距，我们提出了一种新颖的上下文感知的位置编码方法，用于顺序推荐，缩写为斗篷。据我们所知，CAPE是专门为顺序推荐设计的第一种PE方法。在基准SR数据集上进行的综合实验表明，CAPE始终增强多个主流骨干模型，并在小型和大型模型大小上实现最先进的性能。此外，我们在现实世界的商业平台上部署了开普人，清楚地展示了我们方法的有效性。我们的源代码可在https://github.com/yjdy/cape上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.09027</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标准感知图形过滤：非常快而准确的多标准建议</title>
      <link>https://arxiv.org/abs/2502.09046</link>
      <description><![CDATA[ARXIV：2502.09046V1公告类型：新 
摘要：利用MC评级信息进行推荐的多标准（MC）推荐系统在各种电子商务领域都越来越普遍。但是，与单标准相比，使用基于培训的协作过滤的MC建议，需要考虑多个评级，通常在实现最先进的性能以及可扩展的模型培训方面构成实际挑战。为了解决此问题，我们提出了一种无训练的MC建议方法CA-GF，该方法是基于意识到标准的图形过滤而构建的，以有效而准确的MC建议。具体来说，首先，我们使用MC用户扩展图构建了项目项目相似性图。接下来，我们设计由以下关键组件组成的CA-GF，包括1）标准特定的图形滤波，其中使用各种多项式低通滤波器和2）标准偏爱聚合，在其中找到每个标准的最佳过滤器，其中每个标准的平滑信号汇总。我们证明CA-GF是（a）有效的：提供计算效率，即使在最大的基准数据集上，非常快的运行时间也低于0.2秒，（b）准确：优于基准MC建议方法，实现实质性准确性提高。与最佳竞争对手相比，达到24％，以及（c）可解释：根据可视化的模型预测提供了对每个标准的贡献的解释。]]></description>
      <guid>https://arxiv.org/abs/2502.09046</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多视图图滤波利用成员组关系，以进行有效的小组建议</title>
      <link>https://arxiv.org/abs/2502.09050</link>
      <description><![CDATA[ARXIV：2502.09050V1公告类型：新 
摘要：小组建议旨在提供针对不同小组的优化建议，使小组能够享受适当的物品。另一方面，大多数现有的小组推荐方法都是建立在深度神经网络（DNN）架构上的，旨在捕获成员级别和组级交互之间的复杂关系。尽管这些基于DNN的方法证明了它们的有效性，但它们需要复杂且昂贵的培训程序，除了成员水平的交互之外，还需要结合群体水平的相互作用。为了克服此类限制，我们通过多视图图表过滤（GF）介绍了Group-GF，这是一种非常快速推荐项目的新方法，该方法提供了复杂成员组动力学的整体视图，而无需昂贵的模型训练。具体来说，在Group-GF中，我们首先构建了三项相似性图，这些图表表现出了GF的不同观点。然后，我们发现了每个相似性图的独特多项式图滤波器，并明智地汇总了三个图滤波器。广泛的实验证明了组GF在显着降低运行时的有效性并实现了最先进的建议准确性。]]></description>
      <guid>https://arxiv.org/abs/2502.09050</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>释放大型语言模型的力量来剥夺建议</title>
      <link>https://arxiv.org/abs/2502.09058</link>
      <description><![CDATA[ARXIV：2502.09058V1公告类型：新 
摘要：推荐系统对于个性化用户体验至关重要，但通常取决于隐性反馈数据，这可能是嘈杂的和误导的。现有的脱索研究涉及从交互数据中纳入辅助信息或学习策略。但是，他们在外部知识和交互数据的固有局限性以及某些预定义假设的非宇宙性方面遇到了困难，从而阻碍了准确的噪声识别。最近，大型语言模型（LLMS）因其广泛的世界知识和推理能力而引起了人们的关注，但是在推荐中增强deno的潜力仍然没有得到充实的态度。在本文中，我们介绍了Llard，这是一个利用LLM的框架来改善推荐系统中的deNosing，从而提高了总体建议性能。具体而言，LLARD首先通过LLMS从观察数据中丰富语义见解并推断用户项目偏好知识，从而产生与脱氧相关的知识。然后，它在用户 - 项目的交互图上采用了一种新颖的经营链（COT）技术，以揭示denoising的关系知识。最后，它应用信息瓶颈（IB）原理来使LLM生成的DeNosewsions与建议目标，滤除噪声和无关紧要的LLM知识。经验结果表明，llard在增强denoising和建议准确性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.09058</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在沃尔玛电子商务的语义广告检索中，具有在多个知识领域进行培训的语言模型</title>
      <link>https://arxiv.org/abs/2502.09089</link>
      <description><![CDATA[ARXIV：2502.09089V1公告类型：新 
摘要：电子商务中的赞助搜索提出了一些独特而复杂的挑战。这些挑战源于诸如搜索查询和产品名称之间的不对称语言结构，用户搜索意图的固有歧义以及大量稀疏和不平衡的搜索语料库数据。检索组件在赞助的搜索系统中的作用至关重要，它是直接影响随后的排名和竞标系统的初始步骤。在本文中，我们提出了一种量身定制的端到端解决方案，以优化沃尔玛（Walmart.com）上的广告检索系统。我们的方法是通过产品类别信息为类似BERT的分类模型预算，从而增强了该模型对沃尔玛产品语义的理解。其次，我们设计了两个较高的暹罗网络结构，用于嵌入结构以提高训练效率。第三，我们引入了一种人类的渐进式融合训练方法，以确保稳健的模型性能。我们的结果证明了该管道的有效性。与基线DSSM模型相比，它可将搜索相关性指标提高多达16％。此外，我们的大规模在线A/B测试表明，我们的方法超过了现有生产模型的广告收入。]]></description>
      <guid>https://arxiv.org/abs/2502.09089</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用空气质量传感器网络数据用于实时污染意识到的POI建议</title>
      <link>https://arxiv.org/abs/2502.09155</link>
      <description><![CDATA[ARXIV：2502.09155V1公告类型：新 
摘要：该演示论文介绍了Airsense-R，这是一种隐私的移动应用程序，可为城市环境中的实时，污染感知的兴趣点（POI）提出建议。通过将实时空气质量监控数据与用户偏好相结合，该系统旨在帮助用户就所访问的位置做出健康意识的决策。该应用程序利用协作过滤进行个性化建议，并采用联合学习以保护隐私保护，并整合了来自巴里，意大利和爱尔兰诸如城市的Airsence传感器网络的空气污染物读数。此外，可以使用Airsence预测引擎来检测异常读数并插入稀疏传感器覆盖区域的空气质量读数。该系统提供了一种有希望的，以健康为导向的POI推荐解决方案，该解决方案可以动态适应当前的城市空气质量条件，同时保护用户隐私。 Airtown守则和演示视频可在以下回购中提供：https：//github.com/airtownapp/airtown-application.git。]]></description>
      <guid>https://arxiv.org/abs/2502.09155</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ket-rag：一个成本效益的多粒索引框架</title>
      <link>https://arxiv.org/abs/2502.09304</link>
      <description><![CDATA[ARXIV：2502.09304V1公告类型：新 
摘要：图形rag构造了从文本块的知识图，以改善基于大语言模型（LLM）的问题回答的检索。它在诸如生物医学，法律和政治学之类的领域中特别有用，在这种领域中，检索通常需要对专有文件进行多跳的推理。一些现有的图形窗格系统基于文本块相关性构建了KNN图，但是这种粗粒的方法无法捕获文本中的实体关系，从而导致低于标准的检索和发电质量。为了解决这个问题，最近的解决方案利用LLM从文本块中提取实体和关系，从而构建基于三重态的知识图。但是，这种方法会产生巨大的索引成本，尤其是对于大型文档收集而言。
  为了确保在降低索引成本的同时确保良好的结果准确性，我们提出了Ket-rag，这是一个多粒子索引框架。 Ket-rag首先识别一小部分关键文本块，并利用LLM来构建知识图骨架。然后，它从所有文本块中构建了一个文本关键字二分图，并用作完整知识图的轻量级替代方案。在检索过程中，Ket-rag搜索这两个结构：它遵循骨架上现有图形抹布系统的本地搜索策略，同时模仿两部分图上的搜索以提高检索质量。我们在两个现实世界数据集上评估了八种解决方案，这表明KET-rag的表现优于所有竞争对手的成本，检索效率和发电质量。值得注意的是，它可以达到可比或优越的检索质量与微软的图形窗格，同时将索引成本降低到超过数量级。此外，它将发电质量提高了32.4％，同时将索引成本降低了约20％。]]></description>
      <guid>https://arxiv.org/abs/2502.09304</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在建议中桥接Jensen GAP，以进行最大的Min组公平性优化</title>
      <link>https://arxiv.org/abs/2502.09319</link>
      <description><![CDATA[ARXIV：2502.09319V1公告类型：新 
摘要：Max-Min Fairness（MMF）通常用于公平感知的推荐系统（RS）作为优化目标，因为它旨在保护边缘化项目组并确保公平的竞争平台。但是，我们的理论分析表明，整合MMF约束违反了优化过程中样本独立性的假设，从而导致损失函数偏离线性添加性。这种非线性属性引入了模型的收敛点与如果应用微型批次采样的最佳点之间的詹森差距。理论和实证研究都表明，随着微型批量的大小减小，组大小增加，詹森差距将相应地扩大。一些使用启发式重新加权或辩护策略的方法有可能弥合詹森差距。但是，他们要么缺乏理论保证，要么缺乏巨大的计算成本。为了克服这些局限性，我们首先从理论上证明，可以将MMF受限的目标基本重新构成作为集体加权优化目标。然后，我们提出了一种名为FairDual的高效算法，该算法利用双重优化技术来最大程度地减少Jensen Gap。我们的理论分析表明，公平可以实现与全球最佳解决方案的亚线性收敛速率，并且詹森（Jensen）差距可以在随机洗牌的微型批次采样策略下构成良好的界限。在三个公开可用的数据集中使用六个大型RS主链模型进行的广泛实验表明，公平的表现优于所有基准，从精度和公平性角度来看。我们的数据和代码在https://github.com/xuchen0427/fairdual上共享。]]></description>
      <guid>https://arxiv.org/abs/2502.09319</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>农场：跨域现场直播建议的频率感知模型</title>
      <link>https://arxiv.org/abs/2502.09375</link>
      <description><![CDATA[ARXIV：2502.09375V1公告类型：新 
摘要：由于其实时互动和娱乐价值，实时流程服务吸引了广泛的知名度。用户可以通过参与实时聊天，发布喜欢或发送虚拟礼物来传达其偏好和支持来与实时流连的作者互动。但是，实时流传输服务面临严重的数据 - 表格问题，这可以归因于以下两个方面：（1）用户的宝贵行为通常很少，例如，就像，评论和礼物一样，这些行为很容易被模型，模型忽略很难描述用户的个性化偏好。 （2）我们平台上的主要曝光内容是短视频，它比暴露的实时流媒体高9倍，从而导致无法实时流程内容以完全模拟用户的偏好。为此，我们提出了一种用于跨域现场直播建议的频率感知模型，称为农场。具体而言，我们首先介绍了内域频率感知模块，以使我们的模型能够感知用户稀疏但有价值的行为，即高频信息，并由离散的傅立叶变换（DFT）支持。为了将用户偏好转移到短视频和实时流传输域中，我们提出了一个新颖的偏好在Fuse策略之前保持一致，该策略由两个部分组成：跨域偏好对齐模块，以使两个域中的用户偏好与对比度学习和对比度学习，并且跨域偏好保险丝模块使用认真的量身定制的注意机制进一步融合了两个域中的用户偏好。广泛的离线实验和关于Kuaishou Live-treaming Services的在线A/B测试证明了农场的有效性和优势。我们的农场已部署在线实时服务，目前为Kuaishou提供了数亿用户。]]></description>
      <guid>https://arxiv.org/abs/2502.09375</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以任何方式询问：一项关于多式联运的全面调查</title>
      <link>https://arxiv.org/abs/2502.08826</link>
      <description><![CDATA[ARXIV：2502.08826V1公告类型：交叉 
摘要：大型语言模型（LLMS）由于依赖静态培训数据而与幻觉和过时的知识斗争。通过集成外部动态信息来增强事实和更新的基础，检索增强的生成（RAG）通过整合外部动态信息来减轻这些问题。多模式学习的最新进展导致了多模式抹布的发展，并结合了多种模式，例如文本，图像，音频和视频，以增强生成的输出。但是，跨模式的对齐和推理对多模式抹布引入了独特的挑战，将其与传统的单峰抹布区分开。这项调查提供了对多模式抹布系统的结构化和全面分析，涵盖了检索，融合，增强和一代中的数据集，指标，基准，评估，方法和创新。我们精确地审查了培训策略，鲁棒性增强和损失功能，同时还探索了多种多态的破布场景。此外，我们讨论了支持这个不断发展的领域进步的开放挑战和未来的研究方向。这项调查为开发更有效和可靠的AI系统的基础奠定了基础，这些系统有效地利用了多模式动态外部知识库。资源可在https://github.com/llm-lab-org/multimodal-rag-survey上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.08826</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PEAPOD：个性化及时蒸馏以进行生成建议</title>
      <link>https://arxiv.org/abs/2407.05033</link>
      <description><![CDATA[ARXIV：2407.05033V2公告类型：替换 
摘要：最近，研究人员研究了大语模型（LLMS）的能力，用于生成推荐系统。现有的基于LLM的建议模型是通过将用户和项目ID添加到离散提示模板中培训的。但是，IDS和自然语言之间的断开连接使LLM难以学习用户之间的关系。为了解决这个问题，我们提出了一种个性化的及时蒸馏（PEAPOD）方法，以将用户偏好作为个性化的软提示提取。考虑到现实世界中用户偏好的复杂性，我们维护了一组共享的可学习提示，这些提示是根据用户的兴趣动态加权的，以组成方式构建用户个人化提示。三个现实世界数据集的实验结果证明了我们的PEAPOD模型在顺序推荐，顶级建议和解释生成任务上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.05033</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于语言的用户配置文件进行推荐的端到端培训</title>
      <link>https://arxiv.org/abs/2410.18870</link>
      <description><![CDATA[Arxiv：2410.18870V2公告类型：替换 
摘要：对推荐系统的基于天然语言的用户资料越来越感兴趣，该系统旨在增强与基于嵌入的方法相比的透明度和可辨式性。现有研究主要使用大语言模型（LLMS）的零摄入推断产生这些概况，但它们的质量仍然不足，导致了次优建议性能。在本文中，我们介绍了Langptune，这是第一个优化LLM生成的用户配置文件的端到端培训框架。我们的方法通过明确训练LLM的推荐目标来大大优于零击方法。通过对各种培训配置和基准测试的广泛评估，我们证明了Langptune不仅超过了零射基线的基准，而且还可以匹配基于最新的基于嵌入的方法的性能。最后，我们研究培训程序是否通过GPT-4模拟和CrowdWorker用户研究来保留这些配置文件的解释性。可以在https://github.com/zhaolingao/langptune上找到Langptune的实施。]]></description>
      <guid>https://arxiv.org/abs/2410.18870</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RaseRec：检索效果的顺序建议</title>
      <link>https://arxiv.org/abs/2412.18378</link>
      <description><![CDATA[ARXIV：2412.18378V3公告类型：替换 
摘要：尽管有强大的神经网络体系结构进行了盛行的监督和自我监管的学习增强的顺序推荐（SEREC）模型，但仍在提高了性能几乎无法适应不断发展的用户偏好； （2）隐式内存，其中头模式主导了参数学习，因此很难回忆长尾巴。在这项工作中，我们探讨了SEREC中的检索增强，以解决这些局限性。具体而言，我们提出了一个名为Raserec的检索式顺序推荐框架，其主要思想是维护动态内存库以适应偏好漂移并检索相关记忆以明确增强用户建模。它由两个阶段组成：（i）基于协作的预培训，学会了推荐和检索； （ii）检索调查的微调，该调查学会利用检索的记忆。在三个数据集上进行的广泛实验完全证明了RaseRec的优势和有效性。实施代码可在https://github.com/hitsz-tmg/raserec上获得。]]></description>
      <guid>https://arxiv.org/abs/2412.18378</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ABXI：任务指导的跨域顺序建议的不变兴趣改编</title>
      <link>https://arxiv.org/abs/2501.15118</link>
      <description><![CDATA[ARXIV：2501.15118V2公告类型：替换 
摘要：跨域顺序推荐（CDSR）最近通过跨域转移知识来对抗数据稀疏性。一种通用方法将特定于域特异性序列合并为跨域序列，用作连接域的桥梁。一个关键的挑战是在这些序列之间正确提取共享知识，并适当地将其转移。大多数现有作品直接传输未经过滤的跨域知识，而不是提取域 - 不变组件并将其自适应地整合到特定领域的模型中。另一个挑战在于对齐域特异性和跨域序列。现有方法基于时间戳对齐这些序列，但是当当前令牌及其目标属于不同域时，此方法可能会导致预测不匹配。在这种情况下，当前令牌带来的特定领域特定知识可能会降低性能。为了应对这些挑战，我们提出了A-B-Cross到不变的学习建议（ABXI）。具体而言，ABXI利用Lora的有效性来有效适应，并结合了两种类型的Loras来促进知识适应。首先，所有序列都是通过共享编码器处理的，该共享编码器使用每个序列采用域Lora，从而保留独特的域特征。接下来，我们引入了一个不变的投影仪，该投影仪利用不变的洛拉（Lora）从跨域表示中提取域不变兴趣，以使这些兴趣适应每个特定域进行建模。此外，为避免预测不匹配，所有特定于域特异性的序列都符合跨域地面真相的域。三个数据集的实验结果表明，我们的方法的表现要优于其他CDSR的差距。这些代码可在https://github.com/dimarziobian/abxi中找到。]]></description>
      <guid>https://arxiv.org/abs/2501.15118</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>