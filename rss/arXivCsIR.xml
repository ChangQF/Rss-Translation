<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 14 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>改善会话搜索测试收集的可重复性</title>
      <link>https://arxiv.org/abs/2503.09899</link>
      <description><![CDATA[ARXIV：2503.09899V1公告类型：新 
摘要：不完整的相关性判断限制了测试收集的可重复性。当将新系统与以前有助于池的系统进行比较时，它们通常会面临不利地位。这是由于新系统返回的测试集合中的无孔文档（称为孔）的口袋。会话搜索（CS）的本质意味着这些孔在评估系统时可能更大，更有问题。在本文中，我们旨在通过使用大型语言模型（LLM）来扩展CS测试收集，以通过利用现有判断来填充漏洞。我们使用TREC IKAT 23和TREC COST 22集合探讨了这个问题，其中信息需求是高度动态的，并且响应更加多样化，因此可以填补更大的漏洞。我们的实验表明，CS收集表明，在更深层次的转弯中，可重复使用率降低了。同样，对美洲驼3.1模型进行微调导致与人类评估者的高度同意，而促使Chatgpt的射击很少会导致与人类的一致性低。因此，使用CHATGPT填充新系统的孔会导致新系统位置的更改。同时，用很少的拍摄池重新生成评估池，促使ChatGpt模型并使用它来评估与人类评估的池的高级相关性。我们表明，使用少量训练的Llama 3.1模型在填充孔中可以进行更公平的比较，并有助于池。我们基于对美洲驼3.1模型的几次训练的孔填充模型可以改善测试收集的可重复性。]]></description>
      <guid>https://arxiv.org/abs/2503.09899</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对话金：使用金块评估个性化的对话搜索系统</title>
      <link>https://arxiv.org/abs/2503.09902</link>
      <description><![CDATA[ARXIV：2503.09902V1公告类型：新 
摘要：个性化的对话搜索系统的兴起是由大语言模型（LLMS）的进步驱动的，使这些系统能够检索并为复杂的信息需求生成答案。但是，对检索增强发电（RAG）系统产生的响应的自动评估仍然是一个研究的挑战。在本文中，我们介绍了一种新的资源，用于评估使用基于掘金的评估框架，抹布系统产生的响应的检索效率和相关性。我们的数据集建立在TREC IKAT 2023的基础之上，扩展到TREC IKAT 2024系列，其中包括17次对话和20,575个相关性通过评估，以及2,279个提取的金块，以及62位NIST评估者的手动书写金答案。在维护其前身的核心结构的同时，这个新收藏可以更深入地探索对话设置中的发电任务。 IKAT 2024中的主要改进包括：（1）``黄金掘金&#39;&#39; - 简洁，从集合的相关段落中提取的基本信息 - 这是自动响应评估的基础； （2）手动书面答案，以提供响应评估的黄金标准； （3）无法回答评估模型幻觉的问题； （4）扩大用户角色，提供更丰富的上下文基础； （5）从个人文本知识库（PTKB）排名到PTKB分类和选择的过渡。基于此资源，我们为长形式答案生成评估提供了一个框架，涉及掘金提取和与检索相链接的掘金匹配。这为推进个性化的对话搜索和长形答案生成的研究建立了可靠的资源。我们的资源可在https://github.com/irlabamsterdam/cone-rag上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2503.09902</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ImageScope：通过大型多模型集体推理统一语言引导的图像检索</title>
      <link>https://arxiv.org/abs/2503.10166</link>
      <description><![CDATA[ARXIV：2503.10166V1公告类型：新 
摘要：随着在线内容中图像的扩散，在过去的十年中，语言指导的图像检索（LGIR）已成为研究热点，涵盖了各种具有多种输入形式的子任务。尽管大型多模型模型（LMM）的开发显着促进了这些任务，但现有方法通常孤立地解决这些任务，需要为每个任务构建单独的系统。这不仅增加了系统的复杂性和维护成本，而且加剧了由于语言歧义和复杂的图像内容而引起的挑战，因此检索系统很难提供准确可靠的结果。为此，我们提出了ImageScope，这是一个无训练的三阶段框架，利用集体推理来统一LGIR任务。统一背后的关键见解在于语言的组成性质，它将各种LGIR任务转变为广义的文本对图像检索过程，以及LMMS的推理，以作为完善的验证以完善结果。具体来说，在第一阶段，我们通过使用思想链（COT）推理综合跨不同语义粒度的搜索意图来提高框架的鲁棒性。然后，在第二和第三阶段，我们通过在本地验证谓词命题并在全球进行成对评估来反映检索结果。在六个LGIR数据集上进行的实验表明，ImageScope的表现优于竞争基准。全面的评估和消融研究进一步证实了我们设计的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.10166</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的动物的资源有效数据传输</title>
      <link>https://arxiv.org/abs/2503.10277</link>
      <description><![CDATA[ARXIV：2503.10277V1公告类型：交叉 
摘要：生物风险，用于通过各种传感器跟踪动物行为的电子设备，在野生动植物研究中已经至关重要。
  尽管其能力不断提高，但由于尺寸和重量的限制，生物遗传者仍在存储，加工和数据传输方面仍面临重大限制，这是避免干扰动物所必需的。
  这项研究旨在探讨在机器学习的指导下，选择性数据传输如何减少生物遗产的能源消耗，从而延长其运行寿命而无需进行硬件修改。]]></description>
      <guid>https://arxiv.org/abs/2503.10277</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GBSVR：颗粒球支持向量回归</title>
      <link>https://arxiv.org/abs/2503.10539</link>
      <description><![CDATA[ARXIV：2503.10539V1公告类型：交叉 
摘要：支持向量回归（SVR）及其变体被广泛用于处理回归任务，但是，由于它们的解决方案涉及解决昂贵的二次编程问题，因此它限制了其应用程序，尤其是在处理大型数据集时。此外，SVR使用对异晶的不敏感损失函数，该损失函数对异常值敏感，因此可能会对其性能产生不利影响。我们建议使用颗粒球概念来解决回归问题的颗粒球支持矢量回归（GBSVR）。这些球可用于简化用于机器学习任务的复杂数据空间，但是，据我们所知，它们在回归问题方面尚未得到足够的探索。颗粒球根据其接近度将数据点分为球，并通过替换大量粒状球的大量数据点来降低SVR中的计算成本。这项工作还提出了一种连续值属性的离散方法，以促进颗粒球的构造。在几个基准数据集上评估了所提出方法的有效性，并且表现优于现有的最新方法]]></description>
      <guid>https://arxiv.org/abs/2503.10539</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Genup：生成性用户介绍者作为下文学习者的下一个POI推荐系统</title>
      <link>https://arxiv.org/abs/2410.20643</link>
      <description><![CDATA[ARXIV：2410.20643V2公告类型：替换 
摘要：传统利益点（POI）推荐系统通常由于依赖基于密集的向量的用户嵌入而缺乏透明度，可解释性和可忽视性。此外，启动的寒冷问题 - 系统对新用户的数据不足 - 限制了它们生成准确建议的能力。现有方法通常通过利用其他用户的类似轨迹来解决这一问题，但是这种方法在计算上可能很昂贵，并且可以增加基于LLM的方法的上下文长度，从而使它们难以扩展。为了解决这些局限性，我们提出了一种通过大规模，基于位置的社交网络（LBSN）签到的方法生成自然语言（NL）用户资料的方法，利用了强大的个性评估和行为理论。这些NL配置文件捕获了用户的偏好，例程和行为，从而提高了POI预测准确性，同时提供了增强的透明度。通过将NL配置文件作为系统提示向LLM，我们的方法减少了对广泛的历史数据的依赖，同时保持灵活，易于更新和计算效率。我们的方法不仅与其他基于LLM和复杂的代理框架竞争，而且对于现实世界中的POI推荐系统也更具扩展性。结果表明，我们的方法始终优于基线方法，为POI推荐系统提供了更容易解释和资源有效的解决方案。我们的源代码可在以下网址获得：https：//github.com/w11wo/genup/。]]></description>
      <guid>https://arxiv.org/abs/2410.20643</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于连续建议的调查</title>
      <link>https://arxiv.org/abs/2412.12770</link>
      <description><![CDATA[ARXIV：2412.12770V2公告类型：替换 
摘要：与大多数常规建议问题不同，顺序建议通过利用相互作用的项目之间的内部秩序和依赖性来关注学习用户的偏好，这已经受到了研究人员和从业者的极大关注。近年来，我们目睹了这一领域取得的巨大进步和成就，需要进行新的调查。在这项调查中，我们从新的角度研究了SR问题（即，构建项目的属性），并总结了顺序建议中使用的最新技术，例如纯基于ID的SR，带有侧面信息，多模式SR，生成SR，LLM-PAREED SR，Ultra-Long SR，Ultra-Long SR，Ultra-long-long-long-long sr和Data-data-augented sr。此外，我们在顺序推荐中介绍了一些前沿研究主题，例如开放域SR，数据以数据为中心的SR，Come-Edge-Edge-Edge-Edge Cromportation Sr，Contunuel Sr，Sr，SR，for Ode-Oxply和可解释的SR。我们认为，我们的调查可以作为该领域读者的宝贵路线图。]]></description>
      <guid>https://arxiv.org/abs/2412.12770</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加速洪水警告10小时：AI增强洪水预测中河网络拓扑的功能</title>
      <link>https://arxiv.org/abs/2410.05536</link>
      <description><![CDATA[ARXIV：2410.05536V3公告类型：替换 - 交叉 
摘要：气候变化驱动的洪水需求先进的预测模型，但由于树状结构导致高节点电阻距离导致过度阵列而导致的河网络拓扑数量不足。这项研究确定了这一限制，并引入了基于可及的图形转换，以致密拓扑连接，从而降低了电阻距离。经验测试表明，在极端洪水预测中，转化的GNN胜过EA-LSTM，达到24小时的水位精度等于EA-LSTM的14小时预测 - 长期预测范围的增长了71％。该密集图保留了跨分层河分支的流动动力学，使GNN能够捕获远端节点相互作用对于罕见的洪水事件至关重要。这项拓扑创新桥接了河网络结构与GNN建模之间的差距，为预警系统提供了可扩展的框架。]]></description>
      <guid>https://arxiv.org/abs/2410.05536</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当文本嵌入符合大型语言模型时：一项综合调查</title>
      <link>https://arxiv.org/abs/2412.09165</link>
      <description><![CDATA[ARXIV：2412.09165V2公告类型：替换 - 交叉 
摘要：在深度学习时代，文本嵌入已成为自然语言处理（NLP）中的基础技术，推动了各种下游任务的进步。尽管现在可以使用生成范式来对许多自然的语言理解挑战进行建模，并利用大型语言模型（LLMS）的强大生成和理解能力，许多实用的应用，例如语义匹配，聚类和信息检索 - 依靠依赖文本嵌入的效率和有效性。因此，如何结合LLM和文本嵌入已成为近年来学术关注的热点之一。在这项调查中，我们将LLM和文本嵌入之间的相互作用分为三个总体主题：（1）LLM-augment的文本嵌入，增强了使用LLMS的传统嵌入方法； （2）llms作为文本嵌入式，适应其先天能力以嵌入高质量的嵌入； （3）使用LLMS嵌入理解的文本，利用LLMS分析和解释嵌入。通过基于相互作用模式而不是特定的下游应用程序来组织最新的作品，我们为LLM时代的各种研究和应用领域的贡献提供了新颖而系统的概述。此外，我们强调了通过预训练的语言模型（PLM）持续存在的尚未解决的挑战，并探索了LLMS带来的新兴障碍。在此分析的基础上，我们概述了嵌入文本演变的前瞻性方向，在NLP快速前进的景观中既解决理论和实践机遇。]]></description>
      <guid>https://arxiv.org/abs/2412.09165</guid>
      <pubDate>Fri, 14 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>