<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 26 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>算法漂移：研究推荐系统对用户偏好影响的模拟框架</title>
      <link>https://arxiv.org/abs/2409.16478</link>
      <description><![CDATA[arXiv:2409.16478v1 公告类型：新
摘要：社交媒体和电子商务网站等数字平台采用推荐系统为用户提供价值。然而，采用推荐系统所带来的社会后果仍不清楚。许多学者认为，推荐系统可能会导致有害影响，例如算法建议和用户选择之间的反馈回路导致的偏差放大。尽管如此，推荐系统对用户倾向变化的影响程度仍不确定。在这种情况下，在部署之前提供一个受控环境来评估推荐算法非常重要。为了解决这个问题，我们提出了一个随机模拟框架，模拟长期场景中的用户推荐系统交互。具体来说，我们通过形式化用户模型来模拟用户选择，该模型包括行为方面，例如用户对推荐算法的抵制以及他们对收到的建议的依赖惯性。此外，我们引入了两个新的指标来量化算法对用户偏好的影响，特别是在随时间漂移方面。我们对多个合成数据集进行了广泛的评估，旨在测试我们的框架在考虑不同场景和超参数设置时的稳健性。实验结果证明，所提出的方法能够有效地通过模拟检测和量化用户偏好的漂移。用于执行实验的所有代码和数据都是公开的。]]></description>
      <guid>https://arxiv.org/abs/2409.16478</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FusionANNS：一种用于十亿级近似最近邻搜索的高效 CPU/GPU 协同处理架构</title>
      <link>https://arxiv.org/abs/2409.16576</link>
      <description><![CDATA[arXiv:2409.16576v1 公告类型：新
摘要：近似最近邻搜索 (ANNS) 已成为数据库和 AI 基础设施的重要组成部分。不断增加的矢量数据集对 ANNS 服务的性能、成本和准确性提出了重大挑战。没有一个现代 ANNS 系统可以同时解决这些问题。我们提出了 FusionANNS，这是一种高吞吐量、低延迟、经济高效且高精度的 ANNS 系统，适用于十亿级数据集，仅使用 SSD 和一个入门级 GPU。FusionANNS 的关键思想在于 CPU/GPU 协同过滤和重新排序机制，这显著减少了 CPU、GPU 和 SSD 之间的 I/O 操作，从而突破了 I/O 性能瓶颈。具体来说，我们提出了三种新颖的设计：（1）多层索引以避免 CPU 和 GPU 之间的数据交换，（2）启发式重新排序以消除不必要的 I/O 和计算，同时保证高精度，以及（3）冗余感知的 I/O 重复数据删除以进一步提高 I/O 效率。我们实现了 FusionANNS，并将其与最先进的基于 SSD 的 ANNS 系统 SPANN 和 GPU 加速的内存 ANNS 系统 RUMMY 进行了比较。实验结果表明，FusionANNS 1）与 SPANN 相比，每秒查询 (QPS) 提高了 9.4-13.1 倍，成本效率提高了 5.7-8.8 倍；2）与 RUMMY 相比，QPS 提高了 2-4.9 倍，成本效率提高了 2.3-6.8 倍，同时保证了低延迟和高精度。]]></description>
      <guid>https://arxiv.org/abs/2409.16576</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>网络规模的具有过度参数化的生成预训练排名模型（扩展摘要）</title>
      <link>https://arxiv.org/abs/2409.16594</link>
      <description><![CDATA[arXiv:2409.16594v1 公告类型：新
摘要：排名学习 (LTR) 广泛应用于网络搜索，根据输入查询对检索到的内容中的相关网页进行优先排序。然而，传统的 LTR 模型遇到了两个主要障碍，导致性能不佳：(1) 缺乏经过良好注释的查询网页对，其排名分数涵盖了各种搜索查询流行度，这妨碍了它们处理流行度范围内的查询的能力，以及 (2) 训练不足的模型无法为 LTR 诱导出广义表示，导致过度拟合。为了应对这些挑战，我们提出了一个 \emph{\uline{G}enerative \uline{S}emi-\uline{S}supervised \uline{P}re-trained} (GS2P) LTR 模型。我们对公开可用的数据集和从大型搜索引擎收集的真实数据集进行了广泛的离线实验。此外，我们在具有实际流量的大型网络搜索引擎中部署了 GS2P，我们观察到实际应用中的显著改进。]]></description>
      <guid>https://arxiv.org/abs/2409.16594</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一次训练，随处部署：用于多模态推荐的 Matryoshka 表示学习</title>
      <link>https://arxiv.org/abs/2409.16627</link>
      <description><![CDATA[arXiv:2409.16627v1 公告类型：新
摘要：尽管语言和视觉建模最近取得了进展，但将丰富的多模态知识集成到推荐系统中仍然面临重大挑战。这主要是因为需要有效的推荐，这需要自适应和交互式响应。在本研究中，我们专注于顺序推荐，并引入了一个轻量级框架，称为全尺寸 Matryoshka 表示学习多模态推荐 (fMRLRec)。我们的 fMRLRec 以不同的粒度捕获项目特征，学习信息表示以在多个维度上进行有效的推荐。为了整合来自不同模态的项目特征，fMRLRec 采用简单的映射将多模态项目特征投影到对齐的特征空间中。此外，我们设计了一种有效的线性变换，将较小的特征嵌入到较大的特征中，大大减少了对推荐数据进行大规模训练的内存要求。结合改进的状态空间建模技术，fMRLRec 可以扩展到不同的维度，只需一次训练即可生成针对各种粒度的多个模型。我们在多个基准数据集上证明了 fMRLRec 的有效性和效率，其性能始终优于最先进的基线方法。]]></description>
      <guid>https://arxiv.org/abs/2409.16627</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种基于提示的大型语言模型推荐表征学习方法</title>
      <link>https://arxiv.org/abs/2409.16674</link>
      <description><![CDATA[arXiv:2409.16674v1 公告类型：新
摘要：近年来，随着大型语言模型 (LLM) 在自然语言处理 (NLP) 领域的出现，推荐系统 (RS) 经历了一场变革性的转变。GPT-3.5/4、Llama 等模型在理解和生成类似人类的文本方面表现出了前所未有的能力。这些 LLM 预先训练的大量信息有可能从用户和项目的不同上下文信息中捕获更深刻的语义表示。
虽然 LLM 的蓬勃发展背后有着巨大的潜力，但利用上下文信息中的用户项目偏好及其与推荐系统改进的一致性的挑战需要解决。我们相信更好地理解用户或项目本身可能是提高推荐性能的关键因素，因此我们对使用最先进的 LLM 生成信息丰富的配置文件进行了研究。
为了提高推荐系统中 LLM 的语言能力，我们引入了基于提示的推荐表示学习方法 (P4R)。在我们的 P4R 框架中，我们利用 LLM 提示策略来创建个性化项目配置文件。然后，使用预训练的 BERT 模型将这些配置文件转换为语义表示空间，用于文本嵌入。此外，我们结合了图卷积网络 (GCN) 用于协同过滤表示。P4R 框架将这两个嵌入空间对齐，以解决一般推荐任务。在我们的评估中，我们将 P4R 与最先进的推荐模型进行比较，并评估基于提示的配置文件生成的质量。]]></description>
      <guid>https://arxiv.org/abs/2409.16674</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用文本到文本传输转换器 (T5) 架构增强自动关键词标记功能：关键词生成和过滤框架</title>
      <link>https://arxiv.org/abs/2409.16760</link>
      <description><![CDATA[arXiv:2409.16760v1 公告类型：新
摘要：自动关键短语标记代表模型检索充分描述文档内容的单词或短语的能力。先前的工作已经投入了大量精力来探索提取技术来解决此任务；但是，这些方法无法生成文本中找不到的关键短语。鉴于这一限制，关键短语生成方法最近应运而生。本文提出了一种基于文本到文本传输转换器 (T5) 架构的关键短语生成模型。以文档的标题和摘要作为输入，我们学习一个 T5 模型来生成充分定义其内容的关键短语。我们将此模型命名为 docT5keywords。我们不仅执行经典的推理方法，其中直接选择输出序列作为预测值，而且我们还报告多数投票方法的结果。在这种方法中，会生成多个序列，并根据关键短语在这些序列中出现的频率对其进行排名。除了此模型之外，我们还提出了一种基于 T5 架构的新型关键短语过滤技术。我们训练 T5 模型来了解给定的关键短语是否与文档相关。我们设计了两种评估方法来证明我们的模型能够过滤不充分的关键短语。首先，我们执行二元评估，其中我们的模型必须预测关键短语是否与给定文档相关。其次，我们通过几个 AKG 模型过滤预测的关键短语，并检查评估分数是否有所提高。实验结果表明，我们的关键短语生成模型的表现明显优于所有基线，在某些情况下增益超过 100\%。所提出的过滤技术还在所有数据集中消除误报方面实现了近乎完美的准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.16760</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>现代 Hopfield 网络与编码神经表征相遇——解决实际问题</title>
      <link>https://arxiv.org/abs/2409.16408</link>
      <description><![CDATA[arXiv:2409.16408v1 公告类型：交叉 
摘要：内容可寻址存储器（例如现代霍普菲尔德网络 (MHN)）已被研究为人类陈述性记忆中自动联想和存储/检索的数学模型，但它们在大规模内容存储中的实际应用面临挑战。其中最主要的是亚稳态的出现，特别是在处理大量高维内容时。本文介绍了霍普菲尔德编码网络 (HEN)，这是一个将编码神经表征集成到 MHN 中的框架，以提高模式可分离性并减少亚稳态。我们表明，HEN 还可用于在图像与自然语言查询的异质关联环境中进行检索，从而消除了需要访问同一域中的部分内容的限制。实验结果表明，亚稳态显著减少，存储容量增加，同时仍能完美回忆大量输入，从而提高了联想记忆网络在实际任务中的实用性。]]></description>
      <guid>https://arxiv.org/abs/2409.16408</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于预训练 Graphformer 的网络规模搜索排名（扩展摘要）</title>
      <link>https://arxiv.org/abs/2409.16590</link>
      <description><![CDATA[arXiv:2409.16590v1 公告类型：交叉 
摘要：Transformer 和图神经网络 (GNN) 都已用于排名学习 (LTR) 领域。然而，这些方法分别遵循两个截然不同但互补的问题公式：基于查询-网页对的排名分数回归和查询-网页二分图中的链接预测。虽然可以在源数据集上预训练 GNN 或 Transformer，然后在稀疏注释的 LTR 数据集上对其进行微调，但基于对和二分图域之间的分布转变对将这些异构模型集成到统一的 Web 规模 LTR 框架中提出了重大挑战。为了解决这个问题，我们引入了新颖的 MPGraf 模型，该模型利用模块化和基于胶囊的预训练策略，旨在将 Transformer 的回归功能与 GNN 的链接预测优势紧密结合起来。我们进行了大量的离线和在线实验来严格评估 MPGraf 的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.16590</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估和增强大型语言模型以评估学术出版物的新颖性</title>
      <link>https://arxiv.org/abs/2409.16605</link>
      <description><![CDATA[arXiv:2409.16605v1 公告类型：交叉 
摘要：最近的研究主要从语义角度评估了大型语言模型 (LLM) 的创造力/新颖性，使用了认知科学的基准。然而，在评估 LLM 时，获取学术出版物中的新颖性是一个尚未探索的领域。在本文中，我们引入了一个学术新颖性基准 (SchNovel) 来评估 LLM 评估学术论文新颖性的能力。SchNovel 由从 arXiv 数据集中抽样的六个领域的 15000 对论文组成，出版日期相隔 2 至 10 年。在每一对中，最近发表的论文被认为更新颖。此外，我们提出了 RAG-Novelty，它通过利用检索类似论文来评估新颖性，从而模拟人类审阅者的审阅过程。大量实验深入了解了不同 LLM 评估新颖性的能力，并证明 RAG-Novelty 优于最近的基线模型。]]></description>
      <guid>https://arxiv.org/abs/2409.16605</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PIFS-Rec：用于大规模推荐系统推理的 Process-In-Fabric-Switch</title>
      <link>https://arxiv.org/abs/2409.16633</link>
      <description><![CDATA[arXiv:2409.16633v1 公告类型：交叉 
摘要：深度学习推荐模型 (DLRM) 在当今的数据中心越来越流行和普及，占用了大部分 AI 推理周期。由于 DLRM 在嵌入表和并发访问中的向量大小很大，因此可用带宽对 DLRM 的性能影响很大。为了在现有解决方案上实现实质性的改进，需要对 DLRM 进行优化的新方法，尤其是在 CXL 等新兴互连技术的背景下。本研究深入探索支持 CXL 的系统，实施进程架构交换机 (PIFS) 解决方案以加速 DLRM，同时优化其内存和带宽可扩展性。我们对在支持 CXL 的系统上运行的行业规模 DLRM 工作负载进行了深入描述，确定了现有 CXL 系统中的主要瓶颈。因此，我们提出了 PIFS-Rec，这是一种基于 PIFS 的方案，可通过架构交换机的下游端口实现近数据处理。 PIFS-Rec 的延迟比基于行业标准 CXL 的系统 Pond 低 3.89 倍，并且比最先进的方案 BEACON 的延迟高出 2.03 倍。]]></description>
      <guid>https://arxiv.org/abs/2409.16633</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>太空行走者：穿越表征空间，实现非结构化数据的快速交互式探索和注释</title>
      <link>https://arxiv.org/abs/2409.16793</link>
      <description><![CDATA[arXiv:2409.16793v1 公告类型：交叉 
摘要：医疗保健、金融和制造业等行业的非结构化数据对高效分析和决策提出了重大挑战。如果没有合适的工具，检测这些数据中的模式并了解其影响至关重要但也很复杂。传统上，这些任务依赖于数据分析师的专业知识或劳动密集型的人工审查。作为回应，我们推出了 Spacewalker，这是一种交互式工具，旨在探索和注释跨多种模态的数据。Spacewalker 允许用户提取数据表示并在低维空间中可视化它们，从而能够检测语义相似性。通过广泛的用户研究，我们评估了 Spacewalker 在数据注释和完整性验证方面的有效性。结果表明，该工具遍历潜在空间和执行多模态查询的能力显著增强了用户快速识别相关数据的能力。此外，Spacewalker 允许注释速度远远优于传统方法，使其成为有效导航非结构化数据和改进决策过程的有前途的工具。本作品的代码是开源的，可以在以下网址找到：https://github.com/code-lukas/Spacewalker]]></description>
      <guid>https://arxiv.org/abs/2409.16793</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于短暂群组推荐的个性引导偏好聚合器</title>
      <link>https://arxiv.org/abs/2304.08851</link>
      <description><![CDATA[arXiv:2304.08851v2 公告类型：替换 
摘要：短暂群组推荐 (EGR) 旨在为首次聚在一起的一组用户推荐商品。现有工作通常将个人偏好视为聚合群体偏好的唯一因素。然而，他们忽略了个人固有因素（如个性）的重要性，因此无法准确模拟群体决策过程。此外，这些方法往往因交互记录不足而举步维艰。为了解决这些问题，提出了一种个性引导偏好聚合器 (PEGA)，它根据群组成员的个性来指导他们的偏好聚合，而不是仅仅依靠他们的偏好。具体来说，首先从用户评论中提取隐性个性。然后使用超矩形聚合个人个性以获得“群体个性”，从而可以学习群体内的个性分布。随后，采用个性注意机制来聚合群体偏好，并使用基于偏好的微调模块来平衡个性和偏好的权重。个性在这种方法中的作用是双重的：（1）估计群体中个人用户的重要性并提供可解释性；（2）缓解短暂群体中遇到的数据稀疏问题。实验结果表明，在四个真实数据集上，PEGA 模型在分类准确性和可解释性方面明显优于相关基线模型。此外，经验证据支持个性在提高 EGR 任务性能方面起着关键作用的观点。]]></description>
      <guid>https://arxiv.org/abs/2304.08851</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Etsy 搜索中基于统一嵌入的个性化检索</title>
      <link>https://arxiv.org/abs/2306.04833</link>
      <description><![CDATA[arXiv:2306.04833v2 公告类型：替换 
摘要：基于嵌入的神经检索是一种解决语义差距问题的流行方法，该问题经常出现在尾部查询的产品搜索中。相比之下，热门查询通常缺乏上下文，并且具有广泛的意图，而来自用户历史交互的额外上下文可能会有所帮助。在本文中，我们分享了解决这两个问题的新方法：语义差距问题，然后是用于个性化语义检索的端到端训练模型。我们建议学习一个统一的嵌入模型，该模型结合了图、转换器和基于术语的嵌入，并分享了我们在性能和效率之间实现最佳权衡的设计选择。我们分享了我们在特征工程、硬负采样策略和转换器模型应用方面的学习成果，包括一种新颖的预训练策略和其他用于提高搜索相关性并在行业规模上部署这种模型的技巧。我们的个性化检索模型显著改善了整体搜索体验，根据对实时流量进行的多次 A/B 测试汇总得出，搜索购买率提高了 5.58%，全站转化率提高了 2.63%。]]></description>
      <guid>https://arxiv.org/abs/2306.04833</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中隐性排名不公平性的研究</title>
      <link>https://arxiv.org/abs/2311.07054</link>
      <description><![CDATA[arXiv:2311.07054v2 公告类型：替换 
摘要：最近，大型语言模型 (LLM) 已显示出作为排名模型的卓越能力。然而，人们担心 LLM 会根据用户的敏感属性（例如性别）表现出歧视性排名行为。更糟糕的是，在本文中，我们发现了 LLM 中一种更微妙的歧视形式，称为 \textit{隐性排名不公平}，其中 LLM 仅基于非敏感用户资料（例如用户名）表现出歧视性排名模式。这种隐性不公平更为普遍，但不太明显，威胁着道德基础。为了全面探讨这种不公平现象，我们的分析将集中在三个研究方面：（1）我们提出了一种评估方法来调查隐性排名不公平的严重程度。（2）我们揭示了造成这种不公平的原因。（3）为了有效缓解这种不公平现象，我们利用成对回归方法对 LLM 进行公平意识数据增强以进行微调。实验表明，我们的方法在公平性排名方面优于现有方法，而且准确率仅略有下降。最后，我们强调社区需要识别和缓解隐性不公平现象，旨在避免强化人类-LLM 生态系统恶化的潜在恶化。]]></description>
      <guid>https://arxiv.org/abs/2311.07054</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向值得信赖的重新排序：一种简单而有效的弃权机制</title>
      <link>https://arxiv.org/abs/2402.12997</link>
      <description><![CDATA[arXiv:2402.12997v5 公告类型：替换 
摘要：神经信息检索 (NIR) 已显著改进基于启发式的信息检索 (IR) 系统。然而，故障仍然频繁发生，所使用的模型通常无法检索与用户查询相关的文档。我们通过提出一种针对现实世界约束量身定制的轻量级弃权机制来解决这一挑战，特别强调重新排名阶段。我们引入了一种用于评估黑盒场景中的弃权策略的协议（通常在依赖 API 服务时遇到），证明其有效性，并提出一种简单而有效的数据驱动机制。我们提供用于实验复制和弃权实施的开源代码，促进在不同情况下的更广泛采用和应用。]]></description>
      <guid>https://arxiv.org/abs/2402.12997</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>