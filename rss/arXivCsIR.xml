<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Tue, 04 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>零射击和有效的澄清需要在对话搜索中预测</title>
      <link>https://arxiv.org/abs/2503.00179</link>
      <description><![CDATA[ARXIV：2503.00179V1公告类型：新 
摘要：澄清需求预测（CNP）是对话搜索的关键任务，旨在预测是否提出澄清问题或对当前用户查询给出答案。但是，当前对CNP的研究遭受了有限的CNP培训数据和低效率的问题。在本文中，我们提出了一个零射击和有效的CNP框架（ZEF-CNP），其中我们首先以零拍的方式提示大型语言模型（LLMS），以生成两组合成查询：模棱两可和特定（不明式的）查询。然后，我们使用生成的查询来训练有效的CNP模型。 ZEF-CNP消除了培训期间对人类澄清需要的标签的需求，并避免在查询时使用具有高查询延迟的LLM。为了进一步提高合成查询的发电质量，我们设计了一个主题，信息需要和意识到的思想链（COT）提示策略（TIQ-COT）。此外，我们通过反事实查询生成（COQU）增强了TIQ-COT，该查询生成（COQU）首先引导LLMS生成特定/模棱两可的查询，然后顺序生成其相应的模棱两可/特定的查询。实验结果表明，与基于LLM的CNP预测变量相比，ZEF-CNP具有优异的CNP效率和效率。]]></description>
      <guid>https://arxiv.org/abs/2503.00179</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepRetrival：通过增强学习的强大查询生成信息检索</title>
      <link>https://arxiv.org/abs/2503.00223</link>
      <description><![CDATA[ARXIV：2503.00223V1公告类型：新 
摘要：信息检索系统对于有效访问大型文档收集至关重要。最近的方法利用了大型语言模型（LLM）来通过查询增强来提高检索性能，但通常依靠需要大量计算资源和手工标记数据的昂贵监督学习或蒸馏技术。在本文中，我们介绍了DeepRetReval，这是一种基于新颖的增强学习方法，该方法训练LLMS通过反复试验直接通过反复试验进行查询增强，而无需监督数据。通过使用检索召回作为奖励信号，我们的系统学会了生成有效的查询，以最大程度地提高文档检索性能。我们的初步结果表明，DeepRetrival显着胜过现有的最新方法，包括最近的潜在客户系统，在出版搜索中实现了60.82 \％的召回率，在使用较小模型的同时（3B vs. 7B vs. 7B参数）和不需要监督数据时，在出版搜索中获得了60.82 \％的召回率。这些结果表明，我们的强化学习方法为信息检索提供了更高效，有效的范式，可能会改变文档检索系统的景观。代码可从https://github.com/pat-jj/deepretrieval获得。]]></description>
      <guid>https://arxiv.org/abs/2503.00223</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在对话代理中检索和重新掌管的段落查询方法</title>
      <link>https://arxiv.org/abs/2503.00238</link>
      <description><![CDATA[ARXIV：2503.00238V1公告类型：新 
摘要：本文介绍了我们对TREC交互式知识援助曲目（IKAT）的方法，该方法的重点是改善对话信息寻求信息（CIS）系统。尽管CIS的最新进展提高了对话代理协助用户的能力，但在理解环境和检索跨领域和对话转弯的相关文档中仍然存在重大挑战。为了解决这些问题，我们通过开发与目标文档的预期格式保持一致的通道查询（PQ）来扩展生成的retrieve生成管道，以改善检索期间的查询文档匹配。我们提出了这种方法的两种变体：加权的重新加工以及短而长的段落。每种方法都利用元美洲驼模型来理解和生成查询和响应。段落排名评估结果表明，短期和长段落的方法优于组织者的基准，在基于骆驼的系统中表现最好，并获得了与基于GPT-4的系统相当的结果。这些结果表明该方法有效地平衡了效率和性能。调查结果表明，PQS通过目标文档改善了语义一致性，并证明了它们可以改善多转化对话系统的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.00238</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>伪知识图：元路径指导的检索和涂抹式llm的内部文字</title>
      <link>https://arxiv.org/abs/2503.00309</link>
      <description><![CDATA[ARXIV：2503.00309V1公告类型：新 
摘要：大语言模型的出现（LLM）彻底改变了自然语言处理。但是，这些模型在从广泛的数据集中检索精确信息方面面临挑战。开发了检索增强的生成（RAG），以将LLM与外部信息检索系统相结合，以增强响应的准确性和背景。尽管有所改善，但在大量，低信息密度的数据库中，布格仍然在综合检索方面挣扎，并且缺乏关系意识，从而导致了分散的答案。
  为了解决这个问题，本文介绍了伪知识图（PKG）框架，该框架旨在通过将元路径检索，内部文本和向量检索整合到LLMS中来克服这些限制。通过保留自然语言文本并利用各种检索技术，PKG提供了更丰富的知识表示，并提高了信息检索的准确性。使用开放式指南针和多型抹布基准进行广泛的评估，证明了该框架在管理大量数据和复杂关系方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.00309</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Qilin：具有应用程序级用户会话的多模式信息检索数据集</title>
      <link>https://arxiv.org/abs/2503.00501</link>
      <description><![CDATA[ARXIV：2503.00501V1公告类型：新 
摘要：用户生成的内容（UGC）社区，尤其是那些具有多模式内容的社区，通过将视觉和文本信息集成到结果（或项目）中来改善用户体验。通过搜索和推荐（S \＆amp; r）服务改善复杂系统中的用户体验的挑战引起了学术界和行业的极大关注。但是，缺乏高质量的数据集限制了多模式S \ r的研究进度。为了满足开发更好的S \ r Services的日益增长的需求，我们在本文（即Qilin）中提出了一种新颖的多模式检索数据集。该数据集是从Xiaohongshu收集的，这是一个受欢迎的社交平台，每月活跃用户超过3亿，平均搜索渗透率超过70 \％。与现有数据集相反，\ textsf {qilin}提供了全面的用户会话集合，并具有异构结果，例如图像文本注释，视频注释，商业笔记和直接答案，从而促进了跨不同任务设置的高级多模式神经检索模型的开发。为了更好地建模用户满意度并支持对异质用户行为的分析，我们还收集了广泛的应用程序级别的上下文信号和真正的用户反馈。值得注意的是，Qilin包含用户最喜欢的答案及其用于触发深度查询答案（DQA）模块的搜索请求的引用结果。这不仅允许培训\＆评估检索功能生成（RAG）管道，还允许对这种模块如何影响用户的搜索行为的探索。通过全面的分析和实验，我们提供了有趣的发现和见解，以进一步改善S \＆amp; r系统。我们希望\ textsf {qilin}将来将有助于使用S \＆amp; r服务的多模式内容平台的发展。]]></description>
      <guid>https://arxiv.org/abs/2503.00501</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Pinlanding：通过多模式AI进行网络规模的发现，内容优先的关键字着陆页生成</title>
      <link>https://arxiv.org/abs/2503.00619</link>
      <description><![CDATA[ARXIV：2503.00619V1公告类型：新 
摘要：诸如Pinterest之类的在线平台托管大量内容集合传统上依赖手动策展或用户生成的搜索日志来创建关键字着陆页（KLP） - 以主题为中心的集合页面，这些集合作为内容发现的入口点。尽管手动策划可确保质量，但它并不能扩展到数百万的收藏，并且搜索日志方法导致主题覆盖范围有限，并且不准确的内容匹配。在本文中，我们介绍了Pinlanding，这是一种新颖的内容优先架构，它改变了平台创建主题收藏的方式。我们的系统没有从用户行为中得出主题，而是采用多阶段管道，将视觉语言模型（VLM）组合用于属性提取，主题生成的大语言模型（LLM）以及基于夹子的双重编码体系结构来精确内容匹配。我们的模型在Fashion200K基准测试中实现了99.7％的回忆@10，展示了强大的属性理解能力。在搜索引擎优化的生产部署中，该系统的主题覆盖率增加了4倍，通过人类评估，基于传统的搜索日志方法的收集属性精度比传统的属性精度提高了14.29％。可以将架构推广到搜索流量以外的范围内为各种用户体验提供动力，包括内容发现和建议，提供了可扩展的解决方案，将非结构化内容转换为跨任何内容域的策划主题集合。]]></description>
      <guid>https://arxiv.org/abs/2503.00619</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Ordrankben：NLP中有序相关性的新型排名基准</title>
      <link>https://arxiv.org/abs/2503.00674</link>
      <description><![CDATA[ARXIV：2503.00674V1公告类型：新 
摘要：对排名任务的评估仍然是自然语言处理（NLP）的重大挑战，尤其是由于缺乏直接标签来实现现实世界情景。基准数据集在提供标准化的测试床上起着至关重要的作用，以确保公平比较，增强可重复性并实现进度跟踪，促进严格的评估并持续改进排名模型。现有的NLP排名基准通常使用二进制相关性标签或连续相关性得分，从而忽略了序相关得分。但是，二进制标签使相关性的差异过高，而连续得分缺乏明确的序数结构，这使得有效捕获细微的排名差异具有挑战性。为了应对这些挑战，我们介绍了Ordrankben，这是一种新颖的基准测试，旨在捕获多晶状体相关性的区别。与传统的基准不同，Ordrankben结合了结构化的序数标签，从而实现了更精确的排名评估。考虑到NLP中没有适当的数据集，我们构建了两个具有不同序数标签分布的数据集。我们进一步评估了三种模型类型，基于排名的语言模型，一般大语模型以及这些数据集中以排名大型语言模型的各种模型。实验结果表明，序数相关性建模提供了对排名模型的更精确评估，从而提高了其区分对需要细粒相关性差异的任务的排名项目之间多范围差异的能力。]]></description>
      <guid>https://arxiv.org/abs/2503.00674</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向有效的教育聊天机器人：基准测试抹布框架</title>
      <link>https://arxiv.org/abs/2503.00781</link>
      <description><![CDATA[ARXIV：2503.00781V1公告类型：新 
摘要：大型语言模型（LLM）已通过捕获大量基于文献的信息，从而在不依赖外部来源的情况下生成背景，从而在教育中得到了极大的利益。在本文中，我们提出了一个生成的AI驱动的大门提问框架（Gate代表工程学的研究生能力测试），该框架利用LLMS来解释Gate Solutions并在考试准备中为学生提供支持。我们进行了广泛的基准测试，以选择最佳嵌入模型和LLM，并根据诸如延迟，忠诚和相关性等标准评估我们的框架，并通过人类评估进行其他验证。我们的聊天机器人集成了最先进的嵌入模型和LLM，以提供准确的上下文感知响应。通过严格的实验，我们确定了平衡性能和计算效率的配置，从而确保可靠的聊天机器人满足学生需求。此外，我们讨论了数据处理和建模和实施解决方案所面临的挑战。我们的工作探讨了检索功能生成（RAG）在GATE Q/A说明任务中的应用，我们的发现证明了检索准确性和响应质量的显着提高。这项研究提供了开发有效的AI驱动教育工具的实用见解，同时突出了未来可用性和可扩展性的领域。]]></description>
      <guid>https://arxiv.org/abs/2503.00781</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合对话推荐系统</title>
      <link>https://arxiv.org/abs/2503.00999</link>
      <description><![CDATA[ARXIV：2503.009999V1公告类型：新 
摘要：作为提供个性化推荐体验的强大工具，对话推荐系统（CRS）已变得越来越流行。通过以对话方式直接与用户互动以了解其当前和细粒度的偏好，CRS可以迅速得出相关和合理的建议。但是，现有的对话推荐系统（CRS）通常依赖于集中的培训和部署过程，该过程涉及在集中式存储库中收集和存储明确交流的用户偏好。这些细粒度的用户偏好是完全可解剖的，可以轻松地用于推断有关用户（如果泄漏或违反）的敏感信息（例如财务状况，政治立场和健康信息）。为了解决CRS中的用户隐私问题，我们首先定义了一组隐私保护指南，以在对话推荐设置下保存用户隐私。基于这些准则，我们提出了一个新型联合对话推荐框架，该框架有效地降低了通过（i）通过（i）将历史兴趣估计阶段和交互式偏好启发阶段和（ii）严格界限隐私泄漏通过实施用户级别的差异隐私和确定的隐私权预算来实现界限的风险。通过广泛的实验，我们表明所提出的框架不仅满足了这些用户隐私保护指南，而且还使该系统即使与最先进的非私人对话建议方法相比，该系统也能够实现竞争性建议性能。]]></description>
      <guid>https://arxiv.org/abs/2503.00999</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向有效的LLM培训范式进行CTR预测</title>
      <link>https://arxiv.org/abs/2503.01001</link>
      <description><![CDATA[ARXIV：2503.01001V1公告类型：新 
摘要：大型语言模型（LLM）作为基于下一代排名的推荐系统表现出巨大的潜力。最近的许多作品表明，LLM可以显着超过常规点击率（CTR）预测方法。尽管结果如此有希望，但当前培训范式固有的计算效率低效率使得训练LLM在大型数据集上排名的建议任务特别具有挑战性。为了培训LLM进行CTR预测，大多数现有研究都采用了普遍的“滑窗”范式。给定$ m $用户交互的顺序，每次交互构建了独特的培训提示，将其指定为预测目标及其先前的$ n $交互作用。反过来，滑动窗口范式的总体复杂性为$ O（Mn^2）$，该范围随用户交互的长度线性扩展。因此，随着互动的长度的增加，直接采用通过这种策略培训LLM的LLM可能会导致高高的培训成本。为了减轻计算效率低下，我们提出了一种新颖的训练范式，即动态目标隔离（DTI），该训练在结构上平行于$ k $（$ k &gt;&gt; 1 $）目标相互作用的训练。此外，我们确定了两个主要的瓶颈 - 隐藏状态泄漏和过度拟合的位置偏见 - 将DTI限制为仅扩展到$ k $的少量值（例如5），然后提出了一个计算上的轻度解决方案，以有效地解决每个方案。通过对三个广泛采用的公共CTR数据集进行的广泛实验，我们从经验上表明，DTI平均将培训时间缩短了$ \ textbf {92％} $（例如，从$ 70.5 $ hrs降低到$ 5.31 $ HRS），而没有妥协Ctrictication Ctrictical Perdictication Perdictical Pervictical Pervictiation Perdictiation。]]></description>
      <guid>https://arxiv.org/abs/2503.01001</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果关系驱动的ADHOC信息检索的语义搜索管道</title>
      <link>https://arxiv.org/abs/2503.01003</link>
      <description><![CDATA[ARXIV：2503.01003V1公告类型：新 
摘要：我们为因果关系驱动的ADHOC信息检索（CAIR-2021）共享任务提供了无监督的语义搜索管道。 CAIR共享的任务扩展了传统信息检索，以支持收回包含查询事件原因的文档。成功的系统必须能够区分包含与查询事件因果关系的事件的因果描述的局部文档和文档。我们的方法涉及在语义和词汇指数上的多个查询策略中汇总结果。拟议的方法领导CAIR-2021排行榜，并优于传统的IR和纯语义嵌入方法。]]></description>
      <guid>https://arxiv.org/abs/2503.01003</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高系列算法的物质扩散算法和协作过滤的混合物</title>
      <link>https://arxiv.org/abs/2503.01305</link>
      <description><![CDATA[ARXIV：2503.01305V1公告类型：新 
摘要：建议系统面临平衡准确性和多样性的挑战，因为传统的协作过滤（CF）和基于网络的扩散算法表现出互补的限制。基于项目的CF（itemCF）通过项目相似性增强了多样性，但它损害了准确性。相反，质量扩散（MD）算法通过偏爱流行项目来确定准确性，但缺乏多样性。为了解决这一权衡，我们提出了HI系算法，将ItemCF与基于扩散的方法（MD，HHP，BHC，BD）集成的混合模型通过由参数$ \ epsilon $控制的非线性组合。这种杂交利用ItemCF的多样性和MD的准确性，扩展到高级扩散模型（HI-HHP，HI-BHC，HI-BD）以提高性能。 Movielens，Netflix和RYM数据集的实验表明，Hi系列算法的表现明显优于其基本算法。在稀疏数据（$ 20 \％$培训）中，HI-MD获得了0.8 \％$  -  $ 4.4 \％\％$ $ $ $ $ $ $ $ $ $ $ $ $ $比MD的改进，同时保持较高的多样性（多样性@20：459 vs. 396在Movielens上）。对于密集数据（$ 80 \％$培训），与BD相比，HI-BD将F1分数提高了$ 2.3 \％$  -  $ 5.2 \％$，多样性增长到$ 18.6 \％$。值得注意的是，混合模型在稀疏设置中始终提高新颖性，并具有强大的参数适应性。结果证明了战略杂交有效地打破了准确性多样性的权衡，从而提供了一个灵活的框架，以优化跨数据稀少度级别的推荐系统。]]></description>
      <guid>https://arxiv.org/abs/2503.01305</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>组成的多模式检索：对方法和应用的调查</title>
      <link>https://arxiv.org/abs/2503.01334</link>
      <description><![CDATA[ARXIV：2503.01334V1公告类型：新 
摘要：随着社交媒体，简短视频平台和电子商务的多模式数据的快速增长，基于内容的检索对于有效搜索和利用异质信息至关重要。随着时间的流逝，检索技术已从单峰检索（UR）演变为跨模式检索（CR），最近再到组成多模式检索（CMR）。 CMR使用户可以通过将参考视觉输入与文本修改集成，增强搜索灵活性和精度来检索图像或视频。本文对CMR进行了全面的审查，涵盖了其基本挑战，技术进步以及对监督，零射门和半监督学习范式的分类。我们讨论了关键的研究方向，包括监督CMR中的数据增强，模型架构和损失优化，以及零照片CMR中的转换框架和外部知识集成。此外，我们重点介绍了CMR在组成的图像检索，视频检索和人员检索中的应用潜力，这对电子商务，在线搜索和公共安全具有重要意义。鉴于其能够完善和个性化搜索体验，CMR有望成为下一代检索系统中的关键技术。策划的相关作品和资源列表可在以下网址提供：https：//github.com/kkzhang95/awesome-compose--composed-multi-modal-retreval]]></description>
      <guid>https://arxiv.org/abs/2503.01334</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分层因果变压器，具有异质信息，可扩展顺序推荐</title>
      <link>https://arxiv.org/abs/2503.01469</link>
      <description><![CDATA[ARXIV：2503.01469V1公告类型：新 
摘要：顺序建议系统利用变压器体系结构证明了捕获用户行为模式的非凡功能。这些系统的核心是构建有效项目表示形式的关键挑战。传统方法通过简单的串联或基本神经体系结构采用特征融合来创建统一表示序列。但是，这些常规方法无法解决项目属性的内在多样性，从而限制了变压器识别细粒模式和阻碍模型可扩展性的能力。尽管最近的研究已经开始将与用户相关的异质特征纳入项目序列，但同样至关重要的项目侧异质性特征仍被忽略。为了弥合这一方法论差距，我们提出了Heterrec-一个创新的框架，具有两个新的组件：异质令牌扁平层（HTFL）和分层因果变压器（HCT）。 HTFL先驱者是一种复杂的令牌化机制，该机制将项目分解为多维令牌集并将它们构造为异质序列，从而通过模型扩展实现了可扩展的性能增强。 HCT架构通过令牌级别和项目级的注意机制进一步增强了模式发现。此外，我们开发了一个列表的多步骤预测（LMP）目标功能来优化学习过程。包括现实世界中的工业平台在内的严格验证证实了Heterrec在有效和效率方面的最先进表现。]]></description>
      <guid>https://arxiv.org/abs/2503.01469</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>地图：通过LLM驱动的咨询对齐方式的动机感知的个性化搜索</title>
      <link>https://arxiv.org/abs/2503.01711</link>
      <description><![CDATA[ARXIV：2503.01711V1公告类型：新 
摘要：个性化的产品搜索旨在检索和排名与用户偏好和搜索意图相匹配的项目。尽管它们有效，但现有方法通常假定用户的查询完全捕捉了他们的真正动机。但是，我们对现实世界电子商务平台的分析表明，用户在搜索之前经常进行相关咨询，表明他们通过基于动机和需求的咨询来完善意图。咨询中隐含的动机是个性化搜索的关键增强因素。这个未开发的领域面临着新的挑战，包括将上下文动机与简洁的查询保持一致，弥合类别文本差距以及序列历史记录中的噪声。为了解决这些问题，我们提出了一种动机意识的个性化搜索（地图）方法。它通过LLM将查询和咨询嵌入到统一的语义空间中，利用注意专家（MOAE）的混合物优先考虑关键语义，并引入双重对准：（1）对比度学习对比学习，评论，评论和产品功能； （2）双向注意将动机感知的嵌入与用户偏好相结合。关于真实和合成数据的广泛实验显示，地图在检索和排名任务中的现有方法都优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.01711</guid>
      <pubDate>Tue, 04 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>