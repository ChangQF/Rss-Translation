<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 21 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 Silver Answers 进行多语言非事实性问答</title>
      <link>https://arxiv.org/abs/2408.10604</link>
      <description><![CDATA[arXiv:2408.10604v1 公告类型：交叉 
摘要：大多数现有的问答数据集 (QuAD) 主要关注高资源语言中基于事实的短上下文问答 (QA)。然而，此类数据集对于低资源语言的范围仍然有限，只有少数作品以基于事实的 QuAD 为中心，而没有以非事实的 QuAD 为中心。因此，这项工作提出了 MuNfQuAD，一个具有非事实问题的多语言 QuAD。它使用 BBC 新闻文章中的疑问副标题作为问题，并使用相应的段落作为银答案。该数据集包含 38 种语言的超过 370K 个 QA 对，涵盖几种低资源语言，是迄今为止最大的多语言 QA 数据集。根据 MuNfQuAD（黄金集）中 790 个 QA 对的手动注释，我们观察到 98% 的问题可以使用其对应的白银答案来回答。我们经过微调的答案段落选择 (APS) 模型优于基线。APS 模型在 MuNfQuAD 测试集和黄金集上的准确率分别为 80% 和 72%，宏 F1 分别为 72% 和 66%。此外，即使在白银标签上进行微调后，APS 模型也能有效地概括黄金集中的某种语言。]]></description>
      <guid>https://arxiv.org/abs/2408.10604</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:44 GMT</pubDate>
    </item>
    <item>
      <title>LSVOS 挑战赛第三名报告：基于 SAM2 和 Cutie 的 VOS</title>
      <link>https://arxiv.org/abs/2408.10469</link>
      <description><![CDATA[arXiv:2408.10469v2 公告类型：交叉 
摘要：视频对象分割 (VOS) 面临多项挑战，包括对象遮挡和碎片化、对象的消失和重新出现以及在拥挤场景中跟踪特定对象。在这项工作中，我们结合了最先进 (SOTA) 模型 SAM2 和 Cutie 的优势来解决这些挑战。此外，我们还探索了各种超参数对视频实例分割性能的影响。我们的方法在 LSVOS 挑战 VOS 赛道的测试阶段获得了 0.7952 的 J\&amp;F 分数，排名第三。]]></description>
      <guid>https://arxiv.org/abs/2408.10469</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:43 GMT</pubDate>
    </item>
    <item>
      <title>基于计划的文本生成检索分析</title>
      <link>https://arxiv.org/abs/2408.10490</link>
      <description><![CDATA[arXiv:2408.10490v1 公告类型：交叉 
摘要：在文本生成中，幻觉是指生成看似连贯但与既定知识相矛盾的文本。一个令人信服的假设是，当语言模型被赋予其参数知识之外的生成任务时（由于稀有性、新近性、领域等），就会出现幻觉。解决这一限制的常见策略是将检索机制注入语言模型，为模型提供与任务相关的知识。在本文中，我们利用指令调整的 LLM 的规划功能，并分析如何使用规划来指导检索以进一步降低幻觉的频率。我们在长文本生成任务上对我们提出的方法的几种变体进行了实证评估。通过提高相关事实的覆盖率，计划引导的检索和生成可以产生更具信息量的响应，同时提供更高的源文档归因率。]]></description>
      <guid>https://arxiv.org/abs/2408.10490</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:43 GMT</pubDate>
    </item>
    <item>
      <title>用于时间 QoS 预测的目标提示在线图协作学习</title>
      <link>https://arxiv.org/abs/2408.10555</link>
      <description><![CDATA[arXiv:2408.10555v1 公告类型：交叉 
摘要：在面向服务的架构中，准确预测服务质量 (QoS) 对于保持可靠性和提高用户满意度至关重要。然而，当前的方法往往忽略了高阶潜在协作关系，无法动态调整特定用户服务调用的特征学习，而这对于精确的特征提取至关重要。此外，由于管理长期依赖关系的挑战，依靠 RNN 来捕获 QoS 演变限制了检测长期趋势的能力。为了解决这些问题，我们提出了用于时间 QoS 预测的目标提示在线图协作学习 (TOGCL) 框架。它利用动态用户服务调用图来全面建模历史交互。在此图的基础上，它开发了一个目标提示图注意网络，以提取每个时间片上用户和服务的在线深度潜在特征，同时考虑隐式目标邻近协作关系和历史 QoS 值。此外，还采用了多层 Transformer 编码器来揭示时间特征演变模式，从而增强时间 QoS 预测。在 WS-DREAM 数据集上进行的大量实验表明，TOGCL 在多个指标上的表现明显优于最先进的方法，实现了高达 38.80% 的改进。这些结果强调了 TOGCL 对时间 QoS 预测的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.10555</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:43 GMT</pubDate>
    </item>
    <item>
      <title>学术搜索系统中的人工智能透明度：初步探索</title>
      <link>https://arxiv.org/abs/2408.10229</link>
      <description><![CDATA[arXiv:2408.10229v1 公告类型：交叉 
摘要：随着人工智能增强型学术搜索系统在研究人员中越来越受欢迎，调查其人工智能透明度对于确保对搜索结果的信任以及学术工作的可靠性和完整性至关重要。本研究采用定性内容分析方法来检查通过大学图书馆指南确定的 10 个人工智能增强型学术搜索系统样本的网站。这些系统的透明度评估水平各不相同：五个系统提供了有关其机制的详细信息，三个系统提供了部分信息，两个系统提供了很少或根本没有信息。这些发现表明，学术界正在推荐和使用功能不透明的工具，引发了人们对研究诚信的担忧，包括可重复性和研究人员责任问题。]]></description>
      <guid>https://arxiv.org/abs/2408.10229</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>OPDR：用于多模态科学数据语义嵌入的保序降维</title>
      <link>https://arxiv.org/abs/2408.10264</link>
      <description><![CDATA[arXiv:2408.10264v1 公告类型：交叉 
摘要：多模态科学数据管理中最常见的操作之一是在提供新项目后从数据库中搜索 $k$ 个最相似的项目（或 $k$ 个最近邻居，KNN）。尽管多模态机器学习模型的最新进展提供了一个 \textit{语义} 索引，即从原始多模态数据映射的所谓 \textit{嵌入向量}，但生成的嵌入向量的维数通常在数百或一千的数量级，这对于时间敏感的科学应用来说是不切实际的高。
这项工作提出降低输出嵌入向量的维数，使得前 $k$ 个最近邻居的集合在低维空间中不会发生变化，即保序降维 (OPDR)。为了开发这种 OPDR 方法，我们的核心假设是通过分析降维映射过程中关键参数之间的内在关系，可以构建一个定量函数来揭示目标（较低）维度与其他变量之间的相关性。为了证明这一假设，本文首先定义一个正式的度量函数来量化特定向量的 KNN 相似性，然后将度量扩展到全局度量空间的总体准确度，最后推导出目标（较低）维度与其他变量之间的闭式函数。我们将闭式函数合并到流行的降维方法、各种距离度量和嵌入模型中。]]></description>
      <guid>https://arxiv.org/abs/2408.10264</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>超越相关文档：使用大型语言模型进行以查询为中心的摘要的知识密集型方法</title>
      <link>https://arxiv.org/abs/2408.10357</link>
      <description><![CDATA[arXiv:2408.10357v1 公告类型：交叉 
摘要：以查询为中心的摘要 (QFS) 是自然语言处理中的一项基本任务，具有广泛的应用，包括搜索引擎和报告生成。然而，传统方法假设相关文档可用，但在实际场景中，尤其是在高度专业化的主题中，这可能并不总是成立。为了解决这一限制，我们提出了一种新颖的知识密集型方法，将 QFS 重新定义为知识密集型任务设置。该方法包括两个主要组件：检索模块和摘要控制器。检索模块根据给定的文本查询从大规模知识语料库中有效地检索潜在相关文档，消除了对预先存在的文档集的依赖。摘要控制器无缝集成了强大的基于大型语言模型 (LLM) 的摘要器和精心定制的提示，确保生成的摘要全面且与查询相关。为了评估我们方法的有效性，我们创建了一个新数据集以及人工注释的相关性标签，以便对检索和摘要性能进行全面评估。大量实验证明了我们方法的卓越性能，特别是它能够在不依赖相关文档可用性的情况下生成准确的摘要。这强调了我们的方法在各种查询场景中的多功能性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.10357</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>加速针对推荐系统的毒害攻击的代理再训练</title>
      <link>https://arxiv.org/abs/2408.10666</link>
      <description><![CDATA[arXiv:2408.10666v1 公告类型：新
摘要：最近的研究表明推荐系统容易受到数据中毒攻击，攻击者将精心制作的虚假用户交互注入推荐者的训练数据中以推广目标项目。当前的攻击方法涉及使用最新的虚假用户在中毒数据上迭代地重新训练代理推荐者以优化攻击。然而，这种重复的重新训练非常耗时，阻碍了对虚假用户的有效评估和优化。为了缓解这种计算瓶颈并在可承受的时间内开发更有效的攻击，我们分析了重新训练过程并发现一个用户/项目的表示变化将通过用户项目交互图引起级联效应。在理论指导下，我们引入了 \emph{梯度传递} (GP)，这是一种新技术，它在反向传播期间明确传递交互的用户项目对之间的梯度，从而近似级联效应并加速重新训练。只需一次更新，GP 就能实现与多次原始训练迭代相当的效果。在相同数量的重新训练周期下，GP 可以使代理推荐者更接近受害者。这种更准确的近似为优化虚假用户提供了更好的指导，最终导致增强的数据中毒攻击。在真实数据集上进行的大量实验证明了我们提出的 GP 的效率和有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.10666</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>矢量符号开源信息发现</title>
      <link>https://arxiv.org/abs/2408.10734</link>
      <description><![CDATA[arXiv:2408.10734v1 公告类型：新
摘要：联合、政府内、机构间和跨国 (CJIIM) 行动需要快速共享数据，而不受元数据管理和对齐的瓶颈限制。对于外部开源信息 (OSINF)，例如社交媒体，管理和对齐尤其不可行，而社交媒体在理解不断发展的情况方面变得越来越有价值。大型语言模型 (transformers) 有助于语义数据和元数据对齐，但在 CJIIM 环境中效率低下，其特点是拒绝、降级、间歇性和低带宽 (DDIL)。向量符号架构 (VSA) 支持使用高度紧凑的二进制向量（通常为 1-10k 位）进行语义信息处理，适用于 DDIL 设置。我们展示了 Transformer 模型与 VSA 的新型集成，将前者的语义匹配功能与后者的紧凑性和表示结构相结合。该方法通过概念验证 OSINF 数据发现门户进行了说明，该门户允许 CJIIM 运营中的合作伙伴以最少的元数据管理和低通信带宽共享数据源。这项工作是作为以前低技术就绪水平 (TRL) 研究与未来更高 TRL 技术演示和部署之间的桥梁进行的。]]></description>
      <guid>https://arxiv.org/abs/2408.10734</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>单语、跨语言和多语言信息检索的协同优化方法</title>
      <link>https://arxiv.org/abs/2408.10536</link>
      <description><![CDATA[arXiv:2408.10536v1 公告类型：新
摘要：跨不同语言的信息检索是自然语言处理中越来越重要的挑战。基于多语言预训练语言模型的最新方法取得了显著的成功，但它们往往以牺牲其他性能为代价来优化单语、跨语言或多语言检索性能。本文提出了一种新颖的混合批量训练策略，以同时提高单语、跨语言和多语言环境中的零样本检索性能，同时减轻语言偏见。该方法使用基于数据集大小采样的单语和跨语言问答对批次的混合来微调多语言语言模型。在 XQuAD-R、MLQA-R 和 MIRACL 基准数据集上的实验表明，与仅单语或仅跨语言训练相比，所提出的方法在各种语言和检索任务的零样本检索中始终取得相当或更优异的结果。与单语训练相比，混合批量训练还大大减少了多语检索中的语言偏差。这些结果证明了所提出的方法对于学习与语言无关的表示的有效性，该方法能够实现跨多种语言的强大零样本检索性能。]]></description>
      <guid>https://arxiv.org/abs/2408.10536</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的密集检索的任务级分布式鲁棒优化</title>
      <link>https://arxiv.org/abs/2408.10613</link>
      <description><![CDATA[arXiv:2408.10613v1 公告类型：新
摘要：基于大型语言模型的密集检索 (LLM-DR) 针对来自不同领域的大量异构微调集合进行了优化。然而，关于其训练数据分布的讨论仍然很少。以前的研究依赖于经验分配的数据集选择或采样率，这不可避免地会导致次优检索性能。在本文中，我们提出了一种用于 LLM-DR 微调的新任务级分布稳健优化 (tDRO) 算法，旨在通过端到端重新加权每个任务的数据分布来提高通用域泛化能力。tDRO 参数化域权重并使用缩放的域梯度更新它们。然后将优化的权重转移到 LLM-DR 微调以训练更稳健的检索器。实验表明，将我们的优化算法应用于一系列不同大小的 LLM-DR 模型后，大规模检索基准得到了最佳改进，并且数据集使用量减少了高达 30%。]]></description>
      <guid>https://arxiv.org/abs/2408.10613</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>CoRA：通过大型语言模型权重进行推荐的协作信息感知</title>
      <link>https://arxiv.org/abs/2408.10645</link>
      <description><![CDATA[arXiv:2408.10645v1 公告类型：新 
摘要：在大型语言模型 (LLM) 中引入协作信息是一种很有前途的技术，可以使 LLM 适应推荐。现有方法通过将协作特征与文本标记连接到统一的序列输入中，然后进行微调以使这些特征与 LLM 的输入空间对齐来实现这一点。虽然有效，但在这项工作中，我们发现在将 LLM 适应推荐任务时存在两个限制，这些限制阻碍了一般知识和协作信息的整合，导致推荐性能不佳。 (1) 使用推荐数据对 LLM 进行微调会破坏其固有的世界知识和基本能力，而这些对于解释和推断推荐文本至关重要。 (2) 将协作特征合并到文本提示中会破坏原始提示的语义，从而阻止 LLM 生成适当的输出。在本文中，我们提出了一种新的范式 CoRA（Collaborative LoRA 的首字母缩写词），它有一个协作权重生成器。该方法不是输入空间对齐，而是将协作信息与 LLM 的参数空间对齐，将它们表示为增量权重以更新 LLM 的输出。这样，LLM 就可以感知协作信息，而不会改变其一般知识和文本推理能力。具体来说，我们使用协作过滤模型来提取用户和项目嵌入，并通过协作权重生成器将它们转换为具有低秩属性的协作权重。然后，我们将协作权重合并到 LLM 的权重中，使 LLM 能够感知协作信号并生成个性化推荐，而无需在提示中进行微调或添加额外的协作标记。大量实验证实，CoRA 有效地将协作信息集成到 LLM 中，从而提高了推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2408.10645</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>通过统一上下文推荐器 (UniCoRn) 进行搜索和推荐的联合建模</title>
      <link>https://arxiv.org/abs/2408.10394</link>
      <description><![CDATA[arXiv:2408.10394v1 公告类型：新
摘要：搜索和推荐系统在许多服务中都是必不可少的，而且它们通常是单独开发的，导致维护复杂和技术负担。在本文中，我们提出了一个统一的深度学习模型，可以有效地处理这两项任务的关键方面。]]></description>
      <guid>https://arxiv.org/abs/2408.10394</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    <item>
      <title>通过主题嵌入增强文档检索</title>
      <link>https://arxiv.org/abs/2408.10435</link>
      <description><![CDATA[arXiv:2408.10435v1 公告类型：新
摘要：随着检索增强生成 (RAG) 的出现，文档检索系统重新引起了人们的兴趣。RAG 架构提供的幻觉率低于仅 LLM 应用程序。然而，众所周知，检索机制的准确性是这些应用程序效率的瓶颈。在语料库中有来自几个不同但相关主题的多个文档的情况下，会观察到检索性能低于标准的特殊情况。我们设计了一种新的矢量化方法，该方法考虑了文档的主题信息。本文介绍了这种新的文本矢量化方法，并在 RAG 的背景下对其进行了评估。此外，我们讨论了评估 RAG 系统的挑战，这与当前的情况有关。]]></description>
      <guid>https://arxiv.org/abs/2408.10435</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型实现高效、可部署的开放世界推荐知识注入</title>
      <link>https://arxiv.org/abs/2408.10520</link>
      <description><![CDATA[arXiv:2408.10520v1 公告类型：新
摘要：推荐系统 (RS) 在当今的在线服务中发挥着普遍的作用，但它们的闭环特性限制了它们对开放世界知识的访问。最近，大型语言模型 (LLM) 显示出弥合这一差距的希望。然而，以前直接将 LLM 实现为推荐器的尝试未能满足工业 RS 的要求，特别是在在线推理延迟和离线资源效率方面。因此，我们提出 REKI 从 LLM 获取有关用户和项目的两种外部知识。具体来说，我们引入了分解提示，以引出关于用户偏好和项目的准确知识推理。我们开发了针对不同规模场景的个体知识提取和集体知识提取，有效减少了离线资源消耗。随后，生成的知识通过混合专家集成网络进行有效的转换和压缩为增强向量，确保兼容性。然后可以使用获得的向量来增强任何常规推荐模型。我们还通过预处理和预存储来自 LLM 的知识来确保高效推理。实验表明，REKI 的表现优于最先进的基线，并且与许多推荐算法和任务兼容。现在，REKI 已部署到华为的新闻和音乐推荐平台，并在在线 A/B 测试中获得了 7% 和 1.99% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2408.10520</guid>
      <pubDate>Thu, 22 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    </channel>
</rss>