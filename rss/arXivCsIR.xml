<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 27 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过土壤碳辅助试点实现再生农业</title>
      <link>https://arxiv.org/abs/2411.16872</link>
      <description><![CDATA[arXiv:2411.16872v2 公告类型：新
摘要：缓解气候变化需要改变农业以最大限度地减少环境影响并增强气候适应力。再生农业实践可提高土壤有机碳 (SOC) 水平，从而改善土壤健康并封存碳。增加再生农业实践的挑战是随着时间的推移廉价地测量 SOC 并了解 SOC 如何受到再生农业实践和其他环境因素以及农场管理实践的影响。为了应对这一挑战，我们引入了 AI 驱动的土壤有机碳 Copilot，它可以自动提取复杂的多分辨率、多模态数据，以提供有关土壤健康和再生实践的大规模见解。我们的数据包括极端天气事件数据（例如干旱和野火事件）、农场管理数据（例如农田信息和耕作预测）和 SOC 预测。我们发现，整合公共数据和专门模型可以实现可持续农业的大规模本地化分析。在对加州各县的农业实践进行比较时，我们发现，多样化的农业活动可能会减轻耕作的负面影响；尽管极端天气条件严重影响 SOC，但堆肥可能会减轻 SOC 损失。最后，实施特定角色可以让农学家、农场顾问、政策制定者和其他利益相关者实施基于证据的战略，以促进可持续农业并增强气候适应能力。]]></description>
      <guid>https://arxiv.org/abs/2411.16872</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用跨语言搜索增强型法学硕士 (LLM) 消除学者姓名歧义</title>
      <link>https://arxiv.org/abs/2411.17102</link>
      <description><![CDATA[arXiv:2411.17102v1 公告类型：新
摘要：学者姓名消歧任务在各种现实场景中都至关重要，包括基于文献计量的奖项候选人评估、申请材料反欺诈措施等。尽管取得了重大进展，但当前的方法由于异构数据的复杂性而面临限制，通常需要大量人工干预。本文提出了一种新方法，通过利用跨多种语言的搜索增强语言模型来改进姓名消歧。通过利用搜索引擎强大的查询重写、意图识别和数据索引功能，我们的方法可以收集更丰富的信息来区分实体和提取配置文件，从而产生更全面的数据维度。鉴于大型语言模型 (LLM) 具有强大的跨语言能力，使用该技术优化增强检索方法为高效信息检索和利用提供了巨大的潜力。我们的实验表明，结合当地语言可以显着提高消歧性能，特别是对于来自不同地理区域的学者。这种多语言、搜索增强的方法为更有效、更准确的活跃学者姓名消歧义提供了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2411.17102</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于信息检索的 2D Matryoshka 训练</title>
      <link>https://arxiv.org/abs/2411.17299</link>
      <description><![CDATA[arXiv:2411.17299v1 公告类型：新
摘要：2D Matryoshka 训练是一种先进的嵌入表示训练方法，旨在跨各种层维度设置同时训练编码器模型。在使用子层进行嵌入时，该方法在语义文本相似性 (STS) 任务中表现出比传统训练方法更高的有效性。尽管它取得了成功，但两种已发布的实现之间存在差异，导致与基线模型的比较结果不同。在这项可重复性研究中，我们在 STS 任务上实现和评估了两个版本的 2D Matryoshka 训练，并将我们的分析扩展到检索任务。我们的研究结果表明，虽然这两个版本在子维度上都比传统的 Matryoshka 训练和传统的全尺寸模型训练方法更有效，但它们的表现并不优于在特定子层和子维度设置上单独训练的模型。此外，这些结果可以很好地推广到检索任务，无论是在监督（MSMARCO）还是零样本（BEIR）设置中。对不同损失计算的进一步探索揭示了更适合检索任务的实现，例如结合全维度损失和在更广泛的目标维度上进行训练。相反，一些直观的方法，例如将文档编码器固定为完整模型输出，并没有带来改进。我们的复现代码可在 https://github.com/ielab/2DMSE-Reproduce 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.17299</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向具有用户偏好联合可识别性的稳健跨域推荐</title>
      <link>https://arxiv.org/abs/2411.17361</link>
      <description><![CDATA[arXiv:2411.17361v1 公告类型：新
摘要：最近的跨域推荐 (CDR) 研究假设解开域共享和域特定用户表示可以缓解域差距并促进有效的知识转移。然而，在实践中实现完美的解开具有挑战性，因为 CDR 中的用户行为非常复杂，并且仅通过观察到的用户-项目交互无法完全捕捉到真正的潜在用户偏好。鉴于这种不切实际，我们建议对 {\it 联合可识别性} 进行建模，以建立跨域用户表示的唯一对应关系，确保即使用户行为在不同域中表现出变化，也能保持一致的偏好建模。为了实现这一点，我们引入了一个分层用户偏好建模框架，该框架按神经网络编码器的深度组织用户表示，从而允许分别处理浅层和更深层的子空间。在浅层子空间中，我们的框架为每个域内的每个用户建模兴趣质心，以概率方式确定用户的兴趣归属，并有选择地跨域对齐这些质心，以确保域无关特征的细粒度一致性。对于更深层的子空间表示，我们通过将其分解为共享的跨域稳定组件和域变体组件来强制实现联合可识别性，并通过双射变换链接以实现唯一对应。对具有不同域相关性的现实世界 CDR 任务的实证研究表明，即使在弱相关任务中，我们的方法也始终超越最先进的方法，这凸显了联合可识别性在实现稳健 CDR 方面的重要性。]]></description>
      <guid>https://arxiv.org/abs/2411.17361</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索撤回和非撤回作者合作网络中的结构动态：定量分析</title>
      <link>https://arxiv.org/abs/2411.17447</link>
      <description><![CDATA[arXiv:2411.17447v1 公告类型：新
摘要：撤稿破坏了科学文献的可靠性和未来研究的基础。分析撤稿论文中的合作网络可以识别风险因素，例如重复的合著者或机构。本研究使用 Retraction Watch 和 Scopus 中的 30 位有重大撤稿事件的作者的数据，比较了撤稿论文和非撤稿论文的网络结构。构建了合作网络并分析了网络属性。撤稿网络显示出层次化和集中化结构，而非撤稿网络表现出分布式协作，具有更强的聚类性和连通性。统计测试（包括 $t$ 检验和 Cohen&#39;s $d$）揭示了度中心性和加权度等指标的显著差异，突出了不同的结构动态。这些对易撤稿合作的见解可以指导提高研究诚信的政策。]]></description>
      <guid>https://arxiv.org/abs/2411.17447</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于高维近似最近邻搜索的高效数据感知距离比较操作</title>
      <link>https://arxiv.org/abs/2411.17229</link>
      <description><![CDATA[arXiv:2411.17229v1 公告类型：交叉 
摘要：高维近似 $K$ 近邻搜索 (AKNN) 是各种应用（包括信息检索）的基本任务。大多数现有的 AKNN 算法可以分解为两个主要部分，即候选生成和距离比较操作 (DCO)。虽然不同的方法有独特的生成候选的方法，但它们都共享相同的 DCO 过程。在本研究中，我们专注于加速 DCO 的过程，该过程在大多数现有的 AKNN 算法中占据时间成本的主导地位。为了实现这一点，我们提出了一种 \underline{D}ata-\underline{A}ware \underline{D}istance \underline{E} 估计方法，称为 \emph{DADE}，它在低维空间中近似 \emph{exact} 距离。我们从理论上证明 \emph{DADE} 中的距离估计在数据分布方面是 \emph{无偏的}。此外，我们提出了一种基于无偏距离估计公式的优化估计。此外，我们提出了一种假设检验方法来自适应地确定以足够置信度估计 \emph{exact} 距离所需的维数。我们将 \emph{DADE} 集成到广泛使用的 AKNN 搜索算法中，例如 \emph{IVF} 和 \emph{HNSW}，并进行了广泛的实验以证明其优越性。]]></description>
      <guid>https://arxiv.org/abs/2411.17229</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>公平与绩效和谐相处：数据去偏就是你所需要的</title>
      <link>https://arxiv.org/abs/2411.17374</link>
      <description><![CDATA[arXiv:2411.17374v1 公告类型：交叉 
摘要：机器学习 (ML) 预测和人类决策的公平性至关重要，ML 模型容易受到算法和数据偏见的影响，而人类决策则受到主观性和认知偏见的影响。本研究使用包含 870 个配置文件的真实世界大学录取数据集来调查公平性，利用三个 ML 模型，即 XGB、Bi-LSTM 和 KNN。文本特征使用 BERT 嵌入进行编码。对于个人公平性，我们使用一致性分数来评估具有不同背景的专家和 ML 模型之间的决策一致性。结果表明，ML 模型在公平性方面比人类高出 14.08% 到 18.79%。对于群体公平性，我们提出了一种性别去偏见流程，并证明了它在不影响预测性能的情况下消除性别特定语言的有效性。去偏见后，所有模型都保持或提高了分类准确性，验证了公平性和性能可以共存的假设。我们的研究结果强调了机器学习在保持高准确性的同时提高招生公平性的潜力，提倡结合人类判断和机器学习模型的混合方法。]]></description>
      <guid>https://arxiv.org/abs/2411.17374</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Agentic AI 可提高识别可持续发展目标贡献的精准度</title>
      <link>https://arxiv.org/abs/2411.17598</link>
      <description><![CDATA[arXiv:2411.17598v1 公告类型：交叉 
摘要：随着研究机构越来越多地致力于支持联合国的可持续发展目标 (SDG)，迫切需要根据这些目标准确评估其研究成果。当前的方法主要依赖于基于关键字的布尔搜索查询，将偶然的关键字匹配与真正的贡献混为一谈，从而降低了检索精度并使基准测试工作复杂化。本研究调查了自回归大型语言模型 (LLM) 作为评估代理的应用，以识别学术出版物中对 SDG 目标的相关学术贡献。使用通过 SDG 特定关键字查询检索到的学术摘要数据集，我们证明小型、本地托管的 LLM 可以区分对 SDG 目标的语义相关贡献和由于偶然的关键字匹配而检索到的文档，从而解决了传统方法的局限性。通过利用 LLM 的上下文理解，这种方法提供了一个可扩展的框架来改进与 SDG 相关的研究指标并为机构报告提供信息。]]></description>
      <guid>https://arxiv.org/abs/2411.17598</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让历史更易于阅读</title>
      <link>https://arxiv.org/abs/2411.17600</link>
      <description><![CDATA[arXiv:2411.17600v1 公告类型：交叉 
摘要：弗吉尼亚理工大学图书馆 (VTUL) 数字图书馆平台 (DLP) 托管数字收藏，为用户提供各种具有历史和文化重要性的文档。这些收藏不仅具有学术重要性，还为用户提供了当地历史事件的一瞥。我们的 DLP 包含由数字对象组成的收藏，这些对象具有复杂的布局、褪色的图像和难以阅读的手写文本，这使得在线访问这些材料具有挑战性。为了解决这些问题，我们将 AI 集成到我们的 DLP 工作流程中，并将数字对象中的文本转换为机器可读的格式。为了增强用户对我们历史收藏的体验，我们使用自定义 AI 代理进行手写识别、文本提取和大型语言模型 (LLM) 进行摘要。这张海报重点介绍了三个收藏，重点关注手写信件、报纸和数字化地形图。我们讨论了每个收藏所面临的挑战，并详细介绍了我们解决这些挑战的方法。我们提出的方法旨在通过使这些集合中的内容更易于搜索和导航来增强用户体验。]]></description>
      <guid>https://arxiv.org/abs/2411.17600</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>电子学位论文的章节级自动分类</title>
      <link>https://arxiv.org/abs/2411.17614</link>
      <description><![CDATA[arXiv:2411.17614v1 公告类型：交叉 
摘要：描述电子论文和学位论文 (ETD) 的传统档案实践依赖于广泛的高级元数据方案，这些方案无法捕捉这些长篇学术著作的深度、复杂性和跨学科性质。缺乏详细的章节级内容描述妨碍了研究人员定位特定章节或主题的能力，从而降低了可发现性和整体可访问性。通过提供章节级元数据信息，我们提高了 ETD 作为研究资源的有效性。这使学者更容易有效地浏览它们并提取有价值的见解。缺乏此类元数据进一步阻碍了跨学科研究，因为它模糊了各个领域的联系，阻碍了新的学术发现和合作。在本文中，我们提出了一种机器学习和人工智能驱动的解决方案来自动对 ETD 章节进行分类。该解决方案旨在提高可发现性并促进对章节的理解。我们的方法通过提供丰富的上下文描述来丰富传统的档案实践，从而促进有针对性的导航和改进的访问。我们的目标是支持跨学科研究，使 ETD 更易于访问。通过提供章节级分类标签并使用它们在我们开发的原型系统中进行索引，我们使 ETD 章节中的内容更易于发现并可用于满足各种学术需求。实施这种 AI 增强方法使档案馆能够更好地为研究人员服务，从而能够高效地访问相关信息并支持与 ETD 的更深入互动。这将增加 E​​TD 作为研究工具的影响力，促进跨学科探索，并加强档案馆在数据密集型学术领域中在学术交流中的作用。]]></description>
      <guid>https://arxiv.org/abs/2411.17614</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐模型如何放大流行偏差？从光谱角度的分析</title>
      <link>https://arxiv.org/abs/2404.12008</link>
      <description><![CDATA[arXiv:2404.12008v4 公告类型：替换 
摘要：推荐系统 (RS) 经常受到流行度偏差的困扰。在通常长尾数据集上训练推荐模型时，该模型不仅倾向于继承这种偏差，而且往往会加剧这种偏差，导致推荐列表中流行项目的过度代表。本研究进行了全面的实证和理论分析，揭示了这一现象的根本原因，得出了两个核心见解：1）项目流行度被记忆在推荐模型预测的得分矩阵的主谱中；2）维度崩溃现象放大了主谱的相对突出性，从而加剧了流行度偏差。基于这些见解，我们提出了一种新颖的去偏差策略，该策略利用谱范数正则化器来惩罚主奇异值的幅度。我们开发了一种有效的算法，通过利用得分矩阵的谱特性来加快谱范数的计算。我们已经针对七个真实数据集和三个测试范例进行了广泛的实验，以验证所提出方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.12008</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM-RankFusion：缓解 LLM 排名中的内在不一致性</title>
      <link>https://arxiv.org/abs/2406.00231</link>
      <description><![CDATA[arXiv:2406.00231v2 公告类型：替换 
摘要：通过提示大型语言模型 (LLM) 对段落进行排名可以在现代信息检索 (IR) 系统中取得良好的效果。对排名列表进行排序的常用方法是提示 LLM 进行成对或成组比较，这通常依赖于排序算法。但是，基于排序的方法需要一致的比较才能正确地对段落进行排序，我们表明 LLM 经常违反这一点。我们在基于 LLM 的成对比较中确定了两种内在不一致性：顺序不一致导致在切换段落顺序时产生冲突的结果，以及传递不一致导致所有偏好对中出现非传递三元组。我们对这些不一致的研究与理解和提高基于相对偏好的任何排名方案的稳定性有关。在本文中，我们提出了 LLM-RankFusion，这是一个基于 LLM 的排名框架，可缓解这些不一致并生成可靠的排名列表。 LLM-RankFusion 使用上下文学习 (ICL) 来演示顺序无关的比较和校准，以估计两段文章之间的潜在偏好概率，从而缓解顺序不一致问题。然后，我们通过汇总来自多个排名器的排名结果来解决传递性不一致问题。在我们的实验中，我们通过经验证明 LLM-RankFusion 可以显著减少不一致的比较结果，通过使最终排名列表更加稳健来提高排名质量。我们的代码可在 \href{https://github.com/XHMY/LLM-RankFusion}{https://github.com/XHMY/LLM-RankFusion} 获得]]></description>
      <guid>https://arxiv.org/abs/2406.00231</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于异构图的解缠表征学习框架，用于多目标跨领域推荐</title>
      <link>https://arxiv.org/abs/2407.00909</link>
      <description><![CDATA[arXiv:2407.00909v2 公告类型：替换 
摘要：CDR（跨域推荐），即利用来自多个域的信息，是解决推荐系统中数据稀疏问题的关键。以前的大多数研究要么集中在单目标 CDR（STCDR），利用来自源域的数据来提高模型在目标域上的性能，要么应用双目标 CDR（DTCDR），通过整合来自源域和目标域的数据。此外，多目标 CDR（MTCDR）是 DTCDR 的泛化，它能够捕获不同域之间的链接。在本文中，我们提出了 HGDR（基于异构图的解缠表示学习框架），这是一种端到端异构网络架构，其中图卷积层用于模拟不同域之间的关系，同时利用解缠表示的思想来获取域共享和域特定信息。首先，通过收集来自多个域的用户和项目生成共享异构图，而无需任何其他辅助信息。其次，我们使用 HGDR 计算所有域中用户和项目的解耦表示。在真实数据集和在线 A/B 测试上的实验证明，我们提出的模型可以有效地在域之间传递信息并达到 SOTA 性能。代码可以在这里找到：https://github.com/NetEase-Media/HGCDR。]]></description>
      <guid>https://arxiv.org/abs/2407.00909</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习位置注意力机制以实现顺序推荐</title>
      <link>https://arxiv.org/abs/2407.02793</link>
      <description><![CDATA[arXiv:2407.02793v3 公告类型：替换 
摘要：基于自注意力的网络在顺序推荐任务中取得了显著的表现。这些模型的一个关键组成部分是位置编码。在本研究中，我们深入研究了学习到的位置嵌入，表明它通常可以捕捉标记之间的距离。基于这一见解，我们引入了直接学习位置关系的新型注意力模型。大量实验表明，我们提出的模型 \textbf{PARec} 和 \textbf{FPARec} 优于以前基于自注意力的方法。代码可以在这里找到：https://github.com/NetEase-Media/FPARec。]]></description>
      <guid>https://arxiv.org/abs/2407.02793</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM4DSR：利用大型语言模型对序列推荐进行去噪</title>
      <link>https://arxiv.org/abs/2408.08208</link>
      <description><![CDATA[arXiv:2408.08208v2 公告类型：替换 
摘要：顺序推荐器根据用户的历史交互序列生成推荐。然而，在实践中，这些收集到的序列经常受到噪声交互的污染，这严重损害了推荐性能。由于缺乏指示噪声的明确监督信号，在没有额外信息的情况下准确识别这种噪声交互尤其具有挑战性。大型语言模型 (LLM) 配备了广泛的开放知识和语义推理能力，为弥补这一信息差距提供了一条有希望的途径。然而，在顺序推荐中使用 LLM 进行去噪面临着显著的挑战：1) 直接应用预训练的 LLM 可能无法胜任去噪任务，经常会产生无意义的响应；2) 即使经过微调，LLM 输出的可靠性仍然存在疑问，尤其是考虑到去噪任务的复杂性和 LLM 固有的幻觉问题。
为了应对这些挑战，我们提出了 LLM4DSR，这是一种使用 LLM 去噪序列推荐的定制方法。我们构建了一个自监督微调任务来激活 LLM 识别噪声项目并建议替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度响应进行序列校正。值得注意的是，LLM4DSR 与模型无关，允许将校正后的序列灵活地应用于各种推荐模型。大量实验验证了 LLM4DSR 优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2408.08208</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>