<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 13 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>LLM驱动的有用性标签用于IR评估</title>
      <link>https://arxiv.org/abs/2503.08965</link>
      <description><![CDATA[ARXIV：2503.08965V1公告类型：新 
摘要：在信息检索（IR）域中，评估在优化搜索体验和支持各种用户意图方面起着至关重要的作用。在最近的LLM时代，已经进行了研究以使文档相关性标签自动化，因为这些标签传统上是由众包工人分配的 - 这一过程既是时间又消耗且耗费很高。这项研究着重于LLM生成的实用性标签，这是一个关键的评估指标，考虑了用户的搜索意图和任务目标，而相关性不足。我们的实验利用任务级，查询级别和文档级功能以及用户搜索行为信号，这对于定义文档的实用性至关重要。我们的研究发现，（i）预先训练的LLM可以通过了解全面的搜索任务会话来生成中等的有用性标签，（ii）预先培训的LLM在提供搜索会话上下文时在简短的搜索会话中执行更好的判断。此外，我们研究了LLM是否可以捕获相关性和有用性之间的独特差异，同时进行消融研究以确定最关键的指标以获得准确的实用性标签生成。总之，这项工作通过评估关键指标并优化现实世界中的实用性来探讨LLM生成的有用性标签。]]></description>
      <guid>https://arxiv.org/abs/2503.08965</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用检索增强生成LLM进行自动元数据描述生成以增强数据目录</title>
      <link>https://arxiv.org/abs/2503.09003</link>
      <description><![CDATA[ARXIV：2503.09003V1公告类型：新 
摘要：数据目录是组织和访问多种数据资产收集的存储库，但是它们的有效性取决于企业用户可以轻松查找相关内容。不幸的是，组织内的许多数据目录遭受有限的可搜索性，因为元数据（如资产描述）不足。因此，需要以内容生成解决方案以可扩展的方式富集和策展元数据。本文探讨了与元数据创建相关的挑战，并提出了使用基于检索的几弹技术与生成性大语言模型（LLM）相关的独特及时富集概念。文献还考虑了对现有内容的鉴定，并研究了几乎没有预读的LLM（Llama，gpt3.5）的行为，通过基于准确的，事实，接地和毒性来评估其绩效，通过评估其绩效，通过评估其绩效，来评估几乎没有射击的fineTuned LLM（LLAMA2-7B）。对于生成的内容，我们的初步结果显示出超过80％的Rouge-1 F1。这暗示了87％-88％的实例按原样接受或策划数据管理员的次要编辑。通过以最准确的方式自动为表和列生成描述，该研究试图为企业提供一个整体框架，以有效地扩展元数据策划并丰富其数据目录，从而极大地提高数据编目可搜索性和整体可用性。]]></description>
      <guid>https://arxiv.org/abs/2503.09003</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LREF：电子商务基于LLM的新型相关性框架</title>
      <link>https://arxiv.org/abs/2503.09223</link>
      <description><![CDATA[ARXIV：2503.09223V1公告类型：新 
摘要：查询和产品相关性预测是确保在电子商务搜索中获得流畅的用户体验的关键组成部分。传统研究主要集中于基于BERT的模型，以评估查询与产品之间的语义相关性。但是，这些方法的歧视范式和有限的知识能力限制了它​​们完全理解查询与产品之间相关性的能力。随着大语言模型（LLM）的快速发展，最近的研究开始探索其对工业搜索系统的应用，因为LLMS为推理过程提供了广泛的世界知识和灵活的优化。尽管如此，直接利用LLM进行相关预测任务仍引入了新的挑战，包括对数据质量的高需求，对推理过程的细致优化的必要性以及可能导致过度回调的乐观偏见。为了克服上述问题，本文提出了一个名为基于LLM的相关性框架（LREF）的新颖框架，旨在增强电子商务搜索相关性。该框架包括三个主要阶段：具有数据选择的监督微调（SFT），多个思想链（多核）调整以及直接偏好优化（DPO），以进行偏差。我们通过在大规模实际数据集以及在线A/B测试上进行一系列离线实验来评估框架的性能。结果表明，离线和在线指标都有显着改善。最终，该模型被部署在著名的电子商务应用程序中，从而获得了可观的商业福利。]]></description>
      <guid>https://arxiv.org/abs/2503.09223</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向下一代推荐系统：LLMS个性化推荐助理的基准</title>
      <link>https://arxiv.org/abs/2503.09382</link>
      <description><![CDATA[ARXIV：2503.09382V1公告类型：新 
摘要：推荐系统（RECSYS）广泛用于各种现代数字平台，并引起了极大的关注。传统的推荐系统通常仅关注固定和简单的建议方案，因此很难在交互式范式中推广到新的和看不见的建议任务。最近，大型语言模型（LLM）的进步彻底改变了Recsys的基础架构，将其演变推向了更聪明和互动的个性化推荐助手。但是，大多数现有的研究都依赖于固定的特定任务提示模板来生成建议并评估个性化助手的绩效，这限制了对其能力的全面评估。这是因为常用数据集缺乏反映现实世界建议方案的高质量文本用户查询，因此不适合评估基于LLM的个性化建议助手。为了解决此差距，我们引入了RecBench+，这是一种新的数据集基准测试，旨在访问LLMS时LLM时期的复杂用户推荐需求的能力。 Recbench+包括一组涵盖硬条件和软偏好的各种查询，难度级别不同。我们评估了在Recbench+上常用的LLM，并在下面发现的结果：1）LLMS证明了作为推荐助理的初步能力，2）LLM在处理有明确陈述的条件的查询方面更好，同时面对需要推理或包含误解信息的查询面临的挑战。我们的数据集已在https://github.com/jiani-huang/recbench.git上发布。]]></description>
      <guid>https://arxiv.org/abs/2503.09382</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习级联排名为一个网络</title>
      <link>https://arxiv.org/abs/2503.09492</link>
      <description><![CDATA[ARXIV：2503.09492V1公告类型：新 
摘要：级联排名是大规模TOP-K选择系统（例如推荐和广告平台）中的普遍体系结构。传统培训方法着眼于单阶段优化，忽略了阶段之间的相互作用。诸如RankFlow和FS-LTR之类的最新进展引入了互动感知的培训范例，但仍在努力1）将培训目标与整个级联排名的目标保持一致（即端到端召回）和2）学习有效的协作模式。为了应对这些挑战，我们提出了LCRON，它引入了一种新型的替代损失函数，该能力源自级别的级别真实项目的下限概率，从而确保与系统的整体目标保持一致。根据派生结合的属性，我们进一步设计了每个阶段的辅助损失，以驱动这种结合的降低，从而导致更健壮和有效的TOP-K选择。 LCRON可以将整个级联排名系统的端到端培训作为统一网络。实验结果表明，LCRON对公共基准和工业应用的现有方法有了显着改善，解决了级联排名培训的关键局限性并显着提高了系统性能。]]></description>
      <guid>https://arxiv.org/abs/2503.09492</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在LLM投资建议中暴露产品偏差</title>
      <link>https://arxiv.org/abs/2503.08750</link>
      <description><![CDATA[ARXIV：2503.08750V1公告类型：交叉 
摘要：作为新一代推荐引擎的大型语言模型（LLMS）具有强大的摘要和数据分析功能，超过了范围和性能的传统推荐系统。一个有希望的申请是投资建议。在本文中，我们在LLM投资建议中揭示了一种新的产品偏见，其中LLMS对特定产品表现出系统性的偏好。这样的偏好可以巧妙地影响用户投资决策，这可能导致产品和财务泡沫的估值膨胀，从而对个人投资者和市场稳定构成风险。为了全面研究产品偏见，我们开发了一条自动管道，以在五个资产类别（股票，共同基金，加密货币，储蓄和投资组合）的数据集中创建567,000个样本的数据集。使用此数据集，我们介绍了BF在LLM投资建议中有关产品偏见的首次研究。我们的发现表明，LLMS表现出清晰的产品偏好，例如某些股票（例如，来自Apple的AAPL&#39;和Microsoft的“ MSFT”）。值得注意的是，即使在应用了辩护技术之后，这种偏见仍然存在。我们敦促AI研究人员注意LLM投资建议及其含义中的产品偏见，以确保数字空间和市场的公平性和安全性。]]></description>
      <guid>https://arxiv.org/abs/2503.08750</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>质量超过数量？基于LLM的策展，用于数据有效的Audio-Video基础模型</title>
      <link>https://arxiv.org/abs/2503.09205</link>
      <description><![CDATA[ARXIV：2503.09205V1公告类型：交叉 
摘要：整合训练多模式基础模型的音频和视觉数据仍然具有挑战性。我们提出了音频视频矢量对齐（AVVA），该矢量对齐（AVVA）通过大型语言模型（LLM）的数据策划管道使视听场景（AV）场景内容对象超出单纯的时间同步。具体而言，AVVA使用耳语（基于语音的音频基础模型）在双重编码对比度学习框架中为视频评分并选择高质量的培训剪辑。对听觉的评估，英勇和VGGSOUND表明，这种方法可以通过策划的数据大大降低准确性提高。例如，与ImageBind相比，AVVA在VGGSOUND上的音频到视频检索的TOP-1准确性提高了7.6％，尽管仅训练了192个小时的精心过滤数据（vs. 5800小时）。此外，一项消融研究强调，将数据数量用于数据质量可以提高性能，从而在录音机，英勇和VGGSOUND上，相应的前3精度提高47.8、48.4和58.0个百分点，而不是未繁殖的碱基。尽管这些结果强调了AVVA的数据效率，但我们也讨论了LLM驱动的策展的开销，以及如何在较大域中缩放或近似它。总体而言，AVVA提供了一种可行的途径，通往更健壮，无文本的视听学习，并提高了检索精度。]]></description>
      <guid>https://arxiv.org/abs/2503.09205</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>XVLM2VEC：使用自我知识蒸馏将基于LVLM的嵌入模型调整为多语言</title>
      <link>https://arxiv.org/abs/2503.09313</link>
      <description><![CDATA[ARXIV：2503.09313V1公告类型：交叉 
摘要：在当前文献中，大多数嵌入模型基于仅编码的变压器体系结构，以提取给定输入的密集且有意义的表示，这可以是文本，图像等。随着语言建模的最新进展，由于引入了大型语言模型，已经探索了从这些大型训练的模型中提取嵌入的可能性。但是，当前的研究集中于英语中的文本嵌入，这也是对这些模型进行培训的主要语言。此外，很少有模型考虑多模式和多语言输入。鉴于这一点，我们提出了一种适应方法，用于对英语数据进行培训的大型视觉语言模型，以提高其在提取多语言和多模式嵌入方面的性能。最后，我们设计并引入了一个基准，以评估多语言和多模式嵌入模型的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.09313</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>搜索R1：培训LLMS以推理和利用搜索引擎，并通过增强学习</title>
      <link>https://arxiv.org/abs/2503.09516</link>
      <description><![CDATA[ARXIV：2503.09516V1公告类型：交叉 
摘要：有效获取外部知识和最新信息对于大型语言模型（LLM）中的有效推理和文本生成至关重要。检索增强和工具使用培训方法，其中将搜索引擎视为工具缺乏复杂的多转弯检索灵活性或需要大规模监督数据。在推理过程中提示具有推理能力的高级LLM使用搜索引擎并不是最佳的，因为LLM无法学习如何与搜索引擎进行最佳互动。本文介绍了search-r1，这是deepSeek-r1模型的扩展，其中LLM仅通过增强学习（RL）学习，以自主生成（多个）搜索查询，并在实时检索中逐步推理。 Search-R1通过多转弯搜索交互优化LLM的推出，利用将令牌掩盖检索进行稳定的RL培训和简单的基于结果的奖励功能。在七个问题的数据集上进行的实验表明，Search-R1在SOTA碱基上提高了26％（QWEN2.5-7B），21％（QWEN2.5-3B）和10％（Llama3.2-3B）。本文进一步提供了对RL优化方法，LLM选择和响应长度动力学的经验见解。代码和模型检查点可在https://github.com/petergriffinjin/search-r1上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.09516</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分别分发推荐系统的双测试时间培训</title>
      <link>https://arxiv.org/abs/2407.15620</link>
      <description><![CDATA[ARXIV：2407.15620V2公告类型：替换 
摘要：深度学习已被广​​泛应用于推荐系统，该系统最近取得了革命性的进步。但是，大多数现有的基于学习的方法都假定在培训阶段和测试阶段之间的用户和项目分布保持不变。但是，用户和项目功能的分布自然可以在实际情况下改变，可能导致建议性能大大降低。这种现象可以作为分布（OOD）推荐问题的表达。为了应对这一挑战，我们提出了一个新型的双重测试时间训练框架，以推荐DT3OR。在DT3OR中，我们在测试时间阶段合并了模型适应机制，以仔细更新推荐模型，从而使模型可以特别适应移动的用户和项目功能。具体来说，我们提出了一项自我验证任务和对比任务，以帮助模型在测试时间阶段学习用户不变的兴趣偏好和变体用户/项目特征，从而促进对变化功能的平稳适应。此外，我们提供理论分析以支持双重测试时间培训框架背后的理由。据我们所知，本文是通过测试时间训练策略解决OOD建议的第一项工作。我们在三个具有各种骨架的数据集上进行实验。与其他最先进的基线相比，全面的实验结果证明了DT3OR的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.15620</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的图形嵌入式用于基于会话的推荐以及项目功能的嵌入</title>
      <link>https://arxiv.org/abs/2502.13763</link>
      <description><![CDATA[ARXIV：2502.13763V2公告类型：替换 
摘要：在基于会话的推荐系统中，预测基于会话中用户的先前行为。最新的顺序建议算法要么使用图形神经网络在图中对会话进行建模，要么通过利用项目功能来利用会话的相似性。在本文中，我们结合了这两种方法，并提出了一种新颖的方法，即图形卷积网络扩展（GCNext），该方法通过图卷积网络将项目特征直接纳入图表。 GCNext创建了一个丰富的功能项目共发生图形，并以无监督的方式学习相应的项目嵌入。我们在三个数据集上显示，将gcnext集成到顺序推荐算法中可以显着提高最近邻邻方法的性能以及神经网络模型。我们的灵活扩展很容易纳入最先进的方法，并将MRR@20提高到12.79％。]]></description>
      <guid>https://arxiv.org/abs/2502.13763</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在rag-text2sql系统中平衡内容大小</title>
      <link>https://arxiv.org/abs/2502.15723</link>
      <description><![CDATA[arxiv：2502.15723v2公告类型：替换 
摘要：大型语言模型（LLM）已成为将自然语言查询转换为SQL命令的有前途的解决方案，从而实现了无缝的数据库交互。但是，这些文本到SQL（Text2SQL）系统面临固有的局限性，幻觉，过时的知识和无法追踪的推理。为了应对这些挑战，将检索型生成（RAG）与Text2SQL模型的集成已引起关注。 RAG是一种检索机制，提供了基本的上下文信息，例如表模式和元数据，以增强查询生成过程。尽管具有潜力，但RAG + Text2SQL系统仍易受检索文档的质量和大小。尽管更丰富的文档内容可以提高模式的相关性和检索精度，但它也引入了噪音，增加了幻觉的风险，并随着Text2SQL模型的迅速尺寸的增加而降低查询保真度。这项研究调查了文档规模和质量之间的细微折衷，旨在实现优化系统性能的平衡。确定在发生性能降解的位置以及可行的策略以减轻这些挑战的位置。此外，我们探讨了Text2SQL模型中幻觉的现象，并强调了精选文档表现在最小化错误中的关键作用。我们的发现为增强了RAG + Text2SQL系统的鲁棒性提供了路线图，从而为现实世界应用提供了实用的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.15723</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Multiconir：迈向多条件信息检索</title>
      <link>https://arxiv.org/abs/2503.08046</link>
      <description><![CDATA[ARXIV：2503.08046V2公告类型：替换 
摘要：在本文中，我们介绍了Multiconir，这是第一个旨在评估多条件方案中检索模型的基准。与主要关注搜索引擎的单条件查询的现有数据集不同，多诺尼尔通过合并五个不同的域：书籍，电影，人，医疗案件和法律文件来捕获现实世界中的复杂性。我们提出三个任务，以系统地评估有关多条件鲁棒性，单调相关性排名和查询格式灵敏度的检索和重新依据模型。我们的发现表明，现有的检索和重读模型与多条件检索斗争，随着查询复杂性的增加，重读者的性能降低了严重的降级。我们进一步研究了检索模型和重新依给模型之间的性能差距，探讨了这些差异的潜在原因，并分析了不同的合并策略对条件安置敏感性的影响。最后，我们强调了粒度和NV插入的优势，这些优势表明了对多条件查询的适应性增强，为将来的检索模型提供了见解。该代码和数据集可在https://github.com/eit-nlp/multiconir上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.08046</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>合并 - 用于静态音乐情感识别的双峰数据集</title>
      <link>https://arxiv.org/abs/2407.06060</link>
      <description><![CDATA[ARXIV：2407.06060V2公告类型：替换 - 交叉 
摘要：近年来，音乐情感识别（MER）领域一直稳定发展，并从功能工程，机器学习和深度学习中做出了贡献。景观也从以音频为中心的系统转变为结合音频和歌词的双峰合奏。但是，严重缺乏公共和相当大的双峰数据库阻碍了双峰音频 - 乐园系统的发展和改进。本文提出了使用半自动方法创建的三个新音频，歌词和双峰MER研究数据集，称为Merge。为了全面评估所提出的数据集并建立了基准进行基准测试，我们使用功能工程，机器学习和深度学习方法对每种模式进行了几个实验。此外，我们提出并验证固定的火车估计测试拆分。获得的结果证实了所提出的数据集的生存能力，使用深神经网络实现了双峰分类的79.21％F1得分的最佳总体结果。]]></description>
      <guid>https://arxiv.org/abs/2407.06060</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>侦察：通过强大嘈杂对应学习的关系一致性增强真实的对应歧视</title>
      <link>https://arxiv.org/abs/2502.19962</link>
      <description><![CDATA[ARXIV：2502.19962V2公告类型：替换 - 交叉 
摘要：我们可以准确地从包含不匹配数据对的多模式数据集中确定真实的对应关系吗？现有方法主要强调跨模态对象表示之间的相似性匹配，从而有可能忽略模式中关键关系的一致性，这对于区分真实和错误的对应关系特别重要。这样的遗漏通常会冒着将否定性误认为是积极因素的风险，从而导致意外的绩效退化。为了解决这个问题，我们提出了一个一般关系一致性学习框架，即重新侦察，以准确区分多模式数据之间的真实对应关系，从而有效地减轻了不匹配引起的不良影响。具体而言，侦察利用了一种新颖的关系一致性学习，以确保不同方式与模态内模式之间的跨模式关系一致性分别确保双模式关系的一致性。得益于对关系的这种双重约束，侦察大大提高了其对真实对应歧视的有效性，因此可靠地滤除了错配对的成对，以减轻错误监督的风险。在三个广泛使用的基准数据集上进行了广泛的实验，包括Flickr30k，MS-Coco和概念标题，以证明与其他SOTA相比，侦察的有效性和优越性。该代码可在以下网址提供：https：//github.com/qxzha/recon。]]></description>
      <guid>https://arxiv.org/abs/2502.19962</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>