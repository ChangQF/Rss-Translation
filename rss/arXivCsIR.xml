<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 20 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>评估生成搜索引擎在对抗性事实问题上的鲁棒性</title>
      <link>https://arxiv.org/abs/2403.12077</link>
      <description><![CDATA[arXiv:2403.12077v1 公告类型：交叉
摘要：生成搜索引擎有潜力改变人们在线搜索信息的方式，但现有大语言模型（LLM）支持的生成搜索引擎生成的响应可能并不总是准确的。尽管如此，检索增强生成加剧了安全问题，因为对手可能通过巧妙地操纵索赔中最脆弱的部分来成功逃避整个系统。为此，我们建议评估生成搜索引擎在现实和高风险环境中的鲁棒性，其中对手只有黑盒系统访问权限并试图欺骗模型返回错误的响应。通过对各种生成搜索引擎（例如 Bing Chat、PerplexityAI 和 YouChat）跨不同查询的全面人工评估，我们证明了对抗性事实问题在诱导错误响应方面的有效性。此外，与没有检索的法学硕士相比，检索增强生成对事实错误的敏感性更高。这些发现凸显了这些系统的潜在安全风险，并强调在部署前进行严格评估的必要性。]]></description>
      <guid>https://arxiv.org/abs/2403.12077</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>TMU 参加 TREC 临床试验轨道 2023</title>
      <link>https://arxiv.org/abs/2403.12088</link>
      <description><![CDATA[arXiv:2403.12088v1 公告类型：交叉
摘要：本文描述了多伦多城市大学参与 2023 年 TREC 临床试验轨道的情况。作为任务的一部分，我们在实验中利用先进的自然语言处理技术和神经语言模型来检索最相关的临床试验。我们阐述了作为 V-TorontoMU 团队一部分的运行提交的总体方法、实验设置和实施结果。]]></description>
      <guid>https://arxiv.org/abs/2403.12088</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:57 GMT</pubDate>
    </item>
    <item>
      <title>InBox：使用兴趣框嵌入的知识图推荐</title>
      <link>https://arxiv.org/abs/2403.12649</link>
      <description><![CDATA[arXiv:2403.12649v1 公告类型：新
摘要：知识图（KG）在现代推荐系统中变得至关重要，可以有效提高性能和可解释性。从根本上说，推荐系统的目标是根据历史交互来识别用户兴趣并推荐合适的项目。然而，现有的工作忽视了两个关键挑战：（1）兴趣对应于一组潜在的大量相关项目，（2）缺乏对 KG 信息和兴趣连接的明确、细粒度的利用。这导致在以单一方式建模时无法反映实体和兴趣之间的区别。此外，用于推荐的知识图中概念的粒度往往较粗，无法匹配用户兴趣的细粒度性质。这种同质化限制了知识图谱数据和兴趣连接的精确利用。为了解决这些限制，我们引入了一种新颖的基于嵌入的模型，称为 InBox。具体来说，各种知识图实体和关系被嵌入为点或框，而用户兴趣被建模为包含交互历史的框。将兴趣表示为框可以包含与该兴趣相关的项目点的集合。我们进一步提出，兴趣包含不同的基本概念，框交集自然支持概念组合。在三个训练步骤中，InBox 在推荐任务上显着优于 HAKG 和 KGIN 等最先进的方法。进一步的分析为不同 KG 数据的变量值提供了有意义的见解，以供推荐。总之，InBox 通过基于框的兴趣和概念建模来推进推荐系统，以实现复杂的知识图开发。]]></description>
      <guid>https://arxiv.org/abs/2403.12649</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>ERASE：深度推荐系统的基准特征选择方法</title>
      <link>https://arxiv.org/abs/2403.12660</link>
      <description><![CDATA[arXiv:2403.12660v1 公告类型：新
摘要：深度推荐系统（DRS）越来越依赖大量的特征字段来获得更精确的推荐。因此，有效的功能选择方法对于进一步提高准确性和优化存储效率以满足部署需求变得至关重要。这一研究领域，特别是在 DRS 背景下，还处于萌芽阶段，面临着三个核心挑战。首先，研究论文中不同的实验设置常常会产生不公平的比较，从而掩盖了实际的见解。其次，现有文献缺乏基于大规模数据集的对选择属性的详细分析以及选择技术和 DRS 主干网之间的彻底比较，限制了研究结果的普适性并阻碍了 DRS 的部署。最后，研究通常侧重于比较特征选择方法可实现的峰值性能，这种方法通常在计算上无法确定最佳超参数，并且忽略了评估这些方法的鲁棒性和稳定性。为了弥补这些差距，本文提出了 ERASE，这是 DRS 特征选择的综合基准。 ERASE 包括对 11 种特征选择方法的全面评估，涵盖传统和深度学习方法，跨越四个公共数据集、私有工业数据集和一个现实世界的商业平台，实现了显着的增强。我们的代码可在线获取，以便于复制。]]></description>
      <guid>https://arxiv.org/abs/2403.12660</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>通过顺序学习过程的列表生成检索模型</title>
      <link>https://arxiv.org/abs/2403.12499</link>
      <description><![CDATA[arXiv:2403.12499v1 公告类型：新
摘要：最近，提出了一种新颖的生成检索（GR）范式，其中学习单个序列到序列模型来直接生成给定查询的相关文档标识符（docids）列表。现有的 GR 模型通常采用最大似然估计 (MLE) 进行优化：这涉及在给定输入查询的情况下最大化单个相关 docid 的似然性，并假设每个 docid 的似然性独立于列表中的其他 docid。在本文中，我们将这些模型称为逐点方法。虽然逐点方法已被证明在 GR 背景下是有效的，但由于它忽视了排名涉及对列表进行预测的基本原则，因此被认为是次优的。在本文中，我们通过引入另一种列表方法来解决这一限制，该方法使 GR 模型能够优化文档列表级别的相关性。具体来说，我们将排序的 docid 列表的生成视为一个序列学习过程：在每一步，我们学习一个参数子集，在给定（前面的）顶部 $i-1 的情况下，最大化第 $i$ 个 docid 的相应生成可能性$ 文档。为了形式化序列学习过程，我们设计了 GR 的位置条件概率。为了减轻推理过程中波束搜索对生成质量的潜在影响，我们根据相关性等级对模型生成的docids的生成可能性进行相关性校准。我们对代表性的二进制和多级相关性数据集进行了广泛的实验。我们的实证结果表明，我们的方法在检索性能方面优于最先进的 GR 基线。]]></description>
      <guid>https://arxiv.org/abs/2403.12499</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>美团外卖中基于上下文的长用户行为序列快速推荐策略</title>
      <link>https://arxiv.org/abs/2403.12566</link>
      <description><![CDATA[arXiv:2403.12566v1 公告类型：新
摘要： 在美团外卖的推荐系统中，我们正在处理不断加长的用户行为序列，这对有效建模用户偏好提出了越来越大的挑战。现有的顺序推荐模型往往无法捕获长期依赖关系或过于复杂，使得美团外卖独特业务需求的实现变得复杂。为了更好地建模用户兴趣，我们考虑根据用户的偏好从用户广泛的历史行为中选择相关子序列。在这个特定场景中，我们注意到用户交互的上下文对其偏好有重大影响。为此，我们引入了一种称为基于上下文的快速推荐策略的新方法来解决长序列的问题。我们首先识别与目标上下文共享相似用户偏好的上下文，然后根据这些识别的上下文定位相应的 PoIs。这种方法消除了为每个候选 PoI 选择子序列的必要，从而避免了高时间复杂度。具体来说，我们实现了一种基于原型的方法来精确定位反映相似用户偏好的上下文。为了提高准确性和可解释性，我们采用 PoI 属性（例如类别和价格）的 JS 散度作为上下文之间相似性的度量。集成原型和上下文节点的时间图有助于合并时间信息。然后，我们考虑目标环境和短期用户偏好来确定适当的原型。接下来，我们利用与这些原型一致的上下文来生成一个子序列，旨在预测具有目标注意力的 CTR 和 CTCVR 分数。自2023年推出以来，美团外卖的展示推荐系统就采用了这一策略，导致点击率飙升4.6%，GMV提升4.2%。]]></description>
      <guid>https://arxiv.org/abs/2403.12566</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>多模式建议的调整和培训框架</title>
      <link>https://arxiv.org/abs/2403.12384</link>
      <description><![CDATA[arXiv:2403.12384v1 公告类型：新
摘要：随着多媒体应用的发展，多模式推荐发挥着重要作用，因为它们可以利用用户交互之外的丰富上下文。现有方法主要以多模态信息为辅助，利用它们来帮助学习ID特征；然而，多模态内容特征和ID特征之间存在语义差距，直接使用多模态信息作为辅助会导致用户和项目的表示不一致。在本文中，我们首先系统地研究了多模态推荐中的错位问题，并提出了一种名为 AlignRec 的解决方案。在AlignRec中，推荐目标被分解为三种对齐方式，即内容内的对齐方式、内容与分类ID之间的对齐方式以及用户与项目之间的对齐方式。每个对齐都具有特定的目标函数，并集成到我们的多模式推荐框架中。为了有效地训练我们的 AlignRec，我们建议从预训练第一个对齐开始以获得统一的多模态特征，然后将这些特征作为输入来训练以下两个对齐。由于分析每个多模态特征是否有助于训练至关重要，因此我们设计了三类新的指标来评估中间性能。我们对三个真实世界数据集进行的广泛实验一致验证了 AlignRec 与九个基线相比的优越性。我们还发现AlignRec生成的多模态特征比当前使用的多模态特征更好，这些特征将被开源。]]></description>
      <guid>https://arxiv.org/abs/2403.12384</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>具有大型语言模型的会话系统的可解释的用户满意度估计</title>
      <link>https://arxiv.org/abs/2403.12388</link>
      <description><![CDATA[arXiv:2403.12388v1 公告类型：新
摘要：准确且可解释的用户满意度评估（USE）对于理解、评估和持续改进会话系统至关重要。用户对通用（ChatGPT 和 Bing Copilot）和面向任务（客户服务聊天机器人）对话系统中的不同对话模式表达满意或不满意。基于特征化 ML 模型或文本嵌入的现有方法在提取可概括的模式方面存在不足，并且难以解释。在这项工作中，我们表明法学硕士可以比基于嵌入的方法更有效地从自然语言话语中提取可解释的用户满意度信号。此外，法学硕士可以通过使用标记示例的监督的迭代提示框架来定制使用。由此产生的方法，即用户满意度评分标准的监督提示（SPUR），不仅具有更高的准确性，而且更易于解释，因为它通过学习的评分标准和详细的细分来对用户满意度进行评分。]]></description>
      <guid>https://arxiv.org/abs/2403.12388</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:54 GMT</pubDate>
    </item>
    <item>
      <title>丰富用户购物历史：以分级推荐系统赋能电商</title>
      <link>https://arxiv.org/abs/2403.12096</link>
      <description><![CDATA[arXiv:2403.12096v1 公告类型：新
摘要：推荐系统可以通过分析用户的购物历史来提供准确的推荐。更丰富的用户历史记录会带来更准确的推荐。然而，在实际应用中，用户更喜欢在电子商务平台上寻找价格最低的商品。换句话说，大多数用户同时在多个电商平台上购物；用户购物历史的不同部分在不同的电子商务平台之间共享。因此，我们在本研究中假设任何电子商务平台都拥有用户历史的完整记录，但只能访问其中的某些部分。如果推荐系统能够首先预测缺失的部分并适当地丰富用户的购物历史，那么就有可能更准确地推荐下一个商品。我们的推荐系统利用用户购物历史来提高预测准确性。所提出的方法在 NDCG@10 和 HR@10 方面均显示出显着改进。]]></description>
      <guid>https://arxiv.org/abs/2403.12096</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>通过移动树学习时隙偏好以进行下一个 POI 推荐</title>
      <link>https://arxiv.org/abs/2403.12100</link>
      <description><![CDATA[arXiv:2403.12100v1 公告类型：新
摘要：下一个兴趣点（POI）推荐任务旨在根据用户当前的签到轨迹提供 POI 的动态排名。该任务的推荐性能取决于通过基于位置的社交网络（LBSN）数据对用户个性化行为模式的全面理解。虽然之前的研究已经熟练地捕捉了用户签到轨迹中的顺序模式和过渡关系，但在设计一种机制来识别不同时间段（例如中午、下午或晚上）的特殊行为模式方面仍然存在明显的差距。在本文中，我们介绍了一种称为“移动树”的创新数据结构，专为分层描述用户的签到记录而定制。移动树包含多粒度时隙节点，以了解不同时间段内的用户偏好。同时，我们提出了移动树网络（MTNet），这是一种基于移动树的个性化偏好学习的多任务框架。我们开发了一个四步节点交互操作，将特征信息从叶节点传播到根节点。此外，我们采用多任务训练策略来推动模型学习鲁棒的表示。综合实验结果证明了 MTNet 在三个真实 LBSN 数据集上优于十个最先进的下一个 POI 推荐模型，证实了移动树促进的时隙偏好学习的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.12100</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:53 GMT</pubDate>
    </item>
    <item>
      <title>使用多通道情感识别进行分组电影选择</title>
      <link>https://arxiv.org/abs/2403.12087</link>
      <description><![CDATA[arXiv:2403.12087v1 公告类型：新
摘要：经常以小组形式进行的社交活动包括看电视或电影。选择一部能够吸引不同群体情感倾向的电影可能很棘手。提出团体电影建议最困难的方面之一是在成员之间达成一致。同时，情感是连接电影和观众最重要的组成部分。目前的研究提出了一种集体电影选择方法，该方法采用来自多种来源的情感分析，例如电影海报、配乐和文本。我们的研究处于音乐、文本、彩色图像和群体决策中的情感识别技术的交叉点，为在群体环境中处理电影选择的复杂动态提供了实用的工具。调查参与者被赋予了情感类别，并被要求选择最适合特定电影的情感。真实分数和预测分数之间的初步比较结果显示了使用情绪检测进行群体电影推荐的有效性。这样的系统有潜力增强电影推荐系统。]]></description>
      <guid>https://arxiv.org/abs/2403.12087</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>数字病理学中的基础模型和信息检索</title>
      <link>https://arxiv.org/abs/2403.12090</link>
      <description><![CDATA[arXiv:2403.12090v1 公告类型：新
摘要：本文回顾了数字病理学中基础模型、法学硕士、生成人工智能、信息检索和 CBIR 的最新技术]]></description>
      <guid>https://arxiv.org/abs/2403.12090</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>匹配英语地址的方法</title>
      <link>https://arxiv.org/abs/2403.12092</link>
      <description><![CDATA[arXiv:2403.12092v1 公告类型：新
摘要：由于每个单词所具有的位置重要性及其所指的地理范围，地址在文本数据中占据着一个利基位置。匹配地址的任务每天都会发生，存在于邮件重定向、实体解析等各个领域。我们的工作定义并形式化了一个框架，用于生成英语地址的匹配和不匹配对，并用它来评估各种方法自动执行地址匹配。这些方法从基于距离的方法到深度学习模型差异很大。通过研究这些方法的精确度、召回率和准确度指标，我们了解了最适合这种地址匹配任务设置的方法。]]></description>
      <guid>https://arxiv.org/abs/2403.12092</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>超越节拍：歌曲流行的秘诀？机器学习方法</title>
      <link>https://arxiv.org/abs/2403.12079</link>
      <description><![CDATA[arXiv:2403.12079v1 公告类型：新
摘要：在数据驱动算法和 Spotify 等流媒体平台兴起的推动下，音乐流行度预测已引起业界和学术界的高度关注。本研究旨在使用包含 1957 年至 2020 年不同流派的 30,000 首歌曲的数据集，探索各种机器学习模型在预测歌曲流行度方面的预测能力。方法：我们采用普通最小二乘法 (OLS)、多元自适应回归样条 (MARS)、随机森林和 XGBoost 算法来分析歌曲特征及其对流行度的影响。结果：普通最小二乘 (OLS) 回归分析表明，类型是流行度的主要影响因素，并且随着时间的推移呈现出显着的趋势。 MARS 建模强调了变量之间的复杂关系，特别是工具性和持续时间等特征。随机森林和 XGBoost 模型强调了流派（尤其是 EDM）在预测流行度方面的重要性。尽管性能存在差异，但随机森林成为最有效的模型，与平均分数相比，预测精度提高了 7.1%。尽管流派很重要，但预测歌曲流行度仍然具有挑战性，因为观察到的音乐相关特征的变化表明流派和其他因素之间存在复杂的相互作用。因此，虽然响度和歌曲持续时间等某些特征可能会影响流行度得分，但准确预测歌曲的成功仍然难以实现。]]></description>
      <guid>https://arxiv.org/abs/2403.12079</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>介绍 Terrorizer：一种用于合并专利受让人中公司名称的算法</title>
      <link>https://arxiv.org/abs/2403.12083</link>
      <description><![CDATA[arXiv:2403.12083v1 公告类型：新
摘要：公司名称消歧问题对从专利中提取有用信息提出了重大挑战。这个问题使研究结果产生偏差，因为它大多低估了公司的专利数量，特别是跨国公司，它们以过多的名称申请专利，包括同一实体的不同拼写，最终是公司子公司的名称。迄今为止，解决这些挑战一直依赖于劳动密集型的基于字典或字符串匹配的方法，而专利受让人在大型数据集上的协调问题大多尚未解决。为了弥补这一差距，本文描述了 Terrorizer 算法，这是一种基于文本的算法，利用自然语言处理 (NLP)、网络理论和基于规则的技术来协调记录为专利受让人的公司名称的变体。特别是，该算法遵循其前因的三方结构，即解析、匹配和过滤阶段，添加了一个原始的“知识增强”阶段，用于丰富每个受让人姓名的可用信息。我们在一组 325,917 个公司名称上使用 Terrorizer，这些公司是 2005 年至 2022 年美国专利商标局 (USPTO) 授予的专利的受让人。Terrorizer 的性能是在四个黄金标准数据集上进行评估的。此验证步骤向我们展示了两个主要内容：第一是 Terrorizer 在不同类型的数据集上的性能相似，证明我们的算法具有良好的泛化能力。其次，当将其性能与 PatentsView 中当前用于同一任务的算法进行比较时（Monath 等人，2021），它获得了更高的 F1 分数。最后，我们使用树结构 Parzen 估计器（TPE）优化算法进行超参数调整。我们的最终结果是初始名称集减少了 42% 以上。]]></description>
      <guid>https://arxiv.org/abs/2403.12083</guid>
      <pubDate>Wed, 20 Mar 2024 06:16:51 GMT</pubDate>
    </item>
    </channel>
</rss>