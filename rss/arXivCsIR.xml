<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 22 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>事件感知视频语料库时刻检索</title>
      <link>https://arxiv.org/abs/2402.13566</link>
      <description><![CDATA[arXiv:2402.13566v1 公告类型：交叉
摘要：视频语料库时刻检索（VCMR）是一种实用的视频检索任务，专注于使用自然语言查询来识别大量未经修剪的视频语料库中的特定时刻。现有的 VCMR 方法通常依赖于帧感知视频检索，计算查询帧和视频帧之间的相似性，以根据最大帧相似性对视频进行排名。然而，这种方法忽略了嵌入在帧之间信息中的语义结构，即事件、人类理解视频的关键要素。受此启发，我们提出了 EventFormer，这是一种明确利用视频中的事件作为视频检索的基本单元的模型。该模型通过事件推理和分层事件编码来提取事件表示。事件推理模块将连续且视觉上相似的帧表示分组为事件，而分层事件编码在帧和事件级别对信息进行编码。我们还引入了锚点多头自注意力，以鼓励 Transformer 捕获视频中相邻内容的相关性。 EventFormer的训练是通过对VCMR的两个子任务进行双分支对比学习和对偶优化来进行的。 TVR、ANetCaps 和 DiDeMo 基准测试的大量实验显示了 EventFormer 在 VCMR 中的有效性和效率，取得了新的最先进的结果。此外，EventFormer 的有效性也在部分相关视频检索任务上得到了验证。]]></description>
      <guid>https://arxiv.org/abs/2402.13566</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:19 GMT</pubDate>
    </item>
    <item>
      <title>改进信息提取结构化语言模型输出的简单而有效的方法</title>
      <link>https://arxiv.org/abs/2402.13364</link>
      <description><![CDATA[arXiv:2402.13364v1 公告类型：交叉
摘要：大型语言模型（LLM）在根据指令生成非结构化自然语言方面表现出了令人印象深刻的能力。然而，当负责生成符合特定结构化格式的文本时，它们的性能可能不一致，这在命名实体识别 (NER) 或关系提取 (RE) 等应用中至关重要。为了解决这个问题，本文介绍了一种有效的方法 G&amp;O，来增强其结构化文本生成能力。它将生成过程分为两步：最初，法学硕士以自然语言生成答案作为中间响应。随后，法学硕士被要求使用中间响应作为上下文，将输出组织成所需的结构。 G&amp;O 有效地将内容生成与结构化过程分开，减少了同时完成两个正交任务的压力。在零样本 NER 和 RE 上进行测试，结果表明，以最少的额外努力即可显着提高 LLM 性能。这种简单且适应性强的提示技术还可以与其他策略（例如自我一致性）相结合，以进一步提升法学硕士在各种结构化文本生成任务中的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.13364</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:18 GMT</pubDate>
    </item>
    <item>
      <title>ARL2：通过自我引导的自适应相关性标签来对齐黑盒大语言模型的检索器</title>
      <link>https://arxiv.org/abs/2402.13542</link>
      <description><![CDATA[arXiv:2402.13542v1 公告类型：交叉
摘要：检索增强生成通过整合来自外部知识源的相关信息来增强大型语言模型（LLM）。这使得法学硕士能够适应特定领域并减轻知识密集型任务中的幻觉。然而，由于其单独的训练过程和法学硕士的黑盒性质，现有的检索器经常与法学硕士不一致。为了应对这一挑战，我们提出了 ARL2，一种利用法学硕士作为标记器的检索器学习技术。 ARL2 利用 LLM 对相关证据进行注释和评分，从而能够从强大的 LLM 监督中学习检索器。此外，ARL2使用自适应自我训练策略来管理高质量和多样化的相关数据，可以有效降低注释成本。大量实验证明了 ARL2 的有效性，与最先进的方法相比，在 NQ 上实现了 5.4% 的准确率提高，在 MMLU 上实现了 4.6% 的准确率提高。此外，ARL2 还表现出强大的迁移学习能力和强大的零样本泛化能力。我们的代码将发布在\url{https://github.com/zhanglingxi-cs/ARL2}。]]></description>
      <guid>https://arxiv.org/abs/2402.13542</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:18 GMT</pubDate>
    </item>
    <item>
      <title>Science Checker 重装上阵：透明度和逻辑推理的双向范式</title>
      <link>https://arxiv.org/abs/2402.13897</link>
      <description><![CDATA[arXiv:2402.13897v1 公告类型：新
摘要：信息检索是一个快速发展的领域。然而，它在科学和工业海量信息中仍然面临着显着的局限性，例如稀疏检索中的语义分歧和词汇差距，语义搜索中的精度低和缺乏可解释性，或者生成模型中的幻觉和过时信息。在本文中，我们引入了一种两块方法来解决长文档的这些障碍。第一个块通过查询扩展来检索相关文档来增强稀疏检索中的语言理解。第二个块通过仅使用长文档中传播的信息为复杂问题提供全面且信息丰富的答案来深化结果，从而实现双向参与。在管道的各个阶段，中间结果都会呈现给用户，以帮助理解系统的推理。我们相信这种双向方法在科学信息检索领域的透明度、逻辑思维和全面理解方面带来了重大进步。]]></description>
      <guid>https://arxiv.org/abs/2402.13897</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:17 GMT</pubDate>
    </item>
    <item>
      <title>异构用户推荐系统中的保留引起的偏差</title>
      <link>https://arxiv.org/abs/2402.13959</link>
      <description><![CDATA[arXiv:2402.13959v1 公告类型：新
摘要：我研究了具有用户流入和流失动态的推荐系统（RS）的概念模型。当流入和流失平衡时，用户分布达到稳定状态。更改推荐算法会改变稳定状态并创建一个过渡期。在此期间，RS 的行为与其新的稳态不同。特别是，在过渡期获得的 A/B 实验指标是 RS 长期性能的有偏差指标。然而，学者和实践者经常在引入新算法后不久进行 A/B 测试以验证其有效性。这种 A/B 实验范式被广泛认为是评估 RS 改进的黄金标准，因此可能会得出错误的结论。我还简要讨论了用户保留动态造成的数据偏差。]]></description>
      <guid>https://arxiv.org/abs/2402.13959</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:17 GMT</pubDate>
    </item>
    <item>
      <title>用于可扩展推荐的线性时间图神经网络</title>
      <link>https://arxiv.org/abs/2402.13973</link>
      <description><![CDATA[arXiv:2402.13973v1 公告类型：新
摘要：在信息爆炸的时代，推荐系统是为用户提供个性化推荐的重要工具。推荐系统的关键是根据之前的用户-项目交互来预测用户的未来行为。由于图神经网络（GNN）在捕获用户-项目交互数据中的高阶连接性方面具有强大的表达能力，近年来人们对利用图神经网络（GNN）来提高推荐系统的预测性能越来越感兴趣。尽管如此，经典的矩阵分解（MF）和深度神经网络（DNN）方法由于其可扩展性优势，仍然在现实世界的大规模推荐系统中发挥着重要作用。尽管存在 GNN 加速解决方案，但基于 GNN 的推荐系统是否能够像经典 MF 和 DNN 方法一样有效地扩展仍然是一个悬而未决的问题。在本文中，我们提出了一种线性时间图神经网络（LTGNN）来扩展基于 GNN 的推荐系统，以实现与经典 MF 方法相当的可扩展性，同时保持 GNN 强大的表达能力以实现卓越的预测精度。进行了大量的实验和消融研究，以验证所提出算法的有效性和可扩展性。我们基于 PyTorch 的实现已经可用。]]></description>
      <guid>https://arxiv.org/abs/2402.13973</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:17 GMT</pubDate>
    </item>
    <item>
      <title>通过对抗图 Dropout 进行基于图的协同过滤的一般去偏</title>
      <link>https://arxiv.org/abs/2402.13769</link>
      <description><![CDATA[arXiv:2402.13769v1 公告类型：新
摘要：图神经网络（GNN）在推荐系统中表现出了令人印象深刻的性能，特别是在协作过滤（CF）中。关键在于聚合用户-项目交互图上的邻域信息以增强用户/项目表示。然而，我们发现这种聚合机制有一个缺点，它放大了交互图中存在的偏差。例如，用户与项目的交互可以由无偏见的真实兴趣和各种偏见因素（例如项目受欢迎程度或曝光率）驱动。然而，当前的聚合方法结合了所有信息，包括有偏见和无偏见的信息，导致有偏见的表示学习。因此，基于图的推荐器可能会学习到用户/项目的扭曲视图，从而阻碍对其真实偏好和概括的建模。为了解决这个问题，我们引入了一种名为 Adversarial Graph Dropout (AdvDrop) 的新颖框架。它区分无偏见和有偏见的交互，从而实现无偏见的表示学习。对于每个用户/项目，AdvDrop 采用对抗性学习将邻域分为两种视图：一种具有减轻偏见的交互，另一种具有偏见感知的交互。在特定于视图的聚合之后，AdvDrop 确保偏差缓解和偏差感知表示保持不变，从而使它们免受偏差的影响。我们在涵盖一般偏差和特定偏差的五个公共数据集上验证了 AdvDrop 的有效性，展示了显着的改进。此外，正如深入分析所揭示的，我们的方法展示了有意义的子图分离，并实现了基于图的 CF 模型的无偏表示。我们的代码可在 https://github.com/Arthurma71/AdvDrop 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2402.13769</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:16 GMT</pubDate>
    </item>
    <item>
      <title>LLM4SBR：在基于会话的推荐中集成大型语言模型的轻量级且有效的框架</title>
      <link>https://arxiv.org/abs/2402.13840</link>
      <description><![CDATA[arXiv:2402.13840v1 公告类型：新
摘要：传统的基于会话的推荐（SBR）利用匿名用户的会话行为序列进行推荐。虽然这种策略效率很高，但它牺牲了项目固有的语义信息，使得模型很难理解会话的真实意图，导致推荐结果缺乏可解释性。最近，大型语言模型（LLM）在各个领域蓬勃发展，为解决上述挑战带来了希望。受法学硕士影响的启发，探索法学硕士与推荐系统（RS）整合的研究如雨后春笋般涌现。然而，受制于高昂的时间和空间成本，以及会话数据的简短和匿名性，SBR领域尚未出现第一个适合工业部署的LLM推荐框架。为了解决上述挑战，我们提出了SBR的LLM集成框架（LLM4SBR）。 LLM4SBR 作为一个轻量级、即插即用的框架，采用两步策略。首先，我们将会话数据转换为文本和行为的双峰形式。第一步，利用LLM的推理能力，从不同角度对会话文本数据进行推理，并设计辅助增强组件。第二步，SBR 模型根据行为数据进行训练，从不同角度对齐和平均两个模态会话表示。最后，我们融合来自不同角度和模式的会话表示作为推荐的最终会话表示。我们在两个真实数据集上进行了实验，结果表明LLM4SBR显着提高了传统SBR模型的性能，并且高度轻量和高效，适合工业部署。]]></description>
      <guid>https://arxiv.org/abs/2402.13840</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:16 GMT</pubDate>
    </item>
    <item>
      <title>多样性意识 $k$ - 重新审视最大内部产品搜索</title>
      <link>https://arxiv.org/abs/2402.13858</link>
      <description><![CDATA[arXiv:2402.13858v1 公告类型：新
摘要：$k$-最大内积搜索 ($k$MIPS) 是推荐系统和各种数据挖掘任务的基础组件。然而，虽然大多数现有的 $k$MIPS 方法优先考虑为用户有效检索高度相关的项目，但它们经常忽略搜索结果的一个同样关键的方面：\emph{多样性}。为了弥补这一差距，我们通过将两个众所周知的多样性目标（最小化结果中的平均和最大成对项目相似性）纳入到原始相关性目标。这一增强功能受到最大边际相关性 (MMR) 的启发，为用户提供了相关性和多样性之间的可控权衡。我们引入 \textsc{Greedy} 和 \textsc{DualGreedy}，这是两种为 D$k$MIPS 量身定制的基于线性扫描的算法。它们都实现了数据相关的近似，并且当旨在最小化平均成对相似性时，\textsc{DualGreedy} 通过正则化的附加项获得了 $1/4$ 的近似率。为了进一步提高查询效率，我们将轻量级球锥树（BC-Tree）索引与两种算法集成。最后，对十个真实世界数据集的综合实验证明了我们提出的方法的有效性，展示了它们有效地向用户提供多样化且相关的搜索结果的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.13858</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:16 GMT</pubDate>
    </item>
    <item>
      <title>利用翻译实现最佳回忆：根据用户配置文件定制 LLM 个性化</title>
      <link>https://arxiv.org/abs/2402.13500</link>
      <description><![CDATA[arXiv:2402.13500v1 公告类型：新
摘要：本文探索了一种利用基于用户词汇语义空间的迭代查询细化来提高跨语言信息检索（CLIR）系统中的召回率的新技术。所提出的方法结合了多级翻译、基于语义嵌入的扩展和以用户配置文件为中心的增强，以解决用户查询和相关文档之间匹配差异的挑战。通过最初的 BM25 检索、翻译成中间语言、嵌入相似术语的查找以及迭代重新排名，该技术旨在扩大针对个人用户个性化的潜在相关结果的范围。对新闻和 Twitter 数据集的比较实验表明，所提出的方法在 ROUGE 指标上的性能优于基线 BM25 排名。翻译方法还表明通过多步骤过程保持了语义准确性。这种个性化的 CLIR 框架为改进上下文感知检索铺平了道路，关注用户语言的细微差别。]]></description>
      <guid>https://arxiv.org/abs/2402.13500</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:15 GMT</pubDate>
    </item>
    <item>
      <title>打破障碍：通过推理知识图利用工业推荐系统的大型语言模型</title>
      <link>https://arxiv.org/abs/2402.13750</link>
      <description><![CDATA[arXiv:2402.13750v1 公告类型：新
摘要：推荐系统广泛应用于电子商务网站和在线平台，以解决信息过载问题。然而，现有系统主要依赖于历史数据和用户反馈，因此很难捕获用户意图转变。最近，提出了基于知识库（KB）的模型来融合专家知识，但它很难适应新项目和不断发展的电子商务环境。为了应对这些挑战，我们提出了一种新颖的基于大语言模型的补充知识增强推荐系统（LLM-KERec）。它引入了一个实体提取器，可以从项目和用户信息中提取统一的概念术语。为了提供经济高效且可靠的先验知识，实体对是根据实体流行度和特定策略生成的。大语言模型确定每个实体对中的互补关系，构建互补的知识图谱。此外，新的补充召回模块和实体-实体-项目（E-E-I）权重决策模型使用真实的补充曝光点击样本完善了排名模型的评分。对三个行业数据集进行的广泛实验表明，与现有方法相比，我们的模型具有显着的性能改进。此外，详细分析表明，LLM-KERec通过推荐互补品提高了用户的消费热情。总之，LLM-KERec 通过整合互补知识并利用大型语言模型来捕获用户意图转换、适应新项目并在不断发展的电子商务环境中提高推荐效率，从而解决了传统推荐系统的局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.13750</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:15 GMT</pubDate>
    </item>
    <item>
      <title>图对比学习在数学信息检索中的有效性</title>
      <link>https://arxiv.org/abs/2402.13444</link>
      <description><![CDATA[arXiv:2402.13444v1 公告类型：新
摘要：本文详细介绍了使用图对比学习（GCL）生成数学方程表示的实证研究，这是数学信息检索（MIR）的一个关键方面。我们的研究结果表明，这种简单的方法始终优于当前领先的公式检索模型 TangentCFT 的性能。为了支持该领域正在进行的研究和开发，我们已在 https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/ 上向公众开放源代码。]]></description>
      <guid>https://arxiv.org/abs/2402.13444</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:14 GMT</pubDate>
    </item>
    <item>
      <title>一种嵌入可以适应所有情况吗？提高用户兴趣多样性公平性的多兴趣学习范式</title>
      <link>https://arxiv.org/abs/2402.13495</link>
      <description><![CDATA[arXiv:2402.13495v1 公告类型：新
摘要：推荐系统（RS）由于具有捕捉用户兴趣的卓越能力，在各个领域获得了广泛的应用。然而，用户兴趣的复杂性和细微差别，涉及广泛的多样性，对提供公平的推荐构成了重大挑战。在实践中，用户偏好差异很大；一些用户对某些项目类别表现出明显的偏好，而另一些用户则对不同的项目类别具有广泛的兴趣。尽管预计所有用户都应该收到高质量的推荐，但 RS 在迎合这种不同兴趣多样性方面的有效性仍未得到充分探索。
  在这项工作中，我们调查具有不同兴趣多样性水平的用户是否受到公平对待。我们的实证实验揭示了一种固有的差异：兴趣更广泛的用户通常会收到质量较低的推荐。为了缓解这种情况，我们提出了一个多兴趣框架，该框架使用多个（虚拟）兴趣嵌入而不是单个兴趣嵌入来表示用户。具体来说，该框架由堆叠的多兴趣表示层组成，其中包括从共享参数导出虚拟兴趣的兴趣嵌入生成器，以及促进多跳聚合的中心嵌入聚合器。实验证明了该框架在跨各种数据集和骨干网实现公平性和效用之间更好权衡方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.13495</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:14 GMT</pubDate>
    </item>
    <item>
      <title>解锁购买的“原因”：引入新的数据集和购买原因和购买后体验的基准</title>
      <link>https://arxiv.org/abs/2402.13417</link>
      <description><![CDATA[arXiv:2402.13417v1 公告类型：新
摘要：解释对于增强现代推荐系统中用户的信任和理解至关重要。为了构建真正可解释的系统，我们需要高质量的数据集来阐明用户做出选择的原因。虽然之前的努力主要集中在评论中提取用户的购买后情绪，但他们忽略了购买决定背后的原因。
  在我们的工作中，我们提出了一个新颖的购买原因解释任务。为此，我们引入了一种基于 LLM 的方法来生成一个数据集，该数据集包含真实用户为何做出某些购买决定的文本解释。我们引导法学硕士在用户评论中明确区分购买产品背后的原因和购买后的体验。由法学硕士驱动的自动化评估以及小规模的人工评估证实了我们获得高质量、个性化解释的方法的有效性。我们在两个个性化解释生成任务上对该数据集进行了基准测试。我们发布代码并提示以促进进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2402.13417</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:13 GMT</pubDate>
    </item>
    <item>
      <title>学习检索工作匹配</title>
      <link>https://arxiv.org/abs/2402.13435</link>
      <description><![CDATA[arXiv:2402.13435v1 公告类型：新
摘要：网络规模的搜索系统通常通过两步范例来应对可扩展性挑战：检索和排名。检索步骤也称为候选选择，通常涉及提取标准化实体、创建倒排索引以及执行检索的术语匹配。这种传统方法需要手动且耗时地开发查询模型。在本文中，我们讨论应用学习检索技术来增强 LinkedIn 的职位搜索和推荐系统。在晋升职位领域，关键目标是提高申请人的质量，从而为招聘客户提供价值。为了实现这一目标，我们利用已确认的招聘数据构建一个图表来评估求职者的工作资格，并利用学习到的链接进行检索。我们学习的模型很容易解释、调试和调整。另一方面，有机工作的重点是优化搜索者的参与度。我们通过训练个性化检索的嵌入来实现这一目标，并通过从会员反馈分类中得出的一组规则进行强化。除了基于传统倒排索引的解决方案之外，我们还开发了一种能够高效支持 KNN 和术语匹配的 GPU 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2402.13435</guid>
      <pubDate>Thu, 22 Feb 2024 18:16:13 GMT</pubDate>
    </item>
    </channel>
</rss>