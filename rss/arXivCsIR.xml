<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Heisir：使用LLMS的无训练检索倒置语义索引的分层扩展</title>
      <link>https://arxiv.org/abs/2503.04141</link>
      <description><![CDATA[ARXIV：2503.04141V1公告类型：新 
摘要：对话AI服务的增长增加了对对话数据中对有效信息检索的需求。但是，现有方法通常在捕获语义意图或需要广泛的标签和微调方面面临挑战。本文介绍了Heisir（倒倒语义索引的层次扩展），该框架通过优化的数据摄入来增强对话数据检索的语义理解，从而消除了对资源密集型标签或模型适应的需求。 Heisir实现了一个两步的过程：（1）层次三联体配方和（2）辅助扩展，创建由主题 - 动物 - 对象辅助（SVOA）QUADRUPER组成的语义索引。该结构化表示有效地捕获了对话内容中的基本语义信息。 Heisir在实际检索过程中保持较低的潜伏期，取得了很高的检索性能。我们的实验结果表明，Heisir在各种嵌入类型和语言模型上的表现优于微调模型。除了提高检索功能外，海里尔还提供了在对话数据中的意图和主题分析的机会，为对话系统提供了多功能解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.04141</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义检索增强对比度学习以进行顺序推荐</title>
      <link>https://arxiv.org/abs/2503.04162</link>
      <description><![CDATA[ARXIV：2503.04162V1公告类型：新 
摘要：顺序建议旨在基于历史行为序列对用户偏好进行建模，这对于各种在线平台至关重要。由于大多数用户的互动率有限，而且许多项目受到很少的关注，因此数据稀疏仍然是一个重大挑战。为了减轻此问题，对比度学习已被广​​泛采用。通过从数据本身构建阳性样本对并最大化其在嵌入空间中的一致性，它可以更有效地利用可用的数据。构建合理的阳性样品对对于对比度学习的成功至关重要。但是，当前的方法很难产生可靠的积极对，因为它们要么依赖于从固有的稀疏协作信号中学到的表示形式，要么使用带来重大不确定性的随机扰动。为了解决这些局限性，我们提出了一种新的方法，名为语义检索增强对比度学习（SRA-CL），该方法利用语义信息来提高对比度样本的可靠性。 SRA-CL包括两个主要组成部分：（1）通过用户语义检索进行跨序列对比度学习，该学习利用大型语言模型（LLMS）来了解多样化的用户偏好，并通过可学习的样本合成方法来检索语义上相似的用户以形成可靠的正面样本； （2）通过项目语义检索进行对比度学习，该学习使用LLMS来理解项目并检索类似的项目以执行基于语义的项目替代，从而为对比度学习创造了语义上一致的增强视图。 SRA-CL是插件，可以集成到标准的顺序推荐模型中。在四个公共数据集上进行的广泛实验证明了该方法的有效性和普遍性。]]></description>
      <guid>https://arxiv.org/abs/2503.04162</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对统一框架中基于图的抹布的深入分析</title>
      <link>https://arxiv.org/abs/2503.04338</link>
      <description><![CDATA[ARXIV：2503.04338V1公告类型：新 
摘要：基于图的检索效果生成（RAG）已被证明有效地将外部知识整合到大语言模型（LLMS）中，提高了其事实准确性，适应性，可解释性和可信度。文献中已经提出了许多基于图的抹布方法。但是，在同一实验设置下，这些方法尚未进行系统和全面的比较。在本文中，我们首先总结了一个统一的框架，以从高级角度合并所有基于图的抹布方法。然后，我们将基于图形的抹布方法广泛比较了一系列的寻求处理（QA）数据集（从特定问题到抽象问题），并检查所有方法的有效性，从而对基于图的抹布方法进行了详尽的分析。作为我们实验分析的副产品，我们还能够通过结合现有技术，分别在特定的质量质量质量标准和抽象QA任务上分别识别基于图的抹布方法的新变体，从而超越了最先进的方法。最后，根据这些发现，我们提供了有希望的研究机会。我们认为，对现有方法的行为有更深入的了解可以为未来的研究提供新的宝贵见解。]]></description>
      <guid>https://arxiv.org/abs/2503.04338</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多模式特征改进的无训练图表过滤，以实现极快的多模式建议</title>
      <link>https://arxiv.org/abs/2503.04406</link>
      <description><![CDATA[ARXIV：2503.04406V1公告类型：新 
摘要：多模式推荐系统通过利用文本，图像和视频等多样化的内容类型来改善没有项目功能的规范推荐系统的性能，同时减轻用户项目交互的固有稀疏性并加速用户参与度。但是，由于从多种模式中学习和整合信息所需的复杂训练过程，当前基于神经网络的模型通常会产生大量的计算开销。为了克服这一限制，我们提出了多模式循环滤波（MM-GF），这是一种基于图形滤波（GF）概念（GF）的训练方法，以提高高效，准确的多模式建议。具体而言，MM-GF首先通过非平凡的多模式优化构建了多个相似性图，例如通过跨模态的异质特性来解决可靠的缩放和矢量移动。然后，MM-GF使用不同模态的线性低通滤波器最佳地融合了多模式信息。对现实世界基准数据集的广泛实验表明，与最佳竞争者相比，MM-GF不仅可以提高建议精度高达13.35％，而且还可以通过达到不到10秒的运行时间来大大降低计算成本。]]></description>
      <guid>https://arxiv.org/abs/2503.04406</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过日期控制的工具使用测量代理知识的时间影响</title>
      <link>https://arxiv.org/abs/2503.04188</link>
      <description><![CDATA[ARXIV：2503.04188V1公告类型：交叉 
摘要：时间进步是知识积累和更新的组成部分。网络搜索通常被用作代理知识的基础，但其不适当的配置会影响代理响应的质量。在这里，我们构建了一个基于工具的样本外测试框架，以测量来自不同日期控制工具（DCT）的大语言模型（LLM）代理的知识变异性。我们演示了LLM代理作为写作助理的时间影响，该助理可以使用Web搜索来帮助完成科学出版物摘要。我们表明，搜索引擎的时间效应转化为依赖工具的代理性能，但可以通过基本模型选择和明确的推理说明（例如，经过思考链链的提示）来缓解。我们的结果表明，代理评估应具有动态视图，并说明工具的时间影响和外部资源的更新。]]></description>
      <guid>https://arxiv.org/abs/2503.04188</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IFIR：用于评估专家域信息检索中指令遵循的全面基准</title>
      <link>https://arxiv.org/abs/2503.04644</link>
      <description><![CDATA[ARXIV：2503.04644V1公告类型：交叉 
摘要：我们介绍了IFIR，这是第一个旨在评估专家领域中指导遵循信息检索（IR）的全面基准。 IFIR包括2,426个高质量的例子，并涵盖了四个专业领域的八个子集：金融，法律，医疗保健和科学文献。每个子集都介绍一个或多个特定于域的检索任务，复制自定义指令至关重要的现实情况。 IFIR通过在不同级别的复杂性级别纳入指令来详细分析指导遵循检索功能。我们还提出了一种基于LLM的新型评估方法，以在以下说明中对模型性能进行更精确，更可靠的评估。通过对15个边境检索模型（包括基于LLM的）的广泛实验，我们的结果表明，当前模型在有效地遵循复杂的，特定于领域的指令时面临着重大挑战。我们进一步提供了深入的分析，以突出这些局限性，提供有价值的见解，以指导未来的回猎犬开发进步。]]></description>
      <guid>https://arxiv.org/abs/2503.04644</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RADIR：通过放射学报告采矿的多层次医学图像检索的可扩展框架</title>
      <link>https://arxiv.org/abs/2503.04653</link>
      <description><![CDATA[ARXIV：2503.04653V1公告类型：交叉 
摘要：由于在不同的医学环境中对“相似图像”的定义的不同定义，开发先进的医学成像检索系统具有挑战性。由于缺乏大规模，高质量的医学成像检索数据集和基准，这一挑战更加复杂。在本文中，我们提出了一种新型方法，该方法利用密集的放射学报告以可扩展且全自动的方式以多种粒度定义图像相似性排序。使用这种方法，我们构建了两个全面的医学成像检索数据集：用于胸部X射线的模拟IR和CTATE-IR用于CT扫描，提供了以各种解剖结构为条件的详细图像图像排名注释。此外，我们开发了两个检索系统，即Radir-CXR和Model-Chestct，它们在传统的图像图像和图像报告检索任务中表现出卓越的性能。这些系统还可以根据文本中描述的特定解剖结构进行柔性，有效的图像检索，从而在78个指标中达到了最新的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.04653</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估搜索引擎和大型语言模型以回答健康问题</title>
      <link>https://arxiv.org/abs/2407.12468</link>
      <description><![CDATA[ARXIV：2407.12468V3公告类型：替换 
摘要：搜索引擎（SES）传统上是寻求信息的主要工具，但是新的大语言模型（LLMS）正在成为有力的替代方案，尤其是针对提问的任务。这项研究比较了四个受欢迎的SES，七个LLM和检索功能（RAG）变体的性能，从而回答了TREC健康错误信息（HM）曲目中的150个与健康相关的问题。结果表明，SES正确地回答了50％至70％的问题，这通常受到许多检索结果而无法回答健康问题。 LLMS提供了更高的精度，正确回答了大约80％的问题，尽管它们的性能对输入提示很敏感。抹布方法可显着提高较小的LLM的有效性，通过整合检索证据，提高了高达30％的精度。]]></description>
      <guid>https://arxiv.org/abs/2407.12468</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>耀斑：融合语言模型和协作体系结构，用于推荐增强</title>
      <link>https://arxiv.org/abs/2409.11699</link>
      <description><![CDATA[ARXIV：2409.11699V2公告类型：替换 
摘要：推荐系统中的最新建议使用大型语言模型表示具有文本描述的项目。与仅项目ID模型（例如Bert4Rec）相比，它们在标准基准测试中显示出更好的结果。在这项工作中，我们重新审视了经常使用的Bert4Rec基线，并表明，通过进一步的调整，Bert4Rec明显胜过先前报道的数字，在某些数据集中，与最先进的模型具有竞争力。
  借助对项目ID模型的修订基线，本文还为结合ID和文本描述的体系结构建立了新的竞争结果。我们用Flare（融合语言模型和协作架构以提高推荐增强）来证明这一点。 Flare是一种新颖的混合序列推荐，将语言模型与使用感知器网络的协作过滤模型集成在一起。
  先前的研究将评估重点放在有限孔尺寸的数据集上，但是网络上常见的许多商业上适用的推荐系统必须处理较大的语料库。我们在更现实的数据集上评估了耀斑，并具有更大的项目词汇，为此设置引入了新的基线。本文还展示了Flare支持批评的固有能力，使用户能够提供反馈和完善建议。我们利用批评作为一种评估方法来评估模型的语言理解及其对建议任务的转移性。]]></description>
      <guid>https://arxiv.org/abs/2409.11699</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解耦建议系统：探索替代建议生态系统设计</title>
      <link>https://arxiv.org/abs/2503.03606</link>
      <description><![CDATA[ARXIV：2503.03606V2公告类型：替换 
摘要：推荐生态系统是新兴的研究主题。这样的研究研究了算法，建议消费者和项目提供商的特征如何影响系统动态和长期结果。在这一研究中，尚未广泛探索的一种建筑可能性是配置的后果，在这种配置中，建议算法与它们所提供的平台分离。这有时称为“友好的社区算法商店”或“中间件”模型。我们对这些架构如何在消费者，提供商和推荐平台之间提供一系列不同分布的公用事业分布特别感兴趣。在本文中，我们创建了一个建议生态系统的模型，该模型结合了算法选择并检查了这种设计的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.03606</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过二进制托袋指数的半参数检索</title>
      <link>https://arxiv.org/abs/2405.01924</link>
      <description><![CDATA[ARXIV：2405.01924V2公告类型：替换 - 交叉 
摘要：信息检索已从独立系统转变为跨更广泛应用的基本组件，具有索引效率，成本效益和新鲜度越来越重要，但经常被忽视。在本文中，我们引入了半参数散开检索（SIDR），这是一种双重编码器检索框架，将从神经参数取回检索指数以实现有效的，低成本和参数 - 不可能的索引，以实现出现的用例。具体而言，除了将嵌入式用作现有神经检索方法之类的索引外，SIDR还支持非参数令牌化指数用于搜索，从而达到了BM25样索引的复杂性，其有效性明显更高。我们对16个检索基准进行的全面评估表明，SIDR在相同的索引工作量下优于神经和基于术语的检索基准：（i）使用基于嵌入式的索引时，SIDR超过了传统的神经反猎犬的性能，同时保持相似的训练复杂性； （ii）当使用基于令牌化的索引时，SIDR会大大降低索引成本和时间，与传统基于术语的检索的复杂性相匹配，同时在所有域内数据集上始终优于BM25； （iii）此外，我们引入了一种较晚的参数机制，该机制与BM25指数制备时间匹配，同时超过了有效性的其他神经检索基线。]]></description>
      <guid>https://arxiv.org/abs/2405.01924</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于学习的前提检索器协助数学形式化</title>
      <link>https://arxiv.org/abs/2501.13959</link>
      <description><![CDATA[Arxiv：2501.13959V2公告类型：替换 - 交叉 
摘要：前提选择是数学形式化的至关重要但又具有挑战性的步骤，尤其是对于经验有限的用户而言。由于缺乏可用的形式化项目，利用语言模型的现有方法通常会遇到数据稀缺。在这项工作中，我们引入了一种创新方法，用于培训前提猎犬以支持数学的形式化。我们的方法采用BERT模型将证明状态和前提嵌入共享的潜在空间中。检索模型是在对比度学习框架中训练的，并结合了特定的代币器以及细粒度的相似性计算方法。实验结果表明，与现有基线相比，我们的模型具有很高的竞争力，在需要更少的计算资源的同时，实现了强劲的性能。通过集成重新排列模块，进一步提高了性能。为了简化形式化过程，我们将发布一个搜索引擎，使用户可以使用证明状态直接查询Mathlib定理，从而显着提高可访问性和效率。代码可在https://github.com/ruc-ai4math/premise-retreval中找到。]]></description>
      <guid>https://arxiv.org/abs/2501.13959</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SRAG：通过Wikipedia图回答的多实体问题的结构化检索生成</title>
      <link>https://arxiv.org/abs/2503.01346</link>
      <description><![CDATA[ARXIV：2503.01346V2公告类型：替换 - 交叉 
摘要：多实用性问题回答（MEQA）对大型语言模型（LLMS）构成了重大挑战，这些挑战通常很难巩固跨多个文档的散落信息。一个示例问题可能是“ IEEE研究员在各个研究领域之间的分布是什么？”，这需要从Wikipedia页面中检索各种来源的信息。 LLMS从众多页面中汇总见解的能力限制了当前检索效果生成（RAG）方法的有效性。为了解决这一差距，本文介绍了一个结构化的抹布（SRAG）框架，该框架系统地将其提取的实体组织到关系表中（例如，使用模式列的制表实体，例如“名称”和“研究领域”），然后应用基于表格的推理技术。我们的方法解除了检索和推理，使LLM可以专注于结构化数据分析，而不是原始文本聚合。对基于Wikipedia的多实体质量检查任务进行的广泛实验表明，SRAG显着胜过最先进的长篇小说LLM和RAG解决方案，可提高准确性的29.6％。结果强调了构建非结构化数据以增强LLMS推理能力的功效。]]></description>
      <guid>https://arxiv.org/abs/2503.01346</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>