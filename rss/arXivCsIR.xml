<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 16 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>DAPR：文档感知段落检索的基准</title>
      <link>https://arxiv.org/abs/2305.13915</link>
      <description><![CDATA[arXiv:2305.13915v3 公告类型：替换
摘要：迄今为止，神经检索的工作重点是对短文本进行排序，并面临长文档的挑战。在很多情况下，用户希望从庞大的语料库中找到长文档中的相关段落，例如维基百科文章、研究论文等。我们提出并将此任务命名为\emph{文档感知段落检索}（DAPR）。在分析最先进（SoTA）段落检索器的错误时，我们发现主要错误（53.5%）是由于缺少文档上下文造成的。这促使我们为此任务建立一个基准，包括来自异构域的多个数据集。在实验中，我们通过（1）与 BM25 的混合检索和（2）上下文化的段落表示（用文档上下文告知段落表示）来扩展 SoTA 段落检索器和文档上下文。我们发现，尽管混合检索在简单查询和困难查询的混合上表现最强，但它在需要文档上下文理解的硬查询上完全失败。另一方面，上下文化的段落表示（例如前置文档标题）在这些硬查询上取得了很好的改进，但总体而言它们的性能也相当差。我们创建的基准使未来能够研究开发和比较新任务的检索系统。代码和数据可在 https://github.com/UKPLab/arxiv2023-dapr 获取。]]></description>
      <guid>https://arxiv.org/abs/2305.13915</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>DeepSRGM——利用深度学习对印度古典音乐进行序列分类和排序</title>
      <link>https://arxiv.org/abs/2402.10168</link>
      <description><![CDATA[arXiv:2402.10168v1 公告类型：交叉
摘要：印度古典音乐（ICM）的一个重要方面是拉格，它充当作曲和即兴创作的旋律框架。 Raga 识别是 ICM 中一项重要的音乐信息检索任务，因为它可以帮助从音乐推荐到组织庞大的音乐收藏等众多下游应用。在这项工作中，我们提出了一种基于深度学习的 Raga 识别方法。我们的方法采用高效的预占有，并使用基于长短期记忆的循环神经网络 (LSTM-RNN) 来学习音乐数据中的时间序列。我们在从原始音频中采样的较小序列上训练和测试网络，同时对整个音频进行最终的推理。我们的方法在 Comp Music Carnatic 数据集及其 10 个 Raga 子集的推理过程中分别实现了 88.1% 和 97% 的准确率，使其成为 Raga 识别任务的最新技术。我们的方法还支持序列排序，这有助于我们从给定的音乐数据库中检索与所呈现的查询序列密切相关的旋律模式。]]></description>
      <guid>https://arxiv.org/abs/2402.10168</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>利用人类记忆过程对个性化音乐推荐的流派偏好进行建模</title>
      <link>https://arxiv.org/abs/2003.10699</link>
      <description><![CDATA[arXiv:2003.10699v3 公告类型：替换
摘要：在本文中，我们介绍了一种受心理学启发的方法，利用人类记忆过程来建模和预测不同用户群体的音乐流派偏好。这些过程描述了人类如何通过考虑以下因素来访问记忆中的信息单元：（i）过去的使用频率，（ii）过去的使用新近度，以及（iii）当前上下文。使用音乐流媒体平台 Last.fm 上共享的超过十亿个音乐收听记录的公开数据集，我们发现我们的方法为所有评估的用户组提供了比各种基线算法更好的预测准确性结果，即（i）低-主流音乐听众，(ii)中主流音乐听众，以及(iii)高主流音乐听众。此外，我们的方法基于一个简单的心理模型，这有助于计算预测的透明度和可解释性。]]></description>
      <guid>https://arxiv.org/abs/2003.10699</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:46 GMT</pubDate>
    </item>
    <item>
      <title>建筑行业的生成式人工智能：最先进的分析</title>
      <link>https://arxiv.org/abs/2402.09939</link>
      <description><![CDATA[arXiv:2402.09939v1 公告类型：交叉
摘要：建筑业是全球经济的重要部门，但在设计、规划、采购、检查和维护等各个过程中面临着许多生产力挑战。生成人工智能 (AI) 可以根据某些输入或先验知识创建新颖且真实的数据或内容，例如文本、图像、视频或代码，提供创新和颠覆性的解决方案来应对这些挑战。然而，有关建筑行业生成式人工智能的现状、机遇和挑战的文献还存在空白。本研究旨在通过对建筑中的生成人工智能进行最先进的分析来填补这一空白，其三个目标是：（1）审查和分类建筑行业现有和新兴的生成人工智能机遇和挑战； (2) 为建筑公司使用自己的数据构建定制的生成式人工智能解决方案提出一个框架，包括数据收集、数据集管理、训练定制大语言模型（LLM）、模型评估和部署等步骤； (3) 通过开发用于查询合同文档的生成模型的案例研究来演示该框架。结果表明，检索增强生成 (RAG) 在质量、相关性和可重复性方面将基线 LLM 提高了 5.2%、9.4% 和 4.8%。这项研究为学者和建筑专业人士提供了全面的分析和实践框架，以指导采用生成式人工智能技术，以提高整个建筑行业的生产力、质量、安全和可持续性。]]></description>
      <guid>https://arxiv.org/abs/2402.09939</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>用于无监督单词翻译的自我增强情境学习</title>
      <link>https://arxiv.org/abs/2402.10024</link>
      <description><![CDATA[arXiv:2402.10024v1 公告类型：交叉
摘要：最近的工作表明，虽然大型语言模型（LLM）在少数镜头设置中表现出强大的单词翻译或双语词典归纳（BLI）能力，但它们仍然无法与无监督的“传统”基于映射的方法的性能相匹配。没有可用的种子翻译对的场景，特别是对于资源较低的语言。为了应对法学硕士的这一挑战，我们提出了用于无监督 BLI 的自我增强上下文学习（SAIL）：从零样本提示开始，SAIL 迭代地引入一组用于上下文学习的高置信度单词翻译对（ICL ）从法学硕士，然后以 ICL 方式重新应用于同一个法学硕士。我们的方法显示，在跨越多种语言对的两个已建立的 BLI 基准上，LLM 的零样本提示取得了显着的进步，并且全面优于基于映射的基准。除了实现最先进的无监督 BLI 性能外，我们还对 SAIL 进行全面分析并讨论其局限性。]]></description>
      <guid>https://arxiv.org/abs/2402.10024</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>PICS：图像字幕和搜索管道</title>
      <link>https://arxiv.org/abs/2402.10090</link>
      <description><![CDATA[arXiv:2402.10090v1 公告类型：交叉
摘要：数字图像数量的不断增长需要先进的系统来进行有效的分类和检索，这对数据库管理和信息检索提出了重大挑战。本文介绍了 PICS（图像字幕和搜索管道），这是一种新颖的方法，旨在解决组织大型图像存储库所固有的复杂性。 PICS 利用大型语言模型 (LLM) 的进步来自动化图像字幕处理过程，提供超越传统手动注释方法的解决方案。该方法植根于这样的理解：人工智能生成的有意义的字幕可以显着增强大型数据库中图像的可搜索性和可访问性。通过将情感分析集成到管道中，PICS 进一步丰富了元数据，实现了超出基本描述符范围的细致搜索。这种方法不仅简化了管理大量图像集合的任务，而且还为图像检索的准确性和效率树立了新的先例。 PICS 的重要性在于其改变图像数据库系统的潜力，利用机器学习和自然语言处理的力量来满足现代数字资产管理的需求。]]></description>
      <guid>https://arxiv.org/abs/2402.10090</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>POBEVM：通过逐步优化目标主体和边缘进行实时视频抠图</title>
      <link>https://arxiv.org/abs/2402.09731</link>
      <description><![CDATA[arXiv:2402.09731v1 公告类型：交叉
摘要：基于深度卷积神经网络（CNN）的方法在视频抠图方面取得了出色的性能。许多这些方法可以为目标身体产生准确的阿尔法估计，但通常会产生模糊或不正确的目标边缘。这通常是由以下原因引起的： 1）当前的方法总是不加区别地对待目标体和边缘； 2) 目标主体占整个目标的主导地位，仅占目标边缘很小的比例。对于第一个问题，我们提出了一个基于 CNN 的模块，该模块单独优化抠图目标主体和边缘（SOBE）。在此基础上，我们引入了一种实时、无三元图的视频抠图方法，通过逐步优化抠图目标主体和边缘（POBEVM），该方法比以前的方法轻得多，并且在预测目标边缘方面取得了显着改进。对于第二个问题，我们提出了 Edge-L1-Loss (ELL) 函数，该函数在抠图目标边缘上强制执行我们的网络。实验表明，我们的方法在 Distinctions-646 (D646) 和 VideoMatte240K(VM) 数据集上均优于先前的无 trimap 抠图方法，尤其是在边缘优化方面。]]></description>
      <guid>https://arxiv.org/abs/2402.09731</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>通过无组块上下文检索奠定语言模型的基础</title>
      <link>https://arxiv.org/abs/2402.09760</link>
      <description><![CDATA[arXiv:2402.09760v1 公告类型：交叉
摘要：本文提出了一种新颖的无分块上下文内 (CFIC) 检索方法，专为检索增强生成 (RAG) 系统量身定制。由于处理冗长文档和过滤掉不相关内容的挑战，传统的 RAG 系统经常难以使用精确的证据文本来做出基础响应。常用的解决方案，例如文档分块和调整语言模型来处理较长的上下文，都有其局限性。这些方法要么破坏文本的语义连贯性，要么无法有效解决证据检索中的噪声和不准确问题。
  CFIC 通过绕过传统的分块过程来解决这些挑战。它利用文档的编码隐藏状态进行上下文检索，采用自动解码来准确识别用户查询所需的特定证据文本，从而消除了分块的需要。 CFIC 通过结合两种解码策略进一步增强，即约束句子前缀解码和跳过解码。这些策略不仅提高了检索过程的效率，而且确保了生成的基础文本证据的保真度。我们对一系列开放 QA 数据集对 CFIC 的评估证明了其在检索相关和准确证据方面的优越性，比传统方法有了显着改进。通过消除文档分块的需要，CFIC 提供了一种更加简化、有效和高效的检索解决方案，使其成为 RAG 系统领域的宝贵进步。]]></description>
      <guid>https://arxiv.org/abs/2402.09760</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>用户建模和用户分析：综合调查</title>
      <link>https://arxiv.org/abs/2402.09660</link>
      <description><![CDATA[arXiv:2402.09660v1 公告类型：交叉
摘要：人工智能（AI）融入日常生活，特别是通过信息检索和推荐系统，需要先进的用户建模和分析技术来提供个性化体验。这些技术旨在基于与这些系统交互生成的大量数据来构建准确的用户表示。本文对用户建模和分析研究的现状、演变和未来方向进行了全面的调查。我们提供历史概述，追溯从早期刻板印象模型到最新深度学习技术的发展，并提出一种新颖的分类法，涵盖该研究领域的所有活跃主题，包括最新趋势。我们的调查强调了范式转向更复杂的用户分析方法，强调隐式数据收集、多行为建模和图数据结构的集成。我们还解决了对隐私保护技术的迫切需求，以及推动用户建模方法的可解释性和公平性。通过检查核心术语的定义，我们旨在通过提出主要术语的两个新颖的百科全书式定义来澄清歧义并促进对该领域的更清晰的理解。此外，我们还探索用户建模在假新闻检测、网络安全和个性化教育等各个领域的应用。这项调查为研究人员和从业者提供了综合资源，提供了对用户建模和分析的演变的见解，并指导开发更加个性化、道德和有效的人工智能系统。]]></description>
      <guid>https://arxiv.org/abs/2402.09660</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>具有长上下文要点记忆的受人类启发的阅读代理</title>
      <link>https://arxiv.org/abs/2402.09727</link>
      <description><![CDATA[arXiv:2402.09727v1 公告类型：交叉
摘要：当前的大型语言模型（LLM）不仅限于某些最大上下文长度，而且无法稳健地消耗长输入。为了解决这些限制，我们提出了 ReadAgent，这是一种 LLM 代理系统，在我们的实验中将有效上下文长度增加了 20 倍。受人类交互阅读长文档方式的启发，我们将 ReadAgent 实现为一个简单的提示系统，该系统使用法学硕士的高级语言功能来 (1) 决定在记忆片段中一起存储哪些内容，(2) 将这些记忆片段压缩为短片段（3）如果 ReadAgent 需要提醒自己相关细节来完成任务，则采取行动查找原文中的段落。我们使用检索方法、原始长上下文和要点记忆来根据基线评估 ReadAgent。这些评估是针对三个长文档阅读理解任务进行的：QuALITY、NarrativeQA 和 QMSum。 ReadAgent 在所有三项任务上均优于基线，同时将有效上下文窗口扩展了 3-20 倍。]]></description>
      <guid>https://arxiv.org/abs/2402.09727</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>基于LLM的联合推荐</title>
      <link>https://arxiv.org/abs/2402.09959</link>
      <description><![CDATA[arXiv:2402.09959v1 公告类型：新
摘要：大型语言模型（LLM）凭借其先进的上下文理解能力，在通过微调方法增强推荐系统方面表现出了巨大的潜力。然而，微调需要用户的行为数据，由于掺入了敏感的用户信息，带来了相当大的隐私风险。此类数据的无意披露可能会违反数据保护法并引发道德问题。为了缓解这些隐私问题，联合学习推荐（Fed4Rec）已成为一种有前景的方法。然而，将 Fed4Rec 应用于基于 LLM 的推荐存在两个主要挑战：首先，客户端之间性能不平衡的增加，随着时间的推移影响系统的效率，其次，对客户端本地培训和存储的计算和存储资源的高要求。 LLM 的推论。
  为了应对这些挑战，我们引入了基于隐私保护的 LLM 推荐 (PPLR) 框架。 PPLR 框架采用两种主要策略。首先，它实现了动态平衡策略，包括在训练阶段针对不同客户端设计动态参数聚合和学习速度调整，以确保所有客户端的性能相对平衡。其次，PPLR采用灵活的存储策略，有选择地在客户端保留语言模型的某些敏感层，同时将非敏感层卸载到服务器。这种方法旨在保护用户隐私，同时有效节省计算和存储资源。实验结果表明，PPLR不仅实现了客户端之间的性能均衡，而且以计算和存储高效的方式增强了整体系统性能，同时有效保护了用户隐私。]]></description>
      <guid>https://arxiv.org/abs/2402.09959</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>LLM 增强的用户-项目交互：利用边缘信息来优化推荐</title>
      <link>https://arxiv.org/abs/2402.09617</link>
      <description><![CDATA[arXiv:2402.09617v1 公告类型：交叉
摘要：大型语言模型的非凡性能不仅重塑了 NLP 领域的研究格局，而且还展示了其在各个领域的非凡应用潜力。然而，这些模型在从图数据中挖掘关系方面的潜力仍未得到充分探索。图神经网络作为近年来的热门研究领域，关于关系挖掘的研究众多。然而，当前图神经网络的前沿研究尚未与大型语言模型有效集成，导致图关系挖掘任务的效率和能力有限。主要挑战是法学硕士无法深入利用图中的边缘信息，这对于理解复杂的节点关系至关重要。这一差距限制了法学硕士从图结构中提取有意义的见解的潜力，限制了它们在更复杂的基于图的分析中的适用性。我们专注于如何利用现有的法学硕士来挖掘和理解图数据中的关系，并将这些技术应用于推荐任务。我们提出了一种创新框架，将 LLM 强大的上下文表示能力与 GNN 的关系提取和分析功能相结合，用于挖掘图数据中的关系。具体来说，我们设计了一个新的提示构建框架，将图数据的关系信息集成到自然语言表达中，帮助法学硕士更直观地掌握图数据中的连接信息。此外，我们将图关系理解和分析功能引入法学硕士，以增强他们对图数据中连接信息的关注。我们对现实世界数据集的评估证明了该框架理解图形数据中的连接信息的能力。]]></description>
      <guid>https://arxiv.org/abs/2402.09617</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>从可变性到稳定性：推进 RecSys 基准测试实践</title>
      <link>https://arxiv.org/abs/2402.09766</link>
      <description><![CDATA[arXiv:2402.09766v1 公告类型：新
摘要：在快速发展的推荐系统（RecSys）领域，新算法经常声称基于对有限的一组任意选择的数据集的评估而具有最先进的性能。然而，由于数据集特征对算法性能的显着影响，这种方法可能无法全面反映其有效性。针对这一缺陷，本文引入了一种新颖的基准测试方法，以促进 RecSys 算法的公平和稳健比较，从而推进评估实践。通过利用一组不同的 30 美元开放数据集（包括本工作中引入的两个数据集），并通过 9 美元指标评估 11 美元协同过滤算法，我们严格检查数据集特征对算法性能的影响。我们进一步研究将多个数据集的结果汇总为统一排名的可行性。通过严格的实验分析，我们验证了我们的方法在数据集可变性下的可靠性，提供了平衡质量和计算需求的基准测试策略。该方法为评估 RecSys 算法提供了一种公平而有效的方法，为未来的研究工作提供了宝贵的指导。]]></description>
      <guid>https://arxiv.org/abs/2402.09766</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>具有对比学习和自注意力的时间邻近性的顺序推荐</title>
      <link>https://arxiv.org/abs/2402.09784</link>
      <description><![CDATA[arXiv:2402.09784v1 公告类型：新
摘要：顺序推荐系统从过去的交互中识别用户偏好，以最佳地预测后续项目。尽管之前的研究中传统的基于深度学习的模型和现代基于变压器的模型捕获了用户-项目交互中的单向和双向模式，但时间背景（例如个人行为和社会趋势模式）的重要性仍未得到充分探索。值得注意的是，最近的模型经常忽略用户在类似时间范围内隐式发生的用户行为的相似性——我们称之为垂直时间邻近性的概念。这些模型主要采用 Transformer 的自注意力机制来考虑单个用户操作中的时间上下文。与此同时，这种适应在考虑物品交互中的水平时间接近性方面仍然受到限制，例如区分一周内和一个月内的后续物品购买。为了解决这些差距，我们提出了一种名为 TemProxRec 的顺序推荐模型，其中包括对比学习和自注意力方法，以考虑用户-项目交互之间和内部的时间邻近性。所提出的对比学习方法学习不同用户在接近的时间段内选择的项目的表示。同时，所提出的自注意力机制使用绝对和相对嵌入对用户序列中的时间和位置上下文进行编码。这样，我们的 TemProxRec 就可以根据特定时间范围内的用户-项目交互准确预测相关项目。我们通过 TemProxRec 上的综合实验验证了这项工作，在基准数据集上始终优于现有模型，并展示了在顺序推荐中考虑垂直和水平时间邻近性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2402.09784</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>重新思考顺序推荐的大型语言模型架构</title>
      <link>https://arxiv.org/abs/2402.09543</link>
      <description><![CDATA[arXiv:2402.09543v1 公告类型：新
摘要：最近，顺序推荐已适应 LLM 范式，以享受 LLM 的力量。基于LLM的方法通常将推荐信息表述为自然语言，并训练模型以自回归的方式预测下一个项目。尽管它们取得了显着的成功，但推理的大量计算开销对其现实世界的适用性构成了重大障碍。在这项工作中，我们致力于简化现有的基于LLM的推荐模型，并提出一个简单而高效的模型Lite-LLM4Rec。 Lite-LLM4Rec 的主要目标是实现顺序推荐任务的高效推理。 Lite-LLM4Rec 通过使用直项投影头来生成排名分数，从而规避了波束搜索解码。这种设计源于我们的经验观察，即波束搜索解码对于顺序推荐来说最终是不必要的。此外，Lite-LLM4Rec 引入了分层 LLM 结构，旨在有效处理与项目相关的广泛上下文信息，从而在享受 LLM 功能的同时减少计算开销。在三个公开数据集上进行的实验证实了 Lite-LLM4Rec 相对于现有的基于 LLM 的方法在性能和推理效率方面的有效性（特别是 ML-1m 的性能提高了 46.8%，效率提高了 97.28%）。我们的实施将是开源的。]]></description>
      <guid>https://arxiv.org/abs/2402.09543</guid>
      <pubDate>Fri, 16 Feb 2024 06:16:40 GMT</pubDate>
    </item>
    </channel>
</rss>