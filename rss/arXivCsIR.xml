<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 27 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SEQ+MD：使用多分布数据进行多任务序列学习</title>
      <link>https://arxiv.org/abs/2408.13357</link>
      <description><![CDATA[arXiv:2408.13357v1 公告类型：新
摘要：在电子商务中，当客户尝试查找相关列表时，搜索结果的显示顺序会显著影响他们的购物体验和搜索效率。电子商务中基于相关性和参与度信号的定制重新排名系统通常会显示销售额和商品交易总额 (GMV) 的改善。当商店不仅限于国内买家，而是可以向全球国际买家销售时，为此目的设计算法就更具挑战性。我们的解决方案需要结合不同买家市场的购物偏好和文化传统。我们提出了 SEQ+MD 框架，该框架集成了多任务学习 (MTL) 的顺序学习和多分布输入的特征生成区域掩码。这种方法利用任务中的顺序并考虑区域异质性，从而提高了多源数据的性能。对内部数据的评估表明，与最先进的基线模型相比，包括添加到购物车和购买在内的高价值参与度大幅提升，同时保持点击性能中立。此外，我们的多区域学习模块是“即插即用”的，可以轻松调整以增强其他 MTL 应用程序。]]></description>
      <guid>https://arxiv.org/abs/2408.13357</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Airbnb 位置检索转型：从启发式到强化学习的旅程</title>
      <link>https://arxiv.org/abs/2408.13399</link>
      <description><![CDATA[arXiv:2408.13399v1 公告类型：新
摘要：Airbnb 搜索系统在不断发展的过程中面临着许多独特的挑战。我们监管的市场因地理位置、房源多样性和具有各种偏好的客人而千差万别。打造一个高效的搜索系统，既能满足不同客人的需求，又能展示相关的房源，是 Airbnb 成功的核心。Airbnb 搜索面临着许多与其他推荐和搜索系统相似的挑战，但它有一个独特的信息检索问题，即排名的上游，称为位置检索。它需要定义与搜索查询相关的拓扑地图区域，以进行房源列表检索。本文的目的是展示从头开始构建基于机器学习的位置检索产品的方法、挑战和影响。尽管缺乏合适的、流行的基于机器学习的方法，但我们还是解决了冷启动、泛化、分化和算法偏差。我们详细介绍了启发式、统计学、机器学习和强化学习方法解决这些挑战的有效性，特别是对于当前文献中通常未探索的系统。]]></description>
      <guid>https://arxiv.org/abs/2408.13399</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ColBERT 基于 [MASK] 的查询增强：将查询输入长度增加四倍的效果</title>
      <link>https://arxiv.org/abs/2408.13672</link>
      <description><![CDATA[arXiv:2408.13672v1 公告类型：新 
摘要：ColBERT 的一个独特之处在于它在查询中使用 [MASK] 标记来对文档进行评分（查询增强）。先前的工作表明 [MASK] 标记对非 [MASK] 查询词进行加权，强调某些标记优于其他标记，而不是像最初提议的那样引入全新的词。我们首先证明之前报告的 ColBERTv1 中 [MASK] 标记的词权重行为适用于 ColBERTv2。然后，我们检查将 [MASK] 标记的数量从零更改为训练中使用的查询输入长度的四倍（对于第一阶段检索和对候选者进行评分）的效果，观察到最初使用少量 [MASK] 时性能会下降，当添加足够多的 [MASK] 以将查询填充到平均长度 32 时，性能会大幅提升，然后性能会趋于稳定。此外，我们将基线性能与查询长度扩展到 128 个标记时的性能进行比较，发现差异很小（例如，在各种指标上相差 1% 以内）并且通常在统计上不显著，表明如果 ColBERT 呈现的 [MASK] 标记多于预期，性能不会崩溃。]]></description>
      <guid>https://arxiv.org/abs/2408.13672</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的推荐系统已经是最好的了吗？简单的缩放交叉熵释放了传统顺序推荐系统的潜力</title>
      <link>https://arxiv.org/abs/2408.14238</link>
      <description><![CDATA[arXiv:2408.14238v1 公告类型：新
摘要：大型语言模型 (LLM) 在推荐社区中越来越受到关注。一些研究发现，当使用具有完整 softmax 的交叉熵 (CE) 损失进行微调时，LLM 可以在顺序推荐中实现“最先进的”性能。然而，用于比较的大多数基线都是使用逐点/成对损失函数进行训练的。这种不一致的实验设置导致低估传统方法，并进一步助长了对 LLM 排名能力的过度自信。
在本研究中，我们通过展示交叉熵损失的两个理想特性：紧密性和覆盖性，为交叉熵损失的优越性提供了理论依据。此外，本研究还揭示了其他新颖的见解：1) 仅考虑推荐性能，CE 尚未达到最优，因为在某些排名指标方面它不是一个相当严格的界限。 2）在无法执行完整 softmax 的情况下，一种有效的替代方案是扩大采样的正则化项。这些发现有助于释放传统推荐模型的潜力，使其超越基于 LLM 的模型。鉴于巨大的计算负担，现有的基于 LLM 的方法对于顺序推荐并不像声称的那样有效。我们希望这些理论理解与实证结果相结合，将有助于在未来客观评估基于 LLM 的推荐。]]></description>
      <guid>https://arxiv.org/abs/2408.14238</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CURE4Rec：具有更深层次影响的推荐学习基准</title>
      <link>https://arxiv.org/abs/2408.14393</link>
      <description><![CDATA[arXiv:2408.14393v1 公告类型：新
摘要：随着人工智能中隐私问题的日益严重，法规已规定了被遗忘权，赋予个人从模型中撤回数据的权利。机器反学习已成为一种潜在的解决方案，可以在模型中实现选择性遗忘，特别是在历史数据包含敏感用户信息的推荐系统中。尽管最近在推荐反学习方面取得了进展，但由于缺乏统一的评估框架和忽视了更深层次影响的方面，例如公平性，全面评估反学习方法仍然具有挑战性。为了解决这些差距，我们提出了 CURE4Rec，这是第一个全面的推荐反学习评估基准。CURE4Rec 涵盖了四个方面，即反学习完整性、推荐效用、反学习效率和推荐公平性，以及三种数据选择策略，即核心数据、边缘数据和随机数据。具体而言，我们考虑了反学习对具有不同影响程度的数据的推荐公平性和鲁棒性的更深层次影响。我们构建了多个 CURE4Rec 评估数据集，并对现有的推荐反学习方法进行了广泛的实验。我们的代码发布在 https://github.com/xiye7lai/CURE4Rec。]]></description>
      <guid>https://arxiv.org/abs/2408.14393</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DrugAgent：具有基于大型语言模型推理的可解释药物再利用代理</title>
      <link>https://arxiv.org/abs/2408.13378</link>
      <description><![CDATA[arXiv:2408.13378v1 公告类型：交叉 
摘要：药物再利用通过识别现有药物的新治疗潜力，为加速药物开发提供了一条有希望的途径。在本文中，我们提出了一个多智能体框架，使用最先进的机器学习技术和知识整合来增强药物再利用过程。我们的框架由几个专门的代理组成：一个人工智能代理训练强大的药物-靶标相互作用 (DTI) 模型；一个知识图谱代理利用药物-基因相互作用数据库 (DGIdb)、DrugBank、比较毒理基因组学数据库 (CTD) 和化学物质相互作用搜索工具 (STITCH) 系统地提取 DTI；搜索代理与生物医学文献交互以注释和验证计算预测。通过整合这些代理的输出，我们的系统有效地利用了包括外部数据库在内的各种数据源来提出可行的再利用候选方案。初步结果表明，我们的方法不仅在预测药物与疾病的相互作用方面具有潜力，而且在减少传统药物发现方法所需的时间和成本方面也具有潜力。本文重点介绍了多智能体系统在生物医学研究中的可扩展性及其在推动药物再利用创新方面的作用。我们的方法不仅在预测药物再利用潜力方面优于现有方法，而且还提供了可解释的结果，为更高效、更具成本效益的药物发现过程铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2408.13378</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行中医命名实体识别与 COVID-19 文献对比研究</title>
      <link>https://arxiv.org/abs/2408.13501</link>
      <description><![CDATA[arXiv:2408.13501v1 公告类型：交叉 
摘要：目的：探索和比较 ChatGPT 和其他最先进的 LLM 在特定领域 NER 任务上的表现，这些任务涵盖中医抗击 COVID-19 文献中不同实体类型和领域。方法：我们建立了一个包含 389 篇中医抗击 COVID-19 文章的数据集，并以属于 3 个领域的 6 种实体类型作为基本事实，手动注释了其中 48 篇，以此来评估 LLM 的 NER 性能。然后，我们使用 ChatGPT（GPT-3.5 和 GPT-4）和 4 个最先进的基于 BERT 的问答 (QA) 模型（RoBERTa、MiniLM、PubMedBERT 和 SciBERT）对 6 种实体类型执行 NER 任务，而无需事先对特定任务进行训练。还应用了领域微调模型 (GSAP-NER) 进行全面比较。结果：在精确匹配和模糊匹配上，LLM 的整体性能存在明显差异。在模糊匹配中，ChatGPT 在 6 项任务中的 5 项上超越了基于 BERT 的 QA 模型；而在精确匹配中，基于 BERT 的 QA 模型在 6 项任务中的 5 项上优于 ChatGPT，但 F-1 差异较小。GPT-4 在模糊匹配中表现出显著优势，尤其是在中药配方实体类型和中成药 (TFD) 和成分 (IG) 上。虽然 GPT-4 在草药实体类型、目标和研究方法上优于基于 BERT 的模型，但 F-1 得分均未超过 0.5。GSAP-NER 在 F-1 方面略胜于 GPT-4，RM 略胜一筹。ChatGPT 的召回率远高于准确率，尤其是在模糊匹配中。结论：LLM 的 NER 性能高度依赖于实体类型，并且其性能因应用场景而异。对于需要高召回率的场景，ChatGPT 可能是一个不错的选择。但是，对于严格场景下的知识获取，ChatGPT 和基于 BERT 的 QA 模型都不是专业从业者的现成工具。]]></description>
      <guid>https://arxiv.org/abs/2408.13501</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HRGraph：利用 LLM 构建人力资源数据知识图谱，并基于信息传播进行职位推荐</title>
      <link>https://arxiv.org/abs/2408.13521</link>
      <description><![CDATA[arXiv:2408.13521v1 公告类型：交叉 
摘要：知识图谱 (KG) 作为语义网络，通过提供统一、情境化和结构化的表示形式，并具有灵活性，可以轻松适应不断发展的知识，在管理不同领域的复杂互连数据方面被证明是非常有效的。通过处理复杂的人力资源 (HR) 数据，KG 可以帮助完成不同的人力资源职能，如招聘、工作匹配、识别学习差距和提高员工保留率。尽管它们具有潜力，但在实施实用的人力资源知识图谱方面所做的努力有限。本研究通过提出一个使用大型语言模型从文档中有效开发人力资源知识图谱的框架来解决这一差距。由此产生的 KG 可用于各种下游任务，包括工作匹配、识别员工技能差距等等。在这项工作中，我们展示了人力资源 KG 在精确工作匹配方面发挥重要作用的案例，为雇主和雇员都带来了好处。知识图谱和图神经网络中的信息传播实验以及案例研究的经验证据强调了知识图谱在工作和员工推荐以及工作领域分类等任务中的有效性。代码和数据可在以下位置获取：https://github.com/azminewasi/HRGraph]]></description>
      <guid>https://arxiv.org/abs/2408.13521</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgentMove：使用基于大型语言模型的 Agentic 框架预测人类在任何地方的流动性</title>
      <link>https://arxiv.org/abs/2408.13986</link>
      <description><![CDATA[arXiv:2408.13986v1 公告类型：交叉 
摘要：人类流动性预测在各种实际应用中起着至关重要的作用。尽管基于深度学习的模型在过去十年中已经显示出有希望的结果，但它们对大量私人流动性数据进行训练的依赖以及无法进行零样本预测，阻碍了进一步的发展。最近，人们尝试将大型语言模型 (LLM) 应用于流动性预测任务。然而，由于缺乏系统的工作流程设计，它们的性能受到限制。他们直接使用 LLM 生成最终输出，这限制了 LLM 发现复杂流动性模式的潜力，并低估了它们广泛的全球地理空间知识储备。在本文中，我们介绍了 AgentMove，这是一个系统的代理预测框架，可实现全球任何城市的广义流动性预测。在 AgentMove 中，我们首先将移动性预测任务分解为三个子任务，然后设计相应的模块来完成这些子任务，包括用于个人移动模式挖掘的时空记忆、用于建模城市结构影响的世界知识生成器和用于捕捉人口间共享模式的集体知识提取器。最后，我们结合三个模块的结果并进行推理步骤以生成最终预测。对来自 12 个城市的两个来源的移动性数据进行的大量实验表明，AgentMove 在各种指标上的表现均比最佳基线高出 8% 以上，并且它以各种 LLM 为基础表现出稳健的预测，并且跨城市的地理偏差较小。代码和数据可以在 https://github.com/tsinghua-fib-lab/AgentMove 中找到。]]></description>
      <guid>https://arxiv.org/abs/2408.13986</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向终身学习嵌入：一种动态扩展嵌入的算法方法</title>
      <link>https://arxiv.org/abs/2408.14118</link>
      <description><![CDATA[arXiv:2408.14118v1 公告类型：交叉 
摘要：技术的快速发展改变了全球的商业运作和客户互动，个性化成为电子商务公司更有效地吸引客户的关键机会。机器学习的应用，特别是深度学习模型的应用，由于其能够快速识别大数据集中的模式，从而为个性化提供了无数可能性，获得了显著的吸引力。这些模型使用嵌入将离散信息（例如产品 ID）映射到潜在向量空间中，这种方法近年来越来越流行。然而，电子商务的动态特性（以频繁推出新产品为特征）对这些嵌入提出了挑战，这些嵌入通常需要固定的维度和输入，因此需要定期从头开始重新训练。本文介绍了一种模块化算法，该算法在保留学习到的知识的同时扩展了嵌入输入的大小，解决了电子商务动态性带来的挑战。所提出的算法还结合了缓解新产品冷启动问题的策略。初步实验的结果表明，该方法优于传统嵌入。]]></description>
      <guid>https://arxiv.org/abs/2408.14118</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有羊群效应的上下文老虎机：算法和推荐应用</title>
      <link>https://arxiv.org/abs/2408.14432</link>
      <description><![CDATA[arXiv:2408.14432v1 公告类型：交叉 
摘要：上下文老虎机是优化在线推荐决策的基本算法框架。尽管人们广泛关注为推荐应用定制上下文老虎机，但用户反馈中的“羊群效应”却被忽略了。这些羊群效应使用户反馈偏向历史评分，打破了上下文老虎机固有的无偏反馈假设。本文开发了一种上下文老虎机的新变体，专门用于解决羊群效应引起的反馈偏差。制定了一个用户反馈模型来捕捉这种反馈偏差。我们设计了 TS-Conf（一致性下的汤普森采样）算法，该算法采用后验采样来平衡探索和利用权衡。我们证明了算法遗憾的上限，揭示了羊群效应对学习速度的影响。对数据集的大量实验表明，TS-Conf 优于四种基准算法。分析表明，TS-Conf 有效地减轻了羊群效应的负面影响，从而加快了学习速度并提高了推荐准确性。]]></description>
      <guid>https://arxiv.org/abs/2408.14432</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>顺序推荐的智能模型更新策略</title>
      <link>https://arxiv.org/abs/2302.07335</link>
      <description><![CDATA[arXiv:2302.07335v2 公告类型：替换 
摘要：现代在线平台越来越多地采用推荐系统来解决信息过载问题并提高用户参与度。该研究领域有一个不断发展的范式，即推荐网络学习既发生在云端，也发生在边缘，知识在两者之间传递（即边缘-云协作）。最近的研究通过实现特定于边缘的上下文感知自适应性进一步推动了这一领域的发展，其中模型参数根据传入的边缘数据实时更新。然而，我们认为，云和边缘之间频繁的数据交换往往会导致效率低下和通信/计算资源的浪费，因为大量的参数更新可能是多余的。为了研究这个问题，我们引入了智能边缘-云参数请求模型，简称为 IntellectReq。
IntellectReq 旨在在边缘上运行，以最少的计算和通信开销评估参数请求的成本效益格局。我们将其制定为一种新颖的学习任务，旨在检测分布外的数据，从而微调自适应通信策略。此外，我们采用统计映射技术将实时用户行为转换为正态分布，从而采用多样本输出来量化模型的不确定性及其泛化能力。在四个广泛采用的基准上进行严格的实证验证，评估了我们的方法，证明了边缘云协作和动态推荐系统的效率和泛化能力有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2302.07335</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CALRec：用于顺序推荐的生成式 LLM 的对比对齐</title>
      <link>https://arxiv.org/abs/2405.02429</link>
      <description><![CDATA[arXiv:2405.02429v2 公告类型：替换 
摘要：传统的推荐系统（例如矩阵分解方法）主要侧重于学习共享的密集嵌入空间来表示项目和用户偏好。随后，RNN、GRU 以及最近的 Transformers 等序列模型应运而生，并在顺序推荐任务中表现出色。此任务需要了解用户历史交互中存在的顺序结构，以预测他们可能喜欢的下一个项目。基于大型语言模型 (LLM) 在各种任务中的成功，研究人员最近探索了使用在大量文本语料库上预先训练的 LLM 进行顺序推荐。要使用 LLM 进行顺序推荐，用户交互的历史记录和模型对下一个项目的预测都以文本形式表示。我们提出了 CALRec，这是一个两阶段 LLM 微调框架，它使用两种对比损失和一种语言建模损失的混合，以双塔方式对预训练的 LLM 进行微调：首先在来自多个域的数据混合上对 LLM 进行微调，然后再进行一轮目标域微调。我们的模型明显优于许多最先进的基线（Recall@1 中 +37%，NDCG@10 中 +24%），我们的系统消融研究表明：(i) 两个微调阶段都至关重要，如果结合起来，我们可以实现更高的性能；(ii) 对比对齐在我们实验中探索的目标域中是有效的。]]></description>
      <guid>https://arxiv.org/abs/2405.02429</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预算约束下基于提升模型的端到端成本效益激励推荐</title>
      <link>https://arxiv.org/abs/2408.11623</link>
      <description><![CDATA[arXiv:2408.11623v2 公告类型：替换 
摘要：在现代在线平台中，激励措施是增强用户参与度和增加平台收入的重要因素。近年来，提升模型已被引入作为一种向个人客户分配激励的战略方法。特别是在许多实际应用中，在线平台只能激励具有特定预算约束的客户。这个问题可以重新表述为多选背包问题。这种优化旨在为每个客户选择最佳激励措施，以最大化投资回报。该领域的最新研究经常使用两阶段方法解决预算分配问题。然而，这种解决方案面临以下挑战：（1）因果推理方法通常忽略在线营销中的领域知识，其中客户的预期响应曲线应该随着激励的增加而单调且平滑。（2）由于在有限的预算约束下丢失了提升预测的激励推荐信息，因此两个阶段之间的最优性差距导致次优分配性能较差。为了应对这些挑战，我们提出了一种预算约束下的新型端到端成本效益激励推荐 (E3IR) 模型。具体来说，我们的方法由两个模块组成，即提升预测模块和可微分配模块。在提升预测模块中，我们构建了预测头，以捕获具有营销领域约束（即单调和平滑）的相邻处理之间的增量改进。我们将整数线性规划 (ILP) 作为可微层输入纳入分配模块。此外，我们在公共和真实产品数据集上进行了广泛的实验，证明与现有的两阶段方法相比，我们的 E3IR 提高了分配性能。]]></description>
      <guid>https://arxiv.org/abs/2408.11623</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从零到英雄：利用 Transformer 在零样本和少样本环境下进行生物医学命名实体识别</title>
      <link>https://arxiv.org/abs/2305.04928</link>
      <description><![CDATA[arXiv:2305.04928v5 公告类型：replace-cross 
摘要：生物医学领域的监督命名实体识别 (NER) 依赖于具有给定命名实体的大量带注释文本。此类数据集的创建可能非常耗时且成本高昂，而提取新实体则需要额外的注释任务并重新训练模型。为了应对这些挑战，本文提出了一种生物医学领域的零样本和少样本 NER 方法。该方法基于将多类标记分类任务转换为二分类标记分类，并在大量数据集和生物医学实体上进行预训练，从而使模型能够学习给定和潜在新命名实体标签之间的语义关系。使用基于 PubMedBERT 的微调模型，我们在 9 个不同的评估生物医学实体上取得了平均 F1 得分：零样本 NER 为 35.44%，单样本 NER 为 50.10%，10 样本 NER 为 69.94%，100 样本 NER 为 79.51%。结果证明了所提出的方法在识别新的生物医学实体方面非常有效，无需任何示例或示例数量有限，优于以前基于 Transformer 的方法，并且与基于 GPT3 的模型相当，所用模型的参数比 GPT3 少 1000 多倍。我们公开了模型和开发的代码。]]></description>
      <guid>https://arxiv.org/abs/2305.04928</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>