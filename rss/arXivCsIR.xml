<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过解决位置偏见来降低受欢迎程度的影响</title>
      <link>https://arxiv.org/abs/2412.08780</link>
      <description><![CDATA[arXiv:2412.08780v1 公告类型：新
摘要：位置偏差对推荐系统提出了持续的挑战，现有的大部分研究都集中在改进排名相关性和推动用户参与度上。然而，在实际应用中，减轻位置偏差并不总是会导致排名相关性在短期内得到明显的改善。本文提供了一种替代的、实用的观点，说明了位置偏差减少方法可以实现什么。它表明，位置去偏可以更均匀地在整个产品组合中传播可见性和交互，通过反馈回路有效地减少由位​​置偏差引起的产品流行度偏差。我们解释了位置偏差如何影响产品流行度。这包括产品流行度直方图的说明性模型以及位置偏差对其偏度的影响。通过在我们大型电子商务平台上进行的离线和在线实验，我们表明，位置去偏可以显着提高产品组合利用率，而不会降低用户参与度或财务指标。这使得排名更加公平，有助于吸引更多的合作伙伴或内容提供商，从长远来看使客户和企业受益。]]></description>
      <guid>https://arxiv.org/abs/2412.08780</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOPI-HFRS：具有 LLM 增强解释能力的多目标个性化健康食品推荐系统</title>
      <link>https://arxiv.org/abs/2412.08847</link>
      <description><![CDATA[arXiv:2412.08847v1 公告类型：新
摘要：不健康饮食习惯的盛行已成为美国日益令人担忧的问题。然而，主要的食品推荐平台（例如 Yelp）仍然优先考虑用户的饮食偏好，而不是他们选择的健康程度。尽管人们已经努力开发健康意识食品推荐系统，但基于用户特定健康状况的此类系统的个性化仍未得到充分探索。此外，很少有研究关注这些系统的可解释性，这阻碍了用户评估建议的可靠性并阻碍了这些系统的实际部署。为了弥补这一差距，我们首先在第一次尝试中建立了两个大规模个性化健康意识食品推荐基准。然后，我们开发了一个新框架，即多目标个性化可解释健康意识食品推荐系统 (MOPI-HFRS)，该系统通过联合优化三个目标提供食品推荐：用户偏好、个性化健康和营养多样性，以及大型语言模型 (LLM) 增强推理模块，通过解释推荐结果来促进健康饮食知识。具体来说，这个整体图学习框架首先利用两个结构学习和一个结构池模块来利用描述性特征和健康数据。然后，它采用帕累托优化来实现设计的多方面目标。最后，为了进一步促进健康饮食知识和意识，我们利用知识注入来开发 LLM，使用从推荐模型中获得的知识提示 LLM 进行解释。]]></description>
      <guid>https://arxiv.org/abs/2412.08847</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SPRec：利用自我博弈消除基于大型语言模型的推荐偏好偏差</title>
      <link>https://arxiv.org/abs/2412.09243</link>
      <description><![CDATA[arXiv:2412.09243v1 公告类型：新
摘要：大型语言模型 (LLM) 在推荐系统中引起了广泛关注。当前基于 LLM 的推荐系统主要依靠监督微调 (SFT) 来训练模型以完成推荐任务。然而，仅仅依靠正样本会限制模型与用户满意度和期望保持一致的能力。为了解决这个问题，研究人员引入了直接偏好优化 (DPO)，它使用离线偏好排名数据明确地将推荐与用户偏好对齐。尽管它有优势，但我们的理论分析表明，DPO 本质上会使模型偏向少数项目，从而加剧过滤气泡问题并最终降低用户体验。在本文中，我们提出了 SPRec，这是一种新颖的自我游戏推荐框架，旨在减轻过度推荐并提高公平性，而无需额外的数据或人工干预。在每次自我对弈迭代中，模型都会经历一个 SFT 步骤，然后是 DPO 步骤，将离线交互数据视为正样本，将上一次迭代的预测输出视为负样本。这有效地利用模型的逻辑重新加权 DPO 损失函数，自适应地抑制有偏差的项目。在多个真实数据集上进行的大量实验证明了 SPRec 在提高推荐准确性和解决公平性问题方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.09243</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>jina-clip-v2：文本和图像的多语言多模式嵌入</title>
      <link>https://arxiv.org/abs/2412.08802</link>
      <description><![CDATA[arXiv:2412.08802v1 公告类型：交叉 
摘要：对比语言-图像预训练 (CLIP) 是一种在共享嵌入空间中对齐图像和文本的高效方法。这些模型广泛用于跨模态信息检索和多模态理解等任务。然而，CLIP 模型通常在纯文本任务中表现不佳，与专门的文本模型相比表现不佳。这种性能差异迫使检索系统依赖于单独的模型来完成纯文本和多模态任务。在这项工作中，我们在之前的模型 jina-clip-v1 的基础上，引入了一个精炼的框架，该框架利用跨多种语言的多任务、多阶段对比学习，并结合改进的训练方法以增强纯文本检索。由此产生的模型 jina-clip-v2 在纯文本和多模态任务上的表现优于其前身，同时增加了多语言支持，更好地理解复杂的视觉文档，并借助 Matryoshka 表示学习和向量截断提高了效率。该模型在多语言-多模态和多语言文本检索基准测试中的表现与最先进的模型相当，解决了统一纯文本和多模态检索系统的挑战。]]></description>
      <guid>https://arxiv.org/abs/2412.08802</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多目标推荐的目标条件监督学习</title>
      <link>https://arxiv.org/abs/2412.08911</link>
      <description><![CDATA[arXiv:2412.08911v1 公告类型：交叉 
摘要：多目标学习致力于使用单一模型同时优化多个目标，旨在实现这些不同目标之间的高且平衡的性能。然而，它通常涉及更复杂的优化问题，特别是在处理目标之间的潜在冲突时，导致解决方案具有更高的内存要求和计算复杂性。本文介绍了一种多目标目标条件监督学习 (MOGCSL) 框架，用于自动学习从离线序列数据中实现多个目标。MOGCSL 通过将目标从一维标量重新定义为多维向量，将传统的目标条件监督学习 (GCSL) 方法扩展到多目标场景。可以自然消除对复杂架构和优化约束的需求。MOGCSL 的好处是过滤掉无法实现理想长期回报的无信息或嘈杂实例。它还采用了一种新颖的目标选择算法来建模和选择“高”可实现目标进行推理。
虽然 MOGCSL 非常通用，但我们专注于将其应用于商业级推荐系统中的下一个动作预测问题。在这种情况下，任何可行的解决方案都需要具有合理的可扩展性，并且对大量噪声数据具有鲁棒性，这是该应用领域的特征。我们表明 MOGCSL 在这两方面都表现出色。具体而言，在现实世界的推荐数据集上进行的大量实验验证了其有效性和效率。此外，还包括分析和实验来解释其在推荐系统中降低训练数据中噪声较大部分的优势。]]></description>
      <guid>https://arxiv.org/abs/2412.08911</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种灵活的即插即用模块，用于生成可变长度</title>
      <link>https://arxiv.org/abs/2412.08922</link>
      <description><![CDATA[arXiv:2412.08922v1 公告类型：交叉 
摘要：深度监督哈希已成为大规模图像检索中的关键技术，在存储和搜索效率方面具有显着优势。然而，现有的深度监督哈希模型主要侧重于生成固定长度的哈希码。这种方法无法解决使用不同长度的哈希码时效率和有效性之间的固有权衡。为了确定特定任务的最佳哈希码长度，必须针对不同长度训练多个模型，从而增加训练时间和计算开销。此外，当前范式忽略了不同长度的哈希码之间的潜在关系，从而限制了模型的整体有效性。为了应对这些挑战，我们提出了嵌套哈希层（NHL），这是一个为现有深度监督哈希模型设计的即插即用模块。NHL 框架引入了一种新颖的机制，可以以嵌套方式同时生成不同长度的哈希码。为了解决由不同代码长度相关的多个学习目标引起的优化冲突，我们进一步提出了一种自适应权重策略，该策略可在训练期间动态监控和调整梯度。此外，认识到较长哈希码中的结构信息可以为较短哈希码提供有价值的指导，我们在 NHL 中开发了一种长短级联自蒸馏方法，以提高生成的哈希码的整体质量。大量实验表明，NHL 不仅可以加速训练过程，而且可以在各种深度哈希模型中实现出色的检索性能。我们的代码可在 https://github.com/hly1998/NHL 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2412.08922</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用全球规模遥测数据和联合学习预测视频游戏体验质量</title>
      <link>https://arxiv.org/abs/2412.08950</link>
      <description><![CDATA[arXiv:2412.08950v1 公告类型：交叉 
摘要：每秒帧数 (FPS) 显著影响游戏体验。在购买之前为玩家提供准确的 FPS 估计值对玩家和游戏开发者都有好处。然而，我们对如何预测游戏在特定设备上的 FPS 性能的理解有限。在本文中，我们首先在全球规模的数据集上对可能影响游戏 FPS 的各种因素进行全面分析，以确定 FPS 的决定因素。这包括玩家端和游戏端的特征，以及国家层面的社会经济统计数据。此外，认识到准确的 FPS 预测需要大量的用户数据，这引发了隐私问题，我们提出了一个基于联邦学习的模型来确保用户隐私。每个玩家和游戏都被分配一个独特的可学习知识内核，该内核逐渐提取潜在特征以提高准确性。我们还引入了一种新颖的训练和预测方案，允许这些内核动态即插即用，有效解决冷启动问题。为了以最小的偏差训练此模型，我们收集了来自 224 个国家和地区、100,000 名用户和 835 款游戏的大型遥测数据集。我们的模型实现了预测 FPS 分布与真实 FPS 分布之间的平均 Wasserstein 距离为 0.469，优于所有基线方法。]]></description>
      <guid>https://arxiv.org/abs/2412.08950</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当文本嵌入遇到大型语言模型：全面调查</title>
      <link>https://arxiv.org/abs/2412.09165</link>
      <description><![CDATA[arXiv:2412.09165v1 公告类型：交叉 
摘要：在深度学习时代，文本嵌入已成为自然语言处理 (NLP) 的基础技术，推动了一系列下游任务的进步。虽然现在可以使用生成范式对许多自然语言理解挑战进行建模，并利用大型语言模型 (LLM) 强大的生成和理解能力，但许多实际应用（例如语义匹配、聚类和信息检索）仍然依赖于文本嵌入来实现其效率和有效性。在本次调查中，我们将 LLM 和文本嵌入之间的相互作用分为三个总体主题：(1) LLM 增强文本嵌入，使用 LLM 增强传统嵌入方法；(2) LLM 作为文本嵌入器，利用其固有的嵌入生成能力；(3) 使用 LLM 理解文本嵌入，利用 LLM 分析和解释嵌入。通过根据交互模式而不是特定的下游应用来组织这些工作，我们提供了一个新颖而系统的概述，概述了 LLM 时代各个研究和应用领域的贡献。此外，我们强调了 LLM 时代之前使用预训练语言模型 (PLM) 时仍然存在的未解决的挑战，并探讨了 LLM 带来的新障碍。在此分析的基础上，我们概述了文本嵌入发展的未来方向，解决了 NLP 快速发展领域中的理论和实践机会。]]></description>
      <guid>https://arxiv.org/abs/2412.09165</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>材料研究的基础大型语言模型</title>
      <link>https://arxiv.org/abs/2412.09560</link>
      <description><![CDATA[arXiv:2412.09560v1 公告类型：交叉 
摘要：材料的发现和开发对于应对全球挑战至关重要。然而，材料科学文献的指数级增长包含大量文本数据，这在知识提取、综合和科学推理方面造成了重大瓶颈。大型语言模型 (LLM) 通过自动分析和预测提供了前所未有的机会来加速材料研究。尽管如此，它们的有效部署需要特定领域的适应才能理解和解决与领域相关的任务。在这里，我们介绍了 LLaMat，这是一组材料科学的基础模型，它是通过在大量材料文献和晶体学数据上对 LLaMA 模型进行持续预训练而开发的。通过系统评估，我们证明 LLaMat 在材料特定的 NLP 和结构化信息提取方面表现出色，同时保持了一般的语言能力。专门的 LLaMat-CIF 变体展示了前所未有的晶体结构生成能力，可以预测整个元素周期表中具有高覆盖率的稳定晶体。有趣的是，尽管 LLaMA-3 的性能优于 LLaMA-2，但我们观察到 LLaMat-2 在各种材料科学任务中表现出意想不到的增强领域特定性能，包括从文本和表格中提取结构化信息，尤其是在晶体结构生成中，这是过度训练的 LLM 中潜在的适应刚性。总之，本研究证明了领域适应对于开发可用于材料研究的实用 LLM 副驾驶的有效性。除了材料科学之外，我们的研究结果还揭示了 LLM 领域适应的重要考虑因素，例如模型选择、训练方法和领域特定性能，这可能会影响专门的科学 AI 系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2412.09560</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HGCH：用于异构协作图推荐的双曲图卷积网络模型</title>
      <link>https://arxiv.org/abs/2304.02961</link>
      <description><![CDATA[arXiv:2304.02961v2 公告类型：替换 
摘要：协同过滤和图建模任务中的用户-项目交互数据通常表现出幂律特征，这表明双曲空间建模的适用性。双曲图卷积神经网络 (HGCN) 是一种利用 GCN 和双曲空间优势的新技术，并取得了显著的效果。然而，现有的 HGCN 方法有几个缺点：由于任意嵌入初始化和不精确的切线空间聚合，它们无法充分利用双曲空间属性；它们忽略了可以丰富协作图的辅助信息；并且由于边际排名损失和随机负采样，它们的训练收敛速度很慢。为了克服这些挑战，我们提出了用于异构推荐的双曲图协作 (HGCH)，这是一种基于 HGCN 的增强型协同过滤模型，它将各种侧面信息集成到异构协作图中并提高训练收敛速度。 HGCH 首先通过使用幂律先验初始化节点嵌入来保留图的长尾特性；然后使用回转中点法聚合双曲空间中的邻居以进行精确计算；最后，通过与先验的门融合将来自不同双曲空间的多个嵌入融合在一起。此外，HGCH 采用双曲用户特定负采样来加速收敛。我们在四个真实数据集上评估了 HGCH，结果表明 HGCH 取得了有竞争力的结果，并且优于包括 HGCN 在内的领先基线。广泛的消融研究进一步证实了其有效性。]]></description>
      <guid>https://arxiv.org/abs/2304.02961</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GANPrompt：使用 GAN 增强多样性提示增强基于 LLM 的建议的稳健性</title>
      <link>https://arxiv.org/abs/2408.09671</link>
      <description><![CDATA[arXiv:2408.09671v2 公告类型：替换 
摘要：近年来，大型语言模型（LLM）在理解和生成自然语言方面表现出色，在推荐系统领域越来越受欢迎。然而，LLM 仍然面临着一个重大挑战，称为提示敏感性，这指的是它很容易受到提示词的影响。这种对提示输入的微小改变的响应不一致可能会损害推荐模型的准确性和弹性。为了解决这个问题，本文提出了 GANPrompt，一个基于生成对抗网络（GAN）的多维 LLM 提示多样性框架。该框架通过将 GAN 生成技术与 LLM 的深度语义理解能力相结合，增强了模型对不同提示的适应性和稳定性。GANPrompt 首先通过分析多维用户行为数据来训练一个能够产生多样化提示的生成器。然后使用这些多样化的提示来训练 LLM，以提高其在面对从未见过的提示时的性能。此外，为了确保提示的高度多样性和相关性，本研究引入了一种基于数学理论的多样性约束机制，该机制对生成的提示进行优化，以确保它们不仅在表面上截然不同，而且在语义上涵盖广泛的用户意图。通过在多个数据集上进行的大量实验，我们证明了所提框架的有效性，特别是在提高推荐系统在复杂和动态环境中的适应性和鲁棒性方面。实验结果表明，与现有的最先进方法相比，GANPrompt 在准确性和鲁棒性方面有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2408.09671</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的密集检索的任务级分布式鲁棒优化</title>
      <link>https://arxiv.org/abs/2408.10613</link>
      <description><![CDATA[arXiv:2408.10613v2 公告类型：替换 
摘要：基于大型语言模型的密集检索 (LLM-DR) 针对来自不同领域的大量异构微调集合进行了优化。然而，关于其训练数据分布的讨论仍然很少。以前的研究依赖于经验分配的数据集选择或采样率，这不可避免地会导致次优检索性能。在本文中，我们提出了一种用于 LLM-DR 微调的新任务级分布稳健优化 (tDRO) 算法，旨在通过端到端重新加权每个任务的数据分布来提高通用域泛化能力。tDRO 参数化域权重并使用缩放的域梯度更新它们。然后将优化的权重转移到 LLM-DR 微调以训练更稳健的检索器。实验表明，将我们的优化算法应用于一系列不同大小的 LLM-DR 模型后，大规模检索基准得到了最佳改进，并且数据集使用量减少了高达 30%。]]></description>
      <guid>https://arxiv.org/abs/2408.10613</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>写作风格很重要：信息检索系统中的偏见和公平性考察</title>
      <link>https://arxiv.org/abs/2411.13173</link>
      <description><![CDATA[arXiv:2411.13173v2 公告类型：替换 
摘要：语言模型技术的快速发展带来了新的机遇，但也带来了与偏见和公平性相关的新挑战。本文探讨了最先进的通用文本嵌入模型在信息检索 (IR) 系统中对特定文档和查询写作风格的潜在偏见的未知领域。我们的调查显示，不同的嵌入模型表现出不同的文档写作风格偏好，而大多数嵌入模型不太青睐非正式和情绪化的风格。在查询写作风格方面，许多嵌入模型倾向于将查询的风格与检索到的文档的风格相匹配，但有些模型表现出对特定风格的一致偏好。在 LLM 生成的合成数据上微调的文本嵌入模型显示出对某些生成数据风格的一致偏好。基于文本嵌入的 IR 系统中的这些偏见可能会无意中压制或边缘化某些沟通风格，从而对信息检索的公平性构成重大威胁。最后，我们还比较了基于不同 LLM 的检索增强生成 (RAG) 系统的答案风格，发现大多数文本嵌入模型在用作答案正确性的评估指标时都偏向于 LLM 的答案风格。这项研究揭示了 IR 系统中基于写作风格的偏见这一关键问题，为开发更公平、更强大的模型提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.13173</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线推荐的信息作用：来自实地实验的证据</title>
      <link>https://arxiv.org/abs/2211.14219</link>
      <description><![CDATA[arXiv:2211.14219v2 公告类型：替换交叉
摘要：我们在电影推荐平台上进行了一项实地实验，以调查在线推荐是否以及如何影响消费选择。我们的实验采用受试者内设计，测量推荐对消费的因果影响，并分解两种经济机制的相对重要性：扩大消费者的考虑范围并提供有关其特殊匹配值的信息。我们发现信息成分发挥了更大的影响力——推荐塑造了消费者的信念，进而推动了消费，尤其是在经验不足的消费者中。我们的研究结果和实验设计为在线推荐系统的经济评估和优化提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2211.14219</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为使用领域特定知识实例化本体的预言机</title>
      <link>https://arxiv.org/abs/2404.04108</link>
      <description><![CDATA[arXiv:2404.04108v2 公告类型：replace-cross 
摘要：背景。赋予智能系统语义数据通常需要设计和实例化具有领域特定知识的本体。特别是在早期阶段，这些活动通常由人类专家手动执行，可能利用他们自己的经验。因此，由此产生的过程非常耗时、容易出错，并且经常受到本体设计者个人背景的偏见。目的。为了缓解这个问题，我们提出了一种新颖的领域独立方法，通过利用大型语言模型 (LLM) 作为预言机，自动实例化具有领域特定知识的本体。方法。从 (i) 由相互关联的类和属性组成的初始模式和 (ii) 一组查询模板开始，我们的方法多次查询 LLM，并从其回复中为类和属性生成实例。因此，本体会自动填充符合初始模式的领域特定知识。结果，本体可以快速自动地丰富多种实例，专家可以根据自己的需要和专业知识考虑保留、调整、丢弃或补充这些实例。贡献。我们以一般方式形式化我们的方法，并在各种 LLM 以及具体案例研究中实例化它。我们报告了植根于营养领域的实验，其中从膳食及其关系的分类开始，从头开始自动实例化食物膳食及其成分的本体。在那里，我们分析生成的本体的质量，并比较通过利用不同的 LLM 获得的本体。通过实验，我们的方法实现了比最先进技术高出五倍的质量指标，同时将错误的实体和关系减少了十倍。最后，我们对所提出的方法进行了 SWOT 分析。]]></description>
      <guid>https://arxiv.org/abs/2404.04108</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>