<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 22 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用分离嵌入和自注意力进行特征挖掘的推荐模型</title>
      <link>https://arxiv.org/abs/2410.15026</link>
      <description><![CDATA[arXiv:2410.15026v1 Announce Type: new 
摘要：随着互联网数据的爆炸式增长，用户面临着信息过载的问题，如何高效地获取所需资源成为挑战。推荐系统正是在这样的背景下应运而生，通过筛选海量信息，为用户提供符合其需求的内容，在广告推荐、商品推荐等场景中发挥着关键作用。然而传统的点击率预测、TOP-K推荐机制由于计算复杂度高、内存消耗大、特征选择时间长、特征交互不足等问题，逐渐无法满足现代生活场景中的推荐需求。本文提出了一种基于分离embedding交叉网络的推荐系统模型，该模型利用embedding神经网络层将稀疏特征向量转化为稠密embedding向量，并能独立地在不同维度上进行特征交叉操作，从而提高特征挖掘的准确率和深度。实验结果表明，该模型在处理复杂数据集时表现出更强的适应性和更高的预测准确率，有效解决了现有模型存在的问题。]]></description>
      <guid>https://arxiv.org/abs/2410.15026</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将群组先验纳入变分推理，用于 CTR 预测中的尾部用户行为建模</title>
      <link>https://arxiv.org/abs/2410.15098</link>
      <description><![CDATA[arXiv:2410.15098v1 公告类型：新
摘要：用户行为建模旨在从行为数据中提取用户兴趣，在点击率 (CTR) 预测中表现出强大的威力，这是推荐系统的关键组成部分。最近，基于注意力的算法已成为一个有前途的方向，因为注意力机制强调来自丰富行为的相关交互。然而，这些方法很难捕捉到具有稀疏交互历史的尾部用户的偏好。为了解决这个问题，我们提出了一种新的变分推理方法，即组先验采样变分推理 (GPSVI)，它引入群体偏好作为先验来细化尾部用户的潜在用户兴趣。在 GPSVI 中，调整的程度取决于个人偏好建模的估计不确定性。此外，我们通过体积保持流进一步增强了变分推理的表达能力。GPSVI 方法的一个吸引人的特性是它能够恢复到具有丰富行为数据的头部用户的传统注意力，同时持续提高具有稀疏行为的长尾用户的性能。严格的分析和大量的实验表明，GPSVI 可以持续提高尾部用户的表现。此外，在大规模真实世界推荐系统上进行的在线 A/B 测试进一步证实了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.15098</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>挖掘不对称互文性</title>
      <link>https://arxiv.org/abs/2410.15145</link>
      <description><![CDATA[arXiv:2410.15145v1 公告类型：新
摘要：本文介绍了自然语言处理 (NLP) 和数字人文 (DH) 中的一项新任务：挖掘非对称互文性。非对称互文性是指文本之间的单向关系，其中一个文本引用、引用或借用另一个文本而没有回报。这些关系在文学和历史文本中很常见，其中后来的作品引用了保持静态的经典或较旧的文本。
我们提出了一种可扩展且自适应的方法来挖掘非对称互文性，利用拆分-规范化-合并范式。在这种方法中，文档被分成更小的块，使用 LLM 辅助元数据提取将其规范化为结构化数据，并在查询期间合并以检测显式和隐式互文关系。我们的系统使用元数据过滤、向量相似性搜索和基于 LLM 的验证的组合来处理各个级别的互文性，从直接引用到释义和跨文档影响。
这种方法特别适合动态增长的语料库，例如不断扩展的文学档案或历史数据库。通过实现新文档的持续集成，该系统可以高效扩展，这对文学研究、历史研究和相关领域的数字人文学科从业者来说非常有价值。]]></description>
      <guid>https://arxiv.org/abs/2410.15145</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打造明天：社交媒体推荐中设计选择对新鲜内容的影响</title>
      <link>https://arxiv.org/abs/2410.15174</link>
      <description><![CDATA[arXiv:2410.15174v1 公告类型：新
摘要：社交媒体平台的普及导致每天都有数百万个新内容被创建。内容创作的激增强调了我们需要关注设计选择，因为它们会极大地影响内容保持相关性的时间。在当今的环境中，定期推荐新内容至关重要，尤其是在缺乏详细信息的情况下，各种因素（例如 UI 功能、算法和系统设置）都会影响内容在平台上的旅程。虽然以前的研究重点是新内容如何影响用户体验，但本研究采用了不同的方法，通过考虑内容本身来分析这些决策。
通过一系列精心设计的实验，我们探索了看似微小的决策如何影响内容的寿命，以内容进展 (CVP) 和内容生存 (CSR) 等指标来衡量。我们还强调了认识内容所经历的阶段的重要性，强调需要为每个阶段量身定制策略，因为一刀切的方法可能并不有效。此外，我们主张在内容生命周期研究中摆脱传统的实验设置，以避免在提出先进技术时出现潜在的误解，从而在评估过程中实现更高的精度和准确性。]]></description>
      <guid>https://arxiv.org/abs/2410.15174</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HyQE：使用假设查询嵌入对上下文进行排名</title>
      <link>https://arxiv.org/abs/2410.15262</link>
      <description><![CDATA[arXiv:2410.15262v1 公告类型：新
摘要：在检索增强系统中，上下文排名技术通常用于根据检索到的上下文与用户查询的相关性对其进行重新排序。一种标准方法是通过嵌入空间中上下文和查询之间的相似性来衡量这种相关性。然而，这种相似性往往无法捕捉到相关性。或者，大型语言模型 (LLM) 已用于对上下文进行排名。然而，当候选上下文的数量增加而 LLM 的上下文窗口大小仍然受到限制时，它们可能会遇到可扩展性问题。此外，这些方法需要使用特定于域的数据对 LLM 进行微调。在这项工作中，我们引入了一个可扩展的排名框架，该框架结合了嵌入相似性和 LLM 功能，而无需 LLM 微调。我们的框架使用预先训练的 LLM 根据检索到的上下文假设用户查询，并根据假设查询与用户查询之间的相似性对上下文进行排名。我们的框架在推理时非常高效，并且与许多其他检索和排名技术兼容。实验结果表明，我们的方法提高了多个基准测试中的排名性能。完整的代码和数据可在 https://github.com/zwc662/hyqe 上找到]]></description>
      <guid>https://arxiv.org/abs/2410.15262</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量子退火器推荐系统的性能驱动 QUBO</title>
      <link>https://arxiv.org/abs/2410.15272</link>
      <description><![CDATA[arXiv:2410.15272v1 公告类型：新
摘要：我们提出反事实分析二次无约束二元优化 (CAQUBO) 来解决推荐系统中特征选择的 QUBO 问题。CAQUBO 利用反事实分析来衡量单个特征和特征组合对模型性能的影响，并利用测量结果构建量子退火器的系数矩阵，为推荐系统选择最佳特征组合，从而提高其最终推荐性能。通过在特征和推荐性能之间建立明确的联系，与最先进的量子退火方法相比，所提出的方法表现出卓越的性能。大量实验表明，将量子计算与反事实分析相结合对于解决这些挑战大有裨益。]]></description>
      <guid>https://arxiv.org/abs/2410.15272</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签跨模态检索的深度类引导哈希</title>
      <link>https://arxiv.org/abs/2410.15387</link>
      <description><![CDATA[arXiv:2410.15387v1 Announce Type: new 
摘要：深度哈希由于其低成本、高效的检索优势，在跨模态检索中受到广泛重视。然而现有的跨模态哈希方法要么探索数据点之间的关系，这不可避免地导致类内弥散，要么探索数据点与类别之间的关系而忽略了类间结构关系的保存，导致生成的哈希码不是最优的。如何同时保持类内聚合性和类间结构关系，针对这一问题，本文提出了一种DCGH方法。具体来说，我们以代理损失为支柱来维护数据的类内聚合性，结合成对损失来维护类间结构关系，并在此基础上进一步提出方差约束来解决组合带来的语义偏差问题。在三个基准数据集上的大量对比实验表明，与现有的跨模态检索方法相比，DCGH方法具有相当甚至更好的性能。我们的 DCGH 框架实现的代码可在 https://github.com/donnotnormal/DCGH 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.15387</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ConTReGen：用于开放域长文本生成的上下文驱动树结构检索</title>
      <link>https://arxiv.org/abs/2410.15511</link>
      <description><![CDATA[arXiv:2410.15511v1 公告类型：新
摘要：开放域长文本生成需要生成连贯、全面的响应，以广度和深度解决复杂查询。这项任务具有挑战性，因为需要准确捕获输入查询的不同方面。现有的迭代检索增强生成 (RAG) 方法通常难以深入研究复杂查询的每个方面并有效地整合来自各种来源的知识。本文介绍了 ConTReGen，这是一种新颖的框架，它采用上下文驱动的树状结构检索方法来增强检索内容的深度和相关性。ConTReGen 将分层、自上而下的查询方面深入探索与系统自下而上的综合相结合，确保全面覆盖和连贯地整合多方面信息。在包括 LFQA 和 ODSUM 在内的多个数据集以及新引入的数据集 ODSUM-WikiHow 上进行的大量实验表明，ConTReGen 的表现优于现有的最先进的 RAG 模型。]]></description>
      <guid>https://arxiv.org/abs/2410.15511</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>历史地图上多词地名的自动检索</title>
      <link>https://arxiv.org/abs/2410.15586</link>
      <description><![CDATA[arXiv:2410.15586v2 公告类型：新
摘要：历史地图是有关过去的宝贵信息来源，在线图书馆中扫描的历史地图越来越多。为了从这些包含特定名胜古迹的大型图书馆中检索地图，先前的工作已应用计算机视觉技术来识别历史地图上的单词，从而能够搜索包含特定地名的地图。然而，由于历史地图上文本标签的布局复杂，搜索多词地名具有挑战性。本文提出了一种在历史地图上搜索给定多词地名的有效查询方法。使用现有的方法识别历史地图上的单词，我们通过构建最小生成树将单词文本标签链接到潜在的多词短语中。这些树旨在链接空间上接近且具有相似高度、角度和大写字母的文本标签对。然后，我们在这些树中查询给定的多词地名。我们通过两个实验评估了所提出的方法：1）评估最小生成树方法在链接多词地名方面的准确性；2）评估查询方法检索到的地图数量和时间范围。生成的地图揭示了使用多词名称的地点在历史上的大量地图上是如何变化的。]]></description>
      <guid>https://arxiv.org/abs/2410.15586</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>中心性感知的产品检索和排名</title>
      <link>https://arxiv.org/abs/2410.15930</link>
      <description><![CDATA[arXiv:2410.15930v1 公告类型：新
摘要：本文通过提高与用户搜索查询相关的产品排名来解决改善电子商务平台用户体验的挑战。用户查询的模糊性和复杂性通常会导致用户的意图与检索到的产品标题或文档不匹配。最近的方法提出了使用基于 Transformer 的模型，该模型在预训练阶段需要数百万个带注释的查询标题对，而这些数据通常不考虑用户意图。为了解决这个问题，我们从 eBay 现有的数据集中整理样本，手动注释以买家为中心的相关性分数和中心性分数，这反映了产品标题与用户意图的匹配程度。我们为现有模型引入了一种用户意图中心性优化 (UCO) 方法，该方法针对语义产品搜索中的用户意图进行了优化。为此，我们提出了一种基于双损失的优化来处理硬否定，即语义相关但不反映用户意图的产品标题。我们的贡献包括策划具有挑战性的评估集并实施 UCO，从而显著提高了不同评估指标下的产品排名效率。我们的工作旨在确保查询中最以买家为中心的标题排名更高，从而提升电子商务平台上的用户体验。]]></description>
      <guid>https://arxiv.org/abs/2410.15930</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>音乐影响网络中的惊人模式</title>
      <link>https://arxiv.org/abs/2410.15996</link>
      <description><![CDATA[arXiv:2410.15996v1 公告类型：新
摘要：分析音乐影响力网络（例如由艺术家影响或采样形成的网络）为了解当代西方音乐提供了宝贵的见解。在这里，中心性排名等计算方法有助于识别有影响力的艺术家。然而，很少有人关注影响力如何随时间变化。在本文中，我们应用贝叶斯意外来追踪音乐影响力网络的演变。使用两个网络——一个是艺术家影响力网络，另一个是翻唱、混音和样本网络——我们的结果揭示了网络结构发生重大变化的时期。此外，我们证明了贝叶斯意外是一个灵活的框架，可以使用真实世界数据测试有关网络演化的各种假设。]]></description>
      <guid>https://arxiv.org/abs/2410.15996</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>释放多通道融合在个性化推荐检索中的潜力</title>
      <link>https://arxiv.org/abs/2410.16080</link>
      <description><![CDATA[arXiv:2410.16080v1 公告类型：新
摘要：推荐系统 (RS) 在管理现代数字服务中的信息过载方面至关重要。RS 中的一个关键挑战是高效处理大量项目池，以在严格的延迟约束下提供高度个性化的推荐。多阶段级联排名通过采用计算效率高的检索方法来覆盖不同的用户兴趣，然后使用更精确的排名模型来优化结果，从而解决了这一问题。在检索阶段，多通道检索通常用于从不同的候选生成器生成不同的项目子集，利用这些方法的互补优势来最大化覆盖范围。然而，转发所有检索到的项目会使下游排名者不堪重负，因此需要截断。尽管单个检索方法取得了进步，但多通道融合（有效合并多通道检索结果的过程）仍未得到充分探索。我们是第一个在检索阶段识别并系统地研究多通道融合的人。当前的行业实践通常依赖于启发式方法和手动设计，这通常会导致性能不佳。此外，由于选择过程的不可微性，传统的基于梯度的方法（如 SGD）不适合这项任务。在本文中，我们通过为每个通道分配系统优化的权重来探索高级通道融合策略。我们利用黑盒优化技术，包括用于全局权重优化的交叉熵方法和贝叶斯优化，以及用于个性化合并的基于策略梯度的方法。我们的方法增强了个性化和灵活性，在多个数据集上实现了显着的性能改进，并在实际部署中产生了可观的收益，为优化检索中的多通道融合提供了可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.16080</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PODTILE：通过自动生成的章节方便浏览播客剧集</title>
      <link>https://arxiv.org/abs/2410.16148</link>
      <description><![CDATA[arXiv:2410.16148v1 公告类型：新
摘要：长篇谈话音频内容（例如播客剧集）的听众通常发现很难理解整体结构并找到相关部分。一个实用的解决方案是将剧集分成章节——用标题和时间戳标记的语义连贯的片段。由于 Spotify 平台上的大多数剧集目前都缺少创作者提供的章节，因此自动创建章节至关重要。扩展播客剧集的章节化带来了独特的挑战。首先，剧集的结构往往不如书面文本，以自发的讨论和细微的过渡为特色。其次，成绩单通常很长，平均约有 16,000 个标记，这需要能够保留上下文的高效处理。为了应对这些挑战，我们引入了 PODTILE，这是一种经过微调的编码器-解码器转换器，用于分割对话数据。该模型同时为输入成绩单生成章节过渡和标题。为了保留上下文，每个输入文本都添加了全局上下文，包括剧集的标题、描述和之前的章节标题。在我们的内在评估中，PODTILE 的 ROUGE 得分比最强的基线提高了 11%。此外，我们还深入了解了自动生成的章节对浏览剧集内容的听众的实际好处。我们的研究结果表明，自动生成的章节是与不太受欢迎的播客互动的有用工具。最后，我们提供了经验证据，表明使用章节标题可以提高搜索任务中稀疏检索的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.16148</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于属性的语义类型检测和数据质量评估</title>
      <link>https://arxiv.org/abs/2410.14692</link>
      <description><![CDATA[arXiv:2410.14692v1 公告类型：交叉 
摘要：各行业对数据驱动决策的依赖凸显了对高质量数据的迫切需求；尽管取得了进展，但数据质量问题仍然存在，严重影响了商业战略和科学研究。当前的数据质量方法无法利用跨不同数据集和域的属性标签内单词（或表格中的列名/标题）中嵌入的语义丰富性，从而在全面的数据质量评估中留下了一个关键的空白。这项研究通过引入一种以基于属性的语义类型检测和数据质量评估为中心的创新方法来解决这一空白。通过利用属性标签中的语义信息，结合基于规则的分析和全面的格式和缩写词典，我们的方法引入了一个实用的语义类型分类系统，包含大约 23 种类型，包括数值非负、分类、ID、名称、字符串、地理、时间和复杂格式，如 URL、IP 地址、电子邮件和二进制值以及几个数值有界类型，如年龄和百分比。与最先进的语义类型检测系统 Sherlock 的比较分析表明，我们的方法在分类稳健性和适用于数据质量评估任务方面具有优势。我们的研究重点是众所周知的数据质量问题及其相应的数据质量维度违规，将我们的方法建立在强大的学术框架之上。对 UCI 机器学习存储库中 50 个不同数据集的详细分析展示了我们的方法在识别潜在数据质量问题方面的熟练程度。与 YData Profiling 等成熟工具相比，我们的方法表现出更高的准确性，在 922 个属性中检测到 81 个缺失值，而 YData 仅识别出一个。]]></description>
      <guid>https://arxiv.org/abs/2410.14692</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S2 分层离散全局网格作为跨地理空间知识图谱的数据表示、集成和查询的纽带</title>
      <link>https://arxiv.org/abs/2410.14808</link>
      <description><![CDATA[arXiv:2410.14808v1 公告类型：交叉 
摘要：地理空间知识图谱 (GeoKG) 已成为不断发展的地理空间人工智能领域不可或缺的一部分。美国国家科学基金会的开放知识网络计划等计划旨在创建一个国家级、跨学科的 GeoKG 生态系统，提供符合 FAIR 原则的 AI 就绪地理空间数据。然而，构建这种基础设施面临着关键挑战，包括 1) 管理大量数据，2) 通过 SPARQL 发现拓扑关系的计算复杂性，以及 3) 混合多尺度栅格和矢量数据。离散全球网格系统 (DGGS) 通过提供高效的数据集成和表示策略来帮助解决这些问题。KnowWhereGraph 利用 Google 的 S2 Geometry（一个 DGGS 框架）实现高效的多源数据处理、定性空间查询和跨图集成。本文概述了 S2 在 KnowWhereGraph 中的实现，强调了其在拓扑丰富和语义压缩数据方面的作用。最终，这项工作展示了 DGGS 框架（尤其是 S2）在构建可扩展 GeoKG 方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.14808</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>