<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 14 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>GPT-4V(ision) 是一个多面手网络代理，如果接地的话</title>
      <link>https://arxiv.org/abs/2401.01614</link>
      <description><![CDATA[arXiv:2401.01614v2 公告类型：替换
摘要：大型多模态模型（LMM）的最新发展，特别是 GPT-4V(ision) 和 Gemini，迅速扩展了多模态模型的能力边界，超越了图像字幕和视觉问答等传统任务。在这项工作中，我们探索了像 GPT-4V 这样的 LMM 作为通用网络代理的潜力，它可以遵循自然语言指令来完成任何给定网站上的任务。我们提出了 SEEACT，这是一种通用网络代理，它利用 LMM 的力量来实现集成的视觉理解和在网络上的操作。我们对最近的 MIND2WEB 基准进行评估。除了对缓存网站进行标准离线评估之外，我们还通过开发允许在实时网站上运行 Web 代理的工具来启用新的在线评估设置。我们表明，GPT-4V 为网络代理提供了巨大的潜力——如果我们手动将其文本计划转化为网站上的操作，它可以成功完成实时网站上 51.1 的任务。这大大优于 GPT-4 等纯文本法学硕士或专门针对网络代理进行微调的较小模型（FLAN-T5 和 BLIP-2）。然而，接地仍然是一个重大挑战。现有的 LMM 基础策略（如标记集提示）对于 Web 代理来说并不有效，而我们在本文中开发的最佳基础策略同时利用了 HTML 结构和视觉效果。但与预言机落地仍有很大差距，还有很大的改进空间。所有代码、数据和评估工具均可在 https://github.com/OSU-NLP-Group/SeeAct 上获取。]]></description>
      <guid>https://arxiv.org/abs/2401.01614</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>MetaSplit：用于有限库存产品推荐的 Meta-Split 网络</title>
      <link>https://arxiv.org/abs/2403.06747</link>
      <description><![CDATA[arXiv:2403.06747v3 公告类型：替换
摘要： 与企业对消费者（B2C）电子商务系统相比，消费者对消费者（C2C）电子商务平台通常会遇到库存有限的问题，即一种产品在一段时间内只能销售一次。 C2C系统。这给点击率 (CTR) 预测带来了一些独特的挑战。由于每个产品（即项目）的用户交互有限，CTR 模型中相应的项目嵌入可能不容易收敛。这使得传统的基于序列建模的方法无法有效地利用用户历史信息，因为历史用户行为包含具有不同库存量的商品的混合。特别是，序列模型中的注意力机制倾向于为具有更多累积用户交互的产品分配更高的分数，从而使得有限库存的产品被忽略并且对最终输出的贡献较小。为此，我们提出元拆分网络（MSNet），根据每个产品的库存量来拆分用户历史序列，并对不同序列采用差异化的建模方法。对于库存有限的产品，采用元学习方法来解决不收敛问题，这是通过设计元缩放和具有 ID 和辅助信息的移动网络来实现的。此外，一旦产品被消费，传统方法就很难更新项目嵌入。因此，我们提出了一种辅助损失，即使产品不再分发，参数也可以更新。据我们所知，这是第一个解决库存有限产品推荐的解决方案。生产数据集和在线 A/B 测试的实验结果证明了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.06747</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 xFakeSci 学习算法检测 ChatGPT 假科学</title>
      <link>https://arxiv.org/abs/2308.11767</link>
      <description><![CDATA[arXiv:2308.11767v3 公告类型：replace-cross
摘要：ChatGPT 和生成式人工智能工具正在成为新的现实。这项工作的动机是“ChatGPT 内容可能表现出与科学文章不同的独特行为”。在本研究中，我们展示了如何分两个阶段测试这个前提并证明其有效性。随后，我们介绍了 xFakeSci，一种新颖的学习算法，它能够区分 ChatGPT 生成的文章和科学家发表的出版物。该算法使用多种类型数据源驱动的网络模型进行训练，例如通过即时工程实现的 ChatGPT 生成文档和 PubMed 文章。为了缓解过度拟合问题，我们采用了基于数据驱动启发法（包括比率）的校准步骤。我们在涵盖出版周期和疾病（癌症、抑郁症和阿尔茨海默病）的多个数据集上评估该算法。此外，我们还展示了如何将该算法与最先进的 (SOTA) 算法进行基准测试。 xFakeSci 算法的 F1 分数在 80% - 94% 之间，而 SOTA 算法的 F1 分数在 38% - 52% 之间。我们将显着的差异归因于校准和邻近距离启发式的引入，我们强调了这种有希望的性能。事实上，ChatGPT 产生的假科学预测提出了相当大的挑战。尽管如此，xFakeSci 算法的引入是打击假科学的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2308.11767</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>NLQxform-UI：交互式查询 DBLP 的自然语言界面</title>
      <link>https://arxiv.org/abs/2403.08475</link>
      <description><![CDATA[arXiv:2403.08475v1 公告类型：新
摘要：近年来，DBLP 计算机科学参考书目主要用于检索学术信息，例如出版物、学者和场馆。然而，其当前的搜索服务缺乏处理复杂查询的能力，这限制了 DBLP 的可用性。在本文中，我们提出了 NLQxform-UI，一个基于 Web 的自然语言界面，使用户能够直接使用复杂的自然语言问题查询 DBLP。 NLQxform-UI 自动将给定问题转换为 SPARQL 查询，并通过 DBLP 知识图执行查询以检索答案。查询过程以交互的方式呈现给用户，提高了系统的透明度，有助于检查返回的答案。此外，还可以预览和手动更改查询过程中的中间结果，以提高系统的准确性。 NLQxform-UI已完全开源：https://github.com/ruijie-wang-uzh/NLQxform-UI。]]></description>
      <guid>https://arxiv.org/abs/2403.08475</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>ILCiteR：基于证据的可解释的本地引文建议</title>
      <link>https://arxiv.org/abs/2403.08737</link>
      <description><![CDATA[arXiv:2403.08737v1 公告类型：新
摘要：现有的本地引文推荐机器学习方法直接将查询（通常是声明或实体提及）映射或翻译为值得引用的研究论文。在这样的表述中，很难确定为什么应该针对特定查询引用特定的研究论文，从而导致推荐的可解释性有限。为了缓解这一问题，我们引入了基于证据的本地引文推荐任务，其中目标潜在空间包括用于推荐特定论文的证据跨度。我们提出的系统 ILCiteR 使用远程监督的证据检索和多步骤重新排序框架，根据从现有研究文献中提取的类似证据跨度推荐要引用的论文。与过去仅输出推荐的公式不同，ILCiteR 检索证据范围的排名列表和推荐的论文对。其次，先前提出的用于引文推荐的神经模型需要对大量标记数据进行昂贵的训练，最好是在候选论文池的每次重大更新之后。相比之下，ILCiteR 仅依赖于动态证据数据库和预训练的基于 Transformer 的语言模型的远程监督，无需任何模型训练。我们为基于证据的本地引文推荐任务提供了一个新颖的数据集，并证明了我们提出的条件神经排名集成方法对证据跨度重新排名的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.08737</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士的知识冲突：调查</title>
      <link>https://arxiv.org/abs/2403.08319</link>
      <description><![CDATA[arXiv:2403.08319v1 公告类型：交叉
摘要：这项调查对大型语言模型（LLM）的知识冲突进行了深入分析，强调了它们在混合上下文和参数知识时遇到的复杂挑战。我们的重点是三类知识冲突：上下文记忆冲突、上下文间冲突和内存内冲突。这些冲突可能会严重影响法学硕士的可信度和表现，尤其是在噪音和错误信息普遍存在的现实应用中。通过对这些冲突进行分类、探索原因、检查法学硕士在此类冲突下的行为以及审查可用的解决方案，本调查旨在阐明提高法学硕士稳健性的策略，从而为推进这一不断发展的研究提供宝贵的资源。区域。]]></description>
      <guid>https://arxiv.org/abs/2403.08319</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>用于深度点击率预测的离散语义标记化</title>
      <link>https://arxiv.org/abs/2403.08206</link>
      <description><![CDATA[arXiv:2403.08206v1 公告类型：新
摘要：将项目内容信息纳入点击率（CTR）预测模型仍然是一个挑战，特别是在工业场景的时间和空间限制下。内容编码范例将用户和项目编码器直接集成到点击率模型中，随着时间的推移优先考虑空间。相比之下，基于嵌入的范式将项目和用户语义转换为潜在嵌入，然后缓存它们，随着时间的推移优先考虑空间。在本文中，我们引入了一种新的语义标记范式，并提出了一种离散语义标记化方法，即 UIST，用于用户和项目表示。 UIST 有助于快速训练和推理，同时保持保守的内存占用。具体来说，UIST 将密集嵌入向量量化为长度较短的离散标记，并采用分层混合推理模块来权衡每个用户-项目标记对的贡献。我们在新闻推荐上的实验结果展示了 UIST 对于 CTR 预测的有效性和效率（大约 200 倍空间压缩）。]]></description>
      <guid>https://arxiv.org/abs/2403.08206</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>面向符号感知推荐中的积极和消极偏好的统一建模</title>
      <link>https://arxiv.org/abs/2403.08246</link>
      <description><![CDATA[arXiv:2403.08246v1 公告类型：新
摘要：最近，符号感知图推荐引起了广泛关注，因为它可以从与项目的积极和消极交互（即图中的链接）中学习用户除了积极偏好之外的消极偏好。为了适应负面和正面链接的不同语义，现有的工作利用两个独立的编码器分别对用户的正面和负面偏好进行建模。然而，这些方法无法从具有不同符号的多个链接形成的用户和项目之间的高阶异构交互中学习负面偏好，从而导致负面用户偏好不准确和不完整。为了解决这些棘手的问题，我们提出了一种专门针对 \textbf{Rec}ommendation (\textbf{LSGRec}) 的新颖的 \textbf{L}ight \textbf{S}igned \textbf{G}raph 卷积网络，它采用了统一建模方法，在签名的用户-项目交互图上同时对高阶用户的积极和消极偏好进行建模。具体来说，对于高阶异质交互中的负偏好，一阶负偏好由负链接捕获，而高阶负偏好沿着正边缘传播。然后，根据积极偏好生成推荐结果，并根据消极偏好进行优化。最后，我们通过不同的辅助任务来训练用户和项目的表示。对三个现实世界数据集的广泛实验表明，我们的方法在性能和计算效率方面优于现有基线。我们的代码可在 \url{https://anonymous.4open.science/r/LSGRec-BB95} 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.08246</guid>
      <pubDate>Thu, 14 Mar 2024 06:16:43 GMT</pubDate>
    </item>
    </channel>
</rss>