<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>叙事步道：一种通过最大容量路径优化进行连贯的故事情节提取的方法</title>
      <link>https://arxiv.org/abs/2503.15681</link>
      <description><![CDATA[ARXIV：2503.15681V1公告类型：新 
摘要：传统信息检索主要涉及从大数据集中找到相关信息，而无需在检索到的数据片段中施加结构。但是，以叙述形式构造信息 - 构成连贯故事情节的文档的订购集 - 使我们能够识别，解释和分享有关数据中介绍的思想之间的联系和关系的见解。尽管具有重要意义，但目前从数据中提取故事情节的方法很少，现有方法主要依赖于复杂的基于单词的启发式方法和辅助文档结构。此外，这些方法中的许多方法都难以扩展到大型数据集和一般环境，因为它们旨在为狭窄的任务提取故事情节。在本文中，我们提出了叙事步道，这是一种在大型文本语料库中提取连贯故事情节的高效，通用方法。具体而言，我们的方法使用嵌入深度学习模型潜在空间中的语义级信息来构建稀疏的连贯图并提取叙述，从而最大程度地提高故事情节的最低连贯性。通过定量评估我们在两个不同的叙事提取任务上提出的方法，我们在多种情况下显示了叙事跟踪的概括性和可扩展性，同时也简化了提取管道。]]></description>
      <guid>https://arxiv.org/abs/2503.15681</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协作过滤器的扩散图形对比度学习</title>
      <link>https://arxiv.org/abs/2503.16290</link>
      <description><![CDATA[ARXIV：2503.16290V1公告类型：新 
摘要：基于图形的协作过滤已成为推荐系统中的一种突出方法，利用用户项目交互的固有图形拓扑来模拟高阶连接模式并增强建议性能。图形对比度学习（GCL）的最新进展表明，通过通过对比度观点产生和相互信息最大化来改善表示形式学习，可以通过改善表示稀疏问题的潜力来减轻数据稀疏问题。但是，现有方法缺乏有效的数据增强策略。结构增强风险会扭曲基本图形拓扑，而特征级的扰动技术主要采用均匀的噪声量表，无法说明节点特定的特征。为了解决这些挑战，我们提出了扩散式对比度学习（DGCL），这是一个创新的框架，将扩散模型与对比度学习相结合，以增强协作过滤。我们的方法采用了一个扩散过程，该过程学习了表示节点特异性高斯的表述分布，从而通过反向扩散采样来产生语义一致但多样化的对比视图。 DGCL考虑语义连贯性和节点特异性特征，促进基于重建表示的自适应数据增强。此外，它还探索了潜在稀疏特征空间的未代表区域，从而丰富了对比度观点的多样性。广泛的实验结果证明了DGCL对三个公共数据集的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.16290</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过贝叶斯比较判断，使教育评估中的排名在教育评估中排名</title>
      <link>https://arxiv.org/abs/2503.15549</link>
      <description><![CDATA[ARXIV：2503.15549V1公告类型：交叉 
摘要：随着对更公平，更可靠的评估方法的需求增长，确保教育评估的透明度越来越重要，尤其是大流行。比较判断（CJ）为传统评估提供了一种有希望的替代方法，但仍然对其不透明的不透明性感到担忧。本文探讨了贝叶斯比较判断（BCJ）如何通过将先验信息整合到判断过程中，从而提高透明度，从而提供一种结构化的数据驱动方法，从而提高了可解释性和问责制。
  BCJ将概率分配给判断结果，为决策信心提供了可量化的不确定性衡量标准和更深入的见解。通过系统地跟踪先前的数据和连续判断如何为最终排名提供信息，BCJ阐明了评估过程并有助于确定评估者分歧。多标准BCJ通过独立评估多个学习成果（LOS）来扩展这一点，从而保留CJ的丰富性，同时产生透明的，颗粒状的排名与特定的评估目标一致。它还可以从单个LOS中得出一个整体排名，从而确保全面评估而不会损害详细的反馈。
  我们使用在英国具有专业标记的真正高等教育数据集，我们证明了BCJ的定量严格性和澄清排名理由的能力。通过定性分析和与经验丰富的CJ从业人员的讨论，我们在透明度至关重要的环境中探索了其有效性，例如高风险国家评估。我们强调了BCJ的好处和局限性，在各种教育环境中为其现实世界应用提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2503.15549</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于编程语言概念的LLM辅助代码数据可自定义分析</title>
      <link>https://arxiv.org/abs/2503.15571</link>
      <description><![CDATA[ARXIV：2503.15571V1公告类型：交叉 
摘要：数据分析对于生成描述性统计的机器学习至关重要，支持更深入的理解和下游任务（例如数据评估和策划）。这项工作专门针对大型语言模型（Code-llms）的代码数据集进行分析，其中数据质量直接影响了诸如代码生成和摘要之类的任务。用编程语言概念来表征代码数据集可以使更好的见解和有针对性的数据策划。我们提出的方法将代码数据分析分为两个阶段：（1）一个离线阶段，其中LLM的利用来得出和学习在各种编程语言上提取句法和语义概念的规则，包括以前看不见的或低资源的语言，包括（2）在线确定性阶段，用于应用这些得出的这些衍生的规则，以实现这些有效的实时实时时间分析。这种混合方法是可自定义的，可扩展到新的句法和语义结构，并且可扩展到多种语言。在实验上，我们的LLM辅助方法的句法提取规则和语义分类精度的平均准确性分别为90.33％，分别在语言和语义概念中平均为80％和77％。]]></description>
      <guid>https://arxiv.org/abs/2503.15571</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打字摊位：非事实问题的类型多相关分解回答</title>
      <link>https://arxiv.org/abs/2503.15879</link>
      <description><![CDATA[ARXIV：2503.15879V1公告类型：交叉 
摘要：由于其开放性的性质，不同的意图以及对多相关推理的需求，非事实的问题避开（NFQA）构成了重大挑战，这使传统的factoid QA方法（包括检索成绩（RAG））不足。与Factoid问题不同，非事实问题（NFQ）缺乏确切的答案，需要从各种推理维度的多个来源的综合信息。为了解决这些局限性，我们引入了键入rag，这是NFQA的RAG范式内的一种类型感知的多相关分解框架。键入rag将NFQ分类为不同类型的类型，例如辩论，经验和比较 - 并将基于方面的分解应用于完善检索和发电策略。通过将多种敏感的NFQ分解为单一的子征值并汇总结果，键入rag会产生更有信息和上下文相关的响应。为了评估键入rag，我们介绍了Wiki-NFQA，这是一种涵盖不同NFQ类型的基准数据集。实验结果表明，键入rag的表现优于基准，从而突出了类型感知分解对于在NFQA中有效检索和产生的重要性。我们的代码和数据集可在\ href {https://github.com/teamnlp/typed-rag} {https://github.com/teamnlp/typed-rag}中获得。]]></description>
      <guid>https://arxiv.org/abs/2503.15879</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ProPTHASH：自适应哈希检索的亲和力促进的协作跨模式学习</title>
      <link>https://arxiv.org/abs/2503.16064</link>
      <description><![CDATA[ARXIV：2503.16064V1公告类型：交叉 
摘要：跨模式哈希是一种有效的数据检索和存储优化的有前途的方法。但是，当代方法在语义保存，上下文完整性和信息冗余方面表现出重大局限性，这会限制检索功效。我们提出了Prompthash，这是一个创新的框架，利用亲和力及时感知的协作学习进行适应性跨模式哈希。 We propose an end-to-end framework for affinity-prompted collaborative hashing, with the following fundamental technical contributions: (i) a text affinity prompt learning mechanism that preserves contextual information while maintaining parameter efficiency, (ii) an adaptive gated selection fusion architecture that synthesizes State Space Model with Transformer network for precise cross-modal feature integration, and (iii) a prompt affinity alignment strategy that bridges modal通过分层对比学习的异质性。据我们所知，这项研究介绍了对协作跨模式自适应哈希学习中亲和力意识的首次调查，建立了一个范式，以增强跨模态语义一致性。通过对三个基准多标签数据集的全面评估，ProppThash证明了对现有方法的大量绩效改进。值得注意的是，在整个NUS范围的数据集上，我们的方法分别在图像到文本和文本到图像检索任务中获得了18.22％和18.65％的显着增长。该代码可在https://github.com/shishumo/prompthash上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2503.16064</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过抹布原理调整LLM：朝向LLM本地记忆</title>
      <link>https://arxiv.org/abs/2503.16071</link>
      <description><![CDATA[ARXIV：2503.16071V1公告类型：交叉 
摘要：内存，大型语言模型（LLM）培训以外的其他信息，对于各种现实世界应用程序，例如私人助理至关重要。将内存纳入生成过程的两个主流解决方案是长篇文化LLM和检索增强的生成（RAG）。在本文中，我们首先会系统地比较三个翻新/新数据集中的这两种解决方案，并表明（1）长篇小说解决方案虽然更昂贵，但更容易捕获大图和更好的答案查询，这些查询需要考虑整体内存； （2）当查询涉及特定信息时，RAG解决方案应更具竞争力，尤其是当关键字可以明确匹配时。因此，我们提出了一种新型的方法抹布式的llm，该方法使用按照抹布原理生成的数据微调相对小（例如7b）llm，因此它可以结合两种溶液的优势。在三个数据集上进行的广泛实验表明，抹布式的-llm可以在广泛的查询类型中击败长篇小说LLM和抹布方法。]]></description>
      <guid>https://arxiv.org/abs/2503.16071</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Othink-MR1：通过动态增强学习刺激多模式广义推理能力</title>
      <link>https://arxiv.org/abs/2503.16081</link>
      <description><![CDATA[Arxiv：2503.16081V1公告类型：交叉 
摘要：多模式模型已经获得了处理多种输入数据类型并在各种应用程序上产生连贯的，上下文相关的输出的能力。虽然受监督的微调（SFT）一直是提高特定于任务优化的MLLM功能的主要方法，但它通常在培养重要的广义推理能力方面差不多。尽管强化学习的潜力（RL）可以解决这些局限性，但它面临两个问题：（1）其在多模式任务中的广义能力仍未得到充实。 （2）其训练约束，例如恒定的kullback-leibler或夹具策略，很容易导致次优瓶颈。为了解决这些问题，我们介绍了将RL扩展到MLLM的框架Othink-Mr1，从而使它们能够在多模式任务中实现更深入的理解和推理。我们设计了一种动态的kullback-leibler策略，可显着提高RL性能，超过同一任务评估中的SFT。同样，我们是第一个揭示RL表现出显着的交叉任务概括功能的人，该功能表明，在一个多模式任务上对RL进行训练后的模型可以有效地转移到另一个任务上。最后，广泛的实验证明了我们提出的Othink-Mr1的出色推理能力。]]></description>
      <guid>https://arxiv.org/abs/2503.16081</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迭代的最佳关注和单图降雨删除的本地模型</title>
      <link>https://arxiv.org/abs/2503.16165</link>
      <description><![CDATA[ARXIV：2503.16165V1公告类型：交叉 
摘要：高保真成像对于成功的安全监督和基于视觉的测量系统（VBM）的智能部署至关重要。它确保VBM中的高质量成像，这对于可靠的视觉测量和分析是基本的。但是，不利的天气条件，尤其是雨水，导致图像模糊并减少对比度会严重损害成像质量。这种障碍增加了VBM中评估和误解的不准确的风险。为了解决这些局限性，我们提出了一个期望最大化重建变压器（EMRESFORMER），以清除单图雨条。发射形式保留特征聚集的关键自我注意值值，从而增强局部特征以产生出色的图像重建。具体而言，我们提出了一个期望最大化块，无缝集成到单像降雨删除网络中，增强了其消除多余信息并恢复更清洁的背景图像的能力。此外，为了进一步增强本地信息以改善细节的再现，我们引入了局部模型残差块，该模型将两个局部模型块以及一系列卷积和激活功能序列集成在一起。这种集成协同促进了提取更相关的特征，以增强单图雨条的去除。广泛的实验验证了我们提出的发射器超过合成和现实世界数据集上的最新图像降雨删除方法，从而在模型复杂性和单图衍生性能之间取得了改善的平衡。此外，我们评估了方法在VBMS方案中的有效性，这表明高质量成像显着提高了VBMS任务的准确性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2503.16165</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>蛋糕：巡回赛的编辑可以使知识学习者启用</title>
      <link>https://arxiv.org/abs/2503.16356</link>
      <description><![CDATA[ARXIV：2503.16356V1公告类型：交叉 
摘要：知识编辑（KE）可以在大语言模型（LLMS）中修改过时或不正确的信息。尽管现有的KE方法可以更新孤立的事实，但他们努力将这些更新推广到依赖于修改知识的多跳推理任务。通过对推理电路的分析 -  LLM用于基于知识的推理的神经途径，我们观察到，当前层置换的KE方法（例如Memit和Wise）仅编辑单个或几个模型层，难以有效地将更新的信息纳入这些推理途径。为了解决这一限制，我们提出了蛋糕（电路感知知识编辑），这是一种新颖的方法，可以在LLM中更有效地整合更新的知识。 Cake在我们基于电路的分析的指导下利用了战略性策略的数据，该数据强制实施该模型以利用修改后的知识，从而刺激模型以开发适当的推理电路以供新综合知识。实验结果表明，Cake可以在相关推理任务中更准确和一致地使用更新知识，从而导致MQUAKE数据集的多跳上推理精度平均提高了20％，与现有的KE方法相比。我们在https://github.com/zjunlp/cake中发布代码和数据。]]></description>
      <guid>https://arxiv.org/abs/2503.16356</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定的研究国家排名。我们应该继续产生不确定的排名吗？</title>
      <link>https://arxiv.org/abs/2312.17560</link>
      <description><![CDATA[ARXIV：2312.17560V3公告类型：替换 - 交叉 
摘要：目的：基于引用的国家研究能力的评估常常歪曲其实现突破性进步的能力。这些评估通常将日本归类为发展中国家，这与其著名的科学地位相矛盾。这项研究的目的是研究这种不准确评估的根本原因，并提出进行更可靠评估的方法。设计/方法/方法：研究评估了高级引文指标作为突破性研究指标的有效性。利用选定国家和研究主题的案例研究，研究研究了与对数正态引用分布的偏差如何影响这些百分位指标的准确性。使用莱顿排名的大学数据进行了类似的分析，以调查机构层面的引文分布偏差。研究结果：该研究发现，引用分布中的较低尾巴会导致高级技术国家的研究能力低估，如某些百分位指标所捕获的那样。相反，研究密集型大学表现出相反的趋势：相对于上尾巴的下尾部降低，这导致百分位指标高估了其实际的研究能力。研究局限性：描述是数学事实，它们是不言而喻的。实际含义：由于国家和机构之间的引文模式的变化，PTOP 10％/p和ptop 1％/p的比率并不是突破性研究的普遍预测指标。评估应摆脱这些指标。依靠基于引用的不当措施可能导致研究政策的决策不良，从而破坏了研究策略及其结果的有效性。]]></description>
      <guid>https://arxiv.org/abs/2312.17560</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当文本嵌入符合大型语言模型时：一项综合调查</title>
      <link>https://arxiv.org/abs/2412.09165</link>
      <description><![CDATA[ARXIV：2412.09165V3公告类型：替换 - 交叉 
摘要：在深度学习时代，文本嵌入已成为自然语言处理（NLP）中的基础技术，推动了各种下游任务的进步。尽管现在可以使用生成范式来对许多自然的语言理解挑战进行建模，并利用大型语言模型（LLMS）的强大生成和理解能力（例如语义匹配，聚类和信息检索）继续依靠文本嵌入者来提高其效率和有效性。因此，近年来将LLM与文本嵌入的集成已成为主要的研究重点。在这项调查中，我们将LLM和文本嵌入之间的相互作用分为三个总体主题：（1）LLM-augment的文本嵌入，增强了使用LLMS的传统嵌入方法； （2）llms作为文本嵌入式，适应其先天能力以嵌入高质量的嵌入； （3）使用LLMS嵌入理解的文本，利用LLMS分析和解释嵌入。通过基于相互作用模式而不是特定的下游应用程序来组织最新的作品，我们为LLM时代的各种研究和应用领域的贡献提供了新颖而系统的概述。此外，我们强调了通过预训练的语言模型（PLM）持续存在的尚未解决的挑战，并探索了LLMS带来的新兴障碍。在此分析的基础上，我们概述了嵌入文本演变的前瞻性方向，在NLP快速前进的景观中既解决理论和实践机遇。]]></description>
      <guid>https://arxiv.org/abs/2412.09165</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>搜索R1：培训LLMS以推理和利用搜索引擎，并通过增强学习</title>
      <link>https://arxiv.org/abs/2503.09516</link>
      <description><![CDATA[ARXIV：2503.09516V2公告类型：替换 - 交叉 
摘要：有效获取外部知识和最新信息对于大型语言模型（LLM）中的有效推理和文本生成至关重要。在推理过程中提示具有推理能力的高级LLM使用搜索引擎并不是最佳的，因为LLM无法学习如何与搜索引擎进行最佳互动。本文介绍了search-r1，这是deepSeek-r1模型的扩展，其中LLM仅通过增强学习（RL）学习，以自主生成（多个）搜索查询，并在实时检索中逐步推理。 Search-R1通过多转弯搜索交互优化LLM的推出，利用将令牌掩盖检索进行稳定的RL培训和简单的基于结果的奖励功能。在七个提问数据集上的实验表明，搜索R1在强质基础上提高了26％（QWEN2.5-7B），21％（QWEN2.5-3B）和10％（Llama3.2-3B）。本文进一步提供了对RL优化方法，LLM选择和响应长度动力学的经验见解。代码和模型检查点可在https://github.com/petergriffinjin/search-r1上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.09516</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法官：为中国法律制度的判断文件生成基准测试</title>
      <link>https://arxiv.org/abs/2503.14258</link>
      <description><![CDATA[ARXIV：2503.14258V2公告类型：替换 - 交叉 
摘要：本文介绍了法官（判断文件生成评估），这是一种评估中国法律制度判断文件生成的绩效的新基准。我们将任务定义为从给定的事实描述中生成完整的法律判决文件。为了促进此基准，我们构建了一个全面的数据集，该数据集由实际法律案件的事实描述组成，并与相应的完整判断文件配对，这是评估生成文档质量的基础真相。两个外部法律语料库进一步增强了该数据集，这些文件为任务提供了额外的法律知识：一个包括法规和法规，另一个由大量过去的判决文件组成。与法律专业人员合作，我们建立了一个全面的自动化评估框架，以评估各个方面的判断文件的质量。我们使用通用和法律域LLMS评估了各种基线方法，包括几乎没有射击的内在学习，微调和多源检索型生成一代（RAG）方法。实验结果表明，尽管RAG方法可以有效地改善此任务的性能，但仍有大量进一步改进的空间。所有代码和数据集均提供：https：//github.com/oneal2000/judge。]]></description>
      <guid>https://arxiv.org/abs/2503.14258</guid>
      <pubDate>Fri, 21 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>