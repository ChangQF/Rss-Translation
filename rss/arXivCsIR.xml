<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 14 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型进行相关性评估的大规模研究：初步观察</title>
      <link>https://arxiv.org/abs/2411.08275</link>
      <description><![CDATA[arXiv:2411.08275v1 公告类型：新
摘要：大型语言模型的应用提供了令人兴奋的机会来推进信息检索、自然语言处理和其他领域，但迄今为止仍有许多未知数。本文报告了大规模评估（TREC 2024 RAG Track）的结果，其中现场部署了四种不同的相关性评估方法：NIST 几十年来实施的“标准”完全手动流程和三种不同的替代方案，它们使用开源 UMBRELA 工具在不同程度上利用 LLM。这种设置使我们能够关联由不同方法引起的系统排名，以表征成本和质量之间的权衡。我们发现，就 nDCG@20、nDCG@100 和 Recall@100 而言，UMBRELA 自动生成的相关性评估得出的系统排名与 19 支球队的 77 次不同运行中完全手动评估得出的系统排名高度相关。我们的结果表明，自动生成的 UMBRELA 判断可以取代完全手动判断，以准确捕捉运行级别的有效性。令人惊讶的是，我们发现 LLM 辅助似乎并没有增加与完全手动评估的相关性，这表明与人为干预过程相关的成本并没有带来明显的实际好处。总体而言，人类评估员在应用相关性标准方面似乎比 UMBRELA 更严格。我们的工作验证了 LLM 在学术 TREC 式评估中的使用，并为未来的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.08275</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经矫正机降级</title>
      <link>https://arxiv.org/abs/2411.08562</link>
      <description><![CDATA[arXiv:2411.08562v1 公告类型：新 
摘要：神经信息检索 (IR) 系统中的机器反学习需要在保持模型性能的同时删除特定数据。将现有的机器反学习方法应用于 IR 可能会损害检索效果或无意中暴露反学习行为，因为从呈现给用户的检索结果中删除了特定项目。我们形式化了纠正性反排名，它通过整合替代文档来保持排名完整性，从而扩展了 (神经) IR 环境中的机器反学习，并为此任务提出了一种新颖的师生框架，即纠正性反排名蒸馏 (CuRD)。CuRD (1) 通过调整 (训练过的) 神经 IR 模型来促进遗忘，使其待遗忘样本的输出相关性分数模仿低排名、不可检索样本的相关性分数；(2) 通过微调替代样本的相关性分数以与相应的待遗忘样本的相关性分数紧密匹配来实现纠正； （3）力求在非遗忘目标样本上保持性能。我们使用 MS MARCO 和 TREC CAR 数据集在四个神经 IR 模型（BERTcat、BERTdot、ColBERT、PARADE）上评估 CuRD。使用 1% 和 20% 的训练数据集进行的遗忘集大小实验表明，CuRD 在遗忘和纠正方面的表现优于七个最先进的基线，同时保持了模型保留和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2411.08562</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考基于内容的新闻推荐中的负采样</title>
      <link>https://arxiv.org/abs/2411.08700</link>
      <description><![CDATA[arXiv:2411.08700v1 公告类型：新
摘要：新闻推荐系统受到文章短暂寿命的阻碍，因为它们经历了快速的相关性衰减。最近的研究表明基于内容的神经技术在解决这一问题方面的潜力。然而，这些模型通常涉及复杂的神经结构，并且往往缺乏对反面例子的考虑。在这项研究中，我们假设仔细采样负面例子对模型的结果有很大影响。我们设计了一种负采样技术，它不仅可以提高模型的准确性，还可以促进推荐系统的分散化。使用 MIND 数据集获得的实验结果表明，所考虑方法的准确性可以与最先进的模型相媲美。采样技术的利用对于降低模型复杂性和加速训练过程至关重要，同时保持高水平的准确性。最后，我们讨论了分散模型如何帮助提高隐私和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2411.08700</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过视觉对话增强多模态查询表示以实现端到端知识检索</title>
      <link>https://arxiv.org/abs/2411.08334</link>
      <description><![CDATA[arXiv:2411.08334v1 公告类型：交叉 
摘要：现有的多模态检索系统通常依赖于脱节的图像理解模型，例如对象检测器和标题生成器，导致繁琐的实现和训练过程。为了克服这一限制，我们提出了一个端到端检索系统 Ret-XKnow，使文本检索器能够通过动态模态交互理解多模态查询。Ret-XKnow 利用部分卷积机制来关注与给定文本查询相关的视觉信息，从而增强多模态查询表示。为了有效地学习多模态交互，我们还引入了从视觉对话数据集自动构建的视觉对话到检索 (ViD2R) 数据集。我们的数据集构建过程确保使用文本检索器将对话转换为合适的信息检索任务。我们证明，我们的方法不仅显著提高了零样本设置中的检索性能，而且在微调场景中也取得了显著的改进。我们的代码已公开：https://github.com/yeongjoonJu/Ret_XKnow。]]></description>
      <guid>https://arxiv.org/abs/2411.08334</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学术维基数据：使用法学硕士 (LLM) 在维基数据中填充和探索会议数据</title>
      <link>https://arxiv.org/abs/2411.08696</link>
      <description><![CDATA[arXiv:2411.08696v1 公告类型：交叉 
摘要：已经采取了多项举措，使用本体对学术数据领域进行概念建模并创建相应的知识图谱。然而，由于缺乏用于自动填充所述本体的自动化手段，并且语义网社区的相应举措不一定相互关联，因此似乎没有充分发挥其潜力：我们建议通过利用 Wikidata 的基础设施并通过 LLM 以可持续的方式自动化其填充，利用非结构化来源（如会议网站和会议记录文本）以及已经存在的结构化会议数据集，使学术数据更可持续地可访问。虽然初步分析表明语义网会议在 Wikidata 中的代表性极小，但我们认为我们的方法可以帮助在 Wikidata 内填充、发展和维护学术数据作为社区。我们的主要贡献包括 (a) 分析用于表示学术数据的本体，以确定 Wikidata 中的差距和相关实体/属性，(b) 使用 LLM 从网站和会议记录文本中半自动提取（需要（最低限度的）手动验证）会议元数据（例如，接受率、组织者角色、计划委员会成员、最佳论文奖、主题演讲和赞助商）。最后，我们讨论 (c) 在 Wikidata 环境中扩展可视化工具，以探索生成的学术数据。我们的研究重点关注来自 105 个语义网相关会议的数据，并在 Wikidata 中扩展/添加了 6000 多个实体。值得注意的是，该方法可以更广泛地应用于语义网相关会议之外，以增强 Wikidata 作为综合学术资源的实用性。
源存储库：https://github.com/scholarly-wikidata/
DOI：https://doi.org/10.5281/zenodo.10989709
许可证：Creative Commons CC0（数据）、MIT（代码）]]></description>
      <guid>https://arxiv.org/abs/2411.08696</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 CTR 预测的特征交互融合自蒸馏网络</title>
      <link>https://arxiv.org/abs/2411.07508</link>
      <description><![CDATA[arXiv:2411.07508v2 公告类型：替换 
摘要：点击率（CTR）预估在推荐系统、在线广告和搜索引擎中起着至关重要的作用。当前大多数方法通过堆叠或并行结构对特征交互进行建模，其中一些方法采用知识蒸馏进行模型压缩。然而，我们观察到这些方法的一些局限性：（1）在并行结构模型中，显式和隐式组件是独立且同时执行的，这导致特征集内的信息共享不足。（2）知识蒸馏技术的引入带来了师生框架设计复杂、知识转移效率低下的问题。（3）数据集和构建高阶特征交互的过程包含显著的噪声，限制了模型的有效性。为了解决这些限制，我们提出了 FSDNet，这是一个包含即插即用融合自蒸馏模块的 CTR 预估框架。具体而言，FSDNet 在每一层在显式和隐式特征交互之间建立连接，增强了不同特征之间的信息共享。然后使用最深的融合层作为教师模型，利用自我蒸馏来指导浅层的训练。对四个基准数据集的实证评估验证了该框架的有效性和泛化能力。代码可在 https://anonymous.4open.science/r/FSDNet 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.07508</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释丰富驱动的图谱推理器 (EDGAR)，适用于大型知识图谱及其在药物再利用中的应用</title>
      <link>https://arxiv.org/abs/2409.18659</link>
      <description><![CDATA[arXiv:2409.18659v2 公告类型：replace-cross 
摘要：知识图谱 (KG) 表示现实世界实体之间的联系和关系。我们提出了一种名为 Enrichment-Driven GrAph Reasoner (EDGAR) 的 KG 链接预测框架，该框架通过挖掘实体局部规则来推断新边。这种方法利用了富集分析，这是一种成熟的统计方法，用于识别差异表达基因集共有的机制。EDGAR 的推理结果本质上是可解释和可排序的，p 值表示每个基于富集的规则的统计意义。
我们展示了该框架在大型生物医学 KG ROBOKOP 上的有效性，重点关注阿尔茨海默病 (AD) 的药物再利用作为案例研究。最初，我们从 KG 中提取了 14 种已知药物，并通过富集分析确定了 20 种背景生物标志物，揭示了与 AD 共享药物疗效相关的功能途径。随后，利用前 1000 个富集结果，我们的系统确定了另外 1246 种用于 AD 治疗的候选药物。前 10 个候选药物通过医学文献中的证据进行了验证。
EDGAR 部署在 ROBOKOP 中，并配有 Web 用户界面。这是第一项将富集分析应用于大型图完成和药物再利用的研究。]]></description>
      <guid>https://arxiv.org/abs/2409.18659</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DM4Steal：图神经网络链接窃取攻击的扩散模型</title>
      <link>https://arxiv.org/abs/2411.03364</link>
      <description><![CDATA[arXiv:2411.03364v2 公告类型：replace-cross 
摘要：图已经成为推荐系统发展中不可或缺的一部分，尤其是随着图神经网络（GNN）的快速发展。通过探索丰富的节点特征和链接信息的优点，GNN 旨在提供个性化和准确的建议。同时，在这种背景下，GNN 的隐私泄露也引起了特别的关注。先前的研究表明，恶意用户可以利用辅助知识通过目标 GNN 模型的决策来提取目标图中的敏感链接数据，这些数据是推荐系统不可或缺的。这对推荐系统中使用的数据的完整性和机密性构成了重大风险。尽管很重要，但之前关于 GNN 隐私泄露的研究仍然在三个方面受到挑战，即有限的窃取攻击场景、次优攻击性能和对防御的适应性。为了解决这些问题，我们提出了一种基于扩散模型的链接窃取攻击，称为 DM4Steal。它在三个关键方面与以前的工作不同。 (i) 通用性：针对六种辅助知识有限的攻击场景，我们提出了一种新颖的扩散模型训练策略，使 DM4Steal 可以迁移到不同的攻击场景。(ii) 有效性：得益于扩散模型在训练过程中保留的语义结构，DM4Steal 能够通过 GNN 决策过程学习目标图的精确拓扑。(iii) 适应性：当 GNN 处于防御性（例如 DP、Dropout）时，DM4Steal 依靠多次采样分数模型所带来的稳定性将性能下降降至最低，因此 DM4Steal 对防御性 GNN 实施了成功的自适应攻击。]]></description>
      <guid>https://arxiv.org/abs/2411.03364</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索增强大型语言模型中参数知识细化的查询优化</title>
      <link>https://arxiv.org/abs/2411.07820</link>
      <description><![CDATA[arXiv:2411.07820v2 公告类型：replace-cross 
摘要：我们引入了 Extract-Refine-Retrieve-Read (ERRR) 框架，这是一种新颖的方法，旨在通过定制查询优化来弥补检索增强生成 (RAG) 系统中的预检索信息差距，以满足大型语言模型 (LLM) 的特定知识要求。与 RAG 中使用的传统查询优化技术不同，ERRR 框架首先从 LLM 中提取参数知识，然后使用专门的查询优化器来优化这些查询。此过程可确保仅检索生成准确响应所必需的最相关信息。此外，为了增强灵活性并降低计算成本，我们为我们的管道提出了一种可训练方案，该方案利用较小的可调模型作为查询优化器，并通过从较大的教师模型中进行知识提炼来完善。我们对各种问答 (QA) 数据集和不同检索系统的评估表明，ERRR 的表现始终优于现有基线，证明它是一个多功能且经济高效的模块，可用于提高 RAG 系统的实用性和准确性。]]></description>
      <guid>https://arxiv.org/abs/2411.07820</guid>
      <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>