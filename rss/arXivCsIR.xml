<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Thu, 27 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>具有迭代块杠杆分数采样的梯度编码</title>
      <link>https://arxiv.org/abs/2308.03096</link>
      <description><![CDATA[arXiv:2308.03096v2 公告类型：replace-cross 
摘要：我们概括了 $\ell_2$ 子空间嵌入的杠杆分数抽样草图，以适应转换数据的抽样子集，以便草图方法适用于分布式设置。然后用它来推导一阶方法的近似编码计算方法；称为梯度编码，以在分布式计算网络中出现故障时加速线性回归，\textit{即} 落后者。我们在分布式网络中复制数据，以通过诱导采样分布获得近似保证。这项工作的意义和主要贡献在于，它将随机数值线性代数与近似编码计算统一起来，同时通过均匀采样获得诱导的 $\ell_2$ 子空间嵌入。过渡到均匀采样是在不应用随机投影的情况下完成的，就像在子采样随机 Hadamard 变换的情况下一样。此外，通过将这项技术融入编码计算，我们的方案是一种迭代草图方法，可以近似解决线性回归问题。我们还建议在通过替换采样进行草图时加权，以进一步压缩。]]></description>
      <guid>https://arxiv.org/abs/2308.03096</guid>
      <pubDate>Fri, 28 Jun 2024 03:17:01 GMT</pubDate>
    </item>
    <item>
      <title>面向智能营销系统的自适应启发式神经优化</title>
      <link>https://arxiv.org/abs/2405.10490</link>
      <description><![CDATA[arXiv:2405.10490v3 公告类型：replace-cross 
摘要：计算营销在当今的数字世界中变得越来越重要，面临着大量异构数据、多渠道客户旅程和有限的营销预算等挑战。在本文中，我们提出了一个营销 AI 系统的通用框架，即自适应启发式神经优化 (NOAH) 框架。NOAH 是第一个同时考虑面向企业 (2B) 和面向消费者 (2C) 产品以及自有和付费渠道的营销优化通用框架。我们描述了 NOAH 框架的关键模块，包括预测、优化和自适应启发式，并为竞价和内容优化提供了示例。然后，我们详细介绍了 NOAH 在 LinkedIn 电子邮件营销系统中的成功应用，展示了与传统排名系统的重大优势。此外，我们还分享了广泛有用的细节和见解，特别是：（i）解决具有生命周期价值的延迟反馈问题，（ii）执行具有随机性的大规模线性规划，（iii）通过扩大受众群体来改进检索，（iv）减少定位测试中的信号稀释，以及（v）在统计测试中处理零膨胀的重尾指标。]]></description>
      <guid>https://arxiv.org/abs/2405.10490</guid>
      <pubDate>Fri, 28 Jun 2024 03:17:01 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型排名公平吗？关于法学硕士作为排名者公平性的实证研究</title>
      <link>https://arxiv.org/abs/2404.03192</link>
      <description><![CDATA[arXiv:2404.03192v2 公告类型：替换 
摘要：大型语言模型 (LLM) 在信息检索中的集成引发了对文本排名模型公平性的重新评估。LLM（例如 GPT 模型和 Llama2）已在自然语言理解任务中表现出色，之前的研究（例如 RankGPT）也表明 LLM 在排名任务中比传统排名模型表现出更好的性能。然而，它们的公平性仍未得到充分探索。本文提出了一项使用 TREC 公平排名数据集评估这些 LLM 的实证研究，重点关注性别和地理位置等二元受保护属性的表示，这些属性在搜索结果中历来代表性不足。我们的分析深入研究了这些 LLM 如何处理与这些属性相关的查询和文档，旨在揭示其排名算法中的偏见。我们从用户和内容的角度评估公平性，为评估 LLM 作为公平排名者提供了经验基准。]]></description>
      <guid>https://arxiv.org/abs/2404.03192</guid>
      <pubDate>Fri, 28 Jun 2024 03:17:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的持续协同蒸馏</title>
      <link>https://arxiv.org/abs/2405.19046</link>
      <description><![CDATA[arXiv:2405.19046v4 公告类型：替换 
摘要：知识蒸馏（KD）已成为一种有前途的技术，用于解决与部署大规模推荐系统相关的计算挑战。KD 将庞大的教师系统的知识转移到紧凑的学生模型中，以减少推理的巨大计算负担，同时保持高精度。现有的 KD 研究主要集中于静态环境中的一次性蒸馏，在处理连续传入的用户、项目及其交互的实际场景中，它们在适用性方面存在很大差距。在这项工作中，我们深入研究了一种在非平稳数据流中操作师生 KD 的系统方法。我们的目标是通过紧凑的学生实现高效部署，既能保留庞大教师的高性能，又能有效适应连续传入的数据。我们提出了持续协作蒸馏（CCD）框架，其中教师和学生都沿着数据流持续协作地发展。 CCD 有助于学生有效地适应新数据，同时也使老师能够充分利用积累的知识。我们通过对两个真实世界数据集进行大量定量、消融和探索性实验来验证 CCD 的有效性。我们希望这一研究方向有助于缩小现有 KD 研究与实际应用之间的差距，从而提高 KD 在真实世界系统中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2405.19046</guid>
      <pubDate>Fri, 28 Jun 2024 03:17:00 GMT</pubDate>
    </item>
    <item>
      <title>生成然后检索：使用 LLM 作为答案和查询生成器进行对话响应检索</title>
      <link>https://arxiv.org/abs/2403.19302</link>
      <description><![CDATA[arXiv:2403.19302v2 公告类型：替换 
摘要：CIS 是 IR 中的一个突出领域，专注于开发交互式知识助手。这些系统必须熟练地理解用户在对话上下文中的信息需求并检索相关信息。为此，现有方法通过在查询空间嵌入中生成单个查询重写或查询的单个表示来对用户的信息需求进行建模。但是，要回答复杂的问题，单个查询重写或表示通常是无效的。为了解决这个问题，系统需要对多个段落进行推理。在这项工作中，我们建议使用生成然后检索的方法来提高复杂用户查询的段落检索性能。在这种方法中，我们利用大型语言模型 (LLM) 来 (i) 通过对对话上下文进行推理来生成对用户信息需求的初步答案，以及 (ii) 将此答案与集合联系起来。根据实验，我们提出的方法在各种设置下显著提高了 TREC iKAT 23、TREC CAsT 20 和 22 数据集的检索性能。此外，我们还表明，确定 LLM 答案需要多个可搜索查询，其中平均 3 个查询的效果优于人工重写。]]></description>
      <guid>https://arxiv.org/abs/2403.19302</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>基底细胞癌诊断的一致性。建立适当的基本事实来训练人工智能工具</title>
      <link>https://arxiv.org/abs/2406.18240</link>
      <description><![CDATA[arXiv:2406.18240v1 公告类型：交叉 
摘要：背景：无法客观验证不同基底细胞癌 (BCC) 临床标准的存在。需要足够的事实来训练人工智能 (AI) 工具，该工具通过提供其皮肤镜特征来解释 BCC 诊断。目的：确定皮肤科医生对 204 个 BCC 皮肤镜标准的共识。分析推断事实时 AI 工具的性能。方法：进行了一项单中心、诊断和前瞻性研究，以分析四位皮肤科医生对皮肤镜标准的一致性，然后得出参考标准。使用了 1434 张皮肤镜图像，这些图像由初级保健医生拍摄，通过远程皮肤病学发送，并由皮肤科医生诊断。它们是从远程皮肤病学平台 (2019-2021) 随机选择的。其中 204 个用 AI 工具进行了测试；其余的对其进行了训练。使用 McNemar 检验和 Hamming 距离分析了使用一位皮肤科医生的真实数据与从四位皮肤科医生的共识中统计推断出的真实数据训练的 AI 工具的性能。结果：皮肤科医生对 BCC 的诊断完全一致（Fleiss-Kappa=0.9079），并且与活检具有高度相关性（PPV=0.9670）。然而，在检测某些皮肤镜标准时一致性较低。使用一位皮肤科医生的真实数据与从四位皮肤科医生的共识中统计推断出的真实数据训练的 AI 工具的性能存在统计学差异。结论：在训练 AI 工具以确定病变中存在的 BCC 模式时应小心谨慎。应从多位皮肤科医生那里建立真实数据。]]></description>
      <guid>https://arxiv.org/abs/2406.18240</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>ClickPrompt：CTR 模型是适应语言模型进行 CTR 预测的强大提示生成器</title>
      <link>https://arxiv.org/abs/2310.09234</link>
      <description><![CDATA[arXiv:2310.09234v5 公告类型：替换 
摘要：点击率 (CTR) 预测已成为各种互联网应用越来越不可或缺的一部分。传统的 CTR 模型通过独热编码将多字段分类数据转换为 ID 特征，并提取特征之间的协作信号。这种范式存在语义信息丢失的问题。另一条研究路线探索了预训练语言模型 (PLM) 通过硬提示模板将输入数据转换为文本句子来进行 CTR 预测的潜力。虽然保留了语义信号，但它们通常无法捕获协作信息（例如，特征交互、纯 ID 特征），更不用说庞大的模型大小带来的不可接受的推理开销了。在本文中，我们旨在对语义知识和协作知识进行建模以进行准确的 CTR 估计，同时解决推理效率低下的问题。为了从两个领域中受益并缩小差距，我们提出了一种新颖的模型无关框架（即 ClickPrompt），其中我们结合 CTR 模型来为 PLM 生成交互感知软提示。我们设计了一个提示增强掩码语言建模 (PA-MLM) 预训练任务，其中 PLM 必须根据语言上下文恢复掩码标记，以及 CTR 模型生成的软提示。来自 ID 和文本特征的协作和语义知识将通过提示界面明确对齐和交互。然后，我们可以使用 PLM 调整 CTR 模型以获得卓越的性能，或者单独调整不使用 PLM 的 CTR 模型以提高推理效率。在四个真实数据集上进行的实验验证了 ClickPrompt 与现有基线相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2310.09234</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>UniRec：顺序推荐中一致性和频率的双重增强</title>
      <link>https://arxiv.org/abs/2406.18470</link>
      <description><![CDATA[arXiv:2406.18470v1 公告类型：新
摘要：顺序推荐中的表示学习对于准确建模用户交互模式和提高推荐精度至关重要。然而，现有的方法主要强调项目到项目的转换，往往忽略了交互之间的时间间隔，而这与行为模式的变化密切相关。此外，更广泛的交互属性，如项目频率，也经常被忽视。我们发现时间间隔更均匀的序列和频率更高的项目都能产生更好的预测性能。相反，非均匀序列加剧了用户兴趣漂移，由于采样稀疏，频率较低的项目难以建模，这带来了当前方法无法充分解决的独特挑战。在本文中，我们提出了一种新颖的双向增强顺序推荐方法UniRec。UniRec利用序列均匀性和项目频率来增强性能，特别是改进非均匀序列和频率较低的项目的表示。这两个分支相互加强，推动了复杂顺序推荐场景中的全面性能优化。此外，我们提出了一个多维时间模块来进一步增强适应性。据我们所知，UniRec 是第一种利用均匀性和频率特性进行特征增强的方法。与四个数据集上的 11 个高级模型进行比较，我们证明 UniRec 的表现明显优于 SOTA 模型。代码可在 https://github.com/Linxi000/UniRec 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.18470</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>了解用户资料在大型语言模型个性化中的作用</title>
      <link>https://arxiv.org/abs/2406.17803</link>
      <description><![CDATA[arXiv:2406.17803v1 公告类型：交叉 
摘要：利用用户配置文件对大型语言模型 (LLM) 进行个性化处理已被证明可以提高各种任务的性能。然而，用户配置文件的确切作用及其对 LLM 的影响机制仍不清楚。本研究首先证实了用户配置文件的有效性主要归因于个性化信息而不是语义信息。此外，我们研究了用户配置文件如何影响 LLM 的个性化。在用户配置文件中，我们发现用户生成或批准的历史个性化响应在 LLM 的个性化中起着关键作用。这一发现释放了 LLM 在有限输入长度的限制内整合更多用户配置文件的潜力。至于用户配置文件的位置，我们观察到集成到输入上下文不同位置的用户配置文件对个性化的贡献并不相同。相反，更接近开头的用户配置文件对 LLM 的个性化影响更大。我们的研究结果揭示了用户资料在 LLM 个性化中的作用，并展示了整合用户资料如何影响性能，从而提供了有效利用用户资料的洞察力。]]></description>
      <guid>https://arxiv.org/abs/2406.17803</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>NormTab：通过表格数据规范化提高法学硕士 (LLM) 中的符号推理能力</title>
      <link>https://arxiv.org/abs/2406.17961</link>
      <description><![CDATA[arXiv:2406.17961v1 公告类型：交叉 
摘要：近年来，大型语言模型 (LLM) 在解析文本数据和生成代码方面表现出了卓越的能力。然而，它们在涉及表格数据的任务中的表现，尤其是那些需要符号推理的任务，面临着挑战，因为网络表格中经常发现表格单元格值的结构差异和不一致性。在本文中，我们介绍了 NormTab，这是一个新颖的框架，旨在通过规范化网络表格来增强 LLM 的符号推理性能。我们将表规范化作为独立的一次性预处理步骤进行研究，使用 LLM 支持表格数据的符号推理。我们对具有挑战性的网络表数据集（例如 WikiTableQuestion 和 TabFact）进行的实验评估表明，利用 NormTab 可以显着提高符号推理性能，展示了网络表规范化对于增强基于 LLM 的符号推理任务的重要性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.17961</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>使用合成数据对深度推荐模型性能的影响</title>
      <link>https://arxiv.org/abs/2406.18286</link>
      <description><![CDATA[arXiv:2406.18286v1 公告类型：新
摘要：推荐系统对于根据个人偏好推荐商品以增强用户体验至关重要。然而，这些系统经常面临数据不平衡的挑战，其特点是负面互动多于正面互动。这种不平衡可能导致偏向热门商品的推荐出现偏差。本研究调查了合成数据生成在解决推荐系统内数据不平衡方面的有效性。使用了六种不同的方法来生成合成数据。我们的实验方法包括使用这些方法生成合成数据并将生成的样本集成到原始数据集中。我们的结果表明，包含生成的负样本可以持续提高曲线下面积 (AUC) 得分。合成负样本的显著影响凸显了数据增强策略解决数据稀疏和不平衡问题的潜力，最终提高了推荐系统的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.18286</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>数据拆分策略对 CTR 预估离线实验的影响</title>
      <link>https://arxiv.org/abs/2406.18320</link>
      <description><![CDATA[arXiv:2406.18320v1 公告类型：新
摘要：点击率 (CTR) 预测是在线广告中推荐用户可能感兴趣的产品的一项关键任务。为了确定性能最佳的模型，必须进行严格的模型评估。尽管 A/B 测试等在线实验有其自身的局限性和风险，但离线实验在选择实时用户项目交互模型方面发挥着重要作用。通常，离线性能指标与实际在线模型性能之间的相关性不足。造成这种差异的一个主要原因是通常使用随机分割来创建 CTR 预测中的训练、验证和测试数据集。相比之下，现实世界的 CTR 预测遵循时间顺序。因此，离线评估中使用的方法，特别是数据拆分策略，至关重要。本研究旨在通过关注数据拆分策略来解决当前离线评估方法与实际用例之间的不一致问题。为了研究不同的数据分割策略对离线性能的影响，我们在大型开放基准数据集 Criteo 上使用随机和时间分割进行了大量实验。]]></description>
      <guid>https://arxiv.org/abs/2406.18320</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 1-to-K 对比学习提高跨语言跨模态检索的一致性</title>
      <link>https://arxiv.org/abs/2406.18254</link>
      <description><![CDATA[arXiv:2406.18254v1 公告类型：new 
摘要：跨语言跨模态检索（CCR）是网络搜索中的重要任务，旨在同时打破模态和语言之间的障碍，使用单一模型实现多语言场景下的图像文本检索。近年来，基于跨语言跨模态预训练的方法取得了长足的进步，特别是基于大规模数据对比学习的方法显著提升了检索任务。然而，这些方法直接沿用现有的跨语言或跨模态领域的预训练方法，导致 CCR 存在两个不一致的问题：具有跨语言风格的方法存在模态内误差传播的问题，导致整个数据集中跨语言的召回性能不一致。具有跨模态风格的方法存在模态间优化方向偏差的问题，导致每个实例内跨语言的排名不一致，而这无法通过 Recall@K 来反映。为了解决这些问题，我们提出了一种简单但有效的 1-to-K 对比学习方法，该方法平等对待每种语言并消除错误传播和优化偏差。此外，我们提出了一种新的评估指标，即平均等级方差 (MRV)，以反映每个实例中不同语言之间的等级不一致性。在四个 CCR 数据集上进行的大量实验表明，我们的方法在使用较小规模的预训练数据的情况下提高了召回率和 MRV，达到了新的最佳水平。]]></description>
      <guid>https://arxiv.org/abs/2406.18254</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>通过可学习的后期交互实现高效的文档排序</title>
      <link>https://arxiv.org/abs/2406.17968</link>
      <description><![CDATA[arXiv:2406.17968v1 公告类型：新
摘要：交叉编码器 (CE) 和双编码器 (DE) 模型是信息检索中查询文档相关性的两种基本方法。为了预测相关性，CE 模型使用联合查询文档嵌入，而 DE 模型维护分解的查询和文档嵌入；通常，前者具有更高的质量，而后者受益于较低的延迟。最近，已经提出了后期交互模型来实现更有利的延迟质量权衡，通过使用 DE 结构，然后使用基于查询和文档标记嵌入的轻量级评分器。然而，这些轻量级评分器通常是手工制作的，并且人们对它们的近似能力没有了解；此外，这样的评分器需要访问单个文档标记嵌入，这会增加延迟和存储负担。在本文中，我们提出了解决这些问题的新型可学习后期交互模型 (LITE)。从理论上讲，我们证明 LITE 是连续评分函数的通用近似器，即使对于相对较小的嵌入维度也是如此。从经验上讲，LITE 在域内和零样本重新排序任务上都优于之前的后期交互模型（例如 ColBERT）。例如，对 MS MARCO 段落重新排序的实验表明，与 ColBERT 相比，LITE 不仅产生了具有更好泛化的模型，而且延迟更低，并且所需的存储空间是 ColBERT 的 0.25 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.17968</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:54 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱增强检索增强生成用于故障模式和影响分析</title>
      <link>https://arxiv.org/abs/2406.18114</link>
      <description><![CDATA[arXiv:2406.18114v1 公告类型：新
摘要：故障模式和影响分析 (FMEA) 是减轻潜在故障的关键工具，特别是在新产品的启动阶段。然而，它的有效性往往受到 FMEA 工具缺乏推理能力的限制，这些工具通常是表格结构的。同时，大型语言模型 (LLM) 为在 FMEA 上下文中推理自定义数据集提供了新的前景。然而，LLM 在需要事实知识的任务中面临挑战，检索增强生成 (RAG) 方法旨在填补这一空白。RAG 从非参数数据存储中检索信息并使用语言模型生成响应。基于这个想法，我们建议使用知识图 (KG) 来推进非参数数据存储。通过使用 KG 增强 RAG 框架，我们的目标是利用 FMEA 数据的分析和语义问答功能。本文通过介绍一种新的 FMEA 观测本体、一种从 FMEA KG 创建向量嵌入的算法以及一个 KG 增强型 RAG 框架做出了贡献。我们的方法通过人工研究得到验证，并且我们测量了上下文检索的召回率和准确率。]]></description>
      <guid>https://arxiv.org/abs/2406.18114</guid>
      <pubDate>Fri, 28 Jun 2024 03:16:54 GMT</pubDate>
    </item>
    </channel>
</rss>