<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Rago：用于检索效果的系统性能优化</title>
      <link>https://arxiv.org/abs/2503.14649</link>
      <description><![CDATA[ARXIV：2503.14649V1公告类型：新 
摘要：结合大型语言模型（LLM）和从外部知识数据库中检索的检索型生成（RAG）正在成为可靠的LLM服务的一种流行方法。但是，由于许多抹布变体的快速出现以及它们之间的工作量特征的实质性差异，有效的破布效果仍然是一个开放的挑战。在本文中，我们为推进抹布的服务做出了三个基本贡献。首先，我们介绍了Ragschema，这是一种结构化抽象，可捕获各种破布算法，是性能优化的基础。其次，我们分析了几个具有不同Ragschema的代表性RAG工作负载，揭示了这些工作负载的显着性能变异性。第三，为了满足这种可变性并满足各种性能要求，我们建议Rago（检索型发电优化器），这是一个用于有效抹布的系统优化框架。我们的评估表明，与在LLM系统扩展上构建的破布系统相比，Rago的每芯片QP的增加高达2倍，并且降低了55％的延迟延迟。]]></description>
      <guid>https://arxiv.org/abs/2503.14649</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长上下文建模，以排名的存储器调查检索</title>
      <link>https://arxiv.org/abs/2503.14800</link>
      <description><![CDATA[ARXIV：2503.14800V1公告类型：新 
摘要：有效的长期记忆管理对于处理扩展上下文的语言模型至关重要。我们介绍了一个新颖的框架，该框架会根据相关性动态排名记忆条目。与以前的作品不同，我们的模型介绍了一个新颖的相关性评分和一个键值嵌入的重新级别模型，灵感来自信息检索中的学习级技术。增强的排名存储器增强检索Ermar在标准基准方面取得了最新的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.14800</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图形的重新排列：新兴技术，局限性和机会</title>
      <link>https://arxiv.org/abs/2503.14802</link>
      <description><![CDATA[ARXIV：2503.14802V1公告类型：新 
摘要：知识图已成为有希望的数据存储候选者，以增加检索增强发电（RAG）的上下文增强。结果，图表表示学习中的技术已与主要神经信息检索方法同时探索，例如基于两步的检索，也称为重新排列。尽管已经提出了图形神经网络（GNN）来证明对重新排列的图形学习的熟练程度，但在建模和评估输入图结构方面存在持续的限制，用于训练和评估通道和文档排名任务。在这项调查中，我们回顾了新兴的GNN排名模型体系结构及其相应的图表构建方法。我们通过根据社区范围的挑战和机遇提供有关未来研究的建议来结束。]]></description>
      <guid>https://arxiv.org/abs/2503.14802</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>伪相关反馈可以改善基于LLM LLM的密集检索</title>
      <link>https://arxiv.org/abs/2503.14887</link>
      <description><![CDATA[ARXIV：2503.14887V1公告类型：新 
摘要：伪相关反馈（PRF）通过利用最初检索文档来提高检索效率来完善查询。在本文中，我们研究了大型语言模型（LLMS）如何促进基于零LLM的密集检索的PRF，从而扩展了最近提出的Progptreps方法。具体而言，我们的方法使用LLM来提取明显的段落功能，例如关键字和摘要，即顶级文档，然后将其集成到Promptreps中以产生增强的查询表示。对通道检索基准测试的实验表明，合并PRF可以显着提高检索性能。值得注意的是，具有PRF的较小排名者可以在没有PRF的情况下与较大的排名者的有效性相匹配，从而强调了PRF改善LLM驱动搜索的潜力，同时保持有效性和资源使用之间的有效平衡。]]></description>
      <guid>https://arxiv.org/abs/2503.14887</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化财务问题的检索策略，以回收的生成系统回答文件</title>
      <link>https://arxiv.org/abs/2503.15191</link>
      <description><![CDATA[Arxiv：2503.15191V1公告类型：新 
摘要：检索型发电（RAG）已成为减轻大语言模型（LLMS）幻觉的有前途的框架，但其整体性能取决于基本的检索系统。在金融领域中，由于特定于域特异性词汇和多等级表格数据，诸如10K报告诸如10-K报告构成了不同的挑战。在这项工作中，我们引入了一条高效的端到端破布管道，该管道通过三相方法来增强财务文件的检索：退回前，检索和退回后。在退回阶段，采用了各种查询和语料库预处理技术来丰富输入数据。在检索阶段，我们用特定于领域的知识微调了最新的（SOTA）嵌入模型，并实施了混合检索策略，该策略结合了密集和稀疏表示。最后，后期阶段利用直接偏好优化（DPO）培训和文档选择方法来进一步完善结果。对七个财务问题的评估回答数据集，Finqabench，FinanceBench，Tatqa，Finqa，Converfinqa和Multihiertt-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-DECRACH绩效的实质性改进，从而导致更准确且上下文更合适的生成。这些发现突出了量身定制的检索技术在提高抹布系统对金融应用的有效性方面的关键作用。 GitHub上可以完全可复制的管道：https：//github.com/seohyunwoo-0407/gar。]]></description>
      <guid>https://arxiv.org/abs/2503.15191</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>猪生病时：多代理AI用于猪疾病检测</title>
      <link>https://arxiv.org/abs/2503.15204</link>
      <description><![CDATA[ARXIV：2503.15204V1公告类型：交叉 
摘要：猪疾病监测对于全球农业的可持续性至关重要，但是其有效性经常因有限的兽医资源，延迟识别病例以及诊断准确性的可变性而破坏。为了克服这些障碍，我们引入了一种新型的AI驱动，多代理诊断系统，该系统利用检索效果的生成（RAG）提供及时的，基于证据的疾病检测和临床指导。通过将用户输入分类为知识检索查询或基于症状的诊断查询，该系统可确保有针对性的信息检索并促进精确的诊断推理。自适应质疑方案有系统地收集相关的临床体征，而信心加权的决策融合机制则整合了多种诊断假设，以产生强大的疾病预测和治疗建议。全面的评估包括查询分类，疾病诊断和知识检索表明，该系统可实现高准确性，快速响应时间和一致的可靠性。通过提供可扩展的AI驱动诊断框架，这种方法可以增强兽医决策，提高可持续的牲畜管理实践，并为实现全球粮食安全的实现做出了实质性的贡献。]]></description>
      <guid>https://arxiv.org/abs/2503.15204</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于审查的双曲线跨域建议</title>
      <link>https://arxiv.org/abs/2403.20298</link>
      <description><![CDATA[ARXIV：2403.20298V3公告类型：替换 
摘要：数据稀疏性问题对推荐系统构成了重大挑战。为此，已经提出了利用辅助信息（例如评论文本）的算法。此外，捕获可提供域的知识并将其从较富裕的域（源）转移到稀疏的知识（目标）（目标）的跨域推荐（CDR）受到了显着关注。然而，大多数现有方法都假设欧几里得嵌入空间，在准确表示更丰富的文本信息和管理用户与项目之间的复杂互动方面遇到困难。本文提倡一种基于用于建模用户项目关系的评论文本的双曲线CDR方法。我们首先强调，基于距离的域对准技术可能会引起问题，因为双曲几何形状的小修改会导致放大扰动，最终导致层次结构的崩溃。为了应对这一挑战，我们提出了层次结构感知的嵌入和域对准方案，这些方案调整了规模，以提取可分布的域可共享信息而不会破坏结构形式。该过程涉及双曲线空间中的评论文本的初始嵌入，然后进行特征提取，其中包括基于学位的归一化和结构比对。与最新基准相比，我们进行了广泛的实验，以证实我们所提出的模型的效率，鲁棒性和可伸缩性。]]></description>
      <guid>https://arxiv.org/abs/2403.20298</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于ID的建议的粗到1个轻巧的元装置</title>
      <link>https://arxiv.org/abs/2501.11870</link>
      <description><![CDATA[ARXIV：2501.11870V2公告类型：替换 
摘要：最先进的建议系统将注意力转移到了有效的建议下，例如在内存约束下，在设备上的建议。为此，现有的方法要么集中在用户和项目的轻量级嵌入方式上，要么涉及享受紧凑型嵌入的设备系统，以增强可重复性并降低空间的复杂性。但是，它们仅关注嵌入的粗粒度，同时忽略细粒的语义细微差别，以对抗降低元嵌入的效力，使其在用户和项目上捕获复杂的关系，从而导致了次优建议。在本文中，我们旨在研究如何有效地学习多样化的粒度语义，以及如何加强细粒度的粗粒元装置的代表。 To answer these questions, we develop a novel graph neural networks (GNNs) based recommender where each user and item serves as the node, linked directly to coarse-grained virtual nodes and indirectly to fine-grained virtual nodes, ensuring different grained semantic learning, while disclosing: 1) In contrast to coarse-grained semantics, fine-grained semantics are well captured through sparse meta-embeddings, which adaptively 2) balance the嵌入独特性和内存约束。此外，初始化方法出现在SparsePCA上，以及软阈值激活函数，从而呈现元嵌入的稀疏度。我们提出了一个重量桥接更新策略，该策略的重点是根据用户/项目的语义将每个粗粒元元装置与几个细粒度的元装置匹配。广泛的实验证实了我们方法比现有基线的优势。我们的代码可在https://github.com/htyjers/c2f-metabed上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.11870</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>取代链增强一代</title>
      <link>https://arxiv.org/abs/2501.14342</link>
      <description><![CDATA[ARXIV：2501.14342V2公告类型：替换 
摘要：本文介绍了一种培训类似O1的抹布模型的方法，该方法在生成最终答案之前逐步检索和理由，逐步检索和理由。常规的抹布方法通常在生成过程之前执行单个检索步骤，这限制了由于不完善的检索结果而导致的复杂查询的有效性。相比之下，我们提出的方法Corag（重新预应增强链）使该模型可以根据不断发展的状态动态重新重新重新查询查询。为了有效地培训Corag，我们利用拒绝抽样自动生成中间检索链，从而增加仅提供正确最终答案的现有抹布数据集。在测试时，我们提出了各种解码策略，通过控制采样的检索链的长度和数量来扩展模型的测试时间计算。多个基准的实验结果验证了Corag的功效，尤其是在多跳的问题答案任务中，与强基地相比，我们观察到EM得分的10点以上提高了10分。在KILT基准测试中，Corag在各种知识密集型任务中建立了新的最先进的表现。此外，我们提供了全面的分析，以了解Corag的规模行为，为未来的研究奠定了旨在开发事实和扎根基础模型的基础。]]></description>
      <guid>https://arxiv.org/abs/2501.14342</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>回忆他们全部：从长文档中提取长对象列表的检索语言模型</title>
      <link>https://arxiv.org/abs/2405.02732</link>
      <description><![CDATA[ARXIV：2405.02732V2公告类型：替换 - 交叉 
摘要：从文本中提取的方法主要集中于高精度，而召回率有限。但是，高召回率至关重要，对于与给定主题具有特定关系的对象实体的长列表至关重要。相关对象的提示可以分布在长文本中的许多段落中。这构成了从长文本中提取长列表的挑战。我们提出了L3X方法，该方法在两个阶段解决了该问题：（1）使用大型语言模型（LLM）使用明智的检索技术进行召回的生成，以及（2）（2）以精度为导向的审查来验证或修剪候选者。我们的L3X方法的优于仅限LLM的世代优于一个大幅度。]]></description>
      <guid>https://arxiv.org/abs/2405.02732</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引导自己的上下文长度</title>
      <link>https://arxiv.org/abs/2412.18860</link>
      <description><![CDATA[ARXIV：2412.18860V2公告类型：替换 - 交叉 
摘要：我们介绍了一种自举方法，通过仅利用其短篇小写功能来培训长篇文章模型。我们的方法利用简单的代理工作流程来综合多种长篇文章指令调整数据，从而消除了手动数据收集和注释的必要性。所提出的数据综合工作流仅需要一个短篇小写的语言模型，一个文本检索器和文档集合，所有这些模型都可以在开源生态系统中易于访问。随后，使用综合数据来微调语言模型以扩展其上下文长度。通过这种方式，我们通过引导过程有效地将语言模型的短篇小写功能转移到了长篇小说方案。我们使用开源美洲拉玛-3模型家族进行实验，并证明我们的方法可以成功地将上下文长度扩展到最高1M令牌，从而在各种基准中实现出色的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.18860</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用嘈杂变更指示信号的可扩展爬行算法</title>
      <link>https://arxiv.org/abs/2502.02430</link>
      <description><![CDATA[ARXIV：2502.02430V2公告类型：替换 - 交叉 
摘要：Web Refresh Crawling是将网页库保持新鲜的问题，也就是说，在请求页面时提供最新的副本，鉴于爬网机可用的带宽有限。在每个网页上的变更和请求事件的假设遵循独立的泊松过程的假设，最佳的调度策略是由Azar等人得出的。 2018年。在本文中，我们研究了此问题的扩展，其中指示内容变化的附带信息，例如各种类型的网络ping，例如来自站点地图，内容输送网络等的信号。将这种附带信息纳入爬行政策是具有挑战性的，因为（i）信号可能会出现虚假的积极事件和缺少变更事件的噪音； （ii）不管侧面信息的质量如何，爬虫都应在网页上实现公平的性能，这在网页上可能有所不同。我们提出了一种可扩展的爬行算法，该算法（i）在轻度假设下以最佳方式使用嘈杂的侧面信息； （ii）可以在没有重大集中计算的情况下部署； （iii）能够在任何时间间隔内以恒定的总速率爬网，而无需峰值的总带宽使用情况，并在总带宽变化而没有集中计算的情况下自动适应新的最佳解决方案。实验清楚地证明了我们方法的多功能性。]]></description>
      <guid>https://arxiv.org/abs/2502.02430</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>