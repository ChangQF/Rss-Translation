<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 31 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CaLa：增强合成图像检索的互补关联学习</title>
      <link>https://arxiv.org/abs/2405.19149</link>
      <description><![CDATA[arXiv:2405.19149v2 公告类型：replace-cross 
摘要：组合图像检索 (CIR) 涉及根据图像-文本对查询搜索目标图像。虽然当前方法将其视为查询-目标匹配问题，但我们认为 CIR 三元组包含超出此主要关系的其他关联。在我们的论文中，我们在三元组中确定了两个新关系，将每个三元组视为一个图节点。首先，我们引入了文本桥接图像对齐的概念，其中查询文本充当查询图像和目标图像之间的桥梁。我们提出了一种基于铰链的交叉注意机制，将这种关系纳入网络学习。其次，我们探索互补文本推理，将 CIR 视为一种跨模态检索的形式，其中两个图像组合起来推理互补文本。为了有效地整合这些观点，我们设计了一个基于双注意的合成器。通过将这些互补关联与显式查询对目标图像关系相结合，我们为 CIR 建立了一套全面的约束。我们的框架 CaLa（用于增强组合图像检索的互补关联学习）利用了这些见解。我们在具有多个主干的 CIRR 和 FashionIQ 基准上评估了 CaLa，证明了其在组合图像检索方面的优越性。]]></description>
      <guid>https://arxiv.org/abs/2405.19149</guid>
      <pubDate>Fri, 31 May 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>Lookahead：具有无损生成精度的大型语言模型推理加速框架</title>
      <link>https://arxiv.org/abs/2312.12728</link>
      <description><![CDATA[arXiv:2312.12728v3 公告类型：替换 
摘要：随着大型语言模型 (LLM) 在问答、翻译、文本摘要和对话系统等各种任务上取得了重大进展，对信息准确性的需求变得至关重要，尤其是对于像支付宝这样服务于数十亿用户的严肃金融产品而言。然而，对于服务于数百万用户的实际产品，与单纯的实验模型相比，LLM 的推理速度成为一个关键因素。
因此，本文提出了一个通用框架来加速推理过程，从而大幅提高基于 LLM 的场景的速度并降低成本，同时保持无损生成精度。在传统的推理过程中，每个 token 由 LLM 顺序生成，导致时间消耗与生成的 token 数量成正比。为了增强此过程，我们的框架名为 \textit{lookahead}，引入了 \textit{multi-branch} 策略。我们提出了一种基于 Trie 的检索和验证机制，而不是一次生成一个 token，这样就可以在前进的一步中接受多个 token。我们的策略有两个明显的优势：（1）它保证输出的绝对正确性，避免任何近似算法，（2）我们的方法的最坏情况性能与传统过程相当。我们进行了广泛的实验，以证明应用我们的推理加速框架所取得的显著改进。我们的框架自 2023 年 4 月起在支付宝中广泛部署，并获得了显著的 2.66 倍至 6.26 倍的加速。我们的代码可在 https://github.com/alipay/PainlessInferenceAcceleration 上找到。]]></description>
      <guid>https://arxiv.org/abs/2312.12728</guid>
      <pubDate>Fri, 31 May 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>Croissant：适用于 ML-Ready 数据集的元数据格式</title>
      <link>https://arxiv.org/abs/2403.19546</link>
      <description><![CDATA[arXiv:2403.19546v2 公告类型：replace-cross 
摘要：数据是机器学习 (ML) 的关键资源，但处理数据仍然是一个关键的摩擦点。本文介绍了 Croissant，这是一种数据集的元数据格式，可简化 ML 工具和框架使用数据的方式。Croissant 使数据集更易于发现、可移植和可互操作，从而解决了 ML 数据管理和负责任的 AI 中的重大挑战。Croissant 已经得到几个流行的数据集存储库的支持，涵盖数十万个数据集，可以加载到最流行的 ML 框架中。]]></description>
      <guid>https://arxiv.org/abs/2403.19546</guid>
      <pubDate>Fri, 31 May 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>使用语义 ID 实现更好的泛化：推荐排名案例研究</title>
      <link>https://arxiv.org/abs/2306.08121</link>
      <description><![CDATA[arXiv:2306.08121v2 公告类型：替换 
摘要：随机散列的项目 ID 在推荐模型中被广泛使用。然而，从随机散列中学习到的表示阻止了类似项目的泛化，导致学习看不见的和长尾项目的问题，特别是当项目语料库很大、幂律分布且动态变化时。在本文中，我们建议使用内容派生特征来替代随机 ID。我们表明，简单地用基于内容的嵌入替换 ID 特征会导致质量下降，因为记忆能力下降。为了在记忆和泛化之间取得良好的平衡，我们建议使用语义 ID（一种从使用 RQ-VAE 的冻结内容嵌入中学习到的紧凑离散项目表示，可以捕获项目中概念的层次结构）来替代随机项目 ID。与内容嵌入类似，语义 ID 的紧凑性在推荐模型中带来了易于适应的问题。我们提出了一种新颖的方法，通过对语义 ID 序列的子片段进行哈希处理，在行业规模的排名模型中调整语义 ID。特别是，我们发现 LLM 标记化中常用的 SentencePiece 模型比 N-gram 等手工制作的片段表现更好。最后，我们在现实世界的 YouTube 推荐排名模型中评估了我们的方法。我们的实验表明，语义 ID 可以通过提高新项目和长尾项目切片的泛化能力来取代视频 ID 的直接使用，而不会牺牲整体模型质量。]]></description>
      <guid>https://arxiv.org/abs/2306.08121</guid>
      <pubDate>Fri, 31 May 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>一种使用大型语言模型进行有效、高效的零样本排名的集合方法</title>
      <link>https://arxiv.org/abs/2310.09497</link>
      <description><![CDATA[arXiv:2310.09497v2 公告类型：替换 
摘要：我们提出了一种基于大型语言模型 (LLM) 的新型零样本文档排名方法：Setwise 提示方法。我们的方法补充了现有的基于 LLM 的零样本排名提示方法：Pointwise、Pairwise 和 Listwise。通过在一致的实验框架内进行首创的比较评估，并考虑模型大小、token 消耗、延迟等因素，我们表明现有方法本质上以有效性和效率之间的权衡为特征。我们发现，虽然 Pointwise 方法在效率上得分很高，但其有效性较差。相反，Pairwise 方法表现出卓越的有效性，但会产生高计算开销。与以前的方法相比，我们的 Setwise 方法减少了排名过程中的 LLM 推理次数和提示 token 消耗量。这显着提高了基于 LLM 的零样本排名的效率，同时还保持了较高的零样本排名有效性。我们将代码和结果公开发​​布在 \url{https://github.com/ielab/llm-rankers}。]]></description>
      <guid>https://arxiv.org/abs/2310.09497</guid>
      <pubDate>Fri, 31 May 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>Jina CLIP：您的 CLIP 模型也是您的文本检索器</title>
      <link>https://arxiv.org/abs/2405.20204</link>
      <description><![CDATA[arXiv:2405.20204v1 公告类型：交叉 
摘要：对比语言-图像预训练 (CLIP) 被广泛用于训练模型，通过将图像和文本映射到固定大小的向量来在公共嵌入空间中对齐它们。这些模型是多模态信息检索和相关任务的关键。然而，与专门的文本模型相比，CLIP 模型在纯文本任务中的表现通常不佳。这会导致信息检索系统效率低下，因为这些系统将嵌入和模型分开用于纯文本和多模态任务。我们提出了一种新颖的多任务对比训练方法来解决这个问题，我们使用这种方法来训练 jina-clip-v1 模型，以在文本-图像和文本-文本检索任务上实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.20204</guid>
      <pubDate>Fri, 31 May 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>AntCritic：自由形式和视觉丰富的财务评论论据挖掘</title>
      <link>https://arxiv.org/abs/2208.09612</link>
      <description><![CDATA[arXiv:2208.09612v2 公告类型：替换 
摘要：论证挖掘旨在检测所有可能的论证成分并自动识别它们之间的关系。作为自然语言处理中一项蓬勃发展的任务，该领域已经有大量语料库可供学术研究和应用开发。然而，该领域的研究仍然受到现有数据集固有限制的制约。具体来说，所有公开的数据集规模都相对较小，其中很少有数据集提供来自其他模态的信息来促进学习过程。此外，这些语料库中的语句和表达通常为紧凑形式，这限制了模型的泛化能力。为此，我们收集了一个新数据集 AntCritic 作为该领域的有益补充，它包含大约 10k 条自由形式且视觉丰富的金融评论，支持论证成分检测和论证关系预测任务。此外，为了应对场景扩展带来的挑战，我们深入探索了细粒度关系预测和结构重构方案，并讨论了视觉样式和布局的编码机制。在此基础上，我们设计了两个简单但有效的模型架构，并在此数据集上进行了各种实验，以提供基准性能作为参考，并验证了我们提出的架构的实用性。我们在此链接中发布我们的数据和代码，此数据集遵循 CC BY-NC-ND 4.0 许可证。]]></description>
      <guid>https://arxiv.org/abs/2208.09612</guid>
      <pubDate>Fri, 31 May 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>MUVERA：通过固定维度编码进行多向量检索</title>
      <link>https://arxiv.org/abs/2405.19504</link>
      <description><![CDATA[arXiv:2405.19504v1 公告类型：交叉 
摘要：神经嵌入模型已成为现代信息检索 (IR) 管道的基本组成部分。这些模型为每个数据点生成单个嵌入 $x \in \mathbb{R}^d$，允许通过高度优化的最大内积搜索 (MIPS) 算法进行快速检索。最近，从具有里程碑意义的 ColBERT 论文开始，为每个数据点生成一组嵌入的多向量模型在 IR 任务中取得了显着优越的性能。不幸的是，由于多向量检索和评分的复杂性增加，将这些模型用于 IR 在计算上很昂贵。
在本文中，我们介绍了 MUVERA（多向量检索算法），这是一种将多向量相似性搜索简化为单向量相似性搜索的检索机制。这使得可以使用现成的 MIPS 求解器进行多向量检索。 MUVERA 不对称地生成查询和文档的固定维度编码 (FDE)，这些向量的内积近似于多向量相似性。我们证明 FDE 给出了高质量的 $\epsilon$ 近似值，从而为多向量相似性提供了第一个具有理论保证的单向量代理。从经验上讲，我们发现 FDE 实现了与之前最先进的启发式方法相同的召回率，同时检索的候选数减少了 2-5$\times$。与之前最先进的实现相比，MUVERA 在各种 BEIR 检索数据集中实现了始终如一的良好端到端召回率和延迟，平均召回率提高了 10$\%$，延迟降低了 $90\%$。]]></description>
      <guid>https://arxiv.org/abs/2405.19504</guid>
      <pubDate>Fri, 31 May 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>使用概率分布建模实现不确定性感知手语视频检索</title>
      <link>https://arxiv.org/abs/2405.19689</link>
      <description><![CDATA[arXiv:2405.19689v1 公告类型：交叉 
摘要：手语视频检索在促进聋人群体获取信息方面发挥着关键作用。尽管视频文本检索取得了重大进展，但手语的复杂性和固有的不确定性阻碍了这些技术的直接应用。以前的方法通过细粒度模态对齐实现手语视频和文本之间的映射。然而，由于细粒度注释的稀缺，手语视频固有的不确定性被低估，限制了手语检索任务的进一步发展。为了应对这一挑战，我们提出了一种新颖的不确定性感知概率分布检索 (UPRet)，它从概率分布的角度概念化手语视频和文本的映射过程，探索它们潜在的相互关系，并实现灵活的映射。在三个基准测试上的实验证明了我们方法的有效性，在 How2Sign（59.1%）、PHOENIX-2014T（72.0%）和 CSL-Daily（78.4%）上取得了最佳结果。]]></description>
      <guid>https://arxiv.org/abs/2405.19689</guid>
      <pubDate>Fri, 31 May 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>用于冷启动用户推荐的关键字驱动检索增强大型语言模型</title>
      <link>https://arxiv.org/abs/2405.19612</link>
      <description><![CDATA[arXiv:2405.19612v1 公告类型：新 
摘要：大型语言模型 (LLM) 的最新进展已显示出增强推荐系统的巨大潜力。然而，解决用户缺乏历史数据的冷启动推荐问题仍然是一项艰巨的挑战。在本文中，我们介绍了 KALM4Rec（用于冷启动用户推荐的关键字驱动检索增强大型语言模型），这是一个专门为解决此问题而设计的新框架，在冷启动用户餐厅推荐的实际场景中只需要用户输入几个关键字。KALM4Rec 主要分为两个阶段：候选检索和基于 LLM 的候选重新排名。在第一阶段，使用关键字驱动的检索模型来识别潜在候选，解决 LLM 在处理大量标记方面的局限性并降低生成误导信息的风险。在第二阶段，我们使用具有各种提示策略（包括零样本和少样本技术）的 LLM，通过将多个示例直接集成到 LLM 提示中来重新排序这些候选词。我们的评估使用了来自三个英语城市的用户评论的 Yelp 餐厅数据集，结果表明，我们提出的框架显著提高了推荐质量。具体而言，将上下文指令与 LLM 集成以进行重新排序显著提高了冷启动用户推荐系统的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.19612</guid>
      <pubDate>Fri, 31 May 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 LLM 生成查询建议</title>
      <link>https://arxiv.org/abs/2405.19749</link>
      <description><![CDATA[arXiv:2405.19749v1 公告类型：新
摘要：查询推荐系统在现代搜索引擎中无处不在，可帮助用户生成有效的查询以满足他们的信息需求。但是，这些系统需要大量数据才能产生良好的建议，例如要索引的大量文档和查询日志。特别是，查询日志和用户数据在冷启动场景中不可用。查询日志的收集和维护成本很高，并且需要复杂且耗时的级联管道来创建、组合和排名建议。为了解决这些问题，我们将查询推荐问题定义为生成任务，提出了一种称为生成查询推荐（GQR）的新方法。GQR 以 LLM 为基础，不需要进行训练或微调即可解决查询推荐问题。我们设计了一个提示，使 LLM 能够理解特定的推荐任务，即使使用单个示例也是如此。然后，我们通过提出一个利用查询日志的版本（称为 Retriever-Augmented GQR (RA-GQR)）改进了我们的系统。RA-GQr 通过从查询日志中检索类似查询来动态编写其提示。GQR 方法重用了预先存在的神经架构，从而产生了一种更简单、更适合市场的方法，即使在冷启动情况下也是如此。我们提出的 GQR 在 NDCG@10 和清晰度得分方面与两个商业搜索引擎和之前在 Robust04 和 ClueWeb09B 集合上的最新方法相比获得了最先进的性能，平均而言，与之前的最佳竞争对手相比，Robust04 和 ClueWeb09B 上的 NDCG@10 性能提高了约 4%。RA-GQR 进一步改进了 NDCG@10，与最佳竞争对手相比，Robust04 和 ClueWeb09B 上的 NDCG@10 性能提高了约 11%，约 6\%。此外，我们的系统在盲人用户研究中获得约 59％ 的用户偏好，证明我们的方法产生了最具吸引力的查询。]]></description>
      <guid>https://arxiv.org/abs/2405.19749</guid>
      <pubDate>Fri, 31 May 2024 06:20:00 GMT</pubDate>
    </item>
    </channel>
</rss>