<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 12 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 ZeroG 缓解幻觉：一种先进的知识管理引擎</title>
      <link>https://arxiv.org/abs/2411.05936</link>
      <description><![CDATA[arXiv:2411.05936v1 公告类型：新
摘要：数字文档的增长对高效管理和知识提取提出了重大挑战。传统方法通常难以处理复杂文档，导致大型语言模型 (LLM) 响应出现幻觉和高延迟等问题。ZeroG 是一种创新方法，它通过利用知识提炼和快速调整来提高模型性能，从而显著缓解了这些挑战。
ZeroG 使用较小的模型来复制较大的教师模型的行为，确保上下文相关且有根据的响应，通过采用黑盒提炼方法，它创建了一个提炼数据集而不依赖中间特征，从而优化了计算效率。该方法显著提高了准确性并缩短了响应时间，为现代文档管理提供了平衡的解决方案。
ZeroG 结合了文档提取和元数据利用的先进技术，提高了问答系统的准确性。图形数据库和强大的元数据管理的集成进一步简化了信息检索，从而实现了精确且具有上下文感知的响应。通过改变组织与复杂数据的交互方式，ZeroG 提高了生产力和用户体验，并为日益增长的数字文档管理需求提供了可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.05936</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于片段的对话推荐系统</title>
      <link>https://arxiv.org/abs/2411.06064</link>
      <description><![CDATA[arXiv:2411.06064v1 公告类型：新
摘要：对话推荐系统 (CRS) 让用户参与互动对话，以收集偏好并提供个性化推荐。传统上，CRS 依靠预定义属性或昂贵的、特定领域的注释数据集来指导对话，这限制了跨领域的灵活性和适应性。在这项工作中，我们引入了 SnipRec，这是一种新颖的 CRS，它通过从用户生成的内容 (UGC)（如客户评论）中提取不同的表达和偏好来增强对话和推荐。使用大型语言模型，SnipRec 将用户响应和 UGC 映射到简洁的片段，用于生成澄清问题和检索相关项目。我们的方法消除了对特定领域训练的需求，使其能够适应新领域并且在没有用户偏好的先验知识的情况下有效。在 Yelp 数据集上进行的大量实验证明了基于片段的表示相对于基于文档和基于句子的表示的有效性。此外，SnipRec 能够在五轮对话中将 Hits@10 提高 0.25，凸显了 SnipRec 通过多轮对话捕捉用户偏好的效率。]]></description>
      <guid>https://arxiv.org/abs/2411.06064</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用稀疏自动编码器解释推荐模型的内部状态</title>
      <link>https://arxiv.org/abs/2411.06112</link>
      <description><![CDATA[arXiv:2411.06112v1 公告类型：新
摘要：可解释的推荐系统对于提高透明度、准确性和公平性非常重要。除了结果级解释之外，模型级解释还可以提供有价值的见解，使开发人员能够优化系统设计并实施有针对性的改进。然而，大多数当前方法依赖于专门的模型设计，而这些模型设计往往缺乏泛化能力。鉴于推荐模型种类繁多，现有方法对它们的有效解释能力有限。为了解决这个问题，我们提出了 RecSAE，这是一种自动、可泛化的探测方法，用于使用稀疏自动编码器解释推荐模型的内部状态。RecSAE 是一个插件模块，在解释过程中不会影响原始模型，同时还可以根据解释结果对其行为进行可预测的修改。首先，我们训练一个具有稀疏性约束的自动编码器来重建推荐模型的内部激活，使 RecSAE 潜伏期比原始神经元激活更具可解释性和单义性。其次，我们根据潜在激活和输入项目序列之间的关系自动构建概念词典。第三，RecSAE 通过使用概念词典预测新项目序列上的潜在激活并从准确率和召回率中得出解释置信度分数来验证这些解释。我们在两个数据集上证明了 RecSAE 的有效性，从纯基于 ID 的模型中识别出数百个高度可解释的概念。潜在消融研究进一步证实，操纵潜在概念会导致模型输出行为发生相应的变化，这强调了 RecSAE 对于理解和有针对性地调整推荐模型的实用性。代码和数据可在 https://github.com/Alice1998/RecSAE 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.06112</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用检索增强生成进行大学知识检索</title>
      <link>https://arxiv.org/abs/2411.06237</link>
      <description><![CDATA[arXiv:2411.06237v1 公告类型：新
摘要：本文介绍了一种创新方法，使用检索增强生成 (RAG) 管道和大型语言模型 (LLM) 来增强大学相关问答的信息检索和查询响应系统。通过系统地从大学官方网页提取数据并采用先进的提示工程技术，我们可以生成准确、上下文相关的用户查询响应。
我们开发了一个全面的大学基准 UniversityQuestionBench (UQB)，以严格评估我们系统的性能，基于 RAG 管道领域的常见关键指标，通过各种指标和真实场景评估准确性和可靠性。我们的实验结果表明，生成的响应的精度和相关性得到了显着提高，增强了用户体验并减少了获取相关答案所需的时间。总之，本文介绍了 RAG 流程和 LLM 的新应用，并得到了精心准备的大学基准的支持，为学术数据检索的高级 AI 技术提供了宝贵的见解，并为该领域的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.06237</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KeyB2：选择关键块对于使用大型语言模型进行长文档排名也很重要</title>
      <link>https://arxiv.org/abs/2411.06254</link>
      <description><![CDATA[arXiv:2411.06254v1 公告类型：新
摘要：像 Llama 这样的大型语言模型 (LLM) 的快速发展显著推动了信息检索 (IR) 系统的发展。然而，由于计算复杂性（尤其是输入标记长度），将 LLM 用于长文档（如 RankLLaMA）仍然具有挑战性。此外，LLM 在排名过程中的内部机制仍未完全了解。在本文中，我们首先探索 LLM 在相关性判断过程中的内部工作原理，并确定特定的注意力头在对齐相关标记方面起着至关重要的作用。这一观察启发我们重新审视 KeyB 中使用的块预排名策略，该策略在 TREC 2019 DL 文档排名数据集上仍然是最先进的 (SOTA)。基于这些见解，我们开发了 KeyB2，这是一种先进的长文档 IR 方法，将块预排名与 LLM 的性能相结合。 KeyB2 可高效识别和处理最相关的块，从而降低计算成本并提高排名效率。此外，我们为 KeyB2 引入了一种新的双编码器块匹配策略。在 TREC 2019 DL、Robust04 和 MLDR-zh 等长文档数据集上进行的全面实验表明，KeyB2 通过减少重新排序时间和 GPU 内存使用量，同时增强检索性能，优于 RankLLaMA 和 KeyB 等基线，在 TREC 2019 DL 上取得了新的 SOTA 结果，NDCG@10 和 MAP 分数更高。]]></description>
      <guid>https://arxiv.org/abs/2411.06254</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注释索引</title>
      <link>https://arxiv.org/abs/2411.06256</link>
      <description><![CDATA[arXiv:2411.06256v1 公告类型：新
摘要：本文介绍了注释索引，这是一种统一和概括传统倒排索引、列存储、对象存储和图形数据库的新框架。因此，注释索引可以为支持知识图、实体检索、半结构化数据和排名检索的数据库提供底层索引框架。虽然我们主要关注文本形式的人类语言数据，但注释索引足够通用，可以支持一系列其他数据类型，并且我们提供了对包含数字和日期的 JSON 存储的类似 SQL 的查询示例。利用注释索引的灵活性，我们还演示了一个完全动态的注释索引，该索引结合了对具有数百个并发读取器和写入器的事务的 ACID 属性的支持。]]></description>
      <guid>https://arxiv.org/abs/2411.06256</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标签推荐的度量学习：解决数据稀疏性和冷启动问题</title>
      <link>https://arxiv.org/abs/2411.06374</link>
      <description><![CDATA[arXiv:2411.06374v1 Announce Type: new 
摘要：随着数字信息的快速增长，个性化推荐系统已经成为互联网服务中不可或缺的一部分，尤其是在电子商务、社交媒体和在线娱乐等领域。然而，传统的协同过滤和基于内容的推荐方法在处理数据稀疏性和冷启动问题方面存在局限性，特别是面对大规模异构数据时，很难满足用户的期望。本文提出了一种基于度量学习的新型标签推荐算法，旨在通过学习有效的距离或相似性度量来捕捉用户偏好和物品特征之间的细微差异，以克服传统推荐系统的挑战。实验结果表明，该算法在多个评估指标上优于包括局部响应度量学习（LRML）、协同度量学习（CML）和基于对抗学习的自适应张量分解（ATF）在内的基线方法。特别是在前几个推荐项目的准确率上表现尤为出色，同时保持了较高的鲁棒性并保持了较高的推荐准确率。]]></description>
      <guid>https://arxiv.org/abs/2411.06374</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能生成 Mixcode 流行歌曲：概念、计划和推测</title>
      <link>https://arxiv.org/abs/2411.06420</link>
      <description><![CDATA[arXiv:2411.06420v1 公告类型：新
摘要：音乐是一种强大的表达形式，可以传达、强调甚至创造个人或集体的情感。无论是从历史上还是在当代经验中，音乐表达都曾被普遍用于社会、政治和/或经济目的。生成人工智能为音乐及其在社会中的作用提供了丰富的机遇和挑战。本文讨论了一个将人工智能与流行音乐相结合的拟议项目，其最终目标是创建一个强大的工具，用于将音乐用于社会转型、教育、医疗保健和情感健康。鉴于它是在计算机科学家/数据分析师和民族音乐学家/社会人类学家合作之初提出的。它主要是概念性的，在本质上有些推测性。]]></description>
      <guid>https://arxiv.org/abs/2411.06420</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过显著区域和加权特征删除提高对抗样本的目标可转移性</title>
      <link>https://arxiv.org/abs/2411.06784</link>
      <description><![CDATA[arXiv:2411.06784v1 公告类型：新
摘要：深度神经网络容易受到对抗性示例的攻击，这对实际应用构成重大风险。对抗性攻击的一种普遍方法依赖于对抗性示例的可迁移性，这些示例由替代模型生成并用于攻击未知的黑盒模型。尽管有各种旨在提高可迁移性的提议，但这些攻击在有针对性的黑盒场景中的成功往往受到对抗性示例过度拟合替代模型的趋势的阻碍。在本文中，我们介绍了一种基于显著区域和加权特征删除 (SWFD) 的新框架，旨在增强对抗性示例的有针对性的可迁移性。根据可迁移性较高的示例在深层输出中表现出更平滑的分布的观察结果，我们提出了加权特征删除机制，根据按范数分布缩放的权重来调节激活值，从而有效地解决了生成对抗性示例时的过度拟合问题。此外，通过利用图像中的显著区域来构建辅助图像，我们的方法能够以与模型无关的方式将对抗性示例的特征迁移到目标类别，从而增强可迁移性。全面的实验证实，我们的方法在各种配置中都优于最先进的方法。平均而言，提出的 SWFD 分别将正常训练模型和稳健模型的攻击成功率提高了 16.31% 和 7.06%。]]></description>
      <guid>https://arxiv.org/abs/2411.06784</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 辅助相关性评估：我们何时应该向 LLM 寻求帮助？</title>
      <link>https://arxiv.org/abs/2411.06877</link>
      <description><![CDATA[arXiv:2411.06877v1 公告类型：新
摘要：测试集是信息检索工具，可让研究人员快速轻松地评估排名算法。虽然测试集已成为 IR 研究不可或缺的一部分，但数据创建过程需要大量手动注释工作，这通常会使其非常昂贵且耗时。因此，当预算有限时，测试集可能会变小，这可能会导致评估不稳定。作为一种替代方案，最近的研究提出了使用大型语言模型 (LLM) 完全取代人类评估员。然而，虽然 LLM 似乎与人类判断有某种相关性，但它们并不完美，而且经常表现出偏见。此外，即使在一个数据集上找到了表现良好的 LLM 或提示，也不能保证它在实践中的表现会相似，因为任务和数据不同。因此，完全用 LLM 替换被认为风险太大，不完全可信。
因此，在本文中，我们提出了 \textbf{L}LM-\textbf{A}ssisted \textbf{R}elevance \textbf{A}ssessments (\textbf{LARA})，这是一种平衡手动注释和 LLM 注释的有效方法，有助于制作丰富可靠的测试集。我们使用 LLM 的预测相关性概率来选择在预算约束下最有利可图的文档进行手动注释。虽然仅依靠 LLM 的预测概率进行手动注释的效果相当好，但通过理论推理，LARA 可以通过在线校准学习更有效地指导人工注释过程。然后，使用从有限的手动注释中学习到的校准模型，LARA 消除 LLM 预测的偏差以注释剩余的未评估数据。对 TREC-COVID 和 TREC-8 Ad Hoc 数据集的实证评估表明，在几乎任何预算约束下，LARA 都优于替代解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.06877</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Invar-RAG：不变的 LLM 对齐检索，以实现更好的生成</title>
      <link>https://arxiv.org/abs/2411.07021</link>
      <description><![CDATA[arXiv:2411.07021v1 公告类型：新
摘要：检索增强生成 (RAG) 在提供可靠的答案预测和解决幻觉问题方面表现出色。典型的 RAG 实现使用强大的检索模型来提取外部信息，并使用大型语言模型 (LLM) 来生成答案。相比之下，最近基于 LLM 的检索因其在信息检索 (IR) 方面的显著改进而受到关注，这要归功于 LLM 的语义理解能力。然而，将 LLM 直接应用于 RAG 系统存在挑战。这可能会导致特征局部性问题，因为大量的参数知识会阻碍整个语料库中全局信息的有效使用；例如，基于 LLM 的检索器通常输入文档摘要而不是完整文档。此外，LLM 中的各种预训练任务会引入方差，进一步削弱检索器的性能。
为了解决这些问题，我们提出了一种名为 Invar-RAG 的新型两阶段微调架构。在检索阶段，通过集成基于 LoRA 的表示学习来构建基于 LLM 的检索器，以解决特征局部性问题。为了提高检索性能，我们开发了两种模式（不变模式和变体模式）和一个不变性损失来减少 LLM 方差。在生成阶段，采用改进的微调方法来提高 LLM 根据检索到的信息生成答案的准确性。实验结果表明，Invar-RAG 在三个开放域问答 (ODQA) 数据集上的表现明显优于现有基线。代码可在补充材料中获取，以供重现。]]></description>
      <guid>https://arxiv.org/abs/2411.07021</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型识别和分解膳食计划中的复合成分</title>
      <link>https://arxiv.org/abs/2411.05892</link>
      <description><![CDATA[arXiv:2411.05892v1 公告类型：交叉 
摘要：本研究探讨了大型语言模型在膳食计划中的有效性，重点关注其识别和分解复合成分的能力。我们评估了三种模型 - GPT-4o、Llama-3 (70b) 和 Mixtral (8x7b) - 以评估它们识别和分解复杂成分组合的能力。初步结果表明，虽然 Llama-3 (70b) 和 GPT-4o 在准确分解方面表现出色，但所有模型在识别调味料和油等必需元素方面都遇到了困难。尽管整体性能强劲，但不同模型的准确性和完整性存在差异。这些发现强调了 LLM 增强个性化营养的潜力，但也强调了进一步改进成分分解的必要性。未来的研究应该解决这些局限性，以改善营养建议和健康结果。]]></description>
      <guid>https://arxiv.org/abs/2411.05892</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BERTrend：用于新兴趋势检测的神经主题建模</title>
      <link>https://arxiv.org/abs/2411.05930</link>
      <description><![CDATA[arXiv:2411.05930v1 公告类型：交叉 
摘要：检测和跟踪大型不断发展的文本语料库中的新兴趋势和弱信号对于监测科学文献、管理品牌声誉、监视关键基础设施以及更普遍的任何类型的基于文本的事件检测等应用至关重要。现有的解决方案通常无法捕捉细微的上下文或动态跟踪随时间演变的模式。BERTrend 是一种新方法，它使用在线环境中的神经主题建模来解决这些限制。它引入了一种新的指标，通过考虑文档数量和更新频率来量化主题随时间推移的流行度。该指标将主题分类为噪声、弱信号或强信号，标记新兴、快速增长的主题以供进一步研究。在两个大型真实数据集上进行的实验证明了 BERTrend 能够准确检测和跟踪有意义的弱信号，同时滤除噪声，为监测大规模不断发展的文本语料库中的新兴趋势提供了全面的解决方案。该方法还可用于对过去事件的回顾性分析。此外，大型语言模型与 BERTrend 的使用为事件趋势的可解释性提供了有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.05930</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不同特征选择方法对使用 XGBoost 创建的模型的影响</title>
      <link>https://arxiv.org/abs/2411.05937</link>
      <description><![CDATA[arXiv:2411.05937v1 公告类型：交叉 
摘要：本研究考察了不同的特征选择方法对使用 XGBoost（一种具有出色正则化方法的流行机器学习算法）创建的模型的影响。结果表明，三种不同的特征降维方法不会对模型的预测精度产生统计上的显著变化。这表明，传统的去除噪声训练数据以确保模型不会过度拟合的想法可能不适用于 XGBoost。但为了降低计算复杂度，这种方法可能仍然可行。]]></description>
      <guid>https://arxiv.org/abs/2411.05937</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GuidelineGuard：遵循指南的医疗记录评估代理框架</title>
      <link>https://arxiv.org/abs/2411.06264</link>
      <description><![CDATA[arXiv:2411.06264v1 公告类型：交叉 
摘要：尽管大型语言模型 (LLM) 的快速发展促进了基于人工智能的应用程序和服务在医疗保健领域的整合，但有限的研究集中在对医疗记录的系统评估以遵守指南。本文介绍了 GuidelineGuard，这是一个由 LLM 驱动的代理框架，可以自主分析医疗记录，例如出院记录和门诊记录，以确保遵守既定的医疗保健指南。通过识别与推荐做法的偏差并提供基于证据的建议，GuidelineGuard 可帮助临床医生遵守 WHO 和 CDC 等组织的最新标准。该框架提供了一种提高文档质量和减少临床错误的新方法。]]></description>
      <guid>https://arxiv.org/abs/2411.06264</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>