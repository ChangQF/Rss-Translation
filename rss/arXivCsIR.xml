<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>https://rss.arxiv.org/rss</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 13 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>作为顺序决策的检索增强思维过程</title>
      <link>https://arxiv.org/abs/2402.07812</link>
      <description><![CDATA[大型语言模型（LLM）已经证明了其强大的帮助人们的能力并展现出“智慧的火花”。然而，一些公开的挑战阻碍了它们的更广泛应用：例如对隐私的担忧、产生幻觉的倾向以及处理长上下文的困难。在这项工作中，我们通过引入检索增强思维过程（RATP）来应对这些挑战。在获得外部知识的情况下，RATP 将法学硕士的思想生成制定为多步骤决策过程。为了优化这样的思维过程，RATP 利用蒙特卡罗树搜索，并学习 Q 值估计器，以实现经济高效的推理。在解决使用私人数据进行问答的任务时，道德和安全问题限制了 LLM 培训方法，RATP 比现有的上下文检索增强语言模型实现了 50% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2402.07812</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>基于检索增强生成的大语言模型中的即时扰动</title>
      <link>https://arxiv.org/abs/2402.07179</link>
      <description><![CDATA[随着大型语言模型 (LLM) 在广泛领域的使用迅速增长，其稳健性变得越来越重要。检索增强生成（RAG）被认为是提高法学硕士文本生成可信度的一种手段。然而，基于 RAG 的法学硕士的输出如何受到略有不同的输入的影响尚未得到充分研究。在这项工作中，我们发现即使在提示中插入一个短前缀也会导致生成的输出远离实际正确的答案。我们通过引入一种称为梯度引导提示扰动（GGPP）的新颖优化技术来系统地评估此类前缀对 RAG 的影响。 GGPP 在将基于 RAG 的 LLM 的输出引导到有针对性的错误答案方面取得了很高的成功率。它还可以处理提示中要求忽略不相关上下文的指令。我们还利用有和没有 GGPP 扰动的提示之间的 LLM 神经元激活差异，给出了一种方法，通过对 GGPP 生成的提示触发的神经元激活进行训练的高效检测器来提高基于 RAG 的 LLM 的鲁棒性。我们对开源法学硕士的评估证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2402.07179</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>AraSpider：阿拉伯语到 SQL 的民主化</title>
      <link>https://arxiv.org/abs/2402.07448</link>
      <description><![CDATA[这项研究提出了 AraSpider，这是 Spider 数据集的第一个阿拉伯语版本，旨在改进阿拉伯语社区的自然语言处理 (NLP)。测试了四种多语言翻译模型在将英语翻译为阿拉伯语方面的有效性。此外，还评估了两个模型从阿拉伯文本生成 SQL 查询的能力。结果表明，使用反向翻译显着提高了 ChatGPT 3.5 和 SQLCoder 模型的性能，这些模型被认为是 Spider 数据集上表现最好的模型。值得注意的是，ChatGPT 3.5 展示了高质量的翻译，而 SQLCoder 在文本到 SQL 任务方面表现出色。该研究强调了结合上下文模式和采用反向翻译策略来增强阿拉伯语 NLP 任务中模型性能的重要性。此外，提供详细的数据集再现性和翻译成其他语言的方法凸显了该研究致力于促进该领域的透明度和协作知识共享。总体而言，这些贡献推进了 NLP 研究，增强了阿拉伯语研究人员的能力，并丰富了关于语言理解和数据库查询的全球讨论。]]></description>
      <guid>https://arxiv.org/abs/2402.07448</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>LiRank：LinkedIn 的工业大规模排名模型</title>
      <link>https://arxiv.org/abs/2402.06859</link>
      <description><![CDATA[我们推出了 LiRank，这是 LinkedIn 的一个大型排名框架，它为生产带来了最先进的建模架构和优化方法。我们推出了多项建模改进，包括 Residual DCN，它为著名的 DCNv2 架构添加了注意力和残差连接。我们分享有关组合和调整 SOTA 架构以创建统一模型的见解，包括密集门控、变压器和残差 DCN。我们还提出了新颖的校准技术，并描述了我们如何生产基于深度学习的探索/利用方法。为了实现大型排名模型的有效、生产级服务，我们详细介绍了如何使用量化和词汇压缩来训练和压缩模型。我们提供有关 Feed 排名、职位推荐和广告点击率 (CTR) 预测等大规模用例的部署设置的详细信息。我们通过阐明最有效的技术方法来总结从各种 A/B 测试中学到的知识。这些想法为 LinkedIn 的相关指标全面改进做出了贡献：Feed 中的会员会话增加了 0.5%，职位搜索和推荐的合格工作申请增加了 1.76%，广告点击率增加了 4.3%。我们希望这项工作能够为有兴趣利用大规模深度排名系统的从业者提供实用的见解和解决方案。]]></description>
      <guid>https://arxiv.org/abs/2402.06859</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>通过 LLM 认知数据增强推广会话密集检索</title>
      <link>https://arxiv.org/abs/2402.07092</link>
      <description><![CDATA[会话搜索利用多轮自然语言上下文来检索相关段落。现有的会话密集检索模型大多将会话视为固定的问题和响应序列，忽视了严重的数据稀疏问题——即用户可以通过多种方式进行会话，而这些交替的会话是未记录的。因此，他们常常很难概括现实场景中的不同对话。在这项工作中，我们提出了一个通过 LLM 认知数据增强 (ConvAug) 泛化会话密集检索的框架。 ConvAug 首先生成多级增强对话，以捕获对话上下文的多样性。受人类认知的启发，我们设计了一种认知感知过程来减少误报、漏报和幻觉的产生。此外，我们开发了一种难度自适应样本过滤器，可以为复杂的对话选择具有挑战性的样本，从而为模型提供更大的学习空间。然后采用对比学习目标来训练更好的会话上下文编码器。在正常和零样本设置下对四个公共数据集进行的广泛实验证明了 ConvAug 的有效性、普遍性和适用性。]]></description>
      <guid>https://arxiv.org/abs/2402.07092</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>从大型语言模型中定量知识检索</title>
      <link>https://arxiv.org/abs/2402.07770</link>
      <description><![CDATA[大型语言模型 (LLM) 因其生成令人信服的自然语言序列的能力而受到广泛研究，但其在定量信息检索方面的效用却鲜为人知。在本文中，我们探讨了法学硕士作为定量知识检索机制的可行性，以帮助完成贝叶斯模型先验分布和缺失数据插补等数据分析任务。我们提出了一个及时的工程框架，将法学硕士视为科学文献潜在空间的接口，将不同背景和领域的响应与更成熟的方法进行比较。讨论了使用法学硕士作为“专家”的含义和挑战。]]></description>
      <guid>https://arxiv.org/abs/2402.07770</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>MDGNN：用于全面动态股票投资预测的多关系动态图神经网络</title>
      <link>https://arxiv.org/abs/2402.06633</link>
      <description><![CDATA[股票市场是金融体系的重要组成部分，但由于经济指标、财务报告、全球新闻和投资者情绪等各方面之间存在动态且复杂的关系，预测股票价格的变动具有挑战性。传统的序列方法和基于图的模型已应用于股票走势预测，但它们在捕捉股票价格走势的多方面和时间影响方面存在局限性。为了应对这些挑战，提出了多关系动态图神经网络（MDGNN）框架，该框架利用离散动态图来全面捕获股票之间的多方面关系及其随时间的演变。从图表生成的表示提供了股票和关联实体之间相互关系的完整视角。此外，利用 Transformer 结构的强大功能对多重关系的时间演化进行编码，为预测股票投资提供动态且有效的方法。此外，与最先进的（SOTA）股票投资方法相比，我们提出的 MDGNN 框架在公共数据集中实现了最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2402.06633</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>GRILLBot 实践：为适应性强的会话任务助手部署大型语言模型的经验教训和权衡</title>
      <link>https://arxiv.org/abs/2402.07647</link>
      <description><![CDATA[我们应对为复杂的现实任务构建现实世界多模式助手的挑战。我们描述了开发和部署 GRILLBot 的实用性和挑战，GRILLBot 是 Alexa 奖 TaskBot 挑战赛中部署的领先系统（分别于 2022 年和 2023 年获得一等奖和二等奖）。在我们的开放助手工具包 (OAT) 框架的基础上，我们提出了一种混合架构，该架构利用大型语言模型 (LLM) 和针对需要极低延迟的特定子任务进行调整的专用模型。 OAT 使我们能够以结构化和可部署的方式定义何时、如何以及哪些 LLM 被使用。对于基于知识的问答和实时任务适应，我们表明法学硕士对任务上下文和世界知识的推理能力超过了延迟问题。对于对话状态管理，我们实施了一种代码生成方法，并表明专门的较小模型具有 84% 的有效性，延迟降低了 100 倍。总体而言，我们在 Alexa TaskBot 挑战赛中提供了见解并讨论了在复杂的现实世界多模式环境中向用户部署传统模型和 LLM 的权衡。随着法学硕士变得更加有能力和高效，这些经验将继续发展——从根本上重塑 OAT 和未来的助理架构。]]></description>
      <guid>https://arxiv.org/abs/2402.07647</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>偏序图卷积网络的多行为协同过滤</title>
      <link>https://arxiv.org/abs/2402.07659</link>
      <description><![CDATA[在单个图协同过滤（CF）向量中表示多种行为的信息一直是一个长期存在的挑战。这是因为不同的行为自然地形成单独的行为图并学习单独的 CF 嵌入。现有模型通过指定某些行为的 CF 嵌入作为主要嵌入并利用其他辅助来增强主要嵌入来合并单独的嵌入。然而，这种方法通常会导致联合嵌入在主要任务上表现良好，但在辅助任务上表现不佳。为了解决单独的行为图产生的问题，我们提出了偏序图（POG）的概念。 POG 定义了多个行为的偏序关系，并将行为组合建模为加权边，以将单独的行为图合并为联合 POG。理论证明证明 POG 可以推广到任何给定的多种行为集。基于 POG，我们提出了定制的偏序图卷积网络（POGCN），该网络在考虑用户和项目之间的行为关系的同时对邻居信息进行卷积。 POGCN还引入了偏序BPR采样策略，用于高效且有效的多行为CF训练。 POGCN已在阿里巴巴首页成功部署两个月，为超十亿用户提供推荐服务。在三个公共基准数据集上进行的广泛离线实验表明，POGCN 在所有类型的行为中都优于最先进的多行为基线。此外，在线A/B测试证实了POGCN在十亿级推荐系统中的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.07659</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>用于图像建议的多模态学习稀疏检索</title>
      <link>https://arxiv.org/abs/2402.07736</link>
      <description><![CDATA[学习稀疏检索 (LSR) 是一组神经方法，旨在将查询和文档编码为稀疏词汇向量。可以使用倒排索引有效地索引和检索这些向量。虽然 LSR 在文本检索方面显示出前景，但其在多模态检索方面的潜力在很大程度上仍未得到开发。受此启发，在这项工作中，我们探索了LSR在多模态领域的应用，即我们重点关注多模态学习稀疏检索（MLSR）。我们使用多种 MLSR 模型配置进行实验，并评估图像建议任务的性能。我们发现仅根据图像内容解决任务具有挑战性。用标题丰富图像内容可以显着提高模型性能，这意味着图像标题对于提供细粒度概念和图像上下文信息的重要性。我们的方法为在多模态环境中训练 LSR 检索模型提供了实用且有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2402.07736</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 LoCo 和 M2-BERT 进行基准测试并构建长上下文检索模型</title>
      <link>https://arxiv.org/abs/2402.07440</link>
      <description><![CDATA[检索管道（许多机器学习系统的一个组成部分）在文档较长（例如 10K 标记或更多）以及识别相关文档需要合成整个文本信息的领域中表现不佳。开发适合这些领域的长上下文检索编码器提出了三个挑战：（1）如何评估长上下文检索性能，（2）如何预训练基本语言模型来表示短上下文（对应于查询）和长上下文（对应于文档），以及（3）如何在 GPU 内存限制所施加的批量大小限制下微调该模型以进行检索。为了应对这些挑战，我们首先引入 LoCoV1，这是一种新颖的 12 任务基准，旨在测量分块不可能或无效的长上下文检索。接下来我们介绍 M2-BERT 检索编码器，这是一种基于 Monarch Mixer 架构构建的 80M 参数状态空间编码器模型，能够扩展到长达 32K 令牌的文档。我们描述了一种预训练数据混合，它允许该编码器处理短上下文序列和长上下文序列，以及一种微调方法，该方法使该基本模型适应仅使用单样本批次进行检索。最后，我们在 LoCoV1 上验证了 M2-BERT 检索编码器，发现尽管包含的参数少了 5-90 倍，但它的性能比竞争基线高出 23.3 个点。]]></description>
      <guid>https://arxiv.org/abs/2402.07440</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>VCR：上下文检索的视频表示</title>
      <link>https://arxiv.org/abs/2402.07466</link>
      <description><![CDATA[简化媒体档案中的内容发现需要集成先进的数据表示和有效的可视化技术，以便向用户清晰地传达视频主题。所提出的系统通过利用视觉、音频和文本特征的融合，通过基于文本的方法准确索引和分类视频内容，解决了有效导航大型视频集合的挑战。此外，语义嵌入用于向用户提供上下文相关的信息和建议，从而使用 OpenAI GPT-4 对我们的主题本体图提供直观且引人入胜的探索体验。]]></description>
      <guid>https://arxiv.org/abs/2402.07466</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>通过对比预训练增强多领域B2B云解决方案匹配</title>
      <link>https://arxiv.org/abs/2402.07076</link>
      <description><![CDATA[云解决方案在技术行业中广受欢迎，因为它们提供了解决特定问题的服务和工具组合。然而，尽管它们被广泛使用，但为解决方案提供商的销售团队确定特定目标解决方案的合适公司客户的任务仍然是现有匹配系统尚未充分解决的复杂业务问题。在这项工作中，我们研究了 B2B 解决方案匹配问题，并确定了该场景的两个主要挑战：（1）复杂多字段特征的建模；（2）有限、不完整且稀疏的交易数据。为了应对这些挑战，我们提出了一个框架 CAMA，该框架以分层多字段匹配结构为骨干，并辅以三种数据增强策略和对比预训练目标，以补偿可用数据的缺陷。通过对真实世界数据集的大量实验，我们证明 CAMA 的性能显着优于几种强大的基线匹配模型。此外，我们将我们的匹配框架部署在华为云的系统上。我们观察发现，相比之前的线上模式，转化率（CVR）提升了30%左右，可见其巨大的商业价值。]]></description>
      <guid>https://arxiv.org/abs/2402.07076</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>利用个人知名度消除推荐偏差</title>
      <link>https://arxiv.org/abs/2402.07425</link>
      <description><![CDATA[全球流行度（GP）偏差是指流行商品被推荐的频率远远高于应有的推荐频率的现象，这违背了提供个性化推荐的目标，损害了用户体验和推荐准确性。人们已经提出了许多方法来减少 GP 偏差，但它们没有注意到 GP 的根本问题，即它从 \textit{所有用户} 的 \textit{global} 角度考虑流行度并使用一组流行的项目，并且从而无法捕获个人用户的兴趣。因此，我们提出了一个名为 \textit{个人流行度} (PP) 的项目流行度的用户感知版本，它通过考虑具有相似兴趣的用户来识别每个用户的不同流行项目。由于 PP 对个人用户的偏好进行建模，它自然有助于生成个性化推荐并减轻 GP 偏见。为了将 PP 集成到推荐中，我们设计了一个通用的 \textit{个人流行度感知反事实} (PPAC) 框架，它可以轻松适应现有的推荐模型。特别是，PPAC 认识到 PP 和 GP 对推荐有直接和间接影响，并通过反事实推理技术控制直接影响，以实现无偏见的推荐。所有代码和数据集均可在 \url{https://github.com/Stevenn9981/PPAC} 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.07425</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>用于重排序推荐的非自回归生成模型</title>
      <link>https://arxiv.org/abs/2402.06871</link>
      <description><![CDATA[在多阶段推荐系统中，重排序通过对项目之间的列表内相关性进行建模而发挥着至关重要的作用。重排序的关键挑战在于探索排列组合空间内的最佳序列。最近的研究提出了一种生成器评估器学习范式，其中生成器生成多个可行序列，评估器根据估计的列表分数挑选出最佳序列。生成器至关重要，生成模型非常适合生成器功能。当前的生成模型采用自回归策略来生成序列。然而，在实时工业系统中部署自回归模型具有挑战性。因此，我们提出了一种用于重新排名推荐的非自回归生成模型（NAR4Rec），旨在提高效率和有效性。为了解决与稀疏训练样本和影响模型收敛的动态候选相关的挑战，我们引入了匹配模型。考虑到用户反馈的多样性，我们提出了序列级似然性训练目标来区分可行序列和不可行序列。此外，为了克服关于目标项目的非自回归模型中缺乏依赖性建模的问题，我们引入对比解码来捕获这些项目之间的相关性。对公开数据集进行的广泛离线实验验证了我们提出的方法与现有最先进的重新排名方法相比的优越性能。此外，我们的方法已在日活跃用户超过3亿的流行视频应用快手中得到全面部署，显着提高了在线推荐质量，并证明了我们方法的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2402.06871</guid>
      <pubDate>Tue, 13 Feb 2024 06:18:12 GMT</pubDate>
    </item>
    </channel>
</rss>