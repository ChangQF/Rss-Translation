<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 08 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>文本挖掘 arXiv：定量金融论文概览</title>
      <link>https://arxiv.org/abs/2401.01751</link>
      <description><![CDATA[arXiv:2401.01751v2 公告类型：replace-cross
摘要：本文探讨了 arXiv 预印本服务器上托管的文章，旨在揭示隐藏在大量研究中的有价值的见解。我们采用文本挖掘技术并通过自然语言处理方法的应用，检查了 1997 年至 2022 年发表在 arXiv 上的量化金融论文的内容。我们从整个文档（包括参考文献）中提取和分析关键信息，以了解主题趋势随着时间的推移，找出该领域被引用最多的研究人员和期刊。此外，我们还比较了多种执行主题建模的算法，包括最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2401.01751</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>计算机化自适应测试调查：机器学习的视角</title>
      <link>https://arxiv.org/abs/2404.00712</link>
      <description><![CDATA[arXiv:2404.00712v2 公告类型：replace-cross
摘要：计算机自适应测试（CAT）通过根据考生的表现动态调整试题，提供了一种有效且量身定制的方法来评估考生的熟练程度。 CAT 广泛应用于教育、医疗保健、体育和社会学等不同领域，彻底改变了测试实践。虽然传统方法依赖于心理测量学和统计学，但大规模测试的日益复杂性刺激了机器学习技术的集成。本文旨在提供一项以机器学习为中心的 CAT 调查，为这种自适应测试方法提供了新的视角。通过检查作为 CAT 适应性核心的测试问题选择算法，我们阐明了其功能。此外，我们深入研究了 CAT 中的认知诊断模型、题库构建和测试控制，探索机器学习如何优化这些组件。通过对当前方法、优势、局限性和挑战的分析，我们努力开发强大、公平和高效的 CAT 系统。通过将心理测量驱动的 CAT 研究与机器学习联系起来，这项调查倡导对自适应测试的未来采取更具包容性和跨学科的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.00712</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>BanglaAutoKG：使用语义神经图过滤自动构建孟加拉知识图</title>
      <link>https://arxiv.org/abs/2404.03528</link>
      <description><![CDATA[arXiv:2404.03528v2 公告类型：replace-cross
摘要：知识图（KG）已被证明在信息处理和推理应用中至关重要，因为它们链接相关实体并提供丰富的上下文信息，支持高效的信息检索和知识发现；以非常有效的方式呈现信息流。尽管孟加拉语在全球范围内得到广泛使用，但由于缺乏全面的数据集、编码器、NER（命名实体识别）模型、POS（词性）标注器和词形还原器，孟加拉语在知识图谱中的代表性相对不足，阻碍了高效的信息处理和推理应用在语言中。为了解决孟加拉语知识图谱的稀缺问题，我们提出了 BanglaAutoKG，这是一个开创性的框架，能够从任何孟加拉语文本自动构建孟加拉语知识图谱。我们利用多语言法学硕士来理解各种语言并普遍关联实体和关系。通过使用翻译词典来识别英语对等词并从预训练的 BERT 模型中提取单词特征，我们构建了基础知识图谱。为了减少噪音并使词嵌入与我们的目标保持一致，我们采用基于图的多项式滤波器。最后，我们实现了一个基于 GNN 的语义过滤器，它提高了上下文理解并修剪了不必要的边缘，最终形成了明确的知识图谱。实证研究结果和案例研究证明了我们的模型的普遍有效性，能够从任何文本自主构建语义丰富的知识图谱。]]></description>
      <guid>https://arxiv.org/abs/2404.03528</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为预言机，用于使用特定领域的知识实例化本体</title>
      <link>https://arxiv.org/abs/2404.04108</link>
      <description><![CDATA[arXiv:2404.04108v1 公告类型：交叉
摘要：背景。为智能系统赋予语义数据通常需要使用特定领域的知识来设计和实例化本体。特别是在早期阶段，这些活动通常由人类专家手动执行，可能会利用他们自己的经验。因此，最终的过程非常耗时、容易出错，并且常常受到本体设计者个人背景的影响。客观的。为了缓解这个问题，我们提出了一种新颖的独立于领域的方法，通过利用大型语言模型（LLM）作为预言机，自动实例化具有特定领域知识的本体。方法。从（i）由相互关联的类和属性组成的初始模式和（ii）一组查询模板开始，我们的方法多次查询LLM，并从其回复中生成类和属性的实例。因此，本体会自动填充特定领域的知识，符合初始模式。结果，本体快速、自动地丰富了多种实例，专家可以根据自己的需要和专业知识考虑保留、调整、丢弃或补充这些实例。贡献。我们以一般方式形式化我们的方法，并在各种法学硕士以及具体案例研究中实例化它。我们报告植根于营养领域的实验，其中食品膳食及其成分的本体论是从膳食及其关系的分类开始从头开始半自动实例化的。在那里，我们分析生成的本体的质量，并比较通过利用不同的法学硕士获得的本体。最后，我们对所提出的方法进行了 SWOT 分析。]]></description>
      <guid>https://arxiv.org/abs/2404.04108</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>RAT：用于点击率预测的检索增强变压器</title>
      <link>https://arxiv.org/abs/2404.02249</link>
      <description><![CDATA[arXiv:2404.02249v2 公告类型：替换
摘要：预测点击率 (CTR) 是 Web 应用程序的一项基本任务，其中的关键问题是设计有效的功能交互模型。当前的方法主要集中于对单个样本内的特征交互进行建模，而忽略了可以作为增强预测的参考上下文的潜在跨样本关系。为了弥补这一缺陷，本文开发了一种检索增强变压器（RAT），旨在获取样本内和样本间的细粒度特征交互。通过检索相似的样本，我们为每个目标样本构建增强输入。然后，我们构建具有级联注意力的 Transformer 层，以捕获样本内和样本间特征交互，促进综合推理以改进 CTR 预测，同时保持效率。对真实世界数据集的大量实验证实了 RAT 的有效性，并表明了其在长尾场景中的优势。代码已开源于\url{https://github.com/YushenLi807/WWW24-RAT}。]]></description>
      <guid>https://arxiv.org/abs/2404.02249</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>广义彩虹差分隐私</title>
      <link>https://arxiv.org/abs/2309.05871</link>
      <description><![CDATA[arXiv:2309.05871v2 公告类型：replace-cross
摘要：我们研究了一种通过随机图着色设计差分隐私（DP）机制的新框架，称为彩虹差分隐私。在这个框架中，数据集是图中的节点，两个相邻的数据集通过边连接。图中的每个数据集对于机制的可能输出都有一个优先排序，这些排序称为彩虹。不同的彩虹将连接数据集的图划分为不同的区域。我们证明，如果这些区域边界处的 DP 机制是固定的，并且它对于所有相同彩虹边界数据集的行为相同，则存在唯一的最优 $(\epsilon,\delta)$-DP 机制（只要边界条件有效）并且可以用封闭形式表示。我们的证明技术基于优势排序和 DP 之间的有趣关系，该关系适用于任何有限数量的颜色和 $(\epsilon,\delta)$-DP，改进了之前仅适用于最多三种颜色的结果，并且对于$\epsilon$-DP。我们通过给出非齐次边界条件的例子来证明齐次边界条件假设的合理性，对于非齐次边界条件不存在最优的动态规划机制。]]></description>
      <guid>https://arxiv.org/abs/2309.05871</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>生成 IR 评估方法的比较</title>
      <link>https://arxiv.org/abs/2404.04044</link>
      <description><![CDATA[arXiv:2404.04044v1 公告类型：新
摘要：信息检索系统越来越多地包含生成组件。例如，在检索增强生成（RAG）系统中，检索组件可能提供基本事实来源，而生成组件则总结并增强其响应。在其他系统中，大型语言模型 (LLM) 可能会直接生成响应，而无需咨询检索组件。虽然生成信息检索（Gen-IR）系统有多种定义，但在本文中，我们重点关注那些系统响应不是从固定的文档或段落集合中提取的系统。对查询的响应可能永远不会是全新的文本。由于传统的 IR 评估方法在此模型下崩溃，我们探索了将传统离线评估方法扩展到 Gen-IR 环境的各种方法。离线 IR 评估传统上采用付费人工评估员，但越来越多的法学硕士正在取代人工评估，展示出与众包标签相似或优于众包标签的能力。鉴于 Gen-IR 系统不会从固定的集合中生成响应，我们假设 Gen-IR 评估方法必须在很大程度上依赖于 LLM 生成的标签。除了基于二元和分级相关性的方法之外，我们还探索基于显式子主题、成对偏好和嵌入的方法。我们首先根据几个 TREC Deep Learning Track 任务的人类评估来验证这些方法；然后我们应用这些方法来评估几个纯生成系统的输出。对于每种方法，我们都考虑其自主行动的能力（无需人工标签或其他输入）以及支持人工审核的能力。要信任这些方法，我们必须确信它们的结果与人类评估一致。为此，评估标准必须透明，以便评估人员可以对结果进行审核。]]></description>
      <guid>https://arxiv.org/abs/2404.04044</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>从头开始：语言模型如何嵌入长文档进行密集检索</title>
      <link>https://arxiv.org/abs/2404.04163</link>
      <description><![CDATA[arXiv:2404.04163v1 公告类型：新
摘要：本研究调查了基于 Transformer 的文本表示学习模型中是否存在位置偏差，特别是在网络文档检索的背景下。我们以先前的研究为基础，证明因果语言模型的输入序列中间存在信息丢失，并将其扩展到表示学习领域。我们检查编码器-解码器模型训练各个阶段的位置偏差，包括语言模型预训练、对比预训练和对比微调。对 MS-MARCO 文档集的实验表明，经过对比预训练后，模型已经生成了嵌入，可以更好地捕获输入的早期内容，而微调会进一步加剧这种影响。]]></description>
      <guid>https://arxiv.org/abs/2404.04163</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>研究反事实学习对模型排序的鲁棒性：可重复性研究</title>
      <link>https://arxiv.org/abs/2404.03707</link>
      <description><![CDATA[arXiv:2404.03707v1 公告类型：交叉
摘要：反事实排名学习（CLTR）因其利用大量记录的用户交互数据来训练排名模型的能力而引起了 IR 社区的广泛关注。虽然当用户行为假设正确且倾向估计准确时，CLTR 模型在理论上可以是无偏的，但由于缺乏广泛可用的、大规模的真实点击日志，它们的有效性通常是通过基于模拟的实验来凭经验评估的。然而，主流的基于模拟的实验有一定的局限性，因为它们通常具有单一的、确定性的生产排名器和简化的用户模拟模型来生成合成点击日志。因此，CLTR 模型在复杂多样的情况下的鲁棒性很大程度上未知，需要进一步研究。
  为了解决这个问题，在本文中，我们旨在通过广泛的基于模拟的实验来研究现有 CLTR 模型在再现性研究中的稳健性，这些实验（1）同时使用确定性和随机生产排序器，每个排序器具有不同的排序性能，并且（2 ）利用具有不同用户行为假设的多个用户模拟模型。我们发现，与具有离线倾向估计的 IPS-PBM 和 PRS 相比，DLA 模型和 IPS-DCM 在各种模拟设置下表现出更好的鲁棒性。此外，当生产排名器具有相对较高的排名性能或一定的随机性时，现有的 CLTR 模型通常无法超越朴素点击基线，这表明迫切需要开发适用于这些设置的新 CLTR 算法。]]></description>
      <guid>https://arxiv.org/abs/2404.03707</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>GenQREnsemble：零样本 LLM 集成提示生成查询重构</title>
      <link>https://arxiv.org/abs/2404.03746</link>
      <description><![CDATA[arXiv:2404.03746v1 公告类型：新
摘要：查询重构（QR）是一组用于将用户的原始搜索查询转换为更符合用户意图并改善搜索体验的文本的技术。最近，零样本 QR 已被证明是一种有前途的方法，因为它能够利用大型语言模型中固有的知识。通过从使许多任务受益的集成提示策略的成功中汲取灵感，我们研究了它们是否可以帮助改进查询重构。在这种情况下，我们提出了一种基于集成的提示技术 GenQREnsemble，它利用零样本指令的释义来生成多组关键字，最终提高检索性能。我们进一步介绍其检索后变体 GenQREnsembleRF 以合并伪相关反馈。在对四个 IR 基准的评估中，我们发现 GenQREnsemble 生成了更好的重构，与之前的零样本最先进技术相比，相对 nDCG@10 改进高达 18%，MAP 改进高达 24%。在 MSMarco Passage Ranking 任务中，GenQREnsembleRF 使用伪相关反馈显示了 5% MRR 的相对增益，使用相关反馈文档显示了 9% nDCG@10 的相对增益。]]></description>
      <guid>https://arxiv.org/abs/2404.03746</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>了解推荐系统中的语言建模范式适应：经验教训和开放挑战</title>
      <link>https://arxiv.org/abs/2404.03788</link>
      <description><![CDATA[arXiv:2404.03788v1 公告类型：新
摘要：大型语言模型（LLM）的出现在自然语言处理领域取得了巨大的成功，因为多样化的训练范式使 LLM 能够有效地捕获复杂的语言模式和语义表示。特别是，最近的“预训练、提示和预测”训练范式作为一种利用有限标记数据学习可推广模型的方法引起了极大的关注。随着这一进步，这些训练范例最近已适应推荐领域，并被学术界和工业界视为一个有前途的方向。这个为期半天的教程旨在提供对从通过不同训练范式学习的预训练模型中提取和转移知识的透彻理解，以从通用性、稀疏性、有效性和可信性等各个角度改进推荐系统。在本教程中，我们首先介绍用于推荐目的的语言建模范例的基本概念和通用架构。然后，我们重点关注针对不同推荐任务调整 LLM 相关培训策略和优化目标的最新进展。之后，我们将系统地介绍基于法学硕士的推荐系统中的道德问题，并讨论评估和缓解这些问题的可能方法。我们还将总结相关数据集、评估指标以及对训练范式的推荐性能的实证研究。最后，我们将通过讨论开放挑战和未来方向来结束本教程。]]></description>
      <guid>https://arxiv.org/abs/2404.03788</guid>
      <pubDate>Mon, 08 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    </channel>
</rss>