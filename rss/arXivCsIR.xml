<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Mon, 17 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>变分贝叶斯个性化排名</title>
      <link>https://arxiv.org/abs/2503.11067</link>
      <description><![CDATA[ARXIV：2503.11067V1公告类型：新 
摘要：建议系统发现了各种领域的广泛应用。但是，可用的培训数据通常包括隐式反馈，表现为用户点击和购买行为，而不是对用户偏好的明确声明。这种类型的培训数据提出了准确排名预测的三个主要挑战：首先，用户偏好的不可观察的性质使可能性函数固有地建模。其次，由此产生的假阳性（FP）和虚假负面因素（FN）将噪声引入学习过程中，从而破坏了参数学习。第三，由于观察到的相互作用倾向于集中于一些流行项目，因此数据偏差会加剧受欢迎程度偏见的反馈回路。为了解决这些问题，我们提出了一个新颖且易于实现的学习目标，它集成了以增强协作过滤的关键组成部分：似然优化，降低降噪和普及性偏见。我们的方法涉及分解Elbo-KL框架下的成对损失，并得出其变异下限，以建立可管理的学习目标以进行近似推断。在这个结合中，我们引入了一种基于注意力的潜在兴趣原型对比机制，以取代实例级对比度学习，以有效地减少有问题的样本中的噪声。推导兴趣原型的过程隐含地结合了一种灵活的硬采矿策略，能够同时识别硬阳性和硬性阴性样品。此外，我们证明了这种硬样品挖掘策略促进了特征分布均匀性，从而减轻了受欢迎程度的偏见。从经验上讲，我们证明了变异BPR在流行的骨干推荐模型上的有效性。代码和数据可在以下网址找到：https：//github.com/liubin06/variationalbpr]]></description>
      <guid>https://arxiv.org/abs/2503.11067</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决信息丢失和互动崩溃：双重增强的注意力互动框架</title>
      <link>https://arxiv.org/abs/2503.11233</link>
      <description><![CDATA[ARXIV：2503.11233V1公告类型：新 
摘要：变压器已被证明是用于CTR预测的特征交互的重要方法，在以前的工作中取得了巨大的成功。但是，它在处理特征交互作用方面也带来了潜在的挑战。首先，在捕获特征交互时，变压器可能会遇到信息丢失。通过依靠内部产品来表示成对关系，它们会压缩原始的相互作用信息，从而导致保真度的退化。其次，由于长尾特征分布，具有较低信息的嵌入的特征字段限制了其他字段的信息丰度，从而导致嵌入矩阵崩溃。为了解决这些问题，我们提出了一个双重注意框架，以增强功能相互作用，称为双重注意力。该框架整合了两个注意机制：组合ID注意机制和避免崩溃的注意机制。组合注意机制直接保留特征相互作用对减轻信息丢失，而避免散发的注意机制则可以使较低的信息丰度相互作用对滤出较低的滤波，以防止相互作用崩溃。在工业数据集上进行的广泛实验表明了双重注意力的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.11233</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过命题内容提取改善破布检索：语音行动理论方法</title>
      <link>https://arxiv.org/abs/2503.10654</link>
      <description><![CDATA[ARXIV：2503.10654V1公告类型：交叉 
摘要：当用户提出查询时，它们通常不仅包括他们寻求的信息，还包括务实的标记，例如疑问措辞或礼貌请求。尽管这些语音ACT指标传达了用户\ texQuotesingle的意图 - 无论是在问一个问题，提出请求还是说明事实 - 它们并不一定会添加到查询本身的核心信息内容中。本文研究了从用户话语中提取潜在的命题内容（本质上是剥夺了意图的标志）是否可以提高检索功能增强生成（RAG）系统的检索质量。利用语音行为理论的基本见解，我们提出了一种实用方法，可以在嵌入之前自动将查询转换为其命题等效物。为了评估这种方法的功效，我们进行了一项实验研究，涉及与巴西电信新闻语料库有关的63个用户查询，并具有预先计算的语义嵌入。结果表明，查询嵌入和文档嵌入在最高等级之间的语义相似性方面有明显的改善，证实剥离了语音ACT指标的查询更有效地检索了相关内容。]]></description>
      <guid>https://arxiv.org/abs/2503.10654</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>订购文本数据的语义多样性采样</title>
      <link>https://arxiv.org/abs/2503.10698</link>
      <description><![CDATA[ARXIV：2503.10698V1公告类型：交叉 
摘要：多样性采样的目的是以最大化子集中包含的信息的方式选择一个代表性的数据子集，同时保持其基数较小。我们根据一个新的度量标准介绍了有序的多样采样问题，该指标衡量了有序的样品列表中的多样性。我们提出了一种新的方法，用于生成有序的不同样本，以用于使用嵌入向量上的主要成分的文本数据。提出的方法很简单，并与使用新指标的现有方法进行了比较。我们将标准文本分类基准转换为基准，以进行有序的采样。我们的经验评估表明，普遍的方法的效果比我们的方法差6％至61％，同时效率更高。消融研究表明，新方法的各个部分如何促进整体指标。]]></description>
      <guid>https://arxiv.org/abs/2503.10698</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>索赔表：抹布系统的传播信任评分</title>
      <link>https://arxiv.org/abs/2503.10702</link>
      <description><![CDATA[ARXIV：2503.10702V1公告类型：交叉 
摘要：迅速采用检索功能的生成（RAG）系统已彻底改变了大规模的内容生成，但也强调了确保在检索信息中值得信赖的挑战。本文介绍了SuperTrust，这是一个基于传播的信任评分框架，该框架可以动态评估抹布系统中文档的可靠性。使用经过修改的Pagerank启发算法，索赔确实根据从提取的事实索赔中得出的关系来传播文档的信任分数。我们从Kaggle的假新闻检测数据集中进行预处理和分析814条政治新闻文章，以提取2,173个独特的主张，并对965个有意义的关系（支持或矛盾）进行分类。通过将数据集表示为文档图，索赔信托迭代会更新信任分数，直到收敛，从而有效地将可信赖的文章与不可靠的文章区分开来。我们的方法（利用基于嵌入的过滤）进行有效的索赔比较和关系分类，在维持计算可伸缩性的同时，达到了重大连接的11.2％。实验结果表明，索赔保持成功地将更高的信任分数分配给经过验证的文档，同时惩罚包含虚假信息的文档。未来的方向包括微调的索赔提取和比较（Li等，2022），参数优化，增强的语言模型利用以及可靠的评估指标，以跨越各种数据集和域的框架概括。]]></description>
      <guid>https://arxiv.org/abs/2503.10702</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过协作行为信号协调大型语言模型以进行会话建议</title>
      <link>https://arxiv.org/abs/2503.10703</link>
      <description><![CDATA[ARXIV：2503.10703V1公告类型：交叉 
摘要：会话推荐框架已成为一种动态范式，以通过交互式对话提供个性化建议。先进的语言理解技术的结合已大大提高了此类系统的对话流利度。但是，尽管现代语言模型在解释通过自然对话阐明的用户偏好方面表现出良好的熟练程度，但它们经常在有效利用集体行为模式的情况下遇到挑战，这是生成相关建议的关键要素。为了减轻这种限制，这项工作提出了一个新颖的概率框架，该框架通过潜在的偏好建模与对话互动协同行为模式。所提出的方法建立了双通道对准机制，其中隐式偏好表示从集体用户互动中学到的是行为数据和语言表达式之间的连接机制。具体而言，该框架首先通过既定的协作过滤技术来得出潜在的偏好表示，然后采用这些表示形式通过自适应融合过程共同完善语言偏好表达式和行为模式。与各种最新基线方法相比，多个基准数据集的全面评估证明了所提出的方法的出色性能，尤其是在使对话互动与协作行为信号相结合时。]]></description>
      <guid>https://arxiv.org/abs/2503.10703</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RankPo：对工作匹配的优先优化</title>
      <link>https://arxiv.org/abs/2503.10723</link>
      <description><![CDATA[ARXIV：2503.10723V1公告类型：交叉 
摘要：匹配工作描述（JDS）具有合适的人才需要的模型不仅能够理解JDS和候选人简历之间的文本相似性，还可以理解诸如地理位置和学术资历之类的上下文因素。为了应对这一挑战，我们为大型语言模型（LLMS）提出了一个两阶段的培训框架。在第一阶段，使用一种对比性学习方法来训练模型上，该模型是根据现实世界匹配规则（例如地理一致性和研究领域重叠）构建的数据集。虽然有效，但该模型主要学习由匹配规则定义的模式。在第二阶段，我们引入了一种受直接偏好优化（DPO）启发的新型基于偏好的微调方法，称为“等级”偏好优化（RANKPO），以将模型与AI策划的成对偏好相结合，强调文本理解。我们的实验表明，尽管第一阶段模型在基于规则的数据（NDCG@20 = 0.706）上实现了强大的性能，但它缺乏强大的文本理解（与AI Annotations的对齐= 0.46）。通过对RankPo进行微调，我们实现了一个平衡的模型，该模型在原始任务中保持相对良好的性能，同时显着改善了AI偏好的对齐方式。代码和数据可从https://github.com/yflyzhang/rankpo获得。]]></description>
      <guid>https://arxiv.org/abs/2503.10723</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稀有节肢动物的分类推理：将密集的图像字幕和抹布结合在一起，以解释分类</title>
      <link>https://arxiv.org/abs/2503.10886</link>
      <description><![CDATA[Arxiv：2503.1086V1公告类型：交叉 
摘要：在紧迫气候变化挑战和节肢动物之间的显着生物多样性丧失的背景下，来自有机图像的自动分类分类是一项激烈研究的主题。但是，基于CNN或VITS等深层神经视觉架构的传统AI管道面临限制，例如在长尾上的长尾表现降低，并且无法推理其预测。我们将图像字幕和检索型发电（RAG）与大语言模型（LLMS）集成在一起，以增强生物多样性监测，从而表征了稀有和未知的节肢动物物种的特殊希望。虽然天真的视觉模型（VLM）在分类公共物种的图像方面表现出色，但抹布模型通过将分类特征的明确文本描述与外部来源的上下文生物多样性文本数据匹配，从而可以对稀有分类单元进行分类。抹布模型显示出相对于Naive LLM的过度自信和增强精度的希望，这表明其在捕获分类层次结构的细微差别方面的生存能力，尤其是在具有挑战性的家庭和属水平上。我们的发现突出了现代视觉语言AI管道支持生物多样性保护计划的潜力，强调了全面数据策划和与公民科学平台的合作的作用，以改善物种识别，不知名的物种表征以及最终信息保护策略。]]></description>
      <guid>https://arxiv.org/abs/2503.10886</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>空间摊位：用于现实世界空间推理问题的空间检索增强产生</title>
      <link>https://arxiv.org/abs/2502.18470</link>
      <description><![CDATA[Arxiv：2502.18470V3公告类型：替换 
摘要：空间推理仍然是大型语言模型（LLMS）的挑战，该模型在空间数据检索和推理方面遇到了困难。我们建议通过整合稀疏的空间检索（空间数据库）和密集的语义检索（基于LLM的相似性），将空间检索增强的生成（空间抹布）扩展到空间任务。多目标排名策略平衡了空间约束和语义相关性，而LLM引导的发电机可确保连贯的响应。现实世界中的旅游数据集的实验表明，空间抹布显着改善了空间问题的回答，从而弥合了LLMS和空间智能之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2502.18470</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概率扰动差异：一种可调节的同型同轴计，用于比较重尾分配</title>
      <link>https://arxiv.org/abs/2008.13078</link>
      <description><![CDATA[ARXIV：2008.13078V3公告类型：替换 - 交叉 
摘要：现实世界中的复杂系统通常包括许多不同类型的元素以及元素之间更多类型的网络交互。当可以很好地测量类型的相对丰度时，我们经常观察到类型频率的重分类分布。为了比较两个系统的类型频率分布或与自身在不同时间点上的系统（同异轴学方面的一个方面）可用的概率差异。在这里，我们介绍和探索“概率扰动差异”，这是一种可调，直接，可解释的仪器，用于比较可进行正常的分类频率分布。我们在等级扰动差异（RTD）之后对概率扰动差异（PTD）进行建模。虽然概率扰动差异在应用方面的差异比等级扰动差异更为有限，但它对类型频率的变化更为敏感。我们构建同种异体仪以显示概率湍流，并结合了一种视觉上适应“独家类型”的零概率的方法，这些概率仅在一个系统中出现。我们探讨了从文献，社交媒体和生态学中获得的示例分布的比较。我们展示了概率扰动差异是如何明确或功能概括了许多现有种类的距离和度量，包括特殊情况，包括$ l^{（p）} $ norms，s {\ o} rensen-dice系数（$ f_ {1} $统计）和hellinger距离。我们讨论了与R {\&#39;e} Nyi和Tsallis的广义熵以及生态学的多样性指数（或山丘数）的相似之处。我们对关于优化等级和概率扰动差异的优化的开放问题的想法结束了。]]></description>
      <guid>https://arxiv.org/abs/2008.13078</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CSA：单峰特征到多模式特征的数据有效映射</title>
      <link>https://arxiv.org/abs/2410.07610</link>
      <description><![CDATA[ARXIV：2410.07610V4公告类型：替换 - 交叉 
摘要：多模式编码器，例如clip excel，例如零拍图像分类和跨模式检索。但是，它们需要过多的培训数据。我们提出了规范相似性分析（CSA），该分析使用两个单峰编码器使用有限的数据来复制多模式编码器。 CSA使用新的相似性分数将单峰特征映射到多模式空间中，仅保留多模式信息。 CSA仅涉及单峰编码器和立方复合矩阵分解的推论，从而消除了对广泛基于GPU的模型训练的需求。实验表明，CSA的表现优于剪辑，同时需要$ 50,000 \ times $ $更少的多模式数据对，以弥合给定对Imagenet分类和错误信息新闻字幕检测的预先训练的单峰编码器的模态。 CSA超过了最先进的方法，可以将单峰特征映射到多模式特征。我们还展示了CSA具有图像和文本超出图像和文本的模式的能力，为将来的模态配对铺平了道路，并配对了配对的多模式数据，但丰富的未配对单峰数据（例如LiDAR和文本）。]]></description>
      <guid>https://arxiv.org/abs/2410.07610</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绿洲：改进的代码搜索的订单提升策略</title>
      <link>https://arxiv.org/abs/2503.08161</link>
      <description><![CDATA[ARXIV：2503.08161V3公告类型：替换 - 交叉 
摘要：代码嵌入式捕获代码的语义表示，对于各种与代码相关的大语言模型（LLM）应用程序（例如代码搜索）至关重要。以前的培训主要依赖于通过比较积极的自然语言（NL）编码对与内部负面负面物质来优化Infonce损失。但是，由于代码环境的稀疏性质，仅通过比较正面和负面对之间的主要差异而无法捕获更深层的语义细微差别。为了解决这个问题，我们提出了一种新颖的订单提升策略，以改善代码搜索（OASIS）。它利用基于订单的相似性标签来训练模型，以捕获负对之间相似性的细微差异。广泛的基准评估表明，我们的OASIS模型显着优于以前仅着眼于主要正面差异的先前最先进的模型。它强调了用订单标签在负面对之间利用微妙差异的价值，以进行有效的代码嵌入培训。]]></description>
      <guid>https://arxiv.org/abs/2503.08161</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>质量超过数量？基于LLM的策展，用于数据有效的Audio-Video基础模型</title>
      <link>https://arxiv.org/abs/2503.09205</link>
      <description><![CDATA[ARXIV：2503.09205V2公告类型：替换 - 交叉 
摘要：整合训练多模式基础模型的音频和视觉数据仍然具有挑战性。我们提出了音频视频矢量对齐（AVVA），该矢量对齐（AVVA）通过大型语言模型（LLM）的数据策划管道使视听场景（AV）场景内容对象超出单纯的时间同步。具体而言，AVVA使用耳语（基于语音的音频基础模型）在双重编码对比度学习框架中为视频评分并选择高质量的培训剪辑。对听觉的评估，英勇和VGGSOUND表明，这种方法可以通过策划的数据大大降低准确性提高。例如，与ImageBind相比，AVVA在VGGSOUND上的音频到视频检索的TOP-1准确性提高了7.6％，尽管仅训练了192个小时的精心过滤数据（vs. 5800小时）。此外，一项消融研究强调，将数据数量用于数据质量可以提高性能，从而在录音机，英勇和VGGSOUND上，相应的前3精度提高47.8、48.4和58.0个百分点，而不是未繁殖的碱基。尽管这些结果强调了AVVA的数据效率，但我们也讨论了LLM驱动的策展的开销，以及如何在较大域中缩放或近似它。总体而言，AVVA提供了一种可行的途径，通往更健壮，无文本的视听学习，并提高了检索精度。]]></description>
      <guid>https://arxiv.org/abs/2503.09205</guid>
      <pubDate>Mon, 17 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>