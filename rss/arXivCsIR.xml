<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 04 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>广告中的中间人偏见：将关键词推荐与搜索的相关性结合起来</title>
      <link>https://arxiv.org/abs/2502.00131</link>
      <description><![CDATA[arXiv:2502.00131v1 公告类型：新
摘要：根据电子商务卖家的库存，推荐他们使用关键词来增加买家参与度（点击/销售）。关键词必须与商品相关；否则，可能会导致卖家不满意和定位不佳——为此，我们使用了相关性过滤器。在这项工作中，我们描述了在有偏见的点击/销售信号上训练相关性过滤模型的缺点。我们将广告商关键词相关性重新概念化为两个动态系统之间的相互作用——广告产生关键词，搜索充当接触买家的中间人。我们讨论了搜索相关性系统的偏见（中间人偏见）以及将广告商关键词与搜索相关性信号对齐的必要性。我们还比较了交叉编码器和双编码器在建模这种对齐方面的性能，以及这种解决方案对 eBay 卖家的可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2502.00131</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIM：面向用户行为建模的多模态内容兴趣建模范式</title>
      <link>https://arxiv.org/abs/2502.00321</link>
      <description><![CDATA[arXiv:2502.00321v1 公告类型：新 
摘要：点击率 (CTR) 预测是推荐系统、在线搜索和广告平台中的一项关键任务，准确捕捉用户对内容的真正兴趣对于性能至关重要。然而，现有的方法严重依赖 ID 嵌入，而 ID 嵌入无法反映用户对图像和标题等内容的真实偏好。这种限制在冷启动和长尾场景中尤为明显，传统方法难以提供有效的结果。为了应对这些挑战，我们提出了一种新颖的多模态内容兴趣建模范式 (MIM)，它由三个关键阶段组成：预训练、内容兴趣感知监督微调 (C-SFT) 和内容兴趣感知 UBM (CiUBM)。预训练阶段将基础模型适应特定领域的数据，从而能够提取高质量的多模态嵌入。 C-SFT 阶段通过利用用户行为信号来引导嵌入与用户偏好的对齐，从而弥合内容与用户兴趣之间的语义鸿沟。最后，CiUBM 阶段将多模态嵌入和基于 ID 的协同过滤信号集成到一个统一的框架中。在全球最大的电子商务平台之一淘宝上进行的全面离线实验和在线 A/B 测试证明了 MIM 方法的有效性和效率。该方法已成功部署在线，CTR 显着提升了 +14.14%，RPM 显着提升了 +4.12%，展示了其工业适用性和对平台性能的实质性影响。为了促进进一步的研究，我们已在 https://pan.quark.cn/s/8fc8ec3e74f3 公开发布了代码和数据集。]]></description>
      <guid>https://arxiv.org/abs/2502.00321</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健推荐系统的个性化去噪隐式反馈</title>
      <link>https://arxiv.org/abs/2502.00348</link>
      <description><![CDATA[arXiv:2502.00348v1 公告类型：新 
摘要：虽然隐式反馈是现代推荐系统的基础，但人为错误、不确定性和用户行为模糊性等因素不可避免地会给这种反馈带来显著的噪音，从而对推荐的准确性和稳健性产生不利影响。为了解决这个问题，现有的方法通常旨在减少嘈杂反馈的训练权重或完全丢弃它，这是基于这样的观察：嘈杂的交互通常在整体损失分布中表现出更高的损失。然而，我们发现了两个关键问题：(1) 在整体损失分布中，正常和嘈杂的交互之间存在显著的重叠，(2) 当从逐点损失函数（例如，BCE 损失）过渡到成对损失函数（例如，BPR 损失）时，这种重叠变得更加明显。这种重叠导致传统方法将嘈杂的交互错误地归类为正常，反之亦然。为了应对这些挑战，我们进一步研究了损失重叠，发现对于给定用户，在用户的个人损失分布中，正常交互和噪声交互之间存在明显区别。基于这一洞察，我们提出了一种使用用户个人损失分布进行去噪的重采样策略，称为 PLD，它降低了优化噪声交互的概率。具体来说，在每次优化迭代期间，我们为每个用户创建一个候选项目池，并根据用户的个人损失分布从该池中重新采样项目，优先考虑正常交互。此外，我们进行了理论分析以验证 PLD 的有效性并提出了进一步提高其性能的方法。在三个具有不同噪声比的数据集上进行的大量实验证明了 PLD 的有效性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2502.00348</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>撤回引文和撤回出版物中的自我引文：剽窃和虚假同行评审的比较研究</title>
      <link>https://arxiv.org/abs/2502.00673</link>
      <description><![CDATA[arXiv:2502.00673v1 公告类型：新
摘要：撤回引文仍然是学术界关注的重大问题，因为它们虽然无效，但仍会传播错误信息并损害科学文献的完整性。为了分析撤回引文的影响，我们重点关注两种撤回类别：剽窃和虚假同行评审。数据集来自 Scopus，并使用 Retraction Watch 数据库绘制撤回原因。撤回趋势显示剽窃案件的平均增长率稳定在 1.2 倍，而虚假同行评审则呈现波动模式，平均增长率为 5.5 倍。虽然与虚假同行评审相比，剽窃类论文撤回的论文较少，但剽窃类论文的引用量却是虚假同行评审论文的 2.5 倍。此外，剽窃论文的撤回引文总数是虚假同行评审论文的 1.8 倍。在抄袭类别中，46% 的撤回引文是由于抄袭，而在虚假同行评审类别中，53.6% 的撤回引文归因于虚假同行评审。结果还表明，虚假同行评审案件的识别和撤回速度比抄袭案件更快。最后，自我引用在撤回论文的引文中所占比例很小，但在这两个类别中后来被撤回的引文中所占比例明显较高。]]></description>
      <guid>https://arxiv.org/abs/2502.00673</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RankFlow：利用大型语言模型的多角色协作重新排序工作流程</title>
      <link>https://arxiv.org/abs/2502.00709</link>
      <description><![CDATA[arXiv:2502.00709v2 公告类型：新
摘要：在信息检索 (IR) 系统中，重新排序通过根据候选段落与特定查询的相关性对其进行排序起着至关重要的作用。此过程需要对与查询相关的段落之间的差异有细致的了解。在这项工作中，我们引入了 RankFlow，这是一种多角色重新排序工作流程，它利用大型语言模型 (LLM) 和角色专业化的功能来提高重新排序性能。RankFlow 招募 LLM 来履行四个不同的角色：查询重写器、伪回答者、段落摘要器和重新排序器。这种精心设计的方法使 RankFlow 能够：(1) 准确解释查询，(2) 利用 LLM 广泛的预先存在的知识，(3) 将段落提炼为简洁的版本，以及 (4) 以全面的方式评估段落，从而获得明显更好的重新排序结果。我们的实验结果表明，RankFlow 在广受认可的 IR 基准测试（例如 TREC-DL、BEIR 和 NovelEval）上的表现优于现有的领先方法。此外，我们还研究了 RankFlow 中每个角色的单独贡献。代码可在 https://github.com/jincan333/RankFlow 上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.00709</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GFM-RAG：检索增强生成的图形基础模型</title>
      <link>https://arxiv.org/abs/2502.01113</link>
      <description><![CDATA[arXiv:2502.01113v1 公告类型：新
摘要：检索增强生成 (RAG) 已被证明可有效将知识集成到大型语言模型 (LLM) 中。然而，传统的 RAG 难以捕捉知识之间的复杂关系，限制了它们在需要整合来自多个来源的知识的复杂推理中的表现。最近，图形增强检索增强生成 (GraphRAG) 构建图形结构来明确模拟这些关系，从而实现更有效、更高效的检索器。然而，其性能仍然受到图形结构中的噪声和不完整性的阻碍。为了解决这个问题，我们引入了 GFM-RAG，一种用于检索增强生成的新型图形基础模型 (GFM)。GFM-RAG 由创新的图形神经网络提供支持，该网络通过图形结构进行推理以捕获复杂的查询知识关系。具有 8M 个参数的 GFM 在大型数据集上经历了两阶段训练过程，包括 60 个知识图谱，其中包含超过 14M 个三元组和 700k 个文档。这为 GFM-RAG 带来了令人印象深刻的性能和通用性，使其成为第一个适用于未见数据集的图基础模型，无需进行任何微调即可进行检索。在三个多跳 QA 数据集和七个特定领域的 RAG 数据集上进行的大量实验表明，GFM-RAG 实现了最先进的性能，同时保持了效率并与神经缩放定律保持一致，凸显了其进一步改进的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.01113</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 进行增强知识图谱查询</title>
      <link>https://arxiv.org/abs/2502.01298</link>
      <description><![CDATA[arXiv:2502.01298v1 公告类型：新
摘要：采用知识图谱 (KG) 作为结构化、面向语义的数据表示模型，显著提高了跨不同领域的数据集成、推理和查询能力。这在工业 5.0 等现代场景中尤其如此，在这些场景中，人类、智能设备和生产流程产生的数据的集成起着至关重要的作用。然而，由于技术复杂性，使用形式化查询语言管理、检索和可视化 KG 中的数据对于非专家用户来说可能很困难，从而限制了它们在工业环境中的使用。为此，我们引入了 SparqLLM，这是一个利用检索增强生成 (RAG) 解决方案的框架，以增强对知识图谱 (KG) 的查询。SparqLLM 执行提取、转换和加载 (ETL) 管道以从原始数据构建 KG。它还具有由大型语言模型 (LLM) 提供支持的自然语言界面，可实现自动 SPARQL 查询生成。通过将基于模板的方法集成为 LLM 的检索上下文，SparqLLM 可提高查询可靠性并减少语义错误，从而确保更准确、更高效的 KG 交互。此外，为了提高可用性，该系统集成了一个动态可视化仪表板，该仪表板可适应检索数据的结构，以直观的格式呈现查询结果。严格的实验评估表明，SparqLLM 实现了高查询准确性、更高的鲁棒性以及与 KG 的用户友好交互，使其成为访问语义数据的可扩展解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.01298</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VideoRAG：利用超长上下文视频进行检索增强生成</title>
      <link>https://arxiv.org/abs/2502.01549</link>
      <description><![CDATA[arXiv:2502.01549v1 公告类型：新 
摘要：检索增强生成 (RAG) 通过外部知识集成在增强大型语言模型 (LLM) 方面取得了显著成功，但其应用主要集中在文本内容上，而多模态视频知识的丰富领域则尚未得到探索。本文介绍了 VideoRAG，这是第一个专门为处理和理解极长上下文视频而设计的检索增强生成框架。我们的核心创新在于其双通道架构，无缝集成了 (i) 基于图的文本知识基础，用于捕获跨视频语义关系，以及 (ii) 多模态上下文编码，用于有效保留视觉特征。这种新颖的设计使 VideoRAG 能够通过构建跨越多个视频的精确知识图来处理无限长度的视频，同时通过专门的多模态检索范例保持语义依赖关系。通过对我们提出的 LongerVideos 基准进行全面的实证评估（包括 160 多个视频，总计 134 多个小时，涵盖讲座、纪录片和娱乐类别），VideoRAG 与现有的 RAG 替代方案和长视频理解方法相比表现出色。VideoRAG 实现的源代码和基准数据集可在以下网址公开获取：https://github.com/HKUDS/VideoRAG。]]></description>
      <guid>https://arxiv.org/abs/2502.01549</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在电子商务搜索中查询品牌实体链接</title>
      <link>https://arxiv.org/abs/2502.01555</link>
      <description><![CDATA[arXiv:2502.01555v1 公告类型：新
摘要：在这项工作中，我们解决了电子商务搜索查询的品牌实体链接问题。实体链接任务通过以下两种方式完成：i) 一个由实体提及检测和实体消歧组成的两阶段过程，或 ii) 一个端到端链接方法，根据输入文本直接获取目标实体。该任务提出了独特的挑战：查询非常短（平均 2.4 个单词），缺乏自然语言结构，并且必须处理大量独特品牌。我们提出了一种将命名实体识别与匹配相结合的两阶段方法，以及一种使用极端多类分类的新型端到端解决方案。我们通过离线基准和在线 A/B 测试的影响来验证我们的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.01555</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用函数调用查询数据库</title>
      <link>https://arxiv.org/abs/2502.00032</link>
      <description><![CDATA[arXiv:2502.00032v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的功能正在迅速提升，这在很大程度上要归功于它们与外部工具的集成。查询数据库是这些集成中最有效的方法之一，使 LLM 能够访问私有或不断更新的数据。虽然函数调用是将外部工具连接到 LLM 的最常用方法，但它作为一种工具在数据库查询中的应用尚未得到充分探索。我们提出了一种数据库查询的工具定义，它将访问数据与搜索查询、过滤器或两者的组合统一起来，以及使用聚合和 groupby 运算符转换结果。为了评估其有效性，我们对 8 个 LLM 进行了一项研究，涵盖 5 个模型系列。我们提出了一种新颖的管道，它采用 Gorilla LLM 框架来创建合成数据库模式和查询。我们主要使用预测和地面实况查询 API 的精确匹配来评估模型。在测试的模型中，Claude 3.5 Sonnet 以 74.3% 的精确匹配得分获得了最高的性能，其次是 GPT-4o mini（73.7%）和 GPT-4o（71.8%）。我们进一步按所使用的 API 组件和综合用例细分这些结果。我们发现 LLM 在利用布尔属性的运算符方面非常有效，但在文本属性过滤器方面却举步维艰。在各种用例中，我们发现 GPT-4o 等性能较高的模型取得了稳健的结果，但性能较低的模型在各种用例中的性能差异很大。我们还进行了消融研究，探索并行工具调用的影响、添加原理作为工具调用的参数、每个数据库集合使用单独的工具以及使用结构化输出的工具调用。我们的研究结果证明了使用函数调用使 LLM 能够查询数据库的有效性。我们已在 github.com/weaviate/gorilla 上开源了我们的实验代码和结果。]]></description>
      <guid>https://arxiv.org/abs/2502.00032</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向推荐系统 LLMs 游乐场 (RecSysLLMsP)：探索模拟社交网络中的极化和参与</title>
      <link>https://arxiv.org/abs/2502.00055</link>
      <description><![CDATA[arXiv:2502.00055v1 公告类型：交叉 
摘要：鉴于人工智能技术的飞速发展以及推荐系统有害影响的潜在升级，尽早模拟和评估这些影响至关重要。这样做有助于防止对社会和科技公司造成可能的损害。本文介绍了推荐系统 LLMs Playground (RecSysLLMsP)，这是一种利用大型语言模型 (LLM) 来探索不同内容推荐设置对社交网络中用户参与度和极化的影响的新型模拟框架。通过创建具有描述性、静态和动态属性的多样化 AI 代理 (AgentPrompts)，我们在三种场景中评估它们的自主行为：多元化、平衡和相似性。我们的研究结果表明，将内容与用户偏好相结合的相似性场景可以最大限度地提高参与度，同时可能产生回音室。相反，多元化场景促进了多样化的互动，但产生了混合的参与结果。我们的研究强调了在推荐系统设计中需要谨慎平衡，以提高用户满意度，同时缓解社会两极分化。它强调了将 LLM 纳入模拟环境的独特价值和挑战。RecSysLLMsP 的优势在于它能够计算两极分化效应，这对于评估社会影响和确定不同推荐系统设置的用户参与度至关重要。这一优势对于社交媒体公司开发和维护成功的商业模式至关重要。然而，这项研究的局限性在于准确模拟现实。未来的努力应该验证真实人类和 AgentPrompts 之间的行为相似性，并建立衡量两极分化分数的指标。]]></description>
      <guid>https://arxiv.org/abs/2502.00055</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DEUCE：冷启动主动学习的双重多样性增强和不确定性意识</title>
      <link>https://arxiv.org/abs/2502.00305</link>
      <description><![CDATA[arXiv:2502.00305v1 公告类型：交叉 
摘要：冷启动主动学习 (CSAL) 从未标记的数据集中选择有价值的实例进行手动注释。它以较低的注释成本为标签稀缺的文本分类提供高质量的数据。然而，现有的 CSAL 方法忽略了弱类和难以代表性的例子，导致学习有偏差。为了解决这些问题，本文提出了一种用于 CSAL 的新型双重多样性增强和不确定性感知 (DEUCE) 框架。具体来说，DEUCE 利用预训练语言模型 (PLM) 来有效地提取文本表示、类别预测和预测不确定性。然后，它构建了一个双邻域图 (DNG) 来结合文本多样性和类别多样性的信息，确保数据分布平衡。它进一步通过基于密度的聚类传播不确定性信息以选择难代表性实例。DEUCE 在通过双重多样性和信息量选择类别平衡和难代表性数据方面表现良好。在六个 NLP 数据集上的实验证明了 DEUCE 的优越性和效率。]]></description>
      <guid>https://arxiv.org/abs/2502.00305</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>猜猜这个谜语！检索增强生成的隐秘成员推断</title>
      <link>https://arxiv.org/abs/2502.00306</link>
      <description><![CDATA[arXiv:2502.00306v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 使大型语言模型 (LLM) 能够通过利用外部知识数据库而不改变模型参数来生成有根据的响应。虽然没有权重调整可以防止通过模型参数泄漏，但它引入了推理对手利用模型上下文中检索到的文档的风险。现有的成员推理和数据提取方法通常依赖于越狱或精心设计的非自然查询，这些查询可以通过 RAG 系统中常见的查询重写技术轻松检测或阻止。在这项工作中，我们提出了询问攻击 (IA)，这是一种针对 RAG 数据存储中文档的成员推理技术。通过制作只有在目标文档存在的情况下才可回答的自然文本查询，我们的方法仅使用 30 个查询即可成功推理，同时保持隐秘性；直接检测器识别现有方法中的对抗性提示的频率比我们的攻击生成的提示高出约 76 倍。我们观察到，与之前跨不同 RAG 配置的推理攻击相比，TPR@1%FPR 提高了 2 倍，同时每个文档推理的成本不到 0.02 美元。]]></description>
      <guid>https://arxiv.org/abs/2502.00306</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MODS：主持多位文档发言人总结文档集合中的有争议的查询</title>
      <link>https://arxiv.org/abs/2502.00322</link>
      <description><![CDATA[arXiv:2502.00322v1 公告类型：交叉 
摘要：以查询为中心的摘要 (QFS) 提供文档摘要以回答查询。过去的 QFS 工作假设查询只有一个答案，而忽略有争议的答案（法学院值得吗？）。我们引入了可辩论的 QFS (DQFS)，这是一项创建摘要的任务，该摘要通过具有对立观点的文档来回答有争议的查询；摘要必须全面涵盖所有来源并平衡观点，不偏袒任何一方。这些目标逃避了 LLM QFS 系统，该系统：1) 缺乏结构化的内容计划，无法指导 LLM 编写平衡的摘要，2) 使用相同的查询来检索文档中的上下文，无法涵盖每个文档内容的所有特定观点。为了克服这个问题，我们设计了 MODS，这是一个反映人类小组讨论的多 LLM 框架。MODS 将文档视为单独的 Speaker LLM，并有一个 Moderator LLM，它会挑选发言人来响应针对计划主题的定制查询。演讲者使用定制查询从他们的文档中检索相关上下文并提供观点，这些观点在丰富的大纲中进行跟踪，从而产生内容计划来指导最终摘要。在 ConflictingQA 上使用有争议的网络查询和 DebateQFS（我们从 Debatepedia 获得的辩论查询新数据集）进行的实验表明，基于新的引用指标，MODS 在主题段落覆盖率和平衡性方面比 SOTA 高出 38-59%。用户还发现 MODS 的摘要更易读且更平衡。]]></description>
      <guid>https://arxiv.org/abs/2502.00322</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 CAWAL 框架对大型门户网站进行预测建模和异常检测</title>
      <link>https://arxiv.org/abs/2502.00413</link>
      <description><![CDATA[arXiv:2502.00413v1 公告类型：交叉 
摘要：本研究提出了一种方法，该方法使用通过 CAWAL 框架收集的会话和页面浏览数据，通过专门的流程进行丰富，用于 Web 使用挖掘 (WUM) 应用程序中的高级预测建模和异常检测。传统的 WUM 方法通常依赖于 Web 服务器日志，这限制了数据的多样性和质量。CAWAL 框架将应用程序日志与 Web 分析相结合，创建了全面的会话和页面浏览数据集，提供了更详细的用户交互视图并有效地解决了这些限制。这种集成增强了数据多样性和质量，同时消除了传统 WUM 所需的预处理阶段，从而提高了流程效率。通过交叉集成会话和页面浏览数据创建的丰富数据集被应用于高级机器学习模型，例如梯度提升和随机森林，这些模型以捕获复杂模式和建模非线性关系的有效性而闻名。这些模型在预测用户行为方面实现了超过 92% 的准确率，并显着提高了异常检测能力。结果表明，该方法提供了有关用户行为和系统性能指标的详细见解，使其成为提高大型门户网站的效率、可靠性和可扩展性的可靠解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.00413</guid>
      <pubDate>Tue, 04 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>