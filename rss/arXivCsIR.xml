<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 27 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用二阶统计方法研究话语持续时间和语音内容对说话人识别的影响</title>
      <link>https://arxiv.org/abs/2402.16429</link>
      <description><![CDATA[arXiv:2402.16429v1 公告类型：新
摘要：二阶统计方法在受控录音条件下的自动说话人识别方面显示出非常好的结果。这些方法通常用于整个可用的语音材料。在本文中，我们研究了测试语音材料的内容对此类方法性能的影响，即在更具分析性的方法下。目标是研究这些方法使用的信息类型以及它在语音信号中的位置。液体和滑动在一起，元音，更具体地说是鼻元音和鼻辅音，被发现是特定于说话人的：由这些类别之一的大部分声学材料组成的 1 秒测试话语提供了比语音平衡测试更好的说话人识别结果即使在这两种情况下训练都完成了 15 秒的语音平衡语音。尽管如此，其他音素类别的结果从来都不是很差。这些结果往往表明，长期二阶统计捕获的与说话者相关的信息对于所有语音类别来说始终是共同的，并且测试材料的同质性可以提高估计的质量。]]></description>
      <guid>https://arxiv.org/abs/2402.16429</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>寻找发明人-作者：消除专利与科学出版物之间的作者同音异义</title>
      <link>https://arxiv.org/abs/2402.16440</link>
      <description><![CDATA[arXiv:2402.16440v1 公告类型：新
摘要：专利和科学论文提供了衡量科学技术产出的重要来源，可作为各种科学计量分析的基础。作者和发明人的姓名是进行这些分析的关键标识符，然而，这遇到了消歧问题。推而广之，识别同时也是学术作者的发明者是一个不小的挑战。我们提出了一种使用国际专利分类 (IPC) 和 IPCCAT API 来评估给定发明人的专利和论文摘要的相似程度的方法，以便匹配两种类型的文档。该方法是根据从国际 EPO 数据库 Espacenet 中提取的三个专利语料库开发并手动鉴定的。在 4679 项专利和 7720 名发明人中，我们有 2501 名作者。该算法以低于5%的错误率解决了一般的消歧问题。]]></description>
      <guid>https://arxiv.org/abs/2402.16440</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与基于图形会话的推荐相集成</title>
      <link>https://arxiv.org/abs/2402.16539</link>
      <description><![CDATA[arXiv:2402.16539v1 公告类型：新
摘要：随着大型语言模型（LLM）的快速发展，人们对在推荐系统上利用 LLM 的上下文理解能力进行了各种探索。虽然开创性策略主要将传统推荐任务转化为自然语言生成的挑战，但由于其特殊性，基于会话的推荐（SBR）领域的探索相对匮乏。 SBR 主要由图神经网络主导，该网络由于能够捕获相邻行为之间的隐式和显式关系而取得了许多成功的成果。图的结构性质与自然语言的本质形成鲜明对比，给法学硕士带来了巨大的适应差距。在本文中，我们引入了基于图形会话推荐的大型语言模型，名为 LLMGR，这是一个有效的框架，通过将 LLM 与用于 SBR 任务的图神经网络（GNN）和谐集成来弥补上述差距。这种集成旨在利用法学硕士在自然语言理解方面和 GNN 在关系数据处理方面的互补优势，从而形成更强大的基于会话的推荐系统，可以理解和推荐会话中的项目。此外，为了赋予LLM赋能SBR任务的能力，我们为辅助和主要指令调优任务设计了一系列提示。这些提示旨在帮助法学硕士理解图结构数据并将文本信息与节点对齐，有效地将细致入微的用户交互转换为法学硕士架构可以理解和使用的格式。对三个真实世界数据集的广泛实验表明，LLMGR 优于多个竞争基线，表明其在增强 SBR 任务方面的有效性及其作为未来探索研究方向的潜力。]]></description>
      <guid>https://arxiv.org/abs/2402.16539</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:31 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的置信度标定及其应用</title>
      <link>https://arxiv.org/abs/2402.16325</link>
      <description><![CDATA[arXiv:2402.16325v1 公告类型：新
摘要：尽管对推荐结果的置信度很重要，但与推荐的准确性相比，它在文献中却令人惊讶地被忽视了。在本论文中，我提出了一个推荐系统的模型校准框架，用于根据学习到的排名分数来估计推荐结果的准确置信度。此外，我随后介绍了推荐中置信度的两个实际应用：（1）通过将大教师模型的置信度作为额外的学习指导来训练小学生模型，（2）根据预期调整呈现项目的数量使用校准概率估计的用户效用。]]></description>
      <guid>https://arxiv.org/abs/2402.16325</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>协同过滤中新用户的深度评分诱导</title>
      <link>https://arxiv.org/abs/2402.16327</link>
      <description><![CDATA[arXiv:2402.16327v1 公告类型：新
摘要：最近的推荐系统开始使用评级启发，它要求新用户对一个小的种子项目集进行评级以推断他们的偏好，以提高初始推荐的质量。评级引发的关键挑战是选择最能推断新用户偏好的种子项目。本文提出了一种新颖的端到端深度学习框架用于评级启发（DRE），该框架一次选择所有种子项目，同时考虑非线性交互。为此，它首先定义分类分布以从整个项目集中采样种子项目，然后训练分类分布和神经重建网络，以根据采样种子项目的 CF 信息推断用户对剩余项目的偏好。通过端到端训练，学习分类分布以选择最具代表性的种子项，同时反映复杂的非线性交互。实验结果表明，DRE 通过准确推断新用户的偏好，在推荐质量方面优于最先进的方法，并且其种子项集比其他方法获得的种子项集更好地代表了潜在空间。]]></description>
      <guid>https://arxiv.org/abs/2402.16327</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>用于文本属性图表示学习的高频感知分层对比选择性编码</title>
      <link>https://arxiv.org/abs/2402.16240</link>
      <description><![CDATA[arXiv:2402.16240v1 公告类型：新
摘要：我们研究文本属性图（TAG）上的节点表示学习，其中节点与文本信息相关联。尽管最近关于图神经网络（GNN）和预训练语言模型（PLM）的研究已经分别展示了它们在编码网络和文本信号方面的能力，但很少有人关注这两种模型在标签上的微妙耦合。具体来说，现有的 GNN 很少以上下文方式对每个节点中的文本进行建模；由于其序列架构，现有的 PLM 很难应用于表征图结构。为了应对这些挑战，我们提出了 HASH-CODE，这是一种高频感知频谱分层对比选择性编码方法，它将 GNN 和 PLM 集成到一个统一的模型中。与之前直接在 PLM 上添加 GNN 层的“级联架构”不同，我们的 HASH-CODE 依赖于五个自我监督的优化目标，以促进不同粒度的网络和文本信号之间的彻底相互增强。此外，我们表明现有的对比目标可以学习增强图的低频分量，并提出一种高频分量（HFC）感知的对比学习目标，使学习到的嵌入更加独特。对六个现实世界基准的广泛实验证实了我们提出的方法的有效性。此外，理论分析和项目嵌入可视化为我们的模型互操作性提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2402.16240</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>对抗过滤气泡：通过加权超图嵌入学习实现多样化音乐推荐</title>
      <link>https://arxiv.org/abs/2402.16299</link>
      <description><![CDATA[arXiv:2402.16299v1 公告类型：新
摘要：推荐系统为用户提供双重目的：筛选出不适当或不匹配的信息，同时准确识别符合其偏好的项目。许多推荐算法旨在为用户提供适合其偏好的个性化信息。然而，过度的个性化可能会将用户限制在“过滤气泡”内。因此，在建议的准确性和多样性之间实现适当的平衡是一个紧迫的问题。为了应对这一挑战，以音乐推荐为例，我们引入了多样化加权超图音乐推荐算法（DWHRec）。在 DWHRec 算法中，用户和收听的曲目之间的初始连接由加权超图表示。同时，艺术家、专辑和标签与曲目之间的关联也被附加到超图上。为了探索用户的潜在偏好，将基于超图的随机游走嵌入方法应用于构造的超图。在我们的调查中，准确性是通过用户和轨道之间的对齐来衡量的，而推荐轨道类型的数组则衡量多样性。我们使用两个真实世界的音乐数据集将 DWHRec 与七种最先进的推荐算法进行了严格比较。实验结果验证了 DWHRec 是一种能够巧妙地协调准确性和多样性的解决方案，提供更丰富的音乐体验。除了音乐推荐之外，DWHRec 还可以扩展以适应具有类似数据结构的其他场景。]]></description>
      <guid>https://arxiv.org/abs/2402.16299</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>顶级个性化K推荐</title>
      <link>https://arxiv.org/abs/2402.16304</link>
      <description><![CDATA[arXiv:2402.16304v1 公告类型：新
摘要：传统的top-K推荐，即呈现排名分数最高的top-K项目，是生成个性化排名列表的常见做法。然而，这种固定大小的top-K推荐是让每个用户满意的最佳方法吗？不必要。我们指出，在不考虑用户效用的情况下提供固定大小的推荐可能不是最佳的，因为它可能不可避免地包含不相关的项目或限制相关项目的曝光。为了解决这个问题，我们引入了 Top-Personalized-KRecommendation，这是一种新的推荐任务，旨在生成个性化大小的排名列表，以最大限度地提高个人用户满意度。作为所提出任务的解决方案，我们开发了一个名为 PerK 的模型无关框架。 PerK 通过利用校准的交互概率来估计预期用户效用，然后选择最大化该预期效用的推荐大小。通过对真实数据集的广泛实验，我们证明了 PerK 在 Top-Personalized-K 推荐任务中的优越性。我们预计 Top-Personalized-K 推荐有潜力为各种现实世界的推荐场景提供增强的解决方案，基于其与现有模型的良好兼容性。]]></description>
      <guid>https://arxiv.org/abs/2402.16304</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:29 GMT</pubDate>
    </item>
    <item>
      <title>用于具有可解释性的多模态推荐的解纠缠图变分自动编码器</title>
      <link>https://arxiv.org/abs/2402.16110</link>
      <description><![CDATA[arXiv:2402.16110v1 公告类型：新
摘要：多模态推荐系统将多模态信息（例如文本描述、图像）合并到协作过滤框架中，以提供更准确的推荐。虽然多模态信息的结合可以增强这些系统的可解释性，但当前的多模态模型利用纠缠的数值向量来表示用户和项目，这使得它们难以解释。为了解决这个问题，我们提出了一种解缠结图变分自动编码器（DGVAE），旨在增强模型和推荐的可解释性。 DGVAE 最初通过利用最先进的多模态预训练技术将多模态信息投射到文本内容中，例如将图像转换为文本。然后，它构建一个冻结的项目-项目图，并利用简化的残差图卷积网络将内容和交互编码为两组解开的表示。 DGVAE 通过互信息最大化进一步规范这些解开的表示，将从用户和项目之间的交互中得出的表示与从文本内容中学习到的表示对齐。这种对齐方式有助于通过文本解释用户二进制交互。我们对三个真实世界数据集进行的实证分析表明，DGVAE 的性能显着超过最先进基线的性能 10.02%。我们还提供了一个来自现实世界数据集的案例研究来说明 DGVAE 的可解释性。代码位于：\url{https://github.com/enoche/DGVAE}。]]></description>
      <guid>https://arxiv.org/abs/2402.16110</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>IR2：信息检索的信息正则化</title>
      <link>https://arxiv.org/abs/2402.16200</link>
      <description><![CDATA[arXiv:2402.16200v1 公告类型：新
摘要：在训练数据有限的情况下，有效的信息检索（IR），特别是对于复杂的查询，仍然是一项具有挑战性的任务。本文介绍了 IR2（信息检索的信息正则化），这是一种在合成数据生成过程中减少过度拟合的技术。这种方法代表了正则化技术在 IR 合成数据创建中的新颖应用，并在最近三个以复杂查询为特征的 IR 任务上进行了测试：DORIS-MAE、ArguAna 和 WhatsThatBook。实验结果表明，我们的正则化技术不仅在所考虑的任务上优于以前的综合查询生成方法，而且还降低了高达 50% 的成本。此外，本文在查询合成管道的不同阶段（输入、提示和输出）对三种正则化方法进行了分类和探索，与未应用正则化的模型相比，每种方法都提供了不同程度的性能改进。这提供了一种在数据有限、复杂查询 IR 场景中优化合成数据生成的系统方法。所有代码、提示和合成数据均可在 https://github.com/Info-Regularization/Information-Regularization 上获取。]]></description>
      <guid>https://arxiv.org/abs/2402.16200</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>ListT5：使用 Fusion-in-Decoder 进行列表重排序改进了零样本检索</title>
      <link>https://arxiv.org/abs/2402.15838</link>
      <description><![CDATA[arXiv:2402.15838v1 公告类型：新
摘要：我们提出了 ListT5，这是一种基于 Fusion-in-Decoder (FiD) 的新型重新排序方法，可在训练和推理时处理多个候选段落。我们还引入了一种基于具有输出缓存的多进制锦标赛排序的列表排序的高效推理框架。我们在零样本检索任务的 BEIR 基准上评估和比较我们的模型，证明 ListT5 (1) 优于最先进的 RankT5 基线，平均 NDCG@10 得分显着提高 +1.3，(2 ）具有与逐点排序模型相当的效率，并且超越了以前的列表排序模型的效率，并且（3）克服了以前的列表重排序器的中间丢失问题。我们的代码、模型检查点和评估框架在 \url{https://github.com/soyoung97/ListT5} 上完全开源。]]></description>
      <guid>https://arxiv.org/abs/2402.15838</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:27 GMT</pubDate>
    </item>
    <item>
      <title>Pfeed：使用预先计算的嵌入相似性生成近乎实时的个性化提要</title>
      <link>https://arxiv.org/abs/2402.16073</link>
      <description><![CDATA[arXiv:2402.16073v1 公告类型：新
摘要：在个性化推荐系统中，嵌入通常用于对客户操作和项目进行编码，然后使用近似最近邻搜索在嵌入空间中执行检索。然而，这种方法可能会带来两个挑战：1）用户嵌入可能会限制所捕获兴趣的多样性，2）保持它们最新的需要需要昂贵的实时基础设施。在本文中，我们提出了一种在实际工业环境中克服这些挑战的方法。该方法利用预先计算的嵌入及其各自的相似性，动态更新客户资料并每两分钟编写一个提要。我们在荷兰和比利时最大的电子商务平台之一 Bol 测试并部署了这种方法来个性化促销商品。该方法增强了客户参与度和体验，使转化率显着提高了 4.9%。]]></description>
      <guid>https://arxiv.org/abs/2402.16073</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:27 GMT</pubDate>
    </item>
    <item>
      <title>RecWizard：具有模块化、便携式模型和交互式用户界面的对话式推荐工具包</title>
      <link>https://arxiv.org/abs/2402.15591</link>
      <description><![CDATA[arXiv:2402.15591v1 公告类型：新
摘要：我们提出了一个新的 Python 工具包，名为 RecWizard，用于会话推荐系统 (CRS)。 RecWizard 借鉴 Huggingface 生态系统的最佳实践，为模型和交互式用户界面的开发提供支持。带有 RecWizard 的 CRS 是模块化、可移植、交互式和大型语言模型 (LLM) 友好的，可以简化学习过程并减少 CRS 研究的额外工作量。有关 RecWizard 的更全面信息，请查看我们的 GitHub https://github.com/McAuley-Lab/RecWizard。]]></description>
      <guid>https://arxiv.org/abs/2402.15591</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:26 GMT</pubDate>
    </item>
    <item>
      <title>巧妙的治愈之路：利用机器学习进行视觉艺术推荐，以预防和减少重症监护后的情况</title>
      <link>https://arxiv.org/abs/2402.15643</link>
      <description><![CDATA[arXiv:2402.15643v1 公告类型：新
摘要： 住在重症监护室（ICU）通常会造成创伤，导致重症监护后综合症（PICS），包括身体、心理和认知障碍。目前，可用于 PICS 的干预措施有限。研究表明，接触视觉艺术可能有助于解决 PICS 的心理问题，如果是个性化的，效果会更佳。我们开发基于机器学习的视觉艺术推荐系统 (VA RecSys)，为 ICU 术后患者提供个性化的治疗性视觉艺术体验。我们研究了四种最先进的 VA RecSys 引擎，与专家策划的建议相比，评估了它们的建议与治疗目的的相关性。我们进行了专家试点测试和大规模用户研究 (n=150)，以评估这些建议的适当性和有效性。我们的结果表明所有建议都能增强暂时的情感状态。视觉和多模式 VA RecSys 引擎与专家策划的建议相比较，表明它们有潜力支持为 PICS 预防和治疗提供个性化艺术治疗。]]></description>
      <guid>https://arxiv.org/abs/2402.15643</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:26 GMT</pubDate>
    </item>
    <item>
      <title>基于去偏模型的交互推荐</title>
      <link>https://arxiv.org/abs/2402.15819</link>
      <description><![CDATA[arXiv:2402.15819v1 公告类型：新
摘要：现有的基于模型的交互式推荐系统是通过查询世界模型来捕获用户偏好来训练的，但是从历史记录数据中学习世界模型很容易受到流行度偏差和抽样偏差等偏差问题的影响。这就是为什么最近提出了一些去偏方法的原因。然而，仍然存在两个基本缺点：1）忽略流行度随时间变化的动态会导致项目的错误重新加权。 2）负抽样中将未知样本作为负样本会导致抽样偏差。为了克服这两个缺点，我们开发了一个名为 \textbf{i}dentabile \textbf{D}ebiased \textbf{M}odel-based \textbf{I}nteractive \textbf{R}ecommendation 的模型（\textbf{iDMIR} in短的）。在iDMIR中，针对第一个缺点，我们基于具有识别保证的时变推荐生成过程的因果机制，设计了一种去偏因果世界模型；针对第二个缺点，我们设计了一种去偏对比策略，它与去偏对比学习相一致，避免了抽样偏差。此外，我们证明所提出的方法不仅优于几种最新的交互式推荐算法，而且还具有不同的推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2402.15819</guid>
      <pubDate>Tue, 27 Feb 2024 06:16:26 GMT</pubDate>
    </item>
    </channel>
</rss>