<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 21 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用网络医学和 GenAI 加速复杂疾病治疗：乳腺癌药物再利用案例研究</title>
      <link>https://arxiv.org/abs/2406.13106</link>
      <description><![CDATA[arXiv:2406.13106v1 公告类型：交叉 
摘要：本研究的目的是引入一个专门用于预测药物的网络，该网络可以通过调查现实世界的证据来源（例如临床试验和生物医学文献）来重新利用。具体而言，它旨在为复杂疾病（例如癌症、阿尔茨海默氏症）产生药物联合疗法。我们提出了一种多层网络医学方法，该方法由高度配置的 ChatGPT 提示工程系统提供支持，该系统是即时构建的，用于提取临床试验中的药物提及。此外，我们引入了一种将现实世界证据与疾病特异性信号通路（例如 KEGG 数据库）连接起来的新算法。如果发现药物与信号通路的一种或多种蛋白质成分结合，这将揭示药物的可重新利用性。为了证明这一点，我们实例化了乳腺癌的框架，发现在 46 种乳腺癌信号通路中，该框架确定了至少两种药物覆盖的 38 种通路。这一证据表明，这些药物有结合的潜力。具体来说，覆盖率最高的信号通路 ID hsa:2064 被 108 种药物覆盖，其中一些药物可以组合使用。相反，信号通路 ID hsa:1499 仅被两种药物覆盖，这表明进一步研究存在很大差距。我们的网络医学框架由 GenAI 提供支持，有望以高度特异性识别药物组合，了解作为靶标的确切信号通路和蛋白质。值得注意的是，ChatGPT 成功加速了临床试验中识别药物提及的过程，尽管还需要进一步研究来确定药物提及之间的关系。]]></description>
      <guid>https://arxiv.org/abs/2406.13106</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>长上下文语言模型可以包含检索、RAG、SQL 等吗？</title>
      <link>https://arxiv.org/abs/2406.13121</link>
      <description><![CDATA[arXiv:2406.13121v1 公告类型：交叉 
摘要：长上下文语言模型 (LCLM) 有可能彻底改变我们传统上依赖外部工具（如检索系统或数据库）完成任务的方法。利用 LCLM 本地摄取和处理整个信息语料库的能力可以带来许多优势。它通过消除对工具专业知识的需求来增强用户友好性，提供强大的端到端建模以最大限度地减少复杂管道中的级联错误，并允许在整个系统中应用复杂的提示技术。为了评估这种范式转变，我们引入了 LOFT，这是现实世界任务的基准，需要多达数百万个标记的上下文，旨在评估 LCLM 在上下文检索和推理方面的表现。我们的研究结果表明，尽管从未明确训练过这些任务，但 LCLM 具有令人惊讶的能力，可以与最先进的检索和 RAG 系统相媲美。然而，LCLM 在 SQL 类任务所需的组合推理等领域仍面临挑战。值得注意的是，提示策略对性能有显著影响，这强调了随着上下文长度的增加，需要继续进行研究。总体而言，LOFT 为 LCLM 提供了一个严格的测试场地，展示了它们在模型能力扩展时取代现有范式和应对新任务的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.13121</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>利用实体 Top-K 稀疏化实现通信高效的联合知识图谱嵌入</title>
      <link>https://arxiv.org/abs/2406.13225</link>
      <description><![CDATA[arXiv:2406.13225v1 公告类型：交叉 
摘要：联邦知识图谱嵌入学习（FKGE）由于参数量大、通信轮次多而面临通信效率方面的挑战。然而，现有的FKGE方法仅注重通过在每个通信轮次中进行多轮局部训练来减少通信轮次，而忽略了减少在每个通信轮次中传输的参数量。为了解决这个问题，我们首先发现在压缩过程中所有实体的嵌入精度普遍降低会显著阻碍收敛速度，强调了保持嵌入精度的重要性。然后，我们提出了基于实体级别的Top-K稀疏化策略的双向通信高效FedS。在上传过程中，客户端动态识别并仅将变化较大的Top-K实体嵌入上传到服务器。在下载过程中，服务器首先为每个客户端执行个性化的嵌入聚合。然后，它识别并将Top-K聚合嵌入传输给每个客户端。此外，FedS 采用间歇性同步机制来减轻由于联邦知识图谱的异构性而导致的客户端共享实体之间嵌入不一致的负面影响。在三个数据集上进行的大量实验表明，FedS 显著提高了通信效率，而性能下降几乎可以忽略不计（甚至没有）。]]></description>
      <guid>https://arxiv.org/abs/2406.13225</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>LARP：用于冷启动播放列表延续的语言音频关系预训练</title>
      <link>https://arxiv.org/abs/2406.14333</link>
      <description><![CDATA[arXiv:2406.14333v1 公告类型：新
摘要：随着在线音乐消费越来越多地转向基于播放列表的收听，播放列表延续任务（其中算法以个性化和音乐凝聚力的方式推荐歌曲以扩展播放列表）已成为音乐流媒体成功的关键。目前，许多现有的播放列表延续方法都依赖于协同过滤方法来执行推荐。然而，这种方法很难推荐缺乏交互数据的歌曲，这个问题被称为冷启动问题。目前应对这一挑战的方法设计了复杂的机制，用于从稀疏的协作数据中提取关系信号并将其集成到内容表示中。然而，这些方法将内容表示学习排除在范围之外，并使用可能与特定音乐设置的分布或格式不一致的冻结的、预先训练的内容模型。此外，即使是音乐最先进的内容模块要么 (1) 与冷启动设置不兼容，要么 (2) 无法有效地整合跨模态和关系信号。在本文中，我们引入了 LARP，一种多模态冷启动播放列表延续模型，以有效克服这些限制。LARP 是一个三阶段对比学习框架，将多模态和关系信号集成到其学习的表示中。我们的框架使用不断增加的任务特定抽象阶段：曲目内（语言-音频）对比损失、曲目-曲目对比损失和曲目-播放列表对比损失。在两个公开可用的数据集上进行的实验结果证明了 LARP 在冷启动设置中播放列表延续方面优于单模态和多模态模型的有效性。代码和数据集发布于：https://github.com/Rsalganik1123/LARP。]]></description>
      <guid>https://arxiv.org/abs/2406.14333</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>GLiNER 多任务：适用于各种信息提取任务的通用轻量级模型</title>
      <link>https://arxiv.org/abs/2406.12925</link>
      <description><![CDATA[arXiv:2406.12925v1 公告类型：交叉 
摘要：信息提取任务需要准确、高效和可泛化的模型。经典的监督深度学习方法可以实现所需的性能，但它们需要大量数据集，并且适应不同任务的能力有限。另一方面，大型语言模型 (LLM) 表现出良好的泛化能力，这意味着它们可以根据用户请求适应许多不同的任务。然而，LLM 的计算成本很高，并且往往无法生成结构化输出。在本文中，我们将介绍一种新型的 GLiNER 模型，该模型可用于各种信息提取任务，同时也是一种小型编码器模型。我们的模型在零样本 NER 基准上实现了 SoTA 性能，并在问答、摘要和关系提取任务中取得了领先的性能。此外，在本文中，我们将介绍使用 GLiNER 模型进行命名实体识别的自学习方法的实验结果。]]></description>
      <guid>https://arxiv.org/abs/2406.12925</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>DIRAS：检索增强生成中文档相关性的高效 LLM 辅助注释</title>
      <link>https://arxiv.org/abs/2406.14162</link>
      <description><![CDATA[arXiv:2406.14162v1 公告类型：新
摘要：检索增强生成 (RAG) 被广泛用于对特定领域文档的查询做出响应。但是 RAG 实现是否会遗漏重要信息或过多地包含不相关信息？为了缓解这些担忧，有必要注释特定领域的基准以评估信息检索 (IR) 性能，因为相关性定义因查询和领域而异。此外，此类基准应以经济高效的方式进行注释，以避免注释选择偏差。在本文中，我们提出了 DIRAS（具有可扩展性的领域特定信息检索注释），这是一种无需手动注释的模式，可微调开源 LLM 以使用校准的相关性概率注释相关性标签。大量评估表明，DIRAS 微调模型在注释和排名未见（查询、文档）对方面实现了 GPT-4 级别的性能，并且有助于现实世界的 RAG 开发。]]></description>
      <guid>https://arxiv.org/abs/2406.14162</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型和强化学习来优化 Top-k 推荐的新颖性</title>
      <link>https://arxiv.org/abs/2406.14169</link>
      <description><![CDATA[arXiv:2406.14169v1 公告类型：新
摘要：给定一个输入查询，使用用户反馈数据（例如，点击数据）训练推荐模型以输出排序的项目列表。在现实世界的系统中，除了准确性之外，新模型的一个重要考虑因素是其前 k 个推荐相对于现有部署模型的新颖性。然而，前 k 个项目的新颖性是一个难以优化模型的目标，因为它涉及对模型预测的不可微分排序操作。此外，根据定义，新项目没有任何用户反馈数据。鉴于大型语言模型的语义能力，我们使用强化学习 (RL) 公式来解决这些问题，其中大型语言模型为新项目提供反馈。然而，给定数百万个候选项目，标准 RL 算法的样本复杂度可能高得令人望而却步。为了降低样本复杂度，我们将前 k 个列表奖励减少为一组逐项奖励，并将状态空间重新表述为由元组组成，这样动作空间就减少为二元决策；并表明当项目数量很大时，这种重新表述会显著降低复杂度。我们在大型搜索引擎上的查询广告推荐任务中评估了所提出的算法在提高新颖性方面的表现。与最近对的监督微调相比，所提出的基于 RL 的算法可以显著提高新颖性，同时将召回率损失降至最低。我们在 ORCAS 查询网页匹配数据集和基于亚马逊评论的产品推荐数据集上获得了类似的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.14169</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行分类指导的零样本推荐</title>
      <link>https://arxiv.org/abs/2406.14043</link>
      <description><![CDATA[arXiv:2406.14043v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的出现及其执行各种任务的能力，它们在推荐系统 (RecSys) 中的应用已显示出良好的前景。然而，在将 LLM 部署到 RecSys 时，我们面临着重大挑战，例如提示长度有限、项目信息非结构化以及推荐生成不受约束，导致性能不佳。为了解决这些问题，我们提出了一种使用分类词典的新方法。该方法提供了一个系统的框架来对项目进行分类和组织，提高了项目信息的清晰度和结构性。通过将分类词典合并到 LLM 提示中，我们实现了高效的标记利用和受控的特征生成，从而产生更准确和上下文相关的推荐。我们的分类法指导推荐 (TaxRec) 方法具有两步流程：一次性分类和基于 LLM 的推荐，无需进行特定领域的微调即可实现零样本推荐。实验结果表明，与传统的零样本方法相比，TaxRec 显著提高了推荐质量，展示了其作为 LLM 个人推荐系统的有效性。代码可在 https://github.com/yueqingliang1/TaxRec 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14043</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>对基于零样本 LLM 的排序器的即时变化的调查</title>
      <link>https://arxiv.org/abs/2406.14117</link>
      <description><![CDATA[arXiv:2406.14117v1 公告类型：新 
摘要：我们系统地了解了提示中使用的特定组件和措辞对基于零样本大型语言模型 (LLM) 的排名器有效性的影响。最近提出了几种基于 LLM 的零样本排名方法。在许多方面，方法在 (1) 它们实现的排名算法（例如逐点与列表）方面有所不同，(2) 使用的主干 LLM，例如 GPT3.5 与 FLAN-T5，(3) 提示中使用的组件和措辞，例如是否使用角色定义（角色扮演）以及用于表达这一点的实际单词。目前尚不清楚性能差异是由于底层排名算法造成的，还是因为诸如提示中使用的单词选择更好的虚假因素造成的。这种混淆可能会破坏未来的研究。通过大规模实验和分析，我们发现排名算法确实会导致零样本 LLM 排名方法之间的差异。然而，LLM 主干也是如此——但更重要的是，提示组件和措辞的选择会影响排名。事实上，在我们的实验中，我们发现，有时，这些后者元素对排名器有效性的影响比实际排名算法更大，而且当考虑到提示变化时，排名方法之间的差异变得更加模糊。]]></description>
      <guid>https://arxiv.org/abs/2406.14117</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:42 GMT</pubDate>
    </item>
    <item>
      <title>无需等待：电子商务中无需用户反馈即可学习重新排序模型</title>
      <link>https://arxiv.org/abs/2406.14004</link>
      <description><![CDATA[arXiv:2406.14004v1 公告类型：新
摘要：推荐系统已广泛应用于电子商务，重排序模型在该领域发挥着越来越重要的作用，它利用商品间的影响并确定最终的推荐列表。在线学习方法不断使用最新的可用样本更新已部署的模型，以捕捉电子商务中底层数据分布的变化。然而，它们依赖于真实用户反馈的可用性，这些反馈可能会延迟数小时甚至数天，例如商品购买，从而导致模型增强滞后。在本文中，我们提出了一种用于重排序建模的在线学习方法的新扩展，我们称之为 LAST，即 Learning At Serving Time 的缩写。它通过使用替代模型来提供引导模型改进所需的指导信号，从而绕过用户反馈的要求。在收到在线请求后，LAST 会在生成请求的推荐结果之前动态查找并应用模型修改。修改是请求特定的和暂时的。这意味着修改是针对当前请求量身定制的，并且只针对当前请求，以捕获请求的特定上下文。请求结束后，修改将被丢弃，这有助于防止错误传播并稳定在线学习过程，因为替代模型的预测可能不准确。最重要的是，作为基于反馈的在线学习方法的补充，LAST 可以无缝集成到现有的在线学习系统中，以创建更具适应性和响应能力的推荐体验。离线和在线的综合实验证实，LAST 优于最先进的重新排名模型。]]></description>
      <guid>https://arxiv.org/abs/2406.14004</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>EAGER：具有行为语义协作的双流生成推荐器</title>
      <link>https://arxiv.org/abs/2406.14017</link>
      <description><![CDATA[arXiv:2406.14017v1 公告类型：新 
摘要：生成检索最近成为一种有前途的顺序推荐方法，将候选项目检索定义为自回归序列生成问题。然而，现有的生成方法通常只关注项目信息的行为或语义方面，忽视了它们的互补性，从而导致效果有限。为了解决这一限制，我们引入了 EAGER，这是一个新颖的生成推荐框架，可以无缝集成行为和语义信息。具体来说，我们确定了结合这两类信息的三个关键挑战：一个统一的生成架构，能够处理两种特征类型，确保每种类型都有充分和独立的学习，并促进微妙的互动，增强协作信息利用率。为了实现这些目标，我们提出 (1) 一种双流生成架构，利用一个共享编码器和两个独立的解码器，使用基于置信度的排名策略解码行为标记和语义标记；(2) 一个具有摘要标记的全局对比任务，以实现对每种类型信息的判别解码； （3）语义引导的迁移任务，旨在通过重建和估计目标隐性地促进交叉交互。我们在四个公共基准上验证了 EAGER 的有效性，证明了它与现有方法相比的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2406.14017</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:41 GMT</pubDate>
    </item>
    <item>
      <title>UpDLRM：利用真实世界的 PIM 架构加速个性化推荐</title>
      <link>https://arxiv.org/abs/2406.13941</link>
      <description><![CDATA[arXiv:2406.13941v1 公告类型：新
摘要：深度学习推荐模型 (DLRM) 因其在处理大规模推荐任务方面的有效性而在推荐系统中广受欢迎。由于对内存容量和内存带宽的需求很大，DLRM 的嵌入层已成为性能瓶颈。在本文中，我们提出了 UpDLRM，它利用真实世界内存处理 (PIM) 硬件 UPMEM DPU 来提高内存带宽并减少推荐延迟。DPU 内存的并行特性可以为嵌入查找中的大量不规则内存访问提供高聚合带宽，从而为减少推理延迟提供了巨大的潜力。为了充分利用 DPU 内存带宽，我们进一步研究了嵌入表分区问题，以实现良好的工作负载平衡和高效的数据缓存。使用真实世界数据集的评估表明，与仅使用 CPU 和 CPU-GPU 混合的 DLRM 相比，UpDLRM 实现了更短的推理时间。]]></description>
      <guid>https://arxiv.org/abs/2406.13941</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>在协同过滤中统一图卷积和对比学习</title>
      <link>https://arxiv.org/abs/2406.13996</link>
      <description><![CDATA[arXiv:2406.13996v1 公告类型：新
摘要：基于图的模型和对比学习已成为协同过滤 (CF) 中的重要方法。虽然 CF 中的许多现有模型在其设计中都采用了这些方法，但对于它们背后的基本原理的分析深度似乎有限。本文通过理论框架将基于图的模型的关键元素图卷积与对比学习联系起来。通过研究对比损失的学习动态和平衡，我们提供了一个通过图论理解对比学习的新视角，强调其捕捉高阶连通性的能力。在此分析的基础上，我们进一步表明，基于图的模型中经常使用的图卷积层对于高阶连通性建模并不是必不可少的，并且可能会导致过度平滑的风险。根据我们的研究结果，我们引入了简单对比协同过滤 (SCCF)，这是一种基于朴素嵌入模型和改进的对比损失的简单有效算法。通过在四个公共数据集上的大量实验证明了该算法的有效性。实验代码可在 \url{https://github.com/wu1hong/SCCF} 上找到。 \end{abstract}]]></description>
      <guid>https://arxiv.org/abs/2406.13996</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:40 GMT</pubDate>
    </item>
    <item>
      <title>通过图形感知学习增强语言模型驱动推荐的协作语义</title>
      <link>https://arxiv.org/abs/2406.13235</link>
      <description><![CDATA[arXiv:2406.13235v1 公告类型：新
摘要：大型语言模型（LLM）在推荐系统领域越来越突出。现有研究通常利用上下文学习或对特定任务数据进行监督微调来将 LLM 与推荐对齐。然而，语言处理任务和推荐任务之间语义空间的巨大偏差带来了不可忽视的挑战。具体而言，如果没有足够的协作信息捕获能力，现有的建模范式就难以捕捉社区群体中的行为模式，导致 LLM 无法在推荐场景中辨别隐式交互语义。为了解决这个问题，我们考虑增强语言模型驱动的推荐模型对结构化数据的学习能力，特别是通过利用富含协作语义的交互图。我们提出了一种用于语言模型驱动推荐的图形感知学习（GAL-Rec）。 GAL-Rec 通过模仿图神经网络 (GNN) 聚合多跳信息的意图来增强对用户-项目协作语义的理解，从而充分利用 LLM 的强大学习能力来独立解决推荐系统中的复杂图。在三个真实数据集上的大量实验结果表明，GAL-Rec 显著增强了对协作语义的理解，并提高了推荐性能。]]></description>
      <guid>https://arxiv.org/abs/2406.13235</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:39 GMT</pubDate>
    </item>
    <item>
      <title>CLIP-Branches：用于文本图像检索的交互式微调</title>
      <link>https://arxiv.org/abs/2406.13322</link>
      <description><![CDATA[arXiv:2406.13322v1 公告类型：新
摘要：文本图像模型（最著名的是 CLIP）的出现极大地改变了信息检索的格局。这些模型能够融合各种模态，例如文本和图像。CLIP 的一个重要成果是它能够允许用户使用文本作为查询来搜索图像，反之亦然。这是通过图像和文本数据的联合嵌入实现的，例如，可用于搜索相似的项目。尽管有近似最近邻搜索等有效的查询处理技术，但结果可能缺乏准确性和完整性。我们介绍了 CLIP-Branches，这是一种基于 CLIP 架构构建的新型文本图像搜索引擎。我们的方法通过结合交互式微调阶段增强了传统的文本图像搜索引擎，这允许用户通过迭代定义正面和负面示例来进一步具体化搜索查询。我们的框架涉及在给定额外用户反馈的情况下训练分类模型，并基本上输出整个数据目录的所有正面分类实例。然而，基于最近的技术，这个推理阶段不是通过扫描整个数据目录来实现的，而是通过使用为数据预先构建的高效索引结构来实现的。我们的结果表明，经过微调的结果可以在相关性和准确性方面改善初始搜索结果，同时保持快速的响应时间]]></description>
      <guid>https://arxiv.org/abs/2406.13322</guid>
      <pubDate>Fri, 21 Jun 2024 06:20:39 GMT</pubDate>
    </item>
    </channel>
</rss>