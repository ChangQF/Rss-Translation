<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>AmazonQAC：大规模自然查询自动完成数据集</title>
      <link>https://arxiv.org/abs/2411.04129</link>
      <description><![CDATA[arXiv:2411.04129v1 公告类型：新
摘要：查询自动完成 (QAC) 是现代搜索引擎中的一项关键功能，它通过根据输入前缀预测搜索查询来促进用户交互。尽管它被广泛采用，但缺乏大规模、真实的数据集阻碍了 QAC 系统开发的进步。本文通过介绍 AmazonQAC 来解决这一差距，AmazonQAC 是一个来自 Amazon Search 日志的新 QAC 数据集，包含 3.95 亿个样本。该数据集包括用户输入的前缀的实际序列，这些前缀会导致最终搜索词，以及支持对 QAC 的上下文相关方面进行建模的会话 ID 和时间戳。我们评估了前缀树、语义检索和大型语言模型 (LLM)，包括微调和不微调。我们发现经过微调的 LLM 表现最佳，尤其是在结合上下文信息时。然而，即使是我们最好的系统，在测试数据上也只能实现我们计算出的理论可能值的一半，这意味着 QAC 是一个具有挑战性的问题，现有系统还远远没有解决。本文旨在促进对 QAC 系统的进一步研究，以更好地满足不同环境中的用户需求。我们在 Hugging Face 上开源了这些数据，网址为 https://huggingface.co/datasets/amazon/AmazonQAC。]]></description>
      <guid>https://arxiv.org/abs/2411.04129</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向无推理学习稀疏检索器的竞争性搜索相关性</title>
      <link>https://arxiv.org/abs/2411.04403</link>
      <description><![CDATA[arXiv:2411.04403v1 公告类型：新
摘要：学习稀疏检索可以通过成熟的倒排索引引擎高效地执行检索，近年来引起了越来越多的关注。特别是，无推理稀疏检索器很有吸引力，因为它们在检索阶段消除了在线模型推理，从而避免了巨大的计算成本，提供了合理的吞吐量和延迟。然而，与稀疏和密集暹罗模型相比，即使是最先进的 (SOTA) 无推理稀疏模型在搜索相关性方面也远远落后。为了提高无推理稀疏检索器的搜索相关性，我们认为它们应该采用专门的训练方法，而不是使用与暹罗编码器相同的方法。在本文中，我们提出了两种不同的性能改进方法。首先，我们引入了 IDF 感知的 FLOPS 损失，它将倒排文档频率 (IDF) 引入到表示的稀疏化中。我们发现，这减轻了 FLOPS 正则化对搜索相关性的负面影响，使模型在准确性和效率之间取得更好的平衡。此外，我们提出了一个异构集成知识蒸馏框架，该框架结合了暹罗密集和稀疏检索器，在预训练阶段生成监督信号。密集和稀疏检索器的集成框架分别利用它们的优势，为知识蒸馏提供强大的上限。为了获得来自异构主管的不同反馈，我们对教师模型的输出进行了规范化，然后进行了聚合，以消除分数量表差异。在 BEIR 基准测试中，我们的模型比现有的 SOTA 无推理稀疏模型高出 \textbf{3.3 NDCG@10 分数}。它表现出与暹罗稀疏检索器相当的搜索相关性，客户端延迟仅为 \textbf{1.1 倍于 BM25}。]]></description>
      <guid>https://arxiv.org/abs/2411.04403</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型提炼为 BERT 以进行 Web 搜索排名的最佳实践</title>
      <link>https://arxiv.org/abs/2411.04539</link>
      <description><![CDATA[arXiv:2411.04539v1 公告类型：新
摘要：最近的研究强调了大型语言模型 (LLM) 作为零样本相关性排序器的巨大潜力。这些方法主要利用即时学习来评估查询和文档之间的相关性，方法是生成潜在文档的排序列表。尽管 LLM 前景光明，但其高昂成本对其在商业搜索系统中的直接实施构成了重大挑战。为了克服这一障碍并充分利用 LLM 的文本排名功能，我们探索了将 LLM 的排名专业知识转移到类似于 BERT 的更紧凑模型的技术，使用排名损失来实现资源密集程度较低的模型的部署。具体而言，我们通过持续预训练来增强 LLM 的训练，将查询作为输入，将点击的标题和摘要作为输出。然后，我们使用排名损失对 LLM 进行监督微调，将最终标记分配为整个句子的代表。鉴于自回归语言模型的固有特性，只有最后一个标记  才能封装所有前面的标记。此外，我们引入了混合逐点和边际 MSE 损失，将排名知识从 LLM 转移到 BERT 等较小的模型。此方法为资源限制严格的环境创建了一个可行的解决方案。离线和在线评估都证实了我们方法的有效性，并且截至 2024 年 2 月，我们的模型已成功集成到商业网络搜索引擎中。]]></description>
      <guid>https://arxiv.org/abs/2411.04539</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行自校准列表重排序</title>
      <link>https://arxiv.org/abs/2411.04602</link>
      <description><![CDATA[arXiv:2411.04602v1 公告类型：新
摘要：大型语言模型 (LLM) 具有先进的语言能力，已通过序列到序列方法用于重新排序任务。在此范例中，多个段落以列表方式重新排序，并生成文本重新排序排列。但是，由于 LLM 的上下文窗口有限，此重新排序范例需要滑动窗口策略来迭代处理更大的候选集。这不仅增加了计算成本，而且还限制了 LLM 完全捕获所有候选的所有比较信息。为了应对这些挑战，我们提出了一种新颖的自校准列表重新排序方法，旨在利用 LLM 为排名生成全局相关性分数。为了实现它，我们首先提出了相关性感知的列表重新排序框架，该框架结合了显式列表视图相关性分数来提高重新排序效率并实现对整个候选集的全局比较。其次，为了确保计算分数的可比性，我们提出了自校准训练，即使用 LLM 内部生成的观点视图相关性评估来校准列表视图相关性评估。在 BEIR 基准和 TREC 深度学习轨道上进行的大量实验和全面分析证明了我们提出的方法的有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2411.04602</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lightning IR：基于 Transformer 的语言模型的直接微调和推理，用于信息检索</title>
      <link>https://arxiv.org/abs/2411.04677</link>
      <description><![CDATA[arXiv:2411.04677v1 公告类型：新
摘要：已经提出了多种基于 Transformer 的语言模型用于信息检索任务。然而，这些模型的微调和推理通常很复杂，需要大量的工程工作。本文介绍了 Lightning IR，这是一个基于 PyTorch Lightning 的框架，用于对基于 Transformer 的语言模型进行微调和推理，以进行信息检索。Lightning IR 提供了一种模块化和可扩展的架构，支持信息检索管道的所有阶段：从微调和索引到搜索和重新排名。它被设计为易于使用、可扩展和可复制。Lightning IR 可作为开源使用：https://github.com/webis-de/lightning-ir。]]></description>
      <guid>https://arxiv.org/abs/2411.04677</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>dsld：一种用于教学统计的社会相关工具</title>
      <link>https://arxiv.org/abs/2411.04228</link>
      <description><![CDATA[arXiv:2411.04228v1 公告类型：交叉 
摘要：数据科学日益增长的力量可以在解决社会歧视方面发挥关键作用，需要对潜在偏见有细致的理解和有效的缓解策略。数据科学看待歧视 (dsld) 是一个 R 和 Python 包，旨在为用户提供一套全面的统计和图形方法工具包，用于评估与受保护群体（如种族、性别和年龄）相关的可能歧视。我们的软件通过识别和缓解混杂变量提供歧视分析技术，以及减少预测模型偏差的方法。
在教育环境中，dsld 为教师提供了强大的工具，通过激励现实世界中的歧视分析示例来教授重要的统计原理。80 页的 Quarto 书籍的加入进一步支持用户（从统计教育者到法律专业人士）有效地将这些分析工具应用于现实世界场景。]]></description>
      <guid>https://arxiv.org/abs/2411.04228</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接器：一种实时连接音乐的贝叶斯方法</title>
      <link>https://arxiv.org/abs/2411.04366</link>
      <description><![CDATA[arXiv:2411.04366v1 公告类型：交叉 
摘要：我们提出了“Concatenator”，这是一种用于音频引导连接合成的实时系统。与 Driedger 等人的“musaicing”（或“音频马赛克”）技术类似，我们在音频语料库中连接一定数量的窗口，以重新创建目标音频流的谐波和打击乐方面。然而，与 Driedger 基于 NMF 的技术不同，我们使用明确的贝叶斯观点，其中语料库窗口索引是隐藏状态，目标音频流是观察值。我们使用粒子滤波器实时推断最佳隐藏语料库状态。我们的过渡模型包括一个可调参数来控制语料库颗粒的时间连续性，我们的观察模型允许用户优先考虑窗口变化的速度以匹配目标。由于系统的计算复杂性与语料库大小无关，我们的系统可以扩展到长达数小时的语料库，这在庞大的音频数据收集时代是一个重要特征。在 Concatenator 模块本身中，作曲家可以实时改变颗粒长度、适应目标和音调变化，同时对他们听到的声音做出反应，使他们能够快速迭代想法。为了总结我们的工作，我们通过大量定量测试参数的影响以及具有艺术洞察力的定性评估来评估我们的系统。根据结果的质量，我们相信实时功能为音乐表达和控制开辟了新途径，适用于现场表演和模块化合成集成，这进一步代表了连接合成技术的重大突破。]]></description>
      <guid>https://arxiv.org/abs/2411.04366</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Orbit：设计和评估多目标排序器的框架</title>
      <link>https://arxiv.org/abs/2411.04798</link>
      <description><![CDATA[arXiv:2411.04798v1 公告类型：交叉 
摘要：生产中的机器学习需要平衡多个目标：这在排名或推荐模型中尤为明显，其中必须同时考虑相互冲突的目标，例如用户参与度、满意度、多样性和新颖性。然而，设计多目标排名器本质上是一个动态的棘手问题——没有单一的最佳解决方案，而且需求会随着时间的推移而发展。有效的设计需要跨职能团队之间的协作以及对广泛信息的仔细分析。在这项工作中，我们引入了 Orbit，这是一个以目标为中心的排名器构建和迭代的概念框架。该框架将目标置于设计过程的中心，作为沟通的边界对象并指导从业者进行设计和评估。我们将 Orbit 实现为一个交互式系统，使利益相关者能够直接与目标空间交互，并支持实时探索和评估设计权衡。我们通过一项涉及 12 名行业从业人员的用户研究对 Orbit 进行了评估，结果表明它支持高效的设计空间探索，有助于做出更明智的决策，并增强了对多个目标固有权衡的认识。Orbit (1) 为任何多目标 ML 模型开辟了以目标为中心的设计流程的新机会，并且 (2) 为推动从业人员超越狭隘的以指标为中心或以示例为中心的思维模式的未来设计提供了启示。]]></description>
      <guid>https://arxiv.org/abs/2411.04798</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于推荐的 Softmax 直接偏好优化</title>
      <link>https://arxiv.org/abs/2406.09215</link>
      <description><![CDATA[arXiv:2406.09215v3 公告类型：替换 
摘要：推荐系统旨在根据用户偏好数据预测个性化排名。随着语言模型 (LM) 的兴起，基于 LM 的推荐器因其广泛的世界知识和强大的推理能力而得到广泛探索。大多数基于 LM 的推荐器将历史交互转换为语言提示，与积极项目配对作为目标响应，并使用语言建模损失对 LM 进行微调。然而，当前目标未能充分利用偏好数据，并且未针对个性化排名任务进行优化，这阻碍了基于 LM 的推荐器的性能。受到直接偏好优化 (DPO) 在人类偏好对齐方面的当前进展以及 softmax 损失在推荐中的成功的启发，我们提出了 Softmax-DPO (S-DPO) 将排名信息灌输到 LM 中，以帮助基于 LM 的推荐器区分偏好项目和负面项目，而不是仅仅关注积极因素。具体来说，我们在用户偏好数据中加入了多个负样本，并设计了一个专门针对基于 LM 的推荐系统的 DPO 损失的替代版本，该版本从传统的全排序 Plackett-Luce (PL) 模型扩展到部分排序并与 softmax 采样策略相连。从理论上讲，我们将 S-DPO 与 softmax 损失结合起来，而不是负采样，并发现它具有挖掘硬负样本的固有优势，这确保了它在推荐任务中的卓越能力。从经验上讲，在三个真实数据集上进行的大量实验证明了 S-DPO 的优势，它可以有效地模拟用户偏好并进一步提高推荐性能，同时为首选项目提供更好的奖励。我们的代码可在 https://github.com/chenyuxin1999/S-DPO 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.09215</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LightRAG：简单快速的检索增强生成</title>
      <link>https://arxiv.org/abs/2410.05779</link>
      <description><![CDATA[arXiv:2410.05779v2 公告类型：替换 
摘要：检索增强生成 (RAG) 系统通过集成外部知识源来增强大型语言模型 (LLM)，从而能够根据用户需求提供更准确、更符合语境的响应。然而，现有的 RAG 系统存在很大的局限性，包括依赖平面数据表示和语境意识不足，这可能导致无法捕捉复杂相互依赖关系的碎片化答案。为了应对这些挑战，我们提出了 LightRAG，它将图形结构整合到文本索引和检索过程中。这个创新框架采用了双层检索系统，可以增强从低级和高级知识发现中进行的全面信息检索。此外，图形结构与矢量表示的集成有助于高效检索相关实体及其关系，从而显著提高响应时间，同时保持上下文相关性。增量更新算法进一步增强了此功能，该算法确保及时集成新数据，使系统在快速变化的数据环境中保持有效和响应能力。大量实验验证表明，与现有方法相比，检索准确度和效率有显著提高。我们已将 LightRAG 开源，可从以下链接获取：https://github.com/HKUDS/LightRAG。]]></description>
      <guid>https://arxiv.org/abs/2410.05779</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>说到做到并不代表做到：大型语言模型在词汇蕴涵识别中的局限性</title>
      <link>https://arxiv.org/abs/2406.14894</link>
      <description><![CDATA[arXiv:2406.14894v2 公告类型：replace-cross 
摘要：动词是语言的支柱，为句子提供结构和意义。然而，它们复杂的语义细微差别带来了长期的挑战。通过词汇蕴涵的概念理解动词关系对于理解句子意义和掌握动词动态至关重要。这项工作调查了八个大型语言模型通过不同设计的提示策略和零/少样本设置识别动词之间的词汇蕴涵关系的能力，这些模型来自两个词汇数据库，即 WordNet 和 HyperLex。我们的研究结果表明，这些模型可以以中等良好的性能处理词汇蕴涵识别任务，尽管有效性程度不同，条件也不同。此外，利用少样本提示可以提高模型的性能。然而，完美地解决这个任务对于所有经过审查的 LLM 来说都是一个未解决的挑战，这为进一步研究这一主题提供了契机。]]></description>
      <guid>https://arxiv.org/abs/2406.14894</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChartifyText：通过 LLM 从包含数据的文本自动生成图表</title>
      <link>https://arxiv.org/abs/2410.14331</link>
      <description><![CDATA[arXiv:2410.14331v2 公告类型：replace-cross 
摘要：涉及数值的文本文档广泛应用于科学研究、经济、公共卫生和新闻等各种应用领域。然而，读者很难快速解读此类涉及数据的文本并获得深刻的见解。为了填补这一研究空白，这项工作旨在自动生成图表，以准确地向读者传达底层数据和想法，这本质上是一项具有挑战性的任务。挑战源于文本歧义、文本文档中数据的内在稀疏性和不确定性以及主观情绪差异。具体来说，我们提出了 ChartifyText，这是一种新颖的全自动方法，它利用大型语言模型 (LLM) 将复杂的数据相关文本转换为富有表现力的图表。它由两个主要模块组成：表格数据推理和富有表现力的图表生成。表格数据推理模块采用系统提示工程来指导 LLM（例如 GPT-4）推断表格数据，其中明确考虑了数据范围、不确定性、缺失数据值和相应的主观情绪。富有表现力的图表生成模块通过直观的视觉编码和简洁的文本增强了标准图表，以准确传达底层数据和见解。我们通过案例研究、对三位可视化专家的深入访谈以及一项精心设计的 15 名参与者的用户研究，广泛评估了 ChartifyText 对现实世界数据相关文本文档的有效性。结果证明了 ChartifyText 在帮助读者高效、有效地理解数据相关文本方面的实用性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.14331</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ContextIQ：用于情境广告的多模式专家视频检索系统</title>
      <link>https://arxiv.org/abs/2410.22233</link>
      <description><![CDATA[arXiv:2410.22233v2 公告类型：replace-cross 
摘要：上下文广告提供与用户正在观看的内容一致的广告。社交平台和流媒体服务上视频内容的快速增长以及隐私问题增加了对上下文广告的需求。将正确的广告放置在正确的上下文中可以创造无缝且愉快的广告观看体验，从而提高受众参与度，并最终提高广告盈利能力。从技术角度来看，有效的上下文广告需要能够在非常精细的级别理解复杂视频内容的视频检索系统。当前基于联合多模式训练的文本到视频检索模型需要大量数据集和计算资源，这限制了它们的实用性，并且缺乏广告生态系统集成所需的关键功能。我们推出了 ContextIQ，这是一种专为上下文广告设计的多模式专家视频检索系统。 ContextIQ 利用特定模态专家（视频、音频、文字记录（字幕）和元数据，例如对象、动作、情感等）来创建语义丰富的视频表示。我们表明，我们的系统无需联合训练，在多个文本到视频检索基准上就能取得比最先进的模型和商业解决方案更好或相当的结果。我们的消融研究强调了利用多种模态来提高视频检索准确性的好处，而不是单独使用视觉语言模型。此外，我们展示了如何在广告生态系统中将 ContextIQ 等视频检索系统用于情境广告，同时解决与品牌安全和过滤不当内容相关的问题。]]></description>
      <guid>https://arxiv.org/abs/2410.22233</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>INQUIRE：自然世界文本到图像检索基准</title>
      <link>https://arxiv.org/abs/2411.02537</link>
      <description><![CDATA[arXiv:2411.02537v2 公告类型：replace-cross 
摘要：我们推出了 INQUIRE，这是一个文本到图像检索基准，旨在挑战专家级查询的多模态视觉语言模型。INQUIRE 包括 iNaturalist 2024 (iNat24)，这是一个包含 500 万张自然世界图像的新数据集，以及 250 个专家级检索查询。这些查询与 iNat24 中全面标记的所有相关图像配对，总共包含 33,000 个匹配项。查询涵盖物种识别、背景、行为和外观等类别，强调需要细致入微的图像理解和领域专业知识的任务。我们的基准评估了两个核心检索任务：(1) INQUIRE-Fullrank，一个完整的数据集排名任务，以及 (2) INQUIRE-Rerank，一个用于优化前 100 个检索的重新排名任务。对一系列近期多模态模型的详细评估表明，INQUIRE 带来了巨大的挑战，最好的模型未能实现 50% 以上的 mAP@50。此外，我们表明，使用更强大的多模态模型进行重新排序可以提高检索性能，但仍有很大的改进空间。通过专注于科学驱动的生态挑战，INQUIRE 旨在弥合 AI 能力与现实世界科学探究需求之间的差距，鼓励开发有助于加速生态和生物多样性研究的检索系统。我们的数据集和代码可在 https://inquire-benchmark.github.io 上找到]]></description>
      <guid>https://arxiv.org/abs/2411.02537</guid>
      <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>