<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>与自适应功能融合的冷启动推荐的对比度学习</title>
      <link>https://arxiv.org/abs/2502.03664</link>
      <description><![CDATA[ARXIV：2502.03664V1公告类型：新 
摘要：本文提出了一个冷启动推荐模型，该模型集成了对比度学习，旨在解决由于用户和项目交互数据的稀缺性，因此在冷启动方案中，推荐系统的性能退化问题。该模型通过自适应特征选择模块动态调节关键特征的权重，并通过组合多模式特征融合机制，有效地整合用户属性，项目元信息和上下文特征，从而提高建议性能。此外，该模型还引入了一种对比度学习机制，以通过构建正和负样本对来增强特征表示的鲁棒性和概括能力。实验是在Movielens-1M数据集上进行的。结果表明，所提出的模型在HR，NDCG，MRR和召回率方面显着优于主流建议方法，例如矩阵分解，LightGBM，DEEPFM和AUTOREC，尤其是在冷启动场景中。消融实验进一步验证了每个模块在改善模型性能中的关键作用，并且学习率敏感性分析表明，中等学习率对于模型的优化效果至关重要。这项研究不仅为冷启动问题提供了新的解决方案，而且还为在推荐系统中应用对比度学习提供了重要的参考。将来，该模型有望在更广泛的方案中发挥作用，例如实时建议和跨域建议。]]></description>
      <guid>https://arxiv.org/abs/2502.03664</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型来提高知识的基于图形的建议</title>
      <link>https://arxiv.org/abs/2502.03715</link>
      <description><![CDATA[ARXIV：2502.03715V1公告类型：新 
摘要：基于知识图的建议由于能够利用丰富的语义关系而引起了重大关注。但是，构建和维护知识图（kgs）是资源密集的，kgs的准确性可能会遭受嘈杂，过时或无关的三胞胎。大型语言模型（LLMS）的最新进展为提高推荐任务的质量和相关性提供了一种有希望的方法。尽管如此，将LLM集成到基于KG的系统中仍然带来了挑战，例如有效增加KG，解决幻觉并开发有效的联合学习方法。在本文中，我们提出了与LLM增强（CKG-LLMA）的基于信心的推荐框架，该框架是一个新颖的框架，将KGS和LLMS结合在一起，以进行推荐任务。该框架包括：（1）一种基于LLM的子图增强器，用于丰富具有高质量信息的kg，（2）一种信心意识到的消息传播机制，用于过滤嘈杂的三胞胎，以及（3）一种双视的对比度学习方法来集成整合用户项目互动和kg数据。此外，我们采用信心意识的解释生成过程来指导LLM，以为建议提供现实的解释。最后，广泛的实验证明了CKG-LLMA在多个公共数据集中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.03715</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>反事实查询重写以使用历史相关性反馈</title>
      <link>https://arxiv.org/abs/2502.03891</link>
      <description><![CDATA[ARXIV：2502.03891V1公告类型：新 
摘要：当检索系统收到以前遇到的查询时，先前的相关反馈（例如点击或明确的判断）可以帮助改善检索结果。但是，以前相关文档的内容可能已更改，或者该文档可能不再可用。尽管有这种发展的语料库，但我们反映了这些先前相关的文档作为相关信号。在本文中，我们提出了重写用户查询的方法，并将其与直接使用先前QREL进行排名的系统进行比较。我们通过从先前相关的文档中提取的术语或得出所谓的钥匙来扩展查询，这些术语将先前相关的文档对当前语料库的顶部进行排名。我们在CLEF寿命方案中的评估表明，具有历史相关性反馈的重写查询提高了检索效率，甚至胜过计算昂贵的基于变压器的方法。]]></description>
      <guid>https://arxiv.org/abs/2502.03891</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>交叉编码器可以产生有用的句子嵌入吗？</title>
      <link>https://arxiv.org/abs/2502.03552</link>
      <description><![CDATA[ARXIV：2502.03552V1公告类型：交叉 
摘要：交叉编码器（CES）接受句子对训练以检测相关性。由于CES需要在推理时对句子对，因此普遍的视图是它们只能用作信息检索管道中的重新率。双重编码器（DES）用于嵌入句子，其中句子对由两个单独的编码器编码，并在训练中具有共享权重，并且如果句子相关，则可以确保对副词的嵌入在向量空间中附近。但是，需要更大的数据集进行训练，并且不如CES准确。我们报告了一个奇怪的发现，即实际上可以在信息检索管道中使用较早的CES层的嵌入。我们展示了如何利用CES以5.15倍的推理时间提炼较轻的重量DE。]]></description>
      <guid>https://arxiv.org/abs/2502.03552</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM对齐作为检索器优化：信息检索透视图</title>
      <link>https://arxiv.org/abs/2502.03699</link>
      <description><![CDATA[ARXIV：2502.03699V1公告类型：交叉 
摘要：大型语言模型（LLMS）彻底改变了人工智能，具有推理，编码和沟通能力，并跨越行业的创新。它们的真正潜力取决于有效的一致性，以确保正确，值得信赖和道德行为，以应对诸如错误信息，幻觉，偏见和滥用等挑战。尽管现有的加固学习（RL）基于对齐方式是复杂的，但直接优化方法提供了更简单的替代方法。在这项工作中，我们通过利用既定信息检索（IR）原理来介绍一种新颖的LLM对齐方式直接优化方法。我们提出了一个系统的框架，该框架将LLM对齐和IR方法桥接，将LLM生成和奖励模型映射到IR的Retriever-Reranker范式中。在此基础的基础上，我们建议LLM Alignment作为回猎犬偏好优化（LARPO），这是一种新的对齐方法，可提高整体对齐质量。广泛的实验验证了LARPO的有效性，分别对羊角藻和Mixeval-Hard的38.9％和13.7％的平均有效性得到改善。我们的工作开辟了新的途径，以通过整合IR基金会来推进LLM对齐，并为未来的研究提供了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2502.03699</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MRAMG-BENCH：多模式检索多模式生成的超越文本基准</title>
      <link>https://arxiv.org/abs/2502.04176</link>
      <description><![CDATA[ARXIV：2502.04176V1公告类型：交叉 
摘要：通过将外部知识整合到生成模型中，在提高响应准确性和相关性方面的最新进展（RAG）在增强响应准确性和相关性方面表现出色。但是，现有的抹布方法主要集中于提供仅文本的答案，即使在多模式检索的生成场景中也是如此。在这项工作中，我们介绍了多模式检索仪的多模式生成（MRAMG）任务，该任务旨在生成结合文本和图像的答案，并完全利用语料库中的多模式数据。尽管这项任务很重要，但仍有明显的缺乏全面的基准来有效评估MRAMG性能。为了弥合这一差距，我们介绍了Mramg-Bench，这是一个经过精心策划的人类宣传的数据集，其中包括4,346个文档，14,190张图像和4,800个QA对，来自三个类别：网络数据，学术报纸，学术报纸和生活方式。数据集结合了各种难度级别和复杂的多图像场景，为评估多模式生成任务提供了强大的基础。为了促进严格的评估，我们的MRAMG-BENCH结合了统计和基于LLM的指标的全面套件，从而可以对MRAMG任务中流行生成模型的性能进行详尽的分析。此外，我们提出了一个有效的多模式答案生成框架，该框架利用LLM和MLLM来生成多模式响应。我们的数据集可在以下网址找到：https：//huggingface.co/mramg。]]></description>
      <guid>https://arxiv.org/abs/2502.04176</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数字网务：搜索引擎结果的审核显示了以色列 - 巴勒斯坦冲突上查询的裁缝</title>
      <link>https://arxiv.org/abs/2502.04266</link>
      <description><![CDATA[ARXIV：2502.04266V1公告类型：交叉 
摘要：根据用户偏好，位置等，使用自定义算法量身定制搜索结果，通常被视为可靠的信息网关，量身定制搜索结果。尽管这对于常规查询可能很有用，但当主题敏感或有争议，可能会限制暴露于各种观点并增加极化时，它引起了人们的关注。
  为了检查这种裁缝的程度，我们专注于以色列 - 巴勒斯坦冲突，并开发了一种隐私保护工具来审核三种搜索引擎的行为：DuckDuckgo，Google和Yahoo。我们的研究重点介绍了两个主要问题：（1）搜索有关冲突的搜索结果如何在不同用户之间有所不同？ （2）这些结果是否受用户的位置和浏览历史记录的影响？
  我们的发现显示了基于位置和浏览偏好的显着定制，这与以前的研究发现仅针对一般主题的轻度个性化。此外，与冲突相关的查询比无关的查询更定制，结果并不是关于冲突的刻画的中立。]]></description>
      <guid>https://arxiv.org/abs/2502.04266</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有足够的专家吗？从大语言模型中检索定量知识</title>
      <link>https://arxiv.org/abs/2402.07770</link>
      <description><![CDATA[ARXIV：2402.07770V2公告类型：替换 
摘要：大型语言模型（LLM）已被广泛研究其产生令人信服的自然语言序列的能力，但是对定量信息检索的实用性知之甚少。在这里，我们探讨了LLMs作为定量知识检索的一种机制，以帮助两个数据分析任务：启发贝叶斯模型的先前分布和丢失数据的插图。我们介绍了一个框架，该框架利用LLM来通过引起类似专家的先验知识并推出丢失的数据来增强贝叶斯的工作流程。经过不同的数据集测试，这种方法可以提高预测准确性并降低数据需求，从而在医疗保健，环境科学和工程应用中具有巨大潜力。我们讨论将LLM视为“专家”的含义和挑战。]]></description>
      <guid>https://arxiv.org/abs/2402.07770</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MA4DIV：用于搜索结果多元化的多代理增强学习</title>
      <link>https://arxiv.org/abs/2403.17421</link>
      <description><![CDATA[Arxiv：2403.17421V3公告类型：替换 
摘要：搜索结果多元化（SRD）旨在确保排名列表中的文档涵盖广泛的子主题，在信息检索和Web搜索中是一个重大且广泛研究的问题。现有方法主要利用“贪婪选择”的范式，即一次选择一个具有最高多样性得分的文档，或优化目标函数的近似值。这些方法往往效率低下，并且很容易被困在次优状态下。为了应对这些挑战，我们引入了多代理增强学习（MARL），以实现搜索结果多样性，这称为MA4DIV。在这种方法中，每个文档都是一个代理，搜索结果多元化被建模为多个代理之间的合作任务。通过将SRD排名问题建模为合作MARL问题，这种方法可以直接优化多样性指标，例如$ \ alpha $ -ndcg，同时达到高训练效率。我们在公共TREC数据集和工业环境中进行了较大规模的数据集进行了实验。经验表明，与现有基准相比，MA4DIV在有效性和效率方面取得了重大提高，尤其是在工业数据集上。可以在https://github.com/chenyiqun/ma4div上看到MA4DIV的代码。]]></description>
      <guid>https://arxiv.org/abs/2403.17421</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tourrank：利用大型语言模型进行以锦标赛为灵感的策略进行排名</title>
      <link>https://arxiv.org/abs/2406.11678</link>
      <description><![CDATA[Arxiv：2406.11678V2公告类型：替换 
摘要：大语言模型（LLMS）越来越多地用于零摄像文档排名中，从而得出值得称赞的结果。但是，在LLM中仍存在一些重大挑战以进行排名：（1）LLMS受到有限的输入长度的限制，从而无法同时处理大量文档； （2）输出文档序列受文档的输入顺序影响，导致排名不一致； （3）在成本和排名绩效之间取得平衡是具有挑战性的。为了解决这些问题，我们介绍了一种名为Tourrank的新型文档排名方法，该方法灵感来自体育比赛，例如FIFA世界杯。具体而言，我们1）克服输入长度的限制，并通过合并类似于运动比赛的平行组阶段的多阶段分组策略来减少排名延迟； 2）通过使用点系统集合多个排名结果来提高输入订单的排名绩效和鲁棒性。我们在TREC DL数据集和Beir Benchmark上使用不同的LLMS测试Tourrank。实验结果表明，Tourrank以适度的成本提供最先进的性能。可以在https://github.com/chenyiqun/tourrank上看到Tourrank的代码。]]></description>
      <guid>https://arxiv.org/abs/2406.11678</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>COLPALI：有效的文档检索使用视觉语言模型</title>
      <link>https://arxiv.org/abs/2407.01449</link>
      <description><![CDATA[ARXIV：2407.01449V5公告类型：替换 
摘要：文档是视觉上丰富的结构，可以通过文本传达信息，还可以传达信息，页面布局，表甚至字体。由于现代检索系统主要依赖于从文档页面提取的文本信息来索引文档 - 通常通过冗长而脆弱的过程 - 他们很难有效利用关键的视觉提示。这限制了它们在许多实际文档检索应用中的功能，例如检索增强发电（RAG）。为了在视觉上丰富的文档检索中进行基准当前系统，我们介绍了视觉文档检索基准Vidore，由各种页面级检索任务组成，这些任务涵盖了多个域，语言和实际设置。现代系统的固有复杂性和性能缺点激发了一个新概念。通过直接嵌入文档页面的图像来进行文档检索。我们释放了Colpali，这是一种视觉语言模型，该模型训练有素，可从文档页面的图像中产生高质量的多矢量嵌入。结合了较晚的互动匹配机制，Colpali在很大程度上胜过现代文档的检索管道，同时非常简单，更快，端到端训练。我们在https://hf.co/vidore上发布模型，数据，代码和基准。]]></description>
      <guid>https://arxiv.org/abs/2407.01449</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SPREC：基于DEBIAS的自我播放推荐</title>
      <link>https://arxiv.org/abs/2412.09243</link>
      <description><![CDATA[ARXIV：2412.09243V3公告类型：替换 
摘要：大型语言模型（LLM）在推荐系统中引起了极大的关注。当前的工作主要应用监督的微调（SFT）来调整模型以进行建议任务。但是，在积极示例上的SFT仅限制了模型与用户偏好保持一致的能力。为了解决这个问题，研究人员最近引入了直接偏好优化（DPO），该优化将LLMS与脱机偏好排名数据明确与用户偏好保持一致。但是，我们发现DPO固有地将模型偏向几个项目，加剧了过滤器气泡问题并最终降低用户体验。
  在本文中，我们提出了SPREC，这是一种新型的自我播放框架，旨在减轻过度责任心并提高公平性，而无需其他数据或手动干预。在每个自我播放迭代中，该模型都会进行SFT步骤，然后进行DPO步骤，将离线相互作用数据视为正样本，而从上一个迭代中的预测输出则作为负样本。这有效地使用模型的逻辑可以自适应地抑制偏见的项目来重新权重。在多个现实世界数据集上进行的广泛实验表明，SPREC在增强建议准确性和公平性方面的有效性。该实施可通过https://github.com/regionch/sprec获得]]></description>
      <guid>https://arxiv.org/abs/2412.09243</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TD3：基于塔克分解的数据集蒸馏方法，用于顺序建议</title>
      <link>https://arxiv.org/abs/2502.02854</link>
      <description><![CDATA[ARXIV：2502.02854V2公告类型：替换 
摘要：在以数据为中心的AI时代，推荐系统的重点已从以模型为中心的创新转变为以数据为中心的方法。现代AI模型的成功建立在大型数据集上，但这也导致了巨大的培训成本。数据集蒸馏已成为关键解决方案，凝结了大型数据集以加速模型训练，同时保留模型性能。但是，凝结离散并顺序相关的用户项目交互，尤其是在广泛的项目集中，带来了巨大的挑战。本文介绍了\ textbf {td3}，这是一种新颖的\ textbf {t} ucker \ textbf {d}基于\ textbf {d} ataset \ textbf {d} ataset \ textbf {d} istillation istillation方法，用于元学习框架内，该方法用于元素推荐。 TD3从原始数据中提取完全表达的\ emph {合成序列摘要}。为了有效地降低计算复杂性并提取精致的潜在模式，塔克分解将摘要分解为四个因素：\ emph {synthetic用户潜伏因子}，\ emph {暂时性动力学因子}，\ emph {共享项目潜在因子}和a \ \ \ \ \ \ \ \ \ \ \ \ \ \ \建模其互连的emph {关系核心}。此外，提出了一个在双层优化中的替代目标，以使对原始数据和合成序列摘要训练的模型提取到na \“ ive性能匹配方法之外。技术允许学习者紧密地拟合合成的摘要，以确保其在\ emph {ofter-loop}中的准确更新，以加速优化过程并解决长期的依赖性，并用于BI级优化对多个公共数据集的分析证实了拟议设计的优势和跨架构的概括性。]]></description>
      <guid>https://arxiv.org/abs/2502.02854</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与Hier-Sucb进行交互式可视化建议</title>
      <link>https://arxiv.org/abs/2502.03375</link>
      <description><![CDATA[ARXIV：2502.03375V2公告类型：替换 
摘要：可视化建议旨在实现大规模数据集的快速视觉分析。在实际情况下，必须快速收集和理解用户偏好，以涵盖来自不同背景的用户，包括不同的技能水平和分析任务。个性化可视化建议的先前方法是非互动的，并且依靠新用户的初始用户数据。结果，这些模型无法有效地探索选项或适应实时反馈。为了解决此限制，我们提出了一个交互式个性化可视化建议（PVISREC）系统，该系统从以前的交互中学习了用户反馈。为了获得更多的交互式和准确的建议，我们提出了Hier-Sucb，这是PVISREC设置中的上下文组合半伴侣。从理论上讲，我们表现出改善的整体遗憾，其排名与相同的时间相同，但行动空间的排名提高了。我们通过广泛的实验进一步证明了HIER-SUCB的有效性，在可视化建议的情况下，它与离线方法相媲美，并优于其他强盗算法。]]></description>
      <guid>https://arxiv.org/abs/2502.03375</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于基于分析的压缩传感的展开网络的概括分析</title>
      <link>https://arxiv.org/abs/2303.05582</link>
      <description><![CDATA[ARXIV：2303.05582V2公告类型：替换 - 交叉 
摘要：展开的网络在压缩传感（CS）字段中显示出令人鼓舞的结果。然而，对其概括能力的调查仍处于起步阶段。在本文中，我们对基于ADMM的最先进的展开网络进行了概括分析，该网络共同学习了CS的解码器和稀疏的冗余分析操作员。为此，我们首先对可学习的Sparsifier强加了结构性约束，该稀疏器参数为网络的假设类别。对于后者，我们估计其Rademacher的复杂性。在此估计中，我们为检查网络提供了概括误差界（类似于图层数的平方根）。最后，对我们的理论的有效性进行了评估，并在合成和现实世界的数据集上进行了与最先进的展开网络的数值比较。我们的实验结果表明，我们提出的框架符合我们的理论发现，并且在所有数据集中始终超过基线。]]></description>
      <guid>https://arxiv.org/abs/2303.05582</guid>
      <pubDate>Fri, 07 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>