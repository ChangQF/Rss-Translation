<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>反事实学习驱动的表征解缠，实现搜索增强推荐</title>
      <link>https://arxiv.org/abs/2411.18631</link>
      <description><![CDATA[arXiv:2411.18631v1 公告类型：新 
摘要：对于互联网平台中的推荐系统，搜索活动通过与项目的查询-点击交互提供了对用户兴趣的额外洞察，因此被广泛用于增强个性化推荐。然而，这些交互项目不仅具有与用户兴趣相匹配的可迁移特征，对推荐领域有帮助，而且具有与用户在搜索领域的独特意图相关的特征。大多数当前的搜索增强推荐方法都忽略了项目特征的这种领域差距。它们直接将这些搜索行为纳入推荐，从而引入部分负迁移。为了解决这个问题，我们提出了一个反事实学习驱动的搜索增强推荐表示解缠框架，该框架基于一个普遍的信念，即用户点击查询下的项目不仅仅是因为项目查询匹配，还因为该项目具有用户感兴趣的与查询无关的一般特征（例如颜色或样式）。这些一般特征排除了查询中包含的搜索特定意图的反映，确保与用户的潜在兴趣纯粹匹配以补充推荐。根据反事实思维，如果我们在搜索中删除与查询相关的项目特征，用户对项目的偏好和查询匹配将如何变化，我们利用搜索查询来构建反事实信号以解开项目表示，仅隔离与查询无关的一般特征。这些表示随后为推荐场景启用特征增强和数据增强。在真实数据集上的全面实验表明，ClardRec 在协同过滤和顺序推荐场景中都是有效的。]]></description>
      <guid>https://arxiv.org/abs/2411.18631</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一生成式检索和密集检索以实现顺序推荐</title>
      <link>https://arxiv.org/abs/2411.18814</link>
      <description><![CDATA[arXiv:2411.18814v1 公告类型：新
摘要：顺序密集检索模型利用先进的序列学习技术来计算项目和用户表示，然后通过用户和所有项目表示之间的内积计算，将这些表示用于对用户的相关项目进行排名。但是，这种方法需要为每个项目存储一个唯一的表示，随着项目数量的增加，内存需求会很大。相比之下，最近提出的生成检索范式提供了一种有前途的替代方案，它使用在封装项目语义信息的语义 ID 上训练的生成模型直接预测项目索引。尽管它具有大规模应用的潜力，但在公平条件下对生成检索和顺序密集检索进行全面比较仍然缺乏，留下了有关性能和计算权衡的悬而未决的问题。为了解决这个问题，我们在学术基准的受控条件下比较了这两种方法，并提出了 LIGER（利用密集检索进行生成检索），这是一种结合了这两种广泛使用的方法优势的混合模型。 LIGER 将顺序密集检索集成到生成检索中，减轻了性能差异并增强了所评估数据集中的冷启动项目推荐。 这种混合方法提供了对这些方法之间权衡的见解，并展示了小规模基准中推荐系统的效率和有效性的改进。]]></description>
      <guid>https://arxiv.org/abs/2411.18814</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>库存过剩让人头疼？通过无偏见的产品捆绑销售来推广长尾商品</title>
      <link>https://arxiv.org/abs/2411.19107</link>
      <description><![CDATA[arXiv:2411.19107v1 公告类型：新
摘要：产品捆绑旨在将一组主题相关的商品组织成一个组合包，以方便发货和商品促销。为了增加新鲜或库存过剩产品的曝光率，卖家通常将这些商品与热门产品捆绑在一起以清仓。这个特定的任务可以表述为一个长尾产品捆绑场景，它利用用户与商品的交互来定义每个商品的受欢迎程度。预先提取的用户反馈特征中固有的流行度偏差和其他与流行度无关的知识利用不足可能会迫使传统的捆绑方法寻找更受欢迎的商品，从而难以应对这种长尾捆绑场景。通过直观和实证分析，我们找到了这一挑战的核心解决方案，即最大限度地挖掘无流行度特征并有效地将它们纳入捆绑过程。为了实现这一目标，我们提出了一个面向提炼模态的知识转移框架（DieT），以有效对抗用户反馈特征所引入的误解的流行度偏见，并坚持现实世界捆绑行为背后的初衷。具体而言，DieT 首先提出了无流行度协作分布建模模块（PCD），以从捆绑项目视图中捕获与流行度无关的信息，这在长尾捆绑场景中被证明是最有效的，可以实现定向信息传输。通过量身定制的无偏捆绑感知知识转移模块（UBT），DieT 可以突出无流行度特征的重要性，同时通过知识提炼范式减轻长尾场景中用户反馈特征的负面影响。在两个真实数据集上进行的大量实验证明了 DieT 在长尾捆绑场景中优于一系列 SOTA 方法。]]></description>
      <guid>https://arxiv.org/abs/2411.19107</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引入三个新的分层文本分类基准数据集</title>
      <link>https://arxiv.org/abs/2411.19119</link>
      <description><![CDATA[arXiv:2411.19119v1 公告类型：新
摘要：分层文本分类 (HTC) 是一种自然语言处理任务，其目标是将文本文档从结构化的类层次结构中分类为一组类。已经提出了许多 HTC 方法，这些方法试图以各种方式利用类层次结构信息来提高分类性能。基于机器学习的分类方法需要大量的训练数据，最常见的是通过三个已建立的基准数据集进行比较，其中包括 Web Of Science (WOS)、路透社语料库第 1 卷第 2 版 (RCV1-V2) 和纽约时报 (NYT) 数据集。然而，除了有据可查的 RCV1-V2 数据集外，这些数据集没有附带详细的描述方法。在本文中，我们在研究出版物领域介绍了三个新的 HTC 基准​​数据集，这些数据集包括来自 Web of Science 出版物数据库的论文标题和摘要。我们首先创建两个基线数据集，它们使用现有的基于期刊和引文的分类模式。由于这两种现有模式各自存在缺点，我们提出了一种结合它们的分类以提高数据集的可靠性和鲁棒性的方法。我们使用基于聚类的分析评估了这三个创建的数据集，并表明我们提出的方法可以生成更高质量的数据集，其中属于同一类的文档在语义上与其他数据集相比更相似。最后，我们提供了这三个新数据集上四种最先进的 HTC 方法的分类性能，为未来基于机器学习的科学出版物分类技术研究提供基础。]]></description>
      <guid>https://arxiv.org/abs/2411.19119</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大规模互惠推荐系统的并行和小批量稳定匹配</title>
      <link>https://arxiv.org/abs/2411.19214</link>
      <description><![CDATA[arXiv:2411.19214v1 公告类型：新
摘要：互惠推荐系统 (RRS) 在在线双边匹配平台（例如在线工作或约会市场）中至关重要，因为它们需要考虑匹配双方的偏好。这些平台上对部分用户的推荐集中会破坏他们的匹配机会并减少匹配总数。为了最大限度地提高市场参与者之间的预期匹配总数，具有可转移效用的稳定匹配理论已应用于 RRS。然而，计算复杂度和内存效率随着用户数量的增加而成倍增加，因此很难为多个用户实现稳定的匹配算法。在本研究中，我们提出了使用并行和小批量计算的互惠推荐模型的新方法，以提高稳定匹配优化过程的计算时间和空间效率。对真实数据和合成数据的实验证实，我们基于稳定匹配理论的 RRS 提高了计算速度，并且能够使用单个图形处理单元图形卡处理多达一百万个样本的大规模数据，而不会丢失匹配计数。]]></description>
      <guid>https://arxiv.org/abs/2411.19214</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的零索引互联网搜索增强生成</title>
      <link>https://arxiv.org/abs/2411.19478</link>
      <description><![CDATA[arXiv:2411.19478v1 公告类型：新
摘要：检索增强生成已成为增强大型语言模型性能的有效方法。这种方法通常依赖于内部检索模块，该模块使用各种索引机制来管理静态预处理语料库。然而，当需要将生成推理期间未更新到语料库中的最新信息集成到语料库中时，这种范式往往不够用。在本文中，我们探索了一种替代方法，该方法利用标准搜索引擎 API 动态集成最新的在线信息（不为任何固定语料库维护任何索引），从而提高生成内容的质量。我们设计了一个基于 LLM 的协作范式，其中包括：(i) 一个解析器-LLM，它确定是否需要互联网增强生成，如果需要，则通过单一推理提取搜索关键字；(ii) 一种混合排名策略，对检索到的 HTML 文件进行重新排名，以消除从搜索引擎 API 引入的偏见；以及 (iii) 提取器-LLM，它可以准确高效地从每个 HTML 文件中的新鲜内容中提取相关信息。我们进行了广泛的实证研究，以评估这种互联网搜索增强生成范式的性能。实验结果表明，我们的方法生成的内容质量显著提高。我们的系统已成功部署在生产环境中，以满足 01.AI 的生成推理请求。]]></description>
      <guid>https://arxiv.org/abs/2411.19478</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ContextGNN：超越双塔推荐系统</title>
      <link>https://arxiv.org/abs/2411.19513</link>
      <description><![CDATA[arXiv:2411.19513v1 公告类型：新
摘要：推荐系统主要使用双塔架构，通过各自嵌入的内积来评估用户-项目排名。然而，双塔模型的一个关键限制是它们学习用户和项目的成对不可知的表示。相比之下，成对表示要么由于其二次复杂度而扩展性较差，要么对候选对的排名限制过多。为了解决这些问题，我们引入了基于上下文的图神经网络 (ContextGNNs)，这是一种用于推荐系统中链接预测的新型深度学习架构。该方法采用成对表示技术来表示位于用户本地子图中的熟悉项目，同时利用双塔表示来促进探索性项目的推荐。然后，最终网络预测如何将成对和双塔推荐融合到单个项目排名中。我们证明 ContextGNN 能够适应不同的数据特​​征，并且在多种实际推荐任务中优于传统和基于 GNN 的现有方法，平均性能提高 20%。]]></description>
      <guid>https://arxiv.org/abs/2411.19513</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中基于 LLM 的解释的回顾</title>
      <link>https://arxiv.org/abs/2411.19576</link>
      <description><![CDATA[arXiv:2411.19576v1 公告类型：新 
摘要：大型语言模型 (LLM)（例如 LLaMA 和 ChatGPT）的兴起为通过提高可解释性来增强推荐系统开辟了新的机会。本文提供了系统的文献综述，重点是利用 LLM 为推荐生成解释——这是促进透明度和用户信任的关键方面。我们在 ACM 计算文献指南中进行了全面搜索，涵盖了从 ChatGPT 发布（2022 年 11 月）到现在（2024 年 11 月）的出版物。我们的搜索产生了 232 篇文章，但在应用纳入标准后，只有 6 篇被确定为直接涉及使用 LLM 解释推荐。这种稀缺性凸显了尽管 LLM 兴起，但它们在可解释推荐系统中的应用仍处于早期阶段。我们分析这些精选研究以了解当前的方法，确定挑战并为未来的研究提出方向。我们的研究结果强调了 LLM 改善推荐系统解释的潜力，并鼓励开发更加透明和以用户为中心的推荐解释解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.19576</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解您的 RAG：用于评估 RAG 系统的数据集分类和生成策略</title>
      <link>https://arxiv.org/abs/2411.19710</link>
      <description><![CDATA[arXiv:2411.19710v1 公告类型：新
摘要：检索增强生成 (RAG) 系统是大型语言模型 (LLM) 在行业中的广泛应用。虽然存在许多工具使开发人员能够构建自己的系统，但使用反映系统用例的数据集在本地测量其性能是一项技术挑战。该问题的解决方案范围从非特定和廉价（大多数公共数据集）到特定和昂贵（从本地文档生成数据）。在本文中，我们表明使用公共问答 (Q&amp;A) 数据集来评估检索性能可能导致非最佳系统设计，并且用于 RAG 数据集生成的常用工具可能导致数据不平衡。我们根据通过标签和通过标签目标数据生成对 RAG 数据集的表征提出了解决这些问题的解决方案。最后，我们表明经过微调的小型 LLM 可以有效地生成问答数据集。我们相信这些观察对于 RAG 系统开发的了解数据步骤非常有价值。]]></description>
      <guid>https://arxiv.org/abs/2411.19710</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨领域推荐与大型语言模型</title>
      <link>https://arxiv.org/abs/2411.19862</link>
      <description><![CDATA[arXiv:2411.19862v1 公告类型：新
摘要：跨域推荐 (CDR) 已成为单域推荐系统面临的冷启动问题的一种有希望的解决方案。然而，现有的 CDR 模型依赖于复杂的神经架构、大型数据集和大量计算资源，这使得它们在数据稀缺场景或简单性至关重要时效率较低。在这项工作中，我们利用大型语言模型 (LLM) 的推理能力，并探索它们在跨多个域对的 CDR 域中的性能。我们介绍了两种为 CDR 量身定制的新型提示设计，并证明 LLM 在有效提示时，在评级预测和排名任务中跨各种指标和域组合的表现优于最先进的 CDR 基线。这项工作弥合了 LLM 和推荐系统之间的差距，展示了它们作为有效跨域推荐器的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.19862</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ICLERB：上下文学习嵌入和重新排序基准</title>
      <link>https://arxiv.org/abs/2411.18947</link>
      <description><![CDATA[arXiv:2411.18947v1 公告类型：交叉 
摘要：上下文学习 (ICL) 通过调节具有相关信息的提示，使大型语言模型 (LLM) 能够执行新任务。检索增强生成 (RAG) 通过在查询时将检索到的文档合并到 LLM 的上下文中来增强 ICL。然而，传统的检索方法侧重于语义相关性，将检索视为搜索问题。在本文中，我们提出将 ICL 的检索重新定义为推荐问题，旨在选择在 ICL 任务中最大化效用的文档。我们引入了上下文学习嵌入和重新排序基准 (ICLERB)，这是一种新颖的评估框架，它根据检索器在 ICL 设置中增强 LLM 准确性的能力对其进行比较。此外，我们提出了一种新颖的强化学习从 AI 反馈进行排名 (RLRAIF) 算法，旨在使用来自 LLM 的最少反馈来微调检索模型。我们的实验结果揭示了 ICLERB 与现有基准之间的显著差异，并表明使用我们的 RLRAIF 算法进行微调的小型模型优于大型最先进的检索模型。这些发现凸显了现有评估方法的局限性以及对适用于 ICL 的专门基准和训练策略的需求。]]></description>
      <guid>https://arxiv.org/abs/2411.18947</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>本体对齐中上下文描述符的集成以丰富语义对应</title>
      <link>https://arxiv.org/abs/2411.19113</link>
      <description><![CDATA[arXiv:2411.19113v1 公告类型：交叉 
摘要：本文提出了一种使用上下文描述符进行语义本体对齐的新方法。开发了一种形式化方法，可以集成基本描述符和上下文描述符来创建全面的知识模型。展示了语义方法的层次结构和用于分析概念之间潜在冲突的数学工具，特别是在人工智能背景下的“透明度”和“隐私”示例中。实验研究表明，在实施上下文描述符后，本体对齐指标得到了显着改善，尤其是在隐私、责任和自由与自主领域。上下文描述符的应用实现了平均约 4.36% 的整体改进。结果表明，所提出的方法可以更准确地反映知识的复杂性及其上下文依赖性。]]></description>
      <guid>https://arxiv.org/abs/2411.19113</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TQA-Bench：使用可扩展上下文和符号扩展评估多表问答的 LLM</title>
      <link>https://arxiv.org/abs/2411.19504</link>
      <description><![CDATA[arXiv:2411.19504v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的出现为复杂的数据管理任务带来了巨大的机遇，尤其是在复杂的多表关系数据上的问答 (QA) 方面。尽管取得了重大进展，但由于分析异构表结构的固有复杂性和序列化关系数据的潜在大规模性，系统地评估多表 QA 上的 LLM 仍然是一项关键挑战。现有的基准测试主要侧重于单表 QA，无法捕捉跨多个关系表推理的复杂性，而这正是金融、医疗保健和电子商务等现实世界领域所需要的。为了弥补这一差距，我们提出了 TQA-Bench，这是一种新的多表 QA 基准测试，旨在评估 LLM 在处理关系数据上的复杂 QA 任务方面的能力。我们的基准测试结合了来自真实公共数据集的各种关系数据库实例，并引入了一种灵活的采样机制来创建具有不同多表上下文长度（从 8K 到 64K 个标记）的任务。为了确保稳健性和可靠性，我们将符号扩展集成到评估框架中，从而能够评估 LLM 推理能力，而不仅仅是简单的数据检索或概率模式匹配。我们系统地评估了一系列 LLM，包括开源和闭源的，模型规模从 70 亿到 700 亿个参数。我们进行了广泛的实验，揭示了 LLM 在多表 QA 中性能的关键见解，突出了在复杂的数据驱动环境中推进其应用的挑战和机遇。我们的基准测试实施和结果可在 https://github.com/Relaxed-System-Lab/TQA-Bench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.19504</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Graph RAG 进行汽车故障分析的知识管理</title>
      <link>https://arxiv.org/abs/2411.19539</link>
      <description><![CDATA[arXiv:2411.19539v1 公告类型：交叉 
摘要：本文介绍了一种使用检索增强生成 (RAG) 和大型语言模型 (LLM) 和知识图谱 (KG) 进行汽车故障分析的知识管理系统。在汽车行业，对从经验丰富的工程师到年轻工程师的故障分析知识转移的需求日益增长。然而，故障事件是连锁反应中发生的现象，初学者很难对其进行分析。虽然可以描述语义关系和结构信息的知识图谱由于其表示组件之间关系的能力而可以有效地表示故障事件，但是 KG 中的信息量很大，因此对于年轻工程师来说，从 KG 中提取和理解子图是一项挑战。另一方面，人们对使用 Graph RAG 的兴趣日益浓厚，Graph RAG 是一种结合了 LLM 和 KG 进行知识管理的 RAG。然而，当将当前的 Graph RAG 框架与现有的汽车故障知识图谱结合使用时，会出现一些问题，因为很难为非 LLM 构建的知识图谱数据库生成可执行查询。为了解决这个问题，我们专注于优化现有知识图谱的 Graph RAG 管道。使用原始问答数据集，与当前方法相比，所提出方法生成的句子的 ROUGE F1 分数平均提高了 157.6%。这凸显了所提出方法对汽车故障分析的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.19539</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TakeLab Retriever：人工智能驱动的克罗地亚新闻媒体文章搜索引擎</title>
      <link>https://arxiv.org/abs/2411.19718</link>
      <description><![CDATA[arXiv:2411.19718v1 公告类型：交叉 
摘要：TakeLab Retriever 是一个人工智能驱动的搜索引擎，旨在发现、收集和语义分析来自克罗地亚新闻媒体的新闻文章。它提供了对克罗地亚在线新闻媒体的历史和当前格局的独特视角，使其成为研究人员寻求发现通用搜索引擎无法提供的趋势、模式和相关性的重要工具。TakeLab 检索器采用尖端的自然语言处理 (NLP) 方法，使用户能够通过 Web 应用程序使用命名实体、短语和主题筛选文章。本技术报告分为两部分：第一部分解释了如何使用 TakeLab Retriever，而第二部分详细介绍了它的设计。在第二部分中，我们还解决了所涉及的软件工程挑战，并提出了开发基于微服务的语义搜索引擎的解决方案，该引擎能够处理过去二十年发布的一千万多篇新闻文章。]]></description>
      <guid>https://arxiv.org/abs/2411.19718</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>