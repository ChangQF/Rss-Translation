<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 28 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>PCL：推荐系统中用户建模的迅速持续学习</title>
      <link>https://arxiv.org/abs/2502.19628</link>
      <description><![CDATA[ARXIV：2502.19628V1公告类型：新 
摘要：大型电子商务平台中的用户建模旨在通过合并各种客户活动来优化用户体验。针对一项任务的传统模型通常集中在特定的业务指标上，忽略了全面的用户行为，从而限制了其有效性。为了开发更广泛的用户表示，一些现有工作采用多任务学习（MTL）方法。但是，他们都面临优化失衡和适应新任务的效率低下的挑战。持续学习（CL）允许模型逐步学习新任务，已成为解决MTL局限性的解决方案。但是，CL面临着灾难性遗忘的挑战，在模型正在学习新任务时，以前学习的知识就会丢失。受到迅速调整语言模型（PLM）的成功的启发，我们提出了PCL，这是一个基于及时的用户建模的持续学习框架，该框架将位置提示作为每个任务的外部记忆，保留知识并减轻灾难性的遗忘。此外，我们设计上下文提示，以捕获和利用及时调整期间的任务间关系。我们对现实世界数据集进行了广泛的实验，以证明PCL的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.19628</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教授密集的检索模型，专门研究列表蒸馏和LLM数据扩展</title>
      <link>https://arxiv.org/abs/2502.19712</link>
      <description><![CDATA[ARXIV：2502.19712V1公告类型：新 
摘要：虽然当前最新的密集检索模型表现出强大的外域概括，但它们可能无法捕获细微的领域特定知识。原则上，对这些模型进行专门检索任务的微调应比依靠一件大小的模型产生更高的有效性，但实际上，结果可能会令人失望。我们表明，使用Infonce损失的标准微调方法即使对于特定于域特异性的情况，也可以意外地降低有效性，而不是提高效率。即使应用了广泛采用的技术，例如硬性采矿和负面滴定，这也是如此。为了解决这个问题，我们探索了一种培训策略，该培训策略使用列表的蒸馏，从教师交叉编码器中利用丰富的相关性信号来微调猎犬。我们进一步使用大语言模型探索合成查询的产生。通过ListWise蒸馏和培训，通过自然用户搜索和事实索赔到基于关键字的查询，各种各样的查询，我们在多个数据集中实现了一致的有效性提高。我们的结果还表明，合成查询可以与培训公用事业中的人为编写的查询相匹配。但是，我们还确定了局限性，尤其是在跨编码教师作为瓶颈的有效性方面。我们发布我们的代码和脚本以鼓励进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2502.19712</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在抹布中划分K-均值，以增强电信中的提问任务的绩效</title>
      <link>https://arxiv.org/abs/2502.20188</link>
      <description><![CDATA[ARXIV：2502.20188V1公告类型：新 
摘要：在文献中，电信域中的提问任务仍未得到合理探索，这主要是由于该领域的快速变化和不断发展的标准。这项工作提出了一个针对电信域设计的新型检索生成框架，重点是由3GPP文档组成的数据集。该框架引入了二等k-均值聚类技术的使用来通过内容来组织嵌入向量，从而促进了更有效的信息检索。通过利用这种聚类技术，该系统预选了与用户查询最相似的集群的子集，从而增强了检索到的信息的相关性。针对推理计算成本较低的模型，使用小语言模型对该框架进行了测试，在PHI-2上的精度为66.12％，在PHI-3微调模型上的精度为66.12％，并减少了培训时间。]]></description>
      <guid>https://arxiv.org/abs/2502.20188</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>花岗岩嵌入模型</title>
      <link>https://arxiv.org/abs/2502.20204</link>
      <description><![CDATA[ARXIV：2502.20204V1公告类型：新 
摘要：我们介绍了花岗岩嵌入模型，这是一个基于编码器的嵌入模型家族，旨在检索任务，涵盖了密集的回归和稀疏检索体系结构，具有英语和多语言功能。该报告提供了培训这些高效的12层嵌入模型的技术细节，以及其高效的6层蒸馏料。广泛的评估表明，这些模型采用诸如以检索为导向的预审进，对比度进行的固定，知识蒸馏和模型，在内部IBM检索任务和搜索任务上都显着超过了相似大小的公开模型，并且在高度使用高Que extrapriper上，在内部IBM检索任务和搜索任务上都具有相同的性能，并且在培训的信息中广泛使用。我们将在Apache 2.0许可下公开发布所有花岗岩嵌入模型，允许在https://huggingface.co/collections/ibm-Granite上进行研究和商业用途。]]></description>
      <guid>https://arxiv.org/abs/2502.20204</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>值得信赖的答案，Messier数据：在域专家系统中弥合低资源检索生成的差距</title>
      <link>https://arxiv.org/abs/2502.19596</link>
      <description><![CDATA[ARXIV：2502.19596V1公告类型：交叉 
摘要：RAG已通过减少幻觉来增强LLM的关键技术，尤其是在LLMS可能缺乏足够固有知识的领域专家系统中。但是，在低资源设置中开发这些系统引入了几个挑战：（1）处理异质数据源，（2）优化可信赖答案的检索阶段，以及（3）评估各个方面跨不同方面生成的答案。为了解决这些问题，我们介绍了一个数据生成管道，该管道将原始的多模式数据转换为结构化语料库和Q＆amp; A对，高级重新级别提高检索精度以及参考匹配算法增强答案的可靠性。应用于汽车工程领域，我们的系统改善了事实正确性（+1.94），信息性（+1.16）和有用性（+1.67）（+1.67）（+1.67），基于LLM法官的1-5比例。这些结果突出了我们在不同方面的有效性，具有强大的答案接地和透明度。]]></description>
      <guid>https://arxiv.org/abs/2502.19596</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从5个示例中的几个弹药多语言开域质量质量</title>
      <link>https://arxiv.org/abs/2502.19722</link>
      <description><![CDATA[ARXIV：2502.19722V1公告类型：交叉 
摘要：鉴于丰富的特定语言培训数据，多种语言开放域问题答案的最新方法（MLODQA）已取得了令人鼓舞的结果。但是，大量注释成本限制了这些方法在代表性不足的语言中的应用。我们介绍了一种\ emph {少数学习}方法，以合成大型语言模型（LLM）的大规模多语言数据。我们的方法始于使用Wikidata进行的大规模自我监督预训练，然后培训高质量的合成多语言数据，该数据通过促使LLMS几乎没有射击监督而生成的高质量合成多语言数据。最终模型\ textsc {fsmodqa}明显优于MLODQA中的现有少量和监督基线，以及跨语言和单语检索。我们进一步表明，我们的方法可以扩展，以通过仅使用英语监督数据的\ emph {跨语性提示}策略对新语言进行有效的零射击适应，从而使其成为MLODQA任务的一般且适用的解决方案，而无需昂贵的大规模注释。]]></description>
      <guid>https://arxiv.org/abs/2502.19722</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>侦察：通过强大嘈杂对应学习的关系一致性增强真实的对应歧视</title>
      <link>https://arxiv.org/abs/2502.19962</link>
      <description><![CDATA[ARXIV：2502.19962V1公告类型：交叉 
摘要：我们可以准确地从包含不匹配数据对的多模式数据集中确定真实的对应关系吗？现有方法主要强调跨模态对象表示之间的相似性匹配，从而有可能忽略模式中关键关系的一致性，这对于区分真实和错误的对应关系特别重要。这样的遗漏通常会冒着将否定性误认为是积极因素的风险，从而导致意外的绩效退化。为了解决这个问题，我们提出了一个一般关系一致性学习框架，即重新侦察，以准确区分多模式数据之间的真实对应关系，从而有效地减轻了不匹配引起的不良影响。具体而言，侦察利用了一种新颖的关系一致性学习，以确保不同方式与模态内模式之间的跨模式关系一致性分别确保双模式关系的一致性。得益于对关系的这种双重约束，侦察大大提高了其对真实对应歧视的有效性，因此可靠地滤除了错配对的成对，以减轻错误监督的风险。在三个广泛使用的基准数据集上进行了广泛的实验，包括Flickr30k，MS-Coco和概念标题，以证明与其他SOTA相比，侦察的有效性和优越性。该代码可在以下网址提供：https：//github.com/qxzha/recon。]]></description>
      <guid>https://arxiv.org/abs/2502.19962</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>langprobe：语言程序基准</title>
      <link>https://arxiv.org/abs/2502.20315</link>
      <description><![CDATA[ARXIV：2502.20315V1公告类型：交叉 
摘要：将语言模型（LMS）组成多步语言程序，并自动优化其模块化提示，现在是建立AI系统的主流范式，但是该领域的权衡很少才被研究。我们介绍了Langprobe，这是第一个用于评估语言程序的体系结构和优化策略的大规模基准，具有超过2000个任务，体系结构，优化器和LMS选择的组合。使用Langprobe，我们是第一个研究计划架构和优化者（及其组成以及不同模型）对质量和成本折衷的影响的人。我们发现，优化的语言程序提供了良好的成本 - 帕累托对模型的原始调用的质量改善，但同时证明了人类的判断（或经验决策）关于最佳表现仍然需要进行哪些构图仍然是必要的。我们将开放langprobe的代码和评估数据。]]></description>
      <guid>https://arxiv.org/abs/2502.20315</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结构和文本检索在文本丰富的图形知识基础上的混合</title>
      <link>https://arxiv.org/abs/2502.20317</link>
      <description><![CDATA[ARXIV：2502.20317V1公告类型：交叉 
摘要：文本丰富的图形知识库（TG-KB）已通过提供文本和结构知识来回答查询变得越来越重要。但是，当前的检索方法通常会孤立地检索这两种类型的知识，而无需考虑它们的相互强化和某些混合方法，甚至在相邻聚集后完全绕过结构检索。为了填补这一空白，我们提出了结构性和文本检索（MOR）的混合物，以通过计划 - 策划 - 组织 - 组织框架来检索这两种知识。在计划阶段，MOR生成文本计划图表描绘了回答查询的逻辑。在计划图表之后，在推理阶段，MOR将结构遍历和文本匹配交织在一起，从TG-KBS获得候选者。在组织阶段，MOR进一步根据其结构轨迹来收集候选人。广泛的实验表明，MOR在结构和文本检索与见解之间的优势，包括在不同的查询逻辑中检索性能不平衡，以及整合结构轨迹以供候选人重新加工的好处。我们的代码可在https://github.com/yoega/mor上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.20317</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过简明的用户资料提出的建议文本</title>
      <link>https://arxiv.org/abs/2311.01314</link>
      <description><![CDATA[ARXIV：2311.01314V3公告类型：替换 
摘要：推荐系统对流行物品和具有充足互动的用户（例如，评分等）的表现良好。这项工作解决了互动非常稀疏但在提供信息丰富的审核文本的用户的困难和毫无疑问的情况。此设置自然要求使用大语言模型（LLM）编码特定于用户的文本。但是，通过LLM喂食所有评论的全文具有较弱的信噪比，并且会产生高昂的加工令牌成本。本文解决了这两个问题。它提出了一个称为CUP的轻重量框架，该框架首先计算简洁的用户资料，并仅将其馈送到基于变压器推荐人的培训中。对于用户配置文件，我们设计了各种技术，从嘈杂的评论中选择最有用的提示。通过书评数据，实验表明，通过明智地构建的概况进行微调模型，即使与LLM生成的排名相比，也可以实现最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2311.01314</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用聚类和自我监督学习的多模式食品建议</title>
      <link>https://arxiv.org/abs/2406.18962</link>
      <description><![CDATA[ARXIV：2406.18962V2公告类型：替换 
摘要：食品推荐系统是数字生活方式服务领域中的关键组成部分，旨在帮助用户发现与其独特的饮食偏爱共鸣的食谱和食品。通常，多模式描述为每个食谱提供详尽的概况，从而确保了既个性化又准确的建议。我们对两个数据集的初步研究表明，与ID特征相比，预先训练的多模式致密表示可能会导致性能恶化，而在封装交互式关系时。该观察结果表明，ID特征在建模交互式协作信号中具有相对优越性。因此，当代的尖端方法可以增强具有多模式信息作为补充特征的ID特征，从而忽略了食谱之间的潜在语义关系。为了纠正这一点，我们提出了Clussl，这是一个新颖的食品推荐框架，采用聚类和自我监管的学习。具体而言，Clussl为针对每个模态定制的具有离散/连续特征的模式特异性图，从而将语义特征转换为结构表示。此外，Clussl通过图形卷积操作采购与不同模式有关的食谱表示。提出了一个自我监督的学习目标，以促进从不同单形图得出的食谱表示之间的独立性。对现实数据集的全面实验证实了Clussl始终超过最先进的性能建议基准。]]></description>
      <guid>https://arxiv.org/abs/2406.18962</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立Tetun文本临时检索的基础：茎，索引，检索和排名</title>
      <link>https://arxiv.org/abs/2412.11758</link>
      <description><![CDATA[ARXIV：2412.11758V2公告类型：替换 
摘要：搜索Internet和数字平台上的信息以满足信息需求需要有效的检索解决方案。但是，此类解决方案尚未用于Tetun，因此在此语言中找到有关基于文本的搜索查询的相关文档的挑战。为了应对这些挑战，本研究调查了Tetun文本检索，重点是临时检索任务。它首先要开发基本的语言资源 - 包括止词，词干和测试收集列表，它们是针对Tetun文本检索量身定制的解决方案的基础组件。然后，使用文档标题和内容来探索各种策略，以评估检索有效性。结果表明，在删除连字符和撇号而没有应用茎的情况下，检索文档标题与基线相比显着提高了检索性能。效率提高了31.37％，而有效性在10@10中的MAP@10和DFR BM25中的平均增益为9.40％，NDCG@10的平均增益为30.35％。除了前10名截止点之外，Hiemstra LM还表现出各种检索策略和评估指标的出色表现。这项工作的贡献包括开发Labadain-Stopwords（160个Tetun停止词的列表），Labadain-STEMMER（带有三个变体的Tetun Stemmer）和Labadain-avaliad \&#39;或（包含59个主题，33,550个文档和5,900 QRELS）。]]></description>
      <guid>https://arxiv.org/abs/2412.11758</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EMPRA：嵌入对神经排名模型的扰动等级攻击</title>
      <link>https://arxiv.org/abs/2412.16382</link>
      <description><![CDATA[ARXIV：2412.16382V2公告类型：替换 
摘要：最近的研究表明，神经信息检索技术可能容易受到对抗攻击的影响。对抗性攻击旨在操纵文档的排名，以使用户接触目标内容。在本文中，我们介绍了嵌入式扰动等级攻击（EMPRA）方法，这是一种新型方法，旨在对黑盒神经排名模型（NRMS）进行对抗性攻击。 EMPRA操纵句子级的嵌入，引导它们朝着与查询有关的相关背景，同时保持语义完整性。此过程产生的对抗文本，与原始内容无缝集成并被人类无法察觉。我们对广泛使用的MS MARCO V1通道进行的广泛评估表明，EMPRA对广泛的最新基线的有效性在促进给定排名结果中促进一组特定目标文档方面的有效性。具体而言，EMPRA成功实现了几乎96％的目标文档的重新排列，最初排名在51-100之间，以排名在前10名中。此外，EMPRA不依赖于对抗文本生成的代孕模型，从而增强了其在现实设置中针对不同NRMS的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2412.16382</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨域顺序推荐的图像融合</title>
      <link>https://arxiv.org/abs/2502.15694</link>
      <description><![CDATA[ARXIV：2502.15694V2公告类型：替换 
摘要：跨域顺序推荐（CDSR）旨在根据跨多个领域的历史互动来预测未来的用户互动。 CDSR中的主要挑战是通过完全利用内部序列和序列项目相互作用来有效地捕获跨域用户偏好。在本文中，我们提出了一种新颖的方法，即用于跨域顺序推荐（IFCDSR）的图像融合，该方法结合了项目图像信息以更好地捕获视觉偏好。我们的方法集成了一个冷冻的剪辑模型来生成图像嵌入，并通过内部序列和序列相互作用的视觉数据丰富了原始项目嵌入。此外，我们采用多个注意力层来捕获跨域兴趣，从而可以联合学习单域和跨域用户的偏好。为了验证IFCDSR的有效性，我们重新分配了四个电子商务数据集并进行了广泛的实验。结果表明，IFCDR显着胜过现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.15694</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM-QE：通过将大型语言模型与排名偏好对齐来改善查询扩展</title>
      <link>https://arxiv.org/abs/2502.17057</link>
      <description><![CDATA[ARXIV：2502.17057V2公告类型：替换 
摘要：查询扩展在信息检索中起着至关重要的作用，旨在弥合查询和文档之间的语义差距，以提高匹配性能。本文介绍了LLM-QE，这是一种利用大型语言模型（LLM）生成基于文档的查询扩展的新颖方法，从而增强了密集的检索模型。与传统方法不同，LLM-QE设计基于排名的奖励和基于答案的奖励，并使用这些奖励模型来优化LLM，以与猎犬和LLM的排名偏好保持一致，从而减轻查询扩展期间LLMS的幻觉。我们对零射击量检索模型的实验Chrodever展示了LLM-QE的有效性，并提高了8％以上。此外，通过合并基于答案的奖励建模，LLM-QE生成了与文档相关的更相关和精确的信息，而不是简单地产生冗余代币以最大程度地提高基于等级的奖励。值得注意的是，LLM-QE还改善了致密猎犬的训练过程，在微调后取得了5％以上的进步。所有代码均可在https://github.com/neuir/llm-qe上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.17057</guid>
      <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>