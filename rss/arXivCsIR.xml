<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 07 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用交叉编码器进行 k-NN 搜索的自适应检索和可扩展索引</title>
      <link>https://arxiv.org/abs/2405.03651</link>
      <description><![CDATA[arXiv:2405.03651v1 公告类型：新
摘要：通过联合编码查询项目对来计算相似性的交叉编码器（CE）模型在估计查询项目相关性方面比基于嵌入的模型（双编码器）表现更好。现有方法通过使用适合双编码器 (DE) 或 CUR 矩阵分解的向量嵌入空间来近似 CE 相似性，从而使用 CE 执行 k-NN 搜索。基于 DE 的检索和重新排序方法在新领域上的召回率较差，并且 DE 检索与 CE 分离。虽然基于 CUR 的方法比基于 DE 的方法更准确，但它们需要大量的 CE 调用来计算项目嵌入，因此大规模部署不切实际。在本文中，我们通过提出的基于稀疏矩阵分解的方法来解决这些缺点，该方法有效地计算潜在查询和项目嵌入以近似 CE 分数，并使用近似 CE 相似度执行 k-NN 搜索。我们通过分解包含一组训练查询的查询项 CE 分数的稀疏矩阵来离线计算项嵌入。与基于 CUR 的方法相比，我们的方法产生了高质量的近似值，同时只需要一小部分 CE 调用，并且允许利用 DE 初始化嵌入空间，同时避免通过蒸馏对 DE 进行计算和资源密集型微调。在测试时，项目嵌入保持固定，并且检索在多轮中进行，交替进行 a) 通过最小化迄今为止检索到的项目的 CE 分数的近似误差来估计测试查询嵌入，以及 b) 使用更新的测试查询嵌入来检索更多项目。与基于 DE 的方法相比，我们的 k-NN 搜索方法将召回率提高了 5% (k=1) 和 54% (k=100)。此外，我们的索引方法与基于 CUR 的方法相比，速度提高了 100 倍，与 DE 蒸馏方法相比，速度提高了 5 倍，同时与基线相比，匹配或提高了 k-NN 搜索召回率。]]></description>
      <guid>https://arxiv.org/abs/2405.03651</guid>
      <pubDate>Tue, 07 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>通过自动化知识图生成和丰富加速医学知识发现</title>
      <link>https://arxiv.org/abs/2405.02321</link>
      <description><![CDATA[arXiv:2405.02321v1 公告类型：交叉
摘要：知识图（KG）是组织和表示结构化知识的强大工具。虽然它们的实用性得到了广泛认可，但其自动化和完整性方面仍然存在挑战。尽管在自动化和利用专家创建的本体方面做出了努力，但 KG 内的连接性差距仍然普遍存在。为了应对这些挑战，我们提出了一种名为“医学知识图自动化（M-KGA）”的创新方法。M-KGA利用用户提供的医学概念，并使用BioPortal本体在语义上丰富它们，从而通过以下方式增强知识图的完整性：我们的方法引入了两种不同的方法来揭示知识图中的隐藏联系：基于集群的方法和基于节点的方法，通过对电子健康记录 (EHR) 中 100 个经常出现的医学概念进行严格测试。 ），我们的 M-KGA 框架展示了有希望的结果，表明其有潜力解决现有知识图自动化技术的局限性。]]></description>
      <guid>https://arxiv.org/abs/2405.02321</guid>
      <pubDate>Tue, 07 May 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>进行个人 LAPS：用于个性化多会话对话搜索的 LLM 增强对话构建</title>
      <link>https://arxiv.org/abs/2405.03480</link>
      <description><![CDATA[arXiv:2405.03480v1 公告类型：新
摘要：会话代理的未来将为用户提供个性化的信息响应。然而，开发模型的一个重大挑战是缺乏跨越多个会话并反映现实世界用户偏好的大规模对话数据集。以前的方法依赖于专家进行难以扩展的设置，特别是对于个性化任务。我们的方法 LAPS 通过使用大型语言模型 (LLM) 来指导单个人类工作者生成个性化对话来解决这个问题。事实证明，这种方法可以加快创建过程并提高质量。 LAPS 可以收集大规模、人工编写、多会话和多域对话，包括提取用户偏好。与现有数据集相比，LAPS 生成的对话与专家创建的对话一样自然且多样化，这与完全合成的方法形成鲜明对比。收集的数据集适合训练偏好提取和个性化响应生成。我们的结果表明，使用提取的偏好显式生成的响应更好地匹配用户的实际偏好，突出了使用提取的偏好相对于简单对话历史记录的价值。总体而言，LAPS 引入了一种新方法，利用法学硕士比以前的方法更高效、更有效地创建真实的个性化对话数据。]]></description>
      <guid>https://arxiv.org/abs/2405.03480</guid>
      <pubDate>Tue, 07 May 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>以ID为中心的推荐预训练</title>
      <link>https://arxiv.org/abs/2405.03562</link>
      <description><![CDATA[arXiv:2405.03562v1 公告类型：新
摘要：经典的顺序推荐模型通常采用 ID 嵌入来存储从用户历史行为中学到的知识并表示项目。然而，将这些唯一 ID 转移到新域具有挑战性。随着预训练语言模型（PLM）的蓬勃发展，一些先驱作品采用 PLM 进行预训练推荐，其中模态信息（例如文本）通过 PLM 被认为是跨领域通用的。不幸的是，与模态信息相比，ID 嵌入中的行为信息仍然被证明在基于 PLM 的推荐模型中占主导地位，从而限制了这些模型的性能。在这项工作中，我们提出了一种新颖的以 ID 为中心的推荐预训练范式（IDP），它将在预训练领域中学习到的信息丰富的 ID 嵌入直接转移到新领域中的项目表示。具体来说，在预训练阶段，除了基于 ID 的顺序推荐模型外，我们还构建了一个通过行为和模态信息学习的跨域 ID 匹配器（CDIM）。在调优阶段，新领域项的模态信息被视为CDIM构建的跨领域桥梁。我们首先利用下游域项目的文本信息，使用 CDIM 从预训练域中检索行为和语义上相似的项目。接下来，直接采用这些检索到的预先训练的 ID 嵌入，而不是某些文本嵌入，来生成下游新项目的嵌入。通过在寒冷和温暖环境下对现实世界数据集进行广泛的实验，我们证明我们提出的模型显着优于所有基线。代码将在接受后发布。]]></description>
      <guid>https://arxiv.org/abs/2405.03562</guid>
      <pubDate>Tue, 07 May 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>TF4CTR：通过自适应样本区分进行 CTR 预测的双焦点框架</title>
      <link>https://arxiv.org/abs/2405.03167</link>
      <description><![CDATA[arXiv:2405.03167v1 公告类型：新
摘要：有效的特征交互建模对于提高工业推荐系统中点击率（CTR）预测的准确性至关重要。当前大多数深度点击率模型都采用构建复杂的网络架构来更好地捕获复杂的特征交互或用户行为。然而，我们发现这些模型有两个局限性：（1）给予模型的样本是无差别的，这可能导致模型一心一意地学习大量的简单样本，而忽略少量的困难样本，从而降低模型的泛化能力； （2）差异化特征交互编码器被设计为捕获不同的交互信息但接收一致的监督信号，从而限制了编码器的有效性。为了弥补已发现的差距，本文引入了一种新颖的点击率预测框架，通过集成即插即用的双焦点（TF）损失、样本选择嵌入模块（SSEM）和动态融合模块（DFM），命名为双焦点框架点击率（TF4CTR）。具体来说，该框架在模型底部采用了SSEM来区分样本，从而为每个样本分配更合适的编码器。同时，TF Loss 为简单和复杂的编码器提供定制的监督信号。此外，DFM 动态融合编码器捕获的特征交互信息，从而获得更准确的预测。对五个现实世界数据集的实验证实了该框架的有效性和兼容性，证明了其以与模型无关的方式增强各种代表性基线的能力。为了促进可重复的研究，我们的开源代码和详细的运行日志将在以下位置提供：https://github.com/salmon1802/TF4CTR。]]></description>
      <guid>https://arxiv.org/abs/2405.03167</guid>
      <pubDate>Tue, 07 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>透明对话式信息搜索的可解释性</title>
      <link>https://arxiv.org/abs/2405.03303</link>
      <description><![CDATA[arXiv:2405.03303v1 公告类型：新
摘要：对数字信息的日益依赖需要对话式搜索系统的进步，特别是在信息透明度方面。虽然对话式信息搜索的先前研究集中在改进检索技术上，但挑战仍然在于生成从用户角度来看有用的响应。本研究探索了解释响应的不同方法，假设信息来源的透明度、系统置信度和限制可以增强用户客观评估响应的能力。通过探索解释类型、质量和呈现模式的透明度，本研究旨在弥合系统生成的响应和用户可验证的响应之间的差距。我们设计了一项用户研究来回答有关以下方面影响的问题：(1) 解释的质量增强对其有用性的响应；(2) 向用户呈现解释的方式。对收集的数据的分析显示，用户对嘈杂的解释的评分较低，尽管这些分数似乎对响应的质量不敏感。解释演示格式的不确定结果表明，它可能不是此设置中的关键因素。]]></description>
      <guid>https://arxiv.org/abs/2405.03303</guid>
      <pubDate>Tue, 07 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>提高音乐数据集的（重新）可用性：DOREMUS 项目概述</title>
      <link>https://arxiv.org/abs/2405.03382</link>
      <description><![CDATA[arXiv:2405.03382v1 公告类型：新
摘要：DOREMUS 致力于通过构建新工具来链接和探索三个法国机构的数据，从而更好地描述音乐。本文概述了基于 FRBRoo 的数据模型，解释了使用链接数据技术的转换和链接过程，并介绍了根据 Web 用户的需求创建的用于消费数据的原型。]]></description>
      <guid>https://arxiv.org/abs/2405.03382</guid>
      <pubDate>Tue, 07 May 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>提高法学硕士的时间意识以进行顺序推荐</title>
      <link>https://arxiv.org/abs/2405.02778</link>
      <description><![CDATA[arXiv:2405.02778v1 公告类型：新
摘要：大型语言模型（LLM）在解决各种通用任务方面表现出了令人印象深刻的零样本能力。然而，根据经验发现，法学硕士在识别和利用时间信息方面存在不足，导致在需要理解顺序数据的任务（例如顺序推荐）中表现不佳。在本文中，我们的目标是通过设计受人类认知过程启发的原则性提示框架来提高法学硕士的时间意识。具体来说，我们提出了三种提示策略来利用历史交互中的时间信息来进行基于 LLM 的顺序推荐。此外，我们通过汇总这些策略得出的法学硕士排名结果来模拟发散思维。对 MovieLens-1M 和 Amazon Review 数据集的评估表明，我们提出的方法显着增强了 LLM 在顺序推荐任务中的零样本能力。]]></description>
      <guid>https://arxiv.org/abs/2405.02778</guid>
      <pubDate>Tue, 07 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的矢量量化：回顾与展望</title>
      <link>https://arxiv.org/abs/2405.03110</link>
      <description><![CDATA[arXiv:2405.03110v1 公告类型：新
摘要：矢量量化以其无与伦比的特征压缩能力而闻名，几十年来一直是信号处理和机器学习研究中的一个突出课题，至今仍被广泛使用。随着大型模型和生成式人工智能的出现，矢量量化在推荐系统中越来越受欢迎，并成为首选解决方案。本文首先全面回顾了矢量量化技术。然后，它探讨了推荐系统 (VQ4Rec) 的矢量量化方法的系统分类，从多个角度研究了它们的应用。此外，它还全面介绍了各种推荐场景中的研究工作，包括面向效率的方法和面向质量的方法。最后，调查分析了剩余的挑战并预测了 VQ4Rec 的未来趋势，包括与矢量量化训练相关的挑战、大型语言模型带来的机遇以及多模态推荐系统的新兴趋势。我们希望这次调查能够为推荐社区的未来研究人员铺平道路，并加速他们在这个有前途的领域的探索。]]></description>
      <guid>https://arxiv.org/abs/2405.03110</guid>
      <pubDate>Tue, 07 May 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>用于汉明空间搜索的符号引导二分图哈希算法</title>
      <link>https://arxiv.org/abs/2405.02716</link>
      <description><![CDATA[arXiv:2405.02716v1 公告类型：新
摘要：二分图哈希（BGH）以较低的存储和推理成本广泛用于汉明空间中的 Top-K 搜索。最近的研究采用图卷积哈希进行 BGH，并取得了最先进的性能。然而，其各种影响因素对哈希性能的贡献尚未深入探讨，包括汉明空间搜索期间两个二进制嵌入之间的相同/不同符号计数（符号属性）、每层子嵌入的贡献（模型属性）、二分图中不同节点类型的贡献（节点属性）以及增强方法的组合。在这项工作中，我们主要通过删除最先进模型 BGCH 的增强方法来构建一个名为 LightGCH 的轻量级图卷积哈希模型。通过分析各层和节点类型对性能的贡献，以及分析各层的汉明相似度统计，我们发现二分图中的实际邻居在浅层往往具有较低的汉明相似度，并且所有节点都倾向于在 LightGCH 的深层具有较高的汉明相似度。为了解决这些问题，我们提出了一种新的符号引导框架SGBGH来进行改进，它使用符号引导负采样来提高邻居的汉明相似度，并使用符号感知对比学习来帮助节点学习更统一的表示。实验结果表明，SGBGH 在嵌入质量上显着优于 BGCH 和 LightGCH。]]></description>
      <guid>https://arxiv.org/abs/2405.02716</guid>
      <pubDate>Tue, 07 May 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>TREC iKAT 2023：用于评估会话和交互式知识助手的测试集</title>
      <link>https://arxiv.org/abs/2405.02637</link>
      <description><![CDATA[arXiv:2405.02637v1 公告类型：新
摘要：随着大型语言模型（LLM）的发展，对话式信息搜索在过去几年中迅速发展，为以自然方式解释和响应用户请求提供了基础。扩展的 TREC 交互式知识辅助轨道 (iKAT) 系列旨在使研究人员能够测试和评估他们的会话搜索代理 (CSA)。该集合包含 36 个个性化对话，涵盖 20 个不同主题，每个对话都配有定义定制用户角色的个人文本知识库 (PTKB)。总共提供了 344 个回合，大约 26,000 个段落，作为相关性评估，以及对四个关键维度上生成的响应的附加评估：相关性、完整性、基础性和自然性。该集合要求 CSA 有效地驾驭不同的个人背景、引出相关的人物信息并利用背景进行相关对话。 PTKB 的集成和对决策搜索任务的重视造就了该测试集的独特性，使其成为推进对话和交互式知识助理研究的重要基准。]]></description>
      <guid>https://arxiv.org/abs/2405.02637</guid>
      <pubDate>Tue, 07 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>超越相关性：评估和提高检索者的视角意识</title>
      <link>https://arxiv.org/abs/2405.02714</link>
      <description><![CDATA[arXiv:2405.02714v1 公告类型：新
摘要：信息检索 (IR) 任务要求系统根据用户的信息需求识别相关文档。在现实世界中，检索器不仅需要依赖文档和查询之间的语义相关性，还需要识别用户查询背后的细微意图或观点。例如，当被要求验证声明时，检索系统需要识别来自支持和反对观点的证据，以便下游系统做出公平的判断。在这项工作中，我们研究检索器是否能够识别和响应查询的不同观点——除了找到与声明相关的文档之外，检索器是否能够区分支持和反对的文件？我们改革并扩展了六个现有任务以创建检索基准，其中除了根中性查询之外，我们还以自由格式的文本描述了不同的观点。我们表明，我们实验中涉及的当前检索器对查询中细微的不同观点的认识有限，并且也可能偏向某些观点。受此观察的启发，我们进一步探索了利用检索器表示空间的几何特征以零样本方式提高检索器透视意识的潜力。我们在同一组任务上展示了基于投影的方法的效率和效果。进一步的分析还表明，与非透视意识基线相比，透视意识如何提高各种下游任务的性能，AmbigQA 的准确率提高了 4.2%，与论文写作中指定观点的相关性提高了 29.9%。]]></description>
      <guid>https://arxiv.org/abs/2405.02714</guid>
      <pubDate>Tue, 07 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>神经检索模型中逆向工程相关性计算的公理因果干预</title>
      <link>https://arxiv.org/abs/2405.02503</link>
      <description><![CDATA[arXiv:2405.02503v1 公告类型：新
摘要：神经模型在不同的排序任务中表现出了卓越的性能。然而，它们确定相关性的过程和内部机制仍然很大程度上未知。分析神经排序行为相对于 IR 属性的现有方法依赖于评估整体模型行为或采用可能无法完全理解因果机制的探测方法。为了更精细地理解内部模型决策过程，我们建议使用因果干预来逆向工程神经排序器，并演示如何使用机械可解释性方法来隔离排序模型中满足术语频率公理的组件。我们确定一组注意力头，用于检测模型早期层中的重复标记，然后与下游头进行通信以计算整体文档相关性。更一般地说，我们建议这种类型的机械分析为对神经检索模型用于计算相关性的过程进行逆向工程开辟了途径。这项工作旨在启动细粒度的可解释性工作，这不仅有利于检索模型的开发和训练，而且最终确保这些模型的部署更安全。]]></description>
      <guid>https://arxiv.org/abs/2405.02503</guid>
      <pubDate>Tue, 07 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>RLStop：TAR 的强化学习停止方法</title>
      <link>https://arxiv.org/abs/2405.02525</link>
      <description><![CDATA[arXiv:2405.02525v1 公告类型：新
摘要：我们提出了 RLStop，一种基于强化学习的新型技术辅助审阅 (TAR) 停止规则，有助于最大限度地减少 TAR 应用程序中需要手动审阅的文档数量。 RLStop 使用奖励函数对示例排名进行训练，以确定停止检查文档的最佳点。在多个基准数据集（CLEF e-Health、TREC Total Recall 和Reuters RCV1）上进行的一系列目标召回级别的实验表明，RLStop 大大减少了筛选文档集合的相关性所需的工作量。 RLStop 的性能优于多种替代方法，在某些情况下实现的性能接近任务的最大可能值。]]></description>
      <guid>https://arxiv.org/abs/2405.02525</guid>
      <pubDate>Tue, 07 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>CALRec：用于顺序推荐的生成式 LLM 的对比对齐</title>
      <link>https://arxiv.org/abs/2405.02429</link>
      <description><![CDATA[arXiv:2405.02429v1 公告类型：新
摘要：传统的推荐系统（例如矩阵分解方法）依赖于学习共享的密集嵌入空间来表示项目和用户偏好。 RNN、GRU 以及最近的 Transformer 等序列模型在序列推荐任务中也表现出色。此任务需要了解用户历史交互中存在的顺序结构，以预测他们可能喜欢的下一个项目。基于大型语言模型 (LLM) 在各种任务中取得的成功，研究人员最近探索使用在大量文本语料库上进行预训练的 LLM 进行顺序推荐。为了在顺序推荐中使用 LLM，用户交互的历史记录和模型对下一个项目的预测都以文本形式表示。我们提出了 CALRec，一个两阶段的 LLM 微调框架，它使用两种对比损失和语言建模损失的混合，以双塔方式微调预训练的 LLM：LLM 首先对来自多个领域的数据混合进行微调，然后是另一个一轮目标域微调。我们的模型显着优于许多最先进的基线（Recall@1 中+37%，NDCG@10 中+24%），并且系统消融研究表明（i）两个微调阶段都至关重要，并且当结合起来时，我们实现了改进的性能，并且（ii）对比对齐在我们实验中探索的目标域中是有效的。]]></description>
      <guid>https://arxiv.org/abs/2405.02429</guid>
      <pubDate>Tue, 07 May 2024 06:19:03 GMT</pubDate>
    </item>
    </channel>
</rss>