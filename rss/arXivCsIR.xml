<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Wed, 11 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过强化学习增强预测模型</title>
      <link>https://arxiv.org/abs/2412.06791</link>
      <description><![CDATA[arXiv:2412.06791v1 公告类型：新
摘要：我们介绍了 Ringier Axel Springer Polska 实施的大规模新闻推荐系统，重点是通过强化学习技术增强预测模型。该系统名为 Aureus，集成了多种算法，包括多臂老虎机方法和基于大型语言模型 (LLM) 的深度学习模型。我们详细介绍了 Aureus 的架构和实现，强调了通过将排名预测模型与强化学习相结合而实现的在线指标的显著改进。本文进一步探讨了不同模型混合对关键业务绩效指标的影响。我们的方法有效地平衡了个性化推荐的需求与适应快速变化的新闻内容的能力，解决了冷启动问题和内容新鲜度等常见挑战。在线评估的结果证明了所提出的系统在实际生产环境中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.06791</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成多样化合成数据集以评估现实生活中的推荐系统</title>
      <link>https://arxiv.org/abs/2412.06809</link>
      <description><![CDATA[arXiv:2412.06809v1 公告类型：新
摘要：合成数据集对于评估和测试机器学习模型非常重要。在评估现实生活中的推荐系统时，通常会考虑高维分类（和稀疏）数据集。不幸的是，没有多少解决方案可以生成具有此类特征的人工数据集。为此，我们开发了一个新颖的框架来生成多样化且统计一致的合成数据集。我们的框架允许创建具有受控属性的数据集，从而实现迭代修改以满足特定的实验需求，例如引入复杂的特征交互、特征基数或特定分布。我们通过基准概率计数算法、检测算法偏差和模拟 AutoML 搜索等用例展示了该框架的实用性。与现有方法不同，这些方法要么只关注特定的数据集结构，要么通过真实数据优先考虑（私有）数据合成，而我们的方法提供了一种模块化方法，可以快速生成完全合成的数据集，我们可以根据不同的实验要求进行定制。我们的结果表明，该框架有效地隔离了特定情况下的模型行为，并凸显了其在推荐系统评估和开发方面取得重大进步的潜力。该框架现成可用，可作为免费的开放 Python 软件包使用，以最小的摩擦促进研究。]]></description>
      <guid>https://arxiv.org/abs/2412.06809</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连接对话和协作信号以实现对话推荐</title>
      <link>https://arxiv.org/abs/2412.06949</link>
      <description><![CDATA[arXiv:2412.06949v1 公告类型：新
摘要：对话推荐系统 (CRS) 利用对话中的上下文信息来生成推荐，但通常由于缺乏协同过滤 (CF) 信号而遇到困难，而协同过滤信号可以捕获准确推荐所必需的用户-项目交互模式。我们引入了 Reddit-ML32M，这是一个将 reddit 对话与 MovieLens 32M 上的交互链接起来的数据集，通过利用协作知识和解决对话数据集中的交互稀疏性来丰富项目表示。我们提出了一个基于 LLM 的框架，该框架使用 Reddit-ML32M 将 LLM 生成的推荐与 CF 嵌入对齐，从而优化排名以获得更好的性能。我们根据三组基线评估我们的框架：仅使用来自 CRS 任务的交互的基于 CF 的推荐器、传统的 CRS 模型和依赖于对话上下文而没有项目表示的基于 LLM 的方法。我们的方法取得了持续的改进，包括命中率提高了 12.32%，NDCG 提高了 9.9%，优于依赖对话上下文但缺乏协作项目表示的最佳基线。]]></description>
      <guid>https://arxiv.org/abs/2412.06949</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CURE：用于临床理解和检索评估的数据集</title>
      <link>https://arxiv.org/abs/2412.06954</link>
      <description><![CDATA[arXiv:2412.06954v2 公告类型：新
摘要：鉴于密集检索器在训练数据集分布之外的泛化能力不强，因此特定领域的测试集对于评估检索至关重要。医疗保健提供者在护理点环境中使用的检索系统测试数据集很少。为了填补这一空白，我们与医疗专业人士合作创建了 CURE，这是一个用于段落排名的临时检索测试数据集，包含 2000 个查询，涵盖 10 个医学领域，具有单语（英语）和两种跨语言（法语/西班牙语 -&gt; 英语）条件。在本文中，我们描述了 CURE 的构建方式，并提供了基线结果来展示其作为评估工具的有效性。CURE 以知识共享署名非商业 4.0 许可证发布，可在 Hugging Face 上访问。]]></description>
      <guid>https://arxiv.org/abs/2412.06954</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IntellectSeeker：基于概率模型和大型语言模型的个性化文献管理系统</title>
      <link>https://arxiv.org/abs/2412.07213</link>
      <description><![CDATA[arXiv:2412.07213v1 公告类型：新
摘要：面对不断增长的学术文献数量，研究人员经常需要帮助解决使用传统学术引擎进行术语搜索时文章质量不确定和不匹配的问题。我们推出了 IntellectSeeker，这是一个创新且个性化的智能学术文献管理平台，旨在应对这些挑战。该平台将基于大型语言模型 (LLM) 的语义增强机器人与复杂的概率模型相结合，以个性化和简化文献搜索。我们采用 GPT-3.5-turbo 模型，通过多轮小样本学习将日常语言转化为各种场景下的专业学术术语。这种改编主要使学术新手受益，有效地弥合了一般查询和学术术语之间的差距。概率模型可以智能地过滤学术文章，以与用户的特定兴趣紧密结合，这些兴趣源于明确的需求和行为模式。此外，IntellectSeeker 还结合了先进的推荐系统和文本压缩工具。这些功能可根据用户交互实现智能文章推荐，并通过简洁的单行摘要和创新的词云可视化呈现搜索结果，显著提高研究效率和用户体验。IntellectSeeker 为学术研究人员提供高度可定制的文献管理解决方案，具有出色的搜索精度和匹配功能。代码可在此处找到：https://github.com/LuckyBian/ISY5001]]></description>
      <guid>https://arxiv.org/abs/2412.07213</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于顺序推荐的时间线性项目-项目模型</title>
      <link>https://arxiv.org/abs/2412.07382</link>
      <description><![CDATA[arXiv:2412.07382v1 公告类型：新
摘要：在顺序推荐 (SR) 中，神经模型因其出色的性能而受到积极探索，但它们存在由其复杂性固有的低效率问题。另一方面，与神经模型相比，线性 SR 模型表现出高效率并实现具有竞争力或更高的准确性。然而，它们仅处理项目的顺序（即顺序信息）并忽略实际时间戳（即时间信息）。它仅限于有效捕获各种用户偏好随时间的变化。为了解决这个问题，我们提出了一种新的线性 SR 模型，称为 TemporAl LinEar 项目-项目模型 (TALE)，该模型结合了时间信息，同时保持了训练/推理效率，具有三个关键组件。（i）单目标增强集中在单个目标项目上，使我们能够学习目标项目的时间相关性。（ii）时间间隔感知加权利用实际时间戳来根据时间间隔辨别项目相关性。 （三）趋势感知标准化反映了商品受欢迎程度随时间变化的动态变化。我们的实证研究表明，TALE 在五个基准数据集上的表现比十个竞争 SR 模型高出 18.71%。它在评估长尾商品方面也表现出显著的效果，最高可提高 30.45%。源代码可在 https://github.com/psm1206/TALE 获得。]]></description>
      <guid>https://arxiv.org/abs/2412.07382</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RLT4Rec：用于用户冷启动和项目推荐的强化学习 Transformer</title>
      <link>https://arxiv.org/abs/2412.07403</link>
      <description><![CDATA[arXiv:2412.07403v1 公告类型：新
摘要：我们引入了一种新的顺序变换器强化学习架构 RLT4Rec，并证明它在一系列项目推荐任务中取得了出色的表现。RLT4Rec 使用一个相对简单的变换器架构，该架构将用户的（项目，评级）历史记录作为输入，并输出下一个要呈现给用户的项目。与现有的 RL 方法不同，无需输入状态观察或估计。RLT4Rec 在同一个一致的框架内处理新用户和老用户，并自动平衡发现新用户偏好所需的“探索”与更适合老用户的“利用”。RLT4Rec 的训练稳健而快速，并且对训练数据的选择不敏感，学习生成“好的”个性化序列，即使在“坏”数据上训练，用户也倾向于给予高度评价。]]></description>
      <guid>https://arxiv.org/abs/2412.07403</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于文档匹配的 SST 框架</title>
      <link>https://arxiv.org/abs/2412.07573</link>
      <description><![CDATA[arXiv:2412.07573v1 公告类型：新
摘要：长格式文档匹配旨在判断两个文档之间的相关性，已应用于各种场景。大多数现有工作使用分层或长上下文模型来处理文档，这些模型可以实现粗略的理解，但可能会忽略细节。一些研究人员构建了关于对齐文档子主题的类似句子的文档视图，以关注详细的匹配信号。然而，长文档通常包含多个子主题。匹配信号来自多个主题。仅考虑同源对齐的子主题可能不够有代表性，并且可能导致建模偏差。在本文中，我们介绍了一种新的框架来对代表性匹配信号进行建模。首先，我们提出通过文档对的子主题捕获各种匹配信号。接下来，我们基于子主题构建多个文档视图，以涵盖异构且有价值的细节。然而，现有的空间聚合方法（如注意力机制）同时整合所有这些视图，很难整合异构信息。相反，我们提出了时间聚合，它可以随着训练的进展逐渐有效地整合不同的视图。实验结果表明，我们的学习框架对于包括新闻复制和法律案件检索在内的多个文档匹配任务是有效的。]]></description>
      <guid>https://arxiv.org/abs/2412.07573</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引文推荐模型评估与分析基准</title>
      <link>https://arxiv.org/abs/2412.07713</link>
      <description><![CDATA[arXiv:2412.07713v1 公告类型：新
摘要：引文推荐系统引起了学术界的广泛兴趣，并产生了许多研究和实现。这些系统通过根据作者所写的文本建议相关参考文献来帮助作者自动生成适当的引文。然而，引文推荐中使用的方法在不同的研究和实现中有所不同。一些方法侧重于论文的整体内容，而另一些方法则考虑引文文本的上下文。此外，这些研究中使用的数据集包括论文的不同方面，例如元数据、引文上下文，甚至是各种格式和结构的论文全文。模型、数据集和评估指标的多样性使得有效评估和比较引文推荐方法变得具有挑战性。为了解决这个问题，需要一个标准化的数据集和评估指标来一致地评估这些模型。因此，我们建议开发一个专门用于分析和比较引文推荐模型的基准。该基准将评估模型在引文上下文的不同特征上的表现，并对所有这些任务中的模型进行全面评估，以标准化的方式呈现结果。通过创建具有标准化评估指标的基准，引文推荐领域的研究人员和从业者将拥有一个共同的平台来评估和比较不同的模型。这将使有意义的比较成为可能，并有助于确定该领域进一步研究和开发的有前景的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.07713</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FM2DS：基于知识蒸馏的少样本多模态多跳数据合成，用于问答</title>
      <link>https://arxiv.org/abs/2412.07030</link>
      <description><![CDATA[arXiv:2412.07030v1 公告类型：交叉 
摘要：多模态多跳问答是一项复杂的任务，需要对多种信息源（例如图像和文本）进行推理才能回答问题。虽然视觉问答取得了重大进展，但由于缺乏高质量的数据集，多跳设置仍未得到探索。当前的方法侧重于单跳问答或单一模态，这使得它们不适合现实世界的场景，例如分析多模态教育材料、总结冗长的学术文章或解释结合图表、图像和文本的科学研究。为了解决这一差距，我们提出了一种新颖的方法，引入了第一个创建高质量数据集的框架，该数据集支持多模态多跳问答的训练模型。我们的方法包括一个 5 阶段的流程，包括从维基百科获取相关的多模态文档、综合生成高级问题和答案，并通过严格的标准对其进行验证以确保数据质量。我们通过在合成数据集上训练模型并在两个基准上进行测试来评估我们的方法，结果表明，在样本量相同的情况下，在精确匹配 (EM) 方面，在我们的合成数据上训练的模型比在人工收集的数据上训练的模型平均高出 1.9。我们相信我们的数据合成方法将为训练和评估多模态多跳问答模型奠定坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2412.07030</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 RAG 的异构数据和文本问答系统</title>
      <link>https://arxiv.org/abs/2412.07420</link>
      <description><![CDATA[arXiv:2412.07420v1 公告类型：交叉 
摘要：本文介绍了 QUASAR 系统，用于对非结构化文本、结构化表格和知识图进行问答，并统一处理所有来源。该系统采用基于 RAG 的架构，具有证据检索流程和答案生成流程，后者由中等规模的语言模型提供支持。此外，QUASAR 还具有独特的组件，用于问题理解、获取更清晰的证据检索输入，以及在将最具信息量的部分输入答案生成之前对检索到的证据进行重新排序和过滤。使用三个不同基准的实验证明了我们的方法具有很高的回答质量，与大型 GPT 模型相当或更好，同时将计算成本和能耗保持在较低数量级。]]></description>
      <guid>https://arxiv.org/abs/2412.07420</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双语 BSARD：将法定文章检索扩展至荷兰语</title>
      <link>https://arxiv.org/abs/2412.07462</link>
      <description><![CDATA[arXiv:2412.07462v1 公告类型：交叉 
摘要：法定文章检索在使普通民众和法律专业人士更容易获取法律信息方面发挥着至关重要的作用。像比利时这样的多语言国家对检索模型提出了独特的挑战，因为需要处理多种语言的法律问题。在法语比利时法定文章检索数据集 (BSARD) 的基础上，我们推出了该数据集的双语版本 bBSARD。该数据集包含法语和荷兰语的比利时法定文章，以及来自 BSARD 的法律问题及其荷兰语翻译。使用 bBSARD，我们对荷兰语和法语的检索模型进行了广泛的基准测试。我们的基准测试设置包括词汇模型、零样本密集模型和微调的小型基础模型。我们的实验表明，与两种语言的许多零样本密集模型相比，BM25 仍然是一个具有竞争力的基线。我们还观察到，虽然专有模型在零样本设置中的表现优于开放替代方案，但可以通过微调小型语言专用模型来匹敌或超越它们。我们的数据集和评估代码是公开的。]]></description>
      <guid>https://arxiv.org/abs/2412.07462</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OmniDocBench：通过全面的注释对各种 PDF 文档解析进行基准测试</title>
      <link>https://arxiv.org/abs/2412.07626</link>
      <description><![CDATA[arXiv:2412.07626v1 公告类型：交叉 
摘要：文档内容提取在计算机视觉中至关重要，尤其是为了满足大型语言模型 (LLM) 和检索增强生成 (RAG) 技术的高质量数据需求。然而，当前的文档解析方法在多样性和综合评估方面存在很大限制。为了应对这些挑战，我们引入了 OmniDocBench，这是一种旨在推进自动文档内容提取的新型多源基准。OmniDocBench 包含一个精心策划和注释的高质量评估数据集，包含九种不同的文档类型，例如学术论文、教科书、幻灯片等。我们的基准提供了一个灵活而全面的评估框架，具有 19 个布局类别标签和 14 个属性标签，可跨整个数据集、单个模块或特定数据类型进行多级评估。使用 OmniDocBench，我们对现有的模块化流程和多模式端到端方法进行了详尽的比较分析，强调了它们在处理文档多样性和确保公平评估方面的局限性。OmniDocBench 为文档内容提取领域建立了一个强大、多样化和公平的评估标准，为未来的发展提供了重要的见解，并促进了文档解析技术的发展。代码和数据集可在 https://github.com/opendatalab/OmniDocBench 中找到。]]></description>
      <guid>https://arxiv.org/abs/2412.07626</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于捆绑推荐的 Hypergrah 增强双卷积网络</title>
      <link>https://arxiv.org/abs/2312.11018</link>
      <description><![CDATA[arXiv:2312.11018v2 公告类型：替换 
摘要：捆绑推荐力求将一组商品作为名为捆绑包的包裹提供给用户，从而提高便利性并为卖家的收入做出贡献。虽然以前的方法已经表现出显着的性能，但我们认为它们可能会损害用户、商品和捆绑包之间的三元关系。这种妥协可能导致信息丢失，最终影响整体模型性能。为了解决这一差距，我们开发了一个统一的捆绑推荐模型，称为超图增强双卷积神经网络 (HED)。我们的方法有两个关键方面的特点。首先，我们构建一个完整的超图来捕获用户、商品和捆绑包之间的交互动态。其次，我们结合 U-B 交互信息来增强从用户和捆绑包嵌入向量中得出的信息表示。在有书和网易数据集上的大量实验结果表明，HED 超越了最先进的基线，证明了其有效性。此外，各种消融研究和敏感性分析揭示了工作机制并证明了我们的有效性。代码和数据集可在 https://github.com/AAI-Lab/HED 上找到]]></description>
      <guid>https://arxiv.org/abs/2312.11018</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CFaiRLLM：大型语言模型推荐系统中的消费者公平性评估</title>
      <link>https://arxiv.org/abs/2403.05668</link>
      <description><![CDATA[arXiv:2403.05668v2 公告类型：替换 
摘要：这项工作对以前关于基于大型语言模型 (LLM) 的推荐系统中的公平性评估的研究持批判态度，这些研究主要通过比较包含和不包含敏感用户属性的推荐列表来评估消费者公平性。这种方法隐式地将推荐项目中的差异视为偏见，忽略了这些变化是否可能源于与用户真实偏好相一致的真正个性化。此外，这些早期的研究通常孤立地处理单个敏感属性，而忽略了交叉身份的复杂相互作用。为了解决这些缺点，我们引入了 CFaiRLLM，这是一个增强的评估框架，它不仅结合了真正的偏好一致性，而且还通过考虑重叠的敏感属性来严格检查交叉公平性。此外，CFaiRLLM 引入了多种用户配置文件采样策略 - 随机、最高评级和新近度 - 以更好地理解在这些系统固有的令牌限制下输入到 LLM 的配置文件生成的影响。鉴于公平性取决于准确理解用户的品味和偏好，这些策略提供了对 RecLLM 中公平性的更现实的评估。
结果表明，与基于相似性的衡量标准相比，真正的偏好一致性提供了更个性化和公平的评估，当纳入敏感和交叉属性时，会发现显著的差异。值得注意的是，我们的研究发现，交叉属性会更显著地放大公平性差距，尤其是在结构化程度较低的领域，例如 LastFM 中的音乐推荐。]]></description>
      <guid>https://arxiv.org/abs/2403.05668</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>