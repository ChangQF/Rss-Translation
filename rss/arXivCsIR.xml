<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Ragnar_"ok：可重复使用的 RAG 框架和 TREC 2024 检索增强生成轨道的基线</title>
      <link>https://arxiv.org/abs/2406.16828</link>
      <description><![CDATA[arXiv:2406.16828v1 公告类型：新
摘要：您尝试过新的 Bing 搜索吗？或者您可能摆弄过 Google AI~Overviews？这些可能听起来很熟悉，因为现代搜索堆栈最近已经发展到包括检索增强生成 (RAG) 系统。它们允许搜索并将实时数据合并到大型语言模型 (LLM) 中，以提供充分知情、归因、简洁的摘要，这与依赖于显示文档排序列表的传统搜索范式形成鲜明对比。因此，鉴于这些最新进展，拥有一个构建、测试、可视化和系统评估基于 RAG 的搜索系统的舞台至关重要。考虑到这一点，我们提出了 TREC 2024 RAG Track 以促进评估 RAG 系统的创新。在我们的工作中，我们列出了实现这一目标所采取的步骤——我们描述了可重复使用框架 Ragnar&quot;ok 的细节，解释了新 MS MARCO V2.1 系列选择的策划，发布了该轨道的开发主题，并标准化了有助于最终用户的 I/O 定义。接下来，使用 Ragnar&quot;ok，我们识别并提供关键的工业基准，例如 OpenAI 的 GPT-4o 或 Cohere 的 Command R+。此外，我们为交互式舞台引入了一个基于 Web 的用户界面，允许通过众包对成对 RAG 系统进行基准测试。我们开源了我们的 Ragnar&quot;ok 框架和基准，以实现未来 RAG 系统的统一标准。]]></description>
      <guid>https://arxiv.org/abs/2406.16828</guid>
      <pubDate>Wed, 26 Jun 2024 03:17:02 GMT</pubDate>
    </item>
    <item>
      <title>揭秘食物搭配：通过推荐系统探索食谱创作动态</title>
      <link>https://arxiv.org/abs/2406.15533</link>
      <description><![CDATA[arXiv:2406.15533v1 公告类型：交叉
摘要：21 世纪初，著名厨师 Heston Blumenthal 提出了“食物搭配”假说，认为如果食物具有许多共同的风味化合物，那么它们一起吃时往往会味道很好。2011 年，Ahn 等人使用食谱、配料和风味化合物的数据集进行了一项研究，发现在西方美食中，食谱中的配料通常比偶然预期的具有更多的风味化合物，这表明食物搭配是一种自然的倾向。在 Ahn 研究的基础上，我们的工作将最先进的协同过滤技术应用于数据集，提供了一种工具，可以推荐在食谱中添加新食物、检索缺失的配料并建议不要使用某些组合。我们通过两种方式创建推荐器，即考虑食谱中的配料外观或食物之间共享的风味化合物。虽然我们的分析证实了食物搭配的存在，但基于食谱的推荐器的表现明显优于基于风味的推荐器，这让我们得出结论，食物搭配只是制作食谱时要考虑的原则之一。此外，更有趣的是，我们发现数据中的食物搭配主要是由于非常相似的成分的微不足道的结合，这让我们重新考虑它在食谱中的当前作用，从已经存在的功能到开辟美食新场景的关键。因此，我们基于风味的推荐器可以利用这一新概念，并提供引领烹饪创新的新工具。]]></description>
      <guid>https://arxiv.org/abs/2406.15533</guid>
      <pubDate>Wed, 26 Jun 2024 03:17:02 GMT</pubDate>
    </item>
    <item>
      <title>Star+：一种用于 CTR 预测的新型多领域模型</title>
      <link>https://arxiv.org/abs/2406.16568</link>
      <description><![CDATA[arXiv:2406.16568v1 公告类型：新
摘要：在本文中，我们介绍了 Star+，这是一种受 Star 模型启发的用于点击率 (CTR) 预测的新型多域模型。传统的单域方法和现有的多任务学习技术在多域环境中面临挑战，因为它们无法捕获特定于域的数据分布和复杂的域间关系。Star+ 通过各种融合策略（例如添加、自适应添加、连接和门控融合）增强共享和特定于域信息之间的交互来解决这些限制，以找到特定于域和共享信息之间的最佳平衡。我们还研究了不同的规范化技术（包括层规范化、批量规范化和分区规范化）对我们模型性能的影响。我们在工业和公共数据集上进行的大量实验表明，Star+ 显着提高了预测准确性和效率。这项工作通过为多域环境提供强大、可扩展和自适应的解决方案，促进了推荐系统的进步。]]></description>
      <guid>https://arxiv.org/abs/2406.16568</guid>
      <pubDate>Wed, 26 Jun 2024 03:17:01 GMT</pubDate>
    </item>
    <item>
      <title>元实验：通过实验改进实验</title>
      <link>https://arxiv.org/abs/2406.16629</link>
      <description><![CDATA[arXiv:2406.16629v1 公告类型：新
摘要：A/B 测试在行业中被广泛用于优化面向客户的网站。许多公司聘请实验专家来促进和改进 A/B 测试流程。在这里，我们通过在实验过程中运行实验（我们称之为“元实验”）来介绍 A/B 测试在这种改进工作中的应用。我们使用我们的一个元实验的例子讨论了这种方法的挑战，它帮助实验者运行更充分的 A/B 测试。我们还指出了“狗食”对实验专家在运行自己的实验时的好处。]]></description>
      <guid>https://arxiv.org/abs/2406.16629</guid>
      <pubDate>Wed, 26 Jun 2024 03:17:01 GMT</pubDate>
    </item>
    <item>
      <title>通过元优化方法实现价态偏好的跨域转移</title>
      <link>https://arxiv.org/abs/2406.16494</link>
      <description><![CDATA[arXiv:2406.16494v1 公告类型：新
摘要：跨域推荐为缓解数据稀疏和冷启动问题提供了潜在的途径。嵌入和映射作为一种经典的跨域研究类型，旨在确定一个通用的映射函数来执行两个域之间的表示转换。然而，以前的粗粒度偏好表示、非个性化映射函数和对重叠用户的过度依赖限制了它们的性能，特别是在重叠用户稀疏的场景中。为了解决上述挑战，我们提出了一种新颖的跨域方法，即 CVPM。CVPM 将跨域兴趣转移形式化为参数元学习和自监督学习的混合架构，它不仅可以在更精细的层次上转移用户偏好，而且还可以利用非重叠用户的知识增强信号。具体而言，通过深入了解用户偏好和价态偏好理论，我们认为用户的积极偏好和消极行为之间存在显着差异，因此采用差异化编码器来学习它们的分布。特别是，我们进一步利用预训练模型和物品流行度来采样伪交互物品以确保两个分布的完整性。为了保证偏好转移的个性化，我们将每个用户的映射视为两部分，即共同变换和个性化偏差，其中用于生成个性化偏差的网络由元学习器输出。此外，除了重叠用户的监督损失之外，我们还从群体和个体层面为非重叠用户设计了对比任务，以避免模型偏差并增强表示的语义。详尽的数据分析和大量的实验结果证明了我们提出的框架的有效性和先进性。]]></description>
      <guid>https://arxiv.org/abs/2406.16494</guid>
      <pubDate>Wed, 26 Jun 2024 03:17:00 GMT</pubDate>
    </item>
    <item>
      <title>意图感知推荐系统综述</title>
      <link>https://arxiv.org/abs/2406.16350</link>
      <description><![CDATA[arXiv:2406.16350v1 公告类型：新
摘要：许多现代在线服务都具有个性化推荐。提供此类推荐时面临的一个核心挑战是，单个用户访问服务的原因可能会因访问而改变，甚至在持续使用会话期间也会改变。因此，为了有效，推荐系统应旨在考虑用户在某个时间点使用该服务的可能意图。近年来，研究人员开始通过将意图感知纳入推荐系统来应对这一挑战。相应地，提出了许多技术方法，包括多样化技术、意图预测模型或潜在意图建模方法。在本文中，我们调查并分类了构建下一代意图感知推荐系统 (IARS) 的现有方法。基于对当前评估实践的分析，我们概述了该领域的开放差距和可能的未来方向，特别是包括考虑额外的交互信号和上下文信息以进一步提高此类系统的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.16350</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>论长尾知识在检索增强大型语言模型中的作用</title>
      <link>https://arxiv.org/abs/2406.16367</link>
      <description><![CDATA[arXiv:2406.16367v1 公告类型：新
摘要：检索增强生成 (RAG) 在提升大型语言模型 (LLM) 的知识能力方面表现出色，检索到的文档与用户查询相关。然而，RAG 只关注通过使用检索到的信息不加区分地增强查询来提高 LLM 的响应质量，而很少关注 LLM 真正需要什么类型的知识才能更准确地回答原始查询。在本文中，我们认为长尾知识对于 RAG 至关重要，因为 LLM 在大规模预训练期间已经记住了世界常识。基于我们的观察，我们提出了一种简单但有效的 LLM 长尾知识检测方法。具体而言，我们推导出新颖的生成预期校准误差 (GECE) 指标，以基于统计和语义来衡量知识的“长尾性”。因此，只有当输入查询与长尾知识相关时，我们才会检索相关文档并将其注入模型中以修补知识漏洞。实验表明，与现有的 RAG 流程相比，我们的方法在平均推理时间上实现了 4 倍以上的加速，并且在下游任务中实现了持续的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2406.16367</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>上下文增强检索：一种使用大型语言模型进行快速信息检索的响应生成新框架</title>
      <link>https://arxiv.org/abs/2406.16383</link>
      <description><![CDATA[arXiv:2406.16383v1 公告类型：新
摘要：通过提供嵌入在传递给大型语言模型 (LLM) 的提示中的上下文信息来持续生成高质量答案取决于信息检索的质量。随着上下文信息语料库的增长，基于检索增强生成 (RAG) 的问答 (QA) 系统的答案/推理质量下降。这项工作通过将经典文本分类与大型语言模型 (LLM) 相结合来解决此问题，以便从向量存储中快速检索信息并确保检索到的信息的相关性。为此，这项工作提出了一种新方法上下文增强检索 (CAR)，其中通过实时分类流入语料库的信息对向量数据库进行分区。CAR 展示了高质量的答案生成，同时显着减少了信息检索和答案生成时间。]]></description>
      <guid>https://arxiv.org/abs/2406.16383</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:59 GMT</pubDate>
    </item>
    <item>
      <title>SimCE：简化协同过滤的交叉熵损失</title>
      <link>https://arxiv.org/abs/2406.16170</link>
      <description><![CDATA[arXiv:2406.16170v1 公告类型：新
摘要：学习目标是协同过滤系统中不可或缺的一部分，其中贝叶斯个性化排名 (BPR) 损失被广泛用于学习信息主干。然而，BPR 通常会经历缓慢的收敛和次优的局部最优，部分原因是它只考虑每个正项的一个负项，而忽略了其他未观察到的项的潜在影响。为了解决这个问题，最近提出的采样 Softmax 交叉熵 (SSM) 将一个正样本与多个负样本进行比较，从而获得更好的性能。我们的综合实验证实，推荐系统在训练过程中始终受益于多个负样本。此外，我们引入了一个 \underline{Sim}plified 采样 Softmax \underline{C}ross-\underline{E}ntropy 损失 (SimCE)，它使用其上限简化了 SSM。我们使用 MF 和 LightGCN 主干对 12 个基准数据集进行了验证，结果表明 SimCE 的表现明显优于 BPR 和 SSM。]]></description>
      <guid>https://arxiv.org/abs/2406.16170</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>DemoRank：在排名任务中为大型语言模型选择有效的演示</title>
      <link>https://arxiv.org/abs/2406.16332</link>
      <description><![CDATA[arXiv:2406.16332v1 公告类型：新
摘要：最近，人们对将大型语言模型 (LLM) 应用于零样本段落排序器的兴趣日益浓厚。然而，很少有研究探讨如何为段落排序任务选择合适的上下文演示，而这正是本文的重点。先前的研究主要应用演示检索器来检索演示，并使用前 $k$ 个演示进行上下文学习 (ICL)。虽然这种方法有效，但它忽略了演示之间的依赖关系，导致少样本 ICL 在段落排序任务中的表现较差。在本文中，我们将演示选择公式化为 \textit{retrieve-then-rerank} 过程，并引入 DemoRank 框架。在这个框架中，我们首先使用 LLM 反馈来训练演示检索器，并构建一种新颖的依赖感知训练样本来训练演示重排序器以改进少样本 ICL。这种训练样本的构建不仅考虑了演示依赖关系，而且执行效率高。大量实验证明了 DemoRank 在领域内场景中的有效性以及对领域外场景的强大泛化能力。我们的代码可在以下位置获取：~\url{https://github.com/8421BCD/DemoRank}。]]></description>
      <guid>https://arxiv.org/abs/2406.16332</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:58 GMT</pubDate>
    </item>
    <item>
      <title>评估信息检索中部分注释的 D-MERIT</title>
      <link>https://arxiv.org/abs/2406.16048</link>
      <description><![CDATA[arXiv:2406.16048v1 公告类型：新
摘要：检索模型通常在部分注释的数据集上进行评估。每个查询都映射到一些相关文本，其余语料库则被视为不相关。因此，成功检索假阴性的模型在评估中会受到惩罚。不幸的是，为每个查询完全注释所有文本并不节省资源。在这项工作中，我们表明在评估中使用部分注释的数据集可能会产生扭曲的画面。我们从维基百科中整理了 D-MERIT，这是一个段落检索评估集，旨在包含每个查询的所有相关段落。查询描述一个组（例如，“关于语言学的期刊”），相关段落是实体属于该组的证据（例如，一段表明《语言》是关于语言学的期刊的段落）。我们表明，在仅包含相关段落子集注释的数据集上进行评估可能会导致检索系统的排名产生误导，并且随着评估集中包含更多相关文本，排名会趋于一致。我们建议将我们的数据集作为评估资源，并将我们的研究作为在注释文本检索评估集时在资源效率和可靠评估之间取得平衡的建议。]]></description>
      <guid>https://arxiv.org/abs/2406.16048</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>评估新闻推荐系统的集成方法</title>
      <link>https://arxiv.org/abs/2406.16106</link>
      <description><![CDATA[arXiv:2406.16106v1 公告类型：新
摘要：新闻推荐对于促进个人获取文章至关重要，特别是在新闻消费日益数字化的背景下。因此，大量研究致力于新闻推荐系统 (NRS)，其算法也越来越复杂。尽管进行了持续的学术研究，但关于通过合并这些算法以产生更优结果而实现的潜在协同作用的研究仍然存在显着差距。本文致力于通过展示如何使用集成方法将许多不同的最新算法结合起来以在 Microsoft News 数据集 (MIND) 上获得更优结果来解决这一差距。此外，我们确定了集成方法无法改善结果的情况并对此现象提供解释。我们的研究结果表明，只要基础学习者足够多样化，NRS 算法的组合可以胜过单个算法，对于由基于内容的 BERT 方法和协同过滤 LSTUR 算法组成的集成，可以观察到高达 5\% 的改进。此外，我们的结果表明，当组合不够独特的方法时，没有任何改进。这些发现为 NRS 中集成方法的成功提供了见解，并提倡通过适当的集成解决方案开发更好的系统。]]></description>
      <guid>https://arxiv.org/abs/2406.16106</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:57 GMT</pubDate>
    </item>
    <item>
      <title>学习 k 行列式点过程以实现个性化排名</title>
      <link>https://arxiv.org/abs/2406.15983</link>
      <description><![CDATA[arXiv:2406.15983v1 公告类型：新
摘要：个性化推荐的关键是通过对用户偏好进行建模来预测项目目录的个性化排名。有许多个性化排名方法可用于从隐式反馈中进行项目推荐，例如贝叶斯个性化排名 (BPR) 和列表排名。尽管这些方法已显示出性能优势，但仍存在影响推荐性能的局限性。首先，它们都没有直接优化集合的排名，导致无法充分利用多个项目之间的相关性。其次，与相关性相比，推荐的多样性方面没有得到充分解决。
在这项工作中，我们提出了一种基于集合概率比较的个性化排名新优化标准 LkP，它超越了传统的基于排名的方法。它通过行列式点过程 (DPP) 核分解形式化集合级相关性和多样性排名比较。为了赋予 DPP 集概率排名可解释性并优先考虑 LkP 的实用性，我们根据 DPP 分布集的基数 k 来设定标准 DPP，称为 k-DPP，这是 DPP 的一个较少探索的扩展。基于通用随机梯度下降的技术可以直接应用于优化采用 LkP 的模型。我们在三个真实数据集上结合矩阵分解 (MF) 和神经网络方法实现了 LkP，获得了更好的相关性和多样性性能。LkP 适用范围广泛，当应用于现有推荐模型时，它也能带来显著的性能提升，这表明 LkP 对推荐系统领域具有重要价值。]]></description>
      <guid>https://arxiv.org/abs/2406.15983</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:56 GMT</pubDate>
    </item>
    <item>
      <title>FIRST：使用单标记解码实现更快的列表重新排序</title>
      <link>https://arxiv.org/abs/2406.15657</link>
      <description><![CDATA[arXiv:2406.15657v1 公告类型：新
摘要：大型语言模型 (LLM) 极大地推动了信息检索领域的发展，尤其是在重新排序方面。与现有的监督方法相比，列表式 LLM 重新排序器展示了卓越的性能和通用性。然而，传统的列表式 LLM 重新排序方法缺乏效率，因为它们以生成的候选段落标识符的有序序列的形式提供排名输出。此外，它们是用典型的语言建模目标进行训练的，该目标统一处理所有排名错误——可能以对高度相关的段落进行错误排名为代价。为了解决这些限制，我们引入了 FIRST，这是一种新颖的列表式 LLM 重新排序方法，利用第一个生成的标识符的输出逻辑来直接获得候选的排名顺序。此外，我们在训练过程中加入了学习排名损失，优先考虑更相关段落的排名准确性。实证结果表明，FIRST 将推理速度提高了 50%，同时保持了稳健的排名性能，并在 BEIR 基准测试中有所提升。最后，为了说明列表式 LLM 重排器的实际效果，我们研究了它们在推理过程中为检索器提供相关性反馈的应用。我们的结果表明，与交叉编码器相比，LLM 重排器可以提供更强的蒸馏信号，从而显著提高检索器在相关性反馈后的召回率。]]></description>
      <guid>https://arxiv.org/abs/2406.15657</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:55 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士的解释：通过子图推理阐明建议</title>
      <link>https://arxiv.org/abs/2406.15859</link>
      <description><![CDATA[arXiv:2406.15859v1 公告类型：新
摘要：推荐系统通过分析用户和项目之间的复杂关系，在增强各种 Web 应用程序中的用户体验方面发挥着关键作用。知识图谱 (KG) 已被广泛用于增强推荐系统的性能。然而，众所周知，KG 是有噪声和不完整的，很难为推荐结果提供可靠的解释。可解释的推荐系统对于产品开发和后续决策至关重要。为了应对这些挑战，我们引入了一种新型推荐器，它协同大型语言模型 (LLM) 和 KG 来增强推荐并提供可解释的结果。具体来说，我们首先利用 LLM 的功能来增强 KG 重建。LLM 理解并将用户评论分解为添加到 KG 中的新三元组。通过这种方式，我们可以用表达用户偏好的可解释路径来丰富 KG。为了增强增强知识图谱的推荐，我们引入了一种新颖的子图推理模块，可以有效地衡量节点的重要性并发现推荐的推理。最后，这些推理路径被输入到 LLM 中，以生成推荐结果的可解释解释。我们的方法显著提高了推荐系统的有效性和可解释性，尤其是在传统方法失效的交叉销售场景中。我们的方法的有效性已经在四个开放的真实世界数据集上进行了严格测试，我们的方法比当代最先进的技术表现出更好的性能，平均提高了 12%。我们的模型在一家跨国工程和技术公司交叉销售推荐系统中的应用进一步强调了它的实用性和通过提高准确性和用户信任度重新定义推荐实践的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.15859</guid>
      <pubDate>Wed, 26 Jun 2024 03:16:55 GMT</pubDate>
    </item>
    </channel>
</rss>