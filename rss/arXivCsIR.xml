<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 06 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过基于图的检索增强发电来优化开放域问题</title>
      <link>https://arxiv.org/abs/2503.02922</link>
      <description><![CDATA[ARXIV：2503.02922V1公告类型：新 
摘要：在这项工作中，我们基于各种查询类型的各种基于图的检索增强生成（RAG）系统，包括OLTP式（基于事实）和OLAP式（主题）查询，以解决开放域问题答案（QA）的复杂需求。传统的抹布方法通常在处理细微的多档案综合任务方面缺乏。通过将知识构造为图形，我们可以促进捕获更大语义深度并增强语言模型操作的上下文检索。我们探索基于图的抹布方法，并引入Trex，这是一种新颖的，具有成本效益的替代方案，结合了基于图的和基于矢量的检索技术。我们在四个不同数据集中的基准测试强调了不同抹布方法的优势，证明了TREX处理多种开放域QA类型的能力，并揭示了当前评估方法的局限性。
  在现实世界中的技术支持案例研究中，我们演示了Trex解决方案如何在有效地合成异质来源的数据中超过常规矢量的抹布。我们的发现强调了通过高级检索和编排功能增强大型语言模型的潜力，可以推进可扩展的基于图的AI解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.02922</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在各种情况下，固有和外在因素分解供推荐</title>
      <link>https://arxiv.org/abs/2503.03524</link>
      <description><![CDATA[ARXIV：2503.03524V1公告类型：新 
摘要：在推荐系统中，用户行为的模式（例如，购买，单击）可能在不同的上下文（例如时间和位置）中差异很大。这是因为用户行为由两种因素共同决定：内在因素反映了一致的用户偏好和外部因素，这些因素反映了外部激励措施在不同情况下可能会有所不同。区分内在和外在因素有助于更好地学习用户行为。但是，现有的研究仅考虑将它们与单个预定义的上下文（例如时间或位置）区分开来，而忽略了一个事实，即用户的外部因素可能会同时受到各种情况的相互作用的影响。在本文中，我们提出了固有的分解建议（IEDR）模型，该模型是一种通用框架，该框架与同时考虑各种情况的外在因素区分开来，从而更准确地分化了因素，从而提高了建议准确性。 IEDR包含一个上下文不变的对比度学习组件，以捕获内在因素，以及在各种情况相互作用下提取外在因素的分离组件。这两个组件共同努力，以实现有效的因素学习。对现实世界数据集的广泛实验表明，IEDR在学习分离的因素方面的有效性，并在NDCG中最多提高了4％的建议精度。]]></description>
      <guid>https://arxiv.org/abs/2503.03524</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解耦建议系统：探索替代建议生态系统设计</title>
      <link>https://arxiv.org/abs/2503.03606</link>
      <description><![CDATA[ARXIV：2503.03606V2公告类型：新 
摘要：推荐生态系统是新兴的研究主题。这样的研究研究了算法，建议消费者和项目提供商的特征如何影响系统动态和长期结果。在这一研究中，尚未广泛探索的一种建筑可能性是配置的后果，在这种配置中，建议算法与它们所提供的平台分离。这有时称为“友好的社区算法商店”或“中间件”模型。我们对这些架构如何在消费者，提供商和推荐平台之间提供一系列不同分布的公用事业分布特别感兴趣。在本文中，我们创建了一个建议生态系统的模型，该模型结合了算法选择并检查了这种设计的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.03606</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决过度处方挑战：用于药物建议任务的微调大语模型</title>
      <link>https://arxiv.org/abs/2503.03687</link>
      <description><![CDATA[ARXIV：2503.03687V1公告类型：新 
摘要：药物建议系统在医疗保健中引起了人们的关注，因为它们的潜力根据患者的临床数据提供了个性化和有效的药物组合。但是，现有的方法论在适应各种电子健康记录（EHR）系统方面遇到了挑战，并有效地利用了非结构化数据，从而导致概括能力有限和次优性能。最近，利用医疗领域的大型语言模型（LLM）的兴趣正在增长，以支持医疗保健专业人员并增强患者护理。尽管医疗LLM的出现及其有希望的结果，例如医学问答，但它们在临床环境中的实际适用性，尤其是在药物建议中，但通常仍然没有被置换。
  在这项研究中，我们评估了通用和医学特异性LLM的药物建议任务。我们的发现表明，LLMS经常遇到过度处方的挑战，导致临床风险增加并降低了药物建议精度。为了解决这个问题，我们提出了语言辅助药物建议（LAMO），该建议采用参数有效的微调方法来量身定制开源LLM，以在药物建议方案中进行最佳性能。 Lamo在临床注释中利用了大量的临床信息，这是一种在传统方法论中通常不足的资源。由于我们的方法，LAMO的内部验证精度超过10％以上的先前最新方法。此外，时间和外部验证证明了Lamo在各种时间和医院环境中的强大概括能力。此外，即使在培训数据之外的药物中，分发药物推荐实验也表明了Lamo的出色准确性。]]></description>
      <guid>https://arxiv.org/abs/2503.03687</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ExpertGenQA：专业领域的开放式质量检查生成</title>
      <link>https://arxiv.org/abs/2503.02948</link>
      <description><![CDATA[ARXIV：2503.02948V1公告类型：交叉 
摘要：为专门的技术领域生成高质量的问题 - 答案对仍然具有挑战性，现有方法在利用专家示例和实现主题多样性之间面临着权衡。我们提出了ExpertGenQA，该协议将几乎没有的学习与结构化主题和样式分类结合在一起，以生成全面的域特异性质量质量质量质量对。使用美国联邦铁路管理文件作为测试床，我们证明了ExpertgenQA在维持$ 94.4 \％$主题覆盖范围的同时，实现了两倍的基线方法。通过系统的评估，我们表明当前基于LLM的法官和奖励模型对肤浅的写作风格而不是内容质量表现出很大的偏见。我们使用Bloom的分类法分析表明，与基于模板的方法相比，专家Genqa更好地保留了专家编写问题的认知复杂性分布。当用于训练检索模型时，我们生成的查询将TOP-1的准确性提高了$ 13.02 \％$，而不是基线性能，证明了它们在技术域中下游应用的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.02948</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bangla文档的零射击多标签分类：大解码器VS。经典编码器</title>
      <link>https://arxiv.org/abs/2503.02993</link>
      <description><![CDATA[ARXIV：2503.02993V1公告类型：交叉 
摘要：孟加拉国是一种超过3亿本名母语的人所说的语言，并被排名全球第六种口语，由于其复杂的形态学特征和有限的资源，在自然语言处理（NLP）中提出了独特的挑战（NLP）。尽管最近基于大型解码器的模型（LLM），例如GPT，Llama和DeepSeek，在许多NLP任务中都表现出了出色的性能，但它们在孟加拉的有效性仍未得到探索。在本文中，我们建立了第一个基准测试，将基于解码器的LLM与基于经典编码器的模型进行了零击的多标签分类（零摄像-MLC）任务。我们对32种最先进模型的评估表明，现有的所谓强大编码器和解码器仍在努力实现Bangla Zero-Sho-Shot-MLC任务的高精度，这表明需要为Bangla NLP进行更多的研究和资源。]]></description>
      <guid>https://arxiv.org/abs/2503.02993</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半监督的内在学习学习：基线研究</title>
      <link>https://arxiv.org/abs/2503.03062</link>
      <description><![CDATA[ARXIV：2503.03062V1公告类型：交叉 
摘要：在数据选择中的大多数现有工作（ICL）的重点是从地面真理注释中构建演示，而对选择可靠的自我生成的注释的关注有限。在这项工作中，我们提出了一个三步半监督的ICL框架：注释生成，演示选择和半监督推理。我们的基线Naive-semiicl提示选择ICL提示的高信任自我生成的演示，在16个数据集中，平均比16次射击基线的表现平均高9.94％。我们进一步介绍了ITERPSD，这是一种注释方法，可以迭代地完善伪示例，在分类任务中获得多达6.8％的额外收益。最后，我们揭示了半监督ICL的缩放定律，其中模型以1,000多次示威来实现最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2503.03062</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测到优化的客户分配框架在线基金建议</title>
      <link>https://arxiv.org/abs/2503.03165</link>
      <description><![CDATA[ARXIV：2503.03165V1公告类型：交叉 
摘要：随着在线投资平台的快速增长，资金可以在线分配给个人客户。核心问题是将资金与受到限制的潜在客户相匹配。大多数主流平台采用建议公式来解决问题。但是，在应用多个约束的基金匹配问题时，传统的建议制度具有固有的缺点。在本文中，我们在分配公式下对基金匹配进行建模。我们设计了tofa，这是一个预测的，然后优化的资金分配框架。该数据驱动的框架包括两个阶段，即预测和优化，旨在根据客户行为来预测预期收入，并优化印象分配，分别在必要的约束下获得最大收入。来自工业在线投资平台的实际数据集进行了广泛的实验验证了我们解决方案的有效性和效率。此外，在线A/B测试证明了PTOFA在现实世界基金推荐方案中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.03165</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长期推荐模型需要脱钩的嵌入</title>
      <link>https://arxiv.org/abs/2410.02604</link>
      <description><![CDATA[ARXIV：2410.02604V2公告类型：替换 
摘要：终身用户行为序列对于捕获用户兴趣和预测现代推荐系统中的用户响应至关重要。通常采用两个阶段范式来处理这些长序列：首先通过第一阶段的注意机制从原始长序列中搜索相关行为的子集，然后用目标项目汇总以构建第二阶段预测的区分表示。在这项工作中，我们首次确定并表征了现有的长期推荐模型中被忽视的缺陷：一组嵌入式努力在学习注意力和表示方面都在努力，从而导致这两个过程之间的干扰。通过一些常见方法（例如，线性预测 - 从语言处理中借来的一种技术）的初步尝试被证明是无效的，阐明了建议模型的独特挑战。为了克服这一点，我们提出了脱钩的注意力和表示嵌入（DARE）模型，其中两个不同的嵌入表被初始化并分别学习，以完全解除注意力和表示。广泛的实验和分析表明，DARE提供了对相关行为的更准确搜索，并且在公共数据集中获得了高达0.9％的AUC，并在Tencent的广告平台上取得了显着改进。此外，解耦嵌入空间使我们能够将注意力嵌入维度降低，并将搜索程序降低50％，而不会产生重大的性能影响，从而实现了更高效，更高性能的在线服务。 Pytorch中的代码用于实验，包括模型分析，可在https://github.com/thuml/dare上获得。]]></description>
      <guid>https://arxiv.org/abs/2410.02604</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越内容相关性：在检索模型中评估教学</title>
      <link>https://arxiv.org/abs/2410.23841</link>
      <description><![CDATA[Arxiv：2410.23841V2公告类型：替换 
摘要：LLMS中的指令遵循功能已取得显着发展，从而通过详细的提示来实现更复杂的用户交互。但是，检索系统尚未与这些进步相匹配，其中大多数仍然依赖于无法完全捕获用户意图的传统词汇和语义匹配技术。最近的努力介绍了指导感知的检索模型，但主要集中于内在内容相关性，这忽略了定制偏好对更广泛文档级别属性的重要性。这项研究评估了除内容相关性之外的各种检索模型的指导跟踪功能，包括基于LLM的密集检索和重新依赖模型。我们开发了InfoSearch，这是一种新型的检索评估基准，涵盖了六个文档级属性：受众，关键字，格式，语言，长度和来源，并介绍新颖的指标 - 严格的指导依从性比率（SICR）和加权教学敏感性评估（WISE），以准确评估模型对说明的模型的响应能力。我们的发现表明，尽管有关指导感知的检索数据集的微调模型并增加了模型尺寸，但大多数模型仍然缺乏指导符合性。]]></description>
      <guid>https://arxiv.org/abs/2410.23841</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用空气质量传感器网络数据用于实时污染意识到的POI建议</title>
      <link>https://arxiv.org/abs/2502.09155</link>
      <description><![CDATA[Arxiv：2502.09155V2公告类型：替换 
摘要：该演示论文介绍了Airsense-R，这是一种保护隐私的移动应用程序，可为城市兴趣点（POI）提供实时，污染意识到的建议。通过从巴里（意大利）和科克（爱尔兰）的Airsence传感器网络与用户偏好合并实时空气质量数据，该系统可以实现对健康意识的决策。它采用协作过滤进行个性化，联合学习的隐私学习以及预测引擎来检测异常和插值稀疏传感器数据。提出的解决方案动态适应城市空气质量，同时保护用户隐私。代码和演示视频可在https://github.com/airtownapp/airtown-application.git上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.09155</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>地图：通过LLM驱动的咨询对齐方式的动机感知的个性化搜索</title>
      <link>https://arxiv.org/abs/2503.01711</link>
      <description><![CDATA[ARXIV：2503.01711V3公告类型：替换 
摘要：个性化的产品搜索旨在检索和排名与用户偏好和搜索意图相匹配的项目。尽管它们有效，但现有方法通常假定用户的查询完全捕捉了他们的真正动机。但是，我们对现实世界电子商务平台的分析表明，用户在搜索之前经常进行相关咨询，表明他们通过基于动机和需求的咨询来完善意图。咨询中隐含的动机是个性化搜索的关键增强因素。这个未开发的领域面临着新的挑战，包括将上下文动机与简洁的查询保持一致，弥合类别文本差距以及序列历史记录中的噪声。为了解决这些问题，我们提出了一种动机意识的个性化搜索（地图）方法。它通过LLM将查询和咨询嵌入到统一的语义空间中，利用注意专家（MOAE）的混合物优先考虑关键语义，并引入双重对准：（1）对比度学习对比学习，评论，评论和产品功能； （2）双向注意将动机感知的嵌入与用户偏好相结合。关于真实和合成数据的广泛实验显示，地图在检索和排名任务中的现有方法都优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.01711</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>简化的检索器，通过大语言模型提高表型正常化的准确性</title>
      <link>https://arxiv.org/abs/2409.13744</link>
      <description><![CDATA[ARXIV：2409.13744V2公告类型：替换 - 交叉 
摘要：大型语言模型（LLMS）在与猎犬增强时，在表型术语标准化任务中的准确性提高了精度，这些猎犬建议根据术语定义提出候选归一化。在这项工作中，我们引入了一个简化的检索器，该检索器通过搜索人类表型本体论（HPO）使用Biobert的上下文词嵌入而无需明确的术语定义来提高LLM准确性。测试此方法对从在线Mendelian继承的临床概要（OMIM）中得出的术语，我们证明，最先进的LLM的正常化准确性从基线从62.3％的基线增加，而无需增强，而恢复剂的增强量则增加了90.3％。这种方法可能可以推广到其他生物医学术语标准化任务，并为更复杂的检索方法提供了有效的替代方法。]]></description>
      <guid>https://arxiv.org/abs/2409.13744</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越Matryoshka：重新访问自适应表示的稀疏编码</title>
      <link>https://arxiv.org/abs/2503.01776</link>
      <description><![CDATA[Arxiv：2503.01776V2公告类型：替换 - 交叉 
摘要：许多大规模系统依靠高质量的深度表示（嵌入）来促进诸如检索，搜索和生成型建模之类的任务。 Matryoshka表示学习（MRL）最近作为自适应嵌入长度的解决方案出现，但是它需要完整的模型再培训，并且在短长度上遭受了明显的性能降解。在本文中，我们表明，稀疏编码为实现自适应表现提供了令人信服的替代方案，并以最小的开销和更高的忠诚度。我们提出了对比度稀疏表示（CSR），这种方法将预先训练的嵌入量稀疏到高维但有选择性激活的特征空间中。通过利用轻量级自动编码和任务意识到的对比目标，CSR可以保留语义质量，同时允许在不同的稀疏度级别的灵活，具有成本效益的推断。关于图像，文本和多模式基准的广泛实验表明，CSR的表现始终优于MRL的准确性和检索速度，而大幅度通常也将训练时间切成了MRL所需的一小部分。我们的结果将稀疏编码确定为在效率和保真度都至关重要的现实应用程序中自适应表示学习的强大范式。代码可从https://github.com/neilwen987/csr_adaptive_rep获得]]></description>
      <guid>https://arxiv.org/abs/2503.01776</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MCITEBENCH：MLLM中多模式引用文本生成的基准</title>
      <link>https://arxiv.org/abs/2503.02589</link>
      <description><![CDATA[ARXIV：2503.02589V2公告类型：替换 - 交叉 
摘要：多模式大语模型（MLLM）在整合多种方式方面已经进步，但经常遭受幻觉的困扰。缓解此问题的有前途的解决方案是用引用生成文本，提供透明的链条进行验证。但是，现有工作主要集中于为仅文本内容引用引用，忽视了多模式环境的挑战和机会。为了解决这一差距，我们介绍了MciteBench，这是第一个旨在评估和分析MLLM的多模式引用文本生成能力的基准。我们的基准包括来自学术论文和评论 - 雷神交互的数据，这些数据具有多种信息源和多模式内容。我们全面评估了来自多个维度的模型，包括引文质量，源可靠性和答案准确性。通过广泛的实验，我们观察到MLLM与多模式引用文本生成斗争。我们还对模型的性能进行了深入的分析，表明瓶颈在于归因于正确的来源，而不是理解多模式内容。]]></description>
      <guid>https://arxiv.org/abs/2503.02589</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>