<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 26 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>排名者，法官和助手：了解LLM在信息检索评估中的相互作用</title>
      <link>https://arxiv.org/abs/2503.19092</link>
      <description><![CDATA[ARXIV：2503.19092V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地与信息检索（IR），供电排名，评估和AI辅助内容创建不可或缺。这种广泛的采用需要对这些基于LLM的组件之间的相互作用产生的潜在偏见进行批判性检查。本文综合了现有的研究，并提出了新颖的实验设计，这些设计探讨了基于LLM的排名者和助手如何影响基于LLM的法官。我们提供了第一个经验证据表明，LLM法官对基于LLM的排名表现出很大的偏见。此外，我们观察到LLM法官辨别微妙的系统性能差异的能力的局限性。与以前的一些发现相反，我们的初步研究没有发现与AI生成的含量偏见的证据。这些结果突出了对LLM驱动的信息生态系统更全面的看法。为此，我们提供了初始指南和研究议程，以确保在IR评估中可靠地使用LLMS。]]></description>
      <guid>https://arxiv.org/abs/2503.19092</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RGL：一个以图形为中心的模块化框架，用于在图上有效检索的生成</title>
      <link>https://arxiv.org/abs/2503.19314</link>
      <description><![CDATA[ARXIV：2503.19314V1公告类型：新 
摘要：图形学习的最新进展为利用图形数据中固有的关系结构的创新检索生成（RAG）系统铺平了道路。但是，许多现有的方法都遭受了严格的，固定的设置和大量的工程开销，从而限制了它们的适应性和可扩展性。此外，RAG社区在很大程度上忽略了图数据库社区中有关大规模图上有趣的子结构的有效检索的数十年研究。在这项工作中，我们介绍了rag-on-graphs库（RGL），这是一个模块化框架，无缝地集成了完整的rag pipeline-from效率图索引和动态节点检索到子施加，标记化，标记和最终世代的统一系统。 RGL通过支持各种图形格式并集成了针对基本组件的优化实现来解决关键挑战，与常规方法相比，达到高达143倍的加速度。此外，它的灵活实用程序（例如动态节点过滤）可以快速提取相关子图，同时减少令牌消耗。我们的广泛评估表明，RGL不仅加速了原型制作过程，而且还可以增强基于图的抹布系统在一系列任务中的性能和适用性。]]></description>
      <guid>https://arxiv.org/abs/2503.19314</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强了布鲁姆在大语模型时代培养信息素养的教育分类法</title>
      <link>https://arxiv.org/abs/2503.19434</link>
      <description><![CDATA[ARXIV：2503.19434V1公告类型：新 
摘要：大型语言模型的出现（LLM）深刻地改变了信息检索和解决问题的范式，使学生能够更有效地访问信息获取以支持学习。但是，目前缺乏标准化的评估框架，可以有效地指导学习者利用LLM。本文提出了一个由LLM驱动的Bloom的教育分类法，旨在通过LLMS认识和评估学生的信息素养（IL），并正式和指导学生使用LLMS来解决复杂问题的基于基于LLM的活动。该框架描述了与使用LLM分为两个不同阶段所需的认知能力相对应的IL：探索与行动以及创造与元认知。它将这些进一步细分为七个阶段：感知，搜索，推理，互动，评估，组织和策展。通过案例演示，该分析证明了该框架的适用性和可行性，支持了其在具有不同知识水平不同的学生中培养IL的作用。该框架在分析LLM使用框架的分析中填补了现有的空白，并为指导学习者改善IL提供了理论支持。]]></description>
      <guid>https://arxiv.org/abs/2503.19434</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越相关性：基于自适应探索的个性化建议框架</title>
      <link>https://arxiv.org/abs/2503.19525</link>
      <description><![CDATA[ARXIV：2503.19525V1公告类型：新 
摘要：推荐系统必须平衡个性化，多样性和鲁棒性，以在动态内容环境中保持有效。本文介绍了一个基于自适应的，基于探索的推荐框架，该框架适应不断发展的用户偏好和内容分布，以促进多样性和新颖性而不会损害相关性。该系统使用句子转换器嵌入来表示项目，并通过具有自适应阈值的在线算法将其组织为语义相干群集。用户控制的探索机制通过选择性地从不足的群集中进行采样，从而增强了多样性。 Movielens数据集的实验表明，促进探索可以将列表的相似性从0.34降低到0.26，并将出乎意料提高到0.73，表现优于协作过滤和基于受欢迎的基线。与300个模拟用户的A/B测试揭示了交互历史和对多样性的偏好之间的牢固联系，其中72.7％的长期用户赞成探索性建议。计算分析证实，聚类和建议过程与集群数量线性扩展。这些结果表明，自适应探索可以有效地减轻过度特殊化，同时保持个性化和效率。]]></description>
      <guid>https://arxiv.org/abs/2503.19525</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成红外如何机械地检索文档</title>
      <link>https://arxiv.org/abs/2503.19715</link>
      <description><![CDATA[ARXIV：2503.19715V1公告类型：新 
摘要：生成信息检索（Genir）是一种新颖的范式，其中变压器编码器模型模型以端到端方式预测文档排名。这些基因模型由于其简单的检索结构而受到了极大的关注，同时保持了高检索效率。但是，与建立的检索架构（例如跨编码器或双构架）相反，它们的内部计算在很大程度上尚不清楚。因此，这项工作通过基于机械性解释性（例如修补和词汇投影）应用方法来研究基因模型的内部检索过程。通过用更少的文档训练的一个训练的基因编码器，我们证明了解码器是负责成功检索的主要组件。我们的修补实验表明，解码器中并非所有组件对于检索过程至关重要。更具体地说，我们发现通过解码器可以分为三个阶段：（i）启动阶段，该阶段为激活后续层的后续组件有助于重要信息； （ii）桥接阶段，其中交叉注意力主要是活跃的，可以将查询信息从编码器传递到解码器； （iii）相互作用阶段，其中主要是MLP活跃以预测文档标识符。我们的发现表明，查询和文档信息之间的相互作用仅在最后阶段发生。我们希望我们的结果可以促进对基因模型的更好理解，并促进未来的研究，以克服与这些模型相关的当前挑战。]]></description>
      <guid>https://arxiv.org/abs/2503.19715</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>天才：通用多模式搜索的生成框架</title>
      <link>https://arxiv.org/abs/2503.19868</link>
      <description><![CDATA[ARXIV：2503.19868V1公告类型：新 
摘要：生成检索是信息检索中的一种新兴方法，它基于查询生成目标数据的标识符（ID），为传统基于嵌入的检索方法提供了有效替代方案。但是，现有模型是特定于任务的，并且缺乏基于嵌入的性能检索。本文提出了Genius，这是一个普遍的生成检索框架，支持多种模式和领域的各种任务。 Genius以核心引入了模态 - 耦合的语义量化，将多模式数据转换为编码模态和语义的离散ID。此外，为了增强概括，我们提出了一个查询增强，该查询在查询及其目标之间插值，从而使天才适应各种查询形式。在M-Beir基准测试中，它通过明确的边缘超过了先前的生成方法。与基于嵌入的检索不同，天才始终保持跨数据库大小的高检索速度，并且在多个基准测试中具有竞争性能。随着额外的重新排行，天才通常会在保持效率的同时取得接近基于嵌入方法的结果。]]></description>
      <guid>https://arxiv.org/abs/2503.19868</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解和改善在LLM的迅速压缩中的信息保存</title>
      <link>https://arxiv.org/abs/2503.19114</link>
      <description><![CDATA[ARXIV：2503.19114V1公告类型：交叉 
摘要：大语言模型（LLMS）的最新进展使他们成功地应用了广泛的任务。但是，在信息密集型任务中，及时长度可以快速增长，从而增加计算要求，性能下降以及无关或冗余信息引起的偏见。最近，已经引入了各种及时的压缩技术，以优化减少输入长度和保持性能之间的权衡。我们提出了一个整体评估框架，可以深入分析及时压缩方法。除压缩比以外，我们专注于三个关键方面：（i）下游任务性能，（ii）在输入上下文中接地，以及（iii）信息保存。通过此框架，我们研究了最先进的软压缩方法，表明它们很难从原始提示中保留关键细节，从而将其绩效限制在复杂的任务上。我们证明，修改软提示方法以更好地控制压缩信息的粒度可以显着提高其有效性 - 在下游任务性能中，高达+23 \％，地接地中的+8 Bertscore点超过8倍，并且在压缩中保留了2.7倍的实体。]]></description>
      <guid>https://arxiv.org/abs/2503.19114</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>浏览丢失的未形成回忆：用于串提示搜索和推理的基准</title>
      <link>https://arxiv.org/abs/2503.19193</link>
      <description><![CDATA[ARXIV：2503.19193V1公告类型：交叉 
摘要：我们介绍了浏览丢失的未形成回忆，对通用AI助手的丁格语已知项目搜索和推理基准。 Blur介绍了一组573个现实世界验证的问题，这些问题需要在多模式和多语言输入以及熟练的工具使用中进行搜索和推理，以使其脱颖而出。人类很容易就这些问题（平均得分为98％），而表现最佳的系统得分约为56％。为了促进对通用AI助手的具有挑战性和理想的用例的进步，我们通过公共排行榜发布了350个问题，保留了其中250个问题，其余的作为私人测试集。]]></description>
      <guid>https://arxiv.org/abs/2503.19193</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>COMAC：多源辅助上下文的对话代理，具有稀疏和对称的潜在相互作用</title>
      <link>https://arxiv.org/abs/2503.19274</link>
      <description><![CDATA[ARXIV：2503.19274V1公告类型：交叉 
摘要：AI驱动的对话剂的最新进展具有AI应用的巨大潜力。有效的响应产生对于这些药物的成功至关重要。尽管广泛的研究重点是利用多个辅助数据源（例如，知识库和角色）来增强响应的产生，但现有的方法通常很难从这些来源中有效提取相关信息。将多功能对话能力与已知事实的遵守以及对用户偏好和信念系统的巨大差异相结合的能力仍然存在明显的限制，这将继续阻碍广泛采用对话AI工具。本文介绍了一种新颖的方法，即具有稀疏和对称潜在互动（COMAC）的多源辅助上下文的对话代理，用于对话，该语言采用了专门编码流和融合后接地网络的多个数据源，以确定对话的相关性格和知识信息。 COMAC还利用了一个新颖的文本相似性度量，该指标允许多个来源之间的双向信息共享，并着重于有意义的单词的选择性子集。我们的实验表明，在两种最新方法上，COMAC改善了相关的角色和知识预测精度和响应产生质量。]]></description>
      <guid>https://arxiv.org/abs/2503.19274</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过事实分解的上下文有效检索</title>
      <link>https://arxiv.org/abs/2503.19574</link>
      <description><![CDATA[ARXIV：2503.19574V1公告类型：交叉 
摘要：最近有很大的兴趣将信息检索纳入大语言模型（LLMS）。从动态扩展的文本外部语料库中检索允许模型合并时事件，可以看作是情节内存的一种形式。在这里，我们证明将外部语料库预处理成半结构的“原子事实”，从而使检索更有效。更具体地说，我们证明，当检索到的文本的数量有限时，我们特定的原子事实形式可以提高各种问答任务的绩效。限制检索量可降低上下文的大小并提高推理效率。]]></description>
      <guid>https://arxiv.org/abs/2503.19574</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果关系：将因果图整合到检索中</title>
      <link>https://arxiv.org/abs/2503.19878</link>
      <description><![CDATA[ARXIV：2503.19878V1公告类型：交叉 
摘要：大型语言模型（LLMS）彻底改变了自然语言处理（NLP），尤其是通过检索功能增强的一代（RAG），该生成（RAG）通过整合外部知识来增强LLM功能。但是，传统的抹布系统面临着关键的局限性，包括由于文本块而导致的上下文完整性中断，以及对检索的语义相似性的过度依赖。为了解决这些问题，我们提出了Causalrag，这是一个新颖的框架，将因果图纳入检索过程中。通过构建和追踪因果关系，Causalrag保留了上下文的连续性并提高了检索精度，从而导致更准确和可解释的反应。我们评估了针对常规抹布和基于图的抹布方法的因果关系，证明了它在几种指标上的优越性。我们的发现表明，因果推理中的基础检索为知识密集型任务提供了有希望的方法。]]></description>
      <guid>https://arxiv.org/abs/2503.19878</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Collm：一个大型语言模型，用于构成图像检索</title>
      <link>https://arxiv.org/abs/2503.19910</link>
      <description><![CDATA[ARXIV：2503.19910V1公告类型：交叉 
摘要：组成的图像检索（CIR）是一项复杂的任务，旨在根据多模式查询检索图像。典型的培训数据包括包含参考图像的三胞胎，所需修改的文本描述以及目标图像，这些图像昂贵且耗时。 CIR数据集的稀缺性已导致使用合成三胞胎或使用无处不在的Web爬行图像捕获对的视觉模型（VLMS）的零射击方法。但是，这些方法具有重大的局限性：合成三胞胎的规模有限，多样性缺乏和不自然的修改文本，而图像托管对由于缺乏三重态数据而阻碍了对多模式查询的学习。此外，现有的方法在需要复杂的融合以及对视觉和语言方式的理解的复杂和细微的修改文本中挣扎。我们提出Collm，这是一个有效解决这些局限性的一站式框架。我们的方法从图像捕获对生成三胞胎，从而无需手动注释就可以进行监督培训。我们利用大型语言模型（LLM）生成参考图像和修改文本的关节嵌入，从而促进了更深层的多模式融合。此外，我们引入了多文本CIR（MTCIR），该数据集包含3.40万个样本，并完善现有的CIR基准（CIRR和Fashion-IQ），以增强评估可靠性。实验结果表明，Collm在多个CIR基准和设置中实现了最先进的性能。 MTCIR产生竞争成果，最高可提高绩效。我们的精制基准为CIR模型提供了更可靠的评估指标，这有助于这一重要领域的发展。]]></description>
      <guid>https://arxiv.org/abs/2503.19910</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多范围文本分析在财务文件中追踪内容要求</title>
      <link>https://arxiv.org/abs/2110.14960</link>
      <description><![CDATA[Arxiv：2110.14960V2公告类型：替换 
摘要：财务文件的完整性（就内容而言）是投资基金的基本要求。为了确保完整性，财务监管机构必须花费大量时间根据相关内容要求仔细检查每个财务文件，这些内容规定了要包含在财务文件中的信息类型（例如，股票的发行条件和程序的描述）。但是，由于财务文件的复杂性，现有技术提供了有限的支持，可以自动确定与财务信息类型相关的文本块。在本文中，我们建议FITI通过多范围文本分析在财务文档中追踪内容要求。鉴于新的财务文件，Fiti首先选择一组候选句子以进行有效的信息类型标识。然后，为了对候选句子进行排名，Fiti通过利用信息检索（IR）和机器学习（ML）技术（ML）技术结合使用，以分析与信息类型相关的单词，句子和上下文。最后，一个基于启发式的选择器考虑了句子排名和特定于域的短语，它确定了与每种信息类型相对应的句子列表。我们通过评估其在追踪100个现实世界财务文件中的财务内容需求方面的有效性来评估Fiti。实验结果表明，FITI能够以平均精度，召回和F1得分值分别为0.824、0.646和0.716提供准确的识别。 FITI的总体准确性在F1得分方面显着优于最佳基线（基于变压器语言模型）。此外，FITI可以帮助监管机构检测财务文件中约80％的缺失信息类型]]></description>
      <guid>https://arxiv.org/abs/2110.14960</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识增强了AI助手申请中的多域建议</title>
      <link>https://arxiv.org/abs/2306.06302</link>
      <description><![CDATA[arxiv：2306.06302v2公告类型：替换 
摘要：这项工作探讨了通过多域推荐系统在对话式AI助手应用程序中使用多域推荐系统探索统一知识的建议。多域建议利用以前域中用户的交互来改善新建议的建议。知识图增强功能旨在使用外部知识图来改善单个领域内的建议。这两个研究线程都包含相关信息以改进推荐任务。我们建议统一这些方法：使用来自其他域中的交互的信息以及外部知识图，以在新域中进行预测，而这两个信息源将是不可能的。我们开发了一个新模型，并在一个来自现场虚拟助手应用程序中的三个域（视频，音乐和书籍）中对数百万用户对内容（视频，音乐和书籍）的内容的查询得出的数据集进行了这些方法的增效。我们证明了总体建议以及针对域的新用户的建议。]]></description>
      <guid>https://arxiv.org/abs/2306.06302</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DistDNA：在2小时内搜索有效的功能交互</title>
      <link>https://arxiv.org/abs/2311.00231</link>
      <description><![CDATA[ARXIV：2311.00231V2公告类型：替换 
摘要：搜索效率和服务效率是建立功能交互并加快推荐系统中模型开发过程的两个主要轴。在大规模的基准测试中，搜索最佳特征交互设计需要大量的成本，这是由于大量数据的顺序工作流程。此外，融合各种来源，订单和数学操作的相互作用还引入了潜在的冲突，并为推荐模型提供了额外的冗余，从而导致绩效和服务成本的次优折叠。在本文中，我们将DistDNA作为整洁的解决方案，以酿造快速有效的功能交互设计。 DistDNA提出了一个超级网，以将不同订单和类型的相互作用模块作为搜索空间。为了优化搜索效率，DistDNA分发搜索并汇总了不同数据日期上最佳交互模块的选择，从而达到了25倍的速度超过25倍，并将搜索成本从2天减少到2小时。为了优化服务效率，DistDNA引入了可区分的成本感知损失，以惩罚选择冗余交互模块的选择，从而提高了在服务中发现的特征相互作用的效率。我们广泛评估了DistDNA在1TB Criteo Terabyte数据集上制作的最佳模型。实验评估表明，比当前最新的CTR模型相比，0.001 AUC的改善和60％的插槽节省。]]></description>
      <guid>https://arxiv.org/abs/2311.00231</guid>
      <pubDate>Wed, 26 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>