<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 03 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>两阶段电子商务检索的分层多字段表示</title>
      <link>https://arxiv.org/abs/2501.18707</link>
      <description><![CDATA[arXiv:2501.18707v1 公告类型：新
摘要：密集检索方法通常针对以平面字符串表示的非结构化文本数据。但是，电子商务目录通常包含跨多个字段的结构化信息，例如品牌、标题和描述，这些信息对检索系统具有重要的信息潜力。我们提出了级联分层注意检索模型 (CHARM)，这是一种新颖的框架，旨在将结构化产品数据编码为具有逐步更精细细节的分层字段级表示。利用新颖的块三角注意机制，我们的方法可以捕获指定层次结构中产品字段之间的相互依赖关系，从而产生适合快速高效检索的字段级表示和聚合向量。结合这两种表示可以实现两阶段检索管道，其中聚合向量支持初始候选选择，而更具表现力的字段级表示有助于对下游排名进行精确微调。在公开的大型电子商务数据集上进行的实验表明，CHARM 的表现与最先进的基线相当甚至更好。我们的分析突出了该框架能够将不同的查询与适当的产品字段相匹配，从而提高检索准确性和可解释性。]]></description>
      <guid>https://arxiv.org/abs/2501.18707</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐模型中的表征解缠和可解释性是否相关？一项批判性评论和可重复性研究</title>
      <link>https://arxiv.org/abs/2501.18805</link>
      <description><![CDATA[arXiv:2501.18805v1 公告类型：新
摘要：无监督学习的解缠表示与增强推荐系统 (RS) 的表示可解释性密切相关。这是通过使各个特征的表示更加明显地分离来实现的，这样就更容易将特征的贡献归因于模型的预测。然而，这种可解释性和特征归因方面的优势主要是定性探索的。此外，解缠对模型推荐性能的影响在很大程度上被忽视了。在这项工作中，我们在四个 RS 数据集上重现了五个著名推荐模型的推荐性能、表示解缠和表示可解释性。我们量化了解缠，并研究了解缠与推荐有效性和表示可解释性之间的联系。虽然现有的一些 RS 研究已经提出了解缠表示作为提高有效性和可解释性的途径，但我们的研究结果表明，解缠不一定与有效性相关，而是与表示可解释性密切相关。我们的代码和结果可在 https://github.com/edervishaj/disentanglement-interpretability-recsys 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2501.18805</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的协同传播模型</title>
      <link>https://arxiv.org/abs/2501.18997</link>
      <description><![CDATA[arXiv:2501.18997v1 公告类型：新
摘要：基于扩散的推荐系统 (DR) 因其先进的生成和去噪能力而受到越来越多的关注。然而，现有的 DR 面临两个主要限制：(i) 在通过噪声注入增强生成能力和保留个性化信息损失之间进行权衡。(ii) 丰富的项目侧信息利用不足。为了应对这些挑战，我们提出了一种用于推荐系统的协作扩散模型 (CDiff4Rec)。具体来说，CDiff4Rec 从项目特征生成伪用户，并利用通过行为相似性识别的真实和伪个性化邻居的协作信号，从而有效地重建细微的用户偏好。在三个公共数据集上的实验结果表明，CDiff4Rec 通过整合项目内容和协作信号有效地减轻个性化信息的丢失，从而优于竞争对手。]]></description>
      <guid>https://arxiv.org/abs/2501.18997</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 驱动的跨领域序列推荐的零样本泛化框架</title>
      <link>https://arxiv.org/abs/2501.19232</link>
      <description><![CDATA[arXiv:2501.19232v1 公告类型：新
摘要：零样本跨域顺序推荐 (ZCDSR) 无需额外训练或微调即可在看不见的域中进行预测，这使其在传统模型难以应对的数据稀疏环境中特别有价值。大型语言模型 (LLM) 的最新进展通过利用丰富的预训练表示来促进跨域知识转移，极大地改进了 ZCDSR。然而，一个关键的挑战仍然存在：领域语义偏差，它源于不同领域的词汇和内容焦点的变化。这种错位导致项目嵌入不一致并阻碍泛化。
为了解决这个问题，我们提出了一个新颖的框架，旨在通过改进项目和顺序级别的跨域对齐来增强基于 LLM 的 ZCDSR。在项目级别，我们引入了一种泛化损失，通过跨域对齐类似项目的嵌入来促进域间紧凑性，同时保持域内多样性以保留独特的项目特征。这可以防止嵌入变得过于通用，同时确保有效的可转移性。在序列级别，我们开发了一种通过在源域中聚类用户序列并应用基于注意的聚合进行目标域推理来传输用户行为模式的方法。这种用户嵌入的动态调整允许有效的零样本推荐，而无需目标域交互。
跨多个数据集和域的综合实验表明，我们的框架显着提高了 ZCDSR 设置中的序列推荐性能。通过减轻领域偏见并增强序列模式的可转移性，我们的方法提供了一种可扩展且强大的方法，可在各个域中实现更有效的零样本推荐。]]></description>
      <guid>https://arxiv.org/abs/2501.19232</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解放信息检索</title>
      <link>https://arxiv.org/abs/2501.19241</link>
      <description><![CDATA[arXiv:2501.19241v1 公告类型：新
摘要：当今世界正面临着几场相互强化的危机，每一场危机都与社会正义和解放问题相交叉。本文旨在激发计算机中介信息访问在我们的解放斗争中的作用。我们将解放信息检索定义为研究和开发挑战各种形式的人类压迫的信息访问方法，并将其活动置于更广泛的集体解放实践中。这里的“解放”一词表示对所有民族的普遍人性化和消除压迫的道德关注，以创造我们能够共同繁荣的条件。为了为 IR 制定解放研究议程，我们在本文中推测了社区可以采用的实践，列举了该领域应该开展的一些项目，并讨论了激发新思想和研究方向的激发因素。我们挑战信息检索 (IR) 研究领域，使其拥抱人文价值观，并致力于将普遍解放和社会正义作为我们研究的一部分。]]></description>
      <guid>https://arxiv.org/abs/2501.19241</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>mFollowIR：检索中指令跟随的多语言基准</title>
      <link>https://arxiv.org/abs/2501.19264</link>
      <description><![CDATA[arXiv:2501.19264v1 公告类型：新
摘要：检索系统通常侧重于简短且未明确说明的网络式查询。然而，语言模型的进步促进了能够理解具有不同意图的更复杂查询的检索模型的兴起。然而，这些努力只集中在英语上；因此，我们还不了解它们如何跨语言工作。我们引入了 mFollowIR，这是一个用于测量检索模型中指令遵循能力的多语言基准。mFollowIR 以 TREC NeuCLIR 叙述（或指令）为基础，涵盖三种不同的语言（俄语、中文、波斯语），为检索模型提供查询和指令。我们对叙述做了一些小的改动，并分离出检索模型对这些细微变化的遵循程度。我们展示了多语言（XX-XX）和跨语言（En-XX）性能的结果。我们发现，使用指令进行训练的英语检索器具有很强的跨语言表现，但在多语言环境中发现表现明显下降，这表明需要在开发基于指令的多语言检索器的数据方面开展更多的工作。]]></description>
      <guid>https://arxiv.org/abs/2501.19264</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新审视基于投影的数据传输，以实现低资源语言中的跨语言命名实体识别</title>
      <link>https://arxiv.org/abs/2501.18750</link>
      <description><![CDATA[arXiv:2501.18750v1 公告类型：交叉 
摘要：跨语言命名实体识别 (NER) 利用语言之间的知识转移来识别和分类命名实体，这使其对资源匮乏的语言特别有用。我们表明，基于数据的跨语言传输方法是跨语言 NER 的有效技术，并且可以胜过资源匮乏语言的多语言语言模型。本文介绍了针对资源匮乏语言的跨语言 NER 中注释投影步骤的两个关键增强功能。首先，我们探索使用反向翻译来细化单词对齐以提高准确性。其次，我们提出了一种新颖的形式化投影方法，将源实体与提取的目标候选者进行匹配。通过对两个涵盖 57 种语言的数据集进行大量实验，我们证明了我们的方法在资源匮乏的环境中超越了现有的基于投影的方法。这些发现强调了基于投影的数据传输作为基于模型的低资源语言跨语言命名实体识别方法的替代方案的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2501.18750</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>描述用户行为：移动模式与移动流量之间的相互作用</title>
      <link>https://arxiv.org/abs/2501.19348</link>
      <description><![CDATA[arXiv:2501.19348v1 公告类型：交叉 
摘要：移动设备已成为捕捉人类活动的关键，而扩展数据记录 (XDR) 为详细的用户行为建模提供了丰富的机会，这对于设计个性化的数字服务非常有用。以前的研究主要集中在聚合的移动流量和移动性分析上，往往忽略了个人层面的洞察。本文介绍了一种新方法，探索用户层面的流量和移动行为之间的依赖关系。通过分析涵盖流量模式和各种移动方面的 13 个单独特征，我们增强了对这些行为如何相互作用的理解。我们先进的用户建模框架集成了随时间变化的流量和移动行为，允许细粒度的依赖关系，同时通过用户特定的签名保持人口异质性。此外，我们开发了一个马尔可夫模型，可以从移动性推断流量行为，反之亦然，优先考虑重要的依赖关系，同时解决隐私问题。使用来自智利多个省份的 1,337,719 名用户的为期一周的 XDR 数据集，我们验证了我们的方法，证明了其在准确推断用户行为和匹配不同城市环境中的移动性和交通状况方面的稳健性和适用性。]]></description>
      <guid>https://arxiv.org/abs/2501.19348</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM4Rerank：基于 LLM 的推荐自动重新排序框架</title>
      <link>https://arxiv.org/abs/2406.12433</link>
      <description><![CDATA[arXiv:2406.12433v3 公告类型：替换 
摘要：重新排名是推荐系统中的一个关键组件，在改进推荐算法的输出方面起着至关重要的作用。传统的重新排名模型主要关注准确性，但现代应用需要考虑多样性和公平性等其他标准。现有的重新排名方法通常无法在模型级别有​​效地协调这些不同的标准。此外，由于这些模型的复杂性以及不同重新排名标准在不同场景中的重要性不同，这些模型经常在可扩展性和个性化方面遇到挑战。为此，我们引入了一个由 LLM 增强的综合重新排名框架，旨在无缝集成各种重新排名标准，同时保持可扩展性并促进个性化推荐。该框架采用全连通图结构，允许 LLM 通过连贯的思路链 (CoT) 过程同时考虑准确性、多样性和公平性等多个方面。还集成了可自定义的输入机制，可以调整语言模型的重点以满足特定的重新排序需求。我们使用三个流行的公共数据集验证了我们的方法，我们的框架在平衡多个标准方面表现出优于现有最先进的重新排序模型的性能。此实现的代码是公开的。]]></description>
      <guid>https://arxiv.org/abs/2406.12433</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 辅助相关性评估：我们何时应该向 LLM 寻求帮助？</title>
      <link>https://arxiv.org/abs/2411.06877</link>
      <description><![CDATA[arXiv:2411.06877v2 公告类型：替换 
摘要：测试集是信息检索工具，可让研究人员快速轻松地评估排名算法。虽然测试集已成为 IR 研究不可或缺的一部分，但数据创建过程需要大量手动注释工作，这通常会使其非常昂贵且耗时。因此，当预算有限时，测试集可能会变得太小，这可能会导致不稳定的评估。作为一种更便宜的替代方案，最近的研究提出了使用大型语言模型 (LLM) 完全取代人类评估员。然而，虽然 LLM 似乎与人类判断有某种相关性，但它们的预测并不完美，而且经常表现出偏见。因此，完全用 LLM 替代被认为风险太大，也不完全可靠。
因此，在本文中，我们提出了 LLM 辅助相关性评估 (LARA)，这是一种平衡手动注释和 LLM 注释的有效方法，即使在低预算下也有助于构建丰富可靠的测试集。我们使用 LLM 预测的相关性概率在预算约束下选择最有利可图的文档进行手动注释。通过理论推理，LARA 通过主动学习校准 LLM 预测的相关性概率有效地指导人工注释过程。然后，LARA 使用从有限的手动注释中学习到的校准模型消除 LLM 预测的偏差以注释剩余的未评估数据。对 TREC-7 Ad Hoc、TREC-8 Ad Hoc、TREC Robust 2004 和 TREC-COVID 数据集的实证评估表明，LARA 在几乎任何预算约束下都优于替代解决方案。]]></description>
      <guid>https://arxiv.org/abs/2411.06877</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>监督学习增强型多组演员评论家用于动态消息中的直播流分配</title>
      <link>https://arxiv.org/abs/2412.10381</link>
      <description><![CDATA[arXiv:2412.10381v4 公告类型：替换 
摘要：在短视频和直播混合推荐场景中，直播推荐系统 (RS) 决定是否为每个用户请求分配最多一个直播到视频源中。为了最大限度地提高长期用户参与度，确定最佳直播策略以准确分配直播流至关重要。不适当的直播分配策略会显著影响应用程序的使用时长和用户留存，从而忽略了直播分配的长期负面影响。最近，强化学习 (RL) 已广泛应用于推荐系统以捕捉长期用户参与度。然而，传统的 RL 算法经常面临发散和不稳定问题，这限制了它在大规模工业推荐系统中的应用和部署，尤其是在上述具有挑战性的场景中。为了应对这些挑战，我们提出了一种新的监督学习增强多组演员评论家算法 (SL-MGAC)。具体来说，我们引入了一种监督学习增强的演员-评论家框架，该框架结合了方差减少技术，其中多任务奖励学习有助于限制评论家学习期间的引导误差累积。此外，我们为演员和评论家网络设计了一个多组状态分解模块，以减少预测方差并提高模型稳定性。我们还提出了一种新颖的奖励函数来防止过于贪婪的直播流分配。从经验上讲，我们使用离线策略评估 (OPE) 和在线 A/B 测试来评估 SL-MGAC 算法。实验结果表明，所提出的方法不仅在平台级约束下优于基线方法，而且在在线推荐场景中表现出增强的稳定性。]]></description>
      <guid>https://arxiv.org/abs/2412.10381</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>公平生成：针对不完整多模态推荐的模态扩散反事实框架</title>
      <link>https://arxiv.org/abs/2501.11916</link>
      <description><![CDATA[arXiv:2501.11916v2 公告类型：替换 
摘要：不完整场景是多模态推荐 (MMRec) 中普遍存在、实用但又具有挑战性的场景，由于各种因素，某些项目模态缺失。最近，一些努力试图通过探索不完整数据的通用结构来提高推荐准确性。然而，仍然存在两个重大差距：1) 由于捕获模态分布的能力有限，难以准确生成缺失数据；2) 关键但被忽视的可见性偏差，由于项目的多模态数据优先于用户偏好对齐，缺少模态的项目更容易被忽视。这种偏见引起了人们对项目公平对待的严重担忧。为了弥合这两个差距，我们提出了一种用于不完整多模态推荐的新型模态扩散反事实 (MoDiCF) 框架。MoDiCF 具有两个关键模块：一个新颖的模态扩散数据完成模块和一个新的反事实多模态推荐模块。前者配备了专门设计的多模态生成框架，可以从学习到的特定模态分布空间中准确生成缺失数据并迭代细化。后者基于因果视角，有效地减轻了可见性偏差的负面因果影响，从而确保了推荐的公平性。这两个模块协同工作，以解决上述两个重大差距，从而产生更准确、更公平的结果。在三个真实数据集上进行的大量实验证明了 MoDiCF 在推荐准确性和公平性方面的卓越性能。代码和处理后的数据集发布在 https://github.com/JinLi-i/MoDiCF。]]></description>
      <guid>https://arxiv.org/abs/2501.11916</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SampleLLM：优化建议中的表格数据合成</title>
      <link>https://arxiv.org/abs/2501.16125</link>
      <description><![CDATA[arXiv:2501.16125v2 公告类型：更新 
摘要：表格数据合成在机器学习中至关重要，但现有的一般方法（主要基于统计或深度学习模型）高度依赖数据，在推荐系统中往往达不到要求。这种限制源于它们难以从稀疏和有限的数据中捕获复杂分布和理解特征关系，以及无法掌握语义特征关系。最近，大型语言模型 (LLM) 已显示出通过少量学习和语义理解生成合成数据样本的潜力。然而，由于它们与目标数据集固有的分布差异，它们经常遭受分布不一致和缺乏多样性的困扰。为了应对这些挑战并增强推荐任务的表格数据合成，我们提出了一个名为 SampleLLM 的新型两阶段框架，通过确保更好的分布对齐来提高基于 LLM 的推荐表格数据合成的质量。在第一阶段，SampleLLM 使用具有 Chain-of-Thought 提示和多样化样本的 LLM 来生成与目标数据集分布紧密一致的数据，即使输入样本有限。第二阶段使用基于特征归因的高级重要性抽样方法来细化合成数据中的特征关系，从而减少 LLM 引入的任何分布偏差。在三个推荐数据集、两个一般数据集和在线部署上的实验结果表明，SampleLLM 显著超越了现有的推荐任务方法，并有望应用于更广泛的表格数据场景。]]></description>
      <guid>https://arxiv.org/abs/2501.16125</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉语言模型验证新闻中的跨模态实体一致性</title>
      <link>https://arxiv.org/abs/2501.11403</link>
      <description><![CDATA[arXiv:2501.11403v2 公告类型：replace-cross 
摘要：网络已成为重要的信息来源，但它也被用来传播虚假信息，通常通过图像和文本等多种模式传达。识别不一致的跨模态信息，特别是人物、地点和事件等实体，对于检测虚假信息至关重要。以前的研究要么通过评估图像与整个文档的一致性来识别脱离上下文的虚假信息，忽略单个实体的关系，要么关注与新闻无关的通用实体。到目前为止，只有少数方法解决了验证新闻中图像和文本之间实体一致性的任务。然而，大型视觉语言模型 (LVLM) 的潜力尚未得到探索。在本文中，我们提出了一个基于 LVLM 的框架来验证跨模态实体一致性~(LVLM4CEC)，以评估新闻文章中的人物、地点和事件在两种模态中是否一致。我们建议使用有效的提示策略来提示 LVLM 进行实体验证，这些策略利用从网络爬取的参考图像。此外，我们扩展了三个现有数据集，用于新闻中的实体验证任务，提供手动地面实况数据。我们的结果显示了 LVLM 在自动化跨模态实体验证方面的潜力，在使用证据图像时，识别人物和事件的准确性有所提高。此外，我们的方法在文档中的位置和事件验证方面优于基线。数据集和源代码可在 GitHub 上找到，网址为 https://github.com/TIBHannover/LVLM4CEC。]]></description>
      <guid>https://arxiv.org/abs/2501.11403</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>