<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 25 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>科学文献中模型恢复的变量提取</title>
      <link>https://arxiv.org/abs/2411.14569</link>
      <description><![CDATA[arXiv:2411.14569v1 公告类型：新
摘要：全球每年的学术出版物超过 500 万篇文章，这使得人类很难跟上哪怕是一小部分的科学产出。我们需要方法来浏览和解释构成文献的文本、图形、图表、代码、模型和数据集。本文评估了从流行病学研究中提取数学模型变量的各种方法，例如“感染率（$\alpha$）、“恢复率（$\gamma$）”和“死亡率（$\mu$）”。变量提取似乎是一项基本任务，但在从科学文献中恢复模型方面起着关键作用。一旦提取，我们就可以使用这些变量进行自动数学建模、模拟和复制已发布的结果。
我们引入了一个基准数据集，该数据集包含从科学论文中提取的手动注释变量描述和变量值。基于此数据集，我们提出了几种基于大型语言模型 (LLM) 和基于规则的信息提取系统的变量提取基准方法。我们的分析表明，基于 LLM 的解决方案表现最佳。尽管将基于规则的提取输出与 LLM 相结合会带来增量收益，但归因于 LLM 本身的迁移学习和指令调整功能的性能飞跃更为显著。这项调查展示了 LLM 在增强对科学文物的自动理解以及自动模型恢复和模拟方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.14569</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>G-RAG：材料科学知识扩展</title>
      <link>https://arxiv.org/abs/2411.14592</link>
      <description><![CDATA[arXiv:2411.14592v1 公告类型：新
摘要：在材料科学领域，有效的信息检索系统对于促进研究至关重要。大型语言模型 (LLM) 中的传统检索增强生成 (RAG) 方法经常遇到诸如信息过时、幻觉、由于上下文限制而导致的可解释性有限以及检索不准确等挑战。为了解决这些问题，Graph RAG 集成了图形数据库以增强检索过程。我们提出的方法通过从句子中提取关键实体（称为 MatID）来处理材料科学文档，然后利用这些实体查询外部维基百科知识库 (KB) 以获取更多相关信息。我们实施了一种基于代理的解析技术，以实现对文档的更详细表示。我们改进的 Graph RAG 版本称为 G-RAG，它进一步利用图形数据库来捕获这些实体之间的关系，从而提高检索准确性和上下文理解。这种增强的方法对于需要精确信息检索的领域（例如材料科学）表现出显著的性能提升。]]></description>
      <guid>https://arxiv.org/abs/2411.14592</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LIBER：基于大型语言模型的终身用户行为建模</title>
      <link>https://arxiv.org/abs/2411.14713</link>
      <description><![CDATA[arXiv:2411.14713v1 公告类型：新
摘要：CTR 预测在推荐系统中起着至关重要的作用。最近，大型语言模型 (LLM) 因其涌现能力而被应用于推荐系统。虽然利用 LLM 中的语义信息已经显示出推荐系统性能的一些改进，但这些研究仍然存在两个显着的局限性。首先，LLM 增强的推荐系统在从文本上下文中的终身用户行为序列中提取有价值的信息以用于推荐任务时遇到挑战。其次，人类行为固有的多变性导致新行为不断涌现，用户兴趣不规则波动。这一特点对现有模型提出了两个重大挑战。一方面，它使 LLM 难以有效捕捉这些序列中用户兴趣的动态变化，另一方面，如果 LLM 需要在每次更新用户序列时进行重复调用，则存在大量计算开销的问题。在本文中，我们提出了基于大型语言模型的终身用户行为建模 (LIBER)，它包括三个模块：（1）用户行为流式分区 (UBSP)、（2）用户兴趣学习 (UIL) 和（3）用户兴趣融合 (UIF)。首先，UBSP 用于以增量范式将较长的用户行为序列压缩为较短的分区，从而实现更高效的处理。随后，UIL 以级联方式利用 LLM 从这些分区中推断出见解。最后，UIF 集成上述过程生成的文本输出以构建一个全面的表示，任何推荐模型都可以将其合并以提高性能。LIBER 已部署在华为的音乐推荐服务中，用户播放次数和播放时间分别提升了 3.01% 和 7.69%。]]></description>
      <guid>https://arxiv.org/abs/2411.14713</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IRLab@iKAT24：学习稀疏检索并使用多方面 LLM 查询生成进行对话搜索</title>
      <link>https://arxiv.org/abs/2411.14739</link>
      <description><![CDATA[arXiv:2411.14739v1 公告类型：新
摘要：交互式知识助理轨道 (iKAT) 2024 专注于推进对话助理，能够根据个性化的用户知识调整其交互和响应。该轨道结合了个人文本知识库 (PTKB) 以及对话式 AI 任务，例如段落排名和响应生成。查询重写是解决对话上下文的有效方法，我们探索大型语言模型 (LLM) 作为查询重写器。具体来说，我们提交的运行探索使用 MQ4CS 框架的多方面查询生成，我们通过 SPLADE 架构使用学习稀疏检索进一步增强了该框架，并结合了强大的跨编码器模型。我们还提出了一种替代先前交错策略的方法，即在重新排名阶段聚合多个方面。我们的研究结果表明，当与高级检索和重新排名模型相结合时，多方面查询生成可以有效提高性能。我们的结果也为对话式搜索的更好个性化开辟了道路，依靠 LLM 将个性化集成到查询重写中，并超越人工重写性能。]]></description>
      <guid>https://arxiv.org/abs/2411.14739</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>第一届以人为本的推荐系统研讨会</title>
      <link>https://arxiv.org/abs/2411.14760</link>
      <description><![CDATA[arXiv:2411.14760v1 公告类型：新
摘要：推荐系统是人机交互的典型应用。它们广泛应用于日常生活中，提供了极大的便利，但也带来了许多挑战，例如信息茧房效应、隐私问题、公平性问题等。因此，本次研讨会旨在为研究人员提供一个平台，探索以人为本的推荐系统（HCRS）的发展。HCRS 是指创建以人类需求、价值观和能力为设计和操作核心的推荐系统。在本次研讨会上，主题将包括但不限于稳健性、隐私、透明度、公平性、多样性、问责制、道德考虑和用户友好型设计。我们希望就如何在推荐系统中实现和增强这些属性进行讨论。此外，参与者将探索各种评估方法，包括捕捉用户满意度和信任度的创新指标。该研讨会旨在为研究人员营造一个协作环境，以分享见解并推动该领域向更具道德、以用户为中心和对社会负责的推荐系统迈进。]]></description>
      <guid>https://arxiv.org/abs/2411.14760</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于查询生成的大型语言模型的可重复性和可推广性研究</title>
      <link>https://arxiv.org/abs/2411.14914</link>
      <description><![CDATA[arXiv:2411.14914v1 公告类型：新
摘要：系统文献综述 (SLR) 是学术研究的基石，但由于详细的文献整理过程，它们往往是劳动密集型和耗时的。生成式人工智能和大型语言模型 (LLM) 的出现有望彻底改变这一过程，帮助研究人员完成几项繁琐的任务，其中之一就是生成有效的布尔查询，以选择考虑纳入评论的出版物。本文对使用 LLM 进行系统评价的布尔查询生成进行了广泛的研究，复制并扩展了 Wang 等人和 Alaniz 等人的工作。我们的研究调查了使用 ChatGPT 获得的结果的可复制性和可靠性，并将其性能与 Mistral 和 Zephyr 等开源替代方案进行了比较，以提供对查询生成 LLM 的更全面分析。
因此，我们实现了一个管道，该管道使用先前定义的 LLM 自动为给定的评论主题创建布尔查询，从 PubMed 数据库中检索此查询的所有文档，然后评估结果。通过这个管道，我们首先评估使用 ChatGPT 进行查询生成所获得的结果是否可重复且一致。然后，我们通过分析和评估开源模型并评估它们在生成布尔查询方面的有效性来概括我们的结果。
最后，我们进行失败分析，以确定和讨论使用 LLM 进行布尔查询生成的局限性和缺点。这项检查有助于了解 LLM 在信息检索任务中的应用方面的差距和潜在的改进领域。我们的研究结果突出了 LLM 在信息检索和文献综述自动化领域的优势、局限性和潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.14914</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GOT4Rec：顺序推荐的思维图</title>
      <link>https://arxiv.org/abs/2411.14922</link>
      <description><![CDATA[arXiv:2411.14922v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的进步，研究人员已经探索了各种方法，以在顺序推荐场景中最佳地利用它们的理解和生成能力。然而，这一努力仍然存在一些挑战。首先，大多数现有方法依赖于输入输出提示范式，这可能导致不相关或不准确的响应。其次，虽然有人尝试使用思路链 (CoT) 等提示策略来增强 LLM，但这些努力并未充分利用 LLM 的推理能力或有效捕获用户序列中包含的多方面信息。为了解决这些限制，我们提出了 GOT4Rec，这是一种利用思维图 (GoT) 提示策略的顺序推荐方法。具体来说，我们识别并利用用户历史序列中的三种主要信息类型：短期兴趣、长期兴趣和来自其他用户的协作信息。我们的方法使 LLM 能够根据这些不同类型的信息独立推理并生成建议，然后在 GoT 框架内汇总结果以得出最终的推荐项目。这种方法使具有增强推理能力的 LLM 能够更有效地考虑用户序列中的各种信息，从而产生更准确的建议和更全面的解释。对真实世界数据集的大量实验证明了 GOT4Rec 的有效性，表明它优于现有的最先进基线。我们的代码可在 https://anonymous.4open.science/r/GOT4Rec-ED99 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.14922</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 CTR 预测中的长期用户行为建模的多粒度兴趣检索和细化网络</title>
      <link>https://arxiv.org/abs/2411.15005</link>
      <description><![CDATA[arXiv:2411.15005v1 公告类型：新
摘要：点击率 (CTR) 预测对于在线个性化平台至关重要。最近的进展表明，对丰富的用户行为进行建模可以显著提高 CTR 预测的性能。当前的长期用户行为建模算法主要遵循两个级联阶段。第一阶段从长期行为序列中检索与目标项目相关的子序列，而第二阶段建模子序列与目标项目之间的关系。尽管取得了重大进展，但这些方法存在两个关键缺陷。首先，检索查询通常仅包含目标项目信息，限制了捕捉用户多样化兴趣的能力。其次，关系信息，例如子序列内的顺序和交互信息，经常被忽视。因此，需要进一步挖掘它以更准确地模拟用户兴趣。
为此，我们提出了多粒度兴趣检索和细化网络 (MIRRN)。具体来说，我们首先根据在不同时间尺度上观察到的行为构建查询以获得子序列，每个子序列以不同的粒度捕获用户的兴趣。然后，我们引入一种新颖的多头傅里叶变换器来有效地学习子序列中的顺序和交互信息，从而更准确地建模用户兴趣。最后，我们采用多头目标注意力来自适应地评估这些多粒度兴趣对目标项目的影响。大量实验表明，MIRRN 的表现明显优于最先进的基线。此外，A/B 测试表明，MIRRN 在流行的音乐流媒体应用上将平均听歌次数增加了 1.32%，平均听歌时间增加了 0.55%。实现代码可在 https://github.com/psycho-demon/MIRRN 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.15005</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能能否生成反映患者关心的优质研究课题？</title>
      <link>https://arxiv.org/abs/2411.14456</link>
      <description><![CDATA[arXiv:2411.14456v1 公告类型：交叉 
摘要：以患者为中心的研究在缩小研究与患者护理之间的差距方面越来越重要，但将患者观点纳入健康研究一直不一致。我们提出了一个自动化框架，利用创新的自然语言处理 (NLP) 和人工智能 (AI) 与患者门户消息来生成优先考虑重要患者问题的研究想法。我们进一步量化了人工智能生成的研究主题的质量。为了确定患者的临床问题，我们分析了来自一家大型学术医院 (2013 年至 2024 年) 的 25,549 名乳腺癌或皮肤癌患者的 614,464 条患者信息，构建了一个 2 阶段无监督 NLP 主题模型。然后，我们使用广泛使用的人工智能 (ChatGPT-4o，OpenAI Inc，2024 年 4 月版本) 和提示工程策略生成研究主题来解决定义的问题。我们指导 AI 执行多层次任务：1）知识解释和总结（例如，解释和总结 NLP 定义的主题），2）知识生成（例如，生成与患者问题相对应的研究想法），3）自我反思和纠正（例如，在搜索科学文章后确保和修改研究想法），以及 4）自我保证（例如，确认和最终确定研究想法）。六位经验丰富的乳腺肿瘤学家和皮肤科医生使用 5 点李克特量表（1-优秀，5-差）评估了 AI 生成的研究主题的重要性和新颖性。当两个分数都低于平均值时，三分之一的 AI 建议的研究主题非常重要且新颖。三分之二的 AI 建议主题在两种癌症中都是新颖的。我们的研究结果表明，通过大量患者信息反映患者观点的 AI 生成的研究主题可以有意义地指导以患者为中心的健康研究的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2411.14456</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示用户偏好：基于知识图谱和 LLM 驱动的对话式推荐方法</title>
      <link>https://arxiv.org/abs/2411.14459</link>
      <description><![CDATA[arXiv:2411.14459v1 公告类型：交叉 
摘要：对话推荐系统 (CRS) 旨在通过在交互式对话中动态捕获用户偏好来提供个性化推荐。传统的 CRS 通常将用户偏好提取为隐藏表示，这些表示因缺乏可解释性而受到批评。这降低了推荐过程的透明度和可信度。最近的研究探索了将大型语言模型 (LLM) 的强大功能与知识图谱 (KG) 的领域特定知识相结合，以生成人类可理解的推荐解释。尽管做出了这些努力，但由于非结构化对话和结构化 KG 之间的模态差距，将 LLM 和 KG 集成到 CRS 中仍然具有挑战性。此外，在大型语料库上预先训练的 LLM 可能不太适合分析需要领域特定知识的用户偏好。在本文中，我们提出了 COMPASS，这是一个即插即用的框架，它协同 LLM 和 KG 来揭示用户偏好，从而增强现有 CRS 的性能和可解释性。为了应对集成挑战，COMPASS 采用了两阶段训练方法：首先，它通过创新的图形实体字幕预训练机制弥合了结构化 KG 和自然语言之间的差距。这使 LLM 能够将 KG 实体转换为简洁的自然语言描述，从而使它们能够理解特定领域的知识。接下来，COMPASS 通过知识感知指令微调优化用户偏好建模，其中 LLM 学习从对话历史和 KG 增强上下文中推理和总结用户偏好。这使 COMPASS 能够执行知识感知推理并生成全面且可解释的用户偏好，这些偏好可以与现有的 CRS 模型无缝集成，以提高推荐性能和可解释性。]]></description>
      <guid>https://arxiv.org/abs/2411.14459</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习提问：通过表征学习进行对话式产品搜索</title>
      <link>https://arxiv.org/abs/2411.14466</link>
      <description><![CDATA[arXiv:2411.14466v1 公告类型：交叉 
摘要：在线购物平台，如亚马逊和速卖通，在社会上越来越普遍，帮助客户方便地购买产品。随着自然语言处理的最新进展，研究人员和从业人员将重点从传统的产品搜索转移到对话式产品搜索。对话式产品搜索支持用户与机器的对话，并通过对话收集明确的用户反馈，从而主动澄清用户的产品偏好。因此，对通过对话实现的智能购物助手的前瞻性研究是必不可少的。现有的关于对话式产品搜索的出版物要么独立于用户、查询和产品对对话进行建模，要么导致词汇不匹配。在这项工作中，我们提出了一种新的对话式产品搜索模型 ConvPS，以帮助用户找到想要的商品。该模型首先通过统一的生成框架进行训练，以共同学习用户、查询、项目和对话的语义表示。在学习这些表示之后，将它们集成以在潜在语义空间中检索目标项目。同时，我们提出了一套贪婪和探索利用策略来学习向用户提出一系列高性能对话问题。我们提出的 ConvPS 模型可以自然地将用户、查询、项目和对话的表示学习集成到一个统一的生成框架中，这为构建灵活、自适应的准确、强大的对话产品搜索系统提供了一条有希望的途径。实验结果表明，我们的 ConvPS 模型明显优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2411.14466</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源领域命名实体识别数据增强技术的实验研究</title>
      <link>https://arxiv.org/abs/2411.14551</link>
      <description><![CDATA[arXiv:2411.14551v1 公告类型：交叉 
摘要：命名实体识别 (NER) 是一种机器学习任务，传统上依赖于监督学习和注释数据。获取此类数据通常是一项挑战，尤其是在医疗、法律和金融等专业领域。由于可用数据稀缺，这些通常被称为低资源域，其中包含长尾实体。为了解决这个问题，数据增强技术越来越多地被用于从原始数据集生成额外的训练实例。在本研究中，我们评估了两种著名的文本增强技术——提及替换和上下文词替换——对两种广泛使用的 NER 模型 Bi-LSTM+CRF 和 BERT 的有效性。我们对来自低资源域的四个数据集进行了实验，并探讨了训练子集大小和增强示例数量的各种组合的影响。我们不仅证实数据增强对于较小的数据集特别有益，而且还证明没有普遍最佳的增强示例数量，即 NER 从业者必须尝试不同的数量才能对他们的项目进行微调。]]></description>
      <guid>https://arxiv.org/abs/2411.14551</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于遥感图像和文本检索的跨模态预对齐方法</title>
      <link>https://arxiv.org/abs/2411.14704</link>
      <description><![CDATA[arXiv:2411.14704v1 公告类型：交叉 
摘要：遥感跨模态文本图像检索 (RSCTIR) 因其在信息挖掘中的实用性而备受关注。然而，由于遥感图像的变化，在有效整合全局和局部信息以及在模态融合之前确保适当的特征预对齐方面仍然存在挑战，这会影响检索准确性和效率。为了解决这些问题，我们提出了 CMPAGL，一种利用全局和局部信息的跨模态预对齐方法。我们的 Gswin Transformer 块结合了局部窗口自注意力和全局-局部窗口交叉注意力来捕获多尺度特征。预对齐机制简化了模态融合训练，提高了检索性能。此外，我们引入了一种相似矩阵重加权 (SMR) 算法进行重新排序，并使用类内距离项增强了三重态损失函数以优化特征学习。在 RSICD 和 RSITMD 等四个数据集上的实验验证了 CMPAGL 的有效性，与最先进的方法相比，R@1 提高了 4.65%，平均召回率 (mR) 提高了 2.28%。]]></description>
      <guid>https://arxiv.org/abs/2411.14704</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型集成实现高性能自动摘要筛选</title>
      <link>https://arxiv.org/abs/2411.02451</link>
      <description><![CDATA[arXiv:2411.02451v2 公告类型：replace-cross 
摘要：大型语言模型 (LLM) 在需要处理和解释输入文本的任务中表现出色。摘要筛选是系统评价中一项劳动密集型的工作，涉及对通过文献检索确定的大量研究重复应用纳入和排除标准。在这里，LLM（GPT-3.5 Turbo、GPT-4 Turbo、GPT-4o、Llama 3 70B、Gemini 1.5 Pro 和 Claude Sonnet 3.5）在 Cochrane Library 完整期刊的系统评价中进行了试用，以评估它们在摘要筛选的零样本二元分类中的准确性。对 800 条记录子集的试验确定了最佳提示策略，并证明了 LLM 在敏感度（LLM-max = 1.000，human-max = 0.775）、精确度（LLM-max = 0.927，human-max = 0.911）和平衡准确度（LLM-max = 0.904，human-max = 0.865）方面优于人类研究人员。在每次重复的搜索结果（n = 119,691）中都试验了表现最佳的 LLM-prompt 组合，结果显示敏感度一致（范围 0.756-1.000），但精确度降低（范围 0.004-0.096）。66 个 LLM-human 和 LLM-LLM 集成表现出完美的敏感度，最大精确度为 0.458，在更大规模的试验中观察到的性能下降较少。在评论之间观察到了性能的显著差异，凸显了部署前进行领域特定验证的重要性。法学硕士可以减少系统评价的人力成本，同时保持或提高准确性和敏感性。系统评价是跨学科证据综合的基础，包括循证医学，法学硕士可以提高这种研究模式的效率和质量。]]></description>
      <guid>https://arxiv.org/abs/2411.02451</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用模糊图注意网络和动态负采样增强链接预测</title>
      <link>https://arxiv.org/abs/2411.07482</link>
      <description><![CDATA[arXiv:2411.07482v2 公告类型：replace-cross 
摘要：链接预测对于理解复杂网络至关重要，但传统的图神经网络 (GNN) 通常依赖于随机负采样，导致性能不佳。本文介绍了模糊图注意网络 (FGAT)，这是一种集成模糊粗糙集进行动态负采样和增强节点特征聚合的新方法。模糊负采样 (FNS) 根据模糊相似性系统地选择高质量负边，提高训练效率。FGAT 层结合了模糊粗糙集原理，实现了稳健且有判别力的节点表示。在两个研究合作网络上的实验证明了 FGAT 卓越的链接预测准确性，通过利用模糊粗糙集的强大功能进行有效的负采样和节点特征学习，其表现优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2411.07482</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>