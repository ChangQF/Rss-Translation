<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 10 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于扩散的对比学习用于顺序推荐</title>
      <link>https://arxiv.org/abs/2405.09369</link>
      <description><![CDATA[arXiv:2405.09369v3 公告类型：替换 
摘要：自监督对比学习直接从未标记数据中提取固有的数据相关性，已被广泛应用于缓解序列推荐中的数据稀疏性问题。现有的大多数方法通过随机增强对同一用户序列创建不同的增强视图，然后在嵌入空间中最小化它们之间的距离以提高用户表示的质量。然而，随机增强往往会破坏用户序列中固有的语义信息和兴趣演变模式，导致生成语义上不同的增强视图。提高这些语义上不同的增强序列的相似性会导致学习到的用户表示对用户偏好和兴趣演变的变化不敏感，这与序列推荐的核心学习目标相矛盾。为了解决这个问题，我们利用序列推荐的固有特性，提出使用上下文信息来生成更合理的增强正样本。具体来说，我们介绍了一种基于上下文感知扩散的序列推荐对比学习方法。给定一个用户序列，我们的方法会选择某些位置，并采用上下文感知扩散模型在上下文信息的指导下为这些位置生成替代项目。然后，这些生成的项目将替换相应的原始项目，从而创建原始序列的语义一致的增强视图。此外，为了保持表示凝聚力，项目嵌入在扩散模型和推荐模型之间共享，并且整个框架以端到端的方式进行训练。在五个基准数据集上进行的大量实验证明了我们提出的方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2405.09369</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:20 GMT</pubDate>
    </item>
    <item>
      <title>通过对比预训练增强多领域 B2B 云解决方案匹配</title>
      <link>https://arxiv.org/abs/2402.07076</link>
      <description><![CDATA[arXiv:2402.07076v2 公告类型：替换 
摘要：云解决方案在技术行业中获得了极大的欢迎，因为它们提供了解决特定问题的服务和工具组合。然而，尽管它们被广泛使用，但为解决方案提供商的销售团队确定适合特定目标解决方案的公司客户的任务仍然是一个复杂的业务问题，现有的匹配系统尚未充分解决。在这项工作中，我们研究了 B2B 解决方案匹配问题，并确定了该场景的两个主要挑战：（1）复杂多字段特征的建模和（2）有限、不完整和稀疏的交易数据。为了应对这些挑战，我们提出了一个框架 CAMA，它以分层多字段匹配结构为骨干，并辅以三种数据增强策略和对比预训练目标，以弥补可用数据的缺陷。通过对真实数据集的大量实验，我们证明 CAMA 明显优于几个强大的基线匹配模型。此外，我们已经在华为云系统上部署了我们的匹配框架。我们的观察显示，与之前的线上模式相比，转化率（CVR）提升了约30%，体现出巨大的商业价值。]]></description>
      <guid>https://arxiv.org/abs/2402.07076</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>认知偏见用户在辩论主题的全会话搜索中与算法偏见结果进行交互</title>
      <link>https://arxiv.org/abs/2403.17286</link>
      <description><![CDATA[arXiv:2403.17286v2 公告类型：替换 
摘要：在与信息检索 (IR) 系统交互时，受确认偏差影响的用户倾向于选择能够确认他们在具有社会意义的争议问题上的现有信念的搜索结果。为了了解在线搜索用户的判断和态度变化，我们的研究考察了认知偏差用户如何与算法偏差的搜索引擎结果页面 (SERP) 交互。我们在各种偏见条件下针对有争议的话题设计了三个查询搜索会话。我们招募了 1,321 名众包参与者，并探讨了他们的态度变化、搜索互动以及确认偏差的影响。出现了三个关键发现：1) 大多数态度变化发生在搜索会话的初始查询中；2) SERP 上的确认偏差和结果呈现会影响当前查询中的点击次数和深度以及后续查询中对点击结果的熟悉程度；3) 偏见立场还会影响对冲突意见的感知开放性较低的用户的态度变化。我们的研究超越了传统的基于模拟的评估设置和模拟理性用户，揭示了人类偏见和算法偏见在争议话题的信息检索任务中的混合影响，并可以为偏见感知用户模型、以人为本的偏见缓解技术和对社会负责的智能 IR 系统的设计提供参考。]]></description>
      <guid>https://arxiv.org/abs/2403.17286</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>RLStop：一种用于 TAR 的强化学习停止方法</title>
      <link>https://arxiv.org/abs/2405.02525</link>
      <description><![CDATA[arXiv:2405.02525v2 公告类型：替换 
摘要：我们提出了 RLStop，这是一种基于强化学习的新型技术辅助审查 (TAR) 停止规则，有助于最大限度地减少 TAR 应用程序中需要手动审查的文档数量。RLStop 在示例排名上进行训练，使用奖励函数来确定停止检查文档的最佳点。在多个基准数据集（CLEF e-Health、TREC Total Recall 和 Reuters RCV1）上以一系列目标召回水平进行的实验表明，RLStop 大大减少了筛选文档集合相关性所需的工作量。RLStop 优于多种替代方法，在某些情况下可实现接近任务最大可能的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.02525</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>从信息论角度看监督分类的误差界限</title>
      <link>https://arxiv.org/abs/2406.04567</link>
      <description><![CDATA[arXiv:2406.04567v1 公告类型：交叉 
摘要：深度学习 (DL) 中仍存在一系列未解答的研究问题，包括过度参数化的神经网络的卓越泛化能力、非凸性条件下的高效优化性能以及泛化平坦最小值背后的机制。在本文中，我们采用信息论视角探索使用深度神经网络 (DNN) 进行监督分类的理论基础。我们的分析引入了拟合误差和模型风险的概念，它们与泛化误差一起构成了预期风险的上限。我们证明泛化误差受复杂度限制，受分布平滑度和样本大小的影响。因此，任务复杂性是数据集质量的可靠指标，可指导正则化超参数的设置。此外，得出的上限拟合误差将反向传播梯度、神经切线核 (NTK) 和模型的参数计数与拟合误差联系起来。利用三角不等式，我们建立了预期风险的上限。该上限为了解过度参数化、非凸优化和 DNN 中的平坦最小值的影响提供了宝贵的见解。最后，实证验证证实了推导的理论界限与实际预期风险之间存在显著的正相关性，证实了理论研究结果的实际相关性。]]></description>
      <guid>https://arxiv.org/abs/2406.04567</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>多头 RAG：使用 LLM 解决多方面问题</title>
      <link>https://arxiv.org/abs/2406.05085</link>
      <description><![CDATA[arXiv:2406.05085v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 通过将文档检索到 LLM 上下文中以提供更准确和相关的响应，增强了大型语言模型 (LLM) 的能力。现有的 RAG 解决方案不关注可能需要获取具有实质不同内容的多个文档的查询。此类查询经常发生，但具有挑战性，因为这些文档的嵌入在嵌入空间中可能很远，因此很难检索所有文档。本文介绍了多头 RAG (MRAG)，这是一种旨在通过一个简单而强大的想法解决这一差距的新方案：利用 Transformer 的多头注意层（而不是解码器层）的激活作为获取多方面文档的密钥。驱动动机是不同的注意力头可以学习捕获不同的数据方面。利用相应的激活会产生表示数据项和查询各个方面的嵌入，从而提高复杂查询的检索准确性。我们提供了评估方法和指标、合成数据集和实际用例来证明 MRAG 的有效性，与标准 RAG 基线相比，相关性提高了 20%。MRAG 可以与现有的 RAG 框架和基准测试工具（如 RAGAS）以及不同类别的数据存储无缝集成。]]></description>
      <guid>https://arxiv.org/abs/2406.05085</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>音乐个性化的负面反馈</title>
      <link>https://arxiv.org/abs/2406.04488</link>
      <description><![CDATA[arXiv:2406.04488v1 公告类型：交叉 
摘要：下一项推荐系统通常仅使用正反馈和随机采样的负反馈进行训练。我们展示了使用真实负反馈作为用户序列的输入以及作为训练互联网广播的下一首歌曲推荐系统的负目标的好处。特别是，在训练期间使用显式负样本有助于将训练时间缩短约 60%，同时将测试准确率提高约 6%；添加用户跳过作为额外输入也可以显着增加用户覆盖率，同时略微提高准确率。我们测试了使用大量随机负样本捕获“更难”样本的影响，发现测试准确率会随着更多随机采样的负样本而增加，但只能达到一定程度。太多的随机负样本会导致假负样本，从而限制提升，这仍然低于使用真实负反馈的情况。我们还发现，测试准确率对于不同反馈类型的比例相当稳健，并比较了不同反馈类型的学习嵌入。]]></description>
      <guid>https://arxiv.org/abs/2406.04488</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>GNNAnatomy：图神经网络的多级解释的系统生成和评估</title>
      <link>https://arxiv.org/abs/2406.04548</link>
      <description><![CDATA[arXiv:2406.04548v1 公告类型：交叉 
摘要：图神经网络 (GNN) 已被证明在涉及图的各种机器学习 (ML) 任务中非常有效，例如节点/图分类和链接预测。然而，由于基于图结构的聚合关系信息，解释 GNN 做出的决策带来了挑战，从而导致复杂的数据转换。现有的解释 GNN 的方法在系统地探索不同的子结构和在没有基本事实的情况下评估结果方面往往面临限制。为了解决这一差距，我们引入了 GNNAnatomy，这是一个与模型和数据集无关的可视化分析系统，旨在促进 GNN 的多级解释的生成和评估。在 GNNAnatomy 中，我们使用图元来阐明图级分类任务中的 GNN 行为。通过分析 GNN 分类和图元频率之间的关联，我们制定了假设的事实和反事实解释。为了验证假设的图元解释，我们引入了两个指标：(1) 其频率与分类置信度之间的相关性，以及 (2) 从原始图中删除此子结构后分类置信度的变化。为了证明 GNNAnatomy 的有效性，我们对来自各个领域的现实世界和合成图数据集进行了案例研究。此外，我们还将 GNNAnatomy 与最先进的 GNN 解释器进行了定性比较，证明了我们设计的实用性和多功能性。]]></description>
      <guid>https://arxiv.org/abs/2406.04548</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>CHIQ：通过上下文历史增强来改善对话搜索中的查询重写</title>
      <link>https://arxiv.org/abs/2406.05013</link>
      <description><![CDATA[arXiv:2406.05013v1 公告类型：新
摘要：在本文中，我们研究如何有效部署开源大型语言模型 (LLM) 来改进对话搜索中的查询重写，尤其是对于模糊查询。我们引入了 CHIQ，这是一种两步方法，利用 LLM 的功能在查询重写之前解决对话历史中的歧义。这种方法与之前的研究形成对比，之前的研究主要使用闭源 LLM 直接从对话历史中生成搜索查询。我们在五个成熟的基准上证明了 CHIQ 在大多数情况下都能产生最先进的结果，与利用闭源 LLM 的系统相比具有高度竞争力的性能。我们的研究为在对话搜索中利用开源 LLM 迈出了第一步，作为对商业 LLM 普遍依赖的有竞争力的替代方案。数据、模型和源代码将在接受后在 https://github.com/fengranMark/CHIQ 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2406.05013</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>通过近似贪婪梯度下降进行语料库中毒</title>
      <link>https://arxiv.org/abs/2406.05087</link>
      <description><![CDATA[arXiv:2406.05087v1 公告类型：新
摘要：密集检索器广泛应用于信息检索，并已成功扩展到其他知识密集型领域，如语言模型，例如检索增强生成 (RAG) 系统。不幸的是，最近有研究表明，它们容易受到语料库中毒攻击，恶意用户将一小部分对抗性段落注入检索语料库，诱使系统将这些段落返回到大量用户查询的顶级结果中。需要进一步研究以了解这些攻击在多大程度上限制了密集检索器在实际应用中的部署。在这项工作中，我们提出了近似贪婪梯度下降 (AGGD)，这是一种基于广泛使用的 HotFlip 方法对密集检索系统的新攻击，用于有效生成对抗性段落。我们证明，通过用更结构化的搜索替换随机 token 采样，AGGD 可以选择比 HotFlip 更高质量的 token 级扰动集。通过实验，我们表明我们的方法在多个数据集和使用多个检索器上实现了高攻击成功率，并且可以推广到未见过的查询和新域。值得注意的是，我们的方法在攻击 ANCE 检索模型方面非常有效，与 HotFlip 相比，在 NQ 和 MS MARCO 数据集上的攻击成功率分别高出 17.6% 和 13.37%。此外，我们展示了 AGGD 在其他对抗性攻击中取代 HotFlip 的潜力，例如 RAG 系统的知识毒化。\footnote{代码可以在 \url{https://github.com/JinyanSu1/AGGD}} 中找到]]></description>
      <guid>https://arxiv.org/abs/2406.05087</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>缩放伪代码的自动提取</title>
      <link>https://arxiv.org/abs/2406.04635</link>
      <description><![CDATA[arXiv:2406.04635v1 公告类型：新
摘要：学术论文中的伪代码提供了一种简洁的方式来表达其中实现的算法。伪代码也可以被认为是一种中间表示，有助于弥合编程语言和自然语言之间的差距。访问大量伪代码可以带来各种好处，从增强算法理解、促进进一步的算法设计，到增强 NLP 或基于计算机视觉的模型以执行自动代码生成和光学字符识别 (OCR) 等任务。我们从 arXiv 论文中提取了近 320,000 个伪代码示例，创建了一个大型伪代码集合。这个过程涉及扫描超过 220 万美元的学术论文，其中 1,000 篇经过手动检查和标记。考虑到集合固有的异质性，我们的方法包括一种定制的提取机制以优化覆盖率，以及一种基于随机抽样的验证机制来检查其准确性和可靠性。此外，我们还通过聚类和统计分析，对常见的伪代码结构进行了深入分析。值得注意的是，这些分析表明伪代码的使用呈指数级增长，凸显了伪代码的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.04635</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>QAGCF：用于问答推荐的图形协同过滤</title>
      <link>https://arxiv.org/abs/2406.04828</link>
      <description><![CDATA[arXiv:2406.04828v1 公告类型：新
摘要：问答平台通常会推荐问答对来满足用户的知识获取需求，而传统的推荐系统只会推荐一项内容。这使得用户行为变得更加复杂，也给问答推荐带来了两大挑战：一是协同信息纠缠，即用户反馈既受问题影响，又受答案影响；二是语义信息纠缠，即问题与答案相关，不同的问答对之间也存在相关性。传统的推荐方法将问答对作为一个整体来对待，或者只将答案视为单个内容，忽略了这两个挑战，无法有效地对用户兴趣进行建模。为了应对这些挑战，我们引入了问答图协同过滤（QAGCF），这是一种图神经网络模型，它为协同视图和语义视图创建单独的图，以解开问答对中的信息。协作视图将问题和答案分开，以单独建模协作信息，而语义视图则捕获问答对内部和之间的语义信息。这些视图进一步合并为全局图，以整合协作和语义信息。基于多项式的图过滤器用于解决全局图的高度异质性问题。此外，对比学习用于在训练期间获得稳健的嵌入。在工业和公共数据集上进行的大量实验表明，QAGCF 始终优于基线并取得最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.04828</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯激励相容的双边市场动态在线推荐</title>
      <link>https://arxiv.org/abs/2406.04374</link>
      <description><![CDATA[arXiv:2406.04374v1 公告类型：新
摘要：推荐系统通过将用户与相关产品或服务联系起来，在互联网经济中发挥着至关重要的作用。然而，设计有效的推荐系统面临两个关键挑战：（1）在平衡新产品探索与利用已知偏好之间的探索-利用权衡，以及（2）在考虑用户的自利行为和异质偏好方面的动态激励兼容性。本文将这些挑战形式化为动态贝叶斯激励兼容推荐协议（DBICRP）。为了解决 DBICRP，我们提出了一种两阶段算法（RCB），将激励探索与高效的离线学习组件相结合以供利用。在第一阶段，我们的算法探索可用产品，同时保持动态激励兼容性以确定足够的样本量。第二阶段采用反比例间隙抽样与任意机器学习方法相结合，以确保亚线性遗憾。从理论上讲，我们证明 RCB 实现了 $O(\sqrt{KdT})$ 遗憾，并在高斯先验假设下满足贝叶斯激励相容性 (BIC)。从经验上讲，我们通过模拟和个性化华法林剂量的实际应用验证了 RCB 的强激励增益、亚线性遗憾和稳健性。我们的工作为在线偏好学习环境中的激励感知推荐提供了一种原则性方法。]]></description>
      <guid>https://arxiv.org/abs/2406.04374</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>翻唱歌曲检测的创新：基于歌词的方法</title>
      <link>https://arxiv.org/abs/2406.04384</link>
      <description><![CDATA[arXiv:2406.04384v1 公告类型：新
摘要：翻唱歌曲是不同艺术家创作的歌曲的替代版本。长期以来，翻唱歌曲一直是音乐产业的重要组成部分，对音乐文化产生了重大影响，在公共场所经常听到。在线音乐平台的兴起进一步增加了它们的流行度，通常用作背景音乐或视频配乐。虽然当前的自动识别方法足以识别原创歌曲，但对翻唱歌曲的效果较差，主要是因为翻唱版本通常与原始作品有很大偏差。在本文中，我们提出了一种利用歌曲歌词的翻唱歌曲检测新方法。我们引入了一个用于翻唱歌曲及其对应原曲的新数据集。该数据集包含 5078 首翻唱歌曲和 2828 首原创歌曲。与其他翻唱歌曲数据集相比，它包含原曲和翻唱歌曲的带注释歌词。我们在这个数据集上评估了我们的方法，并将其与多种基线方法进行了比较。结果表明，我们的方法优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2406.04384</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>迟做总比不做好：制定和基准化建议编辑</title>
      <link>https://arxiv.org/abs/2406.04553</link>
      <description><![CDATA[arXiv:2406.04553v1 公告类型：新
摘要：推荐系统在根据用户的偏好向他们推荐商品方面起着关键作用。然而，在在线平台中，由于模型容量有限、数据质量差或用户兴趣不断变化，这些系统不可避免地会提供不合适的推荐。提升用户体验需要有效地纠正这种不合适的推荐行为。本文介绍了一项新颖而重要的任务，称为推荐编辑，其重点是修改已知和不合适的推荐行为。具体而言，此任务旨在调整推荐模型以消除已知不合适的项目，而无需访问训练数据或重新训练模型。我们正式定义了推荐编辑问题，其主要目标有三个：严格纠正、协作纠正和集中纠正。制定了三个评估指标来定量评估每个目标的实现情况。我们使用新颖的编辑贝叶斯个性化排名损失为推荐编辑提供了一个简单而有效的基准。为了证明所提出方法的有效性，我们建立了一个综合基准，其中包含来自相关领域的各种方法。代码库位于：https://github.com/cycl2018/Recommendation-Editing。]]></description>
      <guid>https://arxiv.org/abs/2406.04553</guid>
      <pubDate>Mon, 10 Jun 2024 06:21:14 GMT</pubDate>
    </item>
    </channel>
</rss>