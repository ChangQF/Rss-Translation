<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 15 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>减轻大型语言模型中的实体级幻觉</title>
      <link>https://arxiv.org/abs/2407.09417</link>
      <description><![CDATA[arXiv:2407.09417v1 公告类型：交叉 
摘要：大型语言模型 (LLM) 的出现彻底改变了用户访问信息的方式，从传统的搜索引擎转向使用 LLM 进行直接问答交互。然而，LLM 的广泛采用揭示了一个重大挑战，即幻觉，其中 LLM 会产生连贯但事实不准确的反应。这种幻觉现象导致用户对基于 LLM 的信息检索系统不信任。为了应对这一挑战，本文提出了基于幻觉检测 (DRAD) 的动态检索增强作为一种检测和缓解 LLM 中幻觉的新方法。DRAD 通过基于实时幻觉检测动态调整检索过程来改进传统的检索增强。它有两个主要组件：实时幻觉检测 (RHD)，用于在没有外部模型的情况下识别潜在幻觉；基于外部知识的自我校正 (SEK)，用于使用外部知识纠正这些错误。实验结果表明，DRAD 在检测和缓解 LLM 中的幻觉方面表现出色。我们所有的代码和数据都是开源的，网址为 https://github.com/oneal2000/EntityHallucination。]]></description>
      <guid>https://arxiv.org/abs/2407.09417</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能沉浸式辅助，助力工业环境中的交互式任务执行</title>
      <link>https://arxiv.org/abs/2407.09147</link>
      <description><![CDATA[arXiv:2407.09147v1 公告类型：交叉 
摘要：许多工业部门都依赖于能够操作复杂机械的训练有素的员工。在这项工作中，我们展示了一种由人工智能驱动的沉浸式辅助系统，该系统支持用户在工业环境中执行复杂任务。具体来说，我们的系统利用类似于果汁搅拌机设置的 VR 环境。这个物理设置的数字孪生模拟了用于混合制剂或液体的复杂工业机械（例如，类似于制药行业），包括各种容器、传感器、泵和流量控制器。该设置展示了我们系统在受控环境中的功能，同时作为更广泛工业应用的概念验证。我们的多模式人工智能助手的核心组件是一个大型语言模型和一个语音到文本模型，它们处理专家在 VR 环境中执行任务的视频和音频记录。从专家视频中提取的视频和语音输入使其能够提供分步指导，以支持用户执行复杂任务。这次演示展示了我们的人工智能助手在减少认知负荷、提高生产力和增强工业环境安全性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.09147</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:56 GMT</pubDate>
    </item>
    <item>
      <title>上下文嵌入可在 RAG 中高效生成答案</title>
      <link>https://arxiv.org/abs/2407.09252</link>
      <description><![CDATA[arXiv:2407.09252v1 公告类型：交叉 
摘要：检索增强生成 (RAG) 通过使用外部信息扩展输入来克服 LLM 知识有限的问题。因此，模型的上下文输入变得更长，这会减慢解码时间，直接转化为用户等待答案的时间。我们通过提出一种有效的上下文压缩方法 COCOM 来解决这一挑战，将长上下文减少到只有少数上下文嵌入，从而大大加快了生成时间。我们的方法允许不同的压缩率以解码时间和答案质量为代价。与早期的方法相比，COCOM 可以更有效地处理多个上下文，显着减少长输入的解码时间。与现有的高效上下文压缩方法相比，我们的方法实现了高达 5.69 $\times$ 的加速，同时实现了更高的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.09252</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:56 GMT</pubDate>
    </item>
    <item>
      <title>利用 Microsoft Copilot for Security 为安全运营中心提供人工智能引导响应</title>
      <link>https://arxiv.org/abs/2407.09017</link>
      <description><![CDATA[arXiv:2407.09017v1 公告类型：交叉 
摘要：安全运营中心应对源源不断的安全事件，从简单到高度复杂。为了解决这个问题，我们开发了 Copilot Guided Response (CGR)，这是一种行业规模的 ML 架构，可指导安全分析师完成三项关键任务——(1) 调查，通过识别类似事件提供必要的历史背景；(2) 分类以确定事件的性质——是真阳性、假阳性还是良性阳性；(3) 补救，推荐量身定制的遏制措施。CGR 集成到 Microsoft Defender XDR 产品中并在全球范围内部署，为数千名客户生成数百万条建议。我们进行了广泛的评估，包括内部评估、与安全专家的合作以及客户反馈，表明 CGR 在所有三个任务中都提供了高质量的建议。我们提供了 CGR 架构的全面概述，开创了先例，成为第一家如此深入公开讨论这些功能的网络安全公司。此外，我们还拥有最大的真实安全事件公开集合 GUIDE，涵盖 100 万个注释事件中的 1300 万个证据。通过让研究人员和从业人员能够对真实数据进行研究，GUIDE 推动了网络安全的发展并支持下一代机器学习系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2407.09017</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:55 GMT</pubDate>
    </item>
    <item>
      <title>不同的引用分布使研究评估变得复杂。无法制定一个普遍反映研究效率的单一指标</title>
      <link>https://arxiv.org/abs/2407.09138</link>
      <description><![CDATA[arXiv:2407.09138v1 公告类型：交叉摘要：目的：分析不同研究主题中出版物的引用分布的多样性，以调查与规模无关的基于排名的指标的准确性。基于前百分位数的指标是这种类型中最常见的指标，而对日本的评估是最明显的误判。设计/方法/方法：使用对数分箱的直方图、双秩图和对数转换的引用次数的正态概率图，分析了几个研究主题中来自国家和期刊的出版物的引用分布以及相应的全球出版物。结果：当本地出版物的全球排名符合幂律时，与规模无关的基于前百分位数的指标是准确的，但在国家中，引用最少的论文经常出现偏差，并且发生在所有影响因子高的期刊中。在这些情况下，单一指标具有误导性。比较未被引用的论文比例是预测这些偏差的最佳方法。研究局限性：这项研究从根本上说是分析性的；其结果描述的数学事实是不言而喻的。实际意义：经合组织、欧盟委员会、美国国家科学委员会等知名机构使用与规模无关的百分位指标对研究国家进行排名和单独评估，而这些指标在许多国家具有误导性。这些误导性的评估应该停止，因为它们会在研究政策制定者中引起混乱，并导致错误的研究政策。原创性/价值：以前尚未进行过将引用分布的下尾（包括未被引用的论文）与百分位研究指标联系起来的研究。目前的结果表明，这种类型的研究对于找到可靠的研究评估程序是必要的。]]></description>
      <guid>https://arxiv.org/abs/2407.09138</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:55 GMT</pubDate>
    </item>
    <item>
      <title>它们是同一张图片吗？调整概念瓶颈模型以实现图像检索中的人机协作</title>
      <link>https://arxiv.org/abs/2407.08908</link>
      <description><![CDATA[arXiv:2407.08908v1 公告类型：交叉 
摘要：图像检索在从野生动物保护到医疗保健的应用中起着关键作用，用于查找单个动物或相关图像以帮助诊断。尽管用于图像检索的深度学习技术已经取得了显着进步，但它们不完美的现实世界表现往往需要包括人类专业知识。人机循环方法通常依赖于人类独立完成任务，然后以各种方式将他们的意见与人工智能模型相结合，因为这些模型提供的可解释性或\textit{可纠正性}非常小。为了让人类干预人工智能模型，从而节省人类的时间和精力，我们采用了概念瓶颈模型 (CBM) 并提出了 \texttt{CHAIR}。 \texttt{CHAIR} (a) 使人类能够纠正中间概念，这有助于 \textit{改善} 生成的嵌入，并且 (b) 允许灵活的干预级别，以适应不同级别的人类专业知识以实现更好的检索。为了证明 \texttt{CHAIR} 的有效性，我们证明了我们的方法在无需任何外部干预的情况下，在图像检索指标上的表现优于类似模型。此外，我们还展示了人工干预如何帮助进一步提高检索性能，从而实现人机互补。]]></description>
      <guid>https://arxiv.org/abs/2407.08908</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:54 GMT</pubDate>
    </item>
    <item>
      <title>利用高级机器学习改变电影推荐：NMF、SVD 和 K-Means 聚类研究</title>
      <link>https://arxiv.org/abs/2407.08916</link>
      <description><![CDATA[arXiv:2407.08916v1 公告类型：交叉 
摘要：本研究使用各种机器学习技术开发了一个强大的电影推荐系统，包括非负矩阵分解 (NMF)、截断奇异值分解 (SVD) 和 K-Means 聚类。主要目标是通过提供个性化的电影推荐来增强用户体验。研究涵盖数据预处理、模型训练和评估，突出了所采用方法的有效性。结果表明，所提出的系统在推荐中实现了较高的准确性和相关性，为推荐系统领域做出了重大贡献。]]></description>
      <guid>https://arxiv.org/abs/2407.08916</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:54 GMT</pubDate>
    </item>
    <item>
      <title>PersonaRAG：使用以用户为中心的代理增强检索增强生成系统</title>
      <link>https://arxiv.org/abs/2407.09394</link>
      <description><![CDATA[arXiv:2407.09394v1 公告类型：新
摘要：大型语言模型 (LLM) 由于知识过时和幻觉而难以生成可靠的输出。检索增强生成 (RAG) 模型通过使用外部知识增强 LLM 来解决此问题，但通常无法个性化检索过程。本文介绍了 PersonaRAG，这是一个新颖的框架，结合了以用户为中心的代理，可根据实时用户数据和交互来调整检索和生成。在各种问答数据集上进行评估后，PersonaRAG 显示出优于基线模型的优势，可根据用户需求提供量身定制的答案。结果为用户适应的信息检索系统指明了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2407.09394</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:53 GMT</pubDate>
    </item>
    <item>
      <title>深度词袋模型：一种高效且可解释的中国电子商务相关性架构</title>
      <link>https://arxiv.org/abs/2407.09395</link>
      <description><![CDATA[arXiv:2407.09395v1 公告类型：新
摘要：查询和产品的文本相关性或文本匹配是电子商务搜索系统确保显示的产品能够与查询意图相匹配的重要技术。许多研究都致力于提高搜索系统中相关性模型的性能。最近，像 BERT 这样的预训练语言模型在文本相关性任务上取得了令人鼓舞的表现。虽然这些模型在离线测试数据集上表现良好，但由于其高延迟，将预训练语言模型部署到在线系统仍然存在障碍。双塔模型因其能够协调性能和计算效率而被广泛应用于工业场景。遗憾的是，这种模型呈现出不透明的“黑匣子”性质，阻止开发人员进行特殊优化。在本文中，我们提出了深度词袋（DeepBoW）模型，这是一种高效且可解释的中国电子商务相关性架构。我们的方法提出将查询和产品编码成稀疏的BoW表示，它是一组词权重对。权重表示相应词与原始文本之间的重要性或相关分数。相关性分数通过查询和产品的稀疏BoW表示之间匹配词的累积来衡量。与通常存在黑箱缺陷的流行密集分布式表示相比，所提出的表示模型的最大优势在于高度可解释和可干预，这对在线搜索引擎的部署和运行是一个优越的优势。此外，所提模型的在线效率甚至优于最高效的密集表示内积形式......]]></description>
      <guid>https://arxiv.org/abs/2407.09395</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:53 GMT</pubDate>
    </item>
    <item>
      <title>通过 AWRS 了解新闻回避：一种回避感知推荐系统</title>
      <link>https://arxiv.org/abs/2407.09137</link>
      <description><![CDATA[arXiv:2407.09137v1 公告类型：新
摘要：近年来，记者们对新闻文章回避趋势的增加表示担忧，尤其是在特定领域。推荐系统的兴起加剧了这一问题。我们的研究表明，推荐系统应该将回避作为一个基本因素。我们认为新闻文章可以用三个主要元素来描述：曝光、相关性和回避，所有这些都是紧密相连的。为了应对这些挑战，我们引入了 AWRS，一种回避意识推荐系统。该框架在推荐新闻时结合了回避意识，前提是新闻文章回避传达了有关用户偏好的重要信息。对不同语言（英语、挪威语和日语）的三个新闻数据集的评估结果表明，我们的方法优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2407.09137</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:52 GMT</pubDate>
    </item>
    <item>
      <title>通过多模态 Transformer 特征融合实现海报注意力机制的电影推荐</title>
      <link>https://arxiv.org/abs/2407.09157</link>
      <description><![CDATA[arXiv:2407.09157v1 公告类型：新
摘要：预训练模型从大型数据集中学习通用表示，这些表示可以针对特定任务进行微调，以显着减少训练时间。生成式预训练变压器（GPT）、变压器的双向编码器表示（BERT）、视觉变压器（ViT）等预训练模型已成为当前机器学习研究的基石。本研究提出了一种多模态电影推荐系统，通过提取每部电影精心设计的海报和电影的叙述性文本描述的特征。该系统使用 BERT 模型提取文本模态信息，使用 ViT 模型提取海报/图像模态信息，并使用 Transformer 架构融合所有模态的特征以预测用户的偏好。在下游应用中，将预训练的基础模型与一些较小的数据集相结合，可以更全面地捕获多模态内容特征，从而提供更准确的推荐。通过标准基准问题MovieLens 100K和1M数据集验证了概念验证模型的有效性，用户评分预测准确率与基线算法相比有所提高，从而证明了该跨模态算法在电影或视频推荐方面的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.09157</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 DICOM 结构化报告创建用于联邦学习的多模态数据集</title>
      <link>https://arxiv.org/abs/2407.09064</link>
      <description><![CDATA[arXiv:2407.09064v1 公告类型：新
摘要：目的：由于数据存储选项不同、命名方案不一致、注释程序不同以及标签质量差异，联合训练经常受到异构数据集的阻碍。这在新兴的多模态学习范式中尤为明显，其中数据集协调（包括统一的数据表示和过滤选项）至关重要。
方法：DICOM 结构化报告支持标准化链接成像领域之外的任意信息，并且可以在带有 highdicom 的 Python 深度学习管道中使用。在此基础上，我们开发了一个开放的数据集成和交互式过滤功能平台，简化了组装多模态数据集的过程。
结果：在这项研究中，我们扩展了我们之前的工作，展示了它对更多不同数据类型的适用性，并简化了德国八所大学医院联盟内联合训练的数据集。我们通过在所有位置创建协调的多模态数据集来证明其并发过滤能力，以预测微创心脏瓣膜置换术后的结果。数据包括 DICOM 数据（即计算机断层扫描图像、心电图扫描）以及注释（即钙化分割、点集和起搏器依赖性）和元数据（即假体和诊断）。
结论：结构化报告弥合了成像系统和信息系统之间的传统差距。利用固有的 DICOM 参考系统，可以同时查询任意数据类型，以创建有意义的临床研究队列。图形界面以及示例结构化报告模板将公开提供。]]></description>
      <guid>https://arxiv.org/abs/2407.09064</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:51 GMT</pubDate>
    </item>
    <item>
      <title>基于多模态大型语言模型的神经矩阵分解推荐系统模型</title>
      <link>https://arxiv.org/abs/2407.08942</link>
      <description><![CDATA[arXiv:2407.08942v1 Announce Type: new 
摘要：推荐系统已经成为信息搜索问题的重要解决方案。本文提出了一种基于多模态大型语言模型BoNMF的神经矩阵分解推荐系统模型。该模型结合了BoBERTa在自然语言处理、计算机视觉领域的ViT以及神经矩阵分解技术等强大能力，通过捕捉用户和物品的潜在特征，与用户和物品ID组成的低维矩阵进行交互后，神经网络输出结果进行推荐。冷启动和消融实验结果表明，BoNMF模型在大型公共数据集上表现出优异的性能，显著提高了推荐的准确率。]]></description>
      <guid>https://arxiv.org/abs/2407.08942</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:50 GMT</pubDate>
    </item>
    <item>
      <title>用于人员重新识别的可变长度 WiFi CSI 信号的时频分析</title>
      <link>https://arxiv.org/abs/2407.09045</link>
      <description><![CDATA[arXiv:2407.09045v1 Announce Type: new 
摘要：行人重识别（ReID）作为安防领域的关键技术，在安防检测和人数统计中发挥着重要作用。目前的安防和监控系统很大程度上依赖于视觉信息，这可能会侵犯个人隐私，并且在某些情况下容易受到行人外表和衣着的干扰。同时，路由器的广泛使用为ReID提供了新的可能性。本文介绍了一种使用WiFi信道状态信息（CSI）的方法，利用WiFi信号的多径传播特性作为区分不同行人特征的基础。我们提出了一种能够处理变长数据的双流网络结构，分析WiFi信号的时域幅度和频域相位，通过连续的横向连接融合时频信息，并采用先进的目标函数进行表示和度量学习。在现实世界收集的数据集上测试，我们的方法实现了93.68％的mAP和98.13％的Rank-1。]]></description>
      <guid>https://arxiv.org/abs/2407.09045</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:50 GMT</pubDate>
    </item>
    <item>
      <title>面向群体公平性评估的自动群体成员资格标注</title>
      <link>https://arxiv.org/abs/2407.08926</link>
      <description><![CDATA[arXiv:2407.08926v1 公告类型：新 
摘要：随着对信息检索系统公平性的研究关注度不断提高，越来越多的公平感知算法被提出来以确保公平性，从而实现可持续健康的检索生态系统。然而，作为公平感知算法最常用的测量方法，群体公平评估指标需要群体成员信息，而这些信息需要大量的人工注释，而一般信息检索数据集几乎无法获得这些信息。这种数据稀疏性严重阻碍了公平感知信息检索研究的发展。因此，需要一种实用、可扩展、低成本的群体成员注释方法来辅助或替代人工注释。本研究探讨了如何利用语言模型自动注释群体成员身份以进行群体公平性评估，重点关注注释准确性及其影响。我们的实验结果表明，基于 BERT 的模型优于最先进的大型语言模型，包括 GPT 和 Mistral，在最近的公平排名数据集中以最少的监督实现了令人满意的注释准确性。我们以影响为导向的评估表明，最小的注释错误不会降低群体公平性评估的有效性和稳健性。所提出的注释方法减少了大量的人力投入，并将公平意识研究的前沿扩展到更多的数据集。]]></description>
      <guid>https://arxiv.org/abs/2407.08926</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:49 GMT</pubDate>
    </item>
    </channel>
</rss>