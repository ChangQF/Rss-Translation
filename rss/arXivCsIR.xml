<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Tue, 19 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>探索基于特征的推荐系统知识提炼：频率视角</title>
      <link>https://arxiv.org/abs/2411.10676</link>
      <description><![CDATA[arXiv:2411.10676v1 公告类型：新
摘要：本文从频率角度分析了基于特征的知识提炼推荐方法。通过将知识定义为特征的不同频率成分，我们从理论上证明了常规的基于特征的知识提炼等同于对所有知识进行平均最小化损失，并进一步分析了这种平均损失权重分配方法如何导致重要知识被忽视。鉴于此，我们建议通过重新分配知识权重来强调重要知识。此外，我们提出了一种轻量级的知识重新加权方法 FreqD，以避免计算每个知识的损失的计算成本。大量实验表明，FreqD 始终显著优于推荐系统的最新知识提炼方法。我们的代码可在 \url{https://anonymous.4open.science/r/FreqKD/} 获得]]></description>
      <guid>https://arxiv.org/abs/2411.10676</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ForPKG-1.0：林业政策知识图谱构建框架及应用分析</title>
      <link>https://arxiv.org/abs/2411.11090</link>
      <description><![CDATA[arXiv:2411.11090v1 Announce Type: new 
摘要：政策知识图谱可以为项目合规、政策分析、智能问答等任务提供决策支持，也可以作为外部知识库辅助相关大型语言模型的推理过程。虽然目前已经有了很多关于知识图谱的相关工作，但是目前对政策知识图谱的构建方法的研究还比较缺乏。本文针对林业领域，设计了一个完整的政策知识图谱构建框架，包括：首先，提出一个细粒度的林业政策领域本体；然后，提出一种无监督的政策信息提取方法；最后，构建完整的林业政策知识图谱。实验结果表明，所提出的本体具有良好的表达力和可扩展性，本文提出的政策信息提取方法比其他无监督方法取得了更好的效果。此外，通过分析知识图谱在大型语言模型检索增强生成任务中的应用，确认了知识图谱在大型语言模型时代的实际应用价值。该知识图谱资源将在开源平台上发布，可作为林业政策相关智能系统的基础知识库，也可供学术研究使用。此外，本研究可为其他领域的政策知识图谱构建提供借鉴和指导。]]></description>
      <guid>https://arxiv.org/abs/2411.11090</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于流行度感知元学习的在线商品冷启动推荐</title>
      <link>https://arxiv.org/abs/2411.11225</link>
      <description><![CDATA[arXiv:2411.11225v1 公告类型：新
摘要：随着电子商务和短视频的兴起，能够捕捉用户兴趣并实时更新新项目的在线推荐系统发挥着越来越重要的作用。在线和离线推荐中，由于交互稀疏性导致的冷启动问题一直影响着冷启动项目的推荐效果，也称为项目分布的长尾问题。许多基于微调或知识迁移的冷启动方案在离线推荐中表现出色。然而，由于训练方法、计算开销和时间限制不同，这些方案不适用于流数据管道上的在线推荐。
受上述问​​题的启发，我们提出了一种与模型无关的推荐算法，称为流行度感知元学习（PAM），以解决流数据设置下的项目冷启动问题。PAM 根据预定义的项目流行度阈值将传入数据划分为不同的元学习任务。该模型可以根据行为相关特征和内容相关特征在不同流行度等级中所扮演的不同角色，对每个任务进行区分和重新加权，从而适应冷启动样本的推荐。这些针对任务的设计与离线方法相比，大大减少了额外的计算和存储成本。此外，PAM 还引入了数据增强和额外的自监督损失，专门针对低流行度任务设计，利用高流行度样本的洞察。这种方法有效地缓解了由于冷启动样本稀缺导致的监督不足的问题。在多个公共数据集上的实验结果证明了我们的方法在解决在线流数据场景中的冷启动挑战方面优于其他基线方法。]]></description>
      <guid>https://arxiv.org/abs/2411.11225</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>控制推理中的多样性：使用有针对性的类别偏好引导扩散推荐模型</title>
      <link>https://arxiv.org/abs/2411.11240</link>
      <description><![CDATA[arXiv:2411.11240v1 公告类型：新
摘要：多样性控制是缓解偏差放大和过滤气泡问题的重要任务。所需的多样性程度可能会根据用户的日常情绪或业务策略而波动。然而，现有的控制多样性的方法往往缺乏灵活性，因为多样性是在训练过程中决定的，在推理过程中不容易修改。我们提出了 \textbf{D3Rec}（\underline{D}isentangled \underline{D}iffusion model for \underline{D}iversified \underline{Rec}ommendation），这是一种端到端方法，可控制推理时的准确度-多样性权衡。D3Rec 通过 (1) 根据类别偏好生成推荐、(2) 在推理阶段控制类别偏好以及 (3) 适应任意目标类别偏好来满足我们的三个要求。在前向过程中，D3Rec 通过添加噪音来消除潜伏在用户交互中的类别偏好。然后，在逆向过程中，D3Rec 通过去噪步骤生成推荐，同时反映所需的类别偏好。在现实世界和合成数据集上进行的大量实验验证了 D3Rec 在推理时控制多样性的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.11240</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于点击率预测的全域 Moveline 演化网络</title>
      <link>https://arxiv.org/abs/2411.11502</link>
      <description><![CDATA[arXiv:2411.11502v1 公告类型：新 
摘要：电商APP用户的行为具有内在的逻辑一致性，一系列多场景的用户行为相互关联，形成场景级的全域用户行为线，最终揭示用户的真实意图。传统的CTR预估方法一般关注目标商品与历史交互商品之间的商品级交互，而目标商品与用户行为线之间的场景级交互仍未得到充分探索。在对与前述全域用户行为线的交互进行建模时，存在两个挑战：（i）商品与场景的异质性：与传统的以商品为载体的用户行为序列不同，用户行为线以场景为载体，商品与场景的异质性使得在统一的表示空间内对齐交互的过程变得复杂。 (ii) 链接的场景级和项目级行为的时间错位：在具有固定采样长度的先前用户移动线中，某些关键的场景级行为与后续的项目级行为紧密相关。但是，不可能建立完整的时间对齐，以清楚地识别哪些特定的场景级行为对应于哪些项目级行为。为了解决这些挑战并从全域移动线的角度开创性地建模用户意图，我们提出了全域移动线演化网络 (AMEN)。AMEN 不仅将项目和场景之间的交互转移到同质表示空间，而且还引入了时间顺序成对 (TSP) 机制来理解场景级和项目级行为之间的细微关联，确保全域用户移动线对用户喜欢和不喜欢的项目的 CTR 预测产生不同的影响。在线 A/B 测试表明，我们的方法实现了 CTCVR 的 +11.6% 的增长。]]></description>
      <guid>https://arxiv.org/abs/2411.11502</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于点击率预测的协作对比网络</title>
      <link>https://arxiv.org/abs/2411.11508</link>
      <description><![CDATA[arXiv:2411.11508v1 公告类型：新
摘要：电子商务平台为客户提供进入小程序的入口，以满足他们的特定购物需求。在小程序的入口处，会显示根据客户历史偏好推荐的触发项目，以吸引客户进入小程序。现有的点击率 (CTR) 预测方法有两个显着的弱点：（i）部分客户进入是由他们对小程序本身的兴趣而不是触发项目驱动的。在这种情况下，高度依赖触发项目的方法往往会推荐类似的项目，从而误解客户的真实意图；（ii）考虑客户对小程序意图的方法需要小程序定期存在才能让客户培养日常购物习惯，这使得这种方法对于仅在爆炸性促销场景 (EPS) 中短时间（1 或 3 天）可用的小程序不太稳健，例如黑色星期五和中国的双 11 购物嘉年华。为了解决上述问题，我们引入了一种更通用、更稳健的 CTR 预测方法，即协作对比网络 (CCN)。给定一个用户，CCN 通过利用共同点击/共同非点击的协作关系或单一点击的非协作关系作为对比学习的监督信号，学习识别两个可以代表用户兴趣和不感兴趣的项目集群。该范式不需要明确估计用户的二元输入意图，并且避免放大触发项目的影响。在大规模真实数据上的在线 A/B 测试表明，CCN 在淘宝上创下了新的最佳性能，将点击率提高了 12.3%，订单量提高了 12.7%。]]></description>
      <guid>https://arxiv.org/abs/2411.11508</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QARM：快手量化对齐多模态推荐</title>
      <link>https://arxiv.org/abs/2411.11739</link>
      <description><![CDATA[arXiv:2411.11739v1 Announce Type: new 
摘要：近年来，随着多模态大型模型的显著演进，许多推荐研究者意识到了多模态信息在用户兴趣建模中的潜力。在工业界，一种广泛使用的建模架构是级联范式：（1）首先预训练一个多模态模型，为下游服务提供全能的表示；（2）下游推荐模型将多模态表示作为额外输入，以拟合真实的用户-物品行为。虽然这种范式取得了显着的改进，但仍然存在两个限制模型性能的问题：（1）表示不匹配：预训练的多模态模型总是由经典的NLP/CV任务监督，而推荐模型由真实的用户-物品交互监督。因此，两个根本不同的任务的目标相对分离，并且在表示上缺乏一致的目标； （2）表征反学习：生成的多模态表征始终存储在缓存中，并作为推荐模型的额外固定输入，因此无法通过推荐模型梯度进行更新，这对下游训练不利。受下游任务使用中两个困难挑战的启发，我们引入了一个定量多模态框架，为不同的下游模型定制专门的、可训练的多模态信息。]]></description>
      <guid>https://arxiv.org/abs/2411.11739</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>淹没在文档中：扩展重排器推理的后果</title>
      <link>https://arxiv.org/abs/2411.11767</link>
      <description><![CDATA[arXiv:2411.11767v1 公告类型：新
摘要：重排器（通常是交叉编码器）通常用于对较便宜的初始 IR 系统检索到的文档进行重新评分。这是因为，尽管重排器价格昂贵，但人们认为它更有效。我们通过测量重排器对完整检索的性能（而不仅仅是对第一阶段检索进行重新评分）来挑战这一假设。我们的实验揭示了一个令人惊讶的趋势：现有的最佳重排器在对更多文档进行评分时提供的收益递减，并且实际上在超过一定限度时会降低质量。事实上，在这种情况下，重排器可以经常为与查询没有词汇或语义重叠的文档分配高分。我们希望我们的发现能够激发未来改进重排的研究。]]></description>
      <guid>https://arxiv.org/abs/2411.11767</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Any2Any：具有共形预测的不完全多模态检索</title>
      <link>https://arxiv.org/abs/2411.10513</link>
      <description><![CDATA[arXiv:2411.10513v1 公告类型：交叉 
摘要：自主代理通过集成多模态输入（例如视觉、音频和 LiDAR）来感知和解释周围环境。这些感知模态支持检索任务，例如机器人中的地点识别。然而，当前的多模态检索系统在部分数据由于传感器故障或无法访问而丢失时会遇到困难，例如静音视频或缺少 RGB 信息的 LiDAR 扫描。我们提出了 Any2Any——一种新颖的检索框架，可解决查询和参考实例都具有不完整模态的场景。与以前仅限于两种模态插补的方法不同，Any2Any 无需训练生成模型即可处理任意数量的模态。它使用跨模态编码器计算成对相似性，并采用具有共形预测的两阶段校准过程来对齐相似性。 Any2Any 可实现跨多模态数据集（例如文本激光雷达和文本时间序列）的有效检索。它在 KITTI 数据集上实现了 35% 的 Recall@5，与具有完整模态的基线模型相当。]]></description>
      <guid>https://arxiv.org/abs/2411.10513</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强元分析能力：利用大型语言模型进行科学综合</title>
      <link>https://arxiv.org/abs/2411.10878</link>
      <description><![CDATA[arXiv:2411.10878v1 公告类型：交叉 
摘要：本研究使用大型语言模型 (LLM) 调查了科学文献中元分析的自动化。元分析是一种强大的统计方法，它综合了多项研究支持文章的结果以提供全面的理解。我们知道一篇元文章提供了多篇文章的结构化分析。然而，手工进行元分析是劳动密集型的、耗时的，而且容易出现人为错误，这凸显了对自动化管道以简化流程的需求。我们的研究引入了一种新方法，可以在广泛的科学数据集上对 LLM 进行微调，以应对大数据处理和结构化数据提取方面的挑战。我们通过集成检索增强生成 (RAG) 来自动化和优化元分析过程。通过快速工程和新的损失度量反余弦距离 (ICD) 进行定制，LLM 专为在大型上下文数据集上进行微调而设计，可以有效地生成结构化的元分析内容。然后，人工评估将评估相关性并提供关键指标中模型性能的信息。这项研究表明，微调模型的表现优于非微调模型，微调后的 LLM 可生成 87.6% 的相关元分析摘要。基于人工评估的上下文相关性显示，不相关性从 4.56% 降低到 1.9%。这些实验是在资源匮乏的环境中进行的，凸显了该研究对提高元分析自动化效率和可靠性的贡献。]]></description>
      <guid>https://arxiv.org/abs/2411.10878</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对顺序推荐系统的少样本模型提取攻击</title>
      <link>https://arxiv.org/abs/2411.11677</link>
      <description><![CDATA[arXiv:2411.11677v1 公告类型：交叉 
摘要：在针对顺序推荐系统的对抗性攻击中，模型提取攻击是一种在没有先验知识的情况下攻击顺序推荐模型的方法。现有研究主要集中在对手通过无数据模型提取执行黑盒攻击。然而，关于对手能够访问少量原始数据（10\% 甚至更少）来开发替代模型的文献中仍然存在很大的空白。也就是说，如何在少量数据场景中构建具有高功能相似性的替代模型仍然是一个需要解决的问题。本研究通过引入一种针对顺序推荐系统的新型少量模型提取框架来解决这一空白，该框架旨在利用少量数据构建优越的替代模型。提出的少量模型提取框架由两个部分组成：自回归增强生成策略和双向修复损失促进模型蒸馏程序。具体来说，为了生成与原始数据分布非常接近的合成数据，自回归增强生成策略集成了概率交互采样器以提取固有依赖关系和合成决定信号模块以表征用户行为模式。随后，针对推荐列表之间的差异的双向修复损失被设计为辅助损失，以纠正代理模型的错误预测，从而有效地将知识从受害者模型转移到代理模型。在三个数据集上的实验表明，所提出的少样本模型提取框架可以产生卓越的代理模型。]]></description>
      <guid>https://arxiv.org/abs/2411.11677</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>字幕指标能反映音乐语义一致性吗？</title>
      <link>https://arxiv.org/abs/2411.11692</link>
      <description><![CDATA[arXiv:2411.11692v1 公告类型：交叉 
摘要：音乐字幕已成为一项有前途的任务，这得益于高级语言生成模型的出现。然而，音乐字幕的评估严重依赖于为其他领域开发的传统指标，例如 BLEU、METEOR 和 ROUGE，而没有充分的理由证明它们在这个新领域中的使用。我们介绍了传统指标容易受到句法变化影响的案例，并表明它们与人类判断的相关性不强。通过解决这些问题，我们旨在强调需要对音乐字幕的评估方式进行批判性重新评估。]]></description>
      <guid>https://arxiv.org/abs/2411.11692</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于内存的 Lucene 协同过滤</title>
      <link>https://arxiv.org/abs/1607.00223</link>
      <description><![CDATA[arXiv:1607.00223v2 公告类型：替换 
摘要：基于内存的协同过滤是一种广泛使用的推荐方法。它通过形成加权投票来预测未观察到的评级，从而利用用户群体中评级之间的相似性。经常采用定制解决方案来处理大型数据集上的高质量推荐问题。然而，这种方法的一个缺点是失去了一般协同过滤系统的通用性和灵活性。在本文中，我们开发了一种方法，允许人们在传统的全文搜索引擎（如 Apache Lucene）之上构建一个可扩展且有效的协同过滤系统。]]></description>
      <guid>https://arxiv.org/abs/1607.00223</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐之前的理解：通过大型语言模型进行语义方面感知评论开发</title>
      <link>https://arxiv.org/abs/2312.16275</link>
      <description><![CDATA[arXiv:2312.16275v2 公告类型：替换 
摘要：推荐系统利用用户与物品的交互（如点击和评论）来学习它们的表示。先前的研究通过对各个方面和意图的用户偏好进行建模来提高推荐的准确性和可解释性。然而，这些方面和意图是直接从用户评论或行为模式中推断出来的，受到数据噪声和数据稀疏性问题的困扰。此外，由于解释隐式方面和意图的挑战，很难理解推荐背后的原因。受大型语言模型 (LLM) 提供的深度语义理解的启发，我们引入了一种基于链的提示方法来揭示语义方面感知的交互，从而在细粒度的语义级别上更清晰地洞察用户行为。为了结合各个方面的丰富交互，我们提出了简单而有效的基于语义方面的图卷积网络 (SAGCN)。通过在多个语义方面图上执行图卷积，SAGCN 可以高效地将多个语义方面的嵌入组合起来，从而获得最终的用户和项目表示。通过大量实验，我们在三个公开可用的数据集上评估了 SAGCN 的有效性，结果表明它优于所有其他竞争对手。此外，我们还进行了可解释性分析实验，以证明将语义方面纳入模型的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2312.16275</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LoCo 和 M2-BERT 对长上下文检索模型进行基准测试和构建</title>
      <link>https://arxiv.org/abs/2402.07440</link>
      <description><![CDATA[arXiv:2402.07440v3 公告类型：替换 
摘要：检索管道是许多机器学习系统不可或缺的组成部分，但在文档较长（例如 10K 个标记或更多）且识别相关文档需要综合整个文本信息的领域中，其表现不佳。开发适合这些领域的长上下文检索编码器提出了三个挑战：（1）如何评估长上下文检索性能，（2）如何预训练基本语言模型以表示短上下文（对应于查询）和长上下文（对应于文档），以及（3）如何在 GPU 内存限制施加的批量大小限制下微调此模型以进行检索。为了应对这些挑战，我们首先引入了 LoCoV1，这是一个新颖的 12 任务基准，用于测量无法或无效分块的长上下文检索。接下来，我们将介绍 M2-BERT 检索编码器，这是一个基于 Monarch Mixer 架构构建的 80M 参数状态空间编码器模型，能够扩展到长度高达 32K 个 token 的文档。我们描述了一种预训练数据混合，它允许此编码器处理短上下文序列和长上下文序列，以及一种微调方法，该方法可使此基础模型适应仅使用单样本批次进行检索。最后，我们在 LoCoV1 上验证了 M2-BERT 检索编码器，发现它的表现至少比基于 Transformer 的竞争模型高出 23.3 分，尽管其参数减少了 90 倍以上。]]></description>
      <guid>https://arxiv.org/abs/2402.07440</guid>
      <pubDate>Tue, 19 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>