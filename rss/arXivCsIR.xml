<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 19 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过真实世界数据集成实现针对具体地址的可持续住宿选择</title>
      <link>https://arxiv.org/abs/2405.12934</link>
      <description><![CDATA[arXiv:2405.12934v2 公告类型：replace-cross 
摘要：消费者希望在旅行中选择可持续的住宿，对于公司而言，可能需要这样做。然而，住宿市场没有提供可持续选择的任何有意义的能力：通常，提供的二氧化碳估计值对于整个国家/地区所有相同类型的住宿都是相同的。我们提出了一个决策支持系统，可以真正选择可持续的住宿。我们开发了一种数据驱动的地址特定指标 EcoGrade，它集成了政府批准的数据集并在数据稀疏时使用插值。我们在 10 个城市的 10,000 个英国地址上验证了该指标，表明我们的插值与现实的匹配具有统计意义。我们展示了如何将该指标嵌入到全球住宿市场的决策支持系统中，并由真实用户在几个月内进行了测试，并获得了积极的用户反馈。在欧盟，40% 的最终能源消耗来自建筑物。我们需要鼓励所有建筑业主提高其住宿效率。租赁行业是变化最快的行业之一，因为出租房屋经常翻新。我们预计使用 EcoGrade 的决策支持系统将促进这一积极变化。]]></description>
      <guid>https://arxiv.org/abs/2405.12934</guid>
      <pubDate>Mon, 19 Aug 2024 06:22:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健的神经信息检索：对抗性和分布外的视角</title>
      <link>https://arxiv.org/abs/2407.06992</link>
      <description><![CDATA[arXiv:2407.06992v2 公告类型：替换 
摘要：神经信息检索 (IR) 模型的最新进展显著提高了它们在各种 IR 任务中的有效性。这些模型的稳健性对于确保其在实践中的可靠性至关重要，也引起了广泛关注。随着对稳健 IR 的广泛研究被提出，我们认为现在是巩固当前状态、从现有方法中汲取见解并为未来发展奠定基础的好时机。我们认为 IR 的稳健性是一个多方面的概念，强调其对抗对抗攻击、分布外 (OOD) 场景和性能差异的必要性。我们重点关注对抗和 OOD 稳健性，分别剖析密集检索模型 (DRM) 和神经排名模型 (NRM) 的稳健性解决方案，将它们视为神经 IR 管道的关键组件。我们深入讨论了现有的方法、数据集和评估指标，阐明了大型语言模型时代的挑战和未来方向。据我们所知，这是对神经 IR 模型稳健性的首次全面调查，我们还将在 SIGIR 2024 \url{https://sigir2024-robust-information-retrieval.github.io} 上进行首次教程演示。除了组织现有工作外，我们还引入了稳健 IR 基准 (BestIR)，这是稳健神经信息检索的异构评估基准，可在 \url{https://github.com/Davion-Liu/BestIR} 上公开获取。我们希望这项研究为未来关于 IR 模型稳健性的研究提供有用的线索，并有助于开发值得信赖的搜索引擎 \url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}。]]></description>
      <guid>https://arxiv.org/abs/2407.06992</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:59 GMT</pubDate>
    </item>
    <item>
      <title>TWIN V2：扩展超长用户行为序列建模，助力快手CTR预估</title>
      <link>https://arxiv.org/abs/2407.16357</link>
      <description><![CDATA[arXiv:2407.16357v2 公告类型：替换 
摘要：在大规模推荐系统中，对长期用户兴趣进行建模对于 CTR 预测任务的重要性正逐渐引起研究人员和从业者的关注。现有的工作，如 SIM 和 TWIN，出于效率考虑，通常采用两阶段方法来建模长期用户行为序列。第一阶段使用基于搜索的机制，即通用搜索单元 (GSU) 从长序列中快速检索与目标项目相关的序列子集，而第二阶段使用精确搜索单元 (ESU) 对检索到的结果计算兴趣分数。鉴于用户行为序列跨越整个生命周期的长度可能高达 10^6 的规模，目前尚无有效的解决方案来完全建模如此广泛的用户兴趣。为了解决这个问题，我们推出了 TWIN-V2，这是 TWIN 的增强版，其中采用分而治之的方法来压缩生命周期行为并发现更准确和多样化的用户兴趣。具体来说，离线阶段通过层次聚类方法将生命周期行为中具有相似特征的商品归为一簇，通过限制簇的大小，我们可以将超过10^5量级的行为序列压缩到GSU检索在线推理可控的长度；基于聚类感知的目标注意力机制可以提取用户全方位、多方面的长期兴趣，从而使最终的推荐结果更加精准多样。在数十亿级工业数据集上的大量离线实验和线上A/B测试证明了TWIN-V2的有效性。在高效的部署框架下，TWIN-V2已成功部署到快手数亿日活用户的主流量中。]]></description>
      <guid>https://arxiv.org/abs/2407.16357</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:59 GMT</pubDate>
    </item>
    <item>
      <title>RAGSys：项目冷启动推荐系统作为 RAG 系统</title>
      <link>https://arxiv.org/abs/2405.17587</link>
      <description><![CDATA[arXiv:2405.17587v2 公告类型：替换 
摘要：大型语言模型 (LLM) 在实际应用中前景广阔，但它们的通用知识往往无法满足特定领域的需求。微调是一种常见方法，可能会遭受灾难性遗忘并阻碍普遍性。上下文学习 (ICL) 提供了一种替代方案，它可以利用检索增强生成 (RAG) 为 LLM 提供针对少量学习任务的相关演示。本文探讨了 ICL 演示检索系统所需的品质。我们认为，在这种情况下，ICL 检索类似于项目冷启动推荐系统，优先考虑发现并最大化信息增益而不是严格相关性。我们提出了一种新颖的评估方法来衡量 LLM 在 NLP 任务上的后续表现，从而无需主观多样性分数。我们的研究结果证明了多样性和质量偏差在有效 ICL 检索演示中起着关键作用，并强调了推荐系统技术在该领域的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.17587</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:58 GMT</pubDate>
    </item>
    <item>
      <title>超越 KAN：引入 KarSein 实现 CTR 预测中的自适应高阶特征交互建模</title>
      <link>https://arxiv.org/abs/2408.08713</link>
      <description><![CDATA[arXiv:2408.08713v1 公告类型：交叉 
摘要：对特征交互进行建模对于点击率 (CTR) 预测至关重要，尤其是在高阶显式交互方面。传统方法难以完成这项任务，因为它们通常预定义最大交互阶数，这严重依赖于先验知识并可能限制模型的有效性。此外，对高阶交互进行建模通常会导致计算成本增加。因此，挑战在于自适应地对高阶特征交互进行建模，同时保持效率。为了解决这个问题，我们引入了 Kolmogorov-Arnold 表示稀疏高效交互网络 (KarSein)，旨在优化预测准确性和计算效率。我们首先确定直接将 Kolmogorov-Arnold 网络 (KAN) 应用于 CTR 的局限性，然后引入 KarSein 来克服这些问题。它具有一种新颖的架构，可以降低 KAN 的计算成本并支持嵌入向量作为特征输入。此外，KarSein 采用引导符号回归来解决 KAN 在自发学习乘法关系方面的挑战。大量实验证明了 KarSein 的卓越性能，以最小的计算开销实现了显着的预测准确性。此外，KarSein 保持了强大的全局可解释性，同时能够去除冗余特征，从而形成稀疏的网络结构。这些优势也使 KarSein 成为一种有前途的高效推理方法。]]></description>
      <guid>https://arxiv.org/abs/2408.08713</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:57 GMT</pubDate>
    </item>
    <item>
      <title>在用户流量波动的情况下保证准确性和公平性：一种受破产启发的重新排名方法</title>
      <link>https://arxiv.org/abs/2405.16120</link>
      <description><![CDATA[arXiv:2405.16120v2 Announce Type: replace 
摘要：出于可持续发展和经济性的考虑，双边推荐平台必须同时满足用户和提供商的需求。以往的研究往往表明，双方的需求表现出不同的紧迫性：提供商需要相对长期的曝光需求，而用户则需要更短期和准确的服务。然而，我们的实证研究表明，在实际用户流量波动的应用中，以前的公平性-准确性权衡方法往往无法同时保证长期公平性和短期准确性。特别是在用户流量较低时，用户体验往往会下降很多。我们的理论分析也证实了用户流量是这种权衡问题的关键因素。如何在用户流量波动的情况下保证准确性和公平性仍然是一个问题。受经济学中破产问题的启发，我们提出了一种新颖的公平感知重排序方法，名为BankFair。直观地讲，BankFair 利用 Talmud 规则利用用户流量充足的时段来抵消用户流量稀缺的时段，确保每个时段的用户服务一致，同时维护长期公平性。具体来说，BankFair 包含两个模块：(1) 使用 Talmud 规则确定不同用户流量时段所需的公平度；(2) 根据 Talmud 规则确定的公平度执行在线重新排序算法。在两个真实推荐数据集上的实验表明，BankFair 在准确性和提供商公平性方面优于所有基准。]]></description>
      <guid>https://arxiv.org/abs/2405.16120</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:57 GMT</pubDate>
    </item>
    <item>
      <title>迈向逼真的合成用户生成内容：生成在线讨论的支架方法</title>
      <link>https://arxiv.org/abs/2408.08379</link>
      <description><![CDATA[arXiv:2408.08379v1 公告类型：交叉 
摘要：合成数据的出现代表了现代机器学习的一个关键转变，它提供了一种解决方案来满足在真实数据稀缺、高度私密或难以获得的领域对大量数据的需求。我们研究了创建真实的、大规模的用户生成内容合成数据集的可行性，并注意到此类内容越来越普遍，并且是经常被搜索的信息来源。大型语言模型 (LLM) 为生成合成社交媒体讨论线程提供了一个起点，因为它们能够产生代表在线互动的多样化响应。然而，正如我们所展示的，直接应用 LLM 在捕捉在线讨论的复杂结构方面取得的成功有限，而标准的提示机制缺乏足够的控制。因此，我们提出了一个多步骤生成过程，该过程基于创建讨论线程的紧凑表示（称为支架）的想法。我们的框架是通用的，但可以适应特定社交媒体平台的独特特征。我们使用来自两个不同在线讨论平台的数据证明了其可行性。为了解决确保合成数据的代表性和真实性这一根本挑战，我们提出了一系列评估措施来比较我们框架的各种实例。]]></description>
      <guid>https://arxiv.org/abs/2408.08379</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:56 GMT</pubDate>
    </item>
    <item>
      <title>W-RAG：面向开放域问答的 RAG 弱监督密集检索</title>
      <link>https://arxiv.org/abs/2408.08444</link>
      <description><![CDATA[arXiv:2408.08444v1 公告类型：交叉 
摘要：在开放域问答 (OpenQA) 等知识密集型任务中，大型语言模型 (LLM) 通常难以仅依靠其内部 (参数) 知识来生成事实答案。为了解决这一限制，检索增强生成 (RAG) 系统通过从外部来源检索相关信息来增强 LLM，从而将检索器定位为关键组件。尽管密集检索表现出最先进的性能，但由于缺乏基本事实证据，其训练面临挑战，这主要归因于人工注释的高成本。在本文中，我们提出了 W-RAG，利用 LLM 的排名功能来创建弱标记数据以训练密集检索器。具体来说，我们通过评估 LLM 根据问题和每个段落生成正确答案的概率，对通过 BM25 检索到的前 $K$ 个段落进行重新排序。然后将排名最高的段落用作密集检索的正面训练示例。我们在四个公开的 OpenQA 数据集上进行的全面实验表明，与基线模型相比，我们的方法提高了检索和 OpenQA 性能。]]></description>
      <guid>https://arxiv.org/abs/2408.08444</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:56 GMT</pubDate>
    </item>
    <item>
      <title>基于查询的实体对象转换器的多模态关系三元组提取</title>
      <link>https://arxiv.org/abs/2408.08709</link>
      <description><![CDATA[arXiv:2408.08709v1 公告类型：新
摘要：多模态关系提取对于构建灵活而逼真的知识图谱至关重要。最近的研究重点是提取不同模态中存在的实体对的关系类型，例如文本中的一个实体和图像中的另一个实体。然而，现有的方法需要预先给出实体和对象，这既昂贵又不切实际。为了解决这一限制，我们提出了一项新任务，即多模态实体-对象关系三元组提取，旨在从图像-文本对中提取所有三元组（实体跨度、关系、对象区域）。为了促进这项研究，我们修改了一个包含 21 种关系类型的多模态关系提取数据集 MORE，以创建一个包含 20,264 个三元组的新数据集，平均每个图像-文本对有 5.75 个三元组。此外，我们提出了 QEOT，这是一种具有选择性注意机制的基于查询的模型，用于动态探索文本和视觉信息的交互和融合。具体来说，所提出的方法可以通过一组查询同时完成实体提取、关系分类和对象检测。我们的方法适用于下游应用，并且由于采用流水线式方法而减少了错误累积。大量实验结果表明，我们提出的方法比现有基线高出 8.06%，并达到了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.08709</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:55 GMT</pubDate>
    </item>
    <item>
      <title>EasyRec：简单而有效的推荐语言模型</title>
      <link>https://arxiv.org/abs/2408.08821</link>
      <description><![CDATA[arXiv:2408.08821v1 公告类型：新
摘要：深度神经网络已成为推荐系统协同过滤 (CF) 中从用户-项目交互数据中学习表示的强大技术。然而，许多现有方法严重依赖于唯一的用户和项目 ID，这限制了它们在实际零样本学习场景中表现良好的能力，因为在实际零样本学习场景中可能没有足够的训练数据。受到语言模型 (LM) 的成功及其强大的泛化能力的启发，一个关键问题出现了：我们如何利用语言模型的潜力来增强推荐系统并将其泛化能力提升到新的高度？在本研究中，我们提出了 EasyRec——一种有效且易于使用的方法，可将基于文本的语义理解与协作信号无缝集成。EasyRec 采用文本行为对齐框架，将对比学习与协作语言模型调整相结合，以确保文本增强语义空间与协作行为信息之间的强对齐。在各种真实数据集上进行的大量实证评估表明，EasyRec 的性能优于最先进的替代模型，尤其是在具有挑战性的基于文本的零样本推荐场景中。此外，该研究还强调了将 EasyRec 作为即插即用组件无缝集成到文本增强型协同过滤框架中的潜力，从而使现有的推荐系统能够提升其推荐性能并适应动态环境中不断变化的用户偏好。为了更好地重现我们的 EasyRec 框架的结果，模型实现细节、源代码和数据集可在以下链接中找到：https://github.com/HKUDS/EasyRec。]]></description>
      <guid>https://arxiv.org/abs/2408.08821</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:55 GMT</pubDate>
    </item>
    <item>
      <title>SC-Rec：通过自洽重排序增强生成检索以实现顺序推荐</title>
      <link>https://arxiv.org/abs/2408.08686</link>
      <description><![CDATA[arXiv:2408.08686v1 公告类型：新
摘要：语言模型 (LM) 因其先进的语言理解和生成能力而越来越多地应用于推荐系统。最近基于生成检索的推荐系统利用 LM 的推理能力，根据用户交互历史中的项目序列直接生成下一个项目的索引标记。以前的研究主要集中在仅基于文本语义或协作信息的项目索引上。然而，尽管这些方面的独立有效性已经得到证明，但这些信息的整合仍未得到探索。我们的深入分析发现，模型从异构项目索引和不同的输入提示中捕获的知识存在显著差异，这可能具有很高的互补性。在本文中，我们提出了 SC-Rec，这是一个统一的推荐系统，可以从两个不同的项目索引和多个提示模板中学习不同的偏好知识。此外，SC-Rec 采用了一种新颖的重新排序策略，该策略汇总了基于不同指标和提示推断出的一组排序结果，以实现模型的自洽性。我们对三个真实数据集的实证评估表明，SC-Rec 的表现远远优于最先进的顺序推荐方法，有效地整合了来自模型不同输出的互补知识。]]></description>
      <guid>https://arxiv.org/abs/2408.08686</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:54 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的跨模态协同融合推荐</title>
      <link>https://arxiv.org/abs/2408.08564</link>
      <description><![CDATA[arXiv:2408.08564v1 公告类型：新
摘要：尽管传统的协同过滤 (CF) 方法在推荐系统中取得了成功，但它们在利用用户和项目的文本属性中的语义知识方面表现出局限性。最近对大型语言模型在推荐中的应用 (LLM4Rec) 的关注凸显了它们有效语义知识捕获的能力。然而，这些方法往往忽视了用户行为中的协作信号。一些只是指导调整语言模型，而另一些则直接注入基于 CF 的模型的嵌入，缺乏不同模态的协同融合。为了解决这些问题，我们提出了一个用于推荐的大型语言模型的协作跨模态融合框架，称为 CCF-LLM。在这个框架中，我们将用户-项目交互转换成混合提示，以编码语义知识和协作信号，然后采用一种细心的跨模态融合策略来有效地融合两种模态的潜在嵌入。大量实验表明，CCF-LLM 通过在 LLM4Rec 环境中有效利用语义和协作信号，表现优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2408.08564</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:53 GMT</pubDate>
    </item>
    <item>
      <title>OptDist：学习客户终身价值预测的最优分布</title>
      <link>https://arxiv.org/abs/2408.08585</link>
      <description><![CDATA[arXiv:2408.08585v1 公告类型：新
摘要：客户生命周期价值 (CLTV) 预测是商业应用中的一项关键任务。准确预测 CLTV 在现实世界的商业场景中具有挑战性，因为 CLTV 的分布复杂且易变。首先，有大量没有任何消费的用户由长尾部分组成，这太复杂了，无法适应。其次，一小部分高价值用户的消费比典型用户高出几个数量级，导致 CLTV 分布范围很广，很难在单个分布中捕获。现有的 CLTV 估计方法要么假设先验概率分布并为所有样本拟合一组与分布相关的参数，要么以启发式方式直接从后验分布中学习手动预定义的桶。然而，所有这些方法都无法处理复杂且易变的分布。在本文中，我们提出了一种用于 CLTV 预测的新型最优分布选择模型 OptDist，该模型利用自适应最优子分布选择机制来提高复杂分布建模的准确性。具体而言，OptDist 在分布学习模块 (DLM) 中训练多个候选子分布网络，用于对 CLTV 的概率分布进行建模。然后，我们提出了一个分布选择模块 (DSM) 来为每个样本选择子分布，从而自动自适应地进行选择。此外，我们设计了一种连接两个模块的对齐机制，可有效指导优化。我们在两个公共数据集和一个私有数据集上进行了广泛的实验，以验证 OptDist 的表现优于最先进的基线。此外，OptDist 已部署在大型金融平台上用于客户获取营销活动，在线实验也证明了 OptDist 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.08585</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:53 GMT</pubDate>
    </item>
    <item>
      <title>不要上当：通过跨领域对比学习实现标题去偏新闻推荐</title>
      <link>https://arxiv.org/abs/2408.08538</link>
      <description><![CDATA[arXiv:2408.08538v1 公告类型：新
摘要：新闻推荐是用户从大量新闻中获取感兴趣内容的主要手段。标题点击诱饵广泛存在于新闻领域，增加了新闻推荐为用户提供满意服务的难度。幸运的是，我们发现新闻摘要作为新闻的一个重要领域，与新闻真实性紧密相关。为此，我们提出了一种跨领域对比学习的标题去偏新闻推荐 (TDNR-C2)，通过结合新闻摘要来克服标题偏见。具体来说，设计了一个多领域知识提取模块，从各个领域提取关于新闻的多视角知识。之后，我们提出了一个跨领域对比学习模块，通过对比从标题和摘要字段中学习到的知识来进行偏见消除。在真实数据集上的实验结果表明，所提出的 TDNR-C2 优于现有的最先进方法。进一步的分析也表明了新闻摘要对标题去偏的重要意义。]]></description>
      <guid>https://arxiv.org/abs/2408.08538</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:52 GMT</pubDate>
    </item>
    <item>
      <title>MuRAR：一种简单有效的多模态检索和答案细化框架，用于多模态问答</title>
      <link>https://arxiv.org/abs/2408.08521</link>
      <description><![CDATA[arXiv:2408.08521v1 公告类型：新
摘要：检索增强生成 (RAG) 的最新进展在问答 (QA) 任务中表现出色。然而，大多数以前的工作主要关注基于文本的答案。虽然一些研究涉及多模态数据，但它们在生成全面的多模态答案方面仍然不足，特别是在解释概念或提供有关如何实现特定目标的分步教程方面。此功能对于企业聊天机器人等应用程序以及客户服务和教育系统等设置尤其有价值，其中答案来自多模态数据。在本文中，我们介绍了一个简单有效的框架，名为 MuRAR（多模态检索和答案细化）。MuRAR 通过检索相关的多模态数据并细化响应以创建连贯的多模态答案来增强基于文本的答案。这个框架可以轻松扩展，以支持企业聊天机器人中的多模态答案，只需进行最少的修改。人工评估结果表明，与纯文本答案相比，MuRAR 生成的多模式答案更有用、更易读。]]></description>
      <guid>https://arxiv.org/abs/2408.08521</guid>
      <pubDate>Mon, 19 Aug 2024 06:21:51 GMT</pubDate>
    </item>
    </channel>
</rss>