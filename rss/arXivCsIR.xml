<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 FlexEMR 分解嵌入推荐系统</title>
      <link>https://arxiv.org/abs/2410.12794</link>
      <description><![CDATA[arXiv:2410.12794v1 公告类型：新
摘要：由于基于嵌入的推荐 (EMR) 模型对内存的需求越来越大，因此有效地为其提供服务仍然是一项重大挑战。当今的做法是将模型拆分到许多单片服务器上，其中 GPU、CPU 和 DRAM 的混合以固定比例配置。这种方法导致资源利用率不理想并增加成本。将嵌入操作与神经网络推理分离是一种很有前途的解决方案，但带来了新的网络挑战。在本文中，我们讨论了 FlexEMR 的设计以优化 EMR 分解。FlexEMR 提出了两组技术来应对网络挑战：利用嵌入查找的时间和空间局部性来减少网络上的数据移动，并为并发查找子请求设计优化的多线程 RDMA 引擎。我们概述了每种技术的设计空间，并展示了我们早期原型的初步结果。]]></description>
      <guid>https://arxiv.org/abs/2410.12794</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过双重稳健学习实现广告个性化</title>
      <link>https://arxiv.org/abs/2410.12799</link>
      <description><![CDATA[arXiv:2410.12799v1 公告类型：新
摘要：广告供应个性化旨在通过调整广告数量和密度来平衡收入和用户参与度，这是社交媒体广告的两个长期目标。在行业规模系统中，广告供应的挑战在于对长期保守供应处理（例如，小的密度变化）的反事实效应进行建模。在本文中，我们提出了一个简化的个性化广告供应框架。该框架通过双重稳健学习最佳地利用了数据收集策略中的信息。因此，它显着提高了长期治疗效果估计的准确性。此外，与现有方法相比，它的低复杂度设计不仅节省了计算成本，而且使其可扩展到十亿级应用。通过离线实验和在线生产测试，该框架在数月内持续表现出顶线业务指标的显着改善。该框架已在全球最大的社交媒体平台之一的实时流量中全面部署。]]></description>
      <guid>https://arxiv.org/abs/2410.12799</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化和评估企业检索增强生成 (RAG)：内容设计视角</title>
      <link>https://arxiv.org/abs/2410.12812</link>
      <description><![CDATA[arXiv:2410.12812v1 公告类型：新
摘要：检索增强生成 (RAG) 是一种使用大型语言模型 (LLM) 构建客户支持、问答解决方案的流行技术。在本文中，我们分享了我们团队的实践经验，即构建和维护企业级 RAG 解决方案，这些解决方案基于产品文档回答用户有关我们软件的问题。我们的经验并不总是与 RAG 文献中最常见的模式相匹配。本文重点介绍模块化和与模型无关的解决方案策略。例如，我们在过去几年的经验 - 使用不同的搜索方法和 LLM 以及许多知识库集合 - 表明，对我们创建知识库内容的方式的简单更改可能会对我们的 RAG 解决方案的成功产生巨大影响。在本文中，我们还讨论了我们如何监控和评估结果。常见的 RAG 基准评估技术对于评估对新用户问题的回答没有用处，因此我们发现需要一种灵活的“以人为本”的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.12812</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型增强电子商务中的个性化推荐</title>
      <link>https://arxiv.org/abs/2410.12829</link>
      <description><![CDATA[arXiv:2410.12829v1 Announce Type: new 
摘要：本研究深入探索大型语言模型（LLM）在电商个性化推荐系统中的应用，针对传统推荐算法在处理大规模多维数据时的局限性，提出了一种基于LLM的推荐系统框架。通过对比实验，基于LLM的推荐模型在精度、召回率、F1得分、平均点击率（CTR）、推荐多样性等多个关键指标上都有明显提升，其中LLM模型的精度由0.75提升到0.82，召回率由0.68提升到0.77，F1得分由0.71提升到0.79，CTR由0.56提升到0.63，推荐多样性由0.34提升到0.48，提升幅度达41.2%。 LLM通过对用户评论和商品描述数据的深度语义理解，有效捕捉用户隐性需求，并结合上下文数据进行动态推荐，产生更加精准多样的结果。研究表明LLM在个性化推荐领域具有显著优势，能够提升用户体验并促进平台销量增长，为电商个性化推荐技术提供强有力的理论与实践支持。]]></description>
      <guid>https://arxiv.org/abs/2410.12829</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐的偏好扩散</title>
      <link>https://arxiv.org/abs/2410.13117</link>
      <description><![CDATA[arXiv:2410.13117v1 公告类型：新
摘要：推荐系统根据从历史行为数据中得出的用户偏好分布来预测个性化项目排名。最近，扩散模型 (DM) 因其能够对复杂分布进行建模的能力而在推荐领域引起了关注，但当前基于 DM 的推荐器通常依赖于传统目标，如均方误差 (MSE) 或推荐目标，这些目标并未针对个性化排名任务进行优化或未能充分利用 DM 的生成潜力。为了解决这个问题，我们提出了 PreferDiff，这是一个针对基于 DM 的推荐器的定制优化目标。PreferDiff 将 BPR 转换为对数似然排名目标，并整合多个负样本以更好地捕捉用户偏好。具体而言，我们采用变分推理通过最小化变分上限来处理难处理性，并用余弦误差代替 MSE 以改善与推荐任务的一致性。最后，我们平衡学习生成和偏好以增强 DM 的训练稳定性。 PreferDiff 具有三大主要优势：它是第一个专为基于 DM 的推荐器设计的个性化排名损失，并且它通过解决硬否定问题来提高排名和加快收敛速度​​。我们还证明它在理论上与直接偏好优化有关，这表明它有可能通过生成建模在基于 DM 的推荐器中调整用户偏好。在三个基准上进行的大量实验验证了其卓越的推荐性能和值得称赞的一般顺序推荐能力。我们的代码可在 \url{https://github.com/lswhim/PreferDiff} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.13117</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transformers4NewsRec：基于 Transformer 的新闻推荐框架</title>
      <link>https://arxiv.org/abs/2410.13125</link>
      <description><![CDATA[arXiv:2410.13125v1 公告类型：新
摘要：预训练的 Transformer 模型在各种自然语言处理任务中都表现出巨大的潜力，包括个性化新闻推荐。为了充分利用这些模型的强大功能，我们引入了 Transformers4NewsRec，这是一个基于 \textbf{Transformers} 库构建的新 Python 框架。该框架旨在统一和比较各种新闻推荐模型的性能，包括深度神经网络和基于图的模型。Transformers4NewsRec 在模型选择、数据预处理和评估方面提供了灵活性，允许进行定量和定性分析。]]></description>
      <guid>https://arxiv.org/abs/2410.13125</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>星巴克：改进 2D Matryoshka 嵌入训练</title>
      <link>https://arxiv.org/abs/2410.13230</link>
      <description><![CDATA[arXiv:2410.13230v1 公告类型：新
摘要：可以扩展嵌入模型深度（即层）和嵌入大小的有效方法允许创建跨不同计算资源和任务要求高度可扩展的模型。虽然最近提出的 2D Matryoshka 训练方法可以有效地生成单个嵌入模型，使得其子层和子维度可以测量文本相似性，但其有效性明显低于单独训练较小模型。为了解决这个问题，我们提出了星巴克，一种针对 Matryoshka 式嵌入模型的新训练策略，它涵盖了微调和预训练阶段。对于微调阶段，我们发现，与在每个训练步骤中随机采样一个子层和子维度相比，提供一个固定的层维度对列表（从小到大），并计算所有对的损失，可以显著提高 2D Matryoshka 嵌入模型的有效性，使其与单独训练的模型相媲美。为了进一步提高性能，我们引入了一种新的预训练策略，该策略在预训练期间将掩码自动编码器语言建模应用于子层和子维度，从而为后续嵌入模型的微调提供更强大的支撑。在语义文本相似性和检索基准上的实验结果表明，所提出的预训练和微调策略显著提高了 2D Matryoshka 模型的有效性，使星巴克模型比单独训练的模型更高效、更有效。]]></description>
      <guid>https://arxiv.org/abs/2410.13230</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>情境感知自适应个性化推荐：元混合</title>
      <link>https://arxiv.org/abs/2410.13374</link>
      <description><![CDATA[arXiv:2410.13374v1 公告类型：新
摘要：推荐器广泛用于电子商务系统，减少了信息过载问题。最常见的方法是选择系统用来进行预测的推荐器。然而，用户彼此不同；因此，一刀切的方法似乎不是最优的。在本文中，我们提出了一种元混合推荐器，它使用机器学习来预测最佳算法。这样，每个特定会话和用户都会使用表现最佳的推荐器。此选择取决于收集到的有关用户的上下文和偏好信息。我们使用标准 MovieLens 和 Movie DB 数据集进行离线评估。我们表明，基于所提出的模型，可以预测哪个推荐器将为用户提供最精确的推荐。我们的元混合理论性能在标准化折现增益和均方根误差指标方面比单独的方法高出 20-50%。然而，基于广泛使用的用户存储的标准信息很难获得最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2410.13374</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成并实例化您喜欢的内容：用于顺序推荐的文本引导扩散</title>
      <link>https://arxiv.org/abs/2410.13428</link>
      <description><![CDATA[arXiv:2410.13428v1 公告类型：新
摘要：生成推荐系统的最新进展，特别是在顺序推荐任务领域，已显示出增强对新项目的泛化能力的希望。在这些方法中，基于扩散的生成推荐已成为一种有效的工具，利用其捕获数据分布和生成高质量样本的能力。尽管有效，但仍发现了两个主要挑战：1）缺乏对 oracle 项目数据分布的一致建模；2）难以扩展到历史交互之外的更具信息量的控制信号。这些问题源于 ID 嵌入的非信息性，这需要随机初始化并限制了其他控制信号的合并。为了解决这些限制，我们提出了 iDreamRe } 来涉及更具体的先验知识来建立项目嵌入，特别是通过详细的项目文本描述和高级文本嵌入模型 (TEM)。更重要的是，通过将项目描述转换为与 TEM 对齐的嵌入，我们能够将意图指令集成为控制信号来指导 oracle 项目的生成。在四个数据集上的实验结果表明，iDreamRec 不仅优于现有的基于扩散的生成式推荐器，而且还有助于整合意图指令，从而更精确、有效地生成推荐。]]></description>
      <guid>https://arxiv.org/abs/2410.13428</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过神经过程进行跨领域顺序推荐</title>
      <link>https://arxiv.org/abs/2410.13588</link>
      <description><![CDATA[arXiv:2410.13588v1 公告类型：新
摘要：跨域顺序推荐（CDSR）是基于序列的用户兴趣建模的热门话题，旨在利用单一模型预测不同域的下一个项目。为了解决 CDSR，许多方法都集中在领域重叠用户的行为拟合上，这严重依赖于同一用户的不同域项目序列协作信号来捕捉跨域项目-项目相关性的协同作用。事实上，这些重叠用户只占整个用户集的一小部分，这引入了一个强有力的假设，即一小群领域重叠用户足以代表所有领域用户的行为特征。然而，直观地说，这样的建议是有偏见的，非重叠用户的学习范式不足将不可避免地限制模型性能。此外，在 CDSR 中对非重叠用户行为进行建模并非易事，因为没有其他域行为可以协作，这导致观察到的单域用户行为序列很难为跨域知识挖掘做出贡献。考虑到这种现象，我们提出了一个具有挑战性且尚未探索的问题：如何释放非重叠用户行为的潜力来赋能 CDSR？]]></description>
      <guid>https://arxiv.org/abs/2410.13588</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为叙述驱动的推荐系统</title>
      <link>https://arxiv.org/abs/2410.13604</link>
      <description><![CDATA[arXiv:2410.13604v1 公告类型：新
摘要：叙事驱动的推荐器旨在为以自由格式文本表达的用户请求提供个性化建议，例如“我想看一部具有令人费解的故事的惊悚片，比如《禁闭岛》。尽管大型语言模型 (LLM) 已被证明在处理一般自然语言查询方面表现出色，但它们处理此类推荐请求的有效性仍相对未被探索。为了缩小这一差距，我们在电影推荐设置中比较了 38 个不同大小的开源和闭源 LLM（例如 LLama 3.2 和 GPT-4o）的性能。为此，我们利用来自 reddit 电影推荐社区的黄金标准、众包注释的帖子数据集，并采用各种提示策略，包括零样本、身份和少量样本提示。我们的研究结果表明 LLM 能够生成与上下文相关的电影推荐，其表现明显优于其他最先进的方法，例如 doc2vec。虽然我们发现闭源和大参数化模型通常表现最佳，但中型开源模型仍然具有竞争力，仅略胜于计算成本更高的同类模型。此外，我们观察到大多数模型的提示策略之间没有显着差异，这凸显了简单方法（例如零样本提示）对叙述驱动推荐的有效性。总体而言，这项工作为推荐系统研究人员以及旨在将 LLM 集成到现实世界推荐工具中的从业者提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.13604</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>悲观评价</title>
      <link>https://arxiv.org/abs/2410.13680</link>
      <description><![CDATA[arXiv:2410.13680v1 公告类型：新
摘要：信息访问系统的传统评估主要关注一组信息需求（信息检索）或用户（推荐系统）的平均效用。在这项工作中，我们认为仅使用平均度量测量进行评估会假设功利主义价值观与基于平等访问的信息访问传统不一致。我们主张对信息访问系统进行悲观评估，重点关注最坏情况的效用。这些方法 (a) 以道德和务实的概念为基础，(b) 在理论上补充现有的稳健性和公平性方法，(c) 在一组检索和推荐任务中得到实证验证。这些结果表明，悲观评估应该纳入现有的实验过程中，以更好地理解系统的行为，尤其是在涉及社会公益原则时。]]></description>
      <guid>https://arxiv.org/abs/2410.13680</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用定制数据上的变换器模型预测推文的地理位置</title>
      <link>https://arxiv.org/abs/2303.07865</link>
      <description><![CDATA[arXiv:2303.07865v5 公告类型：交叉 
摘要：本研究旨在解决推文/用户地理位置预测任务，并为文本大数据的地理标记提供灵活的方法。建议的方法实现了用于自然语言处理 (NLP) 的神经网络，以将位置估计为坐标对（经度、纬度）和二维高斯混合模型 (GMM)。所提出的模型的范围已在 Twitter 数据集上进行了微调，使用预训练的 Transformers 双向编码器表示 (BERT) 作为基础模型。性能指标显示，对于在推文内容和元数据上下文的文本特征上训练和评估的模型，全球范围内的中位误差小于 30 公里，美国级数据集上的中位误差小于 15 公里。我们的源代码和数据可在 https://github.com/K4TEL/geo-twitter.git 上找到]]></description>
      <guid>https://arxiv.org/abs/2303.07865</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成 (RAG) 的全面概述：演变、现状和未来方向</title>
      <link>https://arxiv.org/abs/2410.12837</link>
      <description><![CDATA[arXiv:2410.12837v1 公告类型：交叉 
摘要：本文对检索增强生成 (RAG) 进行了全面的研究，追溯了其从基础概念到当前最先进的发展历程。RAG 将检索机制与生成语言模型相结合，以提高输出的准确性，解决 LLM 的关键限制。该研究探讨了 RAG 的基本架构，重点研究了如何集成检索和生成来处理知识密集型任务。本文详细回顾了 RAG 的重大技术进步，包括检索增强语言模型的关键创新以及在问答、总结和基于知识的任务等各个领域的应用。本文讨论了最近的研究突破，重点介绍了提高检索效率的新方法。此外，本文还研究了部署中的可扩展性、偏见和道德问题等持续存在的挑战。提出了未来的研究方向，重点是提高 RAG 模型的稳健性、扩大 RAG 模型的应用范围以及解决社会影响。本调查旨在为研究人员和从业者提供基础资源，帮助他们了解 RAG 的潜力及其在自然语言处理中的发展轨迹。]]></description>
      <guid>https://arxiv.org/abs/2410.12837</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过内循环查询机制增强 LLM 中的长上下文性能</title>
      <link>https://arxiv.org/abs/2410.12859</link>
      <description><![CDATA[arXiv:2410.12859v1 公告类型：交叉 
摘要：Transformers 的计算复杂度随输入大小呈二次方增长，这限制了大型语言模型 (LLM) 在训练和推理中的输入上下文窗口大小。同时，基于检索增强生成 (RAG) 的模型可以通过使用检索系统过滤掉不必要的信息，从而更好地处理较长的上下文。然而，大多数 RAG 方法仅根据初始查询执行检索，这可能不适用于需要更深层次推理的复杂问题。我们引入了一种新方法，即内循环记忆增强树检索 (ILM-TR)，它涉及内循环查询，不仅基于查询问题本身，还基于中间发现。在推理时，我们的模型从 RAG 系统中检索信息，集成来自不同抽象级别的长文档的数据。根据检索到的信息，LLM 会生成存储在名为短期记忆 (STM) 的区域中文本，然后使用该文本来制定下一个查询。此检索过程会重复进行，直到 STM 中的文本收敛。我们的实验表明，使用 STM 进行检索比传统的检索增强型 LLM 有改进，特别是在多针大海捞针 (M-NIAH) 和 BABILong 等长上下文测试中。]]></description>
      <guid>https://arxiv.org/abs/2410.12859</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>