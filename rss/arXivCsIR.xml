<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 16 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用上下文相似性进行判决引证检索</title>
      <link>https://arxiv.org/abs/2406.01609</link>
      <description><![CDATA[arXiv:2406.01609v2 公告类型：替换 
摘要：传统上，在法律研究领域，从复杂的案例描述中检索相关引文需要手动操作和基于关键字的搜索应用程序，这些应用程序要求具备理解法律术语的专业知识。法律案例描述为法律专业人士和研究人员提供了关键信息，因此需要更高效和自动化的方法。我们提出了一种结合自然语言处理 (NLP) 和机器学习技术来增强法律案例描述的组织和利用的方法。这种方法围绕借助最先进的嵌入模型创建文本嵌入展开。我们的方法解决了两个主要目标：无监督聚类和监督引文检索，两者都旨在自动化引文提取过程。虽然提出的方法可以用于任何数据集，但我们采用了美国最高法院 (SCOTUS) 数据集，取得了显着的成果。我们的方法实现了令人印象深刻的 90.9% 的准确率。通过自动化劳动密集型流程，我们为法律研究更高效、更省时、更易于访问的环境铺平了道路，使法律专业人士、学者和研究人员受益。]]></description>
      <guid>https://arxiv.org/abs/2406.01609</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>从预训练的 Transformer 模型中提取句子嵌入</title>
      <link>https://arxiv.org/abs/2408.08073</link>
      <description><![CDATA[arXiv:2408.08073v1 公告类型：交叉 
摘要：背景/介绍：预训练的 Transformer 模型在许多自然语言处理任务中大放异彩，因此有望承担输入句子或文本含义的表示。这些句子级嵌入在检索增强生成中也很重要。但常用的普通平均或提示模板是否足以显示它？
方法：给定 110M 参数 BERT 的隐藏表示来自多个层和多个标记，我们尝试了各种方法来提取最佳句子表示。我们测试了各种标记聚合和表示后处理技术。我们还测试了使用通用 Wikitext 数据集来补充 BERT 句子表示的多种方法。所有方法都在 8 个语义文本相似度 (STS)、6 个短文本聚类和 12 个分类任务上进行了测试。我们还在其他静态模型（包括随机标记表示）上评估了我们的表示塑造技术。
结果：提出的表示提取方法提高了所有考虑的模型在 STS 和聚类任务上的性能。对于基于静态 token 的模型，尤其是 STS 任务的随机嵌入，取得了非常大的改进，几乎达到了 BERT 衍生表示的性能。
结论：我们的工作表明，对于多项任务，采用表示塑造技术的简单基线可以达到甚至超越更复杂的基于 BERT 的模型，或者能够提高其性能。]]></description>
      <guid>https://arxiv.org/abs/2408.08073</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>KGV：将大型语言模型与知识图谱相结合，用于网络威胁情报可信度评估</title>
      <link>https://arxiv.org/abs/2408.08088</link>
      <description><![CDATA[arXiv:2408.08088v1 公告类型：交叉 
摘要：网络威胁情报是许多组织和个人用来保护自己免受复杂、有组织、持续和武器化的网络攻击的重要工具。然而，很少有研究关注情报平台提供的威胁情报的质量评估，这项工作仍然需要网络安全专家的人工分析。在本文中，我们提出了一种基于知识图谱的验证器，这是一种结合知识图谱和大型语言模型（LLM）的新型网络威胁情报（CTI）质量评估框架。我们的方法引入了LLM来自动提取需要验证的OSCTI关键声明，并利用由段落组成的知识图谱进行事实核查。该方法不同于传统的以实体为节点构建复杂知识图谱的方法。通过构建以段落为节点、以语义相似度为边的知识图谱，有效地增强了模型的语义理解能力，简化了标注要求。此外，为了填补该研究领域的空白，我们创建并公开了第一个异构源威胁情报评估数据集。据我们所知，这项工作是第一个创建威胁情报可靠性验证数据集的工作，为未来的研究提供了参考。实验结果表明，KGV（知识图谱验证器）显著提高了LLM在情报质量评估中的性能。与传统方法相比，我们减少了大量的数据标注，同时模型仍然表现出强大的推理能力。最终，我们的方法可以在网络威胁评估中达到XXX级的准确率。]]></description>
      <guid>https://arxiv.org/abs/2408.08088</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>Nah Bandit：在推荐系统中对用户不合规行为进行建模</title>
      <link>https://arxiv.org/abs/2408.07897</link>
      <description><![CDATA[arXiv:2408.07897v1 公告类型：交叉 
摘要：推荐系统现在遍布数字世界，从广告到娱乐。然而，在物理世界中实施有效的推荐系统仍然具有挑战性，例如在移动或健康领域。这项工作重点关注一个关键挑战：在物理世界中，如果用户不喜欢任何推荐，她通常很容易选择不接受这些推荐，并回到她的基线行为。因此，在网络物理推荐系统中，使用了解此类用户行为的交互模型至关重要，否则用户会完全放弃推荐。因此，本文介绍了 Nah Bandit，这是一个半开玩笑的参考，描述了一个 Bandit 问题，用户可以对推荐说“不”，而选择他们喜欢的选项。因此，这个问题介于典型的 bandit 设置和监督学习之间。我们通过参数化推荐对用户的锚定效应来模拟用户的不服从行为。然后，我们提出了专家聚类 (EWC) 算法，这是一种分层方法，结合了推荐和非推荐选项的反馈，以加速用户偏好学习。在具有 $N$ 个用户、每个用户 $T$ 轮和 $K$ 个聚类的推荐场景中，EWC 实现了 $O(N\sqrt{T\log K} + NT)$ 的遗憾界限，与 LinUCB 算法相比，在短期内实现了卓越的理论性能。实验结果还强调，EWC 优于监督学习和传统的上下文强盗方法。这一进步表明，有效利用不合规反馈可以加速偏好学习并提高推荐准确性。这项工作为 Nah Bandit 的未来研究奠定了基础，为更有效的推荐系统提供了一个强大的框架。]]></description>
      <guid>https://arxiv.org/abs/2408.07897</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>基于强化学习的序列推荐的有效连续控制视角</title>
      <link>https://arxiv.org/abs/2408.08047</link>
      <description><![CDATA[arXiv:2408.08047v1 公告类型：交叉 
摘要：顺序推荐是推荐系统 (RS) 中的一项关键任务，其中用户偏好是从顺序历史行为中动态推断出来的。为了进一步优化长期用户参与度，基于离线强化学习的 RS 已成为主流技术，因为它们在避免可能损害在线用户体验的全局探索方面提供了额外的优势。然而，以前的研究主要集中在离散动作和策略空间上，这可能难以有效处理急剧增长的项目。
为了缓解这个问题，在本文中，我们旨在设计一个适用于连续策略的算法框架。为了便于在低维但密集的用户偏好空间中进行控制，我们提出了一个 \underline{\textbf{E}} 高效的 \underline{\textbf{Co}} 连续 \underline{\textbf{C}} 控制框架 (ECoC)。基于统计测试的假设，我们首先提出了从规范化的用户和项目空间中抽象出来的新型统一动作表示。然后，我们制定相应的策略评估和策略改进程序。在此过程中，统一行动方面的战略探索和方向控制经过精心设计，对最终的推荐决策至关重要。此外，得益于统一行动，策略和价值函数的保守性正则化得以结合，并与连续框架完美兼容。由此产生的双重正则化确保了基于RL的推荐策略的成功离线训练。最后，我们进行了大量实验来验证我们框架的有效性。结果表明，与离散基线相比，我们的ECoC训练效率更高。同时，最终策略在捕获离线数据和获得长期奖励方面均优于基线。]]></description>
      <guid>https://arxiv.org/abs/2408.08047</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>LLM4DSR：利用大型语言模型对序列推荐进行去噪</title>
      <link>https://arxiv.org/abs/2408.08208</link>
      <description><![CDATA[arXiv:2408.08208v1 公告类型：新
摘要：顺序推荐系统从根本上依赖于用户的历史交互序列，而这些序列通常会受到噪声交互的污染。由于缺乏明确的监督信号来表示噪声，在没有额外信息的情况下准确识别这些噪声交互尤其困难。大型语言模型 (LLM) 配备了广泛的开放知识和语义推理能力，为弥补这一信息差距提供了一种有希望的途径。然而，在顺序推荐中使用 LLM 进行去噪会带来显着的挑战：1) 直接应用预训练的 LLM 可能无法胜任去噪任务，经常会产生无意义的响应；2) 即使经过微调，LLM 输出的可靠性仍然存在疑问，尤其是考虑到任务的复杂性和 LLM 固有的幻觉问题。
为了应对这些挑战，我们提出了 LLM4DSR，这是一种使用 LLM 进行顺序推荐去噪的定制方法。我们构建了一个自监督微调任务，以激活 LLM 识别噪声项目并建议替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度响应进行序列校正。值得注意的是，LLM4DSR 与模型无关，允许将校正后的序列灵活应用于各种推荐模型。大量实验验证了 LLM4DSR 在三个数据集和三个推荐主干上优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2408.08208</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>跨域序列推荐的域和反馈转换建模</title>
      <link>https://arxiv.org/abs/2408.08209</link>
      <description><![CDATA[arXiv:2408.08209v1 公告类型：新
摘要：如今，许多推荐系统涵盖各个领域以满足用户的不同需求，从而导致用户行为在不同领域之间转变。事实上，用户在不同领域的行为揭示了对推荐项目的偏好变化。例如，从负面反馈到正面反馈的转变表明用户满意度提高。然而，现有的跨域顺序推荐方法通常仅通过关注域转换信息来建模用户兴趣，往往忽略了用户反馈转换提供的宝贵见解。在本文中，我们提出了$\text{Transition}^2$，一种跨域和用户反馈类型建模转换的新方法。具体而言，$\text{Transition}^2$引入了一种基于用户历史的转换感知图编码器，根据反馈类型为边分配不同的权重。这使得图编码器能够提取捕获不同域和反馈类型之间转换信息的历史嵌入。随后，我们使用跨转换多头自注意力对用户历史记录进行编码，并结合各种掩码来区分不同类型的转换。最后，我们整合这些模块以跨不同领域进行预测。在两个公共数据集上的实验结果证明了 $\text{Transition}^2$ 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.08209</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>DaRec：用于大型语言模型和推荐系统的解缠对齐框架</title>
      <link>https://arxiv.org/abs/2408.08231</link>
      <description><![CDATA[arXiv:2408.08231v1 公告类型：新
摘要：得益于强大的推理能力，大型语言模型 (LLM) 在推荐系统中表现出色。人们已经做出了各种努力来从 LLM 中提取知识以增强协作模型，并使用对比学习等技术进行表示对齐。在这项工作中，我们根据信息定理证明直接对齐 LLM 和协作模型的表示对于提高下游推荐任务的性能并不是最优的。因此，有效地对齐协作模型和 LLM 之间的语义表示的挑战仍然没有解决。受此观点的启发，我们为 LLM 和协作模型提出了一种新颖的即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化将 LLM 和协作模型的潜在表示分解为特定和共享的组件。随后，我们对共享表示执行全局和局部结构对齐，以促进知识转移。此外，我们从理论上证明了特定和共享表示包含更多相关信息和更少无关信息，这可以提高下游推荐任务的有效性。在基准数据集上的大量实验结果表明，我们的方法优于现有的最先进算法。]]></description>
      <guid>https://arxiv.org/abs/2408.08231</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>从点击到碳：推荐系统对环境的影响</title>
      <link>https://arxiv.org/abs/2408.08203</link>
      <description><![CDATA[arXiv:2408.08203v1 公告类型：新
摘要：随着全球变暖的加剧，评估研究对环境的影响现在比以往任何时候都更加重要。然而，我们发现很少有推荐系统研究论文记录它们对环境的影响。因此，在本文中，我们通过重现一个典型的推荐系统实验流程，对推荐系统研究对环境的影响进行了全面的分析。我们专注于估计推荐系统研究论文的碳足迹，强调推荐系统研究实验对环境影响随时间的变化。我们彻底评估了 2013 年和 2023 年 ACM RecSys 会议的所有 79 篇完整论文，以分析分别使用传统的、所谓的老式 AI 算法和深度学习算法的论文的代表性实验流程。我们重现了这些代表性的实验流程，使用硬件能量计测量了电力消耗，并将测量的能耗转换为二氧化碳当量以估计环境影响。我们的结果表明，使用深度学习算法的推荐系统研究论文产生的二氧化碳当量大约是使用传统算法的论文的 42 倍。此外，平均而言，这样的论文产生的二氧化碳当量为 3,297 公斤，这比一个人从纽约市飞往墨尔本产生的二氧化碳或一棵树在 300 年内吸收的二氧化碳还要多。]]></description>
      <guid>https://arxiv.org/abs/2408.08203</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:33 GMT</pubDate>
    </item>
    <item>
      <title>AIE：在线广告 CTR 预测的拍卖信息增强框架</title>
      <link>https://arxiv.org/abs/2408.07907</link>
      <description><![CDATA[arXiv:2408.07907v1 公告类型：新 
摘要：点击率（CTR）预测是在线广告推荐的基本技术，复杂的在线竞争拍卖过程也给CTR优化带来了许多困难。最近的研究表明，引入后验拍卖信息有助于提高CTR预测的性能。然而，现有的工作并没有充分利用拍卖信息的好处，忽视了拍卖带来的数据偏差，导致结果有偏差且不理想。为了解决这些限制，我们提出了用于在线广告CTR预测的拍卖信息增强框架（AIE），深入研究了拍卖信号利用不足的问题并首次揭示了拍卖偏差。具体来说，AIE引入了两个可插拔模块，即自适应市场价格辅助模块（AM2）和出价校准模块（BCM），它们协同工作以更好地挖掘后验拍卖信号并提高CTR预测的性能。此外，提出的两个模块轻量级、与模型无关，并且对推理延迟友好。在公共数据集和工业数据集上进行了广泛的实验，以证明 AIE 的有效性和兼容性。此外，在大型广告平台进行的为期一个月的在线 A/B 测试表明，AIE 在 eCPM 和 CTR 方面分别比基础模型提高了 5.76% 和 2.44%。]]></description>
      <guid>https://arxiv.org/abs/2408.07907</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:32 GMT</pubDate>
    </item>
    <item>
      <title>曼巴猎犬：利用曼巴进行有效且高效的密集检索</title>
      <link>https://arxiv.org/abs/2408.08066</link>
      <description><![CDATA[arXiv:2408.08066v1 公告类型：新 
摘要：在信息检索 (IR) 领域，密集检索 (DR) 模型使用深度学习技术将查询和段落编码到嵌入空间中以计算它们的语义关系。对于 DR 模型来说，平衡效率和有效性非常重要。预训练语言模型 (PLM)，尤其是基于 Transformer 的 PLM，已被证明是 DR 模型的有效编码器。然而，基于 Transformer 的 PLM 中的自注意力组件导致计算复杂度随序列长度二次增长，因此在长文本检索中表现出较慢的推理速度。一些最近提出的非 Transformer PLM，尤其是 Mamba 架构 PLM，不仅在生成语言任务上表现出与基于 Transformer 的 PLM 相当的有效性，而且由于序列长度的线性时间缩放而具有更好的效率。本文实现了 Mamba Retriever，以探索 Mamba 是否可以作为 IR 任务的 DR 模型的有效编码器。我们在经典的短文本 MS MARCO 段落排名数据集和长文本 LoCoV0 数据集上对 Mamba Retriever 进行了微调。实验结果表明：（1）在 MS MARCO 段落排名数据集和 BEIR 上，Mamba Retriever 与基于 Transformer 的检索模型相比具有相当或更好的效果，并且效果随着 Mamba 模型的规模而增长；（2）在长文本 LoCoV0 数据集上，Mamba Retriever 在检索任务上进行微调后可以扩展到比其预训练长度更长的文本长度，并且与其他长文本检索模型相比具有相当或更好的效果；（3）Mamba Retriever 对长文本检索具有出色的推理速度。总之，Mamba Retriever 既有效又高效，是一个实用的模型，尤其是对于长文本检索。]]></description>
      <guid>https://arxiv.org/abs/2408.08066</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:32 GMT</pubDate>
    </item>
    <item>
      <title>相似度测量指南</title>
      <link>https://arxiv.org/abs/2408.07706</link>
      <description><![CDATA[arXiv:2408.07706v1 公告类型：新
摘要：相似性度量在各种数据科学应用领域中发挥着重要作用，可用于各种任务。本指南介绍了一套全面的流行相似性度量，可供非专家和专业人士使用。希望了解度量动机及其使用方法的非专家可能会找到对度量公式的友好而详细的说明，而专家可能会发现设计相似性度量的原理和想法，以便在给定的应用领域中更好地测量所需任务的相似性。]]></description>
      <guid>https://arxiv.org/abs/2408.07706</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:31 GMT</pubDate>
    </item>
    <item>
      <title>SWaT：通过用户行为分析对视频观看时间进行统计建模</title>
      <link>https://arxiv.org/abs/2408.07759</link>
      <description><![CDATA[arXiv:2408.07759v1 公告类型：新 
摘要：随着（短）视频推荐的重要性日益提高，估计视频观看时间的重要性日益凸显，视频推荐已成为主流社交媒体平台的核心产品。然而，视频观看时间建模受到用户与视频交互复杂性的挑战，例如用户在观看推荐视频时的行为模式不同，以及在视频范围内观看概率不同。尽管重要性和挑战性，但现有的关于视频观看时间建模的文献大多侧重于相对黑盒的机械增强经典的回归/分类损失，而没有以原则性的方式考虑用户行为。在本文中，我们首次以用户为中心的视角对视频观看时间进行建模，由此我们提出了一个白盒统计框架，将观看（短）视频的各种用户行为假设直接转化为统计观看时间模型。这些行为假设由我们对用户观看视频行为模式的领域知识来描述。我们进一步采用了分桶技术来应对用户在视频范围内的非平稳观看概率，这还有助于尊重视频长度的限制，并促进观看时间的连续回归事件与其他二元分类事件之间的实际兼容性。我们在两个公共数据集、一个大规模离线工业数据集和一个拥有数亿日活跃用户的短视频平台上的在线 A/B 测试上对我们的模型进行了广泛的测试。在所有实验中，我们的模型与强相关基线相比都具有竞争力，证明了我们以用户为中心的视角和提出的框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.07759</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:31 GMT</pubDate>
    </item>
    <item>
      <title>通过内容推荐进行数字人际情绪调节的共情反应</title>
      <link>https://arxiv.org/abs/2408.07704</link>
      <description><![CDATA[arXiv:2408.07704v1 公告类型：新
摘要：人际沟通在管理人们的情绪方面起着关键作用，尤其是在数字平台上。研究表明，人们使用社交媒体和消费在线内容来调节情绪并寻求休息和恢复的支持。然而，这些平台并不是为情绪调节而设计的，这限制了它们在这方面的有效性。为了解决这个问题，我们提出了一种通过内容推荐来增强在线平台上人际情绪调节 (IER) 的方法。目标是通过制作符合 IER 策略（尤其是同理心响应）的媒体内容，使用户能够在主动或被动参与在线平台时调节自己的情绪。所提出的推荐系统有望融合系统发起和用户发起的情绪调节，为数字媒体平台上的实时 IER 实践铺平道路。为了评估这种方法的有效性，采用了混合方法研究设计，包括基于文本的社交媒体数据的分析和用户调查。鉴于数字媒体应用在数字情绪调节 (DER) 方面的广泛认可，数字应用在这一过程中发挥了促进作用。该研究在一年内收集了 Reddit 上的 37.5K 个用户帖子和互动实例，以使用来自用户活动和偏好的特征设计基于上下文多臂老虎机 (CMAB) 的推荐系统。实验表明，与广泛接受的 ER 策略（例如分散注意力和回避）相比，用户更喜欢由所提出的推荐系统生成的共情推荐。]]></description>
      <guid>https://arxiv.org/abs/2408.07704</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:30 GMT</pubDate>
    </item>
    <item>
      <title>利用知识图谱和大型语言模型增强供应链可视性</title>
      <link>https://arxiv.org/abs/2408.07705</link>
      <description><![CDATA[arXiv:2408.07705v1 公告类型：新
摘要：在当今的全球化经济中，全面的供应链可视性对于有效的风险管理至关重要。由于供应链合作伙伴之间的信息共享有限，实现可视性仍然是一项重大挑战。本文提出了一个新颖的框架，利用知识图谱 (KG) 和大型语言模型 (LLM) 来增强供应链可视性，而无需依赖直接利益相关者的信息共享。我们的零样本、LLM 驱动方法可以自动从各种公共来源提取供应链信息，并构建 KG 来捕获供应链实体之间复杂的相互依赖关系。我们对命名实体识别 (NER) 和关系提取 (RE) 任务采用零样本提示，从而无需进行大量特定领域的培训。我们通过电动汽车供应链案例研究验证了该框架，重点是跟踪电池制造的关键矿物。结果显示供应链映射有了显着改善，将可视性扩展到二级供应商之外。该框架揭示了关键依赖关系和替代采购选项，增强了风险管理和战略规划。它在 NER 和 RE 任务中具有很高的准确率，为理解复杂的多层供应网络提供了有效的工具。这项研究提供了一种可扩展、灵活的方法来构建特定领域的供应链知识图谱，解决了可见性方面的长期挑战，并为数字供应链监控的进步铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2408.07705</guid>
      <pubDate>Fri, 16 Aug 2024 06:20:30 GMT</pubDate>
    </item>
    </channel>
</rss>