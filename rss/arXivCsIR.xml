<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 10 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>惊叹：可解释的跨模式代理系统，用于通过分层检索检测错误信息检测</title>
      <link>https://arxiv.org/abs/2504.06269</link>
      <description><![CDATA[ARXIV：2504.06269V1公告类型：新 
摘要：错误信息继续在当今信息生态系统中构成重大挑战，从而深刻塑造了公众的看法和行为。在其各种表现形式中，脱节（OOC）的错误信息特别晦涩，因为它通过将真实的图像与误导性的文本叙述配对而扭曲了含义。检测OOC错误信息的现有方法主要依赖于图像文本对之间的粗粒度相似性指标，这些指标通常无法捕获细微的不一致或提供有意义的解释性。虽然多模式的大语言模型（MLLM）在视觉推理和解释生成中表现出显着的功能，但它们尚未证明能够解决稳健OOC检测所需的复杂，细粒度和跨模式区别。为了克服这些局限性，我们引入了Amair，这是一个基于检索的框架，旨在通过多模式事件和实体的多范围索引来利用外部知识。我们的方法将多范围的上下文分析与多代理推理体系结构集成在一起，以系统地评估多模式新闻内容的一致性和完整性。全面的实验验证了惊叹的有效性和韧性，证明了其与最先进的方法相比，准确性高4.3％，同时提供可解释且可操作的见解能力。]]></description>
      <guid>https://arxiv.org/abs/2504.06269</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有监督的扩散建模来解决点击率预测中的冷启动问题</title>
      <link>https://arxiv.org/abs/2504.06270</link>
      <description><![CDATA[ARXIV：2504.06270V1公告类型：新 
摘要：预测点击率是建议和广告平台中的关键功能，因为CTR预测的输出确定了向用户显示的项目的顺序。嵌入\＆MLP范式已成为工业推荐系统的标准方法，并已被广泛部署。但是，这种范式遇到了冷启动的问题，那里没有或仅有有限的用户操作数据，导致学习不良的ID嵌入。冷启动的问题阻碍了新项目的性能。为了解决这个问题，我们设计了一种新颖的扩散模型，以生成对新项目的热烈嵌入。具体而言，我们定义了ID嵌入空间和侧面信息空间之间的新扩散过程。此外，鉴于我们的扩散模型是非马克维亚人，我们可以从扩散步骤中得出一个子序列。我们的扩散模型均由变异推理和二进制跨透明镜目标进行监督，从而使其能够在冷启动和热身阶段中为项目生成热身的嵌入。此外，我们对三个建议数据集进行了广泛的实验。结果证实了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.06270</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ER-rag：通过基于ER的异质数据源的统一建模来增强抹布</title>
      <link>https://arxiv.org/abs/2504.06271</link>
      <description><![CDATA[ARXIV：2504.06271V1公告类型：新 
摘要：大型语言模型（LLMS）在提问（QA）任务中表现出色，并且检索效果生成（RAG）通过合并来自网页，数据库和知识图的各种来源的外部证据，从而提高了其精度。但是，当前的抹布方法依赖于针对单个数据源的特定特定策略，提出了低资源或黑盒环境的挑战，并在跨来源分散的证据时使操作变得复杂。为了解决这些局限性，我们提出了ER-rag，该框架可以使用实体关系（ER）模型统一跨异构数据源的证据集成。 ER-rag通过基于ER的API和加入操作标准化实体检索和关系查询。它采用了两个阶段的生成过程：首先，偏好优化模块选择最佳来源；其次，另一个模块基于源模式构建API链。这种统一的方法允许在各种数据源之间进行有效的微调和无缝集成。 ER-Rag通过赢得2024 KDDCUP CRAG挑战的所有三首曲目，证明了其有效性，并使用8B LLM骨干线在商业抹布管道上取得了表现。它的表现优于Hybrid竞争对手的LLM得分3.1％，并将检索加速5.5倍。]]></description>
      <guid>https://arxiv.org/abs/2504.06271</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Raven：大规模视频收集的多模式实体发现的代理框架</title>
      <link>https://arxiv.org/abs/2504.06272</link>
      <description><![CDATA[ARXIV：2504.06272V1公告类型：新 
摘要：我们为Raven提供了一个自适应AI代理框架，专为多模式实体发现和大规模视频收集中的检索而设计。 Raven自动处理视频数据，以生成有关下游任务的结构化，可操作的表示形式，将信息综合的信息综合。关键贡献包括（1）一个类别理解的步骤来推断视频主题和通用实体，（2）动态定义特定领域特定的内脏和属性的模式生成机制，以及（3）利用语义检索和架构引导的提示的丰富的实体提取过程。 Raven被设计为模型不合时宜，允许基于应用程序特定要求的不同视觉语言模型（VLM）和大型语言模型（LLMS）集成。这种灵活性支持个性化搜索，内容发现和可扩展信息检索中的各种应用程序，从而在大量数据集中实现了实用应用程序。]]></description>
      <guid>https://arxiv.org/abs/2504.06272</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有专家知识的多样化和有效的基于检索的收债系统</title>
      <link>https://arxiv.org/abs/2504.06273</link>
      <description><![CDATA[ARXIV：2504.06273V1公告类型：新 
摘要：设计有效的债务收集系统对于提高运营效率和降低金融行业的成本至关重要。但是，维持脚本多样性，上下文相关性和连贯性的挑战使这项任务特别困难。本文根据主要商业银行的实际债务人收集器数据提供了一种债务收集系统。我们从现实世界中收集对话中构建脚本库，并为上下文相关性提出了一个基于两阶段检索的响应系统。实验结果表明，我们的系统改善了脚本多样性，增强了响应相关性，并通过知识蒸馏实现了实用的部署效率。这项工作提供了可扩展和自动化的解决方案，为在现实世界应用程序中推进收债实践提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2504.06273</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合小组分析和推荐通过基于Deep Never Network的多任务学习</title>
      <link>https://arxiv.org/abs/2504.06274</link>
      <description><![CDATA[ARXIV：2504.06274V1公告类型：新 
摘要：小组推荐系统的目的是生成与小组集体偏好相符的建议，引入与个人建议方案中的挑战显着不同的挑战。本文通过基于Deep Never Network的多任务学习介绍了联合小组分析和建议，该框架统一了单个模型中的小组分析和建议任务。通过共同学习这些任务，该模型对群体动态有了更深入的了解，从而提高了建议准确性。这两个任务之间的共享表示有助于发现两者必不可少的潜在特征，从而导致更丰富，更有信息的组嵌入。为了进一步提高性能，集成了注意机制，以动态评估不同组特征和项目属性的相关性，从而确保模型优先考虑最有影响力的信息。对现实世界数据集的实验和评估表明，我们的多任务学习方法在准确性方面始终超过基线模型，从而验证其有效性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2504.06274</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过音频到文本对齐的多媒体内容的级联体系结构，用于提取多媒体内容</title>
      <link>https://arxiv.org/abs/2504.06275</link>
      <description><![CDATA[ARXIV：2504.06275V1公告类型：新 
摘要：本研究提出了通过音频到文本对齐方式进行多媒体含量提取性汇总的级联体系结构。提出的框架解决了从YouTube视频等多媒体来源中提取关键见解的挑战。它使用Microsoft Azure语音与高级提取性摘要模型（包括Whisper，Pegasus和Facebook Bart Xsum）集成了音频到文本转换。该系统采用pytube，pydub和语音识别等工具，用于内容检索，音频提取和转录。语言分析通过命名的实体识别和语义角色标签得到增强。使用Rouge和F1分数进行评估表明，尽管诸如转录错误之类的挑战，但级联体系结构的表现要优于常规摘要方法。未来的改进可能包括模型微调和实时处理。这项研究通过改善信息检索，可访问性和用户体验来有助于多媒体摘要。]]></description>
      <guid>https://arxiv.org/abs/2504.06275</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将多项选择的提问模型重新利用为重读文档吗？</title>
      <link>https://arxiv.org/abs/2504.06276</link>
      <description><![CDATA[ARXIV：2504.06276V1公告类型：新 
摘要：是的，重新利用用于文档重读的多项选择性提问（MCQA）模型是可行的和有价值的。这项初步工作建立在MCQA决策与跨编码器语义相关性评估之间的数学相似之处，从而导致R*的发展，R*是概念验证模型，统一了这些方法。 R*旨在评估文档的相关性，展示了MCQA的原则如何改善信息检索（IR）和检索功能增强的生成（RAG）系统 - 最终增强AI驱动系统中的搜索和对话。通过实验验证，R*通过证明MCQA的实际原型来提高检索准确性，并通过保持其轻量级来证明MCQA的实际原型。]]></description>
      <guid>https://arxiv.org/abs/2504.06276</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>个性化和值得信赖的代理人的动态评估框架：一种多项式适应性方法</title>
      <link>https://arxiv.org/abs/2504.06277</link>
      <description><![CDATA[ARXIV：2504.06277V1公告类型：新 
摘要：生成AI的最新进展已大大增加了对个性化代理的兴趣。随着个性化的增加，还需要更需要相信这些代理商的决策和采取行动。但是，这些代理的评估方法仍然过时且不足，通常无法捕获用户交互的动态和不断发展的性质。在这篇概念上的文章中，我们主张评估个性化和适应性代理的范式转变。我们提出了一个全面的新颖框架，该框架对用户角色进行了独特的属性和偏好的建模。在此框架中，代理商通过结构化访谈与这些模拟用户进行互动，以收集他们的偏好并提供自定义的建议。然后，使用大型语言模型（LLM）驱动的模拟对这些建议进行动态评估，从而实现自适应和迭代评估过程。我们的灵活框架旨在支持各种代理和应用程序，以确保对专注于积极主动，个性化和值得信赖方面的建议策略进行全面和多功能的评估。]]></description>
      <guid>https://arxiv.org/abs/2504.06277</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散科目：多模式知识图完成的结构感知多模式扩散模型</title>
      <link>https://arxiv.org/abs/2504.06543</link>
      <description><![CDATA[ARXIV：2504.06543V1公告类型：新 
摘要：大多数当前的MKGC方法主要基于最大程度地提高条件可能性的判别模型。这些方法难以有效地捕获现实世界知识图中的复杂联系，从而限制了它们的整体性能。为了解决此问题，我们为多模式知识图完成（扩散Com）提出了一个结构感知的多模式扩散模型。从生成模型的角度来看，扩散性创新地解决了问题，对$（头，关系）$配对和候选尾巴实体之间的关联进行建模，作为其联合概率分布$ p（（（头，关系），（尾巴））$，将MKGC任务作为逐渐从噪声中生成联合可能性分布的过程。此外，为了充分利用MKG中的结构信息，我们提出了一种自适应和结构感知的多模式知识表示方法，作为扩散Com的编码器。结构 -  kggormenter通过多模式图注意网络（MGAT）捕获丰富的结构信息，并将其与实体表示融合，从而增强了这些表示形式的结构意识。该设计有效地解决了现有MKGC方法的局限性，尤其是基于多模式预训练模型的方法，用于利用结构信息。使用发电机的生成和区分损失对扩散Com进行了训练，而特征提取器仅通过判别损失进行优化。这种双重方法允许扩散COM能够利用生成和判别模型的优势。在FB15K-237-IMG和WN18-IMG数据集上进行的广泛实验表明，扩散COM胜过最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2504.06543</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过表检索中的实体桥接查询和表</title>
      <link>https://arxiv.org/abs/2504.06551</link>
      <description><![CDATA[ARXIV：2504.06551V1公告类型：新 
摘要：表检索对于访问以结构化表格格式存储的信息至关重要；但是，它的探索程度不如文本检索。表的内容主要由短语和单词组成，其中包括大量实体，例如时间，位置，人员和组织。实体在文本检索的背景下进行了充分研究，但是对其在表格检索中的应用缺乏研究。在这项工作中，我们探讨了如何利用表中的实体来提高检索性能。首先，我们从统计的角度研究了实体在表中检索的重要作用，并提出了实体增强培训框架。随后，我们使用实体类型来突出显示实体，而不是引入外部知识库。此外，我们设计了基于实体表示的交互范式。我们提出的框架是插件和灵活的，使其易于集成到现有的表猎犬训练过程中。在两个表检索基准（NQ-Tables和OTT-QA）上的经验结果表明，我们提出的框架在增强现有检索器方面既简单有效又有效。我们还进行了广泛的分析以确认不同组件的功效。总体而言，我们的工作为提升桌子检索提供了一个有希望的方向，从而启发了该领域的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2504.06551</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多样性感知的双促销中毒攻击在顺序推荐下</title>
      <link>https://arxiv.org/abs/2504.06586</link>
      <description><![CDATA[ARXIV：2504.06586V1公告类型：新 
摘要：顺序推荐系统（SRSS）在捕获用户的动态兴趣方面表现出色，从而在各种工业应用中发挥关键作用。 SRSS的普及还引发了对其安全方面的新兴研究，其中针对目标项目促销的数据中毒攻击是一个典型的例子。现有的攻击机制主要集中于通过注入精心制作的互动（即中毒序列）来提高推荐列表中目标项目的排名，这是以降级用户的真实偏好为代价的。因此，观察到明显的建议精度下降，从而限制了攻击的隐身性。此外，产生的中毒序列容易重复目标项目重复，这是统一目标的结果，即增加其整体暴露和缺乏有效的多样性正常。这种同质性不仅损害了这些序列的真实性，而且限制了攻击效果，因为它忽略了在SRS中建立依赖顺序依赖性的机会。为了解决概述的问题，我们提出了一种多样性感知的双促销顺序中毒攻击方法，称为SRSS的DDSP。具体而言，通过理论上揭示建议和现有攻击目标之间的冲突，我们设计了一个经过改进的攻击目标，该目标促进了目标项目，同时保持了用户排名列表中首选项目的相关性。我们进一步开发了一种多样性感知的自动回归中毒序列发生器，其中采用了重新排列的方法，可以通过整合多样性约束来依次选择最佳项目。]]></description>
      <guid>https://arxiv.org/abs/2504.06586</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>围绕：个性化的网络尺度搜索预先排名，并具有交互功能</title>
      <link>https://arxiv.org/abs/2504.06609</link>
      <description><![CDATA[ARXIV：2504.06609V1公告类型：新 
摘要：现代搜索系统使用多阶段体系结构有效地提供个性化的结果。关键阶段包括检索，预先排名，完整排名和融合，这些阶段可完善数十亿个项目以最佳选择。预先级别的阶段对于计分和过滤数十万个项目至少至数千个至关重要，尽管通常缺乏捕获复杂的相互作用，但由于其计算效率，通常依赖于两个塔模型。虽然查询项目的交互功能对于全排名至关重要，但将它们集成到前级模型中提出了与效率相关的挑战。在本文中，我们引入了Intertrank，这是一种新型的两塔预级模型，具有Pinterest上使用的稳健交互功能。通过将基于历史用户参与的查询项目相互作用与两个塔点产品一起纳入评分函数，二型货架可显着提高预期性能，并以最小的延迟和计算成本。在Pinterest的现实世界A/B实验中，InterActrank在BM25基线上将在线参与度量指标提高了6.5％，而在香草Two Thik Tower基线上则提高了3.7％。我们还强调了围绕跨界的其他组件，例如实时用户序列建模，并通过离线消融研究分析其贡献。 InterActrank的代码可从https://github.com/pinterest/atg-research/tree/main/main/interactrank获得。]]></description>
      <guid>https://arxiv.org/abs/2504.06609</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>考虑用户好奇心的偶然推荐系统</title>
      <link>https://arxiv.org/abs/2504.06633</link>
      <description><![CDATA[ARXIV：2504.06633V1公告类型：新 
摘要：解决狭窄的建议范围的问题是，强调预测准确性，偶然的建议既引起了有用性又引起了意外性，引起了人们的注意。但是，由于不同用户偏爱的有用性和意外性的比例不同，因此实现偶然的建议是具有挑战性的，这受到其知识的不同愿望的影响。在本文中，我们提出了一种方法，以估计每个用户根据好奇心所希望的有用性和意外性的比例，并提出与此偏好相匹配的建议。提出的方法通过考虑长期和短期利益来估计用户的好奇心。使用Movielens-1M数据集进行了离线实验，以评估所提出方法的有效性。实验结果表明，我们的方法达到了与最先进的方法相同的性能水平，同时成功提供了偶然的建议。]]></description>
      <guid>https://arxiv.org/abs/2504.06633</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BBQREC：多模式顺序推荐的行为结合量化</title>
      <link>https://arxiv.org/abs/2504.06636</link>
      <description><![CDATA[ARXIV：2504.06636V1公告类型：新 
摘要：多模式顺序推荐系统利用辅助信号（例如，文本，图像）来减轻用户项目交互中的数据稀疏性。虽然最近的方法利用大型语言模型将模式编码为自动回归预测的离散语义ID，但我们确定了两个临界局限性：（1）现有方法采用了分散的量化，其中模态被独立地映射到与行为目标差异的语义空间，以及对弱依赖语义的范围的跨越语义的跨性别代码，并在此中删除了跨越型号的跨性别代码，以跨越语义的跨性别代码，以相互构建的互换，互换互换的互换，模式构造的互换，跨越了互换的互换。建模各种用户偏好。
  为了应对这些挑战，我们提出了一个行为绑定的多模式量化，以进行顺序推荐（简短的BBQREC），其中具有双对齐的量化和语义感知的序列建模。首先，我们的行为语义对齐模块通过对比代码簿学习从嘈杂的模态特定特征中解散了模态 - 静态行为模式，从而确保语义ID与推荐任务固有地息息相关。其次，我们设计了一种离散的相似性重新加权机制，该机制使用量化的语义关系动态调整自我注意力分数，保留多模式协同作用，同时避免对序列建模体系结构进行侵入性修改。在四个现实世界基准中进行的广泛评估表明，BBQREC优于最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2504.06636</guid>
      <pubDate>Thu, 10 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>