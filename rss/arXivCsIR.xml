<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Mon, 22 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用自然语言用户配置文件提供透明且可审查的推荐</title>
      <link>https://arxiv.org/abs/2402.05810</link>
      <description><![CDATA[arXiv:2402.05810v2 公告类型：替换 
摘要：最近最先进的推荐系统主要依靠用户的隐式或显式反馈来推荐新项目。虽然在推荐新选项方面很有效，但许多推荐系统通常使用不可解释的嵌入来表示用户偏好。这种缺乏透明度不仅限制了用户对为什么建议某些项目的理解，而且还降低了用户审查和修改其偏好的能力，从而影响他们接收首选推荐列表的能力。鉴于大型语言模型 (LLM) 的最新进展，我们研究如何使用正确制作的提示来总结用户从过去评论中的偏好并仅根据基于语言的偏好推荐项目。特别是，我们研究如何提示 LLM 生成整体描述用户偏好的自然语言 (NL) 用户配置文件。然后可以利用这些 NL 配置文件来微调 LLM，仅使用 NL 配置文件来做出透明且可审查的建议。此外，我们通过调查编辑 NL 用户资料后对推荐变化的影响来验证基于用户资料的推荐系统的可审查性。根据我们对两个基准评级预测数据集上模型评级预测性能的评估，我们观察到这种新方法在热启动设置中保持了与现有推荐系统相当的性能水平。通过对更新用户资料和系统提示的影响进行系统分析，我们展示了我们的方法的优势，即更容易调整用户偏好，并对用户收到的推荐具有更大的自主权。]]></description>
      <guid>https://arxiv.org/abs/2402.05810</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:34 GMT</pubDate>
    </item>
    <item>
      <title>广告和内容推荐系统中的检索算法调查</title>
      <link>https://arxiv.org/abs/2407.01712</link>
      <description><![CDATA[arXiv:2407.01712v2 公告类型：更新 
摘要：本调查研究了广告推荐和内容推荐系统中使用的最有效的检索算法。广告定位算法依靠详细的用户资料和行为数据来提供个性化广告，从而通过有针对性的展示来增加收入。相反，有机检索系统旨在通过推荐符合用户偏好的内容来改善用户体验。本文比较了这两个应用程序，并解释了每个应用程序中使用的最有效的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.01712</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:34 GMT</pubDate>
    </item>
    <item>
      <title>ChatQA 2：弥合与长期背景和 RAG 功能中的专有 LLM 之间的差距</title>
      <link>https://arxiv.org/abs/2407.14482</link>
      <description><![CDATA[arXiv:2407.14482v1 公告类型：交叉 
摘要：在这项工作中，我们引入了 ChatQA 2，这是一个基于 Llama3 的模型，旨在弥合开放获取 LLM 和领先的专有模型（例如 GPT-4-Turbo）在长上下文理解和检索增强生成 (RAG) 能力方面的差距。这两种能力对于 LLM 处理无法容纳在单个提示中的大量信息至关重要，并且相互补充，具体取决于下游任务和计算预算。我们提出了一个详细的持续训练方案，以将 Llama3-70B-base 的上下文窗口从 8K 扩展到 128K 个 token，以及一个三阶段指令调整过程，以增强模型的指令跟踪、RAG 性能和长上下文理解能力。我们的结果表明，Llama3-ChatQA-2-70B 模型在许多长上下文理解任务上实现了与 GPT-4-Turbo-2024-0409 相当的准确率，并在 RAG 基准上超越了它。有趣的是，我们发现最先进的长上下文检索器可以缓解 RAG 中的前 k 个上下文碎片化问题，从而进一步改善基于 RAG 的长上下文理解任务结果。我们还使用最先进的长上下文 LLM 对 RAG 和长上下文解决方案进行了广泛的比较。]]></description>
      <guid>https://arxiv.org/abs/2407.14482</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>可控多样化的顺序推荐：表征退化和多样性</title>
      <link>https://arxiv.org/abs/2306.11986</link>
      <description><![CDATA[arXiv:2306.11986v2 公告类型：替换 
摘要：顺序推荐 (SR) 在低维联合潜在空间（即序列和项目嵌入空间）中对动态用户偏好进行建模，并生成下一项预测作为序列和项目之间的亲和力。由于用户/项目长尾分布，序列和项目表示都受到表示退化问题的影响，其中尾部用户/项目在潜在空间中难以区分地分布为一个窄锥体。我们认为，表示退化问题是现有 SR 方法中推荐多样性不足的根本原因，削弱了用户潜力探索并进一步加剧了回音室问题。
在这项工作中，我们首先揭示了表示退化和推荐多样性之间的联系，其中表示退化越严重，推荐多样性就越低。然后，我们提出了一种新颖的推荐奇异谱平滑正则化 (SPMRec)，它充当可控的替代项，以缓解退化并实现推荐多样性与性能之间的平衡。所提出的平滑正则化通过最大化奇异值曲线下的面积来缓解退化，这也是多样性的替代项。我们在四个基准数据集上进行了实验，以证明 SPMRec 的优越性，并表明所提出的奇异谱平滑可以同时控制推荐性能和多样性的平衡。]]></description>
      <guid>https://arxiv.org/abs/2306.11986</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>使用大型视觉语言模型进行多模态错误信息检测</title>
      <link>https://arxiv.org/abs/2407.14321</link>
      <description><![CDATA[arXiv:2407.14321v1 公告类型：交叉 
摘要：错误信息的日益泛滥及其令人震惊的影响促使业界和学术界都开发错误信息检测和事实核查的方法。大型语言模型 (LLM) 的最新进展在各种任务中表现出色，但 LLM 是否以及如何帮助检测错误信息仍未得到充分探索。大多数现有的最先进方法要么不考虑证据，只关注与声明相关的特征，要么假设提供证据。很少有方法将证据检索视为错误信息检测的一部分，而是依赖于微调模型。在本文中，我们研究了 LLM 在零样本设置中检测错误信息的潜力。我们将证据检索组件纳入流程，因为从各种来源收集相关信息对于检测声明的真实性至关重要。为此，我们提出了一种使用 LLM 和大型视觉语言模型 (LVLM) 进行多模态证据检索的新型重新排序方法。检索到的证据样本（图像和文本）作为基于 LVLM 的多模态事实验证方法 (LVLM4FV) 的输入。为了进行公平评估，我们通过为图像和文本检索注释一组更完整的证据样本来解决现有证据检索数据集中证据样本的真实性不完整的问题。我们在两个数据集上的实验结果证明了所提出的方法在证据检索和事实验证任务中的优越性，并且与监督基线相比，它在数据集上的泛化能力也更好。]]></description>
      <guid>https://arxiv.org/abs/2407.14321</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>PolySinger：从英语翻译成日语的歌声到歌声的翻译</title>
      <link>https://arxiv.org/abs/2407.14399</link>
      <description><![CDATA[arXiv:2407.14399v1 公告类型：交叉 
摘要：语音领域在多种自然语言处理 (NLP) 任务中备受关注，而歌唱领域的探索较少。NLP 的顶峰是语音到语音翻译 (S2ST) 任务，指的是人类语音的翻译和合成。S2ST 与歌唱领域的可能适应性（我们称之为歌唱声音到歌唱声音翻译 (SV2SVT)）之间的差异正变得突出，因为前者进展越来越快，而后者却停滞不前。尽管人们对多语言歌曲创作和歌曲翻译的关注有限，但歌唱声音合成系统正在克服多语言合成的障碍。本文致力于确定成功实现 SV2SVT 所需的条件，并提出了 PolySinger (\textbf{Poly}glot \textbf{Singer})：SV2SVT 的第一个系统，用于将歌词从英语翻译成日语。提出了一种级联方法来建立一个具有高度控制的框架，这可能会缩小 SV2SVT 和 S2ST 之间的差异。PolySinger 的性能通过对日语母语人士的平均意见分数测试来评估。结果和与测试对象的深入讨论表明 SV2SVT 的基础很牢固，但必须克服几个缺点，这些缺点是 SV2SVT 未来的讨论。]]></description>
      <guid>https://arxiv.org/abs/2407.14399</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:32 GMT</pubDate>
    </item>
    <item>
      <title>DisenSemi：通过解缠表征学习进行半监督图分类</title>
      <link>https://arxiv.org/abs/2407.14081</link>
      <description><![CDATA[arXiv:2407.14081v1 公告类型：交叉 
摘要：图形分类是众多多媒体应用中的一项关键任务，其中图形用于表示各种类型的多媒体数据，包括图像、视频和社交网络。然而，在现实世界中，标记的图形数据可能有限或稀缺。为了解决这个问题，我们专注于半监督图分类的问题，它涉及从标记和未标记数据中学习的监督和无监督模型。与最近将整个知识从无监督模型转移到监督模型的方法相比，我们认为有效的转移应该只保留与监督任务很好地一致的相关语义。在本文中，我们提出了一个名为 DisenSemi 的新框架，它学习半监督图分类的解缠结表示。具体而言，提出了一种解缠结图编码器来为监督和无监督模型生成因子式图表示。然后，我们分别通过监督目标和基于互信息 (MI) 的约束训练两个模型。为了确保知识从无监督编码器有意义地转移到监督编码器，我们进一步定义了两个模型之间基于 MI 的解缠一致性正则化，并确定了与当前图分类任务很好地一致的相应原理。在一系列可公开访问的数据集上的实验结果揭示了我们的 DisenSemi 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.14081</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>西方流行音乐的吉他和弦图建议</title>
      <link>https://arxiv.org/abs/2407.14260</link>
      <description><![CDATA[arXiv:2407.14260v1 公告类型：交叉 
摘要：吉他手使用和弦图来显示在指板上的位置和如何弹奏和弦。它们对于学习和弦的初学者或分享弹奏歌曲所需的手部位置很有用。然而，吉他学习工具上呈现的图表通常是从现有数据库中选择的，很少代表表演者使用的实际位置。在本文中，我们提出了一种工具，它可以为和弦标签建议一个和弦图，同时考虑前一个和弦的图表。基于对 DadaGP 和 mySongBook 数据集的统计分析，我们表明某些和弦图在西方流行音乐中过度代表，并且某些和弦可以以 20 多种不同的方式演奏。我们认为考虑上下文可以改善和弦图建议的多样性和质量，并将这种方法与仅考虑当前和弦标签的模型进行比较。我们表明，添加先前的上下文可以将此任务的 F1 分数提高多达 27%，并降低模型建议标准开放和弦的倾向。我们还在和弦图的背景下定义了纹理的概念，并通过各种指标进行展示我们的模型通过前面的图表提高了纹理一致性。]]></description>
      <guid>https://arxiv.org/abs/2407.14260</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:31 GMT</pubDate>
    </item>
    <item>
      <title>利用查询上下文信号改进赞助搜索中的检索</title>
      <link>https://arxiv.org/abs/2407.14346</link>
      <description><![CDATA[arXiv:2407.14346v1 公告类型：新
摘要：准确检索用户查询的相关竞价关键字对于赞助搜索至关重要，但仍然具有挑战性，尤其是对于简短、模糊的查询。现有的密集和生成检索模型在这些情况下通常无法捕捉细微的用户意图。为了解决这个问题，我们提出了一种方法，通过使用来自网络搜索结果和大型语言模型的丰富上下文信号来增强查询理解，这些信号存储在在线缓存中。具体来说，我们使用网络搜索标题和片段将查询扎根于现实世界的信息中，并利用 GPT-4 生成查询重写和解释以阐明用户意图。这些信号通过基于 Fusion-in-Decoder 的 Unity 架构有效集成，从而实现密集和生成检索，服务成本与传统的无上下文模型相当。为了解决缓存中没有上下文的情况，我们引入了上下文浏览，这是一种课程学习策略，即使在推理过程中没有上下文信号，也可以提高模型的鲁棒性和性能。大量离线实验表明，我们的上下文感知方法远胜于上下文无关模型。此外，在 160 多个国家/地区的知名搜索引擎上进行的在线 A/B 测试显示，用户参与度和收入显著提高。]]></description>
      <guid>https://arxiv.org/abs/2407.14346</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>HeCiX：集成知识图谱和大型语言模型用于生物医学研究</title>
      <link>https://arxiv.org/abs/2407.14030</link>
      <description><![CDATA[arXiv:2407.14030v1 公告类型：交叉 
摘要：尽管药物开发策略取得了进步，但 90% 的临床试验都失败了。这表明在靶标验证和药物优化方面被忽视了。为了解决这个问题，我们引入了 HeCiX-KG，Hetionet-Clinicaltrials neXus 知识图谱，这是来自 ClinicalTrials.gov 和 Hetionet 的数据在单个知识图中的新型融合。HeCiX-KG 结合了来自 ClinicalTrials.gov 的先前进行的临床试验的数据以及来自 Hetionet 的疾病和基因领域的专业知识。这为临床研究人员提供了全面的资源。此外，我们引入了 HeCiX，这是一个使用 LangChain 将 HeCiX-KG 与 GPT-4 集成并提高其可用性的系统。HeCiX 在针对一系列临床相关问题的评估中表现出色，证明该模型有望提高临床研究的有效性。因此，这种方法提供了对临床试验和现有生物数据的更全面的了解。]]></description>
      <guid>https://arxiv.org/abs/2407.14030</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:30 GMT</pubDate>
    </item>
    <item>
      <title>具有双重影响的推荐系统中的用户-创建者特征动态</title>
      <link>https://arxiv.org/abs/2407.14094</link>
      <description><![CDATA[arXiv:2407.14094v1 公告类型：新
摘要：推荐系统向用户呈现相关内容并帮助内容创建者接触目标受众。这些系统的双重性质影响着用户和创建者：用户的偏好受到推荐项目的影响，而创建者则受到激励去改变他们的内容，以便更频繁地推荐。我们定义了一个称为用户-创建者特征动态的模型来捕捉推荐系统的双重影响。我们证明，具有双重影响的推荐系统必然会发生两极分化，从而导致系统的多样性损失。然后，我们从理论和实证两个方面研究了减轻推荐系统中两极分化和促进多样性的方法。出乎意料的是，我们发现常见的促进多样性的方法在存在双重影响的情况下不起作用，而像 top-$k$ 推荐这样的相关性优化方法可以防止两极分化并提高系统的多样性。]]></description>
      <guid>https://arxiv.org/abs/2407.14094</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>L^2CL：图协同过滤中令人尴尬的简单层对层对比学习</title>
      <link>https://arxiv.org/abs/2407.14266</link>
      <description><![CDATA[arXiv:2407.14266v1 公告类型：新
摘要：图神经网络 (GNN) 最近成为一种在协同过滤中建模邻域信号的有效方法。在这一研究方向上，图对比学习 (GCL) 通过生成大量自监督信号展示了解决监督标签短缺问题的强大能力。尽管 GCL 很有效，但它在推荐方面面临两个主要挑战：i) GCL 依靠图形增强来生成语义上不同的对比视图，这可能会破坏关键信息并引入不必要的噪音；ii) 目前 GCL 的工作主要集中在使用复杂的网络架构（通常是深度）来捕捉高阶交互的对比表示，这会导致计算复杂度增加和训练效率不理想。为此，我们提出了 L2CL，这是一个原则性的层到层对比学习框架，可以对比来自不同层的表示。通过对齐不同层之间的语义相似性，L2CL 能够学习复杂的结构关系并消除随机数据增强中的噪声扰动。令人惊讶的是，我们发现 L2CL 仅使用一跳对比学习范式就能够捕获内在语义结构并提高节点表示的质量，从而形成一种简单而有效的架构。我们还为 L2CL 在最小化与任务无关的信息方面提供了理论保证。在五个真实数据集上进行的大量实验证明了我们的模型优于各种最先进的协同过滤方法。我们的代码可在 https://github.com/downeykking/L2CL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.14266</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>PRAGyan——推文中的连线</title>
      <link>https://arxiv.org/abs/2407.13909</link>
      <description><![CDATA[arXiv:2407.13909v1 公告类型：新
摘要：随着社交媒体平台的发展，了解事件和声明背后的根本原因对于企业、政策制定者和研究人员来说至关重要。本研究探讨了知识图谱 (KG) 与大型语言模型 (LLM) 的集成，以对推文数据集进行因果分析。LLM 辅助分析技术通常缺乏深度来揭示导致观察到的影响的原因。通过利用编码丰富语义关系和时间信息的 KG 和 LLM，本研究旨在揭示影响因果动态的因素的复杂相互作用，并比较使用 GPT-3.5 Turbo 获得的结果。我们采用检索增强生成 (RAG) 模型，利用存储在 Neo4j（又名 PRAGyan）数据格式中的 KG 来检索因果推理的相关上下文。我们的方法表明，随着源语料库规模的增加，与基线 LLM (GPT-3.5 Turbo) 模型相比，KG 增强型 LLM RAG 可以提供更好的结果。我们的定性分析强调了将 KG 与 LLM 相结合的优势，以提高可解释性和可操作的见解，促进各个领域的明智决策。而使用 BLEU 和余弦相似度等指标的定量分析表明，我们的方法比基线高出 10%。]]></description>
      <guid>https://arxiv.org/abs/2407.13909</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>精准高效推荐系统的知识蒸馏方法</title>
      <link>https://arxiv.org/abs/2407.13952</link>
      <description><![CDATA[arXiv:2407.13952v1 公告类型：新
摘要：尽管知识蒸馏（KD）在分类问题上取得了突破，但在以前的文献中，它对推荐模型和排名问题的研究并不充分。本论文致力于开发推荐系统的知识蒸馏方法，以充分提高紧凑模型的性能。我们提出了专为推荐系统设计的新型蒸馏方法。所提出的方法根据其知识来源分为以下几类：（1）潜在知识：我们提出了两种迁移用户/项目表示潜在知识的方法。它们通过平衡的蒸馏策略有效地转移了小众品味的知识，从而防止 KD 过程偏向少数大偏好群体。此外，我们提出了一种在表示空间中转移用户/项目关系的新方法。考虑到紧凑模型的有限容量，所提出的方法有选择地转移基本关系。（2）排名知识：我们提出了三种从推荐结果中转移排名知识的方法。他们将 KD 过程公式化为排名匹配问题，并通过列表式学习策略传递知识。此外，我们提出了一种新的学习框架，可以压缩异构推荐模型的排名知识。所提出的框架旨在减轻模型集成的计算负担，而模型集成是许多推荐应用的主要解决方案。我们通过大量实验验证了我们提出的方法和框架的优势。总而言之，本论文阐明了知识蒸馏方法，以实现推荐模型的更好的准确性和效率权衡。]]></description>
      <guid>https://arxiv.org/abs/2407.13952</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    <item>
      <title>通过直接偏好优化增强的编码器-解码器模型的临床阅读理解</title>
      <link>https://arxiv.org/abs/2407.14000</link>
      <description><![CDATA[arXiv:2407.14000v1 公告类型：新
摘要：对临床文本进行抽取式问答是解决医院产生的大量临床文本问题的关键。虽然编码器模型（例如 BERT）在阅读理解任务中很受欢迎，但最近编码器-解码器模型（例如 T5）正在兴起。还出现了偏好优化技术，以使仅解码器的 LLM 与人类偏好保持一致。在本文中，我们将编码器-解码器模型与直接偏好优化 (DPO) 方法相结合，使 RadQA 放射学问答任务的 F1 点比以前的最先进水平提高了 12-15 个。据我们所知，这项工作首次表明 DPO 方法也适用于阅读理解，通过新颖的启发式方法生成偏好数据而无需人工输入。]]></description>
      <guid>https://arxiv.org/abs/2407.14000</guid>
      <pubDate>Mon, 22 Jul 2024 06:21:28 GMT</pubDate>
    </item>
    </channel>
</rss>