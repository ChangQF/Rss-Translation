<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Belightrec：使用BERT增强的轻量级推荐系统</title>
      <link>https://arxiv.org/abs/2503.20206</link>
      <description><![CDATA[ARXIV：2503.20206V1公告类型：新 
摘要：使用深度学习模型在图形神经网络上使用深度学习模型的数据挖掘趋势已被证明有效地通过信号编码器和解码器来识别对象特征，尤其是在使用协作过滤方法的推荐系统中。协作过滤利用了从历史数据中的用户和项目之间的相似性。但是，它忽略了独特的信息，例如项目名称和描述。项目的语义数据应使用自然语言处理字段中的模型进一步开采。因此，可以使用文本分类，相似性评估或识别类似句子对比较项目。这项研究建议将两个项目相似性信号的来源结合起来：一个来自协作过滤的来自协作过滤，另一个来自项目名称和描述之间的语义相似性度量。这些信号集成到图形卷积神经网络中，以优化模型权重，从而提供准确的建议。还设计了实验来评估每个信号组对建议结果的贡献。]]></description>
      <guid>https://arxiv.org/abs/2503.20206</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在顺序推荐中，可学习的三胞胎对比度学习序列增强器</title>
      <link>https://arxiv.org/abs/2503.20232</link>
      <description><![CDATA[ARXIV：2503.20232V1公告类型：新 
摘要：大多数现有的基于学习的顺序推荐（SR）方法依赖于随机操作（例如作物，重新有序和替代）来生成增强序列。这些方法通常难以创建与原始序列的表示相似的正面样本对，从而通过删除关键项目或引入嘈杂的iTerac来破坏项目相关性，从而误导了对比度学习过程。
  为了解决这一限制，我们提出了在顺序推荐（LACLREC）中进行三胞胎对比学习的可学习序列增强器。具体而言，基于学习的增强器可以自动从序列中删除嘈杂的项目，并插入新项目，从而更好地捕获项目过渡模式，从而生成更高质量的增强序列。随后，我们随机生成另一个增强序列，并设计基于排名的三重对比度损失，以区分原始序列，增强序列与增强器和随机增强序列之间的相似性，从而提供了更精细的对比度信号。在三个现实世界数据集上进行的广泛实验表明，序列增强器和三重态对比都有助于提高建议精度。 LACLREC显着胜过基线模型CL4SREC，并且与几种最新的顺序推荐算法相比，表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.20232</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>杜威长上下文嵌入模型：技术报告</title>
      <link>https://arxiv.org/abs/2503.20376</link>
      <description><![CDATA[ARXIV：2503.20376V1公告类型：新 
摘要：该技术报告介绍了开源DEWEY_EN_BETA嵌入模型的培训方法和评估结果。大语模型（LLMS）对检索功能的生成（RAG）系统的需求不断增长，并且对传统嵌入模型造成了关键的挑战。当前的方法在处理超过典型序列长度限制的文档时通常难以保持语义连贯性，从而显着影响知识密集型应用中的检索性能。本文介绍了DEWEY_EN_BETA，这是一种新颖的文本嵌入模型，在支持128K令牌序列的同时，在MTEB（ENG，V2）和长期基准测试中实现了出色的性能。我们的技术贡献集中在块对准培训上，这是一种创新的方法，它可以通过蒸馏同时生成本地化的块嵌入和全球文档级表示。有关模型发布的信息，请参见https://huggingface.co/infgrad/dewey_en_beta。]]></description>
      <guid>https://arxiv.org/abs/2503.20376</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RALLREC+：检索增强大语模型的推荐建议</title>
      <link>https://arxiv.org/abs/2503.20430</link>
      <description><![CDATA[ARXIV：2503.20430V1公告类型：新 
摘要：大型语言模型（LLM）已集成到推荐系统中，以增强用户行为理解。将检索增强发电（RAG）技术进一步合并到这些系统中，以检索更相关的项目并提高系统性能。但是，现有的抹布方法有两个缺点。 \ textit {（i）}在\ textit {reterieval}阶段，它们主要依赖于文本语义，并且通常无法合并最相关的项目，从而限制了系统的有效性。 \ textit {（ii）}在\ textit {enation}阶段，他们缺乏明确的经过思考的推理，进一步限制了其潜力。
  在本文中，我们提出表示形式学习和\ textbf {r}恢复授权的检索 -  \ textbf {a} u fighted \ textbf {l} arge \ textbf {l} aragebf {l} arguage模型\ textbf \ textbf {rec} romendation（rallRec+）。具体而言，对于检索阶段，我们提示LLMS生成详细的项目描述并执行联合表示学习，并将分别从LLM和建议模型中提取的文本和协作信号组合在一起。为了说明用户兴趣的随时间变化的性质，我们提出了一种简单而有效的重读方法来捕获偏好动态。对于一代阶段，我们首先评估推理LLM在推荐任务上，发现有价值的见解。然后，我们介绍了知识注入知识的提示和基于一致性的合并方法，以将推理LLM与通用LLMS集成，从而提高整体性能。在三个现实世界数据集上进行的广泛实验验证了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.20430</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Protobert-Lora：用于免疫疗法研究鉴定的参数效率原型鉴定</title>
      <link>https://arxiv.org/abs/2503.20179</link>
      <description><![CDATA[ARXIV：2503.20179V1公告类型：交叉 
摘要：在基因组表达（GEO）（GEO）（GEO）等基因组储存库中鉴定免疫检查点抑制剂（ICI）研究对于癌症研究至关重要，但由于语义歧义，极端的类不平衡和低资源环境中标记的数据有限，因此仍然具有挑战性。我们提出了Protobert-Lora，这是一种混合框架，将PubMedbert与原型网络和低级别适应性（Lora）相结合，以进行有效的微调。该模型通过情节原型训练强化类分离的嵌入，同时保留生物医学领域知识。我们的数据集被分为：训练（20个正，20负），原型集（10个正，10负），验证（20个正，200负）和测试（71个正，765负）。在测试数据集上进行了评估，Protobert-Lora的F1得分为0.624（精度：0.481，召回：0.887），表现优于基于规则的系统，机器学习基线和列出的PubMedbert。在44,287项未标记的研究中申请将手动审查工作减少了82％。消融研究证实，将原型与洛拉相结合，比独立的洛拉提高了29％的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.20179</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开放式搜索：通过开源推理代理商将搜索民主化搜索</title>
      <link>https://arxiv.org/abs/2503.20201</link>
      <description><![CDATA[ARXIV：2503.20201V1公告类型：交叉 
摘要：我们介绍开放的深度搜索（ODS），以缩小专有搜索AI解决方案之间的差距，例如Perplexity的Sonar Challioning Pro和OpenAI的GPT-4O搜索预览及其开放源对应物。 ODS引入的主要创新是通过推理代理可以明智地使用Web搜索工具来回答查询的最新开源LLM的推理能力。具体而言，ODS由两个组件组成，这些组件与用户选择的基本LLM一起使用：打开搜索工具和打开推理代理。开放推理代理解释给定的任务，并通过策划包括通话工具的一系列操作来完成它，其中之一是开放搜索工具。开放搜索工具是一种新颖的网络搜索工具，其表现优于专有对应物。加上强大的开源推理LLM，例如DeepSeek-R1，ODS几乎匹配，有时在两个基准上超过了现有的最新基线：SimpleQA和框架。例如，在框架评估基准测试中，ODS将最近发布的GPT-4O搜索预览的现有基线提高了9.7％。 ODS是无缝增强所有LLM的一般框架（例如，DeepSeek-R1，在SimpleQA上可实现82.4％，框架的30.1％ - 具有搜索和推理能力以实现最新性能：SimpleQA的88.3％，框架为75.3％。]]></description>
      <guid>https://arxiv.org/abs/2503.20201</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMMORRF：多模式多语言模块化等级融合</title>
      <link>https://arxiv.org/abs/2503.20698</link>
      <description><![CDATA[ARXIV：2503.20698V1公告类型：交叉 
摘要：视频固有地包含多种方式，包括视觉事件，文本叠加，声音和语音，所有这些对于检索都很重要。但是，最新的多模式模型（如广阔的语言和语言模型）是建立在视觉模型（VLM）上的，因此过于优先考虑视觉信号。检索基准测试基准通过专注于视觉查询并忽略其他方式进一步加剧了这一偏见。我们创建了一个搜索系统MMMORRF，该系统从视觉和音频模式中提取文本和功能，并将它们与新颖的模态感知的加权相互等级融合相结合。 MMMORRF既有效又有效，可以根据用户的信息需求而不是视觉描述性查询来搜索视频时实用。我们评估了MMMORRF在Multivent 2.0和TVR上，这两个多模式基准测试旨在旨在更具针对性的信息需求，并发现它比领先的多模式编码器改善了NDCG@20乘81％，在单一模式检索中提高了37％，这表明了整合多元化模态的价值。]]></description>
      <guid>https://arxiv.org/abs/2503.20698</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不要使用LLM来做出相关性判断</title>
      <link>https://arxiv.org/abs/2409.15133</link>
      <description><![CDATA[Arxiv：2409.15133V2公告类型：替换 
摘要：对TREC风格的测试收集的相关性判断可能很复杂且昂贵。典型的TREC轨道通常涉及一个由六个承包商组成的团队，工作2-4周。这些承包商需要接受培训和监控。必须编写软件以正确有效地支持记录相关性判断。响应自然语言提示的大型语言模型的最新出现，产生惊人的人类流动文本输出，激发了IR研究人员怀疑如何在相关性判断收集过程中使用这些模型。在ACM Sigir 2024会议上，研讨会``LLM4EVAL&#39;&#39;为这项工作提供了一个场地，并提供了数据挑战活动，参与者像Thomas等人（Arxiv：2408.08896，arxiv：arxiv：2309.10621）一起重现了TREC深度学习轨道判断。我被要求在研讨会上提到一个主题演讲，本文以文章形式介绍了这一主题演讲。最底线的前后消息是，不要使用LLM来为TREC风格的评估创建相关判断。]]></description>
      <guid>https://arxiv.org/abs/2409.15133</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Retro-Li：小规模检索增强一代，支持嘈杂的相似性搜索和域移位概括</title>
      <link>https://arxiv.org/abs/2410.00004</link>
      <description><![CDATA[ARXIV：2410.00004V2公告类型：替换 
摘要：诸如Retro之类的检索增强生成系统（RAG）系统已被证明可以通过从包含数万亿个条目的非参数记忆数据库中检索来提高语言建模能力并降低毒性和幻觉。我们介绍了Retro-Li，显示检索也可以使用小规模数据库帮助，但是在较小的搜索中搜索时，它需要更准确，更好的邻居。可以通过使用适当的语义相似性搜索来实现这一点。我们进一步提出，首次向非参数存储器添加正则化：当邻居搜索操作在推理过程中嘈杂时，它会大大降低困惑，并且当发生域移动时，它会改善概括。我们还表明，Retro-Li的非参数记忆可以在模拟内存计算硬件上实现，显示O（1）搜索时间，同时在检索邻居中引起噪音，而较小（&lt;1％）的性能损失。我们的代码可在以下网址提供：https：//github.com/ibm/retrieval-enhanced-transformer-little。]]></description>
      <guid>https://arxiv.org/abs/2410.00004</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长期推荐模型需要脱钩的嵌入</title>
      <link>https://arxiv.org/abs/2410.02604</link>
      <description><![CDATA[ARXIV：2410.02604V3公告类型：替换 
摘要：终身用户行为序列对于捕获用户兴趣和预测现代推荐系统中的用户响应至关重要。通常采用两个阶段范式来处理这些长序列：首先通过第一阶段的注意机制从原始长序列中搜索相关行为的子集，然后用目标项目汇总以构建第二阶段预测的区分表示。在这项工作中，我们首次确定并表征了现有的长期推荐模型中被忽视的缺陷：一组嵌入式努力在学习注意力和表示方面都在努力，从而导致这两个过程之间的干扰。通过一些常见方法（例如，线性预测 - 从语言处理中借来的一种技术）的初步尝试被证明是无效的，阐明了建议模型的独特挑战。为了克服这一点，我们提出了脱钩的注意力和表示嵌入（DARE）模型，其中两个不同的嵌入表被初始化并分别学习，以完全解除注意力和表示。广泛的实验和分析表明，DARE提供了对相关行为的更准确搜索，并且在公共数据集中获得了高达0.9％的AUC，并在Tencent的广告平台上取得了显着改进。此外，解耦嵌入空间使我们能够将注意力嵌入维度降低，并将搜索程序降低50％，而不会产生重大的性能影响，从而实现了更高效，更高性能的在线服务。 Pytorch中的代码用于实验，包括模型分析，请访问https://github.com/thuml/dare。]]></description>
      <guid>https://arxiv.org/abs/2410.02604</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PRECTR：一个集成个性化搜索相关性匹配和CTR预测的协同框架</title>
      <link>https://arxiv.org/abs/2503.18395</link>
      <description><![CDATA[ARXIV：2503.18395V2公告类型：替换 
摘要：搜索建议系统中的两个主要任务是搜索相关性匹配和点击率（CTR）预测 - 前者专注于寻找用户查询的相关项目，而后者的预测可以更好地匹配用户兴趣。先前的研究通常开发两个模型来预测CTR并分别搜索相关性，然后根据两个输出的融合对候选项目进行排名。但是，这种分裂和诱导范式在不同模型之间造成了不一致。同时，搜索相关模型主要集中在客观文本匹配的程度上，同时忽略了不同用户之间的个性化差异，从而导致模型性能受到限制。为了解决这些问题，我们提出了一个统一的个性化搜索相关性匹配和CTR预测融合模型（PRECTR）。具体而言，根据条件概率融合机制，PRETTR将CTR预测集成并搜索相关性匹配到一个框架中，以增强两个模块的相互作用和一致性。但是，直接优化CTR二进制分类损失可能会给Fusion模型的收敛带来挑战，并无限期地促进具有高CTR的项目的暴露，无论其搜索相关性如何。因此，我们进一步引入了两阶段的训练和语义一致性正规化，以加快模型的收敛性并限制不相关项目的建议。最后，认识到不同用户可能具有各种相关性偏好，我们通过分析过去用户对类似查询的偏好以及对不同候选项目的量身定制激励措施来评估当前用户的相关性偏好。我们的生产数据集和在线A/B测试的广泛实验结果证明了我们提出的PRECTR方法的有效性和优势。]]></description>
      <guid>https://arxiv.org/abs/2503.18395</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bright：用于推理密集型检索的现实且挑战性的基准</title>
      <link>https://arxiv.org/abs/2407.12883</link>
      <description><![CDATA[ARXIV：2407.12883V4公告类型：替换 - 交叉 
摘要：现有的检索基准主要由寻求信息查询（例如，来自搜索引擎的汇总问题）组成，其中关键字或基于语义的检索通常就足够了。但是，许多复杂的现实查询需要深入的推理，以确定超越表面形式匹配的相关文档。例如，找到编码问题的文档需要了解所涉及功能的逻辑和语法。为了更好地检索此类具有挑战性的查询，我们介绍了Bright，这是第一个文本检索基准，需要大量的推理来检索相关文档。我们的数据集由1,384个现实世界中的查询组成，涵盖了经济学，心理学，数学和编码等不同领域。这些查询来自自然发生和精心策划的人类数据。广泛的评估表明，即使是最先进的检索模型在BRIGHT上的表现也很差。 MTEB排行榜上的领先模型（Muennighoff等，2023）SFR-隔离 - 米斯特式（Meng等，2024），其得分为59.0 NDCG@10,1，在Bright上产生的NDCG 10,1分数为NDCG 10。我们表明，结合有关查询的明确推理可以提高检索性能多达12.2分。此外，从表现最好的回收犬中纳入了检索到的文档，提高了提问的效果。我们认为，Bright在更现实和挑战的环境中对未来的检索系统进行研究铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2407.12883</guid>
      <pubDate>Thu, 27 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>