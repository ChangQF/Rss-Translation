<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 01 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>DiFashion：走向个性化服装生成和推荐</title>
      <link>https://arxiv.org/abs/2402.17279</link>
      <description><![CDATA[arXiv:2402.17279v2 公告类型：替换
摘要：服装推荐（OR）在时尚领域的发展经历了两个不同的阶段：预定义服装推荐和个性化服装组合。尽管取得了这些进步，但这两个阶段都面临着现有时尚产品的限制，阻碍了它们满足用户多样化时尚需求的有效性。人工智能生成内容的出现为 OR 克服这些限制铺平了道路，展示了个性化服装生成的潜力。
  为了实现这一目标，我们引入了一项名为生成服装推荐（GOR）的创新任务，其目标是合成一组时尚图像并将它们组合成为个人用户定制的视觉和谐的服装。 GOR 的主要目标是实现所生成服装的高保真度、兼容性和个性化。为了实现这些目标，我们提出了 DiFashion，这是一种生成服装推荐模型，它利用特殊的扩散模型来同时生成多个时尚图像。为了确保实现这些目标，设计了三种类型的条件来指导并行生成过程，并采用无分类器指导来增强生成的图像和条件之间的对齐。 DiFashion 适用于个性化填空任务和 GOR 任务，并在 iFashion 和 Polyvore-U 数据集上进行了大量实验。定量和人为参与的定性评估结果凸显了 DiFashion 相对于竞争基准的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.17279</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的预算嵌入表</title>
      <link>https://arxiv.org/abs/2310.14884</link>
      <description><![CDATA[arXiv:2310.14884v4 公告类型：替换
摘要：当代推荐系统（RS）的核心是为用户提供优质推荐体验的潜在因素模型。这些模型使用嵌入向量（通常具有统一且固定的大小）来表示用户和项目。随着用户和项目数量的不断增长，这种设计变得效率低下且难以扩展。最近的轻量级嵌入方法使不同的用户和项目能够具有不同的嵌入大小，但通常存在两个主要缺点。首先，他们将嵌入大小搜索限制为优化平衡推荐质量和内存复杂性的启发式算法，其中需要针对每个请求的内存预算手动调整权衡系数。隐式强制执行的内存复杂性项甚至可能无法限制参数使用，从而导致生成的嵌入表无法严格满足内存预算。其次，大多数解决方案，尤其是基于强化学习的解决方案，都会逐个实例地推导和优化每个用户/项目的嵌入大小，这会阻碍搜索效率。在本文中，我们提出了预算嵌入表（BET），这是一种生成表级操作（即所有用户和项目的嵌入大小）的新颖方法，保证满足预先指定的内存预算。此外，通过利用基于集合的动作公式和参与集合表示学习，我们提出了一种创新的动作搜索策略，该策略由动作适应度预测器提供支持，可有效评估每个表级动作。实验表明，当 BET 与不同内存预算下的三种流行推荐模型配对时，在两个现实数据集上表现出了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2310.14884</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>重新思考开放世界假设下的跨域顺序推荐</title>
      <link>https://arxiv.org/abs/2311.04590</link>
      <description><![CDATA[arXiv:2311.04590v5 公告类型：替换
摘要：跨域顺序推荐（CDSR）方法旨在解决单域顺序推荐（SDSR）中存在的数据稀疏和冷启动问题。现有的 CDSR 作品设计了复杂的结构，依靠重叠用户来传播跨域信息。然而，当前的 CDSR 方法做出了封闭世界的假设，假设跨多个域的用户完全重叠，并且数据分布从训练环境到测试环境保持不变。因此，由于数据分布的变化，这些方法通常会导致在线现实平台上的性能降低。为了解决开放世界假设下的这些挑战，我们设计了一个用于跨域顺序推荐的 \textbf{A}daptive \textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing 框架（\textbf{AMID }），它由多兴趣信息模块（\textbf{MIM}）和双鲁棒估计器（\textbf{DRE}）组成。我们的框架适用于开放世界环境，并且可以改进大多数现成的 CDSR 单域顺序骨干模型的模型。我们的 MIM 建立了同时考虑重叠和非重叠用户的兴趣组，使我们能够有效地探索用户意图和明确的兴趣。为了减轻跨多个领域的偏差，我们开发了 CDSR 方法的 DRE。我们还提供了理论分析，证明与之前工作中使用的 IPS 估计器相比，我们提出的估计器在偏差和尾部边界方面具有优越性。]]></description>
      <guid>https://arxiv.org/abs/2311.04590</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>模式明智的透明顺序推荐</title>
      <link>https://arxiv.org/abs/2402.11480</link>
      <description><![CDATA[arXiv:2402.11480v2 公告类型：替换
摘要：透明的决策过程对于开发可靠且值得信赖的推荐系统至关重要。对于顺序推荐，这意味着模型可以识别关键项目作为其推荐结果的理由。然而，同时实现模型透明度和推荐性能具有挑战性，特别是对于将整个项目序列作为输入而不进行筛选的模型。在本文中，我们提出了一个可解释的框架（名为 PTSR），它可以实现模式方面的透明决策过程。它将项目序列分解为多级模式，作为整个推荐过程的原子单元。每个模式对结果的贡献在概率空间中量化。通过精心设计的模式加权校正，可以在缺乏地面实况关键模式的情况下学习模式贡献。最终推荐的项目是最关键模式强烈认可的项目。对四个公共数据集的广泛实验证明了卓越的推荐性能，而案例研究则验证了模型的透明度。我们的代码可在 https://anonymous.4open.science/r/PTSR-2237 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.11480</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>OpenMedLM：利用开源大型语言模型，快速工程可以胜过医学问答中的微调</title>
      <link>https://arxiv.org/abs/2402.19371</link>
      <description><![CDATA[arXiv:2402.19371v1 公告类型：交叉
摘要：法学硕士完成一系列专业任务的能力越来越强，可用于扩大医学知识的公平获取。大多数医学法学硕士都涉及广泛的微调，利用专门的医学数据和大量（因此成本高昂）的计算能力。许多表现最好的法学硕士都是专有的，只有极少数的研究小组才能访问它们。然而，开源 (OS) 模型代表了医学法学硕士的一个关键增长领域，因为其性能显着提高，并且具有提供医疗保健所需的透明度和合规性的固有能力。我们推出 OpenMedLM，这是一个提示平台，可为 OS LLM 在医学基准方面提供最先进的 (SOTA) 性能。我们根据四个医学基准（MedQA、MedMCQA、PubMedQA、MMLU 医学子集）评估了一系列操作系统基础法学硕士 (7B-70B)。我们采用了一系列的提示策略，包括零样本、少样本、思维链（随机选择和 kNN 选择）以及集成/自洽投票。我们发现 OpenMedLM 在三个常见的医学 LLM 基准上提供了操作系统 SOTA 结果，超越了之前利用计算成本高昂的广泛微调的最佳性能操作系统模型。该模型在 MedQA 基准上的准确率达到 72.6%，比之前的 SOTA 提高了 2.4%，并且在 MMLU 医学子集上达到了 81.7% 的准确率，成为第一个在此基准上超过 80% 准确率的 OS LLM。我们的结果强调了操作系统法学硕士中迄今为止尚未在其他地方记录的医疗特定的新兴特性，并展示了进一步利用即时工程来提高可访问的法学硕士在医疗应用中的性能的好处。]]></description>
      <guid>https://arxiv.org/abs/2402.19371</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>ReLLa：用于推荐中终身顺序行为理解的检索增强型大型语言模型</title>
      <link>https://arxiv.org/abs/2308.11131</link>
      <description><![CDATA[arXiv:2308.11131v4 公告类型：替换
摘要：随着大型语言模型（LLM）在自然语言处理（NLP）领域取得显着突破，LLM增强型推荐系统目前受到了广泛关注并得到积极探索。在本文中，我们专注于针对零样本和少样本推荐任务调整和增强纯大型语言模型。首先也是最重要的，我们识别并制定了推荐领域中 LLM 的终生序列行为不理解问题，即 LLM 无法从长用户行为序列的文本上下文中提取有用信息，即使上下文的长度远未达到上下文LLM 的限制。为了解决这个问题并提高法学硕士的推荐性能，我们提出了一种新颖的框架，即检索增强型大语言模型（ReLLa），用于零样本和少样本设置中的推荐任务。对于零样本推荐，我们进行语义用户行为检索（SUBR）来提高测试样本的数据质量，这大大降低了法学硕士从用户行为序列中提取本质知识的难度。对于少样本推荐，我们通过采用 SUBR 作为训练样本的数据增强技术，进一步设计了检索增强指令调整（ReiT）。具体来说，我们开发了一个混合训练数据集，其中包含原始数据样本及其检索增强的对应样本。我们对三个现实世界的公共数据集进行了广泛的实验，以证明 ReLLa 与现有基线模型相比的优越性，以及其终身序列行为理解的能力。需要强调的是，只需不到 10% 的训练样本，few-shot ReLLa 就可以超越在整个训练集（例如 DCNv2、DIN、SIM）上训练的传统 CTR 模型。代码可在 \url{https://github.com/LaVieEnRose365/ReLLa} 获取。]]></description>
      <guid>https://arxiv.org/abs/2308.11131</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>创造知识：探索基于聊天的搜索引擎的创造机制</title>
      <link>https://arxiv.org/abs/2402.19421</link>
      <description><![CDATA[arXiv:2402.19421v1 公告类型：新
摘要：在数字信息传播领域，搜索引擎充当着连接信息搜索者和提供者的关键渠道。以 Bing Chat 为例，利用大型语言模型 (LLM) 和检索增强生成 (RAG) 的基于聊天的搜索引擎的出现，标志着搜索生态系统的进化飞跃。他们在解释网络信息和以类似人类的理解力和创造力做出反应方面表现出元认知能力。尽管如此，法学硕士的复杂性使其“认知”过程变得不透明，甚至挑战了其设计者的理解。本研究旨在剖析由法学硕士支持的基于聊天的搜索引擎（特别是 Bing Chat）为其响应选择信息源的机制。为此，我们与 New Bing 合作编制了一个广泛的数据集，记录了它引用的网站以及传统搜索引擎列出的网站。研究表明，Bing Chat 采用自然语言处理 (NLP) 技术，不仅偏爱可读且结构形式明确的内容，而且还表现出较低的困惑度，表明对底层法学硕士可预测的文本有独特的倾向。为了进一步丰富我们的分析，我们通过与基于 GPT-4 的知识检索 API 的交互获取了额外的数据集，揭示了 RAG API 和 Bing Chat 之间一致的文本偏好。这一共识表明，这些文本偏好本质上是从底层语言模型中产生的，而不是由 Bing Chat 的开发人员明确设计的。此外，我们的调查显示，与传统搜索引擎排名最高的网站相比，RAG 技术引用的网站之间的相似性更大。]]></description>
      <guid>https://arxiv.org/abs/2402.19421</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>停止依赖“别无选择”，不要重复行动：最优、高效、实用的分类优化算法</title>
      <link>https://arxiv.org/abs/2402.18917</link>
      <description><![CDATA[arXiv:2402.18917v1 公告类型：交叉
摘要：我们解决带有偏好反馈的主动在线分类优化问题，这是一个用于建模用户选择和子集效用最大化的框架。该框架可用于各种现实世界的应用程序，包括广告投放、在线零售、推荐系统、微调语言模型等。该问题虽然过去已经被研究过，但缺乏一种直观实用的解决方法，同时具有高效的算法和最优的后悔保证。例如，普遍使用的分类选择算法通常需要存在始终包含在选择集中的“强参考”，此外，它们还被设计为重复提供相同的分类，直到选择参考项为止——所有这些要求都非常高。对于实际应用来说不现实。在本文中，我们设计了有效的算法来解决基于 \emph{Plackett Luce} (PL) 的用户选择的品种选择中的遗憾最小化问题。我们设计了一种新颖的集中保证，用于使用“\emph{Pairwise Rank-Breaking}”估计 PL 模型的得分参数，这为我们提出的算法奠定了基础。此外，我们的方法是实用的，被证明是最佳的，并且没有现有方法的上述限制。实证评估证实了我们的发现并优于现有的基线。]]></description>
      <guid>https://arxiv.org/abs/2402.18917</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>合理的方法：使用大型语言模型生成音频描述以进行以自我为中心的文本音频检索</title>
      <link>https://arxiv.org/abs/2402.19106</link>
      <description><![CDATA[arXiv:2402.19106v1 公告类型：交叉
摘要：互联网视频数据库是文本音频检索数据集的宝贵来源。然而，鉴于声音和视觉流代表数据的不同“视图”，将视觉描述视为音频描述远非最佳。即使存在音频类标签，它们通常也不是很详细，使得它们不适合文本音频检索。为了利用视频文本数据集中的相关音频信息，我们引入了一种使用大型语言模型（LLM）生成以音频为中心的描述的方法。在这项工作中，我们考虑以自我为中心的视频设置，并基于 EpicMIR 和 EgoMCQ 任务以及 EpicSounds 数据集提出了三个新的文本音频检索基准。与使用原始的以视觉为中心的描述相比，我们获得以音频为中心的描述的方法提供了显着更高的零样本性能。此外，我们表明，与使用数据集的原始音频类标签相比，使用相同的提示，我们可以成功地利用 LLM 来改进 EpicSounds 上的检索。最后，我们确认 LLM 可用于确定识别与声音相关的动作的难度。]]></description>
      <guid>https://arxiv.org/abs/2402.19106</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>导师：多模式推荐的多层次自监督学习</title>
      <link>https://arxiv.org/abs/2402.19407</link>
      <description><![CDATA[arXiv:2402.19407v1 公告类型：新
摘要：随着多媒体信息的不断增加，多模态推荐受到广泛关注。它利用多模态信息来缓解推荐系统中的数据稀疏问题，从而提高推荐准确性。然而，对标记数据的依赖严重限制了多模态推荐模型的性能。最近，自监督学习已被用于多模态推荐中，以缓解标签稀疏问题。然而，由于不同模态的分布存在巨大差异，最先进的方法在对齐多模态信息时无法避免模态噪声。为此，我们提出了一种多级自监督学习多级推荐（MENTOR）方法来解决标签稀疏问题和模态对齐问题。具体来说，MENTOR 首先使用图卷积网络 (GCN) 增强每种模态的具体特征，并融合视觉和文本模态。然后，它通过所有模态（包括融合模态）的项目语义图增强项目表示。然后，引入了两个多级自监督任务：多级跨模态对齐任务和通用特征增强任务。多级跨模态对齐任务在多个级别的ID嵌入的指导下对齐每个模态，同时维护历史交互信息。通用特征增强任务从图和特征的角度增强通用特征，以提高模型的鲁棒性。对三个公开可用数据集的广泛实验证明了我们方法的有效性。我们的代码可在 https://github.com/Jinfeng-Xu/MENTOR 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2402.19407</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>PaECTER：使用引用通知的 Transformer 进行专利级表示学习</title>
      <link>https://arxiv.org/abs/2402.19411</link>
      <description><![CDATA[arXiv:2402.19411v1 公告类型：新
摘要：PaECTER 是一个公开可用的、开源的文档级编码器，专门针对专利。我们使用审查员添加的引文信息对 BERT for Patents 进行微调，以生成专利文档的数字表示。 PaECTER 在相似性任务中的表现比专利领域当前最先进的模型更好。更具体地说，在我们的专利引文预测测试数据集上，我们的模型在两个不同的排名评估指标上优于次优的专利特定预训练语言模型（BERT for Patents）。 PaECTER 预测，与 25 项不相关专利相比，至少一项最相似的专利的平均排名为 1.32。 PaECTER 根据专利文本生成的数字表示可用于下游任务，例如分类、跟踪知识流或语义相似性搜索。语义相似性检索对于发明人和专利审查员的现有技术检索尤其重要。 PaECTER 可在 Hugging Face 上使用。]]></description>
      <guid>https://arxiv.org/abs/2402.19411</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>探索大型语言模型对推荐系统的影响：广泛回顾</title>
      <link>https://arxiv.org/abs/2402.18590</link>
      <description><![CDATA[arXiv:2402.18590v1 公告类型：新
摘要：本文强调了大型语言模型（LLM）在重塑推荐系统中的重要性，并将其价值归因于传统推荐系统所缺乏的独特推理能力。与缺乏直接用户交互数据的传统系统不同，法学硕士在推荐项目方面表现出非凡的熟练程度，展示了他们理解复杂语言的能力。这标志着建议领域的根本性范式转变。在动态的研究环境中，研究人员积极利用法学硕士的语言理解和生成能力来重新定义推荐任务的基础。该调查彻底探讨了法学硕士在推荐框架内的固有优势，包括细致入微的语境理解、跨不同领域的无缝过渡、采用统一方法、利用共享数据库的整体学习策略、透明的决策和迭代改进。尽管具有变革潜力，但挑战仍然存在，包括对输入提示的敏感性、偶尔的误解和不可预见的推荐，需要法学硕士驱动的推荐系统不断完善和发展。]]></description>
      <guid>https://arxiv.org/abs/2402.18590</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>调整语言模型以实现多功能的基于文本的项目检索</title>
      <link>https://arxiv.org/abs/2402.18899</link>
      <description><![CDATA[arXiv:2402.18899v1 公告类型：新
摘要：本文解决了通用文本嵌入与项目检索任务的特定需求之间的差距。我们展示了现有模型在捕获项目检索任务的零样本性能所需的细微差别方面的缺点。为了克服这些限制，我们建议从十个任务中生成域内数据集，这些任务旨在解锁模型的项目检索表示能力。我们的实证研究表明，微调数据集上的嵌入模型可以显着改进各种检索任务。我们还说明了我们的改进模型在对话环境中的实际应用，它增强了基于 LLM 的推荐代理（如 Chat-Rec）的功能。我们的代码可在 https://github.com/microsoft/RecAI 获取。]]></description>
      <guid>https://arxiv.org/abs/2402.18899</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>多实体跨域推荐的有效两阶段知识转移</title>
      <link>https://arxiv.org/abs/2402.19101</link>
      <description><![CDATA[arXiv:2402.19101v1 公告类型：新
摘要：近年来，电商平台上的推荐内容日益丰富，单个用户信息流可能包含多个实体，例如销售产品、短视频、内容帖子等。针对多实体推荐问题，一个直观的解决方案是采用基于共享网络的架构进行联合训练。这个想法是将提取的知识从一种类型的实体（源实体）转移到另一种类型的实体（目标实体）。然而，与传统的同实体跨域推荐不同，多实体知识迁移遇到了几个重要问题：（1）源实体和目标实体的数据分布天然不同，使得基于共享网络的联合训练容易受到影响。对于负转移问题，（2）更重要的是，每个实体对应的特征模式并不完全一致（例如，价格是销售产品的基本特征，而内容帖子则缺失），使得现有方法不再适用。最近的研究人员还尝试了预训练和微调范式。同样，他们只考虑具有相同实体类型和特征系统的场景，这在我们的例子中是不合适的。为此，我们设计了一个基于预训练和微调的多实体知识转移框架，称为 MKT。 MKT 利用多实体预训练模块来提取跨不同实体的可转移知识。具体来说，首先应用特征对齐模块来缩放和对齐不同的特征模式。然后，采用几个知识提取器来提取公共知识和特定于实体的知识。最后，采用提取的公共知识进行目标实体模型训练。通过广泛的离线和在线实验，我们证明了 MKT 相对于多种最先进方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2402.19101</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>Verif.ai：迈向具有参考和可验证答案的开源科学生成问答系统</title>
      <link>https://arxiv.org/abs/2402.18589</link>
      <description><![CDATA[arXiv:2402.18589v1 公告类型：新
摘要：在本文中，我们介绍了 Verif.ai 项目的当前进展，这是一个开源科学生成问答系统，具有参考和验证的答案。该系统的组件包括 (1) 一个信息检索系统，结合科学论文的语义和词汇搜索技术 (PubMed)，(2) 一个微调的生成模型 (Mistral 7B)，它采用最佳答案并参考论文生成答案(3)验证引擎，交叉检查生成的声明和导出该声明的摘要或论文，验证在生成该声明时是否可能存在任何幻觉。我们通过提供上下文中的摘要来强化生成模型，但此外，一套独立的方法和模型正在验证答案并检查幻觉。因此，我们相信，通过使用我们的方法，我们可以提高科学家的生产力，同时在不能容忍幻觉和错误信息的科学环境中建立对生成语言模型使用的信任。]]></description>
      <guid>https://arxiv.org/abs/2402.18589</guid>
      <pubDate>Fri, 01 Mar 2024 06:17:24 GMT</pubDate>
    </item>
    </channel>
</rss>