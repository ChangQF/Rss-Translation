<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.ir更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.ir更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>联邦设置中的个性化推荐模型：调查</title>
      <link>https://arxiv.org/abs/2504.07101</link>
      <description><![CDATA[ARXIV：2504.07101V1公告类型：新 
摘要：联合推荐系统（FedRecsys）已成为隐私感知建议的关键解决方案，平衡了对数据安全和个性化经验的增长需求。当前的研究工作主要集中于将传统建议体系结构适应联合环境，优化沟通效率并减轻安全漏洞。但是，用户个性化建模对于在此分散和非IID数据设置中捕获异质偏好至关重要。这项调查通过系统地探索Fedrecsys的个性化来解决这一差距，从而将其从集中式范式演变为联合特定的创新。我们在联合环境中建立了个性化的基本定义，强调个性化模型是捕获细粒用户偏好的关键解决方案。这项工作严格研究了建立个性化的Fedrecsys的技术障碍，并综合了有前途的方法来应对这些挑战。作为该领域的首次合并研究，这项调查既是技术参考，也是推进个性化Fedrecsys研究的催化剂。]]></description>
      <guid>https://arxiv.org/abs/2504.07101</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>行为重要性感知图图神经体系结构搜索跨域建议</title>
      <link>https://arxiv.org/abs/2504.07102</link>
      <description><![CDATA[ARXIV：2504.07102V1公告类型：新 
摘要：跨域建议（CDR）减轻建议系统中的数据稀疏性和冷启动问题。虽然最近使用图形神经网络（GNN）捕获复杂的用户项目交互的CDR接近，但它们依赖于通常是次优且劳动力密集的手动设计的体系结构。此外，从源域中提取有价值的行为信息以改善目标域建议仍然具有挑战性。为了应对这些挑战，我们建议行为重要性感知图形神经体系结构搜索（BIGNAS），该框架共同优化了CDR的GNN体系结构和数据重要性。 Bignas介绍了两个关键组件：跨域自定义的超级网和基于图的行为重要性感知。作为一次性的无重新校园模块，SuperNetwork自动搜索每个域的最佳GNN体系结构，而无需重新训练。感知器使用辅助学习来动态评估源域行为的重要性，从而改善目标域建议。基准CDR数据集和大型行业广告数据集的广泛实验表明，Bignas始终超过最先进的基线。据我们所知，这是共同优化GNN体系结构和行为数据重要性的第一项工作，以跨域建议。]]></description>
      <guid>https://arxiv.org/abs/2504.07102</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FG-rag：通过上下文感知的细粒图抹布增强以查询为中心的摘要</title>
      <link>https://arxiv.org/abs/2504.07103</link>
      <description><![CDATA[ARXIV：2504.07103V1公告类型：新 
摘要：检索功能的生成（RAG）使大型语言模型通过合并外部知识可以提供更精确和相关的响应。在以查询为重点的摘要（QFS）任务中，基于GraphRag的方法显着提高了生成的响应的全面性和多样性。但是，现有的基于GraphRag的方法主要集中于粗粒信息摘要而不意识到特定查询，并且检索到的内容缺乏足够的上下文信息来产生全面的响应。为了解决当前抹布系统的缺陷，我们提出了上下文感知的细粒图抹布（FG-rag），以增强QFS任务的性能。 FG-rag在图图检索中采用上下文感知的实体扩展，以扩展图中检索实体的覆盖范围，从而为检索到的内容提供了足够的上下文信息。此外，FG-rag利用查询级的细粒摘要在响应生成过程中纳入细粒细节，从而增强了对生成的摘要的查询意识。我们的评估表明，在处理QFS任务时，FG-rag在多个综合，多样性和授权的多个指标中都优于其他抹布系统。我们的实施可在https://github.com/buptwululu/fg-rag上获得。]]></description>
      <guid>https://arxiv.org/abs/2504.07103</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相关性不是您所需要的：通过多标准重新计算的推理时间计算扩展抹布系统</title>
      <link>https://arxiv.org/abs/2504.07104</link>
      <description><![CDATA[ARXIV：2504.07104V1公告类型：新 
摘要：现代大型语言模型（LLM）系统通常依赖于检索增强发电（RAG），旨在收集对响应生成有用的上下文。这些抹布系统通常严格针对检索与查询最大程度相关的上下文。但是，传统理论表明，试图在没有任何其他明确标准的情况下试图最大化上下文相关性的检索系统可以创建信息瓶颈。我们通过证明在标准的抹布管道中，仅对上下文相关性最大化就可以降低下游响应质量，从而重申了LLM现代的发现。作为回应，我们展示了对现有的抹布方法的评估，这些方法既说明了上下文相关性和答案质量。这些评估引入了一个新颖的发现，即在考虑我们的合并度量时，现有的破布系统随着推理时间计算的用法而缩小。我们介绍了“超越相关性（Rebel）”的“ Rerank”，它使抹布系统能够通过使用经过三链链的提示（以及可选的多转向对话）的多标准优化进行推理时间计算进行扩展。最终，这使得一个新的性能/速度权衡曲线，随着推理时间的增加，RAG系统能够达到更高的检索环境相关性和优越的答案质量。可以在以下PR上找到我们在Llama-index中实现我们方法的代码：可以在https://github.com/microsoft/rebel上找到用于使用此Llama-Index实现的实验的代码。]]></description>
      <guid>https://arxiv.org/abs/2504.07104</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统和反应性用户之间的反馈回路</title>
      <link>https://arxiv.org/abs/2504.07105</link>
      <description><![CDATA[ARXIV：2504.07105V1公告类型：新 
摘要：建议系统是各种在线平台的基础。这些推荐系统及其用户形成反馈循环，其中前者的目的是通过个性化和推广流行内容来最大化用户参与度，而这些建议塑造了用户的意见或行为，从而可能影响未来的建议。这些动态已被证明会导致用户意见的转变。在本文中，我们询问反应性用户是否意识到所消费的内容的影响，可以通过主动选择是否参与推荐内容来防止这种变化。我们首先在反应性用户的意见动力学和推荐系统之间建模反馈循环。我们在三种不同的策略下研究这些动态 - 固定内容消耗（一种被动策略），以及减少或适应性减少内容消耗（反应性策略）。我们在分析上展示了反应性策略如何帮助用户有效预防或限制不良意见转移，同时仍将实用程序从平台上消耗内容中衍生而来。我们通过数值实验来验证和说明我们的理论发现。]]></description>
      <guid>https://arxiv.org/abs/2504.07105</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>业务实体熵</title>
      <link>https://arxiv.org/abs/2504.07106</link>
      <description><![CDATA[ARXIV：2504.07106V1公告类型：新 
摘要：组织在各个平台上生成大量的互连内容。虽然语言模型可以在业务应用程序中使用复杂的推理，但从组织内存中检索和上下文化信息仍然具有挑战性。我们通过熵的镜头探索了这一挑战，提出了一种实体熵的度量，以量化实体知识在文档中的分布以及受扩散模型启发的新颖生成模型，以便为观察到的行为提供解释。大规模企业语料库的经验分析揭示了重尾熵分布，实体大小和熵之间的相关性以及特定类别的熵模式。这些发现表明，并非所有实体都是同等的，激发了以实体为中心的检索或预处理策略的需求，但并非全部是实体。我们讨论实践含义和理论模型，以指导更有效的知识检索系统的设计。]]></description>
      <guid>https://arxiv.org/abs/2504.07106</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保护数字隐私：探索用户分析和安全性增强功能</title>
      <link>https://arxiv.org/abs/2504.07107</link>
      <description><![CDATA[ARXIV：2504.07107V1公告类型：新 
摘要：用户分析是为个性化建议收集用户信息的实践，已经普遍存在，推动了技术的进度。但是，这种增长对用户隐私构成了威胁，因为设备经常在没有所有者的意识的情况下收集敏感数据。本文旨在巩固有关用户分析，探索各种方法和相关挑战的知识。通过两家公司的镜头共享用户数据，并对印度的18种流行Android应用程序进行分析，包括$ \ textit {社交，教育，娱乐，旅行，购物等} $，该文章揭示了隐私脆弱性。此外，本文提出了一个增强的机器学习框架，采用决策树和神经网络，从而改善了最先进的分类器在检测个人信息暴露时。利用XAI（可解释的人工智能）算法石灰（局部可解释的模型 - 静态解释），它增强了可解释性，对于可靠地识别敏感数据至关重要。结果表明，值得注意的性能提升，达到了75.01美元的精度，而神经网络的培训时间减少了3.62美元。最后，本文提出了加强数字安全措施的研究指示。]]></description>
      <guid>https://arxiv.org/abs/2504.07107</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>秋葵：可解释的，异质的，多方利益相关者的建议系统</title>
      <link>https://arxiv.org/abs/2504.07108</link>
      <description><![CDATA[ARXIV：2504.07108V1公告类型：新 
摘要：在最近的立法中，在招聘领域中使用推荐系统已被标记为“高风险”。结果，已经提出了有关解释性和公平性的严格要求，以确保对所有涉及的利益相关者进行适当的处​​理。为了允许利益相关者特定的解释性，同时还可以处理高度异构的招聘数据，我们建议使用图形神经网络：使用Graph Nearurn网络：基于职业知识的推荐人（OKRA）提出了一种可解释的多方利益相关者工作推荐系统。提出的方法能够同时提供候选和公司端的建议和解释。我们发现，对于两个数据集，就NDCG而言，秋葵的性能大于六个基准。此外，我们发现经过测试的模型对位于城市地区的候选人和空缺有偏见。总体而言，我们的发现表明，秋葵在准确性，解释性和公平性之间提供了平衡。]]></description>
      <guid>https://arxiv.org/abs/2504.07108</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>奥斯卡：在线软压缩和重新播放</title>
      <link>https://arxiv.org/abs/2504.07109</link>
      <description><![CDATA[ARXIV：2504.07109V1公告类型：新 
摘要：检索增强的生成（RAG）通过整合外部知识来增强大语模型（LLM），从而提高准确性和相关性。但是，随着检索尺寸的增长，缩放抹布管道在计算上保持昂贵。为了解决这个问题，我们介绍了Oscar，这是一种新颖的查询在线软压缩方法，可在保留性能的同时降低计算开销。与传统的硬压缩方法（缩短了检索文本或软压缩方法）不同，将文档映射到连续的嵌入到离线的连续嵌入方式，奥斯卡在推理时间动态压缩了检索到的信息，消除了存储开销并启用了更高的压缩率。此外，我们延长了奥斯卡奖，以同时执行重新疗法，进一步优化了RAG管道的效率。我们的实验证明了最新的性能，其推理的加速为2-5倍，而LLMS的准确性范围为1B至24B参数，而准确性却没有损失。这些型号可在以下网址提供：https：//huggingface.co/collections/naver/oscar-67D446A8E3A2551F57464295。]]></description>
      <guid>https://arxiv.org/abs/2504.07109</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>dashclip：利用多模型为Doordash生成语义嵌入</title>
      <link>https://arxiv.org/abs/2504.07110</link>
      <description><![CDATA[ARXIV：2504.07110V1公告类型：新 
摘要：尽管视觉模型在各种生成任务中都取得了成功，但由于无法实现的实体模型捕获实体之间的细微关系，因此获得了产品和用户意图的高质量语义表示仍然具有挑战性。在本文中，我们通过对图像文本数据的对比学习来对齐单模式和多模式编码器，从而对产品和用户查询进行了联合培训框架。我们的小说方法使用LLM策划的相关性数据集训练查询编码器，从而消除了对参与历史的依赖。这些嵌入表现出强大的概括能力并提高应用程序的性能，包括产品分类和相关性预测。对于个性化的广告建议，部署后，点击率和转换率的明显提升进一步证实了对关键业务指标的影响。我们认为，我们的框架的灵活性使其成为丰富电子商务环境中用户体验的有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2504.07110</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI代理与在线广告相互作用吗？</title>
      <link>https://arxiv.org/abs/2504.07112</link>
      <description><![CDATA[ARXIV：2504.07112V1公告类型：新 
摘要：随着AI驱动的代理越来越多地集成到数字生态系统中，他们重塑了如何感知和处理在线广告。特别是在旅行和酒店预订领域，这些自主系统会影响传统广告格式的有效性。尽管视觉提示和情感吸引力影响了人类用户，但AI代理人优先考虑结构化数据，例如价格，可用性和规格。这项研究研究了不同的AI代理如何与在线广告相互作用，是否将广告纳入他们的决策过程中，以及哪种广告格式证明是最有效的。我们通过使用多模式模型（例如OpenAI GPT-4O，Anthropic Claude和Google Gemini 2.0 Flash）进行实验来分析互动模式，点击行为和决策策略。我们的发现表明，AI代理人既不忽略也不避免避免广告，而是偏爱某些特征尤其是关键字和结构化数据。这些见解对AI主导的数字环境中广告策略的未来设计具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2504.07112</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为了生成建议</title>
      <link>https://arxiv.org/abs/2504.07363</link>
      <description><![CDATA[ARXIV：2504.07363V1公告类型：新 
摘要：生成建议旨在了解整个项目的基本生成过程，以便为用户提出建议。尽管它利用非线性概率模型超过了线性因子模型的有限建模能力，但通常会受到表示能力和障碍性之间的权衡。随着基于预训练的语言模型（LMS）的新一代生成方法的兴起，将LMS纳入一般建议中，并与隐式反馈纳入了一般建议。但是，将它们适应生成建议仍然具有挑战性。核心原因在于输入输出格式与生成模型和LMS的语义之间的不匹配，因此在特征空间中实现最佳对齐是一项挑战。这项工作通过提出一个称为DMREC的模型不可静止的生成推荐框架来解决此问题，该框架引入了概率的元网络网络，以通过用户交互来桥接LMS的输出，从而启用了同等的概率建模过程。随后，我们设计了三个跨空间分布匹配过程，旨在最大化共享信息，同时保留每个空间的独特语义并滤除无关的信息。我们将DMREC应用于三种不同类型的生成推荐方法，并在三个公共数据集上进行广泛的实验。实验结果表明，DMREC可以有效地提高这些生成模型的建议性能，并且比主流LM增强建议方法具有显着优势。]]></description>
      <guid>https://arxiv.org/abs/2504.07363</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种新型的基于Mamba的顺序推荐方法</title>
      <link>https://arxiv.org/abs/2504.07398</link>
      <description><![CDATA[ARXIV：2504.07398V1公告类型：新 
摘要：编码用户活动以预测下一个动作的顺序推荐（SR）已成为开发商业个性化推荐系统的广泛采用的策略。尽管基于变压器的模型已被证明有效，可有效，但变压器中自发动模块的复杂性与序列长度四二次尺度。控制模型的复杂性对于大规模推荐系统至关重要，因为这些系统可能需要处理连续发展的十亿个词汇，以及可以超过数十万种长度的用户行为序列。在本文中，我们提出了一种新型的多头潜在Mamba体系结构，该体系结构采用多个低维的Mamba层和完全连接的层以及位置编码，以同时捕获每个潜在子空间中的历史和项目信息。我们提出的方法不仅可以扩展到大规模参数，而且还可以通过集成和微调LLMS扩展到多域推荐。通过在公共数据集上进行的广泛实验，我们演示了Hydra如何有效地解决有效性 - 效率困境，超过了最先进的顺序推荐基准，其参数明显较少，并且训练时间减少了。]]></description>
      <guid>https://arxiv.org/abs/2504.07398</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>紧急通信：基于OTFS的语义传输，扩散噪声抑制</title>
      <link>https://arxiv.org/abs/2504.07420</link>
      <description><![CDATA[ARXIV：2504.07420V1公告类型：新 
摘要：由于它们的灵活性和动态覆盖能力，无人驾驶飞机（UAV）已成为灾难地区紧急通信的重要平台。但是，高速移动场景中的复杂渠道条件显着影响传统通信系统的可靠性和效率。本文提出了一个智能的紧急通信框架，该框架集成了正交时频空间（OTFS）调制，语义通信以及基于扩散的DeNoising模块，以应对这些挑战。 OTF由于其出色的抗趋势特征和对快速变化的环境的适应性，可确保在动态通道条件下进行稳健的通信。语义通信通过专注于关键信息提取并减少数据冗余，从而进一步提高了传输效率。此外，提出了一个基于扩散的通道去涂模块，以利用逐渐减少降噪过程和统计噪声建模，从而优化语义信息恢复的准确性。实验结果表明，所提出的解决方案可显着提高链接稳定性和高速型无人机方案的传输性能，从而比现有方法至少实现了至少3DB SNR的增长。]]></description>
      <guid>https://arxiv.org/abs/2504.07420</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>llm4ranking：使用大型语言模型用于文档重新管理的易于使用的框架</title>
      <link>https://arxiv.org/abs/2504.07439</link>
      <description><![CDATA[ARXIV：2504.07439V1公告类型：新 
摘要：近年来，利用大型语言模型（LLMS）进行文档重新管理一直是一个受欢迎且有希望的研究方向，许多研究致力于提高使用LLMS用于reranking的性能和效率。此外，它也可以应用于许多现实世界中的应用程序，例如搜索引擎或检索型发电。为了响应在实践中对研究和应用的不断增长的需求，我们引入了一个统一的框架\ textbf {llm4ranking}，该框架使用户能够使用开源或基于封闭的API LLMS采用不同的排名方法。我们的框架提供了一个简单且可扩展的界面，用于使用LLMS重新播放文档，并为此任务易于使用评估和微调脚本。我们基于此框架进行了实验，并在几个广泛使用的数据集上评估了各种模型和方法，从而为利用LLMS用于文档重新管理提供了可重复性结果。我们的代码可在https://github.com/liuqi67777/llm4ranking上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2504.07439</guid>
      <pubDate>Fri, 11 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>