<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>集合编码器：使用交叉编码器进行列表式段落重排序的排列不变段落间注意</title>
      <link>https://arxiv.org/abs/2404.06912</link>
      <description><![CDATA[arXiv:2404.06912v2 公告类型：替换
摘要：交叉编码器是有效的段落重新排序器。但是，当一次对多个段落重新排序时，现有的交叉编码器无法有效地优化多个输入排列的输出排序，因为它们的段落交互不是排列不变的。此外，它们的高内存占用限制了列表训练期间的段落数量。为了解决这些问题，我们提出了 Set-Encoder，这是一种新的交叉编码器架构，它（1）通过并行通道处理引入通道间注意，以确保输入通道之间的排列不变性，并且（2）使用融合注意内核来一次可以进行更多段落的训练。在 TREC 深度学习和 TIREx 的实验中，Set-Encoder 比之前参数数量相似的交叉编码器更有效。与较大的模型相比，Set-Encoder 效率更高，并且达到同等水平甚至更有效。]]></description>
      <guid>https://arxiv.org/abs/2404.06912</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>从以模型为中心到以人为中心：修订距离作为法学硕士应用程序中文本评估的指标</title>
      <link>https://arxiv.org/abs/2404.07108</link>
      <description><![CDATA[arXiv:2404.07108v2 公告类型：replace-cross
摘要：评估大型语言模型（LLM）是基础，特别是在实际应用中。传统的评估方法通常主要为法学硕士开发而设计，产生的数字分数忽略了用户体验。因此，在人工智能驱动的写作辅助应用程序中，我们的研究重点从以模型为中心的评估转向以人为中心的评估。我们提出的指标称为“修订距离”，利用法学硕士来建议模仿人类写作过程的修订编辑。它是通过计算法学硕士生成的修订编辑来确定的。受益于生成的修订编辑详细信息，我们的指标可以以人类可理解的方式提供不言自明的文本评估结果，超越上下文无关的分数。我们的结果表明，对于简单的写作任务，“修订距离”与既定指标（ROUGE、Bert 分数和 GPT 分数）一致，但提供了更有洞察力、更详细的反馈并更好地区分文本。此外，在具有挑战性的学术写作任务的背景下，我们的指标仍然可以提供可靠的评估，而其他指标往往难以做到这一点。此外，我们的指标对于缺乏参考文本的场景也具有巨大的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.07108</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>OpenP5：用于开发、培训和评估基于 LLM 的推荐系统的开源平台</title>
      <link>https://arxiv.org/abs/2306.11134</link>
      <description><![CDATA[arXiv:2306.11134v2 公告类型：替换
摘要：近年来，将大型语言模型（LLM）集成到推荐系统中引起了从业者和研究人员的兴趣。尽管有这种兴趣，该领域仍然处于新兴阶段，缺乏开源研发平台可能会阻碍对基于法学硕士的推荐的探索。本文介绍了 OpenP5，这是一个开源平台，旨在促进基于 LLM 的生成推荐系统的开发、培训和评估以用于研究目的。该平台使用编码器-解码器 LLM（例如 T5）和仅解码器 LLM（例如 Llama-2）在 10 个广泛认可的公共数据集上实现，满足两个基本推荐任务：顺序推荐和直接推荐。认识到项目 ID 在基于 LLM 的推荐中的关键作用，我们还在 OpenP5 平台中引入了三种项目索引方法：随机索引、顺序索引和协作索引。该平台建立在 Transformers 库的基础上，有助于为用户轻松定制基于 LLM 的建议。 OpenP5 拥有一系列功能，包括可扩展的数据处理、以任务为中心的优化、全面的数据集和检查点、高效的加速和标准化的评估，使其成为基于 LLM 的推荐系统的实施和评估的宝贵工具。 OpenP5 库的开源代码和预训练检查点可在 https://github.com/agiresearch/OpenP5 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2306.11134</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>针对黑盒神经排序模型的多粒度对抗攻击</title>
      <link>https://arxiv.org/abs/2404.01574</link>
      <description><![CDATA[arXiv:2404.01574v2 公告类型：替换
摘要：对抗性排名攻击因其在探测漏洞方面的成功而受到越来越多的关注，从而增强了神经排名模型的鲁棒性。传统的攻击方法采用单一粒度（例如单词或句子级别）的扰动来瞄准文档。然而，将扰动限制在单一粒度级别可能会降低对抗性示例的灵活性，从而减少攻击的潜在威胁。因此，我们专注于通过结合多粒度扰动来生成高质量的对抗性示例。实现这一目标涉及解决组合爆炸问题，这需要在所有可能的粒度、位置和文本片段级别上确定扰动的最佳组合。为了应对这一挑战，我们将多粒度对抗攻击转变为顺序决策过程，其中下一个攻击步骤中的扰动建立在当前攻击步骤中扰动的文档的基础上。由于攻击过程只能在没有直接中间信号的情况下访问最终状态，因此我们使用强化学习来执行多粒度攻击。在强化学习过程中，两个代理协同工作，将多粒度漏洞识别为攻击目标，并将扰动候选者组织成最终的扰动序列。实验结果表明，我们的攻击方法在攻击有效性和不可察觉性方面都超过了主流基线。]]></description>
      <guid>https://arxiv.org/abs/2404.01574</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>利用堆叠分类系统检测微博数据中的金融机会</title>
      <link>https://arxiv.org/abs/2404.07224</link>
      <description><![CDATA[arXiv:2404.07224v1 公告类型：交叉
摘要：Twitter 社交网络等微博资源为市场预测模型提供了有价值的实时数据。该网络中投资者的观点跟随股票市场的波动，通常包括对可能影响其他投资者行为的市场机会的有根据的猜测。有鉴于此，我们提出了一种新颖的系统来检测推文中的积极预测，这是一种我们称之为“机会”的金融情绪，类似于普拉奇克理论中的“预期”。具体来说，我们寻求高检测精度，向金融运营商展示大量此类推文，同时将它们与我们系统中的其他金融情绪区分开来。我们通过三层堆叠机器学习分类系统来实现这一目标，该系统具有复杂的功能，这些功能是通过应用自然语言处理技术来提取有价值的语言信息而产生的。在手动标注了金融情绪和股票出现标签的数据集上的实验结果表明，我们的系统在金融机会检测方面产生了令人满意且有竞争力的性能，精度值高达 83%。这一有希望的结果认可了我们的系统支持投资者决策的可用性。]]></description>
      <guid>https://arxiv.org/abs/2404.07224</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>审核社交媒体中与健康相关的建议：YouTube 上堕胎的案例研究</title>
      <link>https://arxiv.org/abs/2404.07896</link>
      <description><![CDATA[arXiv:2404.07896v1 公告类型：交叉
摘要： YouTube 等社交媒体使用的推荐算法 (RS) 极大地影响了我们在各个领域的信息消费，尤其是在医疗保健领域。因此，算法审计对于发现潜在的偏见和错误信息至关重要，特别是在堕胎等有争议的话题背景下。我们引入了一种简单而有效的袜子木偶审核方法来调查 YouTube 如何向不同背景的个人推荐与堕胎相关的视频。无论底层算法的复杂性如何，我们的框架都可以对 RS 进行高效审核]]></description>
      <guid>https://arxiv.org/abs/2404.07896</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>一种有效的、独立于领域的监督关键短语提取和排名方法</title>
      <link>https://arxiv.org/abs/2404.07954</link>
      <description><![CDATA[arXiv:2404.07954v1 公告类型：新
摘要：我们提出了一种监督学习方法，用于从单个文档中自动提取关键短语。我们的解决方案使用简单的方法来计算候选短语的统计和位置特征，并且不依赖于任何外部知识库或预先训练的语言模型或词嵌入。我们提出的解决方案的排名组件是一个相当轻量级的集成模型。对基准数据集的评估表明，我们的方法比几种最先进的基线模型（包括所有基于深度学习的无监督模型）实现了显着更高的准确性，并且与一些基于监督深度学习的模型也具有竞争力。尽管我们的解决方案具有监督性质，但不依赖任何“黄金”关键字语料库或任何外部知识语料库的事实意味着我们的解决方案在相当程度上具有无监督解决方案的优势。]]></description>
      <guid>https://arxiv.org/abs/2404.07954</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>操纵大型语言模型以提高产品可见性</title>
      <link>https://arxiv.org/abs/2404.07981</link>
      <description><![CDATA[arXiv:2404.07981v1 公告类型：新
摘要：大型语言模型（LLM）越来越多地集成到搜索引擎中，以提供针对用户查询定制的自然语言响应。客户和最终用户也越来越依赖这些模型来快速、轻松地做出购买决策。在这项工作中，我们调查了是否可以操纵法学硕士的推荐来提高产品的知名度。我们证明，在产品的信息页面中添加战略文本序列（STS）（一条精心设计的消息）可以显着增加其被列为法学硕士首选推荐的可能性。为了了解 STS 的影响，我们使用了一个虚构的咖啡机目录，并分析了它对两种目标产品的影响：一种很少出现在法学硕士的推荐中，另一种通常排名第二。我们观察到，战略性文本序列通过增加两种产品出现为热门推荐的机会，显着提高了它们的可见性。这种操纵 LLM 生成的搜索响应的能力为供应商提供了相当大的竞争优势，并有可能扰乱公平的市场竞争。正如搜索引擎优化 (SEO) 彻底改变了网页的定制方式，使其在搜索引擎结果中排名更高，影响法学硕士的推荐可能会对人工智能驱动的搜索服务的内容优化产生深远的影响。我们的实验代码可在 https://github.com/aounon/llm-rank-optimizer 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07981</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>通过信息对齐实现推荐中的个性化公平的自适应公平表示学习</title>
      <link>https://arxiv.org/abs/2404.07494</link>
      <description><![CDATA[arXiv:2404.07494v1 公告类型：新
摘要：推荐中的个性化公平性越来越受到研究者的关注。现有的工作通常将表示为敏感属性集合的公平性要求视为超参数，并通过从学习到的公平嵌入中完全去除敏感属性信息来追求极端公平，这面临两个挑战：产生巨大的训练成本属性组合的爆炸性增长，以及公平性和准确性之间的次优权衡。在本文中，我们提出了一种新颖的自适应公平表示学习（AFRL）模型，由于其在推理阶段仅训练一个模型来自适应地满足不同公平性要求的优点，因此实现了真正的个性化公平性。特别是，AFRL将公平性要求作为输入，可以从不公平的用户嵌入中学习每个属性的属性特定嵌入，这赋予AFRL在推理阶段的适应性，以在用户独特的公平性要求的指导下确定非敏感属性。为了在推荐的公平性和准确性之间实现更好的权衡，AFRL 进行了一种新颖的信息对齐，以准确保留非敏感属性的判别性信息，并将去偏协作嵌入纳入公平嵌入中，以捕获属性无关的协作信号，而不会丢失的公平性。最后，在真实数据集上进行的广泛实验以及合理的理论分析证明了 AFRL 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.07494</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以评估推荐系统中的偶然性吗？</title>
      <link>https://arxiv.org/abs/2404.07499</link>
      <description><![CDATA[arXiv:2404.07499v1 公告类型：新
摘要：面向偶然性的推荐系统旨在抵消用户偏好的过度专业化。然而，由于其情感本质，评估用户对推荐项目的偶然反应可能具有挑战性。在本研究中，我们通过利用可以执行各种任务的大型语言模型（LLM）的丰富知识来解决这个问题。首先，这项研究探讨了法学硕士偶然做出的评估与人类做出的评估之间的一致性。在这项调查中，法学硕士被赋予了一个二元分类任务来预测用户是否会偶然找到推荐的项目。测量了三个法学硕士在基准数据集上的预测表现，在该基准数据集中，人类分配了偶然项目的基本事实。实验结果表明，基于法学硕士的评估方法与人类评估的一致性并不高。然而，它们的表现与基线方法一样好甚至更好。进一步的验证结果表明，应仔细选择提供给 LLM 提示的用户评分历史记录的数量，以避免输入不足和过多，并且显示高分类性能的 LLM 的输出难以解释。]]></description>
      <guid>https://arxiv.org/abs/2404.07499</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>M-scan：多场景因果驱动的自适应推荐网络</title>
      <link>https://arxiv.org/abs/2404.07581</link>
      <description><![CDATA[arXiv:2404.07581v1 公告类型：新
摘要：我们主要关注多场景推荐领域，这对有效利用不同场景的数据来增强数据有限的场景中的预测提出了重大挑战。当前的主流工作主要集中在创新的模型网络架构上，目的是使网络能够隐式地从不同场景中获取知识。然而，网络中隐式学习的不确定性是由于缺乏显式建模而产生的，不仅导致训练困难，而且导致用户表示不完整和性能不理想。此外，通过因果图分析，我们发现场景本身直接影响点击行为，而现有方法在当前场景的训练过程中直接融入其他场景的数据，直接利用其他场景的点击行为来预测会出现预测偏差。火车模型。为了解决这些问题，我们提出了多场景因果驱动的自适应网络 M-scan）。该模型采用了场景感知共同注意机制，可以从与当前场景相符的其他场景中明确提取用户兴趣。此外，它还采用场景偏差消除器模块，利用因果反事实推理来减轻其他场景数据引入的偏差。对两个公共数据集的广泛实验证明了我们的 M 扫描与现有基线模型相比的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.07581</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>混合 RAG：通过语义搜索和基于混合查询的检索器提高 RAG（检索器增强生成）准确性</title>
      <link>https://arxiv.org/abs/2404.07220</link>
      <description><![CDATA[arXiv:2404.07220v1 公告类型：新
摘要：检索增强生成（RAG）是将文档的私有知识库与大型语言模型（LLM）相结合来构建生成式问答（Question-Answering）系统的一种流行方法。然而，随着文档语料库规模的扩大，RAG 准确性变得越来越具有挑战性，检索器通过从语料库中提取最相关的文档为法学硕士提供上下文，在整体 RAG 准确性中发挥着巨大的作用。在本文中，我们提出了利用语义搜索技术（例如密集向量索引和稀疏编码器索引）与混合查询策略混合的“混合 RAG”方法。我们的研究取得了更好的检索结果，并为 NQ 和 TREC-COVID 数据集等 IR（信息检索）数据集设定了新的基准。我们进一步将这种“混合检索器”扩展到 RAG 系统，以在 SQUAD 等生成问答数据集上展示出远远优越的结果，甚至超越了微调性能。]]></description>
      <guid>https://arxiv.org/abs/2404.07220</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>改进基于 RAG 的财务文档问答模型的检索</title>
      <link>https://arxiv.org/abs/2404.07221</link>
      <description><![CDATA[arXiv:2404.07221v1 公告类型：新
摘要：大型语言模型（LLM）生成准确响应的有效性在很大程度上依赖于所提供输入的质量，特别是在采用检索增强生成（RAG）技术时。 RAG 通过获取最相关的文本块作为查询基础来增强法学硕士。尽管近年来法学硕士的回答质量取得了显着进步，但用户仍然可能会遇到不准确或不相关的答案；这些问题通常源于 RAG 的次优文本块检索，而不是法学硕士的固有能力。为了提高法学硕士的效率，完善 RAG 流程至关重要。本文探讨了 RAG 管道的现有限制，并介绍了增强文本检索的方法。它深入研究了复杂的分块技术、查询扩展、元数据注释的合并、重新排序算法的应用以及嵌入算法的微调等策略。实施这些方法可以显着提高检索质量，从而提高法学硕士在处理和响应查询方面的整体性能和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2404.07221</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>不让任何人掉队：在线自监督自蒸馏顺序推荐</title>
      <link>https://arxiv.org/abs/2404.07219</link>
      <description><![CDATA[arXiv:2404.07219v1 公告类型：新
摘要：顺序推荐方法在现代推荐系统中发挥着至关重要的作用。一个关键的挑战在于在数据稀疏的情况下准确建模用户偏好。为了应对这一挑战，最近的方法利用对比学习（CL）通过最大化原始用户行为序列的两个增强视图的互信息来导出自我监督信号。尽管基于 CL 的方法很有效，但在充分利用行为数据有限的用户的自我监督信号方面遇到了限制，因为具有广泛行为的用户自然会提供更多信息。为了解决这个问题，我们引入了一种新颖的学习范式，称为在线自监督自蒸馏顺序推荐（$S^4$Rec），有效地弥合了自监督学习和自蒸馏方法之间的差距。具体来说，我们采用在线聚类来根据用户不同的潜在意图熟练地对用户进行分组。此外，利用对抗性学习策略来确保聚类过程不受行为长度因素的影响。随后，我们采用自蒸馏来促进知识从具有广泛行为的用户（教师）转移到具有有限行为的用户（学生）。在四个真实世界数据集上进行的实验验证了所提出方法的有效性\脚注{代码可在https://github.com/xjaw/S4Rec获取]]></description>
      <guid>https://arxiv.org/abs/2404.07219</guid>
      <pubDate>Fri, 12 Apr 2024 06:17:38 GMT</pubDate>
    </item>
    </channel>
</rss>