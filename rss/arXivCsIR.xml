<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.IR 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 在 arXiv.org 电子印刷档案上进行更新。</description>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用行为日志进行通用用户建模：Snapchat 案例研究</title>
      <link>https://arxiv.org/abs/2312.12111</link>
      <description><![CDATA[arXiv:2312.12111v2 公告类型：replace-cross 
摘要：基于用户行为日志学习通用用户表示是一种越来越流行的用户建模方法。它受益于易于获取、隐私友好且富有表现力的数据，并且不需要对上游用户模型进行大量重新调整以适应不同的下游任务。虽然这种方法在搜索引擎和电子商务应用程序中显示出良好的前景，但它是否适合即时通讯平台（现代数字通信的基石）仍然很大程度上未知。我们使用 Snapchat 数据作为案例研究来探索这一研究空白。具体来说，我们实现了一个基于 Transformer 的用户模型，具有定制的训练目标，并表明该模型可以在广泛的评估任务中产生高质量的用户表示，其中我们引入了三个新的下游任务，这些任务涉及用户研究的关键主题：用户安全、参与度和流失。我们还通过应用一种新颖的位置编码方法来解决在推理时有效推断长序列的挑战。]]></description>
      <guid>https://arxiv.org/abs/2312.12111</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>理解并减轻 Vec2Text 对密集检索系统的威胁</title>
      <link>https://arxiv.org/abs/2402.12784</link>
      <description><![CDATA[arXiv:2402.12784v2 公告类型：替换 
摘要：Vec2Text（一种文本嵌入反转方法）的出现引发了对使用文本嵌入的密集检索系统的严重隐私担忧，例如 OpenAI 和 Cohere 提供的系统。这种威胁来自于能够访问嵌入的恶意攻击者重建原始文本的能力。在本文中，我们研究了与嵌入模型相关的各种因素，这些因素可能会影响通过 Vec2Text 实现的文本可恢复性。我们探讨了距离度量、池化函数、瓶颈预训练、添加噪声的训练、嵌入量化和嵌入维度等因素，这些因素在原始 Vec2Text 论文中没有考虑到。通过对这些因素的全面分析，我们的目标是更深入地了解影响密集检索系统的文本可恢复性和检索有效性之间权衡的关键因素，为设计隐私感知密集检索系统的从业者提供见解。我们还提出了一种简单的嵌入转换修复方法，可保证排名效果相同，同时降低可恢复性风险。总体而言，这项研究表明 Vec2Text 可能对当前的密集检索系统构成威胁，但也有一些有效的方法可以修补此类系统。]]></description>
      <guid>https://arxiv.org/abs/2402.12784</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>利用社会科学的测量知识改进立场检测：以荷兰政治推文和传统性别角色划分为例</title>
      <link>https://arxiv.org/abs/2212.06543</link>
      <description><![CDATA[arXiv:2212.06543v2 公告类型：替换交叉
摘要：立场检测 (SD) 涉及自动确定文本作者对目标的观点（即赞成、反对或中立）。 SD 已应用于许多研究课题，其中检测政治推文背后的立场是一个重要课题。 在本文中，我们将 SD 应用于 2017 年至 2021 年荷兰官方政党账户的推文数据集，重点关注对传统性别角色划分的立场，这是（一些）荷兰政党之间的分歧问题。 为了实施和改进传统性别角色划分的 SD，我们建议利用社会科学中已建立的调查工具，该工具已被验证可用于衡量对传统性别角色划分的态度。 根据我们的实验，我们表明使用这种经过验证的调查工具有助于提高 SD 性能。]]></description>
      <guid>https://arxiv.org/abs/2212.06543</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>我可以听但不能读：对双塔多模式系统仪器识别的评估</title>
      <link>https://arxiv.org/abs/2407.18058</link>
      <description><![CDATA[arXiv:2407.18058v1 公告类型：交叉 
摘要：音乐双塔多模态系统将音频和文本模态集成到联合音频文本空间中，从而可以直接比较歌曲及其相应的标签。这些系统利用这两种模态，为分类和检索提供了新方法。尽管它们在零样本分类和检索任务中显示出了有希望的结果，但仍需要更仔细地检查嵌入。本文评估了联合音频文本空间固有的零样本属性，以用于乐器识别案例研究。我们对零样本乐器识别的双塔系统进行了评估和分析，并对预联合和联合嵌入空间的属性进行了详细分析。我们的研究结果表明，音频编码器本身就表现出良好的质量，而文本编码器或联合空间投影仍然存在挑战。具体而言，双塔系统对特定单词表现出敏感性，偏爱通用提示而不是音乐提示。尽管文本编码器规模庞大，但它们尚未利用额外的文本上下文或从其描述中准确推断乐器。最后，提出了一种利用乐器本体量化文本空间语义意义的新方法。该方法揭示了系统对乐器理解的不足，并提供了需要对音乐数据上的文本编码器进行微调的证据。]]></description>
      <guid>https://arxiv.org/abs/2407.18058</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>连接项目和语言：基于大型语言模型的推荐的过渡范式</title>
      <link>https://arxiv.org/abs/2310.06491</link>
      <description><![CDATA[arXiv:2310.06491v2 公告类型：替换 
摘要：利用大型语言模型 (LLM) 进行推荐正在迅速兴起，它依赖于两个基本步骤来连接推荐项目空间和语言空间：1) 项目索引利用标识符来表示语言空间中的项目，2) 生成基础将 LLM 生成的标记序列与语料库中的项目相关联。然而，以前的方法在这两个步骤中表现出固有的局限性。现有的基于 ID 的标识符（例如数字 ID）和基于描述的标识符（例如标题）要么失去语义，要么缺乏足够的独特性。此外，先前的生成基础方法可能会生成无效的标识符，从而与语料库中的项目不一致。为了解决这些问题，我们提出了一种基于 LLM 的推荐器（名为 TransRec）的新型转换范式来连接项目和语言。具体来说，TransRec 提出了多方面标识符，它同时结合了 ID、标题和属性来进行项目索引，以追求独特性和语义。此外，我们为 TransRec 引入了一种专门的数据结构，以确保只生成有效的标识符，并利用子字符串索引来鼓励 LLM 从任何位置生成标识符。最后，TransRec 提出了一个聚合基础模块，利用生成的多方面标识符有效地对语料库中的项目进行排名。我们在两个骨干模型 BART-large 和 LLaMA-7B 上实例化了 TransRec。在不同设置下对三个真实数据集的大量结果验证了 TransRec 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2310.06491</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>揭示突发事件背景下的合法性：通过主题建模分析对信息系统咨询公司和国际组织进行调查</title>
      <link>https://arxiv.org/abs/2407.17509</link>
      <description><![CDATA[arXiv:2407.17509v1 公告类型：交叉 
摘要：在日益动态和现代化的市场中，意外事件的反复发生需要信息系统 (IS) 利益相关者的积极响应。每个 IS 参与者都努力使其行为合法化并传达其战略。本研究深入研究了 IS 合法化领域，重点关注两个关键利益相关者的沟通：IS 咨询公司和国际组织，特别是在意外事件的背景下。为了实现这一目标，我们研究了这两个参与者发布的各种出版物。采用主题建模方法，我们分析了这些文档以提取有关其合法化方法的宝贵见解。通过这项研究，我们旨在通过探索两个关键 IS 利益相关者如何应对意外事件带来的挑战，为合法化话语文献做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2407.17509</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>BLAZE：通过动态分块和硬示例学习实现跨语言和跨项目错误本地化</title>
      <link>https://arxiv.org/abs/2407.17631</link>
      <description><![CDATA[arXiv:2407.17631v1 公告类型：交叉 
摘要：软件错误需要开发人员付出巨大努力来识别和解决它们，通常会耗费他们大约三分之一的时间。错误本地化，即精确定位需要修改的源代码文件的过程，对于减少这种工作量至关重要。现有的错误本地化工具通常依赖于深度学习技术，在多语言环境中的跨项目适用性和有效性方面受到限制。大型语言模型 (LLM) 的最新进展为错误本地化提供了详细的表示。然而，他们在上下文窗口有限和映射准确性方面遇到了挑战。为了解决这些问题，我们提出了 BLAZE，一种采用动态分块和硬示例学习的方法。首先，BLAZE 动态分段源代码以最大限度地减少连续性损失。然后，BLAZE 使用具有挑战性的错误案例微调基于 GPT 的模型，以增强跨项目和跨语言的错误本地化。为了支持 BLAZE 的功能，我们创建了 BEETLEBOX 数据集，其中包含来自 29 个大型且蓬勃发展的开源项目的 26,321 个错误，这些项目涉及五种不同的编程语言（Java、C++、Python、Go 和 JavaScript）。我们在三个基准数据集 BEETLEBOX、SWE-Bench 和 Ye et al. 上对 BLAZE 的评估表明，与六个最先进的基线相比，BLAZE 有显著的改进。具体而言，BLAZE 的 Top 1 准确率提高了 120%，平均准确率 (M​​AP) 提高了 144%，平均倒数排名 (MRR) 提高了 100%。广泛的消融研究证实了我们的管道组件对整体性能提升的贡献。]]></description>
      <guid>https://arxiv.org/abs/2407.17631</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>用于论文来源追踪的文本驱动神经协同过滤模型</title>
      <link>https://arxiv.org/abs/2407.17722</link>
      <description><![CDATA[arXiv:2407.17722v1 公告类型：新
摘要：在引文知识图谱的复杂相互关系中识别重要参考文献是一项挑战，它包含通过引文、作者、关键字和其他关系属性建立的联系。论文来源追踪 (PST) 任务旨在利用先进的数据挖掘技术自动识别给定学术文章的关键参考文献。在 KDD CUP 2024 中，我们设计了一个针对 PST 任务量身定制的基于推荐的框架。该框架采用神经协同过滤 (NCF) 模型来生成最终预测。为了处理论文的文本属性并提取模型的输入特征，我们使用了预训练语言模型 SciBERT。根据实验结果，我们的方法在平均准确率 (M​​AP) 指标上获得了 0.37814 的分数，优于基线模型，在所有参赛队伍中排名第 11 位。源代码可在https://github.com/MyLove-XAB/KDDCupFinal公开获取。]]></description>
      <guid>https://arxiv.org/abs/2407.17722</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>通过对子序列进行临时操作来丰富样本，以实现顺序推荐</title>
      <link>https://arxiv.org/abs/2407.17802</link>
      <description><![CDATA[arXiv:2407.17802v1 公告类型：新
摘要：顺序推荐利用交互序列来预测即将到来的用户行为，这对于制定个性化推荐至关重要。然而，用户的真实偏好本质上是复杂且高维的，而观察到的数据仅仅是丰富偏好的简化和低维投影，这通常会导致数据稀疏和模型训练不准确等普遍问题。为了从稀疏数据中学习真实偏好，大多数现有工作都试图引入一些额外的信息或设计一些巧妙的模型。虽然它们已被证明是有效的，但额外的信息通常会增加数据收集的成本，而复杂的模型可能会导致部署困难。创新的是，我们避免使用额外的信息或对模型进行更改；相反，我们用随机性填充观察到的数据和底层偏好之间的转换空间。具体来说，我们提出了一种新颖的与模型无关且高度通用的序列推荐框架，称为通过对子序列进行临时操作进行样本丰富 (SETO)，它通过训练中具有合理性约束的序列增强操作临时且单独地丰富转换空间。转换空间不仅存在于从输入样本到偏好的过程中，也存在于偏好到目标样本的过程中。我们强调了 SETO 在多个代表性和最先进的序列推荐模型（包括六个单域序列模型和两个跨域序列模型）上的有效性和多功能性，这些模型跨越多个真实世界数据集（包括三个单域数据集、三个跨域数据集和一个大型行业数据集）。]]></description>
      <guid>https://arxiv.org/abs/2407.17802</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>注释法律数据的挑战和考虑：全面概述</title>
      <link>https://arxiv.org/abs/2407.17503</link>
      <description><![CDATA[arXiv:2407.17503v1 公告类型：新
摘要：法律领域内的数据注释过程充满了与其他领域不同的独特挑战，这主要是由于法律语言和文档固有的复杂性。初始任务通常涉及选择适当的原始数据集以捕获法律文本的复杂方面。此后，提取文本成为一项复杂的任务，因为法律文件通常具有复杂的结构、脚注、参考文献和独特的术语。在这种情况下，数据清理的重要性被放大，确保在保留关键法律细节和背景的同时消除冗余信息。创建全面而直接的注释指南势在必行，因为这些指南是保持统一性和解决法律术语细微差别的路线图。另一个关键方面是法律专业人士参与注释过程。他们的专业知识对于确保数据不仅保持上下文准确性而且遵守现行的法律标准和解释非常有价值。本文对这些挑战进行了更深入的阐述，旨在为从事法律数据注释项目的研究人员和专业人员提供基础理解和指导。此外，我们还提供了我们创建和微调的数据集和语言模型的链接。这些资源是我们讨论的项目的成果，也是在工作过程中遇到的挑战的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2407.17503</guid>
      <pubDate>Fri, 26 Jul 2024 06:21:14 GMT</pubDate>
    </item>
    </channel>
</rss>