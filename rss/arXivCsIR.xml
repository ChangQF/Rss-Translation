<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.IR 更新</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR 更新了 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 08 Mar 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>推荐系统的连续输入嵌入大小搜索</title>
      <link>https://arxiv.org/abs/2304.03501</link>
      <description><![CDATA[arXiv:2304.03501v4 公告类型：替换
摘要：潜在因素模型由于其突出的性能而成为当今推荐系统最受欢迎的骨干。潜在因子模型将用户和项目表示为用于成对相似性计算的实值嵌入向量，并且所有嵌入传统上都限制为相对较大的统一大小（例如，256 维）。随着当代电子商务中用户群和商品目录呈指数级增长，这种设计无疑变得内存效率低下。为了促进轻量级推荐，强化学习（RL）最近为识别不同用户/项目的不同嵌入大小提供了机会。然而，受到搜索效率和学习最佳强化学习策略的挑战，现有的基于强化学习的方法仅限于高度离散、预定义的嵌入大小选择。这导致在嵌入大小中引入更细的粒度以在给定内存预算下获得更好的推荐效果的潜力在很大程度上被忽视。在本文中，我们提出了连续输入嵌入大小搜索（CIESS），这是一种基于强化学习的新颖方法，该方法在连续搜索空间上运行，可以选择任意嵌入大小。在 CIESS 中，我们进一步提出了一种创新的基于随机游走的探索策略，使 RL 策略能够有效地探索更多候选嵌入大小并收敛到更好的决策。 CIESS 也是模型不可知的，因此可推广到各种潜在因子 RS，而对两个现实世界数据集的实验表明，当与三种流行的推荐模型配对时，CIESS 在不同的内存预算下具有最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2304.03501</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的预算嵌入表</title>
      <link>https://arxiv.org/abs/2310.14884</link>
      <description><![CDATA[arXiv:2310.14884v5 公告类型：替换
摘要：当代推荐系统（RS）的核心是为用户提供优质推荐体验的潜在因素模型。这些模型使用嵌入向量（通常具有统一且固定的大小）来表示用户和项目。随着用户和项目数量的不断增长，这种设计变得效率低下且难以扩展。最近的轻量级嵌入方法使不同的用户和项目能够具有不同的嵌入大小，但通常存在两个主要缺点。首先，他们将嵌入大小搜索限制为优化平衡推荐质量和内存复杂性的启发式算法，其中需要针对每个请求的内存预算手动调整权衡系数。隐式强制执行的内存复杂性项甚至可能无法限制参数使用，从而导致生成的嵌入表无法严格满足内存预算。其次，大多数解决方案，尤其是基于强化学习的解决方案，都会逐个实例地推导和优化每个用户/项目的嵌入大小，这会阻碍搜索效率。在本文中，我们提出了预算嵌入表（BET），这是一种生成表级操作（即所有用户和项目的嵌入大小）的新颖方法，保证满足预先指定的内存预算。此外，通过利用基于集合的动作公式和参与集合表示学习，我们提出了一种创新的动作搜索策略，该策略由动作适应度预测器提供支持，可有效评估每个表级动作。实验表明，当 BET 与不同内存预算下的三种流行推荐模型配对时，在两个现实数据集上表现出了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2310.14884</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:28 GMT</pubDate>
    </item>
    <item>
      <title>RATSF：通过检索增强时间序列预测增强客户服务量管理</title>
      <link>https://arxiv.org/abs/2403.04180</link>
      <description><![CDATA[arXiv:2403.04180v1 公告类型：交叉
摘要：高效的客户服务管理系统取决于对服务量的精确预测。在这种数据非平稳性明显的情况下，成功的预测在很大程度上依赖于识别和利用类似的历史数据，而不仅仅是总结周期性模式。基于 RNN 或 Transformer 架构的现有模型常常难以实现这种灵活有效的利用。为了应对这一挑战，我们提出了一种高效且适应性强的交叉注意力模块，称为 RACA，它在预测任务中有效利用历史片段，并且我们设计了一种用于查询历史序列的精确表示方案，并结合知识库的设计。这些关键组件共同构成了我们的检索增强时间序列预测框架 (RATSF)。 RATSF不仅显着提升了飞猪酒店服务量预测的性能，更重要的是可以无缝集成到其他基于Transformer的跨应用场景的时间序列预测模型中。广泛的实验验证了该系统设计在多种不同环境中的有效性和通用性。]]></description>
      <guid>https://arxiv.org/abs/2403.04180</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:27 GMT</pubDate>
    </item>
    <item>
      <title>ALTO：复合人工智能系统的高效网络编排器</title>
      <link>https://arxiv.org/abs/2403.04311</link>
      <description><![CDATA[arXiv:2403.04311v1 公告类型：交叉
摘要：我们提出了 ALTO，一种网络编排器，用于高效地服务于复合 AI 系统，例如语言模型管道。 ALTO 通过利用特定于生成语言模型的优化机会：流式中间输出来实现高吞吐量和低延迟。当语言模型逐个生成输出时，ALTO 提供了在可能的情况下在阶段之间传输中间输出的机会。我们强调了在分布式管道阶段实例之间传输中间数据时出现的两个新挑战：正确性和负载平衡。我们还激发了对聚合感知路由接口和分布式提示感知调度的需求，以应对这些挑战。我们展示了 ALTO 的部分输出流对复杂的聊天机器人验证管道的影响，与基线服务方法相比，对于 4 秒/请求的固定延迟目标，吞吐量提高了 3 倍，同时尾部延迟也减少了 1.8 倍。]]></description>
      <guid>https://arxiv.org/abs/2403.04311</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:27 GMT</pubDate>
    </item>
    <item>
      <title>现实世界中图神经网络的调查：不平衡、噪声、隐私和 OOD 挑战</title>
      <link>https://arxiv.org/abs/2403.04468</link>
      <description><![CDATA[arXiv:2403.04468v1 公告类型：交叉
摘要：图结构数据在社交网络分析、生物化学、金融欺诈检测和网络安全等不同领域中表现出普遍性和广泛的适用性。利用图神经网络 (GNN) 在这些领域取得了显着的成功。然而，在现实场景中，模型的训练环境往往很不理想，导致GNN模型的性能因各种不利因素而大幅下降，包括数据分布不平衡、错误数据中存在噪声、隐私保护等。敏感信息以及分布外 (OOD) 场景的泛化能力。为了解决这些问题，人们投入了大量精力来提高 GNN 模型在实际场景中的性能，并增强其可靠性和鲁棒性。在本文中，我们提出了一项全面的调查，系统地回顾了现有的 GNN 模型，重点关注了许多现有评论未考虑到的实际场景中提到的四个现实挑战的解决方案，包括不平衡、噪声、隐私和 OOD。具体来说，我们首先强调现有 GNN 面临的四个关键挑战，为我们探索现实世界的 GNN 模型铺平道路。随后，我们对这四个方面进行了详细讨论，剖析这些解决方案如何有助于增强 GNN 模型的可靠性和鲁棒性。最后但并非最不重要的一点是，我们概述了有希望的方向并提供了该领域的未来前景。]]></description>
      <guid>https://arxiv.org/abs/2403.04468</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:27 GMT</pubDate>
    </item>
    <item>
      <title>第二届生成模型推荐研讨会</title>
      <link>https://arxiv.org/abs/2403.04399</link>
      <description><![CDATA[arXiv:2403.04399v1 公告类型：新
摘要：生成模型的兴起推动了推荐系统的显着进步，为增强用户的个性化推荐留下了独特的机会。该研讨会为研究人员提供了一个平台，探索和交流与生成模型集成到推荐系统相关的创新概念。它主要关注五个关键观点：（i）改进推荐算法，（ii）生成个性化内容，（iii）发展用户系统交互范式，（iv）增强可信度检查，以及（v）完善生成推荐的评估方法。随着生成模型的快速发展，越来越多的研究正在这些领域涌现，强调了本次研讨会的及时性和至关重要性。相关研究将为推荐系统引入创新技术，并为学术界和工业界带来新的挑战。从长远来看，这个研究方向有可能彻底改变传统的推荐范式，并促进下一代推荐系统的发展。]]></description>
      <guid>https://arxiv.org/abs/2403.04399</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:26 GMT</pubDate>
    </item>
    <item>
      <title>Ducho 2.0：面向多模态推荐的更新的特征提取和处理框架</title>
      <link>https://arxiv.org/abs/2403.04503</link>
      <description><![CDATA[arXiv:2403.04503v1 公告类型：新
摘要：在这项工作中，我们介绍了 Ducho 2.0，这是我们框架的最新稳定版本。与 Ducho 不同的是，Ducho 2.0 通过定义和导入针对特定任务和数据集进行微调的自定义提取模型，提供了更加个性化的用户体验。此外，新版本能够通过多模态设计的大型模型来提取和处理特征。值得注意的是，所有这些新功能都通过优化数据加载和存储到本地内存来支持。为了展示 Ducho 2.0 的功能，我们演示了一个完整的多模式推荐流程，从提取/处理到最终推荐。其想法是为从业者和经验丰富的学者提供一个随时可用的工具，将其置于任何多模式推荐框架之上，可以让他们进行广泛的基准分析。所有材料均可从以下网址获取：\url{https://github.com/sisinflab/Ducho}。]]></description>
      <guid>https://arxiv.org/abs/2403.04503</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:26 GMT</pubDate>
    </item>
    <item>
      <title>绿色AI时代的标杆新闻推荐</title>
      <link>https://arxiv.org/abs/2403.04736</link>
      <description><![CDATA[arXiv:2403.04736v1 公告类型：新
摘要：近年来，新闻推荐系统在学术界和工业界引起了极大的关注，强调需要一个标准化的基准来评估和比较这些系统的性能。同时，绿色人工智能倡导减少机器学习的能源消耗和环境影响。为了解决这些问题，我们引入了第一个用于新闻推荐的绿色人工智能基准测试框架，称为 GreenRec，并提出了一个用于评估推荐准确性和效率之间权衡的指标。我们的基准测试涵盖 30 个基本模型及其变体，涵盖传统的端到端训练范例以及我们提出的高效仅编码一次 (OLEO) 范例。通过消耗 2000 个 GPU 小时的实验，我们观察到，与最先进的端到端范例相比，OLEO 范例实现了有竞争力的准确性，并在可持续性指标方面实现了高达 2992% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2403.04736</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:26 GMT</pubDate>
    </item>
    <item>
      <title>小语言模型可以成为顺序推荐的良好推理机吗？</title>
      <link>https://arxiv.org/abs/2403.04260</link>
      <description><![CDATA[arXiv:2403.04260v1 公告类型：新
摘要：大型语言模型（LLM）由于其卓越的语言理解和生成能力，为顺序推荐开辟了新的视野。然而，要成功实施法学硕士授权的顺序建议，仍然存在许多挑战需要解决。首先，用户行为模式通常很复杂，仅依赖法学硕士的一步推理可能会导致不正确或与任务无关的响应。其次，LLM（例如 ChatGPT-175B）的资源要求极高，对于真正的顺序推荐系统来说是不切实际的。在本文中，我们提出了一种新颖的逐步知识蒸馏推荐框架（SLIM），为顺序推荐者以“苗条”（即资源高效）的方式享受LLM的卓越推理能力铺平了一条有希望的道路。我们为更大的教师模型引入了基于用户行为序列的 CoT 提示。然后，将教师模型生成的基本原理用作标签来提取下游较小的学生模型（例如 LLaMA2-7B）。这样，学生模型就获得了推荐任务中的逐步推理能力。我们将学生模型生成的基本原理编码为密集向量，这可以在基于 ID 和 ID 不可知的场景中提供推荐。大量的实验证明了 SLIM 相对于最先进的基线的有效性，进一步的分析展示了它以可承受的成本生成有意义的推荐推理的能力。]]></description>
      <guid>https://arxiv.org/abs/2403.04260</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:25 GMT</pubDate>
    </item>
    <item>
      <title>SSDRec：用于顺序推荐的自增强序列去噪</title>
      <link>https://arxiv.org/abs/2403.04278</link>
      <description><![CDATA[arXiv:2403.04278v1 公告类型：新
摘要：传统的序列推荐方法假设用户的序列数据足够干净，可以学习准确的序列表示来反映用户的偏好。在实践中，用户的序列不可避免地包含噪声（例如，意外交互），导致用户偏好的错误反映。因此，一些先驱研究探索了对序列中的顺序性和相关性进行建模，以隐式或显式地减少噪声的影响。然而，仅依赖可用的序列内信息（即序列中的顺序性和相关性）是不够的，并且可能导致去噪过度和去噪不足问题（OUP），特别是对于短序列。为了提高可靠性，我们建议通过在去噪之前插入项目来增强序列。然而，由于数据稀疏问题和计算成本，从整个项目域中选择合适的项目并将其插入到目标序列中的正确位置具有挑战性。受上述观察的启发，我们提出了一种新颖的框架——用于顺序推荐的自增强序列去噪（SSDRec），具有三阶段学习范式来解决上述挑战。在第一阶段，我们通过全局关系编码器赋能SSDRec，以数据驱动的方式学习多方面的序列间关系。这些关系作为先验知识来指导后续阶段。在第二阶段，我们设计了一个自我增强模块来增强序列以减轻 OUP。最后，我们在第三阶段采用分层去噪模块来降低错误增强的风险并查明原始序列中的所有噪声。对五个真实世界数据集的广泛实验证明了模型相对于最先进的去噪方法的优越性及其在主流顺序推荐模型中的灵活应用。源代码可在 https://github.com/zc-97/SSDRec 获取。]]></description>
      <guid>https://arxiv.org/abs/2403.04278</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:25 GMT</pubDate>
    </item>
    <item>
      <title>DGR：通过全球和本地视角进行推荐的通用图形去平滑框架</title>
      <link>https://arxiv.org/abs/2403.04287</link>
      <description><![CDATA[arXiv:2403.04287v1 公告类型：新
摘要：图卷积网络（GCN）已成为推荐系统中的关键，它通过利用用户-项目交互图的节点信息和拓扑来学习用户和项目嵌入。然而，这些模型经常面临着名的过度平滑问题，导致用户和项目嵌入不明确并降低个性化。基于 GCN 的系统中的传统去平滑方法是特定于模型的，缺乏通用的解决方案。本文介绍了一种新颖的、与模型无关的方法，名为 \textbf{D}esmoothing Framework，用于基于 \textbf{G}CN 的 \textbf{R} 推荐系统 (\textbf{DGR})。它通过考虑全局和局部视角，有效解决了基于 GCN 的通用推荐模型的过度平滑问题。具体来说，我们首先在每个消息传递层引入向量扰动，以惩罚节点嵌入在全局拓扑结构的指导下过于相似的趋势。同时，我们进一步为读出嵌入开发了一个定制设计的损失项，以保留用户与其相邻项目之间的本地协作关系。特别是，与相邻项目表现出高度相关性的项目也被合并以增强局部拓扑信息。为了验证我们的方法，我们在基于 5 个著名的基于 GCN 的推荐模型的 5 个基准数据集上进行了广泛的实验，证明了我们提出的框架的有效性和泛化性。]]></description>
      <guid>https://arxiv.org/abs/2403.04287</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:25 GMT</pubDate>
    </item>
    <item>
      <title>使用语料库主题分类法改进特定主题应用程序中的检索</title>
      <link>https://arxiv.org/abs/2403.04160</link>
      <description><![CDATA[arXiv:2403.04160v1 公告类型：新
摘要：文档检索极大地受益于大规模预训练语言模型（PLM）的进步。然而，由于独特的术语、不完整的用户查询上下文和专门的搜索意图，它们的有效性通常限制在专门领域或行业的特定主题应用程序中。为了捕获特定主题的信息并改进检索，我们建议使用语料库主题分类法，它概述了语料库的潜在主题结构，同时反映了用户感兴趣的方面。我们引入了 ToTER（主题分类增强检索）框架，该框架在分类的指导下识别查询和文档的中心主题，并利用它们的主题相关性来补充缺失的上下文。作为一个即插即用的框架，ToTER 可以灵活地用于增强各种基于 PLM 的检索器。通过对两个真实世界数据集进行广泛的定量、烧蚀和探索性实验，我们确定了在特定主题应用程序中使用主题分类法进行检索的好处，并证明了 ToTER 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2403.04160</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:24 GMT</pubDate>
    </item>
    <item>
      <title>通过混合检索增强生成的联合推荐</title>
      <link>https://arxiv.org/abs/2403.04256</link>
      <description><![CDATA[arXiv:2403.04256v1 公告类型：新
摘要：联合推荐（FR）作为一种新颖的范式出现，可以实现隐私保护推荐。然而，传统的FR系统通常用离散身份（ID）来表示用户/项目，由于FR中的数据稀疏性和异构性而导致性能下降。另一方面，大型语言模型（LLM）作为推荐器已被证明在各种推荐场景中都是有效的。然而，基于法学硕士的推荐器遇到了推理效率低和潜在幻觉等挑战，从而影响了它们在现实场景中的性能。为此，我们提出了 GPT-FedRec，这是一个利用 ChatGPT 和新颖的混合检索增强生成（RAG）机制的联合推荐框架。 GPT-FedRec 是一个两阶段的解决方案。第一阶段是混合检索过程，挖掘基于 ID 的用户模式和基于文本的项目特征。接下来，检索到的结果将转换为文本提示并输入 GPT 进行重新排名。我们提出的混合检索机制和基于 LLM 的重新排序旨在从数据中提取通用特征并利用 LLM 中的预训练知识，克服 FR 中的数据稀疏性和异质性。此外，RAG方法还可以防止LLM幻觉，提高对现实世界用户的推荐性能。不同基准数据集上的实验结果证明了 GPT-FedRec 相对于最先进的基准方法具有优越的性能。]]></description>
      <guid>https://arxiv.org/abs/2403.04256</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:24 GMT</pubDate>
    </item>
    <item>
      <title>电子商务排名系统的稳健性分析</title>
      <link>https://arxiv.org/abs/2403.04257</link>
      <description><![CDATA[arXiv:2403.04257v1 公告类型：新
摘要：信息检索（IR）是各种应用中的关键组成部分。机器学习 (ML) 的最新进展使得 ML 算法能够集成到 IR 中，特别是在排名系统中。虽然有大量关于基于机器学习的排名系统的鲁棒性的研究，但这些研究在很大程度上忽略了商业电子商务系统，并且未能在现实世界和操纵的查询相关性之间建立联系。在本文中，我们提出了第一个关于电子商务排名系统稳健性的系统测量研究。我们将稳健性定义为语义相同查询的排名结果的一致性。为了定量分析稳健性，我们提出了一种新颖的指标，该指标考虑了现有指标中缺少的排名位置和特定于项目的信息。我们对电子商务零售商的真实世界数据进行的大规模测量研究揭示了测量和提高鲁棒性的开放机会，因为语义相同的查询通常会产生不一致的排名结果。根据我们的观察，我们提出了几个增强鲁棒性的解决方案方向，例如使用大型语言模型。请注意，本文讨论的稳健性问题并不构成错误或疏忽。相反，在存在大量选择的情况下，以各种排列呈现多种产品是可行的，所有这些产品都具有同等的吸引力。然而，这种广泛的选择可能会导致客户感到困惑。由于电子商务零售商使用各种技术来提高搜索结果的质量，我们希望这项研究为衡量排名系统的稳健性提供有价值的指导。]]></description>
      <guid>https://arxiv.org/abs/2403.04257</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:24 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统中增量学习的个性化负库</title>
      <link>https://arxiv.org/abs/2403.03993</link>
      <description><![CDATA[arXiv:2403.03993v1 公告类型：新
摘要：推荐系统已成为在线平台不可或缺的一部分。每天，训练数据量都在扩大，用户交互的次数也在不断增加。探索更大、更具表现力的模型已经成为提升用户体验的必要追求。然而，这种进展带来了计算负担的增加。在商业环境中，一旦推荐系统模型经过训练和部署，通常需要随着新客户数据的到来而频繁更新。累积起来，数据量的增加最终使得从头开始对模型进行批量再训练在计算上变得不可行。仅根据新数据天真地进行微调会遇到有据可查的灾难性遗忘问题。尽管负采样是隐式反馈训练的关键部分，但不存在适合增量学习框架的专门技术。在这项工作中，我们第一步提出了一种个性化的负库策略，用于获取标准三重态损失的负样本。该技术通过鼓励模型记住稳定的用户偏好并在用户兴趣发生变化时选择性地忘记，平衡了遗忘的缓解和可塑性。我们推导出负采样器的数学公式来填充和更新存储库。我们将我们的设计集成到三个 SOTA 和常用的增量推荐模型中。我们表明，负储层框架的这些具体实现在标准基准测试中、在多个标准 top-k 评估指标上取得了最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2403.03993</guid>
      <pubDate>Fri, 08 Mar 2024 06:16:23 GMT</pubDate>
    </item>
    </channel>
</rss>