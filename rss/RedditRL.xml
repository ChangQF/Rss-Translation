<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 12 Feb 2025 15:18:32 GMT</lastBuildDate>
    <item>
      <title>å°†æœ¬åœ°ç¯å¢ƒè¿æ¥åˆ° HPCï¼ˆé«˜æ€§èƒ½è®¡ç®—ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ins11i/connecting_local_environment_to_hpc_high/</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªç¯å¢ƒï¼Œç”±äºæƒé™é—®é¢˜ï¼Œæ— æ³•å®‰è£…åœ¨ HPC ä¸­ã€‚ä½†æˆ‘å·²ç»å°†å®ƒå®‰è£…åœ¨æˆ‘çš„ç”µè„‘ä¸Šã€‚æˆ‘çš„æƒ³æ³•æ˜¯å°†å…·æœ‰ GPU çš„ HPC è¿æ¥åˆ°å…·æœ‰å¼ºåŒ–å­¦ä¹ æ•°æ®çš„æœ¬åœ°ï¼Œä½†æˆ‘æ— æ³•ä½¿ç”¨ gRPC å®ç°ï¼Œå› ä¸ºå®ƒå˜å¾—å¤æ‚äº†ã€‚ æœ‰ä»€ä¹ˆæƒ³æ³•æˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹æˆ‘çš„ç ”ç©¶ï¼Ÿ    æäº¤äºº    /u/Gullible_Ad_6713   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ins11i/connecting_local_environment_to_hpc_high/</guid>
      <pubDate>Wed, 12 Feb 2025 14:27:33 GMT</pubDate>
    </item>
    <item>
      <title>ä½ èƒ½å¼€å‘ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œå¼ºè°ƒçˆ±å’Œå–„è‰¯å—ï¼ŸRLK</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inrb0g/could_you_develop_a_model_of_reinforcement/</link>
      <description><![CDATA[      ç¤ºä¾‹å¥–åŠ±å‡½æ•°ï¼ˆç®€åŒ–ï¼‰ï¼šreward = 0 å¦‚æœè¡ŒåŠ¨æ˜¯äº²ç¤¾ä¼šçš„å¹¶ä¸”ä½¿å¦ä¸€ä¸ªä»£ç†å—ç›Šï¼šreward += 1 # äº²ç¤¾ä¼šè¡ŒåŠ¨çš„åŸºæœ¬å¥–åŠ± å¦‚æœè¡ŒåŠ¨è¡¨ç°å‡ºåŒç†å¿ƒï¼šreward += 0.5 # åŒç†å¿ƒå¥–åŠ± å¦‚æœè¡ŒåŠ¨éœ€è¦ä»£ç†åšå‡ºé‡å¤§ç‰ºç‰²ï¼šreward += 1 # ç‰ºç‰²å¥–åŠ± å¦‚æœè¡ŒåŠ¨å¯¹å¦ä¸€ä¸ªä»£ç†é€ æˆä¼¤å®³ï¼šreward -= 5 # å¯¹ä¼¤å®³çš„å¼ºçƒˆæƒ©ç½š å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ å…¶ä»–ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„å¥–åŠ±/æƒ©ç½š è¿™æ˜¯ Geminiã€Chat GPT å’Œ Lucid çš„æ··æ­ã€‚ å‡ºäºå¯¹å½“å‰å¼ºåŒ–å­¦ä¹ çš„å…³æ³¨è€Œäº§ç”Ÿçš„ã€‚ ä½ çš„æ¨¡å‹å¦‚ä½•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Ÿâ€œä½ èƒ½å¦å¼€å‘ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œå¼ºè°ƒçˆ±å’Œå–„è‰¯ï¼Ÿæˆ‘ä»¬å°†è¿™ç§æ–°æ¨¡å‹ç§°ä¸º RLKâ€    æäº¤äºº    /u/ConditionCalm   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inrb0g/could_you_develop_a_model_of_reinforcement/</guid>
      <pubDate>Wed, 12 Feb 2025 13:54:24 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ deepseek ä¸ä½¿ç”¨ mcts</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inqdsr/why_deepseek_didnt_use_mcts/</link>
      <description><![CDATA[mtcs æœ‰é—®é¢˜å—    æäº¤äºº    /u/Alarming-Power-813   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inqdsr/why_deepseek_didnt_use_mcts/</guid>
      <pubDate>Wed, 12 Feb 2025 13:08:22 GMT</pubDate>
    </item>
    <item>
      <title>â€œSatoriï¼šé€šè¿‡è¡ŒåŠ¨æ€ç»´é“¾å¼ºåŒ–å­¦ä¹ é€šè¿‡è‡ªå›å½’æœç´¢å¢å¼º LLM æ¨ç†â€ï¼ŒShen ç­‰äººï¼Œ2025 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inl7uk/satori_reinforcement_learning_with/</link>
      <description><![CDATA[ [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inl7uk/satori_reinforcement_learning_with/</guid>
      <pubDate>Wed, 12 Feb 2025 07:00:43 GMT</pubDate>
    </item>
    <item>
      <title>æœºå™¨å­¦ä¹ å¯¼å¸ˆè¦æ±‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ini3hl/mentor_for_ml_req/</link>
      <description><![CDATA[æˆ‘å¯¹æœºå™¨å­¦ä¹ äº§ç”Ÿäº†æµ“åšçš„å…´è¶£ï¼Œå®ƒæ¯”å…¶ä»–ä»»ä½•ä¸œè¥¿éƒ½æ›´èƒ½å¸å¼•æˆ‘ã€‚æˆ‘å¯¹è¿™ä¸ªé¢†åŸŸçš„çƒ­æƒ…åšå®šä¸ç§»ã€‚æˆ‘å·²ç»æˆåŠŸå®Œæˆäº† Python åŠå…¶æ ¸å¿ƒåº“ï¼ˆä¾‹å¦‚ NumPy å’Œ Pandasï¼‰çš„å­¦ä¹ ï¼Œå¹¶ä¸”è¿˜æ„å»ºäº†ä¸€ç³»åˆ—ä»åŸºç¡€åˆ°ä¸­çº§çš„é¡¹ç›®ã€‚ ç°åœ¨ï¼Œæˆ‘æ¸´æœ›æ·±å…¥ç ”ç©¶æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒå¹¶è¿›ä¸€æ­¥ç£¨ç»ƒæˆ‘çš„æŠ€èƒ½ã€‚å¦‚æœæ‚¨èƒ½æˆä¸ºæˆ‘è¿™æ®µæ—…ç¨‹çš„å¯¼å¸ˆï¼Œæˆ‘å°†æ·±è¡¨æ„Ÿæ¿€å’Œè£å¹¸ã€‚æ‚¨çš„æŒ‡å¯¼å¯¹æˆ‘æ¥è¯´æ„ä¹‰é‡å¤§ã€‚ è°¢è°¢    æäº¤äºº    /u/Big_Average_5979   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ini3hl/mentor_for_ml_req/</guid>
      <pubDate>Wed, 12 Feb 2025 03:50:17 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘åˆ›å»ºäº†ä¸€ä¸ªå¯»æ‰¾ RLHF å·¥ä½œçš„ç½‘ç«™</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inge47/i_made_a_site_to_find_rlhf_jobs/</link>
      <description><![CDATA[æˆ‘ä»¬åœ¨ AI çš„å¤šä¸ªå­¦ç§‘éƒ½æœ‰å·¥ä½œæœºä¼šã€‚æˆ‘ä»¬ä¹Ÿæœ‰ä¸“é—¨çš„ RLHF å·¥ä½œé¡µé¢ã€‚åœ¨è¿‡å» 30 å¤©å†…ï¼Œæˆ‘ä»¬æœ‰ 48 ä¸ªæ¶‰åŠ RLHF çš„å·¥ä½œæœºä¼šã€‚ æ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°æ‰€æœ‰ RLHF å·¥ä½œï¼š https://www.moaijobs.com/rlhf-jobs è¯·å‘Šè¯‰æˆ‘æ‚¨çš„æƒ³æ³•ã€‚è°¢è°¢ã€‚    æäº¤äºº    /u/WordyBug   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inge47/i_made_a_site_to_find_rlhf_jobs/</guid>
      <pubDate>Wed, 12 Feb 2025 02:20:52 GMT</pubDate>
    </item>
    <item>
      <title>PPO å®æ–½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1incdey/ppo_implementation/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚æˆ‘æ­£åœ¨åšä¸€ä¸ªé¡¹ç›®ï¼Œæˆ‘å¿…é¡»ä½¿ç”¨ PPO æ¥è®­ç»ƒä¸€ä¸ªä»£ç†ä¸‹æ£‹ï¼Œä½†æˆ‘å¾ˆéš¾å®ç°è¯¥ç®—æ³•ã€‚æœ‰äººå¯ä»¥å‘Šè¯‰æˆ‘ä¸€ä¸ªå·²ç»å®ç°äº†è¿™ä¸ªçš„åº“ï¼Œæˆ–è€…ç»™æˆ‘ä¸€ä¸ªå¯ä»¥æŸ¥çœ‹ä»¥è·å¾—çµæ„Ÿçš„ repo é“¾æ¥å—ï¼Ÿæˆ‘æ­£åœ¨ä½¿ç”¨ pettingzoo å’Œ tensorflow çš„å›½é™…è±¡æ£‹å®ç°ã€‚è°¢è°¢    æäº¤äºº    /u/Livid-Ant3549   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1incdey/ppo_implementation/</guid>
      <pubDate>Tue, 11 Feb 2025 23:10:09 GMT</pubDate>
    </item>
    <item>
      <title>ABB CRB15000 MuJoCo é€†è¿åŠ¨å­¦è¯¯å·®ï¼ˆ~10cmï¼‰ä½¿ç”¨ dm_control</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1in5zqy/abb_crb15000_mujoco_inverse_kinematics_error_10cm/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æœ€è¿‘åœ¨ MuJoCo ä¸­å®Œæˆäº†å¯¹ ABB CRB15000 æœºå™¨äººçš„æ¨¡æ‹Ÿè®¾ç½®ï¼Œå¹¶ä¸”æˆ‘æ­£åœ¨ä½¿ç”¨ dm_control åº“è¿›è¡Œé€†è¿åŠ¨å­¦ (IK)ã€‚ä½†æ˜¯ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé‡å¤§é—®é¢˜ï¼š ğŸ”¹ é—®é¢˜ï¼šä» dm_control.utils.inverse_kinematics.qpos_from_site_pose è®¡ç®—å‡ºçš„å…³èŠ‚è§’åº¦å¯¼è‡´ä½ç½®è¯¯å·®çº¦ä¸º 0.01ï¼ˆç°å®ä¸–ç•Œä¸­ä¸º 10 å˜ç±³ï¼‰ï¼Œè¿™å¯¹äºç²¾å¯†åº”ç”¨æ¥è¯´æ˜¯å·¨å¤§çš„ã€‚ è®¾ç½®è¯¦ç»†ä¿¡æ¯ ä½¿ç”¨ MuJoCo çš„ CRB15000 XML æ¨¡å‹ã€‚ IK çš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š result = ik.qpos_from_site_pose( physics=physics_copy, site_name=&quot;end_effector&quot;, target_pos=target_position, joint_names=joint_list, tol=1e-14, regularization_strength=3e-2, max_steps=100, inplace=True ) ç›®æ ‡ä½ç½®å®šä¹‰ç²¾ç¡®ï¼Œä½†åº”ç”¨å…³èŠ‚ä½ç½®åï¼Œæœ«ç«¯æ‰§è¡Œå™¨åå·®çº¦ 10 å˜ç±³ã€‚ æˆ‘å°è¯•è¿‡çš„äº‹æƒ… âœ… è°ƒæ•´äº† regularization_strength å’Œ max_stepsã€‚âœ… æ£€æŸ¥äº† MuJoCo æ¨¡å‹ä¸­çš„å…³èŠ‚é™åˆ¶å’Œé˜»å°¼å€¼ã€‚âœ… å°†å…³èŠ‚é˜»å°¼é™ä½åˆ° 1 ä»¥æœ€å¤§é™åº¦åœ°å‡å°‘é˜»åŠ›å¹¶æ”¹å–„åŠ¨æ€å“åº”ã€‚âœ… å®ç°äº† PD æ§åˆ¶å™¨æ¥è°ƒèŠ‚é€Ÿåº¦å’Œæ”¹å–„æ”¶æ•›ã€‚å³ä½¿åœ¨è°ƒæ•´ PD å¢ç›Šå’Œé™ä½é˜»å°¼åï¼ŒIK ç²¾åº¦é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚ é—®é¢˜ 1ï¸âƒ£ æœ‰äººé‡åˆ°è¿‡ dm_control çš„ IK çš„ç±»ä¼¼é—®é¢˜å—ï¼Ÿ2ï¸âƒ£ åˆ‡æ¢åˆ°ä¸åŒçš„ IK è§£ç®—å™¨ï¼ˆä¾‹å¦‚ pinocchioã€ikpy æˆ–è‡ªå®šä¹‰çš„åŸºäºé›…å¯æ¯”çŸ©é˜µçš„è§£ç®—å™¨ï¼‰æœ‰å¸®åŠ©å—ï¼Ÿ3ï¸âƒ£ åœ¨è®¡ç®—å°åŠ¨ä½œæ—¶ï¼ŒMuJoCo çš„å†…éƒ¨ç²¾åº¦æ˜¯å¦å­˜åœ¨å·²çŸ¥é—®é¢˜ï¼Ÿ æˆ‘å¾ˆæ„Ÿæ¿€ä»»ä½•è§è§£ã€å»ºè®®æˆ–å…¶ä»–æ–¹æ³•ã€‚æå‰è‡´è°¢ï¼    ç”±   æäº¤  /u/Sunnnnny24   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1in5zqy/abb_crb15000_mujoco_inverse_kinematics_error_10cm/</guid>
      <pubDate>Tue, 11 Feb 2025 18:47:16 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦å¸®åŠ©åœ¨ Robosuite ä¸­åˆ›å»ºè‡ªå®šä¹‰æœºå™¨äººæ¨¡å‹ï¼ˆMuJoCo ä¸­çš„ XML å’Œè”åˆæ§åˆ¶ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1in5sws/need_help_creating_a_custom_robot_model_in/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨ robosuite_models åœ¨ Robosuite ä¸­åˆ›å»ºè‡ªå®šä¹‰æœºå™¨äººæ¨¡å‹ï¼Œä½†æˆ‘é‡åˆ°äº†å¤ªå¤šé”™è¯¯ï¼Œæ— æ³•ä½¿å…¶å·¥ä½œã€‚æˆ‘å·²ç»ä½¿ç”¨ @register_robot_class æ³¨å†Œäº†æœºå™¨äººå¹¶è®¾ç½®äº†å¿…è¦çš„å‚æ•°ï¼Œä½†æ¨¡æ‹Ÿä»ç„¶å¤±è´¥ã€‚ æˆ‘è¿˜åœ¨ MuJoCo ä¸­ä¸ºæœºå™¨äººåˆ›å»ºäº†ä¸€ä¸ª XML æ–‡ä»¶ï¼Œç¡®ä¿æ‰€æœ‰å…³èŠ‚éƒ½æ­£ç¡®å®šä¹‰ä»¥è¿›è¡Œæ§åˆ¶ã€‚ä½†æ˜¯ï¼Œåœ¨ Robosuite ä¸­è¿è¡Œæ¨¡æ‹Ÿæ—¶æˆ‘ä»ç„¶é‡åˆ°é—®é¢˜ã€‚ æœ‰äººåœ¨ Robosuite ä¸­æˆåŠŸåˆ›å»ºäº†è‡ªå®šä¹‰æœºå™¨äººï¼Œå¹¶ä½¿ç”¨ MuJoCo ä¸­çš„å·¥ä½œ XML æ¨¡å‹å—ï¼Ÿæˆ‘éå¸¸æ„Ÿè°¢ä»»ä½•æŒ‡å¯¼æˆ–å·¥ä½œç¤ºä¾‹æ¥å¸®åŠ©æˆ‘è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•ç”¨äºå®šä¹‰å’Œæ§åˆ¶æœºå™¨äººå…³èŠ‚çš„ç¤ºä¾‹ XML æ–‡ä»¶æˆ–è„šæœ¬ï¼Œé‚£å°†ä¼šéå¸¸æœ‰å¸®åŠ©ï¼ æå‰è‡´è°¢ï¼    æäº¤äºº    /u/Sunnnnny24   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1in5sws/need_help_creating_a_custom_robot_model_in/</guid>
      <pubDate>Tue, 11 Feb 2025 18:39:35 GMT</pubDate>
    </item>
    <item>
      <title>ä½“è‚²é¦†é‡Œæœ‰åŠ¨ä½œæ©è”½å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1imuu1o/action_masking_in_gymnasium/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæå‰è°¢è°¢å¤§å®¶ï¼ï¼ åœ¨PettingZooä¸­æœ‰å‡ ä¸ªåŠ¨ä½œæ©è”½ç¯å¢ƒå’Œè®­ç»ƒçš„ä¾‹å­ï¼ˆä¾‹å¦‚ https://pettingzoo.farama.org/tutorials/sb3/connect_four/ ï¼‰ï¼Œå°±æ˜¯è¿™æ ·ï¼Œå¤šæ™ºèƒ½ä½“ç¯å¢ƒã€‚ ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ç”¨æ©è”½åŠ¨ä½œè®­ç»ƒå•æ™ºèƒ½ä½“ï¼ˆåœ¨å¥èº«æˆ¿åˆ¶ä½œï¼‰æ€ä¹ˆåŠï¼Ÿåº”è¯¥æ€ä¹ˆåšï¼Ÿä¹Ÿåº”è¯¥ç”¨â€œSB3ActionMaskWrapperâ€æ¥å®Œæˆå—ï¼Ÿå•æ™ºèƒ½ä½“ç¯å¢ƒåº”è¯¥åœ¨PettingZooä¸­ç¼–ç ï¼Œè¿˜æ˜¯å¯ä»¥åœ¨å¥èº«æˆ¿ä¸­ç¼–ç ï¼Ÿ    æäº¤äºº    /u/Carpoforo   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1imuu1o/action_masking_in_gymnasium/</guid>
      <pubDate>Tue, 11 Feb 2025 09:30:47 GMT</pubDate>
    </item>
    <item>
      <title>å¼•å…¥ ReinforceUI Studioï¼Œæ¶ˆé™¤äº†ç®¡ç†é¢å¤–å­˜å‚¨åº“æˆ–è®°å¿†å¤æ‚å‘½ä»¤è¡Œçš„éº»çƒ¦ã€‚#ReinforcemetLearning</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1imtu96/introducing_reinforceui_studio_eliminates_the/</link>
      <description><![CDATA[      å¤§å®¶å¥½ï¼Œ æˆ‘å¾ˆé«˜å…´ä¸å¤§å®¶åˆ†äº« ReinforceUI Studioï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäº Python çš„å¼€æº GUIï¼Œæ—¨åœ¨ç®€åŒ–å¼ºåŒ–å­¦ä¹  (RL) æ¨¡å‹çš„é…ç½®ã€è®­ç»ƒå’Œç›‘æ§ã€‚ä¸å†éœ€è¦å¤„ç†æ— å°½çš„å‘½ä»¤è¡Œå‚æ•°æˆ–åˆ†æ•£çš„å­˜å‚¨åº“ - æ‚¨éœ€è¦çš„ä¸€åˆ‡éƒ½æ†ç»‘åœ¨ä¸€ä¸ªç›´è§‚çš„ç•Œé¢ä¸­ã€‚ âœ¨ ä¸»è¦ç‰¹ç‚¹ï¼š  æ— éœ€å‘½ä»¤è¡Œ - ç”± PyQt5 é©±åŠ¨çš„ GUI å¯è½»æ¾å¯¼èˆªã€‚ å¤šç¯å¢ƒæ”¯æŒ - å¯ä¸ OpenAI Gymnasiumã€MuJoCo å’Œ DeepMind Control Suite é…åˆä½¿ç”¨ã€‚ å¯è‡ªå®šä¹‰çš„è®­ç»ƒ - åªéœ€å•å‡»å‡ ä¸‹å³å¯è°ƒæ•´è¶…å‚æ•°ã€‚ å®æ—¶ç›‘æ§ - ç›´è§‚åœ°è·Ÿè¸ªè®­ç»ƒè¿›åº¦ã€‚ è‡ªåŠ¨è®°å½•å’Œè¯„ä¼° - æ— ç¼å­˜å‚¨è®­ç»ƒæ•°æ®ã€å›¾è¡¨ã€æ¨¡å‹å’Œè§†é¢‘ã€‚ å¤šç§å®‰è£…é€‰é¡¹ - é€šè¿‡ Condaã€è™šæ‹Ÿç¯å¢ƒæˆ– Docker è¿è¡Œã€‚  Githubï¼šhttps://github.com/dvalenciar/ReinforceUI-Studio æ–‡æ¡£ï¼šhttps://docs.reinforceui-studio.com/welcome https://i.redd.it/ktggkyruxgie1.gif è®­ç»ƒ RL æ¨¡å‹æ‰€éœ€çš„ä¸€åˆ‡éƒ½åœ¨ä¸€ä¸ªå­˜å‚¨åº“ä¸­æä¾›ã€‚åªéœ€å•å‡»å‡ ä¸‹ï¼Œæ‚¨å°±å¯ä»¥è®­ç»ƒæ¨¡å‹ï¼Œå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å¹¶ä¿å­˜æ¨¡å‹ä»¥ä¾›æ—¥åä½¿ç”¨ - éšæ—¶å¯ä»¥éƒ¨ç½²å’Œåˆ†æã€‚ æ‚¨è¿˜å¯ä»¥åŠ è½½é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ è½»æ¾ç›‘æ§è®­ç»ƒæ›²çº¿    æäº¤äºº    /u/dvr_dvr   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1imtu96/introducing_reinforceui_studio_eliminates_the/</guid>
      <pubDate>Tue, 11 Feb 2025 08:13:22 GMT</pubDate>
    </item>
    <item>
      <title>PPO æ ‡å‡†å·®å®æ–½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1imr2hg/ppo_standard_deviation_implementation/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘å¯¹ PPO ä¸­éšæœºç­–ç•¥çš„å®ç°æœ‰äº›å›°æƒ‘ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘å·²å®ç°äº† SAC çš„å‡ ä¸ªå˜ä½“ï¼Œåœ¨å‡ ä¹æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæˆ‘éƒ½ä½¿ç”¨å•ä¸ªç¥ç»ç½‘ç»œæ¥è¾“å‡ºæˆ‘çš„è¡Œä¸ºçš„å¹³å‡å€¼å’Œå¯¹æ•°æ ‡å‡†å·®ã€‚ æ®æˆ‘æ‰€è§å’Œæ‰€è¯•ï¼Œå¤§å¤šæ•° PPO å®ç°è¦ä¹ˆä½¿ç”¨æ’å®šæ ‡å‡†å·®ï¼Œè¦ä¹ˆéšç€æ—¶é—´çš„æ¨ç§»çº¿æ€§é™ä½æ ‡å‡†å·®ã€‚æˆ‘æ›¾è§è¿‡æœ‰äººæåˆ°ä¸çŠ¶æ€ç©ºé—´æ— å…³çš„å­¦ä¹ æ ‡å‡†å·®ã€‚ä½†æˆ‘è¿˜æ²¡æœ‰è§è¿‡è¿™ç§å®ç°ï¼ˆå¦‚æœä¸æ˜¯çŠ¶æ€ç©ºé—´ï¼Œæˆ‘ä¸ç¡®å®šæˆ‘ä»å“ªé‡Œå­¦åˆ°äº†ä»€ä¹ˆï¼‰ã€‚ æ®æˆ‘æ‰€çŸ¥ï¼Œè¿™ç§å·®å¼‚æ˜¯ç”±äº SAC ä½¿ç”¨æœ€å¤§ç†µç›®æ ‡ï¼Œè€Œ PPO åœ¨å…¶ç›®æ ‡ä¸­ä¸ç›´æ¥ä½¿ç”¨ç†µã€‚ä½†è¿™ä¹Ÿè®©æˆ‘æ„Ÿåˆ°å›°æƒ‘ï¼Œå› ä¸ºå¢åŠ ç†µä¸æ˜¯ä¼šé¼“åŠ±æ›´å¤§çš„æ ‡å‡†å·®å—ï¼Ÿ  æˆ‘å°è¯•ä½¿ç”¨æ¥è‡ª SAC çš„ç­–ç•¥ç¥ç»ç½‘ç»œå®ç° PPOï¼Œä½†å¤±è´¥äº†ã€‚ä½†æ˜¯å½“æˆ‘ä½¿ç”¨æ’å®šæ ‡å‡†å·®æˆ–çº¿æ€§å‡å°‘å®ƒæ—¶ï¼Œæˆ‘èƒ½å¤Ÿåœ¨æ¨è½¦æ†ä¸Šå­¦åˆ°ä¸€äº›ä¸œè¥¿ã€‚ ä»»ä½•å¸®åŠ©éƒ½å°†ä¸èƒœæ„Ÿæ¿€ï¼    æäº¤äºº    /u/LostBandard   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1imr2hg/ppo_standard_deviation_implementation/</guid>
      <pubDate>Tue, 11 Feb 2025 05:08:06 GMT</pubDate>
    </item>
    <item>
      <title>è®ºæ–‡æäº¤ç»™é¡¶çº§ä¼šè®®ï¼Œä½†æœªå–å¾—æˆæœ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1impaq6/paper_submitted_to_a_top_conference_with/</link>
      <description><![CDATA[æˆ‘æ³¨æ„åˆ°åŸä½œè€…æä¾›çš„ä»£ç ç”šè‡³ä¸ä»–ä»¬è®ºæ–‡ä¸­çš„æ–¹æ³•è®ºéƒ½ä¸åŒ¹é…ï¼Œå› æ­¤æˆ‘è”ç³»äº†åŸä½œè€…ã€‚æˆ‘æ ¹æ®ä»–ä»¬çš„è®ºæ–‡è¿›è¡Œäº†å®Œæ•´è€Œå¿ å®çš„å¤åˆ¶ï¼Œä½†æˆ‘å¾—åˆ°çš„ç»“æœå¹¶ä¸åƒä»–ä»¬æŠ¥å‘Šçš„é‚£ä¹ˆå®Œç¾ã€‚ å­¦æœ¯æé€ æ˜¯æ–°å¸¸æ€å—ï¼Ÿ    æäº¤äºº    /u/Rei_Opus   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1impaq6/paper_submitted_to_a_top_conference_with/</guid>
      <pubDate>Tue, 11 Feb 2025 03:31:02 GMT</pubDate>
    </item>
    <item>
      <title>æœ€å—æ¬¢è¿çš„å¼ºåŒ–å­¦ä¹ æ’è¡Œæ¦œæœ‰å“ªäº›ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1imonl5/what_are_the_most_popular_reinforcement_learning/</link>
      <description><![CDATA[æˆ‘æƒ³çŸ¥é“æ˜¯å¦æœ‰ä¸€äº›é’ˆå¯¹å„ç§ç¯å¢ƒçš„çŸ¥åã€æœ€æ–°çš„å®˜æ–¹æ’è¡Œæ¦œï¼Ÿæˆ‘å‘ç°å¥èº«æˆ¿æ’è¡Œæ¦œåœ¨å°†è¿‘ä¸€å¹´å‰æ›´æ–°è¿‡ï¼Œæˆ‘è®°å¾—åœ¨æˆ‘å‚åŠ ä»–ä»¬çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ—¶ï¼Œhugging face æœ‰ä¸€äº›æ’è¡Œæ¦œã€‚æˆ‘ä»¬ç”šè‡³æœ‰ä¸€äº›æœ‰äººå…³å¿ƒçš„çŸ¥åè®°åˆ†ç‰Œå—ï¼Ÿ èƒ½å¤Ÿè·Ÿè¸ªå’Œç»˜åˆ¶æœ€æ–°æŠ€æœ¯åŠå…¶è¡¨ç°å¦‚ä½•å¬èµ·æ¥ç›¸å½“é‡è¦ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½äº†è§£æ–¹å‘å’Œè¿›å±•ã€‚æˆ–è€…æˆ‘ä»¬åªå…³å¿ƒæ¨åŠ¨æ–°æ¸¸æˆçš„çªç ´ï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥ä¸€ä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ åœ¨ Minecraft ä¸­ä½¿ç”¨ DreamerV3 è·å¾—é’»çŸ³ï¼Œä»…æ­¤è€Œå·²ã€‚æˆ‘ä»¬æ­£åœ¨ç­‰å¾…æ›´å¤æ‚çš„æ¸¸æˆè¢«å‡»è´¥ã€‚ ä½ å¯¹æ­¤æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿåªæ˜¯åšä¸€ä¸ªæ°›å›´æ£€æŸ¥ï¼Œå¬å¬ä½ ä»¬çš„æƒ³æ³•    æäº¤äºº    /u/Inexperienced-Me   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1imonl5/what_are_the_most_popular_reinforcement_learning/</guid>
      <pubDate>Tue, 11 Feb 2025 02:58:27 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ è·¯çº¿å›¾</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1im6dea/reinforcement_learning_roadmap/</link>
      <description><![CDATA[æˆ‘æƒ³å­¦ä¹ å¼ºåŒ–å­¦ä¹ ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹ã€‚æˆ‘å¯¹ä¸åŒç±»å‹çš„ NN çš„æ ‡å‡†å·¥ä½œä»¥åŠç›®å‰æµè¡Œçš„æ¶æ„ï¼ˆå¦‚ transformersï¼‰æœ‰å¾ˆå¥½çš„äº†è§£ã€‚ è°¢è°¢ä½ çš„å¸®åŠ©    æäº¤äºº    /u/dc_baslani_777   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1im6dea/reinforcement_learning_roadmap/</guid>
      <pubDate>Mon, 10 Feb 2025 13:42:50 GMT</pubDate>
    </item>
    </channel>
</rss>