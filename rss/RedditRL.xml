<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯æ—¨åœ¨æ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå’Œå­¦ä¹ å¦‚ä½•æœ€ä½³è·å¾—å¥–åŠ±çš„AI/ç»Ÿè®¡æ•°æ®çš„å­åœºã€‚ä¾‹å¦‚Alphagoï¼Œä¸´åºŠè¯•éªŒå’ŒA/Bæµ‹è¯•ä»¥åŠAtariæ¸¸æˆã€‚</description>
    <lastBuildDate>Sat, 08 Mar 2025 06:19:59 GMT</lastBuildDate>
    <item>
      <title>ç‹­çª„åˆ†å¸ƒçš„äº¤å‰é—®é¢˜ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j67jxk/crossq_on_narrow_distributions/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å—¨ï¼æˆ‘æƒ³çŸ¥é“æ˜¯å¦æœ‰äººæœ‰ä¸Crossqè¿›è¡Œç‹­çª„åˆ†å¸ƒçš„ç»éªŒï¼Ÿå³STDå¾ˆå°ã€‚æˆ‘çš„CrossQå®ç°åœ¨æ‘†ä¸Šæ•ˆæœå¾ˆå¥½ï¼Œä½†åœ¨æˆ‘çš„è‡ªå®šä¹‰ç¯å¢ƒä¸Šæ•ˆæœä¸ä½³ã€‚å®ƒéå¸¸ä¸ç¨³å®šï¼Œè¿”å›å¹³å‡çº¿å°†å¤§å¤§ä¸‹é™ï¼Œç„¶åçˆ¬å›å»ã€‚ä½†æ˜¯ï¼Œå½“æˆ‘ä½¿ç”¨SACåœ¨è‡ªå®šä¹‰ç¯å¢ƒä¸Šå­¦ä¹ æ—¶ï¼Œè¿™å¹¶æ²¡æœ‰å‘ç”Ÿã€‚æˆ‘çŸ¥é“ï¼Œè¿™é‡Œå¯èƒ½ä¼šæœ‰å¤šä¸ªçº§åˆ«çš„é—®é¢˜æ¥æºï¼Œä½†æˆ‘åªæ˜¯å¯¹å¤„ç†ä»¥ä¸‹æƒ…å†µå¾ˆå¥½å¥‡ï¼šSTDéå¸¸å°ï¼Œå¹¶ä¸”éšç€ä»£ç†å•†çš„äº†è§£ï¼Œå³ä½¿æ˜¯å°‘é‡çš„åˆ†é…å˜åŒ–ï¼Œä¹Ÿä¼šå¯¼è‡´å·¨å¤§çš„ä»·å€¼å˜åŒ–ï¼Œå› ä¸ºæ‰¹æ¬¡æ‰¹é‡çš„â€œå½’ä¸€ä»½â€ã€‚è¿è¡Œçš„stdå¾ˆå° - ï¼†gt;éå¸¸ç¨€æœ‰æˆ–æ–°è§çš„çŠ¶æ€ - ï¼†gt; OODï¼Œå¦‚æœSTDå¾ˆå°ï¼Œåˆ™å°†æ–°å€¼æ ‡å‡†åŒ–ä¸ºå·¨å¤§çš„å€¼ - ï¼†GT;é™ä½æ€§èƒ½ - ï¼†gt;éšç€ç»Ÿè®¡ä¿¡æ¯é€‚åº”æ–°å€¼ï¼Œæ€§èƒ½å†æ¬¡æˆé•¿ - ï¼†gt;é‡å¤é‡å¤æˆ–åªæ˜¯æ— æ³•æ¢å¤ã€‚é€šå¸¸æˆ‘çš„åå­—æ¶ç¡®å®æ¢å¤äº†ï¼Œä½†è¿™æ˜¯æ¬¡ä¼˜çš„ã€‚  é‚£ä¹ˆï¼Œæœ‰äººçŸ¥é“å¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µå—ï¼Ÿ  å¦å¤–ï¼Œæ‚¨å¦‚ä½•ç›‘è§†batchnormalizationçš„æ€§ç—…å€¼ï¼Ÿæˆ‘ä¸çŸ¥é“ä¸€ä¸ªç›´æˆªäº†å½“çš„æ–¹å¼ï¼Œå› ä¸ºæ¯ä¸ªç»´åº¦éƒ½ä¼šè·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯ã€‚ä¹Ÿè®¸æ˜¯Max STDå’ŒMin STDï¼Ÿç”±äºæˆ‘çš„é—®é¢˜å°†å‡ºç°åœ¨æœ€å°çš„STDå°æ—¶ã€‚  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/u/automatic-web8429     [link]    32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j67jxk/crossq_on_narrow_distributions/</guid>
      <pubDate>Sat, 08 Mar 2025 02:55:37 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªAIä»£ç†ï¼Œæ§åˆ¶å¸è¡€é¬¼å¹¸å­˜è€…æ¸¸æˆä¸­çš„è§’è‰²</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j64o5r/i_want_to_create_an_ai_agent_to_control_the/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/vampiresurvivors/comments/comments/1j5zdve/i_want_want_to_create_ai_ai_ai_aigent_to_control_to_control_the/â€&gt; [links]  &lt;a href =â€œ https://www.reddit.com/r/reinforecctionlearning/comments/1j64o5r/i_want_want_to_create_create_an_ai_ai_ai_ai_ai_aigent_to_control_to_control_to/]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j64o5r/i_want_to_create_an_ai_agent_to_control_the/</guid>
      <pubDate>Sat, 08 Mar 2025 00:25:49 GMT</pubDate>
    </item>
    <item>
      <title>é‡åŒ–ç¤çŸ³æ¡†æ¶çš„è®¡ç®—æ•ˆç‡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j5riux/quantifying_the_computational_efficiency_of_the/</link>
      <description><![CDATA[       ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/pseud0nym    href =â€œ https://medium.com/@lina.noor.agi/quantifying-the-computation--computation-oficy-of-the-reef-framework-dramework-0e2b30d79746â€&gt; [link]        [æ³¨é‡Š]            ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j5riux/quantifying_the_computational_efficiency_of_the/</guid>
      <pubDate>Fri, 07 Mar 2025 15:50:07 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦å¸®åŠ©å®æ–½RL</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j5o3uj/need_help_implementing_rl/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘æ­£åœ¨ä¸ºæˆ‘çš„å…¬å¸å»ºç«‹AIä»£ç†ï¼Œä»æœ¬è´¨ä¸Šè®²ï¼Œæˆ‘ä»¬æœ‰ä¸€äº›å®¢æˆ·ä½¿ç”¨ä»ªè¡¨æ¿æ¥æ„å»ºåŠ¨æ€UIï¼Œä¾›ç”¨æˆ·ä¿ç•™å’Œè½¬æ¢å…¶ç§»åŠ¨æˆ–Webåº”ç”¨ç¨‹åºã€‚  æˆ‘ä»¬æƒ³å»ºç«‹ä¸€ä¸ªå¯ä»¥é€šè¿‡ç”¨æˆ·çš„è¡Œä¸ºä¸ºå®¢æˆ·é€‰æ‹©æœ€ä½³çš„UIå˜ä½“çš„AIä»£ç†ã€‚  æˆ‘åœ¨åŸºæœ¬å±‚é¢ä¸Šå¼€å§‹å»ºç«‹ä»£ç†çš„æ–¹æ³•åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ æŠ€æœ¯å †æ ˆåº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ  æˆ‘åº”è¯¥çŸ¥é“çš„é“¾æ¥æˆ–èµ„æºæ˜¯å¦å¯ä»¥å¸®åŠ©æˆ‘å»ºç«‹ä»£ç†ï¼Ÿ  è°¢è°¢  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/poperbudget348     [link]   ï¼†ï¼ƒ32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j5o3uj/need_help_implementing_rl/</guid>
      <pubDate>Fri, 07 Mar 2025 13:44:42 GMT</pubDate>
    </item>
    <item>
      <title>æ˜¯æ—¶å€™è®­ç»ƒDQNä¸ºAle Pong V5</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j5icxh/time_to_train_dqn_for_ale_pong_v5/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘ä½¿ç”¨çš„æ˜¯å¸¦æœ‰3ä¸ªConvå±‚ï¼ˆ32ã€64ã€64æ»¤æ³¢å™¨ï¼‰å’Œå®Œå…¨è¿æ¥çš„å±‚ï¼ˆ512ä¸ªå•ä½ï¼‰çš„CNNã€‚æˆ‘çš„è®¾ç½®åŒ…æ‹¬RTX 4070 Ti Superï¼Œä½†æ¯é›†éœ€è¦6-7ç§’ã€‚è¿™æ¯”æˆ‘ä½¿ç”¨CPUçš„æ¯é›†50ç§’è¦å¿«å¾—å¤šï¼Œä½†æ˜¯GPUçš„ä½¿ç”¨ä»…ä¸º20-30ï¼…ï¼Œè€ŒCPUçš„ä½¿ç”¨é‡ä½äº20ï¼… è¿™æ˜¯å…¸å‹çš„æ€§èƒ½ï¼Œè¿˜æ˜¯æˆ‘å¯ä»¥ä¼˜åŒ–çš„ä¸œè¥¿æ¥åŠ å¿«é€Ÿåº¦ï¼Ÿä»»ä½•å»ºè®®å°†ä¸èƒœæ„Ÿæ¿€ï¼  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/soliseeker     [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j5icxh/time_to_train_dqn_for_ale_pong_v5/</guid>
      <pubDate>Fri, 07 Mar 2025 07:51:47 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨çº¿å­¦ä¹ çš„é€»è¾‘å¸®åŠ©</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j57qnn/logic_help_for_online_learning/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªè‡ªåŠ¨çš„é«˜é€Ÿç¼“å­˜å†…å­˜ç®¡ç†é¡¹ç›®ï¼Œæˆ‘æ—¨åœ¨åˆ›å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–çš„ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨å‘ç”Ÿç¼“å­˜å¤±è¯¯æ—¶æé«˜æ€§èƒ½ã€‚ç›®çš„æ˜¯æ ¹æ®è®¾å®šçº§åˆ«å’Œä¼ å…¥çš„å¡«å……è¯¦ç»†ä¿¡æ¯é€‰æ‹©ä¸€ä¸ªç¼“å­˜å—è¿›è¡Œé©±é€ã€‚ å¯¹äºæˆ‘çš„æ¨¡å‹ï¼Œæˆ‘å·²ç»å®æ–½äº†ä¸€ç§ç¦»çº¿å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜¯ä½¿ç”¨ä¸“å®¶ç­–ç•¥åŸ¹è®­çš„ï¼Œå¹¶æ ¹æ®ä¸“å®¶å†³ç­–è¿›è¡Œäº†ç«‹å³çš„å¥–åŠ±ã€‚ç°åœ¨ï¼Œæˆ‘æƒ³ä½¿ç”¨åœ¨çº¿å¢å¼ºå­¦ä¹ æ¥å®Œå–„è¿™ç§è„±æœºåŸ¹è®­çš„æ¨¡å‹ï¼Œåœ¨è¿™ç§æ¨¡å‹ä¸­ï¼Œä¸åŸºå‡†ç›¸æ¯”ï¼Œæ ¹æ®IPCçš„æ”¹è¿›æ¥è®¡ç®—å¥–åŠ±ï¼ˆä¾‹å¦‚ï¼ŒåƒMockingJayè¿™æ ·çš„æœ€å…ˆè¿›çš„ç­–ç•¥ï¼‰ã€‚ æˆ‘å·²ç»ä¸ºè¿™ç§æ–¹æ³•å†™äº†ä¸€ç§åœ¨çº¿å­¦ä¹ ç®—æ³•ï¼ˆæˆ‘ä¸ºæ­¤æä¾›äº†è¿™ç§æ–¹æ³•ï¼‰ï¼Œä½†æ˜¯æˆ‘ä¼šä¸ºæ‚¨æä¾›äº†åŠªåŠ›ï¼Œå› ä¸ºæˆ‘å¯ä»¥ä»ä¸­åŠªåŠ›è¿›è¡Œç¼–ç ã€‚æˆ‘çš„æ–¹æ³•æœ‰æ„ä¹‰å—ï¼Ÿæ‚¨ä¼šå®Œå–„ä»€ä¹ˆï¼Ÿ ä»¥ä¸‹æƒ…å†µæ‚¨å¯èƒ½åº”è¯¥çŸ¥é“ï¼š  1ï¼‰æ²¡æœ‰ä¸‹ä¸€ä¸ªçŠ¶æ€ï¼ˆs&#39;ï¼‰çš„å»ºæ¨¡ï¼Œå› æ­¤æˆ‘ä¸æ¨¡æ‹Ÿå‘ä¸‹ä¸€ä¸ªçŠ¶æ€è¿‡æ¸¡åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€ï¼ˆs&#39;ï¼‰ï¼ˆs&#39;ï¼‰ï¼Œå› ä¸ºç¼“å­˜é©±é€æ˜¯å•æ­¥å†³ç­–é—®é¢˜ï¼Œå› ä¸ºé©±é€çš„æ•ˆæœä»…åœ¨ä¸‹ä¸€æ­¥çš„æƒ…å†µä¸‹ï¼Œè€Œä¸æ˜¯åœ¨æ‰§è¡Œä¸­ï¼Œå› æ­¤æˆ‘åœ¨æ‰§è¡Œæƒ…å†µä¸‹ï¼Œæˆ‘ä¸å¾—ä¸å°†é©±é€å‡ºå¢ƒï¼Œå› æ­¤ï¼Œæˆ‘æ˜¯åœ¨æ‰§è¡Œçš„æƒ…å†µä¸‹ï¼Œè€Œæˆ‘å´ä¸æ˜¯åœ¨æ‰§è¡Œä¸­ï¼Œè€Œæˆ‘å´ä¸æ˜¯åœ¨æ‰§è¡Œä¸­ï¼Œè€Œæˆ‘å´ä¸æ˜¯åœ¨æ‰§è¡Œä¸­ï¼Œè€Œæˆ‘å´ä¸æ˜¯åœ¨æ‰§è¡ŒèŒƒå›´ã€‚ä»…åœ¨æ¨¡æ‹Ÿç»“æŸæ—¶è§‚å¯Ÿã€‚  2ï¼‰åœ¨çº¿å­¦ä¹ å¾®è°ƒç¦»çº¿å­¦ä¹ ç½‘ç»œ  ç¦»çº¿å­¦ä¹ é˜¶æ®µä½¿ç”¨å¯¹ä¸“å®¶å†³ç­–çš„ç›‘ç£å­¦ä¹  åœ¨çº¿å­¦ä¹ é˜¶æ®µåœ¨çº¿å­¦ä¹ é˜¶æ®µåˆå§‹åŒ–æ”¿ç­– åœ¨çº¿å­¦ä¹ é˜¶æ®µå¯ä»¥æ ¹æ®IPCçš„é™åˆ¶          3 Simulation which is slightly different than textbook examples of RL so,  The reward is based on IPC improvement compared to a baseline policy The same reward is assigned to all eviction actions taken during that simulation  4) The bellman equation is simplified so no traditional Q-Learning bootstrapping (Q(s&#39;)) because I dont have my next stateå»ºæ¨¡ã€‚ç„¶åå°†æ–¹ç¨‹å˜ä¸ºqï¼ˆsï¼Œaï¼‰â†qï¼ˆsï¼Œaï¼‰+Î±ï¼ˆr -qï¼ˆsï¼Œaï¼‰ï¼‰ï¼ˆæˆ‘è®¤ä¸ºï¼‰ æ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°æˆ‘ä¸ºæ­¤é—®é¢˜å†™çš„ç®—æ³•ï¼š https://drive.google.com/file/d/100imnq2eeu_huvvztk6youwkeni13kve/view?usp = sharing   å¾ˆæŠ±æ­‰é•¿ç¯‡æ–‡ç« ï¼Œä½†æˆ‘ç¡®å®åœ¨æ­¤å¤„ç¡®å®å¯ä»¥åœ¨æ­¤å¤„æä¾›æ‚¨çš„å¸®åŠ©å’Œåé¦ˆï¼š)   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/saffarini9     [link]     32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j57qnn/logic_help_for_online_learning/</guid>
      <pubDate>Thu, 06 Mar 2025 22:14:44 GMT</pubDate>
    </item>
    <item>
      <title>å“ªç§æœºå™¨äººæ¨¡æ‹Ÿå™¨æ›´é€‚åˆå¢å¼ºå­¦ä¹ ï¼Ÿ Mujocoï¼ŒSapienæˆ–Isaaclabï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4wa9g/which_robotics_simulator_is_better_for/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘è¯•å›¾é€‰æ‹©æœ€åˆé€‚çš„æ¨¡æ‹Ÿå™¨æ¥åŠ å¼ºæˆ‘çš„ç ”ç©¶æœºå™¨äººæ“çºµä»»åŠ¡ã€‚ Based on my knowledge, MuJoCo, SAPIEN, and IsaacLab seem to be the most suitable options, but each has its own pros and cons:  MuJoCo:  pros: good API and documentation, accurate simulation, large user base large. cons:å¹¶è¡Œæ€§ä¸é‚£ä¹ˆå¥½ï¼ˆéœ€è¦ jax æ‰èƒ½å¹³è¡Œæ‰§è¡Œï¼‰ã€‚        sapienï¼š  ä¼˜ç‚¹ï¼šè‰¯å¥½çš„APIï¼Œè‰¯å¥½çš„APIï¼Œè‰¯å¥½çš„å¹³è¡Œæ€§ã€‚   å¹¶è¡Œæ€§ï¼Œä¸°å¯Œçš„ç‰¹å¾ï¼ŒNVIDIAç”Ÿæ€ç³»ç»Ÿã€‚  consï¼šèµ„æºå¯†é›†å‹ï¼Œå­¦ä¹ æ›²çº¿å¤ªé™¡å³­ï¼Œä»åœ¨è¿›è¡Œé‡å¤§æ›´æ–°ï¼Œæ®æŠ¥é“å®¹æ˜“å‡ºç°ã€‚         &lt;ï¼ -  sc_on- sc_on-&gt; 32;æäº¤ç”±ï¼†ï¼ƒ32; /u/xyllong     [link]     [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4wa9g/which_robotics_simulator_is_better_for/</guid>
      <pubDate>Thu, 06 Mar 2025 14:10:29 GMT</pubDate>
    </item>
    <item>
      <title>å°è¯•ä½¿ç”¨Redditæƒ…æ„Ÿæ¥æ„å»ºè‚¡ç¥¨é¢„æµ‹AI  - è¿™å°±æ˜¯å‘ç”Ÿçš„äº‹æƒ…ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4se5b/tried_building_a_stock_prediction_ai_using_reddit/</link>
      <description><![CDATA[    src =â€œ https://external-preview.redd.it/o1h8yk_m1ywxmiw8cslf3a9ukpx5nt7tzwt0h2dxdxd-4.jpgï¼Ÿå®½åº¦= 320ï¼†amp; crop = smartï¼†amp; auto = webpï¼†amp; s = 1EB7518B4C497829A6E6E6E19370950F5D96EA6E3F57â€œ title =â€œå°è¯•ä½¿ç”¨redditæƒ…æ„Ÿå»ºç«‹è‚¡ç¥¨é¢„æµ‹AI  - è¿™å°±æ˜¯å‘ç”Ÿçš„äº‹æƒ…ï¼â€ /&gt;   ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/u/indows-phase-9280     [link]   ï¼†ï¼ƒ32;   [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4se5b/tried_building_a_stock_prediction_ai_using_reddit/</guid>
      <pubDate>Thu, 06 Mar 2025 10:17:01 GMT</pubDate>
    </item>
    <item>
      <title>åŠ å¼º - éœ€è¦å¸®åŠ©æ”¹å–„å¥–åŠ±ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4pk9n/reinforce_need_help_in_improving_rewards/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä»»ä½•äººéƒ½å¯ä»¥æ¨èæˆ‘å¦‚ä½•æé«˜å¥–åŠ±ã€‚ä»»ä½•æŠ€æœ¯ï¼ŒYTè§†é¢‘ç”šè‡³ç ”ç©¶è®ºæ–‡ã€‚ä¸€åˆ‡éƒ½å¾ˆå¥½ã€‚æˆ‘æ˜¯ä¸€ä¸ªå­¦ç”Ÿåˆšå¼€å§‹RLè¯¾ç¨‹ï¼Œæ‰€ä»¥æˆ‘çœŸçš„ä¸çŸ¥é“ã€‚envï¼Œå¥–åŠ±æ˜¯ç¦»æ•£çš„ã€‚è¯·å¸®åŠ©ğŸ˜­ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/loud_lengthiss4987     [link]    [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4pk9n/reinforce_need_help_in_improving_rewards/</guid>
      <pubDate>Thu, 06 Mar 2025 06:46:30 GMT</pubDate>
    </item>
    <item>
      <title>æ›´æ–°ï¼šç¤çŸ³æ¨¡å‹ - ä¸€ç§ç”¨äºAIè¿ç»­æ€§çš„ç”Ÿæ´»ç³»ç»Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4gm8m/updated_the_reef_model_a_living_system_for_ai/</link>
      <description><![CDATA[       &lt;ï¼ -  sc_off- sc_off-&gt;  ç°åœ¨ï¼Œæ‰€æœ‰çš„æ•°å­¦å’Œä»£ç åœ¨æ‚¨çš„å­¦ä¹ ä¸­ï¼Œæ‚¨çš„å­¦ä¹ äº«å—ã€‚     &lt;ï¼ -  sc_on-&gt; 32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/pseud0nym    href =â€œ https://medium.com/@lina.noor.agi/the-reef-model-a-living-system-for-ai-continuity-0233c39c39c39c3f80â€&gt; [link]    [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4gm8m/updated_the_reef_model_a_living_system_for_ai/</guid>
      <pubDate>Wed, 05 Mar 2025 22:52:44 GMT</pubDate>
    </item>
    <item>
      <title>åˆ†æ­¥æ•™ç¨‹ï¼šä½¿ç”¨Llama 3.1ï¼ˆ8bï¼‰ + Google Colab + GrpoåŸ¹è®­è‡ªå·±çš„æ¨ç†æ¨¡å‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4g234/stepbystep_tutorial_train_your_own_reasoning/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4g234/stepbystep_tutorial_train_your_own_reasoning/</guid>
      <pubDate>Wed, 05 Mar 2025 22:29:52 GMT</pubDate>
    </item>
    <item>
      <title>æ¡¥AIæ¡†æ¶v1.1- Noorç¤çš„æ•°å­¦ï¼Œä»£ç å’Œé€»è¾‘</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j4b4cx/the_bridge_ai_framework_v11_the_math_code_and/</link>
      <description><![CDATA[    src =â€œ https://external-preview.redd.it/018wvvyzwksyluuviqcc9pwpzmqo5sq4lnfwx9veedt0.jpgï¼Ÿå®½åº¦= 640ï¼†amp; crop = smartï¼†amp; auto = webpï¼†amp; s = 87D8DE13AF73711F516FDB479E0A7EEDD353B908â€œ title =â€œæ¡¥æ¢AIæ¡†æ¶V1.1- Noorç¤çš„æ•°å­¦ï¼Œä»£ç å’Œé€»è¾‘â€/&gt;      &lt;ï¼ -  sc_off-&gt;   å‘å¸ƒçš„æ–‡ç« è§£é‡Šäº†æœ¬æ–‡æ¡£ä¸­å‘ç°çš„æ•°å­¦å’Œé€»è¾‘ã€‚æäº¤ç”±ï¼†ï¼ƒ32; /u/u/pseud0nym    href =â€œ https://medium.com/@lina.noor.agi/bridge-ai-framework-framework-framework-only-a5efcd9d01c7â€&gt; [link]    32;   [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j4b4cx/the_bridge_ai_framework_v11_the_math_code_and/</guid>
      <pubDate>Wed, 05 Mar 2025 19:10:59 GMT</pubDate>
    </item>
    <item>
      <title>Andrew G. Bartoå’ŒRichard S. Suttonè¢«ä»»å‘½ä¸º2024 ACM A.M.å›¾çµå¥–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j472l7/andrew_g_barto_and_richard_s_sutton_named_as/</link>
      <description><![CDATA[   /u/u/meepinator     &lt;a href =â€œ https://www.reddit.com/r/reinforeccationlearning/comments/comments/1j472l7/andrew_g_barto_and_richard_richard_richard_s_s_sutton_neamed_as/â€]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j472l7/andrew_g_barto_and_richard_s_sutton_named_as/</guid>
      <pubDate>Wed, 05 Mar 2025 16:29:27 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ ç‡è®¡ç®—</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j46zj1/learning_rate_calculation/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œæˆ‘ç›®å‰æ­£åœ¨æ’°å†™åŒ»å­¦ç¡•å£«å­¦ä½è®ºæ–‡ï¼Œåœ¨å¾—åˆ†å¼ºåŒ–å­¦ä¹ ä»»åŠ¡æ—¶éœ€è¦å¸®åŠ©ã€‚ä»åŸºæœ¬ä¸Šæ¥è¯´ï¼Œå—è¯•è€…æ‰§è¡Œäº†é€†è½¬å­¦ä¹ ä»»åŠ¡ï¼Œæˆ‘æƒ³ä½¿ç”¨æœ€ç®€å•çš„æ–¹æ³•æ¥è®¡ç®—å¹³å‡å­¦ä¹ ç‡ï¼ˆæˆ‘è€ƒè™‘åªä½¿ç”¨recrescorla-wagnerå…¬å¼ï¼Œä½†æ˜¯æˆ‘æ‰¾ä¸åˆ°ä»»ä½•è®ºæ–‡è¡¨æ˜ä¸€ä¸ªäººä¼šè¡¨æ˜ä¸€ä¸ªäººä¼šå¦‚ä½•è®¡ç®—å®ƒï¼‰ã€‚ ï¼‰ã€‚ ï¼‰ã€‚ ï¼Œæ‰€ä»¥æˆ‘è¦é—®æˆ‘å¦‚ä½•æ‰èƒ½å¯åŠ¨åˆºæ¿€åˆºæ¿€çš„åˆºæ¿€æ•ˆæœï¼Œå¹¶åˆºæ¿€åˆºæ¿€çš„åˆºæ¿€æ•ˆæœï¼Œæˆ–è€…æ˜¯åˆºæ¿€çš„åˆºæ¿€æ•ˆæœï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/reinforecricelearning/comments/1j46zj1/learning_rate_calculation/â€&gt; [link]   ï¼†ï¼ƒ32;   [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j46zj1/learning_rate_calculation/</guid>
      <pubDate>Wed, 05 Mar 2025 16:26:02 GMT</pubDate>
    </item>
    <item>
      <title>å¸®åŠ©è°ƒè¯•æˆ‘çš„ç®€å•DQN AI</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1j457st/help_debug_my_simple_dqn_ai/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å¤§å®¶å¥½ï¼Œæˆ‘åˆ¶ä½œäº†ä¸€ä¸ªéå¸¸ç®€å•çš„æ¸¸æˆç¯å¢ƒæ¥ä½¿ç”¨pytorchè®­ç»ƒDQNã€‚è¯¥æ¸¸æˆåœ¨10x10ç½‘æ ¼ä¸Šè¿è¡Œï¼ŒAIçš„å”¯ä¸€ç›®æ ‡æ˜¯è·å¾—é£Ÿç‰©ã€‚&lt; /p&gt;  å¥–åŠ±ç³»ç»Ÿï¼š&lt; /strong&gt; æœç€é£Ÿç‰©è¿ˆè¿›ï¼š-1 è¿œç¦»é£Ÿç‰©ï¼š-10 åç¦»ç•Œé™ï¼š-100ï¼ˆgame of the the the the ai nocy the Forky to the the In It It It It It Itikeï¼Œyourty Itik to yourties the Inding Itikeï¼Œ ï¼ˆè¯·å‚è§ä¸‹é¢çš„è§†é¢‘ï¼‰ã€‚å‡ºäºæŸç§åŸå› ï¼Œå®ƒæœ‰æ—¶ä¹Ÿä¼šè¶…å‡ºèŒƒå›´ã€‚ æˆ‘å·²ç»å°è¯•å¢åŠ åŸ¹è®­æƒ…èŠ‚ï¼Œä½†é—®é¢˜ä»ç„¶å‘ç”Ÿã€‚æœ‰ä»€ä¹ˆæƒ³æ³•ä¼šå¯¼è‡´è¿™ä»¶äº‹ï¼ŸçœŸçš„å¾ˆæ„Ÿè°¢ä»»ä½•è§è§£ã€‚è°¢è°¢ã€‚  æºä»£ç ï¼š  æ¸¸æˆç¯å¢ƒ  snake_game.pyï¼š   dqn class   utils.pyï¼š href =â€œ https://pastebin.com/raw/fepnsluvâ€&gt; https://pastebin.com/raw/fepnsluv  href =â€œ https://pastebin.com/raw/ndftrbjxâ€&gt; https://pastebin.com/raw/ndftrbjx  href =â€œ https://reddit.com/link/1j457st/video/9sm5x7clyvme1/playerâ€&gt; https://reddit.com/link/link/1j457st/video/9sm5x7clyvmevme1/player  /u/u/unlikely_tax_4619       [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1j457st/help_debug_my_simple_dqn_ai/</guid>
      <pubDate>Wed, 05 Mar 2025 15:10:14 GMT</pubDate>
    </item>
    </channel>
</rss>