<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯æ—¨åœ¨æ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå’Œå­¦ä¹ å¦‚ä½•æœ€ä½³è·å¾—å¥–åŠ±çš„AI/ç»Ÿè®¡æ•°æ®çš„å­åœºã€‚ä¾‹å¦‚Alphagoï¼Œä¸´åºŠè¯•éªŒå’ŒA/Bæµ‹è¯•ä»¥åŠAtariæ¸¸æˆã€‚</description>
    <lastBuildDate>Tue, 25 Feb 2025 18:24:17 GMT</lastBuildDate>
    <item>
      <title>äº‹åç»éªŒé‡æ’­ï¼ˆå¥¹ï¼‰è¡¨ç°çš„ä¸»è¦è´¡çŒ®è€…æ˜¯ä»€ä¹ˆ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iy1ta1/what_is_the_primary_contributor_to_hindsight/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä½ å¥½ï¼Œæˆ‘æœ€è¿‘ä¸€ç›´åœ¨ç ”ç©¶åè§†ç»éªŒé‡æ’­ï¼ˆå¥¹ï¼‰ï¼Œæˆ‘ä¸€ç›´åœ¨ç ”ç©¶å¥¹çš„æœºåˆ¶åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚ åœ¨æˆ‘çœ‹æ¥ï¼Œå¥¹åœ¨ä¸¤ä¸ªæ–¹é¢å¢å¼ºäº†æ€§èƒ½ï¼š   å¢å¼ºæ¢ç´¢ï¼š  åœ¨ç¨€ç–çš„å¥–åŠ±ä¸­ç¯å¢ƒï¼Œå¦‚æœä»£ç†æœªèƒ½è¾¾åˆ°æœ€åˆçš„ç›®æ ‡ï¼Œå®ƒå‡ ä¹ä¸ä¼šè·å¾—ä»»ä½•å¥–åŠ±ï¼Œä»è€Œå¯¼è‡´ç¼ºä¹å­¦ä¹ ä¿¡å·å¹¶è¿«ä½¿ä»£ç†ç»§ç»­éšæœºæ¢ç´¢ã€‚ å¥¹é€šè¿‡ä½¿ç”¨æœ€ç»ˆçŠ¶æ€é‡æ–°å®šä¹‰äº†ç›®æ ‡ä½œä¸ºå…è®¸ä»£ç†å•†è·å¾—å®é™…å¯è¾¾åˆ°çš„çŠ¶æ€çš„å¥–åŠ±çš„ç›®æ ‡ã€‚ é€šè¿‡æ­¤è¿‡ç¨‹ï¼Œä»£ç†å•†é€šè¿‡éšæœºè¡ŒåŠ¨ä»è¾¾åˆ°çš„å„ç§æœ€ç»ˆçŠ¶æ€ä¸­å­¦ä¹ ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°äº†è§£ç¯å¢ƒ    ç­–ç•¥æ¦‚æ‹¬ï¼š  å¥¹å°†ç›®æ ‡ä¸å›½å®¶ä¸€èµ·æä¾›ç»™ç½‘ç»œçš„è¾“å…¥ï¼Œå…è®¸æœ‰æ¡ä»¶å­¦ä¹ çš„æ”¿ç­– - è€ƒè™‘å›½å®¶å’ŒæŒ‡å®šç›®æ ‡ã€‚ è¿™ä½¿ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ â€œé‡‡å–å“ªç§è¡ŒåŠ¨å’Œç‰¹å®šç›®æ ‡â€ï¼Œä»è€Œæé«˜äº†å…¶åœ¨ä¸åŒä¸åŒçš„ä¸åŒçš„èƒ½åŠ›ç›®æ ‡è€Œä¸æ˜¯ä»…é™äºä¸€ä¸ªç›®æ ‡ã€‚ ul&gt;   é‰´äºè¿™äº›è¦ç‚¹ï¼Œæˆ‘å¾ˆå¥½å¥‡å“ªä¸ªå› ç´ ï¼ˆå¢å¼ºçš„æ¢ç´¢æˆ–æ”¿ç­–æ¦‚æ‹¬ï¼‰åœ¨å¥¹çš„æˆåŠŸè§£å†³ç¨€ç–å¥–åŠ±é—®é¢˜æ–¹é¢çš„æˆåŠŸä¸­æ‰®æ¼”ç€æ›´å…³é”®çš„ä½œç”¨ã€‚ å¦å¤–ï¼Œæˆ‘è¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æœçŠ¶æ€ç©ºé—´ä¸ºr  2 &lt; /sup&gt;ï¼Œç›®æ ‡æ˜¯ï¼ˆ2,2ï¼‰ï¼Œä½†æ˜¯ä»£ç†äººæ°å¥½ä»…åœ¨ç¬¬äºŒä¸ªè±¡é™å†…æ¢ç´¢ï¼Œé‚£ä¹ˆæœ€ç»ˆçŠ¶æ€å°†å±€é™äºè¯¥åœ°åŒºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ”¿ç­–å¯èƒ½å¾ˆéš¾å°†å…¶æ¨å¹¿åˆ°æ¢ç´¢åŒºåŸŸä¹‹å¤–çš„ï¼ˆ2,2ï¼‰ä¹‹ç±»çš„ç›®æ ‡ã€‚è¿™æ ·çš„é™åˆ¶å°†å¦‚ä½•å½±å“å¥¹çš„è¡¨ç°ï¼Ÿ &gt; æ„Ÿè°¢æ‚¨çš„è§è§£å’Œæ‚¨å¯ä»¥å…±äº«çš„ä»»ä½•ç›¸å…³å®éªŒç»“æœã€‚  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/drlc_     [link]    [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iy1ta1/what_is_the_primary_contributor_to_hindsight/</guid>
      <pubDate>Tue, 25 Feb 2025 18:20:38 GMT</pubDate>
    </item>
    <item>
      <title>Qå­¦ä¹ ï¼ŒæŠ˜æ‰£ç³»æ•°ä¸º0ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixzkgs/qlearning_with_a_discount_factor_of_0/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å—¨ï¼Œæˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªé¡¹ç›®ï¼Œä»¥å®ç°Q-å­¦ä¹ çš„ä»£ç†ã€‚æˆ‘åªæ˜¯æ„è¯†åˆ°å¯¹ç¯å¢ƒï¼ŒçŠ¶æ€å’ŒåŠ¨ä½œè¿›è¡Œäº†é…ç½®ï¼Œå› æ­¤å½“å‰çš„è¡ŒåŠ¨ä¸ä¼šå½±å“æœªæ¥çš„çŠ¶æ€æˆ–å¥–åŠ±ã€‚æˆ‘è®¤ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŠ˜ç°å› å­åº”è¯¥ç­‰äºé›¶ï¼Œä½†æ˜¯æˆ‘ä¸çŸ¥é“Qå­¦ä¹ ä»£ç†æ˜¯å¦æœ‰æ„ä¹‰è§£å†³æ­¤ç±»é—®é¢˜ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œå®ƒæ¯”MDPæ›´åƒæ˜¯ä¸Šä¸‹æ–‡çš„å¼ºç›—é—®é¢˜ã€‚ Qå­¦ä¹ ç®—æ³•çš„åç§°ä¸º0ï¼Œæˆ–ç­‰æ•ˆç®—æ³•ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/reinforevericeslearning/comments/1ixzkgs/qlearning_with_a_a_discount_factor_of_0/â€&gt; [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixzkgs/qlearning_with_a_discount_factor_of_0/</guid>
      <pubDate>Tue, 25 Feb 2025 16:50:04 GMT</pubDate>
    </item>
    <item>
      <title>ç²¾ç¡®çš„ä»¿çœŸæ¨¡å‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixtjk0/precise_simulationmodel/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œ æˆ‘ç›®å‰æ­£åœ¨ä½¿ç”¨Bipedalæœºå™¨äººä»äº‹å¤§å­¦é¡¹ç›®ã€‚æˆ‘æƒ³å®ç°ä¸€ä¸ªåŸºäºRLçš„æ§åˆ¶å™¨è¿›è¡Œè¡Œèµ°ã€‚æ®æˆ‘æ‰€çŸ¥ï¼Œæœ‰å¿…è¦æ‹¥æœ‰ä¸€ä¸ªç²¾ç¡®çš„å­¦ä¹ æ¨¡å‹ï¼Œä»¥ä¾¿æˆåŠŸåœ°è·³å…¥SIM2REALå·®è·ã€‚æˆ‘ä»¬åœ¨NXä¸­æœ‰ä¸€ä¸ªCADæ¨¡å‹ï¼Œæˆ‘å¬è¯´æœ‰ä¸€ä¸ªé€‰æ‹©å°†CADè½¬æ¢ä¸ºIsaac Simä¸­çš„UDFã€‚ ï¼Œä½†æ˜¯å“ªäº›å·¥ä¸šâ€œé»„é‡‘æ ‡å‡†â€æ–¹æ³•æ˜¯ä¸ºæ¨¡æ‹Ÿè€Œè·å¾—è‰¯å¥½æ¨¡å‹çš„æ–¹æ³•ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/theoneandonly_ncb      [link]   ï¼†ï¼ƒ32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixtjk0/precise_simulationmodel/</guid>
      <pubDate>Tue, 25 Feb 2025 12:12:12 GMT</pubDate>
    </item>
    <item>
      <title>ç°åœ¨ï¼Œå¢å¼ºå‹å¥—å›¾æ”¯æŒPPOï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixq4nc/reinforceuistudio_now_supports_ppo/</link>
      <description><![CDATA[       &lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œ  racefceui-studioç°åœ¨åŒ…æ‹¬è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ï¼ğŸš€æ‚¨åœ¨æˆ‘ä»¥å‰çš„å¸–å­ä¸­å¯èƒ½çœ‹åˆ°çš„é‚£æ ·ï¼ˆåœ¨è¿™é‡Œâ€ &gt; æˆ‘æ”¶åˆ°äº†è®¸å¤šPPOè¯·æ±‚ï¼Œç»ˆäºåœ¨è¿™é‡Œï¼å¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œè¯·æ£€æŸ¥ä¸€ä¸‹ï¼Œè®©æˆ‘çŸ¥é“æ‚¨çš„æƒ³æ³•ã€‚å¦å¤–ï¼Œä¿æŒç®—æ³•è¯·æ±‚çš„åˆ°æ¥ - æ‚¨çš„åé¦ˆæœ‰åŠ©äºä½¿å·¥å…·å˜å¾—æ›´å¥½ï¼  æ–‡æ¡£ï¼š https://docs.reinforceui-studio.com/algorithm-algorithms/algorithm_lists/algorithm_list  githubä»£ç ï¼š https://github.com/dvalenciar/dvalenciar/reinforceui-studio  &gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/dvr_dvr     [link]        [æ³¨é‡Š] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixq4nc/reinforceuistudio_now_supports_ppo/</guid>
      <pubDate>Tue, 25 Feb 2025 08:18:11 GMT</pubDate>
    </item>
    <item>
      <title>DDPGé—®é¢˜</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixh6k0/ddpg_issue/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixh6k0/ddpg_issue/</guid>
      <pubDate>Tue, 25 Feb 2025 00:02:36 GMT</pubDate>
    </item>
    <item>
      <title>åœ°å¹³çº¿å¾ˆé•¿çš„ç¯å¢ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ix9yx3/environments_with_extremely_long_horizons/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;   hi ash all  æˆ‘æ­£åœ¨å°è¯•æŸ¥æ‰¾å…·æœ‰å‰§é›†çš„ç¯å¢ƒï¼Œè¿™äº›å‰§é›†è¦å®Œæˆæ•°ä»¥ä¸‡è®¡çš„æ­¥éª¤å®Œæˆã€‚ Starcraft 2ï¼ˆæ•°åƒï¼‰ï¼ŒDOTA 2ï¼ˆ20Kï¼‰å’ŒMinecraftï¼ˆ24Kï¼‰å±äºè¿™ä¸€ç±»åˆ«ã€‚æœ‰äººçŸ¥é“ç›¸å…³ç¯å¢ƒå—ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/lilhairdy     [link]       [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ix9yx3/environments_with_extremely_long_horizons/</guid>
      <pubDate>Mon, 24 Feb 2025 19:04:06 GMT</pubDate>
    </item>
    <item>
      <title>ä¸RLä¸€èµ·ä½¿ç”¨çš„æœ€ä½³æœºå™¨äººæ¨¡æ‹Ÿå™¨</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ix8eux/best_robotic_simulator_to_use_with_rl/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å—¨ï¼Œæˆ‘æ­£åœ¨å°è¯•æ¨¡æ‹Ÿæˆ‘çš„æœºå™¨äººå¿…é¡»ä¸è¿æ¥åˆ°æœ«ç«¯æ•ˆåº”å™¨çš„ä¼ æ„Ÿå™¨è®¾å¤‡è¿›è¡Œäº¤äº’çš„ç¯å¢ƒï¼Œå¹¶ä½¿ç”¨RLè¿›è¡Œè¯»æ•°ã€‚æˆ‘å¸Œæœ›ç„¶ååœ¨å®é™…çš„ç¡¬ä»¶ä¸Šä½¿ç”¨è¿™ä¸ªè®­ç»ƒæœ‰ç´ çš„ä»£ç†ã€‚æ‚¨ä¼šæ¨èä»€ä¹ˆæ¨¡æ‹Ÿå™¨ï¼Ÿæˆ‘çœ‹è¿‡Pybulletå’ŒGuazeboã€‚ä½†æ˜¯æˆ‘ä¸ç¡®å®šå“ªä¸ªä¼¼ä¹æ˜¯æœ€ç®€å•ï¼Œæœ€ä½³çš„æ–¹æ³•ï¼Œå› ä¸ºæˆ‘åœ¨æ¨¡æ‹Ÿæ–¹é¢å‡ ä¹æ²¡æœ‰ç»éªŒã€‚   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/bananaoramama   href =â€œ https://www.reddit.com/r/reinforevericeslearning/comments/1ix8eux/best_robotic_simulator_to_to_use_with_with_rl/â€&gt; [link]       [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ix8eux/best_robotic_simulator_to_use_with_rl/</guid>
      <pubDate>Mon, 24 Feb 2025 18:01:00 GMT</pubDate>
    </item>
    <item>
      <title>å¥–åŠ±æˆå‹æƒ³æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ix4a85/reward_shaping_idea/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘æœ‰ä¸€ä¸ªå¥–åŠ±å¡‘é€ å½¢å¼çš„æƒ³æ³•ï¼Œæƒ³çŸ¥é“å¤§å®¶éƒ½åœ¨è€ƒè™‘å®ƒã€‚ æƒ³è±¡ä½ æœ‰ä¸€ä¸ªè¶…çº§ç¨€ç–çš„å¥–åŠ±åŠŸèƒ½ï¼Œä¾‹å¦‚+1èµ¢å¾—èƒœåˆ©å’Œ-1çš„æŸå¤±ï¼Œæƒ…èŠ‚å¾ˆé•¿ã€‚è¿™ä¸ªå¥–åŠ±åŠŸèƒ½æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚  å½“ç„¶ï¼Œæˆ‘ä»¬éƒ½çŸ¥é“ç¨€ç–çš„å¥–åŠ±åŠŸèƒ½å¾ˆéš¾å­¦ä¹ ã€‚å› æ­¤ï¼Œå¼•å…¥å¯†é›†çš„å¥–åŠ±åŠŸèƒ½ä¼¼ä¹å¾ˆæœ‰ç”¨ã€‚ä¸€ä¸ªå‡½æ•°ï¼Œè¡¨æ˜æˆ‘ä»¬çš„ä»£ç†å•†æ­£æœæ­£ç¡®æˆ–é”™è¯¯çš„æ–¹å‘è¡Œé©¶ã€‚å®šä¹‰è¿™æ ·çš„å¥–åŠ±å‡½æ•°é€šå¸¸éå¸¸æ£˜æ‰‹ï¼Œä»¥ä¸æˆ‘ä»¬çš„çœŸå®å¥–åŠ±åŠŸèƒ½å®Œå…¨åŒ¹é…ï¼Œå› æ­¤æˆ‘è®¤ä¸ºæš‚æ—¶ä½¿ç”¨æ­¤å¥–åŠ±åŠŸèƒ½ä»¥æœ€åˆä½¿æˆ‘ä»¬çš„ä»£ç†åœ¨æ”¿ç­–ç©ºé—´ä¸­å¤§è‡´é€‚å½“çš„é¢†åŸŸæ˜¯æœ‰æ„ä¹‰çš„ã€‚ ä½œä¸ºå…è´£å£°æ˜ï¼Œæˆ‘å¿…é¡»è¯´æˆ‘æ²¡æœ‰é˜…è¯»ä»»ä½•æœ‰å…³å¥–åŠ±æˆå‹çš„ç ”ç©¶ï¼Œæ‰€ä»¥å¦‚æœæˆ‘çš„æƒ³æ³•å¾ˆæ„šè ¢ï¼Œè¯·åŸè°…æˆ‘ã€‚ æˆ‘è¿‡å»ç”¨DQNåšçš„ä¸€ä»¶äº‹ - åƒç®—æ³•ä¸€æ ·åœ¨åŸ¹è®­è¿‡ç¨‹ä¸­ï¼Œé€æ¸ä»ä¸€ä¸ªå¥–åŠ±åŠŸèƒ½è½¬ç§»åˆ°å¦ä¸€ä¸ªå¥–åŠ±åŠŸèƒ½ã€‚ä¸€å¼€å§‹ï¼Œæˆ‘ä½¿ç”¨äº†100ï¼…çš„è‡´å¯†å¥–åŠ±åŠŸèƒ½å’Œç¨€ç–çš„0ï¼…ã€‚ä¸€æ®µæ—¶é—´åï¼Œæˆ‘å¼€å§‹é€æ¸â€œé€€ç«â€ã€‚è¿™ä¸ªæ¯”ç‡ç›´åˆ°æˆ‘åªä½¿ç”¨çœŸæ­£çš„ç¨€ç–å¥–åŠ±åŠŸèƒ½ã€‚æˆ‘çœ‹å¾—å¾ˆå¥½ã€‚ æˆ‘è¿™æ ·åšçš„åŸå› æ˜¯â€œé€€ç«â€ã€‚æ˜¯å› ä¸ºæˆ‘è®¤ä¸ºQå­¦ä¹ ç®—æ³•å¾ˆéš¾é€‚åº”å®Œå…¨ä¸åŒçš„å¥–åŠ±åŠŸèƒ½ã€‚ä½†æ˜¯æˆ‘ç¡®å®æƒ³çŸ¥é“é€€ç«ç‡æµªè´¹äº†å¤šå°‘æ—¶é—´ã€‚æˆ‘ä¹Ÿä¸å–œæ¬¢é€€ç«ç‡æ˜¯å¦ä¸€ä¸ªè¶…å‚æ•°ã€‚ æˆ‘çš„æƒ³æ³•æ˜¯å°†å¥–åŠ±å‡½æ•°çš„ç¡¬è½¬æ¢åº”ç”¨äºæ¼”å‘˜æ‰¹è¯„ç®—æ³•ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬å°†æ¨¡å‹è®­ç»ƒåœ¨å¯†é›†çš„å¥–åŠ±åŠŸèƒ½ä¸Šã€‚æˆ‘ä»¬å‡è®¾æˆ‘ä»¬å¾—å‡ºäº†ä¸€é¡¹ä½“é¢çš„æ”¿ç­–ï¼Œä¹Ÿæ˜¯è¯„è®ºå®¶çš„ä½“é¢ä»·å€¼ä¼°è®¡ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯å†»ç»“æ¼”å‘˜ï¼Œç¡¬å‡»å¥–åŠ±åŠŸèƒ½ï¼Œå¹¶é‡æ–°å®¡æŸ¥è¯„è®ºå®¶ã€‚æˆ‘è®¤ä¸ºæˆ‘ä»¬å¯ä»¥æ¶ˆé™¤é«˜å‚æ•°ï¼Œå› ä¸ºç°åœ¨æˆ‘ä»¬å¯ä»¥è®­ç»ƒï¼Œç›´åˆ°è¯„è®ºå®¶çš„é”™è¯¯è¾¾åˆ°ä¸€å®šçš„é—¨æ§›ä¸ºæ­¢ã€‚æˆ‘æƒ³è¿™æ˜¯ä¸€ä¸ªæ–°çš„è¶…å‚æ•°ã€‚æ— è®ºå¦‚ä½•ï¼Œæˆ‘ä»¬ä¼šè§£å¼€æ¼”å‘˜å¹¶æ¢å¤æ­£å¸¸çš„åŸ¹è®­ã€‚ æˆ‘è®¤ä¸ºè¿™åœ¨å®è·µä¸­åº”è¯¥å¾ˆå¥½ã€‚æˆ‘è¿˜æ²¡æœ‰æœºä¼šå°è¯•ã€‚ä½ ä»¬éƒ½å¯¹è¿™ä¸ªæƒ³æ³•æœ‰ä½•çœ‹æ³•ï¼Ÿæœ‰ä»€ä¹ˆç†ç”±æœŸæœ›å®ƒè¡Œä¸é€šå—ï¼Ÿæˆ‘ä¸æ˜¯æ¼”å‘˜ - æ‰¹è¯„ç®—æ³•çš„ä¸“å®¶ï¼Œæ‰€ä»¥è¿™ä¸ªæƒ³æ³•ç”šè‡³æ²¡æœ‰æ„ä¹‰ã€‚ è®©æˆ‘çŸ¥é“ï¼è°¢è°¢ã€‚  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/sandsnip3r     [link]   ï¼†ï¼ƒ32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ix4a85/reward_shaping_idea/</guid>
      <pubDate>Mon, 24 Feb 2025 15:12:25 GMT</pubDate>
    </item>
    <item>
      <title>200 for LLM FINETUNTININGçš„200ä¸ªç»„åˆèº«ä»½å’Œå®šç†æ•°æ®é›†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ix488a/200_combinatorial_identities_and_theorems_dataset/</link>
      <description><![CDATA[       ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/databaebee     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]    /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ix488a/200_combinatorial_identities_and_theorems_dataset/</guid>
      <pubDate>Mon, 24 Feb 2025 15:09:58 GMT</pubDate>
    </item>
    <item>
      <title>Simbav2ï¼šå¯æ‰©å±•æ·±åº¦å¢å¼ºå­¦ä¹ çš„è¶…é€æ˜æ ‡å‡†åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ix04ur/simbav2_hyperspherical_normalization_for_scalable/</link>
      <description><![CDATA[     å¼•å…¥ simbav2ï¼   ğŸ“„é¡¹ç›®é¡µé¢ï¼š https://dojeon-ai.github.io/simbav2/  ğŸ“„çº¸ï¼š https://arxiv.org/abs/2502.15280   ğŸ”—ä»£ç ï¼š https://github.com/dojeon-ai/simbav2     simbav2æ˜¯ä¸€ç§ç®€å•ï¼Œå¯æ‰©å±•çš„RLä½“ç³»ç»“æ„é€šè¿‡ç®€å•åœ°ç”¨Simbav2æ›¿æ¢MLPï¼Œ&lt; /strong&gt;ã€‚&lt; /strong&gt;ã€‚æ¼”å‘˜è¯„è®ºå®¶åœ¨57ä¸ªè¿ç»­çš„æ§åˆ¶ä»»åŠ¡ï¼ˆMujocoï¼Œdmcontrolï¼ŒMyosuiteï¼Œhumyoid-Benchï¼‰ä¸­å®ç°äº†æœ€å…ˆè¿›çš„è¡¨ç°ï¼ˆSOTAï¼‰ã€‚  å®ƒä¸ä½“è‚²é¦†1.0.0 API   - å°è¯•ä¸€ä¸‹ï¼ ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶ä¸ä¹‹ä¼¸å‡ºæ´æ‰‹ï¼šï¼‰ &lt; /div&gt; &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/joonleesky     [link]     [æ³¨é‡Š]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ix04ur/simbav2_hyperspherical_normalization_for_scalable/</guid>
      <pubDate>Mon, 24 Feb 2025 11:43:23 GMT</pubDate>
    </item>
    <item>
      <title>å†™äº†æˆ‘å…³äºç”Ÿé”ˆçš„å¼ºåŒ–å­¦ä¹ çš„è®ºæ–‡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iwyveb/wrote_my_thesis_on_reinforcement_learning_in_rust/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/dashdeckers     [link]       [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iwyveb/wrote_my_thesis_on_reinforcement_learning_in_rust/</guid>
      <pubDate>Mon, 24 Feb 2025 10:18:10 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘çš„å¼ æ¿çš„ä¸»è¦é—®é¢˜ï¼è¯·å¸®åŠ©æˆ‘</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iwyefh/major_issue_with_my_tensorboard_pls_help_me/</link>
      <description><![CDATA[      iæˆ‘æ­£åœ¨è®­ç»ƒRLç®—æ³•ï¼Œå¹¶åœ¨å¼ æ¿ä¸­è®°å½•ç»“æœã€‚æˆ‘æ˜¯Tensorboardçš„æ–°æ‰‹ã€‚å½“æˆ‘ä»…è®°å½•æ•°æ®æ—¶ï¼Œæˆ‘ä¸çŸ¥é“æ—¶ï¼Œæˆ‘ä¸çŸ¥é“æ—¶æƒ…èŠ‚å›æŠ¥å’Œé•¿åº¦æ˜¯æ•…éšœæˆ–é”™è¯¯ã€‚é—®é¢˜åœ¨äºï¼Œæ—¥å¿—ä»¥0ä¸ªæ­¥éª¤å¼€å§‹ï¼Œå›¾è¡¨å¯ä»¥åœ¨100ä¸‡æ­¥ä¸­å¯ä»¥ä½¿ç”¨ï¼Œä¹‹åçš„å¥–åŠ±å´ä»¥100ä¸‡ä¸ªIEçš„å·®è·ç§»åŠ¨ã€‚æœ€åä¸€ä¸ªæ•°æ®ä»…å…·æœ‰20mè‡³21mçš„å›¾å½¢ã€‚  æˆ‘ä¸çŸ¥é“æˆ‘æ˜¯ä»€ä¹ˆé”™è¯¯çš„äº‹æƒ…ï¼Œä½ ä»¬å¯ä»¥æŒ‡å¯¼æˆ‘å—ï¼Ÿ  å¯¼å…¥ç™»å½•ä»torch.utils.utils.tensorboard import import import import oså¯¼å…¥imports imports imports import import inct loggerï¼šdef __init __ï¼ˆselfï¼Œrun_nameï¼Œargsï¼‰ï¼šself.log_name = f&#39;logs/{run_name}&#39;self.start_time = time.timeï¼ˆï¼‰self.n_eps = 0 os.makedirsï¼ˆ&#39;logs&#39;ï¼Œstef_ok = trueï¼‰os.makedirsï¼ˆ&#39;models&#39;ï¼Œequent_ok = trueï¼‰self.writer = summaryWriterï¼ˆself.log_nameï¼‰logging.basicconfigï¼ˆlevel = = logging.debugï¼Œæ ¼å¼=&#39;ï¼…ï¼ˆasctimeï¼‰sï¼…ï¼ˆæ¶ˆæ¯ï¼‰s&#39;ï¼Œhandlers = [ logging.streamhandlerï¼ˆï¼‰ï¼Œlogging.filehandlerï¼ˆf&#39;{self.log_name} .log&#39;ï¼Œï¼†quot&#39;aï¼†quot;ï¼†quot;ï¼†quot;ï¼†quort;]ï¼Œ]ï¼Œdatefmt =&#39;ï¼…y/ï¼…m/ï¼…m/ï¼…dï¼…iï¼šï¼…mï¼šï¼…mï¼šï¼…sï¼…sï¼…p p p &#39;ï¼‰logging.infoï¼ˆargsï¼‰def log_scalarsï¼ˆselfï¼Œscalar_dictï¼Œstepï¼‰ï¼šå¯¹äºé”®ï¼Œval in scalar_dict.itemsï¼ˆï¼‰ï¼šself.writer.add_scalarï¼ˆkeyï¼Œvalï¼Œstepï¼‰def log_episodeï¼ˆselfï¼Œinfoï¼Œstepï¼‰ï¼šrewards = info = info [ï¼†quort returns/epoindic_rewardï¼†quorts;] length = infor = info = info = info; ï¼ƒä½¿ç”¨é•¿åº¦è€Œä¸æ˜¯å¥–åŠ±å®Œæˆçš„trackæƒ…èŠ‚=é•¿åº¦=é•¿åº¦ï¼†gt; 0å¯¹äºiåœ¨èŒƒå›´å†…ï¼ˆlenï¼ˆrewardsï¼‰ï¼‰ï¼‰ï¼šå¦‚æœå®Œæˆäº†_episodes [i]ï¼šself.n_eps += 1 powers_data = {ï¼†querts; returns/ependodic_rewardï¼†quotï¼†quotï¼†quotï¼†quotï¼†quot; } self.log_scalarsï¼ˆemotive_dataï¼Œstepï¼‰time_expired =ï¼ˆtime.timeï¼ˆï¼‰ - self.start_timeï¼‰ / 60 /60 logging.infoï¼ˆfï¼†quot; gt; ep = {self.n_eps} |æ€»æ­¥éª¤= {step}ï¼†quet; fï¼†quets; fï¼†quest; | reward = {rewards [rewards [i]} |é•¿åº¦}ï¼†quot;æˆ‘ç”¨æ¥è¿™æ ·åšçš„ä»£ç ã€‚  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/decter_prune_9756      [link]   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iwyefh/major_issue_with_my_tensorboard_pls_help_me/</guid>
      <pubDate>Mon, 24 Feb 2025 09:46:11 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•æŒæ¡å¼ºåŒ–å­¦ä¹ çš„å¯èƒ½æ€§ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iwwpmo/how_to_master_probability_for_reinforcement/</link>
      <description><![CDATA[åœ¨æˆ‘çš„æ¦‚ç‡æŠ€èƒ½ä¸æ˜¯ä»–ä»¬éœ€è¦çš„åœ°æ–¹ã€‚æˆ‘åœ¨æœ¬ç§‘æœŸé—´å‚åŠ äº†ä¸€ä¸ªæ¦‚ç‡è¯¾ç¨‹ï¼Œä½†æ˜¯æˆ‘å¿˜è®°äº†å¤§éƒ¨åˆ†å†…å®¹ã€‚ æˆ‘ä¸ä»…æƒ³åˆ·æ–°æˆ‘çš„è®°å¿†ï¼Œæˆ‘æƒ³å˜å¾—æ“…é•¿äºæ¦‚ç‡ï¼Œç›´åˆ°æˆ‘å¯ä»¥ç›´è§‚åœ°å°†å…¶åº”ç”¨äºRLå’Œæœºå™¨å­¦ä¹ çš„å…¶ä»–é¢†åŸŸã€‚ å¯¹äºé‚£äº›æŒæ¡æ¦‚ç‡çš„äººæ¥è¯´ï¼Œæœ€é€‚åˆæ‚¨çš„äººï¼Ÿæœ‰ä»€ä¹ˆä¹¦ç±ï¼Œè¯¾ç¨‹ï¼Œé—®é¢˜é›†æˆ–æ¯æ—¥ä¹ æƒ¯ä¼šå¸¦æ¥å¾ˆå¤§çš„ä¸åŒå—ï¼Ÿ å¾ˆæƒ³å¬å¬æ‚¨çš„å»ºè®®ï¼  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32 ;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/hudhuddz     [link]        [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iwwpmo/how_to_master_probability_for_reinforcement/</guid>
      <pubDate>Mon, 24 Feb 2025 07:43:38 GMT</pubDate>
    </item>
    <item>
      <title>RLå¯¹äºAGIï¼Œé‡ç‚¹åº”è¯¥æ”¾åœ¨ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iwrip5/rl_for_agi_what_should_the_focus_be_on/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  é‚£äº›è®¤ä¸ºRLæ˜¯é€šå¾€AGIçš„å¯è¡Œé€”å¾„çš„äººï¼Œå½“å‰éœ€è¦ä¸“æ³¨äºåœ¨RLä¸­æ±‚è§£çš„å½“å‰å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿäººä»¬å¯ä»¥é€‰æ‹©ä¸ºæ­¤åšå‡ºå“ªäº›ç ”ç©¶é—®é¢˜ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/aliaslight     [link]     [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iwrip5/rl_for_agi_what_should_the_focus_be_on/</guid>
      <pubDate>Mon, 24 Feb 2025 02:33:15 GMT</pubDate>
    </item>
    <item>
      <title>åŸºäºæ¨¡å‹çš„RLï¼šå¼€ç¯æ§åˆ¶æ˜¯äºšæœ€ä½³é€‰æ‹©ï¼Œå› ä¸º..ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iwhd9t/model_based_rl_openloop_control_is_suboptimal/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘ç›®å‰æ­£åœ¨è§‚çœ‹Sergei Levineçš„è®²åº§ã€‚ä»–æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ„æºï¼›å°†å­¦ä¹ ç†è®ºçš„è”ç³»èµ·æ¥å¾ˆå¤šã€‚ä½¿ç”¨æ•°å­¦æµ‹è¯•çš„ç±»æ¯”ï¼Œé€šè¿‡å¼€ç¯æ§åˆ¶é€šè¿‡å¼€ç¯æ§åˆ¶æ˜¯äºšæœ€ä½³çš„ã€‚æˆ‘æƒ³è±¡è¿™ä¸ªç±»æ¯”å°±åƒæœç´¢æ ‘ä¸€æ ·ä¾‹å¦‚ï¼Œä½†å³ä½¿å¦‚æ­¤ï¼Œå®ƒä¹Ÿæœ‰ç‚¹æ¸…é™¤ã€‚ä½†æ˜¯ï¼Œè¦ä¸æŠ½è±¡çš„ä¾‹å­ä¿æŒåœ¨ä¸€èµ·ï¼Œä¸ºä»€ä¹ˆè¯¥æ¨¡å‹ä¸ä¼šåŸºäºä»¥å‰ä¸ç¯å¢ƒäº’åŠ¨çš„ç»éªŒäº§ç”Ÿå¯èƒ½æ€§ï¼Ÿ Sergeiæåˆ°ï¼Œå¦‚æœæˆ‘ä»¬é€‰æ‹©æµ‹è¯•ï¼Œæˆ‘ä»¬å°†å¾—åˆ°æ­£ç¡®çš„ç­”æ¡ˆï¼Œä½†ä¹Ÿæ„å‘³ç€æ²¡æœ‰åŠæ³•å°†è¿™äº›ä¿¡æ¯ä¼ é€’ç»™æ¨¡å‹ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»£ç†å•†çš„å†³ç­–è€…ï¼‰ã€‚æ„Ÿè§‰ä»ç°å®ä¸­æ¶ˆé™¤äº†ï¼Œå³å¦‚æœå¯èƒ½çš„æµ‹è¯•å°ºå¯¸è¶³å¤Ÿå¤§ï¼Œé‚£ä¹ˆæœ€ä½³çš„åŠ¨ä½œå°±æ˜¯å›å®¶ã€‚å¦‚æœæ‚¨å¯¹å‚åŠ æµ‹è¯•çš„èƒ½åŠ›æœ‰ä»»ä½•ä¿¡å¿ƒï¼ˆä¾‹å¦‚ä»¥å‰çš„æ¨å‡ºç»éªŒï¼‰ï¼Œé‚£ä¹ˆæ‚¨çš„æœ€ä½³ç­–ç•¥ä¼šæ›´æ”¹ï¼Œä½†è¿™æ˜¯ä¿¡æ¯ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¸ä»¥å‰çš„ç¤ºä¾‹ç›¸åŒçš„åˆ†å¸ƒæ¥ç†è§£ã€‚  ä¹Ÿè®¸æˆ‘ç¼ºå°‘æ ‡è®°ã€‚ä¸ºä»€ä¹ˆå¼€æ”¾ç¯æ§åˆ¶æ¬¡ä¼˜ï¼Ÿ   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/reinforevercylearning/comments/1iwhd9t/model_based_rl_rl_openloop_iscontrol_is_suboptimal/â€&gt; [link]  &lt;a href =â€œ https://www.reddit.com/r/reinforevectionlearning/comments/1iwhd9t/model_based_rl_rl_openloop_control_is_is_suboptimal/]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iwhd9t/model_based_rl_openloop_control_is_suboptimal/</guid>
      <pubDate>Sun, 23 Feb 2025 18:52:18 GMT</pubDate>
    </item>
    </channel>
</rss>