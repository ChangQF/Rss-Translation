<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Fri, 01 Dec 2023 18:17:18 GMT</lastBuildDate>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ å¦‚ä½•å¤„ç†å¤šä¸ªåŠ¨ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188iiew/how_does_rl_work_with_multiple_motions/</link>
      <description><![CDATA[ä¾‹å¦‚ï¼Œè¿™æ˜¯ä½¿ç”¨Unityåˆ›å»ºçš„ï¼Œè¿˜æ˜¯å®ƒè‡ªå·±çš„gymï¼Ÿ https://www.youtube.com/watch?v=SsJ_AusntiU&amp;pp=ygUncmVpbmZvcmNlbWVudCBsZ WFybmluZyB0ZWFjaCBob3cgdG8gYm94&lt; /p&gt; ä»è§†é¢‘ä¸­å¾ˆéš¾çœ‹å‡ºã€‚  ä»¤äººå›°æƒ‘çš„æ˜¯å®ƒä»¬æ˜¯å¦‚ä½•é“¾æ¥åœ¨ä¸€èµ·çš„ï¼Œä»¥åŠæœºå™¨å­¦ä¹ ä»£ç†æ˜¯å¦å¯ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘äº†è§£å¦‚ä½•è®­ç»ƒæ¨¡å‹ç«™ç«‹ï¼Œä½†å¦‚ä½•åŒæ—¶ç«™ç«‹ã€èµ·èº«ã€èµ°åŠ¨å’Œè£…ç®±ï¼Ÿ   è¿™ä¸€åˆ‡éƒ½æ˜¯åœ¨æ•°åäº¿æ¬¡é‡å¤ä¸­é€šè¿‡ç›¸åŒçš„è§‚å¯Ÿå’Œç›¸åŒçš„å¥–åŠ±å®Œæˆçš„å—ï¼Ÿ  æˆ–è€…æ˜¯å¦æœ‰ 1 ä¸ªæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•ç«™ç«‹ï¼Œ1 ä¸ªæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•ç«™èµ·æ¥ã€‚ 1 ä¸ªå­¦ä¹ å¦‚ä½•ç§»åŠ¨çš„ç®€åŒ–æ¨¡å‹ã€‚ç­‰ç­‰ã€‚   ç„¶åè¿™äº›æ¨¡å‹ä½¿ç”¨å¸ƒå¨ƒå¨ƒç‰©ç†åŸç†ç›¸äº’ç»‘å®šã€‚æœ¬è´¨ä¸Šï¼Œæ­£åœ¨å­¦ä¹ çš„æ¨¡å‹ä¸Šçš„å…³èŠ‚ä¸äº†è§£æ¯ä¸ªå•ç‹¬è¿åŠ¨çš„æ¨¡å‹ç»‘å®šåœ¨ä¸€èµ·ã€‚  â€‹ è¿˜æœ‰ï¼Œè¿™äº›å¤©èµ‹æ ‡ç­¾æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿæˆ‘ä¸æ˜ç™½å…¶ä¸­ä»»ä½•ä¸€ä¸ª   ç”±   æäº¤ /u/Sharp-Cat2319   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188iiew/how_does_rl_work_with_multiple_motions/</guid>
      <pubDate>Fri, 01 Dec 2023 18:14:51 GMT</pubDate>
    </item>
    <item>
      <title>Unity ä¹‹å¤–å…è®¸å¯¼å…¥æ¨¡å‹ç­‰çš„ä»»ä½•ç‰©ç†å¼•æ“å¥èº«æˆ¿ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188iazm/any_physics_engine_gyms_outside_of_unity_that/</link>
      <description><![CDATA[æˆ‘å‘ç°ç”¨äºç»Ÿä¸€çš„ ML Agent æœ‰ç‚¹è¿‡æ—¶ä¸”æœ‰å±€é™æ€§ï¼Œå¹¶ä¸”æ¯”æœºå™¨äººæ›´é€‚åˆæ¸¸æˆå¼€å‘ï¼Œæˆ‘æƒ³åˆ›å»ºè‡ªå·±çš„å¥èº«æˆ¿å¯¹äºåƒ 2D æ¸¸æˆè¿™æ ·çš„ç®€å•ä¸œè¥¿ï¼Œå®ƒéå¸¸ç®€å•ï¼Œä½†æˆ‘æƒ³åšä¸€äº› 3D æœºå™¨äººæ¨¡å‹å¹¶ä½¿ç”¨ç¨³å®šçš„åŸºçº¿æ¥é©±åŠ¨å®ƒä»¬ï¼Œä¸ºæ­¤æˆ‘éœ€è¦ä¸€ä¸ªå…·æœ‰ç¢°æ’å’Œç‰©ç†ä»¥åŠæ¨¡å‹/çš„ 3D å¼•æ“çº¹ç†å¯¼å…¥ã€ä¸€äº›ç€è‰²ï¼Œå½“ç„¶è¿˜æœ‰æ¸²æŸ“ã€‚æœ€å¥½æ˜¯ä¹Ÿå¯ä»¥æ¸²æŸ“åˆ° webgl ç¯å¢ƒçš„ä¸œè¥¿ã€‚ æˆ‘å‡è®¾ç¨³å®šåŸºçº¿å¯ä»¥ä¸ä»»ä½• 3D å¼€æºå¼•æ“ä¸€èµ·ä½¿ç”¨ã€‚æ˜¯å¦æœ‰ä¸€äº›éå¸¸åŸºæœ¬çš„ä¸œè¥¿å¯ä»¥ä¸ OpenAI Gym ä¸€èµ·ä½¿ç”¨æ¥å¯¼å…¥æ¨¡å‹ã€æ·»åŠ åˆšä½“å’Œç¢°æ’å‚æ•°ç­‰ã€‚æˆ–è€… OpenAI Gym æ˜¯å¦å·²ç»å…·å¤‡æ‰€æœ‰è¿™äº›åŠŸèƒ½ï¼Ÿ â€‹ â€‹   ç”±   æäº¤ /u/Sharp-Cat2319   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188iazm/any_physics_engine_gyms_outside_of_unity_that/</guid>
      <pubDate>Fri, 01 Dec 2023 18:05:56 GMT</pubDate>
    </item>
    <item>
      <title>ğŸš€ DIAMBRA x OROBIXï¼šå‘å¸ƒ SheepRL å¼ºåŒ–å­¦ä¹ åº“é›†æˆï¼ ğŸ¤–ğŸ®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188eslz/diambra_x_orobix_releasing_sheeprl_reinforcement/</link>
      <description><![CDATA[      æˆ‘ä»¬å¾ˆé«˜å…´å®£å¸ƒä¸é«˜çº§ RL åº“ SheepRL çš„åˆ›å»ºè€… OROBIX è¿›è¡ŒåŠ¨æ€åˆä½œï¼ ğŸ¤ğŸ’¡ ğŸŒŸ ä¸ºä»€ä¹ˆé€‰æ‹© SheepRLï¼Ÿ SheepRL æ— ç¼é›†æˆåˆ° DIAMBRA ä¸­ï¼Œä¸ºç°ä»£ RL ç®—æ³•æä¾›äº†ä¸€æ¡æ¸…æ™°çš„è·¯å¾„ï¼Œé‡ç‚¹å…³æ³¨å¯æ‰©å±•åº”ç”¨ç¨‹åºçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚ ğŸ“š å…¥é—¨ï¼šåœ¨æˆ‘ä»¬çš„å®˜æ–¹ DIAMBRA æ–‡æ¡£ä¸­æ¢ç´¢ SheepRL çš„å¼ºå¤§åŠŸèƒ½ã€‚ DIAMBRA Agents å­˜å‚¨åº“ä¸­åŒ…å«æºä»£ç ç¤ºä¾‹ã€‚ ğŸš€ RL æ¢ç´¢çš„ Swift Launchpadï¼š åªéœ€å‡ è¡Œ Python ä»£ç ï¼Œå³å¯åœ¨æˆ‘ä»¬æ‰€æœ‰çš„æ¸¸æˆä¸Šå¯åŠ¨ RL è®­ç»ƒï¼Œè®© AI æ¢ç´¢å˜å¾—è½»è€Œæ˜“ä¸¾ï¼ /&gt; ğŸ‘‰ é€šè¿‡ä¸‹é¢è¯„è®ºä¸­çš„é“¾æ¥å‘ç°æ›´å¤šä¿¡æ¯ï¼ åŠ å…¥æˆ‘ä»¬ï¼Œæ‹¥æŠ±å¼ºåŒ–å­¦ä¹ ç ”ç©¶çš„æœªæ¥ã€‚ ğŸš€ğŸ¤–âœ¨ DIAMBRA x SheepRL&lt; /a&gt;   ç”±   æäº¤/u/DIAMBRA_AIArena   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188eslz/diambra_x_orobix_releasing_sheeprl_reinforcement/</guid>
      <pubDate>Fri, 01 Dec 2023 15:36:10 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ å¼ºåŒ–å­¦ä¹ ç ”ç©¶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18880wg/learning_rl_research/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘ç°åœ¨æ­£åœ¨ç ”ç©¶å¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘æ­£åœ¨å¯»æ‰¾åŠ å¿«å­¦ä¹ é€Ÿåº¦çš„æ–¹æ³•ã€‚æˆ‘çš„è®¡åˆ’æ˜¯èƒ½å¤Ÿåœ¨è¯¥é¢†åŸŸåšå¥½ç ”ç©¶ã€‚ç°åœ¨æˆ‘æ­£åœ¨ç ”ç©¶ç¦»çº¿å¼ºåŒ–å­¦ä¹ ã€‚  ç°åœ¨æœ‰å¸®åŠ©çš„æ˜¯æˆ‘ä»¬æ¯å‘¨ä¸æˆ‘çš„åšå£«åŒå­¦è¿›è¡Œä¸€æ¬¡ä¼šè®®ã€‚æˆ‘ä»¬å±•ç¤ºæˆ‘ä»¬è¯»è¿‡çš„æ–°ç ”ç©¶è®ºæ–‡ã€‚è½®åˆ°æˆ‘çš„æ—¶å€™æˆ‘ä¼šåˆ†äº«æœ‰å…³ RL è®ºæ–‡çš„å†…å®¹ã€‚  ä½†æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯æˆ‘ä»¬çš„ä¸»é¢˜éå¸¸å¤šæ ·åŒ–ã€‚ä¸€é¡¹ç ”ç©¶è®¡ç®—æœºè§†è§‰ï¼Œä¸€é¡¹ç ”ç©¶å›¾ç¥ç»ç½‘ç»œï¼Œä¸€é¡¹ç ”ç©¶æ—¶é—´åºåˆ—é¢„æµ‹ã€‚æˆ‘æ˜¯å”¯ä¸€ä¸€ä¸ªä»äº‹å¼ºåŒ–å­¦ä¹ çš„äººã€‚ å¦‚æœæˆ‘èƒ½ä¸æ›´å¤šå…·æœ‰ç›¸åŒå…´è¶£çš„äººäº¤è°ˆï¼Œé‚£å°±å¤ªå¥½äº†ã€‚ ä¸ºäº†è¡¥å……èƒŒæ™¯ä¿¡æ¯ï¼Œæˆ‘æ¥è‡ªè²å¾‹å®¾åœ¨è¿™é‡Œå¾ˆéš¾è·å¾—æ”¯æŒæˆ–å…·æœ‰ä¸“ä¸šçŸ¥è¯†çš„å›¢ä½“æ¥æŒ‡å¯¼æˆ‘ã€‚å½“æˆ‘æ„Ÿè§‰è‡ªå·±åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å‡ ä¹æ˜¯å­¤èº«ä¸€äººæ—¶ï¼Œå°±å¾ˆéš¾ä¿æŒåŠ¨åŠ›ã€‚è™½ç„¶æˆ‘åœ¨è·å…°æœ‰ä¸€ä½æ•™æˆç»™äº†æˆ‘å¾ˆå¤šå¸®åŠ©ã€‚ æ‚¨å¯¹åœ¨çº¿å°ç»„ç­‰æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿè¿™å¯ä»¥å¸®åŠ©æˆ‘æ›´å¿«åœ°å­¦ä¹ ï¼ŒåŒ…æ‹¬æ½œåœ¨çš„æŒ‡å¯¼ã€èµ„æºå…±äº«ç­‰ï¼Ÿ è°¢è°¢ï¼   ç”±   æäº¤/u/111user222  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18880wg/learning_rl_research/</guid>
      <pubDate>Fri, 01 Dec 2023 09:44:48 GMT</pubDate>
    </item>
    <item>
      <title>â€œä½¿ç”¨ç›´æ¥åå¥½ä¼˜åŒ– (DPO) çš„æ‰©æ•£æ¨¡å‹å¯¹é½â€ï¼ŒWallace ç­‰äºº 2023 {Salesforce}</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187wknu/diffusion_model_alignment_using_direct_preference/</link>
      <description><![CDATA[       ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187wknu/diffusion_model_alignment_using_direct_preference/</guid>
      <pubDate>Thu, 30 Nov 2023 23:27:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] ä¸€å‘¨åæˆ‘å°†é‡‡è®¿ Rich Suttonï¼Œæˆ‘åº”è¯¥é—®ä»–ä»€ä¹ˆé—®é¢˜ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187t5ir/d_im_interviewing_rich_sutton_in_a_week_what/</link>
      <description><![CDATA[ ç”±   æäº¤ /u/gwern   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187t5ir/d_im_interviewing_rich_sutton_in_a_week_what/</guid>
      <pubDate>Thu, 30 Nov 2023 21:06:43 GMT</pubDate>
    </item>
    <item>
      <title>è§£å†³è½¬å‹å’Œå¥–åŠ±ä¸­çš„åˆ†é…å˜åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187nfvc/addressing_distributional_shifts_in_transitions/</link>
      <description><![CDATA[è§£å†³ RL ä»»åŠ¡ä¸­çš„åˆ†å¸ƒå˜åŒ–çš„æœ€å…ˆè¿›æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ  æˆ‘éœ€è¦å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºäº¤é€šæ§åˆ¶é—®é¢˜ï¼Œå…¶ä¸­äº¤é€šåˆ†å¸ƒï¼ˆè½¦è¾†åˆ°è¾¾ç‡ã€å‡ºå‘åœ°-ç›®çš„åœ°ä½ç½®ç­‰ï¼‰å¯èƒ½éšæ—¶é—´å˜åŒ–ã€‚æˆ‘ç¡®å®å¯ä»¥åœ¨å¤šä¸ªåˆ†å¸ƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†æˆ‘æƒ³ä½¿ç”¨ä¸€äº›æ–¹æ³•ï¼Œè®©æˆ‘èƒ½å¤Ÿå¿«é€Ÿé€‚åº”ä¸åŒçš„åˆ†å¸ƒï¼Œæˆ–è€…å¿«é€Ÿä¸ºå…¶å¾®è°ƒæ–°æ¨¡å‹ã€‚    ç”±   æäº¤ /u/fedetask   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187nfvc/addressing_distributional_shifts_in_transitions/</guid>
      <pubDate>Thu, 30 Nov 2023 17:04:33 GMT</pubDate>
    </item>
    <item>
      <title>åˆ›å»ºè·¨å¤šä¸ªç¯å¢ƒè¿è¡Œçš„å•ä¸ªä»£ç†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187mzev/creating_a_single_agent_that_acts_across_multiple/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œå…ˆæ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼æˆ‘æ­£åœ¨å¼€å±•ä¸€ä¸ª q-learning é¡¹ç›®ï¼Œå…¶ä¸­å•ä¸ªä»£ç†æ­£åœ¨åŠªåŠ›ä¼˜åŒ–è®¸å¤šï¼ˆæ•°åƒå°ï¼‰ç‹¬ç«‹æœºå™¨çš„æ€§èƒ½ã€‚æ‰€æœ‰æœºå™¨éƒ½æ˜¯ç›¸åŒçš„ï¼Œå¹¶åœ¨å®šæœŸæ›´æ–°çš„æ•°æ®åº“ä¸Šç”Ÿæˆç›¸åŒçš„æŒ‡æ ‡ã€‚å‡ å¹´å‰ï¼Œæˆ‘è¯»è¿‡è¿™ä¸ªç¤¾åŒºçš„ä¸€ä¸ªå¸–å­ï¼Œå¬èµ·æ¥å¥½åƒå¯ä»¥åœ¨å¤šä¸ªç¯å¢ƒä¸­åº”ç”¨å•ä¸ªä»£ç†ã€‚é‰´äºè¿™äº›éƒ½æ˜¯ç›¸åŒçš„ç¯å¢ƒå¹¶ç”±å”¯ä¸€çš„ ID è¡¨ç¤ºï¼Œæˆ‘æƒ³çŸ¥é“åœ¨æ„å»ºæ¨¡å‹æ—¶æ˜¯å¦å¯ä»¥åº”ç”¨ä¸€ä¸ªç®€å•çš„å‡½æ•°åˆ†ç»„æ¥åœ¨æ›´å¹¿æ³›çš„æ•°æ®æ•°ç»„ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯ä¹‹å‰åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå°è¯•å°†å…¶éƒ¨ç½²åˆ°æ‰€æœ‰ä¸åŒçš„ç¯å¢ƒä¸­ã€‚å†æ¬¡æ„Ÿè°¢å¤§å®¶çš„å¸®åŠ©ï¼   ç”±   æäº¤/u/Shikaze33_3   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187mzev/creating_a_single_agent_that_acts_across_multiple/</guid>
      <pubDate>Thu, 30 Nov 2023 16:45:03 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨çŸ¢é‡åŸºè§‚æµ‹ç¯å¢ƒä¸Šå®ç° Dreamer v3 æ—¶å‡ºé”™</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187ktu6/error_implementation_dreamer_v3_on_vector_base/</link>
      <description><![CDATA[è¯·é—®æˆ‘åšé”™äº†ä»€ä¹ˆï¼Ÿæˆ‘å°è¯•åœ¨åŸºäºå‘é‡çš„è§‚å¯Ÿçš„è‡ªå®šä¹‰ç¯å¢ƒä¸­ä½¿ç”¨ Dreamerv3 è®­ç»ƒæˆ‘çš„ä»£ç†ã€‚æˆ‘æŒ‰ç…§ Sheaprl æ–¹æ³•æ·»åŠ è‡ªå®šä¹‰ç¯å¢ƒã€‚  è¯·é—®æˆ‘åšé”™äº†ä»€ä¹ˆï¼Ÿæˆ‘å°è¯•åœ¨åŸºäºçŸ¢é‡çš„è§‚å¯Ÿçš„è‡ªå®šä¹‰ç¯å¢ƒä¸­ä½¿ç”¨ Dreamerv3 è®­ç»ƒæˆ‘çš„ä»£ç†ã€‚æˆ‘æŒ‰ç…§ Sheaprl æ–¹æ³•æ·»åŠ è‡ªå®šä¹‰ç¯å¢ƒã€‚è®­ç»ƒä»£ç†å¯¼èˆªåˆ°å…¶ç›®æ ‡ï¼ŒåŒæ—¶é¿å¼€éšœç¢ã€‚  æˆ‘æƒ³ä½¿ç”¨ Dreamer v3ã€‚æˆ‘çš„è§‚å¯Ÿç©ºé—´æ˜¯åŸºäºå¹³é¢å‘é‡çš„è§‚å¯Ÿï¼ˆ23ï¼‰ï¼Œè€Œä¸æ˜¯å›¾åƒï¼Œå¹¶ä¸”åŠ¨ä½œç©ºé—´æ˜¯è¿ç»­çš„äºŒç»´ã€‚æˆ‘æƒ³ç¼–å†™ä¸€ä¸ªä½¿ç”¨ Dreamer v3 çš„è„šæœ¬ã€‚å¦‚æœå¯èƒ½ï¼Œä¸‹é¢çš„è„šæœ¬å°†ä»…é€‚ç”¨äºæˆ‘çš„ç¯å¢ƒï¼š - envsï¼šæˆ‘çš„ç¯å¢ƒ - configs.yaml - dreamer.py -exploration.py - models.py -networks.py -parallel.py -requirements.txt -tools.py æˆ‘æƒ³è¦ä¸€ä¸ªç‰¹å®šçš„ã€å¹²å‡€çš„ä»£ç ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥é’ˆå¯¹å…¶ä»–ç¯å¢ƒå’ŒåŸºäºå›¾åƒçš„é€‰é¡¹ä¿®æ”¹ Dreamer v3ã€‚è¿™è®©æˆ‘å¾ˆéš¾ç®€åŒ–æˆ‘æƒ³åšçš„äº‹æƒ…ã€‚æˆ‘å°†åˆ†äº«æˆ‘çš„ç¯å¢ƒå’Œä¸€ä¸ªå…³äºå¦‚ä½•æµ‹è¯•å®ƒçš„ç®€å•è„šæœ¬ã€‚å¦‚æœæ‚¨èƒ½å¸®åŠ©æˆ‘æˆ–æŒ‡å¯¼æˆ‘å¦‚ä½•ä½¿ç”¨ Dreamer v3 å’ŒåŸºäºå¹³é¢çŸ¢é‡çš„è§‚å¯Ÿç©ºé—´ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚è°¢è°¢ï¼ è¿™æ˜¯æˆ‘çš„ zip æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æˆ‘çš„ç¯å¢ƒï¼š https://www.dropbox.com/scl/fi/z13wkqgjtuszlt3oimxd4/SacNav.zip?rlkey=f0y2yctxa5ajjt442na8abk4l&amp;dl=0   ç”±   æäº¤ /u/Goodluck_o   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187ktu6/error_implementation_dreamer_v3_on_vector_base/</guid>
      <pubDate>Thu, 30 Nov 2023 15:13:09 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ èµ„æº</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187kpy0/learning_sources/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œæˆ‘æƒ³å¬å¬ä½ ä»¬æ˜¯å¦å¯¹æˆ‘å¦‚ä½•ç»§ç»­æˆ‘çš„å­¦ä¹ ä¹‹æ—…æœ‰ä»»ä½•å»ºè®®ã€‚ åˆ°ç›®å‰ä¸ºæ­¢æˆ‘ç›¸ä¿¡æˆ‘å¯¹ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†æœ‰æ·±å…¥çš„äº†è§£ï¼ŒåŒ…æ‹¬å®ƒçš„æ•°å­¦åŸç†å’Œç¼–ç ã€‚æˆ‘æˆåŠŸåœ°åœ¨ä¸€ä¸ªç®€å•çš„ç¯å¢ƒä¸­å®ç°äº†ä¸€ä¸ªæ™®é€šçš„æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚ç°åœ¨æˆ‘æ­£åœ¨è€ƒè™‘å¦‚ä½•ç»§ç»­å‰è¿›ã€‚æˆ‘å–œæ¬¢ä»æ•°å­¦è§’åº¦ç†è§£äº‹ç‰©ï¼Œç„¶åå°è¯•ç”¨ numpy è‡ªå·±å®ç°å®ƒï¼Œä»¥ç¡®ä¿æˆ‘ç†è§£ä¸€åˆ‡ã€‚ä½†æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘æƒ³å¼€å§‹å­¦ä¹ ä½¿ç”¨ç°æœ‰çš„RL å’Œ NNS çš„å®ç”¨å·¥å…·ï¼Œä¾‹å¦‚ pytorch æˆ–è¯¸å¦‚æ­¤ç±»çš„ä¸œè¥¿ã€‚ ä½ ä»¬å¯¹è§£å†³ç†è®ºå’Œå®è·µé—®é¢˜çš„èµ„æºæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ é¡ºä¾¿è¯´ä¸€å¥ï¼Œæˆ‘åœ¨è¿™é‡Œé—®æ˜¯å› ä¸ºæˆ‘å¯¹æ·±åº¦ RL ç‰¹åˆ«æ„Ÿå…´è¶£è™½ç„¶å®ƒçœ‹èµ·æ¥å¾ˆä¸€èˆ¬ã€‚   ç”±   æäº¤ /u/urtropicretarded   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187kpy0/learning_sources/</guid>
      <pubDate>Thu, 30 Nov 2023 15:08:17 GMT</pubDate>
    </item>
    <item>
      <title>è½»æ¾å®æ–½å¹¶è¡Œè®­ç»ƒã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187imzd/easily_implement_parallel_training/</link>
      <description><![CDATA[    /u/NoteDancing   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187imzd/easily_implement_parallel_training/</guid>
      <pubDate>Thu, 30 Nov 2023 13:33:47 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆæˆ‘åº”è¯¥ä½¿ç”¨ RLLib è€Œä¸æ˜¯ stable-baselines3ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187fahg/why_should_i_use_rllib_over_stablebaselines3/</link>
      <description><![CDATA[æ‰€ä»¥æˆ‘å·²ç»ä½¿ç”¨ sb3 å¤§çº¦ 3 å¹´äº†ï¼Œæˆ‘å‘ç°è®¾ç½®å®éªŒã€å‘ RL æ·»åŠ åŠŸèƒ½ä¿®æ”¹/è‡ªå®šä¹‰ç½‘ç»œæ¶æ„éå¸¸ç®€å•ç®—æ³•ï¼Œä½¿ç”¨Optunaä¼˜åŒ–å‚æ•°ï¼Œå¹¶åœ¨è®­ç»ƒåè¿›è¡Œæ¨ç†ã€‚é™¤äº†äº†è§£å…¶å·¥ä½œåŸç†çš„åŸºæœ¬åŠ¨æ€ä¹‹å¤–ï¼Œæ‰€æœ‰è¿™äº›éƒ½ä¸éœ€è¦ä»˜å‡ºä»€ä¹ˆåŠªåŠ›ã€‚  æ‰€ä»¥åœ¨æˆ‘çš„æ–°å…¬å¸ä¸­ï¼Œä»–ä»¬ä½¿ç”¨ RLLibï¼Œè‡³å°‘å¯ä»¥è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ€ªç‰©ï¼Œå¯ä»¥å®Œæˆæˆ‘åœ¨ sb3 ä¸­è½»æ¾å®Œæˆçš„ä¸Šè¿°ä»»ä½•äº‹æƒ…ã€‚ æ‰€ä»¥äº‰è®ºæ˜¯é€šå¸¸è®¤ä¸ºä½¿ç”¨ RLLib éƒ¨ç½²æ¨¡å‹å¾ˆå®¹æ˜“ã€‚ä½†è¿™çœŸçš„é‚£ä¹ˆå®¹æ˜“å—ï¼Ÿè€ƒè™‘åˆ°æˆ‘ä»¬å¯ä»¥é€šè¿‡ FAST api å’Œ docker ç»„åˆè½»æ¾ç”šè‡³æ›´å¿«åœ°éƒ¨ç½²ä½¿ç”¨ sb3 è®­ç»ƒçš„æ¨¡å‹ï¼Œæ˜¯å¦å€¼å¾—ä»…ä»…ä¸ºäº†å®ƒæä¾›çš„é¢å¤–ç®—æ³•è€Œç»å† RLLib çš„å›°éš¾ï¼Ÿå¯¹äºä¸šå†…ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„äººæ¥è¯´ï¼Œæ‚¨çš„ä½“éªŒå¦‚ä½•ï¼Ÿ   ç”±   æäº¤/u/sharafath28  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187fahg/why_should_i_use_rllib_over_stablebaselines3/</guid>
      <pubDate>Thu, 30 Nov 2023 10:14:33 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰æ²¡æœ‰ä»€ä¹ˆæ¸¸æˆå¯ä»¥è®©æˆ‘ä»¬é€šè¿‡pythonä¸ä¹‹äº¤äº’å‘¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187e4jj/is_there_any_game_that_allow_us_to_interact_with/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å­¦ä¹  RLâ€œå¼ºåŒ–å­¦ä¹ â€ï¼Œå¹¶ä¸”æˆ‘å·²ç»å®Œæˆäº†ä¸€äº›å¤§å¤§å°å°çš„é¡¹ç›®æ¥æŒæ¡å®ƒçš„çªé—¨ã€‚ æˆ‘å†™äº†ä¸€ä¸ªä»£ç ï¼ˆè®­ç»ƒäº†ä¸€ä¸ª RL æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ•è·å±å¹•ï¼ˆmssï¼‰å’Œå‘é€è¾“å…¥ï¼ˆPyDirectInputsï¼‰æ¥ç©æ¸¸æˆï¼Œä½†å®ƒå¤ªæ…¢äº†ï¼›å¤§æ¦‚åªæœ‰ 1 fpsã€‚ï¼ˆæ— è®ºæ˜¯åœ¨è®­ç»ƒä¸­ï¼Œè¿˜æ˜¯åœ¨ä½¿ç”¨ä¸­ï¼‰ æ‰€ä»¥æˆ‘æƒ³çŸ¥é“æ˜¯å¦æœ‰ä»»ä½•æ¸¸æˆå¯ä»¥è®©æˆ‘ä»¬é€šè¿‡ python ä¸å…¶äº¤äº’ï¼Ÿåƒä¸€äº› APIã€æ¥å£ã€è½¯ä»¶ç­‰å°†æˆ‘ä»¬çš„ä»£ç ç›´æ¥è¿æ¥åˆ°æ¸¸æˆã€‚æˆ–è€…ç±»ä¼¼çš„ä¸œè¥¿ï¼Ÿ   ç”±   æäº¤ /u/Mr_Lucifer_666   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187e4jj/is_there_any_game_that_allow_us_to_interact_with/</guid>
      <pubDate>Thu, 30 Nov 2023 08:53:39 GMT</pubDate>
    </item>
    <item>
      <title>å°†å¤šå¤„ç†ä¸ CUDA ç›¸ç»“åˆ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/186xc15/combining_multiprocessing_with_cuda/</link>
      <description><![CDATA[æˆ‘æ˜¯é«˜æ€§èƒ½è®¡ç®—æ–¹é¢çš„æ–°æ‰‹ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘çš„é—®é¢˜çœ‹èµ·æ¥å¤ªå¾®ä¸è¶³é“ï¼Œè¯·åŸè°…æˆ‘ã€‚ â€‹ æˆ‘æ­£åœ¨è€ƒè™‘å°†å¤šé‡å¤„ç†åº”ç”¨äº CUDA RL ç¨‹åºã€‚ç°åœ¨æˆ‘æ­£åœ¨å°è¯•è®­ç»ƒä¸€ä¸ªéœ€è¦å¤§çº¦ 9 å°æ—¶è®­ç»ƒçš„ç¯å¢ƒã€‚æˆ‘æƒ³å°è¯•ä¸€ä¸‹è¶…å‚æ•°å’Œå…¶ä»–ä¸€äº›ä¸œè¥¿ã€‚å› æ­¤ï¼Œæˆ‘æƒ³ä½¿ç”¨ç›¸åŒçš„ GPU å¹¶è¡Œè¿è¡Œæˆ‘çš„æ¨¡å‹ 10 æ¬¡ã€‚  è¿™æ˜¯æˆ‘åœ¨è°·æ­Œæœç´¢åè¦å¤„ç†çš„ -   GPU å¤§å° - æˆ‘çŸ¥é“æˆ‘çš„ GPU åº”è¯¥è¶³å¤Ÿå¤§ï¼Œå¯ä»¥æ¥æ”¶ 10 ä¸ªæ•°æ®è¿è¡Œã€‚  GPU å¹´ä»½ - æ˜¾ç„¶è¾ƒæ—§çš„ GPU ä¸å…è®¸å¤šä¸ªç¨‹åºè®¿é—®å®ƒã€‚   æˆ‘è¿˜ç¼ºå°‘ä»€ä¹ˆå—ï¼Ÿæˆ‘çš„å‡è®¾æ˜¯ï¼Œå¦‚æœè¿è¡Œå•ä¸ªæ¨¡å‹éœ€è¦ 9 å°æ—¶ï¼Œé‚£ä¹ˆé€šè¿‡å¤šé‡å¤„ç†ï¼Œåªè¦æ»¡è¶³ä¸Šè¿°çº¦æŸï¼Œæˆ‘å°±å¯ä»¥åœ¨ 9 å°æ—¶å†…è¿è¡Œ 10 ä¸ªæ¨¡å‹ã€‚   ç”±   æäº¤/u/Academic-Rent7800   reddit.com/r/reinforcementlearning/comments/186xc15/combining_multiprocessing_with_cuda/&quot;&gt;[é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/186xc15/combining_multiprocessing_with_cuda/</guid>
      <pubDate>Wed, 29 Nov 2023 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>Rankitectï¼šåœ¨å…ƒè§„æ¨¡ä¸Šå¯¹æ¶æ„æœç´¢ä¸ä¸–ç•Œçº§å·¥ç¨‹å¸ˆè¿›è¡Œæ’å</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/186ssm9/rankitect_ranking_architecture_search_battling/</link>
      <description><![CDATA[      è®ºæ–‡ï¼šhttps://arxiv.org/abs/2311.08430 æ‘˜è¦ï¼š  ç¥ç»æ¶æ„æœç´¢ (NAS) å·²ç»è¯æ˜äº†å…¶åœ¨è®¡ç®—æœºè§†è§‰æ–¹é¢çš„åŠŸæ•ˆå’Œæ’åç³»ç»Ÿçš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨å­¦æœ¯é—®é¢˜ä¸Šï¼Œè¿™äº›é—®é¢˜æ˜¯åœ¨è‰¯å¥½æ§åˆ¶çš„å›ºå®šåŸºçº¿ä¸‹è¿›è¡Œå°è§„æ¨¡è¯„ä¼°çš„ã€‚åœ¨è¡Œä¸šç³»ç»Ÿä¸­ï¼Œä¾‹å¦‚ Meta ä¸­çš„æ’åç³»ç»Ÿï¼Œå°šä¸æ¸…æ¥šæ–‡çŒ®ä¸­çš„ NAS ç®—æ³•æ˜¯å¦èƒ½å¤Ÿè¶…è¶Šç”Ÿäº§åŸºçº¿ï¼Œå› ä¸ºï¼šï¼ˆ1ï¼‰è§„æ¨¡ - Meta æ’åç³»ç»Ÿä¸ºæ•°åäº¿ç”¨æˆ·æœåŠ¡ï¼Œï¼ˆ2ï¼‰å¼ºå¤§çš„åŸºçº¿ - åŸºçº¿æ˜¯ç”Ÿäº§è‡ªæ·±åº¦å­¦ä¹ å…´èµ·ä»¥æ¥ï¼Œå¤šå¹´æ¥æ•°ç™¾åˆ°æ•°åƒåä¸–ç•Œçº§å·¥ç¨‹å¸ˆä¼˜åŒ–äº†æ¨¡å‹ï¼Œ(3) åŠ¨æ€åŸºçº¿ - å·¥ç¨‹å¸ˆå¯èƒ½åœ¨ NAS æœç´¢è¿‡ç¨‹ä¸­å»ºç«‹äº†æ–°çš„ã€æ›´å¼ºçš„åŸºçº¿ï¼Œ(4) æ•ˆç‡ - æœç´¢ç®¡é“å¿…é¡»äº§ç”Ÿç»“æœå¿«é€Ÿä¸ç”Ÿäº§ç”Ÿå‘½å‘¨æœŸä¿æŒä¸€è‡´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† Rankitectï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº Meta æ’åç³»ç»Ÿçš„ NAS è½¯ä»¶æ¡†æ¶ã€‚ Rankitect å¯»æ±‚é€šè¿‡ä»å¤´å¼€å§‹æ„å»ºä½çº§æ„å»ºå—æ¥æ„å»ºå…¨æ–°çš„æ¶æ„ã€‚ Rankitect å®ç°å¹¶æ”¹è¿›äº†æœ€å…ˆè¿› (SOTA) NAS æ–¹æ³•ï¼Œä»¥åœ¨åŒä¸€æœç´¢ç©ºé—´ä¸‹è¿›è¡Œå…¨é¢ã€å…¬å¹³çš„æ¯”è¾ƒï¼ŒåŒ…æ‹¬åŸºäºé‡‡æ ·çš„ NASã€ä¸€æ¬¡æ€§ NAS å’Œå¯å¾®åˆ† NAS (DNAS)ã€‚æˆ‘ä»¬é€šè¿‡ä¸ Meta ä¸Šçš„å¤šä¸ªç”Ÿäº§æ’åæ¨¡å‹è¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼° Rankitectã€‚æˆ‘ä»¬å‘ç° Rankitect å¯ä»¥ä»å¤´å¼€å§‹å‘ç°æ–°æ¨¡å‹ï¼Œå®ç°å½’ä¸€åŒ–ç†µæŸå¤±å’Œ FLOP ä¹‹é—´çš„ç«äº‰æ€§æƒè¡¡ã€‚å½“åˆ©ç”¨å·¥ç¨‹å¸ˆè®¾è®¡çš„æœç´¢ç©ºé—´æ—¶ï¼ŒRankitect å¯ä»¥ç”Ÿæˆæ¯”å·¥ç¨‹å¸ˆæ›´å¥½çš„æ¨¡å‹ï¼Œå®ç°ç§¯æçš„ç¦»çº¿è¯„ä¼°å’Œ Meta è§„æ¨¡çš„åœ¨çº¿ A/B æµ‹è¯•ã€‚  https://preview.redd.it/mlceky7x7b3c1.png?width=1379&amp;format=png&amp;auto =webp&amp;s=2acc4e0451db9fbf455b03f9e293e68cc61d25bf   ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/186ssm9/rankitect_ranking_architecture_search_battling/</guid>
      <pubDate>Wed, 29 Nov 2023 16:00:25 GMT</pubDate>
    </item>
    </channel>
</rss>