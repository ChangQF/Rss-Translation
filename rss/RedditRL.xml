<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Thu, 02 Jan 2025 03:20:19 GMT</lastBuildDate>
    <item>
      <title>ğŸš€ ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºæ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ï¼šåˆ†è€Œæ²»ä¹‹çš„æ–¹æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hr4dvz/enhancing_mathematical_problem_solving_with_large/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ æˆ‘å¾ˆé«˜å…´ä¸å¤§å®¶åˆ†äº«æˆ‘ä»¬çš„æœ€æ–°é¡¹ç›®ï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å¢å¼ºæ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å›¢é˜Ÿå¼€å‘äº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥æ¥æé«˜ LLM åœ¨æ•°å­¦åº”ç”¨ä¸­çš„å‡†ç¡®æ€§ã€‚ ä¸»è¦äº®ç‚¹ï¼š  ä¸“æ³¨äºè®¡ç®—æŒ‘æˆ˜ï¼Œè€Œä¸æ˜¯åŸºäºè¯æ˜çš„é—®é¢˜ã€‚ åœ¨å„ç§æµ‹è¯•ä¸­å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ å¼€æºä»£ç å¯ä¾›ä»»ä½•äººæ¢ç´¢å’Œè´¡çŒ®ï¼  åœ¨æ­¤å¤„æŸ¥çœ‹æˆ‘ä»¬çš„ GitHub å­˜å‚¨åº“ï¼šDaC-LLM æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾æœ‰å…´è¶£æ¨è¿›è¯¥é¢†åŸŸç ”ç©¶çš„åé¦ˆå’Œæ½œåœ¨åˆä½œè€…ã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬æˆ–å‘è¡¨è¯„è®ºï¼ æ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼    æäº¤äºº    /u/jasonhon2013   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hr4dvz/enhancing_mathematical_problem_solving_with_large/</guid>
      <pubDate>Wed, 01 Jan 2025 14:53:09 GMT</pubDate>
    </item>
    <item>
      <title>grokking çš„ä¹¦å¥½çœ‹å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hr03om/is_the_grokkings_book_any_good/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ‰¾ä¼˜ç§€çš„ RL ä¹¦ç±ã€‚æˆ‘çŸ¥é“ Sutton å’Œ Barto çš„ä¹¦æ˜¯æ ‡å‡†ï¼Œä½†æˆ‘å‘ç°å®ƒçš„ pdf æœ‰ç‚¹å“äººã€‚æˆ‘æ­£åœ¨å¯»æ‰¾å¯ä»¥å¸®åŠ©æˆ‘å¿«é€Ÿå­¦ä¹ æ¦‚å¿µçš„ä¹¦ç±ï¼Œæœ€å¥½æ•°å­¦å†…å®¹è¾ƒå°‘ã€‚å¦ä¸€æœ¬ä¹¦æ˜¯ Grokkings ä¹¦ï¼Œæƒ³çŸ¥é“å®ƒæ˜¯å¦å€¼å¾—è´­ä¹°ï¼ˆåœ¨æˆ‘çš„å›½å®¶å®ƒéå¸¸æ˜‚è´µï¼‰ã€‚å¦‚æœæ‚¨æœ‰å…¶ä»–æ¨èçš„ä¹¦ç±ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚è°¢è°¢    æäº¤äºº    /u/insightfuleffect   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hr03om/is_the_grokkings_book_any_good/</guid>
      <pubDate>Wed, 01 Jan 2025 10:02:45 GMT</pubDate>
    </item>
    <item>
      <title>å…³äºåšå£«å½•å–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hqvckw/regarding_phd_admissions/</link>
      <description><![CDATA[æˆ‘æƒ³æ”»è¯» RLã€MLï¼ˆä¸»è¦æ˜¯ç†è®ºéƒ¨åˆ†ï¼‰åšå£«å­¦ä½ï¼Œæˆ‘æ˜¯ä¸€åæœºæ¢°å·¥ç¨‹æœ¬ç§‘ç”Ÿã€‚ä¸æƒ³æ”»è¯»ç¡•å£«å­¦ä½ã€‚ä½†æˆ‘æƒ³çŸ¥é“ GPA åœ¨è·å¾—åšå£«å­¦ä½å½•å–æ—¶æœ‰å¤šé‡è¦ï¼Œæˆ‘çŸ¥é“å®ƒéå¸¸é‡è¦ï¼Œä½†å¦‚æœ GPA å¾ˆå·®ï¼Œæ¯”å¦‚ 6/10ï¼Œä¼šè€ƒä¸ä¸Šå—ï¼Ÿç ”ç©¶è®ºæ–‡èƒ½å¦å¼¥è¡¥ç”±äº GPA é€ æˆçš„è¿™ç§å·®è·ï¼Ÿå‡è®¾æŸäººåœ¨åŒ»å­¦åº”ç”¨æœºå™¨å­¦ä¹ æ–¹é¢æœ‰ä¸€ç¯‡ç¬¬ä¸€ä½œè€…æ–¹æ³•è®ºæ–‡ã€‚è¿˜æœ‰å¦ä¸€ç¯‡å…³äºç¥ç»ç¬¦å· AI çš„æœºå™¨äººæŠ€æœ¯è®ºæ–‡ï¼Œä»¥åŠä¸€äº›å…³äºæœºå™¨äººç­–ç•¥çš„ç»éªŒï¼Œä»¥åŠä¸é”™çš„ MLã€RL è¯¾ç¨‹é¡¹ç›®èƒŒæ™¯ç­‰    æäº¤äºº    /u/vyknot4wongs   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hqvckw/regarding_phd_admissions/</guid>
      <pubDate>Wed, 01 Jan 2025 04:11:27 GMT</pubDate>
    </item>
    <item>
      <title>RL åšå®¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hqsyw2/rl_blogs/</link>
      <description><![CDATA[ä½ ä»¬å¬è¯´è¿‡ TLDR AI å—ï¼Ÿå®ƒè®©æˆ‘å¯¹ AI çš„å‘å±•æœ‰äº†å¾ˆå¥½çš„äº†è§£ã€‚æˆ‘æ˜¯ä¸€ååˆå­¦è€…ï¼Œæƒ³è·Ÿä¸Š RL çš„æ­¥ä¼ã€‚æˆ‘å¯ä»¥é˜…è¯»å“ªäº›å…³äº RL çš„åšå®¢/æ–‡ç« ï¼Ÿ    æäº¤äºº    /u/Cereal_killer09   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hqsyw2/rl_blogs/</guid>
      <pubDate>Wed, 01 Jan 2025 01:39:15 GMT</pubDate>
    </item>
    <item>
      <title>æ¢ç´¢æ€§çš„å®šä¹‰ï¼ˆBarton å’Œ Sutton é—®é¢˜ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hqn7o1/definition_of_exploratory_barton_and_sutton/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨é˜…è¯» Barto å’Œ Sutton çš„ã€Šå¼ºåŒ–å­¦ä¹ å¯¼è®ºã€‹ç¬¬äºŒç‰ˆï¼Œæœ‰ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚ ç»ƒä¹  2.1 &quot;åœ¨ e-è´ªå©ªåŠ¨ä½œé€‰æ‹©ä¸­ï¼Œå¯¹äºä¸¤ä¸ªåŠ¨ä½œä¸” e = 0.5 çš„æƒ…å†µï¼Œé€‰æ‹©è´ªå©ªåŠ¨ä½œçš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ&quot; æˆ‘çš„è§£å†³æ–¹æ¡ˆæ˜¯ 0.75ï¼Œå› ä¸ºæœ‰ 50% çš„æœºä¼šé€‰æ‹©éšæœºé€‰æ‹©ï¼Œè€Œæ­¤åï¼Œåªæœ‰ 50% çš„æœºä¼šé€‰æ‹©éè´ªå©ªåŠ¨ä½œã€‚ä½†å…¶ä»–å‡ ä¸ªåœ¨çº¿èµ„æºè¡¨æ˜æ˜¯ 0.50ã€‚ ä½œä¸ºå‚è€ƒï¼Œæ­¤æ–‡æœ¬åŒ…å«åœ¨ä¹¦ä¸­ã€‚ â€œä¸€ä¸ªç®€å•çš„æ›¿ä»£æ–¹æ³•æ˜¯å¤§å¤šæ•°æ—¶é—´éƒ½è´ªå©ªåœ°è¡Œäº‹ï¼Œä½†å¶å°”ï¼Œä»¥å°æ¦‚ç‡ä»æ‰€æœ‰å…·æœ‰ç›¸åŒæ¦‚ç‡çš„åŠ¨ä½œä¸­éšæœºé€‰æ‹©ï¼Œç‹¬ç«‹äºåŠ¨ä½œå€¼ä¼°è®¡ã€‚â€ æ‰€ä»¥è¦ä¹ˆæˆ‘è¯¯è§£äº†è¿™ä¸€ç‚¹ï¼Œè¦ä¹ˆæ¢ç´¢æ•…æ„çœç•¥äº†è´ªå©ªåŠ¨ä½œï¼Œè¦ä¹ˆæˆ‘é”™è¿‡äº†ä¸€ä¸ªå¾®å¦™çš„è¯­ä¹‰é—®é¢˜ã€‚æˆ‘ä¹Ÿæœ‰å¯èƒ½æ˜¯å¯¹çš„ï¼šï¼‰ ä»»ä½•å¸®åŠ©éƒ½å°†ä¸èƒœæ„Ÿæ¿€ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ²‰é‡çš„æ–‡æœ¬ï¼Œæˆ‘æƒ³ç¡®ä¿æˆ‘ç†è§£äº†ã€‚    æäº¤äºº    /u/EricTheNerd2   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hqn7o1/definition_of_exploratory_barton_and_sutton/</guid>
      <pubDate>Tue, 31 Dec 2024 20:24:44 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹  Issac Sim çš„èµ„æºï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hqa2x2/resources_to_learn_issac_sim/</link>
      <description><![CDATA[æœ€è¿‘å¼€å§‹ä¸ºæˆ‘çš„æ¯•ä¸šé¡¹ç›®åœ¨ç°å®ä¸–ç•Œä¸­ç ”ç©¶å¤šä»£ç† RL å®ç°ã€‚åœ¨é˜…è¯»äº†æœ‰å…³ Unity MLAgentsã€Mujocoã€Gazebo å’Œ IssacSim çš„ä¿¡æ¯åï¼Œå†³å®šä½¿ç”¨å®ƒã€‚æœ‰æ²¡æœ‰ä»€ä¹ˆå¥½çš„èµ„æºå¯ä»¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨ IssacSimï¼Ÿ    æäº¤äºº    /u/Excellent_Mood_3906   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hqa2x2/resources_to_learn_issac_sim/</guid>
      <pubDate>Tue, 31 Dec 2024 07:59:39 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦å¸®åŠ©</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hq8iwu/need_help/</link>
      <description><![CDATA[      æˆ‘æ­£åœ¨ä¸ºä¸€å®¶å…¬å¸è§£å†³ä¼˜åŒ–é—®é¢˜ã€‚ æˆ‘æœ‰ç”Ÿäº§æ—¶é—´èŒƒå›´å†… 5 ä¸ªå˜é‡çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚ 4 ä¸ªå‚æ•°è¢«è§†ä¸ºè¾“å…¥ï¼ˆå°½ç®¡å…¶ä¸­ä¸€ä¸ªæ˜¯æ¸©åº¦æˆ‘å¯¹æ˜¯å¦å°†å…¶ç”¨ä½œè¾“å…¥å‚æ•°æœ‰ç–‘é—®ï¼‰å’Œ 1 ä¸ªå‚æ•°ä½œä¸ºè¾“å‡ºï¼ˆå¯†åº¦ï¼‰ï¼Œå›°éš¾åœ¨äºè¾“å‡ºä¼šå› ä¸€äº›å˜åŒ–çš„æ—¶é—´è€Œæ»åã€‚ æˆ‘è®­ç»ƒäº†ä¸€ä¸ª LSTM æ¥æ•æ‰ç³»ç»Ÿçš„è¡Œä¸ºï¼Œå®ƒå·¥ä½œå¾—å¾ˆå¥½ï¼Œæ¥å— 5 ä¸ªè¾“å…¥å¹¶è¾“å‡º 1 ä¸ªè¾“å‡ºã€‚ ç°åœ¨æˆ‘åœ¨åˆ¶ä½œæ§åˆ¶å™¨æ—¶é‡åˆ°å›°éš¾ï¼Œå‡è®¾æˆ‘çš„ LSTM æ˜¯ä¸€ä¸ªç¯å¢ƒã€‚ æŸ¥çœ‹è¯„è®ºä¸­çš„å›¾è¡¨    æäº¤äºº    /u/Old_Shine_4985   [link] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hq8iwu/need_help/</guid>
      <pubDate>Tue, 31 Dec 2024 06:11:59 GMT</pubDate>
    </item>
    <item>
      <title>â€œåŸºäºååŒæ•ˆåº”çš„æœºå™¨äººç¾¤ä½“è¡Œä¸ºçš„è‡ªåŠ¨è®¾è®¡â€ï¼ŒSalman ç­‰äºº 2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpvi1r/automatic_design_of_stigmergybased_behaviours_for/</link>
      <description><![CDATA[        æäº¤äºº    /u/gwern   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpvi1r/automatic_design_of_stigmergybased_behaviours_for/</guid>
      <pubDate>Mon, 30 Dec 2024 19:39:53 GMT</pubDate>
    </item>
    <item>
      <title>pettingzoo åŸºçº¿3</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpt4tr/pettingzoo_baselines3/</link>
      <description><![CDATA[æˆ‘æœ‰ 2 ä¸ªå…·æœ‰ä¸åŒè§’è‰²çš„ä»£ç†ï¼Œé—®é¢˜æ˜¯å¦‚ä½•è®©æ¨¡å‹åœ¨é¢„æµ‹ä¸­ç†è§£ï¼ˆåœ¨æµ‹è¯•åŠ è½½çš„æ¨¡å‹æ—¶ï¼‰æ¯ä¸ªä»£ç†å…·æœ‰å“ªä¸ªè§’è‰²ï¼ˆå¼‚æ„å¤šä»£ç†ç³»ç»Ÿï¼‰ï¼Ÿæˆ‘æ‰€åšçš„æ˜¯åœ¨ obs ä¸­æ·»åŠ ä¸€ä¸ªå¸ƒå°”å€¼æ¥åŒºåˆ†è§’è‰²ï¼Œä½†æˆ‘æƒ³çŸ¥é“æˆ‘æ˜¯å¦å¯ä»¥å‘å‡ºå®ƒå¹¶åœ¨æµ‹è¯•æ—¶ç®€å•åœ°ä½¿ç”¨ 2 ä¸ªä¸åŒçš„æ¨¡å‹ã€‚ æˆ‘ç›®å‰æ­£åœ¨æµ‹è¯•ï¼ˆaecï¼‰ model = PPO.load(latest_policy) # print(env.possible_agents) rewards = {agent: 0 for agent in env.possible_agents} # æ³¨æ„ï¼šæˆ‘ä»¬ä½¿ç”¨å¹¶è¡Œ API è¿›è¡Œè®­ç»ƒï¼Œä½†ä½¿ç”¨ AEC API è¿›è¡Œè¯„ä¼°# SB3 æ¨¡å‹æ˜¯ä¸ºå•ä»£ç†è®¾ç½®è®¾è®¡çš„ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹æ¯ä¸ªä»£ç†ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ for i in range(num_games): env.reset(seed=i) for agent in env.agent_iter(): obs, reward, terminology, truncation, info = env.last() # print(obs) if reward &gt; 0ï¼šrewards[agent] += reward å¦‚æœç»ˆæ­¢æˆ–æˆªæ–­ï¼šact = None elseï¼šact = model.predict(obs, deterministic=True)[0] print(f&quot;\nAgent: {agent}, Observation: {obs}, Reward: {reward}, Action: {act}&quot;) env.step(act) env.close()  åœ¨è®­ç»ƒï¼ˆå¹¶è¡Œï¼‰ä¸­æˆ‘æœ‰ model = PPO( MlpPolicy, env, verbose=3, learning_rate=1e-3, batch_size=256, tensorboard_log=log_dir ) while Trueï¼šmodel.learn(total_timesteps=steps, reset_num_timesteps=False) save_path = os.path.join(model_dir, f&quot;{env.unwrapped.metadata.get(&#39;name&#39;)}_{time.strftime(&#39;%Y%m%d-%H%M%S&#39;)}&quot;) model.save(save_path)     æäº¤äºº    /u/More_Peanut1312   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpt4tr/pettingzoo_baselines3/</guid>
      <pubDate>Mon, 30 Dec 2024 17:59:58 GMT</pubDate>
    </item>
    <item>
      <title>å…³äºä¸ºåŠ¨æ€å®šä»· RL ä»»åŠ¡åˆ›å»ºåˆæˆæ•°æ®çš„å»ºè®®ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpsnl4/advice_on_creating_synthetic_data_for_dynamic/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ æˆ‘æ­£åœ¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¼€å±•ç”µå­å•†åŠ¡åŠ¨æ€å®šä»·é¡¹ç›®ã€‚ç”±äºæˆ‘æ²¡æœ‰çœŸå®æ•°æ®ï¼Œå› æ­¤æˆ‘å°è¯•ç”Ÿæˆåˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒã€‚æˆ‘çš„è®¡åˆ’æ˜¯æ¯”è¾ƒ DQN å’Œ PPO æ¥å®Œæˆæ­¤ä»»åŠ¡ï¼Œå¹¶åœ¨è‡ªå®šä¹‰ç¯å¢ƒä¸­è®¾ç½®ä»·æ ¼ä»¥æœ€å¤§åŒ–æ”¶å…¥æˆ–åˆ©æ¶¦ã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘äº†è§£äº†ï¼š  çº¿æ€§æ¨¡å‹ï¼šä»·æ ¼ä¸Šæ¶¨ â†’ éœ€æ±‚ä¸‹é™ï¼ˆä»·æ ¼å¼¹æ€§ï¼‰ã€‚ Logit æ¨¡å‹ï¼šåŸºäºç»æµæ¨¡å‹çš„å»ºæ¨¡ã€‚ å­£èŠ‚æ€§ï¼šç”±äºæ—¶é—´/äº‹ä»¶å¯¼è‡´çš„éœ€æ±‚æ³¢åŠ¨ã€‚  æˆ‘å¸Œæœ›æ•°æ®èƒ½å¤Ÿæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„è¡Œä¸ºï¼Œä¾‹å¦‚ä»·æ ¼æ•æ„Ÿåº¦ã€å­£èŠ‚æ€§å˜åŒ–å’Œä¸€äº›éšæœºæ€§ã€‚æˆ‘è§è¿‡å¾ˆå¤šè®ºæ–‡ä½¿ç”¨ DQN è¿›è¡Œç¦»çº¿å­¦ä¹ ï¼Œä½†æˆ‘å¾ˆæƒ³å°è¯• PPO å¹¶æ¯”è¾ƒç»“æœã€‚  æˆ‘å¾ˆä¹æ„è·å¾—æœ‰å…³å¦‚ä½•æ„å»ºæ­¤ç±»æ¨¡å‹æˆ–åº”è¯¥åŒ…å«å“ªäº›å†…å®¹ä»¥ä½¿æ•°æ®æ›´çœŸå®çš„ä»»ä½•å»ºè®®ã€‚ è¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å°è¯•ä»å¤´å¼€å§‹åˆ›å»ºç¯å¢ƒï¼ˆæˆ‘åªè°ƒæ•´è¿‡å¥èº«æˆ¿ç¯å¢ƒï¼‰ï¼Œæ‰€ä»¥æˆ‘å¾ˆä¹æ„å¬å–æ‚¨çš„å»ºè®®ã€‚    æäº¤äºº    /u/Professional_Ant_140   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpsnl4/advice_on_creating_synthetic_data_for_dynamic/</guid>
      <pubDate>Mon, 30 Dec 2024 17:39:19 GMT</pubDate>
    </item>
    <item>
      <title>å½“å›æŠ¥åœ¨ 1e6 å’Œ 1e10 ä¹‹é—´æ—¶ï¼Œå¦‚ä½•æ ‡å‡†åŒ–å¥–åŠ±</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpsned/how_would_you_normalize_the_rewards_when_the/</link>
      <description><![CDATA[å˜¿ï¼Œæˆ‘æ­£åœ¨åŠªåŠ›ä½¿ç”¨ FQI ä»¥å¤–çš„ä»»ä½•å…¶ä»–æ–¹æ³•è·å¾—è‰¯å¥½çš„æ€§èƒ½ï¼Œä»¥é€‚åº”åŸºäº https://orbi.uliege.be/bitstream/2268/13367/1/CDC_2006.pdf çš„ç¯å¢ƒï¼Œæœ€å¤§æ—¶é—´æ­¥é•¿ä¸º 200ã€‚è§‚å¯Ÿç©ºé—´çš„å½¢çŠ¶ä¸º (6,)ï¼ŒåŠ¨ä½œç©ºé—´æ˜¯ç¦»æ•£çš„ (4) æˆ‘ä¸ç¡®å®šå¦‚ä½•è§„èŒƒåŒ–å¥–åŠ±ï¼Œå› ä¸ºéšæœºä»£ç†è·å¾—çš„å›æŠ¥çº¦ä¸º 1e7ï¼Œè€Œæœ€ä½³ä»£ç†åº”è¯¥è·å¾— 5e10ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å¾—åˆ°çš„æœ€ä½³ç»“æœæ˜¯ä½¿ç”¨å¸¦æœ‰ä»¥ä¸‹åŒ…è£…å™¨çš„ PPOï¼š  log(max(obs, 0) + 1) å°†æœ€åä¸€ä¸ªæ“ä½œé™„åŠ åˆ° obs TimeAwareObservation FrameStack(10) VecNormalize  åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å°è¯•ä½¿ç”¨å„ç§å¥–åŠ±æ ‡å‡†åŒ–çš„ PPO å’Œ DQNï¼Œä½†æ²¡æœ‰æˆåŠŸï¼ˆä½¿ç”¨ sb3ï¼‰ï¼š  ä½¿ç”¨ sb3 ä¸­çš„ VecNormalize æ— æ ‡å‡†åŒ– é™¤ä»¥ 1e10ï¼ˆä»…åœ¨ dqn ä¸Šå°è¯•ï¼‰ é™¤ä»¥å›æŠ¥çš„è¿è¡Œå¹³å‡å€¼ï¼ˆä»…åœ¨ dqn ä¸Šå°è¯•ï¼‰ é™¤ä»¥å›æŠ¥çš„è¿è¡Œæœ€å¤§å€¼ï¼ˆä»…åœ¨ dqn ä¸Šå°è¯•ï¼‰  ç°åœ¨æˆ‘æœ‰ç‚¹ç»æœ›ï¼Œå¹¶å°è¯•ä½¿ç”¨ python-neat è¿è¡Œ NEATï¼ˆæ€§èƒ½ä½ä¸‹ï¼‰ã€‚ æ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°æˆ‘å¯¹ env çš„å®ç°ï¼šhttps://pastebin.com/7ybwavEW ä»»ä½•å…³äºå¦‚ä½•ä½¿ç”¨ç°ä»£æŠ€æœ¯å¤„ç†è¿™ç§ç¯å¢ƒçš„å»ºè®®éƒ½ä¼šå—åˆ°æ¬¢è¿ï¼    æäº¤äºº    /u/Butanium_   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpsned/how_would_you_normalize_the_rewards_when_the/</guid>
      <pubDate>Mon, 30 Dec 2024 17:39:06 GMT</pubDate>
    </item>
    <item>
      <title>è¾“å‡ºæ¦‚ç‡ä¸åˆå§‹åˆå§‹åŒ–æ—¶æ²¡æœ‰å˜åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hps2gg/output_probabilities_are_not_changing_from/</link>
      <description><![CDATA[å› æ­¤ï¼Œæˆ‘æ­£åœ¨å®æ–½ä¸€ç§ RL æ–¹æ³•ç”¨äºè‚¡ç¥¨äº¤æ˜“ï¼Œå› æ­¤æˆ‘æœ‰ä¸¤ä¸ªä»£ç†ï¼Œä¸€ä¸ªå†³å®šè¿›å…¥å“ªä¸ªæ–¹å‘ï¼Œå¦ä¸€ä¸ªç®¡ç†äº¤æ˜“ï¼Œå› æ­¤è¿›å…¥æ¨¡å‹è¾“å‡ºä¹°å…¥å’Œå–å‡ºä¹‹é—´çš„æ¦‚ç‡ï¼Œå®ƒä»¬åˆå§‹åŒ–åœ¨ 49ã€50 å·¦å³ï¼Œä½†é—®é¢˜åœ¨äºå¼€å‘ï¼ˆéªŒè¯ï¼‰ï¼Œå¦‚æœæ¨¡å‹åˆå§‹åŒ–æ—¶æœ‰ä¸€ä¸ªç•¥å¾®ä¼˜åŠ¿çš„åŠ¨ä½œï¼Œå®ƒæ€»æ˜¯é€‰æ‹©é‚£ä¸ªåŠ¨ä½œã€‚æˆ‘æ­£åœ¨æ£€æŸ¥æ¢¯åº¦å¹¶ç›‘æ§ wandb ä¸Šçš„æƒé‡ï¼Œç”šè‡³æ¦‚ç‡æ¯”ï¼Œå°½ç®¡å®ƒä»¬å¾ˆå°ï¼Œä½†ä¸€åˆ‡ä¼¼ä¹éƒ½åœ¨ç§»åŠ¨ï¼Œä½†è¾“å‡ºä¿æŒä¸å˜ã€‚æˆ‘çš„ç»ç†ä»£ç†ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ‰€ä»¥æˆ‘å·²ç»è¿è¡Œäº†äº”é›†ï¼Œä½†å•ä¸ªè®­ç»ƒé›†æœ‰ 300 ç¬”äº¤æ˜“ï¼Œæ¯ä¸ªäº¤æ˜“éƒ½æœ‰å…­ä¸ªè®­ç»ƒé˜¶æ®µï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¶³å¤Ÿçš„è®­ç»ƒå¯ä»¥çœ‹åˆ°æ¦‚ç‡åˆ†å¸ƒçš„ä¸€äº›å˜åŒ–ï¼Œä½†æ²¡æœ‰çœ‹åˆ°ä»»ä½•å˜åŒ–ï¼Œå¥–åŠ±æ˜¯ä¸ç¨³å®šçš„ï¼Œæ‰€ä»¥æˆ‘ä¸èƒ½è‚¯å®šåœ°ä½¿ç”¨è¯¥æŒ‡æ ‡æ¥åˆ¤æ–­ï¼Œè‡³äºéªŒè¯ï¼Œå®ƒä¸€ç›´æ‰§è¡Œå•ä¸€åŠ¨ä½œï¼Œä¸åƒåœ¨è®­ç»ƒä¸­å®ƒæ¢ç´¢å¹¶è·å¾—å¯è§‚çš„å›æŠ¥ï¼Œè¿™å¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨    æäº¤äºº    /u/sk3ptica1   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hps2gg/output_probabilities_are_not_changing_from/</guid>
      <pubDate>Mon, 30 Dec 2024 17:14:28 GMT</pubDate>
    </item>
    <item>
      <title>æ¥å—è®ºæ–‡æ‘˜è¦çš„ä¼šè®®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpr46m/conferences_for_accepting_abstract_papers/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æœ‰ä»»ä½•ä¼šè®®/ç ”è®¨ä¼šæ¥å—æ‘˜è¦è®ºæ–‡å—ï¼Ÿæˆ‘ç°åœ¨å…¨èŒå·¥ä½œã€‚æˆ‘æ²¡æœ‰å¤ªå¤šæ—¶é—´è¿›è¡Œå®éªŒï¼Œä½†æˆ‘æœ‰ä¸€äº›æƒ³è¦å‘è¡¨çš„æƒ³æ³•ï¼Œæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ    æäº¤äºº    /u/Blasphemer666   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpr46m/conferences_for_accepting_abstract_papers/</guid>
      <pubDate>Mon, 30 Dec 2024 16:33:51 GMT</pubDate>
    </item>
    <item>
      <title>è¿™é‡Œæœ‰ä¸šä½™çˆ±å¥½è€…æˆ–è€…ç‹¬ç«‹ç°å®çˆ±å¥½è€…å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpqy24/anybody_hobbyist_or_indie_rl_enthusiast_here/</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€äº›å…¸å‹è®¡ç®—æœºç§‘å­¦çš„èƒŒæ™¯å’Œç»éªŒï¼Œä½†åœ¨äººå·¥æ™ºèƒ½æ–¹é¢æ²¡æœ‰ä¸“ä¸šçŸ¥è¯†ã€‚æ‰€ä»¥æˆ‘ç§°è‡ªå·±ä¸ºä¸šä½™çˆ±å¥½è€…ã€‚æˆ‘å¯¹è§£å†³ç°å®ä¸–ç•Œçš„é—®é¢˜ä¸æ„Ÿå…´è¶£ï¼›æˆ‘æ»¡è¶³äºè¿½éšå¤§å¸ˆåœ¨å›½é™…è±¡æ£‹æˆ–äº”å­æ£‹ç­‰å·²ç»å¾æœçš„é¢†åŸŸçš„æˆå°±ã€‚æ— è®ºå¦‚ä½•ï¼Œæˆ‘æƒ³å°† RL åº”ç”¨äºåŒäººå‚ä¸æŠ½è±¡ç­–ç•¥æ¸¸æˆã€‚è¿™ä¸ª subreddit ä¸Šæœ‰æ²¡æœ‰äººå°è¯•è¿‡ç±»ä¼¼çš„ä¸œè¥¿ï¼Ÿ    æäº¤äºº    /u/Gloomy-Status-9258   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpqy24/anybody_hobbyist_or_indie_rl_enthusiast_here/</guid>
      <pubDate>Mon, 30 Dec 2024 16:26:32 GMT</pubDate>
    </item>
    <item>
      <title>æ¯”è¾ƒ RL ä»£ç†çš„æŒ‡æ ‡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1hpqsur/metrics_for_comparing_rl_agents/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ğŸ‘‹ æˆ‘æ­£åœ¨ä¸€ä¸ªå°å‹å¤§å­¦é¡¹ç›®ä¸Šå·¥ä½œï¼Œè¯¥é¡¹ç›®åœ¨å¤ªç©ºä¾µç•¥è€…çš„èƒŒæ™¯ä¸‹æ¢ç´¢å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘æƒ³å°†ä¼ ç»Ÿçš„ Q-Learning ä»£ç†ä¸ DQN è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶ä¸”æ­£åœ¨è€ƒè™‘ä½¿ç”¨å“ªäº›æŒ‡æ ‡è¿›è¡Œåˆ†æã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å·²å†³å®šç»˜åˆ¶ï¼š  æ¯é›†å¾—åˆ† æ¯é›†å¹³å‡å¥–åŠ± æ¯é›†å¹³å‡æ¸¸æˆæ—¶é—´  æˆ‘è¿˜åœ¨è€ƒè™‘ç»˜åˆ¶å¹³å‡ Q å€¼ã€‚ä½†æ˜¯ï¼Œæˆ‘å¯¹è¿™æ˜¯å¦åˆé€‚æœ‰äº›æ€€ç–‘ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä¸ç¡®å®šå¦‚ä½•è§£é‡Šç”±äºæ¯é›†æ­¥éª¤æ•°çš„å·®å¼‚ï¼ŒQ å€¼åœ¨å„é›†ä¹‹é—´å¯èƒ½ä¼šæœ‰æ˜¾è‘—å·®å¼‚è¿™ä¸€äº‹å®ã€‚ é™„æ³¨ï¼šæˆ‘å®Œå…¨æ¸…æ¥š Q-Learning æ˜¯ä¸€ç§è¡¨æ ¼æ–¹æ³•ï¼Œä¸å¤ªé€‚åˆå…·æœ‰å¤§çŠ¶æ€ç©ºé—´çš„ç¯å¢ƒã€‚è¿™ä¸€é™åˆ¶å°†æ˜¯æˆ‘è¿›è¡Œæ¯”è¾ƒåˆ†æçš„å…³é”®éƒ¨åˆ†ã€‚ æå‰è‡´è°¢ï¼    æäº¤äºº    /u/Lonely-Eye-8313   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1hpqsur/metrics_for_comparing_rl_agents/</guid>
      <pubDate>Mon, 30 Dec 2024 16:20:07 GMT</pubDate>
    </item>
    </channel>
</rss>