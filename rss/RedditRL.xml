<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Tue, 28 Nov 2023 05:50:03 GMT</lastBuildDate>
    <item>
      <title>ç¦»ç­–ç•¥æ¼”å‘˜æ‰¹è¯„å®¶ç›®æ ‡å‡½æ•°</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/185kuxr/offpolicy_actorcritic_objective_function/</link>
      <description><![CDATA[      æˆ‘æ­£åœ¨é˜…è¯» Silver çš„ DPG è®ºæ–‡ã€‚åœ¨è¿™é‡Œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œç›®æ ‡å‡½æ•°å·²ä½¿ç”¨è¡Œä¸ºç­–ç•¥ beta è¿›è¡Œäº†ä¿®æ”¹ã€‚æˆ‘å¾ˆå¥½å¥‡ï¼Œå¦‚æœä½¿ç”¨æ¢¯åº¦æœ€å¤§åŒ–ä¸‹é¢çš„ç›®æ ‡ï¼Œç›®æ ‡ç­–ç•¥çš„ç›®æ ‡å‡½æ•°ï¼ˆé€šå¸¸çš„ç­–ç•¥ç›®æ ‡ï¼‰æ˜¯å¦ä¼šæœ€å¤§åŒ–ï¼Ÿ â€‹ &lt; a href=&quot;https://preview.redd.it/1779aomlyz2c1.png?width=737&amp;format=png&amp;auto=webp&amp;s=bd351a72294f0ad0ef8c8bdaef08e173af00f96e&quot;&gt;https://preview.redd.it/1779aomlyz2c1.png?width =737&amp;format=png&amp;auto=webp&amp;s=bd351a72294f0ad0ef8c8bdaef08e173af00f96e   ç”±   æäº¤ /u/RealJuney   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/185kuxr/offpolicy_actorcritic_objective_function/</guid>
      <pubDate>Tue, 28 Nov 2023 02:12:27 GMT</pubDate>
    </item>
    <item>
      <title>å¯»æ‰¾èŒä¸šå»ºè®®ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/185bwr6/looking_for_career_advice/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œè¿‡å» 3 å¹´æˆ‘ä¸€ç›´å¯¹æœºå™¨å­¦ä¹ æ„Ÿå…´è¶£ï¼Œæˆ‘çš„å¤§éƒ¨åˆ†æ³¨æ„åŠ›éƒ½é›†ä¸­åœ¨ç›‘ç£å­¦ä¹ ä¸Šï¼Œä½†æ˜¯åœ¨è¿‡å» 3 ä¸ªæœˆé‡Œ RLå¼•èµ·äº†æˆ‘çš„æ³¨æ„ï¼Œæˆ‘ç›¸ä¿¡äººå·¥æ™ºèƒ½çš„ä¸‹ä¸€ä¸ªé‡å¤§äº‹ä»¶å°†æ¥è‡ªè¯¥é¢†åŸŸã€‚æˆ‘æœ‰å…´è¶£é€šè¿‡å­¦æœ¯ç•Œï¼Œå› ä¸ºæˆ‘åªæœ‰è®¡ç®—æœºç§‘å­¦å­¦å£«å­¦ä½ï¼Œå¹¶ä¸”ä¸ä¼šæ‰¾åˆ°å·¥ä½œï¼Œå› ä¸ºæˆ‘åœ¨æ´¥å·´å¸ƒéŸ¦ï¼Œè€Œæˆ‘ä»¬åœ¨æŠ€æœ¯æ–¹é¢è¿˜æ²¡æœ‰è¾¾åˆ°è¿™ä¸ªæ°´å¹³ã€‚æˆ‘ç”³è¯·åœ¨ç¾å›½æ”»è¯»åšå£«å­¦ä½ï¼Œä½†æ‹’ç»çš„æ¬¡æ•°è¶Šæ¥è¶Šå¤šï¼Œæ‰€ä»¥æˆ‘å¾ˆå¯èƒ½æœ€ç»ˆä¼šå»ä¸­å›½è·å¾—å¥–å­¦é‡‘ã€‚æˆ‘æƒ³è¦ä¸€äº›å»ºè®®ï¼Œå› ä¸ºæœ€ç»ˆæˆ‘æƒ³åœ¨è¥¿æ–¹çš„å¤§å…¬å¸ä»äº‹ç ”å‘å·¥ä½œã€‚å¦‚æœå¯ä»¥çš„è¯ï¼Œè¯·å‘Šè¯‰æˆ‘åœ¨ä¸­å›½æ”»è¯»ç¡•å£«å­¦ä½æœŸé—´æˆ‘å¯ä»¥åšäº›ä»€ä¹ˆï¼Œä»¥ä¾¿åœ¨ 2026/27 å¹´æ¯•ä¸šåè®©æˆ‘æ›´æ¥è¿‘è¿™ä¸ªç›®æ ‡ã€‚ PSï¼šæˆ‘ä¹Ÿåœ¨ä¸­å›½è·å¾—äº†å­¦å£«å­¦ä½ã€‚   ç”±   æäº¤/u/congo43  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/185bwr6/looking_for_career_advice/</guid>
      <pubDate>Mon, 27 Nov 2023 19:53:09 GMT</pubDate>
    </item>
    <item>
      <title>å¤šå¤´DQN</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/185aneo/multihead_dqn/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘æ­£åœ¨åº”ç”¨ DQN æ¯æ¬¡é€‰æ‹©ä¸€ç»„å…ƒç´ ï¼ˆä¸€æ¬¡ä¸€ä¸ªæˆ–å¤šä¸ªï¼‰ã€‚å¦‚ä½•é¿å…åŠ¨ä½œ [0, 0, 0,â€¦]ï¼Œå³å¦‚ä½•å¼ºåˆ¶ä»£ç†é€‰æ‹©è‡³å°‘ä¸€ä¸ªå…ƒç´ ï¼Ÿ   ç”±   æäº¤/u/GuavaAgreeable208  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/185aneo/multihead_dqn/</guid>
      <pubDate>Mon, 27 Nov 2023 19:01:00 GMT</pubDate>
    </item>
    <item>
      <title>ç¡®å®šæ€§å‚æ•°æ€»æ˜¯è¾“å‡ºç›¸åŒçš„åŠ¨ä½œï¼ˆPPOï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1859bj1/deterministic_parameter_always_output_the_same/</link>
      <description><![CDATA[      æˆ‘ä½¿ç”¨ SB3 ä¸­çš„ PPO å’ŒåŠ¨ä½œæ©ç æ¥è®­ç»ƒå…·æœ‰ä»¥ä¸‹è¶…å‚æ•°çš„ç¯å¢ƒã€‚åœ¨è®­ç»ƒä¸­ï¼Œæ¨¡å‹ä¼¼ä¹å­¦ä¼šäº†é‡‡å–ä¸åŒçš„è¡ŒåŠ¨ã€‚ç„¶è€Œï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¨¡å‹ä¼¼ä¹åšåŒæ ·çš„äº‹æƒ…å¹¶ä¸”è¡¨ç°æ­£å¸¸ï¼Œé™¤äº†å½“æˆ‘ä½¿ç”¨â€œç¡®å®šæ€§ = Trueâ€æ—¶ï¼Œæ¨¡å‹å§‹ç»ˆåªé€‰æ‹©ä¸€ä¸ªæ“ä½œã€‚ æˆ‘çš„ä»£ç ï¼š actionï¼Œ_states = model.predictï¼ˆobsï¼Œaction_masks=env.valid_action_mask()ï¼Œç¡®å®šæ€§=Trueï¼‰  initial_learning_rate = 0.00005  model = MaskablePPO(MaskableActorCriticPolicy, env, tensorboard_log=&quot;./tensorboard&quot; ,n_steps=2048 ,learning_rate=initial_learning_rate) # åˆ›å»ºæ ¹æ®å¥–åŠ±è°ƒæ•´å­¦ä¹ ç‡çš„å›è°ƒ callback = RewardBasedLearningRateSchedule() for i in range (1,202): model.learn(total_timesteps=TIMESTEPS , tb_log_name = &#39;PPO2&#39; , reset_num_timesteps=False,callback=callback) &lt;ä»£ç &gt;model.save(f&quot;{models_dir}/{TIMESTEPS*i}&quot;) â€‹ tensororadçš„è¾“å‡ºï¼š https://preview.redd.it/cpdvwhxnkx2c1.png?width=1652&amp;format=png&amp;auto=webp&amp;s=a6d3bdef2f5040ce935a6534b66de2d934029af6   ç”±   æäº¤ /u/Acceptable_Egg6552   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1859bj1/deterministic_parameter_always_output_the_same/</guid>
      <pubDate>Mon, 27 Nov 2023 18:07:01 GMT</pubDate>
    </item>
    <item>
      <title>Mujoco 3.0 å¯¹é˜µ Isaac Gym</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1857nn8/mujoco_30_vs_isaac_gym/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œ å¯¹äºé‚£äº›å°è¯•è¿‡å¹¶ä¸”ç†Ÿæ‚‰ Mujoco 3.0 å’Œ Isaac Gym çš„äººï¼Œå»ºè®®ä»–ä»¬ä½¿ç”¨å“ªä¸€ä¸ªå­¦ä¹ ä»¥åŠä¸ºä»€ä¹ˆï¼Ÿ   ç”±   æäº¤ /u/anointedninja   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1857nn8/mujoco_30_vs_isaac_gym/</guid>
      <pubDate>Mon, 27 Nov 2023 16:59:33 GMT</pubDate>
    </item>
    <item>
      <title>ç”¨äºå›¾åƒåˆ†ç±»çš„ DQNï¼ˆé˜¿å°”èŒ¨æµ·é»˜ç—…ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1856abz/dqn_for_image_classification_alzheimer/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨ 2D MRI æ‰«æè¿›è¡Œç ”ç©¶ã€‚æœ‰4ä¸ªç­ã€‚æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªå¯ä»¥æ‰§è¡Œåˆ†ç±»ä»»åŠ¡çš„ DQNã€‚æœ‰äººèƒ½å¸®æˆ‘å—ï¼Ÿ   ç”±   æäº¤/u/armaghanbz   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1856abz/dqn_for_image_classification_alzheimer/</guid>
      <pubDate>Mon, 27 Nov 2023 16:01:44 GMT</pubDate>
    </item>
    <item>
      <title>â€œOpen AI Gymâ€å¦‚ä½•è·Ÿè¸ª CartPole ç¯å¢ƒä¸­è¶…è¿‡ 500 çš„æ­¥æ•°ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1853fmr/how_did_open_ai_gym_keep_track_of_steps_exceeding/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨æŸ¥çœ‹ è¿™é‡Œï¼Œæˆ‘æ²¡æœ‰çœ‹åˆ° `step` å‡½æ•°ï¼ˆæˆ–ä»»ä½•å…¶ä»–å‡½æ•°ï¼‰å¦‚ä½•ç¡®ä¿ä»£ç†ä¸ä¼šè·¨è¶Š 500 æ­¥ - &lt; /p&gt; ``` def step(self, action): err_msg = f&quot;{action!r} ({type(action)}) æ— æ•ˆ&quot; &gt; assert self.action_space.contains(action), err_msg assert self.state is not None, &quot;åœ¨ä½¿ç”¨stepæ–¹æ³•ä¹‹å‰è°ƒç”¨resetã€‚&quot; x, x_dot, theta, theta_dot = self.state force = self.force_mag if action == 1 else -self.force_mag costheta = math.cos(theta) sintheta = math.sin(theta) â€‹ # å¯¹äºæ„Ÿå…´è¶£çš„è¯»è€…ï¼š # https://coneural.org/florian/papers/05_cart_pole.pdf temp = ( force + self.polemass_length * theta_dot**2 * sintheta ) / self.total_mass thetaacc = (self.gravity * sintheta - costheta * temp) / ( self.length * (4.0 / 3.0 - self.masspole * costheta**2 / self.total_mass) ) xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass â€‹ å¦‚æœ self.kinematics_integrator == &quot;euler&quot;: x = x + self.tau * x_dot x_dot = x_dot + self.tau * xacc theta = theta + self.tau * theta_dot theta_dot = theta_dot + self.tau * thetaacc&lt; /p&gt; else: # åŠéšå¼æ¬§æ‹‰ x_dot = x_dot + self.tau * xacc x = x + self.tau * x_dot &lt; p&gt;theta_dot = theta_dot + self.tau * thetaacc theta = theta + self.tau * theta_dot â€‹ self.state = ( x, x_dot, theta, theta_dot) â€‹ ç»ˆæ­¢ = bool( x &lt;; -self.x_threshold æˆ– x &gt; self.x_threshold æˆ– theta &lt; -self.theta_threshold_radians æˆ– theta &gt; self.theta_threshold_radians ) â€‹ å¦‚æœæ²¡æœ‰ç»ˆæ­¢ï¼š å¥–åŠ± = 1.0  elif self.steps_beyond_termminate is None: # æ†å­åˆšåˆšæ‰ä¸‹æ¥ï¼ self.steps_beyond_termminate = 0 reward = 1.0 else:  if self.steps_beyond_terminate == 0: logger.warn( â€œæ‚¨æ­£åœ¨è°ƒç”¨ &#39;step()&#39;ï¼Œå³ä½¿è¿™æ ·â€ â€œç¯å¢ƒå·²è¿”å›ç»ˆæ­¢ = Trueã€‚æ‚¨â€ â€œä¸€æ—¦æ”¶åˆ°â€œç»ˆæ­¢ =â€ï¼Œå°±åº”å§‹ç»ˆè°ƒç”¨â€œreset()â€  â€œæ­£ç¡®â€â€”â€”ä»»ä½•è¿›ä¸€æ­¥çš„æ­¥éª¤éƒ½æ˜¯æœªå®šä¹‰çš„è¡Œä¸ºã€‚â€ ) self.steps_beyond_termerated += 1 reward = 0.0 â€‹ å¦‚æœ self.render_mode == â€œäººç±»â€: self.render() return np.array(self .state, dtype=np.float32), å¥–åŠ±, ç»ˆæ­¢, False, {} ```  ä½† Farama Gymnasium çš„æƒ…å†µå¹¶éå¦‚æ­¤ã€‚ æ­¥éª¤å‡½æ•°å…·æœ‰ä»¥ä¸‹ä»£ç æ¥ç¡®ä¿å®ƒ -  ``` æˆªæ–­ = self.steps &gt;= self.max_episode_steps â€‹ ```  ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘åº”è¯¥è¿è¡Œâ€œgymâ€ç¯å¢ƒã€‚æˆ‘ç›®å‰é¢ä¸´çš„é—®é¢˜æ˜¯ï¼Œå³ä½¿ä»£ç†è·¨è¶Š 500 æ­¥ï¼Œä¹Ÿä¸ä¼šåœæ­¢ã€‚    ç”±   æäº¤/u/Academic-Rent7800   reddit.com/r/reinforcementlearning/comments/1853fmr/how_did_open_ai_gym_keep_track_of_steps_exceeding/&quot;&gt;[é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1853fmr/how_did_open_ai_gym_keep_track_of_steps_exceeding/</guid>
      <pubDate>Mon, 27 Nov 2023 13:52:19 GMT</pubDate>
    </item>
    <item>
      <title>ç¨³å®šåŸºçº¿æ¨å‡º/ep_rew_mean</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1850jcz/stable_baselines_rolloutep_rew_mean/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åšä¸€äº›éœ€è¦æˆ‘èƒ½å¤Ÿè·å–æ¯ 4 é›†æ‰“å°åˆ°å‘½ä»¤æç¤ºç¬¦ä¸­çš„ ep_rew_mean å€¼çš„äº‹æƒ…ã€‚ä½†æˆ‘åªæ˜¯æ— æ³•å¼„æ¸…æ¥šè¿™äº›å€¼å­˜å‚¨åœ¨å“ªé‡Œï¼Œä»¥ä¾¿æˆ‘å¯ä»¥åœ¨å›è°ƒå‡½æ•°ä¸­è®¿é—®å®ƒä»¬ã€‚æˆ‘æ­£åœ¨ä»â€œep_info_bufferâ€è®¿é—®æœ€åä¸€é›†å¥–åŠ±ï¼Œä½†è¿™ä¸æˆ‘éœ€è¦çš„ ep_rew_mean æœ‰å¾ˆå¤§ä¸åŒã€‚æˆ‘ä¸ºæ­¤æŸ¥çœ‹äº†è®°å½•å™¨ã€OffPolicyAlgorithm å’Œ SAC æ–‡ä»¶ï¼Œä½†ä»ç„¶æ‰¾ä¸åˆ°å®ƒã€‚è¿™äº›ä¿¡æ¯åœ¨æ‰“å°ä¹‹å‰å­˜å‚¨åœ¨å“ªé‡Œï¼Ÿæˆ‘å¦‚ä½•è®¿é—®å®ƒï¼Ÿ   ç”±   æäº¤ /u/aliaslight   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1850jcz/stable_baselines_rolloutep_rew_mean/</guid>
      <pubDate>Mon, 27 Nov 2023 11:08:48 GMT</pubDate>
    </item>
    <item>
      <title>å¸®åŠ©è°ƒè¯• TD3ï¼ˆ4 æ¡æ‚¬æŒ‚ç”µç¼†ï¼‰ç”µç¼†æœºå™¨äººç›®æ ‡åˆ°è¾¾ä»»åŠ¡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/184ypl4/help_in_debugging_td3_for_4_suspended_cables/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ä¸ºç”µç¼†æœºå™¨äººå¼€å‘ RL æ§åˆ¶å™¨ï¼Œä»¥å­¦ä¹ ç›®æ ‡åˆ°è¾¾ä»»åŠ¡ã€‚ æˆ‘ä½¿ç”¨ obi ç»³ç´¢åŒ…å¯¹å¸¦æœ‰æŸ”æ€§ç”µç¼†çš„ç”µç¼†æœºå™¨äººè¿›è¡Œäº†ç»Ÿä¸€æ¨¡æ‹Ÿã€‚ æˆ‘ä¸€ç›´åœ¨åŠªåŠ›ä¸ä»£ç†å­¦ä¹ æ­£ç¡®çš„ç­–ç•¥ã€‚ æˆ‘ä¼šéå¸¸æœ‰å…´è¶£å»ºç«‹åˆä½œæ¥è§£å†³é—®é¢˜ã€‚ ä»»ä½•æˆåŠŸçš„ç»“æœéƒ½å°†è”åˆå‘å¸ƒã€‚ ä»»ä½•æœ‰å…´è¶£å¹¶ä¸”æ„¿æ„çš„äººï¼Œè¯·é€šè¿‡ &lt; a href=&quot;mailto:rohit.dhakate@aau.at&quot;&gt;rohit.dhakate@aau.at ä»¥è·å–æœ‰å…³è¯¥é¡¹ç›®å’Œå½“å‰çŠ¶æ€çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚ äº²åˆ‡çš„é—®å€™ã€‚   ç”±   æäº¤/u/fx619  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/184ypl4/help_in_debugging_td3_for_4_suspended_cables/</guid>
      <pubDate>Mon, 27 Nov 2023 09:02:29 GMT</pubDate>
    </item>
    <item>
      <title>æ²¡æœ‰æ‰¹è¯„å®¶æ¨¡å‹çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/184wmg5/policy_gradient_algorithms_without_critic_model/</link>
      <description><![CDATA[æ˜¯å¦å¯ä»¥åœ¨æ²¡æœ‰ actor-critic çš„æƒ…å†µä¸‹å®ç°åƒ NPGã€PPO è¿™æ ·çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œæˆ–è€…å®ƒä¼šç ´åè¿™äº›ç®—æ³•ä¸­å½“å‰æ›´å¿«çš„æ”¶æ•›æ€§å—ï¼Ÿ  å¦‚æœæˆ‘æƒ³è¿™æ ·åšï¼Œæˆ‘å¯ä»¥ä»å“ªé‡Œå¼€å§‹å‘¢ï¼Ÿ    ç”±   æäº¤/u/eles0range  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/184wmg5/policy_gradient_algorithms_without_critic_model/</guid>
      <pubDate>Mon, 27 Nov 2023 06:37:39 GMT</pubDate>
    </item>
    <item>
      <title>Q*ï¼šå¤šæ­¥æ¨ç†è¿‡ç¨‹ç›‘ç£çš„å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/184qj06/q_reinforcement_learning_for_process_supervision/</link>
      <description><![CDATA[é‚£ä¹ˆæˆ‘ä»¬æ™®é€šäººæ˜¯å¦å¯ä»¥å°è¯•æ¨¡ä»¿ Q*(Q-star) æ‰€é‡‡å–çš„æ–¹æ³•ï¼Œæ®ç§°è¯¥æ–¹æ³•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥è¿›è¡Œå¤šè¿›ç¨‹çš„è¿‡ç¨‹ç›‘ç£-æ­¥éª¤æ¨ç†ï¼ˆåˆåâ€œæ€æƒ³é“¾â€ï¼‰ï¼Ÿ https ://openai.com/research/improving-mathematical-reasoning-with-process-supervision https ://arxiv.org/abs/2305.20050 æ˜¯å¦æœ‰å¯èƒ½é‡‡ç”¨ä¸Šè¿°å¼ºåŒ–å­¦ä¹ å¹¶å°†å…¶ä½œä¸ºè¿ç§»å­¦ä¹ åº”ç”¨åˆ°åƒ Orca2 è¿™æ ·çš„å°è¯­è¨€æ¨¡å‹ä¸Šï¼Ÿå¦‚æœæ˜¯è¿™æ ·ï¼Œé‚£ä¹ˆæœ€å¥½çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘å¯ä»¥æŸ¥æ‰¾å“ªäº›ä»£ç ç¤ºä¾‹å¯¹æˆ‘æœ‰å¸®åŠ©ï¼Ÿ   ç”±   æäº¤/u/san__man   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/184qj06/q_reinforcement_learning_for_process_supervision/</guid>
      <pubDate>Mon, 27 Nov 2023 01:08:37 GMT</pubDate>
    </item>
    <item>
      <title>å½“å‰ç¦»ç­–ç•¥æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ SOTA</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/184ibu2/current_sota_for_offpolicy_deep_rl/</link>
      <description><![CDATA[æˆ‘å¾ˆæƒ³åœ¨è¿™é‡ŒæŸ¥è¯¢ç¤¾åŒºã€‚æˆ‘æœ‰å…´è¶£ç¡®å®šä¸‹ä¸€ä¸ªè¦æ·»åŠ åˆ° ML-Agents çš„ç¦»ç­–ç•¥ç®—æ³•ã€‚ç›®å‰çš„å€™é€‰è€…åŒ…æ‹¬ TQCã€REDQ å’Œ DroQã€‚å‚è€ƒï¼šhttps://github.com/Unity-Technologies/ml-agents/issues/6012   ç”±   æäº¤ /u/drmajr   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/184ibu2/current_sota_for_offpolicy_deep_rl/</guid>
      <pubDate>Sun, 26 Nov 2023 19:19:09 GMT</pubDate>
    </item>
    <item>
      <title>å¤§è„‘ä¸­çš„å¤šæ—¶é—´å°ºåº¦å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18440cc/multitimescale_reinforcement_learning_in_the_brain/</link>
      <description><![CDATA[è®ºæ–‡ï¼šhttps://www.biorxiv.org/content/10.1101/2023.11.12.566754v1 ä»£ç ï¼šhttps://github.com/pablotano8/multi_timescale_RL æ‘˜è¦ï¼š è“¬å‹ƒå‘å±•å¤æ‚çš„ç¯å¢ƒã€åŠ¨ç‰©å’Œäººå·¥æ™ºèƒ½ä½“å¿…é¡»å­¦ä¼šè‡ªé€‚åº”åœ°è¡ŒåŠ¨ï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜é€‚åº”åº¦å’Œå›æŠ¥ã€‚è¿™ç§é€‚åº”æ€§è¡Œä¸ºå¯ä»¥é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ç±»åœ¨è®­ç»ƒäººå·¥æ™ºèƒ½ä½“å’Œè¡¨å¾ä¸­è„‘å¤šå·´èƒºç¥ç»å…ƒæ”¾ç”µæ–¹é¢å–å¾—æˆåŠŸçš„ç®—æ³•ã€‚åœ¨ç»å…¸çš„å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œä»£ç†æ ¹æ®ç”±æŠ˜æ‰£å› å­æ§åˆ¶çš„å•ä¸ªæ—¶é—´å°ºåº¦ä»¥æŒ‡æ•°æ–¹å¼æŠ˜æ‰£æœªæ¥å¥–åŠ±ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ¢ç´¢ç”Ÿç‰©å¼ºåŒ–å­¦ä¹ ä¸­å¤šä¸ªæ—¶é—´å°ºåº¦çš„å­˜åœ¨ã€‚æˆ‘ä»¬é¦–å…ˆè¯æ˜å¼ºåŒ–ä»£ç†åœ¨å¤šä¸ªæ—¶é—´å°ºåº¦ä¸Šå­¦ä¹ å…·æœ‰æ˜æ˜¾çš„è®¡ç®—ä¼˜åŠ¿ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æŠ¥å‘Šæ‰§è¡Œä¸¤ç§è¡Œä¸ºä»»åŠ¡çš„å°é¼ ä¸­çš„å¤šå·´èƒºç¥ç»å…ƒç”¨å¤šç§æŠ˜æ‰£æ—¶é—´å¸¸æ•°ç¼–ç å¥–åŠ±é¢„æµ‹è¯¯å·®ã€‚æˆ‘ä»¬çš„æ¨¡å‹è§£é‡Šäº†æç¤ºè¯±å‘çš„ç¬æ€ååº”å’Œç§°ä¸ºå¤šå·´èƒºæ–œå¡çš„è¾ƒæ…¢æ—¶é—´å°ºåº¦æ³¢åŠ¨çš„æ—¶é—´è´´ç°çš„å¼‚è´¨æ€§ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œæµ‹é‡åˆ°çš„å•ä¸ªç¥ç»å…ƒçš„æŠ˜æ‰£å› å­åœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­æ˜¯ç›¸å…³çš„ï¼Œè¿™è¡¨æ˜å®ƒæ˜¯ç»†èƒç‰¹å¼‚æ€§çš„å±æ€§ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„ç»“æœæä¾›äº†ä¸€ä¸ªæ–°çš„èŒƒä¾‹æ¥ç†è§£å¤šå·´èƒºç¥ç»å…ƒçš„åŠŸèƒ½å¼‚è´¨æ€§ï¼Œä¸ºäººç±»å’ŒåŠ¨ç‰©åœ¨è®¸å¤šæƒ…å†µä¸‹ä½¿ç”¨éæŒ‡æ•°æŠ˜æ‰£çš„ç»éªŒè§‚å¯Ÿæä¾›äº†æœºåˆ¶åŸºç¡€ï¼Œå¹¶ä¸ºè®¾è®¡æ›´æœ‰æ•ˆçš„å¼ºåŒ–å¼€è¾Ÿäº†æ–°é€”å¾„å­¦ä¹ ç®—æ³•ã€‚   ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18440cc/multitimescale_reinforcement_learning_in_the_brain/</guid>
      <pubDate>Sun, 26 Nov 2023 05:57:59 GMT</pubDate>
    </item>
    <item>
      <title>æ–°æ‰‹é—®é¢˜</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/183gccb/newbie_questions/</link>
      <description><![CDATA[è¯·å°½å¯èƒ½å¤šåœ°å›ç­” æˆ‘æ˜¯ RL æ–¹é¢çš„æ–°æ‰‹å’Œä¸šä½™çˆ±å¥½è€…ã€‚æˆ‘çš„é¦–é€‰è®¾ç½®æ˜¯ OpenAI Gym with Stable Baselines3ã€‚  æˆ‘æœ‰ä¸€äº›é—®é¢˜æƒ³é—®ï¼Œä½† Google æˆ– ChatGPT å°šæœªå›ç­”ï¼Œå †æ ˆæº¢å‡ºå¯èƒ½ä¼šå°†å…¶å¦å†³ä¸ºæ·±æ¸Šã€‚ğŸ¥¸  æ˜¯ç”±äºæˆ‘ä»¬æ²¡æœ‰åŸºæœ¬äº‹å®ï¼Œå› æ­¤å¼ºåŒ–å­¦ä¹ ä¸­æœªä½¿ç”¨çºªå…ƒè¿™ä¸ªæœ¯è¯­ï¼Ÿå¦‚æœæ˜¯ï¼Œæ‚¨èƒ½æŒ‡å‡ºå¦‚ä½•å®ç°å—ï¼Ÿ ç†µæ­£åˆ™åŒ–å¯ä»¥ä½¿ç”¨ SB3 PPO å®Œæˆè¿˜æ˜¯éœ€è¦ä½¿ç”¨ PyTorch æˆ–ä»»ä½•å…¶ä»–æ–¹å¼å®ç°ï¼Ÿå®ƒè¿˜å…·æœ‰æˆ‘å¯ä»¥è®¿é—®çš„ä½“éªŒé‡æ’­ç¼“å†²åŒºå—ï¼Ÿ æˆ‘çš„ TensorBoard ä»ªè¡¨æ¿æ²¡æœ‰æŒ‰ç…§ verbose=1 çš„æ–‡æ¡£ä¸­æ‰€è¿°è¾“å‡ºåº”æœ‰çš„æ‰€æœ‰å›¾è¡¨ï¼Œéšæœºè¾“å‡ºä¸€æ¬¡ï¼Œä½†æ˜¯åªæœ‰ä¸€æ¬¡ã€‚æœ‰ä»€ä¹ˆæƒ³æ³•å—ï¼Ÿ åœ¨ OpenAI Gym ä¸­æµ‹è¯•æ—¶ï¼ŒçŠ¶æ€ = è§‚å¯Ÿæ˜¯æ­¥éª¤çš„è¾“å‡ºå—ï¼Ÿ å½“æˆ‘ä»¬ä½¿ç”¨SB3 ä¸­çš„ Predict() æ–¹æ³•ï¼Œæˆ‘ä»¬æ˜¯å¦å‘ NN å‘é€æˆ‘çš„è§‚å¯Ÿç»“æœï¼Œæˆ–è€…ä¸ NN çš„äº¤äº’æ˜¯å¦‚ä½•å‘ç”Ÿçš„ï¼Ÿ   éå¸¸æ„Ÿè°¢æ‚¨çš„å›ç­”ã€‚   ç”±   æäº¤/u/Sadboi1010   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/183gccb/newbie_questions/</guid>
      <pubDate>Sat, 25 Nov 2023 09:46:02 GMT</pubDate>
    </item>
    <item>
      <title>æ¨å¹¿ PPO</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/183bgwl/generalise_ppo/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘æ­£åœ¨ç ”ç©¶å¤šä»£ç†ç¯å¢ƒï¼Œè¯¥ç¯å¢ƒé€‚ç”¨äºè®¸å¤šä»»åŠ¡ã€‚å¥–åŠ±ç»™å‡ºäº†æ¯ä¸ªçº§åˆ«ä¸­ç‰¹å®šä»»åŠ¡çš„è¿›å±•ã€‚è¯¥ä»»åŠ¡ç‰¹å®šäºä¸ªä½“ä»£ç†ï¼Œè€Œä¸æ˜¯åä½œçš„ã€‚æˆ‘å¯¹æ‰€æœ‰ä»£ç†ä½¿ç”¨é›†ä¸­å¼ PPO ç®—æ³•ï¼Œæˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹ä½¿ä»£ç†æ›´åŠ é€šç”¨å’Œå…·æœ‰æ¢ç´¢æ€§ã€‚    ç”±   æäº¤/u/MachinePolaSD   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/183bgwl/generalise_ppo/</guid>
      <pubDate>Sat, 25 Nov 2023 04:27:50 GMT</pubDate>
    </item>
    </channel>
</rss>