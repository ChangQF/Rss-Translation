<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯æ—¨åœ¨æ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå’Œå­¦ä¹ å¦‚ä½•æœ€ä½³è·å¾—å¥–åŠ±çš„AI/ç»Ÿè®¡æ•°æ®çš„å­åœºã€‚ä¾‹å¦‚Alphagoï¼Œä¸´åºŠè¯•éªŒå’ŒA/Bæµ‹è¯•ä»¥åŠAtariæ¸¸æˆã€‚</description>
    <lastBuildDate>Mon, 10 Feb 2025 01:17:19 GMT</lastBuildDate>
    <item>
      <title>ç¨³å®šçš„åŸºçº¿3-åœ¨Model.Learnï¼ˆï¼‰ä¹‹å¤–å­¦ä¹ ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ilpeu9/stable_baselines3_learn_outside_of_modellearn/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘æœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œæˆ‘æƒ³å°†å¼ºåŒ–å­¦ä¹ é›†æˆåˆ°è§£å†³å¯¼èˆªçš„è¾ƒå¤§ç®—æ³•ä¸­ã€‚ä¾‹å¦‚ï¼ŒRLæœºå™¨äººå°†å­¦ä¹ å¦‚ä½•åœ¨éª‘è‡ªè¡Œè½¦ï¼ˆæˆ–å…¶ä»–æ§åˆ¶åŠ©æ”»ï¼‰ä¸Šå–å¾—å¹³è¡¡å¹¶å‘å‰è¿ˆè¿›ï¼Œè€Œæœ‰ä¸€ç§ç®—æ³•æŒ‡å®šäº†å“ªäº›è¡—é“è¦è¾¾åˆ°ç›®æ ‡ã€‚å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œå³ä½¿åœ¨a* sessionsæœŸé—´ï¼Œæˆ‘ä¹Ÿæƒ³å¯¹ä»£ç†äººè¿›è¡ŒæŒ‘æˆ˜ - è¿™äº›ä¼šè®®çš„å¥–åŠ±æ›´æ–°æ”¿ç­–ã€‚æ˜¯å¦æœ‰ä¸€ç§ç®€å•çš„æ–¹æ³•å¦‚ä½•æŒ‡å®šå­¦ä¹ å‚æ•°å¹¶æ›´æ–° model.learnï¼ˆï¼‰ ä¹‹å¤–çš„ç­–ç•¥æƒé‡ï¼Ÿå¦‚æœä¸æ˜¯ï¼Œæˆ‘éœ€è¦ç¼–å†™å’Œæµ‹è¯•è‡ªå®šä¹‰PPOï¼Œè¿™ä¼šå‡æ…¢è¿‡ç¨‹....  æ„Ÿè°¢æ‰€æœ‰ç­”å¤ï¼Œ  michal    &lt; ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/majklost21     [link]   ï¼†ï¼ƒ32;   [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ilpeu9/stable_baselines3_learn_outside_of_modellearn/</guid>
      <pubDate>Sun, 09 Feb 2025 21:14:45 GMT</pubDate>
    </item>
    <item>
      <title>å®‰å…¨å¥–åŠ±å’Œå®‰å…¨/çº¦æŸRLä¹‹é—´æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ildbz0/whats_so_different_between_rl_with_safety_rewards/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å®‰å…¨/çº¦æŸRLçš„ç›®æ ‡æ˜¯åœ¨ä¿è¯å®‰å…¨æ¢ç´¢æˆ–é€šè¿‡å°†çº¦æŸç‡é™åˆ¶åœ¨æŸäº›é˜ˆå€¼ä»¥ä¸‹çš„çº¦æŸç‡æ¥ç¡®ä¿é™åˆ¶ã€‚  ï¼Œä½†æˆ‘æƒ³çŸ¥é“è¿™ä¸æ™®é€šRLæœ‰ä½•ä¸åŒï¼Œå¦‚æœè¿åå®‰å…¨æ€§é™åˆ¶ï¼Œåˆ™å¸¦æ¥äº†ä¸€äº›å¥–åŠ±åŠŸèƒ½ï¼Œä»è€Œç»™äºˆè´Ÿå¥–åŠ±ã€‚æ˜¯ä»€ä¹ˆä½¿å®‰å…¨/çº¦æŸçš„RLå¦‚æ­¤ç‰¹åˆ«å’Œ/æˆ–ä¸åŒï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/open-safety-1585     [link]   ï¼†ï¼ƒ32;  &lt;a href =â€œ https://www.reddit.com/r/reinforecctionlearning/comments/1ildbz0/1ildbz0/whats_so_so_different_between_rl_with_safety_reward/]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ildbz0/whats_so_different_between_rl_with_safety_rewards/</guid>
      <pubDate>Sun, 09 Feb 2025 12:06:55 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘å¯ä»¥å°†æ‰¹é‡åˆ†æˆA2Cçš„è¿·ä½ æ‰¹æ¬¡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1il9odx/can_i_split_my_batch_into_mini_batches_for_a2c/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå®¶æ˜¯ä¸€ç§policy RLç®—æ³•ï¼Œè¿™æ„å‘³ç€ç½‘ç»œä»…é€šè¿‡å½“å‰ç­–ç•¥ç”Ÿæˆçš„ç»éªŒæ¥æ›´æ–°ã€‚ è¯è™½å¦‚æ­¤ï¼Œæˆ‘çŸ¥é“æˆ‘ä¸èƒ½ä½¿ç”¨é‡æ’­ç¼“å†²åŒºæ¥ä½¿ç®—æ³•æ›´æœ‰æ•ˆï¼Œæˆ‘åªèƒ½ä½¿ç”¨æœ€æ–°çš„ä½“éªŒæ¥æ›´æ–°ç½‘ç»œã€‚ ç°åœ¨ï¼Œå‡è®¾æˆ‘ç”Ÿæˆäº†ä¸€ä¸ªæœ€æ–°æ”¿ç­–çš„1000ä¸ªæ ·æœ¬ã€‚æˆ‘åº”è¯¥åœ¨æ•´ä¸ªæ‰¹æ¬¡ä¸Šè¿è¡Œæ¢¯åº¦ä¸‹é™ï¼Œè®¡ç®—æ¢¯åº¦å¹¶è¿›è¡Œä¸€æ¬¡æ›´æ–°ï¼Œè¿˜æ˜¯å¯ä»¥å°†æ‰¹æ¬¡åˆ†æˆ10ä¸ªè¾ƒå°çš„è¿·ä½ æ‰¹æ¬¡å¹¶æ›´æ–°ç½‘ç»œ10æ¬¡ï¼Ÿè¿™ç§æœ€åçš„æ–¹æ³•ä¼šè¿åâ€œ policyâ€å‡è®¾ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/nigage-owl-4088      link]     &lt;a href =â€œ https://www.reddit.com/r/reinforevectionlearning/comments/comments/1il9odx/can_i_split_my_my_my_mini_into_mini_mini_mini_mini_batches_for_a2c/â€]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1il9odx/can_i_split_my_batch_into_mini_batches_for_a2c/</guid>
      <pubDate>Sun, 09 Feb 2025 07:44:51 GMT</pubDate>
    </item>
    <item>
      <title>è®­ç»ƒæ—¶çš„æ¨¡æ‹Ÿæ—¶é—´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1il9jeo/simulation_time_when_training/</link>
      <description><![CDATA[åœ¨ä¼˜åŒ–ç‰©ç†æ¨¡æ‹Ÿï¼Œä½†æ˜¯ç‰©ç†æ¨¡æ‹Ÿæœ¬èº«éœ€è¦1åˆ†é’Ÿæ‰èƒ½è¿è¡Œã€‚å¦‚æœæˆ‘éœ€è¦100ä¸‡ä¸ªæ­¥éª¤æ‰èƒ½èåˆï¼Œåˆ™æ¯ä¸ªæ­¥éª¤å¯èƒ½éœ€è¦2åˆ†é’Ÿã€‚è¿™æ˜¯å¹¶è¡ŒåŒ–ï¼Œæ²¡æœ‰ã€‚è¿™æ ¹æœ¬ä¸å¯è¡Œï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/milkyjuggernuts     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1il9jeo/simulation_time_when_training/</guid>
      <pubDate>Sun, 09 Feb 2025 07:34:41 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å®ç°è¿™ä¸€ç›®æ ‡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1il8vg2/how_to_make_this_happen/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘åœ¨MLä¸­åšäº†ä¸€ä¸ªé¡¹ç›®ï¼Œè¿™ä¸ä¸»åŠ¨å­¦ä¹ æœ‰å…³ã€‚æˆ‘ç°åœ¨æƒ³åšæ›´å¤šçš„äº‹æƒ…ï¼Œæˆ‘æ­£åœ¨å¯»æ‰¾é¡¹ç›®ï¼Œä½†æ˜¯æˆ‘ä¹Ÿæƒ³åšä¸€äº›äº‹æƒ…ï¼Œæˆ‘è®¡åˆ’åœ¨ç½‘ç»œä¸Šåˆ¶ä½œä¸€ä¸ªWordle Cloneï¼Œç„¶ååˆ¶ä½œRLæ¨¡å‹æ¥æ’­æ”¾å®ƒï¼Œä½†æ˜¯å¦‚ä½•ç»§ç»­å‰è¿›å»åšè¿™ï¼Ÿæ¬¢è¿ä»»ä½•èµ„æºå’Œå»ºè®®  tl; new to Mlï¼Œæƒ³åˆ¶ä½œä¸€ä¸ªæ–‡å­—å…‹éš†å¹¶è®­ç»ƒRLæ¨¡å‹æ¥æ’­æ”¾å®ƒï¼Œè¦æ±‚èµ„æºå’Œå»ºè®®ã€‚   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/darklord-0708     link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1il8vg2/how_to_make_this_happen/</guid>
      <pubDate>Sun, 09 Feb 2025 06:48:14 GMT</pubDate>
    </item>
    <item>
      <title>PPOé—®é¢˜ï¼šæ”¿ç­–æŸå¤±å’Œä»·å€¼åŠŸèƒ½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1il6erp/ppo_question_policy_loss_and_value_function/</link>
      <description><![CDATA[           &lt;ï¼ - &gt;  å—¨allï¼Œ æˆ‘è¯•å›¾é¦–æ¬¡ä½¿ç”¨ç®€å•çš„è’™ç‰¹å¡æ´›ä¼°è®¡å™¨æ¥å®ç°PPOã€‚æˆ‘æ¥è‡ªå®æ–½SACå’ŒDQNã€‚æˆ‘åœ¨ç†è§£å¦‚ä½•æœ€å¤§åŒ–ç­–ç•¥æ›´æ–°çš„åŒæ—¶æœ€å¤§ç¨‹åº¦åœ°å‡å°‘ä»·å€¼åŠŸèƒ½æŸå¤±æ—¶é‡åˆ°äº†é—®é¢˜ã€‚æˆ‘çš„ä¼˜åŠ¿æœ¬è´¨ä¸Šæ˜¯g_t -vï¼ˆsï¼‰ï¼Œç­–ç•¥ç¥ç»ç½‘æ—¨åœ¨æœ€å¤§åŒ–æ–°æ”¿ç­–ä¸æ—§æ”¿ç­–çš„æ¯”ç‡ä¹˜ä»¥è¿™ä¸€ä¼˜åŠ¿ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘çš„ä»·å€¼åŠŸèƒ½ç¥ç»ç½‘æ—¨åœ¨æœ€å¤§ç¨‹åº¦åœ°å‡å°‘ç›¸åŒçš„ä¼˜åŠ¿ã€‚æ˜¾ç„¶ï¼Œæˆ‘åœ¨è¿™é‡Œçš„æŸä¸ªåœ°æ–¹æœ‰è¯¯è§£ï¼Œå› ä¸ºæˆ‘ä¸åº”è¯¥å°è¯•æœ€å¤§ç¨‹åº¦åœ°å‡å°‘å’Œæœ€å¤§åŒ–ç›¸åŒçš„åŠŸèƒ½ï¼Œå› æ­¤æˆ‘çš„å®ç°æ²¡æœ‰å­¦ä¹ ä»»ä½•ä¸œè¥¿ã€‚ æˆ‘çš„æŸå¤±åŠŸèƒ½å¦‚ä¸‹ï¼š &lt; pre&gt; ï¼ƒè®¡ç®—ä¼˜åŠ¿= mc_returns -self.criticï¼ˆstatesï¼‰.detachï¼ˆï¼‰ï¼ƒè®¡ç®—ç­–ç•¥æŸå¤±new_log_probs = self.policy.policy.get_get_log_probï¼ˆstateï¼Œactionsï¼Œactionsï¼‰æ¯”ç‡=ï¼ˆnew_log_probs -old_log_log_probs -old_log_probsï¼‰ =æ¯”ç‡ *ä¼˜åŠ¿polition_loss2 = torch.clampï¼ˆæ¯”ç‡ï¼Œ1- self.epsilonï¼Œ1 + self.epsilonï¼‰ *ä¼˜åŠ¿polition_loss = -torch.minï¼ˆpolican_loss1ï¼Œpolition_loss2ï¼Œpolition_loss2ï¼‰.meanï¼ˆï¼‰.meanï¼ˆï¼‰ .criticï¼ˆdatesï¼‰-mc_returnsï¼‰** 2ï¼‰.meanï¼ˆï¼‰ï¼ƒè®¡ç®—ä¼˜åŠ¿= mc_returns -self.criticï¼ˆstatesï¼‰.detachï¼ˆdateï¼‰.detachï¼ˆï¼‰ï¼ƒè®¡ç®—ç­–ç•¥æŸå¤±new_log_probs = self.policy.policy.policy.get_log_probï¼ˆstatesï¼Œantatesï¼Œanctionï¼‰æ¯”ä¾‹=ï¼ˆnew_log_probs -old_log_probsï¼‰.expï¼ˆï¼‰polition_loss1 =æ¯”ç‡ *ä¼˜åŠ¿polition_loss2 = torch.clampï¼ˆæ¯”ç‡ï¼Œ1- self.epsilonï¼Œ1 + self.epsilonï¼‰ ï¼ˆï¼‰ï¼ƒè®¡ç®—å€¼æŸå¤±å€¼_loss =ï¼ˆï¼ˆself.criticï¼ˆstatesï¼‰-mc_returnsï¼‰** 2ï¼‰.meanï¼ˆï¼‰   è¿™æ˜¯æˆ‘å¦‚ä½•è®¡ç®—è’™ç‰¹å¡æ´›ï¼ˆISHï¼‰è¿”å›çš„æ–¹å¼ã€‚æˆ‘åœ¨å›ºå®šçš„æ—¶é—´æ­¥é•¿æˆ–æƒ…èŠ‚ç»“æŸåè®¡ç®—å›æŠ¥åœ¨èŒƒå›´å†…ï¼ˆ1ï¼Œlenï¼ˆå¥–åŠ±ï¼‰ + 1ï¼‰ï¼šå¦‚æœi == 1ä¸”æœªå®Œæˆï¼šcurr_return =å¥–åŠ± + self.gamma*è¯„è®ºå®¶ï¼ˆnext_stateï¼‰.detachï¼ˆï¼‰elseï¼šcurr_return = redward = rewards [-i] + selfã€‚ gamma*curr_return mc_returns [-i] = curr_return curr_return = 0åœ¨èŒƒå›´å†…ï¼ˆ1ï¼Œlenï¼ˆrewardsï¼‰ + 1ï¼‰ï¼šå¦‚æœi == 1ä¸”æœªå®Œæˆï¼šcurr_return = reward = reward + self.gamma*crialted.gamma*è¯„è®ºå®¶ï¼ˆnext_stateï¼‰ã€‚ distachï¼ˆï¼‰elseï¼šcurr_return = rewards [-i] + self.gamma*curr_return mc_returns [-i] = curr_return    å¦‚æœæœ‰äººå¯ä»¥å¸®åŠ©æ¾„æ¸…æˆ‘åœ¨è¿™é‡Œç¼ºå°‘çš„ä¸œè¥¿æ„Ÿè°¢ï¼ ç¼–è¾‘ï¼šæ–°ä¼˜åŠ¿æˆ‘æ­£åœ¨ä½¿ç”¨ï¼š  https://preview.redd.it/zt0l6wpu67ie1.png?width=282&amp;format=png&amp;auto=webp&amp;s=51d7d33d96faf376c8e981c489b577a4033cbc1e  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/lostbandard     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1il6erp/ppo_question_policy_loss_and_value_function/</guid>
      <pubDate>Sun, 09 Feb 2025 04:15:21 GMT</pubDate>
    </item>
    <item>
      <title>â€œå…³äºè¯­è¨€æ¨¡å‹è’¸é¦çš„è€å¸ˆé»‘å®¢æ”»å‡»â€ï¼ŒTiapkinç­‰äºº2025</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1il2g2j/on_teacher_hacking_in_language_model_distillation/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/gwern     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1il2g2j/on_teacher_hacking_in_language_model_distillation/</guid>
      <pubDate>Sun, 09 Feb 2025 00:45:44 GMT</pubDate>
    </item>
    <item>
      <title>å¢å¼ºå­¦ä¹ æ§åˆ¶è·Ÿè¸ªè½¨è¿¹è½¨è¿¹6-DOF Quadcopteræ— äººæœº</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ikvnbb/reinforcerment_learning_control_tracking/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ikvnbb/reinforcerment_learning_control_tracking/</guid>
      <pubDate>Sat, 08 Feb 2025 19:38:32 GMT</pubDate>
    </item>
    <item>
      <title>å››è½®æ‘©æ‰˜è½¦æ— äººæœºçš„å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ikrw11/reinforcement_learning_for_quadcopter_uav/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ikrw11/reinforcement_learning_for_quadcopter_uav/</guid>
      <pubDate>Sat, 08 Feb 2025 17:01:21 GMT</pubDate>
    </item>
    <item>
      <title>â€œå¹³è¡ŒQ-å­¦ä¹ ï¼ˆPQLï¼‰ï¼šåœ¨å¤§è§„æ¨¡å¹³è¡Œæ¨¡æ‹Ÿä¸‹ç¼©æ”¾éæ”¿ç­–çš„å¢å¼ºå­¦ä¹ â€ï¼ŒLi et al 2023</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ikpy13/parallel_qlearning_pql_scaling_offpolicy/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/gwern     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ikpy13/parallel_qlearning_pql_scaling_offpolicy/</guid>
      <pubDate>Sat, 08 Feb 2025 15:37:30 GMT</pubDate>
    </item>
    <item>
      <title>RLHFå®éªŒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ikk6k2/rlhf_experiments/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å½“å‰RLHFä¸LLMæœ‰å…³å—ï¼Ÿæˆ‘æœ‰å…´è¶£åœ¨æ­¤åŸŸä¸­è¿›è¡Œä¸€äº›å®éªŒï¼Œä½†å¯¹LLMä¸æ„Ÿå…´è¶£ï¼ˆä¸æ˜¯ç¬¬ä¸€ä¸ªè‡³å°‘ä¸€ä¸ªï¼‰ã€‚å› æ­¤ï¼Œæˆ‘æ­£åœ¨è€ƒè™‘åœ¨Openai Gymç¯å¢ƒä¸­è¦åšçš„äº‹æƒ…ï¼Œå¹¶ä»¥æŸäº›å¯å‘å¼å……å½“äººç±»ã€‚ Christianoç­‰ã€‚ alã€‚ ï¼ˆ2017å¹´ï¼‰ä»–ä»¬åœ¨Atariå’ŒMujocoç¯å¢ƒä¸Šè¿›è¡Œäº†å®éªŒï¼Œä½†å®ƒæ—©åœ¨2017å¹´ã€‚å¦‚æœä¸è§¦åŠLLMï¼Ÿ   &lt;ï¼ - åœ¨RLHFä¸­å‘è¡¨ç ”ç©¶çš„æœºä¼šæ˜¯å¦éå¸¸ä½ã€‚ -SC_ON-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/wayown2610     [link]  ï¼†ï¼ƒ32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ikk6k2/rlhf_experiments/</guid>
      <pubDate>Sat, 08 Feb 2025 10:10:36 GMT</pubDate>
    </item>
    <item>
      <title>ğŸš€è®­ç»ƒå››å€çš„å¢å¼ºå­¦ä¹ ï¼šä»é›¶åˆ°è‹±é›„ï¼ ğŸ¦¾</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ik7dhn/training_quadrupeds_with_reinforcement_learning/</link>
      <description><![CDATA[    å†…éƒ¨æœ‰ä»€ä¹ˆï¼Ÿå¥–åŠ±åŠŸèƒ½&lt; /strong&gt;ç”¨äºæœ‰æ•ˆå­¦ä¹ âœ…è®­ç»ƒè¿åŠ¨ç­–ç•¥åœ¨æ¨¡æ‹Ÿä¸­ä½¿ç”¨ ppo &lt; /strong&gt;ï¼ˆä»¥æ’’å¥èº«æˆ¿ï¼ŒMujocoç­‰ï¼‰ã€‚ /strong&gt;å¯¹ç°å®ä¸–ç•Œéƒ¨ç½²çš„æŒ‘æˆ˜ çµæ„Ÿæ¥è‡ª Genesis çš„ä½œå“ä»¥åŠåŸºäºRLçš„æœºå™¨äººæ§åˆ¶çš„è¿›æ­¥ï¼Œæˆ‘ä»¬çš„æ•™ç¨‹ä¸ºè®­ç»ƒå››è¶³åŠ¨ç‰©æä¾›äº†ç»“æ„åŒ–æ–¹æ³•ï¼Œæ— è®ºæ‚¨æ˜¯&#39;æ˜¯ç ”ç©¶äººå‘˜ï¼Œå·¥ç¨‹å¸ˆæˆ–çˆ±å¥½è€…ã€‚ ä¸€åˆ‡éƒ½æ˜¯ open-access   - æ²¡æœ‰ä»˜è´¹å¢™ï¼Œåªæ˜¯çº¯RLçŸ¥è¯†ï¼ ğŸš€  æ–‡ç« ï¼š ä½¿å››å€ä½“å­¦ä¼šèµ°è·¯&lt; /a&gt;  ä»£ç ï¼š  github repo     å¾ˆæƒ³å¬å¬æ‚¨çš„åé¦ˆå¹¶è®¨è®ºæœºå™¨äººè¿åŠ¨çš„RLç­–ç•¥ï¼ ğŸ™Œ   https://reddit.com/link./link./link/link/link/1ik7dhn/video/arizr9gikshe1/player &lt; /a&gt;   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/federicosarocco     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ik7dhn/training_quadrupeds_with_reinforcement_learning/</guid>
      <pubDate>Fri, 07 Feb 2025 22:16:46 GMT</pubDate>
    </item>
    <item>
      <title>â€œåŸºäºä»·å€¼çš„æ·±åº¦RLé‡è¡¨å¯ä»¥é¢„è§â€ï¼ŒRybkinç­‰äºº2025</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ik3274/valuebased_deep_rl_scales_predictably_rybkin_et/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/gwern     [link]  ï¼†ï¼ƒ32;  &lt;a href =â€œ https://www.reddit.com/r/reinforecctionlearning/comments/1ik3274/valuebaseed_deep_rl_scal_scales_predictaliquality_rybkin_et/]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ik3274/valuebased_deep_rl_scales_predictably_rybkin_et/</guid>
      <pubDate>Fri, 07 Feb 2025 19:14:27 GMT</pubDate>
    </item>
    <item>
      <title>Schnellç­‰äººâ€œæ—¶é—´å·®å¼‚å­¦ä¹ ï¼šä¸ºä»€ä¹ˆä¼šå˜å¾—å¿«é€Ÿï¼Œå¦‚ä½•æ›´å¿«â€ã€‚ 2025</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ijxavb/temporal_difference_learning_why_it_can_be_fast/</link>
      <description><![CDATA[    [link]   ï¼†ï¼ƒ32;   [æ³¨é‡Š] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ijxavb/temporal_difference_learning_why_it_can_be_fast/</guid>
      <pubDate>Fri, 07 Feb 2025 15:17:07 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘ä»¬çš„RLæ¡†æ¶å°†ç”¨äºå¿«é€Ÿï¼Œè¿›åŒ–HPOçš„ä»»ä½•ç½‘ç»œ/ç®—æ³•è½¬æ¢ã€‚æˆ‘ä»¬åº”è¯¥ä½¿LLMå¯ç”¨äºè¿›åŒ–RLæ¨ç†åŸ¹è®­å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ijr36h/our_rl_framework_converts_any_networkalgorithm/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œå¤§å®¶ï¼Œæˆ‘ä»¬åˆšåˆšå‘å¸ƒäº†agilerl v2.0ï¼ æŸ¥çœ‹æœ€æ–°æ›´æ–°ï¼š https://github.com/agilerl/agilerl     agilerlæ˜¯ä¸€ä¸ªRLåŸ¹è®­åº“ï¼Œå¯å®ç°ä»»ä½•ç½‘ç»œçš„è¿›åŒ–è¶…å‚æ•°ä¼˜åŒ–ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ¯”rllibçš„è®­ç»ƒæ›´å¿«10å€ã€‚ è¿™æ˜¯æˆ‘ä»¬æ·»åŠ çš„ä¸€äº›å¾ˆé…·çš„åŠŸèƒ½ï¼š  å¹¿ä¹‰çªå˜ - ä¸€ä¸ªå®Œå…¨æ¨¡å—åŒ–çš„ï¼Œçµæ´»çš„ç½‘ç»œå’ŒRLçš„æŸ”æ€§çªå˜æ¡†æ¶è¶…å‚æ•°ã€‚  Evolvablenetwork API  - åœ¨å¯æ¼”åŒ–çš„è®¾ç½®ä¸­ä½¿ç”¨ä»»ä½•ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬é¢„éªŒè¯çš„ç½‘ç»œã€‚  evolvableAlgorithmå±‚æ¬¡ç»“æ„ - ç®€åŒ–çš„è¿›åŒ–RLç®—æ³•çš„å®ç°ã€‚ EvolvableModuleå±‚æ¬¡ç»“æ„ - è·Ÿè¸ªå¤æ‚ç½‘ç»œä¸­çªå˜çš„æ›´èªæ˜çš„æ–¹æ³•ã€‚ æ”¯æŒå¤æ‚ç©ºé—´ - ä½¿ç”¨EvolvableMultiinputæ— ç¼å¤„ç†å¤šè¾“å…¥ç©ºé—´ã€‚  çŸ¥é“æ˜¯ï¼šæˆ‘ä»¬åº”è¯¥å°†å…¶å®Œå…¨æ‰©å±•åˆ°LLMå—ï¼Ÿå½“å‰å¤§å‹å‹å·çš„HPOå¹¶ä¸æ˜¯çœŸæ­£çš„ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å¦‚æ­¤éš¾/æ˜‚è´µã€‚ä½†æ˜¯æˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥ä½¿å…¶æ›´åŠ æœ‰æ•ˆã€‚æˆ‘å·²ç»æ„è¯†åˆ°äººä»¬æ¯”è¾ƒäº†ç”¨äºåœ¨DeepSeek R0å¨±ä¹æ´»åŠ¨ä¸­è·å¾—æ›´å¥½ç»“æœçš„è¶…å‚æ•°çš„äººï¼Œè¿™æ„å‘³ç€è¿™å¯èƒ½å¾ˆæœ‰ç”¨ã€‚æˆ‘æƒ³çŸ¥é“æ‚¨å¯¹è¿›åŒ–HPOæ˜¯å¦å¯¹åŸ¹è®­å¤§å‹æ¨ç†æ¨¡å‹æœ‰ç”¨çš„æƒ³æ³•ï¼Ÿè€Œä¸”ï¼Œå¦‚æœæœ‰äººå¹»æƒ³æœ‰åŠ©äºä¸ºè¿™é¡¹å·¥ä½œåšå‡ºè´¡çŒ®ï¼Œæˆ‘ä»¬ä¼šå¾ˆå–œæ¬¢æ‚¨çš„å¸®åŠ©ï¼è°¢è°¢   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/nicku_a     [link]  ï¼†ï¼ƒ32;   [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ijr36h/our_rl_framework_converts_any_networkalgorithm/</guid>
      <pubDate>Fri, 07 Feb 2025 09:21:43 GMT</pubDate>
    </item>
    </channel>
</rss>