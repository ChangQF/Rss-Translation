<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Mon, 28 Oct 2024 21:16:04 GMT</lastBuildDate>
    <item>
      <title>æœºå™¨äººæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼šç°å®ä¸–ç•Œçš„æˆåŠŸè°ƒæŸ¥</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ge2hn5/deep_reinforcement_learning_for_robotics_a_survey/</link>
      <description><![CDATA[  ç”±    /u/bulgakovML  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ge2hn5/deep_reinforcement_learning_for_robotics_a_survey/</guid>
      <pubDate>Mon, 28 Oct 2024 13:48:41 GMT</pubDate>
    </item>
    <item>
      <title>ç»„åˆ DQN</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ge11zq/combining_dqns/</link>
      <description><![CDATA[å°† 3 ä¸ª DQN ç»„åˆæˆä¸€ä¸ª DQN çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆã€‚æ¯ä¸ª DQN éƒ½æœ‰ç±»ä¼¼çš„å‚æ•°ï¼Œå°±åƒå®ƒä»¬åœ¨ä¸åŒçš„ä»»åŠ¡ä¸Šå·¥ä½œä½†ä»ç„¶ç›¸ä¼¼ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæœ‰æ•Œäººå’ŒçŠ¶æ€çš„æ¸¸æˆã€‚é¦–å…ˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ 3 ä¸ªåŠ¨ä½œã€‚  ä½¿ç”¨å‰‘ ä½¿ç”¨å¼“ ä½¿ç”¨é­”æ³•  å¦‚æœæ‚¨ä½¿ç”¨å‰‘ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ 2 ç§ä¸åŒçš„åŠ¨ä½œï¼Œå¦‚è½»æ”»å‡»æˆ–é‡æ”»å‡»ã€‚å¦‚æœæ‚¨ä½¿ç”¨å¼“ï¼Œæ‚¨å¯ä»¥ç”¨å®ƒå‡»ä¸­æ•Œäººçš„è¿‘æˆ˜ï¼Œæˆ–è€…ä½¿ç”¨ç®­ï¼ˆå¦‚æœæœ‰ï¼‰ç­‰ã€‚ æˆ‘ä¸æƒ³åˆ›å»ºä¸€ä¸ªå¯ä»¥å†³å®šç¬¬ä¸€ä¸ªåŠ¨ä½œï¼ˆå°†ä½¿ç”¨ä»€ä¹ˆæ ·çš„æ­¦å™¨ï¼‰ç„¶åä¸ºæ¯ç§æ­¦å™¨å†³å®šå°†é‡‡å–ä»€ä¹ˆæ ·çš„åŠ¨ä½œçš„ DQNï¼Œè€Œæ˜¯æƒ³ä¸ºæ¯ç§æ­¦å™¨åˆ›å»ºä¸€ä¸ª DQNï¼Œå®ƒç¡®åˆ‡åœ°çŸ¥é“å¦‚ä½•ä½¿ç”¨ä¸€ç§æ­¦å™¨ï¼Œç„¶åå°†å®ƒä»¬ç»„åˆæˆ 1ã€‚æœ€ç»ˆçš„ç½‘ç»œåº”è¯¥ä»çŠ¶æ€ä¸­äº†è§£å°†ä½¿ç”¨å“ªç§æ­¦å™¨ä»¥åŠè¿™äº›æ­¦å™¨å°†é‡‡å–ä»€ä¹ˆåŠ¨ä½œã€‚    æäº¤äºº    /u/volvol7   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ge11zq/combining_dqns/</guid>
      <pubDate>Mon, 28 Oct 2024 12:43:08 GMT</pubDate>
    </item>
    <item>
      <title>æœŸå¾…æ˜å¹´å¼€å§‹æ”»è¯» RL åšå£«å­¦ä½â€”â€”å¯»æ±‚å»ºè®®ï¼ğŸ¤ğŸ¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdyx82/looking_forward_to_start_phd_in_rl_next_year/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼æˆ‘å‡†å¤‡æ˜å¹´å¼€å§‹æ”»è¯»å¼ºåŒ–å­¦ä¹ åšå£«å­¦ä½ï¼Œä½†éœ€è¦ä¸€äº›å…³äºç§¯ç´¯ç ”ç©¶ç»éªŒå’Œä¸æ•™æˆè”ç³»çš„å»ºè®®ã€‚  èƒŒæ™¯ï¼šæˆ‘åšè¿‡å¾ˆå¤šå®é™…çš„å¼ºåŒ–å­¦ä¹ é¡¹ç›®ï¼ˆMARLã€PettingZooã€ç­–ç•¥æ¢¯åº¦å·¥ä½œï¼‰ï¼Œä½†æˆ‘ç¼ºä¹æ­£å¼çš„ç ”ç©¶ç»éªŒã€‚æˆ‘ä¹Ÿæœ‰ä¸€å¹´çš„ ML/LLM å®ä¹ ç»å†ï¼Œä½†å¯»æ‰¾å¼ºåŒ–å­¦ä¹ çš„ç ”ç©¶å®ä¹ æœºä¼šä¸€ç›´å¾ˆå›°éš¾ã€‚ æŒ‘æˆ˜ï¼šæˆ‘æ‹…å¿ƒæ¥è§¦ LORï¼Œå› ä¸ºæˆ‘æ²¡æœ‰ç›´æ¥ä¸å¼ºåŒ–å­¦ä¹ çš„æ•™æˆåˆä½œè¿‡ã€‚ä»»ä½•å…³äºæœ‰åŠ©äºå±•ç¤ºæˆ‘çš„èƒ½åŠ›çš„é¡¹ç›®å»ºè®®æˆ–æ¥è§¦æŠ€å·§éƒ½å°†éå¸¸æœ‰å¸®åŠ©ã€‚å¦å¤–ï¼Œå¦‚æœæœ‰äººæœ‰å…´è¶£åˆä½œï¼Œè¯·ç›´æ¥å‘ä¿¡æ¯ç»™æˆ‘ï¼ &lt;3  ä»»ä½•è§è§£éƒ½å€¼å¾—èµèµ - è°¢è°¢å¤§å®¶ï¼    æäº¤äºº    /u/cheenchann   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdyx82/looking_forward_to_start_phd_in_rl_next_year/</guid>
      <pubDate>Mon, 28 Oct 2024 10:41:28 GMT</pubDate>
    </item>
    <item>
      <title>å“ªäº› RL ç®—æ³•é€‚ç”¨äºè®¡ç®—å¿ƒç†å­¦ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdytbm/which_rl_algorithms_for_computational_psychology/</link>
      <description><![CDATA[æˆ‘æ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶ï¼Œå¸Œæœ›é€šè¿‡å¤šä¸ªä»£ç†æ¨¡æ‹Ÿäººç±»ç¤¾äº¤äº’åŠ¨ã€‚æˆ‘åªæ˜¯æƒ³çŸ¥é“æ˜¯å¦æœ‰äººå¯ä»¥æŒ‡ç‚¹ä¸€ä¸‹è¦æ¢ç´¢å“ªäº›ç®—æ³•ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘æƒ³é¼“åŠ±åé¦ˆå¾ªç¯å’Œçªå‘è¡Œä¸ºä»¥æ›´çœŸå®åœ°æè¿°äººç±»è¡Œä¸ºï¼Œæˆ‘åº”è¯¥ä½¿ç”¨æ— æ¨¡å‹ç®—æ³•è¿˜æ˜¯åŸºäºæ¨¡å‹çš„ç®—æ³•ï¼Ÿ ä»æˆ‘æœ€åˆçš„ç ”ç©¶ä¸­ï¼Œæˆ‘å¬è¯´äº†å…³äº Decision Transformer å’Œ DreamerV3 çš„å¥½è¯„ã€‚ æ„Ÿè°¢æ‚¨çš„æ—¶é—´ï¼    æäº¤äºº    /u/culturedindividual   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdytbm/which_rl_algorithms_for_computational_psychology/</guid>
      <pubDate>Mon, 28 Oct 2024 10:33:59 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹æŠ—æ€§ç¨³å¥æ·±åº¦å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdyrwe/adversarial_robust_deep_reinforcement_learning/</link>
      <description><![CDATA[https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning    ç”±   æäº¤  /u/ml_dnn   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdyrwe/adversarial_robust_deep_reinforcement_learning/</guid>
      <pubDate>Mon, 28 Oct 2024 10:31:18 GMT</pubDate>
    </item>
    <item>
      <title>æœ¬ç§‘ç”Ÿåœ¨ç°å®ç”Ÿæ´»ä¸­çš„ç ”ç©¶æƒ³æ³•ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdvrw0/undergraduate_research_in_rl_ideas/</link>
      <description><![CDATA[æˆ‘å¸Œæœ›å®Œæˆä¸ RL ç›¸å…³çš„è£èª‰é¡¹ç›®ã€‚ä»Šå¹´å¤å¤©ï¼Œæˆ‘å°†ä¸æˆ‘çš„æ•™æˆä¸€èµ·å¼€å±•ä¸€ä¸ªå°å‹ RL ä»£ç†é¡¹ç›®ï¼Œæˆ‘çš„ä»»åŠ¡æ˜¯åˆ¶ä½œä¸€ä¸ª RL è •è™«ã€‚æˆ‘å¯¹ RL çš„ä¸–ç•Œè¿˜å¾ˆé™Œç”Ÿï¼Œå¸Œæœ›èƒ½å¾—åˆ°ä»»ä½•å»ºè®®æˆ–åœ°æ–¹ï¼Œè®©æ–°æ‰‹å¼€å§‹ç ”ç©¶è¿™ä¸ªä¸»é¢˜ï¼    æäº¤äºº    /u/Future-Catch-4896   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdvrw0/undergraduate_research_in_rl_ideas/</guid>
      <pubDate>Mon, 28 Oct 2024 06:41:06 GMT</pubDate>
    </item>
    <item>
      <title>å¯»æ±‚æœ‰å…³ PettingZoo å’Œ MARL çš„å¸®åŠ©</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdq509/seeking_help_with_pettingzoo_and_marl_in_general/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªå°å‹ MARL é¡¹ç›®ï¼Œå¸Œæœ›å¯ä»¥æ‰©å±•åˆ°æ›´å¤§çš„é¡¹ç›®ã€‚æˆ‘çš„æƒ³æ³•æ˜¯åŸºäºç½‘æ ¼çš„ï¼ŒMPE çš„ä¸€äº›è‡ªå®šä¹‰å˜ä½“å¯èƒ½æ˜¯å¯è¡Œçš„æ–¹æ³•ã€‚ä½ ä»¬å½“ä¸­æœ‰è°æœ‰ä½¿ç”¨ PettingZoo æˆ–å…¶ä»– MARL åº“çš„ç»éªŒï¼Œå¯ä»¥å¸®æˆ‘å¿«é€Ÿä¸Šæ‰‹å—ï¼Ÿæˆ‘æ„¿æ„ä»˜é’±ã€‚è°¢è°¢ï¼    æäº¤äºº    /u/zarmesan   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdq509/seeking_help_with_pettingzoo_and_marl_in_general/</guid>
      <pubDate>Mon, 28 Oct 2024 00:58:02 GMT</pubDate>
    </item>
    <item>
      <title>RecurrentPPO äº¤æ˜“ç¯å¢ƒçš„åŠ¨ä½œæ©è”½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdjslp/action_masking_for_recurrentppo_trading_env/</link>
      <description><![CDATA[      æˆ‘æ­£åœ¨ä½¿ç”¨ RecurrentPPO sb3 è®­ç»ƒäº¤æ˜“ç¯å¢ƒ   æˆ‘æƒ³ä½¿ç”¨åŠ¨ä½œæ©ç æ¥é˜²æ­¢æ¨¡å‹ä½¿ç”¨æ— æ•ˆæ“ä½œï¼ˆä¾‹å¦‚ï¼Œå½“å¼€ä»“æ—¶è¿›è¡Œè¡¥ä»“æ“ä½œ2.åœ¨äº¤æ˜“å¼€å§‹æ—¶ï¼Œå¥–åŠ±ä»¥æ›´é«˜çš„é€Ÿç‡å¢åŠ ï¼Œç„¶åé€Ÿç‡é™ä½ï¼Œè¿™æ˜¯å¦æ„å‘³ç€æ¨¡å¼å·²ç»æ”¶æ•›æˆ–è€…æˆ‘éœ€è¦è°ƒæ•´ä¸€äº›å‚æ•°ï¼Ÿ  å¥–åŠ±    submitted by    /u/Acceptable_Egg6552   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdjslp/action_masking_for_recurrentppo_trading_env/</guid>
      <pubDate>Sun, 27 Oct 2024 20:00:18 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ï¼šä»æ¸¸æˆåˆ°ç°å®ä¸–ç•Œå½±å“çš„æ¼”å˜ - ç¬¬ 77 å¤© - INGOAMPT</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gddlmo/reinforcement_learning_an_evolution_from_games_to/</link>
      <description><![CDATA[        ç”±    /u/Potential_Arrival326   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gddlmo/reinforcement_learning_an_evolution_from_games_to/</guid>
      <pubDate>Sun, 27 Oct 2024 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘æ˜¯å¦ä»¥æ­£ç¡®çš„æ–¹å¼ä½¿ç”¨ PPO æ¥å®Œæˆè¿™é¡¹è¿ç»­ï¼ˆç®—æ³•äº¤æ˜“ï¼‰ä»»åŠ¡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdaof1/am_i_using_ppo_the_right_way_for_this_continuous/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚ æˆ‘æ˜¯ RL çš„æ–°æ‰‹ï¼Œå¸Œæœ›ç»éªŒä¸°å¯Œçš„ RL ç”¨æˆ·èƒ½å¤Ÿå›ç­”æˆ‘çš„ä¸€äº›é—®é¢˜ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚ æ‰€ä»¥æˆ‘æœ‰è¿™ä¸ªè¢«åŒ…è£…åˆ° gymnasium env ä¸­çš„ç¯å¢ƒï¼Œä½†åŸºæœ¬ä¸Šå®ƒæ˜¯ä¸€ä¸ªåŸºäºäº‹ä»¶çš„å›æµ‹ï¼Œå¤„ç† tick çº§åˆ«çš„ HFT æ•°æ®ã€‚æˆ‘æœ‰ä¸€ä¸ªåšå¸‚äº¤æ˜“ç­–ç•¥ä»£ç ï¼Œæ¯ 100 æ¯«ç§’å‘äº¤æ˜“æ‰€å‘é€è®¢å•ï¼Œæ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡æ»šåŠ¨æŒ‡æ ‡ã€‚æ ¹æ®æ»šåŠ¨æŒ‡æ ‡çš„å€¼ï¼Œå®ƒå†³å®šä»ä¸­é—´ä»·å‘é€è®¢å•çš„æ·±åº¦ä»¥åŠæ ¹æ®å½“å‰åº“å­˜å¦‚ä½•ç§¯æåœ°æ‰­æ›²ä»·æ ¼ã€‚è¯¥ç­–ç•¥æ­£åœ¨å®æ—¶äº¤æ˜“ï¼Œå¹¶ä¸”é€šå¸¸æœ‰åˆ©å¯å›¾ï¼Œä½†æˆ‘è¯»è¿‡ä¸€ç¯‡ç²¾å½©çš„è®ºæ–‡ï¼Œå…¶ä¸­è®¨è®ºäº†åœ¨ç»™å®šæ›´å¯†é›†çš„ç‰¹å¾é›†çš„æƒ…å†µä¸‹åŠ¨æ€è°ƒæ•´äº¤æ˜“ç­–ç•¥çš„è¶…å‚æ•°ï¼Œæˆ‘å¯¹è¿™ä¸ªæƒ³æ³•å¾ˆç€è¿·ï¼Œæ‰€ä»¥æˆ‘è¯•å›¾éƒ¨åˆ†å¤åˆ¶å®ƒã€‚ å› æ­¤ï¼Œä»£ç†çš„ä»»åŠ¡æ˜¯è¯„ä¼°å½“å‰çŠ¶æ€å¹¶è¿”å›ä¸¤ä¸ªè¿ç»­åŠ¨ä½œçš„å‘é‡ï¼Œäº¤æ˜“ç­–ç•¥å°†åœ¨æ¥ä¸‹æ¥çš„ 5 ç§’å†…ä½¿ç”¨è¿™ä¸¤ä¸ªè¶…å‚æ•°ã€‚RL ä»£ç†ä½¿ç”¨çš„ç‰¹å¾é›†æ¯”ç­–ç•¥æœ¬èº«çš„ç‰¹å¾é›†æ›´åŠ å¤šæ ·åŒ–ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªæ›´æ™ºèƒ½çš„ä»£ç†å¸®åŠ©æ›´æœºå™¨äººåŒ–çš„ä»£ç†çš„æƒ…å†µã€‚è¿™ä¸¤ä¸ªè¶…å‚æ•°çš„å€¼é¦–å…ˆæ˜¯åœ¨é€šè¿‡å›æµ‹å¯¹ç­–ç•¥è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–æœŸé—´æ‰¾åˆ°çš„ï¼ˆå› æ­¤æ­¤æ—¶è¿˜æ²¡æœ‰ RLï¼‰ï¼Œç„¶ååŠ¨ä½œå‘é‡æ˜¯ä¸€ä¸ªè¿ç»­ç©ºé—´ï¼Œå…¶ä¸­æœ€ä½³å‚æ•°ä½äºä¸­é—´ï¼Œä¾‹å¦‚ min_value = optimal_value * 0.75ï¼Œmax_value = optimal_value * 1.25ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†ä¸è®©ä»£ç†åç¦»ç­–ç•¥çš„æœ€ä½³å‚æ•°å€¼å¤ªå¤šï¼Œè€Œåªæ˜¯è®©å®ƒæ›´çµæ´»ä¸€ç‚¹ã€‚ å¥–åŠ±å‡½æ•°è®¾ç½®ä¸ºæœ€å 5 ç§’æ­¥éª¤å’Œå‰ä¸€ä¸ªæ­¥éª¤æœŸé—´ pnl å¹³å‡å€¼ä¹‹é—´çš„å˜åŒ–ã€‚è¿˜æ·»åŠ äº†ä¸€äº›æƒ©ç½šé¡¹ä»¥ä¾›å®éªŒã€‚ æˆ‘ä¸ºæ­¤ä½¿ç”¨äº† SB3ã€‚env è¢«åŒ…è£…åˆ° VecNormalize ä¸­ï¼Œaction_space ä»‹äº -1 å’Œ 1 ä¹‹é—´ï¼Œç„¶ååœ¨ç¯å¢ƒä¸­è¢«åè§„èŒƒåŒ–ã€‚ç”±äºä»£ç†æ˜¯åœ¨ä½¿ç”¨å†å²æ•°æ®çš„å›æµ‹å™¨ä¸Šè®­ç»ƒçš„ï¼Œè€Œæˆ‘åªæœ‰æœ‰é™çš„å†å²æ•°æ®ï¼Œå› æ­¤æˆ‘æŒ‰ä»¥ä¸‹æ–¹å¼è®¾ç½®è®­ç»ƒï¼š - ä½¿ç”¨ make_vec_env å’Œ SubprocVecEnv å®ä¾‹åŒ– 48ï¼ˆCPU æ•°é‡ï¼‰ä¸ªç¯å¢ƒ - å¯åŠ¨ï¼ˆæˆ–é‡ç½®ï¼‰ç¯å¢ƒæ—¶ï¼Œä»å¯ç”¨æ•°æ®ä¸­éšæœºæŒ‘é€‰ä¸€å¤©ï¼ˆé€šå¸¸æ˜¯ 10-20 å¤©çš„æ•°æ®ï¼‰ - å½“è¿™ä¸€å¤©ç”¨å°½æ—¶ï¼Œå‘æ¨¡å‹å‘é€ Truncated ä¿¡å· - ç»§ç»­æ‰§è¡Œé¢„è®¾çš„æ­¥éª¤æ•° é—®é¢˜æ˜¯æ¨¡å‹ä¼¼ä¹æ ¹æœ¬æ²¡æœ‰å­¦ä¹ ã€‚å½“æˆ‘å°†æ•°æ®é™åˆ¶ä¸º 10 å°æ—¶çš„æ•°æ®æ—¶ï¼Œå®ƒå¯ä»¥å¾ˆå¥½åœ°å­¦ä¹ ï¼ˆå¯èƒ½åªæ˜¯è¿‡åº¦æ‹Ÿåˆï¼‰ï¼Œä½†æ˜¯å½“æˆ‘å‘å®ƒæä¾› 10-20 å¤©çš„æ•°æ®å¹¶è¦æ±‚å®ƒæ‰¾åˆ°æä¾›è¶…å‚æ•°çš„æœ€ä½³ç­–ç•¥æ—¶ï¼Œå®ƒå´æ— æ³•åšåˆ°ã€‚äº‹å®æ˜¯ï¼Œå¦‚æœå®ƒå§‹ç»ˆåªæ˜¯é€‰æ‹©è¡ŒåŠ¨çš„ä¸­é—´å€¼ï¼Œå®ƒè‡³å°‘ä¼šè·å¾—è¾ƒå¤§çš„ç´¯ç§¯å¥–åŠ±ã€‚  æ‰€ä»¥æˆ‘æœ‰ä»¥ä¸‹é—®é¢˜ï¼š - è¿™æ˜¯è®¾ç½®è¿™ç§å›ºæœ‰è¿ç»­ä»»åŠ¡çš„æ­£ç¡®æ–¹æ³•å—ï¼ˆä¾‹å¦‚ä½¿ç”¨æˆªæ–­æƒ…èŠ‚ï¼‰ï¼Ÿ - PPO æ˜¯å¦æ˜¯é€‚åˆæ­¤ç±»ä»»åŠ¡çš„ç®—æ³•ï¼Ÿ - ç”±äºç¯å¢ƒä»…éƒ¨åˆ†å¯è§‚å¯Ÿï¼Œåº”è¯¥ç‰¹åˆ«æ³¨æ„å“ªäº›è¶…å‚æ•°ï¼Ÿ - ç”±äºæˆ‘ä»¬ä¸ºæ¥ä¸‹æ¥ 5 ç§’çš„äº¤æ˜“ç­–ç•¥æä¾›äº†å‚æ•°å€¼ï¼Œè€Œæ²¡æœ‰äººçŸ¥é“æ¥ä¸‹æ¥ 5 ç§’ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œæˆ‘ä»¬æ˜¯å¦åº”è¯¥æ›´ç§¯æåœ°æŠ˜æ‰£æœªæ¥çš„å¥–åŠ±ï¼Ÿ - ä½¿ç”¨ç¦»æ•£åŠ¨ä½œç©ºé—´æ˜¯å¦ä¼šè®©ä»£ç†æ›´å®¹æ˜“å­¦ä¹ æ­£ç¡®çš„ç­–ç•¥ï¼Ÿ æˆ‘ç›®å‰æ­£åœ¨å°è¯•è¾ƒå¤§çš„ n_step å€¼ï¼Œå½“ä¹˜ä»¥æ­¥æ•°æ—¶ï¼Œéœ€è¦ä¸€æ•´å¤©çš„äº¤æ˜“ï¼ˆæ€»å…±çº¦ 200K æ­¥ï¼‰å’Œæ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œè¿™æ˜¾ç¤ºå‡ºä¸€äº›æ”¹è¿›ï¼Œä½†ä»ç„¶æ²¡æœ‰å­¦ä¹ ã€‚æˆ‘å…è®¸å®ƒè®­ç»ƒ 20M æ­¥ã€‚    æäº¤äºº    /u/StabbMe   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdaof1/am_i_using_ppo_the_right_way_for_this_continuous/</guid>
      <pubDate>Sun, 27 Oct 2024 13:13:50 GMT</pubDate>
    </item>
    <item>
      <title>ä»‹ç»å°†å†›æœºå™¨äººï¼šä¸€ä¸ªå¿«èŠ‚å¥çš„æˆ˜ç•¥æ¸¸æˆç¯å¢ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gda8hj/introducing_generalsbots_a_fastpaced_strategy/</link>
      <description><![CDATA[        ç”±    /u/shrekofspeed  æäº¤  [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gda8hj/introducing_generalsbots_a_fastpaced_strategy/</guid>
      <pubDate>Sun, 27 Oct 2024 12:50:35 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘ä¸€ç›´åœ¨å°è¯•â€œSimbaï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­æ‰©å¤§å‚æ•°çš„ç®€å•åå·®â€ï¼ŒTQC å’Œè¿™ä¸ªçš„ç»“åˆçœŸæ˜¯ä¸€ä¸ªæ€ªç‰©ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gd8j5c/ive_been_trying_out_simba_simplicity_bias_for/</link>
      <description><![CDATA[      https://preview.redd.it/pay0fmh36axd1.png?width=1500&amp;format=png&amp;auto=webp&amp;s=42e8188a85ccbc51da4345f99f62a8a59b32b29a æˆ‘çœ‹åˆ°äº†å…³äºè¾›å·´çš„å¸–å­ï¼ˆé“¾æ¥) å¹¶ç«‹å³åœ¨æˆ‘ç®¡ç†çš„ç©å…·é¡¹ç›®å­˜å‚¨åº“ä¸­å®ç°å®ƒï¼Œåªéœ€åˆ‡æ¢åˆ°å®ƒå°±å¯ä»¥çœ‹åˆ°éå¸¸æ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œæœ€æ˜¾ç€çš„æ˜¯åœ¨ TQC ä¸­ã€‚å®ç°å¦‚ä¸‹ï¼šhttps://github.com/tinker495/jax-baseline çœ‹åˆ°å¦‚æ­¤ä¼˜ç§€çš„ç ”ç©¶åœ¨æˆ‘è‡ªå·±çš„ä»£ç ä¸­å¸¦æ¥çš„å¥½å¤„éå¸¸ä»¤äººå…´å¥‹ï¼Œæˆ‘æ„Ÿè°¢ SonyResearch åˆ†äº«è¿™äº›ç ”ç©¶ï¼    æäº¤äºº    /u/New_East832   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gd8j5c/ive_been_trying_out_simba_simplicity_bias_for/</guid>
      <pubDate>Sun, 27 Oct 2024 11:05:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] å¯»æ±‚é’ˆå¯¹ CVPRã€ICML ç­‰ä¼šè®®æ­£åœ¨è¿›è¡Œçš„å®Œæ•´è®ºæ–‡çš„åˆä½œã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gcjgue/r_looking_for_collaborations_on_ongoing/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘ä»¬å°ç»„ï¼Œå°åº¦ç†å·¥å­¦é™¢é²å°”åŸºåˆ†æ ¡è§†è§‰ä¸è¯­è¨€å°ç»„ï¼Œæœ€è¿‘æœ‰ä¸‰ç¯‡ç ”è®¨ä¼šè®ºæ–‡è¢« NeurIPS ç ”è®¨ä¼šæ¥å—ï¼ğŸš€ æˆ‘ä»¬è¿˜å»ºç«‹äº†ä¸€ä¸ªç½‘ç«™ ğŸ‘‰ VLGï¼Œå±•ç¤ºæˆ‘ä»¬å‚ä¸è¿‡çš„å…¶ä»–å‡ºç‰ˆç‰©ï¼Œå› æ­¤æˆ‘ä»¬çš„å›¢é˜Ÿæ­£åœ¨ç¨³æ­¥å»ºç«‹ ML å’Œ AI ç ”ç©¶ç»„åˆã€‚ç›®å‰ï¼Œæˆ‘ä»¬æ­£åœ¨åˆä½œæ’°å†™å‡ ç¯‡æ­£åœ¨è¿›è¡Œçš„è®ºæ–‡ï¼Œç›®çš„æ˜¯å‘ CVPR å’Œ ICML ç­‰é¡¶çº§ä¼šè®®æäº¤å…¨æ–‡ã€‚ è¯è™½å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜æœ‰æ›´å¤šè®©æˆ‘ä»¬å…´å¥‹çš„æƒ³æ³•ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬çš„ä¸»è¦é™åˆ¶ä¹‹ä¸€æ˜¯æ— æ³•è·å¾—é€‚å½“çš„æŒ‡å¯¼å’Œ GPU å’Œ API çš„èµ„é‡‘ï¼Œè¿™å¯¹äºè¯•éªŒå’Œæ‰©å±•æˆ‘ä»¬çš„ä¸€äº›æ¦‚å¿µè‡³å…³é‡è¦ã€‚å¦‚æœæ‚¨æˆ–æ‚¨çš„å®éªŒå®¤æœ‰å…´è¶£ä¸€èµ·å·¥ä½œï¼Œæˆ‘ä»¬å¾ˆä¹æ„æ¢ç´¢æˆ‘ä»¬æ„Ÿå…´è¶£é¢†åŸŸçš„äº¤é›†ä»¥åŠæ‚¨å¯èƒ½å¸¦æ¥çš„ä»»ä½•æ–°æƒ³æ³•ï¼ å¦‚æœæ‚¨æœ‰å¯ç”¨èµ„æºæˆ–æœ‰å…´è¶£è®¨è®ºæ½œåœ¨çš„åˆä½œï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ï¼æœŸå¾…ç€å»ºç«‹è”ç³»å¹¶å…±åŒå»ºç«‹æœ‰å½±å“åŠ›çš„ä¸œè¥¿ï¼è¿™æ˜¯æˆ‘ä»¬çš„ Open Slack çš„é“¾æ¥ğŸ‘‰ Open Slack    æäº¤äºº    /u/vlg_iitr   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gcjgue/r_looking_for_collaborations_on_ongoing/</guid>
      <pubDate>Sat, 26 Oct 2024 12:01:00 GMT</pubDate>
    </item>
    <item>
      <title>éªŒè¯æˆ‘çš„ DQN å®ç°</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gchroh/validating_my_dqn_implementation/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨å°è¯•ä¸ºä¸€ä¸ªé¡¹ç›®ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ DQN ä»£ç†ï¼Œæˆ‘åœ¨ github ä¸Šæ‰¾åˆ°äº† Phil çš„ DQN å®ç°ï¼ˆhttps://github.com/philtabor/Deep-Q-Learning-Paper-To-Code/tree/master/DQNï¼‰ã€‚æˆ‘æ‰€åšçš„å”¯ä¸€æ›´æ”¹æ˜¯åœ¨ DeepQNetwork ç±»ä¸Šï¼Œå› ä¸ºæˆ‘çš„è¾“å…¥æ˜¯å‘é‡è€Œä¸æ˜¯çŸ©é˜µï¼Œæ‰€ä»¥æˆ‘åˆ é™¤äº† conv å‡½æ•°ï¼Œåªæ˜¯é€šè¿‡å±‚è½¬å‘æˆ‘çš„è¾“å…¥ã€‚ æˆ‘çš„é—®é¢˜æ˜¯ï¼š  æœ‰æ²¡æœ‰åŠæ³•ç”¨å·²ç»å­˜åœ¨çš„ç¯å¢ƒï¼ˆå¯èƒ½æ˜¯ openAIï¼‰æ¥éªŒè¯æ­¤ä»£ç ï¼Œå…¶ä¸­è§‚å¯Ÿç»“æœæ˜¯å‘é‡è€Œä¸æ˜¯çŸ©é˜µï¼Ÿ ä»£ç æœ¬èº«æ­£ç¡®å—ï¼Ÿä¾‹å¦‚ã€‚æˆ‘åœ¨ github é¡µé¢ä¸Šçœ‹åˆ°ä¸€ä¸ªå…³äºåœ¨ q_target è®¡ç®—ä¹‹å‰ä½¿ç”¨ torch.no_grad() çš„é—®é¢˜ï¼Œä½†å°šæœªè§£å†³ã€‚  ï¼ˆç¼–è¾‘ï¼‰ï¼šæˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´ä¹Ÿä½¿ç”¨ç¨³å®šçš„ epsilonï¼Œè€Œä¸æ˜¯éšç€è½®æ¬¡çš„è¿›è¡Œä¸æ–­é™ä½å®ƒã€‚æ­¤å¤–ï¼Œæ ‡é¢˜å…·æœ‰è¯¯å¯¼æ€§ï¼Œå®ƒä¸æ˜¯â€œæˆ‘çš„â€å®ç°ï¼Œè€Œæ˜¯æ¥è‡ª Phil Tabor    æäº¤äºº    /u/CrazyRabb1tStyle   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gchroh/validating_my_dqn_implementation/</guid>
      <pubDate>Sat, 26 Oct 2024 10:06:21 GMT</pubDate>
    </item>
    <item>
      <title>PPO ä¸­ç†µç³»æ•°è¡°å‡çš„æ­£ç¡®æ–¹æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gcf09f/right_way_to_decay_entropy_coeff_in_ppo/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ä½¿ç”¨ PPO è®­ç»ƒä¸€ä¸ªä¸­ç­‰å¤æ‚çš„ä»£ç†ç¯å¢ƒé—®é¢˜ã€‚æˆ‘æƒ³çŸ¥é“è¡°å‡ç†µç³»æ•°çš„æ­£ç¡®æ–¹æ³•æ˜¯ä»€ä¹ˆï¼ˆè€ƒè™‘åˆ°é—®é¢˜çš„æ€§è´¨ï¼Œå®ƒå¿…é¡»è¡°å‡ï¼‰ã€‚ æˆ‘ä½¿ç”¨çº¿æ€§è¡°å‡è¿˜æ˜¯æŒ‡æ•°è¡°å‡ï¼Ÿä¸¤è€…çš„ä¼˜ç‚¹/ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘çŸ¥é“å®ƒå®Œå…¨å–å†³äºç†µæ›²çº¿ï¼Œä½†å½“æ¶‰åŠåˆ°ç†µæ›²çº¿çš„å½¢çŠ¶æ—¶ï¼Œâ€œç»éªŒæ³•åˆ™â€æ˜¯ä»€ä¹ˆï¼Ÿå®ƒæ˜¯ä» 1 åˆ° 0.1 çš„é€æ¸çº¿æ€§ä¸‹é™å—ï¼Ÿè¿˜æ˜¯å®Œå…¨å–å†³äºé—®é¢˜å’Œ rew è¿›å±•ã€‚ å‘Šè¯‰æˆ‘ä½ çš„ç»å†ã€‚æå‰è°¢è°¢ï¼    æäº¤äºº    /u/Famous-Explanation56   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gcf09f/right_way_to_decay_entropy_coeff_in_ppo/</guid>
      <pubDate>Sat, 26 Oct 2024 06:36:37 GMT</pubDate>
    </item>
    </channel>
</rss>