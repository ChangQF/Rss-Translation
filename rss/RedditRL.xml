<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Sun, 27 Oct 2024 21:14:34 GMT</lastBuildDate>
    <item>
      <title>RecurrentPPO äº¤æ˜“ç¯å¢ƒçš„åŠ¨ä½œæ©è”½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdjslp/action_masking_for_recurrentppo_trading_env/</link>
      <description><![CDATA[      æˆ‘æ­£åœ¨ä½¿ç”¨ RecurrentPPO sb3 è®­ç»ƒäº¤æ˜“ç¯å¢ƒ   æˆ‘æƒ³ä½¿ç”¨åŠ¨ä½œæ©ç æ¥é˜²æ­¢æ¨¡å‹ä½¿ç”¨æ— æ•ˆæ“ä½œï¼ˆä¾‹å¦‚ï¼Œå½“å¼€ä»“æ—¶è¿›è¡Œè¡¥ä»“æ“ä½œ2.åœ¨äº¤æ˜“å¼€å§‹æ—¶ï¼Œå¥–åŠ±ä»¥æ›´é«˜çš„é€Ÿç‡å¢åŠ ï¼Œç„¶åé€Ÿç‡é™ä½ï¼Œè¿™æ˜¯å¦æ„å‘³ç€æ¨¡å¼å·²ç»æ”¶æ•›æˆ–è€…æˆ‘éœ€è¦è°ƒæ•´ä¸€äº›å‚æ•°ï¼Ÿ  å¥–åŠ±    submitted by    /u/Acceptable_Egg6552   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdjslp/action_masking_for_recurrentppo_trading_env/</guid>
      <pubDate>Sun, 27 Oct 2024 20:00:18 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ï¼šä»æ¸¸æˆåˆ°ç°å®ä¸–ç•Œå½±å“çš„æ¼”å˜ - ç¬¬ 77 å¤© - INGOAMPT</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gddlmo/reinforcement_learning_an_evolution_from_games_to/</link>
      <description><![CDATA[        ç”±    /u/Potential_Arrival326   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gddlmo/reinforcement_learning_an_evolution_from_games_to/</guid>
      <pubDate>Sun, 27 Oct 2024 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘æ˜¯å¦ä»¥æ­£ç¡®çš„æ–¹å¼ä½¿ç”¨ PPO æ¥å®Œæˆè¿™é¡¹è¿ç»­ï¼ˆç®—æ³•äº¤æ˜“ï¼‰ä»»åŠ¡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdaof1/am_i_using_ppo_the_right_way_for_this_continuous/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚ æˆ‘æ˜¯ RL çš„æ–°æ‰‹ï¼Œå¸Œæœ›ç»éªŒä¸°å¯Œçš„ RL ç”¨æˆ·èƒ½å¤Ÿå›ç­”æˆ‘çš„ä¸€äº›é—®é¢˜ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚ æ‰€ä»¥æˆ‘æœ‰è¿™ä¸ªè¢«åŒ…è£…åˆ° gymnasium env ä¸­çš„ç¯å¢ƒï¼Œä½†åŸºæœ¬ä¸Šå®ƒæ˜¯ä¸€ä¸ªåŸºäºäº‹ä»¶çš„å›æµ‹ï¼Œå¤„ç† tick çº§åˆ«çš„ HFT æ•°æ®ã€‚æˆ‘æœ‰ä¸€ä¸ªåšå¸‚äº¤æ˜“ç­–ç•¥ä»£ç ï¼Œæ¯ 100 æ¯«ç§’å‘äº¤æ˜“æ‰€å‘é€è®¢å•ï¼Œæ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡æ»šåŠ¨æŒ‡æ ‡ã€‚æ ¹æ®æ»šåŠ¨æŒ‡æ ‡çš„å€¼ï¼Œå®ƒå†³å®šä»ä¸­é—´ä»·å‘é€è®¢å•çš„æ·±åº¦ä»¥åŠæ ¹æ®å½“å‰åº“å­˜å¦‚ä½•ç§¯æåœ°æ‰­æ›²ä»·æ ¼ã€‚è¯¥ç­–ç•¥æ­£åœ¨å®æ—¶äº¤æ˜“ï¼Œå¹¶ä¸”é€šå¸¸æœ‰åˆ©å¯å›¾ï¼Œä½†æˆ‘è¯»è¿‡ä¸€ç¯‡ç²¾å½©çš„è®ºæ–‡ï¼Œå…¶ä¸­è®¨è®ºäº†åœ¨ç»™å®šæ›´å¯†é›†çš„ç‰¹å¾é›†çš„æƒ…å†µä¸‹åŠ¨æ€è°ƒæ•´äº¤æ˜“ç­–ç•¥çš„è¶…å‚æ•°ï¼Œæˆ‘å¯¹è¿™ä¸ªæƒ³æ³•å¾ˆç€è¿·ï¼Œæ‰€ä»¥æˆ‘è¯•å›¾éƒ¨åˆ†å¤åˆ¶å®ƒã€‚ å› æ­¤ï¼Œä»£ç†çš„ä»»åŠ¡æ˜¯è¯„ä¼°å½“å‰çŠ¶æ€å¹¶è¿”å›ä¸¤ä¸ªè¿ç»­åŠ¨ä½œçš„å‘é‡ï¼Œäº¤æ˜“ç­–ç•¥å°†åœ¨æ¥ä¸‹æ¥çš„ 5 ç§’å†…ä½¿ç”¨è¿™ä¸¤ä¸ªè¶…å‚æ•°ã€‚RL ä»£ç†ä½¿ç”¨çš„ç‰¹å¾é›†æ¯”ç­–ç•¥æœ¬èº«çš„ç‰¹å¾é›†æ›´åŠ å¤šæ ·åŒ–ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªæ›´æ™ºèƒ½çš„ä»£ç†å¸®åŠ©æ›´æœºå™¨äººåŒ–çš„ä»£ç†çš„æƒ…å†µã€‚è¿™ä¸¤ä¸ªè¶…å‚æ•°çš„å€¼é¦–å…ˆæ˜¯åœ¨é€šè¿‡å›æµ‹å¯¹ç­–ç•¥è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–æœŸé—´æ‰¾åˆ°çš„ï¼ˆå› æ­¤æ­¤æ—¶è¿˜æ²¡æœ‰ RLï¼‰ï¼Œç„¶ååŠ¨ä½œå‘é‡æ˜¯ä¸€ä¸ªè¿ç»­ç©ºé—´ï¼Œå…¶ä¸­æœ€ä½³å‚æ•°ä½äºä¸­é—´ï¼Œä¾‹å¦‚ min_value = optimal_value * 0.75ï¼Œmax_value = optimal_value * 1.25ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†ä¸è®©ä»£ç†åç¦»ç­–ç•¥çš„æœ€ä½³å‚æ•°å€¼å¤ªå¤šï¼Œè€Œåªæ˜¯è®©å®ƒæ›´çµæ´»ä¸€ç‚¹ã€‚ å¥–åŠ±å‡½æ•°è®¾ç½®ä¸ºæœ€å 5 ç§’æ­¥éª¤å’Œå‰ä¸€ä¸ªæ­¥éª¤æœŸé—´ pnl å¹³å‡å€¼ä¹‹é—´çš„å˜åŒ–ã€‚è¿˜æ·»åŠ äº†ä¸€äº›æƒ©ç½šé¡¹ä»¥ä¾›å®éªŒã€‚ æˆ‘ä¸ºæ­¤ä½¿ç”¨äº† SB3ã€‚env è¢«åŒ…è£…åˆ° VecNormalize ä¸­ï¼Œaction_space ä»‹äº -1 å’Œ 1 ä¹‹é—´ï¼Œç„¶ååœ¨ç¯å¢ƒä¸­è¢«åè§„èŒƒåŒ–ã€‚ç”±äºä»£ç†æ˜¯åœ¨ä½¿ç”¨å†å²æ•°æ®çš„å›æµ‹å™¨ä¸Šè®­ç»ƒçš„ï¼Œè€Œæˆ‘åªæœ‰æœ‰é™çš„å†å²æ•°æ®ï¼Œå› æ­¤æˆ‘æŒ‰ä»¥ä¸‹æ–¹å¼è®¾ç½®è®­ç»ƒï¼š - ä½¿ç”¨ make_vec_env å’Œ SubprocVecEnv å®ä¾‹åŒ– 48ï¼ˆCPU æ•°é‡ï¼‰ä¸ªç¯å¢ƒ - å¯åŠ¨ï¼ˆæˆ–é‡ç½®ï¼‰ç¯å¢ƒæ—¶ï¼Œä»å¯ç”¨æ•°æ®ä¸­éšæœºæŒ‘é€‰ä¸€å¤©ï¼ˆé€šå¸¸æ˜¯ 10-20 å¤©çš„æ•°æ®ï¼‰ - å½“è¿™ä¸€å¤©ç”¨å°½æ—¶ï¼Œå‘æ¨¡å‹å‘é€ Truncated ä¿¡å· - ç»§ç»­æ‰§è¡Œé¢„è®¾çš„æ­¥éª¤æ•° é—®é¢˜æ˜¯æ¨¡å‹ä¼¼ä¹æ ¹æœ¬æ²¡æœ‰å­¦ä¹ ã€‚å½“æˆ‘å°†æ•°æ®é™åˆ¶ä¸º 10 å°æ—¶çš„æ•°æ®æ—¶ï¼Œå®ƒå¯ä»¥å¾ˆå¥½åœ°å­¦ä¹ ï¼ˆå¯èƒ½åªæ˜¯è¿‡åº¦æ‹Ÿåˆï¼‰ï¼Œä½†æ˜¯å½“æˆ‘å‘å®ƒæä¾› 10-20 å¤©çš„æ•°æ®å¹¶è¦æ±‚å®ƒæ‰¾åˆ°æä¾›è¶…å‚æ•°çš„æœ€ä½³ç­–ç•¥æ—¶ï¼Œå®ƒå´æ— æ³•åšåˆ°ã€‚äº‹å®æ˜¯ï¼Œå¦‚æœå®ƒå§‹ç»ˆåªæ˜¯é€‰æ‹©è¡ŒåŠ¨çš„ä¸­é—´å€¼ï¼Œå®ƒè‡³å°‘ä¼šè·å¾—è¾ƒå¤§çš„ç´¯ç§¯å¥–åŠ±ã€‚  æ‰€ä»¥æˆ‘æœ‰ä»¥ä¸‹é—®é¢˜ï¼š - è¿™æ˜¯è®¾ç½®è¿™ç§å›ºæœ‰è¿ç»­ä»»åŠ¡çš„æ­£ç¡®æ–¹æ³•å—ï¼ˆä¾‹å¦‚ä½¿ç”¨æˆªæ–­æƒ…èŠ‚ï¼‰ï¼Ÿ - PPO æ˜¯å¦æ˜¯é€‚åˆæ­¤ç±»ä»»åŠ¡çš„ç®—æ³•ï¼Ÿ - ç”±äºç¯å¢ƒä»…éƒ¨åˆ†å¯è§‚å¯Ÿï¼Œåº”è¯¥ç‰¹åˆ«æ³¨æ„å“ªäº›è¶…å‚æ•°ï¼Ÿ - ç”±äºæˆ‘ä»¬ä¸ºæ¥ä¸‹æ¥ 5 ç§’çš„äº¤æ˜“ç­–ç•¥æä¾›äº†å‚æ•°å€¼ï¼Œè€Œæ²¡æœ‰äººçŸ¥é“æ¥ä¸‹æ¥ 5 ç§’ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œæˆ‘ä»¬æ˜¯å¦åº”è¯¥æ›´ç§¯æåœ°æŠ˜æ‰£æœªæ¥çš„å¥–åŠ±ï¼Ÿ - ä½¿ç”¨ç¦»æ•£åŠ¨ä½œç©ºé—´æ˜¯å¦ä¼šè®©ä»£ç†æ›´å®¹æ˜“å­¦ä¹ æ­£ç¡®çš„ç­–ç•¥ï¼Ÿ æˆ‘ç›®å‰æ­£åœ¨å°è¯•è¾ƒå¤§çš„ n_step å€¼ï¼Œå½“ä¹˜ä»¥æ­¥æ•°æ—¶ï¼Œéœ€è¦ä¸€æ•´å¤©çš„äº¤æ˜“ï¼ˆæ€»å…±çº¦ 200K æ­¥ï¼‰å’Œæ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œè¿™æ˜¾ç¤ºå‡ºä¸€äº›æ”¹è¿›ï¼Œä½†ä»ç„¶æ²¡æœ‰å­¦ä¹ ã€‚æˆ‘å…è®¸å®ƒè®­ç»ƒ 20M æ­¥ã€‚    æäº¤äºº    /u/StabbMe   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdaof1/am_i_using_ppo_the_right_way_for_this_continuous/</guid>
      <pubDate>Sun, 27 Oct 2024 13:13:50 GMT</pubDate>
    </item>
    <item>
      <title>ä»‹ç»å°†å†›æœºå™¨äººï¼šä¸€ä¸ªå¿«èŠ‚å¥çš„æˆ˜ç•¥æ¸¸æˆç¯å¢ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gda8hj/introducing_generalsbots_a_fastpaced_strategy/</link>
      <description><![CDATA[        ç”±    /u/shrekofspeed  æäº¤  [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gda8hj/introducing_generalsbots_a_fastpaced_strategy/</guid>
      <pubDate>Sun, 27 Oct 2024 12:50:35 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘ä¸€ç›´åœ¨å°è¯•â€œSimbaï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­æ‰©å¤§å‚æ•°çš„ç®€å•åå·®â€ï¼ŒTQC å’Œè¿™ä¸ªçš„ç»“åˆçœŸæ˜¯ä¸€ä¸ªæ€ªç‰©ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gd8j5c/ive_been_trying_out_simba_simplicity_bias_for/</link>
      <description><![CDATA[      https://preview.redd.it/pay0fmh36axd1.png?width=1500&amp;format=png&amp;auto=webp&amp;s=42e8188a85ccbc51da4345f99f62a8a59b32b29a æˆ‘çœ‹åˆ°äº†å…³äºè¾›å·´çš„å¸–å­ï¼ˆé“¾æ¥) å¹¶ç«‹å³åœ¨æˆ‘ç®¡ç†çš„ç©å…·é¡¹ç›®å­˜å‚¨åº“ä¸­å®ç°å®ƒï¼Œåªéœ€åˆ‡æ¢åˆ°å®ƒå°±å¯ä»¥çœ‹åˆ°éå¸¸æ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œæœ€æ˜¾ç€çš„æ˜¯åœ¨ TQC ä¸­ã€‚å®ç°å¦‚ä¸‹ï¼šhttps://github.com/tinker495/jax-baseline çœ‹åˆ°å¦‚æ­¤ä¼˜ç§€çš„ç ”ç©¶åœ¨æˆ‘è‡ªå·±çš„ä»£ç ä¸­å¸¦æ¥çš„å¥½å¤„éå¸¸ä»¤äººå…´å¥‹ï¼Œæˆ‘æ„Ÿè°¢ SonyResearch åˆ†äº«è¿™äº›ç ”ç©¶ï¼    æäº¤äºº    /u/New_East832   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gd8j5c/ive_been_trying_out_simba_simplicity_bias_for/</guid>
      <pubDate>Sun, 27 Oct 2024 11:05:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] å¯»æ±‚é’ˆå¯¹ CVPRã€ICML ç­‰ä¼šè®®æ­£åœ¨è¿›è¡Œçš„å®Œæ•´è®ºæ–‡çš„åˆä½œã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gcjgue/r_looking_for_collaborations_on_ongoing/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘ä»¬å°ç»„ï¼Œå°åº¦ç†å·¥å­¦é™¢é²å°”åŸºåˆ†æ ¡è§†è§‰ä¸è¯­è¨€å°ç»„ï¼Œæœ€è¿‘æœ‰ä¸‰ç¯‡ç ”è®¨ä¼šè®ºæ–‡è¢« NeurIPS ç ”è®¨ä¼šæ¥å—ï¼ğŸš€ æˆ‘ä»¬è¿˜å»ºç«‹äº†ä¸€ä¸ªç½‘ç«™ ğŸ‘‰ VLGï¼Œå±•ç¤ºæˆ‘ä»¬å‚ä¸è¿‡çš„å…¶ä»–å‡ºç‰ˆç‰©ï¼Œå› æ­¤æˆ‘ä»¬çš„å›¢é˜Ÿæ­£åœ¨ç¨³æ­¥å»ºç«‹ ML å’Œ AI ç ”ç©¶ç»„åˆã€‚ç›®å‰ï¼Œæˆ‘ä»¬æ­£åœ¨åˆä½œæ’°å†™å‡ ç¯‡æ­£åœ¨è¿›è¡Œçš„è®ºæ–‡ï¼Œç›®çš„æ˜¯å‘ CVPR å’Œ ICML ç­‰é¡¶çº§ä¼šè®®æäº¤å…¨æ–‡ã€‚ è¯è™½å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜æœ‰æ›´å¤šè®©æˆ‘ä»¬å…´å¥‹çš„æƒ³æ³•ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬çš„ä¸»è¦é™åˆ¶ä¹‹ä¸€æ˜¯æ— æ³•è·å¾—é€‚å½“çš„æŒ‡å¯¼å’Œ GPU å’Œ API çš„èµ„é‡‘ï¼Œè¿™å¯¹äºè¯•éªŒå’Œæ‰©å±•æˆ‘ä»¬çš„ä¸€äº›æ¦‚å¿µè‡³å…³é‡è¦ã€‚å¦‚æœæ‚¨æˆ–æ‚¨çš„å®éªŒå®¤æœ‰å…´è¶£ä¸€èµ·å·¥ä½œï¼Œæˆ‘ä»¬å¾ˆä¹æ„æ¢ç´¢æˆ‘ä»¬æ„Ÿå…´è¶£é¢†åŸŸçš„äº¤é›†ä»¥åŠæ‚¨å¯èƒ½å¸¦æ¥çš„ä»»ä½•æ–°æƒ³æ³•ï¼ å¦‚æœæ‚¨æœ‰å¯ç”¨èµ„æºæˆ–æœ‰å…´è¶£è®¨è®ºæ½œåœ¨çš„åˆä½œï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ï¼æœŸå¾…ç€å»ºç«‹è”ç³»å¹¶å…±åŒå»ºç«‹æœ‰å½±å“åŠ›çš„ä¸œè¥¿ï¼è¿™æ˜¯æˆ‘ä»¬çš„ Open Slack çš„é“¾æ¥ğŸ‘‰ Open Slack    æäº¤äºº    /u/vlg_iitr   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gcjgue/r_looking_for_collaborations_on_ongoing/</guid>
      <pubDate>Sat, 26 Oct 2024 12:01:00 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦åé¦ˆæ¥æ”¹è¿›æˆ‘çš„ RL æ¨¡å‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gchxzd/need_feedback_to_improve_my_rl_model/</link>
      <description><![CDATA[å¤§å®¶å¥½ æˆ‘æ­£åœ¨å°è¯•è®¾ç½®ä¸€ä¸ª RL ç¯å¢ƒæ¥ä¼˜åŒ–ç”µå­é‚®ä»¶è¥é”€æ´»åŠ¨ï¼Œå…¶ä¸­å˜é‡æ˜¯ email.variantsï¼ˆ3 ç§ç±»å‹ï¼‰ã€å¯èƒ½å‘é€ç”µå­é‚®ä»¶çš„æ—¶é—´ï¼ˆ3 ç§ç±»å‹ï¼‰å’Œæ˜ŸæœŸå‡ ï¼ˆ5 ç§ç±»å‹ï¼‰ã€‚ æˆ‘æ­£åœ¨å°è¯•è®¾ç½®ç¯å¢ƒå¹¶ä½¿ç”¨åˆæˆæ•°æ®ï¼ˆå®¢æˆ·å¯¹ä¸Šè¿°å˜é‡å…·æœ‰é¢„å®šä¹‰çš„åå¥½ï¼‰ã€‚å¦‚æœé‡‡å–çš„è¡ŒåŠ¨ä¸å®¢æˆ·çš„åå¥½ç›¸åŒ¹é…ï¼Œåˆ™ä¼šå‘æ¨¡å‹æä¾›å¥–åŠ±ã€‚è¿™æ˜¯æ¨¡å‹å’Œæˆ‘é—®çš„åŒæ ·çš„é—®é¢˜åœ¨å †æ ˆæº¢å‡ºhttps://stackoverflow.com/questions/79116878/query-on-reinforcement-learning-model-not-converging æˆ‘éœ€è¦æœ‰å…³ä»¥ä¸‹æ–¹é¢çš„å»ºè®® 1. ç¯å¢ƒè®¾ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ 2. æ— è®ºä»»ä½•åˆæˆæ•°æ®æ ·æœ¬ï¼Œæ¨¡å‹ä¼¼ä¹æ€»æ˜¯æ”¶æ•›åœ¨åŒä¸€ç»„åŠ¨ä½œä¸Šã€‚ ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ 3. å…³äºå°è¯•ä¸åŒæ¨¡å‹æˆ–æ¢ç´¢ç­–ç•¥çš„ä»»ä½•å»ºè®®ã€‚    æäº¤äºº    /u/Lanky_Association_57   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gchxzd/need_feedback_to_improve_my_rl_model/</guid>
      <pubDate>Sat, 26 Oct 2024 10:18:41 GMT</pubDate>
    </item>
    <item>
      <title>éªŒè¯æˆ‘çš„ DQN å®ç°</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gchroh/validating_my_dqn_implementation/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨å°è¯•ä¸ºä¸€ä¸ªé¡¹ç›®ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ DQN ä»£ç†ï¼Œæˆ‘åœ¨ github ä¸Šæ‰¾åˆ°äº† Phil çš„ DQN å®ç°ï¼ˆhttps://github.com/philtabor/Deep-Q-Learning-Paper-To-Code/tree/master/DQNï¼‰ã€‚æˆ‘æ‰€åšçš„å”¯ä¸€æ›´æ”¹æ˜¯åœ¨ DeepQNetwork ç±»ä¸Šï¼Œå› ä¸ºæˆ‘çš„è¾“å…¥æ˜¯å‘é‡è€Œä¸æ˜¯çŸ©é˜µï¼Œæ‰€ä»¥æˆ‘åˆ é™¤äº† conv å‡½æ•°ï¼Œåªæ˜¯é€šè¿‡å±‚è½¬å‘æˆ‘çš„è¾“å…¥ã€‚ æˆ‘çš„é—®é¢˜æ˜¯ï¼š  æœ‰æ²¡æœ‰åŠæ³•ç”¨å·²ç»å­˜åœ¨çš„ç¯å¢ƒï¼ˆå¯èƒ½æ˜¯ openAIï¼‰æ¥éªŒè¯æ­¤ä»£ç ï¼Œå…¶ä¸­è§‚å¯Ÿç»“æœæ˜¯å‘é‡è€Œä¸æ˜¯çŸ©é˜µï¼Ÿ ä»£ç æœ¬èº«æ­£ç¡®å—ï¼Ÿä¾‹å¦‚ã€‚æˆ‘åœ¨ github é¡µé¢ä¸Šçœ‹åˆ°ä¸€ä¸ªå…³äºåœ¨ q_target è®¡ç®—ä¹‹å‰ä½¿ç”¨ torch.no_grad() çš„é—®é¢˜ï¼Œä½†å°šæœªè§£å†³ã€‚  ï¼ˆç¼–è¾‘ï¼‰ï¼šæˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´ä¹Ÿä½¿ç”¨ç¨³å®šçš„ epsilonï¼Œè€Œä¸æ˜¯éšç€è½®æ¬¡çš„è¿›è¡Œä¸æ–­é™ä½å®ƒã€‚æ­¤å¤–ï¼Œæ ‡é¢˜å…·æœ‰è¯¯å¯¼æ€§ï¼Œå®ƒä¸æ˜¯â€œæˆ‘çš„â€å®ç°ï¼Œè€Œæ˜¯æ¥è‡ª Phil Tabor    æäº¤äºº    /u/CrazyRabb1tStyle   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gchroh/validating_my_dqn_implementation/</guid>
      <pubDate>Sat, 26 Oct 2024 10:06:21 GMT</pubDate>
    </item>
    <item>
      <title>PPO ä¸­ç†µç³»æ•°è¡°å‡çš„æ­£ç¡®æ–¹æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gcf09f/right_way_to_decay_entropy_coeff_in_ppo/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ä½¿ç”¨ PPO è®­ç»ƒä¸€ä¸ªä¸­ç­‰å¤æ‚çš„ä»£ç†ç¯å¢ƒé—®é¢˜ã€‚æˆ‘æƒ³çŸ¥é“è¡°å‡ç†µç³»æ•°çš„æ­£ç¡®æ–¹æ³•æ˜¯ä»€ä¹ˆï¼ˆè€ƒè™‘åˆ°é—®é¢˜çš„æ€§è´¨ï¼Œå®ƒå¿…é¡»è¡°å‡ï¼‰ã€‚ æˆ‘ä½¿ç”¨çº¿æ€§è¡°å‡è¿˜æ˜¯æŒ‡æ•°è¡°å‡ï¼Ÿä¸¤è€…çš„ä¼˜ç‚¹/ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘çŸ¥é“å®ƒå®Œå…¨å–å†³äºç†µæ›²çº¿ï¼Œä½†å½“æ¶‰åŠåˆ°ç†µæ›²çº¿çš„å½¢çŠ¶æ—¶ï¼Œâ€œç»éªŒæ³•åˆ™â€æ˜¯ä»€ä¹ˆï¼Ÿå®ƒæ˜¯ä» 1 åˆ° 0.1 çš„é€æ¸çº¿æ€§ä¸‹é™å—ï¼Ÿè¿˜æ˜¯å®Œå…¨å–å†³äºé—®é¢˜å’Œ rew è¿›å±•ã€‚ å‘Šè¯‰æˆ‘ä½ çš„ç»å†ã€‚æå‰è°¢è°¢ï¼    æäº¤äºº    /u/Famous-Explanation56   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gcf09f/right_way_to_decay_entropy_coeff_in_ppo/</guid>
      <pubDate>Sat, 26 Oct 2024 06:36:37 GMT</pubDate>
    </item>
    <item>
      <title>å¯»æ±‚æŠ€å·§ï¼Œä½¿æˆ‘çš„ PPO äº¤æ˜“æœºå™¨äººä¿æŒå‡ºè‰²çš„æ€§èƒ½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gc45xu/seeking_tips_to_make_exceptional_performance/</link>
      <description><![CDATA[      å¤§å®¶å¥½ï¼Œ æˆ‘ç›®å‰æ­£åœ¨è¿è¡Œä¸€ä¸ªç»è¿‡å¹¿æ³›æµ‹è¯•çš„ PPO äº¤æ˜“æœºå™¨äºº - æ¯ä¸ªè®¾ç½®å¤§çº¦è¿è¡Œ 50 æ¬¡ã€‚æˆ‘æ³¨æ„åˆ°ï¼Œè¿™äº›æµ‹è¯•ä¸­çš„ä¸€é¡¹é€šå¸¸ä¼šä»¥å‡ºè‰²çš„è¡¨ç°è„±é¢–è€Œå‡ºï¼ˆå›æŠ¥ç‡é«˜è¾¾ 300%ï¼‰ï¼Œè€Œå…¶ä»–æµ‹è¯•çš„å›æŠ¥ç‡åˆ™å¾˜å¾Šåœ¨ +/- 50% å·¦å³ã€‚ æˆ‘æ­£åœ¨å¯»æ‰¾æ´å¯ŸåŠ›ï¼Œäº†è§£ä¸ºä»€ä¹ˆä¸€æ¬¡è¿è¡Œå¾€å¾€ä¼šè¡¨ç°å‡ºè‰²ï¼Œä»¥åŠå¦‚ä½•ä½¿è¿™ç§å‡ºè‰²çš„è¡¨ç°åœ¨æ‰€æœ‰æµ‹è¯•ä¸­æ›´åŠ ä¸€è‡´ï¼Œè€Œä¸æ˜¯å¶å°”å‡ºç°å¼‚å¸¸å€¼ã€‚æˆ‘çš„æœºå™¨äººå¯¹æ¯ä¸ªæµ‹è¯•éƒ½ä½¿ç”¨ç›¸åŒçš„å¸‚åœºæ¡ä»¶ï¼Œæ‰€ä»¥æˆ‘å¾ˆæƒ³çŸ¥é“æ˜¯å¦æœ‰äººçŸ¥é“å“ªäº›å…³é”®å› ç´ æˆ–ä¿®æ”¹å¯ä»¥å¸®åŠ©ä½¿è¿™ç§è¡Œä¸ºæˆä¸ºé»˜è®¤è¡Œä¸ºã€‚ æˆ‘ä¸€ç›´åœ¨å°è¯•å‚æ•°è°ƒæ•´å’Œè´å¶æ–¯ä¼˜åŒ–ï¼Œä½†ä»»ä½•å…¶ä»–æç¤ºéƒ½å°†ä¸èƒœæ„Ÿæ¿€ã€‚æå‰è‡´è°¢ï¼ PSï¼šä»Šå¤©ï¼Œæˆ‘ç”šè‡³åœ¨æ³›åŒ–æµ‹è¯•ä¸­è¾¾åˆ°äº†+1738ï¼…çš„å›æŠ¥ã€‚ https://preview.redd.it/oiemun1crywd1.png?width=3840&amp;format=png&amp;auto=webp&amp;s=1a585f07c9c604c1a54c431bba938f1f6a47333f    æäº¤äºº    /u/nalman1   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gc45xu/seeking_tips_to_make_exceptional_performance/</guid>
      <pubDate>Fri, 25 Oct 2024 20:39:13 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ SAC ç›¸æ¯”ï¼ŒPPO é‡‡å–çš„è¡ŒåŠ¨èŒƒå›´æ›´é«˜ã€‚ä¸ºä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gc2z6y/ppo_takes_upper_range_of_actions_compared_to_sac/</link>
      <description><![CDATA[      æˆ‘æœ‰ä¸€ä¸ªè¡¥æ–™åˆ†æ‰¹å‘é…µæ¨¡æ‹Ÿï¼ˆæˆ–æ¸¸æˆï¼‰ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•è¿›è¡Œæ§åˆ¶ã€‚æ§åˆ¶å‚æ•°æ˜¯è¿›æ–™é‡ï¼ˆåŠ¨ä½œç©ºé—´ï¼‰ï¼ŒèŒƒå›´ä» 0 åˆ° 0.1ï¼Œè€Œè§‚å¯Ÿç©ºé—´åŒ…æ‹¬æ—¶é—´æ­¥é•¿å’Œäº§å“æµ“åº¦ã€‚æˆ‘ä½¿ç”¨ Stable Baselines 3 å°†ä¸åŒçš„ RL ç®—æ³•åº”ç”¨äºæ­¤è‡ªå®šä¹‰å‘é…µç¯å¢ƒã€‚ç›®æ ‡æ˜¯ä¼˜åŒ–è¿›æ–™ï¼ˆ0 - 0.1ï¼‰ä»¥æœ€å¤§åŒ–äº§å“äº§é‡ã€‚ å½“æˆ‘ä½¿ç”¨ PPO æ—¶ï¼Œæˆ‘æ³¨æ„åˆ°å®ƒå€¾å‘äºæ”¯æŒåŠ¨ä½œç©ºé—´çš„ä¸Šé™ï¼Œé€šå¸¸é€‰æ‹© 0.1ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒSAC çš„è¡Œä¸ºä¸åŒï¼Œé€šå¸¸é€‰æ‹©æ›´æ¥è¿‘ä¸‹é™çš„å€¼ï¼Œä¾‹å¦‚ 0.01 æˆ– 0.02ï¼Œå¹¶åœ¨æƒ…èŠ‚ç»“æŸæ—¶é€æ¸å°†åŠ¨ä½œå¢åŠ åˆ°æ›´é«˜çš„å€¼ï¼Œä¾‹å¦‚ ~0.1ã€‚ è¿™ä¸¤ç§è¡Œä¸ºéƒ½å¯èƒ½æœ‰æ•ˆï¼Œä½†æˆ‘å¾ˆå¥½å¥‡ä¸ºä»€ä¹ˆè¿™ä¸¤ç§ç®—æ³•ä»¥ä¸åŒçš„æ–¹å¼è§£å†³é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å› ä¸ºå®ƒä»¬ä»ä¸åŒçš„åŠ¨ä½œç©ºé—´å€¼å¼€å§‹ã€‚å…³äºè®­ç»ƒç¨³å®šæ€§ï¼Œæˆ‘æ³¨æ„åˆ° PPO åœ¨æœ€ç»ˆå¥–åŠ±ä¸­æ³¢åŠ¨æ›´å¤§ï¼Œè€Œ SAC æ›´ç¨³å®šï¼Œå³ä½¿åœ¨é¢„æµ‹æœŸé—´ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ å¦‚ä½•è§£é‡Šè¿™äº›å·®å¼‚ï¼Ÿ  PPO SAC    æäº¤äºº    /u/Fr4gg3r_   [link] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gc2z6y/ppo_takes_upper_range_of_actions_compared_to_sac/</guid>
      <pubDate>Fri, 25 Oct 2024 19:47:42 GMT</pubDate>
    </item>
    <item>
      <title>[å¯»æ±‚ DeepRL å¯¼å¸ˆï¼ˆåšå£«ï¼‰]</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gc0hz7/looking_for_mentoring_in_deeprl_phd/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œ æˆ‘æ­£åœ¨å¯»æ‰¾ä¸€ä½å¯¼å¸ˆæ¥æŒ‡å¯¼æˆ‘å®Œæˆæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åšå£«é¡¹ç›®ï¼Œæœ€å¥½æ˜¯åœ¨ MentorCruise è¿™æ ·çš„å¹³å°ä¸Šã€‚ è°¢è°¢ï¼    æäº¤äºº    /u/TeamTop4542   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gc0hz7/looking_for_mentoring_in_deeprl_phd/</guid>
      <pubDate>Fri, 25 Oct 2024 17:59:47 GMT</pubDate>
    </item>
    <item>
      <title>å¸®åŠ©è¿™ä½ PPO åˆå­¦è€…</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gbpp0j/help_this_beginner_for_ppo/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä»äº‹ä¸€ä¸ªä»»åŠ¡åˆ†é…é¡¹ç›®ã€‚æˆ‘çš„ PPO æ²¡æœ‰å­¦ä¹ ï¼›å°±åƒä»è¾ƒå¤§çš„è´Ÿå€¼å¼€å§‹ï¼Œåœ¨ 500 é›†å†…è¾¾åˆ°æœ€å°å€¼å¹¶åœ¨è¯¥åŒºåŸŸæŒ¯è¡ã€‚æˆ‘ä¸çŸ¥é“å¯èƒ½æ˜¯ä»€ä¹ˆé—®é¢˜ã€‚æˆ‘éœ€è¦åšäº›ä»€ä¹ˆæ‰èƒ½æ›´å¥½åœ°å­¦ä¹ ï¼    æäº¤äºº    /u/Different_Prune_9756   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gbpp0j/help_this_beginner_for_ppo/</guid>
      <pubDate>Fri, 25 Oct 2024 08:48:15 GMT</pubDate>
    </item>
    <item>
      <title>Decision Transformer å­¦ä¹ ä¸æ­£ç¡®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gbntqe/decision_transformer_not_learning_properly/</link>
      <description><![CDATA[å—¨ï¼Œå¦‚æœèƒ½å¾—åˆ°ä¸€äº›å¸®åŠ©ï¼Œè®©æˆ‘çš„å†³ç­–è½¬æ¢å™¨èƒ½å¤Ÿç”¨äºç¦»çº¿å­¦ä¹ ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚ æˆ‘æ­£åœ¨å°è¯•å¯¹å¤šå‘¨æœŸæ··åˆé—®é¢˜è¿›è¡Œå»ºæ¨¡ï¼Œä¸ºæ­¤æˆ‘åˆ›å»ºäº†ä¸€ä¸ªè‡ªå®šä¹‰ç¯å¢ƒã€‚æˆ‘æœ‰ä¸€ä¸ªä»çº¿æ€§æ±‚è§£å™¨è·å¾—çš„ 60k ä¸ªçŠ¶æ€/åŠ¨ä½œå¯¹çš„æ•°æ®é›†ã€‚æˆ‘æ­£å°è¯•åœ¨æ•°æ®ä¸Šè®­ç»ƒ DTï¼Œä½†è®­ç»ƒé€Ÿåº¦ææ…¢ï¼ŒæŸå¤±ä»…ç•¥æœ‰å‡å°‘ã€‚ æˆ‘è®¤ä¸ºæˆ‘çš„ç¯å¢ƒå¹¶ä¸æ˜¯ç‰¹åˆ«å›°éš¾ï¼Œè€Œä¸”æˆ‘åœ¨ç®€å•çš„ç¯å¢ƒä¸­ä½¿ç”¨ PPO è·å¾—äº†ä¸€äº›ä¸é”™çš„ç»“æœã€‚ æœ‰å…³æ›´å¤šä¸Šä¸‹æ–‡ï¼Œè¿™æ˜¯æˆ‘çš„ repoï¼šhttps://github.com/adamelyoumi/BlendingRLï¼›æˆ‘åœ¨ DT å­˜å‚¨åº“ä¸­ä½¿ç”¨ä¿®æ”¹ç‰ˆçš„ experiment.pyã€‚ è°¢è°¢    æäº¤äºº    /u/cheese_n_potato   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gbntqe/decision_transformer_not_learning_properly/</guid>
      <pubDate>Fri, 25 Oct 2024 06:24:15 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ çš„å®è·µ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gb6efv/working_rl_in_practice/</link>
      <description><![CDATA[æˆ‘çŸ¥é“ RL åœ¨å®è·µä¸­å¾ˆè„†å¼±ï¼Œå¾ˆéš¾å‘æŒ¥ä½œç”¨ï¼Œä½†å¦‚æœåšå¾—å¥½ï¼Œå®ƒä¹Ÿä¼šéå¸¸å¼ºå¤§ï¼Œä¾‹å¦‚ Deepmind ä¸ AlphaZero åˆä½œç­‰ã€‚ä½ çŸ¥é“åœ¨ç°å®ç”Ÿæ´»ä¸­åº”ç”¨ RL çš„ä»»ä½•ä»¤äººä¿¡æœçš„ä¾‹å­å—ï¼Ÿè®©ä½ å¿ƒå­˜ç–‘è™‘çš„ä¸œè¥¿ï¼Ÿ    æäº¤äºº    /u/FriendlyStandard5985   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gb6efv/working_rl_in_practice/</guid>
      <pubDate>Thu, 24 Oct 2024 16:11:51 GMT</pubDate>
    </item>
    </channel>
</rss>