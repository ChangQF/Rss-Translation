<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 10 Jul 2024 03:18:13 GMT</lastBuildDate>
    <item>
      <title>å¯¹æ—©æœŸé‡‡ç”¨è€…çš„å»ºè®®ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dzkmvx/advice_for_an_early_adopter/</link>
      <description><![CDATA[æˆ‘ä»äº‹çš„æ˜¯ä¸€ä¸ªå°ä¼—é¢†åŸŸï¼Œè¯¥é¢†åŸŸæœ‰å‡ ç¯‡è®ºæ–‡åœ¨ RL ä¸­ä½¿ç”¨äº† MDPã€‚æˆ‘æˆ–å¤šæˆ–å°‘åˆ›å»ºäº†è‡ªå·±çš„ç¯å¢ƒï¼Œå¹¶ä½¿ç”¨äº†ç›¸åŒçš„åº“æ¥å¤„ç† RL ä»£ç†ï¼Œå¹¶å¤åˆ¶äº†æœ€æ–°å‡ºç‰ˆç‰©çš„å·¥ä½œã€‚ æˆ‘çš„ç›®æ ‡æ˜¯è®©è‡ªå·±èƒ½å¤Ÿåœ¨è¿™ç§ç¯å¢ƒä¸­åº”ç”¨æ–°ç®—æ³•å¹¶æ‰©å±•å…¶å¤æ‚æ€§ï¼šåœ¨æŸä¸ªæœ‰å¿èŒä½ä¸Šï¼ˆæ€€ç–‘å®ƒæ˜¯å¦å·²è¢«è¡Œä¸šæ¥å—ï¼‰ã€‚ æˆ‘çš„è®¡åˆ’æ˜¯æ’°å†™å¤§é‡å°åšå®¢æ–‡ç« ï¼ˆæˆ‘ä¸æ˜¯å­¦è€…ï¼‰ï¼Œä½¿ç”¨ PPO ä»£ç†å¯¹è®­ç»ƒåŠ¨æ€/è¶…å‚æ•°ç©ºé—´è¿›è¡Œè‰¯å¥½çš„å¯è§†åŒ–ï¼Œä»è€Œå»ºç«‹å’Œå›ç­”åŸºæœ¬é—®é¢˜ã€‚ç„¶åè½°ç‚¸ä¸€äº›å­¦æœ¯å®éªŒå®¤ä»¥è·å¾— SWE /æ•°æ®ç§‘å­¦èŒä½ã€‚ ä»»ä½•å»ºè®®ï¼Œä¾‹å¦‚ï¼Œå¯¹äºæ–°çš„åº”ç”¨é¢†åŸŸï¼Œåº”è¯¥ä»”ç»†ç ”ç©¶ RL çš„å“ªäº›æ˜¾è€Œæ˜“è§çš„äº‹æƒ…ï¼ˆé™¤äº†å¢åŠ ç¯å¢ƒçš„å¤æ‚æ€§æˆ–è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼‰ï¼Œæˆ–è€…æ˜¯å¦æœ‰ä»»ä½•è·¯çº¿å›¾/æ—¶é—´è¡¨/æ€»ç»“å¯¹äºå…¶ä¸­æœ‰å¾ˆå¤š RL çš„æˆç†Ÿé¢†åŸŸï¼ˆå…³äºåº”ç”¨ RL çš„å¥½è¯»ç‰©ï¼‰    æäº¤äºº    /u/timbercrisis   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dzkmvx/advice_for_an_early_adopter/</guid>
      <pubDate>Wed, 10 Jul 2024 02:27:13 GMT</pubDate>
    </item>
    <item>
      <title>Craftiumï¼šç”¨äºåˆ›å»ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„å¯æ‰©å±•æ¡†æ¶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz9bp5/craftium_an_extensible_framework_for_creating/</link>
      <description><![CDATA[å—¨ï¼æˆ‘ä¸€ç›´åœ¨å¼€å‘ Craftiumï¼šä¸€ä¸ªæ˜“äºä½¿ç”¨çš„ RL ç¯å¢ƒåˆ›å»ºæ¡†æ¶ã€‚Craftium å°†å¼€æºä½“ç´ æ¸¸æˆå¼•æ“ Minetest åŒ…è£…åœ¨ä¸€ä¸ªå®ç° Gymnasium API çš„ Python åº“ä¸­ã€‚è™½ç„¶ Craftium æ—¨åœ¨ç”¨äºç¯å¢ƒåˆ›å»ºï¼Œä½†æˆ‘ä»¬ä¹ŸåŒ…å«äº†ä¸€äº›ç°æˆçš„ç¯å¢ƒå’Œä»»åŠ¡ï¼ˆè¯·åœ¨æ­¤å¤„ æŸ¥çœ‹ï¼‰ã€‚ç›®å‰ï¼ŒCraftium å¤„äºæ—©æœŸå¼€å‘é˜¶æ®µï¼Œä½†å·²å‡†å¤‡å¥½ä½¿ç”¨å’Œæµ‹è¯•ã€‚å¸Œæœ›æ‚¨è§‰å¾—å®ƒå¾ˆæœ‰è¶£ï¼æ¬¢è¿æä¾›åé¦ˆï¼ï¼    ç”±    /u/mikelma æäº¤   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz9bp5/craftium_an_extensible_framework_for_creating/</guid>
      <pubDate>Tue, 09 Jul 2024 18:12:24 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ Stable_Baselines3 ä¸­é‡ç½®åè®°å½•è§‚å¯Ÿç»“æœï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz885r/how_do_i_log_observations_after_reset_in_stable/</link>
      <description><![CDATA[æˆ‘æƒ³åœ¨ä½¿ç”¨ SB3 æ—¶ï¼Œè®°å½•è®­ç»ƒæœŸé—´`é‡ç½®`åè·å¾—çš„æ¯ä¸ª`è§‚å¯Ÿ`ã€‚ æ ¹æ® [this][1] é—®é¢˜æ¶ˆæ¯ï¼Œæˆ‘â€‹â€‹å†³å®šä½¿ç”¨`Monitor`åŒ…è£…å™¨è€Œä¸æ˜¯å›è°ƒã€‚ ä½†æ˜¯ï¼Œç›‘è§†å™¨åŒ…è£…å™¨ç»™äº†æˆ‘ä»¥ä¸‹é”™è¯¯ -  è¿™æ˜¯æˆ‘çš„ä»£ç  - ```py import gym from stable_baselines3 import PPO from stable_baselines3.common.callbacks import BaseCallback from stable_baselines3.common.monitor import Monitor class CustomMonitor(Monitor): def __init__(self, env, filename=None, allow_early_resets=True, reset_keywords=(), info_keywords=()): super(CustomMonitor, self).__init__(env) self.reset_observations = [] def reset(self, **kwargs): observer = super(CustomMonitor, self).reset(**kwargs) self.reset_observations.append(observation) return observer env = gym.make(&#39;LunarLander-v2&#39;) env = CustomMonitor(env) model = PPO(&#39;MlpPolicy&#39;, env, verbose=1) model.learn(total_timesteps=1000000) model.save(&quot;ppo_lunarlander_mutant&quot;)  ``` ä½†æ˜¯ï¼Œè¿è¡Œå®ƒä¹‹åï¼Œæˆ‘æ”¶åˆ°ä»¥ä¸‹é”™è¯¯ - ``` Traceback (most recent call last): File &quot;minimal_example.py&quot;, line 21, in &lt;module&gt;æ¨¡å‹ = PPOï¼ˆ&#39;MlpPolicy&#39;ï¼Œenvï¼Œverbose = 1ï¼‰æ–‡ä»¶â€œ/home/thoma/anaconda3/envs/wp/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.pyâ€ï¼Œç¬¬ 109 è¡Œï¼Œåœ¨ __init__ superï¼ˆï¼‰ã€‚__init__ï¼ˆæ–‡ä»¶â€œ/home/thoma/anaconda3/envs/wp/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.pyâ€ï¼Œç¬¬ 85 è¡Œï¼Œåœ¨ __init__ superï¼ˆï¼‰ã€‚__init__ï¼ˆæ–‡ä»¶â€œ/home/thoma/anaconda3/envs/wp/lib/python3.8/site-packages/stable_baselines3/common/base_class.pyâ€ï¼Œç¬¬ 180 è¡Œï¼Œåœ¨ __init__ æ–­è¨€ isinstanceï¼ˆself.action_spaceï¼Œ supports_action_spaces), ( AssertionError: è¯¥ç®—æ³•ä»…æ”¯æŒ (&lt;class &#39;gymnasium.spaces.box.Box&#39;&gt;, &lt;class &#39;gymnasium.spaces.discrete.Discrete&#39;&gt;, &lt;class &#39;gymnasium.spaces.multi_discrete.MultiDiscrete&#39;&gt;, &lt;class &#39;gymnasium.spaces.multi_binary.MultiBinary&#39;&gt;) ä½œä¸ºåŠ¨ä½œç©ºé—´ï¼Œä½†æä¾›äº† Discrete(4)  ``` [1]: https://github.com/DLR-RM/stable-baselines3/issues/137#issuecomment-669862467    ç”±   æäº¤  /u/Academic-Rent7800   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz885r/how_do_i_log_observations_after_reset_in_stable/</guid>
      <pubDate>Tue, 09 Jul 2024 17:27:41 GMT</pubDate>
    </item>
    <item>
      <title>â€œè®¤çŸ¥æ ¡å‡†å’Œå¯»æ‰¾çœŸç›¸ç©ºé—´â€ï¼ŒLinus Leeï¼ˆåå¥½è°ƒæ•´å›¾åƒç”Ÿæˆå™¨æ¨¡å‹ä¸­çš„æ¨¡å¼å´©æºƒ - DALL-E 3 ä¸ 2 çš„æ— èŠä¹‹å¤„ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz5sbs/epistemic_calibration_and_searching_the_space_of/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz5sbs/epistemic_calibration_and_searching_the_space_of/</guid>
      <pubDate>Tue, 09 Jul 2024 15:49:18 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ RL ç”Ÿæˆè·¯å¾„</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz4mcu/path_generation_using_rl/</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨å°è¯•è®­ç»ƒä¸€ä¸ª RL æ¨¡å‹ï¼Œè¿™æ ·ç»™å®šä¸€ä¸ª 3D ç©ºé—´ä¸­çš„ç›®æ ‡å’Œä¸€ä¸ªåˆå§‹èµ·å§‹ä½ç½®ï¼Œå°±ä¼šé‡‡å–å°æ­¥éª¤æ¥è¾¾åˆ°ç›®æ ‡â€‹â€‹ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šå°±åƒä»åˆå§‹ä½ç½®åˆ°æœ€ç»ˆä½ç½®çš„è·¯å¾„ç”Ÿæˆã€‚æˆ‘ä¸€ç›´åœ¨ä½¿ç”¨ç¨³å®šçš„åŸºçº¿ 3 å’Œå¥èº«æˆ¿ã€‚åŠ¨ä½œç©ºé—´æ˜¯è¿ç»­çš„ï¼Œåœ¨ xã€y å’Œ z æ–¹å‘ä¸Šä» -1 åˆ° 1ã€‚è§‚å¯Ÿç©ºé—´ä¹Ÿæ˜¯è¿ç»­çš„ï¼Œåœ¨ xã€y å’Œ z æ–¹å‘ä¸Šä» -10 åˆ° 10ã€‚æˆ‘ç»™å‡ºçš„å¥–åŠ±è¦ä¹ˆæ˜¯å¯†é›†å¥–åŠ±ï¼Œè¿™å–å†³äºä»å½“å‰ä½ç½®åˆ°ç›®æ ‡çš„è·ç¦»ï¼Œè¦ä¹ˆæ˜¯ç¨€ç–å¥–åŠ±ï¼ˆå¦‚æœåˆ°ç›®æ ‡çš„è·ç¦»å¤§äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™ä¸º -1ï¼Œå¦åˆ™å¥–åŠ±ä¸º 0ï¼‰ã€‚ æˆ‘å°è¯•äº†å„ç§æƒ…èŠ‚é•¿åº¦å’Œæ­¥é•¿ã€‚æˆ‘é—æ¼äº†ä»€ä¹ˆæˆ–åšé”™äº†ä»€ä¹ˆå—ï¼Ÿ    æäº¤äºº    /u/Necessary-Cabinet-43   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz4mcu/path_generation_using_rl/</guid>
      <pubDate>Tue, 09 Jul 2024 15:02:16 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•è®­ç»ƒç›¸åŒçš„ RL ä»£ç†ï¼ˆå…·æœ‰å•ç‹¬çš„ç­–ç•¥ï¼‰ä»¥åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­ä¼ é€’ä¿¡æ¯ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz33aa/how_to_train_identical_rl_agents_with_individual/</link>
      <description><![CDATA[ä½ å¥½ æˆ‘æ­£åœ¨ StabeBaseline3 ä¸­ä½¿ç”¨ SAC è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå®ƒå¯¹äºå•ä¸ªä»£ç†æ¥è¯´è¿è¡Œè‰¯å¥½ã€‚ç°åœ¨ï¼Œæˆ‘æƒ³è®­ç»ƒå¤šä¸ªç›¸åŒçš„ä»£ç†ï¼ˆä½¿ç”¨å®ƒä»¬è‡ªå·±çš„å•ç‹¬ç­–ç•¥ï¼‰ï¼Œä»¥ä¾¿æ¯ä¸ªä»£ç†çš„æ“ä½œéƒ½ç”¨äºä¸ºæ‰€æœ‰ä»£ç†ç”Ÿæˆæ–°çš„è§‚å¯Ÿç»“æœã€‚ ä½ èƒ½å»ºè®®æˆ‘ä¸€äº›å¯ä»¥å¸®åŠ©æˆ‘å®Œæˆæ­¤æ“ä½œçš„åº“å—ï¼Ÿä¸€ä¸ªå°å‹çš„å·¥ä½œç¤ºä¾‹å°†æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚æˆ‘çœ‹è¿‡ RLIB (ray)ï¼Œä½†ä»ç„¶ä¸çŸ¥é“å¦‚ä½•åœ¨å…¶ä¸­ä½¿ç”¨ stablebaseline3ã€‚ è°¢è°¢    æäº¤äºº    /u/Previous-Advance-921   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz33aa/how_to_train_identical_rl_agents_with_individual/</guid>
      <pubDate>Tue, 09 Jul 2024 13:58:04 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨ Sigmoidï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz1xbn/why_isnt_sigmoid_used/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨ Unity åœ¨ C# ä¸­ä»å¤´å¼€å§‹åˆ¶ä½œä¸€ä¸ªç®€å•çš„ç­–ç•¥æ¢¯åº¦å­¦ä¹ ç®—æ³•ï¼Œæ²¡æœ‰åº“ï¼Œæˆ‘æƒ³çŸ¥é“ä¸ºä»€ä¹ˆæ²¡æœ‰äººä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¸­çš„ sigmoid å‡½æ•°ä½œä¸ºè¾“å‡º ä¸€åˆ‡éƒ½å¯ä»¥åœ¨ç½‘ä¸Šæ‰¾åˆ°ï¼Œæ¯ä¸ªäººéƒ½ä½¿ç”¨ softmax å‡½æ•°æ¥è¾“å‡ºä»£ç†å¯ä»¥é‡‡å–çš„åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åä»–ä»¬éšæœºï¼ˆåå‘æ›´é«˜çš„åŠ¨ä½œï¼‰é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œï¼Œä½†è¿™ç§æ–¹æ³•åªå…è®¸ä»£ç†åœ¨æ¯ä¸ªçŠ¶æ€ä¸‹æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œï¼Œä¾‹å¦‚ã€‚å®ƒæ—¢å¯ä»¥å‘å‰ç§»åŠ¨ï¼Œä¹Ÿå¯ä»¥å°„å‡»ï¼Œä½†æˆ‘ä¸èƒ½åŒæ—¶åšè¿™ä¸¤ä»¶äº‹ï¼Œæˆ‘çŸ¥é“æœ‰æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå³ä¸ºä»£ç†å¯ä»¥é‡‡å–çš„æ¯ç»„åŠ¨ä½œåˆ¶ä½œå¤šä¸ªè¾“å‡ºå±‚ï¼Œä½†æˆ‘æƒ³çŸ¥é“ä½ æ˜¯å¦ä¹Ÿå¯ä»¥æœ‰ä¸€ä¸ªæ˜ å°„åˆ°åŠ¨ä½œçš„ S å½¢è¾“å‡ºå±‚  æ¯”å¦‚å¦‚æœæˆ‘è®©ä¸€ä¸ªä»£ç†å­¦ä¹ èµ°è·¯å’Œå°„å‡»æ•Œäººï¼Œä½¿ç”¨è½¯æœ€å¤§å€¼ï¼Œä½ ä¼šæœ‰ä¸€ä¸ªç”¨äºèµ°è·¯çš„è¾“å‡ºå±‚å’Œä¸€ä¸ªç”¨äºå°„å‡»çš„è¾“å‡ºå±‚ï¼Œä½†ä½¿ç”¨ S å½¢ï¼Œä½ åªéœ€è¦ä¸€ä¸ªè¾“å‡ºå±‚ï¼Œå…¶ä¸­ 5 ä¸ªç¥ç»å…ƒæ˜ å°„åˆ° 4 ä¸ªæ–¹å‘çš„ç§»åŠ¨å’Œå°„å‡»ï¼Œè¿™å–å†³äºç¥ç»å…ƒè¾“å‡ºçš„å€¼æ˜¯å¦å¤§äº 0.5 TLDRï¼šè€Œä¸æ˜¯ä½¿ç”¨è½¯æœ€å¤§å€¼å‡½æ•°å±‚æˆ–å¤šå±‚ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå¤§çš„å±‚ï¼Œå…¶ä¸­ S å½¢å‡½æ•°æ˜ å°„åˆ°åŸºäºå€¼æ˜¯å¦å¤§äº 0.5 çš„åŠ¨ä½œ    æäº¤äºº    /u/DaMrStick   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz1xbn/why_isnt_sigmoid_used/</guid>
      <pubDate>Tue, 09 Jul 2024 13:05:37 GMT</pubDate>
    </item>
    <item>
      <title>æ¥è‡ªæ·±åº¦è§†é¢‘é¦ˆé€çš„ç«¯åˆ°ç«¯æ§åˆ¶ç½‘ç»œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dz1hs0/end_to_end_control_network_from_depth_video_feed/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åˆ›å»ºä¸€ä¸ªç½‘ç»œï¼Œè¯¥ç½‘ç»œä½¿ç”¨é»‘ç™½å›¾åƒï¼ˆæ·±åº¦å›¾ï¼‰ä»¥åŠåŸºæœ¬æƒ¯æ€§æµ‹é‡ï¼ˆé€Ÿåº¦ã€å§¿æ€ï¼‰æ¥è‡ªä¸»æ§åˆ¶å››è½´é£è¡Œå™¨å¹¶å…·æœ‰é¿éšœèƒ½åŠ›ã€‚æ‹Ÿè®®çš„ç½‘ç»œå°†è¾“å‡ºèº«ä½“é€Ÿç‡å‘½ä»¤ï¼Œè¿™äº›å‘½ä»¤å°†è¢«é¦ˆé€åˆ°ä½çº§ PID æ§åˆ¶å™¨ã€‚ è¿™æœ‰å¤šå¯è¡Œï¼Ÿæœ‰æ²¡æœ‰è¿™ç§ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆåœ¨ç°å®ä¸–ç•Œä¸­æˆåŠŸçš„ä¾‹å­ï¼Ÿï¼ˆä¸é™äºæ— äººæœºï¼‰ é€šå¸¸ï¼Œæˆ‘ä»¬é¦–å…ˆåšä¸€äº›åƒ SLAM å’Œ VIO è¿™æ ·çš„æ“ä½œæ¥è¿›è¡Œå®šä½å’ŒçŠ¶æ€ä¼°è®¡ï¼Œç„¶åæˆ‘ä»¬å¿…é¡»åˆ¶å®šä¸€ä¸ªè§„åˆ’ç®—æ³•ï¼Œç„¶åæˆ‘ä»¬æ‰èƒ½æœ‰ä¸€ä¸ªçœŸæ­£å‘å‡ºèº«ä½“é€Ÿç‡å‘½ä»¤çš„ç¥ç»ç½‘ç»œæ§åˆ¶å™¨ï¼Œè¿™å¬èµ·æ¥åƒæ˜¯ä¸€å †ä¸å¿…è¦çš„æŠ½è±¡ + å·¥ä½œã€‚ æˆ‘éå¸¸å¥½å¥‡æˆ‘æ˜¯å¦å‘ç°äº†ä»€ä¹ˆï¼Œæˆ‘åº”è¯¥å®ç°å®ƒğŸ˜…   ç”±    /u/FutureComedian7749  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dz1hs0/end_to_end_control_network_from_depth_video_feed/</guid>
      <pubDate>Tue, 09 Jul 2024 12:45:40 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆä¸ç¦»ç­–ç•¥ç®—æ³•ç›¸æ¯”ï¼ŒçŠ¶æ€è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼ˆé€šè¿‡è¾…åŠ©æŸå¤±ï¼‰è¾ƒå°‘åº”ç”¨äº PPO ç­‰åœ¨çº¿ç­–ç•¥ RL ç®—æ³•ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyzi9z/why_are_state_representation_learning_methods_via/</link>
      <description><![CDATA[æˆ‘å·²ç»çœ‹åˆ°äº†ä¸åŒçš„çŠ¶æ€è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼ˆé€šè¿‡è¾…åŠ©æŸå¤±ï¼Œæ— è®ºæ˜¯è‡ªæˆ‘é¢„æµ‹è¿˜æ˜¯åŸºäºç»“æ„åŒ–æ¢ç´¢ï¼‰ï¼Œå®ƒä»¬å·²ç»ä¸ç¦»çº¿ç­–ç•¥æ–¹æ³•ï¼ˆå¦‚ DQNã€Rainbowã€SAC ç­‰ï¼‰ä¸€èµ·åº”ç”¨ã€‚ä¾‹å¦‚ï¼ŒSPRï¼ˆè‡ªæˆ‘é¢„æµ‹è¡¨å¾ï¼‰å·²ä¸ Rainbow ä¸€èµ·ä½¿ç”¨ï¼ŒCURLï¼ˆå¼ºåŒ–å­¦ä¹ çš„å¯¹æ¯”æ— ç›‘ç£è¡¨å¾ï¼‰å·²ä¸ DQNã€Rainbow å’Œ SAC ä¸€èµ·ä½¿ç”¨ï¼Œä»¥åŠRA-LapRepï¼ˆé€šè¿‡æ‹‰æ™®æ‹‰æ–¯è¡¨å¾è¿›è¡Œè¡¨å¾å­¦ä¹ ï¼‰å·²ä¸ DDPG å’Œ DQN ä¸€èµ·ä½¿ç”¨ã€‚æˆ‘å¾ˆå¥½å¥‡ä¸ºä»€ä¹ˆè¿™äº›æ–¹æ³•æ²¡æœ‰åƒ PPOï¼ˆè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰è¿™æ ·çš„åœ¨çº¿ç­–ç•¥ç®—æ³•å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚å°†è¿™äº›è¡¨ç¤ºå­¦ä¹ æŠ€æœ¯ä¸åœ¨çº¿ç­–ç•¥ç®—æ³•å­¦ä¹ ç›¸ç»“åˆæ˜¯å¦å­˜åœ¨ç†è®ºé—®é¢˜ï¼Ÿ    æäº¤äºº    /u/C7501   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyzi9z/why_are_state_representation_learning_methods_via/</guid>
      <pubDate>Tue, 09 Jul 2024 10:56:37 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰æ²¡æœ‰ä»»ä½•å…·æœ‰éšæœºæ€§çš„ç¦»çº¿ RL åŸºå‡†ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyyr7j/any_benchmark_for_offline_rl_with_stochasticity/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶é£é™©æ•æ„Ÿçš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼Œå‘ç°è®¸å¤šä¼—æ‰€å‘¨çŸ¥çš„åŸºå‡†å¹¶ä¸åˆé€‚ï¼Œå› ä¸ºå®ƒä»¬ç¼ºä¹éšæœºæ€§ã€‚Mujoco ç¯å¢ƒå‡ ä¹æ˜¯ç¡®å®šæ€§çš„ï¼›å®ƒä»¬çš„å†…éƒ¨ä»£ç ä¸åŒ…å«ä»»ä½•éšæœºæ€§ï¼Œé™¤äº†åœ¨â€œé‡ç½®â€æœŸé—´é˜¶æ®µã€‚ [å‚è§ï¼šhttps://arxiv.org/abs/2205.15967\]  æˆ‘å‘ç° NeoRL ä¹Ÿæ˜¯å¦‚æ­¤ [https://arxiv.org/abs/2102.00714.\] æ‚¨å¯ä»¥è½»æ¾éªŒè¯è¿è¡Œ TD3PlusBC æ—¶æ²¡æœ‰å·®å¼‚ã€‚ é‚£ä¹ˆï¼Œæœ‰é’ˆå¯¹å…·æœ‰éšæœºæ€§çš„ç¦»çº¿ RL çš„åŸºå‡†å—ï¼Ÿ    æäº¤äºº    /u/korsyoo   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyyr7j/any_benchmark_for_offline_rl_with_stochasticity/</guid>
      <pubDate>Tue, 09 Jul 2024 10:09:56 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ä»£ç†æ²¡æœ‰é‡‡å–ç°å®è¡ŒåŠ¨</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyxh40/reinforcement_learning_agent_not_taking_realistic/</link>
      <description><![CDATA[æˆ‘åœ¨ Simulink ç¯å¢ƒä¸­ä½¿ç”¨ PPO ä»£ç†ï¼Œä½†ä»£ç†äº§ç”Ÿçš„æ“ä½œä¼¼ä¹æ˜¯ç¦»æ•£çš„ã€‚å…·ä½“æ¥è¯´ï¼Œä»£ç†ä»…è¾“å‡ºä¸Šé™æˆ–ä¸‹é™ã€‚æ‚¨çŸ¥é“ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µå—ï¼Ÿæˆ‘ä½¿ç”¨ RL Toolbox è¿›è¡Œè®­ç»ƒã€‚ä»¥ä¸‹æ˜¯æœ‰å…³æˆ‘çš„è®¾ç½®çš„ä¸€äº›è¯¦ç»†ä¿¡æ¯ï¼š  æˆ‘ä½¿ç”¨å¸¦æœ‰ ode23t æ±‚è§£å™¨çš„å¯å˜æ­¥é•¿æ—¶é—´ Simulink æ¨¡å‹ã€‚ æˆ‘çš„ Simulink æ¨¡å‹ä½¿ç”¨ Simscape çƒ­æµä½“åº“å¹¶æ¨¡æ‹Ÿç®€åŒ–çš„åŒºåŸŸä¾›çƒ­ç½‘ç»œã€‚DHN æœ‰ 2 ä¸ªåˆ†æ”¯ï¼šåŒ— (NORD) å’Œå— (SUD)ã€‚ æˆ‘å°è¯•ä½¿ç”¨ RL ä»£ç†æ¥ä¼˜åŒ–æ§åˆ¶ï¼Œæœ€åˆä¸“æ³¨äºé€šè¿‡æ›´æ”¹åˆ†æ”¯ä¸­çš„è´¨é‡æµé‡æ¥æœ€å¤§é™åº¦åœ°é™ä½èƒ½æºæˆæœ¬ã€‚   å…³äºä»£ç†çš„è¶…å‚æ•°ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯å…·æœ‰ä»¥ä¸‹å‚æ•°çš„ RL å·¥å…·ç®±ï¼š   é‡‡æ ·æ—¶é—´ = 3600  æŠ˜æ‰£å› å­ = 0.99  GPU  æ‰¹æ¬¡å¤§å° = 512  å­¦ä¹ ç‡ = 1e-3ï¼ˆå¯¹äºæ¼”å‘˜å’Œè¯„è®ºå®¶ï¼‰   æˆ‘æ€€ç–‘æˆ‘çš„æ¨¡å‹æˆ–ä»£ç†å¯èƒ½æœ‰é—®é¢˜ã€‚ æˆ‘å°†é™„ä¸Š Simulink æ¨¡å‹ï¼ˆåº”äº‹å…ˆåŠ è½½å±æ€§è¡¨ï¼‰ã€‚ æˆ‘å¸Œæœ›é—®é¢˜æ¸…æ¥šï¼Œå¹¶ä¸”æœ‰äººå¯ä»¥æä¾›å¸®åŠ©ï¼ æå‰è°¢è°¢æ‚¨ï¼    æäº¤äºº    /u/Resident_Wish9453   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyxh40/reinforcement_learning_agent_not_taking_realistic/</guid>
      <pubDate>Tue, 09 Jul 2024 08:42:43 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å¤„ç†3Dä½“ç´ è§‚å¯Ÿï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyvblp/how_to_handle_3d_voxel_observation/</link>
      <description><![CDATA[æˆ‘ç›®å‰åœ¨ä½¿ç”¨ 3D ä½“ç´ çŠ¶æ€è®­ç»ƒ PPO æ—¶é‡åˆ°äº†å›°éš¾ã€‚ 3D ä½“ç´ çš„å½¢çŠ¶ä¸º [64, 128, 128]ï¼ŒåŒºåŸŸä¿¡æ¯å¾ˆé‡è¦ã€‚ åªä½¿ç”¨ 3D CNN ç¼–ç å™¨å¯ä»¥å—ï¼Ÿ æˆ‘æ˜¯å¼ºåŒ–å­¦ä¹ çš„æ–°æ‰‹ï¼Œæˆ‘è¿˜æ²¡æœ‰çœ‹åˆ°ä»»ä½•ä½¿ç”¨ 3D ç¼–ç å™¨çš„è®ºæ–‡ï¼Œè€Œä¸”å¤§å¤šæ•° RL æ•™ç¨‹éƒ½ä½¿ç”¨ 2d CNN ç¼–ç å™¨æˆ–ä»…ä½¿ç”¨ MLP     æäº¤äºº    /u/MediocreAgency6070   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyvblp/how_to_handle_3d_voxel_observation/</guid>
      <pubDate>Tue, 09 Jul 2024 06:16:59 GMT</pubDate>
    </item>
    <item>
      <title>RLHubï¼šå¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„ç»Ÿä¸€å¹³å° - å¯»æ±‚åé¦ˆï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyrza8/rlhub_a_unified_platform_for_reinforcement/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘çš„ RL ä¼™ä¼´ä»¬ï¼ æˆ‘æ˜¯åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡çš„åšå£«åï¼Œå’Œå‡ ä¸ªæœ‹å‹ä¸€èµ·åœ¨å¼€å±•ä¸€ä¸ªåä¸º RLHub çš„æ–°é¡¹ç›®ï¼Œæˆ‘å¾ˆæƒ³å¬å¬ä½ ä»¬çš„æƒ³æ³•ã€‚æˆ‘ä»¬çš„æƒ³æ³•æ˜¯åˆ›å»ºä¸€ä¸ªæ ‡å‡†åŒ–çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒå¹³å°ï¼Œç±»ä¼¼äº Hugging Face ä¸º NLP æ¨¡å‹æ‰€åšçš„å·¥ä½œã€‚ ä¸»è¦åŠŸèƒ½ï¼š1. é€‚ç”¨äºå„ç§ RL ç¯å¢ƒï¼ˆmujocoã€unityã€gym ç­‰ï¼‰çš„ç»Ÿä¸€ API 2. è½»æ¾ä¸Šä¼ å’Œå…±äº«è‡ªå®šä¹‰ç¯å¢ƒ 3. è‡ªåŠ¨ä¾èµ–é¡¹ç®¡ç† 4. æœ¬åœ°å’Œäº‘æ‰§è¡Œé€‰é¡¹ 5. æ ‡å‡†åŒ–å…ƒæ•°æ®å’Œæ–‡æ¡£ å¯èƒ½çš„é™„åŠ åŠŸèƒ½ï¼š- æ ‡å‡†åŒ–ä¸»è¦ç®—æ³•ï¼ˆPPOã€DDPGã€TD3â€¦â€¦ï¼‰UIï¼Œç”¨äºåœ¨äº‘ç«¯è®­ç»ƒä»£ç† ç›®æ ‡æ˜¯ç®€åŒ–æŸ¥æ‰¾ã€ä½¿ç”¨å’Œå…±äº« RL ç¯å¢ƒçš„è¿‡ç¨‹ã€‚ç ”ç©¶äººå‘˜å¯ä»¥è½»æ¾åœ°åœ¨å¤šç§ç¯å¢ƒä¸­å°è¯•ä»–ä»¬çš„ç®—æ³•ï¼Œç¯å¢ƒåˆ›å»ºè€…å¯ä»¥æ¥è§¦åˆ°æ›´å¹¿æ³›çš„å—ä¼—ã€‚ æˆ‘æœ‰ä¸€äº›é—®é¢˜ï¼š1. è¿™å¯¹æ‚¨çš„å·¥ä½œæœ‰ç”¨å—ï¼Ÿ2. æ‚¨ä¼šä¼˜å…ˆè€ƒè™‘å“ªäº›åŠŸèƒ½ï¼Ÿ3. å¯¹æ ‡å‡†åŒ–æœ‰ä»€ä¹ˆé¡¾è™‘ï¼Ÿ4. å…³äºåœ¨ MVP ä¸­åŒ…å«äº‘æ‰§è¡Œçš„æƒ³æ³•ï¼Ÿ æˆ‘ç‰¹åˆ«æƒ³å¬å¬ RL ç ”ç©¶äººå‘˜å’Œä»ä¸šäººå‘˜çš„æ„è§ã€‚æ‚¨å¯¹å½“å‰ RL ç¯å¢ƒç®¡ç†æœ‰å“ªäº›ç—›ç‚¹ï¼Œå¯ä»¥è§£å†³è¿™äº›ç—›ç‚¹å—ï¼Ÿ æå‰æ„Ÿè°¢æ‚¨çš„ä»»ä½•åé¦ˆï¼    æäº¤äºº    /u/elonmusk-A12   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyrza8/rlhub_a_unified_platform_for_reinforcement/</guid>
      <pubDate>Tue, 09 Jul 2024 03:03:51 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œè°ƒè¯•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dyjkv6/neural_network_debugging/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘çŸ¥é“ç¥ç»ç½‘ç»œè°ƒè¯•çš„åŸºç¡€çŸ¥è¯†ã€‚ä½†æˆ‘æƒ³çŸ¥é“æ˜¯å¦æœ‰äººå¯ä»¥åˆ†äº«åœ¨è®­ç»ƒã€æµ‹è¯•å’Œç”Ÿäº§é˜¶æ®µè¿›è¡Œè°ƒè¯•çš„æŠ€å·§ã€‚æˆ‘ç›¸ä¿¡è¿™åœ¨è¿™é‡Œä¼šéå¸¸æœ‰å¸®åŠ©ã€‚    æäº¤äºº    /u/MuscleML   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dyjkv6/neural_network_debugging/</guid>
      <pubDate>Mon, 08 Jul 2024 20:43:56 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘åˆ°åº•è¯¥æ€ä¹ˆåšï¼Ÿå½“æ“ä½œæ— æ³•å½±å“å³å°†åˆ°æ¥çš„çŠ¶æ€æ—¶ä¼šå‡ºç°é—®é¢˜â€¦â€¦</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dy6y4d/what_exactly_should_i_do_problem_when_actions/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œ è€ƒè™‘ä¸€ä¸ªéå¸¸ç®€å•çš„ç©å…·é—®é¢˜ã€‚æ‚¨æœ‰ä¸€è¾†æ±½è½¦ï¼Œå®ƒæ²¿ x è½´ç§»åŠ¨ã€‚æ±½è½¦ä»¥ä¸€å®šçš„èµ·å§‹é€Ÿåº¦åœ¨ 1 ç»´ä¸­ç§»åŠ¨ã€‚æ‚¨çš„æ±½è½¦æœ‰ 2 ä¸ªåˆ¹è½¦ï¼Œä¸€æ—¦æ‰“å¼€åˆ¹è½¦ï¼Œå°±æ— æ³•æ”¶å›ã€‚è¿™æ„å‘³ç€ï¼šå¦‚æœæ‚¨æ‰“å¼€ç¬¬ä¸€ä¸ªåˆ¹è½¦ï¼Œå°±æ— æ³•å†æ¬¡å…³é—­å®ƒï¼Œæ‚¨å·²ç»å¤±å»äº†æœºä¼šã€‚å¦‚æœæ‚¨åœ¨é”™è¯¯çš„æ—¶é—´æ‰“å¼€ç¬¬ä¸€ä¸ªåˆ¹è½¦è€ŒçŠ¯äº†ä¸€ä¸ªé”™è¯¯ï¼Œé‚£ä¹ˆæ‚¨å¿…é¡»å°å¿ƒï¼Œåœ¨æœ€ä½³æ—¶é—´æ‰“å¼€ç¬¬äºŒä¸ªåˆ¹è½¦ã€‚ ç¯å¢ƒï¼š  çŠ¶æ€ï¼š&lt;ä½ç½®ã€é€Ÿåº¦ã€åˆ¹è½¦çŠ¶æ€ (0ï¼šæ— ã€1ï¼šåˆ¹è½¦\_1 æ‰“å¼€ã€2ï¼šåˆ¹è½¦\_2 æ‰“å¼€)&gt; æ“ä½œï¼š0 æˆ– 1 (å½“å‰åˆ¹è½¦çŠ¶æ€ += æ“ä½œ --&gt; æ ¹æ®å½“å‰çŠ¶æ€æ·»åŠ æ“ä½œ) å¥–åŠ± = - (æœ€åä½ç½® - ç›®æ ‡ä½ç½®) ^ 2 èµ·å§‹é€Ÿåº¦ = 10ï¼Œèµ·å§‹ä½ç½® = 0ï¼Œç›®æ ‡ä½ç½® = 55 å¦‚æœæ‰“å¼€ï¼Œç¬¬ä¸€ä¸ªåˆ¹è½¦æ¥åˆï¼šé€Ÿåº¦ -= 1 å¦‚æœæ‰“å¼€ï¼Œç¬¬äºŒä¸ªåˆ¹è½¦æ¥åˆï¼šé€Ÿåº¦-= 2 æƒ…èŠ‚ç»“æŸ -&gt; ï¼ˆå¦‚æœä½ç½® &gt; 65 æˆ–é€Ÿåº¦ &lt; 0ï¼‰  -&gt; è§£å†³æ–¹æ¡ˆæ˜¯ï¼šåœ¨ç¬¬ 3 æ­¥æ‰“å¼€ç¬¬ 1 ä¸ªåˆ¶åŠ¨å™¨ï¼Œåœ¨ç¬¬ 4 æ­¥æ‰“å¼€ç¬¬ 2 ä¸ªåˆ¶åŠ¨å™¨ 10 + 10 + 10ï¼ˆåœ¨æ­¤å¤„æ‰“â€‹â€‹å¼€ Brake_1ï¼‰+ 9ï¼ˆåœ¨æ­¤å¤„æ‰“â€‹â€‹å¼€ Brake_2ï¼‰+ 7 + 5 + 3 + 1 = 55 æˆ‘çš„é—®é¢˜ï¼š æ‰“å¼€ Brake_2 åï¼Œæ“ä½œå°†ä¸å†äº§ç”Ÿä»»ä½•æ•ˆæœã€‚æˆ‘çš„æ„æ€æ˜¯ï¼š&lt;State, Action=0, Same\_Reward, Same\_Next\_State&gt;ï¼Œ&lt;State, Action=1, Same\_Reward, Same\_Next\_State&gt;ã€‚æ— è®ºä»£ç†å°è¯•é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œå®ƒéƒ½ä¼šè¿›å…¥ç›¸åŒçš„ next_state å¹¶è·å¾—ç›¸åŒçš„å¥–åŠ±ã€‚åŸºæœ¬ä¸Šï¼Œä»£ç†å·²ç»å¤±å»äº†æ”¹å˜å³å°†åˆ°æ¥çš„çŠ¶æ€çš„èƒ½åŠ›ã€‚ å¦‚æœæˆ‘æ·»åŠ ä¸€ä¸ªç”±å…³é—­ä¸­æ–­ç»„æˆçš„æœºåˆ¶ï¼Œä»£ç†å°†ç»§ç»­å…·æœ‰å¡‘é€ å³å°†åˆ°æ¥çš„çŠ¶æ€çš„èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€å¡‘é€ æ±½è½¦çš„æœ€åä½ç½®ç›´åˆ°æƒ…èŠ‚ç»“æŸã€‚è¿™å·²ç»å¥æ•ˆï¼Œä»£ç†èƒ½å¤Ÿæ‰¾åˆ°æ­£ç¡®çš„åŠ¨ä½œç»„åˆã€‚åŠ¨ä½œåŸºæœ¬ä¸Šæ˜¯å¯é€†çš„ã€‚ å¦‚æœæˆ‘åˆ›å»ºå¦‚ä¸Šæ‰€è¿°çš„ç¯å¢ƒï¼Œç”±äº Break_2 ä¹‹åï¼Œä¿æŒå¯¹æ±½è½¦é€Ÿåº¦çš„æ§åˆ¶çš„èƒ½åŠ›å°†æ¶ˆå¤±ï¼Œä»£ç†å¼€å§‹åŠªåŠ›è§£å†³é—®é¢˜ã€‚åŠ¨ä½œåŸºæœ¬ä¸Šæ˜¯ä¸å¯é€†çš„ã€‚ æ€»è€Œè¨€ä¹‹ï¼Œå¦‚æœåœ¨æŸäº›äº‹ä»¶ä¹‹ååŠ¨ä½œå¯¹ä¸‹ä¸€ä¸ªçŠ¶æ€å’Œå¥–åŠ±å®é™…ä¸Šæ²¡æœ‰å½±å“ï¼Œæˆ‘è¯¥æ€ä¹ˆåŠï¼Ÿå¿½ç•¥ä¸­é—´çš„ &lt;çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±ã€ä¸‹ä¸€ä¸ªçŠ¶æ€ã€å®Œæˆ&gt;ï¼Œç­‰åˆ°æƒ…èŠ‚ç»“æŸï¼Œå¹¶å°†æœ€åä¸€ä¸ªçŠ¶æ€å’Œå¥–åŠ±ä¸ Break_2 æ‰“å¼€çš„ previous_state ç›¸ç»“åˆï¼Ÿ    æäº¤äºº    /u/OpenToAdvices96   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dy6y4d/what_exactly_should_i_do_problem_when_actions/</guid>
      <pubDate>Mon, 08 Jul 2024 11:51:32 GMT</pubDate>
    </item>
    </channel>
</rss>