<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 16 Oct 2024 15:23:16 GMT</lastBuildDate>
    <item>
      <title>Unity ML ä»£ç†å’Œè´ªåƒè›‡ç­‰æ¸¸æˆ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4xhqd/unity_ml_agents_and_games_like_snake/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘ä¸€ç›´åœ¨å°è¯•ç†è§£ç¥ç»ç½‘ç»œå’Œæ¸¸æˆ AI çš„è®­ç»ƒã€‚ä½†æˆ‘ç›®å‰åœ¨åŠªåŠ›ç© Snakeã€‚æˆ‘æƒ³â€œå¥½å§ï¼Œè®©æˆ‘ä»¬ç»™å®ƒä¸€äº›å°„çº¿ä¼ æ„Ÿå™¨ã€ä¸€ä¸ªæ‘„åƒå¤´ä¼ æ„Ÿå™¨ï¼Œåƒé£Ÿç‰©æ—¶ç»™äºˆå¥–åŠ±ï¼Œä¸è‡ªèº«æˆ–å¢™å£ç¢°æ’æ—¶ç»™äºˆè´Ÿé¢å¥–åŠ±â€ã€‚ æˆ‘æƒ³è¯´å®ƒå­¦å¾—å¾ˆå¥½ï¼Œä½†å¹¶ä¸å®Œç¾ï¼åœ¨ 10x10 çš„æ¸¸æˆåœºä¸­ï¼Œå®ƒçš„æœ€é«˜åˆ†çº¦ä¸º 50ï¼Œä½†åˆ°ç›®å‰ä¸ºæ­¢å®ƒä»æœªæŒæ¡æ¸¸æˆã€‚ æœ‰äººèƒ½ç»™æˆ‘ä¸€äº›å»ºè®®æˆ–çº¿ç´¢ï¼Œå¦‚ä½•æ›´å¥½åœ°å¤„ç†ä½¿ç”¨ PPO è¿›è¡Œè›‡ AI è®­ç»ƒå—ï¼Ÿ å°„çº¿ä¼ æ„Ÿå™¨å¯ä»¥æ£€æµ‹å¢™å£ã€è›‡æœ¬èº«å’Œé£Ÿç‰©ï¼ˆ3 ä¸ªä¸åŒçš„ä¼ æ„Ÿå™¨ï¼Œæ¯ä¸ªä¼ æ„Ÿå™¨æœ‰ 16 æ¡å°„çº¿ï¼‰ æ‘„åƒå¤´ä¼ æ„Ÿå™¨çš„åˆ†è¾¨ç‡ä¸º 50x50ï¼Œä¹Ÿå¯ä»¥çœ‹åˆ°å¢™å£ã€è›‡å¤´ä»¥åŠè›‡å‘¨å›´çš„è›‡å°¾ã€‚å®ƒæ˜¯ä¸€ä¸ªå°ºå¯¸ä¸º 8 çš„æ­£äº¤ç›¸æœºï¼Œå› æ­¤å®ƒå¯ä»¥çœ‹åˆ°æ•´ä¸ªè¿åŠ¨åœºã€‚ é¦–å…ˆï¼Œæˆ‘åªä½¿ç”¨å°„çº¿ä¼ æ„Ÿå™¨è¿›è¡Œæµ‹è¯•ï¼Œç„¶åæˆ‘æ·»åŠ äº†ç›¸æœºä¼ æ„Ÿå™¨ï¼Œæˆ‘å¯ä»¥è¯´çš„æ˜¯ï¼Œå®ƒé€šè¿‡ç›¸æœºè§†è§‰è§‚å¯Ÿå­¦ä¹ å¾—æ›´å¿«ï¼Œä½†æœ€åå®ƒçš„æœ€é«˜åˆ†å¤§çº¦ç›¸åŒã€‚ æˆ‘æ­£åœ¨å¹¶è¡Œè®­ç»ƒ 10 ä¸ªä»£ç†ã€‚ ç½‘ç»œè®¾ç½®ä¸ºï¼š 50x50x1 è§†è§‰è§‚å¯Ÿè¾“å…¥ å¤§çº¦ 100 ä¸ªå°„çº¿è§‚å¯Ÿè¾“å…¥ 512 ä¸ªéšè—ç¥ç»å…ƒ 2 ä¸ªéšè—å±‚ 4 ä¸ªç¦»æ•£è¾“å‡ºåŠ¨ä½œ æˆ‘ç›®å‰æ­£åœ¨å°è¯•ä½¿ç”¨ buffer_size ä¸º 25000 å’Œ batch_size ä¸º 2500ã€‚å­¦ä¹ ç‡ä¸º 0.0003ï¼ŒNum Epoch ä¸º 3ã€‚æ—¶é—´èŒƒå›´è®¾ç½®ä¸º 250ã€‚ æ˜¯å¦æœ‰äººä½¿ç”¨è¿‡ Unity çš„ ML Agents Toolkit å¹¶èƒ½å¸®åŠ©æˆ‘ä¸€ç‚¹ï¼Ÿ æˆ‘åšé”™äº†ä»€ä¹ˆå—ï¼Ÿ æˆ‘å°†æ„Ÿè°¢ä½ ä»¬ç»™äºˆæˆ‘çš„æ¯ä¸€æ¬¡å¸®åŠ©ï¼ è¿™é‡Œæœ‰ä¸€ä¸ªå°è§†é¢‘ï¼Œä½ å¯ä»¥åœ¨å…¶ä¸­çœ‹åˆ°å¤§çº¦ç¬¬ 150 ä¸‡æ­¥çš„åŸ¹è®­ï¼š https://streamable.com/tecde6    æäº¤äºº    /u/Seismoforg   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4xhqd/unity_ml_agents_and_games_like_snake/</guid>
      <pubDate>Wed, 16 Oct 2024 11:51:50 GMT</pubDate>
    </item>
    <item>
      <title>ä¿®æ”¹ç­–ç•¥è¿­ä»£ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4ukf4/modified_policy_iteration/</link>
      <description><![CDATA[æˆ‘æ˜¯å¼ºåŒ–å­¦ä¹ çš„æ–°æ‰‹ï¼Œä»åœ¨å­¦ä¹ ä¸­ã€‚æˆ‘ç°åœ¨æ­£åœ¨å­¦ä¹ ç­–ç•¥è¿­ä»£å’Œå€¼è¿­ä»£ã€‚ å› æ­¤ï¼Œæ®æˆ‘æ‰€çŸ¥ï¼Œåœ¨ç­–ç•¥è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡è·å–æ‰€æœ‰çŠ¶æ€çš„çŠ¶æ€å€¼å‡½æ•°æ¥è¯„ä¼°å½“å‰ç­–ç•¥ï¼Œç„¶åä½¿ç”¨å®ƒä»¬è¿›è¡Œè´ªå©ªæ“ä½œæ›´æ–°ç­–ç•¥ï¼Œç„¶åé€šè¿‡å†æ¬¡è·å–æ‰€æœ‰çŠ¶æ€çš„çŠ¶æ€å€¼å‡½æ•°æ¥è¯„ä¼°æ›´æ–°åçš„ç­–ç•¥ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè¿­ä»£ï¼Œç›´åˆ°è·å¾—æœ€ä½³ç­–ç•¥ã€‚ æˆ‘é˜…è¯»äº†å…³äºä¿®æ”¹åçš„ç­–ç•¥è¿­ä»£çš„æ–‡ç« ï¼Œå¯¹æ­¤æˆ‘çš„çœ‹æ³•ä¸ä¸€ã€‚æˆ‘ç°åœ¨å¯ä»¥çœ‹åˆ°ä¸¤ç§æ–¹æ³•ï¼š  ä¿®æ”¹åçš„ç­–ç•¥è¿­ä»£å°±æ˜¯ç­–ç•¥è¿­ä»£ï¼Œåªä¸è¿‡æˆ‘ä»¬åªè¿›è¡Œ k æ¬¡è¿­ä»£ï¼Ÿ æˆ‘ä»¬åªè¯„ä¼°éƒ¨åˆ†çŠ¶æ€ï¼Ÿ  æˆ‘ä¹‹æ‰€ä»¥é—®è¿™ä¸ªé—®é¢˜ï¼Œæ˜¯å› ä¸ºä»æˆ‘è¯»åˆ°çš„å†…å®¹æ¥çœ‹ï¼Œç¬¬ä¸€ç§æ–¹æ³•ä¼¼ä¹æ˜¯æ­£ç¡®çš„ï¼Œä½†æ˜¯æˆ‘åœ¨ä½¿ç”¨çš„ä¹¦ä¸­çœ‹åˆ°çš„å›¾è¡¨å’Œå…¶ä»–äººçš„è§£é‡Šï¼ˆä»–ç°åœ¨ä¹Ÿæ˜¯ç¬¬ä¸€æ¬¡å­¦ä¹  RLï¼‰è¡¨æ˜å®ƒæ˜¯ç¬¬äºŒç§æ–¹æ³•ã€‚    æäº¤äºº    /u/AdBitter9336   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4ukf4/modified_policy_iteration/</guid>
      <pubDate>Wed, 16 Oct 2024 08:31:37 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åº”å¯¹SACçš„ç¾éš¾æ€§é—å¿˜ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4tklf/how_to_deal_with_the_catastrophic_forgetting_of/</link>
      <description><![CDATA[      å—¨ï¼ æˆ‘å»ºç«‹äº†ä¸€ä¸ªä½¿ç”¨SACè¿›è¡Œè®­ç»ƒçš„è‡ªå®šä¹‰ä»»åŠ¡ã€‚æˆåŠŸç‡æ›²çº¿åœ¨ç¨³æ­¥ä¸Šå‡åé€æ¸ä¸‹é™ã€‚åœ¨æŸ¥é˜…äº†ä¸€äº›ç›¸å…³è®¨è®ºåï¼Œæˆ‘å‘ç°è¿™ç§ç°è±¡å¯èƒ½æ˜¯ç¾éš¾æ€§çš„é—å¿˜ã€‚ https://preview.redd.it/i5bxwet9j2vd1.png?width=1352&amp;format=png&amp;auto=webp&amp;s=81ea533917317b57ebd924668f24fdd59e275c43 æˆ‘å°è¯•è§„èŒƒå¥–åŠ±å¹¶è‡ªåŠ¨è°ƒæ•´ alpha çš„å€¼æ¥æ§åˆ¶æ¢ç´¢å’Œåˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡ã€‚å…¶æ¬¡ï¼Œæˆ‘è¿˜é™ä½äº† actor å’Œ critic çš„å­¦ä¹ ç‡ï¼Œä½†è¿™åªä¼šå‡æ…¢å­¦ä¹ è¿‡ç¨‹å¹¶é™ä½æ•´ä½“æˆåŠŸç‡ã€‚ æˆ‘æƒ³å¾—åˆ°ä¸€äº›å…³äºå¦‚ä½•è¿›ä¸€æ­¥ç¨³å®šè¿™ä¸ªè®­ç»ƒè¿‡ç¨‹çš„å»ºè®®ã€‚ æå‰æ„Ÿè°¢æ‚¨çš„æ—¶é—´å’Œå¸®åŠ©ï¼    æäº¤äºº    /u/UpperSearch4172   [link] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4tklf/how_to_deal_with_the_catastrophic_forgetting_of/</guid>
      <pubDate>Wed, 16 Oct 2024 07:13:25 GMT</pubDate>
    </item>
    <item>
      <title>ä»€ä¹ˆå¯èƒ½å¯¼è‡´æˆ‘çš„ Q-Loss å€¼å‡ºç°åˆ†æ­§ï¼ˆSAC + Godot <-> Pythonï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4t57g/what_could_be_causing_my_qloss_values_to_diverge/</link>
      <description><![CDATA[TLDR; æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªä½¿ç”¨ SAC çš„ PyTorch é¡¹ç›®ï¼Œç±»ä¼¼äºæˆ‘çš„ä¸€ä¸ªæ—§ Tensorflow é¡¹ç›®ï¼šhttps://www.youtube.com/watch?v=Jg7\_PM-q\_Bkã€‚æˆ‘æ— æ³•è®©å®ƒä¸ PyTorch ä¸€èµ·å·¥ä½œï¼Œå› ä¸ºæˆ‘çš„ Q-Loses å’Œ Policy æŸå¤±è¦ä¹ˆå¢é•¿ï¼Œè¦ä¹ˆæ”¶æ•›åˆ° 0 å¤ªå¿«ã€‚ä½ çŸ¥é“ä¸ºä»€ä¹ˆä¼šè¿™æ ·å—ï¼Ÿ  æˆ‘å·²ç»åœ¨ Godot ä¸­åˆ›å»ºäº†ä¸€ä¸ªæ¸¸æˆï¼Œé€šè¿‡å¥—æ¥å­—ä¸ SAC çš„ PyTorch å®ç°è¿›è¡Œé€šä¿¡ï¼šhttps://github.com/philipjball/SAC_PyTorch æ¸¸æˆæ˜¯ï¼š ä»£ç†éœ€è¦é è¿‘ç›®æ ‡ï¼Œä½†å®ƒæ²¡æœ‰è‡ªå·±çš„ä½ç½®æˆ–ç›®æ ‡ä½ç½®ä½œä¸ºè¾“å…¥ï¼Œè€Œæ˜¯æœ‰ 6 ä¸ªè¾“å…¥ï¼Œè¡¨ç¤ºç›®æ ‡ä¸ä»£ç†åœ¨ç‰¹å®šè§’åº¦çš„è·ç¦»ã€‚å§‹ç»ˆæœ‰ä¸”åªæœ‰ 1 ä¸ªè¾“å…¥çš„å€¼ä¸ä¸º 1ã€‚ ä»£ç†è¾“å‡º 2 ä¸ªå€¼ï¼šç§»åŠ¨çš„æ–¹å‘å’Œæ²¿è¯¥æ–¹å‘ç§»åŠ¨çš„å¹…åº¦ã€‚ è¾“å…¥åœ¨ [0,1] èŒƒå›´å†…ï¼ˆç”±æœ€å¤§è·ç¦»æ ‡å‡†åŒ–ï¼‰ï¼Œ2 ä¸ªè¾“å‡ºåœ¨ [-1,1] èŒƒå›´å†…ã€‚ å¥–åŠ±ä¸ºï¼š score = -distance if score &gt;= -300: score = (300 - abs(score )) * 3 score = (score / 650.0) * 2 # 650 æ˜¯æœ€å¤§è·ç¦»ï¼Œ100 æ˜¯æ¯æ­¥çš„æœ€å¤§èŒƒå›´ return score * abs(score )  é—®é¢˜æ˜¯ï¼š ä¸¤ä¸ªè¯„è®ºå®¶å’Œç­–ç•¥çš„ Q-Loss éƒ½åœ¨éšç€æ—¶é—´çš„æ¨ç§»ç¼“æ…¢å¢é•¿ã€‚æˆ‘å°è¯•äº†å‡ ç§ä¸åŒçš„ç½‘ç»œæ‹“æ‰‘ï¼Œä½†å±‚æ•°æˆ–æ¯å±‚ä¸­çš„èŠ‚ç‚¹æ•°ä¼¼ä¹å¯¹ Q-Loss æ²¡æœ‰å½±å“ æˆ‘èƒ½åšçš„æœ€å¥½çš„å°±æ˜¯è®©å¥–åŠ±éå¸¸å°ï¼Œä½†è¿™ä¼šå¯¼è‡´ Q-Loss å’Œ Policy loss æ”¶æ•›åˆ° 0ï¼Œå³ä½¿ä»£ç†æ²¡æœ‰å­¦åˆ°ä»»ä½•ä¸œè¥¿ã€‚ å¦‚æœæ‚¨åšåˆ°äº†è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”æœ‰å…´è¶£æä¾›å¸®åŠ©ï¼Œæˆ‘å¾ˆä¹æ„å‘æ‚¨æ”¯ä»˜å¯¼å¸ˆçš„è´¹ç”¨ï¼Œé€šè¿‡å±å¹•å…±äº«ç”µè¯å®¡æŸ¥æˆ‘çš„æ–¹æ³•ï¼Œå¹¶å¸®åŠ©æˆ‘æ›´å¥½åœ°äº†è§£å¦‚ä½•è®© SAC ä»£ç†å·¥ä½œã€‚ æå‰è°¢è°¢æ‚¨ï¼ï¼    æäº¤äºº    /u/stokaty   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4t57g/what_could_be_causing_my_qloss_values_to_diverge/</guid>
      <pubDate>Wed, 16 Oct 2024 06:41:22 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆä½¿ç”¨ Unity ML Agentsï¼‰åˆ¶ä½œäº†ä¸€ä¸ªæ¶ˆé˜²å‘˜ AI</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4iy4q/i_made_a_firefighter_ai_using_deep_rl_using_unity/</link>
      <description><![CDATA[è§†é¢‘é“¾æ¥ï¼šhttps://www.youtube.com/watch?v=REYx9UznOG4 æˆ‘ä¹‹å‰åšè¿‡è¿™ä¸ªè§†é¢‘ï¼ŒèŠ±äº†å¥½å‡ ä¸ªå°æ—¶æ‰åˆ¶ä½œå‡ºæ¥ï¼Œå´æ²¡æœ‰äººå…³æ³¨ï¼Œè¿™è®©æˆ‘å¾ˆæ²®ä¸§ï¼Œæ‰€ä»¥æˆ‘ç°åœ¨åœ¨æ”»è¯»äººå·¥æ™ºèƒ½åšå£«å­¦ä½ï¼Œè€Œä¸æ˜¯æˆä¸ºä¸€å YouTuberï¼Œå“ˆå“ˆã€‚ æˆ‘æƒ³å¦‚æœäººä»¬è§‰å¾—å®ƒå¾ˆæœ‰è¶£ï¼Œç°åœ¨ä¸ºå®ƒåšå¹¿å‘Šä¹Ÿä¸é”™ã€‚æˆ‘ç¡®ä¿æ·»åŠ äº†ä¸€äº›æ—ç™½å’Œæœ‰è¶£çš„éƒ¨åˆ†ï¼Œè¿™æ ·å®ƒå°±ä¸ä¼šæ— èŠäº†ã€‚æˆ‘å¸Œæœ›è¿™é‡Œçš„ä¸€äº›äººèƒ½è§‰å¾—å®ƒå’Œæˆ‘åšè¿™ä¸ªé¡¹ç›®ä¸€æ ·æœ‰è¶£ã€‚ æˆ‘å¯¹è¿™ä¸ªä¸»é¢˜å¾ˆæ„Ÿå…´è¶£ï¼Œæ‰€ä»¥å¦‚æœæœ‰äººæœ‰é—®é¢˜ï¼Œæˆ‘ä¼šåœ¨æœ‰æ—¶é—´çš„æ—¶å€™å›ç­”ä»–ä»¬:D   ç”±    /u/usernumero  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4iy4q/i_made_a_firefighter_ai_using_deep_rl_using_unity/</guid>
      <pubDate>Tue, 15 Oct 2024 21:28:04 GMT</pubDate>
    </item>
    <item>
      <title>NoisyLinears ä¹‹åçš„ LayerNor/Adanormï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4gbc7/layernoradanorm_after_noisylinears/</link>
      <description><![CDATA[é™¤äº†æœ€åä¸€ä¸ªå™ªå£°è¾“å‡ºå±‚ä¹‹å¤–ï¼Œå¯¹ NN ä¸­çš„æ‰€æœ‰å™ªå£°å±‚åº”ç”¨å±‚èŒƒæ•°æˆ– adanorm æœ‰ä»€ä¹ˆæƒ³æ³•/ç»éªŒå—ï¼Ÿ ä»»ä½•ä¸€ä¸ªèŒƒæ•°å±‚åŸºæœ¬ä¸Šéƒ½ä¼šæ‰¼æ€å™ªå£°çº¿æ€§/æ¢ç´¢å—ï¼Ÿ    æäº¤äºº    /u/dekiwho   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4gbc7/layernoradanorm_after_noisylinears/</guid>
      <pubDate>Tue, 15 Oct 2024 19:36:13 GMT</pubDate>
    </item>
    <item>
      <title>â€œè§£è¯» DPO å’Œ PPOï¼šä»åå¥½åé¦ˆä¸­è§£å¼€å­¦ä¹ çš„æœ€ä½³å®è·µâ€ï¼ŒIvison ç­‰äººï¼Œ2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g4cnnx/unpacking_dpo_and_ppo_disentangling_best/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g4cnnx/unpacking_dpo_and_ppo_disentangling_best/</guid>
      <pubDate>Tue, 15 Oct 2024 17:02:15 GMT</pubDate>
    </item>
    <item>
      <title>Simbaï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­æ‰©å¤§å‚æ•°çš„ç®€å•æ€§åå·®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g460jl/simba_simplicity_bias_for_scaling_up_parameters/</link>
      <description><![CDATA[      æƒ³è¦æ›´å¿«ã€æ›´æ™ºèƒ½çš„å¼ºåŒ–å­¦ä¹ ï¼ŸæŸ¥çœ‹ SimBa â€“ æˆ‘ä»¬å¯ç–¯ç‹‚æ‰©å±•çš„æ–°æ¶æ„ï¼ ğŸ“„ é¡¹ç›®é¡µé¢ï¼šhttps://sonyresearch.github.io/simba ğŸ“„ arXivï¼šhttps://arxiv.org/abs/2410.09754 ğŸ”— ä»£ç ï¼šhttps://github.com/SonyResearch/simba ğŸš€ åŒå€¦äº†æ·±åº¦ RL ä¸­ç¼“æ…¢çš„è®­ç»ƒæ—¶é—´å’Œä¸å°½äººæ„çš„ç»“æœï¼Ÿ ä½¿ç”¨ SimBaï¼Œæ‚¨å¯ä»¥æ¯«ä¸è´¹åŠ›åœ°æ‰©å±•å‚æ•°å¹¶è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ - è€Œæ— éœ€æ›´æ”¹æ ¸å¿ƒ RL ç®—æ³•ã€‚ ğŸ’¡ å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ åªéœ€å°†æ‚¨çš„ MLP ç½‘ç»œæ¢æˆ SimBaï¼Œç„¶åè§‚çœ‹å¥‡è¿¹å‘ç”Ÿï¼åœ¨å•ä¸ª Nvidia RTX 3090 ä¸Šï¼Œåªéœ€ 1-3 å°æ—¶ï¼Œæ‚¨å°±å¯ä»¥è®­ç»ƒå‡ºåœ¨ DMCã€MyoSuite å’Œ HumanoidBench ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³çš„ä»£ç†ã€‚ ğŸ¦¾ âš™ï¸ ä¸ºä»€ä¹ˆå®ƒå¾ˆæ£’ï¼š å³æ’å³ç”¨ï¼Œæ”¯æŒ SACã€DDPGã€TD-MPC2ã€PPO å’Œ METRA ç­‰ RL ç®—æ³•ã€‚ æ— éœ€è°ƒæ•´æ‚¨æœ€å–œæ¬¢çš„ç®—æ³• - åªéœ€åˆ‡æ¢åˆ° SimBa å¹¶è®©æ‰©å±•èƒ½åŠ›æ¥ç®¡å³å¯ã€‚ è®­ç»ƒæ›´å¿«ã€æ›´æ™ºèƒ½ã€æ›´å¥½ - éå¸¸é€‚åˆç ”ç©¶äººå‘˜ã€å¼€å‘äººå‘˜å’Œä»»ä½•æ¢ç´¢æ·±åº¦ RL çš„äººï¼ ğŸ¯ ç«‹å³å°è¯•å¹¶è§‚å¯Ÿæ‚¨çš„ RL æ¨¡å‹æ¼”å˜ï¼ https://i.redd.it/olxmmgyauwud1.gif    æäº¤äºº    /u/joonleesky   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g460jl/simba_simplicity_bias_for_scaling_up_parameters/</guid>
      <pubDate>Tue, 15 Oct 2024 12:03:38 GMT</pubDate>
    </item>
    <item>
      <title>â€œå¤§å‹è¯­è¨€æ¨¡å‹ç©æ˜Ÿé™…äº‰éœ¸ IIï¼šåŸºå‡†æµ‹è¯•å’Œæ€»ç»“é“¾æ–¹æ³•â€ï¼ŒMa ç­‰äºº 2023 å¹´ï¼ˆè®© LLM ç©æ˜Ÿé™…äº‰éœ¸çš„æ–‡æœ¬ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g3sqr7/large_language_models_play_starcraft_ii/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g3sqr7/large_language_models_play_starcraft_ii/</guid>
      <pubDate>Mon, 14 Oct 2024 22:32:24 GMT</pubDate>
    </item>
    <item>
      <title>â€œå…·èº«ä»£ç†ç•Œé¢ï¼šå…·èº«å†³ç­–çš„ LLM åŸºå‡†æµ‹è¯•â€ï¼ŒLi ç­‰äººï¼Œ2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g3p9cr/embodied_agent_interface_benchmarking_llms_for/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g3p9cr/embodied_agent_interface_benchmarking_llms_for/</guid>
      <pubDate>Mon, 14 Oct 2024 20:02:46 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•è®­ç»ƒä»£ç†è¿›è¡Œä»»æ„é•¿åº¦çš„äºŒè¿›åˆ¶åŠ æ³•ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g3hdrt/how_to_train_an_agent_to_do_binary_addition_of/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚ è¿™ä¸ªé—®é¢˜çªç„¶å‡ºç°åœ¨æˆ‘çš„è„‘æµ·é‡Œï¼Œæˆ‘çŸ¥é“å®ƒå¯èƒ½æœ‰ç‚¹çç¢ï¼Œä½†æˆ‘å¾ˆæƒ³çŸ¥é“ç­”æ¡ˆã€‚    æäº¤äºº    /u/blablawawawa   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g3hdrt/how_to_train_an_agent_to_do_binary_addition_of/</guid>
      <pubDate>Mon, 14 Oct 2024 14:40:44 GMT</pubDate>
    </item>
    <item>
      <title>TorchRL ä¸­é’ˆå¯¹ MARL çš„åŠ¨ä½œæ©è”½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g3cjnw/action_masking_in_torchrl_for_marl/</link>
      <description><![CDATA[æ‚¨å¥½ï¼æˆ‘ç›®å‰æ­£åœ¨ä½¿ç”¨ TorchRL è§£å†³æˆ‘çš„ MARL é—®é¢˜ã€‚æˆ‘ä½¿ç”¨çš„æ˜¯è‡ªå®šä¹‰ pettingzoo ç¯å¢ƒå’Œ pettingzoo åŒ…è£…å™¨ã€‚æˆ‘çš„è‡ªå®šä¹‰ç¯å¢ƒçš„è§‚å¯Ÿç»“æœä¸­åŒ…å«ä¸€ä¸ªåŠ¨ä½œæ©ç ã€‚åœ¨ TorchRL ä¸­å¤„ç†å®ƒçš„æœ€ç®€å•æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘è§‰å¾— MultiAgentMLP å’Œ ProbabilisticActor ä¸èƒ½ä¸åŠ¨ä½œæ©ç ä¸€èµ·ä½¿ç”¨ï¼Œå¯¹å—ï¼Ÿ è°¢è°¢ï¼    æäº¤äºº    /u/hc7Loh21BptjaT79EG   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g3cjnw/action_masking_in_torchrl_for_marl/</guid>
      <pubDate>Mon, 14 Oct 2024 10:22:58 GMT</pubDate>
    </item>
    <item>
      <title>é€‚åˆæˆ‘çš„å¼ºåŒ–å­¦ä¹ é¡¹ç›®çš„ ubuntu/ROS2/Gazebo ç‰ˆæœ¬</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g3blyl/suitable_ubunturos2gazebo_versions_for_my/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘å°†åœ¨ Gazebo æ¨¡æ‹Ÿå™¨ä¸­å¯¹ epuck æ¨¡å‹æœºå™¨äººè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆæˆ‘æœ‰ä¸€ä¸ªæ¥è‡ª Gazebo Classic çš„ urdf æ¨¡å‹ï¼Œæˆ‘å¿…é¡»é€‚åº”æ–°ç‰ˆæœ¬ï¼‰ï¼Œæˆ‘å¯¹ ros2 å’Œ Gazebo æœ‰åŸºæœ¬çš„å…ˆéªŒçŸ¥è¯†ï¼Œä½†æˆ‘æƒ³çŸ¥é“é€‚åˆæˆ‘çš„é¡¹ç›®çš„ç‰ˆæœ¬ï¼Œå®ƒæ˜¯å…³äºä½¿ç”¨ RL æŠ€æœ¯è¿›è¡Œè‡ªä¸»å¯¼èˆªï¼Œæˆ‘å°†éå¸¸æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ã€‚    æäº¤äºº    /u/DueStill7268   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g3blyl/suitable_ubunturos2gazebo_versions_for_my/</guid>
      <pubDate>Mon, 14 Oct 2024 09:12:31 GMT</pubDate>
    </item>
    <item>
      <title>ä¸åŒçš„ RL ç®—æ³•çœŸçš„æœ‰å¾ˆå¤§å½±å“å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g35fsg/do_different_rl_algorithms_really_affect_much/</link>
      <description><![CDATA[æˆ‘ç°åœ¨æ­£åœ¨è¿›è¡Œ RL é¡¹ç›®æ¥è§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œç”±äºå¤æ‚çš„çº¦æŸï¼Œè¿™ä¸ªé—®é¢˜å¾ˆéš¾ç”¨æ•°å­¦æ¥è¡¨è¾¾ã€‚æˆ‘æ­£åœ¨ä½¿ç”¨ A2C è®­ç»ƒæˆ‘çš„ä»£ç†ï¼Œè¿™æ˜¯æœ€ç®€å•çš„å…¥é—¨æ–¹æ³•ã€‚ æˆ‘åªæ˜¯æƒ³çŸ¥é“å…¶ä»–ç®—æ³•ï¼ˆå¦‚ TRPOã€PPOï¼‰åœ¨å®è·µä¸­æ˜¯å¦çœŸçš„æ•ˆæœæ›´å¥½ï¼Œè€Œä¸æ˜¯åƒåœ¨åŸºå‡†æµ‹è¯•ä¸­é‚£æ ·ã€‚ æœ‰æ²¡æœ‰äººå°è¯•è¿‡ SOTA ç®—æ³•ï¼ˆè®ºæ–‡ä¸­å£°ç§°ï¼‰å¹¶çœŸçš„çœ‹åˆ°äº†å·®å¼‚ï¼Ÿ æˆ‘è§‰å¾—è®¾è®¡å¥–åŠ±æ¯”ç®—æ³•æœ¬èº«é‡è¦å¾—å¤šã€‚    æäº¤äºº    /u/Electronic_Estate854   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g35fsg/do_different_rl_algorithms_really_affect_much/</guid>
      <pubDate>Mon, 14 Oct 2024 01:53:08 GMT</pubDate>
    </item>
    <item>
      <title>DIAMONDï¼šä¸–ç•Œå»ºæ¨¡çš„æ‰©æ•£</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1g34qgx/diamond_diffusion_for_world_modeling/</link>
      <description><![CDATA[DIAMOND ğŸ’ ä¸–ç•Œå»ºæ¨¡çš„æ‰©æ•£ï¼šAtari ä¸­çš„è§†è§‰ç»†èŠ‚å¾ˆé‡è¦ é¡¹ç›®ç½‘é¡µï¼šhttps://diamond-wm.github.io/ ä»£ç ã€ä»£ç†å’Œå¯ç©ä¸–ç•Œæ¨¡å‹ï¼šhttps://github.com/eloialonso/diamond è®ºæ–‡ï¼šhttps://arxiv.org/pdf/2405.12399 æ‘˜è¦  RL ä»£ç†æ˜¯ç”± REINFORCE è®­ç»ƒçš„æ¼”å‘˜-è¯„è®ºå®¶ã€‚  æ¼”å‘˜å’Œè¯„è®ºå®¶ç½‘ç»œé™¤æœ€åä¸€å±‚å¤–å…±äº«æƒé‡ã€‚è¿™äº›å…±äº«å±‚ç”±ä¸€ä¸ªå·ç§¯â€œä¸»å¹²â€å’Œä¸€ä¸ª LSTM å•å…ƒç»„æˆã€‚å·ç§¯ä¸»å¹²æœ‰å››ä¸ªå¸¦æœ‰ 2x2 æœ€å¤§æ± åŒ–çš„æ®‹å·®å—ã€‚ æ¯æ¬¡è®­ç»ƒè¿è¡Œéƒ½éœ€è¦ 500 ä¸‡å¸§ï¼Œåœ¨ä¸€å° Nvidia RTX 4090 ä¸ŠæŒç»­ 12 å¤©ã€‚  ä¸–ç•Œæ¨¡å‹æ˜¯ä¸€ä¸ªå¸¦æœ‰ U-Net 2D çš„ 2D æ‰©æ•£æ¨¡å‹ã€‚å®ƒä¸æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚å®ƒç›´æ¥ä»è§†é¢‘æ¸¸æˆä¸­ç”Ÿæˆå¸§ã€‚ è¯¥æ¨¡å‹å°†æœ€å 4 å¸§å’ŒåŠ¨ä½œä»¥åŠæ‰©æ•£å™ªå£°æ°´å¹³ä½œä¸ºæ¡ä»¶ã€‚ åœ¨ RTX 3090 ä¸Šä»¥ ~10 FPS è¿è¡Œã€‚ ä»–ä»¬ä½¿ç”¨ EDM é‡‡æ ·å™¨ä»æ‰©æ•£æ¨¡å‹ä¸­é‡‡æ ·ï¼Œå³ä½¿æ¯å¸§åªæœ‰ 1 ä¸ªæ‰©æ•£æ­¥éª¤ï¼Œå®ƒä»ç„¶å¯ä»¥å¾ˆå¥½åœ°è®­ç»ƒ RL ä»£ç†ã€‚     ç”±    /u/furrypony2718  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1g34qgx/diamond_diffusion_for_world_modeling/</guid>
      <pubDate>Mon, 14 Oct 2024 01:13:23 GMT</pubDate>
    </item>
    </channel>
</rss>