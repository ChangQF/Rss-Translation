<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>强化学习</title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>强化学习是人工智能/统计学的一个子领域，专注于探索/理解复杂环境并学习如何以最佳方式获得奖励。例如 AlphaGo、临床试验和 A/B 测试以及 Atari 游戏。</description>
    <lastBuildDate>Sat, 18 Jan 2025 21:14:38 GMT</lastBuildDate>
    <item>
      <title>支持自定义 ResNet 实现的 RL 库？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i48ulh/rl_library_that_supports_custom_resnet/</link>
      <description><![CDATA[我正在训练一个模型，以便在自定义 Gymnasium 环境中工作，使用 tf_agents 进行训练。不幸的是，tf_agents 似乎无法处理任何非直接的 NN。我可以处理多个输入，但一旦它们通过卷积层（必须是直接的），我只能一次合并它们，并且自定义选项有限。我当然不能使用 ResNet 块来尝试获得更好的结果。 是否有一个库具有与 tf_agents 相同的 RL 管理类型，可以处理这些更复杂的 NN 方案？我宁愿使用依赖于 Keras/Tensorflow 的东西，但如果这是除了自己构建之外的唯一选择，我可能会被说服切换到 PyTorch。显然，我宁愿使用现成的东西，而不是自己动手。   提交者    /u/Usual_Macaron8477   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i48ulh/rl_library_that_supports_custom_resnet/</guid>
      <pubDate>Sat, 18 Jan 2025 14:37:27 GMT</pubDate>
    </item>
    <item>
      <title>关于 TD3 的问题</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i3twt1/question_about_td3/</link>
      <description><![CDATA[在 TD3 的原始实现中，更新 q 函数时，您会使用 TD 目标的目标策略。但是，更新策略时，您使用的是 q 函数，而不是目标 q 函数。这是为什么呢？    提交人    /u/nyesslord   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i3twt1/question_about_td3/</guid>
      <pubDate>Fri, 17 Jan 2025 23:29:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建强化学习代理来玩《塞尔达传说》</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i3t4nt/p_building_an_reinforcement_learning_agent_to/</link>
      <description><![CDATA[  由    /u/DarkAutumn  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i3t4nt/p_building_an_reinforcement_learning_agent_to/</guid>
      <pubDate>Fri, 17 Jan 2025 22:52:32 GMT</pubDate>
    </item>
    <item>
      <title>当前最先进的连续动作空间方法是什么？（相当于 2024 个 SAC）</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i3l41q/what_is_the_current_state_of_the_art_method_for/</link>
      <description><![CDATA[大家好！ 我最后一次深入研究强化学习是使用 SAC（软演员评论家：https://arxiv.org/abs/1801.01290）。当时它是​​ q 学习的“最先进”方法，其中动作空间可以是连续的。 我已经关注了 3 到 4 年，目前最先进的等效方法（和论文）是什么？ 谢谢！    提交人    /u/creeky123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i3l41q/what_is_the_current_state_of_the_art_method_for/</guid>
      <pubDate>Fri, 17 Jan 2025 17:04:19 GMT</pubDate>
    </item>
    <item>
      <title>创建/包装移动机器人环境时的最佳实践？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i3c2ov/best_practices_when_creatingwrapping_mobile_robot/</link>
      <description><![CDATA[我目前正在使用 HoloOcean 模拟器在海洋机器人环境中实现 rl。我想在他们的模拟器之上构建一个自定义环境，并在不同的框架中实现观察和操作（例如，相对于移位/旋转的世界框架的观察）。 是否有专门针对移动机器人/无人机构建和包装环境的资源/教程？    提交人    /u/Electric-Diver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i3c2ov/best_practices_when_creatingwrapping_mobile_robot/</guid>
      <pubDate>Fri, 17 Jan 2025 08:42:43 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以学习模仿学习？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i3bm39/where_i_can_learn_imitation_learning/</link>
      <description><![CDATA[大家好， 我对强化学习和所有算法（包括 SAC、DDPG、DQN 等）都有很好的了解。我正在寻找一些模仿学习方面的指导，有人可以帮助我学习这个吗？    提交人    /u/Dizzy-Importance9208   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i3bm39/where_i_can_learn_imitation_learning/</guid>
      <pubDate>Fri, 17 Jan 2025 08:06:35 GMT</pubDate>
    </item>
    <item>
      <title>游戏相关研究方向</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i34tcn/game_related_research_directions/</link>
      <description><![CDATA[我是一名博士生，主要研究与法学硕士相关的主题。然而，我一直觉得这些与游戏相关的项目（Atari、AlphaGo）非常酷，尽管它们似乎在大型实验室中已经失宠了。我想知道在有限的计算预算下，是否还有一些相关的方向可以追求。     提交人    /u/Alternative-Gain335   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i34tcn/game_related_research_directions/</guid>
      <pubDate>Fri, 17 Jan 2025 01:18:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 vanilla 策略梯度法在连续动作空间上训练代理，不收敛</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i2v24h/training_agent_using_vanilla_poilcy_gradient/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i2v24h/training_agent_using_vanilla_poilcy_gradient/</guid>
      <pubDate>Thu, 16 Jan 2025 18:03:23 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个使用 Q-Learning 进行学习和适应的井字游戏 AI</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i2nkag/i_built_a_tic_tac_toe_ai_that_learns_and_adapts/</link>
      <description><![CDATA[我想展示并可能获得我为其制作视频的小项目的反馈，所以请告诉我您的想法！ https://www.youtube.com/watch?v=agyB8opESwA    提交人    /u/Loud-Cherry8396   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i2nkag/i_built_a_tic_tac_toe_ai_that_learns_and_adapts/</guid>
      <pubDate>Thu, 16 Jan 2025 12:13:13 GMT</pubDate>
    </item>
    <item>
      <title>第一次组装电脑时不知道该如何选择 CPU</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i2m0n6/lost_in_the_woods_regarding_cpu_choice_for_my/</link>
      <description><![CDATA[大家好， 我正在寻找一台新电脑，用于两个目的：  强化学习开发 轻度游戏  开发仅用于业余项目，与工作无关。我目前使用的是 RTX 3060 笔记本电脑，其中 GPU 是瓶颈。由于我在这个领域没有任何经验，我正在训练很多模型来研究在输入特征、批量大小等方面适合我的用例的方法…… 目前，我的 GPU 是瓶颈，只有 6gb VRAM，训练时间非常长，在有限的业余时间内这样做并不好。 这就是我决定组装一台新电脑的原因。由于资金有限，我并不是在寻找顶级规格的机器，而是想要一台可以减少训练代理等待时间的像样的机器。 我想知道是否有人使用过 Ryzen 7 9700X，这是否适合我，或者我是否最好为一些额外的核心支付一些额外的现金。互联网上充斥着关于 LLM 和游戏的评论，但关于 ML/RL 的信息却很少。 这款芯片的另一个优点是低 TDP，与市场上的其他芯片相比，我发现这很有趣。对于第一次组装 PC，我更喜欢发热量可控的产品，而不是试图烧毁我房子的 CPU。  鉴于我读到的所有问题，我想远离英特尔，但不确定它们现在是否这么糟糕，或者是否有点夸张。 TLDR： Ryzen 7 9700X 是否是 RL 开发工作 + 轻度游戏的可靠选择，或者我是否应该选择具有更多内核的其他产品？    提交人    /u/MundaneCoach   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i2m0n6/lost_in_the_woods_regarding_cpu_choice_for_my/</guid>
      <pubDate>Thu, 16 Jan 2025 10:29:01 GMT</pubDate>
    </item>
    <item>
      <title>大富翁强化学习项目</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i26zft/monopoly_reinforcement_learning_project/</link>
      <description><![CDATA[大家好，我是大学数学专业的毕业生，正在申请计量经济学和精算学统计学硕士学位。我对人工智能很感兴趣，目前我愿意在人工智能和强化学习方面做我的第一个项目，做一个人工智能模型来模拟大富翁游戏，并提供策略和交易来赢得游戏...我知道在哪里以及如何获取数据和其他东西。我想问你们，我目前需要做什么才能完成这个项目，因为我是数学专业的学生，​​对这个领域没有太多的想法，所以我希望得到一些帮助和建议！谢谢     提交人    /u/good-mathematician-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i26zft/monopoly_reinforcement_learning_project/</guid>
      <pubDate>Wed, 15 Jan 2025 20:30:47 GMT</pubDate>
    </item>
    <item>
      <title>我为 TensorFlow 和 Keras 编写了优化器</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i21sgm/i_wrote_optimizers_for_tensorflow_and_keras/</link>
      <description><![CDATA[大家好，我为 TensorFlow 和 Keras 编写了优化器，它们的使用方式与 Keras 优化器相同。 https://github.com/NoteDance/optimizers    提交人    /u/NoteDancing   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i21sgm/i_wrote_optimizers_for_tensorflow_and_keras/</guid>
      <pubDate>Wed, 15 Jan 2025 16:51:04 GMT</pubDate>
    </item>
    <item>
      <title>关于 DQN 及其变体的收敛性的问题</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i20m49/question_on_convergence_of_dqn_and_its_variants/</link>
      <description><![CDATA[大家好， 我是一名接受过 DSP 正式培训的电子工程专业学生，多年来一直在航空航天行业工作。几年前，我开始将我的视野扩展到深度学习 (DL) 和机器学习，但经验有限。几周前，我开始研究强化学习，特别是 DQN 及其变体。而且，我很惊讶地发现，即使对于像 CartPole-v1 这样的简单环境，DQN 及其变体也不能保证收敛。换句话说，当查看 Total Reward 与 Episode 的图时，它真的很丑。我这里遗漏了什么吗？    提交人    /u/Tasty_Road_3519   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i20m49/question_on_convergence_of_dqn_and_its_variants/</guid>
      <pubDate>Wed, 15 Jan 2025 16:00:26 GMT</pubDate>
    </item>
    <item>
      <title>对转学 RL 论文有什么建议吗？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i1ytan/recommendations_for_transfer_rl_papers/</link>
      <description><![CDATA[我将在迁移 RL 中做一个项目，并希望阅读一些关于该主题的最新论文。具体来说，我将尝试训练 DQN 来玩一款游戏，然后使用迁移学习将技能迁移到其他游戏中。我找到了一些调查，但如果有人对这个主题的好论文有建议，我会非常感激。    提交人    /u/TheGreatBritishNinja   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i1ytan/recommendations_for_transfer_rl_papers/</guid>
      <pubDate>Wed, 15 Jan 2025 14:40:18 GMT</pubDate>
    </item>
    <item>
      <title>奖励规范化</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i1r4dd/reward_normalization/</link>
      <description><![CDATA[我的情景环境具有非常延迟和稀疏的奖励（最后只有 1 或 0）。我可以在 DQN 算法中使用奖励规范化吗？    提交人    /u/No-Eggplant154   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i1r4dd/reward_normalization/</guid>
      <pubDate>Wed, 15 Jan 2025 06:06:15 GMT</pubDate>
    </item>
    </channel>
</rss>