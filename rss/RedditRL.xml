<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯æ—¨åœ¨æ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå’Œå­¦ä¹ å¦‚ä½•æœ€ä½³è·å¾—å¥–åŠ±çš„AI/ç»Ÿè®¡æ•°æ®çš„å­åœºã€‚ä¾‹å¦‚Alphagoï¼Œä¸´åºŠè¯•éªŒå’ŒA/Bæµ‹è¯•ä»¥åŠAtariæ¸¸æˆã€‚</description>
    <lastBuildDate>Thu, 27 Feb 2025 21:16:53 GMT</lastBuildDate>
    <item>
      <title>â€œåŸ¹è®­è¯­è¨€æ¨¡å‹ï¼Œç”¨äºé€šè¿‡å¤šæœºæ„å¢å¼ºå­¦ä¹ å­¦ä¹ â€ï¼ŒSarkarç­‰2025</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1izkjoi/training_language_models_for_social_deduction/</link>
      <description><![CDATA[ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/gwern       [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1izkjoi/training_language_models_for_social_deduction/</guid>
      <pubDate>Thu, 27 Feb 2025 16:59:12 GMT</pubDate>
    </item>
    <item>
      <title>å›½é™…è±¡æ£‹æ ·å“æ•ˆç‡äººä¸sota rl</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1izimy7/chess_sample_efficiency_humans_vs_sota_rl/</link>
      <description><![CDATA[From what I know, SOTA chess RL like AlphaZero reached GM level after training on many more games than a human GM played throughout their lives before becoming GM Even if u include solved puzzles, incomplete games, and everything in between, humans reached GM with much lesser games than SOTA RL did (pls correct me if I&#39;m wrong aboutè¿™ï¼‰ã€‚ æ˜¯å¦æœ‰æ¯”äººç±»æ•ˆç‡è¾ƒä½çš„ç‰¹å®šåŸå› /éšœç¢ï¼Ÿå¯¹äºæé«˜å›½é™…è±¡æ£‹SOTA RLæ ·æœ¬æ•ˆç‡çš„ç ”ç©¶æ˜¯å¦æœ‰å¸Œæœ›ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/aliaslight     [link]       [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1izimy7/chess_sample_efficiency_humans_vs_sota_rl/</guid>
      <pubDate>Thu, 27 Feb 2025 15:40:39 GMT</pubDate>
    </item>
    <item>
      <title>ç¦»çº¿RLçš„åŠ¨ä½œå°†æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1izhryd/what_will_the_action_be_in_offline_rl/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æ‰€ä»¥ï¼Œæˆ‘æ˜¯RLçš„æ–°æ‰‹ï¼Œæˆ‘å¿…é¡»å®ç°ç¦»çº¿RLæ¨¡å‹ï¼Œç„¶ååœ¨åœ¨çº¿RLé˜¶æ®µä¸­å¾®è°ƒå®ƒã€‚ä»æˆ‘çš„æ‰¿è¯ºä¸­ï¼Œç¦»çº¿å­¦ä¹ é˜¶æ®µæœ€åˆçš„ç­–ç•¥å’Œåœ¨çº¿å­¦ä¹ é˜¶æ®µå°†ä½¿ç”¨å®æ—¶åé¦ˆæ¥å®Œå–„æ”¿ç­–ã€‚å¯¹äºç¦»çº¿å­¦ä¹ é˜¶æ®µï¼Œæˆ‘å°†æœ‰ä¸€ä¸ªæ•°æ®é›†d = {ï¼ˆsiï¼Œaiï¼Œriï¼‰}ã€‚æ•°æ®é›†ä¸­æ¯ä¸ªç¤ºä¾‹çš„æ“ä½œæ˜¯å¦æ˜¯æ”¶é›†æ•°æ®æ—¶é‡‡å–çš„åŠ¨ä½œï¼ˆå³ä¸“å®¶è¡ŒåŠ¨ï¼‰ï¼Ÿè¿˜æ˜¯æ‰€æœ‰å¯èƒ½çš„åŠ¨ä½œï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/saffarini9     [link]    ï¼†ï¼ƒ32;   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1izhryd/what_will_the_action_be_in_offline_rl/</guid>
      <pubDate>Thu, 27 Feb 2025 15:03:21 GMT</pubDate>
    </item>
    <item>
      <title>[ä»˜è´¹]å¯»æ‰¾æœ‰äººåœ¨RL NASHå·®å¼‚æ¸¸æˆä¸Šç¼–å†™å¿«é€ŸPythonç¨‹åº</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1izgmws/paid_looking_for_someone_to_write_a_quick_python/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä½ å¥½ï¼Œæˆ‘æ­£åœ¨å¯»æ‰¾ä¸€ä¸ªä¸ºé›¶å’Œéé›¶å’Œnash nashå·®å¼‚æ¸¸æˆç¼–å†™pythonç¨‹åºçš„pythonç¨‹åºã€‚  å¯¹äºç†Ÿç»ƒçš„äººæ¥è¯´ï¼Œè¿™åº”è¯¥æ˜¯ä¸€ä¸ªå°æ—¶çš„å·¥ä½œã€‚æ„¿æ„ä¸ºæ¼”å‡ºæ”¯ä»˜50ç¾å…ƒã€‚ç»™æˆ‘å‘æ¶ˆæ¯ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/used_chapter007     [link]   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1izgmws/paid_looking_for_someone_to_write_a_quick_python/</guid>
      <pubDate>Thu, 27 Feb 2025 14:10:05 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘è¢«å›°åœ¨ç“¶é¢ˆä¸Šï¼Œæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1izdx0j/i_am_stuck_at_a_bottleneck_any_suggestions_to/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘æ­£åœ¨ä½¿ç”¨ç§°ä¸ºRwareçš„RLç¯å¢ƒã€‚å®ƒç»™å‡ºäº†RGBæ•°ç»„ï¼Œä½†ä»…åœ¨æ¸²æŸ“çª—å£åæ‰æä¾›ã€‚å› æ­¤ï¼Œæˆ‘çš„åŸ¹è®­éœ€è¦å¤§é‡æ—¶é—´ã€‚æ˜¯å¦æœ‰ä»»ä½•æƒ³æ³•ç»•è¿‡æˆ–è·³è¿‡æ¸²æŸ“ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/decter_prune_9756      [link]  &lt;a href =â€œ https://www.reddit.com/r/reinforecctionlearning/comments/1izdx0j/i_am_astuck_at_a_bottleneck_any_suggestions_to//]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1izdx0j/i_am_stuck_at_a_bottleneck_any_suggestions_to/</guid>
      <pubDate>Thu, 27 Feb 2025 11:48:05 GMT</pubDate>
    </item>
    <item>
      <title>è·¨é¢†åŸŸçš„å‡‰çˆ½è‡ªæˆ‘æ ¡æ­£æœºåˆ¶ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iywf0w/cool_selfcorrecting_mechanisms_across_fields/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä»æ§åˆ¶ç†è®ºçš„åé¦ˆå¾ªç¯å’Œå¡å°”æ›¼è¿‡æ»¤åˆ°è‡ªç„¶é€‰æ‹©ï¼ŒDNAä¿®å¤ï¼Œå¤šæ•°æŠ•ç¥¨å’Œå¼•å¯¼ - æ— æ•°çš„æ–¹å¼ç³»ç»Ÿè‡ªæˆ‘æ ¡æ­£é”™è¯¯ï¼Œå°¤å…¶æ˜¯å½“åœ°é¢çœŸç†æœªçŸ¥æ—¶ï¼æƒ³çŸ¥é“æ‚¨é‡åˆ°çš„æœ‰è¶£çš„è‡ªæˆ‘çº æ­£æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Œæ— è®ºæ˜¯è‡ªç„¶ç•Œï¼Œå“²å­¦ï¼Œå·¥ç¨‹è¿˜æ˜¯ä»¥åï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/neat_comparison_2726      [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iywf0w/cool_selfcorrecting_mechanisms_across_fields/</guid>
      <pubDate>Wed, 26 Feb 2025 19:48:15 GMT</pubDate>
    </item>
    <item>
      <title>ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨GRPOï¼ˆ5GB VRAMæœ€å°å€¼ï¼‰è®­ç»ƒè‡ªå·±çš„æ¨ç†æ¨¡å‹ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iyw9ly/you_can_now_train_your_own_reasoning_model_using/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œå¾ˆæ£’çš„äººï¼ç¬¬ä¸€ç¯‡æ–‡ç« åœ¨è¿™é‡Œï¼ä»Šå¤©ï¼Œæˆ‘å¾ˆé«˜å…´åœ°å®£å¸ƒï¼Œæ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨grpo +ä½¿ç”¨Grpo +æˆ‘ä»¬çš„å¼€æ”¾å¼é¡¹ç›®unsplothä½¿ç”¨5GB VRAMè®­ç»ƒè‡ªå·±çš„æ¨ç†æ¨¡å‹ï¼š httpsï¼š&gt; httpsï¼š&gt;æ˜¯DeepSeek-R1èƒŒåçš„ç®—æ³•ä»¥åŠå¦‚ä½•å—è¿‡è®­ç»ƒã€‚å®ƒæ¯”PPOæ›´æœ‰æ•ˆï¼Œæˆ‘ä»¬è®¾æ³•å°†VRAMä½¿ç”¨é™ä½äº†90ï¼…ã€‚æ‚¨éœ€è¦ä¸€ä¸ªå¤§çº¦500è¡Œï¼Œç­”æ¡ˆå¯¹å’Œå¥–åŠ±åŠŸèƒ½çš„æ•°æ®é›†ï¼Œç„¶åå¯ä»¥å¯åŠ¨æ•´ä¸ªè¿‡ç¨‹ï¼ è¿™å…è®¸å°†ä»»ä½•å¼€æ”¾çš„LLMï¼ˆå¦‚Llameï¼ŒMisstralï¼ŒPhiç­‰ï¼‰ç­‰å¼€æ”¾ï¼Œå¯ä»¥å°†å…¶è½¬æ¢ä¸ºå…·æœ‰é“¾é“¾è¿‡ç¨‹çš„æ¨ç†æ¨¡å‹ã€‚å…³äºGRPOçš„æœ€å¥½çš„éƒ¨åˆ†æ˜¯ï¼Œä¸æ›´å¤§çš„å‹å·ç›¸æ¯”ï¼Œä¸æ›´å¤§çš„è®­ç»ƒæ—¶é—´ç›¸æ¯”ï¼Œä¸è¾ƒå¤§çš„è®­ç»ƒæ—¶é—´ç›¸æ¯”ï¼Œä¸è¾ƒå¤§çš„å‹å·ç›¸æ¯”ï¼Œè®­ç»ƒå°å‹å‹å·ä¸è¾ƒå¤§çš„å‹å·æ— å…³ç´§è¦ï¼Œå› æ­¤æœ€ç»ˆç»“æœå°†éå¸¸ç›¸ä¼¼ï¼æ‚¨ä¹Ÿå¯ä»¥åœ¨æ‰§è¡Œå…¶ä»–æ“ä½œçš„åŒæ—¶ï¼Œåœ¨PCçš„èƒŒæ™¯ä¸‹è¿›è¡ŒGRPOåŸ¹è®­ï¼  ç”±äºæˆ‘ä»¬æ–°æ·»åŠ çš„æœ‰æ•ˆçš„GRPOç®—æ³•ï¼Œè¿™ä½¿å¾— 10xæ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦é•¿åº¦  90ï¼…ä½¿ç”¨ 90ï¼…çš„vram  vram/strong&gt; vraM/strong&gt; lora/qlora/qula li&gt; li afteraive  li&gt; field afteraiment &lt;0&gt; æ ‡å‡†GRPOè®¾ç½®ï¼ŒLlama 3.1ï¼ˆ8bï¼‰20Kä¸Šä¸‹æ–‡é•¿åº¦çš„åŸ¹è®­éœ€è¦510.8GBçš„VRAMã€‚ä½†æ˜¯ï¼ŒUnsplothçš„90ï¼…VRAMå‡å°‘çš„è¦æ±‚ä½¿åŒä¸€è®¾ç½®ä¸­çš„éœ€æ±‚ä»…ä¸º54.3GBã€‚ æˆ‘ä»¬åˆ©ç”¨æˆ‘ä»¬çš„æ¸å˜â€æ£€æŸ¥ algorithmï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªaLgorithmã€‚å®ƒå¯ä»¥å·§å¦™åœ°å°†ä¸­é—´æ¿€æ´»å¸è½½åˆ°ç³»ç»ŸRAMå¼‚æ­¥ï¼ŒåŒæ—¶ä»…æ…¢1ï¼…ã€‚æ­¤å‰ƒé¡»372GB VRAM ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦num \ _ generations = 8ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸­é—´æ¢¯åº¦ç´¯ç§¯è¿›ä¸€æ­¥å‡å°‘æ­¤å†…å­˜ä½¿ç”¨ã€‚ ä½¿ç”¨Googleçš„å…è´¹ä¸Šä¸‹æ–‡ä½¿ç”¨æˆ‘ä»¬çš„GRPO Notebookï¼Œä½¿ç”¨Googleçš„å…è´¹gpusï¼š href =â€œ https://colab.research.google.com/github/unslothai/notebooks/blob/blob/main/nb/llama3.1_(8Bâ€&gt; llama 3.1ï¼ˆ8bï¼‰on colab  -grpo.ipynbï¼‰ä»¥åŠæ›´å¤šï¼š align =â€œ leftâ€&gt; metric   unsploth   trl + fa2           training Moregre Costï¼ˆGBï¼‰ align =â€œå·¦â€&gt; 414GB      grpoå†…å­˜æˆæœ¬ï¼ˆgbï¼‰   9.8gb    78.3gb  78.3gb  78.3gb    0gb   16gb      æ¨ç†20Kä¸Šä¸‹æ–‡ï¼ˆGBï¼‰   2.5GB  2.5gb  æ€»å†…å­˜ä½¿ç”¨   54.3GBï¼ˆå°‘90ï¼…ï¼‰       510.8GB              æˆ‘ä»¬åœ¨æ‰€æœ‰æ–¹é¢éƒ½èŠ±äº†å¾ˆå¤šæ—¶é—´ï¼ˆpboty&gt;  ï¼šd   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/yoracale     [link]   [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iyw9ly/you_can_now_train_your_own_reasoning_model_using/</guid>
      <pubDate>Wed, 26 Feb 2025 19:41:48 GMT</pubDate>
    </item>
    <item>
      <title>ç­–åˆ’å¯å¡‘æ€§æŸå¤±çš„è®ºæ–‡æ¸…å•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iyrtge/curated_list_of_papers_on_plasticity_loss/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å—¨ï¼Œ æˆ‘å·²ç»åˆ›å»ºäº†ä¸€ä¸ªå­˜å‚¨åº“ï¼Œå…¶ä¸­åŒ…å«æœ‰å…³å¯å¡‘æ€§æŸå¤±çš„è®ºæ–‡åˆ—è¡¨ã€‚é‡ç‚¹æ˜¯æ·±åº¦RLï¼Œä½†æ˜¯é‚£é‡Œä¹Ÿæœ‰ä¸€äº›æŒç»­çš„å­¦ä¹ ã€‚  httpsï¼š//github.com/github.com/github.com/probabilistic--interactive-mlaw---interactive-mlaw yourplastive yourplastive plapery plapery plapery  æˆ‘ä»¬è¿˜åœ¨æ’°å†™æœ‰å…³è¯¥ä¸»é¢˜çš„è°ƒæŸ¥ï¼Œä½†ä»å¤„äºæ—©æœŸé˜¶æ®µï¼šå¾ˆå¤šç‰µå¼•åŠ›ï¼Œæˆ‘å¸Œæœ›è¿™å¯ä»¥å¸®åŠ©äººä»¬åŠ å¿«é€Ÿåº¦ï¼šï¼‰  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/timo_kk     [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iyrtge/curated_list_of_papers_on_plasticity_loss/</guid>
      <pubDate>Wed, 26 Feb 2025 16:40:39 GMT</pubDate>
    </item>
    <item>
      <title>ä»¥éå¸¸æŠ˜æ‰£ä»·çš„å›°æƒ‘pro</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iykcbt/perplexity_pro_at_a_very_discounted_price/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  ä»»ä½•æœ‰å…´è¶£ä»¥50ï¼…æŠ˜æ‰£ä»·è·å¾—å›°æƒ‘Proçš„äººï¼Œè¯·ä¸æˆ‘è”ç³»  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/u/u/beast_of_iit    href =â€œ https://www.reddit.com/r/reinforevercylearning/comments/1iykcbt/perplexity_pro_at_a_very_very_very_very_very_very_very_discounted_price/â€&gt; [link]    [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iykcbt/perplexity_pro_at_a_very_discounted_price/</guid>
      <pubDate>Wed, 26 Feb 2025 10:15:47 GMT</pubDate>
    </item>
    <item>
      <title>RLä»£ç†å½“å‰åœ¨ä¸æ¿€åŠ±ç‰¹å®šè¡Œä¸ºçš„æƒ…å†µä¸‹æœ€ä½³æ‰§è¡Œçš„æœ€å¤æ‚ç¯å¢ƒæ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iyi6ev/what_is_the_most_complex_environment_in_which_rl/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘å¾ˆæƒ³çŸ¥é“sotaåœ¨ç¯å¢ƒå¤æ‚æ€§æ–¹é¢ï¼Œåœ¨ä¸éœ€è¦ä»»ä½•ä¸­çº§å¥–åŠ±çš„æƒ…å†µä¸‹ï¼ŒRLä»£ç†æ‰§è¡Œçš„æ€§èƒ½ - åªæ˜¯+1 +1 forâ€œ winâ€å’Œ-1ä¸ºâ€œæŸå¤±â€   &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32; /u/aliaslight     [link]     32;   [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iyi6ev/what_is_the_most_complex_environment_in_which_rl/</guid>
      <pubDate>Wed, 26 Feb 2025 07:34:50 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆæŸäº›ç¯å¢ƒï¼ˆä¾‹å¦‚Minecraftï¼‰å¤ªå›°éš¾äº†ï¼Œè€Œå¦ä¸€äº›ç¯å¢ƒï¼ˆä¾‹å¦‚Openai's Hide N See Seekï¼‰æ˜¯å¯è¡Œçš„ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iygakk/why_are_some_environments_like_minecraft_too/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;   tldrï¼šæ˜¯ä»€ä¹ˆè®©hide nå¯»æ±‚å¯è§£å†³çš„ç¯å¢ƒï¼Œä½†æ˜¯æˆ‘å¾ˆéš¾è§£å†³çš„æˆ‘çš„minecraftæˆ–ç®€åŒ–çš„Minecraftç¯å¢ƒï¼Ÿ æˆ‘æ²¡æœ‰é‡åˆ°ä»»ä½•RLä»£ç†åœ¨Minecraftä¸­æˆåŠŸç”Ÿå­˜çš„ä»»ä½•RLä»£ç†ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœæ ¹æ®ä»£ç†å•†çš„æ´»åŠ›æ¥ç»™äºˆå¥–åŠ±ï¼Œå®ƒè‡³å°‘åº”è¯¥ä¸ºé£Ÿç‰©å»ºç«‹åº‡æŠ¤æ‰€å’Œå†œåœºã€‚ ï¼Œ ï¼ŒOpenaiçš„hide n of from 5å¹´å‰ä»5å¹´å‰å¼€å§‹å¯»æ±‚è§†é¢‘ï¼Œä»åˆ’ç—•ä¸­ï¼Œåœ¨é‚£ä¸ªç¯å¢ƒä¸­å­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ï¼Œç”šè‡³æ²¡æœ‰æ¿€åŠ±ä»»ä½•è¡Œä¸ºã€‚ä¸ºä»€ä¹ˆä¸é€‚ç”¨äºMinecraftï¼Ÿæœ‰ä¸€ä¸ªæ›´å®¹æ˜“çš„ç¯å¢ƒç§°ä¸ºæ‰‹å·¥è‰ºè€…ï¼Œä½†å³ä½¿æ˜¯è¿™æ ·çš„å¥–åŠ±ä¼¼ä¹æ˜¯è¿™æ ·è®¾è®¡çš„ï¼Œä»¥è‡³äºæœ€ä½³è¡Œä¸ºè¢«æ¿€åŠ±ï¼Œè€Œä¸ä»…ä»…æ˜¯åŸºäºç”Ÿå­˜çš„å¥–åŠ±ï¼Œè€Œæœ€ä½³ç»©æ•ˆï¼ˆDreamerï¼‰ä»ç„¶æ²¡æœ‰ä¸äººç±»çš„ç»©æ•ˆç›¸æ¯”ã€‚ æ˜¯ä»€ä¹ˆè®©hide nå¯»æ±‚å¯è§£å†³çš„ç¯å¢ƒï¼Œä½†å¯ä»¥è§£å†³ï¼Œä½†å¯ä»¥è§£å†³ï¼Œä½†æ˜¯æ˜¯å¦‚æ­¤ï¼Œä½†æ˜¯å¦‚æ­¤éš¾ä»¥è§£å†³çš„æˆ–ç®€åŒ–çš„Minecraftç¯å¢ƒï¼Œä»¥æ±‚è§£Minecraft solveï¼Ÿæäº¤ç”±ï¼†ï¼ƒ32; /u/aliaslight     [link]   [æ³¨é‡Š] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iygakk/why_are_some_environments_like_minecraft_too/</guid>
      <pubDate>Wed, 26 Feb 2025 05:29:58 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨æ·±RLçš„è‡ªæˆ‘æ ‡è®°æ±½è½¦</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iya5jf/selfparking_car_using_deep_rl/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  æˆ‘æƒ³è®­ç»ƒä¸€ä¸ªPPOå‹å·ä»¥å¹¶è¡Œåœè½¦ï¼Œå¯æˆåŠŸåœ°å°†è½¦åœåœ¨æ±½è½¦ä¸Šã€‚ä½ ä»¬çŸ¥é“æˆ‘å¯ä»¥ä¸ºæ­¤ç›®çš„ä½¿ç”¨çš„ä»»ä½•æ¨¡æ‹Ÿç¯å¢ƒå—ï¼Ÿå¦å¤–ï¼Œè®­ç»ƒè¿™æ ·çš„æ¨¡å‹ä¼šå¾ˆé•¿å—ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/reinforevercylearning/comments/1iya5jf/selfparking_car_used_usis_deep_rl/â€‹â€‹â€&gt; [link]   [æ³¨é‡Š]   ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iya5jf/selfparking_car_using_deep_rl/</guid>
      <pubDate>Wed, 26 Feb 2025 00:12:17 GMT</pubDate>
    </item>
    <item>
      <title>äº‹åç»éªŒé‡æ’­ï¼ˆå¥¹ï¼‰è¡¨ç°çš„ä¸»è¦è´¡çŒ®è€…æ˜¯ä»€ä¹ˆ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iy1ta1/what_is_the_primary_contributor_to_hindsight/</link>
      <description><![CDATA[Hello, I have been studying Hindsight Experience Replay (HER) recently, and Iâ€™ve been examining the mechanism by which HER significantly improves performance in sparse reward environments. In my view, HER enhances performance in two aspects:  Enhanced Exploration:  In sparse rewardç¯å¢ƒï¼Œå¦‚æœä»£ç†æœªèƒ½è¾¾åˆ°æœ€åˆçš„ç›®æ ‡ï¼Œå®ƒå‡ ä¹æ— æ³•è·å¾—ä»»ä½•å¥–åŠ±ï¼Œå¯¼è‡´ç¼ºä¹å­¦ä¹ ä¿¡å·å¹¶è¿«ä½¿ä»£ç†ç»§ç»­éšæœºè¿›è¡Œéšæœºæ¢ç´¢ã€‚ å¥¹é€šè¿‡ä½¿ç”¨æœ€ç»ˆçŠ¶æ€ä½œä¸ºç›®æ ‡æ¥é‡æ–°å®šä¹‰ç›®æ ‡ï¼Œè¿™ä½¿å¾—ä»£ç†å¯ä»¥é€šè¿‡å®é™…ä¸Šå¯ä»¥ä»è¯¥è¿‡ç¨‹ä¸­å¯ç”¨çš„å„ä¸ªè¿‡ç¨‹æ¥è·å¾—è‰¯å¥½çš„èŒƒå›´ã€‚     ç­–ç•¥æ¦‚æ‹¬ï¼š  å¥¹å°†ç›®æ ‡ä¸å›½å®¶ä¸€èµ·èå…¥äº†ç½‘ç»œçš„è¾“å…¥ä¸­ï¼Œä½¿æ”¿ç­–èƒ½å¤Ÿæœ‰æ¡ä»¶åœ°å­¦ä¹ ï¼Œä»¥å®ç°å·å’Œè§„å®šçš„ç›®æ ‡ã€‚  å› æ­¤ï¼Œé€šè¿‡æ•è·å„ç§ç›®æ ‡ä¹‹é—´çš„å…³ç³»å¹¶æ²¡æœ‰ç›´æ¥å®ç°çš„ç›®æ ‡ï¼Œä»æŸç§ç¨‹åº¦ä¸Šæ¥å®ç°ã€‚       åœ¨è¿™äº›ç‚¹ä¸Šï¼Œæˆ‘å¾ˆå¥½å¥‡å“ªä¸ªå› ç´  - åœ¨å¥¹çš„èŒƒå›´æˆ–æ”¿ç­–æ™®éçš„é—®é¢˜ä¸Šï¼Œæˆ‘åœ¨å¦‚æœçŠ¶æ€ç©ºé—´ä¸ºr  2 &lt; /sup&gt;ï¼Œç›®æ ‡æ˜¯ï¼ˆ2,2ï¼‰ï¼Œä½†æ˜¯ä»£ç†äººæ°å¥½ä»…åœ¨ç¬¬äºŒä¸ªè±¡é™å†…æ¢ç´¢ï¼Œåˆ™æœ€ç»ˆçŠ¶æ€å°†è¢«é™åˆ¶åœ¨è¯¥åœ°åŒºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ”¿ç­–å¯èƒ½å¾ˆéš¾å°†å…¶æ¨å¹¿åˆ°æ¢ç´¢åŒºåŸŸä¹‹å¤–çš„ï¼ˆ2,2ï¼‰ä¹‹ç±»çš„ç›®æ ‡ã€‚è¿™æ ·çš„é™åˆ¶ä¼šå¦‚ä½•å½±å“å¥¹çš„è¡¨ç°ï¼Ÿæäº¤ç”±ï¼†ï¼ƒ32; /u/drlc_     [link]    [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iy1ta1/what_is_the_primary_contributor_to_hindsight/</guid>
      <pubDate>Tue, 25 Feb 2025 18:20:38 GMT</pubDate>
    </item>
    <item>
      <title>Qå­¦ä¹ ï¼ŒæŠ˜æ‰£ç³»æ•°ä¸º0ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixzkgs/qlearning_with_a_discount_factor_of_0/</link>
      <description><![CDATA[&lt;ï¼ -  sc_off-&gt;  å—¨ï¼Œæˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªé¡¹ç›®ï¼Œä»¥å®ç°Q-å­¦ä¹ çš„ä»£ç†ã€‚æˆ‘åªæ˜¯æ„è¯†åˆ°å¯¹ç¯å¢ƒï¼ŒçŠ¶æ€å’ŒåŠ¨ä½œè¿›è¡Œäº†é…ç½®ï¼Œå› æ­¤å½“å‰çš„è¡ŒåŠ¨ä¸ä¼šå½±å“æœªæ¥çš„çŠ¶æ€æˆ–å¥–åŠ±ã€‚æˆ‘è®¤ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŠ˜ç°å› å­åº”è¯¥ç­‰äºé›¶ï¼Œä½†æ˜¯æˆ‘ä¸çŸ¥é“Qå­¦ä¹ ä»£ç†æ˜¯å¦æœ‰æ„ä¹‰è§£å†³æ­¤ç±»é—®é¢˜ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œå®ƒæ¯”MDPæ›´åƒæ˜¯ä¸Šä¸‹æ–‡çš„å¼ºç›—é—®é¢˜ã€‚ Qå­¦ä¹ ç®—æ³•çš„åç§°ä¸º0ï¼Œæˆ–ç­‰æ•ˆç®—æ³•ï¼Ÿ  &lt;ï¼ -  sc_on-&gt;ï¼†ï¼ƒ32;æäº¤ç”±ï¼†ï¼ƒ32;æ€href =â€œ https://www.reddit.com/r/reinforevericeslearning/comments/1ixzkgs/qlearning_with_a_a_discount_factor_of_0/â€&gt; [link]        [æ³¨é‡Š]  ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixzkgs/qlearning_with_a_discount_factor_of_0/</guid>
      <pubDate>Tue, 25 Feb 2025 16:50:04 GMT</pubDate>
    </item>
    <item>
      <title>ç°åœ¨ï¼Œå¢å¼ºå‹å¥—å›¾æ”¯æŒPPOï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ixq4nc/reinforceuistudio_now_supports_ppo/</link>
      <description><![CDATA[       &lt;ï¼ -  sc_off-&gt;  å˜¿ï¼Œå¤§å®¶ï¼Œ  renforceui-studioç°åœ¨åŒ…æ‹¬æ¥è¿‘ç­–ç•¥ä¼˜åŒ–ï¼ˆppoï¼‰ï¼ğŸš€ href=&quot;https://www.reddit.com/r/reinforcementlearning/comments/1imtu96/introducing_reinforceui_studio_eliminates_the/&quot;&gt;here), I introduced ReinforceUI-Studio as a tool to make training RL models easier. I received many requests for PPO, and it&#39;s finally here!å¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œè¯·æ£€æŸ¥ä¸€ä¸‹ï¼Œè®©æˆ‘çŸ¥é“æ‚¨çš„æƒ³æ³•ã€‚å¦å¤–ï¼Œä¿æŒç®—æ³•è¯·æ±‚çš„åˆ°æ¥ - æ‚¨çš„åé¦ˆæœ‰åŠ©äºä½¿å·¥å…·å˜å¾—æ›´å¥½ï¼  æ–‡æ¡£ï¼š https://docs.reinforceui-studio.com/algorithms/algorithm_list/algorithm_list  href =â€œ https://github.com/dvalenciar/reinforceui-studioâ€&gt; https://github.com/dvalenciar/reinforceui-studio       &lt;ï¼æäº¤ç”±ï¼†ï¼ƒ32; /u/u/dvr_dvr     [link]        [æ³¨é‡Š]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ixq4nc/reinforceuistudio_now_supports_ppo/</guid>
      <pubDate>Tue, 25 Feb 2025 08:18:11 GMT</pubDate>
    </item>
    </channel>
</rss>