<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 03 Jan 2024 21:12:23 GMT</lastBuildDate>
    <item>
      <title>æŒç»­å¼ºåŒ–å­¦ä¹ çš„å®šä¹‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xu67t/a_definition_of_continual_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.11046 OpenReviewï¼šhttps:// /openreview.net/forum?id=ZZS9WEWYbD æ‘˜è¦ï¼š  åœ¨å¼ºåŒ–å­¦ä¹ é—®é¢˜çš„æ ‡å‡†è§†å›¾ä¸­ï¼Œä»£ç†çš„ç›®æ ‡æ˜¯æœ‰æ•ˆåœ°ç¡®å®šæœ€å¤§åŒ–é•¿æœŸå›æŠ¥çš„ç­–ç•¥ã€‚ç„¶è€Œï¼Œè¿™ç§è§‚ç‚¹æ˜¯åŸºäºä¸€ç§æœ‰é™çš„è§‚ç‚¹ï¼Œå³å­¦ä¹ æ˜¯å¯»æ‰¾è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯å°†å­¦ä¹ è§†ä¸ºæ— ä¼‘æ­¢çš„é€‚åº”ã€‚ç›¸åï¼ŒæŒç»­å¼ºåŒ–å­¦ä¹ æ˜¯æŒ‡æœ€å¥½çš„æ™ºèƒ½ä½“æ°¸è¿œä¸ä¼šåœæ­¢å­¦ä¹ çš„ç¯å¢ƒã€‚å°½ç®¡æŒç»­å¼ºåŒ–å­¦ä¹ å¾ˆé‡è¦ï¼Œä½†ç¤¾åŒºç¼ºä¹ä¸€ä¸ªç®€å•çš„é—®é¢˜å®šä¹‰æ¥å¼ºè°ƒå…¶æ‰¿è¯ºå¹¶ä½¿å…¶ä¸»è¦æ¦‚å¿µå‡†ç¡®æ¸…æ™°ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è‡´åŠ›äºä»”ç»†å®šä¹‰æŒç»­å¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚æˆ‘ä»¬å°†â€œæ°¸ä¸åœæ­¢å­¦ä¹ â€çš„ä»£ç†æ¦‚å¿µæ­£å¼åŒ–ã€‚é€šè¿‡ä¸€ç§æ–°çš„æ•°å­¦è¯­è¨€æ¥åˆ†æå’Œç¼–ç›®ä»£ç†ã€‚ä½¿ç”¨è¿™ç§æ–°è¯­è¨€ï¼Œæˆ‘ä»¬å°†æŒç»­å­¦ä¹ ä»£ç†å®šä¹‰ä¸ºå¯ä»¥æ— é™æœŸåœ°æ‰§è¡Œéšå¼æœç´¢è¿‡ç¨‹çš„ä»£ç†ï¼Œå¹¶å°†æŒç»­å¼ºåŒ–å­¦ä¹ å®šä¹‰ä¸ºæœ€ä½³ä»£ç†éƒ½æ˜¯æŒç»­å­¦ä¹ ä»£ç†çš„è®¾ç½®ã€‚æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªæ¿€åŠ±æ€§çš„ä¾‹å­ï¼Œè¯´æ˜å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ å’ŒæŒç»­ç›‘ç£å­¦ä¹ çš„ä¼ ç»Ÿè§‚ç‚¹æ˜¯æˆ‘ä»¬å®šä¹‰çš„ç‰¹ä¾‹ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›å®šä¹‰å’Œè§‚ç‚¹å½¢å¼åŒ–äº†å­¦ä¹ æ ¸å¿ƒçš„è®¸å¤šç›´è§‚æ¦‚å¿µï¼Œå¹¶å¼€è¾Ÿäº†å›´ç»•æŒç»­å­¦ä¹ ä»£ç†çš„æ–°ç ”ç©¶é€”å¾„ã€‚    ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xu67t/a_definition_of_continual_reinforcement_learning/</guid>
      <pubDate>Wed, 03 Jan 2024 21:09:29 GMT</pubDate>
    </item>
    <item>
      <title>æš‘æœŸå®ä¹ åœ¨ RL/Embodied AI é¢†åŸŸå¤„äºé¢†å…ˆåœ°ä½ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xos1z/summer_internship_leads_in_rlembodied_ai_space/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ‰¾ 2024 å¹´æš‘æœŸå®ä¹ çš„ä¸€äº›çº¿ç´¢ï¼Œä»¥å¯»æ‰¾æ½œåœ¨çš„ï¼ˆå¦‚æœå¯èƒ½çš„è¯ç ”ç©¶ï¼‰å®ä¹ æœºä¼šã€‚ æˆ‘ä¸æ˜¯éå¸¸äº†è§£åœ¨è¿™ä¸ªé¢†åŸŸå·¥ä½œçš„æ‰€æœ‰åˆåˆ›å…¬å¸/ç»„ç»‡ï¼Œå› ä¸ºæˆ‘è‡ªå·±å¯¹å®ƒéå¸¸é™Œç”Ÿã€‚æˆ‘æ²¡æœ‰å¤ªå¤šç»éªŒï¼Œä½†å¸Œæœ›åœ¨è¿™äº›å®ä¹ ä¸­è·å¾—ä¸€äº›ç»éªŒã€‚å¦‚æœæœ‰ä»»ä½•å¸®åŠ©ï¼Œæˆ‘ä»¬å°†ä¸èƒœæ„Ÿæ¿€ï¼   ç”±   æäº¤ /u/gchhablani   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xos1z/summer_internship_leads_in_rlembodied_ai_space/</guid>
      <pubDate>Wed, 03 Jan 2024 17:33:56 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘å¦‚ä½•è·å¾—ç ”ç©¶æƒ³æ³•ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xlwli/how_do_i_get_ideas_for_research/</link>
      <description><![CDATA[äº‹æƒ…çš„ç®€çŸ­ç‰ˆæœ¬ï¼šæˆ‘æ˜¯ä¸€å CS ç¡•å£«ç”Ÿã€‚æˆ‘å·²ç»å®Œæˆäº†ä¸€å¹´åŠçš„å°è¯•å¹¶åŠªåŠ›è¿›å…¥ EAI é¢†åŸŸã€‚æˆ‘è¿˜æœ‰å¤§çº¦ä¸€å¹´çš„æ—¶é—´ï¼Œæˆ‘æƒ³å……åˆ†åˆ©ç”¨è¿™ä¸€å¹´ã€‚æˆ‘æœ‰ä¸€äº› NLP ä¸“ä¸šèƒŒæ™¯ï¼Œä¹Ÿæœ‰ä¸€äº›ç ”ç©¶ç»éªŒï¼Œä½†ä¸æ˜¯å¾ˆæ·±å…¥ã€‚æˆ‘äº†è§£ç›‘ç£å­¦ä¹ ï¼Œå¹¶ä¸”æ“…é•¿ PyTorch ä¹‹ç±»çš„ä¸œè¥¿ã€‚æˆ‘ç›®å‰é¢ä¸´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š  æˆ‘æƒ³å‘è¡¨ä¸€äº›ç¬¬ä¸€ä½œè€…çš„ä½œå“ï¼Œä½†æ— æ³•è·å¾—å¼ºå¤§çš„åˆ›é€ åŠ›åœ¨æˆ‘ä½“å†…æµæ·Œã€‚æˆ‘è¯¥å¦‚ä½•å¼€å‘å®ƒï¼Ÿ æˆ‘æƒ³ä»è¯­è¨€ç†è§£æ–¹é¢æ”»å‡» RL çš„å„ä¸ªæ–¹é¢ï¼Œä½†å„ä¸ªæ–¹é¢çš„ç ”ç©¶éƒ½åœ¨ç–¯ç‹‚å¢é•¿ï¼ˆLLMã€VLMï¼‰ ã€RLã€å˜å½¢é‡‘åˆšï¼‰ï¼Œæˆ‘å¾ˆéš¾ç†è§£è¯¥è¯»ä»€ä¹ˆã€ä¸è¯¥è¯»ä»€ä¹ˆã€‚  æ¥è‡ªè¯¥é¢†åŸŸæœ‰ç»éªŒçš„äººçš„ä»»ä½•æƒ³æ³•æˆ–æç¤ºç±»ä¼¼é—®é¢˜æˆ–åªæ˜¯æœ‰è¶³å¤Ÿçš„ç»éªŒï¼Ÿ å¦‚æœè¿™ä¸æ˜¯åˆé€‚çš„è®ºå›ï¼Œè¯·æŒ‡å‡ºæˆ‘å¯ä»¥è®¨è®ºæ­¤é—®é¢˜çš„åœ°æ–¹ã€‚ &lt;!-- SC_ON - -&gt;  ç”±   æäº¤ /u/gchhablani   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xlwli/how_do_i_get_ideas_for_research/</guid>
      <pubDate>Wed, 03 Jan 2024 15:24:28 GMT</pubDate>
    </item>
    <item>
      <title>RLç©æ¸¸æˆï¼šä»å“ªé‡Œå¼€å§‹ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xk6a8/rl_to_play_games_where_to_start/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯åŠ¨ä¸€ä¸ªæœ‰è¶£çš„é¡¹ç›®ï¼Œè®­ç»ƒ AI ç© 2 ç§ç±»å‹çš„æ¸¸æˆï¼š - 1v1 æ¸¸æˆè”ç›Ÿ/Dota é£æ ¼ï¼ŒåŸºäºå›¾åƒçš„è¾“å…¥  - 1v1 å›åˆåˆ¶æ¸¸æˆï¼Œç©å®¶åœ¨å•å…ƒæ ¼ä¸Šç§»åŠ¨å¹¶æ‹¥æœ‰ä¸€å †å’’è¯­ï¼Œå…·æœ‰åŸºäºç‰¹å¾çš„è¾“å…¥ æ‰€ä»¥æˆ‘è¯»è¿‡ Atariã€AlphaGo/Starã€OpenAI Five...æƒ³çŸ¥é“äººä»¬æ˜¯å¦æœ‰å…¶ä»–/è¾ƒæ–°çš„å‚è€ƒèµ„æ–™æˆ–ç›¸å…³é¡¹ç›®ï¼Œåœ¨è¿™äº›æƒ…å†µä¸‹æœ€å¥½ä½¿ç”¨å“ªç§ç±»å‹çš„ç®—æ³•ï¼Ÿè¿‡å»æˆ‘åªåœ¨æ‰€æœ‰äº‹æƒ…ä¸Šä½¿ç”¨ PPOã€‚ æˆ‘è¿˜è®¡åˆ’è‡ªå·±ç¼–å†™æ¸¸æˆä»£ç ï¼ˆåœ¨éå¸¸åŸºç¡€çš„æ°´å¹³ä¸Šï¼‰ - æƒ³çŸ¥é“äººä»¬æ˜¯å¦å·²ç»è¿™æ ·åšäº†å¹¶ä¸”å¯¹ä½¿ç”¨ä»€ä¹ˆè¯­è¨€/æ¡†æ¶æœ‰å»ºè®®ä»¥æœ€å¤§é€Ÿåº¦å†™å…¥æ¸¸æˆã€‚æˆ‘æœ€è¿‘çœ‹åˆ°äº† Madrona Engineï¼Œçœ‹èµ·æ¥å¾ˆæœ‰è¶£ï¼Œä½†æˆ‘è¿˜æ²¡æœ‰å°è¯•è¿‡ã€‚ é¡ºä¾¿è¯´ä¸€å¥ï¼Œåˆ°ç›®å‰ä¸ºæ­¢æˆ‘åªæ˜¯è‡ªå·±åš RLï¼Œæœ‰æ²¡æœ‰å¤§å‹çš„ RL ç¤¾åŒºé™¤äº†è¿™ä¸ª Reddit å­ç‰ˆå—ä¹‹å¤–è¿˜åº”è¯¥çŸ¥é“ä»€ä¹ˆï¼Ÿè°¢è°¢ä½ ï¼ :)   ç”±   æäº¤/u/frenchhusky  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xk6a8/rl_to_play_games_where_to_start/</guid>
      <pubDate>Wed, 03 Jan 2024 14:05:40 GMT</pubDate>
    </item>
    <item>
      <title>é€†å‘å¼ºåŒ–å­¦ä¹ çš„ç°çŠ¶ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xjndc/current_state_of_inverse_reinforcement_learning/</link>
      <description><![CDATA[ ç”±   æäº¤/u/Professional_Card176   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xjndc/current_state_of_inverse_reinforcement_learning/</guid>
      <pubDate>Wed, 03 Jan 2024 13:40:46 GMT</pubDate>
    </item>
    <item>
      <title>ç”¨äºæ§åˆ¶å™¨è°ƒä¼˜ inn python çš„ env</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xgqu8/env_for_controller_tuning_inn_python/</link>
      <description><![CDATA[       è¿™é‡Œæœ‰äººå°è¯•è¿‡ä½¿ç”¨ RL åœ¨ python ä¸­è¿›è¡Œ PI/PID æ§åˆ¶å™¨è°ƒæ•´ å¦‚æœå¯ä»¥çš„è¯ï¼Œæ‚¨å¯ä»¥æä¾›æ‚¨çš„ env æ–‡ä»¶æˆ–å¸®åŠ©æˆ‘åˆ›å»ºç›¸åŒçš„ç¯å¢ƒã€‚&lt; /p&gt; ï¼ˆç¯å¢ƒç”±ä»£ç†ã€æºã€ç³»ç»Ÿæ¨¡å‹ä»¥åŠç³»ç»Ÿè¾“å‡ºåˆ°æºçš„åé¦ˆç»„æˆï¼‰  /u/Wide-Chef-7011   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xgqu8/env_for_controller_tuning_inn_python/</guid>
      <pubDate>Wed, 03 Jan 2024 10:57:38 GMT</pubDate>
    </item>
    <item>
      <title>è¡°å‡å‰ªè¾‘å› å­å’Œç†µæŸå¤±æƒé‡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xevbt/decaying_clip_factor_and_entropy_loss_weight/</link>
      <description><![CDATA[æœ‰æ²¡æœ‰åŠæ³•å¯ä»¥å°†è¡°å‡ç†µæŸå¤±æƒé‡å’Œè£å‰ªå› å­åˆå¹¶åˆ° matlab ä¸­çš„ PPO ç®—æ³•ä¸­ï¼Ÿ æˆ‘çŸ¥é“ Rl matlab æœ‰é—®é¢˜ï¼Œä½†å¦‚æœå¯èƒ½çš„è¯ä»ç„¶å­˜åœ¨    ç”±   æäº¤ /u/Wide-Chef-7011   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xevbt/decaying_clip_factor_and_entropy_loss_weight/</guid>
      <pubDate>Wed, 03 Jan 2024 08:51:34 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦githubé¡¹ç›®çš„åˆä½œè€…ï¼ˆè‚¡ç¥¨äº¤æ˜“çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18x0vtz/need_collaborator_for_github_project_deep/</link>
      <description><![CDATA[â€‹ æœ‰äººæœ‰å…´è¶£åˆä½œå¼€å‘ä¸€ä¸ªä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ è¿›è¡Œè‚¡ç¥¨äº¤æ˜“çš„ Python åº“é¡¹ç›®å—ï¼Ÿ  æ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ° github å­˜å‚¨åº“ï¼šhttps://github.com/RezaSoleymanifar/neuralHFT â€‹ è¿™æ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„é¡¹ç›®ï¼Œç›®å‰æœ‰è¶…è¿‡ 15,000 è¡Œä»£ç å¤„ç†ç«¯åˆ°ç«¯çš„æ‰€æœ‰äº‹åŠ¡ï¼Œä»è¿æ¥åˆ°äº¤æ˜“ APIã€ä¸‹è½½å†å²æ•°æ®ã€æ•°æ®é›†åˆ›å»ºã€DRLç®—æ³•/ç½‘ç»œè®¾è®¡ã€è®­ç»ƒå¹¶æœ€ç»ˆéƒ¨ç½²åœ¨äº¤æ˜“è´¦æˆ·ä¸­ã€‚  â€‹ æˆ‘è®¡åˆ’åœ¨ ICAIF 2024ï¼ˆACM AI in Financeï¼‰ä¼šè®®ä¸Šå‘è¡¨ä¸€ç¯‡å…³äºè¿™ä¸ªåº“çš„è®ºæ–‡ã€‚å¦‚æœæ‚¨æ˜¯å­¦è€…ï¼Œè¿™æ˜¯æˆ‘ä»¬å¯ä»¥è®¨è®ºçš„å¦ä¸€ä¸ªé€”å¾„ã€‚   ç”±   æäº¤ /u/RezaSoleymanifar   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18x0vtz/need_collaborator_for_github_project_deep/</guid>
      <pubDate>Tue, 02 Jan 2024 21:27:53 GMT</pubDate>
    </item>
    <item>
      <title>MARL ä¸­çš„é€šç”¨å…¨å±€å¥–åŠ±ä¸ä¸ªäººå¥–åŠ±</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18x0o5k/common_global_reward_vs_individual_reward_in_marl/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è§£å†³ä¸€ä¸ªé—®é¢˜ï¼Œå…¶ä¸­æœ‰ 2 ä¸ªæ™ºèƒ½ä½“åœ¨ä¸€ä¸ªåŸŸä¸­ç§»åŠ¨ï¼Œæ ¹æ®å¥–åŠ±å‡½æ•°çš„æœ€ä½³æ–¹æ³•æ˜¯ï¼šå¦ä¸€ä¸ªä»£ç†äººã€‚å› æ­¤ï¼Œå®ƒä»¬é¢„è®¡ä¼šæ±‡èšæˆå›´ç»•å½¼æ­¤ç»•åœˆç§»åŠ¨ã€‚å¥–åŠ±å‡½æ•°åŸºäºå„è‡ªçš„ä»£ç†ï¼Œå®Œå…¨ç‹¬ç«‹äºå…¶ä»–ä»£ç†ã€‚  åœ¨æƒ…å†µ1ä¸­ï¼Œä»–ä»¬åªå…³å¿ƒè‡ªå·±çš„å¥–åŠ±ï¼Œå³ä»£ç†1çš„å¥–åŠ±æ˜¯r1ï¼Œä»£ç†2çš„å¥–åŠ±æ˜¯r2ã€‚åœ¨æƒ…å†µ2ä¸­ï¼Œä»–ä»¬å¾—åˆ°ç›¸åŒçš„å¥–åŠ±ï¼Œè¿™æ˜¯ä»–ä»¬ä¸¤ä¸ªå¥–åŠ±çš„å¹³å‡å€¼ï¼Œå³r_common = (r1+r2)/2ã€‚åœ¨æƒ…å†µ 2 ä¸­ï¼Œå®ƒä»¬æœ€ç»ˆåªä¼šäº’ç›¸ç»•åœˆã€‚ä½†æ˜¯ï¼Œæˆ‘é¢„è®¡å®ƒä»¬éƒ½ä¼šæ”¶æ•›åˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“æœ€å¤§åŒ–è‡ªå·±çš„ä¸ªäººå¥–åŠ±ä¹Ÿåº”è¯¥å¯¼è‡´ä»–ä»¬äº’ç›¸è·Ÿéšç»•åœˆã€‚æœ‰äººèƒ½ç»™æˆ‘ä»»ä½•è§è§£å—ï¼Ÿ ç¼–è¾‘ä»¥æ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯   ç”±   æäº¤/u/aish2995  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18x0o5k/common_global_reward_vs_individual_reward_in_marl/</guid>
      <pubDate>Tue, 02 Jan 2024 21:19:28 GMT</pubDate>
    </item>
    <item>
      <title>DQL æ²¡æœ‰æ”¹å–„</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18wwsxt/dql_not_improving/</link>
      <description><![CDATA[æˆ‘å°è¯•ä»å¤´å¼€å§‹å®ç°è›‡æ·±åº¦ Q å­¦ä¹ ï¼Œä½†å®ƒä¼¼ä¹æ²¡æœ‰æ”¹è¿›ï¼Œä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆã€‚ä»»ä½•å¸®åŠ©æˆ–å»ºè®®æˆ–æç¤ºéƒ½ä¼šæœ‰å¸®åŠ©ã€‚ é“¾æ¥https://colabã€‚ Research.google.com/drive/1H3VdTwS4vAqHbmCbQ4iZHytvULpi9Lvz?usp=sharing é€šå¸¸æˆ‘ä½¿ç”¨ Jupyter Notebookï¼Œgoogle colab åªæ˜¯ä¸ºäº†å…±äº« ä¸ºæˆ‘è‡ªç§çš„è¯·æ±‚é“æ­‰ï¼Œ æå‰è‡´è°¢   ç”±   æäº¤/u/Witty_Fan_5776   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18wwsxt/dql_not_improving/</guid>
      <pubDate>Tue, 02 Jan 2024 18:45:23 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å¼€å§‹ä¸º Steam æ¸¸æˆåˆ›å»ºè‡ªå®šä¹‰ç¯å¢ƒï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18wt4pf/how_would_one_even_begin_to_create_a_custom/</link>
      <description><![CDATA[æˆ‘æœ€è¿‘å¯¹ â€‹â€‹rl æœ‰äº†æ›´å¤šçš„äº†è§£ï¼Œè¿™è®©æˆ‘å¯¹åˆ›å»ºä¸€ä¸ªå¯ä»¥ç©ç”µè„‘æ¸¸æˆçš„ä»£ç†çš„æ½œåŠ›æ„Ÿåˆ°å¥½å¥‡ã€‚å”¯ä¸€çš„é—®é¢˜æ˜¯æˆ‘ä»€è‡³ä¸çŸ¥é“åˆ›é€ ç¯å¢ƒæ˜¯å¦å¯è¡Œã€‚ç„¶è€Œï¼Œä»¥å‰åœ¨ã€ŠDOTAã€‹å’Œã€Šç«ç®­è”ç›Ÿã€‹ç­‰æ¸¸æˆä¸­å°±å·²ç»åšè¿‡è¿™æ ·çš„äº‹æƒ…ï¼Œè¿™è®©æˆ‘æƒ³çŸ¥é“ä»–ä»¬æ˜¯å¦‚ä½•åšåˆ°çš„ã€‚æˆ‘å¾ˆå¥½å¥‡æ˜¯å¦æœ‰ä¸€ç§å®é™…çš„æ–¹æ³•å¯ä»¥è®¾ç½®å¸¦æœ‰çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±çš„ç¯å¢ƒçš„æµè¡Œæ¸¸æˆï¼Ÿ   ç”±   æäº¤/u/Scruffy004   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18wt4pf/how_would_one_even_begin_to_create_a_custom/</guid>
      <pubDate>Tue, 02 Jan 2024 16:17:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] å¤§è¯­è¨€æ¨¡å‹ä¸–ç•Œå›½é™…è±¡æ£‹é”¦æ ‡èµ›ğŸ†â™Ÿï¸ (GPT-4 > Gemini-Pro)</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18wez9h/r_large_language_models_world_chess_championship/</link>
      <description><![CDATA[ ç”±   æäº¤ /u/gwern   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18wez9h/r_large_language_models_world_chess_championship/</guid>
      <pubDate>Tue, 02 Jan 2024 03:11:03 GMT</pubDate>
    </item>
    <item>
      <title>é¢å¤–è®­ç»ƒ RL ç®—æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18w7vf0/additional_training_a_rl_algorithm/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è®­ç»ƒ RL æ¨¡å‹ã€‚æˆ‘æƒ³çŸ¥é“æ˜¯å¦å¯ä»¥è®©æ¨¡å‹ä¸€æ¬¡ä»…ä½¿ç”¨ä¸€ä¸ªå¥–åŠ±å‡½æ•°è¿›è¡Œå­¦ä¹ ï¼Œç„¶åå–æ¶ˆæ³¨é‡Šå¹¶ä½¿å…¶ä½¿ç”¨å¦ä¸€ä¸ªäº’æ–¥çš„å‡½æ•°è¿›è¡Œå­¦ä¹ ï¼Ÿç†è®ºä¸Šå¯è¡Œå—ï¼Œæˆ‘å¦‚ä½•åœ¨ä»£ç ä¸­å®ç°å®ƒã€‚  æˆ‘æ˜¯æ–°æ‰‹ã€‚ æˆ‘çš„è®­ç»ƒåˆ¶åº¦ï¼š Name = rf&#39;Agents_Allignment{SimulationVariables[&quot;SimAgents&quot;]}_PPO_{SimulationVariables [â€œLearningTimeStepsâ€]}&#39; env = DummyVecEnv([lambda: FlockingEnv()]) model = PPO(â€œMlpPolicyâ€, env,tensorboard_log=â€œ./ppo_Agents_tensorboard/â€, verbose=1) model.learn( Total_timesteps=SimulationVariables[â€œLearningTimeStepsâ€]) # è°ƒæ•´ä¹˜æ•° # ä¿å­˜æ¨¡å‹ model.save(Name) env.close() # åŠ è½½æ¨¡å‹ env = FlockingEnv() model = PPO.load(Name) # è¿è¡Œ 10èŒƒå›´å†…å‰§é›†çš„å‰§é›†ï¼ˆ1ï¼ŒRLVariables[&#39;Episodes&#39;]ï¼‰ï¼šobs = env.resetï¼ˆï¼‰å®Œæˆ=é”™è¯¯å¥–åŠ±= 0 Position_dict = {iï¼š[] for i in rangeï¼ˆlenï¼ˆenv.agentsï¼‰ï¼‰}æ—¶é—´æ­¥é•¿= 0reward_log=[] print(â€œEpisodeâ€,episode) # å®Œæˆæ¡ä»¶ while((timestep &lt;=SimulationVariables[â€œEvalTimeStepsâ€]) and (not did)): action, state = model.predict(obs) obs,reward,done,info = env.step(action) ######### env.step() #æ·»åŠ ç¢°æ’é€€å‡ºæ¡ä»¶reward_log.append(reward) print(reward) for i, agent in enumerate(env.agents): Positions_dict[i].append(agent.position.tolist()) with open(rf&#39;{Results[&quot;EpRewards&quot;]}_Allignment_{episode}.json&#39;, &#39;w&#39;) as f : json.dump(reward_log, f, indent=4) timestep = timestep + 1 # print(reward_log) with open(rf&#39;agent_positionsTestAllignment_{episode}.json&#39;, &#39;w&#39;) as f: #æ·»åŠ åˆ°å‚æ•°æ–‡ä»¶ json. dump(positions_dict, f, indent=4) env.close()  â€‹   ç”±   æäº¤/u/Sadboi1010   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18w7vf0/additional_training_a_rl_algorithm/</guid>
      <pubDate>Mon, 01 Jan 2024 21:53:51 GMT</pubDate>
    </item>
    <item>
      <title>COOMï¼šæŒç»­å¼ºåŒ–å­¦ä¹ çš„æ¸¸æˆåŸºå‡†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18w24o8/coom_a_game_benchmark_for_continual_reinforcement/</link>
      <description><![CDATA[è®ºæ–‡ï¼šhttpsï¼š //openreview.net/forum?id=qmCxdPkNsa ä»£ç ï¼šhttps ://github.com/hyintell/COOM è§†é¢‘ï¼šhttps://www.youtube.com/watch?v=FUm2B8MZ6d0 æ‘˜è¦ï¼š  è¿›æ­¥æŒç»­å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸€ç›´é¢ä¸´ç€å„ç§éšœç¢ï¼ŒåŒ…æ‹¬æ ‡å‡†åŒ–çš„æŒ‡æ ‡å’Œè¯„ä¼°åè®®ã€è‹›åˆ»çš„è®¡ç®—è¦æ±‚ä»¥åŠç¼ºä¹å¹¿æ³›æ¥å—çš„æ ‡å‡†åŸºå‡†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†COOMï¼ˆContinual DOOMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºåŸºäºåƒç´ çš„å¼ºåŒ–å­¦ä¹ é‡èº«å®šåˆ¶çš„è¿ç»­å¼ºåŒ–å­¦ä¹ åŸºå‡†ã€‚ COOM æä¾›äº†ä¸€å¥—åœ¨è§†è§‰ä¸Šä¸åŒçš„ 3D ç¯å¢ƒä¸­ç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡åºåˆ—ï¼Œä½œä¸ºä¸€ä¸ªå¼ºå¤§çš„è¯„ä¼°æ¡†æ¶æ¥è¯„ä¼°æŒç»­å¼ºåŒ–å­¦ä¹ çš„å…³é”®æ–¹é¢ï¼Œä¾‹å¦‚ç¾éš¾æ€§é—å¿˜ã€çŸ¥è¯†è½¬ç§»å’Œæ ·æœ¬é«˜æ•ˆå­¦ä¹ ã€‚åœ¨å¯¹æµè¡Œçš„æŒç»­å­¦ä¹ ï¼ˆCLï¼‰æ–¹æ³•è¿›è¡Œæ·±å…¥çš„å®è¯è¯„ä¼°åï¼Œæˆ‘ä»¬æŸ¥æ˜äº†å®ƒä»¬çš„å±€é™æ€§ï¼Œæä¾›äº†å¯¹åŸºå‡†çš„å®è´µè§è§£ï¼Œå¹¶å¼ºè°ƒäº†ç‹¬ç‰¹çš„ç®—æ³•æŒ‘æˆ˜ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„å·¥ä½œæˆä¸ºç¬¬ä¸€ä¸ªåœ¨å…·æœ‰å…·ä½“æ„ŸçŸ¥çš„ 3D ç¯å¢ƒä¸­å¯¹åŸºäºå›¾åƒçš„ CRL è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„å·¥ä½œã€‚ COOM åŸºå‡†çš„ä¸»è¦ç›®æ ‡æ˜¯ä¸ºç ”ç©¶ç•Œæä¾›æœ‰ä»·å€¼ä¸”å…·æœ‰æˆæœ¬æ•ˆç›Šçš„æŒ‘æˆ˜ã€‚å®ƒæ—¨åœ¨åŠ æ·±æˆ‘ä»¬å¯¹å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­å½“å‰å’Œå³å°†æ¨å‡ºçš„ CL æ–¹æ³•çš„åŠŸèƒ½å’Œå±€é™æ€§çš„ç†è§£ã€‚ä»£ç å’Œç¯å¢ƒæ˜¯å¼€æºçš„ï¼Œå¯ä»¥åœ¨ GitHub ä¸Šè®¿é—®ã€‚    ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18w24o8/coom_a_game_benchmark_for_continual_reinforcement/</guid>
      <pubDate>Mon, 01 Jan 2024 17:53:01 GMT</pubDate>
    </item>
    <item>
      <title>å…³é—­ç­–ç•¥ç­–ç•¥æ¢¯åº¦å®šç†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18w1fvv/off_policy_policy_gradient_theorem/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘çœŸçš„å¾ˆæƒ³é€è¡Œç†è§£ç¦»ç­–ç•¥ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚ æœ¬æ–‡ç”± Degris æ’°å†™ï¼Œ T.ã€æ€€ç‰¹ã€M. å’Œè¨é¡¿ï¼ŒR.S. (2012).è®ºæ–‡é“¾æ¥ï¼š(https://arxiv.org/pdf/1205.4839.pdf) å› æ­¤ï¼Œåœ¨è®ºæ–‡çš„ 2.2 èŠ‚ä¸­ï¼Œä½œè€…æŒ‡å‡ºï¼Œåœ¨ç¦»ç­–ç•¥ pg ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡çœç•¥å…¨æ¢¯åº¦å…¬å¼ä¸­çš„é™„åŠ é¡¹æ¥ä½¿ç”¨çœŸå® pg çš„è¿‘ä¼¼å€¼ã€‚  ç°åœ¨ï¼Œåœ¨é™„å½• A ä¸­ï¼Œä½œè€…è¯•å›¾é¦–å…ˆåœ¨å„å›½å…±äº«ä¸€ä¸ªå‚æ•°åŒ–æ”¿ç­–çš„å‘é‡ u çš„ä¸€èˆ¬æƒ…å†µä¸‹è¯æ˜è¿™ä¸€ç‚¹ã€‚  æˆ‘ç†è§£ç¬¬ä¸€ç‚¹ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨åœ¨ä¸åŒçŠ¶æ€å’ŒåŠ¨ä½œå¯¹è¯„ä¼°çš„åŠ æ€§æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ï¼Œæ–°å‚æ•°æœ€ç»ˆå°†ä¸ºæˆ‘ä»¬æä¾›æ›´é«˜çš„ç›®æ ‡å‡½æ•°ã€‚åœ¨æ­¤ç›®æ ‡ä¸­ï¼ŒçŠ¶æ€å’ŒåŠ¨ä½œå¯¹çš„ä»·å€¼å‡½æ•°ä¿æŒä¸å˜ï¼Œä½†æ˜¯å…·æœ‰è¾ƒé«˜ä»·å€¼çš„ $Q{\pi_u, \gamma}(s,a)$ åœ¨ $\ pi_{u&#39;, \gamma}$ã€‚  ä½†æ˜¯ï¼Œæˆ‘æ— æ³•å®Œå…¨ç†è§£ï¼Œå¹¶ä¸”æˆ‘æ­£åœ¨åŠªåŠ›ä»¥ä¸€ç§éå¸¸æ•°å­¦ä¸Šç¨³å¥çš„æ–¹å¼çœ‹å¾…å®ƒï¼Œä¸ºä»€ä¹ˆå¦‚æœæˆ‘ä»¬å¼€å§‹ä½¿ç”¨$\pi_{u&#39;, \gamma}$ ä¾æ¬¡ã€‚  æœ¬è´¨ä¸Šè®©æˆ‘å›°æƒ‘çš„æ˜¯è¯æ˜ä¸­çš„æ”¿ç­–æ”¹è¿›éƒ¨åˆ†ï¼ˆå‚è§é™„å›¾2ï¼‰ã€‚   ç”±   æäº¤ /u/Illustrious-Drop5872    reddit.com/r/reinforcementlearning/comments/18w1fvv/off_policy_policy_gradient_theorem/&quot;&gt;[é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18w1fvv/off_policy_policy_gradient_theorem/</guid>
      <pubDate>Mon, 01 Jan 2024 17:22:29 GMT</pubDate>
    </item>
    </channel>
</rss>