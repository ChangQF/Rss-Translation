<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Sat, 07 Dec 2024 03:32:07 GMT</lastBuildDate>
    <item>
      <title>PyBullet ä¸­çš„ç§¯æœ¨å¡”æ­£åœ¨å€’å¡Œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h8bnym/blocks_tower_is_collapsing_in_pybullet/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h8bnym/blocks_tower_is_collapsing_in_pybullet/</guid>
      <pubDate>Fri, 06 Dec 2024 21:02:35 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘æ˜¯ä¸æ˜¯åˆ«æ— é€‰æ‹©</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h87hx1/am_i_left_with_no_other_option/</link>
      <description><![CDATA[ROS å¤ªçƒ‚äº† æˆ‘æ˜¯ä¸€åè®¡ç®—æœºç§‘å­¦ä¸“ä¸šçš„å­¦ç”Ÿï¼Œâ€‹â€‹ä¹‹å‰åšè¿‡ä¸€äº› ROSï¼Œæˆ‘å‘ç°ä¸ºæˆ‘çš„ RL é¡¹ç›®è®¾ç½®ï¼ˆGazeboï¼‰éå¸¸çƒ¦äººã€‚æˆ‘æ²¡æœ‰ FLOSS é€‰é¡¹äº†å—ï¼Ÿ æœ‰æ²¡æœ‰åŠæ³•å¯ä»¥åœ¨æ²¡æœ‰ ROS çš„æƒ…å†µä¸‹æ¨¡æ‹Ÿç¯å¢ƒï¼Ÿ    æäº¤äºº    /u/iconic_sentine_001   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h87hx1/am_i_left_with_no_other_option/</guid>
      <pubDate>Fri, 06 Dec 2024 18:02:21 GMT</pubDate>
    </item>
    <item>
      <title>â€œå¥–åŠ±åŸºç¡€ï¼šä¸€ç§è‡ªé€‚åº”è·å–å¤šç§å¥–åŠ±ç±»å‹çš„ç®€å•æœºåˆ¶â€ï¼ŒMillidge ç­‰äººï¼Œ2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h82gh2/reward_bases_a_simple_mechanism_for_adaptive/</link>
      <description><![CDATA[   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h82gh2/reward_bases_a_simple_mechanism_for_adaptive/</guid>
      <pubDate>Fri, 06 Dec 2024 14:23:34 GMT</pubDate>
    </item>
    <item>
      <title>PPO ä»£ç†å®Œæˆç›®æ ‡ï¼Œä½†è§£é‡Šæ–¹å·®å˜å¾—æ›´ç³Ÿï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h7wwcq/ppo_agent_completing_objective_but_explained/</link>
      <description><![CDATA[      æˆ‘ç›®å‰æ­£åœ¨è®­ç»ƒä¸€ä¸ª RecurrentPPO ä»£ç†å®Œæˆä¸€ä¸ªç®€å•çš„äº¤æ˜“ä»»åŠ¡ã€‚ åŸºæœ¬ä¸Šæ¯ä¸€æ­¥å®ƒéƒ½å¯ä»¥å†³å®šæ˜¯åšç©ºè¿˜æ˜¯åšå¤šã€‚æ²¡æœ‰èŠ±å“¨çš„æŒæœ‰ã€‚ å¥–åŠ±æ˜¯æ¯ä¸ªæ—¶é—´æ­¥çš„é£é™©è°ƒæ•´å›æŠ¥ã€‚ è¾“å…¥æ˜¯æ¥è‡ªå‡ ä¸ªåŸºæœ¬ç‰¹å¾çš„ 7 ä¸ªæ ‡å‡†åŒ– pca ç‰¹å¾ã€‚ ä»£ç†ä¼¼ä¹ç†è§£äº†è¿™é¡¹ä»»åŠ¡ï¼Œå¹¶ä¸”æ‰§è¡Œå¾—ç›¸å½“å¥½ã€‚ ç„¶è€Œï¼Œè™½ç„¶å®ƒåœ¨è§£å†³ä»»åŠ¡æ–¹é¢çš„è¡¨ç°åœ¨é€æ¸æé«˜ï¼Œä½†è§£é‡Šçš„æ–¹å·®åŸºæœ¬ä¸Šè¶Šæ¥è¶Šå·®ï¼Œæˆ–è€…åœ¨ 0 é™„è¿‘æ³¢åŠ¨ã€‚ https://preview.redd.it/d8tt468ut65e1.png?width=2528&amp;format=png&amp;auto=webp&amp;s=6695e68fc80b2149fd8f47d7ce31eba0c7428cbe è¿™æ˜¯ sb3 ä¸­çš„å½“å‰ç­–ç•¥ï¼š policy_kwargs = dict( net_arch=dict(pi=[256, 256], vf=[256, 256]),activation_fn=torch.nn.Tanh,ortho_init=True,enable_critic_lstm=False,lstm_hidden_â€‹â€‹size=28,optimizer_class=AdamW,share_features_extractor=True,features_extractor_class=IdentityFeatureExtractor,ï¼‰æ¨¡å‹=RecurrentPPOï¼ˆâ€œMlpLstmPolicyâ€ï¼Œenvï¼Œverbose=0ï¼Œlearning_rate=0.00001ï¼Œn_steps=400ï¼Œbatch_size=100ï¼Œclip_range=0.2ï¼Œclip_range_vf=0.2ï¼Œent_coef=0.1ï¼Œvf_coef=0.1ï¼Œgamma=0.99ï¼Œgae_lambda=0.95ï¼Œç§å­=42ï¼Œpolicy_kwargs=policy_kwargsï¼Œtensorboard_log=log_dirï¼Œ max_grad_norm=0.5, n_epochs=4, stats_window_size=2, normalize_advantage=True)  ç»“æœï¼š RecurrentActorCriticPolicy( (features_extractor): IdentityFeatureExtractor() (pi_features_extractor): IdentityFeatureExtractor() (vf_features_extractor): IdentityFeatureExtractor() (mlp_extractor): MlpExtractor( (policy_net): Sequential( (0): Linear(in_features=28, out_features=256, bias=True) (1): Tanh() (2): Linear(in_features=256, out_features=256, bias=True) (3): Tanh() ) (value_net): Sequential( (0): Linear(in_features=28, out_features=256, bias=True) (1): Tanh() (2): Linear(in_features=256, out_features=256, bias=True) (3): Tanh() ) ) (action_net): Linear(in_features=256, out_features=2, bias=True) (value_net): Linear(in_features=256, out_features=1, bias=True) (lstm_actor): LSTM(6, 28) (critic): Linear(in_features=6, out_features=28, bias=True) )  æˆ‘æ˜¯å¦é—æ¼äº†æŸäº›å…³é”®ä¿¡æ¯ï¼Œæˆ–è€…å¦‚æœä»£ç†å®ç°äº†é¢„æœŸç›®æ ‡ï¼Œæˆ‘æ˜¯å¦ä¸åº”è¯¥å…³å¿ƒè§£é‡Šæ–¹å·®ï¼Ÿ    æäº¤äºº    /u/Educational_Study553   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h7wwcq/ppo_agent_completing_objective_but_explained/</guid>
      <pubDate>Fri, 06 Dec 2024 08:32:43 GMT</pubDate>
    </item>
    <item>
      <title>åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å®ç°ç«ç®­ç€é™†ï¼šUnity ä¸­çš„ 2D å’Œ 3D æ¨¡æ‹Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h7qbay/landing_rockets_with_reinforcement_learning_2d/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h7qbay/landing_rockets_with_reinforcement_learning_2d/</guid>
      <pubDate>Fri, 06 Dec 2024 02:00:22 GMT</pubDate>
    </item>
    <item>
      <title>ã€ç«èµ›ã€‘æœºå™¨äººè·‘è€…è”ç›Ÿï¼šå®æ—¶åè°ƒæ•°åƒä¸ªæœºå™¨äººï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h7m54r/competition_the_league_of_robot_runners/</link>
      <description><![CDATA[ä½ å¥½ï¼Œæœºå™¨å’Œå¼ºåŒ–å­¦ä¹ è€…ï¼ è¿™æ˜¯ä¸€é¡¹å…¬å‘Šï¼Œå‘¼åå‚åŠ  2024 å¹´æœºå™¨äººè·‘æ­¥è€…è”ç›Ÿï¼Œè¿™æ˜¯ä¸€é¡¹å¤šå­£èŠ‚ ğŸš€ ç«èµ›å’Œç ”ç©¶è®¡åˆ’ ğŸš€ ï¼Œæ—¨åœ¨è§£å†³å·¥ä¸šä¼˜åŒ–ä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ä¹‹ä¸€ï¼šå¤šæœºå™¨äººè·¯å¾„è§„åˆ’ï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸ºå¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼‰ã€‚ è¿™é¡¹æ¯”èµ›çš„çµæ„Ÿæ¥è‡ªä¾èµ–ç§»åŠ¨æœºå™¨äººæŠ€æœ¯çš„å½“å‰å’Œæ–°å…´åº”ç”¨ ğŸ¦¾ğŸ¤–ã€‚ä¾‹å¦‚ï¼Œäºšé©¬é€Šçš„è‡ªåŠ¨åŒ–ä»“åº“ï¼Œæˆåƒä¸Šä¸‡çš„æœºå™¨äººååŒå·¥ä½œï¼Œç¡®ä¿åŒ…è£¹å®‰å…¨é«˜æ•ˆåœ°é€’é€ğŸ§¸ğŸ“¦ğŸššâ¤ï¸ã€‚ ç°åœ¨å·²è¿›å…¥ç¬¬äºŒå­£ï¼Œæ¯”èµ›ä¸»è¦å…³æ³¨ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š  ä»»åŠ¡è°ƒåº¦ï¼Œç”±æ‚¨å†³å®šå“ªä¸ªæœºå™¨äººæ‰§è¡Œå“ªé¡¹ä»»åŠ¡ã€‚ è·¯å¾„è§„åˆ’ï¼Œç”±æ‚¨åè°ƒæœºå™¨äººï¼Œä½¿å®ƒä»¬å°½å¿«åˆ°è¾¾ç›®çš„åœ°å¹¶ä¸”ä¸ä¼šå‘ç”Ÿç¢°æ’ã€‚  è¿™ä¸¤ç§è®¾ç½®éƒ½æ˜¯åœ¨çº¿å’Œå®æ—¶çš„ï¼Œè¿™æ„å‘³ç€åœ¨æ‚¨è®¡ç®—æ—¶æ—¶é’Ÿä¼šæ»´ç­”ä½œå“ã€‚åœ¨æ—¶é—´è€—å°½ä¹‹å‰ï¼Œå°½å¯èƒ½å¤šåœ°å®Œæˆä»»åŠ¡ï¼ æˆ‘ä»¬è®¤ä¸º ğŸ§  åŸºäºå­¦ä¹ çš„ç®—æ³• ğŸ§  å¯¹äºè§£å†³è¿™äº›ç±»å‹çš„é—®é¢˜æœ‰å‡ ä¸ªä¼˜åŠ¿ï¼š  å¤§è§„æ¨¡è®¡ç®—æœºå™¨äººè¿åŠ¨éœ€è¦æå¿«çš„ç­–ç•¥ï¼Œè€Œå­¦ä¹ éå¸¸é€‚åˆè¿™ç§æƒ…å†µ åŸºäºå­¦ä¹ çš„ç­–ç•¥ä¹Ÿå¾ˆå®¹æ˜“æ›´æ–°ï¼Œè¿™å¯¹äºå¤„ç†åŠ¨æ€æ‹¥å¡éå¸¸é‡è¦ æ€»æ˜¯æœ‰æ›´å¤šä»»åŠ¡ï¼Œè¿™æ„å‘³ç€æ²¡æœ‰å›ºå®šçš„å…¨å±€æœ€ä¼˜  å‚åŠ æœ¬æ¬¡æ¯”èµ›æ˜¯å‘å…¨çƒå­¦æœ¯ç•Œå’Œè¡Œä¸šä¸“å®¶å±•ç¤ºæ‚¨çš„ ğŸ’¡ ML/RL æŠ€èƒ½ ğŸ’¡ çš„å¥½æ–¹æ³•ã€‚æ¯”èµ›ç»“æŸåï¼Œé—®é¢˜å®ä¾‹å’Œæäº¤å†…å®¹å°†å¼€æºï¼Œè¿™ä¼šå¢åŠ æ‚¨çš„çŸ¥ååº¦ï¼Œé™ä½å…¶ä»–äººçš„è¿›å…¥é—¨æ§›ï¼Œå¹¶å¸®åŠ©ç¤¾åŒºæˆé•¿å’Œå­¦ä¹ ğŸ‘©â€ğŸ«ğŸ¤”ğŸ“šğŸ“ã€‚ å¯¹äºä¸‰ä¸ªä¸åŒç±»åˆ«çš„ğŸŒŸå‡ºè‰²è¡¨ç°ğŸŒŸï¼Œæˆ‘ä»¬å°†æä¾›10,000 ç¾å…ƒçš„å¥–é‡‘æ± ã€‚æˆ‘ä»¬è¿˜ä»¥ 1,000 ç¾å…ƒ AWS ç§¯åˆ†çš„å½¢å¼æä¾›åŸ¹è®­å¥–åŠ±ï¼Œä»¥å¸®åŠ©å‚ä¸è€…é™ä½çº¿ä¸‹åŸ¹è®­æˆæœ¬ğŸ˜»ã€‚ æäº¤å†…å®¹éšæ—¶å¼€æ”¾ï¼Œè¯„ä¼°ç»“æœå¯ç«‹å³åœ¨æˆ‘ä»¬çš„å®æ—¶æ’è¡Œæ¦œä¸ŠæŸ¥çœ‹ã€‚æ¯”èµ›å°†æŒç»­åˆ°ğŸ“…2025 å¹´ 2 æœˆ 16 æ—¥ğŸ“…ï¼Œç»“æœå°†äº 2025 å¹´ 3 æœˆå…¬å¸ƒã€‚ å…¥é—¨å¾ˆå®¹æ˜“ï¼æˆ‘ä»¬ä¸ºæ‚¨æä¾›æ¨¡æ‹Ÿå™¨å’Œä»£ç çº¿æŸï¼ˆâ€œå…¥é—¨å¥—ä»¶â€ï¼‰ã€è®¸å¤šç¤ºä¾‹é—®é¢˜ä»¥åŠç”¨äºæ¢ç´¢ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆçš„å¯è§†åŒ–å·¥å…·ã€‚æ‚¨è¿˜å¯ä»¥è®¿é—®å»å¹´è¡¨ç°æœ€ä½³çš„è§„åˆ’å™¨ä½œä¸ºåŸºå‡†ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™äº†è§£æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ï¼ˆwww.leagueofrobotrunners.orgï¼‰æˆ–åœ¨æ­¤å¤„å‘å¸–è¯¢é—®ï¼    æäº¤äºº    /u/robotrunnersofficial   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h7m54r/competition_the_league_of_robot_runners/</guid>
      <pubDate>Thu, 05 Dec 2024 22:44:24 GMT</pubDate>
    </item>
    <item>
      <title>è§£é‡Šæ³•å­¦ç¡•å£«å¼ºåŒ–å­¦ä¹ åŸºç¡€çŸ¥è¯†çš„æŠ€æœ¯æŒ‡å—</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h7kixk/technical_guide_explaining_the_fundamentals_of/</link>
      <description><![CDATA[       ç”±    /u/Legaltech_buff  æäº¤  [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h7kixk/technical_guide_explaining_the_fundamentals_of/</guid>
      <pubDate>Thu, 05 Dec 2024 21:34:18 GMT</pubDate>
    </item>
    <item>
      <title>ç ”ç©¶åœ¨ RL ä¸­ä½¿ç”¨ Transformer æ¶æ„çš„èµ„æº</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h7jhmk/resources_to_study_the_use_of_transformer/</link>
      <description><![CDATA[æˆ‘è¯»è¿‡å…³äºåœ¨ RL ä¸­ä½¿ç”¨ transformers çš„è°ƒæŸ¥è®ºæ–‡ï¼Œæˆ‘çŸ¥é“å®ƒä»¬æ˜¯ RL çš„ RNN æ›¿ä»£å“ã€‚è¿™äº›è®ºæ–‡å¹¶æ²¡æœ‰å¯¹å®ç°æä¾›å¤ªå¤šè§è§£ã€‚æˆ‘çŸ¥é“å†³ç­– transformersï¼Œä½†è¿™ä¸æ˜¯æˆ‘æƒ³è¦ä½¿ç”¨çš„ï¼Œå› ä¸ºå®ƒæ²¡æœ‰ä»»ä½•ç­–ç•¥ç½‘ç»œï¼Œæˆ‘æƒ³ä½¿ç”¨ RL ç®—æ³•ï¼Œä½† NN æ¶æ„å¿…é¡»ä½¿ç”¨ transformers æ¥çªå‡ºçŠ¶æ€çš„é•¿æœŸä¾èµ–æ€§ã€‚æœ‰äººç”¨è¿‡è¿™ä¸ªå—ï¼Ÿå¦‚æœæœ‰ï¼Œå¦‚æœä½ èƒ½åˆ†äº«èµ„æºä¼šå¾ˆæœ‰å¸®åŠ©ã€‚    æäº¤äºº    /u/anchit_rana   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h7jhmk/resources_to_study_the_use_of_transformer/</guid>
      <pubDate>Thu, 05 Dec 2024 20:51:38 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h772b4/reinforcement_learning_courses/</link>
      <description><![CDATA[å¯¹äºå¼ºåŒ–å­¦ä¹ ï¼Œä»¥ä¸‹å“ªé—¨è¯¾ç¨‹æ˜¯é¦–é€‰-   UCL X DeepMind â Stanford CS234 â David Silver çš„ RL è¯¾ç¨‹     æäº¤äºº    /u/momosspicy   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h772b4/reinforcement_learning_courses/</guid>
      <pubDate>Thu, 05 Dec 2024 11:28:41 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ é€‚åˆè§£å†³åˆ½å­æ‰‹æ¸¸æˆå—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6ynzs/is_reinforcement_learning_suitable_for_solving/</link>
      <description><![CDATA[åœ¨è¿‡å»çš„ 3 å‘¨é‡Œï¼Œæˆ‘ä¸€ç›´åœ¨ä½¿ç”¨ RL è¿­ä»£ä¸åŒçš„ç­–ç•¥æ¥è§£å†³ Hangman æ¸¸æˆï¼Œä½†åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘çš„å‡†ç¡®ç‡å¹¶ä¸é«˜ï¼ˆ1000 åœºæ¸¸æˆä¸­è§£å†³çš„ä¸åˆ° 100 åœºï¼‰ã€‚è¯´å®è¯ï¼Œæˆ‘å¯¹ RL çš„æ¦‚å¿µè¿˜å¾ˆé™Œç”Ÿã€‚æˆ‘ä¸€å¼€å§‹ä½¿ç”¨ Deep Q-Learning æ¡†æ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘çš„æ–¹æ³•ç›¸å½“ç®€å•ï¼š  å°†è®­ç»ƒå•è¯çš„éšè—çŠ¶æ€è½¬æ¢ä¸ºä¸¤ä¸ªå‘é‡ï¼ˆä¸€ä¸ªå¤§å°ä¸º 26 çš„äºŒè¿›åˆ¶å‘é‡ç”¨äºè·Ÿè¸ªçŒœæµ‹çš„å­—æ¯ï¼Œå¦ä¸€ä¸ªå¤§å°ä¸º 45 çš„è§„èŒƒåŒ–å‘é‡ç”¨äºè·Ÿè¸ªæ­£ç¡®çŒœæµ‹çš„å­—æ¯çš„ä½ç½®ï¼‰ï¼Œå¹¶å°†å…¶ä½œä¸ºè¾“å…¥ä¼ é€’ç»™ç¥ç»ç½‘ç»œï¼ŒåŒæ—¶ä¼ é€’å‰©ä½™çš„çŒœæµ‹æ¬¡æ•°å’Œè¦å‘ç°çš„éšè—å­—æ¯æ•°é‡ã€‚æ€»è¾“å…¥å¤§å°ä¸º 73x1ã€‚ ä»¥ 1 çš„æ¢ç´¢ç‡åˆå§‹åŒ–è®­ç»ƒå¾ªç¯ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ¢ç´¢ç‡è¡°å‡ä¸º 0.1ã€‚æ¢ç´¢éƒ¨åˆ†çš„å·¥ä½œåŸç†æ˜¯ï¼Œä½¿ç”¨è®­ç»ƒå•è¯åˆ—è¡¨ï¼Œæ ¹æ®éšè—å•è¯çš„é•¿åº¦ï¼Œä»é¢„å…ˆè®¡ç®—çš„å­—å…¸ä¸­é€‰æ‹©æœ€å¸¸è§çš„å­—æ¯ã€‚ å¯¹æ¯ä¸ªå•è¯å¼€å§‹è®­ç»ƒè¿‡ç¨‹ï¼Œæ¸¸æˆä¸€ç›´è¿›è¡Œåˆ°ä»£ç†çŒœå‡ºæ­£ç¡®çš„å•è¯æˆ–çŒœé”™ 6 æ¬¡ä¸ºæ­¢ï¼Œè®¡ç®—æŸå¤±å¹¶åœ¨æ¯æ¬¡çŒœæµ‹åæ›´æ–°å‚æ•°ã€‚å¯¹æ¯ä¸ªå•è¯é‡å¤æ­¤è¿‡ç¨‹ã€‚ä½¿ç”¨ q å­¦ä¹ ç½‘ç»œè·å¾—çš„ä¸‹ä¸€æ­¥è®¡ç®—æŸå¤±ã€‚ä¸ºåœ¨æ¯ä¸ªä¼˜åŒ–æ­¥éª¤ä¸­å®Œæˆçš„é‡æ”¾è®¾ç½®äº†æ‰¹é‡å¤§å°ã€‚ ç„¶åå°†è®­ç»ƒå¥½çš„ç½‘ç»œç”¨äºä¸€ç»„çœ‹ä¸è§çš„éªŒè¯è¯ï¼Œç„¶åä½¿ç”¨è¿™äº›è¯æ¥è¡¡é‡å‡†ç¡®æ€§ã€‚ æˆ‘ä½¿ç”¨çš„å¥–åŠ±ç»“æ„æ˜¯æ¯ä¸ªæ­£ç¡®å­—æ¯ +1ï¼Œæ¯ä¸ªé”™è¯¯å­—æ¯ -1ï¼Œå¦‚æœå•è¯çŒœå¯¹äº†åˆ™ +10ï¼Œå¦‚æœå•è¯çŒœé”™äº†åˆ™ -10ã€‚ç„¶åæˆ‘å¯¹å…¶è¿›è¡Œäº†æ›´æ–°ï¼Œä»¥ä¾¿è¿ç»­çŒœå¯¹å­—æ¯å¯è·å¾—æ›´é«˜çš„å¥–åŠ±ï¼Œè¿ç»­çŒœé”™å¯è·å¾—æ›´é«˜çš„è´Ÿå¥–åŠ±ã€‚ çŠ¶æ€å’Œå¥–åŠ±è®¡ç®—çš„æ›´æ–°æ˜¯é€šè¿‡å•ç‹¬çš„ Hangman æ¨¡å—å®Œæˆçš„ã€‚æ¯æ¬¡çŒœæµ‹æ¯ä¸ªå•è¯åéƒ½ä¼šè°ƒç”¨è¯¥æ¨¡å—ã€‚  è®­ç»ƒä» 1000 åœºæ¸¸æˆçš„ 10% å‡†ç¡®ç‡å¼€å§‹ï¼Œç„¶åéšç€æ¢ç´¢ç‡çš„ä¸‹é™ï¼Œå‡†ç¡®ç‡é™ä½åˆ° 1%ï¼Œè¿™ä¹Ÿåæ˜ åœ¨éªŒè¯ä¸­ã€‚ ç°åœ¨æˆ‘è§‰å¾—æˆ‘åšé”™äº†ã€‚ä½†ä½ ä»¬è®¤ä¸ºè¿™æ˜¯ä¸€ç§åˆé€‚çš„æ–¹æ³•å—ï¼Ÿ ç¼–è¾‘ï¼šæˆ‘é”™è¯¯åœ°è¯´æˆ‘ä½¿ç”¨ä¸¤ä¸ªäºŒè¿›åˆ¶å‘é‡å°†æœ‰å…³éšè—çŠ¶æ€çš„ä¿¡æ¯ä½œä¸ºè¾“å…¥ä¼ é€’ç»™ç¥ç»ç½‘ç»œã€‚æˆ‘å®é™…ä¸Šä¼ é€’äº†ä¸€ä¸ªäºŒè¿›åˆ¶å‘é‡å’Œä¸€ä¸ªåœ¨ 0 å’Œ 1 ä¹‹é—´æ ‡å‡†åŒ–çš„å‘é‡ã€‚    æäº¤äºº    /u/hpnr0724   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6ynzs/is_reinforcement_learning_suitable_for_solving/</guid>
      <pubDate>Thu, 05 Dec 2024 02:38:33 GMT</pubDate>
    </item>
    <item>
      <title>ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±åˆ†é…</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6u396/reward_distribution_in_offline_rl/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ä¿å®ˆ Q å­¦ä¹ å’Œ SAC æ¨¡å‹ã€‚æˆ‘çš„å¥–åŠ±åˆ†å¸ƒéå¸¸ä¸å¹³è¡¡ï¼šæ‰€æœ‰å¥–åŠ±éƒ½åœ¨ 0 åˆ° 1 ä¹‹é—´ï¼Œ95% ä½äº 0.02ï¼Œ40% ä½äº 0.001ã€‚ æˆ‘åº”è¯¥å¦‚ä½•è½¬æ¢å®ƒï¼Ÿæˆ‘ä¹‹æ‰€ä»¥é—®è¿™ä¸ªé—®é¢˜ï¼Œæ˜¯å› ä¸ºæˆ‘çš„é¢„æµ‹ Q å€¼ä¸ºè´Ÿï¼šè¿™æ²¡æœ‰æ„ä¹‰ï¼Œå› ä¸ºæ‰€æœ‰å¥–åŠ±éƒ½æ˜¯æ­£çš„ã€‚æˆ‘å·²ç»æ’é™¤äº†æ‰€æœ‰é”™è¯¯çš„å¯èƒ½æ€§ï¼ˆæˆ‘è®¤ä¸ºæ˜¯è¿™æ ·ï¼‰ã€‚æˆ‘ä¹Ÿå¾—åˆ°äº†å¸¦æœ‰éå¸¸å°æƒ©ç½šçš„è´Ÿ q å€¼ï¼ˆä»¥åŠæ²¡æœ‰æƒ©ç½šï¼šæˆ‘ç¡®å®çœ‹åˆ° q å‡½æ•°åœ¨æ½œæ°´å‰å¾ˆé•¿ä¸€æ®µæ—¶é—´éƒ½æ˜¯æ­£çš„ï¼šæ½œæ°´ä¸ q å€¼æ–¹å·®çš„å¢åŠ æœ‰å…³ï¼‰ã€‚ä»»ä½•æŒ‡é’ˆéƒ½å€¼å¾—èµèµï¼    æäº¤äºº    /u/electricsheep123   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6u396/reward_distribution_in_offline_rl/</guid>
      <pubDate>Wed, 04 Dec 2024 23:06:15 GMT</pubDate>
    </item>
    <item>
      <title>â€œæŒ‡å—ï¼šå®æ—¶äººå½¢ä»£ç†â€ï¼ŒZhang ç­‰äººï¼Œ2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6prin/guide_realtime_humanshaped_agents_zhang_et_al_2024/</link>
      <description><![CDATA[ [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6prin/guide_realtime_humanshaped_agents_zhang_et_al_2024/</guid>
      <pubDate>Wed, 04 Dec 2024 20:08:16 GMT</pubDate>
    </item>
    <item>
      <title>LoRAç ”ç©¶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6lepr/lora_research/</link>
      <description><![CDATA[æœ€è¿‘ï¼Œæˆ‘å‘ç°å…³äº LoRA æ›¿ä»£å“çš„è®ºæ–‡æ¿€å¢ã€‚æ‚¨è®¤ä¸ºäººä»¬æ­£åœ¨æ¢ç´¢å“ªäº›ç ”ç©¶æ–¹å‘ï¼Ÿ æ‚¨è®¤ä¸ºå®ƒæœ‰å¯èƒ½ä»¥æŸç§æ–¹å¼ä¸ RL ç›¸ç»“åˆå—ï¼Ÿ    æäº¤äºº    /u/KevinBeicon   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6lepr/lora_research/</guid>
      <pubDate>Wed, 04 Dec 2024 17:15:39 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆæˆ‘çš„ Q_Learning ç®—æ³•æ— æ³•æ­£å¸¸å­¦ä¹ ï¼Ÿï¼ˆæ›´æ–°ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6l4jl/why_is_my_q_learning_algorithm_not_learning/</link>
      <description><![CDATA[å—¨ï¼Œè¿™æ˜¯æˆ‘å‡ å¤©å‰çš„å¦ä¸€ç¯‡æ–‡ç« çš„åç»­æ–‡ç«  ( https://www.reddit.com/r/reinforcementlearning/comments/1h3eq6h/why_is_my_q_learning_algorithm_not_learning/ ) æˆ‘é˜…è¯»äº†æ‚¨çš„è¯„è®ºå¹¶ä¸” u/scprotz å‘Šè¯‰æˆ‘å³ä½¿æ˜¯å¾·æ–‡çš„ï¼Œæ‹¥æœ‰ä»£ç ä¹Ÿä¼šå¾ˆæœ‰ç”¨ã€‚è¿™æ˜¯æˆ‘çš„ä»£ç ï¼šhttps://codefile.io/f/F8mGtSNXMX æˆ‘é€šå¸¸ä¸ä¼šåœ¨ç½‘ä¸Šåˆ†äº«æˆ‘çš„ä»£ç ï¼Œæ‰€ä»¥å¦‚æœç½‘ç«™ä¸æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œæˆ‘å¾ˆæŠ±æ­‰ã€‚ä¸åŒçš„ç±»é€šå¸¸ä½äºä¸åŒçš„æ–‡æ¡£ä¸­ï¼ˆæ‚¨å¯ä»¥åœ¨å¯¼å…¥ä¸­çœ‹åˆ°ï¼‰ï¼Œæˆ‘è¿è¡Œ Spielï¼ˆå³æ¸¸æˆï¼‰æ–‡ä»¶æ¥å¯åŠ¨ç¨‹åºã€‚æˆ‘å¸Œæœ›è¿™ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œå¦‚æœæ‚¨å‘ç°ä»»ä½•çœ‹èµ·æ¥å¥‡æ€ªæˆ–ä¸æ­£ç¡®çš„ä¸œè¥¿ï¼Œè¯·å‘è¡¨è¯„è®ºï¼Œå› ä¸ºå°½ç®¡æœç´¢äº†å‡ ä¸ªå°æ—¶ï¼Œæˆ‘è¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°é—®é¢˜æ‰€åœ¨ã€‚    æäº¤äºº    /u/_waterstar_   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6l4jl/why_is_my_q_learning_algorithm_not_learning/</guid>
      <pubDate>Wed, 04 Dec 2024 17:04:30 GMT</pubDate>
    </item>
    <item>
      <title>é¢„è®­ç»ƒ VAE ä¸å¼ºåŒ–å­¦ä¹ æœŸé—´è®­ç»ƒçš„åŒºåˆ«</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1h6imk0/difference_between_pretrained_vaes_versus/</link>
      <description><![CDATA[      æˆ‘çš„ç›®æ ‡æ˜¯å¼€å‘ä¸€ä¸ªç”¨äº Carla æ¨¡æ‹Ÿå™¨è¿›è¡Œè‡ªåŠ¨é©¾é©¶çš„ä»£ç†ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘å®ç°äº† Soft Actor-Critic (SAC) ç®—æ³•ã€‚åœ¨å°†å›¾åƒè¾“å…¥ SAC ç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä½¿ç”¨äº†å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ (VAE)ã€‚ VAE æ²¡æœ‰ç»è¿‡é¢„è®­ç»ƒï¼Œå› ä¸ºæˆ‘å‡è®¾å®ƒä¼šåœ¨å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­å¾—åˆ°è®­ç»ƒå’Œæ”¹è¿›ã€‚è¿™ç§æ–¹æ³•æœ‰ç¼ºé™·å—ï¼Ÿå¦‚æœæœ‰ï¼Œä¸ºä»€ä¹ˆï¼Œå¦‚ä½•æ”¹è¿›ï¼Ÿæˆ‘é‡‡å–è¿™ä¸€æ­¥éª¤çš„ç†ç”±æ˜¯å—åˆ°è§‚å¯Ÿ DQN ä¸­ CNN åœ¨ Frozen Lake ç¯å¢ƒä¸­çš„ä½¿ç”¨æƒ…å†µçš„å¯å‘ã€‚æˆ‘çš„ä»£ç å¯ä»¥åœ¨ GitHub ä¸Šæ‰¾åˆ°ï¼Œä¾›æ„Ÿå…´è¶£çš„äººä½¿ç”¨ï¼šhttps://github.com/b-gtr/Soft-Actor-Critic è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªç®€å•çš„ä»£ç å·¥ä½œåŸç†è¯´æ˜ï¼š    æäº¤äºº    /u/Fair_Device_4961   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1h6imk0/difference_between_pretrained_vaes_versus/</guid>
      <pubDate>Wed, 04 Dec 2024 15:24:25 GMT</pubDate>
    </item>
    </channel>
</rss>