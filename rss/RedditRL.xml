<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>强化学习</title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>强化学习是人工智能/统计学的一个子领域，专注于探索/理解复杂环境并学习如何以最佳方式获得奖励。例如 AlphaGo、临床试验和 A/B 测试以及 Atari 游戏。</description>
    <lastBuildDate>Sun, 16 Jun 2024 06:19:49 GMT</lastBuildDate>
    <item>
      <title>使用神经网络训练人工智能驾驶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgzw93/training_an_ai_to_drive_using_neural_network/</link>
      <description><![CDATA[        提交人    /u/Flimsy_Roll_5666   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgzw93/training_an_ai_to_drive_using_neural_network/</guid>
      <pubDate>Sun, 16 Jun 2024 04:42:08 GMT</pubDate>
    </item>
    <item>
      <title>哪个 RL 库最好？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgys73/which_rl_library_is_best/</link>
      <description><![CDATA[我们正在寻求为一个项目实现一个自定义的 RL 环境。该环境相当复杂，涉及机场滑行布局，以分析飞机的滑行路线。对此有几个问题 -   哪个框架最适合这个？我们已经尝试使用 OpenAI Gym 的 stable-baselines3，但感觉非常受限。还看到了一些其他 RL 库，如 Acme、Ray (Rllibs) 等。 上述所有库是否都支持自定义环境，以及它对用户的友好程度如何？     提交人    /u/Strange-Durian3382   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgys73/which_rl_library_is_best/</guid>
      <pubDate>Sun, 16 Jun 2024 03:32:55 GMT</pubDate>
    </item>
    <item>
      <title>“选择的单位和级别”，SEP</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgxtco/units_and_levels_of_selection_sep/</link>
      <description><![CDATA[  由    /u/gwern  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgxtco/units_and_levels_of_selection_sep/</guid>
      <pubDate>Sun, 16 Jun 2024 02:34:58 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能搜索：更惨痛的教训”，麦克劳林（回顾 Leela Zero 与 Stockfish 的较量，以及在解决法学硕士问题时钟摆摆回搜索问题）</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgxmnj/ai_search_the_bitterer_lesson_mclaughlin/</link>
      <description><![CDATA[       由    /u/gwern  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgxmnj/ai_search_the_bitterer_lesson_mclaughlin/</guid>
      <pubDate>Sun, 16 Jun 2024 02:23:47 GMT</pubDate>
    </item>
    <item>
      <title>“新兴世界表征：探索在综合任务上训练的序列模型”，li 等人，2022 年（Othello GPT 从动作中学习游戏的世界模型）</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgw9ak/emergent_world_representations_exploring_a/</link>
      <description><![CDATA[  由    /u/gwern  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgw9ak/emergent_world_representations_exploring_a/</guid>
      <pubDate>Sun, 16 Jun 2024 01:05:18 GMT</pubDate>
    </item>
    <item>
      <title>“将价值迭代网络扩展至 5000 层以实现超长期规划”，Wang 等人，2024 年</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dguw5x/scaling_value_iteration_networks_to_5000_layers/</link>
      <description><![CDATA[  由    /u/gwern  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dguw5x/scaling_value_iteration_networks_to_5000_layers/</guid>
      <pubDate>Sat, 15 Jun 2024 23:50:16 GMT</pubDate>
    </item>
    <item>
      <title>有哪些适合学习 RLHF 和 DPO 的玩具问题？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgowls/good_toy_problems_for_learning_about_rlhf_and_dpo/</link>
      <description><![CDATA[我想了解有关这些主题的更多信息，但它们通常应用于非常大的语言模型，我不想仅仅为了学习它们而使用这么大的模型和数据集。 我想知道是否有人知道某种与 cartpole 或其他东西相当的东西，但这更面向人类对序列模型的评分。    提交人    /u/radarsat1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgowls/good_toy_problems_for_learning_about_rlhf_and_dpo/</guid>
      <pubDate>Sat, 15 Jun 2024 18:56:48 GMT</pubDate>
    </item>
    <item>
      <title>“语言模型能否充当基于文本的世界模拟器？”，Wang 等人，2024 年</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgoskw/can_language_models_serve_as_textbased_world/</link>
      <description><![CDATA[  由    /u/gwern  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgoskw/can_language_models_serve_as_textbased_world/</guid>
      <pubDate>Sat, 15 Jun 2024 18:51:25 GMT</pubDate>
    </item>
    <item>
      <title>训练机器人在 MJX 中表演足球技巧</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgonk9/train_a_robot_to_do_football_tricks_in_mjx/</link>
      <description><![CDATA[        由    /u/goncalogordo  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgonk9/train_a_robot_to_do_football_tricks_in_mjx/</guid>
      <pubDate>Sat, 15 Jun 2024 18:44:47 GMT</pubDate>
    </item>
    <item>
      <title>“安全性协调不应只停留在几个代币层面”，Qi 等人，2024 年</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgkkr3/safety_alignment_should_be_made_more_than_just_a/</link>
      <description><![CDATA[  由    /u/gwern  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgkkr3/safety_alignment_should_be_made_more_than_just_a/</guid>
      <pubDate>Sat, 15 Jun 2024 15:33:03 GMT</pubDate>
    </item>
    <item>
      <title>人类生物的现实生活...足够安全吗？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgkafm/rl_for_humanoids_safe_enough/</link>
      <description><![CDATA[      看看这个视频哈哈 - 你无法像其他机器人那样仅使用紧急停止来处理故障。有希望用 RL 解决这个问题吗？ [来源：https://x.com/_wenlixiao/status/1801808951601705258?t=PyYeg362j-mzZkb73NkwKQ&amp;s=19 和 https://x.com/_wenlixiao/status/1801305252760850903?t=S2KzQzXigYI4zyOqaSydXA&amp;s=19 ]    提交人    /u/Boring_Focus_9710   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgkafm/rl_for_humanoids_safe_enough/</guid>
      <pubDate>Sat, 15 Jun 2024 15:19:43 GMT</pubDate>
    </item>
    <item>
      <title>关于 SB3/RLlib 的常见问题</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgjmfc/general_question_about_sb3rllib/</link>
      <description><![CDATA[我是 RL 新手，我想先使用 RLlib 或 SB3 来使用 PPO 训练我的代理。 这将是一个机器人项目，最终我想使用 Pytorch 和 c++ 在现实世界中运行推理，而不需要任何库（RLlib/SB3）。这能做到吗？ 此外，这些库如何进行自定义？我可以在 Pytorch 中定义自己的神经网络，然后告诉 RLlib/SB3 使用它吗？ 提前谢谢大家！    提交人    /u/FutureComedian7749   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgjmfc/general_question_about_sb3rllib/</guid>
      <pubDate>Sat, 15 Jun 2024 14:49:12 GMT</pubDate>
    </item>
    <item>
      <title>即使参与者损失的负面影响不断增加，PPO 代理仍在学习。</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgigr9/ppo_agent_is_learning_even_if_the_negative_of/</link>
      <description><![CDATA[      即使整体目标函数最初是最大化而不是最小化，我的 PPO 代理也会学习。参与者损失和总体目标函数首先增加，然后减少，最后趋于零。在整个过程中，它一直在学习它想要学习的东西。评论家损失和熵正在最小化（正如预期的那样）。原因可能是什么？附注：我知道参与者损失应该最大化，但我说的是参与者损失的负值，理想情况下应该使用 ADAM 优化器将其最小化，但事实并非如此。    提交人    /u/Low-Advertising-1892   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgigr9/ppo_agent_is_learning_even_if_the_negative_of/</guid>
      <pubDate>Sat, 15 Jun 2024 13:52:55 GMT</pubDate>
    </item>
    <item>
      <title>2024 年最好的强化学习算法是什么？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dgdtp2/what_is_the_best_reinforcement_learning_algorithm/</link>
      <description><![CDATA[自 PPO 引入以来，似乎没有出现任何突破性的 RL 算法。    提交人    /u/galaxy_hu   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dgdtp2/what_is_the_best_reinforcement_learning_algorithm/</guid>
      <pubDate>Sat, 15 Jun 2024 09:02:26 GMT</pubDate>
    </item>
    <item>
      <title>我为 Blokus 棋盘游戏创建了一个 RL 环境！</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dg3z08/i_made_an_rl_environment_for_the_board_game_of/</link>
      <description><![CDATA[我上周发现了 Blokus，非常喜欢它！所以我把它变成了一个 RL 环境。训练 RL 代理的工作正在进行中，所以请随意贡献！:)  查看/投一颗星：https://github.com/roger-creus/blokus-ai    由   提交 /u/xWh0am1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dg3z08/i_made_an_rl_environment_for_the_board_game_of/</guid>
      <pubDate>Fri, 14 Jun 2024 23:09:00 GMT</pubDate>
    </item>
    </channel>
</rss>