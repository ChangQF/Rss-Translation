<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Thu, 13 Feb 2025 06:23:57 GMT</lastBuildDate>
    <item>
      <title>ä»€ä¹ˆæ˜¯è‰¯å¥½çš„æ–‡æœ¬åˆ° Avatar è¯­éŸ³æ¨¡å‹/ç®¡é“ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1iobzs1/whats_a_good_text_to_avatar_speech_modelpipeline/</link>
      <description><![CDATA[åŸºæœ¬ä¸Šå°±æ˜¯è¿™æ ·ã€‚ä½ ä»¬æ¨èå“ªä¸ªç®¡é“æ¥ç”Ÿæˆä¸€ä¸ªå¯ä»¥è¯»å–æ–‡æœ¬çš„å¤´åƒ - æ‰€æœ‰æŠ¥å‘Šçš„å›ºå®šå¤´åƒï¼Ÿï¼ˆç†æƒ³æƒ…å†µä¸‹æ˜¯å¼€æºçš„ï¼Œå› ä¸ºæˆ‘å¯ä»¥è®¿é—® gpu é›†ç¾¤å¹¶ä¸”ä¸æƒ³ä¸ºç¬¬ä¸‰æ–¹æœåŠ¡ä»˜è´¹ - å› ä¸ºæˆ‘å°†æä¾›åˆç†çš„ä¿¡æ¯ï¼‰ã€‚     æäº¤äºº    /u/Gvascons   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1iobzs1/whats_a_good_text_to_avatar_speech_modelpipeline/</guid>
      <pubDate>Thu, 13 Feb 2025 05:25:12 GMT</pubDate>
    </item>
    <item>
      <title>Sergey Levine å¼ºåŒ–å­¦ä¹  [åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°è¿™ä¸ª]</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1io9gbn/sergey_levine_reinforcement_learning_where_can_i/</link>
      <description><![CDATA[å—¨  ä½œä¸ºåˆå­¦è€…ï¼Œæˆ‘å¸Œæœ›å¾ˆå¥½åœ°æŒæ¡ RL èƒŒåçš„æ•°å­¦ã€‚## ä½ èƒ½å‘Šè¯‰æˆ‘åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°è¿™é—¨è¯¾ç¨‹å—ï¼Ÿæ‹œæ‰˜ã€‚ ## [Sutton Barto] å¼ºåŒ–å­¦ä¹  = https://www.amazon.in/Reinforcement-Learning-Introduction-Richard-Sutton/dp/0262039249?dplnkId=c3df8b9c-8d63-4f9b-8a4e-bc601029852c è¿˜æœ‰å“ªäº›å…¶ä»–èµ„æºå€¼å¾—å…³æ³¨ï¼Ÿæ‚¨èƒ½åˆ—å‡ºä½¿ç”¨è¿‡çš„èµ„æºå—ï¼Ÿè¯· å¦å¤–  æˆ‘å¼€å§‹å­¦ä¹  MLï¼Œæƒ³é—®é—®è¿™é‡Œçš„æœ‰ç»éªŒçš„äººï¼Œå…³äºç†è§£æ¯ä¸ªç®—æ³•ï¼ˆå¦‚ K-NN/SVMï¼‰èƒŒåçš„æ•°å­¦è¯æ˜çš„è¦æ±‚ äº†è§£ç®—æ³•èƒŒåçš„æ•°å­¦çœŸçš„å¾ˆé‡è¦å—ï¼Ÿæˆ–è€…åªéœ€è§‚çœ‹è§†é¢‘ï¼Œäº†è§£å…³é”®ç‚¹ï¼Œç„¶åå¼€å§‹ç¼–ç  å­¦ä¹  ML çš„é€‚å½“æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ## ML å·¥ç¨‹å¸ˆæ˜¯å¦æ·±å…¥ç ”ç©¶äº†è¿™ä¹ˆå¤šç¼–ç ï¼Œè¿˜æ˜¯ä»–ä»¬åªæ˜¯é€šè¿‡å¯è§†åŒ–å’Œå¼€å§‹ç¼–ç æ¥ä½ä¼°å…³é”®ç‚¹ï¼Ÿ è¯·è®©æˆ‘çŸ¥é“ã€‚ï¼ˆæˆ‘åœ¨è¿™ä¸ªé¢†åŸŸæ— æœ›ï¼‰    æäº¤äºº    /u/InternationalWill912   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1io9gbn/sergey_levine_reinforcement_learning_where_can_i/</guid>
      <pubDate>Thu, 13 Feb 2025 03:02:00 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰äººæœ‰ Julia ä¸­ PPO RL çš„å·¥ä½œç¤ºä¾‹å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1invlta/anyone_have_working_examples_of_ppo_rl_in_julia/</link>
      <description><![CDATA[ä¼¼ä¹æˆ‘å‘ç°çš„æ‰€æœ‰ä»£ç åº“éƒ½å·²è¿‡æ—¶ä¸”æ— æ³•ä½¿ç”¨ã€‚     æäº¤äºº    /u/D3MZ   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1invlta/anyone_have_working_examples_of_ppo_rl_in_julia/</guid>
      <pubDate>Wed, 12 Feb 2025 16:57:19 GMT</pubDate>
    </item>
    <item>
      <title>ç›®å‰ï¼Œå‡»è´¥è¶…çº§é©¬é‡Œå¥¥ç¬¬ä¸€å…³çš„æœ€ä½³ RL æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inugiz/what_is_the_best_rl_method_for_beating_the_first/</link>
      <description><![CDATA[æˆ‘è§è¿‡ PPOã€DQN å’Œ NEATã€‚SethBling åœ¨ 2015 å¹´ä½¿ç”¨ NEAT ç¼–å†™äº†ä¸€ä¸ª RL ä»£ç†ï¼Œçœ‹èµ·æ¥å®ƒçš„è¡¨ç°æ˜¯æ‰€æœ‰ä»£ç†ä¸­æœ€å¥½çš„ã€‚åœ¨ 4 å¹´åï¼Œæˆ‘é‡æ–°å›åˆ°äº† RL é¢†åŸŸï¼Œå¹¶å¸Œæœ›ç”¨ Python å®ç°å®ƒä½œä¸ºä¸ªäººé¡¹ç›®ã€‚æˆ‘åº”è¯¥å®ç°å“ªä¸€ä¸ªï¼Ÿæœ‰æ–°æ–¹æ³•å—ï¼Ÿ    æäº¤äºº    /u/marblesandcookies   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inugiz/what_is_the_best_rl_method_for_beating_the_first/</guid>
      <pubDate>Wed, 12 Feb 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>ä½“è‚²é¦†ç¯å¢ƒä¸­çš„ä»£ç†åŠ¨æ€</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inu52e/dynamics_of_agents_from_gymnasium_environments/</link>
      <description><![CDATA[ä½ å¥½ï¼Œæœ‰äººçŸ¥é“æˆ‘å¦‚ä½•è®¿é—®å®‰å…¨å¥èº«æˆ¿ã€openai gym ä¸­çš„ä»£ç†åŠ¨æ€å—ï¼Ÿ é€šå¸¸ .step() ç›´æ¥æ¨¡æ‹ŸåŠ¨æ€ï¼Œä½†æˆ‘çš„åº”ç”¨ç¨‹åºä¸­éœ€è¦åŠ¨æ€ï¼Œå› ä¸ºæˆ‘éœ€è¦å¯¹è¿™äº›åŠ¨æ€è¿›è¡ŒåŒºåˆ†ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘éœ€è¦è®¡ç®— f(x) çš„æ¢¯åº¦å’Œ g(x) çš„æ¢¯åº¦ï¼Œå…¶ä¸­ x_dot=f(x)+g(x)uã€‚x æ˜¯çŠ¶æ€ï¼Œu æ˜¯è¾“å…¥ï¼ˆåŠ¨ä½œï¼‰ æˆ‘æ€»æ˜¯å¯ä»¥å°†å…¶è§†ä¸ºé»‘åŒ£å­å¹¶å­¦ä¹ å®ƒä»¬ï¼Œä½†æˆ‘æ›´å–œæ¬¢ç›´æ¥ä»åœ°é¢çœŸå®åŠ¨æ€ä¸­å¾—å‡ºæ¢¯åº¦ã€‚ è¯·å‘Šè¯‰æˆ‘ï¼    æäº¤äºº    /u/Limp-Ticket7808   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inu52e/dynamics_of_agents_from_gymnasium_environments/</guid>
      <pubDate>Wed, 12 Feb 2025 15:57:36 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ å’Œæœºå™¨äººæŠ€æœ¯é¢†åŸŸçš„å·¥ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1intpup/jobs_in_rl_and_robotics/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘æœ€è¿‘è·å¾—äº† RLï¼ˆæŠ€æœ¯ä¸Šæ˜¯é€†å‘ RLï¼‰çš„åšå£«å­¦ä½ï¼Œè¯¥å­¦ä½åº”ç”¨äºäººæœºåä½œã€‚æˆ‘ä½¿ç”¨è¿‡ 4 ç§ä¸åŒçš„æœºå™¨äººæ“çºµå™¨ã€4 ç§ä¸åŒçš„å¤¹æŒå™¨å’Œ 4 ç§ä¸åŒçš„ RGB-D ç›¸æœºã€‚æˆ‘çš„ä¸“é•¿åœ¨äºä½¿ç”¨æ„ŸçŸ¥åé¦ˆå­¦ä¹ æ™ºèƒ½è¡Œä¸ºï¼Œä»¥å®ç°å®‰å…¨é«˜æ•ˆçš„æ“ä½œã€‚ æˆ‘å»ºç«‹äº†ç«¯åˆ°ç«¯ç®¡é“ï¼Œç”¨äºåœ¨ä¼ é€å¸¦ä¸Šå¯¹äº§å“è¿›è¡Œåˆ†ç±»ã€åœ¨æœªå—ç²¾çš„åµå­è¿›å…¥å­µåŒ–å™¨ä¹‹å‰å¯¹å…¶è¿›è¡Œæ— æŸè¯†åˆ«å’Œç§»é™¤ã€ä½¿ç”¨æœºå™¨äººå¯¹åŒ»ç–—å™¨æ¢°è¿›è¡Œæ™ºèƒ½æ— èŒå¤„ç†ï¼Œä»¥åŠå…¶ä»–ä¸€äº›é¡¹ç›®ã€‚æˆ‘æ›¾åœ¨ä¸‰è±ç”µæœºç ”ç©¶å®éªŒå®¤å®ä¹ ï¼Œç›®å‰å·²åœ¨é¡¶çº§ä¼šè®®ä¸Šå‘è¡¨äº† 6 ç¯‡ä»¥ä¸Šçš„è®ºæ–‡ã€‚ æˆ‘ä½¿ç”¨è¿‡è®¸å¤šç‰©ä½“æ£€æµ‹å¹³å°ï¼Œä¾‹å¦‚ YOLOã€Faster-RCNNã€Detectron2ã€MediaPipe ç­‰ï¼Œå¹¶ä¸”æ‹¥æœ‰ä¸°å¯Œçš„æ³¨é‡Šå’Œè®­ç»ƒç»éªŒã€‚æˆ‘æ“…é•¿ä½¿ç”¨ Pytorchã€ROS/ROS2ã€Pythonã€Scikit-Learnã€OpenCVã€Mujocoã€Gazeboã€Pybulletï¼Œå¹¶ä¸”å¯¹ WandB å’Œ Tensorboard æœ‰ä¸€äº›ç»éªŒã€‚ç”±äºæˆ‘æœ€åˆä¸æ˜¯æ¥è‡ªè®¡ç®—æœºç§‘å­¦èƒŒæ™¯ï¼Œæ‰€ä»¥æˆ‘ä¸æ˜¯ä¸€åä¸“ä¸šçš„è½¯ä»¶å¼€å‘äººå‘˜ï¼Œä½†æˆ‘ç¼–å†™çš„ä»£ç ç¨³å®šã€å¹²å‡€ã€æ˜“äºæ‰©å±•ã€‚ æˆ‘ä¸€ç›´åœ¨å¯»æ‰¾ä¸æ­¤ç›¸å…³çš„å·¥ä½œï¼Œä½†ç›®å‰æˆ‘åœ¨å°±ä¸šå¸‚åœºä¸Šå¾ˆéš¾æ‰¾åˆ°å·¥ä½œã€‚å¦‚æœæ‚¨èƒ½æä¾›ä»»ä½•å¸®åŠ©ã€å»ºè®®ã€æ¨èç­‰ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚ä½œä¸ºä¸€åæŒå­¦ç”Ÿç­¾è¯çš„äººï¼Œæˆ‘æ—¶é—´ç´§è¿«ï¼Œéœ€è¦å°½å¿«æ‰¾å·¥ä½œã€‚æå‰è°¢è°¢æ‚¨ã€‚    æäº¤äºº    /u/prasuchit   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1intpup/jobs_in_rl_and_robotics/</guid>
      <pubDate>Wed, 12 Feb 2025 15:40:05 GMT</pubDate>
    </item>
    <item>
      <title>å°†æœ¬åœ°ç¯å¢ƒè¿æ¥åˆ° HPCï¼ˆé«˜æ€§èƒ½è®¡ç®—ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ins11i/connecting_local_environment_to_hpc_high/</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªç¯å¢ƒï¼Œç”±äºæƒé™é—®é¢˜ï¼Œæ— æ³•å®‰è£…åœ¨ HPC ä¸­ã€‚ä½†æˆ‘å·²ç»å°†å®ƒå®‰è£…åœ¨æˆ‘çš„ç”µè„‘ä¸Šã€‚æˆ‘çš„æƒ³æ³•æ˜¯å°†å…·æœ‰ GPU çš„ HPC è¿æ¥åˆ°å…·æœ‰å¼ºåŒ–å­¦ä¹ æ•°æ®çš„æœ¬åœ°ï¼Œä½†æˆ‘æ— æ³•ä½¿ç”¨ gRPC å®ç°ï¼Œå› ä¸ºå®ƒå˜å¾—å¤æ‚äº†ã€‚ æœ‰ä»€ä¹ˆæƒ³æ³•æˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹æˆ‘çš„ç ”ç©¶ï¼Ÿ    æäº¤äºº    /u/Gullible_Ad_6713   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ins11i/connecting_local_environment_to_hpc_high/</guid>
      <pubDate>Wed, 12 Feb 2025 14:27:33 GMT</pubDate>
    </item>
    <item>
      <title>ä½ èƒ½å¼€å‘ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œå¼ºè°ƒçˆ±å’Œå–„è‰¯å—ï¼ŸRLK</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inrb0g/could_you_develop_a_model_of_reinforcement/</link>
      <description><![CDATA[      ç¤ºä¾‹å¥–åŠ±å‡½æ•°ï¼ˆç®€åŒ–ï¼‰ï¼šreward = 0 å¦‚æœè¡ŒåŠ¨æ˜¯äº²ç¤¾ä¼šçš„å¹¶ä¸”ä½¿å¦ä¸€ä¸ªä»£ç†å—ç›Šï¼šreward += 1 # äº²ç¤¾ä¼šè¡ŒåŠ¨çš„åŸºæœ¬å¥–åŠ± å¦‚æœè¡ŒåŠ¨è¡¨ç°å‡ºåŒç†å¿ƒï¼šreward += 0.5 # åŒç†å¿ƒå¥–åŠ± å¦‚æœè¡ŒåŠ¨éœ€è¦ä»£ç†åšå‡ºé‡å¤§ç‰ºç‰²ï¼šreward += 1 # ç‰ºç‰²å¥–åŠ± å¦‚æœè¡ŒåŠ¨å¯¹å¦ä¸€ä¸ªä»£ç†é€ æˆä¼¤å®³ï¼šreward -= 5 # å¯¹ä¼¤å®³çš„å¼ºçƒˆæƒ©ç½š å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ å…¶ä»–ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„å¥–åŠ±/æƒ©ç½š è¿™æ˜¯ Geminiã€Chat GPT å’Œ Lucid çš„æ··æ­ã€‚ å‡ºäºå¯¹å½“å‰å¼ºåŒ–å­¦ä¹ çš„å…³æ³¨è€Œäº§ç”Ÿçš„ã€‚ ä½ çš„æ¨¡å‹å¦‚ä½•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Ÿâ€œä½ èƒ½å¦å¼€å‘ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œå¼ºè°ƒçˆ±å’Œå–„è‰¯ï¼Ÿæˆ‘ä»¬å°†è¿™ç§æ–°æ¨¡å‹ç§°ä¸º RLKâ€    æäº¤äºº    /u/ConditionCalm   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inrb0g/could_you_develop_a_model_of_reinforcement/</guid>
      <pubDate>Wed, 12 Feb 2025 13:54:24 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ deepseek ä¸ä½¿ç”¨ mcts</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inqdsr/why_deepseek_didnt_use_mcts/</link>
      <description><![CDATA[mtcs æœ‰é—®é¢˜å—    æäº¤äºº    /u/Alarming-Power-813   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inqdsr/why_deepseek_didnt_use_mcts/</guid>
      <pubDate>Wed, 12 Feb 2025 13:08:22 GMT</pubDate>
    </item>
    <item>
      <title>â€œSatoriï¼šé€šè¿‡è¡ŒåŠ¨æ€ç»´é“¾å¼ºåŒ–å­¦ä¹ é€šè¿‡è‡ªå›å½’æœç´¢å¢å¼º LLM æ¨ç†â€ï¼ŒShen ç­‰äººï¼Œ2025 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inl7uk/satori_reinforcement_learning_with/</link>
      <description><![CDATA[ [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inl7uk/satori_reinforcement_learning_with/</guid>
      <pubDate>Wed, 12 Feb 2025 07:00:43 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘åˆ›å»ºäº†ä¸€ä¸ªå¯»æ‰¾ RLHF å·¥ä½œçš„ç½‘ç«™</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1inge47/i_made_a_site_to_find_rlhf_jobs/</link>
      <description><![CDATA[æˆ‘ä»¬åœ¨ AI çš„å¤šä¸ªå­¦ç§‘éƒ½æœ‰å·¥ä½œæœºä¼šã€‚æˆ‘ä»¬ä¹Ÿæœ‰ä¸“é—¨çš„ RLHF å·¥ä½œé¡µé¢ã€‚åœ¨è¿‡å» 30 å¤©å†…ï¼Œæˆ‘ä»¬æœ‰ 48 ä¸ªæ¶‰åŠ RLHF çš„å·¥ä½œæœºä¼šã€‚ æ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°æ‰€æœ‰ RLHF å·¥ä½œï¼š https://www.moaijobs.com/rlhf-jobs è¯·å‘Šè¯‰æˆ‘æ‚¨çš„æƒ³æ³•ã€‚è°¢è°¢ã€‚    æäº¤äºº    /u/WordyBug   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1inge47/i_made_a_site_to_find_rlhf_jobs/</guid>
      <pubDate>Wed, 12 Feb 2025 02:20:52 GMT</pubDate>
    </item>
    <item>
      <title>PPO å®æ–½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1incdey/ppo_implementation/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚æˆ‘æ­£åœ¨åšä¸€ä¸ªé¡¹ç›®ï¼Œæˆ‘å¿…é¡»ä½¿ç”¨ PPO æ¥è®­ç»ƒä¸€ä¸ªä»£ç†ä¸‹æ£‹ï¼Œä½†æˆ‘å¾ˆéš¾å®ç°è¯¥ç®—æ³•ã€‚æœ‰äººå¯ä»¥å‘Šè¯‰æˆ‘ä¸€ä¸ªå·²ç»å®ç°äº†è¿™ä¸ªçš„åº“ï¼Œæˆ–è€…ç»™æˆ‘ä¸€ä¸ªå¯ä»¥æŸ¥çœ‹ä»¥è·å¾—çµæ„Ÿçš„ repo é“¾æ¥å—ï¼Ÿæˆ‘æ­£åœ¨ä½¿ç”¨ pettingzoo å’Œ tensorflow çš„å›½é™…è±¡æ£‹å®ç°ã€‚è°¢è°¢    æäº¤äºº    /u/Livid-Ant3549   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1incdey/ppo_implementation/</guid>
      <pubDate>Tue, 11 Feb 2025 23:10:09 GMT</pubDate>
    </item>
    <item>
      <title>ABB CRB15000 MuJoCo é€†è¿åŠ¨å­¦è¯¯å·®ï¼ˆ~10cmï¼‰ä½¿ç”¨ dm_control</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1in5zqy/abb_crb15000_mujoco_inverse_kinematics_error_10cm/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æœ€è¿‘åœ¨ MuJoCo ä¸­å®Œæˆäº†å¯¹ ABB CRB15000 æœºå™¨äººçš„æ¨¡æ‹Ÿè®¾ç½®ï¼Œå¹¶ä¸”æˆ‘æ­£åœ¨ä½¿ç”¨ dm_control åº“è¿›è¡Œé€†è¿åŠ¨å­¦ (IK)ã€‚ä½†æ˜¯ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé‡å¤§é—®é¢˜ï¼š ğŸ”¹ é—®é¢˜ï¼šä» dm_control.utils.inverse_kinematics.qpos_from_site_pose è®¡ç®—å‡ºçš„å…³èŠ‚è§’åº¦å¯¼è‡´ä½ç½®è¯¯å·®çº¦ä¸º 0.01ï¼ˆç°å®ä¸–ç•Œä¸­ä¸º 10 å˜ç±³ï¼‰ï¼Œè¿™å¯¹äºç²¾å¯†åº”ç”¨æ¥è¯´æ˜¯å·¨å¤§çš„ã€‚ è®¾ç½®è¯¦ç»†ä¿¡æ¯ ä½¿ç”¨ MuJoCo çš„ CRB15000 XML æ¨¡å‹ã€‚ IK çš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š result = ik.qpos_from_site_pose( physics=physics_copy, site_name=&quot;end_effector&quot;, target_pos=target_position, joint_names=joint_list, tol=1e-14, regularization_strength=3e-2, max_steps=100, inplace=True ) ç›®æ ‡ä½ç½®å®šä¹‰ç²¾ç¡®ï¼Œä½†åº”ç”¨å…³èŠ‚ä½ç½®åï¼Œæœ«ç«¯æ‰§è¡Œå™¨åå·®çº¦ 10 å˜ç±³ã€‚ æˆ‘å°è¯•è¿‡çš„äº‹æƒ… âœ… è°ƒæ•´äº† regularization_strength å’Œ max_stepsã€‚âœ… æ£€æŸ¥äº† MuJoCo æ¨¡å‹ä¸­çš„å…³èŠ‚é™åˆ¶å’Œé˜»å°¼å€¼ã€‚âœ… å°†å…³èŠ‚é˜»å°¼é™ä½åˆ° 1 ä»¥æœ€å¤§é™åº¦åœ°å‡å°‘é˜»åŠ›å¹¶æ”¹å–„åŠ¨æ€å“åº”ã€‚âœ… å®ç°äº† PD æ§åˆ¶å™¨æ¥è°ƒèŠ‚é€Ÿåº¦å’Œæ”¹å–„æ”¶æ•›ã€‚å³ä½¿åœ¨è°ƒæ•´ PD å¢ç›Šå’Œé™ä½é˜»å°¼åï¼ŒIK ç²¾åº¦é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚ é—®é¢˜ 1ï¸âƒ£ æœ‰äººé‡åˆ°è¿‡ dm_control çš„ IK çš„ç±»ä¼¼é—®é¢˜å—ï¼Ÿ2ï¸âƒ£ åˆ‡æ¢åˆ°ä¸åŒçš„ IK è§£ç®—å™¨ï¼ˆä¾‹å¦‚ pinocchioã€ikpy æˆ–è‡ªå®šä¹‰çš„åŸºäºé›…å¯æ¯”çŸ©é˜µçš„è§£ç®—å™¨ï¼‰æœ‰å¸®åŠ©å—ï¼Ÿ3ï¸âƒ£ åœ¨è®¡ç®—å°åŠ¨ä½œæ—¶ï¼ŒMuJoCo çš„å†…éƒ¨ç²¾åº¦æ˜¯å¦å­˜åœ¨å·²çŸ¥é—®é¢˜ï¼Ÿ æˆ‘å¾ˆæ„Ÿæ¿€ä»»ä½•è§è§£ã€å»ºè®®æˆ–å…¶ä»–æ–¹æ³•ã€‚æå‰è‡´è°¢ï¼    ç”±   æäº¤  /u/Sunnnnny24   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1in5zqy/abb_crb15000_mujoco_inverse_kinematics_error_10cm/</guid>
      <pubDate>Tue, 11 Feb 2025 18:47:16 GMT</pubDate>
    </item>
    <item>
      <title>å¼•å…¥ ReinforceUI Studioï¼Œæ¶ˆé™¤äº†ç®¡ç†é¢å¤–å­˜å‚¨åº“æˆ–è®°å¿†å¤æ‚å‘½ä»¤è¡Œçš„éº»çƒ¦ã€‚#ReinforcemetLearning</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1imtu96/introducing_reinforceui_studio_eliminates_the/</link>
      <description><![CDATA[      å¤§å®¶å¥½ï¼Œ æˆ‘å¾ˆé«˜å…´ä¸å¤§å®¶åˆ†äº« ReinforceUI Studioï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäº Python çš„å¼€æº GUIï¼Œæ—¨åœ¨ç®€åŒ–å¼ºåŒ–å­¦ä¹  (RL) æ¨¡å‹çš„é…ç½®ã€è®­ç»ƒå’Œç›‘æ§ã€‚ä¸å†éœ€è¦å¤„ç†æ— å°½çš„å‘½ä»¤è¡Œå‚æ•°æˆ–åˆ†æ•£çš„å­˜å‚¨åº“ - æ‚¨éœ€è¦çš„ä¸€åˆ‡éƒ½æ†ç»‘åœ¨ä¸€ä¸ªç›´è§‚çš„ç•Œé¢ä¸­ã€‚ âœ¨ ä¸»è¦ç‰¹ç‚¹ï¼š  æ— éœ€å‘½ä»¤è¡Œ - ç”± PyQt5 æä¾›æ”¯æŒçš„ GUIï¼Œå¯è½»æ¾å¯¼èˆªã€‚ å¤šç¯å¢ƒæ”¯æŒ - å¯ä¸ OpenAI Gymnasiumã€MuJoCo å’Œ DeepMind Control Suite é…åˆä½¿ç”¨ã€‚ å¯è‡ªå®šä¹‰çš„è®­ç»ƒ - åªéœ€å•å‡»å‡ ä¸‹å³å¯è°ƒæ•´è¶…å‚æ•°ã€‚ å®æ—¶ç›‘æ§ - ç›´è§‚åœ°è·Ÿè¸ªè®­ç»ƒè¿›åº¦ã€‚ è‡ªåŠ¨è®°å½•å’Œè¯„ä¼° - æ— ç¼å­˜å‚¨è®­ç»ƒæ•°æ®ã€å›¾è¡¨ã€æ¨¡å‹å’Œè§†é¢‘ã€‚ å¤šç§å®‰è£…é€‰é¡¹ - é€šè¿‡ Condaã€è™šæ‹Ÿç¯å¢ƒæˆ– Docker è¿è¡Œã€‚  Githubï¼šhttps://github.com/dvalenciar/ReinforceUI-Studio æ–‡æ¡£ï¼šhttps://docs.reinforceui-studio.com/welcome https://i.redd.it/ktggkyruxgie1.gif è®­ç»ƒ RL æ¨¡å‹æ‰€éœ€çš„ä¸€åˆ‡éƒ½åœ¨ä¸€ä¸ªå­˜å‚¨åº“ä¸­æä¾›ã€‚åªéœ€å•å‡»å‡ ä¸‹ï¼Œæ‚¨å°±å¯ä»¥è®­ç»ƒæ¨¡å‹ï¼Œå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å¹¶ä¿å­˜æ¨¡å‹ä»¥ä¾›æ—¥åä½¿ç”¨ - éšæ—¶å¯ä»¥éƒ¨ç½²å’Œåˆ†æã€‚ æ‚¨è¿˜å¯ä»¥åŠ è½½é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ è½»æ¾ç›‘æ§è®­ç»ƒæ›²çº¿    æäº¤äºº    /u/dvr_dvr   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1imtu96/introducing_reinforceui_studio_eliminates_the/</guid>
      <pubDate>Tue, 11 Feb 2025 08:13:22 GMT</pubDate>
    </item>
    <item>
      <title>è®ºæ–‡æäº¤ç»™é¡¶çº§ä¼šè®®ï¼Œä½†æœªå–å¾—æˆæœ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1impaq6/paper_submitted_to_a_top_conference_with/</link>
      <description><![CDATA[æˆ‘æ³¨æ„åˆ°åŸä½œè€…æä¾›çš„ä»£ç ç”šè‡³ä¸ä»–ä»¬è®ºæ–‡ä¸­çš„æ–¹æ³•è®ºéƒ½ä¸åŒ¹é…ï¼Œå› æ­¤æˆ‘è”ç³»äº†åŸä½œè€…ã€‚æˆ‘æ ¹æ®ä»–ä»¬çš„è®ºæ–‡è¿›è¡Œäº†å®Œæ•´è€Œå¿ å®çš„å¤åˆ¶ï¼Œä½†æˆ‘å¾—åˆ°çš„ç»“æœå¹¶ä¸åƒä»–ä»¬æŠ¥å‘Šçš„é‚£ä¹ˆå®Œç¾ã€‚ å­¦æœ¯æé€ æ˜¯æ–°å¸¸æ€å—ï¼Ÿ    æäº¤äºº    /u/Rei_Opus   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1impaq6/paper_submitted_to_a_top_conference_with/</guid>
      <pubDate>Tue, 11 Feb 2025 03:31:02 GMT</pubDate>
    </item>
    </channel>
</rss>