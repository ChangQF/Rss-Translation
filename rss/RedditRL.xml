<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>强化学习</title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>强化学习是人工智能/统计学的一个子领域，专注于探索/理解复杂的环境并学习如何最佳地获得奖励。例如 AlphaGo、临床试验和 A/B 测试以及 Atari 游戏。</description>
    <lastBuildDate>Thu, 04 Jan 2024 12:24:42 GMT</lastBuildDate>
    <item>
      <title>指导我在 RL 领域取得良好的职业生涯</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18y6lgk/guide_me_for_a_good_career_in_rl/</link>
      <description><![CDATA[您好，我最近刚毕业，获得机械工程学士学位，但我对 ML、RL 更感兴趣。作为初学者，我完成了 stanford online 的 ML 课程，完成了 DL 专业化课程，完成了 dl.ai 的 GANs 专业化课程，然后完成了 U-Alberta 的 RL 专业化课程，我还在 youtube 上观看了加州大学伯克利分校的深度 RL 讲座。我参与过几个小项目（至少 3 个写在简历上，一个是关于分割的，两个是关于序列模型的）小项目，其中一个与机器人操作系统（ros）相关的项目，尽管我没有深入、彻底地使用 ROS，并且2 个关于 3D CNN 的项目，将 DL 应用于医学领域（所以不是非常新颖的工作）。 而且我比我探索的任何领域都更喜欢 RL。但是，强化学习中的数学，至少现在确实让我着迷，我理解数学在这里试图做什么，它背后的直觉，但如果我必须自己写数学，那就是不可撤销的。我想在这个领域进行研究。 目前我正在做第二个项目，关于 3d CNN（GAN，与 RL 有一些关系），但我想做一些更好的事情，工业实习或与教授的学术实习是首选，但考虑到我在学士学位中的 GPA 非常非常低，我只是担心没有人会对指导/录取我感兴趣，以至于我什至没有达到人们在某些职位上录取的程度。而且我确信，如果教授考虑得更好，公司可能不会将我视为他们的第一选择。我不确定哪里有更好的机会，但我真的很想从事学术研究，尽管工业界可能会带来更好的钱。我只是想转向更好的地方，你能建议任何路径吗？首先当然是接触人们，接触博士生也可能是获得更多指导的好主意，不是吗？ P.s.我对 RL 的探索和奖励感兴趣   由   提交/u/vyknot4wongs  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18y6lgk/guide_me_for_a_good_career_in_rl/</guid>
      <pubDate>Thu, 04 Jan 2024 06:40:38 GMT</pubDate>
    </item>
    <item>
      <title>“大型语言模型可以自学使用工具”，Schick 等人 2023 {FB}</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18y1hh8/large_language_models_can_teach_themselves_to_use/</link>
      <description><![CDATA[ 由   提交/u/gwern  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18y1hh8/large_language_models_can_teach_themselves_to_use/</guid>
      <pubDate>Thu, 04 Jan 2024 02:15:41 GMT</pubDate>
    </item>
    <item>
      <title>“桥接离散和反向传播：直通和超越”，Liu 等人 2023</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18y0fee/bridging_discrete_and_backpropagation/</link>
      <description><![CDATA[ 由   提交/u/gwern  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18y0fee/bridging_discrete_and_backpropagation/</guid>
      <pubDate>Thu, 04 Jan 2024 01:28:10 GMT</pubDate>
    </item>
    <item>
      <title>在 7 多万英里的纯骑手驾驶中，Waymo 的表现显着优于可比较的人类基准（Kusano 等人，2023 年）</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xzuvh/waymo_significantly_outperforms_comparable_human/</link>
      <description><![CDATA[       由   提交/u/gwern  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xzuvh/waymo_significantly_outperforms_comparable_human/</guid>
      <pubDate>Thu, 04 Jan 2024 01:02:58 GMT</pubDate>
    </item>
    <item>
      <title>“PASTA：预训练的动作状态转换器代理”，Boige 等人 2023</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xymab/pasta_pretrained_actionstate_transformer_agents/</link>
      <description><![CDATA[ 由   提交/u/gwern  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xymab/pasta_pretrained_actionstate_transformer_agents/</guid>
      <pubDate>Thu, 04 Jan 2024 00:09:46 GMT</pubDate>
    </item>
    <item>
      <title>持续强化学习的定义</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xu67t/a_definition_of_continual_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.11046 OpenReview：https:// /openreview.net/forum?id=ZZS9WEWYbD 摘要：  在强化学习问题的标准视图中，代理的目标是有效地确定最大化长期回报的策略。然而，这种观点是基于一种有限的观点，即学习是寻找解决方案，而不是将学习视为无休止的适应。相反，持续强化学习是指最好的智能体永远不会停止学习的环境。尽管持续强化学习很重要，但社区缺乏一个简单的问题定义来强调其承诺并使其主要概念准确清晰。为此，本文致力于仔细定义持续强化学习问题。我们将“永不停止学习”的代理概念正式化。通过一种新的数学语言来分析和编目代理。使用这种新语言，我们将持续学习代理定义为可以无限期地执行隐式搜索过程的代理，并将持续强化学习定义为最佳代理都是持续学习代理的设置。我们提供了两个激励性的例子，说明多任务强化学习和持续监督学习的传统观点是我们定义的特例。总的来说，这些定义和观点形式化了学习核心的许多直观概念，并开辟了围绕持续学习代理的新研究途径。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xu67t/a_definition_of_continual_reinforcement_learning/</guid>
      <pubDate>Wed, 03 Jan 2024 21:09:29 GMT</pubDate>
    </item>
    <item>
      <title>暑期实习在 RL/Embodied AI 领域处于领先地位。</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xos1z/summer_internship_leads_in_rlembodied_ai_space/</link>
      <description><![CDATA[我正在寻找 2024 年暑期实习的一些线索，以寻找潜在的（如果可能的话研究）实习机会。 我不是非常了解在这个领域工作的所有初创公司/组织，因为我自己对它非常陌生。我没有太多经验，但希望在这些实习中获得一些经验。如果有任何帮助，我们将不胜感激！   由   提交 /u/gchhablani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xos1z/summer_internship_leads_in_rlembodied_ai_space/</guid>
      <pubDate>Wed, 03 Jan 2024 17:33:56 GMT</pubDate>
    </item>
    <item>
      <title>我如何获得研究想法？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xlwli/how_do_i_get_ideas_for_research/</link>
      <description><![CDATA[事情的简短版本：我是一名 CS 硕士生。我已经完成了一年半的尝试并努力进入 EAI 领域。我还有大约一年的时间，我想充分利用这一年。我有一些 NLP 专业背景，也有一些研究经验，但不是很深入。我了解监督学习，并且擅长 PyTorch 之类的东西。我目前面临两个主要问题：  我想发表一些第一作者的作品，但无法获得强大的创造力在我体内流淌。我该如何开发它？ 我想从语言理解方面攻击 RL 的各个方面，但各个方面的研究都在疯狂增长（LLM、VLM） 、RL、变形金刚），我很难理解该读什么、不该读什么。  来自该领域有经验的人的任何想法或提示类似问题或只是有足够的经验？ 如果这不是合适的论坛，请指出我可以讨论此问题的地方。 &lt;!-- SC_ON - -&gt;  由   提交 /u/gchhablani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xlwli/how_do_i_get_ideas_for_research/</guid>
      <pubDate>Wed, 03 Jan 2024 15:24:28 GMT</pubDate>
    </item>
    <item>
      <title>RL玩游戏：从哪里开始？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xk6a8/rl_to_play_games_where_to_start/</link>
      <description><![CDATA[我正在启动一个有趣的项目，训练 AI 玩 2 种类型的游戏： - 1v1 游戏联盟/Dota 风格，基于图像的输入  - 1v1 回合制游戏，玩家在单元格上移动并拥有一堆咒语，具有基于特征的输入 所以我读过 Atari、AlphaGo/Star、OpenAI Five...想知道人们是否有其他/较新的参考资料或相关项目，在这些情况下最好使用哪种类型的算法？过去我只在所有事情上使用 PPO。 我还计划自己编写游戏代码（在非常基础的水平上） - 想知道人们是否已经这样做了并且对使用什么语言/框架有建议以最大速度写入游戏。我最近看到了 Madrona Engine，看起来很有趣，但我还没有尝试过。 顺便说一句，到目前为止我只是自己做 RL，有没有大型的 RL 社区除了这个 Reddit 子版块之外还应该知道什么？谢谢你！ :)   由   提交/u/frenchhusky  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xk6a8/rl_to_play_games_where_to_start/</guid>
      <pubDate>Wed, 03 Jan 2024 14:05:40 GMT</pubDate>
    </item>
    <item>
      <title>逆向强化学习的现状？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xjndc/current_state_of_inverse_reinforcement_learning/</link>
      <description><![CDATA[ 由   提交/u/Professional_Card176   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xjndc/current_state_of_inverse_reinforcement_learning/</guid>
      <pubDate>Wed, 03 Jan 2024 13:40:46 GMT</pubDate>
    </item>
    <item>
      <title>用于控制器调优 inn python 的 env</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xgqu8/env_for_controller_tuning_inn_python/</link>
      <description><![CDATA[       这里有人尝试过使用 RL 在 python 中进行 PI/PID 控制器调整 如果可以的话，您可以提供您的 env 文件或帮助我创建相同的环境。&lt; /p&gt; （环境由代理、源、系统模型以及系统输出到源的反馈组成）  /u/Wide-Chef-7011   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xgqu8/env_for_controller_tuning_inn_python/</guid>
      <pubDate>Wed, 03 Jan 2024 10:57:38 GMT</pubDate>
    </item>
    <item>
      <title>衰减剪辑因子和熵损失权重</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18xevbt/decaying_clip_factor_and_entropy_loss_weight/</link>
      <description><![CDATA[有没有办法可以将衰减熵损失权重和裁剪因子合并到 matlab 中的 PPO 算法中？ 我知道 Rl matlab 有问题，但如果可能的话仍然存在    由   提交 /u/Wide-Chef-7011   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18xevbt/decaying_clip_factor_and_entropy_loss_weight/</guid>
      <pubDate>Wed, 03 Jan 2024 08:51:34 GMT</pubDate>
    </item>
    <item>
      <title>需要github项目的合作者（股票交易的深度强化学习）</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18x0vtz/need_collaborator_for_github_project_deep/</link>
      <description><![CDATA[​ 有人有兴趣合作开发一个使用深度强化学习进行股票交易的 Python 库项目吗？  您可以在此处找到 github 存储库：https://github.com/RezaSoleymanifar/neuralHFT ​ 这是一个正在进行的项目，目前有超过 15,000 行代码处理端到端的所有事务，从连接到交易 API、下载历史数据、数据集创建、DRL算法/网络设计、训练并最终部署在交易账户中。  ​ 我计划在 ICAIF 2024（ACM AI in Finance）会议上发表一篇关于这个库的论文。如果您是学者，这是我们可以讨论的另一个途径。   由   提交 /u/RezaSoleymanifar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18x0vtz/need_collaborator_for_github_project_deep/</guid>
      <pubDate>Tue, 02 Jan 2024 21:27:53 GMT</pubDate>
    </item>
    <item>
      <title>DQL 没有改善</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18wwsxt/dql_not_improving/</link>
      <description><![CDATA[我尝试从头开始实现蛇深度 Q 学习，但它似乎没有改进，也不知道为什么。任何帮助或建议或提示都会有帮助。 链接https://colab。 Research.google.com/drive/1H3VdTwS4vAqHbmCbQ4iZHytvULpi9Lvz?usp=sharing 通常我使用 Jupyter Notebook，google colab 只是为了共享 为我自私的请求道歉， 提前致谢   由   提交/u/Witty_Fan_5776   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18wwsxt/dql_not_improving/</guid>
      <pubDate>Tue, 02 Jan 2024 18:45:23 GMT</pubDate>
    </item>
    <item>
      <title>如何开始为 Steam 游戏创建自定义环境？</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18wt4pf/how_would_one_even_begin_to_create_a_custom/</link>
      <description><![CDATA[我最近对 ​​rl 有了更多的了解，这让我对创建一个可以玩电脑游戏的代理的潜力感到好奇。唯一的问题是我什至不知道创造环境是否可行。然而，以前在《DOTA》和《火箭联盟》等游戏中就已经做过这样的事情，这让我想知道他们是如何做到的。我很好奇是否有一种实际的方法可以设置带有状态、动作和奖励的环境的流行游戏？   由   提交/u/Scruffy004   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18wt4pf/how_would_one_even_begin_to_create_a_custom/</guid>
      <pubDate>Tue, 02 Jan 2024 16:17:12 GMT</pubDate>
    </item>
    </channel>
</rss>