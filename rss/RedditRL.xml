<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Sun, 23 Jun 2024 01:08:13 GMT</lastBuildDate>
    <item>
      <title>è‡ªé€‚åº”å››è½´é£è¡Œå™¨ç½‘ç»œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dm8ba1/adaptive_quadcopter_network/</link>
      <description><![CDATA[ğŸ‘‹ å˜¿ï¼Œæˆ‘æ­£åœ¨å°è¯•æƒ³å‡ºä¸€ä¸ªå››è½´é£è¡Œå™¨æ— äººæœºè‡ªä¸»æ§åˆ¶çš„è§£å†³æ–¹æ¡ˆã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘è®¾æ³•è®©å®ƒä½¿ç”¨ç®€å•çš„ MLP + PPO è¿›è¡Œèˆªç‚¹å¯¼èˆªã€‚ è¿™å¾ˆæœ‰æ•ˆï¼Œç‰¹åˆ«æ˜¯åœ¨åŸŸéšæœºåŒ–çš„æƒ…å†µä¸‹ï¼Œä½†å¦‚æœçªç„¶åˆ®èµ·ä¸€é˜µé£ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå››è½´é£è¡Œå™¨çš„é‡é‡è¶…è¿‡äº†å®ƒåœ¨æ¨¡æ‹Ÿä¸­è®­ç»ƒçš„é‡é‡ï¼Ÿèºæ—‹æ¡¨æŸåï¼Œå…¶ä¸­ä¸€ä¸ªç”µæœºäº§ç”Ÿçš„æ¨åŠ›å‡å°ï¼Ÿ é€šè¿‡æ‰€æœ‰è¿™äº›ç¤ºä¾‹ï¼Œæˆ‘çš„é—®é¢˜æ˜¯æ— äººæœºæ— æ³•é€‚åº”å˜åŒ–ã€‚æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿé€‚åº”ä»»ä½•æ— æ³•è§£é‡Šçš„å¤–éƒ¨å¹²æ‰°çš„ç½‘ç»œã€‚ æˆ‘æœ‰ä¸¤ä¸ªè®¡åˆ’ï¼Œä¸€ä¸ªæ˜¯å°† LSTM ä¸ PPO ç»“åˆä½¿ç”¨ï¼Œå› æ­¤ä»£ç†ä¼šä¿ç•™é£è¡Œæ•°æ®ã€‚ æˆ‘çš„å¦ä¸€ä¸ªæƒ³æ³•æ˜¯ä½¿ç”¨æˆ‘ç”¨äºè®­ç»ƒçš„æ¨¡æ‹Ÿå™¨æ¥è·å–æ— äººæœºåœ¨å½“å‰æ—¶é—´æ­¥é•¿çš„é¢„æœŸé€Ÿåº¦/å§¿æ€/ä½ç½®ï¼Œå¹¶å°†å…¶ä¸æˆ‘ä»ä¼ æ„Ÿå™¨è·å¾—çš„å®é™…å€¼ä¸€èµ·è¾“å…¥åˆ°ç­–ç•¥ä¸­ã€‚ æˆ‘å¸Œæœ›æ›´æœ‰ç»éªŒçš„äººå¯ä»¥å¯¹æˆ‘çš„æƒ³æ³•æä¾›åé¦ˆï¼Œè¯´å®è¯æˆ‘æœ‰ç‚¹è¿·èŒ«ï¼Œæˆ‘ä¸ç¡®å®šè¿™äº›æ˜¯å¦å¯è¡Œï¼Œä»»ä½•å¸®åŠ©éƒ½å€¼å¾—èµèµï¼    æäº¤äºº    /u/FutureComedian7749   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dm8ba1/adaptive_quadcopter_network/</guid>
      <pubDate>Sat, 22 Jun 2024 23:15:56 GMT</pubDate>
    </item>
    <item>
      <title>C++ åº“åˆ° JAXï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dlil7i/c_library_to_jax/</link>
      <description><![CDATA[å¤§å®¶å¥½ r/MLQuestionsï¼Œæˆ‘è¯»è¿‡è¿™ç¯‡ 2022 å¹´çš„è®ºæ–‡ https://chrislu.page/blog/meta-disco/ï¼Œå®ƒè®¨è®ºäº†é€šè¿‡çº¯ Jax å¹¶è¡ŒåŒ–å°†æ‰€æœ‰è®¡ç®—ä» CPU è½¬ç§»åˆ° GPU å’Œ TPUã€‚æœ¬è´¨ä¸Šï¼Œä»–ä»¬å·²ç»å°†æ•´ä¸ª RL æ­¥éª¤çŸ¢é‡åŒ–ä»¥è¿›è¡Œ GPU è®¡ç®—ï¼Œå¹¶ä¸”ç”±äºä»¤äººéš¾ä»¥ç½®ä¿¡çš„å¹¶è¡ŒåŒ–ï¼Œèƒ½å¤Ÿåœ¨ 9 å°æ—¶å†…åœ¨ Atari åŸºå‡†æµ‹è¯•ä¸­è®­ç»ƒ 50 ä¸‡ä¸ªä»£ç†ï¼Œä¸ CleanRL å®ç°ç›¸æ¯”ï¼Œè¿™å®ç°äº† 4000 å€çš„åŠ é€Ÿã€‚  æˆ‘è®¤ä¸ºç°åœ¨å®ƒæ›´å¸¸è§äº†ï¼Œä½†åœ¨ 2022 å¹´ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªé‡å¤§çªç ´ã€‚  ç°åœ¨ï¼Œæˆ‘ä¹Ÿæƒ³è¦è¿™ä¸ª æˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼šåœ¨çº¯ jax ä¸­å·¥ä½œã€‚ç°åœ¨ï¼Œæˆ‘æ­£åœ¨åˆ›å»ºä¸€ä¸ªéœ€è¦å¤æ‚ 3d æ•°å­¦å¼•æ“çš„äº§å“ - è¿™äº›å¤æ‚çš„åº“å¾ˆå¤§å¹¶ä¸”ç”¨ C++ ç¼–å†™ã€‚æˆ‘ä¹Ÿéœ€è¦å…¶ä¸­çš„å¾ˆå¤šåº“ã€‚  ä¾‹å¦‚ï¼Œä¸€ä¸ªæ˜¯ OpenCASCADE [https://github.com/Open-Cascade-SAS] ã€‚ä»…â€œsrcâ€æ–‡ä»¶å¤¹å°±æœ‰ 97mbï¼ŒåŒ…å« 16000 ä¸ªæ–‡ä»¶ã€‚å®ƒéå¸¸åºå¤§ï¼Œæˆ‘éœ€è¦å°†å…¶æ’å…¥ JAX ä»¥æé«˜é€Ÿåº¦ã€‚  å¦‚æœæˆ‘ä¸å¯¹æˆ‘çš„åº”ç”¨ç¨‹åºè¿›è¡Œè¶…å¹¶è¡ŒåŒ–ï¼Œæˆ‘å°†ä¼šé™·å…¥ 10 å€çš„å¾ªç¯æ—¶é—´å’Œ 200 å€çš„ç¡¬ä»¶å¹¶è¡Œçº¿å‡å°‘çš„å›°å¢ƒï¼Œè¿™åœ¨æˆ‘çš„é¢†åŸŸæ„å‘³ç€é•¿æ—¶é—´çš„è®¡ç®—ã€‚  ç°åœ¨æˆ‘æ‡‚æ•°å­¦ï¼Œä¹Ÿè®¸å¯ä»¥é‡å†™æˆ‘éœ€è¦çš„å‡½æ•°ï¼Œä½†æ˜¯æˆ‘æœ‰æ²¡æœ‰å¯èƒ½ç”¨æŸç§â€¦â€¦è£…é¥°å™¨å°†æ–‡ä»¶é€‚é…åˆ° Jax ï¼Ÿæ¯•ç«Ÿï¼Œjax ä¹Ÿæ˜¯ç”¨ C++ ç¼–å†™çš„ã€‚æˆ–è€…ä¹Ÿè®¸åˆ†å‰å®ƒå¹¶è¿›è¡Œè°ƒæ•´ã€‚ä»»ä½•èƒ½è®©å‡½æ•°åœ¨ Jax ä¸­å·¥ä½œçš„ä¸œè¥¿ï¼Œå¹¶ä¸”è‡ªå®šä¹‰å®ç°ä¸ä¼šèŠ±è´¹ &gt; ä¸ªæœˆçš„æ—¶é—´ã€‚ å¦‚æœæ‚¨çŸ¥é“ä»»ä½•å¯è¡Œçš„æ–¹æ³•ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚è°¢è°¢å¤§å®¶ï¼ ç¼–è¾‘ï¼šæˆ‘çš„ç›®æ ‡æ˜¯ï¼šåœ¨ GPU ä¸­è¿è¡Œæ‰€æœ‰å†…å®¹ï¼Œå¹¶ä»¥å¤§è§„æ¨¡å¹¶è¡Œæ–¹å¼è¿è¡Œæ‰€æœ‰å†…å®¹ã€‚    æäº¤äºº    /u/JustZed32   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dlil7i/c_library_to_jax/</guid>
      <pubDate>Sat, 22 Jun 2024 00:07:06 GMT</pubDate>
    </item>
    <item>
      <title>AgileRL - ç”¨äºæœ€å…ˆè¿›æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„è¿›åŒ–å‹ RLOps</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dla2e8/agilerl_evolutionary_rlops_for_stateoftheart_deep/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘ä¹‹å‰å‘å¸ƒè¿‡å…³äºæˆ‘ä»¬çš„å¼ºåŒ–å­¦ä¹ è¿›åŒ–è¶…å‚æ•°ä¼˜åŒ–å®ç° SOTA ç»“æœçš„å¸–å­ï¼Œä½†æˆ‘æƒ³åˆ†äº«çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å¼€æºæ¡†æ¶ç°åœ¨å·²ç»å‘å¸ƒäº† v1.0.0 ç‰ˆæœ¬ï¼ è¯·æŸ¥çœ‹ï¼https://github.com/AgileRL/AgileRL è¯¥åº“æœ€åˆä¸“æ³¨äºé€šè¿‡å¼€åˆ›å¼ºåŒ–å­¦ä¹ çš„è¿›åŒ– HPO æŠ€æœ¯æ¥å‡å°‘è®­ç»ƒæ¨¡å‹å’Œè¶…å‚æ•°ä¼˜åŒ–æ‰€éœ€çš„æ—¶é—´ã€‚è¿›åŒ– HPO å·²è¢«è¯æ˜å¯ä»¥é€šè¿‡è‡ªåŠ¨æ”¶æ•›åˆ°æœ€ä½³è¶…å‚æ•°æ¥å¤§å¹…å‡å°‘æ€»ä½“è®­ç»ƒæ—¶é—´ï¼Œè€Œæ— éœ€è¿›è¡Œå¤§é‡çš„è®­ç»ƒè¿è¡Œã€‚ æˆ‘ä»¬ä¸æ–­æ·»åŠ æ›´å¤šç®—æ³•å’ŒåŠŸèƒ½ã€‚ AgileRL å·²ç»åŒ…å«äº†æœ€å…ˆè¿›çš„å¯è¿›åŒ–çš„åœ¨çº¿ç­–ç•¥ã€ç¦»ç­–ç•¥ã€ç¦»çº¿ã€å¤šæ™ºèƒ½ä½“å’Œä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœºå¼ºåŒ–å­¦ä¹ ç®—æ³•ä»¥åŠåˆ†å¸ƒå¼è®­ç»ƒã€‚ æˆ‘å¾ˆä¹æ„æ”¶åˆ°æ‚¨çš„åé¦ˆï¼    æäº¤äºº    /u/nicku_a   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dla2e8/agilerl_evolutionary_rlops_for_stateoftheart_deep/</guid>
      <pubDate>Fri, 21 Jun 2024 17:50:05 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆæˆ–è€…æ›´ç¡®åˆ‡åœ°è¯´ï¼Œå¯¹äºä»»ä½•ç®—æ³•æ¥è¯´ï¼Œæœºå™¨å­¦ä¹ ï¼‰çš„èƒŒæ™¯ä¸‹ï¼Œåƒç­–ç•¥æ¢¯åº¦è¿™æ ·çš„ç®—æ³•çš„å•è°ƒæ”¹è¿›æ„å‘³ç€ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒæ˜¯ç®—æ³•çš„é‡è¦å‚æ•°ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dl0meg/what_does_monotonic_improvement_of_an_algorithm/</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨é˜…è¯»ä¸åŒçš„æ–‡æœ¬ï¼Œä½†ä»ç„¶ä¸æ˜ç™½çœŸæ­£çš„å«ä¹‰ã€‚æœ‰äººå¯ä»¥è§£é‡Šä¸€ä¸‹å—ã€‚     æäº¤äºº    /u/aabra__ka__daabra   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dl0meg/what_does_monotonic_improvement_of_an_algorithm/</guid>
      <pubDate>Fri, 21 Jun 2024 10:19:25 GMT</pubDate>
    </item>
    <item>
      <title>å…³äºå¼ºåŒ–å­¦ä¹ äººå½¢v4é—®é¢˜</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dkuvm7/about_reinforcement_learning_humanoid_v4_problem/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œè¿™æ˜¯æˆ‘åœ¨ colab ä¸Šä¸ºäººå½¢æœºå™¨äºº mujoco_humanoid.ipynb - Colab (google.com) ç¼–å†™çš„ä»£ç ï¼ˆæ‚¨å¯ä»¥åœ¨çº¿è¿è¡Œï¼‰ã€‚ä½†æˆ‘ä¸çŸ¥é“å“ªä¸€æ­¥é”™äº†ï¼Œç»“æœå°±æ˜¯ç½‘ç»œæ²¡æ³•å­¦ä¹ æœºå™¨äººæ§åˆ¶:( çœŸçš„éœ€è¦å¸®åŠ©ã€‚    submitted by    /u/Inevitable_Sea_8466   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dkuvm7/about_reinforcement_learning_humanoid_v4_problem/</guid>
      <pubDate>Fri, 21 Jun 2024 03:57:38 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ä¸­è®¾ç½®ç§å­çš„å®ç”¨è§„åˆ™</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dkh0kp/practical_rules_for_setting_seed_in_rl/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼å¦‚æœè¿™ä¸ªé—®é¢˜é‡å¤äº†ï¼Œæˆ‘å¾ˆæŠ±æ­‰ï¼Œä½†åœ¨é˜…è¯»äº†è®¸å¤šä¸æ­¤ç›¸å…³çš„å¸–å­åï¼Œæˆ‘ä»ç„¶æ‰¾ä¸åˆ°æˆ‘çš„é—®é¢˜çš„ç­”æ¡ˆã€‚ å‡è®¾æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªæ¨¡å‹ï¼Œå…¶æ€§èƒ½æ ¹æ®åˆå§‹ç§å­è€Œæœ‰å¾ˆå¤§å·®å¼‚ã€‚ æˆ‘åº”è¯¥å›ºå®šä¸€ä¸ªç§å­æˆ–ä¸€ç»„ç§å­æ¥æ¯”è¾ƒä¸åŒç‰¹å¾æˆ–å¥–åŠ±å‡½æ•°çš„å½±å“ï¼Œè¿˜æ˜¯åº”è¯¥å§‹ç»ˆä½¿ç”¨éšæœºç§å­å’Œå¹³å‡å€¼è¿è¡Œï¼Œå³ä½¿åœ¨å¼€å‘æ¨¡å‹æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ï¼Ÿ å¦‚æœæ˜¯ç¬¬äºŒç§æƒ…å†µï¼Œæ‚¨å¦‚ä½•äº†è§£æ€§èƒ½æ”¹è¿›æ˜¯ç”±äºç§å­è¿˜æ˜¯ç”±äºç®¡é“ä¸­çš„å…¶ä»–å˜åŒ–ï¼Ÿ    æäº¤äºº    /u/ParfaitFinancial9765   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dkh0kp/practical_rules_for_setting_seed_in_rl/</guid>
      <pubDate>Thu, 20 Jun 2024 17:15:15 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆé‡è¦æ€§é‡‡æ ·æ¯”ä¾‹çš„æœŸæœ›å€¼æ˜¯1å‘¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dkfrzp/why_is_the_expected_value_of_the_importance/</link>
      <description><![CDATA[        æäº¤äºº    /u/hearthstoneplayer100   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dkfrzp/why_is_the_expected_value_of_the_importance/</guid>
      <pubDate>Thu, 20 Jun 2024 16:23:57 GMT</pubDate>
    </item>
    <item>
      <title>RLHF çš„å¯åŠ¨ä»£ç åº“ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dkf3yr/starter_code_repos_for_rlhf/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘åˆšåˆšå¼€å§‹ç ”ç©¶ LLMï¼Œç‰¹åˆ«æ˜¯ RLHFã€‚æˆ‘æ­£åœ¨å¯»æ‰¾å¯ä»¥ä½œä¸ºèµ·ç‚¹çš„å¼€æ”¾è¯¾ç¨‹åº“ã€‚æˆ‘å‘ç°äº†ä»¥ä¸‹å†…å®¹ï¼š  https://github.com/OpenLLMAI/OpenRLHF https://github.com/huggingface/trl https://github.com/CarperAI/trlx  æ‰€æœ‰è¿™äº›ä¼¼ä¹éƒ½ä¸ transformers åº“å…¼å®¹ï¼Œè€Œè¯¥åº“åˆæ”¯æŒå®Œæ•´çš„å¼€æºï¼ˆä»£ç +æ•°æ®ï¼Œè€Œä¸ä»…ä»…æ˜¯æƒé‡ï¼‰æ¨¡å‹ï¼Œä¾‹å¦‚ Pythiaã€‚æ‰€æœ‰è¿™äº›ä¼¼ä¹éƒ½å¾—åˆ°äº†ç›¸å½“ç¨‹åº¦çš„æ›´æ–°ã€‚1) å’Œ 3) æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€‚æ‚¨ä¼šæ¨èå“ªä¸€ä¸ªï¼Ÿè¿˜æœ‰å…¶ä»–å»ºè®®å—ï¼Ÿ æŠ±æ­‰ï¼Œæˆ‘çš„é—®é¢˜å¯èƒ½æœ‰äº›å¹¼ç¨šã€‚æˆ‘æ˜¯ LLM æ–°æ‰‹ :)    æäº¤äºº    /u/South-Conference-395   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dkf3yr/starter_code_repos_for_rlhf/</guid>
      <pubDate>Thu, 20 Jun 2024 15:56:11 GMT</pubDate>
    </item>
    <item>
      <title>ç”¨çŠ¶æ€ä»·å€¼åŸºçº¿æ¥å¼ºåŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dk9lwm/reinforce_with_statevalue_baseline/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘æ˜¯ RL çš„æ–°æ‰‹ï¼Œæˆ‘æ­£åœ¨å°è¯•äº†è§£å¦‚ä½•ä½¿ç”¨çŠ¶æ€å€¼åŸºçº¿ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºç¬¬äºŒä¸ªç¥ç»ç½‘ç»œï¼‰è¿›è¡Œ REINFORCEã€‚ä¾‹å¦‚ï¼Œåœ¨æœ‰ä¸¤ä¸ªç©å®¶çš„æ£‹ç›˜æ¸¸æˆä¸­ï¼Œæˆ‘è®­ç»ƒä¸€ä¸ªä»£ç†å¯¹æŠ—ä¸€ä¸ªéšæœºå¯¹æ‰‹ï¼Œä½•æ—¶åº”è¯¥å­˜å‚¨å¥–åŠ±å’Œä»·å€¼ï¼Ÿæˆ‘åº”è¯¥åœ¨ä»£ç†ç§»åŠ¨åæ‰è€ƒè™‘å¥–åŠ±å¹¶ä¼°è®¡ä»·å€¼ï¼Œè¿˜æ˜¯åœ¨å¯¹æ‰‹ç§»åŠ¨åä¹Ÿè€ƒè™‘å¥–åŠ±å¹¶ä¼°è®¡ä»·å€¼ï¼Ÿ æ­¤å¤–ï¼Œæˆ‘ä¸ç¡®å®šæˆ‘æ˜¯å¦æ­£ç¡®ç†è§£äº†å¦‚ä½•è®¡ç®—ç­–ç•¥æŸå¤±å’Œä»·å€¼ç­–ç•¥æŸå¤±ã€‚æˆ‘çš„ç†è§£æ˜¯ï¼Œå¯¹äºç­–ç•¥æŸå¤±ï¼Œæˆ‘å¿…é¡»è®¡ç®—æŠ˜æ‰£å¥–åŠ±ï¼Œä»ä¸­å‡å»å€¼ä»¥è·å¾—ä¼˜åŠ¿ï¼Œç„¶åå°†å¯¹æ•°æ¦‚ç‡ä¸ä¼˜åŠ¿ç›¸ä¹˜ä»¥è·å¾—ç¼©æ”¾å¯¹æ•°æ¦‚ç‡ï¼Œæœ€åå°†å®ƒä»¬å…¨éƒ¨ç›¸åŠ ï¼ˆèšåˆï¼‰ã€‚å¯¹äºä»·å€¼ç­–ç•¥ï¼Œæˆ‘çš„ç†è§£æ˜¯æˆ‘åº”è¯¥è®¡ç®—ä¼°è®¡å€¼å’ŒæŠ˜æ‰£å¥–åŠ±ä¹‹é—´çš„ MSE æŸå¤±ã€‚ å¯¹å—ï¼Ÿ    æäº¤äºº    /u/miroshuSan   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dk9lwm/reinforce_with_statevalue_baseline/</guid>
      <pubDate>Thu, 20 Jun 2024 11:45:50 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ PPO åˆ¶ä½œåˆ†ç±»å™¨ï¼Œé‡åˆ°å†…å­˜é”™è¯¯</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1dk6npn/making_a_classifier_using_ppo_encountering_memory/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1dk6npn/making_a_classifier_using_ppo_encountering_memory/</guid>
      <pubDate>Thu, 20 Jun 2024 08:30:16 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚æœ PPO å—åˆ°ç¨€ç–å¥–åŠ±çš„å½±å“ï¼Œé‚£ä¹ˆ InstructGPT å’Œ Learning to Summarize æ˜¯å¦‚ä½•ä½¿å…¶å‘æŒ¥ä½œç”¨çš„å‘¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1djz7iw/if_ppo_suffers_from_sparse_reward_how_did/</link>
      <description><![CDATA[æˆ‘è§è¿‡å¾ˆå¤šå…³äº PPO å¦‚ä½•éš¾ä»¥åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­å‘æŒ¥ä½œç”¨çš„è®¨è®ºã€‚åœ¨ instructGPT å’Œå­¦ä¹ ä»äººç±»åé¦ˆä¸­æ€»ç»“çš„æƒ…å†µä¸‹ï¼Œä»…åœ¨ä¸€é•¿ä¸²é‡‡æ ·æ ‡è®°çš„æœ€åä¸€ä¸ªæ ‡è®°å¤„ç»™äºˆå¥–åŠ±ã€‚ç‰¹åˆ«æ˜¯å¯¹äºä¸€äº›æ¶‰åŠéå¸¸é•¿çš„ä»£æ•°ï¼ˆ1000 ä¸ªåŠ¨ä½œèŒƒå›´ï¼‰ä¸”æœ€ååªæœ‰ä¸€ä¸ªå¥–åŠ±çš„ç°ä»£ RLHF ä»»åŠ¡ - PPO å¦‚ä½•åœ¨è¿™é‡Œå–å¾—æˆåŠŸï¼Ÿæˆ‘æ˜¯å¦é—æ¼äº†ä¼˜åŒ–ï¼Ÿ    æäº¤äºº    /u/idioticfuse   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1djz7iw/if_ppo_suffers_from_sparse_reward_how_did/</guid>
      <pubDate>Thu, 20 Jun 2024 01:01:39 GMT</pubDate>
    </item>
    <item>
      <title>â€œGUI-WORLDï¼šé¢å‘ GUI çš„å¤šæ¨¡æ€ LLM ä»£ç†çš„æ•°æ®é›†â€ï¼ŒChen ç­‰äºº 2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1djxzhm/guiworld_a_dataset_for_guioriented_multimodal/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1djxzhm/guiworld_a_dataset_for_guioriented_multimodal/</guid>
      <pubDate>Thu, 20 Jun 2024 00:00:43 GMT</pubDate>
    </item>
    <item>
      <title>â€œåœ¨è®­ç»ƒå’Œæ¨ç†ä¸­æƒè¡¡è®¡ç®—ï¼šæˆ‘ä»¬æ¢ç´¢äº†å‡ ç§åœ¨è®­ç»ƒæˆ–æ¨ç†ä¸ŠèŠ±è´¹æ›´å¤šèµ„æºä¹‹é—´è¿›è¡Œæƒè¡¡çš„æŠ€æœ¯ï¼Œå¹¶æè¿°äº†è¿™ç§æƒè¡¡çš„å±æ€§ã€‚æˆ‘ä»¬æ¦‚è¿°äº†å¯¹äººå·¥æ™ºèƒ½æ²»ç†çš„ä¸€äº›å½±å“â€ï¼ŒEpochAI</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1djxm5z/trading_off_compute_in_training_and_inference_we/</link>
      <description><![CDATA[        æäº¤äºº    /u/gwern   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1djxm5z/trading_off_compute_in_training_and_inference_we/</guid>
      <pubDate>Wed, 19 Jun 2024 23:43:06 GMT</pubDate>
    </item>
    <item>
      <title>â€œå›´æ£‹ AI èƒ½å¦å…·æœ‰å¯¹æŠ—é²æ£’æ€§ï¼Ÿâ€ï¼ŒTseng ç­‰äººï¼Œ2024 å¹´ï¼ˆKataGo çš„â€œç»•åœˆâ€æ”»å‡»å¯ä»¥è¢«å‡»è´¥ï¼Œä½†ä»ç„¶å¯ä»¥æ‰¾åˆ°æ›´å¤šæ”»å‡»ï¼›è¿™å¹¶ä¸æ˜¯ç”±äº CNNï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1djv1r3/can_go_ais_be_adversarially_robust_tseng_et_al/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1djv1r3/can_go_ais_be_adversarially_robust_tseng_et_al/</guid>
      <pubDate>Wed, 19 Jun 2024 21:48:09 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ RLlib è¿›è¡Œå¤šæ™ºèƒ½ä½“ä¾›åº”é“¾ä¼˜åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1djltne/multiagent_supply_chain_optimization_with_rllib/</link>
      <description><![CDATA[äº²çˆ±çš„ç¤¾åŒºï¼Œ æˆ‘æ­£åœ¨å¯»æ‰¾æœ‰å…³æˆ‘ç›®å‰åœ¨é¡¹ç›®ä¸­é¢ä¸´çš„æŒ‘æˆ˜æ€§é—®é¢˜çš„è§è§£å’Œå¸®åŠ©ã€‚ é—®é¢˜ï¼š ä»“åº“ X é¢ä¸´ç€ä¸€é¡¹å¤æ‚çš„ä»»åŠ¡ï¼Œå³ä¼˜åŒ–å…¶ä¾›åº”é“¾æµç¨‹ï¼Œä»¥åº”å¯¹æ¥è‡ª 200 å¤šå®¶ä¾›åº”å•†çš„ 1000 ç§ä¸åŒäº§å“ã€‚ç›®æ ‡æ˜¯é¿å…åº“å­˜è¿‡å‰©ã€é˜²æ­¢ç¼ºè´§å¹¶å§‹ç»ˆæ»¡è¶³å®¢æˆ·éœ€æ±‚ã€‚äº§å“åˆ†ä¸ºæ˜“è…çƒ‚å’Œä¸æ˜“è…çƒ‚ä¸¤ç±»ã€‚ æˆ‘ä»¬æå‡ºçš„è§£å†³æ–¹æ¡ˆï¼š å¤šæ™ºèƒ½ä½“ç¯å¢ƒï¼Œå…¶ä¸­æ¯ä¸ªæ™ºèƒ½ä½“éƒ½ä¼šå­¦ä¹ äº§å“çº¿çš„ç­–ç•¥ã€‚æˆ‘ä»¬ä½¿ç”¨äº†é€šè¿‡ Ray RLlib å®ç°çš„ PPO ç®—æ³•ã€‚æˆ‘ä»¬çš„ RL ç¯å¢ƒæ—¨åœ¨è€ƒè™‘ä»¥ä¸‹æ“ä½œï¼š  ä½•æ—¶ä¸‹é‡‡è´­è®¢å• è®¢è´­å“ªäº›äº§å“ æ¯ç§äº§å“çš„è®¢è´­æ•°é‡ è€ƒè™‘å“ªä¸ªä¾›åº”å•†  ä»£ç†æ ¹æ®è¿‡å»ä¸€å¹´çš„å†å²é”€å”®æƒ…å†µè¿›è¡Œè®­ç»ƒã€‚ç¯å¢ƒç”± N ä¸ªè§‚å¯Ÿå€¼ç»„æˆï¼Œä»£è¡¨åº“å­˜æ°´å¹³å’Œè¶‹åŠ¿ï¼Œä»¥åŠ 2 ä¸ªæ“ä½œï¼ˆè®¢è´­æ•°é‡å’Œä¾›åº”å•† IDï¼‰ã€‚ä»£ç†åœ¨å…·æœ‰å…±äº«ç­–ç•¥é€‰é¡¹é›†çš„å¤šä»£ç†ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒï¼Œæ¯ä¸ªæƒ…èŠ‚ç”± 365 ä¸ªæ—¶é—´æ­¥éª¤ç»„æˆã€‚å¥–åŠ±æ˜¯æ ¹æ®ä¸€ç³»åˆ—è¡ŒåŠ¨ååœ¨ä¸€ä¸ªæƒ…èŠ‚ä¸­è·å¾—çš„å‡€åˆ©æ¶¦è®¡ç®—çš„ã€‚æ­¤å¤–ï¼Œå¥–åŠ±å¡‘é€ ç”¨äºæŒ‡å¯¼ä»£ç†åšå‡ºæ­£ç¡®çš„å†³ç­–ã€‚å½“é”™è¿‡éœ€æ±‚ã€è®¢å•å»¶è¿Ÿå’Œé€‰æ‹©é”™è¯¯çš„ä¾›åº”å•†ï¼ˆä»·æ ¼æ›´é«˜æˆ–äº¤è´§æ—¶é—´æ›´é•¿ï¼‰æ—¶ï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­æ–½åŠ æƒ©ç½šã€‚å®é™…ä¸Šï¼Œä»£ç†åœ¨æ—¶é—´æ­¥éª¤â€œtâ€åšå‡ºçš„æ¯ä¸ªå†³å®šéƒ½ä¼šå¯¹æœªæ¥æ—¶é—´æ­¥éª¤â€œt+Mâ€äº§ç”Ÿè´Ÿé¢/æ­£é¢å½±å“ã€‚ åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ï¼Œå†å²æ•°æ®çš„éœ€æ±‚éƒ½ç”¨äºæ›´æ–°è§‚å¯Ÿå€¼ã€‚å› æ­¤ï¼Œé¢„è®¡ä»£ç†å°†è¾¾åˆ°æˆ–è¶…è¿‡å»å¹´çš„å‡€åˆ©æ¶¦ã€‚ å…³äºç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”±å…·æœ‰ ReLU æ¿€æ´»çš„çº¿æ€§å±‚ç»„æˆï¼Œåˆ†æ”¯ä¸º softmax ç”¨äºä¾›åº”å•†é€‰æ‹©ï¼Œå¹¶ä¸ºæ•°é‡åˆ†æ”¯è¾“å‡ºå€¼ä½¿ç”¨è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°ï¼ŒèŒƒå›´ä¸º [0, max_purchase_quantity]ã€‚å·²åº”ç”¨æ‰¹é‡å½’ä¸€åŒ–æ¥å¢å¼ºæ”¶æ•›å¹¶å‡å°‘è¿‡åº¦æ‹Ÿåˆï¼Œå¹¶å·²ç»“åˆæ³¨æ„åŠ›æœºåˆ¶æ¥å…³æ³¨è§‚å¯Ÿç©ºé—´ä¸­çš„å…³é”®å€¼ã€‚ é‡åˆ°çš„é—®é¢˜ï¼š å°½ç®¡ä»˜å‡ºäº†åŠªåŠ›ï¼Œä½†æˆ‘åœ¨å®ç°æœ€ä½³æ”¶æ•›å’Œæ€§èƒ½æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚è®­ç»ƒè¿‡ç¨‹æ˜æ˜¾å¾ˆæ…¢ï¼ˆä½¿ç”¨ Nvidia GPU GeForce RTX 3080 10GBï¼‰ã€‚åœ¨å¯¹ 50 ç§äº§å“è¿›è¡Œäº† 15,000 æ¬¡è¿­ä»£ï¼ˆå†æ—¶ 28 å°æ—¶ï¼‰ä¹‹åï¼Œä»£ç†ä»æœªè¾¾åˆ°é¢„æœŸçš„å¥–åŠ±ï¼Œæ— æ³•è‡ªä¸»è®¾ç½®è®¢å•æ•°é‡å’Œä¾›åº”å•† IDã€‚æˆ‘ä»¬å°è¯•åœ¨å¥–åŠ±å‡½æ•°ä¸­å¯¹é”™è¯¯å†³ç­–å®æ–½æƒ©ç½šï¼Œå°è¯•äº†ä¸åŒçš„æ¢ç´¢ç­–ç•¥ï¼Œä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ï¼ˆé€æ­¥åº”ç”¨æƒ©ç½šï¼‰ï¼Œå¹¶åº”ç”¨äº†å¥–åŠ±è§„èŒƒåŒ–ã€‚ç„¶è€Œï¼Œç»“æœå¹¶ä¸å¦‚é¢„æœŸã€‚ æ‚¨å¯ä»¥å¦‚ä½•æä¾›å¸®åŠ©ï¼š æˆ‘æ­£åœ¨å¯»æ±‚å¸®åŠ©å’Œæ–°è§‚ç‚¹ã€‚å¦‚æœæ‚¨æœ‰ä¾›åº”é“¾ä¼˜åŒ–é¢†åŸŸå¼ºåŒ–å­¦ä¹ çš„ç»éªŒï¼Œé‚£ä¹ˆå…³äºæé«˜æ”¶æ•›é€Ÿåº¦ã€å¤„ç†å¤æ‚åŠ¨ä½œç©ºé—´æˆ–æœ‰æ•ˆæ¢ç´¢ç­–ç•¥çš„è§è§£çš„å»ºè®®å°†éå¸¸æœ‰ä»·å€¼ã€‚ æ­¤å¤–ï¼Œå¦‚æœæ‚¨é‡åˆ°è¿‡ç±»ä¼¼çš„æŒ‘æˆ˜æˆ–åœ¨ä¾›åº”é“¾ç¯å¢ƒä¸­æˆåŠŸå®æ–½äº† RL ä»£ç†ï¼Œæˆ‘ä»¬å°†éå¸¸æ„Ÿæ¿€æ‚¨å¯¹è°ƒæ•´è¶…å‚æ•°ã€è®¾è®¡æœ‰æ•ˆå¥–åŠ±å‡½æ•°çš„æŒ‡å¯¼æˆ–ä»»ä½•å…¶ä»–ç›¸å…³å»ºè®®ã€‚ æå‰æ„Ÿè°¢æ‚¨è€ƒè™‘è¿™ä¸ªä¸»é¢˜ã€‚ æˆ‘çƒ­åˆ‡æœŸå¾…æ‚¨çš„å›å¤å’Œè§è§£ã€‚    æäº¤äºº    /u/WoodenDot8305   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1djltne/multiagent_supply_chain_optimization_with_rllib/</guid>
      <pubDate>Wed, 19 Jun 2024 15:22:31 GMT</pubDate>
    </item>
    </channel>
</rss>