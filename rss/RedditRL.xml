<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Sun, 03 Dec 2023 01:03:59 GMT</lastBuildDate>
    <item>
      <title>æ¼”å‘˜è¯„è®ºå®¶ï¼šÏ€(A|S,Î¸) æ˜¯ä»€ä¹ˆå½¢çŠ¶ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/189drnd/actor_critic_what_is_the_shape_of_Ï€asÎ¸/</link>
      <description><![CDATA[Ï€(A|S,Î¸) åœ¨ softmax æƒ…å†µä¸‹ä¸º exp(Î¸âŠ¤Ax(S))/ Î£exp(Î¸âŠ¤Ax(S) )). å½¢çŠ¶åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ ç»™å®šåŠ¨ä½œæ•°é‡ = k å’Œç‰¹å¾æ•°é‡ = d â€‹   ç”±   æäº¤ /u/Fashism   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/189drnd/actor_critic_what_is_the_shape_of_Ï€asÎ¸/</guid>
      <pubDate>Sat, 02 Dec 2023 21:35:56 GMT</pubDate>
    </item>
    <item>
      <title>å…·æœ‰å¿«é€Ÿä¸”å¥å¿˜è®°å¿†çš„å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1896eu4/reinforcement_learning_with_fast_and_forgetful/</link>
      <description><![CDATA[   /u/smorad  [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1896eu4/reinforcement_learning_with_fast_and_forgetful/</guid>
      <pubDate>Sat, 02 Dec 2023 15:45:19 GMT</pubDate>
    </item>
    <item>
      <title>ç®€å•çš„ Q å­¦ä¹ ä¸è·¨æ™ºèƒ½ä½“å…±äº«å€¼è¡¨</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18902nv/simple_qlearning_with_value_table_sharing_across/</link>
      <description><![CDATA[å›´ç»•æµ‹è¯•è½¨é“è¿›è¡Œæœ´ç´  q å­¦ä¹ çš„ç®€å•ç¤ºä¾‹ï¼Œä½¿ç”¨ C++ ä¸­çš„ raylib å®ç° - è¾“å…¥ï¼š5 ä¸ªå…‰çº¿æŠ•å°„æ¯ä¸ªä¼ æ„Ÿå™¨åˆ†ä¸º 3 ä¸ªåŒºåŸŸï¼šå±é™©è¿‘ã€ä¸­ã€è¿œã€‚ ï¼ˆæä¾›3^5=243ä¸ªçŠ¶æ€ï¼‰ - åŠ¨ä½œï¼šä»¥åŒ€é€Ÿvç›´è¡Œï¼Œä»¥v/2å‘å·¦è½¬å‘ï¼Œä»¥v/2å‘å³è½¬å‘ ç»“æŸæ—¶æ¯ä¸ªepisodeï¼Œéƒ½ä¼šè®¡ç®—æ‰€æœ‰æ™ºèƒ½ä½“ä¹‹é—´çš„qè¡¨å¹³å‡å€¼å¹¶å°†å…¶è®¾ç½®å›æ™ºèƒ½ä½“ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ªepisodeä¹‹åå…±äº«çŸ¥è¯†ã€‚å½“ epsilon é™è‡³é›¶æ—¶ï¼Œæˆ‘ä»¬åªçœ‹åˆ° 1 æ¬¡å‡åŒ€ç§»åŠ¨ï¼Œè€Œä¸æ˜¯ 30 æ¬¡ï¼Œå› ä¸ºæ‰€æœ‰æ™ºèƒ½ä½“å§‹ç»ˆé€‰æ‹©è´ªå©ªåŠ¨ä½œã€‚ https://reddit.com/link/18902nv/video/hnje6htdou3c1/player   ç”±   æäº¤ /u/goksankobe   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18902nv/simple_qlearning_with_value_table_sharing_across/</guid>
      <pubDate>Sat, 02 Dec 2023 09:26:38 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘èƒ½çŸ¥é“ç»‘å®š k æ˜¯å¦‚ä½•ç»‘å®šçš„å—ï¼Ÿæ¥æºï¼šå¼ºåŒ–å­¦ä¹ ï¼šç†è®ºä¸ç®—æ³•ï¼Œä½œè€…ï¼šAlekh Agarwalã€Nan Jiangã€Sham M. Kakade å’Œ Wen Sun https://rltheorybook.github.io/rltheorybook_AJKS.pdf</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188xrhh/can_i_know_how_the_bound_k_was_bound_origin/</link>
      <description><![CDATA[       ç”±   æäº¤/u/Professional_Card176   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188xrhh/can_i_know_how_the_bound_k_was_bound_origin/</guid>
      <pubDate>Sat, 02 Dec 2023 06:41:09 GMT</pubDate>
    </item>
    <item>
      <title>å¤šä»£ç†å¼ºåŒ–å­¦ä¹ åŸºçº¿</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188ox6r/mutli_agent_reinforcement_learning_baselines/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ‰¾ç¨³å®šåŸºçº¿ 3 çš„ç­‰æ•ˆç‰ˆæœ¬ï¼Œä½†é¡¾åæ€ä¹‰ï¼Œå®ƒé€‚ç”¨äº MARLï¼Œä»¥ä¾¿æˆ‘å¯ä»¥åœ¨è‡ªå®šä¹‰ MARL ç¯å¢ƒä¸Šå¯¹ç®—æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚æåˆ°çš„å¤§å¤šæ•°æ–¹æ³•éƒ½åˆ©ç”¨ä¸ä¸åŒåº“ï¼ˆä¾‹å¦‚ Tianshouã€CleanRL å’Œ Stable Baselines 3 æœ¬èº«ï¼‰å…±äº«å‚æ•°ã€‚ä¸åŒçš„ MARL ç®—æ³•è¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„æ ‡å‡†åŒ–åŸºçº¿å—ï¼Ÿ   ç”±   æäº¤/u/blitzkreig3  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188ox6r/mutli_agent_reinforcement_learning_baselines/</guid>
      <pubDate>Fri, 01 Dec 2023 22:55:03 GMT</pubDate>
    </item>
    <item>
      <title>å½“å…ƒå­¦ä¹ é‡åˆ°åœ¨çº¿å’ŒæŒç»­å­¦ä¹ æ—¶ï¼šä¸€é¡¹è°ƒæŸ¥</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188o8s1/when_metalearning_meets_online_and_continual/</link>
      <description><![CDATA[      è®ºæ–‡ï¼šhttps://arxiv.org/abs/2311.05241 æ‘˜è¦ï¼š &lt; blockquote&gt; åœ¨è¿‡å»çš„åå¹´ä¸­ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œåœ¨ä½¿ç”¨æ¶‰åŠå¹¿æ³›æ•°æ®é›†çš„å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™çš„è®­ç»ƒæ–¹æ¡ˆæ–¹é¢å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚åœ¨è¿™ä¸€æˆå°±çš„åŸºç¡€ä¸Šï¼Œæ¢ç´¢ç¥ç»ç½‘ç»œåœ¨å…¶ä»–å­¦ä¹ åœºæ™¯ä¸­åº”ç”¨çš„ç ”ç©¶æ¿€å¢ã€‚å…ƒå­¦ä¹ æ˜¯ä¸€ä¸ªå¼•èµ·å¹¿æ³›å…³æ³¨çš„è‘—åæ¡†æ¶ã€‚é€šå¸¸è¢«æè¿°ä¸ºâ€œå­¦ä¼šå­¦ä¹ â€ï¼Œå…ƒå­¦ä¹ æ˜¯ä¸€ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•æ¥ä¼˜åŒ–å­¦ä¹ ç®—æ³•ã€‚å…¶ä»–æ„Ÿå…´è¶£çš„åˆ†æ”¯æ˜¯æŒç»­å­¦ä¹ å’Œåœ¨çº¿å­¦ä¹ ï¼Œä¸¤è€…éƒ½æ¶‰åŠä½¿ç”¨æµæ•°æ®å¢é‡æ›´æ–°æ¨¡å‹ã€‚è™½ç„¶è¿™äº›æ¡†æ¶æœ€åˆæ˜¯ç‹¬ç«‹å¼€å‘çš„ï¼Œä½†æœ€è¿‘çš„å·¥ä½œå·²ç»å¼€å§‹ç ”ç©¶å®ƒä»¬çš„ç»„åˆï¼Œæå‡ºæ–°é¢–çš„é—®é¢˜è®¾ç½®å’Œå­¦ä¹ ç®—æ³•ã€‚ç„¶è€Œï¼Œç”±äºå¤æ‚æ€§å¢åŠ ä¸”ç¼ºä¹ç»Ÿä¸€æœ¯è¯­ï¼Œå³ä½¿å¯¹äºç»éªŒä¸°å¯Œçš„ç ”ç©¶äººå‘˜æ¥è¯´ï¼Œè¾¨åˆ«å­¦ä¹ æ¡†æ¶ä¹‹é—´çš„å·®å¼‚ä¹Ÿå¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†ä¿ƒè¿›æ¸…æ™°çš„ç†è§£ï¼Œæœ¬æ–‡æä¾›äº†ä¸€é¡¹å…¨é¢çš„è°ƒæŸ¥ï¼Œä½¿ç”¨ä¸€è‡´çš„æœ¯è¯­å’Œæ­£å¼çš„æè¿°æ¥ç»„ç»‡å„ç§é—®é¢˜è®¾ç½®ã€‚é€šè¿‡æ¦‚è¿°è¿™äº›å­¦ä¹ èŒƒå¼ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ—¨åœ¨ä¿ƒè¿›è¿™ä¸€æœ‰å‰é€”çš„ç ”ç©¶é¢†åŸŸçš„è¿›ä¸€æ­¥è¿›æ­¥ã€‚  https://preview.redd.it/ag7xaviaer3c1.png?width=1249&amp;format=png&amp;auto=webp&amp;s=c4c0aa093ac 20ae7f6f567c9427f9a9e76e3a7ee&lt; /a&gt;   ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188o8s1/when_metalearning_meets_online_and_continual/</guid>
      <pubDate>Fri, 01 Dec 2023 22:24:42 GMT</pubDate>
    </item>
    <item>
      <title>ä¼°è®¡å…·æœ‰å›ºå®šæ­¥æ•°çš„ç¯å¢ƒçš„çŠ¶æ€å€¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188jh9d/estimating_state_value_for_environments_with/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è‡ªå®šä¹‰ç¯å¢ƒä¸­è®­ç»ƒ RL ä»£ç†ã€‚æˆ‘çš„ç¯å¢ƒåœ¨æ‰§è¡Œä¸€å®šæ•°é‡çš„æ“ä½œåç»ˆæ­¢ã€‚æˆ‘çš„ç›´è§‰æ˜¯ï¼Œå½“æ¶‰åŠåˆ°é€šè¿‡ä»·å€¼ç½‘ç»œä¼°è®¡çŠ¶æ€ä»·å€¼æ—¶ï¼Œå‰©ä½™çš„æ­¥éª¤æ•°åº”è¯¥æ˜¯ä»·å€¼ç½‘ç»œè¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚ ï¼ˆç›®å‰æˆ‘æ²¡æœ‰å°†æ­¤ä½œä¸ºè¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚ï¼‰è¿™æ˜¯æ­£ç¡®çš„å—ï¼Ÿæˆ‘å¾ˆæƒ³å¬å¬æ‚¨å¯¹æ­¤çš„æƒ³æ³•ï¼Œå¦‚æœæ‚¨èƒ½ç»™æˆ‘æŒ‡å‡ºä»»ä½•ç°æœ‰çš„å®ç°æˆ–å®Œæˆæ­¤æ“ä½œçš„è®ºæ–‡ï¼Œé‚£å°±å¤ªå¥½äº†ï¼Ÿè°¢è°¢ï¼   ç”±   æäº¤ /u/morakorvai   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188jh9d/estimating_state_value_for_environments_with/</guid>
      <pubDate>Fri, 01 Dec 2023 18:56:14 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ å¦‚ä½•å¤„ç†å¤šä¸ªåŠ¨ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188iiew/how_does_rl_work_with_multiple_motions/</link>
      <description><![CDATA[ä¾‹å¦‚ï¼Œè¿™æ˜¯ä½¿ç”¨Unityåˆ›å»ºçš„ï¼Œè¿˜æ˜¯å®ƒè‡ªå·±çš„gymï¼Ÿ https://www.youtube.com/watch?v=SsJ_AusntiU&amp;pp=ygUncmVpbmZvcmNlbWVudCBsZ WFybmluZyB0ZWFjaCBob3cgdG8gYm94&lt; /p&gt; ä»è§†é¢‘ä¸­å¾ˆéš¾çœ‹å‡ºã€‚  ä»¤äººå›°æƒ‘çš„æ˜¯å®ƒä»¬æ˜¯å¦‚ä½•é“¾æ¥åœ¨ä¸€èµ·çš„ï¼Œä»¥åŠæœºå™¨å­¦ä¹ ä»£ç†æ˜¯å¦å¯ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘äº†è§£å¦‚ä½•è®­ç»ƒæ¨¡å‹ç«™ç«‹ï¼Œä½†å¦‚ä½•åŒæ—¶ç«™ç«‹ã€èµ·èº«ã€èµ°åŠ¨å’Œè£…ç®±ï¼Ÿ   è¿™ä¸€åˆ‡éƒ½æ˜¯åœ¨æ•°åäº¿æ¬¡é‡å¤ä¸­é€šè¿‡ç›¸åŒçš„è§‚å¯Ÿå’Œç›¸åŒçš„å¥–åŠ±å®Œæˆçš„å—ï¼Ÿ  æˆ–è€…æ˜¯å¦æœ‰ 1 ä¸ªæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•ç«™ç«‹ï¼Œ1 ä¸ªæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•ç«™èµ·æ¥ã€‚ 1 ä¸ªå­¦ä¹ å¦‚ä½•ç§»åŠ¨çš„ç®€åŒ–æ¨¡å‹ã€‚ç­‰ç­‰ã€‚   ç„¶åè¿™äº›æ¨¡å‹ä½¿ç”¨å¸ƒå¨ƒå¨ƒç‰©ç†åŸç†ç›¸äº’ç»‘å®šã€‚æœ¬è´¨ä¸Šï¼Œæ­£åœ¨å­¦ä¹ çš„æ¨¡å‹ä¸Šçš„å…³èŠ‚ä¸äº†è§£æ¯ä¸ªå•ç‹¬è¿åŠ¨çš„æ¨¡å‹ç»‘å®šåœ¨ä¸€èµ·ã€‚  æˆ‘é—®çš„åŸå› æ˜¯æˆ‘å‘ç° Unity ML ä»£ç†æœ‰ç‚¹æœ‰é™ã€‚å°±åƒåŠ¨ä½œå¤ªéšæœºä¸€æ ·ï¼Œæˆ‘çš„å¹³å‡å¥–åŠ±å‡ ä¹æ²¡æœ‰å¢é•¿ã€‚è¿™äº›åŠ¨ä½œæ˜¯å¦åº”è¯¥åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¾—åˆ°æ”¹å–„ï¼Œæˆ–è€…å®ƒä»¬åªæ˜¯åœ¨æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹ä¸­éšæœºè¿›è¡Œï¼Ÿå³ä½¿æ˜¯åƒç§»åŠ¨åˆ°ç›®æ ‡è¿™æ ·ç®€å•çš„äº‹æƒ…ï¼Œæˆ‘ä¹Ÿä¼šå‘ç°ä»£ç†ä¸æ–­åœ°æŠ–åŠ¨å¹¶éšæœºåœ°æ¥å›ç§»åŠ¨   ç”±   æäº¤ /u/Sharp-Cat2319   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188iiew/how_does_rl_work_with_multiple_motions/</guid>
      <pubDate>Fri, 01 Dec 2023 18:14:51 GMT</pubDate>
    </item>
    <item>
      <title>Unity ä¹‹å¤–å…è®¸å¯¼å…¥æ¨¡å‹ç­‰çš„ä»»ä½•ç‰©ç†å¼•æ“å¥èº«æˆ¿ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188iazm/any_physics_engine_gyms_outside_of_unity_that/</link>
      <description><![CDATA[æˆ‘å‘ç°ç”¨äºç»Ÿä¸€çš„ ML Agent æœ‰ç‚¹è¿‡æ—¶ä¸”æœ‰å±€é™æ€§ï¼Œå¹¶ä¸”æ¯”æœºå™¨äººæ›´é€‚åˆæ¸¸æˆå¼€å‘ï¼Œæˆ‘æƒ³åˆ›å»ºè‡ªå·±çš„å¥èº«æˆ¿å¯¹äºåƒ 2D æ¸¸æˆè¿™æ ·çš„ç®€å•ä¸œè¥¿ï¼Œå®ƒéå¸¸ç®€å•ï¼Œä½†æˆ‘æƒ³åšä¸€äº› 3D æœºå™¨äººæ¨¡å‹å¹¶ä½¿ç”¨ç¨³å®šçš„åŸºçº¿æ¥é©±åŠ¨å®ƒä»¬ï¼Œä¸ºæ­¤æˆ‘éœ€è¦ä¸€ä¸ªå…·æœ‰ç¢°æ’å’Œç‰©ç†ä»¥åŠæ¨¡å‹/çš„ 3D å¼•æ“çº¹ç†å¯¼å…¥ã€ä¸€äº›ç€è‰²ï¼Œå½“ç„¶è¿˜æœ‰æ¸²æŸ“ã€‚æœ€å¥½æ˜¯ä¹Ÿå¯ä»¥æ¸²æŸ“åˆ° webgl ç¯å¢ƒçš„ä¸œè¥¿ã€‚ æˆ‘å‡è®¾ç¨³å®šåŸºçº¿å¯ä»¥ä¸ä»»ä½• 3D å¼€æºå¼•æ“ä¸€èµ·ä½¿ç”¨ã€‚æ˜¯å¦æœ‰ä¸€äº›éå¸¸åŸºæœ¬çš„ä¸œè¥¿å¯ä»¥ä¸ OpenAI Gym ä¸€èµ·ä½¿ç”¨æ¥å¯¼å…¥æ¨¡å‹ã€æ·»åŠ åˆšä½“å’Œç¢°æ’å‚æ•°ç­‰ã€‚æˆ–è€… OpenAI Gym æ˜¯å¦å·²ç»å…·å¤‡æ‰€æœ‰è¿™äº›åŠŸèƒ½ï¼Ÿ â€‹ â€‹   ç”±   æäº¤ /u/Sharp-Cat2319   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188iazm/any_physics_engine_gyms_outside_of_unity_that/</guid>
      <pubDate>Fri, 01 Dec 2023 18:05:56 GMT</pubDate>
    </item>
    <item>
      <title>ğŸš€ DIAMBRA x OROBIXï¼šå‘å¸ƒ SheepRL å¼ºåŒ–å­¦ä¹ åº“é›†æˆï¼ ğŸ¤–ğŸ®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/188eslz/diambra_x_orobix_releasing_sheeprl_reinforcement/</link>
      <description><![CDATA[      æˆ‘ä»¬å¾ˆé«˜å…´å®£å¸ƒä¸é«˜çº§ RL åº“ SheepRL çš„åˆ›å»ºè€… OROBIX è¿›è¡ŒåŠ¨æ€åˆä½œï¼ ğŸ¤ğŸ’¡ ğŸŒŸ ä¸ºä»€ä¹ˆé€‰æ‹© SheepRLï¼Ÿ SheepRL æ— ç¼é›†æˆåˆ° DIAMBRA ä¸­ï¼Œä¸ºç°ä»£ RL ç®—æ³•æä¾›äº†ä¸€æ¡æ¸…æ™°çš„è·¯å¾„ï¼Œé‡ç‚¹å…³æ³¨å¯æ‰©å±•åº”ç”¨ç¨‹åºçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚ ğŸ“š å…¥é—¨ï¼šåœ¨æˆ‘ä»¬çš„å®˜æ–¹ DIAMBRA æ–‡æ¡£ä¸­æ¢ç´¢ SheepRL çš„å¼ºå¤§åŠŸèƒ½ã€‚ DIAMBRA Agents å­˜å‚¨åº“ä¸­åŒ…å«æºä»£ç ç¤ºä¾‹ã€‚ ğŸš€ RL æ¢ç´¢çš„ Swift Launchpadï¼š åªéœ€å‡ è¡Œ Python ä»£ç ï¼Œå³å¯åœ¨æˆ‘ä»¬æ‰€æœ‰çš„æ¸¸æˆä¸Šå¯åŠ¨ RL è®­ç»ƒï¼Œè®© AI æ¢ç´¢å˜å¾—è½»è€Œæ˜“ä¸¾ï¼ /&gt; ğŸ‘‰ é€šè¿‡ä¸‹é¢è¯„è®ºä¸­çš„é“¾æ¥å‘ç°æ›´å¤šä¿¡æ¯ï¼ åŠ å…¥æˆ‘ä»¬ï¼Œæ‹¥æŠ±å¼ºåŒ–å­¦ä¹ ç ”ç©¶çš„æœªæ¥ã€‚ ğŸš€ğŸ¤–âœ¨ DIAMBRA x SheepRL&lt; /a&gt;   ç”±   æäº¤/u/DIAMBRA_AIArena   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/188eslz/diambra_x_orobix_releasing_sheeprl_reinforcement/</guid>
      <pubDate>Fri, 01 Dec 2023 15:36:10 GMT</pubDate>
    </item>
    <item>
      <title>å­¦ä¹ å¼ºåŒ–å­¦ä¹ ç ”ç©¶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/18880wg/learning_rl_research/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘ç°åœ¨æ­£åœ¨ç ”ç©¶å¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘æ­£åœ¨å¯»æ‰¾åŠ å¿«å­¦ä¹ é€Ÿåº¦çš„æ–¹æ³•ã€‚æˆ‘çš„è®¡åˆ’æ˜¯èƒ½å¤Ÿåœ¨è¯¥é¢†åŸŸåšå¥½ç ”ç©¶ã€‚ç°åœ¨æˆ‘æ­£åœ¨ç ”ç©¶ç¦»çº¿å¼ºåŒ–å­¦ä¹ ã€‚  ç°åœ¨æœ‰å¸®åŠ©çš„æ˜¯æˆ‘ä»¬æ¯å‘¨ä¸æˆ‘çš„åšå£«åŒå­¦è¿›è¡Œä¸€æ¬¡ä¼šè®®ã€‚æˆ‘ä»¬å±•ç¤ºæˆ‘ä»¬è¯»è¿‡çš„æ–°ç ”ç©¶è®ºæ–‡ã€‚è½®åˆ°æˆ‘çš„æ—¶å€™æˆ‘ä¼šåˆ†äº«æœ‰å…³ RL è®ºæ–‡çš„å†…å®¹ã€‚  ä½†æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯æˆ‘ä»¬çš„ä¸»é¢˜éå¸¸å¤šæ ·åŒ–ã€‚ä¸€é¡¹ç ”ç©¶è®¡ç®—æœºè§†è§‰ï¼Œä¸€é¡¹ç ”ç©¶å›¾ç¥ç»ç½‘ç»œï¼Œä¸€é¡¹ç ”ç©¶æ—¶é—´åºåˆ—é¢„æµ‹ã€‚æˆ‘æ˜¯å”¯ä¸€ä¸€ä¸ªä»äº‹å¼ºåŒ–å­¦ä¹ çš„äººã€‚ å¦‚æœæˆ‘èƒ½ä¸æ›´å¤šå…·æœ‰ç›¸åŒå…´è¶£çš„äººäº¤è°ˆï¼Œé‚£å°±å¤ªå¥½äº†ã€‚ ä¸ºäº†è¡¥å……èƒŒæ™¯ä¿¡æ¯ï¼Œæˆ‘æ¥è‡ªè²å¾‹å®¾åœ¨è¿™é‡Œå¾ˆéš¾è·å¾—æ”¯æŒæˆ–å…·æœ‰ä¸“ä¸šçŸ¥è¯†çš„å›¢ä½“æ¥æŒ‡å¯¼æˆ‘ã€‚å½“æˆ‘æ„Ÿè§‰è‡ªå·±åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å‡ ä¹æ˜¯å­¤èº«ä¸€äººæ—¶ï¼Œå°±å¾ˆéš¾ä¿æŒåŠ¨åŠ›ã€‚è™½ç„¶æˆ‘åœ¨è·å…°æœ‰ä¸€ä½æ•™æˆç»™äº†æˆ‘å¾ˆå¤šå¸®åŠ©ã€‚ æ‚¨å¯¹åœ¨çº¿å°ç»„ç­‰æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿè¿™å¯ä»¥å¸®åŠ©æˆ‘æ›´å¿«åœ°å­¦ä¹ ï¼ŒåŒ…æ‹¬æ½œåœ¨çš„æŒ‡å¯¼ã€èµ„æºå…±äº«ç­‰ï¼Ÿ è°¢è°¢ï¼   ç”±   æäº¤/u/111user222  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/18880wg/learning_rl_research/</guid>
      <pubDate>Fri, 01 Dec 2023 09:44:48 GMT</pubDate>
    </item>
    <item>
      <title>â€œä½¿ç”¨ç›´æ¥åå¥½ä¼˜åŒ– (DPO) çš„æ‰©æ•£æ¨¡å‹å¯¹é½â€ï¼ŒWallace ç­‰äºº 2023 {Salesforce}</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187wknu/diffusion_model_alignment_using_direct_preference/</link>
      <description><![CDATA[       ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187wknu/diffusion_model_alignment_using_direct_preference/</guid>
      <pubDate>Thu, 30 Nov 2023 23:27:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] ä¸€å‘¨åæˆ‘å°†é‡‡è®¿ Rich Suttonï¼Œæˆ‘åº”è¯¥é—®ä»–ä»€ä¹ˆé—®é¢˜ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187t5ir/d_im_interviewing_rich_sutton_in_a_week_what/</link>
      <description><![CDATA[ ç”±   æäº¤ /u/gwern   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187t5ir/d_im_interviewing_rich_sutton_in_a_week_what/</guid>
      <pubDate>Thu, 30 Nov 2023 21:06:43 GMT</pubDate>
    </item>
    <item>
      <title>åˆ›å»ºè·¨å¤šä¸ªç¯å¢ƒè¿è¡Œçš„å•ä¸ªä»£ç†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187mzev/creating_a_single_agent_that_acts_across_multiple/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œå…ˆæ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼æˆ‘æ­£åœ¨å¼€å±•ä¸€ä¸ª q-learning é¡¹ç›®ï¼Œå…¶ä¸­å•ä¸ªä»£ç†æ­£åœ¨åŠªåŠ›ä¼˜åŒ–è®¸å¤šï¼ˆæ•°åƒå°ï¼‰ç‹¬ç«‹æœºå™¨çš„æ€§èƒ½ã€‚æ‰€æœ‰æœºå™¨éƒ½æ˜¯ç›¸åŒçš„ï¼Œå¹¶åœ¨å®šæœŸæ›´æ–°çš„æ•°æ®åº“ä¸Šç”Ÿæˆç›¸åŒçš„æŒ‡æ ‡ã€‚å‡ å¹´å‰ï¼Œæˆ‘è¯»è¿‡è¿™ä¸ªç¤¾åŒºçš„ä¸€ä¸ªå¸–å­ï¼Œå¬èµ·æ¥å¥½åƒå¯ä»¥åœ¨å¤šä¸ªç¯å¢ƒä¸­åº”ç”¨å•ä¸ªä»£ç†ã€‚é‰´äºè¿™äº›éƒ½æ˜¯ç›¸åŒçš„ç¯å¢ƒå¹¶ç”±å”¯ä¸€çš„ ID è¡¨ç¤ºï¼Œæˆ‘æƒ³çŸ¥é“åœ¨æ„å»ºæ¨¡å‹æ—¶æ˜¯å¦å¯ä»¥åº”ç”¨ä¸€ä¸ªç®€å•çš„å‡½æ•°åˆ†ç»„æ¥åœ¨æ›´å¹¿æ³›çš„æ•°æ®æ•°ç»„ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯ä¹‹å‰åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå°è¯•å°†å…¶éƒ¨ç½²åˆ°æ‰€æœ‰ä¸åŒçš„ç¯å¢ƒä¸­ã€‚å†æ¬¡æ„Ÿè°¢å¤§å®¶çš„å¸®åŠ©ï¼   ç”±   æäº¤/u/Shikaze33_3   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187mzev/creating_a_single_agent_that_acts_across_multiple/</guid>
      <pubDate>Thu, 30 Nov 2023 16:45:03 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆæˆ‘åº”è¯¥ä½¿ç”¨ RLLib è€Œä¸æ˜¯ stable-baselines3ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/187fahg/why_should_i_use_rllib_over_stablebaselines3/</link>
      <description><![CDATA[æ‰€ä»¥æˆ‘å·²ç»ä½¿ç”¨ sb3 å¤§çº¦ 3 å¹´äº†ï¼Œæˆ‘å‘ç°è®¾ç½®å®éªŒã€å‘ RL æ·»åŠ åŠŸèƒ½ä¿®æ”¹/è‡ªå®šä¹‰ç½‘ç»œæ¶æ„éå¸¸ç®€å•ç®—æ³•ï¼Œä½¿ç”¨Optunaä¼˜åŒ–å‚æ•°ï¼Œå¹¶åœ¨è®­ç»ƒåè¿›è¡Œæ¨ç†ã€‚é™¤äº†äº†è§£å…¶å·¥ä½œåŸç†çš„åŸºæœ¬åŠ¨æ€ä¹‹å¤–ï¼Œæ‰€æœ‰è¿™äº›éƒ½ä¸éœ€è¦ä»˜å‡ºä»€ä¹ˆåŠªåŠ›ã€‚  æ‰€ä»¥åœ¨æˆ‘çš„æ–°å…¬å¸ä¸­ï¼Œä»–ä»¬ä½¿ç”¨ RLLibï¼Œè‡³å°‘å¯ä»¥è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ€ªç‰©ï¼Œå¯ä»¥å®Œæˆæˆ‘åœ¨ sb3 ä¸­è½»æ¾å®Œæˆçš„ä¸Šè¿°ä»»ä½•äº‹æƒ…ã€‚ æ‰€ä»¥äº‰è®ºæ˜¯é€šå¸¸è®¤ä¸ºä½¿ç”¨ RLLib éƒ¨ç½²æ¨¡å‹å¾ˆå®¹æ˜“ã€‚ä½†è¿™çœŸçš„é‚£ä¹ˆå®¹æ˜“å—ï¼Ÿè€ƒè™‘åˆ°æˆ‘ä»¬å¯ä»¥é€šè¿‡ FAST api å’Œ docker ç»„åˆè½»æ¾ç”šè‡³æ›´å¿«åœ°éƒ¨ç½²ä½¿ç”¨ sb3 è®­ç»ƒçš„æ¨¡å‹ï¼Œä»…ä»…ä¸ºäº†å®ƒæä¾›çš„é¢å¤–ç®—æ³•å°±å€¼å¾—ç»å† RLLib çš„å›°éš¾å—ï¼Ÿå¯¹äºä¸šå†…ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„äººæ¥è¯´ï¼Œæ‚¨çš„ä½“éªŒå¦‚ä½•ï¼Ÿ   ç”±   æäº¤/u/sharafath28  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/187fahg/why_should_i_use_rllib_over_stablebaselines3/</guid>
      <pubDate>Thu, 30 Nov 2023 10:14:33 GMT</pubDate>
    </item>
    </channel>
</rss>