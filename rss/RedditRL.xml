<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Fri, 04 Oct 2024 01:15:29 GMT</lastBuildDate>
    <item>
      <title>ï¼ˆé‡å¤ï¼‰æ²¡æœ‰è‡ªæˆ‘æ³¨æ„åŠ›çš„å‰é¦ˆå¯ä»¥é¢„æµ‹æœªæ¥çš„æ ‡è®°å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fvj4gs/repeat_feed_forward_without_selfattention_can/</link>
      <description><![CDATA[       ç”±    /u/Timur_1988  æäº¤  [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fvj4gs/repeat_feed_forward_without_selfattention_can/</guid>
      <pubDate>Thu, 03 Oct 2024 21:43:04 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ TD-MPC2 ä¸­æ²¡æœ‰å¾ªç¯æ¨¡å‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fvckc1/why_no_recurrent_model_in_tdmpc2/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨é˜…è¯» TD-MPC2 è®ºæ–‡ï¼Œæˆ‘å¯¹æ•´ä¸ªæƒ³æ³•éå¸¸äº†è§£ã€‚æˆ‘å”¯ä¸€ä¸å¤ªç†è§£çš„æ˜¯ä¸ºä»€ä¹ˆæ½œåœ¨åŠ¨åŠ›å­¦æ¨¡å‹æ˜¯ä¸€ä¸ªç®€å•çš„ MLPï¼Œè€Œä¸æ˜¯åƒè®¸å¤šå…¶ä»–åŸºäºæ¨¡å‹çš„è®ºæ–‡ä¸­é‚£æ ·çš„å¾ªç¯æ¨¡å‹ã€‚ ä¸»è¦é—®é¢˜æ˜¯ï¼šæ½œåœ¨åŠ¨åŠ›å­¦æ¨¡å‹å¦‚ä½•ä¸€æ­¥ä¸€æ­¥åœ°ç»´æŒä¸€ä¸ªæ½œåœ¨è¡¨ç¤º zï¼Œè¯¥è¡¨ç¤ºç»“åˆäº†æ¥è‡ªå‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤çš„ä¿¡æ¯ï¼Œè€Œæ²¡æœ‰ä»»ä½•éšè—çŠ¶æ€ã€‚æˆ‘çŒœä»–ä»¬æµ‹è¯•çš„è®¸å¤šç¯å¢ƒéƒ½éœ€è¦è¿™ç§èƒ½åŠ›ï¼Œè€Œä¸”è¯¥ç®—æ³•ä¼¼ä¹è¡¨ç°å¾—éå¸¸å¥½ã€‚ æˆ‘çš„ç†è§£æ˜¯ï¼Œé€šè¿‡åå‘ä¼ æ’­æ•´ä¸ªåºåˆ—ï¼Œæ½œåœ¨çŠ¶æ€ z ä»ç„¶ä¼šä»ä»¥ä¸‹æ­¥éª¤æ¥æ”¶æ¢¯åº¦ï¼Œå› æ­¤æ½œåœ¨åŠ¨åŠ›å­¦æ¨¡å‹å¯ä»¥éšå¼å­¦ä¹ å¦‚ä½•äº§ç”Ÿä¸‹ä¸€ä¸ªæ½œåœ¨çŠ¶æ€ï¼Œè¯¥çŠ¶æ€ä¿ç•™æ‰€æœ‰å…ˆå‰çŠ¶æ€çš„ä¿¡æ¯ã€‚ ä½†æ˜¯ï¼Œè¿™ä¸æ˜¯æ•ˆç‡ä½ä¸‹å—ï¼Ÿæˆ‘å¾ˆç¡®å®šä½œè€…æ²¡æœ‰ä½¿ç”¨ä»»ä½•ç±»å‹çš„åºåˆ—æ¨¡å‹ï¼ˆLSTM ç­‰ï¼‰æ˜¯æœ‰åŸå› çš„ï¼Œä½†æˆ‘ä¼¼ä¹æ‰¾ä¸åˆ°ä»¤äººæ»¡æ„çš„ç­”æ¡ˆã€‚ä½ æœ‰å—ï¼Ÿ  è®ºæ–‡é“¾æ¥     æäº¤äºº    /u/fedetask   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fvckc1/why_no_recurrent_model_in_tdmpc2/</guid>
      <pubDate>Thu, 03 Oct 2024 17:01:38 GMT</pubDate>
    </item>
    <item>
      <title>Esquilaxï¼šå¤§å‹å¤šæ™ºèƒ½ä½“ RL JAX åº“</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fva0qn/esquilax_a_largescale_multiagent_rl_jax_library/</link>
      <description><![CDATA[æˆ‘å·²ç»å‘å¸ƒäº†Esquilaxï¼Œä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿå’Œ ML/RL åº“ã€‚  å®ƒä¸“ä¸ºå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆæƒ³æƒ³ç¾¤ä½“ã€ç¾Šç¾¤ç¤¾äº¤ç½‘ç»œï¼‰çš„å»ºæ¨¡åŠå…¶ç”¨ä½œ RL å’Œå…¶ä»– ML æ–¹æ³•çš„è®­ç»ƒç¯å¢ƒè€Œè®¾è®¡ã€‚  å®ƒå®ç°äº†å¸¸è§çš„æ¨¡æ‹Ÿå’Œå¤šæ™ºèƒ½ä½“è®­ç»ƒåŠŸèƒ½ï¼Œå‡å°‘äº†å®ç°å¤æ‚æ¨¡å‹å’Œå®éªŒæ‰€éœ€çš„æ—¶é—´å’Œä»£ç é‡ã€‚å®ƒè¿˜æ—¨åœ¨ä¸ç°æœ‰çš„ JAX ML å·¥å…·ä¸€èµ·ä½¿ç”¨ï¼Œä¾‹å¦‚ Flax å’Œ Evosaxã€‚ ä»£ç å’Œå®Œæ•´æ–‡æ¡£å¯åœ¨ä»¥ä¸‹ä½ç½®æ‰¾åˆ°ï¼š https://github.com/zombie-einstein/esquilax https://zombie-einstein.github.io/esquilax/ æ‚¨è¿˜å¯ä»¥åœ¨æ­¤å¤„çœ‹åˆ°ä¸€ä¸ªä½¿ç”¨ Esquilax å°† boids å®ç°ä¸º RL ç¯å¢ƒçš„æ›´å¤§çš„é¡¹ç›®    ç”±   æäº¤  /u/Familiar-Watercress2   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fva0qn/esquilax_a_largescale_multiagent_rl_jax_library/</guid>
      <pubDate>Thu, 03 Oct 2024 15:09:22 GMT</pubDate>
    </item>
    <item>
      <title>æ‚¨å¦‚ä½•çœ‹å¾… Ben Recht å¯¹å¼ºåŒ–å­¦ä¹ æç«¯ä¸»ä¹‰è€…çš„è¿™ç§æ‰¹è¯„ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fv5iy3/what_do_you_think_of_this_kind_of_critique_of/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fv5iy3/what_do_you_think_of_this_kind_of_critique_of/</guid>
      <pubDate>Thu, 03 Oct 2024 11:33:22 GMT</pubDate>
    </item>
    <item>
      <title>ä»·å€¼æ¨¡å‹ä¸æµç¨‹å¥–åŠ±æ¨¡å‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fut7r6/value_model_vs_process_reward_model/</link>
      <description><![CDATA[å—¨ï¼Œåœ¨ LLM å’Œ RLHF çš„èƒŒæ™¯ä¸‹ï¼Œè¿™ä¸¤è€…æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ æ®æˆ‘äº†è§£ï¼Œä»·å€¼æ¨¡å‹ä¼°è®¡çŠ¶æ€ï¼ˆæˆ–éƒ¨åˆ†ç”Ÿæˆï¼‰çš„ä¼˜åŠ£ï¼Œè€Œ PRM è¿‡ç¨‹ä¼°è®¡ç»™å®šçŠ¶æ€ä¸‹åŠ¨ä½œçš„ä¼˜åŠ£ï¼Ÿè¿™ä½¿å¾— PRM çœ‹èµ·æ¥æœ‰ç‚¹åƒ Q å‡½æ•°ã€‚ è¿˜æœ‰å…¶ä»–ç»†å¾®çš„å·®åˆ«å—ï¼Ÿ    æäº¤äºº    /u/RingKitchen8808   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fut7r6/value_model_vs_process_reward_model/</guid>
      <pubDate>Wed, 02 Oct 2024 22:45:41 GMT</pubDate>
    </item>
    <item>
      <title>Pybullet ä¸ Google Brex ä¸ Mujoco</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fuhw1a/pybullet_vs_google_brex_vs_mujoco/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ‰¾ Pybulletã€Google Brexã€Mujoco ç­‰ä¼˜ç§€çš„ç‰©ç†æ¨¡æ‹Ÿè½¯ä»¶ã€‚å®ƒå¯ç”¨äºå¼ºåŒ–å­¦ä¹ ä»»åŠ¡ã€‚ è¿™äº›æ˜¯è€ƒè™‘çš„è¦ç‚¹ï¼š  åŠŸèƒ½ä¸°å¯Œ å¿«é€Ÿ æ”¯æŒ Ubuntu æ”¯æŒ Jupiter Notebook - æ„å‘³ç€ RL æ¨¡å‹å¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­è®­ç»ƒå¹¶æ¸²æŸ“åŠ¨ä½œã€‚ GUI å¯ç”¨æ€§  æŸ¥çœ‹æŠ•ç¥¨    æäº¤äºº    /u/iNdramal   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fuhw1a/pybullet_vs_google_brex_vs_mujoco/</guid>
      <pubDate>Wed, 02 Oct 2024 14:44:29 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹è¡¨æ ¼ Q å­¦ä¹ å®ç°çš„ç–‘é—®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fufqdw/doubt_about_implementation_of_tabular_qlearning/</link>
      <description><![CDATA[      æˆ‘ä¸€ç›´åœ¨å¤ä¹  Q-learning çš„çŸ¥è¯†ã€‚æˆ‘æ­£åœ¨æ£€æŸ¥ä»¥ä¸‹å®ç°ï¼š https://github.com/dennybritz/reinforcement-learning/blob/master/TD/Q-Learning%20Solution.ipynb è¿™æ˜¯ Sutton ä¹¦ä¸­çš„ä¼ªä»£ç ï¼š https://preview.redd.it/3v3o2e8cccsd1.png?width=1271&amp;format=png&amp;auto=webp&amp;s=86ec7a83efe6fbf563ea5835e7794035f49596d2 æˆ‘ä¸ç¡®å®šè¯¥å®ç°ä¸­çš„ç­–ç•¥ã€‚ä¼¼ä¹å³ä½¿ Q å‡½æ•°åœ¨æ¯ä¸ªæ­¥éª¤åéƒ½ä¼šæ›´æ–°ï¼Œç­–ç•¥ä¹Ÿå§‹ç»ˆæ˜¯å›ºå®šçš„ï¼ˆå› ä¸ºå®ƒä¸åœ¨å¾ªç¯ä¸­ï¼‰ã€‚å®ƒä¸åº”è¯¥åœ¨æ¯æ¬¡æ›´æ–°åï¼ˆæˆ–è‡³å°‘åœ¨æ¯é›†ä¹‹åï¼‰æ›´æ–°å—ï¼Ÿ     ç”±    /u/NavirAur æäº¤   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fufqdw/doubt_about_implementation_of_tabular_qlearning/</guid>
      <pubDate>Wed, 02 Oct 2024 13:06:08 GMT</pubDate>
    </item>
    <item>
      <title>è‡´åŠ›äºå¯æ‰©å±•å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ â€”â€”éœ€è¦å¸®åŠ©ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fuezif/working_on_scalable_multiagent_reinforcement/</link>
      <description><![CDATA[      æ‚¨å¥½ï¼Œ æˆ‘å†™è¿™å°ä¿¡æ˜¯ä¸ºäº†å¯»æ±‚æ‚¨çš„å¸®åŠ©ã€‚ æˆ‘ç›®å‰æ­£åœ¨å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºåä¸º CARLA çš„è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿã€‚ é—®é¢˜å¦‚ä¸‹ï¼š https://preview.redd.it/v9k6ix2q7csd1.png?width=1923&amp;format=png&amp;auto=webp&amp;s=057074710bf54ce02c123734ff28a02a56ec8200  è½¦è¾†åœ¨çº¢è‰²ï¼ˆä¸»å¹²é“ï¼‰å’Œè“è‰²ï¼ˆåˆå¹¶é“è·¯ï¼‰æ ‡è®°çš„åŒºåŸŸä¸­éšæœºç”Ÿæˆã€‚ ï¼ˆä»…ä½¿ç”¨ä¸»å¹²é“ä¸Šçš„æœ€åä¸€æ¡è½¦é“è¿›è¡Œè½¦è¾†ç”Ÿæˆã€‚ï¼‰ æ­¤æ—¶ï¼Œæœ‰äººé©¾é©¶çš„è½¦è¾†ï¼ˆ2 åˆ° 4 è¾†è½¦ï¼‰å’Œå¼ºåŒ–å­¦ä¹ ä»£ç†æ§åˆ¶çš„è½¦è¾†ï¼ˆ3 åˆ° 5 è¾†è½¦ï¼‰æ··åˆå­˜åœ¨ã€‚ æ¯é›†ç”Ÿæˆçš„è½¦è¾†æ•°é‡æ˜¯éšæœºçš„ï¼Œå¹¶ä¸”åœ¨ä¸Šé¢æ‹¬å·ä¸­æŒ‡å®šçš„èŒƒå›´å†…ã€‚ ç”Ÿæˆä½ç½®ä¹Ÿæ˜¯éšæœºçš„ï¼›å®ƒå¯èƒ½åœ¨ä¸»å¹²é“æˆ–åˆå¹¶é“è·¯ä¸Šã€‚ ä»£ç†çš„æ“ä½œå¦‚ä¸‹ï¼š æ²¹é—¨ï¼š0 åˆ° 1 ä¹‹é—´çš„å€¼ã€‚ è§‚å¯ŸåŒ…æ‹¬å›´ç»•ä»£ç†çš„è½¦è¾†ï¼ˆæœ€å¤š 4 è¾†è½¦ï¼‰çš„ xã€yã€vx å’Œ vyï¼ŒæŒ‰è·ç¦»æ’åºã€‚ å¥–åŠ±ç»“æ„ç®€å•ï¼šç¢°æ’ä¼šå¯¼è‡´ -200ï¼Œ0 åˆ° 80 å…¬é‡Œ/å°æ—¶ä¹‹é—´çš„é€Ÿåº¦å€¼ä¼šäº§ç”Ÿ 0 åˆ° 1 ä¹‹é—´çš„å¥–åŠ±ï¼ˆ80 å…¬é‡Œ/å°æ—¶ä¸º 1ï¼Œ0 å…¬é‡Œ/å°æ—¶ä¸º 0ï¼‰ã€‚ å¦‚æœä»»ä½•ä»£ç†å‘ç”Ÿç¢°æ’æˆ–æ‰€æœ‰ä»£ç†éƒ½åˆ°è¾¾ç›®æ ‡ï¼ˆåˆå¹¶ç‚¹å 100 ç±³çš„ç‚¹ï¼‰ï¼Œåˆ™æƒ…èŠ‚ç»“æŸã€‚  æ€»ä¹‹ï¼Œä»»åŠ¡æ˜¯è®©ä»£ç†å®‰å…¨åœ°é€šè¿‡åˆå¹¶åŒºåŸŸè€Œä¸å‘ç”Ÿç¢°æ’ï¼Œå³ä½¿ä»£ç†çš„æ•°é‡éšæœºå˜åŒ–ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ æœ‰ä»€ä¹ˆèµ„æºå¯ä»¥å‚è€ƒå—ï¼Ÿ è¯·æä¾›æˆ‘æœ‰ä¸€äº›å»ºè®®ã€‚è¯·å¸®å¸®æˆ‘ğŸ˜¢ æˆ‘ä¼šå¾ˆæ„Ÿæ¿€ä½ çš„å»ºè®®ã€‚ è°¢è°¢ã€‚    æäº¤äºº    /u/audi_etron   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fuezif/working_on_scalable_multiagent_reinforcement/</guid>
      <pubDate>Wed, 02 Oct 2024 12:28:52 GMT</pubDate>
    </item>
    <item>
      <title>TD3 åœ¨æ™ºèƒ½åˆ—è½¦ä¼˜åŒ–ä¸­çš„åº”ç”¨</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ftwjrn/td3_in_smart_train_optimization/</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªæ¨¡æ‹Ÿç¯å¢ƒï¼Œç«è½¦å¯ä»¥åœ¨å…¶ä¸­å¯åŠ¨ã€åŠ é€Ÿå’Œåœ¨è½¦ç«™åœé ã€‚ä½†æ˜¯ï¼Œå½“ä½¿ç”¨ TD3 ä»£ç†è¿›è¡Œ 1,000 é›†æ—¶ï¼Œå®ƒå¾ˆéš¾æŒæ¡åœºæ™¯ã€‚æˆ‘å°è¯•è°ƒæ•´è¶…å‚æ•°ã€å¥–åŠ±å’Œç¥ç»ç½‘ç»œå±‚ï¼Œä½†ä»£ç†åœ¨æµ‹è¯•æœŸé—´ä»é‡‡å–ç±»ä¼¼çš„æ“ä½œå€¼ã€‚ åœ¨æˆ‘çš„è®¾ç½®ä¸­ï¼Œæ“ä½œæ§åˆ¶ç«è½¦çš„åŠ é€Ÿåº¦ï¼Œå…·æœ‰è·ç¦»ã€é€Ÿåº¦ã€åˆ°è¾¾è½¦ç«™çš„æ—¶é—´å’Œæ¨¡æ‹ŸåŠ¨ä½œç­‰ç‰¹å¾ã€‚å¥–åŠ±å‡½æ•°é‡‡ç”¨å„ç§æŒ‡æ ‡è®¾è®¡ï¼Œåœ¨å¼€å§‹æ—¶åº”ç”¨è¾ƒå¤§çš„æƒ©ç½šï¼Œå¹¶åœ¨ç«è½¦æ¥è¿‘ç›®æ ‡æ—¶å‡å°‘æƒ©ç½šä»¥æ¿€åŠ±å‰è¿›ã€‚ æˆ‘å°†åŸå§‹æ•°æ®ä¼ é€’ç»™ç­–ç•¥è€Œæ²¡æœ‰è¿›è¡Œè§„èŒƒåŒ–ã€‚è¿™ä¸ªé—®é¢˜å¯èƒ½ä¸å¥–åŠ±ç»“æ„ã€æ¨¡å‹æœ¬èº«æœ‰å…³ï¼Œè¿˜æ˜¯æˆ‘åº”è¯¥è€ƒè™‘æ·»åŠ å…¶ä»–åŠŸèƒ½ï¼Ÿ    æäº¤äºº    /u/laxuu   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ftwjrn/td3_in_smart_train_optimization/</guid>
      <pubDate>Tue, 01 Oct 2024 19:20:10 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨ .pt æ–‡ä»¶</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ftiwj7/how_do_i_use_a_pt_file/</link>
      <description><![CDATA[å¤§å®¶å¥½...æˆ‘å¯¹å¼ºåŒ–å­¦ä¹ ã€æœºå™¨å­¦ä¹ ã€ç¥ç»ç½‘ç»œç­‰æ¦‚å¿µè¿˜ä¸ç†Ÿæ‚‰ã€‚æˆ‘æœ‰ä¸€ä¸ª .pt æ–‡ä»¶ï¼Œè¿™æ˜¯æˆ‘åœ¨ isaac sim/lab ç¯å¢ƒä¸­è®­ç»ƒæœºå™¨äººåè·å¾—çš„ç­–ç•¥...æˆ‘æƒ³ä½¿ç”¨ .pt æ–‡ä»¶å¹¶å‘å…¶æä¾›æ¥è‡ªæ¨¡æ‹Ÿä¼ æ„Ÿå™¨çš„è¾“å…¥ï¼Œå¹¶åœ¨ç°å®ä¸–ç•Œä¸­è¿è¡Œç”µæœº...æœ‰äººå¯ä»¥ç»™æˆ‘æŒ‡å‡ºä¸€äº›å¯ä»¥è®©æˆ‘åšåˆ°è¿™ä¸€ç‚¹çš„èµ„æºå—...è¿™é¡¹ç»ƒä¹ èƒŒåçš„ä¸»è¦åŠ¨æœºæ˜¯ä½¿ç”¨ç­–ç•¥å¹¶åœ¨ç°å®ä¸–ç•Œä¸­ç§»åŠ¨æ‰§è¡Œå™¨ã€‚    æäº¤äºº    /u/Grand-Date4504   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ftiwj7/how_do_i_use_a_pt_file/</guid>
      <pubDate>Tue, 01 Oct 2024 08:07:10 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ RL æ„å»ºç®—æ³•äº¤æ˜“ä»£ç†çš„æ•™ç¨‹</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fthite/tutorial_on_using_rl_to_build_algo_trading_agent/</link>
      <description><![CDATA[https://www.aion-research.com/post/building-a-reinforcement-learning-agent-for-algorithmic-trading è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹ï¼Œå› æ­¤è¯·å‹¿å°†å…¶ç”¨äºæ‚¨çš„å®é™…äº¤æ˜“ã€‚æˆ‘è¿˜æ²¡æœ‰èƒ½å¤Ÿå°† RL åº”ç”¨äºæˆ‘çš„çœŸå®é‡åŒ–é‡‘èå·¥ä½œï¼Œæ‰€ä»¥å¦‚æœæœ‰äººä¹‹å‰æˆåŠŸè¿‡ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼    æäº¤äºº    /u/MarketMood   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fthite/tutorial_on_using_rl_to_build_algo_trading_agent/</guid>
      <pubDate>Tue, 01 Oct 2024 06:24:26 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ åœ¨çº¿è®²åº§</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ft5e8u/online_lectures_on_reinforcement_learning/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘æƒ³ä¸å¤§å®¶åˆ†äº«æˆ‘åœ¨ YouTube ä¸Šå…³äºå¼ºåŒ–å­¦ä¹ çš„è®²åº§ï¼š   https://www.youtube.com/playlist?list=PLW4eqbV8qk8YUmaN0vIyGxUNOVqFzC2pd   æ¯å‘¨ä¸‰å’Œå‘¨æ—¥æ—©ä¸Šéƒ½ä¼šå‘å¸ƒæ–°çš„è§†é¢‘ã€‚æ‚¨å¯ä»¥è®¢é˜…æˆ‘çš„YouTubeé¢‘é“ï¼ˆhttps://www.youtube.com/tyucelenï¼‰å¹¶å¼€å¯é€šçŸ¥ä»¥éšæ—¶å…³æ³¨ï¼å¦‚æœæ‚¨èƒ½å°†è¿™äº›è®²åº§è½¬å‘ç»™æ‚¨çš„åŒäº‹/å­¦ç”Ÿï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚   ä»¥ä¸‹æ˜¯è¦æ¶µç›–çš„ä¸»é¢˜ï¼š    å¼ºåŒ–å­¦ä¹ ç®€ä»‹ï¼ˆå·²å‘å¸ƒï¼‰ é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆå·²å‘å¸ƒï¼‰ åŠ¨æ€è§„åˆ’ï¼ˆå·²å‘å¸ƒï¼‰ Q å‡½æ•°è¿­ä»£ Q å­¦ä¹  å¸¦æœ‰ Matlab ä»£ç çš„ Q å­¦ä¹ ç¤ºä¾‹ SARSA å¸¦æœ‰ Matlab ä»£ç çš„ SARSA ç¤ºä¾‹ ç¥ç»ç½‘ç»œ è¿ç»­ç©ºé—´ä¸­çš„å¼ºåŒ–å­¦ä¹  ç¥ç» Q å­¦ä¹  å¸¦æœ‰ Matlab ä»£ç çš„ç¥ç» Q å­¦ä¹ ç¤ºä¾‹ ç¥ç» SARSA å¸¦æœ‰ Matlab ä»£ç çš„ç¥ç» SARSA ç¤ºä¾‹ ç»éªŒé‡æ’­ è¿è¡Œæ—¶ä¿è¯ å¸¦æœ‰ Matlab ä»£ç çš„ Gridworld ç¤ºä¾‹  ç¥ä¸€åˆ‡é¡ºåˆ©ï¼Œ Tansel Tansel Yucelenï¼Œåšå£« è‡ªä¸»ã€æ§åˆ¶ã€ä¿¡æ¯å’Œç³»ç»Ÿå®éªŒå®¤ä¸»ä»»ï¼ˆLACIS) æœºæ¢°å·¥ç¨‹ç³»å‰¯æ•™æˆ å—ä½›ç½—é‡Œè¾¾å¤§å­¦ï¼Œç¾å›½ä½›ç½—é‡Œè¾¾å·å¦å¸•å¸‚ 33620 Xï¼Œé¢†è‹±, YouTube, 770-331-8496 (æ‰‹æœº)    æäº¤äºº    /u/Original-Promise-312   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ft5e8u/online_lectures_on_reinforcement_learning/</guid>
      <pubDate>Mon, 30 Sep 2024 20:16:21 GMT</pubDate>
    </item>
    <item>
      <title>[æ¼”è®²] Rich Suttonï¼Œè¿ˆå‘æ›´å¥½çš„æ·±åº¦å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ft1e84/talk_rich_sutton_toward_a_better_deep_learning/</link>
      <description><![CDATA[       ç”±    /u/atgctg  æäº¤  [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ft1e84/talk_rich_sutton_toward_a_better_deep_learning/</guid>
      <pubDate>Mon, 30 Sep 2024 17:32:37 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ é€ŸæŸ¥è¡¨</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fsrtgf/reinforcement_learning_cheat_sheet/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ æˆ‘åˆšåˆšåœ¨ Medium ä¸Šå‘è¡¨äº†æˆ‘çš„ç¬¬ä¸€ç¯‡æ–‡ç« ï¼Œè¿˜åˆ›å»ºäº†ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ å¤‡å¿˜å•ã€‚ğŸ‰ æˆ‘å¾ˆä¹æ„å¬åˆ°æ‚¨çš„åé¦ˆã€å»ºè®®æˆ–ä»»ä½•å…³äºå¦‚ä½•æ”¹è¿›å®ƒä»¬çš„æƒ³æ³•ï¼ è¯·éšæ—¶æŸ¥çœ‹å®ƒä»¬ï¼Œå¹¶æå‰æ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼ğŸ˜Š https://medium.com/@ruipcf/reinforcement-learning-cheat-sheet-39bdecb8b5b4    æäº¤äºº    /u/Prudent_Nose921   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fsrtgf/reinforcement_learning_cheat_sheet/</guid>
      <pubDate>Mon, 30 Sep 2024 09:55:27 GMT</pubDate>
    </item>
    <item>
      <title>RL ç”¨äºè¿åŠ¨æç¤º</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1fslhhv/rl_for_motion_cueing/</link>
      <description><![CDATA[        æäº¤äºº    /u/FriendlyStandard5985   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1fslhhv/rl_for_motion_cueing/</guid>
      <pubDate>Mon, 30 Sep 2024 02:41:16 GMT</pubDate>
    </item>
    </channel>
</rss>