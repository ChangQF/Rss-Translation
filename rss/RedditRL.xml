<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Mon, 11 Mar 2024 12:24:28 GMT</lastBuildDate>
    <item>
      <title>å›¾ç¥ç»ç½‘ç»œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bc0xf8/graph_neural_network/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œ æˆ‘æ­£åœ¨ç ”ç©¶çµæ´»ä½œä¸šè½¦é—´çš„ç”Ÿäº§è°ƒåº¦ï¼ˆå³ï¼Œä»»åŠ¡æ˜¯å®‰æ’æ“ä½œï¼Œä»¥ä¾¿æ¯ä¸ªæ“ä½œå¯ä»¥åœ¨è®¸å¤šæœºå™¨ä¸Šå¤„ç†ï¼‰ã€‚æˆ‘é€šè¿‡å°†çŠ¶æ€å»ºæ¨¡ä¸ºåŸºäºåŠ¨æ€å›¾çš„ç»“æ„æ¥åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆèŠ‚ç‚¹æ•°é‡åœ¨æ¯ä¸ªå†³ç­–æ—¶é—´æ ¹æ®å¯ç”¨ä½œä¸šå’Œç©ºé—²æœºå™¨è€Œå˜åŒ–ï¼‰ã€‚ æˆ‘æœ‰ä¸‰ä¸ªä¸»è¦é—®é¢˜ï¼š A.æˆ‘åº”è¯¥é€‰æ‹©å“ªä¸ªé€‰é¡¹ï¼Ÿ 1- å°†çŠ¶æ€å»ºæ¨¡ä¸ºæå–å›¾ï¼ˆåœ¨è®¸å¤šå­¦æœ¯è®ºæ–‡ä¸­ä½¿ç”¨ï¼‰ 2- å°†çŠ¶æ€å»ºæ¨¡ä¸ºå›¾æ¨¡å‹ (nx.DiGraph() ï¼‰å¹¶å°†çŠ¶æ€ä½œä¸º Data(x=, edge_index=) é¦ˆé€åˆ° GNN B.å“ªä¸€ä¸ªæ›´å¥½ï¼Ÿ 1- è®­ç»ƒ GAT è¿›è¡Œç‰¹å¾åµŒå…¥æå–ï¼Œç„¶åè®­ç»ƒ DRL ä»£ç†è¿›è¡ŒåŠ¨ä½œé€‰æ‹© 2- å°† GAT é›†æˆåˆ° DRL ä»£ç†ä¸­ï¼Œç›´æ¥æ ¹æ®çŠ¶æ€é€‰æ‹©åŠ¨ä½œè¡¨ç¤ºä¸ºæ•°æ®ï¼Œç„¶åè®­ç»ƒæ•´ä¸ªç½‘ç»œ C.æˆ‘åœ¨å›¾ä¸­æœ‰ä¸‰ä¸ªèŠ‚ç‚¹ç±»åˆ«ï¼Œå¦‚æœè¾“å…¥è¡¨ç¤ºä¸ºæ•°æ®ï¼ŒGNNæ˜¯å¦åº”è¯¥åˆ†åˆ«å¤„ç†å›¾ä¸­çš„ä¸‰ä¸ªèŠ‚ç‚¹ç±»åˆ«ä¸­çš„æ¯ä¸€ä¸ªï¼ˆè¿™æ ·æˆ‘æ¯æ¬¡éƒ½æœ‰ä¸€ä¸ªæœºå™¨èŠ‚ç‚¹ï¼ˆå¤šä»£ç†è®¾ç½®ï¼‰ï¼Œå‡ ä¸ªä½œä¸šèŠ‚ç‚¹, ...)?   ç”±   æäº¤/u/GuavaAgreeable208  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bc0xf8/graph_neural_network/</guid>
      <pubDate>Mon, 11 Mar 2024 11:25:49 GMT</pubDate>
    </item>
    <item>
      <title>ç›‘æ§ RL ä»£ç†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bbzkai/monitoring_rl_agents/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œæˆ‘æœ‰ä¸¤ä¸ªä¸€èˆ¬æ€§é—®é¢˜ï¼š åœ¨è®­ç»ƒå’Œæ¢ç´¢æ—¶ç›‘æ§ RL ä»£ç†æ€§èƒ½çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘çŸ¥é“å¥–åŠ±å‡½æ•°è¡Œä¸ºåæ˜ äº† RL çš„æ€§èƒ½ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬æ˜¯å¦å¯ä»¥è·Ÿè¸ªä»»ä½•å…¶ä»–æ ‡å‡†æ¥äº†è§£ä»£ç†çš„å­¦ä¹ æƒ…å†µï¼Ÿ æœ€å…ˆè¿›çš„å®‰å…¨æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿé™¤äº†ç”¨ä¾‹ç‰¹å®šæ–¹æ³•ä¹‹å¤–çš„æ¢ç´¢æŠ€æœ¯ï¼Ÿ   ç”±   æäº¤/u/alysavalan  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bbzkai/monitoring_rl_agents/</guid>
      <pubDate>Mon, 11 Mar 2024 09:56:51 GMT</pubDate>
    </item>
    <item>
      <title>ç›‘æ§ RL ä»£ç†</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bbzgth/monitoring_the_rl_agent/</link>
      <description><![CDATA[æ‚¨å¥½ï¼Œæˆ‘æœ‰ä¸¤ä¸ªä¸€èˆ¬æ€§é—®é¢˜ï¼š åœ¨è®­ç»ƒå’Œæ¢ç´¢æ—¶ç›‘æ§ RL ä»£ç†æ€§èƒ½çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘çŸ¥é“å¥–åŠ±å‡½æ•°è¡Œä¸ºåæ˜ äº† RL çš„æ€§èƒ½ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬æ˜¯å¦å¯ä»¥è·Ÿè¸ªä»»ä½•å…¶ä»–æ ‡å‡†æ¥äº†è§£ä»£ç†çš„å­¦ä¹ æƒ…å†µï¼Ÿ æœ€å…ˆè¿›çš„å®‰å…¨æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿé™¤äº†ç”¨ä¾‹ç‰¹å®šæ–¹æ³•ä¹‹å¤–çš„æ¢ç´¢æŠ€æœ¯ï¼Ÿ   ç”±   æäº¤/u/raminhashemi   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bbzgth/monitoring_the_rl_agent/</guid>
      <pubDate>Mon, 11 Mar 2024 09:49:31 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨æ–°åœ°å›¾è¿›è¡Œè®­ç»ƒæ—¶ï¼ŒDQN æ¨¡å‹ä¼šå¤±å»ä¹‹å‰è§£å†³åœ°å›¾é—®é¢˜çš„èƒ½åŠ›</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bbh5sv/dqn_model_losing_previous_hability_to_solve_a_map/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è®­ç»ƒ DQN æ¨¡å‹æ¥è§£å†³æ¸¸æˆé—®é¢˜ã€‚è¾“å…¥æ˜¯åœ°å›¾ã€‚å¦‚æœæˆ‘è®¾æ³•ä½¿ç”¨ç‰¹å®šåœ°å›¾è·å¾—è‰¯å¥½çš„ç»“æœï¼Œä¿å­˜æ¨¡å‹ï¼Œç„¶åä½¿ç”¨å¦ä¸€å¼ åœ°å›¾å†æ¬¡è®­ç»ƒå®ƒï¼ˆä¿ç•™æƒé‡ï¼‰ï¼Œå®ƒä¼šå¤±å»è§£å†³å‰ä¸€å¼ åœ°å›¾çš„èƒ½åŠ›ï¼Œå› ä¸ºå®ƒéœ€è¦æ¢ç´¢å’Œå­¦ä¹ æ–°åœ°å›¾å—ï¼Ÿè¿˜æ˜¯é€šè¿‡åœ¨æ¯æ¬¡è¿­ä»£æ—¶æ¢ç´¢æ‰€æœ‰åœ°å›¾æ¥ä¸€æ¬¡è®­ç»ƒæ‰€æœ‰åœ°å›¾æ›´å¥½ï¼ˆè¿™åœ¨è®¡ç®—ä¸Šä¼šç›¸å½“æ˜‚è´µï¼‰ï¼Ÿ åœ¨æˆ‘çš„æ¸¸æˆç¯å¢ƒä¸­ï¼ŒDQN ç®—æ³•éœ€è¦å¤§é‡æ¢ç´¢ï¼Œæ‰€ä»¥ epsilon è¡°å‡éå¸¸æ…¢ï¼Œåˆå§‹ epsilon å€¼ä¸º 1ã€‚   ç”±   æäº¤/u/libichi  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bbh5sv/dqn_model_losing_previous_hability_to_solve_a_map/</guid>
      <pubDate>Sun, 10 Mar 2024 18:26:05 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹äºå†³ç­–è½¬æ¢å™¨å’Œå¼ºåŒ–å­¦ä¹ çš„æœªæ¥æŒä»€ä¹ˆç«‹åœºï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bbavui/what_is_the_stance_on_decision_transformers_and/</link>
      <description><![CDATA[å—¨ï¼Œ è¿™äº›å¤©æˆ‘æ­£åœ¨ç ”ç©¶å†³ç­–è½¬æ¢å™¨ã€‚  æœ‰äº‰è®®çš„æ˜¯ï¼Œåœ¨è¯•å›¾æ‰¾åˆ°æœ€é‡è¦çš„è®ºæ–‡æ—¶ï¼Œæˆ‘æ³¨æ„åˆ°å¼ºåŒ–å­¦ä¹ é¢†åŸŸä¼¼ä¹æ²¡æœ‰å‘ç”Ÿå¤ªå¤šäº‹æƒ…ã€‚æˆ‘æ³¨æ„åˆ°ç ”ç©¶çš„é‡ç‚¹æ˜¯ä¼˜åŒ– Transformer å’Œè®­ç»ƒå·¨å¤§çš„è¯­è¨€å’Œè§†è§‰æ¨¡å‹ï¼ˆè¢«è§†ä¸ºç›‘ç£æ¨¡å‹ï¼‰ã€‚è¿™æ˜¯ RL ä¸­çš„æ–°å¤§äº‹å—ï¼Ÿ  å¼ºåŒ–å­¦ä¹ çš„æœ€æ–°è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ  â€‹   ç”±   æäº¤/u/__Julia  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bbavui/what_is_the_stance_on_decision_transformers_and/</guid>
      <pubDate>Sun, 10 Mar 2024 13:54:56 GMT</pubDate>
    </item>
    <item>
      <title>â€œæ— éœ€æœç´¢çš„å¤§å¸ˆçº§å›½é™…è±¡æ£‹â€ï¼ŒRuoss ç­‰äºº 2024</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1baz8hl/grandmasterlevel_chess_without_search_ruoss_et_al/</link>
      <description><![CDATA[ ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1baz8hl/grandmasterlevel_chess_without_search_ruoss_et_al/</guid>
      <pubDate>Sun, 10 Mar 2024 02:25:15 GMT</pubDate>
    </item>
    <item>
      <title>QLearningæ¨èç³»ç»Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1basms8/qlearning_recommender_system/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯å¼ºåŒ–å­¦ä¹ æ–°æ‰‹ï¼Œæˆ‘æ­£åœ¨å°è¯•åœ¨ Movielens ML-100k æ•°æ®é›†ä¸Šä½¿ç”¨ QLearning åˆ¶ä½œå¼ºåŒ–å­¦ä¹ æ¨èç³»ç»Ÿï¼Œæˆ‘å°†çŠ¶æ€å®šä¹‰ä¸ºç”¨æˆ·ï¼Œå°†åŠ¨ä½œå®šä¹‰ä¸ºç”µå½±ï¼Œæˆ‘æ­£åœ¨å°è¯•é¢„æµ‹è¯„åˆ†ã€‚æˆ‘å°†è¯„åˆ†æ–‡ä»¶è½¬æ¢ä¸ºç”¨æˆ·é¡¹çŸ©é˜µï¼Œå¹¶ç”¨ 0 å¡«å…… NA å€¼ã€‚ å¯¹äºæˆ‘æ­£åœ¨æ£€æŸ¥çš„å¥–åŠ±å‡½æ•°å¦‚æœè¯„çº§å¯ç”¨å¹¶ä¸”æˆ‘è¿”å›å®é™…_è¯„çº§-é¢„æµ‹_è¯„çº§ï¼Œå¦åˆ™æˆ‘åªè¿”å›0ã€‚å¯¹äºæˆ‘ä½¿ç”¨epsilonè´ªå©ªçš„ç­–ç•¥ã€‚æˆ‘çš„é—®é¢˜æ˜¯æˆ‘æ²¡æœ‰å¾—åˆ°å¥½çš„ç»“æœï¼Œæˆ‘çŒœæˆ‘çš„å¥–åŠ±åŠŸèƒ½éœ€è¦å·¥ä½œã€‚å¦‚æœæœ‰äººæƒ³çœ‹ä¸€ä¸‹æˆ‘çš„ä»£ç ï¼Œé‚£å°±æ˜¯ pythonã€‚è°¢è°¢ ç¼–è¾‘ï¼šè¿™æ˜¯æˆ‘çš„ Kaggle ç¬”è®°æœ¬ https://www.kaggle.com/code/asribachir/reinforcement-learning-ml100k    ç”±   æäº¤ /u/Fredybec   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1basms8/qlearning_recommender_system/</guid>
      <pubDate>Sat, 09 Mar 2024 21:23:51 GMT</pubDate>
    </item>
    <item>
      <title>æ¨¡å‹æ€§èƒ½è¯„ä¼°</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ba8tq6/model_performance_evaluation/</link>
      <description><![CDATA[æˆ‘åœ¨åšä»€ä¹ˆï¼š æˆ‘æ­£åœ¨åˆ¶ä½œä¸€ä¸ªè‡ªå®šä¹‰Open AI Gym ä¸­çš„ Boid æ¤ç»’ç¯å¢ƒå…·æœ‰ç¨³å®šçš„åŸºçº¿ 3. å·¥ä½œåŸç†ï¼š  æˆ‘ä¼ é€’äº†ä¸€ä¸ª boids çš„ä½ç½®æ–‡ä»¶ã€‚ å¯¹å…¶è¿›è¡Œ 3000 ä¸ªæ—¶é—´æ­¥é•¿çš„æ¨¡å‹æµ‹è¯•ï¼Œå¹¶è¾“å‡ºæ¯ä¸ªæƒ…èŠ‚çš„å¥–åŠ±ï¼Œå³ä½ç½®æ–‡ä»¶  è®­ç»ƒåˆå§‹ä½ç½®ä¸æµ‹è¯•ä¸åŒ. æˆ‘å…³å¿ƒçš„æ˜¯æˆ‘çš„æ¨¡å‹çš„æ€§èƒ½ã€‚å½“ä»ä¸åŒçš„åˆå§‹ä½ç½®é™ˆè¿°æ—¶ï¼Œå®ƒä¼šè¾“å‡ºç±»ä¼¼çš„å¥–åŠ±ï¼Œå¹¶ä¸”æœºå™¨äººæŒ‰é¢„æœŸç§»åŠ¨ï¼Œæˆ‘è¿˜ç”Ÿæˆäº†ä¸€ä¸ªç§»åŠ¨è§†é¢‘æ–‡ä»¶ã€‚ çœ‹ä¼¼æ­£ç¡®å·¥ä½œçš„æ¨¡å‹çš„è¾“å‡º â€‹  å¥–åŠ±å‡½æ•° defcalculate_combined_reward(self,agent,neighbor_positions):total_reward=0out_of_flock=False if(len(neighbor_positions)&gt;0):forneighbor_positionsinneighbor_positions : è·ç¦» = np.linalg.norm(agent.position - neighbor_position) if (è·ç¦»  é—®é¢˜ï¼šä½†æ˜¯ï¼Œå½“æˆ‘åœ¨ä¸æ›´æ”¹ä»»ä½•å†…å®¹çš„æƒ…å†µä¸‹é‡æ–°è®­ç»ƒå‡ æ¬¡å¹¶è¿›è¡Œæµ‹è¯•æ—¶ï¼Œåªæ˜¯ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œå®ƒçš„è¡¨ç°ä¸ä½³ï¼Œæˆ‘çš„å‰§é›†å¥–åŠ±å¤§å¤šæ˜¯è´Ÿé¢çš„ã€‚è™½ç„¶æˆ‘ä»€ä¹ˆä¹Ÿæ²¡æ”¹å˜ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä¿å­˜äº†å…·æœ‰æœ€ä½³æ€§èƒ½çš„æ¨¡å‹ã€‚ å…³æ³¨ï¼šæ˜¯æˆ‘çš„æ¨¡å‹ï¼Œæˆ‘è®­ç»ƒå¹¶è¾“å‡ºäº†æ­£ç¡®çš„æ€§èƒ½ï¼Œæˆ‘é™„ä¸Šäº†ç…§ç‰‡ï¼Œä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä¾¥å¹¸æˆ–è¿‡åº¦æ‹Ÿåˆï¼Ÿ  â€‹   ç”±   æäº¤/u/Sadboi1010   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ba8tq6/model_performance_evaluation/</guid>
      <pubDate>Sat, 09 Mar 2024 04:18:30 GMT</pubDate>
    </item>
    <item>
      <title>å¤§å®¶å¥½ï¼æˆ‘å°†ä»äº‹æ—¨åœ¨ä½¿ç”¨ RL ç®—æ³•ç¨³å®šæ— äººæœºçš„æ¨¡æ‹Ÿé¡¹ç›®ï¼Œæˆ‘æƒ³è¿‡ä½¿ç”¨ matlab å’Œ simulinkï¼Œä½†æˆ‘æ‰¾ä¸åˆ°è¦æµ‹è¯•çš„æ¨¡å‹ï¼Œä»»ä½•äººéƒ½å¯ä»¥æŒ‡å¯¼æˆ‘å—ï¼Ÿè°¢è°¢</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b9zscg/hi_everyone_im_gonna_work_on_simulation_project/</link>
      <description><![CDATA[ ç”±   æäº¤/u/DueStill7268   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b9zscg/hi_everyone_im_gonna_work_on_simulation_project/</guid>
      <pubDate>Fri, 08 Mar 2024 21:26:25 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨è¦†ç›–é‡æ’­ç¼“å†²åŒºæ—¶æ˜¯å¦å­˜åœ¨ä¼˜å…ˆè€ƒè™‘é™ˆæ—§å†…å­˜çš„èŒƒä¾‹ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b9qxhk/is_there_a_paradigm_on_which_stale_memories_to/</link>
      <description><![CDATA[æˆ‘å¼€å§‹æ€è€ƒï¼Œå› ä¸ºæˆ‘å‘èª“èŒƒä¾‹æ€»æ˜¯å¾ªç¯å…ˆè¿›å…ˆå‡ºï¼Œä½†å¯¹äºæˆ‘æ­£åœ¨ç ”ç©¶çš„åè¿›å…ˆå‡ºçš„å®ç°ä¼¼ä¹å·¥ä½œå¾—æ›´å¥½ã€‚  å¦å¤–ï¼Œåœ¨ä¼˜å…ˆä½“éªŒé‡æ”¾çš„æƒ…å†µä¸‹ï¼Œä¸ºä»€ä¹ˆä¸ä¸¢å¼ƒæœ€ä½çš„ TD å†…å­˜å‘¢ï¼Ÿ  æˆ–è€…å½“ç¼“å†²åŒºæ»¡æ—¶éšæœºæ›´æ¢å†…å­˜ï¼Ÿ    ç”±   æäº¤ /u/DotNetEvangeliser   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b9qxhk/is_there_a_paradigm_on_which_stale_memories_to/</guid>
      <pubDate>Fri, 08 Mar 2024 15:36:40 GMT</pubDate>
    </item>
    <item>
      <title>ğŸš€ DIAMBRA ä¸ Hugging Face åˆä½œæ¨åŠ¨å¼ºåŒ–å­¦ä¹ ç ”ç©¶å’Œé‡‡ç”¨ï¼ ğŸš€</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b9nw82/diambra_teams_up_with_hugging_face_to_push/</link>
      <description><![CDATA[       ç”±   æäº¤/u/DIAMBRA_AIArena   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b9nw82/diambra_teams_up_with_hugging_face_to_push/</guid>
      <pubDate>Fri, 08 Mar 2024 13:27:03 GMT</pubDate>
    </item>
    <item>
      <title>é—®é¢˜ï¼šå…³äºå•ç¯å¢ƒä¸å¤šç¯å¢ƒ RL è®­ç»ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b9le2c/question_regarding_single_environment_vs_multi/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ç ”ç©¶æœºæ¢°è‡‚æ¨¡æ‹Ÿï¼Œä»¥å¯¹æœºå™¨äººæ‰§è¡Œé«˜çº§æ§åˆ¶ä»¥æŠ“å–ç‰©ä½“ã€‚æˆ‘æ­£åœ¨ä½¿ç”¨ Unity ä¸­çš„ ML Agent ä½œä¸ºç¯å¢ƒå¹³å°ã€‚åŒæ—¶ï¼Œä½¿ç”¨ PPO è®­ç»ƒæœºå™¨äººï¼Œæˆ‘èƒ½å¤Ÿåœ¨å¤§çº¦ 8 å°æ—¶çš„è®­ç»ƒæ—¶é—´å†…æˆåŠŸæ‰§è¡Œå®ƒã€‚ä¸ºäº†å‡å°‘æ—¶é—´ï¼Œæˆ‘å°è¯•å¢åŠ åœ¨åŒä¸€ç¯å¢ƒä¸­å·¥ä½œçš„ä»£ç†æ•°é‡ï¼ˆæœ‰ä¸€ä¸ªå†…ç½®çš„è®­ç»ƒåŒºåŸŸå¤åˆ¶å™¨ï¼Œå®ƒåªæ˜¯ä½¿ç”¨ä»£ç†å¤åˆ¶æ•´ä¸ªæœºå™¨äººå•å…ƒï¼‰ã€‚æ ¹æ®mlagentsæºä»£ç ï¼Œå¤šä¸ªä»£ç†åº”è¯¥åªæ˜¯åŠ é€Ÿè½¨è¿¹æ”¶é›†ï¼ˆå› ä¸ºæœ‰è®¸å¤šä»£ç†æ ¹æ®ç›¸åŒçš„ç­–ç•¥å°è¯•é’ˆå¯¹ä¸åŒéšæœºæƒ…å†µçš„æ“ä½œï¼Œæ‰€ä»¥æ›´æ–°ç¼“å†²åŒºåº”è¯¥æ›´å¿«åœ°å¡«æ»¡ï¼‰ã€‚ä½†æ˜¯ï¼Œç”±äºæŸç§åŸå› ï¼Œæˆ‘çš„ç­–ç•¥æ— æ³•æ­£ç¡®è®­ç»ƒã€‚å®ƒåœ¨é›¶å›æŠ¥å¤„æŒå¹³ï¼ˆä» - 1 å¼€å§‹æ”¹å–„ï¼Œä½†ç¨³å®šåœ¨ 0 å·¦å³ã€‚+1 æ˜¯ä¸€ä¸ªæƒ…èŠ‚çš„æœ€å¤§å›æŠ¥ï¼‰ã€‚å¢åŠ ä»£ç†æ•°é‡æ—¶æ˜¯å¦éœ€è¦è¿›è¡Œä¸€äº›ç‰¹å®šçš„æ›´æ”¹ï¼Ÿå¢åŠ ç¯å¢ƒæ•°é‡æ—¶éœ€è¦è®°ä½çš„å…¶ä»–ä¸€äº›äº‹é¡¹ã€‚æ¬¢è¿ä»»ä½•æ„è§æˆ–å»ºè®®ã€‚æå‰è‡´è°¢ã€‚    ç”±   æäº¤ /u/Flaky-Drag-31   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b9le2c/question_regarding_single_environment_vs_multi/</guid>
      <pubDate>Fri, 08 Mar 2024 10:56:15 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ ray å®ç°è‡ªå®šä¹‰ RL Agent</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b9kqh8/implement_custom_rl_agent_with_ray/</link>
      <description><![CDATA[å˜¿ï¼Œæˆ‘ï¼Œç›®å‰æ­£åœ¨å°è¯•ä½¿ç”¨ ray (tune.trainable) å®ç°æˆ‘è‡ªå·±çš„ RL ä»£ç†ï¼Œå¹¶ä½¿ç”¨åŸºäºç¾¤ä½“çš„è®­ç»ƒè°ƒåº¦ç¨‹åºæ¥è®­ç»ƒå®ƒä»¬ã€‚æ ¹æ®æ–‡æ¡£ï¼Œæœ‰ 6 ç§æ–¹æ³•å¯ä»¥å®ç°ï¼š https://docs.ray.io/en /latest/tune/api/trainable.html å‡ºç°äº†è®¸å¤šç–‘é—®å’Œé—®é¢˜ã€‚å¦‚æœæœ‰äººèƒ½ä¸ºæˆ‘å›ç­”ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚ æˆ‘çš„é—®é¢˜æ˜¯ï¼Œæ¯æ¬¡åœ¨è®­ç»ƒæœŸé—´åŠ è½½æ£€æŸ¥ç‚¹æ—¶éƒ½ä¼šè°ƒç”¨ setup() æ–¹æ³•ï¼Œè€Œä¸ä»…ä»…æ˜¯åœ¨å¼€å§‹ä¹‹åï¼ˆæˆ‘è®¾ç½®äº†reuse_agent æ ‡å¿—ï¼‰åœ¨ Tuner é…ç½®ä¸­ï¼Œreset?config() æ–¹æ³•è¿”å› trueï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä¸ç¡®å®šåœ¨ cleanup() æ–¹æ³•ä¸­è¦åšä»€ä¹ˆã€‚ step() æ–¹æ³•åº”è¯¥åœ¨ç¯å¢ƒä¸­æ‰§è¡Œä¸€æ­¥ï¼Œè¿˜æ˜¯åœ¨çºªå…ƒä¸Šæ‰§è¡Œä¸€æ­¥ï¼Ÿå¹¶ä¸”é‡æ’­ç¼“å†²åŒºåº”è¯¥åœ¨ä¸åŒçš„ä»£ç†ä¹‹é—´å…±äº«ï¼Œæˆ–è€…æ¯ä¸ªä»£ç†åº”è¯¥æœ‰è‡ªå·±çš„é‡æ’­ç¼“å†²åŒºã€‚ å¦‚æœæœ‰äººå·²ç»å®ç°äº†è‡ªå®šä¹‰å…‰çº¿å¯è®­ç»ƒï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ github é“¾æ¥:) â€‹   ç”±   æäº¤ /u/ChiefAlu   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b9kqh8/implement_custom_rl_agent_with_ray/</guid>
      <pubDate>Fri, 08 Mar 2024 10:09:41 GMT</pubDate>
    </item>
    <item>
      <title>ä¿®è¡¥å¼ºåŒ–å­¦ä¹ æ‰€éœ€çš„çŸ¥è¯†æ°´å¹³</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b90c96/level_of_knowledge_needed_to_tinker_with_rl/</link>
      <description><![CDATA[æˆ‘æ˜¯ä¸€åæ™®é€šçš„ 3D æ‰“å°æœº/æœºå™¨äººä¿®è¡¥åŒ ï¼Œä»æˆ‘æ‰€çœ‹åˆ°çš„ RL çš„å¤–è§‚æ¥çœ‹ï¼Œå®ƒä¸ä»…æœ‰è¶£è€Œä¸”æœ‰è¶£ã€‚ä½†å½“æˆ‘æµè§ˆè¿™é‡Œçš„å¸–å­æ—¶ï¼Œå®ƒä»¬éƒ½å†™å¾—è¶…å‡ºäº†æˆ‘çš„ç†è§£èŒƒå›´ã€‚å½“æˆ‘åœ¨ç½‘ä¸ŠæŸ¥çœ‹â€œå¦‚ä½•è¿›å…¥â€¦â€¦â€çš„å†…å®¹æ—¶ï¼Œé‡Œé¢å……æ»¡äº†è®©æˆ‘å»¶ä¼¸å¾ˆè¿œçš„æ¦‚å¿µã€‚å¯¹æˆ‘æ¥è¯´ï¼Œæ˜¾ç„¶æˆ‘ä¸çŸ¥é“è¿™ä¸€åˆ‡çš„èƒŒæ™¯æ˜¯ä»€ä¹ˆã€‚è¿™æ˜¯æ‚¨éå¸¸éœ€è¦å­¦ä½æˆ–å¤§å­¦æ°´å¹³çš„æ•™è‚²å’Œç†è§£æ‰èƒ½å¼€å§‹çš„äº‹æƒ…å—ï¼Ÿæˆ‘å‘ç°å¾ˆå¤šæ¶‰åŠå¼ºåŒ–å­¦ä¹ çš„ä¾‹å­éƒ½æ˜¯äººä»¬çš„è¯¾ç¨‹é¡¹ç›®ã€‚æˆ‘ç›¸ä¿¡ä½ å¯ä»¥åšä½ æƒ³åšçš„äº‹ï¼Œä½†æˆ‘å¸Œæœ›çŸ¥é“æˆ‘å¯èƒ½éœ€è¦ä»˜å‡ºå¤šå¤§çš„åŠªåŠ›ï¼Œä»¥åŠè¿™å¯¹æˆ‘æ¥è¯´æ˜¯å¦å€¼å¾—ã€‚ä½ çš„èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ   ç”±   æäº¤ /u/UltimateThrowawayNam   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b90c96/level_of_knowledge_needed_to_tinker_with_rl/</guid>
      <pubDate>Thu, 07 Mar 2024 17:30:27 GMT</pubDate>
    </item>
    <item>
      <title>è´Ÿè§£é‡Šæ–¹å·®</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1b8mjz4/negative_explained_variance/</link>
      <description><![CDATA[   https://wandb .ai/kingsignificant5097/uncategorized?workspace=user-kingsignificant5097 https://preview.redd.it/wqbzrf6dgumc1.png?width=3516&amp;format=png&amp;auto=webp&amp;s=eacf2d106283d3bc2143a9a9e3f7f68f5 bcbdb67 æˆ‘ä¸€ç›´åœ¨è‡´åŠ›äºä¸€ä¸ªé¡¹ç›®ï¼Œè¯•å›¾äº²èº«ä½“éªŒä¸€äº›å¼ºåŒ–å­¦ä¹ ã€‚ æˆ‘æ­£åœ¨å»ºæ¨¡çš„ç¯å¢ƒæ˜¯ä¸€ä¸ªæ—¶é—´åºåˆ—ï¼Œæˆ‘æ­£åœ¨è®­ç»ƒä¸€ä¸ªä»£ç†é€šè¿‡äº¤æ˜“é‡‘èè¡ç”Ÿå“æ¥æœ€å¤§åŒ–è´¢åŠ¡å›æŠ¥ï¼Œç‰¹åˆ«æ˜¯æ æ†æ°¸ç»­æœŸè´§ã€‚å› æ­¤ï¼Œå®ƒéœ€è¦æœ€å¤§åŒ–è´¢åŠ¡æ”¶ç›Šå¹¶æœ€å°åŒ–è´¢åŠ¡æŸå¤±ã€‚æ¯å½“ä»£ç†å¹³ä»“æ—¶éƒ½ä¼šç»™äºˆå¥–åŠ±ï¼Œå¥–åŠ±ä¸ç›¸å¯¹äºåˆå§‹æŠ•èµ„çš„æ”¶ç›Š/æŸå¤±ç™¾åˆ†æ¯”æˆæ­£æ¯”ã€‚ åŠ¨ä½œç©ºé—´æ˜¯ä¸€ä¸ªå…·æœ‰ 4 ä¸ªåŠ¨ä½œçš„å¤šç¦»æ•£ç©ºé—´ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼Œå¼€ä»“æŒä»“ï¼ˆä»¥åŠè¦ä½¿ç”¨çš„èµ„é‡‘ç™¾åˆ†æ¯”ï¼‰ã€å¹³ä»“ã€ç»“æŸäº‹ä»¶ã€‚è§‚å¯Ÿç©ºé—´çº¦ä¸º 100 ä¸ªï¼ŒåŒ…å«å½“å‰å¼€ç›˜/æ”¶ç›˜/äº¤æ˜“é‡å’Œä¸€äº›è´¢åŠ¡æŒ‡æ ‡ï¼ˆæŠ€æœ¯åˆ†æï¼‰ä»¥åŠæŸäº›å†å²æ—¶æœŸçš„èšåˆæŒ‡æ ‡ã€‚ ä½¿ç”¨çš„ç®—æ³•æ˜¯ dd-ppoï¼ˆ56 ä¸ª cpuï¼‰ ï¼‰ä½¿ç”¨ rllib è¿›è¡Œä¸€äº›ä¿®æ”¹ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨å®ç°æ“ä½œå±è”½çš„è‡ªå®šä¹‰æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œç¡®ä¿ä»£ç†åªæœ‰åœ¨æœ‰ä»“ä½å­˜åœ¨æ—¶æ‰å¯ä»¥å¹³ä»“ï¼Œå¹¶ä¸”åªæœ‰åœ¨æ²¡æœ‰æŒä»“å¹¶ä¸”æ€»æ”¶ç›Šæˆ–æŸå¤±&gt; 1æ—¶æ‰èƒ½ç»“æŸä¸€ä¸ªepisodeã€‚ ï¼ˆæŸäº›ï¼…ï¼‰ï¼Œæˆ–è€…æ€»å‰§é›†é•¿åº¦å¤§äºæŸäº›æ­¥æ•°ã€‚ æˆ‘è¿˜ä½¿ç”¨ å…·æœ‰ 8 ä¸ªå¤´å’Œ 4 ä¸ªå˜å‹å™¨çš„æ³¨æ„åŠ›ç½‘ç»œï¼Œå¹¶ä½¿ç”¨ RE3  ç”¨äºæ¢ç´¢ã€‚ é€šè¿‡ä»¥ä¸Šæ‰€æœ‰å†…å®¹ï¼Œæˆ‘èƒ½å¤Ÿè·å¾—è‰¯å¥½çš„ç»“æœï¼Œå¹¶ä¸”ä»£ç†ä¼¼ä¹ç¡®å®åœ¨å­¦ä¹ ï¼ŒåŸºäºå¹³å‡å¥–åŠ±å’ŒåŸºäºé’ˆå¯¹æœªè§æ•°æ®æ£€æŸ¥ç‚¹çš„å®è¯æµ‹è¯•ã€‚  ä½†æ˜¯ï¼Œåœ¨æŸ¥çœ‹ TensorBoard æŒ‡æ ‡æ—¶ï¼Œæˆ‘çœ‹åˆ°äº†ä¸€äº›å¯¹æˆ‘æ¥è¯´æ²¡æœ‰å¤šå¤§æ„ä¹‰çš„äº‹æƒ…ï¼Œå› æ­¤æˆ‘åœ¨è¿™é‡Œå¯»æ±‚ä»»ä½•äººçš„å¸®åŠ©æˆ–å»ºè®®ï¼š &lt; ol&gt; æ˜¯ä»€ä¹ˆå¯¼è‡´è§£é‡Šæ–¹å·®ä¸ºè´Ÿï¼Ÿæˆ‘åº”è¯¥é¢„è®¡è¿™ä¸ªæ•°å­—ä¼šå¼€å§‹å¢åŠ å—ï¼Ÿé‰´äºå¥–åŠ±å‡å€¼åœ¨å¦‚æ­¤å¤æ‚çš„ç¯å¢ƒä¸­ä¸æ–­å¢åŠ ï¼Œè¿™æ ·çš„è´Ÿæ–¹å·®æœ‰ä½•æ„ä¹‰ï¼Ÿ ä¸ºä»€ä¹ˆç†µå¹¶æ²¡æœ‰çœŸæ­£ä¸‹é™ï¼Ÿè¿™å¾ˆé‡è¦å—ï¼Ÿ ä¸ºä»€ä¹ˆæŸå¤±ç»§ç»­ç¼“æ…¢å¢åŠ ï¼Ÿæˆ‘åº”è¯¥æœŸæœ›è¿™ä¸ªå€¼ä¼šåœ¨æŸä¸ªæ—¶å€™å¼€å§‹ä¸‹é™å—ï¼Ÿè¿™æ˜¯ä»£ç†ä»åœ¨å­¦ä¹ çš„æ ‡å¿—å—ï¼Ÿ  æå‰æ„Ÿè°¢æ‚¨çš„æŒ‡ç‚¹ï¼ ä¸€äº›ä¿®æ”¹çš„å‚æ•°ï¼Œé»˜è®¤å€¼æ¥è‡ª rllib for ppo å’Œ dd-ppo è¦†ç›–ï¼š &lt;ä»£ç &gt;åœ°å¹³çº¿ = 60 .training( train_batch_size = åœ°å¹³çº¿ * 4, sgd_minibatch_size = åœ°å¹³çº¿ * 2, num_sgd_iter = 2, gamma = 1.0, lambda_ = 1.0, entropy_coeff = 0.001, grad_clip = 10, model = { â€œfcnet_hiddensâ€: [1024 ï¼Œ1024]ï¼Œâ€œmax_seq_lenâ€ï¼šåœ°å¹³çº¿ï¼Œâ€œattention_num_transformer_unitsâ€ï¼š4ï¼Œâ€œattention_num_headsâ€ï¼š8ï¼Œ}ï¼‰ &lt;ï¼-- SC_ON --&gt;   ;ç”±   æäº¤ /u/KingSignificant5097   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1b8mjz4/negative_explained_variance/</guid>
      <pubDate>Thu, 07 Mar 2024 05:29:18 GMT</pubDate>
    </item>
    </channel>
</rss>