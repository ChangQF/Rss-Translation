<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 30 Oct 2024 15:18:16 GMT</lastBuildDate>
    <item>
      <title>æœ‰æ²¡æœ‰è®ºæ–‡ç ”ç©¶è¿‡RLç®—æ³•å’Œä¼˜åŒ–å™¨ä¹‹é—´çš„å…³ç³»ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gfm7a3/are_there_any_papers_that_have_studied_the/</link>
      <description><![CDATA[æˆ‘ä¸ªäººæ­£åœ¨å°è¯•å¾ˆå¤šç®€å•çš„ç®—æ³•ï¼Œæˆ‘å·²ç»è€ƒè™‘è¿™ä¸ªé—®é¢˜ä¸€æ®µæ—¶é—´äº†ï¼šadam çš„åŠ¨é‡å¯ä»¥å¸®åŠ©æ¨¡å‹å¿«é€Ÿæ”¶æ•›ï¼Œä½†å½“ç›®æ ‡å€¼å‘ç”Ÿå˜åŒ–æ—¶ï¼Œè¿™ä¼šæœ‰å®³å—ï¼Œå°±åƒ RL ä¸€æ ·ï¼Ÿå¦‚æœå¤§éƒ¨åˆ†åŠ¨é‡è¶…å‡ºé¢„æµ‹ï¼Œå¹¶ä¸”ç›®æ ‡ç½‘ç»œå¤åˆ¶äº†è¿™ç§è¶…å‡ºï¼Œåˆ™æ¨¡å‹å¯èƒ½ä¼šå‘æ•£ã€‚æœ‰äººå¯¹æ­¤åšè¿‡ç ”ç©¶å—ï¼Ÿ    æäº¤äºº    /u/New_East832   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gfm7a3/are_there_any_papers_that_have_studied_the/</guid>
      <pubDate>Wed, 30 Oct 2024 13:13:19 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Python å®ç°çš„ PPOï¼Œå­¦ä¹ åŠ¨ä½œåˆ†å¸ƒçš„å¹³å‡å€¼å’Œæ ‡å‡†å·® Ïƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gfgwwq/ppo_implementation_in_python_with_learned_mean/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ‰¾æœ‰å…³ Python è½¯ä»¶åŒ…çš„æ¨èï¼Œè¿™äº›è½¯ä»¶åŒ…å…è®¸è®­ç»ƒ PPO ä»£ç†ï¼Œå…¶ä¸­åŠ¨ä½œåˆ†å¸ƒçš„å¹³å‡å€¼ (Î¼) å’Œæ ‡å‡†å·® (Ïƒ) éƒ½æ˜¯å­¦ä¹ åˆ°çš„ã€‚ å…·ä½“æ¥è¯´ï¼Œæˆ‘éœ€è¦æ¨¡å‹åœ¨ç»™å®šå½“å‰è§‚å¯Ÿçš„æƒ…å†µä¸‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¾“å‡ºåŠ¨ä½œå’Œç›¸åº”çš„æ ‡å‡†å·®ã€‚è¿™å°†å¸®åŠ©æˆ‘è¯„ä¼°ä»£ç†å¯¹å…¶é¢„æµ‹çš„ä¿¡å¿ƒã€‚ æˆ‘è§è¿‡å…³äº skrl å’Œ AgileRL è½¯ä»¶åŒ…çš„è®¨è®ºï¼Œå®ƒä»¬æ®ç§°æ˜¯æ¨¡å—åŒ–çš„ã€‚æœ‰äººç”¨è¿‡è¿™äº›å—ï¼Ÿä»–ä»¬ä¹Ÿå¯ä»¥æä¾›å­¦ä¹ åˆ°çš„ Ïƒ å—ï¼Ÿ ä»»ä½•å»ºè®®æˆ–è§è§£éƒ½å°†ä¸èƒœæ„Ÿæ¿€ã€‚ è°¢è°¢ã€‚    æäº¤äºº    /u/Disastrous_Effort725   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gfgwwq/ppo_implementation_in_python_with_learned_mean/</guid>
      <pubDate>Wed, 30 Oct 2024 07:23:26 GMT</pubDate>
    </item>
    <item>
      <title>Meta FAIR CodeGen å›¢é˜Ÿçš„æ–° RL å®ä¹ æœºä¼š</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gfam2x/new_rl_internship_at_meta_fair_codegen_team/</link>
      <description><![CDATA[        æäº¤äºº    /u/bulgakovML   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gfam2x/new_rl_internship_at_meta_fair_codegen_team/</guid>
      <pubDate>Wed, 30 Oct 2024 00:58:26 GMT</pubDate>
    </item>
    <item>
      <title>â€œCentaurï¼šäººç±»è®¤çŸ¥çš„åŸºç¡€æ¨¡å‹â€ï¼ŒBinz ç­‰äºº 2024 å¹´</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gf6nsf/centaur_a_foundation_model_of_human_cognition/</link>
      <description><![CDATA[  ç”±    /u/gwern  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gf6nsf/centaur_a_foundation_model_of_human_cognition/</guid>
      <pubDate>Tue, 29 Oct 2024 21:55:42 GMT</pubDate>
    </item>
    <item>
      <title>å¼€æºç«ç®­è”ç›Ÿç¯å¢ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gf3q6d/open_source_rocket_league_environment/</link>
      <description><![CDATA[        æäº¤äºº    /u/compressor0101   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gf3q6d/open_source_rocket_league_environment/</guid>
      <pubDate>Tue, 29 Oct 2024 19:51:52 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Memoroids è¿›è¡Œå¾ªç¯å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gekts9/recurrent_reinforcement_learning_with_memoroids/</link>
      <description><![CDATA[  ç”±    /u/smorad  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gekts9/recurrent_reinforcement_learning_with_memoroids/</guid>
      <pubDate>Tue, 29 Oct 2024 02:58:28 GMT</pubDate>
    </item>
    <item>
      <title>æ¼”å‘˜è¯„è®ºå®¶æ¨¡å‹å¯¹æ‰€æœ‰è¾“å…¥é‡‡å–ç›¸åŒçš„åŠ¨ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gek86t/actor_critic_model_taking_same_action_for_all/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æ­£åœ¨ç ”ç©¶ Actor Critic æ¨¡å‹ï¼Œä»¥ä¾¿æ ¹æ®æ—¶é—´åºåˆ—æ•°æ®åšå‡ºå†³ç­–ã€‚æˆ‘å°è¯•äº†ä¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œå¦‚ LSTMã€Transformer ç”šè‡³ Mambaï¼Œä»¥æ£€æŸ¥ä»»ä½•ä¸åŒçš„ç»“æœï¼Œä½†æ²¡æœ‰ä»»ä½•å˜åŒ–ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘å°†æ—¶é—´åºåˆ—æ•°æ®ä¼ é€’ç»™æˆ‘çš„æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­ä» 6 ä¸ªåŠ¨ä½œä¸­é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œã€‚ å¯¹äºè¾“å…¥æ•°æ®ï¼Œæˆ‘å°è¯•äº† 2 ç§ä¸åŒçš„æ–¹æ³•ï¼›å…¨ä¸Šä¸‹æ–‡é•¿åº¦å’Œè¾“å…¥å½¢çŠ¶å¦‚ (seq_len, hidden_â€‹â€‹dim)ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å°†é‡‡å–æ‰€æœ‰æ—¶é—´æ­¥éª¤å¹¶ä¸ºæ¯ä¸ªæ—¶é—´æ­¥éª¤æä¾›åŠ¨ä½œè¾“å‡ºã€‚æˆ‘è¿˜å°è¯•äº†å›ºå®šä¸Šä¸‹æ–‡é•¿åº¦å’Œç±»ä¼¼ (batch_size, seq_len, hidden_â€‹â€‹dim) çš„è¾“å…¥å½¢çŠ¶ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä¸ºæ¯ä¸ªæ‰¹æ¬¡è€Œä¸æ˜¯æ—¶é—´æ­¥é•¿åˆ›å»ºä¸€ä¸ªåŠ¨ä½œè¾“å‡ºã€‚ æˆ‘è¿˜å®ç°äº† Epsilon Greedy è¿›è¡Œæ¢ç´¢ï¼Œå¹¶åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶æ‰“å°æ¯ä¸ªåŠ¨ä½œçš„é€‰å®šåŠ¨ä½œç™¾åˆ†æ¯”ä½œä¸ºè¾“å‡ºï¼Œä»¥æ£€æŸ¥æ¨¡å‹è¾“å‡ºã€‚ æˆ‘çš„é—®é¢˜ä»è¿™ä¸€ç‚¹å¼€å§‹ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨ epsilon é€€ç«è¿›è¡Œ epochï¼Œåœ¨è®­ç»ƒæ—¶å®ƒæ­£åœ¨å‡å°‘ epsilon æ•°ä»¥å‡å°‘æ¢ç´¢ã€‚å½“æˆ‘æ£€æŸ¥æˆ‘çš„ Critic Loss å€¼éšæ—¶é—´çš„å˜åŒ–æ—¶ï¼Œå®ƒæ­£åœ¨æ˜¾ç€å‡å°‘ï¼ˆCritic çš„ MSE Loss ä» 0.9 å·¦å³å¼€å§‹ï¼Œå¯¹äº +1 å’Œ -1 ä¹‹é—´çš„å¥–åŠ±å€¼ä¸‹é™åˆ° 0.002ï¼‰æ‰€ä»¥æˆ‘è®¤ä¸ºæ‰¹è¯„å®¶æ­£åœ¨å­¦ä¹ ã€‚ åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œæˆ‘è¿˜åœ¨è¿è¡Œè¯„ä¼°ä»¥æŸ¥çœ‹çŠ¶æ€ï¼Œåœ¨è¯„ä¼°æ—¶ï¼Œæˆ‘è¿˜åœ¨æ£€æŸ¥æ¯ä¸ªåŠ¨ä½œçš„é€‰å®šåŠ¨ä½œç™¾åˆ†æ¯”ã€‚é—®é¢˜æ˜¯ï¼Œæ— è®ºè¾“å…¥æ˜¯ä»€ä¹ˆï¼Œæˆ‘çš„æ¨¡å‹éƒ½ä¼šé€‰æ‹©ç›¸åŒçš„åŠ¨ä½œã€‚åœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä½¿ç”¨è´ªå©ªçš„ epsilon åˆ†ç±»æŠ½æ ·ï¼Œå› æ­¤å®ƒé€‰æ‹©äº†ä¸åŒçš„åŠ¨ä½œï¼Œä½†æ˜¯å½“æˆ‘åœ¨è¯„ä¼°æ­¥éª¤ä½¿ç”¨ argmax æ—¶ï¼Œå®ƒé€‰æ‹©äº†ç›¸åŒçš„åŠ¨ä½œã€‚  æˆ‘å°è¯•è¿‡çš„ï¼›å…·æœ‰å„ç§å‚æ•°å¤§å°çš„ä¸åŒæ¨¡å‹æ¶æ„ã€‚ä¸åŒçš„å­¦ä¹ ç‡ï¼Œä»å¤ªé«˜åˆ°å¤ªä½ã€‚ä¸åŒçš„åˆå§‹ epsilon å€¼ã€‚ä¸åŒçš„è¾“å…¥ç±»å‹ï¼ˆå›ºå®šé•¿åº¦å’Œå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰  å®ƒä»¬éƒ½æ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚æˆ‘ä»è¿™ä¸ªä¾‹å­ä¸­å®ç°äº†æˆ‘çš„æ¼”å‘˜è¯„è®ºå®¶æ¨¡å‹ï¼Œå¹¶ä»”ç»†æ£€æŸ¥äº†æ˜¯å¦æœ‰ä»»ä½•é”™è¯¯ï¼› https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f ç»è¿‡è¿™ä¸€åˆ‡ï¼Œæˆ‘æ‰¾ä¸åˆ°ä»»ä½•è§£å†³æ–¹æ¡ˆã€‚æœ‰äººæœ‰ä»€ä¹ˆæƒ³æ³•å—ï¼Ÿ    ç”±    /u/BagComprehensive79  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gek86t/actor_critic_model_taking_same_action_for_all/</guid>
      <pubDate>Tue, 29 Oct 2024 02:26:36 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ä¸ä»…èƒ½è§£å†³éš¾é¢˜ï¼Œè¿˜èƒ½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1geez5d/rl_solves_hard_problems_but_also/</link>
      <description><![CDATA[        æäº¤äºº    /u/FriendlyStandard5985   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1geez5d/rl_solves_hard_problems_but_also/</guid>
      <pubDate>Mon, 28 Oct 2024 22:21:13 GMT</pubDate>
    </item>
    <item>
      <title>å¤šå¤´PPO</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gee2o7/multihead_ppo/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æœ‰ä¸€ä¸ªæœ‰å››ä¸ªå¤´çš„ç½‘ç»œã€‚ä¸€ä¸ªå¤´ï¼ˆæœ‰ä¸‰ä¸ªåŠ¨ä½œï¼‰å†³å®šæ˜¯å¦æ‰§è¡Œç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªæˆ–ç¬¬å››ä¸ªå¤´çš„åŠ¨ä½œã€‚ç¬¬äºŒä¸ªå¤´çš„åŠ¨ä½œæœ‰åŠ©äºæƒ…èŠ‚ç»“æŸï¼Œè€Œç¬¬ä¸‰ä¸ªå’Œç¬¬å››ä¸ªå¤´çš„åŠ¨ä½œå¯¹äºå®ç°ä¸»è¦ç›®æ ‡å¾ˆé‡è¦ã€‚æˆ‘æ­£åœ¨ä½¿ç”¨ PPOï¼Œä½†æœ‰æ—¶ç½‘ç»œä¼šå¡åœ¨ç¬¬ä¸‰ä¸ªæˆ–ç¬¬å››ä¸ªå¤´ï¼Œå› æ­¤æƒ…èŠ‚æ°¸è¿œä¸ä¼šç»“æŸã€‚æœ‰äººçŸ¥é“æ˜¯ä»€ä¹ˆå¯¼è‡´äº†è¿™ç§è¡Œä¸ºå—ï¼Ÿ    æäº¤äºº    /u/GuavaAgreeable208   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gee2o7/multihead_ppo/</guid>
      <pubDate>Mon, 28 Oct 2024 21:43:11 GMT</pubDate>
    </item>
    <item>
      <title>æœºå™¨äººæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼šç°å®ä¸–ç•Œçš„æˆåŠŸè°ƒæŸ¥</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ge2hn5/deep_reinforcement_learning_for_robotics_a_survey/</link>
      <description><![CDATA[  ç”±    /u/bulgakovML  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ge2hn5/deep_reinforcement_learning_for_robotics_a_survey/</guid>
      <pubDate>Mon, 28 Oct 2024 13:48:41 GMT</pubDate>
    </item>
    <item>
      <title>ç»„åˆ DQN</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1ge11zq/combining_dqns/</link>
      <description><![CDATA[å°† 3 ä¸ª DQN ç»„åˆæˆä¸€ä¸ª DQN çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆã€‚æ¯ä¸ª DQN éƒ½æœ‰ç±»ä¼¼çš„å‚æ•°ï¼Œå°±åƒå®ƒä»¬åœ¨ä¸åŒçš„ä»»åŠ¡ä¸Šå·¥ä½œä½†ä»ç„¶ç›¸ä¼¼ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæœ‰æ•Œäººå’ŒçŠ¶æ€çš„æ¸¸æˆã€‚é¦–å…ˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ 3 ä¸ªåŠ¨ä½œã€‚  ä½¿ç”¨å‰‘ ä½¿ç”¨å¼“ ä½¿ç”¨é­”æ³•  å¦‚æœæ‚¨ä½¿ç”¨å‰‘ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ 2 ç§ä¸åŒçš„åŠ¨ä½œï¼Œå¦‚è½»æ”»å‡»æˆ–é‡æ”»å‡»ã€‚å¦‚æœæ‚¨ä½¿ç”¨å¼“ï¼Œæ‚¨å¯ä»¥ç”¨å®ƒå‡»ä¸­æ•Œäººçš„è¿‘æˆ˜ï¼Œæˆ–è€…ä½¿ç”¨ç®­ï¼ˆå¦‚æœæœ‰ï¼‰ç­‰ã€‚ æˆ‘ä¸æƒ³åˆ›å»ºä¸€ä¸ªå¯ä»¥å†³å®šç¬¬ä¸€ä¸ªåŠ¨ä½œï¼ˆå°†ä½¿ç”¨ä»€ä¹ˆæ ·çš„æ­¦å™¨ï¼‰ç„¶åä¸ºæ¯ç§æ­¦å™¨å†³å®šå°†é‡‡å–ä»€ä¹ˆæ ·çš„åŠ¨ä½œçš„ DQNï¼Œè€Œæ˜¯æƒ³ä¸ºæ¯ç§æ­¦å™¨åˆ›å»ºä¸€ä¸ª DQNï¼Œå®ƒç¡®åˆ‡åœ°çŸ¥é“å¦‚ä½•ä½¿ç”¨ä¸€ç§æ­¦å™¨ï¼Œç„¶åå°†å®ƒä»¬ç»„åˆæˆ 1ã€‚æœ€ç»ˆçš„ç½‘ç»œåº”è¯¥ä»çŠ¶æ€ä¸­äº†è§£å°†ä½¿ç”¨å“ªç§æ­¦å™¨ä»¥åŠè¿™äº›æ­¦å™¨å°†é‡‡å–ä»€ä¹ˆåŠ¨ä½œã€‚    æäº¤äºº    /u/volvol7   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1ge11zq/combining_dqns/</guid>
      <pubDate>Mon, 28 Oct 2024 12:43:08 GMT</pubDate>
    </item>
    <item>
      <title>æœŸå¾…æ˜å¹´å¼€å§‹æ”»è¯» RL åšå£«å­¦ä½â€”â€”å¯»æ±‚å»ºè®®ï¼ğŸ¤ğŸ¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdyx82/looking_forward_to_start_phd_in_rl_next_year/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼æˆ‘å‡†å¤‡æ˜å¹´å¼€å§‹æ”»è¯»å¼ºåŒ–å­¦ä¹ åšå£«å­¦ä½ï¼Œä½†éœ€è¦ä¸€äº›å…³äºç§¯ç´¯ç ”ç©¶ç»éªŒå’Œä¸æ•™æˆè”ç³»çš„å»ºè®®ã€‚  èƒŒæ™¯ï¼šæˆ‘åšè¿‡å¾ˆå¤šå®é™…çš„å¼ºåŒ–å­¦ä¹ é¡¹ç›®ï¼ˆMARLã€PettingZooã€ç­–ç•¥æ¢¯åº¦å·¥ä½œï¼‰ï¼Œä½†æˆ‘ç¼ºä¹æ­£å¼çš„ç ”ç©¶ç»éªŒã€‚æˆ‘ä¹Ÿæœ‰ä¸€å¹´çš„ ML/LLM å®ä¹ ç»å†ï¼Œä½†å¯»æ‰¾å¼ºåŒ–å­¦ä¹ çš„ç ”ç©¶å®ä¹ æœºä¼šä¸€ç›´å¾ˆå›°éš¾ã€‚ æŒ‘æˆ˜ï¼šæˆ‘æ‹…å¿ƒæ¥è§¦ LORï¼Œå› ä¸ºæˆ‘æ²¡æœ‰ç›´æ¥ä¸å¼ºåŒ–å­¦ä¹ çš„æ•™æˆåˆä½œè¿‡ã€‚ä»»ä½•å…³äºæœ‰åŠ©äºå±•ç¤ºæˆ‘çš„èƒ½åŠ›çš„é¡¹ç›®å»ºè®®æˆ–æ¥è§¦æŠ€å·§éƒ½å°†éå¸¸æœ‰å¸®åŠ©ã€‚å¦å¤–ï¼Œå¦‚æœæœ‰äººæœ‰å…´è¶£åˆä½œï¼Œè¯·ç›´æ¥å‘ä¿¡æ¯ç»™æˆ‘ï¼ &lt;3  ä»»ä½•è§è§£éƒ½å€¼å¾—èµèµ - è°¢è°¢å¤§å®¶ï¼    æäº¤äºº    /u/cheenchann   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdyx82/looking_forward_to_start_phd_in_rl_next_year/</guid>
      <pubDate>Mon, 28 Oct 2024 10:41:28 GMT</pubDate>
    </item>
    <item>
      <title>å“ªäº› RL ç®—æ³•é€‚ç”¨äºè®¡ç®—å¿ƒç†å­¦ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdytbm/which_rl_algorithms_for_computational_psychology/</link>
      <description><![CDATA[æˆ‘æ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶ï¼Œå¸Œæœ›é€šè¿‡å¤šä¸ªä»£ç†æ¨¡æ‹Ÿäººç±»ç¤¾äº¤äº’åŠ¨ã€‚æˆ‘åªæ˜¯æƒ³çŸ¥é“æ˜¯å¦æœ‰äººå¯ä»¥æŒ‡ç‚¹ä¸€ä¸‹è¦æ¢ç´¢å“ªäº›ç®—æ³•ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘æƒ³é¼“åŠ±åé¦ˆå¾ªç¯å’Œçªå‘è¡Œä¸ºä»¥æ›´çœŸå®åœ°æè¿°äººç±»è¡Œä¸ºï¼Œæˆ‘åº”è¯¥ä½¿ç”¨æ— æ¨¡å‹ç®—æ³•è¿˜æ˜¯åŸºäºæ¨¡å‹çš„ç®—æ³•ï¼Ÿ ä»æˆ‘æœ€åˆçš„ç ”ç©¶ä¸­ï¼Œæˆ‘å¬è¯´äº†å…³äº Decision Transformer å’Œ DreamerV3 çš„å¥½è¯„ã€‚ æ„Ÿè°¢æ‚¨çš„æ—¶é—´ï¼    æäº¤äºº    /u/culturedindividual   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdytbm/which_rl_algorithms_for_computational_psychology/</guid>
      <pubDate>Mon, 28 Oct 2024 10:33:59 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹æŠ—æ€§ç¨³å¥æ·±åº¦å¼ºåŒ–å­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdyrwe/adversarial_robust_deep_reinforcement_learning/</link>
      <description><![CDATA[https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning    ç”±   æäº¤  /u/ml_dnn   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdyrwe/adversarial_robust_deep_reinforcement_learning/</guid>
      <pubDate>Mon, 28 Oct 2024 10:31:18 GMT</pubDate>
    </item>
    <item>
      <title>æœ¬ç§‘ç”Ÿåœ¨ç°å®ç”Ÿæ´»ä¸­çš„ç ”ç©¶æƒ³æ³•ï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1gdvrw0/undergraduate_research_in_rl_ideas/</link>
      <description><![CDATA[æˆ‘å¸Œæœ›å®Œæˆä¸ RL ç›¸å…³çš„è£èª‰é¡¹ç›®ã€‚ä»Šå¹´å¤å¤©ï¼Œæˆ‘å°†ä¸æˆ‘çš„æ•™æˆä¸€èµ·å¼€å±•ä¸€ä¸ªå°å‹ RL ä»£ç†é¡¹ç›®ï¼Œæˆ‘çš„ä»»åŠ¡æ˜¯åˆ¶ä½œä¸€ä¸ª RL è •è™«ã€‚æˆ‘å¯¹ RL çš„ä¸–ç•Œè¿˜å¾ˆé™Œç”Ÿï¼Œå¸Œæœ›èƒ½å¾—åˆ°ä»»ä½•å»ºè®®æˆ–åœ°æ–¹ï¼Œè®©æ–°æ‰‹å¼€å§‹ç ”ç©¶è¿™ä¸ªä¸»é¢˜ï¼    æäº¤äºº    /u/Future-Catch-4896   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1gdvrw0/undergraduate_research_in_rl_ideas/</guid>
      <pubDate>Mon, 28 Oct 2024 06:41:06 GMT</pubDate>
    </item>
    </channel>
</rss>