<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•ä»¥æœ€ä½³æ–¹å¼è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Fri, 24 Jan 2025 03:19:00 GMT</lastBuildDate>
    <item>
      <title>ä¸ºä»€ä¹ˆè¦å¯¹å·å‡ºç¼“å†²åŒºæ•°æ®è¿›è¡Œæ··æ’ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i8he0u/why_shuffle_rollout_buffer_data/</link>
      <description><![CDATA[åœ¨ SB3 çš„å¾ªç¯ç¼“å†²åŒºæ–‡ä»¶ (https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/blob/master/sb3_contrib/common/recurrent/buffers.py) ä¸­ï¼Œç¬¬ 182 è¡Œè¡¨ç¤ºè¦åœ¨ä¿ç•™åºåˆ—çš„åŒæ—¶å¯¹æ•°æ®è¿›è¡Œæ··æ´—ï¼Œä»£ç ä¼šåœ¨éšæœºç‚¹æ‹†åˆ†æ•°æ®ï¼Œäº¤æ¢æ¯ä¸ªæ‹†åˆ†ï¼Œç„¶åå°†å…¶é‡æ–°è¿æ¥åœ¨ä¸€èµ·ã€‚  æˆ‘çš„é—®é¢˜æ˜¯ï¼Œä¸ºä»€ä¹ˆè¿™å¯¹äºæ··æ´—æ¥è¯´å·²ç»è¶³å¤Ÿå¥½äº†ï¼Œä½†æˆ‘ä»¬ä¸ºä»€ä¹ˆè¦é¦–å…ˆå¯¹æ¨å‡ºçš„æ•°æ®è¿›è¡Œæ··æ´—å‘¢ï¼Ÿ   ç”±    /u/AUser213  æäº¤  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i8he0u/why_shuffle_rollout_buffer_data/</guid>
      <pubDate>Thu, 23 Jan 2025 23:31:30 GMT</pubDate>
    </item>
    <item>
      <title>IsaacSim äººå½¢æœºå™¨äºº</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i8ec1e/isaacsim_humanoids/</link>
      <description><![CDATA[æˆ‘éœ€è¦ä¸€äº›å¸®åŠ©åœ¨ IsaacSim ä¸­æ„å»ºäººå½¢æœºå™¨äººæ¼”ç¤ºï¼Œä½†é™¤äº†å¼€ç®±å³ç”¨çš„äººå½¢æœºå™¨äºº (H1) ä¹‹å¤–æ²¡æœ‰å…¶ä»–å¯ç”¨çš„ä¸œè¥¿ï¼Œæœ‰äººå¯¹ Neoã€Sanctuary ç­‰æœºå™¨äººçš„äººå½¢æœºå™¨äººæ”¿ç­–æœ‰ä»»ä½•çº¿ç´¢å—    æäº¤äºº    /u/sohaib_01   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i8ec1e/isaacsim_humanoids/</guid>
      <pubDate>Thu, 23 Jan 2025 21:18:29 GMT</pubDate>
    </item>
    <item>
      <title>aiXplain çš„ Evolverï¼šé€šè¿‡è‡ªä¸»ä¼˜åŒ–å½»åº•æ”¹å˜ä»£ç† AI ç³»ç»Ÿ ğŸš€</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i899m4/aixplains_evolver_revolutionizing_agentic_ai/</link>
      <description><![CDATA[å—¨ï¼ŒRL ç¤¾åŒºï¼ğŸ‘‹ æˆ‘ä»¬éƒ½çŸ¥é“ Agentic AI ç³»ç»Ÿåœ¨è‡ªåŠ¨åŒ–æµç¨‹å’Œå¢å¼ºå„è¡Œä¸šå†³ç­–æ–¹é¢å…·æœ‰å¤šä¹ˆå¤§çš„å˜é©æ€§ã€‚ä½†é—®é¢˜æ˜¯ï¼šä»£ç†è§’è‰²ã€ä»»åŠ¡å’Œå·¥ä½œæµç¨‹çš„æ‰‹åŠ¨å¾®è°ƒä¸€ç›´æ˜¯ä¸€ä¸ªä¸»è¦éšœç¢ã€‚aiXplain çš„ Evolver â€“ æˆ‘ä»¬æ­£åœ¨ç”³è¯·ä¸“åˆ©çš„å®Œå…¨è‡ªä¸»æ¡†æ¶ï¼Œæ—¨åœ¨æ”¹å˜æ¸¸æˆè§„åˆ™ã€‚ ğŸ’¡ aiXplain çš„ Evolver æ˜¯ä¸€æ¬¾ä¸‹ä¸€ä»£å·¥å…·ï¼Œå®ƒï¼š  ğŸ”„ è‡ªä¸»ä¼˜åŒ–å·¥ä½œæµç¨‹ï¼šé€šè¿‡è‡ªåŠ¨å¾®è°ƒ Agentic AI ç³»ç»Ÿï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚ ğŸ“ˆ åˆ©ç”¨ LLM é©±åŠ¨çš„åé¦ˆå¾ªç¯ï¼šä½¿ç”¨é«˜çº§è¯­è¨€æ¨¡å‹è¯„ä¼°è¾“å‡ºã€æä¾›åé¦ˆå¹¶æ¨åŠ¨æŒç»­æ”¹è¿›ã€‚ ğŸš€ æé«˜æ•ˆç‡å’Œå¯æ‰©å±•æ€§ï¼šæ¯”ä»¥å¾€æ›´å¿«åœ°å®ç° AI ç³»ç»Ÿçš„æœ€ä½³é…ç½®ã€‚  ğŸŒŸ ä¸ºä»€ä¹ˆé‡è¦ æˆ‘ä»¬å·²åœ¨å¤šä¸ªé¢†åŸŸåº”ç”¨äº† Evolverï¼Œå¹¶çœ‹åˆ°äº†ä»¤äººæƒŠå¹çš„ç»“æœã€‚ä»¥ä¸‹æ˜¯ä¸€äº›äº®ç‚¹ï¼š 1ï¸âƒ£ å¸‚åœºç ”ç©¶ï¼šå¸‚åœºåˆ†æå¸ˆç­‰ä¸“ä¸šè§’è‰²æé«˜äº†å‡†ç¡®æ€§å¹¶ä½¿ç­–ç•¥ä¸è¶‹åŠ¿ä¿æŒä¸€è‡´ã€‚ 2ï¸âƒ£ åŒ»ç–—ä¿å¥ AIï¼šæé«˜äº†æ³•è§„éµä»æ€§å’Œå¯è§£é‡Šæ€§ï¼Œä»¥æ›´å¥½åœ°å¸å¼•æ‚£è€…ã€‚ 3ï¸âƒ£ èŒä¸šè½¬å‹ï¼šå¸®åŠ©è½¯ä»¶å·¥ç¨‹å¸ˆä»¥æ˜ç¡®çš„ç›®æ ‡å’Œé‡èº«å®šåˆ¶çš„ä¸“ä¸šçŸ¥è¯†è½¬å‘ AI è§’è‰²ã€‚ 4ï¸âƒ£ ä¾›åº”é“¾å¤–å±•ï¼šé€šè¿‡é«˜çº§åˆ†æä¼˜åŒ–ç”µå­å•†åŠ¡è§£å†³æ–¹æ¡ˆçš„å¤–å±•ç­–ç•¥ã€‚ 5ï¸âƒ£ LinkedIn å†…å®¹åˆ›å»ºï¼šåˆ›å»ºä»¥å—ä¼—ä¸ºä¸­å¿ƒçš„å¸–å­ï¼Œæ¨åŠ¨å¯¹ AI è¶‹åŠ¿çš„å‚ä¸ã€‚ 6ï¸âƒ£ è¯ç‰©å‘ç°ï¼šä¸ºåˆ¶è¯å…¬å¸æä¾›ä¸åˆ©ç›Šç›¸å…³è€…ä¸€è‡´çš„è§è§£ã€‚ 7ï¸âƒ£ EdTech æ½œåœ¨å®¢æˆ·ç”Ÿæˆï¼šé€šè¿‡ä¸ªæ€§åŒ–çš„å­¦ä¹ è§è§£æé«˜æ½œåœ¨å®¢æˆ·è´¨é‡ã€‚ æ¯ä¸ªæ¡ˆä¾‹ç ”ç©¶éƒ½å±•ç¤ºäº†ç”± Evolver æä¾›æ”¯æŒçš„ä¸“ä¸šè§’è‰²å’ŒæŒç»­æ”¹è¿›å¦‚ä½•å¸¦æ¥æ›´é«˜çš„è¯„ä¼°åˆ†æ•°å’Œæ›´å¥½çš„ç»“æœã€‚ ğŸ“š å¯¹æŠ€æœ¯ç»†èŠ‚æ„Ÿåˆ°å¥½å¥‡å—ï¼Ÿåœ¨ Arxiv ä¸ŠæŸ¥çœ‹ï¼šé€šè¿‡è¿­ä»£ç»†åŒ–å’Œ LLM é©±åŠ¨çš„åé¦ˆå¾ªç¯è‡ªä¸»ä¼˜åŒ–ä»£ç† AI è§£å†³æ–¹æ¡ˆçš„å¤š AI ä»£ç†ç³»ç»Ÿ ğŸ” ä½ æ€ä¹ˆçœ‹ï¼Ÿ ä½ å¦‚ä½•çœ‹å¾…è¿™æ ·çš„å·¥å…·å¡‘é€  AI å·¥ä½œæµç¨‹çš„æœªæ¥ï¼Ÿä½ è®¤ä¸º Evolver å¯ä»¥åœ¨å“ªäº›è¡Œä¸šæˆ–ç‰¹å®šç”¨ä¾‹ä¸­å‘æŒ¥å·¨å¤§ä½œç”¨ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æƒ³æ³•ã€‚ğŸ˜Š    æäº¤äºº    /u/k_yuksel   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i899m4/aixplains_evolver_revolutionizing_agentic_ai/</guid>
      <pubDate>Thu, 23 Jan 2025 17:50:02 GMT</pubDate>
    </item>
    <item>
      <title>å…³äºäº•å­—æ¸¸æˆä¸­çš„è´å°”æ›¼æ–¹ç¨‹ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i86uq1/about_bellman_equation_in_tic_tac_toe_game/</link>
      <description><![CDATA[ä¸€èˆ¬æ¥è¯´ï¼Œè´å°”æ›¼æ–¹ç¨‹æ˜¯ target_Q = Q(state, action) + gamma * Q(next_state, action) ä½†æ˜¯ï¼Œæˆ‘å¾ˆå¥½å¥‡æˆ‘ä»¬æ˜¯å¦åº”è¯¥ä½¿ç”¨ -gamma è€Œä¸æ˜¯ gammaï¼Œå› ä¸ºä¸‹ä¸€ä¸ªç©å®¶æ˜¯å¯¹æ‰‹ã€‚å¦‚æœæˆ‘ä»¬æ·»åŠ å…¶æœ€å¤§ q å€¼ï¼Œæˆ‘è®¤ä¸ºè¿™æ²¡æœ‰æ„ä¹‰ï¼Œå› ä¸ºæˆ‘ä»¬å°†å¯¹æ‰‹çš„æœ€å¤§ q å€¼æ·»åŠ åˆ°æ­¤å›åˆçš„ q å€¼ä¸­ã€‚  ä½†æˆ‘åœ¨äº’è”ç½‘ä¸Šæ‰¾åˆ°äº†å¾ˆå¤šä»£ç ï¼Œä»–ä»¬ä¼šä½¿ç”¨ target_Q = Q(state, action) + gamma * Q(next_state, action) è€Œä¸æ˜¯ target_Q = Q(state, action) - gamma * Q(next_state, action)ã€‚ä¸ºä»€ä¹ˆï¼Ÿ    æäº¤äºº    /u/Upstairs-Lead-2601   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i86uq1/about_bellman_equation_in_tic_tac_toe_game/</guid>
      <pubDate>Thu, 23 Jan 2025 16:09:51 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦æ— äººæœºæ¨¡æ‹Ÿç¯å¢ƒæ–¹é¢çš„å¸®åŠ©</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i820dg/need_some_help_with_simulation_environments_for/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘ç›®å‰æ­£åœ¨æ¨¡æ‹ŸåŸºäºè§†è§‰çš„ SLAM è®¾ç½®ï¼Œç”¨äºåœ¨ GPS æ‹’ç»ç¯å¢ƒä¸­æ¨¡æ‹Ÿ UAVã€‚è¿™æ„å‘³ç€æˆ‘è®¡åˆ’ä½¿ç”¨ä»…æ¥å—ä¸¤ä¸ªä¼ æ„Ÿå™¨è¾“å…¥çš„ SLAM ç®—æ³•ï¼šç›¸æœºå’Œ IMUã€‚æˆ‘éœ€è¦å¸®åŠ©ä¸ºè¿™ä¸ªé¡¹ç›®é€‰æ‹©æ­£ç¡®çš„æ¨¡æ‹Ÿç¯å¢ƒã€‚ç¯å¢ƒå¿…é¡»å…·æœ‰é€‚ç”¨äºç›¸æœºå’Œ IMU çš„è‰¯å¥½ä¼ æ„Ÿå™¨æ¨¡å‹ï¼Œå¹¶ä¸” 3D ä¸–ç•Œå¿…é¡»å°½å¯èƒ½æ¥è¿‘ç°å®ã€‚æˆ‘æ’é™¤äº†å¸¦æœ‰ UE4 è®¾ç½®çš„ Airsimï¼Œå› ä¸º Microsoft å·²å­˜æ¡£ Airsimï¼Œå¹¶ä¸”ä¸æ”¯æŒ UE5ã€‚å½“æˆ‘å°è¯• UE4 æ—¶ï¼Œæˆ‘æ‰¾ä¸åˆ°è¦å¯¼å…¥çš„ 3D ä¸–ç•Œï¼Œå› ä¸º UE å·²å‡çº§å…¶å¸‚åœºã€‚ ä»»ä½•æœ‰å…³æ¨¡æ‹Ÿç¯å¢ƒçš„å»ºè®®ä»¥åŠæ•™ç¨‹é“¾æ¥éƒ½å°†éå¸¸æœ‰å¸®åŠ©ï¼æ­¤å¤–ï¼Œå¦‚æœæœ‰äººçŸ¥é“å¦‚ä½•è®© UE4 é€‚ç”¨äºè¿™ç§åº”ç”¨ç¨‹åºï¼Œå³ä½¿æ˜¯è¿™æ ·ä¹Ÿæ¬¢è¿ï¼    æäº¤äºº    /u/techgeek1216   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i820dg/need_some_help_with_simulation_environments_for/</guid>
      <pubDate>Thu, 23 Jan 2025 12:15:38 GMT</pubDate>
    </item>
    <item>
      <title>æ°‘æ„è°ƒæŸ¥ï¼šè§†é¢‘æ¸¸æˆ RL çš„æœ€ä½³æ¡†æ¶ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7zxga/poll_best_frameworks_for_video_game_rl/</link>
      <description><![CDATA[å„ä½å¼ºåŒ–å­¦ä¹ è€å¸ˆä»¬ï¼Œå¤§å®¶å¥½ï¼æ‚¨çŸ¥é“æˆ–ä½¿ç”¨å“ªäº›å·¥å…·åœ¨ç°ä»£é—­æºè§†é¢‘æ¸¸æˆä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Ÿæˆ‘è¯´çš„å¼ºåŒ–å­¦ä¹ çº¯ç²¹æ˜¯ä»è§†é¢‘å¸§å¼€å§‹çš„ï¼Œæ— æ³•è®¿é—®å†…éƒ¨æ¸¸æˆçŠ¶æ€ã€‚æ‚¨æ˜¯å¦ä½¿ç”¨ä»»ä½•ç‰¹å®šçš„ç­–ç•¥å’Œç®—æ³•æ¥è§£å†³æ˜‚è´µä¸”ç¼“æ…¢çš„æ•°æ®æ”¶é›†é—®é¢˜ï¼Ÿæ˜¯å¦æœ‰ä»»ä½•ç‰¹å®šçš„æŠ€æœ¯é€‚ç”¨äº FPSã€ARPG ç­‰æ¸¸æˆç±»å‹ï¼Ÿå¦‚ä½•ä½¿ç”¨å¯¼èˆªèœå•å¤„ç†çº§åˆ«ä¹‹é—´çš„è§†è§‰å·®å¼‚ï¼Ÿç”¨äºæ¨¡æ‹Ÿæ¸¸æˆæ‰‹æŸ„å’Œé”®ç›˜çš„åº“ï¼Ÿ æˆ‘è®¤ä¸ºè¿™å¯¹äºä¸šä½™é¡¹ç›®æ¥è¯´æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„è¯é¢˜ï¼Œæˆ‘å·²ç»çœ‹åˆ°äº†ä¸€äº›ç›¸å…³çš„å¸–å­ã€‚å¯¹è¿™äº›æ–¹æ³•éå¸¸å¥½å¥‡ã€‚    æäº¤äºº    /u/mjolk   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7zxga/poll_best_frameworks_for_video_game_rl/</guid>
      <pubDate>Thu, 23 Jan 2025 09:51:08 GMT</pubDate>
    </item>
    <item>
      <title>ä¹è§‚çš„åˆå§‹å€¼å¦‚ä½•é¼“åŠ±æ¢ç´¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7xig0/how_do_optimistic_initial_values_encourage/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ï¼ˆæ›´æ–°çš„ï¼‰Sutton&amp;Barto çš„ä¹¦ã€‚ åœ¨ 2.6 ä¸­ï¼Œå®ƒè¯´åˆå§‹ä¼°è®¡ +5 è¿‡äºä¹è§‚ã€‚ä½†è¿™ç§ä¹è§‚é¼“åŠ±è¡ŒåŠ¨ä»·å€¼æ–¹æ³•è¿›è¡Œæ¢ç´¢....å³ä½¿ä¸€ç›´é€‰æ‹©è´ªå©ªåŠ¨ä½œï¼Œç³»ç»Ÿä¹Ÿä¼šè¿›è¡Œå¤§é‡æ¢ç´¢ è¿™æœ¬ä¹¦åªè®¨è®ºäº†ä¸€ä¸ªå¸¸æ•° epsilonï¼Œå…¶ä¸­ä»¥æ’å®šæ¦‚ç‡é€‰æ‹©éšæœºåŠ¨ä½œã€‚ æ‰€ä»¥ï¼Œæˆ‘ä¸å¤ªæ˜ç™½ä¹è§‚çš„ Q1 å€¼å’Œæ¢ç´¢ä¹‹é—´çš„å…³ç³»ã€‚æœ‰äººå¯ä»¥ç”¨ç®€å•çš„æœ¯è¯­è§£é‡Šä¸€ä¸‹å—ï¼Ÿ    æäº¤äºº    /u/datashri   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7xig0/how_do_optimistic_initial_values_encourage/</guid>
      <pubDate>Thu, 23 Jan 2025 06:44:25 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹äºå˜ˆæ‚è§‚å¯Ÿç¯å¢ƒæœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7rlhz/suggestions_for_noisy_observation_environments/</link>
      <description><![CDATA[å—¨ï¼Œæˆ‘æ­£åœ¨æ¢ç´¢å…·æœ‰å™ªå£°è§‚æµ‹çš„ RLã€‚æˆ‘åœ¨ OpenAI Gym Atari ä¸­å‘åƒç´ æ·»åŠ äº†é«˜æ–¯å™ªå£°ï¼Œä½†æ„Ÿè§‰å¤ªç®€å•äº†ã€‚ å¯¹ç¯å¢ƒæˆ–æ›´é€¼çœŸçš„å™ªå£°æ¨¡å‹æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿæœ‰å…³é«˜çº§å™ªå£°ï¼ˆä¾‹å¦‚é®æŒ¡ã€ç»“æ„åŒ–å™ªå£°ï¼‰æˆ–ç›¸å…³åŸºå‡†çš„æç¤ºå°†ä¸èƒœæ„Ÿæ¿€ã€‚è°¢è°¢ï¼    æäº¤äºº    /u/AdministrativeCar545   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7rlhz/suggestions_for_noisy_observation_environments/</guid>
      <pubDate>Thu, 23 Jan 2025 01:14:05 GMT</pubDate>
    </item>
    <item>
      <title>è¿™å°±æ˜¯â€œç³Ÿç³•â€çš„å¥–åŠ±å‡½æ•°</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7k3c9/this_is_what_a_bad_reward_function_looks_like/</link>
      <description><![CDATA[        ç”±    /u/goncalogordo   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7k3c9/this_is_what_a_bad_reward_function_looks_like/</guid>
      <pubDate>Wed, 22 Jan 2025 19:48:44 GMT</pubDate>
    </item>
    <item>
      <title>å…³äº RL ä»£ç†æ§åˆ¶å…¶ä»– RL ä»£ç†çš„é—®é¢˜</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7j9ck/question_about_rl_agents_controlling_other_rl/</link>
      <description><![CDATA[      å—¨ï¼Œæˆ‘æ˜¯å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„åˆå­¦è€…ï¼Œç›®å‰å¯¹åŸºäºç‰©ç†çš„è¿åŠ¨æ§åˆ¶æ„Ÿå…´è¶£ã€‚ å½“æˆ‘æŸ¥çœ‹å„ç§ä¼—æ‰€å‘¨çŸ¥çš„ç¯å¢ƒï¼ˆä¾‹å¦‚æœºæ¢°è‡‚ï¼‰æ—¶ï¼Œæˆ‘æƒ³åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³å¦‚ä½•å°è¯•åœ¨åŸºäºç‰©ç†çš„ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œæ¶‰åŠæ§åˆ¶æ­¤ç±»æ¨¡å‹ä»¥å®ç°æ¯”ç®€å•åœ°åˆ°è¾¾æŸä¸ªç›®çš„åœ°æ›´æŠ½è±¡çš„å¤æ‚ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥é—®é¢˜å‡ºç°åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œé—®é¢˜åœºæ™¯çš„å›¾åƒå¦‚ä¸‹æ‰€ç¤ºã€‚ https://preview.redd.it/wrvz16y7flee1.png?width=612&amp;format=png&amp;auto=webp&amp;s=5c24cb87a696247929aff41e8775833c617b9218 ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘è¦åˆ›å»ºä¸€ä¸ªç‰©ç†æ¨¡æ‹Ÿç¯å¢ƒï¼Œå…¶ä¸­æœºæ¢°è‡‚æ—¨åœ¨åœ¨çº¿ 3D è£…ç®±é—®é¢˜åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œå…¶ä¸­æœºæ¢°è‡‚ä»ä¼ é€å¸¦ä¸ŠæŠ“å–å„ç§å°ºå¯¸çš„ç›’å­å¹¶å°†å®ƒä»¬æ”¾ç½®åœ¨æŒ‡å®šä½ç½®ï¼Œå°è¯•åœ¨å—é™ç©ºé—´å†…å®¹çº³å°½å¯èƒ½å¤šçš„ç›’å­ã€‚ï¼ˆæˆ‘æƒ³æˆ‘å¯ä»¥å°†å¥–åŠ±å»ºæ¨¡ä¸ºä¸æ”¾ç½®çš„ç›’å­å‡¸åŒ…çš„ä½“ç§¯ç›¸å…³ï¼Ÿï¼‰ æˆ‘å¯ä»¥æƒ³è±¡ï¼Œé‡‡ç”¨ä¸åŒä»£ç†çš„å¤šå±‚æ–¹æ³•å¯èƒ½ä¼šå……åˆ†å‘æŒ¥ä½œç”¨ï¼Œä¸€ä¸ªç”¨äºè§£å†³ 3D-BPP é—®é¢˜ï¼Œä¸€ä¸ªç”¨äºæ§åˆ¶æœºæ¢°è‡‚çš„å„ä¸ªç”µæœºä»¥å°†ç›’å­ç§»åŠ¨åˆ°æŸä¸ªä½ç½®ï¼Œä»¥ä¾¿ 3D-BPP æ±‚è§£å™¨çš„è¾“å‡ºå¯ä»¥ä½œä¸ºæœºæ¢°è‡‚æ§åˆ¶å™¨ä»£ç†çš„è¾“å…¥ã€‚ä½†æ˜¯ï¼Œæˆ‘æ— æ³•æƒ³è±¡è¿™ä¸¤ä¸ªä»£ç†ä¼šå®Œå…¨è§£è€¦ï¼Œå› ä¸º 3D-BPP æ±‚è§£å™¨çš„æŸäº›å‘½ä»¤å¯èƒ½åœ¨ç‰©ç†ä¸Šä¸é€‚åˆæœºæ¢°è‡‚çš„ç§»åŠ¨ï¼Œè€Œä¸ä¼šç ´åå…ˆå‰æ”¾ç½®çš„ç›’å­ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘æƒ³çŸ¥é“é€šå¸¸çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼š  ä½¿ç”¨å•ä¸ªä»£ç†èƒ½å¤Ÿç‹¬è‡ªæ§åˆ¶è¿™äº›çœ‹ä¼¼ä¸åŒçš„ä»»åŠ¡ï¼ˆæ±‚è§£ 3d-bpp å’Œæ§åˆ¶æœºæ¢°è‡‚ï¼‰ï¼Ÿ å®é™…ä¸Šä½¿ç”¨ä¸¤ä¸ªä»£ç†å¹¶åœ¨è®­ç»ƒåºåˆ—ä¸­å¼•å…¥ä¸€äº›å¤æ‚æ€§ï¼Œä»¥ä¾¿æ±‚è§£å™¨å¯ä»¥è€ƒè™‘æœºæ¢°è‡‚æ§åˆ¶å™¨çš„è¿åŠ¨ï¼Ÿ  å¦‚æœè¿™æ˜¯ä¸€ä¸ªå¾®ä¸è¶³é“çš„é—®é¢˜ï¼Œä»»ä½•æˆ‘å¯ä»¥é˜…è¯»çš„é€‚åˆåˆå­¦è€…çš„æ–‡çŒ®é“¾æ¥éƒ½å°†ä¸èƒœæ„Ÿæ¿€ï¼    æäº¤äºº    /u/RulerOfCakes   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7j9ck/question_about_rl_agents_controlling_other_rl/</guid>
      <pubDate>Wed, 22 Jan 2025 19:15:47 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é—®é¢˜/è§£å†³æ–¹æ¡ˆå‚è€ƒæŒ‡å—</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7hpnm/a_problemsolution_reference_guide_for_rl/</link>
      <description><![CDATA[åœ¨å­¦ä¹  RL è¯¾ç¨‹æ—¶ï¼Œæˆ‘ä¸ºå‡ ç§ç®—æ³•åˆ›å»ºäº†ä¸€ä¸ªå‚è€ƒï¼Œå¹¶ç®€è¦æè¿°äº†å®ƒä»¬è§£å†³äº†å“ªäº›é™åˆ¶ã€‚ç¤ºä¾‹ï¼š é—®é¢˜ï¼šSARSA å°† q å€¼æ¨å‘å½“å‰ç­–ç•¥ï¼Œä½†ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³è¦çš„æ˜¯æœ€ä¼˜å€¼ã€‚ è§£å†³æ–¹æ¡ˆï¼šåœ¨ TD ç›®æ ‡è®¡ç®—ä¸­ä½¿ç”¨æœ€ä½³æ“ä½œ -&gt; Q å­¦ä¹  ä¹Ÿè®¸å…¶ä»–äººä¼šå‘ç°å®ƒå¾ˆæœ‰ç”¨ï¼å¯åœ¨ https://jakubhalmes.substack.com/p/reinforcement-learning-a-reference è·å¾—    æäº¤äºº    /u/jac08_h   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7hpnm/a_problemsolution_reference_guide_for_rl/</guid>
      <pubDate>Wed, 22 Jan 2025 18:14:36 GMT</pubDate>
    </item>
    <item>
      <title>ç¼©çŸ­ REINFORCE çš„æœŸé™</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7h25q/shortening_the_horizon_in_reinforce/</link>
      <description><![CDATA[å¤§å®¶å¥½ã€‚æˆ‘æ­£åœ¨ç ”ç©¶å¯¹å…·æœ‰åŠ¨æ€çŠ¶æ€ï¼ˆç”Ÿæˆçš„çŠ¶æ€æ˜¯é’ˆå¯¹å…ˆå‰çŠ¶æ€é‡‡å–è¡ŒåŠ¨çš„ç»“æœï¼‰çš„å»ºç­‘ç‰©è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¹¶ä¸”æˆ‘æ­£åœ¨ä½¿ç”¨çº¯ REINFORCE ç®—æ³•å¹¶å­˜å‚¨ï¼ˆsã€aã€rï¼‰è½¬æ¢ã€‚å¦‚æœæˆ‘æƒ³å°†ä¸€ä¸ªæ—¶æœŸåˆ†æˆå‡ ä¸ªæƒ…èŠ‚ï¼Œæ¯”å¦‚ 10 ä¸ªæƒ…èŠ‚ï¼Œï¼ˆå…ˆå‰ï¼šä¸€æ¬¡è¿è¡Œ 4000 ä¸ªæ—¶é—´æ­¥ï¼Œç„¶åå‚æ•°æ›´æ–° --&gt;ç°åœ¨ï¼š400 ä¸ªæ—¶é—´æ­¥ï¼Œæ›´æ–°ï¼Œå¦ä¸€ä¸ª 400 ä¸ªæ—¶é—´æ­¥ï¼Œæ›´æ–°...ï¼‰ï¼Œé™¤äº†æ›´æ”¹å­˜å‚¨è½¬æ¢æ“ä½œå’Œå­¦ä¹ å‡½æ•°çš„ä½ç½®å¤–ï¼Œæˆ‘è¿˜åº”è¯¥æ³¨æ„å“ªäº›äº‹æƒ…æ‰èƒ½æ­£ç¡®è¿›è¡Œæ­¤æ›´æ”¹ï¼Ÿæ‚¨èƒ½å‘Šè¯‰æˆ‘å¯ä»¥å­¦ä¹ çš„ä»»ä½•æ¥æºå—ï¼Ÿè°¢è°¢ã€‚ï¼ˆæˆ‘çš„ NN æ¡†æ¶åœ¨ Tensorflow 1.10 ä¸­ï¼‰ã€‚    æäº¤äºº    /u/Araf_fml   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7h25q/shortening_the_horizon_in_reinforce/</guid>
      <pubDate>Wed, 22 Jan 2025 17:48:30 GMT</pubDate>
    </item>
    <item>
      <title>ç¡•å£«å­¦ä½å†³å®š</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7eiqz/masters_degree_decision/</link>
      <description><![CDATA[å¦‚æœæˆ‘æœ‰å…´è¶£æ·±å…¥äº†è§£å¼ºåŒ–å­¦ä¹ ï¼Œæœ‰äººèƒ½å‘Šè¯‰æˆ‘åœ¨æ¬§æ´²å“ªé‡Œæ”»è¯»ç¡•å£«å­¦ä½ä¼šæ›´æœ‰ç›Šå—ï¼Ÿ    æäº¤äºº    /u/Ok-Engineering4612   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7eiqz/masters_degree_decision/</guid>
      <pubDate>Wed, 22 Jan 2025 16:04:45 GMT</pubDate>
    </item>
    <item>
      <title>TD3 å¥–åŠ±ä¸ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå¢åŠ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7cxi6/td3_reward_not_increasing_over_time/</link>
      <description><![CDATA[      å˜¿ï¼Œå¯¹äºä¸€ä¸ªå¤§å­¦é¡¹ç›®ï¼Œæˆ‘å·²ç»å®ç°äº† td3ï¼Œå¹¶å°è¯•åœ¨ä½¿ç”¨åˆ†é…çš„ç¯å¢ƒä¹‹å‰åœ¨ pendulum v1 ä¸Šå¯¹å…¶è¿›è¡Œæµ‹è¯•ã€‚ è¿™æ˜¯æˆ‘çš„è¶…å‚æ•°åˆ—è¡¨ï¼š  &quot;actor_lr&quot;: 0.0001, &quot;critic_lr&quot;: 0.0001, &quot;discount&quot;: 0.95, &quot;tau&quot;: 0.005, &quot;batch_size&quot;: 128, &quot;hidden_â€‹â€‹dim_critic&quot;: [256, 256], &quot;hidden_â€‹â€‹dim_actor&quot;: [256, 256], &quot;noise&quot;: &quot;Gaussian&quot;, &quot;noise_clip&quot;: 0.3, &quot;noise_std&quot;: 0.2, &quot;policy_update_freq&quot;: 2, &quot;buffer_size&quot;: int(1e6),  æˆ‘é¢ä¸´çš„é—®é¢˜æ˜¯å¥–åŠ±éšç€æ—¶é—´çš„æ¨ç§»ä¸æ–­å‡å°‘ï¼Œå¹¶ä¸”è¾¾åˆ°é¥±å’Œåœ¨ä¸€äº›å‰§é›†ä¹‹åï¼Œå¤§çº¦åœ¨ -1450 å·¦å³ã€‚æœ‰äººçŸ¥é“æˆ‘çš„é—®é¢˜å¯èƒ½å‡ºåœ¨å“ªé‡Œå—ï¼Ÿ å¦‚æœéœ€è¦ï¼Œæˆ‘è¿˜å¯ä»¥æä¾›æ‚¨æ€€ç–‘å¯èƒ½æœ‰é”™è¯¯çš„ä»»ä½•ä»£ç  éšç€æ—¶é—´çš„æµé€å¥–åŠ± æå‰æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼    æäº¤äºº    /u/bela_u   [é“¾æ¥] [è¯„è®º] ]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7cxi6/td3_reward_not_increasing_over_time/</guid>
      <pubDate>Wed, 22 Jan 2025 14:57:18 GMT</pubDate>
    </item>
    <item>
      <title>æ¨é€ä»»åŠ¡æœªå­¦ä¹ </title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1i7717b/pusher_task_not_learning/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åœ¨ mujoco æ¨é€å™¨ç¯å¢ƒä¸­è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½†å®ƒä¸èµ·ä½œç”¨ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä» mujoco github repo è·å¾—äº†æ¨é€å™¨ç±»å¹¶åšäº†ä¸€äº›å°æ”¹åŠ¨ã€‚æˆ‘è¯•å›¾å®ç°çš„æ˜¯è®©æ¨é€å™¨å°† 3 ä¸ªå¯¹è±¡æ¨é€åˆ° 3 ä¸ªä¸åŒçš„ç›®æ ‡ã€‚è¿™äº›å¯¹è±¡ä¸€æ¬¡å‡ºç°ä¸€ä¸ªï¼Œæ‰€ä»¥å½“ç¬¬ä¸€ä¸ªå¯¹è±¡è¢«æ¨é€åˆ°ç›®æ ‡æ—¶ï¼Œç¬¬äºŒä¸ªå¯¹è±¡å°±ä¼šå‡ºç°ï¼Œä¾æ­¤ç±»æ¨ã€‚æ‰€ä»¥æˆ‘å¯¹ mujoco æä¾›çš„ç±»åšçš„å”¯ä¸€ä¿®æ”¹æ˜¯æˆ‘æ·»åŠ äº†åœ¨è§†å›¾ä¸­æ›´æ”¹è¦æ¨é€å¯¹è±¡çš„æœºåˆ¶ã€‚æˆ‘å°è¯•äº† PPO å’Œ SACï¼Œæ—¶é—´æ­¥é•¿ä¸º 100 ä¸‡ï¼Œå¥–åŠ±ä»ç„¶ä¸ºè´Ÿã€‚è¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ï¼Œä½†å®ƒä¸èµ·ä½œç”¨    æäº¤äºº    /u/Latinotech   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1i7717b/pusher_task_not_learning/</guid>
      <pubDate>Wed, 22 Jan 2025 09:01:57 GMT</pubDate>
    </item>
    </channel>
</rss>