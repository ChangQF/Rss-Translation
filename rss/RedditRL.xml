<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Tue, 16 Jan 2024 03:16:09 GMT</lastBuildDate>
    <item>
      <title>SB3 çš„éšæœºå¯åŠ¨çŠ¶æ€</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197nwq0/random_start_state_with_sb3/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ SB3 çš„ DDPGï¼Œä½†åœ¨å­¦ä¹ æ—¶æ— æ³•åŠ è½½å…·æœ‰ä¸åŒå¯åŠ¨çŠ¶æ€çš„æ–‡ä»¶ã€‚æˆ‘æ¯æ¬¡éƒ½å°è¯•åœ¨é‡ç½®æ–¹æ³•ä¸­æ›´æ”¹å®ƒã€‚æˆ‘çš„çŒœæµ‹æ˜¯è®­ç»ƒé»‘é¬¼åªå‘ç”Ÿåœ¨ä¸€ä¸ªæƒ…èŠ‚ä¸­ï¼Œå› ä¸ºæ²¡æœ‰è°ƒç”¨é‡ç½®æ–¹æ³•ï¼Œæ‰€ä»¥æ²¡æœ‰å˜åŒ–ã€‚ä¹Ÿç”¨ PPO å°è¯•è¿‡ã€‚å¦å¤–ï¼Œæˆ‘å¦‚ä½•æ§åˆ¶è®­ç»ƒæ¬¡æ•°å’Œæ—¶é—´æ­¥é•¿ï¼Ÿ åœ¨ç½‘ä¸Šæœç´¢çš„ç»³ç´¢ç»“æŸğŸ™‚   ç”±   æäº¤/u/Sadboi1010   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197nwq0/random_start_state_with_sb3/</guid>
      <pubDate>Mon, 15 Jan 2024 23:44:37 GMT</pubDate>
    </item>
    <item>
      <title>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼šç»¼åˆè°ƒæŸ¥</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197lq1j/multiagent_reinforcement_learning_a_comprehensive/</link>
      <description><![CDATA[è®ºæ–‡ï¼šhttps:// arxiv.org/abs/2312.10256 æ‘˜è¦ï¼š  å¤šä»£ç†åº”ç”¨ç¨‹åºçš„æµè¡ŒéåŠæˆ‘ä»¬çš„å„ç§äº’è¿ç³»ç»Ÿæ—¥å¸¸ç”Ÿæ´»ã€‚å°½ç®¡å®ƒä»¬æ— å¤„ä¸åœ¨ï¼Œä½†åœ¨å…±äº«ç¯å¢ƒä¸­é›†æˆå’Œå¼€å‘æ™ºèƒ½å†³ç­–ä»£ç†å¯¹å…¶æœ‰æ•ˆå®æ–½æå‡ºäº†æŒ‘æˆ˜ã€‚è¿™é¡¹è°ƒæŸ¥æ·±å…¥ç ”ç©¶äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (MAS) é¢†åŸŸï¼Œç‰¹åˆ«å¼ºè°ƒé˜æ˜ MAS æ¡†æ¶å†…å­¦ä¹ æœ€ä¼˜æ§åˆ¶çš„å¤æ‚æ€§ï¼Œé€šå¸¸ç§°ä¸ºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL)ã€‚æœ¬æ¬¡è°ƒæŸ¥çš„ç›®çš„æ˜¯æä¾›å¯¹ MAS å„ä¸ªæ–¹é¢çš„å…¨é¢è§è§£ï¼Œæ­ç¤ºæ— æ•°æœºä¼šï¼ŒåŒæ—¶å¼ºè°ƒå¤šä»£ç†åº”ç”¨ç¨‹åºæ‰€é¢ä¸´çš„å›ºæœ‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¸Œæœ›ä¸ä»…æœ‰åŠ©äºæ›´æ·±å…¥åœ°äº†è§£ MAS æ™¯è§‚ï¼Œè€Œä¸”è¿˜ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›æœ‰ä»·å€¼çš„è§‚ç‚¹ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ MAS çš„åŠ¨æ€é¢†åŸŸå†…ä¿ƒè¿›çŸ¥æƒ…æ¢ç´¢å¹¶ä¿ƒè¿›å‘å±•ï¼Œè®¤è¯†åˆ°åœ¨è§£å†³ MARL ä¸­å‡ºç°çš„å¤æ‚æ€§æ–¹é¢éœ€è¦é€‚åº”æ€§ç­–ç•¥å’ŒæŒç»­å‘å±•ã€‚    ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197lq1j/multiagent_reinforcement_learning_a_comprehensive/</guid>
      <pubDate>Mon, 15 Jan 2024 22:15:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] æ‚¨å¯¹å¼ºåŒ–å­¦ä¹ çš„çœŸå®ä½“éªŒæ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197kl7z/d_what_is_your_honest_experience_with/</link>
      <description><![CDATA[ ç”±   æäº¤ /u/Smallpaul   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197kl7z/d_what_is_your_honest_experience_with/</guid>
      <pubDate>Mon, 15 Jan 2024 21:31:30 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦å¸®åŠ© - æ£€æŸ¥è¾“å…¥æ—¶å‡ºé”™ï¼šé¢„æœŸ flatten_input æœ‰ 3 ä¸ªç»´åº¦ï¼Œä½†å¾—åˆ°å½¢çŠ¶ä¸º (4, 1) çš„æ•°ç»„</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197f70n/need_help_error_when_checking_input_expected/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197f70n/need_help_error_when_checking_input_expected/</guid>
      <pubDate>Mon, 15 Jan 2024 18:02:27 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘çš„ AIRL æ— æ³•æ­£å¸¸å·¥ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1978gsl/my_airl_is_not_working/</link>
      <description><![CDATA[ä¸“å®¶è½¨è¿¹çš„æ¦‚ç‡åœ¨å¢åŠ ï¼Œè€Œç­–ç•¥ç”Ÿæˆçš„è½¨è¿¹åœ¨å‡å°‘ï¼Œä½†ç­–ç•¥æ— æ³•ä»æ¨æ–­çš„å¥–åŠ±å‡½æ•°ä¸­å­¦ä¹ ã€‚   ç”±   æäº¤/u/Professional_Card176   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1978gsl/my_airl_is_not_working/</guid>
      <pubDate>Mon, 15 Jan 2024 13:15:28 GMT</pubDate>
    </item>
    <item>
      <title>ç´¯ç§¯å¥–åŠ±æ›²çº¿å¹³æ»‘</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196svan/cumulative_reward_curve_smooth/</link>
      <description><![CDATA[å—¨ï¼Œ æˆ‘æ­£åœ¨å¤šç»´ç¦»æ•£åŠ¨ä½œå’Œè§‚å¯Ÿç©ºé—´ä¸Šè¿è¡Œ A2Cã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘æ­£åœ¨è®¡ç®—è¿è¡Œå‡å€¼å’Œæ–¹å·®ä»¥æ ‡å‡†åŒ–æˆ‘çš„å¥–åŠ±ã€‚æˆ‘çš„å¥–åŠ±è®¡ç®—æ˜¯éšæœºçš„ï¼Œå› ä¸ºæœ‰éœ€æ±‚è¢«å®ç°ã€‚åœ¨è¯„ä¼°æˆ‘å­¦åˆ°çš„æ”¿ç­–æ—¶ï¼Œæˆ‘å‘ç°æ— è®ºç»™å‡ºä»€ä¹ˆè§‚å¯Ÿï¼Œéƒ½æ˜¯ç›¸åŒçš„è¡ŒåŠ¨ã€‚æˆ‘ç»˜åˆ¶äº†ç´¯ç§¯å¥–åŠ±ï¼Œå®ƒçœ‹èµ·æ¥éå¸¸å¹³æ»‘çš„çº¿æ€§ã€‚æˆ‘æƒ³çŸ¥é“è¿™æ˜¯å¦æ˜¯é¢„æœŸçš„è¡Œä¸ºï¼Ÿæˆ‘æ‰“å°å‡ºäº†é€æ­¥å¥–åŠ±ï¼Œå®ƒç¡®å®å¹¶ä¸æ€»æ˜¯ 1ï¼Œåœ¨ [-1,1] ä¹‹é—´æ³¢åŠ¨ï¼ˆå¤§éƒ¨åˆ†ï¼‰ã€‚è°¢è°¢ï¼   ç”±   æäº¤ /u/polymerase2   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196svan/cumulative_reward_curve_smooth/</guid>
      <pubDate>Sun, 14 Jan 2024 22:54:41 GMT</pubDate>
    </item>
    <item>
      <title>å¥–åŠ±ç¨€ç–ï¼Œå‰§é›†é•¿åº¦é•¿ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196rt1n/sparse_reward_with_long_episode_length/</link>
      <description><![CDATA[å—¨ï¼æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨ PPO ç®—æ³•æ‰¾åˆ°ä¸€ä¸ªå¥½çš„ç­–ç•¥æ¥ä¼˜åŒ–æœ¬åœ°æœç´¢å¯å‘å¼ä¸­çš„å‚æ•°ã€‚æŒ‘æˆ˜åœ¨äºæˆ‘åªèƒ½åœ¨æ¯é›†ç»“æŸæ—¶è¯„ä¼°ç­–ç•¥çš„æ€§èƒ½ï¼Œå…¶ä¸­æä¾› [0,1] èŒƒå›´å†…çš„ç¨€ç–å¥–åŠ±ã€‚å‰§é›†é•¿åº¦å›ºå®šä¸º 1000 æ­¥ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯å¦æœ‰æœºä¼šå­¦ä¹ æˆåŠŸçš„æ”¿ç­–ï¼Ÿåˆ°ç›®å‰ä¸ºæ­¢ï¼Œå³ä½¿é‡‡ç”¨éå¸¸ç®€å•çš„è§‚å¯Ÿç»“æ„ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å–å¾—ä»»ä½•ç§¯æçš„æˆæœã€‚ä¹Ÿè®¸æˆ‘å¯ä»¥å°è¯•ä¸€äº›æŠ€å·§ã€‚é¢„å…ˆæ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼   ç”±   æäº¤ /u/OpportunityHot7289   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196rt1n/sparse_reward_with_long_episode_length/</guid>
      <pubDate>Sun, 14 Jan 2024 22:10:28 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196idl8/reinforcement_learning_for_optimization/</link>
      <description><![CDATA[æœ‰æ²¡æœ‰äººå°è¯•ä½¿ç”¨ RL æ¥è§£å†³ä¼˜åŒ–é—®é¢˜ï¼Œä¾‹å¦‚æ—…è¡Œå•†é—®é¢˜æˆ–ç±»ä¼¼é—®é¢˜ï¼Œæˆ‘æ£€æŸ¥äº†å‡ ç¯‡ä»–ä»¬ä½¿ç”¨ DQN çš„è®ºæ–‡ï¼Œä½†åœ¨å®é™…å®ç°åæˆ‘è¿˜æ²¡æœ‰å³ä½¿å¯¹äºç®€å•çš„é—®é¢˜ï¼Œä¾‹å¦‚å°†ç›’å­ä»è¿·å®«çš„ä¸€ç«¯ç§»åˆ°å¦ä¸€ç«¯ï¼Œä¹Ÿæ²¡æœ‰å¾—åˆ°ä»»ä½•å®é™…çš„ç»“æœã€‚æˆ‘è¿˜æ‹…å¿ƒåŸºäº DQN çš„è§£å†³æ–¹æ¡ˆèƒ½å¦åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ã€‚æ¬¢è¿æå‡ºä»»ä½•å»ºè®®ã€‚   ç”±   æäº¤ /u/HSaurabh   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196idl8/reinforcement_learning_for_optimization/</guid>
      <pubDate>Sun, 14 Jan 2024 15:29:51 GMT</pubDate>
    </item>
    <item>
      <title>[éœ€è¦å»ºè®®/åé¦ˆ] è®­ç»ƒæ—¶ DQN æ³¢åŠ¨å¾ˆå¤§ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196eref/need_advicefeedback_dqn_strongly_fluctuates_when/</link>
      <description><![CDATA[      å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ RL æ–°æ‰‹ï¼Œæƒ³ç”¨ DDQN åšç‚¹ä»€ä¹ˆã€‚æˆ‘ä»è¿™ä¸ª PyTorch ç½‘ç«™ æ‰¾åˆ°äº†è¿™ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ DQN ç© CartPole çš„æ–‡ç« ã€‚æˆ‘å°è¯•é‡‡ç”¨æ­¤ä»£ç ï¼Œä½†å°†æ¸¸æˆæ›´æ”¹ä¸º BreakOutï¼ˆæ›´å…·ä½“åœ°è¯´ï¼ŒBreakOutv5 {frame_skip = 4ï¼Œrepeat_action = 0.25ï¼‰ï¼‰ã€‚  æˆ‘å¯¹åŸå§‹ä»£ç æ‰€åšçš„æ›´æ”¹æ˜¯é€šè¿‡ GreyScaleã€Croppingã€Resize å’Œ FrameStack å¯¹ç¯å¢ƒè¿›è¡Œé¢„å¤„ç†ã€‚ def Observation_preproc(frame):cropped_frame = frame[ 35:195, 7:153]/255 returncropped_frame STACK_NUM= 4 RESIZE_HEIGHT= 84 RESIZE_WIDTH= 84 # åˆ¶ä½œæ¸¸æˆç¯å¢ƒ env=gym.make(&quot;ALE/Breakout-v5&quot;, render_mode=&#39;rgb_array&#39;) env=gym. wrappers.GrayScaleObservationï¼ˆenvï¼‰env=gym.wrappers.TransformObservationï¼ˆenvï¼Œobservation_preprocï¼‰env=gym.wrappers.ResizeObservationï¼ˆenvï¼Œï¼ˆRESIZE_HEIGHTï¼ŒRESIZE_WIDTHï¼‰ï¼‰env=gym.wrappers.FrameStackï¼ˆenvï¼ŒSTACK_NUMï¼‰  æˆ‘è¿˜ç”¨å·ç§¯å±‚é‡æ–°æ„å»ºäº† DDQN æ¨¡å‹ class DQN(nn.Module): def __init__(self, n_stack, n_actions): super(DQN, self).__init__() self.conv_layer1= nn.Sequential( nn.Conv2d(in_channels= n_stack, out_channels= 32, kernel_size= 8, stride= 4), nn.ReLU(inplace= True) ) self.conv_layer2= nn.é¡ºåº( nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size= 4, stride= 2), nn.ReLU(inplace= True) ) self.conv_layer3= nn.Sequential( nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size= 3, stride= 1), nn.ReLU(inplace= True) ) self.relu= nn.ReLU(inplace= True) self.flatten= nn.Flatten() self.layer1= nn.Linear(7 *7*64, 512) self.layer2= nn.Linear(512, n_actions) defforward(self, x): x= self.conv_layer1(x) x= self.conv_layer2(x) x= self.conv_layer3(x ) x= self.flatten(x) x= self.relu(self.layer1(x)) x= self.layer2(x)  æˆ‘è®¡åˆ’è®­ç»ƒå®ƒä¸€ç™¾ä¸‡é›†ä½†åœ¨å¤§çº¦3000é›†æ—¶ï¼Œæˆ‘æ³¨æ„åˆ°ï¼š  è®­ç»ƒé›†å¥–åŠ±å’ŒæŒç»­æ—¶é—´å›¾ã€‚ å­¦ä¹ è¿‡ç¨‹é¢ä¸´ä¸€äº›å¼ºçƒˆçš„æ³¢åŠ¨ã€‚ â€‹ æˆ‘çš„é—®é¢˜æ˜¯ï¼šè¿™ç§ç°è±¡å«ä»€ä¹ˆï¼Ÿä½ è®¤ä¸ºæˆ‘æ€æ ·æ‰èƒ½é˜»æ­¢å®ƒï¼Ÿæˆ‘çŸ¥é“ DQN å·²ç»è¿‡æ—¶äº†ï¼Œä½†æ˜¯æˆ‘æ­£åœ¨ä¸€æ­¥æ­¥å­¦ä¹ ï¼ˆå¦å¤–ï¼Œåœ¨è¿™ä¸ª DeepMindè®ºæ–‡ï¼Œä»–ä»¬çš„DQNå¾—åˆ†æ¯”æˆ‘é«˜:)))) å¦‚æœä½ æƒ³é˜…è¯»æˆ‘çš„æ•´ä¸ªç¬”è®°æœ¬ï¼Œè¿™é‡Œæœ‰ç›´æ¥çš„Github é“¾æ¥ï¼Œè¯·çœ‹ä¸€ä¸‹:)  è°¢è°¢å¤§å®¶ &lt; /div&gt;  ç”±   æäº¤/u/Q_H_Chu  [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196eref/need_advicefeedback_dqn_strongly_fluctuates_when/</guid>
      <pubDate>Sun, 14 Jan 2024 12:24:28 GMT</pubDate>
    </item>
    <item>
      <title>å‡å°‘è¿­ä»£æ¬¡æ•°æˆ–å…¶ä»–æ–¹æ³•</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196dxse/reduce_number_of_iterations_or_other_methods/</link>
      <description><![CDATA[å˜¿ï¼Œ â€‹ æˆ‘ç›®å‰æ­£åœ¨å†™æˆ‘çš„ç¡•å£«è®ºæ–‡ï¼Œæ¶‰åŠå¼ºåŒ–å­¦ä¹ åœ¨ä»£ç ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚æˆ‘çš„é‡ç‚¹æ˜¯æ–°å¼€å‘çš„é¢†åŸŸç‰¹å®šè¯­è¨€ (DSL)ï¼Œå®ƒçš„å¯ç”¨ç¤ºä¾‹æœ‰é™ï¼Œå› ä¸ºè¿˜æ²¡æœ‰ç”¨è¿™ç§è¯­è¨€ç¼–å†™çš„åŠŸèƒ½ç¨‹åºçš„å¹¿æ³›æ•°æ®åº“ã€‚ æˆ‘çš„ç›®æ ‡æ˜¯è®­ç»ƒèƒ½å¤Ÿåœ¨è¿™ä¸ªæ–°çš„ DSL ä¸­ç¼–å†™ä»£ç çš„æ¨¡å‹ã€‚å¯¹äºç¯å¢ƒï¼Œæˆ‘æœ‰èƒ½åŠ›æ‰§è¡Œä»£ç ä»¥ç¡®å®šå®ƒæ˜¯å¦äº§ç”Ÿé¢„æœŸçš„è¾“å‡ºã€‚ç›®å‰ï¼Œæˆ‘çš„æ–¹æ³•åŒ…æ‹¬éšæœºé€‰æ‹© 1 åˆ° 200 ä¸ªæ“ä½œæ¥éªŒè¯æ¯æ¬¡è¿­ä»£ä¸­ç”Ÿæˆçš„ä»£ç æ˜¯å¦æ­£ç¡®ã€‚ç„¶è€Œï¼Œäº‹å®è¯æ˜è¿™ç§æ–¹æ³•éå¸¸è€—æ—¶ã€‚ æ‚¨èƒ½å¦å»ºè®®æˆ‘ä¸€ç§å‡å°‘è¿­ä»£æ¬¡æ•°çš„æ–¹æ³•ï¼Ÿä»»ä½•è§è§£æˆ–å»ºè®®å°†ä¸èƒœæ„Ÿæ¿€ã€‚ â€‹ è°¢è°¢ï¼   ç”±   æäº¤/u/mim549276  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196dxse/reduce_number_of_iterations_or_other_methods/</guid>
      <pubDate>Sun, 14 Jan 2024 11:32:34 GMT</pubDate>
    </item>
    <item>
      <title>å¥‡æ€ªçš„è¡Œä¸º</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196boz1/strange_behaviour/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ Q å­¦ä¹ å¼€å‘å‰ªåˆ€çŸ³å¤´å¸ƒä»£ç† - https://github.com/revyu/RPS .åœ¨ç©mrugeshæ—¶æ²¡æœ‰ä»»ä½•é—®é¢˜ï¼Œå®ƒçš„èƒœç‡ç›¸å½“ç¨³å®šï¼Œä½†åœ¨krisä¸Šå®ƒç©å¾—å¾ˆç³Ÿç³•ã€‚å®ƒå¯ä»¥ç© {&#39;player&#39;: 400, &#39;opponent&#39;: 201, &#39;tie&#39;: 399}, winrate=0.400000 æˆ– {&#39;player&#39;: 0, &#39;opponent&#39;: 1000, &#39;tie&#39;: 0}, winrate=0.000000 ï¼Œæ²¡æœ‰ä¸­é—´ç»“æœã€‚æˆ‘å¯¹æœºå™¨å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ è¿˜å¾ˆé™Œç”Ÿï¼Œæ— æ³•ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆã€‚æœ€è®©æˆ‘æƒŠè®¶çš„ä¸æ˜¯ç®—æ³•è¡¨ç°ä¸ä½³ï¼Œè€Œæ˜¯å®ƒçš„ç»“æœæ­£å¥½ä½äºå½¼æ­¤ç›¸è·å¾ˆè¿œçš„ä¸¤ä¸ªç‚¹ä¸Šã€‚   ç”±   æäº¤ /u/revyakin   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196boz1/strange_behaviour/</guid>
      <pubDate>Sun, 14 Jan 2024 08:59:46 GMT</pubDate>
    </item>
    <item>
      <title>â€œæ½œä¼ç‰¹å·¥ï¼šé€šè¿‡å®‰å…¨åŸ¹è®­æŒç»­å­˜åœ¨çš„è®­ç»ƒæ¬ºéª—æ€§æ³•å­¦ç¡•å£«â€ï¼ŒHubinger ç­‰äºº 2024 {Anthropic}ï¼ˆRLHF å’Œå¯¹æŠ—æ€§è®­ç»ƒæœªèƒ½æ¶ˆé™¤æ³•å­¦ç¡•å£«ä¸­çš„åé—¨ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/195x2tw/sleeper_agents_training_deceptive_llms_that/</link>
      <description><![CDATA[ ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/195x2tw/sleeper_agents_training_deceptive_llms_that/</guid>
      <pubDate>Sat, 13 Jan 2024 20:17:21 GMT</pubDate>
    </item>
    <item>
      <title>â€œè¯­è¨€æ¨¡å‹å¯ä»¥è§£å†³è®¡ç®—æœºä»»åŠ¡â€ï¼ŒKim ç­‰äºº 2023ï¼ˆMiniWoB++ çš„å†…å¿ƒç‹¬ç™½ï¼‰</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/195v9nt/language_models_can_solve_computer_tasks_kim_et/</link>
      <description><![CDATA[ ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/195v9nt/language_models_can_solve_computer_tasks_kim_et/</guid>
      <pubDate>Sat, 13 Jan 2024 19:00:04 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ è‡ªå­¦</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/195l81f/reinforcement_learning_self_taught/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘æƒ³è¿›å…¥å¼ºåŒ–å­¦ä¹ ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹ï¼Œå› æ­¤æˆ‘æƒ³é—®ä¸€ä¸‹å¦‚æœæœ‰äººå¯¹ä»å“ªé‡Œå¼€å§‹æœ‰ä»»ä½•å»ºè®®ï¼Œå¹¶ä¸”å¯èƒ½æœ‰ä¸€äº›èµ„æºæ¥è¿™æ ·åšã€‚æˆ‘æ˜¯ä¸€å STEM ä¸“ä¸šçš„å¤§å­¦ç”Ÿï¼Œæ‹¥æœ‰ Python ç»éªŒï¼Œæƒ³å¼€å§‹æ·±å…¥ç ”ç©¶å¼ºåŒ–å­¦ä¹ ï¼Œå› ä¸ºå®ƒçœ‹èµ·æ¥éå¸¸æœ‰è¶£ä¸”å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘å¾ˆæƒ³å¬å¬æ‚¨æ˜¯å¦‚ä½•å­¦ä¹ çš„ï¼Œä»¥åŠå…³äºæˆ‘å¦‚ä½•å­¦ä¹ çš„ä»»ä½•å»ºè®®ã€‚ æå‰è‡´è°¢   ç”±   æäº¤ /u/Simozzzo   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/195l81f/reinforcement_learning_self_taught/</guid>
      <pubDate>Sat, 13 Jan 2024 10:35:08 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ RL å­¦ä¹ æ¢¯åº¦ä¸‹é™æ­¥é•¿</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1957gll/learning_the_gradient_descent_stepsize_with_rl/</link>
      <description><![CDATA[       é—®é¢˜é™ˆè¿°ï¼š æˆ‘ä¸€ç›´åœ¨ç ”ç©¶ä¸€ä¸ªä½¿ç”¨å¼ºåŒ–å­¦ä¹ åŠ é€Ÿæ¢¯åº¦ä¸‹é™æ”¶æ•›çš„é¡¹ç›®ã€‚æˆ‘æƒ³å­¦ä¹ ä¸€ç§ç­–ç•¥ï¼Œå¯ä»¥å°†æ¢¯åº¦ä¸‹é™çš„å½“å‰çŠ¶æ€æ˜ å°„åˆ°æœ€ä½³åŠ¨ä½œï¼Œå³æœ¬ä¾‹ä¸­çš„æ­¥é•¿ã€‚æé†’ä¸€ä¸‹ï¼šæ¢¯åº¦ä¸‹é™è¿­ä»£ç”± x_k+1 = x_k - gamma*grad(f) ç»™å‡ºï¼Œå…¶ä¸­ gamma ä¸ºæ­¥é•¿ã€‚ç›®å‰ï¼Œæˆ‘åªè€ƒè™‘ f(x) = x&#39;Qx å½¢å¼çš„å‡¸äºŒæ¬¡å‡½æ•°ã€‚æˆ‘æƒ³åœ¨å‡½æ•°åˆ†å¸ƒä¸Šè®­ç»ƒç­–ç•¥ï¼Œä»¥ä¾¿åœ¨é¢„æµ‹æ—¶å®ƒå¯ä»¥æ³›åŒ–åˆ°è¯¥åˆ†å¸ƒä¸­çš„æ‰€æœ‰å‡½æ•°ï¼Œä»¥åŠåœ¨è®­ç»ƒæœŸé—´æœªè§è¿‡çš„å‡½æ•°ã€‚é€šè¿‡åœ¨æ¯æ¬¡è¿­ä»£ä¸­é¢„æµ‹æœ€ä½³æ­¥é•¿çš„ç­–ç•¥ï¼Œç›®æ ‡æ˜¯æ¢¯åº¦ä¸‹é™åœ¨è¯¥åˆ†å¸ƒå†…çš„æ‰€æœ‰å‡½æ•°çš„è¿­ä»£æ¬¡æ•°è¾ƒå°‘çš„æƒ…å†µä¸‹æ”¶æ•›ã€‚ â€‹ å½“å‰æ–¹æ³•ï¼š ç›®å‰ï¼Œæˆ‘ä¸€ç›´åœ¨ä½¿ç”¨æ— æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå¦‚ Soft Actor-Critic (SAC) å’Œ Twin Delayed Deep Definitive Policy Gradient (TD3) æ¥è®­ç»ƒç­–ç•¥ï¼Œä½†æˆ‘å‘ç°å³ä½¿å¯¹äºæŸä¸ªç‰¹å®šå‡½æ•°è¿‡åº¦æ‹Ÿåˆçš„ç®€å•æƒ…å†µï¼Œæ‰€éœ€çš„å†…å­˜å’Œè®¡ç®—é‡ä¹Ÿéå¸¸é«˜ã€‚æ­¤å¤–ï¼Œå½“æ‚¨è¿‡åº¦æ‹Ÿåˆï¼ˆå¯¹åŒä¸€å‡½æ•°è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼‰æ—¶ï¼Œæ‚¨ä¼šæœŸæœ›å¥–åŠ±æ”¶æ•›åˆ°æŸä¸ªå€¼ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œå¥–åŠ±ç¡®å®å¢åŠ äº†ï¼Œä½†åœ¨æŸäº›æ—¶å€™ä»£ç†å®Œå…¨å¿˜è®°äº†å®ƒæ‰€å­¦åˆ°çš„ä¸œè¥¿ã€‚æˆ‘ä½¿ç”¨ç¨€ç–å¥–åŠ±ï¼šæ¯æ¬¡è¿­ä»£ä¸­æ”¶æ•›æ—¶ä¸º 0ï¼Œæœªæ”¶æ•›æ—¶ä¸º -1ã€‚ä¹Ÿè®¸æœ€å¥½æœ‰ä¸€ä¸ªå¥–åŠ±ï¼Œè¯´æ˜æ¯æ¬¡è¿­ä»£ä¸­æ®‹å·®ï¼ˆ=æ¢¯åº¦èŒƒæ•°ï¼‰çš„å‡å°‘ï¼Œè¿™æ ·ä»£ç†ä¸ä»…ä¼šåœ¨å›åˆç»“æŸæ—¶æ¥æ”¶ä¿¡æ¯ã€‚å¯¹äºçŠ¶æ€ï¼Œæˆ‘å°è¯•äº†ä¸åŒçš„æ–¹æ³•ï¼Œä½†ä»…åŒ…å«å½“å‰æ¢¯åº¦ä¼¼ä¹æˆ–å¤šæˆ–å°‘æœ‰æ•ˆã€‚æˆ‘ä½¿ç”¨çš„ç®—æ³•æ˜¯SACï¼Œå®ƒä¼¼ä¹æ¯”TD3æ›´å¿«ã€‚æ¼”å‘˜å’Œè¯„è®ºå®¶å‡ç”±ç¥ç»ç½‘ç»œå‚æ•°åŒ–ï¼Œæ¯ä¸ªç¥ç»ç½‘ç»œæœ‰ 3 ä¸ªéšè—å±‚å’Œ 128 ä¸ªèŠ‚ç‚¹ã€‚æˆ‘ä½¿ç”¨äº† Stable-Baselines 3 çš„å®ç°ã€‚ â€‹ æˆ‘çš„é—®é¢˜ï¼š - æ˜¯æ— æ¨¡å‹çš„RL è§£å†³è¿™ä¸ªé—®é¢˜çš„æ­£ç¡®æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿå®ƒçš„è®¡ç®—æˆæœ¬éå¸¸é«˜ã€‚æ˜¯å¦æœ‰æ›´å¥½çš„æ–¹æ³•ï¼Œä¾‹å¦‚åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æˆ–æŸç§ç­–ç•¥æœç´¢ï¼Ÿ - åœ¨å›¾ä¸­ï¼Œä¸ºä»€ä¹ˆå¥–åŠ±çªç„¶å‡å°‘ï¼Ÿå®ƒä¸é‡æ”¾ç¼“å†²åŒºçš„å¤§å°æœ‰å…³ç³»å—ï¼Ÿç›®å‰æˆ‘å¯ä»¥åˆ†é… 120Gb çš„å†…å­˜ï¼Œè¿™å·²ç»æ˜¯ç›¸å½“å¤šäº†ã€‚ - RL ç†è®ºé€šå¸¸åŸºäºé©¬å°”å¯å¤«è¿‡ç¨‹ã€‚å› æ­¤å®ƒå‡è®¾é©¬å°”å¯å¤«æ€§è´¨ï¼Œå³å½“å‰çŠ¶æ€å®Œå…¨ç‹¬ç«‹äºå…ˆå‰çš„çŠ¶æ€ã€‚ä½†æ˜¯ï¼Œæœ€å¥½æ·»åŠ ä¸€äº›æœ‰å…³å…ˆå‰æ¢¯åº¦çš„ä¿¡æ¯ä»¥å¢åŠ åŠ¨é‡ï¼ˆä¾‹å¦‚ Nesterov åŠ é€Ÿï¼‰ã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸­è¿™å¯èƒ½å—ï¼Ÿ â€‹ https://preview.redd.it/lnn1k9s333cc1.jpg?width=937&amp;format=pjpg&amp;auto=webp&amp;s=4254e662c840e4b4ca719b1f 70a488041376fad2   ç”±   æäº¤ /u/Lennitar   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1957gll/learning_the_gradient_descent_stepsize_with_rl/</guid>
      <pubDate>Fri, 12 Jan 2024 22:15:47 GMT</pubDate>
    </item>
    </channel>
</rss>