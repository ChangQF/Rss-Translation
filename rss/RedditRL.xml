<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Wed, 17 Jan 2024 09:14:49 GMT</lastBuildDate>
    <item>
      <title>å›½é™…è±¡æ£‹ä»£ç†çš„å¥–åŠ±æ€è·¯</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/198b38r/reward_idea_for_chess_agent/</link>
      <description><![CDATA[å—¨ã€‚æˆ‘æ˜¯å¼ºåŒ–å­¦ä¹ æ–°æ‰‹ï¼Œè¯•å›¾åœ¨ Tensorflow å’Œ TensorFlow ä¸­å®ç°å›½é™…è±¡æ£‹ä»£ç†/Cli ç¨‹åºæ—¶å­¦ä¹ ä¸»è¦æ¦‚å¿µã€‚ C++ã€‚ æˆ‘åœ¨æ•°å­¦æ–¹é¢æ²¡æœ‰å¾ˆå¼ºçš„èƒŒæ™¯ï¼Œæˆ‘æ‰€åšçš„æ‰€æœ‰å­¦ä¹ éƒ½æ˜¯é€šè¿‡åœ¨äº’è”ç½‘ä¸Šé˜…è¯»ï¼ˆæˆ‘ç¡®å®åœ¨ç›‘ç£å­¦ä¹ å’Œå¼ é‡æµæ–¹é¢æœ‰ä¸€äº›ç»éªŒï¼‰ã€‚&lt; /p&gt; æˆ‘è®¡åˆ’è®©æˆ‘çš„ä»£ç†ä½¿ç”¨ DQNï¼ˆæˆ–è€…å¯èƒ½æ˜¯ DDQN ä»åœ¨å°è¯•äº†è§£å…¶å·¥ä½œåŸç†ï¼‰ ç°åœ¨ï¼Œæˆ‘æœ€åˆè®¡åˆ’ä½¿æˆ‘çš„å¥–åŠ±å‡½æ•°æˆä¸ºä¸€ä¸ªç®€å•çš„ 1ï¼Œå¦‚æœä»£ç†è·èƒœï¼Œå¹³å±€åˆ™ä¸º 0ï¼Œè¾“äº†åˆ™ä¸º -1ã€‚ä½†æˆ‘æƒ³åˆ°äº†è·Ÿè¸ªæ¯åœºæ¯”èµ›ä¸­æ‰€èµ°æ£‹å­ Q å€¼çš„å˜åŒ–ï¼ˆå³çŠ¶æ€ä¸­ q å€¼æœ€é«˜çš„æ£‹å­ï¼‰çš„å˜åŒ–ï¼Œå½“æ¸¸æˆç»“æŸæ—¶ï¼Œé‡‡ç”¨è¯¥å‡½æ•°å’Œå…¶ä»–ä¸€äº›å‡½æ•°ï¼ˆçº¿æ€§å‡½æ•°ï¼‰ ï¼Œå¯¹æ•°æˆ–å…¶ä»–ï¼‰å¹¶ä½¿å¥–åŠ±ä¸ºè¿™ä¸¤ä¸ªå‡½æ•°çš„è´Ÿç§¯åˆ†å·®ã€‚ è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œåœ¨å›½é™…è±¡æ£‹æ¸¸æˆä¸­ï¼Œå¦‚æœä½ ç©å¾—å¥½ï¼Œä½ çš„ä½ç½®åº”è¯¥ä¼šéšç€æ¸¸æˆçš„è¿›è¡Œè€Œå˜å¾—æ›´å¥½. è¿™å¬èµ·æ¥ä¸é”™è¿˜æ˜¯æˆ‘åªæ˜¯éšæ„ç¼–é€ çš„ä¸œè¥¿ï¼Ÿè¿™ç§æ–¹æ³•æœ‰åå­—å—ï¼Ÿ å¸Œæœ›æœ‰ä¸€ä¸ªå¥½çš„è§£é‡Šã€‚å¦å¤–ï¼Œå¦‚æœæ‚¨å¯¹ DQN çš„æ¶æ„æˆ–ä¸€èˆ¬ä»£ç†æœ‰ä»»ä½•å»ºè®®ï¼Œæˆ‘å¾ˆä¹æ„å¬åˆ°ï¼ è°¢è°¢ï¼  &amp;# 32ï¼›ç”±   æäº¤ /u/C0L0Rpunch   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/198b38r/reward_idea_for_chess_agent/</guid>
      <pubDate>Tue, 16 Jan 2024 19:11:56 GMT</pubDate>
    </item>
    <item>
      <title>å¯»æ±‚å»ºè®®ä»¥åŠ å¿«ç¨³å®šåŸºçº¿ä¸‹çš„ PPO æ¨¡å‹è®­ç»ƒ3</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1983iwd/seeking_advice_to_speed_up_ppo_model_training_in/</link>
      <description><![CDATA[å˜¿å„ä½ Reddit ç”¨æˆ·ï¼ æˆ‘ç›®å‰æ­£åœ¨ä½¿ç”¨ Stable Baselines3 è®­ç»ƒé‡‘èæ—¥äº¤æ˜“æ¨¡å‹ï¼Œå¹¶ä¸”æˆ‘&#39;æˆ‘é¢ä¸´ç€è®­ç»ƒé€Ÿåº¦çš„æŒ‘æˆ˜ã€‚æ¯å¤©ï¼ˆæ¯é›†ï¼‰æ¶‰åŠå¤§çº¦ 250 ä¸‡ä¸ªæ•°æ®ç‚¹ï¼Œå½“é‡‡å–éšæœºæ“ä½œæ—¶ï¼Œæˆ‘çš„æ¨¡æ‹Ÿå™¨å¯ä»¥åœ¨å¤§çº¦ 60-70 ç§’å†…è¿­ä»£å®ƒä»¬ã€‚ è®­ç»ƒæˆ‘çš„ PPO æ¨¡å‹æ—¶ä¼šå‡ºç°é—®é¢˜ï¼Œå› ä¸ºå®ƒéœ€è¦æ¯é›†é•¿è¾¾ 40-45 åˆ†é’Ÿã€‚æˆ‘åªåœ¨å‰§é›†ç»“æŸæ—¶æ‰§è¡Œä¸€æ¬¡æ›´æ–°ï¼Œæ²¡æœ‰æœ‰é™çš„æ°´å¹³çº¿æˆªæ–­ã€‚å½“æ¨¡æ‹Ÿå™¨å¯ä»¥åœ¨ä¸€åˆ†é’Ÿå·¦å³å®Œæˆè®­ç»ƒæ—¶ï¼Œä¸ºä»€ä¹ˆè¦èŠ±è¿™ä¹ˆé•¿æ—¶é—´æ¥è®­ç»ƒä¸€é›†ï¼Ÿæœ‰ä»€ä¹ˆæç¤ºæˆ–æŠ€å·§å¯ä»¥åŠ é€Ÿè¿™ä¸ªè®­ç»ƒè¿‡ç¨‹å—ï¼Ÿæ¥å—å»ºè®®å’Œè§è§£ï¼   ç”±   æäº¤ /u/Bunny_lad   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1983iwd/seeking_advice_to_speed_up_ppo_model_training_in/</guid>
      <pubDate>Tue, 16 Jan 2024 14:00:29 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å­¦ä¹ çŠ¯ç½ªå­¦ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1980su2/how_to_study_criminology/</link>
      <description><![CDATA[å¦‚ä½•å­¦ä¹ çŠ¯ç½ªå­¦ï¼Ÿ å—¨ï¼Œæˆ‘çš„æœ‹å‹æƒ³åœ¨ç¾å›½å­¦ä¹ çŠ¯ç½ªå­¦ã€‚æˆ‘ä»¬ä¸çŸ¥é“æœ‰ä»€ä¹ˆè¦æ±‚ã€è€ƒè¯•ä»¥åŠå“ªäº›å¤§å­¦æœ‰è¿™æ ·çš„æ•™å¸ˆã€‚å¥¹æ”»è¯»è®¾è®¡å­¦å£«å­¦ä½ï¼Œæƒ³è¦æ”»è¯»æœ¬ç§‘çŠ¯ç½ªå­¦ã€‚è¯·å¸®åŠ©æˆ‘ä»¬ï¼Œå¥¹è¯¥å¦‚ä½•å¼€å§‹ï¼Ÿ ï¼ˆå¥¹ä¸åœ¨ç¾å›½ï¼‰   ç”±   æäº¤ /u/DevilSummoned   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1980su2/how_to_study_criminology/</guid>
      <pubDate>Tue, 16 Jan 2024 11:30:39 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œå¯ä»¥å¤„ç†é«˜äº 1 çš„å¥–åŠ±å—ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/19809re/can_a_neural_network_handle_rewards_above_1/</link>
      <description><![CDATA[æˆ‘çŸ¥é“åœ¨ -1 å’Œ 1 ä¹‹é—´ä¼ é€’å€¼å¯ä»¥æé«˜ç¨³å®šæ€§ï¼Œä½†æˆ‘æƒ³çŸ¥é“æ¨¡å‹æ˜¯å¦å¯ä»¥å®¹å¿ä¼ é€’æ›´é«˜çš„å€¼ï¼Ÿä¸å¹¸çš„æ˜¯æˆ‘ç°åœ¨æ²¡æœ‰ç¯å¢ƒå¯ä»¥æµ‹è¯•å®ƒ   ç”±   æäº¤ /u/sogha   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/19809re/can_a_neural_network_handle_rewards_above_1/</guid>
      <pubDate>Tue, 16 Jan 2024 10:58:32 GMT</pubDate>
    </item>
    <item>
      <title>PPO ç‰¹å·¥ä¸éšæœºç©å®¶è¿›è¡Œç¥å¥‡å®è´å¯¹å†³ã€‚ä½ çŸ¥é“ä¸ºä»€ä¹ˆå¹³å‡å¥–åŠ±å¦‚æ­¤ä¸ç¨³å®šå—ï¼Ÿ lr=1e-3ï¼Œ8 ä¸ªå¹¶è¡Œç¯å¢ƒåœ¨è®­ç»ƒå‰è¿›è¡Œ 60 æ¬¡ç§»åŠ¨ï¼Œnum_epochs=3</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197zbyt/ppo_agent_playing_pokemon_showdown_vs_random/</link>
      <description><![CDATA[       ç”±   æäº¤ /u/moisturemeister   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197zbyt/ppo_agent_playing_pokemon_showdown_vs_random/</guid>
      <pubDate>Tue, 16 Jan 2024 09:57:47 GMT</pubDate>
    </item>
    <item>
      <title>TicTacToe çš„è¡¨æ ¼ Q-Learning - ä»…æœ€åä¸€ä¸ªçŠ¶æ€/åŠ¨ä½œå¯¹å­˜å‚¨åœ¨ Q-Table å­—å…¸ä¸­ï¼Œå…¶å€¼ä¸ä¸º 0</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197yxc1/tabular_qlearning_for_tictactoe_only_the_last/</link>
      <description><![CDATA[æˆ‘åœ¨ tictactoe 3x3 æ¿çš„è¡¨æ ¼ q-learning å®ç°ä¸­é‡åˆ°é—®é¢˜ã€‚ â€‹ é—®é¢˜åœ¨äºï¼Œåªæœ‰æœ€åä¸€æ­¥ï¼ˆè·èƒœã€å¤±è´¥ã€å¹³å±€ï¼‰åŠå…¶å„è‡ªçš„æ£‹ç›˜çŠ¶æ€å­˜å‚¨åœ¨ q å€¼ä¸æ˜¯â€œ0.0â€çš„ q è¡¨ä¸­ã€‚å¯¼è‡´æœ€åç§»åŠ¨çš„æ‰€æœ‰å…¶ä»–çŠ¶æ€å’ŒåŠ¨ä½œå¯¹ä»ç„¶å…·æœ‰å€¼â€œ0.0â€ã€‚æˆ‘åœ¨ä¸‹é¢æ·»åŠ äº† q è¡¨ï¼Œå…¶ä¸­æ˜¾ç¤ºæœ€åä¸€æ­¥çš„å€¼ä¸ºâ€œ0.2â€ã€‚ä½†ä¹‹å‰æ‰€æœ‰çš„ç§»åŠ¨çš„å€¼ä¸ºâ€œ0.0â€ã€‚è¿™åªæ˜¯ç¬¬ä¸€é›†ã€‚å³ä½¿å¢åŠ äº†å‰§é›†ä¹Ÿä¸ä¼šæ”¹å˜ä»»ä½•äº‹æƒ…ã€‚åªæœ‰æœ€åä¸€ä¸ªåŠ¨ä½œçš„ q å€¼ä¸æ˜¯â€œ0.0â€ â€‹ éå¸¸æ„Ÿè°¢ä»»ä½•å¸®åŠ©ã€‚æˆ‘èŠ±äº†å‡ å¤©æ—¶é—´å°è¯•ä¿®å¤å®ƒ... :( class Mark(enum.StrEnum): CROSS = &quot;X&quot; NAUGHT = &quot;O&quot;; EMPTY = &quot;; _&quot; class Reward(enum.IntEnum): WIN = 1 LosE = -1 TIE = -0.065 NON_TERMINAL = -0.01 # Q-Learning å¸¸é‡ EPSILON = 0.1 # æ¢ç´¢å› å­ ALPHA = 0.2 # å­¦ä¹ ç‡ GAMMA = 0.95 # æŠ˜æ‰£å› å­ TOTAL_EPISODES = 1 # ä»£ç†å°†ç©çš„æ¸¸æˆæ€»æ•° BOARD = np.array([Mark.EMPTY] * BOARD_SIZE)  â€‹  def update_q_table(board,action,reward,new_board): board_key = &quot;&quot;.join(board) new_board_key = &quot;&quot;.join(new_board) old_value = Q_TABLE_DICT.get((board_key, action), 0) if game_over (new_board): # å¦‚æœæ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œåˆ™æ²¡æœ‰æœªæ¥å¥–åŠ±å¯ä»¥è€ƒè™‘ next_max = 0 else: # ä¼°è®¡æœ€ä¼˜æœªæ¥å€¼ next_max = max( Q_TABLE_DICT.get((new_board_key, a), 0) for a in possible_moves( new_board) ) # ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹æ›´æ–°å½“å‰çŠ¶æ€-åŠ¨ä½œå¯¹çš„ Q å€¼ q_value = old_value + ALPHA * (reward + GAMMA * next_max - old_value) Q_TABLE_DICT[(board_key, action)] = q_value &lt; /pre&gt; â€‹ def train_q_learning_agent(): for Episode in range(TOTAL_EPISODES): board = np.array([Mark.EMPTY] * BOARD_SIZE) # é‡ç½®board current_mark = Mark.CROSS while not game_over(board): # Q-learning ä»£ç† (X) é‡‡å–è¡ŒåŠ¨ if current_mark == Mark.CROSS: action = Choose_action_q_learning(board, Training=True) new_board = make_move_to(board, action, current_mark)reward = get_reward(new_board, current_mark) print(new_board) update_q_table(board, action,reward, new_board) # éšæœºç©å®¶ (O) é‡‡å–è¡ŒåŠ¨ else: action = get_random_move(board) new_board = make_move_to(board, action, current_mark) ) board = new_board current_mark = Mark.NAUGHT if current_mark == Mark.CROSS else Mark.CROSS  â€‹ def Choose_action_q_learning(board,è®­ç»ƒ=çœŸï¼‰-&gt; int: å¦‚æœè®­ç»ƒä¸” random.uniform(0, 1) &lt; EPSILON: # æ¢ç´¢ï¼šé€‰æ‹©ä¸€ä¸ªéšæœºåŠ¨ä½œ return np.random.choice(possible_moves(board)) else: # æ¢ç´¢ï¼šæ ¹æ®å½“å‰ Q è¡¨é€‰æ‹©æœ€ä½³åŠ¨ä½œ board_key = &quot;&quot;.join(board) q_values = {æ“ä½œ: Q_TABLE_DICT.get((board_key, action), 0) for action in possible_moves(board) } return max(q_values, key=q_values.get)  â€‹ ç¬¬ä¸€é›†çš„ Q-Table å­—å…¸ä¸º jsonï¼š â€‹ { &quot;(&#39;_________&#39;, 0)&quot;: 0.0ï¼Œâ€œ(&#39;XO_______&#39;ï¼Œ2)â€ï¼š0.0ï¼Œâ€œ(&#39;XOX____O_&#39;ï¼Œ3)â€ï¼š0.0ï¼Œâ€œ(&#39;XOXX___OO&#39;ï¼Œ4)â€ï¼š0.0ï¼Œâ€œ(&#39;XOXXXO_OO&#39; , 6)â€: 0.2 }  â€‹   ç”±   æäº¤/u/faux190  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197yxc1/tabular_qlearning_for_tictactoe_only_the_last/</guid>
      <pubDate>Tue, 16 Jan 2024 09:29:46 GMT</pubDate>
    </item>
    <item>
      <title>å…·æœ‰ç‹„åˆ©å…‹é›·ä½œç”¨åˆ†å¸ƒçš„ PPO</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197yqqj/ppo_with_dirichlet_action_distribution/</link>
      <description><![CDATA[å—¨ï¼æˆ‘æ­£åœ¨é€šè¿‡ PPO åŸ¹è®­æ”¿ç­–ã€‚è¯¥æ¨¡å‹è¾“å‡ºçš„ logits æˆä¸ºç‹„åˆ©å…‹é›·åˆ†å¸ƒçš„å‚æ•°ã€‚è¿™äº›æ“ä½œçš„æ€»å’Œåº”ä¸º 1ï¼Œå¹¶ä¸”åœ¨ [0, 1]ï¼ˆå•çº¯å½¢ï¼‰èŒƒå›´å†…ã€‚é—®é¢˜æ˜¯ï¼Œéšç€åŠ¨ä½œå¤§å°ï¼ˆç»´åº¦ï¼‰çš„å¢åŠ ï¼ŒåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡ä¹Ÿä¼šå¢åŠ ã€‚è¿™åè¿‡æ¥æœ€ç»ˆä¼šæ”¾å¤§ ppo ä½¿ç”¨çš„æ›¿ä»£æŸå¤±ä¸­çš„ logp æ¯”ç‡ã€‚ æˆ‘çš„å•çº¯å½¢æ“ä½œç©ºé—´æ˜¯é•¿åº¦ä¸º 400 çš„ä¸€ç»´å‘é‡ã€‚å¯¹æ•°æ¦‚ç‡é€šå¸¸åœ¨ 2200 - 3000 çš„èŒƒå›´å†…ã€‚ e^(logp_1 - logp_2) çš„ logp æ¯”ç‡ä¼šæœ‰å¾ˆå¤§çš„å˜åŒ–ï¼Œä»è€Œç ´å pytorch çš„æ¢¯åº¦è®¡ç®—ã€‚å¯¼è‡´çœ‹èµ·æ¥æœ‰æ•ˆä½†æ¢¯åº¦åŒ…å« NaN å€¼çš„æŸå¤±ã€‚ æœ‰äººçŸ¥é“å¦‚ä½•åœ¨ä¿æŒç†è®ºåŸºç¡€å¥å…¨çš„åŒæ—¶æŠµæ¶ˆè¿™ä¸ªé—®é¢˜å—ï¼Ÿæˆ–è€…ä¹Ÿè®¸æˆ‘åœ¨æŸä¸ªåœ°æ–¹çš„æ¨ç†ä¸­çŠ¯äº†é”™è¯¯ï¼Ÿ æå‰è‡´è°¢ï¼   ç”±   æäº¤ /u/JMvanWestendorp   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197yqqj/ppo_with_dirichlet_action_distribution/</guid>
      <pubDate>Tue, 16 Jan 2024 09:16:42 GMT</pubDate>
    </item>
    <item>
      <title>è°ƒæ•´æ³•å­¦ç¡•å£«ä¸è®©ä»–ä»¬æ¥åœ°æœ‰ä½•ä¸åŒï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197uwu3/how_is_aligning_llms_different_from_grounding_them/</link>
      <description><![CDATA[æ˜¯çš„ï¼Œè¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨ - åœ¨å…·ä½“çš„ç¯å¢ƒä¸­ï¼Œæˆ‘æƒ³çŸ¥é“è¿™äº›ä»»åŠ¡ä¼šæœ‰ä»€ä¹ˆä¸åŒã€‚æˆ‘æƒ³ä¼šæœ‰ä¸åŒçš„æ”¿ç­–ï¼Œä½†åœ¨é«˜å±‚æ¬¡ä¸Šè°èƒ½è§£é‡Šä¸€ä¸‹å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ   ç”±   æäº¤/u/dumber_9734   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197uwu3/how_is_aligning_llms_different_from_grounding_them/</guid>
      <pubDate>Tue, 16 Jan 2024 05:18:35 GMT</pubDate>
    </item>
    <item>
      <title>SB3 çš„éšæœºå¯åŠ¨çŠ¶æ€</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197nwq0/random_start_state_with_sb3/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ SB3 çš„ DDPGï¼Œä½†åœ¨å­¦ä¹ æ—¶æ— æ³•åŠ è½½å…·æœ‰ä¸åŒå¯åŠ¨çŠ¶æ€çš„æ–‡ä»¶ã€‚æˆ‘æ¯æ¬¡éƒ½å°è¯•åœ¨é‡ç½®æ–¹æ³•ä¸­æ›´æ”¹å®ƒã€‚æˆ‘çš„çŒœæµ‹æ˜¯è®­ç»ƒé»‘é¬¼åªå‘ç”Ÿåœ¨ä¸€ä¸ªæƒ…èŠ‚ä¸­ï¼Œå› ä¸ºæ²¡æœ‰è°ƒç”¨é‡ç½®æ–¹æ³•ï¼Œæ‰€ä»¥æ²¡æœ‰å˜åŒ–ã€‚ä¹Ÿç”¨ PPO å°è¯•è¿‡ã€‚å¦å¤–ï¼Œæˆ‘å¦‚ä½•æ§åˆ¶è®­ç»ƒæ¬¡æ•°å’Œæ—¶é—´æ­¥é•¿ï¼Ÿ åœ¨ç½‘ä¸Šæœç´¢çš„ç»³ç´¢ç»“æŸğŸ™‚ æˆ‘çš„ä»£ç ï¼šä»£ç  ç¯å¢ƒï¼šè‡ªå®šä¹‰ Boid æ¤ç»’ æ¡†æ¶ï¼šå¼€æ”¾ AI Gym   ç”±   æäº¤/u/Sadboi1010   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197nwq0/random_start_state_with_sb3/</guid>
      <pubDate>Mon, 15 Jan 2024 23:44:37 GMT</pubDate>
    </item>
    <item>
      <title>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼šç»¼åˆè°ƒæŸ¥</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197lq1j/multiagent_reinforcement_learning_a_comprehensive/</link>
      <description><![CDATA[è®ºæ–‡ï¼šhttps:// arxiv.org/abs/2312.10256 æ‘˜è¦ï¼š  å¤šä»£ç†åº”ç”¨ç¨‹åºçš„æµè¡ŒéåŠæˆ‘ä»¬çš„å„ç§äº’è¿ç³»ç»Ÿæ—¥å¸¸ç”Ÿæ´»ã€‚å°½ç®¡å®ƒä»¬æ— å¤„ä¸åœ¨ï¼Œä½†åœ¨å…±äº«ç¯å¢ƒä¸­é›†æˆå’Œå¼€å‘æ™ºèƒ½å†³ç­–ä»£ç†å¯¹å…¶æœ‰æ•ˆå®æ–½æå‡ºäº†æŒ‘æˆ˜ã€‚è¿™é¡¹è°ƒæŸ¥æ·±å…¥ç ”ç©¶äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (MAS) é¢†åŸŸï¼Œç‰¹åˆ«å¼ºè°ƒé˜æ˜ MAS æ¡†æ¶å†…å­¦ä¹ æœ€ä¼˜æ§åˆ¶çš„å¤æ‚æ€§ï¼Œé€šå¸¸ç§°ä¸ºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL)ã€‚æœ¬æ¬¡è°ƒæŸ¥çš„ç›®çš„æ˜¯æä¾›å¯¹ MAS å„ä¸ªæ–¹é¢çš„å…¨é¢è§è§£ï¼Œæ­ç¤ºæ— æ•°æœºä¼šï¼ŒåŒæ—¶å¼ºè°ƒå¤šä»£ç†åº”ç”¨ç¨‹åºæ‰€é¢ä¸´çš„å›ºæœ‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¸Œæœ›ä¸ä»…æœ‰åŠ©äºæ›´æ·±å…¥åœ°äº†è§£ MAS æ™¯è§‚ï¼Œè€Œä¸”è¿˜ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›æœ‰ä»·å€¼çš„è§‚ç‚¹ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ MAS çš„åŠ¨æ€é¢†åŸŸå†…ä¿ƒè¿›çŸ¥æƒ…æ¢ç´¢å¹¶ä¿ƒè¿›å‘å±•ï¼Œè®¤è¯†åˆ°åœ¨è§£å†³ MARL ä¸­å‡ºç°çš„å¤æ‚æ€§æ–¹é¢éœ€è¦é€‚åº”æ€§ç­–ç•¥å’ŒæŒç»­å‘å±•ã€‚    ç”±   æäº¤ /u/APaperADay   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197lq1j/multiagent_reinforcement_learning_a_comprehensive/</guid>
      <pubDate>Mon, 15 Jan 2024 22:15:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] æ‚¨å¯¹å¼ºåŒ–å­¦ä¹ çš„çœŸå®ä½“éªŒæ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197kl7z/d_what_is_your_honest_experience_with/</link>
      <description><![CDATA[ ç”±   æäº¤ /u/Smallpaul   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197kl7z/d_what_is_your_honest_experience_with/</guid>
      <pubDate>Mon, 15 Jan 2024 21:31:30 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦å¸®åŠ© - æ£€æŸ¥è¾“å…¥æ—¶å‡ºé”™ï¼šæœŸæœ› flatten_input æœ‰ 3 ä¸ªç»´åº¦ï¼Œä½†å¾—åˆ°å½¢çŠ¶ä¸º (4, 1) çš„æ•°ç»„</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/197f70n/need_help_error_when_checking_input_expected/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/197f70n/need_help_error_when_checking_input_expected/</guid>
      <pubDate>Mon, 15 Jan 2024 18:02:27 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘çš„ AIRL æ— æ³•æ­£å¸¸å·¥ä½œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1978gsl/my_airl_is_not_working/</link>
      <description><![CDATA[ä¸“å®¶è½¨è¿¹çš„æ¦‚ç‡åœ¨å¢åŠ ï¼Œè€Œç­–ç•¥ç”Ÿæˆçš„è½¨è¿¹åœ¨å‡å°‘ï¼Œä½†ç­–ç•¥æ— æ³•ä»æ¨æ–­çš„å¥–åŠ±å‡½æ•°ä¸­å­¦ä¹ ã€‚   ç”±   æäº¤/u/Professional_Card176   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1978gsl/my_airl_is_not_working/</guid>
      <pubDate>Mon, 15 Jan 2024 13:15:28 GMT</pubDate>
    </item>
    <item>
      <title>å¥–åŠ±ç¨€ç–ï¼Œå‰§é›†é•¿åº¦é•¿ã€‚</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196rt1n/sparse_reward_with_long_episode_length/</link>
      <description><![CDATA[å—¨ï¼æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨ PPO ç®—æ³•æ‰¾åˆ°ä¸€ä¸ªå¥½çš„ç­–ç•¥æ¥ä¼˜åŒ–æœ¬åœ°æœç´¢å¯å‘å¼ä¸­çš„å‚æ•°ã€‚æŒ‘æˆ˜åœ¨äºæˆ‘åªèƒ½åœ¨æ¯é›†ç»“æŸæ—¶è¯„ä¼°ç­–ç•¥çš„æ€§èƒ½ï¼Œå…¶ä¸­æä¾› [0,1] èŒƒå›´å†…çš„ç¨€ç–å¥–åŠ±ã€‚å‰§é›†é•¿åº¦å›ºå®šä¸º 1000 æ­¥ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯å¦æœ‰æœºä¼šå­¦ä¹ æˆåŠŸçš„æ”¿ç­–ï¼Ÿåˆ°ç›®å‰ä¸ºæ­¢ï¼Œå³ä½¿é‡‡ç”¨éå¸¸ç®€å•çš„è§‚å¯Ÿç»“æ„ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å–å¾—ä»»ä½•ç§¯æçš„æˆæœã€‚ä¹Ÿè®¸æˆ‘å¯ä»¥å°è¯•ä¸€äº›æŠ€å·§ã€‚é¢„å…ˆæ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼   ç”±   æäº¤ /u/OpportunityHot7289   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196rt1n/sparse_reward_with_long_episode_length/</guid>
      <pubDate>Sun, 14 Jan 2024 22:10:28 GMT</pubDate>
    </item>
    <item>
      <title>å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/196idl8/reinforcement_learning_for_optimization/</link>
      <description><![CDATA[æœ‰æ²¡æœ‰äººå°è¯•ä½¿ç”¨ RL æ¥è§£å†³ä¼˜åŒ–é—®é¢˜ï¼Œä¾‹å¦‚æ—…è¡Œå•†é—®é¢˜æˆ–ç±»ä¼¼é—®é¢˜ï¼Œæˆ‘æ£€æŸ¥äº†å‡ ç¯‡ä»–ä»¬ä½¿ç”¨ DQN çš„è®ºæ–‡ï¼Œä½†åœ¨å®é™…å®ç°åæˆ‘è¿˜æ²¡æœ‰å³ä½¿å¯¹äºç®€å•çš„é—®é¢˜ï¼Œä¾‹å¦‚å°†ç›’å­ä»è¿·å®«çš„ä¸€ç«¯ç§»åˆ°å¦ä¸€ç«¯ï¼Œä¹Ÿæ²¡æœ‰å¾—åˆ°ä»»ä½•å®é™…çš„ç»“æœã€‚æˆ‘è¿˜æ‹…å¿ƒåŸºäº DQN çš„è§£å†³æ–¹æ¡ˆèƒ½å¦åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ã€‚æ¬¢è¿æå‡ºä»»ä½•å»ºè®®ã€‚   ç”±   æäº¤ /u/HSaurabh   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/196idl8/reinforcement_learning_for_optimization/</guid>
      <pubDate>Sun, 14 Jan 2024 15:29:51 GMT</pubDate>
    </item>
    </channel>
</rss>