<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link>https://www.reddit.com/r/reinforcementlearning/?format=xml.rss</link>
    <description>å¼ºåŒ–å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½/ç»Ÿè®¡å­¦çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºæ¢ç´¢/ç†è§£å¤æ‚çš„ç¯å¢ƒå¹¶å­¦ä¹ å¦‚ä½•æœ€ä½³åœ°è·å¾—å¥–åŠ±ã€‚ä¾‹å¦‚ AlphaGoã€ä¸´åºŠè¯•éªŒå’Œ A/B æµ‹è¯•ä»¥åŠ Atari æ¸¸æˆã€‚</description>
    <lastBuildDate>Tue, 09 Apr 2024 12:25:10 GMT</lastBuildDate>
    <item>
      <title>IMPALA å®æ–½ä¸ä¸æ–­ä¸Šå‡çš„æ‰¹è¯„æŸå¤±ï¼šéœ€è¦æ´å¯Ÿï¼</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bzqheu/impala_implementation_with_rising_critic_loss/</link>
      <description><![CDATA[      æˆ‘åˆšåˆšå®Œæˆäº†ä¸€ä¸ª IMPALA å®æ–½é¡¹ç›®ï¼Œåœ¨è¯¥é¡¹ç›®ä¸­æˆ‘é€šè¿‡å¥—æ¥å­—é€šä¿¡è®­ç»ƒäº†å¤šä¸ªå‚ä¸è€…ã€‚è¿™æ˜¯åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ çš„ä¸€æ®µä»¤äººç€è¿·çš„æ—…ç¨‹ï¼Œä½†æˆ‘é‡åˆ°äº†ä¸€ä¸ªéšœç¢ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½å¸®å¿™è§£å†³ã€‚ å°½ç®¡æ¼”å‘˜è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ€§èƒ½æ”¹è¿›ï¼Œä½†æˆ‘çœ‹åˆ°äº†æŒç»­ä¸”ä»¤äººä¸å®‰çš„é—®é¢˜è¶‹åŠ¿ï¼šæ‰¹è¯„è€…æŸå¤±ä¸ä»…ä¸ç¨³å®šï¼›å®ƒå®é™…ä¸Šéšç€æ—¶é—´çš„æ¨ç§»è€Œå¢åŠ ã€‚è¿™å¾ˆä»¤äººè´¹è§£ï¼Œå› ä¸ºéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œä½ ä¼šæœŸæœ›æ›´å¥½çš„æ¼”å‘˜è¡¨ç°æ¥ç¨³å®šç”šè‡³å‡å°‘æ‰¹è¯„è€…æŸå¤±ï¼Œå¯¹å—ï¼Ÿ å¦å¤–ï¼Œè¯·ç»§ç»­å…³æ³¨ğŸ˜Šæˆ‘è®¡åˆ’è¿›ä¸€æ­¥æ¢ç´¢åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå¹¶å°†ä¸å¤§å®¶åˆ†äº«æˆ‘çš„æ—…ç¨‹ã€‚æ‚¨ä»Šå¤©çš„è§è§£å¯èƒ½æ˜¯è¯¥æ¢ç´¢çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼ æå‰æ„Ÿè°¢æ‚¨çš„æƒ³æ³•å’Œå»ºè®®ï¼ â€‹ https://github.com/seolhokim/SimpleDistributedRL â€‹ &lt; a href=&quot;https://preview.redd.it/9f5nlewf2gtc1.png?width=814&amp;format=png&amp;auto=webp&amp;s=81de8398d0b4175f6d6bdccf4b2fe1b8c95749e6&quot;&gt;https://preview.redd.it/9f5nlewf2gtc1.png?width =814&amp;format=png&amp;auto=webp&amp;s=81de8398d0b4175f6d6bdccf4b2fe1b8c95749e6 â€‹   ç”±   æäº¤ /u/Spiritual_Fig3632   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bzqheu/impala_implementation_with_rising_critic_loss/</guid>
      <pubDate>Tue, 09 Apr 2024 12:06:18 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Q-learning ä¸ºå¥èº«æˆ¿ä¸­çš„ MountainCar æä¾›å¥–åŠ±åŠŸèƒ½</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bzm0qp/reward_function_for_mountaincar_in_gym_using/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘ä¸€ç›´åœ¨å°è¯•ä½¿ç”¨ Qlearning è®­ç»ƒä»£ç†æ¥è§£å†³å¥èº«æˆ¿ä¸­çš„ MountainCar é—®é¢˜ï¼Œä½†æ— æ³•è®©æˆ‘çš„ä»£ç†åˆ°è¾¾æ——å¸œã€‚å½“æˆ‘ä½¿ç”¨è¿”å›çš„é»˜è®¤å¥–åŠ±æ—¶ï¼Œå®ƒæ°¸è¿œä¸ä¼šåˆ°è¾¾æ ‡å¿—ï¼ˆæ¯ä¸€æ­¥ä¸º -1ï¼Œåˆ°è¾¾æ ‡å¿—æ—¶ä¸º 0ï¼‰ï¼Œæˆ‘è®©å®ƒè¿è¡Œ 200,000 é›†ï¼Œä½†æ— æ³•åˆ°è¾¾é‚£é‡Œã€‚æ‰€ä»¥ï¼Œæˆ‘å°è¯•ç¼–å†™è‡ªå·±çš„å¥–åŠ±å‡½æ•°ï¼Œæˆ‘å°è¯•äº†ä¸€å † - è·ç¦»æ——å¸œè¶Šè¿‘ï¼Œå¥–åŠ±å‘ˆæŒ‡æ•°çº§è¶Šé«˜ï¼Œæ——å¸œå¤„çš„å¥–åŠ±è¶Šå¤§ï¼Œå¥–åŠ±ABSï¼ˆåŠ é€Ÿåº¦ï¼‰å’Œé¡¶éƒ¨çš„å¥–åŠ±è¶Šå¤§ï¼Œç­‰ç­‰ã€‚ä½†æˆ‘åªæ˜¯æ— æ³•è®©æˆ‘çš„ä»£ç†ä¸€è·¯åˆ°è¾¾é¡¶éƒ¨ - å…¶ä¸­ä¸€ä¸ªåŠŸèƒ½éå¸¸æ¥è¿‘ï¼Œå°±åƒéå¸¸æ¥è¿‘ï¼Œä½†éšåå†³å®šå…¨åŠ›æ·±å…¥æ½œæ°´ï¼ˆå¯èƒ½æ˜¯å› ä¸ºæˆ‘å¥–åŠ±åŠ é€Ÿï¼Œä½†æˆ‘è®¾ç½®äº†ä¸€ä¸ªæ ‡å¿—ä»…åœ¨ç¬¬ä¸€æ¬¡å‘å·¦ç§»åŠ¨æ—¶å¥–åŠ±åŠ é€Ÿï¼Œä½†æˆ‘çš„ä»£ç†ä»ç„¶å†³å®šå‘ä¸‹æ½œï¼‰ã€‚æˆ‘ä¸æ˜ç™½ï¼Œæœ‰äººå¯ä»¥å»ºè®®æˆ‘åº”è¯¥å¦‚ä½•è§£å†³å®ƒå—ï¼Ÿ æˆ‘ä¸çŸ¥é“æˆ‘åšé”™äº†ä»€ä¹ˆï¼Œå› ä¸ºæˆ‘åœ¨ç½‘ä¸Šçœ‹åˆ°äº†æ•™ç¨‹ï¼Œè€Œä¸”ä»£ç†ä¹Ÿåœ¨é‚£é‡Œä»…ä½¿ç”¨é»˜è®¤å¥–åŠ±å°±éå¸¸å¿«ï¼ˆ&lt;4000 é›†ï¼‰ï¼Œæˆ‘ä¸çŸ¥é“ä¸ºä»€ä¹ˆå³ä½¿ä½¿ç”¨ç›¸åŒçš„å‚æ•°ä¹Ÿæ— æ³•å¤åˆ¶å®ƒã€‚æˆ‘éå¸¸æ„Ÿè°¢ä»»ä½•å¸®åŠ©å’Œå»ºè®®ã€‚ è¿™æ˜¯ github é“¾æ¥ å¦‚æœæœ‰äººæƒ³çœ‹ä¸€ä¸‹ä»£ç ã€‚ ã€ŠQ-learning-å±±è½¦ã€‹æ˜¯åº”è¯¥å·¥ä½œçš„ä»£ç ï¼Œä¸å‘å¸ƒçš„ OpenAI ç¤ºä¾‹éå¸¸ç›¸ä¼¼ï¼Œä½†ç»è¿‡ä¿®æ”¹ä»¥åœ¨gym 0.26ä¸Šå·¥ä½œï¼› copy å’Œ new æ˜¯æˆ‘ä¸€ç›´åœ¨å°è¯•å¥–åŠ±åŠŸèƒ½çš„åœ°æ–¹ã€‚ éå¸¸æ„Ÿè°¢ä»»ä½•æ„è§ã€æŒ‡å¯¼æˆ–å»ºè®®ã€‚æå‰è‡´è°¢ã€‚ ç¼–è¾‘ï¼šåœ¨è¯„è®ºä¸­è§£å†³ã€‚å¦‚æœæœ‰äººæ¥è‡ªæœªæ¥å¹¶ä¸”é¢ä¸´ä¸æˆ‘ç›¸åŒçš„é—®é¢˜ï¼Œè§£å†³çš„ä»£ç å°†ä¸Šä¼ åˆ°ä¸Šé¢é“¾æ¥çš„ github å­˜å‚¨åº“ã€‚   ç”±   æäº¤/u/guccicupcake69   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bzm0qp/reward_function_for_mountaincar_in_gym_using/</guid>
      <pubDate>Tue, 09 Apr 2024 07:14:53 GMT</pubDate>
    </item>
    <item>
      <title>è°ƒè¯• PPO</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byzydz/debugging_a_ppo/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œ æˆ‘è®¤ä¸ºæˆ‘å·²ç»å®Œæˆäº†æ¨¡æ‹Ÿå’Œ ppo ä»£ç†ä¸­çš„æ‰€æœ‰éƒ¨åˆ†çš„ç»„åˆã€‚æˆ‘ç°åœ¨çš„é—®é¢˜æ˜¯ä»£ç†ä¸å­¦ä¹ ã€‚æˆ‘å°è¯•å¯¹å…¶è¿›è¡Œå¤§é‡è®­ç»ƒï¼Œä½†ä»ç„¶æ²¡æœ‰ä»»ä½•æ”¹è¿›ï¼ˆä¸»è¦æ˜¯æŸ¥çœ‹æ¼”å‘˜å’Œè¯„è®ºå®¶çš„æŸå¤±ï¼Œç„¶åæµ‹è¯•æ¨¡å‹ï¼‰ã€‚ æ‚¨å¯¹å¦‚ä½•è°ƒè¯•æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿå®ƒï¼Ÿæˆ‘åº”è¯¥æ³¨æ„ä»€ä¹ˆæ¥æ£€æŸ¥ä¸€åˆ‡æ˜¯å¦æ­£å¸¸å·¥ä½œä»¥åŠå¦‚ä½•æ£€æŸ¥ï¼Ÿ ä»»ä½•æç¤ºéƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œè°¢è°¢:) ç¼–è¾‘ï¼š è¿™æ˜¯æˆ‘çš„ ppo æ”¿ç­– https://pastebin.com/zY3AgeSF ï¼ˆæˆ‘ä¸åƒå¤§å¤šæ•°è®ºæ–‡é‚£æ ·ä½¿ç”¨ gaesï¼Œå› ä¸ºæˆ‘æ­£åœ¨æ‰§è¡Œ on-policy å¹¶ä¸”è¿˜æ²¡æœ‰æ‰¾åˆ°æ­£ç¡®çš„æ–¹æ³•ï¼Œæ— éœ€è¾“å…¥æ•´ä¸ªåºåˆ—ï¼‰ã€‚æˆ‘çš„ä¸»è¦ä»£ç çœŸçš„å¾ˆæ··ä¹±ï¼Œå› ä¸ºæˆ‘å°è¯•äº†å¾ˆå¤šä¸åŒçš„ä¸œè¥¿ï¼Œè€Œä¸”æˆ‘ä¸ç›¸ä¿¡å®ƒå†™å¾—å¾ˆå¥½ã€‚æˆ‘æ›´å–œæ¬¢ä¸€äº›å…³äºå¦‚ä½•åœ¨æ¨¡å‹ä¼¼ä¹æ²¡æœ‰å­¦ä¹ æ—¶è¿›è¡Œè°ƒè¯•çš„ä¸€èˆ¬æç¤ºï¼Œå¦‚ä½•æ£€æŸ¥å®ƒæ˜¯å¦æ˜¯è¶…å‚æ•°æˆ–ä»£ç ä¸­çš„å…¶ä»–å†…å®¹ä¸æ­£ç¡®ã€‚è¿˜ä¸å¤Ÿï¼Œå¦‚æœä½ ä»¬è®¤ä¸ºæœ‰å¸®åŠ©ï¼Œæˆ‘å°†å‘å¸ƒæˆ‘çš„æ‰€æœ‰ä»£ç ã€‚   ç”±   æäº¤/u/razton  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byzydz/debugging_a_ppo/</guid>
      <pubDate>Mon, 08 Apr 2024 14:56:26 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ç¦»çº¿ rl è¿›è¡Œ PPO é¢„è®­ç»ƒï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byzfha/ppo_pre_training_using_offline_rl/</link>
      <description><![CDATA[æœ‰æ²¡æœ‰ç¦»çº¿è®­ç»ƒppoç„¶ååœ¨çº¿finetuneçš„æ–‡ç« ï¼Ÿæˆ–è€…ä¹Ÿè®¸å¯ä»¥ç¦»çº¿å­¦ä¹  Actor Criticï¼Œç„¶ååœ¨çº¿ä½¿ç”¨ Ppo è¿›è¡Œè°ƒä¼˜ï¼Ÿ è°¢è°¢   ç”±   æäº¤ /u/What_Did_It_Cost_E_T   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byzfha/ppo_pre_training_using_offline_rl/</guid>
      <pubDate>Mon, 08 Apr 2024 14:34:49 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å¤„ç† Q-learning ä¸­çš„è¿ç»­ï¼ˆéæƒ…æ™¯ï¼‰ä»»åŠ¡ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byvrfn/how_to_handle_continuing_nonepisodic_tasks_in/</link>
      <description><![CDATA[æˆ‘æƒ³å®ç°ä½œä¸šè½¦é—´è°ƒåº¦ä¼˜åŒ–æ¨¡æ‹Ÿï¼ˆå°†å¤šä¸ªåˆ¶é€ ä»»åŠ¡åˆ†é…ç»™æœ‰é™æ•°é‡çš„å¯ç”¨æœºå™¨ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªæ°¸æ— æ­¢å¢ƒçš„æŒç»­è¿‡ç¨‹ã€‚ æˆ‘ä½¿ç”¨ Q-learning ä»¥åŠé‡æ’­ç¼“å†²åŒºå’Œ epsilon-greedy æ¥è¿›è¡Œæ¢ç´¢/åˆ©ç”¨ã€‚é€šå¸¸æˆ‘ä¼šè®­ç»ƒ N é›†ï¼Œä½†ç”±äºæ²¡æœ‰é›†ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•ç»§ç»­ã€‚  æˆ‘çš„æƒ³æ³•ï¼š å¼•å…¥è¾…åŠ©ç»ˆæ­¢çŠ¶æ€ï¼Œä½¿å…¶å†æ¬¡è½¬å˜ä¸ºæƒ…æ™¯ä»»åŠ¡ã€‚æˆ‘è®¤ä¸ºè¿™å¯¹æˆ‘çš„æƒ…å†µæœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œæˆ‘å¯ä»¥è¯´è¯¥æƒ…èŠ‚åœ¨å¤„ç†å®Œ N ä¸ªä»»åŠ¡åç»“æŸã€‚è¿™æœ‰æ„ä¹‰å—ï¼Ÿæˆ–è€…æœ‰æ›´å¥½çš„æ–¹æ³•æ¥å¤„ç†è¿™ä¸ªé—®é¢˜å—ï¼Ÿ   ç”±   æäº¤/u/NMO13  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byvrfn/how_to_handle_continuing_nonepisodic_tasks_in/</guid>
      <pubDate>Mon, 08 Apr 2024 11:43:59 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘åº”è¯¥ä½¿ç”¨ä»€ä¹ˆè¿›åŒ–ç®—æ³•ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byunu0/what_evolutionary_algorithm_should_i_use/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨åˆ¶ä½œä¸€ä¸ªä¸“æ³¨äºç¼–ç¨‹çš„ Youtube é¢‘é“ï¼Œç”¨æˆ‘è‡ªå·±çš„è¯­è¨€ Spiralï¼Œæˆ‘æ­£åœ¨å®ç°ä¸€ä¸ª æœºå™¨å­¦ä¹ åº“ã€‚æˆ‘ç›´æ¥åœ¨ GPU ä¸Šè¿›è¡Œå¥‡ç‰¹çš„å‡½æ•°å¼ç¼–ç¨‹ï¼Œæˆ‘çš„ç›®æ ‡æ˜¯å°†æ‰‘å…‹æ¸¸æˆä¸ ML åº“èåˆï¼Œå¹¶ä½¿ç”¨å®ƒæ¥è®­ç»ƒè¶…äººä»£ç†ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨å•ä¸ª GPU ä¸Šè¿›è¡Œï¼Œå¹¶ä¸”æ— éœ€æ¥è§¦ CPUã€‚è¿™é¡¹å·¥ä½œçš„ç›®çš„ä¸æˆ‘ä»Šå¤©åˆšåˆšå‘ç°çš„åŸºäº JAX çš„åº“éå¸¸ç›¸ä¼¼ï¼Œå¸Œæœ›å®ƒå­˜åœ¨ 3 å¹´å‰ã€‚å½“æ—¶ Spiral v2 åˆšåˆšå‘å¸ƒï¼Œæˆ‘ä½¿ç”¨ PyTorch å°†å…¶ç”¨äºå¾ˆå¤š RLã€‚å½“æ—¶è¯¥è¯­è¨€æœ‰ Cython åç«¯ï¼Œæˆ‘åšå‡ºäº†ä½¿ç”¨å®ƒçš„é”™è¯¯é€‰æ‹©ã€‚å½“æ—¶æˆ‘åšäº†ä¸€ä¸ªæ‰‘å…‹æ¸¸æˆï¼Œå¹¶å°è¯•ä½¿ç”¨å„ç§ RL æ–¹æ³•æ¥è®­ç»ƒ RL æ™ºèƒ½ä½“ï¼Œå…¶ä¸­è®¸å¤šæ–¹æ³•éƒ½æ˜¯æˆ‘è‡ªå·±ç¼–é€ çš„ï¼Œæˆ‘çš„ç»éªŒéå¸¸ç³Ÿç³•ï¼Œæ‰€ä»¥æˆ‘åœæ­¢äº†ç¼–ç¨‹ä¸¤å¹´ï¼Œè½¬è€Œåšäº† 3d è‰ºæœ¯ã€‚ ç°åœ¨æˆ‘å›æ¥äº†ï¼Œæƒ³è¦åšæ­£ç¡®çš„äº‹æƒ…ã€‚ æˆ‘å·²ç»è„±ç¦» ML æœ‰ä¸€æ®µæ—¶é—´äº†ï¼Œæˆ‘æƒ³çŸ¥é“æ— æ¢¯åº¦æ–¹æ³•çš„æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»æ¥æ²¡æœ‰çœŸæ­£è®¤çœŸå¯¹å¾…è¿‡ evo ç®—æ³•ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºæˆ‘å¯ä»¥é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ æ‰¾åˆ°ä¸€äº›ä¸œè¥¿ï¼Œä½†ç°åœ¨æˆ‘å°†é‡‡å–ä¸åŒçš„æ–¹æ³•å¹¶ä¸“æ³¨äºåŸºç¡€çŸ¥è¯†ã€‚æ‚¨å»ºè®®æˆ‘åšä»€ä¹ˆï¼Ÿ æˆ‘å†³å®šä¸ä½¿ç”¨ OpenAI ESï¼Œå› ä¸ºå®ƒå¯¹å¥–åŠ±ç¼©æ”¾å¾ˆæ•æ„Ÿï¼Œä½†é™¤æ­¤ä¹‹å¤–æ²¡æœ‰ç‰¹åˆ«çš„åå¥½ã€‚   ç”±   æäº¤ /u/abstractcontrol   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byunu0/what_evolutionary_algorithm_should_i_use/</guid>
      <pubDate>Mon, 08 Apr 2024 10:39:19 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ DDQN è§£å†³æ—…è¡Œå•†é—®é¢˜</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byohkp/using_a_ddqn_for_the_travelling_salesman_problem/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byohkp/using_a_ddqn_for_the_travelling_salesman_problem/</guid>
      <pubDate>Mon, 08 Apr 2024 04:03:01 GMT</pubDate>
    </item>
    <item>
      <title>è’™ç‰¹å¡ç½—æ ‘æœç´¢ä¸æ”¶æ•›</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1byifna/monte_carlo_tree_search_not_converging/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•å®ç° MCTSï¼Œä½†åœ¨æµ‹è¯•ä¸­å®ƒæ— æ³•æ”¶æ•›åˆ° minmaxï¼Œå¹¶ä¸”æœ‰ä¸€äº›æˆ‘ä¸æ˜ç™½çš„å†…å®¹ï¼š &lt; p&gt;å‡è®¾æˆ‘çš„æ ¹èŠ‚ç‚¹æœ‰ä¸¤ä¸ªå¯èƒ½çš„åŠ¨ä½œï¼Œç¬¬ä¸€ä¸ªåˆ†æ”¯åˆ†ä¸º 10 ä¸ªå…¶ä»–åŠ¨ä½œï¼Œå…¶ä¸­ä¸€ä¸ªå€¼ä¸º 0.6ï¼ˆè·èƒœæœºä¼šï¼‰ï¼Œå…¶ä»– 9 ä¸ªå€¼ä¸º 0ï¼Œç¬¬äºŒä¸ªåˆ†æ”¯åªæ˜¯ä¸€ä¸ªå€¼ä¸º 0.5 çš„å•ä¸ªåŠ¨ä½œ å› æ­¤ï¼Œåœ¨ minmax ä¸­ï¼Œç¬¬ä¸€ä¸ªåˆ†æ”¯æ›´å¥½ï¼Œå› ä¸ºåœ¨ä¸‹ä¸€æ­¥ä¸­æ‚¨å¯ä»¥é‡‡å– 0.6 æ“ä½œã€‚ä½†åœ¨ MCTS ä¸­ï¼Œç¬¬ä¸€ä¸ªåˆ†æ”¯çš„å€¼æ˜¯å¥½è·¯å¾„è·èƒœçš„å¹³å‡å€¼ï¼Œä¹Ÿæ˜¯æ‰€æœ‰å…¶ä»–åè·¯å¾„çš„å¹³å‡å€¼ 0.6+0+0+0+0+0+0+0+0+0 / 10 çˆ¶èŠ‚ç‚¹çš„å€¼ä¸åº”è¯¥æ˜¯æœ€ä½³å­èŠ‚ç‚¹çš„å€¼å—ï¼Ÿ ä½†æ˜¯åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè¯¥å€¼ä¼šè¢«æ‰€æœ‰å…·æœ‰ 0 çš„è·¯å¾„ç¨€é‡Š è¿™å°±æ˜¯æˆ‘åœ¨æ¨¡æ‹Ÿæ¸¸æˆä¸­å¾—åˆ°çš„ç»“æœã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œåº”è¯¥æ›´å¤šåœ°æ’­æ”¾ 0.6 è·¯å¾„ï¼Œä»¥æœ€ç»ˆä½¿ä½å€¼è·¯å¾„å˜å¾—æ— å…³ç´§è¦ï¼Œä½†ä¹Ÿè®¸ç”±äºæ¢ç´¢æœ¯è¯­ï¼Œä¸è‰¯è·¯å¾„æ°¸è¿œä¸ä¼šå‡å°‘åˆ°è¶³ä»¥ä½¿ 0.6 èƒœè¿‡ 0.5 æˆ‘é”™è¿‡äº†ä»€ä¹ˆå—ï¼Ÿ è°¢è°¢ã€‚   ç”±   æäº¤ /u/SSCharles   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1byifna/monte_carlo_tree_search_not_converging/</guid>
      <pubDate>Sun, 07 Apr 2024 23:11:52 GMT</pubDate>
    </item>
    <item>
      <title>è®­ç»ƒ DQN æ¥è§£å†³ç©å…· MARL é—®é¢˜æœ‰å¤šå›°éš¾ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1by4xtx/how_difficult_is_it_to_train_dqns_for_toy_marl/</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨å°è¯•è®­ç»ƒäº•å­—æ£‹ DQNï¼Œä½†åˆ°ç›®å‰ä¸ºæ­¢è¿˜æ— æ³•è®©å®ƒä»¬å­¦ä¹ æœ€ä½³ç­–ç•¥ã€‚ æˆ‘æ­£åœ¨ä½¿ç”¨ pettingzoo envï¼ˆå› æ­¤æ²¡æœ‰å›¾åƒæˆ– CNNï¼‰ï¼Œå¹¶å¹¶è¡Œè®­ç»ƒä¸¤ä¸ªä»£ç†ï¼Œå½¼æ­¤ç‹¬ç«‹ï¼Œè¿™æ ·æ¯ä¸ªä»£ç†éƒ½æœ‰è‡ªå·±çš„é‡æ’­ç¼“å†²åŒºï¼Œä¸€ä¸ªå§‹ç»ˆä½œä¸ºç¬¬ä¸€ä¸ªæ’­æ”¾ï¼Œå¦ä¸€ä¸ªä½œä¸ºç¬¬ä¸€ä¸ªæ’­æ”¾ç¬¬äºŒã€‚ æˆ‘å°è¯•è®­ç»ƒå®ƒä»¬æ•°åä¸‡æ­¥ï¼Œå¹¶ä¸”é€šå¸¸ä¼šåˆ°è¾¾å®ƒä»¬ï¼ˆä¼¼ä¹ï¼Ÿï¼‰æ”¶æ•›åˆ°çº³ä»€å‡è¡¡çš„ç‚¹ï¼Œæ¸¸æˆä»¥å¹³å±€ç»“æŸã€‚é™¤äº†å½“æˆ‘å°è¯•è®©ä»–ä»¬ä¸­çš„ä»»ä½•ä¸€ä¸ªä¸éšæœºå¯¹æ‰‹å¯¹æŠ—æ—¶ï¼Œä»–ä»¬ä»ç„¶ä¼šè¾“æ‰å¤§çº¦ 10% çš„æ—¶é—´ï¼Œè¿™æ„å‘³ç€ä»–ä»¬è¿˜æ²¡æœ‰å­¦ä¼šæœ€ä½³ç­–ç•¥ã€‚ æˆ‘è®¤ä¸ºå‘ç”Ÿè¿™ç§æƒ…å†µæ˜¯å› ä¸ºä»–ä»¬æ²¡æœ‰&#39;æˆ‘æ— æ³•å……åˆ†æ¢ç´¢æ¸¸æˆç©ºé—´ï¼Œæˆ‘ä¸ç¡®å®šä¸ºä»€ä¹ˆæƒ…å†µå¹¶éå¦‚æ­¤ã€‚æˆ‘ä½¿ç”¨ softmax é‡‡æ ·ä»é«˜æ¸©å¼€å§‹å¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å‡å°‘ï¼Œæ‰€ä»¥ä»–ä»¬è‚¯å®šåº”è¯¥åšä¸€äº›æ¢ç´¢ã€‚æˆ‘å·²ç»å°è¯•è¿‡å­¦ä¹ ç‡å’Œç½‘ç»œæ¶æ„ï¼Œåªåšå‡ºäº†æœ€å°çš„æ”¹è¿›ã€‚ æˆ‘æƒ³æˆ‘å¯ä»¥æ›´æ·±å…¥åœ°ç ”ç©¶è¶…å‚æ•°ä¼˜åŒ–å¹¶è®­ç»ƒæ›´é•¿æ—¶é—´ï¼Œä½†è¿™å¯¹äºè¿™æ ·ä¸€ä¸ªç®€å•çš„ç©å…·é—®é¢˜æ¥è¯´å¬èµ·æ¥æœ‰ç‚¹çŸ«æ‰è¿‡æ­£ã€‚å¦‚æœæˆ‘æƒ³è®­ç»ƒä»–ä»¬ç©ä¸€äº›æ›´å¤æ‚çš„æ¸¸æˆï¼Œæˆ‘æ˜¯å¦éœ€è¦æ›´å¤šçš„èµ„æºï¼Ÿæˆ–è€…ï¼Œä¾‹å¦‚ï¼Œé€‰æ‹© PPO æ˜¯å¦æ›´æ˜æ™ºï¼Ÿ æ— è®ºå¦‚ä½•ï¼Œå’†å“®å·²ç»è¶³å¤Ÿäº†ï¼Œæˆ‘æƒ³é—®ä¸€ä¸‹è®­ç»ƒ DQN æ˜¯å¦çœŸçš„é‚£ä¹ˆå›°éš¾é©¬å°”ã€‚å¦‚æœæ‚¨å¯ä»¥åˆ†äº«ä»»ä½•é€‚ç”¨äº Tic Tac Toe çš„ä¸€ç»„è¶…å‚æ•°çš„å®éªŒï¼Œå‡ºäºå¥½å¥‡ï¼Œæˆ‘ä»¬å°†éå¸¸æ¬¢è¿æ‚¨ã€‚   ç”±   æäº¤ /u/OperaRotas   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1by4xtx/how_difficult_is_it_to_train_dqns_for_toy_marl/</guid>
      <pubDate>Sun, 07 Apr 2024 13:49:06 GMT</pubDate>
    </item>
    <item>
      <title>A3C è¯„è®ºå®¶ä¼°è®¡</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bxxhvv/a3c_critic_estimate/</link>
      <description><![CDATA[      æˆ‘æ­£åœ¨ä½¿ç”¨å¼‚æ­¥ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå®¶æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¼¼ä¹è¿è¡Œå¾—ç›¸å½“å¥½ï¼Œä½†æˆ‘æ³¨æ„åˆ°ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘çš„è¯„è®ºå®¶â€œä¼°è®¡â€å˜å¾—è¶Šæ¥è¶Šå·®ã€‚å’Œâ€œå®é™…å€¼â€éšç€æ—¶é—´çš„æ¨ç§»ä¼šçˆ†ç‚¸æˆè´Ÿé¢çš„ã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¼•å¯¼é—®é¢˜ï¼Œå…¶ä¸­æ‰¹è¯„è€…æŸå¤±å¦‚ä¸‹ï¼š loss = torch.nn.MSELoss()(reward + gamma * value_next , value) ç¯å¢ƒéå¸¸å˜ˆæ‚ï¼Œä½†åå‘äºè´Ÿé¢å¥–åŠ± - æ‰€ä»¥æˆ‘æ¨æµ‹æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…æ˜¯æ‰¹è¯„å®¶ä¼šå®šæœŸçŒœæµ‹å¾—å¤ªç§¯æï¼Œå­¦ä¼šå˜å¾—æ›´åŠ æ¶ˆæï¼Œæ‰€å‘ç”Ÿçš„æ—¢æ˜¯åˆå§‹çŠ¶æ€çš„ä»·å€¼é¢„æµ‹ï¼Œä¹Ÿæ˜¯éšç€æ—¶é—´çš„æ¨ç§»ï¼Œä¸‹ä¸€ä¸ªçŠ¶æ€ï¼ˆéƒ½æ¥è‡ªæ‰¹è¯„è€…ï¼‰å¾€å¾€ä¼šå˜å¾—è¶Šæ¥è¶Šæ¶ˆæã€‚ä½†ç”±äºéšç€æ—¶é—´çš„æ¨ç§»ï¼Œä¸¤è€…éƒ½ä¼šä»¥ç›¸åŒçš„é€Ÿåº¦å˜å¾—æ›´åŠ è´Ÿé¢ï¼Œæ‰¹è¯„è€…æœ¬èº«çš„æŸå¤±è®¡ç®—å¹¶ä¸ä¼šå˜å¾—éå¸¸æ‰­æ›²ã€‚  ç„¶è€Œï¼Œâ€œçœŸå®â€çš„æƒ…å†µæ˜¯è¿™æ ·çš„ã€‚è¯¥æŒ‡æ ‡çš„å€¼å®é™…ä¸Šåº”è¯¥è½åœ¨ [+5,-5] ä¹‹é—´ï¼Œå› æ­¤éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘æ‹…å¿ƒè¿™æœ‰å¯èƒ½å¼€å§‹å‘å‚ä¸è€…å‘å‡ºå¥‡æ€ªçš„ä¿¡å·ä»¥è¿›è¡Œå…¶ä¼˜åŠ¿æ›´æ–°ã€‚  æˆ‘åœ¨è¿™é‡Œåšé”™äº†ä»€ä¹ˆæ•™ç§‘ä¹¦å—ï¼Ÿæ‚¨å¯ä»¥æ¨èä¸€äº›å¥½çš„ä¿®å¤æ–¹æ³•å—ï¼Ÿ  â€‹ â€‹ ï¼ˆé¢œè‰²ä»£è¡¨ä¸åŒçš„è¯„è®ºä»£ç†ï¼‰ â€‹ â€‹ â€‹ â€‹ â€‹ â€‹    ç”±   æäº¤ /u/Rhyno_Time   [é“¾æ¥] [è¯„è®º] &lt; /è¡¨&gt;]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bxxhvv/a3c_critic_estimate/</guid>
      <pubDate>Sun, 07 Apr 2024 06:22:52 GMT</pubDate>
    </item>
    <item>
      <title>éœ€è¦ä¸€äº›å…³äºåœ¨åŒ»å­¦æˆåƒé‡å»ºèƒŒæ™¯ä¸‹ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æƒ³æ³•çš„åé¦ˆ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bxw4ci/need_some_feedback_on_an_idea_for_using/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bxw4ci/need_some_feedback_on_an_idea_for_using/</guid>
      <pubDate>Sun, 07 Apr 2024 05:00:24 GMT</pubDate>
    </item>
    <item>
      <title>æ·±Qç½‘ç»œ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bxtca2/deep_q_network/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bxtca2/deep_q_network/</guid>
      <pubDate>Sun, 07 Apr 2024 02:31:43 GMT</pubDate>
    </item>
    <item>
      <title>è°é¦–å…ˆé€šè¿‡å°†æŒ‡ç¤ºå‡½æ•°å†™æˆé©¬å°”å¯å¤«å™ªå£°æ¥è¯æ˜å¼‚æ­¥ Q å­¦ä¹ çš„æ”¶æ•›æ€§ï¼Ÿ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bxokh3/who_first_proved_the_convergence_of_asynchronous/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»æœ‰äº†å‡ ä¸ªä¾èµ–éšæœºé€¼è¿‘ç†è®ºçš„å¼‚æ­¥ Q-learning æ”¶æ•›è¯æ˜å¹¶è¿›è¡Œäº†æ›´æ–°ï¼š  $Q_k+1(s,a) &lt;- Q_k(s,a) + I[s_k=s, a_k=a] \alpha (Y_k)$ Iæˆ‘æ­£åœ¨è€ƒè™‘è¯æ˜ï¼Œç‰¹åˆ«æ³¨æ„åˆ° I[s_k=s, a_k=a] æ˜¯ä¸€ä¸ªé©¬å°”å¯å¤«è¿‡ç¨‹ï¼ˆå› ä¸ºè¿‡ç¨‹ (s,a) æ˜¯ï¼‰ï¼Œå…¶è¿‡æ¸¡å‡½æ•°ä¾èµ–äº $Q$ çš„å½“å‰å€¼ï¼Œå¹¶å¾—å‡ºæ”¶æ•›ç»“æœæ¥è‡ªå¸¦æœ‰é©¬å°”å¯å¤«å™ªå£°çš„éšæœºè¿‡ç¨‹ã€‚ æœ‰è°çŸ¥é“è°ç¬¬ä¸€ä¸ªå¼•å…¥äº†è¿™ç§æ–¹æ³•ï¼Ÿ éå¸¸æ„Ÿè°¢ï¼   ç”±   æäº¤/u/ttlizon  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bxokh3/who_first_proved_the_convergence_of_asynchronous/</guid>
      <pubDate>Sat, 06 Apr 2024 22:46:39 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨åŒä¸€ä»£ç†å¹¶è¡Œè®­ç»ƒå…·æœ‰ä¸åŒæ•°æ®çš„ç¯å¢ƒ</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1bxh59o/training_environments_with_different_data_in/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è€ƒè™‘è®­ç»ƒå‡ ä¸ªè‡ªå®šä¹‰ç¯å¢ƒï¼Œä½†æ¯ä¸ªç¯å¢ƒéƒ½æœ‰ä¸€æ‰¹æ•°æ®ï¼Œå¤§çº¦æ˜¯ 2k ä¸ª JSON æ–‡ä»¶ï¼Œæ¯ä¸ªæ•°æ®ä»£è¡¨ä¸€ä¸ªå‰§é›†å’Œç¯å¢ƒä»æ•°æ®åº“è·å–è¿™äº›æ–‡ä»¶ã€‚æˆ‘çš„æƒ³æ³•æ˜¯ä½¿ç”¨åŒ…å«åœ¨ SubprocVecEnv ä¸­çš„ 150 ä¸ªç¯å¢ƒå®ä¾‹æ¥è®­ç»ƒ SB3 DQN æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¼¼ä¹æœ‰æ•ˆï¼Œä½†æˆ‘é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼š  é€Ÿåº¦è®­ç»ƒä¼¼ä¹ç›¸å½“ä½ï¼Œæˆ‘æ— æ³•å¼„æ¸…æ¥šç“¶é¢ˆæ˜¯ä»€ä¹ˆï¼ˆåœ¨ 4 ä¸ª Nvidia A100 GPU ä¸Šè®­ç»ƒï¼‰æˆ‘å°è¯•å¢åŠ ç¯å¢ƒæ•°é‡ï¼Œä»è€Œå‡å°‘æ¯ä¸ªç¯å¢ƒçš„æ–‡ä»¶æ•°é‡ï¼Œä½†è¿™å¹¶æ²¡æœ‰&#39; t æ”¹å˜é€Ÿåº¦  æˆ‘ä¸å¤ªç¡®å®šå•ä¸ªä»£ç†æ˜¯å¦ä¼šä»æ‰€æœ‰ 150 ä¸ªå®ä¾‹çš„æ‰€æœ‰ç»éªŒä¸­å­¦ä¹ ï¼Œæˆ‘æƒ³ä¿è¯æ¯ä¸ªå®ä¾‹åœ¨è®­ç»ƒå®Œæˆä¹‹å‰å®Œæˆæ‰€æœ‰æ–‡ä»¶  å¸Œæœ›å¾—åˆ°ä»»ä½•å¸®åŠ©æˆ–æƒ³æ³•ï¼Œè°¢è°¢ï¼   ç”±   æäº¤ /u/CandidateIcy4911   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1bxh59o/training_environments_with_different_data_in/</guid>
      <pubDate>Sat, 06 Apr 2024 17:31:03 GMT</pubDate>
    </item>
    <item>
      <title>â€œæ— éœ€æœç´¢çš„å¤§å¸ˆçº§å›½é™…è±¡æ£‹â€ï¼ŒRuoss ç­‰äºº 2024</title>
      <link>https://www.reddit.com/r/reinforcementlearning/comments/1baz8hl/grandmasterlevel_chess_without_search_ruoss_et_al/</link>
      <description><![CDATA[ ç”±   æäº¤/u/gwern  [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/reinforcementlearning/comments/1baz8hl/grandmasterlevel_chess_without_search_ruoss_et_al/</guid>
      <pubDate>Sun, 10 Mar 2024 02:25:15 GMT</pubDate>
    </item>
    </channel>
</rss>