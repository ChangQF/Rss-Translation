<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 20 Mar 2024 18:16:32 GMT</lastBuildDate>
    <item>
      <title>Tensorflow 分词器问题。 num_words 到底做什么？</title>
      <link>https://stackoverflow.com/questions/78195133/tensorflow-tokenizer-question-what-num-words-does-exactly</link>
      <description><![CDATA[执行此代码时，我得到 11937，但我不应该得到 10.000 吗？
如果我不应该，我有几个后续问题：

num_words 有什么意义？
我得到的数字 11937 代表什么？
如何限制词汇量？

MAX_WORDS_COUNT = 10000
胜利大小 = 1000
获胜跳数 = 100

tokenizer = Tokenizer(num_words=MAX_WORDS_COUNT, 过滤器=&#39;!&quot;#$%&amp;()*+,-–—./…:;&lt;=&gt;?@[\\]^_`{|}~ «»\t\n\xa0\ufeff&#39;,
                      lower=True, split=&#39; &#39;, oov_token=&#39;unknown_word&#39;, char_level=False, )

tokenizer.fit_on_texts(x_data)

items = list(tokenizer.word_index.items())
打印（长度（项目））

我期望输出为 10.000，因为我相信 num_words 限制了词汇量的大小。
如果需要，我可以提供我的 Colab 笔记本中的完整代码。]]></description>
      <guid>https://stackoverflow.com/questions/78195133/tensorflow-tokenizer-question-what-num-words-does-exactly</guid>
      <pubDate>Wed, 20 Mar 2024 17:04:50 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型对于相同的文本输入每次都会预测不同的值</title>
      <link>https://stackoverflow.com/questions/78194276/keras-model-predicts-different-value-everytime-for-the-same-input-of-text</link>
      <description><![CDATA[我已经加载了一个预训练的 LSTM 模型，在使用该模型进行预测时，对于相同的文本输入每次都会给出不同的值，我提供了下面的代码片段，有人可以帮助我识别问题吗？
我还检查了 stateful 并将其设置为 False
]]></description>
      <guid>https://stackoverflow.com/questions/78194276/keras-model-predicts-different-value-everytime-for-the-same-input-of-text</guid>
      <pubDate>Wed, 20 Mar 2024 14:49:54 GMT</pubDate>
    </item>
    <item>
      <title>如何从shap值中只得到重要的词？</title>
      <link>https://stackoverflow.com/questions/78194233/how-can-get-only-important-word-from-shap-value</link>
      <description><![CDATA[我只想获取文字和值，而不获取图表。
shap_values[:,:,1].abs.mean(0) 根据重要性提供“单词”。然而，代码给出了一个仅由数字组成的数组。如果您使用 shap.plots.bar(shap_values[:,:,1].abs.mean(0))，您可以看到单词。在没有图表的情况下，如何获得考虑到其重要性的“单词”？
!pip 安装数据集
从数据集导入load_dataset

数据集 = load_dataset(“imdb”)
df = 数据集[&#39;测试&#39;].to_pandas()
Short_data = [v[:500] for v in df[“text”][:20]]

从转换器导入 AutoTokenizer、AutoModelForSequenceClassification、管道
t1okenizer = AutoTokenizer.from_pretrained(“lvwerra/distilbert-imdb”)
m1odel = AutoModelForSequenceClassification.from_pretrained(“lvwerra/distilbert-imdb”)
分类器 = pipeline(&#39;文本分类&#39;, device=0,return_all_scores=True, model=m1odel,tokenizer=t1okenizer)
分类器（短数据[：10]）

导入形状
解释器 = shap.Explainer(分类器)
shap_values = 解释器(short_data[:20])
shap.plots.bar(shap_values[:,:,1].abs.mean(0))
]]></description>
      <guid>https://stackoverflow.com/questions/78194233/how-can-get-only-important-word-from-shap-value</guid>
      <pubDate>Wed, 20 Mar 2024 14:44:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习移动网V2</title>
      <link>https://stackoverflow.com/questions/78193353/machine-learning-mobile-net-v2</link>
      <description><![CDATA[如何实施渐进学习？
我正在寻找一种训练大型数据集的方法，因此我需要每次在一小部分上训练模型，同时保留之前的训练结果......
询问 Gpt 后：我尝试在训练新模型时将以前的权重加载到基础模型中
input_tensor = 输入(形状=(IMG_SIZE, IMG_SIZE, ColorChannels))
baseModel = MobileNetV2(pooling=&#39;avg&#39;, include_top=False, input_tensor=input_tensor)
baseModel.load_weights(PROJECT_DIR+“/ModelWeights.h5”，by_name = True，skip_mismatch = True)
对于 baseModel.layers 中的图层：
    可训练层 = False
headModel = baseModel.输出
headModel = Dense(1, 激活=“sigmoid”)(headModel)
模型=模型（输入=baseModel.input，输出=headModel，名称=&#39;new_model&#39;）

print(&quot;正在编译模型...&quot;)
model.compile(loss=“binary_crossentropy”,
                优化器=&#39;亚当&#39;,
                指标=[“准确度”])
]]></description>
      <guid>https://stackoverflow.com/questions/78193353/machine-learning-mobile-net-v2</guid>
      <pubDate>Wed, 20 Mar 2024 12:35:11 GMT</pubDate>
    </item>
    <item>
      <title>确定 RTX 4090 训练性能不佳的原因</title>
      <link>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-of-rtx-4090</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-of-rtx-4090</guid>
      <pubDate>Wed, 20 Mar 2024 11:16:15 GMT</pubDate>
    </item>
    <item>
      <title>pytorch和cuda安装问题[重复]</title>
      <link>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</link>
      <description><![CDATA[我正在尝试在 Windows 11 上使用 Anaconda3 安装带有 Cuda 的 PyTorch
我的nvidia-smi输出驱动程序版本：551.76，CUDA版本：12.4
我的火炬版本是我从官方网站安装的 12.2
&lt;前&gt;&lt;代码&gt;火炬2.2.1+cu121
火炬音频2.2.1+cu121
火炬视觉 0.17.1+cu121

但问题是，当我运行 torch.cuda.is_available() 时，它显示 false 作为输出。这里出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</guid>
      <pubDate>Wed, 20 Mar 2024 10:58:20 GMT</pubDate>
    </item>
    <item>
      <title>ViT 模型的 HuggingFace Inference API 问题 - “图像特征提取”错误</title>
      <link>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</link>
      <description><![CDATA[我的 Vision Transformer (ViT) 模型 rshrott/vit-base-renovation2 的推理 API 遇到问题。
https://huggingface.co/rshrott/vit-base-renovation2 
当我尝试使用 API 时，收到以下错误：
&lt;前&gt;&lt;代码&gt;{
“错误”：“HfApiJson（反序列化（错误（“未知变体图像特征提取，预期音频分类，音频到音频，音频源分离，自动语音识别，特征提取之一，文本分类、标记分类、问答、翻译、摘要、文本生成、text2text-生成、填充掩模、零样本分类、零样本图像分类、会话、表格问答、图像分类、图像分割、图像到文本、文本到语音、...视觉问答、视频分类、文档问答、图像到图像、深度估计，行：1 ，栏目：318)))”
}

有趣的是，当我直接在 Python 中使用 Transformer 管道时，模型按预期工作：
从转换器导入管道
从 PIL 导入图像
导入请求

管道=管道（模型=“rshrott/vit-base-renovation2”）
url = &#39;https://example.com/image.jpeg&#39;
图像= Image.open(requests.get(url,stream=True).raw)
preds = 管道(图像)

此代码运行没有任何问题并返回预期的预测。但是，通过推理 API 使用同一模型时会遇到错误。我怀疑可能存在与预期任务类型相关的配置问题，但我不确定如何解决它。
为什么会出现此错误以及如何修复它？我已经检查了型号卡和配置，但我似乎无法找到“图像特征提取”的来源或原因。]]></description>
      <guid>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</guid>
      <pubDate>Wed, 20 Mar 2024 10:44:57 GMT</pubDate>
    </item>
    <item>
      <title>用于在本地部署 70B 参数语言模型以服务 200 个并发用户的最佳基础设施设置 [关闭]</title>
      <link>https://stackoverflow.com/questions/78192362/optimal-infrastructure-setup-for-deploying-a-70b-parameter-language-model-locall</link>
      <description><![CDATA[我有一个由 OLLMA 提供的大型语言模型 (LLM)，包含大约700 亿个参数。我希望在本地部署此模型，以服务最多 200 个并发用户。考虑到有效运行此类模型的繁重计算要求，我正在探索设置必要基础设施的选项。
我应该选择虚拟机 (VM) 还是在本地部署模型？此外，我希望获得有关系统配置的建议，包括 RAM、GPU、存储容量和处理器等规格。
我在没有 GPU 系统的情况下尝试过此操作，但它不起作用。
我想运行700亿参数，为最多200个并发用户提供服务。]]></description>
      <guid>https://stackoverflow.com/questions/78192362/optimal-infrastructure-setup-for-deploying-a-70b-parameter-language-model-locall</guid>
      <pubDate>Wed, 20 Mar 2024 10:01:24 GMT</pubDate>
    </item>
    <item>
      <title>对同一数据集的不同子组进行迁移学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78190629/transfer-learning-on-different-subgroups-of-the-same-dataset</link>
      <description><![CDATA[我正在尝试根据回归任务的特定列中的值将原始数据集分为 6 个子组。每个子组中目标变量的分布非常相似。我的目标是通过首先对 5 个子组进行预训练，然后对最后一个子组进行微调来应用迁移学习。
对于预训练，我为每个子组设置了单独的训练、验证和测试集。预训练包括将5个子组的训练集和验证集结合起来，用它们来训练模型，验证模型，然后测量测试集上的损失。
随后，我使用预训练中的模型权重，并仅使用最终子组的训练集和验证集进行微调，并再次测量测试集上的损失。
但是，我遇到了一个问题，即我的模型对预训练数据过度拟合，导致微调过程中第一个周期的提前停止，因为微调集的验证误差会增加。
我的方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78190629/transfer-learning-on-different-subgroups-of-the-same-dataset</guid>
      <pubDate>Wed, 20 Mar 2024 02:45:43 GMT</pubDate>
    </item>
    <item>
      <title>我的 scikit-learn 代码序列正确吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78187495/is-my-scikit-learn-code-sequence-correct</link>
      <description><![CDATA[我已经构建了一个包含一些转换的管道并训练了一个 SVC 分类器。代码中构建模型的步骤顺序是否正确？ n次交叉验证效率较低。
我正在使用此处找到的processed.cleveland.data数据集：https： //archive.ics.uci.edu/dataset/45/heart+disease。
将 pandas 导入为 pd
将 numpy 导入为 np
导入操作系统
从 pathlib 导入路径

从 sklearn.model_selection 导入 train_test_split
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.model_selection 导入 cross_val_score

从 sklearn.compose 导入 ColumnTransformer
从 sklearn.pipeline 导入管道
从 sklearn.preprocessing 导入 OneHotEncoder
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.impute 导入 SimpleImputer

从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.svm 导入 SVC
url =“C:/Users/.../processedcleveland.data”
名称 = [&#39;年龄&#39;, &#39;性别&#39;, &#39;cp&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;thalach&#39;, &#39;exang&#39;, &#39;oldpeak&#39;, &#39;slope&#39;, &#39;ca&#39; , &#39;thal&#39;, &#39;num&#39;]
def getData():
        返回 pd.read_csv(url, sep=&#39;,&#39;, 名称=名称)

输入 = 获取数据()
打印（输入.info（））
打印（输入.描述（））

数组=输入.值
X = 数组[:,0:13]
y = 数组[:,13]

dataframe = pd.DataFrame.from_records(X)
数据帧[[1,2,5,6,8]] =数据帧[[1,2,5,6,8]].astype(str)

打印(dataframe.info())

numeric_ix = dataframe.select_dtypes(include=[&#39;int64&#39;, &#39;float64&#39;]).columns
categorical_ix = dataframe.select_dtypes(include=[&#39;object&#39;, &#39;bool&#39;]).columns

打印（数字_ix）
打印（分类_ix）
&#39;&#39;&#39;
t = [(&#39;cat0&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;), [1, 2, 5, 6, 8]), (&#39;cat1&#39;, OneHotEncoder(), categorical_ix), (&#39;num0&#39;, SimpleImputer(strategy) =&#39;中位数&#39;), numeric_ix), (&#39;num1&#39;, MinMaxScaler(), numeric_ix)]
col_transform = ColumnTransformer(变压器=t)

管道 = 管道(步骤=[(&#39;t&#39;, col_transform)])
# 将管道拟合到转换后的数据上
结果 = pipeline.fit_transform(dataframe)

打印（类型（pd.DataFrame.from_records（结果）））
打印（pd.DataFrame.from_records（结果）.to_string（））
&#39;&#39;&#39;
X_train、X_validation、Y_train、Y_validation = train_test_split(X、y、test_size=0.20、random_state=1)


categorical_impute = 管道([
    （“mode_impute”，SimpleImputer（missing_values = np.nan，策略=&#39;most_frequent&#39;）），
    (“one_hot”, OneHotEncoder())
]）

numeric_impute = 管道([
    （“num_mode_impute”，SimpleImputer（missing_values = np.nan，策略=&#39;中位数&#39;）），
    (“min_max”, StandardScaler())
]）

预处理器 = ColumnTransformer([
    (“cat_impute”, categorical_impute, categorical_ix),
    (“num_impute”, numeric_impute, numeric_ix)
]，余数=“直通”）


模型 = SVC(伽玛=&#39;自动&#39;)

kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)

pipeline = Pipeline(steps=[(&#39;prep&#39;, 预处理器), (&#39;m&#39;, model)])

cv_results = cross_val_score(管道, X_train, Y_train, cv=kfold, 评分=&#39;准确度&#39;)
print(&#39;%s: %f (%f)&#39; % (&quot;SVC: &quot;, cv_results.mean(), cv_results.std()))
# 结果 = preprocessor.fit_transform(dataframe)
# print(pd.DataFrame.from_records(结果).to_string())

如上所述，分类器的效率非常低。顺序有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78187495/is-my-scikit-learn-code-sequence-correct</guid>
      <pubDate>Tue, 19 Mar 2024 14:38:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 的 Google Colab Bert 实例化错误</title>
      <link>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</link>
      <description><![CDATA[我正在尝试在 Colab 上使用 Tensorflow 构建 Bert 模型。这段代码几周前就可以完美运行。现在，如果我尝试实例化模型，则会收到以下错误：
初始化 TF 2.0 模型 TFBertModel 时未使用 PyTorch 模型的某些权重：[&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls .predictions.transform.LayerNorm.weight&#39;、&#39;cls.predictions.bias&#39;、&#39;cls.seq_relationship.bias&#39;、&#39;cls.predictions.transform.dense.bias&#39;、&#39;cls.seq_relationship.weight&#39;]
- 如果您从在其他任务或其他架构上训练的 PyTorch 模型初始化 TFBertModel（例如，从 BertForPreTraining 模型初始化 TFBertForSequenceClassification 模型），这是预期的。
- 如果您从希望完全相同的 PyTorch 模型初始化 TFBertModel（例如，从 BertForSequenceClassification 模型初始化 TFBertForSequenceClassification 模型），则不会出现这种情况。
TFBertModel 的所有权重都是从 PyTorch 模型初始化的。
如果您的任务与检查点模型训练的任务类似，您就可以使用 TFBertModel 进行预测，而无需进一步训练。
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-b0e769ef7​​890&gt;在&lt;细胞系：7&gt;()
      5 SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
      6 SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
----&gt; 7 SC_pooler_output = SC_bert_model(SC_input_layer, Attention_mask=SC_mask_layer)[1] # 第二个输出，che è il pooler_output
      8
      9 # 辍学层的Aggiungi

36帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py 在 type_spec_from_value(value) 中
   1002 3，“无法将 %r 转换为张量：%s” % (类型(值).__name__, e))
   1003
-&gt;第1004章
   第1005章 1005
   1006

TypeError：调用层“嵌入”时遇到异常（类型 TFBertEmbeddings）。

无法为名称构建 TypeSpec：“tf.debugging.assert_less_5/assert_less/Assert/Assert”
op：“断言”
输入：“tf.debugging.assert_less_5/assert_less/All”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_0”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_1”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_2”
输入：“占位符”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_4”
输入：“tf.debugging.assert_less_5/assert_less/y”
属性{
  键：“总结”
  价值 {
    我：3
  }
}
属性{
  键：“T”
  价值 {
    列表 {
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_INT32
      类型：DT_STRING
      类型：DT_INT32
    }
  }
}
 不支持的类型。

调用层“embeddings”接收的参数（类型 TFBertEmbeddings）：
  • input_ids=
  •position_ids=无
  • token_type_ids=
  • input_embeds=无
  •过去的键值长度=0
  • 训练=False

模型的代码是：
SC_input_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“input_ids”)
SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
SC_pooler_output = SC_bert_model（SC_input_layer，attention_mask = SC_mask_layer）[1]

# Dropout 层的Aggiungi
SC_dropout_layer = Dropout(dropout_rate)(SC_pooler_output)
SC_output_layer = 密集（6，激活=&#39;sigmoid&#39;）（SC_dropout_layer）
SC_model = 模型(输入=[SC_input_layer, SC_mask_layer], 输出=SC_output_layer)

我发现安装tensorflow 2.10.0可以工作，但是使用Google Colab时我的CUDA版本有问题，并且使用tensorflow 2.10它无法识别GPU。
该代码几周前就可以工作，有人有解决方案吗？
编辑：同样的错误出现在 Kaggle 上。]]></description>
      <guid>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</guid>
      <pubDate>Sun, 17 Mar 2024 17:03:42 GMT</pubDate>
    </item>
    <item>
      <title>部分依赖图 - 使用缩放数据开发的模型，如何取消 PDP 缩放？</title>
      <link>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</link>
      <description><![CDATA[我已经用Python制作了一个随机森林分类器模型，现在想要制作部分依赖图（PDP）。我使用缩放数据来训练和测试模型，并使 PDP 如下所示：
PartialDependenceDisplay.from_estimator(best_clf, X_test_final, best_features)。但是，x 轴值经过缩放，这限制了可解释性。
在调用 PartialDependenceDisplay 之前取消缩放数据 X_test_final 不起作用，有关如何将 x 轴值从缩放更改为未缩放的任何建议？我已使用 StandardScaler() 缩放了我的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</guid>
      <pubDate>Fri, 15 Mar 2024 13:15:52 GMT</pubDate>
    </item>
    <item>
      <title>部署机器学习 Flask 项目时出错</title>
      <link>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</link>
      <description><![CDATA[我正在尝试使用 LSTM 构建手语识别模型。我是 Flask 新手，找不到问题所在。当我运行该文件时，它会打开相机但不会检测到该操作。此外，一旦相机打开，应用程序就会卡住。如何找到错误？
代码如下：
来自flask导入Flask，render_template，Response
导入CV2
进口泡菜
导入 pyttsx3
将 numpy 导入为 np
将 mediapipe 导入为 mp
导入线程

应用程序=烧瓶（__名称__）

从tensorflow.keras.models导入load_model
model = load_model(&#39;action.h5&#39;)

mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils

actions = np.array([&#39;你好&#39;,&#39;我是&#39;,&#39;阿凡&#39;,&#39;谢谢&#39;,&#39;我爱你&#39;,&#39;发烧&#39;,&#39;再见&#39;,&#39;上帝&#39;])

def mediapipe_detection（图像，模型）：
    图像 = cv2.cvtColor(图像, cv2.COLOR_BGR2RGB)
    image.flags.writeable = False
    结果 = model.process(图像)
    image.flags.writeable = True
    图像 = cv2.cvtColor(图像, cv2.COLOR_RGB2BGR)
    返回图像、结果

def extract_keypoints（结果）：
    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
    返回 np.concatenate([lh, rh])

def draw_styled_landmarks（图像，结果）：
    mp_drawing.draw_landmarks(图像, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=2)
                             ）
    mp_drawing.draw_landmarks(图像, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(200, 200,200), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(200, 200, 200), 厚度=2, 圆半径=2)
                             ）

序列=[]
句子=[]
预测=[]
阈值 = 0.5

上限 = cv2.VideoCapture(0)

defgenerate_frames():
    sequence = [] # 初始化序列变量
    Sentence = [] # 初始化Sentence变量
    而真实：
        ret, 框架 = cap.read()
        如果不转：
            休息

        图像，结果= mediapipe_detection（框架，整体）
        draw_styled_landmarks（图像，结果）
        关键点 = extract_keypoints(结果)
        序列.append(关键点)
        序列 = 序列[-30:]

        如果长度（序列）== 30：
            res = model.predict(np.expand_dims(序列，轴=0))[0]
            预测.append(np.argmax(res))
            
            if np.unique(预测[-10:])[0] == np.argmax(res):
                如果 res[np.argmax(res)] &gt;临界点：
                    if len(句子) &gt; 0:
                        if actions[np.argmax(res)] !=句子[-1]:
                            句子.append(actions[np.argmax(res)])
                            new_word = 动作[np.argmax(res)]
                            t2s.say(new_word)
                            t2s.runAndWait()
                    别的：
                        句子.append(actions[np.argmax(res)])
                        new_word = 动作[np.argmax(res)]
                        t2s.say(new_word)
                        t2s.runAndWait()

            if len(句子) &gt; 5：
                句子 = 句子[-5:]

        ret, buffer = cv2.imencode(&#39;.jpg&#39;, 图片)
        帧 = buffer.tobytes()
        产量（b&#39;--帧\r\n&#39;
                b&#39;内容类型：image/jpeg\r\n\r\n&#39; + 帧 + b&#39;\r\n&#39;)

    cap.release()


@app.route(&#39;/&#39;)
定义索引（）：
    返回 render_template(&#39;index.html&#39;)

@app.route(&#39;/video_feed&#39;)
def video_feed():
    返回响应（generate_frames（），mimetype =&#39;multipart / x-mixed-replace；边界=框架&#39;）

如果 __name__ == “__main__”：
    t2s = pyttsx3.init()
    整体 = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)
    应用程序运行（调试=真）
  


我尝试过更改模型和修改代码，但不起作用。最初相机馈送未显示，但现在可以正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</guid>
      <pubDate>Fri, 15 Mar 2024 07:20:28 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”</title>
      <link>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</link>
      <description><![CDATA[我正在尝试将 Missforest 作为处理表数据中缺失值的方法。
导入sklearn
打印（sklearn.__version__）
-&gt;1.2.1

导入 sklearn.neighbors._base
导入系统
sys.modules[&#39;sklearn.neighbors.base&#39;] = sklearn.neighbors._base

!pip 安装缺少的py
从missingpy导入MissForest

到目前为止一切正常，但从昨天开始，出现了以下错误消息。
导入错误：无法从“sklearn.neighbors._base”导入名称“_check_weights”

我想知道如何处理这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</guid>
      <pubDate>Sat, 04 Mar 2023 01:48:43 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 中的 TfidfVectorizer 如何专门包含单词</title>
      <link>https://stackoverflow.com/questions/19753945/tfidfvectorizer-in-sklearn-how-to-specifically-include-words</link>
      <description><![CDATA[我对 TfidfVectorizer 有一些疑问。
我不清楚这些词是如何选择的。我们可以提供最低支持，但在那之后，什么将决定选择哪些功能（例如，更高的支持更多机会）？如果我们说 max_features = 10000，我们总是得到相同的结果吗？如果我们说 max_features = 12000，我们会得到相同的 10000 特征，但额外添加 2000 吗？ 
此外，有没有办法扩展例如 max_features=20000 功能？我将它放在一些文本上，但我知道一些肯定应该包含的单词，还有一些表情符号“:-)”等。如何将这些添加到 TfidfVectorizer 对象中，以便它将可以使用该对象，用它来拟合和预测
to_include = [&quot;:-)&quot;, &quot;:-P&quot;]
方法 = TfidfVectorizer(max_features=20000, ngram_range=(1, 3),
                      # 我知道停用词，但是包含单词怎么样？
                      stop_words=test.stoplist[:100],
                      # 包含单词 ??
                      分析器=&#39;词&#39;,
                      min_df=5)
方法.fit(训练数据)

寻求结果：
X = method.transform(traindata)
X
”的稀疏矩阵
 以压缩稀疏行格式存储了 1135520 个元素&gt;]，
 其中 N 是样本大小
]]></description>
      <guid>https://stackoverflow.com/questions/19753945/tfidfvectorizer-in-sklearn-how-to-specifically-include-words</guid>
      <pubDate>Sun, 03 Nov 2013 14:19:46 GMT</pubDate>
    </item>
    </channel>
</rss>