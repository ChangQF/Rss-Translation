<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 22 May 2024 09:16:34 GMT</lastBuildDate>
    <item>
      <title>名为“协助视障人士”的项目的特色</title>
      <link>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</link>
      <description><![CDATA[我正在开展一个名为“为视障人士提供援助”的项目。我已经添加了一些功能，并且正在尝试添加更多功能。
任何人都可以向我建议一个可以添加以使其完美的功能列表吗？]]></description>
      <guid>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</guid>
      <pubDate>Wed, 22 May 2024 07:11:59 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“utils.feature_extractor”的模块[关闭]</title>
      <link>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</link>
      <description><![CDATA[(https://i.sstatic.net/kuuxNTb8.png)]( https://i.sstatic.net/1KEX5aC3.png)
您好，为什么我有这个错误，我的文件上已经有这个函数，但它仍然错误？
我正在创建一个网络钓鱼链接检测，需要在执行结果之前扫描所需的功能。
我已经添加了该功能，我检查了拼写，但什么也没发生。]]></description>
      <guid>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</guid>
      <pubDate>Wed, 22 May 2024 06:36:46 GMT</pubDate>
    </item>
    <item>
      <title>哪个库适合基于人脸检测的考勤系统，需要在没有GPU系统的低硬件设备上运行[关闭]</title>
      <link>https://stackoverflow.com/questions/78515586/which-is-the-suitable-library-for-face-detection-based-attendance-system-which</link>
      <description><![CDATA[需要在 Raspberry pi 中快速且准确地运行人脸检测代码。如果没有 GPU，输出非常慢，而且我无法使用 GPU，因此如果有人可以帮助或指导我，我将非常感激
任何用于人脸识别的库建议或代码]]></description>
      <guid>https://stackoverflow.com/questions/78515586/which-is-the-suitable-library-for-face-detection-based-attendance-system-which</guid>
      <pubDate>Wed, 22 May 2024 06:09:35 GMT</pubDate>
    </item>
    <item>
      <title>模型通过后的梯度检查点</title>
      <link>https://stackoverflow.com/questions/78514889/gradient-checkpointing-after-model-passing</link>
      <description><![CDATA[假设在默认设置中，我有两个 3d 张量作为输入，例如 batch_len x seq_len x ebb_size，我将其传递给类似模型，在输出上我再次有 2 个 3d 张量，然后我得到通过 einsum 计算 4d 张量，例如 torch.einsum(&#39;ijk, mnk -&gt; ijmn&#39;,first_tensor, secondary_tensor)，然后用最大值之和将其减少到 2d，获取分数并计算损失。问题是这个 4d 张量需要很多内存，而且我不能接受大批量大小，这就是为什么我想在 einsum 之前检查所有内容，然后计算第一个张量的前 k 批的 einsum，如 torch.einsum(&#39; ijk, mnk → ijmn,first_tensor[:k], secondary_tensor)，其中k ~first_tensor.shape[0] / 10，然后计算这些小张量的最大值之和，计算损失，从 GPU 内存中删除这个小的 4d 张量，对第二批第一个张量、第三批等进行相同的操作。最主要的是我想从 GPU 内存中删除所有 4d 张量。向后，我们将从检查点（模型传递的输出，但在 einsum 计算之前）向前推进并再次计算 4d 张量，但由于批处理，这个 4d 张量是一个小得多的张量，并且在每个批次中我们都会计算这个小的 4d 张量再次使用张量来计算梯度，然后再次将其从GPU内存中删除。在我看来，它运作良好。当然，由于检查点，它的运行速度较慢，但​​它使用的内存应该比具有大张量的默认 einsum 少得多。
但是我很难在 PyTorch 中实现它。我想典型的 torch.checkpoint 在这里是不够的。有人可以帮助我理解如何以正确的方式实现它，而不是破坏渐变]]></description>
      <guid>https://stackoverflow.com/questions/78514889/gradient-checkpointing-after-model-passing</guid>
      <pubDate>Wed, 22 May 2024 00:41:43 GMT</pubDate>
    </item>
    <item>
      <title>确定可最小化预测误差的最佳聚合级别</title>
      <link>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</link>
      <description><![CDATA[我正在寻找以最大化类别数量同时最小化分类错误的方式聚合预测结果的想法。
作为一个激励示例，假设我正在执行一项预测任务，以按流派对歌曲进行分类，并且有 6 种流派（来自下面的目标列）：

&lt;标题&gt;

类型（广泛）
类型（目标）


&lt;正文&gt;

流行音乐
独立流行音乐


流行音乐
超级流行


流行音乐
韩国流行音乐


摇滚
另类摇滚


摇滚
经典摇滚


摇滚
硬摇滚



该模型在识别前 4 个类别（独立流行、超级流行、韩国流行、另类摇滚）方面具有 100% 的准确率，但将大约 50% 的硬摇滚歌曲错误地分类为经典摇滚，将大约 20% 的经典摇滚歌曲错误地分类为硬摇滚摇滚。
基于此，我们可以想象通过几种方式聚合目标类型，从而减少分类错误。例如

2 个类别：流行、摇滚
4 个类别：独立流行音乐、超级流行音乐、韩国流行音乐、摇滚
5 个类别：独立流行音乐、超级流行音乐、韩国流行音乐、另类摇滚、其他摇滚

在本例中，我希望将目标类型聚合到这 5 个类别，保留尽可能多的类别，同时保持 100% 的准确性。
为了找到理想的聚合结构，我可以排列所有可能的聚合并计算 MSE。然而，考虑到我正在使用的类的数量，这在计算上是不可行的。所以，我想知道是否有一些相关文献可以阅读，以更好地理解如何解决这个问题，或者是否有人有想法。]]></description>
      <guid>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</guid>
      <pubDate>Tue, 21 May 2024 19:51:46 GMT</pubDate>
    </item>
    <item>
      <title>如何将ML模型部署到omnet ++中</title>
      <link>https://stackoverflow.com/questions/78513810/how-to-deploy-ml-model-into-omnet</link>
      <description><![CDATA[我用tensorflow和keras训练了一个深度学习模型来解决分类问题（ddos攻击），
现在我想将此模型部署到 omnet ++ 。我尝试使用 docker，但在 Windows 上效果不佳，所以现在在 omnet ++ 中部署 ml 模型的最简单方法是什么]]></description>
      <guid>https://stackoverflow.com/questions/78513810/how-to-deploy-ml-model-into-omnet</guid>
      <pubDate>Tue, 21 May 2024 18:43:13 GMT</pubDate>
    </item>
    <item>
      <title>联合概率分布如何帮助生成事物？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78513688/how-does-the-joint-probability-distribution-help-to-generate-things</link>
      <description><![CDATA[我试图理解判别模型和生成模型之间的区别。 Stack Overflow 上有用的答案之一在这里：生成算法和判别算法有什么区别？
在最上面的答案中（请参阅上面的链接），有一个简单的示例，其中只有四个 (x,y) 形式的数据点。答案的作者说了以下内容：分布 p(y|x) 是将给定示例 x 分类为类 y 的自然分布code&gt;，这就是为什么直接建模的算法被称为判别算法。生成算法模型p(x,y)，可以应用贝叶斯规则将其转化为p(y|x)，然后用于分类。然而，分布p(x,y)也可以用于其他目的。例如，您可以使用p(x,y)生成可能的(x,y)对。
我不太明白如何使用p(x,y)来生成可能的(x,y)对。我有兴趣查看使用联合概率分布 p(x,y) 生成的 (x,y) 对的示例？另外，为什么条件概率分布p(y|x)不能用来生成新的对？]]></description>
      <guid>https://stackoverflow.com/questions/78513688/how-does-the-joint-probability-distribution-help-to-generate-things</guid>
      <pubDate>Tue, 21 May 2024 18:13:38 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 RTX 4090 训练 Mask RCNN？</title>
      <link>https://stackoverflow.com/questions/78511541/is-it-possible-to-train-mask-rcnn-with-a-rtx-4090</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78511541/is-it-possible-to-train-mask-rcnn-with-a-rtx-4090</guid>
      <pubDate>Tue, 21 May 2024 11:27:34 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow PPO 模型未提供模型输出</title>
      <link>https://stackoverflow.com/questions/78510077/tensorflow-ppo-model-not-giving-model-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78510077/tensorflow-ppo-model-not-giving-model-output</guid>
      <pubDate>Tue, 21 May 2024 06:49:17 GMT</pubDate>
    </item>
    <item>
      <title>如果该层没有任何权重，则如何在 NN 中计算梯度下降</title>
      <link>https://stackoverflow.com/questions/78509864/how-gradient-descent-is-calculated-in-nn-if-the-layer-is-not-having-any-weights</link>
      <description><![CDATA[考虑具有三层的简单神经网络。第二层是我的自定义层，我没有任何权重或偏差，我只是转发输入乘以某个常数值。我了解前向传播流程，但我不了解反向传播如何与自定义层一起使用。我期望梯度下降为零，因为常数的导数为零，但它计算了某个值的梯度下降，我不确定梯度下降是如何计算的。
导入火炬作为t
将 torch.nn 导入为 nn

类自定义层（nn.Module）：
 def __init__(自身):
     超级（自定义层，自我）.__init__()
 def 前向（自身，x）：
     返回 x.mul(0.001)

def hookFunc(模块, gradInput, gradOutput):
   打印（模块）
   打印（等级输入）
   打印（梯度输出）

random_input = t.randn(2,2)

随机输出 = t.randn(1,1)
print(&#39;随机输入是&#39;, random_input)
标准 = nn.MSELoss()
＃ 模型
l1 = nn.Linear(2, 3, 偏差=False)
l2 = 自定义层()
l3 = nn.Linear(3, 1, 偏差=False)


l1.register_backward_hook(hookFunc)
l2.register_backward_hook(hookFunc)
l3.register_backward_hook(hookFunc)

中间1 = l1(随机输入)
中间2 = l2(中间1)
输出= l3(中间2)

损失=标准（输出，随机输出）
loss.backward()

打印（l1.重量）

打印（&#39; -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - &#39;）
打印（l1.体重.grad）
打印（l3.权重.grad）

打印（&#39; -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - - &#39;) ```
]]></description>
      <guid>https://stackoverflow.com/questions/78509864/how-gradient-descent-is-calculated-in-nn-if-the-layer-is-not-having-any-weights</guid>
      <pubDate>Tue, 21 May 2024 05:55:09 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：用户偏好向量和餐厅特征向量必须具有相同的维数</title>
      <link>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</guid>
      <pubDate>Tue, 14 May 2024 03:27:58 GMT</pubDate>
    </item>
    <item>
      <title>MLFlow 配方：缺少临时文件</title>
      <link>https://stackoverflow.com/questions/77096670/mlflow-recipes-missing-temporary-file</link>
      <description><![CDATA[首次在 Azure Databricks 环境中尝试 MLFlow Recipes。直到昨天，从提取到预测一切都很顺利。然而今天，我遇到了一个错误，说 MLFlow 在训练我的模型时找不到看起来像临时文件的东西。我真的没有在所有这些步骤中做任何花哨的事情，我想使用 LGBMClassifier 进行训练。MLFlow 版本是 2.7.0，但它似乎在我尝试的任何其他版本上都不起作用。
experiment_name = &quot;experiment_name&quot;

如果不是 mlflow.get_experiment_by_name(experiment_name):
mlflow.create_experiment(name=experiment_name )
否则：
mlflow.set_experiment(experiment_name)
experiment = mlflow.get_experiment_by_name(experiment_name)

r = Recipe(profile=&quot;databricks&quot;)
r.clean()
r.inspect()
r.run(&quot;ingest&quot;)
r.run(&quot;split&quot;)
r.run(&quot;transform&quot;)
r.run(&quot;train&quot;)

这是我的估算函数在 train.py 中的样子。 estimator_params 在 recipe.yaml 中定义。
def estimator_fn(estimator_params: Dict[str, Any] = None):
from lightgbm import LGBMClassifier

if estimator_params is None:
estimator_params = {}

return LGBMClassifier(**estimator_params)

正如我所说，同样的代码昨天对我来说运行良好，但今天我遇到了这个错误：
运行 MLFlow Recipe 步骤：训练
2023/09/13 11:09:36 INFO mlflow.recipes.step：正在运行步骤训练...
2023/09/13 11:09:38 INFO mlflow.recipes.steps.train：0.50 的类别不平衡优于 0.3，无需重新平衡
回溯（最近一次调用）：
文件&lt;string&gt;&lt;，第 1 行，位于 &lt;module&gt;
文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/step.py”，第 132 行，正在运行
self.step_card = self._run(output_directory=output_directory)
文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/steps/train.py”，第 373 行，正在运行
loaded_estimator = self._log_estimator_to_mlflow(fitted_estimator, X_train)
文件 &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/steps/train.py&quot;，第 1270 行，位于 _log_estimator_to_mlflow
return mlflow.sklearn.log_model(
文件 &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/sklearn/__init__.py&quot;，第 408 行，位于log_model
return Model.log(
File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/models/model.py&quot;, line 568, in log
with TempDir() as tmp:
File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/utils/file_utils.py&quot;, line 383, in __enter__
self._path = os.path.abspath(create_tmp_dir())
File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/utils/file_utils.py&quot;，第 830 行，位于 create_tmp_dir
return tempfile.mkdtemp(dir=repl_local_tmp_dir)
文件 &quot;/usr/lib/python3.10/tempfile.py&quot;，第 507 行，位于 mkdtemp
_os.mkdir(file, 0o700)
FileNotFoundError: [Errno 2] 没有这样的文件或目录：&#39;/tmp/repl_tmp_data/ReplId-68395-9c373-e0490-3/tmpuyeyu8co&#39;
make: *** [Makefile:40: steps/train/outputs/model] 错误 1

我真的不知道该怎么办，因为堆栈跟踪似乎表明存在一些 MLFlow 内部错误。]]></description>
      <guid>https://stackoverflow.com/questions/77096670/mlflow-recipes-missing-temporary-file</guid>
      <pubDate>Wed, 13 Sep 2023 11:30:27 GMT</pubDate>
    </item>
    <item>
      <title>使用更高版本的 PyTorch 库的一阶 MAML 的官方实现是什么？</title>
      <link>https://stackoverflow.com/questions/70961541/what-is-the-official-implementation-of-first-order-maml-using-the-higher-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70961541/what-is-the-official-implementation-of-first-order-maml-using-the-higher-pytorch</guid>
      <pubDate>Wed, 02 Feb 2022 19:17:08 GMT</pubDate>
    </item>
    <item>
      <title>来自变形金刚拥抱脸部的 Adafactor 仅适用于 Transfromers - 它不适用于更高版本的 Resnets 和 MAML 吗？</title>
      <link>https://stackoverflow.com/questions/70171427/adafactor-from-transformers-hugging-face-only-works-with-transfromers-does-it</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70171427/adafactor-from-transformers-hugging-face-only-works-with-transfromers-does-it</guid>
      <pubDate>Tue, 30 Nov 2021 14:57:13 GMT</pubDate>
    </item>
    <item>
      <title>如何使用批量归一化而不忘记刚刚在 Pytorch 中使用的批量统计信息？</title>
      <link>https://stackoverflow.com/questions/64920715/how-to-use-have-batch-norm-not-forget-batch-statistics-it-just-used-in-pytorch</link>
      <description><![CDATA[我处于一个不寻常的环境中，我不应该使用运行统计数据（因为这会被视为作弊，例如元学习）。然而，我经常对一组点（实际上是 5 个点）进行前向传递，然后我只想使用之前的统计数据对 1 个点进行评估，但批归一化会忘记它刚刚使用的批统计数据。我尝试对它应该的值进行硬编码，但出现了奇怪的错误（即使我取消了 pytorch 代码本身的注释，例如检查尺寸大小）。
如何对之前的批次统计数据进行硬编码，以便批次规范适用于新的单个数据点，然后将其重置为全新的下一批？
注意：我不想更改批量标准化图层类型。
我尝试过的示例代码：
def set_tracking_running_stats(模型):
    对于 dir(model) 中的 attr：
        如果属性中有“bn”：
            target_attr = getattr(模型, attr)
            target_attr.track_running_stats = True
            target_attr.running_mean = torch.nn.Parameter(torch.zeros(target_attr.num_features,requires_grad=False))
            target_attr.running_var = torch.nn.Parameter(torch.ones(target_attr.num_features,requires_grad=False))
            target_attr.num_batches_tracked = torch.nn.Parameter(torch.tensor(0, dtype=torch.long), require_grad=False)
            # target_attr.reset_running_stats()
    返回

我最多的评论错误：
&lt;块引用&gt;
引发 ValueError(&#39;预期 2D 或 3D 输入（获得 {}D 输入）&#39;
ValueError：预期 2D 或 3D 输入（获得 1D 输入）

和
&lt;块引用&gt;
IndexError：维度超出范围（预期在 [-1, 0] 范围内，但得到 1）

相关：

https://discuss.pytorch.org/t/how-to-use-have-batch-norm-not-forget-batch-statistics-it-just-used/103437
何时使用 PyTorch 高级库执行 MAML 时应该调用 .eval() 和 .train() 吗？
]]></description>
      <guid>https://stackoverflow.com/questions/64920715/how-to-use-have-batch-norm-not-forget-batch-statistics-it-just-used-in-pytorch</guid>
      <pubDate>Thu, 19 Nov 2020 22:05:16 GMT</pubDate>
    </item>
    </channel>
</rss>