<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 28 Jun 2024 18:19:13 GMT</lastBuildDate>
    <item>
      <title>如何应用 mlflow 来处理 scipy 模型？</title>
      <link>https://stackoverflow.com/questions/78682858/how-can-i-apply-mlflow-to-handle-scipy-models</link>
      <description><![CDATA[我已经使用 Python 中的 scipy 实现了一个 ML 模型。该模型解决了线性回归估计问题，该问题将回归权重限制在给定区间内。
一旦模型校准完毕，我就会存储 scipy.optimize 返回的权重，并像这样使用它们来预测新样本：
import numpy as np
def predict(scipy_model, x_test):
w = scipy_model.x
y_pred = np.sum(w * x_test, axis=1)
return y_pred

我想使用 mlflow 在生产环境中部署此模型。但是，我在文档中没有看到如何将 scipy 与 mlflow 集成。
如果不可能，我可以创建一个具有自定义 train 和 predict 函数的自定义“模型”类并将其与 mlflow 集成吗？]]></description>
      <guid>https://stackoverflow.com/questions/78682858/how-can-i-apply-mlflow-to-handle-scipy-models</guid>
      <pubDate>Fri, 28 Jun 2024 13:49:01 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习确定车辆类别[关闭]</title>
      <link>https://stackoverflow.com/questions/78682086/vehicle-class-determination-using-machine-learning</link>
      <description><![CDATA[如果我的数据集仅包含以下信息：路段容量、路段行程时间、起点-终点行程时间 (ODTT)、平均行程长度和持续时间以及拥堵程度。
并且没有道路图像。我还能使用 ML 将车辆类型分为重型货车和轻型车辆吗？
我还没有尝试过这种方法]]></description>
      <guid>https://stackoverflow.com/questions/78682086/vehicle-class-determination-using-machine-learning</guid>
      <pubDate>Fri, 28 Jun 2024 11:02:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 Haarcascades 时提高我的结果</title>
      <link>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</link>
      <description><![CDATA[来自 https://github.com/opencv/opencv/tree/master/data/haarcascades
我一直在使用 smile.xml 文件，但它工作得不太准确。
我想知道我可以做些什么来改进它，以便它可以在现实生活中准确实现。
此外，我如何为图像添加标签？
我的代码：
import cv2 as cv
import numpy as np
smile_cascade = cv.CascadeClassifier(&#39;haarcascade_smile.xml&#39;)
face_cascade = cv.CascadeClassifier(&#39;haarcascade_frontalface_default.xml&#39;)
cap = cv.VideoCapture(0)
当 True 时：
ret,img = cap.read()
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray,1.3,5)
对于 (x,y,w,h) 中的 faces:
cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
roi_gray = gray[y:y+h,x:x+w]
roi_color = img[y:y+h,x:x+w]
smiles = smile_cascade.detectMultiScale(gray, 
scaleFactor=1.3, 
minNeighbors=40, 
minSize=(30, 30),
flags=cv.CASCADE_SCALE_IMAGE)
对于 (ex,ey,ew,eh) 中的微笑：
cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
cv.imshow(&#39;img&#39;,img)
k = cv.waitKey(30) &amp; 0xFF
if k ==27:
break
cap.release()
cv.destroyAllWindows()

一直在我的脸上而不是嘴巴上画矩形。]]></description>
      <guid>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</guid>
      <pubDate>Fri, 28 Jun 2024 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>MATLAB 中“trainbr”训练函数的 Python 等效项是什么？</title>
      <link>https://stackoverflow.com/questions/78680950/what-is-the-python-equivalent-of-trainbr-training-function-in-matlab</link>
      <description><![CDATA[我正在尝试将以下用 MATLAB 编写的 ANN 模型代码转换为 Python。我只是想知道如何将 trainbr（贝叶斯正则化反向传播）算法转换为 Python。
net=newff(INPTRN,TARTRN,hidden,{&#39;logsig&#39;,&#39;purelin&#39;},&#39;trainbr&#39;);
net.divideFcn=&#39;&#39;;
net.performFcn=&#39;msereg&#39;;
net.trainParam.show=10;
net.trainParam.epochs=50000;
net.trainParam.goal=0.0001;
rand(&#39;state&#39;,0);
net=init(net);
]]></description>
      <guid>https://stackoverflow.com/questions/78680950/what-is-the-python-equivalent-of-trainbr-training-function-in-matlab</guid>
      <pubDate>Fri, 28 Jun 2024 06:34:07 GMT</pubDate>
    </item>
    <item>
      <title>逆问题：使用 LightGBM 模型推荐 X（特征）范围以实现特定的 y（目标）范围</title>
      <link>https://stackoverflow.com/questions/78680915/inverse-problem-using-lightgbm-model-to-recommend-x-feature-ranges-to-achieve</link>
      <description><![CDATA[我正在尝试构建一个 LightGBM 回归模型，其中我有大约 15-20 个输入特征，而我的目标变量在 20-40 的范围内。
我使用了 SHAP 蜂群图来了解每个特征的重要性（由于数据的敏感性，特征名称被隐藏）

现在，用户希望我基于此 LightGBM 模型创建一个优化模型，其中将输入 Y 变量的预期范围，并且模型将返回每个输入变量的理想范围（X，15-20 个特征）以实现相同的目标。问题更像是输入一个 Y 变量，然后返回每个 X 变量的范围。
然而，这里的挑战是，需要 15-20 个特征的组合才能达到 Y 变量的预期范围，因此模型推荐也需要注意这一点。
是否有任何 scikit-learn 库可用于解决这个问题？或者在这种情况下我如何实现解决方案？
我遇到过许多类似的问题，但没有一个是我想要的。]]></description>
      <guid>https://stackoverflow.com/questions/78680915/inverse-problem-using-lightgbm-model-to-recommend-x-feature-ranges-to-achieve</guid>
      <pubDate>Fri, 28 Jun 2024 06:21:25 GMT</pubDate>
    </item>
    <item>
      <title>如何查看 YOLOv6 中的评估指标？</title>
      <link>https://stackoverflow.com/questions/78680846/how-to-see-evaluation-metrics-in-yolov6</link>
      <description><![CDATA[我有以下输出，但无法弄清楚如何评估，因为没有 F1 分数 或 混淆矩阵。
平均召回率 (AR) @[ IoU=0.50:0.95 | area= small |maxDets=100] = -1.000

平均召回率 (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250

平均召回率 (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410

20/499 0.001595 0.6697 0 1.393: 100%|██████████| 12/12 [00:

21/499 0.001594 0.6417 0 1.353: 100%|██████████| 12/12 [00:

22/499 0.001594 0.6727 0 1.431: 100%|██████████| 12/12 [00:

我训练了 400 个 epoch，这只是输出的一小部分。我也看不到 mAP。
我有这行代码要评估
!python tools/eval.py --data Fabric-Defect-2/data.yaml --weights runs/train/exp/weights/best_ckpt.pt --device 0

有没有办法获得详细的评估指标，例如 F1 分数、混淆矩阵 和 mAP？]]></description>
      <guid>https://stackoverflow.com/questions/78680846/how-to-see-evaluation-metrics-in-yolov6</guid>
      <pubDate>Fri, 28 Jun 2024 05:55:12 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft Fabric 数据科学 - 如何使用应用模型向导在 Delta 表中保存概率和预测？</title>
      <link>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</link>
      <description><![CDATA[我为二元分类任务创建了一个逻辑回归模型。该模型在预测方面表现良好，我得到了我想要的结果。但随着业务需求的变化，我也想获得每个类别的概率。我使用 predict_proba 方法来获取 2 个类别的概率。这适用于测试数据。我得到了预测及其概率。我将实验保存为 ML 模型（使用 ML 向导中的应用此模型）并按照以下步骤操作：

选择用于评分的源数据
将数据正确映射到我的 ML 模型的输入
指定我的模型输出的目标
创建一个使用 PREDICT 生成预测结果并将其作为增量表存储到 Lakehouse 的笔记本

但是，我只在我的增量表中获得了预测，而没有概率。有没有办法我也可以获得概率？
我按照此链接上的说明进行操作：链接
我注意到的另一件事是在实验和模型的输出模式上，数据类型是 int 32，这对于预测来说是正确的，但对于概率来说应该是大小为 [-1,2] 的数组。
为了以防万一，我还将链接附加到我的笔记本中：笔记本。
]]></description>
      <guid>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</guid>
      <pubDate>Fri, 28 Jun 2024 04:22:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我尝试从 (.fif) 文件进行可视化时，会在 mne-python 中收到此运行时警告？</title>
      <link>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</link>
      <description><![CDATA[我正在努力使用 mne-python 进行预处理的 eeg 通道可视化部分。这些 (&#39;.fif&#39;) 文件是从 (&#39;.mat&#39;) 文件预处理的。这是我在 kaggle 笔记本中使用的代码：
import mne
import os
import numpy as np

# 定义存储 .fif 文件的目录
data_dir = &#39;/kaggle/input/preproccesed-dataset/128-channel-resting(2.0)/kaggle/working/preprocessed_mat_output_directory&#39;

# 列出目录中的所有 .fif 文件
fif_files = [f for f in os.listdir(data_dir) if f.endswith(&#39;-epo.fif&#39;)]

# 加载每个 .fif 文件
epochs_list = [mne.read_epochs(os.path.join(data_dir, fif_file)) for fif_file in fif_files]

# 连接所有将 epochs 合并为单个 Epochs 对象
all_epochs = mne.concatenate_epochs(epochs_list)

# 预处理：应用高通滤波器
all_epochs.filter(l_freq=1.0, h_freq=40.0)

# 执行 ICA
ica = mne.preprocessing.ICA(n_components=20, random_state=97)
ica.fit(all_epochs)

# 根据检查或自动标准手动排除组件
ica.exclude = [0, 1] # 根据已识别的工件组件进行调整

# 将 ICA 应用于 epochs
all_epochs = ica.apply(all_epochs)

# 绘制诱发反应
evoked = all_epochs.average()
evoked.plot()

# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=True, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=[0.1, 0.2, 0.3], ch_type=&#39;eeg&#39;, average=0.05)

# 计算并绘制 TFR
from mne.time_frequency import tfr_morlet
freqs = np.arange(6, 30, 3)
n_cycles = freqs / 2
power = tfr_morlet(all_epochs, freqs=freqs, n_cycles=n_cycles, return_itc=False, average=True)
fig_tfr = power.plot([0])

# 确保保存目录存在
save_dir = &#39;/kaggle/working/mat_visuals/&#39;
os.makedirs(save_dir, exist_ok=True) # 如果目录不存在，则创建目录

# 保存处理后的数据
all_epochs.save(os.path.join(save_dir, &#39;processed-epochs.fif&#39;), overwrite=True)
evoked.save(os.path.join(save_dir, &#39;evoked-ave.fif&#39;), overwrite=True)

# 如果需要，保存图形
fig_psd.savefig(os.path.join(save_dir, &#39;psd_plot.png&#39;))
fig_topo.savefig(os.path.join(save_dir, &#39;topomap_plot.png&#39;))
fig_tfr.savefig(os.path.join(save_dir, &#39;tfr_plot.png&#39;))

这是我收到的错误：
Runtime-ERROR
我尝试更改这两行代码：
# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=False, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=False, ch_type=&#39;eeg&#39;, average=0.05)

我还尝试阅读以下 2 个文档：
neurotechedu , mne-python
但我仍然找不到任何解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</guid>
      <pubDate>Thu, 27 Jun 2024 19:16:05 GMT</pubDate>
    </item>
    <item>
      <title>Oracle 机器学习（OML）df_datetime 给出“未选择任何列”错误</title>
      <link>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</link>
      <description><![CDATA[如果有人能帮忙，我遇到了一些编码问题！我试图从 oml.Dataframe df 中获取 Datetime 类型。我试过这个代码：
 df = oml.sync(query=QUERY)
df_datetime = df.select_types(include=[&#39;oml.Datetime&#39;])

但我收到一个错误，提示没有选择任何列。我是否错误地使用了此功能？
我找到了一种解决方法
 df = oml.sync(query=QUERY)
df_datetime = []
for col, dtype in df.dtypes.items():
if dtype.__name__ == &#39;Datetime&#39;:
df_datetime.append(col)

这确实返回了 Datetime 对象，所以我知道它们存在。如果可以的话，我更愿意使用 select_types 方法，如果有人能向我解释我做错了什么。]]></description>
      <guid>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</guid>
      <pubDate>Thu, 27 Jun 2024 14:52:10 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Huggingface 训练器的学习率？</title>
      <link>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</link>
      <description><![CDATA[我正在使用以下参数训练模型：
Seq2SeqTrainingArguments(
output_dir = &quot;./out&quot;, 
overwrite_output_dir = True,
do_train = True,
do_eval = True,

per_device_train_batch_size = 2, 
gradient_accumulation_steps = 4,
per_device_eval_batch_size = 8, 

learning_rate = 1.25e-5,
warmup_steps = 1,

save_total_limit = 1,

evaluation_strategy = &quot;epoch&quot;,
save_strategy = &quot;epoch&quot;,
logs_strategy = &quot;epoch&quot;, 
num_train_epochs = 5, 

gradient_checkpointing = True,
fp16 = True, 

predict_with_generate = True,
generation_max_length = 225,

report_to = [&quot;tensorboard&quot;],
load_best_model_at_end = True,
metric_for_best_model = &quot;wer&quot;,
greater_is_better = False,
push_to_hub = False,
)

我假设 warmup_steps=1 固定了学习率。
但是，训练结束后，我查看文件 trainer_state.json，发现学习率似乎没有固定。
以下是 learning_rate 和 step 的值：
learning_rate，steps
1.0006 e-05 1033
7.5062 e-06 2066
5.0058 e-06 3099
2.5053 e-06 4132
7.2618 e-09 5165

学习率似乎没有固定在 1.25e-5（步骤 1 之后）。我遗漏了什么？如何修复学习率。]]></description>
      <guid>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</guid>
      <pubDate>Wed, 10 Jan 2024 09:14:26 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 skimage imsave 保存重建的二进制图像</title>
      <link>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</link>
      <description><![CDATA[我一直在尝试使用 skimage 库对图像进行预处理以进行特征提取。但我无法保存图像，因为它给出错误提示“无法将模式 F 写入 PNG”
处理图像的函数在此处给出
def image_process(image):
img = imread(image)
rem_img = remove(img)
rgb_img = rgba2rgb(rem_img)
gray_img = rgb2gray(rgb_img)
bin_img = gray_img &lt; Threshold_otsu(gray_img)
Smooth_img = gaussian(bin_img)
Seed_px = np.copy(smooth_img)
Seed_px[1:-1 , 1:-1]=smooth_img.max()
Mask = Smooth_img
Filled_img = Reconstruction(seed_px , Mask , Method =&#39;erosion&#39;)

返回 filled_img

然后尝试使用 imsave 将图像保存在 BW 目录中
leaf_img = &quot;neem.jpg&quot;
processing_img = image_process(leaf_img)
imsave(&quot;BW/leaf.png&quot;, processing_img)

显示错误
KeyError Traceback (most recent call last)
File C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1299, in _save(im, fp, filename, chunk, save_all)
1298 try:
-&gt; 1299 rawmode, mode = _OUTMODES[mode]
1300 except KeyError as e:

KeyError: &#39;F&#39;

上述异常是导致以下异常的直接原因：

OSError Traceback (most recent call last)
Cell In[26], line 3
1 leaf_img = &quot;neem.jpg&quot;
2 processing_img = image_process(leaf_img)
----&gt; 3 imsave(&quot;BW/leaf.png&quot;, processing_img)

文件 C:\Python\lib\site-packages\skimage\io\_io.py:143，在 imsave(fname, arr, plugin, check_contrast, **plugin_args) 中
141 如果 check_contrast 和 is_low_contrast(arr):
142 warn(f&#39;{fname} 是低对比度图像&#39;)
--&gt; 143 返回 call_plugin(&#39;imsave&#39;, fname, arr, plugin=plugin, **plugin_args)

文件 C:\Python\lib\site-packages\skimage\io\manage_plugins.py:205，在 call_plugin(kind, *args, **kwargs) 中
202 除外 IndexError:
203 引发 RuntimeError(f&#39;无法找到 {kind} 的插件“{plugin}”。&#39;)
--&gt; 205 return func(*args, **kwargs)

文件 C:\Python\lib\site-packages\imageio\v3.py:139，在 imwrite(uri, image, plugin, extension, format_hint, **kwargs) 中
104 def imwrite(uri, image, *, plugin=None, extension=None, format_hint=None, **kwargs):
105 &quot;&quot;&quot;将 ndimage 写入给定的 URI。
106 
107 具体行为取决于所使用的文件类型和插件。要了解
(...)
136 
137 &quot;&quot;&quot;
--&gt; 139 使用 imopen(
140 uri,
141 &quot;w&quot;,
142 legacy_mode=False,
143 plugin=plugin,
144 format_hint=format_hint,
145 extension=extension,
146 ) 作为 img_file:
147coded = img_file.write(image, **kwargs)
149 returncoded

文件 C:\Python\lib\site-packages\imageio\core\v3_plugin_api.py:367，位于 PluginV3.__exit__(self, type, value, traceback)
366def __exit__(self, type, value, traceback) -&gt; None:
--&gt; 367 self.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:123，位于 PillowPlugin.close(self) 中
122 def close(self) -&gt; None:
--&gt; 123 self._flush_writer()
125 if self._image:
126 self._image.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:457，位于 PillowPlugin._flush_writer(self) 中
454 self.save_args[&quot;save_all&quot;] = True
455 self.save_args[&quot;append_images&quot;] = self.images_to_write
--&gt; 457 primary_image.save(self._request.get_file(), **self.save_args)
458 self.images_to_write.clear()
459 self.save_args.clear()

文件 C:\Python\lib\site-packages\PIL\Image.py:2431，位于 Image.save(self, fp, format, **params)
2428 fp =builtins.open(filename, &quot;w+b&quot;)
2430 尝试：
-&gt; 2431 save_handler(self, fp, filename)
2432 except Exception:
2433 if open_fp:

文件 C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1302，在 _save(im, fp, filename, chunk, save_all) 中
1300 except KeyError as e:
1301 msg = f&quot;cannot write mode {mode} as PNG&quot;
-&gt; 1302 raise OSError(msg) from e
1304 #
1305 # write minimal PNG file
1307 fp.write(_MAGIC)

OSError: 无法在此处将模式 F 写入 PNG 类型


有人可以解释一下这里的问题是什么吗？解决方案将非常有帮助。提前谢谢大家]]></description>
      <guid>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</guid>
      <pubDate>Sat, 07 Oct 2023 06:06:06 GMT</pubDate>
    </item>
    <item>
      <title>计算“torch.tensor”中条目之间的成对距离</title>
      <link>https://stackoverflow.com/questions/75309052/calculating-pairwise-distances-between-entries-in-a-torch-tensor</link>
      <description><![CDATA[我正在尝试实现流形对齐类型的损失，如此处所示。
给定一个表示一批形状为 (L,N) 的嵌入的张量，例如 L=256：
tensor([[ 0.0178, 0.0004, -0.0217, ..., -0.0724, 0.0698, -0.0180],
[ 0.0160, 0.0002, -0.0217, ..., -0.0725, 0.0655, -0.0207],
[ 0.0155, -0.0010, -0.0153, ..., -0.0750, 0.0688, -0.0253],
...,
[ 0.0130, -0.0113, -0.0078, ..., -0.0805, 0.0634, -0.0241],
[ 0.0120, -0.0047, -0.0135, ..., -0.0846, 0.0722, -0.0230],
[ 0.0120, -0.0048, -0.0142, ..., -0.0843, 0.0734, -0.0246]],
grad_fn=&lt;AddmmBackward0&gt;)

我想计算所有成对距离行条目。产生 (L, L) 形状的输出。
我尝试使用 torch.nn.PairwiseDistance，但我不清楚它是否有用，是否符合我的要求。]]></description>
      <guid>https://stackoverflow.com/questions/75309052/calculating-pairwise-distances-between-entries-in-a-torch-tensor</guid>
      <pubDate>Wed, 01 Feb 2023 10:47:38 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 GridSearchCV 选择前 k 个模型</title>
      <link>https://stackoverflow.com/questions/47793569/choosing-top-k-models-using-gridsearchcv-in-scikit-learn</link>
      <description><![CDATA[是否有一种简单/预先存在的方法可以在 scikit-learn 中执行网格搜索，然后自动返回前 k 个最佳表现模型或自动平均它们的输出？我打算尝试通过这种方式减少过度拟合。我还没有找到与此相关的任何内容。
编辑：澄清一下，我知道 sklearn 的 GridSearch，我正在寻找一种选项来执行网格搜索，然后返回前 k 个最佳表现模型或对它们进行平均，而不仅仅是返回最佳单个模型。]]></description>
      <guid>https://stackoverflow.com/questions/47793569/choosing-top-k-models-using-gridsearchcv-in-scikit-learn</guid>
      <pubDate>Wed, 13 Dec 2017 12:55:18 GMT</pubDate>
    </item>
    <item>
      <title>SelectKBest 与 GaussianNB 结果不精确/不一致</title>
      <link>https://stackoverflow.com/questions/42193893/selectkbest-with-gaussiannb-not-precise-consistent-results</link>
      <description><![CDATA[我想使用 SelectKBest 选择 前 K 个特征 并运行 GaussianNB：
selection = SelectKBest(mutual_info_classif, k=300)

data_transformed = choice.fit_transform(data, labels)
new_data_transformed = choice.transform(new_data)

classifier = GaussianNB()
classifier.fit(data_transformed, labels)
y_predicted = classifier.predict(new_data)
acc = accuracy_score(new_data_labels, y_predicted)

但是，对于相同的数据，我没有得到一致的准确度结果。
准确度为：
0.61063743402354853
0.60678034916768164 
0.61733658140479086 
0.61652456354039786 
0.64778725131952908 
0.58384084449857898

对于相同的数据。我不进行拆分等。我只使用两组静态的 data 和 new_data。
为什么结果会有所不同？如何确保对相同的数据获得相同的准确度？ ]]></description>
      <guid>https://stackoverflow.com/questions/42193893/selectkbest-with-gaussiannb-not-precise-consistent-results</guid>
      <pubDate>Sun, 12 Feb 2017 22:11:29 GMT</pubDate>
    </item>
    <item>
      <title>如何提高机器学习的分类准确性</title>
      <link>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</link>
      <description><![CDATA[我曾使用极限学习机进行分类，发现我的分类准确率只有 70% 以上，这导致我使用集成方法创建更多分类模型，并根据大多数模型的分类对测试数据进行分类。但是，这种方法只能将分类准确率提高一小步。请问还有哪些其他方法可用于提高二维线性不可分数据集的分类准确率？]]></description>
      <guid>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</guid>
      <pubDate>Tue, 03 Jan 2017 15:41:10 GMT</pubDate>
    </item>
    </channel>
</rss>