<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 03 Aug 2024 03:16:18 GMT</lastBuildDate>
    <item>
      <title>CSV 与 Pandas Dataframe 之间的转换不正确</title>
      <link>https://stackoverflow.com/questions/78827542/csv-to-from-pandas-dataframe-not-transforming-correctly</link>
      <description><![CDATA[我有一个 csv 文件，其中包含标题、文本和 url 列的新闻文章。当我将文件导入 pandas df 时，长度似乎与 csv 文件中的行数不同。经过检查，我注意到一些文章被分成第二行，并进一步分成许多额外的列，所有 url 都位于单个文章的“第二”行的某个较远的列中。Pandas 正确地解释了这个问题，并合并了文本并将 url 放在正确的列下。
虽然 Pandas 正确地解释了这一点，但我无法将 df（清理后）保存到新的 csv，因为新的清理后的 csv 文件不会反映相同的问题，这会破坏清理后的特征工程和 NLP 任务。这些“额外”的行完全搞砸了诸如计算单词/动词/名词以及获取每个句子的被动语态和音节之类的事情。我尝试过检测/删除换行符（\n 和 \r\n），但没有用。我在读取 csv 时尝试过不同的编码和引用值（见下文），但没有用。我尝试过合并行，但做不到，因为 pandas 看不到 csv 中显示的“第二”行。
我遗漏了什么吗？知道发生了什么吗？
df = pd.read_csv(&#39;filepath.csv&#39;, encoding=&#39;utf-8&#39;, engine=&#39;python&#39;, on_bad_lines=&#39;skip&#39;, quoting=1)

df= df.rename(columns={&#39;Headline&#39;: &#39;title&#39;, &#39;Article text&#39;: &#39;text&#39;, &#39;Url&#39;: &#39;url&#39;})

df= df[[&#39;title&#39;, &#39;text&#39;, &#39;url&#39;]]

df[&#39;text&#39;] = df[&#39;text&#39;].str.replace(&#39;\r\n&#39;, &#39; &#39;, regex=True)
df.to_csv(&#39;df_investigation.csv&#39;, index=False) 
]]></description>
      <guid>https://stackoverflow.com/questions/78827542/csv-to-from-pandas-dataframe-not-transforming-correctly</guid>
      <pubDate>Fri, 02 Aug 2024 23:42:35 GMT</pubDate>
    </item>
    <item>
      <title>无法抑制来自 transformers/src/transformers/modeling_utils.py 的警告</title>
      <link>https://stackoverflow.com/questions/78827482/cant-suppress-warning-from-transformers-src-transformers-modeling-utils-py</link>
      <description><![CDATA[我对 AutoModel AutoTokenizer 类的实现相当简单：
from transformers import AutoModel, AutoTokenizer
import numpy as np
from rank_bm25 import BM25Okapi
from sklearn.neighbors import NearestNeighbors

class EmbeddingModels:

def bert(self, model_name, text):
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
input = tokenizer(text, return_tensors=&quot;pt&quot;, truncation=True, padding=True)
output = model(**inputs)
embeddings = output.last_hidden_​​state.mean(dim=1).detach().numpy()
return embeddings

def create_chunks(self, text, chunk_size):
return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

但我无法让这个警告消失：
包含“beta”的参数名称将在内部重命名为“bias”。
请使用其他名称来抑制此警告。
包含“gamma”的参数名称将在内部重命名为“weight”。
请使用其他名称来抑制此警告。

我的存储库中没有任何地方提到 beta 或 gamma 这个词。
更新软件包，使用 import warnings 抑制警告]]></description>
      <guid>https://stackoverflow.com/questions/78827482/cant-suppress-warning-from-transformers-src-transformers-modeling-utils-py</guid>
      <pubDate>Fri, 02 Aug 2024 23:04:25 GMT</pubDate>
    </item>
    <item>
      <title>VAE：潜在分布。后部塌陷，多个潜在 [关闭]</title>
      <link>https://stackoverflow.com/questions/78827397/vae-latent-distribution-posterior-collapse-multiple-latents</link>
      <description><![CDATA[在探索 VAE 一段时间后，我有两个问题。在标准 VAE 设置中，我们假设 1 个形状为 (BHWD) 的潜在变量：mu 和 var，以及先验 N(0, I)。

潜在分布：我阅读了一些关于卡方分布的资料，想知道潜在变量的 L2 范数 (B,) 是否是潜在变量呈高斯分布的良好指标。在标准 VAE 训练中，我发现它的值稳定在 (D-1)**0.5 附近，这符合中心卡方分布的描述。接下来的问题是，如果 L2 范数不等于预期值，我们可以说潜在分布比高斯分布更复杂吗？

后验崩溃：（1）后验崩溃的症状是什么？它是否必须严格为：mu~0、var~1 和 KL~0？（2）如何解释 var 的平均值。我观察到它也受到 D 的影响。此外，如果极小的 var 表示模型对输入非常确定，爆炸的 var 会告诉我们编码器缺乏能力？一般来说，我们更喜欢较小的 var 还是存在一个理想值。

给定一张图像，我尝试将其转换为 Y/UV 通道并分别学习两组潜在值。具体来说，我对两者应用了标准流程：使用一个/两个编码器为 Y 和 UV 输入生成 mu 和 var，分别计算两个相对于正常 proir 的 KL，对两者进行后验采样，在解码之前将它们连接在一起。解码器的工作是重建原始 RGB 图像。 我想，如果 VAE 能够为图像构建可插值/平滑的潜在空间，它也应该能够处理 Y/UV 潜在值并将来自同一图像的潜在值对齐。 不幸的是，我在实验中没有观察到它。重建很好，但潜在的统计数据（为方便起见，我将它们标记为 1 和 2）非常混乱。 (1) 很难从 mu1 和 mu2 读取，因为它们的值非常接近 0。但是，我总是能发现 var2 爆炸（请参阅我在第 2 点中提出的问题），可能高达 200。 (2) 通常，var1 看起来更像高斯，因为它的 L2 范数在 (d-1)**0.5 处收敛，但 var2 的值稍大一些（请参阅我在第 1 点中提出的问题）。 (3) 我还计算了 mu1 和 mu2 之间的 cos 相似度 和 L2 距离。它们大多是正交的，这与高维向量自然彼此正交的说法相符。并且 L2(mu1, mu2) 和 L2(mu2, origin) 具有相似的值，大于 L1(mu1, origin)。消化这些统计数据的正确方法是什么？或者一般来说，VAE 框架不适合学习两个独立但相关的高斯类潜在变量？


进行了大量实验并尝试更好地理解高维潜在空间。]]></description>
      <guid>https://stackoverflow.com/questions/78827397/vae-latent-distribution-posterior-collapse-multiple-latents</guid>
      <pubDate>Fri, 02 Aug 2024 22:17:58 GMT</pubDate>
    </item>
    <item>
      <title>除非 label_mode=None，否则图像目录无法打开</title>
      <link>https://stackoverflow.com/questions/78827338/image-directory-failing-to-open-unless-label-mode-none</link>
      <description><![CDATA[除非 image_dataset_from_directory 的 label_mode 参数为 None，否则我的图像目录无法打开。
我尝试将类型切换为“int”、“categorical”和“binary”，但无济于事。我还尝试为该类制作一个包装器，然后稍后切换属性（事后看来，这根本行不通），但这也行不通。我需要以某种方式将其保持在 None 之外，因为我稍后会评估生成器的准确性，而 model.evaluate() 无法处理 None 值。这是我目前的代码：
import matplotlib.pyplot as plt
import numpy as np
import random
from PIL import Image
import tensorflow
from tensorflow import keras
from keras import layer, preprocessing, Sequential
from sklearn.neighbors import KernelDensity
import glob

class CustomImageDataset:
def __init__(self, directory, image_size, batch_size, label_mode):
self.dataset = tensorflow.keras.preprocessing.image_dataset_from_directory(
directory,
image_size=image_size,
batch_size=batch_size,
label_mode=label_mode
)
self.label_mode = label_mode

def __iter__(self):
return iter(self.dataset)

def __len__(self):
return len(self.dataset)

def map(self, *args, **kwargs):
返回 self.dataset.map(*args, **kwargs)

def batch(self, *args, **kwargs):
返回 self.dataset.batch(*args, **kwargs)

def prefetch(self, *args, **kwargs):
返回 self.dataset.prefetch(*args, **kwargs)

SIZE = 8
batch_size = 64

train_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\noncloud_train&#39;, 
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

anomaly_generator = CustomImageDataset(
r&#39;C:\Users\{}\Downloads\archive (1)\cloud&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

rescaling_layer = layer.Rescaling(1./255)

def change_inputs(images):
x = tensorflow.image.resize(rescaling_layer(images),[SIZE, SIZE], method=tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)
return x, x

# 对数据集应用预处理
train_dataset = train_generator.map(change_inputs)
validation_dataset = validation_generator.map(change_inputs)
anomaly_dataset = anomaly_generator.map(change_inputs)

test = anomaly_generator.label_mode
def check_none_in_dataset(dataset):
for batch in dataset:
images, labels = batch
if images is None or labels is None:
print(&quot;Found None in dataset&quot;)
return True
print(&quot;No None values in dataset&quot;)
return False

# 检查验证数据集
print(&quot;正在检查验证数据集中是否有 None 值：&quot;)
c = check_none_in_dataset(validation_dataset)
print(c)

def print_labels_from_dataset(dataset, num_batches=1):
for images, labels in dataset.take(num_batches):
print(&quot;标签（应与images):&quot;)
print(labels.numpy()) # 打印标签以检查它们是否是预期值（不是 None）
print(labels.numpy() == images.numpy())

print(&quot;验证数据集标签：&quot;)
bat = print_labels_from_dataset(validation_dataset)

print(&quot;异常数据集标签：&quot;)
cow = print_labels_from_dataset(anomaly_dataset)

model = Sequential()
# 编码器
model.add(layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;,input_shape=(SIZE, SIZE, 3)))
model.add(layers.MaxPooling2D((2, 2),padding=&#39;same&#39;)) 
model.add(layers.Conv2D(32, (3, 3),激活=&#39;relu&#39;，padding=&#39;same&#39;))
model.add(layers.MaxPooling2D((2, 2)，padding=&#39;same&#39;))
model.add(layers.Conv2D(16, (3, 3)，激活=&#39;relu&#39;，padding=&#39;same&#39;))
model.add(layers.MaxPooling2D((2, 2)，padding=&#39;same&#39;))

# Deconder
model.add(layers.Conv2D(16, (3, 3)，激活=&#39;relu&#39;，padding=&#39;same&#39;))
model.add(layers.UpSampling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3)，激活=&#39;relu&#39;，padding=&#39;same&#39;))
model.add(layers.UpSampling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;same&#39;))
model.add(layers.UpSampling2D((2, 2)))

model.add(layers.Conv2D(3, (3, 3), 激活=&#39;sigmoid&#39;, 填充=&#39;same&#39;))

model.compile(optimizer=&#39;adam&#39;, 损失=&#39;mean_squared_error&#39;, 指标=[&#39;mse&#39;])
model.summary()

history = model.fit(
train_dataset,
steps_per_epoch = 1500 // batch_size,
epochs = 1000,
validation_data = validation_dataset,
validation_steps = 225 // batch_size,
shuffle = True
)

# 检查侦察。 val 数据和异常图像之间的错误
validation_error = model.evaluate(validation_generator)
anomaly_error = model.evaluate(anomaly_generator)
]]></description>
      <guid>https://stackoverflow.com/questions/78827338/image-directory-failing-to-open-unless-label-mode-none</guid>
      <pubDate>Fri, 02 Aug 2024 21:47:44 GMT</pubDate>
    </item>
    <item>
      <title>是否有关于所使用的 LLM 模型及其用于创意写作 AI 的架构的信息？（例如 Sudowrite、NovelAI Storyteller）[关闭]</title>
      <link>https://stackoverflow.com/questions/78827337/is-there-any-information-on-the-llm-models-used-and-their-architecture-for-creat</link>
      <description><![CDATA[我找不到任何有关创意写作的 LLM 模型（如 Sudowrite）的信息。由于它们专门用于创意写作，因此它们比 ChatGPT 效果好得多。我想了解如何构建像 Sudowrite 这样的 LLM，因为它们特别擅长帮助创意写作。
我研究了与不同创意写作 ais 相关的模型架构，但找不到太多信息。或者可能收集的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78827337/is-there-any-information-on-the-llm-models-used-and-their-architecture-for-creat</guid>
      <pubDate>Fri, 02 Aug 2024 21:47:19 GMT</pubDate>
    </item>
    <item>
      <title>如何针对 JavaScript 框架微调轻量级 LLM？[关闭]</title>
      <link>https://stackoverflow.com/questions/78827245/how-can-i-fine-tune-a-lightweight-llm-specifically-for-javascript-frameworks</link>
      <description><![CDATA[我需要专门针对 JavaScript 堆栈微调一个模型。目前，所有大型 LLM 都是通用的，但我想要一个仅针对我每天使用的 JavaScript 框架进行训练的自定义模型。我的目标是拥有一个小型、高效的模型，它可以在我的 MacBook Pro 上运行并严格协助编码任务。以下是我正在寻找的具体功能：

代码完成
代码解释
代码文档（可选）
代码审查和优化建议（基于最佳实践）
错误查找和修复
特定于框架的响应（例如，指定时响应仅限于 Express.js）
针对编码问题的交互式问答
了解我的代码库并提供上下文答案

我的目标是将其打造成一个开源项目，而不依赖主要提供商的昂贵解决方案。以下是我向社区提出的具体问题：

基础模型选择：我应该选择哪种基础模型？该模型应该是轻量级的、能够进行微调的，并且针对编码任务进行了优化，没有不必要的功能。
指导与基础模型：如果我想与它进行对话式交互，我应该选择基础模型还是指导就绪模型？
微调方法：根据我的需求微调模型的最佳方法是什么？
训练资源：训练模型的最佳资源是什么？
数据集：我应该使用哪些数据集进行训练，包括最佳实践的文档？我找到了 SRI Lab 的 150k JavaScript 数据集，但我不确定它的质量。有人可以提供见解或推荐其他数据集吗？
硬件要求：我有一台 MacBook Pro M2，内存为 32 GB。这足以进行训练吗，还是我需要付费解决方案？如果是，您会推荐哪些经济实惠的解决方案？
其他注意事项：在此过程中我还应该考虑其他因素吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78827245/how-can-i-fine-tune-a-lightweight-llm-specifically-for-javascript-frameworks</guid>
      <pubDate>Fri, 02 Aug 2024 21:08:50 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中影响年度数据的多个月份模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78827204/model-for-multiple-months-that-impact-an-annual-number-in-machine-learning</link>
      <description><![CDATA[我正在寻找一种机器学习模型的建议，该模型可以解决我即将概述的问题。我最熟悉的两个模型是线性回归和逻辑回归，但似乎不是合适的模型。
我试图预测每月天气数据如何影响年度苹果产量。每个月都有自己的一组天气变量（降雨量、低温、平均温度和高温），一年中月份的组合会影响年产量。我有 X 年的月度数据，年份目前也是我数据中的一个变量。
然而，在设置数据时，使用线性回归将相同数量的年度苹果分配给给定年份的每个月是行不通的，因为模型认为变量的波动不会影响产量，因为它们都被分配了相同的生产值（澄清一下，这是因为每个月的年份都相同）。
有没有什么办法可以解决这个问题，或者我应该使用什么模型？我本质上希望有可能有一个字典数据框，其中模型接收 12 个字典输入（我知道这实际上没有什么意义），以便将每个月对全年苹果产量的影响考虑在内。
（我尝试了线性回归，它基本上将所有类别的权重视为具有完全相同的影响，具有负的 r 平方值，并预测我输入的月份和天气条件下的苹果产量为负数！这也让我回想起，我怎样才能输入所有 12 个月，而不是在预测全年时只选择一个？）]]></description>
      <guid>https://stackoverflow.com/questions/78827204/model-for-multiple-months-that-impact-an-annual-number-in-machine-learning</guid>
      <pubDate>Fri, 02 Aug 2024 20:52:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中使用 WordNet 查找或训练分层数据的 Mamba 模型</title>
      <link>https://stackoverflow.com/questions/78826929/how-to-find-or-train-a-mamba-model-for-hierarchical-data-using-wordnet-in-python</link>
      <description><![CDATA[我正在用 Python 开发一个机器学习项目，涉及表示来自 WordNet 的分层数据。我对此目的感兴趣，因为它适用于分层结构，因此我有兴趣使用 Mamba 模型。
我需要帮助：
我正在寻找一个预先训练好的 Mamba 模型，该模型专门针对 WordNet 数据进行训练。有人知道是否有这样的模型，或者如果没有，我该如何训练它？
我尝试过的方法：

我在 Hugging Face 和其他 ML 模型存储库中搜索过，但没有找到在 WordNet 上训练的明确提及为“Mamba”的模型。
我尝试在 WordNet 的一个子集上训练一个基本的图形神经网络模型，但我不确定我是否走在正确的轨道上。
]]></description>
      <guid>https://stackoverflow.com/questions/78826929/how-to-find-or-train-a-mamba-model-for-hierarchical-data-using-wordnet-in-python</guid>
      <pubDate>Fri, 02 Aug 2024 19:14:40 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 ApplePersistenceIgnoreState 错误？</title>
      <link>https://stackoverflow.com/questions/78826248/how-to-fix-applepersistenceignorestate-error</link>
      <description><![CDATA[我正在学习一个关于如何使用神经网络进行图像分类的 Neuralnine 教程。
我正在使用 Imac。
下面是代码：
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layer, models
#准备数据
(training_images, training_labels), (testing_images, testing_labels) = datasets.cifar10.load_data()
training_images, testing_images = training_images / 255, testing_images / 255

class_names = [&#39;Plane&#39;, &#39;Car&#39;, &#39;Bird&#39;, &#39;Cat&#39;, &#39;Deer&#39;, &#39;Dog&#39;, &#39;Frog&#39;, &#39;Horse&#39;, &#39;Ship&#39;, &#39;Truck&#39;]

for i in range(16):
plt.subplot(4,4,i+1)
plt.xticks([])
plt.yticks([])
plt.imshow(training_images[i], cmap=plt.cm.binary)
plt.xlabel(class_names[training_labels[i][0]])

plt.show()

training_images = training_images[:5000] #节省时间
training_labels = training_labels[:5000]
testing_images = testing_images[:4000]
testing_labels = testing_labels[:4000]

model = models.Sequential()
model.add(layers.Conv2D(32, (3,3),activation=&#39;relu&#39;, input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3),激活=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), 激活=&#39;relu&#39;))
model.add(layers.Flatten())
model.add(layers.Dense(64, 激活=&#39;relu&#39;))
model.add(layers.Dense(10, 激活=&#39;softmax&#39;))

model.compile(optimizer=&#39;adam&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

model.fit(training_images, training_labels, epochs=10, validation_data=(testing_images, testing_labels))

我在终端中收到以下消息：
ApplePersistenceIgnoreState：现有状态将不会已触及。新状态将写入 /var/folders/2g/.../T/org.python.python.savedState
2024-08-02 16:29:19.788 Python[48146:6869495] 警告：未启用可恢复状态的安全编码！通过实现 NSApplicationDelegate.applicationSupportsSecureRestorableState: 并返回 YES 来启用安全编码。

完全不知道该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/78826248/how-to-fix-applepersistenceignorestate-error</guid>
      <pubDate>Fri, 02 Aug 2024 15:36:34 GMT</pubDate>
    </item>
    <item>
      <title>如何优化 SageMaker/Hugging Face 端点以生成 Cypher 查询？</title>
      <link>https://stackoverflow.com/questions/78826111/how-to-optimize-sagemaker-hugging-face-endpoint-for-cypher-query-generation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78826111/how-to-optimize-sagemaker-hugging-face-endpoint-for-cypher-query-generation</guid>
      <pubDate>Fri, 02 Aug 2024 15:00:50 GMT</pubDate>
    </item>
    <item>
      <title>分类器 ML 基于特征和连续变量值预测类别的算法</title>
      <link>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</link>
      <description><![CDATA[我正在尝试编写一个分类器，我可以训练它来查看问题实例，并根据其特征和特定变量的值预测问题属于哪个类。我不是在寻找问题的答案，而只是寻找一些关于我应该专注于研究哪种 ML 算法的指导。
这是一个示例问题。假设我们有一些蛋糕食谱。它们具有以下连续变量特征：

面粉量
牛奶量
鸡蛋数量
糖的量

我们还有一个二进制变量：

蛋糕是用燃气还是电烤箱烤的？ （假设燃气为 1，电为 0）
每个食谱都烹制了两次，一次使用燃气，一次使用电

还通过让一些人吃蛋糕来测试蛋糕，每个人都给每个蛋糕一个“美味”指数。这也是一个连续变量，值越高，人们就越喜欢这个蛋糕。
我多次运行这个程序，最终得到一个数据集，每个食谱有两个条目（一个燃气，一个电），每个食谱都有各自的“美味指数”。我们会发现，对于每道菜谱，人们倾向于用燃气或电烹饪，这反映在口味指数中。
现在，我知道这是不现实的，但这是一种说明我想做什么的简单方法。
在训练系统执行此操作后，我现在想让系统采用一种新食谱，并根据具有相似（不一定相同）特征的过去食谱以及燃气或电是否提供最高的口味指数来预测应该使用燃气还是电烹饪。
任何关于哪种机器学习算法最适合此任务的建议都将不胜感激。如前所述，我只是想缩小我的研究范围，而不一定是被灌输答案。
到目前为止，我已经使用 Scikit-learn 在 Python 中尝试了几种 ML 算法。事实证明，KNN 在基于特征预测类别方面最准确，但我不确定如何将“口味指数”反映到其中。此外，这似乎是监督机器学习的一个例子，因为数据被标记（天然气或电力）。]]></description>
      <guid>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</guid>
      <pubDate>Fri, 02 Aug 2024 12:17:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么我用 Python 实现的 Skip-Gram 产生了错误的结果？</title>
      <link>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-in-python-producing-incorrect-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-in-python-producing-incorrect-results</guid>
      <pubDate>Fri, 02 Aug 2024 07:15:07 GMT</pubDate>
    </item>
    <item>
      <title>更清晰的分割 SAM (Segment Anything)</title>
      <link>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</link>
      <description><![CDATA[我需要像这样分割图像上的对象：
图像 1
图像 2
我选择使用 Meta 的 AI SAM（Segment Anything）来裁剪这些对象。
我的代码如下所示：
import cv2
import numpy as np
import sys, os
from pathlib import Path
import torch
import surveillance as sv
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor

# 获取命令行参数
num = sys.argv[2]
img_path = sys.argv[1]
folder_path = sys.argv[3]

# 从给定路径加载图像
img = cv2.imread(img_path)

# 用于预处理图像以进行裁剪的函数
def preprocess_image_cut(img):
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
return gray

# 用于获取干净图像的函数
def get_clean_image(img, filter_level=1):
gray = preprocess_image_cut(img)
blurred_image = cv2.GaussianBlur(gray, (3, 3), 0)
_, binary_image = cv2.threshold(blurred_image, 210, 255, cv2.THRESH_BINARY)

kernel = np.ones((1, 1), np.uint8)
result_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
result_image = cv2.medianBlur(result_image, filter_level)

output_image = cv2.bitwise_or(gray, result_image)
return output_image

# 设置管道的函数
def setup_pipeline():
HOME = &#39;C:/&#39;
CHECKPOINT_PATH = os.path.join(HOME, &#39;weights&#39;, &#39;sam_vit_h_4b8939.pth&#39;)
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
MODEL_TYPE = &quot;vit_h&quot;

sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)
return mask_generator

# 运行 SAM 模型的函数
def run_sam(mask_generator, clean_image):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
sam_result = mask_generator.generate(image_rgb)
mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)
detections = sv.Detections.from_sam(sam_result=sam_result)

annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)

masks = [mask[&#39;segmentation&#39;] for mask in sorted(sam_result, key=lambda x: x[&#39;area&#39;, reverse=True])]
return mask

# 设置掩码生成器
mask_generator = setup_pipeline()

if __name__ == &quot;__main__&quot;:
if img_path.endswith(&quot;.png&quot;):
save_path = folder_path
os.makedirs(save_path, exist_ok=True)
if os.path.isdir(f&#39;{folder_path}/PROCESSED&#39;):
os.makedirs(f&#39;{folder_path}/PROCESSED&#39;, exist_ok=True)
img = cv2.imread(img_path)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
clean_image = get_clean_image(img, 3)

print(&quot;开始生成掩码&quot;)
mask = run_sam(mask_generator, clean_image)

for i, mask in enumerate(masks):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgra = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGRA)
extract_region = np.zeros_like(image_bgra)
extract_region[mask] = image_bgra[mask]
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
extract_region = extract_region[y:y+h, x:x+w]
extracted_region[:, :, 3] = (mask[y:y+h, x:x+w] &gt; 0) * 255
save_path2 = f&#39;{folder_path}/PROCESSED/img_{x}_{y}_{w}_{h}.png&#39;
cv2.imwrite(save_path2, extracted_region)

print(&quot;Finished&quot;)

但我在一些问题上遇到了困难，比如我不想让 Sam 分割数字，也不想分割将对象与数字联系起来的线条。
有人能就这个问题提出一些想法吗？也接受其他方法来分割图像。]]></description>
      <guid>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</guid>
      <pubDate>Thu, 01 Aug 2024 20:21:17 GMT</pubDate>
    </item>
    <item>
      <title>NotImplementedError：无法将符号张量（up_sampling2d_4_target：0）转换为 numpy 数组</title>
      <link>https://stackoverflow.com/questions/60430561/notimplementederror-cannot-convert-a-symbolic-tensor-up-sampling2d-4-target0</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/60430561/notimplementederror-cannot-convert-a-symbolic-tensor-up-sampling2d-4-target0</guid>
      <pubDate>Thu, 27 Feb 2020 09:59:10 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：估计器不适合，在利用模型之前调用“fit”</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在 Macbook OSX 10.2.1 (Sierra) 上运行 Python 3.5.2。
尝试运行 Kaggle 的 Titanic 数据集的一些代码时，我不断收到以下错误：


NotFittedError Traceback (most recent call
last) in ()
6 
7 # 使用测试集进行预测并打印它们。
----&gt; 8 my_prediction = my_tree_one.predict(test_features)
9 print(my_prediction)
10 
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input) 中
429 &quot;&quot;&quot;
430 
--&gt; 431 X = self._validate_X_predict(X, check_input)
432 proba = self.tree_.predict(X)
433 n_samples = X.shape[0]
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input)
386 “”“每当有人试图预测、应用、predict_proba 时验证 X”””
387 if self.tree_ is None:
--&gt; 388 raise NotFittedError(“估算器未安装，&quot;
389 “在利用模型之前调用 fit。”)
390 
NotFittedError：估算器未安装，在利用
模型之前调用 fit。

有问题的代码似乎是这样的：
# 用中位数估算缺失值
test.Fare[152] = test.Fare.median()

# 从测试集中提取特征：Pclass、Sex、Age 和 Fare。
test_features = test[[&quot;Pclass&quot;, &quot;Sex&quot;, &quot;Age&quot;, &quot;Fare&quot;]].values

# 使用测试集进行预测并打印。
my_prediction = my_tree_one.predict(test_features)
print(my_prediction)

# 创建一个包含两列的数据框：PassengerId 和 Survived。 Survived 包含您的预测
PassengerId =np.array(test[&quot;PassengerId&quot;]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [&quot;Survived&quot;])
print(my_solution)

# 检查您的数据框是否有 418 个条目
print(my_solution.shape)

# 将您的解决方案写入名为 my_solution.csv 的 csv 文件
my_solution.to_csv(&quot;my_solution_one.csv&quot;, index_label = [&quot;PassengerId&quot;])

以下是其余部分的链接 代码。
由于我已经调用了“fit”函数，我无法理解此错误消息。我哪里做错了？感谢您的时间。
编辑：
结果发现该问题继承自上一个代码块。
# 拟合您的第一个决策树：my_tree_one
my_tree_one = tree.DecisionTreeClassifier()
my_tree_one = my_tree_one.fit(features_one, target)

# 查看所包含特征的重要性和分数
print(my_tree_one.feature_importances_)
print(my_tree_one.score(features_one, target))

使用以下行：
my_tree_one = my_tree_one.fit(features_one, target)
生成错误：

ValueError：输入包含 NaN、无穷大或对于
dtype(&#39;float32&#39;)。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>