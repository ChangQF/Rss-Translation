<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Apr 2024 12:25:03 GMT</lastBuildDate>
    <item>
      <title>迁移学习：图像分类精度高，但 val_loss 非常高。为什么？</title>
      <link>https://stackoverflow.com/questions/78408313/transfer-learning-image-classification-high-accuracy-but-very-high-val-loss-wh</link>
      <description><![CDATA[我正在使用 tensorflow 和 Keras 使用 Resnet_50 进行迁移学习。我遇到的问题是，我的模型似乎在准确率上表现不错，但我的 val_loss 非常高，而且当我尝试进行预测时，准确率非常低。
以下是代码的相关部分：
# 创建一个带有数据增强的 ImageDataGenerator 进行训练
data_generator = keras.preprocessing.image.ImageDataGenerator(
rescale=1./255,
validation_split=0.5,
rotation_range=30, # 随机旋转
width_shift_range=0.2, # 水平移位
height_shift_range=0.2, # 垂直移位
sher_range=0.2, # 剪切变换
zoom_range=0.2, # 缩放
Horizo​​ntal_flip=True, # 水平翻转
)

# 加载和预处理训练数据
train_data_flow = data_generator.flow_from_directory(
dataset_path,
target_size=(224, 224), # 将图像大小调整为 224x224
batch_size=32,
class_mode=&#39;categorical&#39;,
subset=&#39;training&#39; # 使用训练子集
)

# 加载并预处理验证数据
val_data_flow = data_generator.flow_from_directory(
dataset_path,
target_size=(224, 224), # 将图像大小调整为 224x224
batch_size=32,
class_mode=&#39;categorical&#39;,
subset=&#39;validation&#39; # 使用验证子集
)

加载模型
# 从 TensorFlow Hub 加载模型
model_url = &quot;https://tfhub.dev/tensorflow/resnet_50/feature_vector/1&quot;
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3) , trainable=False)

# 创建具有 dropout 和批量归一化的 Sequential 模型
model = keras.Sequential([
hub_layer,
layer.Dropout(0.2), # 降低 dropout 率
layer.Dense(256,activation=&#39;relu&#39;),
layer.BatchNormalization(), # 批量归一化
layer.Dropout(0.5), # Dropout
layer.Dense(9,activation=&#39;softmax&#39;)
])

# 构建 Sequential 模型
model.build((None, 224, 224, 3))

# 模型摘要
model.summary()

然后我编译：
# 编译模型
model.compile(
optimizer=&#39;adam&#39;,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;]
)

最后：
# 使用早期停止来拟合模型
history = model.fit(
train_data_flow,
validation_data=val_data_flow,
epochs=15, # epochs 数量,
)

以下是 epochs：
Epoch 1/15
81/81 [================================] - 489s 6s/step - loss: 0.3773 - accuracy: 0.8832 - val_loss: 0.7994 - val_accuracy: 0.7476
Epoch 2/15
81/81 [==============================] - 489s 6s/步 - 损失：0.3316 - 准确度：0.8980 - val_loss：0.8229 - val_accuracy：0.7378
Epoch 3/15
81/81 [==============================] - 488s 6s/步 - 损失：0.3468 - 准确度：0.8879 - val_loss：0.8221 - val_accuracy：0.7362
Epoch 4/15
81/81 [===============================] - 489s 6s/步 - 损失：0.3148 - 准确度：0.9011 - val_loss：0.8380 - val_accuracy：0.7362
Epoch 5/15
81/81 [==============================] - 488s 6s/步 - 损失：0.3250 - 准确度：0.8972 - val_loss：0.7680 - val_accuracy：0.7409
Epoch 6/15
81/81 [================================] - 491s 6s/步 - 损失：0.3100 - 准确度：0.9026 - val_loss：0.7220 - val_accuracy：0.7616
Epoch 7/15
81/81 [=============================] - 491s 6s/步 - 损失：0.2844 - 准确度：0.9120 - val_loss：0.7259 - val_accuracy：0.7651
Epoch 8/15
81/81 [===============================] - 490s 6s/步 - 损失：0.2811 - 准确度：0.9007 - val_loss：0.7722 - val_accuracy：0.7511
Epoch 9/15
81/81 [==============================] - 490s 6s/step - 损失：0.2689 - 准确度：0.9167 - val_loss：0.7943 - val_accuracy：0.7433
Epoch 10/15
81/81 [==============================] - ETA：0s - 损失：0.2569 - 准确度：0.9182

预测：
测试集上的模型准确度：0.2021069059695669
]]></description>
      <guid>https://stackoverflow.com/questions/78408313/transfer-learning-image-classification-high-accuracy-but-very-high-val-loss-wh</guid>
      <pubDate>Tue, 30 Apr 2024 11:50:46 GMT</pubDate>
    </item>
    <item>
      <title>如何输出估计的工作量结果=数据集长度[关闭]</title>
      <link>https://stackoverflow.com/questions/78407801/how-to-output-the-estimated-effort-result-dataset-length</link>
      <description><![CDATA[如何输出估计工作量结果 = 数据集长度？
在此处输入图片描述
用于计算工作估计，可以使用平均值、中位数或 IRWA（逆排名加权平均值）方法对类似的适应进行调整。所使用的类比适配的选择由程序中预先设置的参数决定。对数据集中的每个数据执行计算估计工作量的过程。在每次迭代中，程序都会检查类比适应参数 (self.adaptationAnalogy) 的值。如果值为 1，将使用mean_k 方法来计算该数据的估计工作量。如果值为2，则使用median_k方法，如果值为3，则使用irwa_k方法。]]></description>
      <guid>https://stackoverflow.com/questions/78407801/how-to-output-the-estimated-effort-result-dataset-length</guid>
      <pubDate>Tue, 30 Apr 2024 10:12:29 GMT</pubDate>
    </item>
    <item>
      <title>转换深度学习 esrgan 模型时输入张量形状不匹配</title>
      <link>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</guid>
      <pubDate>Tue, 30 Apr 2024 10:05:56 GMT</pubDate>
    </item>
    <item>
      <title>我无法将数据插入/更新到 postgres 数据库表中[关闭]</title>
      <link>https://stackoverflow.com/questions/78407703/i-am-unable-to-insert-update-data-into-postgres-database-table</link>
      <description><![CDATA[我已经在 postgres 数据库中创建了一个表。我正在尝试使用 api 更新或插入它。正确编写插入查询。
可能是什么原因？]]></description>
      <guid>https://stackoverflow.com/questions/78407703/i-am-unable-to-insert-update-data-into-postgres-database-table</guid>
      <pubDate>Tue, 30 Apr 2024 09:56:37 GMT</pubDate>
    </item>
    <item>
      <title>什么时候应该进行特征选择？</title>
      <link>https://stackoverflow.com/questions/78407668/when-should-i-do-characteristic-selection</link>
      <description><![CDATA[我正在运行一些机器学习算法来训练模型。
到目前为止，我一直在制作相关矩阵，以便选择与目标变量相关性最高的特征。
我在网上读到，除非我运行逻辑回归，否则不需要进行此选择。这是真的吗？
我运行的算法是逻辑回归、决策树、SVM、KNN 和朴素贝叶斯。
我是否应该使用具有除 Logistic 回归之外的所有算法的所有特征的训练集以及仅包含 Logistic 回归最相关变量的另一个版本？]]></description>
      <guid>https://stackoverflow.com/questions/78407668/when-should-i-do-characteristic-selection</guid>
      <pubDate>Tue, 30 Apr 2024 09:50:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使 XGBoost 在分层分类器中工作</title>
      <link>https://stackoverflow.com/questions/78407603/how-to-make-xgboost-work-in-a-hierarchical-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78407603/how-to-make-xgboost-work-in-a-hierarchical-classifier</guid>
      <pubDate>Tue, 30 Apr 2024 09:37:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试对简短的调查答案进行聚类（1 到 10 个单词）。我走在正确的轨道上吗？</title>
      <link>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</link>
      <description><![CDATA[这是我想要完全制作的内容的解释（这是学校的一个项目）。

用户只需将调查中提出的任何问题的答案放入一个文件即可。

2.机器找到相似的答案，并将它们分组到一个未命名的标签或簇下（考虑使用 MeanShift、GMM、KMeans）

如果可能的话，我还希望它为集群生成标签。

4.将聚类和标记的答案写回到文件中以供检查并用于任何目的。
关于数据的一些上下文：很多简短的答案（有一些长的，超过 10 个单词）答案，例如“我不知道”、“??”、“有帮助”、“红色”等，以及每个都有 200 到 2000 个答案。答案是荷兰语或法语，是否建议我将它们翻译成英语以获得更好的性能？通常有大约 7 到 20 个（数量较多的情况很少见）簇。我还有正确的答案标签，这样我就可以检查算法是否正确聚类。
我尝试过研究它，我需要首先对我的文本进行矢量化，为此我尝试了 scikit 中的 TF-IDF 和 Count 矢量化器。我还找到了他们的备忘单，它建议我使用 MeanShift。
我还没有尝试寻找最佳参数，但性能似乎很差（接近随机）。我使用调整兰德指数、归一化互信息和轮廓分数来评估。
我走在正确的道路上还是有更好的东西？矢量化方法、嵌入、聚类算法？]]></description>
      <guid>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</guid>
      <pubDate>Tue, 30 Apr 2024 07:50:57 GMT</pubDate>
    </item>
    <item>
      <title>从 python 中的随机森林回归模型中查找最大值</title>
      <link>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</link>
      <description><![CDATA[当用户给出上限时，我一直在使用随机森林回归来计算广告支出回报率 (ROAS)。我的模型采用三个输入变量：电视、广播和报纸广告的成本。然而，为了找到最优值，我需要使用 for 循环来遍历每一美元，这非常耗时。有没有更快的方法来找到程序中的最高 y 值？
def ROASPrediction(Q、电视、广播、报纸)：
rec=“最佳销售推荐投资”
y_大=0
x_b=0
y_b=0
z_b=0
对于范围内的 x(TV//2,TV)：
  对于范围内的 y(Radio//2,Radio)：
    对于范围内的 z（报纸//2，报纸）：
      customer_features =np.array([x,y,z])
      customer_features1=customer_features.reshape(1, -1)
#customer_features1 =pd.DataFrame(customer_features)
      model_fit1 = joblib.load(&#39;/content/drive/MyDrive/LUV BARNWAL/ROAS.joblib&#39;)
      y_future_pred = model_fit1.predict(customer_features1)
      打印（“y_future_pred”，y_future_pred）
      if(y_future_pred[0]&gt;=y_big):
        y_big=y_future_pred[0]
        x_b=x
        y_b=y
        z_b=z
#y_future_pred1= str(y_future_pred[0]) + “M$”
#y_roas= y_future_pred[0]*1000000 / (电视+广播+报纸)
y_future_pred1= str(y_big) + “M$”
y_roas= y_big*1000000 / (电视+广播+报纸)
x_b1=str(x_b)
y_b1=str(y_b)
z_b1=str(z_b)
y_roas1=str(y_roas) + “%”
返回记录，x_b1，y_b1，z_b1，y_future_pred1，y_roas1

以下代码是我的随机森林模型。
df = pd.read_csv(&#39;/Advertising.csv&#39;)
df.head()
x = df[[&#39;电视&#39;,&#39;广播&#39;,&#39;报纸&#39;]]
y = df[[&#39;销售额&#39;]]
x_train, x_test, y_train, y_test = train_test_split (x, y, test_size=0.20 , random_state=41)
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
rf_regressor.fit(x_train, y_train)
y_pred = rf_regressor.predict(x_test)

这是我正在使用的 csv 文件。 
有没有办法让 ROASPrediction 函数更加高效，这样就不需要 5 分钟来计算 30 美元的电视、广播和报纸？]]></description>
      <guid>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</guid>
      <pubDate>Tue, 30 Apr 2024 06:42:36 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音输入说明如何运作？</title>
      <link>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</link>
      <description><![CDATA[我正在研究一些听写应用程序，例如 Nuance Dragon 等，它允许您用语音进行听写和编辑文本。为了弄清楚这个工作原理，我偶然发现了文档中的谷歌语音输入功能，我对系统的速度和准确性感到震惊。
谷歌语音输入：https://support.google.com/docs/回答/4492226?sjid=14897244542593477678-AP
细微龙：https://www.nuance.com/dragon.html&lt; /p&gt;
所以，这不仅仅是一个简单的 STT 模型来提供转录 - 它允许您转到特定单词、突出显示、应用格式等。我参与了很多后期处理（我认为）
我是一名初级机器学习工程师，所以我了解 STT 模型及其工作原理，但这个语音输入和编辑系统看起来更复杂。
我想知道这样的系统是如何工作的。任何见解将不胜感激。
我试图了解这样的系统的底层架构，但找不到任何具体的东西。我希望了解该系统的人可以帮助我理解它。]]></description>
      <guid>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</guid>
      <pubDate>Tue, 30 Apr 2024 05:25:06 GMT</pubDate>
    </item>
    <item>
      <title>当时间序列元数据变化时如何构建多元时间序列</title>
      <link>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</link>
      <description><![CDATA[我根据多元、地理、时间序列数据进行预测。
我的数据包括每种产品的历史价格和生产数量，不同的地方生产和销售不同的产品组。例如：

&lt;标题&gt;

旧金山
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

小麦





美元价格
3
4
3


生产数量T
200
100
150


苹果





美元价格
1
2
0.8


生产数量T
20
10
50




&lt;标题&gt;

布里斯班
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

米饭





美元价格
3
4
3


生产数量T
200
100
150


香蕉





美元价格
5
4
3


生产数量T
200
300
450



每个地点的产品列表都不同（日期范围和长度也不同，但这些问题的解决方案都有详细记录）。我正在寻找异常情况并预测消费类别。我应该如何构建它来进行训练和预测？
&lt;小时/&gt;
我的猜测（您可能可以停止阅读这里，因为这是新手的猜测，但建议包括迄今为止完成的工作）：
我可以使用的一种方法是将所有价格标准化并平均。 （收集每个区域最重要产品的价格。）但这会消除很多细节。我可以根据种植的数量来猜测每种产品的重要性，但这通常会产生误导。价格和产量之间的关系和紧张关系很重要。
我猜想，暴力方法是在每个示例中包含每个产品，并为未在某个区域交易的任何产品的时间序列使用一个空令牌。但这将是一个非常稀疏且庞大的数据集。
我可以说product1=“大米w2v嵌入”，product2=“香蕉w2v嵌入”，price_timeseries1=[大米价格]，price_timeseries2=[香蕉价格]（加上产量，以及在另一个例子中，小麦和苹果也是如此）？有任何模型能够解释这一点吗？
我最好的猜测是将产品分类，例如，将大米和小麦分类为“碳水化合物”，然后标准化，然后对每个类别的产品进行平均。 （我确实有一个层次结构，但是有没有办法可以导出或学习分类？）这在统计上有效吗？
源地理数据以行政单位（城镇边界多边形）为单位。我正在考虑选择（a）将所有内容转换为 100km2 网格，或（b）cos（lat）.cos（lon），cos（lat）.sin（lon），sin（lat） 形状质心 lon/lat，获取 3D 中的（缩放）坐标，加上面积。选项（b）更容易，除了管理单位随着时间的推移而变化，所以我必须将旧的数字重新分配到最新的边界。
（我还将添加位置元数据，例如国家/地区、人口、季节时间序列等）
有什么建议/预感吗？或者只是从单变量开始并构建？
我（也许天真地）正在考虑 ARIMA、XGBoost、LSTM、timeseries变压器，也许Mamba，如果相关的话。鉴于我完全缺乏经验，我怀疑 XGBoost 可能是复杂性/功能和新手超参数调整技能的最佳点，尽管我会尝试更复杂的架构，因为我知道树会错过生产和价格之间的相互作用，这在这里很重要。&lt; /p&gt;
非常感谢您提供任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</guid>
      <pubDate>Tue, 30 Apr 2024 05:08:43 GMT</pubDate>
    </item>
    <item>
      <title>选择具有相似精度但变量数量不同的模型</title>
      <link>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</link>
      <description><![CDATA[我使用不同的变量集开发了机器学习模型 (XGBClassifier)，两组的准确度得分都在 80% 左右。然而，一个模型使用 17 个变量，而另一个模型使用 18 个变量。我不确定选择哪种模型进行部署。以下是我正在考虑的一些因素：

可解释性：据我所知，为了便于解释，通常更倾向于使用变量较少的简单模型。这是否意味着我应该倾向于使用 17 个变量的模型？

过度拟合：即使使用两个变量集具有相似的准确度分数，具有 18 个变量的模型是否会由于其较高的复杂性而更容易过度拟合？

计算效率：变量较少 (17) 的模型在训练和预测时间方面的计算效率是否更高？

特征重要性：如何评估具有 18 个变量的模型中附加变量的重要性？有没有办法确定它是否提供了有意义的见解或提高了性能？

数据质量：在做出此决定时是否应该考虑数据集的质量和维度？添加额外变量是否存在任何风险，例如对噪声的敏感性增加或过度拟合？

信息：更多变量是否能为模型提供更多信息，从而做出更好的决策？

考虑：我参加的是 Kaggle 私人竞赛，所以评估考虑得更多。


考虑到这些因素，我应该如何在精度相似但变量数量不同的这两个集合之间做出选择？在这种情况下我应该遵循哪些最佳实践或指南？
任何见解或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</guid>
      <pubDate>Tue, 30 Apr 2024 04:35:46 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 Designer 中使用在 Azure AutoML 中创建的 ML 模型？</title>
      <link>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</link>
      <description><![CDATA[我知道我可以在 Azure Designer 中创建自定义代码模块，但是有没有办法连接我在 AutoML 中本机创建的 ML 模型？
AutoML 模型正在使用 XGBoost，这似乎不是 Designer 的 ML 组件功能下的选项。我的目标是创建一个低代码解决方案，因此我不想使用自定义 Python 代码组件。
有什么想法吗？
使用 AutoML 构建模型，需要连接到 Designer 中的现有数据管道]]></description>
      <guid>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</guid>
      <pubDate>Mon, 29 Apr 2024 14:52:21 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：基数为 10 的 int() 的文字无效：Q-learning 中的“”</title>
      <link>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</guid>
      <pubDate>Sun, 28 Apr 2024 17:29:11 GMT</pubDate>
    </item>
    <item>
      <title>调用 OnActionReceived 或 RequestDecision 让 Unity ML-Agent 轮流执行，观察次数较少 (0)</title>
      <link>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</guid>
      <pubDate>Mon, 11 Mar 2024 06:13:00 GMT</pubDate>
    </item>
    <item>
      <title>识别图像中钢筋上的锈迹</title>
      <link>https://stackoverflow.com/questions/59048488/identifying-rust-on-steel-bars-in-images</link>
      <description><![CDATA[我正在探索在类似于此处链接的图像中识别钢制品上生锈的方法：生锈钢筋。 
目前，我只是对整个图像应用简单的图像处理技术，以拾取特定色调的红色/棕色/橙色来识别铁锈。我遇到的问题是，这也将背景区域（任何非钢的东西）识别为生锈，这是可以预料的。因此我需要消除这种噪音以使我的结果更加可靠。
我研究过的一个想法是分割图像中的钢结构，并将简单的图像处理技术仅应用于钢，这将消除背景中的任何噪音。然而，我是计算机视觉的新手，我不知道从哪里开始这样的事情。
所以，我的问题是，对于此类任务，您是否会推荐任何特定的图像分割技术？有没有我可以使用的资源来学习如何应用此类技术？
我的一个想法是在 keras 中训练图像分割模型，但我以前没有这样做过，因此需要大量时间来学习如何做到这一点并准备数据。
另外，回到最初的问题，是否有其他方法可以在不接收背景噪音的情况下隔离钢结构上的锈迹？&lt;​​/p&gt;

谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/59048488/identifying-rust-on-steel-bars-in-images</guid>
      <pubDate>Tue, 26 Nov 2019 10:12:25 GMT</pubDate>
    </item>
    </channel>
</rss>