<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 01 Apr 2024 18:16:36 GMT</lastBuildDate>
    <item>
      <title>损失函数在梯度提升中的作用是什么？</title>
      <link>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</link>
      <description><![CDATA[在梯度提升中，可以使用不同的损失函数。例如，在 sklearn 的 GradientBoostingRegressor 中，可能的损失函数有：“squared_error”、“absolute_error”、“huber”和“quantile”损失函数。
我了解损失函数在梯度下降（而不是梯度提升）中的影响。例如，与绝对误差损失函数相比，平方误差损失函数对大误差的惩罚更大。我们可以在梯度提升的情况下说类似的话吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</guid>
      <pubDate>Mon, 01 Apr 2024 18:03:20 GMT</pubDate>
    </item>
    <item>
      <title>无法解释指标标识符 - scikeras.wrappers.KerasRegressor</title>
      <link>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</link>
      <description><![CDATA[我正在尝试使用 scikeras.wrappers.KerasRegressor 调整超参数，但遇到了如下问题：
代码：
 # 定义一个函数来创建 lstm_model 的实例
def create_lstm_model():
    
    模型=顺序（[
            LSTM(5, input_shape = (Xtrain.shape[1], Xtrain.shape[2]), dropout = 0.1, 激活 = &#39;tanh&#39;, return_sequences = True),
            LSTM(10, dropout = 0.05, 激活 = &#39;tanh&#39;),
            密集（5，激活=&#39;relu&#39;），
            密集(1)
        ]）
    model.compile(优化器 = tf.keras.optimizers.Adam(), 损失 = tf.keras.losses.MeanSquaredError(), 指标 = [keras.metrics.MeanSquaredError()])
    
    返回模型

#为网络创建sklearn模型
模型 = KerasRegressor(build_fn = create_lstm_model, verbose = 1)

#参数网格
批次 = [16, 32]
历元 = [3, 4]

param_grid = dict(batch_size = 批次, epochs = epochs)

网格 = GridSearchCV(估计器 = 模型,
                    参数网格 = 参数网​​格,
                    简历 = 3)
grid.fit（Xtrain，ytrain，validation_data =（Xvalidation，yvalidation））

错误：
&lt;前&gt;&lt;代码&gt; fn_or_cls = keras_metric_get(公制)
  文件“/home/aaa/Desktop/aaa/aaa/2024-gold-price-prediction-with-lstm-model/.venv/lib/python3.10/site-packages/keras/src/metrics/__init__.py” ;，第 204 行，在 get 中
    raise ValueError(f“无法解释指标标识符：{identifier}”)
ValueError：无法解释指标标识符：损失

我从更复杂的代码开始，并在故障排除期间将其简化到最低限度。我什至试图从模型函数中删除指标。
您对我的代码有什么问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</guid>
      <pubDate>Mon, 01 Apr 2024 18:02:32 GMT</pubDate>
    </item>
    <item>
      <title>带有注意力图执行错误的 LSTM 掩码</title>
      <link>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</guid>
      <pubDate>Mon, 01 Apr 2024 17:43:41 GMT</pubDate>
    </item>
    <item>
      <title>为回归数值数据实现 ResNet Multi Output</title>
      <link>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</guid>
      <pubDate>Mon, 01 Apr 2024 14:15:11 GMT</pubDate>
    </item>
    <item>
      <title>ONNX 模型池层转换器不支持称为扩张的属性</title>
      <link>https://stackoverflow.com/questions/78255741/onnx-model-pooling-layer-converter-does-not-support-attribute-called-dilations</link>
      <description><![CDATA[我在尝试使用 SnapChat 提供的多对象笔记本中的 ML 模型时遇到错误，当我导入 ML 模型时出现错误：
“D:/Downloads/best (6).onnx 的资源导入失败：‘/model.8/m/MaxPool’层出现异常：ONNX 模型池层转换器不支持名为 dilations 的属性”,
我不确定如何修复它以及问题是什么，因为它之前工作得很好。谢谢！
错误
我尝试使用其他笔记本转换为 .onnx 模型，但似乎没有效果]]></description>
      <guid>https://stackoverflow.com/questions/78255741/onnx-model-pooling-layer-converter-does-not-support-attribute-called-dilations</guid>
      <pubDate>Mon, 01 Apr 2024 13:25:09 GMT</pubDate>
    </item>
    <item>
      <title>解决神经网络训练期间的错误</title>
      <link>https://stackoverflow.com/questions/78255508/solving-error-during-neural-network-training</link>
      <description><![CDATA[这是我的代码，它给出了这样的错误，我需要帮助来解决这个问题。
train_loader = DataLoader(train_data,batch_size=32)
test_loader = DataLoader(test_data,batch_size=32,shuffle=False)
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
网络类（nn.Module）：
    def __init__(自身):
        超级（网络，自我）.__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, 填充=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        self.batchnorm1 = nn.BatchNorm2d(32)
        self.batchnorm2 = nn.BatchNorm2d(64)
        self.batchnorm3 = nn.BatchNorm2d(128)
        self.batchnorm4 = nn.BatchNorm2d(256)
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 100) # Cifar100 的 100 个类

    def 前向（自身，x）：
        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))
        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))
        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))
        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))
        x = x.view(-1, 256 * 4 * 4)
        x = self.dropout(x)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        返回x

网络 = Network().to(设备)

opt = Adam(network.parameters(),lr=1e-4)
loss_function = nn.CrossEntropyLoss()
对于范围（20）内的纪元：
    总损失= 0
    对于我，批量枚举（train_loader）：
        输入=批量[0].to(设备)
        目标 = 批处理[1].to(设备)
        y = 网络（输入）
        损失值 = 损失函数(y,目标)
        loss_value.backward()
        opt.step()
        总损失 += loss_value.item()
        print(f&quot;{total_loss / (i + 1)} ------ &gt; {i}&quot;)

我的错误是：“ValueError：预期输入batch_size (8) 与目标batch_size (32) 匹配。”
我还有第二个问题：我目前正在使用卷积网络在 CIFAR100 数据集上训练模型，但是从我尝试的各种模型获得的准确率非常低（损失约为 5，准确度约为 1%）。我不知道该怎么做才能选择更好的模型。我尝试过很多不同的模型，但我不想使用预先训练的模型；我想建立自己的。
请通过修改代码解决批量问题，并介绍为 CIFAR100 数据集构建合适模型的解决方案。
最美好的祝愿]]></description>
      <guid>https://stackoverflow.com/questions/78255508/solving-error-during-neural-network-training</guid>
      <pubDate>Mon, 01 Apr 2024 12:36:57 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 GAN 制作一个关于 DR 检测的项目，并尝试运行“models_from_json”，但它不起作用</title>
      <link>https://stackoverflow.com/questions/78255418/i-am-making-a-project-on-dr-detection-using-gan-and-trying-to-run-models-from-j</link>
      <description><![CDATA[所以在我的代码中，我尝试基本上从 json 中获取现有模型，但它不起作用
从 keras.models 导入顺序
从 keras.layers 导入 Convolution2D
从 keras.layers 导入 MaxPooling2D
从 keras.layers 导入扁平化
从 keras.layers 导入密集、激活、BatchNormalization
**从 keras.models 导入 model_from_json**


with open(&#39;model/train.json&#39;, &quot;r&quot;) 作为 json_file:
    load_model_json = json_file.read()
    加载模型 = model_from_json(加载模型_json)

loaded_model.load_weights(“模型/train.h5”)
loaded_model._make_predict_function()
打印（loaded_model.summary（））

我收到此错误：-
 with open(&#39;model/train.json&#39;, &quot;r&quot;) 作为 json_file：
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;model/train.json&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78255418/i-am-making-a-project-on-dr-detection-using-gan-and-trying-to-run-models-from-j</guid>
      <pubDate>Mon, 01 Apr 2024 12:16:19 GMT</pubDate>
    </item>
    <item>
      <title>train_test_split 机器学习中的 random_state</title>
      <link>https://stackoverflow.com/questions/78255303/random-state-in-train-test-split-machine-learning</link>
      <description><![CDATA[我看到了一个视频，他使用下面的循环来找到最佳的 random_state：
&#39;
#找到具有最高分数的TrainTestSplit随机状态的模型
#使用后移除
分数=[]
对于范围（1000）内的 i：
X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=i)
lr=线性回归()
管道=make_pipeline(column_tran,lr)
管道.fit(X_train,y_train)
y_pred=pipe.predict(X_test)
分数.append(r2_score(y_test,y_pred))
print(&#39;最高分由 i=&#39;,np.argmax(scores),&#39;得分为 &#39;,scores[np.argmax(scores)])
&#39;
我在网上看到的任何其他项目都没有这样做，我不确定是否找到最佳随机状态。
在使用它之前，我的 R2_SCORE 是 69.09，使用它之后，我的 R2_SCORE 达到了 89.1]]></description>
      <guid>https://stackoverflow.com/questions/78255303/random-state-in-train-test-split-machine-learning</guid>
      <pubDate>Mon, 01 Apr 2024 11:51:34 GMT</pubDate>
    </item>
    <item>
      <title>随机森林项目</title>
      <link>https://stackoverflow.com/questions/78255277/randomforest-project</link>
      <description><![CDATA[我对机器学习非常陌生，这是我作为大学课程的一部分正在从事的第一个项目。我选择了英国足球比赛。我选择使用随机森林。
使用不同的来源，我成功地获得了 20 年的上述比赛数据，清理了数据并构建了我的模型。
但是，我被困住了。我如何真正让模型对未来的比赛进行预测？
谢谢
我尝试加载模型，然后使用仅填充“日期”、“Home_Team”和“Away_Team”列的 CSV 文件，将其他列留空，以便模型预测这些值 - 这是执行此操作的正确方法吗？ 
更新：
谢谢 - 请参阅用于构建模型的代码；
从 sklearn.ensemble 导入 RandomForestClassifier
train = matches[matches[“日期”] &lt; &#39;2012-06-01&#39;]
测试=匹配[匹配[“日期”]&gt; &#39;2012-06-01&#39;]
预测器 = [&#39;Home_Team&#39;、&#39;Away_Team&#39;、&#39;HT_Winner&#39;、&#39;FT_Winner&#39;、&#39;match_result&#39;、&#39;ht_match_result&#39;、&#39;HomeShots&#39;、&#39;AwayShots&#39;、&#39;HomeCorners&#39;、&#39;AwayCorners&#39;]
rf.fit(train[预测变量], train[“FT_Winner”])
preds = rf.predict(测试[预测变量])

用于未来预测的新 CSV：
导入 pandas 作为 pd

new_data_df = pd.read_csv(..)
预测 = model.predict(new_data_df)

更新的 CSV 包含所有相同的列（仅填充日期、Home_Team 和 Away_Team 列，因为这是当前唯一可用的信息，以及希望模型进行预测的其他列。但是当尝试获取新的预测时CSV，我得到以下内容；
“特征名称的顺序必须与拟合时的顺序相同。\n”
值错误（消息）
ValueError：特征名称应与拟合期间传递的特征名称相匹配。
]]></description>
      <guid>https://stackoverflow.com/questions/78255277/randomforest-project</guid>
      <pubDate>Mon, 01 Apr 2024 11:46:02 GMT</pubDate>
    </item>
    <item>
      <title>C++ 如何创建带有游戏训练的神经网络？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78255012/c-how-to-create-a-neural-network-with-game-training</link>
      <description><![CDATA[互联网上关于如何用 C++ 创建神经网络的信息很少。我对 C++ 基础非常熟悉。我的目标是用 C++ 创建神经网络，以便它们可以玩特定的游戏。例如，您可以从使用井字游戏开始，然后是战舰、国际象棋，以及使用更复杂的游戏，如大富翁和其他游戏。
我使用了来自互联网、YouTube 来源观看视频的更多信息。我了解了不同类型的神经网络，其中一些对某些动作以分数形式给予奖励。
我了解 CNN 模型、RNN、GAN 等架构。我知道LSTM、GRU是用来存储上下文的，充当内存。权重在神经元中用于某种目的，各种激活函数有 ReLu、sigmoid、tanh。
我还想为需要 2 名以上玩家的游戏创建竞争性神经网络，例如大富翁和其他游戏。将代码从 Python 翻译为 C++ 并不是最好的解决方案。
更新：
我需要有关如何制作能够玩游戏以及制作竞争性神经网络的神经网络的信息。问题是如何在 C++ 中实现这一点。我刚刚用 JavaScript 编写了一个更简单的神经网络。
更新：
我问 OpenAI 的 ChatGPT 如何完成这个任务，他回答说：
要为井字游戏创建这样的神经网络，您需要编写 291 个“if else”块来记住游戏所有动作的模式。

实现国际象棋神经网络不可能做到这一点，因为国际象棋有超过 20 万个对手和你的走法模板。

我用 C++ 编写了一些代码。
#include ;
#include &lt;向量&gt;
#include &lt;字符串&gt;
#include &lt;功能&gt;

枚举类型激活{
    正弦，
    雷鲁，
    乙状结肠
};

类实用程序{
    模板&lt;类型名称 T&gt;
    bool static every(const std::vector&gt;&amp;mtx, const std::function cb) {
        for (const auto&amp; row : mtx) {
            for (const auto&amp; i : row) {
               if (cb(i) == 0) 返回 false；
            }
        }
        
       返回真；
    }
};

类代理{
民众：
    代理（）=默认；
 
私人的：
    浮重；
    类型激活激活；
    浮动平均值； // 消除？
};

类游戏{
民众：
    游戏（）=默认；
    〜游戏（）{}；
    
    bool walk(int x, int y, std::string 值) {
        if (x &gt;= 1 &amp;&amp; x &lt;= 3) {
            if (_mtx[x][y] == &quot; &quot;) {
                _mtx[x][y] = 值；
                返回真；
            }
        }
        
        返回假；
    }
    
    布尔 isEmpty() {
        auto = utils::every(_mtx, [](const std::string&amp; str) {
            返回 str == ” ”;
        });
        
        返回的是；
    }
    
私人的：
    std::vector&gt;&gt; _mtx = {
        {” ”、“ ”、“ ”},
        {” ”、“ ”、“ ”},
        {” ”、“ ”、“ ”}
    };
};

int main() {
    游戏游戏；
    代理代理；
    
    
    返回0；
}
]]></description>
      <guid>https://stackoverflow.com/questions/78255012/c-how-to-create-a-neural-network-with-game-training</guid>
      <pubDate>Mon, 01 Apr 2024 10:47:09 GMT</pubDate>
    </item>
    <item>
      <title>Adagrad/Rmsprop/Adam 关于变化方向的困惑</title>
      <link>https://stackoverflow.com/questions/78254992/confusion-about-adagrad-rmsprop-adam-about-the-direction-of-change</link>
      <description><![CDATA[你好，我现在正在学习优化器，
我可以理解动量部分（类似于物理世界），
但对不同参数的不同学习率感到困惑，
对于Adagrad/Rmsprop，如果∂L/∂w_1很大，则学习率
因为w_1很小，如果∂L/∂w_1很小，那么学习率
因为 w_1 很大。（我如何使用 Latex 编码？）
但从数学上讲，-梯度是最陡的方向
值减小，对于 Adagrad/Rmsprop，它本质上改变了这一点
方向变为其他方向，本质上改变了更新方向
更多偏导数较小（如果∂L/∂w_1很小）
这是为什么呢？我的解释是，由于 Adagrad/Rmsprop 本质上改变了更新方向
更倾向于那些偏导数较小的情况，比如 w_1（如果 ∂L/∂w_1 很小），
等于在 -gradient 方向迈出一步，然后在 w_1 方向迈出额外一步，因为 w_1 方向更平坦，因此在 w_1 方向迈出额外一步的风险较小？]]></description>
      <guid>https://stackoverflow.com/questions/78254992/confusion-about-adagrad-rmsprop-adam-about-the-direction-of-change</guid>
      <pubDate>Mon, 01 Apr 2024 10:43:46 GMT</pubDate>
    </item>
    <item>
      <title>如何修复错误：索引错误：标量变量的索引无效</title>
      <link>https://stackoverflow.com/questions/78254954/how-to-fix-error-index-error-invalid-index-to-scalar-variable</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78254954/how-to-fix-error-index-error-invalid-index-to-scalar-variable</guid>
      <pubDate>Mon, 01 Apr 2024 10:35:50 GMT</pubDate>
    </item>
    <item>
      <title>我只想在 python 中从该图像中提取图形部分，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</link>
      <description><![CDATA[我想将右侧的两个图一起提取，也不能单独提取，两者都可以提取为一个（https://i.stack.imgur.com/RqwkB.jpg)
我不知道该尝试什么，我对此很陌生。我正在使用 python，我从图像中提取文本并将其保存在 csv 中
&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np

# 加载图像
image_path = r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\1.jpg&#39;
图像 = cv2.imread(image_path)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊来减少噪音
模糊 = cv2.GaussianBlur(灰色, (5, 5), 0)

# 应用 Canny 边缘检测
边缘 = cv2.Canny(模糊, 50, 150)

# 在边缘检测图像中查找轮廓
轮廓，_ = cv2.findContours（边缘，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE）

# 根据面积过滤轮廓，找到最大的轮廓（假设图形是面积最大的）
轮廓=排序（轮廓，键= cv2.contourArea，反向= True）[：1]

# 创建一个掩码来提取图形区域
mask = np.zeros_like(灰色)
cv2.drawContours(蒙版, 轮廓, -1, (255, 255, 255), 厚度=cv2.FILLED)

# 将掩模应用于原始图像以提取图形
图= cv2.bitwise_and（图像，图像，掩码=掩码）

# 保存提取的图形图像
cv2.imwrite(r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\output\extracted_graph.jpg&#39;, graph)
]]></description>
      <guid>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</guid>
      <pubDate>Mon, 01 Apr 2024 08:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何将预训练的拥抱脸模型转换为.pt并在本地完全运行？</title>
      <link>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</link>
      <description><![CDATA[我正在尝试将此模型转换为.pt格式。它对我来说工作得很好，所以我不想对其进行微调。如何将其导出为.pt并运行界面？
我尝试使用它转换为 .pt：
从变压器导入 AutoConfig、AutoProcessor、AutoModelForCTC、AutoTokenizer、Wav2Vec2Processor
导入库
进口火炬



# 定义模型名称
model_name = “UrukHan/wav2vec2-俄罗斯”

# 加载模型和分词器
config = AutoConfig.from_pretrained(model_name)
模型 = AutoModelForCTC.from_pretrained(model_name, config=config)
处理器 = Wav2Vec2Processor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 将模型保存为.pt 文件
torch.save(model.state_dict(), &quot;model.pt&quot;)

# 如果需要的话也保存分词器
tokenizer.save_pretrained(“模型标记器”)

但不幸的是它没有运行界面：
model = AutoModelForCTC.from_pretrained(“model.pt”)
处理器 = AutoProcessor.from_pretrained(“model.pt”)


# 使用模型进行推理
FILE = &#39;这里是 wav.wav&#39;
音频，_ = librosa.load（文件，sr = 16000）
音频=列表（音频）
def map_to_result(batch):
  使用 torch.no_grad()：
    input_values = torch.tensor(batch, device=“cpu”).unsqueeze(0) #, device=“cuda”
    logits = 模型(input_values).logits
  pred_ids = torch.argmax(logits, dim=-1)
  批处理=处理器.batch_decode(pred_ids)[0]
  退货批次
映射到结果（音频）
打印（映射到结果（音频））


模型.eval()

并遇到错误：
`model.pt 不是本地文件夹，也不是“https://huggingface.co/models”上列出的有效模型标识符
`]]></description>
      <guid>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</guid>
      <pubDate>Sat, 23 Mar 2024 09:18:49 GMT</pubDate>
    </item>
    <item>
      <title>ALS 算法 Spark MLlib - 我如何获得自己的“个人推荐”（我未排名的电影的排名）</title>
      <link>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</link>
      <description><![CDATA[我在 Azure Databricks 中使用 PySpark。我使用 Sparks MLlib 库 ALS 算法来预测电影评级，效果很成功。但是，我正在尝试添加一个数据框，其中包含我对 10 部随机选择的电影的评分。当我这样做时，我只会获得我已经排名的电影的预测排名。 
我希望能够使用该模型根据排名获得推荐。
我有执行以下任务的 Spark 代码：

导入数据（RatingsSmall、MoviesSmall、RatingsLarge、Movies Large）
将小评分与小电影合并，将大评分与大电影合并
一起附加到两个新数据集
删除不相关的列时间戳和流派

我现在有一个干净的表，其中包含 MovieID、标题（电影名称）、UserID 和排名。我将从现在开始展示代码。如果您想要之前的代码，那么我也可以提交。

将数据拆分为训练集和测试集（0.80、0.20）
ALS算法
显示预测。

希望以上内容可以帮助您指导我所附的代码。
我只能获得对我已提交的排名的预测。
我尝试将我的排名加入到训练集中。从这里我想获得数据集中其他电影的推荐或预测。
我的尝试：
导入了一个带有我自己的排名的DF。
将此 (UnionAll) 附加到训练集中。
得到预测（但仅限于我已经排名的电影）
代码：
#分割数据集

    训练，测试 = All_Movies.randomSplit([0.8, 0.2])
    从 pyspark.ml.recommendation 导入 ALS

    从 pyspark.ml.evaluation 导入回归评估器

#设置模型

    ALS = ALS(maxIter=10, regParam=0.01, userCol = &quot;userId&quot;,itemCol=&quot;movieId&quot;, ratingCol=&quot;评级&quot;, ColdStartStrategy=&quot;drop&quot;)

#将模型适合训练集并附上个人建议


     model = ALS.fit(training.unionAll(PersonalDF)) #PersonalDF是我的排名

#获取测试集的预测
    预测 = model.transform(test).dropna()

#到这里为止一切都很好。

#尝试获取我的电影的预测排名
    mySampledMovies = model.transform(PersonalDF)
    mySampledMovies.registerTempTable(&quot;mySampledMovies&quot;)

    显示（sqlContext.sql（“从 mySampledMovies 中选择 userId、movieId、评分、标题、预测”））

我期望一个 DataFrame 能够显示我的用户 ID、电影 ID、排名、预测。对于我还没有看到的电影，排名为 N/A 或 Null，而预测具有价值。
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</guid>
      <pubDate>Fri, 08 Feb 2019 12:00:58 GMT</pubDate>
    </item>
    </channel>
</rss>