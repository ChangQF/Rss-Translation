<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 02 Mar 2025 06:24:10 GMT</lastBuildDate>
    <item>
      <title>DQN代理：损失减少，库尔。奖励停滞不前，Q值在所有动作中都非常相似，并且越来越高</title>
      <link>https://stackoverflow.com/questions/79477950/dqn-agent-loss-decreases-cumul-reward-stagnates-q-values-are-very-similar-ov</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79477950/dqn-agent-loss-decreases-cumul-reward-stagnates-q-values-are-very-similar-ov</guid>
      <pubDate>Sat, 01 Mar 2025 17:05:14 GMT</pubDate>
    </item>
    <item>
      <title>时间融合变压器：0.45R²（Yahoo）与负R²（Investing.com） - 帮助！ FX价格预测</title>
      <link>https://stackoverflow.com/questions/79477349/temporal-fusion-transformer-0-45-r%c2%b2-yahoo-vs-negative-r%c2%b2-investing-com-h</link>
      <description><![CDATA[我正在使用时间融合变压器（TFT）来预测每日FX价格变化。它在Yahoo Finance数据（R²= 0.45）上运行良好，但在Investing.com数据（负R²）上的失败不佳，尽管进行了相同的预处理。每日收益的分布截然不同。数据差异（例如不同的日常定义）是否会成为原因？]]></description>
      <guid>https://stackoverflow.com/questions/79477349/temporal-fusion-transformer-0-45-r%c2%b2-yahoo-vs-negative-r%c2%b2-investing-com-h</guid>
      <pubDate>Sat, 01 Mar 2025 09:21:32 GMT</pubDate>
    </item>
    <item>
      <title>减少类别数量的数量会改善Yolo的性能吗？</title>
      <link>https://stackoverflow.com/questions/79477144/does-reducing-the-number-of-categories-improve-yolo-performance</link>
      <description><![CDATA[假设我有一组包含两个类似类别的图像和一个与前两个不同的类别。想想猫，狗和网球。现在，我需要训练Yolo对象检测器以找到这些对象。我可以使用一些策略：

标记所有对象，在此标记的数据集上训练Yolo 
使用经典的计算机视觉方法检测圆形对象。然后只标记猫和狗，然后训练Yolo才能检测到猫和狗。在推理时，也这样做 - 经典的简历可以找到网球，然后Yolo找到猫和狗。

我是否通过方法2获得任何分类准确性？在第二种情况下训练的模型会使猫的狗不经常混淆吗？]]></description>
      <guid>https://stackoverflow.com/questions/79477144/does-reducing-the-number-of-categories-improve-yolo-performance</guid>
      <pubDate>Sat, 01 Mar 2025 05:32:23 GMT</pubDate>
    </item>
    <item>
      <title>在Python中实施降低多维特征的判别算法[封闭]</title>
      <link>https://stackoverflow.com/questions/79476477/implementing-the-discriminant-algorithm-for-reduced-multidimensional-features-in</link>
      <description><![CDATA[我需要实现判别算法，以减少论文 https://www.jstage.jstage.jst.go.jp/article/nolta/nolta/1/1/1/1_1_1_1_1_1_1_1_1_1_1_1_1_pdf/_pdf/-char/en 作为algorithm 2。我正在使用紧张，scipy和numpy来实现此algorithm。我尝试实现该算法，但无法收敛。另外，投影矩阵 psi （随后 f_matrix ）包含大型复杂值。
在
    “”
    用于降低多维特征的判别算法

    参数：
    G：numpy.ndarray
        核心功能张量J1 x J2 x ... x Jn x k

    我：numpy.ndarray
        核心张量G的目标标签（C类中的K特征）

    f：int
        我们想要的歧视性功能数量

    max_iter：int
        最大化痕量比时的最大迭代次数
    
    TOL：浮动
        收敛动态标准的公差


    返回值：
    psi：numpy.ndarray
        歧视投影矩阵，昏暗l x f

    f_matrix：numpy.ndarray
        歧视性特征的矩阵，昏暗的f x k

    注意：L = J1 * J2 * ... * JN
    “”
    k = g.形[-1] 
    n = g.ndim -1  
    klase = np.unique（i）

    g_mean = np.mean（g，axis = -1）

    g_c_mean = np.zeros（g.shape [：-1]+（len（klase），）））
    g_tilda = np .eros（g. shape）

    对于klase中的C：
        ind = np.Where（i == c）[0]
        g_c = g [...，ind]＃uzori iz klase c
        k_c = g_c.shape [-1]＃broj uzoraka u klasi c
        g_c_mean [...，c] = np.mean（g_c，axis = -1）＃prosjek za klasu c

        因为我在ind：
            g_tilda [...，i] = g [...，i] -g_c_mean [...，c] #centralizacija klase c c c
        g_c_mean [...，c] = np.sqrt（k_c）*（g_c_mean [...，c] -g_mean）

    s_w = tl.base.unfold（g_tilda，n）.t @ tl.base.unfold（g_tilda，n）
    s_b = tl.base.unfold（g_c_mean，n）.t @ tl.base.unfold（g_c_mean，n）

    delta，psi = eigs（s_b，k = f，m = s_w，=&#39;lm&#39;）

    br_iter = 0
    uvjet = 1

    而br_iter＆lt; max_iter和uvjet：
        psi_stari = psi
        br_iter+= 1
        
        fi = np.trace（psi.t @ s_b @ psi）/np.trace（psi.t @ s_w @ psi） 
        delta，psi = eigs（s_b-fi*s_w，k = f，=&#39;lm&#39;）
        delta，psi = eigs（psi@psi.t@s_w@psi@psi.t，k = f，wher =&#39;lm&#39;）
        uvjet =（np.linalg.norm（psi-psi_stari）＆gt; = tol）

    f_matrix = psi.t @ tl.unfold（g，n）.t
    返回psi，f_matrix

 
您能帮我找到错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/79476477/implementing-the-discriminant-algorithm-for-reduced-multidimensional-features-in</guid>
      <pubDate>Fri, 28 Feb 2025 19:09:15 GMT</pubDate>
    </item>
    <item>
      <title>KNN搜索在一个非常大的数据集上，该数据集带有Torchscript兼容库[封闭]</title>
      <link>https://stackoverflow.com/questions/79476351/knn-search-on-a-very-large-dataset-with-a-torchscript-compatible-library</link>
      <description><![CDATA[我正在尝试运行K-NN搜索非常大的数据集（1E5点）。  pykeops 在内存和时间方面工作正常，但不幸的是，它不是Torchscript兼容。还有其他方法吗，我可以进行此搜索并提高内存效率。主要要求是它应该兼容Torchscript。]]></description>
      <guid>https://stackoverflow.com/questions/79476351/knn-search-on-a-very-large-dataset-with-a-torchscript-compatible-library</guid>
      <pubDate>Fri, 28 Feb 2025 18:10:20 GMT</pubDate>
    </item>
    <item>
      <title>管道Future Warning：此管道实例尚未拟合</title>
      <link>https://stackoverflow.com/questions/79475986/pipeline-futurewarning-this-pipeline-instance-is-not-fitted-yet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79475986/pipeline-futurewarning-this-pipeline-instance-is-not-fitted-yet</guid>
      <pubDate>Fri, 28 Feb 2025 15:25:11 GMT</pubDate>
    </item>
    <item>
      <title>在COLAB中无法下载和解开拉链数据集（Human 36M，Penn Action，MPI-INF-3DHP）[关闭]</title>
      <link>https://stackoverflow.com/questions/79475960/unable-to-download-and-unzip-datasets-human3-6m-penn-action-mpi-inf-3dhp-in</link>
      <description><![CDATA[我一直在尝试下载和解压缩以下数据集：Google COLAB中的Human36M，Penn Action和MPI-INF-3DHP。但是，我一直遇到相同的错误，我怀疑这与URL有关。
这是我一直在使用的代码：
 ！wget https://datasets.d2.mpi-inf.mpg.de/mpi_inf_3dhp/mpi_inf_inf_3dhp.zip
！unzip mpi_inf_3dhp.zip
 
错误是：
错误404：找不到。
错误在下载过程中发生，我不确定如何进行。谁能提供有关如何解决此问题或建议直接在COLAB中下载这些数据集的替代方法的指导？]]></description>
      <guid>https://stackoverflow.com/questions/79475960/unable-to-download-and-unzip-datasets-human3-6m-penn-action-mpi-inf-3dhp-in</guid>
      <pubDate>Fri, 28 Feb 2025 15:10:29 GMT</pubDate>
    </item>
    <item>
      <title>我们如何平衡AI模型透明度和关键应用程序性能之间的权衡？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79474671/how-do-we-balance-the-trade-off-between-ai-model-transparency-and-performance-in</link>
      <description><![CDATA[近年来，我们目睹了深度学习模型的性能激增，尤其是在医疗保健，金融和自治系统等关键领域。但是，这种表现通常以可解释性和透明度为代价，尤其是在深层神经网络等复杂模型中。。
问题
在高风险环境中使用黑框模型的含义是什么？ ]]></description>
      <guid>https://stackoverflow.com/questions/79474671/how-do-we-balance-the-trade-off-between-ai-model-transparency-and-performance-in</guid>
      <pubDate>Fri, 28 Feb 2025 06:13:01 GMT</pubDate>
    </item>
    <item>
      <title>在梯度下降算法中，如何诱导-2*WX</title>
      <link>https://stackoverflow.com/questions/78171263/in-gradient-descent-algorithm-how-to-induce-2wx</link>
      <description><![CDATA[ 梯度下降算法的一部分  
  this.upDateWeights = function（）{
 
  令WX;
  令w_deriv = 0;
  令b_deriv = 0;

  for（让i = 0; i＆lt; this.points; i ++）{
    wx = this.yarr [i]  - （this.ueight * this.xarr [i] + this.bias）;
    w_deriv += -2 * wx * this.xarr [i];
    b_deriv += -2 * wx;
  }
  
  此。
  this.bias- =（b_deriv / this.points） * this.learnc;
}
            
 
请解释这部分！
  -2 * wx * this.xarr [i]
 
该部分是诱导的....？
如何通过数学公式诱导.... ]]></description>
      <guid>https://stackoverflow.com/questions/78171263/in-gradient-descent-algorithm-how-to-induce-2wx</guid>
      <pubDate>Sat, 16 Mar 2024 09:41:21 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络是完美的回归而不是分类</title>
      <link>https://stackoverflow.com/questions/73533170/my-neural-network-is-perfroming-regression-instead-of-classification</link>
      <description><![CDATA[我正在从事一个数据科学项目，该项目需要实施神经网络。我为培训提供的数据集不是顺序的，并且具有类标签。但是我不知道为什么它将其视为事件的顺序。
我正在为模型使用以下代码：
  model = keras。
    layers.dense（100，激活=&#39;relu&#39;），
    layers.dropout（0.4），
    layers.dense（100，激活=&#39;relu&#39;），
    layers.dropout（0.4），
    layers.dense（100，激活=&#39;relu&#39;），
    layers.dropout（0.4），
    layers.dense（100，激活=&#39;relu&#39;），
    layers.dense（6，激活=&#39;softmax&#39;）
）））
model.compile（
    优化器=“亚当”
    损失=;
    指标= [&#39;准确性&#39;]
）
model.fit（x_train，y_train，epochs = 100，batch_size = 2100）
y_pred = model.predict（x_test）
打印（efceracy_score（y_test，y_pred））
 
  efceracy_score 函数正在给出此错误
 分类指标无法处理多类和连续的multiOutput目标的混合
 
此错误消息显示算法何时执行回归。我该如何解决这个问题？
 编辑1  
迈克尔·霍德尔（Michael Hodel
  data [&#39;label&#39;] = ohc.fit_transform（data [[&#39;label&#39;]]）
 
它给我错误
 稀疏矩阵长度是模棱两可的；使用getnnz（）或形状[0]
 
 编辑2  
我使用 pd.get_dummies（）而不是&#39;onehotencoder` ]]></description>
      <guid>https://stackoverflow.com/questions/73533170/my-neural-network-is-perfroming-regression-instead-of-classification</guid>
      <pubDate>Mon, 29 Aug 2022 18:27:48 GMT</pubDate>
    </item>
    <item>
      <title>FastAPI：返回ML模型预测时内部服务器错误</title>
      <link>https://stackoverflow.com/questions/72754217/fastapi-internal-server-error-when-returning-ml-model-prediction</link>
      <description><![CDATA[我想在FastAPI中测试我的管道，但是我找不到代码中的错误。当我使用Visual Studio代码（使用 print（）语句）进行测试时，它可以工作。但是，当我尝试通过浏览器访问端点时，我会得到内部服务器错误。当我返回其他内容的结果（例如，某些字符串），而不是实际的预测结果时，它起作用。。
这是我的代码：
 类drauddetection333（basemodel）：
    “”
    输入功能验证ML模型
    “”
    USER_ID：int
    Insigup_day：int
    Insigup_month：int
    INBISP_YEAR：int
    购买_DAY：int
    public_month：int
    public_year：int
    public_value：float
    资料来源：Str
    浏览器：str
    性：str
    年龄：int

@api.post（“/precadionions_test”，tags = [&#39;dekistionTreeClalsifier&#39;]）
def precadiveions_test（欺诈：frauddetection333）：
    “”
    ：param：来自邮政请求的输入数据
    ：返回预测类型
    “”
    功能= [[
    fraud.user_id，
    draud.signup_day，
    fraud.signup_month，
    fraud.signup_year，
    欺诈。purchase_day，
    欺诈。purchase_month，
    欺诈。purchase_year，
    欺诈。purchase_value，
    欺诈。
    odraud.Browser，
    欺诈。
    欺诈
    ]]]]
    rf_model = joblib.load（&#39;./ rf_model.pkl&#39;）
    new =（pd.dataframe（功能，index = [&#39;0&#39;]，columns = [&#39;user_id&#39;，&#39;signup_day&#39;，         
&#39;signup_month&#39;，&#39;signup_year&#39;， 
        “ public_day&#39;，&#39;publice_month&#39;，&#39;puploy_year&#39;，&#39;puphoy_value&#39;，
        “源”，“浏览器”，“性”，“年龄”]）））））
    new_prediction = rf_model.predict（new）
    返回 {
        “预测交易（1-欺诈，0-不是欺诈）＆quot”：new_prediction
    }
 
如果我尝试以下（使用 print（）语句），它将打印出预期的结果：
  featuress = {
  ＆quot“ user_id＆quot”：22058，
  ＆quot&#39;signup_day＆quot＆quot; 24，
  ＆quot&#39;signup_month＆quot;：2，
  ＆quot&#39;signup_year＆quot;：2015，
  ＆quot“ puphoy_day＆quot”：18，
  ＆quot“ puphoy_month＆quot”：4，
  ＆quot&#39;puraper_year＆quot＆quot; 2015，
  ＆quot“ publy_value＆quot”：34，
  “来源”：“ seo”
  “浏览器”：“ Chrome＆quot”，“
  “性别”：“ m＆quot”
  ＆quot“年龄”：39
}
rf_model = joblib.load（&#39;./ rf_model.pkl&#39;）
new =（pd.dataframe（featuress，index = [&#39;0&#39;]，columns = [&#39;user_id&#39;，&#39;signup_day&#39;，     
 &#39;signup_month&#39;，&#39;signup_year&#39;， 
        “ public_day&#39;，&#39;publice_month&#39;，&#39;puploy_year&#39;，&#39;puphoy_value&#39;，
        “源”，“浏览器”，“性”，“年龄”]）））））
new_prediction = rf_model.predict（new）
打印（新）
打印（new_prediction）
 
如果我键入返回{＆quot&#39;预测交易（1-欺诈，0-不是欺诈）＆quot;：&#39;hi&#39;&#39;} ，它也有效。
图像在这里。]]></description>
      <guid>https://stackoverflow.com/questions/72754217/fastapi-internal-server-error-when-returning-ml-model-prediction</guid>
      <pubDate>Sat, 25 Jun 2022 13:24:32 GMT</pubDate>
    </item>
    <item>
      <title>使用keras征求有关脑电图分类的建议</title>
      <link>https://stackoverflow.com/questions/67236791/asking-advice-on-eeg-classification-using-keras</link>
      <description><![CDATA[我在脑电图上有一个数据集，具有这种形状：
 （11,1158，200）
 
其中
  11是EEG频道的数量
1158是每个任务的数量
200是每个任务的时间间隔
 
例如，如果绘制任务，您将获得（请注意数据已归一化）：
  此任务代表一个具有类的任务。 （例如，从2类看图片，数据集中的类总数为5）。
现在我将数组转换为此形状：
 （1158，200，11）
 
使模型可以区分每个任务。这是我使用的模型：
  opt = keras.optimizers.adam（Learning_rate = 1E-4）

型号=顺序（）
model.Add（conv1d（filters = 128，kernel_size = 64，activation =&#39;relu&#39;，input_shape =（200，11）））））
model.Add（conv1d（filters = 64，kernel_size = 8，activation =&#39;relu&#39;））
ADD（辍学（0.5））
ADD（maxpooling1d（pool_size = 2））
模型add（Flatten（））
ADD（密集（100，激活=&#39;relu&#39;））
ADD（密集（5，激活=&#39;SoftMax&#39;）））
model.compile（loss =&#39;accorical_crossentropy&#39;，imptimizer = opt，量级= [&#39;cercucy&#39;]）
model.fit（x_train，y_train，validation_data =（x_valid，y_valid），epochs = 50，batch_size = 16）
 
我尝试了许多不同的超参数，但我所有的结果都像这样：
 时期50/50
58/58 [===============================================
 
训练精度很高，但验证精度在20％至25％之间（100/5 = 20，其中5是班级数）；这基本上意味着该模型可以预测随机的事物。我的方法错了吗？如果是这样，我应该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/67236791/asking-advice-on-eeg-classification-using-keras</guid>
      <pubDate>Fri, 23 Apr 2021 21:01:51 GMT</pubDate>
    </item>
    <item>
      <title>将辍学层提高准确性</title>
      <link>https://stackoverflow.com/questions/60591577/will-dropout-layer-enhance-accuracy</link>
      <description><![CDATA[我知道，在CNN模型中添加辍学层会提高精度，因为它会降低过度拟合的影响。但是，我构建了一个CNN模型，使用16,32和64个过滤器，尺寸3和2为2的Maxpool，并注意到，没有辍学层的模型比所有情况下都有辍学层的模型更好。 
 来自keras.models导入顺序
来自keras.layers导入conv2d，激活，maxpooling2d，密集，扁平，辍学
导入numpy作为NP
来自keras.preprocessing.image导入imagedatagenerator
来自ipython.display导入显示
导入matplotlib.pyplot作为PLT
从PIL导入图像
来自sklearn.metrics导入classification_report，confusion_matrix
进口keras
来自keras.layers导入批次正规化
从keras.optimizer导入亚当
进口泡菜

分类器= sequention（）
classifier.add（conv2d（16，（3,3），input_shape =（200,200,3））））））
classifier.add（激活（&#39;relu&#39;））
classifier.add（maxpooling2d（pool_size =（2,2）））
classifier.add（flatten（））
classifier.Add（密集（128））
classifier.add（激活（&#39;relu&#39;））
classifier.add（辍学（0.5））
classifier.add（密集（7））
classifier.add（激活（&#39;softmax&#39;））
classifier.summary（）
classifier.compile（优化器= keras.optimizers.adam（lr = 0.001），
                   损失=&#39;apcorical_crossentropy&#39;，
                   指标= [&#39;准确性&#39;]）
train_datagen = imagedatagenerator（recage = 1./255，
                                   shear_range = 0.2，
                                   zoom_range = 0.2，
                                   Horizo​​ntal_flip = true）
test_datagen = imagedatagenerator（recage = 1./255）

batchsize = 10
triending_set = train_datagen.flow_from_directory（&#39;/home/osboxes/downloads/downloads/journal_paper/malware_families/spectrogram/train/&#39;，            
                                                target_size =（200,200），
                                                batch_size = batchsize，
                                                class_mode =&#39;分类&#39;）

test_set = test_datagen.flow_from_directory（&#39;/home/osboxes/downloads/downloads/journal_paper/malware_families/spectragram/validate/&#39;，    
                                           target_size =（200,200），
                                           batch_size = batchsize，
                       洗牌= false，
                                           class_mode =&#39;分类&#39;）
历史= clastifier.fit_generator（triending_set，
                        step_per_epoch = 2340 // batchsize，
                        时代= 100，
                        验证_data = test_set，
                        验证_steps = 781 //批处理）

classifier.save（&#39;16_with_dropout_rl_001.h5&#39;）
使用open（&#39;16_with_dropout_rl_001.h5&#39;，&#39;wb&#39;）作为file_pi：
        pickle.dump（history.thistory，file_pi）
y_pred = classifier.predict_generator（test_set，steps = 781 // batchsize+1）
y_pred = np.argmax（y_pred，axis = 1）
打印（“混淆矩阵”）
打印（Confusion_matrix（test_set.classes，y_pred））
打印（“分类报告”）
target_names = test_set.classes
class_labels = list（test_set.class_indices.keys（）） 
target_names = [&#39;coinhive&#39;，&#39;soptet&#39;，fareit&#39;，&#39;gafgyt&#39;，&#39;mirai&#39;，&#39;ramnit&#39;，&#39;razy&#39;]  
报告= classification_report（test_set.classes，y_pred，target_names = class_labels）
打印（报告） 

＃总结历史的准确性
plt.plot（历史学家[&#39;准确性&#39;]）
plt.plot（history.history [&#39;val_accuracy&#39;]）
plt.title（&#39;模型精度16带辍学的RL .001&#39;）
plt.ylabel（“准确性”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）
＃总结损失的历史
plt.plot（历史学家[&#39;损失&#39;]）
plt.plot（历史学家[&#39;val_loss&#39;]）
plt.title（&#39;带有RL .001的型号损失16）
plt.ylabel（“损失”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）
 
     &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stackoverflow.com/questions/60591577/will-dropout-layer-enhance-accuracy</guid>
      <pubDate>Sun, 08 Mar 2020 20:04:03 GMT</pubDate>
    </item>
    <item>
      <title>如何将边界框（X1，Y1，X2，Y2）转换为Yolo样式（X，Y，W，H）</title>
      <link>https://stackoverflow.com/questions/56115874/how-to-convert-bounding-box-x1-y1-x2-y2-to-yolo-style-x-y-w-h</link>
      <description><![CDATA[我正在训练Yolo模型，我的边界框以这种格式： -  
  x1，y1，x2，y2 =＆gt;例如（100、100、200、200）
 
我需要将其转换为yolo格式，以便是： -  
  x，y，w，h =＆gt; 0.436262 0.474010 0.383663 0.178218
 
我已经计算了中心点X，Y，高度H和重量W。
但是仍然需要一个客场将它们转换为提到的浮数。]]></description>
      <guid>https://stackoverflow.com/questions/56115874/how-to-convert-bounding-box-x1-y1-x2-y2-to-yolo-style-x-y-w-h</guid>
      <pubDate>Mon, 13 May 2019 15:52:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么在神经网络中需要体重和偏见？</title>
      <link>https://stackoverflow.com/questions/44497187/why-are-weights-and-biases-necessary-in-neural-networks</link>
      <description><![CDATA[关于神经网络，为什么我们需要权重和偏见？
对于权重，我有了这个直觉，我们正在尝试将某些常数乘以输入，以便我们可以达到 y 的价值，并且知道关系，kinda&#39;sike  y = mx + c 。如果可能的话，请帮助我进行直觉。]]></description>
      <guid>https://stackoverflow.com/questions/44497187/why-are-weights-and-biases-necessary-in-neural-networks</guid>
      <pubDate>Mon, 12 Jun 2017 10:27:35 GMT</pubDate>
    </item>
    </channel>
</rss>