<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 10 Mar 2025 15:22:31 GMT</lastBuildDate>
    <item>
      <title>损失的计算梯度W.R.T学习率Pytorch</title>
      <link>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</link>
      <description><![CDATA[我正在构建一个自定义优化器，该定制优化器从Dirichlet分布中采样学习率，其参数（Alpha）需要在每个反向流中进行更新。我已经想出了如何获得W.R.T.的损失对于这些alpha参数，实际上是∂η/∂α，其中是学习率。
但是，我需要“连接”由于缺乏更好的单词，这种具有损失的梯度有效地∂l/∂η，因此我可以“链”这些梯度在一起，形成表达：
∂l/∂η *ηη/∂α=∂l/∂α
然后，我可以使用此梯度来更新Alpha，因此可以改善分布的采样。问题是我无法弄清楚如何获得∂l/∂η。我尝试使用以下行：
  grad_learning_rate = torch.autograd.grad（损失，self.lear.learning_rate，grad_outputs = torch.tensor（1.0，device = lose.device），retain_graph = true，wasler_unused = true = true）[0] [0]
 
每次前进后损失传递到优化器中。但是返回以下错误消息：
 差异张量之一似乎在图中没有使用。如果这是所需的行为，则设置allow_unused = true。
 
我已经附加了模型：
 类MLP（nn.module）：
    def __init __（self，input_size，output_size，设备：torch.device = none）：
        超级（MLP，self）.__ init __（）
        self.fc1 = nn.linear（input_size，10，dtype = type = turch.float64）
        self.relu = nn.relu（）

        ＃在CPU或输入处理单元（XPU）上拟合模型。
        self.device =设备如果设备不是TORCH.DEVICE（&#39;CPU&#39;）
        self.to（self.device）

    def向前（self，x）：
        x = self.fc1（x）
        返回x
 
和优化器：
 类飞镖（优化器）：
&#39;&#39;&#39;
优化器必须在整个培训中都会损失。
&#39;&#39;&#39;
def __init __（self，params，beta =（0.9，0.999），
             alpha_init = 1.0，alpha_lr = 0.0001，eps = 1e-8，weight_decay = 0）： 
    defaults = dict（beta = beta，eps = eps，weight_decay = weight_decay）
    super（dart，self）.__ init __（参数，默认）
    self.alpha_scaler = alpha_init
    self.alpha_lr = alpha_lr
    self.learning_rate =无
    self.alpha_grads =无
    
def sample_lr_candidates（self，平均= 1e-3，std = 1e-4，num_samples =（10，1），min_lr = 1e-6，max_lr = 1e-1）：
    ＃从高斯分布中的样本
    lr_samples = torch.normal（平均=平均，std = std，size =（num_samples））
    
    ＃剪辑值以确保它们在min_lr和max_lr范围内
    lr_samples = torch.clamp（lr_samples，min = min_lr，max = max_lr）
    
    返回lr_samples.to（torch.float64）

DEF步骤（自我，损失）：
    对于self.param_groups中的组：＃只有一个组。
        对于组[&#39;params&#39;]中的p：
            如果没有P.Grad：
                继续

            DIM =（10，784）如果P.Shape == Torch.Size（[10，784]）ELSE（1，10）
            
            state = self.state [p]＃优化类为参数打开“历史记录”。
            输入= TORCH。

    
            如果len（state）== 0：＃初始化状态（如果尚未完成）。
                状态[&#39;step&#39;] = 0
                state [&#39;lr_candidates&#39;] = self.sample_lr_candidates（num_samples = p. shape）＃.to（&#39;xpu&#39;）
                state [&#39;alphand&#39;] = torch.ones_like（input，memory_format = torch.preserve_format） * self.alpha_scaler
            
            状态[&#39;step&#39;] += 1  
            
            ＃启用Autograd以进行Alpha更新
            state [&#39;alpha&#39;]。需要_grad_（true）
            
            ＃来自Dirichlet的示例（警告：可能不支持自动摩擦）
            samples = torch.distributions.dirichlet（state [&#39;alphand&#39;]）。rsample（）＃.to（&#39;xpu&#39;）＃可区分
            总计=状态[&#39;alpha
            grad_samples = torch._dirichlet_grad（样本，状态[&#39;alphas&#39;]，Total）＃del P（样本） / del alpha
            
            ＃计算学习率
            ＃print（samples.shape，state [&#39;lr_candidates&#39;]。形状）
            self.learning_rate =样本 *状态[&#39;lr_candidates&#39;]＃.to（&#39;xpu&#39;）
            self.learning_rate.retain_grad（）
            
            ＃计算梯度wrt alpha
            grad_learning_rate = torch.autograd.grad（损失，self.lear.learning_rate，grad_outputs = torch.tensor（1.0，device = lose.device），retain_graph = true）[0]
            
            ＃随着梯度下降的更新alpha
            state [&#39;alphas&#39;] = state [&#39;alphas&#39;]  -  self.alpha_lr * grad_samples * state [&#39;lr_candidates&#39;]＃需要del l/ del n n
            self.alpha_grads = state [&#39;alpha&#39;]

            ＃应用重量更新
            ＃print（self.learning_rate.shape，p.grad.shape）
            p.data.sub_（self.learning_rate.squeeze（） * p.grad）＃.to（&#39;xpu&#39;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</guid>
      <pubDate>Mon, 10 Mar 2025 15:11:02 GMT</pubDate>
    </item>
    <item>
      <title>离群值检测和去除[封闭]</title>
      <link>https://stackoverflow.com/questions/79498235/outlier-detection-and-removal</link>
      <description><![CDATA[ z得分和IQR是两种用于离群检测和删除的方法，当数据分布正常时，使用z得分，并且当数据偏斜时使用IQR。数值列的，我们不能使用图形方法检测正态分布，然后如何进行？]]></description>
      <guid>https://stackoverflow.com/questions/79498235/outlier-detection-and-removal</guid>
      <pubDate>Mon, 10 Mar 2025 14:02:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在虚幻引擎5中加入libtorch？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</guid>
      <pubDate>Sun, 09 Mar 2025 15:03:36 GMT</pubDate>
    </item>
    <item>
      <title>当用简化运行时，模态可以正常执行。但是，当输入图像时，它无法正常工作</title>
      <link>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</guid>
      <pubDate>Sun, 09 Mar 2025 07:49:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么投票表决为“努力”的投票表现有所不同？</title>
      <link>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</link>
      <description><![CDATA[我想从Sklearn和不同参数进行比较性能测试投票classifier。我使用了param网格，然后发现一些难以理解的东西。
我准备了三个分类器
  gnb = gaussiannb（）＃准确性0.795
lr = logisticRegress（）＃准确性0.7925
RFC = RandomforestClassifier（）＃准确性0.94

 
然后我做了两个VaitingClassifiers。两者都有有效的设置为“硬”。但是重量不同。该决定是由多数投票做出的，但其准确性是不同的，这是如何可能的？
  vc_hard_equals = fotingClassifier（estionators = [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （&#39;Randomforest＆quot＆quot; rfc）
    ]，， 
    投票=“硬＆quot” 
    权重=（1，1，1），＃等于权重
    ）
vc_hard_forest_priority = fotingClassifier（估算= [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （“ rancomforest”，rfc），]， 
    投票=“硬＆quot” 
    权重=（1，1，3），＃更大的随机孔（在这种情况下最好的型号）
    ）

vc_hard_equals.fit（x_train，y_train）
vc_hard_forest_priority.fit（x_train，y_train）

print（vc_hard_equals.score（x_test，y_test））＃0.832
print（vc_hard_forest_priority.score（x_test，y_test））＃0.915
 ]]></description>
      <guid>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</guid>
      <pubDate>Fri, 28 Feb 2025 02:14:28 GMT</pubDate>
    </item>
    <item>
      <title>在Palantir Foundry模型培训参数（平均，SD）中评估过程是否从“火车数据”到“测试数据”？</title>
      <link>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</link>
      <description><![CDATA[如果我正确理解了该过程，则在机器学习中缩放测试数据时，应使用从培训数据中学到的缩放参数（如平均值和标准偏差）来转换测试数据，而不是测试数据本身。。
所以正确的步骤是：

将数据分开：将数据集分为培训和测试集。
缩放训练数据：计算和应用缩放参数（例如平均值，标准偏差）到训练数据。
将相同的参数应用于测试数据

要实现上述步骤，我使用：

  fit_transform 缩放“培训数据”，
 转换携带“培训数据”参数到比例测试“测试数据” 

但是，当我评估“测试数据”时，我如何在Palantir铸造模型中实现这一目标，我看不到评估配置的选项。有谁知道Palantir是否在评估配置中构建功能？携带参数过程会自动发生吗？如果没有，我该怎么做才能实现？
  fit_transform 然后变换在Palantir Foundry模型培训中等效]]></description>
      <guid>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</guid>
      <pubDate>Wed, 26 Feb 2025 08:32:02 GMT</pubDate>
    </item>
    <item>
      <title>增加自我注意力后，CNN网络的非确定性行为</title>
      <link>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</link>
      <description><![CDATA[当我添加nlbloclos时，在我的网络（简单CNN）中添加了一个自发层时，网络的结果不再可重现，当我再次训练它时，结果是不同的。但是，当我删除网络中的nlblocks时，它是确定性的。
这是代码：
  os.environ [＆quot&#39;cuda_visible_devices;
os.environ [&#39;tf_cpp_min_log_level&#39;] =&#39;3&#39;
种子= 42
os.environ [&#39;tf_deterministic_ops&#39;] =&#39;1&#39;
tf.config.experiment.enable_op_determinism（）

os.environ [&#39;pythonhashseed&#39;] = str（seed）
os.environ [&#39;tf_cudnn_deterministic&#39;] =&#39;1&#39; 

随机种子（种子）
np.random.seed（种子）
tf.random.set_seed（种子）

tf.keras.backend.set_floatx（&#39;float64&#39;）



nlblock类（层）：
    def __init __（self，num_channels，** kwargs）：
        super（nlblock，self）.__ init __（** kwargs）
        self.num_channels = num_channels
        self.theta = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.phi = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.g = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =; same＆quort;）
        self.attention_layer =注意（）＃keras注意层

    def呼叫（self，输入）：
        ＃变换功能图
        query = self.theta（输入）＃query（q）
        key = self.phi（输入）＃key（k）
        value = self.g（输入）＃value（v）

        ＃应用注意力层
        activation_output = self.attention_layer（[查询，键，值]）

        ＃残差连接
        返回输入 +注意_Output
        
＃定义NL注意的模型
def build_model（）：
    优化器= ADAM（Learning_rate = 0.002，beta_1 = 0.89，beta_2 = 0.995）

    输入= tf.keras.input（shape =（num_time_steps，1））＃输入层
    
    ＃Conv Block 1
    x = conv1d（filters = 64，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（输入）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 64）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）

    ＃Conv 2 2
    x = conv1d（filters = 32，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 32）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.1）（x）

    ＃Conv Block 3
    x = conv1d（filters = 16，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 16）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.35）（x）

    ＃完全连接的图层
    x = flatten（）（x）
    x =密集（40，激活=&#39;relu&#39;）（x）
    x =辍学（0.35）（x）
    输出=致密（20）（x）＃回归的输出层
    
    ＃编译模型
    型号= tf.keras.model（输入，输出）
    model.compile（优化器=优化器，lose = root_mean_squared_error，metrics = [&#39;mean_absolute_error&#39;]）
    
    返回模型

model = build_model（）

redy_lr = reducelronplateau（monitor =&#39;val_loss&#39;，因子= 0.6，耐心= 25，min_lr = 1e-6）
早期_Stopping =早期踩踏（Monitor =&#39;Val_loss&#39;，Patience = 30，Restore_best_weights = true）
＃步骤5：训练模型
历史= model.fit（x_train_scaled，y_train，validation_data =（x_val_scaled，y_val），
                epochs = 180，batch_size = 90，callbacks = [redion_lr，ropand_stopping]，冗长= 0）

test_loss，test_mae = model.evaluate（x_test_scaled，y_test，batch_size = len（x_test_scaled），词= 0）
 
我还使用tf.matmul（）和softmax使用自定义注意块，但没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</guid>
      <pubDate>Fri, 14 Feb 2025 15:08:45 GMT</pubDate>
    </item>
    <item>
      <title>无法使用NLTK功能</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>哪种评估指标适合与数据集不平衡的分类问题？</title>
      <link>https://stackoverflow.com/questions/76072393/which-evaluation-metric-will-be-suitable-for-a-classification-problem-with-an-im</link>
      <description><![CDATA[我的X类带有1000个观测值和Y类，具有2000个观测值。我正在尝试确定这里最合适的分类评估指标以及原因。

精确召回曲线。
 AUC ROC 
简单的精度度量
混淆矩阵和分类报告。

我很想坚持选项4，因为它不是一个不平衡的IMO，我们不需要使用精确的回忆曲线。这里有什么合适的？]]></description>
      <guid>https://stackoverflow.com/questions/76072393/which-evaluation-metric-will-be-suitable-for-a-classification-problem-with-an-im</guid>
      <pubDate>Fri, 21 Apr 2023 10:45:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在XGBoost中的提升回合之间显示错误输出？</title>
      <link>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</link>
      <description><![CDATA[我正在使用Scikit-Learn API， XGBRegressor 。我正在尝试使我的模型尽可能详细。这些是模型的参数。这是在Kaggle内核上运行的。  df_train 和 df_target 是pandas dataframes。
  model = XGB.XGBRegressor（
    n_estimators = 2 ** 8，
    max_depth = 5，
    Learning_rate = 0.04，
    子样本= 0.9，
    colsample_bytree = 0.9，    
    objective =&#39;reg：squarederror&#39;，
    booster =&#39;gbtree&#39;，
    eximplease_type =&#39;strige&#39;，
    tree_method =&#39;gpu_hist&#39;，
    静音= false，    
    Random_State =种子
）
 
这是 fit（）的参数。我必须看到像LightGBM这样的提升回合之间的训练RMSE。 XGBoost具有该功能吗？
  model.fit（df_train，df_target，eval_metric =&#39;rmse&#39;，eval_set = [（df_train，df_target）]，verbose = true）
 ]]></description>
      <guid>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</guid>
      <pubDate>Thu, 17 Oct 2019 09:52:56 GMT</pubDate>
    </item>
    <item>
      <title>完美的精确度，召回和F1得分，但预测不好</title>
      <link>https://stackoverflow.com/questions/53278489/perfect-precision-recall-and-f1-score-yet-bad-prediction</link>
      <description><![CDATA[使用Scikit-Learn对二进制问题进行分类。获得完美的 classification_report （全1）。但是预测给出 0.36 。怎么可能？
我熟悉不平衡标签。但是，我认为这里并非如此，因为 f1 和其他得分列以及混乱矩阵表示完美的分数。
 ＃列出最后19个行进行预测。
x1，x_pred，y1，y_pred = train_test_split（x，y，test_size = 19， 
                shuffle = false，Random_state =无）

x_train，x_test，y_train，y_test = train_test_split（x1，y1， 
         test_size = 0.4，strate = y1，Random_state = 11）

clcv = deciestReeClaleCifier（）
scorecv = cross_val_score（clcv，x1，y1，cv = stratifiedkfold（n_splits = 4）， 
                         评分=&#39;f1&#39;）＃平衡精度/召回
clcv.fit（x1，y1）
y_predict = clcv.predict（x1）
cm = Confusion_matrix（y1，y_predict）
cm_df = pd.dataframe（cm，index = [&#39;0&#39;，&#39;1&#39;]，列= [&#39;0&#39;，&#39;1&#39;]）
打印（cm_df）
打印（classification_report（y1，y__predict））
打印（&#39;预测分数：&#39;，clcv.score（x_pred，y_pred））＃看不见的数据
 
输出：
 混乱：
      0 1
0 3011 0
1 0 44

              精确召回F1得分支持
       错误1.00 1.00 1.00 3011
        正确1.00 1.00 1.00 44

   Micro AVG 1.00 1.00 1.00 3055
   宏平均1.00 1.00 1.00 3055
加权公平1.00 1.00 1.00 3055

预测分数：0.36
 ]]></description>
      <guid>https://stackoverflow.com/questions/53278489/perfect-precision-recall-and-f1-score-yet-bad-prediction</guid>
      <pubDate>Tue, 13 Nov 2018 10:05:57 GMT</pubDate>
    </item>
    <item>
      <title>无法获得我的线性回归的准确分数</title>
      <link>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</link>
      <description><![CDATA[我正在基于IMDB数据进行回归模型，以预测IMDB值。在线性回归上，我无法获得准确的得分。
我的代码行：
 量表
 
错误：
  valueerror：不支持连续
 
如果我要更改该线以获得R2分数，
  Metrics.R2_Score（test_y，linear_predicated_rating）
 
我能够获得R2而没有任何错误。
我为什么看到这个？
注意： test_y 是pandas dataframe]]></description>
      <guid>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</guid>
      <pubDate>Fri, 11 Aug 2017 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn.decomposition.pca的特征向量的简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我正在尝试了解主组件分析的工作方式，并且我正在 sklearn.datasets.load_iris  dataset上对其进行测试。  我了解每个步骤的工作原理（例如，使用 k 选定的尺寸，将数据，协方差，特征分类，对最高特征值进行排序，将原始数据转换为新轴）。）。
下一步是可视化这些 eigenVectors 在数据集中投射到（在 pc1 vs. pc2 vs. pc2 plot 上，对吗？）。。
如何在还原尺寸数据集的3D图上绘制[PC1，PC2，PC3]特征向量？
另外，我是否正确绘制了此2D版本？我不确定为什么我的第一个特征向量的长度较短。  我应该乘以特征值吗？

 这是我为实现这一目标所做的一些研究： 
我关注的PCA方法来自：
 https://plot.ly/ipython-notebooks/principal-component-analysis/#shortcut--pca-in-scikit-learn （尽管我不想使用 Plotly 我想坚持使用。
我一直在关注本教程，以绘制特征向量，这似乎很简单： pca for matplotlib 基本示例
我找到了这个，但是我试图做的事情似乎过于复杂，我不想创建一个 fancyarrowpatch ： 的协方差矩阵

 我试图使我的代码尽可能直接地遵循其他教程： 
 导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT
来自sklearn.datasets import load_iris
从sklearn.prepercorsing进口标准标准
来自Sklearn进口分解
进口海洋为SNS； sns.set_style（&#39;whitegrid＆quort; {&#39;axes.grid&#39;：false}）

％matplotlib内联
np.random.seed（0）

＃虹膜数据集
df_data = pd.dataframe（load_iris（）。数据， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]，
                       列= load_iris（）。feature_names）

se_targets = pd.Series（load_iris（）。目标， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]， 
                       名称=“物种”

＃缩放平均= 0，var = 1
df_standard = pd.dataframe（standardscaler（）。fit_transform（df_data）， 
                           index = df_data.index，
                           列= df_data.columns）

＃用于主要组合分析的Sklearn

＃昏暗
m = df_standard.shape [1]
k = 2

＃PCA（我倾向于设置它）
m_pca = demomposition.pca（n_components = m）
df_pca = pd.dataframe（m_pca.fit_transform（df_standard）， 
                列= [＆quot; pc％d＆quot;范围内K的％k（1，m + 1）]）。iloc [：，：k]


＃绘制特征向量
#https：//stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

＃这是东西很奇怪的地方...
data = df_standard

mu = data.mean（轴= 0）
eigenVector，eigenvalues = m_pca.components_，m_pca.explained_variance_ #eigenVectors，eigenvalues，v = np.linalg.svd（data.t，fult_matrices = false）
Projected_data = df_pca＃np.dot（数据，特征向量）

sigma = Projected_data.std（axis = 0）.mean（）

图，ax = plt.subplots（figsize =（10,10））
ax.Scatter（Projected_data [＆quot; pc1;]，Projected_data [＆quot; pc2＆quot;]）
对于轴，zip中的颜色（eigenVectors [：k]，[red&#39;&#39;
＃开始，end = mu，mu + sigma *轴###导致“ valueerror：太多值无法打开（预期2）”

    ＃所以我尝试过，但我认为这是不对的
    start，end =（mu）[：k]，（Mu + Sigma * Axis）[：K] 
    ax.annotate（&#39;&#39;，xy = end，xytext = start，arrowprops = dict（faceColor = color，width = 1.0））
    
ax.set_aspect（&#39;quare&#39;）
plt.show（）
 
  &lt;img alt =“在此处输入图像描述” src =“ https://i.sstatic.net.net/t9st0.png”]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn Lasso回归是否比山脊回归差？</title>
      <link>https://stackoverflow.com/questions/35714772/sklearn-lasso-regression-is-orders-of-magnitude-worse-than-ridge-regression</link>
      <description><![CDATA[我目前使用 sklearn.linear_model 模块实现了脊和拉索回归。
然而，套索回归似乎在同一数据集上差3个数量级！
我不确定怎么了，因为从数学上讲，这不应该发生。这是我的代码：
  def ridge_regression（x_train，y_train，x_test，y_test，model_alpha）：
    clf = linear_model.ridge（model_alpha）
    clf.fit（x_train，y_train）
    预测= clf.predict（x_test）
    损失= np.sum（（预测-y_test）** 2）
    回报损失

def lasso_regression（x_train，y_train，x_test，y_test，model_alpha）：
    clf = linear_model.lasso（model_alpha）
    clf.fit（x_train，y_train）
    预测= clf.predict（x_test）
    损失= np.sum（（预测-y_test）** 2）
    回报损失


x_train，x_test，y_train，y_test = cross_validation.train_test_split（x，x，y，test_size = 0.1，randy_state = 0）
对于alpha，在[0，0.01，0.1，0.5，1，2，5，10，100，1000，10000]中：
    打印（alpha =&#39; + str（alpha） +;
    
对于[1、1.25、1.5、1.75、5、5、10、100、1000、10000、100000、1000000]中的alpha。
    打印（alpha =&#39; + str（alpha） +;
 
这是我的输出：
  alpha = 0：20575.7121727的拉索损失
alpha的套索损失= 0.01：19762.8763969
alpha的套索损失= 0.1：17656.9926418
alpha的拉索损失= 0.5：15699.2014387
alpha的拉索损失= 1：15619.9772649
alpha的拉索损失= 2：15490.0433166
alpha的拉索损失= 5：15328.4303197
alpha的拉索损失= 10：15328.4303197
alpha的拉索损失= 100：15328.4303197
alpha的套索损失= 1000：15328.4303197
alpha的拉索损失= 10000：15328.4303197
Alpha的脊损失= 1：61.6235890425
alpha = 1.25：61.6360790934
alpha的脊损失= 1.5：61.6496312133
alpha = 1.75：61.6636076713
alpha的脊损失= 2：61.6776331539
alpha的脊损失= 5：61.8206621527
Alpha的脊损失= 10：61.9883144732
alpha的脊损失= 100：63.9106882674
alpha = 1000：69.3266510866
alpha = 10000：82.0056669678
alpha的脊损失= 100000：88.4479064159
alpha = 1000000：91.7235727543
 
任何想法为什么？]]></description>
      <guid>https://stackoverflow.com/questions/35714772/sklearn-lasso-regression-is-orders-of-magnitude-worse-than-ridge-regression</guid>
      <pubDate>Tue, 01 Mar 2016 04:36:23 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：稀疏基质长度模棱两可；使用RF分类器时使用getnnz（）或Shape [0]？</title>
      <link>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</link>
      <description><![CDATA[我正在学习Scikit学习中的随机森林，例如，我想使用自己的数据集使用随机森林分类器进行文本分类。因此，首先，我用TFIDF对文本进行了介绍，以进行分类：
 来自sklearn.semble import incort fandyForestClassifier
classifier = RandomforestClassifier（n_estimators = 10） 
classifier.fit（x_train，y_train）           
预测= classifier.predict（x_test）
 
当我运行分类时，我得到了：
  typeError：传递了一个稀疏矩阵，但是需要密集的数据。使用X.ToArray（）转换为密集的numpy阵列。
 
然后，我使用 .toArray（）  x_train ，我得到了以下内容：
  typeError：稀疏矩阵长度是模棱两可的；使用getnnz（）或形状[0]
 
来自以前的问题当我了解我需要减少数量阵列的尺寸性时，我需要相同的尺寸：
 来自sklearn.decomposition.truncated_svd import truncatedSvd        
pca = truncatedSvd（n_components = 300）                                
X_REDUDS_TRAIN = PCA.FIT_TRANSFORM（X_TRAIN）               

从sklearn.semblection incort intim                 
classifier = RandomforestClassifier（n_estimators = 10）                  
classifier.fit（x_reduced_train，y_train）                            
预测= clastifier.predict（x_testing） 
 
然后我得到了这个例外：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
  文件“/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py”，第192行，in __len __
    提高类型（“稀疏矩阵长度是模棱两可的；使用getnnz（）”
TypeError：稀疏基质长度模棱两可；使用getnnz（）或形状[0]
 
我尝试了以下内容：
 预测= classifier.predict（x_train.getnnz（）） 
 
并得到了：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
TypeError：&#39;int&#39;类型的对象没有len（）
 
从中提出了两个问题：如何使用随机森林正确分类？  x_train ？ 
然后我尝试了以下内容：
  df = pd.read_csv（&#39;/path/file.csv&#39;，
header = 0，sep =&#39;，&#39;，names = [&#39;id&#39;，&#39;text&#39;，&#39;label&#39;]）



x = tfidf_vect.fit_transform（df [&#39;text&#39;]。值）
y = df [&#39;label&#39;]。值



来自sklearn.decomposition.truncated_svd导入truncatedSVD
pca = truncatedSvd（n_components = 2）
x = pca.fit_transform（x）

a_train，a_test，b_train，b_test = train_test_split（x，y，test_size = 0.33，andural_state = 42）

从sklearn.semblection incort intim

classifier = RandomforestClassifier（n_estimators = 10）
classifier.fit（a_train，b_train）
预测= classifier.predict（a_test）

来自sklearn.metrics.metrics导入precision_score，recker_score，confusion_matrix，classification_report
打印&#39;\ nscore：&#39;，classifier.score（a_train，b_test）
打印&#39;\ nprecision：&#39;，precision_score（b_test，预测）
打印&#39;\ nRecall：&#39;，recker_score（b_test，预测）
打印&#39;\ n confussion矩阵：\ n&#39;，confusion_matrix（b_test，预测）
打印&#39;\ n clasification报告：\ n&#39;，classification_report（b_test，预测）
 ]]></description>
      <guid>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</guid>
      <pubDate>Wed, 04 Feb 2015 05:48:35 GMT</pubDate>
    </item>
    </channel>
</rss>