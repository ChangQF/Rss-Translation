<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 10 Dec 2023 12:23:34 GMT</lastBuildDate>
    <item>
      <title>请提供使用 ml 的表情符号翻译器的源代码 [关闭]</title>
      <link>https://stackoverflow.com/questions/77634626/please-provide-a-source-code-for-emoji-translator-using-ml</link>
      <description><![CDATA[使用机器学习的表情符号翻译器应用程序代码
我搜索过，但没有找到任何好东西
我想创建一个用于表情符号转文本和文本转表情符号的应用程序
请向我提供包含最多表情符号的源代码]]></description>
      <guid>https://stackoverflow.com/questions/77634626/please-provide-a-source-code-for-emoji-translator-using-ml</guid>
      <pubDate>Sun, 10 Dec 2023 11:36:21 GMT</pubDate>
    </item>
    <item>
      <title>可转移的定向 FGSM 攻击尝试产生非常差的准确度性能</title>
      <link>https://stackoverflow.com/questions/77634593/transferable-targeted-fgsm-attack-attempt-yielding-very-poor-accuracy-performanc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77634593/transferable-targeted-fgsm-attack-attempt-yielding-very-poor-accuracy-performanc</guid>
      <pubDate>Sun, 10 Dec 2023 11:25:53 GMT</pubDate>
    </item>
    <item>
      <title>想要使用监督或无监督构建建议模型吗？</title>
      <link>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</link>
      <description><![CDATA[假设我们从一个巨大的区域开始，想要建立一个模型来建议是否建议在 latlon 的每个点放置多少新信号发射器。
第一步：在边界区域（100m 网格）内创建所有可能的 latlon
第二步：创建所有相关功能，例如
-最近的现有发射器距离
- 该点的当前信号电平（在此示例 latlon 中）
- 使用最接近该点的现有发射器的使用量（在此示例 latlon 中）
-当前点使用信号的用户数量
问题
1.如果我选择NNet模型，我需要提出评分函数来计算每个特征向量的合适分数。因为它是有监督模型，所以需要用该模型进行训练，如何找到合适的评分函数？当我找到分数函数时，我是否需要考虑特定特征的异常值？
2.如果我可以有标记数据，ML模型的好处是什么，因为我可以使用这个评分函数与自动化的传统软件来生成点列表的排名。
3.如果我使用无监督方法，它会根据特征仅对相似的特征点进行分组，但是如何对这个点进行排序，不知何故，我需要教育模型每个特征，较高的值意味着好，或者较高的值意味着不好吧？
4.有什么推荐或者更好的型号选择吗？
我试图概述脚趾步骤，但我有疑问，因为该方法听起来并不优于传统的自动化软件。]]></description>
      <guid>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</guid>
      <pubDate>Sun, 10 Dec 2023 07:29:16 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从 Transformer 导入 Trainer 时，DLL 失败</title>
      <link>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</link>
      <description><![CDATA[我想在本地计算机上微调基于 Transformer 的模型，因此当我尝试导入训练器时
从 Transformers 导入 Trainer

出现此错误
导入错误：导入 lib 时 DLL 加载失败：找不到指定的过程。
运行时错误：由于以下错误，无法导入transformers.trainer（查找其回溯）：
导入 lib 时 DLL 加载失败：找不到指定的过程。
如何解决此错误？
环境
蟒蛇
库达12.3
Python 3.9.18
火炬2.1.0+cu118
火炬音频2.1.0+cu118
火炬视觉 0.16.0+cu118
变形金刚 4.35.2

我尝试升级CUDA，升级和降级transformers库，torch及其子库，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</guid>
      <pubDate>Sun, 10 Dec 2023 05:33:49 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio 在 yolo7v 上训练时找不到 cuda 错误</title>
      <link>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</link>
      <description><![CDATA[当我尝试在 yolo v7 上训练时，出现此错误：
文件“train.py”，第 595 行，在  中
    设备= select_device(opt.device,batch_size=opt.batch_size)
  文件“C:\Users\96Crori\Desktop\yolov7_custom_training\yolov7\utils\torch_utils.py”，第 71 行，位于 select_device
    断言 torch.cuda.is_available(), f&#39;CUDA 不可用，请求的设备 {device} 无效&#39; # 检查可用性
AssertionError：CUDA 不可用，请求的设备 0 无效

我安装了cuda版本11.3，但我不知道为什么Visual Studios找不到它]]></description>
      <guid>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</guid>
      <pubDate>Sun, 10 Dec 2023 02:39:08 GMT</pubDate>
    </item>
    <item>
      <title>一个简单的玩具机器学习问题，令人惊讶的是它无法学到任何东西</title>
      <link>https://stackoverflow.com/questions/77633472/a-simple-toy-ml-problem-that-surprisingly-fails-to-learn-anything</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77633472/a-simple-toy-ml-problem-that-surprisingly-fails-to-learn-anything</guid>
      <pubDate>Sun, 10 Dec 2023 02:00:35 GMT</pubDate>
    </item>
    <item>
      <title>我需要制作一个机器学习模型，根据公司电子邮件使用数据评估员工流失率 [关闭]</title>
      <link>https://stackoverflow.com/questions/77632626/i-need-to-make-an-ml-model-that-evaluates-employee-attrition-rate-based-on-his-c</link>
      <description><![CDATA[此模型输入是每个员工的电子邮件使用情况的元数据，例如发出的电子邮件数量、收到的电子邮件数量等以及每封电子邮件的内容。输出是每个员工的自然流失率。该评估基于比较不同时期之间的电子邮件使用数据。
主要问题是没有附加数据集来解决这个问题。您建议采用什么方法来生成数据集？我应该为此模型选择哪种算法？]]></description>
      <guid>https://stackoverflow.com/questions/77632626/i-need-to-make-an-ml-model-that-evaluates-employee-attrition-rate-based-on-his-c</guid>
      <pubDate>Sat, 09 Dec 2023 19:38:25 GMT</pubDate>
    </item>
    <item>
      <title>在张量流中的卷中执行串联时出现问题</title>
      <link>https://stackoverflow.com/questions/77632484/issue-performing-concatenation-in-a-volume-in-tensorflow</link>
      <description><![CDATA[我正在构建一个肿瘤分割深度学习模型，即将使用3D Unet，但我提出了这个问题，这是我的代码：
# 卷积块
def conv_block(输入, num_filters):
    x = Conv3D(num_filters, (3, 3, 3), padding = “相同”)(输入)
    x = BatchNormalization()(x)
    x = 激活(“relu”)(x)

    x = Conv3D(num_filters, (3, 3, 3), 填充 = “相同”)(x)
    x = BatchNormalization()(x)
    x = 激活(“relu”)(x)

    返回x

# 编码器块
def编码器_块（输入，num_filters）：
    x = conv_block(输入, num_filters)
    p = MaxPool3D((2, 2, 2))(x)
    返回 x, p

# 解码器块
def解码器_块（输入，跳过，num_filters）：
    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=“相同”)(输入)
    x = 连接()([x, 跳过])
    x = conv_block(x, num_filters)
    返回x

# 大学网络

def unet(输入形状):
    输入 = 输入（输入形状）

    “----编码器----”
    s1, p1 = 编码器_块(输入, 64)
    s2, p2 = 编码器_块(p1, 128)
    s3, p3 = 编码器_块(p2, 256)
    s4, p4 = 编码器_块(p3, 512)

    “----桥---”
    b1 = conv_block(p4, 1024)

    “----解码器----”
    d1 = 解码器_块(b1, s4, 512)
    d2 = 解码器_块(d1, s3, 256)
    d3 = 解码器块(d2, s2, 128)
    d4 = 解码器块(d3, s1, 64)

    输出 = Conv3D(1, 1, 填充 =“相同”, 激活 =“sigmoid”)(d4)

    模型=模型（输入，输出，名称=“UNET”）
    返回模型

输入形状 = (155, 255, 255, 3)

测试模型=unet(输入形状)

问题是这样的：
&lt;前&gt;&lt;代码&gt;在&lt;细胞系：3&gt;()
      1 输入形状 = (155, 255, 255, 3)
      2
----&gt; 3 测试模型=unet(输入形状)

3帧
&lt;ipython-input-14-03345eb7b1a8&gt;在unet（输入形状）中
     14
     15、“----解码器----”
---&gt; 16 d1 = 解码器_块(b1, s4, 512)
     17 d2 = 解码器_块（d1，s3，256）
     18 d3 = 解码器_块(d2, s2, 128)

&lt;ipython-input-12-44442d65f832&gt;在解码器块（输入，跳过，num_filters）
      2 def解码器_块（输入，跳过，num_filters）：
      3 x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=“相同”)(输入)
----&gt; 4 x = 连接()([x, 跳过])
      5 x = conv_block(x, num_filters)
      6 返回 x

error_handler 中的 /usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py(*args, **kwargs)
     68 # 要获取完整的堆栈跟踪，请调用：
     69 # `tf.debugging.disable_traceback_filtering()`
---&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
     71 最后：
     72 删除filtered_tb

/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/concatenate.py 在 build(self, input_shape)
    129）
    [130] 第 130 章1：
--&gt; 131 引发值错误（err_msg）
    132
    133 def _merge_function（自我，输入）：

ValueError：“连接”层需要具有匹配形状（连接轴除外）的输入。收到：input_shape=[(无、18、30、30、512)、(无、19、31、31、512)]

我不知道为什么输出层对一个体素求和，这会产生错误，我不想消除该体素，因为它可能是有价值的信息]]></description>
      <guid>https://stackoverflow.com/questions/77632484/issue-performing-concatenation-in-a-volume-in-tensorflow</guid>
      <pubDate>Sat, 09 Dec 2023 18:48:43 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：期望有一个 cuda 设备，但得到：cpu</title>
      <link>https://stackoverflow.com/questions/77632426/valueerror-expected-a-cuda-device-but-got-cpu</link>
      <description><![CDATA[我正在尝试使用 DPO 执行强化学习，但是当我尝试执行 dpo_trainer.train() 时，即使我检查过，我仍然收到此错误
dpo_trainer.args.device

它返回
设备（类型=&#39;cuda&#39;，索引=0）

我看到很少的解决方案，例如将模型移动到 cuda 或设置
&#39;os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;0&#39;&#39;
但没有任何帮助，我无法找到问题所在。以下是我正在使用的训练参数
from Transformers import TrainingArguments
训练参数 = 训练参数（
    per_device_train_batch_size=1,
    per_device_eval_batch_size=1,
    最大步数=100，
    记录步骤=10，
    保存步骤=50，
    梯度累积步数=8，
    梯度检查点=真，
    学习率=2e-4,
    评价_策略=“步骤”，
    评估步骤=50，
    输出目录=&#39;./RL&#39;,
    lr_scheduler_type =“常量”，
    热身步数=0.03，
    optim=&quot;paged_adamw_32bit&quot;,
    fp16=正确，
    删除_未使用的列=假，
    run_name=“dpo_mistral7B”，
）
从 trl 导入 DPOTrainer

dpo_trainer = DPOTrainer(
        模型，
        模型参考，
        参数=训练参数，
        贝塔=0.1，
        train_dataset=数据集，
        分词器=分词器，
        pft_config=peft_config,
        最大提示长度=512，
        最大长度=1024，
        # 生成器=torch.Generator(device=&#39;cuda&#39;),

    ）
]]></description>
      <guid>https://stackoverflow.com/questions/77632426/valueerror-expected-a-cuda-device-but-got-cpu</guid>
      <pubDate>Sat, 09 Dec 2023 18:30:37 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 的自定义优化器</title>
      <link>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</link>
      <description><![CDATA[我正在尝试在 TensorFlow 上试验神经网络的自定义优化算法，但由于缺乏有关该主题的信息而陷入困境。我需要的是一些代码，这些代码将在每次迭代时为我提供向量 x （当前点）和向量 g （x 处的梯度），然后我将更新 x，然后使用一些代码来设置更新后的值。这是我目前所拥有的：
来自tensorflow.python.framework导入操作
从tensorflow.python.ops导入gen_training_ops
从tensorflow.python.ops导入math_ops
从tensorflow.python.training导入优化器
从tensorflow.python.util.tf_export导入tf_export
将张量流导入为 tf
将 numpy 导入为 np

类 TestGD(优化器.优化器):
  def __init__(自身, rad=0.01,
               use_locking=False, name=“TestGD”）：
    super(TestGD, self).__init__(use_locking, 名称)
    self._radius = rad

  def _create_slots(self, var_list):
    num_dims = len(var_list)
    self._beta = (num_dims - 1) / (num_dims + 1)
    self._B_matrix = np.identity(num_dims)

  def _prepare（自我）：
    self._radn_t = ops.convert_to_tensor(self._call_if_callable(self._radius), name=“beta”)
    self._beta_t = ops.convert_to_tensor(self._call_if_callable(self._beta), name=“beta”)
    self._B_matrix_t = ops.convert_to_tensor(self._call_if_callable(self._B_matrix), name=“B”)

  def _apply_dense（自身，梯度，变量）：
    返回 self._resource_apply_dense(grad, var)

  def _resource_apply_dense（自身，梯度，变量）：
    print(grad.shape, &quot;&lt;------------&quot;)
    #我计划在这里的某个地方实现我的算法
    var_update = tf.compat.v1.assign_sub(var, 0.01 * grad)
    返回 tf.group(var_update)

  def _apply_sparse(自我, grad, var):
    raise NotImplementedError(“不支持稀疏梯度更新。”)


# 构建LeNet模型
模型 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), 激活=&#39;relu&#39;, input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), 激活=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(84, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(10, 激活=&#39;softmax&#39;)
]）

# 使用您的自定义优化器
#custom_optimizer = SimpleGD(learning_rate=0.001)
自定义优化器 = TestGD()

# 使用自定义优化器编译模型
model.compile(优化器=custom_optimizer,
              损失=&#39;sparse_categorical_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

# 获取数据集
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0 # 将像素值标准化为 0 到 1 之间

x_train = x_train[..., tf.newaxis].astype(“float32”)
x_test = x_test[..., tf.newaxis].astype(“float32”)

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=60000).batch(64)

test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
测试数据集 = 测试数据集.batch(64)

＃ 训练
model.fit(train_dataset, epochs=5)

＃ 评估
test_loss, test_acc = model.evaluate(test_dataset)
print(f&quot;测试准确度：{test_acc}&quot;)

问题是，我得到的 grad 和 var 的形状非常奇怪，它们绝对不是向量。我应该怎么做才能将问题减少到 x 和 g 向量以及如何在最小化步骤后正确更新结果？]]></description>
      <guid>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</guid>
      <pubDate>Sat, 09 Dec 2023 17:23:42 GMT</pubDate>
    </item>
    <item>
      <title>实时多重检测 (RTMDet) CONFIG_PATH fileNotFoundError</title>
      <link>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</link>
      <description><![CDATA[我正在尝试遵循 Roboflow 指南&lt; /a&gt; 在自定义数据集上训练 RTMDet。我没有高端 GPU，因此我尝试使用 Colab 环境。
当我尝试使用 rtmdet_m 权重和配置文件初始化模型时，我收到 filenotfound 错误，即使我 100% 肯定文件存在于驱动器目录中。我相信这个问题与下面的配置文件中的 Base 有关
_base_ = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;



# ========================修改参数======================
加深因子 = 0.67
加宽因子 = 0.75

# =======================大多数情况下未修改==================
模型=字典（
主干=字典（深度因子=深度因子，加宽因子=加宽因子），
颈部=字典（深度因子=深度因子，加宽因子=加宽因子），
bbox_head=dict(head_module=dict(widen_factor=widen_factor)))

我还尝试将配置文件移动到本地 /content 目录，但它没有解决问题
这是我用于初始化的其余代码以及确切的错误消息
# 设置配置和权重文件的路径
WEIGHTS_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-
300e_coco_20230102_135952-40af4fe8.pth&#39;
CONFIG_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-300e_coco.py&#39;

# 初始化模型
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

-------------------------------------------------- ------------------------
FileNotFoundError Traceback（最近一次调用最后一次）
&lt;ipython-input-61-1d88a7ed1feb&gt;在&lt;细胞系：3&gt;()
      1 # 初始化模型
      2 DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
----&gt; 3 模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

5帧
_is_lazy_import(文件名)中的/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py
   第1653章
   第1654章
-&gt;第1655章
   第1656章
   第1657章

FileNotFoundError: [Errno 2] 没有这样的文件或目录:
&#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</guid>
      <pubDate>Fri, 08 Dec 2023 23:50:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 WEKA 检测信用卡欺诈？需要帮助[关闭]</title>
      <link>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</link>
      <description><![CDATA[我的计算机科学模块有这项作业。我需要使用 WEKA 来检测哪些用户可能拖欠信用卡到期付款。
我是 WEKA 的新手，所以有点困难。我收到了一个包含 48 个属性的 CSV，其中包括一个类：defaultnmIndicator 下个月默认的指示器（1=是，0=否）。
我需要预测，所以我知道我需要一个分类器。其中很多都是灰色的，包括 j48 和后勤。
例如，当我对整个集合运行线性回归时，相关系数约为 0.48。
我认为我在这里遗漏了一些非常明显的步骤。我的讲师刚刚建议我们搜索 YouTube，所以您可以想象这有多大帮助？
尝试的步骤：

我对数据集进行了标准化
估算缺失数据
使用完整训练集运行 CorrelationAttributeEval
尝试添加或删除此列表底部和顶部的属性，但模型没有得到真正的改进。
前 3 名：
`排名属性：
0.32588 43 金融压力指数
0.26159 22 平均循环信用卡利用率
0.24705 23 平均活跃信用额度利用率

&lt;小时/&gt;
底部3
-0.2096 30 任期最旧信用额度
-0.22082 自上次错过付款后 29 天
-0.40432 2 信用评分
`
我期望相关系数会更高。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</guid>
      <pubDate>Fri, 08 Dec 2023 20:33:44 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 模型给出的准确度、F1 分数、精确度和召回率均为 1.0，但似乎过度拟合 [关闭]</title>
      <link>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</link>
      <description><![CDATA[
我有 Spotify 音乐数据集。
playlist_genre 是目标变量，它有 6 个类别 - 摇滚、拉丁、R&amp;B、说唱、流行、器乐
如果我使用标签编码对目标变量进行编码，那么我得到的准确度和 F1 分数为 1.0
如果我使用 getDummies 或 one-hot 编码，那么我的准确度和 f1 分数将分别降至 0.29 和 0.19。

使用的分类算法：随机森林
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</guid>
      <pubDate>Sun, 03 Dec 2023 20:05:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 max_new_tokens 的 LLM 输出不完整</title>
      <link>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</link>
      <description><![CDATA[我正在尝试 Huggingface LLM 模型。
我注意到的一个问题是模型的输出突然结束，我理想地希望它完成其之间的段落/句子/代码。 （或者完全尝试在一些固定数量的标记内完成答案）
虽然我已经提供了 max_new_tokens = 300 并且在提示中我写道：
“输出最多应为 300 个字。”
响应总是不完整并且突然结束。我可以通过什么方式要求在所需数量的输出令牌内获得完整的输出？
代码：
检查点=“HuggingFaceH4/starchat-alpha”
设备=“cuda”； if torch.cuda.is_available() else “cpu”
StarCoderModel 类：
  def __init__(自身):
    self.tokenizer = AutoTokenizer.from_pretrained(检查点)
    # 如果需要 GPU，请确保 docker run 命令中提供了 `--gpus all`
    self.model = AutoModelForCausalLM.from_pretrained(检查点, device_map=&#39;auto&#39;)

  def infer(self, input_text, token_count):
    输入 = self.tokenizer.encode(input_text, return_tensors=“pt”).to(device)
    输出 = self.model.generate(输入, max_new_tokens=token_count, pad_token_id=self.tokenizer.eos_token_id)
    返回 self.tokenizer.decode(outputs[0])[len(input_text):]

样本输出：
私有数据类型FuntionName(String someId) {
    // TODO：替换为利用 someId 获取信息的实现
    返回数据类型.Value；
}


评论：

- 如果代码中存在 someId，则使用 Client 的 getAPI 以 someId 作为参数来获取一些信息。
- 如果

]]></description>
      <guid>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</guid>
      <pubDate>Thu, 07 Sep 2023 18:02:00 GMT</pubDate>
    </item>
    <item>
      <title>UnboundLocalError：赋值前引用的局部变量“batch_outputs”</title>
      <link>https://stackoverflow.com/questions/63364588/unboundlocalerror-local-variable-batch-outputs-referenced-before-assignment</link>
      <description><![CDATA[我正在使用 Keras 编写机器学习代码来对前列腺癌的严重程度进行分级。运行后出现如下错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
UnboundLocalError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-0e08590512ec&gt;在&lt;模块&gt;中
      8 表示列中的文件：
      9 数据=generate_tiles(文件)
---&gt; 10 预测 = model.predict(数据)
     11 max_score = 预测.max()
     12

_method_wrapper 中的 /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py(self, *args, **kwargs)
     86 raise ValueError(&#39;多工作模式下不支持{}。&#39;.format(
     87 方法.__名称__))
---&gt; 88 返回方法（self，*args，**kwargs）
     89
     90返回tf_decorator.make_decorator（

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py 中的预测（自我，x，batch_size，详细，步骤，回调，max_queue_size，工人，use_multiprocessing）
   第1283章
   第1284章
-&gt;第1285章
   第1286章
   第1287章

UnboundLocalError：赋值前引用的局部变量“batch_outputs”

有谁知道批量输出也会引用什么？我的代码中没有这样的变量。]]></description>
      <guid>https://stackoverflow.com/questions/63364588/unboundlocalerror-local-variable-batch-outputs-referenced-before-assignment</guid>
      <pubDate>Tue, 11 Aug 2020 18:50:56 GMT</pubDate>
    </item>
    </channel>
</rss>