<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 29 Apr 2024 18:17:44 GMT</lastBuildDate>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78403969/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[矩阵相乘很有趣：
导入火炬

# 尺寸和内容
批量大小 = 1
输入大小 = 8
Layer_1_emb_size = 3
Layer_2_emb_size = 4
Layer_3_emb_size = 5
Layer_4_emb_size = 6

# 权重矩阵
torch.manual_seed(42) # 再现性 = ♡
l1_weights = torch.rand（input_size，layer_1_emb_size）
l2_weights = torch.rand（layer_1_emb_size，layer_2_emb_size）
l3_weights = torch.rand（layer_2_emb_size，layer_3_emb_size）
l4_weights = torch.rand（layer_3_emb_size，layer_4_emb_size）

# 前向传递
some_input = torch.rand(batch_size, input_size)
out = torch.mm(some_input, l1_weights)
out_again = torch.mm(out, l2_weights)
very_out_again = torch.mm(out_again, l3_weights)
last_very_out_again = torch.mm(very_out_again, l4_weights)

在我的用例中，我有一堆掩蔽张量（值为 0 或 1 的张量，其中 0 是“ “mask”），我需要用它来决定输入矩阵的哪些元素与下一层的权重矩阵相乘：
# 前向传递
some_input = torch.rand(batch_size, input_size)
random_masking_tensor = (torch.rand((batch_size, input_size)) &lt; 0.5).float()
some_input = some_input * random_masking_tensor # 按元素屏蔽
out = torch.mm(some_input, l1_weights)
打印（随机掩码张量）
打印（一些_输入）
打印（l1_权重）
打印出）
&gt;&gt;&gt;&gt;&gt;
张量([[1., 1., 0., 1., 1., 1., 1., 0.]])
张量([[0.7860, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.7980, 0.0000]])
张量([[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696],
        [0.4414, 0.2969, 0.8317]])
张量([[1.7867,2.5470,1.6331]])

但是，我不希望只将所有值相乘（例如，0）。相反，我想要

根据屏蔽索引排除相应的屏蔽列/行。
明智地执行此操作（例如，请不要使用for循环 - 例如，请参阅这个相关的SO问题）
最重要的是保持梯度，所以如果我调用optimizer.backward()，相关元素应该被更新（即，不是屏蔽的行/列）。是的，我知道如果我将它们乘以0，它们的梯度将已经是0，因此它们不会被更新，但我需要完全排除它们。

例如，在上面的示例中，random_masking_tensor 的掩码索引为 [2, 7]，这意味着

我想从 some_input 中排除 [2, 7] 列（例如，元素后面的 0 列）明智的乘法——尽管我不想将它乘以掩码张量）
我想从计算中排除权重矩阵中的 [2, 7] 行（即 [0.2566, 0.7936, 0.9408] 和 [ 0.4414, 0.2969, 0.8317])

所以矩阵乘法应该而不是
print(火炬.mm(
    火炬. 张量([[0.7860, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.7980, 0.0000]]),
    火炬. 张量([[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696],
        [0.4414, 0.2969, 0.8317]])

））
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330]])

是
print(火炬.mm(
    火炬. 张量([[0.7860, 0.1115, 0.6524, 0.6057, 0.3725, 0.7980]]),
    火炬. 张量([[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696]])

））
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330]])

请注意，我的矩阵非常大（例如，emb_size=50000），并且批量大小不是 1（仅在本示例中使用了这些值），这就是为什么我不确定如何来做到这一点（批量大小为1时，我可能可以使用torch.index_select或类似的东西）]]></description>
      <guid>https://stackoverflow.com/questions/78403969/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 16:16:47 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 Designer 中使用在 Azure AutoML 中创建的 ML 模型？</title>
      <link>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</link>
      <description><![CDATA[我知道我可以在 Azure Designer 中创建自定义代码模块，但是有没有办法连接我在 AutoML 中本机创建的 ML 模型？
AutoML 模型正在使用 XGBoost，这似乎不是 Designer 的 ML 组件功能下的选项。我的目标是创建一个低代码解决方案，因此我不想使用自定义 Python 代码组件。
有什么想法吗？
使用 AutoML 构建模型，需要连接到 Designer 中的现有数据管道]]></description>
      <guid>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</guid>
      <pubDate>Mon, 29 Apr 2024 14:52:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么在机器学习中使用管道？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78403533/why-use-pipelines-in-machine-learning</link>
      <description><![CDATA[我们都知道，在机器学习中，我们通常不会对整个数据集及其所有列执行数据处理和特征工程步骤。
例如，在处理缺失值的步骤中，我们假设我们将使用平均值处理某些列，而使用中位数或众数处理其他列。但是，如果我们使用管道，则无法指定要用平均值或中位数替换缺失值的列。这可能会导致不同的结果，那么为什么要使用管道呢？]]></description>
      <guid>https://stackoverflow.com/questions/78403533/why-use-pipelines-in-machine-learning</guid>
      <pubDate>Mon, 29 Apr 2024 14:51:51 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 - 针对 AUC 或 F1 分数进行优化</title>
      <link>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</link>
      <description><![CDATA[我在 sklearn 中使用随机森林，并且我的数据集相当不平衡（20% 为正类，80% 为其他类）。有没有办法让它针对一些考虑到这一点的指标进行训练（优化），比如 AUC 分数或 F1 分数？我可以使用什么技巧来推动它朝这个方向发展吗？
到目前为止，我想到/尝试过的唯一方法是使用不同的类别权重。
或者，是否有其他实现（或其他模型，例如 xgboost）允许我使用这样的自定义指标？]]></description>
      <guid>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</guid>
      <pubDate>Mon, 29 Apr 2024 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能寻找好的视频质量增强器[关闭]</title>
      <link>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</link>
      <description><![CDATA[我有一些 15 年前制作的旧视频。质量很差，它确实被压缩了，而且我有一些小故障，因为此时视频导入非常有问题。
我想尝试一些能够使用人工智能增强这些视频的程序。
如果只有可用的模型，我什至可以编写此代码。
我搜索 MacOS 或 Linux 工具。我更喜欢它是开源的。
你知道我在哪里可以找到一个好的工具吗？我尝试了一些，但质量不太好。
如果没有程序可以做到这一点，我该如何继续训练我的模型？我不知道这是否是一个好方法，因为它需要大量视频来完成......
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</guid>
      <pubDate>Mon, 29 Apr 2024 11:32:19 GMT</pubDate>
    </item>
    <item>
      <title>关于机器学习中预测时间序列的分析和模型的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</link>
      <description><![CDATA[我必须根据 csv 数据对给定日期的网络单元格进行流量预测，其中包含 5 列：区域、站点、单元格、日期、流量
例如：
&lt;上一页&gt;&lt;代码&gt;AAN,AAN001,AAN001A,2021-01-01,2.56

AAN,AAN001,AAN001B,2021-01-01,5.6

ANM,ANM448,ANM448B,2021-04-19,1.2

ANM,ANM448,ANM448C,2021-04-19,3.6

有人可以帮助我一点，我仍然是机器和深度学习的初学者
我已经尝试过 randomforst 但没有成功。
我做了一些研究，结果被告知我们可以使用 LSTM 模型？]]></description>
      <guid>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</guid>
      <pubDate>Mon, 29 Apr 2024 11:01:17 GMT</pubDate>
    </item>
    <item>
      <title>Python SkLearn 线性回归的准确度分数给出了无意义的结果</title>
      <link>https://stackoverflow.com/questions/78402227/python-sklearn-accuracy-scores-for-linear-regression-give-nonsensical-results</link>
      <description><![CDATA[我正在参加 Kaggle 房价 竞赛练习我的机器学习技能。我对数据进行预处理，然后使用交叉验证来测试几个不同的模型，看看哪个模型表现最好。不幸的是，尽管我收到了大多数模型的正常结果，但我得到的线性回归结果毫无意义。我发布了我的代码和结果图片，您可以在 Kaggle 竞赛的链接中找到数据文件。您能否向我解释一下为什么我会收到这些结果以及我可以采取哪些措施来解决这些问题？
准确率得分结果
train = pd.read_csv(&#39;train.csv&#39;)

train.dropna（轴= 1，阈值= 1200，就地= True）
train[&#39;SalePrice&#39;] = np.log(train[&#39;SalePrice&#39;])

num_data = list(train.select_dtypes(include=[&#39;float64&#39;, &#39;int64&#39;]).drop([&#39;Id&#39;, &#39;SalePrice&#39;], axis=1))
cat_data = list(train.select_dtypes(include=&#39;object&#39;))

cat_pipeline = Pipeline([(&#39;cat_imputer&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;)), (&#39;编码器&#39;, OneHotEncoder())])
num_pipeline = Pipeline([(&#39;num_imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)), (&#39;scaler&#39;, StandardScaler())])
                         
col_transformer = ColumnTransformer([(&#39;cat_pipeline&#39;, cat_pipeline, cat_data),
                                     (&#39;num_pipeline&#39;, num_pipeline, num_data)], 余数=&#39;drop&#39;)

y = 火车[&#39;销售价格&#39;]
X = train.drop(columns=[&#39;Id&#39;, &#39;SalePrice&#39;])
X = col_transformer.fit_transform(X).toarray()

X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42)

lin_reg = 线性回归()
sgd = SGDRegressor()
贝叶斯 = BayesianRidge()
树 = DecisionTreeRegressor()
森林 = RandomForestRegressor()
xgb = XGBRegressor()

结果={}
对于 [lin_reg、sgd、bayes、tree、forest、xgb] 中的模型：
    分数 = cross_validate(模型, X_train, y_train, 评分=[&#39;neg_mean_squared_error&#39;, &#39;neg_mean_absolute_error&#39;,
                                                              &#39;explained_variance&#39;, &#39;r2&#39;], cv=10)
    结果[str(model).split(&#39;(&#39;)[0]] = [分数[&#39;test_neg_mean_squared_error&#39;].mean(), 分数[&#39;test_neg_mean_absolute_error&#39;].mean(),
                           分数[&#39;test_explained_variance&#39;].mean(), 分数[&#39;test_r2&#39;].mean()]

pd.options.display.float_format = &#39;{:,.4f}&#39;.format
results_df = pd.DataFrame(数据=结果,
                          index=[&#39;负均方误差&#39;, &#39;负平均绝对误差&#39;, &#39;解释方差得分&#39;, &#39;R2 得分&#39;])
结果_df


我上网查了一下，但没有找到遇到同样问题的人。]]></description>
      <guid>https://stackoverflow.com/questions/78402227/python-sklearn-accuracy-scores-for-linear-regression-give-nonsensical-results</guid>
      <pubDate>Mon, 29 Apr 2024 10:55:30 GMT</pubDate>
    </item>
    <item>
      <title>使用Python从工程图PDF中提取表格[关闭]</title>
      <link>https://stackoverflow.com/questions/78401923/extract-table-from-engineering-drawing-pdf-with-python</link>
      <description><![CDATA[在此处输入图片描述
输入的是pdf文件
我想从中提取表，其中包含 FOOTING SCHEDULE 和项目标题
无论这些信息位于设计中什么
如何做到这一点
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78401923/extract-table-from-engineering-drawing-pdf-with-python</guid>
      <pubDate>Mon, 29 Apr 2024 10:04:06 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将 MobileNet v2 用于 fashinon minst 数据集吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78401789/can-we-mobilenet-v2-for-fashinon-minst-dataset</link>
      <description><![CDATA[我想使用预定义的模型及其基于迁移学习的项目（电子商务）。
我需要知道的是我可以将 mobilenet v2 模型用于时尚 Minst 数据集吗？如果不是，哪种预定义模型更适合迁移学习中的该数据集
谢谢
我尝试了不同的迁移学习教程，但在使用预定义模型时仍然感到困惑]]></description>
      <guid>https://stackoverflow.com/questions/78401789/can-we-mobilenet-v2-for-fashinon-minst-dataset</guid>
      <pubDate>Mon, 29 Apr 2024 09:40:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 进行图像分类的迁移学习</title>
      <link>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</link>
      <description><![CDATA[我正在尝试使用已经训练好的模型将学习转移到我将创建并仅修改最后几层的模型。这样做的目标是使用已经训练的模型（已经在数百万张图像上训练）来帮助我的模型对食品识别进行分类。我对 Keras 还很陌生，我面临着一个问题，我现在开始理解它，但不知道如何解决
# 从 TensorFlow Hub 加载模型
model_url =“https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/classification/1”
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3))

# 创建一个序列模型
模型 = tf.keras.Sequential()

# 将 TensorFlow Hub 层添加到 Sequential 模型中
模型.add(hub_layer)

# 构建顺序模型
模型.build((无, 224, 224, 3))

# 模型总结
模型.summary()

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
[56] 中的单元格，第 9 行
      6 模型 = tf.keras.Sequential()
      8 # 将 TensorFlow Hub 层添加到 Sequential 模型中
----&gt; 9 模型.add(hub_layer)
     11 # 构建顺序模型
     12 模型.build((无, 224, 224, 3))

文件c:\Users\Karim\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\sequential.py:95，在Sequential.add(self，layer，rebuild)中
     93层=origin_layer
     94 如果不是 isinstance(layer, Layer):
---&gt; 95 引发值错误（
     96、“只有‘keras.Layer’的实例可以是”
     97 f”添加到顺序模型中。收到：{层}”
     98 f“(类型{type(层)})”
     99）
    100 如果不是 self._is_layer_name_unique(layer):
    101 引发值错误（
    102“添加到顺序模型的所有层”
    103 f”应该有唯一的名称。名称“{layer.name}”已经是“
    104“该模型中层的名称。更新“name”参数“
    105“传递唯一的名称。”
    106）

ValueError：只能将“keras.Layer”的实例添加到顺序模型中。收到： （类型）
]]></description>
      <guid>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</guid>
      <pubDate>Mon, 29 Apr 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>Keras TextVectorization 似乎区分大小写，即使词汇量没有反映这一点？</title>
      <link>https://stackoverflow.com/questions/78400462/keras-textvectorization-seems-to-be-case-sensitive-even-though-vocabulary-doesn</link>
      <description><![CDATA[我有以下代码
导入 keras

v = {
    “甲板”：[&#39;a&#39;，&#39;B&#39;，&#39;C&#39;，&#39;D&#39;，&#39;E&#39;，&#39;F&#39;，&#39;G&#39;，&#39;H&#39;，&#39;I&#39;，&#39;J&#39;，&#39;K&#39;， &#39;L&#39;]
}

打印（len（v[“甲板”]））

l = keras.layers.TextVectorization(
    max_tokens=len(v[“甲板”])+2,
    词汇=v[“甲板”],
    输出模式=&#39;计数&#39;,
    名称=“甲板”）

打印（l.vocabulary_size（））
打印（l.get_vocabulary（））

print(l(&#39;a A b B&#39;))

输出是：
&lt;前&gt;&lt;代码&gt;12
13
[&#39;[UNK]&#39;、&#39;a&#39;、&#39;B&#39;、&#39;C&#39;、&#39;D&#39;、&#39;E&#39;、&#39;F&#39;、&#39;G&#39;、&#39;H&#39;、&#39;I&#39;、&#39;J&#39;、&#39;K&#39; ，&#39;L&#39;]
tf.Tensor([2.2.0.0.0.0.0.0.0.0.0.0.0.],形状=(13,),dtype=float32)

我希望至少有一个 b 能够被计算在内。
如果我使用l.adapt(v[“deck”])，事情似乎会相应地工作，但词汇都是小写的。
像这样：
导入 keras

v = {
    “甲板”：[&#39;a&#39;，&#39;B&#39;，&#39;C&#39;，&#39;D&#39;，&#39;E&#39;，&#39;F&#39;，&#39;G&#39;，&#39;H&#39;，&#39;I&#39;，&#39;J&#39;，&#39;K&#39;， &#39;L&#39;]
}

打印（len（v[“甲板”]））

l = keras.layers.TextVectorization(
    max_tokens=len(v[“甲板”])+2,
    # 词汇=v[“甲板”],
    输出模式=&#39;计数&#39;,
    名称=“甲板”）

l.adapt(v[&#39;甲板&#39;])

打印（l.vocabulary_size（））
打印（l.get_vocabulary（））

print(l(&#39;a A b B&#39;))

和输出：
&lt;前&gt;&lt;代码&gt;12
13
[&#39;[UNK]&#39;、&#39;l&#39;、&#39;k&#39;、&#39;j&#39;、&#39;i&#39;、&#39;h&#39;、&#39;g&#39;、&#39;f&#39;、&#39;e&#39;、&#39;d&#39;、&#39;c&#39;、&#39;b&#39; ， &#39;A&#39;]
tf.Tensor([0.0.0.0.0.0.0.0.0.0.0.2.2.],形状=(13,),dtype=float32)

如何正确使用词汇参数？]]></description>
      <guid>https://stackoverflow.com/questions/78400462/keras-textvectorization-seems-to-be-case-sensitive-even-though-vocabulary-doesn</guid>
      <pubDate>Mon, 29 Apr 2024 04:20:18 GMT</pubDate>
    </item>
    <item>
      <title>GKE 上的 GPU 时间共享</title>
      <link>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</link>
      <description><![CDATA[我正在尝试使用 说明中的 GPU 时间共享此处，但是我的工作负载不会在启用分时的节点上运行。
我有一个具有 GPU 配置的节点池，启用了策略分时的 GPU 共享以及“每个 GPU 的最大共享客户端数”。如 48 所示。节点运行良好，但我无法使用记录的 nodeSelector 配置为我的工作负载运行工作负载，例如
节点选择器：
  cloud.google.com/gke-accelerator：“nvidia-tesla-t4”
  cloud.google.com/gke-max-shared-clients-per-gpu：“48”
  cloud.google.com/gke-gpu-sharing-strategy：分时

这样，我的 Pod 就会陷入挂起状态，并显示消息xnodes did not match Pod&#39;s nodeaffinity/selector。如果我删除 gke-max-shared-clients-per-gpu 和 gke-gpu-sharing-strategy 密钥对，pod 会正常调度并运行。
当我检查 GPU 分时节点池中节点上的 kubernetes 标签时，它们不包含这些标签，并且我无法手动添加它们，因为 GCP 阻止了它。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</guid>
      <pubDate>Mon, 29 Apr 2024 02:20:41 GMT</pubDate>
    </item>
    <item>
      <title>呼吸信号的对数功率谱</title>
      <link>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</link>
      <description><![CDATA[我的数据集是噪声频谱的LPS，我的标签是干净频谱的LPS，每个图片大小是（1025*1292）。我使用unet作为我的模型。
型号：
导入火炬
将 torch.nn 导入为 nn

解码器类（nn.Module）：
    def __init__(self, in_channels,out_features, kernel_size, maxpoolindex, apply_dropout,stride):
        super(解码器, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels、out_channels=out_features、kernel_size=kernel_size、stride=stride、padding=0、bias=True)
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.LeakyReLU(负斜率=0.2)
        self.dropout = nn.Dropout(p=0.1)
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) 如果 maxpoolindex == 1 否则无

    def 前向（自身，x）：
        x = self.conv(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        如果 self.maxpool 不是 None：
            x = self.maxpool(x)
        返回x

编码器类（nn.Module）：
    def __init__(self,in_channels, out_features, kernel_size, apply_dropout):
        超级（编码器，自我）.__init__()
        self.conv_transpose = nn.ConvTranspose2d（in_channels = in_channels，out_channels = out_features，kernel_size = kernel_size，stride = 2，padding = 0，bias = True）
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def 前向（自身，x）：
        x = self.conv_transpose(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        返回x

class DenoiseUnet(nn.Module):#除到第一个奇数停止的设计
    def __init__(自身):
        超级（DenoiseUnet，自我）.__init__()
        self.down_procedure = nn.ModuleList([
            解码器(1,8,2,0,0,2),
            解码器(8,16,2,0,0,2),
            解码器(16,32,2,0,0,2),
            解码器(32,128,2,0,0,2),
            解码器(128,128,1,0,0,1)
        ]）
        self.up_procedure = nn.ModuleList([
            编码器(2​​56,32,2,0),
            编码器(64,16,2,0),
            编码器(32,8,2,0),
            编码器(16,4,2,0),
        ]）
        self.convert = nn.ConvTranspose2d(4, 1, kernel_size=1, stride=1, padding=0)


    def 前向（自身，x）：
        连接=[]
        对于 self.down_procedure 中的 down：
            x = 向下(x)
            连接.append(x)

        连接=列表（反转（连接[：-1]））
        对于 up，在 zip(self.up_procedure, connection) 中连接：


            如果 x.shape[2] &lt;连接.形状[2]：
              连接 = 连接[:, :, :x.shape[2], :]
            别的：
              x = x[:, :, :connect.shape[2], :]

            如果 x.shape[3] &lt;连接.形状[3]：
              连接 = 连接[:, :, :, :x.shape[3]]
            别的：
              x = x[:, :, :, :connect.shape[3]]



            x = torch.cat([x, 连接], 暗淡=1)
            x = 上(x)

        y = self.convert(x)
        返回y


模型 = DenoiseUnet()
打印（模型）

但是经过 10 轮训练后，我得到这样的结果：
https://i.sstatic.net/b8DxXHUr.png
https://i.sstatic.net/UDhZNKHE.png
一个是预测结果，一个是测试，任何人都可以帮我找出问题所在吗？
数据集数量不同，看起来是一样的。]]></description>
      <guid>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</guid>
      <pubDate>Thu, 25 Apr 2024 17:43:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 在 Python 中崩溃的多线程 [关闭]</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！
下图显示了命令htop：
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用 (pip install pickle5) 安装 Python 的 pickle 包，但安装包失败</title>
      <link>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</link>
      <description><![CDATA[这是我尝试过的：
pip install pickle5

这是带有错误消息的快照。
这也是我收到的错误：
错误：无法为 pickle5 构建 wheel，这是安装基于 pyproject.toml 的项目所必需的
我尝试按照其他一些帖子中的建议安装并重新安装 Microsoft Visual C++，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</guid>
      <pubDate>Sat, 27 Jan 2024 05:36:19 GMT</pubDate>
    </item>
    </channel>
</rss>