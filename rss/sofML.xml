<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 26 Jul 2024 12:28:07 GMT</lastBuildDate>
    <item>
      <title>模型（DecisionTreeClassifier）给出了错误的结果</title>
      <link>https://stackoverflow.com/questions/78797339/the-modeldecisiontreeclassifier-gives-wrong-results</link>
      <description><![CDATA[我正在参加一门机器学习课程，其作业是实现 DecisionTreeClassifier 的拟合方法。以下是更多信息的链接：
https://stepik.org/lesson/333977/step/8?auth=login&amp;unit=317388
https://stepik.org/lesson/333977/step/3?auth=login&amp;unit=317388
这是我的代码：
import numpy as np
import pandas as pd

class MyTreeClf:
def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20):
self.max_depth = max_depth
self.min_samples_split = min_samples_split
self.max_leafs = max_leafs
self.tree = None
self.leafs_cnt = 0

def node_entropy(self, probs):
return -np.sum([p * np.log2(p) for p in probs if p &gt; 0])

def node_ig(self, x_col, y, split_value):
left_mask = x_col &lt;= split_value
right_mask = x_col &gt; split_value

如果 len(x_col[left_mask]) == 0 或 len(x_col[right_mask]) == 0:
返回 0

left_probs = np.bincount(y[left_mask]) / len(y[left_mask])
right_probs = np.bincount(y[right_mask]) / len(y[right_mask])

entropy_after = len(y[left_mask]) / len(y) * self.node_entropy(left_probs) + len(y[right_mask]) / len(y) * self.node_entropy(right_probs)
entropy_before = self.node_entropy(np.bincount(y) / len(y))

返回 entropy_before - entropy_after

def get_best_split(self, X: pd.DataFrame，y：pd.Series）：
best_col，best_split_value，best_ig = None，None，-np.inf

对于 X.columns 中的 col：
sorted_unique_values = np.sort(X[col].unique())

对于 range(1，len(sorted_unique_values)) 中的 i：
split_value = (sorted_unique_values[i - 1] + sorted_unique_values[i]) / 2

ig = self.node_ig(X[col]，y，split_value)

如果 ig &gt; best_ig:
best_ig = ig
best_col = col
best_split_value = split_value

返回 best_col、best_split_value、best_ig

def fit(self, X: pd.DataFrame, y: pd.Series,depth=0):
如果depth == 0:
self.tree = {}

best_col、best_split_value、best_ig = self.get_best_split(X, y)

如果depth &lt; self.max_depth 和 len(y) &gt;= self.min_samples_split 和 self.leafs_cnt &lt; self.max_leafs 和 best_col 不为 None:
left_mask = X[best_col] &lt;= best_split_value
right_mask = X[best_col] &gt; best_split_value

self.tree[depth] = {&#39;col&#39;: best_col, &#39;split&#39;: best_split_value, &#39;left&#39;: {}, &#39;right&#39;: {}}

self.fit(X[left_mask], y[left_mask],depth + 1)
self.fit(X[right_mask], y[right_mask],depth + 1)
else:
class_label = y.mode()[0]
self.tree[depth] = {&#39;class&#39;: class_label}
self.leafs_cnt += 1

我已验证node_entropy、node_ig和get_best_split方法正常工作。但是，fit方法对第一个样本返回4，而预期结果是2。
测试包括三个数据集和参数max_depth、min_samples_split和max_leafs。他们为第一个样本提供了以下参数：
样本输入：{&quot;max_depth&quot;: 3, &quot;min_samples_split&quot;: 2, &quot;max_leafs&quot;: 1}
样本输出：2 (leafs_cnt)
不幸的是，他们没有提供这些数据集]]></description>
      <guid>https://stackoverflow.com/questions/78797339/the-modeldecisiontreeclassifier-gives-wrong-results</guid>
      <pubDate>Fri, 26 Jul 2024 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么在训练期间我的 TensorFlow Siamese 网络中的所有变量的梯度都为无？</title>
      <link>https://stackoverflow.com/questions/78796915/why-are-gradients-none-for-all-variables-in-my-tensorflow-siamese-network-during</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78796915/why-are-gradients-none-for-all-variables-in-my-tensorflow-siamese-network-during</guid>
      <pubDate>Fri, 26 Jul 2024 08:08:30 GMT</pubDate>
    </item>
    <item>
      <title>GradientBoostedClassifier() 中的 min_samples_leaf 行为怪异</title>
      <link>https://stackoverflow.com/questions/78796671/min-samples-leaf-in-gradientboostedclassifier-having-weird-behavior</link>
      <description><![CDATA[尝试在 GradientBoostedClassifer() 中调整 min_samples_leaf。我看到了偏差/方差权衡的预期结果。但是，为了测试边界，我让 min_samples_leaf &gt;训练数据集中有 n_samples，预计会出现错误或其他问题，但我仍然得到与模型调整时类似的结果：
df = df_a # 样本数 = 347
df=df.sample(frac=1) 
train_proportion = 0.8 
n = len(df)
t = int(train_proportion * n)

# 单独的训练和测试集
y = df[&#39;detected&#39;]
X = df.loc[:, ~df.columns.isin([&#39;detected&#39;])]

# 训练集中的样本
train_x = X.iloc[:t,:].reset_index().iloc[:,1:]
# 测试集中的样本
test_x = X.iloc[t:,:].reset_index().iloc[:,1:]
# 训练集中的目标
train_y = pd.Series(y[:t].reset_index().iloc[:,1:].iloc[:,0])
#测试集中的目标
test_y = pd.Series(y[t:].reset_index().iloc[:,1:].iloc[:,0])

clf = GradientBoostingClassifier(n_estimators = 100, max_depth = 10, random_state= 0, min_samples_leaf=500)
clf.fit(train_x,train_y)
print(clf.score(train_x,train_y))
print(clf.score(test_x,test_y))

输出：
0.924187725631769
0.9142857142857143

为什么会这样？我预计会出现错误或不会进行拆分。文档中似乎没有说明如果 min_samples_leaf &gt; n_samples 会发生什么。对 int 的唯一要求是范围 [1,inf]。对此也没有其他说明。
我当时想也许它会将 min_samples_leaf 重置为某个可用值，但所有子树都没有深度，也没有进行拆分：subtree]]></description>
      <guid>https://stackoverflow.com/questions/78796671/min-samples-leaf-in-gradientboostedclassifier-having-weird-behavior</guid>
      <pubDate>Fri, 26 Jul 2024 07:05:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用低质量 PDF 文件来提高 RAG 性能？</title>
      <link>https://stackoverflow.com/questions/78796435/how-to-improve-rag-performance-with-low-quality-pdf-files</link>
      <description><![CDATA[我正在做一个 RAG 项目。其中一个步骤是从 pdf 文件中提取文本。我发现，如果输入的 pdf 质量好，它工作得很好，但是当输入的 pdf 质量差时，我的 RAG 无法回答一些问题。如果我必须处理低质量的 pdf 文件，我该如何改进我的 RAG？
我使用 PyMuPDF 直接从 PDF 中提取文本。
我使用 Chroma 作为我的矢量数据库。
我使用 BAAI/bge-m3 作为我的嵌入模型。]]></description>
      <guid>https://stackoverflow.com/questions/78796435/how-to-improve-rag-performance-with-low-quality-pdf-files</guid>
      <pubDate>Fri, 26 Jul 2024 06:01:26 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 中实现具有多个输入的循环神经网络训练算法</title>
      <link>https://stackoverflow.com/questions/78796429/implementation-of-training-algorithm-for-recurrent-neural-networks-with-multiple</link>
      <description><![CDATA[因此，我在一本名为“使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习实践”的书中阅读了有关 RNN 的知识，该书的作者是 Aurelien Geron。我遇到了一个使用 Keras 的序列到序列 RNN 的非常简单的实现：
seq2seq_model = tf.keras.Sequential([
tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),
tf.keras.layers.Dense(14)
])

这应该采取任意数量的时间步骤（在本例中为 56），每个步骤有 5 个特征，并创建一个向量，其中包含每个时间步骤每天未来 2 周的预测。
这是从 repo 中获取的：
https://github.com/ageron/handson-ml3/blob/main/15_processing_sequences_using_rnns_and_cnns.ipynb
但理解这个问题并不需要它。
因此，时间序列数据以 56 的序列长度传递。因此，在调用 predict 之后，我们有效地获得了 56 个预测向量，每个向量有 14 天的预测（前 55 个用于训练，最后一个是实际预测）。我的问题是：如果有 32 个输入神经元，每个神经元都采用前一个时间步骤，如果前 31 个时间步骤之前的时间步骤不足以作为输入传递给所有神经元，我们如何获得 56 个预测？所有缺失的特征都设置为 0 吗？在这些情况下，前向传递是如何完成的？当我们尝试训练模型使用完整的 56 个时间步骤数据进行预测时，这些情况下的反向传播有何用处？我正在寻找 Keras 特定的答案以及对此的一些一般见解。
我尝试运行此代码：
X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]
y_pred_14 = seq2seq_model.predict(np.asarray(X).astype(np.float32))
print(len(y_pred_14[0]))

发现预测有 56 个向量。我预计一个 32 大小的窗口会在 56 个时间步骤中滚动以产生大约 20 个预测向量。]]></description>
      <guid>https://stackoverflow.com/questions/78796429/implementation-of-training-algorithm-for-recurrent-neural-networks-with-multiple</guid>
      <pubDate>Fri, 26 Jul 2024 06:00:48 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError: ‘list’ 对象没有属性 ‘shape’ 错误</title>
      <link>https://stackoverflow.com/questions/78796342/attributeerror-list-object-has-no-attribute-shape-error</link>
      <description><![CDATA[我目前正在尝试遵循教程，因为我刚刚开始学习机器学习。
我正在尝试预测股票价格。这是我的代码：
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as web
import numpy as np

从 sklearn.preprocessing 导入 MinMaxScaler
从 tensorflow.python.keras.models 导入 Sequential
从 tensorflow.python.keras.layers 导入 Dense、Dropout
从 tensorflow.python.keras.layers.recurrent 导入 LSTM

company = &#39;TSLA&#39;

start=&#39;2012-01-01&#39;
end=&#39;2024-03-01&#39;

data = web.download(company, start=start, end=end)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60

x_train = []
y_train = []

for x in range(prediction_days, len(scaled_data)):
x_train.append(scaled_data[x-prediction_days:x, 0])
y_train.append(scaled_data[x, 0])

model = Sequential()

model.add(LSTM(units = 50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50))
model.add(Dropout(0.2))

我期望它什么都不输入，但是我收到此错误：
但它显示为错误，
回溯（最近一次调用）：
文件
&quot;c:\Users\User1\OneDrive\Documents\Desktop\python\projects\machine\stock_price_predictor.py&quot;，
第 32 行，在 &lt;module&gt;
model.add(LSTM(units = 50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
^^^^^^^^^^^^^
AttributeError: &#39;list&#39; 对象没有属性 &#39;shape&#39;

你们有人知道如何解决这个问题吗？我尝试将其转换为 np.array，但没有任何效果。这是我的尝试：
&#39;
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as web
import numpy as np

从 sklearn.preprocessing 导入 MinMaxScaler
从 tensorflow.python.keras.models 导入 Sequential
从 tensorflow.python.keras.layers 导入 Dense、Dropout
从 tensorflow.python.keras.layers.recurrent 导入 LSTM

company = &#39;TSLA&#39;

start=&#39;2012-01-01&#39;
end=&#39;2024-03-01&#39;

data = web.download(company, start=start, end=end)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data=.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60

x_train = np.array([])
y_train = np.array([])

对于 x 在 range(prediction_days, len(scaled_data)) 中：
x_train = np.append(x_train, scaled_data[x-prediction_days:x, 0])
y_train = np.append(y_train, scaled_data[x, 0])

model = Sequential()

model.add(LSTM(units = 50, return_sequences=True, input_shape= 
(x_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50))
model.add(Dropout(0.2))

&#39;
但我却得到了这个错误
&#39;
Traceback (most recent call last):
File 
&quot;c:\Users\User1\OneDrive\Documents\Desktop\python\projects\machine 
learning\stock_price_predictor.py&quot;, line 32, in &lt;module&gt;
model.add(LSTM(units = 50, return_sequences=True, input_shape= 
(x_train.shape[1], 1))) 
~~~~~~~~~~~~~^^^
IndexError: 元组索引超出范围

&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78796342/attributeerror-list-object-has-no-attribute-shape-error</guid>
      <pubDate>Fri, 26 Jul 2024 05:31:21 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：参数 clone_function 和 input_tensors 仅支持顺序模型或功能模型</title>
      <link>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</link>
      <description><![CDATA[我正在使用Quantization perceived training，参考网上的lstm代码，想把QAT放进lstm，结果遇到了ValueError。
ValueError Traceback (most recent call last)
&lt;ipython-input-11-00669bb76f9d&gt; in &lt;cell line: 6&gt;()
4 return layer
5 
----&gt; 6 annotated_model = tf.keras.models.clone_model(
7 model,
8 clone_function=apply_quantization_to_dense,

/usr/local/lib/python3.10/dist-packages/tf_keras/src/models/cloning.py in clone_model(model, input_tensors, clone_function)
544 # 自定义模型类的情况
545 if clone_function or input_tensors:
--&gt; 546 raise ValueError(
547 &quot;参数 clone_function 和 input_tensors &quot;
548 &quot;仅支持 Sequential 模型 &quot;

ValueError: 参数 clone_function 和 input_tensors 仅支持 Sequential 模型或 Functional 模型。收到类型为“Sequential”的模型，其中 clone_function=&lt;function apply_quantization_to_dense 位于0x78b727ec4040&gt; 和 input_tensors=None

这是我的代码
import keras
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dense、Activation
从 keras.datasets 导入 mnist
从 keras.models 导入 Sequential
从 keras.optimizers 导入 Adam

learning_rate = 0.001
training_iters = 20
batch_size = 128
display_step = 10

n_input = 28
n_step = 28
n_hidden = 128
n_classes = 10

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(-1, n_step, n_input)
x_test = x_test.reshape(-1, n_step, n_input)
x_train = x_train.astype(&#39;float32&#39;)
x_test = x_test.astype(&#39;float32&#39;)
x_train /= 255
x_test /= 255

y_train = keras.utils.to_categorical(y_train, n_classes)
y_test = keras.utils.to_categorical(y_test, n_classes)

model = Sequential()
model.add(LSTM(n_hidden,
batch_input_shape=(None, n_step, n_input),
unroll=True))

model.add(Dense(n_classes))
model.add(Activation(&#39;softmax&#39;))

adam = Adam(lr=learning_rate)
model.summary()
model.compile(optimizer=adam,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

model.fit(x_train, y_train,
batch_size=batch_size,
epochs=training_iters,
verbose=1,
validation_data=(x_test, y_test))

scores = model.evaluate(x_test, y_test, verbose=0)
print(&#39;LSTM 测试分数：&#39;, scores[0])
print(&#39;LSTM 测试准确率：&#39;, scores[1])

def apply_quantization_to_dense(layer):
if isinstance(layer, tf.keras.layers.LSTM):
return tfmot.quantization.keras.quantize_annotate_layer(layer)
return layer

annotated_model = tf.keras.models.clone_model(
model,
clone_function=apply_quantization_to_dense,
)
qat_model = tfmot.quantization.keras.quantize_apply(annotated_model)
qat_model.summary()
]]></description>
      <guid>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</guid>
      <pubDate>Fri, 26 Jul 2024 03:41:57 GMT</pubDate>
    </item>
    <item>
      <title>优化不平衡分类问题中两个特定类别的准确率和召回率</title>
      <link>https://stackoverflow.com/questions/78795688/optimize-precision-and-recall-for-two-specific-classes-in-an-imbalanced-classifi</link>
      <description><![CDATA[我有三个类别 {-1, 0, 1}。相应类别的数据平均比例为 1:20:1。我想要实现
类别 -1 和 1 的高精度 (&gt;70%) 和平均召回率 (30%-40%)。
类别 0 的召回率高 (&gt;90%)。类别 0 的精度无关紧要。

对 -1 和 1 的错误分类代价高昂。
我目前有两个模型。我们将第一个模型称为 m1（集成，在所有三个类别上进行训练），将第二个模型称为 m2。m1 使用 EasyEnsembleClassifier（来自 imblearn，使用 XGBoost 作为基础模型）进行拟合，以对所有三个类别进行分类。如果 m1 的预测为 -1 或 1，则将数据输入到 m2（使用 XGBoost 在 -1 和 1 上训练为二元分类器），然后将 m2 的预测用作最终预测。如果 m1 的预测为 0，则 0 为最终预测。
m2 也已校准。因此，如果 m1 中有许多 0 被错误分类为 1 和 -1，我可以使用 m2 设置概率阈值以过滤掉错误的预测。
从混淆矩阵和下面的分类报告来看，我的方法似乎根本不起作用。我已经尝试过采样（SMOTE、ADASYN）、欠采样和设置类别权重（scale_pos_weight）。我可以做些什么来提高模型的性能并提高 -1 和 1 的预测质量。欢迎提出任何建议。
混淆矩阵
分类报告]]></description>
      <guid>https://stackoverflow.com/questions/78795688/optimize-precision-and-recall-for-two-specific-classes-in-an-imbalanced-classifi</guid>
      <pubDate>Thu, 25 Jul 2024 22:58:52 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：不支持 y 的稀疏多标签指标 - 如何处理具有稀疏数据的多标签分类？</title>
      <link>https://stackoverflow.com/questions/78795297/valueerror-sparse-multilabel-indicator-for-y-is-not-supported-how-to-handle-m</link>
      <description><![CDATA[我只是一个初学者，我还在学习稀疏矩阵以及它们如何与其他东西一起工作。
这是我遇到的问题，在网上搜索后找不到合适的答案。
我使用默认参数 sparse_output=True 对分类标签进行了 OneHotEncoded，
当我尝试在训练测试拆分后使用 transformed_X 和目标 y 拟合 RandomForestClassifier 时，它显示了此错误。
#seed
np.random.seed(42)

#one hot encoding imports
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer as ct

#Data splitting
X = f_data.drop(&#39;attended&#39;, axis = 1)
y = f_data[&#39;attended&#39;]

#select columns
cat_col = [&#39;days_before&#39;,&#39;day_of_week&#39;,&#39;time&#39;,&#39;category&#39;]

#初始化编码器 
enc = OneHotEncoder()

#使用 ct 拟合编码器
transformer = ct([(&#39;enc&#39;,enc,cat_col)], remainder = &#39;passthrough&#39;)
transformed_X = transformer.fit_transform(X)
transformed_X

&lt;1480x36 稀疏矩阵，类型为 &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;压缩稀疏行格式中存储了 10360 个元素&gt;
#BaseLine 模型
np.random.seed(42)

#imports
from sklearn.model_selection import train_test_split as tts
from sklearn.ensemble import RandomForestClassifier

#splitting
X_train,Y_train,X_test,Y_test = tts(transformed_X,y, test_size = 0.2)

#model fitting
model = RandomForestClassifier()
model.fit(X_train,Y_train)

#model score
blsc = model.score(X_test,Y_test)
print(f&#39;Baseline Model Score is : {blsc}&#39;)

-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell在[416]中，第 13 行
11 #modelling
12 model = RandomForestClassifier()
---&gt; 13 model.fit(X_train,Y_train)
15 #模型得分
16 blsc = model.score(X_test,Y_test)

文件 G:\Md Jaffer\UDEMY\Machine Learning Course ZTM\Projects\HeartDesease_Classification\env\Lib\site-packages\sklearn\base.py:1474，在 _fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(estimator, *args, **kwargs)
1467 estimator._validate_params()
1469 使用 config_context(
1470 skip_parameter_validation=(
1471 prefer_skip_nested_validation 或 global_skip_validation
1472 )
1473 ):
-&gt; 1474 返回 fit_method(estimator, *args, **kwargs)

文件 G:\Md Jaffer\UDEMY\Machine Learning Course ZTM\Projects\HeartDesease_Classification\env\Lib\site-packages\sklearn\ensemble\_forest.py:361，位于 BaseForest.fit(self, X, y, sample_weight)
359 # 验证或转换输入数据
360 if issparse(y):
--&gt; 361 引发 ValueError(&quot;不支持 y 的稀疏多标签指标。&quot;)
363 X, y = self._validate_data(
364 X,
365 y,
(...)
369 force_all_finite=False,
370 )
371 # _compute_missing_values_in_feature_mask 检查 X 是否有缺失值，
372 # 如果底层树基础估计器无法处理缺失值，则会引发错误。
373 # 仅需标准即可确定树是否支持
374 # 缺失值。

ValueError: 不支持 y 的稀疏多标签指标。

我尝试设置 sparse_output=False，但结果显示样本数量不一致。标签编码后的实际形状为 (1480 x 36)
---------------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[444]，第 13 行
11 #modelling
12 model = RandomForestClassifier()
---&gt; 13 model.fit(X_train,Y_train)
15 #model score
16 blsc = model.score(X_test,Y_test)

ValueError：发现输入变量的样本数量不一致：[1184, 296]
]]></description>
      <guid>https://stackoverflow.com/questions/78795297/valueerror-sparse-multilabel-indicator-for-y-is-not-supported-how-to-handle-m</guid>
      <pubDate>Thu, 25 Jul 2024 20:21:08 GMT</pubDate>
    </item>
    <item>
      <title>修剪错误无法将“torch.cuda.FloatTensor”分配给参数</title>
      <link>https://stackoverflow.com/questions/78795181/pruning-error-cannot-assign-torch-cuda-floattensor-to-parameter</link>
      <description><![CDATA[我很难弄清楚为什么在尝试将彩票假设应用于我的模型时会出现此错误。显然，这是在修剪回调期间发生的，它似乎试图将之前的权重保存为参数，但保存的是 FloatTensor 的值。我不知道该怎么办。
 文件 &quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/pytorch_lightning/callbacks/pruning.py&quot;, 第 340 行, 在 apply_pruning 中 
self._apply_local_pruning(amount)
文件 &quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/pytorch_lightning/callbacks/pruning.py&quot;, 第 311 行, 在 _apply_local_pruning 中 
self.pruning_fn(module, name=name, amount=amount)
文件&quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/torch/nn/utils/prune.py&quot;，第 909 行，在 l1_unstructured 中 
L1Unstructured.apply(
文件 &quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/torch/nn/utils/prune.py&quot;，第 545 行，在 apply 中 
return super().apply(
文件 &quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/torch/nn/utils/prune.py&quot;，第 163 行，在 apply 中 
module.register_parameter(name + &quot;_orig&quot;, orig)
文件 &quot;/uufs/chpc.utah.edu/common/home/u0977428/.micromamba/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;，第 583 行，在 register_parameter 中 
raise TypeError(f&quot;无法将 &#39;{torch.typename(param)}&#39; 对象分配给参数 &#39;{name}&#39; &quot;
TypeError: 无法将 &#39;torch.cuda.FloatTensor&#39; 对象分配给参数 &#39;weight_orig&#39;（需要 torch.nn.Parameter 或 None）

def main(config, ...):
model = UNetLightning(
...
)

trainer_args = {
&quot;max_epochs&quot;: config.epochs,
&quot;precision&quot;: config.precision,
&quot;accelerator&quot;: config.accelerator,
&quot;callbacks&quot;: [],
&quot;gradient_clip_val&quot;: 1.0,
&quot;accumulate_grad_batches&quot;: 3,
}
initial_state = model.state_dict() # 保存初始状态以进行修剪
pruning_passes = 3 # 要进行的修剪次数

for i in range(pruning_passes):
print(f&quot;Pruning iteration {i + 1}/{pruning_passes}&quot;)

# 使用修剪回调初始化训练器
pruning_callback = ModelPruning(
&quot;l1_unstructured&quot;,
amount=0.2,
verbose=True,
use_global_unstructured=False
)

# 在将模型移至 GPU 之前应用修剪
model.cpu()
pruning_callback.on_fit_start(trainer=None, pl_module=model)

trainer_args[&quot;callbacks&quot;].append(pruning_callback)
trainer = Trainer(**trainer_args)

# 训练模型
trainer.fit(model, data_module)

# 删除下一次迭代的修剪回调
trainer_args[&quot;callbacks&quot;].remove(pruning_callback)

# 将模型重置为初始权重
model.load_state_dict(initial_state)

# 不进行修剪的最终训练传递以微调模型
trainer_args[&quot;callbacks&quot;].append(checkpoint_cb) # 微调后保存最佳模型
trainer = Trainer(**trainer_args)
trainer.fit(model, data_module)

# 保存最终模型
torch.save(model.state_dict(), &#39;final_pruned_model.pth&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78795181/pruning-error-cannot-assign-torch-cuda-floattensor-to-parameter</guid>
      <pubDate>Thu, 25 Jul 2024 19:42:41 GMT</pubDate>
    </item>
    <item>
      <title>我在训练随机森林回归器时不断遇到这个问题</title>
      <link>https://stackoverflow.com/questions/78795096/i-keep-encountering-this-problem-training-a-random-forest-regressor</link>
      <description><![CDATA[/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning：X 有特征名称，但 RandomForestRegressor 在没有特征名称的情况下安装
warnings.warn(
我尝试添加 .values，但它仍然标记错误。]]></description>
      <guid>https://stackoverflow.com/questions/78795096/i-keep-encountering-this-problem-training-a-random-forest-regressor</guid>
      <pubDate>Thu, 25 Jul 2024 19:18:50 GMT</pubDate>
    </item>
    <item>
      <title>hmmlearn 中的隐马尔可夫模型不收敛</title>
      <link>https://stackoverflow.com/questions/78791079/hidden-markov-model-in-hmmlearn-not-converging</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78791079/hidden-markov-model-in-hmmlearn-not-converging</guid>
      <pubDate>Thu, 25 Jul 2024 00:56:12 GMT</pubDate>
    </item>
    <item>
      <title>安装 tf-models-official 时出现元数据生成失败</title>
      <link>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</link>
      <description><![CDATA[我尝试使用 !pip install tf-models-official 安装 tf-models-official，当它开始收集 kaggle&gt;=1.3.9 时，它返回以下错误：
收集 kaggle&gt;=1.3.9（来自 tf-models-official）
使用缓存的 kaggle-1.6.15.tar.gz (9.1 kB)
安装构建依赖项...完成
获取构建 wheel 的要求...完成
准备元数据（pyproject.toml）...错误
错误：子进程退出并出现错误

× 准备元数据（pyproject.toml）未成功运行。
│ 退出代码：1
╰─&gt; [35 行输出]
回溯（最近一次调用）：
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 353 行，位于 &lt;module&gt;
main()
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 335 行，在 main 中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 152 行，在 prepare_metadata_for_build_wheel 中
whl_basename = backend.build_wheel(metadata_directory, config_settings)
文件&quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/build.py&quot;，第 58 行，在 build_wheel 中
return os.path.basename(next(builder.build(directory=wheel_directory,versions=[&#39;standard&#39;])))
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;，第 155 行，在 build 中
artifact = version_api[version](directory,**build_data)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 475 行，在build_standard
for included_file in self.recurse_included_files():
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 176, in recurse_included_files
Yield from self.recurse_selected_project_files()
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 180, in recurse_selected_project_files
if self.config.only_include:
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/config.py&quot;，第 806 行，在 only_include 中
only_include = only_include_config.get(&#39;only-include&#39;, self.default_only_include()) 或 self.packages
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 260 行，在 default_only_include 中
return self.default_file_selection_options.only_include
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/functools.py&quot;，第 981 行，在__get__
val = self.func(instance)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 248 行，位于 default_file_selection_options
raise ValueError(message)
ValueError：无法使用以下启发式方法确定要将哪些文件发送到 wheel 内：https://hatch.py​​pa.io/latest/plugins/builder/wheel/#default-file-selection

最可能的原因是没有与您的项目 (kaggle) 名称匹配的目录。

必须在 `tool.hatch.build.targets.wheel` 表中定义至少一个文件选择选项，请参阅：https://hatch.py​​pa.io/latest/config/build/

例如，如果您打算发送一个名为 `foo` 的目录，该目录位于项目根目录的 `src` 目录中，则可以定义以下内容：

[tool.hatch.build.targets.wheel]
packages = [&quot;src/foo&quot;]
[输出结束]

注意：此错误源自子进程，可能不是 pip 的问题。
错误：metadata-generation-failed

× 生成包元数据时遇到错误。
╰─&gt; 请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip。
提示：请参阅上文了解详情。

我能够在 2 周前安装，现在在新的 jupyter 笔记本内核上突然无法安装。我尝试在旧内核上重新安装，也出现了同样的错误。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</guid>
      <pubDate>Wed, 24 Jul 2024 07:02:59 GMT</pubDate>
    </item>
    <item>
      <title>没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块</title>
      <link>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</link>
      <description><![CDATA[代码下方
import numpy as np
np.random.seed(0)
from sklearn import datasets
import matplotlib.pyplot as plt
%matplotlib inline
%config InlineBackend.figure_format =&#39;retina&#39;

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD

错误消息下方
-------------------------------------------------------------------------------
ModuleNotFoundError Traceback (most recent call last)
~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
2 try:
----&gt; 3 from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
4 except ImportError:

ModuleNotFoundError: 没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块

在处理上述异常期间，发生了另一个异常：

ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-5-943507dd87a6&gt; in &lt;module&gt;
6 get_ipython().run_line_magic(&#39;config&#39;, &quot;InlineBackend.figure_format =&#39;retina&#39;&quot;)
7 
----&gt; 8 从 keras.models 导入 Sequential
9 从 keras.layers 导入 Dense
10 从 keras.optimizers 导入 SGD

~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
4 except ImportError:
5 raise ImportError(
----&gt; 6 &#39;Keras 需要 TensorFlow 2.2 或更高版本。&#39;
7 &#39;通过 `pip install tensorflow`&#39; 安装 TensorFlow)
8 

ImportError: Keras 需要 TensorFlow 2.2 或更高版本。通过 `pip install tensorflow` 安装 TensorFlow

注意：`我认为，主要问题是 Tensorflow 版本。我使用了一些命令，如下所示，
conda create -n tf tensorflow
conda activate tf

我还使用了以下命令
conda create -n tf-gpu tensorflow-gpu
conda activate tf-gpu

但是它不起作用，请帮助解决错误。]]></description>
      <guid>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</guid>
      <pubDate>Sun, 23 Aug 2020 02:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 通过最近邻算法对数据进行分类？</title>
      <link>https://stackoverflow.com/questions/7326958/how-can-i-classify-data-with-the-nearest-neighbor-algorithm-using-python</link>
      <description><![CDATA[我需要使用（我希望）最近邻算法对一些数据进行分类。我在 Google 上搜索了这个问题，找到了很多库（包括 PyML、mlPy 和 Orange），但我不知道从哪里开始。
我应该如何使用 Python 实现 k-NN？]]></description>
      <guid>https://stackoverflow.com/questions/7326958/how-can-i-classify-data-with-the-nearest-neighbor-algorithm-using-python</guid>
      <pubDate>Tue, 06 Sep 2011 22:35:58 GMT</pubDate>
    </item>
    </channel>
</rss>