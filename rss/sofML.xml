<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 20 Aug 2024 15:16:47 GMT</lastBuildDate>
    <item>
      <title>如何使用多层感知器对 FFT 数据进行预处理以进行二元分类？</title>
      <link>https://stackoverflow.com/questions/78892290/how-can-fft-data-be-pre-processed-for-binary-classification-using-multi-layer-pe</link>
      <description><![CDATA[我有 410 个 FFT 样本，我打算将它们输入到 MLP 中，以将数据分为两个（二进制）类别。我使用 PyTorch 在 Python 中构建了一个神经网络，该网络尝试使用这些数据进行训练。但是，我获得的验证准确率仅达到 70%。
更改 MLP 的模型参数对最终准确率几乎没有影响，这让我相信问题出在初始数据处理上，尽管我可能是错的。
进一步研究这个问题后，我知道需要对数据进行预处理，以使其更易于训练，但我不明白如何预处理 FFT 数据。到目前为止，我已经根据最小值/最大值进行了标准化，并将数据设为零中心。
我查看了此处的帖子，但我的问题仍然存在。
编辑：
添加了 FFT 图像和代码片段
FFT 图像
model = nn.Sequential(OrderedDict([
(&#39;drop1&#39;, nn.Dropout(0.1)),
(&#39;dense1&#39;, nn.Linear(410, 100)),
(&#39;act1&#39;, nn.LeakyReLU()),
# (&#39;drop2&#39;, nn.Dropout(0.1)),
(&#39;drop4&#39;, nn.Dropout(0.2)),
(&#39;dense2&#39;, nn.Linear(100,25)),
(&#39;act2&#39;, nn.Sigmoid()),
(&#39;dense4&#39;, nn.Linear(25, 5)),
(&#39;act4&#39;, nn.LeakyReLU()),
(&#39;dense8&#39;, nn.Linear(5, 1)),
(&#39;act5&#39;, nn.Tanh()),
(&#39;dense5&#39;, nn.Linear(1, 1)),
(&#39;act8&#39;, nn.Sigmoid()),
]))
]]></description>
      <guid>https://stackoverflow.com/questions/78892290/how-can-fft-data-be-pre-processed-for-binary-classification-using-multi-layer-pe</guid>
      <pubDate>Tue, 20 Aug 2024 11:53:33 GMT</pubDate>
    </item>
    <item>
      <title>Yolop 输出在 SNPE android 上给出 NaN 值</title>
      <link>https://stackoverflow.com/questions/78892125/yolop-output-giving-nan-values-on-snpe-android</link>
      <description><![CDATA[我使用了 YOLOP 模型，并使用 SNPE SDK 将其转换为 dlc 文件。创建输入张量并构建网络。获取输出张量值给出 NaN 值列表。下面给出了我如何配置网络、传递输入张量。但我的变量 laneLineSeg 和 DetOutValues 是 NaN 值。任何人都可以帮助我。
这是我配置网络、传递输入张量的方式。但我的变量 laneLineSeg、DrivAreaSegValues 和 DetOutValues 是 NaN 值。任何人都可以帮助我。
private val modelName = &quot;yolop_seg.dlc&quot;
private fun configureNetwork(): NeuralNetwork? {
返回尝试 {

val assetInputStream = applicationContext.assets.open(modelName)
val network = SNPE.NeuralNetworkBuilder(application)
.setDebugEnabled(false)
.setRuntimeOrder(NeuralNetwork.Runtime.GPU_FLOAT16)
.setModel(assetInputStream, assetInputStream.available())
.setCpuFallbackEnabled(true)
.setUseUserSuppliedBuffers(false)
.setUnsignedPD(false)
.setCpuFixedPointMode(false)
.setOutputLayers(&quot;Sigmoid_1671&quot;,&quot;Concat_1534&quot;, &quot;Sigmoid_1808&quot; )

.build()
assetInputStream.close()
network
} catch (e: Exception) {
Log.e(&lt;NETWORK&gt;, e.message.toString())
null
}
}
private fun getClassificationResult(network: NeuralNetwork, bitmap: Bitmap): FloatArray{
val image = Bitmap.createScaledBitmap(bitmap, 640, 640, true)

val inputMap: MutableMap&lt;String, FloatTensor&gt; = HashMap()
val inputNames: Set&lt;String&gt; = network.inputTensorsNames
val outputNames: Set&lt;String&gt; = network.outputTensorsNames
var mInputLayer = &quot;&quot;
val mOutputLayer = &quot;&quot;
mInputLayer = inputNames.iterator().next()

val tensor = network.createFloatTensor(1, 640, 640,3)
val dimension = tensor.shape
val isGrayScale = (dimension[dimension.size - 1] == 1)

val input: FloatArray = if (!isGrayScale) {
loadRgbBitmapAsFloat(image)
} else {
loadGrayScaleBitmapAsFloat(image)
}
tensor.write(input, 0, input.size)
输入映射[mInputLayer] = tensor
val 输出映射 = network.execute(inputsMap)

val driveAreaSeg = outputMap[&quot;drive_area_seg&quot;]
val DrivAreaSegValues = FloatArray(driveAreaSeg!!.size)
driveAreaSeg.read(DrivAreaSegValues, 0, DrivAreaSegValues.size)
val i = 0

val laneLineSeg = outputMap[&quot;lane_line_seg&quot;]
val LanLinSegValues = FloatArray(laneLineSeg!!.size)
laneLineSeg.read(LanLinSegValues, 0, LanLinSegValues.size)

val detOut = outputMap.get(&quot;det_out&quot;)
val DetOutValues = FloatArray(detOut!!.size)
detOut.read(DetOutValues, 0, DetOutValues.size)

return laneLineSeg

]]></description>
      <guid>https://stackoverflow.com/questions/78892125/yolop-output-giving-nan-values-on-snpe-android</guid>
      <pubDate>Tue, 20 Aug 2024 11:13:13 GMT</pubDate>
    </item>
    <item>
      <title>加载神经网络的部分权重</title>
      <link>https://stackoverflow.com/questions/78891901/loading-partial-weights-of-a-neural-network</link>
      <description><![CDATA[我正在开展一个深度学习项目，在这个项目中，我将在预先训练好的 Wide ResNet 上添加几个线性层，然后添加我正在使用的另一种技术。
我的问题是，如果我构建网络，将我正在使用的层和技术作为 ModuleList 添加到广义 resnet，那么我会将预先训练的权重加载到整个模型上，并添加这些权重。这是否会在加载过程中引发错误？
或者它是否知道它应该只部分加载权重（即仅在重置时）。
示例代码：
model = get_model(backbone) # 加载 ResNet
model = ConstructNewModel(model) # 添加层
load_weights(model, pretrained_pa​​th) # 加载 ResNet 权重
model = model.to(&quot;cuda&quot;) # 添加到 GPU

或者它应该看起来更像这样？
model = get_model(backbone) # 加载 ResNet
load_weights(model, pretrained_pa​​th) # 加载 ResNet 权重
model = ConstructNewModel(model) # 添加层
model = model.to(&quot;cuda&quot;) # 添加到GPU

换句话说，如何使用 torch.load 加载 PyTorch 中的权重？]]></description>
      <guid>https://stackoverflow.com/questions/78891901/loading-partial-weights-of-a-neural-network</guid>
      <pubDate>Tue, 20 Aug 2024 10:26:32 GMT</pubDate>
    </item>
    <item>
      <title>开发一个系统来识别不同分类网站上列出的同一辆车[关闭]</title>
      <link>https://stackoverflow.com/questions/78891607/developing-a-system-to-identify-the-same-car-listed-on-different-classified-site</link>
      <description><![CDATA[我们正在开展一个项目，我需要确定同一辆车是否在不同的平台上出售，例如 Mobile.de 或 AutoScout24。主要的挑战是 VIN 号通常不会在列表中披露，这使得直接比较列表变得困难。
最初，我考虑使用图像哈希来匹配列表，但如果图像不是唯一的或来自公共域，这种方法可能会导致错误。
以下是我正在考虑的一些方法：

分析列表中的元数据和文本数据。
使用计算机视觉算法分析图像。
开发或应用神经网络来匹配组合数据（文本、图像、元数据）。

我很想听听您对这个问题的潜在解决方案的想法，或者您遇到类似问题的经验。您会推荐哪些方法或技术来实施这个系统？是否有特定的工具或库可以帮助解决此任务？
感谢您的任何建议或意见！]]></description>
      <guid>https://stackoverflow.com/questions/78891607/developing-a-system-to-identify-the-same-car-listed-on-different-classified-site</guid>
      <pubDate>Tue, 20 Aug 2024 09:24:27 GMT</pubDate>
    </item>
    <item>
      <title>为了简化在 Jupyter Notebook 中加载数据集的过程，您可以直接从本地设备上传文件[关闭]</title>
      <link>https://stackoverflow.com/questions/78891329/to-simplify-the-process-of-loading-a-dataset-in-jupyter-notebook-you-can-upload</link>
      <description><![CDATA[从 google.colab 导入文件
从 google.colab 导入 auth
uploaded = files.upload()
for fn in uploaded.keys():
print(&#39;用户上传文件“{name}”，长度为 {length} 字节&#39;.format(
name=fn, length=len(uploaded[fn])))


让机器学习工程师和数据科学家的生活更轻松。]]></description>
      <guid>https://stackoverflow.com/questions/78891329/to-simplify-the-process-of-loading-a-dataset-in-jupyter-notebook-you-can-upload</guid>
      <pubDate>Tue, 20 Aug 2024 08:20:24 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的 GAN [关闭]</title>
      <link>https://stackoverflow.com/questions/78891155/gans-in-deeplearning</link>
      <description><![CDATA[最初，我使用 pix2pixGAN 将 256x256 大小的图像作为模型的输入，并且产生了良好的结果。但是，当我使用相同的模型更改为 1000x1000 大小的图像并应用一些数据增强技术时，结果并不理想。我使用 U-Net 作为生成器，使用 Patch Gan 作为鉴别器。请给我一些关于如何从 1000x1000 图像中获得良好输出的建议。
我想要一些技术来改进模型输出，当我将图像大小从 256X256 更改为 1000X1000 图像时，可以更新哪些功能。]]></description>
      <guid>https://stackoverflow.com/questions/78891155/gans-in-deeplearning</guid>
      <pubDate>Tue, 20 Aug 2024 07:36:37 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 sklearn python 获取预测</title>
      <link>https://stackoverflow.com/questions/78890391/how-use-sklearn-python-get-predicion</link>
      <description><![CDATA[我有一张表，我想传递 features = &quot;train_1, train_2, train_3, train_4&quot; 和 target_result = result_cor。
我想知道什么时候值是 = &quot;1 或 2&quot;在我的预测中：
关注我的数据
关注我的代码：
从 enum 导入 auto
从 sklearn.svm 导入 LinearSVC
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 accuracy_score
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.metrics 导入 classes_report
从 sklearn 导入 svm
从 sklearn.linear_model 导入 LogisticRegression
导入 pandas 作为 pd
导入 numpy 作为 np
导入 matplotlib.pyplot 作为 plt
导入 math
导入 seaborn 作为 sns

sheet_id = &#39;1CfnVwuqysTYNPKLVhgjJ44Af8VDcdN1l&#39; dados = pd.read_excel(f&#39;https://docs.google.com/spreadsheets/export?id={sheet_id}&amp;format=xlsx&#39;) bads.head() # 实现更多数量的数据 x = bados[[&#39;train_1&#39;,&#39;train _2&#39;,&#39;train_3&#39;,&#39;train_4&#39;]] # Gabarito 或 corretos y = bados[[&#39;result_cor&#39;]] # 将 x e y e testes de x e y 分开 treino_x, teste_x, treino_y, teste_y = train_test_split(x,y,test_size=0.33) # 模型类型 modelo = DecisionTreeClassifier() # 训练效果 modelo.fit(x,np.ravel(y,order=&quot;c&quot;)) # 预测新值 model_predict = [0,1,0,1] treino_x[:1] = model_predict model_predict = treino_x[:1] result_cor = [1] treino_y[:1] = result_cor result_cor = treino_y[:1] # 预测新模型 previsoes = modelo.predict(model_predict) # 检查准确率 precision = precision_score(result_cor,previsoes) * 100 print(f&#39;A acuracia é: {round(accuracy,2)}&#39;)


但结果始终为 100.0 % 或 0.0。我需要知道我的 result_cor 出现在模型训练模型的 model_predict 中的次数百分比
请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/78890391/how-use-sklearn-python-get-predicion</guid>
      <pubDate>Tue, 20 Aug 2024 02:18:19 GMT</pubDate>
    </item>
    <item>
      <title>Kornia 中的 ImageRegistrator 翻译结果不正确</title>
      <link>https://stackoverflow.com/questions/78887294/incorrect-translation-results-with-imageregistrator-in-kornia</link>
      <description><![CDATA[当我尝试使用翻译注册两个帧时，我在 Kornia 中的 ImageRegistrator 中遇到了问题。该函数始终返回错误的翻译值，即使是对于基本的合成测试用例也是如此。下面是我用来测试翻译注册的代码。有人能指导我正确的方法吗？

复制步骤
import numpy as np
import torch
import kornia as K
import kornia.geometry as KG
import cv2
import matplotlib.pyplot as plt
from typing import Tuple

def find_frame_translation_kornia(frame_1: np.ndarray, frame_2: np.ndarray) -&gt; Tuple[Tuple[float, float], np.ndarray, bool]:
“使用 Kornia 的 ImageRegistrator 查找两个帧之间的转换。”“”

frame_1 = K.image_to_tensor(frame_1, False).float() / 255.0 # 形状：(C, H, W)
frame_2 = K.image_to_tensor(frame_2, False).float() / 255.0 # 形状：(C, H, W)

if frame_1.ndim == 3:
frame_1 = frame_1.unsqueeze(0) # 形状：(1, C, H, W)
if frame_2.ndim == 3:
frame_2 = frame_2.unsqueeze(0) # 形状：(1, C, H, W)

registrator = KG.ImageRegistrator(&quot;translation&quot;) # 对于&quot;similarity&quot;、&quot;homography&quot;等，结果相同。

try:
model = registrator.register(frame_1, frame_2)
tx, ty = model[0, :2, 2].cpu().detach().numpy()

shift = (tx, ty)
M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)

success = True

except Exception as e:
print(f&quot;注册失败：{e}&quot;)
shift, M, success = (0, 0), np.eye(3, dtype=np.float32)[:2, :], False

return shift, M, success

def create_translated_image(image: np.ndarray, tx: int, ty: int) -&gt; np.ndarray:
rows, cols = image.shape
M = np.float32([[1, 0, tx], [0, 1, ty]])
classified_image = cv2.warpAffine(image, M, (cols, rows))
return classified_image

def test_find_frame_translation_kornia():
image = np.zeros((100, 100), dtype=np.uint8)
image[30:70, 30:70] = 255 # 中心的白色方块

tx, ty = 5, -3
classified_image = create_translated_image(image, tx, ty)

plt.subplot(1, 2, 1)
plt.imshow(image, cmap=&#39;gray&#39;)
plt.title(&quot;Original Image&quot;)
plt.subplot(1, 2, 2)
plt.imshow(translated_image, cmap=&#39;gray&#39;)
plt.title(&quot;翻译后的图像&quot;)
plt.show()

shift, M, success = find_frame_translation_kornia(image, classified_image)

断言成功, &quot;注册失败&quot;
np.testing.assert_almost_equal(shift, (tx, ty), decimal=1)
expected_M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
np.testing.assert_almost_equal(M, expected_M, decimal=1)

if __name__ == &quot;__main__&quot;:
test_find_frame_translation_kornia()

问题：
运行测试时，该函数返回明显错误的翻译值。具体来说，对于已知的翻译 (5, -3)，该函数返回 (-0.1, 0.1)。这是我收到的错误消息：
AssertionError: 
数组不几乎等于 1 个小数

元素不匹配：2 / 2 (100%)
最大绝对差异：5.09875337
最大相对差异：1.02040539
x：array([-0.1, 0.1], dtype=float32)
y：array([ 5, -3])

预期行为
该函数应正确识别原始图像和翻译后图像之间的翻译 (5, -3)。
环境

PyTorch 版本（例如 1.0）：2.4.0+cpu
操作系统（例如 Linux）： Microsoft Windows 10 Pro
您如何安装 PyTorch（conda、pip、source）：
[pip3] torch-pitch-shift==1.2.4
[pip3] torchaudio==2.3.0
[pip3] torchmetrics==1.4.0.post0
[conda] numpy 1.26.4 pypi_0 pypi
[conda] torch 2.4.0 pypi_0 pypi
您使用的构建命令（如果从源代码编译）：
Python 版本：3.9.19
CUDA/cuDNN 版本：False
GPU 型号和配置：False
任何其他相关信息：

]]></description>
      <guid>https://stackoverflow.com/questions/78887294/incorrect-translation-results-with-imageregistrator-in-kornia</guid>
      <pubDate>Mon, 19 Aug 2024 09:52:04 GMT</pubDate>
    </item>
    <item>
      <title>Val_accuracy 正在改变，有时它在补码之间交替（100％-val_acc）</title>
      <link>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</link>
      <description><![CDATA[我被分配根据我读过的一篇论文来实现一个机器学习模型。
这篇论文实现了一个用于属性分类的多任务学习模型（带标签的图像是模型输入，带标签的意思是属性注释，每幅图像有 40 个）。
它是一个多任务学习模型，因为在模型输入层和 40 个属性分支之后有一个共享的密集层，每个分支都有自己的损失函数（所有分支的二元交叉熵）和自己的 S 型激活函数（在最后一层，用于预测 40 个属性中的每一个是否存在于图像中）。
经过大量艰苦的努力，它终于开始在所有分支上返回所有 S 型函数的概率，但只有 val_accuracy 的概率是错误的：val_loss 和损失（训练损失）越来越小，acc（训练准确度）也在正常的概率值范围内，除了 val_accuracy 总是相同的值或它的补码。
例如（仅举 5 个时期为例）：
40 个分支之一的一个属性预测的准确度：
5_o_Clock_Shadow_Accuracy
0 0.823665
1 0.891178
2 0.891178
3 0.891178

同一属性的损失：
 5_o_Clock_Shadow_loss
0 0.921046
1 0.701494
2 0.913597
3 0.765397
4 0.894950

val_loss：
val_5_o_Clock_Shadow_loss
0 730232.750000
1 300412.500000
2 376215.843750
3 0.747685
4 1.607191

最后是 val_Accuracy：
val_5_o_Clock_Shadow_Accuracy
0 0.882382
1 0.117618
2 0.882382
3   0.882382 4 0.882382  我的模型： def subnet(shared_layers_output, i): att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_1&#39;)(shared_layers_output) att_branch = ReLU()(att_branch) att_branch = BatchNormal ization()(att_branch) att_branch = Dropout(0.5)(att_branch) att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_2&#39;)(att_branch) att_branch = ReLU()(att_branch) att_branch = BatchNormalization()(att_branch) att_branch = Dropout(0.5)(att_branch)

branch_output = Dense(1, name=att_list[i],activation=&#39;sigmoid&#39;)(att_branch)

return branch_output

def multi_task_model():

#输入
input_layer = Input(shape=(512,), name=&#39;input_layer&#39;)

#共享网络（1 个网络）
shared_x = Dense(512, name=&#39;shared_dense_layer&#39;)(input_layer)
shared_x = ReLU()(shared_x)
shared_x = BatchNormalization()(shared_x)
shared_x = Dropout(0.5)(shared_x)

branch_outputs = list()
for i in range(40):
branch_outputs.append(subnet(shared_x, i))

model = Model(input_layer, branch_outputs, name=&#39;model&#39;)

返回模型


训练和测试输入形状：(n_samples, 512)
训练和测试标签输入形状：(40, n_samples)
学习率：1e-03
]]></description>
      <guid>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</guid>
      <pubDate>Sun, 18 Aug 2024 18:38:14 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Jupyter Notebook 中导入 nltk</title>
      <link>https://stackoverflow.com/questions/78885044/unable-to-import-nltk-in-jupyter-notebook</link>
      <description><![CDATA[我有一个 Jupyter Notebook。我使用以下代码行安装了 ntlk：
!pip install nltk

我得到以下输出：
要求已满足：./env/lib/python3.12/site-packages 中的 nltk（3.9）
要求已满足：./env/lib/python3.12/site-packages 中的 click（来自 nltk）（8.1.7）
要求已满足：./env/lib/python3.12/site-packages 中的 joblib（来自 nltk）（1.4.0）
要求已满足：./env/lib/python3.12/site-packages 中的 regex&gt;=2021.8.3（来自 nltk）（2024.7.24）
要求已满足：tqdm ./env/lib/python3.12/site-packages（来自 nltk）

现在当我使用 nltk 导入 nltk 时
import nltk 

我收到以下错误：
LookupError Traceback（最近一次调用最后一次）
文件 ~/Desktop/machine-learning/env/lib/python3.12/site-packages/nltk/corpus/util.py:84，在 LazyCorpusLoader.__load(self) 中
83 尝试：
---&gt; 84 root = nltk.data.find(f&quot;{self.subdir}/{zip_name}&quot;)
85 except LookupError:

File ~/Desktop/machine-learning/env/lib/python3.12/site-packages/nltk/data.py:579, in find(resource_name, path)
578 resource_not_found = f&quot;\n{sep}\n{msg}\n{sep}\n&quot;
--&gt; 579 raise LookupError(resource_not_found)

LookupError: 
**************************************************************************
未找到资源 wordnet。
请使用 NLTK 下载器获取资源：

我遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78885044/unable-to-import-nltk-in-jupyter-notebook</guid>
      <pubDate>Sun, 18 Aug 2024 15:53:05 GMT</pubDate>
    </item>
    <item>
      <title>如何建立深度学习模型从 Excel 文件中提取表格数据？[关闭]</title>
      <link>https://stackoverflow.com/questions/78883203/how-to-build-a-deep-leaning-model-to-extract-tabular-data-from-excel-files</link>
      <description><![CDATA[我有数百个 Excel 文件，其中包含各种格式的金融交易（例如股票、共同基金等）。每个文件可以包含一个或多个表格，并且表格位于相对于 zerodha、groww 等不同经纪人的不同位置。
我的目标是训练一个深度学习模型，该模型可以自动识别并从任何给定的 Excel 文件中提取相关表格。
这是数据：https://drive.google.com/drive/folders/1YixwjLg2ZskRXMI5WMjns5kD1Ujfpphd?usp=sharing
与图中一样，我们在 pdf 文件中进行训练。文件，然后给出新的格式，即使格式发生变化，模型也可以精确地提供所需的数据。挑战在于在 excel 文件上执行此操作。
我尝试用表格位置的坐标和该范围内每个单元格中的数据类型注释 excel 文件，但发现它们不相关。
除了机器学习，我还尝试使用 fuzzy-wuzzy 库，这样每当经纪人更改列标题时，它都会映射到单个标题 - 例如 - “购买日期”，“入场日期”将映射到“购买日期”，但这并不能解决问题。]]></description>
      <guid>https://stackoverflow.com/questions/78883203/how-to-build-a-deep-leaning-model-to-extract-tabular-data-from-excel-files</guid>
      <pubDate>Sat, 17 Aug 2024 20:26:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不能用 C++ 构建一个没有依赖关系的神经网络，即使它可以在 Numpy 中运行？</title>
      <link>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</guid>
      <pubDate>Mon, 12 Aug 2024 16:55:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在 kaggle 中使用两个 gpu 进行 pytorch 训练？</title>
      <link>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</link>
      <description><![CDATA[我在 kaggle gpu 中训练模型。
但我发现只有一个 GPU 在工作。

我使用普通方法进行训练，例如
device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;)
model = model.to(device)

我如何使用这两个 gpu？]]></description>
      <guid>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</guid>
      <pubDate>Wed, 13 Sep 2023 04:56:24 GMT</pubDate>
    </item>
    <item>
      <title>在新类中，我收到一个 AttributeError: 无法在 <module '__main__'> 上获取属性 'ResNet1D'</title>
      <link>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</link>
      <description><![CDATA[我已使用 Google Colab 在名为 model_prep.py 的文件中成功训练了卷积神经网络模型。该模型的准确率为 92%。现在我对该模型很满意，我已使用 pyTorch 保存了我的模型。
torch.save(model, &#39;/content/drive/MyDrive/myModel.pt&#39;)

我对此的理解是，一旦模型经过完全训练，我就可以使用 pyTorch 保存训练后的模型，然后将其加载到未来的项目中以对新数据进行预测。因此，我创建了一个单独的 test.py 文件，并在其中加载了经过训练的模型，如下所示：
model = torch.load(&#39;/content/drive/MyDrive/myModel.pt&#39;)
model.eval()

但在新的 test.py 文件中，我收到一条错误消息
AttributeError: 无法在 &lt;module &#39;__main__&#39;&gt; 上获取属性 &#39;ResNet1D&#39;

虽然在与创建经过训练的模型相同的笔记本 (model_prep.py) 中加载模型时不会发生此错误。此错误仅在将模型加载到没有模型架构的单独笔记本中时发生。我该如何解决这个问题？我想将经过训练的模型加载到一个新的单独文件中以对新数据执行。有人能提出解决方案吗？
将来，我想使用 tkinter 创建一个 GUI，并部署经过训练的模型，使用 tkinter 文件中的新数据检查预测。这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</guid>
      <pubDate>Thu, 02 Sep 2021 12:33:05 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 预期为 1D 张量，但得到的是 2D 张量</title>
      <link>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</link>
      <description><![CDATA[我一直在用 Python 从头开始​​制作神经网络。输入张量的形状为 [400,3]，target_tensor 的形状为 [400]。在对权重求导时，我遇到了错误。以下是函数：
def sigmoid(z):
return 1 / (1 + torch.exp(-z))

def nueral_net(data,weights,bias):
return sigmoid( ( data @ weights ) + bias )

def loss_function(prediction,actual,m):
return (-1/m) * (torch.sum(actual * torch.log(prediction) + (1-actual) 
* torch.log(1- prediction)))

w = torch.randn(input_tensor.shape[1],1)

b = torch.randn(1,1)

predictions = nueral_net(input_tensor.float() , w, b) #应用模型
loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)

运行此程序会引发错误：
RuntimeError Traceback (most recent call last)
&lt;ipython-input-26-632338d8fd16&gt; in &lt;module&gt;
1 predictions = nueral_net(input_tensor.float() , w, b) #应用模型
2 loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
----&gt; 3 dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)
4 db = (1/400) * torch.sum(predictions - target_tensor)
5 #m = input_tensor.shape[0]

RuntimeError: 预期为 1D 张量，但得到的是 2D 和 2D 张量
]]></description>
      <guid>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</guid>
      <pubDate>Sat, 20 Mar 2021 10:32:38 GMT</pubDate>
    </item>
    </channel>
</rss>