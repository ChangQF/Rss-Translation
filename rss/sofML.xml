<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 26 Oct 2024 03:20:21 GMT</lastBuildDate>
    <item>
      <title>我需要从图像中提取每个数字</title>
      <link>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</link>
      <description><![CDATA[我正在做图像分割，其中有不同类型的数字图像，如下所示。我能够对 MNIST 合并图像执行图像分割，但该方法不适用于带有水平线的图像。在任何类型的方向和图像噪声中，分别分割每个数字的最佳方法是什么？


我正在使用此代码分割图像中的每个数字，尤其是从数字写在水平线之间的噪声图像中
import os
import cv2
import matplotlib.pyplot as plt

# 加载图像
# image_path = &#39;/mnt/data/013.png&#39;
image_path = &#39;/content/drive/My Drive/demo/captcha/samples/010.png&#39;
image = cv2.imread(image_path)

# 转换为灰度
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊以减少噪音
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# 应用二元阈值
_, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# 在阈值图像中查找轮廓
contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 创建原始图像的副本以绘制轮廓
output_image = image.copy()

# 按大小过滤轮廓（以去除噪音）
digit_contours = [c for c in contours if cv2.contourArea(c) &gt; 50]

# 绘制轮廓（可选可视化）
cv2.drawContours(output_image, digit_contours, -1, (0, 255, 0), 2)

# 创建一个列表来存储单个数字图像
digit_images = []

# 从原始图像中提取每个数字
for i, contour in enumerate(digit_contours):
x, y, w, h = cv2.boundingRect(contour)
digit = gray[y:y+h, x:x+w]
digit_images.append(digit)
# 使用子图单独显示每个数字
plt.subplot(1, len(digit_contours), i + 1) # 为每个数字创建子图
plt.imshow(digit, cmap=&#39;gray&#39;) # 以灰度显示当前数字
plt.axis(&#39;off&#39;) # 关闭轴标签

# 可选将每个数字保存为单独的图像
cv2.imwrite(f&quot;digit_{x}.png&quot;, digit)

# 显示带有单独数字显示的结果
plt.figure(figsize=(10, 6))
plt.imshow(output_image)
plt.title(&quot;Extracted Digits&quot;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</guid>
      <pubDate>Fri, 25 Oct 2024 21:50:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的损失太多[关闭]</title>
      <link>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</link>
      <description><![CDATA[我正在训练一个预测加密货币价格的神经网络，但数据丢失太大，代码如下：
import numpy as np
import tensorflow as tf
from tensorflow.keras import layer, models,Sequential,Model,Input
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import *
import matplotlib.pyplot as plt
import ccxt
import pandas as pd
import request
import json
import datetime as dt
import time

# Определение входов
input1 = Input(shape=(100, 1))
input2 = Input(shape=(100, 1))

# 用 LSTM 构建机器学习模型已保存
lstm1 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input1)
lstm1 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm1)
lstm1 = layer.LSTM(units=64,activation=&#39;linear&#39;)(lstm1)
lstm1 = layer.Dropout(0.2)(lstm1)

lstm2 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input2)
lstm2 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm2)
lstm2 = layer.LSTM(units=64,激活 = &#39;线性&#39;）（lstm2）lstm2 = groups.Dropout（0.2）（lstm2）＃ Объединяем все LSTM выходы merged = groups.concatenate（[lstm1, lstm2]）＃Добавляем Dense слой для объединенного вы хода 输出 = 层.Dense(100, 激活=&#39;线性&#39;)(合并) # Создание и компиляция модели 模型 = 模型(输入=[输入1, 输入2], 输出=输出) 优化器 = Adam(learning_rate=0.000005) model.compile(loss=&#39;mse&#39;, 优化器=优化器) df = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcdata15m.csv&quot;, sep =&quot;\t&quot;)

list_of_close = df[&#39;Open&#39;].to_list()
print(len(list_of_close))

df1 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcoi15m.csv&quot;, sep =&quot;\t&quot;)
list_of_oi = df1[&#39;openInterest&#39;].to_list()
print(len(list_of_oi))

df3 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/y.csv&quot;, sep =&quot;\t&quot;)
y = df3[&#39;Close&#39;].to_list()
print(len(y))
x1 = np.array(list_of_close).reshape(100,100)
x2 = np.array(list_of_oi).reshape(100,100)

min_max_scaler = MinMaxScaler()
x1 = min_max_scaler.fit_transform(x1)
x2 = min_max_scaler.fit_transform(x2)

x1 = x1.astype(float)
x2 = x2.astype(float)

y = np.array(y).reshape(100,100).astype(float)

# 改进模型
history = model.fit([x1,x2], y,batch_size=64, epochs=100)

上次亏损为：3848644352.0000
我的数据集包含 10,000 个收盘蜡烛和 10,000 个未平仓合约值
我如何才能将损失降到最低？]]></description>
      <guid>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</guid>
      <pubDate>Fri, 25 Oct 2024 17:19:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么 train_batch*.jpg 中缺少一些边界框/标签？这些图像是由 YOLOv7 在训练时自动生成的</title>
      <link>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</link>
      <description><![CDATA[我正在自定义数据集上训练 YOLOv7 模型。虽然我的召回率超过 0.9，但精度低于 0.1。为了调查这个问题，我检查了训练脚本生成的 train_batch*.jpg 拼贴画，发现有些图像包含没有任何相关标签或边界框的对象。
我尝试解析图像和标签列表。所有图像都有一个带有适当注释的相应 txt 文件。
这是正常现象吗？如果不是，如何解决这个问题？
https://github.com/WongKinYiu/yolov7/]]></description>
      <guid>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</guid>
      <pubDate>Fri, 25 Oct 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有快速的方法可以提高物体检测模型的置信度？[关闭]</title>
      <link>https://stackoverflow.com/questions/79126036/is-there-a-fast-way-to-raise-the-confidence-levels-of-an-object-detection-model</link>
      <description><![CDATA[我目前正在构建一个对象检测模型，用于识别冰箱图片中的食品成分。我使用 Google Colab 来编码和训练我的模型，并使用 RESNET-50 的架构。我删除了现有的类别，并使用 Google Colab 最好的 GPU 在包含约 6,000 张图像（已注释，70% 为训练，15% 为有效，15% 为测试）的数据集上对其进行训练。训练后，我的模型似乎仍然没有学到任何东西。取得如此糟糕的结果是否正常，或者是否有方法可以更快地进行训练并获得更好的结果？我听说过 Google Cloud，但我不知道它是否会有所作为。我是否遗漏了一些隐藏参数？
这是我编写所有内容的 Google-Colab Notebook：https://colab.research.google.com/drive/1m4zbNE8-qVUkep-37Mz2S3URvELdGWX6?usp=sharing
为了训练我的模型，我使用了 pytorch_lightning 的 Trainer。然而，训练需要很长时间，即使经过 30 个时期的训练，当预测正确时（通常情况并非如此），未见数据的置信度仍然低于 5%。
编辑：目前，我正在使用一个新的、更定性的数据集，其中包含 20k 张图像，分为 68 个类别。我没有对模型进行足够的测试，因为我发现预测太低了，如果你看看笔记本，你会发现我必须设置 CONFIDENCE_THRESHOLD_2 = 0.03 才能获得任何结果，但我认为这是由于训练不足造成的。]]></description>
      <guid>https://stackoverflow.com/questions/79126036/is-there-a-fast-way-to-raise-the-confidence-levels-of-an-object-detection-model</guid>
      <pubDate>Fri, 25 Oct 2024 14:02:24 GMT</pubDate>
    </item>
    <item>
      <title>在 Accord.NET 中使用隔离森林进行异常检测的问题：缺少命名空间</title>
      <link>https://stackoverflow.com/questions/79125178/issue-with-using-isolation-forest-for-anomaly-detection-in-accord-net-missing-n</link>
      <description><![CDATA[在此处输入图片描述
我尝试使用 Accord.NET 库（特别是使用 Isolation Forest 算法）在我的 C# 应用程序中实现异常检测。但是，我遇到一个错误，指示 Accord.MachineLearning.AnomalyDetection 命名空间不存在。
\&lt;PackageReference Include=&quot;Accord.MachineLearning&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;Accord.Math&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;Accord.Statistics&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;CsvHelper&quot; Version=&quot;33.0.1&quot; /\&gt;

CS0234：类型或命名空间名称“AnomalyDetection”在命名空间“Accord.MachineLearning”中不存在（您是否缺少程序集引用？）

using CsvHelper;
using Microsoft.AspNetCore.Http;
using Microsoft.AspNetCore.Mvc;
using System.Collections.Generic;
using System.Globalization;
using System.IO;
using System.Linq;
using CVAnomalyDetection.Models;

public class HomeController : Controller
{
private List&lt;CsvData&gt; _csvData;

public IActionResult Index()
{
return View();
}

[HttpPost]
public IActionResult Upload(IFormFile file)
{
if (file != null &amp;&amp; file.Length &gt; 0)
{
using (var reader = new StreamReader(file.OpenReadStream()))
using (var csv = new CsvReader(reader, CultureInfo.InvariantCulture))
{
_csvData = csv.GetRecords&lt;CsvData&gt;().ToList();
}
return View(&quot;Index&quot;, _csvData);
}
return RedirectToAction(&quot;Index&quot;);
}

[HttpPost]
public IActionResult Predict()
{
var anomalies = DetectAnomalies(_csvData);
return View(&quot;AnomalyResults&quot;, anomalies);
}

private List&lt;CsvData&gt; DetectAnomalies(List&lt;CsvData&gt; data)
{
// 独热编码分类列
var uniqueValuesProductCategory = data.Select(x =&gt; x.ProductCategory).Distinct().ToList();
var uniqueValuesCustomerRegion = data.Select(x =&gt; x.CustomerRegion).Distinct().ToList();
var uniqueValuesPaymentMethod = data.Select(x =&gt; x.PaymentMethod).Distinct().ToList();

// 创建用于异常检测的输入数据数组
var combinedData = new List&lt;double[]&gt;();

foreach (var item in data)
{
var features = new List&lt;double&gt;();

// ProductCategory 的独热编码
foreach (var value in uniqueValuesProductCategory)
{
features.Add(value == item.ProductCategory ? 1.0 : 0.0);
}

// CustomerRegion 的独热编码
foreach (var value in uniqueValuesCustomerRegion)
{
features.Add(value == item.CustomerRegion ? 1.0 : 0.0);
}

// PaymentMethod 的独热编码
foreach (var value in uniqueValuesPaymentMethod)
{
features.Add(value == item.PaymentMethod ? 1.0 : 0.0);
}

combinedData.Add(features.ToArray());
}

// 初始化隔离森林
varisolationForest = new Accord.MachineLearning.IsolationForest()
{
NumberOfTrees = 100,
Contamination = 0.05 // 根据需要进行调整
};

// 使用组合数据训练隔离森林模型
isolationForest.Learn(combinedData.ToArray());

// 预测异常
var predictions =isolationForest.Decide(combinedData.ToArray());

// 查找并返回实际的异常记录
return data.Where((d, index) =&gt; predictions[index] == -1).ToList(); // -1 表示异常
}

private double EuclideanDistance(double[] a, double[] b)
{
return Math.Sqrt(a.Zip(b, (x, y) =&gt; Math.Pow(x - y, 2)).Sum());
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79125178/issue-with-using-isolation-forest-for-anomaly-detection-in-accord-net-missing-n</guid>
      <pubDate>Fri, 25 Oct 2024 10:02:00 GMT</pubDate>
    </item>
    <item>
      <title>我是否需要使用具有混合值的 kprototype 聚类来缩放数据？[关闭]</title>
      <link>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</link>
      <description><![CDATA[我想使用 kmodes.kprototypes 中的 kprototype 对一些混合数据进行聚类。因此，有些是数值数据，有些是分类数据。我需要缩放数据吗？如果是，我是否只需要缩放数值数据？
我不熟悉 kprototype 的实现，我想对一些混合数据进行聚类。缩放能给我带来更好的结果吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</guid>
      <pubDate>Fri, 25 Oct 2024 06:48:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MIRNet 模型保存和重用低光增强功能？[关闭]</title>
      <link>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</link>
      <description><![CDATA[我最近在 Keras 上发现了一个关于图像增强的有趣教程。代码没问题，我运行没有任何错误，但我不知道如何保存模型并重新使用它。
我试了很多次，但无法保存模型。有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</guid>
      <pubDate>Fri, 25 Oct 2024 02:48:27 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型即使训练时具有很高的准确度，也能为所有输入提供完全相同的预测值</title>
      <link>https://stackoverflow.com/questions/79123575/keras-model-gives-exact-same-prediction-value-for-all-inputs-even-though-it-has</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79123575/keras-model-gives-exact-same-prediction-value-for-all-inputs-even-though-it-has</guid>
      <pubDate>Thu, 24 Oct 2024 20:49:05 GMT</pubDate>
    </item>
    <item>
      <title>以 32 位数字为例，FLUX.1-* 和 StableDiffusion 在制​​作图像时执行的典型计算有多大？[关闭]</title>
      <link>https://stackoverflow.com/questions/79123548/how-big-in-terms-of-say-32bit-numbers-are-the-typical-calculations-performed-b</link>
      <description><![CDATA[我没有 GPU，我只依赖我的 CPU，即 2x XEONS（没有 AVX、AVX2、AVX-512、F16C）和大量 RAM，所以我很好奇；

*实际平均矩阵有多大，我假设不是所有 60GB 的 .safetensors，它在图像处理和噪声生成过程中真正处理？

我假设它的根源是 GEMM 计算，但它抖动的真实矩阵有多大，以及它会在任何 AVX* 指令中抛出的每行和每列的长度是多少来乘以和/或加法？


顺便说一句，即使使用我的过时系统，我也会得到一个每 10 分钟左右处理一次 1024x512。
我也不使用 GUI，因此我也节省了大量资源。
仅供参考，所有内容都在 CLI 上的 Python 脚本上运行，我通过笔记本电脑使用 SSH 使用 PUtty 进行操作。
在我看来，GUI 和 GPU 被高估了。
大多数计算是否仅基于图像大小，比如我用作系统基准的 1024x512？
因此，某种方法，任何方法，快速处理 1024x512 矩阵，比如大约 524288 个 32 位浮点数的几个颜色层（RGB）都会很方便，对吧？]]></description>
      <guid>https://stackoverflow.com/questions/79123548/how-big-in-terms-of-say-32bit-numbers-are-the-typical-calculations-performed-b</guid>
      <pubDate>Thu, 24 Oct 2024 20:38:01 GMT</pubDate>
    </item>
    <item>
      <title>训练 AI 模型以纠正多边形坐标中的错误的最佳方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</link>
      <description><![CDATA[我需要选择一个最适合训练的 AI 模型和一个 Python 库。我有来自 djangorestframework-gis 库的以 Multipolygon 字段表示的坐标，它们在不同范围内存在小误差 - 大约 0.75 到 1 米。此外，我有相同地块的正确坐标。该模型需要学习找到正确数据和错误数据之间的差异，并在此基础上找到一种算法来确定错误，以便将来纠正错误坐标。]]></description>
      <guid>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</guid>
      <pubDate>Thu, 24 Oct 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测：如何使用截至 t-1 计算的特征预测未来值而不会发生数据泄漏？</title>
      <link>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</guid>
      <pubDate>Thu, 24 Oct 2024 17:39:23 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 混合预测和预测</title>
      <link>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</link>
      <description><![CDATA[我正在制作一个简单的应用程序来检测 .NET 中的网络异常
应用程序正在收集原始数据包，然后对其进行分析并确定是否发生了潜在攻击（使用静态算法）。目前，我已经实现了基于 TCP 数据包中的 SYN 和 ACK 标志来检测 TCP 洪水攻击的算法。除了分析之外，应用程序还在指定模式中将数据保存在文件中：
SOURCE_IP | DESTINATION_IP | TIMESTAMP (TIMEVAL) | SYN | ACK
10.0.0.5 | 10.0.0.10 | 1726332243,275925 | 1 | 1

我想实现 ML 模型（使用 ML.NET），根据当前“会话”中已经收集的数据预测是否发生攻击。
我尝试添加另一列“IsAttack”，这是我的标签。之后，我模拟了 tcp 洪水攻击，并通过完成最后一列来准备训练数据。但 ml 模型还包括当前会话中所有为“0”的先前标签，因此它无法正常工作。另一方面，当我尝试预测场景时，ML 仅从单行获取数据。有什么想法可以混合预测和预测吗？或者任何其他解决方案？
生成的 ML 模型：
public partial class TCPFloodMLDetector
{
/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输入类。
/// &lt;/summary&gt;
#region 模型输入类
public class ModelInput
{
[LoadColumn(0)]
public string SourceAddress { get; set; }

[LoadColumn(1)]
public string DestinationAddress { get; set; }

[LoadColumn(2)]
public double Timeval { get; set; }

[LoadColumn(3)]
public bool SYN { get; set; }

[LoadColumn(4)]
public bool ACK { get; set; }

[LoadColumn(5)]
[ColumnName(@&quot;col5&quot;)]
public Single IsAttack { get; set; }
}

#endregion

/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输出类。
/// &lt;/summary&gt;
#region 模型输出类
public class ModelOutput
{
[ColumnName(@&quot;col5&quot;)]
public float[] Col5 { get; set; }

[ColumnName(@&quot;col5_LB&quot;)]
public float[] Col5_LB { get; set; }

[ColumnName(@&quot;col5_UB&quot;)]
public float[] Col5_UB { get; set; }

}

#endregion

private static string MLNetModelPath = Path.GetFullPath(@&quot;D:\Projects\NetworkAnalyzer\\Models\TCPFloodMLDetector.mlnet&quot;);

public static readonly Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt; PredictEngine = new Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt;(() =&gt; CreatePredictEngine(), true);

/// &lt;summary&gt;
/// 使用此方法对 &lt;see cref=&quot;ModelInput&quot;/&gt; 进行预测。
/// &lt;/summary&gt;
/// &lt;param name=&quot;input&quot;&gt;model input。&lt;/param&gt;
/// &lt;returns&gt;&lt;seealso cref=&quot; ModelOutput&quot;/&gt;&lt;/returns&gt;
public static ModelOutput Predict(ModelInput? input = null, int? horizo​​n = null)
{
var predEngine = PredictEngine.Value;
return predEngine.Predict(input, horizo​​n);
}

private static TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt; CreatePredictEngine()
{
var mlContext = new MLContext();
ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var schema);
return mlModel.CreateTimeSeriesEngine&lt;ModelInput, ModelOutput&gt;(mlContext);
}
}

我在每秒运行的 Detect 函数中使用它：
public async Task Detect()
{
try
{
var context = new MLContext();
var data = context.Data.LoadFromTextFile&lt;TCPFloodInputModel&gt;(&quot;tcpflood.txt&quot;,
hasHeader: false, SeparatorChar: &#39;|&#39;);

TCPFloodMLDetector.LoadIDataViewFromFile(context, &quot;tcpflood.txt&quot;,
&#39;|&#39;, false, true);

// 使用默认选项进行预测。
var modelOutput = TCPFloodMLDetector.Predict();
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));

// 预测接下来的 5 个周期
modelOutput = TCPFloodMLDetector.Predict(horizo​​n: 5);
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));
}
catch (Exception ex)
{

}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</guid>
      <pubDate>Thu, 24 Oct 2024 13:12:42 GMT</pubDate>
    </item>
    <item>
      <title>基于文本描述的聚类[关闭]</title>
      <link>https://stackoverflow.com/questions/79112237/clustering-based-on-text-descriptions</link>
      <description><![CDATA[我为一家在线电子商务托管网站工作，最近我被要求标记一个数据库，该数据库包含 1000 多万条企业提供的服务。每条条目都有许多数据点，但最重要的是以下字段：
ServiceName：企业主为服务设置的简短名称（例如，“15 分钟儿童理发”）
ServiceDescription：企业主编写的服务详细描述（例如，“这是专为儿童提供的理发服务”）
Price：服务费用（例如，“30 美元”）
此标记任务的主要目标是帮助检测潜在欺诈行为。例如，如果有人报告理发价格为 1000 美元，则会引起警觉，因为我们标记的数据中理发的平均价格约为 60 美元，标准差为 10 美元。
背景环境
我唯一的参考是企业自行报告其业务类型（例如，“美发沙龙”）。我的一位同事使用关键字和预定义的常见销售商品列表成功地对这些数据的一小部分进行了分类。但是，我无法访问这样的列表或有关如何进行的明确指南。
如何在没有预定义标签的情况下有效地标记这个大型数据集？
是否有任何技术或工具可以帮助我根据描述和服务名称对这些服务进行分类？
我使用 chatgpt 将服务标记为类别取得了一些成功，但我认为这对于如此大的数据集来说不是一个可行的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79112237/clustering-based-on-text-descriptions</guid>
      <pubDate>Tue, 22 Oct 2024 02:14:38 GMT</pubDate>
    </item>
    <item>
      <title>ALS 算法 Spark MLlib - 如何获得我自己的“个人推荐”（我尚未排名的电影排名）</title>
      <link>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</link>
      <description><![CDATA[我在 Azure Databricks 中使用 PySpark。我使用 Sparks MLlib 库 ALS 算法来预测电影评分，效果很好。但是，我尝试添加一个数据框，其中包含我对 10 部随机选择的电影的评分。当我这样做时，我只能获得我已经排名的电影的预测排名。 
我希望能够使用该模型根据他们的排名获得推荐。
我有执行以下任务的 Spark 代码：

导入数据（RatingsSmall、MoviesSmall、RatingsLarge、Movies Large）
将 Ratings small 与 Movies Small 合并，将 Ratings Large 与 Movies Large 合并
将两个新数据集附加在一起
删除不相关的列 Timestamp 和 Genre

我现在有一个干净的表，其中包含 MovieID、Title（电影名称）、UserID 和 Ranking。我将从此处展示代码。如果您想要之前的代码，我也可以提交。

将数据拆分为训练集和测试集 (0.80, 0.20)
ALS 算法
显示预测。

希望以上内容能帮助您完成我所附的代码。
我只获得已提交排名的预测。
我尝试将我的排名加入训练集。从这里，我希望获得数据集中其他电影的推荐或预测。
我的尝试：
导入了具有我自己排名的 DF。
将其 (UnionAll) 附加到训练集。
获得预测（但仅限于我已经排名的电影）
code:
#拆分数据集

training, test = All_Movies.randomSplit([0.8, 0.2])
from pyspark.ml.recommendation import ALS

from pyspark.ml.evaluation import RegressionEvaluator

#设置模型

ALS = ALS(maxIter=10, regParam=0.01, userCol = &quot;userId&quot;,itemCol=&quot;movieId&quot;, ratingsCol=&quot;rating&quot;, coldStartStrategy=&quot;drop&quot;)

#将模型拟合到训练集并附加个人推荐

model = ALS.fit(training.unionAll(PersonalDF)) #PersonalDF 是我的排名

#获取测试集的预测
predictions = model.transform(test).dropna()

#直到一切都很好这里。

#尝试获取我的电影的预测排名
mySampledMovies = model.transform(PersonalDF) 
mySampledMovies.registerTempTable(&quot;mySampledMovies&quot;)

display(sqlContext.sql(&quot;select userId, movieId, ratings,title, prediction from mySampledMovies&quot;))

我期望一个 DataFrame 表示我的用户 ID、电影 ID、排名、预测。对于我没见过的电影，排名为 N/A 或 Null，预测有值。
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</guid>
      <pubDate>Fri, 08 Feb 2019 12:00:58 GMT</pubDate>
    </item>
    <item>
      <title>如何从一系列图像中预测下一张图像？</title>
      <link>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</link>
      <description><![CDATA[我计划从图像序列中预测下一张图像。我在互联网上（Google/YouTube）搜索过教程和类似的工作。但我找不到任何内容。
我想知道是否有可能找到模式并预测下一张图像，我能否找到一些相关教程。]]></description>
      <guid>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</guid>
      <pubDate>Sun, 08 Apr 2018 06:07:06 GMT</pubDate>
    </item>
    </channel>
</rss>