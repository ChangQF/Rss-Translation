<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Apr 2024 03:20:23 GMT</lastBuildDate>
    <item>
      <title>torch.nn.function.binary_cross_entropy 如何处理大小为 N x 2 的输出和标签？</title>
      <link>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</link>
      <description><![CDATA[分类器模型输出 N x 2 数组，同样数据集的标签具有相同的形状，每一行 [-ve, +ve] 代表一个分类实例，因此如果该行是，则数组中的左列有 1真负数，右边为零&amp;反之亦然。
使用torch.nn.function.binary_cross_entropy，但我需要使用权重参数，因为这些类非常不平衡13:1 -ve:+ve。我正在使用权重数组 torch.tensor([1.,13.]) 权重 13 是否应用于数组右列的所有条目或具有 1 的所有条目与列无关？文档中不清楚实现细节。]]></description>
      <guid>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</guid>
      <pubDate>Mon, 15 Apr 2024 02:35:47 GMT</pubDate>
    </item>
    <item>
      <title>在测试数据集上进行评估时，模型显示零准确度和几乎零损失？</title>
      <link>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</guid>
      <pubDate>Mon, 15 Apr 2024 00:22:30 GMT</pubDate>
    </item>
    <item>
      <title>如何结合2种模型机器学习？</title>
      <link>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</link>
      <description><![CDATA[我是机器学习的初学者。我有 2 个用于预测水可饮用性的机器学习模型，模型 1 使用决策树，模型 2 使用随机森林。那么如何组合该模型来制作新模型呢？我可以用它制作一个新模型吗？我使用Python编程。
组合 2 个模型来制作一个新模型。]]></description>
      <guid>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</guid>
      <pubDate>Mon, 15 Apr 2024 00:09:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么混淆矩阵只有一个条目作为输出？</title>
      <link>https://stackoverflow.com/questions/78325205/why-is-there-one-entry-as-output-in-confusion-matrix</link>
      <description><![CDATA[我正在仅包含 10 个样本的简单数据集上应用简单的 SVM 和逻辑回归。我正在尝试打印混淆矩阵，但它只给出“array([[2]])”作为输出。
这是代码：
sc = StandardScaler()
X_scaled = sc.fit_transform(X)
X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=42)
LR.fit(X_train,y_train)
y_pred=LR.predict(X_test)
print(accuracy_score(y_test,y_pred))//1.0 输出
con= fusion_matrix(y_test,y_pred) //array([[2]]) 输出
con.shape//(1, 1)
我的数据集是一个二元分类问题。 （0 或 1）]]></description>
      <guid>https://stackoverflow.com/questions/78325205/why-is-there-one-entry-as-output-in-confusion-matrix</guid>
      <pubDate>Sun, 14 Apr 2024 20:43:28 GMT</pubDate>
    </item>
    <item>
      <title>预期类型为“MyEnv”，却得到“Env”</title>
      <link>https://stackoverflow.com/questions/78324963/expected-type-myenv-got-env-instead</link>
      <description><![CDATA[我已经从 OpenGym 创建了自定义环境，并且我在这一行收到了之前的警告：
env: MyEnv=gym.make(&#39;gym_envs/MyEnv-v0&#39;)

当我删除 MyEnv 时，我没有收到警告，但随后我收到警告“类‘MyEnv’的未解析属性引用‘action_type’”在下面一行：
agent = QLearningAgent(env.action_space, env.observation_space.n, env.action_type.n)

知道如何消除警告吗？
我尝试编写一个包装器来返回 ATMEnv 对象而不是 Env，但它没有解决问题]]></description>
      <guid>https://stackoverflow.com/questions/78324963/expected-type-myenv-got-env-instead</guid>
      <pubDate>Sun, 14 Apr 2024 19:12:45 GMT</pubDate>
    </item>
    <item>
      <title>Sklearm FeatureHasher 无法处理数据框中的单个列</title>
      <link>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</link>
      <description><![CDATA[我尝试在数据框中的单个列上执行特征哈希器，但它不断给出错误：
&lt;块引用&gt;
ValueError：样本不能是单个字符串。输入必须是字符串可迭代对象上的可迭代对象。

from sklearn.feature_extraction import FeatureHasher

哈希向量大小 = 50
fh = FeatureHasher(n_features=hash_vector_size, input_type=&#39;string&#39;)
hashed_df = pd.DataFrame(fh.transform(X_train[“Item_Identifier”]).toarray(),
                         columns=[&#39;H&#39;+str(i) for i in range (hash_vector_size)])

我期望一个包含 50 列的数据框，其中的数据将被散列]]></description>
      <guid>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</guid>
      <pubDate>Sun, 14 Apr 2024 17:20:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 Eigen 执行步长卷积</title>
      <link>https://stackoverflow.com/questions/78324587/using-eigen-to-perform-a-convolution-with-stride</link>
      <description><![CDATA[我试图让 Eigen 以跨步执行卷积运算（对于卷积神经网络）。我知道 Eigen 有一个可以在张量上执行的卷积函数：
input.convolve（过滤器，尺寸）

没有参数可以提供步幅值。
我知道 Eigen 还有一个步幅函数，它返回应用特定步幅的张量的视图。然而，这与（我不认为）对卷积应用步幅相同。我想知道是否可以将 stride 函数应用于输入，然后调用 convolve，但我认为这不会导致与 stride 的正确卷积。
有谁知道如何应用步幅卷积（除了手动编写卷积函数而不是依赖 Eigen 的卷积函数）？
我注意到有一个“extract_image_patches”返回输入区域列表的函数 - 这是用来代替卷积函数吗？
谢谢
我查看了 Stackoverflow 和 Cross Validated，但在任何地方都看不到这个答案。 此处提出了类似的问题，但没有得到解答。]]></description>
      <guid>https://stackoverflow.com/questions/78324587/using-eigen-to-perform-a-convolution-with-stride</guid>
      <pubDate>Sun, 14 Apr 2024 16:57:29 GMT</pubDate>
    </item>
    <item>
      <title>facebook / detr-resnet-50 模型中的标签数量</title>
      <link>https://stackoverflow.com/questions/78323867/number-of-labels-in-facebook-detr-resnet-50-model</link>
      <description><![CDATA[我正准备在自定义数据集上训练 Facebook ResNet DETR 模型，以检测图像中的签名（我的数据集中只有 1 个类）。我不确定分配给模型配置中的 num_labels 参数的适当值。根据上下文，该值是否应该设置为 1（因为我只检测签名），或者我应该为没有任何签名的情况添加第二个标签？
这是代码
model = DetrForObjectDetection.from_pretrained(pretrained_model_name_or_path=CHECKPOINT,num_labels=????,ignore_mismatched_sizes=True)]]></description>
      <guid>https://stackoverflow.com/questions/78323867/number-of-labels-in-facebook-detr-resnet-50-model</guid>
      <pubDate>Sun, 14 Apr 2024 13:02:52 GMT</pubDate>
    </item>
    <item>
      <title>具有完整链接的分层凝聚聚类以对一维数据集进行聚类</title>
      <link>https://stackoverflow.com/questions/78323771/hierarchical-agglomerative-clustering-with-complete-linkage-to-cluster-a-1dimens</link>
      <description><![CDATA[我目前正在研究分层凝聚聚类，并熟悉其在表格中呈现的数据集的应用。但是，我不确定如何将此方法应用于一维数据集，特别是当仅对图形 x 轴上表示的数据点进行聚类时。谁能指导我如何在一维数据集的层次凝聚聚类中使用单一和完整的链接？此外，如果您能提供可以帮助我了解如何解决未来类似问题的示例或方法，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78323771/hierarchical-agglomerative-clustering-with-complete-linkage-to-cluster-a-1dimens</guid>
      <pubDate>Sun, 14 Apr 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>Whitewine 数据集上的 K 均值聚类问题</title>
      <link>https://stackoverflow.com/questions/78323717/k-means-clustering-problem-on-whitewine-dataset</link>
      <description><![CDATA[我目前正在努力使用 R 编程语言对名为 Whitewine 的数据集进行聚类，并比较应用主成分分析 (PCA) 之前和之后的聚类效果。尽管进行了多次尝试，我还是面临着挑战，因为即使在应用 PCA 后，我的数据点也没有以最佳方式聚类。
在 PCA 之前：我执行了异常值去除并采用 z 分数标准化来预处理数据集。&lt; /a&gt;
但是，聚类结果并不理想，聚类之间有明显的重叠。
PCA之后：利用prcomp函数，我降低了数据集的维度。
为了读者的利益，我也提供了每个实例的代码。
这是在 PCA 之前
# 异常值去除前的汇总统计信息
摘要(Whitewine_v6[, 1:11])

# 计算每列的下限和上限
lower_bounds &lt;- apply(Whitewine_v6[, 1:11], 2, function(x) 分位数(x, 0.25) - 1.5 * IQR(x))
upper_bounds &lt;- apply(Whitewine_v6[, 1:11], 2, function(x) 分位数(x, 0.75) + 1.5 * IQR(x))

# 识别前 11 列中的任何值超出范围的行
异常值 &lt;- apply(Whitewine_v6[, 1:11], 1, function(row) any(row &lt; lower_bounds | row &gt; upper_bounds))

# 对数据集进行子集化以删除具有异常值的行
Whitewine_clean &lt;- Whitewine_v6[!离群值, ]

# 检查清理后的数据集的维度
暗淡（Whitewine_clean）


#k=2 的 K 均值聚类
#K-Means 聚类投资
设置.种子(123)
k_mean1&lt;-kmeans(Whitewine_scaled, 2)

#有关集群解决方案的有用信息
#集群中心
k_mean1$中心
#集群
k_mean1$簇

# 提取BSS和TSS
BSS &lt;- k_mean1$ Betweenss
TSS &lt;- k_mean1$totss

# 计算WSS
WSS &lt;- sum(k_mean1$withinss)

# 计算总 WSS
Total_WSS &lt;- k_mean1$tot.withinss

# 计算BSS/TSS比率
BSS_TSS_ratio &lt;- BSS / TSS

# 打印结果
猫（“BSS：”，BSS，“\n”）
猫（“TSS：”，TSS，“\n”）
cat(&quot;总 WSS:&quot;, WSS, &quot;\n&quot;)
cat(&quot;BSS/TSS 比率：&quot;, BSS_TSS_ratio, &quot;\n&quot;)

#说明k-means聚类
fviz_cluster(k_mean1, Whitewine_scaled, geom=“点”, ellipse.type=“凸”, ggtheme=theme_light())

cluster_silhouette&lt;-silhouette(k_mean1$cluster, dist(Whitewine_scaled))
fviz_silhouette（cluster_silhouette）


这是 PCA 之后的
#新的“转换”数据集，其中选择的主成分作为属性
Whitewine_pca&lt;-data.frame(processed_data$x[,1:7])


我所做的总结：
我清理并缩放了我的数据集 (Whitewine)，为聚类做好准备。然后，我使用主成分分析（PCA）来简化数据。即使经过这些步骤，我的簇看起来仍然不明显。我尝试了K-means（因为这是我的项目中指定的方法，我不能使用任何其他方法），但结果并没有太大改善。现在，我正在寻求有关如何使我的集群更清晰的建议，尤其是在使用 PCA 之后。正如我之前所说，我的项目只能使用 K-means 聚类方法。我使用 4 种方法（NbClust、Elbow 方法、Gap 统计、Silhouette）确定了最佳簇数。
提前致歉，无法直接提供图像。]]></description>
      <guid>https://stackoverflow.com/questions/78323717/k-means-clustering-problem-on-whitewine-dataset</guid>
      <pubDate>Sun, 14 Apr 2024 12:00:20 GMT</pubDate>
    </item>
    <item>
      <title>将数据拆分为训练集、验证集和测试集，ID 不重叠，并且仍然平衡目标类</title>
      <link>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</link>
      <description><![CDATA[我需要将大型数据集拆分为一定比例的训练集、验证集和测试集，同时确保满足以下条件：

在每组中保留唯一的 ID。任何 ID 不能属于多于一组。
每次数据重组时，训练、验证和测试集中每个级别（“热”、“暖”、“冷”）都需要至少出现一次。

data &lt;- data.frame(ID = c(001, 001, 001,
                           002, 002, 002, 002,
                           003, 003, 003, 003,
                           004, 004, 004, 004, 004, 004,
                           005, 005, 005, 005, 005,
                           006, 006, 006, 006,
                           007, 007, 007,
                           008, 008,
                           009, 009,
                           010, 010, 010),
                   var1 = c(0102, 0210, 0405,
                            0318, 0629, 1201,0101,
                            0923、0702、0710、0801、
                            0203、0501、1204、0516、0112、1005、
                            1101、1125、1020、0112、0310、
                            0203、0401、0607、0811、
                            1010、1212、0707、
                            0430, 0428,
                            1030, 1008,
                            0501, 0511, 0601),
                   var2 = c(“冷”, “冷”, “冷”,
                            “温暖”、“温暖”、“温暖”、“温暖”、
                            “冷”、“冷”、“冷”、“冷”、
                            “温暖”、“温暖”、“温暖”、“温暖”、“温暖”、“温暖”、
                            “热”、“热”、“热”、“热”、“热”、
                            “冷”、“冷”、“冷”、“冷”、
                            “热”、“热”、“热”、
                            “温暖”、“温暖”、
                            “热”、“热”、
                            “冷”、“冷”、“冷”））

我尝试使用数据分割包 caret(fx = createDataPartition()) 和 splitTools (fx = partition()) 以及 dplyr 采样函数，但它们应用的分组可确保每个 ID 出现在所有集合中。 
减少数据集是可以的。以下是由现有 Stack Overflow 问题引导的众多尝试之一：
赋值 &lt;- 数据 %&gt;%
        选择（ID，var2）%&gt;%
        不同的(ID) %&gt;%
        行式() %&gt;%
        mutate(Group=sample(c(“验证”,“训练”,“测试”), 1,
                             概率 = c(0.70, 0.20, 0.10)))
数据%&gt;%
  left_join（作业，数据，by =“ID”）

这种尝试忽略了概率论点*没有设置比例。它还不能确保所有级别都出现在训练、验证和测试集中。]]></description>
      <guid>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</guid>
      <pubDate>Sun, 14 Apr 2024 00:19:39 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 pytorch 训练机器学习多项式回归模型，在尝试绘制预测结果时出现错误</title>
      <link>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch-an</link>
      <description><![CDATA[我想将数据绘制到 plt.scatter 表单中，但是当我尝试填充它时，它只是说 x 和 y 的大小不同，而且我还挤压了它们仅一维，以便更容易绘制，但仍然不起作用。
这是情节机制：
#使用 matplotlib.pyplot 中的散点图 (x,y) 可视化数据
defplot_predictions(train_features=X_train,
                     train_labels=y_train,
                     test_features=X_test,
                     测试标签=y_测试，
                     预测=无）：
    plt.figure(figsize=(10,7))

    plt.scatter(X_train, y_train, c=“g”, label=“训练数据”)

    plt.scatter(X_test, y_test, c=“b”, label=“测试数据”)

    如果预测不是 None：
        plt.scatter（test_features，预测，c =“r”，标签=“预测”）

    plt.legend(prop={“大小”: 14})

绘图预测（）

#这里检查是否存在不匹配的形状
X_train.shape、y_train.shape、y_preds.shape

#output (torch.Size([24, 1]), torch.Size([24, 1]), torch.Size([24, 1]))
#这里尝试解决问题
Predictions_reshape=y_preds.squeeze(dim=1)
labels_reshape=y_train.squeeze(dim=1)
打印（len（y_train），len（y_preds））
打印（labels_reshape.shape，predictions_reshape.shape）

＃输出
#24 24
#torch.Size([24]) torch.Size([24])
#torch.Size([6, 1]) torch.Size([6, 1])


labels_reshape=y_train.detach().numpy()
Predictions_reshape=y_preds.detach().numpy()
图_预测（标签_重塑，预测=预测_重塑）

&lt;块引用&gt;
ValueError：x 和 y 的大小必须相同

我尝试压缩张量，使它们只有一个暗淡，并且我还检查了镜头是否相同，确实如此。]]></description>
      <guid>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch-an</guid>
      <pubDate>Sat, 13 Apr 2024 20:23:01 GMT</pubDate>
    </item>
    <item>
      <title>识别随机森林中错误分类的样本</title>
      <link>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</link>
      <description><![CDATA[我正在 RStudio 中执行随机森林分析，我可以使用下面的代码提取混淆矩阵。我可以看到有多少样本被错误分类，但是我可以使用什么代码来识别哪些特定样本被错误分类？
库（随机森林）
库（rfPermute）

rfmetrics &lt;- randomForest(x, y, ntree=ntree,重要性=T)
打印（rfmetrics）

称呼：
 randomForest(x = x, y = y, ntree = ntree, 重要性 = T)
               随机森林类型：分类
                     树木数量：1999
每次分割尝试的变量数量：25

        OOB 估计错误率：56.88%
混淆矩阵：
  1 2 3 4 类.错误
1 8 7 7 4 0.6923077
2 4 19 2 4 0.3448276
3 3 3 15 6 0.4444444
4 3 9 10 5 0.8148148
]]></description>
      <guid>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</guid>
      <pubDate>Wed, 10 Apr 2024 19:44:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.layers”没有属性“实验性”</title>
      <link>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</link>
      <description><![CDATA[你好，我试图调整我的数据集的大小和比例，如下所示，但我遇到了这个错误：
AttributeError：模块“keras.layers”没有属性“experimental”
&lt;前&gt;&lt;代码&gt;
resize_and_rescale= tf.keras.Sequential([
    图层.实验.预处理.调整大小(IMAGE_SIZE,IMAGE_SIZE),
    层.实验.预处理.重新缩放(1.0/255)
]）

]]></description>
      <guid>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</guid>
      <pubDate>Wed, 14 Dec 2022 00:43:49 GMT</pubDate>
    </item>
    </channel>
</rss>