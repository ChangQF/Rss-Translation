<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Mar 2024 21:12:31 GMT</lastBuildDate>
    <item>
      <title>连体网络反向传播</title>
      <link>https://stackoverflow.com/questions/78208649/siamese-network-backpropagation</link>
      <description><![CDATA[我正在尝试使用 Triplet-loss 构建一个跨视图本地化网络。
我想要查询照片（锚点），通过“model1”，以及负片和“model1”。积极通过“model2” （因为他们来自不同的领域，我不想分享他们的权重）。
我想知道当我计算 2 个不同模型的特征的损失时，如何正确反向传播。
这段代码正确吗？：
criterion_triplet = nn.TripletMarginLoss（margin=args.margin，p=2，reduction=“sum”）
模型 1 = MyNet(参数)
模型2 = MyNet(参数)
优化器1 = torch.optim.Adam(...)
优化器2 = torch.optim.Adam(...)

...训练循环...
   features1 = model1(images_anchor.to(args.device))
   features2 = model2(images_satelite.to(args.device))
   loss_triplet += criteria_triplet(features1,
                                     特点2,
                                     特点2)
   优化器1.zero_grad()
   优化器2.zero_grad()
   loss_triplet.backward()
   优化器1.step()
   优化器2.step()
]]></description>
      <guid>https://stackoverflow.com/questions/78208649/siamese-network-backpropagation</guid>
      <pubDate>Fri, 22 Mar 2024 20:15:29 GMT</pubDate>
    </item>
    <item>
      <title>MLP a2c 策略抱怨 0 不大于 0，或者无穷大不大于 0？</title>
      <link>https://stackoverflow.com/questions/78208624/mlp-a2c-policy-complaining-that-0-isnt-greater-than-0-or-infinity-isnt-greate</link>
      <description><![CDATA[当我训练一些火炬模型时出现以下错误：
ValueError(&#39;分布Normal(loc: torch.Size([1, 4]))的预期参数尺度（形状为(1, 4)的张量），scale: torch.Size([1, 4] )) 以满足约束 GreaterThan(lower_bound=0.0)，但发现无效值：\ntensor([[inf, inf, 0., 0.]])&#39;)。

我的行为具有形状 (4,) 和观察 (3,)。
它是否认为无穷大不&gt;0，或者0不大于0？我不知道为什么会出现这种情况。它是简单地使用 model.learn 在稳定的基线 3 中训练模型。然而，它学习了一段时间，但在这一步失败了：
~\anaconda3\envs\\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py 学习（自我，total_timesteps，回调，log_interval，tb_log_name，reset_num_timesteps，progress_bar）
    第257章
    [第 258 章]总时间步数：
--&gt;第 259 章
    260
    261 如果 continue_training 为 False：

〜\ anaconda3 \ envs \ lib \ site-packages \ stable_baselines3 \ common \ on_policy_algorithm.py在collect_rollouts中（self，env，callback，rollout_buffer，n_rollout_steps）
    167 # 转换为pytorch张量或TensorDict
    第168章
--&gt; 169 个动作，值，log_probs = self.policy(obs_tensor)
    170 个动作 = actions.cpu().numpy()
    171

_call_impl 中的 ~\anaconda3\envs\\lib\site-packages\torch\nn\modules\module.py(self, *input, **kwargs)
   第1192章
   第1193章
-&gt;第1194章
   第1195章
   第1196章

〜\anaconda3\envs\\lib\site-packages\stable_baselines3\common\policies.py 向前（自我，obs，确定性）
    第624章
    625 值 = self.value_net(latent_vf)
--&gt; [第 626 章]
    第627章 行动=distribution.get_actions(确定性=确定性)
    第628章

~\anaconda3\envs\\lib\site-packages\stable_baselines3\common\policies.py 在 _get_action_dist_from_latent(self, Latent_pi)
    第654章
    第655章
--&gt;第656章
    第657章
    第658章

proba_distribution 中的 ~\anaconda3\envs\\lib\site-packages\stable_baselines3\common\distributions.py(self,mean_actions,log_std)
    第162章 162
    第 163 章
--&gt;第164章
    第165章 回归自我
    166

~\anaconda3\envs\\lib\site-packages\torch\distributions\normal.py 在 __init__(self, loc, scale, validate_args)
     54 其他：
     55 batch_shape = self.loc.size（）
---&gt; 56 super(普通，自我).__init__(batch_shape, validate_args=validate_args)
     57
     58 def Expand(self,batch_shape,_instance=None):

__init__ 中的 ~\anaconda3\envs\\lib\site-packages\torch\distributions\distribution.py(self、batch_shape、event_shape、validate_args)
     55 如果无效.all():
     56 引发值错误（
---&gt; 57 f“预期参数{param}”
     58 f&quot;({type(value).__name__}，形状为{tuple(value.shape)})&quot;
     59 f”分布{repr(self)}”

请记住我的操作是 0&lt;=a&lt;=1。我需要将其设置为 0
我很难知道它到底在抱怨什么，因为这段代码深入稳定的基线3。这可能是他们的包中的一个小故障吗？我希望它更新权重并继续运行，但它却抱怨 0 不大于 0.. 我不知道为什么我关心这个，但它应该继续运行，不是吗？
感谢您的浏览。]]></description>
      <guid>https://stackoverflow.com/questions/78208624/mlp-a2c-policy-complaining-that-0-isnt-greater-than-0-or-infinity-isnt-greate</guid>
      <pubDate>Fri, 22 Mar 2024 20:07:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么 torch.nn.function.linear 中重量的维度是 (out,in) 而不是 (in,out)</title>
      <link>https://stackoverflow.com/questions/78208603/why-are-the-dimension-of-the-weight-in-torch-nn-functional-linear-out-in-inste</link>
      <description><![CDATA[在 torch.nn.function.linear 的文档中（https://pytorch.org/docs/stable/ generated/torch.nn.function.linear.html），权重输入的维度为（out_features，in_features），然后计算时对权重矩阵进行转置输出：y=xA^T+b。为什么他们这样做而不是采用维度矩阵 W（in_features、out_features）并执行 y=xW+b？
通过执行 y=xW+b 尺寸将匹配，因此我找不到上述的明确原因。]]></description>
      <guid>https://stackoverflow.com/questions/78208603/why-are-the-dimension-of-the-weight-in-torch-nn-functional-linear-out-in-inste</guid>
      <pubDate>Fri, 22 Mar 2024 20:01:42 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Lite：导入错误：libusb-1.0.so.0：无法打开共享对象文件：没有这样的文件或目录</title>
      <link>https://stackoverflow.com/questions/78208486/tensorflow-lite-importerror-libusb-1-0-so-0-cannot-open-shared-object-file-n</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78208486/tensorflow-lite-importerror-libusb-1-0-so-0-cannot-open-shared-object-file-n</guid>
      <pubDate>Fri, 22 Mar 2024 19:31:01 GMT</pubDate>
    </item>
    <item>
      <title>以下 RandomizedSearchCV 的实现正确吗？</title>
      <link>https://stackoverflow.com/questions/78208446/is-the-following-implementation-of-randomizedsearchcv-right</link>
      <description><![CDATA[我正在通过这本书学习机器学习&quot;动手机器学习”，并且有一个练习来实现SelectFromModel。书中给出的练习的解决方案运行以下代码：
param_distribs = {
        &#39;svr__kernel&#39;: [&#39;线性&#39;, &#39;rbf&#39;],
        &#39;svr__C&#39;: loguniform(20, 200_000),
        &#39;svr__gamma&#39;: 指数(scale=1.0),
    }

svr_pipeline = Pipeline([(“预处理”, 预处理), (“svr”, SVR())])
rnd_search = RandomizedSearchCV(svr_pipeline,
                                param_distributions=param_distribs,
                                n_iter=50，CV=3，
                                评分=&#39;neg_root_mean_squared_error&#39;,
                                详细=2，
                                随机状态=42）

rnd_search.fit(housing.iloc[:5000], housing_labels.iloc[:5000])

选择器管道=管道（[
    （&#39;预处理&#39;，预处理），
    (&#39;选择器&#39;, SelectFromModel(RandomForestRegressor(random_state=42),
                                 阈值=0.005)), # 最小特征重要性
    (&#39;svr&#39;, SVR(C=rnd_search.best_params_[&quot;svr__C&quot;],
                gamma=rnd_search.best_params_[“svr__gamma”],
                kernel=rnd_search.best_params_[“svr__kernel”])),
]）

selector_rmses = -cross_val_score(selector_pipeline,
                                  住房.iloc[:5000],
                                  housing_labels.iloc[:5000],
                                  评分=“neg_root_mean_squared_error”，
                                  简历=3)
pd.Series(selector_rmses).describe()

计数 3.000000
平均值 56211.362086
标准1922.002802
分钟 54150.008629
25% 55339.929909
50% 56529.851189
75% 57242.038815
最大 57954.226441
数据类型：float64

好的。这个结果比之前的练习更糟糕，作者建议：“哦，特征选择似乎没有帮助。”但也许这只是因为我们使用的阈值不是最佳的。也许尝试使用随机搜索或网格搜索来调整它？”
嗯，出于学习的目的，我尝试着实施这个建议。以下是我的尝试：
param_distribs = {
    &#39;选择器__阈值&#39;：统一（0，0.05），
    &#39;svr__C&#39;: loguniform(20, 200_000),
    &#39;svr__gamma&#39;: 指数(scale=1.0),
    &#39;svr__kernel&#39;: [&#39;线性&#39;, &#39;rbf&#39;]
}

选择器管道=管道（[
    （&#39;预处理&#39;，预处理），
    (&#39;选择器&#39;, SelectFromModel(RandomForestRegressor(random_state=42))),
    (&#39;svr&#39;, SVR()),
]）

rnd_search = RandomizedSearchCV(selector_pipeline,
                                param_distributions=param_distribs,
                                n_iter=50，CV=3，
                                评分=&#39;neg_root_mean_squared_error&#39;,
                                详细=2，
                                随机状态=42）

rnd_search.fit(housing.iloc[:5000], housing_labels.iloc[:5000])

# 获取最佳参数
best_threshold = rnd_search.best_params_[&#39;selector__threshold&#39;]
best_svr_C = rnd_search.best_params_[&#39;svr__C&#39;]
best_svr_gamma = rnd_search.best_params_[&#39;svr__gamma&#39;]
best_svr_kernel = rnd_search.best_params_[&#39;svr__kernel&#39;]

# 使用最佳参数更新管道
选择器管道.set_params(
    选择器__阈值=最佳阈值，
    svr__C=best_svr_C,
    svr__gamma=best_svr_gamma,
    svr__kernel=best_svr_kernel
）

但是最后一个输出似乎比前一个输出更糟糕：
selector_rmses = -cross_val_score(selector_pipeline,
                                  住房.iloc[:5000],
                                  housing_labels.iloc[:5000],
                                  评分=“neg_root_mean_squared_error”，
                                  简历=3）
pd.Series(selector_rmses).describe()

计数 3.000000
平均值 56713.692587
标准2011.579891
分钟 55241.366017
25% 55567.689915
50% 55894.013813
75% 57449.855872
最大 59005.697931
数据类型：float64

我只想解释结果：也许阈值的RandomizedSearchCV不需要解决方案，也许优化阈值无论如何都无济于事。但对我来说更根本的问题是：我的实施正确吗？我不能 100% 确定这是正确的方法。就像我说的，我正在研究和学习，然后我不确定代码。如果这是正确的，下一步可以做什么来尝试更好的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78208446/is-the-following-implementation-of-randomizedsearchcv-right</guid>
      <pubDate>Fri, 22 Mar 2024 19:22:22 GMT</pubDate>
    </item>
    <item>
      <title>源代码显示的不同输出（机器学习）（Python）</title>
      <link>https://stackoverflow.com/questions/78207935/different-output-showing-from-a-source-code-machine-learning-python</link>
      <description><![CDATA[我目前正在尝试开展一个小型图像机器学习项目。我找到了这个人的 Kaggle 代码，并尝试从头开始复制它。然而，即使在主要部分，我也已经遇到了错误。
我确信我的结局一定存在本地化问题，但我不知道是什么。
我的代码：
#导入库

#数据处理模块
将 pandas 导入为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入CV2
#文件目录模块
将 glob 导入为 gb
导入操作系统
#训练和测试（机器学习）模块
将张量流导入为 tf
导入keras

#将图像导入到代码中

trainDataset = &#39;melanoma_cancer_dataset/train&#39;
testDataset = &#39;melanoma_cancer_dataset/test&#39;
预测数据集 = &#39;melanoma_cancer_dataset/skinTest&#39;

#为要处理的图像创建空列表
训练列表 = []
测试列表 = []
#为良性和恶性这两个键制作一个分类字典
#用于插入图像
词典 = {&#39;良性&#39;: 0, &#39;恶性&#39;: 1}

#读取文件夹的长度内容
对于 os.listdir(trainDataset) 中的文件夹：
    数据 = gb.glob(路径名=str(trainDataset + 文件夹 + &#39;/*.jpg&#39;))
    print(f&#39;{len(data)} 在文件夹 {fold}&#39;)
    #读取图像，按照统一的顺序调整它们的大小，并将它们存储在空列表中
    对于数据中的数据：
        图像 = cv2.imread(数据)
        imageList = cv2.resize(图像(120,120))
        Training_List.append(列表(imageList))

笔记本的输出显示该文件夹中存储了 0 个图像/内容。现在我有点怀疑这里发生了什么，并且希望得到一些答案。提前致谢。我也在使用自己的 VScode。
这是我的文件的屏幕截图：
]]></description>
      <guid>https://stackoverflow.com/questions/78207935/different-output-showing-from-a-source-code-machine-learning-python</guid>
      <pubDate>Fri, 22 Mar 2024 17:27:51 GMT</pubDate>
    </item>
    <item>
      <title>Text2sql NLP：如何实现与用户的交互界面以进行自然输入并获取模型生成的输出</title>
      <link>https://stackoverflow.com/questions/78207916/text2sql-nlp-how-to-implement-an-interactive-interface-with-the-user-for-natura</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78207916/text2sql-nlp-how-to-implement-an-interactive-interface-with-the-user-for-natura</guid>
      <pubDate>Fri, 22 Mar 2024 17:23:36 GMT</pubDate>
    </item>
    <item>
      <title>我使用 sklearn 和 xgboost 训练了一个模型，现在我想将其转换为 tflite 文件，我该怎么做？我在colab中进行了编码</title>
      <link>https://stackoverflow.com/questions/78207843/i-trained-a-model-using-sklearn-and-xgboost-and-now-i-want-to-convert-it-as-a-tf</link>
      <description><![CDATA[我想使用firebase将其集成到react-native应用程序中，我可以直接将tflite文件添加到firebase。我训练的模型不是tensorflow模型，但我使用sklearn库来使用xgboost。
如果可能的话，我期待相同的过程和代码。]]></description>
      <guid>https://stackoverflow.com/questions/78207843/i-trained-a-model-using-sklearn-and-xgboost-and-now-i-want-to-convert-it-as-a-tf</guid>
      <pubDate>Fri, 22 Mar 2024 17:10:01 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 Web 应用程序中运行数字分类器以捕获绘图板中的图像时出现问题</title>
      <link>https://stackoverflow.com/questions/78207771/problem-in-trying-to-run-a-digit-classifier-in-a-webapp-that-captures-image-in-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78207771/problem-in-trying-to-run-a-digit-classifier-in-a-webapp-that-captures-image-in-a</guid>
      <pubDate>Fri, 22 Mar 2024 16:57:34 GMT</pubDate>
    </item>
    <item>
      <title>Python：运行保存的 SVM 模型时出错：ValueError：X 有 2943 个功能，但 SVC 期望 330320 个功能作为输入</title>
      <link>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</link>
      <description><![CDATA[我使用 Sickit-learn 创建了一个 SVM 模型：
导入 pandas 作为 pd
df = pd.read_csv(r&quot;C:\Users\aaa\Documents\bbb\svm_.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

从 imblearn.over_sampling 导入 RandomOverSampler
过采样器 = RandomOverSampler(sampling_strategy=&#39;auto&#39;, random_state=42)

X_resampled, y_resampled = oversampler.fit_resample(df.drop(columns=[&#39;alvo&#39;]), df[&#39;alvo&#39;])

df_resampled = pd.concat([X_resampled, pd.DataFrame({&#39;alvo&#39;: y_resampled})], axis=1)

打印（df_重采样）

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.svm 导入 SVC
从sklearn.metrics导入accuracy_score，classification_report
从 sklearn.preprocessing 导入 OneHotEncoder

X = df_resampled.drop(columns=[&#39;alvo&#39;])
y = df_resampled[&#39;alvo&#39;]

编码器 = OneHotEncoder()
X_encoded = 编码器.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)

svm_classifier = SVC(kernel=&#39;poly&#39;, random_state=42)

svm_classifier.fit(X_train, y_train)

y_pred = svm_classifier.predict(X_test)

准确度=准确度_得分(y_test, y_pred)
分类报告结果 = 分类报告(y_test, y_pred)

print(f&quot;准确度: {accuracy}&quot;)
print(&quot;分类报告：\n&quot;,classification_report_result)

进口泡菜

model_file_path = “C:\\Users\\aaa\\Documents\\bbb\\svm_modelo_sent_simnao2.pkl”

打开（model_file_path，&#39;wb&#39;）作为f：
    pickle.dump(svm_classifier, f)

print(&quot;模型保存成功！&quot;)




支持向量机的简单实现来预测分类变量是正确的，工作得很好。
但是，当加载模型并运行以下代码时：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 OneHotEncoder
导入作业库

model_file_path = &quot;C:\\Users\\AAA\\Documents\\BBB\\svm_modelo_sent_simnao.pkl&quot;
svm_classifier = joblib.load(model_file_path)

new_df = pd.read_csv(r&quot;C:\Users\AAA\Documents\BBB\svm_simnao_rodar.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

X_new = new_df.drop(columns=[&#39;alvo&#39;, &#39;ID_ASSUNTO&#39;], axis=1) # 删除 &#39;alvo&#39; 和 &#39;ID_ASSUNTO&#39; 列

categorical_columns = [&#39;UF&#39;, &#39;TIPO_ACAO&#39;, &#39;AREA_JURIDICA&#39;, &#39;VARA_CAMARA&#39;, &#39;CLIENTE_NOME&#39;] # 分类列列表
编码器= OneHotEncoder（类别=&#39;自动&#39;，稀疏=假）
X_new_encoded = 编码器.fit_transform(X_new[categorical_columns])

X_new_processed = pd.concat([pd.DataFrame(X_new_encoded), X_new.drop(columns=categorical_columns)], axis=1)

y_pred_new = svm_classifier.predict(X_new_processed)

new_df[&#39;alvo&#39;] = y_pred_new

预测 = new_df[[&#39;ID_ASSUNTO&#39;, &#39;alvo&#39;]]

打印（预测）

什么会导致以下错误：
ValueError Traceback（最近一次调用最后一次）
 在
22
23 # 进行预测
---&gt; 24 y_pred_new = svm_classifier.predict(X_new_processed)
25
26 # 将预测（&#39;alvo&#39;）添加到新数据
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py 在预测(self, X)
第818章
第819章：
--&gt;第820章
第821章
第822章
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py 在预测(self, X)
第431章 预测值。
第432章
--&gt;第433章
第434章
[第 435 章]
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py validate_for_predict(self, X)
611
...
--&gt;第389章
[第 390 章]
[第 391 章] 第 391 章
ValueError：X 有 2943 个特征，但 SVC 期望输入 330320 个特征。
我在部署代码中用来预测 alvo 的数据与我训练模型的数据具有完全相同的结构，并且我在训练和部署代码中都使用 OneHotEncoding...所以我有点迷失了一个。
知道如何解决这个问题吗？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</guid>
      <pubDate>Fri, 22 Mar 2024 15:57:18 GMT</pubDate>
    </item>
    <item>
      <title>R 混淆矩阵 - 错误：“数据”和“参考”应该是具有相同级别的因素[关闭]</title>
      <link>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</link>
      <description><![CDATA[尽管还有其他针对相同错误消息的报告，但没有一个对我的情况有帮助。
我已经准备了自己的数据，分割如下，但无法获得混淆矩阵。
test_index &lt;- createDataPartition(y =workingData$PM10, times = 1, p = 0.5, list = FALSE)
train_set &lt;-工作数据[-test_index,]
test_set &lt;-工作数据[test_index,]

train_knn &lt;- train(PM10 ~. , method= &quot;knn&quot; , data = train_set)

y_hatknn &lt;- 预测(train_knn, train_set, type = “raw”)

fusionMatrix(y_hatknn, test_set$PM10)

上面最后一行给出
错误：“data”和“reference”应该是具有相同级别的因素。

我想上传数据进行复制，但可以提供基本的：
&lt;前&gt;&lt;代码&gt;str(工作数据)
“数据帧”：3653 obs。 3 个变量：
&#39; $ 日期 : 数字 2e+07 2e+07 2e+07 2e+07 2e+07 ...
&#39; $ Rain_mm: 数字 0.1 6.7 0 1.4 0.8 1.8 15.3 0 2.6 3.8 ...
&#39; $ PM10 : 数字 -1 -1 -1 -1 -1 ...

PM10 是污染 PM10 水平。
如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</guid>
      <pubDate>Fri, 22 Mar 2024 09:39:08 GMT</pubDate>
    </item>
    <item>
      <title>给定标签集之外的短 2-3 个标记文本或用户搜索查询的序列标签 [关闭]</title>
      <link>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</link>
      <description><![CDATA[我正在使用 FLAIR 模块解决序列标签问题。
我有包含 3 种不同类型实体的虚拟电子商务数据，每个实体都有大约 1K 个子实体。训练数据（大小约为 200K）是通过 3K 标签的组合综合创建的。
我尝试使用查询分类模型（带有 3K 标签）验证 FLAIR 序列标签。 FLAIR 模型（F1-score：60%）严重低于分类模型（F1-score：80%） &gt;).
我不愿意开发序列标签模块，因为我希望序列标签器也能够检测并提出新实体。
你能帮我了解哪里可能出错以及我可以尝试哪些其他模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</guid>
      <pubDate>Fri, 22 Mar 2024 05:30:33 GMT</pubDate>
    </item>
    <item>
      <title>Spark如何应用于深度学习模型训练阶段？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78204101/how-can-spark-be-used-in-deep-learning-model-training-phase</link>
      <description><![CDATA[我注意到 Apache Spark 被大量用于训练数据准备，但我很好奇它与 PyTorch/TensorFlow 一起在训练阶段的潜在作用，特别是在同时具有 CPU 和 GPU 的环境中。我想知道 Spark 在数据加载或缓存方面是否比 PyTorch/TensorFlow 有任何优势，特别是在分布式训练场景中。
虽然 PyTorch 和 TensorFlow 都支持分布式训练，但我很想知道 Spark 的功能是否可以提高性能或减少延迟，特别是在处理可能超出 GPU 内存容量的大型数据集时。]]></description>
      <guid>https://stackoverflow.com/questions/78204101/how-can-spark-be-used-in-deep-learning-model-training-phase</guid>
      <pubDate>Fri, 22 Mar 2024 04:51:30 GMT</pubDate>
    </item>
    <item>
      <title>在 llm_chain input_variables 中找不到 StuffDocumentsChain document_variable_name 上下文的验证错误：['input'] (type=value_error)</title>
      <link>https://stackoverflow.com/questions/78199098/validation-error-for-stuffdocumentschain-document-variable-name-context-was-not</link>
      <description><![CDATA[我正在尝试根据路由使用不同的rags在langchain中创建一个路由链，每个rags都有不同的提示模板，这是我的代码：
period_template = &quot;&quot;&quot;AAAText
多曼达：
{输入}“””


ref_template = &quot;&quot;&quot;BBBtext.
多曼达：
{输入}“””

list_template = &quot;&quot;&quot;CCCText.
多曼达：
{输入}“””

提示信息 = [
    {
        “名称”：“期间”，
        “描述”：“AAA”，
        “提示模板”：期间模板
    },
    {
        “名称”：“参考”，
        “描述”：“BBB”，
        “提示模板”：参考模板
    },
    {
        “名称”：“历史”，
        “描述”：“CCC”，
        “提示模板”：列表模板
    }
]

目的地链 = {}
对于提示信息中的 p_info：
    PROMPT = PromptTemplate(template=p_info[“prompt_template”], input_variables=[“input”])
    链 = RetrievalQA.from_chain_type(
        聊天模型，
        检索器=db.as_retriever(),
        return_source_documents=真，
        chain_type_kwargs={“提示”: 提示}
    ）
    destination_chains[p_info[“名称”]] = 链

我收到错误：
&lt;块引用&gt;
ValidationError：StuffDocumentsChain 出现 1 个验证错误
root document_variable_name 上下文在 llm_chain input_variables 中找不到：[&#39;input&#39;] (type=value_error)

出了什么问题，如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78199098/validation-error-for-stuffdocumentschain-document-variable-name-context-was-not</guid>
      <pubDate>Thu, 21 Mar 2024 10:16:24 GMT</pubDate>
    </item>
    <item>
      <title>Yolov8 超参数调优</title>
      <link>https://stackoverflow.com/questions/78196468/yolov8-hyperparameter-tunning</link>
      <description><![CDATA[我尝试改进模型中的 mAP 结果。你能帮我调整yolov8中的超参数吗
如何调整 Yolov8 中的超参数？有什么方法可以在 Colab 中用 Python 代码对其进行调优吗？或者我应该与默认一起工作。 yaml 文件，我应该如何使用这个文件？
另外，我想提高准确性。我怎样才能通过调整来做到这一点？
这是我的问题]]></description>
      <guid>https://stackoverflow.com/questions/78196468/yolov8-hyperparameter-tunning</guid>
      <pubDate>Wed, 20 Mar 2024 22:05:12 GMT</pubDate>
    </item>
    </channel>
</rss>