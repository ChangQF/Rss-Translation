<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 26 May 2024 09:15:07 GMT</lastBuildDate>
    <item>
      <title>如何使用生成 AI 的精确输入图像来输出图像</title>
      <link>https://stackoverflow.com/questions/78534726/how-to-use-the-exact-input-image-using-generative-ai-for-output-image</link>
      <description><![CDATA[是否有任何免费或付费的工具/API，我们可以使用精确的输入图像来使用生成人工智能或任何其他自动化方式创建新图像。
以下两种情况
1-我有一个帽子的输入图像，想要生成一个戴着完全相同帽子的男孩的新图像。
2-或者我有一张戴着珍珠项链的模特的图片。在另一张图片中，我有一条 png 金项链，想在新图片中用这条金项链替换那条珍珠项链。]]></description>
      <guid>https://stackoverflow.com/questions/78534726/how-to-use-the-exact-input-image-using-generative-ai-for-output-image</guid>
      <pubDate>Sun, 26 May 2024 08:43:05 GMT</pubDate>
    </item>
    <item>
      <title>如何将图像分割成一系列补丁而不丢弃剩余像素</title>
      <link>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</link>
      <description><![CDATA[我正在尝试使用 pytorch-library 中的 Deeplab v3 模型来实现语义分割项目。该模型需要大小为 520x520 的输入图像。
我想将图像分割成大小为 520x520 的补丁，将它们放入模型中，然后将它们重新形成可以与像素蒙版进行比较的图像。
然而，我发现的每个代码都存在同样的问题：如果我的图像高度或宽度不能完全被 520 整除，则最后无法放入 520x520 补丁中的所有像素都会被丢弃。
例如，如果我有一个宽度为 1920 像素的图像，我会得到 3 个宽度为 520 的补丁，并且丢弃 360 个剩余像素。身高也是如此。
我希望我的代码使最后一个补丁与周围的补丁重叠，以便我可以对图像的每个像素进行预测。
我尝试使用 patchify-library 和 torch.unfold，但两者都有相同的输出，只是丢弃了剩余的像素。]]></description>
      <guid>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</guid>
      <pubDate>Sun, 26 May 2024 08:09:57 GMT</pubDate>
    </item>
    <item>
      <title>创建新 csv 文件时权限被拒绝</title>
      <link>https://stackoverflow.com/questions/78534467/permission-denied-while-creating-a-new-csv-file</link>
      <description><![CDATA[来源：
&lt;前&gt;&lt;代码&gt;@dataclass
类数据摄取配置：
    train_data_path:str = os.path.join(“artifacts/train_data”)
    test_data_path:str = os.path.join(“artifacts/test_data”)
    raw_data_path:str = os.path.join(&#39;artifacts&#39;,&#39;raw.csv&#39;)
# 此地址的权限被拒绝 ^

类数据摄取阶段：
    def __init__(自身):
        self.dataIngestionConfig = DataIngestionConfig

    def 数据摄取（自身）：
        mlflow_logs = Mlflow_logs()
        使用 mlflow.start_run()：
            logging.info(“数据摄取阶段开始”)
            mlflow_logs.log_msg(“数据摄取阶段开始”)
            尝试：
                df = pd.read_csv(“笔记本/数据/Dataset.csv”)
                os.makedirs（os.path.join（self.dataIngestionConfig.raw_data_path），exist_ok = True）
                df.to_csv(self.dataIngestionConfig.raw_data_path，索引=False)
            除了异常 e：
                mlflow_logs.log_msg(f“异常：{e}”)
                引发 CustomException(e,sys)

输出：
[Errno 13] 权限被拒绝：&#39;artifacts\\raw.csv&#39;]

我尝试读取 csv 文件，然后将其作为 raw.csv 存储到 artifacts 文件夹内的新 csv 文件中。文件夹权限已被授予，但我收到此错误。]]></description>
      <guid>https://stackoverflow.com/questions/78534467/permission-denied-while-creating-a-new-csv-file</guid>
      <pubDate>Sun, 26 May 2024 06:40:01 GMT</pubDate>
    </item>
    <item>
      <title>错误：`cargo rustc --lib --message-format=json-render-diagnostics --manifest-path Cargo.toml --release -v --features pyo3/extension-module</title>
      <link>https://stackoverflow.com/questions/78534306/error-cargo-rustc-lib-message-format-json-render-diagnostics-manifest-pa</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78534306/error-cargo-rustc-lib-message-format-json-render-diagnostics-manifest-pa</guid>
      <pubDate>Sun, 26 May 2024 04:52:13 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Xarray 数据集转换为 Darts 时间序列</title>
      <link>https://stackoverflow.com/questions/78534046/how-to-convert-xarray-dataset-to-a-darts-time-series</link>
      <description><![CDATA[
我有一个带有纬度/经度/时间坐标的 Xarray 数据集对象。这是一张气候数据图。我想将其转换为 Darts TimeSeries 对象，以便在其上训练模型。有一个函数可以将 Xarray 对象转换为 TimeSeries，但它需要三个字段：“时间”、“组件”和“样本”。如何将我的 xarray 数据集转换为这种格式？
我尝试过，但得到了 KeyError: &#39;component&#39;
vi_time_series = TimeSeries.from_xarray(ds.vegetation_index)
]]></description>
      <guid>https://stackoverflow.com/questions/78534046/how-to-convert-xarray-dataset-to-a-darts-time-series</guid>
      <pubDate>Sun, 26 May 2024 01:01:52 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测平台的 Transformer 模型 - 求建议</title>
      <link>https://stackoverflow.com/questions/78533853/transformer-model-for-time-series-prediction-plateaus-seeking-suggestion</link>
      <description><![CDATA[对于机器学习领域来说有点陌生，如果这个问题很基本，那么抱歉。我使用一个简单的香草变压器来处理时间序列数据来预测特定的连续值。之前，我通过随机森林实现了一些准确性，并希望使用变压器来提高它。然而，无论其复杂程度如何，我的变压器模型的性能似乎都趋于稳定。
我尝试过批量大小（16、32、64、128、200）、各种学习率和不同的标准化技术。在测试了不同的损失函数（MSE、MAE、Cauchy Loss、Huber损失和RMSE）后，我发现批量大小为200，学习率为0.005，MSE表现最好。
我还可视化了注意力头来识别重要特征，训练了变分自动编码器并在我的变压器中使用了它的权重，并尝试了迁移学习。尽管做出了这些努力，该模型的性能仍然稳定。
我最近看到了 Anthropic 写的这篇文章 (https://transformer- Circuits.pub/2024/scaling-monosemanticity/index.html），但尚未实施其建议。
有人对进一步改进或研究模型有建议吗？我相信它在某个时候会陷入困境，任何见解都将不胜感激。请注意，我已经绘制了异常值，并观察了具有高 MSE 的样本之间的 MSE 及其相互关系，但我没有看到任何可以解释该问题的内容。下面，我粘贴了我正在使用的一个简单的变压器模型。以及显示训练 (25,000) 和验证 (1000) 数据集的损失曲线的图表。 X 轴是纪元，y 轴是 MSE。
class PositionalEncoding(nn.Module):

    def __init__(self, d_model, max_len=1000):
        super(PositionalEncoding, self).__init__()       
        pe = torch.zeros(max_len, d_model)
        位置 = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        #div_term = torch.randn(19)
        print(&#39;div term&#39;, div_term.shape)
        print(&#39;正弦&#39;,torch.sin(position * div_term).shape)
        print(&#39;cosine&#39;,torch.cos(position * div_term).shape)
        print(&#39;位置&#39;, 位置.形状)
        print(&#39;pe&#39;, pe.shape)
        pe[:, 0::2] = torch.sin(位置 * div_term)  
        pe[:, 1::2] = torch.cos(位置 * div_term) 
        pe = pe.unsqueeze(0).transpose(0, 1)
 
        self.register_buffer(&#39;pe&#39;, pe)

    def 前向（自身，x）：
        返回 x + self.pe[:x.size(0), :]
       



def focus_hook(模块, 输入, 输出):
    查询、键、值 = 输入[0]、输入[1]、输入[2] 

TransAm 类（nn.Module）：
    def __init__(self,feature_size=20,num_layers=1,dropout=0.1):
        super(TransAm, self).__init__()
        self.model_type = &#39;变压器&#39;
        
        self.src_mask = 无
        self.pos_encoder = PositionalEncoding(feature_size)
        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        
        self.decoder = nn.Linear(feature_size,1)
        self.init_weights()
        
        
 
        
    def init_weights(自身):
 
        nn.init.constant_(self.decoder.bias.data, 0)

 
        nn.init.xavier_uniform_(self.decoder.weight)

    def 转发（自身，src）：
        如果 self.src_mask 为 None 或 self.src_mask.size(0) != len(src):
            设备 = src.设备
            mask = self._generate_square_subsequent_mask(len(src)).to(device)
            self.src_mask = 掩码

        src = self.pos_encoder(src)
        输出 = self.transformer_encoder(src,self.src_mask) 
        输出 = self.decoder(输出)
        返回输出

    def _generate_square_subsequent_mask(self, sz):
        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)
        mask = mask.float().masked_fill(mask == 0, float(&#39;-inf&#39;)).masked_fill(mask == 1, float(0.0))
        返回掩码
    

模型 = TransAm().to(设备)



 
input_tensor = torch.tensor(np.random.rand(32, 20), dtype = torch.float32).to(device)
print(&quot;输入张量形状：&quot;, input_tensor.shape)
输出=模型（输入张量）
输出形状

]]></description>
      <guid>https://stackoverflow.com/questions/78533853/transformer-model-for-time-series-prediction-plateaus-seeking-suggestion</guid>
      <pubDate>Sat, 25 May 2024 22:18:15 GMT</pubDate>
    </item>
    <item>
      <title>ClassifierChain ValueError：无法将字符串转换为浮点数：'eval'</title>
      <link>https://stackoverflow.com/questions/78533760/classifierchain-valueerror-could-not-convert-string-to-float-eval</link>
      <description><![CDATA[我正在尝试在 CatBoostClassifier 上使用 ClassifierChain。请参阅下面的代码。
X 由数字/分类特征组成
Y 是二维布尔矩阵。
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
/var/folders/qt/pddm3t3951g42p57pf8yms780000gn/T/ipykernel_81478/3196626518.py 在？()
     11 clf = CatBoostClassifier(reg_lambda=0.001,
---&gt; 12次迭代=450，
     13深度=5，
     14 学习率=0.01,
     15 loss_function=&#39;MultiLogloss&#39;,

〜/miniforge3/envs/m_arch/lib/python3.9/site-packages/sklearn/base.py 中？（估计器，*args，**kwargs）
   第1148章
   第1149章
   第1150章
   第1151章
-&gt;第1152章

〜/miniforge3/envs/m_arch/lib/python3.9/site-packages/sklearn/multioutput.py 在？（自我，X，Y，** fit_params）
    第929章”
    930“请参阅用户指南以获取更多信息。”
    第931章）
    第932章 
--&gt;第933章
    第934章
    第935章
    第936章
...
   第2151章
   第2152章
   第2153章

ValueError：无法将字符串转换为浮点数：&#39;eval&#39;

下面是我尝试的代码。
cat_feature_idx/feature_idx 用于指定 catboostclassifier 参数中的索引。只有 5 个数字特征。插补后，df idx 顺序现在变为[数字特征+分类特征]，而不是 X 中列的原始顺序，因此“feature_idx[-cat_feature_idx:]”在争论中。
我在没有 ClassifierChain 的情况下测试了模型，但在包含它时提示错误。
我怀疑发生错误的两个可能原因：

ClassifierChain 包含链中较早模型的预测，从而使 X 更大，但是 CatBoostClassifier 无法识别新“特征”是否适用于该链。是类别或数字（或者列的索引现在可能是随机排列的），因此会出现错误。

在 new_X_train 的一列中，值“eval”导致错误。
怀疑短语“eval”提示错误，或者我弄乱了转换后的 X_train 中的顺序 


该列表是要在 CatboostClassifier feature_idx[-cat_feature_idx:] 中指定的 cat_features 索引
我不确定这个理论是否正确，也不知道如何对此进行更多研究。
下面是代码。
hamming_scorer = make_scorer(hamming_loss,greater_is_better=False)

预处理器 = ColumnTransformer(
    变形金刚=[
        （&#39;num&#39;，IterativeImputer（random_state = 42），numeric_features），
        (&#39;cat&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;), categorical_features)
    ]）

cat_feature_idx = X.shape[1] - len(numerical_features) 
feature_idx = np.arange(X.shape[1])

预处理器 = ColumnTransformer(
    变形金刚=[
        （&#39;num&#39;，IterativeImputer（random_state = 42），numeric_features），
        (&#39;cat&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;), categorical_features)
    ]）
管道 = 管道(步骤=[(&#39;预处理器&#39;, 预处理器)])
new_X_train = pipeline.fit_transform(X_train)


clf = CatBoostClassifier(reg_lambda=0.001,
                        迭代=450，
                        深度=5，
                        学习率=0.01，
                        loss_function=&#39;多对数损失&#39;, 
                        eval_metric=&#39;汉明损失&#39;, 
                        cat_features=feature_idx[-cat_feature_idx:], 
                        详细=0，
                        随机种子=42）
链 = [ClassifierChain(clf, order=“随机”, random_state=i) for i in range(10)]
对于链中链：
    chain.fit(X_train, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/78533760/classifierchain-valueerror-could-not-convert-string-to-float-eval</guid>
      <pubDate>Sat, 25 May 2024 21:24:12 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型总是预测几乎相同的事情</title>
      <link>https://stackoverflow.com/questions/78533664/keras-model-always-predicts-almost-the-same-thing</link>
      <description><![CDATA[我需要帮助，我的 keras 模型几乎总是预测同样的事情。我的 loss 和 val_loss 分别收敛到 0.6 和 0.4 左右，这看起来很奇怪，但我尝试了很多不同的方法，包括 dropout、augmentation、标准化、调整等，但没有任何效果。
datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=&#39;val_loss&#39;, 因子=0.5, 耐心=2, 模式=“自动”, min_delta=0.0001, 冷却时间=0, min_lr=0)
train_generator = datagen.flow(X, y_train_array)
val_generator = datagen.flow(train_array_val, y_val_array)
pred_generator = datagen.flow(train_array_val, shuffle=False)

初始化器 = tf.keras.initializers.HeNormal()

imgModel = models.Sequential([
层.输入(形状=(128, 128, 3)),
Layers.RandomFlip(“水平”),
层.RandomZoom(.2),
层.RandomRotation(0.2),
层.Conv2D(64, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Conv2D(32, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Conv2D(64, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Flatten(),
层.Dense（128，激活=&#39;relu&#39;，kernel_initializer=初始化器，input_dim=81），
层数.Dropout(0.2),
层.Dense(128, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(64, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(32, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(1, 激活=&#39;线性&#39;)
]）

imgModel.compile(优化器=Adam(learning_rate=0.001),loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])

历史= imgModel.fit（train_generator，epochs = 300，shuffle = True，batch_size = 32，validation_data = val_generator，callbacks = [early_stopping，reduce_lr]）

预测 = imgModel.predict(pred_generator)

我正在尝试从 9500 个图像数据集预测 0.0 到 5.0 之间的特征。该数据集已正确加载，我已检查过该数据集，并且以正确的顺序为每个图像分配其特征。我尝试过使用Datagen，没有datagen（是的，我正在按1/255重新缩放），有或没有标准化，不同的密集层，不同的转换层，但它们都不起作用。我也尝试过使用预先训练的模型，但没有成功。请帮忙！
一旦达到“停止点”，那么无论经过多少个纪元，它都会保持相同的损失。然后它进行预测，我发现预测几乎没有什么不同。下面是预期的 val 预测和实际预测。
预测]]></description>
      <guid>https://stackoverflow.com/questions/78533664/keras-model-always-predicts-almost-the-same-thing</guid>
      <pubDate>Sat, 25 May 2024 20:40:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中仅通过歌曲的索引来播放歌曲？</title>
      <link>https://stackoverflow.com/questions/78533401/how-to-play-a-song-in-python-by-only-index-of-it</link>
      <description><![CDATA[我目前正在使用 GTZAN 数据集音乐流派分类数据集。训练模型后（我仍在模型的笔记本中），我运行了这个脚本，并预测了流派输出，直到这里为止一切都很完美，但我不知道如何播放这首歌，并确认是否类型是正确的。通常是通过文件路径完成的，但我只有歌曲的索引。
将 numpy 导入为 np
导入pygame
导入时间

# 选择样本数据点
index = 0 # 从测试集中选择一个索引
Sample = X_test[index] # 从测试集中选择一个样本
Sample = Sample[np.newaxis, ...] # 转换为适合模型的形状

# 别猜
Prediction = model.predict(sample) # 使用模型进行预测
Predicted_index = np.argmax(prediction, axis=1) # 查找预测索引

# 打印预测结果
Predicted_genre = converter.inverse_transform(predicted_index)[0] # 将预测类型转换为标签
Expected_genre = converter.inverse_transform([y_test[index]])[0] # 将预期类型转换为标签

print(&quot;预期类型：{}，预测类型：{}&quot;.format(expected_genre, Predicted_genre))

如果需要任何进一步的信息，我会提供]]></description>
      <guid>https://stackoverflow.com/questions/78533401/how-to-play-a-song-in-python-by-only-index-of-it</guid>
      <pubDate>Sat, 25 May 2024 18:45:50 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
from sklearn.preprocessing import StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>我无法决定选择哪个方向（机器学习或后端）[关闭]</title>
      <link>https://stackoverflow.com/questions/78524267/i-can-t-decide-which-direction-to-choose-ml-or-backend</link>
      <description><![CDATA[请帮帮我。我从 Python 开始了我的 IT 之旅，但无法决定选择哪个方向（机器学习或后端）。我没有任何工作经验，到目前为止我只懂python。我还开始学习 ML 统计，原则是你需要了解更多 ML 知识，这意味着从 ML 切换到后端可能会更容易。请告诉我哪个更好？
我还开始学习 ML 统计，原则是您需要了解更多 ML 知识，这意味着从 ML 切换到后端可能会更容易。]]></description>
      <guid>https://stackoverflow.com/questions/78524267/i-can-t-decide-which-direction-to-choose-ml-or-backend</guid>
      <pubDate>Thu, 23 May 2024 15:42:06 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 CTF 挑战赛 [已关闭]</title>
      <link>https://stackoverflow.com/questions/78522790/machine-learning-ctf-challenge</link>
      <description><![CDATA[我正在尝试解决机器学习 CTF 挑战。 这是链接，这里是网站背后的代码。我需要获取该标志，根据我所见（在 src/api/v1/predict/index.ts 中），该标志在“l33t”输出时被打印。 label 在 totalScores 对象中得分最高。我尝试了多个提示，但没有任何效果。对此的任何帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78522790/machine-learning-ctf-challenge</guid>
      <pubDate>Thu, 23 May 2024 11:25:08 GMT</pubDate>
    </item>
    <item>
      <title>成为一名 mlops 工程师从哪里开始？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78502776/where-to-start-to-become-a-mlops-engineer</link>
      <description><![CDATA[我目前是一名 DevOps 工程师，我非常渴望了解 MLOPS。
从职业角度来看，我希望将 ML 相关工作添加到我的个人资料中。
由于我不是开发人员背景，因此我只能将 MLOPS 视为 ML 领域的一个选项，该领域主要处理我认为的模型的部署。
我需要一些专家的建议，想知道我应该从哪里开始？
我目前正在与 gitlab、cicd、aws 合作。
任何提示或建议将不胜感激。
我已经在高层次上了解了 MLops。]]></description>
      <guid>https://stackoverflow.com/questions/78502776/where-to-start-to-become-a-mlops-engineer</guid>
      <pubDate>Sun, 19 May 2024 13:46:01 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Model.fit() 打印训练数据集</title>
      <link>https://stackoverflow.com/questions/78467703/tensorflow-model-fit-printing-training-dataset</link>
      <description><![CDATA[我是 Tensorflow 和 ML 领域的新手，我对 Tensorflow 的体验很奇怪。
我正在尝试训练 Tensorflow 简单序列模型，但在训练阶段，它不会显示准确性或某些进度条，而是打印整个训练数据集。
这是我的完整代码
导入tensorflow为tf
从数据导入 get_data  
从 sklearn 导入 model_selection

数据 = get_data(&#39;2Y&#39;)

x_train, x_test, y_train, y_test = model_selection.train_test_split(data.get_values([&#39;温度&#39;,&#39;风&#39;,&#39;湿度&#39;]), data.get_values(&#39;雨&#39;), test_size=0.1, shuffle=False)
模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(8),
    tf.keras.layers.Dense(8)
]）

模型.编译(
    优化器=“亚当”，
    损失=“binary_crossentropy”，
    指标=[“准确度”]
）

model.fit(x_train、y_train、epochs=10、batch_size=64、validation_data=(x_test、y_test)、verbose=2)

我阅读了tensorflow文档，但没有提到在模型拟合期间打印整个数据集之类的事情。我不明白哪里出了问题。并且在 model.fit() 之后，程序退出。]]></description>
      <guid>https://stackoverflow.com/questions/78467703/tensorflow-model-fit-printing-training-dataset</guid>
      <pubDate>Sun, 12 May 2024 11:41:45 GMT</pubDate>
    </item>
    <item>
      <title>什么是逻辑？ softmax 和 softmax_cross_entropy_with_logits 有什么区别？</title>
      <link>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</link>
      <description><![CDATA[在 tensorflow API 文档中，他们使用名为 logits 的关键字。它是什么？很多方法都是这样写的：
tf.nn.softmax(logits, name=None)

如果logits只是一个通用的Tensor输入，为什么它被命名为logits？
&lt;小时/&gt;
其次，下面两种方法有什么区别？
tf.nn.softmax(logits, name=None)
tf.nn.softmax_cross_entropy_with_logits（logits，标签，名称=无）

我知道 tf.nn.softmax 的作用，但不知道另一个。一个例子真的很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</guid>
      <pubDate>Sat, 12 Dec 2015 14:03:27 GMT</pubDate>
    </item>
    </channel>
</rss>