<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 10 Mar 2025 18:23:14 GMT</lastBuildDate>
    <item>
      <title>损失的计算梯度W.R.T学习率Pytorch</title>
      <link>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</guid>
      <pubDate>Mon, 10 Mar 2025 15:11:02 GMT</pubDate>
    </item>
    <item>
      <title>离群值检测和去除[封闭]</title>
      <link>https://stackoverflow.com/questions/79498235/outlier-detection-and-removal</link>
      <description><![CDATA[ z得分和IQR是两种用于离群检测和删除的方法，当数据分布正常时，使用z得分，并且当数据偏斜时使用IQR。数值列的，我们不能使用图形方法检测正态分布，然后如何进行？]]></description>
      <guid>https://stackoverflow.com/questions/79498235/outlier-detection-and-removal</guid>
      <pubDate>Mon, 10 Mar 2025 14:02:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在虚幻引擎5中加入libtorch？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</guid>
      <pubDate>Sun, 09 Mar 2025 15:03:36 GMT</pubDate>
    </item>
    <item>
      <title>当用简化运行时，模态可以正常执行。但是，当输入图像时，它无法正常工作</title>
      <link>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</guid>
      <pubDate>Sun, 09 Mar 2025 07:49:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么投票表决为“努力”的投票表现有所不同？</title>
      <link>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</link>
      <description><![CDATA[我想从Sklearn和不同参数进行比较性能测试投票classifier。我使用了param网格，然后发现一些难以理解的东西。
我准备了三个分类器
  gnb = gaussiannb（）＃准确性0.795
lr = logisticRegress（）＃准确性0.7925
RFC = RandomforestClassifier（）＃准确性0.94

 
然后我做了两个VaitingClassifiers。两者都有有效的设置为“硬”。但是重量不同。该决定是由多数投票做出的，但其准确性是不同的，这是如何可能的？
  vc_hard_equals = fotingClassifier（estionators = [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （&#39;Randomforest＆quot＆quot; rfc）
    ]，， 
    投票=“硬＆quot” 
    权重=（1，1，1），＃等于权重
    ）
vc_hard_forest_priority = fotingClassifier（估算= [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （“ rancomforest”，rfc），]， 
    投票=“硬＆quot” 
    权重=（1，1，3），＃更大的随机孔（在这种情况下最好的型号）
    ）

vc_hard_equals.fit（x_train，y_train）
vc_hard_forest_priority.fit（x_train，y_train）

print（vc_hard_equals.score（x_test，y_test））＃0.832
print（vc_hard_forest_priority.score（x_test，y_test））＃0.915
 ]]></description>
      <guid>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</guid>
      <pubDate>Fri, 28 Feb 2025 02:14:28 GMT</pubDate>
    </item>
    <item>
      <title>在Palantir Foundry模型培训参数（平均，SD）中评估过程是否从“火车数据”到“测试数据”？</title>
      <link>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</link>
      <description><![CDATA[如果我正确理解了该过程，则在机器学习中缩放测试数据时，应使用从培训数据中学到的缩放参数（如平均值和标准偏差）来转换测试数据，而不是测试数据本身。。
所以正确的步骤是：

将数据分开：将数据集分为培训和测试集。
缩放训练数据：计算和应用缩放参数（例如平均值，标准偏差）到训练数据。
将相同的参数应用于测试数据

要实现上述步骤，我使用：

  fit_transform 缩放“培训数据”，
 转换携带“培训数据”参数以“测试数据” 

但是，当我评估“测试数据”时，我如何在Palantir铸造模型中实现这一目标，我看不到评估配置的选项。有谁知道Palantir是否在评估配置中构建功能？携带参数过程会自动发生吗？如果没有，我该怎么做才能实现？
  fit_transform 然后变换在Palantir Foundry模型培训中等效]]></description>
      <guid>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</guid>
      <pubDate>Wed, 26 Feb 2025 08:32:02 GMT</pubDate>
    </item>
    <item>
      <title>增加自我注意力后，CNN网络的非确定性行为</title>
      <link>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</link>
      <description><![CDATA[当我添加nlbloclos时，在我的网络（简单CNN）中添加了一个自发层时，网络的结果不再可重现，当我再次训练它时，结果是不同的。但是，当我删除网络中的nlblocks时，它是确定性的。
这是代码：
  os.environ [＆quot&#39;cuda_visible_devices;
os.environ [&#39;tf_cpp_min_log_level&#39;] =&#39;3&#39;
种子= 42
os.environ [&#39;tf_deterministic_ops&#39;] =&#39;1&#39;
tf.config.experiment.enable_op_determinism（）

os.environ [&#39;pythonhashseed&#39;] = str（seed）
os.environ [&#39;tf_cudnn_deterministic&#39;] =&#39;1&#39; 

随机种子（种子）
np.random.seed（种子）
tf.random.set_seed（种子）

tf.keras.backend.set_floatx（&#39;float64&#39;）



nlblock类（层）：
    def __init __（self，num_channels，** kwargs）：
        super（nlblock，self）.__ init __（** kwargs）
        self.num_channels = num_channels
        self.theta = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.phi = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.g = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =; same＆quort;）
        self.attention_layer =注意（）＃keras注意层

    def呼叫（self，输入）：
        ＃变换功能图
        query = self.theta（输入）＃query（q）
        key = self.phi（输入）＃key（k）
        value = self.g（输入）＃value（v）

        ＃应用注意力层
        activation_output = self.attention_layer（[查询，键，值]）

        ＃残差连接
        返回输入 +注意_Output
        
＃定义NL注意的模型
def build_model（）：
    优化器= ADAM（Learning_rate = 0.002，beta_1 = 0.89，beta_2 = 0.995）

    输入= tf.keras.input（shape =（num_time_steps，1））＃输入层
    
    ＃Conv Block 1
    x = conv1d（filters = 64，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（输入）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 64）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）

    ＃Conv 2 2
    x = conv1d（filters = 32，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 32）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.1）（x）

    ＃Conv Block 3
    x = conv1d（filters = 16，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 16）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.35）（x）

    ＃完全连接的图层
    x = flatten（）（x）
    x =密集（40，激活=&#39;relu&#39;）（x）
    x =辍学（0.35）（x）
    输出=致密（20）（x）＃回归的输出层
    
    ＃编译模型
    型号= tf.keras.model（输入，输出）
    model.compile（优化器=优化器，lose = root_mean_squared_error，metrics = [&#39;mean_absolute_error&#39;]）
    
    返回模型

model = build_model（）

redy_lr = reducelronplateau（monitor =&#39;val_loss&#39;，因子= 0.6，耐心= 25，min_lr = 1e-6）
早期_Stopping =早期踩踏（Monitor =&#39;Val_loss&#39;，Patience = 30，Restore_best_weights = true）
＃步骤5：训练模型
历史= model.fit（x_train_scaled，y_train，validation_data =（x_val_scaled，y_val），
                epochs = 180，batch_size = 90，callbacks = [redion_lr，ropand_stopping]，冗长= 0）

test_loss，test_mae = model.evaluate（x_test_scaled，y_test，batch_size = len（x_test_scaled），词= 0）
 
我还使用tf.matmul（）和softmax使用自定义注意块，但没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</guid>
      <pubDate>Fri, 14 Feb 2025 15:08:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么拥抱面提供的DeepSeek代码会导致“未知量化类型”错误？</title>
      <link>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 deepseek上的huggingface网站页面上的页面

 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe =管道（＆quot&#39;text-generation＆quot; deepseek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 

，但我无法加载模型。当我这样做时，我会得到这个问题：

 file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py&quot;，第97行，in_dict 
 提高ValueError（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 

我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：

raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;] 

我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>无法使用NLTK功能</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>哪种评估指标适合与数据集不平衡的分类问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/76072393/which-evaluation-metric-will-be-suitable-for-a-classification-problem-with-an-im</link>
      <description><![CDATA[我的X类带有1000个观测值和Y类，具有2000个观测值。我正在尝试确定这里最合适的分类评估指标以及原因。

精确召回曲线。
 AUC ROC 
简单的精度度量
混淆矩阵和分类报告。

我很想坚持选项4，因为它不是一个不平衡的IMO，我们不需要使用精确的回忆曲线。这里有什么合适的？]]></description>
      <guid>https://stackoverflow.com/questions/76072393/which-evaluation-metric-will-be-suitable-for-a-classification-problem-with-an-im</guid>
      <pubDate>Fri, 21 Apr 2023 10:45:10 GMT</pubDate>
    </item>
    <item>
      <title>在线差异更新批处理数据 /颜色频道的有效算法更新</title>
      <link>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data-color-channel</link>
      <description><![CDATA[我有大量的多维数据（图像），并希望计算所有轴（颜色通道）的方差。内存明智，我无法创建一个大数组来计算一个步骤的方差。因此，我需要分批加载数据并以在线方式以某种方式更新当前差异。
 玩具示例 
最后，批处理明智的更新在线应匹配 recript_var 。
但是，我很难为此找到有效的算法。
 导入numpy作为np
np.random.seed（0）
＃正确计算方差
all_data = np.random.randint（0，9，（9，3））＃＆lt;  - 不适合记忆
recripe_var = all_data.var（axis = 0）
＃创建批次
batches = all_data.Reshape（-1，3，3）

在线_var = 0
批处理批量：
   batch_var = batch.var（轴= 0）
   在线_var =？  ＃如何正确更新此
surstert np.allclose（recript_var，online_var）
 

我找到了

如何以有效考虑整个批次的有效方式更新多个新观察的方差？]]></description>
      <guid>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data-color-channel</guid>
      <pubDate>Thu, 23 Feb 2023 14:10:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在XGBoost中的提升回合之间显示错误输出？</title>
      <link>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</link>
      <description><![CDATA[我正在使用Scikit-Learn API， XGBRegressor 。我正在尝试使我的模型尽可能详细。这些是模型的参数。这是在Kaggle内核上运行的。  df_train 和 df_target 是pandas dataframes。
  model = XGB.XGBRegressor（
    n_estimators = 2 ** 8，
    max_depth = 5，
    Learning_rate = 0.04，
    子样本= 0.9，
    colsample_bytree = 0.9，    
    objective =&#39;reg：squarederror&#39;，
    booster =&#39;gbtree&#39;，
    eximplease_type =&#39;strige&#39;，
    tree_method =&#39;gpu_hist&#39;，
    静音= false，    
    Random_State =种子
）
 
这是 fit（）的参数。我必须看到像LightGBM这样的提升回合之间的训练RMSE。 XGBoost具有该功能吗？
  model.fit（df_train，df_target，eval_metric =&#39;rmse&#39;，eval_set = [（df_train，df_target）]，verbose = true）
 ]]></description>
      <guid>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</guid>
      <pubDate>Thu, 17 Oct 2019 09:52:56 GMT</pubDate>
    </item>
    <item>
      <title>完美的精确度，召回和F1得分，但预测不好</title>
      <link>https://stackoverflow.com/questions/53278489/perfect-precision-recall-and-f1-score-yet-bad-prediction</link>
      <description><![CDATA[使用Scikit-Learn对二进制问题进行分类。获得完美的 classification_report （全1）。但是预测给出 0.36 。怎么可能？
我熟悉不平衡标签。但是，我认为这里并非如此，因为 f1 和其他得分列以及混乱矩阵表示完美的分数。
 ＃列出最后19个行进行预测。
x1，x_pred，y1，y_pred = train_test_split（x，y，test_size = 19， 
                shuffle = false，Random_state =无）

x_train，x_test，y_train，y_test = train_test_split（x1，y1， 
         test_size = 0.4，strate = y1，Random_state = 11）

clcv = deciestReeClaleCifier（）
scorecv = cross_val_score（clcv，x1，y1，cv = stratifiedkfold（n_splits = 4）， 
                         评分=&#39;f1&#39;）＃平衡精度/召回
clcv.fit（x1，y1）
y_predict = clcv.predict（x1）
cm = Confusion_matrix（y1，y_predict）
cm_df = pd.dataframe（cm，index = [&#39;0&#39;，&#39;1&#39;]，列= [&#39;0&#39;，&#39;1&#39;]）
打印（cm_df）
打印（classification_report（y1，y__predict））
打印（&#39;预测分数：&#39;，clcv.score（x_pred，y_pred））＃看不见的数据
 
输出：
 混乱：
      0 1
0 3011 0
1 0 44

              精确召回F1得分支持
       错误1.00 1.00 1.00 3011
        正确1.00 1.00 1.00 44

   Micro AVG 1.00 1.00 1.00 3055
   宏平均1.00 1.00 1.00 3055
加权公平1.00 1.00 1.00 3055

预测分数：0.36
 ]]></description>
      <guid>https://stackoverflow.com/questions/53278489/perfect-precision-recall-and-f1-score-yet-bad-prediction</guid>
      <pubDate>Tue, 13 Nov 2018 10:05:57 GMT</pubDate>
    </item>
    <item>
      <title>无法获得我的线性回归的准确分数</title>
      <link>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</link>
      <description><![CDATA[我正在基于IMDB数据进行回归模型，以预测IMDB值。在线性回归上，我无法获得准确的得分。
我的代码行：
 量表
 
错误：
  valueerror：不支持连续
 
如果我要更改该线以获得R2分数，
  Metrics.R2_Score（test_y，linear_predicated_rating）
 
我能够获得R2而没有任何错误。
我为什么看到这个？
注意： test_y 是pandas dataframe]]></description>
      <guid>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</guid>
      <pubDate>Fri, 11 Aug 2017 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：稀疏基质长度模棱两可；使用RF分类器时使用getnnz（）或Shape [0]？</title>
      <link>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</link>
      <description><![CDATA[我正在学习Scikit学习中的随机森林，例如，我想使用自己的数据集使用随机森林分类器进行文本分类。因此，首先，我用TFIDF对文本进行了介绍，以进行分类：
 来自sklearn.semble import incort fandyForestClassifier
classifier = RandomforestClassifier（n_estimators = 10） 
classifier.fit（x_train，y_train）           
预测= classifier.predict（x_test）
 
当我运行分类时，我得到了：
  typeError：传递了一个稀疏矩阵，但是需要密集的数据。使用X.ToArray（）转换为密集的Numpy数组。
 
然后，我使用 .toArray（）  x_train ，我得到了以下内容：
  typeError：稀疏矩阵长度是模棱两可的；使用getnnz（）或形状[0]
 
来自以前的问题当我了解我需要减少数量阵列的尺寸性时，我需要相同的尺寸：
 来自sklearn.decomposition.truncated_svd import truncatedSvd        
pca = truncatedSvd（n_components = 300）                                
X_REDUDS_TRAIN = PCA.FIT_TRANSFORM（X_TRAIN）               

从sklearn.semblection incort intim                 
classifier = RandomforestClassifier（n_estimators = 10）                  
classifier.fit（x_reduced_train，y_train）                            
预测= clastifier.predict（x_testing） 
 
然后我得到了这个例外：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
  文件“/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py”，第192行，in __len __
    提高类型（“稀疏矩阵长度是模棱两可的；使用getnnz（）”
TypeError：稀疏基质长度模棱两可；使用getnnz（）或形状[0]
 
我尝试了以下内容：
 预测= classifier.predict（x_train.getnnz（）） 
 
并得到了：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
TypeError：&#39;int&#39;类型的对象没有len（）
 
从中提出了两个问题：如何使用随机森林正确分类？  x_train ？ 
然后我尝试了以下内容：
  df = pd.read_csv（&#39;/path/file.csv&#39;，
header = 0，sep =&#39;，&#39;，names = [&#39;id&#39;，&#39;text&#39;，&#39;label&#39;]）



x = tfidf_vect.fit_transform（df [&#39;text&#39;]。值）
y = df [&#39;label&#39;]。值



来自sklearn.decomposition.truncated_svd导入truncatedSVD
pca = truncatedSvd（n_components = 2）
x = pca.fit_transform（x）

a_train，a_test，b_train，b_test = train_test_split（x，y，test_size = 0.33，andural_state = 42）

从sklearn.semblection incort intim

classifier = RandomforestClassifier（n_estimators = 10）
classifier.fit（a_train，b_train）
预测= classifier.predict（a_test）

来自sklearn.metrics.metrics导入precision_score，recker_score，confusion_matrix，classification_report
打印&#39;\ nscore：&#39;，classifier.score（a_train，b_test）
打印&#39;\ nprecision：&#39;，precision_score（b_test，预测）
打印&#39;\ nRecall：&#39;，recker_score（b_test，预测）
打印&#39;\ n confussion矩阵：\ n&#39;，confusion_matrix（b_test，预测）
打印&#39;\ n clasification报告：\ n&#39;，classification_report（b_test，预测）
 ]]></description>
      <guid>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</guid>
      <pubDate>Wed, 04 Feb 2015 05:48:35 GMT</pubDate>
    </item>
    </channel>
</rss>