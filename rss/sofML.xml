<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Mar 2024 00:57:07 GMT</lastBuildDate>
    <item>
      <title>lightfm python 依赖项使用</title>
      <link>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</link>
      <description><![CDATA[将 numpy 导入为 np
从 lightfm.datasets 导入 fetch_movielens
从 lightfm 导入 LightFM

数据 = fetch_movielens(min_ rating=4.0)

打印（repr（数据[&#39;火车&#39;]））
打印（repr（数据[&#39;测试&#39;]））

模型 = LightFM(损失=&#39;扭曲&#39;)

model.fit(data[&#39;train&#39;], epochs=30, num_threads=2)

defsample_recommendation（模型，数据，user_ids）：
    n_users, n_items = 数据[&#39;train&#39;].shape
    
    对于 user_ids 中的 user_id：
        known_positives = data[&#39;item_labels&#39;][data[&#39;train&#39;].tocsr()[user_id].indices]
        
        分数 = model.predict(user_id, np.arange(n_items))
        
        # 修复此处的标签索引
        top_items = 数据[&#39;item_labels&#39;][np.argsort(-scores)]
        
        print(&quot;用户 %s&quot; % user_id)
        print(&quot;已知的积极结果：&quot;)

        对于known_positives[:3]中的x：
            打印(“%s”%x)
            
        print(&quot;推荐：&quot;)

        # 打印最推荐的商品
        对于 top_items[:3] 中的 x：
            打印(“%s”%x)
            
样本推荐（模型，数据，[3,10,56]）


如果我运行我的代码，只输出电影标题的第一个字母，它应该是完整的电影标题，如何修复它？
我问过ai其中一个chat gpt，他们给出代码建议后，代码仍然不起作用，只显示每部电影的第一个字母。]]></description>
      <guid>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</guid>
      <pubDate>Thu, 21 Mar 2024 23:44:11 GMT</pubDate>
    </item>
    <item>
      <title>轨迹和位置算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78202619/algorithm-for-trajectory-and-position</link>
      <description><![CDATA[我正在尝试创建一个项目，计划使用某种类型的相机拍摄地面的高 fps (100-200) 照片，然后将这些照片相互比较，以提取运动信息，例如x,y 坐标、速度和距离。
我正在考虑光流，但是还有其他方法可以解决这个问题吗？
速度永远不会超过 5m/s，但精度要求很高。]]></description>
      <guid>https://stackoverflow.com/questions/78202619/algorithm-for-trajectory-and-position</guid>
      <pubDate>Thu, 21 Mar 2024 20:26:00 GMT</pubDate>
    </item>
    <item>
      <title>调整用于异常检测的 KNN 算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</link>
      <description><![CDATA[我正在尝试使用 k 最近邻 (KNN) 算法在时间序列数据集中进行异常检测，其中包含工业机器的传感器读数。目标是使用 KNN 识别传感器读数中的任何异常行为，这可能表明机器中的潜在问题或故障。
数据集采用以下格式：
&lt;前&gt;&lt;代码&gt;sensor_data.csv
时间戳、温度、压力、振动
2023-03-22 09:00:00,75.2,101.3,2.1
2023-03-22 09:05:00,75.1,101.2,2.2

这是我的 Python 代码：
导入 pandas 作为 pd
从 sklearn.neighbors 导入 NearestNeighbors

# 加载数据集
Sensor_data = pd.read_csv(&#39;sensor_data.csv&#39;)
X =sensor_data[[&#39;温度&#39;,&#39;压力&#39;,&#39;振动&#39;]]

# 实现 KNN 进行异常检测
knn = 最近邻居(n_neighbors=5, metric=&#39;euclidean&#39;)
knn.fit(X)
距离，索引 = knn.kneighbors(X)

这就是我陷入困境的地方：

如何确定此特定场景中邻居数量 (k) 的最佳值？
欧几里得距离度量是此类数据的最佳选择，还是应该考虑其他距离度量？如果有，是哪些以及为什么？
根据 KNN 返回的距离和索引，如何有效识别和处理传感器读数中的异常情况？
]]></description>
      <guid>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</guid>
      <pubDate>Thu, 21 Mar 2024 20:09:04 GMT</pubDate>
    </item>
    <item>
      <title>输入形状如何改变模型架构？</title>
      <link>https://stackoverflow.com/questions/78202453/how-does-the-input-shape-change-model-architecture</link>
      <description><![CDATA[在以下两种情况下我得到不同的结果：
示例 1：训练数据具有形状（batch_size，n_steps），模型为：
model_dense = tf.keras.Sequential([
   tf.keras.layers.Dense(1)
]）

示例 2：我的训练数据具有形状 (batch_size, n_steps, 1)，模型具有形状
model_dense = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=[n_steps, 1]),
    tf.keras.layers.Dense(1)
]）


示例 2 的训练效果要好得多。两个模型都有 n_steps+1 个可训练参数，我认为示例 2 的展平层只会展平通道维度，因此使其等同于示例 1。我认为我错过了一些简单的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78202453/how-does-the-input-shape-change-model-architecture</guid>
      <pubDate>Thu, 21 Mar 2024 19:43:55 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Ridge 和 Lasso 回归处理数据集中潜在的多重共线性？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</link>
      <description><![CDATA[包含各种房屋信息的数据集，包括其大小、卧室数量、浴室数量、年龄和相应的销售价格。目标是建立一个线性回归模型，可以根据这些自变量准确预测房屋的销售价格，同时考虑数据中潜在的多重共线性。
数据集以下格式：
house_data.csv
面积、卧室、浴室、年龄、价格
2500,4,3,25,550000
3000,3,2,15,625000
导入 pandas 作为 pd
从 sklearn. Linear_model 导入 LinearRegression、Ridge、Lasso
从 sklearn.model_selection 导入 train_test_split

# 加载数据集
house_data = pd.read_csv(&#39;house_data.csv&#39;)
X = house_data[[&#39;尺寸&#39;, &#39;卧室&#39;, &#39;浴室&#39;, &#39;年龄&#39;]]
y = house_data[&#39;价格&#39;]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准线性回归
Linear_reg = 线性回归()
Linear_reg.fit(X_train, y_train)
Linear_score = Linear_reg.score(X_test, y_test)
print(f&#39;标准线性回归分数：{linear_score}&#39;)

虽然上面的代码适用于标准线性回归，但我正在努力解决以下问题：

如何确定岭回归中正则化参数 (alpha) 的最佳值？
如何在处理数据集中的多重共线性的同时有效实施 Lasso 回归？
]]></description>
      <guid>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</guid>
      <pubDate>Thu, 21 Mar 2024 18:51:40 GMT</pubDate>
    </item>
    <item>
      <title>找到每个类别的图像原型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78200700/find-the-image-prototypes-for-each-class</link>
      <description><![CDATA[我尝试实现一种方法，该方法采用所有图像特征和相应的标签来为每个类生成图像原型。我在网上搜索过，但找不到任何教程或可用代码来验证我所做的是否正确。
此外，我尝试计算加权图像原型，其中每个图像都有自己的权重。但是，我仍然不确定这种方法是否准确。
labels = torch.arange(num_classes)
weights = torch.tesnor([......]) ## 大小 N 的权重 = num_images
类均值 = []
对于可用标签中的 i：
    idx = (伪标签 == i)
    样本计数 = idx.float().sum().item()
    如果样本数&gt; 0.0：
        壮举=特征[idx]
        class_emebdding = torch.sum(feat*weights[idx],dim=0)
        class_emebdding /= class_emebdding.norm()
原型 = torch.stack(class_means, 0)
]]></description>
      <guid>https://stackoverflow.com/questions/78200700/find-the-image-prototypes-for-each-class</guid>
      <pubDate>Thu, 21 Mar 2024 14:31:36 GMT</pubDate>
    </item>
    <item>
      <title>在基于品种的作物产量预测模型中找到每个品种的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</link>
      <description><![CDATA[我一直在使用回归研究田间作物的产量预测模型。我的输入特征包括 30 多个特定于作物的变量，这些变量是我使用 Google Earth Engine 针对每个由单个多边形标记的田地得出的。我还通过调查了解了每块田地种植的农作物的品种（具体是两种类型）。我想了解每个品种的模型准确性如何。我们以后如何确定模型对每个品种的准确性？
品种 1 - 有 100 个样品
品种 2 - 有 60 个样品
我正在考虑做这样的事情：

如果我遵循 70-30% 的分割，我就有 48 个测试样本。根据每个样本绘制预测产量。
根据多样性将样本分为几类。
通过找出误差差异来计算每个类别的 RMSE/MAE。

我不太确定这种方法。有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</guid>
      <pubDate>Thu, 21 Mar 2024 12:40:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 Tensorflow 时 Python 产生的结果比 kotlin 更准确？</title>
      <link>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</link>
      <description><![CDATA[我正在制作一个应用程序，它将检测不同数字系统中不同的手写数学表达式。截至目前，阻碍任何进展的主要因素是 kotlin 在使用 Tensorflow lite 时产生的不准确性 - 大约 10% 正确。我的 Python 代码非常相似，但它使用常规张量流，并且更加准确 - 大约 70% 正确。
我的想法是图像从 OpenCV Mat 转换为 Tensorbbuffer 的方式导致了一些问题，或者预处理的处理方式导致了差异。
我的代码片段如下：

提取边界矩形后，进行预处理和标准化。

val image_roi = Mat(tmp,boundRect)
Imgproc.cvtColor(image_roi, image_roi, Imgproc.COLOR_RGB2GRAY) Imgproc.GaussianBlur(image_roi, image_roi, Size(3.0,3.0), 0.0)
Imgproc.dilate(image_roi, image_roi, Imgproc.getStructuringElement(Imgproc.MORPH_RECT, Size(4.0, 4.0)))
Imgproc.threshold(image_roi, image_roi, 90.0, 255.0, Imgproc.THRESH_BINARY);
Imgproc.resize(image_roi, image_roi, 大小(28.0,28.0))
Core.normalize(image_roi, image_roi, 0.0, 255.0, Core.NORM_MINMAX);
image_roi.convertTo(image_roi, CvType.CV_8UC1)
提取.add(image_roi)


运行预测，将 OpenCV Mat 转换为 Tensorbuffer（第 3 步）

for（提取的img）{
       val 张量缓冲区 = extractBytes(img)
       val 输出 = model.process(tensorBuffer)
       valoutputFeature0=outputs.outputFeature0AsTensorBuffer
       valconf=outputFeature0.floatArray
       out += getLanguageText(conf, 数字)
 
}


将 Mat 转换为 Tensorbbuffer

私有乐趣 extractBytes(img: Mat): TensorBuffer{
        val inputFeature = TensorBuffer.createFixedSize(intArrayOf(1, 28, 28, 1), DataType.FLOAT32)
        val byteBuffer = ByteBuffer.allocateDirect(28 * 28 * 4) // 每个浮点数 4 个字节
        byteBuffer.order(ByteOrder.nativeOrder())
        byteBuffer.rewind()
 
        for (i 从 0 到 28) {
            for (j in 0 到 28) {
                val temp = img.get(i, j)[0].toFloat() // 假设单通道（灰色）
                byteBuffer.putFloat(临时)
            }
        }
 
        inputFeature.loadBuffer(byteBuffer)
        返回输入特征
    }

在下面的粘贴箱中，我也包含了我的 pythin 代码。我需要一些帮助来弄清楚为什么我的模型无法通过 Kotlin 准确预测，但可以通过 Python 准确预测。
https://pastebin.com/BACzTkq6
以下是在 Python 和 Kotlin 中使用相同图像的差异示例：
通过 Kotlin 显示预测的图像
通过 python 显示预测的图像
我尝试了将 Matrix 转换为 Tensorbuffer 的不同方法，我尝试删除大部分（如果不是全部）图像预处理，我尝试让 python 在 Android studio 中工作（但这并没有成功。）]]></description>
      <guid>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</guid>
      <pubDate>Thu, 21 Mar 2024 11:18:54 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 矩阵乘法形状错误：“RuntimeError：mat1 和 mat2 形状无法相乘”</title>
      <link>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</link>
      <description><![CDATA[我是 PyTorch 的新手，正在创建一个多输出线性回归模型，根据字母为单词着色。 （这将帮助有字素颜色联觉的人更轻松地阅读。）它接收单词并输出 RGB 值。每个单词都表示为 45 个浮点数 [0,1] 的向量，其中 (0, 1] 代表字母，0 代表该位置不存在字母。每个样本的输出应该是一个向量 [r-value, g -值，b-值]。
我懂了
&lt;块引用&gt;
运行时错误：mat1 和 mat2 形状无法相乘（90x1 和 45x3）

当我尝试在训练循环中运行我的模型时。
查看现有的 Stack Overflow 帖子，我认为这意味着我需要重塑我的数据，但我不知道如何/在哪里以解决此问题的方式进行此操作。特别是考虑到我不知道那个 90x1 矩阵来自哪里。
我的模型
我一开始很简单；在我可以让单个层发挥作用之后，可以出现多个层。
类 ColorPredictor(torch.nn.Module):
    #构造函数
    def __init__(自身):
        super(ColorPredictor, self).__init__()
        self.linear = torch.nn.Linear(45, 3, device= device) #编码词向量的长度 &amp; r,g,b 向量的大小
        
    ＃ 预言
    defforward(self, x: torch.Tensor) -&gt;;火炬.张量：
        y_pred = self.线性(x)
        返回 y_pred

我如何加载数据
# 数据集类
数据类（数据集）：
    # 构造函数
    def __init__(自身，输入，输出)：
        self.x = input # 编码词向量列表
        self.y = 输出 # 将 r、g、b 值转换为火炬张量的 Pandas 数据帧
        self.len = len(输入)
    
    # 吸气剂
    def __getitem__(自身，索引)：
        返回 self.x[索引], self.y[索引]
    
    # 获取样本数
    def __len__(自身):
        返回 self.len

# 创建训练/测试分割
train_size = int(0.8 * len(数据))
train_data = 数据(输入[:train_size], 输出[:train_size])
test_data = 数据(输入[train_size:], 输出[train_size:])

# 为训练和测试集创建 DataLoaders
train_loader = DataLoader（数据集= train_data，batch_size = 2）
test_loader = DataLoader（数据集= test_data，batch_size = 2）

发生错误的测试循环
对于范围内的纪元（纪元）：
    ＃ 火车
    model.train() #训练模式
    对于 train_loader 中的 x,y：
        y_pred = model(x) #此处错误
        损失=标准(y_pred, y)
        优化器.zero_grad()
        loss.backward()
        优化器.step()
      

错误回溯


新尝试：
将 45x1 输入张量更改为 2x45 输入张量，第二列全为零。这适用于第一次运行 train_loader 循环，但在第二次运行 train_loader 循环期间，我得到另一个矩阵乘法错误，这次是大小为 90x2 和 45x3 的矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</guid>
      <pubDate>Thu, 21 Mar 2024 01:00:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 的 Google Colab Bert 实例化错误</title>
      <link>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</link>
      <description><![CDATA[我正在尝试在 Colab 上使用 Tensorflow 构建 Bert 模型。这段代码几周前就可以完美运行。现在，如果我尝试实例化模型，则会收到以下错误：
初始化 TF 2.0 模型 TFBertModel 时未使用 PyTorch 模型的某些权重：[&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls .predictions.transform.LayerNorm.weight&#39;、&#39;cls.predictions.bias&#39;、&#39;cls.seq_relationship.bias&#39;、&#39;cls.predictions.transform.dense.bias&#39;、&#39;cls.seq_relationship.weight&#39;]
- 如果您从在其他任务或其他架构上训练的 PyTorch 模型初始化 TFBertModel（例如，从 BertForPreTraining 模型初始化 TFBertForSequenceClassification 模型），这是预期的。
- 如果您从希望完全相同的 PyTorch 模型初始化 TFBertModel（例如，从 BertForSequenceClassification 模型初始化 TFBertForSequenceClassification 模型），则不会出现这种情况。
TFBertModel 的所有权重都是从 PyTorch 模型初始化的。
如果您的任务与检查点模型训练的任务类似，您就可以使用 TFBertModel 进行预测，而无需进一步训练。
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-b0e769ef7​​890&gt;在&lt;细胞系：7&gt;()
      5 SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
      6 SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
----&gt; 7 SC_pooler_output = SC_bert_model(SC_input_layer, Attention_mask=SC_mask_layer)[1] # 第二个输出，che è il pooler_output
      8
      9 # 辍学层的Aggiungi

36帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py 在 type_spec_from_value(value) 中
   1002 3，“无法将 %r 转换为张量：%s” % (类型(值).__name__, e))
   1003
-&gt;第1004章
   第1005章 1005
   1006

TypeError：调用层“嵌入”时遇到异常（类型 TFBertEmbeddings）。

无法为名称构建 TypeSpec：“tf.debugging.assert_less_5/assert_less/Assert/Assert”
op：“断言”
输入：“tf.debugging.assert_less_5/assert_less/All”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_0”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_1”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_2”
输入：“占位符”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_4”
输入：“tf.debugging.assert_less_5/assert_less/y”
属性{
  键：“总结”
  价值 {
    我：3
  }
}
属性{
  键：“T”
  价值 {
    列表 {
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_INT32
      类型：DT_STRING
      类型：DT_INT32
    }
  }
}
 不支持的类型。

调用层“embeddings”接收的参数（类型 TFBertEmbeddings）：
  • input_ids=
  •position_ids=无
  • token_type_ids=
  • input_embeds=无
  •过去的键值长度=0
  • 训练=False

模型的代码是：
SC_input_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“input_ids”)
SC_mask_layer = 输入（形状=（max_seq_length，），dtype=tf.int32，名称=“attention_mask”）
SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
SC_pooler_output = SC_bert_model（SC_input_layer，attention_mask = SC_mask_layer）[1]

# Dropout 层的Aggiungi
SC_dropout_layer = Dropout(dropout_rate)(SC_pooler_output)
SC_output_layer = 密集（6，激活=&#39;sigmoid&#39;）（SC_dropout_layer）
SC_model = 模型(输入=[SC_input_layer, SC_mask_layer], 输出=SC_output_layer)

我发现安装tensorflow 2.10.0可以工作，但是使用Google Colab时我的CUDA版本有问题，并且使用tensorflow 2.10它无法识别GPU。
该代码几周前就可以工作，有人有解决方案吗？
编辑：Kaggle 上也出现同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</guid>
      <pubDate>Sun, 17 Mar 2024 17:03:42 GMT</pubDate>
    </item>
    <item>
      <title>我的 python DBSCAN 工作流程是否可以正确识别具有相似用户评分和流派概况的用户？生成水平状图</title>
      <link>https://stackoverflow.com/questions/77527379/is-my-python-dbscan-workflow-correct-for-identifying-users-that-have-similar-use</link>
      <description><![CDATA[水平图
导入请求
将 pandas 导入为 pd
从 sklearn.cluster 导入 DBSCAN
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.pipeline 导入管道
从 sklearn.decomposition 导入 PCA
将 matplotlib.pyplot 导入为 plt

# 数据帧结构

|标题 |用户评分 |类型 |

# One-Hot 编码 Genre 列（有很多流派）

Anime_dataframe_encoded = pd.get_dummies(anime_dataframe_separated, columns=[&#39;流派&#39;], prefix=&#39;流派&#39;)

Anime_dataframe_encoded = Anime_dataframe_encoded.groupby([&#39;标题&#39;,&#39;分数&#39;]).sum().reset_index()
Anime_dataframe_features = Anime_dataframe_encoded.drop(&#39;标题&#39;, axis=1)


定标器=标准定标器()
Anime_dataframe_scaled = 缩放器.fit_transform(anime_dataframe_features)

pca = PCA(n_components=1)
reduce_features = pca.fit_transform(anime_dataframe_scaled)

dbscan = DBSCAN(eps=0.5, min_samples=5)
标签 = dbscan.fit_predict(reduced_features)

# 可视化结果
plt.figure(figsize=(8, 8))
plt.scatter(reduced_features[:, 0], 标签, c=标签, cmap=&#39;viridis&#39;, s=50)
plt.title(&#39;DBSCAN 聚类结果&#39;)
plt.xlabel(&#39;主成分 1&#39;)
plt.ylabel(&#39;簇标签&#39;)
plt.show()



我只有 1 个用户的列表。但这是正确的前进道路吗？我在 DBSCAN 中看到的图像是甜甜圈形状，这很可能是由于大量数据（我需要添加更多用户列表）。但是，我不确定我所做的是否正确，因为我是初学者。]]></description>
      <guid>https://stackoverflow.com/questions/77527379/is-my-python-dbscan-workflow-correct-for-identifying-users-that-have-similar-use</guid>
      <pubDate>Wed, 22 Nov 2023 04:45:38 GMT</pubDate>
    </item>
    <item>
      <title>一种计算给定数据集中给定属性的循环数的方法</title>
      <link>https://stackoverflow.com/questions/77524730/a-way-to-count-the-number-of-cycles-of-an-given-attribute-in-a-given-dataset</link>
      <description><![CDATA[我想找到给定的电机故障电流数据集中的周期数，它是由在不同时间测量的电机电流给出的，我想知道它是否可以被视为一个信号或者它只是一个信号模式？
电机故障电流
我尝试了一些库，但它们适用于不同的条件，例如它们对所使用的信号有零交叉点，并且我找不到可以为此变成零交叉的点，因为电机电流始终为+ve并且因此它只是随着时间的推移而稍微波动，因此我得到了一个情节
data = pd.read_csv(“healthy.csv”)
y = np.array(data.Current_A)
x = 数据.索引
date_array = pd.array(data.TimeStamp)
plt.plot(日期数组,y)

我在这里使用了 3ph 健康电机电流数据集，有一件事，该数据集有空格作为“”当前-A” ，应固定为“Current_A”]]></description>
      <guid>https://stackoverflow.com/questions/77524730/a-way-to-count-the-number-of-cycles-of-an-given-attribute-in-a-given-dataset</guid>
      <pubDate>Tue, 21 Nov 2023 17:18:31 GMT</pubDate>
    </item>
    <item>
      <title>如何将Polygon格式转换为YOLO格式</title>
      <link>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</link>
      <description><![CDATA[多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
这是 POLYGON 中的边界框
我想要 YOLO v5 格式的
导入日志记录
从 pathlib 导入路径
将 pandas 导入为 pd
从 shapely.wkt 导入负载
yolo_output_dir = 路径(“my_yolo”)
yolo_output_dir.mkdir（父母=真，exist_ok=真）
df = (pd
      .read_csv(&#39;images_bboxes.csv&#39;)
      .fillna(值={&#39;几何&#39;: &#39;2&#39;}))

蠕虫类型 = {
    y: x for (x, y) in enumerate(df[&#39;worm_type&#39;].unique())
}
记录.关键（worm_types）

对于 df.groupby(&#39;image_id&#39;, sort=False) 中的 (i, g)：
    dst = yolo_output_dir.joinpath(i).with_suffix(&#39;.txt&#39;)
    日志记录.警告（dst）
    以 dst.open(&#39;w&#39;) 作为 fp：
        对于 g.itertuples(index=False) 中的 i：
            如果我.几何：
                蠕虫 = 蠕虫_类型[i.蠕虫_类型]
                几何=载荷（i.几何）
                (minx, miny, maxx, maxy) = 几何.边界
                (w, h) = (maxx - minx, maxy - miny)
                打印（蠕虫，minx，miny，w，h，文件= fp）

这是我尝试过的代码，但它给出了错误的坐标..
多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
被转换为
0 389.0 1552.0 160.0 165.0
这是错误的]]></description>
      <guid>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</guid>
      <pubDate>Tue, 01 Nov 2022 13:15:07 GMT</pubDate>
    </item>
    <item>
      <title>Altair 中具有自定义置信区间的折线图</title>
      <link>https://stackoverflow.com/questions/60649486/line-chart-with-custom-confidence-interval-in-altair</link>
      <description><![CDATA[假设我有下面的数据框：

我检查了文档，但它仅基于单个列。 
可重现的代码：
x = np.random.normal(100,5,100)
数据 = pd.DataFrame(x)
ε = 10
数据.列 = [&#39;x&#39;]
数据[&#39;下&#39;] = x - epsilon
数据[&#39;上&#39;] = x + epsilon
数据


我实际上很想使用 Altair，因为我喜欢它的交互性。]]></description>
      <guid>https://stackoverflow.com/questions/60649486/line-chart-with-custom-confidence-interval-in-altair</guid>
      <pubDate>Thu, 12 Mar 2020 07:37:09 GMT</pubDate>
    </item>
    <item>
      <title>Keras：打印出预测的类标签</title>
      <link>https://stackoverflow.com/questions/59910151/keras-printing-out-the-predicted-class-label</link>
      <description><![CDATA[我正在测试基于 cifar10 keras 数据集的 CNN 模型。所以，基本上
预测 = mymodel.predict(x)
打印（预测）

打印出预测本身：

&lt;预&gt;&lt;代码&gt;[[3.3675440e-04 5.7650192e-07 2.5850117e-02 5.4446888e-01 7.0444457e-02
  1.7459875e-01 3.5874096e-03 1.8062484e-01 1.2066155e-06 8.6996079e-05]]

给定 cifar10 类标签，正确的语法是什么
classes = [&#39;飞机&#39;, &#39;汽车&#39;, &#39;鸟&#39;, &#39;猫&#39;, &#39;鹿&#39;, &#39;狗&#39;, &#39;青蛙&#39;, &#39;马&#39;, &#39;船&#39;, &#39;卡车&#39;]

打印预测标签？]]></description>
      <guid>https://stackoverflow.com/questions/59910151/keras-printing-out-the-predicted-class-label</guid>
      <pubDate>Sat, 25 Jan 2020 14:28:07 GMT</pubDate>
    </item>
    </channel>
</rss>