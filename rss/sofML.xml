<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 15 Feb 2024 03:16:20 GMT</lastBuildDate>
    <item>
      <title>在神经网络中运行 train 方法时将 PNG 图像转换为 np.array</title>
      <link>https://stackoverflow.com/questions/77998036/converting-a-png-image-to-a-np-array-while-running-the-train-method-in-a-neural</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77998036/converting-a-png-image-to-a-np-array-while-running-the-train-method-in-a-neural</guid>
      <pubDate>Thu, 15 Feb 2024 01:22:49 GMT</pubDate>
    </item>
    <item>
      <title>集合预测中要缩放什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77997900/what-to-scale-in-ensemble-predictions</link>
      <description><![CDATA[我正在使用堆叠集成方法进行股票预测，但不知道什么和什么不应该扩展。预测训练和测试都是在 x 训练和测试上进行缩放的。我也不知道验证集应该在训练集还是测试集上。
这是代码：
feature_scaler = MinMaxScaler(feature_range=(0, 1))
    Predictions_train_scaled = feature_scaler.fit_transform(predictions_train)
    Predictions_test_scaled = feature_scaler.transform(predictions_test)

    target_scaler = MinMaxScaler(feature_range=(0, 1))
    y_train_shape = y_train.values.reshape(-1, 1)
    y_train_scaled = target_scaler.fit_transform(y_train_shape)
    y_test_shape = y_test.values.reshape(-1, 1)
    y_test_scaled = target_scaler.transform(y_test_shape)


    X_train_meta, y_train_meta_un = train_test_split(predictions_train_scaled,
    y_train_scaled、test_size=0.2、random_state = 1）
    X_val_meta, y_val_meta_un = train_test_split(predictions_test_scaled, y_test_scaled,
    测试大小=0.3，随机状态=1）

    y_train_meta = y_train_meta_un.reshape(-1, 1)
    y_val_meta = y_val_meta_un.reshape(-1, 1)

    #meta_model = 线性回归()
    meta_model = MLPRegressor(hidden_​​layer_sizes=(100, 50)，激活=&#39;relu&#39;，求解器=&#39;adam&#39;，alpha=0.001，random_state=42，max_iter=5000)
    meta_model.fit(X_train_meta, y_train_meta.ravel())

    train_meta_score = meta_model.score(X_train_meta, y_train_meta)
    print(f&quot;元模型训练分数：{train_meta_score}&quot;)
    
    val_score = meta_model.score(X_val_meta, y_val_meta)
    print(f“元模型验证分数：{val_score}”)

    cv_scores = cross_val_score(meta_model, X_train_meta, y_train_meta.ravel(), 评分=&#39;neg_mean_squared_error&#39;, cv=5)
    cv_rmse = np.sqrt(-cv_scores)
    print(f&quot;交叉验证 RMSE: {cv_rmse.mean()}&quot;)

    #predictions_test_scaled = feature_scaler.transform(predictions_test)
    stacked_predictionss = meta_model.predict(predictions_test_scaled)

    stacked_predictions = target_scaler.inverse_transform(stacked_predictionss.reshape(-1, 1))

    返回 stacked_predictions, stacked_predictionss
]]></description>
      <guid>https://stackoverflow.com/questions/77997900/what-to-scale-in-ensemble-predictions</guid>
      <pubDate>Thu, 15 Feb 2024 00:32:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 和 NLP 进行实体活动字段检测</title>
      <link>https://stackoverflow.com/questions/77997504/entity-activity-field-detection-using-python-and-nlp</link>
      <description><![CDATA[我有一个时间有限的项目，从 csv 文件中获取/提取公司名称列表，在 google 上搜索以将每个名称与搜索结果匹配以找到其官方网址，然后提取网址（对于每个公司的数量）并将其存储在数据框中。然后利用 NLP 模型编写另一个脚本来抓取每个网站，并从其 url 中提取地址、员工人数、公司业务类型以及有关公司的其他相关信息，然后将提取的数据存储在更新的数据框中进一步分析。为了保持一致性，该实体流程必须自动化到管道中，以防不时注入新公司名称。我迫切需要帮助来完成这个项目。
我尝试编写一个谷歌搜索脚本来搜索和提取网址，但它没有产生预期的结果。]]></description>
      <guid>https://stackoverflow.com/questions/77997504/entity-activity-field-detection-using-python-and-nlp</guid>
      <pubDate>Wed, 14 Feb 2024 22:24:30 GMT</pubDate>
    </item>
    <item>
      <title>奇怪（？）PySpark 的 OneHotEncoder 行为</title>
      <link>https://stackoverflow.com/questions/77997400/strange-pysparks-onehotencoder-behavior</link>
      <description><![CDATA[我尝试使用 PySpark 的 OneHotEncoder 构建 ML 管道，但我注意到使用“handleInvalid”函数会出现奇怪的行为。 param：当我使用 handleInvalid=“error” 时，我得到 5 个类别，但是当我使用 handleInvalid=“keep” 时，我得到 6 个类别。请参阅下面的示例：
导入操作系统
从 alura_spark.config 导入 configure_spark_env

从 pyspark.sql 导入 SparkSession
从 pyspark.ml.feature 导入 StringIndexer、OneHotEncoder
从 pyspark.ml 导入管道


config_root_dir = os.path.abspath(&#39;.&#39;)
配置_spark_env（root_dir = config_root_dir）

# 启动 SparkSession
火花=（
    SparkSession.builder
    .master(“本地[*]”)
    .appName(“回归模型”)
    .config(“spark.ui.port”,“4050”)
    .getOrCreate()
）
火花

# 创建一个带有分类列的示例 DataFrame
数据=[(“A”,),(“B”,),(“C”,),(“D”,),(“E”,),
        (“A”，)，(“B”，)，(“C”，)，(“D”，)，(“E”，)，
        (“A”,)、(“B”,)、(“C”,)、(“D”,)、(“E”,)]
列 = [“类别”]
df = Spark.createDataFrame(数据, 列)

def apply_pipeline（df，categorical_column，handle_invalid）：
    # StringIndexer 处理新类别
    索引器= StringIndexer(inputCol=categorical_column,outputCol=f“{categorical_column}_index”,handleInvalid=handle_invalid)

    # OneHotEncoder 转换索引类别
    编码器 = OneHotEncoder(inputCols=[f&quot;{categorical_column}_index&quot;], outputCols=[f&quot;{categorical_column}_onehot&quot;], dropLast=True)

    # 管道到链的转换
    管道=管道（阶段=[索引器，编码器]）

    # 拟合并转换 DataFrame
    pipeline_model = pipeline.fit(df)
    df_transformed = pipeline_model.transform(df)

    n_categories = pipeline_model.stages[-1].categorySizes
    打印（&#39;＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃&#39;）
    print(f&quot;n_categories with handleInvalid=&#39;{handle_invalid}&#39; = {n_categories}&quot;)
    df_transformed.show(5)
    打印（&#39;＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃&#39;）

    返回 df_transformed

# 使用handleInvalid=&#39;keep&#39;应用管道
df_transformed_keep = apply_pipeline(df, “类别”, “保留”)

# 应用带有handleInvalid=&#39;error&#39;的管道
df_transformed_error = apply_pipeline(df, “类别”, “错误”)

#spark.stop()

其中 configure_spark_env 只是我用来设置 JAVA_HOME、SPARK_HOME、HADOOP_HOME 和  的函数LD_LIBRARY_PATH 环境变量。
运行上面的代码我得到：
&lt;前&gt;&lt;代码&gt;######################################
n_categories with handleInvalid=&#39;keep&#39; = [6]
+--------+--------------+----------------+
|类别|category_index|category_onehot|
+--------+--------------+----------------+
|一个| 0.0| (5,[0],[1.0])|
|乙| 1.0| (5,[1],[1.0])|
| C| 2.0| (5,[2],[1.0])|
| D| 3.0| (5,[3],[1.0])|
|电子| 4.0| (5,[4],[1.0])|
+--------+--------------+----------------+
只显示前 5 行

######################################
######################################
n_categories with handleInvalid=&#39;error&#39; = [5]
+--------+--------------+----------------+
|类别|category_index|category_onehot|
+--------+--------------+----------------+
|一个| 0.0| (4,[0],[1.0])|
|乙| 1.0| (4,[1],[1.0])|
| C| 2.0| (4,[2],[1.0])|
| D| 3.0| (4,[3],[1.0])|
|电子| 4.0| (4,[],[])|
+--------+--------------+----------------+
只显示前 5 行

######################################

我正在使用以下版本：
&lt;前&gt;&lt;代码&gt;PySpark：3.5.0
JDK：17.0.10
Hadoop：3.3.6
火花：3.5.0
流行操作系统：22.04

由于我在拟合和转换中使用相同的数据，因此我期望使用“keep”或“error”获得 5 个类别。这是我将 sklearn 的 OHE 与 handle_unknow=&#39;ignore&#39; 一起使用时得到的行为。]]></description>
      <guid>https://stackoverflow.com/questions/77997400/strange-pysparks-onehotencoder-behavior</guid>
      <pubDate>Wed, 14 Feb 2024 21:53:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LoRA 微调 ControlNet？</title>
      <link>https://stackoverflow.com/questions/77997278/how-to-fine-tune-controlnet-using-lora</link>
      <description><![CDATA[我想使用 LoRA 适配器微调 ControlNet。我的数据集由成对图像组成 - 分割图（没有家具的房间，只有墙壁、地板、窗户、门） - RGB 图像（有家具的房间）。我的目标是微调 ControlNet 以根据空房间的分割图生成带家具的房间（我使用空提示）
所以，我不太清楚如何训练 LoRA。我考虑了两个选择

训练 LoRA 进行稳定扩散（仅使用带家具的房间图像作为数据集），然后将此稳定扩散注入 ControlNet

例如，如果我使用这个管道
管道 = StableDiffusionControlNetPipeline.from_pretrained(
    “runwayml/stable-diffusion-v1-5”，controlnet=controlnet，torch_dtype=torch.float16
）

然后将“runwayml/stable-diffusion-v1-5”替换为与我精心调校的 LoRA 一起。这是正确的做法吗？如果我仅微调稳定扩散并且不显示我的分割图，ControlNet 是否能够生成房间？

在图像对上训练 LoRA for ControlNet。
然而，我读到 Huggingface 不支持为 ControlNet 训练 LoRA（所有教程仅展示如何训练稳定扩散）。但我找到了文章
https://fangchuan.github.io/ctrl-room.github.io/&lt; /a&gt;
作者对 ControlNet 进行了微调以生成房间全景图（但文章没有提供技术细节），因此我认为可以直接为 ControlNet 训练 LoRA

那么什么方法来微调 ControlNet 是普遍可以接受的呢？]]></description>
      <guid>https://stackoverflow.com/questions/77997278/how-to-fine-tune-controlnet-using-lora</guid>
      <pubDate>Wed, 14 Feb 2024 21:19:17 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow自定义损失函数在直接调用时有效，但在拟合时给出错误</title>
      <link>https://stackoverflow.com/questions/77997255/tensorflow-custom-loss-function-works-when-called-directly-but-gives-error-when</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77997255/tensorflow-custom-loss-function-works-when-called-directly-but-gives-error-when</guid>
      <pubDate>Wed, 14 Feb 2024 21:14:09 GMT</pubDate>
    </item>
    <item>
      <title>有没有方法可以识别 XGBoost 树适合哪个数据子样本？</title>
      <link>https://stackoverflow.com/questions/77997182/are-there-ways-to-identify-which-subsample-of-data-an-xgboost-tree-was-fitted-on</link>
      <description><![CDATA[我想确定为每棵树的训练随机选择哪些特定的样本行（根据子样本参数）。例如，训练集有 100 行，子采样率为 0.7，我想知道为每棵树的训练选择的确切 70 行。我一直在到处寻找解决方案，但没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/77997182/are-there-ways-to-identify-which-subsample-of-data-an-xgboost-tree-was-fitted-on</guid>
      <pubDate>Wed, 14 Feb 2024 20:58:25 GMT</pubDate>
    </item>
    <item>
      <title>Bagging 和 OOB 分配出现问题</title>
      <link>https://stackoverflow.com/questions/77997095/trouble-with-bagging-and-oob-assignment</link>
      <description><![CDATA[我正在学习 ML 课程，这是我的第一门课程，我是 ML 新手，并且我一直在做一些作业。我对其中一个有关装袋和 OOB 的问题有疑问
我必须填写下面代码中的行。这是 sklearn 的 BaggingRegressor 的简化版本。请注意，sklearn API 未保留。
该算法应该能够在引导数据集上训练同一模型类的不同实例，并为训练集提供 OOB 分数。
模型应作为模型类传递，没有显式参数，也没有括号。
虽然我已经有了 _generate_splits() 函数，但我仍然在努力解决其余的问题。
谁能告诉我这些函数的公式是什么？
将 numpy 导入为 np
`SimplifiedBaggingRegressor 类：
def __init__(self, num_bags, oob=False):
    self.num_bags = num_bags
    self.oob = oob
    
def _generate_splits(self, 数据: np.ndarray):
    &#39;&#39;&#39;
    为每个包生成索引并存储在 self.indices_list 列表中
    &#39;&#39;&#39;
    self.indices_list = []
    数据长度 = len(数据)
    对于范围内的包（self.num_bags）：
        # 这里是你的代码
                  bag_indices = list(范围(0,total_samples))
        self.indices_list.append(bag_indices)
    
def fit(自身、模型构造函数、数据、目标)：
    &#39;&#39;&#39;
    每个包袋都适合模型。
    不带参数（且不带 ()）的模型构造函数被传递给此函数。
    
    例子：
    
    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)
    bagging_regressor.fit(线性回归, X, y)
    &#39;&#39;&#39;
    self.data = 无
    自我目标=无
    self._generate_splits（数据）
    assert len(set(list(map(len, self.indices_list)))) == 1, &#39;所有袋子的长度应该相同！&#39;
    assert list(map(len, self.indices_list))[0] == len(data), &#39;所有包都应包含 `len(data)` 个元素！&#39;
    self.models_list = []
    对于范围内的包（self.num_bags）：
        模型 = model_constructor()
        data_bag, target_bag = # 这里是你的代码
        self.models_list.append(model.fit(data_bag, target_bag)) # 在此存储拟合模型
    如果是 self.oob:
        self.data = 数据
        self.target = 目标
    
def 预测（自身，数据）：
    &#39;&#39;&#39;
    从传递的数据集中获取每个对象的平均预测
    &#39;&#39;&#39;
    # 这里是你的代码

def _get_oob_predictions_from_every_model（自身）：
    &#39;&#39;&#39;
    生成列表的列表，其中列表 i 包含 self.data[i] 对象的预测
    来自所有在训练阶段没有见过这个物体的模型
    &#39;&#39;&#39;
    list_of_predictions_lists = [[] for _ in range(len(self.data))]
    # 这里是你的代码
    
    self.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)

def _get_averged_oob_predictions（自我）：
    &#39;&#39;&#39;
    计算训练集中每个对象的平均预测。
    如果训练阶段的所有包中都使用了对象，则返回 None 而不是预测
    &#39;&#39;&#39;
    self._get_oob_predictions_from_every_model()
    self.oob_predictions = # 这里是你的代码
    
    
def OOB_score(自身):
    &#39;&#39;&#39;
    计算至少有一个预测的所有对象的均方误差
    &#39;&#39;&#39;
    self._get_averged_oob_predictions()
    在此处返回#您的代码`

我试图理解原始 BaggingRegressor 类是如何工作的，但我有点困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77997095/trouble-with-bagging-and-oob-assignment</guid>
      <pubDate>Wed, 14 Feb 2024 20:35:59 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中的高损失</title>
      <link>https://stackoverflow.com/questions/77996298/high-loss-in-diffusion-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77996298/high-loss-in-diffusion-model</guid>
      <pubDate>Wed, 14 Feb 2024 17:41:48 GMT</pubDate>
    </item>
    <item>
      <title>UndefinedMetricWarning：精度定义不明确，由于没有预测样本而被设置为 0.0 [重复]</title>
      <link>https://stackoverflow.com/questions/77995496/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-due-to-no</link>
      <description><![CDATA[当我尝试拟合 X 和 Y 训练集时，它会向我发出警告消息：
UndefinedMetricWarning：精度定义不明确，由于没有预测样本而被设置为 0.0。使用“zero_division”参数来控制此行为。 _warn_prf(平均值，修饰符，f“{metric.capitalize()}是”，len(结果))
这导致我的精确率、召回率和 F1 分数为 0。但是添加后
average=&#39;weighted&#39; 和 labels，它产生了可用的分数：
f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;, labels=np.unique(y_pred))

但是我的问题是我的 Y_pred 保持不变，每当我制作 ConfusionMatrix 时，它都会显示有 0 个 True 或 False Positive。有没有办法改变我的 Y_pred，以反映我修正的分数？
如上所述，我修复了分数，但 Y_pred 仍然不变。]]></description>
      <guid>https://stackoverflow.com/questions/77995496/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-due-to-no</guid>
      <pubDate>Wed, 14 Feb 2024 15:37:39 GMT</pubDate>
    </item>
    <item>
      <title>一类 SVM - 测试集上的异常值相对于训练集非常低</title>
      <link>https://stackoverflow.com/questions/77995464/one-class-svm-outliers-on-test-set-very-low-relative-to-training-set</link>
      <description><![CDATA[我正在使用 scikit-learn 一类 SVM 进行异常值检测。但相对于训练集，测试集上检测到的异常值数量非常少。
单类 SVM 的每个输入都是三个浮点数 [float1、float2、float3] 的列表。
所有列都使用最小-最大缩放比例缩放为 0 到 1 之间的值。
我按如下方式初始化并拟合 SVM：
clf = OneClassSVM(kernel=&#39;线性&#39;, nu=0.01, gamma=&#39;auto&#39;).fit(training_and_testing_sets[:TRAINING_SET_SIZE])

因为我对 nu 使用了 0.01 的值。我预计测试集上的异常值数量为整个测试集的 1%。但它是 0.004%。测试集也相应地缩放。
造成这种差异的原因是什么以及如何解决该问题？]]></description>
      <guid>https://stackoverflow.com/questions/77995464/one-class-svm-outliers-on-test-set-very-low-relative-to-training-set</guid>
      <pubDate>Wed, 14 Feb 2024 15:33:33 GMT</pubDate>
    </item>
    <item>
      <title>NLP 中的搜索、NER 和关系提取用例</title>
      <link>https://stackoverflow.com/questions/77992256/search-ner-and-relation-extraction-use-case-in-nlp</link>
      <description><![CDATA[我正在尝试对维基百科的文本创建 NER 和摘要。我正在使用维基页面中的文本： https://en.wikipedia.org/wiki/Hyderabad&lt; /a&gt;
下面是我的代码：
from txtai.embeddings import Embeddings
导入系统
将渐变导入为 gr
导入spacy
从字符串导入标点符号


# 创建嵌入模型，由句子转换器和句子转换器支持变形金刚
嵌入=嵌入（{“路径”：“../Lib/site-packages/all-MiniLM-L6-v2”}）

f = open(&#39;海得拉巴.txt&#39;, &#39;r&#39;, 编码=&#39;ISO-8859-1&#39;)
data = f.read().split(“.”)

# 为文本列表建立索引
嵌入.index（数据）

def 搜索（查询）：
    uid = embeddings.search(查询, 1)[0][0]
    返回数据[uid]

def 响应（问题）：
    合并=搜索（问题）
    ans = 代词_coref(合并)
    返回答案

演示 = gr. 接口(
    fn=响应，
    输入=[“文本”]，
    输出=[“文本”]，
）
演示.launch(share=False)

搜索：什么是 Purana pul？
响应：两者之间由许多跨河桥梁连接，其中最古老的是 Purana Pul（“老桥”），建于公元 1578 年。
我想加强对以下内容的响应：旧城和新城由许多横跨穆西河的桥梁连接起来，其中最古老的是 Purana Pul（“旧桥”），建于公元 1578 年.
NER 可以通过 en_core_web_md 模型完成。
如何在响应中将代词替换为适当的名词？]]></description>
      <guid>https://stackoverflow.com/questions/77992256/search-ner-and-relation-extraction-use-case-in-nlp</guid>
      <pubDate>Wed, 14 Feb 2024 05:33:45 GMT</pubDate>
    </item>
    <item>
      <title>三重态损失时间序列</title>
      <link>https://stackoverflow.com/questions/77879087/triplet-loss-time-series</link>
      <description><![CDATA[我正在阅读这篇论文，我想知道三重态损失在一般情况下是如何工作的时间序列、正样本和上下文。
假设我们有一个包含 3 个样本、一个特征和序列长度为 6 的数据集，如下所示：
&lt;前&gt;&lt;代码&gt;y1 = [1,3,4,7,5,2]
y2 = [1,2,3,4,5,6]
y3 = [9,8,4,6,2,1]

如果我遵循给定论文的逻辑，三元组将生成如下：
s_i = 6 # yi 的长度
s_pos = 3 # 随机长度
s_ref = 3+2 # s_pos 和 之间随机s_i

x_ref = [1,2,3,4,5]
x_pos = [2,3,4]

...
x_1_neg = [3,4,7]

现在为了减少损失，我们希望找到给定锚点 x_ref 的 x_pos。
但是，编码器找到正确的对不是很容易吗？因为 x_pos 包含在 x_ref 中，而 x_1_neg 则不包含？仅向编码器提供 x_pos 周围的上下文（例如 [1,...,5]）不是更有意义吗？]]></description>
      <guid>https://stackoverflow.com/questions/77879087/triplet-loss-time-series</guid>
      <pubDate>Thu, 25 Jan 2024 10:13:24 GMT</pubDate>
    </item>
    <item>
      <title>Wandb：如何在高级图例部分显示分组平均值</title>
      <link>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-average-in-the-advanced-legend-section</link>
      <description><![CDATA[我正在努力记录我的种子机器学习训练的等待和偏差，我可以看到我所做的事情的良好可视化。
在高级图例部分我可以看到。
[[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName}

当我悬停时，[[ ${mean} σ ${stddev} (${min}, ${max}) ]] 部分可见。
如何将此值附加到如下所示的文本
[[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName} - ${mean} σ ${stddev}

感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-average-in-the-advanced-legend-section</guid>
      <pubDate>Mon, 22 Jan 2024 09:41:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 MLP 分类器，少数类精度、召回率、fscore 全部变为零</title>
      <link>https://stackoverflow.com/questions/75389106/minority-class-precision-recall-fscore-all-become-zero-with-mlp-classifier</link>
      <description><![CDATA[我使用 SkLearn 上提供的 MLP 分类器训练了我的模型。
我使用代码分割数据
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size=0.3、stratify=y、random_state=1)

X_train 长度 = 9405
y_train = 0: 7562, 1: 1843 的类别分布
X_测试长度 = 4032
y_test 的类别分布 = 0: 3242, 1: 790

MLP分类器的代码是
MLP = MLPClassifier(random_state=1,learning_rate =“constant”,learning_rate_init=0.3,momentum = 0.2)
MLP.fit(X_train, y_train)
R_y_pred = MLP.predict(X_test)
target_names = [&#39;否&#39;, &#39;是&#39;]
打印（分类报告（y_test，R_y_pred，target_names = target_names，zero_division = 0））

zero_division= 0 已包含在分类报告中，因为这是我之前的问题分类报告中少数类的准确率、召回率、F1 分数均为零值。我上一个问题的错误已得到纠正，但是我使用上述代码获得的分类报告似乎不正确。分类器未能将是类别（少数类别）分类，并将所有类别分类为无类别
分类报告如下所示
 精确召回率 f1-score 支持

            无 0.80 1.00 0.89 3242
            是 0.00 0.00 0.00 790

       精度 0.80 4032
      宏观平均 0.40 0.50 0.45 4032
   加权平均 0.65 0.80 0.72 4032

该问题仅发生在 SVM 和 MLP 分类器上。该模型通过随机森林和逻辑回归训练得很好。该数据集是经过标签编码的分类数据集。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/75389106/minority-class-precision-recall-fscore-all-become-zero-with-mlp-classifier</guid>
      <pubDate>Wed, 08 Feb 2023 16:52:13 GMT</pubDate>
    </item>
    </channel>
</rss>