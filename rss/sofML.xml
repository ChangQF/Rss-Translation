<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 15 Aug 2024 01:05:11 GMT</lastBuildDate>
    <item>
      <title>如何在不使用 for 循环的情况下直接从 Claude API 对多个完成（n）进行采样？</title>
      <link>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</link>
      <description><![CDATA[我正在使用 Anthropic Claude API，并尝试在单个 API 调用中为给定的提示生成多个完成（n 个完成）。 OpenAI 的 API 在其采样设置中提供了一个 n 参数来实现这一点，但我在 Claude API 中找不到等效选项。
我目前的方法：
我目前正在使用重试机制来处理 API 调用期间的潜在错误，如下所示：
from tenacity import retry, stop_after_attempt, wait_exponential

def before_sleep(retry_state):
print(f&quot;(Tenacity) Retry, error that cause it: {retry_state.outcome.exception()}&quot;)

def retry_error_callback(retry_state):
exception = retry_state.outcome.exception()
exception_str = str(exception)
if &quot;prompt is too long&quot; in exception_str and &quot;400&quot;在 exception_str 中：
引发异常
返回“没有需要我们提前退出的错误。”

@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator, prompt: str) -&gt;; dict:
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n, # 旨在生成多个完成
stop_sequences=gen.sampling_params.stop[:3],
)
return response

问题：
我在 Anthropic API 中找不到 n 参数允许在一个请求中生成多个完成的文档。
问题：

Claude API 是否支持在单个 API 调用中直接生成多个完成（n 个完成）？
如果不支持，是否有推荐的解决方法或最佳实践来实现此目的，而无需循环多个请求？
任何指导或建议都将不胜感激！

cross discord：https://discord.com/channels/1072196207201501266/1213976011998498816/threads/1273440866861846549
cross：https://dev.to/brando90/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-loop-2m1e

现在这样做：
@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator，提示：str) -&gt; dict:
# max_tokens=8192, # Claude 3.5 的 max_tokens https://docs.anthropic.com/en/docs/about-claude/models#model-comparison
# client = anthropic.Anthropic(api_key=gen.api_key)
# response = client.messages.create(
# response_text: str = gen.llm.messages.create(
# model=gen.sampling_params.model,
# max_tokens=gen.sampling_params.max_tokens,
# #temperature=temperature, # 注意提示生成器不会将其作为输入
# system=gen.sampling_params.system,
# messages=[
# {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
# ],
#temperature=gen.sampling_params.temperature,
#top_p=gen.sampling_params.top_p,
#n=gen.sampling_params.n,
#stop=gen.sampling_params.stop[:3],
# ).content[0].text
if not hasattr(gen.sampling_params, &#39;n&#39;):
gen.sampling_params.n = 1
content: list[dict] = [] 
for _ in range(gen.sampling_params.n):
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n,
stop_sequences=gen.sampling_params.stop[:3],
)
content.append(response)
response = dict(content=content)
# 消息示例：https://docs.anthropic.com/en/api/messages-examples
返回响应
]]></description>
      <guid>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</guid>
      <pubDate>Thu, 15 Aug 2024 00:37:53 GMT</pubDate>
    </item>
    <item>
      <title>Python：为什么尽管使用了垃圾收集器，我的代码仍然泄漏内存？</title>
      <link>https://stackoverflow.com/questions/78872867/python-why-is-my-code-leaking-memory-despite-using-garbage-collector</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78872867/python-why-is-my-code-leaking-memory-despite-using-garbage-collector</guid>
      <pubDate>Wed, 14 Aug 2024 20:43:25 GMT</pubDate>
    </item>
    <item>
      <title>Python mediappe手部识别方块优化</title>
      <link>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</link>
      <description><![CDATA[所以 python 有 mediapupe lib，它提供了识别照片/视频上手的工具
我在我的项目中使用它。但我正在考虑优化 - 所以它会运行得更快。
我们知道，如果在 1 帧中有一只手 - 它在另一帧中不会太远 - 所以没有必要重复整个照片 - 手周围的区域就足够了（包括测量它的角速度和径向速度）
mediapype 是否包含一些优化方法？或者它只是愚蠢地让代码愚蠢地检查整张照片？
我还没有搜索过有关这方面的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</guid>
      <pubDate>Wed, 14 Aug 2024 20:38:41 GMT</pubDate>
    </item>
    <item>
      <title>python：“顺序”层需要 1 个输入，但它收到了 48 个输入张量</title>
      <link>https://stackoverflow.com/questions/78872766/python-layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78872766/python-layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</guid>
      <pubDate>Wed, 14 Aug 2024 20:06:08 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，backward() 函数如何工作？</title>
      <link>https://stackoverflow.com/questions/78872444/how-backward-function-works-in-this-situation</link>
      <description><![CDATA[假设我将两个模型（例如 SAM 和 U-NET）的参数包含在名为“joint_parameters”的变量中，然后将优化器设置为
optimizer = torch.optim.Adam(joint_params, lr=1e-5)
假设“sam_loss”是从 SAM 模型的输出计算出来的损失。
当我执行时，U-NET 模型的参数会发生什么
sam_loss.backward()
optimizer.step() 

它对 U-NET 的参数有影响吗？还是什么都没有发生？
我认为 U-NET 的参数不会发生任何事情，但我只是想确定一下。]]></description>
      <guid>https://stackoverflow.com/questions/78872444/how-backward-function-works-in-this-situation</guid>
      <pubDate>Wed, 14 Aug 2024 18:25:16 GMT</pubDate>
    </item>
    <item>
      <title>语法错误：无效的不可打印字符 U+00A0</title>
      <link>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</link>
      <description><![CDATA[我想建立一个基本的逻辑回归模型，但当我尝试将数据输入模型时，出现了不可打印字符错误
model.fit(X_train, y_train
SyntaxError: 无效的不可打印字符 U+00A0
我试图建立逻辑回归模型]]></description>
      <guid>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</guid>
      <pubDate>Wed, 14 Aug 2024 17:20:55 GMT</pubDate>
    </item>
    <item>
      <title>批次不同部分多重损失的最佳实践[关闭]</title>
      <link>https://stackoverflow.com/questions/78871584/best-practice-for-multiple-losses-on-different-parts-of-batch</link>
      <description><![CDATA[我有一个想要训练的姿势估计模型。有些实例有 3D 地面实况数据，有些有 2D 地面实况数据。两种类型的预测模型相同，只是损失不同。它们由不同的数据加载器加载。
我希望两者都在同一个批次中，实现此目标的（软件工程）最佳实践是什么。

将它们分别传递给模型，因此两个模型前向和后向调用，然后在累积梯度上运行优化器。
合并两个批次（跟踪每个批次中有多少个样本），将它们输入模型，然后在将其通过损失函数之前将结果分开。
使用虚拟基本事实计算两个批次的两个损失，并乘以 1 或 0 以仅将有效项目包含在整体损失中。

哪种方法可能是最容易理解的，是否有关于如何最好地解决这个问题的秘诀？
交叉发布：https://discuss.pytorch.org/t/best-practice-for-multiple-losses-on-different-parts-of-batch/208071]]></description>
      <guid>https://stackoverflow.com/questions/78871584/best-practice-for-multiple-losses-on-different-parts-of-batch</guid>
      <pubDate>Wed, 14 Aug 2024 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 算法对图像进行分类时，如何修复“找到具有 dim 4 的数组”错误</title>
      <link>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</link>
      <description><![CDATA[我有一个简单的 ML 分类问题。我有 8 个文件夹，每个文件夹代表一个类，因此我首先从文件夹中加载这些图像并分配标签，然后将其保存为 csv 文件（代码如下）
def load_images_from_folder(root_folder):
image_paths = []
images = []
labels = []
for label in os.listdir(root_folder):
label_path = os.path.join(root_folder, label)
if os.path.isdir(label_path):
for filename in os.listdir(label_path):
img_path = os.path.join(label_path, filename)
if os.path.isfile(img_path) and (filename.endswith(&quot;.jpg&quot;):
img = Image.open(img_path)
img = img.resize((128, 128))
img_array = np.array(img)
image_paths.append(img_path)
images.append(img_array)
labels.append(label)
return image_paths, images, labels
if __name__ == &quot;__main__&quot;:
root_folder_path = &quot;./Datasets_1&quot;
image_paths, images, labels = load_images_from_folder(root_folder_path)

然后我将图像和标签转换为 DataFrame 并加载它
data = {&quot;Images&quot;: image_paths, &quot;Labels&quot;: labels}
df = pd.DataFrame(data)
df.to_csv(&quot;original_data.csv&quot;, index=False)
csv_file = &quot;original_data.csv&quot;
df = pd.read_csv(csv_file)

我还将向 DataFrame 添加一个带有编码标签的新列“Encoded_Labels”，并将“Encoded_Labels”列转换为整数
df[&#39;Encoded_Labels&#39;] =coded_labels
df[&#39;Encoded_Labels&#39;] = df[&#39;Encoded_Labels&#39;].astype(int)

最后，我将数据集拆分为训练集和测试集，并对训练图像进行预处理
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
def load_and_preprocess_images(file_paths, target_size=(128, 128)):
images = []
for file_path in file_paths:
img = Image.open(file_path)
img = img.resize(target_size)
img_array = np.array(img) / 255.0 # 标准化像素值
images.append(img_array)
return np.array(images)

X_train = load_and_preprocess_images(train_df[&#39;Images&#39;].values)
y_train = train_df[&#39;Encoded_Labels&#39;].values
X_test = load_and_preprocess_images(test_df[&#39;Images&#39;].values)
y_test = test_df[&#39;Encoded_Labels&#39;].values**your text**

X_train 的输出形状为
(20624, 128, 128, 3)

对于这一点，我没有问题，我可以使用它使用 DL 模型没有问题，但是尝试使用 ML 模型（例如 KNN、SVM、DT 等）时。示例代码如下
from sklearn.svm import SVC
svc = SVC(kernel=&#39;linear&#39;,gamma=&#39;auto&#39;)
svc.fit(X_train, y_train)`

或
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_train)
y_pred = knn_clf.predict(X_test)
accuracy = metrics.accuracy_score(y_test, y_pred)
print(&quot;Accuracy of KNN Classifier : %.2f&quot; % (准确率*100))

我收到此错误
ValueError：找到 dim 为 4 的数组。SVC 预期 &lt;= 2。

如何修复此错误？]]></description>
      <guid>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</guid>
      <pubDate>Wed, 14 Aug 2024 08:26:27 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn 版本不匹配问题。我不知道应该安装哪个版本</title>
      <link>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</link>
      <description><![CDATA[我正在努力解决涉及 Scikit-learn 的版本不匹配问题。每当我尝试安装不同版本的 Scikit-learn 时，我都会遇到一系列错误，这些错误似乎因我尝试的每个版本而异。

问题的核心似乎是 Scikit-learn 与其依赖项（例如 NumPy 和 SciPy）之间的不兼容性。这些依赖项对于 Scikit-learn 正常运行至关重要，找到可以协同工作的正确版本已成为一项艰巨的任务。尽管我付出了努力，但我还是无法找到一个可以解决错误并与我现有设置很好地集成的 Scikit-learn 版本。反复试验的过程只会导致越来越多的挫败感，因为每个新版本都会带来一系列问题，而不是解决核心问题。
这个版本不匹配严重影响了我在项目中有效使用 Scikit-learn 的能力。缺乏关于将 Scikit-learn 与其依赖项的兼容版本对齐的明确指导增加了我的困难，使我很难继续工作并实现预期结果。]]></description>
      <guid>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</guid>
      <pubDate>Wed, 14 Aug 2024 04:15:49 GMT</pubDate>
    </item>
    <item>
      <title>如何为二进制数据集实现自动编码器？</title>
      <link>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset</link>
      <description><![CDATA[我被要求创建一个自动编码器，用于重建二进制 CSV 文件（解码）。
我根据 geeksforgeeks 中的 MNIST 示例实现了一个。但我对正确性非常不确定，包括损失的计算以及 relu 和线性部分。我做了一些研究，似乎在这种情况下 BCEloss 也比 MSEloss 更好。
有什么建议吗？
以下代码可以生成输出，但损失非常小。建议的批量大小、隐藏维度层和时期数是多少。

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# 设置随机种子以实现可重复性
np.random.seed(42)
torch.manual_seed(42)

# 生成玩具数据：D = 100 名患者，K = 10 个表型，二进制值（0 或 1）
D，K = dm.shape
#data = np.random.randint(0, 2, size=(D, K)).astype(np.float32)

# 将 numpy 数组转换为 PyTorch 张量
data_tensor = torch.tensor(dm)
print(data_tensor.shape)

# 定义 Autoencoder 模型
class Autoencoder(nn.Module):
def __init__(self, input_dim, hidden_​​dim):
super(Autoencoder, self).__init__()
# 编码器
self.encoder = nn.Sequential(
nn.Linear(input_dim, hidden_​​dim),
nn.ReLU()
)
# 解码器
self.decoder = nn.Sequential(
nn.Linear(hidden_​​dim, input_dim),
nn.Sigmoid()
)

def forward(self, x):
coded = self.encoder(x)
coded = self.decoder(encoded)
returncoded

# 超参数
input_dim = K
hidden_​​dim = 5 # 隐藏层维度，需要调整

# 初始化模型、损失函数和优化器
model = Autoencoder(input_dim=input_dim, hidden_​​dim=hidden_​​dim)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练参数
num_epochs = 5
batch_size = 10

# 训练循环
for epoch in range(num_epochs):
for i in range(0, D, batch_size):
batch_data = data_tensor[i:i+batch_size]

# 正向传递
outputs = model(batch_data)
loss = criterion(outputs, batch_data)

# 反向传递和优化
optimizer.zero_grad() 
loss.backward()
optimizer.step()

#print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss}&#39;)
if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)

# 通过重建输入数据测试模型
with torch.no_grad():
reconstructed = model(data_tensor)

print(&quot;Original Data:&quot;)
print(data_tensor)

print(&quot;Reconstructed Data:&quot;)
print(reconstructed)
]]></description>
      <guid>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset</guid>
      <pubDate>Wed, 14 Aug 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>runs\train\exp10 不是目录</title>
      <link>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</link>
      <description><![CDATA[我试图在自己的计算机上使用自定义数据训练 YoloV5 模型，但一直出现此错误：
train: weights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, worker=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, waiting=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github：跳过检查（不是 git 存储库），有关更新，请参阅 https://github.com/ultralytics/yolov5
YOLOv5 2024-7-15 Python-3.12.2 torch-2.3.1+cpu CPU
超参数：lr0=0.01, lrf=0.01, motivation=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, Translation=0.1, scale=0.5, sheath=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard：以“tensorboard --logdir runs\train”开始，在 http://localhost:6006/ 查看
回溯（最近一次调用）：
文件&lt;module&gt; 中的“C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py”，第 986 行
main(opt)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 688 行，在 main 中
train(opt.hyp, opt, device, callbacks)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 180 行，在 train 中
loggers = Loggers(
^^^^^^^^^
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\utils\loggers\__init__.py&quot;，第 121 行，在 __init__ 中
self.tb = SummaryWriter(str(s))
^^^^^^^^^^^^^^^^^^^^^^
文件&quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 249 行，在 __init__ 中
self._get_file_writer()
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 281 行，在 _get_file_writer 中
self.file_writer = FileWriter(
^^^^^^^^^^^
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 75 行，在 __init__ 中
self.event_writer = EventFileWriter(**
^^^^^^^^^^^^^^^^^
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorboard\summary\writer\event_file_writer.py”，第 72 行，在 __init__ 中
tf.io.gfile.makedirs(logdir)
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 513 行，在 recursive_create_dir_v2 中
_pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp10 不是目录

我尝试从预先训练的模型训练我的模型（正如 yolov5 文档所推荐的那样），如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --weights yolov5s.pt
或者从头开始，如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --cfg models/yolov5s.yaml
我还看到了其他问题，例如 GitHub 上的问题 #12008 和 Stack Overflow 上的这个问题 tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp3 不是目录，但还没有找到任何解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</guid>
      <pubDate>Tue, 13 Aug 2024 21:58:27 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV8 创建了太多边界框[重复]</title>
      <link>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</link>
      <description><![CDATA[我使用 yoloV8 训练了一个模型，该模型有助于检测摩托车骑手的头盔，并尝试通过创建虚拟环境 venv 并安装以下软件包 numpy opencv-python tensorflow ultralytics 来运行
起初，它向我显示了错误

OSError：[WinError 126] 找不到指定的模块。加载“D:\ACADEMICS\projects\helmet\venv\Lib\site-packages\torch\lib\fbgemm.dll”时出错或其依赖项之一。

通过在安装过程中下载 Visual Studio 2022 社区版 并安装 C++ 桌面环境 解决了缺少文件的问题。
但是现在在随机位置创建的边界框太多了。
当前输出：

预期结果：


已编辑 == 在下面添加了代码

import cv2
from ultralytics import YOLO

model = YOLO(&quot;runs/detect/train2/weights/best.pt&quot;)

results = model.predict(source=&#39;download.jpeg&#39;, show = True, save=True)
]]></description>
      <guid>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</guid>
      <pubDate>Tue, 13 Aug 2024 16:57:54 GMT</pubDate>
    </item>
    <item>
      <title>根据距离/速度/加速度设计运动启动/停止检测器[关闭]</title>
      <link>https://stackoverflow.com/questions/78867452/designing-a-motion-start-stop-detector-based-on-distance-velocity-acceleration</link>
      <description><![CDATA[我训练了 yolov8 nano 来检测培养皿中游动的鱼胚胎。培养皿中任何时候都只有一个胚胎，所以这是一项相当简单的任务，模型表现良好（mAP50=0.994）。我的项目的最终目标是拥有一个以视频为输入的软件，并让其输出指标（每帧的 x、y 坐标、游动距离、游动速度等），仅针对视频中胚胎游动的帧。例如，视频可能有 200 帧，前 40 帧左右胚胎尚未游动，然后是 140 帧游动，然后是 20 帧不游动（鱼已停止游动）。因此，对于此视频，我希望有一个函数，它从包含视频中所有帧信息的 csv 文件中提取仅 140 个相关帧。
使用硬编码算法执行此操作的主要问题是数据嘈杂，使得胚胎游泳模式的结束难以检测。例如，最小每帧速度数字（假设胚胎可以游动 1 个像素）通常约为 10mm/s。然而，即使鱼静止不动，模型预测中的随机变化也会将边界框的中心移动几个像素，因此噪声约为 10-20mm/s。为此，我对速度列应用了简单指数平滑，以尝试降低噪声：
def simple_exponential_smoothing(data, alpha):
&quot;&quot;&quot;
对数据应用简单指数平滑。

参数：
data (array-like)：输入的时间序列数据。
alpha (float)：平滑因子 (0 &lt; alpha &lt;= 1)。

返回：
np.ndarray：平滑的时间序列数据。
&quot;&quot;&quot;
result = [data[0]] # 第一个值与序列相同
for n in range(1, len(data)):
result.append(alpha * data[n] + (1 - alpha) * result[n-1])
return np.array(result)


我最初的方法是使用一个 csv 文件（包含一个视频的预测，每帧一个），并在其上运行一个“检测器”函数。我尝试使用以下函数提取起始和结束帧，以便我可以将数据修剪为仅相关帧以进行进一步计算：
def find_start_end_rows(df, velocity_column,filtered_velocity_column, frame_rate):
&quot;&quot;&quot;
根据更精确的方法查找起始和结束行索引。

参数：
df (pd.DataFrame)：要分析的数据框。
velocity_column (str)：要搜索的速度列的名称。
adopted_velocity_column (str)：过滤后的速度列的名称。

返回：
tuple：包含起始行索引和结束行索引的元组。
&quot;&quot;&quot;
start_row = None
end_row = None
velocity_threshold = 20 # 开始游泳的最小速度
filtered_velocity_threshold = 10 # 考虑运动的最小过滤速度
consistent_low_velocity_frames = 5 # 检测结束的连续低速帧数

# 查找起始行
for i in range(len(df)):
if df.loc[i, velocity_column] &gt;= velocity_threshold:
start_row = i - 1
break

# 如果 start_row 仍为 None，则表示未找到值 &gt;= 20
if start_row is None:
return (-1,-1) # -1 表示函数失败

# 通过检查起始行后的一致低速来查找结束行
low_velocity_count = 0
for i in range(start_row + 2, len(df)):
if df.loc[i,过滤后的低速帧：
low_velocity_column] &lt; 过滤后的低速帧：
low_velocity_count += 1
如果低速帧：
= 一致低速帧：
end_row = i - 一致低速帧：
break
否则：
low_velocity_count = 0

# 如果 end_row 仍为 None，则表示未找到一致的低速帧
如果 end_row 为 None：
end_row = len(df) - 1

返回 start_row, end_row

但是，正如我们在下图中看到的那样，该函数的性能并不理想。该图展示了使用此函数进行起始帧预测和结束帧预测的误差（将函数的输出与这些视频中的真实起始/结束帧进行比较）。对于该项目来说，至关重要的是，我们在预测开始/结束帧时看到的变异性最多为 2-3 帧。
显示 find_start_end_frames 错误的图表
哪种方法可能是检测视频中的开始/结束帧的最佳方法？通过算法解决这个问题会很棒，而不必为这项任务训练整个其他 ML 模型，但我愿意接受任何人们认为可行的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78867452/designing-a-motion-start-stop-detector-based-on-distance-velocity-acceleration</guid>
      <pubDate>Tue, 13 Aug 2024 16:46:36 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 nltk 函数</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>ML 查找四边形的角</title>
      <link>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</link>
      <description><![CDATA[我的作业是使用 ML 模型找到四边形角的 4 个点。有时四边形的一个角会丢失（例如页面的折叠角）。
首先，我尝试使用 MobileNetV3Small 作为主干进行图像分割，因为该模型应该小而快。效果很好，但找到角仍然是一个问题。我曾尝试按照官方 keras 关键点检测、中等教程和许多其他来源等示例查找图像的关键点，但似乎对我都不起作用。我尝试过多次修改它们。损失函数在测试和验证中都下降了，但输出甚至没有接近所需的位置。也尝试了类似下面的方法：
def conv(model, size, conv2d_kernel, dilation_rate=(1, 1), pooling_size=(2, 2)):
model.add(Conv2D(size, conv2d_kernel, dilation_rate=dilation_rate))
model.add(Activation(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=max_pooling))
model.add(Dropout(0.1))

def density(model, unit):
model.add(Dense(units))
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.1))

model = Sequential()
model.add(InputLayer(shape=(224, 224, 3)))

conv(model, size=32, conv2d_kernel=(2, 2))
conv(model, size=64, conv2d_kernel=(3, 3))
conv(model, size=128, conv2d_kernel=(3, 3))

model.add(Flatten())
dense(model, 20)
dense(model, 20)

model.add(Dense(8))
model.compile(optimizer=RMSprop(),
loss=losses.MeanSquaredLogarithmicError(),
metrics=[metrics.MeanAbsoluteError()])

还尝试了输出形状 (8) 和 (4,2)，但似乎没有任何效果。任何帮助都将不胜感激。
PS：还忘记补充一点，数据集的注释是正确的，或者至少这是我在图表上看到的。还尝试将坐标标准化为 0 到 1 之间。我的输入是 (224,224,3)。]]></description>
      <guid>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</guid>
      <pubDate>Sat, 13 Apr 2024 20:06:34 GMT</pubDate>
    </item>
    </channel>
</rss>