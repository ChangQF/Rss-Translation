<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Dec 2024 18:25:23 GMT</lastBuildDate>
    <item>
      <title>在 Jupyter Notebook 上获取“TypeError：ufunc‘isnan’不支持输入类型”</title>
      <link>https://stackoverflow.com/questions/79276186/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types-on-jupyter</link>
      <description><![CDATA[我正在 Jupyter Notebook 上做一个机器学习项目来预测电动汽车的价格。
我运行这个单元：
for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

我收到此错误：
TypeError Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_16424\1094749331.py in &lt;module&gt;
1 for col in cols:
2 le.fit(t[col])
----&gt; 3 df2[col] = le.transform(df2[col])
4 print(le.classes_)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\preprocessing\_label.py in transform(self, y)
136 return np.array([])
137 
--&gt; 138 return _encode(y, uniques=self.classes_)
139 
140 def inverse_transform(self, y):

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _encode(values, uniques, check_unknown)
185 else:
186 if check_unknown:
--&gt; 187 diff = _check_unknown(values, uniques)
188 if diff:
189 raise ValueError(f&quot;y 包含之前未见过的标签：{str(diff)}&quot;)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _check_unknown(values, known_values, return_mask)
259 
260 # 检查 known_values 中的 nans
--&gt; 261 if np.isnan(known_values).any():
262 diff_is_nan = np.isnan(diff)
263 if diff_is_nan.any():

TypeError: ufunc &#39;isnan&#39; 不支持输入类型，并且根据转换规则 &#39;&#39;safe&#39;&#39;，无法将输入安全地强制转换为任何受支持的类型

我尝试了什么？
我尝试使用以下代码：
le = preprocessing.LabelEncoder()
cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]
for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

代码给出了具体的错误。
为了解决这个问题，我尝试使用以下代码来插入缺失值（“N/”）而不是删除它：
for col in cols:
le.fit(t[col].fillna(&#39;Missing&#39;)) # 使用“Missing”插入缺失值
df2[col] = le.transform(df2[col].fillna(&#39;Missing&#39;))
print(le.classes_)

但我仍然收到相同的错误。
这是我的笔记本的链接：https://github.com/SteveAustin583/electric-vehicle-price-prediction-revengers/blob/main/revengers.ipynb
如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79276186/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types-on-jupyter</guid>
      <pubDate>Thu, 12 Dec 2024 18:23:13 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到使用 NLP 进行医疗文档分析和疾病诊断的数据集？[关闭]</title>
      <link>https://stackoverflow.com/questions/79276072/where-can-i-find-datasets-for-medical-document-analysis-and-disease-diagnosis-us</link>
      <description><![CDATA[我正在从事一个与医疗保健相关的项目，我需要分析医疗文件，提取特定值（例如肌酐、血糖水平等），并为患者生成个性化段落，描述他们的病情和推荐药物。但是，我很难找到适合这项任务的数据集。
理想的数据集应包括：
医学测试结果或实验室报告。
基于提取值的疾病诊断。
建议的药物或治疗计划。

任何建议或资源都将不胜感激！
我搜索过 Kaggle、NIH 和 SEER 等平台，但没有找到符合我需求的东西。]]></description>
      <guid>https://stackoverflow.com/questions/79276072/where-can-i-find-datasets-for-medical-document-analysis-and-disease-diagnosis-us</guid>
      <pubDate>Thu, 12 Dec 2024 17:39:30 GMT</pubDate>
    </item>
    <item>
      <title>鸢尾花数据集上的规范化与最小最大缩放</title>
      <link>https://stackoverflow.com/questions/79275753/normalization-vs-minmax-scaling-on-iris-dataset</link>
      <description><![CDATA[我正在对 Iris 数据集进行一些实验。
我面临 MinMaxScaler 和 minimize 之间的不同行为。
尽管我知道我不应该对数据进行规范化或标准化，但我还是尝试了（出于测试目的）。
通过使用 MinMaxScaler：
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
rf = RandomForestClassifier(random_state=43)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

我得到的准确率为 93.3%（由于种子固定，因此可重现）
然后，如果我想尝试使用标准化进行相同的实验，如下所示：
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)

X_train = normalize(X_train)
X_test = normalize(X_test)
rf = RandomForestClassifier(random_state=43)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

我的准确率总是 100%（只有当我使用 &gt;50% 作为测试集时，准确率才会开始下降）。
我不明白为什么会发生这种情况。
我很想阅读关于标准化和标准化之间这种不同行为的解释MinMax。
或者甚至是一些见解，一些我应该检查的东西，以便了解发生了什么。]]></description>
      <guid>https://stackoverflow.com/questions/79275753/normalization-vs-minmax-scaling-on-iris-dataset</guid>
      <pubDate>Thu, 12 Dec 2024 15:53:15 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV SSD MobileNet V2 模型：尽管有置信度阈值，但仍无法检测到物体</title>
      <link>https://stackoverflow.com/questions/79275458/opencv-ssd-mobilenet-v2-model-no-object-detection-despite-confidence-threshold</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79275458/opencv-ssd-mobilenet-v2-model-no-object-detection-despite-confidence-threshold</guid>
      <pubDate>Thu, 12 Dec 2024 14:19:28 GMT</pubDate>
    </item>
    <item>
      <title>无监督递归特征消除</title>
      <link>https://stackoverflow.com/questions/79275101/unsupervised-recursive-feature-elimination</link>
      <description><![CDATA[我想知道是否有人能帮忙提供一些无监督递归特征消除 (uRFE) 的 R 代码？
简而言之，我运行了一个无监督的 SOM，用 k-medoids 进行分区，但也想使用轮廓分数来识别 uRFE。
下面附上了一些虚拟代码。
library(aweSOM)

#IRIS 数据

full.data &lt;- iris
train.data &lt;- full.data[, c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;)]
train.data &lt;- scale(train.data)

#SOM 初始化 + MAP

set.seed(1465)
init &lt;- somInit(train.data, 4, 4)
iris.som &lt;- kohonen::som(train.data, grid = kohonen::somgrid(4, 4, &quot;hexagonal&quot;), 
rlen = 100, alpha = c(0.05, 0.01), radius = c(2.65,-2.65), 
dist.fcts = &quot;sumofsquares&quot;, init = init)

#SOM 聚类

superclust_pam &lt;- cluster::pam(iris.som$codes[[1]], 3)
superclasses_pam &lt;- superclust_pam$clustering
]]></description>
      <guid>https://stackoverflow.com/questions/79275101/unsupervised-recursive-feature-elimination</guid>
      <pubDate>Thu, 12 Dec 2024 12:27:01 GMT</pubDate>
    </item>
    <item>
      <title>将机器学习模型部署在一台服务器上（而不是两台）可增加其响应时间</title>
      <link>https://stackoverflow.com/questions/79275068/increased-response-time-of-a-machine-learning-model-when-deploying-it-on-a-singl</link>
      <description><![CDATA[我最近在两台并行服务器上部署了一个利用 GPU 的机器学习模型。使用负载平衡器在它们之间平衡请求负载。为了减少资源使用量，我决定切换到单服务器设置，将所有请求直接路由到其中一台服务器。该服务器有一个 Nvidia tesla t4 GPU。该模型仅使用了 15GB 容量中的 1.2GB 左右。
更改后，我观察到以下情况：
CPU 利用率：几乎没有变化。
GPU 利用率：如预期一样翻倍，但未超过 GPU 的容量。
平均 GPU 利用率百分比从 7.5% 上升到 16.5%
最大 GPU 利用率百分比从 38% 上升到 48%
第 90 个百分位的 GPU 利用率百分比从 19% 上升到 34%
模型响应时间：平均增加了约 10% 到 15%。
尽管有这些观察结果，但我无法确定模型响应时间增加的确切原因。有什么见解或建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/79275068/increased-response-time-of-a-machine-learning-model-when-deploying-it-on-a-singl</guid>
      <pubDate>Thu, 12 Dec 2024 12:15:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 peft 进行微调时出错</title>
      <link>https://stackoverflow.com/questions/79274171/getting-error-while-fine-tuning-using-peft</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79274171/getting-error-while-fine-tuning-using-peft</guid>
      <pubDate>Thu, 12 Dec 2024 07:31:09 GMT</pubDate>
    </item>
    <item>
      <title>使用预先训练的 CNN 进行螃蟹性别分类 [关闭]</title>
      <link>https://stackoverflow.com/questions/79273773/using-pre-trained-cnn-for-crab-gender-classification</link>
      <description><![CDATA[我可以使用预先训练好的、已针对对象分类进行微调的 cnn 模型，然后添加我自己的螃蟹数据集吗？
示例：一个经过训练可以对花朵等对象进行分类的 cnn 模型，该模型是在 5 个类别上进行训练的，对吗？现在我想添加螃蟹图像，这样它就会知道它是螃蟹。我需要重新训练整个模型吗，还是我可以只添加我的数据集并训练模型？
我现在正在进行螃蟹性别分类。但我的顾问想在我的系统演示中添加，如果用户在螃蟹旁边添加图像，它将识别出不是螃蟹。我解释说这是不可能的，因为模型是针对性别分类而不是对象分类进行训练的（我使用 efficientnetb7 来训练我的螃蟹图像）。
我怎样才能实现他们的要求？
我还没有尝试任何东西，因为 google colab 很贵，而且我还在读学士学位]]></description>
      <guid>https://stackoverflow.com/questions/79273773/using-pre-trained-cnn-for-crab-gender-classification</guid>
      <pubDate>Thu, 12 Dec 2024 03:46:31 GMT</pubDate>
    </item>
    <item>
      <title>根据线条粗细、文字大小和背景颜色对图像进行分类</title>
      <link>https://stackoverflow.com/questions/79273650/classify-images-based-on-line-thickness-text-size-and-background-color</link>
      <description><![CDATA[我正在尝试找到一种方法，根据图像是否适合印在衣服上对图像进行分类，最好使用 Python 库。我主要想做的是找到文本大小和颜色以及一般的线条粗细和背景颜色 - 当背景颜色较暗时，需要大量墨水。如果图像的线条非常细，颜色较浅或为白色，墨水就会“侵入”这些线条，图像将无法识别。检测文本及其大小/线条粗细将是一个不错的开始。我有成千上万张“好”和“坏”图像，因此训练 AI/ML 模型是一种选择，但在我看来，图像分析库可能已经足够好了。欢迎所有选项。]]></description>
      <guid>https://stackoverflow.com/questions/79273650/classify-images-based-on-line-thickness-text-size-and-background-color</guid>
      <pubDate>Thu, 12 Dec 2024 02:14:00 GMT</pubDate>
    </item>
    <item>
      <title>Softmax 函数的哪种表示是正确的？[关闭]</title>
      <link>https://stackoverflow.com/questions/79272621/which-representation-of-the-softmax-function-is-correct</link>
      <description><![CDATA[我偶然发现了 Softmax 函数的公式：
Softmax 公式
但是，我发现了 Softmax 函数的两个非常不同的视觉表示，我不知道哪一个是正确的：

类似 S 形的曲线：随着输入的增长，一条曲线从 0 增加到 1。它看起来类似于 Sigmoid 函数。
类似 Sigmoid 的曲线

多类归一化输出：显示多个类的概率如何随不同输入而变化的图表，其中概率总和为 1。
多类归一化输出



第一张图（类似 Sigmoid 的曲线）是否正确表示了 Softmax 函数，还是仅描述特定条件下的一个组件？
Softmax 是否应始终表示为跨多个类的概率分布（如第二张图所示）图表）？

我正在寻找有关如何正确解释和表示 Softmax 函数的清晰度。]]></description>
      <guid>https://stackoverflow.com/questions/79272621/which-representation-of-the-softmax-function-is-correct</guid>
      <pubDate>Wed, 11 Dec 2024 17:19:50 GMT</pubDate>
    </item>
    <item>
      <title>我实现的 KMeans 的结果并不一致</title>
      <link>https://stackoverflow.com/questions/79271387/the-result-of-my-implementation-of-kmeans-is-not-consistent</link>
      <description><![CDATA[我正在尝试实现一个简化版的 KMeans 聚类，但不知何故，结果有时不一致
import numpy as np
import random

import matplotlib.pyplot as plt

class KMeans:
def __init__(
self,
n_clusters,
max_iter
):
self.n_clusters = n_clusters
self.max_iter = max_iter

def _get_distance(self, x, cluster_location):
&quot;&quot;&quot;计算每个点到聚类中心的欧几里得距离
&quot;&quot;&quot;
return np.linalg.norm(x[:,np.newaxis,:]-cluster_location, axis = 2)

def fit(self, x:np.ndarray) -&gt;无：
“”k 均值聚类步骤
1. 启动聚类位置
2. 计算每个点到聚类点的距离
3. 将每个点分配给一个聚类
4. 使用相关点的平均值更新聚类位置
5. 重复 2-4 直到收敛或达到 max_iter

参数：
x (_type_)：_description_

返回：
_type_：_description_
“”
self.x = x
data_dim = x.shape[1]

# 1. 初始化簇位置
cluster_locations = np.random.uniform(x.min(), x.max(), size=(self.n_clusters,data_dim))
# print(&quot;initial:\n&quot;,cluster_locations)

for _ in range(self.max_iter):
# 2. 计算每个点到簇点的距离
distances = self._get_distance(x, cluster_locations)

# 3. 将每个点分配给一个簇
clusters = np.argmin(distances, axis=1)

# 4. 使用关联点的平均值更新簇位置
for cluster in range(self.n_clusters):
# 检查簇中是否有任何点
cluster_mask = clusters == cluster
if np.any(cluster_mask):
cluster_locations[cluster] = np.mean(x[cluster_mask], axis=0)
else:
# 如果簇为空，则用随机点重新初始化
cluster_locations[cluster] = x[np.random.randint(x.shape[0])] 

self.cluster_locations = cluster_locations
self.clusters = clusters
return None

def visualize(self, data, clusters):
_, ax = plt.subplots(1,1,figsize=(5,5))

cluster_color = [(random.random(),random.random(),random.random()) for _ in range(self.n_clusters)]

for cluster in range(self.n_clusters):
to_plot = data[np.where(clusters == cluster)[0]]
ax.scatter(to_plot[:,0], to_plot[:,1], color=cluster_color[cluster])
ax.scatter(self.cluster_locations[:,0], self.cluster_locations[:,1], marker=&quot;x&quot;, color=&#39;r&#39;, s=30)

plt.show()

这是我使用它的方式
from sklearn.datasets import make_blobs

random_state = 42
n_samples = 100

x, _ = make_blobs(n_samples=n_samples, random_state=random_state)
my_kmeans = KMeans(3, 50)
my_kmeans.fit(x)
my_kmeans.visualize(x, my_kmeans.clusters)

大多数时候，它都会给我一个合理的输出，像这样

但每运行几次，它就会给我类似这样的结果

我是否遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/79271387/the-result-of-my-implementation-of-kmeans-is-not-consistent</guid>
      <pubDate>Wed, 11 Dec 2024 10:41:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么预先训练的 Swin Transformer 编码器在 TPU 上失败但在 Colab 中的 CPU 上可以运行？</title>
      <link>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</link>
      <description><![CDATA[我正在处理图像分割任务，并尝试使用预先训练的 Swin Transformer Large (Swin-L) 编码器作为特征提取主干。代码在 Colab 中的 CPU 上完美运行。但是，当切换到 TPU 时，它会抛出如下所示的错误。
代码：
from tensorflow.keras import layer, Model, Input
from tfswin import SwinTransformerLarge224

def load_swin_encoder(input_shape=(512, 512, 3)):
# 加载预训练的 Swin-L 模型
swin_encoder = SwinTransformerLarge224(include_top=False, weights=&#39;imagenet&#39;,
input_shape=input_shape)

# 冻结预训练层
for layer in swin_encoder.layers:
layer.trainable = False

# 从四个阶段提取输出
stage_outputs = [
swin_encoder.get_layer(&#39;normalize&#39;).output, # 从 0 阶段输出
swin_encoder.get_layer(&#39;layers.0&#39;).output, # 第一阶段的输出
swin_encoder.get_layer(&#39;layers.1&#39;).output, # 第二阶段的输出
swin_encoder.get_layer(&#39;layers.2&#39;).output, # 第三阶段的输出
swin_encoder.get_layer(&#39;layers.3&#39;).output, # 第四阶段的输出
]
return Model(swin_encoder.input, stage_outputs, name=&quot;SwinTransformerEncoder&quot;)

# 测试代码
encoder = load_swin_encoder(input_shape=(512, 512, 3))
dummy_input = tf.random.uniform((1, 512, 512, 3))
encoder_outputs =coder(dummy_input)

for i, output in enumerate(encoder_outputs):
print(f&quot;阶段 {i + 1} 输出形状：{output.shape}&quot;)


错误：
代码在 TPU 上抛出以下错误：
------------------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-28-3cb122d32678&gt; 在 &lt;cell line: 2&gt;()
1 # 加载健全性检查
----&gt; 2 编码器 = load_swin_encoder(input_shape=(512, 512, 3))
3 dummy_input = tf.random.uniform((1, 512, 512, 3))
4 编码器输出 = 编码器(dummy_input)
5 

2 帧
/usr/local/lib/python3.10/dist-packages/keras/src/models/ functional.py in __init__(self, 输入, 输出, 名称, **kwargs)
117 for x in flat_inputs:
118 if not isinstance(x, backend.KerasTensor):
-&gt; 119 引发 ValueError(
120 “所有 `inputs` 值都必须是 KerasTensors。已收到：”
121 f“inputs={inputs} 包括无效值 {x}”

ValueError：所有 `inputs` 值都必须是 KerasTensors。已收到：inputs=KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层 &#39;input_4&#39; 创建”) 包括无效值 KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层创建” &#39;input_4&#39;&quot;) 类型为 &lt;class &#39;tf_keras.src.engine.keras_tensor.KerasTensor&#39;&gt;


问题：
为什么此代码在 Colab 中的 CPU 上有效，但在 TPU 上失败？我该如何修复此问题以使其与 TPU 执行兼容？
任何见解或指导都将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</guid>
      <pubDate>Mon, 02 Dec 2024 13:35:57 GMT</pubDate>
    </item>
    <item>
      <title>pytorch torchvision.datasets.ImageFolder FileNotFoundError：未找到类 .ipynb_checkpoints 的有效文件</title>
      <link>https://stackoverflow.com/questions/68229246/pytorch-torchvision-datasets-imagefolder-filenotfounderror-found-no-valid-file</link>
      <description><![CDATA[尝试在 Colab 中使用 pytorch torch.datasets.ImageFolder 加载训练数据。
transform = transforms.Compose([transforms.Resize(400),
transforms.ToTensor()])
dataset_path = &#39;ss/&#39;
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=20)

我遇到了以下错误：
-------------------------------------------------------------------------------
FileNotFoundError Traceback (most recent call last)
&lt;ipython-input-27-7abcc1f434b1&gt; in &lt;module&gt;()
2 transforms.ToTensor()])
3 dataset_path = &#39;ss/&#39;
----&gt; 4 dataset = datasets.ImageFolder(root=dataset_path, transform=transform)
5 dataloader = torch.utils.data.DataLoader(dataset, batch_size=20)

3 帧
/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py in make_dataset(directory, class_to_idx, extensions, is_valid_file)
100 if extensions 不为 None:
101 msg += f&quot;支持的扩展名是：{&#39;, &#39;.join(extensions)}&quot;
--&gt; 102 raise FileNotFoundError(msg)
103 
104 return entities

FileNotFoundError: 未找到类 .ipynb_checkpoints 的有效文件。支持的扩展名为：.jpg、.jpeg、.png、.ppm、.bmp、.pgm、.tif、.tiff、.webp

我的数据集文件夹包含一个子文件夹，其中包含许多 png 格式的训练图像，但 ImageFolder 仍然无法访问它们。]]></description>
      <guid>https://stackoverflow.com/questions/68229246/pytorch-torchvision-datasets-imagefolder-filenotfounderror-found-no-valid-file</guid>
      <pubDate>Fri, 02 Jul 2021 17:31:32 GMT</pubDate>
    </item>
    <item>
      <title>数据集特征编码和缩放[关闭]</title>
      <link>https://stackoverflow.com/questions/65028379/dataset-features-encoding-and-scaling</link>
      <description><![CDATA[我有一个包含非序数分类特征的数据集。在训练机器学习模型（线性 SVC）之前，对它们进行转换（编码 + 缩放）的最佳方法是什么？
我尝试过的方法：

标签编码 - 这种方法有效。但缩放毫无意义，因为特征中的不同类别没有任何特定顺序。

独热编码 - 特征中有数千个唯一类别，这会通过创建数千列使 ML 模型变得复杂。

计数编码 - 我的训练测试拆分没有训练集中特征的所有唯一类别，当我对这些特征进行计数编码时，测试集中会引入 NaN。

]]></description>
      <guid>https://stackoverflow.com/questions/65028379/dataset-features-encoding-and-scaling</guid>
      <pubDate>Thu, 26 Nov 2020 19:45:23 GMT</pubDate>
    </item>
    <item>
      <title>集成数值/物理数据用于 CNN 图像分类</title>
      <link>https://stackoverflow.com/questions/63206214/integrating-numerical-physical-data-for-cnn-image-classification</link>
      <description><![CDATA[我正在尝试使用 CNN 通过 keras 在 Python 中对医学图像进行分类。这些医学图像还包括年龄和性别等文本信息，这些信息会影响模型的决策。我如何训练一个可以同时使用图像和现实世界信息进行训练的 CNN，以便它能够根据两者进行分类？]]></description>
      <guid>https://stackoverflow.com/questions/63206214/integrating-numerical-physical-data-for-cnn-image-classification</guid>
      <pubDate>Sat, 01 Aug 2020 14:17:57 GMT</pubDate>
    </item>
    </channel>
</rss>