<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Mar 2024 18:16:39 GMT</lastBuildDate>
    <item>
      <title>CNN中的核运动与图像处理中的卷积运算相同吗？</title>
      <link>https://stackoverflow.com/questions/78162534/kernel-movement-in-cnn-is-same-as-convolution-operation-in-image-processing</link>
      <description><![CDATA[我们都知道图像处理中的卷积运算：

翻转蒙版并进行关联。
一维掩模水平翻转，因为只有一行。
2D 蒙版垂直和水平翻转。
遮罩在图像矩阵上从左向右滑动。
当蒙版悬停在图像上时，蒙版和图像的相应元素会相乘并添加产品。

但是在 CNN 中，我们通常不会执行，因为我们仅从左到右水平滑动内核并移动到下一行，并简单地对具有相应内核值的图像像素执行点积，这里我们只执行相关运算而不是卷积。
请解答我的疑问
图像处理中CNNS和卷积运算的区别。]]></description>
      <guid>https://stackoverflow.com/questions/78162534/kernel-movement-in-cnn-is-same-as-convolution-operation-in-image-processing</guid>
      <pubDate>Thu, 14 Mar 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>如何使用mediapipline多类分割模型？</title>
      <link>https://stackoverflow.com/questions/78162416/how-to-use-mediapipline-multiclass-segmentation-model</link>
      <description><![CDATA[我正在使用媒体管道构建我的微调模型。我已经在节点上实现了，但是你知道如何在pyton中使用衣服标签：4用于上衣
我尝试了 meidapipe 的这款笔记本 https://colab.research .google.com/drive/1IFABSWb7-mz0pSXjFizyU0tDZD2RVv8W#scrollTo=Yl_Oiye4mUuo
如果您有任何解决方案或任何笔记本，可以在评论中留言吗？我会喜欢的]]></description>
      <guid>https://stackoverflow.com/questions/78162416/how-to-use-mediapipline-multiclass-segmentation-model</guid>
      <pubDate>Thu, 14 Mar 2024 17:35:36 GMT</pubDate>
    </item>
    <item>
      <title>无法使用拥抱脸耳语和渐变加载 Tokenizer</title>
      <link>https://stackoverflow.com/questions/78161000/cant-load-tokenizer-using-hugging-face-whisper-and-gradio</link>
      <description><![CDATA[引发环境错误(
OSError：无法加载“myusername/whisper-tiny-hi”的标记生成器。如果您尝试加载它
来自“https://huggingface.co/models”，确保您没有同名的本地目录。否则，
确保“myusername/whisper-tiny-hi”是包含所有相关文件的目录的正确路径
WhisperTokenizer快速分词器。

从转换器导入管道
将渐变导入为 gr
从 Transformer 导入 M2M100ForConditionalGeneration、M2M100Tokenizer
从转换器导入 AutoTokenizer、AutoModelForQuestionAnswering
从变压器进口管道

QAtokenizer = AutoTokenizer.from_pretrained(“SRDdev/QABERT-small”)
QAmodel = AutoModelForQuestionAnswering.from_pretrained(“SRDdev/QABERT-small”)

text = &#39;&#39;&#39;提取问答是从给定问题的文本中提取答案的任务。一个例子
问答数据集是 SQuAD 数据集，它完全基于该任务。如果你想微调
SQuAD 任务的模型，您可以利用 Examples/pytorch/question-answering/run_squad.py 脚本。&#39;&#39;&#39;
Question =“什么是提取式问答？”

def Question_answer（文本，问题）：
    Ask = pipeline(“问答”, model= QAmodel , tokenizer = QAtokenizer)
    结果=询问（问题=问题，上下文=文本）
    print(f&quot;答案: &#39;{结果[&#39;answer&#39;]}&#39;&quot;)
    返回结果[&#39;答案&#39;]

tmodel = M2M100ForConditionalGeneration.from_pretrained(“facebook/m2m100_418M”)
ttokenizer = M2M100Tokenizer.from_pretrained(“facebook/m2m100_418M”)

管道=管道（模型=“我的用户名/whisper-tiny-hi”）

def 翻译（文本）：
    # 将印地语翻译成英语
    ttokenizer.src_lang = “嗨”
    encoded_hi = ttokenizer(文本, return_tensors=“pt”)
    generated_tokens = tmodel.generate(**encoded_hi,forced_bos_token_id=ttokenizer.get_lang_id(“en”))
    返回 ttokenizer.batch_decode( generated_tokens,skip_special_tokens=True)
    
def 转录（音频）：
    打印（音频）
    文本 = 管道（音频）[“文本”]
    翻译文本 = 翻译（文本）
    返回翻译后的文本

def ques_ans(音频,问题):
    翻译文本 = 转录（音频）
    答案 = Question_answering(translated_text[0],问题)
    # 打印（翻译文本）
    返回答案


我也删除了hubbing-face的缓存文件后尝试了多次。请帮我解决一下]]></description>
      <guid>https://stackoverflow.com/questions/78161000/cant-load-tokenizer-using-hugging-face-whisper-and-gradio</guid>
      <pubDate>Thu, 14 Mar 2024 13:47:40 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Plot 中 GBT 的值表示什么？</title>
      <link>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</link>
      <description><![CDATA[我正在使用 tfdf.keras.GradientBoostedTreesModel 并在使用 tfdf.model_plotter.plot_model_in_colab 绘制它时显示分割条件下的值： 有值的节点
这个“价值”是什么？意思是？
我已经阅读了 gbt 模型和绘图仪的文档，但找不到有关此值的任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</guid>
      <pubDate>Thu, 14 Mar 2024 13:26:35 GMT</pubDate>
    </item>
    <item>
      <title>根据历史数据预测用户最常问的 5 个问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78160731/predicting-top-5-frequently-asked-questions-by-users-based-on-historical-data</link>
      <description><![CDATA[问题陈述：
我有一个包含用户 ID 和他们提出的问题的数据集。我的目标是根据每个用户的历史数据预测他们最有可能问的前 5 个问题。此任务涉及利用用户过去的问题历史记录来准确预测他们未来的查询。
要点：
数据集：数据集由两列组成：用户 ID 和每个用户提出的相应问题。
预测目标：目标是建立一个模型，可以分析每个用户的历史问题数据，并通过提供用户 ID 来预测他们将来最有可能问的前 5 个问题。
总体而言，我们的目标是开发一个有效的预测模型，该模型可以预测每个用户可能会问的前 5 个问题，从而根据用户的历史行为改善用户互动和满意度。
我尝试了各种聚类算法来根据用户的历史数据预测用户最有可能问的前 5 个问题。然而，这些方法的准确性并不令人满意。我正在寻找可以提高我的预测准确性的替代方法或方法。]]></description>
      <guid>https://stackoverflow.com/questions/78160731/predicting-top-5-frequently-asked-questions-by-users-based-on-historical-data</guid>
      <pubDate>Thu, 14 Mar 2024 13:04:26 GMT</pubDate>
    </item>
    <item>
      <title>哪些指标用于二元预测，哪些指标用于概率？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78160698/which-metrics-are-used-for-binary-prediction-and-which-for-probability</link>
      <description><![CDATA[我正在构建一个 ML 模型（逻辑回归），该模型使用前一天的天气指标观测来预测天气状况。我已经获得了二进制预测以及predict_proba，现在我需要根据几个参数对其进行评估：

准确率得分，
杰卡德指数，
F1 分数，以及
对数丢失。

对于其中哪些我使用 predict_proba，对于哪些 - 预测？
我尝试了几种组合，但我不确定这些组合是否会输出正确的评估，并且我需要 100% 确定。]]></description>
      <guid>https://stackoverflow.com/questions/78160698/which-metrics-are-used-for-binary-prediction-and-which-for-probability</guid>
      <pubDate>Thu, 14 Mar 2024 12:59:25 GMT</pubDate>
    </item>
    <item>
      <title>无法使用此代码从文章中提取信息[关闭]</title>
      <link>https://stackoverflow.com/questions/78160347/fail-to-extract-information-from-articles-using-this-code</link>
      <description><![CDATA[这段代码应该从不同的文章链接中提取标题和主要文本，但由于没有找到任何标题或文本，它只是跳过了网址
# 网页抓取和数据处理
对于范围内的 i(2, ws.max_row + 1)：
    link = ws.cell(row=i,column=2).hyperlink.target if ws.cell(row=i,column=2).hyperlink else ws.cell(row=i,column=2).value
    
    print(&quot;正在处理 URL:&quot;, link) # 打印正在处理的 URL
    
    headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0&#39;}
    响应 = requests.get(链接, headers=headers)
    soup = BeautifulSoup(response.content, &#39;html.parser&#39;)

    如果不是 soup.find(&#39;h1&#39;) 或不是 soup.find(&#39;div&#39;, class_=&#39;td-post-content&#39;):
        print(“由于缺少‘h1’或‘div.td-post-content’而跳过 URL”)
        继续

    head = soup.find(&#39;h1&#39;).get_text()
    text = soup.find(&#39;div&#39;, class_=&#39;td-post-content&#39;).get_text()
]]></description>
      <guid>https://stackoverflow.com/questions/78160347/fail-to-extract-information-from-articles-using-this-code</guid>
      <pubDate>Thu, 14 Mar 2024 12:01:52 GMT</pubDate>
    </item>
    <item>
      <title>难以避开墙壁</title>
      <link>https://stackoverflow.com/questions/78160153/having-a-trouble-avoiding-the-wall</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78160153/having-a-trouble-avoiding-the-wall</guid>
      <pubDate>Thu, 14 Mar 2024 11:28:34 GMT</pubDate>
    </item>
    <item>
      <title>VAE 没有学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78159759/vae-is-not-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78159759/vae-is-not-learning</guid>
      <pubDate>Thu, 14 Mar 2024 10:25:17 GMT</pubDate>
    </item>
    <item>
      <title>由于CPU和GPU之间频繁的数据传输，CNN中的“零填充”是否会增加推理时间？</title>
      <link>https://stackoverflow.com/questions/78158937/does-zero-padding-in-cnn-increase-the-inference-time-due-to-frequent-data-tran</link>
      <description><![CDATA[我认为在设计 DNN 加速器或 NPU 时，CNN 中的零填充是一个非常烦人的操作。所以我想知道在 Pytorch/TF 等现代机器学习框架中，零填充是否在 CPU 或 GPU 上执行。如果在CPU上完成，当存在需要填充的连续层时，由于CPU和GPU之间频繁的数据移动，该操作是否会大大增加总推理时间？否则，GPU如何完成低效的padding操作呢？]]></description>
      <guid>https://stackoverflow.com/questions/78158937/does-zero-padding-in-cnn-increase-the-inference-time-due-to-frequent-data-tran</guid>
      <pubDate>Thu, 14 Mar 2024 08:07:04 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow federated 中工作时遇到“学习属性”错误</title>
      <link>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:24 GMT</pubDate>
    </item>
    <item>
      <title>所有多标签分类模型的准确性为零</title>
      <link>https://stackoverflow.com/questions/78158222/all-multi-label-classification-models-giving-zero-accuracy</link>
      <description><![CDATA[我尝试以零精度应用任何 scikit 多标签模型。
这是预处理后我的数据集的图片： X-label, y 标签，完整数据集
我尝试将 ClassfierChain、BinaryRelevance 和 LabelPowerSet 与多个分类模型一起应用，例如：
def build_model (模型、mlb_estimator、X_train、y_train、X_test、y_test) ：
    #创建实例
    clf = mlb_estimator(模型)
    clf.fit(X_train,y_train)
    
    ＃预测
    clf_pred = clf.predict(X_test)
    
    #检查准确性
    acc = 准确度_分数(y_test, clf_pred)
    火腿 = hamming_loss(y_test,clf_pred)
    结果= {“准确率”：acc，“汉明损失”：ham}
    返回结果

clf_chain_model = build_model(MultinomialNB(),LabelPowerset,X_train, y_train, X_test, y_test)

但我得到的只是 0.0 的准确度。
我认为数据预处理可能存在问题，但我无法弄清楚]]></description>
      <guid>https://stackoverflow.com/questions/78158222/all-multi-label-classification-models-giving-zero-accuracy</guid>
      <pubDate>Thu, 14 Mar 2024 05:05:27 GMT</pubDate>
    </item>
    <item>
      <title>使用遗传算法优化面部情绪识别模型超参数</title>
      <link>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</link>
      <description><![CDATA[我正在构建一个面部情绪识别系统，可以对快乐、悲伤、愤怒、惊讶等情绪进行分类。我已经使用 TensorFlow/Keras 训练了一个卷积神经网络模型，目前它的准确率达到了50%左右。然而，我相信微调超参数可能会进一步提高准确性。
现在，我有兴趣优化模型的超参数以实现更高的准确性。我听说过使用遗传算法进行超参数优化，但我不确定如何继续。有人可以指导我如何应用遗传算法来微调模型的超参数吗？具体来说，如何修改我的代码以纳入遗传算法以进行超参数优化？
这是我的代码摘要：
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras导入模型，层

# 数据增强
增强器 = ImageDataGenerator(
    重新缩放=1.0/255，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真
）

# 加载数据并将图像大小调整为 48x48 像素
Augmented_trained_data = Augmentor.flow_from_directory(
    “面部识别数据集/训练”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_validation_data = Augmentor.flow_from_directory(
    “面部识别数据集/验证”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_testing_data = Augmentor.flow_from_directory(
    “面部识别数据集/测试”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

# 模型定义
模型 = models.Sequential([
    层.Conv2D(32, (2, 2), 激活=“relu”, input_shape=(48, 48, 1)),
    层.MaxPool2D((2, 2)),
    层.Conv2D(64, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Conv2D(128, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Flatten(),
    层.密集（128，激活=“relu”），
    层数.Dropout(0.25),
    层.密集（6，激活=“softmax”）
]）

# 模型编译
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
    指标=[“准确度”]
）

# 模型训练
模型.拟合(
    增强训练数据，
    验证数据=增强验证数据，
    纪元=10
）

# 模型评估
test_loss, test_accuracy = model.evaluate(augmented_testing_data)
print(f&quot;测试准确度: {test_accuracy * 100:.2f}%&quot;)&#39;&#39;&#39;


]]></description>
      <guid>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</guid>
      <pubDate>Wed, 13 Mar 2024 22:53:36 GMT</pubDate>
    </item>
    <item>
      <title>常见用户流程分析[关闭]</title>
      <link>https://stackoverflow.com/questions/78156781/common-userflow-analysis</link>
      <description><![CDATA[我正在尝试在事件日志数据中找到常见的用户流模式。事件日志数据来自桌面应用程序，该应用程序捕获用户单击的位置以及时间戳。桌面应用程序中有 2000 多个独特的按钮。如何使用机器学习、深度学习来找出常见的用户流模式并可视化数据？
我尝试使用前缀跨度，但没有运气，因为我没有得到想要的结果。我认为前缀跨度不是这里的最佳选择。我应该使用任何其他算法或任何其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78156781/common-userflow-analysis</guid>
      <pubDate>Wed, 13 Mar 2024 20:58:12 GMT</pubDate>
    </item>
    <item>
      <title>无法将保存的 keras 模型转换为 TFLite</title>
      <link>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</guid>
      <pubDate>Wed, 13 Mar 2024 19:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>