<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Mar 2024 03:14:35 GMT</lastBuildDate>
    <item>
      <title>如何在 TensorFlow 中计算模型输出的 Hessian 矩阵</title>
      <link>https://stackoverflow.com/questions/78157906/how-to-compute-hessian-matrix-of-model-output-in-tensorflow</link>
      <description><![CDATA[我正在尝试制作拉格朗日神经网络，但遇到了障碍。我有一个训练有素的模型，可以预测系统拉格朗日量，现在为了获得运动方程，我需要一堆输出相对于输入变量的一阶和二阶导数。我可以得到一阶和二阶导数，但不能得到任何交叉项（我可以得到 d^2/dx^2，但不能得到 d^2/dxdy）。
鉴于我的顺序模型名为 model，它接受 8 个特征并输出 1 个预测，我尝试运行以下代码：
将 numpy 导入为 np
将张量流导入为 tf

pred_X = np.random.random(8)

使用 tf.GradientTape(persistent=True) 作为磁带：
    磁带.watch(pred_X)
    将 tf.GradientTape(persistent=True) 用作磁带2：
        Tape2.watch(pred_X)
        拉格朗日 = 模型(pred_X)

    model_grad = Tape2.gradient(拉格朗日, pred_X)
Second_order = Tape.gradient(model_grad, pred_X)
打印（f&#39;{second_order=}&#39;）

我得到的结果是一个 1x8 张量。我希望 Second_order 是 8x8 Hessian 矩阵。我无法使用 tf.hessians() ，因为它出错并表示我无法在 Eager 模式下使用它，而只能使用 GradientTape 来代替。我应该怎么做才能获得交叉项？]]></description>
      <guid>https://stackoverflow.com/questions/78157906/how-to-compute-hessian-matrix-of-model-output-in-tensorflow</guid>
      <pubDate>Thu, 14 Mar 2024 03:09:52 GMT</pubDate>
    </item>
    <item>
      <title>使用遗传算法优化面部情绪识别模型超参数</title>
      <link>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</link>
      <description><![CDATA[我正在致力于构建一个面部情绪识别系统，可以对快乐、悲伤、愤怒、惊讶等情绪进行分类。我已经使用 TensorFlow/Keras 训练了一个卷积神经网络模型，目前，它实现了准确率50%左右。然而，我相信微调超参数可能会进一步提高准确性。
现在，我有兴趣优化模型的超参数以实现更高的准确性。我听说过使用遗传算法进行超参数优化，但我不确定如何继续。有人可以指导我如何应用遗传算法来微调模型的超参数吗？具体来说，如何修改我的代码以纳入遗传算法以进行超参数优化？
任何帮助或建议将不胜感激。谢谢！
这是我的代码摘要：
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras导入模型，层

# 数据增强
增强器 = ImageDataGenerator(
    重新缩放=1.0/255，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真
）

# 加载数据并将图像大小调整为 48x48 像素
Augmented_trained_data = Augmentor.flow_from_directory(
    “面部识别数据集/训练”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_validation_data = Augmentor.flow_from_directory(
    “面部识别数据集/验证”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_testing_data = Augmentor.flow_from_directory(
    “面部识别数据集/测试”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

# 模型定义
模型 = models.Sequential([
    层.Conv2D(32, (2, 2), 激活=“relu”, input_shape=(48, 48, 1)),
    层.MaxPool2D((2, 2)),
    层.Conv2D(64, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Conv2D(128, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Flatten(),
    层.密集（128，激活=“relu”），
    层数.Dropout(0.25),
    层.密集（6，激活=“softmax”）
]）

# 模型编译
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
    指标=[“准确度”]
）

# 模型训练
模型.拟合(
    增强训练数据，
    验证数据=增强验证数据，
    纪元=10
）

# 模型评估
test_loss, test_accuracy = model.evaluate(augmented_testing_data)
print(f&quot;测试准确度: {test_accuracy * 100:.2f}%&quot;)&#39;&#39;&#39;


]]></description>
      <guid>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</guid>
      <pubDate>Wed, 13 Mar 2024 22:53:36 GMT</pubDate>
    </item>
    <item>
      <title>pandas merge 和 pandas concat 有什么区别？ [复制]</title>
      <link>https://stackoverflow.com/questions/78157149/what-is-the-difference-between-pandas-merge-and-pandas-concat</link>
      <description><![CDATA[给出 pandas concat 和 pandas merge 之间的一些主要区别？
答案的理论和这两个功能之间的基本区别。
以及需要重要的重要差异和领域。以及这个函数中使用的是什么函数。]]></description>
      <guid>https://stackoverflow.com/questions/78157149/what-is-the-difference-between-pandas-merge-and-pandas-concat</guid>
      <pubDate>Wed, 13 Mar 2024 22:30:03 GMT</pubDate>
    </item>
    <item>
      <title>常见用户流程分析</title>
      <link>https://stackoverflow.com/questions/78156781/common-userflow-analysis</link>
      <description><![CDATA[我正在尝试在事件日志数据中找到常见的用户流模式。事件日志数据来自桌面应用程序，该应用程序捕获用户单击的位置以及时间戳。桌面应用程序中有 2000 多个独特的按钮。如何使用机器学习、深度学习来找出常见的用户流模式并可视化数据？
我尝试使用前缀跨度，但没有运气，因为我没有得到想要的结果。我认为前缀跨度不是这里的最佳选择。我应该使用任何其他算法或任何其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78156781/common-userflow-analysis</guid>
      <pubDate>Wed, 13 Mar 2024 20:58:12 GMT</pubDate>
    </item>
    <item>
      <title>无法将保存的 keras 模型转换为 TFLite</title>
      <link>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</guid>
      <pubDate>Wed, 13 Mar 2024 19:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在 python 上使用相同的多重对应分析 (MCA) 将两个数据集投影到相同的组件空间上</title>
      <link>https://stackoverflow.com/questions/78156231/project-two-datasets-onto-the-same-component-space-using-the-same-multiple-corre</link>
      <description><![CDATA[我想将多重对应分析 (MCA) 应用于定性数据，以探索变量类别之间的关系。然后，我将此数据以及相同维度的另一个数据集投影到从 MCA 派生的组件上，以观察组件空间中的重叠。然而，我尝试使用 fanalysis 或 Prince 等库来执行此操作，但还没有得出结论性的结果。有人对如何实现这一目标有建议吗？
我尝试使用 fanalysis 和 Prince 从合成数据中重新计算 MCA 的主要成分。您有什么有用的建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78156231/project-two-datasets-onto-the-same-component-space-using-the-same-multiple-corre</guid>
      <pubDate>Wed, 13 Mar 2024 18:59:08 GMT</pubDate>
    </item>
    <item>
      <title>将一种概率分布转换/预测为另一种概率分布的网络</title>
      <link>https://stackoverflow.com/questions/78155703/a-network-to-transform-predict-one-probability-distribution-to-another</link>
      <description><![CDATA[我有一个特定密度的随机变量（例如，正态分布）和一个已知的概率分布（例如，混合高斯分布）。我使用一种简单的 KL 度量来预测/转换彼此。现在我需要使用神经网络来执行此类任务，并将一个随机变量转换为另一个随机变量。您能否建议一种网络类型来执行此操作，如果有开源代码将会非常有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78155703/a-network-to-transform-predict-one-probability-distribution-to-another</guid>
      <pubDate>Wed, 13 Mar 2024 17:20:04 GMT</pubDate>
    </item>
    <item>
      <title>当我在 python(jupyter Notebook) 中设置依赖项时，如何修复此错误？</title>
      <link>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies-in-pythonjupyter-n</link>
      <description><![CDATA[我只是想为我的机器学习作业设置依赖关系
!apt-get install -y xvfb python-opengl &gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
!apt-get install -y xvfb python-opengl ffmpeg &gt; /dev/null 2&gt;&amp;1
!pip 安装gym[classic_control]
!apt-get 更新 &gt; /dev/null 2&gt;&amp;1
!apt-get install cmake &gt; /dev/null 2&gt;&amp;1
!pip install --upgrade setuptools 2&gt;&amp;1
!pip install ez_setup &gt; /dev/null 2&gt;&amp;1

我收到此错误输出，显示某些安装正确，但有很多“系统找不到指定的路径。”
系统找不到指定的路径。

还有另一个错误
错误：子进程退出并出现错误
  
  python setup.py Egg_info 未成功运行。
  退出代码：1
  
  [77行输出]
  
  
  警告，没有“设置”文件存在，正在运行“buildconfig/config.py”
  使用WINDOWS配置...
  
 
  未找到 FREETYPE 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  找不到 PNG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  未找到 JPEG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  freetype 的 DLL：prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/libfreetype-6.dll
  
  ---
  如需编译帮助，请参阅：
      https://www.pygame.org/wiki/CompileWindows
  要为 pygame 开发做出贡献，请参阅：
      https://www.pygame.org/contribute.html
  ---
  
  [输出结束]
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：元数据生成失败

生成包元数据时遇到错误。

请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参见上文。

我尝试用谷歌搜索答案，也尝试过chatgpt，但没有一个能给我答案。任何人都可以帮助这里可怜的灵魂吗:-(,.]]></description>
      <guid>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies-in-pythonjupyter-n</guid>
      <pubDate>Wed, 13 Mar 2024 16:44:29 GMT</pubDate>
    </item>
    <item>
      <title>我无法让任何神经网络在 Pytorch 中工作。我究竟做错了什么？</title>
      <link>https://stackoverflow.com/questions/78155402/i-cant-make-any-nn-work-in-pytorch-what-am-i-doing-wrong</link>
      <description><![CDATA[我处理数据，并且在 Python 方面有不错的技能，我知道如何使用不同的模型，但之前我从未尝试过使用神经网络。
所以我是 pytorch 的新手，我决定使用在线教程和视频进行培训。
不幸的是，我发现我真的无法让这些模型发挥作用，并且得到了极其错误的结果。无论我遵循什么指南，这种情况都会发生，所以这肯定是我做错了。
例如，我遵循此分步指南，介绍如何使用波士顿住房数据集创建用于回归的神经网络。
这是我基本上从指南中复制的代码，因此应该没有任何区别。
导入火炬
从火炬导入 nn
从 torch.utils.data 导入 DataLoader
从 sklearn.preprocessing 导入 StandardScaler
将 pandas 导入为 pd

### 导入数据集
波士顿 = pd.read_csv(&#39;./housing.csv&#39;, header=None, sep=&#39;\s+&#39;)
波士顿.列= [
    &#39;犯罪&#39;，
    &#39;ZN&#39;,
    &#39;印度&#39;,
    &#39;查斯&#39;,
    &#39;氮氧化物&#39;,
    &#39;R M&#39;，
    &#39;年龄&#39;，
    &#39;DIS&#39;,
    &#39;RAD&#39;,
    &#39;税&#39;，
    &#39;普拉蒂奥&#39;,
    &#39;B&#39;,
    &#39;LSTAT&#39;,
    &#39;MEDV&#39;
]
xcol = boston.drop(columns=[&#39;MEDV&#39;]).columns
ycol = [&#39;MEDV&#39;]

X = 波士顿[xcol].values
y = 波士顿[ycol].值

### 创建 Torch 数据集
类 TorchDataset(torch.utils.data.Dataset):
    def __init__(self, X, y, scale_data=True):
        如果不是 torch.is_tensor(X) 也不是 torch.is_tensor(y)：
            如果比例数据：
                X = StandardScaler().fit_transform(X)
            self.X = torch.from_numpy(X)
            self.y = torch.from_numpy(y)

    def __len__(自身):
        返回 len(self.X)
    
    def __getitem__(自我，我)：
        返回 self.X[i], self.y[i]

### 构建 MLP
类 MLP(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.layers = nn.Sequential(
            nn.线性(13, 64),
            ReLU(),
            nn.线性(64, 32),
            ReLU(),
            nn.线性(32, 1)
            ）
        
    def 前向（自身，x）：
        返回 self.layers(x)

火炬.manual_seed(42)

数据集 = TorchDataset(X, y)
trainloader = DataLoader（数据集，batch_size = 10，shuffle = True，num_workers = 0）

MLP = MLP()

loss_function = nn.L1Loss()
优化器 = torch.optim.Adam(mlp.parameters(), lr=0.001)

### 训练循环
损失向量 = []

对于范围（1000）内的纪元：
    纪元损失 = 0

    对于 i，enumerate(trainloader, 0) 中的数据：
        输入、目标 = 数据
        输入，目标 = 输入.float(), 目标.float()
        目标 = 目标.reshape((目标.shape[0], 1))

        ## 将梯度归零
        优化器.zero_grad()
        
        ## 前向传球
        输出 = mlp(输入)

        ## 计算损失
        损失=损失函数（输出，目标）

        ## 向后传递
        loss.backward()
        
        ＃＃ 优化
        优化器.step()
        
        ## 统计
        epoch_loss += loss.item()
    
    loss_vec.append(epoch_loss)

## 可视化损失曲线
将plotly.express导入为px
px.scatter(loss_vec)

## 检查观察值和预测值之间的 R2 分数
从 sklearn.metrics 导入 r2_score

y_pred = mlp(torch.tensor(X, dtype=torch.float)).detach().numpy()


r2_score(y.flatten(), y_pred.flatten()) ##总是一个很大的负数

这是损失图

但最奇怪的部分是预测值
pd.DataFrame({
    &#39;观测&#39;:y.flatten(),
    &#39;Pred&#39;:y_pred.flatten()
})


正如您所看到的，我的神经网络预测的值完全超出了范围。
你能告诉我我在这里做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78155402/i-cant-make-any-nn-work-in-pytorch-what-am-i-doing-wrong</guid>
      <pubDate>Wed, 13 Mar 2024 16:30:40 GMT</pubDate>
    </item>
    <item>
      <title>不稳定、依赖种子的训练，具有约 4 种不同的模式</title>
      <link>https://stackoverflow.com/questions/78155315/unstable-seed-dependent-training-with-4-distinct-patterns</link>
      <description><![CDATA[我正在尝试复制一篇论文，但我遇到了不稳定训练的问题。更准确地说，重新运行代码会产生截然不同的结果。不过，我认为有 4 个主要模式。
模型和训练如下所示（完整代码位于https://www. kaggle.com/code/adelphene/dagmm）：
类 DAGMM(nn.Module):
    def __init__(self, input_dim=118, Latent_dim=1, n_gmm=4):
        超级().__init__()

        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 60), nn.Tanh(),
            nn.Linear(60, 30), nn.Tanh(),
            nn.Linear(30, 10), nn.Tanh(),
            nn.Linear(10, Latent_dim),
        ）

        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 10), nn.Tanh(),
            nn.Linear(10, 30), nn.Tanh(),
            nn.Linear(30, 60), nn.Tanh(),
            nn.Linear(60, input_dim),
        ）

        self.estimator = nn.Sequential(
            nn.Linear(latent_dim + 2, 10), nn.Tanh(),
            nn.Dropout(),
            nn.Linear(10, n_gmm), nn.Softmax(dim=1)
        ）

    def 前向（自身，x）：
        l = self.encoder(x)
        r = self.decoder(l)

        re = (x - r).norm(p=2, dim=1) / x.norm(p=2, dim=1)
        cs = F.cosine_similarity(x, r, 暗淡=1)
        z = torch.cat((l, re.unsqueeze(-1), cs.unsqueeze(-1)), 暗淡=1)

        g = 自估计器(z)

        返回 r、z、g

#------------------------------------------------- -----

torch.autograd.set_detect_anomaly(False)

历元 = 200
lr = 1e-4

loss_fn = 损失()
批次 = len(train_dataloader)
模型 = DAGMM(n_gmm=4).to(设备)
优化器 = torch.optim.Adam(model.parameters(), lr=lr)

对于范围内的纪元（纪元）：
    对于批量，枚举（train_dataloader）中的（x，_）：
        r, z, g = model.train()(x)
        损失，_ = loss_fn(x, r, z, g)
        loss.backward()
        优化器.step()
        优化器.zero_grad()

        如果批次 % 400 == 0:
            r、z、g = model.eval()(val_dataset.x)
            val_loss, e = loss_fn(val_dataset.x, r, z, g)
            阈值 = np.percentile(e.detach().cpu(), 80)
            y_pred = (e &gt; 阈值) * 1
            y_true = val_dataset.y
            报告=分类报告（y_true.cpu（），y_pred.cpu（），output_dict = True）
            a = round(报告[“准确度”], 2)
            p = round(报告[“宏平均值”][“精度”], 2)
            r = round(报告[“宏观平均值”][“召回率”], 2)
            print(f&quot;loss: {round(loss.item(), 3)}, 准确度: {a}, 精度: {p}, 召回率: {r} [{batch+1}/{batches}] [{epoch +1}/{纪元}]”)

需要明确的是，纪元数、优化器和学习率直接取自论文。
我得到的模式如下：

损失降低至 0.5/0.6/0.7，准确率约为 0.88，精确率和召回率均约为 0.82
损失值约为 2.0，准确率约为 0.6，精确率和召回率约为 0.44
损失在 ~1.5 和 ~0.8 之间，准确度在 ~0.75 和 ~0.85 之间，精确率和召回率在 ~0.65 和 ~0.75 之间
（最佳）准确率下降至 ~1.2/~0.8，准确率上升至 ~0.94，精确率和召回率上升至 ~0.92

我不太确定应该如何处理这个问题。任何指导表示赞赏！
PS：我相信我比其他人更频繁地观察模式 2。]]></description>
      <guid>https://stackoverflow.com/questions/78155315/unstable-seed-dependent-training-with-4-distinct-patterns</guid>
      <pubDate>Wed, 13 Mar 2024 16:18:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 sklearns 的 cross_validate 对样本进行加权仅用于评分？</title>
      <link>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</link>
      <description><![CDATA[我正在对由真实样本和增强样本组成的数据集运行回归任务。增强样本是通过抖动真实样本生成的。我想通过与 sklearn 进行交叉验证来选择性能最佳的模型。
为此我想：

在由真实样本和增强样本组成的集合上训练模型。我不希望拟合过程考虑样本的来源（即它应该相当于运行estimator.fit(..., sample_weights = [1,1,..., 1]).
根据模型仅在真实样本上的表现对模型进行评分。为此，我考虑将增强（或真实）样本的权重设置为 0（或 1）。

如何使用sklearn的cross_validate&lt;来实现这一点/代码&gt;？
我尝试了以下方法：
来自 sklearn 导入 model_selection
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error、make_scorer
将 numpy 导入为 np

n_smpl, n_feats = 100, 5
arr_source = np.random.random((n_smpl, n_feats))
arr_target = np.random.random((n_smpl, n_feats))
arr_weight = np.random.randint(0, 2, n_smpl) # 0 表示增强，1 表示真实

模型 = RandomForestRegressor()
kfold_splitter = model_selection.KFold(n_splits=5, random_state=7, shuffle=True)
我的得分者 = {
    “r2_weighted”：make_scorer（r2_score，sample_weight = arr_weight），
    “mse_weighted”：make_scorer（mean_squared_error，greater_is_better = False，sample_weight = arr_weight）
}

cv_results = model_selection.cross_validate（模型，arr_source，arr_target，评分= my_scorers，cv = kfold_splitter）

但这会返回ValueError：发现样本数量不一致的输入变量：[20, 20, 100]。我知道发生这种情况是因为 cross_validate 无法根据折叠分割样本权重。
有什么方法可以让它通过交叉验证吗？或者还有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</guid>
      <pubDate>Wed, 13 Mar 2024 15:36:03 GMT</pubDate>
    </item>
    <item>
      <title>我们可以结合 RL 和 ML/DL 来进行复杂的二元分类吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</link>
      <description><![CDATA[事情是这样的：
有一个金融数据集（Freddie Mac Single-Family Loan-Level Dataset），其中包含：客户的地址、交易流向以及许多其他特征（大约20个）。
有一个特征可以判断客户是否存在延期还款的情况，即判断他是否是诈骗者。
我想通过 RL 和 ML/DL 组合来学习所有其他功能。然后只有通过在模型中输入其他特征来判断该客户是否会进行欺诈。
我目前的想法是：从随机分类开始，然后利用RL和ML/DL结合模型不断调整分类方法（调整特征权重、模型中的内部指标等）以获得最佳分类方法并获得最高的分类精度。
但是我不知道如何开始，因为我对强化学习不是很熟悉。 （我对深度学习和机器学习比较熟悉）
我找不到任何相关参考资料。
有人可以给我一个想法或教程吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</guid>
      <pubDate>Wed, 13 Mar 2024 14:42:00 GMT</pubDate>
    </item>
    <item>
      <title>使用文本特征的二元分类导致 AUC 分数非常低</title>
      <link>https://stackoverflow.com/questions/78154496/binary-classification-using-textual-features-results-in-very-low-auc-scores</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78154496/binary-classification-using-textual-features-results-in-very-low-auc-scores</guid>
      <pubDate>Wed, 13 Mar 2024 14:20:24 GMT</pubDate>
    </item>
    <item>
      <title>验证错误：无法实例化 GPT4AllEmbeddings 模型</title>
      <link>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</link>
      <description><![CDATA[我在尝试创建 GPT4AllEmbeddings 实例时遇到问题。但是我不断收到以下错误
单元格 In[15]，第 1 行
----&gt; 1 vectorstore = Chroma.from_documents(文档 = 分割, 嵌入 = GPT4AllEmbeddings())
      2 检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
      3检索文档=检索器.get_relevant_documents（“你是什么？”）

文件 ~\anaconda3\Lib\site-packages\pydantic\main.py:341，在 pydantic.main.BaseModel.__init__() 中

ValidationError：GPT4AllEmbeddings 出现 1 个验证错误
__根__
  无法实例化模型（type=value_error）

这是相关的代码片段
vectorstore = Chroma.from_documents(documents = splits, embeddings = GPT4AllEmbeddings())
检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
retrieved_docs =retrieve.get_relevant_documents(“什么是Young Decade？”)
打印（len（检索文档））
打印（retrieve_docs[0].page_content）

如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</guid>
      <pubDate>Wed, 13 Mar 2024 09:36:07 GMT</pubDate>
    </item>
    <item>
      <title>如何在sklearn中计算.fit()训练模型的实际大小？</title>
      <link>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</link>
      <description><![CDATA[是否可以在 scikit-learn 中计算模型（假设是随机森林分类器）的大小？ 
例如：

&lt;块引用&gt;
 from sklearn.ensemble import RandomForestClassifier
  clf = RandomForestClassifier(n_jobs=-1, n_estimators=10000, min_samples_leaf=50)
  clf.fit(self.X_train, self.y_train)


我可以确定clf的大小吗？]]></description>
      <guid>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</guid>
      <pubDate>Wed, 09 Aug 2017 23:00:07 GMT</pubDate>
    </item>
    </channel>
</rss>