<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 03 Jan 2024 18:17:26 GMT</lastBuildDate>
    <item>
      <title>请帮助我从 html 页面以数组形式输入 30 个 csv 值，以输入机器学习模型</title>
      <link>https://stackoverflow.com/questions/77753838/please-help-me-to-input-30-csv-values-in-an-array-from-html-page-to-feed-into-ma</link>
      <description><![CDATA[view.py
def 输出（请求）：
    dff = pd.read_csv(r&#39;C:\Users\rabin\Downloads\data.csv&#39;)
    y = dff[&#39;诊断&#39;].值
    x = dff.drop(&#39;诊断&#39;, axis=1).values
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40)
    模型=逻辑回归()
    model.fit(x_train, y_train)
    v1 = np.array((request.GET[&#39;n1&#39;])) 这是我输入 30 个逗号分隔值的地方。

pred = model.predict([v1])
    pred1 = &quot;&quot;;
    如果 pred==[1]:
        pred1 =“阳性”
    别的：
        pred1 =“阴性”
return render(request, &#39;prediction.html&#39;, {&quot;predictResult&quot;:**pred1**})


预测.html
;
    &lt;表单动作＝“输出”&gt;
        &lt;表&gt;
            &lt;tr&gt;
                &lt;tdalign=“右”&gt;怀孕&lt;/td&gt;
               &lt;输入类型=“文本” name=“n1”&gt;&lt;/td&gt;
            
    &lt;/表&gt;
     &lt;输入类型=“提交”&gt;
    &lt;/表格&gt;

    结果：{{ 预测结果 }}


如何将 30 个逗号分隔值放入此代码 v1 = np.array((request.GET[&#39;n1&#39;]))
我在上面尝试过但是
** 收到如下错误消息**

/预测/输出处的值错误
预期是二维数组，却得到一维数组：
数组=[&#39;17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01 587,0.03003,0.006193,25.38,17.33,184.6, 2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189&#39;]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。
请求方式：GET
请求网址：http://127.0.0.1:8000/prediction/output?n1=17.99%2C10.38%2C122.8%2C1001%2C0.1184%2C0.2776%2C0.3001%2C0.1471%2C0.2419 %2C0.07871%2C1.095%2C0.9053%2C8.589%2C153.4%2C0.006399%2C0.04904%2C0.05373%2C0.01587%2C0.03003%2C0.006193%2C25.38%2C17 .33%2C184.6%2C2019%2C0.1622%2C0.6656%2C0.7119%2C0.2654%2C0.4601%2C0.1189
姜戈版本：5.0
异常类型：值错误]]></description>
      <guid>https://stackoverflow.com/questions/77753838/please-help-me-to-input-30-csv-values-in-an-array-from-html-page-to-feed-into-ma</guid>
      <pubDate>Wed, 03 Jan 2024 18:02:59 GMT</pubDate>
    </item>
    <item>
      <title>用于具有非常小的值的回归问题的度量</title>
      <link>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</link>
      <description><![CDATA[我正在研究一个回归问题，目标列中的值范围在 0.01 到 0.1 之间。我正在尝试找到正确的指标来评估训练模型的性能。
r2 分数似乎不太适合它。任何人都可以为这种情况推荐一个吗？]]></description>
      <guid>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</guid>
      <pubDate>Wed, 03 Jan 2024 16:08:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在回归中找到特征值以获得因变量范围内的值？</title>
      <link>https://stackoverflow.com/questions/77753120/how-can-i-find-the-feature-values-in-a-regression-to-get-values-within-a-range</link>
      <description><![CDATA[我已经进行了回归，拟合效果很好。我的响应变量是从 0 到 1 连续的，我想找到给我的值大于 0.7 的解释变量的值。我能做什么？]]></description>
      <guid>https://stackoverflow.com/questions/77753120/how-can-i-find-the-feature-values-in-a-regression-to-get-values-within-a-range</guid>
      <pubDate>Wed, 03 Jan 2024 15:59:36 GMT</pubDate>
    </item>
    <item>
      <title>用于支持向量数据描述的Python包[关闭]</title>
      <link>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</link>
      <description><![CDATA[在寻找支持向量数据描述（SVDD）代码示例时，我发现了这个代码示例页面，其中 SVDD 显示为实用程序，可能位于 python 中的包 libsvm 下。但在包手册页中发现没有类似的东西存在。我发现的其他软件包是 libsvm-svdd 和 SVDD-python 但我无法按照描述使用它们。请建议一个可用的 SVDD 包，我将在疾病数据的研究工作中使用它。]]></description>
      <guid>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</guid>
      <pubDate>Wed, 03 Jan 2024 14:43:53 GMT</pubDate>
    </item>
    <item>
      <title>如何从不同样本预测多变量时间序列[关闭]</title>
      <link>https://stackoverflow.com/questions/77752189/how-to-predict-multi-variate-timeseries-from-different-samples</link>
      <description><![CDATA[在使用不同样本的数据集进行训练时，我无法找到预测时间序列的最佳方法。
我有一个数据集，显示 10 只兔子从第一天到第 50 天的体重，每天测量 5 次。有了它，我还有一些不同的值，例如房间的温度、湿度和其他值。还有更多，但它们可能真的很有用。
我想用一只新兔子的数据来预测它会如何成长。例如，如果兔子只有 30 天大，到目前为止所有其他数据都已收集完毕，我想预测它接下来 20 天的体重。
我不确定如何使用所有信息来完成此任务。我正在考虑使用 ARIMA 或 LSTM 等时间序列预测方法，但考虑到我拥有不同兔子的数据，这可能不是最佳选择。
我也不确定如何将同一特征/目标的多个数据集合并到模型中，以便我可以预测新兔子的数据。使用兔子的名字作为分类变量/特征可能会起作用。
这是绘制的数据图，它们有些相似，但偏移量不同（抱歉，我无法向外部提供这些数据）
所以问题是：

使用所需的尽可能多的数据来预测新兔子未来 20 天的体重的最佳方法是什么？
我真的可以使用 10 只兔子的数据集吗？还是应该只得到它们的平均值，因为它们看起来很相似，只是偏移量有所不同？
如果其他特征/值（例如温度）不可预测/可控，但预测时可能会出现一些错误（例如天气数据），那么使用它们是否会有危险？

我做了什么：
仅针对体重的 ARIMA 效果并不好，但我尝试使用梯度提升等回归模型，将兔子的名称作为数字和分类值来识别每个数据。
我尝试使用迭代方式进行预测，仅预测下一个重量（不使用温度或湿度等其他数据），并通过对每个数据进行滞后来使用一些过去的重量作为特征。结果不太好
我尝试添加一堆目标滞后，但为了未来的权重（例如，weight_after_1_day 等 20 个新功能将成为未来 20 天的目标），以便我使用尽可能多的数据。
我也尝试过 LSTM，但我不知道如何使 calcategories 变量起作用，所以我想知道我之前是否做对了。也许在这种情况下这是不可能的，我应该只使用一个兔子时间序列？]]></description>
      <guid>https://stackoverflow.com/questions/77752189/how-to-predict-multi-variate-timeseries-from-different-samples</guid>
      <pubDate>Wed, 03 Jan 2024 13:23:38 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 StandardScaler 时 CustomScaler 中出现类型错误</title>
      <link>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</link>
      <description><![CDATA[我在使用 scikit-learn 的 Python 中遇到自定义缩放器类的问题。我有一个继承自 BaseEstimator 和 TransformerMixin 的 CustomScaler 类，它使用 StandardScaler。但是，我在初始化过程中遇到了类型错误。相关代码如下：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.preprocessing 导入 StandardScaler

类 CustomScaler(BaseEstimator,TransformerMixin):
    
    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
        self.scaler = StandardScaler(复制,with_mean,with_std)
        self.columns = 列
        self.mean_ = 无
        self.var_ = 无

    def fit(self, X, y=None):
        self.scaler.fit(X[self.columns], y)
        self.mean_ = np.mean(X[self.columns])
        self.var_ = np.var(X[self.columns])
        返回自我

    def 变换（自身，X，y=无，复制=无）：
        init_col_order = X.列
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        返回 pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]


unscaled_input.columns.values
columns_to_scale = [&#39;月份值&#39;,
       “星期几”、“交通费用”、“上班距离”、
       ‘年龄’、‘每日平均工作负荷’、‘体重指数’、‘儿童’、‘宠物’]

absenteeism_scaler = CustomScaler(columns= columns_to_scale) // 这一步出错
缺席主义_scaler.fit（unscaled_input）

我检查了 StandardScaler 类的 scikit-learn 文档以确保正确使用，但我找不到此错误的任何解决方案。
什么可能导致此问题？有其他方法可以解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</guid>
      <pubDate>Wed, 03 Jan 2024 10:34:48 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17)</title>
      <link>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</link>
      <description><![CDATA[
第 1 步：创建管道
第2步：将管道转换为数据帧
第3步：我正在尝试将管道转换为数据帧，但出现异常。如何解决这个问题
第 4 步：如何解决 ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17) 在管道转换为数据帧之上，

from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
从 sklearn.impute 导入 SimpleImputer
从 sklearn.pipeline 导入管道
从 sklearn.compose 导入 ColumnTransformer

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split

print(&quot;步骤1：导入lib&quot;)
print(&quot;第2步：加载原始数据&quot;)
df = pd.read_csv(“online_shoppers_intention.csv”)

print(&quot;第三步：数据准备&quot;)
X = df.drop([&#39;收入&#39;], axis = 1)
y = df[&#39;收入&#39;]

print(&quot;第四步：数据分割&quot;)
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = .3、random_state = 0)
名称 = X_train.columns.tolist()

numeric_transformer = SimpleImputer(策略 = &#39;常量&#39;)
categorical_transformer = OneHotEncoder(handle_unknown = &#39;忽略&#39;)

numeric_cols = X.select_dtypes(exclude = &quot;object&quot;).columns.values.tolist()
categorical_cols = X.select_dtypes(exclude = [&#39;int&#39;, &#39;float64&#39;, &#39;bool&#39;]).columns.values.tolist()
    
预处理器 = ColumnTransformer(
    变形金刚=[
    (&#39;num&#39;, numeric_transformer, numeric_cols)
    ,(&#39;猫&#39;, categorical_transformer, categorical_cols)
    ],
    余数 = &#39;直通&#39;)

pipeline_preprocessor = Pipeline(steps = [(“预处理器”, 预处理器), (“pandarizer”, FunctionTransformer(lambda x: pd.DataFrame(x, columns = 名称)))]).fit(X_train)
    
X_train_pipe = pipeline_preprocessor.transform(X_train)
X_test_pipe = pipeline_preprocessor.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</guid>
      <pubDate>Wed, 03 Jan 2024 07:51:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有一种方法可以使用 matplotlib 绘制多个图形，每个图形上有多条线？</title>
      <link>https://stackoverflow.com/questions/77749447/is-there-a-way-to-plot-multiple-graphs-with-multiple-lines-on-each-one-using-mat</link>
      <description><![CDATA[我正在尝试绘制不同指标的学习曲线，例如训练和验证损失和准确性。
对于学习率中的 lr：
    opt = SGD(学习率 = lr)
    model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])
    网络= model.fit（x_train_subset，y_train_subset，epochs =迭代，batch_size = 32，validation_data =（X_test，y_test），详细= 1）

    train_loss_values = network.history[&#39;loss&#39;]
    train_accuracy_values = network.history[&#39;accuracy&#39;]
    val_loss_values = 网络.history[&#39;val_loss&#39;]
    val_accuracy_values = network.history[&#39;val_accuracy&#39;]

    plt.plot(epochs, train_accuracy_values, label=f&#39;LR = {lr}&#39;)
    
plt.title(&#39;不同学习率下历元的训练精度&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.ylabel(&#39;训练准确率&#39;)
plt.图例()
plt.网格（真）
plt.show()

这是我拥有的代码，对于以训练准确性为指标的一张图来说，它完全按照我想要的方式工作。
上述代码的输出：

但是，我想针对以下代码中存储的所有不同指标复制此操作四次：
train_loss_values = network.history[&#39;loss&#39;]
train_accuracy_values = network.history[&#39;accuracy&#39;]
val_loss_values = 网络.history[&#39;val_loss&#39;]
val_accuracy_values = network.history[&#39;val_accuracy&#39;]

如果我简单地执行以下操作，它不会创建 4 个单独的图表，它只是将所有数据添加到一个图表中。
对于学习率中的 lr：
    opt = SGD(学习率 = lr)
    model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])
    网络= model.fit（x_train_subset，y_train_subset，epochs =迭代，batch_size = 32，validation_data =（X_test，y_test），详细= 1）

    train_loss_values = network.history[&#39;loss&#39;]
    train_accuracy_values = network.history[&#39;accuracy&#39;]
    val_loss_values = 网络.history[&#39;val_loss&#39;]
    val_accuracy_values = network.history[&#39;val_accuracy&#39;]

    plt.plot(epochs, train_accuracy_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, train_loss_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, val_accuracy_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, val_loss_values, label=f&#39;LR = {lr}&#39;)
    
plt.title(&#39;不同学习率下历元的训练精度&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.ylabel(&#39;训练准确率&#39;)
plt.图例()
plt.网格（真）
plt.show()

我询问了 ChatGPT，它总是建议再次运行整个神经网络 4 次，但我已经运行了一次并在列表中收集了我需要的所有数据。我只需要创建 4 个单独的图。]]></description>
      <guid>https://stackoverflow.com/questions/77749447/is-there-a-way-to-plot-multiple-graphs-with-multiple-lines-on-each-one-using-mat</guid>
      <pubDate>Wed, 03 Jan 2024 02:30:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GPT-2计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</link>
      <description><![CDATA[我正在开发一个使用 GPT-2（特别是 GPT2Model 类）计算单词和句子嵌入的程序。对于词嵌入，我在转发 input_ids 后提取最后一个隐藏状态 outputs[0]，其形状为 batch size x seq len ，到 GPT2Model 类。至于句子嵌入，我在序列末尾提取单词的隐藏状态。这是我尝试过的代码：
从变压器导入 GPT2Tokenizer、GPT2Model
进口火炬

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
模型 = GPT2Model.from_pretrained(&#39;gpt2&#39;)
Captions = [“示例标题”、“示例鸟”、“鸟是黄色的，有红色翅膀”、“嗨”、“非常好”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = word_embedding[ :, -1, : ].contigious()


我不确定我对单词和句子嵌入的计算是否正确，有人可以帮我确认一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</guid>
      <pubDate>Tue, 02 Jan 2024 21:55:52 GMT</pubDate>
    </item>
    <item>
      <title>1 个时期后，训练损失显着下降 [关闭]</title>
      <link>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</link>
      <description><![CDATA[在此处输入图像描述
当我运行模型时，一个时期后，训练损失急剧下降，我不明白为什么。
这个模型不是我创建的；相反，我从 GitHub 上 AAAI（人工智能促进协会）接受的代码中获取了它。 （股票预测模型）
代码已经包含了 dropout 和标准化，但我不明白为什么会发生这种情况。
此外，不仅一个数据集会出现此问题，其他数据集（SP、CSI、NDQ 和 NI）也会出现此问题。
*培训：8 年，验证：1 年，测试：2 年
为什么会发生这种情况？
我希望模型不会过度拟合，因为该模型已被顶级会议接受，并且除了按照说明进行操作外，我没有尝试过任何其他操作。
虽然这个模型没有提供具体数据，但我使用了一般股票数据作为模型的输入。
*代码模型
HGAT 类（torch.nn.Module）：
def __init__(self, 代码):
    超级（HGAT，自我）.__init__()
    self.tickers = 代码
    self.grup = gru(5,32) #或 lstm
    self.attention = 注意(32)
    self.hatt1 = nn.HypergraphConv(32, 32, use_attention=True, Heads=4, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.hatt2 = nn.HypergraphConv(32, 32, use_attention=True, Heads=1, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.liear = torch.nn.Linear(32,1)
defforward(self,price_input,e):
    上下文，查询 = self.grup(price_input)
    查询 = 查询.reshape(1026,1,32)
    输出，权重= self.attention（查询，上下文）
    输出 = 输出.reshape((1026,32))
    x = F.leaky_relu(self.hatt1(输出,e), 0.2)
    x = F.leaky_relu(self.hatt2(x,e), 0.2)
    返回 F.leaky_relu(self.liear(x))
]]></description>
      <guid>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</guid>
      <pubDate>Tue, 02 Jan 2024 15:31:25 GMT</pubDate>
    </item>
    <item>
      <title>LipVoicer Online 开源模型使用</title>
      <link>https://stackoverflow.com/questions/77746726/lipvoicer-online-open-source-model-usage</link>
      <description><![CDATA[主题：在自定义样本上测试 LipVoicer 模型的难度
我目前正在使用 LipVoicer 模型，这是一个开源在线工具，旨在从无声视频中生成语音。 LipVoicer 的 GitHub 存储库位于 https://github.com/yochaiye/LipVoicer。
虽然我已经在 Kaggle 笔记本上成功设置了模型环境，如下面的代码所示：
!git 克隆 https://github.com/yochaiye/LipVoicer.git
cd 唇音
!apt-get 安装 ffmpeg
!git 克隆 https://github.com/hhj1897/face_detection.git
cd 人脸检测
!apt-get 安装 git-lfs
!git lfs 拉
pip install -e 。
光盘 ..
!git 克隆 https://github.com/hhj1897/face_alignment.git
cd 面对齐
pip install -e 。
光盘 ..
!git clone --recursive https://github.com/parlance/ctcdecode.git
cd ctc解码
！点安装。

自述文件提供了模型及其设置的概述，但在指导用户完成测试阶段方面存在不足，尤其是在使用示例时。我正在寻求有关如何在我的特定样本集上有效测试 LipVoicer 模型的帮助或指导。
任何有关此事的见解、指示或建议将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77746726/lipvoicer-online-open-source-model-usage</guid>
      <pubDate>Tue, 02 Jan 2024 14:37:46 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML (TensorFlow-Pytorch) 中几乎没有要预测的列，是否有一个库可以以人工方式创建“人工”列？</title>
      <link>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</link>
      <description><![CDATA[我在 ML 中几乎没有要预测的列。
我想要：

生成额外的列（正弦、平均值等）。

应该评估这些额外的列（无论它是否改进模型）。


我的 ML 中需要更多数据来预测的列很少。例如，我有一个以度为单位的角度数据，我取了正弦、余弦和正切值。
我想要所有类型的统计数据（对机器学习有效，即前瞻性数据），以及任何类型的“阿里”数据。 自动为提供数据机器学习模型 (TensorFlow-Pytorch)。提供到具有这些功能的库的链接，以生成“人工”文件。数据或机器学习。 （我不是在寻找 SMOTE）
额外，如果它会为我评估它们??？了解使用哪些输入 fit()。]]></description>
      <guid>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</guid>
      <pubDate>Tue, 02 Jan 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么支持向量机的 varImp() 出现错误？</title>
      <link>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:22 GMT</pubDate>
    </item>
    <item>
      <title>Langchain AgentExecutor 不会使用任何工具</title>
      <link>https://stackoverflow.com/questions/76886176/langchain-agentexecutor-wont-use-any-tools</link>
      <description><![CDATA[我正在使用 tiiuae/falcon-40b-instruct 关闭 HF，并尝试将其与 LangChain ReAct 合并。我使用的是带有 StringPromptTemplate 的常规 LLMChain，它只是标准的思想/动作/动作输入/观察提示，并包含一些示例（我已经尝试过使用和不使用示例，但似乎两种方式都不起作用） 。 LLMChain 是 LLMSingleActionAgent 的一部分，然后由 AgentExecutor 运行。
问题是，执行者似乎无法使用任何工具。大多数时候，它能够选择正确的工具，但只会产生工具的输出结果。打开调试模式后，很明显，大多数时候它实际上并没有进入工具/开始或工具/结束链。之前一些关于类似问题的帖子建议提高模型的温度。随着温度的升高，可能有 5%-10% 的时间会进入工具链，但唯一返回的就是无效或不完整的响应。
我不太清楚哪里可能出了问题，但这里是我的链和代理的定义方式，作为任何感兴趣的人的起点，以及包含完整代码的 Github 存储库 此处：
# 由 LLM 和提示符组成的 LLM 链
llm_chain = LLMChain(llm=local_llm, 提示=提示)

tool_names = [工具中工具的工具名称]

代理 = LLMSingleActionAgent(
    llm_链=llm_链,
    output_parser=自定义输出解析器(),
    stop=[“\n观察结果：”],
    allowed_tools=工具名称
）
#handle_parsing_errors=“检查你的输出并确保它符合要求！”
agent_executor = AgentExecutor.from_agent_and_tools(agent=agent,
                                                    工具=工具，
                                                    详细=真）

我尝试过使用结构化工具并调整提示。然而，执行者只是不使用可用的工具，就会发生同样的错误。我已在此处附加了错误的图像。模型出现幻觉且未使用工具。 ]]></description>
      <guid>https://stackoverflow.com/questions/76886176/langchain-agentexecutor-wont-use-any-tools</guid>
      <pubDate>Fri, 11 Aug 2023 19:06:43 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 scikit-learn K-Means Clustering 指定您自己的距离函数？</title>
      <link>https://stackoverflow.com/questions/5529625/is-it-possible-to-specify-your-own-distance-function-using-scikit-learn-k-means</link>
      <description><![CDATA[是否可以使用 scikit-learn K-Means 聚类指定您自己的距离函数？]]></description>
      <guid>https://stackoverflow.com/questions/5529625/is-it-possible-to-specify-your-own-distance-function-using-scikit-learn-k-means</guid>
      <pubDate>Sun, 03 Apr 2011 12:39:33 GMT</pubDate>
    </item>
    </channel>
</rss>