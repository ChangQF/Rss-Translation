<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Jun 2024 18:20:27 GMT</lastBuildDate>
    <item>
      <title>当我根据 SaleDate 对数据框进行排序时，为什么数据框的字符串列的值会转换为 NaN</title>
      <link>https://stackoverflow.com/questions/78608812/why-are-my-values-of-string-column-of-dataframe-getting-converted-to-nan-when-i</link>
      <description><![CDATA[我的原始数据有一个 UsageBand 列，其中包含低、中和高的字符串值（以及一些缺失的条目）。但是，当我将 sort_values 函数应用于我的数据并根据“saledate”列对其进行排序时，UsageBand 列（以及其他字符串列）的所有字符串值都会转换为 NaN。为什么会发生这种情况？
这是 UsageBand 列中包含字符串值的原始数据
这是排序的代码片段 -
df.sort_values(by=[&quot;saledate&quot;],inplace=True,ascending= True)
这是排序后的数据。注意 UsageBand 列中的值被转换为 NaN
我预计 UsageBand 列（以及所有其他字符串列）中的值即使在应用排序后仍保持为字符串类型。]]></description>
      <guid>https://stackoverflow.com/questions/78608812/why-are-my-values-of-string-column-of-dataframe-getting-converted-to-nan-when-i</guid>
      <pubDate>Tue, 11 Jun 2024 16:41:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用时间序列数据的传统模型提前预测销售额？</title>
      <link>https://stackoverflow.com/questions/78608506/how-to-predict-sales-in-advance-using-tradition-model-using-time-series-data</link>
      <description><![CDATA[将 pandas 导入为 pd
将 numpy 导入为 np
导入 holidays
将 matplotlib.pyplot 导入为 plt
将 statsmodels.api 导入为 sm
从 datetime 导入 datetime、timedelta
从 sklearn.model_selection 导入 train_test_split
从 sklearn.linear_model 导入 LinearRegression
从 sklearn.ensemble 导入 RandomForestRegressor、GradientBoostingRegressor
从 sklearn.metrics 导入 mean_absolute_error

np.random.seed(0) 

start_date = datetime(2022, 1, 1)
end_date = start_date + timedelta(days=730)
dates = pd.date_range(start_date, end_date, freq=&#39;MS&#39;)

sales = np.random.randint(50, 200, size=len(dates))

sales_data = pd.DataFrame({&#39;日期&#39;: 日期, &#39;销售&#39;: 销售})
sales_data.index = sales_data[&#39;日期&#39;]
sales_data = sales_data.drop([&#39;日期&#39;], axis=1)
sales_data[&#39;月份&#39;] = sales_data.index.月份
sales_data[&#39;季度&#39;] = sales_data.index.季度
sales_data[&#39;滞后 1&#39;] = sales_data[&#39;销售&#39;].shift(1)
sales_data[&#39;滞后 3&#39;] = sales_data[&#39;销售&#39;].shift(3)
sales_data[&#39;滞后 6&#39;] = sales_data[&#39;销售&#39;].shift(6)
sales_data[&#39;滚动平均值 2&#39;] = sales_data[&#39;销售&#39;].rolling(window=2).mean()
sales_data[&#39;滚动平均值 3&#39;] = sales_data[&#39;Sales&#39;].rolling(window=3).mean()
sales_data[&#39;Rolling_Mean_6&#39;] = sales_data[&#39;Sales&#39;].rolling(window=6).mean()
sales_data = sales_data.dropna()

我正在尝试学习时间序列建模。
这是我使用虚拟数据的代码。现在我想使用线性回归、随机森林和梯度提升等传统模型来训练这些数据。那么，现在我们如何训练模型，使其能够预测从模型运行之日起 90 天的预测？
例如，目前此数据集中的最小日期为 2022-07-01，最大日期为 2024-01-01。
那么，我们如何准备一个数据集来训练机器学习模型进行 90 天/3 个月的预测？即使模型在 2024-04-01 运行，我们也应该知道或确信它做出的预测是针对 2024-07-01。
我正在尝试学习针对 2024-07-01 进行的单一预测，而不是多个分步预测。]]></description>
      <guid>https://stackoverflow.com/questions/78608506/how-to-predict-sales-in-advance-using-tradition-model-using-time-series-data</guid>
      <pubDate>Tue, 11 Jun 2024 15:29:44 GMT</pubDate>
    </item>
    <item>
      <title>YOLOX 训练时评估问题，操作数不能与形状 (0,5) 和 (0,) 一起广播</title>
      <link>https://stackoverflow.com/questions/78608411/yolox-evaluation-problem-when-training-operands-could-not-be-broadcast-together</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78608411/yolox-evaluation-problem-when-training-operands-could-not-be-broadcast-together</guid>
      <pubDate>Tue, 11 Jun 2024 15:11:33 GMT</pubDate>
    </item>
    <item>
      <title>如何才能使用完全 MLP 架构在 CIFAR10 上获得与原始论文类似的结果？</title>
      <link>https://stackoverflow.com/questions/78608160/how-can-one-get-similar-results-on-cifar10-with-the-fully-mlp-architecture-as-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78608160/how-can-one-get-similar-results-on-cifar10-with-the-fully-mlp-architecture-as-th</guid>
      <pubDate>Tue, 11 Jun 2024 14:23:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 Huggingface Trainer 进行多 GPU 训练时，如何避免内存使用不均衡？</title>
      <link>https://stackoverflow.com/questions/78608004/how-can-i-avoid-unbalanced-memory-usage-when-performing-multi-gpu-training-using</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78608004/how-can-i-avoid-unbalanced-memory-usage-when-performing-multi-gpu-training-using</guid>
      <pubDate>Tue, 11 Jun 2024 13:55:30 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 后台记录器</title>
      <link>https://stackoverflow.com/questions/78607472/tensorflow-under-the-hood-logger</link>
      <description><![CDATA[我必须根据项目日志记录样式（colorlogs、格式化程序等）配置 TensorFlow 日志。项目日志记录配置在 .yaml 文件中描述，然后传递给 logging.dictConfig() 方法。可以通过调用 tf.get_logger() 检索的 TensorFlow 记录器“tensorflow”遵循 logging 配置设置（由执行回调时调用的 WARNING 消息证明）。但是，底层 TensorFlow 记录器并未使用此方法进行配置。我所说的“幕后”是指在导入阶段调用的记录器（或其他日志记录实例），它会记录有用的统计数据：
2024-06-11 13:49:34.476834：I tensorflow/core/platform/cpu_feature_guard.cc:193] 此 TensorFlow 二进制文件使用 oneAPI 深度神经网络库 (oneDNN) 进行了优化，以便在性能关键型操作中使用以下 CPU 指令：AVX AVX2
要在其他操作中启用它们，请使用适当的编译器标志重建 TensorFlow。
2024-06-11 13:49:34.625877：W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] 覆盖 orig_value 设置，因为设置了 TF_FORCE_GPU_ALLOW_GROWTH 环境变量。原始配置值为 0。
2024-06-11 13:49:34.625992：I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] 创建了具有 5563 MB 内存的设备 /device:GPU:0：-&gt; 设备：0，名称：NVIDIA GeForce RTX 4060，pci 总线 ID：0000:01:00.0，计算能力：8.9


通过将 os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] 设置为高级别来在后台更改 TensorFlow 日志记录不是一个好的解决方案。我甚至尝试在导入 TensorFlow 之前和之后获取所有记录器并手动配置新添加的记录器（将它们添加到 .yaml 文件中），但这没有帮助（而且这完全没有必要，因为所有记录器都从具有定义样式的根记录器继承）。我猜想日志记录样式是在编译的 tf 模块中定义的（env 变量指的是 CPP）。您对如何在后台配置 TensorFlow 记录器有什么想法吗？（TensorFlow 版本 2.10，Python 3.10）]]></description>
      <guid>https://stackoverflow.com/questions/78607472/tensorflow-under-the-hood-logger</guid>
      <pubDate>Tue, 11 Jun 2024 12:24:46 GMT</pubDate>
    </item>
    <item>
      <title>在 MNIST 数据集和 Kaggle 数据集上训练同一模型时，MNIST 的准确率 >90，而 Kaggle 的准确率 <15</title>
      <link>https://stackoverflow.com/questions/78607458/when-training-the-same-model-on-an-mnist-dataset-and-a-kaggle-dataset-the-accur</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78607458/when-training-the-same-model-on-an-mnist-dataset-and-a-kaggle-dataset-the-accur</guid>
      <pubDate>Tue, 11 Jun 2024 12:22:05 GMT</pubDate>
    </item>
    <item>
      <title>ResumeParcer 没有给出预期的结果，我希望在从简历中提取实体时至少得到 80%</title>
      <link>https://stackoverflow.com/questions/78606930/resumeparcer-is-not-giving-result-as-expected-i-want-atleast-80-per-while-doing</link>
      <description><![CDATA[我遇到了实体提取问题。
我没有获得预期的准确度。我想要至少 80% 的准确度，但每次（在输出中）都会缺少一些实体，如姓名、电子邮件或联系人
我在 Python 中尝试了很多方法，使用 nir 模型和 huggingFace 转换器，但结果中仍然缺少一些实体。我还尝试在 1500 多份简历上训练模型。但似乎这仍然没有足够的数据。
有什么办法吗？如果有，请帮帮我。
谢谢帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78606930/resumeparcer-is-not-giving-result-as-expected-i-want-atleast-80-per-while-doing</guid>
      <pubDate>Tue, 11 Jun 2024 10:36:29 GMT</pubDate>
    </item>
    <item>
      <title>除了降低神经网络的复杂性之外，卷积层还有其他用途吗？ ANN 能达到与 CNN 模型相同的准确度吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78606784/is-there-any-use-for-convolution-layers-apart-from-reducing-the-complexity-of-th</link>
      <description><![CDATA[对于图像分类任务，为什么 CNN 被如此广泛地使用？
卷积是一个函数，因此具有密集层的足够大的 ANN 应该能够使用相同的数据完成相同的工作（如果需要，可以使用更多的训练时间）？这不就是通用近似定理的意思吗？
相同的逻辑不能应用于 RNN，因为我们实际上从上一个时间步骤传递了一些额外的数据。但对于图像分类任务，CNN 和 ANN 都在相同的数据上运行。
当我尝试 MNIST 数字分类问题并使用 2 层 ANN 达到 95% 以上的准确率时，这个问题突然出现在我的脑海中。]]></description>
      <guid>https://stackoverflow.com/questions/78606784/is-there-any-use-for-convolution-layers-apart-from-reducing-the-complexity-of-th</guid>
      <pubDate>Tue, 11 Jun 2024 10:06:30 GMT</pubDate>
    </item>
    <item>
      <title>当比较不是以相同角度拍摄的图像时，如何处理角度不匹配？[关闭]</title>
      <link>https://stackoverflow.com/questions/78606026/how-can-i-handle-angle-mismatching-when-comparing-images-that-are-not-taken-at-t</link>
      <description><![CDATA[ aligned_image1, aligned_image2 = align_images(image1, image2)

# 将对齐的图像转换为灰度
gray1 = cv2.cvtColor(aligned_image1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(aligned_image2, cv2.COLOR_BGR2GRAY)

# 计算对齐图像之间的绝对差异
difference = cv2.absdiff(gray1, gray2)

# 计算两个灰度图像之间的 SSIM
(score, diff) = ssim(gray1, gray2, full=True)
print(&quot;SSIM: {}&quot;.format(score))

# 差异图像包含两个图像之间的差异
diff = (diff * 255).astype(&quot;uint8&quot;)

# 对差异图像进行阈值处理以获取差异区域
_, thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

# 查找差异区域的轮廓
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 在对齐的图像上绘制边界矩形以可视化差异
output1 = aligned_image1.copy()
output2 = aligned_image2.copy()
contourArea = []
for contour in contours:
contourArea.append(cv2.contourArea(contour))
# (x, y, w, h) = cv2.boundingRect(contour)
# cv2.rectangle(output1, (x, y), (x + w, y + h), (0, 0, 255), 2)
# cv2.rectangle(output2, (x, y), (x + w, y + h), (0, 0, 255), 2)
print(contourArea)
major_changes = detect_major_changes(contourArea)

print(major_changes)
# 在检测到重大变化的轮廓周围绘制矩形
for i in range(len(contours)):
if i in [change[0] for change in major_changes]:
(x, y, w, h) = cv2.boundingRect(contours[i])
cv2.rectangle(output1, (x, y), (x + w, y + h), (0, 0, 255), 2)
cv2.rectangle(output2, (x, y), (x + w, y + h), (0, 0, 255), 2)
# 创建差异图像以可视化变化
difference_image = cv2.bitwise_xor(gray1, gray2)

# 绘制图像以可视化差异
fig, axis = plt.subplots(1, 4, figsize=(25, 10))
axis[0].imshow(cv2.cvtColor(output1, cv2.COLOR_BGR2RGB))
axis[0].set_title(&quot;Aligned Image 1 with Rectangles&quot;)
axis[0].axis(&quot;off&quot;)

axis[1].imshow(cv2.cvtColor(output2, cv2.COLOR_BGR2RGB))
axis[1].set_title(&quot;Aligned Image 2 with Rectangles&quot;)
axis[1].axis(&quot;off&quot;)

axis[2].imshow(diff, cmap=&#39;gray&#39;)
axis[2].set_title(&quot;SSIM差异”）
axes[2].axis(&quot;off&quot;)

axes[3].imshow(difference_image, cmap=&#39;gray&#39;)
axes[3].set_title(&quot;差异图像&quot;)
axes[3].axis(&quot;off&quot;)

plt.show()

我正在做一个实时图像比较项目，用户可以上传两幅图像。这些图像可能不是以相同的角度或相同的视觉条件拍摄的。在比较这些图像时，我该如何处理角度不匹配的问题？
问题：我正在使用 OpenCV 和 Python 进行图像处理和比较。挑战在于准确比较角度或视觉条件不完全对齐的图像。这会引入视角和光线的差异，影响比较的准确性。
当前方法：用户上传两幅图像。实时处理和比较图像。应解决角度和视觉条件不匹配问题，以确保准确的比较结果。

在比较不同角度拍摄的图像时，如何处理角度不匹配问题？
在图像比较过程中，应考虑哪些技术或算法来解决视角和光线差异问题？
OpenCV 或 Python 中是否有特定的库或工具可以帮助处理这些挑战？

目标：我想知道如何解决实时图像比较中的角度不匹配问题，以确保准确的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78606026/how-can-i-handle-angle-mismatching-when-comparing-images-that-are-not-taken-at-t</guid>
      <pubDate>Tue, 11 Jun 2024 07:36:57 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：从“y”的唯一值推断出的类无效。预期：[0 1 2]，结果为 ['Dropout' 'Enrolled' 'Graduate']</title>
      <link>https://stackoverflow.com/questions/78605622/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</link>
      <description><![CDATA[我目前正在使用 XGBoost 分类器模型进行分类任务。我的数据集包含分类变量，我的目标类别（“辍学”、“入学”、“毕业”）。
from xgboost import XGBClassifier

xgb = XGBClassifier(
n_estimators=200,
max_depth=6, 
learning_rate=0.1, 
subsample=0.8,
colsample_bytree=0.8,
eval_metric=&#39;mlogloss&#39; 
)

xgb.fit(X_train, y_train)

我编写了上述代码，然后它显示：“ValueError：从 y 的唯一值推断出无效的类别。预期：[0 1 2]，得到 [&#39;Dropout&#39; &#39;Enrolled&#39; &#39;Graduate&#39;]&quot;
之后，我使用标签编码器技术；它工作正常。但我需要 [&#39;Dropout&#39; &#39;Enrolled&#39; &#39;Graduate&#39;] 这个生产部分的分类。在训练 XGBClassifier 之后，我如何将这个 [0 1 2] 更改为 [&#39;Dropout&#39; &#39;Enrolled&#39; &#39;Graduate&#39;]。
提前感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78605622/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</guid>
      <pubDate>Tue, 11 Jun 2024 05:56:08 GMT</pubDate>
    </item>
    <item>
      <title>为神经网络 MATLAB 实现岭回归方程</title>
      <link>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network-matlab</link>
      <description><![CDATA[我试图在 MATLAB 中复制以下方程，以使用岭回归训练找到神经网络的最佳输出权重矩阵。
使用岭回归训练后的神经网络输出权重矩阵：

此方程来自 Mantas Lukosevicius 提供的回声状态网络指南，可在以下位置找到：https://www.researchgate.net/publication/319770153_A_practical_guide_to_applying_echo_state_networks
我的尝试如下。我认为外括号（红色）使其成为非传统的双重求和，这意味着无法遵循 Voss 提出的方法（参见 https://www.mathworks.com/matlabcentral/answers/1694960-nested-loops-for-double-summation）。请注意，y_i 是一个 T x 1 向量，而 y_i_target 也是一个 T x 1 向量。Wout_i 是一个 N x 1 向量，其中 N 是神经网络中的节点数。我为每个 i^th 目标训练信号生成三个 Ny x 1 向量 Wout_i,y_i,y_i_target，其中 Ny 是训练信号的数量。Wout 的最终输出是一个 N x 1 向量，其中向量中的每个元素都是网络中每个节点的最佳权重。
N = 100; % 神经网络节点数
Ny = 200; % 训练信号数
T = 50; % 每个训练信号的时间长度 
X = rand(N,T); % 神经网络状态矩阵
reg = 10^-4; % 岭回归系数
outer_sum = zeros(Ny,1);
for i = 1:Ny
y_i_target = rand(T,1); % 训练信号
Wout_i = ((X*X&#39; + reg*eye(N)) \ (X*y_i_target)); 
Wouts{i} = Wout_i; % 针对每个第 i 个目标训练信号收集的每个 Wout_i 的单元矩阵
y_i = Wout_i&#39;*X; % 预测信号 
inner_sum = sum(((y_i&#39;-y_i_target).^2)+reg*norm(Wout_i)^2);
outer_sum(i) = inner_sum;
end
outer_sum = outer_sum.*(1/Ny);
[minval, minidx] = min(outer_sum);
Wout = cell2mat(Wouts(minidx));

我对 Wout 的最终答案是 N 乘以 1，正如它应该的那样，但我对我的答案不确定。我特别不确定我是否正确地完成了 Wout 运算的双重求和和 arg min。有什么方法可以验证我的答案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network-matlab</guid>
      <pubDate>Sat, 08 Jun 2024 22:31:47 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归代码在生成的观测值超过约 43,500 个时停止工作</title>
      <link>https://stackoverflow.com/questions/75299046/logistic-regression-code-stops-working-above-43-500-generated-observations</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75299046/logistic-regression-code-stops-working-above-43-500-generated-observations</guid>
      <pubDate>Tue, 31 Jan 2023 15:00:25 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型输入形状</title>
      <link>https://stackoverflow.com/questions/66488807/pytorch-model-input-shape</link>
      <description><![CDATA[我加载了一个自定义 PyTorch 模型，我想找出它的输入形状。类似这样的内容：
model.input_shape

是否可以获取此信息？

更新： print() 和 summary() 不显示此模型的输入形状，因此它们不是我要找的。]]></description>
      <guid>https://stackoverflow.com/questions/66488807/pytorch-model-input-shape</guid>
      <pubDate>Fri, 05 Mar 2021 07:59:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有灰度图像的预训练神经网络？</title>
      <link>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</link>
      <description><![CDATA[我有一个包含灰度图像的数据集，我想在这些图像上训练最先进的 CNN。我非常想微调一个预先训练好的模型（比如这里的模型）。
问题是，我能找到权重的几乎所有模型都是在包含 RGB 图像的 ImageNet 数据集上训练的。
我无法使用其中一个模型，因为它们的输入层需要一批形状为 (batch_size, height, width, 3) 或 (64, 224, 224, 3) 的模型，但我的图像批次是 (64, 224, 224)。
我有什么办法可以使用其中一个模型吗？我曾考虑在加载权重后删除输入层并添加自己的输入层（就像我们对顶层所做的那样）。这种方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</guid>
      <pubDate>Fri, 24 Aug 2018 00:33:04 GMT</pubDate>
    </item>
    </channel>
</rss>