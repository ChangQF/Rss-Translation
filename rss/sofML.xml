<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 25 May 2024 21:13:01 GMT</lastBuildDate>
    <item>
      <title>Keras 模型总是预测几乎相同的事情</title>
      <link>https://stackoverflow.com/questions/78533664/keras-model-always-predicts-almost-the-same-thing</link>
      <description><![CDATA[我需要帮助，我的 keras 模型几乎总是预测同样的事情。我的 loss 和 val_loss 分别收敛到 0.6 和 0.4 左右，这看起来很奇怪，但我尝试了很多不同的方法，包括 dropout、augmentation、标准化、调整等，但没有任何效果。
datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=&#39;val_loss&#39;, 因子=0.5, 耐心=2, 模式=“自动”, min_delta=0.0001, 冷却时间=0, min_lr=0)
train_generator = datagen.flow(X, y_train_array)
val_generator = datagen.flow(train_array_val, y_val_array)
pred_generator = datagen.flow(train_array_val, shuffle=False)

初始化器 = tf.keras.initializers.HeNormal()

imgModel = models.Sequential([
层.输入(形状=(128, 128, 3)),
Layers.RandomFlip(“水平”),
层.RandomZoom(.2),
层.RandomRotation(0.2),
层.Conv2D(64, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Conv2D(32, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Conv2D(64, kernel_size=(3, 3), 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.MaxPooling2D(pool_size=(2, 2)),
层.Flatten(),
层.Dense（128，激活=&#39;relu&#39;，kernel_initializer=初始化器，input_dim=81），
层数.Dropout(0.2),
层.Dense(128, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(64, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(32, 激活=&#39;relu&#39;, kernel_initializer=initializer),
层数.Dropout(0.2),
层.Dense(1, 激活=&#39;线性&#39;)
]）

imgModel.compile(优化器=Adam(learning_rate=0.001),loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])

历史= imgModel.fit（train_generator，epochs = 300，shuffle = True，batch_size = 32，validation_data = val_generator，callbacks = [early_stopping，reduce_lr]）

预测 = imgModel.predict(pred_generator)

我正在尝试从 9500 个图像数据集预测 0.0 到 5.0 之间的特征。该数据集已正确加载，我已检查过该数据集，并且以正确的顺序为每个图像分配其特征。我尝试过使用Datagen，没有datagen（是的，我正在按1/255重新缩放），有或没有标准化，不同的密集层，不同的转换层，但它们都不起作用。我也尝试过使用预先训练的模型，但没有成功。请帮忙！
一旦达到“停止点”，那么无论经过多少个纪元，它都会保持相同的损失。然后它进行预测，我发现预测几乎没有什么不同。下面是预期的 val 预测和实际预测。
预测]]></description>
      <guid>https://stackoverflow.com/questions/78533664/keras-model-always-predicts-almost-the-same-thing</guid>
      <pubDate>Sat, 25 May 2024 20:40:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中仅通过歌曲的索引来播放歌曲？</title>
      <link>https://stackoverflow.com/questions/78533401/how-to-play-a-song-in-python-by-only-index-of-it</link>
      <description><![CDATA[我目前正在使用 GTZAN 数据集音乐流派分类数据集。训练模型后（我仍在模型的笔记本中），我运行了这个脚本，并预测了流派输出，直到这里为止一切都很完美，但我不知道如何播放这首歌，并确认是否类型是正确的。通常是通过文件路径完成的，但我只有歌曲的索引。
将 numpy 导入为 np
导入pygame
导入时间

# 选择样本数据点
index = 0 # 从测试集中选择一个索引
Sample = X_test[index] # 从测试集中选择一个样本
Sample = Sample[np.newaxis, ...] # 转换为适合模型的形状

# 别猜
Prediction = model.predict(sample) # 使用模型进行预测
Predicted_index = np.argmax(prediction, axis=1) # 查找预测索引

# 打印预测结果
Predicted_genre = converter.inverse_transform(predicted_index)[0] # 将预测类型转换为标签
Expected_genre = converter.inverse_transform([y_test[index]])[0] # 将预期类型转换为标签

print(&quot;预期类型：{}，预测类型：{}&quot;.format(expected_genre, Predicted_genre))

如果需要任何进一步的信息，我会提供]]></description>
      <guid>https://stackoverflow.com/questions/78533401/how-to-play-a-song-in-python-by-only-index-of-it</guid>
      <pubDate>Sat, 25 May 2024 18:45:50 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：单例数组 array(1) 不能被视为有效集合</title>
      <link>https://stackoverflow.com/questions/78532981/typeerror-singleton-array-array1-cannot-be-considered-a-valid-collection</link>
      <description><![CDATA[我有一个数据集，其中我的目标变量是 1 到 8 之间的数字。
现在我要实现 Cubic SVM。
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.svm import SVC

model1 = SVC(kernel=&#39;poly&#39;, degree=3)

model1.fit(X_train, y_train)

y_prob = model1.predict(X_test)
y_true = np.argmax(y_prob, axis=0)

auc = roc_auc_score(y_test, y_true, multi_class=&#39;ovr&#39;)

现在获取 AUC，观察到以下错误：
TypeError：单例数组 array(1) 不能被视为有效集合。

如何解决此错误并找到我的模型的 AUC？]]></description>
      <guid>https://stackoverflow.com/questions/78532981/typeerror-singleton-array-array1-cannot-be-considered-a-valid-collection</guid>
      <pubDate>Sat, 25 May 2024 16:00:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 xml 文件在 Pytorch 中训练模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</link>
      <description><![CDATA[我的文件夹 train 文件夹 gest_a 和 gest_b 中有照片和 xml 文件。
如何在 pytorch 中使用它训练模型？
我想要实时识别 gest 的文件。我不使用 ipynb 文件，我只使用 .py 文件
预先感谢您的建议和解答]]></description>
      <guid>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</guid>
      <pubDate>Sat, 25 May 2024 14:06:01 GMT</pubDate>
    </item>
    <item>
      <title>我需要与目标服务器中的资源使用情况相关的 HTTP 请求数据集</title>
      <link>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</link>
      <description><![CDATA[我正在设计一个机器学习模型来预测 HTTP 请求在执行服务器中引起的资源负载。我正在努力寻找具有这两个请求的数据集。
任何人都知道包含 HTTP 请求信息的数据集，例如请求的上下文、类型（POST、GET...）主体大小、标头大小、一天中的时间和一周中的某一天以及任何其他参数，以及请求在 HTTP 数据集的同一时间戳期间对服务器资源或服务器 CPU、RAM、网络 IO 数据集的影响？
我想过生成合成数据，但我想不出如何生成现实的数据，因为如果我生成大量 HTTP 调用数据，然后生成资源某些特性的估计，标签将是太偏颇了。我正在考虑通过配置 Web 服务器来生成数据并在监控时对其进行攻击，但这会很长，不会有很多不同的服务......
有人知道现有数据集或有办法生成真实且多样化的合成数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</guid>
      <pubDate>Sat, 25 May 2024 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>强化学习在完成数据分类后给予奖励，而不是一一进行，基于CNN的强化学习</title>
      <link>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</link>
      <description><![CDATA[我正在尝试编写一个基于强化的交易系统，在尝试这样做时，我能做的唯一方法是奖励每个动作的模型，但它实际上执行了糟糕的结果，并且无法添加我想要的所有参数。 F.E 我想添加这些参数，但为了“一一执行”模型中，我无法添加这些参数作为奖励，因为所有这些参数都可以在所有长空持有分类完成后返回
如果 roi_percent &lt; 30：
    f = 11.8
elif roi_percent &lt;&lt; 70：
    f = 9.5
elif roi_percent &lt;&lt; 140：
    f = 7.6
elif roi_percent &lt;&lt; 250：
    f = 6.4
elif roi_percent &lt;&lt; 340：
    f = 5
elif roi_percent &lt;&lt; 600：
    f = 3.6
elif roi_percent &lt;&lt; 1000：
    f = 2.46
elif roi_percent &lt;&lt; 1600：
    f = 1.34
别的：
    f = 0.7

sayi = self.条目号

如果萨伊 == 20：
    萨伊 = 70
埃利夫·萨伊10：
    萨伊 = 30 - (10*(10-萨伊))
埃利夫·萨伊20：
    萨伊 = 70 - (4*(20-萨伊))
别的：
    萨伊 = 70 - (1.6*(萨伊 - 20))

奖励 = (roi_percent * f) + (win_loss_ratio * 45) - ((self.max_drawdown * 440) / (93 - self.max_drawdown)) + (sharpe_ratio * 64) + sayi

我们还可以通过 DQN、DDQN、PPO、A2C 模型创建强化学习模型，但我想知道我们如何使用 GRU、LSTM、CNN 等模型来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</guid>
      <pubDate>Sat, 25 May 2024 11:31:19 GMT</pubDate>
    </item>
    <item>
      <title>在 OpenAI Gym 中，MuJoCo Fetch 版本 1 与版本 2 的结构相同吗？</title>
      <link>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-the-same-structure-as-version-2</link>
      <description><![CDATA[我正在使用 OpenAI Gym MuJoCo Fetch 环境。由于 MuJoCo 已经开源，Fetch 环境的第 2 版很好地支持了这一点。但网上仍然有很多使用 Fetch 版本 1 的实现（需要手动安装 MuJoCo，而不是通过 pip）。我只是想确定一下版本1和版本2之间的区别。除了MuJoCo安装之外，环境本身是否有任何修改？
在重新实现过程中，安装旧版本的 MuJoCo 对我来说既复杂又困难。所以我只是用 -v2s 替换了 Fetch-v1s，我不确定它是否正确，因为它一直失败。这个问题也可能是由于gym版本引起的，但是MuJoCo版本也可能会影响我的重新实现过程。]]></description>
      <guid>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-the-same-structure-as-version-2</guid>
      <pubDate>Sat, 25 May 2024 09:22:50 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有经过适当的训练，只能达到</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 xgboost 推断 csv 数据时出现问题</title>
      <link>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</link>
      <description><![CDATA[我在使用 xgboost 进行推断时遇到问题：
简单来说，我想使用 xgboost 执行回归任务，由多个 csv 数据集组成。我将它们拼接成一个数据帧，并使用 train_test_split 分割训练/验证/测试。该模型运行良好（mae：0.6）。但是当我手动拆分训练集和测试集（我挑选了一部分 csv 并将其放入测试文件夹中）时，结果变得非常差（mae：12+）。
我真的很想知道这里发生了什么？我已经发布了下面的一些代码。
1：这是带有train_test_split的分割代码：
# 准备好数据
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 合并数据集
[merged_dataset = pd.concat([pd.DataFrame(dataset.X) 用于数据集中的数据集])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)

# 除法
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.2，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

# 构建xgboost模型
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_test_original, y_test_pred)]

2：这是我在代码后的手动划分：
# 训练数据集
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 测试数据，这是我从原始数据中手动分区的测试集的 csv
测试=[]
test_file = &#39;../data/test_xgboost/Thermal014withMidPos.csv&#39;
测试 = ThermalDataset(test_file)
测试.追加（测试）

＃ 结合
merged_dataset = pd.concat([数据集中的数据集的pd.DataFrame(dataset.X)])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
test_x = pd.concat([pd.DataFrame(test.X) 用于测试中的测试])
test_y = pd.concat([pd.DataFrame(test.y) 用于测试中的测试])

# 标准化
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)
x_fill = 缩放器.fit_transform(test_x)
y_fill = 缩放器.fit_transform(test_y)

＃ 分裂
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.05，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

＃ 火车
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred_scaled = model.predict(X_val)
y_test_pred_scaled = model.predict(X_test)
y_fill_res = model.predict(x_fill)

# inverse_transform 获取原始数据
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_pre = scaler.inverse_transform(y_fill_res.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
y_fill = scaler.inverse_transform(y_fill.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_pre, y_fill)`

我希望能够对单个 csv 文件进行正确推理，并获得与训练中一样好的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</guid>
      <pubDate>Sat, 25 May 2024 02:40:08 GMT</pubDate>
    </item>
    <item>
      <title>langchain RetrievalQA 错误：ValueError：缺少一些输入键：{'query'}</title>
      <link>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</link>
      <description><![CDATA[在 RAG 项目中，我使用 langchain。当我使用查询输入运行 QA 链时，此错误不断出现：
----&gt;;结果 = qa_chain({&#39;查询&#39;: 问题})
ValueError：缺少一些输入键：{&#39;query&#39;}

这是我的代码：
from langchain.chains import RetrievalQA
从 langchain.prompts 导入 PromptTemplate

# 构建提示
template = &quot;&quot;&quot; 根据以下上下文回答问题。
    语境：
    {语境}
    ------------------
    问题：{查询}
    答案：“”

# 法学硕士链
QA_CHAIN_PROMPT = PromptTemplate.from_template(模板)
qa_chain = RetrievalQA.from_chain_type(
    嗯，
    检索器=vectordb.as_retriever(),
    return_source_documents=真，
    chain_type_kwargs={“提示”: QA_CHAIN_PROMPT}
）

Question =“这篇研究论文使用了什么方法？”

结果 = qa_chain({&#39;查询&#39;: 问题})

# 查看查询结果
结果[“结果”]
# 检查我们所在的源文档 
结果[“源文档”][0]
]]></description>
      <guid>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</guid>
      <pubDate>Fri, 24 May 2024 21:23:49 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从 sklearn.preprocessing 导入 StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>成为一名 mlops 工程师从哪里开始？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78502776/where-to-start-to-become-a-mlops-engineer</link>
      <description><![CDATA[我目前是一名 DevOps 工程师，我非常渴望了解 MLOPS。
从职业角度来看，我希望将 ML 相关工作添加到我的个人资料中。
由于我不是开发人员背景，因此我只能将 MLOPS 视为 ML 领域的一个选项，该领域主要处理我认为的模型的部署。
我需要一些专家的建议，想知道我应该从哪里开始？
我目前正在与 gitlab、cicd、aws 合作。
任何提示或建议将不胜感激。
我已经在高层次上了解了 MLops。]]></description>
      <guid>https://stackoverflow.com/questions/78502776/where-to-start-to-become-a-mlops-engineer</guid>
      <pubDate>Sun, 19 May 2024 13:46:01 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Model.fit() 打印训练数据集</title>
      <link>https://stackoverflow.com/questions/78467703/tensorflow-model-fit-printing-training-dataset</link>
      <description><![CDATA[我是 Tensorflow 和 ML 领域的新手，我对 Tensorflow 的体验很奇怪。
我正在尝试训练 Tensorflow 简单序列模型，但在训练阶段，它不会显示准确性或某些进度条，而是打印整个训练数据集。
这是我的完整代码
导入tensorflow为tf
从数据导入 get_data  
从 sklearn 导入 model_selection

数据 = get_data(&#39;2Y&#39;)

x_train, x_test, y_train, y_test = model_selection.train_test_split(data.get_values([&#39;温度&#39;,&#39;风&#39;,&#39;湿度&#39;]), data.get_values(&#39;雨&#39;), test_size=0.1, shuffle=False)
模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(8),
    tf.keras.layers.Dense(8)
]）

模型.编译(
    优化器=“亚当”，
    损失=“binary_crossentropy”，
    指标=[“准确度”]
）

model.fit(x_train、y_train、epochs=10、batch_size=64、validation_data=(x_test、y_test)、verbose=2)

我阅读了tensorflow文档，但没有提到在模型拟合期间打印整个数据集之类的事情。我不明白哪里出了问题。并且在 model.fit() 之后，程序退出。]]></description>
      <guid>https://stackoverflow.com/questions/78467703/tensorflow-model-fit-printing-training-dataset</guid>
      <pubDate>Sun, 12 May 2024 11:41:45 GMT</pubDate>
    </item>
    <item>
      <title>损失函数在梯度提升中的作用是什么？</title>
      <link>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</link>
      <description><![CDATA[在梯度提升中，可以使用不同的损失函数。例如，在 sklearn 的 GradientBoostingRegressor 中，可能的损失函数有：“squared_error”、“absolute_error”、“huber”和“quantile”损失函数。
我了解损失函数在梯度下降（而不是梯度提升）中的影响。例如，与绝对误差损失函数相比，平方误差损失函数对大误差的惩罚更大。我们可以在梯度提升的情况下说类似的话吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</guid>
      <pubDate>Mon, 01 Apr 2024 18:03:20 GMT</pubDate>
    </item>
    <item>
      <title>在 Google Colab Notebook 中安装 ZoeDepth</title>
      <link>https://stackoverflow.com/questions/77030715/installation-of-zoedepth-in-google-colab-notebook</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77030715/installation-of-zoedepth-in-google-colab-notebook</guid>
      <pubDate>Sun, 03 Sep 2023 02:32:35 GMT</pubDate>
    </item>
    </channel>
</rss>