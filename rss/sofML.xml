<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 30 Nov 2023 18:17:49 GMT</lastBuildDate>
    <item>
      <title>Orange3 中的关联规则过滤器效果不佳</title>
      <link>https://stackoverflow.com/questions/77580681/association-rules-filters-in-orange3-does-not-work-well</link>
      <description><![CDATA[我正在尝试在 Orange3 中使用关联规则，并且正在使用“按结果过滤工具”。我已经编写了一个条件，但是当我运行程序时，结果图表中给出了其他条件。我已经多次验证是否输入错误，但事实并非如此。
我尝试更改变量，但它没有准确给出所需的内容。
有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77580681/association-rules-filters-in-orange3-does-not-work-well</guid>
      <pubDate>Thu, 30 Nov 2023 17:53:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法省略 OpenAIgym 的输出并保留打印语句？</title>
      <link>https://stackoverflow.com/questions/77580652/is-there-a-way-to-omit-the-output-from-openai-gym-and-leave-the-print-statement</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77580652/is-there-a-way-to-omit-the-output-from-openai-gym-and-leave-the-print-statement</guid>
      <pubDate>Thu, 30 Nov 2023 17:45:58 GMT</pubDate>
    </item>
    <item>
      <title>多维输出/多智能体强化学习库</title>
      <link>https://stackoverflow.com/questions/77579893/library-for-multi-dimensional-output-multi-agent-reinforcement-learning</link>
      <description><![CDATA[只是想知道哪个库可以正确实现这一点？
从我迄今为止所看到和尝试过的情况来看，tf-agent 做不到。
那么有什么建议吗？或者有人知道如何在 tf-agent 上做到这一点（尽管不太可能）？
额外背景信息：
我能找到的最接近的是这个，但它的训练速度是与单个代理相比有点慢。
我知道它会比平常慢，因为它是多代理的，但我怀疑大部分开销来自使用 TFUniformReplayBuffer，而不是混响驱动程序。
我尝试使用混响进行多代理，但它不允许我在使用时自定义运行 PyEnvironment 的方式（也称为无法正确自定义 PyDriver）。
并且这个问题自 2020 年以来一直悬而未决，所以我非常怀疑是否会出现是多智能体 RL 上 tf-agent 中可用的正确解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/77579893/library-for-multi-dimensional-output-multi-agent-reinforcement-learning</guid>
      <pubDate>Thu, 30 Nov 2023 16:03:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练YOLOv8会导致崩溃？</title>
      <link>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</link>
      <description><![CDATA[我想在由单个类别的 1080p 图像组成的自定义数据集上训练对象检测。我认为我已经正确准备了数据集（将其上传到 roboflow 显示了正确概述类的图像），但是我似乎无法让模型开始训练。起初，我怀疑我使用的数据集可能太大，无法满足我普通笔记本电脑的处理能力（270 张 1080p 图像及其遮罩，总计 1.34GB），因此我将其减少到只有 10 个训练图像和 10 个验证图像。还是没有运气。
我的代码：
从 ultralytics 导入 YOLO

# 加载 COCO 预训练的 YOLOv8n 模型
模型 = YOLO(&#39;yolov8n.pt&#39;)

结果 = model.train(data=&#39;(..)\\dataset\\data.yaml&#39;, epochs=5,
                      imgsz=[1920, 1080])

data.yaml 文件：
&lt;前&gt;&lt;代码&gt;名称：
- 烟草
数控：1
测试：数据集\测试
火车：火车\图像
val: 有效\图像

控制台输出：
图像大小 1920 train、1920 val
使用 0 个数据加载器工作人员
将结果记录到运行\检测\train7
开始训练 5 个 epoch...

      Epoch GPU_mem box_loss cls_loss dfl_loss 实例大小
  0%| | 0/1 [00:00
代码在 0% 处停留大约一分钟，我的计算机死机，然后打印处理完成错误。
假设问题确实源于我糟糕的规格，我可以对自定义数据集使用某种云训练吗？我在哪里可以阅读有关构建和上传用于云训练的自定义数据集的更多信息？]]></description>
      <guid>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</guid>
      <pubDate>Thu, 30 Nov 2023 13:59:49 GMT</pubDate>
    </item>
    <item>
      <title>在训练和测试模型时，为什么我们说开发数据和测试数据应该来自相同的分布？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77578962/when-training-and-testing-a-model-why-do-we-say-dev-and-test-data-should-come-f</link>
      <description><![CDATA[我们通常将数据集分为训练数据、开发数据和测试数据。那么为什么我们说开发数据和测试数据应该来自相同的分布呢？我们如何处理开发数据？
我浏览了 andrew ng 的视频，发现了这样的事情！]]></description>
      <guid>https://stackoverflow.com/questions/77578962/when-training-and-testing-a-model-why-do-we-say-dev-and-test-data-should-come-f</guid>
      <pubDate>Thu, 30 Nov 2023 13:46:40 GMT</pubDate>
    </item>
    <item>
      <title>L1 正则化不适用于线性回归</title>
      <link>https://stackoverflow.com/questions/77578761/l1-regularisation-not-working-for-linear-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77578761/l1-regularisation-not-working-for-linear-regression</guid>
      <pubDate>Thu, 30 Nov 2023 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>如何让训练有素的 LSTM 预测了解即将发生的已知特殊事件？</title>
      <link>https://stackoverflow.com/questions/77577239/how-to-make-a-well-trained-lstm-forecast-aware-of-the-upcoming-known-special-eve</link>
      <description><![CDATA[我根据每日销售数据训练了 LSTM 模型，其中包括对销售影响很大的节假日和特殊活动（作为二进制指标）。但是，虽然在测试集之外进行预测，但该模型并未考虑有影响力的已知未来假期。我怎样才能让我的模型意识到这一点？
我使用包含销售和假期的数据集作为二进制指标，直到记录销售的最后一天。我有未来假期二进制指标数据集，但它不包含在此处。问题是如何使用它进行预测。这是我的初始代码，它在测试集上给出了良好的结果：
data = df_resampled[[&#39;销售&#39;, &#39;Hol1&#39;, &#39;Hol2&#39;, &#39;Hol3&#39;, &#39;Hol4&#39;, &#39;Hol5&#39;,&#39;周末&#39;,&#39;夏季&#39;]].values

# 标准化数据

缩放器 = MinMaxScaler(feature_range=(0, 1))
data_scaled = 缩放器.fit_transform(数据)

# 分割数据

train_size = int(len(data_scaled) * 0.8)
训练，测试 = data_scaled[:train_size], data_scaled[train_size:]

# LSTM 训练序列

def create_sequences(数据, seq_length):
序列、目标 = []、[]
对于范围内的 i（len（数据）- seq_length）：
seq = 数据[i:i + seq_length]
目标=数据[i + seq_length]
序列.append(seq)
目标.append(目标)
返回 np.array(序列), np.array(目标)

序列长度 = 10
train_sequences, train_targets = create_sequences(train, seq_length)
test_sequences, test_targets = create_sequences(测试, seq_length)

# 重塑输入（样本、时间步长、特征）

train_sequences = np.reshape(train_sequences, (train_sequences.shape[0], train_sequences.shape[1], train_sequences.shape[2]))
test_sequences = np.reshape(test_sequences, (test_sequences.shape[0], test_sequences.shape[1], test_sequences.shape[2]))

# 具有附加功能的 LSTM 模型

模型=顺序（）
model.add(LSTM(单位=50, input_shape=(train_sequences.shape[1], train_sequences.shape[2])))
model.add(密集(单位=1))
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

# 训练模型

model.fit（train_sequences，train_targets [：，0]，epochs = 50，batch_size = 32）

# 对测试数据进行预测

test_predictions = model.predict(test_sequences)

# 反转至原始比例

test_predictions_inv = scaler.inverse_transform(np.concatenate((test_predictions, test_targets[:, 1:]), axis=1))[:, 0]
test_targets_inv = 缩放器.inverse_transform(test_targets)[:, 0]
]]></description>
      <guid>https://stackoverflow.com/questions/77577239/how-to-make-a-well-trained-lstm-forecast-aware-of-the-upcoming-known-special-eve</guid>
      <pubDate>Thu, 30 Nov 2023 09:22:08 GMT</pubDate>
    </item>
    <item>
      <title>llama 模型来获取 pdf 上下文中问题的答案</title>
      <link>https://stackoverflow.com/questions/77576528/llama-model-to-get-answers-of-the-questions-which-are-in-the-context-of-pdf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77576528/llama-model-to-get-answers-of-the-questions-which-are-in-the-context-of-pdf</guid>
      <pubDate>Thu, 30 Nov 2023 07:14:31 GMT</pubDate>
    </item>
    <item>
      <title>修改来自google的ml教程代码没有给出预期的结果</title>
      <link>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</link>
      <description><![CDATA[有一个很好的使用tensorflow lib的ml python代码的迷你示例。
Google 代码实验室教程
它（正确地）从线性方程预测一个数字。但仅仅制作一个小模型来训练模型并预测二次函数就会得到完全错误的结果。
导入tensorflow为tf
将 numpy 导入为 np
从张量流导入keras

模型 = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mean_squared_error&#39;)

# 从原始教程修改 -&gt; y = 2x^2-1
xs = np.array([-3.0, -2.0, -1.0, 0.0, 2.0, 3.0, 4.0, 5.0], dtype=float)
ys = np.array([ 17.0, 7.0, 1.0, -1.0, 7.0, 17.0, 31.0, 49.0], dtype=float)

model.fit(xs, ys, epochs=5000)

打印（模型.预测（[1.0]））

给出结果：
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;打印（模型.预测（[1.0]））
1/1 [================================] - 0s 84ms/步
[[15.999977]]
&gt;&gt;&gt;&gt;&gt;

我本来预计大约。 1.0。
不知道出了什么问题。]]></description>
      <guid>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</guid>
      <pubDate>Thu, 30 Nov 2023 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>fiass 在查找相似图像方面比余弦相似度更好吗？我们应该标准化嵌入吗？</title>
      <link>https://stackoverflow.com/questions/77574460/is-fiass-better-than-cosine-similarity-in-finding-similar-images-should-we-nor</link>
      <description><![CDATA[我正在研究一个产品识别人工智能项目。任务如下：我们必须找到公司销售的图像中的物体，然后我们必须生成 6 个相似的产品，为此我们使用接地恐龙进行零镜头物体检测，然后进行剪辑以计算余弦相似度在裁剪图像的嵌入与具有相同产品类别或类别的图像的嵌入之间，我们的问题如下：
我们希望它检测的类别非常相似，包括凳子、桌子、书桌、架子，因此有时它会对同一对象标记两次，或者将其标记为与真实标签类似的内容。
其次，同一类别的两个看起来不相似的对象之间的余弦相似度有时非常高，而完全相同产品的图像之间的余弦相似度则较低
我们应该做什么任何帮助将非常感激，问题是因为恐龙还是剪辑，我们是否解决检测或相似性
使用 fiass libraray 代替余弦相似度更好吗？它会生成更多相似的图像
我们尝试增加 dino 的阈值，并在提示中使用单个类多次运行它，这样我们可以设置高阈值而不丢失数据
我们的导师建议我们使用伪标签和 100 个带注释的图像对恐龙进行半监督学习
我们无法训练分类器，因为我们的数据集中只有 200 张图像
我们应该在计算余弦相似度之前对嵌入进行归一化]]></description>
      <guid>https://stackoverflow.com/questions/77574460/is-fiass-better-than-cosine-similarity-in-finding-similar-images-should-we-nor</guid>
      <pubDate>Wed, 29 Nov 2023 20:59:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种 ML 模型来检测图像中特定对象的数量？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-specific-objects-in-an-image</link>
      <description><![CDATA[我有一堆奶酪图像，我需要知道哪种 ML 模型最能解决这个问题。我过去做过一些愿景项目，但这肯定不是我的强项。谁能给我一些入门建议？这可能是一种监督学习，因为我应该事先知道孔的数量，但为了以防万一，请随意建议一种无监督方法。]]></description>
      <guid>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-specific-objects-in-an-image</guid>
      <pubDate>Wed, 29 Nov 2023 19:09:09 GMT</pubDate>
    </item>
    <item>
      <title>在自定义转换器中包含多个数据集转换器</title>
      <link>https://stackoverflow.com/questions/77570948/including-multiple-dataset-transformers-in-custom-transformer</link>
      <description><![CDATA[这是我的自定义转换器，旨在转换编码和缩放的主题数据帧：
类 DfGrooming(BaseEstimator, TransformerMixin):
    def __init__(自身):
        self.encodable_columns = [&#39;教育&#39;、&#39;就业类型&#39;、&#39;婚姻状态&#39;、&#39;HasMortgage&#39;、&#39;HasDependents&#39;、&#39;LoanPurpose&#39;、&#39;HasCoSigner&#39;]
        self.scalable_columns = [&#39;年龄&#39;, &#39;收入&#39;, &#39;贷款金额&#39;, &#39;信用分数&#39;, &#39;就业月数&#39;, &#39;利率&#39;, &#39;贷款期限&#39;]
        self.encoder = LabelEncoder()
        self.scaler = MinMaxScaler(feature_range=(0,5))
        self.X_encoded = pd.DataFrame()
        self.X_scaled = pd.DataFrame()
    
def fit(self, X, y=None):
    self.encoder.fit(X[self.encodable_columns])
    self.scaler.fit(X[self.scalable_columns])
    返回自我

def 变换（自身，X，y=无）：
    self.X_encoded = self.encoder.transform(X[self.encodable_columns])
    打印（self.X_encoded.shape）
    X.drop（列= self.encodable_columns，轴= 1，就地= True）
    X = pd.concat([X, self.X_encoded], axis=1)
    打印（X.形状）
    self.X_scaled = X.filter(self.scalable_columns, axis=1)
    self.X_scaled = pd.DataFrame(scaler.transform(self.X_scaled))
    self.X_scaled.columns = self.scalable_columns
    X[self.scalable_columns] = self.X_scaled[self.scalable_columns]
    X.drop([&#39;LoanID&#39;], axis=1, inplace=True)
    打印（X.形状）
    
    返回X

但是运行管道后：
pipeline = Pipeline([(&#39;preparer&#39;, DfGrooming())])
t = pipeline.fit_transform(train_df)
t.head()

我收到以下错误：
ValueError：输入形状错误 (178742, 7)

我想知道实际发生了什么，以及我在变压器的实现中是否遗漏了任何内容。另请建议更好的方法来实施此过程。谢谢
我尝试在一个自定义变压器中包含 2 个变压器。
我期望结合 2 个步骤（可能还有 4 个步骤 - 删除编码和缩放列并将其添加到主数据帧中）
我有一个工作算法，可以使用函数半自动转换验证和测试集，但想尝试管道]]></description>
      <guid>https://stackoverflow.com/questions/77570948/including-multiple-dataset-transformers-in-custom-transformer</guid>
      <pubDate>Wed, 29 Nov 2023 11:56:48 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>Librosa.resample() 重新采样到低于所需的速率</title>
      <link>https://stackoverflow.com/questions/67870647/librosa-resample-resamples-to-a-lower-rate-than-needed</link>
      <description><![CDATA[我正在做一些音频预处理来训练机器学习模型。
该数据集的所有音频文件为：
&lt;块引用&gt;
RIFF（小端）数据、WAVE 音频、Microsoft PCM、16 位、单声道 16000 Hz。

我使用以下代码片段将数据集重新采样到 8000 Hz：
样本，sample_rate = librosa.load（文件名，sr = 16000）
样本= librosa.resample（样本，sample_rate，8000）

然后我使用以下代码片段来重塑新样本：
samples.reshape(1,8000,1)
但由于某种原因，我不断收到以下错误：ValueError：无法将大小为 4000 的数组重塑为形状 (1,8000,1)，但文件的大小因文件而异，但是它始终低于 8000 HZ（所需的采样率）。
我仔细检查了原始采样率，它是 16000 Hz，我也尝试加载采样率为 8000 的文件，但我没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/67870647/librosa-resample-resamples-to-a-lower-rate-than-needed</guid>
      <pubDate>Mon, 07 Jun 2021 11:18:19 GMT</pubDate>
    </item>
    <item>
      <title>keras中train_on_batch()有什么用？</title>
      <link>https://stackoverflow.com/questions/49100556/what-is-the-use-of-train-on-batch-in-keras</link>
      <description><![CDATA[train_on_batch() 与 fit() 有何不同？什么情况下我们应该使用train_on_batch()？]]></description>
      <guid>https://stackoverflow.com/questions/49100556/what-is-the-use-of-train-on-batch-in-keras</guid>
      <pubDate>Sun, 04 Mar 2018 21:13:27 GMT</pubDate>
    </item>
    </channel>
</rss>