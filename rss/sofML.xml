<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Apr 2024 21:14:36 GMT</lastBuildDate>
    <item>
      <title>如何根据数据集的标签将数据集拆分为文件夹？</title>
      <link>https://stackoverflow.com/questions/78330964/how-to-split-a-dataset-into-folders-depending-in-its-labels</link>
      <description><![CDATA[我在一个文件夹中有一个图像数据集，我想根据包含所有图像 ID 及其标签的 csv 文件将其分成多个文件夹，因此我想阅读以进行检查和分离。另外我想在 Kaggle 上工作，那么如果我想将输出保存在工作目录中是否可以？
我尝试了以下代码，但它在某些方面不起作用。
&lt;前&gt;&lt;代码&gt;
`#首先将图像排序到子文件夹import pandas as pdimport osimport Shutil

将所有图像转储到一个文件夹中并指定路径：

data_dir = os.getcwd() + “/data/all_images/”

我们想要子文件夹的目标目录的路径

dest_dir = os.getcwd() + “/data/reorganized/”

读取包含图像名称和相应标签的csv文件

df= pd.read_csv(&#39;metadata.csv&#39;)print(df[&#39;dx&#39;].value_counts())

label=df[&#39;dx&#39;].unique().tolist() #提取标签到列表中label_images = []

将图像复制到新文件夹

for i in label:os.mkdir(dest_dir + str(i) + &quot;/&quot;)sample = df[df[&#39;dx&#39;] == i][&#39;image_id&#39;]label_images.extend (示例)for id in label_images:shutil.copyfile((data_dir + &quot;/&quot;+ id +&quot;.jpg&quot;), (dest_dir + i + &quot;/&quot;+id+&quot;.jpg&quot;))标签图像=[]

#现在我们准备好处理子文件夹中的图像了

FOR Keras 数据生成

#flow_from_directory 方法#当图像被排序并放置在相应的类/标签文件夹中时有用#从文件夹名称自动识别类。

创建数据生成器

from keras.preprocessing.image import ImageDataGeneratorimport osfrom matplotlib import pyplot as plt

#定义数据生成器。在这里我们可以定义要应用于 imagesdatagen = ImageDataGenerator() 的任何转换

定义包含子文件夹的训练目录

train_dir = os.getcwd() + “/data/reorganized/” ///这不起作用#USe flow_from_directorytrain_data_keras = datagen.flow_from_directory(directory=train_dir,class_mode=&#39;categorical&#39;,batch_size=16, #一次16张图像target_size=(32,32)) #调整图像大小

#我们可以检查单个批次的图像。x, y = next(train_data_keras)#查看范围 (0,15) 内的 i 的每个图像：image = x[i].astype(int)plt. imshow(图像)plt.show()`
]]></description>
      <guid>https://stackoverflow.com/questions/78330964/how-to-split-a-dataset-into-folders-depending-in-its-labels</guid>
      <pubDate>Mon, 15 Apr 2024 20:49:06 GMT</pubDate>
    </item>
    <item>
      <title>LCEL Lanchais RAG 顺序链的问题</title>
      <link>https://stackoverflow.com/questions/78330865/problem-with-lcel-lanchais-rag-sequential-chains</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78330865/problem-with-lcel-lanchais-rag-sequential-chains</guid>
      <pubDate>Mon, 15 Apr 2024 20:20:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用tensorflow.keras库训练神经网络时出错</title>
      <link>https://stackoverflow.com/questions/78330820/error-whilst-attempting-to-train-neural-network-using-tensorflow-keras-library</link>
      <description><![CDATA[我正在使用 tensorflow.keras 开发我的第一个 ML 深度学习项目
这是一个简单的彩票预测，我在完成在线课程后用它来积累我的知识。
输入 1 到 90 之间的 90 个整数值。
输出从输入的 90 个值中选择的 5 个值。
当执行拟合“model.fit(X, train_output_catg, epochs=50, batch_size=32)”时
我遇到错误：
ValueError：参数 target 和 output 必须具有相同的等级 (ndim)。收到：target.shape=(None, 5, 90), output.shape=(None, 5)
我网络上的输出层是：
输出层
model.add(Dense(5,activation=&#39;softmax&#39;))
我正在使用以下损失函数：
编译模型
model.compile（optimizer=&#39;adam&#39;，loss=&#39;categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]）
因为我有整数，所以我使用以下方法将其转换为分类值：
#将 y 更改为分类值
train_output_catg = tf.keras.utils.to_categorical(y - 1, num_classes=None)
我明白问题所在，但不知道如何解决。
我的输出层形状如下“output.shape=(None, 5)”但我的目标形状是“target.shape=(None, 5, 90)”
我最初的“X”和“y”数组是：
X 形状：(2223, 90)
y 的形状：(2223, 5)
然后在“y”数组上，我执行了 to_categorical（如上所述），将其转换为 3 维数组，导致失败，因为输出数组和目标数组之间不匹配。
感谢您提供的任何帮助。
我期望函数 tf.keras.utils.to_categorical 为我提供与“y”数组相同的维度数组，但由于它添加了额外的维度，所以我遇到了上述错误。]]></description>
      <guid>https://stackoverflow.com/questions/78330820/error-whilst-attempting-to-train-neural-network-using-tensorflow-keras-library</guid>
      <pubDate>Mon, 15 Apr 2024 20:06:55 GMT</pubDate>
    </item>
    <item>
      <title>我可以在扩散模型中使用更简单的损失函数（例如直接似然损失）吗？</title>
      <link>https://stackoverflow.com/questions/78330493/can-i-use-a-simpler-loss-function-e-g-direct-likelihood-loss-in-diffusion-mod</link>
      <description><![CDATA[训练扩散模型时，可以选择定义损失函数。常见的包括根据高斯分布的均值或噪声定义损失函数。但它总是从最大化预测 x0 为或接近实际 x0 的可能性开始。然后需要数学推导来用平均值或噪声来表达损失。
我的问题是我们可以直接使用（负）可能性作为损失吗？ IE。在训练步骤中，我们知道 Xt 并尝试预测 Xt-1，然后对于每个像素 (i, j) 如果预测的 &lt; code&gt;Xt-1(i,j) != 实际的 Xt-1(i,j) 那么这就会导致损失。我所描述的只是训练/收敛速度慢还是不正确？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78330493/can-i-use-a-simpler-loss-function-e-g-direct-likelihood-loss-in-diffusion-mod</guid>
      <pubDate>Mon, 15 Apr 2024 18:54:09 GMT</pubDate>
    </item>
    <item>
      <title>实施机器学习进行自动车辆维护：可行性和挑战[关闭]</title>
      <link>https://stackoverflow.com/questions/78330407/implementing-machine-learning-for-automated-vehicle-maintenance-feasibility-and</link>
      <description><![CDATA[我正在探索将机器学习算法纳入车辆维护系统以自动检测组件故障的想法。这一概念涉及嵌入整个车辆的传感器，持续监控其各个部件，如果任何关键部件发生故障，系统会检测到它并自动触发适当的操作。
我正在向社区寻求有关此方法的可行性以及开发人员在实施过程中可能遇到的潜在挑战的见解。具体来说，我想知道：
将机器学习算法集成到现有车辆架构中以进行自动故障检测的可行性如何？
开发准确可靠的车辆故障检测模型的关键技术考虑因素和挑战是什么？
您是否有推荐的用于实施基于机器学习的车辆维护系统的现有框架、库或最佳实践？
此外，如果有人对类似项目或计划有第一手经验或了解，我将非常感谢您可以分享的任何见解或经验教训。
我目前正在研究这个主题一段时间，但到目前为止还没有取得突破，如果我能得到关于这个主题的任何建议，那将是一个很大的帮助。我从上个月参加的一次黑客马拉松中出现的类似问题中得到了这个想法。]]></description>
      <guid>https://stackoverflow.com/questions/78330407/implementing-machine-learning-for-automated-vehicle-maintenance-feasibility-and</guid>
      <pubDate>Mon, 15 Apr 2024 18:34:32 GMT</pubDate>
    </item>
    <item>
      <title>深度学习训练准确率显着变化</title>
      <link>https://stackoverflow.com/questions/78330285/deep-learning-training-accuracy-changes-significantly</link>
      <description><![CDATA[在此处输入图像描述
我正在 DQN 中训练一个深度网络，用于使用 2 臂机器人投掷球。状态为（末端执行器位置、投掷角度、关节值）。这些动作以不同的值移动关节。网络参数为（L_r 0.003、no_layers 10、no_neurons 32、no_epochs 50）
无论我在训练中改变什么，损失函数和准确率总是这样（准确率不超过20%）。我改变了学习率，不行。层，没有神经元和纪元，但我仍然无法达到超过 20% 的准确率。我该如何改进？]]></description>
      <guid>https://stackoverflow.com/questions/78330285/deep-learning-training-accuracy-changes-significantly</guid>
      <pubDate>Mon, 15 Apr 2024 18:04:46 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的有效张量乘法</title>
      <link>https://stackoverflow.com/questions/78330216/effective-tensor-multiplication-in-pytorch</link>
      <description><![CDATA[有谁知道我如何有效地计算两个张量乘法 - 例如，我有两个形状为 (15, 256) 和 (112, 256) 的张量，它们的乘积为形状为 (15, 112) 的张量可以是以7微秒计算。但是，如果我有像 A - (15, 100, 256) 和 B - (112, 2000, 256) 这样的张量，并且我会做出像 C = (A.reshape(-1, 256) @ B.reshape(256, - 1).reshape(15, 100, 112, 2000).permute(0, 2, 1, 3).max(-1).values.sum(-1) 得到形状为(15, 112)的张量，需要 1000 倍的时间才能计算得更快吗？
我知道第二个计算应该比第一个计算大得多，但也许它需要的时间比我的实现要少]]></description>
      <guid>https://stackoverflow.com/questions/78330216/effective-tensor-multiplication-in-pytorch</guid>
      <pubDate>Mon, 15 Apr 2024 17:49:57 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的过度拟合故障排除：优化正则化和数据预处理</title>
      <link>https://stackoverflow.com/questions/78330178/troubleshooting-overfitting-in-neural-networks-optimizing-regularization-and-da</link>
      <description><![CDATA[我正在开展一个机器学习项目，并且在神经网络的训练过程中遇到了问题。尽管使用了 dropout 和批量归一化等技术，我仍然观察到训练数据的过度拟合。这是否是由于我的正则化参数配置错误或数据预处理管道中的缺陷造成的？任何有关如何解决此问题的见解或建议将不胜感激。
在我的机器学习项目中，我使用 dropout 和批量归一化等先进技术实现了神经网络架构，以减轻过度拟合。然而，尽管做出了这些努力，我仍然在训练过程中观察到过度拟合行为。我怀疑该问题可能源于正则化参数的错误配置或数据预处理管道中的缺陷。我正在寻求有关如何有效排除和解决这个持续存在的过度拟合问题的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78330178/troubleshooting-overfitting-in-neural-networks-optimizing-regularization-and-da</guid>
      <pubDate>Mon, 15 Apr 2024 17:42:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有闪电模块的调度程序？</title>
      <link>https://stackoverflow.com/questions/78330089/how-do-i-use-a-scheduler-with-a-lightning-module</link>
      <description><![CDATA[非常不言自明，我正在尝试在我的闪电模块中使用ReduceLROnPlateau调度程序，但我似乎无法让它真正改变学习率。我故意将 lr 设置为 0.1，使其人为地变高，但它在整个训练过程中仍然保持不变。我还制作了一个仅包含 10 个样本的虚拟数据集，因此我可以运行 100 个时期。即使经过 100 个 epoch，lr 仍保持不变。感谢您提前提供的任何帮助。
类 STARCOP_module(L.LightningModule):

    def __init__(自我，模型)：
        超级().__init__()
        self.save_hyperparameters(ignore=[“模型”])
        self.model = 模型
        self.score = BinaryF1Score().to(设备)
        自我.lr = 0.1
        
    def Training_step（自身，批次，batch_idx）：
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        损失 = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_train = self.score(pred, 目标)
        self.log(“学习率”, self.lr)
        self.log(&quot;训练损失&quot;, loss, prog_bar=False)
        self.log(&quot;训练F1得分&quot;, F1_train)
        回波损耗
    
    defvalidation_step(self,batch,batch_idx):
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        v_loss = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_val = self.score(pred, 目标)
        self.log(&quot;验证损失&quot;, v_loss)
        self.log(&quot;验证F1分数&quot;, F1_val)
        返回v_loss
    
    def test_step（自身，批次，batch_idx）：
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        t_loss = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_test = self.score(pred, 目标)
        self.log(&quot;测试损失&quot;, t_loss)
        self.log(&quot;测试F1分数&quot;, F1_test)
        返回 t_loss
    
    def 前向（自身，输入）：
        pred = self.model(输入)
        返回（预测）
        
    def 配置_优化器（自身）：
        优化器 = torch.optim.Adam(self.parameters(), lr=self.lr)
        sched = {“调度程序”: torch.optim.lr_scheduler.ReduceLROnPlateau(优化器,
                                                               模式＝“分钟”，
                                                               系数=0.5，
                                                               耐心=1),
                 “监视器”:“训练损失”}
        return {“优化器”：优化器，“调度器”：sched}

此外，有谁知道一种方法，以便调度程序检查每个步骤而不是每个时期的平稳情况？]]></description>
      <guid>https://stackoverflow.com/questions/78330089/how-do-i-use-a-scheduler-with-a-lightning-module</guid>
      <pubDate>Mon, 15 Apr 2024 17:24:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 中的参考标记句子构建机器学习模型来标记相似的句子？</title>
      <link>https://stackoverflow.com/questions/78329937/building-a-machine-learning-model-to-tag-similar-sentences-using-a-reference-tag</link>
      <description><![CDATA[我是 NLP 新手，正在尝试构建一个 ML 模型来在 Python 中注释/标记类似的句子。
带注释的句子 - “please call [calling] john [name]”
类似的句子 - [“我想给拉姆打电话”、“你能打电话给杰克吗”、“给拉奎尔打电话”]。

我的目标是标记所有相似的句子。我已经拥有相似句子的列表以及每个列表中的一个标记句子。标签基本上是意图和实体。
对上述算法有什么建议吗？我正在使用Python。
注意-

对于建模，我们必须使用 BERT 模型，不能使用任何其他模型。
我已经从所有句子的句子转换器模型中嵌入了可以
如有必要，可重复使用。
]]></description>
      <guid>https://stackoverflow.com/questions/78329937/building-a-machine-learning-model-to-tag-similar-sentences-using-a-reference-tag</guid>
      <pubDate>Mon, 15 Apr 2024 16:53:47 GMT</pubDate>
    </item>
    <item>
      <title>更改pytorch中中毒的输入[关闭]</title>
      <link>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</link>
      <description><![CDATA[实际上，我有这段代码，最初下载了 cifar 10 数据集并对图像应用了中毒（编辑右下角）
然而，此时我需要使用本地的图像，数据集分为 5 个文件夹，其中每个文件夹都是不同的类。这是我尝试编写的代码，但它给了我错误：
将 numpy 导入为 np
从复制导入深复制

标准化参数 = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]
输入大小 = 224
路径=&#39;./DB&#39;


defgenerate_trigger(trigger_type):
    if trigger_type == &#39;checkerboard_1corner&#39;: # 棋盘位于右下角
        模式 = np.zeros(形状=(32, 32, 1), dtype=np.uint8) + 122
        掩码 = np.zeros(形状=(32, 32, 1), dtype=np.uint8)
        触发值 = [[0, 0, 255], [0, 255, 0], [255, 0, 255]]
        触发区域 = [-1, 0, 1]
        对于trigger_region中的h：
            对于trigger_region中的w：
                模式[30 + h, 30 + w, 0] = 触发值[h + 1][w + 1]
                掩码[30 + h, 30 + w, 0] = 1
    返回模式、掩码


def add_trigger_dirty_label（data_set，trigger_type，poison_rate，poison_target，trigger_alpha = 1.0）：
    模式，掩码=generate_trigger(trigger_type=trigger_type)
    poison_cand = [i for i in range(len(data_set.targets)) if data_set.targets[i] !=poison_target]
    poison_set = 深度复制(data_set)
    poison_num = int(poison_rate * len(poison_cand))
    选择= np.random.choice(poison_cand,毒药_num,replace=False)

    对于选择中的 idx：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩码) * 原始 + 掩码 * ((1 - 触发阿尔法) * 原始 + 触发阿尔法 * 模式), 0, 255
        ).astype(np.uint8)
        poison_set.targets[idx] =poison_target
    trigger_info = {&#39;trigger_pattern&#39;: 模式[np.newaxis, :, :, :], &#39;trigger_mask&#39;: 掩码[np.newaxis, :, :, :],
                    &#39;trigger_alpha&#39;：trigger_alpha，&#39;poison_target&#39;：np.array（[poison_target]），
                    &#39;data_index&#39;：选择}
    返回poison_set、trigger_info


def add_trigger_clean_label（数据集，trigger_type，poison_rate，poison_target，trigger_alpha = 1.0）：
    模式，掩码=generate_trigger(trigger_type=trigger_type)
    poison_cand = [i for i in range(len(data_set.targets)) if data_set.targets[i] ==poison_target]
    poison_set = 深度复制(data_set)
    poison_num = int(poison_rate * len(poison_cand))
    选择= np.random.choice(poison_cand,毒药_num,replace=False)

    对于选择中的 idx：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩码) * 原始 + 掩码 * ((1 - 触发阿尔法) * 原始 + 触发阿尔法 * 模式), 0, 255
        ).astype(np.uint8)
    trigger_info = {&#39;trigger_pattern&#39;: 模式[np.newaxis, :, :, :], &#39;trigger_mask&#39;: 掩码[np.newaxis, :, :, :],
                    &#39;trigger_alpha&#39;：trigger_alpha，&#39;poison_target&#39;：np.array（[poison_target]），
                    &#39;data_index&#39;：选择}
    返回poison_set、trigger_info


def add_predefined_trigger(data_set,trigger_info):
    如果trigger_info为None：
        返回数据集

    poison_set = 深度复制(data_set)

    模式=trigger_info[&#39;trigger_pattern&#39;]
    掩码=trigger_info[&#39;trigger_mask&#39;]
    阿尔法 = 触发器信息[&#39;trigger_alpha&#39;]

    对于范围内的 idx(len(poison_set))：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩模) * orig + 掩模 * ((1 - alpha) * orig + alpha * 图案), 0, 255
        ).astype(np.uint8)

    返回poison_set

从torchvision导入数据集，转换


data_transforms = 变换.Compose([
    变换.调整大小(INPUT_SIZE),
    变换.ToTensor(),
    变换.Normalize(NORMALIZATION_PARAMS[0], NORMALIZATION_PARAMS[1])
]）

image_dataset = datasets.ImageFolder(root=PATH, 变换=data_transforms)
#image_dataset = CIFAR10(root=&#39;./&#39;,train=True,download=True,transform=data_transforms)

中毒率 = 0.1
毒物目标 = 1

poisoned_dataset，trigger_info = add_trigger_dirty_label（image_dataset，&#39;checkerboard_1corner&#39;，poison_rate，poison_target）

请注意以下错误：
回溯（最近一次调用最后一次）：
  文件“C:\Users\enric\PycharmProjects\Avvelenatore\main.py”，第 92 行，在  中
    poisoned_dataset，trigger_info = add_trigger_dirty_label（image_dataset，&#39;checkerboard_1corner&#39;，poison_rate，poison_target）
  文件“C:\Users\enric\PycharmProjects\Avvelenatore\main.py”，第 30 行，位于 add_trigger_dirty_label
    orig=poison_set.data[idx]
  文件“C:\Users\enric\anaconda3\envs\pytorch\lib\site-packages\torch\utils\data\dataset.py”，第 83 行，在 __getattr__ 中
    引发属性错误
属性错误

你能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</guid>
      <pubDate>Mon, 15 Apr 2024 16:00:49 GMT</pubDate>
    </item>
    <item>
      <title>了解各种 ML 导出格式</title>
      <link>https://stackoverflow.com/questions/78329031/understanding-the-various-ml-export-format</link>
      <description><![CDATA[在各种类型的 ML 导出格式中 - YAML、Pickle、ONNX 等 - 您使用哪一种？为什么？例如，选择 Pickle 而不是 ONNX 有什么好处吗？
我试图在网上寻找专家对此的意见，但没有任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/78329031/understanding-the-various-ml-export-format</guid>
      <pubDate>Mon, 15 Apr 2024 14:16:33 GMT</pubDate>
    </item>
    <item>
      <title>了解梯度提升中的模型选择</title>
      <link>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</link>
      <description><![CDATA[包含问题的图片
我目前正在研究梯度增强模型，并且遇到了一种我不确定的情况。在我的模型的第一阶段，拟合了决策树，这由模型的阶跃函数外观表示。
但是，当我检查第一阶段的残差时，它们似乎表现出二次模式。这促使我考虑在第二阶段使用 2 次多项式模型。
但我很困惑，因为问题陈述建议在第二阶段使用与第一阶段相同类型的模型（即决策树）。
决策树能否捕获残差中的二次模式？或者，尽管问题陈述提出了建议，但我应该在第二阶段考虑不同类型的模型？
任何关于如何处理这种情况的澄清将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</guid>
      <pubDate>Sat, 13 Apr 2024 23:38:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytest 和假设进行可视化</title>
      <link>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</link>
      <description><![CDATA[我正在使用albumentation库进行图像增强，我也在为每个类似的旋转编写测试用例应该在50 - 90度之内，Blur=blur_limit min：3 max：99，我如何可视化我的测试用例在哪里假设失败
带有假设可视化的 pytest]]></description>
      <guid>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</guid>
      <pubDate>Sat, 13 Apr 2024 19:08:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中计算 TAR (%) @ FAR = 0.1%？</title>
      <link>https://stackoverflow.com/questions/71420229/how-do-i-calculate-tar-far-0-1-in-python</link>
      <description><![CDATA[我正在阅读一篇论文，论文中的结果以如下方式呈现：

我想为我的模型创建一个类似的表格。使用下面的代码我得到了 FAR 和 TAR 值。
来自 sklearn 导入指标

测试 = [0, 0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0 ,0 ,1 ,0 ,0 ,0 ,1, 0]
pred = [0.04172871, 0.01611879, 0.01073375, 0.03344169 ,0.04172871, 0.04172871, 0.00430162 ,0.04172871 ,0.04172871 ,0.04172871 ,0.07977659, 0.905772,0.9396076,  0.03344169, 0.04172871, 0.09125287, 0.02964183, 0.0641269,0.04172871 ,0.04172871, 0.04172871, 0.0641269 , 0.04172871, 0.04172871 ,0.9919831,0.04172871,0.01611879,0.04172871,0.37865442,0.00240888]
远，焦油，阈值=metrics.roc_curve（Y_test，p）

我应该如何修复 FAR = 0.1% 以及如何使用 Python 计算 TAR% @FAR = 0.1%？]]></description>
      <guid>https://stackoverflow.com/questions/71420229/how-do-i-calculate-tar-far-0-1-in-python</guid>
      <pubDate>Thu, 10 Mar 2022 07:25:22 GMT</pubDate>
    </item>
    </channel>
</rss>