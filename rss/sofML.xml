<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 21:16:35 GMT</lastBuildDate>
    <item>
      <title>Azure Custom Vision 从网络摄像头获取图像，然后返回图像</title>
      <link>https://stackoverflow.com/questions/78727554/azure-custom-vision-to-get-an-image-from-webcam-and-then-return-an-image</link>
      <description><![CDATA[我希望创建一项服务，将网络摄像头中的图像发送到 Azure Custom Vision，并让其返回它认为匹配的图像。这可以用于纸牌游戏，因此如果您在网络摄像头上显示黑桃 A，它将能够返回黑桃 A 的图像。这是否适合 Azure Custom Vision？我创建了一个项目并上传和标记了图像，但我还没有看到这样的用例。]]></description>
      <guid>https://stackoverflow.com/questions/78727554/azure-custom-vision-to-get-an-image-from-webcam-and-then-return-an-image</guid>
      <pubDate>Tue, 09 Jul 2024 19:57:34 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未在未知的 TensorShape 上定义 as_list()。图像和掩码形状看起来正确</title>
      <link>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</link>
      <description><![CDATA[我正尝试调整 Tensorflow 的示例 UNet 以达到我的目的。主要区别在于，此 UNet 采用 128x128 图像和掩码，而我的图像为 512x512，掩码为 100x100。
尝试运行 model.fit 时出现此错误：
ValueError：as_list() 未在未知的 TensorShape 上定义。

但是，我可以毫无问题地运行 model.predict，它会生成我期望的未经训练的模型的预测。
这是我用来制作和训练模型的代码：
base_model = tf.keras.applications.MobileNetV2(input_shape=[512, 512, 3], include_top=False)

# 使用这些层的激活
layer_names = [
&#39;block_1_expand_relu&#39;, # 64x64
&#39;block_3_expand_relu&#39;, # 32x32
&#39;block_6_expand_relu&#39;, # 16x16
&#39;block_13_expand_relu&#39;, # 8x8
&#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

# 创建特征提取模型
down_stack = tf.keras.Model(inputs=base_model.input, output=base_model_outputs)

down_stack.trainable = False

up_stack = [
pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
input = tf.keras.layers.Input(shape=[512, 512, 3])

# 通过模型进行下采样
skips = down_stack(inputs)
x = skips[-1]
skips = reversed(skips[:-1])

# 上采样并建立 skip 连接
for up, skip in zip(up_stack, skips):
x = up(x)
concat = tf.keras.layers.Concatenate()
x = concat([x, skip])

# 这是模型的最后一层
last = tf.keras.layers.Conv2DTranspose(
filters=output_channels, kernel_size=3, strides=2,
padding=&#39;same&#39;) #64x64 -&gt; 128x128

x = last(x)

return tf.keras.Model(inputs=inputs, output=x)

OUTPUT_CLASSES = 5

model = unet_model(output_channels=OUTPUT_CLASSES)
model.compile(optimizer=&#39;adam&#39;,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=[&#39;accuracy&#39;])

model_history = model.fit(train_dataset, epochs=EPOCHS,
validation_data=test_dataset)

我尝试检查每个批次的图像形状和掩码形状。除了最后一个批次（只有一个图像）外，每个批次的图像形状为 (16, 512, 512, 3)，掩码形状为 (16, 100, 100, 1)。
我尝试将此代码放入我的 process_paths（教程中称之为）函数中：
image = tf.reshape(image, [512, 512, 3])

...
mask = tf.reshape(mask, [100, 100, 1])

我尝试对 up_stack 部分中的数字进行一些调整，但最终一无所获，因为我不理解那部分。我的假设是，既然我已经更改了输入大小，我必须更改模型层的输出大小，但我真的不知道该怎么做。另外，我很困惑，如果是这样的话，为什么我仍然可以运行 model.predict。
我的 tensorflow 版本是 2.16.1]]></description>
      <guid>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</guid>
      <pubDate>Tue, 09 Jul 2024 19:17:45 GMT</pubDate>
    </item>
    <item>
      <title>如何设置 XGBoost 中的所有默认参数或安装旧版本的 XGBoost？</title>
      <link>https://stackoverflow.com/questions/78727359/how-to-set-all-default-parameters-in-xgboost-or-install-an-older-version-of-xgbo</link>
      <description><![CDATA[XGBoost 将每个参数的值设置为“无”，而不是 2.1.0 文档中所述的默认值。有没有办法将所有参数设置为默认值，而无需手动分配所有参数？我上次使用 XGBoost（2022 年 9 月）时从未遇到过此问题。这个问题是此版本独有的吗？
我尝试过手动设置默认值，但我一定是错过了什么。它一直告诉我缺少一些参数。
我的代码：
xgb_model = XGBClassifier(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1,
colsample_bynode=1, colsample_bytree=1, gamma=0, device = &#39;cpu&#39;,
significance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;,
learning_rate=0.300000012, max_delta_step=0, max_depth=6,
min_child_weight=1, monotone_constraints=&#39;()&#39;,
n_estimators=100, n_jobs=12, num_parallel_tree=1,
objective=&#39;reg:squarederror&#39;, random_state=0, reg_alpha=0,
reg_lambda=1, scale_pos_weight=None, subsample=1,
tree_method=&#39;exact&#39;, verify_parameters=1, verbosity=1, max_leaves = 0)

xgb_model.fit(X_train, y_train)

输出：
XGBClassifier(base_score=0.5, booster=&#39;gbtree&#39;, callbacks=None,
colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
device=&#39;cpu&#39;, early_stopping_rounds=None,
enable_categorical=False, eval_metric=None, feature_types=None,
gamma=0, grow_policy=None, significance_type=&#39;gain&#39;,
interaction_constraints=&#39;&#39;, learning_rate=0.300000012,
max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
missing=nan, monotone_constraints=&#39;()&#39;, multi_strategy=None,
n_estimators=100, n_jobs=12, num_parallel_tree=1,
objective=&#39;reg:squarederror&#39;, ...)

这是上面的错误消息。我甚至无法在 XGBoost 文档中找到其中一些参数的默认值。
此外，我尝试使用 pip 和“pip3 install xgboost 1.6.2”下载旧版本，但它给了我错误“找不到满足要求 1.6.2 的版本，未找到与 1.6.2 匹配的发行版”。我真的希望旧版本不会有同样的问题。
(base) PS C:\Users\myUsername&gt; pip3 install xgboost=1.6.2
错误：无效要求：“xgboost=1.6.2”
提示：= 不是有效运算符。你的意思是 == 吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78727359/how-to-set-all-default-parameters-in-xgboost-or-install-an-older-version-of-xgbo</guid>
      <pubDate>Tue, 09 Jul 2024 19:05:07 GMT</pubDate>
    </item>
    <item>
      <title>如果使用 tf.lite.interpreter，循环中会发生内存泄漏</title>
      <link>https://stackoverflow.com/questions/78727155/memory-leak-in-loop-if-use-tf-lite-interpreter</link>
      <description><![CDATA[我正在开发一个 FastAPI 项目，该项目接受带有模型名称和数据的请求。这些数据经过标准路径：（预处理、模型处理、后处理）。每个模型的解释器都存储在字典中，以便再次调用模型。
由于这些模型很多（超过 500 个），占用的 RAM 量接近 3 GB。
我想尝试减少 RAM 消耗，并尝试删除 tf.lite.interpreter 保存，但这导致了内存泄漏。据我了解，这是由于 tf.lite.interpreter 每次创建实例时都会在内存中存储一​​些数据。
我想知道是否可以在处理后删除 tf.lite.interpreter 创建的所有数据。以减少 RAM 消耗。
还是假设 tf.lite.interpreter 是为模型创建的，并在运行期间不断存储？
使用模型后，有什么方法可以释放内存吗？
我的方法有意义吗？
提前感谢您的帮助。我刚刚开始使用 ML。
一开始，我用 memory_profiler 对内存进行了分析。它显示内存是在 tf.lite.Interpreter() 的行上分配的
之后我创建了一个小脚本进行测试。
from time import perf_counter, sleep
import tensorflow as tf
import psutil
import logs
from logs.handlers import RotatingFileHandler

PATH = ...

rotating_handler = RotatingFileHandler(
filename=&#39;logs/memory_leak.log&#39;, 
mode=&#39;a+&#39;, 
maxBytes=int(20e6),
backupCount=10, 
encoding=&#39;utf-8&#39;
)
formatter = logs.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;, datefmt=&#39;%Y-%m-%d %H:%M:%S&#39;)
rotating_handler.setFormatter(formatter)
root_logger = logs.getLogger()
root_logger.setLevel(logging.WARNING)
root_logger.addHandler(rotating_handler)

def create_interpreter(path:str):
with tf.device(&#39;/CPU:0&#39;):
timer_start: float = perf_counter()
interpretationer = tf.lite.Interpreter(model_path=path)
interpretationer.allocate_tensors()
create_time = perf_counter() - timer_start
print(f&#39;ID 解释器：{id(interpreter)}&#39;)
print(f&#39;时间：{create_time}&#39;)
process = psutil.Process()
mem_info = process.memory_info()
logs.warning(f&#39;内存使用情况：RSS={mem_info.rss / 1024 ** 2:.2f} MB, VMS={mem_info.vms / 1024 ** 2:.2f} MB&#39;)
return interpretationer

while True:
some_interpreter = create_interpreter(path=PATH)
some_interpreter.allocate_tensors()
sleep(5)
del some_interpreter

我知道 del 删除的只是链接，但我认为之后 python GC 会清除内存。
根据这个脚本的日志，python 进程消耗的内存正在缓慢增加。]]></description>
      <guid>https://stackoverflow.com/questions/78727155/memory-leak-in-loop-if-use-tf-lite-interpreter</guid>
      <pubDate>Tue, 09 Jul 2024 18:07:46 GMT</pubDate>
    </item>
    <item>
      <title>Flutter/Tensorflow 形状不匹配错误</title>
      <link>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</link>
      <description><![CDATA[我正在制作一个运行 tensorflow Lite 模型的 Flutter 应用。我收到以下错误：
无法从形状为 [1, 2] 的 TensorFlowLite 张量 (Identity) 复制到形状为 [1, 215] 的 Java 对象。
背景故事：我训练过的算法使用 215 列并输出 1 或 0。下面是使用 netron.app 的屏幕截图：Netron 图
我实在无法理解为什么这个东西想要将形状 [1,2]（输出）复制到输入 Java 类中。这个代码太高级了，我无法正确调试它（我想有办法，但我有点新手）。我找不到 Tensorflow Lite 的 Flutter 文档，因为对我来说太模糊了，它只描述了破坏代码的函数的输入参数。下面是破坏的函数，错误在 runModelOnBinary() 函数中。任何一般性的指导/帮助/经验都将不胜感激，因为我对 Flutter、Dart 和 AI 还不太熟悉。如果需要，我可以发布整个 main.dart 代码，但我不确定是否有必要。
void assessModel() async {
try {

// 生成具有 215 列的随机输入数据以匹配预期的 860 字节输入大小
List&lt;double&gt; inputData = List.generate(215, (index) =&gt; Random().nextInt(2).toDouble());

// 将 List&lt;double&gt;到 Float32List
Float32List inputBytes = Float32List.fromList(inputData);

// 将 Float32List 转换为 Uint8List
Uint8List inputUint8List = inputBytes.buffer.asUint8List();
print(inputData);
// 在输入数据上运行模型
var output = await Tflite.runModelOnBinary(
binary: inputUint8List,
numResults: 2, // 根据需要进行调整
);
print(&quot;here2&quot;);
// 处理 null 或空输出
if (output == null || output.isEmpty) {
var result = output?[0]; 
/* ChatGPT 告诉我这样做，之前将输出变量作为可打印结果。
我认为这个问题没有太大区别，因为它是在代码中断之后*/
setState(() {
_output = &quot;Predicted: ${result[&#39;label&#39;]} (${result[&#39;confidence&#39;]})&quot;;
});
} else {
setState(() {
_output = output.toString();
});
}
} catch (e) {
// 捕获任何错误并显示它们
setState(() {
_output = &quot;Error running model: $e&quot;;
});
}
}

我尝试调整 numResults 参数，查看文档，甚至 chatGippidy，建议执行 var result = output?[0]，但一切都太模糊，没有深入介绍这个特定堆栈的工作原理。]]></description>
      <guid>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</guid>
      <pubDate>Tue, 09 Jul 2024 17:44:04 GMT</pubDate>
    </item>
    <item>
      <title>autokeras 无法运行，依赖项出现错误</title>
      <link>https://stackoverflow.com/questions/78726939/autokeras-not-running-with-error-in-dependency</link>
      <description><![CDATA[import tensorflow as tf
#from tensorflow.keras import layer
#import tensorflow_datasets as tfds
import os
#import PIL
import numpy as np

# 定义路径
train_dir = &#39;data3/train&#39;
val_dir = &#39;data3/val&#39;
test_dir = &#39;data3/test&#39;

# 定义参数
batch_size = 32
img_height = 224
img_width = 224

# 创建用于训练、验证和测试集的 tf.data.Dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
train_dir,
validation_split=0.2,
subset=&quot;training&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

val_ds = tf.keras.utils.image_dataset_from_directory(
val_dir,
validation_split=0.2,
subset=&quot;validation&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

test_ds = tf.keras.utils.image_dataset_from_directory(
test_dir,
image_size=(img_height, img_width),
batch_size=batch_size
)

# 标准化图像
normalization_layer = tf.keras.layers.Rescaling(1./255)

train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))

# 优化数据集性能
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

import autokeras as ak

# 定义 AutoKeras 图像分类器
clf = ak.ImageClassifier(
overwrite=True,
max_trials=1 # 调整数据集的试验次数
)

# 训练 AutoKeras 模型
clf.fit(train_ds, validation_data=val_ds, epochs=1)

# 导出最佳模型
best_model = clf.export_model()

# 将最佳模型保存到文件
best_model.save(&#39;pneumonia_detection_autokeras.h5&#39;)

# 加载已保存的模型
#loaded_model = tf.keras.models.load_model(&#39;pneumonia_detection_autokeras.h5&#39;, custom_objects=ak.CUSTOM_OBJECTS)

出现以下错误
文件“C:\Users\atish\OneDrive\Documents\VSCode\Python2\learning.py”，第 60 行，位于
import autokeras as ak
文件&quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras_init_.py&quot;，第 15 行，位于 
来自 autokeras.auto_model 导入 AutoModel
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\auto_model.py&quot;，第 26 行，位于 
来自 autokeras 导入块
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\blocks_init_.py&quot;，第 18 行，位于 autokeras.blocks.basic 导入 BertBlock
文件&quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\blocks\basic.py&quot;，第 25 行，位于 
来自 autokeras 导入 keras_layers
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\keras_layers.py&quot;，第 27 行，位于 
来自 tensorflow.keras.layers.experimental 导入预处理
ModuleNotFoundError：没有名为“tensorflow.keras.layers.experimental”的模块]]></description>
      <guid>https://stackoverflow.com/questions/78726939/autokeras-not-running-with-error-in-dependency</guid>
      <pubDate>Tue, 09 Jul 2024 17:13:24 GMT</pubDate>
    </item>
    <item>
      <title>加载模型时出错：SyntaxError：意外的标记“<”，“<!DOCTYPE”... 不是有效的 JSON</title>
      <link>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</link>
      <description><![CDATA[我正在使用 React 上的 ml5 和 p5 创建一个瑜伽 ai 训练器。
我创建了一个组件，它从本地 JSON 文件中获取单个姿势作为道具。该组件还加载我在公共文件夹中添加的模型。该组件的目标是检测某个瑜伽姿势，并且该组件动态返回从网络摄像头检测到的姿势名称。
我测试了两个网络摄像头页面。我们称之为第 1 页和第 2 页。
第 1 页有效。网址为 /practice。第 1 页指向网络摄像头 1。网络摄像头 1 有效。
第 2 页的网址为 /practice/poseId。第 2 页指向不同的网络摄像头组件，网络摄像头 2 的代码与网络摄像头 1 完全相同，只是它接受一个道具，并且该道具是与 ID 匹配的特定姿势。
在第二页，我收到此错误
加载模型时出错：SyntaxError：意外的标记“&lt;”，“&lt;!DOCTYPE”... 不是有效的 JSON
它指向此代码
 const modelInfo = {
model: &quot;model/model.json&quot;,
metadata: &quot;model/model_meta.json&quot;,
weights: &quot;model/model.weights.bin&quot;,
};

fetch(modelInfo.model)
.then((response) =&gt; {
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
return response.json();
})
.then((data) =&gt; {
console.log(&quot;Model JSON:&quot;, data);
brain.load(modelInfo, brainLoaded);
})
.catch((error) =&gt; {
console.error(&quot;Error loading model:&quot;, error);
});

我不明白为什么我的组件在 /practice url 上有效，但是当我添加 poseId (/practice/:poseID) 时，即使代码相同，也会显示该错误。
错误出现在以 /practice/:poseId 结尾的 url 上，例如/practice/1.
错误示例（您看不到底部的姿势标签）：

示例（如果页面网址为 /practice，则有效）

这是我的仓库：https://github.com/laura-nguyen/yoga-ai/tree/feature/page-pose-cam
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</guid>
      <pubDate>Tue, 09 Jul 2024 17:06:11 GMT</pubDate>
    </item>
    <item>
      <title>在 MNIST 数据集上训练的 Tensorflow 模型在自己的测试图像上准确率较低</title>
      <link>https://stackoverflow.com/questions/78726737/tensorflow-model-trained-on-mnist-dataset-gives-low-accuracy-on-own-test-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78726737/tensorflow-model-trained-on-mnist-dataset-gives-low-accuracy-on-own-test-images</guid>
      <pubDate>Tue, 09 Jul 2024 16:26:30 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解决 UnicodeDecodeError？[关闭]</title>
      <link>https://stackoverflow.com/questions/78726197/how-can-i-solve-the-unicodedecodeerror</link>
      <description><![CDATA[我尝试使用我的数据集训练更快的 rcnn，但我总是收到此错误。“UnicodeDecodeError：&#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：无效的起始字节”。
这是异常：
UnicodeDecodeError：&#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：无效的起始字节
这是回溯：
文件“C:\Users\90531\Desktop\New_tf2\models\research\object_detection\model_main_tf2.py”，第 114 行，位于 &lt;module&gt;
tf.compat.v1.app.run()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\platform\app.py”，第 36 行，运行中
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\absl\app.py”，第 308 行，运行中
_run_main(main, args)
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\absl\app.py”，第 254 行，运行中
sys.exit(main(argv))
文件“C:\Users\90531\Desktop\New_tf2\models\research\object_detection\model_main_tf2.py”，第 105 行，在 main 中
model_lib_v2.train_loop(
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\object_detection\model_lib_v2.py”，第 505 行，在 train_loop 中
configs = get_configs_from_pipeline_file(
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\object_detection\utils\config_util.py”，第 138 行，在 get_configs_from_pipeline_file 中
proto_str = f.read()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 114 行，在 read 中
self._preread_check()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 76 行，在 _preread_check 中
self._read_buf = _pywrap_file_io.BufferedInputStream(
UnicodeDecodeError: &#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：起始字节无效

我尝试使用此代码进行训练模型（efficientdet_d0_coco17_tpu-32.tar.gz）：
python model_main_tf2.py --pipeline_config_path==ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir==training --alsologtostderr]]></description>
      <guid>https://stackoverflow.com/questions/78726197/how-can-i-solve-the-unicodedecodeerror</guid>
      <pubDate>Tue, 09 Jul 2024 14:26:30 GMT</pubDate>
    </item>
    <item>
      <title>可以将已经经过拆分数据阶段、成为训练、验证和测试数据的图像数据集保存到我的计算机存储文件夹中吗？</title>
      <link>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</link>
      <description><![CDATA[我想问一下我做的训练、验证和测试数据的分布，我可以把数据分布以文件夹的形式保存在存储中吗？可以吗？我希望可以:)
如果你想看完整的代码
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
我想下载测试数据部分，即&quot;test_gen&quot;或测试数据集。我希望有人能用一个代码来回答我的问题，这个代码可以将数据保存到我的电脑中，而我必须从现有的数据集集合中逐个搜索图像数据
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</guid>
      <pubDate>Tue, 09 Jul 2024 09:41:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras Tensorflow load_model 函数需要很长时间才能加载模型</title>
      <link>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</link>
      <description><![CDATA[我使用 tensorflow 训练了一个模型（用于识别面部），然后将其保存为“facetracker.h5”。但是，当我尝试加载该模型时，它只是继续加载“[*]”，如下图所示，并且实际上从未完成加载。该模型 (facetracker.h5) 只有 68 MB，所以我是否可以认为这种情况不是由于其大小而发生的？：

facetracker 如下所示：

如能提供任何帮助，我们将不胜感激。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</guid>
      <pubDate>Tue, 09 Jul 2024 09:28:15 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Roboflow 上将属性添加到类作为子类</title>
      <link>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</link>
      <description><![CDATA[我正在使用 Roboflow 注释我的视频，并尝试向标签框（类）添加属性（子类）。我检查了所有资源，最新文档表明，将属性作为子类添加到我的类的功能应该在项目设置页面中可用。但是，我似乎找不到它。
我目前正在使用免费的公共计划。这可能是我无法访问此功能的原因吗？有没有其他人遇到过这个问题？最近更新后免费版本中是否已禁用此功能？如果升级到付费计划可以解决此问题，我愿意考虑。]]></description>
      <guid>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</guid>
      <pubDate>Tue, 09 Jul 2024 04:00:51 GMT</pubDate>
    </item>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“keras.wrappers”的模块</title>
      <link>https://stackoverflow.com/questions/78541790/modulenotfounderror-no-module-named-keras-wrappers</link>
      <description><![CDATA[我正在尝试使用 GridSearchCV 进行机器学习分类任务，但是这行代码一直出错，有什么建议吗？
from keras.wrappers.scikit_learn import KerasClassifier

我的 tensorflow 版本是 2.16.1，我的 keras 版本是 3.3.3
我尝试了以下操作：
pip install scikeras

from scikeras.wrappers import KerasClassifier

并得到“ImportError：无法从‘sklearn.utils.deprecation’导入名称‘_deprecate_Xt_in_inverse_transform’”
如能提供任何帮助，我们将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78541790/modulenotfounderror-no-module-named-keras-wrappers</guid>
      <pubDate>Tue, 28 May 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>ImportError（'无法导入 PIL.Image。'与 keras-ternsorflow 合作</title>
      <link>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</link>
      <description><![CDATA[我正在学习 lynda.com 上的一些关于在 PyCharmCE 环境中使用 Keras-TensorFlow 进行深度学习的讲座，他们没有遇到这个问题。
我收到此错误：

raise ImportError(&#39;无法导入 PIL.Image。&#39;
ImportError：无法导入 PIL.Image。使用 array_to_img 需要 PIL。

我检查过其他人是否也遇到同样的错误，但对于我来说，使用 pip 安装枕头，命令 pip install Pillow 无法解决任何问题。

MacBook-Pro-de-Rogelio:~ Rogelio$ pip install Pillow
要求已满足：./anaconda3/lib/python3.6/site-packages 中的枕头
MacBook-Pro-de-Rogelio:~ Rogelio$

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</guid>
      <pubDate>Fri, 12 Jan 2018 11:49:58 GMT</pubDate>
    </item>
    </channel>
</rss>