<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 06:23:15 GMT</lastBuildDate>
    <item>
      <title>无法加载贝叶斯神经网络</title>
      <link>https://stackoverflow.com/questions/78955532/unable-to-load-bayesian-nueral-network</link>
      <description><![CDATA[去年夏天我一直与我的教授一起做研究，最近我们开始比较不同的数据模型。一个模型是贝叶斯神经网络，它运行良好，但由于某种原因，我在保存模型后无法加载它，因为它给了我一些错误。
这是我的模型代码：
import tensorflow as tf
import tensorflow_probability as tfp

kernel_divergence_fn = lambda q, p, _: tfp.distributions.kl_divergence(q, p)
bias_divergence_fn = lambda q, p, _: tfp.distributions.kl_divergence(q, p)

inputs = tf.keras.Input(shape=(1024, 2, 1))

x = tfp.layers.Convolution2DFlipout(
filters=32,
kernel_size=(3, 1),
padding=&#39;same&#39;,
activation=&#39;relu&#39;,
kernel_divergence_fn=kernel_divergence_fn,
bias_divergence_fn=bias_divergence_fn
)(输入)
x = tf.keras.layers.Dropout(0.2)(x)

x = tfp.layers.Convolution2DFlipout(
filters=16,
kernel_size=(3, 2),
padding=&#39;same&#39;,
activation=&#39;relu&#39;,
kernel_divergence_fn=kernel_divergence_fn,
bias_divergence_fn=bias_divergence_fn
)(x)
x = tf.keras.layers.Dropout(0.2)(x)

x = tf.keras.layers.Flatten()(x)

解释1 = tfp.layers.DenseFlipout(
128,
bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(),
bias_prior_fn=tfp.layers.default_mean_field_normal_fn(), 
kernel_divergence_fn=kernel_divergence_fn,
bias_divergence_fn=bias_divergence_fn,
activation=&quot;relu&quot;
)(x)

interpretation2 = tfp.layers.DenseFlipout(
64,
bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(),
bias_prior_fn=tfp.layers.default_mean_field_normal_fn(), 
kernel_divergence_fn=kernel_divergence_fn,
bias_divergence_fn=bias_divergence_fn,
activation=&quot;relu&quot;
)(interpretation1)

outputs = tf.keras.layers.Dense(24,activation=&#39;softmax&#39;)(interpretation2)

model = tf.keras.Model(inputs=inputs,outputs=outputs)
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

model.summary()

我添加了自定义对象部分，因为它为自定义层抛出了错误，但现在它只是说“str”对象不可调用，所以现在我非常困惑。]]></description>
      <guid>https://stackoverflow.com/questions/78955532/unable-to-load-bayesian-nueral-network</guid>
      <pubDate>Fri, 06 Sep 2024 03:41:34 GMT</pubDate>
    </item>
    <item>
      <title>React Native 中的实时面部和空中识别</title>
      <link>https://stackoverflow.com/questions/78955519/real-time-facial-aerial-recognition-in-react-native</link>
      <description><![CDATA[如何使用自定义模型在 React Native 中实现实时面部和空中物体识别？
我正在开发一款 React Native 应用，该应用需要实时面部识别和空中物体识别（例如，从无人机信息源中识别建筑物、车辆或其他物体）。我想在不完全依赖 Google ML Kit 或 Face API 等第三方库的情况下实现这一点。我需要一个支持自定义机器学习模型的解决方案。
我已成功集成 react-native-camera 来访问设备摄像头。
我已经探索了 tensorflow.js 和 onnx 进行模型推理，但我在实时性能方面遇到了困难，尤其是空中识别。
我尝试使用 mediapipe 进行面部特征识别，但还没有弄清楚如何以流畅、高效的方式结合面部识别和空中识别。
我的问题：

如何在 React Native 中优化实时面部识别和空中识别，尤其是使用自定义模型？

什么是实时运行这些过程的一些性能注意事项或最佳实践，尤其是对于较大的空中识别模型？
我应该使用本机模块来处理繁重的计算，还是可以使用 tensorflow.js 或 onnx 等库在 JavaScript 中高效处理所有事情？
如何在摄像头供稿上叠加边界框和其他视觉提示（例如，面部边框、对象标签），并确保两种识别（面部 + 空中）同时工作？
相关代码：
从“react-native-camera”导入 { Camera };
从“@tensorflow/tfjs”导入 * 作为 tf;
从“@mediapipe/face_landmarks”导入 * 作为 faceLandmarks;
从“./aerialModel”导入 aluminiumRecognitionModel; // 自定义空中识别模型 

const CameraScreen = () =&gt; {

const [predictions, setPredictions] = useState([]); 

const handleCameraStream = async (cameraStream) =&gt; {
const faceResults = await faceLandmarks.estimateFaces(cameraStream);

const aluminiumResults = await aluminiumRecognitionModel.predict(cameraStream); 

setPredictions([...faceResults, ...aerialResults]);
}; 

return (&lt;Camera onFrame={handleCameraStream} style={{ flex: 1 }} /&gt;);
};

任何有关优化性能或指导我正确方法的帮助都将不胜感激！
其他请求：
如果有人曾经参与过类似的项目或知道任何解决面部和空中识别的开源项目，我很乐意看到一些参考资料。任何相关资源、教程或 GitHub 存储库都将不胜感激。让我们分享知识并共同打造一些很棒的东西！
系统信息：
React Native：0.74.1
平台：iOS 和 Android
模型：自定义训练模型（TensorFlow 格式）
]]></description>
      <guid>https://stackoverflow.com/questions/78955519/real-time-facial-aerial-recognition-in-react-native</guid>
      <pubDate>Fri, 06 Sep 2024 03:30:57 GMT</pubDate>
    </item>
    <item>
      <title>如何微调人脸识别预训练模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78954958/how-can-i-fine-tune-pre-trained-model-for-face-recognition</link>
      <description><![CDATA[我正在开发一个使用人脸识别的自动考勤系统，需要有关最佳方法的建议：
模型选择：哪种高级人脸识别模型（例如 FaceNet、DeepFace、ArcFace）最适合在自定义数据集上进行微调？
数据集管理：我应该如何构建和预处理我的数据集以实现最佳训练和验证？
上下文：
目标：使用人脸识别识别需要出勤的个人。
当前设置：使用 TensorFlow/Keras 和按单个文件夹组织的数据集。
任何指导或提示都将不胜感激！
谢谢！
我尝试制作一个人脸识别模型，我希望知道在自己的数据集中训练其他预训练模型的准确度。]]></description>
      <guid>https://stackoverflow.com/questions/78954958/how-can-i-fine-tune-pre-trained-model-for-face-recognition</guid>
      <pubDate>Thu, 05 Sep 2024 21:54:39 GMT</pubDate>
    </item>
    <item>
      <title>商品预测-时间序列建模</title>
      <link>https://stackoverflow.com/questions/78954699/commotdity-forecasting-time-series-modelling</link>
      <description><![CDATA[我正在与一位客户合作，他希望我按月进行商品价格预测。但他们只能为我们提供过去 5 年的月度数据。（60 个数据点）
我尝试过 Holt 的 Winter 模型、ARIMA、SARIMAX、LSTM、LR、Prophet。但准确度不达标。
进行月度预测所需的最低数据点数是多少？能否请您帮我找到正确的方法？]]></description>
      <guid>https://stackoverflow.com/questions/78954699/commotdity-forecasting-time-series-modelling</guid>
      <pubDate>Thu, 05 Sep 2024 20:17:53 GMT</pubDate>
    </item>
    <item>
      <title>无法将 tensorflow 导入 jupyter 并验证</title>
      <link>https://stackoverflow.com/questions/78954574/can-not-import-tensorflow-to-jupyter-and-verify</link>
      <description><![CDATA[这是它的屏幕截图，我已经安装在正确的路径中，我的 python 版本是 3.9.6，pip 已升级，我不知道为什么我无法导入它，我也尝试运行验证
python3 -c &quot;import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))&quot;

但是它什么也没显示，只是卡在那里，我使用的是 macOS。知道为什么会发生这种情况吗？
尝试创建新的虚拟环境并卸载、重新安装、安装其他版本]]></description>
      <guid>https://stackoverflow.com/questions/78954574/can-not-import-tensorflow-to-jupyter-and-verify</guid>
      <pubDate>Thu, 05 Sep 2024 19:34:12 GMT</pubDate>
    </item>
    <item>
      <title>Python 神经网络中的 DeprecationWarning</title>
      <link>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</link>
      <description><![CDATA[我最近一直在学习神经网络实现，在 Dence、Sequential 和预测函数之后，当我想获得结果时，VS Code 会出现此错误
DeprecationWarning：将 ndim &gt; 0 的数组转换为标量已被弃用，将来会出现错误。确保在执行此操作之前从数组中提取单个元素。 （已弃用 NumPy 1.25。）
p\[i,0\] = my_sequence(X\[i\],W1,b1,W2,b2)

def my_dense(a_in,W,b): # 矩阵的大写 W
units = W.shape[1]
a_out = np.zeros(units)
for j in range(units):
w = W[:,j]
z = np.dot(w,a_in) + b[j]
a_out[j] = sigmoid(z)
return a_out
def my_sequence(a0,W1,b1,W2,b2): # a0 : x（输入）
a1 = my_dense(a0,W1,b1)
a2 = my_dense(a1,W2,b2)
return a2
def my_predict(X,W1,b1,W2,b2):
m = X.shape[0]
p = np.zeros((m,1))
for i in range(m):
p[i,0] = my_sequence(X[i],W1,b1,W2,b2)
return(p) # 预测矩阵中的 p
X = np.array([[210,17],
[190,20],
[240,19]])
W1 = np.array( [[-8.93, 0.29, 12.9 ],
[-0.1, -7.32, 10.81]] )
b1 = np.array( [-9.82, -9.28, 0.96] )
W2 = np.array( [[-31.18],
[-27.59],
[-32.56]] )
b2 = np.array( [15.41] )
norm_l.adapt(X)
X_n = norm_l(X)
predictions = my_predict(X_n,W1_tmp,b1_tmp,W2_tmp,b2_tmp)```
]]></description>
      <guid>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</guid>
      <pubDate>Thu, 05 Sep 2024 19:03:34 GMT</pubDate>
    </item>
    <item>
      <title>如何训练人工智能完成任务？[关闭]</title>
      <link>https://stackoverflow.com/questions/78954394/how-can-an-ai-be-trained-to-do-a-task</link>
      <description><![CDATA[如何训练或指定 ai/ml 来学习某件事？
例如，当给定样本/数据时，如何让它学习我想要它做的事情？
（我不确定如何表述它，但希望有人明白我的意思）]]></description>
      <guid>https://stackoverflow.com/questions/78954394/how-can-an-ai-be-trained-to-do-a-task</guid>
      <pubDate>Thu, 05 Sep 2024 18:26:14 GMT</pubDate>
    </item>
    <item>
      <title>如何从中断的地方继续训练模型？</title>
      <link>https://stackoverflow.com/questions/78954139/how-to-continue-training-a-model-from-where-it-left-off</link>
      <description><![CDATA[我想知道在训练文本分类模型时如何保存检查点，以便我可以从中断的地方继续训练。
我遇到了麻烦，不知道如何配置我的代码以使用适当的文件保存检查点，以便我可以从之前结束的位置继续训练，例如“trainer_state.json”。
这是我的训练代码：
def executar_treinamento(self, base_treinada):
training_args = TrainingArguments(
output_dir=self.output_dir,
learning_rate=2e-5,
per_device_train_batch_size=8,
per_device_eval_batch_size=8,
num_train_epochs=8,
weight_decay=0.01,
evaluation_strategy=&quot;epoch&quot;,
        save_strategy=“epoch”, save_only_model=False, load_best_model_at_end=False ) self.trainer = Trainer( model=self.model, args=training_args,compute_metrics=self.calcular_metricas, train_dataset=base_treinada[&#39;train&#39;], eval_dataset=base_treinada[&#39;validation&#39;], tokenizer=self.tokenizar_textos ) self.trainer.train() def avaliar_modelo(self, base_treinada): self.trainer.evaluate(base_treinada[&#39;test&#39;]) def salvar_modelo(self, caminho): self.model.save_pretrained(caminho)
self.tokenizer.save_pretrained(caminho)

我尝试使用以下参数：
 save_strategy=&quot;steps&quot;, # 每 X 步保存检查点
save_steps=80, # 自定义保存频率（以步数为单位）

但是，即便如此，带有“trainer_state.json”等文件的检查点仍未保存。]]></description>
      <guid>https://stackoverflow.com/questions/78954139/how-to-continue-training-a-model-from-where-it-left-off</guid>
      <pubDate>Thu, 05 Sep 2024 17:01:57 GMT</pubDate>
    </item>
    <item>
      <title>PINN 中的物理损失是如何计算的？[关闭]</title>
      <link>https://stackoverflow.com/questions/78953649/how-is-physics-loss-calculated-in-pinns</link>
      <description><![CDATA[我正在研究物理信息神经网络 (PINN)，对物理损失的计算方式感到困惑。具体来说，在 1D 热方程示例中：
在此处输入图片说明
我知道该方程被平方以给出正输出，但不确定实际应用原始 1D 热方程如何计算成本。
假设输入是预测值，PINN 究竟如何知道“偏离多远”或预测是否在物理约束范围内？]]></description>
      <guid>https://stackoverflow.com/questions/78953649/how-is-physics-loss-calculated-in-pinns</guid>
      <pubDate>Thu, 05 Sep 2024 14:49:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 Scikit Learn 在 Vertex 上导入模型</title>
      <link>https://stackoverflow.com/questions/78953273/importing-a-model-with-scikit-learn-on-vertex</link>
      <description><![CDATA[我尝试从本地导入模型，但每次我都会从 gcp 日志中收到相同的错误。框架是 scikit-learn
AttributeError: 无法从 &#39;/usr/app/model_server.py&#39;&gt; 获取 &lt;module &#39;model_server&#39; 上的属性 &#39;preprocess_text&#39; 
存在此问题的代码片段是
complaints_clf_pipeline = Pipeline(
[
(&quot;preprocess&quot;, text.TfidfVectorizer(preprocessor=utils.preprocess_text, ngram_range=(1, 2))),
(&quot;clf&quot;, naive_bayes.MultinomialNB(alpha=0.3)),
]
)

这个
preprocess_text 

来自上面的单元格，但我一直收到此问题，model_server 不存在于我的代码中。
有人可以帮忙吗？
我尝试重构代码但得到了同样的错误，尝试撤消此管道结构，但在尝试通过 API 查阅模型时又收到另一个错误。]]></description>
      <guid>https://stackoverflow.com/questions/78953273/importing-a-model-with-scikit-learn-on-vertex</guid>
      <pubDate>Thu, 05 Sep 2024 13:24:34 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 中将 flow_from_directory 与多个目录结合使用，实现多输出神经网络</title>
      <link>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</link>
      <description><![CDATA[这是我在这里的第一个问题，所以如果有任何不清楚的地方，我深表歉意。
我正在做一个项目，需要使用 Keras 中的 flow_from_directory 从多个目录加载图像。我的目录结构如下：
Images_folder/
═── Carpet_1/
│ ═── training/
│ │ ═── class_1/
│ │ ═── class_2/
│ ═── validation/
═── Carpet_2/
│ ═── training/
│ │ ═── class_1/
│ │ ═── class_2/
│ ═── validation/
...
每个“Carpet”目录（例如 Carpet_1、Carpet_2）包含相同的类集（class_1、class_2 等）。我想使用来自所有这些目录的图像来训练 CNN。我的目标是构建一个多输出神经网络，其中一个输出预测“地毯”编号（1、2、3、...），另一个输出预测该地毯内的类别。
鉴于这种结构，我如何使用 ImageDataGenerator 或 Keras 中的任何其他方法来加载和预处理这些图像？有没有办法将来自所有这些目录的图像组合成一个生成器，同时仍然允许我区分不同的地毯？
任何关于如何解决这个问题的指导都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</guid>
      <pubDate>Thu, 05 Sep 2024 07:56:05 GMT</pubDate>
    </item>
    <item>
      <title>级联分段-通道设置是否正确？</title>
      <link>https://stackoverflow.com/questions/78951423/cascade-segmentation-are-the-channels-set-up-correctly</link>
      <description><![CDATA[我想训练一个机器学习模型，用于处理 2D DICOM 图像中的精细蒙版细节。我有 500 张图像准备进行标记/注释。我可以使用这种技术吗？还是我理解错了？
鱼 + 脊椎的注释

我用 1 个类别注释了 500 张图像：鱼。然后我训练一个 model1.pth，将鱼与背景区分开来。该模型有 2 个 out_channels：鱼和背景。

我再次注释了相同的 500 张图像，但现在有 2 个类别：鱼 + 脊椎。我加载 model1.pth，并创建一个具有 2 个输入通道 和 3 个输出通道 的模型：脊柱、鱼和背景，并将模型保存为 model2.pth

最后，我再次注释了 500 张图像，但现在我包括了变形。如果我有 3 种类型的变形，则每种变形都有自己的类别。我加载 model2.pth，创建一个具有 3 个输入通道 和 6 个输出通道 的模型：背景、鱼、脊柱、变形 1、变形 2、变形 3，并将模型保存为 model3.pth。

现在模型可以直接在新图像上使用。是这样吗？


背景和细节。我尝试过什么
目标是找到鱼脊椎的变形。到目前为止，我已尝试通过使用 MONAI 的 UNet 模型 来分割 3 个类别 + 背景。图像是转换为 NifTi 格式 (.dcm.nii.gz) 的 2D DICOM 图像，典型尺寸为 2000x900 像素。我使用 3Dslicer 进行注释。到目前为止的类别：

背景

鱼

脊椎

变形


到目前为止，我已经在（仅）12 张训练图像上进行了测试，只是为了让它运行，我得到了所有 3 个类别的结果，但我猜模型训练过度了。此外，我猜这种技术使得在训练结束后进行微小更改变得更加困难。例如，我想要多种不同类型的变形。 
我的结果：红线左侧：来自 tensorboard，红线右侧：在新图像上测试模型
在开始注释 500 张图像之前，我想验证我是否走在正确的道路上。我希望通过使用级联技术，我可以获得一个可以轻松分割鱼和脊椎的模型，并且我可以随后尝试不同的变形注释。]]></description>
      <guid>https://stackoverflow.com/questions/78951423/cascade-segmentation-are-the-channels-set-up-correctly</guid>
      <pubDate>Thu, 05 Sep 2024 05:34:37 GMT</pubDate>
    </item>
    <item>
      <title>具有共享权重的嵌套模块是否应为 nn.Module 对象参数？</title>
      <link>https://stackoverflow.com/questions/78950394/should-nested-modules-with-shared-weights-be-an-nn-module-object-parameter-or-no</link>
      <description><![CDATA[我希望两个 torch.nn.Module 类共享其部分架构和权重，如下例所示：
from torch import nn

class SharedBlock(nn.Module):
def __init__(self, *args, **kwargs):
super().__init__()

self.block = nn.Sequential(
# 在此处定义一些块架构...
)

def forward(self, x):
return self.block(x)

class MyNestedModule(nn.Module):
def __init__(self, shared_block: nn.Module, *args, **kwargs):
super().__init__()

self.linear = nn.Linear(...)
self.shared_block = shared_block

def forward(self, x):
return self.shared_block(self.linear(x))

class MyModule(nn.Module):
def __init__(self, *args, **kwargs):
super().__init__()

# 应该是：
shared_block = SharedBlock(*args, **kwargs)
# 或者：
self.shared_block = SharedBlock(*args, **kwargs) # 注意：self。
# ...如果有区别，区别是什么？

self.nested1 = MyNestedModule(shared_block, *args, **kwargs)
self.nested2 = MyNestedModule(shared_block, *args, **kwargs)

def forward(self, x):
x_1, x_2 = torch.split(x, x.shape[0] // 2, dim=0)
y_1 = self.nested1(x_1)
y_2 = self.nested2(y_2)
return y_1, y_2

我想知道 shared_block 是否应该是 MyModule 的对象参数。我认为不是，因为它在 MyNestedModule 类对象中都被设置为对象参数，所以它应该在 torch grad 中注册，但如果我确实在 MyModule 中将它创建为对象参数，会发生什么？]]></description>
      <guid>https://stackoverflow.com/questions/78950394/should-nested-modules-with-shared-weights-be-an-nn-module-object-parameter-or-no</guid>
      <pubDate>Wed, 04 Sep 2024 20:06:25 GMT</pubDate>
    </item>
    <item>
      <title>将索引数组转换为 NumPy 中的独热编码数组</title>
      <link>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</link>
      <description><![CDATA[给定一个 1D 索引数组：
a = array([1, 0, 3])

我想将其独热编码为 2D 数组：
b = array([[0,1,0,0], [1,0,0,0], [0,0,0,1]])
]]></description>
      <guid>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</guid>
      <pubDate>Thu, 23 Apr 2015 18:24:54 GMT</pubDate>
    </item>
    <item>
      <title>Akinator 游戏背后有什么样的算法？</title>
      <link>https://stackoverflow.com/questions/13649646/what-kind-of-algorithm-is-behind-the-akinator-game</link>
      <description><![CDATA[我一直很惊讶 Akinator 应用 只需问几个问题就能猜出一个字符。所以我想知道是什么样的算法或方法让它做到了这一点？这类算法有名字吗？我在哪里可以阅读更多关于它们的信息？]]></description>
      <guid>https://stackoverflow.com/questions/13649646/what-kind-of-algorithm-is-behind-the-akinator-game</guid>
      <pubDate>Fri, 30 Nov 2012 16:59:38 GMT</pubDate>
    </item>
    </channel>
</rss>