<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 09:16:51 GMT</lastBuildDate>
    <item>
      <title>如何通过调整函数的一个输入参数来训练它输出正确的值（基于训练数据）？</title>
      <link>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</link>
      <description><![CDATA[我是机器学习的新手。我有一个项目，需要帮助选择合适的机器学习算法。
我有一个包含三个输入（x、y 和 N）的函数：
F(x, y, N) → R
我希望软件自动调整并给出 N 的值（基于输入值 x 和 y），以便函数给出正确的值 R。
我有一个如下所示的训练数据集：



x
y
R




7
2
20


8
5
6


15
6
13


...
...



你对我应该寻找哪种合适的机器学习算法？如果神经网络合适，您对从多少层/节点开始有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</guid>
      <pubDate>Fri, 02 Aug 2024 08:29:10 GMT</pubDate>
    </item>
    <item>
      <title>关于训练模型过程中遇到的问题</title>
      <link>https://stackoverflow.com/questions/78824487/questions-about-problems-encountered-during-training-model</link>
      <description><![CDATA[我目前正在训练一个 AI 模型，在训练过程中遇到了一些问题，如附图所示。有人能帮我找出问题并提出解决方案吗？问题情况和设置如下：

设置

模型的参数每 64 次迭代更新一次。

模型每个 epoch 需要 30 步，并且有 5 个 warmup epoch。

我正在使用名为 CosineAnnealingWarmup 的学习率调度程序，最大和最小学习率分别为 2e-4 和 8e-7。



问题情况

损失在一段时间内会减少，但在某个点之后开始振荡。

模型的性能指标在某个时间点之后停滞或下降点。




我将非常感激您提供的任何帮助。以下是我的损失、指标和 lr 调度程序。


我尝试了以下方法，但没有奏效。

我正在使用 AsymmetricLoss，并尝试将 gamma_neg 值设置为 2、将 gamma_pos 设置为 0、将 clip 设置为 0.1。

我还将批次大小从 256 增加到 512，但没有任何效果。

我目前正在尝试增加模型的容量，但我似乎得到了类似的结果。


对于 AsymmetricLoss 代码如下：
class AsymmetricLoss(nn.Module):
def __init__(
self, gamma_neg=3, gamma_pos=0, clip=.05, eps=1e-8,
disable_torch_grad_focal_loss=True, cls_cnt_list=None, smoothing=.1
):
super().__init__()

self.gamma_neg = gamma_neg
self.gamma_pos = gamma_pos
self.clip = clip
self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss
self.eps = eps
self.smoothing = smoothing

如果 cls_cnt_list != None:
n_samples = sum(cls_cnt_list)
self.weights = torch.tensor([n_samples / cnt for cnt in cls_cnt_list]) / n_samples

如果 torch.cuda.is_available():
self.weights = self.weights.cuda()
else:
self.weights = None

def forward(self, x, y):
n_pos = y.sum(dim=1, keepdim=True)
y = (1 - self.smoothing) * y + (self.smoothing / (y.shape[1] - n_pos))

# 计算概率
x_sigmoid = torch.sigmoid(x)
xs_pos = x_sigmoid
xs_neg = 1 - x_sigmoid

# 不对称裁剪
if self.clip is not None and self.clip &gt; 0:
xs_neg = (xs_neg + self.clip).clamp(max=1)

# 基本 CE 计算
los_pos = y * torch.log(xs_pos.clamp(min=self.eps))
los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))
loss = los_pos + los_neg

# 非对称聚焦
if self.gamma_neg &gt; 0 or self.gamma_pos &gt; 0:
if self.disable_torch_grad_focal_loss:
torch.set_grad_enabled(False)
pt0 = xs_pos * y
pt1 = xs_neg * (1 - y) # pt = p if t &gt; 0 else 1-p
pt = pt0 + pt1
one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)
one_sided_w = torch.pow(1 - pt, one_sided_gamma)
if self.disable_torch_grad_focal_loss:
torch.set_grad_enabled(True)
loss *= one_sided_w

# 类权重
if self.weights != None:
loss *= self.weights.unsqueeze(0)

return -loss.sum() * 1024
]]></description>
      <guid>https://stackoverflow.com/questions/78824487/questions-about-problems-encountered-during-training-model</guid>
      <pubDate>Fri, 02 Aug 2024 08:28:46 GMT</pubDate>
    </item>
    <item>
      <title>多类图像分类的准确率未提高超过 50%</title>
      <link>https://stackoverflow.com/questions/78823757/accuracy-for-multi-class-image-classification-not-improving-past-50</link>
      <description><![CDATA[我正在开展一个项目，根据牛仔裤背面的图案预测牛仔裤的品牌。
为此，我在网上收集了 3 个不同牛仔裤品牌（arizona、levi、lucky brand）的数据，并为每个品牌获取了大约 100 张图片。然后我做了一些数据增强，虽然非常基础
def generate_more_images():
for dir in os.listdir(&#39;jean_img&#39;):
if dir != &#39;.DS_Store&#39;:
n = 0
for image in os.listdir(f&#39;jean_img/{dir}&#39;):

if image != &#39;.DS_Store&#39;:
img = Image.open(f&#39;jean_img/{dir}/{image}&#39;)
img = img.resize((500,500))
for i in range(10):
img = img.rotate(np.random.uniform(-35,35))
bright_factor = np.random.uniform(0.6, 1.4)
augmenter = ImageEnhance.Brightness(img) 
img =增强器.增强（亮度因子）
如果 n &lt; 200：
img.save（f&#39;jean_img_expand_test/{dir}_expand/{n}_{dir}_{image}&#39;）
elif n &lt; 300:
img.save(f&#39;jean_img_expand_valid/{dir}_expand/{n}_{dir}_{image}&#39;)
else:
img.save(f&#39;jean_img_expand_train/{dir}_expand/{n}_{dir}_{image}&#39;)
n += 1

然后利用这些图像，我训练并测试了多个模型，由于这些图像的复杂性，我认为这些模型的表现会很好，但令我惊讶的是，我的模型表现最好的时候也只能达到 60 多分到 50 多分。
optimizer = Adam(learning_rate=0.001)
reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2, waiting=5, min_lr=0.00001)

callback = callups.EarlyStopping(monitor=&#39;val_accuracy&#39;, waiting=20, restore_best_weights=True)

model = Sequential([
layer.Input(shape=(500, 500, 3)), 

layer.Conv2D(32, (3, 3), padding=&#39;same&#39;),
layer.LeakyReLU(alpha=0.3),
layer.MaxPooling2D((2, 2)),
layer.Dropout(0.25),

layer.Flatten(),

layer.Dense(64),
layer.LeakyReLU(alpha=0.3),
layer.Dropout(0.5),

layer.Dense(3,activation=&#39;softmax&#39;)
])
model.compile(optimizer=optimizer, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

model.fit(
train_images,
train_labels,
epochs=100,
validation_data=(val_images, val_labels),
callbacks=[callback, reduce_lr]
)

以下是一些训练图像：



我对计算机视觉还很陌生，但我认为这个分类问题并不难。我已经解决了更多类别的问题，算法运行得很好。如果有人能指出我工作中的缺陷，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78823757/accuracy-for-multi-class-image-classification-not-improving-past-50</guid>
      <pubDate>Fri, 02 Aug 2024 04:11:08 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 Pytorch 的 CrossEntropyLoss 应用类权重来解决多类多输出问题的不平衡数据分类问题</title>
      <link>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3），每个目标列有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html，我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。
具体来说，我可以获得如下所示的数据



A
B
C
D
E
OUTPUT_1
OUTPUT_2
OUTPUT_3




5.65
3.56
0.94
9.23
6.43
0
2
1


7.43
3.95
1.24
7.22
&lt; td&gt;2.66
0
0
0


9.31
2.42
2.91
2.64
6.28
2
0
2


8.19
5.12
1.32
3.12
8.41
0
2
0


9.35
1.92
3.12
4.13
3.14
0
1
1


8.43
9.72
7.23
8.29
9.18
1
0
2


4.32
2.12
3.84
9.42
8.19
0
1
0


3.92
3.91
2.90
8.1 9
8.41
2
0
2


7.89
1.92
4.12
8.19
7.28
0
1
2
&lt; /tr&gt;

5.21
2.42
3.10
0.31
1.31
2
0
0



因此，
输出 1 中的比例为：0 = 0.6、1 = 0.1、2 = 0.3
输出 2 中的比例为：0 = 0.4、1 = 0.3、2 = 0.3
输出 3 中的比例为：0 = 0.4、1 = 0.2、2 = 0.4

我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）第 1 类为 0.15，第 0 类和第 2 类各为 0.425（因此对于 output_1，权重将是 [0.425/0.6, 0.15/0.1, 0.425/0.3]，对于输出 2，它将是 [0.425/0.4, 0.15/0.3, 0.425/0.3] 等）。相反，我理解 pytorch 的 crossentropy 损失函数中的权重参数目前正在执行的操作是将单个类权重应用于每个输出列。我想知道我是否遗漏了什么，是否有办法使用 pytorch 的 crossentropyloss 函数来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</guid>
      <pubDate>Fri, 02 Aug 2024 03:34:55 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow model.evaluate() 崩溃，因为不支持 lab​​el_mode 中的 None 值</title>
      <link>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</link>
      <description><![CDATA[我尝试在 preprocessing.image_dataset_from_directory 上运行 model.evaluate()，但由于 label_mode=None 而无济于事
我尝试从 ImageDataGenerator 的 flow_from_directory 实现与 class_mode=&#39;input&#39; 类似的功能。我尝试了多次，但一直收到相同的错误消息。我也尝试过手动更改模型的输入，但我仍然不确定我哪里出错了。下面是我的代码：
 SIZE = 128
batch_size = 64

train_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_train&#39;, 
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

anomaly_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\cloud&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

rescaling_layer = layer.Rescaling(1./255)

def change_inputs(images, labels=None):
x = tensorflow.image.resize(rescaling_layer(images),[SIZE, SIZE], method=tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)
return x, x

train_dataset = train_generator.map(change_inputs)
validation_dataset = validation_generator.map(change_inputs)
anomaly_dataset = anomaly_generator.map(change_inputs)

#此处有一些模型构建和编译代码，但我省略了它#

# 检查侦察。验证数据和异常图像之间的误差
validation_error = model.evaluate(validation_generator)
anomaly_error = model.evaluate(anomaly_generator)

# 打印出结果
print(f&quot;Recon. error for the validation data is {validation_error}&quot;)
print(f&quot;Recon. error for the anomaly_error is {anomaly_error}&quot;)

最后四行是由于 label_mode 而出现的问题]]></description>
      <guid>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</guid>
      <pubDate>Thu, 01 Aug 2024 21:50:38 GMT</pubDate>
    </item>
    <item>
      <title>如何开始开发我自己的机器学习模型 Swift [关闭]</title>
      <link>https://stackoverflow.com/questions/78823105/how-to-start-developing-my-own-machine-learning-model-swift</link>
      <description><![CDATA[最近我一直在研究机器学习功能，例如 CreateML 和 CoreML，但我不太确定它们是否适合我想要完成的任务，因为它们更多地涉及图像识别/文本/语音/语音/等。
本质上，我正在尝试创建一个模型，该模型可以理解用户的颜色偏好，并在应用程序为他们设计的服装中重新创建类似的调色板。
例如，在最初启动应用程序时，用户会对一组随机的服装配色方案进行评分，然后将其用作训练数据以开发用户的风格偏好。
我已经有使用 Python 进行机器学习的经验，有没有办法将 Python 脚本集成到我的 Swift 应用程序中（我只见过一些 hackish tape 和 wish 解决方案，但我不确定这是否有效），或者我如何在 Swift 中使用 CoreML 或类似的东西来创建我自己的模型？ （到目前为止，我看过的教程都只是处理图像识别，我不确定从哪里开始使用这些教程的颜色偏好算法）
请记住，我是 Swift 的新手，但对编程并不陌生，所以老实说，只要指向正确的方向就会很有帮助，我可以弄清楚其余的！]]></description>
      <guid>https://stackoverflow.com/questions/78823105/how-to-start-developing-my-own-machine-learning-model-swift</guid>
      <pubDate>Thu, 01 Aug 2024 21:29:45 GMT</pubDate>
    </item>
    <item>
      <title>更清晰的分割 SAM (Segment Anything)</title>
      <link>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</link>
      <description><![CDATA[好吧，我目前正在做一个项目，我需要像这样分割图像上的对象：
图像 1
图像 2
我选择使用 Meta 的 AI SAM（Segment Anything）来裁剪这些对象。
我的代码如下所示：
import cv2
import numpy as np
import sys, os
from pathlib import Path
import torch
import surveillance as sv
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor

# 获取命令行参数
num = sys.argv[2]
img_path = sys.argv[1]
folder_path = sys.argv[3]

# 从给定路径加载图像
img = cv2.imread(img_path)

# 用于预处理图像以进行裁剪的函数
def preprocess_image_cut(img):
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
return gray

# 用于获取干净图像的函数
def get_clean_image(img, filter_level=1):
gray = preprocess_image_cut(img)
blurred_image = cv2.GaussianBlur(gray, (3, 3), 0)
_, binary_image = cv2.threshold(blurred_image, 210, 255, cv2.THRESH_BINARY)

kernel = np.ones((1, 1), np.uint8)
result_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
result_image = cv2.medianBlur(result_image, filter_level)

output_image = cv2.bitwise_or(gray, result_image)
return output_image

# 设置管道的函数
def setup_pipeline():
HOME = &#39;C:/&#39;
CHECKPOINT_PATH = os.path.join(HOME, &#39;weights&#39;, &#39;sam_vit_h_4b8939.pth&#39;)
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
MODEL_TYPE = &quot;vit_h&quot;

sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)
return mask_generator

# 运行 SAM 模型的函数
def run_sam(mask_generator, clean_image):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
sam_result = mask_generator.generate(image_rgb)
mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)
detections = sv.Detections.from_sam(sam_result=sam_result)

annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)

masks = [mask[&#39;segmentation&#39;] for mask in sorted(sam_result, key=lambda x: x[&#39;area&#39;, reverse=True])]
return mask

# 设置掩码生成器
mask_generator = setup_pipeline()

if __name__ == &quot;__main__&quot;:
if img_path.endswith(&quot;.png&quot;):
save_path = folder_path
os.makedirs(save_path, exist_ok=True)
if os.path.isdir(f&#39;{folder_path}/PROCESSED&#39;):
os.makedirs(f&#39;{folder_path}/PROCESSED&#39;, exist_ok=True)
img = cv2.imread(img_path)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
clean_image = get_clean_image(img, 3)

print(&quot;开始生成掩码&quot;)
mask = run_sam(mask_generator, clean_image)

for i, mask in enumerate(masks):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgra = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGRA)
extract_region = np.zeros_like(image_bgra)
extract_region[mask] = image_bgra[mask]
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
extract_region = extract_region[y:y+h, x:x+w]
extracted_region[:, :, 3] = (mask[y:y+h, x:x+w] &gt; 0) * 255
save_path2 = f&#39;{folder_path}/PROCESSED/img_{x}_{y}_{w}_{h}.png&#39;
cv2.imwrite(save_path2, extracted_region)

print(&quot;Finished&quot;)

但我目前在一些问题上遇到了困难，比如我不想让 Sam 分割数字，也不想分割将对象与数字联系起来的线条。
有人能对这个话题有什么想法吗，也接受其他分割图像的方法。
分割更清晰，垃圾分割更少]]></description>
      <guid>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</guid>
      <pubDate>Thu, 01 Aug 2024 20:21:17 GMT</pubDate>
    </item>
    <item>
      <title>两个数据集的随机森林的数据集结构[关闭]</title>
      <link>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</link>
      <description><![CDATA[我有两个单独的数据集，就变量而言，它们包含相同类型的数据，涉及 2000 多名农民，但针对的是同一农民的 2021 年和 2022 年（列数相同，为 70，行数不同；两者都接近 5000）。我必须使用机器学习和随机森林算法预测 2023 年的产量 (Y)（动物公斤数/农场总公顷数）。但是，我不确定您如何统一数据集（2021 年和 2022 年），或者我应该如何设置最终数据集以进行预测，这意味着：

我应该将两个数据集统一为一个吗？如果是，怎么办？
选项 A：



ID 农民
KG 动物
农场公顷
产量
年份
...




1
30
2
15
2021
...


1
40
3
13
2022
...


2
 20
4
5
2021
...


2
30
5
6
2022
...


...
...
...
...
...
...



选项B:



农民 ID
2021 年牲畜公斤数
2022 年牲畜公斤数
2021 年农场公顷数
2022 年农场公顷数
2021 年产量
产量2022




1
30
40
2
3
15
13


2
20
30
4
5
5
6


...
...
...
...
...
...
...



如果不是，最好的构造方法是什么？算法需要什么来构造数据集？或者它需要什么输入才能进行可靠的预测（我是机器学习的新手）？

我是否应该只将基于 2021 年的变化数据添加到 2022 年的数据集中，因此 kg、农场公顷的增加、减少 ecc 的百分比添加到新列中？或者应该如何设置？

我应该使用另一个机器学习模型进行预测吗？如果是，哪一个？我知道我不能使用时间序列预测，因为时间数据很少。

]]></description>
      <guid>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</guid>
      <pubDate>Thu, 01 Aug 2024 17:50:10 GMT</pubDate>
    </item>
    <item>
      <title>训练模型时出现错误“对象 __array__ 方法未生成数组”</title>
      <link>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</link>
      <description><![CDATA[我正在尝试使用神经网络模型 Sequential 来训练一个模型。在模型编译之前，一切都进展顺利。当我点击 model.fit() 进行模型训练时，我收到错误“对象 array 方法未生成数组”。请告诉我错误在哪里。我还打印了 X_train 和 y_train 样本及其形状。
下面是相同的代码。
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.utils import to_categorical
import numpy as np

# 编码分类特征
label_encoders = {}
for column in solidated_super.columns:
le = LabelEncoder()
consolidated_super[column] = le.fit_transform(consolidated_super[column])
label_encoders[column] = le

# 将数据拆分为输入和输出
X = solidated_super[[&#39;DeviceName_df1&#39;, &#39;AlarmName_df1&#39;]].values
y = solided_super[[&#39;DeviceName_df2&#39;, &#39;AlarmName_df2&#39;]].values

# 对输出标签进行独热编码
y_device = to_categorical(consolidated_super[&#39;DeviceName_df2&#39;])
y_alarm = to_categorical(consolidated_super[&#39;AlarmName_df2&#39;])

# 合并独热编码输出
y = np.concatenate([y_device, y_alarm], axis=1)

# 确保 y 为数字且具有正确的形状
print(f&#39;X shape: {X.shape}, y shape: {y.shape}&#39;)
print(f&#39;X sample: {X[:5]}, y sample: {y[:5]}&#39;)
&#39;&#39;&#39;
上述打印语句的 op
X shape: (396, 2), y shape: (396, 25)
X 样本：[[16 19]
[16 19]
[16 19]
[16 19]
[12 20]]，y 样本：[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 
0. 0.
1.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
0.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
0.]]
&#39;&#39;&#39;

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
random_state=42)

# 对输入特征进行归一化
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 定义神经网络模型
model = Sequential()
model.add(Input(shape=(X_train.shape[1],)))
model.add(Dense(64,激活=&#39;relu&#39;))
model.add(Dense(32, 激活=&#39;relu&#39;))
model.add(Dense(y_train.shape[1], 激活=&#39;softmax&#39;)) # 使用 softmax 进行多类分类
# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 训练模型
model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)

在执行 model.fit() 时，我收到错误：-
ValueError Traceback (most recent call last) Cell In[59], line 2
1 # 训练模型
----&gt; 2 model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)
文件 C:\Python312\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb
文件 C:\Python312\Lib\site-packages\tensorflow\python\framework\constant_op.py:108，在 convert_to_eager_tensor(value, ctx, dtype) 中
106 dtype = dtypes.as_dtype(dtype).as_datatype_enum
107 ctx.ensure_initialized()
--&gt; 108 返回 ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: 对象 __array__ 方法未生成数组

示例数据框为：-
{
&#39;DeviceName_df1&#39;: [&#39;Device A&#39;, &#39;Device B&#39;, &#39;Device C&#39;],
&#39;AlarmName_df1&#39;: [&#39;Alarm1&#39;, &#39;Alarm2&#39;, &#39;Alarm3&#39;],
&#39;DeviceName_df2&#39;: [&#39;Device X&#39;, &#39;Device Y&#39;, &#39;Device Z&#39;],
&#39;AlarmName_df2&#39;: [&#39;Alarm4&#39;, &#39;Alarm5&#39;, &#39;Alarm6&#39;]
}

所有字符串值。]]></description>
      <guid>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</guid>
      <pubDate>Thu, 01 Aug 2024 17:19:22 GMT</pubDate>
    </item>
    <item>
      <title>模型输出与输入具有相同的形状</title>
      <link>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</link>
      <description><![CDATA[我尝试制作一个股票价格预测程序，而不是根据最后 60 个值获取单个值，而是获得一个具有不同数字且形状与输入相同的输出，而不是单个值。
!pip install yfinance tensorflow==2.10.0
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import yfinance as yf
import datetime as dt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
import tensorflow as tf

start = dt.datetime(2012,1,1)
end = dt.datetime(2020,1,1)

data = yf.download(&quot;META&quot;, start=&#39;2012-01-01&#39;, end=&#39;2020-01-01&#39;)

data = pd.DataFrame(data)
data.head()

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60
x_train = []
y_train = []

for x in range(prediction_days,len(scaled_data)):
x_train.append(scaled_data[x-prediction_days:x,0]​​)
y_train.append(scaled_data[x,0])

x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))
ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)

model = Sequential()
model.add(tf.keras.Input(shape = (60,1)))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(Dense(1))

model.compile(optimizer = &#39;adam&#39;,loss = tf.keras.losses.MeanSquaredError())
model.fit(ds,epochs = 10)

test_data = yf.download(&quot;META&quot;, start=&#39;2020-01-01&#39;, end=&#39;2024-07-30&#39;)
actual_prices = test_data[&#39;Close&#39;].values
total_dataset = pd.concat((data[&#39;Close&#39;], test_data[&#39;Close&#39;]),axis = 0)
model_inputs = total_dataset[len(total_dataset)-len(test_data)-prediction_days:].values
model_inputs = model_inputs.reshape(-1,1)
model_inputs = scaler.transform(model_inputs)

x_test = []

for x in range(prediction_days, len(model_inputs)):
x_test.append(model_inputs[x-prediction_days:x,0]​​)

x_test = np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))
print(x_test)
predicted_prices = model.predict(x_test)
print(predicted_prices)

我尝试了不同的 tensorflow 版本和不同的损失函数，甚至为最后一层设置了不同的激活函数，但还是不起作用。
模式的输入形状为 (60,1)，输出应该只有一个数字，但却是一个形状为的随机数的完整列表（60,1）（当我运行它时，在我的例子中它是输入形状（1150,60,1）并且输出也是（1150,60,1））]]></description>
      <guid>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</guid>
      <pubDate>Thu, 01 Aug 2024 14:40:25 GMT</pubDate>
    </item>
    <item>
      <title>Colab：内存不足，无法加载 Llama 3</title>
      <link>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</link>
      <description><![CDATA[我正在按照 Youtube 上的教程操作，然后想要加载 Llama3 8B：
model_name = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hugging_face_key)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key)

得到：
您的会话失败，因为所有可用 RAM 都已使用

尝试过：model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key, low_cpu_mem_usage=True)
但再次出现同样的错误]]></description>
      <guid>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</guid>
      <pubDate>Thu, 01 Aug 2024 12:45:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在人工神经网络中进行样本外预测？</title>
      <link>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</guid>
      <pubDate>Thu, 01 Aug 2024 10:36:16 GMT</pubDate>
    </item>
    <item>
      <title>面部识别 - 机器学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</link>
      <description><![CDATA[我尝试在 Google Colab 上使用 Tensorflow 进行面部识别，但遇到了错误。之前运行正常，但现在却出现此错误。完整的 .ipynb 文件已链接（请注意，您需要一个包含 .jpg 文件的负、正和锚文件夹才能运行程序。）
使暹罗模型出错
文件链接：https://www.mediafire.com/file/a5azngcpmdrrxyd/facial_recognition.ipynb/file
我尝试从 4.3 函数中删除嵌入函数，但当它进入训练时会抛出另一个错误。训练错误
文本代码错误复制：
（删除嵌入后）
Epoch 1/100
-----------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-123-5343d5708b2c&gt; in &lt;cell line: 5&gt;()
3 
4 # 使用提供的训练数据和指定的 epoch 数训练 Siamese 网络
----&gt; 5 训练（siamese_model、train_data、EPOCHS）

7 帧
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py 在 binary_crossentropy（target、output、from_logits）中
666 
667 如果 len（target.shape）!= len（output.shape）：
-&gt; 668 引发 ValueError(
669 “参数 `target` 和 `output` 必须具有相同的等级”
670 “(ndim)。已收到：”

ValueError：在用户代码中：

文件“&lt;ipython-input-20-c4cff50f6a59&gt;”，第 18 行，在 train_step *
loss = binary_cross_loss(y, yhat)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py”，第 43 行，在 __call__ **
loss = self.call(y_true, y_pred)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py”，第 27 行，在 call
return self.fn(y_true, y_pred, **self._fn_kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py&quot;，第 1913 行，在 binary_crossentropy 中
ops.binary_crossentropy(y_true, y_pred, from_logits=from_logits),
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py&quot;，第 1398 行，在 binary_crossentropy 中
return backend.nn.binary_crossentropy(
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py&quot;，第 668 行，在 binary_crossentropy 中
引发 ValueError(

ValueError: 参数 `target` 和 `output` 必须具有相同的等级 (ndim)。收到：target.shape=(16,)，output.shape=(16, 100, 100, 1)

（在删除嵌入之前）

[&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_87&gt;]
-------------------------------------------------------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-139-ccc48c560ce8&gt; in &lt;cell line: 24&gt;()
22 
23 # 使用 make_siamese_model() 函数创建 Siamese 神经网络模型
---&gt; 24 siamese_model = make_siamese_model()
25 
26 # 显示 Siamese 模型的架构和参数摘要

2 帧
&lt;ipython-input-138-755d3b4e05cd&gt; in call(self, input_embedding, validation_embedding)
7 # 魔法在这里发生 - 相似度计算
8 def call(self, input_embedding, validation_embedding):
----&gt; 9 return tf.math.abs(input_embedding - validation_embedding)

TypeError：调用 L1Dist.call() 时遇到异常。

无法自动推断“l1_dist_12”（类型为 L1Dist）的输出形状/dtype。 `L1Dist.call()` 方法不正确，或者您需要实现 `L1Dist.compute_output_spec() / compute_output_shape()` 方法。遇到错误：

不支持的操作数类型：-：&#39;list&#39; 和 &#39;list&#39;

L1Dist.call() 收到的参数：
• args=([&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_88&gt;&#39;], [&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_89&gt;&#39;])
• kwargs=&lt;class &#39;inspect._empty&#39;&gt;
]]></description>
      <guid>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</guid>
      <pubDate>Wed, 31 Jul 2024 23:57:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行单类物体检测，结果为假阳性 [关闭]</title>
      <link>https://stackoverflow.com/questions/78793283/single-class-object-detection-using-cnn-getting-false-positive</link>
      <description><![CDATA[在这里，我尝试使用 cnn 构建一个 Manhole 物体检测，在这个模型中，经过训练我得到了 95% 的准确率。我得到的是假阳性，例如，如果我用人孔（训练对象）测试图像进​​行检测，它将绘制边界框，而我测试没有训练对象的随机图像，则会出现一个随机边界框，这就是问题所在，在实时网络摄像头测试中也是如此，但在这里，如果对象甚至没有被检测到，则会在框架中获取一些随机边界框。这里我提供我的代码，请帮助
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Conv2D, Input, BatchNormalization``, Flatten, MaxPool2D, Dense
from pathlib import Path

train_img = Path(&quot;DATASET/train/Manhole&quot;)
val_img = Path(&quot;DATASET\valid\Manhole&quot;)

train_csv = pd.read_csv(&#39;DATASET/train/Manhole/_annotations.csv&#39;) 
val_csv = pd.read_csv(&#39;DATASET/valid/_annotations.csv&#39;)
#print(train_csv)
train_csv[[&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]] = train_csv[[&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]].fillna(0)
train_csv[[&#39;xmin&#39;,&#39;ymin&#39;,&#39;xmax&#39;,&#39;ymax&#39;]] = train_csv[[&#39;xmin&#39;,&#39;ymin&#39;,&#39;xmax&#39;,&#39;ymax&#39;]].astype(int)
train_csv.drop_duplicates(subset=&#39;filename&#39;,inplace=True, ignore_index=True)
val_csv.drop_duplicates(subset=&#39;filename&#39;, inplace=True, ignore_index=True)

def datagenerator(df ,batch_size ,path):
while True:
images = np.zeros((batch_size,640,640,3))
bounding_box_coords = np.zeros((batch_size, 4))

for i in range(batch_size):
rand_index = np.random.randint(0, train_csv.shape[0])
row = df.loc[rand_index, :]
images[i] = cv2.imread(str(path/row.filename)) / 255.
bounding_box_coords[i] = np.array([row.xmin, row.ymin, row.xmax, row.ymax])

产生 {&#39;filename&#39;: images}, {&#39;coords&#39;: bounding_box_coords}

# example, label = next(datagenerator(batch_size=16))
# img = example[&#39;filename&#39;][0]
# bbox_coords = label[&#39;coords&#39;][0] 

# x1, y1, x2, y2 = map(int, bbox_coords)
# print(&#39;bbox cords&#39;,x1,y1,x2,y2)
# cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
# cv2.putText(img, &#39;&#39;, (x1,y1-10),cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 2)
# # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
# plt.imshow(img)
# plt.show()

input_ = 输入(shape=[640, 640, 3], name=&#39;filename&#39;)

x = input_
x = Conv2D(16, (3,3), 激活=&#39;relu&#39;, 填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2, 填充=&#39;same&#39;)(x)

x = Conv2D(32, (3,3), 激活=&#39;relu&#39;, 填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2, 填充=&#39;same&#39;)(x)

x = Conv2D(64, (3,3),激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(128，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(256，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(312，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(500，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(580，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(680，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Flatten()(x)
x = Dense(256，激活=&#39;relu&#39;)(x)
x = Dense(32, 激活=&#39;relu&#39;)(x)
输出坐标 = Dense(4, 名称=&#39;coords&#39;)(x)

模型 = tf.keras.models.Model(input_,output_coords)

模型摘要()

模型编译(loss={&#39;coords&#39;: &#39;mse&#39;},
优化器=tf.keras.optimizers.Adam(5e-5), 
指标={&#39;coords&#39;: &#39;accuracy&#39;})

检查点回调 = ModelCheckpoint(&#39;model_Checkpoint.h5&#39;, 监视器=&#39;val_loss&#39;, save_best_only=True, 模式=&#39;min&#39;)

模型拟合(数据生成器(df=train_csv,batch_size=6,path=train_img), 
epochs=80, steps_per_epoch=150,
validation_data=datagenerator(df=val_csv,batch_size=6,path=val_img), 
validation_steps=240, 
callbacks=[checkpoint_callback])

model.save(&#39;model2.h5&#39;)

我需要代码来在实时网络摄像头中正确检测训练过的对象，而不会出现任何边界框，并从 cnn 接收置信度值，这样我就可以设置检测的阈值]]></description>
      <guid>https://stackoverflow.com/questions/78793283/single-class-object-detection-using-cnn-getting-false-positive</guid>
      <pubDate>Thu, 25 Jul 2024 12:22:40 GMT</pubDate>
    </item>
    <item>
      <title>TF2 和 Python 中的 BERT 预处理器模型存在问题</title>
      <link>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</link>
      <description><![CDATA[我正在尝试使用 BERT 进行文本分类项目。但是我一直遇到此错误
`
ValueError Traceback（最近一次调用最后一次）
Cell In[37]，第 4 行
2 text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
3 bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
----&gt; 4 preprocessed_text = bert_preprocess(text_input)
5 bert_encoder = hub.KerasLayer(encoder_url, 
6 trainable=True, 
7 name=&#39;BERT_encoder&#39;)
8 output = bert_encoder(preprocessed_text)
ValueError：调用层“preprocessing”（类型 KerasLayer）时遇到异常。
KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。

调用层“预处理”（类型 KerasLayer）接收的参数：
• 输入=&lt;KerasTensor shape=(None,), dtype=string, sparse=None, name=text&gt;
• 训练=None

KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。


构建此模型时：

preprocess_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3&#39;
encoder_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2&#39;

# Bert 层
text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
preprocessed_text = bert_preprocess(text_input)
bert_encoder = hub.KerasLayer(encoder_url,
trainable=True, 
name=&#39;BERT_encoder&#39;)
outputs = bert_encoder(preprocessed_text)

# 神经网络层
l = tf.keras.layers.Dropout(0.1)(outputs[&#39;pooled_output&#39;])
l = tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;,name=&#39;output&#39;)(l)

# 构建最终模型
model = tf.keras.Model(inputs=[text_input],outputs=[l])

我看过无数教程，甚至使用过 tensorflow 文档中的教程，但即使我复制粘贴，它们仍然不起作用。我尝试过不同版本的 tf、tf-text 和 tf-hub。我正在为这个项目使用 tensorflow-gpu-jupyter docker 容器。
以下是我安装库的方法：
!pip install &quot;tensorflow-text&quot;
!pip install &quot;tf-models-official&quot;
!pip install &quot;tensorflow-hub&quot;

版本如下：
Tensorflow：2.16.1
tensorflow-text：2.16.1
tensorflow-hub：0.16.1
我看到的所有其他论坛都说要执行 tf.config.run_functions_eagerly(True)，但这不起作用。
任何方法都会有帮助。如果您知道如何解决，请回答。]]></description>
      <guid>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</guid>
      <pubDate>Tue, 19 Mar 2024 01:42:01 GMT</pubDate>
    </item>
    </channel>
</rss>