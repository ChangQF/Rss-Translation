<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 28 Apr 2024 01:04:25 GMT</lastBuildDate>
    <item>
      <title>机器学习：numpy，处理 NaN 值的问题</title>
      <link>https://stackoverflow.com/questions/78396645/machine-learning-numpy-issue-dealing-with-nan-values</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78396645/machine-learning-numpy-issue-dealing-with-nan-values</guid>
      <pubDate>Sat, 27 Apr 2024 23:19:52 GMT</pubDate>
    </item>
    <item>
      <title>多级数据的分类模型</title>
      <link>https://stackoverflow.com/questions/78396178/classification-models-for-multilevel-data</link>
      <description><![CDATA[我正在研究一个机器学习项目，准确地说是分类。我的数据集包含 217 个国家的社会、人口和经济指数，每个国家 60 年。目标变量是二进制的。我想训练随机森林和 xgboost 模型，我想知道：我可以用 Caret 训练这些模型吗？他们能够理解这种结构并处理多级数据吗？
如果是的话，我想用这种方式训练模型：
&lt;前&gt;&lt;代码&gt;#tree
ctrl_tree &lt;- trainControl(方法 = “cv”，数字 = 10，classProbs = TRUE，summaryFunction=twoClassSummary)
树 &lt;- train(Target~.，data=under，method =“rpart”，tuneLength = 10，metric=“ROC”，trControl = ctrl_tree)


#XGBoost
设置种子(76)
ctrl_xgb &lt;- trainControl(方法=“cv”，数字=10，搜索=“网格”，summaryFunction = TwoClassSummary，classProbs = TRUE)
param_grid_xgb &lt;- Expand.grid(nrounds=500, max_depth = c(3, 6, 9),eta = c(0.01, 0.1, 0.3),
  伽马 = c(0, 0.2, 0.4)，子样本 = c(0.8, 0.9, 1)，colsample_bytree = c(0.8, 0.9, 1)，
  min_child_weight=c(1, 5, 10))
xgb&lt;-train(Target~.,data=under,method=“xgbTree”,metric=“ROC”,tuneGrid=param_grid_xgb,
           trControl=ctrl_xgb,详细程度=0)
]]></description>
      <guid>https://stackoverflow.com/questions/78396178/classification-models-for-multilevel-data</guid>
      <pubDate>Sat, 27 Apr 2024 19:37:36 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制多类分类中所有类的 SHAP 摘要图</title>
      <link>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</link>
      <description><![CDATA[我正在使用 XGBoost 和 SHAP 来分析多类分类问题中的特征重要性，并且需要帮助一次性绘制所有类的 SHAP 摘要图。目前，我一次只能生成一个类的绘图。
SHAP 版本：0.45.0
Python版本：3.10.12

这是我的代码：
将 xgboost 导入为 xgb
导入形状
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 make_classification
从 sklearn.metrics 导入 precision_score

# 生成合成数据
X，y = make_classification（n_samples = 500，n_features = 20，n_informative = 4，n_classes = 6，random_state = 42）
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 训练用于多类分类的 XGBoost 模型
模型 = xgb.XGBClassifier(objective=“multi:softprob”, random_state=42)
model.fit(X_train, y_train)

然后我尝试绘制形状值：
# 创建一个 SHAP TreeExplainer
解释器 = shap.TreeExplainer(模型)

# 计算测试集的SHAP值
shap_values = 解释器.shap_values(X_test)

# 尝试绘制所有类的摘要
shap.summary_plot（shap_values，X_test，plot_type =“酒吧”）

我得到了这个交互图：

我在 此帖子：
shap.summary_plot(shap_values[:,:,0], X_test,plot_type=&quot;bar&quot;)

它给出了 0 类的正常条形图：

然后我可以对类 1、2、3 等执行相同的操作。
问题是，如何为所有类别制作汇总图？即，显示某个特征对每个类的贡献的单个图？]]></description>
      <guid>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</guid>
      <pubDate>Sat, 27 Apr 2024 19:02:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用机器学习实时检测Windows网络异常？</title>
      <link>https://stackoverflow.com/questions/78396046/how-to-detect-real-time-windows-network-anomaly-using-ml</link>
      <description><![CDATA[我正在开发一个项目来检测网络中的异常检测，并且我的目标是其中的 Windows 网络异常检测。但我遇到了一些问题。

如何获取异常检测的 ML 模型的数据集，即我已经搜索过，大多数数据集都是 HDFS、服务器等。Windows 网络异常数据集没有特定的数据集

如何实时获取数据以进行异常检测。就像我希望将数据从用户电脑发送到管理员电脑，然后每 20 分钟发送到 api，看看是否有任何异常。


我对这两方面感到困惑。谁能引导我走上正确的道路？]]></description>
      <guid>https://stackoverflow.com/questions/78396046/how-to-detect-real-time-windows-network-anomaly-using-ml</guid>
      <pubDate>Sat, 27 Apr 2024 18:51:52 GMT</pubDate>
    </item>
    <item>
      <title>将灰狼优化器应用于我的支持向量回归模型</title>
      <link>https://stackoverflow.com/questions/78395857/applying-a-gray-wolf-optimiser-to-my-support-vector-regression-model</link>
      <description><![CDATA[这是我正在使用的 SVR 模型。我只需要稍微提高模型的准确性，并想尝试 GWO。我需要包含什么代码？
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 StandardScaler
进口火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
从 torch.optim.lr_scheduler 导入 ReduceLROnPlateau
从 scipy 导入统计数据

# 使用 PyTorch 定义 SVR 模型
类 SVRModel(nn.Module):
    def __init__(自身):
        超级（SVRModel，自我）.__init__()
        self.fc1 = nn.Linear(in_features=7, out_features=64) # 如果需要调整输入和输出特征
        self.fc2 = nn.Linear(in_features=64, out_features=32)
        self.fc3 = nn.Linear(in_features=32, out_features=1) # 输出层

    def 前向（自身，x）：
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        返回x


# 将数据转换为 PyTorch 张量
X_train_tensor = torch.tensor(scaled_X_train, dtype=torch.float32)
Y_train_tensor = torch.tensor(Y_train.reshape(-1, 1), dtype=torch.float32)
X_test_tensor = torch.tensor(scaled_X_test, dtype=torch.float32)

# 定义超参数
C = 1
ε = 0.1
lr = 0.01
历元 = 1000

# 实例化SVR模型
模型 = SVRModel()

# 定义损失函数和优化器
标准 = nn.MSELoss()
优化器 = optim.Adam(model.parameters(), lr=lr)

# 定义学习率调度器
调度程序=ReduceLROnPlateau（优化器，模式=&#39;min&#39;，因子=0.5，耐心=5，详细=True）

# 训练循环
对于范围内的纪元（纪元）：
    模型.train()
    优化器.zero_grad()
    输出=模型（X_train_tensor）
    损失 = 标准（输出，Y_train_tensor）
    loss.backward()
    优化器.step()
    
    # 步骤调度器
    调度程序.step(损失)
    
    print(f&#39;Epoch [{epoch+1}/{epochs}], 损失: {loss.item():.4f}&#39;)

＃ 评估
模型.eval()
使用 torch.no_grad()：
    Y_pred_tensor = 模型(X_test_tensor)
    Y_pred = Y_pred_tensor.numpy().flatten()

# 计算相关性
corr = stats.pearsonr(Y_test, Y_pred)[0]
print(f&#39;相关性：{corr}&#39;)

# 创建结果数据框
result_df = pd.DataFrame({&#39;svr_predicted&#39;: Y_pred, &#39;true&#39;: Y_test})
result_df[&#39;svr_error&#39;] = abs(result_df[&#39;true&#39;] - result_df[&#39;svr_predicted&#39;])
]]></description>
      <guid>https://stackoverflow.com/questions/78395857/applying-a-gray-wolf-optimiser-to-my-support-vector-regression-model</guid>
      <pubDate>Sat, 27 Apr 2024 17:43:56 GMT</pubDate>
    </item>
    <item>
      <title>模型训练时间过长</title>
      <link>https://stackoverflow.com/questions/78395684/model-training-taking-too-long-time</link>
      <description><![CDATA[我正在尝试训练 XGBRegressor，但代码执行时间太长。我有什么错误吗？代码如下：
&lt;前&gt;&lt;代码&gt;%%时间
!pip 安装 xgboost
将 xgboost 导入为 xgb
测试 = dd.read_csv(&#39;/kaggle/input/leap-atmospheric-physicals-ai-climsim/test.csv&#39;)
#dd 指 dask.dataframe
样本 ID = 测试[&#39;样本 ID&#39;]

测试 = test.drop(&#39;sample_id&#39;, axis = 1)
X = df_train.drop(目标 + [&#39;sample_id&#39;], axis = 1)
预测 = {}
提交={}
提交[&#39;样本id&#39;] = 样本id
对于 i，枚举中的目标（目标）：
    y = df_train[目标]
    X_train，X_test，y_train，y_test = train_test_split（X，y，random_state = 42，test_size = 0.33）
    dtr = xgb.XGBRegressor(详细 = False)
    dtr.fit(X_train, y_train)
    y_hat = dtr.predict(X_test)
    提交[目标] = dtr.predict(测试)
    预测[目标] = y_hat
    print(f&#39;r2_score for {target} : {r2_score(y_hat, y_test)}&#39;)

训练数据很大，但即使记录应该有效，但我在输出中看不到任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/78395684/model-training-taking-too-long-time</guid>
      <pubDate>Sat, 27 Apr 2024 16:34:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 获取 One vs Rest SVC() 的模型参数？</title>
      <link>https://stackoverflow.com/questions/78395647/how-to-get-the-model-parameter-for-one-vs-rest-svc-using-python</link>
      <description><![CDATA[我尝试使用decision_function_shape= ovr制作onvsrest分类模型，但是当我将其更改为decision_function_shape= ovo时，它给了我与ovr相同的结果。结果我读到 svc() 正在使用 ovo 作为基础，无论它是作为 ovr 还是 ovo 启动的。那么我怎样才能改变我的代码，以便它给我一个 ovr 结果呢？
model3 = SVC(kernel = &#39;rbf&#39;, Decision_function_shape=&#39;ovr&#39;)
model3.fit(X_train, Y_train)
model3_predictions = model3.predict(X_test)

我尝试过使用 OneVsRestClassifier() 但不知道如何给出所有这些命令的输出，它总是出错并说 OneVsRestClassifier 没有这些命令。有没有办法用 OneVsRestClassifier 获取 cm、sm、sv、beta 和截距？
cm3 = fusion_matrix(Y_test, model3_predictions, labels=[-1,0,1])
sm3 = 分类报告（Y_测试，model3_预测）
support_vector3 = model3.support_
n_sv_model3 = model3.n_support_
alpha_model3 = pd.DataFrame(model3.dual_coef_)
b_model3 = pd.DataFrame(model3.intercept_)

希望有人能帮助我，先谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78395647/how-to-get-the-model-parameter-for-one-vs-rest-svc-using-python</guid>
      <pubDate>Sat, 27 Apr 2024 16:20:07 GMT</pubDate>
    </item>
    <item>
      <title>如何访问和更新LSTM层的权重？</title>
      <link>https://stackoverflow.com/questions/78394601/how-to-access-and-update-the-weight-of-the-lstm-layer</link>
      <description><![CDATA[我使用 Tensorflow 2.17 版本构建了混合 CNN 和 LSTM 模型。我想向 LSTM 添加反向传播调整来修改 LSTM 层的权重。我尝试找到一种方法来访问权重进行计算并在 LSTM 训练期间更新权重。我做了一些研究，他们手动构建 LSTM，而不是应用 TensorFlow API。我只是好奇是否有一种方法可以获取权重，然后应用导数，最后在训练时进行更新。
这是我的模型：
 model_cnn = tf.keras.models.Sequential([
        tf.keras.layers.Conv1D(input_shape = input_data_shape,
                               过滤器=256，
                               内核大小=3，
                               激活=&#39;线性&#39;，
                               步幅=1，
                               填充=“因果”），
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Conv1D（过滤器=128，
                               内核大小=3，
                               激活=&#39;线性&#39;，
                               步幅=1，
                               填充=“因果”），
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.LSTM(16,return_sequences=True),
        tf.keras.layers.LSTM(8,return_sequences=True),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1)
    ]）
    返回 model_cnn


我的期望是在混合 CNN 和 LSTM 模型的训练期间访问权重并更新权重。]]></description>
      <guid>https://stackoverflow.com/questions/78394601/how-to-access-and-update-the-weight-of-the-lstm-layer</guid>
      <pubDate>Sat, 27 Apr 2024 10:01:25 GMT</pubDate>
    </item>
    <item>
      <title>检查给定图像是否是另一个更大图像的裁剪[关闭]</title>
      <link>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</link>
      <description><![CDATA[我有一些图片。其中一些图像是裁剪版本。
就像这里是原始图片大图
和裁剪后的图像小图像。
请注意，图像的形状（分辨率）不相同。
我有几双这样的。原始图像保存在一个文件夹中，裁剪后的图像保存在另一个文件夹中。
最终我想从这些图像中找到原始图像和裁剪图像对。
所以我想迭代这两个文件夹中的图像，并检查裁剪后的图像是否是更大图像的一部分。
但是我找不到任何算法可以用不同形状（分辨率）的图像给出这样的结果。
我已经尝试过cv2.matchTemplate和skimage.metrics.structural_similarity
但它们仅适用于形状（分辨率）相似的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</guid>
      <pubDate>Fri, 26 Apr 2024 10:32:29 GMT</pubDate>
    </item>
    <item>
      <title>使用带注释的数据进行图像分类</title>
      <link>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</guid>
      <pubDate>Thu, 25 Apr 2024 18:31:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：输入 X 包含 NaN。 SVR 不接受原生编码为 NaN 的缺失值</title>
      <link>https://stackoverflow.com/questions/78378560/valueerror-input-x-contains-nan-svr-does-not-accept-missing-values-encoded-as</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78378560/valueerror-input-x-contains-nan-svr-does-not-accept-missing-values-encoded-as</guid>
      <pubDate>Wed, 24 Apr 2024 12:44:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 的神经网络 NarX 模型</title>
      <link>https://stackoverflow.com/questions/78374854/neural-network-narx-model-with-python</link>
      <description><![CDATA[我正在尝试使用 Python 编写 NarX 模型代码。当我运行以下代码时，出现以下错误。我该如何解决这个错误？这个错误是什么意思？我相信问题出在我正在使用的数据集格式上，因为它适用于另一个数据集。我添加了来自 kaagle 数据集的示例。

这也是我的代码和错误消息：
inpt = all_data[[“category”,“cuisine”,“checkout_price”,“center_type”,“num_orders”,“city_code”]]
inpt = pd.get_dummies(inpt, columns=categorical_columns)
输出 = inpt[[“订单数量”]]
inpt = inpt.drop(columns=[“num_orders”])
sc = 标准缩放器()
in1 = sc.fit_transform(inpt[0:int(len_df * .8)]) #训练并拟合训练输入数据
in2 = sc.transform(inpt[int(len_df * .8)+1:len_df-1]) #测试变换
inp = np.concatenate([in1,in2]) #添加到末尾 df1 arr df2
inpt = pd.DataFrame(inp, columns=inpt.columns)
out1 = sc.fit_transform(output[0:int(len_df * .8)]) #训练并拟合训练出数据
out2 = sc.transform(output[int(len_df * .8)+1:len_df-1]) #测试变换
out = np.concatenate([out1,out2]) #添加到末尾 df1 arr df2
输出 = pd.DataFrame(out, columns=output.columns)
all_inputs = inpt.values
all_targets = 输出.值
对于 all_targets 中的 val：
    值=[值]
类型（所有目标）

&lt;前&gt;&lt;代码&gt;input_nodes = 6
隐藏节点 = 3
输出节点 = 1

输出顺序 = 9
来自输出的传入权重 = .6
输入顺序 = 2
来自输入的传入权重 = .4
网络 = 神经网络()

net.init_layers（输入节点，[隐藏节点]，输出节点，
    NARX循环（
        输出顺序，
        来自输出的传入权重，
        输入顺序，
        来自输入的传入权重））

net.randomize_network()

net.set_halt_on_extremes(True)
net.set_random_constraint(.5)
net.set_learnrate(.1)

net.set_all_inputs(all_inputs)
net.set_all_targets(all_targets)

长度 = len(所有输入)
学习结束点 = int(长度 * .8)

net.set_learn_range(0, learn_end_point)
net.set_test_range(learn_end_point + 1, 长度 - 1)

net.layers[1].set_activation_type(&#39;sigmoid&#39;)#sigmoid,线性 TF

net.learn(epochs= 30, show_epoch_results=True, random_testing=False)

ValueError：尝试将输入值加载到非输入节点
]]></description>
      <guid>https://stackoverflow.com/questions/78374854/neural-network-narx-model-with-python</guid>
      <pubDate>Tue, 23 Apr 2024 20:31:49 GMT</pubDate>
    </item>
    <item>
      <title>ML 预测的 NER（命名实体识别）的 CUDA 问题</title>
      <link>https://stackoverflow.com/questions/77440001/cuda-issue-with-ner-named-entity-recognition-for-ml-predictions</link>
      <description><![CDATA[我正在尝试使用NamedEntityRecognition (NER)(https ://github.com/dotnet/machinelearning/issues/630）来预测大量文本中单词/短语的类别。
当前使用 3 个 Nuget 包来尝试实现此功能：
Microsoft.ML (3.0.0-preview.23511.1)
Microsoft.ML.TorchSharp (0.21.0-preview.23511.1)
Torchsharp-cpu (0.101.1)
在训练模型 [estimator.Fit(dataView)] 时，出现以下错误：
找不到字段：“TorchSharp.torch.CUDA”。
我可能在这里误解了一些东西，但我应该使用 Torchsharp-cpu 包中的 CPU 进行处理，并且我不确定 CUDA 参考来自哪里。这似乎也是一个包引用而不是一个字段？
使用 Microsoft.ML；
使用 Microsoft.ML.Data；
使用 Microsoft.ML.TorchSharp；
使用系统；
使用 System.Collections.Generic；
使用 System.Windows.Forms；

命名空间 NerTester
{
    公共部分类 Form1 ：表格
    {
        公共表格1()
        {
            初始化组件();
        }

    私有类 TestSingleSentenceData
    {
        公共字符串句子；
        公共字符串[]标签；
    }

    私人班级标签
    {
        公共字符串密钥{获取;放; }
    }

    私人无效startButton_Click（对象发送者，EventArgs e）
        {
        尝试
        {
                var context = new MLContext();
                context.FallbackToCpu = true;
                上下文.GpuDeviceId = null;

                var labels = context.Data.LoadFromEnumerable(
                新的[] {
                新标签{Key =“PERSON”; },
                新标签 { Key = &quot;CITY&quot;; },
                新标签 { Key = &quot;COUNTRY&quot;; }
                });

                var dataView = context.Data.LoadFromEnumerable(
                    新列表（新TestSingleSentenceData[] {
                    新的 TestSingleSentenceData()
                    { // 测试长度超过 512 个单词。
                        句子=“爱丽丝和鲍勃住在美国”，
                        Label = new string[]{&quot;人员&quot;, &quot;0&quot;, &quot;人员&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;国家&quot;}
                    },
                     新的 TestSingleSentenceData()
                     {
                        句子=“爱丽丝和鲍勃住在美国”，
                        Label = new string[]{&quot;人员&quot;, &quot;0&quot;, &quot;人员&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;国家&quot;}
                     },
                    }));
                var chain = new EstimatorChain();
                var estimator = chain.Append(context.Transforms.Conversion.MapValueToKey(“Label”, keyData: labels))
                   .Append(context.MulticlassClassification.Trainers.NameEntityRecognition(outputColumnName:“outputColumn”))
                   .Append(context.Transforms.Conversion.MapKeyToValue(“outputColumn”));

                var Transformer = estimator.Fit(dataView);
                Transformer.Dispose();
                
                MessageBox.Show(&quot;成功！&quot;);
            }
        catch（异常前）
            {
        MessageBox.Show($&quot;错误: {ex.Message}&quot;);
            }
    }
    }
}

应用程序在 x64 上运行，NER 的文档似乎有限。
任何帮助将不胜感激。
尝试更改我引用的 Nuget 软件包，包括使用 if libtorch 软件包。
尝试在 x86 和 x64 配置中运行应用程序。
添加了代码以尝试强制使用 CPU 而不是 GPU (CUDA)。]]></description>
      <guid>https://stackoverflow.com/questions/77440001/cuda-issue-with-ner-named-entity-recognition-for-ml-predictions</guid>
      <pubDate>Tue, 07 Nov 2023 16:42:42 GMT</pubDate>
    </item>
    <item>
      <title>我应该把reuse_actors=True放在哪里？</title>
      <link>https://stackoverflow.com/questions/76354078/where-should-i-put-reuse-actors-true</link>
      <description><![CDATA[运行以下代码后，它会显示
&lt;块引用&gt;
INFO trainable.py:172 – Trainable.setup 花费了 2940.989 秒。如果您的可训练初始化速度很慢，请考虑设置reuse_actors=True以减少actor创建开销

导入光线
ray.init(地址=“自动”, _temp_dir=&#39;/home/ray_dir&#39;)

rnd = 随机.种子(8)
grid_cv = StratifiedKFold(n_splits=3,random_state=rnd, shuffle=True)

从 xgboost.callback 导入 EarlyStopping
Early_stopping = EarlyStopping(轮数 = 50, 最大化 = True, save_best = True)
clf = xgb.XGBClassifier(
                tree_method=&#39;gpu_hist&#39;,
                最大bin=512，
                学习率 = 0.0001,
                n_估计器=1000，
                目标=&#39;二进制：逻辑&#39;，reg_alpha=0.01，
                scale_pos_weight = pos_weight, eval_metric= &#39;aucpr&#39;,
                回调=[early_stopping],
                详细程度 = 0,
                线程数 = 96
                ）


参数 = {
    &#39;eta&#39;: [0.01, 0.1, 0.3],
    &#39;min_child_weight&#39;: [1,3,8,16],
    &#39;最大深度&#39;:[25,50,100,500],
    &#39;colsample_bytree&#39;: [0.4,0.6,0.8],
    &#39;子样本&#39;: [0.4,0.6,0.8],
    &#39;伽玛&#39;：[0,0.5,2,10],
}

gs = TuneGridSearchCV（估计器 = clf、param_grid = param、cv = grid_cv、n_jobs = -1、refit = True、return_train_score = True、verbose = 3、评分 = &#39;average_ precision&#39;、use_gpu = True ）

gs.fit(X_train, y_train, eval_set= eval_set_xgboost, verbose=True)

我应该在代码中的何处添加 reuse_actors=True ？]]></description>
      <guid>https://stackoverflow.com/questions/76354078/where-should-i-put-reuse-actors-true</guid>
      <pubDate>Mon, 29 May 2023 00:25:33 GMT</pubDate>
    </item>
    <item>
      <title>平滑后的GPS数据对比</title>
      <link>https://stackoverflow.com/questions/27709732/gps-data-comparison-after-smoothing</link>
      <description><![CDATA[我正在尝试比较用于平滑 GPS 数据的多种算法。我想知道比较结果以查看哪一个提供更好的平滑效果的标准方法应该是什么。
我正在考虑一种机器学习方法。基于分类器创建汽车模型并检查哪些轨道提供更好的行为。
对于在这方面有更多经验的人来说，这是一个好方法吗？还有其他方法可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/27709732/gps-data-comparison-after-smoothing</guid>
      <pubDate>Tue, 30 Dec 2014 17:21:04 GMT</pubDate>
    </item>
    </channel>
</rss>