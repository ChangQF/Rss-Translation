<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 06 Aug 2024 15:17:12 GMT</lastBuildDate>
    <item>
      <title>关于量子机器学习的多项选择题</title>
      <link>https://stackoverflow.com/questions/78839469/multiple-choice-question-about-quantum-machine-learning</link>
      <description><![CDATA[如果您能回答以下问题，我将不胜感激。谢谢。
问题 1.什么是 𝜒2 测试？

(a) 它是一种避免过度拟合的方法
(b) 它是一种统计的特征选择方法
(c) 它是一种基于训练的特征选择方法
(d) 它是分类器准确度的统计度量
(e) 它是一种用于测量监督分类器准确度的经验方法

问题 2. 让 D = {xi} 成为对象 xi 的数据集。让 Dk = {kxi} 成为通过将对象 xi 的每个坐标乘以常数 k 获得的新数据集。以下哪项陈述不正确：

(a) 如果 D 不平衡，则 kD 也不平衡
(b) 将最近均值分类器 (NMC) 应用于 D 和 kD 将产生相同的准确度
(c) 将量子质心分类器 (QCC) 应用于 D 和 kD 将产生相同的准确度
(d) 将量子质心分类器 (QCC) 应用于 D 和 kD 不会产生相同的准确度
(e) 以上都不是

问题 3. 量子态鉴别 (QSD)：

(a) 没有经典类似物，因为它基于量子测量的概念
(b) 是经典状态鉴别的量子对应物
(c) 基于以下事实相互作用后，两个物理系统即使相距任意距离也能共享某种属性
(d) 基于区分微观和宏观现象的能力
(e) 是海森堡不确定性原理的形式表示

问题 4. 设 D = {xi} 为基数为 n 的数据集。设 DQ 为将数据集 D 的每个元素 xi 编码为密度算子 ρxi 后得到的数据集。最后，设 ⊗DQ 为将每个元素 ρxi 的张量副本复制自身（ρxi ⊗ ρxi ）后得到的数据集。设 A 为 D 的质心，B 为 DQ 的质心，C 为 ⊗DQ 的质心。我们可以说：

(a) C = A ⊗ A
(b) C = B ⊗ B
(c) B = C ⊗ C
(d) B = A ⊗ A
(e) 以上都不是

问题 5. 引入了 Pretty Good Classifier (PGM)：

(a) 作为能够在量子计算机上运行的 Helstrom Quantum Classifier 版本
(b) 作为 Helstrom Quantum Classifier 的自然多类扩展
(c) 作为 One Versus One 多类分类器的量子转换
(d) 作为次优量子启发分类器，允许多类分类
(e) 作为量子质心分类器的多类扩展
]]></description>
      <guid>https://stackoverflow.com/questions/78839469/multiple-choice-question-about-quantum-machine-learning</guid>
      <pubDate>Tue, 06 Aug 2024 14:00:41 GMT</pubDate>
    </item>
    <item>
      <title>预测期间决策树中的 KeyError</title>
      <link>https://stackoverflow.com/questions/78839421/keyerror-in-decision-tree-during-prediction</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78839421/keyerror-in-decision-tree-during-prediction</guid>
      <pubDate>Tue, 06 Aug 2024 13:50:01 GMT</pubDate>
    </item>
    <item>
      <title>Jupiter 笔记本中的 MetaTrader5</title>
      <link>https://stackoverflow.com/questions/78839326/metatrader5-in-jupiter-notebook</link>
      <description><![CDATA[我安装了 Anacona3，并使用 jupiter 笔记本进行编程。
但是我无法在 jupiter 中导入 MetaTrader5 模块。
你能帮助我吗？
我也尝试在 Windows 中安装 MetaTrader5。但它告诉我“已满足要求：metatrader5 位于 c:\users\general\appdata\local\programs\python\python312\lib\site-packages (5.0.4200)”
我需要你的帮助。
这意味着 MetaTrader5 模块之前已安装到我的电脑上。
请帮我，我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78839326/metatrader5-in-jupiter-notebook</guid>
      <pubDate>Tue, 06 Aug 2024 13:33:04 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 和 Opacus 中差分隐私的错误</title>
      <link>https://stackoverflow.com/questions/78839246/error-in-pytorch-and-opacus-for-differential-privacy</link>
      <description><![CDATA[在使用 Jupyter Notebook 测试来自 TensorFlow 网站的示例代码时，我遇到了一个错误，该代码可从以下链接获取： [LINK_1]。您可以在以下链接中找到有关该错误的问题： [LINK_2]。
因此，我决定使用 PyTorch、Opacus 和 PySyft 为相同功能编写等效实现。然而，不幸的是，我又遇到了另一个错误。
下面是实现与 TensorFlow 网站中的示例代码相同功能的代码，但使用 PyTorch 和 Opacus 和 PySyft，以及错误消息。
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from opacus import PrivacyEngine

# 定义一个简单的模型
class SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
self.fc1 = nn.Linear(32*26*26, 10)

def forward(self, x):
x = torch.relu(self.conv1(x))
x = x.view(-1, 32*26*26)
x = self.fc1(x)
return torch.log_softmax(x, dim=1)

# 数据加载器
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(&#39;.&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、优化器和损失函数
model = SimpleCNN()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.NLLLoss()

# 初始化 PrivacyEngine
privacy_engine = PrivacyEngine(
model,
batch_size=64,
sample_size=len(train_loader.dataset),
epochs=1,
max_grad_norm=1.0,
)

privacy_engine.attach(optimizer)

# 训练循环
model.train()
for epoch in range(1):
for data, target in train_loader:
optimizer.zero_grad()
output = model(data)
loss = criterion(output, target)
loss.backward()
optimizer.step()

# 打印隐私统计数据
epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(1e-5)
print(f&quot;Epsilon: {epsilon}, Delta: 1e-5&quot;)

-------------------------------------------------------------------------------
TypeError Traceback (most recent call last)
Cell In[1], line 32
29 criterion = nn.NLLLoss()
31 # 初始化PrivacyEngine
---&gt; 32 privacy_engine = PrivacyEngine(
33 model,
34 batch_size=64,
35 sample_size=len(train_loader.dataset),
36 epochs=1,
37 max_grad_norm=1.0,
38 )
40 privacy_engine.attach(optimizer)
42 # 训练循环

TypeError: PrivacyEngine.__init__() 获得了意外的关键字参数“batch_size”
]]></description>
      <guid>https://stackoverflow.com/questions/78839246/error-in-pytorch-and-opacus-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>神经网络，信号处理，窗口大小[关闭]</title>
      <link>https://stackoverflow.com/questions/78838750/neural-network-signal-processing-window-size</link>
      <description><![CDATA[我想找到合适的窗口大小来划分包含信号的 csvm 数据，以训练我的神经网络。您建议使用哪些方法来找到合适的窗口大小？
最主要的傅立叶频率
多窗口查找器
摘要统计子序列]]></description>
      <guid>https://stackoverflow.com/questions/78838750/neural-network-signal-processing-window-size</guid>
      <pubDate>Tue, 06 Aug 2024 11:24:57 GMT</pubDate>
    </item>
    <item>
      <title>如何优化机器学习模型，以最少的误报检测网络钓鱼推文？</title>
      <link>https://stackoverflow.com/questions/78838741/how-to-optimize-a-machine-learning-model-for-detecting-phishing-tweets-with-mini</link>
      <description><![CDATA[我目前正在开展一个旨在检测网络钓鱼推文的机器学习项目。虽然我的模型表现相当不错，但我面临的挑战是误报数量相对较多，这降低了系统的整体准确性和可用性。以下是我当前设置的详细信息：
数据集：平衡的网络钓鱼和非网络钓鱼推文数据集。
特征：推文文本、用户元数据、URL 特征。
尝试的算法：随机森林、SVM 和基本 LSTM 模型。
当前性能：准确率高，但由于误报，召回率低。
特征工程：添加了更多特征，如情绪分数和词嵌入。
模型调整：执行网格搜索以优化超参数。
集成方法：结合不同的算法来提高鲁棒性。]]></description>
      <guid>https://stackoverflow.com/questions/78838741/how-to-optimize-a-machine-learning-model-for-detecting-phishing-tweets-with-mini</guid>
      <pubDate>Tue, 06 Aug 2024 11:23:31 GMT</pubDate>
    </item>
    <item>
      <title>relative_attention_max_distance and relative_attention_num_buckets?</title>
      <link>https://stackoverflow.com/questions/78838655/relative-attention-max-distance-and-relative-attention-num-buckets</link>
      <description><![CDATA[在 T5 中，relative_attention_max_distance 和relative_attention_num_buckets 这两个参数代表什么？
在我的用例中，我想给出 512 个条件标记（编码器）并生成 384 个标记（解码器）。
这个用例的最佳参数应该是什么。我也想要长距离依赖。在理想情况下，任务需要绝对位置嵌入。]]></description>
      <guid>https://stackoverflow.com/questions/78838655/relative-attention-max-distance-and-relative-attention-num-buckets</guid>
      <pubDate>Tue, 06 Aug 2024 11:02:17 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 错误 - 需要使用适当的编译器标志进行重建</title>
      <link>https://stackoverflow.com/questions/78838145/tensorflow-error-rebuild-needed-with-appropriate-compiler-flags</link>
      <description><![CDATA[2024-08-06 14:18:52.654763: 
I tensorflow/core/platform/cpu_feature_guard.cc:210]。此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。

要启用以下指令：AVX2 AVX_VNNI FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。

每当我尝试运行任何类型的面部识别代码时，我都会收到这种错误。即使它与面部识别无关，而只是常规的张量流，我也会收到此错误。有人可以帮忙吗？但由于这个错误，我被困在了起跑线上。
from deepface import DeepFace
import os

os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39;
img1 = &#39;reference.jpg&#39;
img2 = &#39;reference1.jpg&#39;

model_name = &#39;Facenet&#39;

result = DeepFace.verify(
img1_path=img1,
img2_path=img2,
model_name=model_name
)
]]></description>
      <guid>https://stackoverflow.com/questions/78838145/tensorflow-error-rebuild-needed-with-appropriate-compiler-flags</guid>
      <pubDate>Tue, 06 Aug 2024 08:58:22 GMT</pubDate>
    </item>
    <item>
      <title>什么是 tf.data.Dataset 以及为什么我的 Epoch 没有运行？</title>
      <link>https://stackoverflow.com/questions/78837808/what-tf-data-dataset-and-why-is-my-epoch-not-running</link>
      <description><![CDATA[history = Model_Enhancer.fit(x=[X_,X_wb,X_gc,X_ce],y=X_gt,batch_size=16,epochs=400,validation_split=0.3,shuffle=True)

我在使用这段代码时遇到了问题。
当我运行这段代码时，出现了以下错误：
RuntimeError Traceback (most recent call last)
&lt;ipython-input-19-46332b46168a&gt; in &lt;cell line: 1&gt;()
----&gt; 1 history = Model_Enhancer.fit(x=[X_,X_wb,X_gc,X_ce],y=X_gt,batch_size=16,epochs=400,validation_split=0.3,shuffle=True)

1 帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py in __iter__(self)
501 return iterator_ops.OwnedIterator(self)
502 else:
--&gt; 503 引发 RuntimeError(“`tf.data.Dataset` 仅支持 Python 样式”
504 “在 Eager 模式或 tf.function 内迭代。”)
505 

RuntimeError：`tf.data.Dataset` 仅支持在 Eager 模式或 tf.function 内迭代 Python 样式。

我期待 Epoch 运行。为什么 Epoch 没有运行。]]></description>
      <guid>https://stackoverflow.com/questions/78837808/what-tf-data-dataset-and-why-is-my-epoch-not-running</guid>
      <pubDate>Tue, 06 Aug 2024 07:42:40 GMT</pubDate>
    </item>
    <item>
      <title>何时使用复合损失深度学习（图像分割）？</title>
      <link>https://stackoverflow.com/questions/78837046/when-to-use-composite-losses-deep-learning-image-segmentation</link>
      <description><![CDATA[我想知道在训练图像分割算法时，复合损失（例如 Dice + Focal Loss、Dice + Cross-Entropy Loss 或 Generalized Dice + Focal Loss）何时优于使用常规 Dice/CE Loss。
在什么情况下它们可以帮助算法更好地收敛？这是一个比较普遍的问题，但是否存在一个粗略的策略来确定某些算法的良好复合损失？]]></description>
      <guid>https://stackoverflow.com/questions/78837046/when-to-use-composite-losses-deep-learning-image-segmentation</guid>
      <pubDate>Tue, 06 Aug 2024 02:43:38 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 中的差分隐私错误</title>
      <link>https://stackoverflow.com/questions/78836989/error-in-tensorflow-for-differential-privacy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78836989/error-in-tensorflow-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 02:18:31 GMT</pubDate>
    </item>
    <item>
      <title>点数据（x，y 坐标）数组在 python 中转换为图像？</title>
      <link>https://stackoverflow.com/questions/78836964/point-data-x-y-coordinate-array-convert-to-image-in-python</link>
      <description><![CDATA[我从用户处收到点数据（x，y）。用户在屏幕上绘制一些数字。
我收到点数据...我需要将这些点数据转换为图像数据。
（用于识别数字）
请帮帮我...]]></description>
      <guid>https://stackoverflow.com/questions/78836964/point-data-x-y-coordinate-array-convert-to-image-in-python</guid>
      <pubDate>Tue, 06 Aug 2024 02:01:38 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 haarcascades 分类器进行车牌号检测？[关闭]</title>
      <link>https://stackoverflow.com/questions/78836768/how-to-train-haarcascades-classifier-for-plate-number-detection</link>
      <description><![CDATA[我正在菲律宾使用 python、OpenCV 和 haarcascade 分类器进行车牌号检测。我正在使用 haarcascade_russian_plate_number.xml，但它给出了更多的误报。检测的示例文件为 mp4 格式。
我尝试使用 indian_license_plate.xml，但它给出了更多的误报，并且是在图像的同一位置进行检测。]]></description>
      <guid>https://stackoverflow.com/questions/78836768/how-to-train-haarcascades-classifier-for-plate-number-detection</guid>
      <pubDate>Mon, 05 Aug 2024 23:47:54 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型聚合器 TensorFlow Federated</title>
      <link>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Federated，我想为我的训练程序编写一个自定义模型聚合器，这样客户端大小与某个预定义值的距离就用于加权每个客户端的更新（优先考虑某些客户端的更新而不是其他客户端的更新）。
我想继续使用我在之前的模拟中使用的简单 FedAvg 算法，以便能够比较结果：
trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn= tff_model,
client_optimizer_fn=client_optimizer,
server_optimizer_fn=server_optimizer
)

我知道 tff.learning.algorithms.build_weighted_fed_avg() 接受 model_aggregator 作为参数，但我不知道如何创建一个计算此类权重的聚合器。
有没有简单的方法来定义它？]]></description>
      <guid>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</guid>
      <pubDate>Mon, 05 Aug 2024 16:06:48 GMT</pubDate>
    </item>
    <item>
      <title>超参数调优与分类算法对比</title>
      <link>https://stackoverflow.com/questions/65516888/hyper-prparameter-tuning-and-classification-algorithm-comparation</link>
      <description><![CDATA[我对分类算法比较有疑问。
我正在做一个关于数据集的超参数调整和分类模型比较的项目。
目标是找出最适合我的数据集的具有最佳超参数的最佳拟合模型。
例如：我有 2 个分类模型（SVM 和随机森林），我的数据集有 1000 行和 10 列（9 列是特征），最后一列是标签。
首先，我将数据集分成 2 个部分（80-10），分别用于训练（800 行）和测试（200 行）。之后，我使用 CV = 10 的网格搜索来调整这两个模型（SVM 和随机森林）在训练集上的超参数。当确定了每个模型的超参数后，我会使用这两个模型的超参数再次测试训练集和测试集上的 Accuracy_score，以找出哪个模型最适合我的数据（条件：训练集上的 Accuracy_score &lt; 测试集上的 Accuracy_score（未过度拟合）并且哪个模型在测试集上的 Accuracy_score 更高，则该模型为最佳模型）。
但是，SVM 显示训练集的 Accuracy_score 为 100，测试集的 Accuracy_score 为 83.56，这意味着调整超参数的 SVM 过度拟合。另一方面，随机森林显示训练集的 Accuracy_score 为 72.36，测试集的 Accuracy_score 为 81.23。很明显，SVM 的测试集准确度得分高于随机森林的测试集准确度得分，但 SVM 过度拟合。
我有一些问题：
_ 当我像上面一样对训练和测试集的准确度得分进行比较而不是使用交叉验证时，我的方法是否正确？（如果使用交叉验证，该怎么做？
_ 很明显，上面的 SVM 过度拟合，但其测试集准确度得分高于随机森林的测试集准确度得分，在这种情况下我能得出 SVM 是最佳模型的结论吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/65516888/hyper-prparameter-tuning-and-classification-algorithm-comparation</guid>
      <pubDate>Thu, 31 Dec 2020 05:11:06 GMT</pubDate>
    </item>
    </channel>
</rss>