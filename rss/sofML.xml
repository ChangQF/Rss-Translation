<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 23 May 2024 18:18:37 GMT</lastBuildDate>
    <item>
      <title>Logistic reg 预测同一类</title>
      <link>https://stackoverflow.com/questions/78524770/logistic-reg-predicting-the-same-class</link>
      <description><![CDATA[所以我从头开始创建了一个逻辑回归模型，它工作得很好，但问题是它每次都会预测同一个类，有时它会预测其他类，但这种情况非常罕见
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt


逻辑回归类：
    def __init__(self, *, lr=0.01, n_epochs=1000, verbose=False):
        self.lr = lr
        self.n_epochs = n_epochs
        self.verbose = 详细

    def 初始化（自身，形状，n_class）：
        _, 列 = 形状
        w = np.random.randn(n_class, 列数 + 1) * 0.01
        返回w

    def _inverse_mapper（自身，y_mapped）：
        inverse_mapper = {v: k for k, v in self.mapper.items()}
        返回 np.vectorize(inverse_mapper.get)(y_mapped)

    def _mapper（自身，y）：
        矢量化映射 = np.vectorize(self.mapper.get)
        返回向量化映射（y）

    def _get_mapper（自身，y）：
        self.unique = np.unique(y)
        self._range = np.arange(len(self.unique))
        返回 dict(zip(self.unique, self._range))

    def _one_hot(自我, y):
        n_rows = y.shape[0]
        n_class = len(np.unique(y))
        one_hot = np.zeros((n_rows, n_class))
        one_hot[np.arange(len(y)), y.ravel()] = 1
        返回 one_hot

    def _vec_o​​h(自身，y)：
        self.mapper = self._get_mapper(y)
        y_mapped = self._mapper(y)
        y_oh = self._one_hot(y_mapped)
        返回 y_oh, y_mapped

    def softmax(自身, X):
        z = np.dot(X, self.w.T)
        pk = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)
        返回PK

    def Predict_proba(自身, X):
        X_added_ones = self.addOnes(X)
        返回 self.softmax(X_added_ones)

    def addOnes(self, X):
        行，_ = X.shape
        个= np.ones((行, 1))
        返回 np.hstack((ones, X))

    def _cost(自身, y, preds):
        返回-np.mean(np.sum(y * np.log(preds + 1e-9), axis=1))

    def _init_data(自身, X, y):
        n_class = len(np.unique(y))
        self.w = self.initialize(X.shape, n_class)
        y_oh, _ = self._vec_o​​h(y)
        返回 y_oh

    def grad_desc(自身, X, y):
        m = X.shape[0]
        y_oh = self._init_data(X, y)

        对于范围内的纪元（self.n_epochs）：
            X_added_ones = self.addOnes(X)
            pk = self.softmax(X_added_ones)
            误差 = pk - y_oh
            w_gradient = np.dot(X_added_ones.T, 错误) / m
            self.w -= self.lr * w_gradient

            如果 self.verbose 和 epoch % 100 == 0:
                损失 = self._cost(y_oh, pk)
                print(f&quot;纪元 {epoch}: 损失 = {损失}&quot;)

    def fit(自身, X, y):
        X = np.array(X)
        y = np.array(y)
        self.grad_desc(X, y)

    def 预测（自身，X）：
        概率 = self.predict_proba(X)
        Predictions_encoded = np.argmax（概率，轴= 1）
        预测 = self._inverse_mapper(predictions_encoded)
        返回预测

我尝试更改公式，但这似乎不起作用我尝试更改渐变似乎根本不起作用我根本不知道问题是什么]]></description>
      <guid>https://stackoverflow.com/questions/78524770/logistic-reg-predicting-the-same-class</guid>
      <pubDate>Thu, 23 May 2024 17:44:42 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[当我尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我认为问题不在于我的代码，而在于库冲突，但我不确定。
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler #actually scikit-learn
from imblearn.over_sampling import RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
X = dataframe[dataframe.columns[:-1]].values
Y = dataframe[dataframe.columns[-1]].values

scaler = StandardScaler() 
X = scaler.fit_transform(X) 

if oversample:
ros = RandomOverSampler()
X, Y = ros.fit_resample(X,Y) 
data = np.hstack((X, np.reshape(Y, (-1, 1))))
返回数据，X，Y

print(len(train[train[&quot;class&quot;]==1]))
print(len(train[train[&quot;class&quot;]==0]))

train, X_train, Y_train = scale_dataset(train, True)

我尝试完全导入 sklearn，卸载并重新安装 scipi 和 sklearn（作为 scikit-learn），安装 Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>文本分类最新模型</title>
      <link>https://stackoverflow.com/questions/78524470/text-classification-latest-models</link>
      <description><![CDATA[我正在寻找构建一个文本多标签分类器，并且需要一些有关最佳模型的帮助或建议。您能为这项任务推荐一些有效的模型吗？我对大型语言模型 (LLM) 和传统模型都感兴趣。
预先感谢您的建议！]]></description>
      <guid>https://stackoverflow.com/questions/78524470/text-classification-latest-models</guid>
      <pubDate>Thu, 23 May 2024 16:28:40 GMT</pubDate>
    </item>
    <item>
      <title>在 VS Code 上使用计算机视觉 + yolov8 应用程序进行实时网络摄像头数据分类</title>
      <link>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</guid>
      <pubDate>Thu, 23 May 2024 15:57:14 GMT</pubDate>
    </item>
    <item>
      <title>图像分类中的融合特征向量？</title>
      <link>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</link>
      <description><![CDATA[目前，我正在处理一个关于面部情感分类的图像分类问题。我使用 2 种提取方法：HOG 和面部地标。我的想法是使用 HOG 来查找图像的梯度大小和方向，并使用面部标志来查找面部关键点。我想我可以融合两种方法来制作更好的功能。但新特征比 HOG 差，比面部特征点好（评估相同模型）。我有一个问题：

我想知道如何融合这两种方法，其中 HOG 归一化之前和面部标志返回 68x2 对点整数。

如果可以，我应该在熔断之前进行正常化或其他操作吗？我可以尝试哪种方法来融合它们（连接、加法、乘法……）？

有没有办法衡量我的方法会更好或评估它？我也尝试融合 HOG 和 SIFT（视觉词袋）。


我曾尝试融合 HOG 和 Facial Landmark 功能，但在同一模型中，它比 HOG 更差，但比 Facial Landmark 更好。我还融合了（SIFT）视觉词袋和 HOG，但它仍然比 HOG 差，但比视觉词袋好。这是我使用的代码：
x_hogp_train = pca.transform(x_hog_train)[:,:382]
x_hogp_valid = pca.transform(x_hog_valid)[:,:382]
x_hogp_test = pca.transform(x_hog_test)[:,:382]

scaler = StandardScaler() # 缩放 bovw 特征
缩放器.fit(x_bovw_train)
x_scale_bovw_train = 缩放器.transform(x_bovw_train)
x_scale_bovw_valid = 缩放器.transform(x_bovw_valid)
x_scale_bovw_test = 缩放器.transform(x_bovw_test)

# 使用 concat 融合它们
x_fused_train = np.concatenate((x_hogp_train, x_scale_bovw_train), axis=1)
x_fused_valid = np.concatenate((x_hogp_valid, x_scale_bovw_valid), axis=1)
x_fused_test = np.concatenate((x_hogp_test, x_scale_bovw_test), axis=1)

]]></description>
      <guid>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</guid>
      <pubDate>Thu, 23 May 2024 14:35:09 GMT</pubDate>
    </item>
    <item>
      <title>我使用 K-means 对图像中的颜色进行聚类。当使用 matplotlib 中的 imshow() 进行重建时，绘图为空白</title>
      <link>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</link>
      <description><![CDATA[我在kaggle上运行以下代码
img = imread(“/kaggle/input/image-segmentation/ladybug.png”)
x = img.reshape(-1, 3)
kmeans = KMeans(n_clusters=8, random_state=42).fit(x)
segmented_img = kmeans.cluster_centers_[kmeans.labels_]
Segmented_img = Segmented_img.reshape(img.shape)
图 = plt.figure()
ax = Fig.add_subplot(1,2,1)
斧头.imshow(img)

ax = Fig.add_subplot(1,2,2)
ax.imshow(segmented_img)

我得到这个输出。请告诉我为什么我没有获得分割图像。
]]></description>
      <guid>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</guid>
      <pubDate>Thu, 23 May 2024 11:19:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从电脑屏幕上的 (x,y) 像素点确定 3D 凝视矢量值？</title>
      <link>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</link>
      <description><![CDATA[我有一个拍摄对象距离屏幕 X 厘米。屏幕尺寸 (S1xS2) 分辨率也是已知的。摄像头位于屏幕顶部中间。屏幕上显示随机点。我也有面部标志检测。
问题是，如何获得人注视位置的 3D 凝视向量？]]></description>
      <guid>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</guid>
      <pubDate>Thu, 23 May 2024 10:37:40 GMT</pubDate>
    </item>
    <item>
      <title>何时在卷积神经网络中使用/不使用偏差项</title>
      <link>https://stackoverflow.com/questions/78522177/when-to-use-not-use-bias-term-in-convolutional-neural-networks</link>
      <description><![CDATA[这个问题最近突然出现在我的脑海里。我向 GPT 和其他几个模型询问了卷积网络中偏差项的重要性。他们所有人的反应都不同，而且非常肤浅。我偶尔也会看到 Kaggle 笔记本，人们在训练模型时在 conv/dense 层中设置“bias=False”或“bias=True”。您能否分享关于为什么偏差术语可能很重要以及何时考虑启用/禁用它的见解？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78522177/when-to-use-not-use-bias-term-in-convolutional-neural-networks</guid>
      <pubDate>Thu, 23 May 2024 09:34:17 GMT</pubDate>
    </item>
    <item>
      <title>AIF360 我是否使用 BinaryLabel 或 StandardDataset 作为自定义数据集/数据框？</title>
      <link>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</link>
      <description><![CDATA[我有一个自定义数据集，已将其加载到数据框中，并且希望使用 AIF360 进行公平的机器学习。
我总是使用 pandas 的 get_dummies() 方法对分类特征进行 one-hot 编码。
现在，我是否必须将 BinaryLabelDataset 类用于 one-hot 编码数据，而 StandardDataset 类也用于自定义数据集，但尚未进行 one-hot 编码？
基本上，我不确定在哪种情况下使用哪个类（对于单热编码的 dataframe = BinaryLabelDataset？ - 对于没有 transformations = StandardDataset 的数据帧？）&lt; /p&gt;
我阅读了 AIF360 的文档和 API 参考指南。但是，我不太清楚应该使用哪一个。
我知道 BinaryLabelDataset 类是基于 StandardDataset 类构建的。
另外，StandardDataset类还可以做一些数据转换。
另外，我还可以使用与 sklearn 兼容的 API。]]></description>
      <guid>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</guid>
      <pubDate>Thu, 23 May 2024 09:22:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 if 条件将两个 scikit-learn 子模型组合成一个整体并将其保存到 pickle 文件中？</title>
      <link>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</link>
      <description><![CDATA[我使用 IF 条件训练了两个 scikit-learn 模型（根据 X1 功能定义的标准生成了两个训练集）。如何将这个 if 条件与这两个经过训练的模型集成到一个单个整体模型中并将其保存到 pickle 文件中？]]></description>
      <guid>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</guid>
      <pubDate>Thu, 23 May 2024 02:12:38 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型的小批量实现的奇怪绘图模式</title>
      <link>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</guid>
      <pubDate>Sun, 19 May 2024 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>cnn 模型的纪元大小 [关闭]</title>
      <link>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</link>
      <description><![CDATA[如果我有一个包含大约 200 个样本的数据集并且我正在应用 CNN，那么我的纪元大小应该是多少？
我尝试将纪元大小设置为 50，但结果非常差。
但是当我设置 epoch = 5 时，它会给出明显更好的结果，但我不确定正确的 epoch 大小应该是多少。]]></description>
      <guid>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</guid>
      <pubDate>Fri, 17 May 2024 09:52:20 GMT</pubDate>
    </item>
    <item>
      <title>我无法从“typing_extensions”导入名称“TypeAliasType”</title>
      <link>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</link>
      <description><![CDATA[我是 Python 新手，发现了以下类似错误。我非常感谢您的评论。谢谢
我尝试将 Gradio 库导入为 gr
我已经尝试了一些现有的建议，但结果都是徒劳的。我不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</guid>
      <pubDate>Thu, 09 Nov 2023 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未知层：“CustomScaleLayer”。请确保您使用的是`keras.utils.custom_object_scope`</title>
      <link>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</guid>
      <pubDate>Fri, 16 Jun 2023 09:13:29 GMT</pubDate>
    </item>
    <item>
      <title>SVC 分类器花费太多时间进行训练</title>
      <link>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</link>
      <description><![CDATA[我正在使用带有线性内核的 SVC 分类器来训练我的模型。
列车数据：42000条记录
 模型 = SVC(概率=True)
    model.fit(self.features_train, self.labels_train)
    y_pred = model.predict(self.features_test)
    train_accuracy = model.score(self.features_train,self.labels_train)
    test_accuracy = model.score(self.features_test, self.labels_test)

训练我的模型需要两个多小时。
难道我做错了什么？ 
另外，可以采取哪些措施来缩短时间
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</guid>
      <pubDate>Thu, 27 Dec 2018 05:43:30 GMT</pubDate>
    </item>
    </channel>
</rss>