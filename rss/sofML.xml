<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Apr 2024 03:14:40 GMT</lastBuildDate>
    <item>
      <title>使用 2 层神经网络进行 sin 近似</title>
      <link>https://stackoverflow.com/questions/78307766/sin-approximation-with-a-2-layer-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78307766/sin-approximation-with-a-2-layer-neural-network</guid>
      <pubDate>Thu, 11 Apr 2024 00:58:29 GMT</pubDate>
    </item>
    <item>
      <title>尝试寻找相关数据模式</title>
      <link>https://stackoverflow.com/questions/78307684/attempting-to-find-relative-data-patterns</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78307684/attempting-to-find-relative-data-patterns</guid>
      <pubDate>Thu, 11 Apr 2024 00:21:56 GMT</pubDate>
    </item>
    <item>
      <title>将手写数学方程解析为字符串/数值</title>
      <link>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</link>
      <description><![CDATA[我有这个图像，我需要用Python来解决。它非常像手写数字，我需要将图像解析为字符串，甚至更好，对其进行评估并获取该表达式或与此类似的表达式的结果。
有没有办法至少半可靠地做到这一点？阅读它需要使用大量手写字符的机器学习，但我无法理解它是如何工作的。我也希望它能够相当快地解析图像，但我不介意用数据训练我的模型，无论它在实际识别数字之前需要训练多长时间。
感谢任何帮助，提前致谢！
我尝试过超正方体，但它只能从该图像中检测到 4 和 5，因为我认为这些图像是不整洁和草率的，即使在将其转换为黑白并增强对比度等之后也是如此。]]></description>
      <guid>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</guid>
      <pubDate>Wed, 10 Apr 2024 20:44:13 GMT</pubDate>
    </item>
    <item>
      <title>识别随机森林中错误分类的样本</title>
      <link>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</link>
      <description><![CDATA[我正在 RStudio 中执行随机森林分析，我可以使用下面的代码提取混淆矩阵。我可以看到有多少样本被错误分类，但是我可以使用什么代码来识别哪些特定样本被错误分类？
库（随机森林）
库（rfPermute）

rfmetrics &lt;- randomForest(x, y, ntree=ntree,重要性=T)
打印（rfmetrics）

称呼：
 randomForest(x = x, y = y, ntree = ntree, 重要性 = T)
               随机森林类型：分类
                     树木数量：1999
每次分割尝试的变量数量：25

        OOB 估计错误率：56.88%
混淆矩阵：
  1 2 3 4 类.错误
1 8 7 7 4 0.6923077
2 4 19 2 4 0.3448276
3 3 3 15 6 0.4444444
4 3 9 10 5 0.8148148
]]></description>
      <guid>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</guid>
      <pubDate>Wed, 10 Apr 2024 19:44:24 GMT</pubDate>
    </item>
    <item>
      <title>生成每个 ID 具有多个记录的合成数据</title>
      <link>https://stackoverflow.com/questions/78306740/generating-synthetic-data-with-multiple-records-per-id</link>
      <description><![CDATA[我想生成一个合成数据集，其中每个 ID 有多个记录，并且每个 ID 的记录之间保持自我一致性。
例如，想象一个数据集，其中 ID 是一家杂货店，每条记录是该商店在给定日期内各种商品的销售额。换句话说，多个时间序列。您可以想象，虽然所有商店都有全球趋势，但也存在商店级别的趋势，而现实的数据集不仅必须保留全球趋势，还必须保留商店级别的趋势。也许 A 店在周末出售的薯条较多，而 B 店周末出售的薯条较少，但饼干较多。
对虚假记录 IID 进行采样的合成数据模型只能保留全球销售趋势（“周五薯条的销量通常比饼干多”）。复杂性又提高了一步的模型，例如 LSTM，可以保留在所有商店中表达的时间趋势（“如果饼干在时间 t-1 的销量少于薯片，那么它们在时间 t 的销量通常会更高”）。但是，我如何制作一个模型，同时允许这些趋势因商店而异（“在某些商店，薯片在周六的销量通常超过饼干，但在其他商店却恰恰相反”）？
我的一个想法是使用领域知识/集群将商店分配给 N 个“配置文件”之一，然后使用该配置文件作为功能。该模型自然能够捕获依赖性。也就是说，这种方法需要手动定义 N 并创建一组有限的配置文件。我正在寻找限制较少的东西，并且可以检测到比我手动检测到的更微妙的配置文件（如果存在）。
希望我已经很好地解释了我的问题 - 请随时要求澄清。相关论文的链接将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78306740/generating-synthetic-data-with-multiple-records-per-id</guid>
      <pubDate>Wed, 10 Apr 2024 19:39:08 GMT</pubDate>
    </item>
    <item>
      <title>克服时间序列分类中的重叠数据点：寻找有效的模型</title>
      <link>https://stackoverflow.com/questions/78306506/overcoming-overlapping-data-points-in-time-series-classification-searching-for</link>
      <description><![CDATA[我目前正在研究时间序列分类问题，并遇到了挑战。在我的时间序列数据中，某些类之间的数据点相同且重叠，使得分类任务变得困难。我尝试过使用各种分类器，例如 LSTM、CNN、SVM 和 FNN，但它们的准确率都很差，约为 60-64%。不幸的是，我无法添加新功能，因为我已经使用了所有可用的功能进行分类。此外，我无法包含更多训练数据，因为它只会添加更多相似的重叠数据点。有没有任何模型/分类器可以帮助解决这个问题？
分类准确率高。]]></description>
      <guid>https://stackoverflow.com/questions/78306506/overcoming-overlapping-data-points-in-time-series-classification-searching-for</guid>
      <pubDate>Wed, 10 Apr 2024 18:43:03 GMT</pubDate>
    </item>
    <item>
      <title>需要为我的应用程序在日志中记录机器学习模型及其版本的输入</title>
      <link>https://stackoverflow.com/questions/78306322/need-inputs-on-logging-machine-learning-models-and-their-versions-in-logs-for-my</link>
      <description><![CDATA[所以我有一个网络应用程序，它根据用户输入的主题和问题推荐电影，它还使用 NLP 和 ML 模型，如命名实体识别 (NER) 模型来提取关键字和 BERT 模型。我目前只是将登录数据记录到 sql 中的数据库表之一中。现在我还想将 ML 模型及其版本记录到表中。
我脑子里有几个捕获点，即什么时候捕获这些数据。第一个是用户登录时，第二个是用户将电影添加到列表时。我考虑实现这一点，以便提高 ML 模型的准确性和跟踪性能。如果提出任何不相关的建议，它也将帮助我发现任何类型的差异。
计划只是记录提出建议时触发的模型及其版本。基本上我还会显示与推荐电影匹配的关键字，因此也可能显示这些关键字来自哪些型号以及版本
我只是对如何实现这个感到困惑，并且想要一些意见，如果有人以前做过类似的事情。会有帮助的。]]></description>
      <guid>https://stackoverflow.com/questions/78306322/need-inputs-on-logging-machine-learning-models-and-their-versions-in-logs-for-my</guid>
      <pubDate>Wed, 10 Apr 2024 18:05:25 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类 - 平面二元分类器与分层二元分类器[关闭]</title>
      <link>https://stackoverflow.com/questions/78305775/multilabel-classification-flat-binary-classifiers-vs-hierarchical-binary-class</link>
      <description><![CDATA[正在研究多标签分类，以解决用主题和国家/地区标记新闻文章的问题，其中标签遵循​​语法 &lt;主题&gt;-&lt;国家/地区&gt;，并且希望权衡多个二元分类器选项（平面与分层）分类）。
方法 1（平面分类）为每个标签构建 1 个模型。该模型学习 1 个标签内的依赖关系（即主题和国家/地区之间），但不学习标签之间的依赖关系。
方法 2（层次分类）构建主题模型（父模型）和随后的国家模型（子模型）。这种方法的好处是它考虑了分层信息，因此保留了标签之间的依赖性，但代价是父级传播到子级的错误，以及测量分层分类器性能的复杂性。它还假设主题的概念对于各个国家/地区保持相同。
想知道还有哪些其他因素会导致人们选择一种方法而不是另一种方法，为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78305775/multilabel-classification-flat-binary-classifiers-vs-hierarchical-binary-class</guid>
      <pubDate>Wed, 10 Apr 2024 16:18:31 GMT</pubDate>
    </item>
    <item>
      <title>在 MacOS 上编译 llama-cpp-python 时找不到 ggml-common.h</title>
      <link>https://stackoverflow.com/questions/78305294/ggml-common-h-not-found-compiling-llama-cpp-python-on-macos</link>
      <description><![CDATA[我正在学习 LLM 和 RAG。
目前，我在尝试使用带有 M2 的 MAC PRO 实例化 llm 时遇到问题。
# 回调支持 token-wise 流式传输
callback_manager2 = CallbackManager([StreamingStdOutCallbackHandler()])
 
n_gpu_layers = 1 # 根据您的模型和 GPU VRAM 池更改此值。
n_batch = 1 # 应介于 1 和 n_ctx 之间，考虑 GPU 中的 VRAM 量。

llmGPU = LlamaCpp(
 model_path=“路径/llama-2-13b-chat.Q2_K.gguf”,
 输入={“温度”：0.75，“max_length”：2000，“top_p”：1}，
 n_gpu_layers=n_gpu_layers,
 n_batch=n_batch,
 回调管理器=回调管理器2,
 详细=真，
）

当我尝试这样做时，它会出现此错误：
“program_source：3：10：致命错误：找不到“ggml-common.h”文件#include“ggml-common.h” ^~~~~~~~~~~~~~~” UserInfo={NSLocalizedDescription=program_source:3:10: 致命错误：找不到“ggml-common.h”文件 #include “ggml-common.h” ^~~~~~~~~~~~~~~ } llama_new_context_with_model：无法初始化 Metal 后端

我在互联网上发现使用此命令安装 llama 可以解决这个问题：
!CMAKE_ARGS=“-DLLAMA_METAL_EMBED_LIBRARY=ON -DLLAMA_METAL=on” pip install -U llama-cpp-python --no-cache-dir

但这不适合我。 （我是在 jupyter 笔记本上完成所有这些操作。
请注意，如果我避免使用 GPU 层和批处理，它会起作用，但需要 3 分钟才能解决 3+3，所以太慢了。我尝试过使用其他 LLama 版本，但仍然存在同样的问题。
我将不胜感激一些帮助！谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78305294/ggml-common-h-not-found-compiling-llama-cpp-python-on-macos</guid>
      <pubDate>Wed, 10 Apr 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>尽管已安装，脚本仍不断请求安装face_recognition_models</title>
      <link>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</link>
      <description><![CDATA[我在使用 Face_recognition 库的 Python 脚本中遇到问题。尽管已经成功安装了face_recognition_models包，但当我尝试执行脚本时，脚本反复提示我安装它。这是我收到的命令和输出：

代码：
导入操作系统
导入人脸识别
导入人脸识别模型
导入CV2


image_path = “tes.png”;

# 检查图片文件是否存在
如果不是 os.path.isfile(image_path):
    print(&quot;图像文件不存在:&quot;, image_path)
    出口（）

# 获取网络摄像头 #0 的引用（默认摄像头）
video_capture = cv2.VideoCapture(0)

# 加载您的图像并学习如何识别它。
图像=face_recognition.load_image_file(image_path)
face_encoding =face_recognition.face_encodings(图像)[0]

# 创建已知面部编码及其名称的数组
已知人脸编码 = [
    面部编码，
]
已知面孔名称 = [
        “瓦利德”
]

而真实：
        # 抓取单帧视频
        ret, 帧 = video_capture.read()

        # 将图像从 BGR 颜色（OpenCV 使用）转换为 RGB 颜色（face_recognition 使用）
        rgb_frame = 帧[:, :, ::-1]

        # 查找当前帧视频中的所有人脸
        面部位置 = 面部识别.面部位置(rgb_frame)
        face_encodings =face_recognition.face_encodings（rgb_frame，face_locations）

        # 循环遍历该视频帧中的每张脸
        对于（上，右，下，左），zip中的face_encoding（face_locations，face_encodings）：
            # 查看该面孔是否与已知面孔匹配
            匹配=face_recognition.compare_faces（known_face_encodings，face_encoding）

            名称=“未知”

            如果匹配中为真：
                first_match_index = matches.index(True)
                名称 =known_face_names[first_match_index]

            # 在脸部周围画一个框
            cv2.rectangle(frame, (左, 上), (右, 下), (0, 0, 255), 2)

            # 在脸部下方画一个带有名字的标签
            cv2.rectangle(frame, (左, 下 - 35), (右, 下), (0, 0, 255), cv2.FILLED)
            字体= cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(框架, 名称, (左 + 6, 下 - 6), 字体, 1.0, (255, 255, 255), 1)

        # 显示结果图像
        cv2.imshow(&#39;视频&#39;, 帧)

        # 按键盘上的“q”退出！
        如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
            休息

# 释放网络摄像头的句柄
video_capture.release()
cv2.destroyAllWindows()


我尝试利用face_recognition 库执行Python 脚本。尽管成功安装了face_recognition_models包，但该脚本在执行时不断提示我安装它。我希望脚本能够识别已安装的包并执行而不会出现错误，但它继续请求安装face_recognition_models。]]></description>
      <guid>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</guid>
      <pubDate>Tue, 09 Apr 2024 19:29:09 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“deepface.commons”导入名称“距离”（/opt/anaconda3/envs/LIP/lib/python3.9/site-packages/deepface/commons/__init__.py）</title>
      <link>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</link>
      <description><![CDATA[无法在Python中导入deepface
我目前在 macbook 上使用 Pycharm。
虚拟环境已激活，但仍出现以下错误。
谁能帮我一下吗？
Python 3.9
Deepface 0.0.89（最新）
张量流版本2.14.1
虚拟环境已激活。
一切都已安装，但仍无法解决导入错误。]]></description>
      <guid>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</guid>
      <pubDate>Tue, 09 Apr 2024 12:57:54 GMT</pubDate>
    </item>
    <item>
      <title>TensorBoard HParams 未显示超参数调整的准确性指标</title>
      <link>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</link>
      <description><![CDATA[我正在 TensorFlow 中进行超参数调整，并使用 TensorBoard 中的 HParams 插件设置了一个实验来记录不同的配置。我的模型正在使用 dropout 和学习率的变化进行训练，并且我正在记录这些参数以及模型的准确性。但是，当我打开 TensorBoard 并导航到 HParams 仪表板时，不会显示与每个试验相关的准确性指标。该表正确显示了超参数，但“准确性”列为空，即使我的代码使用“准确性”作为指标来编译模型并使用 hp.KerasCallback 进行日志记录。我已经验证模型训练是否正确，并且标量仪表板等其他 TensorBoard 功能显示了各个时期的准确性趋势。我正在寻求帮助来理解为什么 HParams 表中没有显示准​​确性以及如何解决此问题。
图片：准确度列中缺少值
我使用 TensorBoard 的 HParams 进行超参数调整的代码：
从tensorboard.plugins.hparams导入api作为hp
将张量流导入为 tf
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、Dense、Flatten、Dropout

# 定义超参数
HP_DROPOUT = hp.HParam(&#39;dropout&#39;, hp.Discrete([0.2, 0.3, 0.4]))
HP_LEARNING_RATE = hp.HParam(&#39;learning_rate&#39;, hp.Discrete([1e-2, 1e-3]))

# 设置日志记录
log_dir = &#39;./tensorboard/nn_1&#39;
使用 tf.summary.create_file_writer(log_dir).as_default()：
    hp.hparams_config(
        hparams=[HP_DROPOUT, HP_LEARNING_RATE],
        指标=[hp.Metric(&#39;准确度&#39;,display_name=&#39;准确度&#39;)]
    ）

# 训练函数
def train_test_model(hparams, session_num):
    model_name = f“model_1_session_{session_num}”
    print(f&quot;使用超参数 {hparams} 训练 {model_name}...&quot;)
    模型 = tf.keras.Sequential([
        Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
        辍学（hparams [HP_DROPOUT]），
        Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
        辍学（hparams [HP_DROPOUT]），
        MaxPooling2D(pool_size=(2, 2)),
        展平（），
        密集（10，激活=&#39;softmax&#39;）
    ]）
    模型.编译(
        损失=&#39;分类交叉熵&#39;，
        优化器=tf.keras.optimizers.Adam(hparams[HP_LEARNING_RATE]),
        指标=[&#39;准确性&#39;]
    ）

    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f&#39;{log_dir}/{model_name}&#39;)
    hparams_callback = hp.KerasCallback(writer=f&#39;{log_dir}/{model_name}&#39;, hparams=hparams)

    模型.拟合(
        x_train_reshape, y_train_,
        纪元=3，
        验证数据=（x_val_reshape，y_val），
        回调=[hparams_callback，tensorboard_callback]
    ）

# 对每组超参数进行训练
会话编号 = 0
对于 HP_DROPOUT.domain.values 中的 dropout_rate：
    对于 HP_LEARNING_RATE.domain.values 中的learning_rate：
        hparams = {
            HP_DROPOUT：辍学率，
            HP_LEARNING_RATE：学习率，
        }
        train_test_model(hparams, session_num)
        会话编号 += 1

]]></description>
      <guid>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</guid>
      <pubDate>Tue, 09 Apr 2024 12:14:56 GMT</pubDate>
    </item>
    <item>
      <title>错误“无法将字符串转换为浮点数：'INLAND'”</title>
      <link>https://stackoverflow.com/questions/55332339/error-could-not-convert-string-to-float-inland</link>
      <description><![CDATA[我正在做一个使用机器学习进行房价预测的项目，并想将其提交给一家私营公司申请。
我正在 Jupiter 笔记本中处理这个项目，但我无法修复有关将字符串转换为数字数据的错误
from sklearn.model_selection import train_test_split
X_train,X_test, Y_train, Y_test=train_test_split(X,
                                              是，
                                             测试大小=0.2，
                                               随机状态=0）
从 sklearn.preprocessing 导入 StandardScaler
独立标量 = StandardScaler()
X_train = Independent_scalar.fit_transform(X_train) #拟合和变换
X_test = Independent_scalar.transform(X_test) # 只进行变换
打印（X_train）

我期望训练集数据是完全数字化的]]></description>
      <guid>https://stackoverflow.com/questions/55332339/error-could-not-convert-string-to-float-inland</guid>
      <pubDate>Mon, 25 Mar 2019 06:33:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 Docker 和 Flask 进行机器学习的性能问题</title>
      <link>https://stackoverflow.com/questions/50464643/performance-issues-with-machine-learning-using-docker-and-flask</link>
      <description><![CDATA[我有一些应用于 json 文件的 python3 代码，代码中有一些神经网络和随机森林。我将代码放入 Docker 容器中，但注意到这些 ML 任务在不使用 Docker 的情况下比使用 Docker 运行得更快。在 Docker 中，我使用 Flask 加载 json 文件并运行代码。当然，我在本地和 Docker 内部使用了相同版本的 python 模块，这些是：

theano 0.8.2
keras 2.0.5
scikit-learn 0.19.0

另外，Flask 是

0.12

起初，我认为 theano 在有 Docker 的情况下可能会使用不同的资源，但它同时运行单 CPU 和单线程。它也没有使用我的 GPU。当我意识到我的随机森林在 Docker 中运行速度也变慢时，我意识到这可能不是 theano。以下是我执行的一系列测试（我对每个测试进行了多次测试，我报告了平均时间，因为这些测试是稳定的）
没有 Docker，没有 Flask：

任务 1（theano + keras 代码）：1.0s 
任务 2（theano + keras 代码）：0.7s
任务 3（scikit-learn 代码）：0.25 秒

Docker (cpus=1) + Flask (调试模式 = True):

T1：6.5秒
T2：2.2秒
T3：0.58s

Docker (cpus=2) + Flask (调试模式 = True):

T1：5.5秒
T2：1.4秒
T3：0.55s

Docker (cpus=2) + Flask (调试模式 = False)：

T1：4.5秒
T2：1.2秒
T3：0.5秒

Docker (cpus=2)（无 Flask，仅调用本地完成的 json 文件）：

T1：2.8s
T2：1.1秒
T3：0.5秒

Flask（调试模式 = True）（无 Docker 容器）：

T1：2.8s
T2：1.5秒
T3：0.2秒

我猜 cpu=1 与 cpu=2 只是将一个 cpu 分配给代码，而第二个 cpu 只是接管一些其他工作。显然，当不使用 Flask 或 Docker 时，时间会有所减少，但仍然无法达到没有 Docker 和 Flask 的速度。有谁猜到为什么会发生这种情况吗？
这是我们如何使用 Flask 运行应用程序的最小代码块
api = Flask(__name__)
pipeline = Pipeline() # 调用多个任务的私有类

@api.route(&quot;/&quot;,methods=[&#39;POST&#39;])
def 条目():
    数据 = request.get_json(force=True)
    数据 = pipeline.process(数据)
    # 这会调用不同的定时任务

如果 __name__ == &quot;__main__&quot;:
    api.run（调试= True，主机=&#39;0.0.0.0&#39;，线程= False）


PS。如果问题缺少任何内容，请原谅我，这是我的第一个 StackOverflow 问题]]></description>
      <guid>https://stackoverflow.com/questions/50464643/performance-issues-with-machine-learning-using-docker-and-flask</guid>
      <pubDate>Tue, 22 May 2018 09:48:58 GMT</pubDate>
    </item>
    <item>
      <title>使用无标签的机器学习进行异常检测[关闭]</title>
      <link>https://stackoverflow.com/questions/44942551/anomaly-detection-with-machine-learning-without-labels</link>
      <description><![CDATA[我正在一段时间内跟踪多个信号，并将它们与时间戳相关联，如下所示：
&lt;前&gt;&lt;代码&gt;t0 1 10 2 0 1 0 ...
t1 1 10 2 0 1 0 ...
t2 3 0 9 7 1 1 ... //按下按钮更改模式
t3 3 0 9 7 1 1 ...
t4 3 0 8 7 1 1 ... // 按下按钮来调整某个特性，如温度（信号 3）

其中 t0 是时间戳，1 是信号 1 的值，10 是信号 2 的值，依此类推。
在该特定时间段内捕获的数据应被视为正常情况。现在应该可以检测到与正常情况的显着偏差。通过显着的推导，我并不是指一个信号值仅更改为跟踪阶段期间未见过的值，而是指许多值发生了尚未相互关联的更改。我不想对规则进行硬编码，因为将来可能会添加或删除更多信号，并且可能会添加或删除其他“modi”信号。可以实现具有其他信号值的。
这可以通过某种机器学习算法来实现吗？如果发生小的推导，我希望算法首先将其视为对训练集的微小更改，如果将来多次发生，则应该“学习”。主要目标是检测更大的变化/异常。
我希望我能足够详细地解释我的问题。提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/44942551/anomaly-detection-with-machine-learning-without-labels</guid>
      <pubDate>Thu, 06 Jul 2017 07:36:35 GMT</pubDate>
    </item>
    </channel>
</rss>