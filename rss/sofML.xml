<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 20 Aug 2024 09:17:38 GMT</lastBuildDate>
    <item>
      <title>为了简化在 Jupyter Notebook 中加载数据集的过程，您可以直接从本地设备上传文件</title>
      <link>https://stackoverflow.com/questions/78891329/to-simplify-the-process-of-loading-a-dataset-in-jupyter-notebook-you-can-upload</link>
      <description><![CDATA[从 google.colab 导入文件
从 google.colab 导入 auth
uploaded = files.upload()
for fn in uploaded.keys():
print(&#39;用户上传文件“{name}”，长度为 {length} 字节&#39;.format(
name=fn, length=len(uploaded[fn])))


让机器学习工程师和数据科学家的生活更轻松。]]></description>
      <guid>https://stackoverflow.com/questions/78891329/to-simplify-the-process-of-loading-a-dataset-in-jupyter-notebook-you-can-upload</guid>
      <pubDate>Tue, 20 Aug 2024 08:20:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 sklearn python 获取预测</title>
      <link>https://stackoverflow.com/questions/78890391/how-use-sklearn-python-get-predicion</link>
      <description><![CDATA[我有一张表，我想传递 features = &quot;train_1, train_2, train_3, train_4&quot; 和 target_result = result_cor。
我想知道什么时候值是 = &quot;1 或 2&quot;在我的预测中：
关注我的数据
关注我的代码：
从 enum 导入 auto
从 sklearn.svm 导入 LinearSVC
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 accuracy_score
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.metrics 导入 classes_report
从 sklearn 导入 svm
从 sklearn.linear_model 导入 LogisticRegression
导入 pandas 作为 pd
导入 numpy 作为 np
导入 matplotlib.pyplot 作为 plt
导入 math
导入 seaborn 作为 sns

sheet_id = &#39;1CfnVwuqysTYNPKLVhgjJ44Af8VDcdN1l&#39; dados = pd.read_excel(f&#39;https://docs.google.com/spreadsheets/export?id={sheet_id}&amp;format=xlsx&#39;) bads.head() # 实现更多数量的数据 x = bados[[&#39;train_1&#39;,&#39;train _2&#39;,&#39;train_3&#39;,&#39;train_4&#39;]] # Gabarito 或 corretos y = bados[[&#39;result_cor&#39;]] # 将 x e y e testes de x e y 分开 treino_x, teste_x, treino_y, teste_y = train_test_split(x,y,test_size=0.33) # 模型类型 modelo = DecisionTreeClassifier() # 训练效果 modelo.fit(x,np.ravel(y,order=&quot;c&quot;)) # 预测新值 model_predict = [0,1,0,1] treino_x[:1] = model_predict model_predict = treino_x[:1] result_cor = [1] treino_y[:1] = result_cor result_cor = treino_y[:1] # 预测新模型 previsoes = modelo.predict(model_predict) # 检查准确率 precision = precision_score(result_cor,previsoes) * 100 print(f&#39;A acuracia é: {round(accuracy,2)}&#39;)


但结果始终为 100.0 % 或 0.0。我需要知道我的 result_cor 出现在模型训练模型的 model_predict 中的次数百分比
请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/78890391/how-use-sklearn-python-get-predicion</guid>
      <pubDate>Tue, 20 Aug 2024 02:18:19 GMT</pubDate>
    </item>
    <item>
      <title>构建基于图像的推荐应用程序的最佳技术堆栈？[关闭]</title>
      <link>https://stackoverflow.com/questions/78890196/best-tech-stack-to-build-an-image-based-recommendation-app</link>
      <description><![CDATA[我想开发一款应用，推荐与给定对象图像最相似的对象。用户将从相机胶卷中输入图像，然后应用将输出来自互联网的类似图像。开发这款产品的最佳技术堆栈是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78890196/best-tech-stack-to-build-an-image-based-recommendation-app</guid>
      <pubDate>Tue, 20 Aug 2024 00:15:45 GMT</pubDate>
    </item>
    <item>
      <title>ml5js“检查时出错：预期dense_Dense1_input的形状为[null，2134]，但得到的数组形状为[1,37]”</title>
      <link>https://stackoverflow.com/questions/78890052/ml5js-error-when-checking-expected-dense-dense1-input-to-have-shape-null-213</link>
      <description><![CDATA[我正在使用 ml5js 训练一个模型，根据以下字段预测面包店将出售的商品数量：
day_of_week
next_holiday
days_until_next_holiday
avg_cloud_cover
avg_precip
avg_temp
highest_cloud_cover
highest_precip
highest_temp
lowest_cloud_cover
lowest_precip
lowest_temp

我已经训练了模型，创建了三个常用文件：

model_meta.json
model.json
model.weights.bin

但是，当我导入模型并使用模型进行预测时，使用如下测试输入：
const input = { 
day_of_week: &quot;星期四&quot;, 
next_holiday: &quot;加拿大国庆日&quot;, 
days_until_next_holiday: 10, 
avg_cloud_cover: 0, 
avg_precip: 0, 
avg_temp: 0, 
highest_cloud_cover: 0, 
highest_precip: 0, 
highest_temp: 0, 
lowest_cloud_cover: 0, 
lowest_precip: 0, 
lowest_temp: 0 
}

我收到此错误：

错误：检查时出错：预期dense_Dense1_input 具有形状[null,2134]，但得到的数组具有形状[1,37]。

我认为我收到此错误是因为我没有正确格式化输入。我在创建模型时对数据进行了规范化，因此它创建了许多新字段，所有字段的值都是 0 或 1。
例如，对于 day_of_week，model_meta.json 的开头如下所示：
{
&quot;inputUnits&quot;:[2134],
&quot;outputUnits&quot;:1,
&quot;inputs&quot;:{
&quot;day_of_week&quot;:{
&quot;dtype&quot;:&quot;string&quot;,
&quot;min&quot;:0,
&quot;max&quot;:1,
&quot;uniqueValues&quot;:[&quot;Thursday&quot;,&quot;Wednesday&quot;,&quot;Tuesday&quot;,&quot;Monday&quot;,&quot;Sunday&amp; quot;,&quot;星期六&quot;,&quot;星期五&quot;],
&quot;legend&quot;:{&quot;星期四&quot;:[1,0,0,0,0,0,0],&quot;星期三&quot;:[0,1,0,0,0,0,0],&quot;星期二&quot;:[0,0,1,0,0,0,0],&quot;星期一&quot;:[0,0,0,1,0,0,0],&quot;星期日&quot;:[0,0,0,0,1,0,0],&quot;星期六&quot;:[0,0,0,0,0,1,0],&quot;星期五&quot;:[0,0,0,0,0,0,1]
}
},
...

我想知道我是否需要格式化输入以不使用字符串作为 day_of_week 等字段。但如果是这样，我不确定用什么来替换它。
有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/78890052/ml5js-error-when-checking-expected-dense-dense1-input-to-have-shape-null-213</guid>
      <pubDate>Mon, 19 Aug 2024 23:04:00 GMT</pubDate>
    </item>
    <item>
      <title>GradCam：层 Sequenced_1 从未被调用，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78889743/gradcam-the-layer-sequential-1-has-never-been-called-and-thus-has-no-defined-ou</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78889743/gradcam-the-layer-sequential-1-has-never-been-called-and-thus-has-no-defined-ou</guid>
      <pubDate>Mon, 19 Aug 2024 20:51:58 GMT</pubDate>
    </item>
    <item>
      <title>Kornia 中的 ImageRegistrator 翻译结果不正确</title>
      <link>https://stackoverflow.com/questions/78887294/incorrect-translation-results-with-imageregistrator-in-kornia</link>
      <description><![CDATA[当我尝试使用翻译注册两个帧时，我在 Kornia 中的 ImageRegistrator 中遇到了问题。该函数始终返回错误的翻译值，即使是对于基本的合成测试用例也是如此。下面是我用来测试翻译注册的代码。有人能指导我正确的方法吗？

复制步骤
import numpy as np
import torch
import kornia as K
import kornia.geometry as KG
import cv2
import matplotlib.pyplot as plt
from typing import Tuple

def find_frame_translation_kornia(frame_1: np.ndarray, frame_2: np.ndarray) -&gt; Tuple[Tuple[float, float], np.ndarray, bool]:
“使用 Kornia 的 ImageRegistrator 查找两个帧之间的转换。”“”

frame_1 = K.image_to_tensor(frame_1, False).float() / 255.0 # 形状：(C, H, W)
frame_2 = K.image_to_tensor(frame_2, False).float() / 255.0 # 形状：(C, H, W)

if frame_1.ndim == 3:
frame_1 = frame_1.unsqueeze(0) # 形状：(1, C, H, W)
if frame_2.ndim == 3:
frame_2 = frame_2.unsqueeze(0) # 形状：(1, C, H, W)

registrator = KG.ImageRegistrator(&quot;translation&quot;) # 对于&quot;similarity&quot;、&quot;homography&quot;等，结果相同。

try:
model = registrator.register(frame_1, frame_2)
tx, ty = model[0, :2, 2].cpu().detach().numpy()

shift = (tx, ty)
M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)

success = True

except Exception as e:
print(f&quot;注册失败：{e}&quot;)
shift, M, success = (0, 0), np.eye(3, dtype=np.float32)[:2, :], False

return shift, M, success

def create_translated_image(image: np.ndarray, tx: int, ty: int) -&gt; np.ndarray:
rows, cols = image.shape
M = np.float32([[1, 0, tx], [0, 1, ty]])
classified_image = cv2.warpAffine(image, M, (cols, rows))
return classified_image

def test_find_frame_translation_kornia():
image = np.zeros((100, 100), dtype=np.uint8)
image[30:70, 30:70] = 255 # 中心的白色方块

tx, ty = 5, -3
classified_image = create_translated_image(image, tx, ty)

plt.subplot(1, 2, 1)
plt.imshow(image, cmap=&#39;gray&#39;)
plt.title(&quot;Original Image&quot;)
plt.subplot(1, 2, 2)
plt.imshow(translated_image, cmap=&#39;gray&#39;)
plt.title(&quot;翻译后的图像&quot;)
plt.show()

shift, M, success = find_frame_translation_kornia(image, classified_image)

断言成功, &quot;注册失败&quot;
np.testing.assert_almost_equal(shift, (tx, ty), decimal=1)
expected_M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
np.testing.assert_almost_equal(M, expected_M, decimal=1)

if __name__ == &quot;__main__&quot;:
test_find_frame_translation_kornia()

问题：
运行测试时，该函数返回明显错误的翻译值。具体来说，对于已知的翻译 (5, -3)，该函数返回 (-0.1, 0.1)。这是我收到的错误消息：
AssertionError: 
数组不几乎等于 1 个小数

元素不匹配：2 / 2 (100%)
最大绝对差异：5.09875337
最大相对差异：1.02040539
x：array([-0.1, 0.1], dtype=float32)
y：array([ 5, -3])

预期行为
该函数应正确识别原始图像和翻译后图像之间的翻译 (5, -3)。
环境

PyTorch 版本（例如 1.0）：2.4.0+cpu
操作系统（例如 Linux）： Microsoft Windows 10 Pro
您如何安装 PyTorch（conda、pip、source）：
[pip3] torch-pitch-shift==1.2.4
[pip3] torchaudio==2.3.0
[pip3] torchmetrics==1.4.0.post0
[conda] numpy 1.26.4 pypi_0 pypi
[conda] torch 2.4.0 pypi_0 pypi
您使用的构建命令（如果从源代码编译）：
Python 版本：3.9.19
CUDA/cuDNN 版本：False
GPU 型号和配置：False
任何其他相关信息：

]]></description>
      <guid>https://stackoverflow.com/questions/78887294/incorrect-translation-results-with-imageregistrator-in-kornia</guid>
      <pubDate>Mon, 19 Aug 2024 09:52:04 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，torch.Tensor.backward() 函数如何工作？</title>
      <link>https://stackoverflow.com/questions/78872444/how-torch-tensor-backward-function-works-in-this-situation</link>
      <description><![CDATA[假设我将两个模型（例如 SAM 和 U-NET）的参数包含在名为“joint_parameters”的变量中，然后将优化器设置为
optimizer = torch.optim.Adam(joint_params, lr=1e-5)

假设“sam_loss”是从 SAM 模型的输出计算出来的损失。
当我执行时，U-NET 模型的参数会发生什么
sam_loss.backward()
optimizer.step() 

它对 U-NET 的参数有影响吗？还是什么都没有发生？
我认为 U-NET 的参数不会发生任何事情，但我只是想确定一下。]]></description>
      <guid>https://stackoverflow.com/questions/78872444/how-torch-tensor-backward-function-works-in-this-situation</guid>
      <pubDate>Wed, 14 Aug 2024 18:25:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不能用 C++ 构建一个没有依赖关系的神经网络，即使它可以在 Numpy 中运行？</title>
      <link>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</guid>
      <pubDate>Mon, 12 Aug 2024 16:55:51 GMT</pubDate>
    </item>
    <item>
      <title>Keras ValueError：从未调用过层顺序，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78722413/keras-valueerror-the-layer-sequential-has-never-been-called-and-thus-has-no-def</link>
      <description><![CDATA[我想将 Keras 的 Grad-CAM 与我自己的 CNN 模型一起使用。我已遵循此 https://keras.io/examples/vision/grad_cam/，其中的 make_gradcam_heatmap 函数也来自此。我对 CNN 还不熟悉，所以我可能忽略了一些显而易见的东西，但为什么它在我运行模型时无法识别呢？
这是我的代码：
import numpy as np
import os
import tensorflow as tf
import keras
from tensorflow.keras.models import load_model
import cv2
from tensorflow.keras.models import Model

os.environ[&quot;KERAS_BACKEND&quot;] = &quot;tensorflow&quot;

从 IPython.display 导入图像，显示
导入 matplotlib 作为 mpl
导入 matplotlib.pyplot 作为 plt

img_path = &#39;/Users/.../image_1.npy&#39;

model = load_model(&#39;/Users/.../particle_classifier_model.h5&#39;)

model_builder = keras.applications.xception.Xception
preprocess_input = keras.applications.xception.preprocess_input
decode_predictions = keras.applications.xception.decode_predictions

image = np.load(img_path)
img_size = image.shape # 应为形状为 (240, 146) 的数组

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
# 首先，我们创建一个将输入图像映射到最后一个 conv 的激活的模型层以及输出预测
grad_model = keras.models.Model(
model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]
)

# 然后，我们计算输入图像的顶部预测类的梯度
# 相对于最后一个卷积层的激活
with tf.GradientTape() as tape:
last_conv_layer_output, preds = grad_model(img_array)
if pred_index is None:
pred_index = tf.argmax(preds[0])
class_channel = preds[:, pred_index]

# 这是输出神经元的梯度（顶部预测或选择）
# 相对于最后一个卷积层的输出特征图
grads = tape.gradient(class_channel, last_conv_layer_output)

# 这是一个向量，其中每个条目都是梯度的平均强度
# 在特定特征图通道上
pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

# 我们将特征图数组中的每个通道乘以
# 相对于顶部预测类的“此通道的重要性”
# 然后对所有通道求和以获得热图类激活
last_conv_layer_output = last_conv_layer_output[0]
heatmap = last_conv_layer_output @pooled_grads[..., tf.newaxis]
heatmap = tf.squeeze(heatmap)

# 为了可视化目的，我们还将在 0 和 1 之间对热图进行标准化
heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
return heatmap.numpy()

last_conv_layer_name = “max_pooling2d_4”

image = image.reshape(1, 240, 146, 1)
preds = model.predict(image)

model.layers[-1].activation = None

heatmap = make_gradcam_heatmap(image, model, last_conv_layer_name)
plt.matshow(heatmap)
plt.show()

我的数据是维度 (240, 146) 的 numpy 数组，CNN 将其作为输入。]]></description>
      <guid>https://stackoverflow.com/questions/78722413/keras-valueerror-the-layer-sequential-has-never-been-called-and-thus-has-no-def</guid>
      <pubDate>Mon, 08 Jul 2024 18:32:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 kaggle 中使用两个 gpu 进行 pytorch 训练？</title>
      <link>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</link>
      <description><![CDATA[我在 kaggle gpu 中训练模型。
但我发现只有一个 GPU 在工作。

我使用普通方法进行训练，例如
device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;)
model = model.to(device)

我如何使用这两个 gpu？]]></description>
      <guid>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</guid>
      <pubDate>Wed, 13 Sep 2023 04:56:24 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下预测正确吗？</title>
      <link>https://stackoverflow.com/questions/72611140/does-the-prediction-ok-or-not-in-this-case</link>
      <description><![CDATA[请告诉我以下代码的预测是否正确，这是 CNN 的测试代码，
我使用的是 Jupyter、Tensorflow 2.9.0 和 Keras 2.9.0
import math
import os
import numpy as np
import cv2
from keras.models import load_model
from PIL import Image
############# 参数 ##############
threshold = 0.90 # 分类的最小概率
#### 加载训练模型 
model = load_model(&#39;model_trained.h5&#39;)
path = r&#39;C:\Users\Issam\AppData\Local\Programs\Python\Python36\Digits-Classification-master\Weed_Detection\MyTestData\test9.jpg&#39;
# 以默认模式读取图像并创建子图像
i = Image.open (path)
width, height = i.size
print(width)
print(height)
L=0
T=0
R=width
B=height
imgOriginal= frame1
img = np.asarray(imgOriginal)
img = cv2.resize(img,(200, 200))
img = preProcessing(img)
cv2.imshow(&quot;Processed Image&quot;,img)
img = img.reshape(1,200,200,1)
frame1 = i.crop(((L, T, R, B/3)))
def预处理（img）：
img = cv2.cvtColor（img，cv2.COLOR_BGR2GRAY）
img = cv2.equalizeHist（img）
img = img / 255
返回 img
# 预测
predictions = model.predict（img）
classIndex = np.argmax（predictions，axis=1）
probVal = np.amax（predictions）
如果 probVal &gt; 阈值：
如果 classIndex == 0：
item1 = &quot;No_Weed&quot;
prob1=probVal
print（item1，&quot;Probability: &quot;，probVal）
elif classIndex == 1：
item1 = &quot;Weed&quot;
prob1=probVal
print(item1, &quot;Probability: &quot;,probVal)

模型结果如下
模型：“顺序”
_________________________________________________________________
层（类型）输出形状参数 # 
=====================================================================
conv2d (Conv2D) (无，196，196，60) 1560 

conv2d_1 (Conv2D) (无，192，192，60) 90060 

max_pooling2d (MaxPooling2D (无，96，96，60) 0 
) 

conv2d_2 (Conv2D) (无，94，94，30) 16230 

conv2d_3 (Conv2D) (无，92，92，30) 8130 

max_pooling2d_1 (MaxPooling (无，46，46，30) 0 
2D) 

dropout (Dropout) (无，46，46，30) 0 

flatten (Flatten) (无，63480) 0 

density (Dense) (无，500) 31740500 

dropout_1 (Dropout) (无，500) 0 

density_1 (Dense) (无，2) 1002

==========================================================================
总参数：31,857,482
可训练参数：31,857,482
不可训练参数：0
_________________________________________________________________
无
]]></description>
      <guid>https://stackoverflow.com/questions/72611140/does-the-prediction-ok-or-not-in-this-case</guid>
      <pubDate>Tue, 14 Jun 2022 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>浏览数据集时遇到“TypeError：'Tensor' 和 'list' 实例之间不支持 '<'”</title>
      <link>https://stackoverflow.com/questions/72506050/ran-into-typeerror-not-supported-between-instances-of-tensor-and-list</link>
      <description><![CDATA[我正在复制 ResNet（来源：https://arxiv.org/abs/1512.03385）。
我遇到了错误“TypeError：&#39;&lt;&#39; 在 &#39;Tensor&#39; 和 &#39;list&#39; 的实例之间不受支持”尝试在代码的不同部分中遍历几个不同的数据集时。
我尝试了不同的修复方法，但都不起作用：（i）我删除了枚举，因为我担心使用它可能会导致问题（ii）我尝试通过数据加载器而不是数据集，但没有工作
第一次：当我尝试查看图像时：
for images, _ in train_loader:
print(&#39;images.shape:&#39;, images.shape)
plt.figure(figsize=(16,8))
plt.axis(&#39;off&#39;)
plt.imshow(torchvision.utils.make_grid(images, nrow=16).permute((1, 2, 0)))
break

第二次/第三次：当我尝试验证/测试 resnet 时：
with torch.no_grad():
for j, input, labels in enumerate(test_loader, start=0):
output = resnet_models[i](inputs) 
_, prediction = torch.max(outputs, dim=1) 

大家可能注意到，我在训练resnet的时候并没有遇到这个错误，代码也挺相似的：
for batch, data in enumerate(train_dataloader, start=0): 
input, labels = data
input, labels = input.to(device), labels.to(device) 

错误信息（以第一个错误为例）其余部分基本相同）

TypeError Traceback（最近一次调用最后一次）
输入 In [38]，在 &lt;cell line: 8&gt;()
6 print(&quot;Images AFTER NORMALIZATION&quot;)
7 print(&quot;-------------------------&quot;)
----&gt; 8 for images, _ in training_data:
9 sort=False
10 print(&#39;images.shape:&#39;, images.shape)
文件 ~/miniconda3/envs/resnet/lib/python3.9/site-&gt;packages/torch/utils/data/dataset.py:471，在 Subset 中。getitem(self, idx)
469 if isinstance(idx, list):
470 return self.dataset[[self.indices[i] for i in idx]]
--&gt; 471 返回 self.dataset[self.indices[idx]]
文件 ~/miniconda3/envs/resnet/lib/python3.9/site-&gt;packages/torchvision/datasets/cifar.py:118，在 CIFAR10 中。getitem(self, index)
115 img = Image.fromarray(img)
117 如果 self.transform 不为 None：
--&gt; 118 img = self.transform(img)
120 如果 self.target_transform 不为 None:
121 target = self.target_transform(target)
文件 ~/miniconda3/envs/resnet/lib/python3.9/site-&gt;packages/torchvision/transforms/transforms.py:95，在 Compose 中。call(self, img)
93 def call(self, img):
94 for t in self.transforms:
---&gt; 95 img = t(img)
96 返回 img
File ~/miniconda3/envs/resnet/lib/python3.9/site-&gt;packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
1106 # 如果我们没有任何钩子，我们希望跳过此函数中的其余逻辑
1107 # 并只调用 forward。
1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks &gt;or _global_backward_hooks
1109 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1110 return forward_call(*input, **kwargs)
1111 # 使用 jit 时不要调用函数
1112 full_backward_hooks, non_full_backward_hooks = [], []
File ~/miniconda3/envs/resnet/lib/python3.9/site-&gt;packages/torchvision/transforms/transforms.py:707, in RandomHorizo​​ntalFlip.forward(self, &gt;img)
699 def forward(self, img):
700 &quot;&quot;&quot;
701 Args:
702 img (PIL 图像或张量)：要翻转的图像。
(...)
705 PIL 图像或张量：随机翻转的图像。
706 &quot;&quot;&quot;
--&gt; 707 if torch.rand(1) &lt; self.p:
708 return F.hflip(img)
709 return img
TypeError: &#39;&lt;&#39; 不支持在 &#39;Tensor&#39; 和 &#39;list&#39; 实例之间使用 &#39;
]]></description>
      <guid>https://stackoverflow.com/questions/72506050/ran-into-typeerror-not-supported-between-instances-of-tensor-and-list</guid>
      <pubDate>Sun, 05 Jun 2022 09:07:09 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 预期为 1D 张量，但得到的是 2D 张量</title>
      <link>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</link>
      <description><![CDATA[我一直在用 Python 从头开始​​制作神经网络。输入张量的形状为 [400,3]，target_tensor 的形状为 [400]。在对权重求导时，我遇到了错误。以下是函数：
def sigmoid(z):
return 1 / (1 + torch.exp(-z))

def nueral_net(data,weights,bias):
return sigmoid( ( data @ weights ) + bias )

def loss_function(prediction,actual,m):
return (-1/m) * (torch.sum(actual * torch.log(prediction) + (1-actual) 
* torch.log(1- prediction)))

w = torch.randn(input_tensor.shape[1],1)

b = torch.randn(1,1)

predictions = nueral_net(input_tensor.float() , w, b) #应用模型
loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)

运行此程序会引发错误：
RuntimeError Traceback (most recent call last)
&lt;ipython-input-26-632338d8fd16&gt; in &lt;module&gt;
1 predictions = nueral_net(input_tensor.float() , w, b) #应用模型
2 loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
----&gt; 3 dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)
4 db = (1/400) * torch.sum(predictions - target_tensor)
5 #m = input_tensor.shape[0]

RuntimeError: 预期为 1D 张量，但得到的是 2D 和 2D 张量
]]></description>
      <guid>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</guid>
      <pubDate>Sat, 20 Mar 2021 10:32:38 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 在部署时无法提取容器的模型数据存档 tar.gz</title>
      <link>https://stackoverflow.com/questions/65881699/sagemaker-failed-to-extract-model-data-archive-tar-gz-for-container-when-deployi</link>
      <description><![CDATA[我正在尝试在 Amazon Sagemaker 中部署现有的 Scikit-Learn 模型。因此，该模型不是在 SageMaker 上训练的，而是在我的本地机器上训练的。
在我的本地 (windows) 机器上，我将模型保存为 model.joblib，并将模型压缩为 model.tar.gz。
接下来，我已将此模型上传到我的 S3 存储桶 (&#39;my_bucket&#39;)，路径为 s3://my_bucket/models/model.tar.gz。我可以在 S3 中看到 tar 文件。
但是当我尝试部署模型时，它一直显示错误消息“无法提取模型数据存档”。
.tar.gz 是通过在 powershell 命令窗口中运行“tar -czf model.tar.gz model.joblib”在我的本地机器上生成的。
上传到 S3 的代码
import boto3
s3 = boto3.client(&quot;s3&quot;, 
region_name=&#39;eu-central-1&#39;, 
aws_access_key_id=AWS_KEY_ID, 
aws_secret_access_key=AWS_SECRET)
s3.upload_file(Filename=&#39;model.tar.gz&#39;, Bucket=my_bucket, Key=&#39;models/model.tar.gz&#39;)

创建估算器并部署的代码：
import boto3
from sagemaker.sklearn.estimator import SKLearnModel

...

model_data = &#39;s3://my_bucket/models/model.tar.gz&#39;
sklearn_model = SKLearnModel(model_data=model_data,
role=role,
entry_point=&quot;my-script.py&quot;,
framework_version=&quot;0.23-1&quot;)
predictor = sklearn_model.deploy(instance_type=&quot;ml.t2.medium&quot;, initial_instance_count=1) 

错误消息：

错误消息：UnexpectedStatusException：托管错误端点
sagemaker-scikit-learn-2021-01-24-17-24-42-204：失败。原因：无法从 URL“s3://my_bucket/models/model.tar.gz”提取容器“container_1”的模型数据存档。请确保位于 URL 处的对象是有效的 tar.gz 存档

有没有办法查看存档无效的原因？]]></description>
      <guid>https://stackoverflow.com/questions/65881699/sagemaker-failed-to-extract-model-data-archive-tar-gz-for-container-when-deployi</guid>
      <pubDate>Mon, 25 Jan 2021 09:03:31 GMT</pubDate>
    </item>
    <item>
      <title>CNN 中的 Conv2D 输出形状太小</title>
      <link>https://stackoverflow.com/questions/63522998/conv2d-output-shape-in-cnn-too-small</link>
      <description><![CDATA[第一个 Conv2D 层的输入形状应该是 (100, 100, 1)，但输出是 (None, 98, 98, 200)。我理解 200 和 None 决定了什么，但我不确定 98 作为参数。
此外，我还随机选择了 200 作为我的模型的 Conv2D 中的过滤器数量。我应该如何确定适合我的模型的过滤器数量。它是基于反复试验的吗？
来自 keras.models 导入 Sequential
来自 keras.layers 导入 Dense、Activation、Flatten、Dropout
来自 keras.layers 导入 Conv2D、MaxPooling2D
来自 keras.callbacks 导入 ModelCheckpoint

print(data.shape[1:])
model = Sequential()
model.add(Conv2D(200, (3,3), input_shape = data.shape[1:]))
model.add(Activation(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Conv2D(100,(3,3)))

model.add(Activation(&#39;relu&#39;))

model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dropout(0.5))

model.add(Dense(50,activation =&#39;relu&#39;))

model.add(Dense(2,activation =&#39;softmax&#39;))

model.compile(loss =&#39;categorical_crossentropy&#39;,optimizer =&#39;adam&#39;,metrics =[&#39;accuracy&#39;])

model.summary()

输出：
(100,100,1)
模型：“sequence_3”
_________________________________________________________________
层（类型）输出形状参数 # 
======================================================================
conv2d_5 (Conv2D) (无，98，98，200) 2000 
_________________________________________________________________
activation_5 (激活) (无，98，98，200) 0 
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (无，49，49，200) 0 
_________________________________________________________________
conv2d_6 (Conv2D) (无，47，47，100) 180100
_________________________________________________________________
activation_6 (激活) (无，47，47，100) 0 
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (无，23，23，100) 0 
_________________________________________________________________
flatten_3 (扁平化) (无，52900) 0 
_________________________________________________________________
dropout_3 (丢失) (无，52900) 0 
_________________________________________________________________
dense_5 (密集) (无，50) 2645050 
_________________________________________________________________
dense_6 (密集) (无，2) 102
=========================================================================
总参数：2,827,252
可训练参数：2,827,252
不可训练参数：0
___________________________
]]></description>
      <guid>https://stackoverflow.com/questions/63522998/conv2d-output-shape-in-cnn-too-small</guid>
      <pubDate>Fri, 21 Aug 2020 12:31:54 GMT</pubDate>
    </item>
    </channel>
</rss>