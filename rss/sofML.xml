<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 02 Dec 2024 18:24:40 GMT</lastBuildDate>
    <item>
      <title>我有一系列小分子结构，想根据结构相似性对它们进行比较和聚类</title>
      <link>https://stackoverflow.com/questions/79244995/i-have-a-collection-of-structures-of-small-molecules-want-to-compare-and-cluster</link>
      <description><![CDATA[我是一名计算生物学家，有一组代表数百个小生物分子（代谢物）的化学结构。
除了这些分子，我还有每个分子的元数据（物种、条件、表型、存在/不存在等）。我的目标是找到将化合物中存在的一些分子多样性与这些元数据联系起来的方法。
例如，我正在考虑的一件事是不可知地对这些分子进行聚类（PCA 或类似方法），并识别在元数据的光照下看起来分离的模式。
是否有做类似事情的标准做法？我知道药物发现领域有查看命中之间的共同点的方法，并希望做类似的事情。]]></description>
      <guid>https://stackoverflow.com/questions/79244995/i-have-a-collection-of-structures-of-small-molecules-want-to-compare-and-cluster</guid>
      <pubDate>Mon, 02 Dec 2024 17:16:21 GMT</pubDate>
    </item>
    <item>
      <title>开始一个项目 [关闭]</title>
      <link>https://stackoverflow.com/questions/79244312/getting-started-with-a-project</link>
      <description><![CDATA[我该如何着手构建一个数据科学中的机器学习项目，我需要指导如何正确进入它。
我还没有开始，但是，这就是我想要进入的。得到答案将是一件令人高兴的事。]]></description>
      <guid>https://stackoverflow.com/questions/79244312/getting-started-with-a-project</guid>
      <pubDate>Mon, 02 Dec 2024 13:43:20 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV11 缓存中未找到标签</title>
      <link>https://stackoverflow.com/questions/79243452/yolov11-no-labels-found-in-cache</link>
      <description><![CDATA[我正在尝试训练一个对坦克进行分类的模型。我有 9 个标签。我正在 Google Collab 上工作：
这是文件夹结构：

现在，我从 Roboflow 获得了这个坦克数据集。我最初加载数据集的方式是使用网站上提供给我的下载代码。我的初始代码如下所示
!mkdir {HOME}/datasets
%cd {HOME}/datasets

from google.colab import userdata
from roboflow import Roboflow

ROBOFLOW_API_KEY = userdata.get(&#39;ROBOFLOW_API_KEY&#39;)
rf = Roboflow(api_key=ROBOFLOW_API_KEY)

workspace = rf.workspace(&quot;liangdianzhong&quot;)
project = rf.workspace(&quot;capstoneproject&quot;).project(&quot;russian-military-annotated&quot;)
version = project.version(4)
dataset = version.download(&quot;yolov11&quot;)

下一行代码显示我初始化训练模型
%cd {HOME}

!yolo task=detect mode=train model=yolo11s.pt data={dataset.location}/data.yaml epochs=1 batch= 60 imgsz=640 plots=True

我的错误在这里抛出：
从预训练权重中转移了 493/499 个项目
TensorBoard：以“tensorboard --logdir runs/detect/train7”开始，在 http://localhost:6006/ 查看
冻结层“model.23.dfl.conv.weight”
AMP：正在运行自动混合精度 (AMP) 检查...
AMP：检查已通过✅
train：正在扫描 /content/datasets/Russian-military-annotated-4/train/labels... 1026 张图片，33 个背景，0 个损坏：100% 1026/1026 [00:00&lt;00:00， 1995.16it/s]
train：已创建新缓存：/content/datasets/Russian-military-annotated-4/train/labels.cache
albumentations：Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method=&#39;weighted_average&#39;), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
val：正在扫描 /content/datasets/Russian-military-annotated-4/valid/labels... 9 张图片，9 个背景，0 个损坏：100% 9/9 [00:00&lt;00:00， 1585.35it/s]
val：已创建新缓存：/content/datasets/Russian-military-annotated-4/valid/labels.cache
警告⚠️在/content/datasets/Russian-military-annotated-4/valid/labels.cache 中未找到标签，训练可能无法正常工作。请参阅 https://docs.ultralytics.com/datasets 获取数据集格式指南。
将标签绘制到 runs/detect/train7/labels.jpg... 
优化器：发现“optimizer=auto”，忽略“lr0=0.01”和“momentum=0.937”，并自动确定最佳“optimizer”、“lr0”和“momentum”... 
优化器：AdamW(lr=0.000714, motivation=0.9)，参数组为 81 weight(decay=0.0)、88 weight(decay=0.00046875)、87 bias(decay=0.0)
TensorBoard：添加了模型图可视化✅
图像大小 640 train，640 val
使用 2 个数据加载器工作者
将结果记录到 runs/detect/train7
开始训练 1 个时期...

时期 GPU_mem box_loss cls_loss dfl_loss 实例大小
1/1 15.2G 1.125 5.288 1.594 18 640: 100% 18/18 [00:22&lt;00:00, 1.24s/it]
类别图像实例框（P R mAP50 mAP50-95）：100% 1/1 [00:00&lt;00:00, 1.50it/s]
全部 9 0 0 0 0 0
警告 ⚠️ 在检测集中未找到标签，无法在没有标签的情况下计算指标

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79243452/yolov11-no-labels-found-in-cache</guid>
      <pubDate>Mon, 02 Dec 2024 09:03:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 MNIST 训练模型会在 Python 中对自定义图像进行错误分类？</title>
      <link>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image-in-python</link>
      <description><![CDATA[我使用 MNIST 数据集训练了一个神经网络模型来识别手写数字。该模型在 MNIST 测试集上的准确率达到 97%，但无法正确预测自定义图像文件中的数字。例如，下图包含数字 8，但模型的预测始终不正确。
我在预处理步骤中做错了什么，如何正确准备自定义图像以匹配 MNIST 数据格式？
import cv2
import numpy as np
import os
from keras.api.datasets import mnist
from keras.api.models import Sequential
from keras.api.layers import Dense, Flatten
from keras.api.utils import to_categorical
from PIL import Image

# 加载 MNIST 数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 将 mnist 数据集从 uint8 转换为 float32，因为大多数深度学习框架都希望输入数据为浮点格式。
train_images = train_images.astype(&#39;float32&#39;) / 255
test_images = test_images.astype(&#39;float32&#39;) / 255

# 添加新的通道维度，得到形状 (num_samples, 28, 28, 1)
train_images = np.expand_dims(train_images, axis=-1)
test_images = np.expand_dims(test_images, axis=-1)

# 对标签进行独热编码
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 构建模型
model = Sequential([
Flatten(input_shape=(28, 28, 1)),
Dense(128,activation=&#39;relu&#39;),
Dense(10,activation=&#39;softmax&#39;)
])

#编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

# 训练模型
print(&quot;训练模型...&quot;)
model.fit(train_images, train_labels, epochs=5, batch_size=128)

# 评估模型
loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)
print(f&quot;测试准确率：{accuracy * 100:.2f}%&quot;)

# 加载图像进行预测
image_path = &#39;digit.png&#39; # 替换为您的图像路径
print(f&quot;加载并预测 {image_path}...&quot;)

try:
# 以灰度读取图像
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
raise IOError(f&quot;Error loading image at {image_path}&quot;)

# 将图像大小调整为 28x28
image = cv2.resize(image, (28, 28))

# 反转颜色（如果需要）
image = cv2.bitwise_not(image)

# 标准化图像
image_normalized = image.astype(&#39;float32&#39;) / 255

# 转换为可以保存为 PNG 的格式（值 0 到 255）
image_for_saving = (image_normalized * 255).astype(np.uint8)

# 定义保存图像的路径
preprocessed_image_path = &quot;preprocessed_digit.png&quot;

# 确保目录存在（当前目录）
output_directory = os.path.dirname(preprocessed_image_path)
if not os.path.exists(output_directory) and output_directory != &#39;&#39;:
os.makedirs(output_directory)

# 使用 PIL 保存图像
pil_image = Image.fromarray(image_for_saving)
pil_image.save(preprocessed_image_path)
print(f&quot;已将预处理图像保存到 {preprocessed_image_path}&quot;)

# 使用模型预测数字（假设模型已加载）
# 必要时将图像重塑为模型输入格式
image_input = np.expand_dims(image_normalized, axis=0)
image_input = np.expand_dims(image_input, axis=-1)
prediction = np.argmax(model.predict(image_input))
print(&quot;预测数字：&quot;, prediction)

except Exception as e:
print(f&quot;处理图像时出错：{e}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image-in-python</guid>
      <pubDate>Mon, 02 Dec 2024 08:03:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练过程中测试集损失逐渐增加？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79243289/why-does-the-test-set-loss-increase-gradually-during-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79243289/why-does-the-test-set-loss-increase-gradually-during-training</guid>
      <pubDate>Mon, 02 Dec 2024 07:42:20 GMT</pubDate>
    </item>
    <item>
      <title>由 AI ML 提供支持的聊天机器人 [关闭]</title>
      <link>https://stackoverflow.com/questions/79243253/ai-ml-powered-chat-bot</link>
      <description><![CDATA[我想创建一个聊天机器人或 slack bot/app 类型的应用程序，用于解决用户问题。例如，如果用户发布他们遇到的一些构建问题或错误，机器人应该能够读取 slack 频道中以前的聊天记录以查找类似问题，并能够为用户提供一些答案。是否可以开发类似的东西。基本上，我是一名 Java 开发人员，我是 Python 的新手。它可能涉及与 AI/ML 相关的东西，我不知道。有人可以指导我应该学习什么才能开发上述应用程序/设计吗？]]></description>
      <guid>https://stackoverflow.com/questions/79243253/ai-ml-powered-chat-bot</guid>
      <pubDate>Mon, 02 Dec 2024 07:25:49 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 中使用 Thundersvm</title>
      <link>https://stackoverflow.com/questions/79243091/using-thundersvm-in-kaggle</link>
      <description><![CDATA[当我想使用 !pip install thundersvm 在 kaggle 中安装 thundersvm 时，我遇到了此错误：
---------------------------------------------------------------------------
OSError Traceback (most recent call last)
Cell In[6], line 3
1 get_ipython().run_line_magic(&#39;pip&#39;, &#39;install thundersvm&#39;)
2 get_ipython().run_line_magic(&#39;pip&#39;, &#39;install keras_tuner&#39;)
----&gt; 3 from thundersvm import SVC
4 from sklearn.preprocessing import StandardScaler
5 from sklearn.metrics import classes_report

File /opt/conda/lib/python3.10/site-packages/thundersvm/__init__.py:10
3 &quot;&quot;&quot;
4 * 名称 : __init__.py
5 * 作者 : Locke &lt;luojiahuan001@gmail.com&gt;
6 * 版本 : 0.0.1
7 * 说明 :
8 &quot;&quot;&quot;
9 name = &quot;thundersvm&quot;
---&gt; 10 from .thundersvm import *

File /opt/conda/lib/python3.10/site-packages/thundersvm/thundersvm.py:39
36 lib_path = path.join(dirname, shared_library_name)
38 if path.exists(lib_path):
---&gt; 39 thundersvm = CDLL(lib_path)
40 else:
41 # 尝试构建目录
42 if platform == &quot;linux&quot;或平台 == &quot;linux2&quot;:

文件 /opt/conda/lib/python3.10/ctypes/__init__.py:374，在 CDLL.__init__(self, name, mode, handle, use_errno, use_last_error, winmode) 中
371 self._FuncPtr = _FuncPtr
373 如果句柄为 None:
--&gt; 374 self._handle = _dlopen(self._name, mode)
375 else:
376 self._handle = handle

OSError: libcusparse.so.9.0: 无法打开共享对象文件：没有此文件或目录

为了修复此问题，我尝试了以下方法：
# 下载并安装 CUDA 9.0
wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run
sudo sh cuda_9.0.176_384.81_linux-run

此方法也不起作用。我该如何修复此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79243091/using-thundersvm-in-kaggle</guid>
      <pubDate>Mon, 02 Dec 2024 06:08:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中使用 ImageAI 加载自定义训练的 ResNet50 模型？</title>
      <link>https://stackoverflow.com/questions/79242938/how-to-load-a-custom-trained-resnet50-model-with-imageai-in-python</link>
      <description><![CDATA[我正在使用 ImageAI 的自定义训练 ResNet50 模型进行图像分类项目，但遇到了持续的加载错误，导致我无法使用训练好的模型进行预测。该错误表明在尝试将自定义训练的 PyTorch 模型加载到 ImageAI 框架时存在兼容性问题或缺少特定方法。
我尝试使用 ImageAI 的标准模型加载程序加载自定义训练的 ResNet50 模型：
from imageai.Classification import ImageClassification

classifier = ImageClassification()
classifier.setModelPath(&quot;path/to/custom/model.pt&quot;)
classifier.setModelTypeAsResNet50()
classifier.loadModel() # 预计会成功加载模型

我期望的是一个类似于使用预训练模型的简单模型加载过程。相反，我收到了一个令人沮丧的错误：
分类失败：模型尚未加载。执行图像分类之前，您需要调用 &#39;.loadModel()&#39;


我的环境详情：

Python 3.12
ImageAI 3.0.3
PyTorch 2.5.1+cu118
Windows 11

我已确认：

模型路径正确
模型已保存为有效的 .pt 文件
该模型使用 ResNet50 架构在自定义数据集上进行训练

具体问题：

ImageAI 中是否有加载自定义训练模型的特定方法？
自定义模型是否有任何特殊的导出或转换要求？
我需要修改我的模型的状态字典或使用特定的导出格式？
]]></description>
      <guid>https://stackoverflow.com/questions/79242938/how-to-load-a-custom-trained-resnet50-model-with-imageai-in-python</guid>
      <pubDate>Mon, 02 Dec 2024 04:07:18 GMT</pubDate>
    </item>
    <item>
      <title>通过 Streamlit 上的 YFinance 获取数据 [关闭]</title>
      <link>https://stackoverflow.com/questions/79242889/fetching-data-via-yfinance-on-streamlit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79242889/fetching-data-via-yfinance-on-streamlit</guid>
      <pubDate>Mon, 02 Dec 2024 03:31:17 GMT</pubDate>
    </item>
    <item>
      <title>在简单数据集上使用分类器。使用分数时出错</title>
      <link>https://stackoverflow.com/questions/79241877/use-of-classifiers-on-a-simple-dataset-error-using-score</link>
      <description><![CDATA[我是 ML 新手，我正在尝试在一个简单的数据集上使用分类器

labels = [1, 0, 1, 0, 1, 0] 
data = pd.DataFrame({
&#39;Delta&#39;: delta_energy,
&#39;Theta&#39;: theta_energy,
&#39;Alpha&#39;: alpha_energy,
&#39;Beta&#39;: beta_energy,
&#39;Gamma&#39;: gamma_energy,
&#39;Label&#39;: labels
})

但是我在尝试运行此代码后遇到了错误 - AttributeError: &#39;NoneType&#39; 对象没有属性 &#39;split&#39;
clf_index = 5
feature_indexes = [0,3]
names = [
&quot;Nearest Neighbors&quot;,
&quot;Linear SVM&quot;,
&quot;RBF SVM&quot;,
&quot;高斯过程&quot;,
&quot;决策树&quot;,
&quot;随机森林&quot;,
&quot;神经网络&quot;,
&quot;AdaBoost&quot;,
&quot;朴素贝叶斯&quot;,
&quot;QDA&quot;,
]
分类器 = [
KNeighborsClassifier(3),
SVC(kernel=&quot;linear&quot;, C=0.025, random_state=42),
SVC(gamma=2, C=1, random_state=42),
GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),
DecisionTreeClassifier(max_depth=5, random_state=42),
RandomForestClassifier(
max_depth=5, n_estimators=10, max_features=1, random_state=42
),
MLPClassifier(max_iter=1000, random_state=42),
AdaBoostClassifier(algorithm=&quot;SAMME&quot;, random_state=42),
GaussianNB(),
QuadraticDiscriminantAnalysis(),
]
table_data = (data.values[:,feature_indexes], data[data.columns[clf_index]])
datasets = [table_data]
figure = plt.figure(figsize=(27, 3))
i = 1
for ds_cnt, ds in enumerate(datasets):
X, y = ds
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.3, random_state=42
)

x_range = abs(X[:, 0].max()) - abs(X[:, 0].min())
y_range = abs(X[:, 1].max()) - abs(X[:, 1].min())

x_min, x_max = X[:, 0].min() - 0.05*x_range, X[:, 0].max() + 0.05*x_range
y_min, y_max = X[:, 1].min() - 0.05*y_range, X[:, 1].max() + 0.05*y_range

# 先绘制数据集，红色和蓝色 = 0000FF 颜色。红色 = 0。蓝色 = 1 状态
cm = plt.cm.RdBu
cm_bright = ListedColormap([&quot;#FF0000&quot;, &quot;#0000FF&quot;])
ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
if ds_cnt == 0:
ax.set_title(&quot;Input data&quot;)
# 绘制训练点
ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=&quot;k&quot;)
# 绘制测试点
ax.scatter(
X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=&quot;k&quot;
)
ax.set_xlim(x_min, x_max)
ax.set_ylim(y_min, y_max)
ax.set_xlabel(data.columns[feature_indexes[0]])
ax.set_ylabel(data.columns[feature_indexes[1]])
i += 1
for name, clf in zip(names, classifiers):
ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
clf = make_pipeline(StandardScaler(), clf)
clf.fit(X_train, y_train)
score = clf.score(X_test, y_test)
DecisionBoundaryDisplay.from_estimator(
clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5
)
# 绘制训练点
ax.scatter(
X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=&quot;k&quot;
)
# 绘制测试点
ax.scatter(
X_test[:, 0],
X_test[:, 1],
c=y_test,
cmap=cm_bright,
edgecolors=&quot;grey&quot;,
alpha=0.4,
)
ax.set_xlim(x_min, x_max)
ax.set_ylim(y_min, y_max)
ax.set_xticks(())
ax.set_yticks(())
if ds_cnt == 0:
ax.set_title(name)
ax.text(
x_max - x_range*0.1,
y_min + y_range*0.1,
(&quot;%.2f&quot; % score).lstrip(&quot;0&quot;),
size=25,
Horizo​​ntalalignment=&quot;right&quot;,
)
i += 1

plt.tight_layout()
plt.show()

在这个特定位置：clf = make_pipeline(StandardScaler(), clf)
clf.fit(X_train, y_train) 我该如何修复它？我尝试更改数据集，但仍然不起作用]]></description>
      <guid>https://stackoverflow.com/questions/79241877/use-of-classifiers-on-a-simple-dataset-error-using-score</guid>
      <pubDate>Sun, 01 Dec 2024 15:20:56 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 不接受数据集生成器的列表类型</title>
      <link>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</link>
      <description><![CDATA[我正在构建一个神经网络。我无法一次性将所有训练数据加载到内存中，因此我使用 TensorFlow 的 tf.data.Dataset.from_generator 函数逐步加载数据。但是，它会抛出一个错误，指出它不接受张量列表作为类型。
TypeError：`output_signature` 必须包含属于 
`tf.TypeSpec` 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。

我的神经网络的输入是 151 个独立张量的列表。我如何在生成器中表示它？我的代码如下：
def generator(file_paths, batch_size, files_per_batch, tam, value):
return tf.data.Dataset.from_generator(
lambda: data_generator(file_paths, batch_size, files_per_batch, tam, value),
output_signature=(
[tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) for _ in range(tam+1)], # 151 个张量列表
tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) # 数组
)
)

inputArray = [Input(shape=(tam,)) for _ in range(tam + 1)]

train_dataset = generator(file_paths, batch_size, files_per_batch, tam, False)
train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)

model.fit(train_dataset, epochs=1000, validation_split=0.2, verbose=1)

我尝试使用 tf.data.Dataset.from_generator 将数据批量输入到我的神经网络中，因为我无法一次将所有数据加载到内存中。
但是，我遇到了一个错误：
TypeError：output_signature 必须包含属于 tf.TypeSpec 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。
]]></description>
      <guid>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</guid>
      <pubDate>Sun, 01 Dec 2024 13:13:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中实现 Softmax，其中输入是有符号的 8 个整数</title>
      <link>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</link>
      <description><![CDATA[我正在尝试实现一个softmax 函数，该函数接受有符号的 int8 输入并返回有符号的 int8 输出数组。
我目前正在进行的实现是这样的，
 import numpy as np

def softmax_int8(inputs):
input = np.array(inputs, dtype=np.int8)

x = input.astype(np.int32)
x_max = np.max(x)
x_shifted = x - x_max
scale_factor = 2 ** 14
exp_limit = 16
exp_x = np.clip(x_shifted + exp_limit, 0, None)
exp_x = (1 &lt;&lt; exp_x)
sum_exp_x = np.sum(exp_x)

如果 sum_exp_x == 0:
sum_exp_x = 1

softmax_probs = (exp_x * scale_factor) // sum_exp_x
max_prob = np.max(softmax_probs)
min_prob = np.min(softmax_probs)
range_prob = max_prob - min_prob 如果 max_prob != min_prob 否则 1

scaled_probs = ((softmax_probs - min_prob) * 255) // range_prob - 128
output = scaled_probs.astype(np.int8)

返回输出

我使用此输入进行测试，Input = [101, 49, 6, -34, -75, -79, -38, 120, -55, 115]
但我得到此输出 array([-128, -128, -128, -128, -128, -128, -128, 127, -128, -121],dtype=int8)。
我的预期输出是 array([-57, -70, -79, -86, -92, -94, -88, -54, -91, -56], dtype=int8)。
我在这里做错了什么，我该如何修复？]]></description>
      <guid>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</guid>
      <pubDate>Sat, 30 Nov 2024 09:37:57 GMT</pubDate>
    </item>
    <item>
      <title>计算多标签分类问题的 ROC 曲线、分类报告和混淆矩阵</title>
      <link>https://stackoverflow.com/questions/60857415/calculate-roc-curve-classification-report-and-confusion-matrix-for-multilabel-c</link>
      <description><![CDATA[我正在尝试了解如何为我的多标签分类问题创建混淆矩阵和 ROC 曲线。我正在构建一个神经网络。
以下是我的类别：
mlb = MultiLabelBinarizer()
ohe = mlb.fit_transform(as_list)
# 循环遍历每个可能的类别标签并显示它们
for (i, label) in enumerate(mlb.classes_):
print(&quot;{}. {}&quot;.format(i + 1, label))

[INFO] 类别标签：
1. class1
2. class2
3. class3
4. class4
5. class5
6. class6

我的标签已转换：
ohe
array([[0, 1, 0, 0, 1, 1],
[0, 1, 1, 1, 1, 0],
[1, 1, 1, 0, 1, 0],
[0, 1, 1, 1, 0, 1],...]]

训练数据：
array([[[[ 1.93965047e+04, 8.49532852e-01],
[ 1.93965047e+04, 8.49463479e-01],
[ 1.93965047e+04, 8.49474722e-01],
...,

模型：
model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt,metrics=[&quot;accuracy&quot;])
H = model.fit(trainX, trainY, batch_size=BS,
validation_data=(testX, testY),
epochs=EPOCHS, verbose=1)

我能够获得百分比，但我对如何计算混淆矩阵或 ROC 曲线或获取分类报告有点不知所措。
以下是百分比：
proba = model.predict(testX)
idxs = np.argsort(proba)[::-1][:2]

for i in proba:
print (&#39;\n&#39;)
for (label, p) in zip(mlb.classes_, i):
print(&quot;{}: {:.2f}%&quot;.format(label, p * 100))

class1: 69.41%
class2: 76.41%
class3: 58.02%
class4: 63.97%
class5: 48.91%
class6: 58.28%

class1: 69.37%
class2: 76.42%
class3: 58.01%
class4: 63.92%
class5: 48.88%
class6: 58.26%

如何操作，最好有例子？]]></description>
      <guid>https://stackoverflow.com/questions/60857415/calculate-roc-curve-classification-report-and-confusion-matrix-for-multilabel-c</guid>
      <pubDate>Wed, 25 Mar 2020 21:07:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 训练期间显示损失值？</title>
      <link>https://stackoverflow.com/questions/44443479/how-to-show-loss-values-during-training-in-scikit-learn</link>
      <description><![CDATA[我想在训练期间检查我的损失值，这样我就可以观察每次迭代的损失。到目前为止，我还没有找到一种简单的方法让 scikit learn 给我一个损失值的历史记录，也没有找到 scikit 中已有的为我绘制损失的功能。
如果没有办法绘制这个，如果我能在 classifier.fit 的末尾简单地获取最终的损失值就太好了。
注意：我知道有些解决方案是封闭形式的。我正在使用几个没有分析解决方案的分类器，例如逻辑回归和 svm。
有人有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/44443479/how-to-show-loss-values-during-training-in-scikit-learn</guid>
      <pubDate>Thu, 08 Jun 2017 18:50:55 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：估计器不适合，在利用模型之前调用“fit”</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在 Macbook OSX 10.2.1 (Sierra) 上运行 Python 3.5.2。
尝试运行 Kaggle 的 Titanic 数据集的一些代码时，我不断收到以下错误：


NotFittedError Traceback (most recent call
last) in ()
6 
7 # 使用测试集进行预测并打印它们。
----&gt; 8 my_prediction = my_tree_one.predict(test_features)
9 print(my_prediction)
10 
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input) 中
429 &quot;&quot;&quot;
430 
--&gt; 431 X = self._validate_X_predict(X, check_input)
432 proba = self.tree_.predict(X)
433 n_samples = X.shape[0]
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input)
386 “”“每当有人试图预测、应用、predict_proba 时验证 X”””
387 if self.tree_ is None:
--&gt; 388 raise NotFittedError(“估算器未安装，”
389 “在利用模型之前调用 fit。”)
390 
NotFittedError：估算器未安装，在利用
模型之前调用 fit。

有问题的代码似乎是这样的：
# 用中位数估算缺失值
test.Fare[152] = test.Fare.median()

# 从测试集中提取特征：Pclass、Sex、Age 和 Fare。
test_features = test[[&quot;Pclass&quot;, &quot;Sex&quot;, &quot;Age&quot;, &quot;Fare&quot;]].values

# 使用测试集进行预测并打印。
my_prediction = my_tree_one.predict(test_features)
print(my_prediction)

# 创建一个包含两列的数据框：PassengerId 和 Survived。 Survived 包含您的预测
PassengerId =np.array(test[&quot;PassengerId&quot;]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [&quot;Survived&quot;])
print(my_solution)

# 检查您的数据框是否有 418 个条目
print(my_solution.shape)

# 将您的解决方案写入名为 my_solution.csv 的 csv 文件
my_solution.to_csv(&quot;my_solution_one.csv&quot;, index_label = [&quot;PassengerId&quot;])

以下是其余部分的链接 代码。
由于我已经调用了“fit”函数，我无法理解此错误消息。我哪里做错了？感谢您的时间。
编辑：
结果发现该问题继承自上一个代码块。
# 拟合您的第一个决策树：my_tree_one
my_tree_one = tree.DecisionTreeClassifier()
my_tree_one = my_tree_one.fit(features_one, target)

# 查看所包含特征的重要性和分数
print(my_tree_one.feature_importances_)
print(my_tree_one.score(features_one, target))

使用以下行：
my_tree_one = my_tree_one.fit(features_one, target)
生成错误：

ValueError：输入包含 NaN、无穷大或对于
dtype(&#39;float32&#39;)。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>