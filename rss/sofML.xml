<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 13 Apr 2024 03:12:22 GMT</lastBuildDate>
    <item>
      <title>拟合投票回归器中权重的估计器预测[关闭]</title>
      <link>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</link>
      <description><![CDATA[投票回归器所做的似乎就是取平均值，除非您手动输入一些权重，但这看起来并不有效。对 x 和 y 中的所有预测进行线性拟合是否有意义以及它会是什么样子。我假设有一些限制的一阶线性拟合。
我尝试为其编写一些代码，这不是一项艰巨的任务，但我更好奇第二次拟合的统计实现，因为它感觉不“真实”。]]></description>
      <guid>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</guid>
      <pubDate>Fri, 12 Apr 2024 20:45:00 GMT</pubDate>
    </item>
    <item>
      <title>在用于大数据分析的 PySpark 中，面临使用哈希转换字符串特征的问题。有什么解决办法吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</link>
      <description><![CDATA[我是大数据分析新手，目前正在使用 PySpark 处理大数据机器学习任务，特别是信用卡欺诈检测。然而，我遇到了障碍。在我的数据集中，我有两个字符串特征，需要在构建模型之前将其转换为数值。我尝试过各种方法，例如one-hot编码和散列，但没有成功。下面，我提供我最近遇到的错误。您能否建议如何解决这个问题，或者是否有更好的方法来解决这个问题？如果需要，请随时询问任何其他信息，例如代码片段或其他信息。


大多数时候我都会面临这个错误和缓冲区溢出！

如果有人可以帮助我解决这种情况，请告诉我。几天来我尝试了不同的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</guid>
      <pubDate>Fri, 12 Apr 2024 17:09:42 GMT</pubDate>
    </item>
    <item>
      <title>如何修改我的代码，以便它可以使用网络摄像头正确预测</title>
      <link>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</guid>
      <pubDate>Fri, 12 Apr 2024 15:39:17 GMT</pubDate>
    </item>
    <item>
      <title>一些训练记录，以及训练后的一份记录 [关闭]</title>
      <link>https://stackoverflow.com/questions/78316879/a-few-records-for-training-and-one-record-after-training</link>
      <description><![CDATA[我尝试做一些信用评分任务。我陷入了概念问题。
有：
train_data（62 列、10339239 行、1250000 个唯一 ID 值 [0 - 1249999]（[最小-最大] ID 值） ),
test_data（62 列、4724601 行、500000 个唯一 ID 值 [3000000 - 3499999]（[最小-最大] ID 值） ),
train_target.csv（2列：ID和flag（flag是目标变量，必须预测)，有 361870 行，全部具有唯一的 ID，[0 - 361869]([min-max] ID 值)) ,
test_target.csv（1 列：ID，500000 行，所有 ID 都是唯一的，[3000000 - 3499999]([min- max] ID 值)) 。
需要为 test_target.csv 获取 [0,1] 范围内的分数。
train_data 和 test_data 有 62 列，ID、RN，...。两者都是对应的时间（如果日期时间较大，则 RN 的 ID 值会更大）。 ID表示信用/贷款请求，RN表示信用记录中的信用/贷款数量。 train_target.csv 中的 FLAG 表示：1-默认/破产。
我不知道如何针对这些数据训练模型。我尝试使用XGBoost。训练后的模型必须采用具有相同 ID 的 RN 排序的几条记录，并给出 [0, 1] 范围内的一个 FLAG 答案。如何才能做到这一点？ XGB分类器？或回归器？通过train_test_split还是TimeSeriesSplit？请问您能给我建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78316879/a-few-records-for-training-and-one-record-after-training</guid>
      <pubDate>Fri, 12 Apr 2024 14:19:39 GMT</pubDate>
    </item>
    <item>
      <title>重新称重预处理技术与 AdaBoost 的结合</title>
      <link>https://stackoverflow.com/questions/78316838/combination-of-reweighing-as-pre-processing-technique-and-adaboost</link>
      <description><![CDATA[我使用了预处理技术“重新称重”来消除数据集的偏差。该技术为我提供了一个列，其中包含每个实例的权重。对于重新称重，我使用了 AIF 360。
对于模型，我想使用 sklearn 的 AdaBoost 分类器。
将 .fit() 方法中的预处理技术的权重移交给 AdaBoost 分类器是否有意义？该参数为sample_weight。
有点不清楚我是否应该使用 class_weight 还是sample_weight。
我已经研究了应该使用什么参数，或者将权重交给 AdaBoost 是否有意义。然而，我觉得这项研究让我更加不清楚了。我知道 sklearn 的 AdaBoost 分类器没有 class_weight 参数。但如果将权重交给 AdaBoost 有意义的话，也许专家可以帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78316838/combination-of-reweighing-as-pre-processing-technique-and-adaboost</guid>
      <pubDate>Fri, 12 Apr 2024 14:11:12 GMT</pubDate>
    </item>
    <item>
      <title>这是对不平衡数据集进行过采样交叉验证的正确方法吗？</title>
      <link>https://stackoverflow.com/questions/78316022/is-this-the-right-way-to-do-cross-validation-with-oversampling-on-imbalance-data</link>
      <description><![CDATA[def stratified_cross_validation_metrics(模型, X, y, method=&#39;&#39;):
    指标={
        &#39;准确性&#39;： []，
        &#39;精确&#39;： []，
        &#39;记起&#39;： []，
        &#39;f1_score&#39;：[]
    }
    
    kf = StratifiedKFold(n_splits=10, shuffle=False)
    
    对于 kf.split(X, y) 中的 train_index、test_index：
        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]
        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]
        
        if method.lower() == &#39;adasyn&#39;:
            X_train_cv, y_train_cv = adasyn.fit_resample(X_train_cv, y_train_cv)
            X_test_cv, y_test_cv = adasyn.fit_resample(X_test_cv, y_test_cv)
        elif method.lower() == &#39;smote&#39;:
            X_train_cv, y_train_cv = smote.fit_resample(X_train_cv, y_train_cv)
            X_test_cv, y_test_cv = smote.fit_resample(X_test_cv, y_test_cv)
        
        model.fit(X_train_cv, y_train_cv)

        y_pred_cv = model.predict(X_test_cv)

        准确度=准确度_分数（y_test_cv，y_pred_cv）
        精度 = precision_score(y_test_cv, y_pred_cv, 平均值=&#39;加权&#39;)
        召回率=召回率（y_test_cv，y_pred_cv，平均值=&#39;加权&#39;）
        f1 = f1_score(y_test_cv, y_pred_cv, 平均值=&#39;加权&#39;)

        指标[&#39;准确度&#39;].append(准确度)
        指标[&#39;精度&#39;].append(精度)
        指标[&#39;recall&#39;].append(recall)
        指标[&#39;f1_score&#39;].append(f1)

    print(&quot;10 倍分层交叉验证的平均指标：&quot;)
    print(&quot;准确率：&quot;, np.mean(metrics[&#39;accuracy&#39;]))
    print(&quot;精度：&quot;, np.mean(metrics[&#39;精度&#39;]))
    print(&quot;召回率：&quot;, np.mean(metrics[&#39;recall&#39;]))
    print(&quot;F1 分数：&quot;, np.mean(metrics[&#39;f1_score&#39;]))

    df = pd.DataFrame(指标)
    
    返回df

我读到，当你使用过采样方法进行交叉验证时，你不应该首先过采样，这样它就不会泄漏到测试数据，所以我按照所示的方式执行函数，这是正确的方法还是我做错了什么？
对于不平衡数据集使用什么指标平均值比较好？]]></description>
      <guid>https://stackoverflow.com/questions/78316022/is-this-the-right-way-to-do-cross-validation-with-oversampling-on-imbalance-data</guid>
      <pubDate>Fri, 12 Apr 2024 11:37:37 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：操作数无法与形状一起广播 (10,1024) (1024,1) [关闭]</title>
      <link>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</guid>
      <pubDate>Fri, 12 Apr 2024 11:33:12 GMT</pubDate>
    </item>
    <item>
      <title>根据之前的元素，甚至不基于之前的元素，使用 LSTM 预测下一个元素</title>
      <link>https://stackoverflow.com/questions/78315830/predicting-next-elements-with-an-lstm-based-on-previous-ones-or-even-based-on</link>
      <description><![CDATA[我有一个时间序列问题，其中包括使用 LSTM 预测价格。该数据集是从 Python 库 yfinance 导入的。我在内置的极客教程中使用了示例代码Pytorch，并设法理解一切。我认为我不明白的唯一具体部分可以在这段代码片段中看到：
# 定义要预测的未来时间步数
预测步数 = 30

# 转换为 NumPy 并删除单一维度
sequence_to_plot = X_test.squeeze().cpu().numpy()

# 使用最后 30 个数据点作为起点
历史数据=序列到图[-1]
打印（历史数据.形状）

# 初始化一个列表来存储预测值
预测值 = []

# 使用训练好的模型来预测未来值
使用 torch.no_grad()：
    对于 _ 在范围内（num_forecast_steps*2）：
        # 准备历史数据张量
        历史数据张量 = torch.as_tensor(历史数据).view(1, -1, 1).float().to(设备)
        # 使用模型预测下一个值
        预测值 = 模型(历史数据张量).cpu().numpy()[0, 0]

        # 将预测值添加到forecasted_values列表中
        Forecasted_values.append(predicted_value[0])

        # 通过删除最旧的值并添加预测值来更新历史数据序列
        历史数据 = np.roll(历史数据, 移位=-1)
        历史数据[-1] = 预测值

        
# 生成未来日期
最后日期 = test_data.index[-1]

# 生成接下来的 30 个日期
future_dates = pd.date_range(start=last_date + pd.DateOffset(1), period=30)

# 将原始索引与未来日期连接起来
组合索引 = test_data.index.append(future_dates)

根据教程内容，使用滚动预测。这意味着，如果我是对的，带有输入元素的数组将用作预测下一个元素的窗口，该窗口将附加到窗口，以预测下一个元素，依此类推。我的问题可能与概念或代码的其他部分有关，但我不太理解这行代码：
# 将预测值追加到 Forecasted_values 列表中
Forecasted_values.append(predicted_value[0])

如果我想根据之前的 30 个元素来预测下一个元素，为什么我应该采用预测数组的第一个预测元素？ （对我来说，这意味着前 30 个输入序列的第二个元素）。如果我需要基于动态生成的值构建一个序列窗口，并且之前没有先前的元素，我该如何修改此示例？]]></description>
      <guid>https://stackoverflow.com/questions/78315830/predicting-next-elements-with-an-lstm-based-on-previous-ones-or-even-based-on</guid>
      <pubDate>Fri, 12 Apr 2024 11:01:41 GMT</pubDate>
    </item>
    <item>
      <title>读取包含字符串数据的 csv 文件时出现错误</title>
      <link>https://stackoverflow.com/questions/78315561/getting-error-while-reading-csv-file-with-string-data</link>
      <description><![CDATA[我正在编写 DeepLearning4j 代码来读取下面的 csv 文件：
键，值
员工 ID、同事 ID
员工证、工人证
员工证,员工证

下面是我尝试过的Java代码
 数据集 allData1;
    尝试 (RecordReader recordReader1 = new CSVRecordReader(1, &#39;,&#39;)) {
        recordReader1.initialize(new FileSplit(new ClassPathResource(“EmployeeData.txt”).getFile()));

        DataSetIterator 迭代器 = new RecordReaderDataSetIterator(recordReader1, 3, 1,1, true);
        allData1 = 迭代器.next();
    }

但是，导致以下错误..
线程“main”中出现异常java.lang.NumberFormatException：对于输入字符串：“员工 ID”
    在 java.base/jdk.internal.math.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2054)
    在 java.base/jdk.internal.math.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
    在 java.base/java.lang.Double.parseDouble(Double.java:651)
    在 org.datavec.api.writable.Text.toDouble(Text.java:590)
    在 org.datavec.api.util.ndarray.RecordConverter.toMinibatchArray(RecordConverter.java:207)
    在 org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next（RecordReaderMultiDataSetIterator.java:153）
    在 org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next（RecordReaderDataSetIterator.java:346）
    在 org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next（RecordReaderDataSetIterator.java:421）
    在 org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:53)

我哪里出错了？
此代码可以正常处理 CSV 文件中的 int 和 float 值...]]></description>
      <guid>https://stackoverflow.com/questions/78315561/getting-error-while-reading-csv-file-with-string-data</guid>
      <pubDate>Fri, 12 Apr 2024 10:10:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 检测 PDF 中选定的文本？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78314645/how-to-detect-selected-text-from-a-pdf-using-python</link>
      <description><![CDATA[我有一个 Python 程序，可以使用 PDF 查看器打开 PDF 文件。查看 PDF 时，我用鼠标光标选择一些文本。有没有办法让我的 Python 程序检测我选择的文本？
我知道 PyMuPDF、PyPDF2 和 pdfplumber 等库可用于从 PDF 中提取文本。不过，我正在专门寻找一种方法来检测我在查看 PDF 时以交互方式选择的文本。
如果无法从鼠标光标直接检测，是否有任何替代方法或解决方法可以实现类似的结果？
有什么见解或建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78314645/how-to-detect-selected-text-from-a-pdf-using-python</guid>
      <pubDate>Fri, 12 Apr 2024 06:57:54 GMT</pubDate>
    </item>
    <item>
      <title>训练时间融合网络 - 多少数据？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78313682/training-temporal-fusion-network-how-much-data</link>
      <description><![CDATA[关于多少数据足以训练时间融合变压器，是否有任何经验法则？更具体地说，我有大约 20 个特征，数据集大约有 50 万。这足够吗？对于多大的模型来说？
或者，我有大约 20 个产品，每个产品大约有 500k 行，而不是为每个“产品”训练不同的模型。也许我应该为所有产品训练一个模型以获得一个模型，然后定制它？
我知道这是非常高水平和模糊的，我只是在寻找一些经验法则和指导 - 我是否处于正确的范围，或者我应该去哪里？]]></description>
      <guid>https://stackoverflow.com/questions/78313682/training-temporal-fusion-network-how-much-data</guid>
      <pubDate>Fri, 12 Apr 2024 01:13:06 GMT</pubDate>
    </item>
    <item>
      <title>在运行 ML 项目时如何使用存储在 google Drive 中的数据集？</title>
      <link>https://stackoverflow.com/questions/78312337/how-can-i-use-the-dataset-that-is-stored-in-google-drive-while-running-ml-projec</link>
      <description><![CDATA[我正在运行 SoccerNet 项目，该项目为足球视频生成字幕。
我正在尝试将路径传递到存储数据集的 Google 云端硬盘，即 https://drive.google.com/drive/folders/{folder_id}
我正在运行的命令如下：
python main.py --SoccerNet_path=“https://drive.google.com/drive/folders/{folder_id}” --model_name=new_model --features=baidu_soccer_embeddings.npy --framerate=1 --pool=NetVLAD --window_size_caption=45 --window_size_spotting=15 --NMS_window=30 --num_layers=4 --first_stage=caption --pretrain --GPU=0

我收到操作系统错误：如下
OSError：[Errno 22] 参数无效：&#39;https:https://drive.google.com/drive/folders/{folder_id}?usp=drive_link\\england_epl\\2014-2015\\2015 -02-21 - 18-00 切尔西 1 - 1 伯恩利\\1_baidu_soccer_embeddings.npy&#39;

我尝试使用 google colab，但我没有得到 colab 中预期的输出，因为它没有生成应包含预期字幕的 json 文件。
我正在使用 VS 代码。]]></description>
      <guid>https://stackoverflow.com/questions/78312337/how-can-i-use-the-dataset-that-is-stored-in-google-drive-while-running-ml-projec</guid>
      <pubDate>Thu, 11 Apr 2024 18:15:53 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow federated 中工作时遇到“学习属性”错误</title>
      <link>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:24 GMT</pubDate>
    </item>
    <item>
      <title>Adam 优化器在 PyTorch 上进行预热</title>
      <link>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</link>
      <description><![CDATA[在论文Attention is all you need中，在在5.3节中，作者建议线性增加学习率，然后与步长的平方根倒数成比例地减少。

我们如何使用 Adam 优化器在 PyTorch 中实现这一点？最好没有额外的软件包。]]></description>
      <guid>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</guid>
      <pubDate>Thu, 17 Dec 2020 15:12:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 word2vec 对类别中的单词进行分类</title>
      <link>https://stackoverflow.com/questions/47666699/using-word2vec-to-classify-words-in-categories</link>
      <description><![CDATA[背景
我有带有一些示例数据的向量，每个向量都有一个类别名称（地点、颜色、名称）。
[&#39;约翰&#39;,&#39;杰伊&#39;,&#39;丹&#39;,&#39;内森&#39;,&#39;鲍勃&#39;] -&gt; “名字”
[&#39;黄色&#39;, &#39;红色&#39;, &#39;绿色&#39;] -&gt; &#39;颜色&#39;
[&#39;东京&#39;,&#39;北京&#39;,&#39;华盛顿&#39;,&#39;孟买&#39;] -&gt; “地方”

我的目标是训练一个模型，该模型采用新的输入字符串并预测它属于哪个类别。例如，如果新输入是“紫色”，那么我应该能够将“颜色”预测为正确的类别。如果新输入是“卡尔加里”，它应该将“地点”预测为正确的类别。
方法
我做了一些研究并发现了Word2vec。这个库有一个我可以使用的“相似性”和“最相似性”函数。所以我想到的一种强力方法如下：

接受新的输入。
计算它与每个向量中每个单词的相似度并取平均值。

例如，对于输入“粉红色”，我可以计算其与向量“名称”中单词的相似度，取平均值，然后对其他 2 个向量也执行此操作。给我最高相似度平均值的向量将是输入所属的正确向量。
问题
鉴于我在 NLP 和机器学习方面的知识有限，我不确定这是否是最好的方法，因此我正在寻求有关更好方法的帮助和建议来解决我的问题。我愿意接受所有建议，也请指出我可能犯的任何错误，因为我是机器学习和 NLP 世界的新手。]]></description>
      <guid>https://stackoverflow.com/questions/47666699/using-word2vec-to-classify-words-in-categories</guid>
      <pubDate>Wed, 06 Dec 2017 04:16:35 GMT</pubDate>
    </item>
    </channel>
</rss>