<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 15 Jun 2024 18:19:37 GMT</lastBuildDate>
    <item>
      <title>Chromadb EOFError：输入不足</title>
      <link>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</link>
      <description><![CDATA[我正在使用 chromadb 来保存我的向量嵌入。
过去几个月，数据库更新得很好。我突然收到以下错误：
EOFError：输入不足

以下代码是导致问题的代码。
collection.add(
documents=docs,
metadatas=metadatas,
ids=ids,
)

我不确定从哪里开始调试和修复这个问题。
完整错误如下：
文件“/var/www/panoraapp.com/public_html/api/genius/search_embeddings.py”，第 237 行，在 save_to_chroma 中
collection.add(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/api/models/Collection.py”，第 168 行，在 add 中
self._client._add(ids, self.id、嵌入、元数据、文档、uris)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/rate_limiting/__init__.py&quot;，第 45 行，在包装器中
return f(self, *args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py&quot;，第 372 行，在 _add 中
self._manager.hint_use_collection(collection_id, t.Operation.ADD)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 230 行，在 hint_use_collection 中
instance = self.get_segment(collection_id, type)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 217 行，在 get_segment 中
instance = self._instance(segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 246 行，在 _instance 中
instance = cls(self._system,segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py&quot;，第 107 行，在 __init__ 中
self._persist_data = PersistentData.load_from_file(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py”，第 70 行，位于 load_from_file
]]></description>
      <guid>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</guid>
      <pubDate>Sat, 15 Jun 2024 17:25:34 GMT</pubDate>
    </item>
    <item>
      <title>Keras 的 one_hot 对不同的词产生相同的值</title>
      <link>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</link>
      <description><![CDATA[我使用 keras 的 one_hot 函数将单词转换为数字。但出于某种原因，它会为不同的单词生成相同的数字。在下面的代码中，您可以看到 48 用于“amazing”，但 48 也用于“too”。这是为什么？
from tensorflow.keras.preprocessing.text import one_hot

reviews = [&#39;nice food&#39;,
&#39;amazing restaurant&#39;,
&#39;too good&#39;,
&#39;just loved it!&#39;,
&#39;will go again&#39;,
&#39;horrible food&#39;,
&#39;never go there&#39;,
&#39;poor service&#39;,
&#39;poor quality&#39;,
&#39;needs Improvement&#39;]

# 转换为 ont hot 向量 
encoded_reviews = [one_hot(d, vocab_size) for d in reviews]

当我打印coded_reviews 时，它显示：
[[13, 12],
[48, 44],
[48, 19],
[38, 28, 46],
[13, 29, 19],
[46, 12],
[19, 29, 4],
[18, 38],
[18, 35],
[42, 7]]
]]></description>
      <guid>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</guid>
      <pubDate>Sat, 15 Jun 2024 15:16:01 GMT</pubDate>
    </item>
    <item>
      <title>对文档执行 OCR 后，如何训练模型来检测文档中的键值对？[关闭]</title>
      <link>https://stackoverflow.com/questions/78626692/how-can-i-train-a-model-to-detect-key-value-pairs-in-documents-after-performing</link>
      <description><![CDATA[对所需文档执行 OCR 后，我希望能够从每个文档中提取键值对。可以将其视为与 Azure 的文档智能相同的方式。
我该怎么做？
到目前为止，我还没有真正尝试过任何事情，我一直在网上搜索并试图找到答案，但仍然一无所获。]]></description>
      <guid>https://stackoverflow.com/questions/78626692/how-can-i-train-a-model-to-detect-key-value-pairs-in-documents-after-performing</guid>
      <pubDate>Sat, 15 Jun 2024 13:07:55 GMT</pubDate>
    </item>
    <item>
      <title>验证期间批次大小的影响</title>
      <link>https://stackoverflow.com/questions/78626534/influence-of-batch-size-during-validation</link>
      <description><![CDATA[我想澄清一些与验证batch_size相关的疑问。
我正在研究二元分割。我有点困惑，我的计算 validation_loss 的函数是否正确。
我检查过类似的问题：批量大小是否会影响模型的准确性？
我通过修复种子等使我的代码具有确定性，
即对于具有相同 batch_size 的两个单独验证运行，我获得了相同的 validation_loss、f1 和 mae 值。
假设我有 valid_dataset1 = 5 张图像。

对于 batch_size = 1，我将获得一个验证损失每批次，最终验证损失除以 5。
对于 batch_size = 2，我将得到每批次一个验证损失，最终验证损失除以 3。

当我将 validation_batch_size 从 1 增加到 2 时，最终 F1 和 MAE 仍然相同，但验证损失略有不同。
这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78626534/influence-of-batch-size-during-validation</guid>
      <pubDate>Sat, 15 Jun 2024 12:02:06 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“ValueError：找到具有 0 个样本的数组（shape=(0, 5)），而 LinearRegression 至少需要 1 个。”</title>
      <link>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</guid>
      <pubDate>Sat, 15 Jun 2024 10:53:01 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层 Sequenced_4 从未被调用，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</link>
      <description><![CDATA[我尝试在 Grad cam 实现中使用它，但它显示这个错误。在下面我的 CNN 模型中-
import tensorflow as tf
from tensorflow.keras import layer

model = tf.keras.Sequential()

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, input_shape=(128,128,3), name=&#39;conv1&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool1&#39;))

model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv2&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool2&#39;))

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv3&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool3&#39;))

model.add(layers.Flatten(name=&#39;flatten&#39;))
model.add(layers.Dense(256,activation=&#39;relu&#39;, name=&#39;dense1&#39;))
model.add(layers.Dense(2,activation=tf.nn.sigmoid, name=&#39;dense2&#39;))

ValueError: 层 Sequenced_4 从未被调用，因此没有定义的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</guid>
      <pubDate>Sat, 15 Jun 2024 08:21:56 GMT</pubDate>
    </item>
    <item>
      <title>Python 中分类列的目标编码设置问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78625992/target-encoding-setup-issue-for-a-categorial-column-in-python</link>
      <description><![CDATA[我正在尝试对具有多个类别级别的一列进行目标编码。我首先将数据拆分为训练和测试以避免泄漏，然后尝试进行如下所示的编码：

X_train[&quot;Municipality&quot;] 和 y_train 没有 NA 值。X_train[&quot;Municipality&quot; 的类型是分类的，y_train 是浮点型

但我收到此错误，我不确定问题是什么。
当我尝试进行目标编码时，我认为它会起作用，因为列中没有 na 值，但由于某种原因，出现了与该列相关的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78625992/target-encoding-setup-issue-for-a-categorial-column-in-python</guid>
      <pubDate>Sat, 15 Jun 2024 08:04:28 GMT</pubDate>
    </item>
    <item>
      <title>将模型正确预测的图像传回模型进行训练是否会对我们产生任何有用的结果？</title>
      <link>https://stackoverflow.com/questions/78625950/would-passing-correctly-predicted-images-by-a-model-back-to-the-model-for-traini</link>
      <description><![CDATA[我没有所需的技术知识来尝试测试模型的指标以比较结果和假设，因此我依靠社区的智慧。
我试图寻找答案，但没有找到任何有用的东西（也许我的问题表述不正确）。
任何有关上述主题的指导都将不胜感激。
尝试谷歌搜索，期望找到一篇文章或一些答案，但没有找到任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/78625950/would-passing-correctly-predicted-images-by-a-model-back-to-the-model-for-traini</guid>
      <pubDate>Sat, 15 Jun 2024 07:41:59 GMT</pubDate>
    </item>
    <item>
      <title>在平面图图像中分割墙壁（纯黑色和条纹）[关闭]</title>
      <link>https://stackoverflow.com/questions/78625835/segmenting-walls-solid-black-striped-in-floorplan-images</link>
      <description><![CDATA[数据集中的示例图像
给定这样的平面图，我想执行家具检测（对象检测）和墙壁分割。
现在，在手动注释数据集中的图像后，家具检测是可行的。我总共有 57 幅图像，很难再获得更多图像。
我将在下面列出我尝试执行的墙壁分割方法。
墙壁分割 - 如果墙壁被分割出来，我可以删除图像中的所有其他项目并应用洪水填充来分割房间。
现在，我遇到了一个堆栈溢出帖子检测/分割填充的矩形 OpenCV。这有一种检测模式的方法，这正是我们在本例中所需要的。墙壁上画有成对的平行线，角度为 45 度。问题是我编写了一个锅炉代码，但不知道参数值，似乎根本无法得到结果。
我还发现了一种无监督方法，可以从平面图中分割出任何类型的墙壁 -&gt; https://refbase.cvc.uab.es/files/HFV2013.pdf。然而，阈值再次没有在任何地方指定，也没有提供指向 github repo 的链接。
有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78625835/segmenting-walls-solid-black-striped-in-floorplan-images</guid>
      <pubDate>Sat, 15 Jun 2024 06:46:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit-learn 在 Python 中对未标记数据实现层次聚类？</title>
      <link>https://stackoverflow.com/questions/78625589/how-to-implement-hierarchical-clustering-in-python-with-scikit-learn-for-unlabel</link>
      <description><![CDATA[我正在学习聚类，在尝试查找带有标记数据的数据库时遇到了一些问题，这对我来说是一个限制，因为我发现了非常有趣的未标记数据集。我读过各种无监督聚类技术，并想实现层次聚类。
我将数据加载到 pandas DataFrame 中，对数据进行标准化并应用层次聚类。然后我可视化了树状图，但我不确定如何解释结果或我是否使用了正确的参数。]]></description>
      <guid>https://stackoverflow.com/questions/78625589/how-to-implement-hierarchical-clustering-in-python-with-scikit-learn-for-unlabel</guid>
      <pubDate>Sat, 15 Jun 2024 04:03:59 GMT</pubDate>
    </item>
    <item>
      <title>了解 Vits 对 HiFi-GAN 的使用</title>
      <link>https://stackoverflow.com/questions/78625475/understanding-usage-of-hifi-gan-by-vits</link>
      <description><![CDATA[我正在（尝试）学习语音合成的 AI/ML，并尝试了解 Vits 如何使用 HiFi-GAN。
据我所知，Vits 会将文本输入转换为梅尔频谱图，然后由 HiFi-GAN 转换为音频波。
让我困惑的是为什么从 Vits 发送到 HiFi-GAN 的输入不是梅尔频谱图。
例如，当我测试其他模型并将以下代码添加到 HiFi-GAN 的 forward 方法时：
class Generator(torch.nn.Module):
...
def forward(self, x):
plot_spectrogram(x[0].cpu().detach().numpy(), &quot;mel_spec.png&quot;)
...
...

它保存了正确的图像，看起来像梅尔频谱图图像，但是，当我对 vits 执行相同操作时，保存的图像是纯绿色图像，当然不是梅尔频谱图的表示。
但生成的音频文件当然是有效的音频文件。
有人能向我解释一下吗？
我正在评估一些神经 tts 模型，我想要做的是保存由模型创建的梅尔频谱图，以便以后进行比较，并通过不同的声码器运行它们以进行比较。
我注意到 vits repo 中的 HiFi-GAN 代码与原始 repo 略有不同，但我不明白为什么。
有什么方法可以转换输入参数 x 转换为梅尔频谱图表示，而无需先将其转换为音频，然后再将音频转换为梅尔？]]></description>
      <guid>https://stackoverflow.com/questions/78625475/understanding-usage-of-hifi-gan-by-vits</guid>
      <pubDate>Sat, 15 Jun 2024 02:17:36 GMT</pubDate>
    </item>
    <item>
      <title>用于分割的视觉变换器[关闭]</title>
      <link>https://stackoverflow.com/questions/78625015/vision-transformer-for-segmentation</link>
      <description><![CDATA[我正在使用视觉转换器 (ViT) 进行图像分割，但我不确定要使用哪个分割头。
我知道我需要一个视觉转换器作为我的主干，以及一个分割头，以便根据给定输入图像的主干的学习表示生成图像分割。我可以将任何分割头与 ViT 主干一起使用吗，或者某些分割头是否适用于特定的 ViT 主干？
感谢任何可以提供一些见解的人！]]></description>
      <guid>https://stackoverflow.com/questions/78625015/vision-transformer-for-segmentation</guid>
      <pubDate>Fri, 14 Jun 2024 21:18:56 GMT</pubDate>
    </item>
    <item>
      <title>模型不适用于多类分割</title>
      <link>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</link>
      <description><![CDATA[我正在训练一个多类分割问题的模型。我有 3 个类，图像大小为 512x512 和 1 个通道。我的数据集中的类别不平衡。问题是该模型在多类分割方面表现不佳。
我尝试过交叉熵损失、Dice 损失、Jaccard 损失和损失组合（Jaccard + Focal）。
交叉熵工作正常，但结果并不令人满意。
我应该在其中进行哪些更改？
以下是模型的代码
class AxialDW(nn.Module):
def __init__(self, dim, mixer_kernel, dilation=1):
super().__init__()
h, w = mixer_kernel
self.dw_h = nn.Conv2d(dim, dim, kernel_size=(h, 1), padding=(max(h // 2, dilation), 0), groups=dim, dilation=dilation)
self.dw_w = nn.Conv2d(dim, dim, kernel_size=(1, w), padding=(0, max(w // 2, dilation)), groups=dim, dilation=dilation)

def forward(self, x):
x = x + self.dw_h(x) + self.dw_w(x)
返回 x

class EncoderBlock(nn.Module):
&quot;&quot;&quot;编码然后下采样&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.dw = AxialDW(in_c, mixer_kernel=(7, 7))
self.bn = nn.BatchNorm2d(in_c)
self.pw = nn.Conv2d(in_c, out_c, kernel_size=1)
self.down = nn.MaxPool2d((2, 2))
self.act = nn.GELU()

def forward(self, x):
skip = self.bn(self.dw(x))
x = self.act(self.down(self.pw(skip)))
return x, skip

class DecoderBlock(nn.Module):
&quot;&quot;&quot;上采样然后解码&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.up = nn.Upsample(scale_factor=2)
self.pw = nn.Conv2d(in_c + out_c, out_c, kernel_size=1)
self.bn = nn.BatchNorm2d(out_c)
self.dw = AxialDW(out_c, mixer_kernel=(7, 7))
self.act = nn.GELU()
self.pw2 = nn.Conv2d(out_c, out_c, kernel_size=1)

def forward(self, x, skip):
x = self.up(x)
x = torch.cat([x, skip], dim=1)
x = self.act(self.pw2(self.dw(self.bn(self.pw(x)))))
return x

class BottleNeckBlock(nn.Module):
&quot;&quot;&quot;轴向扩张 DW 卷积&quot;&quot;&quot;

def __init__(self, dim):
super().__init__()

gc = dim // 4
self.pw1 = nn.Conv2d(dim, gc, kernel_size=1)
self.dw1 = AxialDW(gc, mixer_kernel=(3, 3), dilation=1)
self.dw2 = AxialDW(gc, mixer_kernel=(3, 3), dilation=2)
self.dw3 = AxialDW(gc, mixer_kernel=(3, 3), dilation=3)

self.bn = nn.BatchNorm2d(4 * gc)
self.pw2 = nn.Conv2d(4 * gc, dim, kernel_size=1)
self.act = nn.GELU()

def forward(self, x):
x = self.pw1(x)
x = torch.cat([x, self.dw1(x), self.dw2(x), self.dw3(x)], 1)
x = self.act(self.pw2(self.bn(x)))
return x

class ULite(nn.Module):
def __init__(self, freeze_model, num_classes=3):
super().__init__()

&quot;&quot;&quot;Encoder&quot;&quot;&quot;
self.conv_in = nn.Conv2d(1, 16, kernel_size=7, padding=3)
self.e1 = EncoderBlock(16, 32)
self.e2 = EncoderBlock(32, 64)
self.e3 = EncoderBlock(64, 128)
self.e4 = EncoderBlock(128, 256)
self.e5 = EncoderBlock(256, 512)

“瓶颈”
self.b5 = BottleNeckBlock(512)

“解码器”
self.d5 = DecoderBlock(512, 256)
self.d4 = DecoderBlock(256, 128)
self.d3 = DecoderBlock(128, 64)
self.d2 = DecoderBlock(64, 32)
self.d1 = DecoderBlock(32, 16)
self.conv_out = nn.Conv2d(16, num_classes, kernel_size=1)

if freeze_model:
self.freeze_model()

def forward(self, x):
&quot;&quot;&quot;编码器&quot;&quot;&quot;
x = self.conv_in(x)
x, skip1 = self.e1(x)
x, skip2 = self.e2(x)
x, skip3 = self.e3(x)
x, skip4 = self.e4(x)
x, skip5 = self.e5(x)

“瓶颈” “” “”
x = self.b5(x) # (512, 8, 8)

“解码器” “” “”
x = self.d5(x, skip5)
x = self.d4(x, skip4)
x = self.d3(x, skip3)
x = self.d2(x, skip2)
x = self.d1(x, skip1)
x = self.conv_out(x)

# 应用 softmax 进行多类分类
x = F.softmax(x, dim=1)
return x

def freeze_model(self):
for name, param in self.named_pa​​rameters():
param.requires_grad = False

Jaccard + Focal Loss
Loss Image
Jaccard Loss
丢失图片]]></description>
      <guid>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</guid>
      <pubDate>Fri, 14 Jun 2024 19:30:25 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
Splitter/consolidator 工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中的 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);

var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var formedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我已检查，我的数据中没有 NaN，并且我的变量都不是 Null。我非常迷茫，不知道如何修复这个问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 BARTDecoder 和 cached_property 的 Nougat OCR 中的 ImportError 和 TypeError 问题</title>
      <link>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</guid>
      <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
    </item>
    </channel>
</rss>