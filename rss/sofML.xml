<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 12 Jul 2024 21:15:11 GMT</lastBuildDate>
    <item>
      <title>如何在不使用标签编码的情况下对 RandomForest 的非序数分类变量进行编码？</title>
      <link>https://stackoverflow.com/questions/78742216/how-to-encode-non-ordinal-categorical-variables-for-randomforest-without-using-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78742216/how-to-encode-non-ordinal-categorical-variables-for-randomforest-without-using-l</guid>
      <pubDate>Fri, 12 Jul 2024 21:11:51 GMT</pubDate>
    </item>
    <item>
      <title>二元分类中的 SHAP 值解释</title>
      <link>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</link>
      <description><![CDATA[我尝试使用每个特征的 SHAP 值来解释我的二元分类模型。我想知道：
正的 SHAP 值是否意味着该特征对预测“1”类的贡献更大，而负的 SHAP 值是否意味着该特征对预测“0”类的贡献更大？
如果我使用绝对 SHAP 值差异来描述特征贡献变化，这个想法是否合理？]]></description>
      <guid>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</guid>
      <pubDate>Fri, 12 Jul 2024 14:25:43 GMT</pubDate>
    </item>
    <item>
      <title>关于使用lstm模型的时间序列数据预测模型数据集</title>
      <link>https://stackoverflow.com/questions/78739703/about-time-series-data-prediction-model-dataset-using-lstm-model</link>
      <description><![CDATA[我有 1400 个地点的年平均交通量数据，并且有 2008 年至 2022 年的数据。目前，为了进行时间序列分析并创建预测模型，我们计划通过将 2008 年至 2019 年设置为训练数据、2020 年至 2021 年设置为验证数据、2022 年设置为测试数据来运行分析。我想使用 lstm 模型继续此方法，从时间序列分析中学习。我不确定如何正确设置和继续验证和测试数据比率。
目前，我们正尝试使用 2008 年的 2020 年数据作为训练数据，使用 2021 年数据作为验证数据，但数据数量不正确的错误仍然出现。]]></description>
      <guid>https://stackoverflow.com/questions/78739703/about-time-series-data-prediction-model-dataset-using-lstm-model</guid>
      <pubDate>Fri, 12 Jul 2024 09:51:37 GMT</pubDate>
    </item>
    <item>
      <title>如何并行化yolov5的Darknet53的卷积层（在一台电脑上）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</link>
      <description><![CDATA[我想把YOLOv5的主干算法拆分，部署在多块FPGA上，但是首先需要在一台电脑上把Darknet53卷积层划分成2个或多个区域，进行并行卷积操作。YOLOv5项目要学习什么？需要修改哪些文件？一堆YAML和common.py好混乱啊（YOLOVv5是最新版本）。
我已经在PC上部署了YOLOv5，也做了一些前期的研究，大部分的重点应该在models文件夹，models文件夹里有5个YAML网络配置文件，yolo.py，common.py等，现在想搞清楚研究的顺序，以及如何学习这些文件，在一台电脑上把Darknet53卷积层划分成2个或多个区域，进行并行卷积操作。]]></description>
      <guid>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</guid>
      <pubDate>Fri, 12 Jul 2024 07:10:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使adapter_conditioning_scale在多个T2I_Adapter中可训练？</title>
      <link>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</link>
      <description><![CDATA[下面是使用 Multi T2I_Adapter 的代码。如以下代码所示，adapter_conditioning_scale=[0.8, 0.8]，是手动设置的。
adapters = MultiAdapter(
[
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_keypose_sd14v1&quot;),
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_depth_sd14v1&quot;),
]
)
adapters = adapters.to(torch.float16)

pipe = StableDiffusionAdapterPipeline.from_pretrained(
&quot;CompVis/stable-diffusion-v1-4&quot;,
torch_dtype=torch.float16,
adapter=adapters,
).to(&quot;cuda&quot;)

image = pipe(prompt, cond, adapter_conditioning_scale=[0.8, 0.8]).images[0]
make_image_grid([cond_keypose, cond_depth, image], rows=1, cols=3)

Google 的 Colab
我们可以使用哪种 ML 技术来找到 adapter_conditioning_scale 的最佳值？
参考文献：
huggingface.co
T2IAdapter 代码]]></description>
      <guid>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</guid>
      <pubDate>Fri, 12 Jul 2024 06:45:55 GMT</pubDate>
    </item>
    <item>
      <title>查明代码文件中的错误来源[关闭]</title>
      <link>https://stackoverflow.com/questions/78738937/pinpointing-the-source-of-error-in-a-code-file</link>
      <description><![CDATA[我正在尝试实现一个小工具，它可以自动识别一组代码文件（作为输入）中的哪一部分代码导致了执行期间显示的错误文本。
错误可能是语法错误，也可能是逻辑错误。我还在考虑利用 llms 的 api 调用来更正代码。
据我所知，RAG 是必要的，因为我不可能将所有代码文件的数据都放入提示中，因为它肯定会超出上下文窗口的大小。这就是我尝试探索信息检索技术的原因。我知道一些 RAG 技术，如 RAG-fusion，但我想得到一些反馈和想法，了解我可以探索哪些其他方法/工具/模型。
代码调试问题可能存在我没有意识到的某些方面。任何帮助都非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78738937/pinpointing-the-source-of-error-in-a-code-file</guid>
      <pubDate>Fri, 12 Jul 2024 06:41:48 GMT</pubDate>
    </item>
    <item>
      <title>pytorch：ninja：构建已停止：子命令失败</title>
      <link>https://stackoverflow.com/questions/78738275/pytorch-ninja-build-stopped-subcommand-failed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78738275/pytorch-ninja-build-stopped-subcommand-failed</guid>
      <pubDate>Fri, 12 Jul 2024 01:57:54 GMT</pubDate>
    </item>
    <item>
      <title>在交互式笔记本中加载 Azure ML Studio 中已注册的模型</title>
      <link>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</link>
      <description><![CDATA[我正在使用 Azure 机器学习工作室，我的默认数据存储（blob 存储）中存储了一个 sklearn mlflow 模型，然后我将其注册为模型资产。在将其部署为批处理端点之前，如何将此模型加载到交互式笔记本中以执行一些快速模型推理和测试。
我看到了一篇链接为此处的帖子，建议在本地下载模型工件，但我不需要这样做。我应该能够直接从数据存储或注册的资产加载模型，而无需在多个位置复制模型。我尝试了以下操作，但没有成功。
从已注册的模型资产读取
import mlflow
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Model

ml_client = MLClient(DefaultAzureCredential(), &quot;&lt;subscription_id&gt;&quot;, &quot;&lt;resource_group&gt;&quot;, &quot;&lt;workspace_id&gt;&quot;)

model = ml_client.models.get(&quot;&lt;model_name&gt;&quot;, version=&quot;1&quot;)
loaded_model = mlflow.sklearn.load_model(model.id)

&gt;&gt;&gt; OSError：没有这样的文件或目录：...

从数据存储中读取
import mlflow

model_path = &quot;&lt;datastore_uri_to_model_folder&gt;&quot;
loaded_model = mlflow.sklearn.load_model(model_path)

&gt;&gt;&gt; DeserializationError：无法反序列化内容类型：text/html
]]></description>
      <guid>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</guid>
      <pubDate>Thu, 11 Jul 2024 16:45:51 GMT</pubDate>
    </item>
    <item>
      <title>检测图像中的算术运算符[关闭]</title>
      <link>https://stackoverflow.com/questions/78736359/detect-arithmetic-operators-in-an-image</link>
      <description><![CDATA[我使用 keras_ocr 创建了一个 OCR 脚本。输入是流程图（灰度图）。我想提取流程图图像的文本和形状坐标。但是，它不会提取诸如“+、-、*、/”之类的算术运算符。有时它也无法检测数值。这是我的完整脚本。
# 导入必要的库
import os
import matplotlib.pyplot as plt
import keras_ocr
import cv2
import numpy as np
from google.colab import drive
from symspellpy.symspellpy import SymSpell, Verbosity
import pkg_resources

class OCRProcessor:
def __init__(self):
# 创建用于 OCR 处理的管道
self.pipeline = keras_ocr.pipeline.Pipeline()

def __get_bbox(self, image_path):
try:
# 使用 OpenCV 读取图像
image = cv2.imread(image_path)
if image is None:
raise ValueError(f&quot;Image at path {image_path} could not be read.&quot;)

# 将图像转换为 RGB（keras-ocr 需要 RGB 图像）
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# 使用 OCR 管道检测文本
images = keras_ocr.tools.read(image_path)
self.image = images
prediction_groups = self.pipeline.recognize([images])

if not prediction_groups or not prediction_groups[0]:
return [], []

# 提取边界框和文本
texts = []
results = []
for text, box in prediction_groups[0]:
texts.append(text)
xs, ys = set(), set()
for x in box:
xs.add(x[0])
ys.add(x[1])
results.append(list(map(int, [min(xs), min(ys), max(xs), max(ys)]))) # ymin, xmin, ymax, xmax

return texts, results
except Exception as e:
print(f&quot;An error occurred in __get_bbox: {e}&quot;)
return [], []

def process_image(self, image_path):
return self.__get_bbox(image_path)

# 定义函数来更正文本
def correct_text(text_array):
# 初始化 SymSpell 对象
sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)

# 加载字典
dictionary_path = pkg_resources.resource_filename(
&quot;symspellpy&quot;, &quot;frequency_dictionary_en_82_765.txt&quot;)
sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)

corrected_text_array = []
for text in text_array:
suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)
if suggestions:
corrected_text_array.append(suggestions[0].term)
else:
corrected_text_array.append(text)
return corrected_text_array

# 主函数
def main(image_path):
ocr_processor = OCRProcessor()
ex_text, ex_co = ocr_processor.process_image(image_path)
if not ex_text:
print(f&quot;在路径 {image_path} 处的图像中未检测到文本。&quot;)
return [], [], []

# 更正提取的文本
cr_text = correct_text(ex_text)

# 打印结果
print(&quot;提取的文本：&quot;, ex_text)
print(&quot;更正的文本：&quot;, cr_text)
print(&quot;Extracted Coordinates:&quot;, ex_co)

return ex_text, cr_text, ex_co

# 示例用法（您可以根据需要更新图像路径）
image_path = &#39;/content/Test2.jpg&#39;
ex_text, cr_text, ex_co = main(image_path)

ex_shape, ex_coor = detect_shapes(image_path)

# 打印或使用结果
print(&quot;Detected Shapes:&quot;, ex_shape)
print(&quot;Coordinates for Shapes:&quot;, ex_coor)

当我输入如下所示的流程图图像时，

它会生成一个文本和坐标，如下：
{{&#39;start&#39;,&#39;input&#39;,&#39;as&#39;,&#39;a&#39;,&#39;product&#39;,&#39;axe&#39;,&#39;a&#39;,&#39;print&#39;,&#39;product&#39;,&#39;end&#39;}}

问题是它无法检测到某些算术运算符。有没有什么解决方案可以解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/78736359/detect-arithmetic-operators-in-an-image</guid>
      <pubDate>Thu, 11 Jul 2024 15:09:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的空间数据管理机器学习模型中的类别不平衡问题</title>
      <link>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</guid>
      <pubDate>Thu, 11 Jul 2024 05:01:17 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow keras Model.fit 返回：ValueError：无法识别的数据类型</title>
      <link>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</link>
      <description><![CDATA[我尝试用 2 个输入来训练 keras 模型：一个图像部分，即 tf.data.Dataset 和一个由 pd.DataFrame 表示的正常部分&gt;
from tensorflow.keras.optimizers import Adam
opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)

model.compile(loss=&quot;mean_absolute_percentage_error&quot;, optimizer=opt)

model.fit(
x=[df.loc[:, df.columns != &#39;target&#39;], ds.batch(8)], y=df[&quot;target&quot;],
epochs=200)

我尝试拟合模型，但我得到了ValueError
ValueError：无法识别的数据类型：x=[...][401059 行 x 52 列]
，&lt;_BatchDataset element_spec=(TensorSpec(shape=(None, 32, 256, 256, 3), 
dtype=tf.float32, name=None), 
TensorSpec(shape=(None, 32, 256, 256, 3), dtype=tf.float32, name=None))&gt;]（类型为 &lt;class &#39;list&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</guid>
      <pubDate>Wed, 10 Jul 2024 15:36:58 GMT</pubDate>
    </item>
    <item>
      <title>在 Android Studio 中集成已训练的模型</title>
      <link>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</guid>
      <pubDate>Wed, 10 Jul 2024 11:31:14 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的梯度消失</title>
      <link>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</guid>
      <pubDate>Wed, 03 Jul 2024 03:59:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-does-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-does-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.layers”没有属性“experimental”</title>
      <link>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</link>
      <description><![CDATA[你好，我试图调整数据集的大小和比例，如下所示，但遇到了此错误：
AttributeError：模块“keras.layers”没有属性“experimental”

resize_and_rescale= tf.keras.Sequential([
layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),
layers.experimental.preprocessing.Rescaling(1.0/255)
])

]]></description>
      <guid>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</guid>
      <pubDate>Wed, 14 Dec 2022 00:43:49 GMT</pubDate>
    </item>
    </channel>
</rss>