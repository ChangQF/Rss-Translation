<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 05 Apr 2024 06:17:56 GMT</lastBuildDate>
    <item>
      <title>机器学习 | ECG 信号预处理、峰值检测和绘图</title>
      <link>https://stackoverflow.com/questions/78277984/ml-ecg-signal-preprocessing-peak-detection-and-plotting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78277984/ml-ecg-signal-preprocessing-peak-detection-and-plotting</guid>
      <pubDate>Fri, 05 Apr 2024 05:51:11 GMT</pubDate>
    </item>
    <item>
      <title>如何找到不同公司竞争对手产品矩阵与特定品牌数据集的相关性？有机器学习来预测适合度吗？</title>
      <link>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</link>
      <description><![CDATA[我非常感谢有关此挑战的任何建议，我正在尝试找到数据集（矩阵）的相关性，该数据集（矩阵）包含行上的客户和他们按列拥有的竞争对手产品（拥有=&#39;是&#39;，不拥有= “否”）以及拥有我们品牌的客户的另一个数据集（拥有=1，不拥有=0）。我可以使用任何机器学习模型或算法来根据客户拥有的产品来预测客户的适合度吗？请记住，我们品牌数据集中的所有零值都是潜在客户。
我尝试了随机森林，但我们对拥有我们品牌的客户的所有价值观都是积极的，我如何根据所有积极的价值观来预测适合度？]]></description>
      <guid>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</guid>
      <pubDate>Fri, 05 Apr 2024 00:53:35 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow”没有属性“Summary”</title>
      <link>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</link>
      <description><![CDATA[运行此代码时：
def scalar_summary(自身、标签、值、步骤)：
“”“记录标量变量。”“”
摘要 = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])
self.writer.add_summary(摘要，步骤)
我收到错误消息：
AttributeError：模块“tensorflow”没有属性“Summary”。您指的是：“摘要”吗？
我正在尝试运行来自 https:/ 的代码Google colabs 上的 /github.com/InhwanBae/ENet-SAD_Pytorch/blob/master/utils/tensorboard.py。我正在尝试使用 CULane 数据集训练 ENet-SAD 模型。]]></description>
      <guid>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</guid>
      <pubDate>Fri, 05 Apr 2024 00:51:51 GMT</pubDate>
    </item>
    <item>
      <title>Keras 3 与 Pytorch 后端 - 自定义 test_step</title>
      <link>https://stackoverflow.com/questions/78277162/keras-3-with-pytorch-backend-custom-test-step</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78277162/keras-3-with-pytorch-backend-custom-test-step</guid>
      <pubDate>Fri, 05 Apr 2024 00:00:45 GMT</pubDate>
    </item>
    <item>
      <title>线性回归调整问题：学习率与方程精度 (Python)</title>
      <link>https://stackoverflow.com/questions/78276066/linear-regression-adjustment-issue-learning-rate-vs-equation-accuracy-python</link>
      <description><![CDATA[我正在尝试以 0.01 的学习率调整线性回归。但是，我遇到了一个问题，线路似乎无法正确调整。该线似乎没有遵循学习率规定的预期路径，而是随机移动到不同的位置，而没有正确对齐。我确信这不是因为学习率，而是因为方程。
这是我尝试过的
from sklearn.datasets import make_regression, make_classification, make_blobs
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
将随机导入为 rd

# 1.make_regression
x, y = make_regression(
  n_样本=100，
  n_特征=1，
  噪音=30
）

# 2.make_classification
train_x = x[:-20]
test_x = x[-20:]

train_y = y[:-20]
test_y = y[-20:]

# 3.make_blob
def graph_linear_regression():
  # 绘制数据
  plt.scatter(train_x, train_y, color=&#39;blue&#39;, label=&#39;Data&#39;)

  # 绘制线性回归线
  plt.plot(train_x, train_x, color=&#39;red&#39;, label=&#39;线性回归&#39;)

  # 添加标签和标题
  plt.xlabel(&#39;x&#39;)
  plt.ylabel(&#39;y&#39;)
  plt.title(&#39;线性回归&#39;)

  # 显示绘图
  plt.图例()
  plt.show()

# 4.计算误差
defcalculate_update_error():
  全球米
  全球b
  学习率 = 0.01
  # 计算误差
  # M = 1/n * 总和(f(x) - y)
  # B = 1/n * 总和(f(x) - y) * x

  M = 1 / n * np.sum(f(train_x) - train_y)
  B = 1 / n * np.sum(np.sum(f(train_x) - train_y) * train_x)

  m = m - 学习率 * M
  b = b - 学习率 * B

# 计算线性回归
# 步骤 1 - 初始化

m = rd.randint(1, 100)
b = rd.randint(1, 100)
n = len(train_x)
学习率 = 0.01

打印（f“n：{n}”）
打印（f“m：{m}”）
打印（f“b：{b}”）
print(f“学习率：{学习率}”)

定义 f(x):
  返回 m * x + b

＃ 问题？
对于范围 (n) 内的 i：
  计算更新错误()
  打印（）

graph_linear_regression()

这就是我得到的
在此处输入图片描述
现在，这就是我想要获得的，这是使用最小平方
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78276066/linear-regression-adjustment-issue-learning-rate-vs-equation-accuracy-python</guid>
      <pubDate>Thu, 04 Apr 2024 18:58:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么在启用 from_logits 的情况下使用 BinaryCrossEntropy 生成器损失？</title>
      <link>https://stackoverflow.com/questions/78275777/why-generator-loss-using-binarycrossentropy-with-from-logits-enabled</link>
      <description><![CDATA[从简单的普通 GAN 代码中，我查看  GitHub
我看到这个生成器模型具有激活sigmoid：
&lt;前&gt;&lt;代码&gt;# 生成器
G = tf.keras.models.Sequential([
  tf.keras.layers.Dense(28*28 // 2, input_shape = (z_dim,), 激活=&#39;relu&#39;),
  tf.keras.layers.Dense(28*28, 激活=&#39;sigmoid&#39;),
  tf.keras.layers.Reshape((28, 28))])

在启用 from_logits 的情况下，G 的损失定义如下：
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)
def G_loss(D, x_fake):
  返回 cross_entropy(tf.ones_like(D(x_fake)), D(x_fake))

据我所知，from_logits=True旨在使损失函数接受范围在-infinity到&lt;之间的y_pred值代码&gt;无穷大。与 from_logits=False 相反，损失函数假设值的范围在 0 到 1 之间。
如您所见，G 模型的输出层已经具有 sigmoid 激活，其范围在 0 到 1.
但是，为什么作者仍然使用 from_logits=True？]]></description>
      <guid>https://stackoverflow.com/questions/78275777/why-generator-loss-using-binarycrossentropy-with-from-logits-enabled</guid>
      <pubDate>Thu, 04 Apr 2024 18:03:32 GMT</pubDate>
    </item>
    <item>
      <title>如何得到Adam训练时的平均学习率？</title>
      <link>https://stackoverflow.com/questions/78275586/how-to-get-the-average-learning-rate-for-adam-during-training</link>
      <description><![CDATA[Adam 优化器的每个参数都有一个自适应学习率，该学习率在训练期间会发生变化。我试图获得所有参数的平均学习率。我发现这个SO问题有一个相关的问题，并且建议使用答案之一（没有接受此问题的答案）
def get_current_lr（优化器，group_idx，parameter_idx）：
    # Adam 对每个参数都有不同的学习率。所以我们需要选择
    # 首先是组和参数。
    组=optimizer.param_groups[group_idx]
    p = 组[&#39;params&#39;][parameter_idx]

    beta1, _ = 组[&#39;betas&#39;]
    状态 = 优化器.状态[p]

    bias_ Correction1 = 1 - beta1 ** 状态[&#39;step&#39;]
    current_lr = group[&#39;lr&#39;] /bias_ Correction1 / torch.sqrt(state[&#39;exp_avg_sq&#39;] + 1e-8)
    返回当前_lr

我尝试根据我的情况调整它以获得平均值，但结果没有多大意义，因为学习率似乎高得离谱（有时超过 15）。所以我想知道这是否是正确的方法，或者我是否遗漏了一些东西。
导入火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim

火炬.manual_seed(42)

def get_current_lr(优化器):
    # Adam 对每个参数都有不同的学习率。所以我们需要选择
    # 首先是组和参数。
    劳斯莱斯 = []
    对于范围内的 group_idx(len(optimizer.param_groups))：
        组=optimizer.param_groups[group_idx]
        对于范围内的parameter_idx(len(opt.param_groups[group_idx][&#39;params&#39;]))：
            p = 组[&#39;params&#39;][parameter_idx]

            beta1, _ = 组[&#39;betas&#39;]
            状态 = 优化器.状态[p]

            bias_ Correction1 = 1 - beta1 ** 状态[&#39;step&#39;]
            current_lr = group[&#39;lr&#39;] /bias_ Correction1 / torch.sqrt(state[&#39;exp_avg_sq&#39;] + 1e-8)
            # 打印(current_lr.mean())
            lrs.append(current_lr.mean().item())

    返回总和(lrs)/len(lrs)

类模型（nn.Module）：
    def __init__(自身):
        超级（模型，自我）.__init__()
        self.fc1 = nn.Linear(10, 100)
        self.fc2 = nn.Linear(100, 1)

    def 前向（自身，x）：
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        返回x

净=模型（）
# opt = optim.SGD(net.parameters(), lr=1e-2)
opt = optim.Adam(net.parameters())

特征 = torch.rand((100,10))
x_goal = torch.tensor(100)

对于范围（100）内的纪元：
    x = 净值（特征）
    损失 = torch.square(x_goal - x).mean()
    opt.zero_grad()
    loss.backward()
    opt.step()
    如果纪元 % 5 == 0 ：
        打印（get_current_lr（选择））
&gt;&gt;&gt;&gt;&gt;
16.065366545983125
3.296213309022278
2.23316600310136
1.8703228593794847
1.7041209160006474
1.6200325103309297
1.5739126955249958
1.5481085549622549
1.5332565682870154
1.5246047580963022
1.5195341832059057
1.5165529197865908
1.5148021120267003
1.5137746352747854
1.5131711492076647
1.512817604085285
1.5126127881085267
1.5124981075282449
1.5124379168978521
1.5124109954704181
]]></description>
      <guid>https://stackoverflow.com/questions/78275586/how-to-get-the-average-learning-rate-for-adam-during-training</guid>
      <pubDate>Thu, 04 Apr 2024 17:26:49 GMT</pubDate>
    </item>
    <item>
      <title>验证集和测试集之间的性能差距（ResNet-18、k-Fold CV）</title>
      <link>https://stackoverflow.com/questions/78275584/performance-gap-between-validation-and-test-sets-resnet-18-k-fold-cv</link>
      <description><![CDATA[我正在使用 k 折交叉验证开发二值图像分类器 (ResNet-18)。训练过程中，模型的最高验证准确率达到99%。然而，在单独的测试集上，准确率下降至 92%。我还观察到损失函数有类似的趋势，其中验证损失比测试集损失更低。训练和测试数据中的标签分布是平衡的。
为什么验证集和测试集之间的性能存在如此显着的差异？]]></description>
      <guid>https://stackoverflow.com/questions/78275584/performance-gap-between-validation-and-test-sets-resnet-18-k-fold-cv</guid>
      <pubDate>Thu, 04 Apr 2024 17:26:41 GMT</pubDate>
    </item>
    <item>
      <title>可能是什么引发了错误：ValueError：X 有 23 个特征，但 SVR 期望 24 个特征作为输入？</title>
      <link>https://stackoverflow.com/questions/78275238/what-may-be-raising-the-error-valueerror-x-has-23-features-but-svr-is-expecti</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78275238/what-may-be-raising-the-error-valueerror-x-has-23-features-but-svr-is-expecti</guid>
      <pubDate>Thu, 04 Apr 2024 16:21:48 GMT</pubDate>
    </item>
    <item>
      <title>在 ARMA 模型中使用梯度下降进行系数估计</title>
      <link>https://stackoverflow.com/questions/78270443/using-gradient-descent-for-coefficient-estimation-in-arma-model</link>
      <description><![CDATA[我正在尝试使用梯度下降来估计其系数，从头开始实现 ARMA 模型。我知道这可能不是理想的解决方案。但我最担心的是，如果这不是一个正确的解决方案。
这是我的 ARMA 模型方程。为此，假设数据集已经静止。

为此，我采用了残差平方和，如下所示，
 
以及衍生品如下：

然后使用梯度下降算法，我可以获得所有系数的值。这是一个好方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78270443/using-gradient-descent-for-coefficient-estimation-in-arma-model</guid>
      <pubDate>Wed, 03 Apr 2024 20:50:17 GMT</pubDate>
    </item>
    <item>
      <title>我在测试模型时遇到未知层错误</title>
      <link>https://stackoverflow.com/questions/78268793/i-am-getting-unknown-layer-error-while-testing-a-model</link>
      <description><![CDATA[错误是这样的：
我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
2024-04-03 20:51:40.389067：我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
警告：tensorflow：来自 C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\tf_keras\src\losses.py:2976：名称 tf.losses.sparse_softmax_cross_entropy 已弃用。请改用 tf.compat.v1.losses.sparse_softmax_cross_entropy。
2024-04-03 20:51:47.709342: I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可以在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 AVX512F AVX512_VNNI FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
回溯（最近一次调用最后一次）：
文件“D:\image title\testing_caption_generator.py”，第 68 行，位于
模型 = 加载模型（
ValueError：未知层：“NotEqual”。请确保您使用的是 keras.utils.custom_object_scope 并且该对象包含在范围内。请参阅https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object 详细信息。
这是我的代码：
从 PIL 导入图像
将 matplotlib.pyplot 导入为 plt
导入argparse
进口泡菜
从 keras.models 导入 load_model
从 keras.layers 导入 Lambda
从 keras.applications.xception 导入 Xception
从 keras.preprocessing.sequence 导入 pad_sequences
从tensorflow.keras.preprocessing.text导入Tokenizer
from pickle import load # 从 pickle 模块导入 load 函数
导入tensorflow_hub作为集线器

# 定义自定义层
def NotEqual(x, y):
    将张量流导入为 tf
    返回 tf.math.not_equal(x, y)

# 定义用于提取特征、生成描述和其他必要实用程序的函数
def extract_features(文件名, 模型):
    尝试：
        图像 = Image.open(文件名)
    除了：
        print(&quot;错误：无法打开图像！请确保图像路径和扩展名正确&quot;)
    图像 = image.resize((299,299))
    图像 = np.array(图像)
    如果图像.shape[2] == 4:
        图像 = 图像[...,:3]
    图像 = np.expand_dims(图像, 轴=0)
    图像=图像/127.5
    图像 = 图像 - 1.0
    特征 = model.predict(图像)
    返回功能

def word_for_id(整数, 分词器):
    对于单词，在 tokenizer.word_index.items() 中索引：
        如果索引==整数：
            返回词
    返回无

defgenerate_desc（模型，分词器，照片，max_length）：
    in_text = &#39;开始&#39;
    对于范围内的 i（最大长度）：
        序列 = tokenizer.texts_to_sequences([in_text])[0]
        序列 = pad_sequences([序列], maxlen=max_length)
        pred = model.predict([照片, 序列], verbose=0)
        pred = np.argmax(pred)
        word = word_for_id(pred, 分词器)
        如果单词为“无”：
            休息
        in_text += &#39; &#39; + 单词
        如果单词==&#39;结束&#39;：
            休息
    返回 in_text

ap = argparse.ArgumentParser()
ap.add_argument(&#39;-i&#39;, &#39;--image&#39;, required=True, help=“图像路径”)
args = vars(ap.parse_args())
img_path = args[&#39;图像&#39;]




#path = &#39;Flicker8k_Dataset/111537222_07e56d5a30.jpg&#39;
最大长度 = 32
tokenizer = pickle.load(open(&quot;tokenizer.p&quot;,&quot;rb&quot;))
路径=&#39;模型/model_9.h5&#39;
模型 = 加载模型（
       （小路），
       custom_objects={&#39;KerasLayer&#39;:hub.KerasLayer}
）
xception_model = Xception(include_top=False, pooling=“avg”)

照片 = extract_features(img_path, xception_model)
img = Image.open(img_path)

描述 =generate_desc(模型、分词器、照片、max_length)
打印(“\n\n”)
打印（描述）
plt.imshow(img)```
]]></description>
      <guid>https://stackoverflow.com/questions/78268793/i-am-getting-unknown-layer-error-while-testing-a-model</guid>
      <pubDate>Wed, 03 Apr 2024 15:32:23 GMT</pubDate>
    </item>
    <item>
      <title>创建一个自定义人工智能模型，从任何输入网站提取特定数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78268338/create-a-custom-ai-model-that-extracts-specific-data-from-any-input-website</link>
      <description><![CDATA[我想制作一个自定义脚本，可以从网站（可以是具有类似数据类型的任何网站）中提取特定类型的表数据。因为有很多网站的结构不同，有些有table标签，有些使用div，有些使用其他标签。
数据有相似之处，我认为这是可能实现的。
我将向专家展示一些示例。
https://www.rockauto.com/en/moreinfo.php?pk=101750&amp;cc=0&amp;pt=1000587&amp;jsn=788&amp;optionchoice=0-0-8-1


像这样的表和交换号码（如果有）将由脚本提取。
另一个例子是
https://www.aimsinduscial。 com.au/gates-9770-13a1955-green-stripe-belt-heavy-duty-en

您可以看到表格中有产品的规格。需要提取此类表。
现在，我对机器学习一无所知，并且想要这个项目的路线图。我没有太多时间，这就是我需要指导的原因。
如果有人可以指导我如何实现这一目标或给我一个正确的路线图。我应该学习什么，什么对我这个项目有帮助。不过，我精通 python 和数据抓取。]]></description>
      <guid>https://stackoverflow.com/questions/78268338/create-a-custom-ai-model-that-extracts-specific-data-from-any-input-website</guid>
      <pubDate>Wed, 03 Apr 2024 14:20:16 GMT</pubDate>
    </item>
    <item>
      <title>（误）-使用 open.ai Whisper 进行文本到文本的翻译</title>
      <link>https://stackoverflow.com/questions/74667955/mis-using-open-ai-whisper-for-text-to-text-translation</link>
      <description><![CDATA[我注意到使用 openai whisper 语音转文本库 转录多种语言的语音有时可以准确识别以另一种语言插入并提供预期输出，例如：八十多个人与八十几个人相同。所以多和几可以互换，都可以表示几个。
然而，不同通道上的相同音频输入（使用相同的模型或更小/更大的模型）会间歇性地导致整个句子被翻译的故障，而不是翻译转录。 IE。片段将被翻译成音频中出现的第一语言或第二语言。对于上面的示例输入，要么整个句子是英语（中文部分翻译成英语），要么整个句子是中文（英语部分翻译成中文）。 重要：在这两种情况下都没有指定输入语言，也没有传递任务类型（这意味着默认的 --task transcribe）。
耳语文档提到将英语翻译为唯一可用的目标语言（使用选项--tasktranslate 在命令行版本中），但没有提到翻译成其他目标语言。然而，上述行为表明这些模型也能够翻译成其他语言。
问题是是否有一种已知的方法来配置模型以进行文本到文本的翻译？或者这种行为只是某种故障，不能被“利用”或在较低级别上进行配置，从而允许使用模型在任何受支持的语言之间进行文本翻译？]]></description>
      <guid>https://stackoverflow.com/questions/74667955/mis-using-open-ai-whisper-for-text-to-text-translation</guid>
      <pubDate>Sat, 03 Dec 2022 15:12:21 GMT</pubDate>
    </item>
    <item>
      <title>wandb - 在运行时访问记录的值</title>
      <link>https://stackoverflow.com/questions/65392269/wandb-access-logged-values-during-runtime</link>
      <description><![CDATA[如何在运行完成之前从 wandb 检索记录的值？
导入操作系统
导入万数据库
wandb.init(项目=&#39;someproject&#39;)


def loss_a():
    # do_stuff 和日志：
    wandb.log({“loss_a”: 1.0})
    
def loss_b():
    # do_stuff 和日志：
    wandb.log({“loss_b”: 2.0})

对于范围（2）中的纪元：
    损失_a（）
    损失_b()
    
    # 以某种方式检索loss_a和loss_b并在此处打印它们：
    print(f&#39;loss_a={??}, loss_b={??}&#39;)


运行完成后，我可以使用 wandb.Api 找到它来获取 run.history。但似乎在 run 完成之前，访问 run.history 不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/65392269/wandb-access-logged-values-during-runtime</guid>
      <pubDate>Mon, 21 Dec 2020 11:51:10 GMT</pubDate>
    </item>
    <item>
      <title>使不同大小的火炬张量相等</title>
      <link>https://stackoverflow.com/questions/61943896/pad-torch-tensors-of-different-sizes-to-be-equal</link>
      <description><![CDATA[我正在寻找一种方法来获取图像/目标批次进行分割并返回图像尺寸已更改为与整个批次相同的批次。我已经使用下面的代码尝试过：
def collat​​e_fn_padd(批处理):
    &#39;&#39;&#39;
    可变长度的衬垫批次

    注意：自从 ToTensor 变换以来，它在这里手动将事物转换为 ToTensor
    假设它接受图像而不是任意张量。
    &#39;&#39;&#39;
    # 分离图像和蒙版
    image_batch,mask_batch = zip(*batch)

    # 填充图像和蒙版
    image_batch = torch.nn.utils.rnn.pad_sequence（image_batch，batch_first = True）
    mask_batch = torch.nn.utils.rnn.pad_sequence（mask_batch，batch_first = True）

    # 重新压缩批处理
    批次=列表（zip（image_batch，mask_batch））

    退货批次

但是，我收到此错误：
运行时错误：张量 (650) 的扩展大小必须与非单一维度 2 处的现有大小 (439) 匹配。目标大小：[3, 650, 650]。张量大小：[3, 406, 439]

如何有效地将张量填充为相等尺寸并避免此问题？]]></description>
      <guid>https://stackoverflow.com/questions/61943896/pad-torch-tensors-of-different-sizes-to-be-equal</guid>
      <pubDate>Thu, 21 May 2020 21:11:02 GMT</pubDate>
    </item>
    </channel>
</rss>