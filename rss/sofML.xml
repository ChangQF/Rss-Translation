<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 26 Oct 2024 18:20:42 GMT</lastBuildDate>
    <item>
      <title>NLP 疾病检测</title>
      <link>https://stackoverflow.com/questions/79128775/nlp-diseases-detection</link>
      <description><![CDATA[我正在做一个项目，目标是从不同的句子中检测出疾病名称
我需要一些建议
我正在寻找可以从中获取疾病名称列表的库，这样我至少可以从我的数据框中检测出疾病
然后我想通过从这种疾病中训练来使用 NER 名称实体识别
希望有人能指导我并给我一些建议
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/79128775/nlp-diseases-detection</guid>
      <pubDate>Sat, 26 Oct 2024 14:45:31 GMT</pubDate>
    </item>
    <item>
      <title>用于实时音频分类的深度学习预训练模型</title>
      <link>https://stackoverflow.com/questions/79128715/deep-learning-pre-trained-model-for-real-time-audio-classification</link>
      <description><![CDATA[对于 Raspberry Pi 3（可用的 mcu）等微控制器上的实时音频分类系统，最好的预训练深度学习模型是什么？如果模型可以进行音频到音频转换，则意味着输出取决于音频是否通过分类，这会带来额外的好处。
我正在尝试创建自己的模型。但是，使用预训练模型并将其用于我的情况似乎更好，因为训练我自己的模型需要花费大量时间。]]></description>
      <guid>https://stackoverflow.com/questions/79128715/deep-learning-pre-trained-model-for-real-time-audio-classification</guid>
      <pubDate>Sat, 26 Oct 2024 14:15:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 pytorch 查找奇偶分类器 sin(w*x)^2 中 w 的值</title>
      <link>https://stackoverflow.com/questions/79128525/using-pytorch-to-find-value-of-w-in-sinwx2-for-an-even-odd-classifier</link>
      <description><![CDATA[这不是重复的，因为其他关于奇偶分类的问题都没有尝试使用这个特定的函数来学习，而是使用通常的 ReLU 或 sigmoid。
我正在尝试估计函数 x -&gt; sin(w*x)^2 中的参数 w，以将整数分类为偶数或奇数，使用 pytorch 作为自我分配的练习。当然，正确的 w 有多个可能的值，包括 w = pi/2。我初始化了我的网络（一个无偏差的线性网络，然后是 sin 激活，然后是平方），其中 w = 1.5 接近 pi/2，希望它收敛到 pi/1 = 1.507...，但无论我如何调整学习率或使用什么优化器，模型都没有学习。
class Net(torch.nn.Module):
def __init__(self):
super().__init__()
# 无偏差的线性网络 
self.fc1 = torch.nn.Linear(1, 1, bias=False)
# 初始化接近理论解
with torch.no_grad():
self.fc1.weight.data.fill_(1.5) # 接近 π/2 ≈ 1.57

def forward(self, x):
x = self.fc1(x)
return torch.sin(x)**2

net = Net()
criterion = torch.nn.MSELoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.0004)

weights = []
for epoch in range(100):
net.train()

optimizer.zero_grad()
output = net(train_x)

loss = criterion(output, train_y)
loss.backward()
optimizer.step()

weights.append(w)

权重图表明没有趋向于任何一点。
我想相信我避免了常见的陷阱：我让输入和输出为 float 32，目标函数可以使用模型完美学习，我也尝试过其他损失函数，但失败了。
请帮我找到我犯了一个错误，这里是完整的代码（从 jupyter 笔记本导出）：
# %%
import torch
import numpy as np
import pandas as pd

# %%
# 生成数据并缩放输入
def generate_data(size):
x = np.random.randint(0, size, size) # 范围较小，可视化效果更好
return x.astype(float), (x % 2).astype(float)

# %%
# 生成数据集
train_x, train_y = generate_data(1000)
val_x, val_y = generate_data(1000)

# 转换为张量
train_x = torch.tensor(train_x, dtype=torch.float32).reshape(-1, 1)
train_y = torch.tensor(train_y, dtype=torch.float32).reshape(-1, 1)
val_x = torch.tensor(val_x, dtype=torch.float32).reshape(-1, 1)
val_y = torch.tensor(val_y, dtype=torch.float32).reshape(-1, 1)

# %%
class Net(torch.nn.Module):
def __init__(self):
super().__init__()
# 无偏差线性 
self.fc1 = torch.nn.Linear(1, 1, bias=False)
# 初始化接近理论解
with torch.no_grad():
self.fc1.weight.data.fill_(1.5) # 接近 π/2 ≈ 1.57

def forward(self, x):
x = self.fc1(x)
return torch.sin(x)**2

# %%
net = Net()
criterion = torch.nn.MSELoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.0004)

# %%
weights = []
for epoch in range(100):
net.train()

optimizer.zero_grad()
output = net(train_x)

loss = criterion(output, train_y)
loss.backward()
optimizer.step()

net.eval()
with torch.no_grad():
val_output = net(val_x)
val_loss = criterion(val_output, val_y)

if epoch % 1 == 0:
print(f&quot;Epoch {epoch}&quot;)
print(f&quot;Loss: {loss.item():.8f} Val损失：{val_loss.item():.8f}&quot;)
w = net.fc1.weight.item()
print(f&quot;权重：{w:.8f} (目标：{np.pi/2:.8f})&quot;)
print(&quot;---&quot;)

weights.append(w)

# %%
# 绘制权重
import matplotlib.pyplot as plt
plt.plot(weights)
plt.plot([np.pi/2]*len(weights))

# %%
# 测试模型
w = net.fc1.weight.item()
print(&quot;\n最终参数：&quot;)
print(f&quot;权重：{w:.8f} (目标：{np.pi/2:.8f})&quot;)

# 对偶数和奇数进行测试
test_numbers = np.arange(0, 1500, 1)
net.eval()
使用 torch.no_grad():
for x in test_numbers:
test_input = torch.tensor([[float(x)]], dtype=torch.float32)
pred = net(test_input).item()
print(&quot;✅&quot; if (pred &lt; 0.5) == (x % 2 == 0) else &quot;❌&quot;, end=&quot;&quot;)
if (x+1) % 60 == 0:
print()

]]></description>
      <guid>https://stackoverflow.com/questions/79128525/using-pytorch-to-find-value-of-w-in-sinwx2-for-an-even-odd-classifier</guid>
      <pubDate>Sat, 26 Oct 2024 12:24:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个简单的机器学习代码会给出错误的答案？</title>
      <link>https://stackoverflow.com/questions/79127884/why-does-this-simple-machine-learning-code-give-the-wrong-answer</link>
      <description><![CDATA[我正在尝试学习一些时间序列神经网络 ML，但得到的解有些奇怪，因此我尝试对我能想到的最简单的非平凡情况进行建模，即预测 n+1 为序列 0,1,2,3,...n 中的下一个数字（使用 LSTM 模型）。
每个数据点的训练数据是一系列紧接在前的数字，我假设只要每个训练集的数据长度 &gt;= 2（因为它是一个算术序列），它就应该很容易解决模型。
无论训练系列的大小如何，下面的代码都会为所有测试数据返回一个常数。有人能解释一下我做错了什么吗？
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math

import statistics

dim = 5

data = pd.Series(range(0,200))

# 设置 80% 的数据用于训练
training_data_len = math.ceil(len(data) * .8)

# 规范化数据
train_data = data[:training_data_len]

# 拆分数据集
train_data = data[:training_data_len]
test_data = data[training_data_len:]
print(train_data.shape, test_data.shape)

# 选择值
dataset_train = train_data.values 
# 将 1D 重塑为 2D 数组
dataset_train = np.reshape(dataset_train, (-1,1))

# 选择值
dataset_test = test_data.values
# 将 1D 数组重塑为 2D 数组
dataset_test = np.reshape(dataset_test, (-1,1)) 

X_train = []
y_train = []
for i in range(dim, len(dataset_train)):
X_train.append(dataset_train[i-dim:i, 0])
y_train.append(dataset_train[i, 0])

X_test = []
y_test = []
for i in range(dim, len(dataset_test)):
X_test.append(dataset_test[i-dim:i, 0])
y_test.append(dataset_test[i, 0])

# 将数据转换为 Numpy 数组
X_train, y_train = np.array(X_train), np.array(y_train)

#重塑
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))
y_train = np.reshape(y_train, (y_train.shape[0],1))
print(&quot;X_train :&quot;,X_train.shape,&quot;y_train :&quot;,y_train.shape)

# 将数据转换为 numpy 数组
X_test, y_test = np.array(X_test), np.array(y_test)

#重塑
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))
y_test = np.reshape(y_test, (y_test.shape[0],1))
print(&quot;X_test :&quot;,X_test.shape,&quot;y_test :&quot;,y_test.shape)

# 导入库
从 keras.models 导入 Sequential
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dense
从 keras.layers 导入 SimpleRNN
从 keras.layers 导入 Dropout
从 keras.layers 导入 GRU, Bidirectional
从 keras.optimizers 导入 SGD
从 sklearn 导入 metrics
从 sklearn.metrics 导入 mean_squared_error

# 初始化模型
regressorLSTM = Sequential()

# 添加 LSTM 层
regressorLSTM.add(LSTM(dim, 
return_sequences = True, 
input_shape = (X_train.shape[1],1)))
regressorLSTM.add(LSTM(dim, 
return_sequences = False))

#添加输出层
regressorLSTM.add(Dense(1))

#编译模型
regressorLSTM.compile(optimizer = &#39;adam&#39;,
loss = &#39;mean_squared_error&#39;,
metrics = [&quot;accuracy&quot;])

#拟合模型
regressorLSTM.fit(X_train, 
y_train, 
batch_size = 1, 
epochs = 4)
regressorLSTM.summary()

# 使用 X_test 数据的预测
y_LSTM = regressorLSTM.predict(X_test)

#绘制 LSTM 预测图
plt.plot(train_data.index[dim:], train_data[dim:], label = &quot;train_data&quot;, color = &quot;b&quot;)
plt.plot(test_data.index, test_data, label = &quot;test_data&quot;, color = &quot;g&quot;)
plt.plot(test_data.index[dim:], y_LSTM, label = &quot;y_LSTM&quot;, color = &quot;orange&quot;)
plt.legend()
plt.xlabel(&quot;X&quot;)
plt.ylabel(&quot;Y&quot;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79127884/why-does-this-simple-machine-learning-code-give-the-wrong-answer</guid>
      <pubDate>Sat, 26 Oct 2024 05:28:55 GMT</pubDate>
    </item>
    <item>
      <title>我需要从图像中提取每个数字</title>
      <link>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</link>
      <description><![CDATA[我正在做图像分割，其中有不同类型的数字图像，如下所示。我能够对 MNIST 合并图像执行图像分割，但该方法不适用于带有水平线的图像。在任何类型的方向和图像噪声中，分别分割每个数字的最佳方法是什么？


我正在使用此代码分割图像中的每个数字，尤其是从数字写在水平线之间的噪声图像中
import os
import cv2
import matplotlib.pyplot as plt

# 加载图像
# image_path = &#39;/mnt/data/013.png&#39;
image_path = &#39;/content/drive/My Drive/demo/captcha/samples/010.png&#39;
image = cv2.imread(image_path)

# 转换为灰度
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊以减少噪音
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# 应用二元阈值
_, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# 在阈值图像中查找轮廓
contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 创建原始图像的副本以绘制轮廓
output_image = image.copy()

# 按大小过滤轮廓（以去除噪音）
digit_contours = [c for c in contours if cv2.contourArea(c) &gt; 50]

# 绘制轮廓（可选可视化）
cv2.drawContours(output_image, digit_contours, -1, (0, 255, 0), 2)

# 创建一个列表来存储单个数字图像
digit_images = []

# 从原始图像中提取每个数字
for i, contour in enumerate(digit_contours):
x, y, w, h = cv2.boundingRect(contour)
digit = gray[y:y+h, x:x+w]
digit_images.append(digit)
# 使用子图单独显示每个数字
plt.subplot(1, len(digit_contours), i + 1) # 为每个数字创建子图
plt.imshow(digit, cmap=&#39;gray&#39;) # 以灰度显示当前数字
plt.axis(&#39;off&#39;) # 关闭轴标签

# 可选将每个数字保存为单独的图像
cv2.imwrite(f&quot;digit_{x}.png&quot;, digit)

# 显示带有单独数字显示的结果
plt.figure(figsize=(10, 6))
plt.imshow(output_image)
plt.title(&quot;Extracted Digits&quot;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</guid>
      <pubDate>Fri, 25 Oct 2024 21:50:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的损失太多[关闭]</title>
      <link>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</link>
      <description><![CDATA[我正在训练一个预测加密货币价格的神经网络，但数据丢失太大，代码如下：
import numpy as np
import tensorflow as tf
from tensorflow.keras import layer, models,Sequential,Model,Input
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import *
import matplotlib.pyplot as plt
import ccxt
import pandas as pd
import request
import json
import datetime as dt
import time

# Определение входов
input1 = Input(shape=(100, 1))
input2 = Input(shape=(100, 1))

# 用 LSTM 构建机器学习模型已保存
lstm1 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input1)
lstm1 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm1)
lstm1 = layer.LSTM(units=64,activation=&#39;linear&#39;)(lstm1)
lstm1 = layer.Dropout(0.2)(lstm1)

lstm2 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input2)
lstm2 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm2)
lstm2 = layer.LSTM(units=64,激活 = &#39;线性&#39;）（lstm2）lstm2 = groups.Dropout（0.2）（lstm2）＃ Объединяем все LSTM выходы merged = groups.concatenate（[lstm1, lstm2]）＃Добавляем Dense слой для объединенного вы хода 输出 = 层.Dense(100, 激活=&#39;线性&#39;)(合并) # Создание и компиляция модели 模型 = 模型(输入=[输入1, 输入2], 输出=输出) 优化器 = Adam(learning_rate=0.000005) model.compile(loss=&#39;mse&#39;, 优化器=优化器) df = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcdata15m.csv&quot;, sep =&quot;\t&quot;)

list_of_close = df[&#39;Open&#39;].to_list()
print(len(list_of_close))

df1 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcoi15m.csv&quot;, sep =&quot;\t&quot;)
list_of_oi = df1[&#39;openInterest&#39;].to_list()
print(len(list_of_oi))

df3 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/y.csv&quot;, sep =&quot;\t&quot;)
y = df3[&#39;Close&#39;].to_list()
print(len(y))
x1 = np.array(list_of_close).reshape(100,100)
x2 = np.array(list_of_oi).reshape(100,100)

min_max_scaler = MinMaxScaler()
x1 = min_max_scaler.fit_transform(x1)
x2 = min_max_scaler.fit_transform(x2)

x1 = x1.astype(float)
x2 = x2.astype(float)

y = np.array(y).reshape(100,100).astype(float)

# 改进模型
history = model.fit([x1,x2], y,batch_size=64, epochs=100)

上次亏损为：3848644352.0000
我的数据集包含 10,000 个收盘蜡烛和 10,000 个未平仓合约值
我如何才能将损失降到最低？]]></description>
      <guid>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</guid>
      <pubDate>Fri, 25 Oct 2024 17:19:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么 train_batch*.jpg 中缺少一些边界框/标签？这些图像是由 YOLOv7 在训练时自动生成的 [closed]</title>
      <link>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</link>
      <description><![CDATA[我正在自定义数据集上训练 YOLOv7 模型。虽然我的召回率超过 0.9，但精度低于 0.1。为了调查这个问题，我检查了训练脚本生成的 train_batch*.jpg 拼贴画，发现有些图像包含没有任何相关标签或边界框的对象。
我尝试解析图像和标签列表。所有图像都有一个带有适当注释的相应 txt 文件。
这是正常现象吗？如果不是，如何解决这个问题？
https://github.com/WongKinYiu/yolov7/]]></description>
      <guid>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</guid>
      <pubDate>Fri, 25 Oct 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MIRNet 模型保存和重用低光增强功能？[关闭]</title>
      <link>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</link>
      <description><![CDATA[我最近在 Keras 上发现了一个关于图像增强的有趣教程。代码没问题，我运行没有任何错误，但我不知道如何保存模型并重新使用它。
我试了很多次，但无法保存模型。有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</guid>
      <pubDate>Fri, 25 Oct 2024 02:48:27 GMT</pubDate>
    </item>
    <item>
      <title>训练 AI 模型以纠正多边形坐标中的错误的最佳方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</link>
      <description><![CDATA[我需要选择一个最适合训练的 AI 模型和一个 Python 库。我有来自 djangorestframework-gis 库的以 Multipolygon 字段表示的坐标，它们在不同范围内存在小误差 - 大约 0.75 到 1 米。此外，我有相同地块的正确坐标。该模型需要学习找到正确数据和错误数据之间的差异，并在此基础上找到一种算法来确定错误，以便将来纠正错误坐标。]]></description>
      <guid>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</guid>
      <pubDate>Thu, 24 Oct 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch RuntimeError：mat1 和 mat2 形状无法相乘</title>
      <link>https://stackoverflow.com/questions/75693007/pytorch-runtimeerror-mat1-mat2-shapes-cannot-be-multiplied</link>
      <description><![CDATA[我在 Pytorch 上构建 CNN 并收到以下错误消息：

RuntimeError：mat1 和 mat2 形状无法相乘（32x32768 和
512x256）

我已构建以下模型：
def classifier_block(input, output, kernel_size, stride, last_layer=False):
if not last_layer:
x = nn.Sequential(
nn.Conv2d(input, output, kernel_size, stride, padding=3),
nn.BatchNorm2d(output),
nn.LeakyReLU(0.2, inplace=True)
)
else:
x = nn.Sequential(
nn.Conv2d(input, output, kernel_size, stride),
nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
)
返回 x

class Classifier(nn.Module):
def __init__(self, input_dim, output):
super(Classifier, self).__init__()
self.classifier = nn.Sequential(
classifier_block(input_dim, 64, 7, 2),
classifier_block(64, 64, 3, 2),
classifier_block(64, 128, 3, 2),
classifier_block(128, 256, 3, 2),
classifier_block(256, 512, 3, 2, True)
)
print(&#39;CLF: &#39;,self.classifier)

self.linear = nn.Sequential(
nn.Linear(512, 256),
nn.ReLU(inplace=True),
nn.Linear(256, 128),
nn.ReLU(inplace=True),
nn.Linear(128, 64),
nn.ReLU(inplace=True),
nn.Linear(64, output)
)
print(&#39;Linear: &#39;, self.linear)

def forward(self, image):
print(&#39;IMG: &#39;, image.shape)
x = self.classifier(image)
print(&#39;X: &#39;, x.shape)
return self.linear(x.view(len(x), -1))

输入图像的大小为 512x512。这是我的训练块：
loss_train = []
loss_val = []

for epoch in range(epochs):
print(&#39;Epoch: {}/{}&#39;.format(epoch, epochs))
total_train = 0
correct_train = 0
cumloss_train = 0
classifier.train()
for batch, (x, y) in enumerate(train_loader):
x = x.to(device)
print(x.shape)
print(y.shape)
output = classifier(x)
loss = criterion(output, y.to(device))
optimizer.zero_grad()
loss.backward()
optimizer.step()

print(&#39;Loss: {}&#39;.format(loss))

任何建议都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/75693007/pytorch-runtimeerror-mat1-mat2-shapes-cannot-be-multiplied</guid>
      <pubDate>Fri, 10 Mar 2023 06:48:16 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 异常：TreeExplainer 中的可加性检查失败</title>
      <link>https://stackoverflow.com/questions/68233466/shap-exception-additivity-check-failed-in-treeexplainer</link>
      <description><![CDATA[我试图为局部解释创建单行的 shap 值，但一直出现此错误。我尝试了各种方法，但仍然无法修复它们。
我到目前为止所做的事情 -
创建了随机决策树模型 -
from sklearn.ensemble import ExtraTreesRegressor
extra_tree = ExtraTreesRegressor(random_state=42)
extra_tree.fit(X_train, y_train)

然后尝试计算 shap 值 -
# 创建解释器对象
explainer = shap.Explainer(extra_tree) 
explainer.expected_value
array([15981.25812347])

#计算单行的 shap 值
shap_values = explainer.shap_values(pd.DataFrame(X_train.iloc[9274]).T)

这给了我这个错误 -
异常：TreeExplainer 中的可加性检查失败！请确保传递给解释器的数据矩阵与模型训练时的形状相同。如果您的数据形状正确，请在 GitHub 上报告此问题。考虑使用 feature_perturbation=&#39;interventional&#39; 选项重试。此检查失败，因为对于其中一个样本，SHAP 值的总和为 25687017588058.968750，而模型输出为 106205.580000。如果这个差异是可以接受的，您可以设置 check_additivity=False 以禁用此检查。

我传递的训练形状和单行具有相同的列数
X_train.shape
(421570, 164)
(pd.DataFrame(X_train.iloc[9274]).T).shape
(1, 164)

我不认为这会引起任何问题。但为了确保万无一失，我还尝试使用重塑方法带来正确的形状。
shap_values = explainer.shap_values(X_train.iloc[9274].values.reshape(1, -1))

X_train.iloc[9274].values.reshape(1, -1).shape
(1, 164)

这也不能解决问题。所以，我想也许我还需要匹配行数。所以我创建了一个小数据框并尝试测试它。
train = pd.concat([X_train, y_train], axis=&quot;columns&quot;)
train_small = train.sample(n=500, random_state=42)
X_train_small = train_small.drop(&quot;Weekly_Sales&quot;, axis=1).copy()
y_train_small = train_small[&quot;Weekly_Sales&quot;].copy()

# 训练随机决策树模型
from sklearn.ensemble import ExtraTreesRegressor
extra_tree_small = ExtraTreesRegressor(random_state=42)
extra_tree_small.fit(X_train_small, y_train_small)

# 创建解释器对象
explainer = shap.Explainer(extra_tree_small)
shap_values = explainer.shap_values(X_train_small)

# 我也尝试过像这样添加 y 值 
shap_values = explainer.shap_values(X_train_small, y_train_small)

但什么都没起作用。
GitHub 上的一个人建议卸载并重新安装
shap 在 GitHub 上的最新版本：
pip install git+https://github.com/slundberg/shap.git

也试过了，还是不行。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/68233466/shap-exception-additivity-check-failed-in-treeexplainer</guid>
      <pubDate>Sat, 03 Jul 2021 05:21:02 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 分类器对 mnist 数据不起作用</title>
      <link>https://stackoverflow.com/questions/64962318/pytorch-classifier-for-mnist-data-not-work</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/64962318/pytorch-classifier-for-mnist-data-not-work</guid>
      <pubDate>Mon, 23 Nov 2020 03:51:20 GMT</pubDate>
    </item>
    <item>
      <title>批量标准化是否适用于小批量？</title>
      <link>https://stackoverflow.com/questions/56859748/does-batch-normalisation-work-with-a-small-batch-size</link>
      <description><![CDATA[我使用批量标准化，批量大小为 10 来进行人脸检测。
批量标准化是否适用于如此小的批量大小？如果不行，那么我还能使用什么来进行标准化？]]></description>
      <guid>https://stackoverflow.com/questions/56859748/does-batch-normalisation-work-with-a-small-batch-size</guid>
      <pubDate>Tue, 02 Jul 2019 20:38:25 GMT</pubDate>
    </item>
    <item>
      <title>SciKitLearn 中 MLPRegressor 的隐藏层大小是如何确定的？</title>
      <link>https://stackoverflow.com/questions/55786860/how-is-the-hidden-layer-size-determined-for-mlpregressor-in-scikitlearn</link>
      <description><![CDATA[假设我使用以下代码创建一个神经网络：
from sklearn.neural_network import MLPRegressor

model = MLPRegressor(
hidden_​​layer_sizes=(100,),
activation=&#39;identity&#39;
)
model.fit(X_train, y_train)

对于 hidden_​​layer_sizes，我只是将其设置为默认值。但是，我真的不明白它是如何工作的。我的定义中隐藏层的数量是多少？是 100 吗？]]></description>
      <guid>https://stackoverflow.com/questions/55786860/how-is-the-hidden-layer-size-determined-for-mlpregressor-in-scikitlearn</guid>
      <pubDate>Sun, 21 Apr 2019 21:21:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit learn 进行快速 ICA 重构误差分析</title>
      <link>https://stackoverflow.com/questions/45758280/fast-ica-using-scikit-learn-reconstruction-error-analysis</link>
      <description><![CDATA[我正在尝试在 scikitLearn 中使用 fastICA 程序。为了验证目的，我试图了解基于 PCA 和 ICA 的信号重建之间的区别。
观察到的信号的原始数量为 6，我尝试使用 3 个重建独立分量。问题是，无论我使用什么规范，ICA 和 PCA 都会导致相同的重建误差。有人能解释一下这里发生了什么吗？
代码如下：
 pca = PCA(n_components=3)
icamodel = FastICA(n_components=3,whiten=True)

Data = TrainingDataDict[YearSpan][RiskFactorNames]

PCR_Dict[YearSpan] = pd.DataFrame(pca.fit_transform(Data), 
columns=[&#39;PC1&#39;,&#39;PC2&#39;,&#39;PC3&#39;],index=Data.index)

ICR_Dict[YearSpan] = pd.DataFrame(icamodel.fit_transform(Data), 
columns=[&#39;IC1&#39;,&#39;IC2&#39;,&#39;IC3&#39;],index=Data.index)

&#39;------------------------IC 和 PC 的逆变换 -----------&#39;

PCA_New_Data_Df = pd.DataFrame(pca.inverse_transform(PCR_Dict[YearSpan]),
columns =[&#39;F1&#39;,&#39;F2&#39;,&#39;F3&#39;],index = Data.index)

ICA_New_Data_Df = pd.DataFrame(icamodel.inverse_transform(ICR_Dict[YearSpan]),
columns =[&#39;F1&#39;,&#39;F2&#39;,&#39;F3&#39;],index = Data.index)

下面是我测量重建误差的方法
&#39;-----------重建误差------------------&#39;
print &#39;PCA 重建误差 L2 范数：&#39;,np.sqrt((PCA_New_Data_Df - Data).apply(np.square).mean())

print &#39;ICA 重建误差 L2 范数：&#39;,np.sqrt((ICA_New_Data_Df - Data).apply(np.square).mean())

print &#39;PCA 重建误差 L1 范数：&#39;,(PCA_New_Data_Df - Data).apply(np.absolute).mean()

print &#39;ICA 重建误差 L1 范数：&#39;,(ICA_New_Data_Df - Data).apply(np.absolute).mean()

以下是 PC 和 IC 尾部的描述
PC 统计：(&#39;2003&#39;, &#39;2005&#39;) 
峰度 偏度
PCR_1 -0.001075 -0.101006
PCR_2 1.057140 0.316163
PCR_3 1.067471 0.047946 

IC 统计： (&#39;2003&#39;, &#39;2005&#39;) 
峰度 偏度
ICR_1 -0.221336 -0.204362
ICR_2 1.499278 0.433495
ICR_3 3.654237 0.072480 

以下是重建的结果
PCA 重建误差 L2 范数：
SPTR 0.000601
SPTRMDCP 0.001503
RU20INTR 0.000788
LBUSTRUU 0.002311
LF98TRUU 0.001811
NDDUEAFE 0.000135
dtype: float64 

ICA 重建误差 L2 范数：
SPTR 0.000601
SPTRMDCP 0.001503
RU20INTR 0.000788
LBUSTRUU 0.002311
LF98TRUU 0.001811
NDDUEAFE 0.000135

连L1规范都一样。我有点糊涂了！]]></description>
      <guid>https://stackoverflow.com/questions/45758280/fast-ica-using-scikit-learn-reconstruction-error-analysis</guid>
      <pubDate>Fri, 18 Aug 2017 13:48:17 GMT</pubDate>
    </item>
    </channel>
</rss>