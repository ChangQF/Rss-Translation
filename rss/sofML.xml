<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Jan 2024 12:20:49 GMT</lastBuildDate>
    <item>
      <title>对 MLH 奖学金代码示例有什么建议吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77890706/any-suggestions-for-mlh-fellowship-code-sample</link>
      <description><![CDATA[我计划今年申请 MLH 奖学金，我想展示一个强大的代码示例来展示我的全栈开发技能。我正在考虑的项目是任务管理器 Web 应用程序。该应用程序将包括用户身份验证、任务创建/编辑/删除、数据库集成、响应式用户界面和部署等功能。
我希望获得有关如何有效实施该项目的建议，以及能够给评选委员会留下深刻印象的任何具体技术或框架。此外，我们将非常感谢有关确保代码质量、安全实践以及任何可以使我的项目脱颖而出的额外功能的指导。
我的目标不仅仅是满足奖学金的要求，而是提供一个全面且精心制作的代码示例，反映我作为全栈开发人员的能力。经历过类似申请流程的经验丰富的开发人员提供的任何见解、技巧或建议都会非常有帮助。
提前感谢您的指导！]]></description>
      <guid>https://stackoverflow.com/questions/77890706/any-suggestions-for-mlh-fellowship-code-sample</guid>
      <pubDate>Sat, 27 Jan 2024 09:45:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么 DecisionTreeClassifier 会按照指定的标准错误地分割数据？</title>
      <link>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</link>
      <description><![CDATA[在第一次使用 DecisionTreeClassifier 时，我们得到了样本数为 192 和 346 的两个子树，但是当我们使用文件 Counter 并在 Treeclassifier 决策中设置与分离相同的条件时，我们得到了样本数 171 和 367。这种差异的标志是什么？
DecisionTreeClassifier 代码块：
导入 pandas 作为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn 导入树
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
数据 = pd.read_csv(r“PCOS.csv”)
X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[“PCOS (Y/N)”]
模型= DecisionTreeClassifier（max_深度= 2，标准=“基尼”）
模型.fit(X, y)

树.plot_tree(模型)
fn = 数据.列

标签 = [“0”,“1”]
图，轴 = plt.subplots()
tree.plot_tree(模型，feature_names=fn，class_names=label，filled=True)
Fig.savefig(&#39;imagenae.png&#39;)


计数器代码块：
导入 pandas 作为 pd


def 子树（数据，列）：
    第一个列表 = []
    秒列表 = []
    对于范围内的 i（len（数据））：
        如果数据[col][i] &lt;= 7.5：
            first_list.append(data.loc[i, :].values)
        别的：
            sec_l​​ist.append(data.loc[i, :].values)
    基尼系数（第一个列表）
    基尼系数（秒列表）


定义基尼系数（数据）：
    a, b= 0, 0
    对于数据中的 i：
        如果 i[-1] == 0:
            一个+= 1
        别的：
            b+=1
    print(&quot;标签 0 :&quot;, a)
    print(&quot;标签 1 :&quot;, b)


col = [&#39;皮肤变黑(Y/N)&#39;, &#39;毛发生长(Y/N)&#39;, &#39;体重增加(Y/N)&#39;, &#39;周期(R/I)&#39;, &#39;毛囊编号(R)&#39; ,
       &#39;快餐（Y/N）&#39;、&#39;卵泡编号（L）&#39;、&#39;PCOS（Y/N）&#39;]

数据 = pd.read_csv(“PCOS.csv”)[col]

X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[[“PCOS（是/否）”]]

subtree(data, &#39;毛囊编号 (L)&#39;)

结果决策树分类器：
192 和 346
结果计数器：
171 和 367
数据库：
数据库
可视化决策树：
可视化决策树]]></description>
      <guid>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</guid>
      <pubDate>Sat, 27 Jan 2024 08:24:18 GMT</pubDate>
    </item>
    <item>
      <title>两阶段推荐系统中的top-K推荐</title>
      <link>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</guid>
      <pubDate>Sat, 27 Jan 2024 08:22:43 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用 (pip install pickle5) 安装 Python 的 pickle 包，但安装包失败</title>
      <link>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</link>
      <description><![CDATA[这是我尝试过的：
pip install pickle5

这是包含错误消息的快照。
这也是我得到的错误：
错误：无法为 pickle5 构建轮子，这是安装基于 pyproject.toml 的项目所必需的
我尝试按照其他一些帖子中的建议安装并重新安装 Microsoft Visual C++，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</guid>
      <pubDate>Sat, 27 Jan 2024 05:36:19 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：编译神经网络进行情感分析时，模块“keras.src.backend”没有属性“floatx”</title>
      <link>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序
从tensorflow.keras导入层

# 设置嵌入维度
嵌入尺寸 = 100

# 创建模型
模型=顺序（[
    层.Embedding(max_words, embedding_dim, input_length=max_length),
    层.LSTM(64),
    层.Dense(1, 激活=&#39;sigmoid&#39;)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 打印模型摘要
打印（模型.摘要（））

我尝试使用 Jupyter Notebook (.ipynb) 在 VSCode 中编译上述模型，但遇到以下错误：
AttributeError：模块“keras.src.backend”没有属性“floatx”
最初，我成功地编译了模型，但在拟合模型时导致 VScode 崩溃。重新加载 VSCode 后，我收到此错误。
为了解释上下文，我正在尝试构建一个非常基本的 NLP 模型，以根据情绪对亚马逊评论进行分类。我也在使用 Python 3.11 和 Tensorflow 版本 2.15
首先我尝试了以下方法：
导入keras.backend为K
K.set_floatx(&#39;float32&#39;)

但是我遇到了同样的错误。然后我尝试重置 VSCode 并再次运行笔记本，但仍然遇到相同的错误？]]></description>
      <guid>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</guid>
      <pubDate>Sat, 27 Jan 2024 04:41:13 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 部署到 sagemaker</title>
      <link>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</link>
      <description><![CDATA[我已压缩并保存到 s3，如下所示：
导入 tar 文件
使用 tarfile.open(&#39;model.tar.gz&#39;, mode=&#39;w:gz&#39;) 作为存档：
archive.add(&#39;Model&#39;, recursive=True)
导入Sagemaker
sagemaker_session = sagemaker.Session()
输入= sagemaker_session.upload_data(path=&#39;model.tar.gz&#39;, key_prefix=&#39;model&#39;)
尝试像这样部署：
从 sagemaker 导入 get_execution_role
从 sagemaker.pytorch.model 导入 PyTorchModel
角色 = get_execution_role()
pytorch_model = PyTorchModel(model_data= &#39;s3://&#39; + sagemaker_session.default_bucket() + &#39;/model/model.tar.gz&#39;, role=role,
Entry_point=&#39;inference.py&#39;,framework_version=&#39;2.1&#39;,py_version=&#39;py310&#39;)
预测器= pytorch_model.deploy（instance_type=&#39;ml.p3.2xlarge&#39;，initial_instance_count=1）
但我收到一个错误：
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;inference.py&#39;
我尝试了上面解释的所有内容]]></description>
      <guid>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</guid>
      <pubDate>Sat, 27 Jan 2024 03:20:13 GMT</pubDate>
    </item>
    <item>
      <title>安装斗争</title>
      <link>https://stackoverflow.com/questions/77889759/installation-struggle</link>
      <description><![CDATA[我们正在使用 Qiskit 工具包进行一个量子计算项目。但我们在导入或安装软件包和库时遇到了困难。在 Qiskit 中我们如何导入库和包？
澄清如何从外包安装库的疑问。]]></description>
      <guid>https://stackoverflow.com/questions/77889759/installation-struggle</guid>
      <pubDate>Sat, 27 Jan 2024 01:36:23 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 前向返回张量与标量</title>
      <link>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</link>
      <description><![CDATA[假设我有一个具有以下前向函数的 Pytorch 模型：
defforward(self, input_tensors):
    ”“”
    所有变量的维度：
    - input_tensors：（头、批次、feature_dim）
    - self.w：（头，feature_dim，1）
    - self.b: (头, 1, 1)
    ”“”

    out = torch.bmm(input_tensor, self.w) + self.b # (头数, 批次, 1)
    out = out.transpose(0, 1).squeeze(2) # （批次，头）
    标签 = torch.ones([批次, 头]) # (批次, 头
    logloss = SOMELOSSFUNC(logits=logits, labels=labels) # 输出可以是 [heads] 维度的标量或张量

    返回对数损失

如果对数损失是标量，则模型会针对一个值进行优化。如果对数损失是 [heads] 维度的张量怎么办？这是否意味着我正在独立优化每个头的 w 和 b ？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</guid>
      <pubDate>Sat, 27 Jan 2024 01:18:12 GMT</pubDate>
    </item>
    <item>
      <title>(Keras) 尝试加载以数组形式保存的优化器权重，但不断遇到问题</title>
      <link>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</link>
      <description><![CDATA[我很久以前训练了一个模型，当时我无法使用任何内置的 keras 函数保存模型或优化器权重，因为它不断抛出错误，所以我将权重保存为数组。&lt; /p&gt;
现在我尝试再次加载它，但在加载优化器权重时我不断遇到错误。我 100% 确定我正确保存了权重，并且模型架构是正确的，因为我使用了
my_model.optimizer.get_weights()
保存权重（尽管该行代码现在不起作用，因为它说“&#39;Adam&#39;对象没有属性&#39;get_weights&#39;”），我基本上复制粘贴了模型架构。
所以首先，我尝试简单地加载优化器权重，就像使用
my_model.optimizer.set_weights(saved_optimizer_weights)
但我收到以下错误
“您正在对尚未构建的优化器调用“set_weights()”。请在调用“set_weights()”之前调用“optimizer.build(trainable_variables)”创建优化器权重。
我认为“trainable_variables”指的是my_model.trainable_variables，所以我跑了
my_model.optimizer.build(my_model.trainable_variables)
并且成功了。但当我尝试时
my_model.optimizer.set_weights(saved_optimizer_weights)
我再次收到以下错误
“优化器变量 v/top_conv/kernel_25469 的形状 (1, 1, 352, 1408) 与提供的权重形状 (1408,) 不兼容。”
我不太确定从这里该去哪里。]]></description>
      <guid>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</guid>
      <pubDate>Fri, 26 Jan 2024 23:53:24 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker实例中的CUDA路径解决NameError：名称'_C'未使用GroundingDINO定义</title>
      <link>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</link>
      <description><![CDATA[我正在尝试在 Sagemaker 实例（使用 GPU）中安装和使用 grounding dino ）但我收到错误：
NameError：名称“_C”未定义

我发现原因是因为变量CUDA_HOME没有配置，所以要解决这个问题我需要设置该变量，但在搜索答案后我找不到cuda在sagemaker实例中安装的路径。
cuda 安装在 sagemaker 实例中的什么位置以便我可以设置 CUDA_HOME？]]></description>
      <guid>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</guid>
      <pubDate>Fri, 26 Jan 2024 18:45:06 GMT</pubDate>
    </item>
    <item>
      <title>TF-TRT 警告：无法 dlopen 某些 TensorRT 库</title>
      <link>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</link>
      <description><![CDATA[我一直在尝试在HPC集群上搭建虚拟环境，但是每次涉及到使用GPU的tensorflow时都碰壁。
模块加载 python3.8/3.8 eval “$(conda shell.bash hook)” conda 激活 graphgan
之后我使用以下命令来设置环境
conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0
当我尝试将tensorflow导入为tf时，它显示以下错误
2024-01-26 23:06:17.968937: I tensorflow/core/platform/cpu_feature_guard.cc:193] 此 TensorFlow 二进制文件使用 oneAPI 深度神经网络库（在 eDNN 上）进行了优化，以使用以下 CPU性能关键操作中的指令：AVX2 AVX512F FMA 要在其他操作中启用它们，请使用适当的编译器标志重建 TensorFlow。 2024-01-26 23:06:18.289070: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] 无法注册 cuBLAS 工厂：在已注册插件 cu BLAS 的情况下尝试注册工厂 2024-01-26 23 ：06：20.132284：Wtensorflow/stream_executor/platform/default/dso_lo ader.cc:64]无法加载动态库“libnvinfer.so.7”； dlerror: libnvinfe r.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21.iitbhu/.conda/envs/graphgan/lib/2024-01-26 23:06:20.132710:W tensorflow/stream_executor/platform/default/dso_lo ader.cc:64] 无法加载动态库“libnvinfer_plugin.so.7”； dlerror: li bnvinfer_plugin.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21。 iitbhu/.conda/envs/graphgan/lib/ 2024-01-26 23:06:20.132755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc: 38] TF-TRT 警告：无法 dlopen 某些 TensorRT 库。如果您想将 Nvidia GPU 与 TensorRT 一起使用，请确保正确安装了上面提到的缺少的库。
我知道这将毫无问题地运行我的代码，但我想使用 GPU 加速。谁能告诉我我应该做什么来解决这个问题
我预计 GPU 会被检测到，就像我在教程中看到的那样。相反，它开始抛出错误。我还检查了它提到的目录，确实文件丢失了。为了使其工作，我必须安装哪些额外的库？]]></description>
      <guid>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</guid>
      <pubDate>Fri, 26 Jan 2024 18:02:56 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到 ml_utils.model GPS？我看过一些论文引用了这些依赖项，但找不到带有 gp 的 ml_utils 包</title>
      <link>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</link>
      <description><![CDATA[ml_utils 包是否仍然与 .models.gp 一起存在？
我找不到它，但现在已经在 4 篇以上的论文中看到过它。
找到了 pandas ml_utils 文档 (https://github.com/KIC/pandas_ml_utils/blob/master/pandas_ml_utils/model/models.py），但在模型下没有看到任何 GP。有人可以帮我弄清楚这些论文是用什么做的吗？他们都只是说 from ml_utils.model import gp 并在依赖项下列出了 ml_utils 。]]></description>
      <guid>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</guid>
      <pubDate>Fri, 26 Jan 2024 17:11:19 GMT</pubDate>
    </item>
    <item>
      <title>将从 keras YOLOV8Detector 获取的模型更新到 Apple MLPackage/CoreML</title>
      <link>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</link>
      <description><![CDATA[我按照 KerasCV 上的教程使用 YOLOV8 和 KerasCV 进行高效目标检测，并在 不同的数据集
一段时间后，我能够获得预测并将其可视化，如教程中所述：
&lt; /p&gt;
我想在苹果 iOS 应用程序中使用这个模型，所以我使用了 coremltools 包来转换它。然而，“输出”似乎是这样的。 kerascv 制作的产品并不完全是苹果界所期望的。
模型训练完成后，我可以要求进行预测：
 图像，y_true = next(iter(dataset.take(1)))
 y_pred = model.predict(images) // y_pred 是一个字典

y_pred 是包含这些键的字典 [&#39;boxes&#39;, &#39;confidence&#39;, &#39;classes&#39;, &#39;num_detections&#39;]
使用Netron，我可以看看苹果世界所期待的模型的形状
&lt;img alt=&quot; “ src =“https://github.com/keras-team/keras-cv/assets/170917/5fae9594-694a-477c-a7a2-3c4419e3b98a”/&gt;
如何修改/重塑从 kerascv 生成的模型，这样我就可以拥有一个将置信度和坐标答案作为两个单独的输出输出的模型，而不是输出字典？]]></description>
      <guid>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</guid>
      <pubDate>Fri, 26 Jan 2024 13:00:22 GMT</pubDate>
    </item>
    <item>
      <title>wasserstein GAN 中“没有为任何变量提供梯度”</title>
      <link>https://stackoverflow.com/questions/77870522/no-gradients-provided-for-any-variable-in-wasserstein-gan</link>
      <description><![CDATA[我一直在研究一个旨在输出微笑序列的 GAN 模型。在我的训练步骤中，我收到错误“值错误：没有为任何变量提供梯度”，我在生成器的可训练变量的 gan_model 中遇到了这个问题。我已经正确定义了损失和优化器以及鉴别器的梯度裁剪。
编辑
我已经使用 tf.op 函数（tf.reduce_mean）实现了我的损失函数，并检查了它是否可微。我仍然遇到没有为任何变量提供梯度的错误。我的生成器使用注意机制，并且我已经在我的级别检查了生成器中的任何函数是否不可微分或有任何不正确的输入。
wasserstein 损失函数返回合理的值并且输出形状似乎正确
这是我用于定义生成器和训练协议的相关代码。
损失函数
def wasserstein_loss(y_true, y_pred):
    损失 = tf.reduce_mean(y_true * y_pred)
    回波损耗


y_true = tf.constant([1.0, -1.0, 1.0], dtype=tf.float32)
y_pred = tf.constant([0.5, -0.5, 0.2], dtype=tf.float32)

使用 tf.GradientTape() 作为磁带：
    磁带.watch(y_pred)
    损失 = wasserstein_loss(y_true, y_pred)

梯度 = Tape.gradient(loss, y_pred)

print(&quot;损失：&quot;, loss.numpy())
print(&quot;渐变：&quot;,gradient.numpy())

发电机
def 生成器（latent_dim、num_ Protein_tokens、num_smiles_tokens、max_ Protein_seq_length、max_smiles_length）：

    init_hidden_​​state = 输入（形状=（max_smiles_length，），名称=&#39;s0&#39;）
    init_cell_state = 输入（形状=（max_smiles_length，），名称=&#39;c0&#39;）
    隐藏状态 = 初始化隐藏状态
    细胞状态 = 初始化细胞状态

    input_latent = 输入（形状=（max_smiles_length，latent_dim，），名称=&#39;input_latent&#39;）
    输入蛋白质=输入（形状=（max_蛋白质_seq_length，），名称=&#39;输入蛋白质&#39;）
    embedding_ Protein = 嵌入（num_ Protein_tokens，25，mask_zero = True，input_length = max_ Protein_seq_length）（input_ Protein）

    lstm_蛋白质=双向（LSTM（75，return_sequences = True））（嵌入_蛋白质）
    lstm_combined_outputs =[]
    对于范围内的 t（max_smiles_length）：
        上下文= one_step_attention（lstm_ Protein，hidden_​​state）
        lstm_combined，hidden_​​state，cell_state = post_activation_LSTM_cell（输入=上下文，initial_state = [hidden_​​state，cell_state]）
        lstm_combined_outputs.append(lstm_combined)


    lstm_combined_outputs = 连接（轴=1）（lstm_combined_outputs）
    concat_layer = 连接（轴=2）（[input_latent，lstm_combined_outputs]）
    generated_smiles_array = TimeDistributed(Dense(num_smiles_tokens,activation=&#39;softmax&#39;,name=&#39;output_smiles&#39;))(concat_layer)
    output_smiles = softargmax( generated_smiles_array, beta=1e10)

    生成器模型 = 模型（输入=[输入蛋白，init_hidden_​​state，init_cell_state，input_latent]，输出=output_smiles，名称=&#39;生成器&#39;）

    返回生成器模型

生成器模型 = 生成器（latent_dim、num_ Protein_tokens、num_smiles_tokens、max_ Protein_seq_length、max_smiles_length）
gen_optimizer = RMSprop(learning_rate=0.00005)
生成器模型.编译（损失= wasserstein_loss，优化器= gen_optimizer）

我非常感谢有关此问题的任何帮助，并很乐意分享任何可能相关的代码]]></description>
      <guid>https://stackoverflow.com/questions/77870522/no-gradients-provided-for-any-variable-in-wasserstein-gan</guid>
      <pubDate>Wed, 24 Jan 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pre-Train Bert 进行二元分类的 Shap 值：如何提取摘要图？</title>
      <link>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</link>
      <description><![CDATA[我使用预训练 bert 模型进行二元分类。用小数据训练我的模型后，我想提取这样的摘要图 我想要的图&lt; /a&gt;.然而，我想用文字来代替这些重要的特征。
但是，我不确定一切都好，因为 shap_value 的形状只是二维的。其实，这是有道理的。尽管如此，我没有得到图表，因为如果我使用这段代码，我遇到了两个问题：
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=comments_text)`

问题太不明智了：如果我用 shap_values 或 shap_values[0] 或  更改 shap_values[:,:10] shap_values.values vb.我总是遇到
516：断言 len(shap_values.shape) != 1，“汇总图需要一个矩阵
shap_values，而不是向量。” ==&gt; AssertionError：摘要图需要一个矩阵
shap_values，不是向量。

（拳头问题）
顺便说一句，我的 shap_value 由 10 个输入（shape_value.shape）组成。如果我选择范围从 1 到 147 的最大值，那么绘制图表就一切顺利。然而，此时，该图不合适：我的图仅由蓝点组成（-第二个问题-）。像这样只有蓝色。
注意：shap_values[:,:10]如果数字（10）改变不同的数字，图表显示不同的单词，但图表的总数相同（最多 20）。只有部分词序可以改变。
最小可重现示例：
&lt;前&gt;&lt;代码&gt;导入nlp
将 numpy 导入为 np
将 pandas 导入为 pd
将 scipy 导入为 sp
进口火炬
进口变压器
进口火炬
导入形状

# 加载 BERT 情感分析模型
tokenizer = Transformers.DistilBertTokenizerFast.from_pretrained(
    “distilbert-base-uncased”
）
模型 = Transformers.DistilBertForSequenceClassification.from_pretrained(
    “distilbert-base-uncased-finetuned-sst-2-english”
).cuda()


如果 torch.cuda.is_available():
    设备 = torch.device(“cuda”)
    print(&#39;我们将使用 GPU:&#39;, torch.cuda.get_device_name(0))

别的：
    print(&#39;没有可用的 GPU，请使用 CPU。&#39;)
    设备 = torch.device(“CPU”)

定义 f(x):
    # 对批量句子进行编码
    输入 = tokenizer.batch_encode_plus(x.tolist(), max_length=450,add_special_tokens=True, return_attention_mask=True,padding=&#39;max_length&#39;,truncation=True,return_tensors=&#39;pt&#39;)

    # 将张量发送到与模型相同的设备
    input_ids = 输入[&#39;input_ids&#39;].to(设备)
    注意掩码 = 输入[&#39;注意掩码&#39;].to(设备)
    ＃ 预测
    使用 torch.no_grad()：
        输出=模型（input_ids，attention_mask=attention_masks）[0].detach（）.cpu（）.numpy（）
    分数 = (np.exp(输出).T / np.exp(输出).sum(-1)).T
    val = sp.special.logit(scores[:, 1]) # 使用 1 与其余 logit 单位
    返回值
# 使用 token masker 构建一个解释器
解释器 = shap.Explainer(f, tokenizer )

imdb_train = nlp.load_dataset(“imdb”)[“火车”]
shap_values = 解释器(imdb_train[:10],fixed_context=1,batch_size=16)
队列 = {“”：shap_values}
team_labels = 列表(cohorts.keys())
team_exps = 列表(cohorts.values())
对于范围内的 i(len(cohort_exps))：
    如果 len(cohort_exps[i].shape) == 2:
        队列_exps[i] = 队列_exps[i].abs.mean(0)
特征=cohort_exps[0].data
特征名称=同类群组表达式[0].特征名称
#values = np.array([cohort_exps[i].values for i in range(len(cohort_exps))], dtype=object)
值 = np.array([cohort_exps[i].i 在范围内的值(len(cohort_exps))])
feature_importance = pd.DataFrame(list(zip(feature_names, sum(values))), columns=[&#39;features&#39;, &#39;importance&#39;])
feature_importance.sort_values(by=[&#39;重要性&#39;], 升序=False, inplace=True)
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=imdb_train[&#39;text&#39;][10:20],show=False)


上面的代码产生相同的结果。我花了大约200台电脑，但没有成功:(。我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</guid>
      <pubDate>Tue, 09 Jan 2024 08:49:10 GMT</pubDate>
    </item>
    </channel>
</rss>