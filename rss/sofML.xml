<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Jan 2024 15:15:07 GMT</lastBuildDate>
    <item>
      <title>如何使用经过训练/测试的线性回归模态进行预测</title>
      <link>https://stackoverflow.com/questions/77840461/how-to-make-prediction-with-linear-regression-modal-that-has-been-trained-tested</link>
      <description><![CDATA[我在我的数据集上制作了线性回归模态。但我不知道如何让模态进行预测。
我的数据集的格式为“年份”、“旅程类型”、“值”作为列标题。我想预测数据集中未包含的年份的值（因为我没有此数据）。所以我想预测 2023-2027 年的值。
线性回归的变量是
X = &#39;年份&#39;
y = &#39;值&#39;
我尝试了不同的方法，但似乎都不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/77840461/how-to-make-prediction-with-linear-regression-modal-that-has-been-trained-tested</guid>
      <pubDate>Thu, 18 Jan 2024 15:14:05 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 过度拟合 [关闭]</title>
      <link>https://stackoverflow.com/questions/77839964/xgboost-overfitting</link>
      <description><![CDATA[我一直在尝试使用 XGBoost（Last sem 迷你项目）构建流失预测模型。
但无论我做什么，模型都会过度拟合，我无法提前停止，因为我找不到最佳点。
该模型仅预测未见过的数据集中的一个值（在本例中为 1）。
是因为训练数据集（它是通过 minmaxscaler 进行平衡和缩放的）吗？
499998 行 × 11 列
有人遇到过这种情况吗？
我缩放并平衡了训练数据集
这些是我使用的参数：

测试大小 = 0.33
随机状态 = 7
子样本：0.5
reg_lambda: 5
reg_alpha：0.1
n_估计器：800
最小分割损失：0
最小儿童体重：0
最大深度：3
学习率：0.3
colsample_bytree：0.7
colsample_bynode：0.9
colsample_bylevel: 0.7


训练精度：0.9993223840142329
测试精度：0.9991333333333333
混淆矩阵：流失 0.0 1.0
行_0
0 82533 140
1 3 82324
]]></description>
      <guid>https://stackoverflow.com/questions/77839964/xgboost-overfitting</guid>
      <pubDate>Thu, 18 Jan 2024 14:00:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在XGBoost模型中应用滑动窗口技术？</title>
      <link>https://stackoverflow.com/questions/77839471/how-to-apply-sliding-windows-technique-in-the-xgboost-model</link>
      <description><![CDATA[我正在处理一个在 2023 年具有显着价格不连续性的时间序列。我相信步进（或滑动窗口）方法可以帮助我，但我在将其适应 XGBoost 时遇到了困难（它最初有效）非常适合指数平滑）。
我首先导入并预处理数据库，如下所示：
df = pd.read_csv(&quot;https://raw.githubusercontent.com/nunesisabella/Analise-Preditiv-Cacau/main/ICCO_2018-2024.csv&quot;,sep=&quot;;&quot;)

df[&quot;Valor_Londres&quot;] = df[&quot;Valor_Londres&quot;].str.replace(&quot;,&quot;, &quot;&quot;).astype(float)
df[&quot;Valor_NY&quot;] = df[&quot;Valor_NY&quot;].str.replace(&quot;,&quot;, &quot;&quot;).astype(float)
df[&quot;ICCO_USD&quot;] = df[&quot;ICCO_USD&quot;].str.replace(&quot;,&quot;, &quot;&quot;).astype(float)
df[&quot;ICCO_EUR&quot;] = df[&quot;ICCO_EUR&quot;].str.replace(&quot;,&quot;, &quot;&quot;).astype(float)

df[&#39;Data&#39;] = pd.to_datetime(df[&#39;Data&#39;], format=&#39;%d.%m.%Y&#39;)

df.set_index(&#39;数据&#39;, inplace=True)

df = df.sort_values(&#39;数据&#39;)

所以我只选择 ICCO_USD 列：
df = df[&#39;ICCO_USD&#39;]
然后，我分离数据集：
train = df.loc[df.index &lt;; &#39;01-01-2022&#39;]
测试 = df.loc[df.index &gt;= &#39;01-01-2022&#39;]

我定义我的历史变量和我的预测列表：
历史 = [i for i in train]
预测 = 列表()

我执行差异：
def 差异（数据集，间隔）：
    差异=列表（）
    对于范围内的 i（间隔，len（数据集））：
        值 = 数据集[i] - 数据集[i-间隔]
        diff.append(值)
    返回差异

def inverse_difference(历史、预测、区间):
    返回预测+历史[-区间]

最后，应用前向技术：
for t in range(len(test))：
    直径 = 20
    diff = 差异（历史，直径）

    #model_EXPS = SimpleExpSmoothing(diff)

    #model_EXPS_fit = model_EXPS.fit()
    
    #y_pred = model_EXPS_fit.forecast()[0]

    model_XGB = xgb.XGBRegressor(n_estimators=1000)

    model_XGB_fit = model_XGB.fit(diff, test.values[:len(diff)]) #错误

    y_pred = model_XGB.predict()
    
    y_pred = inverse_difference(历史记录, y_pred, dias)

    pred.append(y_pred)

    valor_real = 测试[t]

    历史记录.append(valor_real)

    print(&#39;Valor predito: &#39;, y_pred, &#39;Valor real:&#39;, valor_real)

对于指数平滑模型，该方法效果很好，因为它不明确依赖于 X_train 和 y_train 的拟合。对于 XGBoost，这似乎是必需的。我该如何适应它？]]></description>
      <guid>https://stackoverflow.com/questions/77839471/how-to-apply-sliding-windows-technique-in-the-xgboost-model</guid>
      <pubDate>Thu, 18 Jan 2024 12:40:25 GMT</pubDate>
    </item>
    <item>
      <title>T 的 VC 维数是多少？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77839409/what-is-the-vc-dimension-of-t</link>
      <description><![CDATA[令 T 包含所有单向（内部为 +，外部为 -）等边三角形的无限集合，面朝上。
T 的 VC 维数是多少？证明你的答案。
我尝试绘制所有可以被三角形打碎的 3 个点的标签。但是，我不知道这是不是真的！
我认为 VC-D = 4，但我同意从其他人那里获得更多答案来检查...]]></description>
      <guid>https://stackoverflow.com/questions/77839409/what-is-the-vc-dimension-of-t</guid>
      <pubDate>Thu, 18 Jan 2024 12:31:17 GMT</pubDate>
    </item>
    <item>
      <title>模型遭受巨额亏损</title>
      <link>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</link>
      <description><![CDATA[我正在尝试按标题制作文本生成器。文本最大长度为2500，词典大小为45,000字。这是我正在使用的模型。训练过程中，损失增加，但准确率保持不变。
&lt;前&gt;&lt;代码&gt;纪元 1/75
1311/1311 [================================] - 461s 347ms/步 - 损失：27230606.0000 - 准确度：0.0382
纪元 2/75
1311/1311 [================================] - 454s 346ms/步 - 损失：78650848.0000 - 准确度：0.0382


我在 anaconda 环境中使用 Tensorflow GPU 和 python 3.11。
模型 = keras.Sequential([
    嵌入（vocab_size，256，input_length = max_sequence_length），
    LSTM（单位= 256，kernel_regularizer = l2（0.01），return_sequences = True），
    LSTM（单位= 128，kernel_regularizer = l2（0.01）），
    密集（max_sequence_length，激活=&#39;softmax&#39;）
]）

亚当 = 亚当(lr=0.01)

model.compile(optimizer=adam,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
model.fit（标题_序列_填充，食谱_序列_填充，纪元= 75，详细= 1，
          回调=[ModelCheckpoint(filepath=Settings.new_model_path)])

我尝试增加单位数量、损失类型​​，但没有任何效果。]]></description>
      <guid>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</guid>
      <pubDate>Thu, 18 Jan 2024 11:28:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的有损与无损音频格式</title>
      <link>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</link>
      <description><![CDATA[我们希望提供一种通过声音识别疾病的机器学习模型。特征提取基于专有算法。通常我们一直使用wav文件。我们一直在问自己是否也可以使用像 mp3 这样的东西？由于我们可能无法再次收集我们收集的数据，并且我们无法预见我们的专有算法的进一步开发在某个时候将需要什么样的信息，因此我们担心像 mp3 这样的东西会导致太多信息丢失。你觉得怎么样？
疾病示例：多动症、抑郁症、糖尿病、帕金森病、自杀。
算法生成特征的类别示例：旋律、节奏、停顿、语速、动态...
我对具体答案不太感兴趣，因为我知道由于某些细节的悬而未决的问题，不可能给出具体答案。更多的是分享经验和交流想法。例如，有人在机器学习领域有过这样的经验：MP3 中被切除的区域通常对 ML 算法影响很小或没有影响。这只是一个例子。我在互联网上还没有真正找到有关此主题的任何内容。
即使这与“非此即彼”没有太大关系。关于支持格式的决定，一个 &lt;a href=&quot;https://medium.com/voice-tech-podcast/improve-your-machine-learning-with-compressed-audio-3393a6c55aba&quot; rel=&quot;nofollow noreferrer例如，文章&lt;/a&gt;建议如下：“数据增强是机器学习领域众所周知的实践。我们可以简单地将音频数据的编码版本视为数据的增强，就像我们通过添加交通噪声或模拟干净语音的房间回声一样。例如，仅用几个不同的 Opus 质量级别来增强训练数据将改善所有 Opus 测试样本的分类。” ...这非常有趣。]]></description>
      <guid>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</guid>
      <pubDate>Thu, 18 Jan 2024 08:13:51 GMT</pubDate>
    </item>
    <item>
      <title>Python dgl 库 API 更新</title>
      <link>https://stackoverflow.com/questions/77837193/python-dgl-library-api-updates</link>
      <description><![CDATA[这是我的代码：
def 标准化（自我，logits）：
    self.\_logits_name = “\_logits”
    self.\_normalizer_name = “\_norm”
    self.g.edata\[self.\_logits_name\] = logits

    self.g.update_all(fn.copy_u(self._logits_name, self._logits_name),
                     fn.sum(self._logits_name, self._normalizer_name))
    返回 self.g.edata.pop(self._logits_name), self.g.ndata.pop(self._normalizer_name)

def edge_softmax(自身):

    如果 self.l0 == 0:
        分数 = self.softmax(self.g, self.g.edata.pop(&#39;a&#39;))
    别的：
        分数，归一化器 = self.normalize(self.g.edata.pop(&#39;a&#39;))
        self.g.ndata[&#39;z&#39;] = 标准化器[:,0,:].unsqueeze(1)

    self.g.edata[&#39;a&#39;] = 分数[:,0,:].unsqueeze(1)

这是堆栈跟踪：
回溯（最近一次调用最后一次）：
文件“/datasets/\_deepnote_work/train.py”，第 211 行，位于 \ 中
主要（参数）

文件“/datasets/\_deepnote_work/train.py”，第 130 行，在 main 中
logits = 模型（特征）

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1518 行，位于 \_wrapped_call_impl
返回 self.\_call_impl(\*args, \*\*kwargs)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1527 行，位于 \_call_impl
返回forward_call(\*args, \*\*kwargs)

文件“/datasets/\_deepnote_work/gat.py”，第 209 行，向前
h，边缘 = self.gat_layers\[0\](h，边缘)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1518 行，位于 \_wrapped_call_impl
返回 self.\_call_impl(\*args, \*\*kwargs)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1527 行，位于 \_call_impl
返回forward_call(\*args, \*\*kwargs)

文件“/datasets/\_deepnote_work/gat.py”，第 105 行，向前
self.edge_softmax()

文件“/datasets/\_deepnote_work/gat.py”，第 166 行，edge_softmax
分数，归一化器 = self.normalize(self.g.edata.pop(&#39;a&#39;))

文件“/datasets/\_deepnote_work/gat.py”，第 157 行，标准化
self.g.update_all(fn.copy_u(self.\_logits_name, self.\_logits_name),

文件“/root/venv/lib/python3.9/site-packages/dgl/heterograph.py”，第 5110 行，位于 update_all
ndata = core.message_passing()
文件“/root/venv/lib/python3.9/site-packages/dgl/core.py”，第 398 行，message_passing
ndata = invoke_gspmm(g, mfunc, rfunc)

文件“/root/venv/lib/python3.9/site-packages/dgl/core.py”，第 361 行，invoke_gspmm
x = alldata\[mfunc.target\]\[mfunc.in_field\]

文件“/root/venv/lib/python3.9/site-packages/dgl/view.py”，第 80 行，在 _getitem_ 中
返回 self.\_graph.\_get_n_repr(self.\_ntid, self.\_nodes)\[key\]

文件“/root/venv/lib/python3.9/site-packages/dgl/frame.py”，第 688 行，在 _getitem_ 中
返回 self.\_columns\[name\].data
关键错误：&#39;\_logits&#39;

我查看了DGLEdgeBatch的文档，但没有找到任何解决方案
链接到文档：https://docs.dgl.ai/en/1.1.x/api/python/udf.html#edge-wise-user-defined-function
阅读 DGL 的文档并尝试了一些替代函数。但他们没有工作。
因此，如果有人可以帮助我修复/更新代码，那将是一个巨大的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77837193/python-dgl-library-api-updates</guid>
      <pubDate>Thu, 18 Jan 2024 06:02:39 GMT</pubDate>
    </item>
    <item>
      <title>召回分数！=使用confusion_matrix手动计算</title>
      <link>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</link>
      <description><![CDATA[我遇到了一个问题，即使用 recall_score(y, y_pred) 获得的召回分数与使用 confusion_matrix 手动计算的值不匹配。
不仅如此，召回率与特异性的值完全相同，我也在下面手动计算了该值。
这是我正在使用的相关代码：
recall = recall_score(y, y_pred) # &lt;-- 不同的分数

conf_matrix = fusion_matrix(y, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()
Manual_recall = tp / (tp + fn) # &lt;-- 达到这个分数
特异性 = tn / (tn + fp) # &lt;-- 与上面的分数相同

这是发生这种情况的终端中打印的混淆矩阵的示例：
&lt;前&gt;&lt;代码&gt;[[34 6]
 [20 20]]

科学套件召回：0.85
手动召回：0.5
或
&lt;前&gt;&lt;代码&gt;[[29 11]
 [9 31]]

科学套件召回：0.725
手动召回：0.775
问题：
scikit-learn 返回的召回和手动召回不会产生相同的值。
问题：
为什么recall_score和使用confusion_matrix的手动计算可能会产生不同的召回分数结果？
更多信息...

这是一个二元分类问题。

我正在使用 recall_score 的默认阈值。

我尝试确定混淆表是否准确（确实如此）。

]]></description>
      <guid>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</guid>
      <pubDate>Wed, 17 Jan 2024 18:08:23 GMT</pubDate>
    </item>
    <item>
      <title>事故报告统一分类：多类分类问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77825594/accident-reports-to-unified-taxonomy-a-multi-class-classification-problem</link>
      <description><![CDATA[我来这里是为了集思广益，为我的标签问题寻找可能的解决方案。
核心数据
我有约 4500 份滑翔伞事故报告。报告是非结构化文本，有些在多个页面上对事件的不同方面进行了详细阐述，有些只有几行。
我的想法
从事故中提取语义相关信息，形成统一的分类，以便进一步分析事故原因等。
我的方法
我想使用主题建模为所有事故创建统一的分类法，其中几乎可以捕获每个事故的所有相关信息。然后，分类法 + 一次事故将形成一次 API 调用。在大约 4500 次 API 调用之后，我最终应该得到由统一分类法表示的所有事故。
示例
分类法有不同的类别，例如天气、飞行员经验、表面状况等。这些主要类别进一步细分，例如，天气 -&gt; 天气风-&gt;速度。
当前状态
目前，我的分类法尚未完成，但我估计在一次事故中大约需要注意 150 个参数。一年前我也研究过类似的问题，用 GPT 构建了一个语音助手。在那里，我使用 Davinci 将语音输入转换为具有预定义 JSON 操作的 JSON 格式。这对于大多数情况都适用，但我必须对输出进行后处理，因为格式并不总是正确的，等等。
目前，我的担忧和问题是：

与我的语音助手 (14) 相比，现在有更多的类别 (150) 和更大的文本输入（语音助手只有一句话，现在一整份事故报告多达 8 页），GPT 使用的类别与那些不同分类学中定义的，或幻觉不可预测的。
如何有效地从 GPT 获取结构化输出（此处以分类法的形式）？
我的解决方案能否按预期工作？
这是实现我的目标的明智方法吗？
有哪些替代方案？
]]></description>
      <guid>https://stackoverflow.com/questions/77825594/accident-reports-to-unified-taxonomy-a-multi-class-classification-problem</guid>
      <pubDate>Tue, 16 Jan 2024 11:59:16 GMT</pubDate>
    </item>
    <item>
      <title>使用二元分类、体育场景的意外结果[关闭]</title>
      <link>https://stackoverflow.com/questions/77821455/unexpected-results-using-binary-classification-sports-scenario</link>
      <description><![CDATA[我有一个按季度划分的大型体育数据集，目的是预测复出。我创建了一个目标列，将第一节结束时领先的球队与赢得比赛的球队进行比较。我尝试了本专栏的两种变体：

多类分类版本：将游戏行标记为“False” （第一节结束时领先的球队也是赢得比赛的球队），而“客场”则为（客队在第一节结束时落后，但最终逆转赢得了比赛），而“主场”队则在第一节比赛中落后。 （主队在季度末落后，但后来逆转赢得了比赛。在这个版本中，我将其作为多类分类问题处理，因为有 3 种可能的类别（假、客队、主场）。

二元分类版本：将目标列标记为 False：（第一节结束时领先的球队仍然领先，或者他们在第一节结束时打平，因此没有“逆转”），或者正确：第一节结束时有一支球队落后，但他们逆转赢得了比赛。


我有点不确定该使用什么方法。部分问题在于，正如您可能想象的那样，卷土重来并不常见，因此 True 类已经很小了。进入多类会创建两个微类。
我尝试过一些提高平衡准确性的方法：
-下采样（在多类和二元方法中）
-添加更多数据（几年的数据），删除第一节末双方打平的比赛，这自然会降低“错误”数据的采样率。在“安全”的环境中上课因为该模型的目的是专门预测第一节末的逆转（意味着平局与该模型无关）
-进一步将该数据下采样到大约 40%/60% 真/假（从大约 15%/85% 的自然分布）
-添加了一个工程特征（分数增量），即第一季度末的主客场得分，正如预期的那样，它成为了一个高度预测的特征。因此，如果主队获胜，则该值始终为负数；如果客队获胜，则该值始终为正数。
这就是有趣的地方。我专注于二元分类方法，因为在将其作为二元分类问题运行时，我获得了更高的平衡精度。让我非常惊讶的是，我昨晚在现场游戏中对此进行了测试，并得到了“True”结果。响应概率为 67%。作为测试，我修改了 API 调用并交换了领先/落后的团队，当然还交换了工程分数增量列上的符号。让我震惊的是，它让我“东山再起”。再次正确的决定，但为 57%。我一直在努力理解这意味着什么，因为模型肯定不会说“现在落后的球队将会回来赢得比赛”，不是吗？这看起来很奇怪，但也让我重新考虑是否要重新关注多类分类（主场、客场、假）。只是看起来这并不是一条路线，这看起来确实是一个二进制问题。]]></description>
      <guid>https://stackoverflow.com/questions/77821455/unexpected-results-using-binary-classification-sports-scenario</guid>
      <pubDate>Mon, 15 Jan 2024 17:36:12 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的弱形式公式损失函数[关闭]</title>
      <link>https://stackoverflow.com/questions/77461940/weak-form-fomulation-loss-function-for-a-neural-network</link>
      <description><![CDATA[我在 Matlab 上编写了一个神经网络算法，它基本上可以求解以下偏微分方程：div(sigma)=f，这是固体力学的平衡方程。我的新目标是创建一个神经网络，它不是求解先前的方程（强形式），而是在虚功原理或最小势能的背景下求解弱形式公式。
对于强形式，我恢复了板的每个配置点的有用量，然后施加了控制方程。最终结果是一个 900x500 的矩阵，其中 900 是评估数量的搭配点，500 是神经元的数量，代表 div(sigma) 部分，向量 f 为 900x1，代表外力。通过求解这个方程，我获得了一个 500x1 的向量，通过它我上传了神经元的权重。在弱形式的背景下，我实现了虚拟工作原理，并将内部工作等于外部工作，但我不知道如何在矩阵维度上保持一致，因为内部和外部工作应该具有相同的维度，并且输出具有是一个 500x1 的向量，它允许我更新神经元的权重。]]></description>
      <guid>https://stackoverflow.com/questions/77461940/weak-form-fomulation-loss-function-for-a-neural-network</guid>
      <pubDate>Fri, 10 Nov 2023 17:48:19 GMT</pubDate>
    </item>
    <item>
      <title>我无法从 C++ 安装 openpose 库来进行姿势检测</title>
      <link>https://stackoverflow.com/questions/76959397/i-could-not-installl-a-openpose-library-from-c-for-pose-detection</link>
      <description><![CDATA[我已经使用 C++ 为我的姿势检测项目安装了 OpenPose 库。但是，我在安装过程中遇到了困难，特别是在尝试按照  上提供的说明下载模型时https://sourceforge.net/projects/openpose.mirror/。
这些是他们提供的说明：
&lt;前&gt;&lt;代码&gt;1。双击“models/getBaseModels.bat”下载所需的身体、面部和手部模型。
    - 可选：双击“models/getCOCO_and_MPII_optional.bat”下载 COCO 和 MPII 模型（速度较慢且不太准确，只有在确实有理由这样做时才下载）。
2.检查所有信息：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/tree/v1.7.0
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/
3.特别是C++快速入门指南：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/quick_start.md
4. 对于 Python，请检查 C++ 快速入门指南（相同标志）和 Python 测试文档：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/quick_start.md
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/modules/python_module.md#testing，但替换“cd build/examples/tutorial_api_python”通过“cd python/”。
        - 注意：其余的 python_module.md 指令是针对 GitHub 源代码库的，您可以在这里忽略它们。
    - Python 代码示例：

cd {OpenPose_root_path}
cd 蟒蛇/
python openpose_python.py

但是，当我尝试从下载的文件夹运行 models/getBaseModels.bat 脚本时，它不会下载或安装任何内容。相反，它不断尝试下载但没有成功。这是我在命令提示符中看到的输出片段：
------------------------ 身体、脚、脸和手模型 ---------- ----------------
----- 下载身体姿势（COCO 和 MPI）、面部和手部模型 -----

------------------------- 姿势（身体+脚）模型 ------------------ --------
身体 (BODY_25)
--2023-08-23 12:50:47-- http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel
正在解析posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)... 64:ff9b::8002:dc39, 128.2.220.57
连接到posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|64:ff9b::8002:dc39|:80...失败：未知错误。
正在连接到posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|128.2.220.57|:80...


由于此问题，我无法进一步继续我的项目。您能否提供一个解决方案或建议一种用于姿势检测和获取关键坐标的替代方法]]></description>
      <guid>https://stackoverflow.com/questions/76959397/i-could-not-installl-a-openpose-library-from-c-for-pose-detection</guid>
      <pubDate>Wed, 23 Aug 2023 07:56:16 GMT</pubDate>
    </item>
    <item>
      <title>ValidationError：StuffDocumentsChain __root__ 出现 1 个验证错误</title>
      <link>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</link>
      <description><![CDATA[我收到此错误ValidationError：在 llm_chain input_variables 中找不到 StuffDocumentsChain __root__ document_variable_name 上下文的 1 个验证错误：[&#39;chat_history&#39;、&#39;user_query&#39;、&#39;relevant_context&#39;] (type=value_error)
在使用 load_qa_chain 时，我搜索了此错误，但没有找到与此相关的任何内容。谁能告诉我这里缺少什么。
代码：
template = &quot;&quot;&quot;您是一个正在与人类对话的聊天机器人。

给定长文档和问题的以下提取部分，创建最终答案。

{相关上下文}

{聊天记录}
人类：{user_query}
聊天机器人：“”“”

提示=提示模板(
input_variables=[“chat_history”, “user_query”, “relevant_context”],
模板=模板
）

内存= ConversationBufferMemory（memory_key =“聊天历史记录”，input_key =“用户查询”）

llm = OpenAI()
llm_chain = LLMChain(
    llm=llm,
    提示=提示，
    内存=内存，
）

链 = load_qa_chain(
    llm，chain_type =“东西”，内存=内存，提示=提示
）
]]></description>
      <guid>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</guid>
      <pubDate>Thu, 27 Jul 2023 05:20:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型的扩展</title>
      <link>https://stackoverflow.com/questions/64739128/scaling-on-machine-learning-models</link>
      <description><![CDATA[我对机器学习模型中的缩放概念有点困惑。
在分类中，如果变量具有不同的尺度，我通常对自变量进行缩放，对目标变量进行标签编码，并对预测结果进行逆变换以获得实际标签
在回归中，如果我的变量不同，我知道我们必须缩放自变量，我是否也应该缩放我的目标变量？
如果我在上述情况下的理解是正确的，有人可以帮助我吗？我应该在回归模型中缩放我的目标变量吗？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/64739128/scaling-on-machine-learning-models</guid>
      <pubDate>Sun, 08 Nov 2020 14:18:39 GMT</pubDate>
    </item>
    <item>
      <title>在 sklearn 中训练后是否必须再次使用 fit() ？</title>
      <link>https://stackoverflow.com/questions/49466944/do-i-have-to-use-fit-again-after-training-in-sklearn</link>
      <description><![CDATA[我正在使用LinearRegression()。您可以在下面看到我为预测新功能所做的工作：

&lt;前&gt;&lt;代码&gt; lm = 线性回归()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=say)
    lm.fit(X_train, y_train)
    lm.predict(X_test)
    scr = lm.score(X_test, y_test)
    lm.fit(X, y)
    pred = lm.predict(X_real)

我真的需要lm.fit(X, y)行吗？或者我可以不使用它吗？另外，如果我不需要计算准确性，您认为以下方法是否更好，而不是使用训练和测试？ （如果我不想测试）：

&lt;前&gt;&lt;代码&gt; lm.fit(X, y)
    pred = lm.predict(X_real)

即使我获得了 0.997 的准确度，预测值也没有接近或偏移。有没有办法让预测更准确？]]></description>
      <guid>https://stackoverflow.com/questions/49466944/do-i-have-to-use-fit-again-after-training-in-sklearn</guid>
      <pubDate>Sat, 24 Mar 2018 16:11:42 GMT</pubDate>
    </item>
    </channel>
</rss>