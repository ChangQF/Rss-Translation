<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Jun 2024 18:20:12 GMT</lastBuildDate>
    <item>
      <title>如何使用 detector2 区分灰度图像中的两种颜色并掩盖它们？</title>
      <link>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</link>
      <description><![CDATA[我刚开始使用detectron2，我计划将它用于一个项目。该项目包括使用模型来区分灰度图像中的对象。图像由形状怪异的灰色单元格组成，而其余空间为黑色。我的任务是使用该模型并描绘出灰色单元格的形状。
示例图像：
单元格的灰度图像
我曾尝试使用预先存在的模型来解决这个问题，但它们无法识别出物体的存在。解决这个问题的最佳方法是什么？
提前谢谢您！]]></description>
      <guid>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</guid>
      <pubDate>Thu, 13 Jun 2024 17:36:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习视觉模型以 95% 的准确率预测新数据相同的标签</title>
      <link>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</guid>
      <pubDate>Thu, 13 Jun 2024 16:45:35 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 2 个特征，但 StandardScaler 需要 3 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/78619143/valueerror-x-has-2-features-but-standardscaler-is-expecting-3-features-as-inpu</link>
      <description><![CDATA[我的代码中出现此错误“
ValueError：X 有 2 个特征，但 StandardScaler 需要 3 个特征作为输入。”
我正在使用神经网络训练我的模型以预测 RSC（雷达截面）的幅度。]]></description>
      <guid>https://stackoverflow.com/questions/78619143/valueerror-x-has-2-features-but-standardscaler-is-expecting-3-features-as-inpu</guid>
      <pubDate>Thu, 13 Jun 2024 16:31:11 GMT</pubDate>
    </item>
    <item>
      <title>不一致的否定 [关闭]</title>
      <link>https://stackoverflow.com/questions/78619130/inconsistent-nos</link>
      <description><![CDATA[`
#表示发现样本 [154,53] 的编号不一致
#这是来自 kaggle 的糖尿病预测模型
x_train,x_test,y_train_test=train_test_split(x, y, test_size=0.2`,random_state=42)在此处输入图片描述
我尝试更改随机状态值，但仍然出现相同的错误，如果有人知道如何解决它。请在 3 天内尽快完成。]]></description>
      <guid>https://stackoverflow.com/questions/78619130/inconsistent-nos</guid>
      <pubDate>Thu, 13 Jun 2024 16:28:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个 AMD GPU 运行 Ollama [关闭]</title>
      <link>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</link>
      <description><![CDATA[问题：
我尝试在配备多个 AMD GPU 的系统上运行 Ollama，但在正确使用所有 GPU 时遇到了困难。
设置详细信息：

操作系统：RedHat
GPU：MI210 x 4
Ollama 版本：0.1.42
ROCm

面临的问题：

似乎只使用了一个 GPU，或者没有明显的性能改进。
[watch -n 0.1 /opt/rocm/bin/rocm-smi]
0 2 0x740f，30145 63.0°C 253.0W N/A，N/A，0 1700Mhz 1600Mhz 0% 自动 300.0W 60% 100%
1 3 0x740f，41677 28.0°C 41.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
2 4 0x740f，39309 31.0°C 40.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
3 5 0x740f, 50825 35.0°C 40.0W N/A, N/A, 0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%

问题：

我是否缺少在 Ollama 中启用多 GPU 支持的具体步骤？
Ollama 中是否需要任何其他配置设置才能进行多 GPU 设置？

如能提供任何指导或详细步骤以正确设置和验证 Ollama 是否使用多个 AMD GPU，我们将不胜感激！
提前致谢！
我尝试过 /set 参数 num_gpu 12，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</guid>
      <pubDate>Thu, 13 Jun 2024 15:56:57 GMT</pubDate>
    </item>
    <item>
      <title>尝试将 Kaggle 笔记本提交到 GitHub 存储库时出错？如何解决此问题</title>
      <link>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository-h</link>
      <description><![CDATA[提交内核时发生错误：ConcurrencyViolation 序列号必须匹配草稿记录：KernelId=59714315、ExpectedSequence=43、ActualSequence=42、AuthorUserId=16388128（这是什么意思）
当我尝试将笔记本从 kaggle 提交到 github 时出现此错误。我该如何解决这个问题？
我原本以为它会直接提交到 github 而不会遇到任何问题]]></description>
      <guid>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository-h</guid>
      <pubDate>Thu, 13 Jun 2024 15:06:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 `tf.data.Dataset.from_generator` 训练序列模型时 Tensorflow 性能下降</title>
      <link>https://stackoverflow.com/questions/78618554/tensorflow-performance-drop-when-training-sequential-model-using-tf-data-datase</link>
      <description><![CDATA[我正在训练二元分类问题中的顺序模型。我的数据集是 HDF 格式，包含许多文件，这些文件通常太大而无法放入内存中。为了解决这个问题，我尝试使用基于 tf.data.Dataset.from_generator 的 TensorFlow 管道方法。但是，经过多次尝试（使用这篇文章等资源），我发现训练模型的性能明显下降。
我设法使用以下代码在通用数据集中复制了该问题：
import tensorflow as tf
import tensorflow.keras as keras
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

def set_seeds(seed=999):
tf.random.set_seed(seed)
np.random.seed(seed)
tf.keras.utils.set_random_seed(seed) # 设置种子base-python、numpy 和 tf

n_features = 5

# 生成合成数据集并分成训练集和测试集
X, y = make_classification(n_samples=1_000_000, n_features=n_features, n_classes=2, random_state=42)
X_train = pd.DataFrame(X)
y_train = pd.DataFrame(y)

X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# 定义一个顺序模型
def define_model(n_features=n_features):
model = keras.models.Sequential([
keras.layers.BatchNormalization(input_shape=(n_features, )),
keras.layers.Dense(10,activation=&#39;relu&#39;),
keras.layers.Dense(1,activation=&#39;sigmoid&#39;)
])
return model

def compile(model):
# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])


基于 DataFrame 方法的训练
当我使用 pd.DataFrame 训练模型时，我得到以下结果：
# 基于 pd.DataFrame 进行训练
set_seeds()
model = define_model()
compile(model)
history = model.fit(X_train, y_train, epochs=10, batch_size=10_000,validation_split=0.0, verbose=True)
ax = pd.DataFrame(history.history).plot()
ax.set_ylim(0, 1.0)

# 在测试样本上进行评估
model.evaluate(X_test, y_test, batch_size=10_000)


这大约需要 5 秒钟，并且准确率约为 0.96。
基于 Dataset 方法进行训练
但是，当我使用 tf.data.Dataset 进行训练时，代码如下：
class Generator:
def __call__(self):
Yield X_train.values, y_train.values

ds_train = tf.data.Dataset.from_generator(
Generator(),
output_signature=(
tf.TensorSpec(shape=(None, n_features), dtype=tf.float32),
tf.TensorSpec(shape=(None, 1), dtype=tf.int32)
)
)

set_seeds()
model = define_model()
compile(model)
history = model.fit(ds_train, epochs=10, batch_size=10_000, verbose=True)
ax = pd.DataFrame(history.history).plot()
ax.set_ylim(0, 1.0)

model.evaluate(X_test, y_test, batch_size=10_000)

我得到的准确率约为 0.6。但是，这种方法大约需要 2.5 秒。为了达到与 DataFrame 方法相同的准确度，我需要训练大约 400 个 epoch，这需要 40 秒。
为什么数据集表现更差？
我不确定我是否从根本上误解了 tf.data.Dataset 的用法，但这种行为是意料之外的。似乎 Dataset 方法中的 epoch 比使用 DataFrame 方法的 epoch 提供的信息更少。
有人对为什么会发生这种情况以及如何修复它有什么见解或建议吗？
我使用的是 TF 2.13.1
和 python 3.11.3]]></description>
      <guid>https://stackoverflow.com/questions/78618554/tensorflow-performance-drop-when-training-sequential-model-using-tf-data-datase</guid>
      <pubDate>Thu, 13 Jun 2024 14:40:53 GMT</pubDate>
    </item>
    <item>
      <title>优化数据结构以微调客户服务聊天机器人开发中的 LLM 模型</title>
      <link>https://stackoverflow.com/questions/78618258/optimizing-data-structure-for-fine-tuning-an-llm-model-in-customer-service-chatb</link>
      <description><![CDATA[在开发客户服务聊天机器人以协助制定解决客户问题的指令时，我可以访问客户电子邮件、指令列表以及客户服务人员之间交换的电子邮件。我正在寻求有关微调 LLM 模型以提供特定领域响应的理想数据结构的指导。您的见解对于提高聊天机器人的性能和改善客户服务将非常有价值。
问题：
数据表示：表示客户电子邮件和指令以微调 LLM 模型的最有效方法是什么？

上下文信息：数据集中应包含哪些其他上下文信息以提高模型对客户问题的理解？

处理指令：应如何将指令纳入数据集以确保聊天机器人正确理解和应用它们？

模型训练：在微调过程中应采用哪些策略来优化模型生成对客户查询的特定响应的能力？

评估指标：哪些指标最适合评估微调后的 LLM 模型在客户服务聊天机器人环境中的性能？

与聊天机器人集成：如何将微调后的 LLM 模型有效地集成到客户服务聊天机器人框架中以提供实时决策支持？

我读到过我可以使用 RAG 或微调来实现此目的，但我不确定 LLM 模型所需的输入数据格式。]]></description>
      <guid>https://stackoverflow.com/questions/78618258/optimizing-data-structure-for-fine-tuning-an-llm-model-in-customer-service-chatb</guid>
      <pubDate>Thu, 13 Jun 2024 13:46:40 GMT</pubDate>
    </item>
    <item>
      <title>通过 FLASK API 调用获取图像的面部编码时出现 tensorflow 包问题</title>
      <link>https://stackoverflow.com/questions/78617502/issue-with-tensorflow-package-while-getting-face-encodings-for-a-image-through-a</link>
      <description><![CDATA[我有一个名为 get_signatures_localmodel(image_path) 的 Python 函数，它将在图像上运行 ML 模型，并为提供的图像提供 face encodings = face_model.predict([input_pairs])，我正在使用 Flask API 服务调用此函数。当我执行此操作时，我收到以下错误和警告：
venv/lib/python3.6/site-packages/keras/engine/training.py:2470: 
UserWarning: `Model.state_updates` 将在未来的版本中删除。
此属性不应在 TensorFlow 2.0 中使用，因为 `updates` 
会自动应用。

warnings.warn(&#39;`Model.state_updates` 将在未来的版本中删除。&#39;
异常：找不到变量 conv5_1_1x1_reduce/kernel。
这可能意味着变量已被删除。
在 TF1 中，它也可能意味着变量未初始化。
调试信息：容器 = localhost，状态 = 未找到：
容器 localhost 不存在。
（找不到资源：localhost/conv5_1_1x1_reduce/kernel）
[[{{node model_1_2/conv5_1_1x1_reduce/Conv2D/ReadVariableOp}}]]

但是当我尝试将图像直接传递给此函数并像普通的 python 文件一样运行它时，它没有给出任何错误并获得预期的输出，问题仅与 API 有关调用。
目前我正在使用 tensorflow 1.x 版本，也尝试使用 tensorflow 2.x，但仍然卡在此。
我尝试将 tensorflow 版本从 1.x 更改为 2.x。
尝试加载模型并将其保存在 session() 中。
预期输出：当我们使用 Flask API 调用访问该函数时，它应该提供面部编码以及此错误和警告的原因....]]></description>
      <guid>https://stackoverflow.com/questions/78617502/issue-with-tensorflow-package-while-getting-face-encodings-for-a-image-through-a</guid>
      <pubDate>Thu, 13 Jun 2024 11:14:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Kotlin 上的移动应用程序中使用 imshow()？</title>
      <link>https://stackoverflow.com/questions/78617059/how-to-use-imshow-in-mobile-app-on-kotlin</link>
      <description><![CDATA[我决定创建一个检测物体的计算机视觉模型。它从相机获取实时图像并显示检测到的物体的矩形。但我不知道如何可视化 OpenCV imshow() 函数。
我的模型使用 Yolov8，我尝试将其转换为 tflite，但 Tensorflow 已更新，因此目前无法实现。因此，在移动应用上部署模型的一种方法是将结果发送到屏幕上。但我不知道 Kotlin，对我来说这太难了]]></description>
      <guid>https://stackoverflow.com/questions/78617059/how-to-use-imshow-in-mobile-app-on-kotlin</guid>
      <pubDate>Thu, 13 Jun 2024 09:38:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 Huggingface Trainer 进行多 GPU 训练时，如何避免内存使用不均衡？</title>
      <link>https://stackoverflow.com/questions/78608004/how-can-i-avoid-unbalanced-memory-usage-when-performing-multi-gpu-training-using</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78608004/how-can-i-avoid-unbalanced-memory-usage-when-performing-multi-gpu-training-using</guid>
      <pubDate>Tue, 11 Jun 2024 13:55:30 GMT</pubDate>
    </item>
    <item>
      <title>搜索具有相似文本的文档</title>
      <link>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</link>
      <description><![CDATA[我有一个包含三个属性的文档：标签、位置和文本。
目前，我正在使用 LangChain/pgvector/embeddings 对它们全部进行索引。
我得到了满意的结果，但我想知道是否有更好的方法，因为我想查找一个或多个具有特定标签和位置的文档，但文本可能会有很大差异，但含义仍然相同。出于这个原因，我考虑使用嵌入/向量数据库。
这是否也是使用 RAG（检索增强生成）来“教”的一个例子LLM 不知道的一些常见缩写？
import pandas as pd

from langchain_core.documents import Document
from langchain_postgres import PGVector
from langchain_postgres.vectorstores import PGVector
from langchain_openai.embeddings import OpenAIEmbeddings

connection = &quot;postgresql+psycopg://langchain:langchain@localhost:5432/langchain&quot;
embeddings = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)
collection_name = &quot;notas_v0&quot;

vectorstore = PGVector(
embeddings=embeddings,
collection_name=collection_name,
connection=connection,
use_jsonb=True,
)

# 开始索引

# df = pd.read_csv(&quot;notes.csv&quot;)
# df = df.dropna() # .head(10000)
# df[&quot;tags&quot;] = df[&quot;tags&quot;].apply(
# lambda x: [tag.strip() for tag in x.split(&quot;,&quot;) if tag.strip()]
# )

# long_texts = df[&quot;Texto Longo&quot;].tolist()
# wc = df[&quot;Centro Trabalho Responsável&quot;].tolist()
# notes = df[&quot;Nota&quot;].tolist()
# tags = df[&quot;tags&quot;].tolist()

# documents = list(
# map(
# lambda x: Document(
# page_content=x[0], metadata={&quot;wc&quot;: x[1], &quot;note&quot;: x[2], &quot;tags&quot;: x[3]}
# ),
# zip(long_texts, wc, notes, tags),
# )
# )

# print(
# [
# vectorstore.add_documents(documents=documents[i : i + 100])
# for i in range(0, len(documents), 100)
# ]
# )
# print(&quot;Done.&quot;)

### END INDEX

### BEGIN QUERY

result = vectorstore.similarity_search_with_relevance_scores(
&quot;EVTD202301222707&quot;,
filter={&quot;note&quot;: {&quot;$in&quot;: [&quot;15310116&quot;]}, &quot;tags&quot;: {&quot;$in&quot;: [&quot;abcd&quot;, &quot;xyz&quot;]}},
k=10, # 结果限制
)

### END QUERY
]]></description>
      <guid>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</guid>
      <pubDate>Sun, 09 Jun 2024 16:40:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Huggingface Pipeline 中使用适配器变压器</title>
      <link>https://stackoverflow.com/questions/77673353/how-to-use-adapter-transformers-with-a-huggingface-pipeline</link>
      <description><![CDATA[我尝试运行模型“AdapterHub/bert-base-uncased-pf-conll2003” （此处为模型描述）用于 NLP 中的标记分类。
首先，我尝试安装适配器变压器
pip install -U adapter-transformers 

上述命令的输出是
收集适配器变压器

[... 查看跳过的行的编辑历史记录...]

安装收集的软件包：tokenizers、huggingface-hub、adapter-transformers
尝试卸载：tokenizers
找到现有安装：tokenizers 0.15.0
卸载 tokenizers-0.15.0：
成功卸载 tokenizers-0.15.0
尝试卸载：huggingface-hub
找到现有安装：huggingface-hub 0.19.4
卸载 huggingface-hub-0.19.4:
成功卸载 huggingface-hub-0.19.4
错误：pip 的依赖解析器目前未考虑已安装的所有软件包。此行为是以下依赖冲突的根源。
transformers 4.35.2 需要 huggingface-hub&lt;1.0,&gt;=0.16.4，但您拥有不兼容的 huggingface-hub 0.13.4。
transformers 4.35.2 需要 tokenizers&lt;0.19,&gt;=0.14，但您拥有不兼容的 tokenizers 0.13.3。
成功安装 adapter-transformers-3.2.1.post0 huggingface-hub-0.13.4 tokenizers-0.13.3


我尝试将模型像这样加载到管道中：
from transformers import AutoModelWithHeads
from transformers import pipeline
token_classification = pipeline(&quot;token-classification&quot;, model = &quot;AdapterHub/bert-base-uncased-pf-conll2003&quot;)
res = token_classification(&quot;从垃圾箱中取出垃圾袋并放回原处。&quot;)
print(res)

我收到了错误
EntryNotFoundError: 404 客户端错误。 （请求 ID：Root=1-657e793c-0ce0c1936aff5e5741676650）

未找到 URL 的条目：https://huggingface.co/AdapterHub/bert-base-uncased-pf-conll2003/resolve/main/config.json。

在处理上述异常期间，发生了另一个异常：

OSError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-030dfe0e128d&gt; in &lt;cell line: 3&gt;()
1 from transformers import AutoModelWithHeads
2 from transformers import pipeline
----&gt; 3 token_classification = pipeline(&quot;token-classification&quot;, model = &quot;AdapterHub/bert-base-uncased-pf-conll2003&quot;)
4 res = token_classification(&quot;从垃圾箱中取出垃圾袋并放回原处。&quot;)
5 print(res)

/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py in pipeline(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)
673 hub_kwargs[&quot;_commit_hash&quot;] = config._commit_hash
674 elif config is None and isinstance(model, str):
--&gt; 675 config = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **model_kwargs)
676 hub_kwargs[&quot;_commit_hash&quot;] = config._commit_hash
677 

[... 查看跳过的行的编辑历史记录 ...]

/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py in _get_config_dict(cls, pretrained_model_name_or_path, **kwargs)
624 try:
625 # 从本地文件夹或缓存加载或从模型 Hub 和缓存下载
--&gt; 626 solved_config_file = cached_file(
627 pretrained_model_name_or_path,
628 configuration_file,

/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)
452 if revision is None:
453 revision = &quot;main&quot;
--&gt; 454 raise EnvironmentError(
455 f&quot;{path_or_repo_id} 似乎没有名为 {full_filename} 的文件。结帐&quot;
456 f&quot;&#39;https://huggingface.co/{path_or_repo_id}/{revision}&#39; 查找可用文件。&quot;

OSError：AdapterHub/bert-base-uncased-pf-conll2003 似乎没有名为 config.json 的文件。
查看 &#39;https://huggingface.co/AdapterHub/bert-base-uncased-pf-conll2003/main&#39; 查找可用文件。

如何正确加载此适配器模型？]]></description>
      <guid>https://stackoverflow.com/questions/77673353/how-to-use-adapter-transformers-with-a-huggingface-pipeline</guid>
      <pubDate>Sun, 17 Dec 2023 04:49:28 GMT</pubDate>
    </item>
    <item>
      <title>如何获取 keras 模型的中间输出？</title>
      <link>https://stackoverflow.com/questions/75269671/how-to-get-an-intermediate-output-of-a-keras-model</link>
      <description><![CDATA[例如，我想查看模型的中间输出：
import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4,activation=tf.nn.relu)(inputs)
x1 = tf.keras.layers.Dense(5,activation=tf.nn.softmax)(x)
outputs = tf.keras.layers.Dense(5,activation=tf.nn.softmax)(x1)
model = tf.keras.Model(inputs=inputs,outputs=outputs)
model.compile()

实际模型非常复杂，我只是提供了一个片段。有没有办法在前向传递中设置断点或类似内容来查看中间模型输出。]]></description>
      <guid>https://stackoverflow.com/questions/75269671/how-to-get-an-intermediate-output-of-a-keras-model</guid>
      <pubDate>Sat, 28 Jan 2023 17:50:47 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 将特征重要性作为列表而不是绘图</title>
      <link>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</link>
      <description><![CDATA[我想知道是否可以将特征重要性作为列表而不是图表来获取。这就是我所拥有的
xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)
import matplotlib.pyplot as plt

xgb.plot_importance(xg_reg)
plt.rcParams[&#39;figure.figsize&#39;] = [5,5]
plt.show()

这给了我这个图

我想只获取主要特征的列表，因为我有超过 800 个不同的特征。]]></description>
      <guid>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</guid>
      <pubDate>Thu, 23 Jul 2020 17:57:31 GMT</pubDate>
    </item>
    </channel>
</rss>