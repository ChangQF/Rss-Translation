<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Apr 2024 00:58:46 GMT</lastBuildDate>
    <item>
      <title>为什么 PredictedLabel 没有显示在控制台的输出中？</title>
      <link>https://stackoverflow.com/questions/78393460/why-does-the-predictedlabel-not-show-up-in-the-output-in-the-console</link>
      <description><![CDATA[我是一名初学者，尝试使用 C# 学习机器学习，我要求 ChatGPT 为我提供一个可以学习的示例。
它给了我这个代码：
使用系统；
使用 System.Collections.Generic；
使用 Microsoft.ML；
使用 Microsoft.ML.Data；

班级计划
{
    静态无效主（字符串[]参数）
    {
        // 用于演示的示例数据
        列表 TrainingData = new List;
        {
            新 IrisData { 萼片长度 = 5.1f，萼片宽度 = 3.5f，花瓣长度 = 1.4f，花瓣宽度 = 0.2f，标签 =“Setosa”； },
            新 IrisData { SepalLength = 4.9f，SepalWidth = 3.0f，PetalLength = 1.4f，PetalWidth = 0.2f，Label =“Setosa” },
            // 添加更多数据点...
        };

        // 创建机器学习上下文
        MLContext mlContext = new MLContext();

        // 将训练数据转换为IDataView
        IDataView dataView = mlContext.Data.LoadFromEnumerable(trainingData);

        // 定义数据预处理管道
        var pipeline = mlContext.Transforms.Concatenate(&quot;特征&quot;, &quot;SepalLength&quot;, &quot;SepalWidth&quot;, &quot;PetalLength&quot;, &quot;PetalWidth&quot;)
            .Append(mlContext.Transforms.Conversion.MapValueToKey(“标签”))
            .Append(mlContext.Transforms.NormalizeMinMax(“特征”));

        // 训练模型
        var trainedModel = pipeline.Fit(dataView);

        // 创建预测引擎
        var PredictionEngine = mlContext.Model.CreatePredictionEngine(trainedModel);

        // 用于预测的样本输入
        var testIris = new IrisData { SepalLength = 5.1f, SepalWidth = 3.5f, PetalLength = 1.4f, PetalWidth = 0.2f };

        // 进行预测
        var Prediction = PredictionEngine.Predict(testIris);

        // 输出预测标签
        Console.WriteLine($&quot;预测花型：{prediction.PredictedLabel}&quot;);
        控制台.Read();
    }
}

// 定义数据类
公共类 IrisData
{
    [加载列(0)]
    公共浮动萼片长度；

    [加载列(1)]
    公共浮动萼片宽度；

    [加载列(2)]
    公共浮动花瓣长度；

    [加载列(3)]
    公共浮动花瓣宽度；

    [加载列(4)]
    公共字符串标签{获取;放; }
}

公开课 IrisPrediction
{
    [列名(“预测标签”)]
    公共字符串 PredictedLabel { 获取；放; }
}

没有错误或警告。我仍然不知道为什么它只显示字符串“预测的花类型：”每次我运行它时。
我不知道这是否重要，但我为 Label 和 PredictedLabel 提供了 getter 和 setter，但 PredictedLabel 仍然不显示]]></description>
      <guid>https://stackoverflow.com/questions/78393460/why-does-the-predictedlabel-not-show-up-in-the-output-in-the-console</guid>
      <pubDate>Sat, 27 Apr 2024 00:41:43 GMT</pubDate>
    </item>
    <item>
      <title>如何学习 Pix2Pix GAN 中较低像素率的模式而不是背景</title>
      <link>https://stackoverflow.com/questions/78392870/how-to-learn-pattern-of-lower-pixels-rate-in-pix2pix-gan-and-not-background</link>
      <description><![CDATA[我正在开发一个项目，从一些源图像生成伪造图像（几乎是它的副本，但不是完全副本！）。
经过一些时期后，生成器模型会生成一些白色图像。我认为这是因为所有源图像的背景都是白色像素。
我想通过模型学习源图像的线条和形状并生成它们。但由于黑色像素与白色像素的比例较小，模型无法学习黑色像素。如果有人对此模型有任何建议，甚至其他架构有帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78392870/how-to-learn-pattern-of-lower-pixels-rate-in-pix2pix-gan-and-not-background</guid>
      <pubDate>Fri, 26 Apr 2024 20:33:56 GMT</pubDate>
    </item>
    <item>
      <title>在 Pytorch 中调整 Ray 进行无尽运行</title>
      <link>https://stackoverflow.com/questions/78392510/tune-ray-in-pytorch-on-endless-run</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78392510/tune-ray-in-pytorch-on-endless-run</guid>
      <pubDate>Fri, 26 Apr 2024 18:51:46 GMT</pubDate>
    </item>
    <item>
      <title>我们如何以优雅的方式捕获使用optimizer.step()完成的更新？</title>
      <link>https://stackoverflow.com/questions/78392429/how-can-we-capture-update-done-with-optimizer-step-in-an-elegant-way</link>
      <description><![CDATA[我想实现一种方法，按照 Karpathy 视频中提到的想法，在使用 PyTorch 训练期间在 Tensorboard 中监控更新数据比率。我已经提出了一个解决方案，但我正在寻找一种更优雅且可配置的方法。
当前的实现直接修改训练循环如下：
对于步骤，在 data_loader 中进行批处理：
    x, y = 批次
    优化器.zero_grad()
    对于名称，model.named_pa​​rameters() 中的参数：
        if param.requires_grad 和“weight”名称：
            param.data_before_step = param.data.clone()
    输出=模型(x)
    损失 = loss_fn(输出, y)
    loss.backward()
    优化器.step()
    lr_scheduler.step()
    对于名称，model.named_pa​​rameters() 中的参数：
        if hasattr(param, “data_before_step”):
            更新 = param.data - param.data_before_step
            update_to_data = (update.std() / param.data_before_step.std()).log10().item()
            summary_writer.add_scalar(f“更新：数据比率 {name}”，update_to_data，epoch * len(data_loader) + 步骤)
            param.data_before_step = param.data.clone()

但是，这种方法直接在训练循环中添加代码，这可能会使代码变得混乱，如果我们想要使其可配置，则需要 if-else 语句，这会使代码更加混乱。
我还探索过使用 PyTorch hooks 来实现这一点。我已经成功实现了一个钩子来跟踪梯度：
类 GradToDataRatioHook：
    def __init__(自身、名称、参数、start_step、summary_writer):
        self.name = 名字
        self.param = 参数
        self.summary_writer = 摘要_writer
        自我.毕业生 = []
        self.grads_to_data = []
        self.param.update_step = start_step

    def __call__(自我，毕业生)：
        self.grads.append(grad.std().item())
        self.grads_to_data.append((grad.std() / (self.param.data.std() + 1e-5)).log10().item())
        self.summary_writer.add_scalar(f&quot;Grad {self.name}&quot;, self.grads[-1], self.param.update_step)
        self.summary_writer.add_scalar(f&quot;梯度:数据比例{self.name}&quot;, self.grads_to_data[-1], self.param.update_step)
        self.param.update_step += 1

但是，实现类似的钩子来捕获更新似乎很棘手。据我了解， param.register_hook(...) 注册了钩子，该钩子在计算梯度时调用，即在 optimizer.step() 之前调用叫。虽然梯度和学习率为标准 SGD 提供了更新的直接值，但像 Adam 这样的现代优化器使更新过程变得更加复杂。我正在寻找一种以与优化器无关的方式捕获更新的解决方案，最好使用 PyTorch 挂钩。但是，任何建议或替代方法也将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78392429/how-can-we-capture-update-done-with-optimizer-step-in-an-elegant-way</guid>
      <pubDate>Fri, 26 Apr 2024 18:32:22 GMT</pubDate>
    </item>
    <item>
      <title>我想从 pdf 中提取图像及其标题，并将这些带有标题的图像保存在 blob 存储中[关闭]</title>
      <link>https://stackoverflow.com/questions/78392387/i-want-to-extract-the-images-and-its-caption-from-the-pdf-and-save-those-images</link>
      <description><![CDATA[&lt;块引用&gt;
我想从 pdf 中提取图像及其标题，并将这些带有标题的图像保存在 blob 存储中。你能建议我怎么做吗？目前我正在考虑对象检测模型，我已经在 pdf 列表中的 20-30 pdf 上进行了训练。将 pdf 每页的转换图像传递给模型并获取边界框。但不管这是否有效。
下面是我的 pdf 图像的示例屏幕截图，没有硬性规则要求所有图像都将位于特定页面上，它也可能会有所不同。


&lt;块引用&gt;
我还想提取图像中的标题并仅保存带有此标题的图像。
请指导我。注意：我订阅了顶点 AI，因此如果我可以从中使用任何优势，请告诉我。
]]></description>
      <guid>https://stackoverflow.com/questions/78392387/i-want-to-extract-the-images-and-its-caption-from-the-pdf-and-save-those-images</guid>
      <pubDate>Fri, 26 Apr 2024 18:23:15 GMT</pubDate>
    </item>
    <item>
      <title>无法为 RandomForest ML 模型提供自定义输入</title>
      <link>https://stackoverflow.com/questions/78392007/unable-to-give-custom-input-to-randomforest-ml-model</link>
      <description><![CDATA[我目前正在使用 RandomForestClassifier 开发分类模型，我从 YouTube 上自己学习了算法，所以我在这个项目上工作有点困难，所以我设计了模型并在测试集上进行了测试我从原始数据集中分离出来，我也得到了96%的准确率。问题是，当我尝试提供自定义输入时，我遇到一个错误，指出您提供的数组是一维数组，而模型需要一个二维数组作为输入。
我尝试使用“custom_input_2d = custom_input.reshape(1, -1)”将输入转换为二维数组，但随后弹出一个新错误：“发现样本数量不一致的输入变量：[528, 1]”。我该怎么办，我给出的输入是：[[ 21.008297 0.1.723587 131.92972 2.1.
3.3.0.0.1.683448 1.
1.2.3.]]。该模型需要输入 15 个特征，请帮我看看，我需要以哪种格式给模型输入，如果可能，请给出自定义输入作为示例。]]></description>
      <guid>https://stackoverflow.com/questions/78392007/unable-to-give-custom-input-to-randomforest-ml-model</guid>
      <pubDate>Fri, 26 Apr 2024 17:01:37 GMT</pubDate>
    </item>
    <item>
      <title>如何解决问题。帮助我[关闭]</title>
      <link>https://stackoverflow.com/questions/78391920/how-to-fix-the-problems-help-me</link>
      <description><![CDATA[我想创建决策树图
class_names = model.classes\_.astype(str)

plt.figure(figsize=(20,10))

plot_tree(模型，feature_names=X.columns，class_names=class_names，filled=True，rounded=True)

plt.show()

InvalidParameterError Traceback（最近一次调用最后一次）
单元格 In[73]，第 4 行
      1 类名 = model.classes_.astype(str)
      3 plt.figure(figsize=(20,10))
----&gt; 4plot_tree(模型，feature_names=X.columns，class_names=class_names，filled=True，rounded=True)
      5 plt.show()

文件 ~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:201，在 validate_params..decorator..wrapper(*args, **kwargs)
    198 to_ignore += [“自我”，“cls”]
    199 params = {k: v for k, v in params.arguments.items() if k not in to_ignore}
--&gt; 201 验证参数约束（
    第202章
    203）
    205 尝试：
    206 与 config_context(
    第207章
    第208章
    209）
    210）：

文件〜/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95，在validate_parameter_constraints（parameter_constraints，params，caller_name）
     89 其他：
     90 约束_str = (
     [第 91 回]
     92f” {约束[-1]}”
     93）
---&gt; 95 引发无效参数错误（
     96 f“{caller_name}的{param_name！r}参数必须是”
     97 f” {constraints_str}。而是得到了 {param_val!r}。”
     98）

InvalidParameterError：plot_tree 的“feature_names”参数必须是“list”或 None 的实例。 Got Index([&#39;未命名：0&#39;, &#39;专业&#39;, &#39;奖学金&#39;, &#39;交通&#39;, &#39;出勤&#39;,
       &#39;项目_工作&#39;，&#39;点&#39;]，
      dtype=&#39;object&#39;) 代替。

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78391920/how-to-fix-the-problems-help-me</guid>
      <pubDate>Fri, 26 Apr 2024 16:41:48 GMT</pubDate>
    </item>
    <item>
      <title>用于无人机基地垃圾检测的城市固体废物数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/78390012/msw-data-set-for-drone-base-garbage-detection</link>
      <description><![CDATA[我的项目需要一个根据 MSW 进行标记和分类的城市固体废物数据集，该项目是使用 Raspberry Pi 进行无人机基础垃圾检测。
我检查了 Kaggle &amp; Roboflow，但没有为我的项目获得任何有用的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78390012/msw-data-set-for-drone-base-garbage-detection</guid>
      <pubDate>Fri, 26 Apr 2024 11:08:21 GMT</pubDate>
    </item>
    <item>
      <title>检查给定图像是否是另一个更大图像的裁剪</title>
      <link>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</link>
      <description><![CDATA[我有一些图片。其中一些图像是裁剪版本。
就像这里是原始图片大图
和裁剪后的图像小图像。
请注意，图像的形状（分辨率）不相同。
我有几双这样的。原始图像保存在一个文件夹中，裁剪后的图像保存在另一个文件夹中。
最终我想从这些图像中找到原始图像和裁剪图像对。
所以我想迭代这两个文件夹中的图像，并检查裁剪后的图像是否是更大图像的一部分。
但我找不到任何算法可以用不同形状（分辨率）的图像给出这样的结果。
我已经尝试过cv2.matchTemplate和skimage.metrics.structural_similarity
但它们仅适用于形状（分辨率）相似的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</guid>
      <pubDate>Fri, 26 Apr 2024 10:32:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在数学方程中表示使用样条变换器 + 线性回归拟合的模型。数据是高维的</title>
      <link>https://stackoverflow.com/questions/78389349/how-to-represent-a-model-fitted-using-spline-transformer-linear-regression-in</link>
      <description><![CDATA[我有一个由 5 个特征和 1 个目标组成的数据集。我使用样条变换器来转换特征，然后使用线性回归来拟合它。我正在使用 1 度和 5 节样条变换特征来拟合数据。现在我想用数学方程表示模型拟合，其中包括各个项以及交互项。
我怎样才能做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78389349/how-to-represent-a-model-fitted-using-spline-transformer-linear-regression-in</guid>
      <pubDate>Fri, 26 Apr 2024 09:02:21 GMT</pubDate>
    </item>
    <item>
      <title>当在加速配置和 TrainingArguments 中同时设置时，哪种混合精度设置有效？</title>
      <link>https://stackoverflow.com/questions/78387547/which-mixed-precision-setting-is-in-effect-when-it-is-set-both-in-accelerate-con</link>
      <description><![CDATA[我正在使用 HuggingFace 的 transformers 库和 accelerate 库。
当谈到混合精度设置时，我可以设置两个地方：

位于加速配置，在下面的界面中
您希望使用 FP16 还是 BF16（混合精度）？
请使用箭头或数字键选择一个选项，然后按 Enter 键进行选择
   不
   FP16
➔ bf16
   FP8


在TrainingArguments，例如
transformers.TrainingArguments(
    bf16=假,
    fp16=真
）



所以我的问题是，哪个地方的设置最终会取代另一个地方并生效？
例如，如果在accelerate config中我设置了bf16，但在TrainingArguments中我设置了fp16，那么将使用哪一个？
我尝试修复加速配置中的设置并更改TrainingArguments中的设置，并且确实注意到一些速度变化。所以看来 TrainingArguments 中的设置会被取代。但我还是想得到一些确认。]]></description>
      <guid>https://stackoverflow.com/questions/78387547/which-mixed-precision-setting-is-in-effect-when-it-is-set-both-in-accelerate-con</guid>
      <pubDate>Thu, 25 Apr 2024 23:01:21 GMT</pubDate>
    </item>
    <item>
      <title>呼吸信号的对数功率谱</title>
      <link>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</link>
      <description><![CDATA[我的数据集是噪声频谱的LPS，我的标签是干净频谱的LPS，每个图片大小是（1025*1292）。我使用unet作为我的模型。
型号：
导入火炬
将 torch.nn 导入为 nn

解码器类（nn.Module）：
    def __init__(self, in_channels,out_features, kernel_size, maxpoolindex, apply_dropout,stride):
        super(解码器, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels、out_channels=out_features、kernel_size=kernel_size、stride=stride、padding=0、bias=True)
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.LeakyReLU(负斜率=0.2)
        self.dropout = nn.Dropout(p=0.1)
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) 如果 maxpoolindex == 1 否则无

    def 前向（自身，x）：
        x = self.conv(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        如果 self.maxpool 不是 None：
            x = self.maxpool(x)
        返回x

编码器类（nn.Module）：
    def __init__(self,in_channels, out_features, kernel_size, apply_dropout):
        超级（编码器，自我）.__init__()
        self.conv_transpose = nn.ConvTranspose2d（in_channels = in_channels，out_channels = out_features，kernel_size = kernel_size，stride = 2，padding = 0，bias = True）
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def 前向（自身，x）：
        x = self.conv_transpose(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        返回x

class DenoiseUnet(nn.Module):#除到第一个奇数停止的设计
    def __init__(自身):
        超级（DenoiseUnet，自我）.__init__()
        self.down_procedure = nn.ModuleList([
            解码器(1,8,2,0,0,2),
            解码器(8,16,2,0,0,2),
            解码器(16,32,2,0,0,2),
            解码器(32,128,2,0,0,2),
            解码器(128,128,1,0,0,1)
        ]）
        self.up_procedure = nn.ModuleList([
            编码器(2​​56,32,2,0),
            编码器(64,16,2,0),
            编码器(32,8,2,0),
            编码器(16,4,2,0),
        ]）
        self.convert = nn.ConvTranspose2d(4, 1, kernel_size=1, stride=1, padding=0)


    def 前向（自身，x）：
        连接=[]
        对于 self.down_procedure 中的 down：
            x = 向下(x)
            连接.append(x)

        连接=列表（反转（连接[：-1]））
        对于 up，在 zip(self.up_procedure, connection) 中连接：


            如果 x.shape[2] &lt;连接.形状[2]：
              连接 = 连接[:, :, :x.shape[2], :]
            别的：
              x = x[:, :, :connect.shape[2], :]

            如果 x.shape[3] &lt;连接.形状[3]：
              连接 = 连接[:, :, :, :x.shape[3]]
            别的：
              x = x[:, :, :, :connect.shape[3]]



            x = torch.cat([x, 连接], 暗淡=1)
            x = 上(x)

        y = self.convert(x)
        返回y


模型 = DenoiseUnet()
打印（模型）

但是经过 10 轮训练后，我得到这样的结果：
https://i.sstatic.net/b8DxXHUr.png
https://i.sstatic.net/UDhZNKHE.png
一个是预测结果，一个是测试，任何人都可以帮我找出问题所在吗？
数据集数量不同，看起来是一样的。]]></description>
      <guid>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</guid>
      <pubDate>Thu, 25 Apr 2024 17:43:28 GMT</pubDate>
    </item>
    <item>
      <title>在数据分割过程中保留数据的空间分布</title>
      <link>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</link>
      <description><![CDATA[我正在尝试使用随机森林模型来模拟德国巴伐利亚河流中的硝酸盐浓度。我使用 Python，主要使用 sklearn。我有 490 个水质站的数据。我遵循 LongzhuQ.Shen 等人论文中的方法，该论文可以在这里找到：https://www.nature.com/articles/s41597-020-0478-7
我想将数据集分成训练集和测试集，以便两个集中数据的空间分布相同。这个想法是，如果数据分割忽略空间分布，则训练集可能最终会集中来自人口稠密区域的点，而忽略稀疏区域。这可能会扭曲模型的学习过程，使其在整个感兴趣领域的准确性或概括性降低。 sklearn train_test_split只是将数据随机划分为训练集和测试集，并且不考虑数据中的空间模式。
我上面提到的论文遵循了这种方法：“我们将完整的数据集分为两个子数据集，分别是训练和测试。为了考虑监测站空间分布的异质性，我们在数据分割步骤中采用了空间密度估计技术，通过使用带宽为 50 km 的高斯核（使用 GRASS GIS33 中可用的 v.kernel）构建密度表面来计算每个物种和季节。所得密度表面的像素值用作权重因子，将数据分成具有相同空间分布的训练和测试子集。”
我想遵循相同的方法，但我不使用草地 GIS，而是自己用 Python 构建密度表面。我还提取了概率密度值和站点的权重。 （附图）
现在我面临的唯一问题是如何使用这些权重将数据分成训练集和测试集？我检查了sklearn train_test_split函数中没有可以考虑权重的关键字。我也与GPT 4聊天来回，但它也无法给我一个明确的答案。我在互联网上也没有找到任何关于此的具体信息。也许我错过了一些东西。
还有其他函数可以用来执行此操作吗？或者我必须编写自己的算法来进行分割？如果是后者，您能否建议我一种方法，以便我自己编写代码？
在附图中您可以看到站点的位置以及使用核密度估计方法（使用高斯核）生成的概率密度面。
还附上我的数据框的屏幕截图，让您了解数据结构。 （经度（‘lon’）列之后的所有列都用作特征。NO3 列用作目标变量。）
请查找附件图片以供参考。
使用高斯核的核密度估计方法生成的概率密度曲面。&lt; /p&gt;
我用来模拟硝酸盐浓度的数据集]]></description>
      <guid>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</guid>
      <pubDate>Thu, 25 Apr 2024 10:10:26 GMT</pubDate>
    </item>
    <item>
      <title>UnicodeEncodeError：“charmap”编解码器无法对位置 19-38 中的字符进行编码：字符映射到 <未定义></title>
      <link>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</link>
      <description><![CDATA[我正在开发一个基于 Flask 的 Web 应用程序，用户可以上传图像以使用机器学习模型进行预测。上传的图像存储在本地目录中，并使用预先训练的模型进行预测。然而，当我点击预测按钮时
是什么导致了这个 UnicodeEncodeError？
如何解决此问题以确保我的应用程序能够正确处理图像上传和预测？
是否有在 Flask 环境中处理字符编码的最佳实践，尤其是在 Windows 上？
==app.py====
@app.route(&#39;/uploadimage&#39;,methods=[&#39;GET&#39;, &#39;POST&#39;])
def upload_image():

        文件 = request.files[&#39;my_image&#39;]
        # 获取预测结果
        预测标签 = 预测标签(img_path)
        # 返回预测的标签和一条提示信息
        flash(f&quot;预测：{predicted_label}&quot;, &quot;成功&quot;)
        os.remove(img_path) # 处理后删除临时文件
    return render_template(&#39;uploadimage.html&#39;) # 对于 GET 请求，渲染表单


即使我设置了环境变量“UTF-8”，我仍然收到此错误
错误
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，编码
返回 codecs.charmap_encode(输入,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^
UnicodeEncodeError：“charmap”编解码器无法对位置 19-38 中的字符进行编码：字符映射为未定义。
============
即使我有一个最简单的代码来测试编码
标题是“要测试您的控制台是否可以处理 UTF-8，请尝试输出带有特殊字符或 Unicode 字符的文本：”
print(&quot;UTF-8 测试: àéîöü — 中文 — 阿拉伯语&quot;)


错误也相同
print(&quot;UTF-8 测试：����� � \u4e2d\u6587 � \u0627\u0644\u0639\u0631\u0628\u064a\u0629&quot;)
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，编码
返回 codecs.charmap_encode(输入,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^
UnicodeEncodeError：“charmap”编解码器无法对位置 20-21 中的字符进行编码：字符映射到 ]]></description>
      <guid>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</guid>
      <pubDate>Mon, 22 Apr 2024 17:25:20 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我使用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    </channel>
</rss>