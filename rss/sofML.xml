<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 03:18:17 GMT</lastBuildDate>
    <item>
      <title>为什么偏差的导数是对所有数据点求和而不是平均值</title>
      <link>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</link>
      <description><![CDATA[我有一个基本的仿射层，即，我有 out=X@W+bias，其中 X@W 的形状为 (N,C)，b 的形状为 (C,)。如果我有损失的导数，wrt out 为 dout，形状为 (N.C)，为什么 db=dout 所有行的总和？为什么不是平均值之类的东西？]]></description>
      <guid>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</guid>
      <pubDate>Thu, 06 Jun 2024 02:19:01 GMT</pubDate>
    </item>
    <item>
      <title>使用同一模型问题预测时间序列中多个实例的未来 CPU 使用率</title>
      <link>https://stackoverflow.com/questions/78583575/predicting-future-cpu-usage-in-time-series-with-multiple-instances-with-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583575/predicting-future-cpu-usage-in-time-series-with-multiple-instances-with-the-same</guid>
      <pubDate>Wed, 05 Jun 2024 21:27:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python tensorflow 图像回归模型中增加我的 MAE 损失函数[关闭]</title>
      <link>https://stackoverflow.com/questions/78583554/how-to-increase-my-mae-loss-function-in-python-tensorflow-image-regression-model</link>
      <description><![CDATA[我有 8000 张黑色背景上的圆圈图像。每个标签都是圆圈的 x 坐标。每张图片的尺寸为 (128,128,3)。我的训练损失从 2000 开始，到 10 结束，而验证损失保持在 200 左右。另外，我通过将每幅图像除以 255 来对其进行标准化。
images_array 的形状为：(8000,128,128,3)
y 的形状为：(8000,1)
这是我的代码：
from sklearn.model_selection import train_test_split
X_train, X_temp, y_train, y_temp = train_test_split(images_array, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

import tensorflow as tf
X_train = tf.convert_to_tensor(X_train)
y_train = tf.convert_to_tensor(y_train)

从 tensorflow 导入 keras
从 tensorflow.keras 导入层，模型
从 tensorflow.keras.models 导入顺序

输入 = keras.Input(shape=(128, 128, 3))

# 定义层

x = 层。Conv2D(8, 3, 激活=&#39;relu&#39;)(输入)
x = 层。MaxPooling2D(2)(x)
x = 层。Conv2D(16, 3, 激活=&#39;relu&#39;)(x)
x = 层。MaxPooling2D(2)(x)
x=层。Flatten()(x)
x = 层。Dense(128, 激活=&#39;relu&#39;)(x)
output_x = 层。Dense(1, 激活 = &#39;linear&#39;, 名称 = &quot;y1_output&quot;)(x)

model = Model(inputs = input, output = output_x)
model.summary()


我可以做些什么来显著改善我的损失？
我尝试了不同的激活函数和不同的优化器。]]></description>
      <guid>https://stackoverflow.com/questions/78583554/how-to-increase-my-mae-loss-function-in-python-tensorflow-image-regression-model</guid>
      <pubDate>Wed, 05 Jun 2024 21:21:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 模型或其他实践在大型数据集中识别名字和姓氏的最佳实践是什么？</title>
      <link>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</guid>
      <pubDate>Wed, 05 Jun 2024 20:00:15 GMT</pubDate>
    </item>
    <item>
      <title>EasyOCR TypeError：Reader.__init__() 得到了意外的关键字参数“detection”[关闭]</title>
      <link>https://stackoverflow.com/questions/78582788/easyocr-typeerror-reader-init-got-an-unexpected-keyword-argument-detecti</link>
      <description><![CDATA[我尝试使用 easyocr 包，但出现以下错误
reader = easyocr.Reader([&#39;en&#39;], detection=&#39;DB&#39;, identification = &#39;Transformer&#39;)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Reader.init() 获得了意外的关键字参数“detection”
我刚开始使用 ocr 包。有谁能帮我解决这个问题
在官方仓库中，他们也包含了这些参数，但现在出现了错误
, ]]></description>
      <guid>https://stackoverflow.com/questions/78582788/easyocr-typeerror-reader-init-got-an-unexpected-keyword-argument-detecti</guid>
      <pubDate>Wed, 05 Jun 2024 18:02:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方与orange3和python不同？</title>
      <link>https://stackoverflow.com/questions/78582697/why-chi-square-is-differ-from-orange3-and-python</link>
      <description><![CDATA[*我计算了平方的种类，但是我从orang3程序和python得到了不同的结果，有什么原因吗？
*这是我从 python 得到的数字
0个(毫升) 18.932143 0.755599
价格指数（克） 22.009615 0.519671
2毫克（毫克）84.000000 0.448668
3 件（克） 49.275000 0.382270
4年价格(克) 19.560714 0.848676
5 由 Google 数字化 13.391551 0.643942
*这是我通过orange3得到的号码
橙色3卡方数
*这是我使用的表的所有信息
仅供参考
*这是我使用的python代码
导入 pandas 作为 pd
导入 scipy.stats
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
从 matplotlib 导入 font_manager ， rc

font_path = “C:/Windows/Fonts/malgun.ttf” # Windows 的“Malgun Gothic”屏幕
字体 = font_manager.FontProperties(fname=font_path).get_name()
rc(&#39;字体&#39;, 系列=字体)

数据 = pd.read_csv(&#39;C:/Users/tlotr/OneDrive/Entertainment/BYDIET/Calorcateglrized_calorcateglrized.csv&#39;, 编码=&#39;euc-kr&#39;);
数据.info()

Variables = [&#39;浓度(ml)&#39;, &#39;含量浓度(g)&#39;, &#39;浓度浓度(mg)&#39;, &#39;浓度浓度(g)&#39;, &#39;浓度浓度(g)&#39; , &#39;雪花雪花(g)&#39; ]

chi2_结果 = []

对于变量中的 var：
contingency_table = pd.crosstab(data[&#39;languageC&#39;], data[var]);
chi2, p, _, _ = stats.chi2_contingency(contingency_table);
chi2_结果。追加（（var，chi2，p））

chi2_results_df = pd.DataFrame(chi2_results, columns=[&#39;变量&#39;, &#39;Chi2&#39;, &#39;p 值&#39;]);
打印（chi2_results_df）
plt. 图（图大小=(12, 8)）
sns.barplot(x=&#39;变量&#39;, y=&#39;Chi2&#39;, data=chi2_df_results);
plt.title(&#39;美国&#39;)
plt.xlabel(&#39;标签&#39;)
plt.ylabel(&#39;Chi2 값&#39;)
plt.xticks（旋转=45）
plt.tight_layout()
plt . 显示 ( )


*这是我用的Orange3
Orage3 GUI]]></description>
      <guid>https://stackoverflow.com/questions/78582697/why-chi-square-is-differ-from-orange3-and-python</guid>
      <pubDate>Wed, 05 Jun 2024 17:39:06 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root、_、os.walk(input_folder) 中的文件：
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试：
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}: {e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：我有一张 800x800 像素的 jpg 图片。但背景是黑色的，根本不在中心。
有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>llama-index、uncharted 和 llama2:7b 在本地运行以生成索引</title>
      <link>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</link>
      <description><![CDATA[我想在本地使用 llama-index 和 ollama 以及 llama3:8b 来索引 utf-8 json 文件。我没有 gpu。我使用 uncharted 将文档转换为 json。现在，如果没有 GPU 就无法在本地使用 llama-index，我想使用 hugging face 推理 API。但我不确定它是否免费。有人能建议一种方法吗？
这是我的 python 代码：


from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex
from llama_index.llms.ollama import Ollama
import json
from llama_index.core import Settings

# 将 JSON 文档转换为 LlamaIndex Document 对象
with open(&#39;data/UBER_2019.json&#39;, &#39;r&#39;,encoding=&#39;utf-8&#39;) as f:
json_doc = json.load(f)
documents = [Document(text=str(doc)) for doc in json_doc]

# 使用本地 LLM 初始化 Ollama
ollama_llm = Ollama(model=&quot;llama3:8b&quot;)
Settings.llm = ollama_llm

# 使用本地 LLM 创建索引
index = VectorStoreIndex.from_documents(documents)#, llm=ollama_llm)


但我一直收到没有 OPENAI 密钥的错误。我想使用 llama2，这样就不需要 OPENAI 密钥了
有人能指出我做错了什么吗？我还可以免费使用 huggingfaceinference API 对本地 json 文件进行索引吗？]]></description>
      <guid>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</guid>
      <pubDate>Wed, 05 Jun 2024 12:38:14 GMT</pubDate>
    </item>
    <item>
      <title>ViTHybrid 无法添加位置嵌入和嵌入</title>
      <link>https://stackoverflow.com/questions/78581025/vithybrid-cant-add-positional-embeddings-and-embeddings</link>
      <description><![CDATA[当我创建一个新模型并为其提供随机大小的数据作为输入 [1, 3, 224, 224] 时，我得到了 embeddings 和 positional_embeddings 维度错误
model = ViTHybridModel(ViTHybridConfig(backbone_config = {
&quot;depths&quot;: [3, 4, 16, 3],
&quot;hidden_​​sizes&quot;: [128, 256, 512, 1024],
&quot;layer_type&quot;: &quot;bottleneck&quot;
}, image_size=224)

torch.Size([1, 3, 224, 224])
Traceback（最近一次调用最后一次）：
文件 &quot;D:\sddif\itestingvit.py&quot;，第 17 行，位于&lt;module&gt;
输出 = 模型 (输入 [&quot;pixel_values&quot;])
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1532 行，位于 _wrapped_call_impl
返回 self._call_impl(*args, **kwargs)
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1541 行，位于 _call_impl
返回 forward_call(*args, **kwargs)
文件&quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\models\vit_hybrid\modeling_vit_hybrid.py&quot;，第 588 行，在 forward
embedding_output = self.embeddings(
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1532 行，在 _wrapped_call_impl
return self._call_impl(*args, **kwargs)
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1541 行，在 _call_impl
return forward_call(*args, **kwargs)
文件“C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\models\vit_hybrid\modeling_vit_hybrid.py”，第 128 行，正向
embeddings = embeddings + self.position_embeddings
RuntimeError：张量 a (50) 的大小必须与非单例维度 1 上的张量 b (577) 的大小匹配

]]></description>
      <guid>https://stackoverflow.com/questions/78581025/vithybrid-cant-add-positional-embeddings-and-embeddings</guid>
      <pubDate>Wed, 05 Jun 2024 12:35:10 GMT</pubDate>
    </item>
    <item>
      <title>最新版本的 Mask-RCNN 和 TensorFlow 版本的错误</title>
      <link>https://stackoverflow.com/questions/78579595/newest-version-of-working-mask-rcnn-errors-on-tensorflow-version</link>
      <description><![CDATA[我一直在尝试在生物实验室的细胞图像上实现 Mask-RCNN。
我知道 matterport/Mask_RCNN 无法正常工作，因为它使用的是 TensorFlow 1，所以我尝试使用使用 TensorFlow 2 的 github repos。但我仍然觉得有些已经过时了，或者我的设置不匹配，它没有运行。我一直在使用这个：https://github.com/ahmedfgad/Mask-RCNN-TF2
是否有 2024 年或 2023 年的最新版本可以作为我的基础？我真的很想尝试在我的系统上实现，但是当我尝试从同一位置修复问题时，不断收到类似 ModuleNotFoundError: 没有名为“keras.engine”的模块 或 ERROR: 找不到满足要求 tensorflow==2.2.0 的版本的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78579595/newest-version-of-working-mask-rcnn-errors-on-tensorflow-version</guid>
      <pubDate>Wed, 05 Jun 2024 08:11:47 GMT</pubDate>
    </item>
    <item>
      <title>请问如何改进我的混合 1D CNN 和 Bi-LSTM 模型以实现高精度</title>
      <link>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</link>
      <description><![CDATA[我正在构建一个混合 1D CNN 和 Bi-LSTM 模型，用于预测心脏病。然而，该模型的准确率是 0.73，但我想将其提高到 0.80 及以上。请就如何改进此模型提供任何帮助。谢谢。我期望准确率能稍微提高一点。
我的输入形状如下所示 (70000,13)
import tensorflow as tf 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling2D, MaxPooling1D, LSTM, Bidirectional, Dense, Flatten, Dropout, Input, BatchNormalization, Reshape
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils.class_weight import compute_class_weight 

dataset = pd.read_csv(&#39;heart_disease.csv&#39;)
dataset.shape

#预处理数据集
X = dataset.drop(columns=[&#39;disease&#39;])
y = dataset[&#39;disease&#39;]

`#标准化特征
scaler = StandardScaler()
X = scaler.fit_transform(X)
# print(X)

#将数据分成训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(&quot;训练集大小：&quot;, X_train.shape)
print(&quot;测试集大小：&quot;, X_test.shape)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#重塑数据1D CNN + Bi-LSTM 模型
X_train_dl = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_dl = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

#print(X_train_dl)
#print(X_test_dl)

# 构建混合模型

model = Sequential()
model.add(Input(shape=(X_train_dl.shape[1], X_train_dl.shape[2])))

model.add(Conv1D(filters=32, kernel_size=2,activation=&#39;relu&#39;))

model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Conv1D(filters=64, kernel_size=2,activation=&#39;relu&#39;))
model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Bidirectional(LSTM(50, return_sequences=True)))
model.add(Dropout(0.5))
model.add(Flatten())

`model.add(Dense(128,activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
model.add(Dropout(0.5))

model.add(Dense(1,activation=&#39;sigmoid&#39;))

#编译模型

model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 提前停止回调
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=20, restore_best_weights=True)

# 训练模型
history = model.fit(X_train_dl, y_train, epochs=10, batch_size=32, validation_data=(X_test_dl, y_test), callbacks=[early_stopping])

# 保存模型
model.save(&#39;my_model.keras&#39;)

# 评估模型
loss accuracy = model.evaluate(X_test_dl, y_test)
print(f &quot;混合模型 (1D CNN + Bi-LSTM) 准确率： {准确度：.2f}&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</guid>
      <pubDate>Tue, 04 Jun 2024 12:04:25 GMT</pubDate>
    </item>
    <item>
      <title>微调模型时内存不足</title>
      <link>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</link>
      <description><![CDATA[我目前正在尝试微调 Wav2Vec2 模型：https://huggingface.co/dima806/bird_sounds_classification。但是我的 RAM 使用率超过了 Google Colab 的免费套餐。
以下是我的代码：
from transformers import TrainingArguments, Trainer

# 使用 ignore_mismatched_sizes=True 加载模型
model = Wav2Vec2ForSequenceClassification.from_pretrained(
&quot;dima806/bird_sounds_classification&quot;,
num_labels=len(label2id),
ignore_mismatched_sizes=True
)

# 使用梯度累积设置训练
batch_size = 1 # 减少批次大小以管理内存
accumulation_steps = 4 # 在 4 个步骤中累积梯度

training_args = TrainingArguments(
output_dir=&quot;./results&quot;,
evaluation_strategy=&quot;epoch&quot;,
learning_rate=2e-5,
per_device_train_batch_size=batch_size,
per_device_eval_batch_size=batch_size,
gradient_accumulation_steps=accumulation_steps, # 梯度累积
num_train_epochs=3,
weight_decay=0.01,
fp16=True, # 启用混合精度训练
)

trainer = Trainer(
model=model,
args=training_args,
train_dataset=train_dataset,
eval_dataset=val_dataset,
tokenizer=feature_extractor,
)

# 训练模型
trainer.train()

RAM 超过 12.7GB 的原因可能是什么？我的数据集只包含 20 个项目。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</guid>
      <pubDate>Tue, 28 May 2024 07:10:21 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地会合中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物疾病识别模型。我有一个包含 38 种疾病的数据集，每种疾病大约有 2000 张图像。但在训练模型时，由于某些 OUT_OF_RANGE 错误，一些时期被跳过。有人能帮我解决这个问题吗？
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

train_dir = &#39;dataset/train&#39;
valid_dir = &#39;dataset/valid&#39;
batch_size = 32

train_datagen = ImageDataGenerator(
rescale=1./255,
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
sher_range=0.2,
zoom_range=0.2,
Horizo​​ntal_flip=True,
fill_mode=&#39;nearest&#39;
)

valid_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
train_dir,
target_size=(150, 150),
batch_size=batch_size,
class_mode=&#39;categorical&#39;
)

valid_generator = valid_datagen.flow_from_directory(
valid_dir,
target_size=(150, 150),
batch_size=batch_size,
class_mode=&#39;categorical&#39;
)

model = Sequential([
输入(shape=(150, 150, 3)),
Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Flatten(),
Dense(512,activation=&#39;relu&#39;),
Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别数量调整输出单元
])

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

history = model.fit(
train_generator,
steps_per_epoch=train_generator.samples //batch_size,
epochs=10,
validation_data=valid_generator,
validation_steps=valid_generator.samples //batch_size
)

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
disease_names = list(class_indices.keys())
print(&quot;类别索引到疾病名称的映射：&quot;, class_indices)

终端：
找到属于 38 个类别的 70295 张图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19:50:32.085744：I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 FMA，在其他操作中，请使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y:120：UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()
←[1m2196/2196←[0m ←[32m━━━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m905s←[0m 411ms/step - 准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
loss：0.8556
Epoch 2/10
←[1m 1/2196←[0m ←[37m━━━━━━━━━━━━━━━━━━━━━←[0m ←[1m12:02←[0m 329ms/step - 准确度：0.6875 - 损失：0.78202024-04-23 20:05:37.996528：W tensorfl
ow/core/framework/local_rendezvous.cc:404] 本地会合正在中止，状态为：OUT_OF_RANGE：序列结束
[[{{node IteratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155：UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 个批次。您可能需要在构建数据集时使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)
2024-04-23 20:05:38.068817: W tensorflow/core/framework/local_rendezvous.cc:404] 本地会合正在中止，状态为：OUT_OF_RANGE：序列结束
[[{{node IteratorGetNext}}]]
←[1m2196/2196←[0m ←[32m━━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 49us/step - 精度：0.6875 - 损失：0.7820 - val_accuracy： 0.7500 - val_los
s: 0.2462

如上所示，epoch 1 成功完成，但 epoch 2 因某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>错误 conda.core.link:_execute(698): 安装包“defaults::icu-58.2-ha925a31_3”时发生错误</title>
      <link>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</link>
      <description><![CDATA[我使用 anaconda prompt conda create -n talkingbot python=3.5 创建了环境，然后安装了 pip install tensorflow==1.0.0（遵循与 udemy 课程中使用的相同命令），但是当我尝试使用 conda install spyder 安装 spyder 时，它给了我这个错误：
准备交易：完成
验证交易：完成
执行交易：完成
错误 conda.core.link:_execute(698)：安装包“defaults::icu-58.2-ha925a31_3”时发生错误。
回滚事务：完成

[Errno 13] 权限被拒绝：&#39;C:\\Users\\Lenovo\\anaconda3\\envs\\talkingbot\\Library\\bin\\icudt58.dll&#39;
()

然后我尝试使用 anaconda navigator 安装 spyder，但 spyder 也未安装。
帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</guid>
      <pubDate>Sun, 13 Sep 2020 13:42:24 GMT</pubDate>
    </item>
    <item>
      <title>Statsmodels - 使用经过训练的 arima 模型通过明确提供 endog 值来进行手动点预测</title>
      <link>https://stackoverflow.com/questions/56971901/statsmodels-use-trained-arima-model-to-do-manual-point-prediction-by-explicitl</link>
      <description><![CDATA[我正在使用 statsmodels 库来提供 ARIMAX 模型，用于预测时间序列。我有一个相当奇怪的问题 - 如何通过明确提供用于预测的 endog 和 exog 变量来强制训练模型执行完全手动点预测？
为了给你一个想法，我使用 2000-2017 年的年度数据训练我的模型，其中我根据前几年的劳动力和一堆 exog 变量预测公司未来的劳动力。它效果很好。问题是，2018 年和 2019 年，公司大幅扩大了员工数量，这是一次性的商业决策，我们也知道，从商业角度来看，我们在 2000-2017 年训练的模型是“正确的”。
我想要做的是使用我在 2000-2017 年训练的模型，并提供 2020 年的预测，同时明确提供 2018 年和 2019 年的“实际值”。这样，我们就可以确保模型不会试图适应这种一次性的跳跃，从而降低其质量。但我该怎么做呢？请注意，我使用 AR(2) 模型 - 因此我需要提供前 2 年的数据。
我见过一些 statsmodels 方法，它们允许您：
1) 选择经过训练的 ARIMAX 模型
2) 明确提供前 2 年的 exog 变量值
3) 明确提供前 2 年的 endog 值
4) 仅提供单点预测
predict 和 forecast 方法仅允许您指定要提供样本外预测的步数，但不允许明确提供用于预测的新内源值]]></description>
      <guid>https://stackoverflow.com/questions/56971901/statsmodels-use-trained-arima-model-to-do-manual-point-prediction-by-explicitl</guid>
      <pubDate>Wed, 10 Jul 2019 13:34:27 GMT</pubDate>
    </item>
    </channel>
</rss>