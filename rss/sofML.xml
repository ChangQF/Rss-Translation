<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Thu, 20 Mar 2025 01:19:36 GMT</lastBuildDate>
    <item>
      <title>为什么tf.keras不让我通过多个样本权重的字典？</title>
      <link>https://stackoverflow.com/questions/79521352/why-wont-tf-keras-let-me-pass-a-dictionary-of-multiple-sample-weights</link>
      <description><![CDATA[我正在尝试通过单个np。示例的阵列对我的keras模型的两个输出进行了示例阵列，其中一个是对二进制值的置信度度量，其中一个是连续的输出。但是，根据Trackback，我会收到 keyError：0 作为TF.Keras试图使用 Object = Object = Object = Object [_Path] 读取它。代码段中提供了导入，以确保
  def train_model（型号，x_ts_train，x_item_train，y_train_conf，y_train_pct，epochs = 50，batch_size = 32）：
    导入numpy作为NP
    来自sklearn.utils.class_weight导入compute_class_weight

    ＃----确保y_train_conf是整数（0或1）----＃
    y_train_conf = np.asarray（y_train_conf）.astype（int）

    ＃----计算二进制分类的每类权重----＃
    unique_classes = np.unique（y_train_conf.ravel（））
    class_weight_dict = {0：1.0，1：1.0}＃默认权重
    如果len（unique_classes）== 2：＃确保存在0和1
        class_weights = compute_class_weight（class_weight =&#39;balanced&#39;，class = unique_classes，y = y__train_conf.ravel（））
        class_weight_dict = {int（unique_classes [i]）：class_weights [i] for in range（len（simolor_classes））}}

    ＃----将类权重转换为按样本权重（匹配y_train_conf形状）----＃
   sample_weights_conf = np.array（[class_weight_dict [label] for y_train_conf.ravel（））
   sample_weights_conf = sample_weights_conf.reshape（y_train_conf.shape）＃现在形状为（84，5）

   ＃----计算连续尖峰百分比的按样本重量----＃
   y_train_pct = np.Asarray（y_train_pct）
   sample_weights_pct = np.ones_like（y_train_pct）＃默认权重= 1

   nonzero_mask = y_train_pct＆gt; 0
   如果np.any（nonzero_mask）：
       scaling_factor = np.sum（nonzero_mask） / y_train_pct.size
       sample_weights_pct [nonzero_mask] = 1 / max（scaling_factor，1e-6）
   print（sample_weights_conf.shape，sample_weights_pct.shape，y_train_conf.shape，y_train_pct.shape.shape，flush = true）

   ＃sample_weights_binary = np.mean（sample_weights_conf，axis = 1）
   ＃sample_weights_continous = np.mean（sample_weights_pct，axis = 1）

   ＃print（sample_weights_continous.shape，sample_weights_binary.shape，flush = true）
   ＃----火车模型----＃
   历史= model.fit（
       {ts_input＆quot＆quot; x_ts_train，＆quot; item_input＆quot＆quot; x_item_train}，
       {&#39;output_binary＆quot;：y_train_conf，＆quort&#39;output_continouul＆quot;：y_train_pct}，
       时代= epochs，
       batch_size = batch_size，
       验证_split = 0.1，
       详细= 2，
       sample_weight = {&#39;output_binary&#39;：sample_weights_conf，&#39;output_continuul&#39;：sample_weights_pct}＃单独通过
   ）

   返回历史
 
我希望该模型可以毫无意义地将样品权重采用，并试图将它们作为列表作为一个阵列，这是两者的平均值，并试图给出y_train，x_train和sample_ weapters作为阵列，所有这些都给了我多种错误，并且仍然给我带来了无数的错误，但仍然没有给出积极的结果。&gt;                    。]]></description>
      <guid>https://stackoverflow.com/questions/79521352/why-wont-tf-keras-let-me-pass-a-dictionary-of-multiple-sample-weights</guid>
      <pubDate>Wed, 19 Mar 2025 20:47:01 GMT</pubDate>
    </item>
    <item>
      <title>需要在流失预测模型上帮助[封闭]</title>
      <link>https://stackoverflow.com/questions/79521346/need-help-on-churn-prediction-model</link>
      <description><![CDATA[我是一个小组，为公司做一个ML项目。我们正在进行的项目是服务的流失预测模型，现在该公司将其定义为Churn，整个数据集中只有大约2％的流失。 200万行。这些是我们迄今为止最佳模型的结果：
分类报告 
我们尝试了所有常规的监督学习算法和pytorch神经网络算法，并且我们一直在使用Smote Overplating和Smotetomek，但是对于流失案例，我们的结果不足。截至目前，使用梯度提升，我们在上传图片中看到的分数获得了最佳效果。有什么建议吗？另外，如果我们要通过每行计算搅动或进行窗户的ChurnF.X。如果我们要以3个月的基础计算终止服务的数量，并且如果他们删除了证书百分比，那么它将被视为流失，或者我们是否应该对独特的客户进行分组并将数据集转换为每个客户的一行，而不是出现48个不同时间？数据集中有30列以上的列是捕获太多噪声的模型吗？
任何建议都会有所帮助！
我们尝试了所有常规监督的学习算法和pytorch神经网络。]]></description>
      <guid>https://stackoverflow.com/questions/79521346/need-help-on-churn-prediction-model</guid>
      <pubDate>Wed, 19 Mar 2025 20:42:11 GMT</pubDate>
    </item>
    <item>
      <title>从Edge Export TFJS模型，Express/Node API中获取对象检测结果</title>
      <link>https://stackoverflow.com/questions/79521051/get-object-detection-results-from-edge-export-tfjs-model-bin-dict-in-express</link>
      <description><![CDATA[我已经将我的vertexai模型导出到tfjs as&#39;edge;

 dict.txt 
 group1_shard1of2.bin 
 group1_shard2of2.bin 
 model.json 

现在，我将图像从客户发送到节点/快递端点，我真的很难弄清楚 - 因为我发现TFJS文档很糟糕，可以理解我需要做什么。  但这是我所拥有的：
 &#39;@tensorflow/tfjs-node;：＆quot&#39;^4.22.0＆quot;
＆quot@types/multer＆quot;：＆quot^1.4.12＆quot;
＆quot“ multer”：&#39;^1.4.5-lts.1＆quort;
 
，然后在我的端点处理程序中进行图像＆amp;型号：
 
const upload = multer（{{
  存储：MemoryStorage（），
  限制：{
    文件大小：10 * 1024 * 1024，// 10MB限制
  }，，
}）。单个（&#39;image&#39;）;

//加载字典文件
const loadDictionary =（）=＆gt; {
  const dictpath = path.join（__ dirname，&#39;model&#39;，&#39;dict_03192025.txt&#39;）;
  const content = fs.ReadFileSync（dictpath，&#39;utf-8&#39;）;
  return content.split（&#39;\ n&#39;）。filter（line =＆gt; line.trim（）！==&#39;&#39;&#39;）;
};

const getToppredictions =（
  预测：数字[]，
  标签：字符串[]，
  topk = 5
）=＆gt; {
  //获取按概率排序的索引
  const索引=预测
    .map（（（_，i）=＆gt; i）
    。

  //以其概率获得顶级K预测
  return indices.slice（0，topk）.map（index =＆gt;（{{
    标签：标签[索引]，
    概率：预测[索引]，
  }））;
};

导出const扫描= async（req：request，res：response）=＆gt; {
  上载（req as not，res as any，async err =＆gt; {
    如果（err）{
      返回res.status（400）.send（{消息：err.message}）;
    }

    const file =（req as noy）.file as express.multer.file;

    如果（！文件||！file.buffer）{
      返回res.status（400）.send（{消息：&#39;没有图像文件提供&#39;}）;
    }

    尝试 {
      //加载字典
      const labels = loadDictionary（）;

      //加载JSON格式的模型
      const模型=等待tf.loadgraphmodel（
        &#39;file：//&#39; + __dirname +&#39;/model/model_03192025.json&#39;
      ）；

      //处理图像
      const image = tf.node.decodeimage（file.Buffer，3，&#39;int32&#39;）;
      const尺寸= tf.image.ResizeBilesBileNear（图像，[512，512]）;
      const rangure image = justized.div（255.0）;
      const batchedimage = normolizedImage.expandDims（0）;
      const预测=等待model.executeasync（batchedimage）;

      //提取预测数据并获得最佳匹配
      const预测= array.isarray（预测）
        ？等待（预测[0]作为tf.tensor）.array（）
        ：等待（作为tf.tensor的预测）.array（）;

      const flatpredictions =（预测为number [] []）。flat（）;
      const toppredictions = getToppredictions（flatpredictions，labels）;

      //清理张量
      image.dispose（）;
      调整大小。dispose（）;
      归一化图。dispose（）;
      batchedimage.dispose（）;
      if（array.isarray（predivions））{
        prective.foreach（p =＆gt;（p as tf.tensor）.dispose（））;
      } 别的 {
        （作为tf.tensor的预测）.dispose（）;
      }

      返回res.status（200）。
        消息：“成功处理的图像”，
        尺寸：file.size，
        类型：file.mimetype，
        预测：预测，
      }）;
    } catch（错误）{
      Console.Error（&#39;错误处理图像：&#39;，错误）;
      返回res.status（500）.send（{消息：&#39;错误处理image&#39;}）;
    }
  }）;
};

//包装器功能处理类型铸造
导出const scanhandler = [
  上传，
  （req：request，res：reverse）=＆gt;扫描（req，res），
]作为const;
 
这是我关注的内容：

我是否正确加载模型为 GraphModel ？我尝试了其他人，这是唯一起作用的。
我正在调整大小为512x512好吗？
如何更好地处理结果？  如果我想要最高的“评分”图像，最好的方法是什么？
]]></description>
      <guid>https://stackoverflow.com/questions/79521051/get-object-detection-results-from-edge-export-tfjs-model-bin-dict-in-express</guid>
      <pubDate>Wed, 19 Mar 2025 18:11:20 GMT</pubDate>
    </item>
    <item>
      <title>获得RuntimeRor：使用MPS时，视图大小与输入张量的大小和大步不兼容</title>
      <link>https://stackoverflow.com/questions/79274150/getting-runtimeerror-view-size-is-not-compatible-with-input-tensors-size-and-s</link>
      <description><![CDATA[ RuntimeError：视图大小与输入张量的大小和大步不兼容（在两个连续子空间上至少一个维度跨度一个维度）。使用.RESHAPE（...）代替。
仅在使用MP而不是CPU 时获取此错误
 
fine_tuned_decoder_path =＆quot; path/fine_tuned_decoder;
模型= visionencoderdecodermodel.from_encoder_decoder_pretrated（
    encoder_pretratained_model_name_or_path =＆quot; google/vit-base-patch16-224-in21k;
    desoder_pretratained_model_name_or_path = fine_tuned_decoder_path，
    tie_encoder_decoder = true，
    cache_dir =;/path/dataSets/＆quot+;  ＃缓存模型目录
）
os.environ [&#39;wandb_mode&#39;] =; quot;

＃设定批次大小和训练时期的数量
batch_size = 16
train_epochs = 5

＃定义存储培训输出的输出目录
output_directory = os.path.join（“路径”;

＃检查议员是否可用
设备= torch.device（MPS“如果Torch.backends.mps.is_available（）else; cuda;

＃将模型移至正确的设备
型号（设备）

＃设置混合精度和设备处理
fp16 = false＃完全禁用fp16
mixed_precision =无＃禁用混合精度（默认）

＃培训论点
triending_args = triencharguments（
    output_dir = output_directory，
    per_device_train_batch_size = batch_size，
    do_train = true，
    num_train_epochs = train_epochs，
    operwrite_output_dir = true，
    use_cpu = false，＃确保您不使用CPU
    dataloader_pin_memory = false，
    fp16 = fp16，＃禁用FP16如果使用MPS
    bf16 = false，＃禁用BF16如果使用MPS
    optim =“ adamw_torch”
    gradient_checkpointing = false，＃如有必要
    logging_dir = os.path.join（output_directory，&#39;logs&#39;），
    report_to =; none＆quot;＃禁用报告
    
）

＃在正确的设备上使用培训师与型号
培训师=教练（
    processing_class = feature_extractor，＃tokenizer
    模型=模型，＃训练模型
    args = triending_args，＃培训论点
    train_dataset = train_dataset，＃培训数据集
    data_collat​​or = default_data_collat​​or＃数据碰撞器
）
＃开始训练过程
Trainer.Train（）
 
尝试设置use_cpu = true，它可以正常运行，但与MPS 不行]]></description>
      <guid>https://stackoverflow.com/questions/79274150/getting-runtimeerror-view-size-is-not-compatible-with-input-tensors-size-and-s</guid>
      <pubDate>Thu, 12 Dec 2024 07:20:47 GMT</pubDate>
    </item>
    <item>
      <title>修复错误：root：发生错误：MPS不支持INT64输入的Cumsum OP</title>
      <link>https://stackoverflow.com/questions/79235675/fix-errorrootan-error-occurred-mps-does-not-support-cumsum-op-with-int64-inpu</link>
      <description><![CDATA[我正在研究一个项目，试图使用LLM总结一堆电影评论。我会遇到这个错误，因为我使用的是Mac芯片M3。我不想使用CPU，因为我得到了700个簇，我想利用我的M3。该怎么办？这是我的代码：
 来自domain.interfaces导入summarizationserviceInterface
从变形金刚导入自动源，AutoModelForseq2Seqlm`
导入火炬
导入OS`

huggingface_token = os.getEnv（&#39;huggingface_token＆quot）`
类Summarizationservice（summarizationserviceInterface）：
   “”“使用预训练的型号总结文本”。”

   def __init __（self，model_name：str =; sshleifer/distilbart-cnn-12-6＆quort＆quort;设备：str =; qure
       “”
       初始化摘要服务。

       args：
           model_name（str）：加载预训练模型的名称。
           设备（STR）：在（&#39;CPU&#39;或“ MPS”）上运行模型的设备。
       “”
       self.device = torch.device（设备）
       self.tokenizer = autotokenizer.from_pretaining（model_name）
       self.model = automodelforseq2seqlm.from_pretrated（model_name）.to（self.device）

   def汇总（self，texts：list [str]） - ＆gt; str：
       “”
       总结文本列表。

       args：
           文本（列表[str]）：要总结的文本列表。

       返回：
           str：总结文本。
       “”
       combined_text =＆quot; ＆quot join（文本）
       输入= self.tokenizer（
           combined_text，max_length = 512，return_tensors =; pt; quord; truncation = true
       ）.to（self.device）

       summary_ids = self.model.generate（
           输入[＆quot; input_ids;]，max_length = 150，min_length = 40，num_beams = 4，roford_stopping = true = true
       ）
       返回self.tokenizer.decode（summary_ids [0]，skip_special_tokens = true）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79235675/fix-errorrootan-error-occurred-mps-does-not-support-cumsum-op-with-int64-inpu</guid>
      <pubDate>Fri, 29 Nov 2024 02:07:04 GMT</pubDate>
    </item>
    <item>
      <title>从MAC上的2-1升级到稳定的扩散3</title>
      <link>https://stackoverflow.com/questions/78643538/upgrading-to-stable-diffusion-3-from-2-1-on-mac</link>
      <description><![CDATA[我正在将稳定扩散从2-1升级到稳定的扩散-3-矿物 - 散布器
这是我的代码，它适用于版本2-1 
 ＃源venv/bin/activate

从扩散器导入扩散置

pipe = diffusionPipeline.from_pretained（“稳定/稳定 - 扩散2-1”）
管道=管道。

pipe.enable_attention_slicing（）

打印（“开始过程”

步骤= 200
查询=“蒙特卡洛的暴风雨天气”

image = pipe（查询，num_inference_steps = steps）.images [0]

image.save（&#39;OneOffimage.jpg＆quot;）

打印（“成功地创建图像为OneOffimage.jpg”）
 
我升级了扩散器，在拥抱面上注册以访问封闭式存储库，创建并将HF_Token添加到我的.env中，然后运行此代码
 ＃源venv/bin/activate

从扩散器导入Stablediffusion3Pipeline
来自dotenv import load_dotenv
导入操作系统

load_dotenv（）

打印（“开始过程”

pipe = stablediffusion3pipeline.from_pretaining（“稳定/稳定-Diffusion-3-Medium-diffusers”）
管道=管道。

＃pipe.set_progress_bar_config（disable = true）
pipe.enable_attention_slicing（）

打印（“开始过程”

步骤= 200
查询=“蒙特卡洛的暴风雨天气”

image = pipe（查询，num_inference_steps = steps）.images [0]

image.save（&#39;OneOffimage.jpg＆quot;）

打印（“成功地创建图像为OneOffimage.jpg”）
 
我能够下载该模型，还记录了令牌并确认它在env var中，我尝试添加火炬和设置，torch_dtype = torch.float16），但这无所作为，但这无所作为，而且我认为cuda，我也尝试了一个auth tag，但我也没有添加任何东西，但我却没有任何东西，但我却没有任何东西。我的想法用完了。
这是当前错误
 （VENV）Mikeland@Mikes-Mac-Mini Weatherwindow％Python3 OneOffGenstablediffusion.py 
/USERS/MIKELAND/WeatherWindow/venv/lib/python3.9/site-packages/diffusers/models/models/transformers/transformer_2d.py:34：futureWarning：`tronScormenTer2dmodeLoutput&#39;被贬低，并将在版本1.0.0.0.0.0中删除。从`diffusers.models.transformer_2d`导入`transformer2dmodeLoutput`已弃用，这将在将来的版本中删除。请使用`from diffusers.models.modeling_outputs导入transformer2dmodeloutput`而代替。
  dobecate（“ trransformer2dmodeloutput”＆quot＆quot” 1.0.0＆quot; eutrecation_message）
启动过程
加载管道组件...：0％|                                                                                  | 0/9 [00：00＆lt;？，？it/s]
Trackback（最近的最新电话）：
  file＆quot＆quort＆quot＆weatherwindow/oneoffgenstablediffusion.py&quot;，第15行，in＆lt; module＆gt;
    pipe = stablediffusion3pipeline.from_pretaining（“稳定/稳定-Diffusion-3-Medium-diffusers”）
  file＆quot＆quot＆quot＆quot＆quesland/weatherwindow/venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py&quot; line 114，in _inner_fn
    返回fn（*args，** kwargs）
  file＆quot＆quot＆quot＆quot＆quot＆quot＆quot of_pretrented in_pretrented in_pretrented
    loaded_sub_model = load_sub_model（
  file＆quot＆quot＆quot＆quot＆quote＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot pipelines/pipeline/pipeline_loading_utils.py＆quot＆quot＆quot;
    loaded_sub_model = load_method（os.path.join（cached_folder，name），** loading_kwargs）
  file＆quot＆quot＆quot＆quot＆quot＆quot of_pretained in_pretrented in_pretrented
    提高侵居者（
Importerror：使用`low_cpu_mem_usage = true`或`device_map`需要加速了：`pip install ackelerate&#39;
 
我只是在寻找我现在可以在Mac上工作的任何示例。]]></description>
      <guid>https://stackoverflow.com/questions/78643538/upgrading-to-stable-diffusion-3-from-2-1-on-mac</guid>
      <pubDate>Wed, 19 Jun 2024 15:58:26 GMT</pubDate>
    </item>
    <item>
      <title>MPS设备和Pytorch</title>
      <link>https://stackoverflow.com/questions/78523154/mps-device-and-pytorch</link>
      <description><![CDATA[我想在我的Mac上与闪电教练一起朗姆语。
这些是我的教练设置：
  Trainer = PL.Trainer（Trainer（
    logger = false，
    enable_checkpointing = true，＃
    enable_progress_bar = true，
    加速器=“ MPS”
    设备= 1，
    max_epochs = 20，＃要训练的时期数
）
 
我还改变了我的环境，如下所示：
 导入OS
os.environ [&#39;pytorch_enable_mps_fallback&#39;] =&#39;1&#39;
 
我开始培训时仍然：
 
Trainer.fit（MPNN，Train_loader）
 
我会有以下错误消息：
 notimplementedError：当前未针对MPS设备实现操作员&#39;aten :: sctity_reduce.two_out&#39;。如果您希望在此功能的原型阶段中优先添加此操作，请在 https：&gt; https://github.com.com.com.com.com.com.com./pytorch/pytorch/siss/777.77.764上，请评论。作为临时修复，您可以设置环境变量 pytorch_enable_mps_fallback = 1 将CPU用作此OP的后备。警告：这将比国会议员本地运行要慢。
输出被截断。将其视为可滚动元素或在文本编辑器中打开。调整单元输出设置... 
我尝试以下步骤解决该问题：
在培训师中更改了从Accelerator =&#39;auto&#39;，到Accellerator =&#39;MPS&#39;
如误差所建议更改了环境变量。
尝试：
 
如果Torch.backends.mps.is_available（）：
    设备= TORCH.DEVICE（&#39;MPS&#39;）
别的：
    设备= TORCH.DEVICE（&#39;CPU&#39;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/78523154/mps-device-and-pytorch</guid>
      <pubDate>Thu, 23 May 2024 12:34:08 GMT</pubDate>
    </item>
    <item>
      <title>数据加载器 -  CPU和MPS之间的Pytorch不一致 - 苹果硅</title>
      <link>https://stackoverflow.com/questions/76991341/dataloader-pytorch-inconsistency-between-cpu-and-mps-apple-silicon</link>
      <description><![CDATA[我在Mac Apple Silicone上与Pytorch的Dataloader陷入了这种不一致之处。
如果我使用cpu  y ，请正确解释。但是，如果我使用MPS，它总是以正确的长度返回向量，但是仅基于第一个元素 y [0] 。
 导入火炬
来自torch.utils.data导入tensordataset，Random_split，dataLoader


设备= TORCH.DEVICE（MPS;） 
x = torch.tensor（[[[[[0.5,0.4]，[0,0]]，[[0.3,0.2]，[0,0]]，[[0.5,0.2]，[0,0,0]，[0,0.0.2]，[[0.2,0.2]，[0,0,0]，[0,0,0]，[0,0,0]
Y = TORCH.TENSOR（[1,0,0,0]，dtype = Type = Torch.float32）TO（设备）

打印（X.Shape）
打印（y.形）
打印（y）
dataset = tensordataset（x，y）
train_size = int（0.5 * len（数据集））
test_size = len（数据集） -  train_size
train_dataset，test_dataset = Random_split（数据集，[train_size，test_size]）
train_loader = dataloader（train_dataset，batch_size = 10，shuffle = true）

对于i（batch_data，batch_labels）枚举（train_loader）：
    打印（batch_data）
    打印（batch_labels）
    休息
 
对于 batch_labels  on  mps 我总是在 y  中根据第一个值获得张量。
  torch.size（[4，2，2]）
TORCH.Size（[4]）
张量（[1.，0.，1。1。，0。]，设备=&#39;MPS：0&#39;）
张量（[[[[0.5000，0.2000]，
         [0.0000，0.0000]]，

        [[0.5000，0.4000]，
         [0.0000，0.0000]]]，设备=&#39;MPS：0&#39;）
张量（[1。，1。]，设备=&#39;MPS：0&#39;）
 
也许它与一般MPS OP覆盖范围跟踪问题＃777764 ]]></description>
      <guid>https://stackoverflow.com/questions/76991341/dataloader-pytorch-inconsistency-between-cpu-and-mps-apple-silicon</guid>
      <pubDate>Mon, 28 Aug 2023 08:55:44 GMT</pubDate>
    </item>
    <item>
      <title>Intel Mac上的Torch MPS：获取设备的名称？</title>
      <link>https://stackoverflow.com/questions/76954976/torch-mps-on-intel-mac-get-name-of-device</link>
      <description><![CDATA[在Python中，在具有NVIDIA GPU的机器上，可以使用以下方式确认GPU的MPS设备名称：
  torch.cuda.get_device_name（） 
根据文档： https://pytorch.org/docs/stable/generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name  
如何确认具有AMD GPU的Intel Mac的MPS设备名称？我在文档中没有任何提及。]]></description>
      <guid>https://stackoverflow.com/questions/76954976/torch-mps-on-intel-mac-get-name-of-device</guid>
      <pubDate>Tue, 22 Aug 2023 15:48:25 GMT</pubDate>
    </item>
    <item>
      <title>稳定的扩散模型的运行模型提示从MPOS上拥抱脸部的稳定扩散模型</title>
      <link>https://stackoverflow.com/questions/76939164/running-model-prompt-on-stable-diffusion-model-from-hugging-face-on-mps-macos</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76939164/running-model-prompt-on-stable-diffusion-model-from-hugging-face-on-mps-macos</guid>
      <pubDate>Sun, 20 Aug 2023 11:27:44 GMT</pubDate>
    </item>
    <item>
      <title>反馈循环：预期发电机的“ CPU”设备类型，但找到了“ MPS”</title>
      <link>https://stackoverflow.com/questions/76817578/feedback-loop-expected-a-cpu-device-type-for-generator-but-found-mps</link>
      <description><![CDATA[我试图在MacOS M2上捕获拥抱面模型。但是，MPS尚不存在火炬操作员“ Aten :: Random_”。因此，我用运行了该程序
  pytorch_enable_mps_fallback = 1 
 
然后，我收到了以下消息，“预期“ CPU”发电机设备类型，但找到了“ MPS”。我试图通过指定 generator = torch.generator（device =&#39;mps&#39;）在数据载加载程序中解决此问题。然而，这扭曲了信息，并产生“预期A MPS：0”生成器设备，但发现了“ MPS”。因此，看来我陷入了循环。
这是我正在使用的完整代码
 从数据集导入load_dataset
从变形金刚导入自动源
导入火炬
来自torch.utils.data导入数据加载程序

dataset = load_dataset（&#39;yelp_review_flull&#39;）
tokenizer = autotokenizer.from_pretaining（“ bert-base cased;）
def tokenize_function（示例）：
    返回tokenizer（示例[&#39;text;]，padding =; max_length＆quort＆quot; truncation = true）

tokenize_datasets = dataset.map（tokenize_function，batched = true）

tokenized_datasets = tokenized_datasets.remove_columns（[text;]）
tokenized_datasets = tokenized_datasets.rename_column（“ label; quot”;
tokenized_datasets.set_format（“ Torch”）
small_train_dataset = tokenized_datasets [&#39;train;]。shuffle（seed = 42）。选择（range（1000））
small_eval_dataset = tokenized_datasets [&#39;test&#39;]。shuffle（seed = 42）。选择（range（range（1000）））


train_dataloader = dataloader（small_train_dataset，shuffle = true，batch_size = 8，generator = torch.generator（device =&#39;cpu&#39;）
eval_dataloader = dataloader（small_eval_dataset，batch_size = 8，generator = torch.generator（device =&#39;cpu&#39;））
对于train_dataloader中的批次：
    打印（批次）
    ＃当然，我想在这里做其他事情，但是打开循环已经产生错误。 
 
我正在使用火炬2.0.1，数据集2.14.0与变压器4.31.0 一起使用]]></description>
      <guid>https://stackoverflow.com/questions/76817578/feedback-loop-expected-a-cpu-device-type-for-generator-but-found-mps</guid>
      <pubDate>Wed, 02 Aug 2023 07:34:31 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch MPS：“ MPS.Scatter_nd” OP无效输入张量形状</title>
      <link>https://stackoverflow.com/questions/76196734/pytorch-mps-mps-scatter-nd-op-invalid-input-tensor-shape</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76196734/pytorch-mps-mps-scatter-nd-op-invalid-input-tensor-shape</guid>
      <pubDate>Sun, 07 May 2023 23:44:53 GMT</pubDate>
    </item>
    <item>
      <title>M2 Mac上的Pytorch（2022）：RuntimeError：占位符存储尚未在MPS设备上分配</title>
      <link>https://stackoverflow.com/questions/75842303/pytorch-on-m2-mac2022-runtimeerror-placeholder-storage-has-not-been-allocate</link>
      <description><![CDATA[I&#39;m training a model in PyTorch 2.0.0.I built a model Bert+Liner Model below. I have set device=torch.device(&quot;mps&quot;).Error occurs where input_ids,attention_mask,token_type_ids,labels. Thanks for your help~~
i expect that model could run on mps, while i figure it out on cpu, with much time to spend.I want to run the model on mps with less time.Thanks
model = bert+Linear
class Model(torch.nn.Module):
def init(self):
super().init()
# 定义一个全连接层
# 输入768维：bert-base-chinese的输出维度，输出2维：情感倾向的种类数
self.fc = torch.nn.Linear(768, 2)
# 前向传播函数
def forward(self, input_ids, attention_mask, token_type_ids):
    with torch.no_grad():  
        out = pretrained(input_ids=input_ids,
                         attention_mask=attention_mask,
                         token_type_ids=token_type_ids)  # 基于bert模型，直接获得输出768维的结果

    # 取0个词的特征作为全连接层的输入
    out = self.fc(out.last_hidden_state[:, 0])
    out = out.softmax(dim=1)  # 取出概率最大的一维作为结果
    return out

predict sentiment of text
for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(bar_predict):
print(&#39;当前批次:&#39;, i)
    # 将变量转移到MPS上
    input_ids = input_ids.to(torch.long).to(config.device)
    attention_mask = attention_mask.to(torch.long).to(config.device)
    token_type_ids = token_type_ids.to(torch.long).to(config.device)
    labels = labels.to(torch.long).to(config.device)

    with torch.no_grad():  # 预测过程不计算梯度，
        out = sentimodel(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        out = out.argmax(dim=1)  # 取列维度最大的值所对应的位置索引
]]></description>
      <guid>https://stackoverflow.com/questions/75842303/pytorch-on-m2-mac2022-runtimeerror-placeholder-storage-has-not-been-allocate</guid>
      <pubDate>Sat, 25 Mar 2023 14:20:30 GMT</pubDate>
    </item>
    <item>
      <title>如何解决M1 Mac上的“ MPS Framework不支持Float64”</title>
      <link>https://stackoverflow.com/questions/75173055/how-to-resolve-mps-framework-doesnt-support-float64-on-m1-mac</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75173055/how-to-resolve-mps-framework-doesnt-support-float64-on-m1-mac</guid>
      <pubDate>Thu, 19 Jan 2023 13:34:42 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机。精度和/或准确性？</title>
      <link>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</link>
      <description><![CDATA[我正在尝试弄清我使用的代码是计算精度还是准确性或两者兼而有之。由于我只有少量的统计背景（用另一种语言），所以我真的不理解 wikipedia&#39;&gt; wikipedia文章涵盖该主题。
具体地我使用以下python代码：
 来自Sklearn Import SVM，Cross_validation
clf = svm.svc（内核=内核，c = c）
scores = cross_validation.cross_val_score（clf，featurematrix，np.squeeze（labelmatrix），cv = d_inds）
 
  scikit-learn 函数可以在此处找到：

     sklearn.svc.svm.svc.svc.svc       
 ]]></description>
      <guid>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</guid>
      <pubDate>Mon, 25 Apr 2016 17:03:37 GMT</pubDate>
    </item>
    </channel>
</rss>