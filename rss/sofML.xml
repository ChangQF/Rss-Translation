<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 01 Dec 2023 03:15:17 GMT</lastBuildDate>
    <item>
      <title>unserialize(socklist[[n]]) 中的错误：在插入符中执行 RF 模型时从连接读取错误</title>
      <link>https://stackoverflow.com/questions/77582605/error-in-unserializesocklistn-error-reading-from-connection-while-execut</link>
      <description><![CDATA[我正在尝试运行随机森林代码，以使用 R studio 中的插入符包对卫星图像进行分类。在训练模型时，我总是收到错误“unserialize(socklist[[n]]) 中的错误：从连接读取错误”。尝试关闭集群时“unserialize(node$con) 中的错误：从连接读取时出错”这个错误来了。我正在使用 caret 包并使用 doparallel 包进行并行计算
&quot;cl &lt;- makeCluster(3/4 * detectorCores())
registerDoParallel(cl)”
我使用的系统具有 i9（第 13 代）、128 GB 内存，并尝试使用 28、24、16 核。所有的尝试都以这个错误告终。我重新安装了 R 和 R studio，将版本更改为旧版本，在终端中运行脚本，但出现了同样的错误。相同的代码在 i5（第 9 代）笔记本电脑上成功运行； 16 GB 内存仅使用 3 个核心，但输出需要 12 小时。我该如何解决这个问题。这是代码、R studio 还是我正在使用的系统的问题？]]></description>
      <guid>https://stackoverflow.com/questions/77582605/error-in-unserializesocklistn-error-reading-from-connection-while-execut</guid>
      <pubDate>Fri, 01 Dec 2023 01:53:00 GMT</pubDate>
    </item>
    <item>
      <title>有人可以向我解释这个错误吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77582582/guys-can-some-one-explain-this-error-to-me</link>
      <description><![CDATA[文件“e:\\Projects\\Ai\\NumReco\\train.py”，第 16 行，位于 __init__ 中
   尝试：self.qtr，self.atr，self.qte，self.ate=self.train，self.test=self.mnist=self.getqa（路径）
                                           ^^^^^^^^^^^^^^^^^^^^^^
ValueError：需要解压的值太多（预期为 2）

有人可以告诉我为什么有“太多的值需要解包（预计有 2 个）”，但我却得到了两个需要解包的值？]]></description>
      <guid>https://stackoverflow.com/questions/77582582/guys-can-some-one-explain-this-error-to-me</guid>
      <pubDate>Fri, 01 Dec 2023 01:39:01 GMT</pubDate>
    </item>
    <item>
      <title>数据库部署新手</title>
      <link>https://stackoverflow.com/questions/77582450/new-to-database-deployment</link>
      <description><![CDATA[我是数据库世界的新手，我正在处理具有时间序列高分辨率数据集的测试数据，并且每个数据集都被计算/汇总为更简单的事务集（包括其元数据）。目前这些都存储在本地服务器中。我很少遇到连接表的需求，但我不断使用时间序列数据来创建其他指标来构建机器学习模型。
csv中的每个时间序列数据集最大可达2.6MB，而交易数据则为kB大小。我有超过 20,000 组这样的数据。

什么是具有最佳性能的良好数据库选项/架构？关系型还是非关系型？每个选项都有哪些优秀的供应商？
如何确定是否应该迁移到云服务器？有哪些推荐的供应商？

对此的任何指导将不胜感激！或者任何好的教程101都会很好！
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77582450/new-to-database-deployment</guid>
      <pubDate>Fri, 01 Dec 2023 00:47:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在此示例代码中探索 AWS 分析/ML/AI 服务？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77582249/how-do-i-explore-aws-analytics-ml-ai-services-in-this-example-code</link>
      <description><![CDATA[我想开始使用 AWS 的一些机器学习模型。我看到他们最近发布了 Bedrock 服务，我想设置一个环境来执行此操作。我还需要与 S3、Langchain 和 Vector 数据库（例如 Pinecone）进行交互。这里有一些关于我可能会玩的想法： 示例
我的电脑上有 VS Code，并且我看过一份指南，详细介绍了设置此功能的一些步骤：指南
我从示例链接中看到的是，我猜测使用了 Jupyter notbeook。另外（请原谅我的天真），如果我将 S3 文件放入 Vector 数据库，这些服务肯定需要启动（或设置），并由我付费。之后，只需通过 AWS Bedrock（处理许多底层内容）查询数据库即可。
所以我想我的问题是最初将数据导入矢量数据库：
我需要 Jupyter 笔记本吗？
我需要 AWS Sagemaker 吗？我在设置 SageMaker 时看到，您可以指定 EC2 或某些计算能力。
我需要 VS Code + Python + 其他东西吗？
或者此处链接的指南是否足够？
本质上，要使用我链接的示例，我的设置应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77582249/how-do-i-explore-aws-analytics-ml-ai-services-in-this-example-code</guid>
      <pubDate>Thu, 30 Nov 2023 23:35:25 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 蜂群图解读</title>
      <link>https://stackoverflow.com/questions/77581801/shap-beeswarm-plot-interpretation</link>
      <description><![CDATA[我创建了一个 SHAP 蜂群图，我发现当高特征值和低特征值以微笑随机方式聚集在一起时，很难解释变量的影响。以下是几个示例（绿色 = 高，蓝色 = 低）：
示例 1

示例 2

在示例 1 中，我至少可以说极高的特征值对模型输出有积极的影响。但是，我不明白如何处理高点和低点集群，特别是在示例 2 中。我唯一的想法是，具有相同 SHAP 值的相同数量的高点和低点特征值。
那么，对于此类簇是否有更有意义的解释？]]></description>
      <guid>https://stackoverflow.com/questions/77581801/shap-beeswarm-plot-interpretation</guid>
      <pubDate>Thu, 30 Nov 2023 21:22:32 GMT</pubDate>
    </item>
    <item>
      <title>获取 'model.fit' keras API 参数的值</title>
      <link>https://stackoverflow.com/questions/77581428/get-values-of-model-fit-keras-api-parameters</link>
      <description><![CDATA[我正在尝试使用自定义回调函数获取 Kera 顺序模型的详细信息。我需要提取 model.fit() API 中设置的参数的所有值，例如 batch_size、epochs、validation_split 等。但我无法在 Keras 的回调中访问它们。您知道如何自动获取这些值吗？
我正在使用 Python 3.10 和 Keras 2.8。]]></description>
      <guid>https://stackoverflow.com/questions/77581428/get-values-of-model-fit-keras-api-parameters</guid>
      <pubDate>Thu, 30 Nov 2023 20:13:45 GMT</pubDate>
    </item>
    <item>
      <title>我的项目应该使用 TensorFlow 还是 PyTorch？</title>
      <link>https://stackoverflow.com/questions/77581368/should-i-use-tensorflow-or-pytorch-for-my-project</link>
      <description><![CDATA[我正在开展一个导师与学员匹配项目，我的目标是使用深度学习技术和语言模型（例如 BERT 或 GPT）来分析导师和学员的文本资料，以找到合适的匹配。该项目涉及对文本配置文件进行编码、计算相似性分数、生成建议，以及可能微调预训练模型以获得更好的性能。
我正在决定使用 TensorFlow 还是 PyTorch 来实施这个项目。考虑到所涉及的任务，例如文本编码、相似性计算和潜在的微调模型，哪种框架更适合此类项目？在导师与受训者匹配任务的背景下，我应该考虑这两种框架的具体优点或局限性吗？]]></description>
      <guid>https://stackoverflow.com/questions/77581368/should-i-use-tensorflow-or-pytorch-for-my-project</guid>
      <pubDate>Thu, 30 Nov 2023 20:00:14 GMT</pubDate>
    </item>
    <item>
      <title>OpenAi 从我的应用程序检索数据</title>
      <link>https://stackoverflow.com/questions/77575498/openai-to-retrieve-data-from-my-application</link>
      <description><![CDATA[我管理一个包含数千个商机、客户、联系人等的 CRM 应用程序。我正在寻求实现类似聊天的功能，允许用户提出问题并从存储的记录中检索数据。例如，他们可以查询价值超过 10,000 美元的机会。
最初，我探索使用 NLP to SQL 方法。我向 OpenAI 提供了我的表结构和用户提示，执行生成的 SQL 查询产生了准确的结果。然而，正如在各种实例中所观察到的那样，仅仅依靠 OpenAI 生成 SQL 会带来安全风险。
我正在探索替代方法。一种想法是为特定任务创建专用 API，然后使用 OpenAI 对其进行训练。这看起来是一个可行的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/77575498/openai-to-retrieve-data-from-my-application</guid>
      <pubDate>Thu, 30 Nov 2023 02:19:04 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在一个 Colab（或 Jupyter Notebook）中使用“train_test_split”两次吗？</title>
      <link>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</link>
      <description><![CDATA[我必须使用决策树机器学习算法执行分类和回归。现在我已经完成了代码的回归部分。如果我继续对此进行分类任务，我应该对预处理的数据集执行train_test_split。 在代码中我必须定义 X 和 y 变量，然后执行 X_train、X_test、y_train 和 y_test 部分。回归和分类中都会重复相同的变量。通过从分类中获取相同的变量，它会考虑回归中首先给出的先前值还是会采用新给定的值？
我想清楚地知道我们是否可以在单个 colab 或 jupyter 笔记本中多次使用 train_test_split 函数。]]></description>
      <guid>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</guid>
      <pubDate>Mon, 27 Nov 2023 08:05:19 GMT</pubDate>
    </item>
    <item>
      <title>基于预定义的特征子集创建分类器集合</title>
      <link>https://stackoverflow.com/questions/77524700/creating-an-ensemble-of-classifiers-based-on-predefined-feature-subsets</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77524700/creating-an-ensemble-of-classifiers-based-on-predefined-feature-subsets</guid>
      <pubDate>Tue, 21 Nov 2023 17:12:25 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>如何防止 Keras 在训练期间计算指标</title>
      <link>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</link>
      <description><![CDATA[我正在使用 Tensorflow/Keras 2.4.1，并且我有一个（无监督的）自定义指标，它将我的多个模型输入作为参数，例如：
model = build_model() # 返回一个 tf.keras.Model 对象
my_metric = custom_metric(model.output, model.input[0], model.input[1])
模型.add_metric(my_metric)
[...]
model.fit([...]) # 使用 fit 进行训练

但是，custom_metric 非常昂贵，因此我希望仅在验证期间计算它。我找到了这个答案，但我几乎不明白如何使解决方案适应我的指标，该指标使用多个模型输入作为参数，因为update_state 方法似乎不太灵活。
在我的上下文中，除了编写自己的训练循环之外，是否有办法避免在训练期间计算我的指标？
另外，我很惊讶我们无法本机指定 Tensorflow 某些指标只能在验证时计算，这有什么原因吗？
此外，由于模型经过训练来优化损失，并且训练数据集不应用于评估模型，我什至不明白为什么默认情况下 Tensorflow 在训练期间计算指标。]]></description>
      <guid>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</guid>
      <pubDate>Wed, 09 Mar 2022 16:11:26 GMT</pubDate>
    </item>
    <item>
      <title>Keras 何时以及如何计算每批样本的指标？</title>
      <link>https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples</link>
      <description><![CDATA[我看到 Keras 自定义指标如何工作，并且指标函数中的 tf.print 与 model.fit 的回调打印之间的计算不匹配。
导入张量流为 tf # tf2.4.1
将 numpy 导入为 np
模型 = tf.keras.models.Sequential(
    tf.keras.layers.Dense(1, input_shape=(1,))
）
def my_metric_fn(y_true, y_pred):
    squared_difference = tf.square(y_true - y_pred)
    损失 = tf.reduce_mean(squared_difference, axis=-1)
    tf.print(y_true.shape, y_pred.shape, 损失, tf.reduce_mean(squared_difference))
    回波损耗
model.compile（优化器=&#39;adam&#39;，损失=&#39;mean_squared_error&#39;，指标=[my_metric_fn]）
x = np.random.rand(4,1)
y = x ** 2
历史= model.fit（x = x，y = y，batch_size = 2，epochs = 2）
打印（历史.历史）

输出（格式化以提高可读性）
纪元 1/2
TensorShape([2, 1]) TensorShape([2, 1]) [9.79962078e-06 0.0534314588] 0.02672063
1/2 [==============&gt;........................] - ETA：0秒 - 损失：0.0267 - my_metric_fn：0.0267
TensorShape([2, 1]) TensorShape([2, 1]) [0.0397406667 0.179955378] 0.109848022
2/2 [================================] - 0s 7ms/步 - 损耗：0.0544 - my_metric_fn：0.0544

纪元2/2
TensorShape([2, 1]) TensorShape([2, 1]) [0.0392204635 0.0521505736] 0.0456855185
1/2 [==============&gt;........................] - ETA：0秒 - 损失：0.0457 - my_metric_fn：0.0457
TensorShape([2, 1]) TensorShape([2, 1]) [0.177408844 2.45939535e-08] 0.088704437
2/2 [================================] - 0s 5ms/步 - 损耗：0.0600 - my_metric_fn：0.0600
{&#39;损失&#39;：[0.06828432530164719，0.06719497591257095]，&#39;my_metric_fn&#39;：[0.06828432530164719，0.06719497591257095]}

在上面的输出中查看批次的打印损失。
纪元 1/2 1/2 tf.print：0.02672063，model.fit：0.0267。好的。
Epoch 1/2 2/2 tf.print：0.109848022，但 model.fit：0.0544。不行。
如何理解这些匹配和不匹配？ 0.0544 从哪里来？]]></description>
      <guid>https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples</guid>
      <pubDate>Mon, 22 Feb 2021 07:31:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 keras 计算每个时期的 Fscore（不是批量）</title>
      <link>https://stackoverflow.com/questions/61683829/calculating-fscore-for-each-epoch-using-keras-not-batch-wise</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/61683829/calculating-fscore-for-each-epoch-using-keras-not-batch-wise</guid>
      <pubDate>Fri, 08 May 2020 16:41:15 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：feature_names 不匹配：在 xgboost 中的 Predict() 函数中</title>
      <link>https://stackoverflow.com/questions/42338972/valueerror-feature-names-mismatch-in-xgboost-in-the-predict-function</link>
      <description><![CDATA[我训练了一个 XGBoostRegressor 模型。当我必须使用这个经过训练的模型来预测新输入时，predict() 函数会抛出 feature_names 不匹配错误，尽管输入特征向量与训练数据具有相同的结构。
此外，为了以与训练数据相同的结构构建特征向量，我做了很多低效的处理，例如添加新的空列（如果数据不存在），然后重新排列数据列，以便它与训练结构相匹配。是否有更好、更简洁的方式来格式化输入以使其与训练结构相匹配？]]></description>
      <guid>https://stackoverflow.com/questions/42338972/valueerror-feature-names-mismatch-in-xgboost-in-the-predict-function</guid>
      <pubDate>Mon, 20 Feb 2017 07:43:24 GMT</pubDate>
    </item>
    </channel>
</rss>