<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Dec 2023 01:01:48 GMT</lastBuildDate>
    <item>
      <title>为什么我的模型能够在数据集上进行训练和测试，但在添加 SoftMax 层并要求其进行预测时出现错误？</title>
      <link>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</guid>
      <pubDate>Mon, 11 Dec 2023 23:58:34 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证和标准缩放，以便在每次迭代时对训练部分进行 fit_transformed，而验证部分仅进行变换</title>
      <link>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</link>
      <description><![CDATA[我有 X 数据，我想要进行交叉验证，并且我需要以某种方式在交叉验证的每次迭代中使用 StandardScaler，因此它的训练部分是 fit_transformed，而它的验证部分仅进行转换。我应该如何将其包含在逻辑中。我正在使用 LGBM 模型。
我很困惑如何处理它]]></description>
      <guid>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</guid>
      <pubDate>Mon, 11 Dec 2023 22:38:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   模型=llm_模型）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score（自我，查询，k，过滤器，where_document，**kwargs）
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>设计神经网络时，如何调用 keras.NonNeg()？</title>
      <link>https://stackoverflow.com/questions/77642420/when-designing-a-neural-network-how-do-i-call-keras-nonneg</link>
      <description><![CDATA[我试图确保我的 y 值都不为负数。我找不到代码示例。如何使用这个功能？
在构建模型的函数中，我将该函数放在 model.add 函数之上。我希望我的 y 值都不会为负。]]></description>
      <guid>https://stackoverflow.com/questions/77642420/when-designing-a-neural-network-how-do-i-call-keras-nonneg</guid>
      <pubDate>Mon, 11 Dec 2023 21:13:19 GMT</pubDate>
    </item>
    <item>
      <title>Adaboost 多数投票[关闭]</title>
      <link>https://stackoverflow.com/questions/77642189/adaboost-majority-voting</link>
      <description><![CDATA[我正在准备 ML 考试，但我真的不知道如何解决这个关于 Adaboost 的考试问题。
如果我是对的，第一个分类器的权重将为 0，因为 alpha 变为 0，因为 log((1-1/2)/1/2)=log(1)=0。但是，我不确定我计算的重量是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/77642189/adaboost-majority-voting</guid>
      <pubDate>Mon, 11 Dec 2023 20:13:51 GMT</pubDate>
    </item>
    <item>
      <title>没有属性。切换到 mps 时出现张量列表错误 [关闭]</title>
      <link>https://stackoverflow.com/questions/77641848/no-attribute-to-error-for-a-list-of-tensors-while-switching-to-mps</link>
      <description><![CDATA[defforward(self,fft_result_tensors):
    # 前向通过网络

    # 如果可用的话使用 MPS（可选）
    尝试：
       导入 torch.backends.mps
       可用=真
    除了导入错误：
                      可用=假

    如果可用：
                   设备=“mps”；
                   fft_result_tensors = [fft_result_tensors 中张量的tensor.to(device)]
                   自身到（设备）

错误：
&lt;前&gt;&lt;代码&gt;&gt; 77 fft_result_tensors = fft_result_tensors.to（设备）
     78 自传（设备）
     80 # 在将输入提供给模型之前对其进行压缩

AttributeError：“列表”对象没有属性“to”

我添加了for ...in，但仍然不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77641848/no-attribute-to-error-for-a-list-of-tensors-while-switching-to-mps</guid>
      <pubDate>Mon, 11 Dec 2023 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>获取标准普尔成分股的股票方向[关闭]</title>
      <link>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</link>
      <description><![CDATA[我们通常使用一两只股票作为线性回归的自变量（例如 SPX 和 GOOG），并使用 AAPL 作为因变量，用于预测 AAPL 股票的方向。
假设我们使用所有 S&amp;P500 成分，每个成分都有自己的功能，例如收盘价、移动平均线、相对强弱指数&lt; /code&gt;, ..etc，我们使用 80% 的 S&amp;P500 成分作为训练集，20% 作为测试数据集。
我需要什么类型的机器学习技术来实现此模型？]]></description>
      <guid>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</guid>
      <pubDate>Mon, 11 Dec 2023 18:57:47 GMT</pubDate>
    </item>
    <item>
      <title>关于使用从用户交互的物理设置中提取的数据设置近端策略优化代码的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/77641484/advice-on-setting-up-a-code-for-proximal-policy-optimization-using-data-pulled-f</link>
      <description><![CDATA[对于一个项目，我使用 PyTorch 在 Python 中设置近端策略优化算法 (PPO)，为用户定制振动反馈策略。我的项目是对用户肘部角度位置的一维跟踪。该系统的目标是提供振动反馈，描述肘部相对于目标位置的当前角度位置。我正在努力寻找一种在使用从现实世界传感器而不是模拟环境收集的数据的场景中实现 PPO 的方法。
我浏览了多个设置 PPO 的示例（例如这个 https ://github.com/ericyangyu/PPO-for-Beginners/tree/master）；然而，许多人依赖使用 OpenAI 健身房环境来创建模拟。我已经找到了如何根据我的项目创建自定义环境，但我似乎找不到一种可以处理从物理传感器收集的数据的方法。我也尝试过修改这些例子；但是，我找不到任何方法来推进训练过程，因为每个步骤都需要来自传感器的数据。
如果有人能够提供一些关于如何设置 PPO 算法以使用通过 OpenAI 环境或不通过 OpenAI 环境从物理传感器收集的数据的建议或示例，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77641484/advice-on-setting-up-a-code-for-proximal-policy-optimization-using-data-pulled-f</guid>
      <pubDate>Mon, 11 Dec 2023 17:58:03 GMT</pubDate>
    </item>
    <item>
      <title>我们如何从图中知道训练模型是否良好？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77641405/how-do-we-know-if-training-model-is-considered-good-from-the-graph</link>
      <description><![CDATA[所以我一直在使用 TensorFlow 训练模型。数据有6列，输出为1列（分类为6）。我想知道我的训练是否符合图表的外观。
我尝试了几种不同的模型，并且我保存了 2 个训练图。其中之一具有更好的验证损失，但图表看起来有点不稳定（？）。第二个的验证损失更严重，但图表比第一个更不摇晃。哪一个更好？

]]></description>
      <guid>https://stackoverflow.com/questions/77641405/how-do-we-know-if-training-model-is-considered-good-from-the-graph</guid>
      <pubDate>Mon, 11 Dec 2023 17:41:34 GMT</pubDate>
    </item>
    <item>
      <title>确定特征是连续的还是分类的[关闭]</title>
      <link>https://stackoverflow.com/questions/77641331/determining-if-feature-is-continuous-or-categorical</link>
      <description><![CDATA[我有一个包含 50 个特征和 2000 个样本的数据集。我需要确定每个特征是分类特征还是连续特征。在这两种情况下，特征值都是整数。我有一个列表，其中包含每个功能的唯一值的数量：
[10, 7, 10, 16, 6, 7, 14, 6, 5, 2, 2, 2, 7, 37, 10, 6, 7, 13, 9, 6, 10, 9, 7, 14, 8 , 8, 12, 11, 6, 6, 6, 10, 9, 11, 7, 8, 9, 6, 10, 10, 8, 8, 12, 11, 4, 11, 11, 7, 7, 6 , 2]
确定特征是连续的还是分类的阈值应该是多少？
我发现这个阈值通常是10或15个不同的值，但在这种情况下似乎阈值应该更高（所以只有具有37个不同值的特征是连续的）？]]></description>
      <guid>https://stackoverflow.com/questions/77641331/determining-if-feature-is-continuous-or-categorical</guid>
      <pubDate>Mon, 11 Dec 2023 17:26:03 GMT</pubDate>
    </item>
    <item>
      <title>如何创建实时预测代码？</title>
      <link>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</link>
      <description><![CDATA[我想创建一个实时基本手语翻译器来翻译字母和数字。我使用 CNN 完成了训练，我可以通过将新图像放入文件并运行比较来测试新图像。我如何使其实时？
我尝试了网上建议的一些步骤，但相机似乎没有检测到我的手，而且准确性很糟糕
导入操作系统
将张量流导入为 tf
将 numpy 导入为 np
导入路径库
导入 json

使用 open(“model_arch.json”, “r”) 作为 json_file：
    model_json = json_file.read()

模型 = tf.keras.models.model_from_json(model_json)
model.load_weights(“model_weights.h5”)

data_dir = pathlib.Path(&#39;C:\\Users\\User\\Documents\\FYP\\FYP\\data&#39;)
图像高度 = 180
图像宽度 = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
    数据目录，
    验证分割=0.2，
    子集=“训练”，
    种子=123，
    图像大小=（img_高度，img_宽度），
    批量大小=32
）

类名=train_ds.类名

test_directory = &quot;C:\\Users\\User\\Documents\\FYP\\FYP\\test&quot;;
image_count = len(列表(data_dir.glob(&#39;*/*.jpeg&#39;)))
test_image_paths = [os.path.join(test_directory, f) for f in os.listdir(test_directory) if f.lower().endswith(&#39;.jpeg&#39;)]

如果不是 test_image_paths：
    print(“在指定的测试目录中找不到 JPEG 图像。”)
    出口（）

对于 test_image_paths 中的 test_image_path：
    尝试：
        img = tf.keras.utils.load_img(
            test_image_path, target_size=(img_height, img_width)
        ）
    除了异常 e：
        print(f“加载图像 {test_image_path} 时出错：{e}”)
        继续

    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    预测 = model.predict(img_array)
    分数 = tf.nn.softmax(预测[0])

    预测类别 = 类别名称[np.argmax(分数)]
    置信度 = 100 * np.max(分数)

    打印（
        f“图像最有可能属于具有{置信度：.2f}％置信度的{预测_类}类。”
    ）
]]></description>
      <guid>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</guid>
      <pubDate>Mon, 11 Dec 2023 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>重新排列 LGBMClassifier Predict_proba 输出列</title>
      <link>https://stackoverflow.com/questions/77639975/rearranging-lgbmclassifier-predict-proba-outputs-columns</link>
      <description><![CDATA[我正在训练一个 LGBMClassifier，以便使用其 predict_proba 方法。目标有 3 个类别：a、b 和 c。我想确保模型 predict_proba 按 b、a、c 的顺序输出列的概率。
有没有办法确保 LGBMClassifier predict_proba 的输出具有上述顺序？
导入 pandas 作为 pd
从 lightgbm 导入 LGBMClassifier
将 numpy 导入为 np

＃数据
特征 = [&#39;feat_1&#39;]
目标=&#39;目标&#39;
df = pd.DataFrame({
    &#39;feat_1&#39;：np.random.uniform（大小= 100），
    &#39;目标&#39;:np.random.choice(a=[&#39;b&#39;,&#39;c&#39;,&#39;a&#39;], size=100)
})

＃训练
模型 = LGBMClassifier()
model.fit(df[特征], df[目标])
打印（模型.classes_）

&lt;块引用&gt;
[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]

我尝试过的事情

只需重新排列 .classes_ 属性即可。
model.classes_ = [&#39;b&#39;,&#39;a&#39;,&#39;c&#39;]

&lt;块引用&gt;
AttributeError：无法设置属性“classes_”


根据 .classes_ 属性手动重新排列列。

我知道这是可以做到的，但我不想在每次 predict_proba 调用时都重新排列列顺序。]]></description>
      <guid>https://stackoverflow.com/questions/77639975/rearranging-lgbmclassifier-predict-proba-outputs-columns</guid>
      <pubDate>Mon, 11 Dec 2023 13:35:28 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>MSE 值远大于应有的值 [关闭]</title>
      <link>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</link>
      <description><![CDATA[知道我在这里做错了什么吗：
我的数据集约为 20k 行，mse 约为 11298955095.811989，我不太确定我做错了什么？
我试图找到哪个数据集以及哪个 k 给出最小值，但没有一个值有任何意义：
随机导入
def split_df(数据帧):
    data_rows = dataframe.values.tolist()

    随机播放（数据行）

    训练值 = 0.7
    split_index = int(len(data_rows) * train_val)

    train_data = data_rows[:split_index]
    test_data = data_rows[split_index:]

    train_df = pd.DataFrame(train_data, columns=dataframe.columns)
    test_df = pd.DataFrame(test_data, columns=dataframe.columns)

    返回train_df、test_df

从 sklearn.neighbors 导入 KNeighborsRegressor
从 sklearn.metrics 导入mean_squared_error

数据帧 = [no_nulls、outliers_removed、mean_impulated、median_impulated]
目标 = &#39;中位房屋价值&#39;
k_vals = 范围(1, 30)

对于数据帧中的 df：
    mse_字典 = {}
    X = df.drop(columns=[target]) # 特征
    y = df[target] # 目标变量

    # 将数据分为训练和测试
    train_df, test_df = split_df(df)

    # 训练和测试的单独特征和目标变量
    X_train = train_df.drop(列=[目标])
    y_train = train_df[目标]
    X_test = test_df.drop(列=[目标])
    y_test = test_df[目标]
    
    对于 k_vals 中的 k：
        knn_regressor = KNeighborsRegressor(n_neighbors=k)
        knn_regressor.fit(X_train, y_train)
        预测 = knn_regressor.predict(X_test)
        squared_errors = (预测 - y_test) ** 2 # 计算平方误差
        mse = squared_errors.mean() # 计算平方误差的平均值以获得 MSE
        mse_dictionary[k] = mse

    print(f“数据帧 {df} 的 MSE 字典：{mse_dictionary}”)
    # 用于调试的附加信息
    print(f&quot;最大 MSE: {max(mse_dictionary.values())}&quot;)
    print(f&quot;最小 MSE: {min(mse_dictionary.values())}&quot;)
    print(f&quot;平均 MSE: {sum(mse_dictionary.values()) / len(mse_dictionary)}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</guid>
      <pubDate>Tue, 05 Dec 2023 16:54:01 GMT</pubDate>
    </item>
    <item>
      <title>Vowpal Wabbit：低阶矩阵分解？</title>
      <link>https://stackoverflow.com/questions/39040721/vowpal-wabbit-low-rank-matrix-factorization</link>
      <description><![CDATA[我有一个非常基本的问题。我想做低阶矩阵分解，我正在查看 Vowpal Wabbit有关该主题的文档。我的问题是：
这两种方法之间有区别吗？（实现或其他）

&lt;前&gt;&lt;代码&gt;$ vw --lrq ab5

或
$ vw -q ab --rank 5

这里，a和b是特征命名空间，5是潜在因子维度。

&lt;小时/&gt;

可能的后续行动：
如果这些是等价的，--rank 也适用于高阶交互吗？]]></description>
      <guid>https://stackoverflow.com/questions/39040721/vowpal-wabbit-low-rank-matrix-factorization</guid>
      <pubDate>Fri, 19 Aug 2016 13:49:06 GMT</pubDate>
    </item>
    </channel>
</rss>