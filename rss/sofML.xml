<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 29 Oct 2024 09:18:37 GMT</lastBuildDate>
    <item>
      <title>对整个数据集进行标准化（MinMax）是否会对看不见的时间序列数据产生更好的结果？</title>
      <link>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</link>
      <description><![CDATA[我已经训练了一个模型，用于预测 15 天内价格的最小最大值：1 最大值；0.5 无，0 最小值。问题是 Keras 中的 mse 回归，模型是无状态的：
RNN(PeepholeCell(units=2,activation=&#39;relu&#39;))
TimeDistributed(Dense(1))
Dense(1)
优化器是 Adam。形状：
test_X.shape = (69501, 1, 45); test_y.shape = (11508, 1, 1)
我进行了如下拟合：
history = model.fit(train_X, train_y,
epochs=num_epochs, batch_size=10080, validation_data=(test_X, test_y), verbose=2,
shuffle=False, callbacks=[
earlystopping,
reduce_lr
]
, class_weight=class_weights
)

我对不同的模型配置、学习率策略进行了不同的训练尝试，并使用了 2014 年至 2021 年的每小时汇总数据，并使用了 2019 年至 2021 年的数据进行测试。对于验证，我使用了当前未见的数据（最近 900 天），粒度为 1 天，（最近 900 * 24）粒度为 1 小时。要预测的 y 数据为 0（表示最小相对值），1（表示最大值），否则为 0.5。标签 (y) 具有振荡统计数据，但在不同批次（平均值、标准差、最大值、最小值、QR）中，其幅度随时间相同。除了一些大小反映价格幅度变化的特征外，这些特征还具有恒定范围（例如振荡器）。
我发现，通过回测对未见数据执行的最佳模型是仅将 MinMax 缩放器（scikit）应用于整个数据集的模型。我尝试在训练数据集上安装 RobustScaling 和 MinMax 标准化，并用它来转换测试数据。
我的理解是，仅应用 MinMax 缩放器，而不进行标准化或异常值移除，将保留数据的分布，即使不均匀，NN 也应该能够从中学习。
这样，模型可以专注于学习 x 数据幅度差异的两个阶段，同时不会将信息泄露给 y 变量，因为分布相似且幅度恒定。
为了避免过度拟合，我恰当地将 LSTM 的单位减少到最小值，与更高的单位值相比，该值表现最佳。
你觉得我做错了什么吗？
因此，对整个数据集进行规范化（MinMax）可以在看不见的时间序列数据上产生更好的结果？]]></description>
      <guid>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</guid>
      <pubDate>Tue, 29 Oct 2024 07:40:35 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：'KerasHistory'对象没有属性'layer'</title>
      <link>https://stackoverflow.com/questions/79135894/attributeerror-kerashistory-object-has-no-attribute-layer</link>
      <description><![CDATA[我在使用 Keras 模型时遇到错误“AttributeError：&#39;KerasHistory&#39; 对象没有属性 &#39;layer&#39;”。
我尝试访问层信息，但似乎我引用了错误的对象。我尝试将名称层更改为操作，但没有成功。
我使用的是 TensorFlow v2.17.0。这是代码：
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, MaxPooling2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten, Dense, Dropout

input_shape = (96, 96, 1)

# 输入张量形状
X_input = Input(input_shape)

# 零填充
X = ZeroPadding2D((3,3))(X_input)

# 1 - 阶段
X = Conv2D(64, (7,7), strides= (2,2), name = &#39;conv1&#39;, kernel_initializer= glorot_uniform(seed = 0))(X)
X = BatchNormalization(axis =3, name = &#39;bn_conv1&#39;)(X)
X = Activation(&#39;relu&#39;)(X)
X = MaxPooling2D((3,3), strides= (2,2))(X)

# 2 - 阶段
X = res_block(X, filter= [64,64,256], stage= 2)

# 3 - 阶段
X = res_block(X, filter= [128,128,512], stage= 3)

# 平均池化
X = AveragePooling2D((2,2), name = &#39;Averagea_Pooling&#39;)(X)

# 最终层
X = Flatten()(X)
X = Dense(4096, 激活 = &#39;relu&#39;)(X)
X = Dropout(0.2)(X)
X = Dense(2048, 激活 = &#39;relu&#39;)(X)
X = Dropout(0.1)(X)
X = Dense(30, 激活 = &#39;relu&#39;)(X)

model_1_facialKeyPoints = Model(inputs= X_input, 输出 = X)
model_1_facialKeyPoints.summary()

这是回溯：
AttributeError Traceback (最近一次调用最后一次)
&lt;ipython-input-366-fd266d53d661&gt; 在 &lt;cell line: 34&gt;()
32 
33 
---&gt; 34 model_1_facialKeyPoints = Model( 输入= X_input，输出 = X)
35 model_1_facialKeyPoints.summary()

4 帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/ functional.py in _validate_graph_inputs_and_outputs(self)
692 # 检查 x 是否为输入张量。
693 # pylint：disable=protected-access
--&gt; 694 
695 layer = x._keras_history.layer
696 if len(layer._inbound_nodes) &gt; 1 or (

AttributeError: &#39;KerasHistory&#39; 对象没有属性 &#39;layer&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/79135894/attributeerror-kerashistory-object-has-no-attribute-layer</guid>
      <pubDate>Tue, 29 Oct 2024 05:11:46 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 值错误：按要求创建数组时无法避免复制</title>
      <link>https://stackoverflow.com/questions/79135634/xgboost-value-error-unable-to-avoid-copy-while-creating-an-array-as-requested</link>
      <description><![CDATA[我正在尝试拟合 xgboost 模型，但它给出了一个错误：
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# 假设 y_train 和 y_val 是具有多列的 DataFrames
y_train_single = y_train[&#39;Fraction_Insertions&#39;] # 替换为您的特定目标
y_val_single = y_val[&#39;Fraction_Insertions&#39;] # 替换为您的特定目标

# 创建 DMatrix 对象
train = xgb.DMatrix(X_train, label=y_train_single)
test = xgb.DMatrix(X_val, label=y_val_single)

# 设置参数
params = {
&#39;objective&#39;: &#39;reg:squarederror&#39;,
&#39;eval_metric&#39;: &#39;rmse&#39;,
&#39;eta&#39;: 0.1,
&#39;max_depth&#39;: 3,
&#39;seed&#39;: 42
}

# 训练模型
model = xgb.train(params, train, num_boost_round=100)

# 进行预测
y_pred = model.predict(test)

# 评估
print(&quot;均方误差 (MSE)：&quot;, mean_squared_error(y_val_single, y_pred))
print(&quot;R^2 分数：&quot;, r2_score(y_val_single, y_pred))


{
&quot;name&quot;: &quot;ValueError&quot;,
&quot;message&quot;: &quot;按要求创建数组时无法避免复制。
如果使用 `np.array(obj, copy=False)`，请将其替换为 `np.asarray(obj)`，以便在需要时进行复制（NumPy 1.x 中没有行为变化）。
有关更多详细信息，请参阅 https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-i
]]></description>
      <guid>https://stackoverflow.com/questions/79135634/xgboost-value-error-unable-to-avoid-copy-while-creating-an-array-as-requested</guid>
      <pubDate>Tue, 29 Oct 2024 02:12:22 GMT</pubDate>
    </item>
    <item>
      <title>训练 CNN 模型时的损失和指标问题</title>
      <link>https://stackoverflow.com/questions/79135625/a-loss-and-metrics-problem-while-training-a-cnn-model</link>
      <description><![CDATA[我的自定义损失和指标出现了问题。我的目的是用图像训练一个 CNN 模型，并使用图像中物体的角度方向的切线，我有一列指示切线是正还是负。最后我有两个输出，一个是切线（回归），另一个是（分类）。现在，当我编写 model.evaluate 时，我把回归写为第一个出现的东西，但它并没有作为第一个出现。我不确定它们是否以某种方式被反转了。因为我找不到我得到的奇怪结果的解释。这是我的代码：
# 自定义损失和度量函数
@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)

def angular_loss(y_true, y_pred):
angles_true = tf.math.atan(y_true) * 180.0 / np.pi
angles_pred = tf.math.atan(y_pred) * 180.0 / np.pi
return tf.abs(angles_true - angles_pred)

@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)
def rmse_degrees(y_true, y_pred):
a = tf.constant(np.pi)
angles_true = tf.math.atan(y_true) * 180.0 / a
angles_pred = tf.math.atan(y_pred) * 180.0 / a
b = tf.square(angles_true - angles_pred)
return tf.reduce_mean(b)
# 定义模型
input_image = Input(shape=X_train_images.shape[1:], name=&#39;input_image&#39;)
x = layer.Conv2D(32, (3, 3),activation=&#39;relu&#39;)(input_image)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Conv2D(64, (3, 3),activation=&#39;relu&#39;)(x)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Flatten()(x)
x = layer.Dense(128,activation=&#39;relu&#39;)(x) # 中间密集层
x = layer.Dropout(0.3)(x)

output_regression = layer.Dense(1,activation=&#39;linear&#39;,name=&#39;reg_output&#39;)(x)
output_classification = layer.Dense(1,activation=&#39;sigmoid&#39;,name=&#39;cls_output&#39;)(x)
model = keras.Model(inputs=input_image,outputs=[output_regression,output_classification])
model.summary()
model.save(&quot;modelfinal3.keras&quot;)
# 编译模型

model.compile(
optimizer = RMSprop(learning_rate=0.0001),
loss={
&#39;reg_output&#39;: angular_loss,
&#39;cls_output&#39;:&#39;binary_crossentropy&#39;
},
metrics={
&#39;reg_output&#39;: [rmse_degrees],
&#39;cls_output&#39;: [&#39;accuracy&#39;]
}
)

# 定义 ModelCheckpoint 回调以保存最佳模型
callbacks = [
keras.callbacks.ModelCheckpoint(&quot;modelfinal3.keras&quot;, monitor=&quot;reg_output_loss&quot;, save_best_only=True , mode=&#39;min&#39;),
keras.callbacks.EarlyStopping(monitor=&#39;reg_output_loss&#39; , waiting = 8 ,mode=&#39;min&#39; )
]

# 在没有验证数据的情况下训练模型
history = model.fit(
X_train_images,{&#39;reg_output&#39; : Y1_regression ,&#39;cls_output&#39; : Y2_classification} ,
epochs= 10 ,
batch_size= 64,
回调=回调
)

test_model =keras.models.load_model(&quot;modelfinal3.keras&quot;, custom_objects ={&#39;angular_loss&#39;: angular_loss, &#39;rmse_degrees&#39;: rmse_degrees })
results = test_model.evaluate(X_test_images, {&#39;reg_output&#39; : Y1_regression_test ,&#39;cls_output&#39; : Y2_classification_test },return_dict=True )

print(results)

结果
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6618 - cls_output_loss：9.0815 - 损失：14.4716 - reg_output_loss：5.3914 - reg_output_rmse_degrees：2806.2744
Epoch 7/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 53s 2s/步 - cls_output_accuracy：0.6401 - cls_output_loss：8.9781 - 损失：14.7173 - reg_output_loss：5.7363 - reg_output_rmse_degrees： 2787.8420
时代 8/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6524 - cls_output_loss：9.0007 - 损失：14.5403 - reg_output_loss：5.5401 - reg_output_rmse_degrees：2789.3442
时代 9/10
30/30 ━━━━━━━━━━━━━━━━━━━━━ 51 秒 2 秒/步 - cls_output_accuracy：0.6674 - cls_output_loss：9.4412 - 损失：14.7438 - reg_output_loss：5.3030 - reg_output_rmse_degrees：2844.9971
Epoch 10/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━━ 52 秒 2 秒/步 - cls_output_accuracy：0.6610 - cls_output_loss：9.3189 - 损失：14.7248 - reg_output_loss：5.4059 - reg_output_rmse_degrees：2828.9368
11/11 ━━━━━━━━━━━━━━━━━━━━━━ 2s 142ms/步 - cls_output_accuracy：1.0000 - cls_output_loss：9.4424 - 损失：9.4928 - reg_output_loss：1.1921e-07 - reg_output_rmse_degrees： 2435.0107
{&#39;cls_output_accuracy&#39;: 1.0, &#39;cls_output_loss&#39;: 8.932900428771973, &#39;loss&#39;: 9.235373497009277, &#39;reg_output_loss&#39;: 1.1920930376163597e-07, &#39;reg_output_rmse_degrees&#39;: 2396.7568359375}

进程已完成，退出代码为 0 

我预计 cls 指标的正常值约为 90%，reg 指标的正常值约为 4。]]></description>
      <guid>https://stackoverflow.com/questions/79135625/a-loss-and-metrics-problem-while-training-a-cnn-model</guid>
      <pubDate>Tue, 29 Oct 2024 02:11:19 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：Pandas 数据转换为对象的 numpy dtype。使用 np.asarray(data) 检查输入数据。解决它</title>
      <link>https://stackoverflow.com/questions/79135568/valueerror-pandas-data-cast-to-numpy-dtype-of-object-check-input-data-with-np</link>
      <description><![CDATA[https://colab.research.google.com/drive/1O98QhAdit3D8s61WCSGj35AkKAGkBtu8?usp=sharing
解决无错误代码
测试此部分使用的两个数据集来自加州大学欧文分校机器学习
存储库。您可以下载这些数据集并手动将其加载到您的程序中，也可以使用 ucimlrepo python 包导入它们，可以使用命令 pip install ucimlrepo 安装（每个存储库的网页都有使用 ucimlrepo 直接从 python 中加载数据所需的代码）。
说明：请在单个 Python 文件和 pdf 文件中提供您的代码，并附上您的书面回复。

使用混凝土抗压强度数据集
(https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength)：
(a) (15 分) 使用其他 8 个变量执行线性回归以预测混凝土抗压强度。报告您获得的拟合系数以及 R2 值，并写出您的拟合方程。
(b) (5 分) 报告拟合的 F 统计量的 p 值。F 统计量的零假设可以拒绝吗？
(c) (5 分) 报告每个系数的 p 值，并说明是否可以拒绝零假设。
使用电离层数据集
(https://archive.ics.uci.edu/dataset/52/ionosphere)：
(a) (5 分) 拟合逻辑回归模型，使用其他 34 个变量作为输入预测因子，预测接收到的信号是“好”还是“坏”。
(b) (5 分) 根据拟合的 p 值，是否可以从模型中删除任何属性？提供答案的理由。
(c) (5 分) 使用 k 倍交叉验证优化此数据集上高斯朴素贝叶斯分类器的 var_smoothing 参数。提供图表并说明所选最优值的理由。
(d) (5 分) 使用 k 倍交叉验证优化此数据集上的 KNN 的 k。提供图表并说明所选最优值的理由。
(e) (5 分) 在三个拟合模型中，哪一个最准确？请务必为您的答案提供理由。
]]></description>
      <guid>https://stackoverflow.com/questions/79135568/valueerror-pandas-data-cast-to-numpy-dtype-of-object-check-input-data-with-np</guid>
      <pubDate>Tue, 29 Oct 2024 01:50:29 GMT</pubDate>
    </item>
    <item>
      <title>评估模型预测性能时，mase() 错误无法索引数据以外的行</title>
      <link>https://stackoverflow.com/questions/79134999/error-with-mase-cant-indexes-rows-beyond-data-when-evaluating-model-forecasti</link>
      <description><![CDATA[我正在预测时间序列结果 Y，其预测因子滞后 t-12 天，以产生 12 天前的预测，样本外验证框架为 10 个不重叠的折叠。我想使用平均缩放误差作为性能指标。根据我对这篇文章的理解，我将朴素预测的时间步长设置为 12，以便朴素预测和我的模型预测在同一时间间隔。我理解这会将我的模型预测（使用滞后值预测）与 12 天前的 y 值进行比较。由于某种原因，mase() 函数似乎无法以 12 天的步长循环遍历数据，因为它会返回一条错误消息，指出它必须索引“负值行”，这是不可能的。我使用 yardstick 包 mase 函数 时也遇到了同样的情况。有谁知道如何修复该问题，或者可以指出我做错了什么吗？
查看带有模拟数据的示例
#load libraries#

library(tidiverse)

library(Metrics)

#create simulation data

set.seed(123)
y&lt;-sample(1:150,662,replace = T)
X1_L12&lt;-runif(662,-1,1)#假设 X1 滞后 12 天
X2_L12&lt;-runif(662,-1:1)#假设 X2 滞后 12 天
date&lt;-sample(1:662)

dat&lt;-data.frame(date,y,X1_L12,X2_L12)

#create the function to compute mase setting the naive prediction at t-12

mase_lag16 &lt;- function(data, lev = NULL, model = NULL) {
data$pred &lt;- as.numeric(data$pred)
data$obs &lt;- as.numeric(data$obs)
masefunction = mase(data$obs,data$pred,12)
names(masefunction) &lt;- c(&#39;MASE&#39;)
masefunction
}

#OOS 验证框架
#创建时间片并定义性能指标
myTimeControlmase &lt;- trainControl(method = &quot;timeslice&quot;,
initialWindow = 53,
horizo​​n = 13,
skip=65,
fixedWindow = TRUE,
summaryFunction = mase_lag12)

#model
glmnetmod_lag16 = train(y~X1_L12+X2_L12,
method = &quot;glmnet&quot;,
family=&quot;poisson&quot;,
trControl = myTimeControlmase,maximize=FALSE,
preProc = c(&quot;range&quot;),
data=dat)

在代码的最后一部分拟合模型时，它会返回以下错误消息：
actual[1:naive_end] 中的错误：只有 0 可以与负下标混合
]]></description>
      <guid>https://stackoverflow.com/questions/79134999/error-with-mase-cant-indexes-rows-beyond-data-when-evaluating-model-forecasti</guid>
      <pubDate>Mon, 28 Oct 2024 20:20:47 GMT</pubDate>
    </item>
    <item>
      <title>快速 AI 暹罗模型没有改进</title>
      <link>https://stackoverflow.com/questions/79134990/fast-ai-siamese-model-not-improving</link>
      <description><![CDATA[所以我按照这个教程：Fast Ai Siamese，然而在我完成它之后，我的准确率只有 50%。我尝试了很多方法，但都没有奏效。所以我认为问题可能出在 Siamese 实现本身，但我对 fast.ai 经验很少，也不知道如何修复它，甚至不知道从哪里开始。也许我遗漏了一些明显的东西？无论如何，任何评论都有帮助。这是我的代码
class SiameseImage(fastuple):

def show(self, ctx=None, **kwargs):
if len(self) &gt; 2：
img1，img2，相似度 = 自身
其他：
img1，img2 = 自身
相似度 = &#39;未确定&#39;

如果不是 isinstance(img1，Tensor)：
如果 img2.size != img1.size： img2 = img2.resize(img1.size)
t1 = 张量(img1)
t2 = 张量(img2)
t1 = t1.permute(2,0,1)
t2 = t2.permute(2,0,1)
其他：
t1 = img1
t2 = img2

line = t1.new_zeros(t1.shape[0]，t1.shape[1]，10)
返回 show_image(torch.cat([t1，line，t2]，dim=2)，title = 相似度，ctx=ctx， **kwargs) 

class ImageTuple(fastuple):

@classmethod
def create(cls, fns): return cls(tuple(PILImage.create(f) for f in fns))

def show(self, ctx=None, **kwargs): 
t1,t2 = self
if not isinstance(t1, Tensor) or not isinstance(t2, Tensor) or t1.shape != t2.shape: return ctx
line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)
return show_image(torch.cat([t1,line,t2], dim=2), ctx=ctx, **kwargs)

class SiameseModel(Module):

def __init__(self,coder, head):
self.encoder =coder
self.head = head

def forward(self, x1, x2):
ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim = 1)
return self.head(ftrs)

class SiameseTransform(Transform):

def __init__(self, files, splits, labels):
self.labels = labels
self.splbl2files = [{l: [f for f in files[splits[i]] if parent_label(f) == l] for l in labels}
for i in range(2)]
self.valid = {f: self._draw(f,1) for f in files[splits[1]]}

def encodes(self, f):
f2,same = self.valid.get(f, self._draw(f,0))
img1,img2 = PILImage.create(f),PILImage.create(f2)
return SiameseImage(img1, img2, int(same))

def _draw(self, f, split=0):
same = random.random() &lt; 0.5
cls = parent_label(f)
如果不相同：cls = random.choice(L(l for l in self.labels if l != cls)) 
返回 random.choice(self.splbl2files[split][cls])，相同

def get_x(t): 返回 t[:2]
def get_y(t): 返回 t[2]

def siamese_splitter(model):
返回 [params(model.encoder), params(model.head)]

def loss_func(out, targ):
返回 CrossEntropyLossFlat()(out, targ.long())

def train(dataset_path):
files = get_image_files(dataset_path)

labels = list(set(files.map(parent_label)))

coder = create_body(resnet50(), cut=-2)
head = create_head(2048*2, 2, ps=0.5)
model = SiameseModel(编码器，head)

splits = RandomSplitter()(文件)
tfm = SiameseTransform(文件，splits，标签)
tls = TfmdLists(文件，tfm，splits=splits)
dls = tls.dataloaders(
after_item=[Resize(256, method=&#39;squash&#39;), ToTensor], 
after_batch=[IntToFloatTensor, *aug_transforms(flip_vert=True, do_flip=True, max_rotate=50, max_warp=0.4, max_zoom=1.3), Normalize.from_stats(*imagenet_stats)],
bs = 8
)

torch.cuda.empty_cache()
learn = Learner(dls， model, loss_func=loss_func, splitter=siamese_splitter, metrics=accuracy)
learn.fine_tune(
epochs = 15,
base_lr=2.51e-5,
cbs=[SaveModelCallback(monitor=&#39;valid_loss&#39;), EarlyStoppingCallback(monitor=&#39;valid_loss&#39;, waiting=5)])
learn.export(&#39;siamese1.pkl&#39;)

我尝试更改批量大小、不同的架构、图像大小、epoch、各种批量转换和其他内容，但没有任何变化，我的准确率始终为 50%...]]></description>
      <guid>https://stackoverflow.com/questions/79134990/fast-ai-siamese-model-not-improving</guid>
      <pubDate>Mon, 28 Oct 2024 20:17:44 GMT</pubDate>
    </item>
    <item>
      <title>如何通过递归特征消除来选择最佳的特征数量和具有最高F1和ROC的最佳算法？</title>
      <link>https://stackoverflow.com/questions/79134937/how-to-select-the-best-number-of-feature-and-best-algorithm-with-highest-f1-and</link>
      <description><![CDATA[我想对我的数据的多个子集（即每个子集针对每个特定客户）运行递归特征消除，其中有 X 个特征（即 4-12）和 Y 个不同算法（即 DecisionTreeClassifier、GradientBoostingClassifier、LogisticRegression）。
如何创建一个代码，在每个子集上生成并显示具有最佳算法的最佳特征数量（最高精确度-召回率，其次是最高 ROC），而不是逐一查看结果？我的数据集不平衡。
下面是我尝试在逻辑回归中为不同数量的特征生成结果，但我仍然需要替换估算器中的算法并逐一检查结果。
for i in range(4, 13):
rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)
rfe.fit(X_resampled,Y_resampled)
selector = X_resampled.columns[rfe.support_]
X_train_selected = X_resampled[selector]
X_test_selected = X_test[selector]
log_reg_model = sm.Logit(Y_resampled, X_train_selected).fit()
pred_test = log_reg_model.predict(X_test_selected)
pred_test_1 = np.where(pred_test&gt;0.5,1,0)
logit_roc_auc = roc_auc_score(Y_test, pred_test)
fpr, tpr, 阈值 = roc_curve(Y_test, pred_test)
print(f&#39;特征数量：{i}，准确率得分：{accuracy_score(Y_test, pred_test_1)}&#39;)
print(f&#39;特征数量：{i}，ROC：&#39;，logit_roc_auc)
precision, recall, 阈值 = precision_recall_curve(Y_test, pred_test)
print(f&#39;特征数量：{i}，f1 得分：{f1_score(Y_test, pred_test_1)}&#39;)
print(f&#39;特征数量：{i}，PRC AUC：{auc(recall,precision)}&#39;)
precision = precision_score(Y_test, pred_test_1)
recall = recall_score(Y_test, pred_test_1)
print(f&#39;特征数量：{i},召回率：&#39;, recall)
print(f&#39;特征数量：{i},精确度：&#39;, precision)
]]></description>
      <guid>https://stackoverflow.com/questions/79134937/how-to-select-the-best-number-of-feature-and-best-algorithm-with-highest-f1-and</guid>
      <pubDate>Mon, 28 Oct 2024 19:57:20 GMT</pubDate>
    </item>
    <item>
      <title>性能权衡 - 降低速度以更好地利用 TTS 中的内存[关闭]</title>
      <link>https://stackoverflow.com/questions/79134305/performance-trade-off-reduce-speed-for-better-memory-usage-in-tts</link>
      <description><![CDATA[我正在使用 https://github.com/coqui-ai/tts/ 运行多个 TTS 模型。目前，我正在试验 your_tts 模型，这是一个较小的模型。我有 4 GB 内存的 GPU（GTX 1050），支持 Cuda。一段时间内，它运行没有问题，而且速度非常快。过了一会儿，它抛出了内存错误。我想知道是否有办法降低速度并减少内存使用？通过 config.json 或类似的东西，也许在代码中通过一些参数？]]></description>
      <guid>https://stackoverflow.com/questions/79134305/performance-trade-off-reduce-speed-for-better-memory-usage-in-tts</guid>
      <pubDate>Mon, 28 Oct 2024 16:30:39 GMT</pubDate>
    </item>
    <item>
      <title>模型（输入，训练=True）和模型（输入，训练=False）之间的巨大差异[关闭]</title>
      <link>https://stackoverflow.com/questions/79134261/huge-difference-between-modelinput-training-true-and-modelinput-training-fa</link>
      <description><![CDATA[我被要求根据我读过的一篇文章实现一个机器学习模型。为此，该论文推荐了一种特定类型的预测可靠性度量：该模型运行 M 次随机前向传递，其中有 M 种不同的 dropout 模式（其中 alpha=0.5%）。但是，我注意到，模型（输入，训练=True）的 M 次随机运行的平均输出与模型（输入，训练=False）的 M 次随机运行的平均输出有很大不同。这是由于什么原因？如果不使用 droput 模式，运行不应该收敛到相似的值吗？]]></description>
      <guid>https://stackoverflow.com/questions/79134261/huge-difference-between-modelinput-training-true-and-modelinput-training-fa</guid>
      <pubDate>Mon, 28 Oct 2024 16:16:55 GMT</pubDate>
    </item>
    <item>
      <title>删除所有人口后，NEAT 给出错误</title>
      <link>https://stackoverflow.com/questions/79130999/neat-giving-error-after-deleting-all-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130999/neat-giving-error-after-deleting-all-the-population</guid>
      <pubDate>Sun, 27 Oct 2024 16:27:23 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 真的需要可学习的自注意力层吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79120787/do-the-transformers-really-need-the-learnable-self-attention-layer</link>
      <description><![CDATA[Transformer 的核心组件是自注意力机制，它负责通过计算注意力分数来捕获 token 之间的依赖关系。这些分数通常通过可学习的投影（查询、键、值）计算得出。
我想知道自注意力层是否需要可学习。是否可以用更简单或不可学习的东西（例如固定或动态生成的表示）替换可学习的查询、键和值投影？这是否仍允许模型捕获足够的上下文信息以用于语言建模等任务？
我尝试删除所有可学习的投影（查询、键、值）并直接将点积应用于 token 本身。但是，我正在寻找一种替代方案，其中可以在不使用可学习参数的情况下将 token 投影到更有意义的维度。有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79120787/do-the-transformers-really-need-the-learnable-self-attention-layer</guid>
      <pubDate>Thu, 24 Oct 2024 07:21:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在 p5.js 中更改 bodySegmentation-mask-body-parts 的默认背景？</title>
      <link>https://stackoverflow.com/questions/79110858/how-to-change-the-default-background-of-bodysegmentation-mask-body-parts-in-p5-j</link>
      <description><![CDATA[我试图更改检测到的身体部位背后的背景，但无法使其工作。即使我修改了 background(...) 函数，它仍然默认为白色。有人能解释为什么会发生这种情况吗？
这是我正在处理的文件的链接：
https://editor.p5js.org/speedyonion/sketches/X9mwX9XB9
let bodySegmentation;
let video;
let fragmentation;

let options = {
maskType: &quot;parts&quot;,
};

function preload() {
bodySegmentation = ml5.bodySegmentation(&quot;BodyPix&quot;, options);
}

function setup() {
createCanvas(640, 480);
// 创建视频
video = createCapture(VIDEO);
video.size(640, 480);
video.hide();

bodySegmentation.detectStart(video, gotResults);
}

function draw() {
background(0,0,0);
image(video, 0, 0);
if (segmentation) {
image(segmentation.mask, 0, 0, width, height);
}
}

// 身体分割回调函数
function gotResults(result) {
fragmentation = result;
}
]]></description>
      <guid>https://stackoverflow.com/questions/79110858/how-to-change-the-default-background-of-bodysegmentation-mask-body-parts-in-p5-j</guid>
      <pubDate>Mon, 21 Oct 2024 16:01:40 GMT</pubDate>
    </item>
    <item>
      <title>sklearn：获取点到最近聚类的距离</title>
      <link>https://stackoverflow.com/questions/44041347/sklearn-get-distance-from-point-to-nearest-cluster</link>
      <description><![CDATA[我正在使用 DBSCAN 之类的聚类算法。
它返回一个名为 -1 的“聚类”，这些点不属于任何聚类。对于这些点，我想确定它与最近聚类之间的距离，以获得类似于该点异常程度的指标。这可能吗？或者这种指标还有其他选择吗？]]></description>
      <guid>https://stackoverflow.com/questions/44041347/sklearn-get-distance-from-point-to-nearest-cluster</guid>
      <pubDate>Thu, 18 May 2017 07:31:36 GMT</pubDate>
    </item>
    <item>
      <title>免费提供的真实公共数据[关闭]</title>
      <link>https://stackoverflow.com/questions/24962111/freely-available-real-public-data</link>
      <description><![CDATA[注意：我不是在寻找样本数据。
不同域中向公众免费公开的真实数据集：
例如：

FCM 的财务报告。
http://www.cftc.gov/MarketReports/FinancialDataforFCMs/HistoricalFCMReports/index.htm
YouTube 数据：（频道的受欢迎程度指标和统计数据）
https://developers.google.com/youtube/analytics/

如果有更多此类数据，请分享。 
可能与以下内容或其他任何可能有用的内容相关。
可能涉及医疗领域、药房、药品消费。
不同城市、道路等的交通、事故、伤亡。
不同地区的妇女安全指标。
食品/饮料消费、价格。
根据地区/公寓的垃圾收集量、洗手间。
有多少孤儿院以及他们获得了多少资助。
一个城市有多少个残疾人停车位等。
如果您认为这个问题不适合这种类型的平台，我将非常感激您为我推荐一个更好的论坛。]]></description>
      <guid>https://stackoverflow.com/questions/24962111/freely-available-real-public-data</guid>
      <pubDate>Fri, 25 Jul 2014 18:18:32 GMT</pubDate>
    </item>
    </channel>
</rss>