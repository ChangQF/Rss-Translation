<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 04 Aug 2024 18:18:59 GMT</lastBuildDate>
    <item>
      <title>将 OneHotencoder 传来的稀疏矩阵转换为数组，然后转换为 DataFrame</title>
      <link>https://stackoverflow.com/questions/78831669/covert-a-sparse-matrix-arrived-from-onehotencoder-into-an-array-and-then-into-a</link>
      <description><![CDATA[我在将 OneHotencoder 传来的稀疏矩阵转换为数组，然后再转换为 DataFrame 的过程中遇到了错误
即 ValueError：必须传递 2-D 输入。shape=()
实际上，它之前运行良好。但在重新启动内核后重新运行 shell 后遇到了这个问题。
对于以下代码：-
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(handle_unknown=&#39;ignore&#39;)
temp = ohe.fit_transform(df[[&#39;encoded_data&#39;]])
temp

temp = pd.DataFrame(np.array(temp))
temp
]]></description>
      <guid>https://stackoverflow.com/questions/78831669/covert-a-sparse-matrix-arrived-from-onehotencoder-into-an-array-and-then-into-a</guid>
      <pubDate>Sun, 04 Aug 2024 17:09:05 GMT</pubDate>
    </item>
    <item>
      <title>python-error-the-truth-value-of-a-dataframe-is-ambiguous - 无法解析</title>
      <link>https://stackoverflow.com/questions/78831608/python-error-the-truth-value-of-a-dataframe-is-ambiguous-not-able-to-resolve</link>
      <description><![CDATA[我是这些 ML 库的新手，无法使用以下代码解决错误：
main.html 不会返回推荐的产品，并在数据框上抛出此错误。
def content_based_recommendations(train_data, item_name, top_n=10):
if item_name not in train_data[&#39;Name&#39;].values:
print(f&quot;在训练数据中未找到项目 &#39;{item_name}&#39;。&quot;)
return pd.DataFrame()

tfidf_vectorizer = TfidfVectorizer(stop_words=&#39;english&#39;)
tfidf_matrix_content = tfidf_vectorizer.fit_transform(train_data[&#39;Tags&#39;])
cosine_similarities_content = cosine_similarity(tfidf_matrix_content, tfidf_matrix_content)
item_index = train_data[train_data[&#39;名称&#39;] == item_name].index[0]
similar_items = list(enumerate(cosine_similarities_content[item_index]))
similar_items = sorted(similar_items, key=lambda x: x[1], reverse=True)
top_similar_items = similar_items[1:top_n+1]
Recommended_item_indices = [x[0] for x in top_similar_items]
Recommended_items_details = train_data.iloc[recommended_item_indices][[&#39;名称&#39;, &#39;评论数&#39;, &#39;品牌&#39;, &#39;图片网址&#39;, &#39;评分&#39;]]
return Recommended_items_details

@app.route(&quot;/recommendations&quot;, methods=[&#39;POST&#39;])
def suggestions():
尝试：
prod = request.form.get(&#39;prod&#39;)
nbr = request.form.get(&#39;nbr&#39;)

如果不是 prod 或不是 nbr：
返回 render_template(&#39;main.html&#39;, message=&quot;缺少产品名称或推荐数量。&quot;)

尝试：
nbr = int(nbr)
除外 ValueError：
返回 render_template(&#39;main.html&#39;, message=&quot;无效的推荐数量。&quot;)

df = pd.read_csv(&#39;clean_data.csv&#39;)
print(df.to_string())
content_based_rec = content_based_recommendations(train_data, prod, top_n=nbr)

如果 content_based_rec.empty：
返回 render_template(&#39;main.html&#39;, message=&quot;此产品无可用推荐。&quot;)
其他：
random_product_image_urls = [random.choice(random_image_urls) for _ in range(len(content_based_rec))]
price = [40, 50, 60, 70, 100, 122, 106, 50, 30, 50]
return render_template(&#39;main.html&#39;, content_based_rec=content_based_rec, truncate=truncate,
random_product_image_urls=random_product_image_urls,
random_price=random.choice(price))

except Exception as e:
return render_template(&#39;main.html&#39;, message=f&quot;An error occurred: {str(e)}&quot;)


请提供任何可能的解决方案以解决此问题。
谢谢
我期待模板上显示的类似项目列表。`]]></description>
      <guid>https://stackoverflow.com/questions/78831608/python-error-the-truth-value-of-a-dataframe-is-ambiguous-not-able-to-resolve</guid>
      <pubDate>Sun, 04 Aug 2024 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>有人可以解释一下如何计算梯度吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78831458/can-someone-explain-how-to-go-about-calculating-gradients</link>
      <description><![CDATA[我正在学习 CS231n 2017 并完成 cs231n 2024 的 HW 作业。在每一道题中，特别是 SVM 和 Softmax，我可以轻松计算损失，但总是发现很难计算相对于 W 或 X 的梯度。我想我遗漏了一些东西，但我不确定。我希望有人能一步一步地指导我完成这些步骤。我非常绝望 :(
PS：我懂矩阵、微积分等。
在之前的问题中，我尝试对损失函数求导，然后在代码中实现它。但是，对于 softmax 和 svm，我似乎在实现它时遇到了困难。我希望有人可以指导我完成如何做到这一点的数学步骤。]]></description>
      <guid>https://stackoverflow.com/questions/78831458/can-someone-explain-how-to-go-about-calculating-gradients</guid>
      <pubDate>Sun, 04 Aug 2024 15:33:03 GMT</pubDate>
    </item>
    <item>
      <title>Ultralytics YOLOv8 姿势估计在自定义数据集上绘制边/颜色时不尊重顶点顺序</title>
      <link>https://stackoverflow.com/questions/78831319/ultralytics-yolov8-pose-estimation-not-respecting-vertices-order-when-drawing-ed</link>
      <description><![CDATA[我按照官方文档，使用 Python 中的 ultralytics 在自定义数据集上进行人体姿势估计训练。我有一个由我标记的 1 幅图像组成的小型数据集，预测工作正常，因此顶点识别和类别识别工作正常。
问题是程序绘制顶点的方式，包括边缘和颜色，与我的骨架不匹配。YOLO 训练中的鼻子被画在我的脚踝上。预测实际上工作正常，但它非常丑陋，因为它绘制了不应该存在的边缘（例如将膝盖顶点与肩部顶点连接起来）。此外，我的姿势估计对象与人类非常相似，因此我认为如果我有相同的骨架，训练会更快。
我已经做过和尝试过的事情：

密切关注官方文档中的标签，0 代表鼻子，1 代表左耳，依此类推。
尝试另一种标签，看看文档是否过时。这会导致 txt 中 train 和 val 的坐标顺序发生变化，因此我认为它会改变输出的颜色和边缘。它什么都不做，这对我来说很奇怪。
读取标准数据集 yaml 选项，例如 super-gradients on coco 中的选项，并复制“edge_links”、“edge_colors”和“keypoint_colors”选项。这样，即使我的顺序不同，它也应该解析这些选项并正确绘制它们。它也没有做任何事情，在我看来，我误解了 yaml 的编写方式。但我不知道是什么。
重要提示，我没有使用任何自动数据集创建工具，而是手动创建所有这些文件。由于图像版权原因，我无法使用 Roboflow，因此我使用本地注释器。我检查了在 Roboflow 中创建的数据集（来自 ultralytics 的 tiger 示例）以查看差异，但我没有看到它们，它们甚至没有定义这些东西，但结果只显示顶点，没有任何边缘。这对我来说也很奇怪。
我正在使用当前版本的 ultralytics，几天前刚刚安装了 pip。

我拥有的代码（由文档提取）是这样的。我的 yaml 是“checa.yaml”。
yaml_of_model=“yolov8n-pose.yaml”
model_to_load =“best.pt”
# 加载模型
model = YOLO(yaml_of_model) # 从 YAML 构建新模型
model = YOLO(model_to_load) # 加载预训练模型（建议用于训练）
model = YOLO(yaml_of_model).load(model_to_load) # 从 YAML 构建并传输权重
results = model.train(data=&quot;./checa.yaml&quot;, epochs=4, imgsz=1920)
results = model(&#39;./screenshot_1.jpg&#39;)

for result in results:
result.show()

我的 yaml 摘录：
# 数据集根目录
path: ...

# 训练和验证目录
train: ...
val: ...

# 关键点和维度的数量（x,y 为 2，x,y,visible 为 3）
kpt_shape: [17, 3]
flip_indexes: [ 0, 2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15,]

edge_links:
- [0, 1]
- ...

edge_colors:
- [214, 39, 40] # Nose -&gt; LeftEye
- ...

keypoint_colors:
- [148, 103, 189]
- ...

# Classes 字典
names:
0: FirstClass
1: ...
]]></description>
      <guid>https://stackoverflow.com/questions/78831319/ultralytics-yolov8-pose-estimation-not-respecting-vertices-order-when-drawing-ed</guid>
      <pubDate>Sun, 04 Aug 2024 14:26:27 GMT</pubDate>
    </item>
    <item>
      <title>模型生成 512x512 的照片</title>
      <link>https://stackoverflow.com/questions/78831225/model-to-generated-512x512-photos</link>
      <description><![CDATA[我怎样才能让这个模型生成 512x512 像素或更大的图像？现在它生成 64x64px 图像。我尝试更改模型中的某些值，但没有成功。请问有人能解释一下这些卷积层是如何工作的，特别是 Conv2D 和 Conv2DTranspose，因为我不明白图像在这些层中是如何调整大小的。
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layer
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt

cd /content/drive/MyDrive

dataset = keras.preprocessing.image_dataset_from_directory(
directory = &#39;Humans&#39;, label_mode = None, image_size = (64,64), batch_size = 32,
shuffle = True
).map(lambda x: x/255.0)

discriminator = keras.models.Sequential(
[
keras.Input(shape = (64,64,3)),
layer.Conv2D(64, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layer.LeakyReLU(0.2),
layer.Conv2D(128, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layer.LeakyReLU(0.2),
layer.Conv2D(128, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layer.LeakyReLU(0.2),
layer.Flatten(),
layer.Dropout(0.2),
layer.Dense(1,activation = &#39;sigmoid&#39;)
]
)

latent_dim = 128
generator = keras.models.Sequential(
[
图层。输入（形状 = (latent_dim,)），
图层。密集（8*8*128），
图层。重塑（（8,8,128）），
图层。Conv2DTranspose（128，kernel_size = 4，步幅 = 2，填充 = &#39;相同&#39;），
图层。LeakyReLU（0.2），
图层。Conv2DTranspose（256，kernel_size = 4，步幅 = 2，填充 = &#39;相同&#39;），
图层。LeakyReLU（0.2），
图层。Conv2DTranspose（512，kernel_size = 4，步幅 = 2，填充 = &#39;相同&#39;），
图层。LeakyReLU（0.2），
图层。Conv2D（3，kernel_size = 5，填充 = &#39;相同&#39;，激活 = &#39;sigmoid&#39;）
]
)

opt_gen = keras.optimizers.Adam(1e-4)
opt_disc = keras.optimizers.Adam(1e-4)
loss_fn = keras.losses.BinaryCrossentropy()

对于 epoch in range(500):
对于 idx, real in enumerate(tqdm(dataset)):
batch_size = real.shape[0]
random_latent_vectors = tf.random.normal(shape = (batch_size,latent_dim))
fake = generator(random_latent_vectors)

如果 idx % 50 == 0:
img = keras.preprocessing.image.array_to_img(fake[0])
img.save(f&#39;gen_images/generated_img{epoch}_{idx}_.png&#39;)

使用 tf.GradientTape() 作为disc_tape:
loss_disc_real = loss_fn(tf.ones((batch_size,1)), discriminator(real))
loss_disc_fake = loss_fn(tf.zeros(batch_size,1), discriminator(fake))
loss_disc = (loss_disc_real+loss_disc_fake)/2

grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)

opt_disc.apply_gradients(
zip(grads, discriminator.trainable_weights)
)

使用 tf.GradientTape() 作为 gen_tape:
fake = generator(random_latent_vectors)
output = discriminator(fake)
loss_gen = loss_fn(tf.ones(batch_size,1),output)

grads = gen_tape.gradient(loss_gen, generator.trainable_weights)
opt_gen.apply_gradients(
zip(grads, generator.trainable_weights)
)

我尝试更改图像大小和卷积层中的某些值，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/78831225/model-to-generated-512x512-photos</guid>
      <pubDate>Sun, 04 Aug 2024 13:42:23 GMT</pubDate>
    </item>
    <item>
      <title>检测并定位图像中大量不同的物体</title>
      <link>https://stackoverflow.com/questions/78830813/detect-and-localize-a-large-number-of-different-objects-in-an-image</link>
      <description><![CDATA[我有多个 Match 3 游戏的图片，例如 Candy Crush。下面给出了一个示例图片。我想检测和定位图片中所有不同颜色的物体。定位的意思是获取图片中每个物体的精确坐标。我尝试过不同的方法，例如边缘检测技术、轮廓和其他一些方法，但到目前为止效果并不理想。无法使用模板匹配，因为图像大小不同。我正在考虑切换到 ML 技术，特别是 CNN，但为此我必须创建一个庞大的数据集，而且不确定这是否可行。那么有没有可以解决上述问题的计算机视觉方法呢？
]]></description>
      <guid>https://stackoverflow.com/questions/78830813/detect-and-localize-a-large-number-of-different-objects-in-an-image</guid>
      <pubDate>Sun, 04 Aug 2024 10:33:33 GMT</pubDate>
    </item>
    <item>
      <title>Pandas 高效地获取每个数据框组中具有多个 n 值的前 n 行[重复]</title>
      <link>https://stackoverflow.com/questions/78830630/pandas-efficiently-get-top-n-rows-in-each-dataframe-group-with-multiple-values-o</link>
      <description><![CDATA[对于这种用例来说，Groupby-apply 太慢了。从类似这样的数据框开始
df = pd.DataFrame(
[
{&#39;name&#39;: &#39;a&#39;, &#39;id&#39;: 0, &#39;category&#39;: &#39;1&#39;},
{&#39;name&#39;: &#39;b&#39;, &#39;id&#39;: 1, &#39;category&#39;: &#39;1&#39;},
{&#39;name&#39;: &#39;c&#39;, &#39;id&#39;: 2, &#39;category&#39;: &#39;1&#39;},
{&#39;name&#39;: &#39;d&#39;, &#39;id&#39;: 3, &#39;category&#39;: &#39;1&#39;},
{&#39;name&#39;: &#39;e&#39;, &#39;id&#39;: 4, &#39;category&#39;: &#39;2&#39;},
{&#39;name&#39;: &#39;f&#39;, &#39;id&#39;: 5, &#39;category&#39;: &#39;2&#39;},
{&#39;name&#39;: &#39;g&#39;, &#39;id&#39;: 6, &#39;category&#39;: &#39;2&#39;},
{&#39;name&#39;: &#39;h&#39;, &#39;id&#39;: 7, &#39;category&#39;: &#39;3&#39;},
{&#39;name&#39;: &#39;i&#39;, &#39;id&#39;: 8, &#39;category&#39;: &#39;3&#39;},
{&#39;name&#39;: &#39;j&#39;, &#39;id&#39;: 9, &#39;category&#39;: &#39;3&#39;},
]
)

或
 name id category
0 a 0 1
1 b 1 1
2 c 2 1
3 d 3 1
4 e 4 2
5 f 5 2
6 g 6 2
7 h 7 3
8 i 8 3
9 j 9 3

我想提取每个类别的前 n 行，每个类别的 n 值不同。如果 n 对于所有类别都相同，那么这个问题的解决方案将会非常快速：
df_head = df.groupby(by=[&#39;category&#39;], as_index=False, sort=False).head(2)

给出
 name id category
0 a 0 1
1 b 1 1
4 e 4 2
5 f 5 2
7 h 7 3
8 i 8 3

但如果我想要不同的 n，我只能使用类似 这个
num_grabs = {&#39;1&#39;: 3, &#39;2&#39;: 1, &#39;3&#39;: 2}
df_apply = df.groupby(
by=[&#39;category&#39;],
as_index=False,
sort=False
).apply(
lambda x: x.head(num_grabs[x.loc[x.index[0], &#39;category&#39;]])
).reset_index(drop=True)

正确给出
 name id category
0 a 0 1
1 b 1 1
2 c 2 1
3 e 4 2
4 h 7 3
5 i 8 3

但是，即使是中等大小的数据，这也非常慢。有没有更有效的方法来解决多n问题？]]></description>
      <guid>https://stackoverflow.com/questions/78830630/pandas-efficiently-get-top-n-rows-in-each-dataframe-group-with-multiple-values-o</guid>
      <pubDate>Sun, 04 Aug 2024 08:48:58 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 不兼容的形状：计算 MSE 时 [64] 与 [64,8,8,3]</title>
      <link>https://stackoverflow.com/questions/78830210/tensorflow-incompatible-shapes-64-vs-64-8-8-3-when-calculating-mse</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78830210/tensorflow-incompatible-shapes-64-vs-64-8-8-3-when-calculating-mse</guid>
      <pubDate>Sun, 04 Aug 2024 03:36:33 GMT</pubDate>
    </item>
    <item>
      <title>如何将风格化效果应用于视频？</title>
      <link>https://stackoverflow.com/questions/78830209/how-can-i-apply-a-stylized-effect-to-a-video</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78830209/how-can-i-apply-a-stylized-effect-to-a-video</guid>
      <pubDate>Sun, 04 Aug 2024 03:36:28 GMT</pubDate>
    </item>
    <item>
      <title>加载 Keras 模型时，“密集层”需要 1 个输入，但它收到了 2 个输入张量”</title>
      <link>https://stackoverflow.com/questions/78829665/layer-dense-expects-1-inputs-but-it-received-2-input-tensors-when-loading</link>
      <description><![CDATA[我正在使用 Kaggle 开发乳腺癌组织病理学图像的分类模型。该数据集包含 157,572 张图像（78,786 张 IDC 阴性和 78,786 张 IDC 阳性），每张图像的尺寸为 50x50 像素。
我使用 ResNet50 作为基础模型，并尝试保存并稍后加载经过训练的模型的最高效版本。但是，当我尝试加载已保存的模型时，我遇到了以下错误：
# 加载模型
model = load_model(&#39;/kaggle/working/resnet50_model.keras&#39;)
“密集”层需要 1 个输入，但它收到了 2 个输入张量。收到的输入：[&lt;KerasTensor shape=(None, 2, 2, 2048), dtype=float32, sparse=False, name=keras_tensor_566&gt;, &lt;KerasTensor shape=(None, 2, 2, 2048), dtype=float32, sparse=False, name=keras_tensor_567&gt;]

这是我的代码：
import tensorflow as tf
from tensorflow.keras import layer, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import load_model

# 数据增强管道
data_augmentation = tf.keras.Sequential([
layer.RandomFlip(&quot;horizo​​ntal_and_vertical&quot;),
layer.RandomRotation(0.5),
layer.RandomContrast(0.2),
layer.RandomBrightness(0.2),
layer.GaussianNoise(0.1)
])

# 预处理函数以规范化图像
def preprocess(image, label):
image = tf.image.resize(image, (50, 50))
image = tf.cast(image, tf.float32) / 255.0
return image, label

# 使用验证分割加载数据集
train_dir = &#39;path/to/data&#39;
batch_size = 64
img_height = 50
img_width = 50
validation_split = 0.2
test_split_ratio = 0.5

# 加载数据集
data_train = tf.keras.utils.image_dataset_from_directory(
train_dir,
validation_split=validation_split,
subset=&quot;training&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

data_val = tf.keras.utils.image_dataset_from_directory(
train_dir,
validation_split=validation_split,
subset=&quot;validation&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

# 将验证集拆分为验证集和测试集
def split_dataset(dataset, split_ratio=0.5):
dataset_size = len(dataset)
split = int(split_ratio * dataset_size)
train_dataset = dataset.take(split)
test_dataset = dataset.skip(split)
return train_dataset, test_dataset

data_val, data_test = split_dataset(data_val, split_ratio=test_split_ratio)

# 应用预处理和增强
data_train = data_train.map(lambda x, y: (data_augmentation(x, training=True), y)).map(preprocess)
data_val = data_val.map(preprocess)
data_test = data_test.map(preprocess)

# 预取数据以获得更好的性能
data_train = data_train.prefetch(tf.data.AUTOTUNE)
data_val = data_val.prefetch(tf.data.AUTOTUNE)
data_test = data_test.prefetch(tf.data.AUTOTUNE)

# 定义 ResNet50 模型
input_shape = (50, 50, 3)
base_model = ResNet50(weights=&#39;imagenet&#39;, include_top=False, input_shape=input_shape)
base_model.trainable = False

# 构建模型
model = models.Sequential([
layer.Input(shape=(img_height, img_width, 3)),
base_model,
layer.GlobalAveragePooling2D(),
layer.Dense(256,activation=&#39;relu&#39;),
layer.Dropout(0.5),
layer.Dense(1,activation=&#39;sigmoid&#39;)
])

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 用于提前停止和检查点的回调
early_stopping = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;,patient=5, restore_best_weights=True)

model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
filepath=&#39;/kaggle/working/resnet50_model.keras&#39;,
monitor=&#39;val_loss&#39;,
mode=&#39;min&#39;,
save_best_only=True,
save_weights_only=False
)

# 训练模型
model.fit(data_train, epochs=50, validation_data=data_val, callbacks=[early_stopping, model_checkpoint_callback])

# 微调模型
base_model.trainable = True
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
model.fit(data_train, epochs=50, validation_data=data_val,回调=[early_stopping, model_checkpoint_callback])

# 保存模型
model.save(&#39;/kaggle/working/resnet50_model.keras&#39;)

# 加载最佳微调模型
model = load_model(&#39;/kaggle/working/resnet50_model.keras&#39;)

为了调试该问题，我在预处理阶段通过打印数据批次的形状来检查图像输入。结果如下：

训练数据 - 批次 0：图像形状：(64, 50, 50, 3)，标签形状：(64,)

验证数据 - 批次 0：图像形状：(64, 50, 50, 3)，标签形状：(64,)

测试数据 - 批次 0：图像形状：(64, 50, 50, 3)，标签形状：(64,)


我预计保存的模型可以顺利加载，这样我就可以使用训练后的权重和架构进行评估和预测。]]></description>
      <guid>https://stackoverflow.com/questions/78829665/layer-dense-expects-1-inputs-but-it-received-2-input-tensors-when-loading</guid>
      <pubDate>Sat, 03 Aug 2024 20:01:05 GMT</pubDate>
    </item>
    <item>
      <title>通过 OpenCV 快速查找重复图像</title>
      <link>https://stackoverflow.com/questions/78829582/fast-finding-of-the-duplicate-images-via-opencv</link>
      <description><![CDATA[我正在尝试通过 C# 添加一种在 MongoDB 中存储和查找重复图片的方法。我有一个应用程序，允许用户创建图像并将其保存在我的网站上。我将它们存储在 MongoDB 中，现在想查找重复项，但由于图像数量太多，我无法只用其他图像检查新图像。我希望有一些索引和标志来快速找到可能的重复项，然后完全检查它们。我使用 OpenCV 库来查找图片的描述符并存储它们，以便之后我可以轻松地用新图片检查它们。我可以使用什么作为标志或索引来不搜索整个数据库？有没有快速的方法？这是我的代码示例，它允许我找到描述符：
Mat img1 = Cv2.ImRead(&quot;somepic&quot;, ImreadModes.Grayscale); 
var orb = ORB.Create(); 
KeyPoint[] keyPoints; 
Mat descriptors = new Mat(); 
orb.DetectAndCompute(img1, null, out keyPoints, descriptors);

有一个通过描述符比较两幅图像的示例（左侧原始图像和右侧裁剪后的图像）。所以这种方法确实有效。但是如何在数百万张图片中快速做到这一点？
比较图像
我听说我可以将描述符分成 4-8 个部分并将它们用作索引，但无法保证我会找到可能的重复项。我也听说过 k-means，但我也不了解如何将其与描述符一起使用。或者也许还有其他没有机器学习的方法？
附言：我尝试过 PHash，但它对裁剪后的图片效果很糟糕。]]></description>
      <guid>https://stackoverflow.com/questions/78829582/fast-finding-of-the-duplicate-images-via-opencv</guid>
      <pubDate>Sat, 03 Aug 2024 19:14:23 GMT</pubDate>
    </item>
    <item>
      <title>Kaldi steps/nnet3/align.sh 中缺少对齐文件 (ali.*.gz) [关闭]</title>
      <link>https://stackoverflow.com/questions/78828864/missing-alignment-files-ali-gz-in-kaldi-steps-nnet3-align-sh</link>
      <description><![CDATA[我正在尝试使用 Kaldi 训练语音识别模型。我已成功运行 steps/nnet3/align.sh 脚本，但 exp/chain/tree_sp 目录中未创建预期的 ali.1.gz 文件。
我已检查 exp/chain/tree_sp/log 目录中的终端输出和日志文件，但没有错误消息。该脚本似乎运行正常，但缺少所需的输出。
您能否建议此问题的潜在原因或进一步调试的步骤？如何解决？
我已成功运行 steps/nnet3/align.sh 脚本（终端或日志文件中没有错误）。我已检查 exp/chain/tree_sp 目录中是否存在 ali.JOB.gz 文件，但它们不存在（未创建），并且在运行 local/chain/tuning/run_tdnn_1j.sh 时出现此错误
Traceback（最近一次调用最后一次）：
文件“/mnt/d/kaldi/egs/mini_librispeech/s5/steps/nnet3/chain/train.py”，第 651 行，在 main
train(args, run_opts)
文件“/mnt/d/kaldi/egs/mini_librispeech/s5/steps/nnet3/chain/train.py”，第 287 行，在 train
chain_lib.check_for_required_files(args.feat_dir, args.tree_dir,
文件&quot;/mnt/d/kaldi/egs/mini_librispeech/s5/steps/libs/nnet3/train/chain_objf/acoustic_model.py&quot;，第 378 行，在 check_for_required_files 中
raise Exception(&#39;预期 {0} 存在。&#39;.format(file))
异常：预期 exp/chain/tree_sp/ali.1.gz 存在。
]]></description>
      <guid>https://stackoverflow.com/questions/78828864/missing-alignment-files-ali-gz-in-kaldi-steps-nnet3-align-sh</guid>
      <pubDate>Sat, 03 Aug 2024 14:01:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中有效地将大型 .txt 文件拆分为训练集和测试集？</title>
      <link>https://stackoverflow.com/questions/78827762/how-can-i-efficiently-split-a-large-txt-file-into-training-and-test-sets-in-pyt</link>
      <description><![CDATA[我有一个非常大的 .txt 文件（几 GB），我需要将其拆分为机器学习项目的训练集和测试集。由于内存限制，将整个文件读入内存然后拆分的常用方法不可行。我正在寻找一种高效拆分文件而不使内存过载的方法。
我尝试使用 scikit-learn 进行拆分，但它会将整个文件加载到内存中，这会导致性能问题，不适合我的大型数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78827762/how-can-i-efficiently-split-a-large-txt-file-into-training-and-test-sets-in-pyt</guid>
      <pubDate>Sat, 03 Aug 2024 03:36:13 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 Pytorch 的 CrossEntropyLoss 应用类权重来解决多类多输出问题的不平衡数据分类问题</title>
      <link>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3），每个目标列有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html，我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。
具体来说，我可以获得如下所示的数据



A
B
C
D
E
OUTPUT_1
OUTPUT_2
OUTPUT_3




5.65
3.56
0.94
9.23
6.43
0
2
1


7.43
3.95
1.24
7.22
&lt; td&gt;2.66
0
0
0


9.31
2.42
2.91
2.64
6.28
2
0
2


8.19
5.12
1.32
3.12
8.41
0
2
0


9.35
1.92
3.12
4.13
3.14
0
1
1


8.43
9.72
7.23
8.29
9.18
1
0
2


4.32
2.12
3.84
9.42
8.19
0
1
0


3.92
3.91
2.90
8.1 9
8.41
2
0
2


7.89
1.92
4.12
8.19
7.28
0
1
2
&lt; /tr&gt;

5.21
2.42
3.10
0.31
1.31
2
0
0



因此，
输出 1 中的比例为：0 = 0.6、1 = 0.1、2 = 0.3
输出 2 中的比例为：0 = 0.4、1 = 0.3、2 = 0.3
输出 3 中的比例为：0 = 0.4、1 = 0.2、2 = 0.4

我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）第 1 类为 0.15，第 0 类和第 2 类各为 0.425（因此对于 output_1，权重将是 [0.425/0.6, 0.15/0.1, 0.425/0.3]，对于输出 2，它将是 [0.425/0.4, 0.15/0.3, 0.425/0.3] 等）。相反，我理解 pytorch 的 crossentropy 损失函数中的权重参数目前正在执行的操作是将单个类权重应用于每个输出列。我想知道我是否遗漏了什么，是否有办法使用 pytorch 的 crossentropyloss 函数来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</guid>
      <pubDate>Fri, 02 Aug 2024 03:34:55 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 分类器的 SHAP 解释中 expected_value 的计算</title>
      <link>https://stackoverflow.com/questions/77126001/calculation-of-expected-value-in-shap-explanations-of-xgboost-classifier</link>
      <description><![CDATA[我们如何理解SHAP explainer.expected_value？为什么经过sigmoid变换后，它与y_train.mean()不一样？
下面是代码摘要，供快速参考。完整代码可在此笔记本中找到：https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb
model = xgb.XGBClassifier()
model.fit(X_train, y_train)
explainer = shap.Explainer(model)
shap_test = explainer(X_test)
shap_df = pd.DataFrame(shap_test.values)

#对于每种情况，如果我们将所有特征的 shap 值加上预期值相加，我们就可以得到该情况的边际，然后可以将其转换为返回该情况的预测概率case:
np.isclose(model.predict(X_test, output_margin=True),explainer.expected_value + shap_df.sum(axis=1))
#True

但是为什么下面不成立？为什么经过 sigmoid 变换后，XGBoost 分类器的 explainer.expected_value 与 y_train.mean() 不一样？
expit(explainer.expected_value) == y_train.mean()
#False
]]></description>
      <guid>https://stackoverflow.com/questions/77126001/calculation-of-expected-value-in-shap-explanations-of-xgboost-classifier</guid>
      <pubDate>Mon, 18 Sep 2023 09:28:55 GMT</pubDate>
    </item>
    </channel>
</rss>