<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Sep 2024 15:15:31 GMT</lastBuildDate>
    <item>
      <title>CRNN 实现不兼容的形状：[32] vs. [32,29] [关闭]</title>
      <link>https://stackoverflow.com/questions/78987265/crnn-implementation-incompatible-shapes-32-vs-32-29</link>
      <description><![CDATA[我正在尝试训练一个从图像中读取值和单位的 ml 模型。我正在尝试实现基于 CRNN 的架构，但无法弄清楚为什么会出现此错误。任何帮助都将不胜感激。
这是笔记本文本的链接&gt;]]></description>
      <guid>https://stackoverflow.com/questions/78987265/crnn-implementation-incompatible-shapes-32-vs-32-29</guid>
      <pubDate>Sun, 15 Sep 2024 11:29:58 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 MarianMT 中的单词翻译问题？[关闭]</title>
      <link>https://stackoverflow.com/questions/78986346/how-to-overcome-the-issue-of-single-word-translation-in-marianmt</link>
      <description><![CDATA[我认真思考了 HuggingFace 中 MarianMT 模型的单词翻译问题。我目前正在开发用于翻译的 Telegram 机器人。为此，我选择了 MarianMT 模型。作为训练数据集，我选择了 Europarl 著名的并行语料库，它支持不同的语言，并且以正式的风格编写。
现在，我想解释一下我做了什么以及我遇到了哪些问题：
首先，我想描述一下我使用了哪些技术。编程语言是 Python3，深度学习框架称为 PyTorch。正如我上面提到的，模型是 MarianMT。我使用不同版本的 MarianMT 来处理多种语言，例如法语、英语、德语等。
其次，我想描述一下我的问题：
问题是，当我使用英德语言模型时，它无法正确翻译或根本不翻译输入的单词，并显示“抱歉，但尚不支持此语言的翻译”。但是，如果我用德语输入相同的单词，它会正确翻译该单词。此外，城市、国家等命名实体也存在问题。例如，如果我用英语输入 City of Düsseldorf is the capital of the state of NRW，模型将产生类似这样的结果：
City of485 ist die Hauptstadt des Bundesstaates Houston

这真的很差劲，而且不正确。
在翻译诸如汽车、黄油、乌克兰、丹麦、操场等与国家、城市、主题甚至有时是动作有关的类似词语时，它也会失败。
第三，我想定义我使用的模型和参数：
Helsinki-NLP/opus-mt-en-de 用于英语-德语和德语-英语翻译 
Helsinki-NLP/opus-mt-en-fr 用于英语-法语翻译
Helsinki-NLP/opus-mt-fr-en 用于法语-英语翻译 

现在介绍训练的参数：
框架：PyTorch 最新版 + Google Colab Pro 
编程语言：Python 3.10 
数据集：Europarl paralell corpora 
epoch 数：2 
损失函数：稀疏分类交叉熵 
优化器：Adam 
学习率：0.0001 
批次大小：32 

那么我该如何克服某些单词或句子根本没有翻译或翻译不正确的问题呢？]]></description>
      <guid>https://stackoverflow.com/questions/78986346/how-to-overcome-the-issue-of-single-word-translation-in-marianmt</guid>
      <pubDate>Sat, 14 Sep 2024 23:31:14 GMT</pubDate>
    </item>
    <item>
      <title>使用单一特征训练模型同时使用观察权重是否正确？[关闭]</title>
      <link>https://stackoverflow.com/questions/78985636/is-it-correct-to-train-a-model-with-a-single-feature-while-also-using-observati</link>
      <description><![CDATA[使用单个特征（在本例中为距离）同时使用观测权重来训练模型是否正确？
我正在尝试训练一个机器学习模型，其中唯一的输入特征是距离。此外，我有一个表示观测权重的权重列，以及一个指示距离是高还是低的目标变量（这是我想要预测的目标）。
仅使用一个特征（在本例中为距离）来训练模型是否合适？此外，在处理此类加权数据时，您会推荐哪种类型的模型？
我尝试使用逻辑回归和随机森林等模型，仅将距离作为输入特征。我希望模型能够学习距离与目标变量（高或低）之间的关系。此外，我应用权重来赋予某些观测值更重要的意义，但我不确定这是最有效的方法还是其他模型在加权数据方面的表现会更好。]]></description>
      <guid>https://stackoverflow.com/questions/78985636/is-it-correct-to-train-a-model-with-a-single-feature-while-also-using-observati</guid>
      <pubDate>Sat, 14 Sep 2024 16:34:26 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Pretrained 中 device_map = "auto" 的替代方案</title>
      <link>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</link>
      <description><![CDATA[我有一个从 huggingface 读取的模型，使用以下代码：
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

现在我读取了模型，并对内部层做了一些修改，并添加了更多层。当我开始训练/微调时，我发现并非所有东西都在同一个模型上。
现在经过更多调查，我发现我的自定义层没有像原始模型那样分布在多个 GPU 上。因此我需要类似 device_map=&quot;auto&quot; 的内容，但在读取模型之后。
因此只需类似
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

model.device_map = &quot;auto&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</guid>
      <pubDate>Sat, 14 Sep 2024 12:42:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在稳定的扩散修复模型中提高对象生成质量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78984494/how-to-improve-object-generation-quality-in-a-stable-diffusion-inpainting-model</link>
      <description><![CDATA[我目前正在微调一个稳定扩散修复模型，以完成一项特定任务：在图像中生成新对象。但是，我面临着几个挑战：

生成不一致：有时模型根本无法生成任何对象。

低质量输出：当模型确实生成对象时，质量通常不令人满意。


采取的步骤：

我一直在使用负面提示来阻止模型产生低质量的输出。
我已经收集并准备了一个数据集，其中包括高质量图像和应生成对象的区域的相应蒙版。

问题：

我可以采用哪些策略来提高生成对象的质量？
是否有特定的超参数或训练技术可以帮助提高模型在此任务中的性能？
如何有效地使用负面提示来引导模型而不导致生成不足？
是否有任何推荐的数据集或资源专注于图像中的对象生成，我应该考虑？

我正在使用 RealVisXL Inpaint 和 Hugging Face。
我当前的设置是 V100。]]></description>
      <guid>https://stackoverflow.com/questions/78984494/how-to-improve-object-generation-quality-in-a-stable-diffusion-inpainting-model</guid>
      <pubDate>Sat, 14 Sep 2024 07:06:23 GMT</pubDate>
    </item>
    <item>
      <title>roboflow 教程使用 albumentations：TypeError：图像必须是 numpy 数组类型</title>
      <link>https://stackoverflow.com/questions/78984257/roboflow-tutorial-using-albumentations-typeerror-image-must-be-numpy-array-typ</link>
      <description><![CDATA[更新
从 3.12.4 切换到 python 3.10.14 并解决了该问题。
在 Mac 上使用 conda venv 运行
albumentations 1.4.15
opencv 4.10.0
Original
我正在尝试使用 albumentations 调整图像大小，并偶然发现了这个 roboflow 教程 并准确复制了代码。
import albumentations as A
import cv2

image = cv2.imread(&quot;img.jpg&quot;)

pipeline = A.Compose([
A.Resize(height=640, width=640, p=1),
])

augmented_image = pipeline(image=image)[&quot;image&quot;]

但是，当我运行它时，我得到了以下信息错误：
回溯（最近一次调用）：
文件“/Users/user/Documents/test.py”，第 16 行，位于 &lt;module&gt;
augmented_image = pipeline(image=image)[&quot;image&quot;]
^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 334 行，在 __call__ 中
self.preprocess(data)
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 363 行，在 preprocess 中
self._check_args(**data)
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 412 行，在_check_args
引发 TypeError(f&quot;{data_name} 必须是 numpy 数组类型&quot;)
TypeError: 图像必须是 numpy 数组类型

我已使用 type(image) 确认它是 &lt;class &#39;numpy.ndarray&#39;&gt;
我也尝试过不同的图像以及 jpg 和 png
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78984257/roboflow-tutorial-using-albumentations-typeerror-image-must-be-numpy-array-typ</guid>
      <pubDate>Sat, 14 Sep 2024 03:55:15 GMT</pubDate>
    </item>
    <item>
      <title>注意力图逐渐消失 - 这是正常的吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78983457/the-attention-map-fades-is-this-normal</link>
      <description><![CDATA[我目前正在构建 Vision Transformer (ViT)，到目前为止，一切似乎进展顺利 - 低损失值、高准确率。然而，当我可视化注意力图时，我注意到它们随着时间的推移逐渐消失并变得统一。我预期的情况恰恰相反 - 随着模型的学习，注意力图将被 Transformer 用于识别哪些补丁对决策的影响更大，哪些补丁的影响较小。最初，情况确实如此，但随着模型的不断学习，注意力图变得越来越统一。
似乎我的模型出了问题，或者 Transformer 在决策过程中停止关注补丁之间的关系。我很好奇是否有其他人遇到过这种行为并可以帮助我解释发生了什么。
至于模型本身，它表现良好并显示出有希望的结果，所以我倾向于认为它没有问题。然而，很难明确地说什么是“正确的”或“错误的”在这种情况下。
简而言之，如果您能帮助我解释这些结果，我将不胜感激——我不明白为什么注意力图变得如此统一，而且它们的值可以忽略不计，这表明转换器在决策过程中可能没有考虑补丁之间的关系。
我使用了超过 10k 个样本。在第 5 个时期，我得到了这些值
Epoch 5/20
1179/1179 [===============================] - 1197s 1s/step - 损失：0.1253 - 稀疏分类准确度：0.9950 - val_loss：0.0607 - val_sparse_categorical_accuracy：1.0000
谢谢你的帮助。




]]></description>
      <guid>https://stackoverflow.com/questions/78983457/the-attention-map-fades-is-this-normal</guid>
      <pubDate>Fri, 13 Sep 2024 19:05:30 GMT</pubDate>
    </item>
    <item>
      <title>ML 模型置信度问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78983303/ml-model-confidence-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78983303/ml-model-confidence-issue</guid>
      <pubDate>Fri, 13 Sep 2024 18:07:05 GMT</pubDate>
    </item>
    <item>
      <title>Ray 自定义环境渲染</title>
      <link>https://stackoverflow.com/questions/78975679/ray-custom-environment-render</link>
      <description><![CDATA[我正在创建自己的 gym 环境来测试 freeze-tag 问题。我正在尝试使用 Ray 来做 MAPPO。我有两个问题：
1：我的模拟没有渲染
2：它创建了多个 PyGame 窗口
我已将渲染方法和训练脚本的片段附加到附件中。
# 渲染函数
def render(self):
self.screen.fill((255, 255, 255))

for agent in self.all_agents:
if agent.status == 1:
pygame.draw.circle(self.screen, agent.color, (agent.x, agent.y), agent.size)

elif agent.status == 0:
pygame.draw.circle(self.screen, (0, 255, 255), (agent.x, agent.y),agent.size)

pygame.display.flip()

# Train_MAPPO_FTP.py
import ray
from ray.rllib.algorithms.ppo import PPOConfig
from ray.tune.registry import register_env
import gym_FTP as e
import pygame
import numpy as np

# 环境创建函数
def env_creator(config):
robots = 5
adversaries = 2
time_steps = 500

screen = pygame.display.set_mode([1000, 1000])
gym_ftp = e.gym_FTP(screen, robots, 0, adversaries, time_steps, 15)
return gym_ftp

def train_and_evaluate(time_steps):
# 初始化 Ray
ray.init(ignore_reinit_error=True)

# 注册环境
register_env(&quot;Env_FTP&quot;, env_creator)

# create_env_on_local_worker = True
# 配置算法
config = PPOConfig() \
.environment(&quot;Env_FTP&quot;) \
.rollouts(num_rollout_workers=1,
rollout_fragment_length=1,
create_env_on_local_worker=True) \
.training(
train_batch_size=1, # 每次训练更新前汇总经验
sgd_minibatch_size=1,
model={&quot;fcnet_hiddens&quot;: [64, 64]}
) \
.framework(&quot;torch&quot;) \
.evaluation(evaluation_num_workers=1) \
.resources(num_gpus=0) # 设置 GPU 数量

# 构建算法
algo = config.build()

# 参数
episodes = 5
iterations = time_steps / 10

for episode in range(episodes):
for i in range(int(iterations)):
results = algo.train()
print(f&quot;训练迭代 {i + 1} 已完成。mean_reward {results[&#39;episode_reward_mean&#39;]},&quot;
f&quot; 总损失 {results[&#39;info&#39;][&#39;learner&#39;][&#39;__all__&#39;][&#39;total_loss&#39;]}&quot;)

# 关闭 Ray
ray.shutdown()

def main():
time_steps = 500
train_and_evaluate(time_steps)

main()


我已进行多次检查，以测试我的代理的速度是否根据新操作进行更新，以及位置是否正在更新，因此我确定这不是问题所在。当我使用其他算法进行测试时，此环境也有效。我可以正确使用 gym 环境的其他功能，并让它渲染和做一些有趣的事情。这似乎完全是 RAY 的问题。我的目标是拥有 n 个机器人和 m 个对手。我想根据环境状态为 n 个代理获取新操作。我想每集训练 500 个时间步，收集 10 个批次。例如前 10 个时间步，然后再添加 10 个时间步作为经验，然后再添加 10 个。所以我们每集最多更新 50 次。我们将进行 100 集。]]></description>
      <guid>https://stackoverflow.com/questions/78975679/ray-custom-environment-render</guid>
      <pubDate>Wed, 11 Sep 2024 20:54:21 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确地实现了带有反向传播的感知器？</title>
      <link>https://stackoverflow.com/questions/78961133/am-i-implementing-my-perceptron-with-backpropagation-correctly</link>
      <description><![CDATA[我在课堂上学习了感知器以及如何使用反向传播来训练模型。我目前在实施过程中遇到了麻烦，因为它仅能为我提供 50% 的准确率，而班上大多数同学的准确率都达到 90%。我在实施过程中是否忽略了什么？这是我目前从我查看过的资料中得到的结果。
class Perceptron():
def __init__(self, num_features):
self.num_features = num_features
self.weights = np.random.rand(num_features) * 0.1 # 这将创建一个用零填充的数组，形状为 num_features
self.bias = 0.0

def forward(self, x):
linear = np.dot(x, self.weights) + self.bias
print(linear)
predictions = np.where(linear &gt; 0, 1, 0)
return predictions

def behind(self, x, y, predictions):
errors = y - predictions
self.weights += self.learning_rate * np.dot(x.T, errors)
self.bias += self.learning_rate * np.sum(errors)
return errors

def train(self, x, y, epochs, learning_rate = 0.01):
self.learning_rate = learning_rate
for e in range(epochs):
for i in range(y.shape[0]):
x_i, y_i = x[i], y[i]
prediction = self.forward(x_i)
self.backward(x_i, y_i, prediction)

def assess(self, x, y):
predictions = self.forward(x)
accuracy = np.mean(predictions == y)
return accuracy

到目前为止，我已经尝试了不同的学习率，并询问了班上的其他人，说实话，这并没有真正改变我的实施结果。我期望准确率约为 90%，但实际只有 50%。
以下是一些示例数据：
0.77 -1.14 0
-0.33 1.44 0
0.91 -3.07 0
-0.37 -1.91 0
-1.84 -1.13 0
-1.50 0.34 0
-0.63 -1.53​​ 0
-1.08 -1.23 0
0.39 -1.99 0
-1.26 -2.90 0
-5.27 -0.78 0
-0.49 -2.74 0
1.48 -3.74 0
-1.64 -1.96 0
0.45 0.36 0
-1.48   -1.17 0 -2.94 -4.47 0 -2.19 -1.48 0 0.02 -0.02 0 -2.24 -2.12 0 -3.17 -3.69 0 -4.09 1.03 0 -2.41 -2.31 0 -3.45 -0.61 0 -3.96 -2.00 0 -2.95 -1。 16 0 -2.42 -3.35 0 -1.74 -1.10 0 -1.61 -1.28 0 -2.59 -2.21 0 -2.64 -2.20 0 -2.84 -4.12 0 -1.45 -2.26 0 -3.98 -1.05 0 -2.97   -1.63 0 -0.68 -1.52 0 -0.10 -3.43 0 -1.14 -2.66 0 -2.92 -2.51 0 -2.14 -1.62 0 -3.33 -0.44 0 -1.05 -3.85 0 0.38 0.95 0 -0.05 -1.95 0 -3.20 -0 22 0 -2.26 0.01 0 -1.41 -0.33 0 -1.20 -0.71 0 -1.69 0.80 0 -1.52 -1.14 0 3.88 0.65 1 0.73 2.97 1 0.83 3.94 1 1.59    1.25 1 3.92 3.48 1 3.87 2.91 1 1.14 3.91 1 1.73 2.80 1 2.95 1.84 1 2.61 2.92 1 2.38 0.90 1 2.30 3.33 1 1.31 1.85 1 1.56 3. 85 1 2.67 2.41 1 1.23 2.54 1 1.33 2.03 1 1.36 2.68 1 2.58 1.79 1 2.40 0.91 1 0.51 2.44 1 2.17 2.64 1 4.38 2.94 1 1.09 3.12    1 0.68 1.54 1 1.93 3.71 1 1.26 1.17 1 1.90 1.34 1 3.13 0.92 1 0.85 1.56 1 1.50 3.93 1 2.95 2.09 1 0.77 2.84 1 1.00 0.46 1 3.19 2.32 1 2.92 2.32 1 2.86 1.35 1 0.97 2.68 1 1.20 1.31 1 1.54 2.02 1 1.65 0.63 1 1.36 -0.22 1 2.63 0.40 1 0.90 2.05 1
1.26 3.54 1
0.71 2.27 1
1.96 0.83 1
2.52 1.83 1
2.77 2.82 1
4.16 3.34 1

在使用感知器模型之前，此代码首先进行随机化，然后分成2部分：原始数据的2/3用于训练，另外1/3用于测试。之后，对训练和测试数据集的前 2 个特征执行 z 分数标准化。
这是我使用该类的方式：
perceptron = Perceptron(num_features = 2)
perceptron.train(combined_x_train[:, :2], combined_x_train[:, 2], epochs = 5, learning_rate=0.1)
accuracy = perceptron.evaluate(x_train, y_train)
print(f&#39;Final Accuracy: {accuracy * 100:.2f}%&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78961133/am-i-implementing-my-perceptron-with-backpropagation-correctly</guid>
      <pubDate>Sat, 07 Sep 2024 21:05:33 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型聚合器 TensorFlow Federated</title>
      <link>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Federated，使用 FedAvg 算法模拟训练过程。
def model_fn():
# 包装 Keras 模型以用于 TensorFlow Federated
keras_model = get_uncompiled_model()

# 对于联合过程，模型必须是未编译的
return tff.learning.models. functional_model_from_keras(
keras_model,
loss_fn=tf.keras.losses.BinaryCrossentropy(),
input_spec=(
tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float32),
tf.TensorSpec(shape=[None], dtype=tf.int32)
),
metrics_constructor=collections.OrderedDict(
accuracy=tf.keras.metrics.BinaryAccuracy,
precision=tf.keras.metrics.Precision,
recall=tf.keras.metrics.Recall,
false_positives=tf.keras.metrics.FalsePositives,
false_negatives=tf.keras.metrics.FalseNegatives,
true_positives=tf.keras.metrics.TruePositives,
true_negatives=tf.keras.metrics.TrueNegatives
)
)

trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn= model_fn(),
client_optimizer_fn=client_optimizer,
server_optimizer_fn=server_optimizer
)

我想使用自定义权重来聚合客户端的更新，而不是使用它们的样本。我知道 tff.learning.algorithms.build_weighted_fed_avg() 有一个名为 client_weighting 的参数，但唯一接受的值来自类 tff.learning.ClientWeighting，它是一个枚举。
因此，唯一的方法似乎是编写自定义 WeightedAggregator。我尝试按照本教程进行操作，该教程解释了如何编写无加权聚合器，但我无法将其转换为加权聚合器。
这是我尝试做的：
@tff.tensorflow.computation
def custom_weighted_aggregate(values, weights):
# 规范化客户端权重
total_weight = tf.reduce_sum(weights)
normalized_weights = weights / total_weight

# 计算客户端更新的加权总和
weighted_sum = tf.nest.map_structure(
lambda v: tf.reduce_sum(normalized_weights * v, axis=0),
values
)

return weighted_sum

class CustomWeightedAggregator(tff.aggregators.WeightedAggregationFactory):
def __init__(self):
pass

def create(self, value_type, weight_type):
@tff.federated_computation
def initialize():
return tff.federated_value(0.0, tff.SERVER)

@tff.federated_computation(
initialize.type_signature.result,
tff.FederatedType(value_type, tff.CLIENTS),
tff.FederatedType(weight_type, tff.CLIENTS)
)
def next(state, value, weight):
aggregate_value = tff.federated_map(custom_weighted_aggregate, (value, weight))
return tff.templates.MeasuredProcessOutput(
state,aggregate_value,tff.federated_value((),tff.SERVER)
)

return tff.templates.AggregationProcess(initialize,next)

@property
def is_weighted(self):
return True

但是我得到了以下错误：
AggregationPlacementError：next_fn 返回类型的“result”属性必须放置在 SERVER 中，但发现 {&lt;float32[7],float32,float32[1],float32&gt;}@CLIENTS。]]></description>
      <guid>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</guid>
      <pubDate>Mon, 05 Aug 2024 16:06:48 GMT</pubDate>
    </item>
    <item>
      <title>优化欺诈检测不平衡数据的指标</title>
      <link>https://stackoverflow.com/questions/77444565/optimize-metrics-for-fraud-detection-imbalanced-data</link>
      <description><![CDATA[我需要您的帮助来提高我的模型性能。就像大多数欺诈检测一样，我有一个不平衡的数据集（0.1/0.9）。我想优化目标 1 和 0 的召回率，因为一方面我想避免欺诈检测，另一方面我想限制将非欺诈客户定位为欺诈的成本，因为 5% 的错误分类会使我的收入减少 3000 欧元（而定位正确的欺诈者会让我为检测到的每位客户节省 1000 欧元的损失）。
我的第一个问题是：您会根据这个问题考虑哪些指标？我更关注召回率，但我会阅读您的意见。
第二个问题：我如何提高模型性能？
到目前为止，我在不降低阈值的情况下获得的最佳结果是：
准确率：0.89
混淆矩阵：
[[3153 279]
[ 145 297]]
分类报告：
准确率 召回率 f1 分数 支持
 0 0.96 0.92 0.94 3432
1 0.52 0.67 0.58 442

准确率 0.89 3874

而如果我降低阈值以增加目标 1 的召回率：
准确率：0.61
混淆矩阵：
[[1959 1473]
[ 42 400]]
分类报告：
准确率 召回率 f1 分数 支持率
 0 0.98 0.57 0.72 3432
1 0.21 0.90 0.35 442

准确率 0.61 3874

我尝试了几种模型：
线性回归、XGBoost、随机森林和 SVM
此外，甚至过采样/反采样技术（仅在训练集上）
RandomOverSampling、RandomUnderSampling、SMOTE
您还有其他建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77444565/optimize-metrics-for-fraud-detection-imbalanced-data</guid>
      <pubDate>Wed, 08 Nov 2023 10:08:43 GMT</pubDate>
    </item>
    <item>
      <title>如何处理一列包含图像名称、另一列包含图像路径的 csv 文件数据集？</title>
      <link>https://stackoverflow.com/questions/72773807/how-to-handle-dataset-which-is-a-csv-file-that-contains-image-names-in-one-colum</link>
      <description><![CDATA[我是 Python 和机器学习的新手。我只是在练习模型训练和数据集。我偶然发现了这个数据集，它有测试和训练文件夹。该文件夹中有几个包含不同图像的文件（这是一个乐器数据集，因此每个乐器都按名称分类在不同的文件夹中）。csv 文件包含乐器的名称及其在文件夹中的路径，如下所示：Instrument.csv
现在我的问题是如何处理这个数据集？我应该遍历训练和测试文件夹还是使用这个 csv 文件？
如果我想选择文件夹选项，那么如何遍历每个子文件夹并访问图像？
这是数据集的链接：https://www.kaggle.com/datasets/gpiosenka/musical-instruments-image-classification
如果问题没有任何意义或太容易回答，我很抱歉。我承认我是菜鸟]]></description>
      <guid>https://stackoverflow.com/questions/72773807/how-to-handle-dataset-which-is-a-csv-file-that-contains-image-names-in-one-colum</guid>
      <pubDate>Mon, 27 Jun 2022 14:30:58 GMT</pubDate>
    </item>
    <item>
      <title>设置 SciKeras 模型时出现问题</title>
      <link>https://stackoverflow.com/questions/66094139/issue-setting-up-scikeras-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/66094139/issue-setting-up-scikeras-model</guid>
      <pubDate>Sun, 07 Feb 2021 23:19:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 计算累积分布函数 (CDF)</title>
      <link>https://stackoverflow.com/questions/24788200/calculate-the-cumulative-distribution-function-cdf-in-python</link>
      <description><![CDATA[如何在 Python 中计算累积分布函数 (CDF)？
我想从我拥有的点数组（离散分布）来计算它，而不是使用例如 scipy 所具有的连续分布。]]></description>
      <guid>https://stackoverflow.com/questions/24788200/calculate-the-cumulative-distribution-function-cdf-in-python</guid>
      <pubDate>Wed, 16 Jul 2014 18:36:16 GMT</pubDate>
    </item>
    </channel>
</rss>