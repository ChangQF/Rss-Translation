<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 08 Apr 2025 09:22:00 GMT</lastBuildDate>
    <item>
      <title>ML河的决策树的印刷规则</title>
      <link>https://stackoverflow.com/questions/79561495/printing-rules-from-decision-tree-in-river-ml</link>
      <description><![CDATA[我正在使用河流ML库，并使用决策树模型。我想从训练有素的树木中打印或提取决策规则。但是，看来图书馆目前没有提供内置方法来执行此操作。
有人知道一种从河中的树模型手动打印或提取决策规则的方法吗？
  pipeline = compose.pipeline（
        self.extract_features（事件=事件），
        ordinalencoder（），
        lastClassifier（max_depth = 5，track_error = true，remove_poor_attrs = true）
    ）
metric = f1（）
    self.state.update（{&#39;pipeline&#39;：pipeline，&#39;metric&#39;：metric}）


标签= 1如果分类_label其他0

＃检索当前管道组件
pipeline = self.state.value（）[&#39;pipeline&#39;]
模型=管道[&#39;lastClassifier&#39;]
metric = self.state.value（）[&#39;metric&#39;]

＃进行预测并更新度量
predicted_label = model.predict_one（self.state.value（）[&#39;pipeline&#39;] [&#39;dict&#39;]）
吨

＃通过新事件更新模型
model.learn_one（self.state.value（）[&#39;pipeline&#39;] [&#39;dict&#39;]，标签）

＃保存更新的状态
self.state.update（{&#39;pipeline&#39;：pipeline，&#39;metric&#39;：metric}）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79561495/printing-rules-from-decision-tree-in-river-ml</guid>
      <pubDate>Tue, 08 Apr 2025 07:59:08 GMT</pubDate>
    </item>
    <item>
      <title>图像旋转：使用Pytorch进行角度检测的模型</title>
      <link>https://stackoverflow.com/questions/79560879/image-rotation-model-for-angle-detection-using-pytorch</link>
      <description><![CDATA[基本上，我正在尝试创建一个模型，该模型将检测旋转特定图像的角度。另外，我还有一个由1500个文档的数据集，该数据集由上旋转的图像产生
 随机。样本（[0，90，-90，180]，2）
 
每个角度的变化
  random.均匀（-10，10）
 
导致〜4K旋转图像。
所以我想出了当前的模型来预测所需角度的罪和cos：
 类CnnRotAteRegression（nn.Module）：
    def __init __（自我）：
        super（cnnrotateregression，self）.__ init __（）
        self.conv1 = nn.conv2d（3，64，kernel_size = 3）
        self.conv2 = nn.conv2d（64，128，kernel_size = 3）
        self.conv3 = nn.conv2d（128，256，kernel_size = 3）
        self.conv4 = nn.conv2d（256，512，kernel_size = 3）
        self.conv5 = nn.conv2d（512，512，kernel_size = 3）
        
        self.bn1 = nn.batchnorm2d（64）
        self.bn2 = nn.batchnorm2d（128）
        self.bn3 = nn.batchnorm2d（256）
        self.bn4 = nn.batchnorm2d（512）
        self.bn5 = nn.batchnorm2d（512）
        
        self.activation = nn.relu（）
        self.pool = nn.avgpool2d（kernel_size = 2）
        self.pool2 = nn.adaptiveavgpool2d（（8,8））

        self.linear_l1 = nn.linear（512*8*8，512）
        self.linear_l2 = nn.linear（512，256）
        self.linear_l3 = nn.linear（256，2）＃sin + cos

    def向前（self，x）：
        x = self.activation（self.pool（self.bn1（self.conv1（x））））
        x = self.activation（self.pool（self.bn2（self.conv2（x））））
        x = self.activation（self.pool（self.bn3（self.conv3（x））））
        x = self.activation（self.pool（self.bn4（self.conv4（x））））
        x = self.activation（self.pool（self.bn5（self.conv5（x））））
        
        x = self.pool2（x）
        x = x.view（x.Size（0），-1）
        
        x = self.activation（self.linear_l1（x））
        x = self.activation（self.linear_l2（x））
        x = self.linear_l3（x）

        x = f.normalize（x，p = 2，dim = 1）

        返回x
 
训练零件：
  model = cnnrotateRegression（）
模型=型号。

loss_function = nn.mseloss（）
优化器= Optim.Adam（model.parameters（），LR = 0.001）
num_of_epochs = 11


对于范围（num_of_epochs）的时代：
    model.train（）
    Running_loss = 0.0
    对于图像，在tqdm中的标签（train_loader，desc =＆quot;训练循环”：

        图像，标签=图像。

        angles = Angle_to_sin_cos（标签）
        norm_angles = f.normalize（角度，p = 2，dim = 1）

        优化器.zero_grad（）
        输出=模型（图像）
        损失= lose_function（输出，norm_angles）
        loss.backward（）
        优化器.step（）

        running_loss += loss.item（）
    train_loss = runn_loss / len（train_loader）
 
函数将sin和cos转换为角度，反之亦然：
  def angle_to_sin_cos（angle）：
    tensor_angle = Angle.clone（）。distach（）
    radian = tensor_angle * torch.pi / 180.0
    返回Torch.Stack（[[Torch.Cos（Radian），Torch.sin（Radian）]，DIM = 1）

DEF SIN_COS_TO_ANGLE（输出）：
    cos_val，sin_val =输出[：，0]，输出[：，1]
    Angle_rad = torch.atan2（sin_val，cos_val）
    Angle_deg = Angle_rad *（180 / Torch.pi）
    返回angle_deg
 
我的模型在确定范围 +-10度的小角度方面的表现差。您建议改进/增强以实现更好的“小度”。预言？预先感谢您！]]></description>
      <guid>https://stackoverflow.com/questions/79560879/image-rotation-model-for-angle-detection-using-pytorch</guid>
      <pubDate>Mon, 07 Apr 2025 22:20:43 GMT</pubDate>
    </item>
    <item>
      <title>我如何在自定义表情数据集中正确训练或微调通量。1-dev？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79560686/how-do-i-properly-train-or-fine-tune-flux-1-dev-on-a-custom-emoji-dataset</link>
      <description><![CDATA[我正在尝试训练   black-forest-luxs/flux.1-dev  在我自己的数据集中大约25,000 emoji-style-style s-style图像。每个图像（512×512 PNG）都有一个简短的标题，我正在尝试从文本提示中生成新的表情符号图像。
 数据集/
├ - 图像/
│└└─Image_1.png
├ - 字幕/
│└└前caption_1.txt
train。
 
我不想调试任何具体的内容 - 我只想明确的指导或如何正确训练该模型。具体：

 应该如何微调？

我应该冻结vae或文本编码吗？
我应该使用Lora，全面调查或Dreambooth？


 我的数据集格式好吗？

是.txt字幕 +图像对 +火车。


 您有示例培训脚本或笔记本吗？

我找不到特定磁道的官方示例。1。


 什么是好配置？

批处理大小，学习率，体面结果的时期数量？


]]></description>
      <guid>https://stackoverflow.com/questions/79560686/how-do-i-properly-train-or-fine-tune-flux-1-dev-on-a-custom-emoji-dataset</guid>
      <pubDate>Mon, 07 Apr 2025 19:56:27 GMT</pubDate>
    </item>
    <item>
      <title>对于基于等级的数据集选择的正确模型是什么？</title>
      <link>https://stackoverflow.com/questions/79560209/what-is-the-correct-model-to-choose-for-a-rank-based-dataset-with-many-missing-o</link>
      <description><![CDATA[我目前正在进行一个项目，我计划研究Tiktok歌曲病毒性对Spotify图表表现的影响，以及哪种歌曲特征适度这种关系。
我的数据集包含来自两个平台的每周前50个图表数据，涉及约200周，因此我总共有约20,000个观察结果，其中约9,500个是独特的歌曲。由于图表的性质，歌曲通常仅出现几周，从而导致小组数据集中缺少许多观察结果。我也有许多歌曲特征变量，这些变量是数值的值，以及每首歌曲发布的视频数量，我可以用作独立变量。我计划给每个排名号码的分数，以将层次结构转换为数值。
我当前的方法是使用混合效应模型，因为：

 数据集的嵌套结构（嵌套在歌曲中）

 混合模型对于不平衡数据（缺少观测）是可靠的

 歌曲变异性中的随机效果捕获


这是一个好方法吗？否则，在这种情况下应用的ML方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79560209/what-is-the-correct-model-to-choose-for-a-rank-based-dataset-with-many-missing-o</guid>
      <pubDate>Mon, 07 Apr 2025 14:58:02 GMT</pubDate>
    </item>
    <item>
      <title>单词错误率在第一个时期自动语音识别系统后几乎100％[封闭]</title>
      <link>https://stackoverflow.com/questions/79560091/word-error-rate-almost-100-after-first-epoch-automatic-speech-recognition-syste</link>
      <description><![CDATA[我尝试使用语音脑训练ASR系统。但是，在第一个时期之后，我的单词错误率是疯狂的 - 为99.63％。实际上几乎是100％。这是训练日志的整个行：
 时期：1，LR：1.00E+00-火车损失：5.15-有效损失：4.42，有效CER 81.95，有效的WER。 99.63
 
我不确定我是否只是完全搞砸了。我知道在第一个时代之后很难说，但是我的计算机运行速度真的很慢，所以我只是想知道看起来是否错了。
如果是相关的，则数据集由149,759个话语组成。我了解LM和该表演的代币因素，但我只想知道这是否是主要的危险信号。]]></description>
      <guid>https://stackoverflow.com/questions/79560091/word-error-rate-almost-100-after-first-epoch-automatic-speech-recognition-syste</guid>
      <pubDate>Mon, 07 Apr 2025 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>与Keras进行渐进学习[关闭]</title>
      <link>https://stackoverflow.com/questions/79559837/progressive-learning-with-keras</link>
      <description><![CDATA[我正在使用UNET类型网络来解决细分问题。我的图像是384x348x3（是频道的最后一个维度）。我使用Keras（TensorFlow后端）。我有一个庞大的数据集，并且面临一些内存问题，这就是为什么我正在与数据机器合作。但是，我的模型正在努力学习，在某个时候，由于内存问题而破裂。为了提供一种可以提高F1分数（精度和召回）的强大学习，我了解了一个想法：以间隔（0.1、0.2、0.3、0.4）切碎数据集，因此首先培训只会占整个数据集的10％。首先拟合之后，我使用训练有素的模型，并使用第一个10％的数据和接下来的20％数据重新训练。这样，我就能获得更合理的F1分数，但记忆问题仍然存在。我不知道这个近似是否有意义，或者我是否在代码的某些部分中弄乱了它：
  def load_progress（self）：
    尝试：
        开放（self.models_path + triending_progress.json.json＆quot” r＆quot;“）为f：
           数据= JSON.LOAD（F）
           返回数据[last_phase_completed＆quot&#39;]
    除了filenotfounderror：
        返回-1＃如果没有保存进展，请从0开始
    
def save_progress（self，阶段）：
    开放（self.models_path +&#39;triending_progress.json.json＆quot“ w＆quot”）为f：
        json.dump（{&#39;last_phase_completed＆quot;：phase}，f）

增量= [0.1、0.2、0.3、0.4]＃％dat datos USADOS EN CADA FASE
datasets_indices = []
total_datos = len（火车）
    
inicio = 0
以增量为INC：
    fin = inicio + int（inc * total_datos）
    datasets_indices.append（list（range（inicio，fin））））
    inicio = fin＃包括旧组和新的数据组
            
    ＃加载最后一个完整的阶段
    last_phase_completed = self.load_progress（）


模型= []
对于我，枚举（datasets_indices）中的subset_indices：
    
    train_sub = train.iloc [subset_indices]
    train_sub = train_sub.sample（frac = 1.0，Random_state = 7）
    val = val.sample（frac = 1.0，Random_state = 7）
    train_loader = datagenerator（data = trib_sub.reset_index（drop =; true＆quort; quot;），
                                        batch_size = batch_size，
                                        dim =（高度，宽度））
    验证_loader = datagenerator（data = val.reset_index（drop =＆quot; true＆quort; quot），
                                            batch_size = batch_size，
                                            dim =（高度，宽度））
            
    如果i＆lt; = last_phase_completed：
        继续＃跳过阶段已经完成
            
    {len（subset_indices）}样本＆quort＆quort&#39;&#39;
    logging.info（f＆quot; \ n training阶段{i+1}带{len（subset_indices）}示例＆quot;）
            
    历史记录，model_name，model，train_loader，val_loader = vgapp.execute（train_loader，validation_loader，i，model）
    ＃Guardar Modelo y Progreso
    model.Save（conf [model; quod; quot; quartial; quartial; quot; quote; quode; quode&#39; + f＆quot; f＆quot&#39;ground&#39;/modelo_fase_ {i + 1} .h5; h5;
    vgapp.save_progress（i）
 
  vgapp.execute 是一个函数，如果步骤= 0，则它构建模型，对其进行编译并适合它。否则，它采用输入模型并适合它。
在一些时期之后，Docker断断续续，我想这是因为记忆问题。
我的问题是：

我在这里做什么以提高F1分数并减少记忆问题？
如果这样做，为什么我会继续遇到内存问题？
有更好的方法吗？
]]></description>
      <guid>https://stackoverflow.com/questions/79559837/progressive-learning-with-keras</guid>
      <pubDate>Mon, 07 Apr 2025 12:10:06 GMT</pubDate>
    </item>
    <item>
      <title>获取RF回归器模型的分析方程[重复]</title>
      <link>https://stackoverflow.com/questions/79559492/get-analytical-equation-of-rf-regressor-model</link>
      <description><![CDATA[我有以下数据集：
  x1 x2 x3 y
0 0.548814 0.715189 0.602763 0.264556
1 0.544883 0.423655 0.645894 0.774234
2 0.437587 0.891773 0.963663 0.456150
3 0.383442 0.791725 0.528895 0.568434
4 0.568045 0.925597 0.071036 0.018790
5 0.087129 0.020218 0.832620 0.617635
6 0.778157 0.870012 0.978618 0.612096
7 0.799159 0.461479 0.780529 0.616934
8 0.118274 0.639921 0.143353 0.943748
9 0.944669 0.521848 0.414662 0.681820
 
使用此代码生成：
 导入numpy作为NP
导入大熊猫作为pd
来自sklearn.linear_model导入linearrecress

＃创建一个带有10个观测值和3个X变量的示例数据集和一个目标Y-变量
np.random.seed（0）
x = np.random.rand（10，3）
y = np.random.rand（10）

＃转换为数据框以更好地可视化
df = pd.dataframe（x，columns = [&#39;x1&#39;，&#39;x2&#39;，&#39;x3&#39;]）
df [&#39;y&#39;] = y
 
 i可以使用以下方式拟合线性回归模型
  model = linearregression（）
型号（x，y）
 
并获得估计的系数
 系数= model.coef_
拦截= model.intercept_

打印（“ \嵌套系数：系数）
打印（“截距：＆quot”，截距）
 
这将返回：
 估计系数：[-0.06965376 -0.39155857 0.05822415]
截距：0.8021881697754355
 
那么，如果我有一个新观察，我可以使用经过训练的模型进行预测：
  new_observation = np.Array（[[[0.5，0.2，0.8]]））
预测= model.predict（new_observation）

打印（新观察的“ \ nprediction：＆quot”，预测）
 
这将返回值 0.73562889 。
预测值来自模型的分析形式：
 0.8021881697754355-0.5*0.06965376 -0.39155857*0.2 + 0.2 + 0.05822415*0.8  
 任务 
我想获得随机森林回归模型的分析形式，而不是线性回归。当模型接受以下代码训练时，我如何获得随机森林回归剂的分析形式：
  rf_model = RandomForestRegressor（n_estimators = 100，Random_State = 0）
rf_model.fit（x，y）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79559492/get-analytical-equation-of-rf-regressor-model</guid>
      <pubDate>Mon, 07 Apr 2025 09:27:58 GMT</pubDate>
    </item>
    <item>
      <title>通过预测前馈神经网络预测可变长度的输出？</title>
      <link>https://stackoverflow.com/questions/79559377/how-to-handle-outputs-of-variable-length-when-predicting-with-a-feed-forward-neu</link>
      <description><![CDATA[我正在处理一个回归问题，在给定固定大小的输入x时，输出y可以是可变长度值的序列。
输入和输出都是归一化的浮点值。因此，我们正在谈论回归任务。
问题以y数组样本的可变大小（最大长度46）。
平均而言，只有前30-35个值（在46中）有效。
因此，要训练网络，我正在尝试的解决方案是：

将每个Y阵列样品的非valid值（0.0）
火车和预测
&#39;undad＆quot＆quot＆quot输出阵列通过删除所有尾随零（或非常小的值）。

问题是：

实际上，小值在0.0左右也可以是有效值，从而产生歧义。也许最好使用像-100这样的可笑的怪异数字？
看来，网络从未真正从有效的谷（例如：2.3）跳到0.0，但是它正在产生平稳的过渡到0.0，从而产生了非常糟糕的输出。

解决这个问题的好解决方案是什么？
如果数组值是整数，则可以使用特殊的int作为令牌。但是拥有浮子会使一切变得更加棘手。]]></description>
      <guid>https://stackoverflow.com/questions/79559377/how-to-handle-outputs-of-variable-length-when-predicting-with-a-feed-forward-neu</guid>
      <pubDate>Mon, 07 Apr 2025 08:13:54 GMT</pubDate>
    </item>
    <item>
      <title>通过程序裁剪之前或之后进行预处理？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79559367/preprocessing-before-or-after-programmatically-cropping</link>
      <description><![CDATA[我在自定义数据集上微调了Yolo模型，该模型在整个图像上进行了培训，而不是裁剪的图像。通常，我在将图像传递给模型之前对图像进行注释，调整和标准化。在我的任务中，我需要以编程方式将图像裁剪成两个部分，然后将每个部分分开传递给受过训练的模型。我应该像训练期间一样，在裁剪之前或裁剪后处理图像吗？如果我在处理前进行裁剪，则两个部分之一的分辨率将较低，因为它会较小。将其调整到640x640时，结果将具有非常低的分辨率，使其不清楚并且可能导致模型未发现的对象。
我应该像训练期间，裁剪之前或裁剪后一样处理图像吗？]]></description>
      <guid>https://stackoverflow.com/questions/79559367/preprocessing-before-or-after-programmatically-cropping</guid>
      <pubDate>Mon, 07 Apr 2025 08:08:16 GMT</pubDate>
    </item>
    <item>
      <title>tflite-runtime valueError：找不到opcode'firms'connected的'12'的op op。可能支持此内置的较旧版本</title>
      <link>https://stackoverflow.com/questions/79559242/tflite-runtime-valueerror-didnt-find-op-for-builtin-opcode-fully-connected-v</link>
      <description><![CDATA[我已经在 tensorflow == 2.19.0 上训练和量化了我的模型，而不是以前的版本，现在正在使用定量模型来推断我的Raspberry Pi（Raspbian GNU/Linux 11 Bullseye）面临麻烦。最新版本的 tflite-runtime 似乎是 2.13.0 ，当我运行时，我会遇到以下错误：
  interneter = tflite.interpreter（model_content = tflite_model）
 
  value eRror：找不到内置opcode的op op op opcode&#39;firmon_connected&#39;版本&#39;12&#39;。可以支持此内置的较旧版本。您是否正在使用具有较新型号的旧Tflite二进制文件？
 
我确实知道，如果我将张力流降低到2.13并训练+量化我的型号，但是我有30个型号需要大约2周的时间来培训和量化我的资源。，我确实可以解决此问题。
我可以在Raspberry Pi上使用最新的 tflite-Interpreter 吗？在这方面的任何帮助都很好！
 PC ]]></description>
      <guid>https://stackoverflow.com/questions/79559242/tflite-runtime-valueerror-didnt-find-op-for-builtin-opcode-fully-connected-v</guid>
      <pubDate>Mon, 07 Apr 2025 06:55:44 GMT</pubDate>
    </item>
    <item>
      <title>如何将标签编码值标记以比较结果，（产品代码描述）[封闭]</title>
      <link>https://stackoverflow.com/questions/79558994/how-to-revers-label-encoded-values-to-compare-the-results-product-code-descri</link>
      <description><![CDATA[ i标记了数据集中的所有列，在运行了随机孔后，我想找到“每个产品代码描述”中有多少个记录。得到正确的结果，我该怎么做？
我想通过“产品代码描述” 查看结果]]></description>
      <guid>https://stackoverflow.com/questions/79558994/how-to-revers-label-encoded-values-to-compare-the-results-product-code-descri</guid>
      <pubDate>Mon, 07 Apr 2025 02:50:50 GMT</pubDate>
    </item>
    <item>
      <title>如何消除功能生成期间自定义某些服务的需求[关闭]</title>
      <link>https://stackoverflow.com/questions/79558725/how-to-remove-the-need-for-custom-deployment-of-some-services-during-feature-gen</link>
      <description><![CDATA[每当我必须运行功能生成器时，我都需要切换到另一个分支并在代码中进行一些更改，例如在什么日期范围内运行的DATE范围，并且在部署中进行了一些更改。yaml，service.yaml文件等。然后，我部署了 userAttribute  and strong&gt;和   useractivity   Service。  如何消除自定义部署这些服务的需求？
这些是我遵循的步骤：
生成ML功能
鉴于Zentari的大小，因此在使用Prod群集的Zentari运行功能生成器中现有问题，我们遵循以下步骤为Zentari生成ML功能。
🚨caution：非常仔细地按照步骤
产卵自定义BT实例
🚨深吸一口气。仔细记下名称。验证在任何最终操作之前提到的所有名称 /配置（创建 /修复 /删除）&lt; / p&gt;
您将需要从PAM中扮演Boogtable Admin角色。
备份NOVEXA-DATA实例。选择群集NOVEXA-DATA-JP-C1从中备份。用格式Zentari-FG-Backup-给备份一个有意义的名称。 [yyyymmdd]选择备份到期为1天。
创建一个具有以下配置的新大表实例
名称和ID：Zentari-Training-Data-Instance 
存储类型：SSD 
群集ID：Zentari-training-data-insta-c1 
区域：亚洲 - 东北1（东京）
区域：任何
节点缩放模式：自动化（最小节点：5，最大节点：8）
转到novexa-data实例→备份。选择您创建的备份。单击还原。从实例下拉列表中选择实例zentari-training-data-instance。将表ID作为HB-prod-data-backup。单击创建。
进行更改以准备要功能生成器
将PR中的分支拉动，然后对Master的最新更改进行更新。请注意，请仔细注意文件feature generatorPipeline.kt，它仅在处理时间戳时具有生成功能的流动。 
更新文件：
 userActivity/eventtransfer/featuregenerator/src/src/ain/kotlin/io/novexa/userActivity/eventtransfer/eventtransfer/featuregenerator/options.kt 
在Snapshottimestamp中更新日期到最后一个日期 + 1，您想生成功能。 （例如：今天-2D + 1）
末日更新到您要生成的SnapShotTimestamp的天数。
部署功能生成器＆amp; prod上的用户属性批处理服务。这应该在工作负载中提出实例zentari-eventtransfer-featureGenerator。
 ./ deploy/dev/decloy.sh jp-prod：userAttribute：service：debolyall 
 ./ deploy/dev/decloy.sh JP-prod：userActivity：EventTransfer：featuregenerator：Decloperall 
开始工作并监视
作业完成后，删除自定义的bigtable实例zentari-training-data-instance和backup zentari-fg-backup-您从BigTable创建了为此实例创建的。
还删除了名称：
 zentari-userattribute-batch-service-deployment ]]></description>
      <guid>https://stackoverflow.com/questions/79558725/how-to-remove-the-need-for-custom-deployment-of-some-services-during-feature-gen</guid>
      <pubDate>Sun, 06 Apr 2025 20:47:13 GMT</pubDate>
    </item>
    <item>
      <title>在Kaggle中使用thundersvm</title>
      <link>https://stackoverflow.com/questions/79243091/using-thundersvm-in-kaggle</link>
      <description><![CDATA[当我想使用！PIP安装Thundersvm 安装thundersvm时，我遇到了此错误：
在
Oserror Trackback（最近的最新电话）
[6]中的单元，第3行
      1 get_ipython（）。run_line_magic（&#39;pip&#39;，&#39;安装thundersvm&#39;）
      2 get_ipython（）。run_line_magic（&#39;pip&#39;，&#39;安装keras_tuner&#39;）
----＆gt; 3来自Thundersvm进口SVC
      4来自Sklearn.Perprecorsing Import StandardardScaler
      5来自Sklearn.metrics Import Classification_Report

file/opt/conda/lib/python3.10/site-packages/thundersvm/__init__.py:10
      3“”
      4 *名称：__init__.py
      5 *作者：locke＆lt; luojiahuan001@gmail.com&gt;
      6 *版本：0.0.1
      7 *描述：
      8“”
      9名=“ Thundersvm”
---＆gt; 10来自.thundersvm进口 *

file/opt/conda/lib/python3.10/site-packages/thundersvm/thundersvm.py:39
     36 lib_path =路径。
     38如果path.exists（lib_path）：
---＆gt; 39 thundersvm = cdll（lib_path）
     40其他：
     41＃尝试构建目录
     42如果平台==“ Linux”或platform ==＆quot＆quot2＆quot;：

file/opt/conda/lib/python3.10/ctypes/__init__.py:374，在cdll .__ Init __（self，name，name，mode，hander，hander，use_errno，use_last_error，winmode）
    371 self._funcptr = _funcptr
    373如果没有手柄：
 - ＆gt; 374 self._handle = _dlopen（self._name，模式）
    375其他：
    376 self._handle =句柄

Oserror：libcusparse.so.9.0：无法打开共享对象文件：没有此类文件或目录
 
为了解决此问题，我尝试了此操作：
 ＃下载并安装cuda 9.0
wget https://developer.nvidia.com/compute/cuda/9.0/prod/local_installers/cuda_9.0.176_384.81_linux-run
sudo sh cuda_9.0.176_384.81_linux-run
 
也无效。我该如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/79243091/using-thundersvm-in-kaggle</guid>
      <pubDate>Mon, 02 Dec 2024 06:08:54 GMT</pubDate>
    </item>
    <item>
      <title>tensorboard的add_hparams（）函数无法正常工作</title>
      <link>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</link>
      <description><![CDATA[我正在尝试将指标添加到此摘要Writer，但它不起作用。
我正在使用summarywriter的add_hparams（）函数，其详细信息可以在此处找到： https://pytorch.org/docs/stable/tensorboard.html 。
我这样做：
  writer = summaryWriter（f&#39;runs/lstm_experiment_final&#39;）

对于tqdm（range（num_epochs））中的e：
    tr_loss，tr_f1，tr_precision，tr_recall = triending_loop（型号，train_dataloader，loss_function，优化器，e，writer）
    val_loss，val_f1，val_precision，val_recall = validation_loop（型号，test_dataloader，loss_function，e，e，writer）

metric_dict = {&#39;损失/火车&#39;：tr_loss，&#39;损失/有效&#39;：val_loss，
                         &#39;F1/train&#39;：tr_f1，&#39;f1/有效&#39;：val_f1，
                         “精确/火车”：tr_precision，“精确/有效”：val_precision，
                         “召回/火车”：tr_recall，&#39;召回/有效&#39;：val_recall}
writer.add_hparams（best_params，metric_dict，global_step = num_epochs-1）
writer.close（）    
 
这就是发生的事情。
 在此处输入图像说明 
换句话说，超参数确实在张板上记录，但公制值不是。
我希望有人已经看到我的问题，并且知道如何解决这个问题。
预先感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</guid>
      <pubDate>Sun, 11 Aug 2024 00:21:56 GMT</pubDate>
    </item>
    <item>
      <title>如何获得随机森林算法在自变量上使用的最终方程式来预测因变量？</title>
      <link>https://stackoverflow.com/questions/54212769/how-to-get-the-final-equation-that-the-random-forest-algorithm-uses-on-your-inde</link>
      <description><![CDATA[我正在努力优化基于制造的数据集，该数据集由大量可控参数组成。目标是获得这些参数的最佳运行设置。
我在进行研究时熟悉了几种预测算法，如果我说，请使用随机森林来预测我的因变量以了解每个自变量的重要性，有没有一种方法来提取算法使用的最终方程/关系？]]></description>
      <guid>https://stackoverflow.com/questions/54212769/how-to-get-the-final-equation-that-the-random-forest-algorithm-uses-on-your-inde</guid>
      <pubDate>Wed, 16 Jan 2019 08:14:52 GMT</pubDate>
    </item>
    </channel>
</rss>