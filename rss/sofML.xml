<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 09 Dec 2023 00:59:30 GMT</lastBuildDate>
    <item>
      <title>实时多重检测 (RTMDet) CONFIG_PATH fileNotFoundError</title>
      <link>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</link>
      <description><![CDATA[我正在尝试遵循 Roboflow 指南&lt; /a&gt; 在自定义数据集上训练 RTMDet。我没有高端 GPU，因此我尝试使用 Colab 环境。
当我尝试使用 rtmdet_m 权重和配置文件初始化模型时，我收到 filenotfound 错误，即使我 100% 肯定文件存在于驱动器目录中。我相信这个问题与下面的配置文件中的 Base 有关
_base_ = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;



# ========================修改参数======================
加深因子 = 0.67
加宽因子 = 0.75

# =======================大多数情况下未修改==================
模型=字典（
主干=字典（深度因子=深度因子，加宽因子=加宽因子），
颈部=字典（深度因子=深度因子，加宽因子=加宽因子），
bbox_head=dict(head_module=dict(widen_factor=widen_factor)))

我还尝试将配置文件移动到本地 /content 目录，但它没有解决问题
这是我用于初始化的其余代码以及确切的错误消息
# 设置配置和权重文件的路径
WEIGHTS_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-
300e_coco_20230102_135952-40af4fe8.pth&#39;
CONFIG_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-300e_coco.py&#39;

# 初始化模型
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

-------------------------------------------------- ------------------------
FileNotFoundError Traceback（最近一次调用最后一次）
&lt;ipython-input-61-1d88a7ed1feb&gt;在&lt;细胞系：3&gt;()
      1 # 初始化模型
      2 DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
----&gt; 3 模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

5帧
_is_lazy_import(文件名)中的/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py
   第1653章
   第1654章
-&gt;第1655章
   第1656章
   第1657章

FileNotFoundError: [Errno 2] 没有这样的文件或目录:
&#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</guid>
      <pubDate>Fri, 08 Dec 2023 23:50:24 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将 n 个文件夹中的一组图像转换为数据集（例如：Mnist），以便与 CNN 一起使用？</title>
      <link>https://stackoverflow.com/questions/77629619/is-it-possible-to-convert-a-group-of-images-in-n-folders-to-be-converted-in-to-d</link>
      <description><![CDATA[我正在尝试将生成的图像转换为数据集。（我所拥有的只是 n 个文件夹中的 png 图像，并且没有标签或元数据）
这就是我渴望做的事情：

我正在使用 torch audio 将音频格式转换为 Mel 频谱图并将图像保存为 Png 格式。状态：完成

现在我有“n”个带有图像的文件夹（类），所以我很好奇是否可以将新生成的图像转换为数据并
像普通数据集中一样的目标，这样我就可以使用 sklearn 来执行
测试列车分割sklearn.model_selection.train_test_split


。
状态：未完成
例如：获取 mnist 数据集
&lt;块引用&gt;
ds_mnist = sklearn.datasets.fetch_openml(
数据 ID=554，
as_frame=假
）
将数据和目标拆分为 X 和 y

dataset_X = ds_mnist .data.astype(&#39;float32&#39;)
dataset_y = ds_mnist .target.astype(&#39;int64&#39;)]]></description>
      <guid>https://stackoverflow.com/questions/77629619/is-it-possible-to-convert-a-group-of-images-in-n-folders-to-be-converted-in-to-d</guid>
      <pubDate>Fri, 08 Dec 2023 23:30:07 GMT</pubDate>
    </item>
    <item>
      <title>为深度学习项目寻找替代库[关闭]</title>
      <link>https://stackoverflow.com/questions/77629191/looking-for-alternate-libraries-for-a-deep-learning-project</link>
      <description><![CDATA[我有Python 3.12.0。我的项目需要 TensorFlow，但它只能与 Python 3.11 一起使用。 PyTorch 也是如此。有谁知道我可以使用其他库来代替我提到的库，并且与 Python 3.12 兼容？尝试安装 TensorFlow 和 PyTorch。]]></description>
      <guid>https://stackoverflow.com/questions/77629191/looking-for-alternate-libraries-for-a-deep-learning-project</guid>
      <pubDate>Fri, 08 Dec 2023 21:09:44 GMT</pubDate>
    </item>
    <item>
      <title>如何提取 SequentialFeatureSelector 的最佳估计器</title>
      <link>https://stackoverflow.com/questions/77629138/how-to-extract-best-estimator-of-a-sequentialfeatureselector</link>
      <description><![CDATA[我已经从 sklearn 训练了一个 SequentialFeatureSelector，现在对它生成的最佳模型（基于给定的评分方法）感兴趣。是否有可能提取参数并使用它们生成所使用的模型？
我已经看到 SequentialFeatureSelector 存在一个 get_params() 函数，但我不明白如何解释输出并检索最佳估计器。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77629138/how-to-extract-best-estimator-of-a-sequentialfeatureselector</guid>
      <pubDate>Fri, 08 Dec 2023 20:58:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 WEKA 检测信用卡欺诈？需要帮助</title>
      <link>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</link>
      <description><![CDATA[我的计算机科学模块有这项作业。我需要使用 WEKA 来检测哪些用户可能拖欠信用卡到期付款。
我是 WEKA 的新手，所以有点困难。我收到了一个包含 48 个属性的 CSV，其中包括一个类：defaultnmIndicator 下个月默认的指示器（1=是，0=否）。
我需要预测，所以我知道我需要一个分类器。其中很多都是灰色的，包括 j48 和后勤。
例如，当我对整个集合运行线性回归时，相关系数约为 0.48。
我认为我在这里遗漏了一些非常明显的步骤。我的讲师刚刚建议我们搜索 YouTube，所以您可以想象这有多大帮助？
尝试的步骤：

我对数据集进行了标准化
估算缺失数据
使用完整训练集运行 CorrelationAttributeEval
尝试添加或删除此列表底部和顶部的属性，但模型没有得到真正的改进。
前 3 名：
`排名属性：
0.32588 43 金融压力指数
0.26159 22 平均循环信用卡利用率
0.24705 23 平均活跃信用额度利用率

&lt;小时/&gt;
底部3
-0.2096 30 任期最旧信用额度
-0.22082 自上次错过付款后 29 天
-0.40432 2 信用评分
`
我期望获得更高的相关系数。
有什么想法吗？有什么想法吗？
谢谢！！！]]></description>
      <guid>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</guid>
      <pubDate>Fri, 08 Dec 2023 20:33:44 GMT</pubDate>
    </item>
    <item>
      <title>在张量流中加载包含预训练模型层的层的权重</title>
      <link>https://stackoverflow.com/questions/77628549/loading-weights-for-layer-containing-layers-of-a-pretrained-model-in-tensorflow</link>
      <description><![CDATA[我一直在张量流中尝试对象检测器（v.2.14）提前感谢您的帮助！
最好的问候，埃里克
最近，我陷入了想要用我的模型迁移学习的地步。
我使用以下结构训练了 CNN 对象检测器
模型
    -layer_old_1
    -layer_old_2
    -layer_old_3
    -layer_old_4
    -...

现在我想将预训练的 CNN 检测器的权重转移到具有结构的新模型中
模型
    -编码器层
        -layer_old_1
        -layer_old_2
        -layer_old_3
    -解码器层
        -layer_new_1
        -layer_new_2
        -layer_new_3

我的旧模型的重量保存在 weights.hdf5 文件中。
我同时遇到了多个挑战：

我需要加载一层的权重，而不是整个模型。通常，我会使用带有“by_name”选项的 load_weigths，但由于我的旧层已合并到 encoder_layer 中，我认为名称已更改（从 layer_old_1 更改为  &gt;encoder_layer/layer_old_1）。
我剪掉了之前训练的模型的一些层。如果我不使用层的 set_weights 中不存在的选项“by_name”，我很可能会出现权重大小不匹配的情况

到目前为止，我唯一可行的想法是重新训练旧模型并调整其结构
模型
    -编码器层
        -layer_old_1
        -layer_old_2
        -layer_old_3
        -layer_old_4
        -...

这会导致大量的时间损失]]></description>
      <guid>https://stackoverflow.com/questions/77628549/loading-weights-for-layer-containing-layers-of-a-pretrained-model-in-tensorflow</guid>
      <pubDate>Fri, 08 Dec 2023 18:32:53 GMT</pubDate>
    </item>
    <item>
      <title>实施跟踪器以在视频帧中保存汽车的 OCR 结果</title>
      <link>https://stackoverflow.com/questions/77628515/implementing-tracker-to-persist-ocr-results-for-cars-in-video-frames</link>
      <description><![CDATA[我有一个 Python 函数，Detect_and_draw_cars 在循环中使用并给定视频帧，它利用 YOLO 来识别并绘制视频每一帧中汽车周围的边界框。此外，该函数还会对这些边界框中的感兴趣区域（如果找到）执行 OCR，以提取车牌（函数 box4）。
为了优化 OCR 处理，我希望实现一个 OpenCV 跟踪器，它可以在多个帧上跟踪汽车的中心。目标是每辆车每 60 帧左右更新一次 OCR 结果，因为汽车的形状和方向随着时间的推移逐渐变化，我正在考虑通过它们的中心跟踪图像。
如果 tracked_cars[car_id][“frames_since_last_ocr”] == 60：
   car_roi = 图像[y1:y2, x1:x2]
   ocr_结果 = box4(car_roi)

我掌握了 openCV 跟踪器的想法，但在有很多不同跟踪器的情况下，我遇到了障碍。我正在寻求有关如何集成 OpenCV 跟踪器的指导，该跟踪器可以跨帧有效跟踪汽车的中心，确保每辆车的 OCR 结果仅每 60 帧更新一次。任何代码片段、建议或示例将不胜感激。
这是实现跟踪器之前的现有代码片段：
def detector_and_draw_cars（图像）：
    汽车图像，汽车坐标= yolo_predire（图像）
    对于 i，(x1，y1，x2，y2) 在 enumerate(car_coordinates) 中：
        结果=[]

        cv2.矩形(图像, (x1, y1), (x2, y2), (0, 255, 0), 2)
        car_roi = 图像[y1:y2, x1:x2]

        结果 = box4(car_roi)
        如果结果：
          打印（结果）
          ocr_text = f&quot;{结果[0][-2]} - {(结果[0][-1]*100):.2f}%&quot;
          text_size, _ = cv2.getTextSize(ocr_text, cv2.FONT_HERSHEY_SIMPLEX, 2, 1)
          cv2.矩形(图像, (x1, y1 - 文本大小[1] - 10), (x1 + 文本大小[0] + 10, y1), (255, 255, 255), -1)
          cv2.putText(图像, ocr_text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)

    返回图像

我尝试为视频帧中的多个对象实现 openCV 跟踪器，但无法让它循环工作]]></description>
      <guid>https://stackoverflow.com/questions/77628515/implementing-tracker-to-persist-ocr-results-for-cars-in-video-frames</guid>
      <pubDate>Fri, 08 Dec 2023 18:23:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么tensorflow的AudioIOTensor的WAV文件的张量输出与decode_wav不同？</title>
      <link>https://stackoverflow.com/questions/77628394/why-does-tensor-output-for-wav-file-from-tensorflows-audioiotensor-differ-that</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77628394/why-does-tensor-output-for-wav-file-from-tensorflows-audioiotensor-differ-that</guid>
      <pubDate>Fri, 08 Dec 2023 17:55:59 GMT</pubDate>
    </item>
    <item>
      <title>不确定为什么我在 Snowflake 上使用 Python 进行逻辑回归时会遇到类型错误？</title>
      <link>https://stackoverflow.com/questions/77628292/unsure-why-im-running-into-type-errors-in-logistic-regression-using-python-on-s</link>
      <description><![CDATA[我正在使用 Python 在 Snowflake 上创建逻辑回归模型。我在本地 R 中做了相同的逻辑回归，但想将其转换到我的 Snowflake 数据仓库。我取得了一些成功，但我对 Python 的熟悉度还不如对 R 的熟悉度。
我相信回归是拟合并给出了一个模型。我真的不知道预测的概率是什么样的，但这确实是目前的次要问题。
我只想从 pandas DataFrame 返回一个雪花 DataFrame。我无法让它发生。
下面是我的代码片段。
导入snowflake.snowpark作为snowpark
导入 Snowflake.snowpark.functions 作为 F
从 sklearn.linear_model 导入 LogisticRegression
从 Snowflake.snowpark.functions 导入 col
将 pandas 导入为 pd

def main（会话：snowpark.Session）：
#
# 下面的一切都是数据转换，一切都工作得很好
＃ 据我所知

# ind_cols 和 dep_cols 是列名数组
# 定义哪些列是自变量，哪些列是因变量。
# 这里我将样本分为独立列和从属列，
# 并使用 scikit-learn 中的 LogisticRegression。

    X = full_sample[ind_cols].to_pandas()
    y = full_sample[dep_col].to_pandas()

# ret_df 是我有兴趣预测概率的雪花数据帧。
    ret_df_lm = ret_df[ind_cols].to_pandas()

    lm = 逻辑回归()

    lm.fit(X, y)

    y_pred = lm.predict_proba(ret_df_lm)

    y_final = session.table(y_pred)

    #retention_pred = lm.predict(ret_df)

    返回 y_final

当我尝试返回y_final时，我收到错误TypeError：序列项0：预期的str实例，找到numpy.ndarray。我一定错过了一些东西。我尝试过其他东西，比如雪花的 session.write_pandas() 但我不确定这是否是我需要的。
如何使 y_final 成为雪花 DataFrame？]]></description>
      <guid>https://stackoverflow.com/questions/77628292/unsure-why-im-running-into-type-errors-in-logistic-regression-using-python-on-s</guid>
      <pubDate>Fri, 08 Dec 2023 17:36:04 GMT</pubDate>
    </item>
    <item>
      <title>用于 Siamese 网络的变压器编码器</title>
      <link>https://stackoverflow.com/questions/77628283/transformer-encoder-for-siamese-networks</link>
      <description><![CDATA[我正在考虑制作面部编码器的方法。我对 Transformer 编码器的工作原理有了直观的了解。据我所知，编码器是双向的，因此可以获取上下文信息，我们能否非常擅长编码......
因此，对于面部编码的图像数据或面部深度数据执行相同的操作是否会更好。
我最初尝试使用 Resnet 和 inceptionnet（均作为暹罗网络）实现 2D 图像的人脸编码器......但想知道我是否可以使用 Transformer 编码器对 3D 数据执行相同的操作3D数据从而获得高精度]]></description>
      <guid>https://stackoverflow.com/questions/77628283/transformer-encoder-for-siamese-networks</guid>
      <pubDate>Fri, 08 Dec 2023 17:34:37 GMT</pubDate>
    </item>
    <item>
      <title>在硬边距 SVM 的背景下，当一个点违反边距时会发生什么？</title>
      <link>https://stackoverflow.com/questions/77628142/in-the-context-of-hard-margin-svms-what-happens-when-a-point-violates-the-margi</link>
      <description><![CDATA[我目前正在自学机器学习理论，并正在阅读有关硬边距和软边距支持向量机的信息。我知道，当我们拥有非线性可分离数据并且我们希望允许一些噪声，这样我们可能会有“违反”标准的点时，软边缘 SVM 会很有用。边距。然而，我想知道与这个想法相关的两个案例，但在硬裕度 SVM 的背景下：(a) 如果向数据集中添加一个“违反”规则的新点硬边际SVM，这一定会导致边际缩小吗？ (b)类似地，如果不是添加新点而是扰乱数据集中已有的点，使得它现在“违反”了数据集。边距，这会导致边距缩小吗？
直观上，我认为边距不一定会缩小，而是硬边距 SVM 不再可行，您会想使用软边距 SVM。例如，如果您正在考虑二元分类问题，如果违规点非常严重，以至于它跨越了决策边界并进入了具有不同分类的点簇，我不知道边距会如何缩小 - 它看来你只能使用软边缘 SVM。]]></description>
      <guid>https://stackoverflow.com/questions/77628142/in-the-context-of-hard-margin-svms-what-happens-when-a-point-violates-the-margi</guid>
      <pubDate>Fri, 08 Dec 2023 17:02:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 解决机器学习分类中类不平衡的优化技术 [关闭]</title>
      <link>https://stackoverflow.com/questions/77627877/optimization-techniques-for-addressing-class-imbalance-in-machine-learning-class</link>
      <description><![CDATA[我正在使用 TensorFlow 进行机器学习分类项目，并且在我的数据集中遇到了严重的类别不平衡问题。正类实例的数量远远多于负类实例，导致模型性能不佳。我正在寻求有关有效技术的指导，以减轻类别不平衡的影响并提高模型的整体性能。
我已经探索了类权重调整和过采样等方法，但我很想了解 TensorFlow 框架内的其他高级方法或最新进展。此外，我想知道是否有任何预处理步骤或模型架构已被证明可以有效处理此类不平衡场景。
您能给我指出相关的研究论文、教程或代码示例吗？我的目标是增强模型正确预测正类实例的能力，同时保持较高的整体准确性。
作为 Open AI 开发的基于文本的 AI 模型，我没有个人经验、意图或期望。我的目的是根据我收到的意见提供帮助和信息。如果您有特定问题或主题需要帮助，请随时询问，我将尽力提供有用的信息！]]></description>
      <guid>https://stackoverflow.com/questions/77627877/optimization-techniques-for-addressing-class-imbalance-in-machine-learning-class</guid>
      <pubDate>Fri, 08 Dec 2023 16:12:19 GMT</pubDate>
    </item>
    <item>
      <title>“机器学习的最佳预处理：解决数据集中的缺失数据和异常值。”</title>
      <link>https://stackoverflow.com/questions/77627148/optimal-preprocessing-for-machine-learning-addressing-missing-data-and-outlier</link>
      <description><![CDATA[在训练机器学习模型之前，如何有效地预处理和清理数据集，尤其是在处理丢失数据和异常值时？
预处理和清理数据集是为机器学习模型准备数据的关键步骤。处理缺失数据和异常值需要仔细考虑]]></description>
      <guid>https://stackoverflow.com/questions/77627148/optimal-preprocessing-for-machine-learning-addressing-missing-data-and-outlier</guid>
      <pubDate>Fri, 08 Dec 2023 14:11:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 tfidf 对象会抛出“没有属性预测”错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77626940/why-is-the-tfidf-object-throwing-the-has-no-attribute-predict-error</link>
      <description><![CDATA[在此处输入图像描述
这是我的代码
在此处输入图片描述
在此处输入图像描述
我正在尝试加载两个预定义模型，一个是 tfidf，另一个是 LR_model，但如果电影评论是正面还是负面，它将进行分类。]]></description>
      <guid>https://stackoverflow.com/questions/77626940/why-is-the-tfidf-object-throwing-the-has-no-attribute-predict-error</guid>
      <pubDate>Fri, 08 Dec 2023 13:32:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 RNN 确定可接受的情感分析基线</title>
      <link>https://stackoverflow.com/questions/77623881/determining-an-acceptable-baseline-for-sentiment-analysis-using-rnns</link>
      <description><![CDATA[按照我发现的教程，我一直在尝试使用循环神经网络 (RNN) 进行情感分析 此处。虽然我的模型可以正常运行，但我在准确性方面遇到了障碍，始终达到 85-90% 之间。我尝试了各种优化，但我不确定什么构成合理的基线来结束我的努力，特别是考虑到基于 Transformer 的 LSTM 模型的潜在效率。
我的主要查询并不是以进一步提高准确性为中心；相反，我寻求指导来确定何时考虑情感分析模型对于实际使用足够有效，特别是在使用 RNN 来完成此任务时。由于我对机器学习比较陌生，因此我不清楚何时确定我的目标已经实现。]]></description>
      <guid>https://stackoverflow.com/questions/77623881/determining-an-acceptable-baseline-for-sentiment-analysis-using-rnns</guid>
      <pubDate>Fri, 08 Dec 2023 01:35:34 GMT</pubDate>
    </item>
    </channel>
</rss>