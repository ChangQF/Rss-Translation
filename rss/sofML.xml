<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 22 Jul 2024 06:22:45 GMT</lastBuildDate>
    <item>
      <title>GPy 回归（高斯过程）中的输出 Gram 矩阵</title>
      <link>https://stackoverflow.com/questions/78776963/output-gram-matrix-in-gpy-regression-gaussian-process</link>
      <description><![CDATA[因为我需要在大量点上训练我的 GP，所以我不仅想保存优化的超参数
ker = GPy.kern.Matern32(nc, ARD=True) 
m = GPy.models.GPRegression(xTrain, np.reshape(yTrain, (-1, 1)), ker, noise_var=1e-8)
m.Mat32.lengthscale.constrain_bounded(0.01, 5e0)
m.Mat32.variance.constrain_bounded(1e-4, 1e+10)
m.Gaussian_noise.variance.constrain_fixed(1e-8)

m.optimize_restarts(messages=True, num_restarts=1, max_f_eval=10000)
np.save(f, m.param_array)

yPrd, yVar = m.predict_noiseless(xTest)
yStd = np.sqrt(yVar)
yPred = np.squeeze(yPrd)

但也要保存 Gram 矩阵与观测值 K(s,s)^{-1} f 的乘积
后验均值 = K(s^*,s)K(s,s)^{-1} f
这样加载块 K(s,s)^{-1} f 并仅与相应的测试点 K(s^*,s) 执行一次乘法。我如何访问/输出这些矩阵/保存它们？]]></description>
      <guid>https://stackoverflow.com/questions/78776963/output-gram-matrix-in-gpy-regression-gaussian-process</guid>
      <pubDate>Mon, 22 Jul 2024 04:33:20 GMT</pubDate>
    </item>
    <item>
      <title>使用经过 Gamma 风险暴露数据训练的机器学习模型预测期权到期效应 [关闭]</title>
      <link>https://stackoverflow.com/questions/78776893/predicting-the-options-expiration-effect-using-machine-learning-models-trained-w</link>
      <description><![CDATA[我正在尝试实现一篇论文。它适用于机器学习和股票市场数据，我已经收集了有关研究论文的训练所需的所有数据。如果有人知道如何训练有关这篇论文的模型，请重播。
研究论文
我尝试过模型，但我对机器学习不是很熟悉，我不知道我做的是否正确]]></description>
      <guid>https://stackoverflow.com/questions/78776893/predicting-the-options-expiration-effect-using-machine-learning-models-trained-w</guid>
      <pubDate>Mon, 22 Jul 2024 03:52:53 GMT</pubDate>
    </item>
    <item>
      <title>模型需要很长时间才能加载 [tf.keras.models.load_model]</title>
      <link>https://stackoverflow.com/questions/78776878/model-taking-forever-to-load-tf-keras-models-load-model</link>
      <description><![CDATA[我尝试在 Visual Studio Code 上本地加载模型，但当我运行脚本时，它卡在加载模型行。我已在 Google Collab 上使用 CPU 成功运行该脚本，因此我不认为这是计算能力不足造成的，并且在运行脚本时，我的 CPU 容量只有 25%。有人知道为什么会发生这种情况吗？
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.applications.resnet import preprocess_input
import pickle

# 列出可用的 GPU
gpus = tf.config.list_physical_devices(&#39;CPU&#39;)

if gpus:
print(&quot;CPU found:&quot;, gpus)
else:
print(&quot;No CPU found.&quot;)
...
model = tf.keras.models.load_model(&#39;multi_output_model.h5&#39;)
print(&quot;model loaded&quot;)
...

VSC 终端：
(classificationenv) C:\Users\Lenovo\Documents\classification&gt;python certification.py
2024-07-22 12:29:17.362739：我 tensorflow/core/util/port.cc:153] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 `TF_ENABLE_ONEDNN_OPTS=0`。
2024-07-22 12:29:19.621902：我 tensorflow/core/util/port.cc:153] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 `TF_ENABLE_ONEDNN_OPTS=0`。
找到 CPU：[PhysicalDevice(name=&#39;/physical_device:CPU:0&#39;, device_type=&#39;CPU&#39;)]
2024-07-22 12:29:26.002626：I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 AVX512F AVX512_VNNI FMA，在其他操作中，请使用适当的编译器标志重建 TensorFlow。

模型来源：https://www.kaggle.com/code/stdntlfe/fashion-styles-final/notebook
]]></description>
      <guid>https://stackoverflow.com/questions/78776878/model-taking-forever-to-load-tf-keras-models-load-model</guid>
      <pubDate>Mon, 22 Jul 2024 03:43:36 GMT</pubDate>
    </item>
    <item>
      <title>使用python图像去噪没有得到想要的重建图像</title>
      <link>https://stackoverflow.com/questions/78776540/not-getting-desired-reconstructed-image-with-python-image-denoising</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78776540/not-getting-desired-reconstructed-image-with-python-image-denoising</guid>
      <pubDate>Sun, 21 Jul 2024 23:19:13 GMT</pubDate>
    </item>
    <item>
      <title>目标文件的对称拟合问题</title>
      <link>https://stackoverflow.com/questions/78776322/symmetry-fitting-problem-with-target-file</link>
      <description><![CDATA[我正在构建一个有 6 列和 6700 行的数据集。该数据是从不同研究的各种蒙特卡罗模拟中提取的光子剂量转换系数获得的。数据中的列包括能量、器官名称、器官质量、器官密度、AP 剂量、PA 剂量和横向剂量。能量行表示从 1keV 到 20 MeV 的每个能量箱计算出的剂量，分为 20 个箱。每个箱重复器官名称、器官质量和器官密度。
如果我们排除器官名称，数据可用于数值拟合。但是，如果我们使用独热编码器对器官名称进行编码，则可以更有效地使用数据，并且交叉验证比仅有数值数据显示出更好的结果。不同器官的剂量取自不同的幻像，其中一些幻像比其他幻像拥有更多的器官。使用独热编码器后，合并的器官总数为 32。
当尝试从新的模型中预测器官时，问题就出现了，因为模型显示输入和目标文件之间存在对称性错误。我的问题是，我们如何解决这个问题？
如果我使用一个带有 1000 个箱子的模型来表示 20 个器官，并预测另一个带有 1000 个箱子的模型，其中 20 个器官完全相同，但器官质量和密度不同，则该文件有效
如何使用分类整体数据（来自 32 个器官的 6700 个箱子来预测（32 个器官的 1000 个箱子）？]]></description>
      <guid>https://stackoverflow.com/questions/78776322/symmetry-fitting-problem-with-target-file</guid>
      <pubDate>Sun, 21 Jul 2024 20:47:32 GMT</pubDate>
    </item>
    <item>
      <title>我们如何通过解决问题的能力来提高问题分析和设计能力？[关闭]</title>
      <link>https://stackoverflow.com/questions/78775745/how-can-we-improve-problem-analysis-and-design-skills-through-problem-solving-ab</link>
      <description><![CDATA[我希望提高我的问题分析和设计技能，并了解提高我的问题解决能力是这一过程的关键部分。作为一名在 Python、Java、机器学习和数据科学方面有经验的程序员，我想知道：

在开始编码之前，系统地分析问题的最佳实践或方法是什么？
如何有效地将复杂问题分解为可管理的部分？
是否有特定的练习或项目类型可以帮助提高我的问题解决和设计技能？
如何将计算机科学的概念（如算法、数据结构和设计模式）应用于现实世界的问题解决场景？
推荐哪些资源（书籍、课程、在线平台）来提高这些技能？
]]></description>
      <guid>https://stackoverflow.com/questions/78775745/how-can-we-improve-problem-analysis-and-design-skills-through-problem-solving-ab</guid>
      <pubDate>Sun, 21 Jul 2024 16:28:07 GMT</pubDate>
    </item>
    <item>
      <title>如何优化递归多步预测以提高性能？</title>
      <link>https://stackoverflow.com/questions/78775642/how-to-optimize-recursive-multi-step-forecasting-to-improve-performance</link>
      <description><![CDATA[我正在开发一个用于每小时销售预测的机器学习项目。我需要提前 7 天进行销售预测。我的模型 (XGBoost) 使用 24 小时前的滞后销售作为输入之一，为了能够在生产中使用它，我必须使用预测值作为第二天预测的滞后特征。我目前使用的递归实现非常慢，需要几分钟才能完成，这是不可行的，因为我每天需要为数百个模型运行它。
当前实现
下面是我正在使用的代码：
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def predict_7_days_ahead(model, X_test, y_test, transform_target_func):
y_pred_df = pd.DataFrame()
input_forecasts_df = pd.DataFrame()

concatenated_df = pd.concat([X_test, y_test], axis=1)

for hour in concatenated_df.index.hour.unique():
print(f&quot;Processing hour: {hour}&quot;)
df = concatenated_df[concatenated_df.index.hour == hour]

for index, row in df.iterrows():
data = df.copy(deep=True)
predictions = []

for steps_ahead in range(8): # 0 到 7
datetime = index + pd.Timedelta(days=steps_ahead)

if datetime in data.index:
row = data.loc[datetime]
X = row.drop(&#39;sales&#39;).values.reshape(1, -1)
y_pred = model.predict(X)
y_pred = transform_target_func(y_pred, method=&#39;log&#39;, how=&#39;inverse&#39;)

col_name = &#39;sales(t)&#39; if steps_ahead == 0 else f&#39;sales(t+{steps_ahead})&#39;
y_pred_df.loc[index, col_name] = y_pred[0]

predictions.append(y_pred[0])

# 更新第二天的滞后特征
next_day_index = datetime + pd.Timedelta(days=1)
if next_day_index in data.index:
for lag in range(1, min(len(forecasts) + 1, 8)):
data.loc[next_day_index, f&#39;sales_lag_{lag}&#39;] = Forecasts[-lag]

input_forecasts_df = pd.concat([input_forecasts_df, row.to_frame().T])

return y_pred_df, input_forecasts_df

def convert_y_test_to_multi_steps_ahead(y_test, steps_ahead=7):
sales = y_test.copy(deep=True)
sales.index = pd.to_datetime(sales.index)
sales = sales.to_frame(name=&#39;sales(t)&#39;)

for i in range(1, steps_ahead+1):
sales[f&#39;sales(t+{i})&#39;] = sales[&#39;sales(t)&#39;].shift(-15*i) # 从 24 更改为 15

return sales

def calculate_and_plot_accuracy(actual_df, Forecast_df, column_prefix=&#39;sales(t&#39;, Threshold=80):
columns = [col for col in Forecast_df.columns if col.startswith(column_prefix)]
columns.sort(key=lambda x: int(x.split(&#39;+&#39;)[-1][:-1]) if &#39;+&#39; in x else 0)

accuracies = []

for column in columns:
if column not in actual_df.columns or column not in Forecast_df.columns:
print(f&quot;在一个或两个数据框中未找到列 {column}。&quot;)
continue

actual = actual_df[column]
Forecast = Forecast_df[column]

accuracy = ((100 - np.abs(actual - Forecast) / actual * 100) &gt;= Threshold).mean() * 100
accuracies.append(accuracy)

# 绘图
plt.figure(figsize=(12, 6))
plt.plot(columns, accuracies, marker=&#39;o&#39;)
plt.title(f&quot;每个步骤的预测准确度 (阈值：{threshold}%)&quot;)
plt.xlabel(&quot;预测步骤&quot;)
plt.ylabel(&quot;准确度 (%)&quot;)
plt.ylim(0, 100)
plt.xticks(rotation=45, ha=&#39;right&#39;)

for i, (col, accuracy) in enumerate(zip(columns, accuracies)):
plt.annotate(f&#39;{accuracy:.2f}%&#39;, (col, accuracy), textcoords=&quot;offset points&quot;, xytext=(0,10), ha=&#39;center&#39;)

plt.tight_layout()
plt.show()

y_pred_df, input_forecasts_df = predict_7_days_ahead(model, X_test, y_test, transform_target)
y_test_multi = convert_y_test_to_multi_steps_ahead(y_test, steps_ahead=7)
calculate_and_plot_accuracy(y_test_multi, y_pred_df, column_prefix=&#39;sales(t&#39;,阈值=80)


是否有任何最佳实践或技术可以优化此递归预测过程？
如何在保持预测准确性的同时提高此函数的性能？
在这种情况下，矢量化操作或使用特定库（例如 Dask、Joblib）是否有帮助？]]></description>
      <guid>https://stackoverflow.com/questions/78775642/how-to-optimize-recursive-multi-step-forecasting-to-improve-performance</guid>
      <pubDate>Sun, 21 Jul 2024 15:45:41 GMT</pubDate>
    </item>
    <item>
      <title>我想使用基于 PCA 的人脸识别技术对 Yaledatabase 进行识别，并使用留一交叉验证法测量识别率</title>
      <link>https://stackoverflow.com/questions/78775565/i-want-to-use-pca-based-face-recognition-for-yaledatabase-and-measure-the-recogn</link>
      <description><![CDATA[我不确定增加特征向量的数量却没有看到识别率发生明显变化有什么问题。我使用的 yaledatabase 总共有 15 组，我通过对每组留一然后除以总数据集来获得识别率，但我不确定哪里出了问题……
import numpy as np
import cv2
import os
from numpy import linalg as LA
def read_images(path):
images = []
filenames = []
for root, dirs, files in os.walk(path):
for index, file in enumerate(files):
if(file.endswith(&#39;.gif&#39;)):
img_path = os.path.join(root, file)
img = loadImageFromPath(img_path)
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_resized = cv2.resize(img_gray, (20,20))
img_normalized = img_resized / 255.0 
images.append((img_normalized, index))
filenames.append(file)
else:
img_path = os.path.join(root, file)
img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
if img_gray 不为 None:
img_resized = cv2.resize(img_gray, (20,20))
img_normalized = img_resized / 255.0 
images.append((img_normalized, index))
filenames.append(file)
返回图像、文件名
def loadImageFromPath(imgPath):
try:
if str(imgPath).lower().endswith(&#39;.gif&#39;):
gif = cv2.VideoCapture(imgPath)
ret, frame = gif.read() # 如果找到帧则 ret=True，否则为 False。
if ret:
返回帧
else:
返回 cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)
除 Exception 外，因为 e:
print(e)
返回 None

def image_as_row(x):
返回 x.flatten()

def covariance(m):
返回 np.cov(m, rowvar=False) 

def eigenvector(m, k):
w, v = np.linalg.eig(m)
idx = np.argsort(w)[::-1][:k] 
返回 v[:, idx] 

def im_map(image, mean, mv):
new = image_as_row(image)
new = np.subtract(new, mean)
返回 np.dot(new, mv)

def Euclidean_distance(v1, v2):
返回np.sqrt(np.sum(np.power((v1 - v2), 2)))

def find_similar(image, tagged):
distances = [Euclidean_distance(image, m) for m in tagged]
return np.argmin(distances)

def leave_one_out(images, k):
if len(images) == 0:
print(&quot;Error: 没有要处理的图像在 leave_one_out&quot;)
return 0
correct_predictions = 0
n = len(images)

for leave_out_index in range(n):
test_image, test_image_index = images[leave_out_index]
train_images = images[:leave_out_index] + images[leave_out_index + 1:]

vector = np.array([image_as_row(image[0]) for image in train_images])
mean_train = vector.mean(axis=0)
diff = np.subtract(vector, mean_train)
cov = covariance(diff) / len(train_images)
mv = eigenvector(cov, k)

mapped_train = np.dot(diff, mv)
new_image = im_map(test_image, mean_train, mv)

index = find_similar(new_image,mapped_train)
print(f&quot;测试图像 {test_image_index} 与训练图像 {index} 最相似&quot;)

if leave_out_index == index:
correct_predictions += 1

recognition_rate = correct_predictions / n
return identification_rate

def main():
base_path = &#39;Yaledatabase_full/data&#39;
num_sets = 10
images_per_set = 10
k = 10 # Number主成分

all_recognition_rates = []
for set_index in range(1, num_sets + 1):
set_path = os.path.join(base_path, f&quot;{set_index:01d}&quot;)
images, filenames = read_images(set_path)

print(f&quot;Images in set {set_index}:&quot;)
for idx, filename in enumerate(filenames):
print(f&quot;Index: {idx}, Filename: {filename}&quot;)

recognition_rate = leave_one_out(images, k)
all_recognition_rates.append(recognition_rate)
print(f&#39;Recognition rate for set {set_index}: {recognition_rate * 100:.2f}%&#39;)
print(&#39;---------------------------------------------&#39;)

overall_recognition_rate = np.mean(all_recognition_rates)
print(&#39;---------------------------------------------&#39;)
print(f&#39;总体识别率为 {overall_recognition_rate * 100:.2f}%&#39;)

if __name__ == &quot;__main__&quot;:
main()

我想知道，当有 100 个特征向量时，基于 PCA 技术的人脸识别的识别率是否约为 40%，如各种论文所示。]]></description>
      <guid>https://stackoverflow.com/questions/78775565/i-want-to-use-pca-based-face-recognition-for-yaledatabase-and-measure-the-recogn</guid>
      <pubDate>Sun, 21 Jul 2024 15:13:11 GMT</pubDate>
    </item>
    <item>
      <title>在多分类中如何进行特征和模型选择以及参数调整？</title>
      <link>https://stackoverflow.com/questions/78775112/how-to-do-feature-and-model-selection-with-the-parameter-tuning-in-multi-class-c</link>
      <description><![CDATA[在此处输入图片描述
我想使用这三个数据，传感器与地面的距离（因为有冰和无冰的地面的距离会有所不同）、湿度和表面温度。
我想使用 SVM 方法，因为我认为数据足够干净，使用神经网络会太多。
我想进行多类分类，预测“干冰环境（创建 O ）”、“干冰环境（创建 X ）”、“湿路”、“干路”......
并使用三个特征：传感器与地面的距离、湿度和表面温度。

我怎样才能制作一个好的预测监督机器学习算法？
我尝试了 SVM 和 NN 方法，两者的准确率都是 1.0，但打印出来的结果却不同，通过搜索我发现这可能是过度拟合。是吗？以及如何修复？
我发现精度召回率 f1 分数和准确率的指标为 1.0，这很奇怪。

我的代码
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classes_report

file_path_blackice = &#39;&#39;
df_blackice = pd.read_excel(file_path_blackice, sheet_name=None, header=0)
sheet_name_blackice = list(df_blackice.keys())[0]
df_blackice_all = df_blackice[sheet_name_blackice]

df_blackice_gen = df_blackice_all.iloc[20:40, :]
df_blackice_gen = df_blackice_gen[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_blackice_gen[&#39;标签&#39;] = &#39;黑冰（已生成）&#39;

df_blackice_notgen = df_blackice_all.drop(df_blackice_gen.index)
df_blackice_notgen = df_blackice_notgen[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_blackice_notgen[&#39;标签&#39;] = &#39;黑冰（未生成）&#39;

file_path_wet_asphalt = &#39;&#39;
df_wet_asphalt = pd.read_excel(file_path_wet_asphalt, sheet_name=None, header=0)
sheet_name_wet_asphalt = list(df_wet_asphalt.keys())[0]
df_wet_asphalt = df_wet_asphalt[sheet_name_wet_asphalt].dropna()[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_wet_asphalt[&#39;标签&#39;] = &#39;湿沥青&#39;

file_path_dry_asphalt = &#39;&#39;
df_dry_asphalt = pd.read_excel(file_path_dry_asphalt, sheet_name=None, header=0)
sheet_name_dry_asphalt = list(df_dry_asphalt.keys())[0]
df_dry_asphalt = df_dry_asphalt[sheet_name_dry_asphalt].dropna()[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_dry_asphalt[&#39;标签&#39;] = &#39;干沥青&#39;

df_blackice_all = df_blackice_all[(df_blackice_all[&#39;距离&#39;] &gt; 0) &amp; (df_blackice_all[&#39;距离&#39;] &lt; 10000)]
df_wet_asphalt = df_wet_asphalt[(df_wet_asphalt[&#39;距离&#39;] &gt; 0) &amp; (df_wet_asphalt[&#39;Distance&#39;] &lt; 10000)]
df_dry_asphalt = df_dry_asphalt[(df_dry_asphalt[&#39;Distance&#39;] &gt; 0) &amp; (df_dry_asphalt[&#39;Distance&#39;] &lt; 10000)]

df = pd.concat([df_blackice_gen, df_blackice_notgen, df_wet_asphalt, df_dry_asphalt])

features = df[[&#39;Humidity&#39;,&#39;SurfaceTemp&#39;,&#39;Distance&#39;]]
labels = df[&#39;Label&#39;]

X = features.to_numpy()
y = labels.to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

svm_model = SVC(kernel=&#39;linear&#39;, C=1.0, random_state=42)
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)
print(f&quot;测试准确率：{test_acc}&quot;)
print(classification_report(y_test, y_pred, target_names=[&#39;黑冰（已生成）&#39;, &#39;黑冰（未生成）&#39;, &#39;湿沥青&#39;, &#39;干沥青&#39;]))

def predict_surface_condition(svm_model, scaler, new_data):
new_data_scaled = scaler.transform(new_data)
prediction = svm_model.predict(new_data_scaled)
return prediction

new_data = np.array([[63, 15, 20]]) # 地形（地形、地形、地形）
prediction = predict_surface_condition(svm_model, scaler, new_data)
print(f&quot;新数据的预测：{prediction[0]}&quot;)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, project=&#39;3d&#39;)

ax.scatter(df_blackice_gen[&#39;Humidity&#39;], df_blackice_gen[&#39;SurfaceTemp&#39;], df_blackice_gen[&#39;Distance&#39;], c=&#39;blue&#39;, label=&#39;Black Ice （已生成）&#39;)
ax.scatter(df_blackice_notgen[&#39;湿度&#39;], df_blackice_notgen[&#39;表面温度&#39;], df_blackice_notgen[&#39;距离&#39;], c=&#39;lightblue&#39;, label=&#39;黑冰（未生成）&#39;)
ax.scatter(df_wet_asphalt[&#39;湿度&#39;], df_wet_asphalt[&#39;表面温度&#39;], df_wet_asphalt[&#39;距离&#39;], c=&#39;绿色&#39;, label=&#39;湿沥青&#39;)
ax.scatter(df_dry_asphalt[&#39;湿度&#39;], df_dry_asphalt[&#39;表面温度&#39;], df_dry_asphalt[&#39;距离&#39;], c=&#39;红色&#39;, label=&#39;干沥青&#39;)

ax.set_xlabel(&#39;湿度&#39;)
ax.set_ylabel(&#39;表面温度&#39;)
ax.set_zlabel(&#39;距离&#39;)
ax.set_title(&#39;湿度、表面温度和距离的 3D 散点图&#39;)

ax.legend()

plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78775112/how-to-do-feature-and-model-selection-with-the-parameter-tuning-in-multi-class-c</guid>
      <pubDate>Sun, 21 Jul 2024 11:54:53 GMT</pubDate>
    </item>
    <item>
      <title>是否有用于模糊 iOS 图像中人脸和裸露部分的库？[关闭]</title>
      <link>https://stackoverflow.com/questions/78773917/are-there-libraries-for-blurring-faces-and-nudity-in-images-for-ios</link>
      <description><![CDATA[我正在寻找一个库或 ML 模型，可用于模糊图像中存在的面部和裸体。您对此类库或模型有什么建议吗？
或者您将如何为此目的训练 ML 模型？我对 ML 还很陌生，因此如果我必须创建自己的 ML 模型或库，我将非常感激示例和教程。]]></description>
      <guid>https://stackoverflow.com/questions/78773917/are-there-libraries-for-blurring-faces-and-nudity-in-images-for-ios</guid>
      <pubDate>Sat, 20 Jul 2024 21:07:35 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习方法检测玩具车中的未知缺陷</title>
      <link>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</link>
      <description><![CDATA[我们需要从玩具车图片中判断汽车是否有缺陷。我们没有缺陷汽车的图片，我们无法提前知道这些汽车可能存在哪些缺陷。
我们可以使用各种技巧拍摄数千张完好无损的汽车照片。此外，我们还可以自动拍摄数千/数万张汽车 CAD 图像的快照。
我尝试过的方法：

在传统方法中，我尝试过 OpenCV，但它对所有事物都过于敏感，并且只能应用于以完全相同方式拍摄的两张照片。 :(

Siamese Network 和 Sentence Transformers（余弦相似度等...）也不适合，因为它们对摄影产生的差异很敏感。 :(

Autoencoder 有两种不同的方法：

3.1. 我用基于 CAD 的快照训练了一个自动编码器，然后在真实的有缺陷和无缺陷的图像上对其进行了测试，根据这些重建误差的分布从两个方向切断异常值。这个想法来自这里：https://github.com/sohamk10/Image-reconstruction-and-Anomaly-detection。不是很好解决方案。

3.2. 我用原始照片（大约 10,000 张照片，仅从一个视角拍摄）创建了一个自动编码器模型，其中解码器部分是从 ResNet50 拍摄（并冻结）的，我只训练了编码器部分。我也尝试了其他模型（MobileNetV3、EfficientNet-B3）。结果非常令人满意：它根据重建误差独立于照片环境识别训练过的对象，但它也将那些有轻微缺陷的对象识别为好对象，而它不应该这样做。



YOLO v7：产生与上一点（3.2.）中提到的自动编码器类似的结果。因此，它识别了物体，但不幸的是，它也会识别有缺陷的物体。


如何使用人工智能甚至不使用人工智能来解决这个业余项目问题？
如何修改第 3.2 点中提到的自动编码器。在训练期间提供较低的 loss 和 val_loss 值（目前约为 0.6，但在 MNIST 数据集上为 0.02...）？]]></description>
      <guid>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</guid>
      <pubDate>Sat, 20 Jul 2024 20:36:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么我通过 Mediapipe Model Maker 训练制作的自定义模型会将人检测为我的对象？[关闭]</title>
      <link>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</link>
      <description><![CDATA[我有一个想要检测的软玩具。我使用 Mediapipe Model Maker 对大约 100 张图像进行了训练。结果还不错。该模型大多数时候都能从正面识别我的玩具。但问题是，它似乎认为任何人（人的侧面或正面）都是我的玩具，而且比例很高（比如 &gt;90%）。
我不明白为什么会发生这种情况，我该怎么做才能微调我的模型，让它不把人检测为我的玩具。我已将我的玩具和检测示例的图像附在下面。

]]></description>
      <guid>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</guid>
      <pubDate>Sat, 20 Jul 2024 19:04:20 GMT</pubDate>
    </item>
    <item>
      <title>如何保存这个 RNN 模型以及如何使用它来构建翻译 api？</title>
      <link>https://stackoverflow.com/questions/78773642/how-to-save-this-rnn-model-and-how-use-this-to-build-api-to-translation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78773642/how-to-save-this-rnn-model-and-how-use-this-to-build-api-to-translation</guid>
      <pubDate>Sat, 20 Jul 2024 18:50:20 GMT</pubDate>
    </item>
    <item>
      <title>yolov8 在训练后不会启动冻结：扫描</title>
      <link>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</guid>
      <pubDate>Sun, 28 Jan 2024 01:33:57 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将 ML 模型从 R 转换为 ONNX 格式</title>
      <link>https://stackoverflow.com/questions/77522002/is-it-possible-to-transfer-a-ml-model-from-r-into-onnx-format</link>
      <description><![CDATA[我目前正在 R 中训练 ML 模型（具体来说是使用 mlr3 框架 - 如果不行，我也愿意使用其他软件包）。稍后我想将模型应用到生产中，但为此它需要采用 ONNX 格式。我的在线研究并没有找到任何可能的解决方案，可以将任何在 R 中训练的 ML 模型转换为 ONNX 格式。这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/77522002/is-it-possible-to-transfer-a-ml-model-from-r-into-onnx-format</guid>
      <pubDate>Tue, 21 Nov 2023 10:18:59 GMT</pubDate>
    </item>
    </channel>
</rss>