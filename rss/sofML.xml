<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Mon, 15 Jul 2024 12:29:42 GMT</lastBuildDate>
    <item>
      <title>å¦‚ä½•å‘ CNN_M_LSTM æ¨¡å‹æ·»åŠ  3 ä¸ªè¾“å…¥å‚æ•°ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/78749657/how-to-add-3-inputs-parameters-to-the-cnn-m-lstm-model</link>
      <description><![CDATA[æˆ‘å°è¯•å°†å¸¦æœ‰æ—¶é—´æˆ³çš„èƒ½è€—æ•°æ®é›†å’Œ covid æ•°æ®é›†è¾“å…¥åˆ° CNN_M_LSTM æ¨¡å‹ï¼ˆåº“ Tensorflowï¼‰ä¸­ã€‚
èƒ½è€—å’Œæ—¶é—´æˆ³çš„å¤§å°ä¸º (70082, 2)
Covid æ•°æ®é›†çš„å¤§å°ä¸º (744, 1)
æˆ‘æ›¾ä½¿ç”¨ tensorslice å’Œ zip å°†æ•°æ®æ‰“åŒ…åœ¨ä¸€èµ·å¹¶å¯¹æ•°æ®é›†è¿›è¡Œçª—å£åŒ–ï¼š
è¿™æ˜¯æˆ‘æ‰“åŒ…å’Œçª—å£åŒ–èƒ½è€—å’Œæ—¶é—´æˆ³æ•°æ®é›†ä»¥åŠ covid æ•°æ®é›†çš„ä»£ç ï¼š
MAX_LENGTH = 96
BATCH_SIZE = 128 
TRAIN.SHUFFLE_BUFFER_SIZE = 1000

def windowed_dataset(series_energy,series_covid, window_size=MAX_LENGTH, batch_size=BATCH_SIZE, shuffle_buffer=TRAIN.SHUFFLE_BUFFER_SIZE):
&quot;&quot;&quot;
æˆ‘ä»¬åˆ›å»ºæ—¶é—´çª—å£æ¥åˆ›å»º X å’Œ y ç‰¹å¾ã€‚
ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ª 30 çš„çª—å£ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç”± 30 ä¸ªç‚¹ç»„æˆçš„æ•°æ®é›†ä½œä¸º X
&quot;&quot;&quot;
dataset_energy = tf.data.Dataset.from_tensor_slices(series_energy) 
dataset_covid = tf.data.Dataset.from_tensor_slices(series_covid) 
dataset = tf.data.Dataset.zip(dataset_energy,dataset_covid)
dataset = dataset.window(96 + 1, shift=1) #
dataset = dataset.flat_map(lambda window_covid, window_series: tf.data.Dataset.zip((window_covid, window_series)).batch(96 + 1))
dataset = dataset.shuffle(1000)
dataset = dataset.map(lambda window_covid, window_series: (window_covid[:-1], window_series[-1][0])) 
dataset = dataset.padded_batch(128,drop_remainder=True).cache()

è¿”å›æ•°æ®é›†

å¯¹äºæ¨¡å‹ CNN_M_LSTMï¼Œæˆ‘åˆ›å»ºäº† 2 ä¸ªè¾“å…¥ã€‚è¿™æ˜¯æˆ‘çš„æ¨¡å‹ï¼š

def create_CNN_LSTM_model():
# å®šä¹‰è¾“å…¥
input1 = tf.keras.layers.Input(shape=(96, 1), name=&quot;input1&quot;)
input2 = tf.keras.layers.Input(shape=(96, 2), name=&quot;input2&quot;)

# å®šä¹‰æ¨¡å‹çš„ CNN-LSTM éƒ¨åˆ†
x = tf.keras.layers.Conv1D(filters=128, kernel_size=3,activation=&#39;relu&#39;, strides=1, padding=&quot;causal&quot;)(input1)
x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)
x = tf.keras.layers.Conv1D(filters=64, kernel_size=3,activation=&#39;relu&#39;, strides=1, padding=&quot;causal&quot;)(x)
x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)
x = tf.keras.layers.Dropout(0.5)(x)
x = tf.keras.layers.LSTM(16, return_sequences=True)(x)
x = tf.keras.layers.LSTM(8, return_sequences=True)(x)
x = tf.keras.layers.Flatten()(x)
output_lstm = tf.keras.layers.Dense(1)(x)

# å®šä¹‰æ¨¡å‹çš„å¯†é›†éƒ¨åˆ†
output_dense_1 = tf.keras.layers.Dense(1)(input2[:, -1, :])

# è¿æ¥ LSTM å’Œ Dense å±‚çš„è¾“å‡º
concatenated = tf.keras.layers.Concatenate()([output_dense_1, output_lstm])

# æ·»åŠ æ›´å¤šå¯†é›†å±‚
x = tf.keras.layers.Dense(6,activation=tf.nn.leaky_relu)(concatenated)
output = tf.keras.layers.Dense(4)(x)
model_final = tf.keras.Model(inputs=[input1, input2],outputs=output)
# å®šä¹‰æœ€ç»ˆæ¨¡å‹
return model_final


æˆ‘å¦‚ä½•æ‹Ÿåˆæˆ‘çš„æ¨¡å‹ï¼š
model_cnn_m_lstm = create_CNN_LSTM_model()

# ç¼–è¯‘æ¨¡å‹
model_cnn_m_lstm.compile(
loss=tf.keras.losses.Huber(),
optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
metrics=[&quot;mse&quot;]
)

model_cnn_m_lstm.summary()

model_cnn_m_lstm.fit(train_dataset, epochs=100, batch_size=128)

é”™è¯¯æ˜¯æ¨¡å‹éœ€è¦ 2 ä¸ªè¾“å…¥ï¼Œä½†æ”¶åˆ° 1 ä¸ªè¾“å…¥å¼ é‡ã€‚æˆ‘æ›¾å°è¯•å°† covid æ•°æ®é›†ã€èƒ½é‡åˆ—å’Œæ—¶é—´æˆ³å‹ç¼©åˆ°ä¸€ä¸ªæ•°æ®é›†ã€‚
æˆ‘çš„æœŸæœ›æ˜¯å°† 3 ä¸ªè¾“å…¥è¾“å…¥åˆ°æˆ‘çš„ CNN_M_LSTM æ¨¡å‹ä¸­ã€‚æˆ‘è¿˜å°è¯•å•ç‹¬è¾“å…¥æ•°æ®ï¼Œæˆ‘æ”¶åˆ°æ•°æ®å½¢çŠ¶é”™è¯¯ï¼Œæˆ‘å°è¯•é‡æ–°å¡‘é€ å®ƒï¼Œä½†å®ƒä¹Ÿä¸èµ·ä½œç”¨ã€‚æœ‰æ²¡æœ‰åŠæ³•åœ¨æˆ‘çš„ CNN_M_LSTM æ¨¡å‹ä¸­è¾“å…¥ 3 ä¸ªå‚æ•°ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/78749657/how-to-add-3-inputs-parameters-to-the-cnn-m-lstm-model</guid>
      <pubDate>Mon, 15 Jul 2024 11:49:20 GMT</pubDate>
    </item>
    <item>
      <title>çº¿æ€§å›å½’å‡†ç¡®åº¦ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/78749472/linear-regression-accuracy</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä»…ä½¿ç”¨ NumPy åˆ›å»ºçº¿æ€§å›å½’ç®—æ³•ã€‚æˆ‘ä½¿ç”¨ä½æˆ¿æ•°æ®é›†ç¼–å†™äº†æ­¤ä»£ç ã€‚æˆ‘çš„æˆæœ¬å‡½æ•°åœ¨å¤§çº¦ 500 æ¬¡è¿­ä»£åæ”¶æ•›ï¼Œä½†é¢„æµ‹è¿œéå‡†ç¡®ã€‚é—®é¢˜å¯èƒ½å‡ºåœ¨å“ªé‡Œï¼Ÿæˆ‘è¯¢é—®äº† ChatGPTï¼Œä½†æ²¡æœ‰å¾—åˆ°æœ‰ç”¨çš„ç­”æ¡ˆã€‚æˆ‘è®¤ä¸ºè¯¥ç®—æ³•å¾ˆå¥½ï¼ˆè¯·åŸè°…ä»»ä½•ç³Ÿç³•çš„ç¼–ç ï¼Œå› ä¸ºæˆ‘æ˜¯æ–°æ‰‹ğŸ˜¬ï¼‰ï¼Œæˆ‘æ€€ç–‘é—®é¢˜å¯èƒ½ä¸è¿‡åº¦æ‹Ÿåˆæˆ–ç±»ä¼¼é—®é¢˜æœ‰å…³ã€‚
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def z_score_normalization(x):
mean = np.mean(x)
std = np.std(x)

x = (x - mean)/std
return x,mean,std

def reverse_z_score_normalization(x,mean,std):
return x*std+mean

def compute_prediction(x_i,w,b):
fx = np.dot(x_i,w) + b
return fx

def cost_function(x,y,w,b,m,n,rp):#mï¼šæ•°æ®æ•°é‡ï¼Œnï¼šç‰¹å¾æ•°é‡ï¼Œrpï¼šæ­£åˆ™åŒ–å‚æ•°ï¼ˆlambdaï¼‰
total_cost = 0
for i in range(m):
total_cost += (compute_prediction(x[i],w,b) - y[i])**2
total_cost /= 2*m

#è¿”å› total_cost #ä¸å¸¦æ­£åˆ™åŒ–

#æ­£åˆ™åŒ–
temp_cost = 0
for j in range(n):
temp_cost += (w[j])**2
total_cost += temp_cost*rp/(2*m)

cost_history.append(total_cost)

è¿”å› total_cost

def deriveds_for_gradient_descent(x,y,w,b,m,rp,j):#mï¼šæ•°æ®æ•°é‡ï¼Œnï¼šç‰¹å¾æ•°é‡ï¼Œrpï¼šæ­£åˆ™åŒ–å‚æ•°ï¼ˆlambdaï¼‰
dj_dw = 0
dj_db = 0

for i in range(m):
dj_dw += (compute_prediction(x[i],w,b) - y[i])*x[i,j]
dj_db += (compute_prediction(x[i],w,b) - y[i])

dj_dw /= m
dj_db /= m

dj_dw += rp*w[j]/m

return dj_dw,dj_db

def gradient_descent(x,y,w,b,m,n,rp,lr): #m: æ•°æ®æ•°é‡,n: ç‰¹å¾æ•°é‡,rp: æ­£åˆ™åŒ–å‚æ•°(lambda),lr: å­¦ä¹ ç‡(alpha)
for j in range(n):
dj_dw , dj_db = derived_for_gradient_descent(x,y,w,b,m,rp,j)
w[j] = w[j] - lr*dj_dw
b = b - lr*dj_db

è¿”å› w,b

def raw_training_set_process(raw_x,size):#[7420 4 2 3 &#39;yes&#39; &#39;no&#39; &#39;no&#39; &#39;no&#39; &#39;yes&#39; 2 &#39;yes&#39; &#39;furnished&#39;]

scaled_raw1 = raw_x[:,4:11] #[&#39;yes&#39; &#39;no&#39; &#39;no&#39; &#39;no&#39; &#39;yes&#39; 2 &#39;yes&#39; ] =&gt;å¦ï¼š0ï¼Œæ˜¯ï¼š1
scaled_raw2 = raw_x[:,-1] #[&#39;å¸¦å®¶å…·&#39;:2, &#39;åŠå¸¦å®¶å…·&#39;:1,&#39;æ— å®¶å…·&#39;:0]

for i in range(size):
for j in scaled_raw1[i]:
if j == &#39;æ˜¯&#39;: scaled_raw1[i] = 1
elif j == &#39;å¦&#39; : scaled_raw1[i] = 0 

if scaled_raw2[i] == &#39;å¸¦å®¶å…·&#39; : scaled_raw2[i] = 2 
elif scaled_raw2[i] == &#39;åŠå¸¦å®¶å…·&#39; : scaled_raw2[i] = 1
else: scaled_raw2[i]=0

raw_x[:,4:11] = scaled_raw1
raw_x[:,-1] = scaled_raw2

è¿”å›raw_x

data_set = pd.read_csv(r&#39;path-to-dataset\Housing.csv&#39;)
data_set_in_numpy = data_set.to_numpy() # shape = (545,13)
#print(dataSetInNumpy[0])

y_trainingSet = data_set_in_numpy[:,0]#price
y_trainingSet,y_mean,y_std = z_score_normalization(y_trainingSet)
#print(y_trainingSet[0])
size_of_dataset= len(y_trainingSet) # sizeOfTrainingSet

X_trainingSet = raw_training_set_process(data_set_in_numpy[:,1:],size_of_dataset)#features
X_trainingSet,X_mean,X_std= z_score_normalization(X_trainingSet)
#print(X_trainingSet[0])
number_of_features = len(X_trainingSet[0])

w = np.zeros(number_of_features) #æƒé‡
b = 0 #åå·®

lr = 0.01 #å­¦ä¹ ç‡
rp = 0.01 #æ­£åˆ™åŒ–å‚æ•°

cost_history = []

number_of_iterate = 100
for i in range(number_of_iterate):
w,b = gradient_descent(X_trainingSet,y_trainingSet,w,b,size_of_dataset,number_of_features,rp,lr)

cost_history.append(cost_function(X_trainingSet,y_trainingSet,w,b,size_of_dataset,number_of_features,lr))

if (i % 10 == 0):
print(f&quot;è¿­ä»£æ¬¡æ•°ï¼š{i} wï¼š{np.round(w,2)} bï¼š{bï¼š.2f} &quot;)

numbers = np.arange(len(cost_history))
plt.scatter(numbers,cost_history, marker=&#39;x&#39;, c=&#39;r&#39;)
plt.xlabel(&#39;è¿­ä»£æ¬¡æ•°&#39;)
plt.ylabel(&#39;æˆæœ¬&#39;)
plt.show()

prediction = compute_prediction(X_trainingSet[9],w,b)
target = y_trainingSet[9]

print(f&quot;é¢„æµ‹ï¼š{é¢„æµ‹} ç›®æ ‡ï¼š{ç›®æ ‡}&quot;)

prediction = reverse_z_score_normalization(prediction,X_mean,X_std)
target = reverse_z_score_normalization(target,y_mean,y_std)

print(f&quot;é¢„æµ‹ï¼š{é¢„æµ‹} ç›®æ ‡ï¼š{ç›®æ ‡}&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/78749472/linear-regression-accuracy</guid>
      <pubDate>Mon, 15 Jul 2024 11:00:58 GMT</pubDate>
    </item>
    <item>
      <title>äº¤å‰éªŒè¯å’Œ MICE å½’å›  [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/78748357/cross-validation-and-mice-imputation</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æœ‰ä¸€äº›ç¼ºå¤±æ•°æ®ã€‚æˆ‘æœ€åˆçš„æƒ³æ³•æ˜¯ä½¿ç”¨ MiceForestã€‚æˆ‘è¿˜ä½¿ç”¨äº†åˆ†å±‚ k æŠ˜æŠ€æœ¯ï¼ˆæ•°æ®ä¸å¹³è¡¡ï¼‰ã€‚æˆ‘è¿˜æƒ³å°½é‡å‡å°‘æ•°æ®æ³„æ¼ã€‚

æˆ‘åº”è¯¥ä½•æ—¶ä½¿ç”¨ MiceForest å¡«è¡¥ç¼ºå¤±å€¼ï¼Ÿé’ˆå¯¹æ¯ä¸ªæŠ˜ï¼Ÿè¿˜æ˜¯ä¸€å¼€å§‹å°±å¡«è¡¥æ•´ä¸ªæ•°æ®é›†ï¼Ÿ
æˆ‘åº”è¯¥ä½¿ç”¨ SMOTE æ¥è§£å†³æ¯ä¸ªæŠ˜ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜å—ï¼Ÿå› ä¸ºæˆ‘å¾—åˆ°äº†å¾ˆå¤šè¯¯æŠ¥ï¼ˆå½“ä»…ä½¿ç”¨åˆ†å±‚ k æŠ˜è€Œæ²¡æœ‰è¿‡åº¦é‡‡æ ·æ—¶ï¼‰ã€‚

å½“æˆ‘å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œ mice å¡«è¡¥ï¼Œç”¨ smote è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œç„¶åè¿›è¡Œäº¤å‰éªŒè¯æ—¶ï¼Œæˆ‘è·å¾—äº†éå¸¸å¥½çš„æ€§èƒ½ã€‚æˆ‘è§‰å¾—è¿™æ˜¯è¿‡åº¦æ‹Ÿåˆï¼Ÿè¿™æ˜¯å› ä¸ºæ•°æ®æ³„æ¼å—ï¼Ÿï¼ˆæˆ‘å¯¹è¿™ä¸ªé¢†åŸŸæœ‰ç‚¹é™Œç”Ÿï¼‰]]></description>
      <guid>https://stackoverflow.com/questions/78748357/cross-validation-and-mice-imputation</guid>
      <pubDate>Mon, 15 Jul 2024 06:37:02 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFaceï¼šLlama-3-8B åˆä½œæ£€æŸ¥ç‚¹ç¢ç‰‡åŠ è½½è¿›åº¦åœ¨ 25% å¤„åœæ­¢</title>
      <link>https://stackoverflow.com/questions/78748213/huggingface-loading-checkpoint-shards-in-collab-for-llama-3-8b-stops-at-25</link>
      <description><![CDATA[æˆ‘å°è¯•ä½¿ç”¨ huggingface åœ¨æˆ‘çš„ Colab ç¬”è®°æœ¬ä¸­æœ¬åœ°è¿è¡Œ Llama-3-8B æ¨¡å‹ã€‚åŠ è½½æ¨¡å‹æ—¶ï¼Œæ£€æŸ¥ç‚¹åˆ†ç‰‡åœ¨ 25% å¤„åœæ­¢åŠ è½½ã€‚æˆ‘ä¸æ˜ç™½é—®é¢˜å¯èƒ½æ˜¯ä»€ä¹ˆã€‚
from transformers import AutoModelForCausalLM, AutoTokenizer

# å®šä¹‰æ¨¡å‹åç§°ï¼ˆè¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œè¯·æ›¿æ¢ä¸ºå®é™…æ¨¡å‹åç§°ï¼‰
model_name = &quot;meta-llama/Meta-Llama-3-8B&quot;

!huggingface-cli login --token $HF_TOKEN
# åŠ è½½ tokenizer å’Œæ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# å¦‚æœæ¨¡å‹å¾ˆå¤§ï¼Œå°†å…¶ç§»åŠ¨åˆ° GPU å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©
model.to(&#39;cuda&#39;)

HF_Token å·²å®šä¹‰ï¼Œå‡ºäºéšç§åŸå› ï¼Œæ­¤å¤„æœªæåŠã€‚
æç¤ºä»¥ä¸‹é”™è¯¯ï¼š
æ‚¨çš„ token å·²ä¿å­˜åˆ° /root/.cache/huggingface/token
ç™»å½•æˆåŠŸ
/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: 
æ‚¨çš„ Colab secrets ä¸­ä¸å­˜åœ¨ secret `HF_TOKEN`ã€‚
è¦ä½¿ç”¨ Hugging Face Hub è¿›è¡Œèº«ä»½éªŒè¯ï¼Œè¯·åœ¨è®¾ç½®é€‰é¡¹å¡ (https://huggingface.co/settings/tokens) ä¸­åˆ›å»ºä¸€ä¸ªä»¤ç‰Œï¼Œå°†å…¶è®¾ç½®ä¸º Google Colab ä¸­çš„æœºå¯†ï¼Œç„¶åé‡æ–°å¯åŠ¨ä¼šè¯ã€‚
æ‚¨å°†èƒ½å¤Ÿåœ¨æ‰€æœ‰ç¬”è®°æœ¬ä¸­é‡å¤ä½¿ç”¨æ­¤æœºå¯†ã€‚
è¯·æ³¨æ„ï¼Œå»ºè®®è¿›è¡Œèº«ä»½éªŒè¯ï¼Œä½†ä»ç„¶å¯ä»¥é€‰æ‹©è®¿é—®å…¬å…±æ¨¡å‹æˆ–æ•°æ®é›†ã€‚
warnings.warn(
è¯æ±‡è¡¨ä¸­å·²æ·»åŠ ç‰¹æ®Šä»¤ç‰Œï¼Œè¯·ç¡®ä¿å¯¹ç›¸å…³çš„è¯åµŒå…¥è¿›è¡Œäº†å¾®è°ƒæˆ–è®­ç»ƒã€‚
æ­£åœ¨åŠ è½½â€‡æ£€æŸ¥ç‚¹â€‡åˆ†ç‰‡ï¼šâ€‡â€‡25%
â€‡1/4â€‡[00:22&lt;01:07,â€‡22.37s/it]
]]></description>
      <guid>https://stackoverflow.com/questions/78748213/huggingface-loading-checkpoint-shards-in-collab-for-llama-3-8b-stops-at-25</guid>
      <pubDate>Mon, 15 Jul 2024 05:44:13 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å¯¹è§†é¢‘ä¸­å¯¹è±¡æ‰§è¡Œçš„å…·ä½“åŠ¨ä½œè¿›è¡Œåˆ†ç±»ã€‚ï¼ˆä¸æ˜¯ä»…ä½¿ç”¨ä¸€å¸§ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ç»„å¸§ï¼‰[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/78747441/how-to-classify-what-specific-actions-an-object-performs-in-a-video-not-using</link>
      <description><![CDATA[æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªäººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œé€šè¿‡æŸ¥çœ‹å¸§é›†åˆæ¥ç¡®å®šå¯¹è±¡è¡Œä¸ºçš„ç»“æœï¼Œè€Œä¸æ˜¯é€šè¿‡åœ¨å®¶æ‰“é«˜å°”å¤«çƒæ—¶æŸ¥çœ‹å•ä¸ªå¸§æ¥ç¡®å®šé«˜å°”å¤«çƒæ˜¯è¿›å…¥è¿˜æ˜¯ç¦»å¼€ã€‚
æˆ‘å°è¯•ä½¿ç”¨ ultralyticsï¼Œä½† ultralytics æŒ‰å¸§å¯¹å¯¹è±¡è¿›è¡Œåˆ†ç±»ï¼Œå› æ­¤å®ƒä¸ç¬¦åˆæˆ‘çš„ç›®çš„ã€‚æˆ‘æƒ³çŸ¥é“å¦‚ä½•åˆ›å»ºä¸€ä¸ªåŒºåˆ†è§†é¢‘ä¸­è¡Œä¸ºåˆ†ç±»çš„æ¨¡å‹ã€‚
å¦‚ä½•åˆ¶ä½œä¸€ä¸ªåˆ†æå¸§è€Œä¸æ˜¯å¸§çš„äººå·¥æ™ºèƒ½æ¨¡å‹ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/78747441/how-to-classify-what-specific-actions-an-object-performs-in-a-video-not-using</guid>
      <pubDate>Sun, 14 Jul 2024 20:58:11 GMT</pubDate>
    </item>
    <item>
      <title>IndexErrorï¼šç›®æ ‡ 32 è¶…å‡ºèŒƒå›´ã€‚è¿è¡Œæ—¶æŸå¤± = æ ‡å‡†ï¼ˆy_predï¼Œy_trainï¼‰[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/78747258/indexerror-target-32-is-out-of-bounds-while-running-loss-criteriony-pred-y</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è¿è¡Œä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œå…¶ä¸­åŒ…å«ä¸€äº›å¤§çº¦ 1112 è¡Œã€23 ä¸ªè¾“å…¥ã€2 ä¸ªéšè—å±‚å’Œ 31 ä¸ªå¯èƒ½è¾“å‡ºçš„ csv æ•°æ®ã€‚åœ¨å‰å‘è®­ç»ƒä¹‹åï¼Œåœ¨ä»¥ä¸‹ä»£ç æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œæˆ‘æ”¶åˆ°ä»¥ä¸‹é”™è¯¯æ¶ˆæ¯
åœ¨è¡Œ loss = criterion(y_pred, y_train)
é”™è¯¯ï¼š
-----------------------------------------------------------------------------
IndexError Tracebackï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰
&lt;ipython-input-64-47488b841fa2&gt; åœ¨ &lt;cell line: 5&gt;()
8 
9 
---&gt; 10 loss = criterion(y_pred, y_train)
11 
12 #loss.append(loss.detach().numpy())

3 å¸§
/usr/local/lib/python3.10/dist-packages/torch/nn/ functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)
3084 å¦‚æœ size_average ä¸ä¸º None æˆ– reduce ä¸ä¸º None:
3085 reduction = _Reduction.legacy_get_string(size_average, reduce)
-&gt; 3086 è¿”å› torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
3087 
3088 

IndexErrorï¼šç›®æ ‡ 32 è¶…å‡ºèŒƒå›´ã€‚

æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/78747258/indexerror-target-32-is-out-of-bounds-while-running-loss-criteriony-pred-y</guid>
      <pubDate>Sun, 14 Jul 2024 19:10:09 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow/Keras `load_img` é”™è¯¯ï¼šâ€œæ— æ³•å¯¼å…¥ PIL.Imageâ€</title>
      <link>https://stackoverflow.com/questions/78746872/tensorflow-keras-load-img-error-could-not-import-pil-image</link>
      <description><![CDATA[å°½ç®¡ä¸‹è½½äº†æ•å¤´æ¨¡å—ï¼Œæˆ‘ä»ç„¶é‡åˆ°å¯¼å…¥é”™è¯¯ï¼Œæ˜¯çš„ï¼Œå°½ç®¡æˆ‘é‡åˆ°äº†é”™è¯¯ï¼Œä½†æˆ‘è¿˜æ˜¯å¸è½½äº†æ•å¤´ã€‚æœ‰ä»€ä¹ˆåŠæ³•å¯ä»¥ä¿®å¤å®ƒå—ï¼Ÿhttps://i.sstatic.net/eAhcTExv.png
æˆ‘å¸Œæœ›åŒ…å«æ‰€æœ‰å›¾åƒçš„æ–‡ä»¶å¤¹è¢«å¯¼å…¥ï¼Œè¿™æ ·æˆ‘å°±å¯ä»¥é€šè¿‡å¯¼å…¥çš„å›¾åƒè®­ç»ƒæ•°æ®]]></description>
      <guid>https://stackoverflow.com/questions/78746872/tensorflow-keras-load-img-error-could-not-import-pil-image</guid>
      <pubDate>Sun, 14 Jul 2024 16:20:23 GMT</pubDate>
    </item>
    <item>
      <title>æ— æ³•å°† (Dimension(None)ã€Dimension(80)) çš„å…ƒç´ è½¬æ¢ä¸ºå¼ é‡</title>
      <link>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•é˜…è¯» LibRecommender ä¸­æœ‰å…³æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„æ•™ç¨‹ï¼šhttps://librecommender.readthedocs.io/en/latest/tutorial.html
æˆ‘åœåœ¨äº†è®­ç»ƒæ¨¡å‹é˜¶æ®µï¼Œä»£ç å¦‚ä¸‹ï¼š
model = WideDeep(
task=&quot;ranking&quot;,
data_info=data_info,
embed_size=16,
n_epochs=2,
loss_type=&quot;cross_entropy&quot;,
lr={&quot;wide&quot;: 0.05, &quot;deep&quot;: 7e-4},
batch_size=2048,
use_bn=True,
hidden_â€‹â€‹units=(128, 64, 32),
)

model.fit(
train_data,
neg_sampling=True, # å¯¹è®­ç»ƒå’Œè¯„ä¼°æ•°æ®æ‰§è¡Œè´ŸæŠ½æ ·
verbose=2,
shuffle=True,
eval_data=eval_data,
metrics=[&quot;loss&quot;, &quot;roc_auc&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;ndcg&quot;],
)

æˆ‘æ”¶åˆ°é”™è¯¯ï¼š
TypeErrorï¼šè°ƒç”¨ Flatten.call() æ—¶é‡åˆ°å¼‚å¸¸ã€‚

æ— æ³•å°† (Dimension(None)ã€Dimension(80)) çš„å…ƒç´ è½¬æ¢ä¸º Tensorã€‚è¯·è€ƒè™‘å°†å…ƒç´ è½¬æ¢ä¸ºå—æ”¯æŒçš„ç±»å‹ã€‚è¯·å‚é˜… https://www.tensorflow.org/api_docs/python/tf/dtypes äº†è§£å—æ”¯æŒçš„ TF æ•°æ®ç±»å‹ã€‚

Flatten.call() æ¥æ”¶çš„å‚æ•°ï¼š
â€¢ è¾“å…¥=tf.Tensor(shape=(?, 5, 16), dtype=float32)

æˆ‘ä¸çŸ¥é“ä¸ºä»€ä¹ˆä¼šæ”¶åˆ°æ­¤é”™è¯¯ï¼Ÿæˆ‘å‡è®¾æœ¬æ•™ç¨‹ä¸­æ²¡æœ‰é”™è¯¯ï¼Œæˆ‘æŒ‰ç…§æ‰€ç¤ºæŒ‰ 1:1 æ‰§è¡Œã€‚
æˆ‘åœ¨ PyCharm ç¯å¢ƒä¸­å·¥ä½œå¹¶ä½¿ç”¨ Jupyter ç¬”è®°æœ¬ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</guid>
      <pubDate>Sun, 14 Jul 2024 14:37:06 GMT</pubDate>
    </item>
    <item>
      <title>å¤šçº¿ç¨‹ TFRecord å†™å…¥åœ¨ kaggle ç¬”è®°æœ¬ä¸Šçªç„¶åœæ­¢[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯»æ±‚æœ‰å…³åœ¨ Kaggle ç¬”è®°æœ¬ä¸­ TFRecord å†™å…¥çš„å¤šçº¿ç¨‹æ–¹é¢çš„å¸®åŠ©ã€‚æˆ‘æ­£åœ¨ç ”ç©¶ VGGFace2 æ•°æ®é›†ï¼Œæ—¨åœ¨å°†å›¾åƒå¯¹è½¬æ¢ä¸º TFRecordsï¼Œç”¨äºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ï¼Œä½†è¯¥è¿‡ç¨‹åœ¨å•çº¿ç¨‹ä¸Šè¿è¡Œé€Ÿåº¦è¿‡æ…¢ã€‚
TFRecord æ–‡ä»¶åŒ…å«æ­¤é…å¯¹å›¾åƒçš„ protobuf ç¤ºä¾‹ï¼Œä»¥è¡¨ç¤ºåŒä¸€ä¸ªäººå’Œä¸åŒçš„äººã€‚
æŒ‘æˆ˜å’Œæˆ‘å°è¯•è¿‡çš„æ–¹æ³•ï¼š

å•çº¿ç¨‹å¤„ç†é€Ÿåº¦æ…¢ï¼šå³ä½¿æ˜¯å¤„ç†æ•°æ®é›†çš„æœ‰é™å­é›†ï¼ˆæ¯ä¸ªç›®å½• 5 ä¸ªå›¾åƒå¯¹ç”¨äºè®­ç»ƒï¼Œæ¯ä¸ªç›®å½• 2 ä¸ªå›¾åƒå¯¹ç”¨äºéªŒè¯/æµ‹è¯•ï¼‰ï¼Œä½¿ç”¨å•çº¿ç¨‹ä¹Ÿéœ€è¦å¤§é‡æ—¶é—´ï¼ˆå¯èƒ½é•¿è¾¾ 24 å°æ—¶ï¼‰ã€‚æˆ‘å·²å°½å¯èƒ½ä¼˜åŒ–ä»£ç ï¼Œå› æ­¤æˆ‘å¼€å§‹æ¢ç´¢å¤šçº¿ç¨‹ä»¥æé«˜æ€§èƒ½ã€‚

å¤šçº¿ç¨‹é—®é¢˜ï¼šå½“æˆ‘ä½¿ç”¨ concurrent.futures.ThreadPoolExecutor å®ç°å¤šçº¿ç¨‹æ—¶ï¼Œä¼šè¯çªç„¶åœæ­¢ï¼Œæ²¡æœ‰ä»»ä½•é”™è¯¯æ¶ˆæ¯ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰å˜é‡éƒ½ä¸¢å¤±ï¼Œéœ€è¦ä»å¤´å¼€å§‹å®Œå…¨é‡æ–°å¯åŠ¨ã€‚æœ‰è¶£çš„æ˜¯ï¼Œä½¿ç”¨å•ä¸ªç›®å½•æ—¶ï¼Œå¤šçº¿ç¨‹å¯ä»¥å®Œç¾è¿è¡Œï¼ˆå› ä¸ºæˆ‘å®ç°çš„å¤šçº¿ç¨‹æ˜¯åŒæ—¶å¤„ç†ä¸åŒçš„ç›®å½•ï¼Œæ‰€ä»¥å³ä½¿ä½¿ç”¨å¤šçº¿ç¨‹æ± æ‰§è¡Œå™¨å¯¹è±¡ï¼Œå¤„ç†å•ä¸ªç›®å½•ä¹Ÿä¸å†æ˜¯å¤šçº¿ç¨‹ï¼Œè€Œæ˜¯å•çº¿ç¨‹è¿›ç¨‹ï¼‰ï¼Œä½†å³ä½¿ä½¿ç”¨ä¸¤ä¸ªç›®å½•ä¹Ÿä¼šå¯¼è‡´ä¸ä¸Šè¿°ç›¸åŒçš„é—®é¢˜ï¼ˆVGGFace2 å¤§çº¦æœ‰ 8631 ä¸ªç›®å½•ï¼‰ã€‚


æˆ‘çš„é—®é¢˜ï¼š

æ½œåœ¨åŸå› ï¼šè¿™äº›å¤šçº¿ç¨‹é—®é¢˜èƒŒåçš„åŸå› å¯èƒ½æ˜¯ä»€ä¹ˆï¼Ÿè¿™æ˜¯ Kaggle èµ„æºçš„å†…å­˜é™åˆ¶å—ï¼Ÿ

æ›¿ä»£æ–¹æ³•ï¼šå…¶ä»–äººæ˜¯å¦é‡åˆ°è¿‡ç±»ä¼¼çš„æŒ‘æˆ˜ï¼Ÿåœ¨ Kaggle ç¯å¢ƒä¸­ï¼Œæ˜¯å¦æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥åŠ é€Ÿ TFRecord å†™å…¥ï¼Ÿ


é™„åŠ è¯´æ˜ï¼š

æˆ‘æ­£åœ¨ä½¿ç”¨ contextlib.ExitStack åº“æ¥æ‰“å¼€è®¸å¤šå†™å…¥å™¨å¹¶åŒæ—¶å†™å…¥ã€‚

æˆ‘åœ¨ Kaggle è®¨è®ºå’Œ Stack Overflow ä¸Šå¹¿æ³›æœç´¢è§£å†³æ–¹æ¡ˆï¼Œä½†æ²¡æœ‰æ‰¾åˆ°é’ˆå¯¹è¿™ç§æƒ…å†µçš„å…·ä½“è§£å†³æ–¹æ¡ˆã€‚


æ‚¨å¯¹ Kaggle ç¬”è®°æœ¬ä¸­çš„å¤šçº¿ç¨‹æœ‰ä»€ä¹ˆè§è§£æˆ–ç»éªŒï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†åƒ VGGFace2 è¿™æ ·çš„æ•°æ®é›†æ—¶ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</guid>
      <pubDate>Sun, 14 Jul 2024 11:10:50 GMT</pubDate>
    </item>
    <item>
      <title>BERT åµŒå…¥ä½™å¼¦ç›¸ä¼¼åº¦çœ‹èµ·æ¥éå¸¸éšæœºä¸”æ— ç”¨</title>
      <link>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</link>
      <description><![CDATA[æˆ‘ä»¥ä¸ºä½ å¯ä»¥ä½¿ç”¨ BERT åµŒå…¥æ¥ç¡®å®šè¯­ä¹‰ç›¸ä¼¼æ€§ã€‚æˆ‘è¯•å›¾ç”¨è¿™ä¸ªå°†ä¸€äº›å•è¯åˆ†ç»„ï¼Œä½†ç»“æœå¾ˆç³Ÿç³•ã€‚
ä¾‹å¦‚ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºåŠ¨ç‰©å’Œæ°´æœçš„å°ä¾‹å­ã€‚æ³¨æ„åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„æ˜¯çŒ«å’Œé¦™è•‰å—ï¼Ÿ
import torch
from transformers import BertTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity

tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
model = BertModel.from_pretrained(&#39;bert-base-uncased&#39;, output_hidden_â€‹â€‹states=True).eval()

def gen_embedding(word):
encoding = tokenizer(word, return_tensors=&#39;pt&#39;)
with torch.no_grad():
output = model(**encoding)

token_embeddings = output.last_hidden_â€‹â€‹state.squeeze()
token_embeddings = token_embeddings[1 : -1]
word_embedding = token_embeddings.mean(dim=0)
return word_embedding

words = [
&#39;cat&#39;,
&#39;seagull&#39;,
&#39;mango&#39;,
&#39;banana&#39;
]

embs = [gen_embedding(word) for word in words]

print(cosine_similarity(embs))

# array([[1. , 0.33929926, 0.7086487 , 0.79372996],
# [0.33929926, 1.0000001 , 0.29915804, 0.4000572 ],
# [0.7086487 , 0.29915804, 1. , 0.7659105 ],
# [0.79372996, 0.4000572 , 0.7659105 , 0.99999976]], dtype=float32)

æˆ‘åšé”™äº†ä»€ä¹ˆå—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</guid>
      <pubDate>Sat, 13 Jul 2024 20:58:49 GMT</pubDate>
    </item>
    <item>
      <title>äºŒå…ƒåˆ†ç±»ä¸­çš„ SHAP å€¼è§£é‡Š</title>
      <link>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</link>
      <description><![CDATA[æˆ‘å°è¯•ä½¿ç”¨æ¯ä¸ªç‰¹å¾çš„ SHAP å€¼æ¥è§£é‡Šæˆ‘çš„äºŒå…ƒåˆ†ç±»æ¨¡å‹ã€‚æˆ‘æƒ³çŸ¥é“ï¼š
æ­£çš„ SHAP å€¼æ˜¯å¦æ„å‘³ç€è¯¥ç‰¹å¾å¯¹é¢„æµ‹â€œ1â€ç±»çš„è´¡çŒ®æ›´å¤§ï¼Œè€Œè´Ÿçš„ SHAP å€¼æ˜¯å¦æ„å‘³ç€è¯¥ç‰¹å¾å¯¹é¢„æµ‹â€œ0â€ç±»çš„è´¡çŒ®æ›´å¤§ï¼Ÿ
å¦‚æœæˆ‘ä½¿ç”¨ç»å¯¹ SHAP å€¼å·®å¼‚æ¥æè¿°ç‰¹å¾è´¡çŒ®å˜åŒ–ï¼Œè¿™ä¸ªæƒ³æ³•æ˜¯å¦åˆç†ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</guid>
      <pubDate>Fri, 12 Jul 2024 14:25:43 GMT</pubDate>
    </item>
    <item>
      <title>python ä¸­æŸäº›å‡½æ•°çš„è´¬å€¼ï¼šæ•°æ®æ¡†çš„çœŸå€¼ä¸æ˜ç¡®</title>
      <link>https://stackoverflow.com/questions/78735084/depreciation-of-some-function-in-python-ambiguous-truth-value-of-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78735084/depreciation-of-some-function-in-python-ambiguous-truth-value-of-dataframe</guid>
      <pubDate>Thu, 11 Jul 2024 10:52:14 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å‡†ç¡®è®¡ç®—Doctr ocrä¸­æ£€æµ‹åˆ°çš„æ–‡æœ¬çš„ç»å¯¹bboxåæ ‡ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/78733724/how-to-accurately-calculate-absolute-bbox-coordinates-of-detected-text-in-doctr</link>
      <description><![CDATA[æˆ‘ä¸€ç›´è¯•å›¾åœ¨æ–‡æ¡£çš„å›¾ç‰‡ä¸Šç»˜åˆ¶ bboxï¼Œå¹¶å°è¯•ä½¿ç”¨ mindee-doctr è¿›è¡Œ ocr ä»¥æŸ¥çœ‹æ£€æµ‹åˆ°çš„æ–‡æœ¬è¡Œã€‚æˆ‘é¢ä¸´çš„é—®é¢˜æ˜¯ï¼Œæˆ‘é€šè¿‡ä¹˜ä»¥ç›¸å¯¹åæ ‡å’Œé¡µé¢å°ºå¯¸è®¡ç®—å‡ºçš„ bbox çš„ç»å¯¹åæ ‡ï¼Œåœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ—¶éƒ½å‘å³ä¸Šè§’åç§»ã€‚æœ‰æ²¡æœ‰åŠæ³•çº æ­£è¿™ä¸ªé—®é¢˜ï¼Ÿ
è¿™æ˜¯æˆ‘è®¡ç®— bbox çš„ä»£ç ï¼š
from doctr.models import ocr_predictor
from doctr.io import DocumentFile

# ä½¿ç”¨ docTR åˆ†æå›¾åƒå¹¶è·å–ç»“æœ
line_boundaries = []
model = ocr_predictor(pretrained=True) #è®¾ç½®preserve_aspect_ratio=False æˆ–symmetric_pad=False æ²¡æœ‰åŒºåˆ«ã€‚
doc = DocumentFile.from_images(img_path)
result = model(doc)

# æå–æ¯è¡Œçš„è¾¹ç•Œæ¡†åæ ‡
for page in result.pages:
for block in page.blocks:
for line in block.lines:
# å°†ç›¸å¯¹åæ ‡ä¸é¡µé¢å°ºå¯¸ç›¸ä¹˜ï¼Œå¾—åˆ°ç»å¯¹åæ ‡
x_min, y_min, x_max, y_max = round(line.geometry[0][0] * page.dimensions[0]), round(line.geometry[0][1] * page.dimensions[1]), round(line.geometry[1][0] * page.dimensions[0]), round(line.geometry[1][1] * page.dimensions[1])
line_boundaries.append((x_min, y_min, x_max, y_max))

è¿™æ˜¯ line_boundaries çš„å€¼ï¼š
[(531, 148, 1321, 184), (2725, 148, 3061, 177), (526, 254, 3071, 295), (526, 288, 3071, 332), (535, 324, 3071, 363), ... ]
è¿™æ˜¯æˆ‘ç”¨æ¥ç»˜åˆ¶æ–¹æ¡†çš„å‡½æ•°ï¼š
import cv2
from google.colab.patches import cv2_imshow # ä»£æ›¿ cv2.imshow ä½¿ç”¨ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ collab å´©æºƒ

def draw_rectangles(image_path, line_boundaries):
&quot;&quot;&quot;
ä½¿ç”¨æä¾›çš„çº¿è¾¹ç•Œåœ¨å›¾åƒä¸Šç»˜åˆ¶çŸ©å½¢ã€‚

å‚æ•°ï¼š
image_pathï¼šå›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚
line_boundariesï¼šçº¿è¾¹ç•Œåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªè¾¹ç•Œéƒ½æ˜¯å››ä¸ªç‚¹çš„åˆ—è¡¨ã€‚

è¿”å›ï¼š
æ— 
&quot;&quot;&quot;

# åŠ è½½å›¾åƒ
image = cv2.imread(img_path)

# éå†çº¿è¾¹ç•Œå¹¶ç»˜åˆ¶çŸ©å½¢
for bounding in line_boundaries:
#x1, y1, x2, y2 = int(boundary[0][0]), int(boundary[0][1]), int(boundary[2][0]), int(boundary[2][1])
x1, y1, x2, y2 = map(int, bounding) # å°†åæ ‡è½¬æ¢ä¸ºæ•´æ•°
cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

# ç”¨çŸ©å½¢æ˜¾ç¤ºå›¾åƒ
cv2_imshow(image) # ä»…ä½¿ç”¨ cv2_imshow ä»£æ›¿ cv2.imshow è¿›è¡Œåä½œ
cv2.waitKey(0)
cv2.destroyAllWindows()

è¿™æ˜¯å¸¦æœ‰åœ¨å…¶ä¸Šç»˜åˆ¶çš„ bboxesã€‚

æˆ‘å°è¯•è¿‡ä¸ä½¿ç”¨èˆå…¥ï¼Œä½†æ²¡æœ‰ä»»ä½•åŒºåˆ«ï¼Œä¹Ÿå°è¯•è¿‡åªä½¿ç”¨é¢„æµ‹å™¨ï¼Œä½†æ— æµäºäº‹ã€‚åœ¨ ocr_predictor ä¸­è®¾ç½®preserve_aspect_ratio=False æˆ–symmetric_pad=False ä¹Ÿæ²¡æœ‰åŒºåˆ«ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/78733724/how-to-accurately-calculate-absolute-bbox-coordinates-of-detected-text-in-doctr</guid>
      <pubDate>Thu, 11 Jul 2024 05:38:22 GMT</pubDate>
    </item>
    <item>
      <title>ä»€ä¹ˆæ˜¯ x_train.reshape() ä»¥åŠå®ƒçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</link>
      <description><![CDATA[ä½¿ç”¨ MNIST æ•°æ®é›†
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist

# MNIST æ•°æ®é›†å‚æ•°
num_classes = 10 # æ€»ç±»åˆ«ï¼ˆ0-9 ä½æ•°å­—ï¼‰
num_features = 784 # æ•°æ®ç‰¹å¾ï¼ˆå›¾åƒå½¢çŠ¶ï¼š28*28ï¼‰

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# è½¬æ¢ä¸º float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)

# å°†å›¾åƒå±•å¹³ä¸º 784 ä¸ªç‰¹å¾ï¼ˆ28*28ï¼‰çš„ä¸€ç»´å‘é‡
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])

# å°†å›¾åƒå€¼ä» [0, 255] æ ‡å‡†åŒ–ä¸º [0, 1]
x_train, x_test = x_train / 255., x_test / 255.

åœ¨è¿™äº›ä»£ç çš„ç¬¬ 15 è¡Œä¸­ï¼Œ
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])ã€‚æˆ‘æ— æ³•ç†è§£è¿™äº›é‡å¡‘åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸­åˆ°åº•èµ·ä»€ä¹ˆä½œç”¨..?? è¯·è§£é‡Šä¸€ä¸‹ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</guid>
      <pubDate>Sat, 02 May 2020 06:44:34 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn èšç±»ï¼šé¢„æµ‹ï¼ˆXï¼‰ä¸ fit_predictï¼ˆXï¼‰</title>
      <link>https://stackoverflow.com/questions/37106983/scikit-learn-clustering-predictx-vs-fit-predictx</link>
      <description><![CDATA[åœ¨ scikit-learn ä¸­ï¼Œä¸€äº›èšç±»ç®—æ³•åŒæ—¶å…·æœ‰ predict(X) å’Œ fit_predict(X) æ–¹æ³•ï¼Œä¾‹å¦‚ KMeans å’Œ MeanShiftï¼Œè€Œå…¶ä»–ç®—æ³•ä»…å…·æœ‰åè€…ï¼Œä¾‹å¦‚ SpectralClusteringã€‚æ ¹æ®æ–‡æ¡£ï¼š
fit_predict(X[, y]): å¯¹ X æ‰§è¡Œèšç±»å¹¶è¿”å›èšç±»æ ‡ç­¾ã€‚
predict(X): é¢„æµ‹ X ä¸­æ¯ä¸ªæ ·æœ¬æ‰€å±çš„æœ€æ¥è¿‘èšç±»ã€‚

æˆ‘ä¸å¤ªæ˜ç™½è¿™ä¸¤è€…ä¹‹é—´çš„åŒºåˆ«ï¼Œåœ¨æˆ‘çœ‹æ¥å®ƒä»¬ä¼¼ä¹æ˜¯ç­‰ä»·çš„ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/37106983/scikit-learn-clustering-predictx-vs-fit-predictx</guid>
      <pubDate>Mon, 09 May 2016 02:25:29 GMT</pubDate>
    </item>
    </channel>
</rss>