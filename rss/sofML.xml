<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 16 May 2024 09:15:27 GMT</lastBuildDate>
    <item>
      <title>如何评估 SVM 模型的变量重要性？</title>
      <link>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</link>
      <description><![CDATA[我正在开发一个机器学习项目。我的目标变量是二进制的，我用插入符构建了一个 SVM 径向模型：
ctrl_SVM &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
param_grid_SVM_radial &lt;- Expand.grid(C = c(0.01, 0.1, 1, 10, 100), sigma = c(0.01, 0.1, 1, 10))
SVM_radial &lt;- train(Target~., data=under_svm, method = &quot;svmRadial&quot;, trControl = ctrl_SVM,tuneGrid = param_grid_SVM_radial,
                    指标=“ROC”，预处理=NULL）

如何评估变量的重要性？正确的代码是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</guid>
      <pubDate>Thu, 16 May 2024 08:44:20 GMT</pubDate>
    </item>
    <item>
      <title>有谁可以询问有关使用 NER 和 XLM-RoBERTa 进行信息提取的问题吗？</title>
      <link>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</link>
      <description><![CDATA[大家好我想问一下关于从PDF文档中提取信息的问题。因此，我将使用 XLM-RoBERTa 和 NER 来执行信息提取，并使用来自以下来源的代码进行微调：https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a。从这个来源来看，它确实使用了 BERT，并且在我尝试之后，结果发现来自单词的预测实体与真实值不同。我很困惑是否需要从代码中更改某些内容，或者数据集是否有问题，因为我使用的数据集是自制的数据集。有什么可以问的吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</guid>
      <pubDate>Thu, 16 May 2024 08:03:25 GMT</pubDate>
    </item>
    <item>
      <title>识别和提取特定语句</title>
      <link>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</link>
      <description><![CDATA[鉴于一份包含排除声明的文件，例如“提供的所有文件都证明没有涉及印度尼西亚船只”。我想从文件中识别此类声明，然后使用机器学习模型提取国家/地区。我
正在考虑我们可以使用 lstm 和 NER 或 smtng...请给我更好的管道]]></description>
      <guid>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</guid>
      <pubDate>Thu, 16 May 2024 05:26:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 DeepSeekMath 7b 模型在 vllm 中进行无说明的断言，为什么，如何修复？</title>
      <link>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</guid>
      <pubDate>Thu, 16 May 2024 02:49:09 GMT</pubDate>
    </item>
    <item>
      <title>如何避免保存pytorch中register_forward_hook跳过的参数？</title>
      <link>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</link>
      <description><![CDATA[代码如下。
我可以跳过 register_forward_hook 跳过的保存权重吗？
def get_activation(mem, 名称):
    def get_output_hook（模块，输入，输出）：
        mem[名称] = 输出

    返回 get_output_hook

def add_hook（网络，mem，mapping_layers）：
    对于 net.named_modules() 中的 n、m：
        如果mapping_layers中有n：
            m.register_forward_hook(get_activation(mem, n))

行为_stu = {}
mapping_layers_stu = [&#39;块1&#39;,&#39;块2&#39;]
add_hook（网络，acts_stu，mapping_layers_stu）

]]></description>
      <guid>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</guid>
      <pubDate>Thu, 16 May 2024 01:44:44 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker SDK 无法使用自定义算法运行训练</title>
      <link>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</guid>
      <pubDate>Wed, 15 May 2024 23:54:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Flask 时的机器学习问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</guid>
      <pubDate>Wed, 15 May 2024 14:32:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TensorFlow 提高多类分类的准确性？</title>
      <link>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</link>
      <description><![CDATA[我正在使用 TensorFlow 解决多类分类问题，并在实现令人满意的准确性方面遇到了挑战。我有7节课。文件夹中的每个类包含 2000 个 .csv 文件（每个文件有两列）。当我使用二元分类方法训练模型并用另一个类测试一个类时，准确性和 val_accuracy 会很高，0.85 到 0.95，但是当我使用多类进行测试时，精度最高可达0.47。下面是包含数据抛光和模型多类的代码。
#文件夹中的 csv 类
文件夹路径 = [
    &#39;/content/drive/MyDrive/medical_chem/Aa&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ab&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ac&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ba&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Bb&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Cc&#39;,
    &#39;/内容/驱动器/MyDrive/medical_chem/DD&#39;
]


数据 = []
标签=[]

#加载文件夹并将文件csv存档在数据框中
对于 enumerate(folder_paths) 中的 class_index、folder_path：
    对于 os.listdir(folder_path) 中的文件：
        file_path = os.path.join(文件夹路径, 文件)
        df = pd.read_csv(文件路径)
        数据.append(df)
        标签.append(class_index)

X = 数据
y = 标签

# 找到数据框中的最小值
min_length = min(len(df) for df in X)
# 设置数据帧长度相同
truncated_dfs = [df.head(min_length) for df in X]
# 数据帧到 numpy 数组
X = np.array([df.truncated_dfs 中 df 的值])


# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 标准化数据
X_train = 归一化(X_train, 轴=1)
X_test = 归一化(X_test, 轴=1)
y_train = to_categorical(y_train, num_classes=7)
y_test = to_categorical(y_test, num_classes=7)


X_train.shape、y_train.shape、X_test.shape、y_test.shape
# 输出 ((8943, 2906, 2), (8943, 7), (2236, 2906, 2), (2236, 7))

模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(64, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(32, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(7,activation=&#39;softmax&#39;) # 7个类的输出层
]）

# 训练模型的检查点
checkpoint_path = “training_checkpoint/cp.ckpt”
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_callback = ModelCheckpoint(文件路径=checkpoint_path,
                                      save_weights_only=真，
                                      save_best_only=真，
                                      监视器=&#39;val_loss&#39;,
                                      详细=1)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;分类交叉熵&#39;，
              指标=[&#39;准确性&#39;])

#model.load_weights(检查点路径)

历史 = model.fit(X_train, y_train,
                    纪元=100，
                    验证数据=（X_测试，y_测试），
                    回调=[检查点回调])


我尝试过调整神经网络的架构，尝试不同的激活函数，并优化学习率和批量大小等超参数。但是，我仍然没有达到预期的准确性。
我确信我出错的地方是在预处理数据或模型中，因为二进制训练有很好的结果。
与二进制训练相比，准确度为 0.85 至 0.95
**多类别的预期准确率：高于 0.90
**
数据集： https://drive .google.com/drive/folders/1UAt50dPH7ABeoLu16nfa19g4oVccPeFO?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</guid>
      <pubDate>Wed, 15 May 2024 00:27:22 GMT</pubDate>
    </item>
    <item>
      <title>特征工程是一种新近特征[关闭]</title>
      <link>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</link>
      <description><![CDATA[我有一个客户评分问题，我正在专门研究预测转化并得出转化的概率分数（使用 xgboost 分类器 atm）。我想介绍一个功能，但我很难明确该功能的定义。
具体来说，我知道当事件 A 最近发生时（例如，客户给我们的办公室打电话），这表明客户对我们的产品感兴趣并且可能会转化。为此，我创建了一个新近度功能，基本上是：（今天 - 事件日期）以天为单位。
问题在于，这没有捕捉到旧客户记录的影响。例如，客户可能在一年前给我们打电话（事件 A 触发），并在不久后进行转换，并且使用该公式，新近度特征将相对较大。我希望模型知道低新近度值会转化为更高的概率。
有没有什么好的方法来设计功能来捕捉这种关系？]]></description>
      <guid>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</guid>
      <pubDate>Wed, 15 May 2024 00:26:20 GMT</pubDate>
    </item>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>如何构建交易分类的分类引擎？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78468435/how-to-build-a-classification-engine-for-transaction-categorization</link>
      <description><![CDATA[我目前正在开发这个个人项目，以便让我的生活更轻松地预算支出，并且我正在尝试添加一种方法，允许用户训练模型来对其交易进行分类（或更详细地说是分类）。
问题是，除了本大学课程中的一些术语和小型项目之外，我没有深厚的数据科学背景，我需要一些帮助来理解如何执行此操作以及我需要学习/重新学习哪些内容。从来没有做过这样的事情。
基本上，我的想法是：
允许用户上传其交易的 CSV 数据文件（带有我预定义的校准类别变量，例如交易名称、金额、日期等）。
我知道分类模型必须经过训练才能有效，因此我希望用户分类数据量的阈值是 x，然后用户才能使用模型来预测类别（正确我，如果我不需要这个...）。
一旦超过阈值，模型将被解锁，供用户用来预测其数据的类别。
使用模型时，它将返回包含预测类别的数据集，然后用户可以根据需要编辑类别。编辑后的数据集将反馈给模型以提高准确性。
我的方向正确吗？我该如何执行此操作以及我应该学习/重新学习哪些内容？我可以在 SQL 数据库中执行此操作还是应该使用 Python 脚本（我的理解是我可以将数据存储在 SQL 服务器中，然后在 Python 中执行预处理和 ML 任务）？]]></description>
      <guid>https://stackoverflow.com/questions/78468435/how-to-build-a-classification-engine-for-transaction-categorization</guid>
      <pubDate>Sun, 12 May 2024 15:41:45 GMT</pubDate>
    </item>
    <item>
      <title>将 PyG 数据对象列表转换为 PyG 数据集？</title>
      <link>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</link>
      <description><![CDATA[我有一个 torch_geometric.data.Data 对象的 python 列表（每个对象代表一个图形）。我没有简单的方法来访问这些数据的原始文件：我只有列表。我需要将此数据对象列表转换为 torch_geometric.data.InMemoryDataset 或 torch_geometric.data.Dataset 对象，以便将其与我没有编写的更大的代码库集成。我该怎么做？
需要明确的是，我知道可以使用一系列数据对象来创建 torch_geometric.data.DataLoader 对象。但是，我特别需要一个 Dataset 对象，而不是 DataLoader 对象，因为较大的代码库在将 Dataset 对象转换为加载器之前会对它们执行一些额外的处理步骤。
我不明白为什么 PyG 让这变得如此困难。难道没有一种非常简单的方法可以做到这一点吗？
我尝试使用一个简单的 CustomDataset 类
类 CustomDataset(InMemoryDataset):
    def __init__(自身，数据)：
        超级().__init__()
        self.data = 数据
    
    def __len__(自身):
        返回 len(self.data)
    
    def __getitem__(self, idx):
        样本 = self.data[idx]
        返回样品

当我尝试获取索引 0 处的 Data 对象时，它给了我一个 KeyIndex 错误。我还尝试了上述代码的一个版本，其中超类是 Dataset 而不是 InMemoryDataset，但我不知道如何制作整理方法有效。]]></description>
      <guid>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</guid>
      <pubDate>Sun, 05 May 2024 18:30:03 GMT</pubDate>
    </item>
    <item>
      <title>在一个巨大的向量上执行余弦相似度时出现内存错误</title>
      <link>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</link>
      <description><![CDATA[我试图使用词袋模型构建一个基于内容的推荐系统。我接下来的教程使用 sklearn 库中大小为 (4000,5000) 的向量的余弦相似度，其中 4000 是数据集中的行数，5000 是特征数。
从 sklearn.feature_extraction.text 导入 CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words=&#39;english&#39;)
向量 = cv.fit_transform(new_df[&#39;tags&#39;]).toarray()
// 这里 new_df 是数据帧，new_df[tags] 包含将执行推荐的所有标签（例如：位置、流派）

但是当我尝试在另一个具有 94955 行的数据集上实现余弦相似度（这会产生大小为 (94955, 5000) 的向量时，我收到以下错误
MemoryError：无法为形状为 (94955, 94955) 和数据类型 float64 的数组分配 67.2 GiB

上线了
相似度= cosine_similarity（向量，dense_output=False）
有没有办法实现余弦相似度的批处理，以便我可以克服这个问题，或者我应该更改算法吗？]]></description>
      <guid>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</guid>
      <pubDate>Wed, 07 Sep 2022 03:33:45 GMT</pubDate>
    </item>
    <item>
      <title>从训练集或测试集计算残差值</title>
      <link>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</link>
      <description><![CDATA[我想执行残差分析，并且我知道残差等于观测值减去预测值。但我不知道应该计算训练集还是测试集的残差？
我应该使用这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_train)
残差 = y_train - y_pred.to_frame(&#39;价格&#39;)

或者这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_test)
resid = y_test- y_pred.to_frame(&#39;价格&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</guid>
      <pubDate>Tue, 11 Jun 2019 22:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比 tf/idf 和余弦相似度更好的文本文档聚类？</title>
      <link>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</link>
      <description><![CDATA[我正在尝试对 Twitter 流进行聚类。我想将每条推文放入讨论同一主题的集群中。我尝试使用具有 tf/idf 和余弦相似度的在线聚类算法对流进行聚类，但我发现结果非常糟糕。
使用 tf/idf 的主要缺点是它会聚集关键字相似的文档，因此只能识别几乎相同的文档。例如，考虑以下句子：
1- Stackoverflow 网站是一个不错的地方。
2- Stackoverflow 是一个网站。
前面的两个句子可能会以合理的阈值聚集在一起，因为它们共享很多关键字。但现在考虑以下两句话：
1- Stackoverflow 网站是一个不错的地方。
2- 我定期访问 Stackoverflow。
现在，通过使用 tf/idf，聚类算法将严重失败，因为即使它们谈论同一主题，它们也只共享一个关键字。
我的问题：是否有更好的技术来聚类文档？]]></description>
      <guid>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</guid>
      <pubDate>Mon, 08 Jul 2013 23:40:57 GMT</pubDate>
    </item>
    </channel>
</rss>