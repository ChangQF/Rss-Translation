<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Dec 2024 21:15:02 GMT</lastBuildDate>
    <item>
      <title>面向 JAVA 开发人员的新语音转文本项目 https://github.com/eix128/WhisperJET</title>
      <link>https://stackoverflow.com/questions/79298398/new-speech-to-text-project-for-java-developers-https-github-com-eix128-whisper</link>
      <description><![CDATA[我们很高兴与大家分享 WhisperJET，这是 OpenAI Whisper 的一个全新、可移植且速度最快的 Java 实现。
它非常易于使用，几乎可以实时使用
主要特点：
最小内存消耗：进程使用期间最大 1.5GB。
计划支持多个平台：CUDA、FAST CPU、AMD ROCM、INTEL。
即将支持 iOS 版 RoboVM 和 LibGDX。
WhisperJET 仍在开发中，我们正在积极寻求社区的反馈，以使其变得更好。
存储库链接：
https://github.com/eix128/WhisperJET 在 GitHub 上
我们很乐意听到您的想法、建议和贡献！
感谢您的时间和支持。]]></description>
      <guid>https://stackoverflow.com/questions/79298398/new-speech-to-text-project-for-java-developers-https-github-com-eix128-whisper</guid>
      <pubDate>Fri, 20 Dec 2024 21:07:13 GMT</pubDate>
    </item>
    <item>
      <title>如何使用安装在我的 Windows 机器上的 cuda 和 cudnn 在 wsl 中通过 jupiter notebook 训练 ml 模型</title>
      <link>https://stackoverflow.com/questions/79297793/how-to-use-cuda-and-cudnn-which-is-installed-on-my-windows-machine-side-in-wsl-f</link>
      <description><![CDATA[如何在 wsl 中使用安装在我的 Windows 机器上的 cuda 和 cudnn。我需要通过 jupiter 笔记本训练 ml 模型，我创建了一个虚拟环境并安装了 tensorflow 和 pytorch，然后安装了所有与 jupyter 相关的依赖项，但似乎存在一些小问题，即 cudnnn 未被识别，即使它已正确配置
警告：调用 absl::InitializeLog() 之前的所有日志消息都写入为平台 CUDA 初始化的 STDERR（这不能保证将使用 XLA）。设备：StreamExecutor 设备 (0)：NVIDIA GeForce RTX 4060 笔记本电脑 GPU，计算能力 8.9：I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] 禁用 MLIR 崩溃重现器，设置 env var MLIR_CRASH_REPRODUCER_DIRECTORY 以启用。675 cuda_dnn.cc:522] 加载的运行时 CuDNN 库：9.1.0 但源代码是使用 9.3.0 编译的。CuDNN 库需要具有匹配的主版本和相同或更高的次版本。如果使用二进制安装，请升级您的 CuDNN 库。如果从源代码构建，请确保运行时加载的库与编译配置期间指定的版本兼容。 675 cuda_dnn.cc:522] 加载的运行时 CuDNN 库：9.1.0 但源代码是使用 9.3.0 编译的。CuDNN 库需要具有匹配的主版本和相同或更高的次版本。如果使用二进制安装，请升级您的 CuDNN 库。如果从源代码构建，请确保运行时加载的库与编译配置期间指定的版本兼容。W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES 在 xla_ops.cc:577 失败：FAILED_PRECONDITION：DNN 库初始化失败。查看上述错误了解更多详细信息。：I tensorflow/core/framework/local_rendezvous.cc:405] 本地会合正在中止，状态为：FAILED_PRECONDITION：DNN 库初始化失败。查看上述错误了解更多详细信息。 [[{{node StatefulPartitionedCall}}]]
当我执行 nvcc-version 时，为什么它显示 cuda 12.7，即使我的 Windows 上安装了 cuda 12.2。它的配置是正确的，因为我能够用它运行另一个不同的计算机视觉项目
我尝试了所有不同类型的 pytorch、torch vision 和 cuda 兼容版本，甚至还有多种配置，但似乎没有任何效果，我甚至尝试使用 docker。我认为问题是我没有连接或配置正确的 wsl 连接与我的 Windows 驱动程序，据我所知，或者我可能会再次安装 wsl，似乎存在一些冲突，我无法弄清楚]]></description>
      <guid>https://stackoverflow.com/questions/79297793/how-to-use-cuda-and-cudnn-which-is-installed-on-my-windows-machine-side-in-wsl-f</guid>
      <pubDate>Fri, 20 Dec 2024 16:09:17 GMT</pubDate>
    </item>
    <item>
      <title>在 FastAPI 中提供多种机器学习模型的最佳实践：Docker 与 Celery 与 Redis 或其他方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/79296580/best-practice-for-serving-multiple-machine-learning-models-in-fastapi-docker-vs</link>
      <description><![CDATA[我正在开发一个 FastAPI 应用程序，该应用程序处理来自 Web 应用程序的请求，以使用多个机器学习模型（例如，糖尿病预测模型、面部分析模型等）进行预测。我正在尝试确定部署和管理这些模型的最佳架构。
以下是我正在考虑的方法：
选项 1：Docker + Flask 服务器
将每个模型打包在其自己的 Docker 映像中。
在各自的 Docker 容器内为每个模型运行一个 Flask 服务器。
FastAPI 通过维护每个模型的连接字符串与这些服务器通信（例如，一个用于糖尿病模型，另一个用于面部分析模型等）。

但是，这种方法意味着 FastAPI 必须管理多个连接字符串，随着模型数量的增加，这可能会变得混乱。
选项 2：Celery + Redis
使用 Celery 工作程序处理预测，每个工作程序负责一个特定模型。
使用 Redis 作为任务队列。
FastAPI 只会在 Redis 队列中注册任务，而无需知道各个工作程序的连接详细信息。

这种方法集中了任务管理，并消除了从 FastAPI 管理多个连接字符串的负担。
选项 3：其他方法
在这样的设置中，是否有用于管理和提供多个机器学习模型的替代架构或最佳实践？
我希望系统具有可扩展性、可维护性和高效性。如果您曾经使用过类似的设置，我将不胜感激您的见解！]]></description>
      <guid>https://stackoverflow.com/questions/79296580/best-practice-for-serving-multiple-machine-learning-models-in-fastapi-docker-vs</guid>
      <pubDate>Fri, 20 Dec 2024 08:19:43 GMT</pubDate>
    </item>
    <item>
      <title>iOS Swift 根据用户数据进行动态机器学习</title>
      <link>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</link>
      <description><![CDATA[是否可以使用 Apple ML 框架动态学习应用中的用户行为？我已经使用 Create ML 应用程序训练了一个模型，然后我可以从 iOS 设备更新并重新训练吗？这就是我目前使用该模型的方式。
public func calculateMuscleRecoveryTime(_ workout: Workout) {
do {

let config = MLModelConfiguration()
let model = try MuscleRecoveryModel(configuration: config)

let allMuscleGroups = workout.exercises
.compactMap { $0.muscles } // 展平每个锻炼的肌肉数组
.reduce(Set&lt;MuscleGroup&gt;()) { $0.union($1) } // 联合以删除重复项

let uniqueMuscleGroups = Array(allMuscleGroups)

for muscleGroup in uniqueMuscleGroups {
let trainingIntensity = Int64(workout.intensity.intValue)
let lastTrainedTimestamp = workout.date
let timeAgo = timeAgoInSeconds(from: lastTrainedTimestamp)
let muscleName = muscleGroup.rawValue.lowercased()

let prediction = try model.prediction(muscle: muscleName, intense: trainingIntensity, lastTrained: timeAgo)
}
} catch let error {
print(&quot;Error: &quot;, error)
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</guid>
      <pubDate>Fri, 20 Dec 2024 01:10:59 GMT</pubDate>
    </item>
    <item>
      <title>提取 LLaVa 转换器中的 hidden_​​states</title>
      <link>https://stackoverflow.com/questions/79294056/extracting-hidden-states-in-llavas-transformer</link>
      <description><![CDATA[我需要使用LLaVa来获取图像的嵌入+已提供给LLM的查询。
据我所知，我需要LLaVa模型在经过编码层之前的输出。
从StackOverflow上的这篇文章，我尝试使用pre-hook来保存每个层的输入：
def capture_hidden_​​states(module, module_input):
print(f&#39;module_input: {module_input}\n&#39;)

model_path = &quot;liuhaotian/llava-v1.6-vicuna-7b&quot;
model_name = get_model_name_from_path(model_path)

tokenizer, model, image_processor, context_len = load_pretrained_model(
model_path = model_path,
model_base = None,
model_name = model_name,
load_4bit = True, # 保存 GPU 内存
device = &quot;cuda:0&quot; # 默认
)
model.register_forward_pre_hook(capture_hidden_​​states)

但我的输出显示每个级别的输入都是空的：
module_input: ()

我看到 Hugging Face 的版本在 forward 方法中有一个 output_hidden_​​states 参数，但我目前无法让这个版本的 LLaVa 运行，所以我试图让它在我之前编写的代码上运行。]]></description>
      <guid>https://stackoverflow.com/questions/79294056/extracting-hidden-states-in-llavas-transformer</guid>
      <pubDate>Thu, 19 Dec 2024 11:11:59 GMT</pubDate>
    </item>
    <item>
      <title>ESP32 S3 MINI 1 上的 TinyML 部署问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/79293436/tinyml-deployment-issue-on-esp32-s3-mini-1</link>
      <description><![CDATA[我使用 TinyML 根据 6 轴加速度计和陀螺仪数据预测马的活动。数据通过 ESP32-S3 收集，我正尝试在 ESP32-S3 上部署 TensorFlow Lite (TFLite) 模型以进行实时预测。
但是，我遇到了几个库兼容性和部署问题。尽管遵循了标准的 TinyML 部署实践，但模型与 ESP32-S3 的集成似乎存在问题，尤其是在处理 TFLite Micro 运行时时。我尝试了一些优化，但仍然无法让一切顺利运行。
如果您能提供以下方面的任何建议，我将不胜感激：

如何在 ESP32-S3 上有效部署 TinyML 模型。
可能更适合此用例的替代方法或工具。
有关类似设置的任何提示、文档或经验
]]></description>
      <guid>https://stackoverflow.com/questions/79293436/tinyml-deployment-issue-on-esp32-s3-mini-1</guid>
      <pubDate>Thu, 19 Dec 2024 07:39:46 GMT</pubDate>
    </item>
    <item>
      <title>无论如何，PyTorch DeiT 模型都会持续预测一个类别</title>
      <link>https://stackoverflow.com/questions/79293139/pytorch-deit-model-keeps-predicting-one-class-no-matter-what</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79293139/pytorch-deit-model-keeps-predicting-one-class-no-matter-what</guid>
      <pubDate>Thu, 19 Dec 2024 04:52:07 GMT</pubDate>
    </item>
    <item>
      <title>如何以与“https://www.tensorflow.org/tfmodels/vision/object_detection”中类似的方式修改配置文件？</title>
      <link>https://stackoverflow.com/questions/79292447/how-can-i-modify-the-config-file-in-a-similar-way-used-in-https-www-tensorflo</link>
      <description><![CDATA[我正在寻找有关如何修改现有脚本以使用 EfficientDet D1 模型的指导。我按照教程操作，并使用默认脚本成功训练了自定义数据集。该脚本使用以下行来配置模型：
exp_config = exp_factory.get_exp_config(&#39;retinanet_resnetfpn_coco&#39;)

这对于默认的 RetinaNet 模型来说很好。但是，我想改用 EfficientDet D1 模型。我已经下载了 EfficientDet D1 配置文件，但不确定如何在脚本中引用它。
我尝试过的方法

检查了配置文件：我检查了 EfficientDet D1 配置文件中的参数，看它是否有任何明确的引用名称，可以与 exp_factory.get_exp_config() 一起使用。
检查了替代配置方法：我寻找了加载自定义模型配置的其他方法，但找不到任何明确的说明。

我正在寻找什么

如何修改 exp_factory.get_exp_config() 行以引用 EfficientDet D1 配置文件？
如果这种方法不可行，我该如何加载和引用手动修改配置文件？
配置文件本身是否需要进行任何特定更改才能使其正常工作？

如果需要，我愿意手动修改配置文件参数。并尝试通过此方法运行训练
!python model_main_tf2.py \
--model_dir=/content/trainingdemo/models/my_efficientDet_d0 \
--pipeline_config_path=/content/trainingdemo/models/my_efficientDet_d0/pipeline.config

但结果却是
2024-12-18 23:14:43.163543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] 无法注册 cuFFT 工厂：尝试注册插件 cuFFT 工厂，但已注册一个
警告：调用 absl::InitializeLog() 之前的所有日志消息都写入 STDERR
E0000 00:00:1734563683.182126 16153 cuda_dnn.cc:8310] 无法注册 cuDNN 工厂：尝试注册插件 cuDNN 工厂，但有一个工厂已注册
E0000 00:00:1734563683.187813 16153 cuda_blas.cc:1418] 无法注册 cuBLAS 工厂：尝试注册插件 cuBLAS 工厂，但有一个工厂已注册
回溯（最近一次调用）：
文件 &quot;/content/trainingdemo/model_main_tf2.py&quot;，第 32 行，位于 &lt;module&gt;
从 object_detection 导入 model_lib_v2
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py&quot;，第 29 行，位于 &lt;module&gt;
从 object_detection 导入 eval_util
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/eval_util.py&quot;，第 35 行，位于 &lt;module&gt;
从 object_detection.metrics 导入 coco_evaluation
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/metrics/coco_evaluation.py&quot;，第 28 行，位于 &lt;module&gt;
从 object_detection.utils 导入 o​​bject_detection_evaluation
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/utils/object_detection_evaluation.py&quot;，第 46 行，在 &lt;module&gt;
从 object_detection.utils 导入 label_map_util
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/utils/label_map_util.py&quot;，第 29 行，在 &lt;module&gt;
从 object_detection.protos 导入 string_int_label_map_pb2
文件 &quot;/usr/local/lib/python3.10/dist-packages/object_detection/protos/string_int_label_map_pb2.py&quot;，第 33 行，在 &lt;module&gt;
_descriptor.EnumValueDescriptor(
文件 &quot;/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py&quot;，第 789 行，位于 __new__
_message.Message._CheckCalledFromGeneratedFile()
TypeError：无法直接创建描述符。
如果此调用来自 _pb2.py 文件，则您生成的代码已过期，必须使用 protoc &gt;= 3.19.0 重新生成。
如果您无法立即重新生成您的原型，其他一些可能的解决方法是：
1. 将 protobuf 包降级到 3.20.x 或更低版本。
2. 设置 PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python（但这将使用纯 Python 解析，速度会慢得多）。
]]></description>
      <guid>https://stackoverflow.com/questions/79292447/how-can-i-modify-the-config-file-in-a-similar-way-used-in-https-www-tensorflo</guid>
      <pubDate>Wed, 18 Dec 2024 20:49:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 ssd 和 mobilenetv2 进行对象检测时“目标”和“输出形状”不匹配</title>
      <link>https://stackoverflow.com/questions/79292180/mismatch-target-and-output-shape-on-object-detection-using-ssd-and-mobilenet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79292180/mismatch-target-and-output-shape-on-object-detection-using-ssd-and-mobilenet</guid>
      <pubDate>Wed, 18 Dec 2024 18:50:54 GMT</pubDate>
    </item>
    <item>
      <title>在 Google Cloud Functions 中部署 Keras 模型进行预测</title>
      <link>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</link>
      <description><![CDATA[我一直在尝试将一个非常简单的 Keras 玩具模型部署到 Cloud Functions，该模型可以预测图像的类别，但由于未知原因，当执行到 predict 方法时，它会卡住，不会抛出任何错误，最终会超时。
import functions_framework
import io
import numpy as np
import tensorflow as tf

from tensorflow.keras.models import load_model
from PIL import Image

model = load_model(&quot;gs://&lt;my-bucket&gt;/cifar10_model.keras&quot;)

class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]

def preprocess_image(image_file):
img = Image.open(io.BytesIO(image_file.read()))
img = img.resize((32, 32))
img = np.array(img)
img = img / 255.0
img = img.reshape(1, 32, 32, 3)
return img

@functions_framework.http
def predict(request):
image = preprocess_image(request.files[&#39;image_file&#39;])
print(image.shape) # 这会打印 OK
prediction = model.predict(image)
print(prediction) # 永远不会打印
predict_class = class_names[np.argmax(prediction)]
return f&quot;Predicted class: {predicted_class}&quot;

本地调试运行良好，预测速度如预期一样快（模型权重文件为 2MB）。我还在此过程中添加了几个打印（从上面的代码片段中删除），执行工作正常，直到 predict 方法。
即使最小计算配置应该可以工作，我还是尝试保留更多内存和 CPU，但没有任何效果。该模型托管在存储中，我尝试先下载它，但也没有用。我也尝试在 tf.device(&#39;/cpu:0&#39;) 上下文中进行预测，传递 step=1 参数并首先将图像数组转换为 Keras 数据集，如 ChatGPT 所建议的那样，结果相同。实际上，调用 predict 根本没有打印任何内容。调用 call 而不是 predict 没有任何效果。
我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</guid>
      <pubDate>Tue, 17 Dec 2024 13:51:16 GMT</pubDate>
    </item>
    <item>
      <title>SAM 2.1 是什么导致 hydra.errors.MissingConfigException：未找到主配置模块“sam2”？</title>
      <link>https://stackoverflow.com/questions/79199682/sam-2-1-what-is-causing-hydra-errors-missingconfigexception-primary-config-modu</link>
      <description><![CDATA[我正在尝试使用此处给出的 roboflow 指南微调新的 SAM 2.1 分割模型：Sam 2.1 roboflow 指南
使用 google collab 时，此代码运行正常，没有遇到任何错误。当我在本地机器上运行完全相同的代码时，运行训练代码命令时会出现以下错误：
!python training/train.py -c &#39;configs/train.yaml&#39; --use-cluster 0 --num-gpus 1
在 Windows 10 上使用 vscode 运行时出现以下错误：
hydra.errors.MissingConfigException：未找到主配置模块“sam2”。
检查它是否正确并包含 __init__.py 文件

我的工作目录：
C:\..\SAM_2_1\sam2

]]></description>
      <guid>https://stackoverflow.com/questions/79199682/sam-2-1-what-is-causing-hydra-errors-missingconfigexception-primary-config-modu</guid>
      <pubDate>Mon, 18 Nov 2024 11:00:31 GMT</pubDate>
    </item>
    <item>
      <title>总参数：0，执行 model.summary() keras</title>
      <link>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</link>
      <description><![CDATA[model = Sequential()
model.add(Embedding(283, 100, input_length=56))
model.add(LSTM(150))
model.add(LSTM(150))
model.add(Dense(283,activation=&#39;softmax&#39;))

model.compile(loss=&#39;categorical_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])

model.summary()

Tensorflow 版本：2.16.1，
Keras 版本：3.3.3，
设备 - M3 pro macbook
我尝试使用虚拟数据集（有 282 个唯一单词，使用 tokenizer 检查）构建用于文本生成的 LSTM 模型，预期参数为非零，但输出每个层都有 0 个参数。]]></description>
      <guid>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</guid>
      <pubDate>Fri, 10 May 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：使用“bitsandbytes”8 位量化需要加速：“pip install accelerate”</title>
      <link>https://stackoverflow.com/questions/78040978/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</link>
      <description><![CDATA[我正在尝试使用开源数据集微调 llama2-13b-chat-hf。
我一直使用此模板，但现在出现此错误：
ImportError：使用 bitsandbytes 8 位量化需要 Accelerate：pip install accelerate 和最新版本的 bitsandbytes：pip install -i https://pypi.org/simple/ bitsandbytes
我安装了所有必需的软件包，这些是版本：
 accelerate @ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344
bitsandbytes==0.42.0
datasets==2.17.1
huggingface-hub==0.20.3
peft==0.8.2
tokenizers==0.13.3
torch==2.1.0+cu118
torchaudio==2.1.0+cu118
torchvision==0.16.0+cu118
transformers==4.30.0
trl==0.7.11

有人知道这是不是版本问题吗？
你是怎么解决的？
我尝试安装其他版本，但没有任何效果。]]></description>
      <guid>https://stackoverflow.com/questions/78040978/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</guid>
      <pubDate>Thu, 22 Feb 2024 12:37:11 GMT</pubDate>
    </item>
    <item>
      <title>如何处理缺失值超过 80% 的特征</title>
      <link>https://stackoverflow.com/questions/72611870/how-to-deal-with-features-with-more-than-80-missingness</link>
      <description><![CDATA[我正在处理一个非常糟糕的临床数据集，它有 300 个样本、400 个特征，将用于机器学习。我的导师告诉我这个数据集中有一些具有生物学意义的特征，并要求我保留它们，但其中许多特征缺失了 50% 以上，甚至 80% 以上。我该怎么办？使用模式填充是否会影响它们的性能。]]></description>
      <guid>https://stackoverflow.com/questions/72611870/how-to-deal-with-features-with-more-than-80-missingness</guid>
      <pubDate>Tue, 14 Jun 2022 05:23:12 GMT</pubDate>
    </item>
    <item>
      <title>Google Cloud Vision API 和 Mobile Vision 有什么区别？</title>
      <link>https://stackoverflow.com/questions/44091577/what-is-the-difference-between-google-cloud-vision-api-and-mobile-vision</link>
      <description><![CDATA[我一直在使用 cloud vision API。我做了一些标签和面部检测。在这次 Google I/O 期间，有一个会议讨论了 mobile vision。我知道这两个 API 都与 Google Cloud 中的机器学习有关。
有人能解释（用例）何时使用其中一个而不是另一个吗？
我们可以同时使用这两个 API 来构建什么样的应用程序？]]></description>
      <guid>https://stackoverflow.com/questions/44091577/what-is-the-difference-between-google-cloud-vision-api-and-mobile-vision</guid>
      <pubDate>Sat, 20 May 2017 22:59:56 GMT</pubDate>
    </item>
    </channel>
</rss>