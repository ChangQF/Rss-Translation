<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 10 May 2024 09:15:33 GMT</lastBuildDate>
    <item>
      <title>我正在训练一个暹罗网络，我有 gtx 1650ti 但张量流仅使用 CPU。如何利用GPU</title>
      <link>https://stackoverflow.com/questions/78458890/i-am-training-a-siamese-network-i-have-gtx-1650ti-but-tensorflow-is-only-using</link>
      <description><![CDATA[从tensorflow.python.client导入device_lib

def get_available_devices():
    local_device_protos = device_lib.list_local_devices()
    返回 [local_device_protos 中 x 的 x.name]

打印（获取可用设备（））

输出：[&#39;/设备:CPU:0&#39;]

所以 GPU 甚至没有显示，是否可以利用 GPU ？ ，如果是的话请指导我。
我认为我没有安装 cudnn 或 cuda。
我是张量流和机器学习方面的新手。
谢谢
我在没有使用 GPU 的情况下训练了模型，但它没有给出准确的结果。
所以我必须使用更多数据集进行重新训练，所以我认为使用 GPU 会让工作更快。
关于 GPU 利用率，我没有编写任何代码，因为 GPU 甚至没有显示
从tensorflow.python.client导入device_lib
def get_available_devices():
    local_device_protos = device_lib.list_local_devices()
    返回 [local_device_protos 中 x 的 x.name]

打印（获取可用设备（））

输出：[&#39;/设备:CPU:0&#39;]
]]></description>
      <guid>https://stackoverflow.com/questions/78458890/i-am-training-a-siamese-network-i-have-gtx-1650ti-but-tensorflow-is-only-using</guid>
      <pubDate>Fri, 10 May 2024 08:29:50 GMT</pubDate>
    </item>
    <item>
      <title>当文件位于单独的 URL 中时，进行网页抓取和下载吗？</title>
      <link>https://stackoverflow.com/questions/78458393/webscraping-and-downloading-files-when-they-are-in-seperate-urls</link>
      <description><![CDATA[我正在尝试为我正在进行的项目下载澳大利亚法律案件文件。我试图抓取的网站是 https://www.austlii.edu.au/ 。提供 rtf 文档下载，这很好，但是要访问它们，您必须单击链接才能进入该站点，然后您可以从那里进入。问题是我不太确定如何设计一个程序来有效地做到这一点，例如我不必手动提供不同的 url 来获取文件。
有人知道如何实施一个程序来做到这一点吗？如果您单击下面的链接，您可以看到，它很好地列出了每种情况，但我不太确定如何获取尽可能多的数据。
https://www. austlii.edu.au/cgi-bin/viewtoc/au/cases/nsw/NSWSC/2012/
我尝试了一个简单的网页抓取应用程序，但它太慢且效率低下。]]></description>
      <guid>https://stackoverflow.com/questions/78458393/webscraping-and-downloading-files-when-they-are-in-seperate-urls</guid>
      <pubDate>Fri, 10 May 2024 06:31:57 GMT</pubDate>
    </item>
    <item>
      <title>装袋与粘贴[关闭]</title>
      <link>https://stackoverflow.com/questions/78457742/bagging-vs-pasting</link>
      <description><![CDATA[引用 Aurélien Géron 的《使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习实践：构建智能系统的概念、工具和技术》。
“引导在每个预测器训练的子集中引入了更多的多样性，因此装袋最终会比粘贴产生稍高的偏差，但这也意味着预测器最终的相关性较低，因此整体的方差会减少。总体而言，bagging 通常会产生更好的模型，这解释了为什么它通常受到青睐。”
有人可以直观地解释一下吗？
我无法理解为什么装袋是比粘贴更好的选择？]]></description>
      <guid>https://stackoverflow.com/questions/78457742/bagging-vs-pasting</guid>
      <pubDate>Fri, 10 May 2024 02:32:23 GMT</pubDate>
    </item>
    <item>
      <title>如何基于另一个张量创建张量 - 在实践中学习 PyTorch？</title>
      <link>https://stackoverflow.com/questions/78457370/how-to-create-a-tensor-based-on-another-one-studying-pytorch-in-practice</link>
      <description><![CDATA[我正在使用 PyTorch 学习 IA 并实现一些玩具示例。
首先，我创建了一个一维张量 (X) 和第二个张量 (y)，它们由第一个张量派生而来：
X = torch.arange(0, 100, 1.0).unsqueeze(dim=1)
y = X * 2

因此，我有类似这样的内容
X = tensor([[0.], [1.], [2.], [3.], [4.], [5.], ...
y = tensor([[ 0.], [ 2.], [ 4.], [ 6.], [ 8.], [10.], ...

然后，我训练了一个模型来预测 y，它运行良好。
现在，我想要一些不同的东西。X 将是 2D，y 将是 1D。 y 由 X 元素中的运算计算得出：
如果 x[0] + x[1] &gt;0? y = 10: y -10 
X = tensor([[ 55.5348, -97.7608],
[ 29.0493, -52.1908],
[ 47.1722, -43.1151],
[ 11.1242, -62.8652],
[ 44.8067, 80.8335],...
y = tensor([[-10.], [-10.], [ 10.], [-10.], [ 10.],...

第一个问题，从机器学习的角度来看，这有意义吗？
第二个问题...
我使用 numpy 生成张量。我能用更聪明的方式做到这一点吗？
# 创建 X 值作为测试项
X_numpy = np.random.uniform(low=-100, high=100, size=(1000,2))
print(&quot;X&quot;, X_numpy)

#y_numpy = np.array([[ (n[0]+n[1]) &gt;= 0 ? 10:-10] for n in X_numpy])
y_numpy = np.empty(shape=[0, 1])
for n in X_numpy:
if n[0] + n[1] &gt;= 0:
y_numpy = np.append(y_numpy, [[10.]], axis=0)
elif n[0] + n[1] &lt; 0:
y_numpy = np.append(y_numpy, [[-10.]], axis=0)
]]></description>
      <guid>https://stackoverflow.com/questions/78457370/how-to-create-a-tensor-based-on-another-one-studying-pytorch-in-practice</guid>
      <pubDate>Thu, 09 May 2024 23:28:50 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的模型以匹配 U-Net 图</title>
      <link>https://stackoverflow.com/questions/78457326/how-do-i-fix-my-model-up-to-match-the-u-net-diagram</link>
      <description><![CDATA[运行时错误：张量的大小必须匹配（维度 1 除外）。预期大小为 1024，但列表中第 1 个张量的大小为 512。
U-Net
类 UNet(torch.nn.Module):
  def __init__(自身):
    超级().__init__()
    self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=3, padding=&#39;相同&#39;)
    self.conv2 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=&#39;相同&#39;)
    self.pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)

    self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=&#39;相同&#39;)
    self.conv4 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=&#39;相同&#39;)
    self.pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)

    self.conv5 = torch.nn.Conv2d(128, 256, kernel_size=3, padding=&#39;相同&#39;)
    self.conv6 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=&#39;相同&#39;)
    self.pool3 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)

    self.conv7 = torch.nn.Conv2d(256, 512, kernel_size=3, padding=&#39;相同&#39;)
    self.conv8 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=&#39;相同&#39;)
    self.pool4 = torch.nn.MaxPool2d(kernel_size=2, 步长 = 2)

    self.conv9 = torch.nn.Conv2d(512, 1024, kernel_size=3, padding=&#39;相同&#39;)
    self.conv10 = torch.nn.Conv2d(1024, 1024, kernel_size=3, padding=&#39;相同&#39;)
    self.Upsample = torch.nn.Upsample(scale_factor=2)
    #ConCat
    self.conv11 = torch.nn.Conv2d(1536, 512, kernel_size=3, padding=&#39;相同&#39;)#1024 + 512 = 1536
    self.conv12 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=&#39;相同&#39;)
    self.conv13 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=&#39;相同&#39;)
    #self.Upsample = torch.nn.Upsample(scale_factor=2)
    #ConCat
    self.conv14 = torch.nn.Conv2d(768, 256, kernel_size=3, padding=&#39;相同&#39;) #512 + 256 = 768
    self.conv15 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=&#39;相同&#39;)
    #self.Upsample = torch.nn.Upsample(scale_factor=2)
    #ConCat
    self.conv16 = torch.nn.Conv2d(384, 128, kernel_size=3, padding=&#39;相同&#39;) #256 + 128 = 384
    self.conv17 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=&#39;相同&#39;)
    #self.Upsample = torch.nn.Upsample(scale_factor=2)
    #ConCat
    self.conv18 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=&#39;相同&#39;)
    self.conv19 = torch.nn.Conv2d(192, 64, kernel_size=3, padding=&#39;相同&#39;) #128 + 64 = 192
    self.conv20 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=&#39;相同&#39;)
    self.conv21 = torch.nn.Conv2d(64, 1, kernel_size=1, padding=&#39;相同&#39;)
    self.relu = torch.nn.ReLU()

  def 前向（自身，x）：
    x = self.conv1(x)
    x = self.relu(x)
    x = self.conv2(x)
    x1 = self.relu(x)
    x = self.pool1(x1)

&lt;前&gt;&lt;代码&gt; x = self.conv3(x)
    x = self.relu(x)
    x = self.conv4(x)
    x2 = self.relu(x)
    x = self.pool2(x)

    x = self.conv5(x)
    x = self.relu(x)
    x = self.conv6(x)
    x3 = self.relu(x)
    x = self.pool3(x)

    x = self.conv7(x)
    x = self.relu(x)
    x = self.conv8(x)
    x4 = self.relu(x)
    x = self.pool4(x)

    x = self.conv9(x)
    x = self.relu(x)
    x = self.conv10(x)
    x = self.relu(x)
    x = self.Upsample(x)

    x = torch.cat((x, x4), 暗淡=1)

    x = self.conv11(x)
    x = self.relu(x)`

x = self.conv12(x)
    x = self.relu(x)
    x = self.conv13(x)
    x = self.relu(x)
    x = self.Upsample(x)

    x = torch.cat((x, x3), 暗淡=1)
    x = self.conv14(x)
    x = self.relu(x)
    x = self.conv15(x)
    x = self.relu(x)
    x = self.Upsample(x)

    x = torch.cat((x, x2), 暗淡=1)

    x = self.conv16(x)
    x = self.relu(x)
    x = self.conv17(x)

    x = self.relu(x)
    x = self.conv18(x)
    x = self.relu(x)
    x = self.Upsample(x)

    x = torch.cat((x, x1), 暗淡=1)

    x = self.conv19(x)
    x = self.relu(x)
    x = self.conv20(x)
    x = self.relu(x)
    x = self.conv21(x)
    x = self.relu(x)

    返回x

我尝试更改我的连接输出通道以获得与 1024 相同的输出。我看到错误就在我第一次开始连接的第 10 层之后出现。我想知道我是否连接错误。]]></description>
      <guid>https://stackoverflow.com/questions/78457326/how-do-i-fix-my-model-up-to-match-the-u-net-diagram</guid>
      <pubDate>Thu, 09 May 2024 23:07:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 VAE 减少和重建 CNN 模型参数</title>
      <link>https://stackoverflow.com/questions/78457309/reducing-and-reconstruction-cnn-model-parameters-using-a-vae</link>
      <description><![CDATA[假设我有一个带有 2 个 Conv2D 层的简单 CNN 模型，我在图像数据集上训练了这个模型，我将把这个 CNN 模型的参数输入到 VAE（作为编码器的输入）中，首先将其参数减少为嵌入空间（Z 或 VAE 的潜在空间）。然后，我想使用 VAE 解码器的输出重建 CNN 参数（及其原始尺寸）。
我不知道如何在 PyTorch 中实现这一点，也不知道如何将参数向量重建回 CNN 模型参数。
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78457309/reducing-and-reconstruction-cnn-model-parameters-using-a-vae</guid>
      <pubDate>Thu, 09 May 2024 22:59:50 GMT</pubDate>
    </item>
    <item>
      <title>如何查找变量值以获得特定于因变量范围的值？</title>
      <link>https://stackoverflow.com/questions/78457218/how-do-i-find-the-values-of-variables-to-obtain-a-value-specific-to-a-range-of-t</link>
      <description><![CDATA[我有一个数据库，我使用随机森林算法进行回归分析来预测响应变量，该响应变量取决于 8 个解释变量。我的随机森林算法性能良好。我想找到解释变量的值，以便我的响应变量只取某个区间内的值。我曾尝试实现 slsqp 算法，但无法使代码运行：
from scipy.optimize import minimal
import numpy as np

def objective_function(x, X, best_rf):
prediction = best_rf.predict(np.array(x).reshape(1, -1))
return prediction

lower_bounds = [0, 0, 0, 34.5, 0.25, 0, 0, 0.07699] # 变量 cada 的下限
upper_bounds = [50, 50, 428.2, 93.44, 2, 58, 5, 3.70255] # 变量 cada 的上限

def constrain_function(x, X, best_rf):
prediction = objective_function(x, X, best_rf)
返回 0.3 - 预测 # 限制预测值小于 0.3

initial_guess = [15.0, 0.0, 0.000, 93.44, 0.50, 0.0, 0.0, 0.674536] # 可以使用初始值

result = minimal(
objective_function, 
initial_guess, 
args=(X, best_rf), 
method=&#39;SLSQP&#39;, 
bounds=list(zip(lower_bounds, upper_bounds)), 
constrains={&#39;type&#39;: &#39;ineq&#39;, &#39;fun&#39;: constrain_function, &#39;args&#39;: (X, best_rf)} 
)

optimized_values = result.x
print(&quot;Valores优化解释变量的值：&quot;,optimized_values)

optimized_prediction = objective_function(optimized_values, X, best_rf)
print(&quot;Predicción con valores optimizados:&quot;,optimized_prediction)

我正在等待解决此问题的建议，或者帮助我的代码可以执行我想要的操作。我的代码现在仅打印我给出的解释变量的值]]></description>
      <guid>https://stackoverflow.com/questions/78457218/how-do-i-find-the-values-of-variables-to-obtain-a-value-specific-to-a-range-of-t</guid>
      <pubDate>Thu, 09 May 2024 22:23:12 GMT</pubDate>
    </item>
    <item>
      <title>将分类加权损失函数集成到我的代码中后，准确性下降</title>
      <link>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</link>
      <description><![CDATA[我想提高准确性，并且我有不平衡数据集：akiec：229，bcc：360，bkl：769，df：81，mel：779，vasc：99。为了解决这个问题，我选择将分类加权损失机制集成到模型中。然而，尽管进行了这样的调整，我还是注意到准确性随后下降了。这个意想不到的结果让我怀疑实施过程中出现了错误。您能否帮助我识别和解决任何潜在的错误以优化模型的性能？
# 定义目录
train_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Train&#39;
test_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Test&#39;
validation_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Validation&#39;

# 确定类的数量
numClasses = len(os.listdir(train_dir))

# 定义超参数网格
参数网格 = {
    &#39;学习率&#39;：[0.001]，
    &#39;批量大小&#39;：[16]，
}

最佳准确度 = 0
最佳参数=无

# 执行网格搜索
对于 ParameterGrid(param_grid) 中的参数：
    # 为每次网格搜索迭代加载预训练的 VGG19 模型
    base_model = VGG19(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    对于 base_model.layers 中的图层：
        可训练层 = False

    # 定义函数从最后一个卷积层提取特征
    def extract_features（生成器，模型）：
        特征 = model.predict(生成器)
        返回 features.reshape((len(generator.filenames), -1))

    # 创建数据生成器
    train_datagen = 图像数据生成器(
        重新缩放=1./255，
        旋转范围=20，
        宽度偏移范围=0.2，
        height_shift_range=0.2，
        剪切范围=0.2，
        缩放范围=0.2，
        水平翻转=真，
        fill_mode=&#39;最近&#39;)

    validation_datagen = ImageDataGenerator（重新缩放=1./255）

    train_generator = train_datagen.flow_from_directory(
        火车目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）

    validation_generator =validation_datagen.flow_from_directory(
        验证目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）
&#39;&#39;&#39;

可能这里有一个错误

&#39;&#39;&#39;

    # 定义类索引
    类索引 = {
        &#39;基亚克&#39;: 0,
        “密件抄送”：1，
        &#39;bkl&#39;：2，
        “df”：3，
        “梅尔”：4，
        “血管”：5
    }

    ## 计算班级人数
    类计数 = {}
    对于 os.listdir(train_dir) 中的 class_name：
        class_counts[class_name] = len(os.listdir(os.path.join(train_dir, class_name)))

    # 计算类别权重
    类权重 = {}
    Total_samples = sum(class_counts.values())
    对于 class_name、class_count 在 class_counts.items() 中：
        class_weights[class_indices[class_name]] = 总样本数 / (class_count * len(class_counts))



    # 定义模型架构以接受提取的特征作为输入
    输入=输入(形状=(combined_data_train.shape[1],))
    x = 密集（256，激活=&#39;relu&#39;）（输入）
    预测=密集（numClasses，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=预测）

    # 使用当前的超参数和类权重编译模型
    model.compile（优化器=SGD（learning_rate=params[&#39;learning_rate&#39;]），loss=&#39;sparse_categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]，sample_weight_mode=&#39;temporal&#39;）

    # 定义提前停止
    Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

    # 通过提前停止来训练模型
    num_epochs = 50 # 您可以在此处调整纪元数
    历史=模型.fit(
        x=组合数据训练，
        y=train_generator.labels,
        纪元=num_epochs，
        批量大小=参数[&#39;批量大小&#39;],
        validation_data=(combined_data_validation,validation_generator.labels),
        回调=[early_stopping],
        类权重=类权重，
        详细=1
    ）

    model.save(&#39;best_vgg19_model_with_age.h5&#39;)

    # 根据验证数据评估模型
    _，val_accuracy = model.evaluate（combined_data_validation，validation_generator.labels，详细= 0）

    # 如有必要，更新最佳精度和最佳参数
    如果 val_accuracy &gt;最佳准确度：
        最佳准确度 = 验证准确度
        最佳参数 = 参数

# 打印最佳参数和准确度
print(&#39;最佳参数：&#39;, best_params)
print(&#39;最佳验证准确度：&#39;, best_accuracy)


# 加载最佳模型
best_model = load_model(&#39;best_vgg19_model_with_age.h5&#39;)

]]></description>
      <guid>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</guid>
      <pubDate>Thu, 09 May 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>如何纠正 r 中光栅堆栈的方向</title>
      <link>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</link>
      <description><![CDATA[我有一个每日数据的 NetCDF 文件。我将其转换为光栅堆栈，但其方向不正确（我已附上图像）。我该如何纠正它。我还将我的代码附在本文中。 [raster_stack 图像和 r 代码](https://i.sstatic.net/UmI4kSNE.png)
另外，请告诉是否有人知道，我如何从这些栅格文件中提取年度数据到 Excel 格式（在 arcGIS 或 r 中）。我有 1955 年到 2023 年的栅格文件，其中包含每日降雨量数据，我想根据我拥有的管理形状文件提取年降雨量数据。
我在 r 中运行了代码，但没有取得任何进展。
库（光栅）
库（ncdf4）

ncfile &lt;- nc_open(“E:/IMD2/Rainfall/netcdfFiles_0.25 Degree/RF25_ind1955_rfp25.nc”)

variable_name &lt;- “RAINFALL”
降雨量数据 &lt;- ncvar_get(ncfile, 变量名)
lon &lt;- ncvar_get(ncfile, “经度”)
lat &lt;- ncvar_get(ncfile, “纬度”)
时间 &lt;- ncvar_get(ncfile, “TIME”)
lon_range &lt;- 范围(lon)
lat_range &lt;- 范围(lat)

raster_stack &lt;- stack()
for (i in 1:dim(rainfall_data)[3]) {
  raster_layer &lt;- raster(matrix(rainfall_data[,,i], nrow = nrow(rainfall_data), ncol = ncol(rainfall_data)),
                         xmn = lon_range[1], xmx = lon_range[2], ymn = lat_range[1], ymx = lat_range[2],
                         crs =“+proj=longlat +datum=WGS84”）
  raster_stack &lt;- addLayer(raster_stack, raster_layer)
}

&lt;前&gt;&lt;代码&gt;绘图（raster_stack）
翻转 = t(翻转(raster_stack))
情节（翻转）
]]></description>
      <guid>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</guid>
      <pubDate>Thu, 09 May 2024 13:18:03 GMT</pubDate>
    </item>
    <item>
      <title>IndexError：列表索引超出 Streamlit 范围</title>
      <link>https://stackoverflow.com/questions/78418486/indexerror-list-index-out-of-range-in-streamlit</link>
      <description><![CDATA[因此，我正在尝试构建一个 Streamlit RAG 应用程序，该应用程序从 URL 中提取信息并从中学习。然后，用户可以向模型询问与 URL 中的文章相关的问题，模型将提供合适的答案。
我在笔记本上执行了此操作，效果非常好，只是在我的 Streamlit 应用程序中遇到 IndexError: list index out of range 错误。我将 GoogleGenerativeAIEmbeddings 与 FAISS 结合使用。
这是代码块：
 main_placeholder = sl.empty()
    llm = ChatGoogleGenerativeAI(模型 = &#39;gemini-pro&#39;)
    如果 process_url_clicked:
        加载器 = UnstructedURLLoader(urls = urls)
        main_placeholder.text(&quot;数据加载...开始...✅✅✅&quot;)
        数据 = 加载器.load()
        text_splitter = RecursiveCharacterTextSplitter(
            分隔符 = [&#39;\n&#39;,&#39;\n\n&#39;,&#39;.&#39;,&#39;,&#39;],
            块大小 = 1000,
            块重叠 = 200
        ）
        main_placeholder.text(&quot;文本分割器...开始...✅✅✅&quot;)
        文档 = text_splitter.split_documents(数据)
        嵌入 = GoogleGenerativeAIEmbeddings(模型 = &#39;models/embedding-001&#39;)
        矢量索引= FAISS.from_documents（文档，嵌入）

这是来自 Streamlit 应用程序的回溯：
IndexError：列表索引超出范围
追溯：
文件“C:\Python312\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 584 行，位于 _run_script
    exec（代码，模块.__dict__）
文件“C:\Users\owner\Desktop\Projects\nlp\main.py”，第 84 行，在  中
    vectorstore_openai = FAISS.from_documents（文档，嵌入）
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Python312\Lib\site-packages\langchain_core\vectorstores.py”，第 550 行，from_documents
    返回 cls.from_texts(文本、嵌入、元数据=元数据、**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^
文件“C:\Python312\Lib\site-packages\langchain_community\vectorstores\faiss.py”，第 931 行，from_texts
    返回 cls.__from(
           ^^^^^^^^^^^
文件“C:\Python312\Lib\site-packages\langchain_community\vectorstores\faiss.py”，第 888 行，位于 __from
    索引 = faiss.IndexFlatL2(len(embeddings[0]))
                                  ~~~~~~~~~~^^^

这在我的笔记本上完美运行，我很困惑为什么会发生这种情况。]]></description>
      <guid>https://stackoverflow.com/questions/78418486/indexerror-list-index-out-of-range-in-streamlit</guid>
      <pubDate>Thu, 02 May 2024 10:25:27 GMT</pubDate>
    </item>
    <item>
      <title>如何标记未标记的文本数据</title>
      <link>https://stackoverflow.com/questions/74815891/how-to-label-unlabeled-text-data</link>
      <description><![CDATA[我收集了一些有关食品评论的社交媒体评论，我计划进行方面基础情感分析。作为初始过程，我想将那些未标记的数据标记为一些预定义的主题，例如价格、质量、口味等。
由于我是机器学习的新手，不确定是否可以在没有标记测试数据的情况下进行标记。感谢您的帮助
我尝试过 LDA 主题建模，但觉得这不是正确的方法。]]></description>
      <guid>https://stackoverflow.com/questions/74815891/how-to-label-unlabeled-text-data</guid>
      <pubDate>Thu, 15 Dec 2022 18:17:08 GMT</pubDate>
    </item>
    <item>
      <title>如何找到两个图像之间的相关性</title>
      <link>https://stackoverflow.com/questions/59608470/how-to-find-correlation-between-two-images</link>
      <description><![CDATA[我需要使用 numpy 找到两个图像之间的相关性，但仅使用基本数学。我遇到问题：“*
IndexError：索引 5434 超出了尺寸为 5434* 的轴 0 的范围*”。我有一个代码。请告诉我该怎么做。
img = PIL.Image.open(&quot;SR1.png&quot;).convert(&quot;L&quot;)
im = numpy.array(img)
img2 = PIL.Image.open(&quot;SR61.png&quot;).convert(&quot;L&quot;)
im2 = numpy.array(img2)
np.array(im,dtype=float)
np.array(im2,dtype=浮点)
导入数学
导入数学
def相关系数（X，Y，n）：
    总和X = 0
    总和_Y = 0
    总和_XY = 0
    平方和_X = 0
    平方和_Y = 0


    我=0
    对于范围 (n) 内的 i ：
        sum_X = sum_X + X[i]
        sum_Y = sum_Y + Y[i]
        sum_XY = sum_XY + X[i] * Y[i]
        squareSum_X = squareSum_X + X[i] * X[i]
        squareSum_Y = squareSum_Y + Y[i] * Y[i]

        我=我+1

    corr = (n * sum_XY - sum_X * sum_Y)/(cmath.sqrt((n * squareSum_X - sum_X * sum_X)* (n * squareSum_Y - sum_Y * sum_Y)))
    返回更正


X = im.flatten()
Y = im2.展平()


n = 长度 (X)


print (&#39;{0:.6f}&#39;.format(correlationCoefficient(X, Y, n)))

]]></description>
      <guid>https://stackoverflow.com/questions/59608470/how-to-find-correlation-between-two-images</guid>
      <pubDate>Mon, 06 Jan 2020 07:53:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中添加L1标准化？</title>
      <link>https://stackoverflow.com/questions/48782758/how-to-add-l1-normalization-in-python</link>
      <description><![CDATA[我正在尝试从头开始编写逻辑回归代码。在这段代码中，我认为我的成本导数是我的正则化，但我的任务是添加 L1norm 正则化。你如何在Python中添加这个？是否应该在我定义成本导数的地方添加此内容？感谢任何正确方向的帮助。
def Sigmoid(z):
    返回 1/(1 + np.exp(-z))

def 假设(theta, X):
    返回 Sigmoid(X @ theta)

def Cost_Function(X,Y,theta,m):
    hi = 假设(theta, X)
    _y = Y.reshape(-1, 1)
    J = 1/float(m) * np.sum(-_y * np.log(hi) - (1-_y) * np.log(1-hi))
    返回J

def Cost_Function_Derivative(X,Y,theta,m,alpha):
    hi = 假设(theta,X)
    _y = Y.reshape(-1, 1)
    J = alpha/float(m) * X.T @ (hi - _y)
    返回J

def Gradient_Descent(X,Y,θ,m,alpha):
    new_theta = theta - Cost_Function_Derivative(X,Y,theta,m,alpha)
    返回 new_theta

定义精度(theta):
    正确 = 0
    长度 = len(X_test)
    预测=（假设（theta，X_test）&gt; 0.5）
    _y = Y_test.reshape(-1, 1)
    正确=预测==_y
    my_accuracy = (np.sum(正确) / 长度)*100
    print (&#39;LR 精度:&#39;, my_accuracy, &quot;%&quot;)

def Logistic_Regression(X,Y,alpha,theta,num_iters):
    m = 长度（Y）
    对于范围内的 x（num_iters）：
        new_theta = Gradient_Descent(X,Y,theta,m,alpha)
        θ = 新_θ
        如果 x % 100 == 0：
            打印 #(&#39;θ: &#39;, θ)
            print #(&#39;成本：&#39;, Cost_Function(X,Y,theta,m))
    精度(θ)
ep = .012
初始_theta = np.random.rand(X_train.shape[1],1) * 2 * ep - ep
阿尔法 = 0.5
迭代次数 = 10000
Logistic_Regression(X_train,Y_train,alpha,initial_theta,迭代)
]]></description>
      <guid>https://stackoverflow.com/questions/48782758/how-to-add-l1-normalization-in-python</guid>
      <pubDate>Wed, 14 Feb 2018 08:34:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow Estimator 打印额外的训练指标</title>
      <link>https://stackoverflow.com/questions/45353389/printing-extra-training-metrics-with-tensorflow-estimator</link>
      <description><![CDATA[有没有办法让 Tensorflow 在使用 Estimator API 时打印额外的训练指标（例如批量准确性）？
人们可以添加摘要并在 Tensorboard 中查看结果（请参阅另一篇文章），但我想知道是否有一种优雅的方法可以在训练时打印标量摘要值。这已经发生在训练损失中，例如：
损失 = 0.672677，步长 = 2901（52.995 秒）

但是如果有这样的例子就好了
损失 = 0.672677，准确度 = 0.54678，步长 = 2901（52.995 秒）

没有太多麻烦。我知道大多数时候绘制测试集准确性更有用（我已经使用验证监视器执行此操作），但在这种情况下，我也对训练批次准确性感兴趣。]]></description>
      <guid>https://stackoverflow.com/questions/45353389/printing-extra-training-metrics-with-tensorflow-estimator</guid>
      <pubDate>Thu, 27 Jul 2017 14:14:04 GMT</pubDate>
    </item>
    <item>
      <title>多变量梯度下降</title>
      <link>https://stackoverflow.com/questions/24411315/multi-variable-gradient-descent</link>
      <description><![CDATA[我正在学习梯度下降来计算系数。以下是我正在做的事情：
#!/usr/bin/Python

 将 numpy 导入为 np


   # 这里 m 表示示例的数量，而不是特征的数量
 defgradientDescent(x, y, theta, alpha, m, numIterations):
     xTrans = x.transpose()
     对于范围内的 i(0, numIterations)：
        假设 = np.dot(x, theta)
        损失 = 假设 - y
        # 每个示例的平均成本（2 in 2*m 在这里并不重要。
        # 但为了与渐变保持一致，我将其包括在内）
        成本 = np.sum(损失 ** 2) / (2 * m)
        #print(&quot;迭代 %d | 成本：%f&quot; % (i, 成本))
        # 每个示例的平均梯度
        梯度 = np.dot(xTrans, 损失) / m
        ＃ 更新
        θ = θ - α * 梯度
     返回θ

 X = np.array([41.9,43.4,43.9,44.5,47.3,47.5,47.9,50.2,52.8,53.2,56.7,57.0,63.5,65.3,71.1,77.0,77.8])
 y = np.array([251.3,251.3,248.3,267.5,273.0,276.5,270.3,274.9,285.0,290.0,297.0,302.5,304.5,309.3,321.7,330.7,349.0])
 n = np.max(X.形状)
 x = np.vstack([np.ones(n), X]).T
 m, n = np.shape(x)
 迭代次数= 100000
 阿尔法 = 0.0005
 θ = np.ones(n)
 theta = 梯度下降(x, y, theta, alpha, m, numIterations)
 打印（θ）

现在我上面的代码工作正常了。如果我现在尝试多个变量并将 X 替换为 X1，如下所示：

&lt;预&gt;&lt;代码&gt; X1 = np.array([[41.9,43.4,43.9,44.5,47.3,47.5,47.9,50.2,52.8,53.2,56.7,57.0,63.5,65.3,71.1,77.0,77.8], [ 29.1,29.3,29.5,29.7,29.9,30.3,30.5,30.7,30.8,30.9,31.5,31.7,31.9,32.0,32.1,32.5,32.9]])

然后我的代码失败并显示以下错误：
 JustTestingSGD.py:14: RuntimeWarning: square 遇到溢出
  成本 = np.sum(损失 ** 2) / (2 * m)
  JustTestingSGD.py:19: RuntimeWarning: 减法中遇到无效值
  θ = θ - α * 梯度
  [楠楠楠]

谁能告诉我如何使用X1进行梯度下降？我使用 X1 的预期输出是：

&lt;前&gt;&lt;代码&gt;[-153.5 1.24 12.08]

我也对其他 Python 实现持开放态度。我只想要 X1 和 y 的系数（也称为 thetas）。]]></description>
      <guid>https://stackoverflow.com/questions/24411315/multi-variable-gradient-descent</guid>
      <pubDate>Wed, 25 Jun 2014 14:24:39 GMT</pubDate>
    </item>
    </channel>
</rss>