<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Sat, 28 Dec 2024 01:14:08 GMT</lastBuildDate>
    <item>
      <title>çº¿æ€§å›å½’æ¨¡å‹å‹‰å¼ºä¼˜åŒ–äº†æˆªè·b</title>
      <link>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</link>
      <description><![CDATA[æˆ‘ä»å¤´å¼€å§‹ç¼–å†™äº†ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ã€‚æˆ‘ä½¿ç”¨â€œæ®‹å·®å¹³æ–¹å’Œâ€ä½œä¸ºæ¢¯åº¦ä¸‹é™çš„æŸå¤±å‡½æ•°ã€‚ä¸ºäº†è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä½¿ç”¨çº¿æ€§æ•°æ® (y=x)
è¿è¡Œç®—æ³•æ—¶ï¼Œæˆªè· b å‡ ä¹æ²¡æœ‰å˜åŒ–ã€‚å› æ­¤æ–œç‡ m è®¡ç®—ä¸æ­£ç¡®ã€‚
%matplotlib qt5 
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
y = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345)

class LinearRegression():
def __init__(self):
self.X = None
self.y = None

def ssr(self, m, b):
sum = 0
for i in range(len(self.X)):
sum += (self.y[i] - (m * self.X[i] + b) ) ** 2

return sum

def ssr_gradient(self, m, b):
sum_m = 0
sum_b = 0
n = len(self.X)
for i in range(n):
error = self.y[i] - (m * self.X[i] + b)
derivative_m = -(2/n) * self.X[i] * error # ç›¸å¯¹äº m çš„å¯¼æ•°
derivative_b = -(2/n) * error # ç›¸å¯¹äº m çš„å¯¼æ•°b
sum_m += derived_m
sum_b += derived_b

return sum_m, sum_b

def fit(self, X, y, m, b): # æ¢¯åº¦ä¸‹é™
self.X = X
self.y = y

M, B = np.meshgrid(np.arange(-10, 10, 0.1), np.arange(-10, 10, 0.1))
SSR = np.zeros_like(M)
for i in range(M.shape[0]):
for j in range(M.shape[1]):
SSR[i, j] = self.ssr(M[i, j], B[i, j])

fig, axis = plt.subplots(1, 2, figsize=(12, 6))
gd_model = fig.add_subplot(121,æŠ•å½±=â€œ3dâ€ï¼Œcomputed_zorder=False)
lin_reg_model = axis[1] 

current_pos = (m, b, self.ssr(m, b))
learning_rate = 0.001
min_step_size = 0.001
max_steps = 1000
current_steps = 0

while(current_steps &lt; max_steps):
M_derivative, B_derivative = self.ssr_gradient(current_pos[0], current_pos[1])
M_step_size, B_step_size = M_derivative * learning_rate, B_derivative * learning_rate

if abs(M_step_size) &lt; min_step_size æˆ– abs(B_step_size) &lt; min_step_size:
break

M_new, B_new = current_pos[0] - M_step_size, current_pos[1] - B_step_size

current_pos = (M_new, B_new, self.ssr(M_new, B_new))

print(f&quot;å‚æ•°ï¼šmï¼š{current_pos[0]}; bï¼š{current_pos[1]}; SSRï¼š{current_pos[2]}&quot;)

current_steps += 1

x = np.arange(0, 10, 1)
y = current_pos[0] * x + current_pos[1]
lin_reg_model.scatter(X_train, y_train, label=&quot;Train&quot;, s=75, c=&quot;#1f77b4&quot;)
lin_reg_model.plot(x, y)

gd_model.plot_surface(M, B, SSR, cmap=&quot;viridis&quot;, zorder=0)
gd_model.scatter(current_pos[0], current_pos[1], current_pos[2], c=&quot;red&quot;, zorder=1)
gd_model.set_xlabel(&quot;æ–œç‡ m&quot;)
gd_model.set_ylabel(&quot;æˆªè· b&quot;)
gd_model.set_zlabel(&quot;æ®‹å·®å¹³æ–¹å’Œ&quot;)

plt.tight_layout()
plt.pause(0.001)

gd_model.clear()
lin_reg_model.clear()

self.m = current_pos[0]
self.b = current_pos[1]

def predict(self, X_test):
return self.m * X_test + self.b

lin_reg_model = LinearRegression()
lin_reg_model.fit(X_train, y_train, 1, 10)


è¿™æ˜¯åˆå§‹å€¼ m=1 å’Œ b=10 çš„ç»“æœï¼š
å‚æ•°ï¼šmï¼š-0.45129949840919587ï¼›bï¼š9.50972664859535ï¼›SSRï¼š145.06534359577407

æ˜¾ç„¶è¿™ä¸æ˜¯æœ€ä½³çš„ï¼Œå› ä¸ºæˆ‘çš„æ•°æ®æ˜¯çº¿æ€§çš„ã€‚å› æ­¤æœ€ä½³å‚æ•°åº”è¯¥æ˜¯ m=1 å’Œ b=0
ä½†æˆ‘åœ¨ä»£ç ä¸­æ‰¾ä¸åˆ°é—®é¢˜ã€‚è¯¥ç®—æ³•æ ¹æ®åˆå§‹å€¼æ‰“å°ä¸åŒçš„ç»“æœï¼Œä½†åªè¦ SSR å‡½æ•°æ°å¥½æœ‰ä¸€ä¸ªæœ€å°å€¼ï¼Œå®ƒå°±åº”è¯¥ä¸€éåˆä¸€éåœ°æ‰“å°ç›¸åŒçš„ç»“æœã€‚
æˆ‘å°è¯•ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡ï¼Œä½†é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</guid>
      <pubDate>Fri, 27 Dec 2024 19:40:21 GMT</pubDate>
    </item>
    <item>
      <title>RCNN RESNET 50 æ¨¡å‹ - æˆ‘çš„é£Ÿç‰©å›è´­ TRAIN [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79312423/rcnn-resnet-50-model-my-food-repo-train</link>
      <description><![CDATA[æˆ‘å¯ä»¥å¯»æ±‚å¸®åŠ©å—ï¼Ÿ
æˆ‘æ‰¾åˆ°äº†è¿™ç¯‡ç§‘å­¦æ–‡ç« ï¼š
https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2022.875143/full
å…¶ä¸­æœ‰ä¸€ä¸ªæŒ‡å‘å­˜å‚¨åº“çš„é“¾æ¥ï¼Œå…¶ä¸­åŒ…å«åœ¨ COCO æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚
æˆ‘æƒ³åœ¨ MyFoodRepo æ•°æ®é›†ä¸Šè®­ç»ƒå…¶ä¸­ä¸€ä¸ªæ¨¡å‹ï¼ˆmask r-CNN ResNet50ï¼‰ã€‚æˆ‘æƒ³åœ¨ Google Colab pro ä¸­ä½¿ç”¨ GPUï¼ˆæˆ‘æœ¬åœ°æ²¡æœ‰è¿™ç§å¯èƒ½æ€§ï¼‰ï¼Œä½†åº“å…¼å®¹æ€§å­˜åœ¨å¾ˆå¤§é—®é¢˜ï¼ˆColab æœ‰ CUDA 12.2ï¼‰ã€‚æˆ‘å°è¯•äº†å¾ˆå¤šæ–¹æ³•ï¼Œä½†è‡³ä»Šè¿˜æ²¡æœ‰æ‰¾åˆ°è§£å†³åŠæ³•ã€‚ä¹Ÿè®¸æœ‰äººæœ‰ä¸»æ„ï¼ŸğŸ™ğŸ¼
https://gitlab.aicrowd.com/.../myfoodrepo-experiments/
mmdetetection å­˜åœ¨å¾ˆå¤šé—®é¢˜ï¼š(]]></description>
      <guid>https://stackoverflow.com/questions/79312423/rcnn-resnet-50-model-my-food-repo-train</guid>
      <pubDate>Fri, 27 Dec 2024 17:20:38 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Trainer åœ¨å®Œæˆæ‰€æœ‰ Epoch ä¹‹å‰åœæ­¢</title>
      <link>https://stackoverflow.com/questions/79312241/huggingface-trainer-stops-before-completing-all-epochs</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ Huggingface Trainer è¿›è¡Œåºåˆ—åˆ†ç±»ä»»åŠ¡ï¼Œé…ç½®å¦‚ä¸‹ï¼š

num_train_epochs=5
save_strategy=&quot;epoch&quot;
evaluation_strategy=&quot;epoch&quot;
load_best_model_at_end=False

ä½†æ˜¯ï¼Œè®­ç»ƒåœ¨ç¬¬ 4 ä¸ª epoch ä¹‹ååœæ­¢ï¼Œå°½ç®¡æˆ‘é¢„è®¡å®ƒä¼šå®Œæˆæ‰€æœ‰ 5 ä¸ª epochã€‚
ä»¥ä¸‹æ˜¯æˆ‘çš„è®­ç»ƒå‚æ•°å’Œ Trainer è®¾ç½®çš„ç‰‡æ®µï¼š
åœ¨æ­¤å¤„è¾“å…¥å›¾ç‰‡è¯´æ˜
outputTable
æˆ‘æ€€ç–‘å®ƒå¯èƒ½ä¸æ—©æœŸåœæ­¢è¡Œä¸ºã€æ¢¯åº¦ç´¯ç§¯æˆ–å…¶ä»–å‚æ•°äº¤äº’æœ‰å…³ã€‚
æˆ‘è¿˜ç¡®ä¿æ²¡æœ‰ä½¿ç”¨æ—©æœŸåœæ­¢å›è°ƒã€‚
å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ
æˆ‘å°è¯•è¿‡çš„æ–¹æ³•ï¼š
æˆ‘åœ¨ TrainingArguments ä¸­è®¾ç½®äº† num_train_epochs=5ï¼Œå¹¶ä½¿ç”¨äº† Huggingface Transformers åº“ä¸­çš„ Trainerã€‚æˆ‘çš„ç›®æ ‡æ˜¯è®­ç»ƒæ¨¡å‹æ°å¥½ 5 ä¸ªæ—¶æœŸã€‚æˆ‘ç¡®è®¤æ²¡æœ‰åº”ç”¨ä»»ä½•æ—©æœŸåœæ­¢å›è°ƒæˆ–é¢å¤–çš„ç»ˆæ­¢é€»è¾‘ã€‚
æˆ‘çš„é¢„æœŸï¼š
è®­ç»ƒè¿‡ç¨‹åº”è¯¥è¿è¡Œæ‰€æœ‰ 5 ä¸ªæ—¶æœŸï¼Œè®°å½•æŒ‡æ ‡å¹¶æŒ‰ç…§é…ç½®åœ¨æ¯ä¸ªæ—¶æœŸåä¿å­˜æ£€æŸ¥ç‚¹ã€‚
å‘ç”Ÿäº†ä»€ä¹ˆï¼š
è®­ç»ƒåœ¨ç¬¬ 4 ä¸ªæ—¶æœŸååœæ­¢ï¼Œæ²¡æœ‰ä»»ä½•é”™è¯¯æ¶ˆæ¯ã€‚å°½ç®¡ num_train_epochs æ˜ç¡®è®¾ç½®ä¸º 5ï¼Œä½†æ—¥å¿—ä»è¿‡æ—©åœ°è¡¨æ˜è®­ç»ƒè¿‡ç¨‹ç»“æŸã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79312241/huggingface-trainer-stops-before-completing-all-epochs</guid>
      <pubDate>Fri, 27 Dec 2024 15:54:31 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨å¤šç±»æ•°æ®é›†è®­ç»ƒæ¨¡å‹æ¥é¢„æµ‹å·¥ä½œè§’è‰²ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å±•ä¸€ä¸ªé¡¹ç›®ï¼Œæ ¹æ®åŒ…å«39 ä¸ªç‰¹å¾å’Œ33 ä¸ªç‹¬ç‰¹å·¥ä½œè§’è‰²ä½œä¸ºç›®æ ‡æ ‡ç­¾çš„æ•°æ®é›†æ¥é¢„æµ‹å·¥ä½œè§’è‰²ã€‚æ•°æ®é›†æœ‰ 20,000 è¡Œï¼ŒåŒ…æ‹¬æ•°å€¼åˆ—å’Œåˆ†ç±»åˆ—ã€‚
ä»¥ä¸‹æ˜¯æ•°æ®é›†çš„æ‘˜è¦ï¼š

æ•°å€¼ç‰¹å¾ (14)ï¼šå­¦æœ¯ç§‘ç›®ï¼ˆä¾‹å¦‚æ“ä½œç³»ç»Ÿã€ç®—æ³•ï¼‰çš„ç™¾åˆ†æ¯”ã€é€»è¾‘å•†è¯„åˆ†ã€å‚åŠ çš„é»‘å®¢é©¬æ‹‰æ¾ç­‰ã€‚
äºŒè¿›åˆ¶ç‰¹å¾ (16)ï¼šè¯¸å¦‚â€œå¯ä»¥åœ¨ç³»ç»Ÿä¹‹å‰é•¿æ—¶é—´å·¥ä½œå—ï¼Ÿâ€ï¼Œâ€œè‡ªå­¦èƒ½åŠ›ï¼Ÿâ€ç­‰é—®é¢˜ã€‚
åˆ†ç±»ç‰¹å¾ (8)ï¼šåŒ…æ‹¬â€œè®¤è¯â€ã€â€œè®°å¿†èƒ½åŠ›â€åˆ†æ•°â€ã€â€œæ„Ÿå…´è¶£çš„èŒä¸šé¢†åŸŸâ€ç­‰ã€‚
ç›®æ ‡å˜é‡ï¼šå»ºè®®çš„å·¥ä½œè§’è‰²ï¼ˆä¾‹å¦‚ï¼Œâ€œæ•°æ®åº“å¼€å‘äººå‘˜â€ã€â€œè½¯ä»¶å·¥ç¨‹å¸ˆâ€ç­‰ï¼‰ã€‚

é—®é¢˜ï¼š
æˆ‘é¢„å¤„ç†äº†æ•°æ®é›†å¹¶å°è¯•äº†éšæœºæ£®æ—ã€SVMå’ŒXGBoostç­‰è®­ç»ƒæ¨¡å‹ï¼Œä½†å‡†ç¡®ç‡ä»ç„¶ä¸€ç›´å¾ˆä½ï¼ˆçº¦ 3%ï¼‰ã€‚æˆ‘æ€€ç–‘æˆ‘çš„é¢„å¤„ç†ã€æ¨¡å‹é€‰æ‹©æˆ–è¶…å‚æ•°è°ƒæ•´å¯èƒ½å­˜åœ¨é—®é¢˜ã€‚
é¢„å¤„ç†ç®¡é“ï¼š
ä»¥ä¸‹æ˜¯æˆ‘é¢„å¤„ç†æ•°æ®çš„æ–¹æ³•ï¼š
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler

def transform_data(df):
X = df.drop(&#39;Suggested Job Role&#39;, axis=1)
y = df[&#39;Suggested Job Role&#39;]

# ç‰¹å¾ç±»å‹
two_category_features = [&#39;can work long time before system?&#39;, &#39;self-learning capacity?&#39;, 
&#39;Extra-courses did&#39;, &#39;talenttests taken?&#39;, &#39;olympiads&#39;, &#39;Job/Higherå­¦ä¹ ï¼Ÿ&#39;,
&#39;ä»å¹´é•¿è€…æˆ–é•¿è¾ˆé‚£é‡Œè·å–ä¿¡æ¯&#39;, &#39;å¯¹æ¸¸æˆæ„Ÿå…´è¶£&#39;, &#39;æœŸæœ›è–ªèµ„èŒƒå›´&#39;, 
&#39;å¤„äºæ‹çˆ±å…³ç³»ä¸­ï¼Ÿ&#39;, &#39;è¡Œä¸ºæ¸©å’Œè¿˜æ˜¯å¼ºç¡¬ï¼Ÿ&#39;, &#39;ç®¡ç†æˆ–æŠ€æœ¯&#39;, 
&#39;è–ªæ°´/å·¥ä½œ&#39;, &#39;åŠªåŠ›/èªæ˜çš„å‘˜å·¥&#39;, &#39;æ›¾ç»åœ¨å›¢é˜Ÿä¸­å·¥ä½œè¿‡å—ï¼Ÿ&#39;, &#39;å†…å‘&#39;]

categorical_features = [&#39;è®¤è¯&#39;, &#39;ç ”è®¨ä¼š&#39;, &#39;é˜…è¯»å’Œå†™ä½œæŠ€èƒ½&#39;, 
&#39;è®°å¿†èƒ½åŠ›å¾—åˆ†&#39;, &#39;æ„Ÿå…´è¶£çš„ç§‘ç›®&#39;, 
&#39;æ„Ÿå…´è¶£çš„èŒä¸šé¢†åŸŸ&#39;, &#39;æƒ³è¦åœ¨å“ªå®¶å…¬å¸å®‰é¡¿ä¸‹æ¥ï¼Ÿ&#39;, 
&#39;æ„Ÿå…´è¶£çš„ä¹¦ç±ç±»å‹&#39;]

numeric_features = [&#39;æ“ä½œç³»ç»Ÿä¸­çš„å­¦æœ¯ç™¾åˆ†æ¯”&#39;, &#39;ç®—æ³•ä¸­çš„ç™¾åˆ†æ¯”&#39;, 
&#39;ç¼–ç¨‹æ¦‚å¿µä¸­çš„ç™¾åˆ†æ¯”&#39;, &#39;è½¯ä»¶å·¥ç¨‹ä¸­çš„ç™¾åˆ†æ¯”&#39;,
&#39;è®¡ç®—æœºç½‘ç»œå æ¯”&#39;, &#39;ç”µå­å­¦ç§‘å æ¯”&#39;, 
&#39;è®¡ç®—æœºæ¶æ„å æ¯”&#39;, &#39;æ•°å­¦å æ¯”&#39;, 
&#39;æ²Ÿé€šæŠ€å·§å æ¯”&#39;, &#39;é€»è¾‘å•†è¯„åˆ†&#39;, 
&#39;é»‘å®¢é©¬æ‹‰æ¾&#39;, &#39;ç¼–ç æŠ€èƒ½è¯„åˆ†&#39;, &#39;å…¬å¼€æ¼”è®²è¦ç‚¹&#39;, &#39;æ¯å¤©å·¥ä½œæ—¶é—´&#39;]

# é¢„å¤„ç†ç®¡é“
two_category_transformer = Pipeline(steps=[
(&#39;ordinal&#39;, OrdinalEncoder())
])
categorical_transformer = Pipeline(steps=[
(&#39;onehot&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))
])
numeric_transformer = Pipeline(steps=[
(&#39;minmax&#39;, MinMaxScaler())
])

# ç»„åˆè½¬æ¢
preprocessor = ColumnTransformer(transformers=[
(&#39;two_cat&#39;, two_category_transformer, two_category_features),
(&#39;cat&#39;, categorical_transformer, categorical_features),
(&#39;minmax&#39;, numeric_transformer, numeric_features)
])

formed_X = preprocessor.fit_transform(X)
return formed_X, y

å°è¯•çš„æ¨¡å‹ï¼š

éšæœºæ£®æ—ï¼šä½¿ç”¨é»˜è®¤å‚æ•°ã€‚
SVMï¼šå°è¯•ä½¿ç”¨ RBF å†…æ ¸ï¼Œé»˜è®¤è¶…å‚æ•°ã€‚
XGBoostï¼šé»˜è®¤å‚æ•°ã€‚

å°½ç®¡å°è¯•äº†è¿™äº›æ¨¡å‹ï¼Œå‡†ç¡®ç‡ä»ç„¶åœç•™åœ¨ 3% å·¦å³ã€‚

é—®é¢˜ï¼š

ä¸ºä»€ä¹ˆæ¨¡å‹åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ï¼Ÿ
æˆ‘åº”è¯¥å°è¯•å“ªäº›ç‰¹å®šçš„æŠ€æœ¯æˆ–æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼Œè¶…å‚æ•°è°ƒæ•´ã€ç‰¹å¾é€‰æ‹©ã€è¿‡é‡‡æ ·ï¼‰ï¼Ÿ
æˆ‘å¦‚ä½•æ›´å¥½åœ°å¤„ç†ç›®æ ‡å˜é‡çš„é«˜åŸºæ•°ï¼ˆ33 ä¸ªç‹¬ç‰¹çš„å·¥ä½œè§’è‰²ï¼‰ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</guid>
      <pubDate>Fri, 27 Dec 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>pytorchä¸­å¦‚ä½•åœ¨å•èŠ‚ç‚¹å•GPUç³»ç»Ÿä¸­å¼€å‘å¤šGPUæ¨¡å—ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79311997/how-to-develop-multi-gpu-modules-in-single-node-single-gpu-system-in-pytorch</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªå¤š GPU PyTorch åº”ç”¨ç¨‹åºã€‚torch.distributed ä¸­çš„ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ scatter/gatherï¼‰ä¸èƒ½æ»¡è¶³æˆ‘çš„è¦æ±‚ï¼Œå› æ­¤æˆ‘éœ€è¦å¼€å‘å‰å‘/åå‘ä¼ æ’­æ­¥éª¤ï¼Œåœ¨ GPU ä¹‹é—´å‘é€å’Œæ¥æ”¶æ¢¯åº¦ï¼ŒåŒæ—¶ä½¿ç”¨å†…ç½®æ–¹æ³• scatter/gatherã€‚æˆ‘å¯ä»¥è‡ªå·±åšã€‚æˆ‘çš„æœ€ç»ˆåº”ç”¨ç¨‹åºå°†åœ¨å¤š GPU æœåŠ¡å™¨ä¸Šæ‰§è¡Œã€‚
å¯¹äºå¼€å‘ï¼Œé¢„ç®—é™åˆ¶å°†æˆ‘é™åˆ¶åœ¨å•èŠ‚ç‚¹å• GPU æœåŠ¡å™¨ä¸Šï¼Œå› ä¸ºæˆ‘ä»¬çš„ç»„ç»‡å…±äº«å¤§å‹é›†ç¾¤æœåŠ¡å™¨ã€‚æˆ‘é‡åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯åœ¨è¿™ä¸ªå• GPU ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå¤š GPU è®¾ç½®ã€‚
å¦‚ä½•åœ¨å• GPU ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå¤š GPU è®¾ç½®ä»¥æµ‹è¯•è¿™äº›æ¨¡å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79311997/how-to-develop-multi-gpu-modules-in-single-node-single-gpu-system-in-pytorch</guid>
      <pubDate>Fri, 27 Dec 2024 14:10:33 GMT</pubDate>
    </item>
    <item>
      <title>äº¤å‰éªŒè¯ç»“æœä¸æ··æ·†çŸ©é˜µæŒ‡æ ‡ä¹‹é—´çš„å·®å¼‚</title>
      <link>https://stackoverflow.com/questions/79311670/discrepancy-between-cross-validation-results-and-confusion-matrix-metrics</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä½¿ç”¨åˆ†å±‚ 10 å€äº¤å‰éªŒè¯å¯¹åˆ†ç±»æ¨¡å‹è¿›è¡Œ 5 æ¬¡é‡å¤ï¼Œå¹¶æŠ¥å‘Šç»“æœã€‚é—®é¢˜æ˜¯ï¼Œå½“å®ƒç»˜åˆ¶æ··æ·†çŸ©é˜µæ—¶ï¼Œæˆ‘æ‰‹åŠ¨è®¡ç®—çŸ©é˜µä¸­çš„å‡†ç¡®åº¦å’Œå…¶ä»–æŒ‡æ ‡ï¼Œå®ƒä»¬ä¸æŠ¥å‘Šçš„ç»“æœä¸åŒ
æˆ‘å°è¯•æ±‡æ€»æ‰€æœ‰ç»“æœå¹¶ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç»“æœç»˜åˆ¶æ··æ·†æŒ‡æ ‡ï¼Œä½†æ²¡æœ‰æˆåŠŸ]]></description>
      <guid>https://stackoverflow.com/questions/79311670/discrepancy-between-cross-validation-results-and-confusion-matrix-metrics</guid>
      <pubDate>Fri, 27 Dec 2024 11:23:26 GMT</pubDate>
    </item>
    <item>
      <title>æ›´æ”¹ YOLO ç‰‡æ®µé¢„æµ‹å›¾åƒä¸­çš„ç‰‡æ®µé¢œè‰²</title>
      <link>https://stackoverflow.com/questions/79309903/changing-color-of-segments-from-yolo-segment-predicted-images</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å±•ä¸€ä¸ªå¯¹è±¡æ£€æµ‹é¡¹ç›®ï¼Œåœ¨ä¸€ç»„å›¾åƒä¸­æ£€æµ‹ä¸‰ç§ç±»å‹çš„å¯¹è±¡ã€‚æ­¤å›¾åƒæ˜¾ç¤ºäº† yolo ç‰‡æ®µæ¨¡å‹é¢„æµ‹æ¨¡å‹ç¤ºä¾‹ å›¾åƒã€‚
æˆ‘é‡åˆ°çš„é—®é¢˜æ˜¯æ£€æµ‹åˆ°çš„ç¬¦å·æ˜¯ç™½è‰²çš„ã€‚è¿™ç§é¢œè‰²å¯¹æŸäº›äººæ¥è¯´å¯èƒ½å¯è§ï¼Œä½†å¯¹å…¶ä»–äººæ¥è¯´å¯èƒ½ä¸å¯è§ã€‚æœ‰æ²¡æœ‰åŠæ³•æ”¹å˜è¿™ç§é¢œè‰²ï¼Ÿæˆ‘å¯¹ Python å¾ˆé™Œç”Ÿã€‚æˆ‘å·²ç»é¢„æµ‹äº†æ•´ä¸ªé›†åˆçš„å›¾åƒï¼ˆæ€»è®¡è¶…è¿‡ 100,000 å¼ å›¾åƒï¼‰ã€‚
æˆ‘ä½¿ç”¨ä½¿ç”¨ LabelStudio æ ‡è®°æ„Ÿå…´è¶£çš„ç¬¦å·çš„å›¾åƒè®­ç»ƒäº† YOLOv8 æ¨¡å‹ã€‚åœ¨æ ‡è®°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä½¿ç”¨äº†çº¢è‰²ã€è“è‰²å’Œç»¿è‰²ç­‰é¢œè‰²ã€‚ä½†ä¸çŸ¥ä½•æ•…ï¼Œåœ¨è·å¾—æœ€ç»ˆçš„ YOLOv8 æ¨¡å‹ (best.pt) å¹¶è¿è¡Œé¢„æµ‹åï¼Œæ£€æµ‹åˆ°çš„ç¬¦å·çš„é¢œè‰²ä¸æœ€åˆä½¿ç”¨çš„é¢œè‰²ä¸åŒã€‚æˆ‘æœ‰ä»¥ä¸‹é—®é¢˜ï¼š

å¦‚ä½•æ›´æ”¹æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ç™½è‰²ï¼Ÿ

æœ‰æ²¡æœ‰åŠæ³•ç¡®ä¿åœ¨ labelstudio ä¸Šæ ‡è®°æ—¶ä½¿ç”¨çš„é¢œè‰²ä¿ç•™åœ¨é¢„æµ‹å›¾åƒä¸­ï¼Ÿ


import cv2
import numpy as np

# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ›¿æ¢å®Œæ•´çš„çŸ©å½¢ç™½è‰²è¾¹ç•Œæ¡†çš„é¢œè‰²
def replace_white_rectangles_with_green(image_path, output_path):
# è¯»å–å›¾åƒ
image = cv2.imread(image_path, cv2.IMREAD_COLOR)

# å°†å›¾åƒè½¬æ¢ä¸ºç°åº¦ä»¥è¿›è¡Œè½®å»“æ£€æµ‹
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# å¯¹ç°åº¦å›¾åƒè¿›è¡Œé˜ˆå€¼å¤„ç†ä»¥åˆ›å»ºç™½è‰²åŒºåŸŸçš„äºŒå…ƒæ©ç 
_, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)

# æŸ¥æ‰¾è½®å»“ä»¥æ£€æµ‹å½¢çŠ¶
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

for contour in contours:
# è¿‘ä¼¼è½®å»“ä»¥æ£€æŸ¥å…¶æ˜¯å¦å½¢æˆçŸ©å½¢
epsilon = 0.02 * cv2.arcLength(contour, True)
approx = cv2.approxPolyDP(contour, epsilon, True)

# æ£€æŸ¥è½®å»“æ˜¯å¦æœ‰å››ä¸ªè¾¹ï¼ˆçŸ©å½¢æˆ–æ­£æ–¹å½¢ï¼‰
if len(approx) == 4:
# éªŒè¯å½¢çŠ¶æ˜¯å¦å‡¸ï¼ˆä»¥ç¡®è®¤å®ƒæ˜¯çŸ©å½¢/æ­£æ–¹å½¢ï¼‰
if cv2.isContourConvex(approx):
# å°†è¾¹ç•Œæ¡†çš„ç™½è‰²æ›¿æ¢ä¸ºäº®ç»¿è‰²
cv2.drawContours(image, [contour], -1, (0, 255, 0), thicken=cv2.FILLED)

# ä¿å­˜ä¿®æ”¹åçš„å›¾åƒ
cv2.imwrite(output_path, image)

# è¾“å…¥å’Œè¾“å‡ºå›¾åƒçš„è·¯å¾„
input_image_path = &quot;path_to_your_image.jpg&quot; # æ›¿æ¢ä¸ºè¾“å…¥å›¾åƒè·¯å¾„
output_image_path = &quot;path_to_save_modified_image.jpg&quot; # æ›¿æ¢ä¸ºæ‰€éœ€çš„è¾“å‡ºè·¯å¾„

# å°†å‡½æ•°åº”ç”¨äºå›¾åƒ
replace_white_rectangles_with_green(input_image_path, output_image_path)

print(&quot;å›¾åƒå·²å¤„ç†ï¼Œç™½è‰²çŸ©å½¢è¾¹ç•Œæ¡†è¢«ç»¿è‰²æ›¿æ¢ã€‚&quot;)

æˆ‘å°è¯•äº†ä¸Šè¿°ä»£ç ï¼Œä½†ä¸çŸ¥ä½•æ•…å®ƒåªä¼šéšæœºäº§ç”Ÿç»¿è‰²æ¡†æˆ–åœ¨åŸæœ¬ä¸ºç™½è‰²çš„åŸå§‹èƒŒæ™¯ä¸Šäº§ç”Ÿç»¿è‰²æ¡†ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79309903/changing-color-of-segments-from-yolo-segment-predicted-images</guid>
      <pubDate>Thu, 26 Dec 2024 16:15:02 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åˆ©ç”¨ä»£è¡¨æ€§æ¨¡å¼åŸç†æé«˜ç°åº¦çº¹ç†åˆ†å‰²çš„å‡†ç¡®æ€§[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79309630/how-to-improve-the-accuracy-of-grayscale-texture-segmentation-using-the-principl</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79309630/how-to-improve-the-accuracy-of-grayscale-texture-segmentation-using-the-principl</guid>
      <pubDate>Thu, 26 Dec 2024 13:48:07 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ batch() ä»…è¿”å›ä¸€ä¸ªæ‰¹æ¬¡ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79309133/why-does-batch-return-only-one-batch</link>
      <description><![CDATA[æˆ‘æ˜¯å›¾åƒå¤„ç†æ–¹é¢çš„æ–°æ‰‹ã€‚æˆ‘æœ‰ä¸¤ä¸ªäºŒè¿›åˆ¶ç±»ä½œä¸ºå­ç›®å½•ï¼Œæ€»å…±æœ‰ 496 å¼ å›¾åƒï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡ä¸­è¿˜æœ‰å‰©ä½™çš„ 13 å¼ å›¾åƒï¼Œè¿™ç»™æˆ‘å¸¦æ¥äº†é—®é¢˜ã€‚å› æ­¤ï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡ä¸­çš„ tf.dataset å¼ é‡ä¸æ˜¯ (32, 300, 300, 3)ï¼Œè€Œæ˜¯ (16, 300, 300, 3)ã€‚å®é™…ä¸Šï¼Œæˆ‘æ³¨æ„åˆ°ï¼š

shuffle åå®ƒåŒ…å« 13 ä¸ªæ‰¹æ¬¡
æ‰¹å¤„ç†åå®ƒåªäº§ç”Ÿ 1 ä¸ªæ‰¹æ¬¡ï¼ˆæˆ‘å‡è®¾å®ƒæ˜¯å‰©ä½™æ‰¹æ¬¡ï¼‰
drop_remainder æ—¶æ•°æ®ä¸ºç©º

ä¸ºä»€ä¹ˆ shuffle ååªå‰©ä¸‹ 1 ä¸ªæ‰¹æ¬¡ï¼Ÿ
image_size = (300, 300)
batch_size = 32

train_dataset = image_dataset_from_directory(
dataset_dir,
image_size=(image_size[0], image_size[1]),
batch_size=batch_size,
label_mode=&quot;binary&quot;,
validation_split=0.2,
subset=&quot;training&quot;,
seed=123,
)

train_dataset = train_dataset.shuffle(1000)
train_dataset = train_dataset.batch(
batch_size=batch_size, drop_remainder=True
).prefetch(buffer_size=AUTOTUNE)

print(train_dataset.cardinality().numpy())
]]></description>
      <guid>https://stackoverflow.com/questions/79309133/why-does-batch-return-only-one-batch</guid>
      <pubDate>Thu, 26 Dec 2024 09:23:52 GMT</pubDate>
    </item>
    <item>
      <title>åˆ†ç¦»å›¾åƒå†…çš„ç›²æ–‡å­—ç¬¦</title>
      <link>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</link>
      <description><![CDATA[æˆ‘æ­£åœ¨åšä¸€ä¸ªå°†ç›²æ–‡è½¬æ¢ä¸ºæ–‡æœ¬çš„é¡¹ç›®ã€‚æˆ‘å·²ç»ç¼–å†™äº†ä»å›¾åƒä¸­è¯†åˆ«ç›²æ–‡ç‚¹çš„ä»£ç ï¼Œä½†æˆ‘ä¸çŸ¥é“å¦‚ä½•å°†ç›²æ–‡åˆ†å‰²æˆå•å…ƒæ ¼ã€‚
è¿™éƒ¨åˆ†æ˜¯è¯†åˆ«å›¾åƒä¸­çš„æ–‘ç‚¹ï¼ˆè¾ƒå°çš„ä½è´¨é‡å›¾åƒç›®å‰ä¸èµ·ä½œç”¨ï¼‰
import cv2
import numpy as np
from sklearn.cluster import KMeans

# åŠ è½½å›¾åƒ
image_path = &quot;braille.jpg&quot;
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# è®¾ç½® SimpleBlobDetector
params = cv2.SimpleBlobDetector_Params()

# æŒ‰åŒºåŸŸè¿‡æ»¤ï¼ˆæ–‘ç‚¹å¤§å°ï¼‰
params.filterByArea = True
params.minArea = 100 # æ ¹æ®ç‚¹å¤§å°è¿›è¡Œè°ƒæ•´
params.maxArea = 1000

# æŒ‰åœ†åº¦è¿‡æ»¤
params.filterByCircularity = True
params.minCircularity = 0.9 # è°ƒæ•´ç‚¹çš„å½¢çŠ¶

# æŒ‰å‡¸åº¦è¿‡æ»¤
params.filterByConvexity = False
params.minConvexity = 0.7

# æŒ‰æƒ¯æ€§è¿‡æ»¤ï¼ˆåœ†åº¦ï¼‰
params.filterByInertia = True
params.minInertiaRatio = 0.95

# ä½¿ç”¨å‚æ•°åˆ›å»ºæ£€æµ‹å™¨
detector = cv2.SimpleBlobDetector_create(params)

# æ£€æµ‹æ–‘ç‚¹
keypoints = detector.detect(image)

# å°†æ£€æµ‹åˆ°çš„æ–‘ç‚¹ç»˜åˆ¶ä¸ºçº¢è‰²åœ†åœˆ
output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
output_image = cv2.drawKeypoints(output_image, keypoints, np.array([]),
(0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

print(&quot;è¾“å‡ºå›¾åƒ&quot;)
cv2.imshow(&quot;è¾“å‡ºå›¾åƒ&quot;,output_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

print(f&quot;æ£€æµ‹åˆ°çš„æ–‘ç‚¹æ•°é‡ï¼š{len(keypoints)}&quot;)

ä»¥ä¸‹ä»£ç å°† blob çš„åæ ‡æ”¾åœ¨å›¾å½¢ä¸Šï¼ˆè®¤ä¸ºè¿™ç§æ–¹å¼å¯èƒ½æ›´å®¹æ˜“æ“ä½œï¼‰
#å°†å›¾åƒè½¬æ¢ä¸ºå›¾å½¢

import matplotlib.pyplot as plt
import numpy

blob_coords = np.array([kp.pt for kp in keypoints]) #blob çš„åæ ‡
rounded_coords = np.round(blob_coords).astype(int) #å››èˆäº”å…¥çš„åæ ‡

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

# åŸºäºé‚»è¿‘åº¦çš„åˆ†ç»„
# å¦‚æœ X è·ç¦»å°äºæœ€å°è·ç¦»
# å¦‚æœ Y è·ç¦»å°äºæœ€å°è·ç¦»
# å­˜å‚¨ X å’Œ Y åæ ‡

# è®¡ç®—æœ€å° x å’Œ yå·®å¼‚ï¼ˆå°è¯•åŸºäºæ¥è¿‘åº¦ï¼‰
minx = 10000
miny = 10000
for i in x_coords:
for j in x_coords:
if abs(i - j) &lt;= minx and (15 &lt; abs(i - j)): # å•å…ƒæ ¼å®½åº¦é˜ˆå€¼
minx = abs(i - j)

for i in y_coords:
for j in y_coords:
if abs(i - j) &lt;= miny and (15 &lt; abs(i - j)): # å•å…ƒæ ¼é«˜åº¦é˜ˆå€¼
miny = abs(i - j)

print(f&quot;Smallest x difference: {minx}, Smallest y difference: {miny}&quot;,)

# ç»˜å›¾
fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # ç»˜åˆ¶æ–‘ç‚¹
ax.invert_yaxis()
plt.title(&quot;Braille Cell Detection&quot;)
plt.show()

å°è¯•é€šè¿‡æ¥è¿‘åº¦å°†å®ƒä»¬åˆ†å¼€ï¼ˆä½äºæˆ‘å°è¯•å°†è·ç¦»å¾ˆè¿‘çš„ç‰©ä½“åˆ†ç»„åˆ°ä¸€èµ·ï¼ˆæˆ‘å°†è·ç¦»å¾ˆè¿‘çš„ç‰©ä½“åˆ†ç»„åˆ°ä¸€èµ·ï¼‰ï¼Œä½†æˆ‘æ— æ³•ç†è§£å…¶ä¸­çš„é€»è¾‘ã€‚æˆ‘ä¹Ÿå°è¯•äº†ç»„èšç±» (Kmeans)ï¼Œä½†å®ƒä¸æ˜¯å¾ˆå‡†ç¡®ï¼Œå¹¶ä¸”ä¸é€‚ç”¨äºå…·æœ‰ä¸åŒå­—ç¬¦æ•°çš„å›¾åƒï¼Œå› ä¸ºå®ƒéœ€è¦ä¸æ–­çŸ¥é“è¦å½¢æˆå¤šå°‘ä¸ªç°‡ã€‚
# å°è¯• kmeans èšç±»æ–¹æ³•
# kmeans ä¸èµ·ä½œç”¨ï¼ˆæ— æ³•ä»å›¾åƒä¸­æ‰¾å‡ºç°‡çš„æ•°é‡ï¼‰
# å¦‚æœå¯ä»¥æ‰¾å‡º nclustersï¼Œåˆ™å¯ä»¥å·¥ä½œ

å¯¼å…¥æ•°å­¦
ä» sklearn.cluster å¯¼å…¥ KMeans

blob_coords = np.array([kp.pt for kp in keypoints]) # æå– blob çš„ (x, y) ä½ç½®
rounded_coords = np.round(blob_coords).astype(int) # ä¸ºç®€å•èµ·è§ï¼Œå¯¹åæ ‡è¿›è¡Œå››èˆäº”å…¥

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # ç»˜åˆ¶æ–‘ç‚¹

ax.invert_yaxis() # åè½¬ Y è½´ä»¥è·å¾—ç±»ä¼¼å›¾åƒçš„åæ ‡
plt.title(&quot;ç›²æ–‡å•å…ƒæ£€æµ‹&quot;)
plt.show()

inertias = []

# 2
kmeans = KMeans(n_clusters=26)
kmeans.fit(rounded_coords)

plt.scatter(x_coords,y_coords, c=kmeans.labels_)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</guid>
      <pubDate>Wed, 25 Dec 2024 05:54:00 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ YOLO å°†æ— ç•Œè¾“å…¥å¯¼å‡ºåˆ° mlpackage/mlmodel æ–‡ä»¶</title>
      <link>https://stackoverflow.com/questions/79305588/use-yolo-with-unbounded-input-exported-to-an-mlpackage-mlmodel-file</link>
      <description><![CDATA[æˆ‘æƒ³åˆ›å»ºä¸€ä¸ª .mlpackage æˆ– .mlmodel æ–‡ä»¶ï¼Œå¯ä»¥å°†å…¶å¯¼å…¥ Xcode è¿›è¡Œå›¾åƒåˆ†å‰²ã€‚ä¸ºæ­¤ï¼Œæˆ‘æƒ³ä½¿ç”¨ YOLO ä¸­çš„åˆ†å‰²åŒ…æ¥æ£€æŸ¥å®ƒæ˜¯å¦ç¬¦åˆæˆ‘çš„éœ€æ±‚ã€‚
ç°åœ¨çš„é—®é¢˜æ˜¯ï¼Œæ­¤è„šæœ¬åˆ›å»ºçš„ .mlpackage æ–‡ä»¶ä»…æ¥å—å›ºå®šå¤§å°ï¼ˆ640x640ï¼‰çš„å›¾åƒï¼š
from ultralytics import YOLO

model = YOLO(&quot;yolo11n-seg.pt&quot;)

model.export(format=&quot;coreml&quot;)

æˆ‘æƒ³åœ¨è¿™é‡Œè¿›è¡Œä¸€äº›æ›´æ”¹ï¼Œå¯èƒ½ä½¿ç”¨ coremltoolsï¼Œä»¥å¤„ç†æ— ç•ŒèŒƒå›´ï¼ˆæˆ‘æƒ³å¤„ç†ä»»æ„å¤§å°çš„å›¾åƒï¼‰ã€‚è¿™é‡Œæœ‰ä¸€äº›æè¿°ï¼šhttps://apple.github.io/coremltools/docs-guides/source/flexible-inputs.html#enable-unbounded-rangesï¼Œä½†æˆ‘ä¸æ˜ç™½å¦‚ä½•ç”¨æˆ‘çš„è„šæœ¬å®ç°å®ƒã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79305588/use-yolo-with-unbounded-input-exported-to-an-mlpackage-mlmodel-file</guid>
      <pubDate>Tue, 24 Dec 2024 12:23:06 GMT</pubDate>
    </item>
    <item>
      <title>iOS Swift æ ¹æ®ç”¨æˆ·æ•°æ®è¿›è¡ŒåŠ¨æ€æœºå™¨å­¦ä¹ </title>
      <link>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</link>
      <description><![CDATA[æ˜¯å¦å¯ä»¥ä½¿ç”¨ Apple ML æ¡†æ¶åŠ¨æ€å­¦ä¹ åº”ç”¨ä¸­çš„ç”¨æˆ·è¡Œä¸ºï¼Ÿæˆ‘å·²ç»ä½¿ç”¨ Create ML åº”ç”¨ç¨‹åºè®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åæˆ‘å¯ä»¥ä» iOS è®¾å¤‡æ›´æ–°å¹¶é‡æ–°è®­ç»ƒå—ï¼Ÿè¿™å°±æ˜¯æˆ‘ç›®å‰ä½¿ç”¨è¯¥æ¨¡å‹çš„æ–¹å¼ã€‚
public func calculateMuscleRecoveryTime(_ workout: Workout) {
do {

let config = MLModelConfiguration()
let model = try MuscleRecoveryModel(configuration: config)

let allMuscleGroups = workout.exercises
.compactMap { $0.muscles } // å±•å¹³æ¯ä¸ªé”»ç‚¼çš„è‚Œè‚‰æ•°ç»„
.reduce(Set&lt;MuscleGroup&gt;()) { $0.union($1) } // è”åˆä»¥åˆ é™¤é‡å¤é¡¹

let uniqueMuscleGroups = Array(allMuscleGroups)

for muscleGroup in uniqueMuscleGroups {
let trainingIntensity = Int64(workout.intensity.intValue)
let lastTrainedTimestamp = workout.date
let timeAgo = timeAgoInSeconds(from: lastTrainedTimestamp)
let muscleName = muscleGroup.rawValue.lowercased()

let prediction = try model.prediction(muscle: muscleName, intense: trainingIntensity, lastTrained: timeAgo)
}
} catch let error {
print(&quot;Error: &quot;, error)
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</guid>
      <pubDate>Fri, 20 Dec 2024 01:10:59 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨ Google Cloud Functions ä¸­éƒ¨ç½² Keras æ¨¡å‹è¿›è¡Œé¢„æµ‹</title>
      <link>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨å°è¯•å°†ä¸€ä¸ªéå¸¸ç®€å•çš„ Keras ç©å…·æ¨¡å‹éƒ¨ç½²åˆ° Cloud Functionsï¼Œè¯¥æ¨¡å‹å¯ä»¥é¢„æµ‹å›¾åƒçš„ç±»åˆ«ï¼Œä½†ç”±äºæœªçŸ¥åŸå› ï¼Œå½“æ‰§è¡Œåˆ° predict æ–¹æ³•æ—¶ï¼Œå®ƒä¼šå¡ä½ï¼Œä¸ä¼šæŠ›å‡ºä»»ä½•é”™è¯¯ï¼Œæœ€ç»ˆä¼šè¶…æ—¶ã€‚
import functions_framework
import io
import numpy as np
import tensorflow as tf

from tensorflow.keras.models import load_model
from PIL import Image

model = load_model(&quot;gs://&lt;my-bucket&gt;/cifar10_model.keras&quot;)

class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]

def preprocess_image(image_file):
img = Image.open(io.BytesIO(image_file.read()))
img = img.resize((32, 32))
img = np.array(img)
img = img / 255.0
img = img.reshape(1, 32, 32, 3)
return img

@functions_framework.http
def predict(request):
image = preprocess_image(request.files[&#39;image_file&#39;])
print(image.shape) # è¿™ä¼šæ‰“å° OK
prediction = model.predict(image)
print(prediction) # æ°¸è¿œä¸ä¼šæ‰“å°
predict_class = class_names[np.argmax(prediction)]
return f&quot;Predicted class: {predicted_class}&quot;

æœ¬åœ°è°ƒè¯•è¿è¡Œè‰¯å¥½ï¼Œé¢„æµ‹é€Ÿåº¦å¦‚é¢„æœŸä¸€æ ·å¿«ï¼ˆæ¨¡å‹æƒé‡æ–‡ä»¶ä¸º 2MBï¼‰ã€‚æˆ‘è¿˜åœ¨æ­¤è¿‡ç¨‹ä¸­æ·»åŠ äº†å‡ ä¸ªæ‰“å°ï¼ˆä»ä¸Šé¢çš„ä»£ç ç‰‡æ®µä¸­åˆ é™¤ï¼‰ï¼Œæ‰§è¡Œå·¥ä½œæ­£å¸¸ï¼Œç›´åˆ° predict æ–¹æ³•ã€‚
å³ä½¿æœ€å°è®¡ç®—é…ç½®åº”è¯¥å¯ä»¥å·¥ä½œï¼Œæˆ‘è¿˜æ˜¯å°è¯•ä¿ç•™æ›´å¤šå†…å­˜å’Œ CPUï¼Œä½†æ²¡æœ‰ä»»ä½•æ•ˆæœã€‚è¯¥æ¨¡å‹æ‰˜ç®¡åœ¨å­˜å‚¨ä¸­ï¼Œæˆ‘å°è¯•å…ˆä¸‹è½½å®ƒï¼Œä½†ä¹Ÿæ²¡æœ‰ç”¨ã€‚æˆ‘ä¹Ÿå°è¯•åœ¨ tf.device(&#39;/cpu:0&#39;) ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œé¢„æµ‹ï¼Œä¼ é€’ step=1 å‚æ•°å¹¶é¦–å…ˆå°†å›¾åƒæ•°ç»„è½¬æ¢ä¸º Keras æ•°æ®é›†ï¼Œå¦‚ ChatGPT æ‰€å»ºè®®çš„é‚£æ ·ï¼Œç»“æœç›¸åŒã€‚å®é™…ä¸Šï¼Œè°ƒç”¨ predict æ ¹æœ¬æ²¡æœ‰æ‰“å°ä»»ä½•å†…å®¹ã€‚è°ƒç”¨ call è€Œä¸æ˜¯ predict æ²¡æœ‰ä»»ä½•æ•ˆæœã€‚
æˆ‘é”™è¿‡äº†ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</guid>
      <pubDate>Tue, 17 Dec 2024 13:51:16 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/XGBRanker ç”Ÿæˆæ¦‚ç‡è€Œä¸æ˜¯æ’ååˆ†æ•°</title>
      <link>https://stackoverflow.com/questions/79278625/xgboost-xgbranker-to-produce-probabilities-instead-of-ranking-scores</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªå­¦ç”Ÿè€ƒè¯•æˆç»©çš„æ•°æ®é›†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
ç­çº§ ID ç­çº§è§„æ¨¡ å­¦ç”Ÿç¼–å· æ™ºå•† å­¦ä¹ æ—¶é—´ åˆ†æ•°
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 4 4 93 5 50
2 4 5 103 9 88
2 4 8 112 12 99
2 4 1 200 10 100 

æˆ‘æƒ³å»ºç«‹ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨ IQ å’Œ Hours_Studied é¢„æµ‹è°å°†æˆä¸ºç­çº§ç¬¬ä¸€åï¼ˆå³æœ€é«˜ Scoreï¼‰ï¼Œå¯¹äºä»»ä½•ç»™å®šçš„ Class_IDç‰¹å¾ã€‚
ç”±äºè¿™æ˜¯ä¸€ä¸ªæ’åé—®é¢˜ï¼Œå› æ­¤è‡ªç„¶çš„ä¸€ç±»å­¦ä¹ æ¨¡å‹æ˜¯ä½¿ç”¨ XGBoost ä¸­çš„ XGBRanker æˆ– lightgbm ä¸­çš„ LGBMRankerã€‚
è¿™æ˜¯æˆ‘ä½¿ç”¨ xgboost çš„ä»£ç ï¼š
from sklearn.model_selection import GroupShuffleSplit
import xgboost as xgb

gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df[&#39;Class_ID&#39;])

X_train_inds, X_test_inds = next(gss)

train_data = df.iloc[X_train_inds]
X_train = train_data.loc[:, ~train_data.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;,&#39;Score&#39;])]
y_train = train_data.loc[:, train_data.columns.isin([&#39;Score&#39;])]

groups = train_data.groupby(&#39;Class_ID&#39;).size().to_frame(&#39;Class_size&#39;)[&#39;Class_size&#39;].to_numpy()

test_data = df.iloc[X_test_inds]

X_test = test_data.loc[:, ~test_data.columns.isin([&#39;Student_Number&#39;,&#39;Score&#39;])]
y_test = test_data.loc[:, test_data.columns.isin([&#39;Score&#39;])]

model = xgb.XGBRanker( 
tree_method=&#39;hist&#39;,
device=&#39;cuda&#39;,
booster=&#39;gbtree&#39;,
objective=&#39;rank:pairwise&#39;,
enable_categorical=True,
random_state=42, 
learning_rate=0.1,
colsample_bytree=0.9, 
eta=0.05, 
max_depth=6, 
n_estimators=175, 
subsample=0.75 
)

model.fit(X_train, y_train, group=groups, verbose=True)

def predict(model, df):
return model.predict(df.loc[:, ~df.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;])])

predictions = (X_test.groupby(&#39;Class_ID&#39;)
.apply(lambda x: predict(model, x)))

ä»£ç è¿è¡Œè‰¯å¥½ï¼Œå…·æœ‰åˆç†çš„é¢„æµ‹èƒ½åŠ›ã€‚ä½†æ˜¯ï¼Œè¾“å‡ºæ˜¯â€œç›¸å…³æ€§å¾—åˆ†â€åˆ—è¡¨ï¼Œè€Œä¸æ˜¯æ¦‚ç‡åˆ—è¡¨ã€‚ä½†ä¼¼ä¹ XGBRanker å’Œ LGBMRanker éƒ½æ²¡æœ‰å±æ€§ predict_probaï¼Œè¯¥å±æ€§è¿”å›è·å¾—ç­çº§æœ€é«˜åˆ†çš„æ¦‚ç‡ã€‚
æ‰€ä»¥æˆ‘çš„é—®é¢˜æ˜¯ï¼Œæœ‰æ²¡æœ‰åŠæ³•å°† ç›¸å…³æ€§å¾—åˆ† è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œæˆ–è€…æ˜¯å¦æœ‰å…¶ä»–è‡ªç„¶ç±»åˆ«çš„æ’åæ¨¡å‹å¯ä»¥å¤„ç†æ­¤ç±»é—®é¢˜ï¼Ÿ
ç¼–è¾‘åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæˆ‘åªå…³å¿ƒæœ€ç»ˆååˆ—å‰èŒ…çš„äººï¼ˆæˆ–è€…å¯èƒ½æ˜¯å‰ä¸‰åï¼‰ï¼Œæ‰€ä»¥æ’åå¹¶ä¸æ˜¯é‚£ä¹ˆé‡è¦ï¼ˆä¾‹å¦‚ï¼ŒçŸ¥é“å­¦ç”Ÿ 4 æ’åç¬¬ 11 ä½ï¼Œå­¦ç”Ÿ 8 æ’åç¬¬ 12 ä½å¹¶ä¸é‚£ä¹ˆé‡è¦ï¼‰ï¼Œæ‰€ä»¥æˆ‘æƒ³ä¸€ç§æ–¹æ³•æ˜¯åœ¨ xgboost ä¸­ä½¿ç”¨åˆ†ç±»è€Œä¸æ˜¯æ’åã€‚ä½†æˆ‘æƒ³çŸ¥é“è¿˜æœ‰å…¶ä»–æ–¹æ³•å—ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79278625/xgboost-xgbranker-to-produce-probabilities-instead-of-ranking-scores</guid>
      <pubDate>Fri, 13 Dec 2024 14:20:37 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learnäº¤å‰éªŒè¯è¿‡åº¦æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/20357705/scikit-learn-cross-validation-over-fitting-or-under-fitting</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ scikit-learn cross_validation å¹¶è·å¾—ä¾‹å¦‚ 0.82 å¹³å‡åˆ†æ•° (r2_scorer)ã€‚
æˆ‘å¦‚ä½•çŸ¥é“ä½¿ç”¨ scikit-learn å‡½æ•°æ—¶æ˜¯å¦å­˜åœ¨è¿‡åº¦æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/20357705/scikit-learn-cross-validation-over-fitting-or-under-fitting</guid>
      <pubDate>Tue, 03 Dec 2013 17:25:03 GMT</pubDate>
    </item>
    </channel>
</rss>