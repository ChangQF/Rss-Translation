<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 22 Jun 2024 01:03:20 GMT</lastBuildDate>
    <item>
      <title>使用 C/fortran 函数在 pytorch 中创建可微分函数</title>
      <link>https://stackoverflow.com/questions/78654585/create-differentiable-functions-in-pytorch-with-c-fortran-functions</link>
      <description><![CDATA[我正在尝试创建一种策略，使从编译语言（C/fortran）调用的函数相对于输入中的 pytorch 张量可微分。
为了清楚起见，让我们考虑以下示例：
假设我有一个神经网络“NN”，它接受输入 x 并计算输出：
y = NN(x;\theta) \theta：参数
假设我需要获取此函数 y 的输出并在 C/fortran 中执行一些操作（出于速度目的）。因此，我需要将输出张量转换为 numpy 数组，然后将其发送到 C/fortran 中的函数。此时，我的操作的输出不可微分，并且无法计算操作输出相对于输入的梯度。
我被困在这一点上。我看过各种论坛，但没有成功。
如果有人有任何建议，我将不胜感激。
我尝试了 pytorch 的扩展“torch.autograd.Function”，但我不明白如何解决这个问题。前向传递很简单，但我不明白如何实现后向传递。]]></description>
      <guid>https://stackoverflow.com/questions/78654585/create-differentiable-functions-in-pytorch-with-c-fortran-functions</guid>
      <pubDate>Fri, 21 Jun 2024 22:05:42 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型训练期间使用提前停止功能时出现 Python 解释器状态错误</title>
      <link>https://stackoverflow.com/questions/78653468/python-interpreter-state-error-during-tensorflow-model-training-with-early-stopp</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78653468/python-interpreter-state-error-during-tensorflow-model-training-with-early-stopp</guid>
      <pubDate>Fri, 21 Jun 2024 16:16:11 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：图形执行错误不兼容的形状：ViT 中 PatchEncoder 中的 [32,800,64] 与 [32,125,64]</title>
      <link>https://stackoverflow.com/questions/78653170/invalidargumenterror-graph-execution-error-incompatible-shapes-32-800-64-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78653170/invalidargumenterror-graph-execution-error-incompatible-shapes-32-800-64-vs</guid>
      <pubDate>Fri, 21 Jun 2024 15:17:08 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中如何处理“真实”数据和封闭式方程？</title>
      <link>https://stackoverflow.com/questions/78652914/how-to-deal-with-real-data-and-closed-formed-equation-in-machine-learning</link>
      <description><![CDATA[我的目标是对来自“现实世界”（传感器）的一组数据进行回归分析。
数据采用表格格式。有 6 个独立特征，其值差异很大（需要缩放）。此外，因变量具有很大的可变性（可能需要缩放？）。
当其中一个变量（假设 X1）的绝对值较低时，初始经典训练会显示预测中的弱点。
专家告诉我，在 X1 较低的这个特定区域中，要预测的值（我们称之为 Y）可以通过线性回归来近似。因此，如果所有其他特征都是恒定的，则 X1 和 Y 具有 Y=a * X1 + b 类型的线性依赖关系。
问题是系数“a”和“b”取决于其他特征 a = f(X2,X3,X4,X5)...
请注意，我有一个表，其中列出了其他 5 个特征的几种组合的系数“a”和“b”。
我想将“物理信息”的线性化集成到训练过程中。但我该怎么做呢？我看过物理信息神经网络，但它们仅适用于 PDE，而不是像我一样的闭式方程。
对我来说，一个自然的做法是通过方程在这个区域生成假数据。这会被视为物理信息机器学习吗？我看不出添加假数据和添加试图满足方程的损失之间的区别。]]></description>
      <guid>https://stackoverflow.com/questions/78652914/how-to-deal-with-real-data-and-closed-formed-equation-in-machine-learning</guid>
      <pubDate>Fri, 21 Jun 2024 14:26:46 GMT</pubDate>
    </item>
    <item>
      <title>MOT 遮挡度量</title>
      <link>https://stackoverflow.com/questions/78652127/mot-occlusion-metric</link>
      <description><![CDATA[是否有任何度量计算，例如 IDF1、MOTA、HOTA 等，专门用于计算方法/算法的性能，例如遮挡对象的 DeepSORT
我试过 IDF1，但它是 ID 的度量，例如 ID 切换，尽管遮挡是 ID 切换的原因之一，但我只想将度量重点放在遮挡上]]></description>
      <guid>https://stackoverflow.com/questions/78652127/mot-occlusion-metric</guid>
      <pubDate>Fri, 21 Jun 2024 11:32:47 GMT</pubDate>
    </item>
    <item>
      <title>聚类实际上会减少数据集中的行数吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78652112/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</link>
      <description><![CDATA[我正在阅读 Luis G. Serrano 的《grokking Machine Learning》一书，看到了以下摘录：

看起来聚类和降维没什么相似之处，但实际上它们并没有太大区别。如果我们有一张满是数据的表，每一行对应一个数据点，每一列对应一个特征。因此，我们可以使用聚类来减少数据集中的行数，使用降维来减少列数。

我对聚类减少行数的说法有疑问。似乎聚类只是对数据进行分组，而不减少其列数。我错了吗？]]></description>
      <guid>https://stackoverflow.com/questions/78652112/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</guid>
      <pubDate>Fri, 21 Jun 2024 11:30:08 GMT</pubDate>
    </item>
    <item>
      <title>如何知道是否有办法改进这个模型，以及如何知道我是否达到了特定模型的限制[关闭]</title>
      <link>https://stackoverflow.com/questions/78650661/how-to-know-if-there-is-a-way-to-improve-this-model-and-also-how-should-i-know-i</link>
      <description><![CDATA[我是数据科学领域的新手，所以当我建立模型时，我不确定我是否已经到达终点，而且我也不知道我还能如何改进模型。这是随机森林分类器，我使用 RandomizeSearchCV 作为参数，最终得到了最高的 73%。此外，我还使用了 class_weight 来平衡类别，我缩放了所有内容并清理了数据，正如您将看到的。我不确定这是否是最好的方法，也不知道在制作模型时 73% 是否足够好，也不知道我是否达到了随机森林分类器的极限。
从 matplotlib 导入 pyplot 作为 plt
从 matplotlib.colors 导入 ListedColormap
导入 pandas 作为 pd
导入 numpy 作为 np
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.model_selection 导入 RandomizedSearchCV、train_test_split
从 sklearn.preprocessing 导入 OneHotEncoder、StandardScaler、LabelEncoder、MinMaxScaler、MaxAbsScaler、RobustScaler
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 classes_report、accuracy_score、confusion_matrix
从 imblearn.over_sampling 导入 SMOTE

pd.set_option(&#39;display.max_rows&#39;, None)
pd.set_option(&#39;display.max_columns&#39;, None)
df = pd.read_csv(&#39;pokemon_data.csv&#39;)

duplicates = df.duplicated()
if duplicates.any():
print(df[duplicates], &quot;DUPLICATE&quot;)
else:
print(&quot;NO DUPLICATES&quot;)

class_dist = df[&#39;type1&#39;].value_counts()
print(class_dist)

df.replace(&#39;—&#39;, np.nan, inplace=True)
numerical_cols = df.select_dtypes(include=np.number).columns
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())
# 现在我们填充分类缺失数据列
categorical_cols = df.select_dtypes(include=&#39;object&#39;).columns
df[categorical_cols] = df[categorical_cols].fillna(&#39;Unknown&#39;)

preprocessor = ColumnTransformer(
transformers=[
(&#39;num&#39;, StandardScaler(), [&#39;dexnum&#39;]),
(&#39;cat&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;), [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;, &#39;egg_group2&#39;])
])

features = [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;,
&#39;egg_group2&#39;]

X = df[features] # 我们用来预测的变量 
y_type1 = df[&#39;type1&#39;] # 我们预测的内容
y_type2 = df[&#39;type2&#39;] # 我们预测什么

preprocessor = ColumnTransformer(
transformers=[
(&#39;num&#39;, StandardScaler(), []),
(&#39;cat&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;), [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;, &#39;egg_group2&#39;])
])

# Train_test_split 用于将数据集拆分为两个子集，即训练集和测试集
X_train, X_test, y_type1_train, y_type1_test = train_test_split(X, y_type1, test_size=0.4, random_state=42)

X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

param_dist = {
&#39;n_estimators&#39;: [9000],
&#39;max_depth&#39;: [1000],
&#39;min_samples_split&#39;: [2],
&#39;min_samples_leaf&#39;: [1],
&#39;max_features&#39;: [&#39;log2&#39;],
&#39;bootstrap&#39;: [False]
}

rf_type1 = RandomForestClassifier(class_weight=&#39;balanced&#39;, random_state=42)
random_search = RandomizedSearchCV(estimator=rf_type1, param_distributions=param_dist, n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1)
random_search.fit(X_train, y_type1_train)

# 获取最佳参数
print(&quot;找到最佳参数：&quot;, random_search.best_params_)
print(&quot;最佳准确率： &quot;, random_search.best_score_)

# 使用最佳参数重新训练模型
best_rf = random_search.best_estimator_
y_type1_pred_best = best_rf.predict(X_test)

# 评估模型
print(&quot;具有最佳参数的 Type1 分类报告：&quot;)
print(classification_report(y_type1_test, y_type1_pred_best))
print(&quot;具有最佳参数的 Type1 准确率：&quot;, accuracy_score(y_type1_test, y_type1_pred_best))

]]></description>
      <guid>https://stackoverflow.com/questions/78650661/how-to-know-if-there-is-a-way-to-improve-this-model-and-also-how-should-i-know-i</guid>
      <pubDate>Fri, 21 Jun 2024 06:07:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 pytorch 时如何最大化 GPU 利用率？</title>
      <link>https://stackoverflow.com/questions/78650444/how-to-maximize-gpu-utilization-when-using-pytorch</link>
      <description><![CDATA[我使用的是 RTX 4090 和 7950X CPU。我的目标是在表格数据上运行相对简单的模型时最大限度地提高 GPU 利用率。该模型的参数少于 100 万个，数据形状为 (5,000,000, 120)。当我训练模型时，只有 18% 的 GPU 被利用，完成训练大约需要 3 个小时。
主要问题是，如果我能以某种方式利用 90% 的 GPU，训练时间将显著减少，可能减少到当前时间的五分之一，这将为我节省大量时间。
我尝试了各种解决方案，例如调整批处理大小、增加模型的复杂性以及更改 DataLoader 的 num_workers，但这些都没有起到很好的作用。无论我如何调整，GPU 负载仍然在 10-15% 左右。这真是令人沮丧。
由此，我想到了使用多处理的想法。由于我使用的是单个 GPU，并且单个模型仅使用 18%，因此我仍有空间运行另​​外四个模型。我认为同时运行五个不同的模型可以将 GPU 利用率提高到 100% 左右，从而节省大量时间。但是，当我尝试使用 PyTorch 的多处理时，结果并不理想。
有人能帮我解决这个问题吗，或者我的想法在 PyTorch 中不可行？
我尝试过的方法：

将批次大小从 64 增加到 4096、40962、40964
使用 num_workers (2,4,8)
向模型添加更多层
使用 pytorch.multiprocessing
]]></description>
      <guid>https://stackoverflow.com/questions/78650444/how-to-maximize-gpu-utilization-when-using-pytorch</guid>
      <pubDate>Fri, 21 Jun 2024 04:50:59 GMT</pubDate>
    </item>
    <item>
      <title>通过几个步骤优化一个过程：如果我们使用一个模型几次才能够计算出损失，那么如何训练它？</title>
      <link>https://stackoverflow.com/questions/78650011/optimizing-a-process-in-several-steps-how-to-train-a-model-if-we-use-it-severa</link>
      <description><![CDATA[我有一个包含一定步骤数的过程；假设是 3。

我们从一个初始化的零矩阵 M0 开始，该矩阵描述系统的状态，并且必须采取一项行动，其后果是随机的，但受该行动的强烈影响
我们更新矩阵 (M1)，然后再次采取行动
我们再次更新矩阵 (M2)，采取最后一个行动
只有现在我们才能从最后一个矩阵 M3 计算损失，因此我们可以评估我们的策略

我已经建立了一个神经网络，其中状态矩阵是输入，输出是决定采取哪种行动的权重列表。从我（初学者）的理解来看，整个过程有点像循环神经网络，但多了一些步骤。
我用 Python 实现了这个过程，但当我尝试训练模型时，GradientTape() 看起来不太好，因为我的变量从未计算过梯度；我不确定，但我认为损失的随机性使得梯度不可计算（计算权重的损失远非易事，因为权重放在图的边缘，我们对其执行算法）。
我曾想过在没有权重列表的情况下进行强化学习以采取行动，但我不知道奖励的随机性效果如何。此外，我从未做过这样的事情，我只有一周的时间来实现一切。行动空间也很大，所以这种方法存在很多不确定性。
有没有解决这类问题的常见做法？]]></description>
      <guid>https://stackoverflow.com/questions/78650011/optimizing-a-process-in-several-steps-how-to-train-a-model-if-we-use-it-severa</guid>
      <pubDate>Fri, 21 Jun 2024 00:18:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 和 rembg 去除车窗玻璃背景？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78649936/how-can-remove-car-window-glass-bg-with-python-rembg</link>
      <description><![CDATA[我正在使用 rembg 去除背景，但问题是车窗玻璃的背景没有被去除。在这种情况下，如何去除车窗玻璃的背景。有人能帮帮我吗？
主图像 
--&gt;当前结果图像
--&gt;预期结果图像 
output_data = rembg.remove(input_data)
]]></description>
      <guid>https://stackoverflow.com/questions/78649936/how-can-remove-car-window-glass-bg-with-python-rembg</guid>
      <pubDate>Thu, 20 Jun 2024 23:37:59 GMT</pubDate>
    </item>
    <item>
      <title>超分辨率 GAN 训练中生成器和鉴别器损失之间的不平衡</title>
      <link>https://stackoverflow.com/questions/78647617/imbalance-between-generator-and-discriminator-losses-in-gan-training-for-super-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78647617/imbalance-between-generator-and-discriminator-losses-in-gan-training-for-super-r</guid>
      <pubDate>Thu, 20 Jun 2024 12:57:24 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras-Tuner 中使用 F1 分数作为指标时遇到困难</title>
      <link>https://stackoverflow.com/questions/77498936/having-trouble-using-f1-score-as-a-metric-in-keras-tuner</link>
      <description><![CDATA[我想使用 keras-tuner 优化二元图像分类模型的 f1 分数。我知道 keras 已删除默认的 F1 Score 指标，因此我尝试使用 Tensorflow Addons 的 F1Score() 类，但它给出了 KeyError，因为据我所知，keras-tuner 无法将 f1-score 识别为指标。
我尝试使用 Tensorflow Addons 的 F1Score() 类作为指标，但似乎不起作用。
def model_builder(hp):
model = tf.keras.Sequential()
model.add(tf.keras.layers.Rescaling(scale=255))
model.add(tf.keras.layers.TimeDistributed(net))
model.add(tf.keras.layers.Dense(units=hp.Int(
&#39;units&#39;, min_value=32, max_value=512, step=32),activation=&#39;relu&#39;))
model.add(tf.keras.layers.GlobalAveragePooling3D())
model.add(tf.keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

custom_optimizer = keras.optimizers.Adam(
learning_rate=hp.Choice(&#39;learning_rate&#39;,values=[1e-2,1e-3,1e-4]),
beta_1=hp.Choice(&#39;beta_1&#39;,values=[0.9,0.99,0.999]),
beta_2=hp.Choice(&#39;beta_2&#39;,values=[0.999,0.9999]),
epsilon=hp.Float(&#39;epsilon&#39;,min_value=1e-10,max_value=1e-7)
)

# 定义指标
#metrics = [tf.keras.metrics.AUC(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.TruePositives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalseNegatives(), tf.keras.metrics.FalsePositives()]

# 使用 SGD 优化器运行
model.compile(optimizer=&#39;sgd&#39;,
loss=keras.losses.binary_crossentropy, metrics=tfa.metrics.F1Score(num_classes=1, average=&#39;macro&#39;,threshold=0.5))

返回模型

# 初始化调谐器
tuner = RandomSearch(
model_builder,
# 了解“objective”应转换为二进制
objective=Objective(tfa.metrics.F1Score(num_classes=1, average=&#39;macro&#39;,threshold=0.5), direction=max),
max_trials=10, # 根据需要调整试验次数
directory=&#39;test_directory/logs&#39;
)

# 启动调整过程
tuner.search(train_ds, epochs=10, validation_data=(
val_ds), callbacks=combined)

这是我的代码输出的错误：
RuntimeError Traceback (most recent call last)
3 combined = [tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, waiting=5)]
5 # 启动调整过程
----&gt; 6 tuner.search(train_ds, epochs=10, validation_data=(
7 val_ds), callbacks=combined)

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras_tuner\src\engine\base_tuner.py:234，位于 BaseTuner.search(self, *fit_args, **fit_kwargs)
232 self.on_trial_begin(trial)
233 self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)
--&gt; 234 self.on_trial_end(trial)
235 self.on_search_end()

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras_tuner\src\engine\base_tuner.py:338，位于 BaseTuner.on_trial_end(self, trial)
332 def on_trial_end(self, trial):
333 &quot;&quot;&quot;在试验结束时调用。
334 
335 参数：
336 trial：`Trial` 实例。
337 &quot;&quot;&quot;
--&gt; 338 self.oracle.end_trial(trial)
339 self.save()

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras_tuner\src\engine\oracle.py:108，位于 synchronized.&lt;locals&gt;.wrapped_func(*args, **kwargs)
...
文件 &quot;C:\Users\name_here\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras_tuner\src\engine\objective.py&quot;，第 59 行，位于 get_value
return logs[self.name]
~~~~^^^^^^^^^^^
KeyError: &lt;tensorflow_addons.metrics.f_scores.F1Score 对象位于 0x000001C8709D6710&gt;

我想知道是否有一种解决方法可以从 keras 的 Tuner 类中获取 f1 分数。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77498936/having-trouble-using-f1-score-as-a-metric-in-keras-tuner</guid>
      <pubDate>Fri, 17 Nov 2023 01:42:54 GMT</pubDate>
    </item>
    <item>
      <title>如何将主成分分析的结果映射回输入模型的实际特征？</title>
      <link>https://stackoverflow.com/questions/67585809/how-to-map-the-results-of-principal-component-analysis-back-to-the-actual-featur</link>
      <description><![CDATA[当我运行下面的代码时，我会看到“pca.explained_variance_ratio_”和一个直方图，其中显示了每个特征解释的方差比例。
import statsmodels.api as sm
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf
from statsmodels.stats import anova

mtcars = sm.datasets.get_rdataset(&quot;mtcars&quot;, &quot;datasets&quot;, cache=True).data
df = pd.DataFrame(mtcars)

x = df.iloc[:,2:]

from sklearn.preprocessing import StandardScaler

pca = PCA(n_components=11)
principalComponents = pca.fit_transform(df)

#绘制每个 PC 的方差
PC = range(1, pca.n_components_+1)
plt.bar(PC, pca.explained_variance_ratio_, color=&#39;gold&#39;)
plt.xlabel(&#39;Principal Components&#39;)
plt.ylabel(&#39;Variance %&#39;)
plt.xticks(PC)


如何将 PCA 1 和 2 映射回数据框中的原始特征？]]></description>
      <guid>https://stackoverflow.com/questions/67585809/how-to-map-the-results-of-principal-component-analysis-back-to-the-actual-featur</guid>
      <pubDate>Tue, 18 May 2021 12:04:25 GMT</pubDate>
    </item>
    <item>
      <title>二元语法和单元语法文本特征提取有什么区别</title>
      <link>https://stackoverflow.com/questions/43463792/what-is-the-difference-between-bigram-and-unigram-text-features-extraction</link>
      <description><![CDATA[我在网上搜索了二元和一元文本特征提取的方法，但还是没有找到有用的信息，有人能告诉我它们之间有什么区别吗？
例如，如果我有一段文本“我有一只可爱的狗”，如果我用二元方式进行特征提取和一元提取，会发生什么？]]></description>
      <guid>https://stackoverflow.com/questions/43463792/what-is-the-difference-between-bigram-and-unigram-text-features-extraction</guid>
      <pubDate>Tue, 18 Apr 2017 04:50:04 GMT</pubDate>
    </item>
    <item>
      <title>讲座视频和文字记录的数据集</title>
      <link>https://stackoverflow.com/questions/39943231/dataset-of-lecture-videos-together-with-transcript</link>
      <description><![CDATA[我在哪里可以找到包含讲座视频以及成绩单和笔记的数据集？我有一个机器学习项目需要这些，但我似乎找不到任何包含讲座视频以及成绩单的现有数据集。任何帮助都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/39943231/dataset-of-lecture-videos-together-with-transcript</guid>
      <pubDate>Sun, 09 Oct 2016 11:46:59 GMT</pubDate>
    </item>
    </channel>
</rss>