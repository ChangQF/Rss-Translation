<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 27 Dec 2023 18:16:41 GMT</lastBuildDate>
    <item>
      <title>变压器网络中的自注意力</title>
      <link>https://stackoverflow.com/questions/77723389/self-attention-in-a-transformer-network</link>
      <description><![CDATA[自我关注图
我对 Transformer Network 感到困惑。特别是注意力部分。一旦计算出输入中每个句子的注意力，该计算器之后的注意力值是否会添加到输入值中，还是网络仅根据注意力值进行预测？因为在安德鲁的视频中，他说正在计算注意力的输入单词之前的单词的权重可能大于正在计算注意力的单词的权重，因为它更重要，因为它为以下内容提供了更多上下文输入的单词。但我的问题是，当所有值在注意力计算结束时求和时，注意力是否会描述更多前一个单词，因为它的权重最大？或者本例中的 A^3 然后与 X^3 重新组合？]]></description>
      <guid>https://stackoverflow.com/questions/77723389/self-attention-in-a-transformer-network</guid>
      <pubDate>Wed, 27 Dec 2023 18:05:40 GMT</pubDate>
    </item>
    <item>
      <title>从拥抱的脸上加载耳语基础模型？</title>
      <link>https://stackoverflow.com/questions/77723275/loading-whisper-base-model-from-hugging-face</link>
      <description><![CDATA[我正在尝试加载耳语的基本模型，但我很难这样做。
貌似没有直接的方法可以直接从抱脸网站下载模型，而且使用变压器也不行。我知道我做错了什么，因为我知道我加载了模型两次，但我不能这样做。
目前，这是我尝试过的：
导入耳语
进口火炬
从变压器导入 AutoProcessor、AutoModelForSpeechSeq2Seq
print(&quot;正在下载模型...&quot;)
直接=“型号/”
model_1 = AutoModelForSpeechSeq2Seq.from_pretrained(&#39;openai/whisper-base&#39;,cache_dir=direct)
处理器= AutoProcessor.from_pretrained(&#39;openai/whisper-base&#39;,cache_dir=direct)

模型 = 耳语.load_model(model_1)
print(“模型已加载。正在转录测试音频...”)
结果 = model.transcribe(“audio_test.mp3”)
打印（结果[“文本”]）

我需要使用变压器吗？我还应该这样做吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77723275/loading-whisper-base-model-from-hugging-face</guid>
      <pubDate>Wed, 27 Dec 2023 17:33:49 GMT</pubDate>
    </item>
    <item>
      <title>Azure 机器学习工作室设计器 - 预测未来销售的算法</title>
      <link>https://stackoverflow.com/questions/77722671/azure-machine-learning-studio-designer-algorithm-to-predict-future-sales</link>
      <description><![CDATA[我正在 Azure 机器学习设计器中进行一项实验，使用线性回归算法来构建可以预测未来销售的原型模型。
我在管理前向预测时遇到问题，我找到的所有示例，例如 Microsoft 提供的“回归 - 汽车价格预测（基本）”示例，均适用于我的预测。 (https://github .com/Azure/MachineLearningDesigner/blob/master/articles/samples/regression-automobile-price-prediction-basic.md）用于处理已获得的给定数据集并预测一个缺失值。
我的数据集有 5 列（VoucherDate、Amount、BranchCode、Dolar oficial、Dolar blue）
数据集示例
管道执行
如何根据给定的当前数据来预测未来销售额？然后，我怎样才能看到计算出的所有行？因为在数据预览中我只能看到几行。
我开发了一个管道，可以预测数据集中的销售额（基于 MS 给出的示例），该管道由 SQL Azure 数据库中获得的销售额加上 2 个具有 UDS/ARS 汇率的变量组成报价。
管道执行已成功完成，评分数据集显示给定数据集金额的评分标签。但是，当我尝试生成一个新的数据集（包含我的信息和一些没有销售额的未来记录）时，管道会给出其他结果。]]></description>
      <guid>https://stackoverflow.com/questions/77722671/azure-machine-learning-studio-designer-algorithm-to-predict-future-sales</guid>
      <pubDate>Wed, 27 Dec 2023 15:17:30 GMT</pubDate>
    </item>
    <item>
      <title>分类特征的标签编码：在运行中保持标签一致性</title>
      <link>https://stackoverflow.com/questions/77720799/label-encoding-for-categorical-features-preserving-label-consistency-across-run</link>
      <description><![CDATA[问题描述：
标签编码问题：重新运行标签编码代码后，标签会发生变化，导致不一致。
来自服务器的动态数据：传入数据可能会引入新值，从而使预定义标签限制变得不切实际。
需要持久标签：现有标签应保持一致，而新值应获得新生成的标签，而不更改现有标签。
重复函数运行：代码需要处理多个函数运行。
程序运行之间的持久内存：程序可能会重新启动，并且内存应保留标签映射以避免从头开始重新运行。
现有代码：
from sklearn.preprocessing import LabelEncoder
进口泡菜

def label_encoding(df_logs):
    # 现有标签映射或空标签映射
    尝试：
        将 open(&#39;label_mapping.pkl&#39;, &#39;rb&#39;) 作为 f：
            label_mapping = pickle.load(f)
    除了文件未找到错误：
        标签映射 = {}

    # 标签编码列
    cols_to_encode = [
        &#39;攻击&#39;，&#39;类别&#39;，&#39;目标位置&#39;，&#39;Os&#39;，&#39;SignName&#39;，&#39;源位置&#39;，&#39;目标&#39;，
        &#39;用户名&#39;、&#39;VSys&#39;、&#39;插槽&#39;、&#39;操作&#39;、&#39;策略&#39;、&#39;配置文件&#39;、&#39;协议名称&#39;、
        &#39;应用程序&#39;，&#39;源区域&#39;，&#39;关闭原因&#39;，&#39;目标区域&#39;，&#39;模块名称&#39;，
        &#39;ModuleBrief&#39;、&#39;RecieveInterface&#39;、&#39;策略名称&#39;、&#39;IP 地址&#39;、&#39;源地址&#39;、&#39;目标地址&#39;
    ]

    # 转换列中的特定值
    df_logs[&#39;源地址&#39;] = df_logs[&#39;源地址&#39;].apply(lambda x: &#39;0&#39; if x.startswith(&#39;192.168&#39;) else x)
    df_logs[&#39;目标地址&#39;] = df_logs[&#39;目标地址&#39;].apply(lambda x: &#39;0&#39; if x.startswith(&#39;192.168&#39;) else x)

    # 对列应用LabelEncoder，保持标签一致
    对于 cols_to_encode 中的 col：
        label_encoder = label_mapping.get(col, LabelEncoder())
        df_logs[col] = label_encoder.fit_transform(df_logs[col])
        label_mapping[col] = label_encoder # 更新标签映射

    # 保存标签映射以供将来使用
    将 open(&#39;label_mapping.pkl&#39;, &#39;wb&#39;) 作为 f：
        pickle.dump(label_mapping, f)

    返回 df_logs

请求：
寻求一种解决方案，在多次运行中保持现有值的标签一致，同时允许新遇到的值接收新标签，而不会破坏现有映射。目标是即使在系统重新启动后也保留程序执行之间的这些映射。寻找建议或方法来实现标签编码的持久性和一致性。]]></description>
      <guid>https://stackoverflow.com/questions/77720799/label-encoding-for-categorical-features-preserving-label-consistency-across-run</guid>
      <pubDate>Wed, 27 Dec 2023 08:24:15 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：发现输入变量的样本数量不一致：[24, 6]</title>
      <link>https://stackoverflow.com/questions/77720269/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-24-6</link>
      <description><![CDATA[我在构建回归模型时遇到值错误。下面是我的代码。
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
数据集 = pd.read_csv(&#39;Salary_Data.csv&#39;)
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
从 sklearn.model_selection 导入 train_test_split
X_train,y_train,X_test,y_test=train_test_split(X,y,test_size=0.2,random_state=0)
#建立一个模型来理解工作年限和薪资之间的相互关系。
当您必须预测连续值时使用#regression，当您必须预测类别时使用#regression。
从 sklearn. Linear_model 导入 LinearRegression
回归器=线性回归()
#连接到训练集的函数称为拟合函数（线性回归类或预测测试集的未来结果的方法）
回归器.fit(X_train, y_train)

我尝试构建一个使用 fit 函数连接两个训练集的模型，但无法进一步进行。

数据集：
&lt;前&gt;&lt;代码&gt;|年经验|薪资|
|------------------:|---------:|
| 1.1| 39343 | 39343
| 1.3 | 1.3 46205 | 46205
| 1.5 | 1.5 37731 | 37731
| 2 | 43525 | 43525
| 2.2 | 2.2 39891 |
| 2.9 | 2.9 56642 |
| 3 | 60150|
| 3.2 | 54445 |
| 3.2 | 64445 | 64445
| 3.7 | 3.7 57189 | 57189
| 3.9 | 3.9 63218 |
| 4 | 55794 |
| 4 | 56957 | 56957
| 4.1 | 57081 |
| 4.5 | 4.5 61111 |
| 4.9 | 4.9 67938 |
| 5.1 | 66029 | 66029
| 5.3 | 83088 |
| 5.9 | 5.9 81363 |
| 6 | 93940 | 93940
| 6.8 | 91738 | 91738
| 7.1 | 98273 |
| 7.9 | 7.9 101302 |
| 8.2 | 8.2 113812 |
| 8.7 | 8.7 109431 | 109431
| 9 | 105582 |
| 9.5 | 9.5 116969 | 116969
| 9.6 | 112635 | 112635
| 10.3 | 10.3 122391 |
| 10.5 | 10.5 121872 |
]]></description>
      <guid>https://stackoverflow.com/questions/77720269/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-24-6</guid>
      <pubDate>Wed, 27 Dec 2023 05:53:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么 nn.Dropout 改变张量的元素值？ [复制]</title>
      <link>https://stackoverflow.com/questions/77719979/why-nn-dropout-change-the-elements-values-of-a-tensor</link>
      <description><![CDATA[我在使用 dropout 层时遇到问题。
根据我的理解， nn.Dropout 的输入可以是一个张量，并且 nn.dropout 以给定的概率随机地使某些元素为零。但是，请参阅我的代码：
dropout = nn.Dropout(0.1)
y = torch.tensor([5.0,7.0,9.0])
y = 辍学（y）
打印（y）

输出是
张量([ 5.5556, 7.7778, 10.0000])
我尝试了很多次，有时有一个零元素。但是其他元素每次都会更改为另一个固定值（5.0 -&gt; 5.5556、7.0 -&gt; 7.7778、9.0 -&gt; 10.000）
为什么会发生这种情况？]]></description>
      <guid>https://stackoverflow.com/questions/77719979/why-nn-dropout-change-the-elements-values-of-a-tensor</guid>
      <pubDate>Wed, 27 Dec 2023 03:59:10 GMT</pubDate>
    </item>
    <item>
      <title>在“__init__.py | 中找不到引用“keras” __init__.py' [关闭]</title>
      <link>https://stackoverflow.com/questions/77719828/cannot-find-reference-keras-in-init-py-init-py</link>
      <description><![CDATA[训练 模型
错误是：
&lt;块引用&gt;
在“init.py”中找不到引用“keras”| init.py&#39;


Python 3.11.5
Mac OS M2
tensorflow-macos 2.15
Keras 2.15
Conda 环境

张量流也有同样的问题，但现在我不知道如何解决它。
我的代码有 9 个问题，但它可以工作。不知道什么意思？？？]]></description>
      <guid>https://stackoverflow.com/questions/77719828/cannot-find-reference-keras-in-init-py-init-py</guid>
      <pubDate>Wed, 27 Dec 2023 02:42:30 GMT</pubDate>
    </item>
    <item>
      <title>朱莉娅维度不匹配[关闭]</title>
      <link>https://stackoverflow.com/questions/77719712/julia-dimension-mismatch</link>
      <description><![CDATA[我无法理解如何在 julia 的 nn 模型中实现转换层。每次我尝试实现它时都会收到此错误
DimensionMismatch：x 和 w 的等级必须匹配！ （2 对 3）

下面是我试图实现 Conv 层的 julia 模型，它应该位于倒数第二个 Dense 层之前，但每次我把它放在那里时，它都会抛出上述错误。
&lt;前&gt;&lt;代码&gt;链(
  变压器分类器（
    嵌入((32, 6654)), # 212_928个参数
    位置编码(32),
    辍学率（0.3），
    大批（
      TransformerEncoderBlock(
        多头注意力（
          密集(32 =&gt; 32), # 1_056 个参数
          密集(32 =&gt; 32), # 1_056 个参数
          密集(32 =&gt; 32), # 1_056 个参数
          密集(32 =&gt; 32), # 1_056 个参数
        ),
        LayerNorm(32), # 64个参数
        Dense(32 =&gt; 128, relu), # 4_224个参数
        Dense(128 =&gt; 32), # 4_128个参数
        LayerNorm(32), # 64个参数
        辍学率（0.3），
      ),
    ),
    Dense(32 =&gt; 16), # 528 个参数
    压平图层(),
    密集(800 =&gt; 32), # 25_632个参数
  ),
  密集(32 =&gt; 50), # 1_650个参数
  Dense(50 =&gt; 5), # 255 个参数
) # 总计：25 个可训练数组，253_697 个参数，

我尝试了很多不同的值和方法，但它仍然不起作用，有人可以解释一下如何实现这个转换层。输入是一个 32x50 矩阵，批量大小为 32，因此是 32x50x32 矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/77719712/julia-dimension-mismatch</guid>
      <pubDate>Wed, 27 Dec 2023 01:36:36 GMT</pubDate>
    </item>
    <item>
      <title>它真正试图调用什么属性以及如何定义它[重复]</title>
      <link>https://stackoverflow.com/questions/77719606/what-attribute-is-it-really-trying-to-call-and-how-to-define-it</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77719606/what-attribute-is-it-really-trying-to-call-and-how-to-define-it</guid>
      <pubDate>Wed, 27 Dec 2023 00:40:08 GMT</pubDate>
    </item>
    <item>
      <title>Python 中 MLE（非线性模型）的多变量梯度下降</title>
      <link>https://stackoverflow.com/questions/77719569/multivariable-gradient-descent-for-mles-nonlinear-model-in-python</link>
      <description><![CDATA[我正在尝试执行梯度下降来计算三个 MLE（从头开始）。我有数据 $x_i=s_i+w_i$ 其中 $s_i=A(nu_i/nu_0)^{alpha}(nu_i/nu_0+1)^{-4alpha}$ 我已分析计算一阶导数：
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

#模型函数s_i
def 信号(A,nu_0,alpha,nu):
    返回 A*(nu/nu_0)**alpha*(1+nu/nu_0)**(-4*alpha)

#对数似然函数的偏导数
def MLE_A(A,nu_0,alpha,nu,x_i):
    nu=np.array(nu)
    x_i=np.array(x_i)
    返回-np.sum(((nu/nu_0)**alpha*((A*(nu/nu_0)**alpha)/(nu/nu_0+1)**(4*alpha)-x_i))/( nu/nu_0+1)**(4*alpha))

def MLE_alpha(A,nu_0,alpha,nu,x_i):
    nu=np.array(nu)
    x_i=np.array(x_i)
    
    返回-np.sum((A*(nu/nu_0)**alpha*(4*np.log(nu/nu_0+1)-np.log(nu/nu_0))*(x_i*(nu/nu_0+ 1)**(4*alpha)-A*(nu/nu_0)**alpha))/(nu/nu_0+1)**(8*alpha))

def MLE_nu_0(A,nu_0,alpha,nu,x_i):
    nu=np.array(nu)
    x_i=np.array(x_i)
    
    返回-np.sum((A*alpha*(nu/nu_0)**(alpha)*(nu_0-3*nu)*((x_i*((nu)/nu_0+1)**(4*alpha) )-A*(nu/nu_0)**alpha))/(nu_0*(nu+nu_0)*((nu)/nu_0+1)**(8*alpha)))

 
defgradient_descent(A_init,nu_0_init,alpha_init,nu,x_i,迭代=1000,learning_rate=0.01):
    
    A=A_init
    nu_0=nu_0_init
    阿尔法=阿尔法_init
    theta=np.array([A_init,nu_0_init,alpha_init])
    update_theta=[θ]
    对于范围内的 i（迭代）：
        new_theta = theta - 学习率 * np.array([MLE_A(A,nu_0,alpha,nu,x_i), MLE_nu_0(A,nu_0,alpha,nu,x_i), MLE_alpha(A,nu_0,alpha,nu,x_i)] ）
        西塔=新_西塔
        Updated_theta.append（theta）
        A,nu_0,alpha = new_theta[0],new_theta[1],new_theta[2]
    返回（更新的_theta）

A=6
nu_0=2
阿尔法=1
nu=np.linspace(0.05,1.0,200)
x_i=信号(A,nu_0,alpha,nu)+np.random.normal(0,0.05,len(nu))


参数=梯度下降（A，nu_0，alpha，nu，x_i，迭代= 10000，learning_rate = 0.01）

打印（参数[-1]）
A_fit=参数[-1][0]
nu_0_fit=参数[-1][1]
alpha_fit=参数[-1][2]

plt.plot(nu,x_i)
plt.plot(nu,信号(A_fit,nu_0_fit,alpha_fit,nu))

plt.show()



有时我会收到诸如 RuntimeWarning：在 power 中遇到溢出和 RuntimeWarning：在 true_divide 中遇到无效值之类的错误，有时我会得到严重偏离值的错误。我对学习率使用了不同的值，但它没有解决这个问题。我已经手动并使用符号软件检查了这些功能。另外，我使用 Latexify 来查看我确实正确输入了它们，因此我假设这是我对梯度下降的实现以某种方式关闭。]]></description>
      <guid>https://stackoverflow.com/questions/77719569/multivariable-gradient-descent-for-mles-nonlinear-model-in-python</guid>
      <pubDate>Wed, 27 Dec 2023 00:24:26 GMT</pubDate>
    </item>
    <item>
      <title>在验证步骤中计算 F1-Score</title>
      <link>https://stackoverflow.com/questions/76919033/compute-f1-score-inside-validation-step</link>
      <description><![CDATA[我正在微调 mT5 模型以进行 QA。
我正在使用 PyTorch Lightning，目前，我的验证步骤如下所示：
 defvalidation_step(self,batch,batch_idx):
    input_ids = 批处理[&#39;input_ids&#39;]
    注意掩码 = 批处理[&#39;注意掩码&#39;]
    标签=批次[&#39;标签&#39;]
    损失，输出= self（input_ids，attention_mask，标签）
    self.log(&#39;val_loss&#39;, loss, prog_bar=True, logger=True)
    回波损耗

我不想记录 val_loss 并据此选择最佳检查点，而是计算 F1 分数，并根据最佳整体 F1 选择最佳检查点。
训练循环完成后我成功计算了预测：
预测 = []
地面真相 = []
对于 tqdm(data_module.test_dataloader(), desc=“评估”) 中的批次：
    input_ids = 批处理[&#39;input_ids&#39;].to(DEVICE)
    注意掩码 = 批处理[&#39;注意掩码&#39;].to(DEVICE)
    标签 = 批量[&#39;标签&#39;].to(DEVICE)
    使用 torch.no_grad()：
        generated_ids = Training_model.model.generate(
            输入ID=输入ID，
            注意掩码=注意掩码，
        ）

    Predicted_answers = tokenizer.batch_decode( generated_ids,skip_special_tokens=True)
    预测.扩展（预测的_答案）

    掩码=标签！= -100
    标签 = torch.masked_select(标签, 掩码)
    true_text = tokenizer.decode（标签，skip_special_tokens=True，clean_up_tokenization_spaces=True）
    ground_truths.append(true_text)

如何在验证步骤中计算预测/ground_truth，以便计算那里的 F1-Score？]]></description>
      <guid>https://stackoverflow.com/questions/76919033/compute-f1-score-inside-validation-step</guid>
      <pubDate>Thu, 17 Aug 2023 06:41:15 GMT</pubDate>
    </item>
    <item>
      <title>糖尿病视网膜病变检测 CNN 总是猜测同一类</title>
      <link>https://stackoverflow.com/questions/65751654/diabetic-retinopathy-detection-cnn-always-guesses-same-class</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/65751654/diabetic-retinopathy-detection-cnn-always-guesses-same-class</guid>
      <pubDate>Sat, 16 Jan 2021 16:06:50 GMT</pubDate>
    </item>
    <item>
      <title>如何为 test_train_split 选择数据框中的数据列和目标列？</title>
      <link>https://stackoverflow.com/questions/58697757/how-to-choose-data-columns-and-target-columns-in-a-dataframe-for-test-train-spli</link>
      <description><![CDATA[我正在尝试使用从 csv 读取到 pandas 数据帧的数据来设置 test_train_split 。我正在读的书说我应该分为 x_train 作为数据和 y_train 作为目标，但是如何定义哪一列是目标以及哪一列是数据？到目前为止我有以下内容
导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
数据 = pd.read_csv(&quot;数据.csv&quot;)

我已经阅读了按以下方式进行分割，但是以下使用的是已经定义了data和target的一堆：
X_train, X_test, y_train, y_test = train_test_split(businessleisure_data[&#39;data&#39;],
                                                    iris_dataset[&#39;目标&#39;]，random_state=0)
]]></description>
      <guid>https://stackoverflow.com/questions/58697757/how-to-choose-data-columns-and-target-columns-in-a-dataframe-for-test-train-spli</guid>
      <pubDate>Mon, 04 Nov 2019 16:46:37 GMT</pubDate>
    </item>
    <item>
      <title>如何合并数值模型和嵌入序列模型来处理 RNN 中的类别</title>
      <link>https://stackoverflow.com/questions/52627739/how-to-merge-numerical-and-embedding-sequential-models-to-treat-categories-in-rn</link>
      <description><![CDATA[我想为我的分类特征构建一个带有嵌入的单层 LSTM 模型。我目前有数字特征和一些分类特征，例如位置，它不能进行单热编码，例如由于计算复杂性，使用 pd.get_dummies() ，这正是我最初打算做的。 
让我们想象一个例子：
示例数据

&lt;前&gt;&lt;代码&gt;数据 = {
    &#39;用户id&#39;: [1,1,1,1,2,2,3],
    &#39;页面时间&#39;: [10,20,30,20,15,10,40],
    &#39;地点&#39;: [&#39;伦敦&#39;,&#39;纽约&#39;,&#39;伦敦&#39;,&#39;纽约&#39;,&#39;香港&#39;,&#39;东京&#39;,&#39;马德里&#39;],
    &#39;page_id&#39;: [5,4,2,1,6,8,2]
}
d = pd.DataFrame(数据=数据)
打印（d）
   user_id time_on_page 位置 page_id
0 1 10 伦敦 5
1 1 20 纽约 4
2 1 30 伦敦 2
3 1 20 纽约 1
4 2 15 香港 6
5 2 10 东京 8
6 3 40 马德里 2

让我们看看访问网站的人。我正在跟踪数字数据，例如页面停留时间等。分类数据包括：位置（超过 1000 个唯一值）、Page_id（&gt; 1000 个唯一值）、Author_id（超过 100 个唯一值）。最简单的解决方案是对所有内容进行 one-hot 编码，并将其放入具有可变序列长度的 LSTM 中，每个时间步对应于不同的页面视图。
上面的DataFrame将生成7个训练样本，序列长度可变。例如，对于 user_id=2 我将有 2 个训练样本：

&lt;前&gt;&lt;代码&gt;[ ROW_INDEX_4 ] 和 [ ROW_INDEX_4, ROW_INDEX_5 ]

让X作为训练数据，让我们看一下第一个训练样本X[0]。

从上图中，我的分类特征是 X[0][:, n:]。
在创建序列之前，我使用 pd.factorize() 将分类变量分解为 [0,1... number_of_cats-1]，因此 中的数据code&gt;X[0][:, n:] 是与其索引相对应的数字。 
我需要为每个分类特征单独创建一个嵌入吗？例如。每个 x_*n, x_*n+1, ..., x_*m 的嵌入？
如果是这样，我如何将其放入 Keras 代码中？

&lt;前&gt;&lt;代码&gt;模型 = 顺序()

model.add(Embedding(?, ?, input_length=variable)) # 如何将数据输入到此嵌入中？仅分类输入。

模型.add(LSTM())
model.add(密集())
model.add.Activation(&#39;sigmoid&#39;)
model.compile()

model.fit_generator() # 一个接一个地拟合“X[i]”可变长度序列。

我的解决方案想法：
看起来像这样的东西：

我可以在每个分类特征 (m-n) 上训练 Word2Vec 模型，以对任何给定值进行矢量化。例如。伦敦将在 3 个维度上进行矢量化。假设我使用 3 维嵌入。然后我将所有内容放回到 X 矩阵中，该矩阵现在将有 n + 3(n-m)，并使用 LSTM 模型来训练它？ 
我只是认为应该有一种更简单/更聪明的方法。]]></description>
      <guid>https://stackoverflow.com/questions/52627739/how-to-merge-numerical-and-embedding-sequential-models-to-treat-categories-in-rn</guid>
      <pubDate>Wed, 03 Oct 2018 13:07:04 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：发现输入变量的样本数量不一致：[2750, 1095]</title>
      <link>https://stackoverflow.com/questions/51031746/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-2750-1</link>
      <description><![CDATA[这个错误是什么？我该如何修复它？我无法更改我的数据。
 X = train[[&#39;id&#39;, &#39;listing_type&#39;, &#39;楼层&#39;, &#39;纬度&#39;, &#39;经度&#39;,
             &#39;床&#39;、&#39;浴室&#39;、&#39;total_rooms&#39;、&#39;square_feet&#39;、&#39;group&#39;、&#39;grades&#39;]]
    Y = 测试[&#39;价格&#39;]
    n = pd.get_dummies(train.group)

训练数据如下所示：
id Listing_type 楼层 纬度 经度 床位 浴室 总数 房间 平方英尺 等级 high_price_high_freq high_price_low_freq low_price
265183 10 4 40.756224 -73.962506 1 1 3 790 2 1 0 0 0
270356 10 7 40.778010 -73.962547 5 5 9 4825 2 1 0 0
176718 10 25 40.764955 -73.963483 2 2 4 1645 2 1 0 0
234589 10 5 40.741448 -73.994216 3 3 5 2989 2 1 0 0
270372 10 5 40.837000 -73.947787 1 1 3 1045 2 0 0 1

错误代码是：
from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)
从 sklearn. Linear_model 导入 LinearRegression
回归器=线性回归()
回归器.fit(X_train, y_train)

错误信息：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-479-ca78b7b5f096&gt;在&lt;模块&gt;()中
      1 从 sklearn.cross_validation 导入 train_test_split
----&gt; 2 X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)
      3 从sklearn.linear_model导入LinearRegression
      4 回归器 = LinearRegression()
      5 regressor.fit(X_train, y_train)

train_test_split 中的 ~\Anaconda3\lib\site-packages\sklearn\cross_validation.py(*arrays, **options)
   第2057章
   第2058章 测试大小=0.25
-&gt;第2059章
   第2060章
   第2061章

~\Anaconda3\lib\site-packages\sklearn\utils\validation.py 可索引(*iterables)
    227 其他：
    228 结果.append(np.array(X))
--&gt;第229章
    230 返回结果
    第231章

〜\Anaconda3\lib\site-packages\sklearn\utils\validation.py 在 check_confirm_length(*arrays)
    202 if len(唯一) &gt; 1：
    203 raise ValueError(“发现输入变量的数量不一致”
--&gt; 204》样本：%r” % [int(l) 表示 l 的长度])
    205
    206

ValueError：发现输入变量的样本数量不一致：[2750, 1095]
]]></description>
      <guid>https://stackoverflow.com/questions/51031746/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-2750-1</guid>
      <pubDate>Mon, 25 Jun 2018 21:03:11 GMT</pubDate>
    </item>
    </channel>
</rss>