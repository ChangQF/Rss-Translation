<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Jan 2024 18:17:38 GMT</lastBuildDate>
    <item>
      <title>Cora 数据集中的节点特征</title>
      <link>https://stackoverflow.com/questions/77760163/node-features-in-the-cora-dataset</link>
      <description><![CDATA[我正在使用具有节点特征的 Cora 数据集。在这个数据集中，每个节点特征都是一个长度为1433的向量，表示字典中第i个单词是否出现在文档中的0-1热编码。
我已经打印出了几个节点（文档）有多少个 1（即出现了多少个不同的单词），而且数量相对较小，大约 18-20 个。

这是否意味着每个文档在字典中只有大约 20 个单词？我想知道节点特征是如何构造的以及这看起来是否正确。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77760163/node-features-in-the-cora-dataset</guid>
      <pubDate>Thu, 04 Jan 2024 17:31:58 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试训练 2D nn 和 1D nn 时出现错误。 Epoch 1/10，UnimplementedError：图形执行错误</title>
      <link>https://stackoverflow.com/questions/77760031/im-getting-an-error-when-i-try-to-train-my-2d-conv-nn-and-1d-conv-nn-epoch-1-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77760031/im-getting-an-error-when-i-try-to-train-my-2d-conv-nn-and-1d-conv-nn-epoch-1-1</guid>
      <pubDate>Thu, 04 Jan 2024 17:09:04 GMT</pubDate>
    </item>
    <item>
      <title>不完全理解梯度是如何计算的。我的计算（手工）和约定的梯度公式是不同的</title>
      <link>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</link>
      <description><![CDATA[我正在尝试实现一个多层感知器，而不使用任何外部库来获得反向传播的直觉。我现在可以自信地说我理解了这个算法。但问题是：我试图手动推导出所有梯度计算方程，但它们并不成立。他们错了。
为了获得更多上下文，我使用交叉熵损失。
例如：
loss = -np.sum(true_labels * np.log(outputs)) / m

然后我们计算这个损失相对于输出的梯度，如下所示：
&lt;前&gt;&lt;代码&gt;dz2 = (1/m) * (-标签/Z2)

但是我在任何地方看到这个特定的梯度都是由以下给出的：
dz2 = Z2 - 标签

我不会进入下一个渐变，因为我认为一旦我明白我在这里做错了什么，这将是解锁其余部分的关键。
更多背景信息：正在 MNIST 数据集、10 个类、1 个隐藏层上进行训练。]]></description>
      <guid>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</guid>
      <pubDate>Thu, 04 Jan 2024 14:36:45 GMT</pubDate>
    </item>
    <item>
      <title>将大型语料库中的 n 元模型加载到集合中时如何避免内存问题</title>
      <link>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</link>
      <description><![CDATA[我一直在尝试实现一种无监督学习算法，该算法根据从语料库中提取的特定特征来匹配相似性。一个用例是作者识别。该算法的工作方式是从训练语料库中提取不同类型的 n-gram，然后每个作者都会获得一个“指纹”。基于文章中出现的 n 元语法。
为此，我首先需要收集训练语料库中存在的所有 n 元语法。这就是我遇到内存问题的地方，我一直在使用 Yelp 评论数据，并且在某些时候我的程序由于内存限制而崩溃。我尝试过存储中间结果，然后将 n-gram 加载到最终集合中，以避免我的稀疏计算中出现任何潜在的内存泄漏问题，但这也失败了，看来该集合太大了。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</guid>
      <pubDate>Thu, 04 Jan 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>出现错误不知道如何解决请解决？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77757272/error-occurred-i-dont-know-how-to-solve-please-solve</link>
      <description><![CDATA[src.exception.CustomException：python 脚本名称 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py] 行号 [18] 错误消息中发生错误 [ python 脚本名称 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py] 行号 [52] 错误消息中发生错误 [pickle 中的节点数组具有不兼容的 dtype：
- 预期：{&#39;names&#39;：[&#39;left_child&#39;，&#39;right_child&#39;，&#39;feature&#39;，&#39;threshold&#39;，&#39;impurity&#39;，&#39;n_node_samples&#39;，&#39;weighted_n_node_samples&#39;，&#39;missing_go_to_left&#39;]，&#39;formats&#39;：[&#39;&lt; i8&#39;、&#39;

回溯（最近一次调用最后一次）
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py”，第 52 行，位于 load_object
返回pickle.load(file_obj)
       ^^^^^^^^^^^^^^^^^^^^^^^
文件“sklearn\tree\_tree.pyx”，第 728 行，位于 sklearn.tree._tree.Tree.__setstate__
文件“sklearn\tree\_tree.pyx”，第 1434 行，位于 sklearn.tree._tree._check_node_ndarray
在处理上述异常的过程中，又出现了一个异常：
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py”，第 18 行，在预测中
模型=加载对象（模型路径）
      ^^^^^^^^^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py”，第 55 行，位于 load_object
引发 CustomException(e,sys)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
在处理上述异常的过程中，又出现了一个异常：
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1478 行，在 __call__ 中
返回 self.wsgi_app（环境，start_response）
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1458 行，在 wsgi_app 中
响应 = self.handle_exception(e)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1455 行，在 wsgi_app 中
响应 = self.full_dispatch_request()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 869 行，在 full_dispatch_request 中
rv = self.handle_user_exception(e)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 867 行，在 full_dispatch_request 中
rv = self.dispatch_request()
     ^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 852 行，dispatch_request
返回 self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\application.py”，第 33 行，位于 Predict_datapoint
pred=predict_pipeline.predict(final_new_data)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py”，第 28 行，在预测中
引发 CustomException(e,sys)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src.exception.CustomException：python 脚本名称中发生错误 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py] 行号 [18] 错误消息 [python 脚本名称中发生错误[c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py] 行号 [52] 错误消息 [pickle 中的节点数组具有不兼容的 dtype：
- 预期：{&#39;names&#39;：[&#39;left_child&#39;，&#39;right_child&#39;，&#39;feature&#39;，&#39;threshold&#39;，&#39;impurity&#39;，&#39;n_node_samples&#39;，&#39;weighted_n_node_samples&#39;，&#39;missing_go_to_left&#39;]，&#39;formats&#39;：[&#39;&lt; i8&#39;、&#39;]]></description>
      <guid>https://stackoverflow.com/questions/77757272/error-occurred-i-dont-know-how-to-solve-please-solve</guid>
      <pubDate>Thu, 04 Jan 2024 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>Bigquery ML，用于表中分区的多个线性回归模型</title>
      <link>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</link>
      <description><![CDATA[任务
我想使用 bigquery ml 对表中的分区执行多元线性回归，最好使用 dbt 实现。
背景
该表包含 customer_key、c​​ategory、week_key 和花费。应为每个分区计算回归线：customer_key 和类别，按周升序排序。这样，每个类别的每个客户都可以获得该分区内几周内支出趋势的斜率系数。实际上，我需要每个分区一个回归模型，而不是整个表一个回归模型。回归模型的数量估计约为 1 亿个。因此，我想使用 bigquery 来实现工作负载的并行化。

最终结果应该是一个表，其中包含：所有客户的 customer_key、类别、斜率。

此外，我使用 dbt 来运行所有模型，并使用 bigquery 作为数据的计算和存储。因此，我想使用dbt来实现该解决方案。
研究
通过与各个 llms 的聊天，他们似乎建议结合使用程序语句和跨每个分区的 for 循环来执行回归。但是，我想并行化计算。从这个问题 bigquery ML: Running a regression per group and全部组合起来，似乎“BQML 目前不支持在单个 CREATE MODEL 语句中指定不同的组 id 进行回归。”。
创建临时表partitioned_data AS
选择 customer_key、类别、week_key、支出
来自你的表
按客户键分组，类别；

DECLARE partition_list ARRAY&gt;；
开始
-- 迭代暂存表中的每个分区
FOR 分区 IN (
  选择客户键，类别
  FROM 分区数据
  按客户键分组，类别
 ）
 环形
   -- 提取当前分区的数据
 DECLARE partition_data ARRAY&gt;；
 开始
  FOR week_data IN (
    选择 week_key，花费
    FROM 分区数据
    WHERE customer_key = 分区.customer_key
    AND 类别 = 分区.类别
  ）
  环形
    array_append(partition_data, week_data);
  结束循环；
结尾

-- 为当前分区创建模型
创建或替换模型 my_model
选项（
  model_type = &#39;线性回归&#39;,
  标签=&#39;花费&#39;，
  特征 = &#39;week_key&#39;
）
作为
选择 *
FROM UNNEST(partition_data);
结束循环；
结尾;

创建临时表 Final_results AS
选择
  s.customer_key，
  s.类别，
  米坡度
FROM 分区数据 p
加入 （
  选择
    *,
    斜率 = MEAN(statistics.mean_slope)
   来自 ML.MODEL_STATS(model.my_model)
   按客户键、商店键、类别分组
  ）米
 ON p.customer_key = m.customer_key
 AND p.category = m.category;

但是，这个建议的解决方案无法在 bigquery gui 中运行，也不能在 dbt 中运行。
问题
有人知道如何完成这个回归任务吗？要么在 bigquery 上将上面的 sql 代码作为单独的脚本运行，要么重写它以在 dbt 中工作。]]></description>
      <guid>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</guid>
      <pubDate>Thu, 04 Jan 2024 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>多元数据排序算法设计[关闭]</title>
      <link>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</link>
      <description><![CDATA[目前我已经收集了很多学校的相关数据。每个学校都有教师人数、学生人数、硬件设施等十个评价指标，每个指标的权重我不知道。现在我们想用机器学习算法来自动对高校综合实力进行排名，而不需要参考任何知名的国际排名，比如QS。]]></description>
      <guid>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</guid>
      <pubDate>Thu, 04 Jan 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 StandardScaler 时 CustomScaler 中出现类型错误</title>
      <link>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</link>
      <description><![CDATA[我在使用 scikit-learn 的 Python 中遇到自定义缩放器类的问题。我有一个继承自 BaseEstimator 和 TransformerMixin 的 CustomScaler 类，它使用 StandardScaler。但是，我在初始化过程中遇到了类型错误。相关代码如下：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.preprocessing 导入 StandardScaler

类 CustomScaler(BaseEstimator,TransformerMixin):
    
    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
        self.scaler = StandardScaler(复制,with_mean,with_std)
        self.columns = 列
        self.mean_ = 无
        self.var_ = 无

    def fit(self, X, y=None):
        self.scaler.fit(X[self.columns], y)
        self.mean_ = np.mean(X[self.columns])
        self.var_ = np.var(X[self.columns])
        返回自我

    def 变换（自身，X，y=无，复制=无）：
        init_col_order = X.列
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        返回 pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]


unscaled_input.columns.values
columns_to_scale = [&#39;月份值&#39;,
       “星期几”、“交通费用”、“上班距离”、
       ‘年龄’、‘每日平均工作负荷’、‘体重指数’、‘儿童’、‘宠物’]

absenteeism_scaler = CustomScaler(columns= columns_to_scale) // 这一步出错
缺席主义_scaler.fit（unscaled_input）

我检查了 StandardScaler 类的 scikit-learn 文档以确保正确使用，但我找不到此错误的任何解决方案。
什么可能导致此问题？有其他方法可以解决这个问题吗？
错误消息：
TypeError Traceback（最近一次调用最后一次）
单元格 In[24]，第 1 行
----&gt; 1 缺勤缩放器 = CustomScaler(columns_to_scale)

Cell In[20]，第 7 行，在 CustomScaler.__init__(self, columns, copy, with_mean, with_std)
      6 def __init__(self, columns, copy=True, with_mean=True, with_std=True):
----&gt; 7 self.scaler = StandardScaler(copy, with_mean, with_std)
      8 self.columns = 列
      9 self.mean_ = 无

TypeError: __init__() 采用 1 个位置参数，但给出了 4 个
]]></description>
      <guid>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</guid>
      <pubDate>Wed, 03 Jan 2024 10:34:48 GMT</pubDate>
    </item>
    <item>
      <title>如何将 model.safetensor 转换为 pytorch_model.bin？</title>
      <link>https://stackoverflow.com/questions/77708996/how-to-convert-model-safetensor-to-pytorch-model-bin</link>
      <description><![CDATA[我正在微调预训练的 bert 模型，但遇到了一个奇怪的问题：
当我使用 CPU 进行微调时，代码会像这样保存模型：

使用“pytorch_model.bin”。但是当我使用 CUDA（我必须这样做）时，模型会像这样保存：

当我尝试加载这个“model.safetensors”时将来，它会引发错误“pytorch_model.bin”未找到。我使用两个不同的 venv 来测试 CPU 和 CUDA。
如何解决这个问题？是版本问题吗？
我正在使用sentence_transformers框架来微调模型。
这是我的训练代码：
检查点 = &#39;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#39;

word_embedding_model = models.Transformer(checkpoint,cache_dir=f&#39;model/{checkpoint}&#39;)
pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=&#39;mean&#39;)
模型 = SentenceTransformer(模块=[word_embedding_model, pooling_model], device=&#39;cuda&#39;)


train_loss = 损失.CosineSimilarityLoss(模型)

evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name=&#39;sbert&#39;)

model.fit(train_objectives=[(train_dataloader, train_loss)]，epochs=5，evaluator=evaluator，show_progress_bar=True，output_path=f&#39;model_FT/{checkpoint}&#39;，save_best_model=True)

我确实在两个不同的环境中尝试了测试，我希望代码能够保存一个“pytorch_model.bin”文件。不是“model.safetensors”。
编辑：我真的还不知道，但似乎是新版本的 Transformer 库导致了这个问题。我看到使用拥抱脸可以加载安全张量，但使用句子转换器（我需要使用）则不能。]]></description>
      <guid>https://stackoverflow.com/questions/77708996/how-to-convert-model-safetensor-to-pytorch-model-bin</guid>
      <pubDate>Sat, 23 Dec 2023 20:43:20 GMT</pubDate>
    </item>
    <item>
      <title>以 PMML 格式转储的 LightGBM 模型给出了与原始模型不同的预测</title>
      <link>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</link>
      <description><![CDATA[我训练了一个 lightGBM 模型，它给出了倾向问题的概率。
然后将此模型转换为 PMML 格式，如下所示：
从 sklearn2pmml 导入 sklearn2pmml
sklearn2pmml(trained_model, &#39;prod_trained_model.pmml&#39;)

然后我像这样读取 PMML 模型：
从 pypmml_spark 导入 ScoreModel
model_pipeline = ScoreModel.fromFile(&#39;prod_trained_model.pmml&#39;)

然后我做出这样的预测：
predictions_df = model_pipeline.transform(features_df)

现在的问题是模型预测与原始模型的预测不匹配。预测概率有 5% 到 10% 的变化。
此外，对于输入数据帧中大约 5% 的行，PMML 模型的输出概率为 NaN。而对于完全相同的行，原始模型预测得很好。]]></description>
      <guid>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</guid>
      <pubDate>Fri, 15 Dec 2023 07:56:51 GMT</pubDate>
    </item>
    <item>
      <title>Llama2 回归语言模型 (huggingface)</title>
      <link>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</link>
      <description><![CDATA[我尝试利用给定整个输入序列的模型的最后一个隐藏状态，调整 Llama2 来解决回归任务。
如果随后问问题“2+2 的答案是什么”，则应回答4（虚拟问题，用于解释问题）。&lt; /p&gt;
为此，我将在 pytorch 模型中使用它
导入火炬
将 torch.nn 导入为 nn
从 Transformer 导入 LlamaModel、LlamaTokenizer

类 TransformerModel(nn.Module):
    def __init__(self, 模型名称:str, 附加层大小:int = 1):
        super(TransformerModel, self).__init__()
        self.transformer = LlamaModel.from_pretrained(model_name, torch_dtype=torch.float32, cache_dir=“hugginface_cache/models”)
        self.tokenizer = LlamaTokenizer.from_pretrained(model_name,cache_dir=“hugginface_cache/tokenizer”)

        # 添加一个带有一个输出的附加层
        self.additional_layer = nn.Linear(self.transformer.config.hidden_​​size,additional_layer_size)
        
    defforward(self, input_text):
        # 对输入文本进行标记
        input_ids = self.tokenizer(input_text, return_tensors=“pt”).input_ids.to(“cuda”)
        打印（“输入ID：”，输入ID）

        # 获取变压器的输出
        输出 = self.transformer(input_ids)
        
        # 使用整个最后的隐藏状态作为附加层的输入
        最后隐藏状态 = 输出.最后隐藏状态
        打印（&#39;last_hidden_​​state_shape：&#39;，last_hidden_​​state.size（））

        # 应用附加层
        附加输出= self.附加层（最后隐藏状态）

        返回额外的输出


model_url = “meta-llama/Llama-2-7b-hf”

模型 = TransformerModel(model_url)

但是，对于给定的输入模型（“Hello world！”），输出是大小为 1,4,1 的张量。
我可以验证标记生成器是否将字符串拆分为 4 个标记，我预计这会导致问题。但是，我不确定如何解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</guid>
      <pubDate>Wed, 13 Dec 2023 14:22:48 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>Rapids 无法导入 cudf：驱动程序初始化时出错：调用 cuInit 会导致 CUDA_ERROR_NO_DEVICE (100)</title>
      <link>https://stackoverflow.com/questions/77380210/rapids-cannot-import-cudf-error-at-driver-init-call-to-cuinit-results-in-cuda</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77380210/rapids-cannot-import-cudf-error-at-driver-init-call-to-cuinit-results-in-cuda</guid>
      <pubDate>Sat, 28 Oct 2023 16:02:14 GMT</pubDate>
    </item>
    <item>
      <title>MLFLOW 工件存储在 ftp 服务器上但未显示在 ui 中</title>
      <link>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</link>
      <description><![CDATA[我在远程跟踪服务器上训练期间使用 MLFLOW 存储一些参数和指标。现在我还尝试添加一个 .png 文件作为工件，但由于 MLFLOW 服务器远程运行，我将该文件存储在 ftp 服务器上。我通过以下方式提供了 ftp 服务器地址和 MLFLOW 路径：
mlflow 服务器 --backend-store-uri sqlite:///mlflow.sqlite --default-artifact-root ftp://user:password@1.2.3.4/artifacts/ --host 0.0.0.0 &amp;

现在我训练一个网络并通过运行来存储工件：
mlflow.set_tracking_uri(remote_server_uri)
mlflow.set_experiment(“默认”)
mlflow.pytorch.autolog()

使用 mlflow.start_run()：
    mlflow.log_params(flow_params)
    训练师.fit(模型)
    训练师.test()
    mlflow.log_artifact(“confusion_matrix.png”)
mlflow.end_run()

我将 .png 文件保存在本地，然后使用 mlflow.log_artifact(“confusion_matrix.png”) 将其记录到与实验对应的右侧文件夹中的 ftp 服务器。到目前为止，一切正常，只是该工件没有显示在在线 mlflow ui 中。记录的参数和指标正常显示。工件面板保持空白，仅显示
未记录任何工件
使用日志工件 API 存储 MLflow 运行的文件输出。

我发现了类似的线程，但仅限于在本地 mlflow 存储上遇到相同问题的用户。不幸的是，我无法将这些修复应用于我的问题。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</guid>
      <pubDate>Tue, 10 Aug 2021 14:15:42 GMT</pubDate>
    </item>
    <item>
      <title>分类与回归？</title>
      <link>https://stackoverflow.com/questions/33908127/classification-vs-regression</link>
      <description><![CDATA[我不太清楚分类和回归之间有什么区别。
据我了解，分类是绝对的。要么是这个，要么是那个。
回归更多的是一种预测。


上面的两个问题都更像是回归问题，对吗？它都是使用学习算法来预测。谁能举一个分类与回归的例子吗？]]></description>
      <guid>https://stackoverflow.com/questions/33908127/classification-vs-regression</guid>
      <pubDate>Wed, 25 Nov 2015 03:41:55 GMT</pubDate>
    </item>
    </channel>
</rss>