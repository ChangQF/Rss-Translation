<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 26 Dec 2023 12:24:13 GMT</lastBuildDate>
    <item>
      <title>如何将 Synthesia 风格的视频转换为 Midi 文件？</title>
      <link>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</link>
      <description><![CDATA[我正在尝试找出一些方法来使用 Python 将一些合成风格的视频转换为 midi 文件。视频如下所示： 
我在研究将提取的数据转换为 Midi 的方法时没有遇到问题，因为有大量的资源，但我找不到从视频中提取数据的有效方法。
基本的运动检测不起作用，因为手和粒子也被标记为移动物体（显然）。
有什么方法可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</guid>
      <pubDate>Tue, 26 Dec 2023 12:04:15 GMT</pubDate>
    </item>
    <item>
      <title>我的模型在训练后预测完全相反的值。 （即将圆的内部值预测为外部值，将外部值预测为内部值）</title>
      <link>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</link>
      <description><![CDATA[制作数据集
from sklearn.datasets import make_circles
n_样本=1000
x, y = make_circles(n_samples, 噪声=0.03, random_state=42)
X = torch.from_numpy(x).type(torch.float)
Y = torch.from_numpy(y).type(torch.float)
从 sklearn.model_selection 导入 train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=42)

模型（预测圆）（我们知道圆的方程 s (x**2 + y**2 = r**2)
类 cp(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.r = nn.Parameter(torch.randn(1, require_grad = True, dtype=torch.float))
    def 前向（自身，x）：
        返回 x[:, 0]**2 + x[:, 1]**2 - self.r**2
火炬.manual_seed(42)
米 = cp()
loss_fn = nn.BCEWithLogitsLoss()
opt = torch.optim.SGD(params = m.parameters(), lr=0.1)

训练循环
&lt;前&gt;&lt;代码&gt;e = 1000
对于范围 (e+1) 内的 i：
    m.train()
    p = m(xtrain).squeeze()
    f = torch.round(torch.sigmoid(p))
    l = loss_fn(p, ytrain)
    acc = precision_fn(f, ytrain)
    opt.zero_grad()
    l.backward()
    opt.step()
    如果（i%10==0）：
        使用 torch.inference_mode()：
            tp = m(xtest).squeeze()
            tf= 火炬.round(火炬.sigmoid(tp))
            tl = loss_fn(tp, ytest)
            tacc = precision_fn(tf, ytest)
            print(f&quot;epoch: {i} | 训练损失: {l:.4f} | 训练 acc: {acc} | 测试损失: {tl:.4f} | 测试 acc: {tacc}&quot;)
            if(i%100==0): 打印(m.state_dict())

如果我按照上述方式训练模型，它会预测 1 为 0，O 为 1。
IE。 ytrain[:10] = 张量([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])。预测值为： torch.round(torch.sigmoid(m(xtrain[:10]))) = tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1.])
但是，当我绘制圆时，它的预测正确（圆的半径预测正确）
预测圆
我试图预测一个圆。里面都是0，外面都是1。但训练后，它以相反的顺序进行预测（即外部 0 和内部 1）。请检查一次。我已经提供了完整的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</guid>
      <pubDate>Tue, 26 Dec 2023 09:49:49 GMT</pubDate>
    </item>
    <item>
      <title>人工智能公司的投资回报率场景[关闭]</title>
      <link>https://stackoverflow.com/questions/77716540/roi-scenario-of-company-in-ai</link>
      <description><![CDATA[我想创建一个基于公司数据的应用程序，它会生成许多投资回报率方案，而不仅仅是投资回报率，您知道有什么可以帮助我的吗？另外，如果您有任何 Github 存储库，请在下面提及
我想要解决此问题的 Github 存储库]]></description>
      <guid>https://stackoverflow.com/questions/77716540/roi-scenario-of-company-in-ai</guid>
      <pubDate>Tue, 26 Dec 2023 09:30:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 val_loss 曲线看起来这么奇怪？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</link>
      <description><![CDATA[类 myResidualBlock1DSample(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DSample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, out_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(out_channels//2)
        self.relu = nn.ReLU()
        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv1d(out_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)
        别的：
            self.conv3 = 无
            self.pool3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.pool1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.pool2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.pool3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 myResidualBlock1DUpsample(nn.Module)：
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DUpsample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, in_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(in_channels//2)
        self.relu = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        self.conv2 = nn.Conv1d(in_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.upsample2 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.upsample3 = nn.Upsample(scale_factor=4, mode=&#39;线性&#39;)
        别的：
            self.conv3 = 无
            self.upsample3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.upsample1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.upsample2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.upsample3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 ResidualAutoencoder1Dv2(nn.Module):
    def __init__(自身):
        超级().__init__()
        #编码器
        self.res1 = myResidualBlock1DSample(1, 32, use_1x1conv=True)
        self.res2 = myResidualBlock1DSample(32, 128, use_1x1conv=True)
        self.res5 = myResidualBlock1DSample(128,512,use_1x1conv=True)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(5120, 4096)
        self.fc2 = nn.Linear(4096, 2048)
        self.fc3 = nn.Linear(2048, 1024)
        self.dropout = nn.Dropout(p=0.2)
        self.fc4 = nn.Linear(1024, 4)
        self.relu = nn.ReLU()
        #解码器
        self.fc5 = nn.Linear(4, 47)
        self.conv1 = nn.Conv1d(1, 128, kernel_size=3, stride=1)#序列长度变成45
        self.res3 = myResidualBlock1DUpsample(128, 32, use_1x1conv=True)
        self.res4 = myResidualBlock1DUpsample(32, 1, use_1x1conv=True)
        self.fc6 = nn.Linear(720,700)

    def 前向（自身，x）：
        #编码器
        x = self.res1(x)
        x = self.res2(x)
        x = self.res5(x)
        x = self.展平(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.relu(x)
        x = self.dropout(x)
        编码输出 = self.fc4(x)
        #解码器
        x = self.fc5(编码输出)
        x = x.unsqueeze(1)
        x = self.conv1(x)
        x = self.res3(x)
        x = self.res4(x)
        解码输出 = self.fc6(x)
        返回编码输出、解码输出


为什么我的损失曲线晃动这么大？事实上，曲线仍然可以下降到低点。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</guid>
      <pubDate>Tue, 26 Dec 2023 08:53:40 GMT</pubDate>
    </item>
    <item>
      <title>RocCurveDisplay.from_estimator 无法显示 Roc 曲线图</title>
      <link>https://stackoverflow.com/questions/77716366/roccurvedisplay-from-estimator-is-not-able-to-display-roc-curve-graph</link>
      <description><![CDATA[RocCurveDisplay.from_estimator 无法显示图表。
随机森林：无结果中显示“无”而不是图表
我不明白这是什么问题？
我曾尝试尽一切可能，不幸的是我未能查明显示图表的正确代码。任何帮助都将不胜感激。下面是我的代码
导入 pandas 作为 pd
从 sklearn.naive_bayes 导入 GaussianNB
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 precision_score, precision_score

df = pd.read_csv(“xyz.csv”)

X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.3, random_state=56)

分类器 = [
    [&#39;朴素贝叶斯：&#39;, GaussianNB()],
    [&#39;决策树：&#39;, DecisionTreeClassifier(random_state=56)],
    [&#39;随机森林：&#39;, RandomForestClassifier(random_state=56)],
]

Predictions_df=pd.DataFrame()
Predictions_df[&#39;action&#39;] = Y_test

# 使用的各个分类器的准确性
对于名称，分类器中的分类器：
    分类器 = 分类器
    classifier.fit (X_train,Y_train.ravel())
    预测 = classifier.predict(X_test)
    Predictions_df[name.strip(&quot;:&quot;)] = 预测
    打印(“\n”)
    打印（名称，“准确度：”，accuracy_score（Y_test，预测））
    print(名称,“精度:”, precision_score(Y_test,预测))
    RocCurveDisplay.from_estimator(分类器, X_test, Y_test)
    print(name, plt.show()) # 为什么我无法显示 ROC 曲线？
    打印(“\n”)
]]></description>
      <guid>https://stackoverflow.com/questions/77716366/roccurvedisplay-from-estimator-is-not-able-to-display-roc-curve-graph</guid>
      <pubDate>Tue, 26 Dec 2023 08:39:35 GMT</pubDate>
    </item>
    <item>
      <title>Keras / Tensorflow：类型错误：无法序列化类型为 <class 'ellipsis'> 的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/keras-tensorflow-typeerror-cannot-serialize-object-ellipsis-of-type-class</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息（我使用的是 Tensorflow 版本 2.15.0）
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层（代码如下）。
问题：
model.fit(...) 会导致以下错误：
类型错误：无法序列化  类型的对象省略号。要可序列化，类必须实现 get_config() 方法。
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

历史=模型.fit(
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/keras-tensorflow-typeerror-cannot-serialize-object-ellipsis-of-type-class</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>在本地计算机中设置 UDpipe 服务器</title>
      <link>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</guid>
      <pubDate>Tue, 26 Dec 2023 06:18:57 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据的随机森林建模：寻求不需要插补或数据删除的包或方法</title>
      <link>https://stackoverflow.com/questions/77715672/random-forest-modeling-with-missing-data-seeking-packages-or-approaches-that-do</link>
      <description><![CDATA[我有一个包含多个变量的数据集，其中包含缺失值，并且我不希望估算或丢弃它们。我有兴趣在处理缺失的观察结果时将随机森林模型拟合到这些数据。谁能推荐专门设计的软件包或方法，用于将随机森林拟合到缺失值的数据，而不需要插补或删除不完整的记录？”]]></description>
      <guid>https://stackoverflow.com/questions/77715672/random-forest-modeling-with-missing-data-seeking-packages-or-approaches-that-do</guid>
      <pubDate>Tue, 26 Dec 2023 04:28:14 GMT</pubDate>
    </item>
    <item>
      <title>ML Kit 的姿势检测模型不适用于 Flutter</title>
      <link>https://stackoverflow.com/questions/77715363/ml-kits-pose-detection-model-not-working-on-flutter</link>
      <description><![CDATA[我们需要一个InputImage实例来检测身体的关键点，但是“null”正在退货。
将文件路径传递给InputImage.fromFilePath()：
最终InputImage inputImage = InputImage.fromFilePath(&#39;/assets/images/girl.png&#39;);
打印（inputImage.bytes）； // 输出：空

相同的文件，使用相同的文件路径，并且正在显示图像：
&lt;前&gt;&lt;代码&gt;@覆盖
  小部件构建（BuildContext上下文）{
    返回常量中心（
      孩子：图像（
        image: AssetImage(&#39;assets/images/girl.png&#39;) // 这有效
      ),
    ）；
  }
]]></description>
      <guid>https://stackoverflow.com/questions/77715363/ml-kits-pose-detection-model-not-working-on-flutter</guid>
      <pubDate>Tue, 26 Dec 2023 01:37:57 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe 静态存储视频人脸标志检测</title>
      <link>https://stackoverflow.com/questions/77715244/mediapipe-static-stored-video-face-landmark-detection</link>
      <description><![CDATA[该帖子已被隐藏。你刚刚删除了这篇文章。
关闭。这个问题需要更加有针对性。目前不接受答案。
更新问题，使其仅关注一个问题。这将有助于其他人回答问题。您可以编辑问题或发布新问题。
22 小时前关闭。
此帖子已于 19 小时前编辑并提交审核。
我一直在尝试让媒体管道来检测静态（存储）视频中的面部标志，但所有在线指南和教程都使用实时摄像头源。在 Python 中很容易，但我必须在 JavaScript 中完成。
我发现这两个指南最相关，但都使用实时摄像头。
 https://medium.com/@mamikonyanmichael/what-is-media-pipe-and-how-to-use-it-in-react-53ff418e5a68
https://github.com/jays0606/mediapipe-facelandmark-demo 
如何在静态（本地存储）视频而不是 JavaScript 中的实时摄像头源上运行 Mediapipe 的人脸检测？]]></description>
      <guid>https://stackoverflow.com/questions/77715244/mediapipe-static-stored-video-face-landmark-detection</guid>
      <pubDate>Tue, 26 Dec 2023 00:07:55 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 执行情感分析</title>
      <link>https://stackoverflow.com/questions/77714420/how-can-i-perform-sentiment-analysis-using-python</link>
      <description><![CDATA[有人可以帮我解释一下 python 代码吗，因为我是一个尝试做项目的初学者。请亲自联系我，以便我可以分享我的代码，因为我非常紧急地需要代码方面的帮助...
尝试对社交媒体帖子进行情感分析，但在执行算法时遇到问题。]]></description>
      <guid>https://stackoverflow.com/questions/77714420/how-can-i-perform-sentiment-analysis-using-python</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:37 GMT</pubDate>
    </item>
    <item>
      <title>用于实时流处理的 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</link>
      <description><![CDATA[我正在 aws 上对实时视频流进行实时机器学习处理。
对于直播，正在使用 kinesis 视频流。
我正在从模型工件（存储我们的推理脚本和模型文件的位置）创建 sagemaker 端点
当我们从实时流中获取它们时，每个帧都会独立调用此端点。
挑战在于维护变量的缓存/会话状态。当每个帧到达端点时，它没有有关先前运行的结果的信息。为了解决这个问题，我为每次调用下载缓存并将其上传到数据库（dynamo db），这似乎是一种低效的方法。
供参考 - 我在推理脚本中使用 pytorch 框架中外部训练的 YOLO 对象检测模型。
所以我的问题是-
如何维护一个活动的 sagemaker 实例，它可以监听实时流和进程生成的帧？该实例应维护其流的会话状态，并应通过实时流自动调用。]]></description>
      <guid>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</guid>
      <pubDate>Fri, 22 Dec 2023 08:28:38 GMT</pubDate>
    </item>
    <item>
      <title>从 Keras model.evaluate 和 model.predict 获得不同的结果</title>
      <link>https://stackoverflow.com/questions/57212021/getting-different-results-from-keras-model-evaluate-and-model-predict</link>
      <description><![CDATA[我已经使用 word2vec 训练了一个模型来预测主题类别，并使用 keras 训练了一个 lstm 模型，并且在训练期间获得了大约 98% 的准确率，我保存了模型，然后将其加载到另一个文件中以在测试集上进行尝试，我使用了 model.evaluate 和 model.predict 结果非常不同。
我使用keras和tensorflow作为后端，模型摘要是：

&lt;前&gt;&lt;代码&gt;_________________________________________________________________
层（类型）输出形状参数#
=================================================== ===============
lstm_1（LSTM）（无，22）19624
_________________________________________________________________
dropout_1（辍学）（无，22）0
_________________________________________________________________
密集_1（密集）（无，40）920
_________________________________________________________________
activation_1（激活）（无，40）0
=================================================== ===============
总参数：20,544
可训练参数：20,544
不可训练参数：0
_________________________________________________________________
没有任何

代码：
model.compile（loss=&#39;binary_crossentropy&#39;，optimizer=&#39;adam&#39;，metrics=[&#39;accuracy&#39;]）
model.load_weights(os.path.join(&#39;model&#39;, &#39;lstm_model_weights.hdf5&#39;))
分数，acc = model.evaluate（x_test，y_test，batch_size=batch_size）

打印（）
print(&#39;分数：%1.4f&#39; % 分数)
print(&#39;评估准确度：%1.2f%%&#39; % (acc*100))

预测= model.predict(x_test,batch_size=batch_size)
acc2 = np.count_nonzero(预测.argmax(1) == y_test.argmax(1))/y_test.shape[0]
print(&#39;预测精度：%1.2f%%&#39; % (acc2*100))

这段代码的输出是

&lt;前&gt;&lt;代码&gt;39680/40171 [==============================&gt;.] - 预计到达时间：0 秒
得分：0.1192
评估准确率：97.50%
预测准确率：9.03%

谁能告诉我我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/57212021/getting-different-results-from-keras-model-evaluate-and-model-predict</guid>
      <pubDate>Fri, 26 Jul 2019 01:29:13 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”</title>
      <link>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</link>
      <description><![CDATA[我正在尝试使用最新的可用资源来开发一些时间序列序列预测。为此，我确实检查了 TensorFlow 时间序列中的示例代码，但收到此错误：
AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”

我正在使用 Anaconda。当前环境是Python 3.5和TensorFlow 1.2.1。也尝试过 TensorFlow 1.3，但没有任何改变。
这是我的代码尝试运行。我在谷歌上没有找到与该问题相关的任何有用信息。有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</guid>
      <pubDate>Sat, 02 Sep 2017 04:48:51 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能 (AI) 预测股票价格</title>
      <link>https://stackoverflow.com/questions/2686981/using-artificial-intelligence-ai-to-predict-stock-prices</link>
      <description><![CDATA[给定一组与  非常相似的数据Motley Fool CAPS 系统，个人用户可以在其中输入各种股票的买入和卖出建议。我想做的是显示每个建议，并且我猜想它是否是未来股票价格（或每股收益或其他）的良好预测器&lt;5&gt;（即相关系数= 1）的评级（1-5）或一个可怕的预测变量（即相关系数 = -1）或介于两者之间。
每个推荐都标记给特定用户，以便可以随着时间的推移进行跟踪。我还可以根据 SP500 价格等来跟踪市场方向（看涨/看跌）。我认为在模型中有意义的组件是：

&lt;前&gt;&lt;代码&gt;用户
方向（长/空）
市场方向
股票部门

我们的想法是，有些用户在牛市中比熊市中表现更好（反之亦然），而有些用户在空头方面比多头方面更好，然后是上述的组合。我可以自动标记市场方向和板块（基于当时的市场和推荐的股票）。
我的想法是，我可以呈现一系列屏幕，并允许我通过显示特定时间段内的可用数据绝对值、市场和部门表现来对每个单独的推荐进行排名。我会按照详细的列表对股票进行排名，以便排名尽可能客观。我的假设是单个用户正确的概率不超过 57% - 但谁知道呢。
我可以加载系统并说“让我们将推荐排名为 90 天后股票价值的预测指标”；这将代表一组非常明确的排名。
现在，关键是 - 我想创建某种机器学习算法，可以识别一系列时间的模式，以便当建议流入应用程序时，我们维护该股票的排名（即类似于相关系数） ）关于该推荐（除了过去的一系列推荐之外）影响价格的可能性。
现在这是超级关键。我从未上过人工智能课程/读过人工智能书籍/更不用说特定于机器学习的内容。因此，我正在寻找指导 - 我可以适应的类似系统的示例或描述。寻找信息或任何一般帮助的地方。或者甚至推动我朝着正确的方向开始......
我的希望是用 F# 来实现这一点，并能够通过 F# 中的新技能、机器学习的实现以及我可以包含在技术组合或博客空间中的潜在内容（应用程序/源代码）给我的朋友留下深刻的印象； 
感谢您提前提供任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/2686981/using-artificial-intelligence-ai-to-predict-stock-prices</guid>
      <pubDate>Wed, 21 Apr 2010 22:24:38 GMT</pubDate>
    </item>
    </channel>
</rss>