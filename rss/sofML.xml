<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 17 Jul 2024 18:20:05 GMT</lastBuildDate>
    <item>
      <title>如何使用 golearn 在 GoLang 中训练随机森林</title>
      <link>https://stackoverflow.com/questions/78760263/how-to-train-random-forest-in-golang-using-golearn</link>
      <description><![CDATA[我正在使用“github.com/sjwhitworth/golearn”在我的数据集上训练随机森林，我已经正确配置了它，但我一直收到错误：
未定义：新参数
未定义：新问题
未定义：训练
未定义：预测
我是新手，所以我不知道如何修复它。
这是我目前的代码：
package main

import (
&quot;fmt&quot;
&quot;log&quot;

&quot;github.com/sjwhitworth/golearn/base&quot;
&quot;github.com/sjwhitworth/golearn/ensemble&quot;
&quot;github.com/sjwhitworth/golearn/evaluation&quot;
)
func trainAndTest() {
// 加载训练数据集
trainingData, err := base.ParseCSVToInstances(&quot;training.csv&quot;, true)
if err != nil {
log.Fatal(err)
}

// 加载测试数据集
testData, err := base.ParseCSVToInstances(&quot;test.csv&quot;, true)
if err != nil {
log.Fatal(err)
}

// 假设类标签位于 golearn 中的最后一列
//trainingData.Shuffle()

// 初始化一个新的 RandomForest 分类器
rf := ensemble.NewRandomForest(10, 2)

// 训练 RandomForest 分类器
rf.Fit(trainingData)

// 使用训练好的分类器预测测试数据集的标签
predictions, err := rf.Predict(testData)
if err != nil {
log.Fatal(err)
}

// 评估模型
chaosMat, err := evaluation.GetConfusionMatrix(testData, predictions)
if err != nil {
log.Fatal(err)
}

// 打印评估指标
fmt.Println(evaluation.GetSummary(confusionMat))

}
func main() {
trainAndTest()

}


我已经将 golang 版本更改为可能的解决方案，但不知道如何进一步处理。
任何帮助都将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78760263/how-to-train-random-forest-in-golang-using-golearn</guid>
      <pubDate>Wed, 17 Jul 2024 15:06:13 GMT</pubDate>
    </item>
    <item>
      <title>Kai 文本中的灰狼算法和 CNN</title>
      <link>https://stackoverflow.com/questions/78760010/gray-wolf-algorithm-and-cnn-in-kai-text</link>
      <description><![CDATA[我使用灰狼优化算法来优化 CNN 的超参数，但结果不但没有得到更多，准确率只有 95 左右，准确率只有 35，而且我找不到问题所在。有人能帮我吗，哪里出错了？我知道自己代码吗？
我从 GPT chat 上得到了灰狼代码，但似乎有些部分是错误的]]></description>
      <guid>https://stackoverflow.com/questions/78760010/gray-wolf-algorithm-and-cnn-in-kai-text</guid>
      <pubDate>Wed, 17 Jul 2024 14:10:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Huggingface Hub 上成功设置和检索 HuggingfaceDataset 的元数据信息？</title>
      <link>https://stackoverflow.com/questions/78759790/how-do-i-successfully-set-and-retrieve-metadata-information-for-a-huggingfacedat</link>
      <description><![CDATA[我有许多数据集，它们是从字典中创建的，如下所示：
info = DatasetInfo(
description=&quot;my happy lil dataset&quot;,
version=&quot;0.0.1&quot;,
homepage=&quot;https://www.myhomepage.co.uk&quot;
)
train_dataset = Dataset.from_dict(prepare_data(data[&quot;train&quot;]), info=info)
test_dataset = Dataset.from_dict(prepare_data(data[&quot;test&quot;]), info=info)
validation_dataset = Dataset.from_dict(prepare_data(data[&quot;validation&quot;]),info=info)

然后我将它们组合成一个 DatasetDict。
# 创建 DatasetDict
dataset = DatasetDict(
{&quot;train&quot;: train_dataset, &quot;test&quot;: test_dataset, &quot;validation&quot;: validation_dataset}
)

到目前为止，一切顺利。如果我访问 dataset[&#39;train&#39;].info.description，我会看到预期结果“My happy lil dataset”。
因此，我将其推送到集线器，如下所示：
dataset.push_to_hub(f&quot;{organization}/{repo_name}&quot;, commit_message=&quot;Some commit message&quot;)

这也成功了。
但是，当我从集线器拉回数据集并访问与其相关的信息时，我没有获取数据集的描述，而是只得到了一个空字符串；像这样：
pulled_data = full = load_dataset(&quot;f{organization}/{repo_name}&quot;, use_auth_token = True)

# 我希望以下内容打印出&quot;my happy lil dataset&quot;
print(pulled_data[&quot;train&quot;].info.description)
# 但是，它返回的是 &#39;&#39;

我是否以错误的方式从集线器加载了数据？我是否以某种方式只推送了我的数据集而不推送信息？
我觉得我遗漏了一些显而易见的东西，但我真的不确定。任何帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78759790/how-do-i-successfully-set-and-retrieve-metadata-information-for-a-huggingfacedat</guid>
      <pubDate>Wed, 17 Jul 2024 13:23:04 GMT</pubDate>
    </item>
    <item>
      <title>DSPy 无法检索 ChromaDB 中带有文本嵌入的段落</title>
      <link>https://stackoverflow.com/questions/78758312/dspy-cant-retrieve-passage-with-text-embeddings-in-chromadb</link>
      <description><![CDATA[我正在使用 DSPy 和 ChromaDB 为 pdf 文件开发 RAG 应用程序。
首先，我从 pdf 中获取文本并将其作为块添加到 Chromadb。还添加了块的嵌入。并尝试使用 DSPy 检索与查询相关的块。但是它出现了错误
存储数据和嵌入
def store_document_in_chromadb(text):
chunks = chunk_document(text)
ids = [f&#39;chunk_{i}&#39; for i in range(len(chunks))]
embeddings = [get_embedding(chunk).tolist() for chunk in chunks]

collection.add(ids=ids, documents=chunks, embeddings=embeddings)

我尝试像这样检索相关块，
retriever_model = ChromadbRM(&quot;contracts_collection&quot;, &#39;db/&#39;, k=2)
dspy.settings.configure(lm=llama2_model, rm=retriever_model)

class GenerateAnswer(dspy.Signature): 
“”“”根据给出的上下文回答问题。“”“”
context = dspy.InputField(desc=&quot;可能包含相关上下文&quot;)
question = dspy.InputField()
answer = dspy.OutputField(desc=&quot;通常为 5 到 10 个单词&quot;)

class RAG(dspy.Module): 
def __init__(self, num_passages=2):
super().__init__()
self.retrieve = dspy.Retrieve(k=num_passages)
self.generate_answer = dspy.ChainOfThought(GenerateAnswer)

def forward(self, question):
context = self.retrieve(question).passages
prediction = self.generate_answer(context=context, question=question)
return dspy.Prediction(context=context, answer=prediction.answer)

with dspy.context(lm=llama2_model, rm=retriever_model):
module = RAG()
response = module(&quot;总支出是多少&quot;)
print(response)

当我运行此程序时，出现此错误
InvalidDimensionException：嵌入维度 384 与集合维度 768 不匹配
但是当我从 ChromaDB 中删除嵌入时，它会正确检索相关块。
有人知道为什么使用嵌入时没有出现此错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78758312/dspy-cant-retrieve-passage-with-text-embeddings-in-chromadb</guid>
      <pubDate>Wed, 17 Jul 2024 08:03:30 GMT</pubDate>
    </item>
    <item>
      <title>请帮助我构建我的二元分类项目[关闭]</title>
      <link>https://stackoverflow.com/questions/78758049/please-help-me-to-structure-my-binary-classification-project</link>
      <description><![CDATA[我正在开发一个二元分类项目。最初，我得到了一个包含 3290 行和 15 列的真实数据的数据集。然后，我使用 CTGAN 网络生成了包含 100000 行的合成数据集。然后，我将这两个数据集混洗，得到 1 个数据集。我的目标变量高度不平衡（是：23175，否：76825）。我对我的项目有以下问题？

有 7 个分类预测因子，其中有 4 个二元分类列（性别、婚姻状况等），其他是非二元分类变量（省、区等）。我应该使用什么编码技术？

处理这里的数据不平衡问题是否重要？如果重要，我应该使用什么技术来处理这个不平衡问题？

我的数值变量都不是正态分布的。处理这个问题是否重要？如果是，我需要使用哪些技术（例如，如果需要，进行转换）？

我需要标准化或规范化我的数据吗？如果是，为什么？

我应该在这里使用哪些特征选择技术？

我的项目的顺序是什么。请按以下顺序排列。（数据不平衡问题处理/编码分类变量/转换数值数据/标准化或规范化数值数据/特征选择\建模）

最后我可以使用神经网络来实现这一点吗？如果可以，我可以使用哪些 NN 类型


我知道这是一个很长的问题，感谢您花时间和精力回答这些问题。
我期待上述问题的答案。]]></description>
      <guid>https://stackoverflow.com/questions/78758049/please-help-me-to-structure-my-binary-classification-project</guid>
      <pubDate>Wed, 17 Jul 2024 06:57:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在 XGBoost 决策树的叶节点上显示预测类标签？</title>
      <link>https://stackoverflow.com/questions/78757774/how-do-i-display-predicted-class-labels-on-the-leaf-nodes-of-an-xgboost-decision</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78757774/how-do-i-display-predicted-class-labels-on-the-leaf-nodes-of-an-xgboost-decision</guid>
      <pubDate>Wed, 17 Jul 2024 05:22:10 GMT</pubDate>
    </item>
    <item>
      <title>无法安装 pytorch-forecasting：没有名为“distutils”的模块错误</title>
      <link>https://stackoverflow.com/questions/78757738/unable-to-install-pytorch-forecasting-no-module-named-distutils-error</link>
      <description><![CDATA[当我尝试在 VSCode 终端中运行 pip install pytorch-forecasting 时，我收到错误消息，提示没有 没有名为“distutils”的模块。
首先，PyTorch 已安装，并且使用 conda install pytorch-forecasting pytorch&gt;=1.7 -c pytorch -c conda-forge 在 Anaconda 上安装了 pytorch-forecasting。
我已经看到了 pip install setuptools 的解决方案。我在我的终端上成功运行了安装 setuptools 的命令，但它并没有摆脱“没有名为“distutils”的模块”错误。
我需要帮助来绕过“没有名为“distutils”的模块”错误，以便我可以安装 pytorch-forecasting 包。]]></description>
      <guid>https://stackoverflow.com/questions/78757738/unable-to-install-pytorch-forecasting-no-module-named-distutils-error</guid>
      <pubDate>Wed, 17 Jul 2024 05:09:49 GMT</pubDate>
    </item>
    <item>
      <title>如何将多头自注意力输出的形状更改为可以馈送到卷积层的形状？</title>
      <link>https://stackoverflow.com/questions/78757193/how-to-change-shape-of-multi-head-self-attention-output-to-a-shape-that-can-be-f</link>
      <description><![CDATA[我遇到了这样的错误：
MHSA（多头自注意力）的输出如下：
torch.Size([20, 197, 768])


批次大小为 20
序列长度为 197（之前为 196，添加类标记后变为 197）
嵌入维度为 768

我想将其重塑以适应以下格式，以便将其馈送到卷积层：
torch.Size([batch_size, channel, width, height])

我尝试通过使用以下方法添加新维度来实现此目的方法：
torch.unsqueeze(1)
torch.transpose(1, 3)

这成功地允许馈送到卷积层。但是，我不确定这种方法是否正确，如果不正确，请纠正我。
目前，我正在尝试一种不同的方法：
new_size = int(math.sqrt(sequence_length))
torch.transpose(1, 2).view(batch_size, embed_dim, new_size, new_size)

这导致错误，指出形状对于大小为 (some_number) 的输入无效。这是因为序列长度（197）不是完全平方的，得出的是一个十进制数，而视图函数需要输入一个整数，平方运算在转换为整数后得出 16，但 batch_size * 768 * 16 * 16 不等于 batch_size * 197 * 768，导致错误
我的分析正确吗？我该如何解决这个问题？还有没有更好的方法？]]></description>
      <guid>https://stackoverflow.com/questions/78757193/how-to-change-shape-of-multi-head-self-attention-output-to-a-shape-that-can-be-f</guid>
      <pubDate>Wed, 17 Jul 2024 00:24:06 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型无法训练</title>
      <link>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</link>
      <description><![CDATA[我正在尝试使用深度学习来查找粒子的化学状态。作为输入，我有粒子在 X_train 中随时间的位置，形状为 (num_train,sequence_length)。 （我的序列长度为 100），输出是形状为 (num_train,1) 的 Y_train 中包含的转换帧（介于 1 和 100 之间）。
这是一个序列示例（https://i.sstatic.net/Ddmhjc24.jpg），转换位于第 84 帧。
所有数据都是用非常具体的算法生成的，但是该算法不会生成非常复杂的数据，我认为自己很容易找到转换，但我希望这个深度学习模型能够正常工作。
这是 LSTM 代码：
# 过滤

# 定义 LSTM 模型
model = Sequential([
LSTM(64, input_shape=(sequence_length, 1), return_sequences=False), Dense(64,activation=&#39;relu&#39;), Dense(1) ]) # 模型编译器 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) # 回归的均方误差 # 模型摘要 model.summary() # 模型模型嵌入 model.fit( X_train, Y_train, epochs=40, batch_size=32,validation_data=(X_test, Y_test)) # 新预测示例预测 = model.predict(X_test) print(prediction)  结果： 模型：“顺序”
_________________________________________________________________
层（类型）输出形状参数 # 
====================================================================
lstm (LSTM) (无，64) 16896 

密集 (密集) (无，64) 4160 

密集_1 (密集) (无，1) 65 

============================================================================
总参数：21121 (82.50 KB)
可训练参数： 21121 (82.50 KB)
不可训练参数：0 (0.00 字节)
_________________________________________________________________
Epoch 1/10
631/631 [==============================] - 35s 50ms/step - 损失：1043.6710 - val_loss：840.6771
Epoch 2/10
631/631 [==============================] - 30s 48ms/step - 损失：840.9444 - val_loss：839.9596
Epoch 3/10
631/631 [===============================] - 32s 50ms/步 - 损失：841.6289 - val_loss：840.7188
Epoch 4/10
631/631 [=============================] - 30s 48ms/步 - 损失：840.9946 - val_loss：840.6344
Epoch 5/10
631/631 [===============================] - 33s 52ms/步 - 损失：841.8745 - val_loss：839.9298
Epoch 6/10
631/631 [==============================] - 31s 49ms/步 - 损失：841.6499 - val_loss：839.8434
Epoch 7/10
631/631 [=============================] - 31s 49ms/步 - 损失：841.2045 - val_loss：840.0717
Epoch 8/10
631/631 [===============================] - 30s 48ms/步 - 损失：842.0576 - val_loss： 840.2137
纪元 9/10
631/631 [=============================] - 33s 52ms/步 - 损失：842.7056 - val_loss：840.5657
纪元 10/10
631/631 [=============================] - 30s 48ms/步 - 损失：841.5714 - val_loss：839.8404
70/70 [================================] - 2s 16ms/步
[[52.569366]
[52.569286]
[52.569378]
...
[52.569344]
[52.569313]
[52.56937 ]]

如您所见，当我测试训练后的模型时，无论输入是什么，输出都是相同的。 val_loss 不会随着 epoch 的数量而改善。 这就是问题所在，我不明白发生了什么。
我是深度学习的初学者，所以也许我犯了一个非常简单的错误。 但是我仔细检查了我的数据，X_train 已标准化，我尝试在我的模型上添加一些 drop out 和其他层，但没有任何变化。
也许使用 LSTM 无法做到这一点，但我认为数据非常简单。 我真的想尝试找到一种方法来使用深度学习来找到它。 我 d]]></description>
      <guid>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</guid>
      <pubDate>Tue, 16 Jul 2024 07:31:40 GMT</pubDate>
    </item>
    <item>
      <title>即使经过数百个时期，pytorch AdamW 的 LR 仍未衰减</title>
      <link>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</link>
      <description><![CDATA[我有以下使用 Pytorch 中的 AdamW 优化器的代码：
optimizer = AdamW(params=self.model.parameters(), lr=0.00005)

我尝试使用 wandb 进行登录，如下所示：
lrs = {f&#39;lr_group_{i}&#39;: param_group[&#39;lr&#39;]
for i, param_group in enumerate(self.optimizer.param_groups)}
wandb.log({&quot;train_loss&quot;: avg_train_loss, &quot;val_loss&quot;: val_loss, **lrs})

请注意 weight_decay 参数的默认值为 0.01（对于 AdamW）。
当我检查 wandb 仪表板时，它显示 AdamW 的 LR 即使在 200 个 epoch 之后也相同，并且根本没有衰减。我尝试了几次。

为什么 LR 衰减没有发生？
此外，它仅显示一个参数组的 LR。为什么会这样？似乎我在这里错过了一些基本的东西。有人可以指出吗？]]></description>
      <guid>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</guid>
      <pubDate>Tue, 16 Jul 2024 06:09:44 GMT</pubDate>
    </item>
    <item>
      <title>在生物学项目中使用人体细胞实例分割</title>
      <link>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</link>
      <description><![CDATA[我被困在为与生物学相关的项目进行实例分割的过程中。
我有一些人类细胞的图片（每张图片大约有 5 个细胞），我想要实现的是创建一个模型来拍摄这些图片并识别这些细胞。我面临的问题是：我可以让模型识别细胞，但它无法区分不同的细胞。（这意味着作为输出，我得到的 .png 图片要么是 0 代表背景，要么是 1 代表细胞；所以我没有得到关于它们分离的信息）。例如，如果我想计算图片上有多少个单元格，那么这将是一个问题。
澄清一下：我手头有：单元格图片（RGB，.jpg）和 2 种类型的蒙版：第一种是灰度（背景为 0，单元格全部为 1，.png）和 RGB 图片，其中所有单元格都有不同的 RGB 值（如果图片上有 4 个单元格，则存在 4 个不同的 RGB 值；背景始终为 0）。也是 .png。
使用 fastai，我的 DataBlock 如下所示：
dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),
get_items = get_image_files,
splitter = RandomSplitter(),
get_y = get_label,
item_tfms = Resize(224))

dls = dblock.dataloaders(path, bs=5)

问题：我知道此代码无法工作，因为模型输入的灰度图像只有 0 和 1。但我不知道如何合并其他类型的掩码，该掩码实际上包含有关不同细胞分离的信息（所有细胞都是同一类型）。]]></description>
      <guid>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</guid>
      <pubDate>Fri, 05 Jul 2024 10:24:16 GMT</pubDate>
    </item>
    <item>
      <title>如何查看 YOLOv6 中的评估指标？</title>
      <link>https://stackoverflow.com/questions/78680846/how-to-see-evaluation-metrics-in-yolov6</link>
      <description><![CDATA[我有以下输出，但无法弄清楚如何评估，因为没有 F1 分数 或 混淆矩阵。
平均召回率 (AR) @[ IoU=0.50:0.95 | area= small |maxDets=100] = -1.000

平均召回率 (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250

平均召回率 (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410

20/499 0.001595 0.6697 0 1.393: 100%|██████████| 12/12 [00:

21/499 0.001594 0.6417 0 1.353: 100%|██████████| 12/12 [00:

22/499 0.001594 0.6727 0 1.431: 100%|██████████| 12/12 [00:

我训练了 400 个 epoch，这只是输出的一小部分。我也看不到 mAP。
我有这行代码要评估
!python tools/eval.py --data Fabric-Defect-2/data.yaml --weights runs/train/exp/weights/best_ckpt.pt --device 0

有没有办法获得详细的评估指标，例如 F1 分数、混淆矩阵 和 mAP？]]></description>
      <guid>https://stackoverflow.com/questions/78680846/how-to-see-evaluation-metrics-in-yolov6</guid>
      <pubDate>Fri, 28 Jun 2024 05:55:12 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 FastAPI 在 model.predict() 中直接使用 Pydantic 模型（BaseModel）吗？如果不行，为什么？</title>
      <link>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</link>
      <description><![CDATA[我正在使用带有 FastAPI 的 Pydantic 模型 (Basemodel)，并将输入转换为 dictionary，然后将其转换为 Pandas DataFrame，以便将其传递到 model.predict() 函数中进行机器学习预测，如下所示：
from fastapi import FastAPI
import uvicorn
from pydantic import BaseModel
import pandas as pd
from typing import List

class Inputs(BaseModel):
f1: float,
f2: float,
f3: str

@app.post(&#39;/predict&#39;)
def predict(features: List[Inputs]):
output = []

# 循环输入特征列表
for data in features:
result = {}

# 将数据转换为 dict()，然后转换为 DataFrame
data = data.dict()
df = pd.DataFrame([data])

# 获取预测
prediction = classifier.predict(df)[0]

# 获取概率
probability = classifier.predict_proba(df).max()

# 分配给字典 
result[&quot;prediction&quot;] = prediction
result[&quot;probability&quot;] = probability

# 将字典附加到列表（许多输出）
output.append(result)

返回输出

它运行良好，只是我不太确定它是否优化或是否是正确的方法，因为我将输入转换两次以获得预测。此外，我不确定在输入数量巨大的情况下它是否会快速地工作。对此有什么改进吗？如果有办法（甚至除了使用 Pydantic 模型之外），我可以直接工作并避免经过转换和循环。]]></description>
      <guid>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</guid>
      <pubDate>Tue, 12 Apr 2022 22:11:19 GMT</pubDate>
    </item>
    <item>
      <title>如何计算伯努利朴素贝叶斯的联合对数似然</title>
      <link>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</link>
      <description><![CDATA[对于使用 BernoulliNB 的分类问题，如何计算联合对数似然。联合似然由以下公式计算，其中 y(d) 是实际输出（不是预测值）的数组，x(d) 是特征的数据集。
我阅读了这个答案并阅读了文档，但它并没有完全满足我的目的。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</guid>
      <pubDate>Wed, 17 Oct 2018 18:08:50 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块'_Box2D'没有属性'RAND_LIMIT_swigconstant'</title>
      <link>https://stackoverflow.com/questions/50037674/attributeerror-module-box2d-has-no-attribute-rand-limit-swigconstant</link>
      <description><![CDATA[我正在尝试在强化学习上运行 lunar_lander，但运行时出现错误。
另外我的电脑是osx系统。
这是月球着陆器的代码：
import numpy as np
import gym
import csv

from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from keras.optimizers import Adam

from rl.agents.dqn import DQNAgent
from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy
from rl.memory import SequentialMemory

import io
import sys
import csv

# 路径环境改变以使一切正常工作
# export DYLD_FALLBACK_LIBRARY_PATH=$DYLD_FALLBACK_LIBRARY_PATH:/usr/lib

# 获取环境并提取操作数量。
ENV_NAME = &#39;LunarLander-v2&#39;
env = gym.make(ENV_NAME)
np.random.seed(123)
env.seed(123)
nb_actions = env.action_space.n

# 接下来，我们建立一个非常简单的模型。
model = Sequential()
model.add(Flatten(input_shape=(1,) + env.observation_space.shape))
model.add(Dense(16))
model.add(Activation(&#39;relu&#39;))
model.add(Dense(16))
model.add(Activation(&#39;relu&#39;))
model.add(Dense(16))
model.add(Activation(&#39;relu&#39;))
model.add(Dense(nb_actions))
model.add(Activation(&#39;linear&#39;))
#print(model.summary())

# 最后，我们配置并编译我们的代理。您可以使用每个内置的 Keras 优化器和
# 甚至指标！
memory = SequentialMemory(limit=300000, window_length=1)
policy = EpsGreedyQPolicy()
dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,
target_model_update=1e-2, policy=policy)
dqn.compile(Adam(lr=1e-3), metrics=[&#39;mae&#39;])

# 训练完成后，我们保存最终权重。
dqn.load_weights(&#39;dqn_{}_weights.h5f&#39;.format(ENV_NAME))

# 重定向 stdout 以捕获测试结果
old_stdout = sys.stdout
sys.stdout = mystdout = io.StringIO()

# 评估我们的算法的几个情节。
dqn.test(env, nb_episodes=200, visualize=False)

# 重置 stdout
sys.stdout = old_stdout

results_text = mystdout.getvalue()

# 打印结果文本
print(&quot;results&quot;)
print(results_text)

# 从结果中提取奖励列表
total_rewards = list()
for idx, line in enumerate(results_text.split(&#39;\n&#39;)):
if idx &gt; 0 and len(line) &gt; 1：
reward = float(line.split(&#39;:&#39;)[2].split(&#39;,&#39;)[0].strip())
total_rewards.append(reward)

# 打印奖励和平均值
print(&quot;total rewards&quot;, total_rewards)
print(&quot;average total reward&quot;, np.mean(total_rewards))

# 将总奖励写入文件
f = open(&quot;lunarlander_rl_rewards.csv&quot;,&#39;w&#39;)
wr = csv.writer(f)
for r in total_rewards:
wr.writerow([r,])
f.close()

错误如下：
回溯（最近一次调用最后一次）：
文件“/s/user/Document/Semester2/Advanced Machine Learning/Lab/Lab6/lunar_lander_ml_states_player.py”，第 23 行，在 &lt;module&gt; 中
env = gym.make(ENV_NAME)
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/registration.py”，第 167 行，在 make 中
return registry.make(id)
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/registration.py”，第 119 行，在 make 中
env = spec.make()
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/registration.py”，第 85 行，在 make 中
cls = load(self._entry_point)
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/registration.py”，第 14 行，加载中
result = entry_point.load(False)
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/pkg_resources/__init__.py”，第 2405 行，加载中
return self.resolve()
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/pkg_resources/__init__.py”，第 2411 行，解析中
module = __import__(self.module_name, fromlist=[&#39;__name__&#39;], level=0)
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/box2d/__init__.py”，第 1 行，&lt;module&gt;
从 gym.envs.box2d.lunar_lander 导入 LunarLander
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py”，第 4 行，位于 &lt;module&gt;
导入 Box2D
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/Box2D/__init__.py”，第 20 行，位于 &lt;module&gt;
从 .Box2D 导入 *
文件“/s/user/anaconda/envs/untitled/lib/python3.6/site-packages/Box2D/Box2D.py”，第 435 行，位于 &lt;module&gt;
_Box2D.RAND_LIMIT_swigconstant(_Box2D)
AttributeError: 模块 &#39;_Box2D&#39; 没有属性 &#39;RAND_LIMIT_swigconstant&#39;

我尝试按照 https://github.com/pybox2d/pybox2d/blob/master/INSTALL.md 的指南重新安装 Box2d
但仍然不起作用，有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/50037674/attributeerror-module-box2d-has-no-attribute-rand-limit-swigconstant</guid>
      <pubDate>Thu, 26 Apr 2018 07:55:13 GMT</pubDate>
    </item>
    </channel>
</rss>