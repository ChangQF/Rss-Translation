<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 19 May 2024 03:17:14 GMT</lastBuildDate>
    <item>
      <title>如何在训练模型时修复此 KeyError？</title>
      <link>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</guid>
      <pubDate>Sun, 19 May 2024 00:36:44 GMT</pubDate>
    </item>
    <item>
      <title>标准化将 NaN 值插入到我的数据框中</title>
      <link>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</guid>
      <pubDate>Sat, 18 May 2024 23:40:21 GMT</pubDate>
    </item>
    <item>
      <title>GflowNet 无法学习某些奖励</title>
      <link>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</link>
      <description><![CDATA[我尝试将问题简化为以下代码：
# 图表上的转换
转换 = {
    # 0：无操作
    ＃1：N
    ＃2：S
    ＃3：W
    ＃4：E
    1：{0：1、1：2、2：1、3：3、4：1}，
    2：{0：2、1：12、2：1、3：2、4：2}，
    3：{0：3、1：3、2：3、3：4、4：1}，
    4：{0：4、1：5、2：4、3：6、4：3}，
    5: {0: 5, 1: 13, 2: 4, 3: 5, 4: 5},
    6: {0: 6, 1: 6, 2: 6, 3: 7, 4: 4},
    7: {0: 7, 1: 8, 2: 7, 3: 9, 4: 6},
    8: {0: 8, 1: 14, 2: 7, 3: 8, 4: 8},
    9: {0: 9, 1: 9, 2: 9, 3: 10, 4: 7},
    10: {0: 10, 1: 11, 2: 10, 3: 10, 4: 9},
    11: {0: 11, 1: 15, 2: 10, 3: 16, 4: 11},
    12: {0: 12, 1: 18, 2: 2, 3: 12, 4: 12},
    13: {0: 13, 1: 19, 2: 5, 3: 13, 4: 13},
    14: {0: 14, 1: 20, 2: 8, 3: 14, 4: 14},
    15: {0: 15, 1: 21, 2: 11, 3: 17, 4: 15},
    16: {0: 16, 1: 17, 2: 16, 3: 16, 4: 11},
    17: {0: 17, 1: 22, 2: 16, 3: 23, 4: 15},
    18: {0: 18, 1: 18, 2: 12, 3: 25, 4: 18},
    19: {0: 19, 1: 19, 2: 13, 3: 26, 4: 25},
    20: {0: 20, 1: 20, 2: 14, 3: 27, 4: 26},
    21: {0: 21, 1: 21, 2: 15, 3: 22, 4: 27},
    22: {0: 22, 1: 22, 2: 17, 3: 24, 4: 21},
    23: {0: 23, 1: 24, 2: 17, 3: 23, 4: 17},
    24: {0: 24, 1: 22, 2: 23, 3: 24, 4: 22},
    25: {0: 25, 1: 25, 2: 25, 3: 19, 4: 18},
    26: {0: 26, 1: 26, 2: 26, 3: 20, 4: 19},
    27: {0: 27, 1: 27, 2: 27, 3: 21, 4: 20}
}

＃ 模型
类 TBModel(nn.Module):
  def __init__(self, num_hid):
    超级().__init__()

    self.mlp_forward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                     nn.LeakyReLU(),
                                     nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.mlp_backward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                      nn.LeakyReLU(),
                                      nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.logZ = nn.Parameter(torch.ones(1))

  def 前向（自身，x）：
    P_F = self.mlp_forward(x)
    返回P_F
  
  def向后（自身，x）：
    P_B = torch.tensor([(1/INPUT_DIMS)]*INPUT_DIMS)#self.mlp_backward(x)

    返回P_B

# 奖励函数
def奖励_that_model_does_not_learn（轨迹）：
  目标轨迹 = [21, 27, 20, 14, 8]
  奖励=0
  对于范围内的 i(len(轨迹))：
    如果轨迹[i] == goal_trajectory[i]：
      奖励=奖励+1
  返回 torch.tensor(奖励)

def奖励_that_model_learns（轨迹）：
  如果轨迹 == [21, 27, 20, 14, 8]：
    返回 torch.tensor([1])
  返回 torch.tensor([0])


模型 = TBModel(512)
opt = torch.optim.Adam(model.parameters(), 3e-4)

tb_losses = []
tb_奖励 = []
logZs = []
小批量损失= 0
小批量奖励 = 0

对于 tqdm.tqdm 中的剧集（范围（NUM_EPOCHS），ncols = 40）：
  
  gflow_state = torch.zeros(TRAJECTORY_LENGTH)
  状态 = 起始节点
  总计_P_F = 0
  总P_B = 0
  轨迹=[]

  对于范围内的 t（TRAJECTORY_LENGTH）：
    轨迹.append(状态)
    P_F_s = model.forward(gflow_state)
    P_B_s = torch.tensor([(1/5)])

    猫=分类（logits=P_F_s）
    动作 = cat.sample()
    _gflow_state = gflow_state.clone()
    _gflow_state[t] = 操作
    gflow_state = _gflow_state.clone()

    new_state = 转换[状态][action.item()]
    Total_P_F += cat.log_prob(动作)
    Total_P_B += torch.log(P_B_s)

    状态 = 新状态

  奖励=reward_that_model_does_not_learn（轨迹）

  损失 = (model.logZ +total_P_F - torch.log(reward).clip(-20) -total_P_B).pow(2)
  
  minibatch_loss += 损失
  minibatch_reward += 奖励

  if (episode + 1) % BATCH_SIZE == 0:
    wandb.log({
      “损失”：minibatch_loss.item(),
      “奖励”：minibatch_reward.item()/BATCH_SIZE,
      “Z”：model.logZ.item()
    })
    minibatch_loss.backward()
    opt.step()
    opt.zero_grad()
    小批量损失= 0
    小批量奖励 = 0

这是我对 GFlowNet 的实现。我正在使用此模型引导代理通过具有 27 个节点的地图，如转换所述。 GFlowNet 对动作排列进行采样，这些动作将使代理在地图上移动。在轨迹结束时，将为代理计算奖励。该模型能够通过奖励reward_that_model_learns来学习明确的轨迹。然而，代理学习优化由 reward_that_model_does_not_learn 定义的奖励要困难得多。两者之间的唯一区别是，一个得分为全有或全无，而另一种则对轨迹给予部分评分。我不明白为什么该模型可以与一个模型斗争，但可以学习另一个模型，因为在这两种情况下，它都处理相同的状态空间（动作的排列）。如果能够从理论上理解为什么某些奖励更难学习以及如何继续前进，那就太好了，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</guid>
      <pubDate>Sat, 18 May 2024 21:22:00 GMT</pubDate>
    </item>
    <item>
      <title>建立预测模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78500710/build-a-prediction-model</link>
      <description><![CDATA[我想建立一个模型来预测游戏仍在玩时的结果。我的数据包括过去比赛的结果以及有关这些比赛状态的一些简单信息，例如每个球员的分数和位置。每分钟都会获取一次信息，直到比赛结束。我有很多游戏样本，其中每个样本都是结果+每分钟有关游戏的信息。最大分钟为 60 分钟，因此如果比赛在 60 分钟之前结束，则数据将只是初始值 0。
时间序列模型我在网上搜索到所有点都指向单个时间线，他们根据过去进行预测，但我希望我的模型根据游戏的进展（包括过去发生的事情）进行预测。
我会在比赛进行时使用我的模型，它会更新每分钟获胜的机会。因此，输入仅与某个时间点之前的先前数据相关。
我尝试使用 lstm 但它似乎效果不佳。我期望它像语言模型一样学习我的数据，尝试从过去到当前的信息预测游戏状态，但准确率不会超过 55%。我尝试调整参数，但似乎没有产生很大的差异。
我还可以使用哪些其他模型来实现此目的？或者我可以使用什么巧妙的方法？]]></description>
      <guid>https://stackoverflow.com/questions/78500710/build-a-prediction-model</guid>
      <pubDate>Sat, 18 May 2024 18:50:53 GMT</pubDate>
    </item>
    <item>
      <title>我如何为该调查计划中的这些答案选择分配数字权重？</title>
      <link>https://stackoverflow.com/questions/78500666/how-do-i-assign-numerical-weights-to-these-answer-choices-in-this-survey-program</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78500666/how-do-i-assign-numerical-weights-to-these-answer-choices-in-this-survey-program</guid>
      <pubDate>Sat, 18 May 2024 18:33:20 GMT</pubDate>
    </item>
    <item>
      <title>感知器的图像识别不起作用</title>
      <link>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</link>
      <description><![CDATA[我必须调整我的图像识别代码，以便它使用感知器来代替分类器进行图像识别。我按照讲师提供的示例执行了所有操作（并且我正在使用他们的感知器代码）。使用分类器，我的图像识别工作完美，没有出错，但是当我用感知器替换这些分类器时，无论我使用什么图像，它总是被识别为第二种类型。
我的图像识别代码：
learning_matrix = []
网络 = 感知器.PerceptronNetwork(6000, 1)
大小 = 75, 6000
Learning_matrix = np.zeros(大小, dtype=np.float32)
学习矩阵 = gabor_attributes
纪元数 = 0

对于范围（100）内的纪元：
    错误总数 = 0
    对于范围 (75) 内的 i：
        error_in_network = network.teachNetwork(learning_matrix[i],label_matrix[i])
        总错误数 += 网络中的错误数
    number_of_epochs += 1
    如果总错误数 == 0：
        休息

识别矩阵 = []
recognize_matrix = (GaborFilter(“Test.jpg”))

雷兹 = [10]
网络.giveNetworkAnswer(recognition_matrix, rez)

如果 rez[0] == 0:
    print(&quot;第一种类型&quot;)
elif rez[0] == 1:
    print(&quot;第二个管子&quot;)
elif rez[0] == 2:
    print(&quot;第三种类型&quot;)
别的：
    print(&quot;错误：&quot;+str(rez[0]))

感知器代码，由我的讲师提供：
### 单独的神经元（感知器）类###
神经元类：

    利亚姆达 = 0.001
    def __init__(this, input_nr):
        this.input_number = input_nr
        this.权重 = []

        对于范围内的 i（this.input_number）：
            this.weights.append(np.random.normal(0, 0.01))
        this.threshold = np.random.normal(0, 0.01)
        
    def 响应（此，输入信号）：
        总和 = 0
        对于范围内的 i（this.input_number）：
            sum += inputSignal[i] * this.weights[i]
        sum -= this.threshold
        如果总和 &gt; 返回 1 0 否则 0
            
    def changeWeights(this, inputSignal, targetResponse):

        实际响应 = this.response(inputSignal)
        错误 = 目标响应 - 实际响应
        
        如果错误！= 0：
            对于范围内的 i（this.input_number）：
                deltaSvoris = this.liambda * inputSignal[i] * 错误
                this.weights[i] += deltaSvoris
            this.threshold += this.liambda * 错误
        返回错误
           
########## 感知器 ANN 类 ############
类感知器网络：

    def __init__(this, 输入_nr, 输出_nr):
        this.input_number = input_nr
        this.neuronNumber = 输出编号
        this.outputLayer = []
        对于范围内的 i(this.neuronNumber)：
            神经元 = 神经元(this.input_number)
            this.outputLayer.append(神经元)

    def示教网络（这个，输入向量，输出向量）：
        错误编号输入输出 = 0
        对于范围内的 i(this.neuronNumber)：
            神经响应 = this.outputLayer[i].response(inputVector)
            如果神经元响应！= 输出向量[i]：
                错误= this.outputLayer [i] .changeWeights（inputVector，outputVector [i]）
                错误编号输入输出+=abs(错误)
        返回错误编号输入输出
    
    def GiveNetworkAnswer(this, inputVector, networkResponse):
        对于范围内的 i(this.neuronNumber)：
            networkResponse[i] = this.outputLayer[i].response(inputVector)
            打印（f“{networkResponse}”）

我尝试更改纪元数，打印出一些值以查看我使用的数据是否存在错误，但没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</guid>
      <pubDate>Sat, 18 May 2024 18:12:53 GMT</pubDate>
    </item>
    <item>
      <title>如何将数据清理纳入训练模型中</title>
      <link>https://stackoverflow.com/questions/78497891/how-to-incorporate-data-cleansing-into-trained-model</link>
      <description><![CDATA[如果我清理数据并将中值归入 NaN 值，我是否应该以某种方式将其合并到将用于测试数据的模型中？换句话说，我的测试数据是否也需要清理和估算，或者训练会解决这个问题吗？
我想说它需要被合并，因为否则 NaN 值会破坏模型，而且任何偏度都不会得到解决。
特别是：
用中位数替换 NaN：
data = data.fillna(data.median())

使用分位数变换处理偏度，使每个特征遵循正态分布（以下仅举一例）。
qualtile_transformer = QuantileTransformer(output_distribution=&#39;正常&#39;, random_state=0&#39;)
数据[&#39;feat_0&#39;] = quantile_transformer.fit_transform(数据[&#39;feat_0&#39;].values.reshape(-1,1)).flatten()

型号：
从 sklearn.linear_model 导入 LinearRegression
Linear_regr = 线性回归()
Linear_regr.fit(Xtrain,Ytrain)

预测：
# 使用测试集进行预测
Ypred = Linear_regr.predict(Xtest)

因此，最终，如果我要采用我的模型并将其用于类似但不同的数据，我如何才能确保它不会失败，并且 NaN 和分位数转换将在之前使用新数据进行处理预测已实现，所以不会失败？]]></description>
      <guid>https://stackoverflow.com/questions/78497891/how-to-incorporate-data-cleansing-into-trained-model</guid>
      <pubDate>Fri, 17 May 2024 20:47:39 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中为我的标签应用程序处理数据库锁</title>
      <link>https://stackoverflow.com/questions/78497797/handle-database-locks-in-python-for-my-labeling-app</link>
      <description><![CDATA[我希望我的应用程序的用户检索一些要标记的数据。在第一个版本中，我没有实现锁定，因此多个用户可以同时访问相同的数据，因此第二个版本会覆盖第一个版本的标签。
我正在使用 python fastAPI sqlite 后端。
我最初想出了为标签添加“is-being-labeled”值的想法，以便下一个提议的数据不一样。我不喜欢它，因为我不知道如何处理用户在没有标记数据的情况下退出应用程序（或其他应用程序）的情况。目前，我最好的方法是添加一个包含检索时间时间戳的列，并实现一个逻辑，假设检索后 30 秒，我们检查标签是否不再是 None。如果它仍然是 None （意味着该人没有标记），我们删除时间戳的值。我也不完全高兴，因为它不能处理人们冥想然后回来标记数据的情况。
你有更好的建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78497797/handle-database-locks-in-python-for-my-labeling-app</guid>
      <pubDate>Fri, 17 May 2024 20:19:31 GMT</pubDate>
    </item>
    <item>
      <title>我用自己的数据集训练yolo模型但没有测试结果</title>
      <link>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</link>
      <description><![CDATA[我正在使用 Yolov3 模型和从 Kaggle 收到的数据集来训练模型。模型训练已完成，我将新权重添加到备份文件夹。我运行我训练过的水果之一进行测试，但没有发生物体检测。相同的图像显示为 Prediction.jpg。训练似乎不错，但我不明白为什么它无法检测物体。请帮助我。
训练终端代码：
./darknet detector train /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/Desktop/Projects/Bitirmeprojesi/yolov3.weights

测试终端代码：
./darknet detector test /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/darknet/backup/yolov3_final.weights -thresh 0.25 -out predictions.jpg

我设置并编辑了 obj.data 和 obj.names 和yolov3.cfg 文件。
我有 3 个类：苹果、香蕉和橙子。我已经根据3个classes在cfg文件中正确设置了filter、class值等值。
cfg文件 
[net]
# Testing
batch=64
subdivisions=1
# Training
subdivisions=16
width= 608
height=608
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=0.3

learning_rate=0.001
burn_in=1000
max_batches = 6000 # classnum * 2000
policy=steps
steps=3600,4800 # max_batches num %80, %90 
scales=.1,.1

数据集中除了.jpg图片，还有yolo 格式的同名 .txt 文件。
在此处输入图像描述 文件图像
包含所有图像路径的 train.txt 和 test.txt 文件也已准备就绪。
当我在终端中运行测试命令时，它可以工作，但图片看起来一样，没有检测对象的边界框。我确定我已经安装了 Opencv。我正在使用 macOS。为什么它没有检测到它？请有人帮忙。我多次通过 make clean 清理了暗网，并通过 make opencv = 1 运行它，但结果没有改变。
[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00
总 BFLOPS 137.613 
avg_outputs = 1052318 
从 /Users/melisabagcivan/darknet/backup/yolov3_final.weights... 加载权重
查看 64，训练：32013 K-images (500 Kilo-batches_64) 
完成！从权重文件加载了 107 个层 
输入图像路径：/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg
检测层：82 - 类型 = 28 
检测层：94 - 类型 = 28 
检测层：106 - 类型 = 28 
/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg：预测时间为 6738.129000 毫秒。

我尝试使用了许多图像，但它没有在任何图像中绘制方框。我不明白它是否无法检测到它，或者我在测试时是否犯了错误。]]></description>
      <guid>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</guid>
      <pubDate>Fri, 17 May 2024 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用决策树算法和bert模型对文本进行分类？</title>
      <link>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-model-to-classify-a-text</link>
      <description><![CDATA[我想集成并使用 BERT 和决策树两种算法进行文本分类，因此我需要该领域的指导和帮助。
如果有人有这个领域的源代码或文章，请提供给我。或者即使朋友有更好的建议将 BERT 算法与任何其他算法结合起来]]></description>
      <guid>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-model-to-classify-a-text</guid>
      <pubDate>Fri, 17 May 2024 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在流模式下分割拥抱脸部数据集而不将其加载到内存中？</title>
      <link>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</link>
      <description><![CDATA[我正在使用 Hugging Face 数据集，我需要将数据集拆分为训练集和验证集。我的主要要求是数据集应该以流模式处理，因为我不想将整个数据集加载到内存中。
从数据集导入load_dataset，DatasetDict

# 从 Hugging Face 加载数据集
数据集 = load_dataset(&#39;小队&#39;, split=&#39;训练&#39;)

# 将数据集分为训练集和验证集
# 指定测试集（验证集）的分数
train_val_split = dataset.train_test_split(test_size=0.1)

# 提取训练和验证数据集
train_dataset = train_val_split[&#39;train&#39;]
val_dataset = train_val_split[&#39;测试&#39;]

# 打印数据集的大小
print(f&quot;训练集大小: {len(train_dataset)}&quot;)
print(f&quot;验证集大小: {len(val_dataset)}&quot;)

# 如果需要的话保存数据集
# train_dataset.save_to_disk(&#39;路径/到/train_dataset&#39;)
# val_dataset.save_to_disk(&#39;路径/到/val_dataset&#39;)

是否有一种方法可以在流模式下分割 Hugging Face 数据集？
参考文献：

https ://discuss.huggingface.co/t/how-to-split-a-dataset-into-train-test-and-validation/1238
https://discuss.huggingface.co/t/how-to-split-main-dataset-into-train-dev-test-as-datasetdict/1090/21
https://discuss.huggingface .co/t/possible-to-stream-and-create-new-splits/67214
https://huggingface.co/docs/datasets/v1.11.0 /splits.html
https://discuss.huggingface.co/t/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-memory /87205
]]></description>
      <guid>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</guid>
      <pubDate>Fri, 17 May 2024 17:18:18 GMT</pubDate>
    </item>
    <item>
      <title>学习率不更新</title>
      <link>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</link>
      <description><![CDATA[def make_prediction(x0,t0):
输入 = torch.vstack([x0,t0])
layer_1 = torch.matmul(w0,inputs)
返回 layer_1

loss1 = nn.MSELoss()
def loss_function():
u_t=(make_prediction(x,t+inf_s)-make_prediction(x,t))/inf_s
u_x=(make_prediction(x+inf_s,t)-make_prediction(x,t))/inf_s
u_xx=(make_prediction(x+inf_s,t)-2*make_prediction(x,t)+make_prediction(x-inf_s,t))/inf_s**2
返回 (1/N_i)*(loss1(make_prediction(x0IC,t0IC), u0IC))+(1/N_b)*(loss1(make_prediction(x0BC1,t0BC1), u0BC1))
+(1/N_b)*(loss1(make_prediction(x0BC2,t0BC2), u0BC2))+(1/N_f)*(np.pi/0.01)*(loss1(u_xx-u_t-make_prediction(x,t)*u_x, 0))

def train_step(w,b, learning_rate):
trainable_variables = [w,b]
optimizer = torch.optim.SGD(trainable_variables, lr=learning_rate,momentum=0.9)
scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01)
loss = loss_function()
loss.backward()
with torch.no_grad():
w -= learning_rate * w.grad
b -= learning_rate * b.grad
w.grad.zero_()
b.grad.zero_()
optimizer.step()
scheduler.step()
train_step(w,bias,learning_rate)

我运行此代码（通过scheduler.ExponentialLR），但学习率没有变化。
您认为问题出在哪里？
我写了完整的代码...感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</guid>
      <pubDate>Fri, 17 May 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>我的逻辑回归模型有问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistic-regression-model</link>
      <description><![CDATA[我的模型精度很差。此数据取自 https://archive.ics.uci .edu/dataset/15/breast+cancer+wisconsin+original 显示逻辑回归模型的准确度为 96%，所以问题确实出在我的模型中。我建立了以下模型：
# 导入数据集
tumor_study &lt;- read.csv(“breast-cancer-wisconsin.data”, header = FALSE, na.strings = “NA”)

# 添加列名
特征&lt;-c(“id_number”，“ClumpThickness”，“Uniformity_CellSize”，
              “Uniformity_CellShape”、“边缘粘附”、
              “SingleEpithelial_CellSize”、“BareNuclei”、“Bland_Chromatin”、
              “Normal_Nucleoli”、“Mitoses”、“Class”）

colnames(tumor_study) &lt;- 特征

# 清洗数据
# 删除第一列（id_number）
肿瘤研究 &lt;- 肿瘤研究[,-1]

# 转换“?” BareNuclei 列中为 NA，然后为数字
tumor_study$BareNuclei[tumor_study$BareNuclei == &quot;?&quot;] &lt;- NA
tumor_study$BareNuclei &lt;- as.numeric(tumor_study$BareNuclei)

# 删除 BareNuclei 中缺失值的行
tumor_study &lt;-tumor_study[!is.na(tumor_study$BareNuclei),]

# 将类转换为因子
tumor_study$Class &lt;- 因子(tumor_study$Class, level = c(2, 4), labels = c(“良性”, “恶性”))

# 将数据集分为训练集和测试集
库（caTools）
设置.种子(123)
split &lt;-sample.split(tumor_study$Class, SplitRatio = 0.8)
Training_set &lt;-tumor_study[split == TRUE,]
test_set &lt;-tumor_study[split == FALSE,]

# 应用特征缩放
训练集[, 1:9] &lt;- 比例(训练集[, 1:9])
test_set[, 1:9] &lt;- 比例(test_set[, 1:9])

# 构建逻辑回归模型
分类器 &lt;- glm(公式 = Class ~ ., family = 二项式, data = Training_set)

# 预测训练集的概率
prob_y_train &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = Training_set[,-10]）
Predicted_y_training &lt;- ifelse(prob_y_train &gt;= 0.5,“良性”,“恶性”)

# 使用 test_set 进行预测
prob_y_test &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = test_set[,-10]）
Predicted_y_test &lt;- ifelse(prob_y_test &gt;= 0.5,“良性”,“恶性”)

# 使用混淆矩阵检查准确性
cm_test &lt;- 表(test_set[,10], Predicted_y_test)
打印（厘米_测试）

但我的准确率接近 2%。
如何找出模型中的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistic-regression-model</guid>
      <pubDate>Fri, 17 May 2024 06:43:30 GMT</pubDate>
    </item>
    <item>
      <title>反馈管理器需要具有单一签名推断的模型</title>
      <link>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</link>
      <description><![CDATA[我在尝试运行机器运行模型时遇到了此错误，该模型应该为驾驶员睡意检测项目提供动力
&lt;前&gt;&lt;代码&gt;W0000 00:00:1715924294.765512 2256 inference_feedback_manager.cc:114]
反馈管理器需要具有单一签名推断的模型。
禁用对反馈张量的支持。

模型架构如下：
&lt;前&gt;&lt;代码&gt;#**型号**
从 keras.layers 导入 BatchNormalization
模型 = tf.keras.models.Sequential()
# 输入形状是所需的图像大小 145 x 145，颜色为 3 字节

#这是第一个卷积
   model.add(Conv2D(16, 3, 激活=&#39;relu&#39;, input_shape=X_train.shape[1:]))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第二次卷积
   model.add(Conv2D(32, 5, 激活=&#39;relu&#39;))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第三次卷积
  model.add(Conv2D(64, 10, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())
  model.add(MaxPooling2D())
  tf.keras.layers.Dropout(0.3)

# 第四次卷积
  model.add(Conv2D(128, 12, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())

# 将结果压平以输入 DNN
  模型.add(压平())
  model.add（密集（128，激活=&#39;relu&#39;））
  模型.add(Dropout(0.25))
  model.add（密集（64，激活=&#39;relu&#39;））
# 只有 1 个输出神经元。
  model.add（密集（1，激活=&#39;sigmoid&#39;））

  model.compile(loss=“binary_crossentropy”，metrics=[“accuracy”]，optimizer=Adam(lr=0.001))
  历史= model.fit（train_generator，epochs = 10，batch_size = 32，validation_data = test_generator）

# 定义服务签名
  输入签名 = [
      tf.TensorSpec(shape=[None, 145, 145, 3], dtype=tf.float32, name=&#39;input_tensor&#39;)
  ]

@tf.function(input_signature=input_signature)
defserving_fn（输入）：
    返回模型（输入）

export_dir = &#39;E:\系统项目\项目&#39;
tf.saved_model.save（serving_fn，export_dir）

# 加载模型进行推理
load_model = tf.saved_model.load(&#39;my_model.keras&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</guid>
      <pubDate>Fri, 17 May 2024 05:59:50 GMT</pubDate>
    </item>
    <item>
      <title>为职位推荐系统选择正确的集成方法</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发机器学习职位推荐系统，并且正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，例如职位、职位描述、工资、地点和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用结合多种模型和技术的混合方法来提高其性能：
协作过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络用于处理复杂的数据类型，例如职位描述中的文本。
决策树或随机森林具有可解释性以及处理数字和分类数据混合的能力。
我正在寻找关于哪种集成方法最适合此任务的建议。我希望模型能够很好地过滤、灵活地处理数据类型、在训练和时间上具有良好的性能，并提供可解释性。
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    </channel>
</rss>