<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 25 May 2024 09:14:18 GMT</lastBuildDate>
    <item>
      <title>如何在缺失值的情况下训练模型并使用预测函数</title>
      <link>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</link>
      <description><![CDATA[我正在开发一个 ML 项目，我正在尝试训练一些分类模型，然后对测试 df 进行一些预测。
如何训练一个能够使用每个可用观察值的模型，无论它是否有缺失值？我如何做出预测？
我的 df 的大多数观察结果至少有一个缺失值。
为了训练我的模型，我使用了 caret 库。
例如，给定此模型：
control &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
unegrid &lt;- Expand.grid(.mtry=c(1:6))
rf &lt;- train(Target~.，data=train，method=“rf”，metric=“ROC”，tuneGrid=tunegrid，ntree=100，trControl=control)

然后我这样做出预测：
test$pred&lt;-predict(rf,test,&#39;prob&#39;)[,2]

在训练时，我已经尝试过这个 na.action 选项：

na.omit;

-na.exclude;

na.pass。

前两个工作正常，但如果我使用 na.pass 我会收到此错误：
出了点问题；所有 ROC 指标值均丢失：
      ROC Sens 规格    
 分钟。   ：NA 最小值。   ：NA 最小值。   : 不适用  
 第一季度：不适用 第一季度：不适用 第一季度：不适用  
 中位数 : NA 中位数 : NA 中位数 : NA  
 平均值：NaN 平均值：NaN 平均值：NaN  
 第三季度：不适用 第三季度：不适用 第三季度：不适用  
 最大限度。   ：不适用 最大。   ：不适用 最大。   : 不适用  
 不适用 :6 不适用 :6 不适用 :6    
错误：停止
警告()
1：Fold01 的模型拟合失败：mtry=1 randomForest.default(x, y, mtry = param$mtry, ...) 中的错误： 
  预测变量中不允许使用 NA

如果我使用前两个之一，当我进行预测时，我会得到与此类似的错误：
set(x, j = name, value = value) 中的错误： 
  已提供 199 件物品，分配给 5425 件物品

]]></description>
      <guid>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</guid>
      <pubDate>Sat, 25 May 2024 08:52:03 GMT</pubDate>
    </item>
    <item>
      <title>通过 Python 脚本使用模型</title>
      <link>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</link>
      <description><![CDATA[首先，我对机器学习很菜鸟，我可能无法理解复杂的建议和答案，但这是针对我的大学的，我没有时间学习基础知识。
我正在尝试使用我通过 GTZAN 数据集创建的模型 - 音乐流派分类 (https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)
模型具有很高的准确性，但我没有得到令人满意的输出，我不知道需要多少信息，但我觉得我在使用模型的脚本中犯了一个错误。这是脚本。
导入tensorflow为tf
导入库
将 numpy 导入为 np

# 加载预训练模型
模型 = tf.keras.models.load_model(&#39;C:/Users/VOLKAN/Desktop/SonProject/model.keras&#39;)

# 定义流派（假设您有模型预测的固定流派列表）
types = [&#39;Blues&#39;, &#39;Classical&#39;, &#39;Country&#39;, &#39;Disco&#39;, &#39;Hip-hop&#39;, &#39;Jazz&#39;, &#39;Metal&#39;, &#39;Pop&#39;, &#39;Reggae&#39;, &#39;Rock&#39;] # 替换为实际流派名字

def extract_features(文件路径):
    y，sr = librosa.load（文件路径，持续时间= 30）
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=58)
    mfccs = np.mean(mfccs.T, 轴=0)
    特征 = mfccs[np.newaxis, ...]
    返回特征



def Predict_genre(文件路径):
    特征 = extract_features(文件路径)
    预测 = model.predict(features)
    Genre_index = np.argmax(预测，轴=1)[0]
    返回类型[genre_index]

# 用法示例
audio_file = &#39;C:/Users/VOLKAN/Desktop/Data/genres_original/classical/classical.00059.wav&#39; # 替换为您的音频文件路径
预测流派 = 预测流派（音频文件）
print(f&#39;预测的类型是：{predicted_genre}&#39;)


`
在模型中我使用了 cnn。模型具有 .keras 扩展名。]]></description>
      <guid>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</guid>
      <pubDate>Sat, 25 May 2024 08:21:11 GMT</pubDate>
    </item>
    <item>
      <title>基于 Python 的模型学习，通过使用 TF、Keras 和 NLTK 进行标记化的意图</title>
      <link>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</link>
      <description><![CDATA[我使用 Tensorflow、keras 和 nltk 进行标记化，用 Python 开发了一个聊天机器人模型。当我在 vs 终端中运行它时，它会显示时间戳和模型提供答案所需的时间，但我试图在使用 React 设计的网站中显示它。如何从输出中删除日志。我已经尝试了一切，包括抑制日志，除非它们很关键，但我仍然无法删除它们。
我尝试使用这个，但它不起作用，它仍然显示它们。我知道日志不是警告，因此它们可能不会因此被删除。
导入 os os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;3&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</guid>
      <pubDate>Sat, 25 May 2024 08:01:27 GMT</pubDate>
    </item>
    <item>
      <title>MODIS图像增强优化模型</title>
      <link>https://stackoverflow.com/questions/78531465/image-enhancement-optimum-model-for-modis</link>
      <description><![CDATA[我正在尝试将超分辨率模型应用于 MODIS 500m 图像，以便将其分辨率缩小到 Sentinel-2 的 60m 光谱带。
我知道这是一项非常具有挑战性的任务，因为我的数据集仅包含 20000 张图像，而且到目前为止我还没有在文献中发现类似的内容。
我尝试过实现多种架构，从简单的 CNN 到更复杂的 SRGAN，但我的结果与预期输出相去甚远。您有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78531465/image-enhancement-optimum-model-for-modis</guid>
      <pubDate>Sat, 25 May 2024 05:21:54 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有得到适当的训练，mu 和 std 很快收敛到奇怪的值</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-mu-and-std-co</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-mu-and-std-co</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>在 CNN 推理中跳过零乘法</title>
      <link>https://stackoverflow.com/questions/78531437/skipping-zero-multiplications-in-cnn-inference</link>
      <description><![CDATA[我在 MNIST 上有一个预训练的 CNN 模型，每次都会加载经过训练的权重和偏差来运行推理。有什么方法可以仅在推理阶段跳过 conv 和 fc 层中的零操作（我不想重新训练它，因此它不需要反向传播）？
由于 MNIST 图像很稀疏，因此我预计跳过零操作时的执行时间会少得多。工作的最优性对我来说并不是那么重要，我只是想看看输入的不同零率下执行时间有多少差异。
我尝试了一些用于 sprase 卷积的存储库，但他们正在考虑您在之后重新训练模型。我期望在 Pytorch 代码中找到一个简单的更改，只跳过零操作。还尝试找到一种方法来更改 Pytorch 的 C++ 代码库，但我无法弄清楚。]]></description>
      <guid>https://stackoverflow.com/questions/78531437/skipping-zero-multiplications-in-cnn-inference</guid>
      <pubDate>Sat, 25 May 2024 05:06:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 xgboost 推断 csv 数据时出现问题</title>
      <link>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</link>
      <description><![CDATA[我在使用 xgboost 进行推断时遇到问题。我是xgboost的新手，所以可能犯了一些低级错误，希望得到帮助，谢谢！
简单来说，我想使用 xgboost 执行回归任务，由多个 csv 数据集组成。我将它们拼接成一个数据帧，并使用 train_test_split 分割训练/验证/测试。该模型运行良好（mae：0.6）。但是当我手动拆分训练集和测试集（我挑选了一部分 csv 并将其放入测试文件夹中）时，结果变得非常差（mae：12+）。
我真的很想知道这里发生了什么？我已经发布了下面的一些代码。
1：这是带有train_test_split的分割代码：
# 准备好数据
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 合并数据集
[merged_dataset = pd.concat([pd.DataFrame(dataset.X) 用于数据集中的数据集])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)

# 除法
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.2，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

# 构建xgboost模型
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_test_original, y_test_pred)]

2：这是我在代码后的手动划分：
`# 训练数据集
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 测试数据，这是我从原始数据中手动分区的测试集的 csv
测试=[]
test_file = &#39;../data/test_xgboost/Thermal014withMidPos.csv&#39;
测试 = ThermalDataset(test_file)
测试.追加（测试）

＃ 结合
merged_dataset = pd.concat([数据集中的数据集的pd.DataFrame(dataset.X)])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
test_x = pd.concat([pd.DataFrame(test.X) 用于测试中的测试])
test_y = pd.concat([pd.DataFrame(test.y) 用于测试中的测试])

# 标准化
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)
x_fill = 缩放器.fit_transform(test_x)
y_fill = 缩放器.fit_transform(test_y)

＃ 分裂
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.05，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

＃ 火车
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred_scaled = model.predict(X_val)
y_test_pred_scaled = model.predict(X_test)
y_fill_res = model.predict(x_fill)

# inverse_transform 获取原始数据
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_pre = scaler.inverse_transform(y_fill_res.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
y_fill = scaler.inverse_transform(y_fill.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_pre, y_fill)`

我希望能够对单个 csv 文件进行正确推理，并获得与训练中一样好的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</guid>
      <pubDate>Sat, 25 May 2024 02:40:08 GMT</pubDate>
    </item>
    <item>
      <title>时间序列相关回归中的数据泄漏</title>
      <link>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</link>
      <description><![CDATA[我有一个包含解释变量值和目标变量的数据集。它们都是不同的历史日常值。 X 是不同的经济指标，Y 是债券收益率的前瞻性变化。因此，对于第 N 天，X 是当前失业率和通货膨胀率，Y 是 (yield_n+3 / Yield_n) - 1，这是 3 天的变化。
我的问题是，如果我稍后使用 sklearn 中的 train_test_split，我可以打开 shuffle = True 吗？
我知道对于典型的时间序列回归，这将导致数据泄漏，但在这里我不使用 Y 的过去值，也不使用任何滞后。
理论上，我想对数据进行洗牌，因为从我所看到的来看，X 和 Y 之间的关系会随着时间的推移而变化，所以如果我仅根据较早和较晚的日期分割数据，我担心我会训练模型稍微过时的值。
顺便说一句，我使用梯度提升作为我的模型
那么，我可以在我的情况下使用 shuffle = True 吗？如果是，哪些附加功能可能导致泄漏：滞后、季节性影响或其他因素？]]></description>
      <guid>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</guid>
      <pubDate>Thu, 23 May 2024 20:43:46 GMT</pubDate>
    </item>
    <item>
      <title>Mediapipe 培训数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</link>
      <description><![CDATA[我正在尝试向媒体管道框架提供尽可能多的图片，但我发现从各个角度制作人物图片以从人们那里获取数据非常累人。
我还没有尝试媒体管道的视频训练，因为我讨厌它剪切视频。
举个例子，我想训练演习小队，所以我需要三个州来组建一个小队

站立
小队下线
小分队

对于每一个状态，我都需要大量的训练数据来喂养人工智能，否则它不会计算我的运动。
从动作中获取尽可能多的图片而不浪费太多时间的最佳方法是什么？
制作手动图片，但我意识到这会花费多少时间。]]></description>
      <guid>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</guid>
      <pubDate>Thu, 23 May 2024 19:45:15 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
from sklearn.preprocessing import StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>在 VS Code 上使用计算机视觉 + yolov8 应用程序进行实时网络摄像头数据分类</title>
      <link>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</guid>
      <pubDate>Thu, 23 May 2024 15:57:14 GMT</pubDate>
    </item>
    <item>
      <title>寻找特定于移动设备的二进制文件的数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</link>
      <description><![CDATA[我目前正在训练机器学习模型，并需要特定于移动设备的二进制文件的数据集。尽管我付出了努力，但我仍然无法找到大量的数据集。
向我建议的另一种选择是从 AOSP 批量下载二进制文件，但我不确定如何开始此过程。]]></description>
      <guid>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</guid>
      <pubDate>Thu, 23 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 SHAP 解释学习到的潜在空间位置</title>
      <link>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</link>
      <description><![CDATA[我在 MNIST 数据集上的 pytorch 中实现了一个监督自动编码器。
我在潜在空间（大小 8）上使用分类层对其进行监督。在训练期间，我优化了 MSE 重建损失和分类损失 (BCE)。我在潜在空间中有单个实例，这些实例很有趣，我想找到它们不同位置的解释。
所以我的问题是，在潜在维度上使用 SHAP 值是否是一种有效的方法（它有效，我得到了值，但我不确定这是否有意义）。
更具体地说：我想比较例如实例 A 和实例 B。假设在潜在空间中它们相距很远，例如在潜在维度 3 of 8 中。现在我想找到输入中可以解释这种现象的像素。因此，我计算实例 A 和 B 的潜在表示的 SHAP 值，并比较两者的维度 3 的 SHAP 值。这是有效的吗？我认为它与解释多输出回归没有太大不同，对吧？但我还没有看到任何 SHAP 的应用来解释潜在位置。]]></description>
      <guid>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</guid>
      <pubDate>Wed, 22 May 2024 12:17:33 GMT</pubDate>
    </item>
    <item>
      <title>每个时期 Retinanet 模型内的数据流</title>
      <link>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</link>
      <description><![CDATA[通过提供batch_size、epochs和每个epoch的步骤，向retinanet model_network提供了多少数据？
到目前为止，我认为步长的计算如下：
step_size = (total_number_of_data/batch_size)*epochs

而在keras-retinanet中，它以batch_size、epochs和steps_per_epoch作为参数，这与上述情况不同。我怀疑计算是如何进行的。]]></description>
      <guid>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</guid>
      <pubDate>Wed, 22 May 2024 09:04:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的分段似乎没有保存？关于totalsegmentator</title>
      <link>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</link>
      <description><![CDATA[我一步步按照您的教程进行操作，但得到的结果类似于分段未保存。
这是我输入的语句和得到的结果：
(d:\totalsegmentotar.conda) D:\totalsegmentotar&gt;TotalSegmentator -i hip_left.nii.gz -o 分段 -ta hip_implant

如果您使用此工具，请引用：https://pubs.rsna.org/doi/10.1148/ryai.230024

未检测到 GPU。在CPU上运行。这可能会非常慢。 &#39;--fast&#39; 或 --roi_subset 选项可以帮助减少运行时间。
生成粗糙的身体分割...
重新采样...
1.93 秒内重新采样
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ ██| 1/1 [00:00&lt;00:00, 1.12it/s]
预测12.95秒后
重新采样...
警告：无法裁剪，因为未检测到前景
从 (333, 333, 539) 裁剪到 (333, 333, 539)
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ | 64/64 [04:27&lt;00:00, 4.18s/it]
预测 288.96 秒
保存分段...
0%| | 0/1 [00:00
可以看到分割没有保存，我用切片器软件看确实没有预测结果，什么也没有显示。
当我使用`-tatotal时，分割器进度条发生变化，但不幸的是它似乎没有保存分割的结果。这是我的输出，以及在切片器 5.6.2 中打开的输出文件夹和图像，但没有显示任何内容。
这是我的 powershell 输出
这是我的输出文件夹和在切片器 5.6.2 中打开的图像]]></description>
      <guid>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</guid>
      <pubDate>Wed, 22 May 2024 07:52:18 GMT</pubDate>
    </item>
    </channel>
</rss>