<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 04 Jun 2024 15:15:45 GMT</lastBuildDate>
    <item>
      <title>我的深度学习流程出了什么问题</title>
      <link>https://stackoverflow.com/questions/78576231/what-is-wrong-with-my-deep-learning-pipeline</link>
      <description><![CDATA[希望你们都一切顺利。我正在开发一个深度学习管道，例如分割任务。我的数据集非常复杂，因为我最近才开始使用 pytorch 和深度学习。
我目前正在努力解决与我的数据形状相关的错误，特别是与掩码或 pc 形状相关的错误。我已经建立了一个由 VIT 组成的模型 -&gt; 用于 2D 图像和掩码和稀疏注意力 -&gt; 3D bbox3d，pc。
我的代码与形状相关：
 image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        mask = np.load(mask_path).astype(np.uint8)
        mask = np.transpose(mask, (1, 2, 0)).astype(np.uint8)
        
        bbox3d = np.load(bbox3d_path)
        pc = np.load(pc_path)

        if self.transforms:
            augment = self.transforms(
               图像=图像， 
                  mask=mask
            )
            
          图像 = augment[&#39;image&#39;]
            mask = augment[&#39;mask&#39;]

        图像 = image.permute(0, 1, 2)
        mask = mask.permute(2, 0, 1)
        
        bbox3d = torch.as_tensor(bbox3d, dtype=torch.float32).permute(0, 2, 1)
        pc = torch.as_tensor(pc, dtype=torch.float32).permute(0, 2, 1)

然后加载我的数据集：
dataset = Dataset(data_dir, transforms=transforms)

    print(&quot;数据集预处理 -&gt;&gt;&gt; &quot;)    
    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collat​​e_fn=collat​​e_fn, num_workers=2)

经历训练循环：
for batch_idx, target in enumerate(data_loader):

        print(&quot;模型输出执行 -&gt;&gt;&gt; &quot;)
        images = [target[&#39;image&#39;] for target in target]
        mask = [target[&#39;mask&#39;] for target in target]
        bbox3ds = [target[&#39;bbox3d&#39;] for target in target]
        pcs = [target[&#39;pc&#39;] for target in target]

        mask_array = np.stack(masks)
        mask_array = mask_array.reshape((3, 254, 254))
        mask = mask_array.tolist()

        images = torch.stack(images).to(device)
        mask = torch.stack(masks).to(device)
        bbox3ds = torch.stack(bbox3ds).to(device)
        pcs = torch.stack(pcs).to(device)

        print(&quot;::: 模型入口点 :::&quot;)

        输出 = 模型(图像, 掩码, pcs, bbox3ds)

在模型前向函数中结束：
    def forward(self, img, mask, pc, bbox3d):

        print(&quot;::: 在前向函数内部 ::::&quot;)

        # 2D 图像特征
        img_features = self.vit(img).last_hidden_​​state[:, 0, :]
        print(f&quot;img_features shape: {img_features.shape}&quot;)

        # 2D 蒙版特征
        mask_features = self.vit(mask).last_hidden_​​state[:, 0, :]
        print(f&quot;mask_features shape: {mask_features.shape}&quot;)

我不断收到与蒙版形状相关的错误：
masks_array = mask_array.reshape((3, 254, 254)) 
ValueError: 无法将大小为 8258048 的数组重塑为形状 (3,254,254)

如果你们能提供任何帮助，我将不胜感激。提前感谢你们的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78576231/what-is-wrong-with-my-deep-learning-pipeline</guid>
      <pubDate>Tue, 04 Jun 2024 15:01:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么会出现此错误？“TransformerMixin.fit_transform() 缺少 1 个必需的位置参数：‘X’”</title>
      <link>https://stackoverflow.com/questions/78575884/why-is-this-error-coming-up-transformermixin-fit-transform-missing-1-require</link>
      <description><![CDATA[我有这行代码
cols_to_scale = [&#39;tenure&#39;,&#39;MonthlyCharges&#39;,&#39;TotalCharges&#39;]

来自 sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler

df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

这会引发此错误，为什么？
TypeError Traceback (most recent call last)
Cell In[77], line 6
3 来自 sklearn.preprocessing import MinMaxScaler
4 scaler = MinMaxScaler
----&gt; 6 df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

TypeError: TransformerMixin.fit_transform() 缺少 1 个必需的位置参数：“X”

不知道为什么会发生此错误。]]></description>
      <guid>https://stackoverflow.com/questions/78575884/why-is-this-error-coming-up-transformermixin-fit-transform-missing-1-require</guid>
      <pubDate>Tue, 04 Jun 2024 13:58:35 GMT</pubDate>
    </item>
    <item>
      <title>无论如何在 tensorflow 2.16 上使用 tensorflow 的 set_session</title>
      <link>https://stackoverflow.com/questions/78575816/anyway-to-use-tensorflows-set-session-on-tensorflow-2-16</link>
      <description><![CDATA[我完全不知道该如何为项目导入这个 set_session。我尝试过使用：
from tensorflow.compat.v1.keras.backend import set_session

and
from tensorflow.keras.backend import set_session`

（以及许多其他变体）
一切都没希望了吗？我使用的是 python 3.11.1、tensorflow 2.16.1（安装 keras 3.3.3）

我希望让这个程序尽可能容易运行，但似乎唯一的方法可能是安装旧版本的 tensorflow（使用 pip 无法做到这一点）
set_session 应该可以工作，我已经让它在旧版本的 tensorflow 上运行，我只是希望它能够友好地下载我的程序，而不需要经历这种挣扎。我也用过这个：
def get_session(gpu_fraction): #为 TensorFlow 设置 GPU 内存使用量
config = tf.compat.v1.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction
return tf.compat.v1.Session(config=config)
]]></description>
      <guid>https://stackoverflow.com/questions/78575816/anyway-to-use-tensorflows-set-session-on-tensorflow-2-16</guid>
      <pubDate>Tue, 04 Jun 2024 13:45:55 GMT</pubDate>
    </item>
    <item>
      <title>将图像从灰度转换为 RGB 混乱</title>
      <link>https://stackoverflow.com/questions/78575740/converting-images-from-grayscale-to-rgb-confusion</link>
      <description><![CDATA[当我查看已通过代码读取“转换为灰度”的图像时，它会显示为 RGB。
但是当我单击目录中的图像文件时，它会显示为灰度，这很令人困惑，有人可以帮忙吗？
`import os
import cv2
def convert_images_to_grayscale(input_dir, output_dir):
&quot;&quot;&quot;
将输入目录中的所有图像转换为灰度并将它们保存在输出目录中。
Args:
input_dir (str): 包含输入图像的目录的路径。
output_dir (str): 保存灰度图像的目录的路径。
&quot;&quot;&quot;
# 如果不存在则创建输出目录
if not os.path.exists(output_dir):
os.makedirs(output_dir)

# 列出输入目录中的所有文件
files = os.listdir(input_dir)

# 遍历每个文件
for file in files:
# 检查文件是否为图像（如果需要，可以添加更多图像扩展名）
if file.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.gif&#39;, &#39;.tif&#39;, &#39;.tiff&#39;)):
# 读取图像
img_path = os.path.join(input_dir, file)
img = cv2.imread(img_path)

# 将图像转换为灰度
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 保存灰度图像
output_path = os.path.join(output_dir, file)
cv2.imwrite(output_path, gray_img)
print(f&quot;将 {file} 转换为灰度并保存为 {output_path}&quot;)`

# 示例用法：#input_directory = &#39;/path/to/input/directory&#39; #output_directory = &#39;/path/to/output/directory&#39; #convert_images_to_grayscale(input_directory, output_directory)
convert_images_to_grayscale(&#39;OCT/kermany2018/oct2017/OCT2017/test/DRUSEN&#39;, &#39;OCT/greytest/greydrusen&#39;)
当我在目录中查看这些图像时（在 jupyter 环境中双击文件），它会显示灰度，当我读取图像时以下内容：
img = mpimg.imread(&#39;OCT/greytest/greydrusen/DRUSEN-1193659-1.jpeg&#39;) imgplot = plt.imshow(img) plt.show()
它显示为 rgb]]></description>
      <guid>https://stackoverflow.com/questions/78575740/converting-images-from-grayscale-to-rgb-confusion</guid>
      <pubDate>Tue, 04 Jun 2024 13:31:27 GMT</pubDate>
    </item>
    <item>
      <title>无需独热编码即可实现标签平滑</title>
      <link>https://stackoverflow.com/questions/78575618/label-smoothing-without-having-to-one-hot-encode</link>
      <description><![CDATA[我想在我的 NMT 任务中使用标签平滑正则化。按照建议，其完成方式如下
loss_object = CategoricalCrossentropy(from_logits=True, reduction=&#39;none&#39;)

def masked_loss_function(y_true, pred, smoothing_factor=0.1):
mask = tf.logical_not(tf.equal(y_true, fa_tokenizer.pad_token_id))
y_hot = (1 - smoothing_factor) * tf.one_hot(y_true,depth=VOCAB_TARG_SIZE) + (smoothing_factor / VOCAB_TARG_SIZE)
loss = loss_object(y_hot, pred)
mask = tf.cast(mask, loss.dtype)
loss *= mask
return tf.reduce_sum(loss) / tf.reduce_sum(mask)

the问题是我使用的是配备 6GB RAM 的 RTX 2060 笔记本，并且对爆炸形状为 [64, 30, 25000] 的向量进行 one_hot 编码非常昂贵（我使用的是 float32）。
我正在寻找一种替代方法来稀疏地进行这些计算。有人能帮我吗？
我尝试从 y_true 中选择 y_pred 进行携带
chosen = 从 y_pred 中选择正索引
$
-\sum_i (1-smoothing_factor) \times log(chosen) + (\frac{smoothing_factor}{num_classes} log(all))
$]]></description>
      <guid>https://stackoverflow.com/questions/78575618/label-smoothing-without-having-to-one-hot-encode</guid>
      <pubDate>Tue, 04 Jun 2024 13:13:02 GMT</pubDate>
    </item>
    <item>
      <title>尝试实现一个函数来可视化决策边界，但我得到了 ValueError: 'red' 不是有效的颜色值</title>
      <link>https://stackoverflow.com/questions/78575616/trying-to-implement-a-function-to-visualize-the-decision-boundaries-and-i-get-va</link>
      <description><![CDATA[我试图在 Iris 数据集中使用感知器并实现一个函数来可视化决策边界，但我得到了这个：

ValueError：“red”不是有效的颜色值。

我也尝试使用颜色代码。
这是我的代码：
 import numpy as np 

class Perceptron:
&quot;&quot;&quot; 感知器分类器

参数
----------

eta:float
学习率（介于 0.0 和 1.0 之间）
n_iter:int
传递训练数据集
random_state:int
随机生成器 sedd 用于随机权重
初始化。

属性
----------

W_:1-darray
拟合后的权重
b_:Scalar
拟合后的偏差单位

errors_: list
每个时期的错误分类（更新）数量。

&quot;&quot;&quot;

def __init__(self, eta=0.01, n_iter=50, random_state=1):
self.eta = eta
self.n_iter= n_iter
self.random_state=random_state

def fit(self,X,Y):
&quot;&quot;&quot; 拟合训练数据。

参数
----------

X: {array-like}, shape = [n_examples, n_features]
训练向量，其中 n_examples 是示例数量，n_features 是特征数量。
y : array-like, shape = [n_examples]
目标值。

返回
-------
self: object

&quot;&quot;&quot;

rgen=np.random.RandomState(self.random_state)
self.w_ = rgen.normal(loc=0.0, scale=0.01,
size=X.shape[1])
self.b_=np.float_(0.)
self.errors_ = []

for _ in range(self.n_iter):
errors=0
for xi, target in zip(X, y):
update=self.eta * (target - self.predict(xi))
self.w_ += update * xi
self.b_ += update
errors += int(update != 0.0)
self.errors_.append(errors)

return self

def net_input(self, X):
&quot;&quot;&quot; 计算净输出 &quot;&quot;&quot;
返回 np.dot(X, self.w_) + self.b_

def predict(self, X):
&quot;&quot;&quot; 返回单位步骤后的类标签 &quot;&quot;&quot;
返回 np.where(self.net_input(X) &gt;= 0.0, 1, 0)

# 在 Iris 数据集上训练

将 pandas 导入为 pd 
从 urllib.request 导入 urlretrieve
s=&#39; https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data &#39;

df=pd.read_csv(s,header= None )
df.tail()

# 选择 Setosa 和 versicolor

将 matplotlib.pyplot 导入为 plt 
将 numpy 导入为 np

y=df.iloc[0:100, 4].values
y=np.where(y==&#39;Iris-setosa&#39;,0,1)

# 提取萼片长度和花瓣长度

X=df.iloc[0:100,[0,2]].values
#绘制数据
plt.scatter(X[:50,0],X[:50,1],
color=&#39;red&#39;, marker=&#39;o&#39;, label =&#39;Setosa&#39;)
plt.scatter(X[50:100,0],X[50:100,1],
color=&#39;blue&#39;, marker =&#39;s&#39;, label=&#39;Versicolor&#39;)
plt.xlabel(&#39;萼片长度[cm]&#39;)
plt.ylabel(&#39;花瓣长度[cm]&#39;)
plt.legend(loc=&#39;左上&#39;)
plt.show()

 花卉样本分布
import numpy作为 np
导入 matplotlib.pyplot 作为 plt
从 matplotlib.colors 导入 ListedColormap

从 matplotlib.colors 导入 ListedColormap
def plot_decision_regions(X, y, classifier,resolution=0.02):
#设置标记生成器和颜色图
markers=(&#39;o&#39;, &#39;s&#39;, &#39;^&#39;, &#39;v&#39;, &#39;&lt;&#39;)
colors = (&#39;#FF0000&#39;, &#39;#0000FF&#39;, &#39;#90EE90&#39;, &#39;#808080&#39;, &#39;#00FFFF&#39;)
cmap= ListedColormap(colors[:len(np.unique(y))])

#绘制决策面
x1_min, x1_max = X[:, 0].min()-1,X[:,0].max()+1
x2_min, x2_max = X[:,1].min()-1, X[:, 1].max()+1
xx1, xx2 = np.meshgrid(np.arange(x1_min, x2_max,resolution),
np.arange(x2_min, x2_max,resolution))
lab=classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
lab=lab.reshape(xx1.shape)
plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)
plt.xlim(xx1.min(), xx1.max())
plt.ylim(xx2.min(), xx2.max())

#plot 类示例 
for idx, cl in enumerate(np.unique(y)):
plt.scatter(x=X[y==cl, 0],
y=X[y==cl, 1],
alpha=0.8,
c=colors[idx],
marker=markers[idx],
label=f&#39;Class{cl}&#39;,
edgecolor=&#39;black&#39;)

最后
plot_decision_regions(X, y, classifier=ppn)
plt.xlabel(&#39;萼片长度[cm]&#39;)
plt.ylabel(&#39;花瓣长度[cm]&#39;)
plt.legend(loc=&#39;左上&#39;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78575616/trying-to-implement-a-function-to-visualize-the-decision-boundaries-and-i-get-va</guid>
      <pubDate>Tue, 04 Jun 2024 13:12:53 GMT</pubDate>
    </item>
    <item>
      <title>PySpark 错误要求失败：A 和 B 维度不匹配</title>
      <link>https://stackoverflow.com/questions/78575590/pyspark-error-requirement-failed-a-b-dimension-mismatch</link>
      <description><![CDATA[我正在使用 PySpark 中的房屋贷款还款数据构建神经网络。执行了 EDA、数据预处理和特征工程步骤，但当涉及到模型时，我收到错误：

java.lang.IllegalArgumentException：要求失败：A 和 B 维度不匹配！

代码如下：
# 要转换为数字的列的列表 -&gt;解决不支持字符串的错误
columns_to_cast = [&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;, &#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;, &#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;,
&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;, &#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;, &#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;]

for col_name in columns_to_cast:
train_df = train_df.withColumn(col_name, col(col_name).cast(&quot;double&quot;))
test_df = test_df.withColumn(col_name, col(col_name).cast(&quot;double&quot;))

print(&quot;转换完成。正在检查schema:&quot;)
train_df.printSchema()

print(&quot;组装特征向量...&quot;)
# 组装特征向量
ohe_columns = [col + &#39;_ohe&#39; for col in categorical_columns]
numerical_columns = [col for col in train_df.columns if col not in ohe_columns + [&#39;SK_ID_CURR&#39;, &#39;TARGET&#39;]]

print(f&quot;数值列：{numerical_columns}&quot;)
print(f&quot;独热编码列：{ohe_columns}&quot;)

assembler = VectorAssembler(inputCols=numerical_columns + ohe_columns, outputCol=&quot;features&quot;)
train_df = assembler.transform(train_df)
test_df = assembler.transform(test_df)
print(&quot;特征向量组装完成。&quot;)

print(&quot;检查组装的特征向量模式：&quot;)
train_df.select(&quot;features&quot;).show(5, truncate=False)

print(&quot;缩放特征...&quot;)
# 缩放特征
scaler = StandardScaler(inputCol=&quot;features&quot;, outputCol=&quot;scaled_features&quot;)
scaler_model = scaler.fit(train_df)
train_df = scaler_model.transform(train_df)
test_df = scaler_model.transform(test_df)
print(&quot;缩放完成。&quot;)

print(&quot;检查缩放的特征模式：&quot;)
train_df.select(&quot;scaled_features&quot;).show(5, truncate=False)

print(&quot;定义神经网络结构...&quot;)
# 定义神经网络的层
num_features = len(numerical_columns + ohe_columns)
print(f&quot;输入特征数量：{num_features}&quot;)

layers = [
num_features, # 输入特征数量
64, # 隐藏层大小
32, # 隐藏层大小
2 # 类数
]

print(f&quot;神经网络层数：{layers}&quot;)

# 初始化多层感知器分类器
mlp = MultilayerPerceptronClassifier(
featuresCol=&#39;scaled_features&#39;,
labelCol=&#39;TARGET&#39;,
maxIter=100,
layer=layers,
blockSize=128,
seed=1234
)

print(&quot;训练model...&quot;)
# 训练模型
mlp_model = mlp.fit(train_df)
print(&quot;模型训练完成。&quot;)

print(&quot;对训练集进行预测...&quot;)
# 对训练集进行预测（用于评估目的）
train_predictions = mlp_model.transform(train_df)

print(&quot;评估模型...&quot;)
# 评估模型
evaluator = BinaryClassificationEvaluator(labelCol=&#39;TARGET&#39;, rawPredictionCol=&#39;rawPrediction&#39;, metricName=&#39;areaUnderROC&#39;)
auc_train = evaluator.evaluate(train_predictions)
print(f&#39;Training AUC: {auc_train}&#39;)

print(&quot;对测试集进行预测...&quot;)
# 对测试集进行预测
test_predictions = mlp_model.transform(test_df)

# 显示预测
test_predictions.select(&#39;SK_ID_CURR&#39;, &#39;prediction&#39;, &#39;probability&#39;).show()

print(&quot;准备提交文件...&quot;)
# 准备提交文件
submission = test_predictions.select(&#39;SK_ID_CURR&#39;, &#39;prediction&#39;)
submission.show()

# 将提交保存到 CSV 文件
submission.write.csv(&#39;./prediction&#39;, header=True)
print(&quot;提交文件已保存。&quot;)

请注意，我添加了打印语句来帮助我识别错误发生的位置，并且似乎错误是在评估过程中产生的。
打印语句：
定义神经网络结构...
输入特征数量：86
神经网络层：[86, 64, 32, 2]
训练模型...
模型训练完成。
对训练集进行预测...
评估模型...
（错误出现在这里）
这是什么意思？]]></description>
      <guid>https://stackoverflow.com/questions/78575590/pyspark-error-requirement-failed-a-b-dimension-mismatch</guid>
      <pubDate>Tue, 04 Jun 2024 13:07:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 和 opencv 计算盒子的尺寸</title>
      <link>https://stackoverflow.com/questions/78575461/calculate-the-dimensions-of-a-box-using-python-and-opencv</link>
      <description><![CDATA[我正在使用 Python 绘制盒子照片的轮廓，并使用 opencv 在盒子的轮廓上画线，我试图做的是计算，如附图所示。
绘制另一个不同颜色的轮廓并标记顶点 (tl、tr、br、bl)。
我正在尝试计算宽度 (BL + BR)、高度 (BL、TL) 和长度 (TL、TR)。
但这样做时，它会计算出不同的大小，并采用其他引用。
import cv2
import numpy as np
from scipy.spatial import distance as dist

def tup(point):
return (int(point[0]), int(point[1]))

# 按正确顺序排列点的函数
def order_points(pts):
rect = np.zeros((4, 2), dtype=&quot;float32&quot;)
s = pts.sum(axis=1)
rect[0] = pts[np.argmin(s)]
rect[2] = pts[np.argmax(s)]

diff = np.diff(pts, axis=1)
rect[1] = pts[np.argmin(diff)]
rect[3] = pts[np.argmax(diff)]

return rect

# 加载图像
img = cv2.imread(&quot;boxing.jpg&quot;)

# 缩小尺寸以适合屏幕
scale = 0.2
h, w = img.shape[:2]
h = int(scale * h)
w = int(scale * w)
img = cv2.resize(img, (w, h))
copy = np.copy(img)

# 转换为 hsv
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(hsv)

# 制作掩码
mask = cv2.inRange(s, 30, 255)

# 扩大和侵蚀以消除小孔
kernel = np.ones((5, 5), np.uint8)
mask = cv2.dilate(mask, kernel, iterations=1)
mask = cv2.erode(mask, kernel, iterations=1)

# 查找轮廓
contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contour = max(contours, key=cv2.contourArea) # 使用最大轮廓

# 将轮廓近似为多边形
epsilon = 0.02 * cv2.arcLength(contour, True)
approx = cv2.approxPolyDP(contour, epsilon, True)

# 绘制轮廓
cv2.drawContours(img, [approx], -1, (0, 0, 200), 2)

# 计算框尺寸
if len(approx) == 6:
pts = approx.reshape(6, 2)

# 对点进行排序
rect = order_points(pts[:4])

# 计算尺寸
(tl, tr, br, bl) = rect
widthA = dist.euclidean(br, bl)
widthB = dist.euclidean(tr, tl)
heightA = dist.euclidean(tr, br)
heightB = dist.euclidean(tl, bl)

maxWidth = max(int(widthA), int(widthB))
maxHeight = max(int(heightA), int(heightB))

print(f&quot;Width: {maxWidth}px&quot;)
print(f&quot;Height: {maxHeight}px&quot;)

# 绘制带标签的点和线
colors = [(0, 255, 0), (0, 255, 255), (255, 0, 255), (255, 255, 0)]
标签 = [&quot;TL&quot;, &quot;TR&quot;, &quot;BR&quot;, &quot;BL&quot;]

对于 i，点在枚举（rect）中：
cv2.circle(img, tup(point), 5, colors[i], -1)
cv2.putText(img, labels[i], tup(point), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[i], 2)

cv2.line(img, tup(tl), tup(tr), (0, 255, 0), 2)
cv2.line(img, tup(tr), tup(br), (0, 255, 0), 2)
cv2.line(img, tup(br), tup(bl), (0, 255, 0), 2)
cv2.line(img, tup(bl), tup(tl), (0, 255, 0), 2)

# 显示
cv2.imshow(&quot;Image&quot;, img)
cv2.waitKey(0)
cv2.destroyAllWindows()

使用的图片
处理后的图片
我正在尝试计算方框的大小，尝试获取宽度、高度和长度。]]></description>
      <guid>https://stackoverflow.com/questions/78575461/calculate-the-dimensions-of-a-box-using-python-and-opencv</guid>
      <pubDate>Tue, 04 Jun 2024 12:40:25 GMT</pubDate>
    </item>
    <item>
      <title>请问如何改进我的混合 1D CNN 和 Bi-LSTM 模型以实现高精度</title>
      <link>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</link>
      <description><![CDATA[我正在构建一个混合 1D CNN 和 Bi-LSTM 模型，用于预测心脏病。然而，该模型的准确率是 0.73，但我想将其提高到 0.80 及以上。请就如何改进此模型提供任何帮助。谢谢。我期望准确率能稍微提高一点。
我的输入形状如下所示 (70000,13)
import tensorflow as tf 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling2D, MaxPooling1D, LSTM, Bidirectional, Dense, Flatten, Dropout, Input, BatchNormalization, Reshape
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils.class_weight import compute_class_weight 

dataset = pd.read_csv(&#39;heart_disease.csv&#39;)
dataset.shape

#预处理数据集
X = dataset.drop(columns=[&#39;disease&#39;])
y = dataset[&#39;disease&#39;]

`#标准化特征
scaler = StandardScaler()
X = scaler.fit_transform(X)
# print(X)

#将数据分成训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(&quot;训练集大小：&quot;, X_train.shape)
print(&quot;测试集大小：&quot;, X_test.shape)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#重塑数据1D CNN + Bi-LSTM 模型
X_train_dl = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_dl = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

#print(X_train_dl)
#print(X_test_dl)

# 构建混合模型

model = Sequential()
model.add(Input(shape=(X_train_dl.shape[1], X_train_dl.shape[2])))

model.add(Conv1D(filters=32, kernel_size=2,activation=&#39;relu&#39;))

model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Conv1D(filters=64, kernel_size=2,activation=&#39;relu&#39;))
model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Bidirectional(LSTM(50, return_sequences=True)))
model.add(Dropout(0.5))
model.add(Flatten())

`model.add(Dense(128,activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
model.add(Dropout(0.5))

model.add(Dense(1,activation=&#39;sigmoid&#39;))

#编译模型

model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 提前停止回调
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=20, restore_best_weights=True)

# 训练模型
history = model.fit(X_train_dl, y_train, epochs=10, batch_size=32, validation_data=(X_test_dl, y_test), callbacks=[early_stopping])

# 保存模型
model.save(&#39;my_model.keras&#39;)

# 评估模型
loss accuracy = model.evaluate(X_test_dl, y_test)
print(f &quot;混合模型 (1D CNN + Bi-LSTM) 准确率： {准确度：.2f}&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</guid>
      <pubDate>Tue, 04 Jun 2024 12:04:25 GMT</pubDate>
    </item>
    <item>
      <title>人工智能集成来分析数据</title>
      <link>https://stackoverflow.com/questions/78575195/ai-integration-to-analyze-data</link>
      <description><![CDATA[我是 AI/ML 新手。我有一个挂载点的 6 个月数据集（分钟级）利用率。例如：
时间 -- 利用率
4-Jan-24 5:01 -- 10 GB
4-Jan-24 5:02 -- 11 GB
4-Jan-24 5:03 -- 9 GB
4-Jan-24 5:04 -- 12 GB

---

4-Aug-24 5:04 -- 20 GB
4-Aug-24 5:04 -- 15 GB
4-Aug-24 5:04 -- 30 GB

现在，如果我想获取未来 2/3 个月的趋势/预测。我该如何实现？
获取数据预测]]></description>
      <guid>https://stackoverflow.com/questions/78575195/ai-integration-to-analyze-data</guid>
      <pubDate>Tue, 04 Jun 2024 11:47:03 GMT</pubDate>
    </item>
    <item>
      <title>BIRCH 无法分配，太大</title>
      <link>https://stackoverflow.com/questions/78574823/birch-unable-to-allocate-its-too-big</link>
      <description><![CDATA[MemoryError: 无法为形状为 (49604310962128,) 且数据类型为 float64 的数组分配 361. TiB
from sklearn.cluster import Birch
from sklearn.metrics import pairwise_distances
branching_factor = 50
n_clusters = 1000000 # 设置一个较大的聚类数
threshold = 0.5

# 创建BIRCH聚类器
birch = Birch(n_clusters=n_clusters, Threshold=threshold, Branching_factor=branching_factor)

# 训练BIRCH聚类器
birch.fit(reduced_data)

包含10,000,000个样本，每个样本为一行，第一个样本号，剩余64个样本特征。数据来自DNA序列最大簇数为1000000，如果超过1000000，多余的簇会被合并到第1000000个簇中。
哪种聚类方案最好，如何做]]></description>
      <guid>https://stackoverflow.com/questions/78574823/birch-unable-to-allocate-its-too-big</guid>
      <pubDate>Tue, 04 Jun 2024 10:31:38 GMT</pubDate>
    </item>
    <item>
      <title>排名模型中的聚合以更改观察单位</title>
      <link>https://stackoverflow.com/questions/78574761/aggregation-in-the-ranking-model-to-change-the-unit-of-observation</link>
      <description><![CDATA[设置：
我需要建立一个排名模型来对酒店进行排名（让我们考虑一个没有个性化的搜索系统），因此应用程序中的最终观察单位必须是酒店。但在训练和测试我的模型期间，我有一个客户查询作为观察单位（因此我的数据如下所示：query_id + hotel + features + target）。
问题：
从初始观察单位到最终观察单位的最佳方法是什么？在对每个查询进行预测并计算平均/中位数分数后，按酒店分组汇总结果是否是个好主意？有什么想法吗？
提前谢谢您~~
现在我唯一的想法是在 Catboost 模型中计算平均/中位数预测分数，并按酒店分组。但这似乎不是最好的方法……]]></description>
      <guid>https://stackoverflow.com/questions/78574761/aggregation-in-the-ranking-model-to-change-the-unit-of-observation</guid>
      <pubDate>Tue, 04 Jun 2024 10:17:48 GMT</pubDate>
    </item>
    <item>
      <title>加载预先训练的 json 模型时出错</title>
      <link>https://stackoverflow.com/questions/78570246/error-when-loading-a-pre-trained-json-model</link>
      <description><![CDATA[我一直在尝试执行一个项目，其中我必须使用经过训练的模型的架构（我存储在 json 文件中），但我收到了下面提到的错误
这是我收到的错误：
回溯（最近一次调用最后一次）：
文件“C:\Users\Richard.Joy\Desktop\Final-antispoofing_models\anti.py”，第 14 行，位于&lt;module&gt;
model = tf.keras.models.model_from_json(loaded_model_json)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\Richard.Joy\Desktop\Final-antispoofing_models\antispoof_env\Lib\site-packages\keras\src\models\model.py&quot;，第 575 行，位于 model_from_json
return serialization_lib.deserialize_keras_object(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;C:\Users\Richard.Joy\Desktop\Final-antispoofing_models\antispoof_env\Lib\site-packages\keras\src\saving\serialization_lib.py&quot;，第 694 行，位于 deserialize_keras_object
cls = _retrieve_class_or_fn(
^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\Richard.Joy\Desktop\Final-antispoofing_models\antispoof_env\Lib\site-packages\keras\src\saving\serialization_lib.py&quot;，第 812 行，位于 _retrieve_class_or_fn
raise TypeError(
TypeError：无法找到类“Functional”。确保自定义类已用修饰`@keras.saving.register_keras_serializable()`。完整对象配置：{&#39;class_name&#39;: &#39;Functional&#39;, &#39;config&#39;:.....(**json 文件的内容**........&#39;keras_version&#39;: &#39;2.15.0&#39;, &#39;backend&#39;: &#39;tensorflow&#39;)

以下是库版本（在 vscode 上）：
keras 3.3.3
opencv-python 4.9.0.80
tensorflow 2.16.1
python 3.12.3

以下是库版本（在我训练模型的 google colab 上）：
keras 3.3.3
opencv-python 4.8.0.76
tensorflow 2.15.0

这是我的代码：
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing.image import img_to_array 
import os
import numpy as np

root_dir = os.getcwd()
# 加载人脸检测模型
trained_face_data = cv2.CascadeClassifier(cv2.data.haarcascades + &#39;haarcascade_frontalface_default.xml&#39;)
# 加载反欺骗模型图
json_file = open(&#39;C:/Users/Richard.Joy/Desktop/Final-antispoofing_models/Antispoofing_model_mobilenet.json&#39;,&#39;r&#39;)
loaded_model_json = json_file.read()
json_file.close()
model = tf.keras.models.model_from_json(loaded_model_json)
# 加载反欺骗模型权重 
model.load_weights(&#39;C:/Users/Richard.Joy/Desktop/Final-antispoofing_models/project_antispoofing_model_97-0.957895.h5&#39;)
print(&quot;模型从磁盘加载&quot;)

video = cv2.VideoCapture(0)
while True:
try:
ret,frame = video.read()
gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
faces = training_face_data.detectMultiScale(gray,1.3,5)
for (x,y,w,h) in faces: 
face = frame[y-5:y+h+5,x-5:x+w+5]
resized_face = cv2.resize(face,(160,160))
resized_face = resized_face.astype(&quot;float&quot;) / 255.0
resized_face = np.expand_dims(resized_face, axis=0)
# 将人脸 ROI 传递到经过训练的活体检测器
# 模型确定人脸是“真”还是“假”
preds = model.predict(resized_face)[0]
print(preds)
if preds&gt; 0.5:
标签 = &#39;poof&#39;
cv2.putText(frame, 标签, (x,y - 10),
cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)
cv2.rectangle(frame, (x, y), (x+w,y+h),
(0, 0, 255), 2)
else:
标签 = &#39;eal&#39;
cv2.putText(frame, 标签, (x,y - 10),
cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
cv2.rectangle(frame, (x, y), (x+w,y+h),
(0, 255, 0), 2)
cv2.imshow(&#39;frame&#39;, frame)
key = cv2.waitKey(1)
if key == ord(&#39;q&#39;):
break
except Exception as e: 
pass
video.release() 
cv2.destroyAllWindows()

我该怎么办？我尝试降级库，但也遇到了错误。]]></description>
      <guid>https://stackoverflow.com/questions/78570246/error-when-loading-a-pre-trained-json-model</guid>
      <pubDate>Mon, 03 Jun 2024 12:21:33 GMT</pubDate>
    </item>
    <item>
      <title>如何在 M3 Mac 上安装 ML-Agents：Onnx 和 Protobuf 问题</title>
      <link>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</link>
      <description><![CDATA[我正尝试使用 conda 在我的 M3 Mac 上安装 ML-Agents。我按照网络文档 (https://unity-technologies.github.io/ml-agents/Installation/) 中列出的说明进行操作，但遇到了 protobuf 版本问题。我将其更改为 3.6，但这不适用于 onnx，因为 onnx 似乎需要 4.25。我真的不确定如何解决这个问题，如果能得到任何帮助，我将不胜感激！
以下是我运行到此点的命令：

conda create -n mlagents python=3.10.12 &amp;&amp; conda 激活 mlagents
git clone --branch release_21 https://github.com/Unity-Technologies/ml-agents.git
python -m pip install ./ml-agents-envs (有效)
python -m pip install ./ml-agents
]]></description>
      <guid>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</guid>
      <pubDate>Sun, 04 Feb 2024 06:53:10 GMT</pubDate>
    </item>
    <item>
      <title>使用单类 SVM 计算异常检测的异常分数</title>
      <link>https://stackoverflow.com/questions/53956538/calculating-anomaly-score-for-anomaly-detection-using-one-class-svm</link>
      <description><![CDATA[我对使用单类 SVM 计算异常检测的异常分数有疑问。我的问题是：如何使用 decision_function(X) 计算它，就像我在隔离森林中计算异常分数一样？
非常感谢，]]></description>
      <guid>https://stackoverflow.com/questions/53956538/calculating-anomaly-score-for-anomaly-detection-using-one-class-svm</guid>
      <pubDate>Fri, 28 Dec 2018 09:50:20 GMT</pubDate>
    </item>
    </channel>
</rss>