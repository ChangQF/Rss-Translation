<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Dec 2023 09:14:07 GMT</lastBuildDate>
    <item>
      <title>RuntimeError尝试在pytorch中的backward()函数中第二次向后浏览图表</title>
      <link>https://stackoverflow.com/questions/77644164/runtimeerror-trying-to-backward-through-the-graph-a-second-time-in-backward-fu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77644164/runtimeerror-trying-to-backward-through-the-graph-a-second-time-in-backward-fu</guid>
      <pubDate>Tue, 12 Dec 2023 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>EconML 和 SHAP</title>
      <link>https://stackoverflow.com/questions/77644092/econml-and-shap</link>
      <description><![CDATA[我们可以使用形状值工具（TreeExplainer）来帮助我们评估EconML中的因果森林并进行一些可视化吗？我正在阅读EconML的cookbook，似乎SHAP在因果推理中可能有用，但我正在尝试在我的程序中应用因果森林！
也许我希望有人能教我如何使用这两个工具！]]></description>
      <guid>https://stackoverflow.com/questions/77644092/econml-and-shap</guid>
      <pubDate>Tue, 12 Dec 2023 06:33:54 GMT</pubDate>
    </item>
    <item>
      <title>用于检测源代码中语法问题的 ML 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/77644081/ml-model-for-detecting-syntax-issues-in-source-code</link>
      <description><![CDATA[我编写了一个使用正则表达式来识别源代码中的语法错误的工具，该工具还提供了纠正问题的原因和建议。
同样，我需要训练一个机器学习模型，以便照顾到每个极端情况并将其推广。
需要建议来实现这一目标。（是否使用监督方法或现在哪种方法更好）
示例：避免在 src 代码中使用特定变量、以正确的推荐格式为变量赋值等。]]></description>
      <guid>https://stackoverflow.com/questions/77644081/ml-model-for-detecting-syntax-issues-in-source-code</guid>
      <pubDate>Tue, 12 Dec 2023 06:29:43 GMT</pubDate>
    </item>
    <item>
      <title>VS Code .ipynb 中的 FileUpload 小部件问题：显示“Upload(6)”，但数据长度返回 0</title>
      <link>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</link>
      <description><![CDATA[我试图使用 widget.FileUpload() 上传文件并打印图像。但上传 6 张图像并尝试在新单元格中运行最后一行后，它返回错误，提示“索引超出范围”
btn_upload = widgets.FileUpload()
btn_上传


img = PILImage.create(btn_upload.data[-1])

在此处输入图像描述
然后我尝试了这条线
print(&quot;上传文件数：&quot;, len(btn_upload.data))
期待“6”因为这是我上传的文件数，所以它返回了 0。]]></description>
      <guid>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</guid>
      <pubDate>Tue, 12 Dec 2023 05:06:16 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 GPU 减少 xgboost 的处理时间？</title>
      <link>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</link>
      <description><![CDATA[我正在关注数据营的本教程，他们有一件事提到的是利用 GPU 来加快处理时间。他们甚至说它“速度极快”。
然而，我看到了相反的结果。对于下面的代码块，在 10k 提升的情况下，我看到在我的 params 中传递 “hist” 大约需要 30 秒，而在 ” 中传递则只需一分多钟。 gpu_hist&quot; 与我的 params 一起传递。
使用 “gpu_hist” 时，我的 GPU 的使用率上限为 12%，使用 “hist” 时，所有 24 个逻辑核心的使用率上限为 100%
params = {“objective”: “reg:squarederror”, “tree_method”: “gpu_hist”, “subsample”: 0.8,
    “colsample_bytree”：0.8}

evals = [(dtrain_reg, “训练”),(dtest_reg, “验证”)]

n = 10000


模型 = xgb.train(
   参数=参数，
   dtrain=dtrain_reg,
   num_boost_round=n,
   评估=评估，
   详细评估=50，
）

我正在尝试在 jupyter 笔记本的 VSCode 中运行它。

我已安装 CUDA 工具包和 cuDNN
我已检查它们是否已添加到路径中
我已确保安装了正确版本的 xgboost 来使用 GPU。
数据集有 53k 行 10 列，所以我不认为数据集太小
我已确认兼容性（使用 RTX 2060）

我问过 chatGPT，在网上搜索过，甚至问过我正在学习的课程中的导师，但无法诊断为什么“gpu_hist”花费了这么长时间。 vs 只是“历史”。
4 个月前在 stackoverflow 上还有另一个类似问题零回应。如有任何帮助，我们将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</guid>
      <pubDate>Tue, 12 Dec 2023 05:02:17 GMT</pubDate>
    </item>
    <item>
      <title>在 Java 中包含 Python 分类器模型</title>
      <link>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</link>
      <description><![CDATA[我已经用 Python 开发了一个 ML 分类器模型，我想从 java 中使用它。
我查找了一些选项，例如 Jython 等。
谁能帮助我，我怎样才能实现这个用例？
我尝试使用 Jython，但没有找到适合此用例的任何好的文档]]></description>
      <guid>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</guid>
      <pubDate>Tue, 12 Dec 2023 04:58:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用坐标 X、Y 和图像训练深度学习模型？</title>
      <link>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</link>
      <description><![CDATA[我的任务是头影测量地标定位。
我的图像路径的坐标显示在此数据框中。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文件名
X1
Y1


&lt;正文&gt;

/Images_data/binary0006.png
89
80


/Images_data/binary0008.png
37
70


/Images_data/binary0007.png
50
76


/Images_data/binary0003.png
55
92


/Images_data/binary0005.png
91
64


/Images_data/binary0004.png
100
76




如何准备用于 model.fit 训练的数据集？
我尝试使用 ImageDataGenerator 创建用于训练的图像数据集。
 train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  数据目录，
  label_mode=无，
  验证分割=0.2，
  子集=“训练”，
  种子=123，
  图像大小=（img_高度，img_宽度），
  批量大小=批量大小）

但现在我陷入困境，因为我不知道如何将坐标与图像匹配。]]></description>
      <guid>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</guid>
      <pubDate>Tue, 12 Dec 2023 02:46:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型能够在数据集上进行训练和测试，但在添加 SoftMax 层并要求其进行预测时出现错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</guid>
      <pubDate>Mon, 11 Dec 2023 23:58:34 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证和标准缩放，以便在每次迭代时对训练部分进行 fit_transformed，而验证部分仅进行变换</title>
      <link>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</link>
      <description><![CDATA[我有 X 数据，我想要进行交叉验证，并且我需要以某种方式在交叉验证的每次迭代中使用 StandardScaler，因此它的训练部分是 fit_transformed，而它的验证部分仅进行转换。我应该如何将其包含在逻辑中。我正在使用 LGBM 模型。
我很困惑如何处理它]]></description>
      <guid>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</guid>
      <pubDate>Mon, 11 Dec 2023 22:38:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   模型=llm_模型）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score（自我，查询，k，过滤器，where_document，**kwargs）
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>获取标准普尔成分股的股票方向[关闭]</title>
      <link>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</link>
      <description><![CDATA[我们通常使用一两只股票作为线性回归的自变量（例如 SPX 和 GOOG），并使用 AAPL 作为因变量，用于预测 AAPL 股票的方向。
假设我们使用所有 S&amp;P500 成分，每个成分都有自己的功能，例如收盘价、移动平均线、相对强弱指数&lt; /code&gt;, ..etc，我们使用 80% 的 S&amp;P500 成分作为训练集，20% 作为测试数据集。
我需要什么类型的机器学习技术来实现此模型？]]></description>
      <guid>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</guid>
      <pubDate>Mon, 11 Dec 2023 18:57:47 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>MSE 值远大于应有的值 [关闭]</title>
      <link>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</link>
      <description><![CDATA[知道我在这里做错了什么吗：
我的数据集约为 20k 行，mse 约为 11298955095.811989，我不太确定我做错了什么？
我试图找到哪个数据集以及哪个 k 给出最小值，但没有一个值有任何意义：
随机导入
def split_df(数据帧):
    data_rows = dataframe.values.tolist()

    随机播放（数据行）

    训练值 = 0.7
    split_index = int(len(data_rows) * train_val)

    train_data = data_rows[:split_index]
    test_data = data_rows[split_index:]

    train_df = pd.DataFrame(train_data, columns=dataframe.columns)
    test_df = pd.DataFrame(test_data, columns=dataframe.columns)

    返回train_df、test_df

从 sklearn.neighbors 导入 KNeighborsRegressor
从 sklearn.metrics 导入mean_squared_error

数据帧 = [no_nulls、outliers_removed、mean_impulated、median_impulated]
目标 = &#39;中位房屋价值&#39;
k_vals = 范围(1, 30)

对于数据帧中的 df：
    mse_字典 = {}
    X = df.drop(columns=[target]) # 特征
    y = df[target] # 目标变量

    # 将数据分为训练和测试
    train_df, test_df = split_df(df)

    # 训练和测试的单独特征和目标变量
    X_train = train_df.drop(列=[目标])
    y_train = train_df[目标]
    X_test = test_df.drop(列=[目标])
    y_test = test_df[目标]
    
    对于 k_vals 中的 k：
        knn_regressor = KNeighborsRegressor(n_neighbors=k)
        knn_regressor.fit(X_train, y_train)
        预测 = knn_regressor.predict(X_test)
        squared_errors = (预测 - y_test) ** 2 # 计算平方误差
        mse = squared_errors.mean() # 计算平方误差的平均值以获得 MSE
        mse_dictionary[k] = mse

    print(f“数据帧 {df} 的 MSE 字典：{mse_dictionary}”)
    # 用于调试的附加信息
    print(f&quot;最大 MSE: {max(mse_dictionary.values())}&quot;)
    print(f&quot;最小 MSE: {min(mse_dictionary.values())}&quot;)
    print(f&quot;平均 MSE: {sum(mse_dictionary.values()) / len(mse_dictionary)}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</guid>
      <pubDate>Tue, 05 Dec 2023 16:54:01 GMT</pubDate>
    </item>
    <item>
      <title>如何为多重损失设置可训练的权重？</title>
      <link>https://stackoverflow.com/questions/77380874/how-to-have-trainable-weights-for-multiple-losses</link>
      <description><![CDATA[我有一个加权损失，其中包含用于训练模型的多个损失。
损失 = w1 * 损失1 + w2 * 损失2 + w3 * 损失3
loss.backward()

是否有任何可能的方法使 w1、w2 和 w3 可学习参数？我尝试在模型内使用 self.w1 = nn.Parameter(torch.tensor(0.33), require_grad=True) 来初始化它们，但在一次迭代之后，它的值变成了 nan代码&gt;.
当我们想要使权重可学习时，还需要考虑其他问题，例如，什么阻止它们趋于零甚至负数以使损失为零，我们如何确保权重不会集中于只有一次损失。
有没有办法让这些权重可以学习，而不是手动调整权重？]]></description>
      <guid>https://stackoverflow.com/questions/77380874/how-to-have-trainable-weights-for-multiple-losses</guid>
      <pubDate>Sat, 28 Oct 2023 19:14:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 ConvNext 分类器层</title>
      <link>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</link>
      <description><![CDATA[Convnext 的源代码内部：
self.classifier = nn.Sequential(
    norm_layer(lastconv_output_channels), nn.Flatten(1), nn.Linear(lastconv_output_channels, num_classes)
）

当我调用预训练模型并且我想在分类器层中进行更改时，norm_layer未定义，我不知道如何从源代码中使用它
模型 = torchvision.models.convnext_base(prtrained=True, stochastic_depth_prob=0.1,
                                         层规模=1e-4)

model.classifier = nn.Sequential(
   **norm_layer**(1024), nn.Flatten(1), nn.Linear(1024, 7)
）

请问谁能帮忙写正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</guid>
      <pubDate>Fri, 30 Dec 2022 19:14:20 GMT</pubDate>
    </item>
    </channel>
</rss>