<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 08 Mar 2024 09:13:23 GMT</lastBuildDate>
    <item>
      <title>cnn 代码有问题，可能是班级老师的问题</title>
      <link>https://stackoverflow.com/questions/78126559/problem-with-a-cnn-code-maybe-instructor-problem-of-the-class</link>
      <description><![CDATA[我建立了一个 CNN
将 numpy 导入为 np
进口火炬
将 torch.nn 导入为 nn

CNN 类（nn.Module）：
 def __init__(自身):
  超级（CNN，自我）.__init__()
    自我.n = 10
    内核大小 = 3
    填充 = (内核大小 - 1) / 2
    self.conv1 = nn.Conv2d(in_channels=3,out_channels=self.n,kernel_size=kernel_size,stride = (2,2),padding=padding),

    self.conv2 = nn.Conv2d(in_channels=self.n,out_channels=2*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding),
        
    self.conv3 = nn.Conv2d(in_channels=2*self.n,out_channels=4*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding),
    
    self.conv4 = nn.Conv2d(in_channels=4*self.n,out_channels=8*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding),
    
    self.fc1 = nn.Linear(8 * self.n * 7 * 4, 100)
    self.fc2 = nn.Linear(100, 2)

 def 转发（自身，inp）：
   输出 = nn.function.relu(self.conv1(inp))
   输出 = nn.function.relu(self.conv2(out))
   输出 = nn.function.relu(self.conv3(out))
   输出 = nn.function.relu(self.conv4(out))

   出=出。视图(-1, 8 * self.n * 7 * 4)
   输出 = nn.function.relu(self.fc1(out))
   输出 = self.fc2(输出)
    
   返回

输入数据inp是形状为(N,3,448,224)的张量，输出形状为(N,2)。
问题是我收到错误：“TypeError: &#39;tuple&#39; object is not callable”
对于行：” out = nn.function.relu(self.conv1(inp))”
有什么解决办法吗？
我尝试将其分离为：
inp = self.conv1(inp)
inp = nn.function.relu(inp)
仍然无法工作...]]></description>
      <guid>https://stackoverflow.com/questions/78126559/problem-with-a-cnn-code-maybe-instructor-problem-of-the-class</guid>
      <pubDate>Fri, 08 Mar 2024 09:05:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么 `skorecard.WoeEncoder()` 这么慢，如何让它更快？</title>
      <link>https://stackoverflow.com/questions/78126501/why-is-skorecard-woeencoder-so-slow-and-how-can-i-make-it-faster</link>
      <description><![CDATA[我正在使用 WoeEncoder()  从 skorecard Python 库到对预测建模的大量特征进行目标编码，但由于某种原因速度非常慢。
是否有任何方法可以修改 WoeEncoder() 的代码以保留相同的功能，但只是使其运行速度更快？我需要在 sklearn 管道等中使用它。

可重现的示例显示了巨大的速度差异：
from skorecard.preprocessing import WoeEncoder # pip install skorecard

随机导入
将 pandas 导入为 pd
将 numpy 导入为 np

# 时间安排：
导入时间
来自人类友好的导入 format_timespan

def tic():
    全球圣
    st = 时间.time()
    
def 目录():
    et = 时间.time()
    time_elapsed = 轮(et - st, 1)
    print(&quot;经过的时间:&quot;, format_timespan(time_elapsed))

生成随机分箱数据以进行 WOE 编码：
X_train_binned = pd.DataFrame(np.random.randint(0,10, size = (20000, 1000))).astype(str)
X_test_binned = pd.DataFrame(np.random.randint(0,10, size = (20000, 1000))).astype(str)

y_train = np.random.randint(0,2, 大小 = (20000, ))



&lt;强&gt;1。使用 skorecard.WoeEncoder() ：
&lt;前&gt;&lt;代码&gt;tic()

祸 = WoeEncoder()
woe.fit(X_train_binned, y_train) # 快
X_train_WOE_1 = woe.transform(X_train_binned) # 非常慢
X_test_WOE_1 = woe.transform(X_test_binned) # 非常慢

目录()

&lt;块引用&gt;
已用时间：3 分 26.1 秒



&lt;强&gt;2。使用我自己的函数：
def woe_mapping_1d(X_train_binned_col, y_train, epsilon = 0.0001):
    df = pd.DataFrame({&#39;feat&#39;: X_train_binned_col, &#39;target&#39;: y_train}).reset_index(drop = True)
    df[&#39;non_target&#39;] = np.where(df[&#39;target&#39;] == 1, 0, 1)
    
    woe_table = df.groupby(&#39;feat&#39;, as_index = False).agg(target_count = (&#39;target&#39;, &#39;sum&#39;),
                                                         non_target_count = (&#39;non_target&#39;, &#39;总和&#39;))
    woe_table[&#39;pct_of_target&#39;] = (woe_table[&#39;target_count&#39;] / df[&#39;target&#39;].sum()) + epsilon
    woe_table[&#39;pct_of_non_target&#39;] = (woe_table[&#39;non_target_count&#39;] / df[&#39;non_target&#39;].sum()) + epsilon
    woe_table[&#39;WOE&#39;] = np.log(woe_table[&#39;pct_of_non_target&#39;] / woe_table[&#39;pct_of_target&#39;])

    映射_dict = dict(zip(woe_table[&#39;feat&#39;], woe_table[&#39;WOE&#39;]))
    返回映射字典


def create_woe_mapping_dict(X_train_binned, y_train, epsilon = 0.0001):
    woe_mapping_dict = {}

    对于 X_train_binned.columns 中的 var：
        woe_mapping_dict[var] = woe_mapping_1d(X_train_binned_col = X_train_binned[var], y_train = y_train, epsilon = epsilon)
        
    返回 woe_mapping_dict


def apply_woe_mappings(X_binned, woe_mapping_dict, woe_value_unknown = 0):
    X_WOE_列表 = []
    
    对于 X_binned.columns 中的 var：
        X_WOE_var = X_binned[var].map(woe_mapping_dict[var]).fillna(woe_value_unknown)
        X_WOE_list.append(X_WOE_var)
    
    X_WOE_df = pd.concat(X_WOE_list, 轴 = 1)
    返回X_WOE_df

它的运行速度快了约 40 倍，并产生相同的结果：
&lt;前&gt;&lt;代码&gt;tic()

woe_dict = create_woe_mapping_dict(X_train_binned, y_train)

X_train_WOE_2 = apply_woe_mappings(X_train_binned, woe_dict)
X_test_WOE_2 = apply_woe_mappings(X_test_binned, woe_dict)

目录()

打印（X_train_WOE_1.等于（X_train_WOE_2））
打印（X_test_WOE_1.等于（X_test_WOE_2））

&lt;块引用&gt;
已用时间：5.3 秒
真的
真的


任何帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78126501/why-is-skorecard-woeencoder-so-slow-and-how-can-i-make-it-faster</guid>
      <pubDate>Fri, 08 Mar 2024 08:54:26 GMT</pubDate>
    </item>
    <item>
      <title>目标和输入大小不匹配的 ValueError</title>
      <link>https://stackoverflow.com/questions/78126473/valueerror-with-mismatched-target-and-input-size</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78126473/valueerror-with-mismatched-target-and-input-size</guid>
      <pubDate>Fri, 08 Mar 2024 08:50:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么LSTM在大时间步长的情况下仍然存在梯度消失的问题？</title>
      <link>https://stackoverflow.com/questions/78126328/why-does-lstm-still-have-the-problem-of-gradient-vanishing-in-large-time-step-ca</link>
      <description><![CDATA[我构建了一个 LSTM 模型来预测机械零件的行为。
输入的大小为 (256, 32)。 256 是时间步数，32 是每个步中的特征数。输出的大小为 2。我有 20,000 组这些输入和输出
我使用以下模型来训练输入和输出，
`模型 = keras.Sequential()
model.add(layers.Input(shape=(None, input_size)))
model.add(layers.Bi Direction(layers.LSTM(32, return_sequences=True)))
model.add(layers.Dropout(0.1))
model.add(layers.Dense(output_size))`
我使用 mse 作为训练的损失函数，并使用 adam 作为优化器。
但是，我得到的损失结果如下所示：
图片
训练和验证损失收敛到接近 0.5，这是相当大的。
我认为问题在于时间步长。较长的时间步长会导致梯度消失的问题。因为如果我减少时间步长，使输入的大小为 (64, 32)，那么训练损失和验证损失都会收敛到一个非常小的数字 (10^-2)。
但我仍然想训练输入大小为 (256, 32) 的数据集。我该怎么办？
我看到一些博客建议将输入切割成几个部分（例如 4 个 (64, 32) 形成 (256, 32)）并将这些部分连接在一起，并将前一个输出缓存到下一个输入的输入。但我不知道如何提取 LSTM 中的隐藏信息，以便将其输入到下一部分的输入中。您有什么想法或有其他解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78126328/why-does-lstm-still-have-the-problem-of-gradient-vanishing-in-large-time-step-ca</guid>
      <pubDate>Fri, 08 Mar 2024 08:19:11 GMT</pubDate>
    </item>
    <item>
      <title>尽管张量是叶子，但神经网络（pytorch）中的损失却没有得到任何结果</title>
      <link>https://stackoverflow.com/questions/78126160/getting-none-from-loss-in-neural-network-pytorch-despite-tensors-being-leaf</link>
      <description><![CDATA[我检查了所有的张量和输入参数，它们都是叶子，根据下面的代码，
def train_step(w1,b1):
    打印（“w=”，w1）
    可训练变量 = [w1,b1]
    优化器 = torch.optim.SGD(trainable_variables, lr=learning_rate)
    损失=变量（loss2_function（），requires_grad = True）
    打印(loss.backward())
    使用 torch.no_grad()：
        w1 -=(学习率 * w1.grad)
        b1 -= (学习率 * b1.grad)
        w1.grad.zero_()
        b1.grad.zero_()
    优化器.step()
    优化器.zero_grad()

我仍然没有得到任何结果，即使学习率、权重和偏差发生变化，网络仍然无法工作，请指导我。]]></description>
      <guid>https://stackoverflow.com/questions/78126160/getting-none-from-loss-in-neural-network-pytorch-despite-tensors-being-leaf</guid>
      <pubDate>Fri, 08 Mar 2024 07:42:18 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型训练</title>
      <link>https://stackoverflow.com/questions/78126036/deep-learning-model-training</link>
      <description><![CDATA[我一直在尝试创建一个 CNN 模型来预测头部受伤。我已经确定了数据集的频谱图图像，并创建了指示头部是否受伤的标签文件。
我拿了两个数据集，都有列：通道、标签和图像路径。标记为1（表示头部受伤）和0（表示未受伤）。从每个数据集中总共识别出 117 个通道图像。在尝试运行 CNN 模型时，我在 Jupyter Notebook 中使用了以下代码：
导入操作系统
将 pandas 导入为 pd
将 numpy 导入为 np
将张量流导入为 tf
从 sklearn.model_selection 导入 train_test_split
从tensorflow.keras.preprocessing.image导入load_img，img_to_array
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、Flatten、Dense、Dropout
从tensorflow.keras.optimizers导入Adam
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.utils导入to_categorical

df1 = pd.read_csv(&#39;C:/Users/Lenovo/Desktop/EEG 处理材料/div_attention.cnt 频谱图图像/更新的头部损伤标签.csv&#39;)
df2 = pd.read_csv(&#39;C:/Users/Lenovo/Desktop/EEG 处理材料/1c_p300 频谱图图像/更新的头部受伤标签 2.csv&#39;)

df = pd.concat([df1, df2], axis=0).reset_index(drop=True)

df[&#39;标签&#39;] = df[&#39;标签&#39;].astype(str)

train_df，test_df = train_test_split（df，test_size = 0.2，random_state = 42）

train_df[&#39;标签&#39;] = train_df[&#39;标签&#39;].astype(str)
test_df[&#39;标签&#39;] = test_df[&#39;标签&#39;].astype(str)

train_datagen = ImageDataGenerator(重新缩放=1./255)
test_datagen = ImageDataGenerator（重新缩放=1./255）

train_generator = train_datagen.flow_from_dataframe(
    数据框=train_df，
    x_col=&#39;图像路径&#39;,
    y_col=&#39;标签&#39;,
    目标大小=(1000, 800),
    批量大小=32，
    class_mode=&#39;二进制&#39;）

test_generator = test_datagen.flow_from_dataframe(
    数据框=test_df，
    x_col=&#39;图像路径&#39;,
    y_col=&#39;标签&#39;,
    目标大小=(1000, 800),
    批量大小=32，
    class_mode=&#39;二进制&#39;）

直到这一部分，它给我的输出为：
找到 186 个经过验证的图像文件名，属于 2 个类别。
找到 47 个经过验证的图像文件名，属于 2 个类别。
#创建模型
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、Flatten、Dense、Dropout

模型=顺序（[
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;, input_shape=(1000, 800, 3)),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（256，激活=&#39;relu&#39;），
    辍学（0.5），
    密集（1，激活=&#39;sigmoid&#39;）
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

模型.summary()

输出：
模型摘要：
#训练模型
历史 = model.fit(
    火车发电机，
    steps_per_epoch=train_generator.n // train_generator.batch_size,
    纪元=5，
    验证数据=测试生成器，
    validation_steps=test_generator.n // test_generator.batch_size
）

输出：
模型训练输出：
模型训练代码后，我的内核自动死亡，显示 ResourceExhausted 错误，我该如何解决这个问题？我也尝试在 Google colab 中运行，也遇到了类似的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78126036/deep-learning-model-training</guid>
      <pubDate>Fri, 08 Mar 2024 07:12:06 GMT</pubDate>
    </item>
    <item>
      <title>物体检测（Opencv）</title>
      <link>https://stackoverflow.com/questions/78125895/object-detectionopencv</link>
      <description><![CDATA[我是机器学习和计算机视觉领域的新手，
我尝试过精简版的 SSD MobileNet 模型来检测对象，但我的主要动机是
应该检测未经训练的对象，如果该对象在我们的数据集中不可用，那么它应该被检测为未知对象。
我该怎么做。请帮助我。
我需要的解决方案是我的模型应该将对象检测为未知对象，而无需机器学习。
我不想认出这个物体。只是应该检测到它。]]></description>
      <guid>https://stackoverflow.com/questions/78125895/object-detectionopencv</guid>
      <pubDate>Fri, 08 Mar 2024 06:34:43 GMT</pubDate>
    </item>
    <item>
      <title>训练 ViT 训练损失稳定，但验证曲线振荡</title>
      <link>https://stackoverflow.com/questions/78125693/stable-training-loss-but-oscillating-validation-curves-training-vit</link>
      <description><![CDATA[我正在修改后的视觉变换器模型上训练大约 1000 个通道的成像数据。
我的样本数量有限，因为我只有 10 个可用图像 (~200x200x1000)，我已将其中的图像转换为补丁，生成约 15k 个补丁，每个补丁都有关联的标签和平衡数据集。我还在通道上执行了 PCA 以降低维度。当前集包含 6 个训练、2 个验证和 2 个测试。
目前，这些是我迄今为止最好结果的训练和验证曲线。为这些结果生成的补丁大小为 8x8x25，重叠率为 50%：
训练损失
val 准确度
val 平衡精度
val f1
价值损失
我的问题是，了解如何推进这些结果。模型似乎是根据验证指标进行训练和学习的，但是，它波动很大，我不知道如何缓解这种情况。
我尝试过的：

不同的补丁大小（4x4、8x8、16x16 等）
不同的通道大小（8、16、32 等...）
生成补丁时的不同重叠（20%、50% 等）
降低学习率
降低权重衰减
平衡数据集

这些是我尝试减轻波动并提高整体准确性的方法。然而，它反而导致性能较差，例如在训练早期趋于稳定和更加极端的波动。]]></description>
      <guid>https://stackoverflow.com/questions/78125693/stable-training-loss-but-oscillating-validation-curves-training-vit</guid>
      <pubDate>Fri, 08 Mar 2024 05:29:54 GMT</pubDate>
    </item>
    <item>
      <title>如何根据当前时间获取前n天同一时间的数据</title>
      <link>https://stackoverflow.com/questions/78125442/how-to-get-data-for-the-same-time-of-the-previous-n-days-base-on-current-time</link>
      <description><![CDATA[示例
导入 pandas 作为 pd
data1 = {&#39;时间&#39;: [&#39;2020-01-01 00:00:00&#39;, &#39;2020-01-01 04:00:00&#39;, &#39;2020-01-01 08:00:00&#39;, &#39;2020- 01-01 12:00:00&#39;, &#39;2020-01-01 16:00:00&#39;, &#39;2020-01-01 20:00:00&#39;, &#39;2020-01-02 00:00:00&#39;, &#39; 2020-01-02 04:00:00&#39;, &#39;2020-01-02 08:00:00&#39;, &#39;2020-01-02 12:00:00&#39;, &#39;2020-01-02 16:00:00&#39; , &#39;2020-01-02 20:00:00&#39;, &#39;2020-01-03 00:00:00&#39;, &#39;2020-01-03 04:00:00&#39;, &#39;2020-01-03 08:00: 00&#39;, &#39;2020-01-03 12:00:00&#39;, &#39;2020-01-03 16:00:00&#39;, &#39;2020-01-03 20:00:00&#39;, &#39;2020-01-04 00: 00:00&#39;, &#39;2020-01-04 04:00:00&#39;], &#39;类别&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b &#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;], &#39;nums&#39;: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] }
df = pd.DataFrame(data1)


&lt;小时/&gt;
我有一个如图所示的数据
我想要 pd.groupby(&#39;category&#39;)，然后获取前 n 个同一时间的数据（n 可以是 1,2 ..依此类推，我们可以假设 n=1）天基于当前时间组
如果不需要分组操作，可以通过 (data.rolling(window=&#39;1D&#39;,lined=&#39;both&#39;,on=&#39;time&#39;).apply(lambda x:x[0])) 获取与 pandas，但是，如果需要 groupy，我不知道该怎么做
总之，我希望在每个组中都能得到它。
期待您的帮助！！]]></description>
      <guid>https://stackoverflow.com/questions/78125442/how-to-get-data-for-the-same-time-of-the-previous-n-days-base-on-current-time</guid>
      <pubDate>Fri, 08 Mar 2024 03:49:02 GMT</pubDate>
    </item>
    <item>
      <title>这段代码有问题吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78125395/is-there-a-problem-in-this-piece-of-code</link>
      <description><![CDATA[机器学习，Python
model.add(LSTM(units=50,activation=&#39;relu&#39;,return_sequences=True,input_shape=(x_train.shape[1],1)))

无法访问成员“shape”对于类型“列表[未知]”构件“形状”未知]]></description>
      <guid>https://stackoverflow.com/questions/78125395/is-there-a-problem-in-this-piece-of-code</guid>
      <pubDate>Fri, 08 Mar 2024 03:29:16 GMT</pubDate>
    </item>
    <item>
      <title>siann的解决方案有一个问题： ValueError: Variable <tf.Variable 'u/bias:0' shape=(1,) dtype=float64> has `None` forgradient</title>
      <link>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</link>
      <description><![CDATA[使用scinn求解偏微分方程时出现问题，结果显示：
&lt;块引用&gt;
ValueError：变量 渐变有“无”。请确保您的所有操作都定义了梯度（即可微分）。常见的无梯度操作：K.argmax、K.round、K.eval。

导入数学
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 siann 导入为 sn
从 siann.utils.math 导入 diff、sign、sin、cos、tan、exp、sqrt、pow


亩=0.20
罗 = 1000
xE = 21*1000000000
G = xE/(2*(1 + mu))
cp = math.sqrt(xE*(1 - mu)/(rho*(1 + mu)*(1 - 2*mu)))
r0 = 2.5
xdb = 100/1000
xdp = 2.5*100/1000
ρ0 = 1000
xD = 4000
SB = 4000/1000
r0 = 3.0
b = 2.0
阿尔法 = 2000

# 计算A0
定义 A0():
    term1 = xdb/(8*sb)*rho0*xD**2
    项 2 = (xdp/xdb)**2.2
    返回第 1 项/第 2 项

# 待解变量
r = sn.Variable(&#39;r&#39;, dtype=&#39;float64&#39;)
z = sn.Variable(&#39;z&#39;, dtype=&#39;float64&#39;)
t = sn.Variable(&#39;t&#39;, dtype=&#39;float64&#39;)
u = sn.Functional(&#39;u&#39;, [r, z, t], 4*[40], &#39;tanh&#39;)

# 偏微分方程
PDE1= diff(u,r,阶=2)+1/r*diff(u,r)+diff(u,z,阶=2)-1/cp*diff(u,t,阶=2)


＃边界条件
公差=0.0000001
BC1= (1-符号(t-TOL))*(1-符号(r-r0-TOL))*(diff(u,z))
BC2=(1+符号(z-TOL))*(1-符号(z-b-TOL))*(1-符号(r-r0-TOL))*(xE/(1+mu)*(mu/( 1-2*mu)*(diff(u,r,阶=2)+diff(u,r)/r+diff(u,z,阶=2))+diff(u,r,阶=2) )-A0()*exp(-1*alpha*t))

# 训练和验证模型
m = sn.SciModel([r,z,t], [PDE1, BC1,BC2])
r_data,z_data,t_data = np.meshgrid(
    np.linspace(r0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 100)
）
 
# 这一步出错了
h = m.train([r_data,z_data,t_data], 3*[&#39;零&#39;],learning_rate=0.002, epochs=1000, verbose=0)

r_test,z_test ,t_test = np.meshgrid(
    np.linspace(0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 80)
）
u_pred = u1.eval(m, [r_test,z_test ,t_test])

图 = plt.figure(figsize=(3, 4))
plt.pcolor(r_test, z_test, u_pred, cmap=&#39;地震&#39;)
plt.xlabel(&#39;r&#39;)
plt.ylabel(&#39;z&#39;)
plt.colorbar()

我试图解决它，然后在 h = m.train(...) 步骤出现了 ValueError。]]></description>
      <guid>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</guid>
      <pubDate>Fri, 08 Mar 2024 03:00:25 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 Mbed 编译过程中的问题？（深度明智_conv.cc）</title>
      <link>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</link>
      <description><![CDATA[我正在使用tinyML 书学习机器学习。
我正在尝试 Mbed 编译，但它不起作用。
问题情况如下：
本书提出了以下流程。
make -f tensorflow/lite/micro/tools/make/Makefile \
TARGET=mbed TAGS=“cmsis-nn disco_f746ng”生成_微_语音_mbed_项目

更改目录。
cd tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed

配置 Mbed 项目根目录。
mbed 配置根目录。

MBed 部署
mbed 部署

修改 Mbed 配置文件以使用 C++11。
python3 -c &#39;导入文件输入，glob;
对于 glob.glob(“mbed-os/tools/profiles/*.json”) 中的文件名：
    对于 fileinput.input(filename, inplace=True) 中的行：
        print(line.replace(&quot;\&quot;-std=gnu++98\&quot;&quot;,&quot;\&quot;-std=c++11\&quot;, \&quot;-fpermissive\&quot;&quot;; ))&#39;


并编译
mbed 编译 -m DISCO_F746NG -t GCC_ARM

但是，在部署过程中遇到了一些问题。在部署过程中，出现了问题。在寻找解决方案时，我发现了修改 make 命令的建议，如下所示。
make -f tensorflow/lite/micro/tools/make/Makefile \
TARGET=mbed TAGS=“CMSIS-NN disco_f746ng”生成_微_语音_mbed_项目

修改后，我按照同样的方式进行了编译过程，但遇到了以下错误。
编译[82.7%]：深度明智_conv.cc
[错误] heightwise_conv.cc@178,9：从“int”到“const cmsis_nn_dims*”的无效转换[-fpermissive]
[错误] heightwise_conv.cc@178,22：从“int”到“const cmsis_nn_dims*”的无效转换[-fpermissive]
[错误] heightwise_conv.cc@178,49：函数“int32_t arm_depthwise_conv_s8_opt_get_buffer_size(const cmsis_nn_dims*, const cmsis_nn_dims*)”的参数太多
[错误] heightwise_conv.cc@184,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@195,9: &#39;ARM_MATH_SUCCESS&#39; 未在此范围内声明；您的意思是“ARM_MATH_DSP”吗？
[错误] heightwise_conv.cc@184,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@200,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@212,9: &#39;ARM_MATH_SUCCESS&#39; 未在此范围内声明；您的意思是“ARM_MATH_DSP”吗？
[错误] heightwise_conv.cc@200,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@272,5: &#39;arm_depthwise_conv_u8_basic_ver1&#39; 未在此范围内声明；您的意思是“arm_depthwise_conv_fast_s16”吗？
[错误]“_queue.SimpleQueue”对象没有属性“queue”
[mbed] 错误：“/usr/bin/python3”返回错误。
       代码：1
       路径：“/home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed”
       命令：“/usr/bin/python3 -u /home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed/mbed-os/tools/make .py -t GCC_ARM -m DISCO_F746NG --源 . --build ./BUILD/DISCO_F746NG/GCC_ARM”
       提示：您可以使用“-v”重试最后一个命令详细输出标志
---


我无法解决这个问题。我已经2天无法解决这个问题了。我预先感谢任何可以提供帮助的人。
[错误]“_queue.SimpleQueue”对象没有属性“queue”

我看到信息表明上述错误可以通过使用Python 2.7来解决。但是，我不确定这是否允许使用 CLI1。因为ARM建议CLI1需要Python 3.7.x版本。]]></description>
      <guid>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</guid>
      <pubDate>Fri, 08 Mar 2024 02:44:08 GMT</pubDate>
    </item>
    <item>
      <title>如何用奇数样本大小批量训练神经网络？</title>
      <link>https://stackoverflow.com/questions/78119974/how-to-train-nn-in-batches-with-odd-examples-size</link>
      <description><![CDATA[我是神经网络领域的新手，正在使用 pytorch 进行一些训练。
我决定做一个简单的普通神经网络。
我使用了一个包含 2377 个数字特征和 6277 个示例的个人数据集。
我的第一次尝试是让神经网络预测每个示例，因此伪代码如下所示
对于范围内的 i(...)：
    X = ... # 特征
    y = ... # 结果
    y_pred = 模型(X[i])
    损失=标准(y_pred, y)

    y_pred.size # [1,1]
    y.尺寸#[1,1]

每个时期大约需要 10 秒，我决定使用小批量来改进它。
所以我在开始时定义了批量大小，Pytorch 中的神经网络是这样定义的
&lt;前&gt;&lt;代码&gt;batch_size = 30
n_inputs = X.size[1] #2377

## 2 个隐藏层
模型 = nn.Sequential(
    nn.Linear(n_inputs, 1024),
    ReLU(),
    nn.线性(1024, 512),
    ReLU(),
    nn.线性(512, 356),
    ReLU(),
    nn.Linear(356,batch_size),
    ReLU(),
）

然后我分批进行训练
对于范围（5）内的纪元：
    总损失 = 0
    排列 = torch.randperm(X.size()[0])
    对于范围内的 i（0，X.size（）[0]，batch_size）：
        优化器.zero_grad()
        索引 = 排列[i:i+batch_size]
        batch_x, batch_y = x[索引], y[索引]

        ypred = 模型(batch_x)
        损失=标准(ypred,batch_y)
        总损失 += loss.item()
        
        ## 更新权重
        loss.backward()
        优化器.step()

现在的问题是我的神经网络总是输出 100 个值但最后的批量大小可能会有所不同。
事实上，如果我选择 100 作为批量大小，最后一批将由 77 个示例组成 (6277%100)。
我确信有一种方法可以解决这个问题，并且我的结构中有一个错误，但我看不到它。
您能帮助我概括批量训练以处理任意数量的示例和批量大小吗？]]></description>
      <guid>https://stackoverflow.com/questions/78119974/how-to-train-nn-in-batches-with-odd-examples-size</guid>
      <pubDate>Thu, 07 Mar 2024 08:58:57 GMT</pubDate>
    </item>
    <item>
      <title>用Python代码编写的RNN反向传播公式[关闭]</title>
      <link>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</link>
      <description><![CDATA[鉴于常规 RNN 网络反向传播的文本描述，我无法将给定的公式与此处的 python 代码关联起来：
https://dennybritz.com/posts/ wildml/recurrent-neural-networks-tutorial-part-3/
另请参阅此屏幕截图。
你能澄清一下吗？
为我应用链式法则与给定的 python 代码不匹配。如果我没记错的话，给出：
f(x) = tanh(x)
然后：
df/dx = 1 - tanh^2(x)
但是我没有看到给定的 python 代码对 tanh 函数的任何使用。]]></description>
      <guid>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</guid>
      <pubDate>Mon, 04 Mar 2024 16:16:44 GMT</pubDate>
    </item>
    <item>
      <title>学习一种双线性形式的矩阵函数</title>
      <link>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</link>
      <description><![CDATA[我正在考虑对标量函数 f:R^n-&gt;R 进行回归的问题，其中我有一组训练样本 (x1,y1),...,(xN,yN)，其中 yi = f(xi)。
我知道原则上我可以应用任何神经网络架构来对此函数进行回归，但是我想利用我了解的属性来设计网络。
准确地说，我知道 f(x)= x^TA(x)x$ 对于 nxn 矩阵值函数 A(x)，我不太清楚，但我知道它是对称且正定的。
我认为，既然我知道函数的这种结构，那么应用“标准”函数并不是一种有效的方法。架构来解决这个问题。这个问题实际上看起来像是在 R^n 上寻找并逼近度量的问题。
由于 A(x) 是对称正定的，对于未知的矩阵值函数 B(x)，我想将其重写为 A(x) = B(x)^TB(x)。因此，函数 f(x) 以更简单的方式重写：f(x) = |B(x)x|^2，其中唯一的未知数是矩阵函数 B(x)。
现在，是否有一些已知的架构非常适合这种情况？
使用 B(x) 常数生成训练数据，我已经很容易地解决了这个问题，定义了要优化的权重，并且效果很好。但是，如果矩阵 B(x) 与 x 相关，我不完全确定如何继续。
到目前为止，我已经实现了一个从 R^n 到 R^{n^2} 的神经网络，其中输出被重新整形为 nxn 矩阵 B(x) 来学习。然而，这仅适用于简单的 B(x)，对我来说仍然不清楚原因。]]></description>
      <guid>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</guid>
      <pubDate>Fri, 28 May 2021 13:51:58 GMT</pubDate>
    </item>
    </channel>
</rss>