<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Mar 2024 00:57:53 GMT</lastBuildDate>
    <item>
      <title>使用 sklearn，其中标签是多个输入的组合</title>
      <link>https://stackoverflow.com/questions/78150382/using-sklearn-where-the-label-a-combination-of-multiple-inputs</link>
      <description><![CDATA[我正在对分类标签相互关联的数据集进行数据分析。
我的标签跟踪实验条件。
就我而言，标签跟踪两种化学物质的组合浓度，这些化学物质产生由 n 个特征测量的输出。
使用分类标签代替化学物质组合的浓度是最佳做法，还是有更好的方法？
以下是分类标签与其代表的现实生活条件之间的转换示例。

&lt;标题&gt;

条件
化学1
化学2


&lt;正文&gt;

1
1
0


2
2
0


3
0
1


4
0
2


5
1
1


6
1
2


]]></description>
      <guid>https://stackoverflow.com/questions/78150382/using-sklearn-where-the-label-a-combination-of-multiple-inputs</guid>
      <pubDate>Tue, 12 Mar 2024 22:39:35 GMT</pubDate>
    </item>
    <item>
      <title>pytorch sdpa 与相对位置嵌入的兼容性</title>
      <link>https://stackoverflow.com/questions/78150102/pytorch-sdpa-compatibility-with-relative-positional-embeddings</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78150102/pytorch-sdpa-compatibility-with-relative-positional-embeddings</guid>
      <pubDate>Tue, 12 Mar 2024 21:22:17 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中，如何使用图像中的对象和相应标签创建数据集</title>
      <link>https://stackoverflow.com/questions/78149741/in-tensorflow-how-do-i-make-a-dataset-with-objects-corresponding-labels-from-a</link>
      <description><![CDATA[我有一个符号键，我正在寻找有关提取这些符号及其文本作为数据集标签的方法的建议；稍后用于匹配工程图上的这些符号。
我只是在寻找正确方向的推动力，我有 Tensorflow 的经验；只要非常确定如何解决这个问题即可。
简单示例
https://i.stack.imgur.com/5RBau.png 
复杂示例
https://i.stack.imgur.com/pRLWf.png 
正在寻找正确方向的推动力，感谢大家的帮助！
我没有尝试太多，因为我很困惑首先要尝试什么，我以前没有使用过这样的文档。]]></description>
      <guid>https://stackoverflow.com/questions/78149741/in-tensorflow-how-do-i-make-a-dataset-with-objects-corresponding-labels-from-a</guid>
      <pubDate>Tue, 12 Mar 2024 19:57:15 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 Python 中使用多处理库，但我遇到了它冻结但不抛出错误的问题</title>
      <link>https://stackoverflow.com/questions/78149659/trying-to-use-the-multiprocessing-library-in-python-but-i-am-running-into-issues</link>
      <description><![CDATA[所以我在咨询chatgpt后编写了这段代码，它在很大程度上有效：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score
来自多处理导入池，cpu_count

def评估_子集（模型，评分，X_in，y_in，子集=无）：
    #model = RandomForestClassifier(n_estimators=100, random_state=42)
    列表分数 = []
    对于 skf.split(X_in, y_in) 中的 train_index、test_index：
        X_train, y_train = X_in.values[train_index], y_in.values[train_index]
        X_test, y_test = X_in.values[test_index], y_in.values[test_index]
        model.fit(X_train[:, 子集], y_train)
        y_pred = model.predict(X_test[:, 子集])
        list_scores.append(评分(y_test, y_pred))
    返回 np.mean(list_scores)

def stepwise_add_selection（模型，评分，X_in，y_in，n_processes =无）：
    如果 n_processes 为 None：
        n_processes = cpu_count()

    池 = 池（进程=n_进程）
    剩余特征 = 设置（范围（X_in.shape[1]））
    选定的特征 = []
    最佳准确度 = 0
    而剩余特征：
        结果=[]
        对于剩余特征中的特征：
            子集 = 选定的特征 + [特征]
            results.append(pool.apply_async(evaluate_subset, args=(模型, 评分, X_in, y_in, 子集)))
        精度 = [结果中的 res.get()]
        best_index = np.argmax(精度)
        print(“当前最佳”)
        打印（最大（精度））
        print(&quot;上一个最佳值&quot;)
        打印（最佳准确度）
        打印（选定的特征）
        如果 best_accuracy &lt;最大（精度）：
            selected_features.append(列表(剩余特征)[(best_index)])
            最佳准确度 = 准确度[最佳索引]
        别的：
            休息
        
    池.close()
    池.join()

    返回selected_features，best_accuracy


但是，我正在尝试创建另一个删除功能的贪婪搜索：
&lt;前&gt;&lt;代码&gt;
def stepwise_feature_removal（模型，评分，X_in，y_in，n_processes =无）：
    剩余特征 = 设置（范围（X_train.shape[1]））
    选定的特征 = 列表（剩余特征）
    best_accuracy=evaluate_subset（模型，评分，X_in，y_in，selected_features）
    print(&quot;初始准确度分数：&quot;, best_accuracy)
    而剩余特征：
        结果=[]
        最坏的特征 = 无
        池 = 池（进程=n_进程）
        对于剩余特征中的特征：
            temp_features = 选定的_features[:]
            temp_features.remove（功能）
            results.append(pool.apply_async(evaluate_subset, args=(模型, 评分, X_in, y_in, temp_features)))
        池.close()
        池.join()
        精度 = [结果中的 res.get()]
        best_index = np.argmax(精度)
        如果准确度[best_index] &gt;最佳准确度：
            最佳准确度 = 准确度[最佳索引]
            最坏的特征 = temp_features[最佳索引]
        print(“当前最佳”)
        打印（准确度）
        print(&quot;上一个最佳值&quot;)
        打印（最佳准确度）
        print(&quot;已删除的功能：&quot;)
        打印（最差特征）

        如果最坏的特征不是无：
            selected_features.remove(worst_feature)
            剩余特征.删除（最差特征）
        别的：
            休息

    返回selected_features，best_accuracy

在功能删除方法中，我遇到的问题是程序停止运行。它并不表明存在错误或任何情况。我添加了 pool.close() 和 pool.join() 但它没有解决问题。
提前致谢。
我正在尝试编写一个贪婪特征缩减函数，其工作原理与贪婪特征添加函数类似。不知道为什么会结冰，所以这也会有帮助。
编辑：我应该澄清当我使用 imblearn 包运行此代码时出现的问题。如果没有 imblearn，可能会发生多处理并且程序会运行。
def use_pipeline(clf, resample = False):
    如果重新采样==假：
        管道 = make_pipeline(MinMaxScaler(), clf)
    别的：
        管道= make_pipeline（重新采样，MinMaxScaler（），clf）
    回水管
sm = SMOTE（随机状态 = 38）
pipeline_clf = use_pipeline(clf1, sm)
stepwise_feature_removal(pipe_clf, matthews_corrcoef, X_train, y_train, 15)
]]></description>
      <guid>https://stackoverflow.com/questions/78149659/trying-to-use-the-multiprocessing-library-in-python-but-i-am-running-into-issues</guid>
      <pubDate>Tue, 12 Mar 2024 19:36:45 GMT</pubDate>
    </item>
    <item>
      <title>Amazon Sagemaker 在后台从 jupyter 笔记本运行代码</title>
      <link>https://stackoverflow.com/questions/78149372/amazon-sagemaker-run-code-from-jupyter-notebook-in-background</link>
      <description><![CDATA[我正在 Amazon Sagemkaer 笔记本实例上运行代码（在普通的 jupyter 笔记本中，而不是 jupyterLab）。

如何在后台运行代码并关闭浏览器选项卡？当我关闭 jupyter 笔记本选项卡时，程序停止，我想避免这种情况。我读到我不应该在笔记本本身中进行处理，而应该使用 Sagemaker 处理作业。如何在更高的 i 上运行如下所示的简单代码单元

df_new[&#39;predicted_values&#39;] = df_original.progress_apply(lambda x: LLM_pretrained_model.predict( x[&#39;comment_body&#39;] )


12 小时后，内核崩溃，提示我需要再次登录。我怎样才能避免这种情况？由于我的数据量较大，程序至少需要 28 小时才能运行

是否可以从 sagemaker jupyter 笔记本（不是 jupyterLab 笔记本）将代码推送到 GitHub？

]]></description>
      <guid>https://stackoverflow.com/questions/78149372/amazon-sagemaker-run-code-from-jupyter-notebook-in-background</guid>
      <pubDate>Tue, 12 Mar 2024 18:39:54 GMT</pubDate>
    </item>
    <item>
      <title>结合区块链和机器学习可以实现什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78149327/what-can-i-implement-combining-blockchain-and-machine-learning</link>
      <description><![CDATA[我想知道我们如何使用区块链和机器学习，也许有人可以给我一个项目的想法，我可以实施它来制作我的研究项目。我想结合机器学习 + 区块链（关于网络安全领域）。如果您能给我一些论文或 github 相关代码的想法，那就太好了。
对于这个项目我想学习：

区块链基础知识并实现一些区块链
学习机器学习并以某种方式将机器学习集成到该区块链中
]]></description>
      <guid>https://stackoverflow.com/questions/78149327/what-can-i-implement-combining-blockchain-and-machine-learning</guid>
      <pubDate>Tue, 12 Mar 2024 18:31:34 GMT</pubDate>
    </item>
    <item>
      <title>多类不平衡数据集预处理问题</title>
      <link>https://stackoverflow.com/questions/78148016/multiclass-imbalance-dataset-preprocessing-problem</link>
      <description><![CDATA[在预处理我面临的数据集时
ValueError：目标是多类，但平均值=&#39;二进制&#39;。请选择其他
平均设置，[无、&#39;微观&#39;、&#39;宏观&#39;、&#39;加权&#39;]之一。

如何解决？
https://colab.research.google.com/drive/1O_fxtFLThjgC2KrpDTAzwLGoxGPcRNKj ?usp=共享
我会请专家去检查一下我在那里犯了什么错误。
我尝试使用迄今为止学到的知识进行预处理部分。]]></description>
      <guid>https://stackoverflow.com/questions/78148016/multiclass-imbalance-dataset-preprocessing-problem</guid>
      <pubDate>Tue, 12 Mar 2024 14:42:42 GMT</pubDate>
    </item>
    <item>
      <title>“list”对象没有属性“lower”无法解决这个问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78147467/list-object-has-no-attribute-lower-cant-solve-this</link>
      <description><![CDATA[这是我的代码
words = [stemmer.stem(w) for w in Words if w != &quot;?&quot;]
单词=排序（列表（集合（单词）））

之前，我使用了 stemmer.stem(w.lower()) 但遇到了相同的错误，因此将其删除。仍然显示：
第207行，在stem中
    字=字.lower()
           ^^^^^^^^^^
AttributeError：“列表”对象没有属性“较低”

它是在stem .lower()中实现的，我该怎么办？
我从代码中删除了.lower()，但stem在内部使用了.lower()，因此无法对此执行任何操作。我该如何修复它？]]></description>
      <guid>https://stackoverflow.com/questions/78147467/list-object-has-no-attribute-lower-cant-solve-this</guid>
      <pubDate>Tue, 12 Mar 2024 13:19:45 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 1 个特征，但 DecisionTreeClassifier 期望 416809 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/78146852/valueerror-x-has-1-features-but-decisiontreeclassifier-is-expecting-416809-fea</link>
      <description><![CDATA[我正在制作一个简单的程序，给出提示后，将预测相关的情绪。我有一个 CSV 文件形式的数据集，其中包含 416809 个项目，其中包含如下示例：

&lt;标题&gt;

id
文本
标签


&lt;正文&gt;

0
我只是感到非常无助和心情沉重
4


1
我很享受能够无精打采地放松身心，坦率地说，在大学结束和世博会结束的最后几周之后，我最近开始发现自己感觉有点无精打采，这从来都不是一件好事
0



（标签是 0-5 之间的数字，对应六种情绪之一）
我的代码如下：
print(“正在加载模块...”)
将 pandas 导入为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.preprocessing 导入 LabelEncoder

print(&quot;正在加载数据...&quot;)
data = pd.read_csv(&#39;data/emotions.csv&#39;) #加载数据集到data变量
X = data[&quot;text&quot;] #将X值设置为所有指定列的表
y = data[“label”] #将 y 值设置为答案列

le = LabelEncoder() #对标签进行编码
le.fit(y)
编码_y = le.transform(y)
拟合(X)
编码_X = le.transform(X)

print(&quot;训练模型...&quot;)
模型 = DecisionTreeClassifier()
model.fit([encoded_X],[encoded_y]) #训练模型
提示=输入（“输入提示：”）

编码提示 = le.transform([提示])

预测 = model.predict([encoded_prompt]) #predict

我在最后一行收到错误：
ValueError：X 有 1 个特征，但 DecisionTreeClassifier 期望 416809 个特征作为输入。

我期望的是 predictions 变量是一个数字或包含 0-5 之间的单个数字的列表，并让它打印代码中的最后一行。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78146852/valueerror-x-has-1-features-but-decisiontreeclassifier-is-expecting-416809-fea</guid>
      <pubDate>Tue, 12 Mar 2024 11:47:03 GMT</pubDate>
    </item>
    <item>
      <title>深度学习 (LSTM) 项目实习生 [已关闭]</title>
      <link>https://stackoverflow.com/questions/78146798/project-intern-working-on-deep-learnning-lstm</link>
      <description><![CDATA[我使用深度学习开发了单词预测模型。我已经保存并加载了我的模型，但我想知道如何使用该模型进行预测，而无需下次运行纪元
我已经开发了下一个单词预测模型，并对它进行了训练，然后保存了它，但现在我想重用该模型，而无需再次运行纪元]]></description>
      <guid>https://stackoverflow.com/questions/78146798/project-intern-working-on-deep-learnning-lstm</guid>
      <pubDate>Tue, 12 Mar 2024 11:40:33 GMT</pubDate>
    </item>
    <item>
      <title>在 TensorFlow 推荐模型中初始化 FactorizedTopK 时出现 ValueError</title>
      <link>https://stackoverflow.com/questions/78144515/valueerror-when-initializing-factorizedtopk-in-tensorflow-recommenders-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78144515/valueerror-when-initializing-factorizedtopk-in-tensorflow-recommenders-model</guid>
      <pubDate>Tue, 12 Mar 2024 03:28:18 GMT</pubDate>
    </item>
    <item>
      <title>预测分位数与梯度增强回归相交</title>
      <link>https://stackoverflow.com/questions/78140825/prediction-quantiles-intersect-from-gradient-boosted-regression</link>
      <description><![CDATA[我正在尝试构建一个回归模型，该模型接收各种类型的产品和市场信息，对数据进行转换，并在一天中定期预测产品的价格。我希望能够预测分位数置信带，以帮助我的团队根据模型的预测做出决策。我遵循了 scikit-learn 文档中的示例&lt; /code&gt;，但我发现这些回归器产生的预测有时会相交，例如有时P50预测大于P75预测或小于P25预测。
查看此处突出显示的图表中的错误。
即使使用更宽的频段（包括 P95 和 P05），这个问题仍然存在。尽管数据集比我正在使用的数据集简单得多，但我已经能够毫无问题地重现链接的示例。
下面的代码代表了该问题的可重现示例，并带有生成的数据集：
# 导入和定义
将 pandas 导入为 pd
将 numpy 导入为 np
从 sklearn.ensemble 导入 HistGradientBoostingRegressor
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 make_regression

X,y = make_regression(
    n_样本 = 14000,
    n_特征 = 39,
    n_targets = 1,
    随机状态 = 684
）
rng = np.random.default_rng()
bools = rng.integers(低=0，高=2，大小=14000)
X = pd.concat([pd.DataFrame(X),pd.Series(bools, name=39)], axis=1)

# 进行测试/训练分割和模型字典
X_train, X_test, y_train, y_test = train_test_split(
    X、y、test_size=0.1、random_state=59654
）
型号={}

for alpha in [0.25, 0.5, 0.75]: # HistGradientBoostingRegressor model - Early_stopping = False 有助于解决问题，但不能解决问题
    hgbr = HistGradientBoostingRegressor(
        随机状态=86184，
        早期停止=假，
        max_iter=100, # 通常在1000左右，例如减少
        损失=“分位数”，
        分位数 = 阿尔法，
        分类特征 = [39],
    ）

    # 将最佳模型添加到字典中
    models[f&quot;P{alpha*100:02.0f}&quot;] = hgbr.fit(X_train, y_train.ravel())


任何帮助或建议将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78140825/prediction-quantiles-intersect-from-gradient-boosted-regression</guid>
      <pubDate>Mon, 11 Mar 2024 13:05:06 GMT</pubDate>
    </item>
    <item>
      <title>将 Android ML-Kit 鸟类分类器与 Python 结合使用</title>
      <link>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</link>
      <description><![CDATA[我测试了 ML Kit 中的 Android Vision 快速入门应用程序。正如您在图片中看到的，这里可以进行对象跟踪。现在我正在使用 Python 尝试相同的模型 (bird_classifier.tflite)。这非常有效，但是我如何在这里获取边界框呢？无论我做什么，反馈都是：该模型仅包含一个张量。但为什么它可以在 Android 应用程序中运行呢？
有人可以给我看一个代码示例吗？

image = Image.fromarray(screenshot)
image_pred = image.resize((宽度,高度), Image.ANTIALIAS)
结果=分类图像（解释器，image_pred）
# TrackingID = 结果[i0][0]
# 分数 = 结果[i0][1]
# 盒子 = ?
]]></description>
      <guid>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</guid>
      <pubDate>Mon, 11 Mar 2024 10:19:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 Huggingface MT5 模型中执行批量编码时会得到不同的嵌入？</title>
      <link>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</link>
      <description><![CDATA[我正在尝试使用 HuggingFace 的 mt5-base 模型对一些文本进行编码。我使用的模型如下所示
从转换器导入 MT5EncoderModel、AutoTokenizer

模型 = MT5EncoderModel.from_pretrained(“google/mt5-base”)
tokenizer = AutoTokenizer.from_pretrained(“google/mt5-base”)

def get_t5_embeddings(文本):
    last_hidden_​​state = model(input_ids=tokenizer(texts, return_tensors=“pt”, padding=True).input_ids).last_hidden_​​state
    pooled_sentence = torch.max(last_hidden_​​state, 暗淡=1)
    返回 pooled_sentence[0].detach().numpy()

当我注意到相同的文本与其自身的余弦相似度分数较低时，我正在做一些实验。我做了一些挖掘，意识到如果我批量进行编码，模型会返回非常不同的嵌入。为了验证这一点，我运行了一个小实验，逐步生成 Hello 的嵌入和 10 个 Hello 的列表。并检查列表中 Hello 和第一个 Hello 的嵌入（两者应该相同）。
对于范围 (1, 10) 内的 i：
    print(i, (get_t5_embeddings([“你好”])[0] == get_t5_embeddings([“你好”]*i)[0]).sum())

这将返回嵌入中相互匹配的值的数量。
结果是这样的：
&lt;前&gt;&lt;代码&gt;1 768
2 768
3 768
4 768
5 768
6 768
7 768
8 27
9 27

每次运行它时，如果批量大小超过 768，就会出现不匹配情况。
为什么我会得到不同的嵌入以及如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</guid>
      <pubDate>Mon, 11 Mar 2024 10:14:53 GMT</pubDate>
    </item>
    <item>
      <title>除了最小-最大归一化和分位数变换之外，是否有任何数据缩放方法可以保持范围在 [0,1] 之间？</title>
      <link>https://stackoverflow.com/questions/76911491/is-there-any-data-scaling-methods-except-for-min-max-normalization-and-quantile</link>
      <description><![CDATA[我一直在从事一个机器学习项目，并且在将其输入到我的模型之前，我一直在尝试扩展功能。我知道最小-最大归一化和分位数变换会缩小 0 到 1 范围内的特征。我想知道是否还有其他缩放方法或方式可以将范围缩小到 0 到 1 之间。]]></description>
      <guid>https://stackoverflow.com/questions/76911491/is-there-any-data-scaling-methods-except-for-min-max-normalization-and-quantile</guid>
      <pubDate>Wed, 16 Aug 2023 07:43:55 GMT</pubDate>
    </item>
    </channel>
</rss>