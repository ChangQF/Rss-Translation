<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 26 Feb 2025 01:18:10 GMT</lastBuildDate>
    <item>
      <title>在随机速度环境中用于RL代理问题的最佳路径查找/计划算法</title>
      <link>https://stackoverflow.com/questions/79468187/best-path-finding-planning-algorithm-to-use-for-rl-agent-problem-in-stochastic-s</link>
      <description><![CDATA[在我的项目中，我有一个环境，代理商在该环境中导航，试图在右侧到达目标线。环境的某些部分比其他部分快（黑暗区域被标记为快速，白色区域标记慢）。我有一个启发式近似值，能够近似机器人的位置（不是很精确，但足够好）并近似其速度。据此，我创建了一个2D状态矩阵，该矩阵具有高空值（深蓝色），对于强制机器人可以非常快，小的正值（0-10，浅蓝色），机器人以足够速度运行，并且在机器人停止并卡住或进展太慢的情况下（红色区域）的负（红色）值（红色区域）。

我正在使用CEM随机选择动作和移动向量来探索环境，并且能够在培训期间获得65％-80％的环境，这已经足够好了，在我到目前为止我测试的所有情况下，我都可以在视觉上进行视觉上的测试。查看到达最终目标线的各种可能的路径：
但是，我想知道一旦我知道我的状态值，进行测试时要使用什么算法。视觉上我总是能够找到一条良好的快速路径，优先考虑完成路径所需的速度和时间，但是我尝试的所有方法是CME还是某种动态值迭代，所有方法都失败了，并且在某些时候代理商最终会得到卡住或经历非常缓慢的部分，例如在此屏幕截图中（绿线是在训练过程中产生的各种路径，橙色是在测试过程中开始的，但随后不遵循正值，而是直接进入未探索或负面的区域）
 
如前所述，我尝试了CME和某些形式的DP，但是您认为这里还有其他算法吗？我想确保它永远不会陷入负面状态，找到优先级速度的最佳途径，最好采取行动前往具有很高比例的积极状态的领域（即一般不接近负面状态），感谢任何提示！]]></description>
      <guid>https://stackoverflow.com/questions/79468187/best-path-finding-planning-algorithm-to-use-for-rl-agent-problem-in-stochastic-s</guid>
      <pubDate>Wed, 26 Feb 2025 00:06:11 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行DeepSeek模型</title>
      <link>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</link>
      <description><![CDATA[我试图根据他们的说明在本地运行DeepSeek，但它不能带来一些愚蠢的错误（我将稍后显示）。
这就是我正在做的。

从此处下载最小型号（3.5GB） noreferrer“&gt; https://huggingface.co/deepseek-ai/deepseek-r1-distill-qwen-1.5b  
按照此处的步骤操作： https://github.com/deepseek-ai/deepseek-v3?tab=readMe-Readme-ov-file#6-how-to-to-to-run-locally  

 2.1获取这个项目
 https://github.com/deepseek-ai/deepseek-ai/deepseek-aiek-v3.git  
 2.2运行码头容器类似于预先创建的卷以放置模型
  docker run  -  gpus all -it -it -name deepSeek01 -rm -mount source = deepSeekv3，target =/root/deepSeekv3 python：3.10 -Slim bash
 
我正在使用python：3.10-slim，因为这里（ https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-how-to-run-locally ）
＆quot&#39; linux只有python 3.10。 Mac和Windows不支持。
 2.3安装最新更新
apt-get Update 
 2.4获取此文件 https://github.com/deepseek-ai/deepseek-v3/blob/main/main/inference/requirements.txt 并安装要求
  pip install -r sumpliont.txt
 
 2.5将模型复制到安装在Docker容器上的音量。这5个文件来自此处 https：// https://huggging.co/deepseek.co/deepseek-co/deepseek-co/deepseek-co/ AI/DeepSeek-R1-Distill-Qwen-1.5b  
  config.json
generation_config.json
模型。系统
tokenizer.json
tokenizer_config.json
 
 2.6在此处编写的模型 https://github.com/deepseek-ai/deepseek-v3?tab=readme-readme-ov-file#model-weights-conversion 通过此命令
  python convert.py-hf-ckpt-path/root/deepSeekv3/source_model -save-path/root/deepSeekv3/converted_model -n-experts 256-model-parelally 16
 
在此步骤中（转换模型）我得到了此错误
  trackback（最近的最新通话）：
  file＆quort＆quort＆quot deepseekv3/inference/convert.py&quot;，第96行，in＆lt; module＆gt;
    main（args.hf_ckpt_path，args.save_path，args.n_experts，args.model_parallel）
  file＆quot＆quot&#39;deepseekv3/inference/convert.py&quot;，第63行，在main中
    主张映射中的密钥
断言
 
因此，基本上，下一步没有意义，因为这是必不可少的步骤。
我的问题：

我做错了什么？
 YouTube上有一些视频，其中DeepSeek与Ollama一起安装了。真的需要吗？我是否应该像他们在此处描述的那样运行它， https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-to-run-locally ？
]]></description>
      <guid>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</guid>
      <pubDate>Tue, 25 Feb 2025 22:14:20 GMT</pubDate>
    </item>
    <item>
      <title>无法获得我重量的原始小数，在某个地方自动四舍五入？</title>
      <link>https://stackoverflow.com/questions/79467839/unable-to-get-the-raw-decimal-of-my-weights-auto-rounding-somewhere</link>
      <description><![CDATA[我正在做一个单层perceptron，我需要让我的模型预测用户是否使用网站上的某些按钮制作t还是l。 RN我正在尝试获得权重和偏见，以便我可以将它们实现到我的网站Pyscript代码中，因为我无法进行网站拟合和预测。但是，每当我试图打印重量时，它们会回到SCI符号。我已经尝试执行reter，但这是由于某种原因无法使用的。有人可以告诉我我要在哪里做错什么？
 导入numpy作为NP
导入大熊猫作为pd
来自sklearn.model_selection导入train_test_split
从Sklearn Import DataSet中
导入matplotlib.pyplot作为PLT

Def Activation_Function（Z）：
    返回np.Where（z＆gt; = 0，1，0）

＃将数据集作为熊猫数据框架
df = pd.read_csv（&#39;triendingdata.csv＆quot;）
df.head（）

#split培训数据到X和Y
x = df.iloc [：，1：]
打印（x）

y = df.iloc [：，0]
打印（y）


#convert y标签进入整数
y = y.map（{&#39;l&#39;：0，&#39;t&#39;：1}）

#Convert X和Y到Numpy数组以进行以后处理
x = x.to_numpy（dtype = np.float64）
y = y.to_numpy（dtype = np.int32）

打印（x）
打印（y）

打印（x.dtype）
打印（y.dtype）

#split培训数据并检查形状。由于数据集不是很大的原因（58个样本，16个功能），进行70/30拆分
x_train，x_test，y_train，y_test = train_test_split（x，y，test_size = 0.3，andural_state = 42）

打印（x_train.shape）
打印（x_test.shape）
打印（y_train.shape）
打印（y_test.shape）

＃适合该模型以重新考虑代码的Pyscript部分的权重和偏差
权重= np .eros（16）*1
偏差= 0

Learning_rate = 0.01
    
对于_范围（1000）：
    对于IDX，x_i enumerate（x_train）：
        
        linear_product = np.dot（x_i，weights） +偏见 
        
        y_pred = activation_function（linear_product）
        
        损失= y_pred -y_train [idx]
                
        权重 -  = Learning_rate *损失 * x_i
        
        偏见 -  = Learning_rate *损失

ret（（重量））
ret（（偏见））
 
，我希望假设我的转换和方程式是准确的，我希望能得到很大的小数。我已经尝试询问朋友，教授和chatgpt，并使用其他方法以及其他方法以正确的方式打印。]]></description>
      <guid>https://stackoverflow.com/questions/79467839/unable-to-get-the-raw-decimal-of-my-weights-auto-rounding-somewhere</guid>
      <pubDate>Tue, 25 Feb 2025 20:47:24 GMT</pubDate>
    </item>
    <item>
      <title>概率扩散模型的推导[封闭]</title>
      <link>https://stackoverflow.com/questions/79467325/derivation-of-probabilistic-diffusion-model</link>
      <description><![CDATA[在扩散模型教程中（ paper ） 22通过将概率过程从$$ q（x_（t）| x_（t-1））$$逆转到$$ q（x_（t-1）| x_t，x_0）$$。我了解个人术语是如何重新重新制定的，但对期望操作和KL分歧并不十分清楚。简而言之，如何将方程式（21）重新重新为等式（22）？？
我试图将方程21扩展到积分形式中，并将概率反向变为积分形式，但仍无法在等式22中获得结果。]]></description>
      <guid>https://stackoverflow.com/questions/79467325/derivation-of-probabilistic-diffusion-model</guid>
      <pubDate>Tue, 25 Feb 2025 16:57:48 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost在400个示例数据集上 - 我的模型过于拟合吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79467253/xgboost-on-400-sample-dataset-is-my-model-overfitting</link>
      <description><![CDATA[我正在处理一个回归任务，我可以从包含400个样本和15个功能的数据集中预测机器的生产持续时间（数小时）。这些功能包括数值和编码的分类变量。我正在使用XGBoost进行回归。
作为结果，我观察到以下指标：

训练R²：〜0.99 
测试R²：〜0.80-0.90 
当我从测试集中删除特定异常值时，其他错误指标（MSE，RMSE，MAE）较低，但Mape几乎保持不变。

学习曲线表明，即使有少量样本，训练分数也接近1.0。验证分数从0.65左右开始，攀升至0.90左右，但差距仍然存在。
学习曲线 
所以我认为我的模型过于适应，我知道这是一个很小的数据集，但这就是我所拥有的。我可以申请什么以减少过度拟合？
我已经尝试使用超参数调整。更改训练/测试拆分。]]></description>
      <guid>https://stackoverflow.com/questions/79467253/xgboost-on-400-sample-dataset-is-my-model-overfitting</guid>
      <pubDate>Tue, 25 Feb 2025 16:30:21 GMT</pubDate>
    </item>
    <item>
      <title>在线性调度程序训练DDPM后，如何实现其他类型的调度程序？</title>
      <link>https://stackoverflow.com/questions/79465469/how-do-i-implement-a-different-type-of-scheduler-after-training-my-ddpm-on-a-lin</link>
      <description><![CDATA[我使用以下代码定义的线性调度程序训练了扩散模型（DDPM）：
 调度程序= ddpmscheduler（
    num_train_timesteps = 1000，
    beta_start = 0.0001，
    beta_end = 0.02，
    beta_schedule =＆quot&#39;线性
）
 
但是，在训练此模型并使用代码加载之后：
  def load_checkpoint（模型，优化器，checkpoint_）：
    ““从检查点加载模型和优化器词典”。“”。
    checkpoint = torch.load（checkpoint_path，map_location =设备）
    model.load_state_dict（checkpoint [&#39;model_state_dict&#39;]）
    Optimizer.load_state_dict（checkpoint [&#39;Optimizer_state_dict&#39;]）
    start_epoch = checkpoint [&#39;epoch&#39;] + 1＃从下一个时代恢复。
    打印（f＆quot“从epoch {start_epoch}＆quot恢复）
    返回start_epoch
 
当我尝试切换到余弦调度程序以使用以下代码推理：
 调度程序= ddpmscheduler（
    num_train_timesteps = 1000，
    beta_schedule =＆quot; 
）
 
我有以下错误：
  notimplementedError：cosine未针对＆lt; class&#39;dribfusers.schedulers.scheduling_ddpm.ddpmm.ddpmscheduler&#39;＆gt; gt;
 
我尝试将DDPM调度程序更改为DDIM调度程序，将代码更改为：
 调度程序= ddimscheduler（
    num_train_timesteps = 1000，
    beta_schedule =＆quot;
）
 
，但我仍然有一个非常相似的错误：
  notimplementedError：cosine未针对＆lt; class&#39;drifusers.schedulers.scheduling_ddim.ddimscheduler&#39;＆gt; gt;
 
我不明白我在做什么错，因为我从多个来源读到，在一个调度程序上训练扩散模型是正常的（在我的情况下是线性），然后更改为推理的另一个调度程序（在我的情况，余弦）。我如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79465469/how-do-i-implement-a-different-type-of-scheduler-after-training-my-ddpm-on-a-lin</guid>
      <pubDate>Tue, 25 Feb 2025 05:14:09 GMT</pubDate>
    </item>
    <item>
      <title>ASR的单方言语音语料库[关闭]</title>
      <link>https://stackoverflow.com/questions/79464867/single-dialect-speech-corpus-for-asr</link>
      <description><![CDATA[我正在进行有关减轻自动语音识别系统中音调偏差的研究。我的研究涉及测试流行的语音助手和创建的ASR系统。但是，我正在努力寻找用于测试和培训数据集的语音数据集。因为我专注于音调，所以我想通过找到一个每个人都具有相同口音/英语方言的数据集来缩小变异性。由于大多数语音语料库都专注于ASR培训的不同演讲者，因此很难遇到这一点。我发现了一个免费的语料库，其中包含来自不列颠群岛的6个方言（）。但是，由于我仅利用一种方言，即使是最坚固的方言也没有提供来自高音的声音的足够数据。我正在寻找大约80-350 Hz的一系列音高。一些录音确实降落在300-350上方的范围内，但只有大约12个，这对我的数据集还不够。我花了无数小时的时间进行搜索，并努力寻找合适的语料库。我没有钱可以花在演讲语料库上，所以有人对我能做什么有任何建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/79464867/single-dialect-speech-corpus-for-asr</guid>
      <pubDate>Mon, 24 Feb 2025 21:45:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Docling库从DOCX文件中提取页面上的HTML内容，以检测页面断路？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79461458/how-to-extract-page-wise-html-content-from-docx-files-using-docling-library-by-d</link>
      <description><![CDATA[我已经成功地使用 docling&gt; docling 和 pypdf2 。这是我当前代码对PDF的作用：

使用PYPDF2将PDF分为单个页面
使用Docling的 Document Converter  将每个页面转换为HTML
用嵌入式图像提取HTML内容
添加元数据（页码，文档ID，文件名）
将所有内容保存到JSON结构

重要说明：我首先将PDF划分为单个页面的原因是因为Docling的 save_as_html（） and  export_to_to_html（）函数在完整的文档对象上工作，而不是在单个页面。要获取页面html内容，我需要创建临时的单页PDF并分别转换一个。
这是我每页获得的示例JSON结构：
  {
    ＆quot“ page”：“第1页”
    ＆quot“ content＆quot”：＆quot＆lt; html内容＆gt;＆quot ,,
    “元数据：{{
        ＆quot“ docutsId”：; quot“ uuid; quot”
        “文件名”：“ document.pdf”
        &#39;page_number＆quot”：1，
        ＆quot“ total_pages”：总计
    }
}
 
现在，我需要为DOCX文件实现相同的功能。据我说，DOCX文件包含标题，页脚和页面断路等元素，我们可以使用这些页面中断将内容分为页面。
我正在使用Docling库进行转换（DOCX到HTML），但是我无法识别或检测到DOCX文件中的页面中断。由于Docling的HTML转换在完整的文档上起作用，因此我需要根据页面断路首先将DOCX内容拆分，类似于我处理PDF的方式。
问题：

如何使用Docling在DOCX文件中检测页面中断？
是否有一种方法可以根据这些页面断开以创建单独的文档对象来拆分DOCX内容？
如果Docling不直接支持此内容，是否还有其他python库，我应该与文档一起使用以检测和拆分页面中断？

我尝试查看文档文档，但找不到有关DOCX文件中处理页面中断的信息。
任何帮助或指导将不胜感激！
我正在使用的相关库：

  docling 
  python-docx （如果需要）
]]></description>
      <guid>https://stackoverflow.com/questions/79461458/how-to-extract-page-wise-html-content-from-docx-files-using-docling-library-by-d</guid>
      <pubDate>Sun, 23 Feb 2025 15:19:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在NLTK中下载Punkt Tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用安装了NLTK库
  PIP安装NLTK
 
使用lib 
 来自nltk.tokenize导入send_tokenize 
send_tokenize（文本）
 
我遇到此错误
  lookuperror： 
****************************************************** ********************
  找不到资源朋克。
  请使用NLTK下载器获取资源：

  ＆gt;＆gt;＆gt;导入NLTK
  ＆gt;＆gt;＆gt; nltk.download（&#39;punkt&#39;）
  
  有关更多信息，请参见：https：//www.nltk.org/data.html

  尝试加载dokenizers/punkt/English.pickle

  搜索：
     - &#39;c：\\用户\\ adars/nltk_data&#39;
     - &#39;c：\\用户\\ adars \\ appdata \\ local \\ program \\ python \\ python310 \\ nltk_data&#39;
     - &#39;c：\\用户\\ adars \\ appdata \\ local \\ program \\ python \\ python310 \\ share \\ nltk_data&#39;
     - &#39;c：\\用户\\ adars \\ appdata \\ local \\ program \\ python \\ python310 \\ lib lib \\ nltk_data&#39;
     - &#39;c：\\用户\\ adars \\ appdata \\漫游\\ nltk_data&#39;
     - &#39;c：\\ nltk_data&#39;
     - &#39;d：\\ nltk_data&#39;
     - &#39;e：\\ nltk_data&#39;
     - &#39;&#39;&#39;
 
因此，为了解决此错误，我尝试了
 导入NLTK
nltk.download（&#39;punkt&#39;）
 
但是我无法下载此软件包，因为每次运行时，我都会收到错误的错误
  [nltk_data]错误加载punkt：＆lt; urlopen错误[WinError 10060] a
[nltk_data]连接尝试失败，因为连接的聚会
[nltk_data]一段时间后没有正确响应，或者
[nltk_data]建立的连接失败，因为连接的主机
[nltk_data]未能响应＆gt;
 
请在这里帮助我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的基本CNN模型不适合分段图像数据集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/65707204/why-is-my-basic-cnn-model-not-overfitting-segmentation-image-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/65707204/why-is-my-basic-cnn-model-not-overfitting-segmentation-image-dataset</guid>
      <pubDate>Wed, 13 Jan 2021 17:49:43 GMT</pubDate>
    </item>
    <item>
      <title>我的培训数据集对于我的神经网络来说太复杂了吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/57224353/is-my-training-data-set-too-complex-for-my-neural-network</link>
      <description><![CDATA[我正在尝试解释我的回归模型的两个图。
 我的机器学习模型的培训错误和验证错误 
我的情况与此相似：训练Keras中的多回归模型的损失值非常大，但是我的MSE和RMSE非常高。
我的建模不足？如果是，我该怎么办才能解决这个问题？
这是我用于解决回归问题的神经网络
  def build_model（）：
模型= keras。
    layers.dense（128，激活= tf.nn.relu，input_shape = [len（train_dataset.keys（））），
    layers.dense（64，激活= tf.nn.relu），
    层。
）））
优化器= tf.keras.optimizers.rmsprop（0.001）

model.compile（loss =&#39;mean_squared_error&#39;，
              优化器=优化器，
              metrics = [&#39;mean_absolute_error&#39;，&#39;mean_squared_error&#39;]）
返回模型
 
和我的数据集
我有500个样本，10个功能和1个目标]]></description>
      <guid>https://stackoverflow.com/questions/57224353/is-my-training-data-set-too-complex-for-my-neural-network</guid>
      <pubDate>Fri, 26 Jul 2019 17:03:09 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机过度适合我的数据</title>
      <link>https://stackoverflow.com/questions/44939725/support-vector-machine-overfitting-my-data</link>
      <description><![CDATA[我正在尝试对虹膜数据集做出预测。我决定将SVM用于此目的。但是，它给了我准确的1.0。是过度拟合的情况还是因为模型很好？这是我的代码。
  x_train，x_test，y_train，y_test = train_test_split（x，y，test_size = 0.2，andury_state = 0）
svm_model = svm.svc（kernel =&#39;linear&#39;，c = 1，gamma =&#39;auto&#39;）
svm_model.fit（x_train，y_train）
预测= svm_model.predict（x_test）
准确_score（预测，y_test）
 
在这里，准确_score返回1。请帮助我。我是机器学习的初学者。]]></description>
      <guid>https://stackoverflow.com/questions/44939725/support-vector-machine-overfitting-my-data</guid>
      <pubDate>Thu, 06 Jul 2017 04:17:53 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn-型号不断拟合</title>
      <link>https://stackoverflow.com/questions/31956501/sklearn-model-keeps-overfitting</link>
      <description><![CDATA[我正在寻找有关当前机器学习问题的最佳前进方向的建议
问题的轮廓和我所做的是如下：

我有900多次脑电图数据的试验，其中每个试验长1秒。地面真相是每个人都知道的，并分类状态0和状态1（40-60％拆分）
每个试验都通过预处理进行过滤和提取某些频带的功率，这些频段构成了一组功能（功能矩阵：913x32）
然后，我使用Sklearn来训练模型。在使用测试尺寸为0.2的情况下，使用Cross_validation。分类器设置为使用RBF内核，C = 1，伽马= 1（我尝试过许多不同的值）

您可以在此处找到代码的缩短版本： http:/pastebin.com/xu13cil4  P&gt;

我的问题：

当我使用分类器预测测试集的标签时，每个预测为0 
火车准确性为1，而测试集精度约为0.56 
我的学习曲线情节看起来像这样：

    
现在，这似乎是在这里过度拟合的经典案例。但是，这里的过度拟合不太可能是由于样本数量不成比例的（32个功能，900个样本）引起的。我已经尝试了许多事情来缓解这个问题：

我尝试使用降低维度（PCA），以防万一，因为我对样本的数量有太多功能，但是准确的分数和学习曲线图看起来与上述相同。除非我将组件的数量设置为10以下，否则火车准确性开始下降，但是考虑到您开始丢失信息，这不是某种程度上吗？
我尝试将数据标准化和标准化。标准化（SD = 1）无助于更改火车或准确分数。标准化（0-1）将我的训练精度降低到0.6。
我已经为SVC尝试了各种C和伽马设置，但它们不会更改任何分数
尝试使用其他估计器（例如高斯人），甚至使用Adaboost等集合方法。没有更改
尝试使用LinareArsVC设置正规化方法，但没有改善情况
我尝试使用Theano通过神经网运行相同的功能，而我的火车准确性约为0.6，测试约为0.5 

我很高兴继续思考这个问题，但是在这一点上，我正在寻找适当方向的轻推。我的问题可能在哪里，我该怎么办？
我的一组功能完全可能不会区分这两个类别，但是我想在得出这个结论之前尝试其他选项。此外，如果我的功能没有区分，那么这可以解释低测试场得分，但是在这种情况下，您如何获得完美的训练场得分呢？这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/31956501/sklearn-model-keeps-overfitting</guid>
      <pubDate>Wed, 12 Aug 2015 05:10:59 GMT</pubDate>
    </item>
    <item>
      <title>SVM在Scikit学习</title>
      <link>https://stackoverflow.com/questions/28154839/svm-overfitting-in-scikit-learn</link>
      <description><![CDATA[我正在使用SVM构建数字识别分类。我有10000个数据，然后将它们分为训练和测试数据，比率7：3。我使用线性内核。
结果证明，当更改训练示例编号时，训练精度总是1，但是测试精度仅为0.9（我预计准确性至少为0.95）。我认为结果表明过度拟合。但是，我从事参数，例如C，伽玛，...它们不会太多更改结果。
如何处理SVM中的过度拟合？
以下是我的代码：
 来自Sklearn Import SVM，Cross_validation
svc = svm.svc（kernel =&#39;linear&#39;，c = 10000，伽马= 0.0，冗长= true）.fit（sample_x，sample_y_1num）

Clf = SVC

preditive_y_train = clf.predict（sample_x）
preditive_y_test = clf.predict（test_x）    
准确性= clf.score（sample_x，sample_y_1num） 
efceracy_test = clf.score（test_x，test_y_1num）  
    
#CODDUCT交叉验证 

cv = cross_validation.shufflesplit（sample_y_1num.size，n_iter = 10，test_size = 0.2，andural_state = none）
scores = cross_validation.cross_val_score（clf，sample_x，sample_y_1num，cv = cv）
score_mean =平均值（得分） 
 ]]></description>
      <guid>https://stackoverflow.com/questions/28154839/svm-overfitting-in-scikit-learn</guid>
      <pubDate>Mon, 26 Jan 2015 16:54:04 GMT</pubDate>
    </item>
    <item>
      <title>熵和信息增益</title>
      <link>https://stackoverflow.com/questions/5465447/entropy-and-information-gain</link>
      <description><![CDATA[如果我有这样的数据：
 分类属性-1属性-2

正确的狗狗 
正确的狗狗
错误的狗猫 
正确的猫猫
错误的猫狗
错误的猫狗
 
那么，属性-2相对于atteribute-1的信息获益是什么？
我已经计算了整个数据集的熵： - （3/6）log2（3/6） - （3/6）log2（3/6）= 1 
那我被卡住了！  我认为您还需要计算属性-1和属性-2的熵吗？  然后在信息增益计算中使用这三个计算？]]></description>
      <guid>https://stackoverflow.com/questions/5465447/entropy-and-information-gain</guid>
      <pubDate>Mon, 28 Mar 2011 21:44:44 GMT</pubDate>
    </item>
    </channel>
</rss>