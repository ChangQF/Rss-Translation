<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 14 Aug 2024 09:16:40 GMT</lastBuildDate>
    <item>
      <title>使用 ML 算法对图像进行分类时，如何修复“找到具有 dim 4 的数组”错误</title>
      <link>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</link>
      <description><![CDATA[我有一个简单的 ML 分类问题。我有 8 个文件夹，每个文件夹代表一个类，因此我首先从文件夹中加载这些图像并分配标签，然后将其保存为 csv 文件（代码如下）
def load_images_from_folder(root_folder):`
image_paths = []
images = []
labels = []
for label in os.listdir(root_folder):
label_path = os.path.join(root_folder, label)
if os.path.isdir(label_path):
for filename in os.listdir(label_path):
img_path = os.path.join(label_path, filename)
if os.path.isfile(img_path) and (filename.endswith(&quot;.jpg&quot;):
img = Image.open(img_path)
img = img.resize((128, 128))
img_array = np.array(img)
image_paths.append(img_path)
images.append(img_array)
labels.append(label)
return image_paths, images, labels
if __name__ == &quot;__main__&quot;:
root_folder_path = &quot;./Datasets_1&quot;
image_paths, images, labels = load_images_from_folder(root_folder_path)

然后我将图像和标签转换为 DataFrame 并加载它
data = {&quot;Images&quot;: image_paths, &quot;Labels&quot;: labels}
df = pd.DataFrame(data)
df.to_csv(&quot;original_data.csv&quot;, index=False)
csv_file = &quot;original_data.csv&quot;
df = pd.read_csv(csv_file)

我还将向 DataFrame 添加一个带有编码标签的新列“Encoded_Labels”，并将“Encoded_Labels”列转换为整数
df[&#39;Encoded_Labels&#39;] =coded_labels
df[&#39;Encoded_Labels&#39;] = df[&#39;Encoded_Labels&#39;].astype(int)

最后，我将数据集拆分为训练集和测试集，并对训练图像进行预处理
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
def load_and_preprocess_images(file_paths, target_size=(128, 128)):
images = []
for file_path in file_paths:
img = Image.open(file_path)
img = img.resize(target_size)
img_array = np.array(img) / 255.0 # 标准化像素值
images.append(img_array)
return np.array(images)

X_train = load_and_preprocess_images(train_df[&#39;Images&#39;].values)
y_train = train_df[&#39;Encoded_Labels&#39;].values
X_test = load_and_preprocess_images(test_df[&#39;Images&#39;].values)
y_test = test_df[&#39;Encoded_Labels&#39;].values**your text**

X_train 的输出形状是
(20624, 128, 128, 3)`

对于这一点我没有问题，我可以使用它与 DL 模型一起使用没有问题，但是当尝试使用 ML 模型（例如 KNN、SVM、DT 等）时。示例代码如下
from sklearn.svm import SVC
svc = SVC(kernel=&#39;linear&#39;,gamma=&#39;auto&#39;)
svc.fit(X_train, y_train)`

或
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_train)
y_pred = knn_clf.predict(X_test)
accuracy = metrics.accuracy_score(y_test, y_pred)
print(&quot;Accuracy of KNN Classifier : %.2f&quot; % (准确率*100))

我收到此错误
“ValueError：找到 dim 为 4 的数组。SVC 预期 &lt;= 2。”
如何修复此错误？
使用 ML 训练模型]]></description>
      <guid>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</guid>
      <pubDate>Wed, 14 Aug 2024 08:26:27 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 是否使用有放回抽样、无放回抽样或者其他完全不同的抽样方法？</title>
      <link>https://stackoverflow.com/questions/78869855/does-xgboost-use-sampling-with-replacement-sampling-without-replacement-or-some</link>
      <description><![CDATA[在Coursera 上学习这门课程，据说它像传统的集成树一样使用替换采样。我知道 xgboost 在第一次迭代后会为错误分类的示例赋予更多权重，但是第一次迭代呢？即使在网上，我也得到了不同的信息。
课程片段
尝试了 GPT、Gemini 和在线资源。]]></description>
      <guid>https://stackoverflow.com/questions/78869855/does-xgboost-use-sampling-with-replacement-sampling-without-replacement-or-some</guid>
      <pubDate>Wed, 14 Aug 2024 08:23:38 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 3 中从“.keras”文件加载模型时出现反序列化错误，密集层可能存在问题</title>
      <link>https://stackoverflow.com/questions/78869745/deserializing-error-when-loading-models-from-keras-files-in-keras-3-possible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78869745/deserializing-error-when-loading-models-from-keras-files-in-keras-3-possible</guid>
      <pubDate>Wed, 14 Aug 2024 07:58:35 GMT</pubDate>
    </item>
    <item>
      <title>NotImplementedError：调用 Lambda.call() 时遇到异常。我们无法自动推断 Lambda 输出的形状</title>
      <link>https://stackoverflow.com/questions/78869440/notimplementederror-exception-encountered-when-calling-lambda-call-we-could</link>
      <description><![CDATA[NotImplementedError Traceback（最近一次调用最后一次）
&lt;ipython-input-36-138183a2a830&gt; 在 &lt;cell line: 2&gt;()
1 # 在推理模式下创建模型对象。
----&gt; 2 model = modellib.MaskRCNN(mode=&quot;inference&quot;, model_dir=MODEL_DIR, config=config)
3 
4 # 加载在 MS-COCO 上训练的权重
5 model.load_weights(COCO_MODEL_PATH, by_name=True)

4 帧
/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py in compute_output_shape(self, input_shape)
93 return nest.map_structure(lambda x: x.shape, output_spec)
94 except:
---&gt; 95 raise NotImplementedError(
96 “我们无法自动推断 Lambda 输出的形状”
97 “请指定 `output_shape`”

NotImplementedError：调用 Lambda.call() 时遇到异常。

我们无法自动推断 Lambda 输出的形状。请为此 Lambda 层指定 `output_shape` 参数。

Lambda.call() 收到的参数：
• args=(&#39;&lt;KerasTensor shape=(None, 1000, 1, 1, 1024), dtype=float32, sparse=False, name=keras_tensor_9478&gt;&#39;,)
• kwargs={&#39;mask&#39;: &#39;None&#39;}

如何解决在 google colab 中运行 MRCNN 的问题]]></description>
      <guid>https://stackoverflow.com/questions/78869440/notimplementederror-exception-encountered-when-calling-lambda-call-we-could</guid>
      <pubDate>Wed, 14 Aug 2024 06:33:59 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn 版本不匹配问题。我不知道应该安装哪个版本</title>
      <link>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</link>
      <description><![CDATA[在此处输入图片说明我正在努力解决涉及 Scikit-learn 的版本不匹配问题，事实证明这是一个相当棘手的问题。每当我尝试安装不同版本的 Scikit-learn 时，我都会遇到一系列错误，这些错误似乎因我尝试的每个版本而异。问题的核心似乎是 Scikit-learn 与其依赖项（例如 NumPy 和 SciPy）之间的不兼容性。这些依赖项对于 Scikit-learn 正常运行至关重要，找到可以协同工作的正确版本已成为一项艰巨的任务。尽管我付出了努力，但我还是无法找到一个可以解决错误并与我现有设置很好地集成的 Scikit-learn 版本。反复试验的过程只会导致越来越多的挫败感，因为每个新版本都会带来自己的一系列问题，而不是解决核心问题。此版本不匹配严重影响了我在项目中有效使用 Scikit-learn 的能力。缺乏关于如何将 Scikit-learn 与其依赖项的兼容版本对齐的明确指导增加了我的困难，使我很难继续工作并实现预期成果。]]></description>
      <guid>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</guid>
      <pubDate>Wed, 14 Aug 2024 04:15:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Pytorch 为二进制数据集实现自动编码器</title>
      <link>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset-using-pytorch</link>
      <description><![CDATA[我对 Autoencoder 及其功能非常陌生。我被要求创建一个重建二进制 CSV 文件（解码）的 Autoencoder。
我根据 geeksforgeeks 的 MNIST 示例实现了一个。但我对包括损失计算和 relu 和线性部分的正确性非常不确定。我做了一些研究，似乎在这种情况下 BCEloss 也比 MSEloss 更好。
任何建议都非常感谢。
以下代码可以生成输出，但损失非常小。建议的批量大小、隐藏维度层和时期数是多少。

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# 设置随机种子以实现可重复性
np.random.seed(42)
torch.manual_seed(42)

# 生成玩具数据：D = 100 名患者，K = 10 个表型，二进制值（0 或 1）
D，K = dm.shape
#data = np.random.randint(0, 2, size=(D, K)).astype(np.float32)

# 将 numpy 数组转换为 PyTorch 张量
data_tensor = torch.tensor(dm)
print(data_tensor.shape)

# 定义 Autoencoder 模型
class Autoencoder(nn.Module):
def __init__(self, input_dim, hidden_​​dim):
super(Autoencoder, self).__init__()
# 编码器
self.encoder = nn.Sequential(
nn.Linear(input_dim, hidden_​​dim),
nn.ReLU()
)
# 解码器
self.decoder = nn.Sequential(
nn.Linear(hidden_​​dim, input_dim),
nn.Sigmoid()
)

def forward(self, x):
coded = self.encoder(x)
coded = self.decoder(encoded)
return解码

# 超参数
input_dim = K
hidden_​​dim = 5 # 隐藏层维度，需要调整

# 初始化模型、损失函数和优化器
model = Autoencoder(input_dim=input_dim, hidden_​​dim=hidden_​​dim)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练参数
num_epochs = 5
batch_size = 10

# 训练循环
for epoch in range(num_epochs):
for i in range(0, D, batch_size):
batch_data = data_tensor[i:i+batch_size]

# 正向传递
outputs = model(batch_data)
loss = criterion(outputs, batch_data)

# 反向传递和优化
optimizer.zero_grad()
loss.backward()
optimizer.step()

#print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss}&#39;)
if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)

# 通过重建输入数据测试模型
with torch.no_grad():
reconstructed = model(data_tensor)

print(&quot;Original Data:&quot;)
print(data_tensor)

print(&quot;Reconstructed Data:&quot;)
print(reconstructed)
]]></description>
      <guid>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset-using-pytorch</guid>
      <pubDate>Wed, 14 Aug 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>runs\train\exp10 不是目录</title>
      <link>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</link>
      <description><![CDATA[我正在尝试使用我的自定义数据训练 YoloV5 模型。我正在尝试在自己的电脑上进行训练（因为如果我离开，Google Colab 就会断开连接，而且我的数据集大约有 3000 张图像，所以它真的很大），但我一直收到此错误：
train: weights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, worker=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, pains=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github：跳过检查（不是 git 存储库），有关更新，请参阅 https://github.com/ultralytics/yolov5
YOLOv5 2024-7-15 Python-3.12.2 torch-2.3.1+cpu CPU
超参数：lr0=0.01、lrf=0.01、momentum=0.937、weight_decay=0.0005、warmup_epochs=3.0， warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, Translation=0.1, scale=0.5, Shelf=0.0, Perspective=0.0, flipud=0.0, fliplr=0.5, Mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard：以“tensorboard --logdir runs\train”开始，在 http://localhost:6006/ 查看
回溯（最近一次调用）：
文件&lt;module&gt; 中的“C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py”，第 986 行
main(opt)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 688 行，在 main 中
train(opt.hyp, opt, device, callbacks)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 180 行，在 train 中
loggers = Loggers(
^^^^^^^^^
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\utils\loggers\__init__.py&quot;，第 121 行，在 __init__ 中
self.tb = SummaryWriter(str(s))
^^^^^^^^^^^^^^^^^^^^^^
文件&quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 249 行，在 __init__ 中
self._get_file_writer()
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 281 行，在 _get_file_writer 中
self.file_writer = FileWriter(
^^^^^^^^^^^
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 75 行，在 __init__ 中
self.event_writer = EventFileWriter(**
^^^^^^^^^^^^^^^^^
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorboard\summary\writer\event_file_writer.py”，第 72 行，在 __init__ 中
tf.io.gfile.makedirs(logdir)
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 513 行，在 recursive_create_dir_v2 中
_pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp10 不是目录

我尝试从预先训练的模型训练我的模型（正如 yolov5 文档所推荐的那样），如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --weights yolov5s.pt
或者从头开始，如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --cfg models/yolov5s.yaml
我还看到了其他问题，例如 GitHub 上的问题 #12008 和 Stack Overflow 上的这个问题 tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp3 不是目录，但还没有找到任何解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</guid>
      <pubDate>Tue, 13 Aug 2024 21:58:27 GMT</pubDate>
    </item>
    <item>
      <title>如何将保存的模型从 Kaggle 导入和下载到本地模型</title>
      <link>https://stackoverflow.com/questions/78867971/how-to-import-and-download-saved-models-from-kaggle-to-local-model</link>
      <description><![CDATA[我正在开展一个使用模型组合进行集成训练的项目，但在处理某些数据格式时遇到了问题。我能够在 Kaggle 上成功下载并使用 gemma 和 llama 语言模型，但很难从 Bert 模型下载并转换为有用的模型进行预处理。文件格式为 .pb 保存的模型格式。到目前为止，我已经成功导入了模型数据，构建了编码器，并从下载的文件中保存了一个模型（至少我认为是这样）。这是我目前所拥有的：
import tensorflow as tf
from transformers import BertTokenizer
import kagglehub
import keras

# 下载模型（假设已设置 api 密钥和访问权限）
path = kagglehub.model_download(&quot;tensorflow/bert/tensorFlow2/en-wwm-uncased-l-24-h-1024-a-16&quot;)

print(&quot;模型文件路径：&quot;, path)

model_path=path
#使用 keras 和 bert tokenizer 构建模型和编码器
model = keras.layers.TFSMLayer(model_path, call_endpoint=&#39;serving_default&#39;)
encoder = BertTokenizer.from_pretrained(model_path+r&#39;\assets\vocab.txt&#39;)

# 概念证明
print(&quot;用户：&quot;)
input_text = tf.keras.layers.Input(shape=(), dtype=tf.string)
# 标记输入（此处出错）
tokenize=[encoder(segment) for fragment in input_text]

我遇到的主要问题是 tokenizer。当我标记文本时，它会抛出错误：
回溯（最近一次调用最后一次）：
文件“C:\Users\cwaid\example4.py”，第 20 行，位于 &lt;module&gt;
tokenize=[encoder(segment) for section in input_text]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\cwaid\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\backend\common\keras_tensor.py&quot;, line 120, in __iter__
raise NotImplementedError(
NotImplementedError: 不支持对符号 KerasTensor 进行迭代。

我不太确定我的模型和编码器是否根据此错误正确初始化，但我不知道如何修复它，因为这是从Kaggle 文档。
就我的项目而言，我没有使用 kaggle journal 或 jupyter notebook，因为我试图用低级语言构建一个独立的预训练模型系统，用于集成学习，而是用 python 构建一个概念证明。
我曾尝试将 pb 文件转换为纯 keras 和元文件，但没有一个有据可查的解决方案，所以我试图避免这样做，以免使我正在做的事情复杂化（尽管如果它更合适，我愿意接受它）。此外，我尝试将其转换为基于 pytorch 的系统，但似乎除非我的模型和编码器正确，否则数据不适合直接翻译，但同样，我不知道是否是这种情况。]]></description>
      <guid>https://stackoverflow.com/questions/78867971/how-to-import-and-download-saved-models-from-kaggle-to-local-model</guid>
      <pubDate>Tue, 13 Aug 2024 19:13:56 GMT</pubDate>
    </item>
    <item>
      <title>COCO 格式到 YOLO 格式（分割蒙版）[关闭]</title>
      <link>https://stackoverflow.com/questions/78867841/coco-format-to-yolo-format-segmentation-masks</link>
      <description><![CDATA[我需要分割我拥有的图像，以便创建用于训练 YOLOv8-seg 的数据集。
我正在尝试使用 CVAT 创建分割蒙版，但是我无法使用 YOLO 导出格式导出分割注释，因此我使用 COCO 导出格式，然后考虑将其转换为 YOLO 格式。
如何使用 Python 代码将 COCO 格式（带分割）转换为 YOLO 格式（带分割）？
有谁知道任何（免费/便宜）工具可以自动将分割导出为 YOLO 格式，而不必转换 COCO 格式？]]></description>
      <guid>https://stackoverflow.com/questions/78867841/coco-format-to-yolo-format-segmentation-masks</guid>
      <pubDate>Tue, 13 Aug 2024 18:23:45 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Sums 包无法进行标记</title>
      <link>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</link>
      <description><![CDATA[我使用以下代码在 Python 中总结我的文本。代码正在 Jupyter Notebook 中运行。我已经使用 pip 命令安装了 sumy。
pip install sumy nltk
python -m nltk.downloader punkt

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from io import StringIO

# 定义要总结的文本
text = &quot;&quot;&quot;
自然语言处理 (NLP) 是人工智能的一个领域，专注于通过自然语言实现计算机与人类之间的互动。NLP 的最终目标是使计算机能够以有价值和有意义的方式理解、解释和响应人类语言。
NLP 用于应用算法来识别和提取自然语言规则，从而将非结构化语言数据转换为计算机可以理解的形式。当提供文本时，计算机可以采用多种不同的方法来处理它。算法可以是基于规则的方法，也可以是基于机器学习的方法。
“”“”

# 使用 StringIO 模拟文件类对象
text_io = StringIO(text)

# 解析文本
parser = PlaintextParser.from_file(text_io, Tokenizer(&quot;english&quot;))

# 初始化 LSA 摘要器
summarizer = LsaSummarizer()

# 生成摘要（您可以调整句子数量）
summary = summaryr(parser.document, sentences_count=2)

# 打印摘要
for sentence in summary:
print(sentence) 

当我运行程序时，我收到以下错误：
ame)
662 def find_class(self, module, name):
663 # 禁止每个函数
--&gt; 664 引发 pickle.UnpicklingError(f&quot;全局 &#39;{module}.{name}&#39; 被禁止&quot;)

UnpicklingError: 全局 &#39;copy_reg._reconstructor&#39; 被禁止 

有什么想法！]]></description>
      <guid>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</guid>
      <pubDate>Mon, 12 Aug 2024 15:37:15 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降算法中的学习率</title>
      <link>https://stackoverflow.com/questions/78844901/learning-rate-in-gradient-descent-algorithm</link>
      <description><![CDATA[在梯度下降算法中，我根据它们的导数更新B和M值，然后将它们与学习率值相乘，但是当我对L使用相同的值，例如0.0001时，它不能正常工作。减小或增加L值不起作用。作为一种解决方法，我不得不为b和m值设置不同的L值。这是正常的还是有错误？
import pandas as pd
import matplotlib.pyplot as plt
import time
import random

# Veri seti
veri_seti = &quot;study_score_decreasing.csv&quot; #study_score_decreasing.csv #study_score_increasing.csv 
data = pd.read_csv(veri_seti)

# 梯度下降 Fonksiyonu
def gradient_descent(m_next, b_next, points, L):
m_gradient = 0
b_gradient = 0
n = len(points)

for i in range(n):
x = points.iloc[i].study_time
y = points.iloc[i].score

m_gradient += -(2/n) * x * (y - (m_next * x + b_next))
b_gradient += -(2/n) * (y - (m_next * x + b_next))

m = m_next - m_gradient * 0.0001 #(L = 0.0001)
b = b_next - b_gradient * 0.1 #(L = 0.1)

return m, b

# 图形选项 图表
def show_graph(m, b):
plt.scatter(data.study_time, data.score, color=&quot;red&quot;)
x_range = range(int(data.study_time.min()), int(data.study_time.max()) + 1)
plt.plot(x_range, [m * x + b for x in x_range], color=&quot;blue&quot;)
plt.xlabel(&#39;学习时间&#39;)
plt.ylabel(&#39;分数&#39;)
plt.title(&#39;学习时间与分数&#39;)
plt.show()
time.sleep(0.001)
print(&quot;=&gt; F(X):&quot;, round(m, 1), &quot;X +&quot;, round(b, 3))

# Ana Fonksiyon
def main(m, b, L, epochs):
print(&quot;=&gt; F(X):&quot;, m, &quot;X&quot;, b)

for i in range(epochs):
m, b = gradient_descent(m, b, data, L)
show_graph(m, b)

# 基础说明
main(random.uniform(-1, 110), random.uniform(-10, 10), 0.1, 250)

我逐个更新了L值，得到了合乎逻辑的结果，但是用一个共同的L值，为什么解看起来不合逻辑？]]></description>
      <guid>https://stackoverflow.com/questions/78844901/learning-rate-in-gradient-descent-algorithm</guid>
      <pubDate>Wed, 07 Aug 2024 16:59:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv8 进行大量错误检测</title>
      <link>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</link>
      <description><![CDATA[我尝试使用 Visual Code Studio 运行 YOLOv8。安装了 ultralytics 并在 vs code 终端上运行了 yolo predict model=yolov8n.pt source=&#39;https://ultralytics.com/images/bus.jpg&#39;。
但是我收到的输出是
2 个人、1 辆自行车、5 辆汽车、10 辆摩托车、73 艘船、3 个停车标志、1 只狗、10 匹马、10 头牛、32 只熊、1 只长颈鹿、63 把雨伞、6 个手提包、9 个飞盘、15 块滑雪板、5 块冲浪板、12 把刀、5 张床、37 张餐桌

这些显然不是这张图片的一部分。

当我第一次安装 ultralytics 并尝试运行 torch 时，出现了缺少依赖项的错误。fbgemm.ddl 丢失。后来，当我安装 vs_BuildTools 时，这个问题得到了解决。然后我继续在虚拟环境中运行代码，其中使用 torch 的程序运行没有任何错误。然后我继续输入此代码片段并遇到此问题。我也尝试使用命令提示符和 jupyter 笔记本运行，但同样的问题仍然存在。
我也检查了版本是否兼容，结果是兼容的。我还没有安装 cuda，是因为这个原因还是还有其他我不知道的问题？请有人帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</guid>
      <pubDate>Thu, 01 Aug 2024 11:33:58 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的空间数据框中识别横断面上的点</title>
      <link>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</link>
      <description><![CDATA[我有调查数据，沿着与海岸垂直的平行横断面每隔 1 海里记录一次。对于每条记录，我都有纬度和经度、速度、方位等信息。沿着横断面，速度约为 10 节。我还在样条间（速度可能不同，方位肯定不同）处有一些点，如果进行了拖网，我还在样条外有一些点。
我想要做的是将属于同一样条的所有点分组（例如，参见图）：

这只是使用 1 NM 点间距离完成的，正如您在图中看到的那样，这实际上不起作用，因为只要有样条间（如样条 5），它就会与样条本身分组在一起。此外，在横断面 13 中，由于某种原因，2 个后续记录之间的距离略大于 1 海里，因此这些点被分成 2 个横断面（您可以看到颜色略有不同）。
此处显示的数据框示例：
 |year |datetime |xkm |ykm |logdiff |time_diff |distance |bearing |speed |
|&lt;dbl&gt; |&lt;dttm&gt; |&lt;dbl&gt; |&lt;dbl&gt; |&lt;dbl&gt;| &lt;dbl&gt;| &lt;drtn&gt; | &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;|
|------|---------- |------|-----|--------|------ --|---------|--------|------|
|2023 |2023-09-26 15:03:00 |221. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:08:00 |223. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:14:00 |225. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:19:00 |227. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:25:00 |229. |1606.| 1| 360 秒 | 1| -1.84| 10|
|2023 |2023-09-26 15:30:00 |231. |1606.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:36:00 |233. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:41:00 |234. |1605.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:47:00 |236. |1605.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:52:00 |238. |1605.| 1| 300 秒 | 1| -1.58| 12|

在 R 中解决这个问题的最佳方法是什么？我考虑过一些无监督的机器学习算法，比如使用 dbscan 进行聚类，但我不确定我是否正确使用了它。除了点之间的距离，我还想使用其他参数来分类一个点是否属于横断面（例如方位和速度）。
我的尝试：
# 准备聚类数据
clustering_data &lt;- df %&gt;% select(year, speed, bearing, xkm, ykm)

dput(clustering_data) 

# dput 输出
structure(list(year = c(2023, 2023, 2023, 2023, 2023, 2023, 2023, 
2023, 2023, 2023), datetime = c(45195.6270833333, 45195.6305555556, 
45195.6347222222, 45195.6381944444, 45195.6423611111, 45195.6458333333, 
45195.65, 45195.6534722222, 45195.6576388889, 45195.6611111111
), xkm = c(221, 223, 225, 227, 229, 231, 233, 234, 236, 238), 
ykm = c(1606, 1606, 1606, 1606, 1606, 1606, 1606, 1605, 1605, 
1605), logdiff = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1), time_diff = c(&quot; 360 秒 &quot;, 
&quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;, 
&quot; 360 秒 &quot;, &quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;), 
distance = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1), bearing = c(-1.58, 
-1.58, -1.58, -1.58, -1.84, -1.85, -1.58, -1.85, -1.58, -1.58
), speed = c(10, 12, 10, 12, 10, 12, 10, 12, 10, 12)), row.names = c(NA, 
10L), class = &quot;data.frame&quot;)

# 应用 DBSCAN 聚类
set.seed(123)
db &lt;- dbscan(clu​​stering_data, eps = 1.8, minPts = 5)


有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</guid>
      <pubDate>Wed, 24 Jul 2024 10:33:52 GMT</pubDate>
    </item>
    <item>
      <title>我无法从“typing_extensions”导入名称“TypeAliasType”</title>
      <link>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</link>
      <description><![CDATA[我是 Python 新手，发现了以下这样的错误。非常感谢您的评论。谢谢
我尝试将 Gradio 库导入为 gr
我尝试了几个现有的建议，但结果都是徒劳的。我不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</guid>
      <pubDate>Thu, 09 Nov 2023 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>Torch Geometric - RuntimeError: mat1 和 mat2 形状无法相乘（1479x1 和 1479x1024）</title>
      <link>https://stackoverflow.com/questions/70844354/torch-geometric-runtimeerror-mat1-and-mat2-shapes-cannot-be-multiplied-1479x</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70844354/torch-geometric-runtimeerror-mat1-and-mat2-shapes-cannot-be-multiplied-1479x</guid>
      <pubDate>Tue, 25 Jan 2022 06:39:32 GMT</pubDate>
    </item>
    </channel>
</rss>