<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 06:21:04 GMT</lastBuildDate>
    <item>
      <title>当模型在高度不平衡的数据集上训练时，其性能如何</title>
      <link>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</link>
      <description><![CDATA[假设我们有 1000 个 1 类样本和 1000 个 2 类样本。我们用这个数据训练了一个模型，发现模型的性能很好。如果用 10000 个 1 类样本和 90000 个 2 类样本的数据训练模型，模型的性能会发生什么变化？
我认为模型过度拟合了 2 类数据，性能会下降。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</guid>
      <pubDate>Mon, 24 Jun 2024 05:43:12 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型的评估结果为损失 = 68（大于 1）</title>
      <link>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</link>
      <description><![CDATA[我按照书中的示例，使用时尚 MNIST
我的代码如下：
\`import tensorflow as tf
from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
X_valid, X_train = X_train_full\[:5000\] / 255.0, X_train_full\[5000:\] / 255.0
y_valid, y_train = y_train_full\[:5000\], y_train_full\[5000:\]

class_names = \[&quot;T-shirt/top&quot;, &quot;Trouser&quot;, “套头衫”、“连衣裙”、“外套”、“凉鞋”、“衬衫”、“运动鞋”、“包”、“踝靴”\]

#构建神经网络模型
model = keras.models.Sequential() 
model.add(keras.layers.Flatten(input_shape=\[28, 28\]))
model.add(keras.layers.Dense(300,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(100,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(10,激活=&quot;softmax&quot;))

model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=&quot;sgd&quot;, metrics=\[&quot;accuracy&quot;\])

history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))

model.evaluate(X_test, y_test)\`

我这次评估的输出是这样的
313/313 [===============================] - 1s 3ms/step - 损失：68.7269 - 准确率：0.8385
[68.72686004638672, 0.8385000228881836]
使用 .fit 方法后，我得到了以下结果：
Epoch 30/30
1719/1719 [==============================] - 9s 5ms/step - 损失：0.2115 - 准确度：0.9236 - val_loss：0.2171 - val_accuracy：0.9209
我还在学习，我不知道该怎么做才能解决这个问题，我也不知道我可能哪里做错了……]]></description>
      <guid>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</guid>
      <pubDate>Mon, 24 Jun 2024 04:51:24 GMT</pubDate>
    </item>
    <item>
      <title>这个销售问题应该使用哪种机器学习模型？我是新手，很困惑</title>
      <link>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</link>
      <description><![CDATA[我在这个领域很新，最近我有一个建立模型的练习。我很困惑是建立回归模型还是分类模型。我应该怎么做，我应该继续使用这个模型还是建立一个新模型？如果我继续，应该改进什么？
数据集链接
我尝试建立一个随机森林模型，并获得 0.5 的准确度得分和 f1 得分。特征包括地区、国家、商品类型、销售渠道、订单优先级，目标是销售单位。我试图将每个特征对销售单位的重要性包括在内。]]></description>
      <guid>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</guid>
      <pubDate>Mon, 24 Jun 2024 00:37:32 GMT</pubDate>
    </item>
    <item>
      <title>System.AccessViolationException：尝试在 TorchSharp.PInvoke.LibTorchSharp.THSGenerator_manual_seed 读取或写入受保护的内存</title>
      <link>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</guid>
      <pubDate>Sun, 23 Jun 2024 23:08:49 GMT</pubDate>
    </item>
    <item>
      <title>我正在做一个足球分析跟踪机器学习项目，我得到了速度和距离估计器的导入错误</title>
      <link>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</link>
      <description><![CDATA[ImportError: 无法从 
&#39;speed_and_distance_estimator.speed_and_distance_estimator&#39; 
(c:\Users...\Football analysis\speed_and_distance_estimator\speed_and_distance_estimator.py) 导入名称 &#39;Speed_and_Distance_Estimator&#39;

在我的文件 speed_and_distance_estimator.py 中
sys.path.append(&#39;../&#39;)
from utils import measure_distance, get_foot_position

class Speed_and_Distance_Estimator:
pass

在我的 init.py 中
from .speed_and_distance_estimator import Speed_and_Distance_Estimator

我预计我的 main.py 中不会出现任何错误
from utils import read_video, save_video
from trackers import Tracker
import cv2
import numpy as np
from team_assigner import TeamAssigner
from player_ball_assigner import PlayerBallAssigner
from camera_movement_estimator import CameraMovementEstimator
from view_transformer import ViewTransformer
from speed_and_distance_estimator import Speed_and_Distance_Estimator

def main():
# 读取视频
video_frames = read_video(&#39;input_videos/08fd33_4.mp4&#39;)

# 初始化跟踪器
tracker = Tracker(&#39;models/best.pt&#39;)

tracks = tracker.get_object_tracks(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/track_stubs.pkl&#39;)
# 获取对象位置 
tracker.add_position_to_tracks(tracks)

# 相机运动估计器
camera_movement_estimator = CameraMovementEstimator(video_frames[0])
camera_movement_per_frame = camera_movement_estimator.get_camera_movement(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/camera_movement_stub.pkl&#39;)
camera_movement_estimator.add_adjust_positions_to_tracks(tracks,camera_movement_per_frame)

# 视图转换器
view_transformer = ViewTransformer()
view_transformer.add_transformed_position_to_tracks(tracks)

# 插入球位置
tracks[&quot;ball&quot;] = tracker.interpolate_ball_positions(tracks[&quot;ball&quot;])

# 速度和距离估算器
speed_and_distance_estimator = Speed_and_Distance_Estimator()
speed_and_distance_estimator.add_speed_and_distance_to_tracks(tracks)

# 分配球员队伍
team_assigner = TeamAssigner()
team_assigner.assign_team_color(video_frames[0], 
tracks[&#39;players&#39;][0])

for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
for player_id, track in player_track.items():
team = team_assigner.get_player_team(video_frames[frame_num], 
track[&#39;bbox&#39;],
player_id)
tracks[&#39;players&#39;][frame_num][player_id][&#39;team&#39;] = team 
tracks[&#39;players&#39;][frame_num][player_id][&#39;team_color&#39;] = team_assigner.team_colors[team]

# 分配球获取
player_assigner =PlayerBallAssigner()
team_ball_control= []
for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
ball_bbox = tracks[&#39;ball&#39;][frame_num][1][&#39;bbox&#39;]
assigned_player = player_assigner.assign_ball_to_player(player_track, ball_bbox)

if assignment_player != -1:
tracks[&#39;players&#39;][frame_num][assigned_player][&#39;has_ball&#39;] = True
team_ball_control.append(tracks[&#39;players&#39;][frame_num][assigned_player][&#39;team&#39;])
else:
team_ball_control.append(team_ball_control[-1])
team_ball_control= np.array(team_ball_control)

# 绘制输出 
## 绘制对象轨迹
output_video_frames = tracker.draw_annotations(video_frames, tracks,team_ball_control)

## 绘制摄像机运动
output_video_frames = camera_movement_estimator.draw_camera_movement(output_video_frames,camera_movement_per_frame)

## 绘制速度和距离
speed_and_distance_estimator.draw_speed_and_distance(output_video_frames,tracks)

# 保存视频
save_video(output_video_frames, &#39;output_videos/output_video.avi&#39;)

if __name__ == &#39;__main__&#39;:
main()
]]></description>
      <guid>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</guid>
      <pubDate>Sun, 23 Jun 2024 20:05:06 GMT</pubDate>
    </item>
    <item>
      <title>为训练、验证和测试分割创建 LMDB 文件 [关闭]</title>
      <link>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</link>
      <description><![CDATA[为训练、验证和测试分割创建 LMDB 文件。
python tools/create_dataset.py --root_dir &lt;dataset_dir&gt; --save &lt;lmdb_dst_path&gt;

数据集文件夹应遵循与 IIIT-INDIC-HW-WORDS 结构相同的结构。
生成一个包含用于预测的 Unicode 符号/字符的文件。将此文件移动到 alphabet/ 文件夹。此 repo 已包含 alphabet/ 文件夹中印度语脚本的排序字母表列表。
python tools/create_dataset.py --root_dir /Users/armanmansury/Developer/Work/indic-htr-main/tools/create_dataset.py --save /Users/armanmansury/Developer/Work/indic-htr-main
]]></description>
      <guid>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</guid>
      <pubDate>Sun, 23 Jun 2024 19:50:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 vif 选择线性回归的变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78659510/how-to-use-vif-to-select-variables-for-linear-regression</link>
      <description><![CDATA[我正在尝试使用此 kaggle 数据集，通过 mlr 预测学生的期末成绩。
我知道你应该
a) 对所有二进制和分类数据进行编码
b) 丢弃显示多重共线性的变量
c) 选择与你的因变量具有线性关系的变量（我对此也有点困惑，因为到目前为止，在我看过的很多视频中，人们在使用线性回归训练模型时并没有真正检查这一点）
我已经通过对我的二进制变量进行标签编码和对我的分类变量进行单热编码来完成 (a)。我甚至为每个变量计算了我的 vif（经过单热编码的变量具有无限的 vif 值）。现在……我不知道该如何继续。我只能肯定地说，由于 G2 具有较高的 vif 分数，我可以丢弃它；而且由于 Medu 的得分与 Fedu 接近但更高，我也可以将其丢弃（Walc 和 Dalc 相同）
这是我得到的值：
const 0.000000
school 1.518331
sex 1.489316
age 1.818399
address 1.388570
famsize 1.153361
Pstatus 1.145962
Medu 2.946452
Fedu 2.147572
traveltime 1.322387
studytime 1.398220
failures 1.567588
schoolsup 1.262329
famsup 1.306325
paid 1.339139
activities 1.167950
托儿所 1.153852
高等教育 1.316551
互联网 1.258651
浪漫 1.179480
家庭 1.173444
空闲时间 1.322079
外出 1.496537
Dalc 2.036903
Walc 2.405555
健康 1.181635
缺勤 1.297898
G1 4.794857
G2 8.414788
G3 6.483623
Mjob__at_home inf
Mjob__health inf
Mjob__other inf
Mjob__services inf
Mjob__teacher inf
Fjob__at_home inf
Fjob__health inf
Fjob__other inf
Fjob__services inf
Fjob__teacher inf
reason__course inf
reason__home inf
reason__other inf
reason__reputation inf
guardian__father inf
guardian__mother inf
guardian__other inf
dtype: float64

顺便说一句，我还尝试通过删除每列来删除 inf 值，这是更新后的表格：
const 444.290274
school 1.511859
sex 1.467679
age 1.812452
address 1.374540
famsize 1.133540
Pstatus 1.135528
Fedu 1.573887
traveltime 1.307404
studytime 1.359323
失败 1.564388
学校辅导 1.256581
家庭辅导 1.297111
付费 1.322515
活动 1.160221
托儿所 1.143275
更高 1.315591
互联网 1.250430
浪漫 1.163283
家庭关系 1.116803
空闲时间 1.317057
外出 1.302700
Dalc 1.413114
健康 1.151149
缺勤 1.245384
G1 3.665802
G3 3.347264
Mjob__at_home 1.420409
Mjob__health 1.392905
Mjob__services 1.555274
Mjob__teacher 1.685721
Fjob__at_home 1.167256
Fjob__health 1.237499
Fjob__services 1.352274
Fjob__teacher 1.422042
reason__course 1.668734
reason__other 1.401163
reason__reputation 1.619025
guardian__father 1.213142
guardian__other 1.457884
dtype: float64
]]></description>
      <guid>https://stackoverflow.com/questions/78659510/how-to-use-vif-to-select-variables-for-linear-regression</guid>
      <pubDate>Sun, 23 Jun 2024 18:16:56 GMT</pubDate>
    </item>
    <item>
      <title>transformers 4.41.x 中不再存在 top_k_top_p_filtering 函数</title>
      <link>https://stackoverflow.com/questions/78659374/function-top-k-top-p-filtering-doesnt-exist-anymore-in-transformers-4-41-x</link>
      <description><![CDATA[函数 top_k_top_p_filtering 在 transformers 4.41.x 中不再存在。在以前的版本中，我仅使用此函数
 next_token_logscores = top_k_top_p_filtering(logits, top_k=k, top_p=p)


其中 k 是元素的数量，p 是累积概率，如下所示
def top_k_top_p_filtering(
logits: Tensor,
top_k: int = 0,
top_p: float = 1.0,
filter_value: float = -float(&quot;Inf&quot;),
min_tokens_to_keep: int = 1,
) -&gt;张量：
“”使用 top-k 和/或 nucleus (top-p) 过滤对 logits 分布进行过滤
参数：
logits：logits 分布形状（批次大小、词汇量）
如果 top_k &gt; 0：仅保留概率最高的前 k 个标记（top-k 过滤）。
如果 top_p &lt; 1.0：保留累积概率 &gt;= top_p 的前几个标记（nucleus 过滤）。
Holtzman 等人描述了 Nucleus 过滤。（http://arxiv.org/abs/1904.09751）
确保我们在输出中为每个批次示例保留至少 min_tokens_to_keep
来自：https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317
“”“”
如果 top_k &gt; 0:
top_k = min(max(top_k, min_tokens_to_keep), logits.size(-1)) # 安全检查
# 删除所有概率小于 top-k 中最后一个 token 的 token
indices_to_remove = logits &lt; torch.topk(logits, top_k)[0][..., -1, None]
logits[indices_to_remove] = filter_value

if top_p &lt; 1.0:
sorted_logits, sorted_indices = torch.sort(logits, descending=True)
cumumsum_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)

# 删除累计概率高于阈值的 token（保留 0 的 token）
sorted_indices_to_remove =cumumum_probs &gt; top_p
如果 min_tokens_to_keep &gt; 1:
# 至少保留 min_tokens_to_keep（设置为 min_tokens_to_keep-1，因为我们在下面添加了第一个）
sorted_indices_to_remove[..., :min_tokens_to_keep] = 0
# 将索引向右移动以保留高于阈值的第一个标记
sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
sorted_indices_to_remove[..., 0] = 0

# 将排序后的张量分散到原始索引
indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)
logits[indices_to_remove] = filter_value
return logits

this代码链接 https://huggingface.co/transformers/v3.2.0/_modules/transformers/generation_utils.html
如何仅使用 transformers 4.41 中提供的函数重写此函数的调用？]]></description>
      <guid>https://stackoverflow.com/questions/78659374/function-top-k-top-p-filtering-doesnt-exist-anymore-in-transformers-4-41-x</guid>
      <pubDate>Sun, 23 Jun 2024 17:20:47 GMT</pubDate>
    </item>
    <item>
      <title>循环训练模型（每次迭代都会生成新模型），经过近 600 次循环迭代后，训练时间会增加</title>
      <link>https://stackoverflow.com/questions/78659373/training-model-in-loop-new-model-in-each-iteration-training-time-increases-af</link>
      <description><![CDATA[我正在训练一个 LSTM 模型，并使用“留一法”交叉验证对其进行验证。我有 11520 个样本，所以我必须训练一个新模型 11520 次。我对 scikit learn 的“LeaveOneOut”函数给出的每个数据分割使用循环，在该循环中，我初始化一个新模型，对其进行训练，预测测试集，然后使用“keras.backend.clear_session()”清除旧模型，之后使用“tf.compat.v1.reset_default_graph()”重置图形，然后使用“gc.collect()”收集抓取的数据。最初，模型的训练时间约为 6-7 秒，但在训练 600 个模型后，训练时间增加到 25-50 秒。这是我的代码：
def get_model(channels):

model2 = keras.models.Sequential()
model2.add(keras.layers.LSTM(64, return_sequences=False))
model2.add(keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model2.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

return model2 

def leaveOneOutCVLSTM(X, y, epochs, batch_size, validation_split):

X_shuffle, y_shuffle = shuffle(X, y, random_state=42)
cv = LeaveOneOut()
# 枚举分割
y_true, y_pred = list(), list()
i = 1
for train_ix, test_ix in cv.split(X_shuffle):
# 分割数据
X_train, X_test = X_shuffle[train_ix, :], X_shuffle[test_ix, :]

scalers = {}
X_train_scaled = np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])
X_test_scaled = np.random.rand(X_test.shape[0], X_test.shape[1], X_test.shape[2])
for j in range(X_train.shape[2]):
scalers[j] = StandardScaler()
X_train_scaled[:, :, j] = scalers[j].fit_transform(X_train[:, :, j])
for j in range(X_test.shape[2]):
X_test_scaled[:, :, j] = scalers[j].transform(X_test[:, :, j])

y_train, y_test = y_shuffle[train_ix], y_shuffle[test_ix]
# 拟合模型
new_model = get_model(X_train_scaled.shape[1])
st = time()
if(i &lt;= 5):
new_model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)
else:
new_model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=False)

# 评估模型
y_hat = new_model.predict(X_test_scaled, verbose=False)

ed = time()
dr = ed-st
print(i,&quot; &quot;,dr)
# store
y_true.append(y_test[0])
y_pred.append(y_hat[0])
i+=1
keras.backend.clear_session()
tf.compat.v1.reset_default_graph()
gc.collect()

return y_true, y_pred

X_batch = X.reshape(11520, 1, 156)

y_true, y_pred = leaveOneOutCVLSTM(X_batch, Y, 10, 32, 0.2)

这是我从第 1 次迭代到第 16 次迭代打印的训练时间
1 8.427346229553223
2 7.397351503372192
3 7.472941875457764
4 7.418887615203857
5 7.5288026332855225
6 6.432919502258301
7 6.417744398117065
8 6.312522649765015
9 6.350329160690308
10 6.340737342834473
11 6.3199241161346436
12 6.310317039489746
13 6.3174097537994385
14 6.346491813659668
15 6.2766053676605225
16 6.296995401382446

以及第 600 次迭代至第 616 次迭代
600 26.77048420906067
601 20.864712238311768
602 20.118656873703003
603 23.869750022888184
604 23.6923668384552
605 26.10648512840271
606 23.909359216690063
607 36.399033069610596
608 22.179851055145264
609 16.407938718795776
610 30.585895776748657
611 23.5596022605896
612 25.86080241203308
613 44.86601257324219
614 23.27703547477722
615 24.88290023803711
616 19.156887531280518

我已使用 keras.backend.clear_session()、tf.compat.v1.reset_default_graph()、gc.collect() 来清除开销，但训练时间仍然增加。所以我想知道

为什么循环 600 次迭代后训练时间会增加？
我应该怎么做才能使训练时间保持在 6-7 秒？
]]></description>
      <guid>https://stackoverflow.com/questions/78659373/training-model-in-loop-new-model-in-each-iteration-training-time-increases-af</guid>
      <pubDate>Sun, 23 Jun 2024 17:20:17 GMT</pubDate>
    </item>
    <item>
      <title>即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</link>
      <description><![CDATA[以下代码模拟了一个简单的 TFX 管道，它提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>对于深度学习，将胸部 CT 图像从 jpg 转换为 NIFTI 有什么好处吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78658245/for-deep-learning-is-there-any-benefits-converting-chest-ct-images-from-jpg-to</link>
      <description><![CDATA[我正在研究从胸部 CT 图像中自动检测疾病。我一直与一家医院保持联系，他们向我提供胸部 CT 切片，全部为 jpg 格式。我担心转换为 jpg 格式可能会导致空间信息丢失，如果由我决定，我会将 dicom 转换为 nifti
现在，我已使用 python 中的 nibabel 库将 3D 体积从 jpg 转换为 nifti，希望医学图像的 3D 体积能够更好地表示数据。我的假设正确吗？将 jpg 图像切片转换为 3D nifti 体积有什么好处吗？]]></description>
      <guid>https://stackoverflow.com/questions/78658245/for-deep-learning-is-there-any-benefits-converting-chest-ct-images-from-jpg-to</guid>
      <pubDate>Sun, 23 Jun 2024 09:11:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>所有时期的损失和准确率相同</title>
      <link>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</guid>
      <pubDate>Thu, 20 Jun 2024 06:01:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么这些简单的线性回归权重梯度 numpy 计算会给出不同的结果？</title>
      <link>https://stackoverflow.com/questions/78644274/why-are-these-simple-linear-regression-weights-gradient-numpy-calculations-givin</link>
      <description><![CDATA[对于权重梯度计算，它们对相同参数给出了不同的结果。
# 定义训练集
X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])
y_train = np.array([460, 232, 178])
b_init = 785.1811367994083
w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])

方法 (1)
def dj_dw(w,x,b,y):
# 示例数量
m = x.shape[0]
dj_dw = (1/m)*(np.dot(np.transpose(np.dot(x,w)+b-y),x))
return dj_dw

方法 (2)
def dj_dw_2(w, x, b, y):
m, n = x.shape
dj_dw = np.zeros(n)
for j in range(n):
for i in range(m):
dj_dw[j] += (1/m) * ((w[j]*x[i][j] + b - y[i]) * (x[i][j]))
return dj_dw

以及结果分别
[-2.72623574e-03 -6.27197255e-06 -2.21745574e-06 -6.92403377e-05]
[ 1.59529824e+06 1.73748484e+03 5.72854200e+02 -2.33772157e+04]
]]></description>
      <guid>https://stackoverflow.com/questions/78644274/why-are-these-simple-linear-regression-weights-gradient-numpy-calculations-givin</guid>
      <pubDate>Wed, 19 Jun 2024 19:14:12 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle GPU 上的训练模型问题 - 只有一个 GPU 正常工作</title>
      <link>https://stackoverflow.com/questions/78638417/issue-with-training-model-on-kaggle-gpu-only-one-gpu-working</link>
      <description><![CDATA[我目前正在尝试使用 GPU 资源在 Kaggle 上训练模型，但似乎只使用了一个 GPU，而不是多个。我使用以下训练代码：
# 步骤 1：安装所需的软件包
#!pip install ultralytics xmltodict albumentations torch torchvision torchaudio

# 步骤 5：训练 YOLO 模型
import os
import torch
from ultralytics import YOLO

# 将 WANDB_MODE 设置为“dryrun”以禁用 WanDB 日志记录
os.environ[&#39;WANDB_MODE&#39;] = &#39;dryrun&#39;

# 为多个 GPU 设置设备
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = YOLO(&#39;yolov8x.pt&#39;) # 加载预训练的 YOLOv8 模型

# 检查是否有多个 GPU 可用
if torch.cuda.device_count() &gt; 1：
print(f&quot;使用 {torch.cuda.device_count()} GPU&quot;)
model = torch.nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count()))).to(device)
else：
model = model.to(device)

# 定义训练配置
data_yaml = &quot;&quot;&quot;
train: /../images/train_combined_data
val: /../images/val
test: /../images/test
nc: 1
names: [&#39;Hotspot&#39;]
&quot;&quot;&quot;

with open(&#39;data.yaml&#39;, &#39;w&#39;) as f:
f.write(data_yaml)

# 训练模型
model.train(
data=&#39;data.yaml&#39;,
epochs=50, # 训练 epoch 总数
batch=16, 
imgsz=640, # 训练的目标图像大小
device=&#39;cuda&#39;
)


我查看了 Kaggle 的文档，它应该支持使用多个 GPU 进行训练。我需要在代码中添加一些特定内容来启用多 GPU 训练吗？或者 Kaggle 上是否有我可能遗漏的设置？
如能就此问题提供任何帮助或指导，我将不胜感激。谢谢！
我该如何使用这两个 GPU？]]></description>
      <guid>https://stackoverflow.com/questions/78638417/issue-with-training-model-on-kaggle-gpu-only-one-gpu-working</guid>
      <pubDate>Tue, 18 Jun 2024 15:40:00 GMT</pubDate>
    </item>
    </channel>
</rss>