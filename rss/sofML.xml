<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 14 Sep 2024 12:28:59 GMT</lastBuildDate>
    <item>
      <title>如何在 Python 中使用约 20K 张图像加速 cv2.imwrite 循环？</title>
      <link>https://stackoverflow.com/questions/78984991/how-to-speedup-cv2-imwrite-in-loop-with-20k-images-in-python</link>
      <description><![CDATA[我正在创建处理后的图像以微调自定义控制网络。数据大小约为 20K 张图像。由于这些是条件图像，因此它们是通过处理函数创建的，流程基本上如下所示：
def process(image, conditions, filename):
im1 = cond1(image, conditions)
cv2.imwrite(f&quot;filename{1}.png&quot;, im1)

im2 = cond2(image, conditions)
cv2.imwrite(f&quot;filename{2}.png&quot;, im2)

im3 = cond3(image, conditions)
cv2.imwrite(f&quot;filename{3}.png&quot;, im3)

im4 = cond4(image, conditions)
cv2.imwrite(f&quot;filename{4}.png&quot;, im4)

def main():
for image, conditions in zip(images, conditions, filenames):
process(image, conditions, filename)


我已经优化了代码生成过程中的图像。但瓶颈似乎是 imwrite。而且文件真的很小。平均而言，它们为 10-20 kb，5-10% 可能超过 100 kb。
我尝试切换到 jpeg 并更改压缩。但这也无济于事。
是否有一种多处理方法可以做到这一点，而不需要将图像保存在队列中？当前处理每幅图像大约需要 2-5 秒。]]></description>
      <guid>https://stackoverflow.com/questions/78984991/how-to-speedup-cv2-imwrite-in-loop-with-20k-images-in-python</guid>
      <pubDate>Sat, 14 Sep 2024 11:26:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在稳定的扩散修复模型中提高对象生成质量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78984494/how-to-improve-object-generation-quality-in-a-stable-diffusion-inpainting-model</link>
      <description><![CDATA[我目前正在微调一个稳定扩散修复模型，以完成一项特定任务：在图像中生成新对象。但是，我面临着几个挑战：

生成不一致：有时模型根本无法生成任何对象。

低质量输出：当模型确实生成对象时，质量通常不令人满意。


采取的步骤：

我一直在使用负面提示来阻止模型产生低质量的输出。
我已经收集并准备了一个数据集，其中包括高质量图像和应生成对象的区域的相应蒙版。

问题：

我可以采用哪些策略来提高生成对象的质量？
是否有特定的超参数或训练技术可以帮助提高模型在此任务中的性能？
如何有效地使用负面提示来引导模型而不导致生成不足？
是否有任何推荐的数据集或资源专注于图像中的对象生成，我应该考虑？

我正在使用 RealVisXL Inpaint 和 Hugging Face。
我当前的设置是 V100。]]></description>
      <guid>https://stackoverflow.com/questions/78984494/how-to-improve-object-generation-quality-in-a-stable-diffusion-inpainting-model</guid>
      <pubDate>Sat, 14 Sep 2024 07:06:23 GMT</pubDate>
    </item>
    <item>
      <title>roboflow 教程使用 albumentations：TypeError：图像必须是 numpy 数组类型</title>
      <link>https://stackoverflow.com/questions/78984257/roboflow-tutorial-using-albumentations-typeerror-image-must-be-numpy-array-typ</link>
      <description><![CDATA[我尝试使用 albumentations 调整图像大小，并偶然发现了这个 roboflow 教程，并准确复制了代码。
import albumentations as A
import cv2

image = cv2.imread(&quot;img.jpg&quot;)

pipeline = A.Compose([
A.Resize(height=640, width=640, p=1),
])

augmented_image = pipeline(image=image)[&quot;image&quot;]

cv2.imwrite(&quot;augmented_image.jpg&quot;, augmented_image) 

但是，当我运行它时，我收到以下错误：
Traceback（最近一次调用last):
文件 &quot;/Users/user/Documents/test.py&quot;，第 16 行，位于 &lt;module&gt;
augmented_image = pipeline(image=image)[&quot;image&quot;]
^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 334 行，在 __call__ 中
self.preprocess(data)
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 363 行，在 preprocess 中
self._check_args(**data)
文件 &quot;/Users/user/anaconda3/envs/venv/lib/python3.12/site-packages/albumentations/core/composition.py&quot;，第 412 行，在_check_args
引发 TypeError(f&quot;{data_name} 必须是 numpy 数组类型&quot;)
TypeError: 图像必须是 numpy 数组类型

我已使用 type(image) 确认它是 &lt;class &#39;numpy.ndarray&#39;&gt;
我也尝试过不同的图像以及 jpg 和 png
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78984257/roboflow-tutorial-using-albumentations-typeerror-image-must-be-numpy-array-typ</guid>
      <pubDate>Sat, 14 Sep 2024 03:55:15 GMT</pubDate>
    </item>
    <item>
      <title>注意力图逐渐消失 - 这是正常的吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78983457/the-attention-map-fades-is-this-normal</link>
      <description><![CDATA[我目前正在构建 Vision Transformer (ViT)，到目前为止，一切似乎进展顺利 - 低损失值、高准确度。然而，当我可视化注意力图时，我注意到它们随着时间的推移逐渐消失并变得统一。我预期的情况恰恰相反 - 随着模型的学习，注意力图将被 Transformer 用于识别哪些补丁对决策的影响更大，哪些补丁的影响较小。最初，情况确实如此，但随着模型的不断学习，注意力图变得越来越统一。
似乎我的模型出了问题，或者 Transformer 在决策过程中停止关注补丁之间的关系。我很好奇是否有其他人遇到过这种行为并可以帮助我解释发生了什么。
至于模型本身，它表现良好并显示出有希望的结果，所以我倾向于认为它没有问题。然而，很难明确地说什么是“正确”或“错误”在这种情况下。
简而言之，如果您能帮助我解释这些结果，我将不胜感激——我不明白为什么注意力图变得如此统一，而且它们的值可以忽略不计，这表明转换器在决策过程中可能没有考虑补丁之间的关系。
我使用了超过 10k 个样本。在第 5 个时期，我得到了这些值
Epoch 5/20
1179/1179 [===============================] - 1197s 1s/step - 损失：0.1253 - 稀疏分类准确度：0.9950 - val_loss：0.0607 - val_sparse_categorical_accuracy：1.0000
谢谢你的帮助。




]]></description>
      <guid>https://stackoverflow.com/questions/78983457/the-attention-map-fades-is-this-normal</guid>
      <pubDate>Fri, 13 Sep 2024 19:05:30 GMT</pubDate>
    </item>
    <item>
      <title>ML 模型置信度问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78983303/ml-model-confidence-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78983303/ml-model-confidence-issue</guid>
      <pubDate>Fri, 13 Sep 2024 18:07:05 GMT</pubDate>
    </item>
    <item>
      <title>无法捕捉不同的隐藏状态</title>
      <link>https://stackoverflow.com/questions/78983228/failure-to-capture-different-hidden-states</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78983228/failure-to-capture-different-hidden-states</guid>
      <pubDate>Fri, 13 Sep 2024 17:40:19 GMT</pubDate>
    </item>
    <item>
      <title>哪些机器学习技术可以结合文本和数字/分类数据？[关闭]</title>
      <link>https://stackoverflow.com/questions/78981863/what-machine-learning-techniques-can-combine-text-and-numerical-categorical-data</link>
      <description><![CDATA[问题描述：我正在开展一个项目，需要结合文本数据（例如，客户评论）和数字/分类数据（如年龄、产品类别）来构建预测模型。虽然这不是专门针对客户评论的，但我仍处于研究的早期阶段。我的数据集中有大约 150 万行，但只有大约 1200 行具有真实的 Y 值。
我正在寻找机器学习技术来处理这个问题，但我现在想避免深度学习，特别是因为我不确定我的数据集大小是否足以支持深度学习模型。
我的问题：
我可以使用哪些机器学习技术将文本数据与数字和分类数据相结合，而无需使用深度学习？我已经研究过堆叠，但我想知道还有哪些其他选项可以有效地组合这些类型的数据。
数据集详细信息：
大约 150 万行，其中只有 1200 行具有真实 Y 值。
文本特征：类似于客户评论（仅作为示例）。
数字/分类特征：年龄、产品类别等。
目标：
我正在寻找有关技术或工作流程的建议，以帮助我有效地组合这些数据类型而无需深度学习。堆叠是我最好的选择，还是我应该考虑其他方法？]]></description>
      <guid>https://stackoverflow.com/questions/78981863/what-machine-learning-techniques-can-combine-text-and-numerical-categorical-data</guid>
      <pubDate>Fri, 13 Sep 2024 11:00:29 GMT</pubDate>
    </item>
    <item>
      <title>带有随机森林的分类链：为什么即使 Base Estimator 可以处理 np.nan 却不支持它？</title>
      <link>https://stackoverflow.com/questions/78981288/classifierchain-with-random-forest-why-is-np-nan-not-supported-even-though-base</link>
      <description><![CDATA[我正在研究一个多标签分类问题，使用ClassifierChain方法，以RandomForestClassifier作为基础估计器。我遇到了一个问题，我的输入矩阵X包含np.nan值。当单独使用RandomForestClassifier时，它可以毫无问题地处理NaN值，因为它通过其内部树分割机制原生支持缺失值。
这让我很困惑，因为基础估计器（RandomForestClassifier）确实可以正确处理NaN值。我不明白为什么 ClassifierChain（它只是一个包装器）会在底层分类器没有 NaN 问题的情况下引发此错误。
当我训练一个简单的 RandomClassifier 时，它确实会处理 np.nan：
from sklearn.ensemble import RandomForestClassifier
import numpy as np

X = np.array([np.nan, -1, np.nan, 1]).reshape(-1, 1)
y_single_label = [0, 0, 1, 1]

tree = RandomForestClassifier(random_state=0)
tree.fit(X, y_single_label)
X_test = np.array([np.nan]).reshape(-1, 1)
tree.predict(X_test)

即使我使用 MultiOutputClassifier 而不是ClassifierChain（不模拟标签之间的依赖关系），训练进行时没有任何错误，即使输入中有 NaN - 正如预期的那样。
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import ClassifierChain , MultiOutputClassifier

X = np.array([np.nan, -1, np.nan, 1]).reshape(-1, 1)

# 用于多标签分类的两个标签列
y = np.array([[0, 1], [0, 0], [1, 0], [1, 1]])

# 基础分类器
base_clf = RandomForestClassifier()

# MultiOutputClassifier（二元相关性）与基础分类器
clf_BR = MultiOutputClassifier(base_clf)

# 拟合模型
clf_BR.fit(X, y)

但是，当我切换到 ClassifierChain 方法时：
# 带有基础分类器的分类器链
clf_chain = ClassifierChain(base_clf)

# 拟合模型
clf_chain.fit(X, y)

我在超参数调整期间收到以下错误：

试验 0 失败，参数为：{&#39;n_estimators&#39;: 30, &#39;max_depth&#39;: 16, &#39;max_samples&#39;: 0.4497444900238575, &#39;max_features&#39;: 550, &#39;order_type&#39;: &#39;random&#39;}，错误原因如下：ValueError(&#39;输入 X 包含 NaN.\nClassifierChain 不接受编码为 NaN 的缺失值原生。对于监督学习，您可能需要考虑 sklearn.ensemble.HistGradientBoostingClassifier 和 Regressor，它们原生接受编码为 NaN 的缺失值。或者，可以预处理数据，例如通过在管道中使用 imputer 转换器或删除具有缺失值的样本。请参阅https://scikit-learn.org/stable/modules/impute.html 您可以在以下页面找到处理 NaN 值的所有估算器的列表：https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values&#39;)

由于保持缺失值原样而不是对其进行插补或删除非常重要，我想知道是否有办法让 ClassifierChain 处理缺失值。是否有任何解决方法或我遗漏了什么？
以下是我的环境详细信息：

Python 版本：3.12.5（由 conda-forge 打包）
scikit-learn 版本：1.5.1
]]></description>
      <guid>https://stackoverflow.com/questions/78981288/classifierchain-with-random-forest-why-is-np-nan-not-supported-even-though-base</guid>
      <pubDate>Fri, 13 Sep 2024 08:25:24 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：'Dense' 对象在 TensorFlow/Keras 的 ann_visualizer 中没有属性 'output_shape'</title>
      <link>https://stackoverflow.com/questions/78980852/attributeerror-dense-object-has-no-attribute-output-shape-in-ann-visualizer</link>
      <description><![CDATA[我遇到了这个错误：
Epoch 1/2
1/1 ━━━━━━━━━━━━━━━━━━━━━━ 0s 391ms/step - 损失：6272135168.0000
Epoch 2/2
1/1 ━━━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - 损失：6272133632.0000
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step
均方误差：7431671762.639743
回溯（最近一次调用）：

文件 ~\anaconda3\Lib\site-packages\spyder_kernels\py3compat.py:356 in compat_exec
exec(code, globals, locals)

文件 c:\users\mouli\.spyder-py3\temp.py:27
ann_viz(model,title=&#39;线性回归&#39;)

文件 ~\anaconda3\Lib\site-packages\ann_visualizer\visualize.py:42 in ann_viz
input_layer = int(str(layer.input_shape).split(&quot;,&quot;)[1][1:-1]);

AttributeError: &#39;Dense&#39; 对象没有属性 &#39;input_shape

为此：
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import pandas as pd`
`# 导入数据集
dataset = pd.read_csv(r&quot;Salary_Data (1).csv&quot;)
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 1].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = keras.Sequential([
keras.layers.Input(shape=(1,)),
keras.layers.Dense`(1)
])`
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
model.fit(`你的文本`X_train, y_train, epochs=2, batch_size=32, verbose=1)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f&quot;均方误差：{mse}&quot;)`

# 可视化数据和回归线

# 可视化神经网络
from ann_visualizer.visualize import ann_viz
from graphviz `你的文本`import Source
ann_viz(model,title=&#39;线性回归&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78980852/attributeerror-dense-object-has-no-attribute-output-shape-in-ann-visualizer</guid>
      <pubDate>Fri, 13 Sep 2024 06:14:36 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确地实现了带有反向传播的感知器？</title>
      <link>https://stackoverflow.com/questions/78961133/am-i-implementing-my-perceptron-with-backpropagation-correctly</link>
      <description><![CDATA[我在课堂上学习了感知器以及如何使用反向传播来训练模型。我目前在实施过程中遇到了麻烦，因为它仅能为我提供 50% 的准确率，而班上大多数同学的准确率都达到 90%。我在实施过程中是否忽略了什么？这是我目前从我查看过的资料中得到的结果。
class Perceptron():
def __init__(self, num_features):
self.num_features = num_features
self.weights = np.random.rand(num_features) * 0.1 # 这将创建一个用零填充的数组，形状为 num_features
self.bias = 0.0

def forward(self, x):
linear = np.dot(x, self.weights) + self.bias
print(linear)
predictions = np.where(linear &gt; 0, 1, 0)
return predictions

def behind(self, x, y, predictions):
errors = y - predictions
self.weights += self.learning_rate * np.dot(x.T, errors)
self.bias += self.learning_rate * np.sum(errors)
return errors

def train(self, x, y, epochs, learning_rate = 0.01):
self.learning_rate = learning_rate
for e in range(epochs):
for i in range(y.shape[0]):
x_i, y_i = x[i], y[i]
prediction = self.forward(x_i)
self.backward(x_i, y_i, prediction)

def assess(self, x, y):
predictions = self.forward(x)
accuracy = np.mean(predictions == y)
return accuracy

到目前为止，我已经尝试了不同的学习率，并询问了班上的其他人，说实话，这并没有真正改变我的实施结果。我期望准确率约为 90%，但实际只有 50%。
以下是一些示例数据：
0.77 -1.14 0
-0.33 1.44 0
0.91 -3.07 0
-0.37 -1.91 0
-1.84 -1.13 0
-1.50 0.34 0
-0.63 -1.53​​ 0
-1.08 -1.23 0
0.39 -1.99 0
-1.26 -2.90 0
-5.27 -0.78 0
-0.49 -2.74 0
1.48 -3.74 0
-1.64 -1.96 0
0.45 0.36 0
-1.48   -1.17 0 -2.94 -4.47 0 -2.19 -1.48 0 0.02 -0.02 0 -2.24 -2.12 0 -3.17 -3.69 0 -4.09 1.03 0 -2.41 -2.31 0 -3.45 -0.61 0 -3.96 -2.00 0 -2.95 -1。 16 0 -2.42 -3.35 0 -1.74 -1.10 0 -1.61 -1.28 0 -2.59 -2.21 0 -2.64 -2.20 0 -2.84 -4.12 0 -1.45 -2.26 0 -3.98 -1.05 0 -2.97   -1.63 0 -0.68 -1.52 0 -0.10 -3.43 0 -1.14 -2.66 0 -2.92 -2.51 0 -2.14 -1.62 0 -3.33 -0.44 0 -1.05 -3.85 0 0.38 0.95 0 -0.05 -1.95 0 -3.20 -0 22 0 -2.26 0.01 0 -1.41 -0.33 0 -1.20 -0.71 0 -1.69 0.80 0 -1.52 -1.14 0 3.88 0.65 1 0.73 2.97 1 0.83 3.94 1 1.59    1.25 1 3.92 3.48 1 3.87 2.91 1 1.14 3.91 1 1.73 2.80 1 2.95 1.84 1 2.61 2.92 1 2.38 0.90 1 2.30 3.33 1 1.31 1.85 1 1.56 3. 85 1 2.67 2.41 1 1.23 2.54 1 1.33 2.03 1 1.36 2.68 1 2.58 1.79 1 2.40 0.91 1 0.51 2.44 1 2.17 2.64 1 4.38 2.94 1 1.09 3.12    1 0.68 1.54 1 1.93 3.71 1 1.26 1.17 1 1.90 1.34 1 3.13 0.92 1 0.85 1.56 1 1.50 3.93 1 2.95 2.09 1 0.77 2.84 1 1.00 0.46 1 3.19 2.32 1 2.92 2.32 1 2.86 1.35 1 0.97 2.68 1 1.20 1.31 1 1.54 2.02 1 1.65 0.63 1 1.36 -0.22 1 2.63 0.40 1 0.90 2.05 1
1.26 3.54 1
0.71 2.27 1
1.96 0.83 1
2.52 1.83 1
2.77 2.82 1
4.16 3.34 1

在使用感知器模型之前，此代码首先进行随机化，然后分成2部分：原始数据的2/3用于训练，另外1/3用于测试。之后，对训练和测试数据集的前 2 个特征执行 z 分数标准化。
这是我使用该类的方式：
perceptron = Perceptron(num_features = 2)
perceptron.train(combined_x_train[:, :2], combined_x_train[:, 2], epochs = 5, learning_rate=0.1)
accuracy = perceptron.evaluate(x_train, y_train)
print(f&#39;Final Accuracy: {accuracy * 100:.2f}%&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78961133/am-i-implementing-my-perceptron-with-backpropagation-correctly</guid>
      <pubDate>Sat, 07 Sep 2024 21:05:33 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型聚合器 TensorFlow Federated</title>
      <link>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Federated，使用 FedAvg 算法模拟训练过程。
def model_fn():
# 包装 Keras 模型以用于 TensorFlow Federated
keras_model = get_uncompiled_model()

# 对于联合过程，模型必须是未编译的
return tff.learning.models. functional_model_from_keras(
keras_model,
loss_fn=tf.keras.losses.BinaryCrossentropy(),
input_spec=(
tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float32),
tf.TensorSpec(shape=[None], dtype=tf.int32)
),
metrics_constructor=collections.OrderedDict(
accuracy=tf.keras.metrics.BinaryAccuracy,
precision=tf.keras.metrics.Precision,
recall=tf.keras.metrics.Recall,
false_positives=tf.keras.metrics.FalsePositives,
false_negatives=tf.keras.metrics.FalseNegatives,
true_positives=tf.keras.metrics.TruePositives,
true_negatives=tf.keras.metrics.TrueNegatives
)
)

trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn= model_fn(),
client_optimizer_fn=client_optimizer,
server_optimizer_fn=server_optimizer
)

我想使用自定义权重来聚合客户端的更新，而不是使用它们的样本。我知道 tff.learning.algorithms.build_weighted_fed_avg() 有一个名为 client_weighting 的参数，但唯一接受的值来自类 tff.learning.ClientWeighting，它是一个枚举。
因此，唯一的方法似乎是编写自定义 WeightedAggregator。我尝试按照本教程进行操作，该教程解释了如何编写无加权聚合器，但我无法将其转换为加权聚合器。
这是我尝试做的：
@tff.tensorflow.computation
def custom_weighted_aggregate(values, weights):
# 规范化客户端权重
total_weight = tf.reduce_sum(weights)
normalized_weights = weights / total_weight

# 计算客户端更新的加权总和
weighted_sum = tf.nest.map_structure(
lambda v: tf.reduce_sum(normalized_weights * v, axis=0),
values
)

return weighted_sum

class CustomWeightedAggregator(tff.aggregators.WeightedAggregationFactory):
def __init__(self):
pass

def create(self, value_type, weight_type):
@tff.federated_computation
def initialize():
return tff.federated_value(0.0, tff.SERVER)

@tff.federated_computation(
initialize.type_signature.result,
tff.FederatedType(value_type, tff.CLIENTS),
tff.FederatedType(weight_type, tff.CLIENTS)
)
def next(state, value, weight):
aggregate_value = tff.federated_map(custom_weighted_aggregate, (value, weight))
return tff.templates.MeasuredProcessOutput(
state,aggregate_value,tff.federated_value((),tff.SERVER)
)

return tff.templates.AggregationProcess(initialize,next)

@property
def is_weighted(self):
return True

但是我得到了以下错误：
AggregationPlacementError：next_fn 返回类型的“result”属性必须放置在 SERVER 中，但发现 {&lt;float32[7],float32,float32[1],float32&gt;}@CLIENTS。]]></description>
      <guid>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</guid>
      <pubDate>Mon, 05 Aug 2024 16:06:48 GMT</pubDate>
    </item>
    <item>
      <title>设置 SciKeras 模型时出现问题</title>
      <link>https://stackoverflow.com/questions/66094139/issue-setting-up-scikeras-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/66094139/issue-setting-up-scikeras-model</guid>
      <pubDate>Sun, 07 Feb 2021 23:19:56 GMT</pubDate>
    </item>
    <item>
      <title>批次内的数据是否应该平衡？</title>
      <link>https://stackoverflow.com/questions/48200136/should-the-data-in-batch-be-balanced</link>
      <description><![CDATA[我正在训练一个深度学习模型，通过输入推文内容来预测三种情绪（快乐、悲伤、愤怒）。
我遇到的一个问题是，我的模型在悲伤、快乐方面学习得很好，但在快乐方面学习得很糟糕。

我认为原因是我的训练数据集不平衡。
快乐中的数据大小：196952，悲伤：29407，愤怒：42420
因此，在训练模型时，批量大小包含太多快乐数据集，这使得模型只能猜测答案是快乐而不是其他。
我想通过平衡每个数据集中的数据来解决这个问题批次。
也就是说批次大小为 128，我们随机选择相同数量的三种情绪数据。防止模型被快乐数据所主导。
问题是：批次中的数据应该平衡吗？
另一个问题是，我随机选择了数据集，这是否违反了 epoch 的定义？
因为 epoch 意味着读取所有训练数据集。当随机选择时，可能某些数据集在某些 epoch 中不会被选择。或者只需训练更多 epoch 即可解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/48200136/should-the-data-in-batch-be-balanced</guid>
      <pubDate>Thu, 11 Jan 2018 05:09:56 GMT</pubDate>
    </item>
    <item>
      <title>推荐相关项目的推荐算法</title>
      <link>https://stackoverflow.com/questions/43029589/recommender-algorithm-to-recommend-associated-items</link>
      <description><![CDATA[我有一个场景，我想提供建议。为简单起见，假设我有包含购买和购买项目记录的数据库表。每个购买项目都描述了应用程序向用户呈现的每件商品的数量、描述（鞋子、裤子、衬衫）以及总价。通常，与特定购买相关的购买项目或一系列购买项目会自动触发添加其他相关购买项目以进行类似类型的购买（也许他们想添加帽子或手套）。
需要注意的是，没有为这些类型的项目分配类别。它们可能完全不相关，除非它们定期一起应用于购买（衬衫、食物和相机不相关，但可能经常一起购买）。也就是说，这是用户的购买习惯，而不是（推荐帽子，因为它们是一种像衬衫一样的服装）。
我尝试了推荐算法，但不完全了解如何在这种情况下应用它。这是我应该关注的正确算法吗？]]></description>
      <guid>https://stackoverflow.com/questions/43029589/recommender-algorithm-to-recommend-associated-items</guid>
      <pubDate>Sun, 26 Mar 2017 13:52:13 GMT</pubDate>
    </item>
    <item>
      <title>多步预测神经网络</title>
      <link>https://stackoverflow.com/questions/10327260/multi-step-prediction-neural-networks</link>
      <description><![CDATA[我一直在使用 matlab 神经网络工具包。这里我使用的是 NARX 网络。我有一个数据集，其中包含某个物品的价格以及在一段时间内购买的物品数量。本质上，这个网络执行一步预测，其数学定义如下：
y(t)= f (y(t −1),y(t −2),...,y(t −ny),x(t −1),x(t −2),...,x(t −nx))
这里 y(t) 是时间 t 时的价格，x 是金额。所以我使用的输入特征是价格和金额，目标是时间 t+1 时的价格。假设我有 100 条此类交易的记录，每笔交易都包含价格和金额。那么我的神经网络基本上可以预测第 101 笔交易的价格。这对于一步预测来说效果很好。但是，如果我想进行多步预测，比如说我想预测未来 10 笔交易（第 110 笔交易），那么我假设我对价格进行一步预测，然后将其反馈给神经网络。我一直这样做，直到达到第 110 次预测。但是，在这种情况下，在我预测第 101 个价格后，我可以将此价格输入神经网络以预测第 102 个价格，但是，我不知道第 101 笔交易的物品数量。我该怎么做？我正在考虑将我的目标设置为比当前交易提前 10 笔交易的交易价格，这样当我预测第 101 笔交易时，我基本上就是在预测第 110 笔交易的价格。这是一个可行的解决方案吗，还是我完全错误地处理了这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/10327260/multi-step-prediction-neural-networks</guid>
      <pubDate>Thu, 26 Apr 2012 04:28:45 GMT</pubDate>
    </item>
    </channel>
</rss>